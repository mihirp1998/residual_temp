vid count  30510
total images: 457647; total batches: 114412
hypernet  603253760
encoder  0
decoder  0
binarizer  0
Loaded
[TRAIN] Epoch[1](1/114412); Loss: 0.053044; Backpropagation: 0.3207 sec; Batch: 2.1611 sec
0.0990 0.0752 0.0636 0.0576 0.0544 0.0512 0.0490 0.0476 0.0461 0.0452 0.0445 0.0440 0.0435 0.0429 0.0426 0.0424 

[TRAIN] Epoch[1](2/114412); Loss: 0.067344; Backpropagation: 0.2955 sec; Batch: 2.1153 sec
0.1339 0.0891 0.0771 0.0716 0.0665 0.0630 0.0612 0.0600 0.0589 0.0581 0.0575 0.0569 0.0564 0.0560 0.0557 0.0555 

[TRAIN] Epoch[1](3/114412); Loss: 0.065060; Backpropagation: 0.2919 sec; Batch: 2.0869 sec
0.1001 0.0827 0.0732 0.0688 0.0656 0.0633 0.0616 0.0605 0.0595 0.0590 0.0585 0.0581 0.0579 0.0576 0.0575 0.0573 

[TRAIN] Epoch[1](4/114412); Loss: 0.082717; Backpropagation: 0.2921 sec; Batch: 2.0833 sec
0.1542 0.1173 0.1015 0.0835 0.0792 0.0778 0.0747 0.0734 0.0721 0.0714 0.0710 0.0701 0.0698 0.0695 0.0691 0.0689 

[TRAIN] Epoch[1](5/114412); Loss: 0.053020; Backpropagation: 0.2931 sec; Batch: 2.0800 sec
0.1126 0.0929 0.0714 0.0590 0.0516 0.0480 0.0452 0.0436 0.0427 0.0415 0.0410 0.0405 0.0400 0.0397 0.0395 0.0392 

[TRAIN] Epoch[1](6/114412); Loss: 0.058120; Backpropagation: 0.2951 sec; Batch: 2.0837 sec
0.0972 0.0773 0.0673 0.0624 0.0582 0.0562 0.0545 0.0534 0.0522 0.0516 0.0509 0.0504 0.0500 0.0496 0.0495 0.0492 

[TRAIN] Epoch[1](7/114412); Loss: 0.050225; Backpropagation: 0.2930 sec; Batch: 2.0887 sec
0.0922 0.0727 0.0608 0.0552 0.0503 0.0476 0.0459 0.0447 0.0436 0.0430 0.0424 0.0418 0.0414 0.0410 0.0407 0.0404 

[TRAIN] Epoch[1](8/114412); Loss: 0.070518; Backpropagation: 0.2933 sec; Batch: 2.0888 sec
0.1283 0.1027 0.0877 0.0754 0.0709 0.0670 0.0650 0.0629 0.0616 0.0604 0.0593 0.0584 0.0578 0.0573 0.0570 0.0567 

[TRAIN] Epoch[1](9/114412); Loss: 0.048294; Backpropagation: 0.2915 sec; Batch: 2.0927 sec
0.1010 0.0723 0.0623 0.0557 0.0481 0.0458 0.0439 0.0421 0.0398 0.0389 0.0385 0.0375 0.0371 0.0368 0.0365 0.0363 

[TRAIN] Epoch[1](10/114412); Loss: 0.075746; Backpropagation: 0.2907 sec; Batch: 2.0788 sec
0.1198 0.1002 0.0903 0.0847 0.0780 0.0743 0.0720 0.0700 0.0683 0.0672 0.0662 0.0654 0.0648 0.0641 0.0636 0.0632 

[TRAIN] Epoch[1](11/114412); Loss: 0.056842; Backpropagation: 0.2913 sec; Batch: 2.1070 sec
0.0903 0.1084 0.0874 0.0668 0.0558 0.0509 0.0487 0.0471 0.0462 0.0452 0.0447 0.0442 0.0438 0.0435 0.0433 0.0431 

[TRAIN] Epoch[1](12/114412); Loss: 0.066486; Backpropagation: 0.2905 sec; Batch: 2.0864 sec
0.1038 0.0856 0.0764 0.0704 0.0667 0.0643 0.0627 0.0616 0.0608 0.0601 0.0596 0.0591 0.0586 0.0583 0.0580 0.0578 

[TRAIN] Epoch[1](13/114412); Loss: 0.088390; Backpropagation: 0.2955 sec; Batch: 2.0834 sec
0.1445 0.1199 0.1062 0.0959 0.0900 0.0877 0.0841 0.0809 0.0789 0.0777 0.0763 0.0755 0.0748 0.0742 0.0739 0.0735 

[TRAIN] Epoch[1](14/114412); Loss: 0.045186; Backpropagation: 0.2952 sec; Batch: 2.0825 sec
0.0979 0.0575 0.0527 0.0464 0.0435 0.0418 0.0405 0.0399 0.0393 0.0386 0.0381 0.0378 0.0376 0.0373 0.0372 0.0370 

[TRAIN] Epoch[1](15/114412); Loss: 0.055281; Backpropagation: 0.2943 sec; Batch: 2.0903 sec
0.1041 0.0756 0.0650 0.0585 0.0550 0.0528 0.0509 0.0495 0.0484 0.0476 0.0470 0.0467 0.0463 0.0459 0.0457 0.0454 

[TRAIN] Epoch[1](16/114412); Loss: 0.058054; Backpropagation: 0.2941 sec; Batch: 2.0817 sec
0.1075 0.0849 0.0728 0.0645 0.0605 0.0564 0.0534 0.0512 0.0498 0.0487 0.0479 0.0472 0.0466 0.0461 0.0458 0.0455 

[TRAIN] Epoch[1](17/114412); Loss: 0.059400; Backpropagation: 0.2915 sec; Batch: 2.0785 sec
0.1001 0.0844 0.0688 0.0651 0.0606 0.0570 0.0553 0.0537 0.0524 0.0518 0.0512 0.0507 0.0503 0.0499 0.0496 0.0494 

[TRAIN] Epoch[1](18/114412); Loss: 0.037563; Backpropagation: 0.2952 sec; Batch: 2.0819 sec
0.0849 0.0585 0.0484 0.0418 0.0377 0.0345 0.0328 0.0317 0.0304 0.0299 0.0294 0.0288 0.0285 0.0282 0.0279 0.0276 

[TRAIN] Epoch[1](19/114412); Loss: 0.071474; Backpropagation: 0.2930 sec; Batch: 2.0815 sec
0.1287 0.1073 0.0894 0.0800 0.0738 0.0684 0.0646 0.0624 0.0610 0.0601 0.0594 0.0586 0.0580 0.0577 0.0573 0.0572 

[TRAIN] Epoch[1](20/114412); Loss: 0.062172; Backpropagation: 0.2915 sec; Batch: 2.0787 sec
0.1458 0.1102 0.0936 0.0755 0.0558 0.0535 0.0512 0.0486 0.0473 0.0464 0.0456 0.0450 0.0445 0.0441 0.0439 0.0437 

[TRAIN] Epoch[1](21/114412); Loss: 0.048305; Backpropagation: 0.2914 sec; Batch: 2.0899 sec
0.1191 0.0883 0.0654 0.0523 0.0467 0.0412 0.0394 0.0376 0.0371 0.0364 0.0357 0.0353 0.0350 0.0347 0.0344 0.0342 

[TRAIN] Epoch[1](22/114412); Loss: 0.081737; Backpropagation: 0.2931 sec; Batch: 2.0820 sec
0.1242 0.1003 0.0906 0.0859 0.0827 0.0801 0.0779 0.0767 0.0755 0.0747 0.0742 0.0736 0.0733 0.0730 0.0727 0.0725 

[TRAIN] Epoch[1](23/114412); Loss: 0.062796; Backpropagation: 0.2913 sec; Batch: 2.0796 sec
0.1015 0.0854 0.0784 0.0697 0.0640 0.0616 0.0588 0.0570 0.0560 0.0549 0.0542 0.0535 0.0530 0.0526 0.0522 0.0520 

[TRAIN] Epoch[1](24/114412); Loss: 0.052130; Backpropagation: 0.2910 sec; Batch: 2.0776 sec
0.1395 0.1084 0.0921 0.0630 0.0490 0.0427 0.0405 0.0359 0.0347 0.0342 0.0333 0.0328 0.0323 0.0320 0.0319 0.0317 

[TRAIN] Epoch[1](25/114412); Loss: 0.069767; Backpropagation: 0.2912 sec; Batch: 2.0792 sec
0.1219 0.0999 0.0853 0.0776 0.0718 0.0684 0.0652 0.0633 0.0617 0.0600 0.0588 0.0577 0.0569 0.0564 0.0558 0.0554 

[TRAIN] Epoch[1](26/114412); Loss: 0.043639; Backpropagation: 0.2910 sec; Batch: 2.0780 sec
0.1091 0.0628 0.0542 0.0475 0.0431 0.0396 0.0378 0.0361 0.0352 0.0344 0.0338 0.0335 0.0332 0.0329 0.0326 0.0324 

[TRAIN] Epoch[1](27/114412); Loss: 0.050110; Backpropagation: 0.2929 sec; Batch: 2.0811 sec
0.1195 0.0796 0.0643 0.0527 0.0474 0.0439 0.0420 0.0411 0.0403 0.0399 0.0393 0.0388 0.0385 0.0383 0.0381 0.0379 

[TRAIN] Epoch[1](28/114412); Loss: 0.057553; Backpropagation: 0.2914 sec; Batch: 2.0788 sec
0.0880 0.0784 0.0687 0.0614 0.0590 0.0564 0.0543 0.0530 0.0519 0.0512 0.0507 0.0502 0.0497 0.0495 0.0492 0.0490 

[TRAIN] Epoch[1](29/114412); Loss: 0.057340; Backpropagation: 0.2909 sec; Batch: 2.0774 sec
0.1005 0.0822 0.0738 0.0625 0.0595 0.0551 0.0521 0.0512 0.0495 0.0486 0.0481 0.0475 0.0471 0.0468 0.0466 0.0464 

[TRAIN] Epoch[1](30/114412); Loss: 0.056491; Backpropagation: 0.2912 sec; Batch: 2.0790 sec
0.0942 0.0769 0.0693 0.0601 0.0567 0.0545 0.0531 0.0507 0.0500 0.0495 0.0489 0.0486 0.0482 0.0480 0.0477 0.0475 

[TRAIN] Epoch[1](31/114412); Loss: 0.062598; Backpropagation: 0.2911 sec; Batch: 2.0788 sec
0.1161 0.0803 0.0735 0.0676 0.0638 0.0605 0.0580 0.0562 0.0553 0.0547 0.0537 0.0531 0.0526 0.0524 0.0519 0.0517 

[TRAIN] Epoch[1](32/114412); Loss: 0.069397; Backpropagation: 0.2909 sec; Batch: 2.0775 sec
0.1295 0.1075 0.0924 0.0762 0.0677 0.0644 0.0620 0.0602 0.0590 0.0580 0.0571 0.0564 0.0558 0.0552 0.0547 0.0542 

[TRAIN] Epoch[1](33/114412); Loss: 0.045346; Backpropagation: 0.2914 sec; Batch: 2.0862 sec
0.0823 0.0662 0.0582 0.0503 0.0463 0.0433 0.0418 0.0404 0.0393 0.0383 0.0377 0.0371 0.0366 0.0363 0.0359 0.0355 

[TRAIN] Epoch[1](34/114412); Loss: 0.047305; Backpropagation: 0.2912 sec; Batch: 2.0787 sec
0.1064 0.0830 0.0662 0.0511 0.0475 0.0443 0.0410 0.0388 0.0379 0.0361 0.0353 0.0346 0.0341 0.0338 0.0335 0.0333 

[TRAIN] Epoch[1](35/114412); Loss: 0.080162; Backpropagation: 0.2938 sec; Batch: 2.0810 sec
0.1277 0.1033 0.0942 0.0870 0.0808 0.0776 0.0751 0.0737 0.0725 0.0715 0.0709 0.0704 0.0699 0.0696 0.0693 0.0691 

[TRAIN] Epoch[1](36/114412); Loss: 0.057980; Backpropagation: 0.2913 sec; Batch: 2.0786 sec
0.0954 0.0775 0.0685 0.0622 0.0584 0.0558 0.0544 0.0531 0.0522 0.0513 0.0508 0.0503 0.0499 0.0496 0.0493 0.0490 

[TRAIN] Epoch[1](37/114412); Loss: 0.068434; Backpropagation: 0.2906 sec; Batch: 2.0780 sec
0.0976 0.0881 0.0793 0.0728 0.0694 0.0666 0.0651 0.0637 0.0630 0.0625 0.0619 0.0615 0.0612 0.0609 0.0608 0.0606 

[TRAIN] Epoch[1](38/114412); Loss: 0.066623; Backpropagation: 0.2903 sec; Batch: 2.0769 sec
0.0977 0.0876 0.0799 0.0721 0.0689 0.0658 0.0632 0.0617 0.0606 0.0596 0.0591 0.0587 0.0582 0.0578 0.0576 0.0575 

[TRAIN] Epoch[1](39/114412); Loss: 0.055042; Backpropagation: 0.2910 sec; Batch: 2.0778 sec
0.0891 0.0812 0.0667 0.0609 0.0563 0.0538 0.0514 0.0494 0.0483 0.0475 0.0469 0.0464 0.0461 0.0457 0.0455 0.0453 

[TRAIN] Epoch[1](40/114412); Loss: 0.029288; Backpropagation: 0.2911 sec; Batch: 2.0782 sec
0.0880 0.0425 0.0328 0.0304 0.0281 0.0253 0.0245 0.0234 0.0227 0.0223 0.0219 0.0216 0.0215 0.0213 0.0212 0.0211 

[TRAIN] Epoch[1](41/114412); Loss: 0.086386; Backpropagation: 0.2913 sec; Batch: 2.0774 sec
0.1216 0.1073 0.0971 0.0907 0.0869 0.0848 0.0831 0.0819 0.0809 0.0799 0.0792 0.0785 0.0780 0.0777 0.0773 0.0771 

[TRAIN] Epoch[1](42/114412); Loss: 0.076759; Backpropagation: 0.2931 sec; Batch: 2.0796 sec
0.1283 0.1036 0.0935 0.0839 0.0766 0.0739 0.0719 0.0701 0.0685 0.0676 0.0667 0.0657 0.0652 0.0647 0.0642 0.0638 

[TRAIN] Epoch[1](43/114412); Loss: 0.053589; Backpropagation: 0.2911 sec; Batch: 2.0771 sec
0.0988 0.0820 0.0662 0.0583 0.0525 0.0499 0.0484 0.0473 0.0460 0.0454 0.0446 0.0443 0.0439 0.0436 0.0433 0.0430 

[TRAIN] Epoch[1](44/114412); Loss: 0.074968; Backpropagation: 0.2913 sec; Batch: 2.0783 sec
0.1201 0.1030 0.0899 0.0826 0.0772 0.0738 0.0704 0.0688 0.0674 0.0659 0.0651 0.0643 0.0636 0.0629 0.0624 0.0621 

[TRAIN] Epoch[1](45/114412); Loss: 0.064239; Backpropagation: 0.2910 sec; Batch: 2.0779 sec
0.1183 0.1014 0.0856 0.0746 0.0677 0.0623 0.0589 0.0560 0.0547 0.0524 0.0514 0.0502 0.0495 0.0489 0.0482 0.0478 

[TRAIN] Epoch[1](46/114412); Loss: 0.057758; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.1093 0.0730 0.0658 0.0600 0.0576 0.0563 0.0540 0.0522 0.0513 0.0506 0.0501 0.0495 0.0490 0.0487 0.0484 0.0482 

[TRAIN] Epoch[1](47/114412); Loss: 0.051641; Backpropagation: 0.2952 sec; Batch: 2.0820 sec
0.0904 0.0770 0.0604 0.0535 0.0510 0.0485 0.0471 0.0463 0.0453 0.0448 0.0443 0.0439 0.0437 0.0435 0.0433 0.0432 

[TRAIN] Epoch[1](48/114412); Loss: 0.067605; Backpropagation: 0.2950 sec; Batch: 2.0811 sec
0.1092 0.0927 0.0818 0.0758 0.0721 0.0662 0.0629 0.0613 0.0601 0.0589 0.0581 0.0575 0.0569 0.0565 0.0561 0.0557 

[TRAIN] Epoch[1](49/114412); Loss: 0.055835; Backpropagation: 0.2955 sec; Batch: 2.0816 sec
0.1259 0.1013 0.0847 0.0688 0.0573 0.0514 0.0469 0.0438 0.0429 0.0410 0.0396 0.0389 0.0384 0.0379 0.0374 0.0371 

[TRAIN] Epoch[1](50/114412); Loss: 0.069083; Backpropagation: 0.2928 sec; Batch: 2.0787 sec
0.1077 0.0868 0.0789 0.0720 0.0691 0.0674 0.0654 0.0643 0.0634 0.0626 0.0622 0.0617 0.0614 0.0611 0.0608 0.0606 

[TRAIN] Epoch[1](51/114412); Loss: 0.043829; Backpropagation: 0.2954 sec; Batch: 2.0816 sec
0.0922 0.0689 0.0581 0.0502 0.0443 0.0410 0.0389 0.0371 0.0360 0.0350 0.0343 0.0336 0.0332 0.0330 0.0327 0.0326 

[TRAIN] Epoch[1](52/114412); Loss: 0.055760; Backpropagation: 0.2950 sec; Batch: 2.0808 sec
0.0962 0.0820 0.0691 0.0596 0.0555 0.0532 0.0508 0.0493 0.0487 0.0479 0.0475 0.0471 0.0467 0.0464 0.0462 0.0459 

[TRAIN] Epoch[1](53/114412); Loss: 0.054665; Backpropagation: 0.2929 sec; Batch: 2.0794 sec
0.0941 0.0805 0.0683 0.0616 0.0562 0.0530 0.0505 0.0488 0.0474 0.0466 0.0457 0.0451 0.0447 0.0444 0.0440 0.0437 

[TRAIN] Epoch[1](54/114412); Loss: 0.044234; Backpropagation: 0.2909 sec; Batch: 2.0767 sec
0.0886 0.0744 0.0609 0.0506 0.0433 0.0405 0.0390 0.0374 0.0363 0.0351 0.0344 0.0340 0.0336 0.0334 0.0331 0.0330 

[TRAIN] Epoch[1](55/114412); Loss: 0.082315; Backpropagation: 0.2913 sec; Batch: 2.0775 sec
0.1283 0.1102 0.0999 0.0876 0.0841 0.0806 0.0777 0.0757 0.0743 0.0733 0.0723 0.0717 0.0711 0.0705 0.0700 0.0697 

[TRAIN] Epoch[1](56/114412); Loss: 0.073056; Backpropagation: 0.2910 sec; Batch: 2.0833 sec
0.1044 0.0951 0.0842 0.0766 0.0737 0.0711 0.0695 0.0683 0.0675 0.0667 0.0661 0.0657 0.0654 0.0650 0.0649 0.0647 

[TRAIN] Epoch[1](57/114412); Loss: 0.056820; Backpropagation: 0.2912 sec; Batch: 2.0845 sec
0.0894 0.0772 0.0675 0.0605 0.0573 0.0556 0.0539 0.0521 0.0510 0.0505 0.0500 0.0494 0.0491 0.0488 0.0486 0.0484 

[TRAIN] Epoch[1](58/114412); Loss: 0.041060; Backpropagation: 0.2914 sec; Batch: 2.0793 sec
0.0703 0.0661 0.0524 0.0478 0.0434 0.0409 0.0379 0.0363 0.0352 0.0342 0.0332 0.0326 0.0322 0.0318 0.0314 0.0312 

[TRAIN] Epoch[1](59/114412); Loss: 0.078484; Backpropagation: 0.2911 sec; Batch: 2.0759 sec
0.1160 0.1029 0.0929 0.0862 0.0813 0.0770 0.0747 0.0732 0.0715 0.0704 0.0696 0.0690 0.0683 0.0679 0.0675 0.0674 

[TRAIN] Epoch[1](60/114412); Loss: 0.050107; Backpropagation: 0.2911 sec; Batch: 2.0774 sec
0.0950 0.0652 0.0591 0.0530 0.0505 0.0489 0.0459 0.0449 0.0442 0.0433 0.0429 0.0424 0.0419 0.0418 0.0415 0.0412 

[TRAIN] Epoch[1](61/114412); Loss: 0.092323; Backpropagation: 0.2907 sec; Batch: 2.0763 sec
0.1537 0.1325 0.1151 0.1007 0.0918 0.0872 0.0844 0.0826 0.0814 0.0801 0.0793 0.0786 0.0780 0.0776 0.0773 0.0770 

[TRAIN] Epoch[1](62/114412); Loss: 0.087384; Backpropagation: 0.2907 sec; Batch: 2.0761 sec
0.1427 0.1200 0.1048 0.0969 0.0910 0.0855 0.0823 0.0799 0.0780 0.0763 0.0752 0.0742 0.0736 0.0730 0.0725 0.0722 

[TRAIN] Epoch[1](63/114412); Loss: 0.068105; Backpropagation: 0.2925 sec; Batch: 2.0771 sec
0.0950 0.0849 0.0771 0.0716 0.0693 0.0674 0.0656 0.0645 0.0634 0.0627 0.0623 0.0617 0.0614 0.0612 0.0609 0.0607 

[TRAIN] Epoch[1](64/114412); Loss: 0.078219; Backpropagation: 0.2930 sec; Batch: 2.0792 sec
0.1300 0.1044 0.0895 0.0821 0.0773 0.0752 0.0728 0.0713 0.0704 0.0697 0.0691 0.0686 0.0682 0.0679 0.0677 0.0674 

[TRAIN] Epoch[1](65/114412); Loss: 0.045786; Backpropagation: 0.2925 sec; Batch: 2.0777 sec
0.0848 0.0670 0.0547 0.0491 0.0467 0.0440 0.0416 0.0405 0.0397 0.0390 0.0384 0.0379 0.0377 0.0374 0.0372 0.0370 

[TRAIN] Epoch[1](66/114412); Loss: 0.070682; Backpropagation: 0.2910 sec; Batch: 2.0770 sec
0.1293 0.1039 0.0903 0.0762 0.0701 0.0663 0.0641 0.0618 0.0606 0.0599 0.0591 0.0586 0.0582 0.0578 0.0575 0.0573 

[TRAIN] Epoch[1](67/114412); Loss: 0.065592; Backpropagation: 0.2912 sec; Batch: 2.0769 sec
0.1096 0.0949 0.0815 0.0730 0.0658 0.0633 0.0612 0.0594 0.0573 0.0565 0.0558 0.0551 0.0546 0.0542 0.0539 0.0537 

[TRAIN] Epoch[1](68/114412); Loss: 0.053209; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1147 0.0913 0.0700 0.0600 0.0527 0.0477 0.0452 0.0435 0.0424 0.0416 0.0411 0.0407 0.0404 0.0402 0.0400 0.0399 

[TRAIN] Epoch[1](69/114412); Loss: 0.061421; Backpropagation: 0.2908 sec; Batch: 2.0771 sec
0.1215 0.1047 0.0824 0.0682 0.0622 0.0565 0.0537 0.0519 0.0505 0.0494 0.0484 0.0476 0.0471 0.0465 0.0461 0.0459 

[TRAIN] Epoch[1](70/114412); Loss: 0.060730; Backpropagation: 0.2954 sec; Batch: 2.0801 sec
0.0974 0.0829 0.0743 0.0665 0.0627 0.0594 0.0572 0.0561 0.0543 0.0532 0.0526 0.0518 0.0513 0.0511 0.0506 0.0503 

[TRAIN] Epoch[1](71/114412); Loss: 0.054409; Backpropagation: 0.2928 sec; Batch: 2.0780 sec
0.0888 0.0805 0.0674 0.0587 0.0541 0.0519 0.0501 0.0488 0.0480 0.0474 0.0466 0.0462 0.0459 0.0455 0.0454 0.0452 

[TRAIN] Epoch[1](72/114412); Loss: 0.052040; Backpropagation: 0.2928 sec; Batch: 2.0781 sec
0.0910 0.0804 0.0680 0.0574 0.0522 0.0488 0.0467 0.0455 0.0445 0.0438 0.0432 0.0427 0.0425 0.0423 0.0420 0.0419 

[TRAIN] Epoch[1](73/114412); Loss: 0.045733; Backpropagation: 0.2953 sec; Batch: 2.0807 sec
0.0893 0.0610 0.0526 0.0488 0.0448 0.0432 0.0419 0.0411 0.0404 0.0396 0.0391 0.0386 0.0382 0.0380 0.0377 0.0375 

[TRAIN] Epoch[1](74/114412); Loss: 0.048328; Backpropagation: 0.2951 sec; Batch: 2.0791 sec
0.0974 0.0808 0.0620 0.0539 0.0484 0.0442 0.0429 0.0411 0.0399 0.0390 0.0383 0.0378 0.0374 0.0370 0.0367 0.0365 

[TRAIN] Epoch[1](75/114412); Loss: 0.068252; Backpropagation: 0.2931 sec; Batch: 2.0778 sec
0.1271 0.0930 0.0817 0.0737 0.0677 0.0652 0.0624 0.0609 0.0599 0.0587 0.0579 0.0574 0.0570 0.0567 0.0564 0.0562 

[TRAIN] Epoch[1](76/114412); Loss: 0.060647; Backpropagation: 0.2943 sec; Batch: 2.0799 sec
0.1164 0.1000 0.0818 0.0712 0.0598 0.0556 0.0538 0.0521 0.0500 0.0487 0.0481 0.0474 0.0469 0.0465 0.0461 0.0458 

[TRAIN] Epoch[1](77/114412); Loss: 0.040164; Backpropagation: 0.2951 sec; Batch: 2.0798 sec
0.0779 0.0529 0.0483 0.0427 0.0391 0.0389 0.0369 0.0360 0.0352 0.0346 0.0341 0.0337 0.0335 0.0332 0.0329 0.0328 

[TRAIN] Epoch[1](78/114412); Loss: 0.051612; Backpropagation: 0.2930 sec; Batch: 2.0772 sec
0.0910 0.0684 0.0586 0.0549 0.0522 0.0493 0.0478 0.0466 0.0457 0.0452 0.0448 0.0445 0.0444 0.0442 0.0441 0.0441 

[TRAIN] Epoch[1](79/114412); Loss: 0.062412; Backpropagation: 0.2929 sec; Batch: 2.0770 sec
0.1155 0.0988 0.0814 0.0730 0.0641 0.0602 0.0567 0.0548 0.0528 0.0514 0.0502 0.0493 0.0484 0.0479 0.0473 0.0469 

[TRAIN] Epoch[1](80/114412); Loss: 0.056560; Backpropagation: 0.2954 sec; Batch: 2.0807 sec
0.1012 0.0876 0.0783 0.0651 0.0588 0.0551 0.0509 0.0498 0.0476 0.0458 0.0451 0.0445 0.0441 0.0439 0.0437 0.0436 

[TRAIN] Epoch[1](81/114412); Loss: 0.071608; Backpropagation: 0.2954 sec; Batch: 2.0795 sec
0.1304 0.1112 0.0938 0.0803 0.0725 0.0668 0.0643 0.0626 0.0609 0.0595 0.0585 0.0578 0.0573 0.0570 0.0566 0.0564 

[TRAIN] Epoch[1](82/114412); Loss: 0.041964; Backpropagation: 0.2910 sec; Batch: 2.0762 sec
0.0848 0.0686 0.0505 0.0449 0.0427 0.0390 0.0372 0.0362 0.0350 0.0343 0.0338 0.0333 0.0331 0.0328 0.0326 0.0326 

[TRAIN] Epoch[1](83/114412); Loss: 0.068112; Backpropagation: 0.2910 sec; Batch: 2.0757 sec
0.1122 0.0931 0.0820 0.0746 0.0695 0.0664 0.0639 0.0619 0.0607 0.0596 0.0588 0.0581 0.0578 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](84/114412); Loss: 0.061825; Backpropagation: 0.2907 sec; Batch: 2.0759 sec
0.1190 0.0895 0.0767 0.0648 0.0627 0.0579 0.0553 0.0540 0.0530 0.0521 0.0515 0.0511 0.0508 0.0505 0.0503 0.0501 

[TRAIN] Epoch[1](85/114412); Loss: 0.070375; Backpropagation: 0.2908 sec; Batch: 2.0747 sec
0.1207 0.1076 0.0909 0.0784 0.0725 0.0673 0.0644 0.0619 0.0609 0.0592 0.0584 0.0576 0.0571 0.0567 0.0563 0.0560 

[TRAIN] Epoch[1](86/114412); Loss: 0.073204; Backpropagation: 0.2904 sec; Batch: 2.0749 sec
0.1182 0.0992 0.0863 0.0780 0.0751 0.0723 0.0690 0.0671 0.0654 0.0645 0.0638 0.0632 0.0628 0.0624 0.0622 0.0618 

[TRAIN] Epoch[1](87/114412); Loss: 0.060692; Backpropagation: 0.2912 sec; Batch: 2.0753 sec
0.1273 0.0989 0.0813 0.0700 0.0615 0.0549 0.0517 0.0507 0.0491 0.0480 0.0474 0.0468 0.0463 0.0460 0.0457 0.0455 

[TRAIN] Epoch[1](88/114412); Loss: 0.070799; Backpropagation: 0.2909 sec; Batch: 2.0757 sec
0.1199 0.1032 0.0893 0.0796 0.0703 0.0674 0.0649 0.0630 0.0617 0.0608 0.0599 0.0593 0.0587 0.0585 0.0582 0.0578 

[TRAIN] Epoch[1](89/114412); Loss: 0.072099; Backpropagation: 0.2929 sec; Batch: 2.0766 sec
0.1185 0.1025 0.0862 0.0780 0.0720 0.0688 0.0671 0.0657 0.0639 0.0630 0.0623 0.0617 0.0615 0.0610 0.0608 0.0606 

[TRAIN] Epoch[1](90/114412); Loss: 0.066528; Backpropagation: 0.2927 sec; Batch: 2.0768 sec
0.1061 0.0848 0.0756 0.0705 0.0669 0.0640 0.0623 0.0614 0.0604 0.0600 0.0594 0.0591 0.0588 0.0586 0.0584 0.0582 

[TRAIN] Epoch[1](91/114412); Loss: 0.076001; Backpropagation: 0.2908 sec; Batch: 2.0746 sec
0.1288 0.1018 0.0909 0.0839 0.0774 0.0736 0.0710 0.0691 0.0676 0.0666 0.0656 0.0649 0.0643 0.0639 0.0636 0.0632 

[TRAIN] Epoch[1](92/114412); Loss: 0.046336; Backpropagation: 0.2911 sec; Batch: 2.0759 sec
0.0952 0.0672 0.0580 0.0529 0.0472 0.0434 0.0414 0.0400 0.0390 0.0381 0.0375 0.0370 0.0366 0.0363 0.0361 0.0358 

[TRAIN] Epoch[1](93/114412); Loss: 0.043311; Backpropagation: 0.2913 sec; Batch: 2.0764 sec
0.0991 0.0741 0.0599 0.0470 0.0439 0.0421 0.0369 0.0356 0.0345 0.0329 0.0324 0.0317 0.0312 0.0308 0.0306 0.0303 

[TRAIN] Epoch[1](94/114412); Loss: 0.078378; Backpropagation: 0.2911 sec; Batch: 2.0754 sec
0.1625 0.1296 0.1116 0.0901 0.0761 0.0709 0.0670 0.0646 0.0630 0.0619 0.0609 0.0602 0.0595 0.0591 0.0588 0.0585 

[TRAIN] Epoch[1](95/114412); Loss: 0.057204; Backpropagation: 0.2928 sec; Batch: 2.0822 sec
0.1019 0.0813 0.0707 0.0628 0.0582 0.0551 0.0521 0.0508 0.0498 0.0489 0.0483 0.0478 0.0473 0.0470 0.0467 0.0464 

[TRAIN] Epoch[1](96/114412); Loss: 0.056257; Backpropagation: 0.2909 sec; Batch: 2.0772 sec
0.1424 0.0843 0.0664 0.0581 0.0525 0.0501 0.0484 0.0466 0.0457 0.0449 0.0444 0.0440 0.0436 0.0432 0.0430 0.0428 

[TRAIN] Epoch[1](97/114412); Loss: 0.050679; Backpropagation: 0.2910 sec; Batch: 2.0768 sec
0.1057 0.0742 0.0627 0.0537 0.0501 0.0472 0.0454 0.0440 0.0429 0.0421 0.0415 0.0410 0.0406 0.0402 0.0399 0.0396 

[TRAIN] Epoch[1](98/114412); Loss: 0.040395; Backpropagation: 0.2910 sec; Batch: 2.0761 sec
0.0944 0.0667 0.0500 0.0457 0.0404 0.0380 0.0343 0.0327 0.0320 0.0313 0.0307 0.0304 0.0302 0.0300 0.0298 0.0297 

[TRAIN] Epoch[1](99/114412); Loss: 0.049906; Backpropagation: 0.2905 sec; Batch: 2.0764 sec
0.0882 0.0732 0.0595 0.0526 0.0495 0.0475 0.0454 0.0444 0.0437 0.0431 0.0427 0.0423 0.0420 0.0417 0.0414 0.0413 

[TRAIN] Epoch[1](100/114412); Loss: 0.074539; Backpropagation: 0.2906 sec; Batch: 2.0751 sec
0.1160 0.0945 0.0850 0.0791 0.0753 0.0727 0.0709 0.0694 0.0684 0.0675 0.0667 0.0662 0.0658 0.0654 0.0651 0.0648 

[TRAIN] Epoch[1](101/114412); Loss: 0.069542; Backpropagation: 0.2904 sec; Batch: 2.0757 sec
0.1527 0.1095 0.0907 0.0773 0.0722 0.0658 0.0610 0.0590 0.0565 0.0548 0.0537 0.0530 0.0523 0.0518 0.0514 0.0511 

[TRAIN] Epoch[1](102/114412); Loss: 0.066248; Backpropagation: 0.2913 sec; Batch: 2.0781 sec
0.1305 0.0936 0.0832 0.0721 0.0677 0.0638 0.0597 0.0576 0.0568 0.0556 0.0544 0.0540 0.0534 0.0528 0.0526 0.0522 

[TRAIN] Epoch[1](103/114412); Loss: 0.058540; Backpropagation: 0.2909 sec; Batch: 2.0772 sec
0.1209 0.0974 0.0789 0.0661 0.0566 0.0527 0.0515 0.0498 0.0480 0.0470 0.0460 0.0451 0.0447 0.0442 0.0439 0.0437 

[TRAIN] Epoch[1](104/114412); Loss: 0.050731; Backpropagation: 0.2930 sec; Batch: 2.0782 sec
0.1008 0.0676 0.0600 0.0539 0.0506 0.0481 0.0466 0.0452 0.0442 0.0435 0.0428 0.0423 0.0420 0.0416 0.0413 0.0412 

[TRAIN] Epoch[1](105/114412); Loss: 0.061949; Backpropagation: 0.2932 sec; Batch: 2.0785 sec
0.1187 0.0944 0.0813 0.0699 0.0618 0.0572 0.0551 0.0535 0.0524 0.0514 0.0505 0.0498 0.0494 0.0490 0.0486 0.0483 

[TRAIN] Epoch[1](106/114412); Loss: 0.047961; Backpropagation: 0.2927 sec; Batch: 2.0780 sec
0.0897 0.0662 0.0552 0.0515 0.0472 0.0450 0.0439 0.0428 0.0420 0.0415 0.0410 0.0407 0.0404 0.0402 0.0401 0.0399 

[TRAIN] Epoch[1](107/114412); Loss: 0.083873; Backpropagation: 0.2912 sec; Batch: 2.0765 sec
0.1306 0.1155 0.1017 0.0943 0.0836 0.0798 0.0787 0.0764 0.0748 0.0740 0.0733 0.0726 0.0721 0.0719 0.0716 0.0713 

[TRAIN] Epoch[1](108/114412); Loss: 0.067772; Backpropagation: 0.2908 sec; Batch: 2.0765 sec
0.1264 0.0912 0.0806 0.0718 0.0676 0.0649 0.0620 0.0612 0.0607 0.0591 0.0580 0.0574 0.0563 0.0560 0.0557 0.0553 

[TRAIN] Epoch[1](109/114412); Loss: 0.045103; Backpropagation: 0.2913 sec; Batch: 2.0757 sec
0.0804 0.0679 0.0596 0.0504 0.0466 0.0437 0.0409 0.0395 0.0384 0.0376 0.0370 0.0365 0.0361 0.0358 0.0356 0.0355 

[TRAIN] Epoch[1](110/114412); Loss: 0.074959; Backpropagation: 0.2911 sec; Batch: 2.0758 sec
0.1389 0.0981 0.0878 0.0789 0.0732 0.0713 0.0687 0.0674 0.0663 0.0652 0.0648 0.0643 0.0640 0.0637 0.0634 0.0632 

[TRAIN] Epoch[1](111/114412); Loss: 0.038475; Backpropagation: 0.2954 sec; Batch: 2.0793 sec
0.0790 0.0596 0.0482 0.0451 0.0384 0.0357 0.0340 0.0330 0.0319 0.0312 0.0307 0.0302 0.0299 0.0297 0.0295 0.0295 

[TRAIN] Epoch[1](112/114412); Loss: 0.066928; Backpropagation: 0.2925 sec; Batch: 2.0773 sec
0.1053 0.0900 0.0803 0.0732 0.0682 0.0649 0.0629 0.0615 0.0606 0.0593 0.0585 0.0580 0.0575 0.0572 0.0568 0.0566 

[TRAIN] Epoch[1](113/114412); Loss: 0.090505; Backpropagation: 0.2908 sec; Batch: 2.0763 sec
0.1637 0.1443 0.1218 0.1060 0.0926 0.0854 0.0814 0.0783 0.0757 0.0744 0.0728 0.0718 0.0710 0.0703 0.0696 0.0691 

[TRAIN] Epoch[1](114/114412); Loss: 0.061575; Backpropagation: 0.2911 sec; Batch: 2.0764 sec
0.1323 0.0955 0.0797 0.0676 0.0603 0.0561 0.0533 0.0515 0.0506 0.0496 0.0490 0.0486 0.0482 0.0479 0.0476 0.0474 

[TRAIN] Epoch[1](115/114412); Loss: 0.052026; Backpropagation: 0.2910 sec; Batch: 2.0758 sec
0.0941 0.0719 0.0623 0.0579 0.0515 0.0493 0.0474 0.0462 0.0454 0.0447 0.0443 0.0440 0.0437 0.0435 0.0432 0.0430 

[TRAIN] Epoch[1](116/114412); Loss: 0.075656; Backpropagation: 0.2913 sec; Batch: 2.0777 sec
0.1364 0.1191 0.1009 0.0859 0.0775 0.0708 0.0670 0.0649 0.0637 0.0623 0.0614 0.0609 0.0603 0.0600 0.0597 0.0594 

[TRAIN] Epoch[1](117/114412); Loss: 0.046261; Backpropagation: 0.2903 sec; Batch: 2.0760 sec
0.1027 0.0737 0.0569 0.0494 0.0457 0.0425 0.0404 0.0390 0.0382 0.0371 0.0366 0.0363 0.0359 0.0355 0.0353 0.0350 

[TRAIN] Epoch[1](118/114412); Loss: 0.061275; Backpropagation: 0.2909 sec; Batch: 2.0772 sec
0.1220 0.0964 0.0819 0.0682 0.0608 0.0559 0.0539 0.0521 0.0506 0.0499 0.0492 0.0486 0.0482 0.0478 0.0475 0.0473 

[TRAIN] Epoch[1](119/114412); Loss: 0.055665; Backpropagation: 0.2932 sec; Batch: 2.0794 sec
0.1116 0.0771 0.0638 0.0596 0.0563 0.0532 0.0507 0.0491 0.0479 0.0471 0.0465 0.0461 0.0457 0.0454 0.0452 0.0452 

[TRAIN] Epoch[1](120/114412); Loss: 0.065977; Backpropagation: 0.2929 sec; Batch: 2.0788 sec
0.1231 0.1103 0.0905 0.0738 0.0677 0.0631 0.0584 0.0564 0.0546 0.0535 0.0519 0.0513 0.0508 0.0504 0.0500 0.0498 

[TRAIN] Epoch[1](121/114412); Loss: 0.070973; Backpropagation: 0.2953 sec; Batch: 2.0824 sec
0.1408 0.1013 0.0800 0.0731 0.0695 0.0666 0.0641 0.0628 0.0616 0.0607 0.0602 0.0598 0.0594 0.0589 0.0586 0.0584 

[TRAIN] Epoch[1](122/114412); Loss: 0.071390; Backpropagation: 0.2951 sec; Batch: 2.0817 sec
0.1144 0.0972 0.0836 0.0774 0.0740 0.0708 0.0679 0.0659 0.0646 0.0632 0.0621 0.0613 0.0606 0.0601 0.0598 0.0593 

[TRAIN] Epoch[1](123/114412); Loss: 0.063799; Backpropagation: 0.2909 sec; Batch: 2.0771 sec
0.1141 0.0885 0.0730 0.0659 0.0634 0.0613 0.0592 0.0575 0.0564 0.0558 0.0552 0.0548 0.0544 0.0540 0.0538 0.0536 

[TRAIN] Epoch[1](124/114412); Loss: 0.053126; Backpropagation: 0.2915 sec; Batch: 2.0776 sec
0.1061 0.0824 0.0672 0.0582 0.0539 0.0504 0.0474 0.0457 0.0444 0.0434 0.0429 0.0423 0.0418 0.0416 0.0414 0.0411 

[TRAIN] Epoch[1](125/114412); Loss: 0.051840; Backpropagation: 0.2912 sec; Batch: 2.0767 sec
0.1354 0.0981 0.0684 0.0514 0.0489 0.0455 0.0423 0.0407 0.0394 0.0383 0.0377 0.0372 0.0369 0.0366 0.0364 0.0363 

[TRAIN] Epoch[1](126/114412); Loss: 0.049120; Backpropagation: 0.2949 sec; Batch: 2.0810 sec
0.0928 0.0773 0.0648 0.0531 0.0486 0.0451 0.0434 0.0424 0.0412 0.0406 0.0402 0.0398 0.0395 0.0392 0.0391 0.0390 

[TRAIN] Epoch[1](127/114412); Loss: 0.089743; Backpropagation: 0.2932 sec; Batch: 2.0796 sec
0.1663 0.1321 0.1116 0.0961 0.0884 0.0852 0.0821 0.0789 0.0775 0.0764 0.0750 0.0743 0.0737 0.0731 0.0727 0.0725 

[TRAIN] Epoch[1](128/114412); Loss: 0.056373; Backpropagation: 0.2916 sec; Batch: 2.0765 sec
0.1444 0.0891 0.0662 0.0594 0.0550 0.0503 0.0476 0.0460 0.0452 0.0443 0.0434 0.0429 0.0425 0.0421 0.0420 0.0418 

[TRAIN] Epoch[1](129/114412); Loss: 0.076414; Backpropagation: 0.2913 sec; Batch: 2.0767 sec
0.1281 0.1001 0.0903 0.0831 0.0773 0.0748 0.0718 0.0700 0.0688 0.0676 0.0666 0.0659 0.0653 0.0646 0.0643 0.0639 

[TRAIN] Epoch[1](130/114412); Loss: 0.086657; Backpropagation: 0.2911 sec; Batch: 2.0765 sec
0.1533 0.1277 0.1128 0.0977 0.0888 0.0824 0.0785 0.0759 0.0743 0.0730 0.0719 0.0712 0.0705 0.0699 0.0694 0.0690 

[TRAIN] Epoch[1](131/114412); Loss: 0.049321; Backpropagation: 0.2931 sec; Batch: 2.0781 sec
0.0818 0.0671 0.0655 0.0592 0.0539 0.0494 0.0466 0.0442 0.0427 0.0415 0.0406 0.0400 0.0395 0.0392 0.0390 0.0387 

[TRAIN] Epoch[1](132/114412); Loss: 0.076033; Backpropagation: 0.2926 sec; Batch: 2.0793 sec
0.1241 0.1062 0.0956 0.0843 0.0777 0.0738 0.0712 0.0691 0.0674 0.0662 0.0652 0.0643 0.0636 0.0630 0.0626 0.0622 

[TRAIN] Epoch[1](133/114412); Loss: 0.065481; Backpropagation: 0.2912 sec; Batch: 2.0767 sec
0.1250 0.0882 0.0763 0.0685 0.0644 0.0612 0.0593 0.0585 0.0575 0.0568 0.0563 0.0558 0.0553 0.0551 0.0548 0.0547 

[TRAIN] Epoch[1](134/114412); Loss: 0.061342; Backpropagation: 0.2911 sec; Batch: 2.0769 sec
0.1278 0.0938 0.0764 0.0669 0.0624 0.0582 0.0549 0.0526 0.0511 0.0500 0.0491 0.0485 0.0481 0.0475 0.0472 0.0470 

[TRAIN] Epoch[1](135/114412); Loss: 0.052099; Backpropagation: 0.2910 sec; Batch: 2.0766 sec
0.1126 0.0925 0.0714 0.0546 0.0513 0.0497 0.0449 0.0424 0.0417 0.0409 0.0396 0.0391 0.0387 0.0383 0.0381 0.0379 

[TRAIN] Epoch[1](136/114412); Loss: 0.062475; Backpropagation: 0.2911 sec; Batch: 2.0765 sec
0.1264 0.0967 0.0763 0.0666 0.0611 0.0578 0.0552 0.0536 0.0525 0.0517 0.0510 0.0507 0.0503 0.0501 0.0499 0.0497 

[TRAIN] Epoch[1](137/114412); Loss: 0.052914; Backpropagation: 0.2904 sec; Batch: 2.0755 sec
0.1035 0.0854 0.0775 0.0599 0.0520 0.0499 0.0465 0.0447 0.0429 0.0420 0.0412 0.0408 0.0405 0.0402 0.0400 0.0397 

[TRAIN] Epoch[1](138/114412); Loss: 0.051709; Backpropagation: 0.2912 sec; Batch: 2.0827 sec
0.1292 0.0991 0.0705 0.0563 0.0487 0.0451 0.0422 0.0402 0.0392 0.0383 0.0375 0.0369 0.0365 0.0361 0.0359 0.0356 

[TRAIN] Epoch[1](139/114412); Loss: 0.051971; Backpropagation: 0.2912 sec; Batch: 2.1161 sec
0.1056 0.0822 0.0670 0.0567 0.0508 0.0475 0.0456 0.0443 0.0433 0.0427 0.0421 0.0415 0.0409 0.0406 0.0405 0.0403 

[TRAIN] Epoch[1](140/114412); Loss: 0.066220; Backpropagation: 0.2906 sec; Batch: 2.0775 sec
0.1464 0.1029 0.0784 0.0686 0.0647 0.0612 0.0587 0.0568 0.0553 0.0542 0.0534 0.0526 0.0521 0.0518 0.0514 0.0511 

[TRAIN] Epoch[1](141/114412); Loss: 0.051944; Backpropagation: 0.2910 sec; Batch: 2.0775 sec
0.0852 0.0755 0.0640 0.0555 0.0519 0.0493 0.0479 0.0468 0.0460 0.0453 0.0447 0.0443 0.0440 0.0438 0.0435 0.0433 

[TRAIN] Epoch[1](142/114412); Loss: 0.063053; Backpropagation: 0.2908 sec; Batch: 2.0766 sec
0.1067 0.0894 0.0769 0.0678 0.0627 0.0595 0.0580 0.0568 0.0556 0.0550 0.0544 0.0538 0.0535 0.0532 0.0530 0.0528 

[TRAIN] Epoch[1](143/114412); Loss: 0.074059; Backpropagation: 0.2907 sec; Batch: 2.0757 sec
0.1216 0.1101 0.0957 0.0844 0.0778 0.0727 0.0690 0.0667 0.0648 0.0630 0.0618 0.0608 0.0599 0.0593 0.0588 0.0583 

[TRAIN] Epoch[1](144/114412); Loss: 0.038222; Backpropagation: 0.2910 sec; Batch: 2.0764 sec
0.0819 0.0724 0.0548 0.0449 0.0385 0.0338 0.0324 0.0307 0.0295 0.0287 0.0282 0.0277 0.0274 0.0270 0.0268 0.0267 

[TRAIN] Epoch[1](145/114412); Loss: 0.057752; Backpropagation: 0.2951 sec; Batch: 2.0809 sec
0.1517 0.0884 0.0684 0.0606 0.0537 0.0504 0.0485 0.0470 0.0461 0.0454 0.0448 0.0444 0.0440 0.0437 0.0435 0.0433 

[TRAIN] Epoch[1](146/114412); Loss: 0.084643; Backpropagation: 0.2933 sec; Batch: 2.0800 sec
0.1661 0.1349 0.1007 0.0875 0.0820 0.0785 0.0759 0.0737 0.0722 0.0711 0.0699 0.0694 0.0687 0.0682 0.0680 0.0676 

[TRAIN] Epoch[1](147/114412); Loss: 0.052905; Backpropagation: 0.2911 sec; Batch: 2.0768 sec
0.0925 0.0822 0.0661 0.0576 0.0542 0.0509 0.0482 0.0469 0.0451 0.0444 0.0439 0.0433 0.0431 0.0429 0.0426 0.0425 

[TRAIN] Epoch[1](148/114412); Loss: 0.056623; Backpropagation: 0.2911 sec; Batch: 2.0773 sec
0.1064 0.0913 0.0736 0.0620 0.0565 0.0527 0.0505 0.0492 0.0476 0.0466 0.0459 0.0454 0.0450 0.0447 0.0444 0.0441 

[TRAIN] Epoch[1](149/114412); Loss: 0.080686; Backpropagation: 0.2909 sec; Batch: 2.0766 sec
0.1296 0.1133 0.0983 0.0877 0.0813 0.0779 0.0755 0.0733 0.0718 0.0709 0.0700 0.0694 0.0687 0.0681 0.0678 0.0674 

[TRAIN] Epoch[1](150/114412); Loss: 0.072353; Backpropagation: 0.2954 sec; Batch: 2.0810 sec
0.1150 0.0919 0.0805 0.0766 0.0738 0.0706 0.0683 0.0669 0.0661 0.0652 0.0647 0.0642 0.0639 0.0637 0.0633 0.0631 

[TRAIN] Epoch[1](151/114412); Loss: 0.055254; Backpropagation: 0.2956 sec; Batch: 2.0811 sec
0.1125 0.0902 0.0728 0.0624 0.0545 0.0508 0.0489 0.0471 0.0458 0.0444 0.0436 0.0431 0.0425 0.0421 0.0417 0.0416 

[TRAIN] Epoch[1](152/114412); Loss: 0.065393; Backpropagation: 0.2948 sec; Batch: 2.0821 sec
0.1511 0.1022 0.0796 0.0693 0.0644 0.0592 0.0564 0.0548 0.0534 0.0527 0.0517 0.0511 0.0507 0.0502 0.0499 0.0496 

[TRAIN] Epoch[1](153/114412); Loss: 0.055963; Backpropagation: 0.2930 sec; Batch: 2.0789 sec
0.1180 0.0967 0.0799 0.0679 0.0584 0.0546 0.0503 0.0490 0.0451 0.0426 0.0410 0.0398 0.0389 0.0381 0.0377 0.0373 

[TRAIN] Epoch[1](154/114412); Loss: 0.077743; Backpropagation: 0.2913 sec; Batch: 2.0774 sec
0.1258 0.1074 0.0934 0.0841 0.0779 0.0749 0.0725 0.0708 0.0695 0.0685 0.0676 0.0671 0.0666 0.0663 0.0660 0.0657 

[TRAIN] Epoch[1](155/114412); Loss: 0.068010; Backpropagation: 0.2950 sec; Batch: 2.0820 sec
0.1976 0.1286 0.0836 0.0684 0.0605 0.0570 0.0552 0.0528 0.0509 0.0500 0.0490 0.0480 0.0473 0.0469 0.0464 0.0460 

[TRAIN] Epoch[1](156/114412); Loss: 0.071660; Backpropagation: 0.2933 sec; Batch: 2.0799 sec
0.1309 0.1044 0.0840 0.0754 0.0713 0.0678 0.0654 0.0640 0.0626 0.0617 0.0609 0.0603 0.0599 0.0596 0.0592 0.0590 

[TRAIN] Epoch[1](157/114412); Loss: 0.057245; Backpropagation: 0.2910 sec; Batch: 2.0783 sec
0.1157 0.0974 0.0726 0.0644 0.0552 0.0522 0.0504 0.0487 0.0472 0.0462 0.0455 0.0449 0.0444 0.0440 0.0437 0.0435 

[TRAIN] Epoch[1](158/114412); Loss: 0.058042; Backpropagation: 0.2910 sec; Batch: 2.0778 sec
0.1087 0.0884 0.0760 0.0681 0.0603 0.0539 0.0515 0.0501 0.0489 0.0480 0.0468 0.0462 0.0460 0.0455 0.0452 0.0451 

[TRAIN] Epoch[1](159/114412); Loss: 0.055474; Backpropagation: 0.2912 sec; Batch: 2.0776 sec
0.0968 0.0781 0.0684 0.0605 0.0553 0.0530 0.0512 0.0498 0.0487 0.0479 0.0472 0.0468 0.0464 0.0461 0.0459 0.0456 

[TRAIN] Epoch[1](160/114412); Loss: 0.052782; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.0943 0.0809 0.0681 0.0581 0.0530 0.0496 0.0475 0.0459 0.0450 0.0442 0.0437 0.0433 0.0431 0.0428 0.0426 0.0424 

[TRAIN] Epoch[1](161/114412); Loss: 0.064914; Backpropagation: 0.2929 sec; Batch: 2.0805 sec
0.1159 0.1011 0.0836 0.0755 0.0638 0.0614 0.0586 0.0560 0.0549 0.0540 0.0533 0.0527 0.0523 0.0520 0.0518 0.0517 

[TRAIN] Epoch[1](162/114412); Loss: 0.052633; Backpropagation: 0.2912 sec; Batch: 2.0780 sec
0.1010 0.0761 0.0633 0.0554 0.0515 0.0490 0.0475 0.0465 0.0453 0.0448 0.0443 0.0439 0.0437 0.0435 0.0432 0.0431 

[TRAIN] Epoch[1](163/114412); Loss: 0.060357; Backpropagation: 0.2911 sec; Batch: 2.0775 sec
0.1076 0.0881 0.0744 0.0657 0.0604 0.0572 0.0551 0.0535 0.0525 0.0516 0.0509 0.0504 0.0500 0.0497 0.0494 0.0492 

[TRAIN] Epoch[1](164/114412); Loss: 0.045595; Backpropagation: 0.2956 sec; Batch: 2.0822 sec
0.0932 0.0837 0.0670 0.0527 0.0442 0.0414 0.0393 0.0376 0.0361 0.0352 0.0343 0.0337 0.0333 0.0328 0.0327 0.0324 

[TRAIN] Epoch[1](165/114412); Loss: 0.053888; Backpropagation: 0.2924 sec; Batch: 2.0788 sec
0.1046 0.0868 0.0658 0.0578 0.0527 0.0497 0.0476 0.0465 0.0456 0.0448 0.0442 0.0438 0.0434 0.0432 0.0429 0.0428 

[TRAIN] Epoch[1](166/114412); Loss: 0.071785; Backpropagation: 0.2928 sec; Batch: 2.0790 sec
0.1209 0.0960 0.0844 0.0763 0.0705 0.0683 0.0667 0.0655 0.0645 0.0637 0.0633 0.0626 0.0620 0.0616 0.0613 0.0610 

[TRAIN] Epoch[1](167/114412); Loss: 0.062838; Backpropagation: 0.2931 sec; Batch: 2.0794 sec
0.1069 0.0921 0.0810 0.0686 0.0624 0.0592 0.0571 0.0558 0.0548 0.0538 0.0534 0.0528 0.0524 0.0520 0.0517 0.0514 

[TRAIN] Epoch[1](168/114412); Loss: 0.063143; Backpropagation: 0.2931 sec; Batch: 2.0788 sec
0.1629 0.1304 0.0922 0.0726 0.0569 0.0542 0.0502 0.0481 0.0459 0.0447 0.0440 0.0428 0.0420 0.0416 0.0410 0.0407 

[TRAIN] Epoch[1](169/114412); Loss: 0.049939; Backpropagation: 0.2931 sec; Batch: 2.1097 sec
0.1083 0.0826 0.0660 0.0558 0.0499 0.0461 0.0430 0.0414 0.0401 0.0392 0.0387 0.0382 0.0378 0.0375 0.0373 0.0372 

[TRAIN] Epoch[1](170/114412); Loss: 0.063180; Backpropagation: 0.2912 sec; Batch: 2.0775 sec
0.1281 0.0948 0.0762 0.0696 0.0608 0.0579 0.0555 0.0541 0.0534 0.0526 0.0520 0.0518 0.0514 0.0510 0.0509 0.0507 

[TRAIN] Epoch[1](171/114412); Loss: 0.048466; Backpropagation: 0.2904 sec; Batch: 2.0768 sec
0.1015 0.0777 0.0625 0.0548 0.0484 0.0452 0.0433 0.0415 0.0400 0.0390 0.0381 0.0376 0.0370 0.0366 0.0363 0.0360 

[TRAIN] Epoch[1](172/114412); Loss: 0.074992; Backpropagation: 0.2907 sec; Batch: 2.0769 sec
0.1481 0.1187 0.0956 0.0841 0.0749 0.0705 0.0668 0.0645 0.0624 0.0614 0.0603 0.0594 0.0589 0.0585 0.0581 0.0577 

[TRAIN] Epoch[1](173/114412); Loss: 0.061888; Backpropagation: 0.2904 sec; Batch: 2.0764 sec
0.1417 0.1232 0.0956 0.0781 0.0664 0.0565 0.0527 0.0481 0.0444 0.0430 0.0419 0.0409 0.0400 0.0396 0.0392 0.0389 

[TRAIN] Epoch[1](174/114412); Loss: 0.068517; Backpropagation: 0.2951 sec; Batch: 2.0822 sec
0.1172 0.1050 0.0886 0.0772 0.0700 0.0661 0.0631 0.0605 0.0588 0.0578 0.0569 0.0560 0.0554 0.0549 0.0546 0.0543 

[TRAIN] Epoch[1](175/114412); Loss: 0.042751; Backpropagation: 0.2933 sec; Batch: 2.0807 sec
0.0978 0.0770 0.0581 0.0478 0.0425 0.0391 0.0365 0.0350 0.0335 0.0326 0.0317 0.0311 0.0308 0.0304 0.0301 0.0300 

[TRAIN] Epoch[1](176/114412); Loss: 0.058215; Backpropagation: 0.2912 sec; Batch: 2.0787 sec
0.1107 0.0935 0.0767 0.0643 0.0580 0.0542 0.0520 0.0500 0.0487 0.0477 0.0470 0.0464 0.0461 0.0457 0.0453 0.0450 

[TRAIN] Epoch[1](177/114412); Loss: 0.044392; Backpropagation: 0.2912 sec; Batch: 2.0760 sec
0.1021 0.0770 0.0564 0.0484 0.0423 0.0388 0.0375 0.0361 0.0353 0.0347 0.0343 0.0339 0.0337 0.0334 0.0332 0.0331 

[TRAIN] Epoch[1](178/114412); Loss: 0.045906; Backpropagation: 0.2910 sec; Batch: 2.0775 sec
0.1076 0.0770 0.0573 0.0472 0.0432 0.0408 0.0394 0.0380 0.0370 0.0363 0.0358 0.0354 0.0352 0.0349 0.0348 0.0347 

[TRAIN] Epoch[1](179/114412); Loss: 0.070925; Backpropagation: 0.2914 sec; Batch: 2.0771 sec
0.1197 0.1055 0.0961 0.0808 0.0733 0.0677 0.0651 0.0626 0.0608 0.0597 0.0589 0.0580 0.0573 0.0568 0.0563 0.0560 

[TRAIN] Epoch[1](180/114412); Loss: 0.077393; Backpropagation: 0.2912 sec; Batch: 2.0771 sec
0.1318 0.1150 0.0977 0.0862 0.0789 0.0740 0.0713 0.0690 0.0672 0.0661 0.0650 0.0643 0.0637 0.0632 0.0627 0.0623 

[TRAIN] Epoch[1](181/114412); Loss: 0.047013; Backpropagation: 0.2949 sec; Batch: 2.0824 sec
0.0968 0.0813 0.0638 0.0527 0.0474 0.0434 0.0409 0.0396 0.0384 0.0374 0.0363 0.0357 0.0351 0.0348 0.0344 0.0342 

[TRAIN] Epoch[1](182/114412); Loss: 0.062311; Backpropagation: 0.2928 sec; Batch: 2.0918 sec
0.1087 0.0950 0.0798 0.0679 0.0633 0.0589 0.0569 0.0550 0.0538 0.0527 0.0519 0.0513 0.0509 0.0506 0.0503 0.0501 

[TRAIN] Epoch[1](183/114412); Loss: 0.060188; Backpropagation: 0.2912 sec; Batch: 2.0784 sec
0.1151 0.0904 0.0718 0.0636 0.0600 0.0574 0.0551 0.0532 0.0519 0.0510 0.0502 0.0495 0.0491 0.0487 0.0483 0.0480 

[TRAIN] Epoch[1](184/114412); Loss: 0.073922; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1290 0.1165 0.1015 0.0851 0.0718 0.0686 0.0662 0.0642 0.0627 0.0616 0.0608 0.0599 0.0593 0.0589 0.0585 0.0582 

[TRAIN] Epoch[1](185/114412); Loss: 0.066299; Backpropagation: 0.2913 sec; Batch: 2.0777 sec
0.1148 0.0992 0.0813 0.0706 0.0658 0.0629 0.0606 0.0593 0.0580 0.0571 0.0565 0.0558 0.0552 0.0548 0.0546 0.0543 

[TRAIN] Epoch[1](186/114412); Loss: 0.056385; Backpropagation: 0.2908 sec; Batch: 2.0784 sec
0.1006 0.0891 0.0727 0.0599 0.0556 0.0538 0.0506 0.0496 0.0484 0.0476 0.0469 0.0460 0.0456 0.0454 0.0452 0.0451 

[TRAIN] Epoch[1](187/114412); Loss: 0.065667; Backpropagation: 0.2906 sec; Batch: 2.0768 sec
0.1024 0.0869 0.0757 0.0706 0.0663 0.0636 0.0616 0.0607 0.0596 0.0590 0.0583 0.0578 0.0574 0.0572 0.0569 0.0567 

[TRAIN] Epoch[1](188/114412); Loss: 0.056312; Backpropagation: 0.2955 sec; Batch: 2.0827 sec
0.0870 0.0761 0.0662 0.0632 0.0571 0.0548 0.0530 0.0515 0.0505 0.0497 0.0492 0.0490 0.0488 0.0485 0.0483 0.0481 

[TRAIN] Epoch[1](189/114412); Loss: 0.074395; Backpropagation: 0.2930 sec; Batch: 2.0803 sec
0.1409 0.1179 0.0977 0.0819 0.0756 0.0696 0.0672 0.0641 0.0625 0.0611 0.0600 0.0593 0.0588 0.0583 0.0578 0.0576 

[TRAIN] Epoch[1](190/114412); Loss: 0.058054; Backpropagation: 0.2908 sec; Batch: 2.0786 sec
0.1103 0.0932 0.0758 0.0650 0.0583 0.0543 0.0520 0.0501 0.0486 0.0476 0.0467 0.0463 0.0458 0.0453 0.0449 0.0448 

[TRAIN] Epoch[1](191/114412); Loss: 0.067688; Backpropagation: 0.2912 sec; Batch: 2.0774 sec
0.1131 0.0940 0.0800 0.0719 0.0675 0.0649 0.0627 0.0617 0.0605 0.0597 0.0590 0.0584 0.0580 0.0576 0.0572 0.0570 

[TRAIN] Epoch[1](192/114412); Loss: 0.073018; Backpropagation: 0.2911 sec; Batch: 2.0790 sec
0.1357 0.1145 0.0925 0.0817 0.0748 0.0701 0.0667 0.0650 0.0621 0.0600 0.0593 0.0583 0.0575 0.0571 0.0567 0.0563 

[TRAIN] Epoch[1](193/114412); Loss: 0.070492; Backpropagation: 0.2912 sec; Batch: 2.0784 sec
0.1285 0.0955 0.0798 0.0738 0.0695 0.0668 0.0649 0.0635 0.0628 0.0619 0.0611 0.0607 0.0601 0.0599 0.0597 0.0594 

[TRAIN] Epoch[1](194/114412); Loss: 0.043632; Backpropagation: 0.2911 sec; Batch: 2.0781 sec
0.0877 0.0648 0.0577 0.0483 0.0435 0.0409 0.0394 0.0378 0.0367 0.0358 0.0352 0.0347 0.0343 0.0340 0.0338 0.0336 

[TRAIN] Epoch[1](195/114412); Loss: 0.047491; Backpropagation: 0.2910 sec; Batch: 2.0781 sec
0.0909 0.0653 0.0557 0.0512 0.0460 0.0436 0.0428 0.0421 0.0412 0.0408 0.0405 0.0403 0.0401 0.0400 0.0398 0.0397 

[TRAIN] Epoch[1](196/114412); Loss: 0.078870; Backpropagation: 0.2907 sec; Batch: 2.0771 sec
0.1353 0.1117 0.0941 0.0850 0.0792 0.0753 0.0734 0.0713 0.0699 0.0687 0.0679 0.0672 0.0665 0.0660 0.0654 0.0650 

[TRAIN] Epoch[1](197/114412); Loss: 0.060611; Backpropagation: 0.2906 sec; Batch: 2.0773 sec
0.1034 0.0844 0.0748 0.0674 0.0609 0.0580 0.0562 0.0546 0.0534 0.0525 0.0519 0.0513 0.0508 0.0504 0.0500 0.0497 

[TRAIN] Epoch[1](198/114412); Loss: 0.073600; Backpropagation: 0.2914 sec; Batch: 2.0794 sec
0.1319 0.0971 0.0871 0.0795 0.0728 0.0706 0.0684 0.0665 0.0652 0.0645 0.0635 0.0632 0.0625 0.0620 0.0615 0.0613 

[TRAIN] Epoch[1](199/114412); Loss: 0.046348; Backpropagation: 0.2909 sec; Batch: 2.0782 sec
0.1150 0.0806 0.0631 0.0529 0.0465 0.0423 0.0392 0.0371 0.0354 0.0343 0.0337 0.0331 0.0327 0.0322 0.0319 0.0317 

[TRAIN] Epoch[1](200/114412); Loss: 0.077400; Backpropagation: 0.2910 sec; Batch: 2.0781 sec
0.1217 0.1054 0.0903 0.0811 0.0769 0.0744 0.0725 0.0712 0.0702 0.0693 0.0685 0.0680 0.0676 0.0674 0.0671 0.0667 

[TRAIN] Epoch[1](201/114412); Loss: 0.087378; Backpropagation: 0.2905 sec; Batch: 2.0780 sec
0.1767 0.1471 0.1287 0.1109 0.0896 0.0836 0.0792 0.0745 0.0706 0.0673 0.0655 0.0631 0.0620 0.0609 0.0596 0.0587 

[TRAIN] Epoch[1](202/114412); Loss: 0.056893; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1234 0.0979 0.0708 0.0583 0.0528 0.0508 0.0491 0.0475 0.0466 0.0459 0.0453 0.0449 0.0446 0.0443 0.0441 0.0440 

[TRAIN] Epoch[1](203/114412); Loss: 0.092043; Backpropagation: 0.2908 sec; Batch: 2.0780 sec
0.1765 0.1445 0.1251 0.1072 0.0999 0.0941 0.0886 0.0829 0.0788 0.0754 0.0721 0.0686 0.0665 0.0655 0.0642 0.0630 

[TRAIN] Epoch[1](204/114412); Loss: 0.067467; Backpropagation: 0.2910 sec; Batch: 2.0772 sec
0.1762 0.1395 0.1161 0.0929 0.0743 0.0575 0.0510 0.0494 0.0469 0.0444 0.0421 0.0406 0.0386 0.0372 0.0365 0.0361 

[TRAIN] Epoch[1](205/114412); Loss: 0.084921; Backpropagation: 0.2907 sec; Batch: 2.0784 sec
0.1493 0.1189 0.1052 0.0920 0.0861 0.0825 0.0792 0.0767 0.0751 0.0734 0.0721 0.0710 0.0701 0.0695 0.0690 0.0686 

[TRAIN] Epoch[1](206/114412); Loss: 0.070509; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.1713 0.1343 0.1070 0.0813 0.0698 0.0646 0.0608 0.0562 0.0535 0.0516 0.0497 0.0477 0.0466 0.0454 0.0446 0.0437 

[TRAIN] Epoch[1](207/114412); Loss: 0.057589; Backpropagation: 0.2927 sec; Batch: 2.0806 sec
0.1146 0.0929 0.0772 0.0664 0.0601 0.0532 0.0508 0.0488 0.0470 0.0456 0.0451 0.0445 0.0442 0.0439 0.0436 0.0435 

[TRAIN] Epoch[1](208/114412); Loss: 0.069680; Backpropagation: 0.2921 sec; Batch: 2.0789 sec
0.1648 0.1303 0.1058 0.0846 0.0721 0.0666 0.0603 0.0559 0.0531 0.0495 0.0477 0.0462 0.0455 0.0447 0.0442 0.0437 

[TRAIN] Epoch[1](209/114412); Loss: 0.068251; Backpropagation: 0.2914 sec; Batch: 2.0780 sec
0.1386 0.1071 0.0859 0.0712 0.0664 0.0635 0.0605 0.0587 0.0572 0.0561 0.0555 0.0550 0.0545 0.0541 0.0540 0.0537 

[TRAIN] Epoch[1](210/114412); Loss: 0.073610; Backpropagation: 0.2932 sec; Batch: 2.0803 sec
0.1786 0.1270 0.0958 0.0750 0.0681 0.0641 0.0606 0.0595 0.0583 0.0574 0.0568 0.0560 0.0557 0.0553 0.0549 0.0546 

[TRAIN] Epoch[1](211/114412); Loss: 0.068074; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.2077 0.1581 0.1109 0.0721 0.0571 0.0517 0.0485 0.0462 0.0450 0.0438 0.0428 0.0420 0.0415 0.0411 0.0406 0.0403 

[TRAIN] Epoch[1](212/114412); Loss: 0.055912; Backpropagation: 0.2908 sec; Batch: 2.0785 sec
0.1303 0.0982 0.0701 0.0600 0.0519 0.0496 0.0468 0.0457 0.0447 0.0437 0.0433 0.0428 0.0423 0.0420 0.0417 0.0415 

[TRAIN] Epoch[1](213/114412); Loss: 0.061731; Backpropagation: 0.2910 sec; Batch: 2.0773 sec
0.1493 0.1096 0.0898 0.0696 0.0605 0.0539 0.0516 0.0486 0.0472 0.0461 0.0451 0.0443 0.0435 0.0432 0.0428 0.0426 

[TRAIN] Epoch[1](214/114412); Loss: 0.055536; Backpropagation: 0.2929 sec; Batch: 2.0794 sec
0.1437 0.1091 0.0794 0.0675 0.0583 0.0502 0.0446 0.0408 0.0392 0.0380 0.0374 0.0368 0.0365 0.0359 0.0357 0.0356 

[TRAIN] Epoch[1](215/114412); Loss: 0.070386; Backpropagation: 0.2912 sec; Batch: 2.0787 sec
0.1889 0.1483 0.1068 0.0797 0.0696 0.0605 0.0562 0.0524 0.0498 0.0477 0.0464 0.0452 0.0445 0.0438 0.0433 0.0430 

[TRAIN] Epoch[1](216/114412); Loss: 0.079667; Backpropagation: 0.2914 sec; Batch: 2.0788 sec
0.2194 0.1690 0.1220 0.0847 0.0646 0.0629 0.0594 0.0580 0.0568 0.0555 0.0545 0.0539 0.0538 0.0536 0.0535 0.0532 

[TRAIN] Epoch[1](217/114412); Loss: 0.060362; Backpropagation: 0.2906 sec; Batch: 2.0784 sec
0.1145 0.0937 0.0758 0.0669 0.0586 0.0562 0.0540 0.0521 0.0515 0.0504 0.0497 0.0492 0.0488 0.0484 0.0481 0.0478 

[TRAIN] Epoch[1](218/114412); Loss: 0.068875; Backpropagation: 0.2906 sec; Batch: 2.0778 sec
0.1896 0.1401 0.1078 0.0766 0.0564 0.0531 0.0524 0.0501 0.0490 0.0480 0.0472 0.0470 0.0465 0.0462 0.0461 0.0459 

[TRAIN] Epoch[1](219/114412); Loss: 0.063797; Backpropagation: 0.2911 sec; Batch: 2.0790 sec
0.1143 0.0883 0.0759 0.0675 0.0642 0.0602 0.0582 0.0567 0.0558 0.0554 0.0547 0.0544 0.0541 0.0538 0.0536 0.0535 

[TRAIN] Epoch[1](220/114412); Loss: 0.078863; Backpropagation: 0.2915 sec; Batch: 2.0781 sec
0.1488 0.1230 0.1036 0.0877 0.0811 0.0758 0.0707 0.0683 0.0659 0.0644 0.0635 0.0627 0.0621 0.0616 0.0614 0.0612 

[TRAIN] Epoch[1](221/114412); Loss: 0.064962; Backpropagation: 0.2910 sec; Batch: 2.0781 sec
0.1350 0.1118 0.0928 0.0757 0.0664 0.0581 0.0558 0.0539 0.0520 0.0508 0.0497 0.0487 0.0479 0.0474 0.0469 0.0464 

[TRAIN] Epoch[1](222/114412); Loss: 0.053845; Backpropagation: 0.2953 sec; Batch: 2.0817 sec
0.1084 0.0876 0.0733 0.0647 0.0540 0.0493 0.0474 0.0455 0.0436 0.0430 0.0419 0.0413 0.0410 0.0404 0.0402 0.0399 

[TRAIN] Epoch[1](223/114412); Loss: 0.062752; Backpropagation: 0.2911 sec; Batch: 2.0775 sec
0.1267 0.1027 0.0813 0.0669 0.0595 0.0574 0.0548 0.0532 0.0521 0.0510 0.0506 0.0502 0.0497 0.0496 0.0492 0.0491 

[TRAIN] Epoch[1](224/114412); Loss: 0.063819; Backpropagation: 0.2930 sec; Batch: 2.0803 sec
0.1323 0.0990 0.0863 0.0720 0.0638 0.0587 0.0569 0.0537 0.0525 0.0514 0.0502 0.0498 0.0491 0.0487 0.0486 0.0481 

[TRAIN] Epoch[1](225/114412); Loss: 0.052837; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.1151 0.0874 0.0695 0.0560 0.0525 0.0490 0.0462 0.0443 0.0428 0.0420 0.0414 0.0405 0.0402 0.0398 0.0395 0.0392 

[TRAIN] Epoch[1](226/114412); Loss: 0.081145; Backpropagation: 0.2927 sec; Batch: 2.0796 sec
0.1508 0.1189 0.0993 0.0865 0.0819 0.0772 0.0744 0.0723 0.0702 0.0690 0.0681 0.0669 0.0665 0.0659 0.0654 0.0651 

[TRAIN] Epoch[1](227/114412); Loss: 0.045801; Backpropagation: 0.2953 sec; Batch: 2.0827 sec
0.0894 0.0628 0.0544 0.0495 0.0460 0.0429 0.0417 0.0405 0.0398 0.0389 0.0385 0.0382 0.0378 0.0376 0.0374 0.0373 

[TRAIN] Epoch[1](228/114412); Loss: 0.065054; Backpropagation: 0.2930 sec; Batch: 2.0890 sec
0.1329 0.0998 0.0804 0.0685 0.0619 0.0600 0.0586 0.0564 0.0551 0.0543 0.0534 0.0529 0.0523 0.0519 0.0515 0.0512 

[TRAIN] Epoch[1](229/114412); Loss: 0.042927; Backpropagation: 0.2953 sec; Batch: 2.0841 sec
0.1274 0.0634 0.0512 0.0461 0.0407 0.0378 0.0355 0.0340 0.0329 0.0321 0.0316 0.0313 0.0309 0.0308 0.0306 0.0305 

[TRAIN] Epoch[1](230/114412); Loss: 0.053350; Backpropagation: 0.2926 sec; Batch: 2.0813 sec
0.1069 0.0838 0.0709 0.0616 0.0537 0.0502 0.0474 0.0456 0.0443 0.0432 0.0423 0.0415 0.0411 0.0407 0.0403 0.0401 

[TRAIN] Epoch[1](231/114412); Loss: 0.069953; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1153 0.0934 0.0841 0.0737 0.0705 0.0675 0.0652 0.0639 0.0629 0.0618 0.0612 0.0607 0.0603 0.0599 0.0596 0.0593 

[TRAIN] Epoch[1](232/114412); Loss: 0.048773; Backpropagation: 0.2911 sec; Batch: 2.0793 sec
0.1018 0.0764 0.0611 0.0541 0.0498 0.0457 0.0434 0.0416 0.0405 0.0393 0.0387 0.0384 0.0378 0.0374 0.0374 0.0369 

[TRAIN] Epoch[1](233/114412); Loss: 0.066815; Backpropagation: 0.2910 sec; Batch: 2.0778 sec
0.1151 0.0977 0.0807 0.0725 0.0670 0.0635 0.0618 0.0602 0.0589 0.0578 0.0570 0.0563 0.0557 0.0553 0.0549 0.0545 

[TRAIN] Epoch[1](234/114412); Loss: 0.042336; Backpropagation: 0.2905 sec; Batch: 2.0777 sec
0.0772 0.0648 0.0575 0.0467 0.0422 0.0407 0.0379 0.0366 0.0358 0.0348 0.0345 0.0342 0.0338 0.0337 0.0335 0.0333 

[TRAIN] Epoch[1](235/114412); Loss: 0.065318; Backpropagation: 0.2905 sec; Batch: 2.0775 sec
0.1265 0.0955 0.0806 0.0709 0.0650 0.0610 0.0583 0.0569 0.0559 0.0550 0.0542 0.0537 0.0533 0.0531 0.0528 0.0525 

[TRAIN] Epoch[1](236/114412); Loss: 0.036710; Backpropagation: 0.2904 sec; Batch: 2.0783 sec
0.0820 0.0598 0.0482 0.0390 0.0371 0.0340 0.0322 0.0310 0.0299 0.0291 0.0285 0.0279 0.0275 0.0273 0.0270 0.0268 

[TRAIN] Epoch[1](237/114412); Loss: 0.065182; Backpropagation: 0.2904 sec; Batch: 2.0776 sec
0.1192 0.0963 0.0796 0.0720 0.0657 0.0620 0.0593 0.0574 0.0561 0.0552 0.0544 0.0539 0.0534 0.0531 0.0528 0.0526 

[TRAIN] Epoch[1](238/114412); Loss: 0.054940; Backpropagation: 0.2911 sec; Batch: 2.0770 sec
0.1094 0.0871 0.0777 0.0623 0.0557 0.0518 0.0491 0.0467 0.0453 0.0438 0.0430 0.0423 0.0418 0.0413 0.0410 0.0407 

[TRAIN] Epoch[1](239/114412); Loss: 0.070869; Backpropagation: 0.2927 sec; Batch: 2.0794 sec
0.1232 0.1063 0.0915 0.0789 0.0713 0.0682 0.0651 0.0627 0.0613 0.0599 0.0590 0.0583 0.0578 0.0572 0.0568 0.0565 

[TRAIN] Epoch[1](240/114412); Loss: 0.049341; Backpropagation: 0.2927 sec; Batch: 2.0800 sec
0.0861 0.0668 0.0586 0.0521 0.0493 0.0470 0.0456 0.0449 0.0439 0.0433 0.0428 0.0423 0.0420 0.0417 0.0416 0.0414 

[TRAIN] Epoch[1](241/114412); Loss: 0.060724; Backpropagation: 0.2929 sec; Batch: 2.0801 sec
0.1083 0.0847 0.0724 0.0660 0.0612 0.0568 0.0555 0.0540 0.0531 0.0524 0.0520 0.0515 0.0512 0.0510 0.0509 0.0506 

[TRAIN] Epoch[1](242/114412); Loss: 0.061077; Backpropagation: 0.2930 sec; Batch: 2.0807 sec
0.1022 0.0828 0.0705 0.0638 0.0605 0.0596 0.0573 0.0553 0.0546 0.0539 0.0534 0.0533 0.0529 0.0526 0.0524 0.0522 

[TRAIN] Epoch[1](243/114412); Loss: 0.045876; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.0853 0.0692 0.0587 0.0511 0.0461 0.0436 0.0415 0.0404 0.0393 0.0382 0.0377 0.0372 0.0367 0.0366 0.0363 0.0361 

[TRAIN] Epoch[1](244/114412); Loss: 0.063777; Backpropagation: 0.2915 sec; Batch: 2.0791 sec
0.1067 0.0888 0.0779 0.0691 0.0649 0.0621 0.0596 0.0577 0.0565 0.0555 0.0547 0.0541 0.0537 0.0533 0.0531 0.0529 

[TRAIN] Epoch[1](245/114412); Loss: 0.068463; Backpropagation: 0.2930 sec; Batch: 2.0804 sec
0.1356 0.1061 0.0938 0.0788 0.0703 0.0669 0.0616 0.0587 0.0567 0.0550 0.0538 0.0528 0.0523 0.0516 0.0509 0.0506 

[TRAIN] Epoch[1](246/114412); Loss: 0.043184; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.0903 0.0587 0.0489 0.0453 0.0423 0.0401 0.0388 0.0378 0.0371 0.0367 0.0364 0.0361 0.0359 0.0357 0.0356 0.0355 

[TRAIN] Epoch[1](247/114412); Loss: 0.065817; Backpropagation: 0.2912 sec; Batch: 2.0774 sec
0.1136 0.0947 0.0791 0.0710 0.0668 0.0633 0.0612 0.0595 0.0581 0.0567 0.0560 0.0554 0.0549 0.0545 0.0542 0.0539 

[TRAIN] Epoch[1](248/114412); Loss: 0.085614; Backpropagation: 0.2950 sec; Batch: 2.0893 sec
0.1350 0.1156 0.1000 0.0922 0.0867 0.0834 0.0806 0.0788 0.0772 0.0761 0.0753 0.0746 0.0742 0.0738 0.0733 0.0729 

[TRAIN] Epoch[1](249/114412); Loss: 0.062871; Backpropagation: 0.2951 sec; Batch: 2.0821 sec
0.1158 0.0842 0.0743 0.0687 0.0647 0.0607 0.0577 0.0557 0.0547 0.0539 0.0533 0.0529 0.0526 0.0524 0.0523 0.0521 

[TRAIN] Epoch[1](250/114412); Loss: 0.052935; Backpropagation: 0.2910 sec; Batch: 2.0783 sec
0.1193 0.1019 0.0751 0.0603 0.0527 0.0467 0.0438 0.0419 0.0404 0.0395 0.0386 0.0380 0.0377 0.0373 0.0370 0.0368 

[TRAIN] Epoch[1](251/114412); Loss: 0.064502; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1183 0.1080 0.0876 0.0736 0.0672 0.0628 0.0587 0.0558 0.0533 0.0520 0.0506 0.0499 0.0491 0.0487 0.0482 0.0481 

[TRAIN] Epoch[1](252/114412); Loss: 0.069330; Backpropagation: 0.2913 sec; Batch: 2.0777 sec
0.1186 0.1020 0.0846 0.0766 0.0711 0.0674 0.0640 0.0621 0.0606 0.0593 0.0586 0.0579 0.0572 0.0567 0.0564 0.0562 

[TRAIN] Epoch[1](253/114412); Loss: 0.048152; Backpropagation: 0.2926 sec; Batch: 2.0803 sec
0.0867 0.0730 0.0601 0.0539 0.0488 0.0456 0.0435 0.0421 0.0413 0.0405 0.0399 0.0395 0.0392 0.0389 0.0387 0.0386 

[TRAIN] Epoch[1](254/114412); Loss: 0.074923; Backpropagation: 0.2927 sec; Batch: 2.0806 sec
0.1436 0.1221 0.1055 0.0867 0.0803 0.0736 0.0686 0.0644 0.0623 0.0590 0.0571 0.0567 0.0557 0.0549 0.0544 0.0539 

[TRAIN] Epoch[1](255/114412); Loss: 0.060006; Backpropagation: 0.2911 sec; Batch: 2.0789 sec
0.0998 0.0828 0.0720 0.0644 0.0594 0.0586 0.0566 0.0541 0.0536 0.0529 0.0516 0.0515 0.0512 0.0505 0.0506 0.0504 

[TRAIN] Epoch[1](256/114412); Loss: 0.094033; Backpropagation: 0.2909 sec; Batch: 2.0784 sec
0.1380 0.1238 0.1112 0.1012 0.0953 0.0920 0.0891 0.0874 0.0858 0.0847 0.0841 0.0832 0.0827 0.0824 0.0819 0.0817 

[TRAIN] Epoch[1](257/114412); Loss: 0.059658; Backpropagation: 0.2909 sec; Batch: 2.0790 sec
0.1112 0.0905 0.0738 0.0631 0.0602 0.0557 0.0536 0.0523 0.0514 0.0503 0.0496 0.0493 0.0489 0.0484 0.0482 0.0481 

[TRAIN] Epoch[1](258/114412); Loss: 0.051814; Backpropagation: 0.2907 sec; Batch: 2.0777 sec
0.1020 0.0773 0.0628 0.0531 0.0500 0.0481 0.0467 0.0454 0.0445 0.0439 0.0432 0.0428 0.0426 0.0424 0.0422 0.0421 

[TRAIN] Epoch[1](259/114412); Loss: 0.066657; Backpropagation: 0.2905 sec; Batch: 2.0775 sec
0.1098 0.0926 0.0770 0.0693 0.0669 0.0640 0.0616 0.0605 0.0596 0.0591 0.0587 0.0581 0.0577 0.0575 0.0571 0.0570 

[TRAIN] Epoch[1](260/114412); Loss: 0.057268; Backpropagation: 0.2927 sec; Batch: 2.0811 sec
0.1157 0.0868 0.0733 0.0625 0.0569 0.0531 0.0507 0.0489 0.0479 0.0472 0.0464 0.0459 0.0457 0.0454 0.0450 0.0448 

[TRAIN] Epoch[1](261/114412); Loss: 0.062230; Backpropagation: 0.2929 sec; Batch: 2.0807 sec
0.1314 0.1071 0.0866 0.0693 0.0603 0.0559 0.0532 0.0517 0.0498 0.0487 0.0480 0.0475 0.0471 0.0467 0.0464 0.0461 

[TRAIN] Epoch[1](262/114412); Loss: 0.047686; Backpropagation: 0.2909 sec; Batch: 2.0782 sec
0.1095 0.0806 0.0607 0.0535 0.0475 0.0427 0.0408 0.0394 0.0381 0.0371 0.0365 0.0360 0.0356 0.0352 0.0350 0.0349 

[TRAIN] Epoch[1](263/114412); Loss: 0.057720; Backpropagation: 0.2909 sec; Batch: 2.0789 sec
0.1074 0.0964 0.0835 0.0710 0.0632 0.0572 0.0539 0.0492 0.0470 0.0455 0.0437 0.0425 0.0418 0.0409 0.0404 0.0401 

[TRAIN] Epoch[1](264/114412); Loss: 0.045465; Backpropagation: 0.2905 sec; Batch: 2.0787 sec
0.0924 0.0717 0.0566 0.0502 0.0447 0.0423 0.0402 0.0387 0.0378 0.0373 0.0365 0.0362 0.0360 0.0357 0.0356 0.0356 

[TRAIN] Epoch[1](265/114412); Loss: 0.073433; Backpropagation: 0.2906 sec; Batch: 2.0783 sec
0.1175 0.0997 0.0849 0.0787 0.0744 0.0720 0.0693 0.0675 0.0664 0.0654 0.0646 0.0638 0.0633 0.0629 0.0625 0.0622 

[TRAIN] Epoch[1](266/114412); Loss: 0.050369; Backpropagation: 0.2906 sec; Batch: 2.0785 sec
0.1252 0.0769 0.0584 0.0504 0.0469 0.0444 0.0428 0.0417 0.0411 0.0405 0.0400 0.0399 0.0397 0.0395 0.0393 0.0392 

[TRAIN] Epoch[1](267/114412); Loss: 0.079590; Backpropagation: 0.2930 sec; Batch: 2.0810 sec
0.1307 0.1092 0.0949 0.0856 0.0807 0.0766 0.0746 0.0725 0.0711 0.0700 0.0692 0.0684 0.0679 0.0675 0.0673 0.0673 

[TRAIN] Epoch[1](268/114412); Loss: 0.064134; Backpropagation: 0.2928 sec; Batch: 2.0808 sec
0.1280 0.0997 0.0797 0.0701 0.0638 0.0601 0.0579 0.0557 0.0541 0.0529 0.0518 0.0513 0.0509 0.0503 0.0501 0.0497 

[TRAIN] Epoch[1](269/114412); Loss: 0.053014; Backpropagation: 0.2913 sec; Batch: 2.0792 sec
0.1041 0.0829 0.0663 0.0570 0.0530 0.0491 0.0468 0.0456 0.0448 0.0439 0.0433 0.0428 0.0425 0.0422 0.0421 0.0419 

[TRAIN] Epoch[1](270/114412); Loss: 0.043757; Backpropagation: 0.2954 sec; Batch: 2.0836 sec
0.1173 0.0738 0.0642 0.0492 0.0429 0.0384 0.0359 0.0348 0.0327 0.0315 0.0309 0.0305 0.0300 0.0296 0.0293 0.0290 

[TRAIN] Epoch[1](271/114412); Loss: 0.069586; Backpropagation: 0.2953 sec; Batch: 2.0964 sec
0.1228 0.0905 0.0813 0.0734 0.0683 0.0660 0.0639 0.0626 0.0618 0.0611 0.0608 0.0606 0.0603 0.0601 0.0600 0.0598 

[TRAIN] Epoch[1](272/114412); Loss: 0.054020; Backpropagation: 0.2913 sec; Batch: 2.1081 sec
0.1022 0.0844 0.0666 0.0606 0.0547 0.0518 0.0487 0.0470 0.0458 0.0448 0.0440 0.0435 0.0429 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](273/114412); Loss: 0.074446; Backpropagation: 0.2911 sec; Batch: 2.0794 sec
0.1365 0.1161 0.1012 0.0834 0.0748 0.0698 0.0668 0.0645 0.0627 0.0614 0.0605 0.0596 0.0590 0.0586 0.0582 0.0579 

[TRAIN] Epoch[1](274/114412); Loss: 0.062146; Backpropagation: 0.2929 sec; Batch: 2.0809 sec
0.1189 0.0938 0.0799 0.0660 0.0617 0.0574 0.0551 0.0537 0.0529 0.0519 0.0513 0.0509 0.0506 0.0502 0.0501 0.0499 

[TRAIN] Epoch[1](275/114412); Loss: 0.059557; Backpropagation: 0.2926 sec; Batch: 2.0834 sec
0.1316 0.0934 0.0742 0.0643 0.0583 0.0544 0.0521 0.0501 0.0488 0.0480 0.0475 0.0467 0.0463 0.0460 0.0458 0.0456 

[TRAIN] Epoch[1](276/114412); Loss: 0.068639; Backpropagation: 0.2911 sec; Batch: 2.0790 sec
0.1139 0.0970 0.0822 0.0751 0.0707 0.0669 0.0641 0.0620 0.0608 0.0595 0.0588 0.0582 0.0578 0.0574 0.0571 0.0569 

[TRAIN] Epoch[1](277/114412); Loss: 0.053165; Backpropagation: 0.2905 sec; Batch: 2.0777 sec
0.1172 0.0829 0.0711 0.0572 0.0507 0.0485 0.0457 0.0444 0.0432 0.0423 0.0419 0.0414 0.0413 0.0411 0.0409 0.0408 

[TRAIN] Epoch[1](278/114412); Loss: 0.072971; Backpropagation: 0.2913 sec; Batch: 2.0786 sec
0.1217 0.0963 0.0840 0.0771 0.0721 0.0702 0.0682 0.0668 0.0656 0.0650 0.0644 0.0641 0.0635 0.0631 0.0629 0.0627 

[TRAIN] Epoch[1](279/114412); Loss: 0.060990; Backpropagation: 0.2929 sec; Batch: 2.0819 sec
0.1361 0.1003 0.0793 0.0703 0.0608 0.0561 0.0534 0.0510 0.0495 0.0481 0.0469 0.0460 0.0452 0.0447 0.0443 0.0439 

[TRAIN] Epoch[1](280/114412); Loss: 0.092383; Backpropagation: 0.2915 sec; Batch: 2.0791 sec
0.1407 0.1157 0.1028 0.0952 0.0922 0.0895 0.0878 0.0866 0.0855 0.0847 0.0840 0.0834 0.0830 0.0826 0.0823 0.0820 

[TRAIN] Epoch[1](281/114412); Loss: 0.045247; Backpropagation: 0.2911 sec; Batch: 2.0788 sec
0.0879 0.0691 0.0555 0.0504 0.0450 0.0421 0.0405 0.0396 0.0386 0.0378 0.0372 0.0367 0.0363 0.0360 0.0358 0.0355 

[TRAIN] Epoch[1](282/114412); Loss: 0.063480; Backpropagation: 0.2956 sec; Batch: 2.0838 sec
0.1395 0.1025 0.0845 0.0718 0.0621 0.0589 0.0559 0.0541 0.0514 0.0501 0.0489 0.0481 0.0476 0.0471 0.0468 0.0465 

[TRAIN] Epoch[1](283/114412); Loss: 0.046534; Backpropagation: 0.2930 sec; Batch: 2.0808 sec
0.0977 0.0721 0.0568 0.0505 0.0462 0.0432 0.0413 0.0401 0.0388 0.0379 0.0373 0.0370 0.0367 0.0364 0.0363 0.0362 

[TRAIN] Epoch[1](284/114412); Loss: 0.070720; Backpropagation: 0.2914 sec; Batch: 2.0804 sec
0.1342 0.0992 0.0851 0.0762 0.0708 0.0671 0.0639 0.0620 0.0609 0.0602 0.0595 0.0591 0.0587 0.0584 0.0582 0.0579 

[TRAIN] Epoch[1](285/114412); Loss: 0.078784; Backpropagation: 0.2913 sec; Batch: 2.0788 sec
0.1379 0.1017 0.0919 0.0830 0.0778 0.0757 0.0739 0.0720 0.0707 0.0699 0.0690 0.0683 0.0679 0.0674 0.0669 0.0666 

[TRAIN] Epoch[1](286/114412); Loss: 0.071212; Backpropagation: 0.2927 sec; Batch: 2.0805 sec
0.1230 0.0952 0.0815 0.0754 0.0708 0.0683 0.0663 0.0649 0.0636 0.0631 0.0623 0.0617 0.0613 0.0609 0.0606 0.0604 

[TRAIN] Epoch[1](287/114412); Loss: 0.066590; Backpropagation: 0.2927 sec; Batch: 2.0795 sec
0.1390 0.1001 0.0780 0.0710 0.0651 0.0622 0.0597 0.0578 0.0565 0.0556 0.0548 0.0542 0.0535 0.0531 0.0526 0.0522 

[TRAIN] Epoch[1](288/114412); Loss: 0.065033; Backpropagation: 0.2913 sec; Batch: 2.0787 sec
0.1061 0.0873 0.0766 0.0696 0.0661 0.0632 0.0609 0.0596 0.0584 0.0575 0.0569 0.0564 0.0560 0.0556 0.0553 0.0551 

[TRAIN] Epoch[1](289/114412); Loss: 0.061077; Backpropagation: 0.2907 sec; Batch: 2.0782 sec
0.1409 0.1031 0.0829 0.0696 0.0612 0.0545 0.0514 0.0497 0.0479 0.0470 0.0462 0.0454 0.0449 0.0445 0.0441 0.0439 

[TRAIN] Epoch[1](290/114412); Loss: 0.049374; Backpropagation: 0.2911 sec; Batch: 2.0789 sec
0.1022 0.0740 0.0596 0.0527 0.0493 0.0460 0.0438 0.0425 0.0417 0.0409 0.0403 0.0399 0.0396 0.0393 0.0391 0.0390 

[TRAIN] Epoch[1](291/114412); Loss: 0.057650; Backpropagation: 0.2930 sec; Batch: 2.0810 sec
0.1018 0.0831 0.0676 0.0611 0.0578 0.0548 0.0531 0.0516 0.0505 0.0499 0.0493 0.0490 0.0486 0.0483 0.0481 0.0478 

[TRAIN] Epoch[1](292/114412); Loss: 0.086227; Backpropagation: 0.2944 sec; Batch: 2.0829 sec
0.1660 0.1344 0.1018 0.0965 0.0881 0.0822 0.0779 0.0759 0.0733 0.0719 0.0708 0.0695 0.0686 0.0681 0.0677 0.0670 

[TRAIN] Epoch[1](293/114412); Loss: 0.080951; Backpropagation: 0.2931 sec; Batch: 2.0808 sec
0.1847 0.1468 0.1287 0.0975 0.0713 0.0685 0.0660 0.0639 0.0621 0.0602 0.0589 0.0582 0.0577 0.0573 0.0568 0.0565 

[TRAIN] Epoch[1](294/114412); Loss: 0.056507; Backpropagation: 0.2949 sec; Batch: 2.0838 sec
0.1115 0.0874 0.0695 0.0596 0.0551 0.0522 0.0502 0.0486 0.0479 0.0471 0.0466 0.0462 0.0459 0.0457 0.0454 0.0453 

[TRAIN] Epoch[1](295/114412); Loss: 0.059431; Backpropagation: 0.2928 sec; Batch: 2.0809 sec
0.1223 0.0922 0.0741 0.0651 0.0600 0.0558 0.0530 0.0511 0.0496 0.0486 0.0478 0.0472 0.0466 0.0462 0.0458 0.0455 

[TRAIN] Epoch[1](296/114412); Loss: 0.047144; Backpropagation: 0.2927 sec; Batch: 2.0802 sec
0.1140 0.0784 0.0614 0.0526 0.0452 0.0418 0.0399 0.0384 0.0372 0.0363 0.0357 0.0353 0.0349 0.0346 0.0344 0.0342 

[TRAIN] Epoch[1](297/114412); Loss: 0.058447; Backpropagation: 0.2912 sec; Batch: 2.0787 sec
0.1112 0.0804 0.0671 0.0619 0.0586 0.0554 0.0535 0.0522 0.0512 0.0505 0.0500 0.0493 0.0490 0.0486 0.0483 0.0480 

[TRAIN] Epoch[1](298/114412); Loss: 0.059130; Backpropagation: 0.2909 sec; Batch: 2.0783 sec
0.1397 0.1022 0.0782 0.0624 0.0575 0.0533 0.0501 0.0485 0.0466 0.0456 0.0449 0.0442 0.0438 0.0434 0.0430 0.0427 

[TRAIN] Epoch[1](299/114412); Loss: 0.042160; Backpropagation: 0.2909 sec; Batch: 2.0783 sec
0.0869 0.0571 0.0516 0.0456 0.0424 0.0403 0.0378 0.0366 0.0358 0.0352 0.0349 0.0344 0.0342 0.0341 0.0338 0.0338 

[TRAIN] Epoch[1](300/114412); Loss: 0.081378; Backpropagation: 0.2905 sec; Batch: 2.0774 sec
0.1240 0.0952 0.0887 0.0839 0.0809 0.0787 0.0775 0.0767 0.0758 0.0753 0.0748 0.0746 0.0742 0.0741 0.0739 0.0737 

[TRAIN] Epoch[1](301/114412); Loss: 0.048883; Backpropagation: 0.2950 sec; Batch: 2.0827 sec
0.1002 0.0711 0.0642 0.0559 0.0508 0.0448 0.0427 0.0416 0.0406 0.0399 0.0393 0.0387 0.0384 0.0382 0.0379 0.0379 

[TRAIN] Epoch[1](302/114412); Loss: 0.063466; Backpropagation: 0.2927 sec; Batch: 2.0804 sec
0.1390 0.0974 0.0844 0.0724 0.0630 0.0598 0.0560 0.0533 0.0512 0.0502 0.0493 0.0486 0.0483 0.0478 0.0475 0.0471 

[TRAIN] Epoch[1](303/114412); Loss: 0.059930; Backpropagation: 0.2915 sec; Batch: 2.0780 sec
0.1040 0.0818 0.0697 0.0642 0.0605 0.0579 0.0561 0.0546 0.0535 0.0526 0.0519 0.0513 0.0508 0.0504 0.0500 0.0497 

[TRAIN] Epoch[1](304/114412); Loss: 0.039575; Backpropagation: 0.2912 sec; Batch: 2.0785 sec
0.0890 0.0549 0.0475 0.0422 0.0393 0.0373 0.0353 0.0340 0.0332 0.0324 0.0320 0.0317 0.0314 0.0311 0.0310 0.0309 

[TRAIN] Epoch[1](305/114412); Loss: 0.046060; Backpropagation: 0.2909 sec; Batch: 2.0782 sec
0.0846 0.0723 0.0586 0.0499 0.0461 0.0436 0.0419 0.0403 0.0391 0.0383 0.0380 0.0375 0.0371 0.0368 0.0366 0.0365 

[TRAIN] Epoch[1](306/114412); Loss: 0.067132; Backpropagation: 0.2906 sec; Batch: 2.0775 sec
0.1144 0.0966 0.0808 0.0728 0.0675 0.0644 0.0623 0.0604 0.0593 0.0582 0.0575 0.0568 0.0563 0.0559 0.0557 0.0553 

[TRAIN] Epoch[1](307/114412); Loss: 0.043728; Backpropagation: 0.2907 sec; Batch: 2.0782 sec
0.0807 0.0617 0.0509 0.0472 0.0439 0.0421 0.0404 0.0392 0.0383 0.0377 0.0371 0.0366 0.0363 0.0361 0.0358 0.0357 

[TRAIN] Epoch[1](308/114412); Loss: 0.045261; Backpropagation: 0.2907 sec; Batch: 2.0780 sec
0.0831 0.0642 0.0564 0.0488 0.0446 0.0427 0.0412 0.0401 0.0395 0.0388 0.0382 0.0378 0.0375 0.0372 0.0371 0.0369 

[TRAIN] Epoch[1](309/114412); Loss: 0.067740; Backpropagation: 0.2902 sec; Batch: 2.0783 sec
0.1236 0.1054 0.0887 0.0762 0.0708 0.0653 0.0617 0.0594 0.0573 0.0558 0.0548 0.0540 0.0534 0.0529 0.0524 0.0520 

[TRAIN] Epoch[1](310/114412); Loss: 0.060502; Backpropagation: 0.2914 sec; Batch: 2.0791 sec
0.1104 0.0868 0.0737 0.0663 0.0621 0.0580 0.0554 0.0538 0.0524 0.0515 0.0507 0.0503 0.0498 0.0493 0.0489 0.0487 

[TRAIN] Epoch[1](311/114412); Loss: 0.056584; Backpropagation: 0.2915 sec; Batch: 2.0785 sec
0.1023 0.0748 0.0623 0.0594 0.0564 0.0543 0.0526 0.0513 0.0506 0.0499 0.0494 0.0489 0.0487 0.0484 0.0481 0.0480 

[TRAIN] Epoch[1](312/114412); Loss: 0.055633; Backpropagation: 0.2905 sec; Batch: 2.0781 sec
0.0934 0.0826 0.0672 0.0629 0.0587 0.0542 0.0521 0.0502 0.0484 0.0475 0.0467 0.0461 0.0456 0.0451 0.0448 0.0446 

[TRAIN] Epoch[1](313/114412); Loss: 0.065697; Backpropagation: 0.2914 sec; Batch: 2.1049 sec
0.1200 0.1033 0.0896 0.0731 0.0665 0.0612 0.0585 0.0561 0.0550 0.0544 0.0536 0.0528 0.0523 0.0519 0.0517 0.0513 

[TRAIN] Epoch[1](314/114412); Loss: 0.065698; Backpropagation: 0.2907 sec; Batch: 2.0786 sec
0.1157 0.0947 0.0823 0.0706 0.0664 0.0627 0.0600 0.0585 0.0574 0.0563 0.0556 0.0549 0.0544 0.0541 0.0538 0.0536 

[TRAIN] Epoch[1](315/114412); Loss: 0.074401; Backpropagation: 0.2909 sec; Batch: 2.0789 sec
0.1268 0.1081 0.0932 0.0841 0.0790 0.0731 0.0688 0.0672 0.0653 0.0630 0.0621 0.0615 0.0603 0.0598 0.0593 0.0588 

[TRAIN] Epoch[1](316/114412); Loss: 0.073104; Backpropagation: 0.2938 sec; Batch: 2.0843 sec
0.1094 0.0967 0.0848 0.0785 0.0744 0.0711 0.0693 0.0677 0.0665 0.0658 0.0652 0.0647 0.0643 0.0640 0.0637 0.0634 

[TRAIN] Epoch[1](317/114412); Loss: 0.054015; Backpropagation: 0.2954 sec; Batch: 2.0836 sec
0.0902 0.0797 0.0692 0.0603 0.0551 0.0518 0.0495 0.0482 0.0473 0.0462 0.0455 0.0449 0.0445 0.0442 0.0439 0.0438 

[TRAIN] Epoch[1](318/114412); Loss: 0.047417; Backpropagation: 0.2952 sec; Batch: 2.0832 sec
0.1104 0.0821 0.0591 0.0501 0.0466 0.0419 0.0400 0.0389 0.0378 0.0371 0.0366 0.0362 0.0359 0.0355 0.0353 0.0351 

[TRAIN] Epoch[1](319/114412); Loss: 0.053643; Backpropagation: 0.2928 sec; Batch: 2.0808 sec
0.1080 0.0849 0.0644 0.0570 0.0536 0.0501 0.0482 0.0465 0.0452 0.0445 0.0439 0.0433 0.0427 0.0423 0.0420 0.0417 

[TRAIN] Epoch[1](320/114412); Loss: 0.072735; Backpropagation: 0.2928 sec; Batch: 2.0800 sec
0.1093 0.0930 0.0831 0.0776 0.0743 0.0708 0.0692 0.0679 0.0668 0.0663 0.0655 0.0647 0.0644 0.0639 0.0635 0.0634 

[TRAIN] Epoch[1](321/114412); Loss: 0.048574; Backpropagation: 0.2930 sec; Batch: 2.0803 sec
0.0995 0.0751 0.0616 0.0527 0.0482 0.0451 0.0430 0.0416 0.0405 0.0398 0.0393 0.0388 0.0384 0.0381 0.0379 0.0377 

[TRAIN] Epoch[1](322/114412); Loss: 0.063932; Backpropagation: 0.2913 sec; Batch: 2.0780 sec
0.1157 0.0936 0.0756 0.0705 0.0650 0.0619 0.0590 0.0570 0.0555 0.0545 0.0536 0.0530 0.0525 0.0520 0.0518 0.0515 

[TRAIN] Epoch[1](323/114412); Loss: 0.035659; Backpropagation: 0.2952 sec; Batch: 2.0821 sec
0.0673 0.0536 0.0429 0.0375 0.0356 0.0330 0.0321 0.0313 0.0305 0.0302 0.0299 0.0296 0.0294 0.0293 0.0292 0.0291 

[TRAIN] Epoch[1](324/114412); Loss: 0.063150; Backpropagation: 0.2917 sec; Batch: 2.0789 sec
0.1105 0.0889 0.0734 0.0672 0.0639 0.0607 0.0584 0.0569 0.0558 0.0550 0.0544 0.0537 0.0533 0.0530 0.0526 0.0524 

[TRAIN] Epoch[1](325/114412); Loss: 0.053089; Backpropagation: 0.2952 sec; Batch: 2.0829 sec
0.1005 0.0747 0.0633 0.0576 0.0543 0.0515 0.0487 0.0468 0.0458 0.0452 0.0444 0.0440 0.0435 0.0432 0.0431 0.0428 

[TRAIN] Epoch[1](326/114412); Loss: 0.054166; Backpropagation: 0.2930 sec; Batch: 2.0790 sec
0.0932 0.0727 0.0652 0.0585 0.0553 0.0530 0.0504 0.0489 0.0481 0.0470 0.0467 0.0461 0.0457 0.0456 0.0452 0.0450 

[TRAIN] Epoch[1](327/114412); Loss: 0.071158; Backpropagation: 0.2954 sec; Batch: 2.0865 sec
0.1205 0.1005 0.0880 0.0793 0.0737 0.0694 0.0669 0.0650 0.0627 0.0616 0.0603 0.0594 0.0587 0.0580 0.0574 0.0571 

[TRAIN] Epoch[1](328/114412); Loss: 0.075698; Backpropagation: 0.2927 sec; Batch: 2.0812 sec
0.1339 0.1102 0.0920 0.0792 0.0746 0.0722 0.0692 0.0674 0.0664 0.0653 0.0647 0.0641 0.0635 0.0631 0.0627 0.0625 

[TRAIN] Epoch[1](329/114412); Loss: 0.041201; Backpropagation: 0.2928 sec; Batch: 2.0796 sec
0.0813 0.0714 0.0543 0.0488 0.0421 0.0386 0.0364 0.0346 0.0332 0.0324 0.0319 0.0314 0.0310 0.0309 0.0305 0.0304 

[TRAIN] Epoch[1](330/114412); Loss: 0.081302; Backpropagation: 0.2954 sec; Batch: 2.0828 sec
0.1497 0.1189 0.1033 0.0897 0.0839 0.0777 0.0746 0.0714 0.0693 0.0679 0.0671 0.0664 0.0658 0.0654 0.0651 0.0647 

[TRAIN] Epoch[1](331/114412); Loss: 0.046112; Backpropagation: 0.2928 sec; Batch: 2.0798 sec
0.0992 0.0771 0.0652 0.0514 0.0471 0.0419 0.0397 0.0375 0.0364 0.0357 0.0352 0.0347 0.0344 0.0342 0.0340 0.0340 

[TRAIN] Epoch[1](332/114412); Loss: 0.038718; Backpropagation: 0.2912 sec; Batch: 2.0788 sec
0.0951 0.0627 0.0532 0.0443 0.0388 0.0354 0.0321 0.0310 0.0300 0.0292 0.0288 0.0283 0.0280 0.0278 0.0275 0.0273 

[TRAIN] Epoch[1](333/114412); Loss: 0.061019; Backpropagation: 0.2914 sec; Batch: 2.0784 sec
0.1184 0.0812 0.0709 0.0650 0.0609 0.0594 0.0558 0.0545 0.0536 0.0523 0.0518 0.0512 0.0507 0.0504 0.0502 0.0499 

[TRAIN] Epoch[1](334/114412); Loss: 0.055201; Backpropagation: 0.2912 sec; Batch: 2.0791 sec
0.1061 0.0817 0.0680 0.0597 0.0551 0.0514 0.0495 0.0481 0.0471 0.0464 0.0458 0.0455 0.0451 0.0448 0.0446 0.0444 

[TRAIN] Epoch[1](335/114412); Loss: 0.062116; Backpropagation: 0.2931 sec; Batch: 2.0808 sec
0.1076 0.0881 0.0743 0.0683 0.0638 0.0598 0.0575 0.0559 0.0544 0.0535 0.0529 0.0523 0.0520 0.0515 0.0511 0.0510 

[TRAIN] Epoch[1](336/114412); Loss: 0.047467; Backpropagation: 0.2907 sec; Batch: 2.0791 sec
0.1065 0.0769 0.0578 0.0505 0.0464 0.0438 0.0412 0.0400 0.0387 0.0380 0.0375 0.0371 0.0366 0.0363 0.0361 0.0359 

[TRAIN] Epoch[1](337/114412); Loss: 0.069838; Backpropagation: 0.2909 sec; Batch: 2.0790 sec
0.1115 0.0991 0.0811 0.0732 0.0695 0.0671 0.0653 0.0642 0.0628 0.0620 0.0614 0.0609 0.0603 0.0601 0.0596 0.0594 

[TRAIN] Epoch[1](338/114412); Loss: 0.065300; Backpropagation: 0.2914 sec; Batch: 2.0806 sec
0.0912 0.0819 0.0737 0.0695 0.0666 0.0643 0.0629 0.0620 0.0609 0.0601 0.0596 0.0590 0.0586 0.0584 0.0581 0.0579 

[TRAIN] Epoch[1](339/114412); Loss: 0.076563; Backpropagation: 0.2910 sec; Batch: 2.0783 sec
0.1204 0.1041 0.0903 0.0827 0.0780 0.0752 0.0728 0.0704 0.0689 0.0678 0.0670 0.0664 0.0659 0.0654 0.0650 0.0645 

[TRAIN] Epoch[1](340/114412); Loss: 0.073643; Backpropagation: 0.2908 sec; Batch: 2.0794 sec
0.1298 0.1030 0.0857 0.0770 0.0729 0.0703 0.0684 0.0666 0.0653 0.0645 0.0638 0.0630 0.0625 0.0622 0.0618 0.0616 

[TRAIN] Epoch[1](341/114412); Loss: 0.060705; Backpropagation: 0.2910 sec; Batch: 2.0785 sec
0.1020 0.0825 0.0731 0.0667 0.0619 0.0584 0.0567 0.0548 0.0539 0.0530 0.0523 0.0519 0.0514 0.0511 0.0509 0.0506 

[TRAIN] Epoch[1](342/114412); Loss: 0.047761; Backpropagation: 0.2909 sec; Batch: 2.0795 sec
0.1071 0.0815 0.0608 0.0517 0.0479 0.0429 0.0408 0.0397 0.0383 0.0375 0.0370 0.0364 0.0361 0.0358 0.0355 0.0353 

[TRAIN] Epoch[1](343/114412); Loss: 0.063100; Backpropagation: 0.2917 sec; Batch: 2.0797 sec
0.1235 0.0975 0.0792 0.0692 0.0635 0.0597 0.0569 0.0546 0.0534 0.0523 0.0512 0.0507 0.0501 0.0496 0.0492 0.0489 

[TRAIN] Epoch[1](344/114412); Loss: 0.049588; Backpropagation: 0.2929 sec; Batch: 2.0802 sec
0.0913 0.0718 0.0608 0.0542 0.0488 0.0464 0.0454 0.0440 0.0429 0.0422 0.0417 0.0413 0.0410 0.0408 0.0406 0.0404 

[TRAIN] Epoch[1](345/114412); Loss: 0.058809; Backpropagation: 0.2913 sec; Batch: 2.0788 sec
0.1273 0.0962 0.0809 0.0689 0.0605 0.0536 0.0513 0.0486 0.0470 0.0459 0.0448 0.0441 0.0436 0.0430 0.0427 0.0425 

[TRAIN] Epoch[1](346/114412); Loss: 0.077555; Backpropagation: 0.2909 sec; Batch: 2.0780 sec
0.1463 0.1183 0.0993 0.0958 0.0830 0.0742 0.0693 0.0666 0.0635 0.0626 0.0616 0.0609 0.0604 0.0601 0.0596 0.0594 

[TRAIN] Epoch[1](347/114412); Loss: 0.057337; Backpropagation: 0.2929 sec; Batch: 2.0817 sec
0.1143 0.0960 0.0767 0.0678 0.0603 0.0545 0.0518 0.0497 0.0470 0.0454 0.0441 0.0433 0.0424 0.0418 0.0413 0.0409 

[TRAIN] Epoch[1](348/114412); Loss: 0.036866; Backpropagation: 0.2925 sec; Batch: 2.0809 sec
0.0784 0.0668 0.0531 0.0435 0.0370 0.0334 0.0313 0.0300 0.0286 0.0280 0.0274 0.0269 0.0267 0.0265 0.0263 0.0261 

[TRAIN] Epoch[1](349/114412); Loss: 0.054210; Backpropagation: 0.2906 sec; Batch: 2.0799 sec
0.0995 0.0760 0.0627 0.0571 0.0536 0.0516 0.0500 0.0487 0.0478 0.0470 0.0464 0.0460 0.0457 0.0454 0.0452 0.0449 

[TRAIN] Epoch[1](350/114412); Loss: 0.051595; Backpropagation: 0.2910 sec; Batch: 2.0779 sec
0.0978 0.0742 0.0628 0.0556 0.0520 0.0490 0.0471 0.0456 0.0447 0.0438 0.0433 0.0427 0.0422 0.0419 0.0415 0.0413 

[TRAIN] Epoch[1](351/114412); Loss: 0.049343; Backpropagation: 0.2909 sec; Batch: 2.0793 sec
0.0918 0.0648 0.0572 0.0530 0.0499 0.0475 0.0455 0.0444 0.0437 0.0428 0.0423 0.0419 0.0416 0.0413 0.0410 0.0408 

[TRAIN] Epoch[1](352/114412); Loss: 0.061197; Backpropagation: 0.2911 sec; Batch: 2.0806 sec
0.1103 0.0870 0.0742 0.0674 0.0634 0.0597 0.0567 0.0546 0.0533 0.0523 0.0514 0.0508 0.0501 0.0498 0.0493 0.0490 

[TRAIN] Epoch[1](353/114412); Loss: 0.048700; Backpropagation: 0.2911 sec; Batch: 2.0800 sec
0.1040 0.0876 0.0628 0.0544 0.0471 0.0433 0.0420 0.0405 0.0391 0.0385 0.0378 0.0371 0.0368 0.0364 0.0361 0.0359 

[TRAIN] Epoch[1](354/114412); Loss: 0.074713; Backpropagation: 0.2911 sec; Batch: 2.0793 sec
0.1343 0.1062 0.0942 0.0840 0.0788 0.0740 0.0696 0.0674 0.0656 0.0633 0.0618 0.0607 0.0596 0.0590 0.0585 0.0583 

[TRAIN] Epoch[1](355/114412); Loss: 0.046550; Backpropagation: 0.2904 sec; Batch: 2.0772 sec
0.1119 0.0832 0.0568 0.0505 0.0463 0.0423 0.0395 0.0376 0.0367 0.0358 0.0350 0.0345 0.0341 0.0338 0.0336 0.0334 

[TRAIN] Epoch[1](356/114412); Loss: 0.058207; Backpropagation: 0.2910 sec; Batch: 2.0784 sec
0.1158 0.0863 0.0732 0.0638 0.0588 0.0553 0.0528 0.0512 0.0495 0.0484 0.0475 0.0466 0.0462 0.0457 0.0453 0.0450 

[TRAIN] Epoch[1](357/114412); Loss: 0.051026; Backpropagation: 0.2915 sec; Batch: 2.0804 sec
0.1027 0.0765 0.0658 0.0570 0.0520 0.0475 0.0453 0.0439 0.0425 0.0418 0.0412 0.0407 0.0403 0.0401 0.0398 0.0394 

[TRAIN] Epoch[1](358/114412); Loss: 0.071843; Backpropagation: 0.2912 sec; Batch: 2.0873 sec
0.1095 0.0929 0.0850 0.0763 0.0723 0.0700 0.0674 0.0666 0.0657 0.0647 0.0642 0.0636 0.0632 0.0630 0.0625 0.0624 

[TRAIN] Epoch[1](359/114412); Loss: 0.084496; Backpropagation: 0.2909 sec; Batch: 2.0818 sec
0.1471 0.1218 0.1032 0.0906 0.0853 0.0814 0.0776 0.0756 0.0746 0.0731 0.0719 0.0712 0.0704 0.0698 0.0693 0.0690 

[TRAIN] Epoch[1](360/114412); Loss: 0.047967; Backpropagation: 0.2912 sec; Batch: 2.0794 sec
0.0896 0.0754 0.0668 0.0573 0.0522 0.0477 0.0437 0.0412 0.0395 0.0381 0.0374 0.0366 0.0362 0.0356 0.0353 0.0350 

[TRAIN] Epoch[1](361/114412); Loss: 0.060619; Backpropagation: 0.2916 sec; Batch: 2.0803 sec
0.1532 0.1113 0.0899 0.0757 0.0644 0.0516 0.0474 0.0461 0.0439 0.0429 0.0421 0.0413 0.0406 0.0401 0.0399 0.0396 

[TRAIN] Epoch[1](362/114412); Loss: 0.056864; Backpropagation: 0.2911 sec; Batch: 2.0794 sec
0.0912 0.0758 0.0668 0.0612 0.0576 0.0552 0.0536 0.0524 0.0510 0.0503 0.0500 0.0495 0.0491 0.0489 0.0487 0.0486 

[TRAIN] Epoch[1](363/114412); Loss: 0.076169; Backpropagation: 0.2906 sec; Batch: 2.0791 sec
0.1546 0.1325 0.1058 0.0825 0.0794 0.0750 0.0664 0.0644 0.0629 0.0617 0.0576 0.0565 0.0554 0.0550 0.0549 0.0541 

[TRAIN] Epoch[1](364/114412); Loss: 0.068300; Backpropagation: 0.2905 sec; Batch: 2.0796 sec
0.1139 0.0935 0.0793 0.0744 0.0677 0.0656 0.0637 0.0621 0.0610 0.0602 0.0596 0.0590 0.0587 0.0584 0.0580 0.0578 

[TRAIN] Epoch[1](365/114412); Loss: 0.075945; Backpropagation: 0.2911 sec; Batch: 2.0795 sec
0.1175 0.1032 0.0919 0.0788 0.0761 0.0750 0.0710 0.0696 0.0691 0.0679 0.0668 0.0664 0.0658 0.0656 0.0653 0.0651 

[TRAIN] Epoch[1](366/114412); Loss: 0.056648; Backpropagation: 0.2950 sec; Batch: 2.0848 sec
0.1020 0.0801 0.0699 0.0623 0.0572 0.0537 0.0518 0.0503 0.0490 0.0484 0.0478 0.0475 0.0471 0.0468 0.0464 0.0463 

[TRAIN] Epoch[1](367/114412); Loss: 0.044660; Backpropagation: 0.2952 sec; Batch: 2.0828 sec
0.0813 0.0672 0.0577 0.0482 0.0441 0.0424 0.0406 0.0394 0.0382 0.0377 0.0371 0.0367 0.0364 0.0361 0.0358 0.0356 

[TRAIN] Epoch[1](368/114412); Loss: 0.057921; Backpropagation: 0.2912 sec; Batch: 2.0798 sec
0.1214 0.0871 0.0730 0.0651 0.0576 0.0543 0.0526 0.0499 0.0482 0.0474 0.0465 0.0457 0.0452 0.0446 0.0442 0.0440 

[TRAIN] Epoch[1](369/114412); Loss: 0.051326; Backpropagation: 0.2909 sec; Batch: 2.0789 sec
0.0908 0.0697 0.0619 0.0565 0.0517 0.0496 0.0480 0.0462 0.0454 0.0444 0.0438 0.0433 0.0429 0.0425 0.0424 0.0422 

[TRAIN] Epoch[1](370/114412); Loss: 0.067332; Backpropagation: 0.2930 sec; Batch: 2.0806 sec
0.1153 0.0931 0.0817 0.0722 0.0678 0.0654 0.0627 0.0609 0.0598 0.0587 0.0579 0.0574 0.0567 0.0563 0.0559 0.0555 

[TRAIN] Epoch[1](371/114412); Loss: 0.057580; Backpropagation: 0.2910 sec; Batch: 2.0791 sec
0.0959 0.0780 0.0649 0.0611 0.0586 0.0558 0.0542 0.0530 0.0519 0.0510 0.0504 0.0498 0.0495 0.0492 0.0489 0.0487 

[TRAIN] Epoch[1](372/114412); Loss: 0.051770; Backpropagation: 0.2913 sec; Batch: 2.0794 sec
0.1100 0.0810 0.0610 0.0571 0.0509 0.0475 0.0460 0.0444 0.0431 0.0424 0.0419 0.0413 0.0409 0.0405 0.0402 0.0401 

[TRAIN] Epoch[1](373/114412); Loss: 0.064362; Backpropagation: 0.2912 sec; Batch: 2.0795 sec
0.1102 0.0845 0.0766 0.0686 0.0644 0.0616 0.0598 0.0589 0.0576 0.0568 0.0561 0.0556 0.0552 0.0548 0.0546 0.0545 

[TRAIN] Epoch[1](374/114412); Loss: 0.064833; Backpropagation: 0.2908 sec; Batch: 2.0787 sec
0.1425 0.1021 0.0794 0.0679 0.0613 0.0584 0.0572 0.0552 0.0537 0.0529 0.0522 0.0517 0.0512 0.0508 0.0505 0.0503 

[TRAIN] Epoch[1](375/114412); Loss: 0.059460; Backpropagation: 0.2908 sec; Batch: 2.0790 sec
0.0963 0.0797 0.0705 0.0646 0.0606 0.0581 0.0561 0.0543 0.0532 0.0526 0.0520 0.0513 0.0510 0.0506 0.0503 0.0501 

[TRAIN] Epoch[1](376/114412); Loss: 0.052159; Backpropagation: 0.2921 sec; Batch: 2.0807 sec
0.0974 0.0733 0.0620 0.0560 0.0517 0.0491 0.0476 0.0462 0.0454 0.0448 0.0443 0.0439 0.0435 0.0434 0.0431 0.0430 

[TRAIN] Epoch[1](377/114412); Loss: 0.047358; Backpropagation: 0.2928 sec; Batch: 2.0803 sec
0.0949 0.0697 0.0567 0.0514 0.0466 0.0438 0.0423 0.0411 0.0401 0.0396 0.0391 0.0388 0.0385 0.0384 0.0383 0.0382 

[TRAIN] Epoch[1](378/114412); Loss: 0.053646; Backpropagation: 0.2915 sec; Batch: 2.0797 sec
0.1186 0.0797 0.0677 0.0608 0.0538 0.0490 0.0470 0.0455 0.0442 0.0435 0.0427 0.0421 0.0415 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](379/114412); Loss: 0.058020; Backpropagation: 0.2908 sec; Batch: 2.0781 sec
0.0906 0.0755 0.0659 0.0623 0.0579 0.0562 0.0545 0.0535 0.0529 0.0523 0.0518 0.0514 0.0512 0.0509 0.0507 0.0506 

[TRAIN] Epoch[1](380/114412); Loss: 0.061709; Backpropagation: 0.2911 sec; Batch: 2.0797 sec
0.1154 0.0924 0.0767 0.0690 0.0624 0.0581 0.0557 0.0541 0.0528 0.0519 0.0512 0.0504 0.0499 0.0494 0.0491 0.0487 

[TRAIN] Epoch[1](381/114412); Loss: 0.052675; Backpropagation: 0.2913 sec; Batch: 2.0791 sec
0.0967 0.0656 0.0594 0.0573 0.0531 0.0500 0.0489 0.0478 0.0469 0.0464 0.0458 0.0455 0.0452 0.0449 0.0447 0.0445 

[TRAIN] Epoch[1](382/114412); Loss: 0.061744; Backpropagation: 0.2911 sec; Batch: 2.0935 sec
0.1165 0.0886 0.0741 0.0677 0.0629 0.0589 0.0567 0.0547 0.0534 0.0523 0.0515 0.0509 0.0505 0.0500 0.0497 0.0494 

[TRAIN] Epoch[1](383/114412); Loss: 0.045096; Backpropagation: 0.2913 sec; Batch: 2.0799 sec
0.0833 0.0637 0.0548 0.0479 0.0438 0.0423 0.0407 0.0397 0.0391 0.0387 0.0384 0.0381 0.0379 0.0378 0.0377 0.0376 

[TRAIN] Epoch[1](384/114412); Loss: 0.053043; Backpropagation: 0.2913 sec; Batch: 2.0800 sec
0.1279 0.0906 0.0731 0.0598 0.0542 0.0473 0.0443 0.0427 0.0409 0.0399 0.0390 0.0385 0.0381 0.0377 0.0374 0.0372 

[TRAIN] Epoch[1](385/114412); Loss: 0.070319; Backpropagation: 0.2912 sec; Batch: 2.0794 sec
0.1363 0.1113 0.0907 0.0803 0.0723 0.0663 0.0631 0.0615 0.0585 0.0572 0.0565 0.0555 0.0545 0.0541 0.0538 0.0533 

[TRAIN] Epoch[1](386/114412); Loss: 0.047484; Backpropagation: 0.2912 sec; Batch: 2.0799 sec
0.1083 0.0770 0.0586 0.0513 0.0475 0.0441 0.0414 0.0400 0.0386 0.0377 0.0370 0.0364 0.0360 0.0356 0.0353 0.0349 

[TRAIN] Epoch[1](387/114412); Loss: 0.061247; Backpropagation: 0.2911 sec; Batch: 2.0787 sec
0.1143 0.0987 0.0778 0.0696 0.0655 0.0649 0.0594 0.0577 0.0568 0.0526 0.0491 0.0474 0.0440 0.0415 0.0402 0.0404 

[TRAIN] Epoch[1](388/114412); Loss: 0.065025; Backpropagation: 0.2950 sec; Batch: 2.0831 sec
0.1196 0.0903 0.0765 0.0693 0.0659 0.0628 0.0602 0.0583 0.0570 0.0561 0.0553 0.0546 0.0541 0.0537 0.0533 0.0531 

[TRAIN] Epoch[1](389/114412); Loss: 0.056607; Backpropagation: 0.2948 sec; Batch: 2.0828 sec
0.0867 0.0788 0.0677 0.0639 0.0594 0.0561 0.0533 0.0517 0.0507 0.0497 0.0490 0.0485 0.0479 0.0477 0.0474 0.0472 

[TRAIN] Epoch[1](390/114412); Loss: 0.058542; Backpropagation: 0.2951 sec; Batch: 2.0828 sec
0.1181 0.0786 0.0700 0.0619 0.0575 0.0548 0.0531 0.0516 0.0509 0.0498 0.0492 0.0489 0.0484 0.0481 0.0480 0.0477 

[TRAIN] Epoch[1](391/114412); Loss: 0.078005; Backpropagation: 0.2951 sec; Batch: 2.0829 sec
0.1320 0.1170 0.0983 0.0868 0.0801 0.0747 0.0713 0.0690 0.0675 0.0664 0.0655 0.0648 0.0642 0.0639 0.0635 0.0631 

[TRAIN] Epoch[1](392/114412); Loss: 0.054827; Backpropagation: 0.2950 sec; Batch: 2.0828 sec
0.0897 0.0930 0.0791 0.0671 0.0616 0.0533 0.0483 0.0461 0.0446 0.0434 0.0429 0.0423 0.0419 0.0416 0.0412 0.0409 

[TRAIN] Epoch[1](393/114412); Loss: 0.062662; Backpropagation: 0.2954 sec; Batch: 2.0834 sec
0.1078 0.0880 0.0735 0.0659 0.0639 0.0607 0.0585 0.0569 0.0559 0.0548 0.0541 0.0534 0.0528 0.0525 0.0522 0.0519 

[TRAIN] Epoch[1](394/114412); Loss: 0.045271; Backpropagation: 0.2938 sec; Batch: 2.0814 sec
0.0913 0.0675 0.0549 0.0499 0.0457 0.0427 0.0406 0.0392 0.0384 0.0379 0.0371 0.0366 0.0361 0.0358 0.0355 0.0353 

[TRAIN] Epoch[1](395/114412); Loss: 0.076287; Backpropagation: 0.2931 sec; Batch: 2.0808 sec
0.1264 0.1068 0.0876 0.0796 0.0761 0.0742 0.0725 0.0697 0.0684 0.0675 0.0665 0.0659 0.0654 0.0649 0.0647 0.0643 

[TRAIN] Epoch[1](396/114412); Loss: 0.059340; Backpropagation: 0.2909 sec; Batch: 2.0793 sec
0.1006 0.0870 0.0720 0.0654 0.0609 0.0582 0.0561 0.0540 0.0523 0.0507 0.0501 0.0494 0.0486 0.0483 0.0481 0.0477 

[TRAIN] Epoch[1](397/114412); Loss: 0.056733; Backpropagation: 0.2955 sec; Batch: 2.0831 sec
0.1333 0.0922 0.0735 0.0606 0.0548 0.0518 0.0485 0.0469 0.0454 0.0445 0.0437 0.0431 0.0428 0.0425 0.0421 0.0419 

[TRAIN] Epoch[1](398/114412); Loss: 0.089240; Backpropagation: 0.2955 sec; Batch: 2.0831 sec
0.1381 0.1147 0.1011 0.0944 0.0921 0.0892 0.0863 0.0838 0.0813 0.0804 0.0794 0.0785 0.0778 0.0773 0.0769 0.0767 

[TRAIN] Epoch[1](399/114412); Loss: 0.059242; Backpropagation: 0.2914 sec; Batch: 2.0790 sec
0.1083 0.0917 0.0723 0.0640 0.0615 0.0608 0.0554 0.0521 0.0502 0.0491 0.0484 0.0477 0.0472 0.0467 0.0464 0.0461 

[TRAIN] Epoch[1](400/114412); Loss: 0.073545; Backpropagation: 0.2913 sec; Batch: 2.0789 sec
0.1412 0.1117 0.0891 0.0776 0.0723 0.0698 0.0666 0.0646 0.0634 0.0621 0.0611 0.0603 0.0598 0.0593 0.0590 0.0589 

[TRAIN] Epoch[1](401/114412); Loss: 0.080946; Backpropagation: 0.2913 sec; Batch: 2.0781 sec
0.1152 0.1104 0.0958 0.0881 0.0825 0.0806 0.0770 0.0746 0.0735 0.0727 0.0718 0.0712 0.0708 0.0704 0.0703 0.0701 

[TRAIN] Epoch[1](402/114412); Loss: 0.063670; Backpropagation: 0.2947 sec; Batch: 2.0825 sec
0.1160 0.0869 0.0774 0.0688 0.0710 0.0660 0.0611 0.0574 0.0546 0.0534 0.0526 0.0518 0.0511 0.0505 0.0502 0.0499 

[TRAIN] Epoch[1](403/114412); Loss: 0.054513; Backpropagation: 0.2928 sec; Batch: 2.0822 sec
0.1183 0.0794 0.0654 0.0588 0.0534 0.0507 0.0483 0.0472 0.0461 0.0451 0.0444 0.0437 0.0432 0.0430 0.0427 0.0424 

[TRAIN] Epoch[1](404/114412); Loss: 0.068360; Backpropagation: 0.2954 sec; Batch: 2.0823 sec
0.1740 0.1105 0.0827 0.0721 0.0654 0.0607 0.0570 0.0556 0.0545 0.0533 0.0525 0.0519 0.0514 0.0511 0.0507 0.0505 

[TRAIN] Epoch[1](405/114412); Loss: 0.084595; Backpropagation: 0.2930 sec; Batch: 2.0799 sec
0.1580 0.1112 0.0960 0.0911 0.0831 0.0795 0.0778 0.0759 0.0748 0.0740 0.0733 0.0727 0.0722 0.0717 0.0713 0.0710 

[TRAIN] Epoch[1](406/114412); Loss: 0.067586; Backpropagation: 0.2932 sec; Batch: 2.0801 sec
0.1263 0.0951 0.0811 0.0726 0.0668 0.0636 0.0616 0.0597 0.0587 0.0579 0.0572 0.0567 0.0563 0.0560 0.0558 0.0557 

[TRAIN] Epoch[1](407/114412); Loss: 0.118733; Backpropagation: 0.2911 sec; Batch: 2.0826 sec
0.1507 0.1454 0.1294 0.1139 0.1087 0.1060 0.0987 0.0998 0.1102 0.1162 0.1228 0.1243 0.1216 0.1198 0.1180 0.1144 

[TRAIN] Epoch[1](408/114412); Loss: 0.067703; Backpropagation: 0.2920 sec; Batch: 2.0852 sec
0.1432 0.1031 0.0857 0.0743 0.0699 0.0632 0.0598 0.0576 0.0560 0.0549 0.0541 0.0532 0.0526 0.0522 0.0518 0.0515 

[TRAIN] Epoch[1](409/114412); Loss: 0.043053; Backpropagation: 0.2915 sec; Batch: 2.0815 sec
0.1099 0.0710 0.0556 0.0503 0.0449 0.0380 0.0365 0.0345 0.0330 0.0322 0.0316 0.0310 0.0306 0.0302 0.0298 0.0296 

[TRAIN] Epoch[1](410/114412); Loss: 0.092338; Backpropagation: 0.2907 sec; Batch: 2.0780 sec
0.1697 0.1219 0.1065 0.0975 0.0915 0.0882 0.0860 0.0834 0.0820 0.0809 0.0798 0.0790 0.0785 0.0779 0.0774 0.0771 

[TRAIN] Epoch[1](411/114412); Loss: 0.080186; Backpropagation: 0.2906 sec; Batch: 2.0777 sec
0.1406 0.1120 0.0929 0.0865 0.0819 0.0769 0.0746 0.0725 0.0707 0.0696 0.0687 0.0682 0.0676 0.0671 0.0668 0.0664 

[TRAIN] Epoch[1](412/114412); Loss: 0.075845; Backpropagation: 0.2911 sec; Batch: 2.0789 sec
0.1838 0.1307 0.1102 0.0909 0.0817 0.0722 0.0657 0.0601 0.0575 0.0552 0.0533 0.0522 0.0510 0.0503 0.0498 0.0492 

[TRAIN] Epoch[1](413/114412); Loss: 0.067918; Backpropagation: 0.2913 sec; Batch: 2.0785 sec
0.1220 0.1032 0.0893 0.0806 0.0705 0.0651 0.0630 0.0600 0.0578 0.0560 0.0548 0.0539 0.0533 0.0528 0.0524 0.0519 

[TRAIN] Epoch[1](414/114412); Loss: 0.084449; Backpropagation: 0.2906 sec; Batch: 2.0781 sec
0.1828 0.1442 0.1122 0.0939 0.0861 0.0792 0.0733 0.0703 0.0680 0.0658 0.0646 0.0635 0.0626 0.0621 0.0615 0.0610 

[TRAIN] Epoch[1](415/114412); Loss: 0.079736; Backpropagation: 0.2906 sec; Batch: 2.0781 sec
0.1603 0.1189 0.0965 0.0882 0.0818 0.0760 0.0725 0.0707 0.0676 0.0658 0.0650 0.0639 0.0629 0.0624 0.0618 0.0614 

[TRAIN] Epoch[1](416/114412); Loss: 0.057519; Backpropagation: 0.2952 sec; Batch: 2.0829 sec
0.1478 0.0901 0.0731 0.0648 0.0592 0.0533 0.0509 0.0484 0.0452 0.0436 0.0427 0.0415 0.0406 0.0401 0.0397 0.0392 

[TRAIN] Epoch[1](417/114412); Loss: 0.063408; Backpropagation: 0.2944 sec; Batch: 2.0820 sec
0.1399 0.0953 0.0770 0.0707 0.0662 0.0587 0.0555 0.0537 0.0520 0.0509 0.0503 0.0496 0.0492 0.0488 0.0486 0.0483 

[TRAIN] Epoch[1](418/114412); Loss: 0.081619; Backpropagation: 0.2953 sec; Batch: 2.0840 sec
0.1501 0.1115 0.0954 0.0891 0.0817 0.0776 0.0749 0.0731 0.0716 0.0706 0.0697 0.0691 0.0686 0.0680 0.0676 0.0672 

[TRAIN] Epoch[1](419/114412); Loss: 0.056854; Backpropagation: 0.2931 sec; Batch: 2.0807 sec
0.1167 0.0974 0.0774 0.0689 0.0626 0.0544 0.0511 0.0479 0.0452 0.0439 0.0424 0.0414 0.0408 0.0402 0.0398 0.0395 

[TRAIN] Epoch[1](420/114412); Loss: 0.066493; Backpropagation: 0.2934 sec; Batch: 2.0811 sec
0.1333 0.1050 0.0790 0.0721 0.0660 0.0616 0.0593 0.0571 0.0559 0.0551 0.0544 0.0537 0.0534 0.0530 0.0526 0.0524 

[TRAIN] Epoch[1](421/114412); Loss: 0.052882; Backpropagation: 0.2952 sec; Batch: 2.0821 sec
0.1065 0.0771 0.0670 0.0619 0.0546 0.0502 0.0481 0.0458 0.0443 0.0432 0.0425 0.0418 0.0413 0.0409 0.0406 0.0403 

[TRAIN] Epoch[1](422/114412); Loss: 0.057282; Backpropagation: 0.2929 sec; Batch: 2.0803 sec
0.1130 0.0842 0.0687 0.0645 0.0606 0.0542 0.0527 0.0504 0.0484 0.0479 0.0467 0.0459 0.0455 0.0450 0.0446 0.0444 

[TRAIN] Epoch[1](423/114412); Loss: 0.061508; Backpropagation: 0.2913 sec; Batch: 2.0792 sec
0.1293 0.0928 0.0750 0.0685 0.0631 0.0579 0.0555 0.0536 0.0517 0.0506 0.0494 0.0485 0.0479 0.0472 0.0468 0.0465 

[TRAIN] Epoch[1](424/114412); Loss: 0.067600; Backpropagation: 0.2929 sec; Batch: 2.0805 sec
0.1322 0.1030 0.0853 0.0773 0.0683 0.0641 0.0604 0.0584 0.0569 0.0556 0.0547 0.0541 0.0534 0.0531 0.0526 0.0522 

[TRAIN] Epoch[1](425/114412); Loss: 0.053826; Backpropagation: 0.2929 sec; Batch: 2.0804 sec
0.1012 0.0789 0.0660 0.0612 0.0565 0.0517 0.0497 0.0478 0.0460 0.0454 0.0444 0.0434 0.0430 0.0424 0.0419 0.0417 

[TRAIN] Epoch[1](426/114412); Loss: 0.048795; Backpropagation: 0.2911 sec; Batch: 2.0785 sec
0.1138 0.0846 0.0689 0.0576 0.0516 0.0458 0.0427 0.0393 0.0375 0.0361 0.0353 0.0344 0.0338 0.0335 0.0331 0.0326 

[TRAIN] Epoch[1](427/114412); Loss: 0.071765; Backpropagation: 0.2910 sec; Batch: 2.0777 sec
0.1157 0.1012 0.0829 0.0781 0.0739 0.0689 0.0672 0.0655 0.0643 0.0633 0.0625 0.0618 0.0613 0.0609 0.0605 0.0603 

[TRAIN] Epoch[1](428/114412); Loss: 0.048991; Backpropagation: 0.2913 sec; Batch: 2.0793 sec
0.0905 0.0725 0.0610 0.0543 0.0504 0.0480 0.0455 0.0437 0.0424 0.0412 0.0405 0.0396 0.0391 0.0386 0.0384 0.0380 

[TRAIN] Epoch[1](429/114412); Loss: 0.089729; Backpropagation: 0.2914 sec; Batch: 2.0788 sec
0.1519 0.1217 0.1099 0.0998 0.0916 0.0869 0.0838 0.0816 0.0797 0.0780 0.0770 0.0761 0.0752 0.0747 0.0742 0.0736 

[TRAIN] Epoch[1](430/114412); Loss: 0.071684; Backpropagation: 0.2912 sec; Batch: 2.0790 sec
0.1373 0.1010 0.0860 0.0816 0.0709 0.0658 0.0650 0.0623 0.0619 0.0609 0.0599 0.0595 0.0592 0.0588 0.0586 0.0583 

[TRAIN] Epoch[1](431/114412); Loss: 0.070948; Backpropagation: 0.2928 sec; Batch: 2.0797 sec
0.1344 0.1076 0.0891 0.0743 0.0699 0.0661 0.0640 0.0622 0.0608 0.0599 0.0592 0.0583 0.0578 0.0575 0.0571 0.0569 

[TRAIN] Epoch[1](432/114412); Loss: 0.057268; Backpropagation: 0.2926 sec; Batch: 2.0800 sec
0.0974 0.0766 0.0702 0.0618 0.0567 0.0548 0.0522 0.0512 0.0505 0.0499 0.0496 0.0492 0.0492 0.0492 0.0488 0.0489 

[TRAIN] Epoch[1](433/114412); Loss: 0.053642; Backpropagation: 0.2912 sec; Batch: 2.0790 sec
0.1047 0.0774 0.0695 0.0606 0.0550 0.0514 0.0494 0.0466 0.0454 0.0447 0.0435 0.0428 0.0425 0.0419 0.0416 0.0413 

[TRAIN] Epoch[1](434/114412); Loss: 0.046882; Backpropagation: 0.2913 sec; Batch: 2.0793 sec
0.1046 0.0809 0.0648 0.0534 0.0494 0.0443 0.0415 0.0387 0.0366 0.0356 0.0348 0.0340 0.0334 0.0331 0.0327 0.0325 

[TRAIN] Epoch[1](435/114412); Loss: 0.070019; Backpropagation: 0.2913 sec; Batch: 2.0780 sec
0.1192 0.0921 0.0824 0.0761 0.0706 0.0677 0.0660 0.0635 0.0625 0.0617 0.0607 0.0603 0.0599 0.0594 0.0592 0.0590 

[TRAIN] Epoch[1](436/114412); Loss: 0.078563; Backpropagation: 0.2915 sec; Batch: 2.0779 sec
0.1124 0.1006 0.0900 0.0837 0.0815 0.0782 0.0758 0.0740 0.0728 0.0716 0.0708 0.0699 0.0696 0.0691 0.0686 0.0685 

[TRAIN] Epoch[1](437/114412); Loss: 0.067317; Backpropagation: 0.2910 sec; Batch: 2.0977 sec
0.1518 0.1111 0.0902 0.0739 0.0657 0.0615 0.0573 0.0549 0.0539 0.0527 0.0518 0.0512 0.0507 0.0503 0.0502 0.0499 

[TRAIN] Epoch[1](438/114412); Loss: 0.049462; Backpropagation: 0.2910 sec; Batch: 2.0789 sec
0.0897 0.0700 0.0636 0.0564 0.0508 0.0482 0.0456 0.0439 0.0428 0.0417 0.0409 0.0403 0.0397 0.0394 0.0392 0.0390 

[TRAIN] Epoch[1](439/114412); Loss: 0.073910; Backpropagation: 0.2914 sec; Batch: 2.0808 sec
0.1242 0.1007 0.0898 0.0808 0.0748 0.0707 0.0688 0.0669 0.0654 0.0645 0.0638 0.0632 0.0627 0.0623 0.0620 0.0619 

[TRAIN] Epoch[1](440/114412); Loss: 0.043157; Backpropagation: 0.2914 sec; Batch: 2.0782 sec
0.0998 0.0660 0.0549 0.0490 0.0437 0.0409 0.0385 0.0363 0.0351 0.0340 0.0331 0.0326 0.0321 0.0317 0.0315 0.0312 

[TRAIN] Epoch[1](441/114412); Loss: 0.060341; Backpropagation: 0.2913 sec; Batch: 2.0784 sec
0.1008 0.0820 0.0703 0.0648 0.0617 0.0587 0.0561 0.0549 0.0539 0.0530 0.0523 0.0519 0.0516 0.0513 0.0511 0.0510 

[TRAIN] Epoch[1](442/114412); Loss: 0.052411; Backpropagation: 0.2911 sec; Batch: 2.0786 sec
0.0920 0.0721 0.0623 0.0585 0.0543 0.0499 0.0480 0.0466 0.0460 0.0452 0.0447 0.0444 0.0440 0.0438 0.0435 0.0434 

[TRAIN] Epoch[1](443/114412); Loss: 0.077166; Backpropagation: 0.2930 sec; Batch: 2.0802 sec
0.1233 0.1102 0.0954 0.0874 0.0817 0.0763 0.0726 0.0704 0.0685 0.0665 0.0655 0.0645 0.0637 0.0634 0.0629 0.0624 

[TRAIN] Epoch[1](444/114412); Loss: 0.045528; Backpropagation: 0.2930 sec; Batch: 2.0801 sec
0.0900 0.0707 0.0569 0.0478 0.0440 0.0428 0.0405 0.0392 0.0385 0.0378 0.0374 0.0370 0.0368 0.0366 0.0363 0.0362 

[TRAIN] Epoch[1](445/114412); Loss: 0.047181; Backpropagation: 0.2913 sec; Batch: 2.0786 sec
0.0836 0.0626 0.0558 0.0509 0.0476 0.0458 0.0440 0.0428 0.0419 0.0410 0.0406 0.0402 0.0399 0.0397 0.0394 0.0392 

[TRAIN] Epoch[1](446/114412); Loss: 0.069871; Backpropagation: 0.2915 sec; Batch: 2.0778 sec
0.1082 0.0971 0.0824 0.0755 0.0712 0.0684 0.0657 0.0639 0.0625 0.0617 0.0611 0.0607 0.0602 0.0600 0.0598 0.0596 

[TRAIN] Epoch[1](447/114412); Loss: 0.029064; Backpropagation: 0.2911 sec; Batch: 2.0789 sec
0.0640 0.0485 0.0367 0.0303 0.0299 0.0267 0.0252 0.0241 0.0240 0.0229 0.0225 0.0226 0.0220 0.0218 0.0220 0.0216 

[TRAIN] Epoch[1](448/114412); Loss: 0.061821; Backpropagation: 0.2930 sec; Batch: 2.0794 sec
0.1064 0.0816 0.0745 0.0669 0.0618 0.0594 0.0576 0.0558 0.0549 0.0541 0.0534 0.0530 0.0528 0.0526 0.0523 0.0522 

[TRAIN] Epoch[1](449/114412); Loss: 0.069322; Backpropagation: 0.2911 sec; Batch: 2.0774 sec
0.1149 0.0926 0.0831 0.0752 0.0694 0.0665 0.0645 0.0631 0.0620 0.0612 0.0604 0.0598 0.0595 0.0592 0.0589 0.0588 

[TRAIN] Epoch[1](450/114412); Loss: 0.060279; Backpropagation: 0.2927 sec; Batch: 2.0805 sec
0.1158 0.0889 0.0778 0.0668 0.0596 0.0555 0.0534 0.0517 0.0509 0.0502 0.0496 0.0493 0.0490 0.0487 0.0487 0.0486 

[TRAIN] Epoch[1](451/114412); Loss: 0.079123; Backpropagation: 0.2924 sec; Batch: 2.0801 sec
0.1447 0.1178 0.1080 0.0954 0.0870 0.0791 0.0725 0.0694 0.0654 0.0641 0.0623 0.0615 0.0605 0.0598 0.0595 0.0590 

[TRAIN] Epoch[1](452/114412); Loss: 0.068233; Backpropagation: 0.2925 sec; Batch: 2.0804 sec
0.1088 0.0814 0.0790 0.0713 0.0687 0.0658 0.0643 0.0633 0.0624 0.0619 0.0615 0.0610 0.0609 0.0606 0.0604 0.0603 

[TRAIN] Epoch[1](453/114412); Loss: 0.062431; Backpropagation: 0.2926 sec; Batch: 2.0804 sec
0.1207 0.0908 0.0768 0.0686 0.0629 0.0593 0.0565 0.0549 0.0535 0.0524 0.0517 0.0512 0.0504 0.0501 0.0497 0.0495 

[TRAIN] Epoch[1](454/114412); Loss: 0.082250; Backpropagation: 0.2915 sec; Batch: 2.0800 sec
0.1336 0.1147 0.0996 0.0869 0.0827 0.0790 0.0765 0.0747 0.0738 0.0730 0.0725 0.0716 0.0707 0.0697 0.0688 0.0682 

[TRAIN] Epoch[1](455/114412); Loss: 0.071990; Backpropagation: 0.2971 sec; Batch: 2.0840 sec
0.1203 0.1026 0.0874 0.0799 0.0735 0.0694 0.0669 0.0651 0.0637 0.0622 0.0615 0.0608 0.0603 0.0598 0.0594 0.0590 

[TRAIN] Epoch[1](456/114412); Loss: 0.041781; Backpropagation: 0.2943 sec; Batch: 2.0821 sec
0.0694 0.0616 0.0549 0.0456 0.0419 0.0400 0.0380 0.0369 0.0363 0.0356 0.0351 0.0350 0.0347 0.0345 0.0345 0.0345 

[TRAIN] Epoch[1](457/114412); Loss: 0.054550; Backpropagation: 0.2952 sec; Batch: 2.0823 sec
0.0988 0.0752 0.0641 0.0582 0.0550 0.0521 0.0503 0.0490 0.0480 0.0474 0.0468 0.0463 0.0459 0.0455 0.0452 0.0450 

[TRAIN] Epoch[1](458/114412); Loss: 0.055007; Backpropagation: 0.2956 sec; Batch: 2.0824 sec
0.1119 0.0903 0.0811 0.0636 0.0559 0.0511 0.0474 0.0457 0.0442 0.0429 0.0421 0.0416 0.0412 0.0406 0.0403 0.0401 

[TRAIN] Epoch[1](459/114412); Loss: 0.041157; Backpropagation: 0.2955 sec; Batch: 2.0828 sec
0.0763 0.0653 0.0513 0.0453 0.0415 0.0389 0.0374 0.0359 0.0348 0.0342 0.0336 0.0332 0.0330 0.0327 0.0326 0.0324 

[TRAIN] Epoch[1](460/114412); Loss: 0.073676; Backpropagation: 0.2931 sec; Batch: 2.0803 sec
0.1178 0.1017 0.0900 0.0807 0.0750 0.0718 0.0695 0.0678 0.0661 0.0648 0.0640 0.0632 0.0624 0.0618 0.0614 0.0608 

[TRAIN] Epoch[1](461/114412); Loss: 0.080710; Backpropagation: 0.2930 sec; Batch: 2.0805 sec
0.1459 0.1264 0.1059 0.0922 0.0874 0.0789 0.0752 0.0708 0.0676 0.0657 0.0643 0.0633 0.0625 0.0621 0.0617 0.0613 

[TRAIN] Epoch[1](462/114412); Loss: 0.045628; Backpropagation: 0.2942 sec; Batch: 2.0817 sec
0.0832 0.0670 0.0572 0.0499 0.0456 0.0427 0.0413 0.0405 0.0392 0.0386 0.0382 0.0377 0.0375 0.0373 0.0371 0.0371 

[TRAIN] Epoch[1](463/114412); Loss: 0.052246; Backpropagation: 0.2943 sec; Batch: 2.0823 sec
0.0960 0.0758 0.0643 0.0580 0.0527 0.0496 0.0479 0.0465 0.0454 0.0445 0.0437 0.0432 0.0426 0.0422 0.0419 0.0416 

[TRAIN] Epoch[1](464/114412); Loss: 0.055552; Backpropagation: 0.2926 sec; Batch: 2.0808 sec
0.1073 0.0813 0.0660 0.0625 0.0582 0.0532 0.0507 0.0486 0.0474 0.0466 0.0456 0.0448 0.0446 0.0442 0.0439 0.0439 

[TRAIN] Epoch[1](465/114412); Loss: 0.047917; Backpropagation: 0.2928 sec; Batch: 2.0799 sec
0.1138 0.0827 0.0654 0.0523 0.0474 0.0438 0.0408 0.0387 0.0375 0.0365 0.0356 0.0350 0.0347 0.0344 0.0340 0.0339 

[TRAIN] Epoch[1](466/114412); Loss: 0.063824; Backpropagation: 0.2956 sec; Batch: 2.0833 sec
0.1044 0.0919 0.0767 0.0697 0.0651 0.0617 0.0597 0.0579 0.0566 0.0556 0.0548 0.0542 0.0538 0.0534 0.0530 0.0527 

[TRAIN] Epoch[1](467/114412); Loss: 0.071805; Backpropagation: 0.2968 sec; Batch: 2.0840 sec
0.1072 0.0976 0.0862 0.0784 0.0743 0.0706 0.0683 0.0666 0.0650 0.0641 0.0631 0.0624 0.0620 0.0614 0.0610 0.0606 

[TRAIN] Epoch[1](468/114412); Loss: 0.079785; Backpropagation: 0.2970 sec; Batch: 2.0850 sec
0.1323 0.1118 0.0969 0.0885 0.0822 0.0776 0.0744 0.0720 0.0706 0.0691 0.0682 0.0675 0.0671 0.0665 0.0661 0.0658 

[TRAIN] Epoch[1](469/114412); Loss: 0.065435; Backpropagation: 0.2955 sec; Batch: 2.0828 sec
0.1086 0.0917 0.0791 0.0701 0.0663 0.0628 0.0610 0.0595 0.0582 0.0575 0.0566 0.0559 0.0555 0.0550 0.0547 0.0544 

[TRAIN] Epoch[1](470/114412); Loss: 0.061077; Backpropagation: 0.2952 sec; Batch: 2.0822 sec
0.1080 0.0876 0.0727 0.0667 0.0609 0.0577 0.0566 0.0548 0.0537 0.0528 0.0521 0.0515 0.0511 0.0506 0.0503 0.0501 

[TRAIN] Epoch[1](471/114412); Loss: 0.048511; Backpropagation: 0.2955 sec; Batch: 2.0884 sec
0.1169 0.0824 0.0675 0.0546 0.0468 0.0432 0.0408 0.0386 0.0376 0.0366 0.0360 0.0356 0.0352 0.0350 0.0347 0.0346 

[TRAIN] Epoch[1](472/114412); Loss: 0.070329; Backpropagation: 0.2956 sec; Batch: 2.0834 sec
0.1147 0.0929 0.0847 0.0760 0.0712 0.0679 0.0657 0.0642 0.0630 0.0622 0.0615 0.0610 0.0605 0.0602 0.0599 0.0597 

[TRAIN] Epoch[1](473/114412); Loss: 0.094632; Backpropagation: 0.2933 sec; Batch: 2.0835 sec
0.1651 0.1245 0.1126 0.1029 0.0942 0.0907 0.0884 0.0859 0.0843 0.0831 0.0819 0.0812 0.0805 0.0799 0.0796 0.0792 

[TRAIN] Epoch[1](474/114412); Loss: 0.067459; Backpropagation: 0.2929 sec; Batch: 2.0811 sec
0.1378 0.1106 0.0885 0.0743 0.0663 0.0619 0.0592 0.0571 0.0556 0.0545 0.0536 0.0528 0.0524 0.0519 0.0516 0.0514 

[TRAIN] Epoch[1](475/114412); Loss: 0.046203; Backpropagation: 0.2912 sec; Batch: 2.0790 sec
0.1026 0.0774 0.0598 0.0483 0.0452 0.0423 0.0400 0.0385 0.0373 0.0366 0.0360 0.0356 0.0353 0.0350 0.0347 0.0346 

[TRAIN] Epoch[1](476/114412); Loss: 0.077404; Backpropagation: 0.2916 sec; Batch: 2.0808 sec
0.1499 0.1124 0.0962 0.0868 0.0786 0.0734 0.0706 0.0678 0.0660 0.0648 0.0637 0.0629 0.0621 0.0615 0.0610 0.0606 

[TRAIN] Epoch[1](477/114412); Loss: 0.059216; Backpropagation: 0.2910 sec; Batch: 2.0782 sec
0.1191 0.0888 0.0750 0.0663 0.0584 0.0556 0.0530 0.0514 0.0500 0.0490 0.0482 0.0475 0.0469 0.0464 0.0461 0.0457 

[TRAIN] Epoch[1](478/114412); Loss: 0.101525; Backpropagation: 0.2912 sec; Batch: 2.0788 sec
0.1772 0.1444 0.1292 0.1146 0.1048 0.0969 0.0921 0.0897 0.0879 0.0863 0.0852 0.0845 0.0837 0.0830 0.0825 0.0822 

[TRAIN] Epoch[1](479/114412); Loss: 0.075669; Backpropagation: 0.2953 sec; Batch: 2.0811 sec
0.1387 0.1019 0.0888 0.0819 0.0765 0.0723 0.0699 0.0683 0.0664 0.0653 0.0647 0.0640 0.0635 0.0631 0.0628 0.0626 

[TRAIN] Epoch[1](480/114412); Loss: 0.068407; Backpropagation: 0.2930 sec; Batch: 2.0808 sec
0.1438 0.1092 0.0889 0.0761 0.0662 0.0619 0.0592 0.0577 0.0563 0.0553 0.0548 0.0542 0.0535 0.0529 0.0524 0.0521 

[TRAIN] Epoch[1](481/114412); Loss: 0.070491; Backpropagation: 0.2931 sec; Batch: 2.0805 sec
0.1438 0.0986 0.0850 0.0760 0.0693 0.0663 0.0634 0.0624 0.0605 0.0593 0.0585 0.0577 0.0572 0.0569 0.0566 0.0563 

[TRAIN] Epoch[1](482/114412); Loss: 0.060012; Backpropagation: 0.2927 sec; Batch: 2.0803 sec
0.1241 0.0855 0.0709 0.0637 0.0595 0.0563 0.0542 0.0527 0.0514 0.0504 0.0497 0.0492 0.0487 0.0482 0.0480 0.0477 

[TRAIN] Epoch[1](483/114412); Loss: 0.053835; Backpropagation: 0.2929 sec; Batch: 2.0811 sec
0.1068 0.0842 0.0674 0.0601 0.0560 0.0508 0.0484 0.0463 0.0447 0.0440 0.0432 0.0427 0.0422 0.0418 0.0415 0.0413 

[TRAIN] Epoch[1](484/114412); Loss: 0.059297; Backpropagation: 0.2912 sec; Batch: 2.0793 sec
0.1392 0.0974 0.0771 0.0674 0.0591 0.0523 0.0505 0.0489 0.0468 0.0461 0.0451 0.0445 0.0440 0.0438 0.0433 0.0431 

[TRAIN] Epoch[1](485/114412); Loss: 0.048214; Backpropagation: 0.2910 sec; Batch: 2.0781 sec
0.1330 0.0796 0.0617 0.0551 0.0471 0.0426 0.0407 0.0387 0.0363 0.0354 0.0346 0.0341 0.0336 0.0333 0.0330 0.0327 

[TRAIN] Epoch[1](486/114412); Loss: 0.054219; Backpropagation: 0.2930 sec; Batch: 2.0802 sec
0.1339 0.0829 0.0632 0.0584 0.0544 0.0493 0.0468 0.0452 0.0437 0.0428 0.0424 0.0416 0.0412 0.0409 0.0405 0.0403 

[TRAIN] Epoch[1](487/114412); Loss: 0.068037; Backpropagation: 0.2928 sec; Batch: 2.0791 sec
0.1105 0.0849 0.0774 0.0722 0.0690 0.0663 0.0643 0.0627 0.0618 0.0610 0.0604 0.0600 0.0597 0.0596 0.0595 0.0593 

[TRAIN] Epoch[1](488/114412); Loss: 0.080483; Backpropagation: 0.2952 sec; Batch: 2.0831 sec
0.1281 0.1109 0.0989 0.0896 0.0845 0.0796 0.0760 0.0732 0.0715 0.0700 0.0692 0.0684 0.0677 0.0671 0.0668 0.0664 

[TRAIN] Epoch[1](489/114412); Loss: 0.065400; Backpropagation: 0.2930 sec; Batch: 2.0801 sec
0.1251 0.0952 0.0806 0.0723 0.0670 0.0624 0.0599 0.0578 0.0561 0.0549 0.0540 0.0530 0.0526 0.0522 0.0518 0.0514 

[TRAIN] Epoch[1](490/114412); Loss: 0.065493; Backpropagation: 0.2931 sec; Batch: 2.0791 sec
0.1247 0.0940 0.0785 0.0696 0.0652 0.0622 0.0602 0.0582 0.0569 0.0559 0.0551 0.0544 0.0539 0.0534 0.0530 0.0528 

[TRAIN] Epoch[1](491/114412); Loss: 0.050733; Backpropagation: 0.2931 sec; Batch: 2.0802 sec
0.1195 0.0834 0.0649 0.0553 0.0503 0.0461 0.0436 0.0422 0.0408 0.0396 0.0388 0.0382 0.0378 0.0374 0.0371 0.0368 

[TRAIN] Epoch[1](492/114412); Loss: 0.046872; Backpropagation: 0.2929 sec; Batch: 2.0798 sec
0.1218 0.0752 0.0637 0.0531 0.0453 0.0420 0.0385 0.0373 0.0362 0.0353 0.0345 0.0341 0.0338 0.0333 0.0330 0.0329 

[TRAIN] Epoch[1](493/114412); Loss: 0.050033; Backpropagation: 0.2911 sec; Batch: 2.0776 sec
0.0862 0.0691 0.0620 0.0558 0.0519 0.0485 0.0464 0.0450 0.0438 0.0429 0.0423 0.0419 0.0416 0.0413 0.0410 0.0408 

[TRAIN] Epoch[1](494/114412); Loss: 0.053556; Backpropagation: 0.2911 sec; Batch: 2.0780 sec
0.0953 0.0764 0.0672 0.0582 0.0550 0.0519 0.0498 0.0481 0.0467 0.0458 0.0450 0.0443 0.0438 0.0435 0.0432 0.0429 

[TRAIN] Epoch[1](495/114412); Loss: 0.073890; Backpropagation: 0.2915 sec; Batch: 2.0786 sec
0.1371 0.0989 0.0862 0.0794 0.0737 0.0705 0.0681 0.0664 0.0652 0.0643 0.0634 0.0627 0.0621 0.0617 0.0615 0.0611 

[TRAIN] Epoch[1](496/114412); Loss: 0.068181; Backpropagation: 0.2926 sec; Batch: 2.0805 sec
0.1440 0.1066 0.0842 0.0755 0.0688 0.0640 0.0610 0.0584 0.0562 0.0552 0.0542 0.0534 0.0529 0.0524 0.0521 0.0519 

[TRAIN] Epoch[1](497/114412); Loss: 0.077847; Backpropagation: 0.2908 sec; Batch: 2.0780 sec
0.1181 0.0985 0.0917 0.0843 0.0796 0.0762 0.0742 0.0725 0.0714 0.0704 0.0695 0.0687 0.0682 0.0678 0.0674 0.0670 

[TRAIN] Epoch[1](498/114412); Loss: 0.042850; Backpropagation: 0.2932 sec; Batch: 2.0793 sec
0.0940 0.0621 0.0554 0.0470 0.0430 0.0397 0.0380 0.0365 0.0357 0.0349 0.0341 0.0337 0.0333 0.0330 0.0327 0.0325 

[TRAIN] Epoch[1](499/114412); Loss: 0.046021; Backpropagation: 0.2911 sec; Batch: 2.0768 sec
0.0962 0.0676 0.0585 0.0514 0.0464 0.0436 0.0414 0.0396 0.0382 0.0375 0.0369 0.0364 0.0360 0.0358 0.0355 0.0353 

[TRAIN] Epoch[1](500/114412); Loss: 0.088378; Backpropagation: 0.2950 sec; Batch: 2.0807 sec
0.1669 0.1496 0.1312 0.1065 0.0945 0.0884 0.0831 0.0761 0.0738 0.0681 0.0675 0.0676 0.0624 0.0601 0.0606 0.0578 

[TRAIN] Epoch[1](501/114412); Loss: 0.054416; Backpropagation: 0.2930 sec; Batch: 2.0807 sec
0.0927 0.0783 0.0686 0.0589 0.0549 0.0522 0.0507 0.0490 0.0478 0.0469 0.0462 0.0456 0.0452 0.0449 0.0446 0.0443 

[TRAIN] Epoch[1](502/114412); Loss: 0.058699; Backpropagation: 0.2929 sec; Batch: 2.0799 sec
0.0993 0.0840 0.0699 0.0621 0.0586 0.0561 0.0546 0.0532 0.0520 0.0512 0.0506 0.0501 0.0498 0.0494 0.0492 0.0491 

[TRAIN] Epoch[1](503/114412); Loss: 0.055438; Backpropagation: 0.2918 sec; Batch: 2.0847 sec
0.1124 0.0751 0.0689 0.0610 0.0569 0.0523 0.0498 0.0488 0.0475 0.0467 0.0457 0.0450 0.0447 0.0443 0.0440 0.0438 

[TRAIN] Epoch[1](504/114412); Loss: 0.039327; Backpropagation: 0.2914 sec; Batch: 2.0790 sec
0.0874 0.0691 0.0511 0.0439 0.0407 0.0374 0.0339 0.0322 0.0310 0.0303 0.0295 0.0291 0.0287 0.0285 0.0283 0.0281 

[TRAIN] Epoch[1](505/114412); Loss: 0.061187; Backpropagation: 0.2971 sec; Batch: 2.0855 sec
0.1079 0.0898 0.0771 0.0664 0.0629 0.0590 0.0566 0.0545 0.0529 0.0520 0.0512 0.0507 0.0501 0.0496 0.0493 0.0490 

[TRAIN] Epoch[1](506/114412); Loss: 0.052696; Backpropagation: 0.2940 sec; Batch: 2.0815 sec
0.1267 0.0925 0.0671 0.0588 0.0543 0.0486 0.0453 0.0429 0.0412 0.0403 0.0390 0.0383 0.0377 0.0372 0.0368 0.0365 

[TRAIN] Epoch[1](507/114412); Loss: 0.062526; Backpropagation: 0.2908 sec; Batch: 2.0778 sec
0.1500 0.1131 0.0908 0.0699 0.0563 0.0554 0.0526 0.0501 0.0486 0.0467 0.0460 0.0450 0.0444 0.0441 0.0438 0.0435 

[TRAIN] Epoch[1](508/114412); Loss: 0.066719; Backpropagation: 0.2915 sec; Batch: 2.0776 sec
0.1212 0.0945 0.0786 0.0728 0.0666 0.0638 0.0617 0.0594 0.0583 0.0574 0.0567 0.0562 0.0556 0.0552 0.0549 0.0545 

[TRAIN] Epoch[1](509/114412); Loss: 0.066795; Backpropagation: 0.2909 sec; Batch: 2.0769 sec
0.1471 0.1153 0.0963 0.0844 0.0658 0.0600 0.0577 0.0543 0.0523 0.0504 0.0492 0.0483 0.0476 0.0471 0.0466 0.0463 

[TRAIN] Epoch[1](510/114412); Loss: 0.062747; Backpropagation: 0.2931 sec; Batch: 2.0802 sec
0.1523 0.0859 0.0718 0.0638 0.0606 0.0580 0.0550 0.0534 0.0522 0.0516 0.0509 0.0503 0.0499 0.0497 0.0494 0.0492 

[TRAIN] Epoch[1](511/114412); Loss: 0.101521; Backpropagation: 0.2929 sec; Batch: 2.0809 sec
0.1570 0.1260 0.1175 0.1099 0.1046 0.1005 0.0968 0.0950 0.0931 0.0916 0.0904 0.0896 0.0888 0.0883 0.0878 0.0874 

[TRAIN] Epoch[1](512/114412); Loss: 0.052521; Backpropagation: 0.2951 sec; Batch: 2.0832 sec
0.1270 0.0754 0.0633 0.0555 0.0522 0.0477 0.0457 0.0437 0.0429 0.0421 0.0415 0.0411 0.0408 0.0406 0.0405 0.0403 

[TRAIN] Epoch[1](513/114412); Loss: 0.054433; Backpropagation: 0.2948 sec; Batch: 2.0820 sec
0.1157 0.0850 0.0672 0.0590 0.0555 0.0516 0.0486 0.0464 0.0450 0.0439 0.0432 0.0426 0.0422 0.0419 0.0416 0.0414 

[TRAIN] Epoch[1](514/114412); Loss: 0.072884; Backpropagation: 0.2954 sec; Batch: 2.0817 sec
0.1563 0.1073 0.0898 0.0779 0.0731 0.0681 0.0655 0.0627 0.0612 0.0599 0.0588 0.0581 0.0575 0.0570 0.0566 0.0563 

[TRAIN] Epoch[1](515/114412); Loss: 0.066638; Backpropagation: 0.2932 sec; Batch: 2.0812 sec
0.1415 0.1092 0.0868 0.0715 0.0647 0.0598 0.0577 0.0557 0.0541 0.0535 0.0528 0.0523 0.0519 0.0517 0.0516 0.0515 

[TRAIN] Epoch[1](516/114412); Loss: 0.047481; Backpropagation: 0.2909 sec; Batch: 2.0776 sec
0.1077 0.0839 0.0602 0.0519 0.0472 0.0426 0.0404 0.0387 0.0376 0.0369 0.0363 0.0358 0.0355 0.0353 0.0350 0.0347 

[TRAIN] Epoch[1](517/114412); Loss: 0.068531; Backpropagation: 0.2915 sec; Batch: 2.0874 sec
0.1146 0.1019 0.0811 0.0741 0.0701 0.0658 0.0629 0.0618 0.0603 0.0593 0.0586 0.0579 0.0576 0.0572 0.0568 0.0566 

[TRAIN] Epoch[1](518/114412); Loss: 0.055925; Backpropagation: 0.2911 sec; Batch: 2.0786 sec
0.1345 0.0960 0.0766 0.0638 0.0555 0.0513 0.0476 0.0449 0.0432 0.0420 0.0412 0.0405 0.0400 0.0396 0.0393 0.0390 

[TRAIN] Epoch[1](519/114412); Loss: 0.089682; Backpropagation: 0.2910 sec; Batch: 2.0789 sec
0.1448 0.1174 0.1067 0.0962 0.0904 0.0873 0.0840 0.0825 0.0806 0.0794 0.0788 0.0782 0.0777 0.0774 0.0771 0.0767 

[TRAIN] Epoch[1](520/114412); Loss: 0.084513; Backpropagation: 0.2929 sec; Batch: 2.0795 sec
0.1717 0.1137 0.0984 0.0901 0.0837 0.0789 0.0761 0.0745 0.0732 0.0718 0.0712 0.0706 0.0699 0.0696 0.0694 0.0692 

[TRAIN] Epoch[1](521/114412); Loss: 0.076806; Backpropagation: 0.2931 sec; Batch: 2.0805 sec
0.1719 0.1248 0.0978 0.0775 0.0724 0.0692 0.0657 0.0647 0.0635 0.0622 0.0611 0.0606 0.0601 0.0594 0.0591 0.0589 

[TRAIN] Epoch[1](522/114412); Loss: 0.067112; Backpropagation: 0.2928 sec; Batch: 2.0799 sec
0.1364 0.0902 0.0847 0.0713 0.0666 0.0629 0.0613 0.0594 0.0575 0.0564 0.0556 0.0550 0.0547 0.0542 0.0539 0.0537 

[TRAIN] Epoch[1](523/114412); Loss: 0.061816; Backpropagation: 0.2915 sec; Batch: 2.0779 sec
0.1280 0.0863 0.0787 0.0703 0.0631 0.0580 0.0554 0.0531 0.0518 0.0509 0.0500 0.0495 0.0490 0.0485 0.0483 0.0481 

[TRAIN] Epoch[1](524/114412); Loss: 0.042691; Backpropagation: 0.2932 sec; Batch: 2.0810 sec
0.1073 0.0618 0.0524 0.0467 0.0426 0.0393 0.0366 0.0352 0.0342 0.0335 0.0330 0.0325 0.0322 0.0320 0.0319 0.0318 

[TRAIN] Epoch[1](525/114412); Loss: 0.061359; Backpropagation: 0.2913 sec; Batch: 2.0831 sec
0.1274 0.0893 0.0791 0.0664 0.0626 0.0575 0.0554 0.0525 0.0512 0.0505 0.0496 0.0487 0.0483 0.0480 0.0477 0.0475 

[TRAIN] Epoch[1](526/114412); Loss: 0.048241; Backpropagation: 0.2904 sec; Batch: 2.0811 sec
0.1083 0.0743 0.0628 0.0551 0.0490 0.0447 0.0421 0.0399 0.0386 0.0377 0.0373 0.0369 0.0366 0.0363 0.0361 0.0362 

[TRAIN] Epoch[1](527/114412); Loss: 0.069292; Backpropagation: 0.2952 sec; Batch: 2.0886 sec
0.1499 0.1111 0.0937 0.0784 0.0700 0.0630 0.0598 0.0574 0.0559 0.0547 0.0538 0.0529 0.0524 0.0521 0.0519 0.0516 

[TRAIN] Epoch[1](528/114412); Loss: 0.053684; Backpropagation: 0.2928 sec; Batch: 2.0802 sec
0.1167 0.0803 0.0686 0.0580 0.0535 0.0483 0.0463 0.0457 0.0443 0.0436 0.0430 0.0425 0.0422 0.0421 0.0419 0.0420 

[TRAIN] Epoch[1](529/114412); Loss: 0.069132; Backpropagation: 0.2910 sec; Batch: 2.0877 sec
0.1235 0.0947 0.0833 0.0751 0.0713 0.0662 0.0639 0.0625 0.0608 0.0597 0.0589 0.0582 0.0575 0.0571 0.0569 0.0566 

[TRAIN] Epoch[1](530/114412); Loss: 0.079369; Backpropagation: 0.2911 sec; Batch: 2.0787 sec
0.1263 0.1065 0.0927 0.0866 0.0804 0.0773 0.0748 0.0733 0.0716 0.0705 0.0695 0.0689 0.0686 0.0680 0.0676 0.0673 

[TRAIN] Epoch[1](531/114412); Loss: 0.050584; Backpropagation: 0.2954 sec; Batch: 2.0827 sec
0.1177 0.0835 0.0680 0.0570 0.0508 0.0463 0.0438 0.0415 0.0402 0.0391 0.0382 0.0375 0.0371 0.0365 0.0363 0.0360 

[TRAIN] Epoch[1](532/114412); Loss: 0.060076; Backpropagation: 0.2930 sec; Batch: 2.0799 sec
0.1078 0.0851 0.0725 0.0659 0.0614 0.0572 0.0550 0.0540 0.0525 0.0515 0.0510 0.0503 0.0498 0.0495 0.0490 0.0488 

[TRAIN] Epoch[1](533/114412); Loss: 0.071514; Backpropagation: 0.2916 sec; Batch: 2.0776 sec
0.1517 0.1089 0.0869 0.0810 0.0727 0.0678 0.0659 0.0614 0.0594 0.0580 0.0568 0.0557 0.0552 0.0547 0.0542 0.0539 

[TRAIN] Epoch[1](534/114412); Loss: 0.071838; Backpropagation: 0.2954 sec; Batch: 2.0971 sec
0.1306 0.0993 0.0873 0.0764 0.0714 0.0681 0.0658 0.0645 0.0630 0.0621 0.0614 0.0607 0.0603 0.0598 0.0595 0.0592 

[TRAIN] Epoch[1](535/114412); Loss: 0.073257; Backpropagation: 0.2926 sec; Batch: 2.0806 sec
0.1244 0.0940 0.0857 0.0793 0.0742 0.0710 0.0686 0.0670 0.0658 0.0647 0.0642 0.0636 0.0629 0.0626 0.0623 0.0620 

[TRAIN] Epoch[1](536/114412); Loss: 0.082260; Backpropagation: 0.2912 sec; Batch: 2.0778 sec
0.1435 0.1033 0.0936 0.0867 0.0826 0.0798 0.0773 0.0755 0.0739 0.0727 0.0722 0.0717 0.0712 0.0709 0.0707 0.0705 

[TRAIN] Epoch[1](537/114412); Loss: 0.053368; Backpropagation: 0.2926 sec; Batch: 2.0800 sec
0.1216 0.0857 0.0703 0.0605 0.0538 0.0494 0.0473 0.0447 0.0428 0.0416 0.0406 0.0400 0.0396 0.0390 0.0386 0.0384 

[TRAIN] Epoch[1](538/114412); Loss: 0.073504; Backpropagation: 0.2913 sec; Batch: 2.0813 sec
0.1303 0.1002 0.0880 0.0794 0.0738 0.0702 0.0677 0.0659 0.0648 0.0639 0.0631 0.0626 0.0622 0.0616 0.0613 0.0610 

[TRAIN] Epoch[1](539/114412); Loss: 0.050276; Backpropagation: 0.2913 sec; Batch: 2.0785 sec
0.1065 0.0818 0.0660 0.0573 0.0518 0.0472 0.0443 0.0427 0.0408 0.0397 0.0390 0.0382 0.0378 0.0375 0.0372 0.0368 

[TRAIN] Epoch[1](540/114412); Loss: 0.050761; Backpropagation: 0.2907 sec; Batch: 2.0782 sec
0.1161 0.0740 0.0649 0.0569 0.0505 0.0465 0.0441 0.0428 0.0414 0.0407 0.0399 0.0395 0.0391 0.0388 0.0386 0.0384 

[TRAIN] Epoch[1](541/114412); Loss: 0.044649; Backpropagation: 0.2928 sec; Batch: 2.0965 sec
0.0963 0.0774 0.0621 0.0522 0.0456 0.0405 0.0384 0.0368 0.0351 0.0341 0.0336 0.0332 0.0327 0.0324 0.0322 0.0320 

[TRAIN] Epoch[1](542/114412); Loss: 0.062708; Backpropagation: 0.2912 sec; Batch: 2.0834 sec
0.1239 0.0924 0.0767 0.0666 0.0628 0.0592 0.0563 0.0548 0.0533 0.0525 0.0518 0.0512 0.0508 0.0505 0.0503 0.0502 

[TRAIN] Epoch[1](543/114412); Loss: 0.045841; Backpropagation: 0.2915 sec; Batch: 2.0774 sec
0.1316 0.0797 0.0567 0.0490 0.0436 0.0395 0.0371 0.0357 0.0346 0.0336 0.0330 0.0325 0.0321 0.0318 0.0316 0.0314 

[TRAIN] Epoch[1](544/114412); Loss: 0.075692; Backpropagation: 0.2911 sec; Batch: 2.1217 sec
0.1518 0.1068 0.0883 0.0796 0.0746 0.0704 0.0682 0.0665 0.0652 0.0641 0.0634 0.0631 0.0626 0.0623 0.0622 0.0621 

[TRAIN] Epoch[1](545/114412); Loss: 0.050961; Backpropagation: 0.2911 sec; Batch: 2.1214 sec
0.1052 0.0781 0.0654 0.0569 0.0504 0.0476 0.0452 0.0437 0.0427 0.0417 0.0409 0.0402 0.0397 0.0395 0.0392 0.0388 

[TRAIN] Epoch[1](546/114412); Loss: 0.066538; Backpropagation: 0.2913 sec; Batch: 2.1165 sec
0.1320 0.0960 0.0848 0.0705 0.0649 0.0616 0.0589 0.0575 0.0567 0.0556 0.0553 0.0549 0.0543 0.0541 0.0539 0.0537 

[TRAIN] Epoch[1](547/114412); Loss: 0.079111; Backpropagation: 0.2913 sec; Batch: 2.0777 sec
0.1403 0.1111 0.0940 0.0837 0.0797 0.0766 0.0735 0.0716 0.0702 0.0691 0.0679 0.0669 0.0661 0.0656 0.0651 0.0647 

[TRAIN] Epoch[1](548/114412); Loss: 0.053735; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1218 0.0837 0.0656 0.0587 0.0545 0.0497 0.0473 0.0453 0.0440 0.0430 0.0422 0.0417 0.0411 0.0407 0.0404 0.0401 

[TRAIN] Epoch[1](549/114412); Loss: 0.076633; Backpropagation: 0.2916 sec; Batch: 2.0820 sec
0.1490 0.1226 0.1008 0.0885 0.0792 0.0733 0.0698 0.0665 0.0641 0.0621 0.0606 0.0594 0.0585 0.0578 0.0573 0.0566 

[TRAIN] Epoch[1](550/114412); Loss: 0.059653; Backpropagation: 0.2908 sec; Batch: 2.0765 sec
0.1057 0.0855 0.0711 0.0656 0.0611 0.0578 0.0560 0.0538 0.0525 0.0515 0.0504 0.0497 0.0491 0.0486 0.0482 0.0479 

[TRAIN] Epoch[1](551/114412); Loss: 0.043764; Backpropagation: 0.2902 sec; Batch: 2.0766 sec
0.0861 0.0653 0.0541 0.0519 0.0455 0.0419 0.0397 0.0378 0.0365 0.0357 0.0352 0.0347 0.0343 0.0341 0.0338 0.0336 

[TRAIN] Epoch[1](552/114412); Loss: 0.060972; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1178 0.0881 0.0726 0.0640 0.0601 0.0566 0.0550 0.0536 0.0527 0.0520 0.0514 0.0510 0.0506 0.0503 0.0500 0.0498 

[TRAIN] Epoch[1](553/114412); Loss: 0.056256; Backpropagation: 0.2913 sec; Batch: 2.1255 sec
0.0981 0.0786 0.0695 0.0621 0.0568 0.0533 0.0521 0.0508 0.0494 0.0484 0.0478 0.0473 0.0468 0.0466 0.0464 0.0461 

[TRAIN] Epoch[1](554/114412); Loss: 0.060791; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.0920 0.0819 0.0762 0.0659 0.0621 0.0593 0.0568 0.0553 0.0544 0.0538 0.0533 0.0529 0.0526 0.0523 0.0520 0.0518 

[TRAIN] Epoch[1](555/114412); Loss: 0.037336; Backpropagation: 0.2914 sec; Batch: 2.1172 sec
0.0740 0.0677 0.0489 0.0428 0.0390 0.0347 0.0326 0.0313 0.0300 0.0293 0.0287 0.0282 0.0279 0.0276 0.0274 0.0273 

[TRAIN] Epoch[1](556/114412); Loss: 0.055259; Backpropagation: 0.2931 sec; Batch: 2.1159 sec
0.0946 0.0728 0.0656 0.0605 0.0555 0.0528 0.0513 0.0500 0.0492 0.0484 0.0480 0.0476 0.0473 0.0471 0.0468 0.0467 

[TRAIN] Epoch[1](557/114412); Loss: 0.073549; Backpropagation: 0.2912 sec; Batch: 2.1190 sec
0.1143 0.1014 0.0848 0.0802 0.0747 0.0709 0.0691 0.0678 0.0662 0.0654 0.0648 0.0641 0.0639 0.0634 0.0630 0.0628 

[TRAIN] Epoch[1](558/114412); Loss: 0.072254; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1467 0.1047 0.0895 0.0820 0.0740 0.0684 0.0658 0.0634 0.0610 0.0595 0.0586 0.0576 0.0569 0.0564 0.0559 0.0555 

[TRAIN] Epoch[1](559/114412); Loss: 0.054296; Backpropagation: 0.2926 sec; Batch: 2.1107 sec
0.1179 0.0831 0.0679 0.0604 0.0539 0.0499 0.0477 0.0467 0.0450 0.0440 0.0433 0.0426 0.0421 0.0417 0.0413 0.0411 

[TRAIN] Epoch[1](560/114412); Loss: 0.064775; Backpropagation: 0.2912 sec; Batch: 2.0780 sec
0.1274 0.1054 0.0894 0.0756 0.0682 0.0631 0.0584 0.0553 0.0530 0.0513 0.0502 0.0489 0.0483 0.0478 0.0472 0.0468 

[TRAIN] Epoch[1](561/114412); Loss: 0.066550; Backpropagation: 0.2952 sec; Batch: 2.1307 sec
0.1160 0.0949 0.0828 0.0744 0.0674 0.0641 0.0610 0.0594 0.0581 0.0570 0.0561 0.0556 0.0549 0.0547 0.0544 0.0540 

[TRAIN] Epoch[1](562/114412); Loss: 0.046699; Backpropagation: 0.2954 sec; Batch: 2.1041 sec
0.1053 0.0794 0.0612 0.0518 0.0449 0.0416 0.0397 0.0383 0.0372 0.0365 0.0359 0.0355 0.0352 0.0351 0.0349 0.0346 

[TRAIN] Epoch[1](563/114412); Loss: 0.044350; Backpropagation: 0.2904 sec; Batch: 2.0815 sec
0.0774 0.0634 0.0535 0.0483 0.0454 0.0436 0.0416 0.0399 0.0391 0.0383 0.0376 0.0371 0.0366 0.0362 0.0359 0.0357 

[TRAIN] Epoch[1](564/114412); Loss: 0.064763; Backpropagation: 0.2913 sec; Batch: 2.1200 sec
0.1306 0.1205 0.0966 0.0835 0.0693 0.0587 0.0546 0.0510 0.0489 0.0476 0.0467 0.0464 0.0460 0.0455 0.0453 0.0451 

[TRAIN] Epoch[1](565/114412); Loss: 0.077334; Backpropagation: 0.2911 sec; Batch: 2.0872 sec
0.1342 0.1148 0.0927 0.0848 0.0813 0.0769 0.0736 0.0703 0.0679 0.0664 0.0648 0.0635 0.0626 0.0618 0.0611 0.0605 

[TRAIN] Epoch[1](566/114412); Loss: 0.056078; Backpropagation: 0.2914 sec; Batch: 2.0778 sec
0.1094 0.0812 0.0696 0.0619 0.0575 0.0534 0.0520 0.0497 0.0484 0.0472 0.0460 0.0453 0.0446 0.0440 0.0436 0.0434 

[TRAIN] Epoch[1](567/114412); Loss: 0.036955; Backpropagation: 0.2914 sec; Batch: 2.1203 sec
0.0773 0.0557 0.0437 0.0407 0.0371 0.0345 0.0329 0.0317 0.0311 0.0304 0.0301 0.0297 0.0294 0.0292 0.0290 0.0289 

[TRAIN] Epoch[1](568/114412); Loss: 0.068223; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.1301 0.1006 0.0871 0.0765 0.0705 0.0647 0.0618 0.0594 0.0578 0.0567 0.0558 0.0551 0.0545 0.0540 0.0536 0.0533 

[TRAIN] Epoch[1](569/114412); Loss: 0.047959; Backpropagation: 0.2910 sec; Batch: 2.1199 sec
0.0926 0.0731 0.0605 0.0524 0.0490 0.0449 0.0429 0.0418 0.0402 0.0395 0.0391 0.0385 0.0384 0.0382 0.0380 0.0380 

[TRAIN] Epoch[1](570/114412); Loss: 0.043135; Backpropagation: 0.2910 sec; Batch: 2.1325 sec
0.1014 0.0716 0.0601 0.0491 0.0434 0.0392 0.0371 0.0355 0.0338 0.0327 0.0320 0.0315 0.0311 0.0308 0.0305 0.0303 

[TRAIN] Epoch[1](571/114412); Loss: 0.073539; Backpropagation: 0.2915 sec; Batch: 2.1261 sec
0.1329 0.1054 0.0893 0.0795 0.0741 0.0705 0.0680 0.0657 0.0643 0.0630 0.0620 0.0614 0.0608 0.0603 0.0599 0.0594 

[TRAIN] Epoch[1](572/114412); Loss: 0.072374; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1125 0.0952 0.0849 0.0782 0.0738 0.0704 0.0683 0.0666 0.0657 0.0649 0.0642 0.0637 0.0631 0.0625 0.0622 0.0618 

[TRAIN] Epoch[1](573/114412); Loss: 0.071771; Backpropagation: 0.2912 sec; Batch: 2.3820 sec
0.1239 0.0917 0.0812 0.0740 0.0707 0.0688 0.0670 0.0655 0.0646 0.0641 0.0635 0.0632 0.0628 0.0626 0.0625 0.0623 

[TRAIN] Epoch[1](574/114412); Loss: 0.050269; Backpropagation: 0.2913 sec; Batch: 2.1198 sec
0.1037 0.0788 0.0679 0.0593 0.0523 0.0471 0.0444 0.0427 0.0407 0.0398 0.0390 0.0383 0.0380 0.0376 0.0374 0.0372 

[TRAIN] Epoch[1](575/114412); Loss: 0.070505; Backpropagation: 0.2929 sec; Batch: 2.2632 sec
0.1134 0.0983 0.0853 0.0767 0.0720 0.0686 0.0662 0.0645 0.0630 0.0620 0.0613 0.0603 0.0597 0.0594 0.0588 0.0584 

[TRAIN] Epoch[1](576/114412); Loss: 0.030657; Backpropagation: 0.2921 sec; Batch: 2.0968 sec
0.0630 0.0547 0.0436 0.0375 0.0311 0.0269 0.0256 0.0247 0.0240 0.0235 0.0230 0.0228 0.0227 0.0225 0.0224 0.0224 

[TRAIN] Epoch[1](577/114412); Loss: 0.053219; Backpropagation: 0.2914 sec; Batch: 2.1212 sec
0.0919 0.0744 0.0664 0.0582 0.0540 0.0515 0.0494 0.0476 0.0466 0.0458 0.0452 0.0448 0.0444 0.0441 0.0438 0.0436 

[TRAIN] Epoch[1](578/114412); Loss: 0.068477; Backpropagation: 0.2921 sec; Batch: 2.1207 sec
0.1119 0.0930 0.0818 0.0742 0.0689 0.0660 0.0641 0.0626 0.0613 0.0604 0.0597 0.0591 0.0587 0.0583 0.0579 0.0576 

[TRAIN] Epoch[1](579/114412); Loss: 0.066389; Backpropagation: 0.2997 sec; Batch: 2.4218 sec
0.1264 0.0950 0.0827 0.0745 0.0673 0.0648 0.0611 0.0588 0.0571 0.0558 0.0545 0.0539 0.0532 0.0527 0.0524 0.0520 

[TRAIN] Epoch[1](580/114412); Loss: 0.076907; Backpropagation: 0.2939 sec; Batch: 2.4043 sec
0.1498 0.1231 0.1004 0.0886 0.0784 0.0716 0.0684 0.0657 0.0639 0.0621 0.0611 0.0604 0.0599 0.0593 0.0589 0.0587 

[TRAIN] Epoch[1](581/114412); Loss: 0.061428; Backpropagation: 0.2935 sec; Batch: 2.1186 sec
0.1130 0.0941 0.0797 0.0696 0.0631 0.0587 0.0556 0.0534 0.0520 0.0509 0.0499 0.0495 0.0489 0.0484 0.0481 0.0478 

[TRAIN] Epoch[1](582/114412); Loss: 0.057919; Backpropagation: 0.2927 sec; Batch: 2.1194 sec
0.0958 0.0850 0.0722 0.0667 0.0598 0.0558 0.0528 0.0514 0.0503 0.0496 0.0490 0.0485 0.0480 0.0476 0.0473 0.0470 

[TRAIN] Epoch[1](583/114412); Loss: 0.069428; Backpropagation: 0.2911 sec; Batch: 2.1159 sec
0.1200 0.1010 0.0860 0.0772 0.0710 0.0672 0.0637 0.0620 0.0606 0.0594 0.0585 0.0577 0.0572 0.0568 0.0564 0.0561 

[TRAIN] Epoch[1](584/114412); Loss: 0.051277; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.0969 0.0806 0.0648 0.0576 0.0514 0.0479 0.0466 0.0447 0.0435 0.0426 0.0417 0.0411 0.0406 0.0403 0.0401 0.0399 

[TRAIN] Epoch[1](585/114412); Loss: 0.070949; Backpropagation: 0.2911 sec; Batch: 2.1129 sec
0.1061 0.0934 0.0821 0.0764 0.0720 0.0695 0.0675 0.0660 0.0649 0.0641 0.0634 0.0627 0.0622 0.0619 0.0617 0.0614 

[TRAIN] Epoch[1](586/114412); Loss: 0.094622; Backpropagation: 0.2916 sec; Batch: 2.1202 sec
0.1593 0.1364 0.1185 0.1048 0.0952 0.0888 0.0863 0.0847 0.0831 0.0813 0.0807 0.0800 0.0793 0.0789 0.0785 0.0782 

[TRAIN] Epoch[1](587/114412); Loss: 0.065099; Backpropagation: 0.2912 sec; Batch: 2.1136 sec
0.1275 0.0990 0.0797 0.0732 0.0641 0.0609 0.0593 0.0568 0.0551 0.0541 0.0532 0.0526 0.0520 0.0516 0.0513 0.0510 

[TRAIN] Epoch[1](588/114412); Loss: 0.041279; Backpropagation: 0.2913 sec; Batch: 2.1280 sec
0.0704 0.0562 0.0498 0.0471 0.0416 0.0395 0.0383 0.0370 0.0363 0.0358 0.0354 0.0350 0.0348 0.0346 0.0344 0.0343 

[TRAIN] Epoch[1](589/114412); Loss: 0.046749; Backpropagation: 0.2912 sec; Batch: 2.1333 sec
0.0880 0.0690 0.0591 0.0541 0.0483 0.0439 0.0418 0.0402 0.0395 0.0386 0.0382 0.0379 0.0376 0.0374 0.0373 0.0372 

[TRAIN] Epoch[1](590/114412); Loss: 0.060074; Backpropagation: 0.2911 sec; Batch: 2.1227 sec
0.0975 0.0820 0.0698 0.0633 0.0601 0.0582 0.0562 0.0549 0.0539 0.0534 0.0529 0.0525 0.0520 0.0517 0.0514 0.0512 

[TRAIN] Epoch[1](591/114412); Loss: 0.043404; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.0944 0.0756 0.0588 0.0494 0.0430 0.0396 0.0374 0.0355 0.0346 0.0337 0.0329 0.0325 0.0322 0.0319 0.0316 0.0314 

[TRAIN] Epoch[1](592/114412); Loss: 0.057114; Backpropagation: 0.2908 sec; Batch: 2.1577 sec
0.0996 0.0853 0.0724 0.0639 0.0592 0.0551 0.0524 0.0505 0.0490 0.0483 0.0476 0.0469 0.0465 0.0461 0.0457 0.0454 

[TRAIN] Epoch[1](593/114412); Loss: 0.046314; Backpropagation: 0.2910 sec; Batch: 2.1284 sec
0.0872 0.0684 0.0527 0.0479 0.0453 0.0430 0.0417 0.0409 0.0403 0.0397 0.0394 0.0391 0.0389 0.0388 0.0388 0.0388 

[TRAIN] Epoch[1](594/114412); Loss: 0.051251; Backpropagation: 0.2914 sec; Batch: 2.0774 sec
0.0801 0.0755 0.0627 0.0590 0.0542 0.0498 0.0479 0.0468 0.0454 0.0442 0.0434 0.0426 0.0424 0.0421 0.0420 0.0420 

[TRAIN] Epoch[1](595/114412); Loss: 0.060421; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.0958 0.0823 0.0734 0.0661 0.0626 0.0598 0.0563 0.0556 0.0542 0.0530 0.0526 0.0518 0.0512 0.0509 0.0506 0.0505 

[TRAIN] Epoch[1](596/114412); Loss: 0.043124; Backpropagation: 0.2933 sec; Batch: 2.0837 sec
0.0926 0.0699 0.0572 0.0485 0.0422 0.0400 0.0378 0.0358 0.0351 0.0344 0.0337 0.0332 0.0328 0.0325 0.0322 0.0320 

[TRAIN] Epoch[1](597/114412); Loss: 0.052473; Backpropagation: 0.2918 sec; Batch: 2.0989 sec
0.0926 0.0761 0.0685 0.0559 0.0525 0.0497 0.0478 0.0463 0.0455 0.0449 0.0441 0.0437 0.0434 0.0432 0.0429 0.0427 

[TRAIN] Epoch[1](598/114412); Loss: 0.041524; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.0793 0.0620 0.0499 0.0443 0.0418 0.0393 0.0378 0.0366 0.0356 0.0349 0.0345 0.0341 0.0338 0.0336 0.0335 0.0333 

[TRAIN] Epoch[1](599/114412); Loss: 0.083337; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1180 0.1068 0.0949 0.0882 0.0838 0.0811 0.0791 0.0779 0.0770 0.0762 0.0758 0.0755 0.0751 0.0748 0.0746 0.0744 

[TRAIN] Epoch[1](600/114412); Loss: 0.081499; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1249 0.1080 0.0965 0.0885 0.0836 0.0802 0.0774 0.0756 0.0741 0.0730 0.0719 0.0712 0.0705 0.0701 0.0695 0.0692 

[TRAIN] Epoch[1](601/114412); Loss: 0.074848; Backpropagation: 0.2930 sec; Batch: 2.1211 sec
0.1607 0.1319 0.1079 0.0900 0.0769 0.0697 0.0657 0.0624 0.0594 0.0567 0.0551 0.0540 0.0530 0.0518 0.0513 0.0510 

[TRAIN] Epoch[1](602/114412); Loss: 0.039771; Backpropagation: 0.2912 sec; Batch: 2.1196 sec
0.0938 0.0631 0.0475 0.0421 0.0381 0.0360 0.0343 0.0333 0.0326 0.0319 0.0314 0.0310 0.0306 0.0304 0.0302 0.0300 

[TRAIN] Epoch[1](603/114412); Loss: 0.044780; Backpropagation: 0.2907 sec; Batch: 2.0762 sec
0.0760 0.0666 0.0516 0.0483 0.0451 0.0427 0.0415 0.0402 0.0393 0.0389 0.0384 0.0380 0.0378 0.0375 0.0374 0.0374 

[TRAIN] Epoch[1](604/114412); Loss: 0.057280; Backpropagation: 0.2915 sec; Batch: 2.1178 sec
0.1072 0.0865 0.0729 0.0638 0.0584 0.0547 0.0514 0.0495 0.0483 0.0475 0.0470 0.0465 0.0461 0.0458 0.0456 0.0453 

[TRAIN] Epoch[1](605/114412); Loss: 0.066102; Backpropagation: 0.2913 sec; Batch: 2.1167 sec
0.1289 0.0906 0.0783 0.0702 0.0653 0.0625 0.0605 0.0590 0.0577 0.0566 0.0559 0.0553 0.0547 0.0544 0.0540 0.0538 

[TRAIN] Epoch[1](606/114412); Loss: 0.051872; Backpropagation: 0.2910 sec; Batch: 2.1096 sec
0.1165 0.0744 0.0593 0.0538 0.0497 0.0471 0.0457 0.0447 0.0440 0.0432 0.0427 0.0423 0.0420 0.0418 0.0416 0.0413 

[TRAIN] Epoch[1](607/114412); Loss: 0.086041; Backpropagation: 0.2917 sec; Batch: 2.1133 sec
0.1384 0.1136 0.0991 0.0909 0.0872 0.0834 0.0811 0.0793 0.0780 0.0770 0.0762 0.0755 0.0749 0.0744 0.0740 0.0735 

[TRAIN] Epoch[1](608/114412); Loss: 0.048709; Backpropagation: 0.2913 sec; Batch: 2.1146 sec
0.0872 0.0820 0.0647 0.0529 0.0472 0.0446 0.0432 0.0419 0.0408 0.0403 0.0397 0.0394 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[1](609/114412); Loss: 0.066636; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1098 0.0906 0.0794 0.0730 0.0678 0.0648 0.0621 0.0606 0.0593 0.0583 0.0576 0.0571 0.0567 0.0565 0.0563 0.0561 

[TRAIN] Epoch[1](610/114412); Loss: 0.065884; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1393 0.1055 0.0869 0.0718 0.0647 0.0618 0.0586 0.0569 0.0547 0.0530 0.0520 0.0511 0.0503 0.0496 0.0492 0.0487 

[TRAIN] Epoch[1](611/114412); Loss: 0.058771; Backpropagation: 0.2912 sec; Batch: 2.1189 sec
0.1070 0.0894 0.0732 0.0644 0.0587 0.0553 0.0530 0.0515 0.0502 0.0496 0.0490 0.0483 0.0480 0.0478 0.0476 0.0473 

[TRAIN] Epoch[1](612/114412); Loss: 0.068703; Backpropagation: 0.2911 sec; Batch: 2.1160 sec
0.1073 0.0880 0.0794 0.0741 0.0696 0.0667 0.0649 0.0636 0.0623 0.0617 0.0613 0.0606 0.0602 0.0600 0.0598 0.0596 

[TRAIN] Epoch[1](613/114412); Loss: 0.057263; Backpropagation: 0.2944 sec; Batch: 2.1215 sec
0.0958 0.0781 0.0676 0.0618 0.0588 0.0554 0.0537 0.0523 0.0511 0.0503 0.0496 0.0491 0.0487 0.0483 0.0479 0.0476 

[TRAIN] Epoch[1](614/114412); Loss: 0.043155; Backpropagation: 0.2921 sec; Batch: 2.0997 sec
0.1174 0.0788 0.0555 0.0469 0.0413 0.0367 0.0348 0.0334 0.0321 0.0316 0.0311 0.0306 0.0304 0.0301 0.0299 0.0298 

[TRAIN] Epoch[1](615/114412); Loss: 0.057637; Backpropagation: 0.2932 sec; Batch: 2.1180 sec
0.1050 0.0819 0.0701 0.0631 0.0586 0.0558 0.0534 0.0517 0.0504 0.0492 0.0484 0.0478 0.0472 0.0469 0.0465 0.0462 

[TRAIN] Epoch[1](616/114412); Loss: 0.044424; Backpropagation: 0.2919 sec; Batch: 2.1156 sec
0.0871 0.0710 0.0600 0.0507 0.0440 0.0415 0.0396 0.0378 0.0365 0.0357 0.0352 0.0348 0.0345 0.0343 0.0340 0.0339 

[TRAIN] Epoch[1](617/114412); Loss: 0.088510; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1476 0.1274 0.1089 0.0983 0.0913 0.0861 0.0824 0.0796 0.0778 0.0763 0.0752 0.0742 0.0735 0.0730 0.0725 0.0721 

[TRAIN] Epoch[1](618/114412); Loss: 0.062296; Backpropagation: 0.2913 sec; Batch: 2.1205 sec
0.1222 0.1017 0.0813 0.0683 0.0624 0.0587 0.0553 0.0532 0.0519 0.0506 0.0498 0.0492 0.0486 0.0481 0.0478 0.0476 

[TRAIN] Epoch[1](619/114412); Loss: 0.056265; Backpropagation: 0.2913 sec; Batch: 2.1142 sec
0.1143 0.0895 0.0701 0.0609 0.0558 0.0518 0.0497 0.0485 0.0471 0.0461 0.0455 0.0449 0.0444 0.0441 0.0438 0.0436 

[TRAIN] Epoch[1](620/114412); Loss: 0.052946; Backpropagation: 0.2914 sec; Batch: 2.1180 sec
0.1027 0.0859 0.0687 0.0601 0.0550 0.0500 0.0473 0.0454 0.0441 0.0430 0.0421 0.0415 0.0409 0.0405 0.0402 0.0398 

[TRAIN] Epoch[1](621/114412); Loss: 0.054484; Backpropagation: 0.2908 sec; Batch: 2.0777 sec
0.0870 0.0747 0.0668 0.0609 0.0552 0.0528 0.0508 0.0493 0.0485 0.0476 0.0470 0.0467 0.0464 0.0462 0.0460 0.0458 

[TRAIN] Epoch[1](622/114412); Loss: 0.047875; Backpropagation: 0.2908 sec; Batch: 2.0969 sec
0.0840 0.0678 0.0582 0.0531 0.0486 0.0462 0.0443 0.0429 0.0419 0.0413 0.0404 0.0400 0.0397 0.0394 0.0391 0.0390 

[TRAIN] Epoch[1](623/114412); Loss: 0.067384; Backpropagation: 0.2935 sec; Batch: 2.1265 sec
0.1003 0.0889 0.0831 0.0717 0.0686 0.0665 0.0627 0.0618 0.0609 0.0602 0.0598 0.0593 0.0590 0.0587 0.0585 0.0583 

[TRAIN] Epoch[1](624/114412); Loss: 0.040756; Backpropagation: 0.2929 sec; Batch: 2.1182 sec
0.0821 0.0774 0.0581 0.0482 0.0397 0.0374 0.0348 0.0332 0.0321 0.0312 0.0305 0.0301 0.0297 0.0294 0.0292 0.0290 

[TRAIN] Epoch[1](625/114412); Loss: 0.038830; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.0763 0.0585 0.0471 0.0425 0.0390 0.0372 0.0352 0.0341 0.0333 0.0324 0.0319 0.0314 0.0310 0.0307 0.0305 0.0303 

[TRAIN] Epoch[1](626/114412); Loss: 0.056634; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1035 0.0840 0.0690 0.0604 0.0562 0.0524 0.0510 0.0497 0.0488 0.0483 0.0479 0.0475 0.0472 0.0469 0.0467 0.0466 

[TRAIN] Epoch[1](627/114412); Loss: 0.072084; Backpropagation: 0.2913 sec; Batch: 2.1163 sec
0.1221 0.1028 0.0836 0.0770 0.0722 0.0689 0.0666 0.0653 0.0642 0.0632 0.0625 0.0618 0.0614 0.0608 0.0606 0.0603 

[TRAIN] Epoch[1](628/114412); Loss: 0.051853; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.0993 0.0757 0.0614 0.0556 0.0516 0.0485 0.0466 0.0451 0.0442 0.0438 0.0434 0.0431 0.0430 0.0428 0.0427 0.0428 

[TRAIN] Epoch[1](629/114412); Loss: 0.057033; Backpropagation: 0.2907 sec; Batch: 2.1054 sec
0.0983 0.0835 0.0706 0.0631 0.0573 0.0548 0.0523 0.0508 0.0498 0.0489 0.0482 0.0477 0.0473 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](630/114412); Loss: 0.065153; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1400 0.1105 0.0872 0.0774 0.0663 0.0598 0.0581 0.0539 0.0518 0.0505 0.0493 0.0487 0.0479 0.0474 0.0470 0.0467 

[TRAIN] Epoch[1](631/114412); Loss: 0.059378; Backpropagation: 0.2911 sec; Batch: 2.1190 sec
0.1117 0.0834 0.0696 0.0640 0.0596 0.0564 0.0544 0.0529 0.0518 0.0509 0.0503 0.0497 0.0493 0.0490 0.0486 0.0483 

[TRAIN] Epoch[1](632/114412); Loss: 0.075298; Backpropagation: 0.2908 sec; Batch: 2.1169 sec
0.1327 0.0991 0.0886 0.0835 0.0768 0.0725 0.0704 0.0683 0.0670 0.0659 0.0649 0.0641 0.0635 0.0630 0.0625 0.0622 

[TRAIN] Epoch[1](633/114412); Loss: 0.057726; Backpropagation: 0.2930 sec; Batch: 2.1199 sec
0.1083 0.0793 0.0702 0.0630 0.0581 0.0549 0.0526 0.0511 0.0503 0.0494 0.0488 0.0483 0.0479 0.0474 0.0472 0.0468 

[TRAIN] Epoch[1](634/114412); Loss: 0.055949; Backpropagation: 0.2930 sec; Batch: 2.1219 sec
0.0938 0.0769 0.0684 0.0595 0.0559 0.0538 0.0520 0.0506 0.0496 0.0488 0.0484 0.0480 0.0476 0.0475 0.0473 0.0471 

[TRAIN] Epoch[1](635/114412); Loss: 0.071935; Backpropagation: 0.2916 sec; Batch: 2.0802 sec
0.1385 0.1149 0.0929 0.0804 0.0733 0.0682 0.0635 0.0613 0.0598 0.0586 0.0580 0.0572 0.0567 0.0563 0.0559 0.0555 

[TRAIN] Epoch[1](636/114412); Loss: 0.058628; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.0968 0.0790 0.0722 0.0633 0.0591 0.0563 0.0546 0.0533 0.0524 0.0516 0.0510 0.0504 0.0501 0.0497 0.0494 0.0491 

[TRAIN] Epoch[1](637/114412); Loss: 0.076507; Backpropagation: 0.2927 sec; Batch: 2.1193 sec
0.1284 0.1100 0.0918 0.0816 0.0766 0.0733 0.0709 0.0689 0.0676 0.0668 0.0660 0.0654 0.0649 0.0643 0.0640 0.0637 

[TRAIN] Epoch[1](638/114412); Loss: 0.053416; Backpropagation: 0.2914 sec; Batch: 2.1194 sec
0.1148 0.0899 0.0707 0.0637 0.0569 0.0518 0.0486 0.0449 0.0432 0.0414 0.0400 0.0390 0.0383 0.0376 0.0372 0.0369 

[TRAIN] Epoch[1](639/114412); Loss: 0.041273; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.0933 0.0701 0.0533 0.0458 0.0415 0.0378 0.0354 0.0341 0.0330 0.0320 0.0315 0.0310 0.0308 0.0304 0.0302 0.0301 

[TRAIN] Epoch[1](640/114412); Loss: 0.063139; Backpropagation: 0.2941 sec; Batch: 2.1216 sec
0.1133 0.0911 0.0765 0.0694 0.0636 0.0599 0.0576 0.0557 0.0546 0.0538 0.0533 0.0529 0.0526 0.0523 0.0519 0.0516 

[TRAIN] Epoch[1](641/114412); Loss: 0.066753; Backpropagation: 0.2942 sec; Batch: 2.1177 sec
0.1171 0.0920 0.0804 0.0730 0.0666 0.0640 0.0615 0.0600 0.0589 0.0579 0.0572 0.0566 0.0562 0.0559 0.0555 0.0553 

[TRAIN] Epoch[1](642/114412); Loss: 0.053484; Backpropagation: 0.2911 sec; Batch: 2.1148 sec
0.0956 0.0793 0.0682 0.0587 0.0535 0.0509 0.0486 0.0470 0.0461 0.0453 0.0447 0.0443 0.0439 0.0435 0.0432 0.0430 

[TRAIN] Epoch[1](643/114412); Loss: 0.054026; Backpropagation: 0.2917 sec; Batch: 2.1170 sec
0.1115 0.0857 0.0698 0.0580 0.0539 0.0500 0.0474 0.0458 0.0447 0.0440 0.0432 0.0428 0.0424 0.0420 0.0418 0.0415 

[TRAIN] Epoch[1](644/114412); Loss: 0.067089; Backpropagation: 0.2930 sec; Batch: 2.1194 sec
0.1178 0.0892 0.0771 0.0719 0.0671 0.0638 0.0624 0.0610 0.0598 0.0591 0.0585 0.0578 0.0575 0.0570 0.0567 0.0566 

[TRAIN] Epoch[1](645/114412); Loss: 0.065846; Backpropagation: 0.2913 sec; Batch: 2.1197 sec
0.1282 0.0968 0.0819 0.0727 0.0644 0.0613 0.0592 0.0577 0.0562 0.0551 0.0543 0.0538 0.0534 0.0531 0.0529 0.0526 

[TRAIN] Epoch[1](646/114412); Loss: 0.068458; Backpropagation: 0.2906 sec; Batch: 2.1167 sec
0.1207 0.1024 0.0875 0.0756 0.0707 0.0652 0.0624 0.0605 0.0585 0.0578 0.0568 0.0561 0.0557 0.0553 0.0551 0.0549 

[TRAIN] Epoch[1](647/114412); Loss: 0.046489; Backpropagation: 0.2910 sec; Batch: 2.1143 sec
0.0886 0.0729 0.0641 0.0530 0.0478 0.0439 0.0415 0.0396 0.0384 0.0376 0.0370 0.0366 0.0361 0.0358 0.0356 0.0354 

[TRAIN] Epoch[1](648/114412); Loss: 0.077617; Backpropagation: 0.2915 sec; Batch: 2.0846 sec
0.1351 0.1024 0.0917 0.0840 0.0774 0.0748 0.0719 0.0704 0.0691 0.0679 0.0674 0.0667 0.0662 0.0659 0.0656 0.0654 

[TRAIN] Epoch[1](649/114412); Loss: 0.061061; Backpropagation: 0.2952 sec; Batch: 2.0827 sec
0.1161 0.0872 0.0752 0.0682 0.0616 0.0581 0.0557 0.0537 0.0525 0.0515 0.0507 0.0500 0.0496 0.0493 0.0490 0.0487 

[TRAIN] Epoch[1](650/114412); Loss: 0.048144; Backpropagation: 0.2903 sec; Batch: 2.1164 sec
0.1064 0.0745 0.0597 0.0520 0.0485 0.0443 0.0427 0.0411 0.0395 0.0387 0.0380 0.0376 0.0372 0.0369 0.0367 0.0365 

[TRAIN] Epoch[1](651/114412); Loss: 0.069746; Backpropagation: 0.2915 sec; Batch: 2.1306 sec
0.1371 0.1027 0.0848 0.0757 0.0706 0.0673 0.0630 0.0611 0.0594 0.0582 0.0574 0.0567 0.0561 0.0556 0.0553 0.0550 

[TRAIN] Epoch[1](652/114412); Loss: 0.079319; Backpropagation: 0.2929 sec; Batch: 2.1192 sec
0.1356 0.1133 0.1003 0.0878 0.0815 0.0771 0.0734 0.0712 0.0695 0.0682 0.0670 0.0662 0.0653 0.0648 0.0642 0.0637 

[TRAIN] Epoch[1](653/114412); Loss: 0.060235; Backpropagation: 0.2910 sec; Batch: 2.1197 sec
0.1103 0.0845 0.0740 0.0676 0.0616 0.0587 0.0552 0.0537 0.0523 0.0512 0.0504 0.0496 0.0493 0.0488 0.0485 0.0482 

[TRAIN] Epoch[1](654/114412); Loss: 0.068570; Backpropagation: 0.2952 sec; Batch: 2.1329 sec
0.1327 0.1034 0.0893 0.0799 0.0690 0.0656 0.0616 0.0594 0.0577 0.0564 0.0554 0.0545 0.0538 0.0533 0.0528 0.0524 

[TRAIN] Epoch[1](655/114412); Loss: 0.064953; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1133 0.0956 0.0797 0.0717 0.0656 0.0615 0.0592 0.0576 0.0563 0.0553 0.0548 0.0543 0.0540 0.0536 0.0534 0.0532 

[TRAIN] Epoch[1](656/114412); Loss: 0.073021; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1342 0.1052 0.0884 0.0795 0.0743 0.0695 0.0669 0.0648 0.0634 0.0623 0.0615 0.0606 0.0601 0.0596 0.0592 0.0589 

[TRAIN] Epoch[1](657/114412); Loss: 0.085056; Backpropagation: 0.2912 sec; Batch: 2.1231 sec
0.1501 0.1310 0.1081 0.0964 0.0881 0.0829 0.0791 0.0761 0.0736 0.0715 0.0700 0.0684 0.0675 0.0668 0.0661 0.0653 

[TRAIN] Epoch[1](658/114412); Loss: 0.042754; Backpropagation: 0.2928 sec; Batch: 2.0828 sec
0.0865 0.0710 0.0572 0.0484 0.0430 0.0397 0.0378 0.0365 0.0350 0.0341 0.0336 0.0329 0.0324 0.0322 0.0320 0.0318 

[TRAIN] Epoch[1](659/114412); Loss: 0.064646; Backpropagation: 0.2916 sec; Batch: 2.1189 sec
0.1243 0.1053 0.0810 0.0749 0.0686 0.0623 0.0595 0.0563 0.0534 0.0522 0.0515 0.0503 0.0494 0.0489 0.0484 0.0481 

[TRAIN] Epoch[1](660/114412); Loss: 0.055843; Backpropagation: 0.2915 sec; Batch: 2.0789 sec
0.1073 0.0839 0.0695 0.0616 0.0576 0.0538 0.0511 0.0491 0.0476 0.0469 0.0454 0.0448 0.0444 0.0438 0.0436 0.0431 

[TRAIN] Epoch[1](661/114412); Loss: 0.064913; Backpropagation: 0.2916 sec; Batch: 2.0814 sec
0.1140 0.1048 0.0789 0.0688 0.0656 0.0621 0.0592 0.0576 0.0559 0.0549 0.0539 0.0533 0.0528 0.0525 0.0523 0.0520 

[TRAIN] Epoch[1](662/114412); Loss: 0.057986; Backpropagation: 0.2930 sec; Batch: 2.0801 sec
0.1073 0.0865 0.0755 0.0636 0.0590 0.0550 0.0523 0.0507 0.0494 0.0485 0.0476 0.0471 0.0467 0.0463 0.0461 0.0461 

[TRAIN] Epoch[1](663/114412); Loss: 0.055775; Backpropagation: 0.2909 sec; Batch: 2.1204 sec
0.1082 0.0822 0.0705 0.0630 0.0570 0.0535 0.0505 0.0488 0.0474 0.0463 0.0455 0.0447 0.0443 0.0439 0.0435 0.0432 

[TRAIN] Epoch[1](664/114412); Loss: 0.053087; Backpropagation: 0.2907 sec; Batch: 2.1025 sec
0.1035 0.0780 0.0713 0.0612 0.0547 0.0512 0.0472 0.0459 0.0446 0.0433 0.0425 0.0420 0.0415 0.0412 0.0408 0.0405 

[TRAIN] Epoch[1](665/114412); Loss: 0.063737; Backpropagation: 0.2922 sec; Batch: 2.1208 sec
0.1162 0.1032 0.0839 0.0755 0.0668 0.0623 0.0581 0.0547 0.0535 0.0515 0.0505 0.0497 0.0490 0.0486 0.0483 0.0480 

[TRAIN] Epoch[1](666/114412); Loss: 0.052945; Backpropagation: 0.2932 sec; Batch: 2.1201 sec
0.1080 0.0787 0.0690 0.0612 0.0550 0.0514 0.0477 0.0455 0.0440 0.0428 0.0417 0.0412 0.0407 0.0404 0.0401 0.0398 

[TRAIN] Epoch[1](667/114412); Loss: 0.065944; Backpropagation: 0.2952 sec; Batch: 2.1231 sec
0.1121 0.0909 0.0770 0.0699 0.0659 0.0631 0.0617 0.0600 0.0587 0.0579 0.0572 0.0568 0.0564 0.0560 0.0558 0.0556 

[TRAIN] Epoch[1](668/114412); Loss: 0.076843; Backpropagation: 0.2929 sec; Batch: 2.1188 sec
0.1322 0.1090 0.0936 0.0878 0.0799 0.0758 0.0721 0.0693 0.0672 0.0658 0.0647 0.0638 0.0630 0.0622 0.0618 0.0613 

[TRAIN] Epoch[1](669/114412); Loss: 0.078217; Backpropagation: 0.2912 sec; Batch: 2.1203 sec
0.1310 0.1115 0.0940 0.0857 0.0803 0.0757 0.0725 0.0706 0.0689 0.0679 0.0670 0.0663 0.0657 0.0651 0.0648 0.0645 

[TRAIN] Epoch[1](670/114412); Loss: 0.065740; Backpropagation: 0.2908 sec; Batch: 2.1209 sec
0.1161 0.1002 0.0841 0.0733 0.0683 0.0636 0.0610 0.0577 0.0563 0.0552 0.0540 0.0534 0.0529 0.0523 0.0519 0.0517 

[TRAIN] Epoch[1](671/114412); Loss: 0.082259; Backpropagation: 0.2928 sec; Batch: 2.1233 sec
0.1371 0.1091 0.0970 0.0883 0.0837 0.0801 0.0779 0.0758 0.0742 0.0728 0.0718 0.0710 0.0703 0.0696 0.0690 0.0686 

[TRAIN] Epoch[1](672/114412); Loss: 0.090247; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.1652 0.1376 0.1117 0.1046 0.0949 0.0891 0.0827 0.0813 0.0781 0.0755 0.0736 0.0721 0.0706 0.0698 0.0689 0.0683 

[TRAIN] Epoch[1](673/114412); Loss: 0.073398; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1200 0.1181 0.0936 0.0846 0.0791 0.0723 0.0680 0.0656 0.0629 0.0614 0.0602 0.0591 0.0583 0.0576 0.0571 0.0566 

[TRAIN] Epoch[1](674/114412); Loss: 0.075570; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.1322 0.1108 0.0986 0.0844 0.0792 0.0751 0.0709 0.0674 0.0656 0.0637 0.0622 0.0611 0.0603 0.0597 0.0592 0.0588 

[TRAIN] Epoch[1](675/114412); Loss: 0.055360; Backpropagation: 0.2914 sec; Batch: 2.1016 sec
0.1052 0.0991 0.0795 0.0663 0.0586 0.0530 0.0488 0.0458 0.0444 0.0429 0.0420 0.0410 0.0404 0.0399 0.0395 0.0393 

[TRAIN] Epoch[1](676/114412); Loss: 0.079282; Backpropagation: 0.2928 sec; Batch: 2.1189 sec
0.1368 0.1107 0.0945 0.0880 0.0815 0.0765 0.0742 0.0718 0.0697 0.0683 0.0675 0.0666 0.0663 0.0657 0.0653 0.0651 

[TRAIN] Epoch[1](677/114412); Loss: 0.090490; Backpropagation: 0.2909 sec; Batch: 2.0780 sec
0.1418 0.1326 0.1109 0.1031 0.0948 0.0886 0.0851 0.0820 0.0801 0.0783 0.0774 0.0760 0.0751 0.0746 0.0740 0.0735 

[TRAIN] Epoch[1](678/114412); Loss: 0.053707; Backpropagation: 0.2907 sec; Batch: 2.0780 sec
0.1247 0.0796 0.0717 0.0586 0.0563 0.0499 0.0467 0.0450 0.0435 0.0422 0.0416 0.0407 0.0402 0.0399 0.0394 0.0394 

[TRAIN] Epoch[1](679/114412); Loss: 0.082510; Backpropagation: 0.2913 sec; Batch: 2.1192 sec
0.1578 0.1260 0.1080 0.0969 0.0861 0.0804 0.0763 0.0722 0.0695 0.0673 0.0657 0.0644 0.0633 0.0627 0.0621 0.0615 

[TRAIN] Epoch[1](680/114412); Loss: 0.080706; Backpropagation: 0.2912 sec; Batch: 2.1213 sec
0.1538 0.1268 0.1106 0.0974 0.0841 0.0776 0.0721 0.0685 0.0664 0.0648 0.0636 0.0624 0.0616 0.0610 0.0604 0.0600 

[TRAIN] Epoch[1](681/114412); Loss: 0.076396; Backpropagation: 0.2910 sec; Batch: 2.1206 sec
0.1312 0.1123 0.0972 0.0851 0.0792 0.0740 0.0701 0.0679 0.0663 0.0648 0.0638 0.0630 0.0625 0.0619 0.0616 0.0615 

[TRAIN] Epoch[1](682/114412); Loss: 0.073130; Backpropagation: 0.2911 sec; Batch: 2.1190 sec
0.1479 0.1070 0.0896 0.0858 0.0803 0.0766 0.0711 0.0659 0.0632 0.0597 0.0570 0.0555 0.0539 0.0527 0.0522 0.0516 

[TRAIN] Epoch[1](683/114412); Loss: 0.064607; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1264 0.0986 0.0866 0.0743 0.0682 0.0628 0.0580 0.0557 0.0538 0.0522 0.0512 0.0503 0.0496 0.0491 0.0486 0.0483 

[TRAIN] Epoch[1](684/114412); Loss: 0.072910; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1311 0.1020 0.0895 0.0818 0.0758 0.0711 0.0681 0.0660 0.0643 0.0625 0.0612 0.0602 0.0592 0.0585 0.0580 0.0574 

[TRAIN] Epoch[1](685/114412); Loss: 0.065922; Backpropagation: 0.2914 sec; Batch: 2.1208 sec
0.1214 0.1016 0.0861 0.0751 0.0680 0.0636 0.0614 0.0584 0.0563 0.0546 0.0531 0.0524 0.0517 0.0509 0.0504 0.0499 

[TRAIN] Epoch[1](686/114412); Loss: 0.083957; Backpropagation: 0.2912 sec; Batch: 2.1432 sec
0.1390 0.1115 0.0992 0.0912 0.0856 0.0822 0.0794 0.0773 0.0757 0.0743 0.0731 0.0722 0.0714 0.0708 0.0703 0.0700 

[TRAIN] Epoch[1](687/114412); Loss: 0.083039; Backpropagation: 0.2911 sec; Batch: 2.1419 sec
0.1280 0.1104 0.1018 0.0906 0.0856 0.0823 0.0794 0.0773 0.0750 0.0736 0.0724 0.0716 0.0708 0.0704 0.0699 0.0694 

[TRAIN] Epoch[1](688/114412); Loss: 0.058030; Backpropagation: 0.2909 sec; Batch: 2.1081 sec
0.1118 0.0874 0.0740 0.0639 0.0587 0.0557 0.0530 0.0510 0.0496 0.0484 0.0473 0.0464 0.0458 0.0456 0.0450 0.0448 

[TRAIN] Epoch[1](689/114412); Loss: 0.082204; Backpropagation: 0.2913 sec; Batch: 2.0878 sec
0.1368 0.1118 0.0993 0.0889 0.0813 0.0788 0.0767 0.0747 0.0737 0.0724 0.0716 0.0707 0.0701 0.0697 0.0694 0.0692 

[TRAIN] Epoch[1](690/114412); Loss: 0.059216; Backpropagation: 0.2909 sec; Batch: 2.1398 sec
0.1115 0.0917 0.0743 0.0678 0.0614 0.0586 0.0552 0.0530 0.0510 0.0489 0.0477 0.0467 0.0458 0.0450 0.0447 0.0443 

[TRAIN] Epoch[1](691/114412); Loss: 0.071295; Backpropagation: 0.2912 sec; Batch: 2.0837 sec
0.1429 0.1004 0.0870 0.0784 0.0728 0.0685 0.0655 0.0631 0.0612 0.0595 0.0585 0.0578 0.0571 0.0565 0.0560 0.0556 

[TRAIN] Epoch[1](692/114412); Loss: 0.046540; Backpropagation: 0.2918 sec; Batch: 2.1098 sec
0.1308 0.0841 0.0701 0.0556 0.0455 0.0415 0.0382 0.0355 0.0331 0.0321 0.0313 0.0302 0.0300 0.0293 0.0288 0.0285 

[TRAIN] Epoch[1](693/114412); Loss: 0.068307; Backpropagation: 0.2931 sec; Batch: 2.1196 sec
0.1540 0.1102 0.0851 0.0779 0.0704 0.0679 0.0631 0.0597 0.0556 0.0537 0.0514 0.0503 0.0492 0.0486 0.0481 0.0477 

[TRAIN] Epoch[1](694/114412); Loss: 0.072045; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1498 0.1136 0.0924 0.0793 0.0710 0.0677 0.0642 0.0624 0.0598 0.0584 0.0571 0.0563 0.0557 0.0552 0.0550 0.0547 

[TRAIN] Epoch[1](695/114412); Loss: 0.091814; Backpropagation: 0.2913 sec; Batch: 2.1134 sec
0.1702 0.1342 0.1170 0.1092 0.0973 0.0902 0.0849 0.0819 0.0789 0.0764 0.0744 0.0727 0.0716 0.0707 0.0701 0.0694 

[TRAIN] Epoch[1](696/114412); Loss: 0.073842; Backpropagation: 0.2915 sec; Batch: 2.1179 sec
0.1618 0.1219 0.0978 0.0837 0.0752 0.0702 0.0665 0.0628 0.0601 0.0579 0.0564 0.0549 0.0541 0.0533 0.0527 0.0522 

[TRAIN] Epoch[1](697/114412); Loss: 0.071128; Backpropagation: 0.2918 sec; Batch: 2.1245 sec
0.1536 0.1187 0.1046 0.0895 0.0770 0.0693 0.0615 0.0574 0.0553 0.0531 0.0518 0.0507 0.0498 0.0492 0.0486 0.0481 

[TRAIN] Epoch[1](698/114412); Loss: 0.065207; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1345 0.1201 0.0842 0.0760 0.0661 0.0611 0.0577 0.0551 0.0527 0.0507 0.0493 0.0485 0.0474 0.0470 0.0467 0.0464 

[TRAIN] Epoch[1](699/114412); Loss: 0.062406; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.1283 0.1043 0.0808 0.0673 0.0613 0.0588 0.0567 0.0537 0.0518 0.0505 0.0494 0.0483 0.0477 0.0471 0.0465 0.0460 

[TRAIN] Epoch[1](700/114412); Loss: 0.058238; Backpropagation: 0.2910 sec; Batch: 2.1210 sec
0.1430 0.0969 0.0774 0.0680 0.0584 0.0533 0.0499 0.0481 0.0456 0.0439 0.0426 0.0419 0.0413 0.0408 0.0405 0.0401 

[TRAIN] Epoch[1](701/114412); Loss: 0.068627; Backpropagation: 0.2908 sec; Batch: 2.1180 sec
0.1406 0.1080 0.0851 0.0719 0.0657 0.0627 0.0610 0.0596 0.0575 0.0569 0.0560 0.0553 0.0550 0.0544 0.0542 0.0541 

[TRAIN] Epoch[1](702/114412); Loss: 0.061145; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1181 0.0927 0.0771 0.0681 0.0629 0.0592 0.0562 0.0537 0.0519 0.0506 0.0495 0.0488 0.0481 0.0475 0.0470 0.0468 

[TRAIN] Epoch[1](703/114412); Loss: 0.056304; Backpropagation: 0.2913 sec; Batch: 2.1192 sec
0.1139 0.0879 0.0739 0.0619 0.0562 0.0524 0.0500 0.0484 0.0471 0.0458 0.0451 0.0446 0.0440 0.0435 0.0432 0.0429 

[TRAIN] Epoch[1](704/114412); Loss: 0.059794; Backpropagation: 0.2931 sec; Batch: 2.1191 sec
0.1105 0.0871 0.0769 0.0670 0.0600 0.0567 0.0542 0.0522 0.0509 0.0503 0.0497 0.0492 0.0487 0.0482 0.0479 0.0476 

[TRAIN] Epoch[1](705/114412); Loss: 0.062107; Backpropagation: 0.2914 sec; Batch: 2.1294 sec
0.1306 0.1084 0.0880 0.0727 0.0658 0.0592 0.0544 0.0517 0.0498 0.0477 0.0461 0.0450 0.0444 0.0437 0.0433 0.0429 

[TRAIN] Epoch[1](706/114412); Loss: 0.061198; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1150 0.0956 0.0798 0.0688 0.0628 0.0587 0.0558 0.0530 0.0518 0.0505 0.0492 0.0487 0.0480 0.0476 0.0471 0.0469 

[TRAIN] Epoch[1](707/114412); Loss: 0.052765; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.1193 0.0831 0.0717 0.0602 0.0545 0.0485 0.0452 0.0426 0.0418 0.0412 0.0403 0.0398 0.0395 0.0390 0.0389 0.0387 

[TRAIN] Epoch[1](708/114412); Loss: 0.066402; Backpropagation: 0.2930 sec; Batch: 2.1368 sec
0.1579 0.1138 0.0995 0.0871 0.0808 0.0704 0.0619 0.0549 0.0503 0.0448 0.0432 0.0415 0.0402 0.0395 0.0387 0.0380 

[TRAIN] Epoch[1](709/114412); Loss: 0.064933; Backpropagation: 0.2972 sec; Batch: 2.0880 sec
0.1296 0.0984 0.0867 0.0736 0.0667 0.0618 0.0582 0.0561 0.0539 0.0526 0.0517 0.0509 0.0504 0.0499 0.0493 0.0490 

[TRAIN] Epoch[1](710/114412); Loss: 0.085766; Backpropagation: 0.2929 sec; Batch: 2.1195 sec
0.1459 0.1188 0.1011 0.0946 0.0878 0.0838 0.0811 0.0789 0.0769 0.0750 0.0736 0.0730 0.0717 0.0708 0.0698 0.0695 

[TRAIN] Epoch[1](711/114412); Loss: 0.075997; Backpropagation: 0.2907 sec; Batch: 2.1158 sec
0.1339 0.1090 0.0954 0.0890 0.0833 0.0767 0.0719 0.0685 0.0665 0.0649 0.0621 0.0611 0.0598 0.0587 0.0580 0.0570 

[TRAIN] Epoch[1](712/114412); Loss: 0.071814; Backpropagation: 0.2909 sec; Batch: 2.1183 sec
0.1318 0.1131 0.0939 0.0853 0.0774 0.0737 0.0676 0.0636 0.0602 0.0580 0.0562 0.0549 0.0541 0.0535 0.0530 0.0527 

[TRAIN] Epoch[1](713/114412); Loss: 0.058529; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1053 0.0893 0.0752 0.0685 0.0613 0.0564 0.0540 0.0516 0.0499 0.0485 0.0475 0.0469 0.0462 0.0456 0.0453 0.0449 

[TRAIN] Epoch[1](714/114412); Loss: 0.073308; Backpropagation: 0.2910 sec; Batch: 2.0782 sec
0.1303 0.1131 0.0977 0.0856 0.0797 0.0733 0.0683 0.0649 0.0621 0.0605 0.0585 0.0580 0.0567 0.0553 0.0549 0.0540 

[TRAIN] Epoch[1](715/114412); Loss: 0.095637; Backpropagation: 0.2911 sec; Batch: 2.1212 sec
0.1726 0.1462 0.1259 0.1102 0.1033 0.0987 0.0880 0.0849 0.0811 0.0789 0.0781 0.0758 0.0745 0.0720 0.0705 0.0696 

[TRAIN] Epoch[1](716/114412); Loss: 0.081380; Backpropagation: 0.2912 sec; Batch: 2.1018 sec
0.1291 0.1081 0.1032 0.0926 0.0881 0.0816 0.0779 0.0754 0.0721 0.0706 0.0690 0.0683 0.0673 0.0667 0.0663 0.0658 

[TRAIN] Epoch[1](717/114412); Loss: 0.068350; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1295 0.1051 0.0874 0.0764 0.0698 0.0661 0.0630 0.0603 0.0578 0.0564 0.0551 0.0544 0.0538 0.0533 0.0528 0.0525 

[TRAIN] Epoch[1](718/114412); Loss: 0.069070; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1578 0.1045 0.0791 0.0727 0.0657 0.0623 0.0603 0.0586 0.0574 0.0563 0.0557 0.0554 0.0551 0.0549 0.0548 0.0546 

[TRAIN] Epoch[1](719/114412); Loss: 0.074217; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.1384 0.1157 0.1003 0.0877 0.0794 0.0734 0.0689 0.0655 0.0628 0.0607 0.0591 0.0574 0.0558 0.0549 0.0540 0.0535 

[TRAIN] Epoch[1](720/114412); Loss: 0.085818; Backpropagation: 0.2912 sec; Batch: 2.1204 sec
0.1469 0.1397 0.1214 0.1066 0.0912 0.0839 0.0777 0.0736 0.0708 0.0690 0.0675 0.0664 0.0656 0.0649 0.0642 0.0637 

[TRAIN] Epoch[1](721/114412); Loss: 0.080258; Backpropagation: 0.2925 sec; Batch: 2.1012 sec
0.1349 0.1207 0.0969 0.0842 0.0782 0.0751 0.0730 0.0718 0.0704 0.0699 0.0689 0.0687 0.0684 0.0679 0.0676 0.0673 

[TRAIN] Epoch[1](722/114412); Loss: 0.079132; Backpropagation: 0.2914 sec; Batch: 2.1156 sec
0.1371 0.1080 0.0989 0.0873 0.0809 0.0760 0.0728 0.0707 0.0693 0.0682 0.0673 0.0666 0.0662 0.0658 0.0656 0.0654 

[TRAIN] Epoch[1](723/114412); Loss: 0.076005; Backpropagation: 0.2919 sec; Batch: 2.1191 sec
0.1695 0.1287 0.0945 0.0808 0.0736 0.0690 0.0657 0.0634 0.0620 0.0608 0.0597 0.0588 0.0581 0.0576 0.0571 0.0567 

[TRAIN] Epoch[1](724/114412); Loss: 0.059741; Backpropagation: 0.2910 sec; Batch: 2.1152 sec
0.1080 0.0957 0.0770 0.0693 0.0621 0.0576 0.0541 0.0521 0.0505 0.0492 0.0481 0.0473 0.0468 0.0463 0.0460 0.0458 

[TRAIN] Epoch[1](725/114412); Loss: 0.076714; Backpropagation: 0.2907 sec; Batch: 2.1173 sec
0.1313 0.1194 0.0985 0.0897 0.0809 0.0753 0.0711 0.0677 0.0657 0.0636 0.0626 0.0616 0.0607 0.0602 0.0598 0.0594 

[TRAIN] Epoch[1](726/114412); Loss: 0.077500; Backpropagation: 0.2941 sec; Batch: 2.1209 sec
0.1481 0.1257 0.1015 0.0886 0.0797 0.0731 0.0690 0.0660 0.0638 0.0625 0.0615 0.0608 0.0604 0.0600 0.0598 0.0595 

[TRAIN] Epoch[1](727/114412); Loss: 0.075915; Backpropagation: 0.2941 sec; Batch: 2.1223 sec
0.1420 0.1282 0.1056 0.0953 0.0808 0.0720 0.0663 0.0638 0.0616 0.0596 0.0582 0.0574 0.0567 0.0562 0.0557 0.0553 

[TRAIN] Epoch[1](728/114412); Loss: 0.087966; Backpropagation: 0.2913 sec; Batch: 2.1228 sec
0.1592 0.1314 0.1124 0.1005 0.0916 0.0856 0.0805 0.0774 0.0749 0.0733 0.0721 0.0712 0.0704 0.0696 0.0689 0.0685 

[TRAIN] Epoch[1](729/114412); Loss: 0.064062; Backpropagation: 0.2913 sec; Batch: 2.1225 sec
0.1126 0.0969 0.0767 0.0702 0.0644 0.0603 0.0580 0.0563 0.0554 0.0545 0.0539 0.0535 0.0532 0.0532 0.0530 0.0529 

[TRAIN] Epoch[1](730/114412); Loss: 0.056014; Backpropagation: 0.2914 sec; Batch: 2.0787 sec
0.1252 0.1105 0.0791 0.0659 0.0557 0.0500 0.0455 0.0446 0.0427 0.0414 0.0404 0.0397 0.0394 0.0389 0.0387 0.0384 

[TRAIN] Epoch[1](731/114412); Loss: 0.079223; Backpropagation: 0.2952 sec; Batch: 2.1192 sec
0.1608 0.1322 0.1022 0.0905 0.0798 0.0737 0.0697 0.0670 0.0648 0.0633 0.0622 0.0613 0.0606 0.0601 0.0599 0.0595 

[TRAIN] Epoch[1](732/114412); Loss: 0.052410; Backpropagation: 0.2928 sec; Batch: 2.1232 sec
0.1015 0.0750 0.0660 0.0593 0.0535 0.0498 0.0481 0.0461 0.0446 0.0434 0.0428 0.0423 0.0419 0.0416 0.0414 0.0412 

[TRAIN] Epoch[1](733/114412); Loss: 0.062022; Backpropagation: 0.2910 sec; Batch: 2.1211 sec
0.1264 0.1095 0.0815 0.0725 0.0627 0.0575 0.0542 0.0521 0.0502 0.0490 0.0476 0.0467 0.0462 0.0458 0.0455 0.0452 

[TRAIN] Epoch[1](734/114412); Loss: 0.053010; Backpropagation: 0.2909 sec; Batch: 2.1191 sec
0.1101 0.0973 0.0753 0.0659 0.0577 0.0511 0.0453 0.0430 0.0410 0.0395 0.0384 0.0375 0.0370 0.0366 0.0364 0.0361 

[TRAIN] Epoch[1](735/114412); Loss: 0.062767; Backpropagation: 0.2928 sec; Batch: 2.1157 sec
0.1375 0.1193 0.0816 0.0716 0.0641 0.0596 0.0550 0.0526 0.0493 0.0478 0.0461 0.0452 0.0445 0.0439 0.0433 0.0429 

[TRAIN] Epoch[1](736/114412); Loss: 0.066952; Backpropagation: 0.2908 sec; Batch: 2.1159 sec
0.1359 0.1167 0.0927 0.0792 0.0695 0.0622 0.0592 0.0563 0.0539 0.0522 0.0509 0.0498 0.0490 0.0484 0.0478 0.0473 

[TRAIN] Epoch[1](737/114412); Loss: 0.069279; Backpropagation: 0.2910 sec; Batch: 2.1197 sec
0.1393 0.1233 0.0992 0.0877 0.0784 0.0679 0.0629 0.0581 0.0541 0.0514 0.0499 0.0486 0.0478 0.0472 0.0466 0.0462 

[TRAIN] Epoch[1](738/114412); Loss: 0.057476; Backpropagation: 0.2908 sec; Batch: 2.1155 sec
0.1219 0.0976 0.0800 0.0666 0.0587 0.0546 0.0492 0.0473 0.0459 0.0443 0.0434 0.0428 0.0423 0.0419 0.0416 0.0414 

[TRAIN] Epoch[1](739/114412); Loss: 0.069420; Backpropagation: 0.2910 sec; Batch: 2.1282 sec
0.1375 0.1194 0.0995 0.0861 0.0753 0.0667 0.0594 0.0566 0.0543 0.0531 0.0521 0.0511 0.0505 0.0500 0.0496 0.0493 

[TRAIN] Epoch[1](740/114412); Loss: 0.081151; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1280 0.1174 0.0993 0.0904 0.0816 0.0779 0.0746 0.0724 0.0712 0.0709 0.0703 0.0697 0.0691 0.0688 0.0685 0.0684 

[TRAIN] Epoch[1](741/114412); Loss: 0.066440; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1485 0.1215 0.0881 0.0782 0.0680 0.0631 0.0580 0.0544 0.0517 0.0501 0.0486 0.0478 0.0470 0.0464 0.0460 0.0455 

[TRAIN] Epoch[1](742/114412); Loss: 0.075267; Backpropagation: 0.2921 sec; Batch: 2.1183 sec
0.1451 0.1203 0.0945 0.0827 0.0756 0.0707 0.0675 0.0657 0.0636 0.0622 0.0612 0.0603 0.0595 0.0589 0.0585 0.0581 

[TRAIN] Epoch[1](743/114412); Loss: 0.046605; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1014 0.0807 0.0701 0.0567 0.0464 0.0429 0.0403 0.0384 0.0367 0.0350 0.0341 0.0334 0.0329 0.0327 0.0322 0.0319 

[TRAIN] Epoch[1](744/114412); Loss: 0.044742; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1394 0.1051 0.0606 0.0499 0.0437 0.0359 0.0330 0.0312 0.0296 0.0287 0.0279 0.0270 0.0266 0.0261 0.0257 0.0254 

[TRAIN] Epoch[1](745/114412); Loss: 0.067447; Backpropagation: 0.2920 sec; Batch: 2.1163 sec
0.1348 0.1110 0.0889 0.0766 0.0693 0.0635 0.0609 0.0581 0.0561 0.0543 0.0528 0.0519 0.0510 0.0503 0.0500 0.0497 

[TRAIN] Epoch[1](746/114412); Loss: 0.065791; Backpropagation: 0.2912 sec; Batch: 2.1161 sec
0.1360 0.1197 0.0917 0.0794 0.0671 0.0606 0.0565 0.0540 0.0523 0.0507 0.0494 0.0484 0.0474 0.0469 0.0463 0.0460 

[TRAIN] Epoch[1](747/114412); Loss: 0.090547; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1587 0.1353 0.1102 0.1052 0.0936 0.0890 0.0824 0.0799 0.0780 0.0766 0.0754 0.0744 0.0734 0.0729 0.0722 0.0717 

[TRAIN] Epoch[1](748/114412); Loss: 0.042327; Backpropagation: 0.2910 sec; Batch: 2.1220 sec
0.1054 0.0801 0.0547 0.0472 0.0404 0.0370 0.0353 0.0333 0.0322 0.0314 0.0308 0.0303 0.0300 0.0300 0.0297 0.0295 

[TRAIN] Epoch[1](749/114412); Loss: 0.086331; Backpropagation: 0.2909 sec; Batch: 2.1009 sec
0.1508 0.1227 0.1072 0.0927 0.0848 0.0817 0.0793 0.0777 0.0761 0.0747 0.0743 0.0732 0.0726 0.0719 0.0712 0.0707 

[TRAIN] Epoch[1](750/114412); Loss: 0.080679; Backpropagation: 0.2926 sec; Batch: 2.1195 sec
0.1321 0.1155 0.0949 0.0855 0.0807 0.0784 0.0755 0.0735 0.0723 0.0709 0.0703 0.0694 0.0685 0.0683 0.0677 0.0672 

[TRAIN] Epoch[1](751/114412); Loss: 0.053063; Backpropagation: 0.2917 sec; Batch: 2.1167 sec
0.1132 0.0803 0.0703 0.0584 0.0538 0.0495 0.0476 0.0456 0.0438 0.0429 0.0419 0.0414 0.0407 0.0403 0.0398 0.0396 

[TRAIN] Epoch[1](752/114412); Loss: 0.043474; Backpropagation: 0.2909 sec; Batch: 2.0976 sec
0.1001 0.0746 0.0577 0.0486 0.0426 0.0394 0.0373 0.0355 0.0347 0.0335 0.0327 0.0323 0.0319 0.0317 0.0316 0.0314 

[TRAIN] Epoch[1](753/114412); Loss: 0.062707; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.1262 0.1017 0.0778 0.0695 0.0631 0.0592 0.0559 0.0535 0.0523 0.0510 0.0503 0.0496 0.0490 0.0484 0.0480 0.0477 

[TRAIN] Epoch[1](754/114412); Loss: 0.074573; Backpropagation: 0.2911 sec; Batch: 2.1338 sec
0.1553 0.1196 0.0879 0.0791 0.0722 0.0687 0.0659 0.0640 0.0626 0.0616 0.0608 0.0600 0.0596 0.0589 0.0587 0.0583 

[TRAIN] Epoch[1](755/114412); Loss: 0.064721; Backpropagation: 0.2929 sec; Batch: 2.0942 sec
0.1221 0.0916 0.0811 0.0738 0.0717 0.0630 0.0608 0.0582 0.0557 0.0546 0.0524 0.0516 0.0509 0.0501 0.0493 0.0486 

[TRAIN] Epoch[1](756/114412); Loss: 0.076076; Backpropagation: 0.2920 sec; Batch: 2.0859 sec
0.1238 0.1030 0.0913 0.0848 0.0777 0.0737 0.0716 0.0698 0.0680 0.0667 0.0659 0.0651 0.0646 0.0642 0.0637 0.0634 

[TRAIN] Epoch[1](757/114412); Loss: 0.101639; Backpropagation: 0.2920 sec; Batch: 2.1215 sec
0.1823 0.1471 0.1167 0.1100 0.1030 0.0979 0.0939 0.0917 0.0894 0.0878 0.0867 0.0857 0.0847 0.0838 0.0831 0.0826 

[TRAIN] Epoch[1](758/114412); Loss: 0.062050; Backpropagation: 0.2914 sec; Batch: 2.1163 sec
0.1327 0.0926 0.0841 0.0701 0.0629 0.0578 0.0546 0.0532 0.0514 0.0498 0.0484 0.0479 0.0474 0.0471 0.0467 0.0463 

[TRAIN] Epoch[1](759/114412); Loss: 0.071665; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1366 0.1136 0.0976 0.0859 0.0765 0.0685 0.0637 0.0612 0.0590 0.0576 0.0563 0.0554 0.0545 0.0539 0.0534 0.0530 

[TRAIN] Epoch[1](760/114412); Loss: 0.043974; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.0895 0.0661 0.0569 0.0524 0.0470 0.0430 0.0404 0.0381 0.0360 0.0351 0.0342 0.0337 0.0332 0.0329 0.0327 0.0325 

[TRAIN] Epoch[1](761/114412); Loss: 0.044214; Backpropagation: 0.2909 sec; Batch: 2.1216 sec
0.0959 0.0700 0.0655 0.0548 0.0466 0.0420 0.0395 0.0363 0.0345 0.0335 0.0327 0.0321 0.0316 0.0311 0.0308 0.0306 

[TRAIN] Epoch[1](762/114412); Loss: 0.060392; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.1330 0.1017 0.0756 0.0662 0.0583 0.0544 0.0520 0.0504 0.0490 0.0482 0.0474 0.0467 0.0464 0.0459 0.0457 0.0454 

[TRAIN] Epoch[1](763/114412); Loss: 0.062233; Backpropagation: 0.2939 sec; Batch: 2.1195 sec
0.1269 0.1006 0.0731 0.0675 0.0614 0.0577 0.0554 0.0536 0.0524 0.0511 0.0506 0.0499 0.0494 0.0491 0.0487 0.0484 

[TRAIN] Epoch[1](764/114412); Loss: 0.073677; Backpropagation: 0.2942 sec; Batch: 2.1222 sec
0.1617 0.1215 0.0907 0.0813 0.0728 0.0676 0.0642 0.0623 0.0605 0.0591 0.0580 0.0571 0.0564 0.0558 0.0552 0.0548 

[TRAIN] Epoch[1](765/114412); Loss: 0.060222; Backpropagation: 0.2952 sec; Batch: 2.1218 sec
0.1417 0.1075 0.0770 0.0661 0.0585 0.0547 0.0509 0.0490 0.0474 0.0463 0.0453 0.0447 0.0442 0.0437 0.0434 0.0432 

[TRAIN] Epoch[1](766/114412); Loss: 0.072376; Backpropagation: 0.2919 sec; Batch: 2.1356 sec
0.1506 0.1162 0.0871 0.0775 0.0726 0.0678 0.0644 0.0620 0.0603 0.0592 0.0582 0.0575 0.0568 0.0563 0.0559 0.0556 

[TRAIN] Epoch[1](767/114412); Loss: 0.071353; Backpropagation: 0.2907 sec; Batch: 2.1195 sec
0.1249 0.0911 0.0814 0.0743 0.0706 0.0675 0.0659 0.0646 0.0638 0.0633 0.0628 0.0626 0.0623 0.0622 0.0622 0.0621 

[TRAIN] Epoch[1](768/114412); Loss: 0.064563; Backpropagation: 0.2911 sec; Batch: 2.1221 sec
0.1337 0.1061 0.0853 0.0733 0.0665 0.0605 0.0569 0.0548 0.0529 0.0513 0.0501 0.0494 0.0487 0.0482 0.0478 0.0475 

[TRAIN] Epoch[1](769/114412); Loss: 0.056103; Backpropagation: 0.2908 sec; Batch: 2.1171 sec
0.1519 0.1117 0.0688 0.0592 0.0521 0.0475 0.0450 0.0435 0.0422 0.0412 0.0404 0.0397 0.0392 0.0388 0.0384 0.0381 

[TRAIN] Epoch[1](770/114412); Loss: 0.056291; Backpropagation: 0.2907 sec; Batch: 2.1218 sec
0.1225 0.0885 0.0761 0.0609 0.0560 0.0518 0.0502 0.0477 0.0461 0.0448 0.0438 0.0432 0.0427 0.0424 0.0421 0.0418 

[TRAIN] Epoch[1](771/114412); Loss: 0.061999; Backpropagation: 0.2910 sec; Batch: 2.0861 sec
0.1262 0.0943 0.0791 0.0685 0.0626 0.0577 0.0550 0.0531 0.0517 0.0509 0.0501 0.0494 0.0489 0.0485 0.0481 0.0478 

[TRAIN] Epoch[1](772/114412); Loss: 0.086149; Backpropagation: 0.2909 sec; Batch: 2.0810 sec
0.1441 0.1119 0.1016 0.0935 0.0872 0.0820 0.0802 0.0788 0.0771 0.0763 0.0754 0.0748 0.0744 0.0740 0.0736 0.0732 

[TRAIN] Epoch[1](773/114412); Loss: 0.059484; Backpropagation: 0.2907 sec; Batch: 2.0856 sec
0.1488 0.0927 0.0680 0.0601 0.0557 0.0528 0.0508 0.0494 0.0484 0.0475 0.0471 0.0467 0.0462 0.0460 0.0458 0.0456 

[TRAIN] Epoch[1](774/114412); Loss: 0.070920; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1223 0.0980 0.0857 0.0770 0.0718 0.0688 0.0654 0.0638 0.0626 0.0615 0.0608 0.0602 0.0597 0.0593 0.0590 0.0588 

[TRAIN] Epoch[1](775/114412); Loss: 0.069258; Backpropagation: 0.2918 sec; Batch: 2.0792 sec
0.1194 0.0986 0.0862 0.0770 0.0718 0.0666 0.0639 0.0617 0.0604 0.0593 0.0583 0.0577 0.0572 0.0569 0.0566 0.0563 

[TRAIN] Epoch[1](776/114412); Loss: 0.068503; Backpropagation: 0.2910 sec; Batch: 2.0856 sec
0.1521 0.1123 0.0862 0.0748 0.0685 0.0634 0.0595 0.0571 0.0555 0.0543 0.0533 0.0527 0.0522 0.0518 0.0513 0.0511 

[TRAIN] Epoch[1](777/114412); Loss: 0.067073; Backpropagation: 0.2915 sec; Batch: 2.0854 sec
0.1142 0.0937 0.0812 0.0719 0.0674 0.0646 0.0626 0.0604 0.0594 0.0584 0.0577 0.0572 0.0566 0.0563 0.0559 0.0557 

[TRAIN] Epoch[1](778/114412); Loss: 0.075312; Backpropagation: 0.2905 sec; Batch: 2.0821 sec
0.1364 0.1057 0.0919 0.0830 0.0769 0.0716 0.0689 0.0668 0.0652 0.0644 0.0636 0.0628 0.0625 0.0621 0.0617 0.0614 

[TRAIN] Epoch[1](779/114412); Loss: 0.061645; Backpropagation: 0.2910 sec; Batch: 2.1187 sec
0.1264 0.0941 0.0800 0.0693 0.0639 0.0584 0.0553 0.0529 0.0513 0.0500 0.0491 0.0483 0.0475 0.0469 0.0466 0.0463 

[TRAIN] Epoch[1](780/114412); Loss: 0.069619; Backpropagation: 0.2910 sec; Batch: 2.1182 sec
0.1409 0.1051 0.0834 0.0743 0.0681 0.0642 0.0625 0.0610 0.0593 0.0586 0.0573 0.0567 0.0562 0.0557 0.0554 0.0550 

[TRAIN] Epoch[1](781/114412); Loss: 0.089263; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1447 0.1215 0.1060 0.0974 0.0922 0.0866 0.0840 0.0821 0.0800 0.0787 0.0776 0.0767 0.0760 0.0754 0.0749 0.0745 

[TRAIN] Epoch[1](782/114412); Loss: 0.067669; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1489 0.1017 0.0825 0.0745 0.0690 0.0636 0.0599 0.0579 0.0560 0.0548 0.0537 0.0529 0.0524 0.0519 0.0515 0.0512 

[TRAIN] Epoch[1](783/114412); Loss: 0.063961; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.1479 0.0974 0.0772 0.0687 0.0617 0.0581 0.0559 0.0541 0.0528 0.0515 0.0509 0.0504 0.0498 0.0494 0.0490 0.0485 

[TRAIN] Epoch[1](784/114412); Loss: 0.069985; Backpropagation: 0.2928 sec; Batch: 2.1194 sec
0.1325 0.0949 0.0879 0.0778 0.0724 0.0679 0.0651 0.0625 0.0608 0.0592 0.0583 0.0573 0.0566 0.0561 0.0555 0.0551 

[TRAIN] Epoch[1](785/114412); Loss: 0.100052; Backpropagation: 0.2928 sec; Batch: 2.1171 sec
0.1621 0.1344 0.1174 0.1087 0.1026 0.0974 0.0947 0.0922 0.0904 0.0887 0.0875 0.0863 0.0853 0.0848 0.0843 0.0839 

[TRAIN] Epoch[1](786/114412); Loss: 0.066949; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1658 0.1260 0.1028 0.0827 0.0725 0.0583 0.0547 0.0520 0.0488 0.0468 0.0453 0.0445 0.0436 0.0430 0.0426 0.0420 

[TRAIN] Epoch[1](787/114412); Loss: 0.070580; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1421 0.1080 0.0944 0.0810 0.0726 0.0668 0.0631 0.0609 0.0588 0.0567 0.0559 0.0550 0.0541 0.0537 0.0533 0.0529 

[TRAIN] Epoch[1](788/114412); Loss: 0.071901; Backpropagation: 0.2912 sec; Batch: 2.0823 sec
0.1323 0.1061 0.0875 0.0781 0.0734 0.0692 0.0656 0.0635 0.0621 0.0613 0.0601 0.0593 0.0587 0.0580 0.0578 0.0576 

[TRAIN] Epoch[1](789/114412); Loss: 0.063852; Backpropagation: 0.2907 sec; Batch: 2.0785 sec
0.1635 0.1037 0.0754 0.0671 0.0615 0.0567 0.0538 0.0519 0.0512 0.0502 0.0489 0.0484 0.0480 0.0474 0.0472 0.0468 

[TRAIN] Epoch[1](790/114412); Loss: 0.071697; Backpropagation: 0.2911 sec; Batch: 2.0877 sec
0.1158 0.0972 0.0874 0.0790 0.0734 0.0700 0.0677 0.0657 0.0642 0.0631 0.0621 0.0612 0.0608 0.0602 0.0598 0.0595 

[TRAIN] Epoch[1](791/114412); Loss: 0.061384; Backpropagation: 0.2903 sec; Batch: 2.1174 sec
0.1184 0.0809 0.0704 0.0648 0.0618 0.0590 0.0565 0.0550 0.0540 0.0531 0.0523 0.0519 0.0515 0.0511 0.0509 0.0507 

[TRAIN] Epoch[1](792/114412); Loss: 0.057280; Backpropagation: 0.2915 sec; Batch: 2.1195 sec
0.1407 0.0853 0.0676 0.0601 0.0546 0.0521 0.0502 0.0479 0.0467 0.0457 0.0451 0.0446 0.0443 0.0441 0.0439 0.0437 

[TRAIN] Epoch[1](793/114412); Loss: 0.065501; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1139 0.0830 0.0769 0.0698 0.0660 0.0634 0.0615 0.0599 0.0591 0.0582 0.0573 0.0567 0.0561 0.0558 0.0554 0.0551 

[TRAIN] Epoch[1](794/114412); Loss: 0.070018; Backpropagation: 0.2916 sec; Batch: 2.0798 sec
0.1946 0.1256 0.1013 0.0848 0.0719 0.0624 0.0559 0.0522 0.0496 0.0482 0.0470 0.0462 0.0458 0.0452 0.0449 0.0447 

[TRAIN] Epoch[1](795/114412); Loss: 0.049915; Backpropagation: 0.2908 sec; Batch: 2.1256 sec
0.1359 0.0793 0.0636 0.0530 0.0467 0.0440 0.0418 0.0398 0.0391 0.0382 0.0373 0.0368 0.0363 0.0360 0.0356 0.0354 

[TRAIN] Epoch[1](796/114412); Loss: 0.067942; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1412 0.1014 0.0879 0.0782 0.0698 0.0643 0.0613 0.0586 0.0566 0.0551 0.0538 0.0529 0.0522 0.0517 0.0513 0.0508 

[TRAIN] Epoch[1](797/114412); Loss: 0.040471; Backpropagation: 0.2930 sec; Batch: 2.1201 sec
0.1062 0.0661 0.0559 0.0440 0.0391 0.0355 0.0337 0.0320 0.0311 0.0303 0.0298 0.0294 0.0289 0.0287 0.0285 0.0284 

[TRAIN] Epoch[1](798/114412); Loss: 0.063173; Backpropagation: 0.2928 sec; Batch: 2.1214 sec
0.1281 0.0933 0.0817 0.0709 0.0630 0.0588 0.0569 0.0551 0.0532 0.0521 0.0513 0.0505 0.0497 0.0491 0.0487 0.0483 

[TRAIN] Epoch[1](799/114412); Loss: 0.055034; Backpropagation: 0.2910 sec; Batch: 2.1195 sec
0.1192 0.0912 0.0682 0.0627 0.0555 0.0520 0.0486 0.0465 0.0447 0.0435 0.0429 0.0419 0.0415 0.0412 0.0407 0.0404 

[TRAIN] Epoch[1](800/114412); Loss: 0.055566; Backpropagation: 0.2911 sec; Batch: 2.1214 sec
0.1332 0.0824 0.0690 0.0611 0.0552 0.0514 0.0490 0.0471 0.0453 0.0441 0.0433 0.0425 0.0419 0.0415 0.0412 0.0409 

[TRAIN] Epoch[1](801/114412); Loss: 0.049135; Backpropagation: 0.2927 sec; Batch: 2.1236 sec
0.1292 0.0807 0.0568 0.0566 0.0514 0.0440 0.0418 0.0402 0.0379 0.0370 0.0363 0.0356 0.0351 0.0348 0.0345 0.0343 

[TRAIN] Epoch[1](802/114412); Loss: 0.053353; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1395 0.0827 0.0616 0.0546 0.0494 0.0466 0.0449 0.0437 0.0430 0.0422 0.0417 0.0414 0.0409 0.0406 0.0405 0.0403 

[TRAIN] Epoch[1](803/114412); Loss: 0.065208; Backpropagation: 0.2915 sec; Batch: 2.1298 sec
0.1363 0.0943 0.0771 0.0700 0.0664 0.0618 0.0590 0.0572 0.0557 0.0542 0.0533 0.0527 0.0520 0.0516 0.0512 0.0508 

[TRAIN] Epoch[1](804/114412); Loss: 0.058721; Backpropagation: 0.2914 sec; Batch: 2.1214 sec
0.1434 0.0955 0.0764 0.0668 0.0605 0.0546 0.0516 0.0488 0.0463 0.0444 0.0432 0.0427 0.0419 0.0414 0.0411 0.0410 

[TRAIN] Epoch[1](805/114412); Loss: 0.058659; Backpropagation: 0.2911 sec; Batch: 2.1213 sec
0.1673 0.1049 0.0750 0.0541 0.0506 0.0482 0.0465 0.0453 0.0446 0.0440 0.0436 0.0433 0.0430 0.0428 0.0428 0.0426 

[TRAIN] Epoch[1](806/114412); Loss: 0.082239; Backpropagation: 0.2930 sec; Batch: 2.0804 sec
0.1592 0.1175 0.0971 0.0884 0.0828 0.0784 0.0756 0.0734 0.0714 0.0698 0.0688 0.0679 0.0671 0.0666 0.0661 0.0659 

[TRAIN] Epoch[1](807/114412); Loss: 0.057971; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1354 0.0892 0.0687 0.0597 0.0546 0.0524 0.0503 0.0489 0.0478 0.0469 0.0463 0.0459 0.0456 0.0454 0.0453 0.0450 

[TRAIN] Epoch[1](808/114412); Loss: 0.050812; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1200 0.0744 0.0704 0.0586 0.0545 0.0495 0.0448 0.0429 0.0411 0.0388 0.0378 0.0371 0.0364 0.0359 0.0355 0.0352 

[TRAIN] Epoch[1](809/114412); Loss: 0.064113; Backpropagation: 0.2932 sec; Batch: 2.1228 sec
0.1193 0.0879 0.0765 0.0697 0.0648 0.0612 0.0591 0.0574 0.0561 0.0553 0.0544 0.0538 0.0532 0.0527 0.0524 0.0520 

[TRAIN] Epoch[1](810/114412); Loss: 0.077447; Backpropagation: 0.2913 sec; Batch: 2.1157 sec
0.1589 0.1142 0.1008 0.0880 0.0804 0.0732 0.0695 0.0667 0.0644 0.0629 0.0619 0.0607 0.0601 0.0596 0.0591 0.0587 

[TRAIN] Epoch[1](811/114412); Loss: 0.075603; Backpropagation: 0.2917 sec; Batch: 2.1180 sec
0.1528 0.1144 0.0949 0.0803 0.0739 0.0700 0.0676 0.0653 0.0636 0.0627 0.0618 0.0613 0.0608 0.0603 0.0600 0.0597 

[TRAIN] Epoch[1](812/114412); Loss: 0.067011; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1137 0.0945 0.0835 0.0751 0.0690 0.0648 0.0622 0.0602 0.0587 0.0576 0.0567 0.0561 0.0555 0.0551 0.0549 0.0544 

[TRAIN] Epoch[1](813/114412); Loss: 0.071851; Backpropagation: 0.2909 sec; Batch: 2.1184 sec
0.1483 0.1151 0.0929 0.0811 0.0706 0.0669 0.0641 0.0612 0.0594 0.0581 0.0569 0.0563 0.0554 0.0548 0.0544 0.0539 

[TRAIN] Epoch[1](814/114412); Loss: 0.092475; Backpropagation: 0.2911 sec; Batch: 2.1208 sec
0.2033 0.1639 0.1374 0.1135 0.1014 0.0879 0.0789 0.0720 0.0693 0.0676 0.0664 0.0649 0.0641 0.0634 0.0629 0.0625 

[TRAIN] Epoch[1](815/114412); Loss: 0.075046; Backpropagation: 0.2914 sec; Batch: 2.1176 sec
0.1313 0.1024 0.0897 0.0817 0.0769 0.0728 0.0700 0.0680 0.0663 0.0652 0.0643 0.0635 0.0629 0.0623 0.0619 0.0616 

[TRAIN] Epoch[1](816/114412); Loss: 0.076390; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1119 0.0950 0.0875 0.0812 0.0774 0.0746 0.0727 0.0716 0.0706 0.0700 0.0693 0.0687 0.0683 0.0680 0.0678 0.0676 

[TRAIN] Epoch[1](817/114412); Loss: 0.039319; Backpropagation: 0.2920 sec; Batch: 2.1187 sec
0.1529 0.0776 0.0526 0.0372 0.0313 0.0286 0.0275 0.0265 0.0255 0.0250 0.0246 0.0243 0.0241 0.0238 0.0238 0.0238 

[TRAIN] Epoch[1](818/114412); Loss: 0.068685; Backpropagation: 0.2909 sec; Batch: 2.1234 sec
0.1346 0.1076 0.0891 0.0772 0.0686 0.0652 0.0613 0.0587 0.0573 0.0565 0.0557 0.0547 0.0538 0.0532 0.0528 0.0526 

[TRAIN] Epoch[1](819/114412); Loss: 0.071883; Backpropagation: 0.2911 sec; Batch: 2.0882 sec
0.1440 0.1070 0.0858 0.0787 0.0737 0.0683 0.0660 0.0634 0.0612 0.0599 0.0586 0.0579 0.0572 0.0565 0.0562 0.0557 

[TRAIN] Epoch[1](820/114412); Loss: 0.069072; Backpropagation: 0.2916 sec; Batch: 2.1246 sec
0.1368 0.1035 0.0844 0.0743 0.0712 0.0656 0.0621 0.0600 0.0585 0.0572 0.0567 0.0560 0.0552 0.0548 0.0545 0.0542 

[TRAIN] Epoch[1](821/114412); Loss: 0.061989; Backpropagation: 0.2914 sec; Batch: 2.0983 sec
0.1296 0.0860 0.0755 0.0668 0.0631 0.0585 0.0562 0.0545 0.0529 0.0515 0.0507 0.0501 0.0495 0.0492 0.0490 0.0487 

[TRAIN] Epoch[1](822/114412); Loss: 0.078472; Backpropagation: 0.2919 sec; Batch: 2.1257 sec
0.1461 0.1145 0.0956 0.0878 0.0809 0.0758 0.0731 0.0699 0.0680 0.0663 0.0648 0.0636 0.0629 0.0624 0.0620 0.0617 

[TRAIN] Epoch[1](823/114412); Loss: 0.048863; Backpropagation: 0.2914 sec; Batch: 2.1155 sec
0.1011 0.0693 0.0630 0.0528 0.0495 0.0459 0.0437 0.0426 0.0417 0.0408 0.0398 0.0392 0.0387 0.0382 0.0380 0.0374 

[TRAIN] Epoch[1](824/114412); Loss: 0.053380; Backpropagation: 0.2922 sec; Batch: 2.1197 sec
0.1230 0.0759 0.0691 0.0566 0.0533 0.0499 0.0477 0.0452 0.0443 0.0431 0.0428 0.0418 0.0411 0.0405 0.0400 0.0396 

[TRAIN] Epoch[1](825/114412); Loss: 0.056206; Backpropagation: 0.2924 sec; Batch: 2.1174 sec
0.1140 0.0851 0.0657 0.0608 0.0551 0.0516 0.0498 0.0486 0.0477 0.0471 0.0466 0.0461 0.0458 0.0454 0.0450 0.0449 

[TRAIN] Epoch[1](826/114412); Loss: 0.047712; Backpropagation: 0.2913 sec; Batch: 2.1128 sec
0.1438 0.0665 0.0527 0.0476 0.0430 0.0412 0.0396 0.0385 0.0377 0.0372 0.0366 0.0363 0.0360 0.0358 0.0355 0.0353 

[TRAIN] Epoch[1](827/114412); Loss: 0.058859; Backpropagation: 0.2911 sec; Batch: 2.1613 sec
0.1588 0.1091 0.0649 0.0665 0.0596 0.0552 0.0520 0.0471 0.0450 0.0432 0.0421 0.0409 0.0401 0.0395 0.0389 0.0386 

[TRAIN] Epoch[1](828/114412); Loss: 0.082477; Backpropagation: 0.2910 sec; Batch: 2.1106 sec
0.1554 0.1094 0.0960 0.0868 0.0820 0.0774 0.0759 0.0739 0.0727 0.0718 0.0708 0.0704 0.0698 0.0694 0.0692 0.0687 

[TRAIN] Epoch[1](829/114412); Loss: 0.081488; Backpropagation: 0.2909 sec; Batch: 2.1448 sec
0.1611 0.1033 0.0883 0.0849 0.0803 0.0759 0.0743 0.0728 0.0720 0.0714 0.0707 0.0703 0.0700 0.0696 0.0696 0.0693 

[TRAIN] Epoch[1](830/114412); Loss: 0.075397; Backpropagation: 0.2929 sec; Batch: 2.1124 sec
0.1550 0.1062 0.0916 0.0806 0.0745 0.0707 0.0683 0.0661 0.0643 0.0635 0.0625 0.0617 0.0611 0.0604 0.0601 0.0598 

[TRAIN] Epoch[1](831/114412); Loss: 0.054039; Backpropagation: 0.2911 sec; Batch: 2.1450 sec
0.1035 0.0871 0.0713 0.0601 0.0564 0.0528 0.0493 0.0468 0.0452 0.0437 0.0428 0.0421 0.0415 0.0411 0.0406 0.0403 

[TRAIN] Epoch[1](832/114412); Loss: 0.053571; Backpropagation: 0.2911 sec; Batch: 2.1198 sec
0.1396 0.0898 0.0688 0.0563 0.0524 0.0472 0.0450 0.0430 0.0417 0.0408 0.0399 0.0393 0.0388 0.0385 0.0381 0.0379 

[TRAIN] Epoch[1](833/114412); Loss: 0.061266; Backpropagation: 0.2914 sec; Batch: 2.1429 sec
0.1112 0.0933 0.0767 0.0667 0.0623 0.0580 0.0557 0.0541 0.0527 0.0517 0.0510 0.0502 0.0497 0.0494 0.0490 0.0487 

[TRAIN] Epoch[1](834/114412); Loss: 0.063812; Backpropagation: 0.2915 sec; Batch: 2.0846 sec
0.1279 0.1034 0.0806 0.0705 0.0647 0.0591 0.0563 0.0544 0.0530 0.0518 0.0512 0.0505 0.0499 0.0496 0.0492 0.0489 

[TRAIN] Epoch[1](835/114412); Loss: 0.069921; Backpropagation: 0.2913 sec; Batch: 2.1317 sec
0.1597 0.1093 0.0905 0.0778 0.0715 0.0651 0.0623 0.0590 0.0569 0.0553 0.0537 0.0532 0.0523 0.0513 0.0506 0.0503 

[TRAIN] Epoch[1](836/114412); Loss: 0.058499; Backpropagation: 0.2910 sec; Batch: 2.1146 sec
0.1282 0.0974 0.0744 0.0638 0.0594 0.0544 0.0515 0.0496 0.0476 0.0464 0.0454 0.0447 0.0439 0.0435 0.0430 0.0427 

[TRAIN] Epoch[1](837/114412); Loss: 0.054695; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1031 0.0813 0.0674 0.0616 0.0545 0.0515 0.0497 0.0480 0.0471 0.0459 0.0452 0.0448 0.0443 0.0439 0.0435 0.0433 

[TRAIN] Epoch[1](838/114412); Loss: 0.067244; Backpropagation: 0.2926 sec; Batch: 2.1147 sec
0.1298 0.1034 0.0840 0.0738 0.0682 0.0635 0.0604 0.0584 0.0568 0.0558 0.0550 0.0543 0.0537 0.0532 0.0529 0.0527 

[TRAIN] Epoch[1](839/114412); Loss: 0.054385; Backpropagation: 0.2939 sec; Batch: 2.0886 sec
0.1061 0.0857 0.0645 0.0562 0.0533 0.0502 0.0485 0.0473 0.0463 0.0455 0.0451 0.0446 0.0445 0.0443 0.0441 0.0440 

[TRAIN] Epoch[1](840/114412); Loss: 0.076366; Backpropagation: 0.2911 sec; Batch: 2.1339 sec
0.1317 0.1000 0.0882 0.0821 0.0769 0.0734 0.0713 0.0697 0.0684 0.0676 0.0667 0.0660 0.0654 0.0651 0.0648 0.0645 

[TRAIN] Epoch[1](841/114412); Loss: 0.065750; Backpropagation: 0.2948 sec; Batch: 2.1224 sec
0.1270 0.0895 0.0806 0.0695 0.0643 0.0619 0.0597 0.0582 0.0571 0.0562 0.0556 0.0551 0.0547 0.0544 0.0542 0.0540 

[TRAIN] Epoch[1](842/114412); Loss: 0.057524; Backpropagation: 0.2931 sec; Batch: 2.2809 sec
0.1060 0.0891 0.0669 0.0601 0.0574 0.0539 0.0522 0.0508 0.0499 0.0490 0.0483 0.0479 0.0476 0.0473 0.0470 0.0468 

[TRAIN] Epoch[1](843/114412); Loss: 0.060562; Backpropagation: 0.2909 sec; Batch: 2.1124 sec
0.1474 0.1019 0.0835 0.0729 0.0652 0.0589 0.0529 0.0496 0.0467 0.0446 0.0430 0.0417 0.0409 0.0403 0.0399 0.0395 

[TRAIN] Epoch[1](844/114412); Loss: 0.063075; Backpropagation: 0.2909 sec; Batch: 2.1729 sec
0.1215 0.0991 0.0819 0.0726 0.0675 0.0620 0.0565 0.0541 0.0523 0.0509 0.0499 0.0492 0.0486 0.0480 0.0477 0.0473 

[TRAIN] Epoch[1](845/114412); Loss: 0.056164; Backpropagation: 0.2961 sec; Batch: 2.3747 sec
0.1263 0.0887 0.0655 0.0598 0.0560 0.0514 0.0496 0.0479 0.0463 0.0454 0.0447 0.0443 0.0438 0.0433 0.0430 0.0427 

[TRAIN] Epoch[1](846/114412); Loss: 0.083370; Backpropagation: 0.2954 sec; Batch: 2.1029 sec
0.1591 0.1323 0.1131 0.1006 0.0884 0.0819 0.0789 0.0769 0.0698 0.0679 0.0672 0.0631 0.0610 0.0592 0.0578 0.0568 

[TRAIN] Epoch[1](847/114412); Loss: 0.060015; Backpropagation: 0.2959 sec; Batch: 2.1556 sec
0.1249 0.0996 0.0814 0.0687 0.0597 0.0552 0.0524 0.0505 0.0489 0.0475 0.0466 0.0459 0.0453 0.0449 0.0445 0.0441 

[TRAIN] Epoch[1](848/114412); Loss: 0.066339; Backpropagation: 0.2970 sec; Batch: 2.1265 sec
0.1113 0.1037 0.0899 0.0796 0.0706 0.0653 0.0633 0.0609 0.0566 0.0546 0.0530 0.0522 0.0512 0.0503 0.0498 0.0490 

[TRAIN] Epoch[1](849/114412); Loss: 0.053589; Backpropagation: 0.2959 sec; Batch: 2.1201 sec
0.1139 0.0790 0.0671 0.0576 0.0526 0.0502 0.0482 0.0464 0.0449 0.0441 0.0436 0.0429 0.0424 0.0419 0.0415 0.0412 

[TRAIN] Epoch[1](850/114412); Loss: 0.051831; Backpropagation: 0.2962 sec; Batch: 2.1251 sec
0.0993 0.0667 0.0602 0.0547 0.0510 0.0488 0.0473 0.0466 0.0457 0.0453 0.0448 0.0442 0.0440 0.0437 0.0436 0.0434 

[TRAIN] Epoch[1](851/114412); Loss: 0.075424; Backpropagation: 0.2953 sec; Batch: 2.1234 sec
0.1789 0.1071 0.0826 0.0734 0.0703 0.0685 0.0659 0.0645 0.0637 0.0630 0.0622 0.0618 0.0617 0.0612 0.0610 0.0609 

[TRAIN] Epoch[1](852/114412); Loss: 0.045496; Backpropagation: 0.2953 sec; Batch: 2.0987 sec
0.1059 0.0636 0.0537 0.0481 0.0433 0.0410 0.0398 0.0387 0.0380 0.0374 0.0370 0.0366 0.0364 0.0362 0.0361 0.0360 

[TRAIN] Epoch[1](853/114412); Loss: 0.085008; Backpropagation: 0.2954 sec; Batch: 2.1206 sec
0.1282 0.1077 0.0980 0.0920 0.0871 0.0834 0.0812 0.0796 0.0782 0.0769 0.0760 0.0754 0.0746 0.0741 0.0739 0.0736 

[TRAIN] Epoch[1](854/114412); Loss: 0.054622; Backpropagation: 0.2954 sec; Batch: 2.0810 sec
0.0983 0.0809 0.0689 0.0604 0.0543 0.0515 0.0495 0.0483 0.0472 0.0462 0.0457 0.0452 0.0448 0.0445 0.0442 0.0440 

[TRAIN] Epoch[1](855/114412); Loss: 0.046959; Backpropagation: 0.2977 sec; Batch: 2.0843 sec
0.1389 0.0690 0.0629 0.0509 0.0439 0.0404 0.0385 0.0366 0.0356 0.0347 0.0341 0.0336 0.0333 0.0331 0.0330 0.0328 

[TRAIN] Epoch[1](856/114412); Loss: 0.054491; Backpropagation: 0.2954 sec; Batch: 2.1226 sec
0.1174 0.0871 0.0720 0.0624 0.0541 0.0499 0.0470 0.0454 0.0441 0.0432 0.0426 0.0421 0.0416 0.0413 0.0409 0.0407 

[TRAIN] Epoch[1](857/114412); Loss: 0.061285; Backpropagation: 0.2957 sec; Batch: 2.1179 sec
0.1483 0.0940 0.0811 0.0685 0.0608 0.0566 0.0535 0.0514 0.0494 0.0477 0.0467 0.0458 0.0449 0.0445 0.0440 0.0435 

[TRAIN] Epoch[1](858/114412); Loss: 0.050718; Backpropagation: 0.2954 sec; Batch: 2.1249 sec
0.1124 0.0754 0.0618 0.0556 0.0496 0.0472 0.0448 0.0431 0.0422 0.0412 0.0406 0.0401 0.0397 0.0394 0.0392 0.0391 

[TRAIN] Epoch[1](859/114412); Loss: 0.058159; Backpropagation: 0.2958 sec; Batch: 2.1187 sec
0.1132 0.0865 0.0682 0.0657 0.0596 0.0543 0.0526 0.0509 0.0491 0.0486 0.0478 0.0476 0.0470 0.0466 0.0465 0.0462 

[TRAIN] Epoch[1](860/114412); Loss: 0.059910; Backpropagation: 0.2957 sec; Batch: 2.1248 sec
0.1096 0.0879 0.0746 0.0673 0.0611 0.0567 0.0540 0.0527 0.0517 0.0507 0.0499 0.0493 0.0488 0.0484 0.0481 0.0478 

[TRAIN] Epoch[1](861/114412); Loss: 0.075736; Backpropagation: 0.2963 sec; Batch: 2.1187 sec
0.1297 0.1036 0.0912 0.0831 0.0767 0.0732 0.0709 0.0688 0.0672 0.0660 0.0652 0.0644 0.0638 0.0632 0.0626 0.0621 

[TRAIN] Epoch[1](862/114412); Loss: 0.070932; Backpropagation: 0.2956 sec; Batch: 2.1208 sec
0.1224 0.1020 0.0861 0.0786 0.0729 0.0692 0.0664 0.0639 0.0623 0.0612 0.0601 0.0593 0.0585 0.0579 0.0573 0.0569 

[TRAIN] Epoch[1](863/114412); Loss: 0.054812; Backpropagation: 0.2985 sec; Batch: 2.1325 sec
0.1101 0.0755 0.0683 0.0609 0.0545 0.0513 0.0492 0.0479 0.0466 0.0459 0.0454 0.0449 0.0445 0.0442 0.0439 0.0439 

[TRAIN] Epoch[1](864/114412); Loss: 0.056585; Backpropagation: 0.2984 sec; Batch: 2.1210 sec
0.1221 0.0807 0.0661 0.0604 0.0567 0.0528 0.0506 0.0492 0.0479 0.0471 0.0464 0.0457 0.0454 0.0450 0.0447 0.0445 

[TRAIN] Epoch[1](865/114412); Loss: 0.048027; Backpropagation: 0.2985 sec; Batch: 2.1255 sec
0.0991 0.0650 0.0573 0.0514 0.0480 0.0450 0.0430 0.0419 0.0410 0.0405 0.0400 0.0395 0.0395 0.0392 0.0391 0.0390 

[TRAIN] Epoch[1](866/114412); Loss: 0.046826; Backpropagation: 0.2957 sec; Batch: 2.1180 sec
0.1198 0.0816 0.0617 0.0503 0.0450 0.0415 0.0392 0.0376 0.0363 0.0355 0.0346 0.0340 0.0335 0.0331 0.0329 0.0326 

[TRAIN] Epoch[1](867/114412); Loss: 0.040324; Backpropagation: 0.2956 sec; Batch: 2.1331 sec
0.1056 0.0580 0.0487 0.0446 0.0402 0.0369 0.0347 0.0334 0.0320 0.0314 0.0310 0.0303 0.0300 0.0297 0.0294 0.0294 

[TRAIN] Epoch[1](868/114412); Loss: 0.068992; Backpropagation: 0.2982 sec; Batch: 2.0995 sec
0.1466 0.0983 0.0790 0.0716 0.0686 0.0651 0.0616 0.0605 0.0592 0.0581 0.0571 0.0565 0.0559 0.0556 0.0552 0.0548 

[TRAIN] Epoch[1](869/114412); Loss: 0.071584; Backpropagation: 0.2960 sec; Batch: 2.1236 sec
0.1679 0.1143 0.0862 0.0750 0.0667 0.0621 0.0609 0.0595 0.0583 0.0578 0.0570 0.0565 0.0563 0.0558 0.0555 0.0554 

[TRAIN] Epoch[1](870/114412); Loss: 0.055931; Backpropagation: 0.2953 sec; Batch: 2.1252 sec
0.1039 0.0791 0.0694 0.0620 0.0563 0.0529 0.0509 0.0496 0.0484 0.0476 0.0469 0.0462 0.0458 0.0455 0.0452 0.0450 

[TRAIN] Epoch[1](871/114412); Loss: 0.045574; Backpropagation: 0.2963 sec; Batch: 2.1219 sec
0.1033 0.0749 0.0620 0.0519 0.0448 0.0412 0.0392 0.0372 0.0362 0.0353 0.0347 0.0343 0.0339 0.0337 0.0333 0.0332 

[TRAIN] Epoch[1](872/114412); Loss: 0.063757; Backpropagation: 0.2962 sec; Batch: 2.1220 sec
0.1151 0.0876 0.0771 0.0690 0.0646 0.0622 0.0592 0.0575 0.0562 0.0548 0.0541 0.0535 0.0528 0.0524 0.0520 0.0518 

[TRAIN] Epoch[1](873/114412); Loss: 0.065649; Backpropagation: 0.2957 sec; Batch: 2.0914 sec
0.1450 0.0953 0.0803 0.0695 0.0636 0.0610 0.0579 0.0566 0.0552 0.0540 0.0533 0.0525 0.0520 0.0517 0.0514 0.0511 

[TRAIN] Epoch[1](874/114412); Loss: 0.068255; Backpropagation: 0.2957 sec; Batch: 2.1561 sec
0.1094 0.0850 0.0806 0.0734 0.0702 0.0676 0.0655 0.0636 0.0624 0.0613 0.0604 0.0598 0.0591 0.0584 0.0579 0.0574 

[TRAIN] Epoch[1](875/114412); Loss: 0.063625; Backpropagation: 0.2941 sec; Batch: 2.0895 sec
0.1355 0.0935 0.0771 0.0692 0.0638 0.0592 0.0567 0.0548 0.0537 0.0526 0.0517 0.0510 0.0504 0.0500 0.0496 0.0492 

[TRAIN] Epoch[1](876/114412); Loss: 0.068187; Backpropagation: 0.2959 sec; Batch: 2.1196 sec
0.1711 0.1013 0.0898 0.0816 0.0705 0.0629 0.0603 0.0561 0.0537 0.0521 0.0503 0.0495 0.0488 0.0480 0.0476 0.0472 

[TRAIN] Epoch[1](877/114412); Loss: 0.058016; Backpropagation: 0.2956 sec; Batch: 2.1202 sec
0.1164 0.0925 0.0808 0.0651 0.0576 0.0533 0.0508 0.0492 0.0477 0.0465 0.0459 0.0452 0.0447 0.0446 0.0442 0.0439 

[TRAIN] Epoch[1](878/114412); Loss: 0.057056; Backpropagation: 0.2958 sec; Batch: 2.1175 sec
0.1264 0.0784 0.0703 0.0626 0.0559 0.0532 0.0511 0.0491 0.0482 0.0471 0.0464 0.0458 0.0452 0.0448 0.0444 0.0441 

[TRAIN] Epoch[1](879/114412); Loss: 0.075663; Backpropagation: 0.2963 sec; Batch: 2.1185 sec
0.1288 0.0910 0.0848 0.0794 0.0762 0.0733 0.0713 0.0698 0.0687 0.0680 0.0675 0.0671 0.0666 0.0663 0.0660 0.0657 

[TRAIN] Epoch[1](880/114412); Loss: 0.096098; Backpropagation: 0.2959 sec; Batch: 2.1214 sec
0.1545 0.1260 0.1155 0.1082 0.1028 0.0959 0.0915 0.0888 0.0864 0.0845 0.0828 0.0819 0.0808 0.0800 0.0793 0.0788 

[TRAIN] Epoch[1](881/114412); Loss: 0.070502; Backpropagation: 0.2954 sec; Batch: 2.1206 sec
0.1128 0.1107 0.0964 0.0832 0.0725 0.0688 0.0648 0.0623 0.0602 0.0590 0.0578 0.0570 0.0563 0.0557 0.0554 0.0551 

[TRAIN] Epoch[1](882/114412); Loss: 0.057895; Backpropagation: 0.2960 sec; Batch: 2.1299 sec
0.1090 0.0859 0.0839 0.0729 0.0619 0.0547 0.0515 0.0502 0.0483 0.0465 0.0454 0.0444 0.0437 0.0430 0.0427 0.0423 

[TRAIN] Epoch[1](883/114412); Loss: 0.082961; Backpropagation: 0.2959 sec; Batch: 2.1205 sec
0.1393 0.1137 0.0999 0.0896 0.0825 0.0806 0.0783 0.0757 0.0740 0.0722 0.0712 0.0706 0.0704 0.0702 0.0698 0.0693 

[TRAIN] Epoch[1](884/114412); Loss: 0.067991; Backpropagation: 0.2961 sec; Batch: 2.1214 sec
0.1169 0.0939 0.0871 0.0769 0.0712 0.0652 0.0625 0.0618 0.0598 0.0583 0.0569 0.0563 0.0558 0.0555 0.0551 0.0548 

[TRAIN] Epoch[1](885/114412); Loss: 0.072720; Backpropagation: 0.3011 sec; Batch: 2.1358 sec
0.1305 0.0999 0.0917 0.0812 0.0803 0.0746 0.0702 0.0665 0.0634 0.0610 0.0594 0.0584 0.0573 0.0567 0.0563 0.0560 

[TRAIN] Epoch[1](886/114412); Loss: 0.061876; Backpropagation: 0.2979 sec; Batch: 2.1223 sec
0.1618 0.1151 0.0811 0.0673 0.0592 0.0561 0.0524 0.0489 0.0471 0.0459 0.0441 0.0434 0.0426 0.0420 0.0417 0.0413 

[TRAIN] Epoch[1](887/114412); Loss: 0.079376; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.1447 0.1170 0.1029 0.0890 0.0831 0.0768 0.0739 0.0706 0.0682 0.0667 0.0649 0.0639 0.0630 0.0622 0.0618 0.0614 

[TRAIN] Epoch[1](888/114412); Loss: 0.069044; Backpropagation: 0.2963 sec; Batch: 2.1205 sec
0.1464 0.1068 0.0877 0.0774 0.0734 0.0674 0.0638 0.0601 0.0572 0.0552 0.0537 0.0524 0.0516 0.0510 0.0505 0.0500 

[TRAIN] Epoch[1](889/114412); Loss: 0.083632; Backpropagation: 0.2960 sec; Batch: 2.1214 sec
0.1649 0.1250 0.1107 0.0979 0.0906 0.0850 0.0780 0.0733 0.0694 0.0669 0.0654 0.0640 0.0627 0.0619 0.0613 0.0610 

[TRAIN] Epoch[1](890/114412); Loss: 0.063764; Backpropagation: 0.3009 sec; Batch: 2.1314 sec
0.1185 0.0865 0.0816 0.0716 0.0662 0.0617 0.0587 0.0564 0.0550 0.0537 0.0528 0.0522 0.0516 0.0514 0.0512 0.0511 

[TRAIN] Epoch[1](891/114412); Loss: 0.093729; Backpropagation: 0.2983 sec; Batch: 2.1211 sec
0.1493 0.1261 0.1192 0.1085 0.1029 0.0990 0.0937 0.0905 0.0858 0.0834 0.0805 0.0767 0.0742 0.0720 0.0699 0.0678 

[TRAIN] Epoch[1](892/114412); Loss: 0.091191; Backpropagation: 0.2981 sec; Batch: 2.1215 sec
0.1834 0.1306 0.1093 0.1018 0.0974 0.0914 0.0877 0.0833 0.0793 0.0770 0.0748 0.0732 0.0712 0.0683 0.0659 0.0644 

[TRAIN] Epoch[1](893/114412); Loss: 0.084834; Backpropagation: 0.2958 sec; Batch: 2.1190 sec
0.1459 0.1143 0.1115 0.1021 0.0938 0.0861 0.0811 0.0769 0.0738 0.0712 0.0696 0.0679 0.0668 0.0661 0.0653 0.0648 

[TRAIN] Epoch[1](894/114412); Loss: 0.086800; Backpropagation: 0.2959 sec; Batch: 2.1174 sec
0.1833 0.1366 0.1168 0.1088 0.0960 0.0885 0.0803 0.0742 0.0699 0.0671 0.0648 0.0631 0.0617 0.0603 0.0593 0.0583 

[TRAIN] Epoch[1](895/114412); Loss: 0.090317; Backpropagation: 0.2958 sec; Batch: 2.1015 sec
0.1771 0.1370 0.1173 0.1047 0.0909 0.0833 0.0818 0.0807 0.0777 0.0745 0.0730 0.0713 0.0699 0.0695 0.0686 0.0679 

[TRAIN] Epoch[1](896/114412); Loss: 0.059181; Backpropagation: 0.2958 sec; Batch: 2.1215 sec
0.1289 0.0905 0.0814 0.0714 0.0662 0.0592 0.0526 0.0486 0.0467 0.0452 0.0443 0.0433 0.0428 0.0423 0.0419 0.0416 

[TRAIN] Epoch[1](897/114412); Loss: 0.084080; Backpropagation: 0.2960 sec; Batch: 2.1253 sec
0.1770 0.1320 0.1065 0.0947 0.0877 0.0807 0.0757 0.0714 0.0691 0.0678 0.0660 0.0647 0.0638 0.0633 0.0626 0.0623 

[TRAIN] Epoch[1](898/114412); Loss: 0.084880; Backpropagation: 0.2956 sec; Batch: 2.1596 sec
0.1722 0.1383 0.1116 0.0960 0.0849 0.0790 0.0758 0.0720 0.0703 0.0681 0.0670 0.0659 0.0651 0.0644 0.0639 0.0634 

[TRAIN] Epoch[1](899/114412); Loss: 0.067141; Backpropagation: 0.2957 sec; Batch: 2.1175 sec
0.1380 0.1010 0.0807 0.0726 0.0671 0.0623 0.0601 0.0581 0.0568 0.0559 0.0548 0.0542 0.0537 0.0533 0.0529 0.0527 

[TRAIN] Epoch[1](900/114412); Loss: 0.087065; Backpropagation: 0.2946 sec; Batch: 2.1476 sec
0.1657 0.1280 0.1133 0.0987 0.0907 0.0826 0.0802 0.0767 0.0739 0.0722 0.0706 0.0694 0.0687 0.0679 0.0674 0.0669 

[TRAIN] Epoch[1](901/114412); Loss: 0.063787; Backpropagation: 0.2958 sec; Batch: 2.1134 sec
0.1113 0.0932 0.0814 0.0713 0.0684 0.0619 0.0594 0.0571 0.0553 0.0538 0.0527 0.0520 0.0513 0.0509 0.0504 0.0501 

[TRAIN] Epoch[1](902/114412); Loss: 0.072903; Backpropagation: 0.2958 sec; Batch: 2.1469 sec
0.1506 0.1182 0.0939 0.0775 0.0695 0.0672 0.0648 0.0622 0.0606 0.0591 0.0583 0.0576 0.0571 0.0568 0.0565 0.0564 

[TRAIN] Epoch[1](903/114412); Loss: 0.091886; Backpropagation: 0.3011 sec; Batch: 2.1324 sec
0.1642 0.1317 0.1128 0.0997 0.0916 0.0876 0.0847 0.0820 0.0802 0.0789 0.0778 0.0769 0.0764 0.0757 0.0753 0.0749 

[TRAIN] Epoch[1](904/114412); Loss: 0.085754; Backpropagation: 0.3006 sec; Batch: 2.1030 sec
0.1531 0.1219 0.1053 0.0950 0.0889 0.0828 0.0799 0.0761 0.0746 0.0732 0.0718 0.0710 0.0703 0.0698 0.0694 0.0692 

[TRAIN] Epoch[1](905/114412); Loss: 0.065082; Backpropagation: 0.3006 sec; Batch: 2.1269 sec
0.1092 0.0927 0.0746 0.0697 0.0650 0.0626 0.0606 0.0588 0.0577 0.0570 0.0565 0.0559 0.0555 0.0553 0.0552 0.0550 

[TRAIN] Epoch[1](906/114412); Loss: 0.055796; Backpropagation: 0.2980 sec; Batch: 2.1227 sec
0.1134 0.0840 0.0705 0.0608 0.0567 0.0536 0.0505 0.0487 0.0471 0.0458 0.0452 0.0442 0.0438 0.0433 0.0428 0.0424 

[TRAIN] Epoch[1](907/114412); Loss: 0.071546; Backpropagation: 0.2959 sec; Batch: 2.1192 sec
0.1072 0.1003 0.0864 0.0806 0.0745 0.0713 0.0683 0.0656 0.0638 0.0630 0.0620 0.0611 0.0608 0.0603 0.0599 0.0596 

[TRAIN] Epoch[1](908/114412); Loss: 0.070024; Backpropagation: 0.3009 sec; Batch: 2.1228 sec
0.1134 0.1089 0.0873 0.0759 0.0712 0.0683 0.0655 0.0631 0.0613 0.0601 0.0591 0.0584 0.0577 0.0572 0.0567 0.0563 

[TRAIN] Epoch[1](909/114412); Loss: 0.052447; Backpropagation: 0.2960 sec; Batch: 2.1313 sec
0.1070 0.0749 0.0646 0.0549 0.0530 0.0495 0.0475 0.0461 0.0444 0.0438 0.0430 0.0425 0.0423 0.0420 0.0419 0.0418 

[TRAIN] Epoch[1](910/114412); Loss: 0.071631; Backpropagation: 0.2959 sec; Batch: 2.1223 sec
0.1489 0.1090 0.0859 0.0797 0.0741 0.0694 0.0645 0.0618 0.0599 0.0585 0.0575 0.0567 0.0558 0.0553 0.0548 0.0543 

[TRAIN] Epoch[1](911/114412); Loss: 0.070816; Backpropagation: 0.2953 sec; Batch: 2.1210 sec
0.1415 0.1032 0.0856 0.0779 0.0721 0.0668 0.0638 0.0617 0.0604 0.0595 0.0581 0.0574 0.0569 0.0564 0.0560 0.0557 

[TRAIN] Epoch[1](912/114412); Loss: 0.050320; Backpropagation: 0.2958 sec; Batch: 2.1187 sec
0.0964 0.0849 0.0668 0.0553 0.0528 0.0478 0.0461 0.0432 0.0420 0.0405 0.0397 0.0389 0.0382 0.0378 0.0374 0.0371 

[TRAIN] Epoch[1](913/114412); Loss: 0.065190; Backpropagation: 0.2957 sec; Batch: 2.1216 sec
0.1161 0.0977 0.0799 0.0732 0.0673 0.0630 0.0609 0.0580 0.0565 0.0554 0.0540 0.0533 0.0526 0.0521 0.0518 0.0514 

[TRAIN] Epoch[1](914/114412); Loss: 0.058899; Backpropagation: 0.2955 sec; Batch: 2.1204 sec
0.1241 0.0942 0.0671 0.0622 0.0587 0.0563 0.0527 0.0506 0.0495 0.0483 0.0474 0.0470 0.0465 0.0462 0.0460 0.0457 

[TRAIN] Epoch[1](915/114412); Loss: 0.092125; Backpropagation: 0.2975 sec; Batch: 2.1201 sec
0.1858 0.1458 0.1196 0.0937 0.0940 0.0863 0.0821 0.0789 0.0771 0.0755 0.0742 0.0735 0.0726 0.0721 0.0716 0.0712 

[TRAIN] Epoch[1](916/114412); Loss: 0.060165; Backpropagation: 0.2957 sec; Batch: 2.1198 sec
0.1283 0.1028 0.0765 0.0676 0.0603 0.0563 0.0539 0.0508 0.0490 0.0477 0.0465 0.0456 0.0451 0.0445 0.0440 0.0437 

[TRAIN] Epoch[1](917/114412); Loss: 0.067225; Backpropagation: 0.2955 sec; Batch: 2.1187 sec
0.1354 0.1013 0.0830 0.0714 0.0671 0.0619 0.0607 0.0584 0.0568 0.0559 0.0550 0.0544 0.0540 0.0536 0.0534 0.0531 

[TRAIN] Epoch[1](918/114412); Loss: 0.067551; Backpropagation: 0.3004 sec; Batch: 2.1246 sec
0.1291 0.1091 0.0878 0.0771 0.0720 0.0658 0.0615 0.0596 0.0568 0.0552 0.0534 0.0522 0.0512 0.0506 0.0499 0.0496 

[TRAIN] Epoch[1](919/114412); Loss: 0.051643; Backpropagation: 0.2983 sec; Batch: 2.1241 sec
0.1008 0.0859 0.0628 0.0559 0.0518 0.0491 0.0468 0.0444 0.0441 0.0425 0.0416 0.0411 0.0404 0.0400 0.0398 0.0395 

[TRAIN] Epoch[1](920/114412); Loss: 0.084156; Backpropagation: 0.2957 sec; Batch: 2.1217 sec
0.1594 0.1350 0.1082 0.0981 0.0893 0.0818 0.0764 0.0741 0.0712 0.0686 0.0677 0.0656 0.0644 0.0635 0.0618 0.0612 

[TRAIN] Epoch[1](921/114412); Loss: 0.050265; Backpropagation: 0.2959 sec; Batch: 2.1182 sec
0.0943 0.0796 0.0652 0.0569 0.0520 0.0486 0.0464 0.0441 0.0426 0.0417 0.0403 0.0396 0.0389 0.0383 0.0380 0.0377 

[TRAIN] Epoch[1](922/114412); Loss: 0.065410; Backpropagation: 0.2979 sec; Batch: 2.1231 sec
0.1249 0.1066 0.0863 0.0737 0.0668 0.0634 0.0597 0.0573 0.0553 0.0534 0.0519 0.0508 0.0500 0.0493 0.0487 0.0483 

[TRAIN] Epoch[1](923/114412); Loss: 0.061831; Backpropagation: 0.2953 sec; Batch: 2.1152 sec
0.1200 0.1005 0.0809 0.0681 0.0645 0.0595 0.0565 0.0544 0.0521 0.0505 0.0491 0.0481 0.0472 0.0467 0.0459 0.0454 

[TRAIN] Epoch[1](924/114412); Loss: 0.090883; Backpropagation: 0.2955 sec; Batch: 2.1221 sec
0.1439 0.1333 0.1161 0.1014 0.0954 0.0899 0.0859 0.0828 0.0799 0.0783 0.0770 0.0755 0.0745 0.0740 0.0734 0.0729 

[TRAIN] Epoch[1](925/114412); Loss: 0.051818; Backpropagation: 0.2954 sec; Batch: 2.0813 sec
0.0914 0.0742 0.0666 0.0560 0.0524 0.0502 0.0482 0.0462 0.0452 0.0442 0.0435 0.0430 0.0425 0.0422 0.0418 0.0415 

[TRAIN] Epoch[1](926/114412); Loss: 0.049853; Backpropagation: 0.2956 sec; Batch: 2.1213 sec
0.1440 0.0963 0.0555 0.0499 0.0476 0.0432 0.0402 0.0387 0.0373 0.0363 0.0358 0.0353 0.0349 0.0345 0.0343 0.0341 

[TRAIN] Epoch[1](927/114412); Loss: 0.043441; Backpropagation: 0.2957 sec; Batch: 2.0811 sec
0.0888 0.0745 0.0537 0.0493 0.0439 0.0406 0.0379 0.0365 0.0355 0.0347 0.0341 0.0337 0.0334 0.0330 0.0328 0.0326 

[TRAIN] Epoch[1](928/114412); Loss: 0.057719; Backpropagation: 0.2955 sec; Batch: 2.1619 sec
0.1191 0.0993 0.0762 0.0672 0.0596 0.0551 0.0512 0.0486 0.0466 0.0452 0.0440 0.0432 0.0428 0.0423 0.0417 0.0413 

[TRAIN] Epoch[1](929/114412); Loss: 0.057709; Backpropagation: 0.2956 sec; Batch: 2.1704 sec
0.1184 0.0971 0.0767 0.0647 0.0567 0.0535 0.0509 0.0489 0.0471 0.0460 0.0453 0.0445 0.0439 0.0436 0.0432 0.0429 

[TRAIN] Epoch[1](930/114412); Loss: 0.068726; Backpropagation: 0.2978 sec; Batch: 2.1296 sec
0.1377 0.1059 0.0880 0.0770 0.0695 0.0653 0.0623 0.0599 0.0586 0.0574 0.0555 0.0541 0.0531 0.0522 0.0517 0.0514 

[TRAIN] Epoch[1](931/114412); Loss: 0.083706; Backpropagation: 0.2954 sec; Batch: 2.0813 sec
0.1515 0.1257 0.1066 0.0923 0.0842 0.0789 0.0760 0.0736 0.0720 0.0708 0.0696 0.0687 0.0681 0.0675 0.0671 0.0667 

[TRAIN] Epoch[1](932/114412); Loss: 0.064677; Backpropagation: 0.2953 sec; Batch: 2.0845 sec
0.1091 0.0906 0.0769 0.0708 0.0675 0.0645 0.0609 0.0582 0.0568 0.0557 0.0550 0.0544 0.0540 0.0538 0.0534 0.0532 

[TRAIN] Epoch[1](933/114412); Loss: 0.066584; Backpropagation: 0.2953 sec; Batch: 2.0860 sec
0.1280 0.0980 0.0809 0.0725 0.0671 0.0629 0.0607 0.0582 0.0568 0.0561 0.0553 0.0546 0.0542 0.0538 0.0533 0.0530 

[TRAIN] Epoch[1](934/114412); Loss: 0.058446; Backpropagation: 0.2959 sec; Batch: 2.1089 sec
0.1123 0.0892 0.0774 0.0693 0.0624 0.0574 0.0543 0.0512 0.0490 0.0471 0.0460 0.0450 0.0443 0.0437 0.0433 0.0431 

[TRAIN] Epoch[1](935/114412); Loss: 0.071406; Backpropagation: 0.2955 sec; Batch: 2.0809 sec
0.1396 0.1119 0.0916 0.0787 0.0729 0.0678 0.0641 0.0608 0.0595 0.0585 0.0575 0.0568 0.0562 0.0558 0.0555 0.0553 

[TRAIN] Epoch[1](936/114412); Loss: 0.059185; Backpropagation: 0.2955 sec; Batch: 2.1186 sec
0.1255 0.1083 0.0863 0.0676 0.0591 0.0545 0.0496 0.0473 0.0457 0.0450 0.0440 0.0435 0.0431 0.0427 0.0424 0.0423 

[TRAIN] Epoch[1](937/114412); Loss: 0.070855; Backpropagation: 0.2957 sec; Batch: 2.0824 sec
0.1254 0.1019 0.0887 0.0783 0.0729 0.0692 0.0657 0.0626 0.0614 0.0602 0.0592 0.0585 0.0579 0.0575 0.0573 0.0570 

[TRAIN] Epoch[1](938/114412); Loss: 0.058772; Backpropagation: 0.2955 sec; Batch: 2.0840 sec
0.1081 0.0910 0.0762 0.0668 0.0608 0.0559 0.0538 0.0516 0.0499 0.0485 0.0475 0.0469 0.0464 0.0460 0.0456 0.0453 

[TRAIN] Epoch[1](939/114412); Loss: 0.059428; Backpropagation: 0.2957 sec; Batch: 2.0890 sec
0.1128 0.0922 0.0781 0.0673 0.0610 0.0567 0.0536 0.0514 0.0499 0.0486 0.0477 0.0471 0.0466 0.0463 0.0458 0.0456 

[TRAIN] Epoch[1](940/114412); Loss: 0.057556; Backpropagation: 0.2981 sec; Batch: 2.1242 sec
0.1190 0.0900 0.0764 0.0653 0.0595 0.0540 0.0514 0.0493 0.0474 0.0461 0.0452 0.0444 0.0438 0.0432 0.0430 0.0427 

[TRAIN] Epoch[1](941/114412); Loss: 0.050705; Backpropagation: 0.2981 sec; Batch: 2.1248 sec
0.1033 0.0747 0.0614 0.0575 0.0499 0.0474 0.0459 0.0439 0.0428 0.0418 0.0411 0.0408 0.0405 0.0403 0.0400 0.0399 

[TRAIN] Epoch[1](942/114412); Loss: 0.065513; Backpropagation: 0.3006 sec; Batch: 2.1270 sec
0.1283 0.1007 0.0811 0.0713 0.0638 0.0602 0.0586 0.0568 0.0557 0.0547 0.0539 0.0535 0.0531 0.0524 0.0522 0.0520 

[TRAIN] Epoch[1](943/114412); Loss: 0.064406; Backpropagation: 0.3005 sec; Batch: 2.1295 sec
0.1233 0.0971 0.0781 0.0712 0.0648 0.0617 0.0587 0.0564 0.0549 0.0538 0.0530 0.0524 0.0519 0.0514 0.0511 0.0508 

[TRAIN] Epoch[1](944/114412); Loss: 0.081629; Backpropagation: 0.2957 sec; Batch: 2.1203 sec
0.1515 0.1290 0.1109 0.0974 0.0848 0.0774 0.0726 0.0692 0.0673 0.0657 0.0647 0.0641 0.0635 0.0630 0.0626 0.0624 

[TRAIN] Epoch[1](945/114412); Loss: 0.047995; Backpropagation: 0.2952 sec; Batch: 2.1147 sec
0.1054 0.0783 0.0636 0.0549 0.0486 0.0443 0.0416 0.0401 0.0386 0.0376 0.0367 0.0363 0.0360 0.0356 0.0353 0.0351 

[TRAIN] Epoch[1](946/114412); Loss: 0.069469; Backpropagation: 0.2948 sec; Batch: 2.1199 sec
0.1301 0.1072 0.0906 0.0795 0.0721 0.0665 0.0632 0.0608 0.0587 0.0574 0.0559 0.0550 0.0543 0.0538 0.0535 0.0530 

[TRAIN] Epoch[1](947/114412); Loss: 0.036916; Backpropagation: 0.2991 sec; Batch: 2.1218 sec
0.0759 0.0597 0.0491 0.0411 0.0382 0.0352 0.0323 0.0310 0.0300 0.0293 0.0287 0.0283 0.0282 0.0280 0.0279 0.0277 

[TRAIN] Epoch[1](948/114412); Loss: 0.060291; Backpropagation: 0.2982 sec; Batch: 2.1314 sec
0.1135 0.0909 0.0797 0.0698 0.0637 0.0588 0.0557 0.0529 0.0504 0.0493 0.0483 0.0476 0.0467 0.0462 0.0458 0.0454 

[TRAIN] Epoch[1](949/114412); Loss: 0.049203; Backpropagation: 0.2952 sec; Batch: 2.1189 sec
0.0935 0.0752 0.0595 0.0510 0.0475 0.0460 0.0447 0.0435 0.0424 0.0416 0.0411 0.0407 0.0405 0.0403 0.0400 0.0398 

[TRAIN] Epoch[1](950/114412); Loss: 0.061210; Backpropagation: 0.2973 sec; Batch: 2.2830 sec
0.1193 0.0975 0.0852 0.0729 0.0652 0.0591 0.0548 0.0520 0.0500 0.0486 0.0476 0.0466 0.0458 0.0454 0.0449 0.0445 

[TRAIN] Epoch[1](951/114412); Loss: 0.074594; Backpropagation: 0.2929 sec; Batch: 2.1203 sec
0.1671 0.1265 0.0918 0.0809 0.0736 0.0692 0.0651 0.0625 0.0605 0.0589 0.0580 0.0572 0.0564 0.0557 0.0552 0.0549 

[TRAIN] Epoch[1](952/114412); Loss: 0.088731; Backpropagation: 0.2905 sec; Batch: 2.1157 sec
0.1648 0.1325 0.1147 0.1033 0.0955 0.0896 0.0849 0.0812 0.0779 0.0736 0.0709 0.0686 0.0672 0.0658 0.0650 0.0642 

[TRAIN] Epoch[1](953/114412); Loss: 0.096453; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1519 0.1253 0.1093 0.1028 0.0976 0.0939 0.0913 0.0894 0.0882 0.0870 0.0861 0.0853 0.0846 0.0841 0.0835 0.0831 

[TRAIN] Epoch[1](954/114412); Loss: 0.061079; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1275 0.1035 0.0830 0.0718 0.0631 0.0580 0.0550 0.0518 0.0496 0.0478 0.0463 0.0452 0.0446 0.0440 0.0434 0.0428 

[TRAIN] Epoch[1](955/114412); Loss: 0.076020; Backpropagation: 0.2914 sec; Batch: 2.0795 sec
0.1454 0.1191 0.0931 0.0834 0.0754 0.0722 0.0697 0.0672 0.0652 0.0636 0.0626 0.0617 0.0606 0.0598 0.0590 0.0585 

[TRAIN] Epoch[1](956/114412); Loss: 0.089296; Backpropagation: 0.2907 sec; Batch: 2.1153 sec
0.1483 0.1277 0.1118 0.1018 0.0928 0.0876 0.0834 0.0810 0.0787 0.0768 0.0754 0.0744 0.0734 0.0726 0.0718 0.0712 

[TRAIN] Epoch[1](957/114412); Loss: 0.057274; Backpropagation: 0.2925 sec; Batch: 2.1218 sec
0.1174 0.0921 0.0745 0.0630 0.0566 0.0521 0.0503 0.0491 0.0479 0.0467 0.0459 0.0452 0.0445 0.0441 0.0437 0.0433 

[TRAIN] Epoch[1](958/114412); Loss: 0.053856; Backpropagation: 0.2928 sec; Batch: 2.1351 sec
0.1054 0.0891 0.0690 0.0594 0.0546 0.0504 0.0487 0.0465 0.0451 0.0441 0.0430 0.0423 0.0417 0.0412 0.0408 0.0404 

[TRAIN] Epoch[1](959/114412); Loss: 0.061319; Backpropagation: 0.2909 sec; Batch: 2.1159 sec
0.1262 0.1006 0.0861 0.0725 0.0648 0.0585 0.0549 0.0512 0.0496 0.0475 0.0467 0.0456 0.0451 0.0444 0.0439 0.0435 

[TRAIN] Epoch[1](960/114412); Loss: 0.082659; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1511 0.1150 0.1013 0.0903 0.0842 0.0799 0.0767 0.0742 0.0718 0.0704 0.0695 0.0686 0.0680 0.0675 0.0672 0.0669 

[TRAIN] Epoch[1](961/114412); Loss: 0.082423; Backpropagation: 0.2912 sec; Batch: 2.1208 sec
0.1405 0.1196 0.1043 0.0951 0.0879 0.0826 0.0783 0.0745 0.0718 0.0700 0.0683 0.0670 0.0657 0.0649 0.0644 0.0639 

[TRAIN] Epoch[1](962/114412); Loss: 0.068167; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1387 0.1169 0.0964 0.0830 0.0727 0.0658 0.0613 0.0574 0.0544 0.0521 0.0505 0.0496 0.0489 0.0483 0.0476 0.0470 

[TRAIN] Epoch[1](963/114412); Loss: 0.055217; Backpropagation: 0.2905 sec; Batch: 2.1171 sec
0.1044 0.0881 0.0735 0.0619 0.0557 0.0517 0.0497 0.0478 0.0463 0.0453 0.0447 0.0438 0.0431 0.0428 0.0425 0.0423 

[TRAIN] Epoch[1](964/114412); Loss: 0.064114; Backpropagation: 0.2912 sec; Batch: 2.1141 sec
0.1024 0.0903 0.0756 0.0711 0.0647 0.0617 0.0596 0.0585 0.0575 0.0565 0.0559 0.0552 0.0547 0.0544 0.0539 0.0538 

[TRAIN] Epoch[1](965/114412); Loss: 0.069564; Backpropagation: 0.2911 sec; Batch: 2.1263 sec
0.1381 0.1132 0.0854 0.0746 0.0681 0.0645 0.0612 0.0593 0.0581 0.0573 0.0565 0.0559 0.0554 0.0552 0.0551 0.0552 

[TRAIN] Epoch[1](966/114412); Loss: 0.075449; Backpropagation: 0.2911 sec; Batch: 2.0856 sec
0.1398 0.1181 0.0969 0.0833 0.0763 0.0723 0.0691 0.0658 0.0642 0.0625 0.0613 0.0605 0.0598 0.0594 0.0591 0.0588 

[TRAIN] Epoch[1](967/114412); Loss: 0.091218; Backpropagation: 0.2910 sec; Batch: 2.0787 sec
0.1569 0.1322 0.1095 0.0987 0.0920 0.0884 0.0850 0.0825 0.0803 0.0787 0.0777 0.0767 0.0760 0.0754 0.0751 0.0746 

[TRAIN] Epoch[1](968/114412); Loss: 0.066253; Backpropagation: 0.2914 sec; Batch: 2.1196 sec
0.1283 0.1061 0.0877 0.0754 0.0687 0.0619 0.0599 0.0570 0.0550 0.0536 0.0526 0.0518 0.0510 0.0506 0.0503 0.0501 

[TRAIN] Epoch[1](969/114412); Loss: 0.073241; Backpropagation: 0.2925 sec; Batch: 2.0794 sec
0.1463 0.1125 0.0917 0.0783 0.0722 0.0703 0.0658 0.0634 0.0617 0.0611 0.0600 0.0589 0.0583 0.0577 0.0571 0.0567 

[TRAIN] Epoch[1](970/114412); Loss: 0.081300; Backpropagation: 0.2916 sec; Batch: 2.0860 sec
0.1826 0.1444 0.1186 0.0999 0.0886 0.0775 0.0700 0.0656 0.0612 0.0588 0.0574 0.0567 0.0562 0.0549 0.0545 0.0540 

[TRAIN] Epoch[1](971/114412); Loss: 0.080325; Backpropagation: 0.2914 sec; Batch: 2.1288 sec
0.1496 0.1248 0.1047 0.0931 0.0840 0.0779 0.0729 0.0699 0.0678 0.0661 0.0647 0.0634 0.0626 0.0619 0.0610 0.0607 

[TRAIN] Epoch[1](972/114412); Loss: 0.068689; Backpropagation: 0.2902 sec; Batch: 2.1143 sec
0.1209 0.0989 0.0802 0.0790 0.0718 0.0654 0.0634 0.0615 0.0601 0.0589 0.0577 0.0571 0.0565 0.0562 0.0560 0.0555 

[TRAIN] Epoch[1](973/114412); Loss: 0.070910; Backpropagation: 0.2911 sec; Batch: 2.1194 sec
0.1538 0.1239 0.0938 0.0760 0.0687 0.0668 0.0629 0.0602 0.0579 0.0560 0.0544 0.0532 0.0524 0.0519 0.0515 0.0512 

[TRAIN] Epoch[1](974/114412); Loss: 0.079359; Backpropagation: 0.2926 sec; Batch: 2.0987 sec
0.1362 0.1152 0.0998 0.0927 0.0829 0.0774 0.0722 0.0695 0.0683 0.0672 0.0665 0.0652 0.0648 0.0643 0.0639 0.0636 

[TRAIN] Epoch[1](975/114412); Loss: 0.045239; Backpropagation: 0.2915 sec; Batch: 2.1180 sec
0.0989 0.0715 0.0523 0.0518 0.0460 0.0413 0.0393 0.0385 0.0369 0.0363 0.0357 0.0353 0.0352 0.0349 0.0348 0.0350 

[TRAIN] Epoch[1](976/114412); Loss: 0.064904; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1347 0.1107 0.0848 0.0792 0.0689 0.0622 0.0576 0.0540 0.0520 0.0504 0.0494 0.0485 0.0474 0.0467 0.0462 0.0459 

[TRAIN] Epoch[1](977/114412); Loss: 0.078308; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1668 0.1393 0.1149 0.1041 0.0883 0.0799 0.0700 0.0649 0.0603 0.0565 0.0537 0.0530 0.0517 0.0508 0.0498 0.0490 

[TRAIN] Epoch[1](978/114412); Loss: 0.054338; Backpropagation: 0.2909 sec; Batch: 2.1302 sec
0.1093 0.0876 0.0681 0.0590 0.0545 0.0513 0.0483 0.0466 0.0455 0.0449 0.0436 0.0429 0.0422 0.0420 0.0418 0.0419 

[TRAIN] Epoch[1](979/114412); Loss: 0.052822; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.1222 0.0864 0.0642 0.0590 0.0554 0.0509 0.0465 0.0441 0.0430 0.0412 0.0401 0.0394 0.0389 0.0383 0.0378 0.0376 

[TRAIN] Epoch[1](980/114412); Loss: 0.077566; Backpropagation: 0.2914 sec; Batch: 2.1180 sec
0.1291 0.1130 0.0927 0.0853 0.0809 0.0758 0.0737 0.0701 0.0677 0.0667 0.0662 0.0650 0.0643 0.0638 0.0635 0.0632 

[TRAIN] Epoch[1](981/114412); Loss: 0.102868; Backpropagation: 0.2909 sec; Batch: 2.1150 sec
0.1504 0.1358 0.1261 0.1192 0.1137 0.1071 0.1019 0.0994 0.0953 0.0904 0.0885 0.0863 0.0848 0.0834 0.0824 0.0814 

[TRAIN] Epoch[1](982/114412); Loss: 0.084608; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1387 0.1193 0.1055 0.0980 0.0923 0.0827 0.0809 0.0789 0.0744 0.0718 0.0706 0.0693 0.0686 0.0679 0.0676 0.0673 

[TRAIN] Epoch[1](983/114412); Loss: 0.062040; Backpropagation: 0.2932 sec; Batch: 2.1186 sec
0.1002 0.0836 0.0789 0.0752 0.0683 0.0634 0.0602 0.0575 0.0544 0.0531 0.0517 0.0504 0.0496 0.0492 0.0486 0.0483 

[TRAIN] Epoch[1](984/114412); Loss: 0.100069; Backpropagation: 0.2928 sec; Batch: 2.1055 sec
0.1692 0.1527 0.1384 0.1264 0.1190 0.1107 0.1017 0.0884 0.0845 0.0790 0.0779 0.0746 0.0716 0.0692 0.0688 0.0689 

[TRAIN] Epoch[1](985/114412); Loss: 0.075613; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1434 0.1277 0.1106 0.1034 0.0891 0.0802 0.0707 0.0647 0.0599 0.0576 0.0549 0.0522 0.0501 0.0492 0.0484 0.0476 

[TRAIN] Epoch[1](986/114412); Loss: 0.080383; Backpropagation: 0.2956 sec; Batch: 2.1211 sec
0.1374 0.1196 0.1052 0.0961 0.0824 0.0780 0.0750 0.0719 0.0684 0.0666 0.0656 0.0652 0.0644 0.0638 0.0634 0.0630 

[TRAIN] Epoch[1](987/114412); Loss: 0.084261; Backpropagation: 0.2929 sec; Batch: 2.1226 sec
0.1531 0.1382 0.1230 0.1070 0.0967 0.0873 0.0794 0.0737 0.0705 0.0666 0.0634 0.0601 0.0587 0.0574 0.0568 0.0563 

[TRAIN] Epoch[1](988/114412); Loss: 0.076919; Backpropagation: 0.2913 sec; Batch: 2.1158 sec
0.1282 0.1133 0.0993 0.0922 0.0853 0.0784 0.0737 0.0699 0.0662 0.0642 0.0626 0.0606 0.0601 0.0595 0.0588 0.0585 

[TRAIN] Epoch[1](989/114412); Loss: 0.065756; Backpropagation: 0.2931 sec; Batch: 2.1202 sec
0.1395 0.1188 0.0905 0.0803 0.0719 0.0625 0.0589 0.0539 0.0517 0.0492 0.0473 0.0463 0.0458 0.0454 0.0452 0.0450 

[TRAIN] Epoch[1](990/114412); Loss: 0.093063; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.1370 0.1259 0.1209 0.1157 0.1041 0.0958 0.0903 0.0860 0.0824 0.0801 0.0785 0.0766 0.0753 0.0741 0.0735 0.0729 

[TRAIN] Epoch[1](991/114412); Loss: 0.067361; Backpropagation: 0.2931 sec; Batch: 2.1343 sec
0.1169 0.1133 0.1003 0.0874 0.0719 0.0659 0.0611 0.0584 0.0536 0.0522 0.0515 0.0505 0.0494 0.0488 0.0484 0.0481 

[TRAIN] Epoch[1](992/114412); Loss: 0.063383; Backpropagation: 0.2913 sec; Batch: 2.1155 sec
0.1255 0.1059 0.0915 0.0753 0.0671 0.0603 0.0557 0.0534 0.0515 0.0495 0.0482 0.0475 0.0463 0.0458 0.0455 0.0452 

[TRAIN] Epoch[1](993/114412); Loss: 0.075684; Backpropagation: 0.2908 sec; Batch: 2.1138 sec
0.1306 0.1085 0.0968 0.0857 0.0776 0.0727 0.0693 0.0668 0.0652 0.0642 0.0633 0.0627 0.0623 0.0619 0.0617 0.0615 

[TRAIN] Epoch[1](994/114412); Loss: 0.068993; Backpropagation: 0.2906 sec; Batch: 2.0853 sec
0.1302 0.1141 0.0947 0.0812 0.0694 0.0644 0.0593 0.0578 0.0561 0.0551 0.0546 0.0540 0.0535 0.0532 0.0531 0.0532 

[TRAIN] Epoch[1](995/114412); Loss: 0.079151; Backpropagation: 0.2907 sec; Batch: 2.1177 sec
0.1668 0.1407 0.1200 0.0931 0.0833 0.0734 0.0674 0.0657 0.0607 0.0592 0.0579 0.0577 0.0559 0.0554 0.0547 0.0543 

[TRAIN] Epoch[1](996/114412); Loss: 0.067372; Backpropagation: 0.2955 sec; Batch: 2.1258 sec
0.1195 0.1126 0.1018 0.0838 0.0730 0.0647 0.0596 0.0562 0.0540 0.0520 0.0513 0.0507 0.0502 0.0498 0.0495 0.0492 

[TRAIN] Epoch[1](997/114412); Loss: 0.081527; Backpropagation: 0.2933 sec; Batch: 2.2152 sec
0.1274 0.1122 0.0967 0.0875 0.0838 0.0791 0.0756 0.0740 0.0731 0.0720 0.0715 0.0708 0.0705 0.0702 0.0700 0.0699 

[TRAIN] Epoch[1](998/114412); Loss: 0.072522; Backpropagation: 0.2908 sec; Batch: 2.1000 sec
0.1304 0.1123 0.0962 0.0872 0.0758 0.0694 0.0658 0.0630 0.0605 0.0588 0.0580 0.0574 0.0568 0.0565 0.0561 0.0560 

[TRAIN] Epoch[1](999/114412); Loss: 0.077145; Backpropagation: 0.2926 sec; Batch: 2.1227 sec
0.1226 0.1144 0.1071 0.0909 0.0822 0.0757 0.0730 0.0675 0.0662 0.0645 0.0635 0.0624 0.0620 0.0613 0.0607 0.0604 

[TRAIN] Epoch[1](1000/114412); Loss: 0.062492; Backpropagation: 0.2914 sec; Batch: 2.1223 sec
0.1029 0.0871 0.0783 0.0709 0.0645 0.0610 0.0585 0.0566 0.0553 0.0541 0.0530 0.0523 0.0519 0.0515 0.0512 0.0509 

[TRAIN] Epoch[1](1001/114412); Loss: 0.064997; Backpropagation: 0.2936 sec; Batch: 2.1270 sec
0.1333 0.1037 0.0802 0.0662 0.0618 0.0569 0.0594 0.0566 0.0555 0.0535 0.0529 0.0523 0.0520 0.0522 0.0519 0.0514 

[TRAIN] Epoch[1](1002/114412); Loss: 0.055357; Backpropagation: 0.3089 sec; Batch: 2.1049 sec
0.1105 0.0863 0.0732 0.0645 0.0560 0.0518 0.0488 0.0473 0.0461 0.0449 0.0438 0.0432 0.0428 0.0425 0.0422 0.0420 

[TRAIN] Epoch[1](1003/114412); Loss: 0.071310; Backpropagation: 0.2908 sec; Batch: 2.1142 sec
0.1223 0.1066 0.0889 0.0791 0.0739 0.0672 0.0642 0.0628 0.0618 0.0605 0.0598 0.0594 0.0590 0.0587 0.0585 0.0584 

[TRAIN] Epoch[1](1004/114412); Loss: 0.041093; Backpropagation: 0.2920 sec; Batch: 2.0803 sec
0.0772 0.0702 0.0547 0.0434 0.0400 0.0375 0.0355 0.0346 0.0338 0.0335 0.0332 0.0330 0.0329 0.0327 0.0327 0.0326 

[TRAIN] Epoch[1](1005/114412); Loss: 0.067680; Backpropagation: 0.2929 sec; Batch: 2.1173 sec
0.1111 0.0977 0.0859 0.0739 0.0691 0.0647 0.0621 0.0610 0.0589 0.0583 0.0575 0.0570 0.0568 0.0566 0.0564 0.0561 

[TRAIN] Epoch[1](1006/114412); Loss: 0.055894; Backpropagation: 0.2956 sec; Batch: 2.1234 sec
0.1050 0.0879 0.0754 0.0631 0.0567 0.0525 0.0495 0.0481 0.0470 0.0461 0.0452 0.0444 0.0439 0.0435 0.0432 0.0428 

[TRAIN] Epoch[1](1007/114412); Loss: 0.061798; Backpropagation: 0.2929 sec; Batch: 2.1152 sec
0.1130 0.1049 0.0918 0.0755 0.0644 0.0560 0.0539 0.0523 0.0503 0.0486 0.0478 0.0470 0.0464 0.0459 0.0456 0.0455 

[TRAIN] Epoch[1](1008/114412); Loss: 0.063755; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1379 0.1072 0.0862 0.0781 0.0695 0.0618 0.0552 0.0526 0.0497 0.0481 0.0471 0.0464 0.0457 0.0452 0.0448 0.0446 

[TRAIN] Epoch[1](1009/114412); Loss: 0.079621; Backpropagation: 0.2908 sec; Batch: 2.1160 sec
0.1246 0.1096 0.0926 0.0847 0.0788 0.0756 0.0742 0.0729 0.0715 0.0707 0.0703 0.0700 0.0698 0.0697 0.0696 0.0693 

[TRAIN] Epoch[1](1010/114412); Loss: 0.084551; Backpropagation: 0.2915 sec; Batch: 2.1015 sec
0.1552 0.1294 0.1147 0.0980 0.0927 0.0839 0.0769 0.0723 0.0698 0.0681 0.0670 0.0660 0.0654 0.0649 0.0644 0.0641 

[TRAIN] Epoch[1](1011/114412); Loss: 0.047840; Backpropagation: 0.2928 sec; Batch: 2.1181 sec
0.0875 0.0718 0.0613 0.0542 0.0499 0.0461 0.0441 0.0418 0.0407 0.0399 0.0390 0.0385 0.0381 0.0378 0.0375 0.0373 

[TRAIN] Epoch[1](1012/114412); Loss: 0.078224; Backpropagation: 0.2930 sec; Batch: 2.1170 sec
0.1245 0.1132 0.1029 0.0892 0.0820 0.0772 0.0731 0.0706 0.0685 0.0666 0.0656 0.0649 0.0642 0.0636 0.0631 0.0627 

[TRAIN] Epoch[1](1013/114412); Loss: 0.072574; Backpropagation: 0.2933 sec; Batch: 2.1171 sec
0.1759 0.1415 0.1098 0.0841 0.0719 0.0625 0.0578 0.0570 0.0539 0.0527 0.0509 0.0501 0.0489 0.0485 0.0480 0.0475 

[TRAIN] Epoch[1](1014/114412); Loss: 0.086017; Backpropagation: 0.2909 sec; Batch: 2.1156 sec
0.1428 0.1204 0.1031 0.0932 0.0878 0.0851 0.0808 0.0783 0.0761 0.0751 0.0738 0.0730 0.0723 0.0718 0.0715 0.0712 

[TRAIN] Epoch[1](1015/114412); Loss: 0.054089; Backpropagation: 0.2912 sec; Batch: 2.0981 sec
0.0856 0.0765 0.0697 0.0621 0.0571 0.0528 0.0512 0.0496 0.0483 0.0466 0.0455 0.0447 0.0444 0.0441 0.0438 0.0436 

[TRAIN] Epoch[1](1016/114412); Loss: 0.071001; Backpropagation: 0.2927 sec; Batch: 2.1159 sec
0.1364 0.1285 0.1089 0.0856 0.0728 0.0667 0.0620 0.0589 0.0563 0.0541 0.0528 0.0516 0.0510 0.0506 0.0501 0.0497 

[TRAIN] Epoch[1](1017/114412); Loss: 0.081524; Backpropagation: 0.2930 sec; Batch: 2.1237 sec
0.1601 0.1265 0.1087 0.0902 0.0831 0.0763 0.0728 0.0703 0.0680 0.0666 0.0653 0.0645 0.0637 0.0632 0.0628 0.0623 

[TRAIN] Epoch[1](1018/114412); Loss: 0.067170; Backpropagation: 0.2910 sec; Batch: 2.0770 sec
0.1579 0.1304 0.1106 0.0886 0.0710 0.0615 0.0552 0.0504 0.0485 0.0463 0.0443 0.0436 0.0426 0.0417 0.0412 0.0408 

[TRAIN] Epoch[1](1019/114412); Loss: 0.069276; Backpropagation: 0.2913 sec; Batch: 2.0779 sec
0.1315 0.1146 0.0953 0.0779 0.0693 0.0639 0.0615 0.0588 0.0574 0.0563 0.0552 0.0545 0.0538 0.0532 0.0529 0.0525 

[TRAIN] Epoch[1](1020/114412); Loss: 0.093713; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1811 0.1522 0.1243 0.1092 0.0957 0.0873 0.0830 0.0794 0.0771 0.0753 0.0743 0.0734 0.0725 0.0720 0.0716 0.0712 

[TRAIN] Epoch[1](1021/114412); Loss: 0.073063; Backpropagation: 0.2925 sec; Batch: 2.1185 sec
0.1253 0.1050 0.0902 0.0803 0.0730 0.0698 0.0673 0.0655 0.0642 0.0629 0.0622 0.0614 0.0609 0.0605 0.0604 0.0600 

[TRAIN] Epoch[1](1022/114412); Loss: 0.072032; Backpropagation: 0.2928 sec; Batch: 2.1218 sec
0.1235 0.1055 0.0935 0.0804 0.0759 0.0696 0.0678 0.0645 0.0629 0.0609 0.0599 0.0590 0.0582 0.0575 0.0569 0.0565 

[TRAIN] Epoch[1](1023/114412); Loss: 0.080720; Backpropagation: 0.2909 sec; Batch: 2.1159 sec
0.1416 0.1210 0.1051 0.0910 0.0871 0.0823 0.0776 0.0718 0.0700 0.0673 0.0655 0.0643 0.0630 0.0620 0.0612 0.0608 

[TRAIN] Epoch[1](1024/114412); Loss: 0.055734; Backpropagation: 0.2911 sec; Batch: 2.1138 sec
0.1076 0.0874 0.0746 0.0660 0.0563 0.0519 0.0488 0.0470 0.0461 0.0450 0.0443 0.0440 0.0436 0.0432 0.0429 0.0429 

[TRAIN] Epoch[1](1025/114412); Loss: 0.059674; Backpropagation: 0.2905 sec; Batch: 2.1165 sec
0.1169 0.0899 0.0695 0.0649 0.0598 0.0567 0.0541 0.0522 0.0511 0.0501 0.0495 0.0488 0.0483 0.0480 0.0476 0.0474 

[TRAIN] Epoch[1](1026/114412); Loss: 0.056457; Backpropagation: 0.2942 sec; Batch: 2.1190 sec
0.1055 0.0829 0.0723 0.0626 0.0572 0.0525 0.0518 0.0496 0.0487 0.0474 0.0466 0.0459 0.0455 0.0452 0.0449 0.0448 

[TRAIN] Epoch[1](1027/114412); Loss: 0.068705; Backpropagation: 0.2926 sec; Batch: 2.0802 sec
0.1232 0.1085 0.0960 0.0794 0.0694 0.0639 0.0614 0.0584 0.0571 0.0559 0.0555 0.0548 0.0543 0.0540 0.0539 0.0537 

[TRAIN] Epoch[1](1028/114412); Loss: 0.092980; Backpropagation: 0.2908 sec; Batch: 2.0790 sec
0.1379 0.1211 0.1182 0.1038 0.1000 0.0934 0.0916 0.0876 0.0839 0.0810 0.0801 0.0791 0.0782 0.0778 0.0772 0.0767 

[TRAIN] Epoch[1](1029/114412); Loss: 0.061396; Backpropagation: 0.2905 sec; Batch: 2.1158 sec
0.1023 0.0872 0.0844 0.0678 0.0628 0.0583 0.0554 0.0545 0.0540 0.0527 0.0520 0.0512 0.0506 0.0501 0.0498 0.0494 

[TRAIN] Epoch[1](1030/114412); Loss: 0.070970; Backpropagation: 0.2910 sec; Batch: 2.1149 sec
0.1178 0.0864 0.0847 0.0742 0.0710 0.0679 0.0664 0.0649 0.0643 0.0636 0.0632 0.0629 0.0624 0.0622 0.0619 0.0616 

[TRAIN] Epoch[1](1031/114412); Loss: 0.096909; Backpropagation: 0.2931 sec; Batch: 2.1162 sec
0.1811 0.1524 0.1256 0.1089 0.0946 0.0902 0.0869 0.0847 0.0822 0.0804 0.0795 0.0782 0.0772 0.0767 0.0762 0.0759 

[TRAIN] Epoch[1](1032/114412); Loss: 0.089674; Backpropagation: 0.2915 sec; Batch: 2.1191 sec
0.1369 0.1207 0.1065 0.0977 0.0890 0.0873 0.0838 0.0826 0.0812 0.0800 0.0796 0.0786 0.0783 0.0778 0.0775 0.0773 

[TRAIN] Epoch[1](1033/114412); Loss: 0.074114; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1450 0.1203 0.0938 0.0817 0.0784 0.0694 0.0671 0.0638 0.0612 0.0602 0.0589 0.0582 0.0575 0.0570 0.0568 0.0564 

[TRAIN] Epoch[1](1034/114412); Loss: 0.054599; Backpropagation: 0.2906 sec; Batch: 2.1163 sec
0.1076 0.0781 0.0685 0.0599 0.0552 0.0524 0.0501 0.0474 0.0467 0.0454 0.0447 0.0441 0.0437 0.0435 0.0432 0.0432 

[TRAIN] Epoch[1](1035/114412); Loss: 0.048834; Backpropagation: 0.2912 sec; Batch: 2.1193 sec
0.1024 0.0787 0.0741 0.0515 0.0491 0.0451 0.0422 0.0411 0.0390 0.0377 0.0375 0.0370 0.0367 0.0367 0.0362 0.0363 

[TRAIN] Epoch[1](1036/114412); Loss: 0.049351; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1087 0.0689 0.0723 0.0543 0.0507 0.0451 0.0430 0.0418 0.0398 0.0390 0.0386 0.0382 0.0378 0.0374 0.0371 0.0370 

[TRAIN] Epoch[1](1037/114412); Loss: 0.067730; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1358 0.0977 0.0879 0.0732 0.0677 0.0642 0.0600 0.0588 0.0572 0.0562 0.0553 0.0547 0.0542 0.0539 0.0536 0.0532 

[TRAIN] Epoch[1](1038/114412); Loss: 0.091637; Backpropagation: 0.2912 sec; Batch: 2.1471 sec
0.1770 0.1425 0.1256 0.1087 0.0961 0.0892 0.0826 0.0789 0.0754 0.0734 0.0725 0.0706 0.0696 0.0686 0.0682 0.0675 

[TRAIN] Epoch[1](1039/114412); Loss: 0.084457; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1508 0.1276 0.1082 0.0917 0.0831 0.0790 0.0765 0.0743 0.0727 0.0713 0.0706 0.0700 0.0695 0.0690 0.0686 0.0683 

[TRAIN] Epoch[1](1040/114412); Loss: 0.089702; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1714 0.1386 0.1154 0.0989 0.0901 0.0856 0.0806 0.0784 0.0764 0.0745 0.0732 0.0719 0.0709 0.0702 0.0697 0.0694 

[TRAIN] Epoch[1](1041/114412); Loss: 0.066939; Backpropagation: 0.2907 sec; Batch: 2.1141 sec
0.1112 0.0966 0.0888 0.0751 0.0692 0.0654 0.0624 0.0603 0.0587 0.0573 0.0562 0.0553 0.0546 0.0539 0.0532 0.0528 

[TRAIN] Epoch[1](1042/114412); Loss: 0.065634; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1342 0.0955 0.0893 0.0738 0.0679 0.0622 0.0590 0.0566 0.0548 0.0532 0.0524 0.0514 0.0506 0.0502 0.0497 0.0495 

[TRAIN] Epoch[1](1043/114412); Loss: 0.070519; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1399 0.1057 0.0944 0.0801 0.0716 0.0688 0.0654 0.0618 0.0595 0.0574 0.0561 0.0550 0.0542 0.0534 0.0527 0.0522 

[TRAIN] Epoch[1](1044/114412); Loss: 0.090312; Backpropagation: 0.2910 sec; Batch: 2.1184 sec
0.1654 0.1324 0.1232 0.1080 0.0993 0.0899 0.0824 0.0794 0.0758 0.0737 0.0720 0.0705 0.0694 0.0684 0.0680 0.0673 

[TRAIN] Epoch[1](1045/114412); Loss: 0.080737; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1335 0.1153 0.0992 0.0875 0.0775 0.0755 0.0744 0.0729 0.0717 0.0708 0.0700 0.0694 0.0690 0.0687 0.0684 0.0682 

[TRAIN] Epoch[1](1046/114412); Loss: 0.049474; Backpropagation: 0.2908 sec; Batch: 2.1169 sec
0.1141 0.1004 0.0846 0.0612 0.0493 0.0415 0.0388 0.0364 0.0357 0.0340 0.0336 0.0330 0.0326 0.0323 0.0322 0.0320 

[TRAIN] Epoch[1](1047/114412); Loss: 0.090568; Backpropagation: 0.2909 sec; Batch: 2.1210 sec
0.1572 0.1187 0.1087 0.0969 0.0924 0.0869 0.0853 0.0827 0.0809 0.0796 0.0784 0.0775 0.0768 0.0761 0.0757 0.0753 

[TRAIN] Epoch[1](1048/114412); Loss: 0.076815; Backpropagation: 0.2930 sec; Batch: 2.1190 sec
0.1103 0.1344 0.1224 0.0949 0.0781 0.0721 0.0670 0.0654 0.0636 0.0630 0.0617 0.0605 0.0597 0.0591 0.0587 0.0582 

[TRAIN] Epoch[1](1049/114412); Loss: 0.090478; Backpropagation: 0.2930 sec; Batch: 2.1154 sec
0.1466 0.1269 0.1180 0.0990 0.0899 0.0868 0.0840 0.0817 0.0800 0.0788 0.0776 0.0768 0.0760 0.0756 0.0750 0.0748 

[TRAIN] Epoch[1](1050/114412); Loss: 0.108617; Backpropagation: 0.2908 sec; Batch: 2.1148 sec
0.1798 0.1592 0.1395 0.1246 0.1121 0.1075 0.1001 0.0976 0.0944 0.0923 0.0913 0.0892 0.0889 0.0874 0.0875 0.0864 

[TRAIN] Epoch[1](1051/114412); Loss: 0.083801; Backpropagation: 0.2910 sec; Batch: 2.1150 sec
0.1478 0.1233 0.1112 0.0957 0.0873 0.0809 0.0772 0.0745 0.0732 0.0709 0.0691 0.0676 0.0666 0.0659 0.0652 0.0644 

[TRAIN] Epoch[1](1052/114412); Loss: 0.045357; Backpropagation: 0.2955 sec; Batch: 2.1326 sec
0.0938 0.0733 0.0649 0.0520 0.0458 0.0441 0.0411 0.0386 0.0369 0.0357 0.0348 0.0340 0.0333 0.0328 0.0325 0.0322 

[TRAIN] Epoch[1](1053/114412); Loss: 0.066030; Backpropagation: 0.2916 sec; Batch: 2.1180 sec
0.1450 0.0990 0.0839 0.0731 0.0686 0.0640 0.0592 0.0561 0.0544 0.0527 0.0518 0.0509 0.0501 0.0495 0.0493 0.0487 

[TRAIN] Epoch[1](1054/114412); Loss: 0.059131; Backpropagation: 0.2907 sec; Batch: 2.1165 sec
0.1343 0.0930 0.0736 0.0683 0.0606 0.0562 0.0519 0.0497 0.0478 0.0465 0.0454 0.0447 0.0441 0.0435 0.0434 0.0431 

[TRAIN] Epoch[1](1055/114412); Loss: 0.077693; Backpropagation: 0.2912 sec; Batch: 2.1145 sec
0.1673 0.1159 0.1017 0.0859 0.0780 0.0724 0.0694 0.0659 0.0646 0.0629 0.0616 0.0607 0.0600 0.0594 0.0588 0.0584 

[TRAIN] Epoch[1](1056/114412); Loss: 0.090496; Backpropagation: 0.2914 sec; Batch: 2.1125 sec
0.1762 0.1163 0.1010 0.0957 0.0905 0.0875 0.0840 0.0812 0.0799 0.0785 0.0775 0.0767 0.0761 0.0757 0.0755 0.0753 

[TRAIN] Epoch[1](1057/114412); Loss: 0.067840; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1655 0.1024 0.0830 0.0715 0.0662 0.0614 0.0585 0.0569 0.0556 0.0543 0.0535 0.0526 0.0518 0.0512 0.0507 0.0504 

[TRAIN] Epoch[1](1058/114412); Loss: 0.078253; Backpropagation: 0.2914 sec; Batch: 2.1187 sec
0.1602 0.1031 0.0880 0.0845 0.0787 0.0759 0.0725 0.0697 0.0676 0.0664 0.0655 0.0648 0.0642 0.0638 0.0637 0.0634 

[TRAIN] Epoch[1](1059/114412); Loss: 0.074497; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1619 0.1123 0.0914 0.0839 0.0742 0.0702 0.0660 0.0633 0.0616 0.0606 0.0595 0.0588 0.0580 0.0572 0.0568 0.0563 

[TRAIN] Epoch[1](1060/114412); Loss: 0.054433; Backpropagation: 0.2913 sec; Batch: 2.1287 sec
0.1339 0.1154 0.0756 0.0571 0.0539 0.0457 0.0438 0.0414 0.0404 0.0393 0.0384 0.0381 0.0374 0.0370 0.0367 0.0367 

[TRAIN] Epoch[1](1061/114412); Loss: 0.067514; Backpropagation: 0.2906 sec; Batch: 2.1201 sec
0.1510 0.1074 0.0892 0.0785 0.0728 0.0679 0.0623 0.0579 0.0548 0.0519 0.0503 0.0490 0.0476 0.0469 0.0465 0.0461 

[TRAIN] Epoch[1](1062/114412); Loss: 0.086919; Backpropagation: 0.2928 sec; Batch: 2.0800 sec
0.1715 0.1232 0.1049 0.0925 0.0853 0.0822 0.0786 0.0767 0.0751 0.0734 0.0727 0.0719 0.0713 0.0708 0.0705 0.0702 

[TRAIN] Epoch[1](1063/114412); Loss: 0.062280; Backpropagation: 0.2927 sec; Batch: 2.1185 sec
0.1597 0.1035 0.0778 0.0649 0.0600 0.0554 0.0525 0.0507 0.0494 0.0482 0.0471 0.0464 0.0458 0.0454 0.0451 0.0449 

[TRAIN] Epoch[1](1064/114412); Loss: 0.077024; Backpropagation: 0.2907 sec; Batch: 2.1137 sec
0.1813 0.1261 0.0969 0.0802 0.0753 0.0687 0.0663 0.0644 0.0622 0.0609 0.0598 0.0589 0.0584 0.0579 0.0576 0.0574 

[TRAIN] Epoch[1](1065/114412); Loss: 0.096750; Backpropagation: 0.2930 sec; Batch: 2.1183 sec
0.1593 0.1343 0.1192 0.1056 0.0993 0.0952 0.0917 0.0889 0.0868 0.0848 0.0830 0.0817 0.0806 0.0799 0.0791 0.0787 

[TRAIN] Epoch[1](1066/114412); Loss: 0.063176; Backpropagation: 0.2912 sec; Batch: 2.1153 sec
0.1562 0.1005 0.0705 0.0636 0.0587 0.0562 0.0542 0.0526 0.0517 0.0508 0.0501 0.0497 0.0494 0.0491 0.0489 0.0486 

[TRAIN] Epoch[1](1067/114412); Loss: 0.061637; Backpropagation: 0.2933 sec; Batch: 2.1219 sec
0.1160 0.0965 0.0790 0.0705 0.0639 0.0588 0.0564 0.0533 0.0515 0.0503 0.0493 0.0487 0.0483 0.0480 0.0479 0.0478 

[TRAIN] Epoch[1](1068/114412); Loss: 0.087845; Backpropagation: 0.2909 sec; Batch: 2.0960 sec
0.1561 0.1338 0.1142 0.1036 0.0959 0.0866 0.0817 0.0795 0.0742 0.0720 0.0711 0.0691 0.0679 0.0674 0.0665 0.0660 

[TRAIN] Epoch[1](1069/114412); Loss: 0.073914; Backpropagation: 0.2909 sec; Batch: 2.0977 sec
0.1432 0.1098 0.0893 0.0774 0.0725 0.0688 0.0664 0.0648 0.0636 0.0627 0.0619 0.0613 0.0608 0.0603 0.0600 0.0597 

[TRAIN] Epoch[1](1070/114412); Loss: 0.059593; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1410 0.0891 0.0790 0.0686 0.0605 0.0567 0.0517 0.0495 0.0480 0.0464 0.0454 0.0446 0.0439 0.0434 0.0430 0.0427 

[TRAIN] Epoch[1](1071/114412); Loss: 0.080880; Backpropagation: 0.2916 sec; Batch: 2.1173 sec
0.1807 0.1382 0.1169 0.0934 0.0774 0.0709 0.0677 0.0655 0.0636 0.0618 0.0612 0.0603 0.0597 0.0593 0.0589 0.0587 

[TRAIN] Epoch[1](1072/114412); Loss: 0.075447; Backpropagation: 0.2907 sec; Batch: 2.0770 sec
0.1545 0.1234 0.1010 0.0826 0.0737 0.0684 0.0653 0.0638 0.0619 0.0608 0.0600 0.0593 0.0587 0.0583 0.0579 0.0575 

[TRAIN] Epoch[1](1073/114412); Loss: 0.055279; Backpropagation: 0.2907 sec; Batch: 2.1279 sec
0.1133 0.0998 0.0827 0.0655 0.0571 0.0509 0.0477 0.0445 0.0430 0.0417 0.0410 0.0403 0.0398 0.0395 0.0391 0.0388 

[TRAIN] Epoch[1](1074/114412); Loss: 0.075068; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.1384 0.1180 0.1027 0.0904 0.0797 0.0744 0.0699 0.0652 0.0626 0.0607 0.0588 0.0578 0.0567 0.0559 0.0552 0.0546 

[TRAIN] Epoch[1](1075/114412); Loss: 0.069721; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1225 0.1124 0.1015 0.0790 0.0752 0.0669 0.0626 0.0609 0.0579 0.0568 0.0556 0.0544 0.0534 0.0529 0.0521 0.0516 

[TRAIN] Epoch[1](1076/114412); Loss: 0.072295; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1547 0.1376 0.1048 0.0852 0.0731 0.0650 0.0595 0.0570 0.0556 0.0538 0.0531 0.0525 0.0517 0.0513 0.0510 0.0508 

[TRAIN] Epoch[1](1077/114412); Loss: 0.082921; Backpropagation: 0.2911 sec; Batch: 2.1218 sec
0.1353 0.1271 0.1143 0.0997 0.0867 0.0801 0.0759 0.0729 0.0710 0.0689 0.0677 0.0666 0.0660 0.0654 0.0648 0.0644 

[TRAIN] Epoch[1](1078/114412); Loss: 0.038798; Backpropagation: 0.2914 sec; Batch: 2.1190 sec
0.0781 0.0773 0.0544 0.0446 0.0387 0.0345 0.0323 0.0311 0.0302 0.0295 0.0291 0.0287 0.0283 0.0280 0.0279 0.0277 

[TRAIN] Epoch[1](1079/114412); Loss: 0.060044; Backpropagation: 0.2952 sec; Batch: 2.1013 sec
0.1043 0.1094 0.0887 0.0709 0.0615 0.0566 0.0534 0.0506 0.0485 0.0471 0.0461 0.0455 0.0450 0.0447 0.0443 0.0441 

[TRAIN] Epoch[1](1080/114412); Loss: 0.056795; Backpropagation: 0.2932 sec; Batch: 2.1193 sec
0.1087 0.0970 0.0795 0.0672 0.0603 0.0560 0.0514 0.0482 0.0464 0.0446 0.0433 0.0424 0.0417 0.0412 0.0407 0.0403 

[TRAIN] Epoch[1](1081/114412); Loss: 0.053406; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.0941 0.0933 0.0825 0.0672 0.0543 0.0496 0.0474 0.0442 0.0429 0.0416 0.0408 0.0400 0.0395 0.0392 0.0390 0.0388 

[TRAIN] Epoch[1](1082/114412); Loss: 0.067599; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.0942 0.1150 0.0938 0.0802 0.0710 0.0662 0.0639 0.0608 0.0585 0.0568 0.0553 0.0543 0.0536 0.0530 0.0527 0.0523 

[TRAIN] Epoch[1](1083/114412); Loss: 0.067687; Backpropagation: 0.2914 sec; Batch: 2.1185 sec
0.1197 0.1133 0.0931 0.0804 0.0722 0.0653 0.0607 0.0570 0.0556 0.0542 0.0534 0.0527 0.0520 0.0515 0.0511 0.0507 

[TRAIN] Epoch[1](1084/114412); Loss: 0.071908; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1677 0.1586 0.1316 0.1036 0.0854 0.0706 0.0578 0.0476 0.0437 0.0427 0.0418 0.0407 0.0402 0.0399 0.0395 0.0392 

[TRAIN] Epoch[1](1085/114412); Loss: 0.079946; Backpropagation: 0.2911 sec; Batch: 2.1331 sec
0.1181 0.1098 0.0946 0.0862 0.0809 0.0775 0.0764 0.0742 0.0726 0.0716 0.0706 0.0702 0.0697 0.0693 0.0688 0.0686 

[TRAIN] Epoch[1](1086/114412); Loss: 0.071481; Backpropagation: 0.2909 sec; Batch: 2.1207 sec
0.1330 0.1178 0.0924 0.0801 0.0732 0.0674 0.0637 0.0613 0.0594 0.0581 0.0575 0.0569 0.0562 0.0558 0.0555 0.0552 

[TRAIN] Epoch[1](1087/114412); Loss: 0.050239; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.1258 0.0937 0.0682 0.0557 0.0508 0.0433 0.0428 0.0396 0.0377 0.0368 0.0359 0.0352 0.0348 0.0346 0.0346 0.0343 

[TRAIN] Epoch[1](1088/114412); Loss: 0.066005; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1259 0.1091 0.0852 0.0716 0.0671 0.0615 0.0590 0.0563 0.0550 0.0540 0.0532 0.0525 0.0520 0.0516 0.0512 0.0509 

[TRAIN] Epoch[1](1089/114412); Loss: 0.089963; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1308 0.1251 0.1084 0.1000 0.0939 0.0882 0.0847 0.0828 0.0809 0.0799 0.0790 0.0782 0.0775 0.0770 0.0766 0.0763 

[TRAIN] Epoch[1](1090/114412); Loss: 0.068177; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1235 0.1074 0.0845 0.0766 0.0708 0.0667 0.0623 0.0598 0.0584 0.0567 0.0557 0.0548 0.0540 0.0536 0.0531 0.0527 

[TRAIN] Epoch[1](1091/114412); Loss: 0.068925; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1147 0.1015 0.0807 0.0756 0.0697 0.0662 0.0638 0.0620 0.0606 0.0598 0.0590 0.0585 0.0581 0.0578 0.0575 0.0572 

[TRAIN] Epoch[1](1092/114412); Loss: 0.071044; Backpropagation: 0.2928 sec; Batch: 2.1229 sec
0.1340 0.1184 0.0918 0.0817 0.0719 0.0688 0.0647 0.0618 0.0594 0.0573 0.0560 0.0551 0.0546 0.0542 0.0537 0.0533 

[TRAIN] Epoch[1](1093/114412); Loss: 0.068455; Backpropagation: 0.2935 sec; Batch: 2.1349 sec
0.1229 0.1045 0.0883 0.0777 0.0704 0.0659 0.0625 0.0601 0.0588 0.0574 0.0562 0.0552 0.0546 0.0541 0.0536 0.0533 

[TRAIN] Epoch[1](1094/114412); Loss: 0.064854; Backpropagation: 0.2953 sec; Batch: 2.1059 sec
0.1306 0.1111 0.0895 0.0780 0.0665 0.0608 0.0574 0.0544 0.0524 0.0505 0.0493 0.0486 0.0479 0.0472 0.0467 0.0465 

[TRAIN] Epoch[1](1095/114412); Loss: 0.052753; Backpropagation: 0.2929 sec; Batch: 2.1149 sec
0.1066 0.0867 0.0688 0.0601 0.0543 0.0488 0.0466 0.0447 0.0429 0.0423 0.0414 0.0408 0.0404 0.0401 0.0398 0.0396 

[TRAIN] Epoch[1](1096/114412); Loss: 0.055935; Backpropagation: 0.2912 sec; Batch: 2.1202 sec
0.1002 0.0811 0.0678 0.0592 0.0561 0.0525 0.0509 0.0498 0.0487 0.0480 0.0474 0.0470 0.0468 0.0466 0.0465 0.0464 

[TRAIN] Epoch[1](1097/114412); Loss: 0.077224; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1520 0.1206 0.1009 0.0866 0.0763 0.0705 0.0682 0.0659 0.0643 0.0633 0.0625 0.0618 0.0611 0.0608 0.0605 0.0602 

[TRAIN] Epoch[1](1098/114412); Loss: 0.067733; Backpropagation: 0.2912 sec; Batch: 2.1350 sec
0.1253 0.1027 0.0847 0.0747 0.0686 0.0644 0.0619 0.0591 0.0574 0.0568 0.0560 0.0552 0.0547 0.0544 0.0541 0.0538 

[TRAIN] Epoch[1](1099/114412); Loss: 0.057979; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1505 0.1274 0.0974 0.0744 0.0585 0.0479 0.0446 0.0397 0.0381 0.0374 0.0364 0.0359 0.0355 0.0349 0.0346 0.0345 

[TRAIN] Epoch[1](1100/114412); Loss: 0.069109; Backpropagation: 0.2913 sec; Batch: 2.1199 sec
0.1297 0.1083 0.0824 0.0701 0.0675 0.0645 0.0623 0.0613 0.0597 0.0590 0.0580 0.0574 0.0569 0.0564 0.0562 0.0559 

[TRAIN] Epoch[1](1101/114412); Loss: 0.072375; Backpropagation: 0.2906 sec; Batch: 2.0792 sec
0.1337 0.1145 0.0959 0.0844 0.0780 0.0719 0.0681 0.0627 0.0595 0.0589 0.0568 0.0562 0.0553 0.0545 0.0542 0.0536 

[TRAIN] Epoch[1](1102/114412); Loss: 0.071974; Backpropagation: 0.2935 sec; Batch: 2.1154 sec
0.1146 0.1002 0.0856 0.0799 0.0745 0.0703 0.0674 0.0657 0.0643 0.0633 0.0623 0.0617 0.0611 0.0607 0.0602 0.0599 

[TRAIN] Epoch[1](1103/114412); Loss: 0.069370; Backpropagation: 0.2956 sec; Batch: 2.1223 sec
0.1236 0.1076 0.0825 0.0772 0.0707 0.0664 0.0634 0.0616 0.0601 0.0591 0.0578 0.0571 0.0564 0.0559 0.0555 0.0552 

[TRAIN] Epoch[1](1104/114412); Loss: 0.087659; Backpropagation: 0.2911 sec; Batch: 2.1378 sec
0.1866 0.1507 0.1229 0.1034 0.0864 0.0753 0.0742 0.0714 0.0692 0.0682 0.0674 0.0666 0.0659 0.0653 0.0647 0.0642 

[TRAIN] Epoch[1](1105/114412); Loss: 0.060067; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1145 0.0995 0.0777 0.0657 0.0612 0.0567 0.0544 0.0519 0.0503 0.0492 0.0480 0.0474 0.0467 0.0463 0.0460 0.0458 

[TRAIN] Epoch[1](1106/114412); Loss: 0.080691; Backpropagation: 0.2907 sec; Batch: 2.1156 sec
0.1349 0.1170 0.1010 0.0895 0.0813 0.0768 0.0744 0.0719 0.0705 0.0694 0.0686 0.0679 0.0674 0.0671 0.0668 0.0666 

[TRAIN] Epoch[1](1107/114412); Loss: 0.061709; Backpropagation: 0.2910 sec; Batch: 2.1224 sec
0.1370 0.1093 0.0747 0.0656 0.0596 0.0558 0.0539 0.0515 0.0504 0.0493 0.0477 0.0470 0.0467 0.0465 0.0462 0.0459 

[TRAIN] Epoch[1](1108/114412); Loss: 0.069014; Backpropagation: 0.2915 sec; Batch: 2.1179 sec
0.1323 0.1061 0.0888 0.0801 0.0735 0.0670 0.0623 0.0594 0.0576 0.0560 0.0550 0.0541 0.0536 0.0531 0.0528 0.0525 

[TRAIN] Epoch[1](1109/114412); Loss: 0.080545; Backpropagation: 0.2954 sec; Batch: 2.1199 sec
0.1187 0.1137 0.0957 0.0887 0.0824 0.0788 0.0764 0.0740 0.0725 0.0713 0.0706 0.0700 0.0694 0.0692 0.0688 0.0684 

[TRAIN] Epoch[1](1110/114412); Loss: 0.055605; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1123 0.1023 0.0792 0.0658 0.0591 0.0540 0.0484 0.0457 0.0440 0.0422 0.0411 0.0402 0.0395 0.0390 0.0386 0.0383 

[TRAIN] Epoch[1](1111/114412); Loss: 0.083475; Backpropagation: 0.2933 sec; Batch: 2.1039 sec
0.1405 0.1209 0.1055 0.0940 0.0871 0.0814 0.0783 0.0756 0.0736 0.0718 0.0701 0.0690 0.0680 0.0672 0.0665 0.0660 

[TRAIN] Epoch[1](1112/114412); Loss: 0.056126; Backpropagation: 0.2911 sec; Batch: 2.0829 sec
0.1045 0.0913 0.0672 0.0598 0.0552 0.0521 0.0505 0.0490 0.0479 0.0471 0.0466 0.0461 0.0455 0.0453 0.0450 0.0448 

[TRAIN] Epoch[1](1113/114412); Loss: 0.060722; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1294 0.1107 0.0888 0.0699 0.0651 0.0579 0.0524 0.0501 0.0478 0.0459 0.0442 0.0432 0.0424 0.0418 0.0412 0.0408 

[TRAIN] Epoch[1](1114/114412); Loss: 0.069493; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1528 0.1271 0.1029 0.0878 0.0786 0.0710 0.0634 0.0577 0.0530 0.0509 0.0471 0.0458 0.0447 0.0437 0.0429 0.0426 

[TRAIN] Epoch[1](1115/114412); Loss: 0.068579; Backpropagation: 0.2910 sec; Batch: 2.1240 sec
0.1153 0.0951 0.0838 0.0761 0.0703 0.0659 0.0638 0.0618 0.0605 0.0596 0.0588 0.0581 0.0575 0.0571 0.0568 0.0566 

[TRAIN] Epoch[1](1116/114412); Loss: 0.073276; Backpropagation: 0.2931 sec; Batch: 2.1166 sec
0.1364 0.1048 0.0811 0.0744 0.0729 0.0688 0.0671 0.0654 0.0649 0.0642 0.0631 0.0626 0.0622 0.0618 0.0615 0.0612 

[TRAIN] Epoch[1](1117/114412); Loss: 0.056820; Backpropagation: 0.2930 sec; Batch: 2.1220 sec
0.1172 0.0813 0.0690 0.0614 0.0569 0.0535 0.0513 0.0498 0.0484 0.0475 0.0466 0.0461 0.0455 0.0451 0.0449 0.0446 

[TRAIN] Epoch[1](1118/114412); Loss: 0.057139; Backpropagation: 0.2909 sec; Batch: 2.1192 sec
0.1104 0.0901 0.0724 0.0624 0.0562 0.0531 0.0512 0.0491 0.0479 0.0471 0.0466 0.0461 0.0457 0.0454 0.0452 0.0450 

[TRAIN] Epoch[1](1119/114412); Loss: 0.073670; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1357 0.0979 0.0839 0.0763 0.0734 0.0698 0.0678 0.0663 0.0653 0.0646 0.0637 0.0633 0.0630 0.0627 0.0626 0.0625 

[TRAIN] Epoch[1](1120/114412); Loss: 0.053677; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1101 0.0905 0.0711 0.0624 0.0541 0.0499 0.0478 0.0446 0.0435 0.0423 0.0415 0.0409 0.0404 0.0401 0.0399 0.0396 

[TRAIN] Epoch[1](1121/114412); Loss: 0.060864; Backpropagation: 0.2930 sec; Batch: 2.1153 sec
0.1505 0.1096 0.0838 0.0664 0.0587 0.0563 0.0519 0.0491 0.0468 0.0451 0.0441 0.0433 0.0426 0.0422 0.0419 0.0416 

[TRAIN] Epoch[1](1122/114412); Loss: 0.059459; Backpropagation: 0.2911 sec; Batch: 2.1206 sec
0.1262 0.0996 0.0840 0.0702 0.0624 0.0561 0.0514 0.0491 0.0472 0.0460 0.0450 0.0440 0.0434 0.0427 0.0422 0.0419 

[TRAIN] Epoch[1](1123/114412); Loss: 0.067577; Backpropagation: 0.2929 sec; Batch: 2.1352 sec
0.1266 0.1084 0.0870 0.0741 0.0683 0.0628 0.0602 0.0582 0.0571 0.0560 0.0552 0.0544 0.0538 0.0535 0.0530 0.0526 

[TRAIN] Epoch[1](1124/114412); Loss: 0.074754; Backpropagation: 0.2911 sec; Batch: 2.1191 sec
0.1403 0.1072 0.0927 0.0813 0.0776 0.0723 0.0688 0.0662 0.0644 0.0628 0.0620 0.0612 0.0605 0.0601 0.0596 0.0591 

[TRAIN] Epoch[1](1125/114412); Loss: 0.057464; Backpropagation: 0.2915 sec; Batch: 2.1017 sec
0.1417 0.1073 0.0746 0.0654 0.0552 0.0505 0.0477 0.0457 0.0439 0.0428 0.0420 0.0414 0.0409 0.0405 0.0401 0.0398 

[TRAIN] Epoch[1](1126/114412); Loss: 0.059779; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1220 0.0907 0.0815 0.0713 0.0638 0.0587 0.0554 0.0527 0.0497 0.0480 0.0464 0.0448 0.0438 0.0430 0.0426 0.0419 

[TRAIN] Epoch[1](1127/114412); Loss: 0.060389; Backpropagation: 0.2902 sec; Batch: 2.1126 sec
0.1223 0.1045 0.0912 0.0793 0.0671 0.0564 0.0533 0.0490 0.0463 0.0447 0.0436 0.0428 0.0421 0.0416 0.0411 0.0408 

[TRAIN] Epoch[1](1128/114412); Loss: 0.073336; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1445 0.1201 0.0970 0.0822 0.0745 0.0692 0.0651 0.0627 0.0606 0.0592 0.0582 0.0572 0.0563 0.0559 0.0554 0.0552 

[TRAIN] Epoch[1](1129/114412); Loss: 0.055688; Backpropagation: 0.2940 sec; Batch: 2.0809 sec
0.1225 0.1017 0.0799 0.0667 0.0578 0.0532 0.0485 0.0477 0.0434 0.0412 0.0400 0.0387 0.0381 0.0377 0.0372 0.0369 

[TRAIN] Epoch[1](1130/114412); Loss: 0.054827; Backpropagation: 0.2929 sec; Batch: 2.1203 sec
0.1336 0.0912 0.0671 0.0601 0.0543 0.0496 0.0470 0.0452 0.0439 0.0427 0.0418 0.0410 0.0404 0.0401 0.0398 0.0396 

[TRAIN] Epoch[1](1131/114412); Loss: 0.061360; Backpropagation: 0.2930 sec; Batch: 2.1172 sec
0.1196 0.0895 0.0740 0.0681 0.0614 0.0587 0.0561 0.0543 0.0528 0.0515 0.0507 0.0500 0.0494 0.0489 0.0485 0.0482 

[TRAIN] Epoch[1](1132/114412); Loss: 0.054159; Backpropagation: 0.2912 sec; Batch: 2.1156 sec
0.1059 0.0832 0.0649 0.0595 0.0546 0.0510 0.0490 0.0473 0.0459 0.0450 0.0445 0.0439 0.0435 0.0431 0.0428 0.0426 

[TRAIN] Epoch[1](1133/114412); Loss: 0.073678; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1313 0.1107 0.0892 0.0795 0.0745 0.0711 0.0681 0.0659 0.0643 0.0629 0.0618 0.0609 0.0603 0.0598 0.0594 0.0591 

[TRAIN] Epoch[1](1134/114412); Loss: 0.063736; Backpropagation: 0.2906 sec; Batch: 2.0811 sec
0.1247 0.0957 0.0803 0.0711 0.0658 0.0607 0.0579 0.0558 0.0541 0.0527 0.0518 0.0509 0.0504 0.0499 0.0493 0.0489 

[TRAIN] Epoch[1](1135/114412); Loss: 0.063100; Backpropagation: 0.2905 sec; Batch: 2.0781 sec
0.1113 0.0916 0.0755 0.0694 0.0630 0.0602 0.0584 0.0566 0.0552 0.0543 0.0534 0.0529 0.0524 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](1136/114412); Loss: 0.086387; Backpropagation: 0.2913 sec; Batch: 2.1196 sec
0.1921 0.1428 0.1094 0.0860 0.0839 0.0777 0.0750 0.0729 0.0710 0.0697 0.0686 0.0678 0.0671 0.0665 0.0660 0.0657 

[TRAIN] Epoch[1](1137/114412); Loss: 0.067595; Backpropagation: 0.2909 sec; Batch: 2.0920 sec
0.1558 0.1087 0.0857 0.0726 0.0653 0.0596 0.0579 0.0553 0.0543 0.0536 0.0528 0.0525 0.0522 0.0518 0.0517 0.0514 

[TRAIN] Epoch[1](1138/114412); Loss: 0.063013; Backpropagation: 0.2930 sec; Batch: 2.0873 sec
0.1354 0.1097 0.0816 0.0664 0.0608 0.0563 0.0545 0.0523 0.0511 0.0503 0.0494 0.0489 0.0483 0.0480 0.0478 0.0474 

[TRAIN] Epoch[1](1139/114412); Loss: 0.069744; Backpropagation: 0.2914 sec; Batch: 2.1200 sec
0.1239 0.1079 0.0936 0.0819 0.0718 0.0657 0.0631 0.0605 0.0593 0.0577 0.0566 0.0560 0.0552 0.0547 0.0542 0.0538 

[TRAIN] Epoch[1](1140/114412); Loss: 0.063620; Backpropagation: 0.2912 sec; Batch: 2.1206 sec
0.0959 0.0828 0.0751 0.0685 0.0644 0.0614 0.0601 0.0587 0.0579 0.0573 0.0567 0.0565 0.0560 0.0557 0.0555 0.0552 

[TRAIN] Epoch[1](1141/114412); Loss: 0.066878; Backpropagation: 0.2910 sec; Batch: 2.1188 sec
0.1319 0.1067 0.0890 0.0748 0.0666 0.0631 0.0594 0.0572 0.0555 0.0541 0.0532 0.0525 0.0519 0.0515 0.0515 0.0513 

[TRAIN] Epoch[1](1142/114412); Loss: 0.075032; Backpropagation: 0.2910 sec; Batch: 2.0851 sec
0.1218 0.1047 0.0882 0.0812 0.0757 0.0725 0.0705 0.0688 0.0676 0.0663 0.0656 0.0647 0.0639 0.0634 0.0630 0.0626 

[TRAIN] Epoch[1](1143/114412); Loss: 0.058145; Backpropagation: 0.2912 sec; Batch: 2.1159 sec
0.1032 0.0926 0.0692 0.0609 0.0580 0.0543 0.0529 0.0513 0.0501 0.0495 0.0489 0.0484 0.0481 0.0478 0.0476 0.0475 

[TRAIN] Epoch[1](1144/114412); Loss: 0.069303; Backpropagation: 0.2911 sec; Batch: 2.1187 sec
0.1325 0.0906 0.0867 0.0759 0.0695 0.0654 0.0632 0.0617 0.0606 0.0595 0.0587 0.0579 0.0572 0.0568 0.0565 0.0562 

[TRAIN] Epoch[1](1145/114412); Loss: 0.069824; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1310 0.1069 0.0838 0.0748 0.0699 0.0665 0.0639 0.0621 0.0605 0.0590 0.0582 0.0571 0.0565 0.0560 0.0556 0.0552 

[TRAIN] Epoch[1](1146/114412); Loss: 0.081550; Backpropagation: 0.2910 sec; Batch: 2.1137 sec
0.1480 0.1274 0.1038 0.0919 0.0825 0.0765 0.0742 0.0714 0.0699 0.0681 0.0669 0.0658 0.0653 0.0648 0.0644 0.0639 

[TRAIN] Epoch[1](1147/114412); Loss: 0.058415; Backpropagation: 0.2905 sec; Batch: 2.1166 sec
0.1003 0.0888 0.0690 0.0668 0.0617 0.0571 0.0544 0.0522 0.0507 0.0496 0.0487 0.0480 0.0474 0.0470 0.0466 0.0462 

[TRAIN] Epoch[1](1148/114412); Loss: 0.047013; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.1181 0.0843 0.0602 0.0503 0.0449 0.0419 0.0392 0.0374 0.0363 0.0354 0.0347 0.0343 0.0340 0.0338 0.0338 0.0337 

[TRAIN] Epoch[1](1149/114412); Loss: 0.062382; Backpropagation: 0.2915 sec; Batch: 2.0794 sec
0.1452 0.1111 0.0915 0.0713 0.0568 0.0572 0.0518 0.0495 0.0485 0.0468 0.0461 0.0454 0.0447 0.0444 0.0440 0.0438 

[TRAIN] Epoch[1](1150/114412); Loss: 0.068718; Backpropagation: 0.2913 sec; Batch: 2.0979 sec
0.1340 0.0947 0.0795 0.0731 0.0691 0.0655 0.0631 0.0613 0.0601 0.0588 0.0578 0.0574 0.0568 0.0563 0.0561 0.0558 

[TRAIN] Epoch[1](1151/114412); Loss: 0.099194; Backpropagation: 0.2909 sec; Batch: 2.1212 sec
0.1507 0.1397 0.1153 0.1049 0.0998 0.0959 0.0932 0.0915 0.0897 0.0888 0.0876 0.0869 0.0863 0.0859 0.0855 0.0852 

[TRAIN] Epoch[1](1152/114412); Loss: 0.061242; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1019 0.0834 0.0748 0.0670 0.0621 0.0590 0.0569 0.0557 0.0546 0.0536 0.0529 0.0523 0.0519 0.0515 0.0513 0.0510 

[TRAIN] Epoch[1](1153/114412); Loss: 0.101003; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1638 0.1584 0.1399 0.1178 0.1065 0.1000 0.0933 0.0875 0.0850 0.0833 0.0818 0.0808 0.0802 0.0796 0.0792 0.0789 

[TRAIN] Epoch[1](1154/114412); Loss: 0.056513; Backpropagation: 0.2907 sec; Batch: 2.1206 sec
0.1018 0.0905 0.0720 0.0650 0.0579 0.0537 0.0510 0.0491 0.0480 0.0467 0.0460 0.0453 0.0449 0.0445 0.0441 0.0438 

[TRAIN] Epoch[1](1155/114412); Loss: 0.050111; Backpropagation: 0.2917 sec; Batch: 2.1137 sec
0.0983 0.0922 0.0687 0.0602 0.0517 0.0464 0.0440 0.0416 0.0402 0.0389 0.0381 0.0373 0.0367 0.0362 0.0357 0.0354 

[TRAIN] Epoch[1](1156/114412); Loss: 0.049653; Backpropagation: 0.2915 sec; Batch: 2.1184 sec
0.0991 0.0882 0.0617 0.0548 0.0504 0.0466 0.0437 0.0422 0.0401 0.0397 0.0392 0.0386 0.0381 0.0376 0.0373 0.0371 

[TRAIN] Epoch[1](1157/114412); Loss: 0.054818; Backpropagation: 0.2914 sec; Batch: 2.1683 sec
0.1129 0.0876 0.0718 0.0603 0.0549 0.0510 0.0488 0.0469 0.0455 0.0444 0.0435 0.0428 0.0422 0.0419 0.0415 0.0413 

[TRAIN] Epoch[1](1158/114412); Loss: 0.059516; Backpropagation: 0.2906 sec; Batch: 2.1181 sec
0.1376 0.1062 0.0912 0.0748 0.0629 0.0541 0.0493 0.0463 0.0444 0.0434 0.0421 0.0412 0.0404 0.0398 0.0394 0.0391 

[TRAIN] Epoch[1](1159/114412); Loss: 0.063706; Backpropagation: 0.2904 sec; Batch: 2.1201 sec
0.1124 0.1022 0.0780 0.0701 0.0658 0.0608 0.0586 0.0563 0.0547 0.0535 0.0525 0.0518 0.0512 0.0508 0.0505 0.0503 

[TRAIN] Epoch[1](1160/114412); Loss: 0.050719; Backpropagation: 0.2932 sec; Batch: 2.1195 sec
0.1080 0.0798 0.0611 0.0552 0.0509 0.0478 0.0448 0.0436 0.0423 0.0412 0.0406 0.0400 0.0395 0.0392 0.0388 0.0386 

[TRAIN] Epoch[1](1161/114412); Loss: 0.066102; Backpropagation: 0.2916 sec; Batch: 2.1173 sec
0.1075 0.0980 0.0798 0.0734 0.0680 0.0638 0.0613 0.0598 0.0582 0.0572 0.0564 0.0557 0.0552 0.0548 0.0544 0.0542 

[TRAIN] Epoch[1](1162/114412); Loss: 0.051494; Backpropagation: 0.2954 sec; Batch: 2.1260 sec
0.1147 0.1003 0.0769 0.0617 0.0552 0.0462 0.0431 0.0408 0.0390 0.0379 0.0365 0.0355 0.0348 0.0343 0.0338 0.0334 

[TRAIN] Epoch[1](1163/114412); Loss: 0.074190; Backpropagation: 0.2920 sec; Batch: 2.1207 sec
0.1203 0.1022 0.0852 0.0802 0.0750 0.0717 0.0694 0.0677 0.0665 0.0656 0.0649 0.0644 0.0639 0.0637 0.0633 0.0631 

[TRAIN] Epoch[1](1164/114412); Loss: 0.063141; Backpropagation: 0.2913 sec; Batch: 2.1170 sec
0.1138 0.0951 0.0799 0.0712 0.0654 0.0611 0.0577 0.0559 0.0546 0.0533 0.0521 0.0513 0.0505 0.0499 0.0494 0.0489 

[TRAIN] Epoch[1](1165/114412); Loss: 0.075439; Backpropagation: 0.2912 sec; Batch: 2.0903 sec
0.1511 0.1274 0.1010 0.0817 0.0767 0.0702 0.0676 0.0642 0.0621 0.0606 0.0592 0.0584 0.0575 0.0568 0.0564 0.0562 

[TRAIN] Epoch[1](1166/114412); Loss: 0.077465; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1345 0.1138 0.0981 0.0867 0.0800 0.0745 0.0712 0.0685 0.0671 0.0659 0.0647 0.0639 0.0633 0.0627 0.0624 0.0622 

[TRAIN] Epoch[1](1167/114412); Loss: 0.068706; Backpropagation: 0.2931 sec; Batch: 2.1513 sec
0.1225 0.1070 0.0899 0.0776 0.0708 0.0664 0.0627 0.0602 0.0587 0.0571 0.0561 0.0553 0.0545 0.0539 0.0535 0.0531 

[TRAIN] Epoch[1](1168/114412); Loss: 0.080817; Backpropagation: 0.2933 sec; Batch: 2.1215 sec
0.1212 0.1064 0.0932 0.0868 0.0834 0.0813 0.0782 0.0759 0.0739 0.0727 0.0716 0.0709 0.0701 0.0695 0.0692 0.0688 

[TRAIN] Epoch[1](1169/114412); Loss: 0.071649; Backpropagation: 0.2913 sec; Batch: 2.1141 sec
0.1318 0.1157 0.0908 0.0842 0.0764 0.0704 0.0666 0.0634 0.0610 0.0588 0.0571 0.0557 0.0547 0.0538 0.0532 0.0527 

[TRAIN] Epoch[1](1170/114412); Loss: 0.067145; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1328 0.1131 0.0889 0.0749 0.0680 0.0630 0.0595 0.0564 0.0547 0.0535 0.0528 0.0521 0.0514 0.0513 0.0510 0.0508 

[TRAIN] Epoch[1](1171/114412); Loss: 0.069135; Backpropagation: 0.2914 sec; Batch: 2.1211 sec
0.1385 0.1119 0.0873 0.0778 0.0707 0.0667 0.0630 0.0598 0.0575 0.0559 0.0545 0.0536 0.0529 0.0523 0.0520 0.0516 

[TRAIN] Epoch[1](1172/114412); Loss: 0.050214; Backpropagation: 0.2915 sec; Batch: 2.1168 sec
0.1206 0.0857 0.0703 0.0580 0.0510 0.0463 0.0428 0.0406 0.0389 0.0377 0.0369 0.0358 0.0354 0.0347 0.0345 0.0342 

[TRAIN] Epoch[1](1173/114412); Loss: 0.076109; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1338 0.1160 0.0997 0.0880 0.0779 0.0730 0.0691 0.0668 0.0649 0.0635 0.0625 0.0616 0.0610 0.0606 0.0600 0.0595 

[TRAIN] Epoch[1](1174/114412); Loss: 0.087928; Backpropagation: 0.2914 sec; Batch: 2.1217 sec
0.1287 0.1168 0.1067 0.0959 0.0893 0.0859 0.0830 0.0811 0.0800 0.0788 0.0779 0.0772 0.0767 0.0766 0.0763 0.0760 

[TRAIN] Epoch[1](1175/114412); Loss: 0.081928; Backpropagation: 0.2904 sec; Batch: 2.1203 sec
0.1695 0.1372 0.1021 0.0885 0.0798 0.0747 0.0720 0.0697 0.0676 0.0662 0.0651 0.0646 0.0641 0.0636 0.0632 0.0629 

[TRAIN] Epoch[1](1176/114412); Loss: 0.097539; Backpropagation: 0.2918 sec; Batch: 2.1146 sec
0.1479 0.1296 0.1130 0.1039 0.0990 0.0952 0.0927 0.0907 0.0892 0.0879 0.0869 0.0861 0.0854 0.0849 0.0843 0.0838 

[TRAIN] Epoch[1](1177/114412); Loss: 0.044689; Backpropagation: 0.2910 sec; Batch: 2.0971 sec
0.0893 0.0747 0.0604 0.0527 0.0461 0.0419 0.0395 0.0379 0.0363 0.0355 0.0347 0.0340 0.0335 0.0331 0.0328 0.0327 

[TRAIN] Epoch[1](1178/114412); Loss: 0.083491; Backpropagation: 0.2908 sec; Batch: 2.0775 sec
0.2008 0.1623 0.1214 0.0939 0.0801 0.0733 0.0693 0.0654 0.0632 0.0612 0.0595 0.0586 0.0576 0.0570 0.0563 0.0559 

[TRAIN] Epoch[1](1179/114412); Loss: 0.062219; Backpropagation: 0.2904 sec; Batch: 2.1091 sec
0.1107 0.0985 0.0772 0.0703 0.0634 0.0590 0.0558 0.0545 0.0530 0.0520 0.0513 0.0506 0.0503 0.0499 0.0496 0.0493 

[TRAIN] Epoch[1](1180/114412); Loss: 0.053798; Backpropagation: 0.2914 sec; Batch: 2.1259 sec
0.0962 0.0823 0.0657 0.0609 0.0555 0.0525 0.0501 0.0477 0.0461 0.0452 0.0444 0.0437 0.0432 0.0427 0.0424 0.0421 

[TRAIN] Epoch[1](1181/114412); Loss: 0.077913; Backpropagation: 0.2914 sec; Batch: 2.0785 sec
0.1202 0.1047 0.0859 0.0800 0.0773 0.0750 0.0735 0.0721 0.0713 0.0706 0.0701 0.0698 0.0694 0.0691 0.0690 0.0688 

[TRAIN] Epoch[1](1182/114412); Loss: 0.066061; Backpropagation: 0.2912 sec; Batch: 2.1211 sec
0.1146 0.0946 0.0822 0.0737 0.0673 0.0636 0.0605 0.0589 0.0573 0.0564 0.0556 0.0552 0.0548 0.0543 0.0542 0.0539 

[TRAIN] Epoch[1](1183/114412); Loss: 0.049475; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1409 0.1069 0.0669 0.0512 0.0453 0.0411 0.0379 0.0366 0.0351 0.0344 0.0335 0.0331 0.0328 0.0322 0.0320 0.0317 

[TRAIN] Epoch[1](1184/114412); Loss: 0.076601; Backpropagation: 0.2914 sec; Batch: 2.1184 sec
0.1280 0.1071 0.0914 0.0833 0.0793 0.0748 0.0718 0.0696 0.0680 0.0668 0.0659 0.0652 0.0645 0.0639 0.0632 0.0628 

[TRAIN] Epoch[1](1185/114412); Loss: 0.068468; Backpropagation: 0.2913 sec; Batch: 2.0790 sec
0.1415 0.1223 0.0860 0.0719 0.0665 0.0622 0.0600 0.0580 0.0562 0.0551 0.0541 0.0534 0.0529 0.0523 0.0518 0.0514 

[TRAIN] Epoch[1](1186/114412); Loss: 0.075020; Backpropagation: 0.2899 sec; Batch: 2.1174 sec
0.1168 0.1018 0.0887 0.0821 0.0767 0.0735 0.0708 0.0690 0.0677 0.0667 0.0659 0.0650 0.0647 0.0640 0.0635 0.0633 

[TRAIN] Epoch[1](1187/114412); Loss: 0.064354; Backpropagation: 0.2933 sec; Batch: 2.0810 sec
0.1205 0.0948 0.0806 0.0702 0.0638 0.0605 0.0581 0.0566 0.0557 0.0544 0.0536 0.0530 0.0524 0.0520 0.0518 0.0516 

[TRAIN] Epoch[1](1188/114412); Loss: 0.056952; Backpropagation: 0.2933 sec; Batch: 2.1210 sec
0.1237 0.1015 0.0793 0.0641 0.0573 0.0525 0.0489 0.0471 0.0454 0.0440 0.0429 0.0420 0.0414 0.0408 0.0403 0.0399 

[TRAIN] Epoch[1](1189/114412); Loss: 0.076751; Backpropagation: 0.2914 sec; Batch: 2.1190 sec
0.1335 0.1055 0.0920 0.0806 0.0767 0.0727 0.0705 0.0686 0.0676 0.0670 0.0664 0.0660 0.0656 0.0653 0.0651 0.0650 

[TRAIN] Epoch[1](1190/114412); Loss: 0.070244; Backpropagation: 0.2929 sec; Batch: 2.1266 sec
0.1490 0.1213 0.0957 0.0772 0.0705 0.0654 0.0615 0.0591 0.0567 0.0555 0.0540 0.0530 0.0521 0.0514 0.0510 0.0505 

[TRAIN] Epoch[1](1191/114412); Loss: 0.059185; Backpropagation: 0.2929 sec; Batch: 2.1069 sec
0.1263 0.1060 0.0724 0.0651 0.0584 0.0542 0.0515 0.0492 0.0479 0.0469 0.0460 0.0454 0.0449 0.0446 0.0442 0.0440 

[TRAIN] Epoch[1](1192/114412); Loss: 0.062504; Backpropagation: 0.2911 sec; Batch: 2.1194 sec
0.1265 0.1004 0.0778 0.0657 0.0602 0.0566 0.0546 0.0533 0.0523 0.0516 0.0510 0.0505 0.0502 0.0500 0.0498 0.0496 

[TRAIN] Epoch[1](1193/114412); Loss: 0.061886; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1249 0.1039 0.0789 0.0700 0.0635 0.0580 0.0546 0.0524 0.0507 0.0496 0.0486 0.0479 0.0474 0.0469 0.0467 0.0463 

[TRAIN] Epoch[1](1194/114412); Loss: 0.074702; Backpropagation: 0.2909 sec; Batch: 2.1162 sec
0.1301 0.1127 0.0952 0.0850 0.0805 0.0737 0.0702 0.0669 0.0640 0.0623 0.0607 0.0598 0.0593 0.0586 0.0582 0.0578 

[TRAIN] Epoch[1](1195/114412); Loss: 0.050315; Backpropagation: 0.2914 sec; Batch: 2.1190 sec
0.1119 0.0875 0.0685 0.0586 0.0501 0.0457 0.0433 0.0411 0.0400 0.0388 0.0378 0.0372 0.0366 0.0362 0.0359 0.0357 

[TRAIN] Epoch[1](1196/114412); Loss: 0.062674; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.1108 0.0961 0.0779 0.0670 0.0629 0.0594 0.0571 0.0556 0.0544 0.0534 0.0526 0.0520 0.0515 0.0511 0.0507 0.0504 

[TRAIN] Epoch[1](1197/114412); Loss: 0.076646; Backpropagation: 0.2955 sec; Batch: 2.1169 sec
0.1505 0.1363 0.1121 0.0904 0.0775 0.0673 0.0649 0.0625 0.0608 0.0597 0.0588 0.0581 0.0574 0.0570 0.0566 0.0562 

[TRAIN] Epoch[1](1198/114412); Loss: 0.063881; Backpropagation: 0.2929 sec; Batch: 2.1192 sec
0.1134 0.1012 0.0772 0.0691 0.0634 0.0599 0.0586 0.0567 0.0554 0.0543 0.0533 0.0528 0.0522 0.0519 0.0516 0.0512 

[TRAIN] Epoch[1](1199/114412); Loss: 0.073306; Backpropagation: 0.2919 sec; Batch: 2.0781 sec
0.1311 0.1036 0.0821 0.0752 0.0713 0.0699 0.0677 0.0662 0.0652 0.0644 0.0638 0.0633 0.0628 0.0624 0.0621 0.0618 

[TRAIN] Epoch[1](1200/114412); Loss: 0.059601; Backpropagation: 0.2916 sec; Batch: 2.1086 sec
0.1100 0.0969 0.0702 0.0613 0.0583 0.0559 0.0538 0.0522 0.0513 0.0505 0.0499 0.0494 0.0490 0.0486 0.0483 0.0481 

[TRAIN] Epoch[1](1201/114412); Loss: 0.054187; Backpropagation: 0.2929 sec; Batch: 2.1184 sec
0.1040 0.0851 0.0684 0.0585 0.0540 0.0507 0.0487 0.0470 0.0458 0.0451 0.0444 0.0438 0.0434 0.0430 0.0427 0.0425 

[TRAIN] Epoch[1](1202/114412); Loss: 0.075183; Backpropagation: 0.2909 sec; Batch: 2.1134 sec
0.1493 0.1291 0.0976 0.0808 0.0747 0.0679 0.0655 0.0635 0.0620 0.0608 0.0599 0.0593 0.0588 0.0583 0.0579 0.0575 

[TRAIN] Epoch[1](1203/114412); Loss: 0.039855; Backpropagation: 0.2910 sec; Batch: 2.0841 sec
0.0931 0.0785 0.0514 0.0415 0.0378 0.0351 0.0330 0.0316 0.0309 0.0303 0.0297 0.0293 0.0290 0.0289 0.0288 0.0286 

[TRAIN] Epoch[1](1204/114412); Loss: 0.070857; Backpropagation: 0.2909 sec; Batch: 2.1011 sec
0.1132 0.0992 0.0862 0.0777 0.0720 0.0681 0.0657 0.0641 0.0629 0.0622 0.0615 0.0610 0.0605 0.0600 0.0599 0.0596 

[TRAIN] Epoch[1](1205/114412); Loss: 0.050300; Backpropagation: 0.2910 sec; Batch: 2.1397 sec
0.1178 0.0958 0.0764 0.0604 0.0525 0.0463 0.0416 0.0389 0.0374 0.0358 0.0349 0.0343 0.0337 0.0333 0.0330 0.0326 

[TRAIN] Epoch[1](1206/114412); Loss: 0.050601; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1067 0.0857 0.0646 0.0566 0.0492 0.0459 0.0443 0.0427 0.0416 0.0406 0.0397 0.0392 0.0388 0.0383 0.0381 0.0378 

[TRAIN] Epoch[1](1207/114412); Loss: 0.052360; Backpropagation: 0.2913 sec; Batch: 2.1146 sec
0.0900 0.0744 0.0636 0.0583 0.0538 0.0503 0.0482 0.0469 0.0459 0.0452 0.0445 0.0440 0.0436 0.0433 0.0430 0.0427 

[TRAIN] Epoch[1](1208/114412); Loss: 0.099918; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1585 0.1418 0.1183 0.1083 0.1005 0.0951 0.0928 0.0911 0.0897 0.0887 0.0876 0.0867 0.0858 0.0852 0.0846 0.0839 

[TRAIN] Epoch[1](1209/114412); Loss: 0.066253; Backpropagation: 0.2909 sec; Batch: 2.1136 sec
0.1411 0.1122 0.0864 0.0710 0.0632 0.0603 0.0572 0.0556 0.0543 0.0530 0.0521 0.0516 0.0510 0.0507 0.0504 0.0501 

[TRAIN] Epoch[1](1210/114412); Loss: 0.034024; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.0791 0.0663 0.0451 0.0344 0.0325 0.0307 0.0287 0.0273 0.0264 0.0259 0.0254 0.0250 0.0247 0.0245 0.0244 0.0242 

[TRAIN] Epoch[1](1211/114412); Loss: 0.065554; Backpropagation: 0.2913 sec; Batch: 2.1163 sec
0.1232 0.0954 0.0835 0.0736 0.0662 0.0617 0.0591 0.0577 0.0563 0.0550 0.0541 0.0533 0.0529 0.0526 0.0523 0.0521 

[TRAIN] Epoch[1](1212/114412); Loss: 0.076375; Backpropagation: 0.2950 sec; Batch: 2.0825 sec
0.1368 0.1184 0.0967 0.0816 0.0758 0.0716 0.0692 0.0671 0.0656 0.0647 0.0639 0.0631 0.0625 0.0620 0.0617 0.0614 

[TRAIN] Epoch[1](1213/114412); Loss: 0.061277; Backpropagation: 0.2915 sec; Batch: 2.1164 sec
0.1278 0.1088 0.0857 0.0725 0.0657 0.0602 0.0547 0.0513 0.0482 0.0460 0.0449 0.0441 0.0434 0.0428 0.0425 0.0420 

[TRAIN] Epoch[1](1214/114412); Loss: 0.064162; Backpropagation: 0.2907 sec; Batch: 2.1171 sec
0.1309 0.1082 0.0848 0.0726 0.0645 0.0590 0.0555 0.0539 0.0525 0.0514 0.0504 0.0496 0.0490 0.0484 0.0480 0.0477 

[TRAIN] Epoch[1](1215/114412); Loss: 0.050478; Backpropagation: 0.2906 sec; Batch: 2.1171 sec
0.0970 0.0846 0.0639 0.0556 0.0511 0.0474 0.0453 0.0434 0.0421 0.0412 0.0405 0.0398 0.0394 0.0390 0.0387 0.0385 

[TRAIN] Epoch[1](1216/114412); Loss: 0.062463; Backpropagation: 0.2930 sec; Batch: 2.1164 sec
0.1310 0.1107 0.0835 0.0683 0.0592 0.0542 0.0527 0.0513 0.0504 0.0495 0.0489 0.0484 0.0481 0.0479 0.0477 0.0475 

[TRAIN] Epoch[1](1217/114412); Loss: 0.051347; Backpropagation: 0.2930 sec; Batch: 2.1178 sec
0.1022 0.0802 0.0637 0.0558 0.0506 0.0485 0.0461 0.0442 0.0434 0.0425 0.0417 0.0412 0.0408 0.0405 0.0402 0.0399 

[TRAIN] Epoch[1](1218/114412); Loss: 0.088046; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1528 0.1273 0.1087 0.0949 0.0893 0.0844 0.0815 0.0789 0.0772 0.0759 0.0747 0.0738 0.0731 0.0726 0.0720 0.0716 

[TRAIN] Epoch[1](1219/114412); Loss: 0.065105; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1254 0.1015 0.0807 0.0706 0.0648 0.0614 0.0589 0.0570 0.0553 0.0542 0.0533 0.0526 0.0520 0.0516 0.0513 0.0510 

[TRAIN] Epoch[1](1220/114412); Loss: 0.050652; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1196 0.0929 0.0712 0.0542 0.0483 0.0448 0.0422 0.0407 0.0396 0.0385 0.0377 0.0369 0.0364 0.0361 0.0359 0.0357 

[TRAIN] Epoch[1](1221/114412); Loss: 0.052437; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.1235 0.0978 0.0794 0.0627 0.0550 0.0478 0.0439 0.0407 0.0390 0.0377 0.0366 0.0358 0.0353 0.0349 0.0346 0.0343 

[TRAIN] Epoch[1](1222/114412); Loss: 0.072919; Backpropagation: 0.2930 sec; Batch: 2.1167 sec
0.1269 0.1068 0.0879 0.0775 0.0726 0.0694 0.0669 0.0654 0.0641 0.0631 0.0622 0.0615 0.0610 0.0607 0.0604 0.0602 

[TRAIN] Epoch[1](1223/114412); Loss: 0.070699; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1204 0.1020 0.0882 0.0791 0.0722 0.0682 0.0656 0.0634 0.0622 0.0608 0.0598 0.0589 0.0583 0.0577 0.0574 0.0570 

[TRAIN] Epoch[1](1224/114412); Loss: 0.077727; Backpropagation: 0.2928 sec; Batch: 2.1138 sec
0.1559 0.1369 0.1039 0.0861 0.0757 0.0698 0.0669 0.0646 0.0635 0.0622 0.0611 0.0605 0.0598 0.0593 0.0589 0.0585 

[TRAIN] Epoch[1](1225/114412); Loss: 0.051095; Backpropagation: 0.2910 sec; Batch: 2.0798 sec
0.1229 0.0900 0.0572 0.0531 0.0477 0.0450 0.0436 0.0420 0.0410 0.0403 0.0398 0.0394 0.0392 0.0390 0.0388 0.0387 

[TRAIN] Epoch[1](1226/114412); Loss: 0.058916; Backpropagation: 0.2910 sec; Batch: 2.0944 sec
0.1153 0.0968 0.0822 0.0661 0.0594 0.0546 0.0520 0.0495 0.0483 0.0471 0.0464 0.0459 0.0453 0.0450 0.0446 0.0443 

[TRAIN] Epoch[1](1227/114412); Loss: 0.059886; Backpropagation: 0.2943 sec; Batch: 2.1242 sec
0.1230 0.0921 0.0716 0.0614 0.0580 0.0547 0.0531 0.0518 0.0507 0.0498 0.0494 0.0489 0.0488 0.0485 0.0483 0.0479 

[TRAIN] Epoch[1](1228/114412); Loss: 0.072717; Backpropagation: 0.2952 sec; Batch: 2.1184 sec
0.1423 0.1208 0.0987 0.0828 0.0721 0.0677 0.0649 0.0621 0.0600 0.0585 0.0573 0.0563 0.0557 0.0552 0.0548 0.0544 

[TRAIN] Epoch[1](1229/114412); Loss: 0.081599; Backpropagation: 0.2952 sec; Batch: 2.0847 sec
0.1525 0.1317 0.1056 0.0945 0.0847 0.0784 0.0748 0.0704 0.0683 0.0662 0.0649 0.0639 0.0632 0.0626 0.0622 0.0618 

[TRAIN] Epoch[1](1230/114412); Loss: 0.075344; Backpropagation: 0.2931 sec; Batch: 2.0834 sec
0.1248 0.1060 0.0859 0.0797 0.0756 0.0724 0.0707 0.0690 0.0677 0.0667 0.0658 0.0651 0.0646 0.0643 0.0638 0.0634 

[TRAIN] Epoch[1](1231/114412); Loss: 0.079364; Backpropagation: 0.2931 sec; Batch: 2.0833 sec
0.1451 0.1232 0.1060 0.0911 0.0824 0.0748 0.0713 0.0687 0.0669 0.0655 0.0642 0.0633 0.0626 0.0621 0.0614 0.0612 

[TRAIN] Epoch[1](1232/114412); Loss: 0.047788; Backpropagation: 0.2925 sec; Batch: 2.0805 sec
0.1073 0.0941 0.0666 0.0495 0.0458 0.0410 0.0391 0.0378 0.0372 0.0361 0.0358 0.0353 0.0350 0.0349 0.0346 0.0343 

[TRAIN] Epoch[1](1233/114412); Loss: 0.062757; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1807 0.1202 0.0707 0.0643 0.0561 0.0518 0.0502 0.0488 0.0474 0.0465 0.0458 0.0451 0.0445 0.0442 0.0439 0.0437 

[TRAIN] Epoch[1](1234/114412); Loss: 0.064738; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1545 0.1167 0.0883 0.0694 0.0593 0.0569 0.0537 0.0516 0.0502 0.0493 0.0487 0.0482 0.0478 0.0474 0.0470 0.0468 

[TRAIN] Epoch[1](1235/114412); Loss: 0.089382; Backpropagation: 0.2907 sec; Batch: 2.1323 sec
0.1576 0.1367 0.1213 0.1087 0.0960 0.0868 0.0804 0.0770 0.0749 0.0732 0.0718 0.0707 0.0696 0.0690 0.0684 0.0680 

[TRAIN] Epoch[1](1236/114412); Loss: 0.064323; Backpropagation: 0.2909 sec; Batch: 2.0794 sec
0.1372 0.1059 0.0763 0.0644 0.0605 0.0581 0.0558 0.0549 0.0539 0.0531 0.0526 0.0520 0.0516 0.0513 0.0510 0.0507 

[TRAIN] Epoch[1](1237/114412); Loss: 0.057615; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1365 0.1115 0.0946 0.0689 0.0571 0.0507 0.0465 0.0435 0.0419 0.0409 0.0399 0.0391 0.0383 0.0378 0.0375 0.0372 

[TRAIN] Epoch[1](1238/114412); Loss: 0.044771; Backpropagation: 0.2911 sec; Batch: 2.0784 sec
0.1102 0.0903 0.0556 0.0462 0.0405 0.0378 0.0367 0.0358 0.0347 0.0339 0.0331 0.0328 0.0325 0.0323 0.0320 0.0319 

[TRAIN] Epoch[1](1239/114412); Loss: 0.061598; Backpropagation: 0.2954 sec; Batch: 2.1246 sec
0.1066 0.0939 0.0765 0.0665 0.0619 0.0589 0.0570 0.0549 0.0536 0.0526 0.0518 0.0512 0.0507 0.0502 0.0498 0.0495 

[TRAIN] Epoch[1](1240/114412); Loss: 0.077627; Backpropagation: 0.2933 sec; Batch: 2.0885 sec
0.1249 0.1117 0.0918 0.0830 0.0781 0.0739 0.0717 0.0704 0.0694 0.0685 0.0677 0.0670 0.0665 0.0661 0.0658 0.0656 

[TRAIN] Epoch[1](1241/114412); Loss: 0.066239; Backpropagation: 0.2931 sec; Batch: 2.0794 sec
0.1143 0.0949 0.0820 0.0758 0.0676 0.0650 0.0623 0.0595 0.0583 0.0565 0.0554 0.0548 0.0541 0.0535 0.0531 0.0527 

[TRAIN] Epoch[1](1242/114412); Loss: 0.063889; Backpropagation: 0.2931 sec; Batch: 2.1357 sec
0.1143 0.1018 0.0788 0.0688 0.0638 0.0604 0.0579 0.0562 0.0551 0.0540 0.0531 0.0524 0.0518 0.0514 0.0512 0.0511 

[TRAIN] Epoch[1](1243/114412); Loss: 0.082117; Backpropagation: 0.2930 sec; Batch: 2.1189 sec
0.1597 0.1269 0.1044 0.0870 0.0795 0.0746 0.0720 0.0705 0.0695 0.0684 0.0680 0.0676 0.0669 0.0666 0.0663 0.0660 

[TRAIN] Epoch[1](1244/114412); Loss: 0.075251; Backpropagation: 0.2915 sec; Batch: 2.1157 sec
0.1321 0.1151 0.0962 0.0846 0.0774 0.0721 0.0686 0.0666 0.0644 0.0630 0.0620 0.0613 0.0608 0.0603 0.0600 0.0597 

[TRAIN] Epoch[1](1245/114412); Loss: 0.059786; Backpropagation: 0.2910 sec; Batch: 2.1268 sec
0.1122 0.0929 0.0840 0.0703 0.0607 0.0561 0.0528 0.0507 0.0498 0.0489 0.0478 0.0471 0.0464 0.0459 0.0456 0.0452 

[TRAIN] Epoch[1](1246/114412); Loss: 0.048407; Backpropagation: 0.2929 sec; Batch: 2.1158 sec
0.1022 0.0818 0.0617 0.0529 0.0475 0.0449 0.0428 0.0408 0.0400 0.0391 0.0379 0.0373 0.0368 0.0363 0.0362 0.0362 

[TRAIN] Epoch[1](1247/114412); Loss: 0.043088; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1053 0.0820 0.0581 0.0468 0.0410 0.0383 0.0366 0.0343 0.0328 0.0317 0.0311 0.0308 0.0305 0.0302 0.0300 0.0298 

[TRAIN] Epoch[1](1248/114412); Loss: 0.066841; Backpropagation: 0.2927 sec; Batch: 2.0830 sec
0.1049 0.0873 0.0782 0.0711 0.0672 0.0646 0.0629 0.0619 0.0607 0.0600 0.0594 0.0589 0.0586 0.0582 0.0579 0.0577 

[TRAIN] Epoch[1](1249/114412); Loss: 0.061785; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1050 0.0909 0.0777 0.0690 0.0639 0.0595 0.0571 0.0552 0.0537 0.0526 0.0518 0.0512 0.0507 0.0503 0.0500 0.0499 

[TRAIN] Epoch[1](1250/114412); Loss: 0.056828; Backpropagation: 0.2908 sec; Batch: 2.0771 sec
0.1164 0.0929 0.0720 0.0634 0.0580 0.0532 0.0508 0.0488 0.0476 0.0460 0.0449 0.0440 0.0435 0.0431 0.0426 0.0422 

[TRAIN] Epoch[1](1251/114412); Loss: 0.042405; Backpropagation: 0.2931 sec; Batch: 2.1087 sec
0.0798 0.0731 0.0561 0.0499 0.0448 0.0410 0.0384 0.0361 0.0348 0.0335 0.0328 0.0324 0.0319 0.0315 0.0313 0.0311 

[TRAIN] Epoch[1](1252/114412); Loss: 0.069157; Backpropagation: 0.2932 sec; Batch: 2.1203 sec
0.1458 0.1250 0.0965 0.0790 0.0697 0.0622 0.0578 0.0559 0.0545 0.0532 0.0523 0.0517 0.0512 0.0509 0.0506 0.0503 

[TRAIN] Epoch[1](1253/114412); Loss: 0.070263; Backpropagation: 0.2934 sec; Batch: 2.1173 sec
0.1200 0.1051 0.0869 0.0787 0.0732 0.0683 0.0649 0.0629 0.0611 0.0598 0.0588 0.0581 0.0574 0.0568 0.0563 0.0559 

[TRAIN] Epoch[1](1254/114412); Loss: 0.069080; Backpropagation: 0.2955 sec; Batch: 2.1242 sec
0.1470 0.1253 0.1030 0.0810 0.0700 0.0616 0.0582 0.0552 0.0532 0.0518 0.0512 0.0505 0.0499 0.0495 0.0491 0.0488 

[TRAIN] Epoch[1](1255/114412); Loss: 0.051865; Backpropagation: 0.2915 sec; Batch: 2.1206 sec
0.1035 0.0818 0.0648 0.0560 0.0520 0.0483 0.0463 0.0445 0.0435 0.0428 0.0421 0.0416 0.0412 0.0408 0.0405 0.0403 

[TRAIN] Epoch[1](1256/114412); Loss: 0.061666; Backpropagation: 0.2915 sec; Batch: 2.1266 sec
0.1216 0.0942 0.0730 0.0661 0.0621 0.0583 0.0561 0.0542 0.0525 0.0517 0.0507 0.0499 0.0495 0.0492 0.0489 0.0486 

[TRAIN] Epoch[1](1257/114412); Loss: 0.066264; Backpropagation: 0.2913 sec; Batch: 2.1162 sec
0.1257 0.1037 0.0820 0.0731 0.0676 0.0623 0.0596 0.0576 0.0563 0.0551 0.0542 0.0535 0.0529 0.0525 0.0522 0.0520 

[TRAIN] Epoch[1](1258/114412); Loss: 0.057665; Backpropagation: 0.2928 sec; Batch: 2.0804 sec
0.1309 0.0965 0.0724 0.0604 0.0560 0.0527 0.0505 0.0483 0.0467 0.0458 0.0450 0.0444 0.0439 0.0435 0.0430 0.0427 

[TRAIN] Epoch[1](1259/114412); Loss: 0.091423; Backpropagation: 0.2910 sec; Batch: 2.1183 sec
0.1520 0.1325 0.1064 0.0970 0.0905 0.0878 0.0856 0.0837 0.0819 0.0804 0.0794 0.0784 0.0776 0.0770 0.0765 0.0762 

[TRAIN] Epoch[1](1260/114412); Loss: 0.068791; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1287 0.1150 0.0906 0.0781 0.0690 0.0632 0.0603 0.0584 0.0569 0.0560 0.0552 0.0546 0.0542 0.0537 0.0534 0.0532 

[TRAIN] Epoch[1](1261/114412); Loss: 0.065642; Backpropagation: 0.2930 sec; Batch: 2.1195 sec
0.1396 0.1169 0.0937 0.0776 0.0692 0.0626 0.0584 0.0546 0.0522 0.0499 0.0484 0.0472 0.0461 0.0451 0.0446 0.0442 

[TRAIN] Epoch[1](1262/114412); Loss: 0.049153; Backpropagation: 0.2919 sec; Batch: 2.0843 sec
0.0917 0.0700 0.0647 0.0565 0.0500 0.0469 0.0448 0.0430 0.0418 0.0410 0.0404 0.0398 0.0394 0.0391 0.0388 0.0387 

[TRAIN] Epoch[1](1263/114412); Loss: 0.057073; Backpropagation: 0.2904 sec; Batch: 2.1159 sec
0.1192 0.1047 0.0766 0.0669 0.0588 0.0523 0.0497 0.0476 0.0452 0.0440 0.0429 0.0420 0.0414 0.0410 0.0406 0.0402 

[TRAIN] Epoch[1](1264/114412); Loss: 0.076304; Backpropagation: 0.2905 sec; Batch: 2.1216 sec
0.1317 0.1027 0.0879 0.0799 0.0760 0.0729 0.0709 0.0696 0.0683 0.0675 0.0667 0.0661 0.0657 0.0653 0.0650 0.0647 

[TRAIN] Epoch[1](1265/114412); Loss: 0.046918; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1124 0.0766 0.0583 0.0503 0.0456 0.0423 0.0402 0.0387 0.0377 0.0368 0.0362 0.0358 0.0354 0.0351 0.0348 0.0346 

[TRAIN] Epoch[1](1266/114412); Loss: 0.058243; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1375 0.1016 0.0798 0.0637 0.0579 0.0534 0.0502 0.0476 0.0458 0.0443 0.0432 0.0425 0.0418 0.0412 0.0408 0.0404 

[TRAIN] Epoch[1](1267/114412); Loss: 0.076384; Backpropagation: 0.2908 sec; Batch: 2.1178 sec
0.1211 0.1053 0.0888 0.0813 0.0771 0.0742 0.0718 0.0702 0.0689 0.0679 0.0671 0.0665 0.0661 0.0656 0.0653 0.0650 

[TRAIN] Epoch[1](1268/114412); Loss: 0.059504; Backpropagation: 0.2932 sec; Batch: 2.1213 sec
0.1320 0.0994 0.0775 0.0650 0.0589 0.0547 0.0521 0.0495 0.0482 0.0471 0.0460 0.0455 0.0449 0.0440 0.0438 0.0435 

[TRAIN] Epoch[1](1269/114412); Loss: 0.071522; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1227 0.1123 0.0860 0.0752 0.0706 0.0670 0.0649 0.0633 0.0622 0.0615 0.0607 0.0602 0.0598 0.0595 0.0593 0.0591 

[TRAIN] Epoch[1](1270/114412); Loss: 0.059769; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1204 0.0936 0.0747 0.0654 0.0595 0.0555 0.0534 0.0518 0.0503 0.0491 0.0483 0.0477 0.0472 0.0468 0.0465 0.0463 

[TRAIN] Epoch[1](1271/114412); Loss: 0.073581; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.1463 0.1212 0.0960 0.0752 0.0705 0.0671 0.0640 0.0624 0.0615 0.0605 0.0597 0.0592 0.0588 0.0585 0.0583 0.0580 

[TRAIN] Epoch[1](1272/114412); Loss: 0.081456; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1302 0.1146 0.1005 0.0889 0.0831 0.0779 0.0757 0.0732 0.0719 0.0710 0.0705 0.0699 0.0695 0.0691 0.0687 0.0685 

[TRAIN] Epoch[1](1273/114412); Loss: 0.058595; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1186 0.0946 0.0834 0.0696 0.0619 0.0534 0.0507 0.0490 0.0471 0.0459 0.0451 0.0445 0.0440 0.0436 0.0432 0.0429 

[TRAIN] Epoch[1](1274/114412); Loss: 0.064022; Backpropagation: 0.2908 sec; Batch: 2.1205 sec
0.1150 0.0987 0.0805 0.0685 0.0638 0.0601 0.0578 0.0563 0.0551 0.0543 0.0536 0.0529 0.0525 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](1275/114412); Loss: 0.053170; Backpropagation: 0.2909 sec; Batch: 2.1219 sec
0.1281 0.0920 0.0652 0.0570 0.0509 0.0476 0.0454 0.0439 0.0422 0.0412 0.0407 0.0400 0.0396 0.0392 0.0389 0.0387 

[TRAIN] Epoch[1](1276/114412); Loss: 0.066785; Backpropagation: 0.2910 sec; Batch: 2.1446 sec
0.1481 0.1135 0.0836 0.0691 0.0630 0.0599 0.0589 0.0567 0.0548 0.0536 0.0526 0.0520 0.0514 0.0508 0.0504 0.0501 

[TRAIN] Epoch[1](1277/114412); Loss: 0.062058; Backpropagation: 0.2916 sec; Batch: 2.1229 sec
0.1066 0.0961 0.0826 0.0710 0.0639 0.0592 0.0572 0.0543 0.0526 0.0519 0.0509 0.0501 0.0497 0.0494 0.0489 0.0487 

[TRAIN] Epoch[1](1278/114412); Loss: 0.064747; Backpropagation: 0.2907 sec; Batch: 2.0784 sec
0.1180 0.1051 0.0839 0.0718 0.0659 0.0613 0.0583 0.0561 0.0548 0.0537 0.0527 0.0519 0.0513 0.0508 0.0503 0.0501 

[TRAIN] Epoch[1](1279/114412); Loss: 0.058764; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.0967 0.0830 0.0731 0.0649 0.0602 0.0564 0.0539 0.0528 0.0518 0.0511 0.0504 0.0498 0.0495 0.0491 0.0489 0.0487 

[TRAIN] Epoch[1](1280/114412); Loss: 0.068815; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1302 0.1078 0.0877 0.0736 0.0670 0.0647 0.0616 0.0598 0.0589 0.0577 0.0569 0.0561 0.0555 0.0549 0.0546 0.0542 

[TRAIN] Epoch[1](1281/114412); Loss: 0.051460; Backpropagation: 0.2917 sec; Batch: 2.0822 sec
0.1097 0.0791 0.0626 0.0558 0.0508 0.0474 0.0455 0.0443 0.0432 0.0423 0.0416 0.0410 0.0405 0.0401 0.0399 0.0396 

[TRAIN] Epoch[1](1282/114412); Loss: 0.035074; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.0877 0.0785 0.0482 0.0410 0.0338 0.0295 0.0274 0.0263 0.0252 0.0243 0.0240 0.0235 0.0231 0.0230 0.0228 0.0227 

[TRAIN] Epoch[1](1283/114412); Loss: 0.063127; Backpropagation: 0.2915 sec; Batch: 2.1167 sec
0.1243 0.1113 0.0800 0.0684 0.0619 0.0581 0.0558 0.0537 0.0523 0.0511 0.0500 0.0494 0.0489 0.0484 0.0482 0.0480 

[TRAIN] Epoch[1](1284/114412); Loss: 0.045516; Backpropagation: 0.2910 sec; Batch: 2.1210 sec
0.0880 0.0784 0.0618 0.0515 0.0471 0.0423 0.0400 0.0385 0.0370 0.0362 0.0355 0.0349 0.0345 0.0343 0.0341 0.0340 

[TRAIN] Epoch[1](1285/114412); Loss: 0.058106; Backpropagation: 0.2932 sec; Batch: 2.1184 sec
0.1110 0.1042 0.0794 0.0694 0.0609 0.0563 0.0509 0.0492 0.0481 0.0444 0.0437 0.0432 0.0425 0.0423 0.0422 0.0421 

[TRAIN] Epoch[1](1286/114412); Loss: 0.077941; Backpropagation: 0.2908 sec; Batch: 2.1273 sec
0.1495 0.1285 0.1109 0.0974 0.0829 0.0735 0.0704 0.0668 0.0624 0.0602 0.0599 0.0591 0.0577 0.0567 0.0560 0.0551 

[TRAIN] Epoch[1](1287/114412); Loss: 0.076833; Backpropagation: 0.2924 sec; Batch: 2.0994 sec
0.1672 0.1376 0.1039 0.0810 0.0723 0.0687 0.0652 0.0633 0.0619 0.0608 0.0591 0.0585 0.0581 0.0575 0.0573 0.0570 

[TRAIN] Epoch[1](1288/114412); Loss: 0.066154; Backpropagation: 0.2919 sec; Batch: 2.0794 sec
0.1079 0.0951 0.0801 0.0717 0.0684 0.0653 0.0619 0.0596 0.0587 0.0576 0.0565 0.0562 0.0556 0.0550 0.0547 0.0542 

[TRAIN] Epoch[1](1289/114412); Loss: 0.098631; Backpropagation: 0.2909 sec; Batch: 2.1224 sec
0.1679 0.1387 0.1224 0.1137 0.1076 0.0992 0.0955 0.0933 0.0894 0.0848 0.0820 0.0810 0.0783 0.0757 0.0747 0.0740 

[TRAIN] Epoch[1](1290/114412); Loss: 0.074553; Backpropagation: 0.2912 sec; Batch: 2.0786 sec
0.1498 0.1166 0.0915 0.0815 0.0760 0.0702 0.0668 0.0646 0.0628 0.0616 0.0604 0.0595 0.0587 0.0580 0.0577 0.0573 

[TRAIN] Epoch[1](1291/114412); Loss: 0.079820; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1344 0.1193 0.0908 0.0842 0.0818 0.0763 0.0731 0.0720 0.0706 0.0694 0.0687 0.0680 0.0675 0.0672 0.0669 0.0666 

[TRAIN] Epoch[1](1292/114412); Loss: 0.080713; Backpropagation: 0.2920 sec; Batch: 2.0798 sec
0.1278 0.1194 0.0983 0.0872 0.0812 0.0775 0.0731 0.0713 0.0729 0.0708 0.0688 0.0696 0.0699 0.0686 0.0677 0.0671 

[TRAIN] Epoch[1](1293/114412); Loss: 0.059395; Backpropagation: 0.2907 sec; Batch: 2.0829 sec
0.0899 0.0888 0.0784 0.0674 0.0622 0.0569 0.0557 0.0542 0.0526 0.0512 0.0508 0.0496 0.0487 0.0482 0.0480 0.0477 

[TRAIN] Epoch[1](1294/114412); Loss: 0.097692; Backpropagation: 0.2905 sec; Batch: 2.0785 sec
0.1462 0.1327 0.1110 0.0993 0.0974 0.0959 0.0927 0.0911 0.0902 0.0887 0.0881 0.0871 0.0863 0.0860 0.0856 0.0849 

[TRAIN] Epoch[1](1295/114412); Loss: 0.076842; Backpropagation: 0.2908 sec; Batch: 2.0788 sec
0.1606 0.1488 0.1211 0.1027 0.0812 0.0737 0.0668 0.0617 0.0568 0.0545 0.0531 0.0514 0.0500 0.0495 0.0489 0.0485 

[TRAIN] Epoch[1](1296/114412); Loss: 0.083746; Backpropagation: 0.2907 sec; Batch: 2.1177 sec
0.1638 0.1438 0.1166 0.0962 0.0862 0.0819 0.0767 0.0715 0.0687 0.0667 0.0651 0.0625 0.0609 0.0606 0.0600 0.0587 

[TRAIN] Epoch[1](1297/114412); Loss: 0.056058; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.0826 0.0754 0.0754 0.0634 0.0569 0.0545 0.0533 0.0511 0.0502 0.0496 0.0487 0.0480 0.0475 0.0471 0.0467 0.0466 

[TRAIN] Epoch[1](1298/114412); Loss: 0.061773; Backpropagation: 0.2912 sec; Batch: 2.1927 sec
0.0957 0.0856 0.0791 0.0702 0.0625 0.0604 0.0587 0.0561 0.0550 0.0539 0.0529 0.0520 0.0517 0.0520 0.0514 0.0512 

[TRAIN] Epoch[1](1299/114412); Loss: 0.059729; Backpropagation: 0.2907 sec; Batch: 2.1137 sec
0.1199 0.1006 0.0752 0.0665 0.0602 0.0561 0.0531 0.0511 0.0496 0.0483 0.0475 0.0468 0.0460 0.0454 0.0448 0.0444 

[TRAIN] Epoch[1](1300/114412); Loss: 0.067523; Backpropagation: 0.2953 sec; Batch: 2.1188 sec
0.1177 0.1020 0.0840 0.0774 0.0692 0.0650 0.0628 0.0600 0.0582 0.0573 0.0561 0.0552 0.0545 0.0540 0.0537 0.0533 

[TRAIN] Epoch[1](1301/114412); Loss: 0.063926; Backpropagation: 0.2928 sec; Batch: 2.1220 sec
0.1467 0.1158 0.0807 0.0729 0.0608 0.0582 0.0561 0.0519 0.0499 0.0488 0.0482 0.0473 0.0467 0.0465 0.0462 0.0461 

[TRAIN] Epoch[1](1302/114412); Loss: 0.087829; Backpropagation: 0.2907 sec; Batch: 2.1178 sec
0.1485 0.1372 0.1130 0.0988 0.0892 0.0857 0.0826 0.0787 0.0758 0.0743 0.0730 0.0715 0.0704 0.0697 0.0688 0.0682 

[TRAIN] Epoch[1](1303/114412); Loss: 0.083183; Backpropagation: 0.2909 sec; Batch: 2.1198 sec
0.1431 0.1157 0.0984 0.0893 0.0856 0.0800 0.0768 0.0750 0.0737 0.0726 0.0716 0.0709 0.0701 0.0698 0.0695 0.0691 

[TRAIN] Epoch[1](1304/114412); Loss: 0.057493; Backpropagation: 0.2905 sec; Batch: 2.1167 sec
0.1211 0.0984 0.0749 0.0664 0.0608 0.0554 0.0516 0.0489 0.0467 0.0446 0.0439 0.0428 0.0418 0.0412 0.0410 0.0406 

[TRAIN] Epoch[1](1305/114412); Loss: 0.081290; Backpropagation: 0.2913 sec; Batch: 2.1146 sec
0.1428 0.1228 0.1038 0.0904 0.0830 0.0798 0.0751 0.0718 0.0704 0.0684 0.0671 0.0663 0.0655 0.0648 0.0645 0.0642 

[TRAIN] Epoch[1](1306/114412); Loss: 0.062084; Backpropagation: 0.2910 sec; Batch: 2.1187 sec
0.1276 0.1118 0.0878 0.0764 0.0619 0.0591 0.0565 0.0513 0.0477 0.0472 0.0464 0.0448 0.0445 0.0441 0.0432 0.0429 

[TRAIN] Epoch[1](1307/114412); Loss: 0.058743; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1371 0.1010 0.0807 0.0703 0.0585 0.0556 0.0520 0.0477 0.0455 0.0438 0.0431 0.0419 0.0413 0.0408 0.0404 0.0403 

[TRAIN] Epoch[1](1308/114412); Loss: 0.067708; Backpropagation: 0.2908 sec; Batch: 2.1208 sec
0.1221 0.1212 0.1060 0.0867 0.0752 0.0698 0.0631 0.0574 0.0543 0.0512 0.0488 0.0475 0.0463 0.0452 0.0446 0.0439 

[TRAIN] Epoch[1](1309/114412); Loss: 0.053260; Backpropagation: 0.2910 sec; Batch: 2.1223 sec
0.1348 0.1091 0.0811 0.0578 0.0487 0.0483 0.0436 0.0401 0.0389 0.0382 0.0369 0.0360 0.0354 0.0348 0.0344 0.0343 

[TRAIN] Epoch[1](1310/114412); Loss: 0.072230; Backpropagation: 0.2911 sec; Batch: 2.1115 sec
0.1210 0.1055 0.0883 0.0787 0.0721 0.0695 0.0674 0.0649 0.0634 0.0629 0.0618 0.0609 0.0605 0.0601 0.0596 0.0592 

[TRAIN] Epoch[1](1311/114412); Loss: 0.057545; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.0937 0.0813 0.0713 0.0642 0.0596 0.0555 0.0541 0.0525 0.0509 0.0500 0.0490 0.0484 0.0481 0.0476 0.0473 0.0472 

[TRAIN] Epoch[1](1312/114412); Loss: 0.086291; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1485 0.1382 0.1194 0.1056 0.0934 0.0855 0.0791 0.0753 0.0728 0.0698 0.0684 0.0662 0.0654 0.0650 0.0643 0.0637 

[TRAIN] Epoch[1](1313/114412); Loss: 0.050663; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1000 0.0896 0.0758 0.0590 0.0521 0.0490 0.0446 0.0415 0.0406 0.0393 0.0375 0.0372 0.0372 0.0360 0.0357 0.0356 

[TRAIN] Epoch[1](1314/114412); Loss: 0.083999; Backpropagation: 0.2912 sec; Batch: 2.1142 sec
0.1422 0.1230 0.1081 0.0923 0.0833 0.0805 0.0783 0.0758 0.0734 0.0721 0.0710 0.0700 0.0693 0.0687 0.0682 0.0678 

[TRAIN] Epoch[1](1315/114412); Loss: 0.071024; Backpropagation: 0.2932 sec; Batch: 2.1245 sec
0.1379 0.1208 0.0977 0.0775 0.0707 0.0693 0.0640 0.0600 0.0585 0.0569 0.0554 0.0545 0.0540 0.0535 0.0530 0.0526 

[TRAIN] Epoch[1](1316/114412); Loss: 0.086997; Backpropagation: 0.2930 sec; Batch: 2.1172 sec
0.1620 0.1311 0.1073 0.0943 0.0865 0.0822 0.0781 0.0759 0.0748 0.0734 0.0725 0.0718 0.0711 0.0706 0.0703 0.0700 

[TRAIN] Epoch[1](1317/114412); Loss: 0.066112; Backpropagation: 0.2913 sec; Batch: 2.1190 sec
0.1320 0.1103 0.0866 0.0723 0.0681 0.0618 0.0581 0.0565 0.0545 0.0532 0.0524 0.0515 0.0508 0.0503 0.0499 0.0496 

[TRAIN] Epoch[1](1318/114412); Loss: 0.071515; Backpropagation: 0.2909 sec; Batch: 2.1241 sec
0.1192 0.1043 0.0900 0.0785 0.0698 0.0683 0.0663 0.0649 0.0632 0.0621 0.0611 0.0602 0.0596 0.0592 0.0589 0.0586 

[TRAIN] Epoch[1](1319/114412); Loss: 0.054736; Backpropagation: 0.2915 sec; Batch: 2.1159 sec
0.1401 0.1099 0.0743 0.0580 0.0526 0.0496 0.0456 0.0431 0.0415 0.0398 0.0387 0.0378 0.0370 0.0364 0.0359 0.0354 

[TRAIN] Epoch[1](1320/114412); Loss: 0.059526; Backpropagation: 0.2912 sec; Batch: 2.1166 sec
0.1247 0.0912 0.0782 0.0647 0.0600 0.0556 0.0530 0.0513 0.0497 0.0488 0.0476 0.0467 0.0460 0.0453 0.0450 0.0445 

[TRAIN] Epoch[1](1321/114412); Loss: 0.076639; Backpropagation: 0.2906 sec; Batch: 2.1166 sec
0.1698 0.1306 0.1012 0.0807 0.0736 0.0704 0.0661 0.0633 0.0618 0.0606 0.0595 0.0587 0.0581 0.0575 0.0572 0.0569 

[TRAIN] Epoch[1](1322/114412); Loss: 0.051654; Backpropagation: 0.2905 sec; Batch: 2.1390 sec
0.1256 0.0930 0.0638 0.0537 0.0504 0.0462 0.0435 0.0420 0.0408 0.0399 0.0391 0.0386 0.0380 0.0376 0.0373 0.0370 

[TRAIN] Epoch[1](1323/114412); Loss: 0.062278; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.1574 0.1071 0.0833 0.0647 0.0583 0.0548 0.0520 0.0497 0.0485 0.0477 0.0465 0.0458 0.0456 0.0452 0.0449 0.0449 

[TRAIN] Epoch[1](1324/114412); Loss: 0.061236; Backpropagation: 0.2915 sec; Batch: 2.1178 sec
0.1793 0.1090 0.0729 0.0617 0.0560 0.0513 0.0492 0.0477 0.0466 0.0455 0.0446 0.0439 0.0435 0.0431 0.0428 0.0427 

[TRAIN] Epoch[1](1325/114412); Loss: 0.057979; Backpropagation: 0.2912 sec; Batch: 2.1201 sec
0.1146 0.0872 0.0704 0.0621 0.0570 0.0540 0.0522 0.0502 0.0492 0.0484 0.0478 0.0473 0.0470 0.0468 0.0468 0.0467 

[TRAIN] Epoch[1](1326/114412); Loss: 0.084950; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1784 0.1426 0.1174 0.0898 0.0839 0.0777 0.0742 0.0707 0.0690 0.0673 0.0660 0.0653 0.0648 0.0643 0.0640 0.0638 

[TRAIN] Epoch[1](1327/114412); Loss: 0.059816; Backpropagation: 0.2926 sec; Batch: 2.1204 sec
0.1095 0.0978 0.0770 0.0656 0.0611 0.0576 0.0538 0.0520 0.0506 0.0496 0.0487 0.0478 0.0472 0.0466 0.0462 0.0459 

[TRAIN] Epoch[1](1328/114412); Loss: 0.067256; Backpropagation: 0.2928 sec; Batch: 2.1208 sec
0.1582 0.1140 0.0832 0.0658 0.0623 0.0596 0.0573 0.0558 0.0547 0.0538 0.0531 0.0524 0.0520 0.0516 0.0512 0.0510 

[TRAIN] Epoch[1](1329/114412); Loss: 0.064726; Backpropagation: 0.2928 sec; Batch: 2.1237 sec
0.1387 0.1157 0.0879 0.0720 0.0629 0.0593 0.0558 0.0537 0.0521 0.0505 0.0495 0.0486 0.0478 0.0475 0.0470 0.0465 

[TRAIN] Epoch[1](1330/114412); Loss: 0.067863; Backpropagation: 0.2922 sec; Batch: 2.0827 sec
0.1641 0.1197 0.0886 0.0651 0.0604 0.0591 0.0567 0.0549 0.0539 0.0532 0.0524 0.0519 0.0517 0.0514 0.0513 0.0511 

[TRAIN] Epoch[1](1331/114412); Loss: 0.058479; Backpropagation: 0.2907 sec; Batch: 2.0786 sec
0.1630 0.1104 0.0763 0.0583 0.0518 0.0492 0.0466 0.0449 0.0438 0.0430 0.0424 0.0418 0.0414 0.0411 0.0409 0.0408 

[TRAIN] Epoch[1](1332/114412); Loss: 0.076500; Backpropagation: 0.2910 sec; Batch: 2.1192 sec
0.1493 0.1219 0.0911 0.0777 0.0736 0.0700 0.0681 0.0666 0.0653 0.0643 0.0636 0.0631 0.0627 0.0624 0.0622 0.0621 

[TRAIN] Epoch[1](1333/114412); Loss: 0.048770; Backpropagation: 0.2908 sec; Batch: 2.0778 sec
0.1268 0.0910 0.0675 0.0552 0.0489 0.0441 0.0402 0.0381 0.0363 0.0351 0.0342 0.0334 0.0329 0.0326 0.0321 0.0320 

[TRAIN] Epoch[1](1334/114412); Loss: 0.073126; Backpropagation: 0.2910 sec; Batch: 2.1170 sec
0.1242 0.1025 0.0900 0.0796 0.0746 0.0712 0.0685 0.0663 0.0649 0.0636 0.0624 0.0614 0.0609 0.0603 0.0598 0.0596 

[TRAIN] Epoch[1](1335/114412); Loss: 0.069961; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.1171 0.0973 0.0868 0.0769 0.0713 0.0683 0.0653 0.0632 0.0618 0.0606 0.0597 0.0590 0.0585 0.0581 0.0578 0.0576 

[TRAIN] Epoch[1](1336/114412); Loss: 0.089850; Backpropagation: 0.2907 sec; Batch: 2.1164 sec
0.1744 0.1369 0.1156 0.1026 0.0885 0.0850 0.0812 0.0781 0.0761 0.0743 0.0733 0.0721 0.0709 0.0704 0.0695 0.0689 

[TRAIN] Epoch[1](1337/114412); Loss: 0.069585; Backpropagation: 0.2932 sec; Batch: 2.0804 sec
0.1417 0.1127 0.0875 0.0767 0.0691 0.0635 0.0612 0.0599 0.0575 0.0565 0.0560 0.0551 0.0546 0.0541 0.0538 0.0536 

[TRAIN] Epoch[1](1338/114412); Loss: 0.051021; Backpropagation: 0.2913 sec; Batch: 2.1053 sec
0.1443 0.0929 0.0680 0.0594 0.0510 0.0454 0.0415 0.0390 0.0374 0.0361 0.0349 0.0341 0.0336 0.0332 0.0328 0.0327 

[TRAIN] Epoch[1](1339/114412); Loss: 0.058848; Backpropagation: 0.2908 sec; Batch: 2.0799 sec
0.1191 0.0859 0.0726 0.0619 0.0565 0.0536 0.0522 0.0504 0.0497 0.0492 0.0487 0.0484 0.0484 0.0484 0.0483 0.0484 

[TRAIN] Epoch[1](1340/114412); Loss: 0.079530; Backpropagation: 0.2911 sec; Batch: 2.1285 sec
0.1573 0.1290 0.1000 0.0835 0.0778 0.0748 0.0704 0.0679 0.0671 0.0657 0.0642 0.0638 0.0634 0.0627 0.0625 0.0625 

[TRAIN] Epoch[1](1341/114412); Loss: 0.069820; Backpropagation: 0.2931 sec; Batch: 2.1163 sec
0.1331 0.1097 0.0877 0.0779 0.0704 0.0654 0.0630 0.0604 0.0587 0.0576 0.0567 0.0562 0.0556 0.0551 0.0550 0.0548 

[TRAIN] Epoch[1](1342/114412); Loss: 0.080298; Backpropagation: 0.2931 sec; Batch: 2.1167 sec
0.1889 0.1374 0.1059 0.0863 0.0802 0.0756 0.0669 0.0645 0.0623 0.0608 0.0600 0.0597 0.0593 0.0589 0.0589 0.0591 

[TRAIN] Epoch[1](1343/114412); Loss: 0.053111; Backpropagation: 0.2925 sec; Batch: 2.1420 sec
0.1510 0.0990 0.0654 0.0546 0.0493 0.0451 0.0432 0.0413 0.0397 0.0389 0.0381 0.0375 0.0371 0.0368 0.0367 0.0364 

[TRAIN] Epoch[1](1344/114412); Loss: 0.070279; Backpropagation: 0.2930 sec; Batch: 2.0979 sec
0.1713 0.1425 0.1014 0.0780 0.0672 0.0622 0.0567 0.0544 0.0528 0.0504 0.0495 0.0485 0.0479 0.0476 0.0471 0.0469 

[TRAIN] Epoch[1](1345/114412); Loss: 0.085023; Backpropagation: 0.2929 sec; Batch: 2.0990 sec
0.1493 0.1226 0.1057 0.0930 0.0857 0.0813 0.0783 0.0762 0.0747 0.0731 0.0717 0.0710 0.0702 0.0696 0.0691 0.0689 

[TRAIN] Epoch[1](1346/114412); Loss: 0.057763; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1208 0.0942 0.0764 0.0619 0.0583 0.0542 0.0507 0.0490 0.0474 0.0462 0.0453 0.0448 0.0442 0.0437 0.0437 0.0435 

[TRAIN] Epoch[1](1347/114412); Loss: 0.076040; Backpropagation: 0.2917 sec; Batch: 2.1302 sec
0.1340 0.1140 0.0953 0.0838 0.0769 0.0727 0.0699 0.0675 0.0661 0.0647 0.0634 0.0626 0.0620 0.0615 0.0612 0.0609 

[TRAIN] Epoch[1](1348/114412); Loss: 0.067408; Backpropagation: 0.2908 sec; Batch: 2.1121 sec
0.1392 0.1061 0.0842 0.0718 0.0661 0.0626 0.0602 0.0579 0.0568 0.0554 0.0545 0.0538 0.0532 0.0526 0.0522 0.0520 

[TRAIN] Epoch[1](1349/114412); Loss: 0.061208; Backpropagation: 0.2910 sec; Batch: 2.1464 sec
0.1738 0.1257 0.0773 0.0616 0.0569 0.0521 0.0484 0.0463 0.0450 0.0436 0.0430 0.0422 0.0413 0.0410 0.0408 0.0403 

[TRAIN] Epoch[1](1350/114412); Loss: 0.067971; Backpropagation: 0.2904 sec; Batch: 2.1062 sec
0.1252 0.0988 0.0819 0.0751 0.0689 0.0656 0.0627 0.0607 0.0591 0.0577 0.0567 0.0560 0.0554 0.0549 0.0546 0.0543 

[TRAIN] Epoch[1](1351/114412); Loss: 0.074429; Backpropagation: 0.2914 sec; Batch: 2.1276 sec
0.1628 0.1383 0.1009 0.0813 0.0733 0.0689 0.0644 0.0616 0.0589 0.0573 0.0561 0.0550 0.0538 0.0532 0.0527 0.0524 

[TRAIN] Epoch[1](1352/114412); Loss: 0.049087; Backpropagation: 0.2909 sec; Batch: 2.0941 sec
0.0904 0.0813 0.0686 0.0570 0.0517 0.0492 0.0459 0.0422 0.0418 0.0395 0.0380 0.0374 0.0363 0.0358 0.0353 0.0349 

[TRAIN] Epoch[1](1353/114412); Loss: 0.043142; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1414 0.0858 0.0476 0.0420 0.0370 0.0338 0.0326 0.0316 0.0305 0.0301 0.0298 0.0297 0.0296 0.0296 0.0296 0.0295 

[TRAIN] Epoch[1](1354/114412); Loss: 0.051067; Backpropagation: 0.2955 sec; Batch: 2.1165 sec
0.0985 0.0858 0.0670 0.0559 0.0511 0.0483 0.0457 0.0438 0.0423 0.0412 0.0403 0.0399 0.0397 0.0394 0.0391 0.0391 

[TRAIN] Epoch[1](1355/114412); Loss: 0.059468; Backpropagation: 0.2931 sec; Batch: 2.1222 sec
0.1442 0.1052 0.0755 0.0613 0.0562 0.0530 0.0507 0.0484 0.0470 0.0460 0.0450 0.0445 0.0440 0.0437 0.0435 0.0433 

[TRAIN] Epoch[1](1356/114412); Loss: 0.067602; Backpropagation: 0.2933 sec; Batch: 2.0902 sec
0.1270 0.1005 0.0863 0.0757 0.0690 0.0654 0.0627 0.0593 0.0577 0.0561 0.0550 0.0545 0.0537 0.0533 0.0528 0.0526 

[TRAIN] Epoch[1](1357/114412); Loss: 0.052960; Backpropagation: 0.2930 sec; Batch: 2.1298 sec
0.1336 0.0949 0.0715 0.0539 0.0486 0.0465 0.0443 0.0426 0.0408 0.0400 0.0393 0.0388 0.0385 0.0382 0.0380 0.0380 

[TRAIN] Epoch[1](1358/114412); Loss: 0.053987; Backpropagation: 0.2911 sec; Batch: 2.2889 sec
0.1140 0.0817 0.0680 0.0561 0.0518 0.0495 0.0472 0.0465 0.0453 0.0444 0.0440 0.0435 0.0433 0.0430 0.0427 0.0429 

[TRAIN] Epoch[1](1359/114412); Loss: 0.072014; Backpropagation: 0.2931 sec; Batch: 2.2209 sec
0.1644 0.1315 0.0963 0.0806 0.0714 0.0640 0.0614 0.0586 0.0558 0.0547 0.0538 0.0530 0.0523 0.0519 0.0515 0.0511 

[TRAIN] Epoch[1](1360/114412); Loss: 0.067247; Backpropagation: 0.2915 sec; Batch: 2.0888 sec
0.1331 0.1018 0.0827 0.0716 0.0674 0.0622 0.0602 0.0587 0.0572 0.0563 0.0555 0.0547 0.0543 0.0538 0.0533 0.0531 

[TRAIN] Epoch[1](1361/114412); Loss: 0.070488; Backpropagation: 0.2936 sec; Batch: 2.0848 sec
0.1428 0.1159 0.0870 0.0717 0.0669 0.0654 0.0634 0.0610 0.0596 0.0578 0.0573 0.0567 0.0558 0.0556 0.0556 0.0552 

[TRAIN] Epoch[1](1362/114412); Loss: 0.054605; Backpropagation: 0.2928 sec; Batch: 2.1344 sec
0.1342 0.0907 0.0706 0.0597 0.0524 0.0498 0.0466 0.0443 0.0430 0.0417 0.0410 0.0404 0.0401 0.0400 0.0396 0.0395 

[TRAIN] Epoch[1](1363/114412); Loss: 0.087576; Backpropagation: 0.2914 sec; Batch: 2.1194 sec
0.1431 0.1245 0.1059 0.0968 0.0891 0.0848 0.0817 0.0791 0.0774 0.0763 0.0754 0.0746 0.0738 0.0734 0.0729 0.0724 

[TRAIN] Epoch[1](1364/114412); Loss: 0.078158; Backpropagation: 0.2932 sec; Batch: 2.1208 sec
0.1226 0.1009 0.0901 0.0855 0.0809 0.0773 0.0748 0.0726 0.0713 0.0699 0.0690 0.0683 0.0675 0.0669 0.0666 0.0663 

[TRAIN] Epoch[1](1365/114412); Loss: 0.073715; Backpropagation: 0.2909 sec; Batch: 2.1199 sec
0.1185 0.1026 0.0887 0.0799 0.0750 0.0719 0.0689 0.0675 0.0659 0.0646 0.0638 0.0633 0.0627 0.0623 0.0620 0.0617 

[TRAIN] Epoch[1](1366/114412); Loss: 0.081826; Backpropagation: 0.2910 sec; Batch: 2.1204 sec
0.1413 0.1210 0.0974 0.0864 0.0812 0.0779 0.0751 0.0730 0.0718 0.0708 0.0698 0.0694 0.0689 0.0686 0.0684 0.0682 

[TRAIN] Epoch[1](1367/114412); Loss: 0.057996; Backpropagation: 0.2913 sec; Batch: 2.1137 sec
0.1325 0.1003 0.0785 0.0657 0.0580 0.0523 0.0495 0.0474 0.0457 0.0446 0.0436 0.0429 0.0423 0.0418 0.0415 0.0414 

[TRAIN] Epoch[1](1368/114412); Loss: 0.081979; Backpropagation: 0.2928 sec; Batch: 2.0786 sec
0.1480 0.1311 0.1071 0.0914 0.0819 0.0756 0.0722 0.0706 0.0690 0.0678 0.0673 0.0666 0.0660 0.0659 0.0658 0.0656 

[TRAIN] Epoch[1](1369/114412); Loss: 0.069509; Backpropagation: 0.2913 sec; Batch: 2.1266 sec
0.1333 0.1099 0.0901 0.0825 0.0737 0.0680 0.0637 0.0608 0.0588 0.0564 0.0549 0.0538 0.0525 0.0517 0.0513 0.0508 

[TRAIN] Epoch[1](1370/114412); Loss: 0.060573; Backpropagation: 0.2916 sec; Batch: 2.1160 sec
0.1253 0.1090 0.0818 0.0693 0.0625 0.0562 0.0528 0.0499 0.0486 0.0470 0.0457 0.0449 0.0444 0.0441 0.0438 0.0438 

[TRAIN] Epoch[1](1371/114412); Loss: 0.063562; Backpropagation: 0.2955 sec; Batch: 2.1234 sec
0.1235 0.1077 0.0821 0.0682 0.0635 0.0591 0.0571 0.0552 0.0532 0.0518 0.0507 0.0499 0.0493 0.0489 0.0485 0.0483 

[TRAIN] Epoch[1](1372/114412); Loss: 0.095685; Backpropagation: 0.2933 sec; Batch: 2.1192 sec
0.1416 0.1252 0.1119 0.0992 0.0959 0.0929 0.0902 0.0895 0.0881 0.0869 0.0864 0.0856 0.0850 0.0847 0.0842 0.0839 

[TRAIN] Epoch[1](1373/114412); Loss: 0.075689; Backpropagation: 0.2911 sec; Batch: 2.1151 sec
0.1229 0.1024 0.0898 0.0803 0.0755 0.0725 0.0703 0.0689 0.0679 0.0669 0.0663 0.0660 0.0656 0.0654 0.0653 0.0650 

[TRAIN] Epoch[1](1374/114412); Loss: 0.059764; Backpropagation: 0.2909 sec; Batch: 2.1126 sec
0.1245 0.0936 0.0757 0.0643 0.0595 0.0558 0.0534 0.0510 0.0495 0.0486 0.0478 0.0471 0.0468 0.0464 0.0462 0.0460 

[TRAIN] Epoch[1](1375/114412); Loss: 0.057894; Backpropagation: 0.2912 sec; Batch: 2.1136 sec
0.1076 0.0881 0.0715 0.0630 0.0579 0.0556 0.0528 0.0507 0.0498 0.0486 0.0478 0.0474 0.0469 0.0465 0.0462 0.0459 

[TRAIN] Epoch[1](1376/114412); Loss: 0.048048; Backpropagation: 0.2929 sec; Batch: 2.1154 sec
0.1056 0.0741 0.0600 0.0515 0.0477 0.0451 0.0426 0.0410 0.0396 0.0385 0.0379 0.0373 0.0372 0.0370 0.0369 0.0369 

[TRAIN] Epoch[1](1377/114412); Loss: 0.077568; Backpropagation: 0.2914 sec; Batch: 2.1174 sec
0.1642 0.1306 0.1150 0.0917 0.0748 0.0721 0.0680 0.0636 0.0619 0.0597 0.0584 0.0576 0.0565 0.0561 0.0557 0.0552 

[TRAIN] Epoch[1](1378/114412); Loss: 0.072950; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1114 0.0973 0.0886 0.0797 0.0752 0.0726 0.0693 0.0674 0.0658 0.0647 0.0638 0.0631 0.0625 0.0622 0.0618 0.0617 

[TRAIN] Epoch[1](1379/114412); Loss: 0.056614; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.0970 0.0869 0.0802 0.0633 0.0577 0.0550 0.0516 0.0499 0.0481 0.0468 0.0462 0.0453 0.0448 0.0445 0.0442 0.0442 

[TRAIN] Epoch[1](1380/114412); Loss: 0.084201; Backpropagation: 0.2907 sec; Batch: 2.0770 sec
0.1352 0.1204 0.1040 0.0934 0.0879 0.0836 0.0791 0.0770 0.0747 0.0729 0.0717 0.0708 0.0699 0.0694 0.0688 0.0685 

[TRAIN] Epoch[1](1381/114412); Loss: 0.062270; Backpropagation: 0.2905 sec; Batch: 2.0767 sec
0.1181 0.1006 0.0807 0.0686 0.0654 0.0592 0.0559 0.0538 0.0521 0.0507 0.0497 0.0492 0.0487 0.0481 0.0480 0.0475 

[TRAIN] Epoch[1](1382/114412); Loss: 0.071210; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1293 0.1065 0.0845 0.0767 0.0704 0.0689 0.0656 0.0634 0.0620 0.0612 0.0603 0.0594 0.0585 0.0581 0.0574 0.0571 

[TRAIN] Epoch[1](1383/114412); Loss: 0.059033; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1160 0.1006 0.0798 0.0688 0.0628 0.0568 0.0530 0.0501 0.0483 0.0464 0.0452 0.0444 0.0438 0.0433 0.0428 0.0426 

[TRAIN] Epoch[1](1384/114412); Loss: 0.078796; Backpropagation: 0.2908 sec; Batch: 2.0779 sec
0.1214 0.1024 0.0933 0.0862 0.0802 0.0770 0.0749 0.0731 0.0718 0.0705 0.0696 0.0689 0.0683 0.0679 0.0676 0.0674 

[TRAIN] Epoch[1](1385/114412); Loss: 0.052651; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1167 0.0900 0.0668 0.0558 0.0526 0.0488 0.0459 0.0445 0.0430 0.0417 0.0408 0.0399 0.0394 0.0390 0.0387 0.0386 

[TRAIN] Epoch[1](1386/114412); Loss: 0.071470; Backpropagation: 0.2905 sec; Batch: 2.1130 sec
0.1375 0.1058 0.0869 0.0777 0.0715 0.0684 0.0655 0.0628 0.0614 0.0602 0.0591 0.0584 0.0578 0.0572 0.0568 0.0564 

[TRAIN] Epoch[1](1387/114412); Loss: 0.077258; Backpropagation: 0.2906 sec; Batch: 2.1131 sec
0.1496 0.1155 0.0944 0.0834 0.0782 0.0739 0.0709 0.0680 0.0663 0.0646 0.0634 0.0626 0.0620 0.0615 0.0611 0.0607 

[TRAIN] Epoch[1](1388/114412); Loss: 0.055831; Backpropagation: 0.2910 sec; Batch: 2.1147 sec
0.1234 0.0793 0.0716 0.0616 0.0560 0.0521 0.0490 0.0476 0.0463 0.0454 0.0446 0.0440 0.0436 0.0431 0.0429 0.0426 

[TRAIN] Epoch[1](1389/114412); Loss: 0.051341; Backpropagation: 0.2905 sec; Batch: 2.1140 sec
0.1012 0.0755 0.0642 0.0566 0.0517 0.0495 0.0466 0.0447 0.0436 0.0425 0.0419 0.0414 0.0410 0.0407 0.0403 0.0401 

[TRAIN] Epoch[1](1390/114412); Loss: 0.082062; Backpropagation: 0.2910 sec; Batch: 2.0990 sec
0.1486 0.1286 0.1109 0.0998 0.0907 0.0832 0.0785 0.0742 0.0691 0.0658 0.0644 0.0612 0.0604 0.0598 0.0591 0.0586 

[TRAIN] Epoch[1](1391/114412); Loss: 0.069423; Backpropagation: 0.2910 sec; Batch: 2.1146 sec
0.1261 0.1072 0.0914 0.0827 0.0744 0.0690 0.0650 0.0613 0.0589 0.0569 0.0552 0.0541 0.0530 0.0523 0.0519 0.0514 

[TRAIN] Epoch[1](1392/114412); Loss: 0.065315; Backpropagation: 0.2916 sec; Batch: 2.1212 sec
0.1259 0.0963 0.0792 0.0704 0.0666 0.0626 0.0604 0.0582 0.0563 0.0551 0.0539 0.0531 0.0525 0.0520 0.0516 0.0510 

[TRAIN] Epoch[1](1393/114412); Loss: 0.065514; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1067 0.0909 0.0790 0.0721 0.0669 0.0633 0.0613 0.0597 0.0585 0.0574 0.0567 0.0559 0.0554 0.0552 0.0547 0.0545 

[TRAIN] Epoch[1](1394/114412); Loss: 0.064914; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.1338 0.0990 0.0817 0.0729 0.0645 0.0603 0.0573 0.0555 0.0542 0.0534 0.0524 0.0517 0.0512 0.0507 0.0503 0.0500 

[TRAIN] Epoch[1](1395/114412); Loss: 0.059398; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.0936 0.0807 0.0763 0.0655 0.0613 0.0614 0.0561 0.0541 0.0542 0.0518 0.0511 0.0501 0.0492 0.0490 0.0482 0.0479 

[TRAIN] Epoch[1](1396/114412); Loss: 0.066537; Backpropagation: 0.2930 sec; Batch: 2.1161 sec
0.1159 0.0940 0.0752 0.0696 0.0653 0.0639 0.0617 0.0603 0.0596 0.0586 0.0579 0.0575 0.0568 0.0564 0.0562 0.0558 

[TRAIN] Epoch[1](1397/114412); Loss: 0.051058; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1183 0.0868 0.0694 0.0583 0.0510 0.0482 0.0446 0.0418 0.0402 0.0389 0.0379 0.0372 0.0366 0.0361 0.0359 0.0357 

[TRAIN] Epoch[1](1398/114412); Loss: 0.081684; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1604 0.1359 0.1149 0.1016 0.0923 0.0839 0.0774 0.0716 0.0672 0.0641 0.0606 0.0584 0.0564 0.0551 0.0541 0.0532 

[TRAIN] Epoch[1](1399/114412); Loss: 0.062575; Backpropagation: 0.2903 sec; Batch: 2.1177 sec
0.1131 0.0930 0.0757 0.0692 0.0629 0.0597 0.0572 0.0559 0.0544 0.0530 0.0525 0.0517 0.0512 0.0508 0.0505 0.0503 

[TRAIN] Epoch[1](1400/114412); Loss: 0.049690; Backpropagation: 0.2909 sec; Batch: 2.1137 sec
0.0934 0.0741 0.0630 0.0547 0.0511 0.0475 0.0450 0.0438 0.0424 0.0416 0.0409 0.0401 0.0398 0.0395 0.0392 0.0391 

[TRAIN] Epoch[1](1401/114412); Loss: 0.060157; Backpropagation: 0.2907 sec; Batch: 2.1136 sec
0.1156 0.1029 0.0864 0.0734 0.0639 0.0612 0.0547 0.0511 0.0488 0.0464 0.0452 0.0440 0.0433 0.0425 0.0419 0.0414 

[TRAIN] Epoch[1](1402/114412); Loss: 0.088501; Backpropagation: 0.2912 sec; Batch: 2.1190 sec
0.1368 0.1281 0.1120 0.1007 0.0919 0.0868 0.0832 0.0803 0.0784 0.0769 0.0757 0.0746 0.0736 0.0729 0.0723 0.0718 

[TRAIN] Epoch[1](1403/114412); Loss: 0.085322; Backpropagation: 0.2911 sec; Batch: 2.1332 sec
0.1298 0.1107 0.1047 0.0924 0.0859 0.0839 0.0809 0.0790 0.0777 0.0765 0.0754 0.0749 0.0740 0.0735 0.0732 0.0725 

[TRAIN] Epoch[1](1404/114412); Loss: 0.038739; Backpropagation: 0.2908 sec; Batch: 2.1136 sec
0.0877 0.0686 0.0458 0.0407 0.0390 0.0362 0.0335 0.0324 0.0312 0.0306 0.0298 0.0294 0.0292 0.0286 0.0287 0.0285 

[TRAIN] Epoch[1](1405/114412); Loss: 0.066997; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1199 0.1029 0.0794 0.0715 0.0670 0.0633 0.0605 0.0590 0.0582 0.0571 0.0565 0.0560 0.0556 0.0553 0.0550 0.0548 

[TRAIN] Epoch[1](1406/114412); Loss: 0.081604; Backpropagation: 0.2911 sec; Batch: 2.1137 sec
0.1327 0.1131 0.0996 0.0874 0.0824 0.0791 0.0761 0.0744 0.0728 0.0717 0.0708 0.0698 0.0693 0.0690 0.0688 0.0687 

[TRAIN] Epoch[1](1407/114412); Loss: 0.050904; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1022 0.0798 0.0664 0.0566 0.0518 0.0483 0.0460 0.0440 0.0426 0.0412 0.0403 0.0398 0.0393 0.0390 0.0386 0.0385 

[TRAIN] Epoch[1](1408/114412); Loss: 0.052196; Backpropagation: 0.2905 sec; Batch: 2.1174 sec
0.1052 0.0716 0.0724 0.0603 0.0538 0.0503 0.0475 0.0453 0.0437 0.0426 0.0416 0.0409 0.0404 0.0400 0.0398 0.0396 

[TRAIN] Epoch[1](1409/114412); Loss: 0.053544; Backpropagation: 0.2899 sec; Batch: 2.1120 sec
0.1313 0.0893 0.0763 0.0629 0.0526 0.0475 0.0449 0.0427 0.0412 0.0402 0.0391 0.0386 0.0380 0.0375 0.0373 0.0371 

[TRAIN] Epoch[1](1410/114412); Loss: 0.063303; Backpropagation: 0.2897 sec; Batch: 2.1167 sec
0.1365 0.1094 0.0866 0.0706 0.0634 0.0586 0.0549 0.0522 0.0506 0.0491 0.0481 0.0474 0.0471 0.0464 0.0461 0.0459 

[TRAIN] Epoch[1](1411/114412); Loss: 0.079745; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1173 0.1054 0.0943 0.0870 0.0823 0.0784 0.0760 0.0738 0.0726 0.0715 0.0706 0.0701 0.0697 0.0693 0.0689 0.0687 

[TRAIN] Epoch[1](1412/114412); Loss: 0.061830; Backpropagation: 0.2930 sec; Batch: 2.1197 sec
0.1145 0.0972 0.0758 0.0680 0.0626 0.0587 0.0565 0.0546 0.0529 0.0518 0.0509 0.0501 0.0495 0.0491 0.0487 0.0483 

[TRAIN] Epoch[1](1413/114412); Loss: 0.087270; Backpropagation: 0.2928 sec; Batch: 2.1171 sec
0.1252 0.1154 0.1050 0.0951 0.0900 0.0856 0.0833 0.0815 0.0795 0.0784 0.0777 0.0770 0.0763 0.0759 0.0754 0.0751 

[TRAIN] Epoch[1](1414/114412); Loss: 0.049595; Backpropagation: 0.2926 sec; Batch: 2.1168 sec
0.1011 0.0790 0.0653 0.0543 0.0491 0.0457 0.0439 0.0422 0.0407 0.0400 0.0393 0.0390 0.0388 0.0385 0.0383 0.0383 

[TRAIN] Epoch[1](1415/114412); Loss: 0.051963; Backpropagation: 0.2930 sec; Batch: 2.1209 sec
0.1380 0.0940 0.0608 0.0505 0.0478 0.0451 0.0432 0.0413 0.0406 0.0398 0.0391 0.0388 0.0385 0.0382 0.0380 0.0378 

[TRAIN] Epoch[1](1416/114412); Loss: 0.070530; Backpropagation: 0.2927 sec; Batch: 2.1180 sec
0.1088 0.1005 0.0910 0.0817 0.0730 0.0692 0.0666 0.0637 0.0622 0.0609 0.0599 0.0591 0.0585 0.0581 0.0576 0.0574 

[TRAIN] Epoch[1](1417/114412); Loss: 0.093471; Backpropagation: 0.2913 sec; Batch: 2.1141 sec
0.1503 0.1286 0.1105 0.1000 0.0950 0.0907 0.0876 0.0860 0.0840 0.0829 0.0820 0.0810 0.0802 0.0795 0.0789 0.0783 

[TRAIN] Epoch[1](1418/114412); Loss: 0.066865; Backpropagation: 0.2935 sec; Batch: 2.1207 sec
0.1074 0.0925 0.0853 0.0778 0.0699 0.0671 0.0640 0.0612 0.0597 0.0578 0.0567 0.0557 0.0548 0.0542 0.0532 0.0526 

[TRAIN] Epoch[1](1419/114412); Loss: 0.055753; Backpropagation: 0.2915 sec; Batch: 2.1183 sec
0.1133 0.0991 0.0674 0.0586 0.0552 0.0513 0.0490 0.0472 0.0463 0.0450 0.0444 0.0439 0.0433 0.0430 0.0427 0.0424 

[TRAIN] Epoch[1](1420/114412); Loss: 0.057507; Backpropagation: 0.2930 sec; Batch: 2.1222 sec
0.1123 0.0886 0.0712 0.0620 0.0576 0.0546 0.0518 0.0501 0.0487 0.0477 0.0471 0.0464 0.0458 0.0457 0.0454 0.0451 

[TRAIN] Epoch[1](1421/114412); Loss: 0.081084; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1336 0.1029 0.0919 0.0879 0.0810 0.0785 0.0756 0.0745 0.0735 0.0727 0.0717 0.0712 0.0708 0.0706 0.0703 0.0704 

[TRAIN] Epoch[1](1422/114412); Loss: 0.061455; Backpropagation: 0.2926 sec; Batch: 2.1200 sec
0.1251 0.1016 0.0798 0.0694 0.0623 0.0571 0.0545 0.0522 0.0502 0.0491 0.0484 0.0476 0.0471 0.0466 0.0462 0.0460 

[TRAIN] Epoch[1](1423/114412); Loss: 0.069046; Backpropagation: 0.2916 sec; Batch: 2.0788 sec
0.1360 0.1011 0.0862 0.0749 0.0689 0.0665 0.0630 0.0605 0.0591 0.0578 0.0568 0.0560 0.0552 0.0546 0.0543 0.0538 

[TRAIN] Epoch[1](1424/114412); Loss: 0.074365; Backpropagation: 0.2913 sec; Batch: 2.1586 sec
0.1173 0.1094 0.0866 0.0812 0.0758 0.0731 0.0699 0.0679 0.0670 0.0657 0.0644 0.0635 0.0629 0.0621 0.0616 0.0614 

[TRAIN] Epoch[1](1425/114412); Loss: 0.069617; Backpropagation: 0.2917 sec; Batch: 2.1165 sec
0.1206 0.1085 0.0897 0.0781 0.0712 0.0674 0.0633 0.0609 0.0595 0.0582 0.0574 0.0568 0.0561 0.0558 0.0555 0.0551 

[TRAIN] Epoch[1](1426/114412); Loss: 0.062686; Backpropagation: 0.2931 sec; Batch: 2.1193 sec
0.1007 0.0852 0.0723 0.0727 0.0626 0.0604 0.0587 0.0567 0.0558 0.0551 0.0544 0.0542 0.0539 0.0535 0.0534 0.0533 

[TRAIN] Epoch[1](1427/114412); Loss: 0.060379; Backpropagation: 0.2915 sec; Batch: 2.1515 sec
0.1110 0.0905 0.0816 0.0690 0.0613 0.0577 0.0546 0.0521 0.0510 0.0498 0.0488 0.0484 0.0479 0.0477 0.0474 0.0473 

[TRAIN] Epoch[1](1428/114412); Loss: 0.063453; Backpropagation: 0.2910 sec; Batch: 2.1201 sec
0.1228 0.0885 0.0773 0.0728 0.0650 0.0610 0.0580 0.0552 0.0540 0.0530 0.0522 0.0517 0.0512 0.0510 0.0509 0.0506 

[TRAIN] Epoch[1](1429/114412); Loss: 0.061123; Backpropagation: 0.2914 sec; Batch: 2.2201 sec
0.1183 0.0964 0.0766 0.0688 0.0611 0.0583 0.0564 0.0531 0.0516 0.0505 0.0491 0.0483 0.0481 0.0475 0.0470 0.0468 

[TRAIN] Epoch[1](1430/114412); Loss: 0.054893; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.0862 0.0732 0.0698 0.0623 0.0575 0.0542 0.0521 0.0503 0.0490 0.0479 0.0472 0.0465 0.0459 0.0456 0.0454 0.0452 

[TRAIN] Epoch[1](1431/114412); Loss: 0.055469; Backpropagation: 0.2908 sec; Batch: 2.0798 sec
0.0928 0.0805 0.0737 0.0652 0.0579 0.0558 0.0534 0.0504 0.0487 0.0468 0.0455 0.0447 0.0438 0.0433 0.0428 0.0423 

[TRAIN] Epoch[1](1432/114412); Loss: 0.039804; Backpropagation: 0.2911 sec; Batch: 2.1384 sec
0.1154 0.0933 0.0556 0.0452 0.0418 0.0346 0.0312 0.0284 0.0264 0.0252 0.0245 0.0238 0.0233 0.0230 0.0226 0.0225 

[TRAIN] Epoch[1](1433/114412); Loss: 0.065187; Backpropagation: 0.2928 sec; Batch: 2.1189 sec
0.1144 0.0927 0.0782 0.0701 0.0651 0.0627 0.0601 0.0583 0.0573 0.0561 0.0555 0.0552 0.0547 0.0544 0.0542 0.0539 

[TRAIN] Epoch[1](1434/114412); Loss: 0.069239; Backpropagation: 0.2930 sec; Batch: 2.0797 sec
0.1593 0.1100 0.0840 0.0731 0.0687 0.0655 0.0612 0.0587 0.0573 0.0555 0.0543 0.0532 0.0525 0.0519 0.0514 0.0511 

[TRAIN] Epoch[1](1435/114412); Loss: 0.056045; Backpropagation: 0.2913 sec; Batch: 2.1535 sec
0.0935 0.0784 0.0697 0.0617 0.0561 0.0544 0.0521 0.0503 0.0494 0.0486 0.0479 0.0474 0.0471 0.0469 0.0467 0.0465 

[TRAIN] Epoch[1](1436/114412); Loss: 0.054588; Backpropagation: 0.2916 sec; Batch: 2.1155 sec
0.1153 0.0870 0.0709 0.0610 0.0553 0.0518 0.0484 0.0463 0.0447 0.0436 0.0427 0.0421 0.0416 0.0411 0.0409 0.0407 

[TRAIN] Epoch[1](1437/114412); Loss: 0.067493; Backpropagation: 0.2914 sec; Batch: 2.1440 sec
0.1437 0.1060 0.0858 0.0761 0.0685 0.0636 0.0601 0.0571 0.0556 0.0541 0.0530 0.0522 0.0515 0.0511 0.0508 0.0505 

[TRAIN] Epoch[1](1438/114412); Loss: 0.058764; Backpropagation: 0.2910 sec; Batch: 2.1411 sec
0.1106 0.0939 0.0734 0.0633 0.0581 0.0553 0.0530 0.0514 0.0503 0.0492 0.0482 0.0475 0.0471 0.0466 0.0463 0.0460 

[TRAIN] Epoch[1](1439/114412); Loss: 0.071545; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.1103 0.0953 0.0864 0.0783 0.0723 0.0701 0.0673 0.0655 0.0642 0.0633 0.0628 0.0622 0.0619 0.0618 0.0616 0.0614 

[TRAIN] Epoch[1](1440/114412); Loss: 0.056810; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.0972 0.0826 0.0733 0.0642 0.0584 0.0557 0.0532 0.0510 0.0496 0.0484 0.0476 0.0468 0.0460 0.0455 0.0449 0.0446 

[TRAIN] Epoch[1](1441/114412); Loss: 0.067054; Backpropagation: 0.2912 sec; Batch: 2.1438 sec
0.1034 0.0930 0.0846 0.0774 0.0714 0.0655 0.0632 0.0612 0.0595 0.0583 0.0572 0.0565 0.0560 0.0556 0.0552 0.0550 

[TRAIN] Epoch[1](1442/114412); Loss: 0.058078; Backpropagation: 0.2912 sec; Batch: 2.1101 sec
0.1052 0.0904 0.0772 0.0647 0.0572 0.0548 0.0537 0.0513 0.0495 0.0483 0.0473 0.0466 0.0462 0.0458 0.0456 0.0455 

[TRAIN] Epoch[1](1443/114412); Loss: 0.077196; Backpropagation: 0.2921 sec; Batch: 2.1462 sec
0.1289 0.1090 0.0922 0.0833 0.0778 0.0747 0.0721 0.0702 0.0689 0.0674 0.0666 0.0658 0.0651 0.0647 0.0643 0.0641 

[TRAIN] Epoch[1](1444/114412); Loss: 0.074620; Backpropagation: 0.2972 sec; Batch: 2.0938 sec
0.1142 0.1014 0.0920 0.0833 0.0776 0.0745 0.0711 0.0686 0.0670 0.0656 0.0646 0.0639 0.0633 0.0628 0.0622 0.0619 

[TRAIN] Epoch[1](1445/114412); Loss: 0.071281; Backpropagation: 0.2910 sec; Batch: 2.1271 sec
0.1212 0.1006 0.0908 0.0803 0.0722 0.0694 0.0665 0.0640 0.0625 0.0613 0.0601 0.0593 0.0588 0.0582 0.0578 0.0574 

[TRAIN] Epoch[1](1446/114412); Loss: 0.077267; Backpropagation: 0.2912 sec; Batch: 2.2618 sec
0.1459 0.1198 0.0994 0.0873 0.0799 0.0751 0.0705 0.0671 0.0655 0.0635 0.0622 0.0614 0.0605 0.0599 0.0593 0.0588 

[TRAIN] Epoch[1](1447/114412); Loss: 0.070395; Backpropagation: 0.2908 sec; Batch: 2.2804 sec
0.1052 0.0944 0.0833 0.0764 0.0720 0.0694 0.0673 0.0659 0.0643 0.0629 0.0621 0.0615 0.0610 0.0606 0.0602 0.0599 

[TRAIN] Epoch[1](1448/114412); Loss: 0.054185; Backpropagation: 0.2944 sec; Batch: 2.1545 sec
0.0915 0.0814 0.0664 0.0598 0.0554 0.0524 0.0500 0.0481 0.0472 0.0464 0.0455 0.0451 0.0448 0.0446 0.0443 0.0442 

[TRAIN] Epoch[1](1449/114412); Loss: 0.073501; Backpropagation: 0.2931 sec; Batch: 2.0871 sec
0.1287 0.1131 0.0984 0.0825 0.0751 0.0739 0.0679 0.0635 0.0622 0.0607 0.0596 0.0589 0.0584 0.0581 0.0576 0.0574 

[TRAIN] Epoch[1](1450/114412); Loss: 0.086394; Backpropagation: 0.2908 sec; Batch: 2.1157 sec
0.1246 0.1146 0.1034 0.0948 0.0893 0.0859 0.0827 0.0806 0.0786 0.0773 0.0764 0.0758 0.0752 0.0747 0.0743 0.0742 

[TRAIN] Epoch[1](1451/114412); Loss: 0.056090; Backpropagation: 0.2909 sec; Batch: 2.1211 sec
0.1239 0.0993 0.0787 0.0651 0.0574 0.0515 0.0477 0.0451 0.0435 0.0423 0.0415 0.0411 0.0406 0.0402 0.0400 0.0395 

[TRAIN] Epoch[1](1452/114412); Loss: 0.067031; Backpropagation: 0.2921 sec; Batch: 2.0788 sec
0.1056 0.0968 0.0786 0.0728 0.0688 0.0659 0.0633 0.0618 0.0602 0.0589 0.0581 0.0573 0.0567 0.0563 0.0559 0.0555 

[TRAIN] Epoch[1](1453/114412); Loss: 0.054799; Backpropagation: 0.2909 sec; Batch: 2.4907 sec
0.1081 0.0783 0.0661 0.0602 0.0542 0.0520 0.0499 0.0480 0.0468 0.0462 0.0454 0.0449 0.0444 0.0442 0.0441 0.0441 

[TRAIN] Epoch[1](1454/114412); Loss: 0.075752; Backpropagation: 0.2905 sec; Batch: 2.1176 sec
0.1333 0.1205 0.1017 0.0890 0.0820 0.0754 0.0699 0.0663 0.0629 0.0618 0.0600 0.0589 0.0582 0.0576 0.0573 0.0572 

[TRAIN] Epoch[1](1455/114412); Loss: 0.102696; Backpropagation: 0.2931 sec; Batch: 2.1177 sec
0.1677 0.1527 0.1353 0.1185 0.1100 0.1055 0.0982 0.0938 0.0909 0.0868 0.0843 0.0831 0.0810 0.0795 0.0785 0.0773 

[TRAIN] Epoch[1](1456/114412); Loss: 0.078282; Backpropagation: 0.2931 sec; Batch: 2.1432 sec
0.1735 0.1386 0.1093 0.0916 0.0801 0.0730 0.0668 0.0631 0.0605 0.0589 0.0581 0.0571 0.0562 0.0557 0.0553 0.0549 

[TRAIN] Epoch[1](1457/114412); Loss: 0.055006; Backpropagation: 0.2909 sec; Batch: 2.1383 sec
0.1097 0.0906 0.0734 0.0609 0.0553 0.0518 0.0489 0.0464 0.0449 0.0442 0.0434 0.0426 0.0424 0.0420 0.0418 0.0417 

[TRAIN] Epoch[1](1458/114412); Loss: 0.061595; Backpropagation: 0.2909 sec; Batch: 2.1065 sec
0.1069 0.0895 0.0797 0.0692 0.0633 0.0595 0.0564 0.0543 0.0532 0.0520 0.0514 0.0508 0.0502 0.0500 0.0496 0.0493 

[TRAIN] Epoch[1](1459/114412); Loss: 0.058910; Backpropagation: 0.2905 sec; Batch: 2.1232 sec
0.1296 0.1071 0.0843 0.0705 0.0605 0.0534 0.0496 0.0467 0.0454 0.0438 0.0429 0.0423 0.0417 0.0416 0.0415 0.0415 

[TRAIN] Epoch[1](1460/114412); Loss: 0.062884; Backpropagation: 0.2950 sec; Batch: 2.0941 sec
0.1007 0.0886 0.0760 0.0689 0.0643 0.0613 0.0590 0.0574 0.0560 0.0550 0.0544 0.0538 0.0531 0.0528 0.0525 0.0524 

[TRAIN] Epoch[1](1461/114412); Loss: 0.079171; Backpropagation: 0.2928 sec; Batch: 2.1432 sec
0.1384 0.1082 0.0937 0.0857 0.0800 0.0764 0.0742 0.0716 0.0702 0.0690 0.0680 0.0672 0.0666 0.0663 0.0657 0.0654 

[TRAIN] Epoch[1](1462/114412); Loss: 0.054524; Backpropagation: 0.2908 sec; Batch: 2.1144 sec
0.1152 0.0945 0.0787 0.0651 0.0566 0.0508 0.0467 0.0440 0.0422 0.0415 0.0407 0.0400 0.0396 0.0392 0.0389 0.0386 

[TRAIN] Epoch[1](1463/114412); Loss: 0.054710; Backpropagation: 0.2914 sec; Batch: 2.1381 sec
0.1053 0.0870 0.0629 0.0553 0.0523 0.0512 0.0485 0.0473 0.0467 0.0460 0.0458 0.0458 0.0454 0.0454 0.0454 0.0451 

[TRAIN] Epoch[1](1464/114412); Loss: 0.081251; Backpropagation: 0.2912 sec; Batch: 2.0915 sec
0.1526 0.1315 0.1055 0.0888 0.0829 0.0779 0.0743 0.0712 0.0688 0.0665 0.0654 0.0643 0.0635 0.0627 0.0622 0.0620 

[TRAIN] Epoch[1](1465/114412); Loss: 0.053045; Backpropagation: 0.2905 sec; Batch: 2.1394 sec
0.1221 0.0828 0.0636 0.0570 0.0514 0.0477 0.0455 0.0443 0.0434 0.0427 0.0421 0.0417 0.0414 0.0411 0.0410 0.0410 

[TRAIN] Epoch[1](1466/114412); Loss: 0.088319; Backpropagation: 0.2907 sec; Batch: 2.1240 sec
0.1649 0.1260 0.1078 0.0979 0.0910 0.0859 0.0811 0.0783 0.0761 0.0743 0.0732 0.0724 0.0716 0.0712 0.0711 0.0705 

[TRAIN] Epoch[1](1467/114412); Loss: 0.044924; Backpropagation: 0.2907 sec; Batch: 2.1075 sec
0.0864 0.0744 0.0537 0.0476 0.0437 0.0416 0.0401 0.0391 0.0380 0.0372 0.0368 0.0364 0.0361 0.0359 0.0358 0.0358 

[TRAIN] Epoch[1](1468/114412); Loss: 0.038394; Backpropagation: 0.2912 sec; Batch: 2.1413 sec
0.0791 0.0665 0.0512 0.0434 0.0389 0.0362 0.0340 0.0322 0.0308 0.0300 0.0292 0.0289 0.0286 0.0285 0.0284 0.0284 

[TRAIN] Epoch[1](1469/114412); Loss: 0.071271; Backpropagation: 0.2910 sec; Batch: 2.1085 sec
0.1230 0.1049 0.0876 0.0792 0.0732 0.0691 0.0660 0.0638 0.0623 0.0609 0.0598 0.0592 0.0586 0.0579 0.0575 0.0572 

[TRAIN] Epoch[1](1470/114412); Loss: 0.059246; Backpropagation: 0.2914 sec; Batch: 2.1467 sec
0.1060 0.1125 0.0895 0.0735 0.0614 0.0547 0.0507 0.0492 0.0468 0.0454 0.0443 0.0436 0.0430 0.0427 0.0424 0.0422 

[TRAIN] Epoch[1](1471/114412); Loss: 0.047789; Backpropagation: 0.2910 sec; Batch: 2.1113 sec
0.1189 0.0874 0.0598 0.0521 0.0454 0.0427 0.0396 0.0387 0.0374 0.0360 0.0353 0.0348 0.0344 0.0341 0.0341 0.0340 

[TRAIN] Epoch[1](1472/114412); Loss: 0.058048; Backpropagation: 0.2933 sec; Batch: 2.1500 sec
0.1021 0.0880 0.0722 0.0637 0.0592 0.0551 0.0529 0.0511 0.0499 0.0491 0.0486 0.0482 0.0477 0.0474 0.0470 0.0466 

[TRAIN] Epoch[1](1473/114412); Loss: 0.047361; Backpropagation: 0.2921 sec; Batch: 2.0879 sec
0.1007 0.0837 0.0655 0.0549 0.0488 0.0445 0.0408 0.0389 0.0376 0.0363 0.0353 0.0349 0.0345 0.0341 0.0339 0.0335 

[TRAIN] Epoch[1](1474/114412); Loss: 0.078767; Backpropagation: 0.2912 sec; Batch: 2.3471 sec
0.1563 0.1423 0.1133 0.0962 0.0844 0.0761 0.0702 0.0660 0.0624 0.0598 0.0578 0.0566 0.0556 0.0548 0.0543 0.0540 

[TRAIN] Epoch[1](1475/114412); Loss: 0.075412; Backpropagation: 0.2914 sec; Batch: 2.0928 sec
0.1375 0.1258 0.1063 0.0904 0.0794 0.0744 0.0679 0.0647 0.0619 0.0601 0.0585 0.0573 0.0563 0.0558 0.0553 0.0549 

[TRAIN] Epoch[1](1476/114412); Loss: 0.056675; Backpropagation: 0.2911 sec; Batch: 2.1050 sec
0.1303 0.1008 0.0826 0.0686 0.0601 0.0540 0.0480 0.0447 0.0433 0.0413 0.0401 0.0395 0.0389 0.0385 0.0381 0.0377 

[TRAIN] Epoch[1](1477/114412); Loss: 0.080228; Backpropagation: 0.2913 sec; Batch: 2.1118 sec
0.1303 0.1163 0.0981 0.0886 0.0840 0.0778 0.0744 0.0729 0.0710 0.0694 0.0684 0.0676 0.0669 0.0664 0.0659 0.0656 

[TRAIN] Epoch[1](1478/114412); Loss: 0.083544; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1303 0.1172 0.1021 0.0917 0.0838 0.0799 0.0771 0.0758 0.0744 0.0731 0.0726 0.0724 0.0719 0.0716 0.0716 0.0712 

[TRAIN] Epoch[1](1479/114412); Loss: 0.064656; Backpropagation: 0.2930 sec; Batch: 2.0792 sec
0.1202 0.0987 0.0782 0.0692 0.0651 0.0610 0.0584 0.0574 0.0554 0.0547 0.0539 0.0532 0.0530 0.0525 0.0520 0.0518 

[TRAIN] Epoch[1](1480/114412); Loss: 0.057750; Backpropagation: 0.2931 sec; Batch: 2.1207 sec
0.1008 0.0818 0.0701 0.0628 0.0582 0.0553 0.0530 0.0517 0.0506 0.0496 0.0492 0.0488 0.0484 0.0481 0.0479 0.0478 

[TRAIN] Epoch[1](1481/114412); Loss: 0.069761; Backpropagation: 0.2910 sec; Batch: 2.1154 sec
0.1290 0.1051 0.0879 0.0790 0.0724 0.0670 0.0640 0.0610 0.0594 0.0580 0.0570 0.0563 0.0557 0.0551 0.0548 0.0544 

[TRAIN] Epoch[1](1482/114412); Loss: 0.061774; Backpropagation: 0.2906 sec; Batch: 2.1132 sec
0.1115 0.0929 0.0744 0.0652 0.0602 0.0581 0.0560 0.0545 0.0539 0.0528 0.0523 0.0519 0.0515 0.0514 0.0510 0.0507 

[TRAIN] Epoch[1](1483/114412); Loss: 0.072799; Backpropagation: 0.2909 sec; Batch: 2.1183 sec
0.1195 0.1070 0.0911 0.0816 0.0752 0.0720 0.0681 0.0653 0.0643 0.0628 0.0611 0.0604 0.0599 0.0591 0.0588 0.0586 

[TRAIN] Epoch[1](1484/114412); Loss: 0.063047; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1186 0.1058 0.0887 0.0776 0.0692 0.0626 0.0571 0.0535 0.0510 0.0491 0.0477 0.0466 0.0460 0.0454 0.0450 0.0448 

[TRAIN] Epoch[1](1485/114412); Loss: 0.070527; Backpropagation: 0.2908 sec; Batch: 2.1217 sec
0.1448 0.1021 0.0901 0.0785 0.0711 0.0664 0.0630 0.0603 0.0589 0.0577 0.0571 0.0565 0.0560 0.0557 0.0554 0.0550 

[TRAIN] Epoch[1](1486/114412); Loss: 0.081826; Backpropagation: 0.2915 sec; Batch: 2.1303 sec
0.1319 0.1116 0.0988 0.0908 0.0857 0.0807 0.0762 0.0737 0.0728 0.0714 0.0705 0.0700 0.0694 0.0689 0.0686 0.0683 

[TRAIN] Epoch[1](1487/114412); Loss: 0.090504; Backpropagation: 0.2904 sec; Batch: 2.0790 sec
0.1748 0.1530 0.1204 0.1017 0.0943 0.0879 0.0798 0.0765 0.0748 0.0720 0.0709 0.0697 0.0690 0.0683 0.0676 0.0673 

[TRAIN] Epoch[1](1488/114412); Loss: 0.062637; Backpropagation: 0.2904 sec; Batch: 2.1179 sec
0.1094 0.0974 0.0791 0.0700 0.0630 0.0601 0.0573 0.0553 0.0537 0.0528 0.0518 0.0514 0.0509 0.0502 0.0500 0.0498 

[TRAIN] Epoch[1](1489/114412); Loss: 0.065294; Backpropagation: 0.2946 sec; Batch: 2.0810 sec
0.1233 0.1026 0.0849 0.0740 0.0659 0.0623 0.0591 0.0569 0.0548 0.0536 0.0525 0.0521 0.0514 0.0508 0.0505 0.0501 

[TRAIN] Epoch[1](1490/114412); Loss: 0.055254; Backpropagation: 0.2905 sec; Batch: 2.1179 sec
0.1461 0.0949 0.0659 0.0599 0.0516 0.0488 0.0460 0.0442 0.0429 0.0419 0.0413 0.0407 0.0402 0.0400 0.0399 0.0397 

[TRAIN] Epoch[1](1491/114412); Loss: 0.077251; Backpropagation: 0.2904 sec; Batch: 2.0770 sec
0.1252 0.1035 0.0905 0.0818 0.0774 0.0745 0.0723 0.0708 0.0698 0.0686 0.0679 0.0675 0.0670 0.0666 0.0664 0.0661 

[TRAIN] Epoch[1](1492/114412); Loss: 0.081329; Backpropagation: 0.2905 sec; Batch: 2.1306 sec
0.1383 0.1179 0.1000 0.0896 0.0812 0.0780 0.0750 0.0734 0.0717 0.0702 0.0693 0.0685 0.0678 0.0672 0.0668 0.0664 

[TRAIN] Epoch[1](1493/114412); Loss: 0.071779; Backpropagation: 0.2906 sec; Batch: 2.1169 sec
0.1387 0.1188 0.0960 0.0857 0.0769 0.0697 0.0647 0.0611 0.0584 0.0564 0.0552 0.0547 0.0537 0.0533 0.0530 0.0524 

[TRAIN] Epoch[1](1494/114412); Loss: 0.077335; Backpropagation: 0.2914 sec; Batch: 2.1052 sec
0.1303 0.1113 0.0916 0.0816 0.0765 0.0727 0.0706 0.0694 0.0688 0.0679 0.0671 0.0668 0.0663 0.0658 0.0654 0.0652 

[TRAIN] Epoch[1](1495/114412); Loss: 0.070888; Backpropagation: 0.2909 sec; Batch: 2.1189 sec
0.1238 0.1075 0.0859 0.0794 0.0729 0.0681 0.0649 0.0624 0.0613 0.0598 0.0591 0.0586 0.0580 0.0578 0.0574 0.0572 

[TRAIN] Epoch[1](1496/114412); Loss: 0.055010; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1191 0.0958 0.0750 0.0629 0.0550 0.0500 0.0469 0.0454 0.0438 0.0426 0.0419 0.0411 0.0406 0.0402 0.0399 0.0397 

[TRAIN] Epoch[1](1497/114412); Loss: 0.075661; Backpropagation: 0.2909 sec; Batch: 2.1123 sec
0.1497 0.1257 0.1042 0.0933 0.0834 0.0747 0.0679 0.0626 0.0599 0.0583 0.0574 0.0560 0.0552 0.0546 0.0540 0.0536 

[TRAIN] Epoch[1](1498/114412); Loss: 0.101811; Backpropagation: 0.2911 sec; Batch: 2.1134 sec
0.1745 0.1509 0.1287 0.1134 0.0997 0.0955 0.0925 0.0904 0.0882 0.0874 0.0862 0.0853 0.0847 0.0841 0.0839 0.0836 

[TRAIN] Epoch[1](1499/114412); Loss: 0.051556; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1106 0.0851 0.0668 0.0575 0.0494 0.0465 0.0447 0.0432 0.0421 0.0411 0.0405 0.0402 0.0398 0.0394 0.0392 0.0389 

[TRAIN] Epoch[1](1500/114412); Loss: 0.055390; Backpropagation: 0.2910 sec; Batch: 2.1260 sec
0.1072 0.0749 0.0750 0.0602 0.0561 0.0527 0.0503 0.0490 0.0471 0.0466 0.0457 0.0449 0.0447 0.0441 0.0439 0.0437 

[TRAIN] Epoch[1](1501/114412); Loss: 0.076646; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1367 0.1176 0.0962 0.0860 0.0798 0.0751 0.0712 0.0687 0.0667 0.0645 0.0633 0.0621 0.0606 0.0600 0.0593 0.0585 

[TRAIN] Epoch[1](1502/114412); Loss: 0.057399; Backpropagation: 0.2931 sec; Batch: 2.1150 sec
0.1182 0.1000 0.0773 0.0654 0.0595 0.0517 0.0499 0.0480 0.0460 0.0450 0.0441 0.0432 0.0428 0.0426 0.0424 0.0422 

[TRAIN] Epoch[1](1503/114412); Loss: 0.080984; Backpropagation: 0.2928 sec; Batch: 2.1340 sec
0.1421 0.1212 0.1009 0.0885 0.0799 0.0764 0.0738 0.0722 0.0707 0.0693 0.0683 0.0676 0.0670 0.0664 0.0659 0.0656 

[TRAIN] Epoch[1](1504/114412); Loss: 0.059467; Backpropagation: 0.2931 sec; Batch: 2.1216 sec
0.1162 0.0910 0.0723 0.0655 0.0587 0.0564 0.0538 0.0518 0.0507 0.0495 0.0488 0.0482 0.0477 0.0474 0.0470 0.0467 

[TRAIN] Epoch[1](1505/114412); Loss: 0.062953; Backpropagation: 0.2925 sec; Batch: 2.1206 sec
0.1376 0.1158 0.0937 0.0706 0.0648 0.0626 0.0553 0.0509 0.0488 0.0470 0.0454 0.0443 0.0435 0.0427 0.0423 0.0419 

[TRAIN] Epoch[1](1506/114412); Loss: 0.075408; Backpropagation: 0.2952 sec; Batch: 2.1206 sec
0.1563 0.1184 0.0928 0.0816 0.0742 0.0705 0.0671 0.0647 0.0632 0.0619 0.0608 0.0601 0.0594 0.0588 0.0585 0.0582 

[TRAIN] Epoch[1](1507/114412); Loss: 0.056724; Backpropagation: 0.2932 sec; Batch: 2.1231 sec
0.1325 0.0955 0.0736 0.0611 0.0538 0.0519 0.0491 0.0466 0.0454 0.0443 0.0434 0.0428 0.0423 0.0421 0.0418 0.0415 

[TRAIN] Epoch[1](1508/114412); Loss: 0.051252; Backpropagation: 0.2928 sec; Batch: 2.1228 sec
0.0926 0.0813 0.0756 0.0615 0.0503 0.0481 0.0454 0.0433 0.0424 0.0412 0.0405 0.0403 0.0397 0.0395 0.0393 0.0391 

[TRAIN] Epoch[1](1509/114412); Loss: 0.070416; Backpropagation: 0.2908 sec; Batch: 2.1188 sec
0.1305 0.1101 0.0857 0.0777 0.0713 0.0687 0.0664 0.0620 0.0605 0.0599 0.0571 0.0566 0.0562 0.0550 0.0547 0.0543 

[TRAIN] Epoch[1](1510/114412); Loss: 0.076395; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1224 0.1108 0.0999 0.0887 0.0819 0.0761 0.0714 0.0687 0.0663 0.0650 0.0638 0.0628 0.0620 0.0612 0.0607 0.0603 

[TRAIN] Epoch[1](1511/114412); Loss: 0.078742; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1413 0.1204 0.0982 0.0848 0.0784 0.0743 0.0715 0.0695 0.0681 0.0667 0.0657 0.0652 0.0646 0.0640 0.0638 0.0634 

[TRAIN] Epoch[1](1512/114412); Loss: 0.062052; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1117 0.0925 0.0791 0.0682 0.0634 0.0584 0.0562 0.0542 0.0531 0.0522 0.0514 0.0510 0.0507 0.0503 0.0503 0.0501 

[TRAIN] Epoch[1](1513/114412); Loss: 0.053461; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1142 0.0970 0.0774 0.0638 0.0542 0.0508 0.0469 0.0442 0.0416 0.0399 0.0391 0.0382 0.0376 0.0372 0.0367 0.0366 

[TRAIN] Epoch[1](1514/114412); Loss: 0.061728; Backpropagation: 0.2933 sec; Batch: 2.1199 sec
0.1209 0.1015 0.0797 0.0679 0.0603 0.0575 0.0543 0.0524 0.0515 0.0503 0.0497 0.0491 0.0486 0.0483 0.0480 0.0477 

[TRAIN] Epoch[1](1515/114412); Loss: 0.087042; Backpropagation: 0.2925 sec; Batch: 2.0797 sec
0.1637 0.1453 0.1182 0.1026 0.0882 0.0814 0.0774 0.0741 0.0719 0.0704 0.0687 0.0676 0.0667 0.0660 0.0655 0.0651 

[TRAIN] Epoch[1](1516/114412); Loss: 0.070535; Backpropagation: 0.2930 sec; Batch: 2.1142 sec
0.1420 0.1162 0.0950 0.0794 0.0717 0.0670 0.0630 0.0601 0.0583 0.0566 0.0550 0.0546 0.0534 0.0526 0.0522 0.0515 

[TRAIN] Epoch[1](1517/114412); Loss: 0.080360; Backpropagation: 0.2913 sec; Batch: 2.1168 sec
0.1278 0.1184 0.0928 0.0851 0.0808 0.0773 0.0747 0.0731 0.0719 0.0709 0.0702 0.0694 0.0689 0.0685 0.0681 0.0679 

[TRAIN] Epoch[1](1518/114412); Loss: 0.075684; Backpropagation: 0.2913 sec; Batch: 2.1145 sec
0.1369 0.1124 0.0918 0.0813 0.0767 0.0727 0.0696 0.0675 0.0661 0.0645 0.0635 0.0626 0.0620 0.0615 0.0611 0.0608 

[TRAIN] Epoch[1](1519/114412); Loss: 0.062130; Backpropagation: 0.2928 sec; Batch: 2.1187 sec
0.0995 0.0868 0.0771 0.0702 0.0655 0.0602 0.0580 0.0563 0.0551 0.0540 0.0531 0.0524 0.0519 0.0516 0.0513 0.0511 

[TRAIN] Epoch[1](1520/114412); Loss: 0.060617; Backpropagation: 0.2912 sec; Batch: 2.1206 sec
0.1057 0.0896 0.0742 0.0650 0.0598 0.0583 0.0555 0.0540 0.0531 0.0521 0.0514 0.0509 0.0505 0.0502 0.0499 0.0497 

[TRAIN] Epoch[1](1521/114412); Loss: 0.073436; Backpropagation: 0.2912 sec; Batch: 2.1206 sec
0.1250 0.1127 0.0920 0.0828 0.0789 0.0709 0.0676 0.0659 0.0631 0.0614 0.0606 0.0598 0.0592 0.0588 0.0584 0.0580 

[TRAIN] Epoch[1](1522/114412); Loss: 0.066561; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1446 0.0962 0.0738 0.0681 0.0644 0.0617 0.0596 0.0580 0.0571 0.0561 0.0553 0.0549 0.0543 0.0540 0.0537 0.0534 

[TRAIN] Epoch[1](1523/114412); Loss: 0.061733; Backpropagation: 0.2913 sec; Batch: 2.0812 sec
0.1642 0.1068 0.0717 0.0632 0.0568 0.0551 0.0527 0.0495 0.0483 0.0473 0.0464 0.0459 0.0454 0.0450 0.0448 0.0446 

[TRAIN] Epoch[1](1524/114412); Loss: 0.056077; Backpropagation: 0.2912 sec; Batch: 2.0997 sec
0.1179 0.0870 0.0725 0.0637 0.0550 0.0520 0.0500 0.0477 0.0463 0.0451 0.0444 0.0440 0.0434 0.0430 0.0427 0.0425 

[TRAIN] Epoch[1](1525/114412); Loss: 0.078019; Backpropagation: 0.2910 sec; Batch: 2.1183 sec
0.1454 0.1248 0.1008 0.0895 0.0833 0.0755 0.0703 0.0672 0.0653 0.0642 0.0625 0.0613 0.0604 0.0596 0.0593 0.0589 

[TRAIN] Epoch[1](1526/114412); Loss: 0.074522; Backpropagation: 0.2950 sec; Batch: 2.1252 sec
0.1278 0.1137 0.0938 0.0820 0.0783 0.0734 0.0697 0.0673 0.0648 0.0633 0.0621 0.0608 0.0599 0.0591 0.0585 0.0578 

[TRAIN] Epoch[1](1527/114412); Loss: 0.052946; Backpropagation: 0.2942 sec; Batch: 2.1219 sec
0.1045 0.0844 0.0684 0.0605 0.0548 0.0504 0.0477 0.0459 0.0439 0.0429 0.0419 0.0412 0.0408 0.0402 0.0399 0.0397 

[TRAIN] Epoch[1](1528/114412); Loss: 0.053058; Backpropagation: 0.2953 sec; Batch: 2.1218 sec
0.0970 0.0817 0.0609 0.0556 0.0517 0.0494 0.0481 0.0468 0.0461 0.0455 0.0451 0.0447 0.0444 0.0441 0.0440 0.0439 

[TRAIN] Epoch[1](1529/114412); Loss: 0.071254; Backpropagation: 0.2929 sec; Batch: 2.1176 sec
0.1519 0.1057 0.0784 0.0720 0.0681 0.0684 0.0648 0.0622 0.0612 0.0600 0.0590 0.0585 0.0580 0.0576 0.0574 0.0570 

[TRAIN] Epoch[1](1530/114412); Loss: 0.070209; Backpropagation: 0.2913 sec; Batch: 2.0985 sec
0.1563 0.1247 0.0953 0.0847 0.0750 0.0666 0.0623 0.0575 0.0539 0.0524 0.0510 0.0501 0.0494 0.0485 0.0481 0.0476 

[TRAIN] Epoch[1](1531/114412); Loss: 0.050667; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1236 0.1012 0.0728 0.0603 0.0504 0.0448 0.0412 0.0391 0.0375 0.0362 0.0351 0.0344 0.0340 0.0336 0.0334 0.0331 

[TRAIN] Epoch[1](1532/114412); Loss: 0.057605; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.1019 0.0796 0.0744 0.0637 0.0587 0.0552 0.0530 0.0514 0.0502 0.0492 0.0484 0.0478 0.0475 0.0472 0.0469 0.0466 

[TRAIN] Epoch[1](1533/114412); Loss: 0.062143; Backpropagation: 0.2912 sec; Batch: 2.1124 sec
0.1006 0.0849 0.0831 0.0699 0.0628 0.0596 0.0585 0.0565 0.0549 0.0537 0.0528 0.0523 0.0517 0.0513 0.0510 0.0506 

[TRAIN] Epoch[1](1534/114412); Loss: 0.056540; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1451 0.0929 0.0701 0.0605 0.0552 0.0504 0.0480 0.0462 0.0447 0.0437 0.0427 0.0418 0.0413 0.0410 0.0406 0.0403 

[TRAIN] Epoch[1](1535/114412); Loss: 0.051124; Backpropagation: 0.2911 sec; Batch: 2.1152 sec
0.0991 0.0755 0.0643 0.0575 0.0524 0.0487 0.0468 0.0449 0.0432 0.0425 0.0415 0.0408 0.0406 0.0402 0.0401 0.0399 

[TRAIN] Epoch[1](1536/114412); Loss: 0.056025; Backpropagation: 0.2934 sec; Batch: 2.1195 sec
0.1144 0.0899 0.0717 0.0631 0.0566 0.0532 0.0496 0.0481 0.0464 0.0453 0.0446 0.0436 0.0431 0.0426 0.0422 0.0418 

[TRAIN] Epoch[1](1537/114412); Loss: 0.045299; Backpropagation: 0.2924 sec; Batch: 2.1167 sec
0.0953 0.0841 0.0587 0.0520 0.0460 0.0410 0.0386 0.0369 0.0358 0.0351 0.0346 0.0340 0.0336 0.0333 0.0330 0.0327 

[TRAIN] Epoch[1](1538/114412); Loss: 0.046834; Backpropagation: 0.2935 sec; Batch: 2.1239 sec
0.0884 0.0785 0.0590 0.0540 0.0502 0.0463 0.0424 0.0400 0.0387 0.0378 0.0369 0.0361 0.0357 0.0353 0.0351 0.0349 

[TRAIN] Epoch[1](1539/114412); Loss: 0.073013; Backpropagation: 0.2942 sec; Batch: 2.0819 sec
0.1163 0.1013 0.0959 0.0822 0.0751 0.0710 0.0684 0.0661 0.0643 0.0628 0.0620 0.0613 0.0609 0.0606 0.0603 0.0600 

[TRAIN] Epoch[1](1540/114412); Loss: 0.050095; Backpropagation: 0.2918 sec; Batch: 2.0852 sec
0.0916 0.0837 0.0745 0.0593 0.0502 0.0503 0.0457 0.0420 0.0419 0.0397 0.0384 0.0377 0.0371 0.0368 0.0364 0.0361 

[TRAIN] Epoch[1](1541/114412); Loss: 0.075418; Backpropagation: 0.2906 sec; Batch: 2.0768 sec
0.1317 0.0995 0.0896 0.0798 0.0746 0.0723 0.0698 0.0686 0.0670 0.0663 0.0656 0.0650 0.0646 0.0644 0.0641 0.0639 

[TRAIN] Epoch[1](1542/114412); Loss: 0.115581; Backpropagation: 0.2910 sec; Batch: 2.1152 sec
0.1843 0.1501 0.1341 0.1245 0.1177 0.1131 0.1095 0.1073 0.1053 0.1034 0.1022 0.1011 0.1001 0.0995 0.0988 0.0982 

[TRAIN] Epoch[1](1543/114412); Loss: 0.080634; Backpropagation: 0.2930 sec; Batch: 2.1168 sec
0.1743 0.1499 0.1227 0.0966 0.0838 0.0752 0.0660 0.0621 0.0602 0.0588 0.0582 0.0575 0.0568 0.0564 0.0561 0.0557 

[TRAIN] Epoch[1](1544/114412); Loss: 0.062638; Backpropagation: 0.2930 sec; Batch: 2.1462 sec
0.1127 0.0964 0.0838 0.0703 0.0639 0.0609 0.0579 0.0548 0.0532 0.0519 0.0507 0.0500 0.0494 0.0491 0.0488 0.0485 

[TRAIN] Epoch[1](1545/114412); Loss: 0.058244; Backpropagation: 0.2911 sec; Batch: 2.1102 sec
0.1029 0.0851 0.0735 0.0648 0.0597 0.0559 0.0538 0.0520 0.0507 0.0496 0.0488 0.0480 0.0474 0.0470 0.0466 0.0463 

[TRAIN] Epoch[1](1546/114412); Loss: 0.072069; Backpropagation: 0.2928 sec; Batch: 2.1053 sec
0.1477 0.1295 0.0920 0.0804 0.0741 0.0659 0.0623 0.0595 0.0576 0.0567 0.0559 0.0552 0.0546 0.0542 0.0539 0.0536 

[TRAIN] Epoch[1](1547/114412); Loss: 0.052157; Backpropagation: 0.2911 sec; Batch: 2.1131 sec
0.1046 0.0838 0.0762 0.0635 0.0540 0.0502 0.0457 0.0434 0.0419 0.0410 0.0399 0.0390 0.0383 0.0380 0.0377 0.0374 

[TRAIN] Epoch[1](1548/114412); Loss: 0.064954; Backpropagation: 0.2909 sec; Batch: 2.1155 sec
0.1234 0.1075 0.0874 0.0747 0.0669 0.0596 0.0575 0.0554 0.0540 0.0526 0.0514 0.0507 0.0502 0.0496 0.0493 0.0490 

[TRAIN] Epoch[1](1549/114412); Loss: 0.080535; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1552 0.1177 0.0975 0.0878 0.0815 0.0772 0.0731 0.0718 0.0695 0.0680 0.0667 0.0655 0.0651 0.0644 0.0639 0.0636 

[TRAIN] Epoch[1](1550/114412); Loss: 0.054608; Backpropagation: 0.2911 sec; Batch: 2.1207 sec
0.0957 0.0799 0.0690 0.0589 0.0551 0.0525 0.0507 0.0489 0.0478 0.0467 0.0461 0.0453 0.0448 0.0445 0.0441 0.0439 

[TRAIN] Epoch[1](1551/114412); Loss: 0.054798; Backpropagation: 0.2930 sec; Batch: 2.1163 sec
0.0944 0.0787 0.0691 0.0603 0.0566 0.0525 0.0505 0.0490 0.0482 0.0471 0.0463 0.0456 0.0451 0.0448 0.0444 0.0441 

[TRAIN] Epoch[1](1552/114412); Loss: 0.068406; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1161 0.0911 0.0821 0.0744 0.0695 0.0666 0.0640 0.0621 0.0608 0.0597 0.0591 0.0584 0.0580 0.0577 0.0575 0.0572 

[TRAIN] Epoch[1](1553/114412); Loss: 0.076713; Backpropagation: 0.2906 sec; Batch: 2.1144 sec
0.1345 0.1036 0.0959 0.0847 0.0779 0.0753 0.0720 0.0699 0.0678 0.0663 0.0648 0.0639 0.0634 0.0628 0.0624 0.0622 

[TRAIN] Epoch[1](1554/114412); Loss: 0.063397; Backpropagation: 0.2905 sec; Batch: 2.1286 sec
0.1021 0.0924 0.0749 0.0671 0.0635 0.0611 0.0593 0.0578 0.0565 0.0557 0.0549 0.0544 0.0540 0.0538 0.0535 0.0533 

[TRAIN] Epoch[1](1555/114412); Loss: 0.056192; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1029 0.0832 0.0731 0.0615 0.0575 0.0544 0.0521 0.0498 0.0478 0.0470 0.0464 0.0457 0.0450 0.0446 0.0442 0.0439 

[TRAIN] Epoch[1](1556/114412); Loss: 0.072378; Backpropagation: 0.2909 sec; Batch: 2.1334 sec
0.1180 0.1021 0.0980 0.0851 0.0769 0.0726 0.0689 0.0659 0.0639 0.0610 0.0599 0.0587 0.0577 0.0572 0.0564 0.0560 

[TRAIN] Epoch[1](1557/114412); Loss: 0.061700; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1441 0.1214 0.0836 0.0652 0.0582 0.0553 0.0523 0.0497 0.0476 0.0463 0.0454 0.0444 0.0440 0.0436 0.0433 0.0430 

[TRAIN] Epoch[1](1558/114412); Loss: 0.060606; Backpropagation: 0.2908 sec; Batch: 2.1229 sec
0.1020 0.0933 0.0888 0.0712 0.0622 0.0581 0.0555 0.0532 0.0515 0.0502 0.0487 0.0482 0.0475 0.0468 0.0465 0.0461 

[TRAIN] Epoch[1](1559/114412); Loss: 0.070890; Backpropagation: 0.2909 sec; Batch: 2.0790 sec
0.1421 0.1185 0.0935 0.0777 0.0688 0.0656 0.0630 0.0603 0.0584 0.0572 0.0565 0.0555 0.0552 0.0544 0.0540 0.0537 

[TRAIN] Epoch[1](1560/114412); Loss: 0.076310; Backpropagation: 0.2915 sec; Batch: 2.1169 sec
0.1232 0.1062 0.0959 0.0840 0.0781 0.0740 0.0713 0.0691 0.0675 0.0664 0.0655 0.0649 0.0643 0.0639 0.0635 0.0633 

[TRAIN] Epoch[1](1561/114412); Loss: 0.079599; Backpropagation: 0.2928 sec; Batch: 2.0792 sec
0.1450 0.1197 0.0950 0.0827 0.0788 0.0753 0.0730 0.0708 0.0695 0.0686 0.0676 0.0668 0.0660 0.0654 0.0649 0.0644 

[TRAIN] Epoch[1](1562/114412); Loss: 0.064285; Backpropagation: 0.2907 sec; Batch: 2.1153 sec
0.1341 0.1020 0.0790 0.0678 0.0642 0.0598 0.0575 0.0554 0.0542 0.0528 0.0518 0.0512 0.0503 0.0498 0.0494 0.0490 

[TRAIN] Epoch[1](1563/114412); Loss: 0.051001; Backpropagation: 0.2920 sec; Batch: 2.1183 sec
0.0912 0.0748 0.0621 0.0575 0.0529 0.0495 0.0473 0.0456 0.0445 0.0434 0.0425 0.0418 0.0412 0.0409 0.0405 0.0402 

[TRAIN] Epoch[1](1564/114412); Loss: 0.070189; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1199 0.0995 0.0839 0.0771 0.0729 0.0686 0.0654 0.0629 0.0616 0.0604 0.0599 0.0592 0.0585 0.0580 0.0577 0.0575 

[TRAIN] Epoch[1](1565/114412); Loss: 0.059017; Backpropagation: 0.2905 sec; Batch: 2.1191 sec
0.0997 0.0856 0.0761 0.0647 0.0602 0.0568 0.0552 0.0528 0.0514 0.0503 0.0496 0.0490 0.0486 0.0484 0.0481 0.0478 

[TRAIN] Epoch[1](1566/114412); Loss: 0.059592; Backpropagation: 0.2924 sec; Batch: 2.1045 sec
0.1299 0.1013 0.0725 0.0632 0.0594 0.0558 0.0529 0.0496 0.0485 0.0474 0.0467 0.0460 0.0456 0.0451 0.0448 0.0447 

[TRAIN] Epoch[1](1567/114412); Loss: 0.057554; Backpropagation: 0.2910 sec; Batch: 2.1142 sec
0.1042 0.0903 0.0691 0.0611 0.0567 0.0538 0.0518 0.0507 0.0498 0.0490 0.0482 0.0477 0.0474 0.0472 0.0470 0.0468 

[TRAIN] Epoch[1](1568/114412); Loss: 0.060859; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1263 0.0929 0.0755 0.0670 0.0607 0.0562 0.0541 0.0524 0.0509 0.0496 0.0491 0.0486 0.0482 0.0477 0.0475 0.0471 

[TRAIN] Epoch[1](1569/114412); Loss: 0.049367; Backpropagation: 0.2911 sec; Batch: 2.1428 sec
0.1113 0.0874 0.0642 0.0549 0.0482 0.0445 0.0422 0.0403 0.0391 0.0382 0.0378 0.0371 0.0366 0.0364 0.0360 0.0357 

[TRAIN] Epoch[1](1570/114412); Loss: 0.061214; Backpropagation: 0.2908 sec; Batch: 2.1230 sec
0.1172 0.0969 0.0744 0.0647 0.0603 0.0569 0.0549 0.0532 0.0521 0.0510 0.0507 0.0501 0.0497 0.0494 0.0491 0.0490 

[TRAIN] Epoch[1](1571/114412); Loss: 0.050908; Backpropagation: 0.2915 sec; Batch: 2.0826 sec
0.0991 0.0860 0.0670 0.0578 0.0514 0.0474 0.0454 0.0435 0.0418 0.0408 0.0401 0.0397 0.0392 0.0388 0.0385 0.0381 

[TRAIN] Epoch[1](1572/114412); Loss: 0.062283; Backpropagation: 0.2905 sec; Batch: 2.0781 sec
0.1244 0.1080 0.0835 0.0721 0.0641 0.0574 0.0545 0.0523 0.0504 0.0493 0.0479 0.0474 0.0470 0.0464 0.0460 0.0458 

[TRAIN] Epoch[1](1573/114412); Loss: 0.061786; Backpropagation: 0.2907 sec; Batch: 2.0781 sec
0.0959 0.0875 0.0703 0.0647 0.0614 0.0601 0.0579 0.0568 0.0559 0.0550 0.0547 0.0543 0.0538 0.0536 0.0534 0.0532 

[TRAIN] Epoch[1](1574/114412); Loss: 0.048354; Backpropagation: 0.2901 sec; Batch: 2.1155 sec
0.1004 0.0750 0.0602 0.0523 0.0467 0.0438 0.0426 0.0415 0.0402 0.0395 0.0392 0.0389 0.0387 0.0385 0.0382 0.0380 

[TRAIN] Epoch[1](1575/114412); Loss: 0.059896; Backpropagation: 0.2908 sec; Batch: 2.1184 sec
0.1150 0.1012 0.0778 0.0664 0.0600 0.0562 0.0532 0.0511 0.0498 0.0486 0.0478 0.0471 0.0465 0.0461 0.0459 0.0455 

[TRAIN] Epoch[1](1576/114412); Loss: 0.071080; Backpropagation: 0.2915 sec; Batch: 2.1146 sec
0.1074 0.0970 0.0857 0.0778 0.0735 0.0695 0.0669 0.0656 0.0643 0.0632 0.0622 0.0617 0.0612 0.0607 0.0604 0.0601 

[TRAIN] Epoch[1](1577/114412); Loss: 0.066540; Backpropagation: 0.2928 sec; Batch: 2.1180 sec
0.1113 0.0994 0.0847 0.0738 0.0676 0.0642 0.0618 0.0601 0.0584 0.0572 0.0562 0.0553 0.0543 0.0538 0.0535 0.0530 

[TRAIN] Epoch[1](1578/114412); Loss: 0.073979; Backpropagation: 0.2905 sec; Batch: 2.1157 sec
0.1262 0.1108 0.0933 0.0813 0.0740 0.0708 0.0682 0.0659 0.0642 0.0632 0.0624 0.0618 0.0612 0.0606 0.0601 0.0597 

[TRAIN] Epoch[1](1579/114412); Loss: 0.069277; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1056 0.0978 0.0817 0.0733 0.0704 0.0682 0.0656 0.0639 0.0625 0.0617 0.0608 0.0602 0.0597 0.0592 0.0589 0.0588 

[TRAIN] Epoch[1](1580/114412); Loss: 0.071751; Backpropagation: 0.2908 sec; Batch: 2.1309 sec
0.1222 0.1065 0.0929 0.0833 0.0773 0.0718 0.0685 0.0653 0.0620 0.0608 0.0590 0.0573 0.0564 0.0556 0.0550 0.0543 

[TRAIN] Epoch[1](1581/114412); Loss: 0.081628; Backpropagation: 0.2909 sec; Batch: 2.1126 sec
0.1313 0.1197 0.1039 0.0926 0.0888 0.0836 0.0791 0.0751 0.0716 0.0696 0.0676 0.0663 0.0651 0.0645 0.0638 0.0635 

[TRAIN] Epoch[1](1582/114412); Loss: 0.071718; Backpropagation: 0.2908 sec; Batch: 2.1282 sec
0.1060 0.0950 0.0839 0.0775 0.0740 0.0709 0.0683 0.0667 0.0655 0.0643 0.0636 0.0630 0.0626 0.0623 0.0621 0.0618 

[TRAIN] Epoch[1](1583/114412); Loss: 0.065100; Backpropagation: 0.2914 sec; Batch: 2.1422 sec
0.1093 0.0986 0.0811 0.0711 0.0662 0.0641 0.0609 0.0591 0.0573 0.0558 0.0547 0.0537 0.0530 0.0525 0.0522 0.0520 

[TRAIN] Epoch[1](1584/114412); Loss: 0.093147; Backpropagation: 0.2932 sec; Batch: 2.1260 sec
0.1473 0.1335 0.1140 0.1022 0.0958 0.0912 0.0873 0.0842 0.0819 0.0805 0.0797 0.0790 0.0787 0.0785 0.0782 0.0782 

[TRAIN] Epoch[1](1585/114412); Loss: 0.083604; Backpropagation: 0.2911 sec; Batch: 2.2670 sec
0.1396 0.1169 0.1005 0.0912 0.0859 0.0815 0.0788 0.0762 0.0748 0.0731 0.0723 0.0710 0.0700 0.0690 0.0687 0.0682 

[TRAIN] Epoch[1](1586/114412); Loss: 0.086875; Backpropagation: 0.2904 sec; Batch: 2.1159 sec
0.1535 0.1233 0.1035 0.0940 0.0872 0.0834 0.0811 0.0782 0.0759 0.0753 0.0740 0.0731 0.0725 0.0719 0.0716 0.0715 

[TRAIN] Epoch[1](1587/114412); Loss: 0.107605; Backpropagation: 0.2931 sec; Batch: 2.1169 sec
0.2025 0.1717 0.1449 0.1175 0.1080 0.1031 0.0985 0.0960 0.0925 0.0891 0.0864 0.0847 0.0832 0.0820 0.0812 0.0802 

[TRAIN] Epoch[1](1588/114412); Loss: 0.074451; Backpropagation: 0.2931 sec; Batch: 2.1206 sec
0.1301 0.1136 0.0950 0.0846 0.0812 0.0765 0.0706 0.0676 0.0643 0.0616 0.0600 0.0588 0.0578 0.0572 0.0566 0.0559 

[TRAIN] Epoch[1](1589/114412); Loss: 0.078798; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1127 0.1064 0.0937 0.0881 0.0870 0.0836 0.0791 0.0755 0.0723 0.0696 0.0674 0.0662 0.0654 0.0649 0.0647 0.0642 

[TRAIN] Epoch[1](1590/114412); Loss: 0.116114; Backpropagation: 0.2930 sec; Batch: 2.1229 sec
0.1781 0.1596 0.1398 0.1272 0.1211 0.1155 0.1114 0.1078 0.1054 0.1032 0.1012 0.0997 0.0983 0.0972 0.0964 0.0959 

[TRAIN] Epoch[1](1591/114412); Loss: 0.089374; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1432 0.1289 0.1132 0.1018 0.0946 0.0892 0.0853 0.0822 0.0789 0.0760 0.0746 0.0737 0.0731 0.0723 0.0719 0.0713 

[TRAIN] Epoch[1](1592/114412); Loss: 0.065447; Backpropagation: 0.2930 sec; Batch: 2.1212 sec
0.1147 0.0983 0.0848 0.0749 0.0710 0.0671 0.0630 0.0596 0.0561 0.0538 0.0524 0.0514 0.0508 0.0501 0.0497 0.0494 

[TRAIN] Epoch[1](1593/114412); Loss: 0.058006; Backpropagation: 0.2909 sec; Batch: 2.0777 sec
0.0990 0.0924 0.0734 0.0635 0.0586 0.0559 0.0531 0.0511 0.0499 0.0483 0.0475 0.0475 0.0470 0.0470 0.0469 0.0470 

[TRAIN] Epoch[1](1594/114412); Loss: 0.071714; Backpropagation: 0.2914 sec; Batch: 2.1144 sec
0.1190 0.1087 0.0891 0.0771 0.0717 0.0684 0.0674 0.0656 0.0633 0.0619 0.0607 0.0598 0.0590 0.0588 0.0584 0.0585 

[TRAIN] Epoch[1](1595/114412); Loss: 0.087090; Backpropagation: 0.2928 sec; Batch: 2.1154 sec
0.1582 0.1403 0.1195 0.1030 0.0916 0.0844 0.0805 0.0747 0.0725 0.0706 0.0689 0.0674 0.0663 0.0655 0.0650 0.0649 

[TRAIN] Epoch[1](1596/114412); Loss: 0.073740; Backpropagation: 0.2911 sec; Batch: 2.1155 sec
0.1197 0.0974 0.0848 0.0814 0.0774 0.0757 0.0712 0.0690 0.0659 0.0646 0.0635 0.0630 0.0618 0.0615 0.0617 0.0613 

[TRAIN] Epoch[1](1597/114412); Loss: 0.093117; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1465 0.1360 0.1126 0.0998 0.0940 0.0916 0.0879 0.0856 0.0834 0.0823 0.0806 0.0792 0.0785 0.0776 0.0773 0.0770 

[TRAIN] Epoch[1](1598/114412); Loss: 0.067529; Backpropagation: 0.2927 sec; Batch: 2.1197 sec
0.1111 0.1056 0.0797 0.0728 0.0699 0.0671 0.0637 0.0610 0.0592 0.0578 0.0565 0.0558 0.0553 0.0554 0.0550 0.0548 

[TRAIN] Epoch[1](1599/114412); Loss: 0.086314; Backpropagation: 0.2910 sec; Batch: 2.1151 sec
0.1350 0.1163 0.1019 0.0923 0.0885 0.0858 0.0836 0.0805 0.0797 0.0775 0.0759 0.0742 0.0734 0.0724 0.0720 0.0721 

[TRAIN] Epoch[1](1600/114412); Loss: 0.073487; Backpropagation: 0.2910 sec; Batch: 2.1189 sec
0.1209 0.1123 0.0975 0.0830 0.0783 0.0745 0.0710 0.0669 0.0646 0.0622 0.0603 0.0584 0.0572 0.0566 0.0563 0.0559 

[TRAIN] Epoch[1](1601/114412); Loss: 0.087876; Backpropagation: 0.2903 sec; Batch: 2.1157 sec
0.1759 0.1609 0.1274 0.0985 0.0889 0.0789 0.0757 0.0721 0.0699 0.0690 0.0679 0.0663 0.0644 0.0643 0.0631 0.0629 

[TRAIN] Epoch[1](1602/114412); Loss: 0.083962; Backpropagation: 0.2953 sec; Batch: 2.1207 sec
0.1699 0.1409 0.1115 0.1021 0.0893 0.0816 0.0741 0.0719 0.0703 0.0687 0.0651 0.0634 0.0603 0.0592 0.0576 0.0574 

[TRAIN] Epoch[1](1603/114412); Loss: 0.109333; Backpropagation: 0.2922 sec; Batch: 2.1205 sec
0.2179 0.1869 0.1456 0.1191 0.1028 0.0971 0.0960 0.0942 0.0911 0.0897 0.0883 0.0858 0.0850 0.0837 0.0835 0.0826 

[TRAIN] Epoch[1](1604/114412); Loss: 0.095783; Backpropagation: 0.2928 sec; Batch: 2.1188 sec
0.1472 0.1279 0.1133 0.1042 0.1005 0.0970 0.0933 0.0897 0.0872 0.0854 0.0834 0.0821 0.0814 0.0806 0.0800 0.0795 

[TRAIN] Epoch[1](1605/114412); Loss: 0.105750; Backpropagation: 0.2930 sec; Batch: 2.1166 sec
0.1792 0.1557 0.1288 0.1142 0.1067 0.1014 0.0984 0.0950 0.0931 0.0916 0.0902 0.0890 0.0885 0.0873 0.0868 0.0860 

[TRAIN] Epoch[1](1606/114412); Loss: 0.073999; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1187 0.1103 0.0902 0.0815 0.0758 0.0723 0.0699 0.0676 0.0657 0.0640 0.0628 0.0620 0.0615 0.0610 0.0605 0.0601 

[TRAIN] Epoch[1](1607/114412); Loss: 0.069112; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1246 0.0968 0.0863 0.0776 0.0755 0.0732 0.0683 0.0639 0.0600 0.0582 0.0556 0.0545 0.0537 0.0530 0.0525 0.0522 

[TRAIN] Epoch[1](1608/114412); Loss: 0.072232; Backpropagation: 0.2911 sec; Batch: 2.0869 sec
0.1499 0.1261 0.1090 0.0892 0.0761 0.0664 0.0610 0.0601 0.0568 0.0550 0.0534 0.0520 0.0512 0.0503 0.0499 0.0493 

[TRAIN] Epoch[1](1609/114412); Loss: 0.082765; Backpropagation: 0.2912 sec; Batch: 2.1324 sec
0.1490 0.1358 0.1074 0.0934 0.0878 0.0803 0.0768 0.0727 0.0699 0.0673 0.0665 0.0648 0.0641 0.0632 0.0630 0.0623 

[TRAIN] Epoch[1](1610/114412); Loss: 0.098763; Backpropagation: 0.2911 sec; Batch: 2.1221 sec
0.1766 0.1573 0.1302 0.1135 0.1038 0.0977 0.0924 0.0880 0.0847 0.0817 0.0793 0.0776 0.0760 0.0748 0.0737 0.0728 

[TRAIN] Epoch[1](1611/114412); Loss: 0.089919; Backpropagation: 0.2910 sec; Batch: 2.0789 sec
0.1692 0.1489 0.1188 0.1020 0.0918 0.0864 0.0828 0.0789 0.0763 0.0737 0.0716 0.0698 0.0683 0.0674 0.0668 0.0659 

[TRAIN] Epoch[1](1612/114412); Loss: 0.065835; Backpropagation: 0.2912 sec; Batch: 2.1155 sec
0.1224 0.1127 0.0802 0.0744 0.0667 0.0614 0.0592 0.0566 0.0553 0.0540 0.0530 0.0523 0.0518 0.0514 0.0511 0.0509 

[TRAIN] Epoch[1](1613/114412); Loss: 0.081920; Backpropagation: 0.2911 sec; Batch: 2.1222 sec
0.1736 0.1467 0.1111 0.0916 0.0831 0.0764 0.0723 0.0686 0.0659 0.0638 0.0616 0.0604 0.0597 0.0593 0.0587 0.0581 

[TRAIN] Epoch[1](1614/114412); Loss: 0.089702; Backpropagation: 0.2895 sec; Batch: 2.0770 sec
0.1484 0.1372 0.1234 0.1089 0.0979 0.0882 0.0838 0.0791 0.0758 0.0736 0.0722 0.0711 0.0700 0.0691 0.0685 0.0679 

[TRAIN] Epoch[1](1615/114412); Loss: 0.098562; Backpropagation: 0.2932 sec; Batch: 2.1172 sec
0.1676 0.1449 0.1243 0.1103 0.0995 0.0912 0.0896 0.0879 0.0857 0.0846 0.0836 0.0826 0.0821 0.0814 0.0810 0.0806 

[TRAIN] Epoch[1](1616/114412); Loss: 0.102560; Backpropagation: 0.2908 sec; Batch: 2.1162 sec
0.1718 0.1638 0.1179 0.1109 0.1032 0.0998 0.0930 0.0917 0.0903 0.0890 0.0867 0.0859 0.0850 0.0843 0.0839 0.0836 

[TRAIN] Epoch[1](1617/114412); Loss: 0.090753; Backpropagation: 0.2910 sec; Batch: 2.1145 sec
0.1941 0.1510 0.1079 0.0941 0.0856 0.0830 0.0822 0.0784 0.0756 0.0734 0.0729 0.0719 0.0712 0.0708 0.0700 0.0699 

[TRAIN] Epoch[1](1618/114412); Loss: 0.115445; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.2042 0.1830 0.1379 0.1199 0.1100 0.1074 0.1048 0.1025 0.1014 0.0994 0.0980 0.0970 0.0961 0.0956 0.0952 0.0948 

[TRAIN] Epoch[1](1619/114412); Loss: 0.075239; Backpropagation: 0.2930 sec; Batch: 2.1165 sec
0.1258 0.1190 0.0929 0.0835 0.0777 0.0722 0.0698 0.0672 0.0653 0.0639 0.0628 0.0618 0.0612 0.0607 0.0603 0.0598 

[TRAIN] Epoch[1](1620/114412); Loss: 0.085788; Backpropagation: 0.2909 sec; Batch: 2.0945 sec
0.1899 0.1588 0.1196 0.1037 0.0920 0.0831 0.0733 0.0693 0.0663 0.0636 0.0613 0.0600 0.0591 0.0582 0.0574 0.0570 

[TRAIN] Epoch[1](1621/114412); Loss: 0.088044; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1698 0.1454 0.1258 0.1029 0.0980 0.0859 0.0823 0.0732 0.0710 0.0678 0.0667 0.0653 0.0646 0.0638 0.0634 0.0629 

[TRAIN] Epoch[1](1622/114412); Loss: 0.067960; Backpropagation: 0.2932 sec; Batch: 2.1196 sec
0.1468 0.1221 0.0913 0.0727 0.0702 0.0660 0.0622 0.0579 0.0553 0.0523 0.0509 0.0495 0.0485 0.0479 0.0472 0.0466 

[TRAIN] Epoch[1](1623/114412); Loss: 0.077389; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1585 0.1160 0.0913 0.0838 0.0788 0.0737 0.0711 0.0689 0.0664 0.0643 0.0626 0.0616 0.0610 0.0604 0.0600 0.0596 

[TRAIN] Epoch[1](1624/114412); Loss: 0.114919; Backpropagation: 0.2910 sec; Batch: 2.1138 sec
0.1893 0.1797 0.1570 0.1400 0.1298 0.1218 0.1153 0.1082 0.1023 0.0962 0.0909 0.0867 0.0837 0.0806 0.0791 0.0781 

[TRAIN] Epoch[1](1625/114412); Loss: 0.091493; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.1411 0.1382 0.1142 0.1030 0.0943 0.0884 0.0856 0.0827 0.0809 0.0792 0.0781 0.0768 0.0762 0.0755 0.0751 0.0745 

[TRAIN] Epoch[1](1626/114412); Loss: 0.082157; Backpropagation: 0.2909 sec; Batch: 2.1199 sec
0.1585 0.1474 0.1096 0.0974 0.0841 0.0768 0.0726 0.0694 0.0671 0.0650 0.0634 0.0621 0.0612 0.0605 0.0599 0.0594 

[TRAIN] Epoch[1](1627/114412); Loss: 0.079974; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1304 0.1225 0.0949 0.0886 0.0828 0.0785 0.0753 0.0725 0.0706 0.0690 0.0679 0.0667 0.0658 0.0652 0.0646 0.0642 

[TRAIN] Epoch[1](1628/114412); Loss: 0.087527; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1749 0.1646 0.1172 0.1052 0.0905 0.0829 0.0767 0.0736 0.0707 0.0677 0.0655 0.0642 0.0628 0.0619 0.0613 0.0607 

[TRAIN] Epoch[1](1629/114412); Loss: 0.089403; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.1733 0.1543 0.1267 0.1131 0.0973 0.0865 0.0816 0.0760 0.0707 0.0682 0.0666 0.0649 0.0637 0.0631 0.0624 0.0620 

[TRAIN] Epoch[1](1630/114412); Loss: 0.058404; Backpropagation: 0.2908 sec; Batch: 2.1145 sec
0.0978 0.0882 0.0702 0.0651 0.0615 0.0578 0.0549 0.0530 0.0513 0.0498 0.0488 0.0482 0.0476 0.0471 0.0467 0.0464 

[TRAIN] Epoch[1](1631/114412); Loss: 0.063079; Backpropagation: 0.2913 sec; Batch: 2.1128 sec
0.1293 0.1038 0.0780 0.0715 0.0641 0.0600 0.0562 0.0541 0.0520 0.0508 0.0496 0.0488 0.0483 0.0478 0.0476 0.0473 

[TRAIN] Epoch[1](1632/114412); Loss: 0.082278; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.1465 0.1370 0.1101 0.0990 0.0890 0.0805 0.0735 0.0702 0.0681 0.0665 0.0648 0.0641 0.0627 0.0625 0.0613 0.0607 

[TRAIN] Epoch[1](1633/114412); Loss: 0.082132; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1939 0.1672 0.1262 0.0968 0.0863 0.0747 0.0683 0.0608 0.0588 0.0571 0.0558 0.0547 0.0541 0.0536 0.0531 0.0528 

[TRAIN] Epoch[1](1634/114412); Loss: 0.091502; Backpropagation: 0.2904 sec; Batch: 2.1183 sec
0.1629 0.1445 0.1160 0.0999 0.0929 0.0886 0.0838 0.0809 0.0787 0.0771 0.0753 0.0741 0.0734 0.0726 0.0720 0.0714 

[TRAIN] Epoch[1](1635/114412); Loss: 0.079013; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.1637 0.1375 0.1024 0.0871 0.0777 0.0723 0.0689 0.0665 0.0643 0.0629 0.0618 0.0609 0.0603 0.0597 0.0592 0.0589 

[TRAIN] Epoch[1](1636/114412); Loss: 0.078004; Backpropagation: 0.2930 sec; Batch: 2.1229 sec
0.1702 0.1480 0.1037 0.0914 0.0777 0.0717 0.0675 0.0638 0.0607 0.0591 0.0579 0.0566 0.0558 0.0550 0.0546 0.0543 

[TRAIN] Epoch[1](1637/114412); Loss: 0.054523; Backpropagation: 0.2930 sec; Batch: 2.1202 sec
0.1174 0.0992 0.0863 0.0667 0.0570 0.0503 0.0462 0.0440 0.0417 0.0400 0.0386 0.0379 0.0372 0.0370 0.0367 0.0362 

[TRAIN] Epoch[1](1638/114412); Loss: 0.062157; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1091 0.1076 0.0775 0.0699 0.0634 0.0589 0.0560 0.0540 0.0529 0.0513 0.0503 0.0497 0.0492 0.0487 0.0482 0.0479 

[TRAIN] Epoch[1](1639/114412); Loss: 0.083260; Backpropagation: 0.2906 sec; Batch: 2.1189 sec
0.1562 0.1284 0.1038 0.0894 0.0809 0.0779 0.0751 0.0734 0.0718 0.0704 0.0689 0.0683 0.0676 0.0671 0.0666 0.0663 

[TRAIN] Epoch[1](1640/114412); Loss: 0.083518; Backpropagation: 0.2907 sec; Batch: 2.0781 sec
0.1373 0.1247 0.1039 0.0941 0.0865 0.0816 0.0775 0.0744 0.0727 0.0713 0.0703 0.0695 0.0687 0.0683 0.0679 0.0677 

[TRAIN] Epoch[1](1641/114412); Loss: 0.080317; Backpropagation: 0.2909 sec; Batch: 2.1195 sec
0.1396 0.1343 0.1054 0.0963 0.0870 0.0801 0.0749 0.0711 0.0679 0.0653 0.0634 0.0615 0.0603 0.0598 0.0593 0.0589 

[TRAIN] Epoch[1](1642/114412); Loss: 0.087232; Backpropagation: 0.2930 sec; Batch: 2.1249 sec
0.1618 0.1397 0.1126 0.0949 0.0847 0.0806 0.0778 0.0761 0.0743 0.0733 0.0718 0.0711 0.0702 0.0694 0.0690 0.0685 

[TRAIN] Epoch[1](1643/114412); Loss: 0.082226; Backpropagation: 0.2932 sec; Batch: 2.1164 sec
0.1570 0.1353 0.0986 0.0913 0.0814 0.0758 0.0738 0.0712 0.0693 0.0679 0.0671 0.0662 0.0657 0.0654 0.0649 0.0647 

[TRAIN] Epoch[1](1644/114412); Loss: 0.084523; Backpropagation: 0.2913 sec; Batch: 2.1150 sec
0.1341 0.1244 0.0981 0.0894 0.0836 0.0805 0.0787 0.0771 0.0757 0.0745 0.0739 0.0732 0.0728 0.0723 0.0720 0.0720 

[TRAIN] Epoch[1](1645/114412); Loss: 0.058042; Backpropagation: 0.2909 sec; Batch: 2.0776 sec
0.1018 0.0879 0.0702 0.0644 0.0596 0.0556 0.0538 0.0518 0.0502 0.0491 0.0484 0.0479 0.0473 0.0470 0.0469 0.0468 

[TRAIN] Epoch[1](1646/114412); Loss: 0.061684; Backpropagation: 0.2912 sec; Batch: 2.1210 sec
0.1317 0.1148 0.0803 0.0735 0.0629 0.0592 0.0516 0.0493 0.0483 0.0468 0.0459 0.0454 0.0448 0.0444 0.0441 0.0438 

[TRAIN] Epoch[1](1647/114412); Loss: 0.084322; Backpropagation: 0.2916 sec; Batch: 2.1009 sec
0.1772 0.1421 0.1075 0.0967 0.0837 0.0780 0.0751 0.0721 0.0693 0.0678 0.0659 0.0646 0.0633 0.0626 0.0620 0.0613 

[TRAIN] Epoch[1](1648/114412); Loss: 0.062314; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1188 0.1126 0.0845 0.0730 0.0619 0.0580 0.0545 0.0521 0.0505 0.0492 0.0483 0.0476 0.0470 0.0467 0.0463 0.0460 

[TRAIN] Epoch[1](1649/114412); Loss: 0.080259; Backpropagation: 0.2914 sec; Batch: 2.1243 sec
0.1585 0.1394 0.1081 0.0902 0.0809 0.0756 0.0722 0.0704 0.0672 0.0649 0.0626 0.0606 0.0596 0.0585 0.0581 0.0576 

[TRAIN] Epoch[1](1650/114412); Loss: 0.064298; Backpropagation: 0.2910 sec; Batch: 2.1070 sec
0.1330 0.1150 0.0836 0.0738 0.0670 0.0595 0.0567 0.0539 0.0515 0.0503 0.0490 0.0482 0.0475 0.0468 0.0467 0.0465 

[TRAIN] Epoch[1](1651/114412); Loss: 0.098960; Backpropagation: 0.2916 sec; Batch: 2.1426 sec
0.2040 0.1638 0.1221 0.1005 0.0950 0.0899 0.0886 0.0865 0.0846 0.0808 0.0792 0.0798 0.0783 0.0775 0.0768 0.0759 

[TRAIN] Epoch[1](1652/114412); Loss: 0.081114; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1512 0.1336 0.1017 0.0927 0.0833 0.0759 0.0729 0.0709 0.0684 0.0668 0.0659 0.0645 0.0636 0.0628 0.0622 0.0617 

[TRAIN] Epoch[1](1653/114412); Loss: 0.072351; Backpropagation: 0.2906 sec; Batch: 2.1163 sec
0.1692 0.1541 0.1118 0.0969 0.0750 0.0666 0.0588 0.0545 0.0513 0.0489 0.0473 0.0462 0.0453 0.0445 0.0439 0.0433 

[TRAIN] Epoch[1](1654/114412); Loss: 0.088162; Backpropagation: 0.2929 sec; Batch: 2.1207 sec
0.1575 0.1465 0.1150 0.1009 0.0925 0.0875 0.0825 0.0780 0.0754 0.0733 0.0701 0.0685 0.0674 0.0659 0.0651 0.0644 

[TRAIN] Epoch[1](1655/114412); Loss: 0.060726; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1058 0.0977 0.0837 0.0695 0.0611 0.0581 0.0557 0.0529 0.0509 0.0495 0.0487 0.0484 0.0479 0.0474 0.0473 0.0470 

[TRAIN] Epoch[1](1656/114412); Loss: 0.076358; Backpropagation: 0.2926 sec; Batch: 2.1180 sec
0.1373 0.1194 0.0974 0.0885 0.0770 0.0732 0.0689 0.0664 0.0641 0.0631 0.0624 0.0618 0.0612 0.0607 0.0603 0.0600 

[TRAIN] Epoch[1](1657/114412); Loss: 0.073102; Backpropagation: 0.2907 sec; Batch: 2.1211 sec
0.1385 0.1170 0.0998 0.0892 0.0809 0.0730 0.0658 0.0625 0.0597 0.0576 0.0562 0.0552 0.0544 0.0537 0.0532 0.0529 

[TRAIN] Epoch[1](1658/114412); Loss: 0.081322; Backpropagation: 0.2905 sec; Batch: 2.1168 sec
0.1587 0.1367 0.1097 0.0926 0.0825 0.0760 0.0716 0.0683 0.0666 0.0649 0.0641 0.0631 0.0623 0.0617 0.0613 0.0610 

[TRAIN] Epoch[1](1659/114412); Loss: 0.089565; Backpropagation: 0.2910 sec; Batch: 2.0780 sec
0.1415 0.1408 0.1157 0.1005 0.0920 0.0868 0.0825 0.0804 0.0788 0.0768 0.0753 0.0740 0.0729 0.0722 0.0717 0.0713 

[TRAIN] Epoch[1](1660/114412); Loss: 0.056658; Backpropagation: 0.2911 sec; Batch: 2.1612 sec
0.1343 0.1204 0.0745 0.0632 0.0522 0.0507 0.0464 0.0449 0.0431 0.0415 0.0407 0.0400 0.0392 0.0389 0.0384 0.0381 

[TRAIN] Epoch[1](1661/114412); Loss: 0.058403; Backpropagation: 0.2952 sec; Batch: 2.1214 sec
0.1194 0.1122 0.0692 0.0616 0.0574 0.0531 0.0513 0.0500 0.0481 0.0470 0.0457 0.0449 0.0443 0.0437 0.0434 0.0431 

[TRAIN] Epoch[1](1662/114412); Loss: 0.071869; Backpropagation: 0.2925 sec; Batch: 2.1186 sec
0.1616 0.1206 0.0866 0.0771 0.0714 0.0666 0.0639 0.0616 0.0580 0.0567 0.0559 0.0550 0.0544 0.0538 0.0534 0.0533 

[TRAIN] Epoch[1](1663/114412); Loss: 0.077659; Backpropagation: 0.2929 sec; Batch: 2.1235 sec
0.1433 0.1306 0.1037 0.0902 0.0835 0.0760 0.0722 0.0682 0.0648 0.0624 0.0604 0.0593 0.0580 0.0573 0.0566 0.0560 

[TRAIN] Epoch[1](1664/114412); Loss: 0.074661; Backpropagation: 0.2929 sec; Batch: 2.1216 sec
0.1346 0.1254 0.0981 0.0877 0.0777 0.0720 0.0675 0.0644 0.0622 0.0607 0.0592 0.0583 0.0575 0.0568 0.0565 0.0559 

[TRAIN] Epoch[1](1665/114412); Loss: 0.088690; Backpropagation: 0.2909 sec; Batch: 2.0956 sec
0.1244 0.1148 0.1014 0.0977 0.0927 0.0904 0.0867 0.0842 0.0823 0.0804 0.0793 0.0782 0.0775 0.0769 0.0763 0.0760 

[TRAIN] Epoch[1](1666/114412); Loss: 0.085620; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1752 0.1501 0.1118 0.0970 0.0855 0.0803 0.0763 0.0726 0.0697 0.0677 0.0663 0.0651 0.0639 0.0633 0.0629 0.0623 

[TRAIN] Epoch[1](1667/114412); Loss: 0.074131; Backpropagation: 0.2912 sec; Batch: 2.1191 sec
0.1426 0.1345 0.0976 0.0842 0.0758 0.0710 0.0669 0.0628 0.0604 0.0583 0.0570 0.0560 0.0554 0.0549 0.0544 0.0541 

[TRAIN] Epoch[1](1668/114412); Loss: 0.072831; Backpropagation: 0.2910 sec; Batch: 2.1155 sec
0.1283 0.1161 0.0924 0.0818 0.0750 0.0700 0.0669 0.0642 0.0625 0.0609 0.0598 0.0587 0.0580 0.0575 0.0569 0.0565 

[TRAIN] Epoch[1](1669/114412); Loss: 0.061770; Backpropagation: 0.2908 sec; Batch: 2.0768 sec
0.1109 0.1044 0.0820 0.0694 0.0619 0.0586 0.0563 0.0548 0.0523 0.0506 0.0495 0.0486 0.0480 0.0474 0.0470 0.0467 

[TRAIN] Epoch[1](1670/114412); Loss: 0.082582; Backpropagation: 0.2909 sec; Batch: 2.1139 sec
0.1426 0.1256 0.0993 0.0890 0.0826 0.0788 0.0760 0.0742 0.0723 0.0711 0.0699 0.0691 0.0684 0.0679 0.0675 0.0671 

[TRAIN] Epoch[1](1671/114412); Loss: 0.064192; Backpropagation: 0.2927 sec; Batch: 2.1189 sec
0.1204 0.1192 0.0791 0.0726 0.0636 0.0600 0.0563 0.0545 0.0531 0.0519 0.0506 0.0500 0.0495 0.0490 0.0487 0.0485 

[TRAIN] Epoch[1](1672/114412); Loss: 0.090629; Backpropagation: 0.2919 sec; Batch: 2.1211 sec
0.1400 0.1331 0.1089 0.1009 0.0935 0.0888 0.0852 0.0830 0.0810 0.0795 0.0776 0.0769 0.0761 0.0758 0.0752 0.0747 

[TRAIN] Epoch[1](1673/114412); Loss: 0.064231; Backpropagation: 0.2918 sec; Batch: 2.1215 sec
0.1345 0.1139 0.0835 0.0707 0.0615 0.0575 0.0566 0.0542 0.0529 0.0508 0.0498 0.0490 0.0487 0.0482 0.0481 0.0479 

[TRAIN] Epoch[1](1674/114412); Loss: 0.081087; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1426 0.1263 0.1024 0.0906 0.0826 0.0778 0.0743 0.0713 0.0692 0.0679 0.0670 0.0660 0.0655 0.0650 0.0646 0.0644 

[TRAIN] Epoch[1](1675/114412); Loss: 0.082432; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1613 0.1306 0.1046 0.0924 0.0849 0.0804 0.0756 0.0715 0.0688 0.0669 0.0656 0.0646 0.0639 0.0632 0.0625 0.0621 

[TRAIN] Epoch[1](1676/114412); Loss: 0.082546; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1475 0.1185 0.0954 0.0867 0.0821 0.0801 0.0765 0.0740 0.0725 0.0715 0.0705 0.0701 0.0696 0.0692 0.0685 0.0681 

[TRAIN] Epoch[1](1677/114412); Loss: 0.083940; Backpropagation: 0.2907 sec; Batch: 2.1162 sec
0.1327 0.1238 0.1042 0.0953 0.0873 0.0822 0.0789 0.0768 0.0737 0.0720 0.0711 0.0701 0.0694 0.0689 0.0685 0.0681 

[TRAIN] Epoch[1](1678/114412); Loss: 0.085302; Backpropagation: 0.2930 sec; Batch: 2.1175 sec
0.2286 0.1927 0.1405 0.1053 0.0749 0.0664 0.0640 0.0613 0.0596 0.0561 0.0546 0.0537 0.0526 0.0519 0.0515 0.0510 

[TRAIN] Epoch[1](1679/114412); Loss: 0.066499; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.1750 0.1392 0.1062 0.0680 0.0625 0.0523 0.0514 0.0496 0.0471 0.0462 0.0455 0.0448 0.0446 0.0440 0.0439 0.0437 

[TRAIN] Epoch[1](1680/114412); Loss: 0.054432; Backpropagation: 0.2906 sec; Batch: 2.1164 sec
0.1094 0.0920 0.0716 0.0627 0.0557 0.0527 0.0492 0.0468 0.0449 0.0431 0.0420 0.0411 0.0406 0.0401 0.0396 0.0394 

[TRAIN] Epoch[1](1681/114412); Loss: 0.089726; Backpropagation: 0.2912 sec; Batch: 2.1189 sec
0.1574 0.1474 0.1231 0.1059 0.0957 0.0867 0.0822 0.0791 0.0762 0.0729 0.0710 0.0696 0.0685 0.0675 0.0666 0.0659 

[TRAIN] Epoch[1](1682/114412); Loss: 0.078090; Backpropagation: 0.2914 sec; Batch: 2.1169 sec
0.1523 0.1324 0.0948 0.0830 0.0757 0.0733 0.0697 0.0673 0.0659 0.0645 0.0635 0.0625 0.0619 0.0612 0.0610 0.0605 

[TRAIN] Epoch[1](1683/114412); Loss: 0.062596; Backpropagation: 0.2907 sec; Batch: 2.1175 sec
0.1039 0.1001 0.0823 0.0720 0.0636 0.0608 0.0581 0.0557 0.0538 0.0524 0.0514 0.0503 0.0498 0.0495 0.0491 0.0488 

[TRAIN] Epoch[1](1684/114412); Loss: 0.062078; Backpropagation: 0.2924 sec; Batch: 2.1212 sec
0.1071 0.1031 0.0762 0.0700 0.0615 0.0594 0.0555 0.0543 0.0530 0.0522 0.0512 0.0506 0.0502 0.0500 0.0497 0.0494 

[TRAIN] Epoch[1](1685/114412); Loss: 0.079845; Backpropagation: 0.2930 sec; Batch: 2.1212 sec
0.1712 0.1432 0.1087 0.0901 0.0795 0.0728 0.0708 0.0679 0.0647 0.0627 0.0609 0.0589 0.0579 0.0569 0.0560 0.0554 

[TRAIN] Epoch[1](1686/114412); Loss: 0.058971; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1320 0.0963 0.0723 0.0597 0.0539 0.0542 0.0525 0.0503 0.0484 0.0472 0.0469 0.0464 0.0462 0.0460 0.0457 0.0456 

[TRAIN] Epoch[1](1687/114412); Loss: 0.063436; Backpropagation: 0.2929 sec; Batch: 2.1183 sec
0.1527 0.1426 0.0954 0.0794 0.0654 0.0607 0.0531 0.0492 0.0467 0.0434 0.0405 0.0394 0.0379 0.0368 0.0360 0.0356 

[TRAIN] Epoch[1](1688/114412); Loss: 0.097893; Backpropagation: 0.2914 sec; Batch: 2.0794 sec
0.1482 0.1373 0.1136 0.1047 0.0990 0.0951 0.0920 0.0902 0.0884 0.0872 0.0864 0.0858 0.0853 0.0848 0.0843 0.0840 

[TRAIN] Epoch[1](1689/114412); Loss: 0.069840; Backpropagation: 0.2914 sec; Batch: 2.0783 sec
0.1458 0.1387 0.0916 0.0818 0.0685 0.0642 0.0605 0.0568 0.0544 0.0530 0.0517 0.0512 0.0504 0.0501 0.0496 0.0494 

[TRAIN] Epoch[1](1690/114412); Loss: 0.069741; Backpropagation: 0.2915 sec; Batch: 2.1216 sec
0.1164 0.0957 0.0833 0.0767 0.0715 0.0693 0.0654 0.0630 0.0616 0.0605 0.0597 0.0592 0.0588 0.0585 0.0582 0.0581 

[TRAIN] Epoch[1](1691/114412); Loss: 0.068378; Backpropagation: 0.2912 sec; Batch: 2.1153 sec
0.1602 0.1304 0.0944 0.0739 0.0624 0.0586 0.0554 0.0548 0.0536 0.0522 0.0513 0.0505 0.0498 0.0494 0.0488 0.0485 

[TRAIN] Epoch[1](1692/114412); Loss: 0.061496; Backpropagation: 0.2911 sec; Batch: 2.1142 sec
0.1237 0.1165 0.0822 0.0693 0.0599 0.0553 0.0530 0.0505 0.0489 0.0481 0.0472 0.0466 0.0462 0.0458 0.0455 0.0452 

[TRAIN] Epoch[1](1693/114412); Loss: 0.078055; Backpropagation: 0.2912 sec; Batch: 2.1034 sec
0.1791 0.1386 0.0968 0.0831 0.0713 0.0682 0.0667 0.0644 0.0630 0.0619 0.0610 0.0601 0.0595 0.0589 0.0584 0.0580 

[TRAIN] Epoch[1](1694/114412); Loss: 0.098138; Backpropagation: 0.2912 sec; Batch: 2.0781 sec
0.1818 0.1551 0.1210 0.1078 0.0986 0.0938 0.0898 0.0866 0.0842 0.0821 0.0807 0.0794 0.0784 0.0776 0.0770 0.0766 

[TRAIN] Epoch[1](1695/114412); Loss: 0.082593; Backpropagation: 0.2926 sec; Batch: 2.1202 sec
0.1776 0.1552 0.1200 0.1015 0.0893 0.0814 0.0741 0.0681 0.0642 0.0607 0.0585 0.0564 0.0550 0.0539 0.0531 0.0522 

[TRAIN] Epoch[1](1696/114412); Loss: 0.059415; Backpropagation: 0.2916 sec; Batch: 2.1193 sec
0.1348 0.1138 0.0745 0.0645 0.0573 0.0540 0.0506 0.0480 0.0465 0.0455 0.0446 0.0440 0.0435 0.0432 0.0430 0.0428 

[TRAIN] Epoch[1](1697/114412); Loss: 0.071107; Backpropagation: 0.2915 sec; Batch: 2.1306 sec
0.1600 0.1370 0.0951 0.0800 0.0668 0.0629 0.0597 0.0574 0.0557 0.0545 0.0531 0.0523 0.0517 0.0510 0.0505 0.0501 

[TRAIN] Epoch[1](1698/114412); Loss: 0.063530; Backpropagation: 0.2932 sec; Batch: 2.1043 sec
0.1573 0.1321 0.0939 0.0816 0.0659 0.0578 0.0511 0.0480 0.0456 0.0434 0.0422 0.0412 0.0403 0.0393 0.0387 0.0382 

[TRAIN] Epoch[1](1699/114412); Loss: 0.087930; Backpropagation: 0.2913 sec; Batch: 2.1155 sec
0.1964 0.1681 0.1383 0.1160 0.0938 0.0844 0.0742 0.0688 0.0652 0.0620 0.0600 0.0583 0.0568 0.0557 0.0547 0.0541 

[TRAIN] Epoch[1](1700/114412); Loss: 0.084615; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.2000 0.1766 0.1239 0.0995 0.0814 0.0772 0.0695 0.0653 0.0633 0.0610 0.0591 0.0575 0.0565 0.0555 0.0541 0.0534 

[TRAIN] Epoch[1](1701/114412); Loss: 0.115127; Backpropagation: 0.2925 sec; Batch: 2.1156 sec
0.2199 0.1974 0.1635 0.1412 0.1243 0.1125 0.1059 0.0982 0.0946 0.0899 0.0875 0.0849 0.0834 0.0807 0.0796 0.0784 

[TRAIN] Epoch[1](1702/114412); Loss: 0.069331; Backpropagation: 0.2920 sec; Batch: 2.1199 sec
0.1263 0.1096 0.0888 0.0795 0.0697 0.0654 0.0619 0.0600 0.0586 0.0577 0.0568 0.0562 0.0554 0.0547 0.0545 0.0542 

[TRAIN] Epoch[1](1703/114412); Loss: 0.093390; Backpropagation: 0.2928 sec; Batch: 2.1206 sec
0.1898 0.1674 0.1435 0.1184 0.0974 0.0829 0.0781 0.0747 0.0717 0.0698 0.0684 0.0674 0.0667 0.0663 0.0661 0.0657 

[TRAIN] Epoch[1](1704/114412); Loss: 0.098723; Backpropagation: 0.2930 sec; Batch: 2.1191 sec
0.1663 0.1523 0.1253 0.1164 0.1041 0.0974 0.0902 0.0866 0.0846 0.0826 0.0813 0.0800 0.0792 0.0784 0.0777 0.0772 

[TRAIN] Epoch[1](1705/114412); Loss: 0.081162; Backpropagation: 0.2907 sec; Batch: 2.1162 sec
0.1538 0.1404 0.1144 0.1028 0.0893 0.0802 0.0732 0.0695 0.0659 0.0634 0.0608 0.0590 0.0580 0.0567 0.0560 0.0554 

[TRAIN] Epoch[1](1706/114412); Loss: 0.083919; Backpropagation: 0.2909 sec; Batch: 2.1140 sec
0.1835 0.1486 0.1145 0.0899 0.0773 0.0733 0.0708 0.0689 0.0676 0.0660 0.0652 0.0644 0.0638 0.0632 0.0630 0.0627 

[TRAIN] Epoch[1](1707/114412); Loss: 0.063900; Backpropagation: 0.2904 sec; Batch: 2.1761 sec
0.1330 0.1096 0.0881 0.0766 0.0669 0.0602 0.0559 0.0530 0.0510 0.0495 0.0482 0.0473 0.0466 0.0459 0.0454 0.0451 

[TRAIN] Epoch[1](1708/114412); Loss: 0.098856; Backpropagation: 0.2927 sec; Batch: 2.0978 sec
0.2241 0.1940 0.1508 0.1249 0.1026 0.0926 0.0849 0.0785 0.0746 0.0705 0.0677 0.0658 0.0643 0.0631 0.0621 0.0612 

[TRAIN] Epoch[1](1709/114412); Loss: 0.076933; Backpropagation: 0.2929 sec; Batch: 2.1213 sec
0.1462 0.1159 0.0952 0.0842 0.0776 0.0735 0.0701 0.0672 0.0656 0.0641 0.0633 0.0627 0.0621 0.0615 0.0611 0.0607 

[TRAIN] Epoch[1](1710/114412); Loss: 0.070662; Backpropagation: 0.2926 sec; Batch: 2.1154 sec
0.1363 0.1135 0.0936 0.0810 0.0717 0.0664 0.0629 0.0609 0.0590 0.0576 0.0566 0.0554 0.0548 0.0541 0.0536 0.0532 

[TRAIN] Epoch[1](1711/114412); Loss: 0.083458; Backpropagation: 0.2930 sec; Batch: 2.1368 sec
0.1633 0.1479 0.1205 0.1042 0.0897 0.0827 0.0772 0.0700 0.0668 0.0641 0.0613 0.0597 0.0583 0.0572 0.0564 0.0559 

[TRAIN] Epoch[1](1712/114412); Loss: 0.068795; Backpropagation: 0.2933 sec; Batch: 2.0886 sec
0.1551 0.1345 0.1066 0.0892 0.0762 0.0664 0.0607 0.0571 0.0532 0.0485 0.0456 0.0445 0.0422 0.0409 0.0402 0.0399 

[TRAIN] Epoch[1](1713/114412); Loss: 0.075454; Backpropagation: 0.2951 sec; Batch: 2.0809 sec
0.1474 0.1271 0.1013 0.0840 0.0768 0.0721 0.0677 0.0645 0.0624 0.0608 0.0593 0.0581 0.0573 0.0568 0.0561 0.0556 

[TRAIN] Epoch[1](1714/114412); Loss: 0.075959; Backpropagation: 0.2926 sec; Batch: 2.1245 sec
0.2010 0.1583 0.1131 0.0882 0.0716 0.0655 0.0603 0.0568 0.0542 0.0528 0.0512 0.0499 0.0491 0.0483 0.0477 0.0473 

[TRAIN] Epoch[1](1715/114412); Loss: 0.083218; Backpropagation: 0.2910 sec; Batch: 2.1195 sec
0.1975 0.1606 0.1294 0.1031 0.0836 0.0734 0.0699 0.0625 0.0609 0.0594 0.0575 0.0565 0.0555 0.0546 0.0539 0.0532 

[TRAIN] Epoch[1](1716/114412); Loss: 0.084876; Backpropagation: 0.2916 sec; Batch: 2.0771 sec
0.1819 0.1513 0.1233 0.1077 0.0908 0.0806 0.0733 0.0676 0.0647 0.0630 0.0614 0.0602 0.0593 0.0581 0.0577 0.0573 

[TRAIN] Epoch[1](1717/114412); Loss: 0.078520; Backpropagation: 0.2930 sec; Batch: 2.1323 sec
0.2094 0.1591 0.1189 0.0924 0.0714 0.0654 0.0616 0.0586 0.0558 0.0541 0.0533 0.0523 0.0517 0.0511 0.0509 0.0504 

[TRAIN] Epoch[1](1718/114412); Loss: 0.077940; Backpropagation: 0.2913 sec; Batch: 2.0807 sec
0.1517 0.1204 0.0946 0.0832 0.0768 0.0732 0.0704 0.0680 0.0661 0.0653 0.0645 0.0635 0.0629 0.0626 0.0621 0.0618 

[TRAIN] Epoch[1](1719/114412); Loss: 0.089560; Backpropagation: 0.2913 sec; Batch: 2.1165 sec
0.1676 0.1289 0.1075 0.0963 0.0898 0.0864 0.0826 0.0801 0.0786 0.0768 0.0757 0.0742 0.0732 0.0722 0.0717 0.0713 

[TRAIN] Epoch[1](1720/114412); Loss: 0.085026; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.2006 0.1532 0.1213 0.0885 0.0772 0.0743 0.0716 0.0687 0.0670 0.0652 0.0640 0.0630 0.0621 0.0618 0.0612 0.0609 

[TRAIN] Epoch[1](1721/114412); Loss: 0.081014; Backpropagation: 0.2910 sec; Batch: 2.1192 sec
0.2053 0.1653 0.1285 0.1017 0.0773 0.0619 0.0601 0.0591 0.0577 0.0565 0.0557 0.0547 0.0536 0.0535 0.0528 0.0525 

[TRAIN] Epoch[1](1722/114412); Loss: 0.087728; Backpropagation: 0.2915 sec; Batch: 2.0780 sec
0.1961 0.1529 0.1270 0.0988 0.0841 0.0772 0.0741 0.0717 0.0693 0.0672 0.0661 0.0651 0.0643 0.0637 0.0633 0.0627 

[TRAIN] Epoch[1](1723/114412); Loss: 0.075535; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1762 0.1400 0.1060 0.0844 0.0731 0.0681 0.0642 0.0606 0.0582 0.0566 0.0556 0.0545 0.0536 0.0531 0.0525 0.0520 

[TRAIN] Epoch[1](1724/114412); Loss: 0.063580; Backpropagation: 0.2908 sec; Batch: 2.0773 sec
0.1612 0.1047 0.0780 0.0654 0.0593 0.0571 0.0544 0.0521 0.0513 0.0499 0.0492 0.0484 0.0476 0.0468 0.0462 0.0458 

[TRAIN] Epoch[1](1725/114412); Loss: 0.096762; Backpropagation: 0.2934 sec; Batch: 2.1185 sec
0.1709 0.1416 0.1215 0.1021 0.0959 0.0916 0.0882 0.0859 0.0844 0.0828 0.0818 0.0810 0.0807 0.0804 0.0799 0.0794 

[TRAIN] Epoch[1](1726/114412); Loss: 0.089407; Backpropagation: 0.2929 sec; Batch: 2.1183 sec
0.1595 0.1248 0.1107 0.0993 0.0906 0.0859 0.0836 0.0805 0.0788 0.0771 0.0756 0.0743 0.0735 0.0728 0.0720 0.0715 

[TRAIN] Epoch[1](1727/114412); Loss: 0.086818; Backpropagation: 0.2907 sec; Batch: 2.1147 sec
0.1650 0.1158 0.1003 0.0934 0.0886 0.0845 0.0804 0.0783 0.0765 0.0748 0.0736 0.0730 0.0722 0.0713 0.0709 0.0704 

[TRAIN] Epoch[1](1728/114412); Loss: 0.064741; Backpropagation: 0.2911 sec; Batch: 2.1148 sec
0.1585 0.1102 0.0818 0.0659 0.0615 0.0575 0.0557 0.0532 0.0517 0.0510 0.0495 0.0489 0.0483 0.0478 0.0474 0.0470 

[TRAIN] Epoch[1](1729/114412); Loss: 0.084545; Backpropagation: 0.2905 sec; Batch: 2.1149 sec
0.1989 0.1465 0.1127 0.0894 0.0816 0.0783 0.0724 0.0692 0.0672 0.0653 0.0640 0.0632 0.0620 0.0612 0.0606 0.0599 

[TRAIN] Epoch[1](1730/114412); Loss: 0.082886; Backpropagation: 0.2931 sec; Batch: 2.0957 sec
0.2117 0.1501 0.1136 0.0882 0.0788 0.0722 0.0678 0.0652 0.0641 0.0620 0.0609 0.0598 0.0591 0.0582 0.0575 0.0568 

[TRAIN] Epoch[1](1731/114412); Loss: 0.075318; Backpropagation: 0.2930 sec; Batch: 2.1176 sec
0.1605 0.1109 0.0970 0.0852 0.0759 0.0717 0.0685 0.0655 0.0635 0.0617 0.0599 0.0588 0.0577 0.0568 0.0561 0.0555 

[TRAIN] Epoch[1](1732/114412); Loss: 0.102393; Backpropagation: 0.2934 sec; Batch: 2.1202 sec
0.1921 0.1494 0.1333 0.1125 0.1014 0.0969 0.0941 0.0901 0.0880 0.0860 0.0846 0.0838 0.0827 0.0817 0.0813 0.0805 

[TRAIN] Epoch[1](1733/114412); Loss: 0.123981; Backpropagation: 0.2923 sec; Batch: 2.1172 sec
0.1971 0.1670 0.1547 0.1358 0.1240 0.1203 0.1155 0.1129 0.1110 0.1093 0.1083 0.1072 0.1064 0.1054 0.1047 0.1041 

[TRAIN] Epoch[1](1734/114412); Loss: 0.092072; Backpropagation: 0.2914 sec; Batch: 2.1168 sec
0.1676 0.1220 0.1115 0.1001 0.0944 0.0902 0.0860 0.0837 0.0816 0.0797 0.0783 0.0772 0.0762 0.0754 0.0749 0.0744 

[TRAIN] Epoch[1](1735/114412); Loss: 0.097362; Backpropagation: 0.2913 sec; Batch: 2.1124 sec
0.1839 0.1398 0.1270 0.1097 0.0969 0.0928 0.0886 0.0854 0.0835 0.0815 0.0799 0.0790 0.0783 0.0776 0.0772 0.0767 

[TRAIN] Epoch[1](1736/114412); Loss: 0.094684; Backpropagation: 0.2911 sec; Batch: 2.1144 sec
0.1644 0.1451 0.1234 0.1064 0.0969 0.0912 0.0875 0.0848 0.0823 0.0801 0.0784 0.0768 0.0757 0.0748 0.0739 0.0732 

[TRAIN] Epoch[1](1737/114412); Loss: 0.103935; Backpropagation: 0.2949 sec; Batch: 2.1211 sec
0.2201 0.1616 0.1738 0.1210 0.0990 0.1047 0.0884 0.0841 0.0838 0.0800 0.0779 0.0762 0.0745 0.0733 0.0725 0.0719 

[TRAIN] Epoch[1](1738/114412); Loss: 0.076177; Backpropagation: 0.2931 sec; Batch: 2.1206 sec
0.1621 0.1252 0.1095 0.0884 0.0801 0.0723 0.0667 0.0637 0.0609 0.0590 0.0575 0.0560 0.0553 0.0546 0.0540 0.0535 

[TRAIN] Epoch[1](1739/114412); Loss: 0.095290; Backpropagation: 0.2929 sec; Batch: 2.1165 sec
0.1622 0.1315 0.1183 0.1082 0.0977 0.0912 0.0881 0.0855 0.0839 0.0824 0.0813 0.0802 0.0794 0.0787 0.0783 0.0776 

[TRAIN] Epoch[1](1740/114412); Loss: 0.092493; Backpropagation: 0.2928 sec; Batch: 2.0794 sec
0.1700 0.1302 0.1250 0.1035 0.0965 0.0911 0.0867 0.0835 0.0798 0.0775 0.0755 0.0739 0.0728 0.0719 0.0713 0.0707 

[TRAIN] Epoch[1](1741/114412); Loss: 0.073263; Backpropagation: 0.2911 sec; Batch: 2.1141 sec
0.1602 0.1197 0.1037 0.0831 0.0736 0.0701 0.0657 0.0615 0.0591 0.0571 0.0556 0.0545 0.0533 0.0523 0.0518 0.0510 

[TRAIN] Epoch[1](1742/114412); Loss: 0.065945; Backpropagation: 0.2911 sec; Batch: 2.1139 sec
0.1310 0.1046 0.0829 0.0726 0.0667 0.0629 0.0600 0.0576 0.0559 0.0542 0.0531 0.0520 0.0512 0.0505 0.0501 0.0498 

[TRAIN] Epoch[1](1743/114412); Loss: 0.104085; Backpropagation: 0.2913 sec; Batch: 2.1283 sec
0.2007 0.1499 0.1362 0.1112 0.1019 0.0991 0.0943 0.0911 0.0889 0.0875 0.0860 0.0851 0.0843 0.0836 0.0829 0.0826 

[TRAIN] Epoch[1](1744/114412); Loss: 0.101191; Backpropagation: 0.2915 sec; Batch: 2.1191 sec
0.1823 0.1407 0.1280 0.1079 0.1005 0.0979 0.0940 0.0908 0.0885 0.0871 0.0855 0.0845 0.0838 0.0831 0.0825 0.0821 

[TRAIN] Epoch[1](1745/114412); Loss: 0.085462; Backpropagation: 0.2932 sec; Batch: 2.1200 sec
0.2219 0.1571 0.1325 0.0948 0.0786 0.0739 0.0692 0.0660 0.0633 0.0616 0.0599 0.0589 0.0583 0.0576 0.0571 0.0567 

[TRAIN] Epoch[1](1746/114412); Loss: 0.097209; Backpropagation: 0.2931 sec; Batch: 2.1166 sec
0.1903 0.1456 0.1397 0.1112 0.1015 0.0931 0.0874 0.0845 0.0805 0.0780 0.0768 0.0752 0.0741 0.0730 0.0725 0.0719 

[TRAIN] Epoch[1](1747/114412); Loss: 0.091735; Backpropagation: 0.2914 sec; Batch: 2.1435 sec
0.1960 0.1441 0.1163 0.1022 0.0928 0.0863 0.0821 0.0779 0.0752 0.0734 0.0720 0.0708 0.0701 0.0697 0.0694 0.0693 

[TRAIN] Epoch[1](1748/114412); Loss: 0.060315; Backpropagation: 0.2913 sec; Batch: 2.1229 sec
0.1453 0.0961 0.0882 0.0663 0.0587 0.0550 0.0512 0.0486 0.0469 0.0456 0.0449 0.0443 0.0438 0.0436 0.0433 0.0433 

[TRAIN] Epoch[1](1749/114412); Loss: 0.089364; Backpropagation: 0.2933 sec; Batch: 2.0797 sec
0.1761 0.1256 0.1174 0.0974 0.0909 0.0848 0.0806 0.0783 0.0762 0.0745 0.0732 0.0723 0.0713 0.0708 0.0704 0.0701 

[TRAIN] Epoch[1](1750/114412); Loss: 0.071557; Backpropagation: 0.2932 sec; Batch: 2.1205 sec
0.1438 0.0962 0.0962 0.0790 0.0699 0.0681 0.0647 0.0624 0.0607 0.0596 0.0586 0.0581 0.0574 0.0570 0.0567 0.0564 

[TRAIN] Epoch[1](1751/114412); Loss: 0.090105; Backpropagation: 0.2910 sec; Batch: 2.1150 sec
0.1859 0.1411 0.1270 0.1026 0.0891 0.0848 0.0793 0.0764 0.0742 0.0721 0.0704 0.0691 0.0683 0.0676 0.0671 0.0667 

[TRAIN] Epoch[1](1752/114412); Loss: 0.086902; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.2130 0.1454 0.1157 0.0979 0.0842 0.0780 0.0745 0.0706 0.0687 0.0661 0.0646 0.0636 0.0627 0.0622 0.0618 0.0616 

[TRAIN] Epoch[1](1753/114412); Loss: 0.072647; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.2019 0.1198 0.1194 0.0779 0.0693 0.0621 0.0574 0.0558 0.0542 0.0518 0.0511 0.0494 0.0486 0.0483 0.0478 0.0476 

[TRAIN] Epoch[1](1754/114412); Loss: 0.058855; Backpropagation: 0.2917 sec; Batch: 2.1186 sec
0.1363 0.1036 0.0873 0.0673 0.0564 0.0530 0.0501 0.0472 0.0448 0.0439 0.0434 0.0424 0.0418 0.0417 0.0414 0.0411 

[TRAIN] Epoch[1](1755/114412); Loss: 0.083367; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1833 0.1461 0.1112 0.0933 0.0827 0.0750 0.0695 0.0681 0.0650 0.0642 0.0638 0.0627 0.0626 0.0624 0.0620 0.0621 

[TRAIN] Epoch[1](1756/114412); Loss: 0.096510; Backpropagation: 0.2906 sec; Batch: 2.1262 sec
0.1953 0.1551 0.1246 0.1084 0.0971 0.0905 0.0850 0.0816 0.0794 0.0779 0.0766 0.0756 0.0751 0.0744 0.0739 0.0736 

[TRAIN] Epoch[1](1757/114412); Loss: 0.081913; Backpropagation: 0.2913 sec; Batch: 2.0861 sec
0.1990 0.1386 0.1166 0.1001 0.0827 0.0738 0.0700 0.0654 0.0625 0.0606 0.0588 0.0575 0.0569 0.0562 0.0559 0.0559 

[TRAIN] Epoch[1](1758/114412); Loss: 0.081709; Backpropagation: 0.2923 sec; Batch: 2.0799 sec
0.2092 0.1514 0.1295 0.0992 0.0829 0.0728 0.0664 0.0621 0.0584 0.0566 0.0551 0.0539 0.0531 0.0526 0.0522 0.0519 

[TRAIN] Epoch[1](1759/114412); Loss: 0.079791; Backpropagation: 0.2917 sec; Batch: 2.1197 sec
0.1706 0.1143 0.1064 0.0844 0.0795 0.0750 0.0711 0.0680 0.0662 0.0652 0.0639 0.0633 0.0628 0.0623 0.0619 0.0617 

[TRAIN] Epoch[1](1760/114412); Loss: 0.065555; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.1195 0.0942 0.0836 0.0736 0.0664 0.0628 0.0598 0.0578 0.0562 0.0553 0.0544 0.0537 0.0534 0.0530 0.0527 0.0525 

[TRAIN] Epoch[1](1761/114412); Loss: 0.074585; Backpropagation: 0.2911 sec; Batch: 2.1082 sec
0.1763 0.1230 0.1002 0.0821 0.0741 0.0676 0.0636 0.0610 0.0589 0.0574 0.0566 0.0555 0.0549 0.0544 0.0539 0.0537 

[TRAIN] Epoch[1](1762/114412); Loss: 0.054056; Backpropagation: 0.2928 sec; Batch: 2.1278 sec
0.1361 0.1002 0.0858 0.0694 0.0573 0.0512 0.0461 0.0421 0.0389 0.0366 0.0355 0.0343 0.0332 0.0330 0.0328 0.0324 

[TRAIN] Epoch[1](1763/114412); Loss: 0.075960; Backpropagation: 0.2913 sec; Batch: 2.1112 sec
0.1157 0.1089 0.0962 0.0837 0.0774 0.0745 0.0712 0.0699 0.0674 0.0661 0.0652 0.0644 0.0640 0.0637 0.0635 0.0635 

[TRAIN] Epoch[1](1764/114412); Loss: 0.098970; Backpropagation: 0.2929 sec; Batch: 2.1499 sec
0.2015 0.1342 0.1264 0.1071 0.0983 0.0940 0.0898 0.0869 0.0846 0.0830 0.0816 0.0807 0.0797 0.0792 0.0786 0.0780 

[TRAIN] Epoch[1](1765/114412); Loss: 0.080917; Backpropagation: 0.2930 sec; Batch: 2.1151 sec
0.1771 0.1389 0.1184 0.0987 0.0830 0.0741 0.0695 0.0650 0.0625 0.0605 0.0594 0.0587 0.0578 0.0575 0.0570 0.0565 

[TRAIN] Epoch[1](1766/114412); Loss: 0.082838; Backpropagation: 0.2910 sec; Batch: 2.1558 sec
0.1812 0.1373 0.1103 0.0893 0.0810 0.0759 0.0722 0.0694 0.0673 0.0654 0.0642 0.0634 0.0628 0.0623 0.0620 0.0615 

[TRAIN] Epoch[1](1767/114412); Loss: 0.084573; Backpropagation: 0.2930 sec; Batch: 2.1062 sec
0.1578 0.1335 0.1163 0.0957 0.0860 0.0794 0.0763 0.0735 0.0704 0.0686 0.0678 0.0668 0.0661 0.0655 0.0650 0.0645 

[TRAIN] Epoch[1](1768/114412); Loss: 0.074034; Backpropagation: 0.2916 sec; Batch: 2.1148 sec
0.1526 0.1108 0.0975 0.0824 0.0759 0.0708 0.0667 0.0638 0.0617 0.0602 0.0589 0.0579 0.0573 0.0564 0.0559 0.0556 

[TRAIN] Epoch[1](1769/114412); Loss: 0.064403; Backpropagation: 0.2909 sec; Batch: 2.0776 sec
0.1217 0.0905 0.0822 0.0720 0.0665 0.0615 0.0582 0.0565 0.0548 0.0541 0.0532 0.0525 0.0521 0.0518 0.0516 0.0513 

[TRAIN] Epoch[1](1770/114412); Loss: 0.051761; Backpropagation: 0.2917 sec; Batch: 2.1132 sec
0.1181 0.0722 0.0672 0.0583 0.0530 0.0488 0.0458 0.0438 0.0422 0.0416 0.0408 0.0401 0.0395 0.0391 0.0390 0.0388 

[TRAIN] Epoch[1](1771/114412); Loss: 0.074623; Backpropagation: 0.2908 sec; Batch: 2.1195 sec
0.1447 0.1072 0.0984 0.0840 0.0767 0.0717 0.0675 0.0653 0.0635 0.0620 0.0606 0.0595 0.0588 0.0583 0.0579 0.0577 

[TRAIN] Epoch[1](1772/114412); Loss: 0.067928; Backpropagation: 0.2909 sec; Batch: 2.1286 sec
0.1069 0.1090 0.0953 0.0832 0.0748 0.0668 0.0618 0.0594 0.0573 0.0558 0.0544 0.0535 0.0527 0.0522 0.0520 0.0515 

[TRAIN] Epoch[1](1773/114412); Loss: 0.059726; Backpropagation: 0.2907 sec; Batch: 2.1429 sec
0.1244 0.0933 0.0769 0.0676 0.0612 0.0562 0.0529 0.0509 0.0494 0.0480 0.0472 0.0464 0.0459 0.0454 0.0451 0.0449 

[TRAIN] Epoch[1](1774/114412); Loss: 0.082789; Backpropagation: 0.2915 sec; Batch: 2.1146 sec
0.1690 0.1218 0.1075 0.0907 0.0829 0.0774 0.0737 0.0709 0.0690 0.0679 0.0670 0.0662 0.0658 0.0654 0.0650 0.0646 

[TRAIN] Epoch[1](1775/114412); Loss: 0.076879; Backpropagation: 0.2914 sec; Batch: 2.1200 sec
0.1980 0.1486 0.1094 0.0797 0.0742 0.0656 0.0626 0.0591 0.0571 0.0560 0.0546 0.0540 0.0535 0.0530 0.0525 0.0521 

[TRAIN] Epoch[1](1776/114412); Loss: 0.060185; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1272 0.1007 0.0819 0.0667 0.0601 0.0555 0.0526 0.0500 0.0485 0.0472 0.0466 0.0461 0.0455 0.0452 0.0447 0.0444 

[TRAIN] Epoch[1](1777/114412); Loss: 0.062283; Backpropagation: 0.2914 sec; Batch: 2.1194 sec
0.1213 0.0897 0.0766 0.0680 0.0615 0.0593 0.0564 0.0544 0.0532 0.0520 0.0515 0.0511 0.0507 0.0504 0.0502 0.0500 

[TRAIN] Epoch[1](1778/114412); Loss: 0.093569; Backpropagation: 0.2913 sec; Batch: 2.0976 sec
0.1715 0.1288 0.1167 0.1039 0.0946 0.0892 0.0856 0.0835 0.0813 0.0802 0.0790 0.0779 0.0771 0.0765 0.0759 0.0755 

[TRAIN] Epoch[1](1779/114412); Loss: 0.066801; Backpropagation: 0.2913 sec; Batch: 2.1163 sec
0.1460 0.1058 0.0887 0.0764 0.0671 0.0617 0.0589 0.0559 0.0539 0.0530 0.0519 0.0508 0.0504 0.0499 0.0494 0.0492 

[TRAIN] Epoch[1](1780/114412); Loss: 0.145303; Backpropagation: 0.2914 sec; Batch: 2.0779 sec
0.2033 0.1864 0.1671 0.1553 0.1504 0.1445 0.1404 0.1377 0.1352 0.1329 0.1312 0.1299 0.1287 0.1279 0.1273 0.1268 

[TRAIN] Epoch[1](1781/114412); Loss: 0.087927; Backpropagation: 0.2911 sec; Batch: 2.0941 sec
0.1517 0.1243 0.1078 0.0936 0.0877 0.0843 0.0816 0.0787 0.0775 0.0765 0.0754 0.0747 0.0740 0.0734 0.0730 0.0725 

[TRAIN] Epoch[1](1782/114412); Loss: 0.056794; Backpropagation: 0.2924 sec; Batch: 2.0853 sec
0.1142 0.0868 0.0776 0.0666 0.0577 0.0529 0.0501 0.0478 0.0465 0.0455 0.0449 0.0443 0.0439 0.0435 0.0433 0.0431 

[TRAIN] Epoch[1](1783/114412); Loss: 0.087872; Backpropagation: 0.2913 sec; Batch: 2.1208 sec
0.1537 0.1193 0.1091 0.0969 0.0889 0.0852 0.0819 0.0795 0.0772 0.0757 0.0747 0.0741 0.0732 0.0728 0.0722 0.0717 

[TRAIN] Epoch[1](1784/114412); Loss: 0.058469; Backpropagation: 0.2914 sec; Batch: 2.0781 sec
0.1497 0.0982 0.0974 0.0713 0.0580 0.0512 0.0489 0.0449 0.0427 0.0418 0.0403 0.0394 0.0387 0.0380 0.0377 0.0374 

[TRAIN] Epoch[1](1785/114412); Loss: 0.071217; Backpropagation: 0.2909 sec; Batch: 2.1156 sec
0.1444 0.1033 0.0923 0.0818 0.0742 0.0677 0.0636 0.0608 0.0590 0.0580 0.0570 0.0563 0.0559 0.0554 0.0550 0.0549 

[TRAIN] Epoch[1](1786/114412); Loss: 0.075058; Backpropagation: 0.2912 sec; Batch: 2.1193 sec
0.1842 0.1438 0.1034 0.0936 0.0763 0.0672 0.0620 0.0587 0.0559 0.0540 0.0525 0.0514 0.0505 0.0497 0.0491 0.0487 

[TRAIN] Epoch[1](1787/114412); Loss: 0.065859; Backpropagation: 0.2926 sec; Batch: 2.0785 sec
0.1425 0.0968 0.0835 0.0696 0.0683 0.0639 0.0591 0.0556 0.0543 0.0533 0.0522 0.0518 0.0513 0.0508 0.0505 0.0504 

[TRAIN] Epoch[1](1788/114412); Loss: 0.106656; Backpropagation: 0.2912 sec; Batch: 2.1199 sec
0.2431 0.1944 0.1464 0.1298 0.1067 0.0960 0.0899 0.0844 0.0807 0.0791 0.0782 0.0768 0.0761 0.0755 0.0748 0.0743 

[TRAIN] Epoch[1](1789/114412); Loss: 0.067619; Backpropagation: 0.2931 sec; Batch: 2.1190 sec
0.1412 0.1099 0.0927 0.0752 0.0685 0.0634 0.0595 0.0569 0.0548 0.0535 0.0526 0.0517 0.0510 0.0507 0.0503 0.0500 

[TRAIN] Epoch[1](1790/114412); Loss: 0.081900; Backpropagation: 0.2931 sec; Batch: 2.1179 sec
0.1435 0.1174 0.1010 0.0929 0.0825 0.0775 0.0755 0.0729 0.0713 0.0702 0.0692 0.0685 0.0677 0.0672 0.0668 0.0663 

[TRAIN] Epoch[1](1791/114412); Loss: 0.070839; Backpropagation: 0.2909 sec; Batch: 2.1156 sec
0.1538 0.1051 0.0934 0.0830 0.0743 0.0693 0.0644 0.0597 0.0581 0.0569 0.0540 0.0533 0.0528 0.0522 0.0517 0.0513 

[TRAIN] Epoch[1](1792/114412); Loss: 0.063583; Backpropagation: 0.2909 sec; Batch: 2.1373 sec
0.1113 0.0998 0.0837 0.0688 0.0637 0.0599 0.0582 0.0557 0.0541 0.0535 0.0526 0.0519 0.0516 0.0511 0.0508 0.0506 

[TRAIN] Epoch[1](1793/114412); Loss: 0.064805; Backpropagation: 0.2927 sec; Batch: 2.0796 sec
0.1209 0.0945 0.0830 0.0706 0.0659 0.0619 0.0594 0.0573 0.0557 0.0545 0.0537 0.0528 0.0522 0.0518 0.0515 0.0511 

[TRAIN] Epoch[1](1794/114412); Loss: 0.081061; Backpropagation: 0.2912 sec; Batch: 2.0843 sec
0.1397 0.1127 0.1002 0.0890 0.0822 0.0773 0.0744 0.0728 0.0713 0.0700 0.0691 0.0685 0.0679 0.0676 0.0673 0.0669 

[TRAIN] Epoch[1](1795/114412); Loss: 0.064406; Backpropagation: 0.2919 sec; Batch: 2.0799 sec
0.1281 0.0993 0.0864 0.0702 0.0644 0.0602 0.0578 0.0557 0.0542 0.0527 0.0517 0.0511 0.0503 0.0497 0.0495 0.0492 

[TRAIN] Epoch[1](1796/114412); Loss: 0.063021; Backpropagation: 0.2909 sec; Batch: 2.1180 sec
0.1594 0.1179 0.0805 0.0704 0.0626 0.0566 0.0540 0.0507 0.0484 0.0465 0.0451 0.0444 0.0438 0.0430 0.0426 0.0423 

[TRAIN] Epoch[1](1797/114412); Loss: 0.059856; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.1596 0.1129 0.0905 0.0705 0.0574 0.0523 0.0483 0.0456 0.0437 0.0421 0.0407 0.0399 0.0390 0.0387 0.0384 0.0380 

[TRAIN] Epoch[1](1798/114412); Loss: 0.115034; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.2036 0.1701 0.1435 0.1290 0.1161 0.1090 0.1051 0.1021 0.1001 0.0978 0.0964 0.0954 0.0945 0.0933 0.0925 0.0920 

[TRAIN] Epoch[1](1799/114412); Loss: 0.098160; Backpropagation: 0.2922 sec; Batch: 2.1065 sec
0.1597 0.1320 0.1182 0.1068 0.0997 0.0947 0.0919 0.0897 0.0880 0.0868 0.0856 0.0847 0.0841 0.0833 0.0828 0.0825 

[TRAIN] Epoch[1](1800/114412); Loss: 0.057976; Backpropagation: 0.2912 sec; Batch: 2.0783 sec
0.1354 0.0815 0.0906 0.0711 0.0578 0.0534 0.0501 0.0477 0.0454 0.0438 0.0433 0.0425 0.0419 0.0416 0.0410 0.0406 

[TRAIN] Epoch[1](1801/114412); Loss: 0.078723; Backpropagation: 0.2903 sec; Batch: 2.1194 sec
0.1366 0.1143 0.1037 0.0900 0.0834 0.0787 0.0752 0.0706 0.0682 0.0664 0.0650 0.0634 0.0621 0.0612 0.0606 0.0601 

[TRAIN] Epoch[1](1802/114412); Loss: 0.082964; Backpropagation: 0.2909 sec; Batch: 2.1188 sec
0.1885 0.1435 0.1032 0.0965 0.0822 0.0763 0.0719 0.0697 0.0659 0.0649 0.0635 0.0618 0.0609 0.0601 0.0594 0.0592 

[TRAIN] Epoch[1](1803/114412); Loss: 0.065832; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1208 0.0908 0.0827 0.0737 0.0664 0.0632 0.0603 0.0585 0.0571 0.0559 0.0551 0.0546 0.0542 0.0537 0.0534 0.0530 

[TRAIN] Epoch[1](1804/114412); Loss: 0.055953; Backpropagation: 0.2924 sec; Batch: 2.1191 sec
0.1286 0.0956 0.0734 0.0570 0.0522 0.0502 0.0480 0.0463 0.0448 0.0442 0.0433 0.0429 0.0426 0.0422 0.0421 0.0421 

[TRAIN] Epoch[1](1805/114412); Loss: 0.047837; Backpropagation: 0.2914 sec; Batch: 2.0833 sec
0.1075 0.0773 0.0648 0.0544 0.0484 0.0447 0.0421 0.0404 0.0386 0.0370 0.0362 0.0355 0.0352 0.0348 0.0345 0.0342 

[TRAIN] Epoch[1](1806/114412); Loss: 0.054948; Backpropagation: 0.2919 sec; Batch: 2.0798 sec
0.0947 0.0807 0.0692 0.0605 0.0565 0.0537 0.0512 0.0493 0.0480 0.0470 0.0460 0.0453 0.0449 0.0443 0.0440 0.0438 

[TRAIN] Epoch[1](1807/114412); Loss: 0.074667; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.1564 0.1204 0.0999 0.0880 0.0764 0.0698 0.0669 0.0637 0.0609 0.0594 0.0578 0.0565 0.0556 0.0548 0.0544 0.0538 

[TRAIN] Epoch[1](1808/114412); Loss: 0.055469; Backpropagation: 0.2916 sec; Batch: 2.1301 sec
0.1104 0.1033 0.0883 0.0710 0.0577 0.0513 0.0477 0.0445 0.0419 0.0405 0.0402 0.0391 0.0385 0.0381 0.0378 0.0374 

[TRAIN] Epoch[1](1809/114412); Loss: 0.077886; Backpropagation: 0.2914 sec; Batch: 2.1314 sec
0.1661 0.1282 0.0962 0.0867 0.0776 0.0716 0.0685 0.0666 0.0641 0.0625 0.0615 0.0606 0.0597 0.0591 0.0587 0.0583 

[TRAIN] Epoch[1](1810/114412); Loss: 0.076905; Backpropagation: 0.2913 sec; Batch: 2.0781 sec
0.1596 0.1144 0.0922 0.0794 0.0731 0.0716 0.0686 0.0670 0.0655 0.0641 0.0636 0.0631 0.0626 0.0622 0.0619 0.0617 

[TRAIN] Epoch[1](1811/114412); Loss: 0.064494; Backpropagation: 0.2931 sec; Batch: 2.1207 sec
0.1407 0.1098 0.0930 0.0779 0.0684 0.0612 0.0570 0.0540 0.0510 0.0489 0.0473 0.0464 0.0453 0.0443 0.0436 0.0430 

[TRAIN] Epoch[1](1812/114412); Loss: 0.086678; Backpropagation: 0.2914 sec; Batch: 2.1194 sec
0.1525 0.1298 0.1109 0.0976 0.0902 0.0840 0.0796 0.0765 0.0742 0.0728 0.0716 0.0707 0.0700 0.0693 0.0688 0.0684 

[TRAIN] Epoch[1](1813/114412); Loss: 0.069873; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1275 0.1080 0.0912 0.0732 0.0701 0.0664 0.0631 0.0619 0.0597 0.0586 0.0579 0.0569 0.0567 0.0562 0.0553 0.0552 

[TRAIN] Epoch[1](1814/114412); Loss: 0.064081; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1842 0.1064 0.0939 0.0719 0.0620 0.0558 0.0517 0.0491 0.0467 0.0454 0.0442 0.0436 0.0433 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](1815/114412); Loss: 0.091911; Backpropagation: 0.2914 sec; Batch: 2.0826 sec
0.1503 0.1274 0.1165 0.1040 0.0974 0.0914 0.0868 0.0836 0.0809 0.0793 0.0780 0.0764 0.0755 0.0749 0.0743 0.0739 

[TRAIN] Epoch[1](1816/114412); Loss: 0.080504; Backpropagation: 0.2913 sec; Batch: 2.1206 sec
0.1308 0.1065 0.0978 0.0874 0.0815 0.0780 0.0755 0.0736 0.0721 0.0711 0.0704 0.0697 0.0691 0.0686 0.0681 0.0678 

[TRAIN] Epoch[1](1817/114412); Loss: 0.082056; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1308 0.1112 0.0982 0.0879 0.0835 0.0793 0.0767 0.0751 0.0738 0.0727 0.0718 0.0712 0.0707 0.0703 0.0700 0.0697 

[TRAIN] Epoch[1](1818/114412); Loss: 0.082122; Backpropagation: 0.2934 sec; Batch: 2.1157 sec
0.1293 0.1166 0.1059 0.0954 0.0873 0.0810 0.0767 0.0739 0.0718 0.0702 0.0690 0.0681 0.0677 0.0674 0.0670 0.0668 

[TRAIN] Epoch[1](1819/114412); Loss: 0.057817; Backpropagation: 0.2916 sec; Batch: 2.1148 sec
0.1048 0.1008 0.0850 0.0685 0.0627 0.0560 0.0508 0.0486 0.0469 0.0452 0.0445 0.0435 0.0426 0.0420 0.0417 0.0415 

[TRAIN] Epoch[1](1820/114412); Loss: 0.051664; Backpropagation: 0.2931 sec; Batch: 2.1199 sec
0.1081 0.0885 0.0688 0.0605 0.0523 0.0466 0.0452 0.0429 0.0415 0.0405 0.0398 0.0393 0.0387 0.0383 0.0381 0.0377 

[TRAIN] Epoch[1](1821/114412); Loss: 0.079212; Backpropagation: 0.2909 sec; Batch: 2.1189 sec
0.1600 0.1214 0.1202 0.0925 0.0815 0.0758 0.0702 0.0664 0.0638 0.0619 0.0605 0.0598 0.0590 0.0585 0.0581 0.0577 

[TRAIN] Epoch[1](1822/114412); Loss: 0.056998; Backpropagation: 0.2911 sec; Batch: 2.1212 sec
0.1149 0.0932 0.0728 0.0606 0.0566 0.0533 0.0508 0.0487 0.0474 0.0463 0.0457 0.0451 0.0446 0.0443 0.0439 0.0438 

[TRAIN] Epoch[1](1823/114412); Loss: 0.075944; Backpropagation: 0.2913 sec; Batch: 2.1119 sec
0.1487 0.1120 0.0924 0.0826 0.0762 0.0718 0.0696 0.0671 0.0651 0.0639 0.0626 0.0617 0.0611 0.0605 0.0600 0.0597 

[TRAIN] Epoch[1](1824/114412); Loss: 0.067945; Backpropagation: 0.2909 sec; Batch: 2.1141 sec
0.1906 0.1327 0.0991 0.0715 0.0641 0.0583 0.0553 0.0516 0.0492 0.0474 0.0463 0.0453 0.0447 0.0441 0.0437 0.0433 

[TRAIN] Epoch[1](1825/114412); Loss: 0.062507; Backpropagation: 0.2934 sec; Batch: 2.1006 sec
0.1389 0.1041 0.0948 0.0776 0.0630 0.0588 0.0525 0.0507 0.0491 0.0466 0.0458 0.0449 0.0441 0.0437 0.0430 0.0426 

[TRAIN] Epoch[1](1826/114412); Loss: 0.088802; Backpropagation: 0.2928 sec; Batch: 2.1214 sec
0.1285 0.1214 0.1051 0.0935 0.0894 0.0865 0.0838 0.0818 0.0810 0.0801 0.0793 0.0789 0.0784 0.0780 0.0776 0.0772 

[TRAIN] Epoch[1](1827/114412); Loss: 0.081472; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1853 0.1302 0.1160 0.0955 0.0844 0.0761 0.0687 0.0655 0.0640 0.0625 0.0608 0.0602 0.0594 0.0587 0.0584 0.0580 

[TRAIN] Epoch[1](1828/114412); Loss: 0.078424; Backpropagation: 0.2906 sec; Batch: 2.0775 sec
0.1445 0.1106 0.0994 0.0844 0.0776 0.0746 0.0715 0.0697 0.0685 0.0672 0.0660 0.0653 0.0646 0.0639 0.0636 0.0633 

[TRAIN] Epoch[1](1829/114412); Loss: 0.061106; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1320 0.0967 0.0852 0.0704 0.0607 0.0556 0.0539 0.0515 0.0492 0.0481 0.0471 0.0465 0.0459 0.0452 0.0450 0.0447 

[TRAIN] Epoch[1](1830/114412); Loss: 0.066089; Backpropagation: 0.2912 sec; Batch: 2.0776 sec
0.1394 0.1094 0.0856 0.0730 0.0675 0.0625 0.0580 0.0562 0.0539 0.0525 0.0516 0.0507 0.0500 0.0494 0.0490 0.0487 

[TRAIN] Epoch[1](1831/114412); Loss: 0.051774; Backpropagation: 0.2912 sec; Batch: 2.1134 sec
0.1125 0.0807 0.0678 0.0577 0.0521 0.0483 0.0458 0.0442 0.0426 0.0415 0.0405 0.0400 0.0394 0.0388 0.0385 0.0381 

[TRAIN] Epoch[1](1832/114412); Loss: 0.059292; Backpropagation: 0.2917 sec; Batch: 2.0792 sec
0.1084 0.0861 0.0755 0.0638 0.0589 0.0577 0.0548 0.0526 0.0515 0.0503 0.0493 0.0488 0.0483 0.0479 0.0476 0.0473 

[TRAIN] Epoch[1](1833/114412); Loss: 0.068370; Backpropagation: 0.2913 sec; Batch: 2.1193 sec
0.1388 0.1142 0.0865 0.0735 0.0658 0.0620 0.0600 0.0588 0.0568 0.0558 0.0549 0.0542 0.0537 0.0533 0.0530 0.0526 

[TRAIN] Epoch[1](1834/114412); Loss: 0.082060; Backpropagation: 0.2914 sec; Batch: 2.0992 sec
0.1444 0.1271 0.1066 0.0883 0.0813 0.0771 0.0745 0.0721 0.0708 0.0694 0.0682 0.0677 0.0671 0.0664 0.0662 0.0657 

[TRAIN] Epoch[1](1835/114412); Loss: 0.063927; Backpropagation: 0.2913 sec; Batch: 2.1271 sec
0.1215 0.1051 0.0902 0.0719 0.0636 0.0603 0.0565 0.0539 0.0527 0.0514 0.0506 0.0497 0.0493 0.0490 0.0486 0.0483 

[TRAIN] Epoch[1](1836/114412); Loss: 0.056532; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1154 0.0919 0.0801 0.0650 0.0563 0.0536 0.0515 0.0480 0.0466 0.0451 0.0432 0.0424 0.0420 0.0414 0.0411 0.0409 

[TRAIN] Epoch[1](1837/114412); Loss: 0.075625; Backpropagation: 0.2908 sec; Batch: 2.1214 sec
0.1674 0.1022 0.1025 0.0850 0.0758 0.0700 0.0666 0.0643 0.0627 0.0615 0.0603 0.0593 0.0588 0.0583 0.0578 0.0574 

[TRAIN] Epoch[1](1838/114412); Loss: 0.075960; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1642 0.1234 0.0969 0.0831 0.0750 0.0699 0.0659 0.0639 0.0620 0.0605 0.0598 0.0592 0.0586 0.0580 0.0577 0.0572 

[TRAIN] Epoch[1](1839/114412); Loss: 0.076103; Backpropagation: 0.2911 sec; Batch: 2.1227 sec
0.1481 0.1195 0.0992 0.0848 0.0755 0.0720 0.0680 0.0651 0.0638 0.0623 0.0613 0.0606 0.0599 0.0596 0.0593 0.0588 

[TRAIN] Epoch[1](1840/114412); Loss: 0.068190; Backpropagation: 0.2911 sec; Batch: 2.0860 sec
0.1481 0.1352 0.0943 0.0749 0.0674 0.0615 0.0583 0.0547 0.0527 0.0513 0.0501 0.0494 0.0489 0.0485 0.0481 0.0478 

[TRAIN] Epoch[1](1841/114412); Loss: 0.056145; Backpropagation: 0.2905 sec; Batch: 2.1209 sec
0.0965 0.0822 0.0732 0.0621 0.0551 0.0536 0.0514 0.0497 0.0488 0.0479 0.0471 0.0469 0.0465 0.0461 0.0459 0.0455 

[TRAIN] Epoch[1](1842/114412); Loss: 0.048651; Backpropagation: 0.2910 sec; Batch: 2.1148 sec
0.1118 0.0878 0.0663 0.0577 0.0499 0.0447 0.0408 0.0394 0.0375 0.0362 0.0354 0.0349 0.0343 0.0340 0.0339 0.0338 

[TRAIN] Epoch[1](1843/114412); Loss: 0.069477; Backpropagation: 0.2909 sec; Batch: 2.1248 sec
0.1511 0.1099 0.1005 0.0810 0.0679 0.0648 0.0611 0.0569 0.0553 0.0546 0.0530 0.0524 0.0515 0.0508 0.0507 0.0503 

[TRAIN] Epoch[1](1844/114412); Loss: 0.050173; Backpropagation: 0.2913 sec; Batch: 2.1077 sec
0.1475 0.0854 0.0703 0.0480 0.0433 0.0424 0.0402 0.0389 0.0376 0.0370 0.0363 0.0359 0.0354 0.0351 0.0349 0.0347 

[TRAIN] Epoch[1](1845/114412); Loss: 0.077629; Backpropagation: 0.2928 sec; Batch: 2.1253 sec
0.1729 0.1051 0.0976 0.0801 0.0742 0.0729 0.0694 0.0670 0.0662 0.0642 0.0635 0.0628 0.0621 0.0618 0.0612 0.0609 

[TRAIN] Epoch[1](1846/114412); Loss: 0.060270; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.1185 0.0942 0.0846 0.0664 0.0598 0.0569 0.0538 0.0513 0.0503 0.0488 0.0478 0.0475 0.0467 0.0461 0.0460 0.0456 

[TRAIN] Epoch[1](1847/114412); Loss: 0.067368; Backpropagation: 0.2906 sec; Batch: 2.1445 sec
0.1707 0.1065 0.0873 0.0707 0.0660 0.0616 0.0582 0.0555 0.0536 0.0522 0.0511 0.0499 0.0494 0.0488 0.0484 0.0482 

[TRAIN] Epoch[1](1848/114412); Loss: 0.064942; Backpropagation: 0.2913 sec; Batch: 2.1460 sec
0.1384 0.1054 0.0890 0.0743 0.0659 0.0610 0.0574 0.0541 0.0524 0.0509 0.0498 0.0492 0.0485 0.0480 0.0477 0.0472 

[TRAIN] Epoch[1](1849/114412); Loss: 0.059143; Backpropagation: 0.2907 sec; Batch: 2.1871 sec
0.1270 0.0923 0.0787 0.0639 0.0574 0.0550 0.0518 0.0501 0.0488 0.0476 0.0467 0.0462 0.0458 0.0453 0.0451 0.0447 

[TRAIN] Epoch[1](1850/114412); Loss: 0.080377; Backpropagation: 0.2913 sec; Batch: 2.0882 sec
0.1304 0.1187 0.0992 0.0838 0.0799 0.0766 0.0740 0.0724 0.0713 0.0702 0.0694 0.0688 0.0683 0.0679 0.0677 0.0674 

[TRAIN] Epoch[1](1851/114412); Loss: 0.078722; Backpropagation: 0.2913 sec; Batch: 2.1431 sec
0.1785 0.1119 0.1115 0.0875 0.0796 0.0758 0.0699 0.0667 0.0636 0.0617 0.0606 0.0597 0.0590 0.0584 0.0579 0.0575 

[TRAIN] Epoch[1](1852/114412); Loss: 0.052627; Backpropagation: 0.2951 sec; Batch: 2.1178 sec
0.1083 0.0986 0.0719 0.0554 0.0508 0.0465 0.0444 0.0426 0.0415 0.0412 0.0408 0.0403 0.0402 0.0400 0.0398 0.0397 

[TRAIN] Epoch[1](1853/114412); Loss: 0.070685; Backpropagation: 0.2942 sec; Batch: 2.4855 sec
0.1307 0.1075 0.0959 0.0779 0.0716 0.0678 0.0648 0.0622 0.0602 0.0584 0.0574 0.0565 0.0557 0.0552 0.0548 0.0544 

[TRAIN] Epoch[1](1854/114412); Loss: 0.069620; Backpropagation: 0.2915 sec; Batch: 2.1129 sec
0.1215 0.1206 0.0920 0.0776 0.0715 0.0668 0.0625 0.0606 0.0583 0.0569 0.0557 0.0549 0.0543 0.0539 0.0536 0.0533 

[TRAIN] Epoch[1](1855/114412); Loss: 0.068473; Backpropagation: 0.2929 sec; Batch: 2.0861 sec
0.1402 0.1064 0.0845 0.0731 0.0673 0.0643 0.0620 0.0589 0.0577 0.0566 0.0553 0.0548 0.0542 0.0537 0.0535 0.0531 

[TRAIN] Epoch[1](1856/114412); Loss: 0.094217; Backpropagation: 0.2932 sec; Batch: 2.2239 sec
0.1426 0.1394 0.1255 0.1079 0.1012 0.0960 0.0896 0.0857 0.0823 0.0806 0.0782 0.0773 0.0762 0.0755 0.0750 0.0745 

[TRAIN] Epoch[1](1857/114412); Loss: 0.075546; Backpropagation: 0.2951 sec; Batch: 2.1255 sec
0.1458 0.1072 0.0968 0.0845 0.0765 0.0722 0.0685 0.0663 0.0644 0.0632 0.0619 0.0612 0.0608 0.0601 0.0597 0.0594 

[TRAIN] Epoch[1](1858/114412); Loss: 0.070993; Backpropagation: 0.2914 sec; Batch: 2.1166 sec
0.1199 0.1037 0.0940 0.0782 0.0719 0.0684 0.0649 0.0624 0.0616 0.0606 0.0598 0.0591 0.0584 0.0580 0.0577 0.0574 

[TRAIN] Epoch[1](1859/114412); Loss: 0.098685; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1750 0.1437 0.1162 0.1058 0.0992 0.0937 0.0910 0.0882 0.0863 0.0853 0.0839 0.0832 0.0827 0.0819 0.0815 0.0814 

[TRAIN] Epoch[1](1860/114412); Loss: 0.064987; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1555 0.1236 0.1007 0.0767 0.0671 0.0567 0.0523 0.0497 0.0481 0.0465 0.0451 0.0443 0.0440 0.0435 0.0432 0.0430 

[TRAIN] Epoch[1](1861/114412); Loss: 0.072706; Backpropagation: 0.2914 sec; Batch: 2.1141 sec
0.1672 0.1220 0.1075 0.0874 0.0771 0.0681 0.0626 0.0591 0.0561 0.0539 0.0527 0.0516 0.0505 0.0497 0.0491 0.0487 

[TRAIN] Epoch[1](1862/114412); Loss: 0.049381; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.0939 0.0832 0.0695 0.0596 0.0521 0.0483 0.0450 0.0420 0.0405 0.0388 0.0377 0.0370 0.0362 0.0358 0.0355 0.0351 

[TRAIN] Epoch[1](1863/114412); Loss: 0.073200; Backpropagation: 0.2915 sec; Batch: 2.1209 sec
0.1418 0.1057 0.0890 0.0789 0.0720 0.0686 0.0666 0.0644 0.0629 0.0619 0.0613 0.0606 0.0599 0.0596 0.0591 0.0588 

[TRAIN] Epoch[1](1864/114412); Loss: 0.102614; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.2246 0.1797 0.1709 0.1290 0.1077 0.0947 0.0884 0.0835 0.0781 0.0743 0.0729 0.0705 0.0686 0.0674 0.0663 0.0652 

[TRAIN] Epoch[1](1865/114412); Loss: 0.071583; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1171 0.1066 0.0871 0.0767 0.0711 0.0674 0.0654 0.0640 0.0631 0.0621 0.0617 0.0612 0.0608 0.0605 0.0603 0.0601 

[TRAIN] Epoch[1](1866/114412); Loss: 0.099569; Backpropagation: 0.2904 sec; Batch: 2.1128 sec
0.1752 0.1315 0.1193 0.1063 0.0992 0.0954 0.0924 0.0900 0.0887 0.0872 0.0861 0.0856 0.0849 0.0842 0.0838 0.0834 

[TRAIN] Epoch[1](1867/114412); Loss: 0.073340; Backpropagation: 0.2912 sec; Batch: 2.1191 sec
0.1424 0.1053 0.0941 0.0806 0.0738 0.0702 0.0667 0.0643 0.0627 0.0613 0.0603 0.0594 0.0587 0.0581 0.0578 0.0575 

[TRAIN] Epoch[1](1868/114412); Loss: 0.044397; Backpropagation: 0.2911 sec; Batch: 2.0973 sec
0.0941 0.0893 0.0688 0.0539 0.0466 0.0414 0.0389 0.0358 0.0336 0.0320 0.0309 0.0301 0.0294 0.0290 0.0286 0.0282 

[TRAIN] Epoch[1](1869/114412); Loss: 0.080850; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1252 0.1118 0.0992 0.0882 0.0807 0.0777 0.0756 0.0736 0.0724 0.0717 0.0710 0.0702 0.0697 0.0693 0.0688 0.0685 

[TRAIN] Epoch[1](1870/114412); Loss: 0.083330; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1752 0.1155 0.1130 0.0982 0.0877 0.0815 0.0760 0.0715 0.0697 0.0678 0.0651 0.0641 0.0631 0.0622 0.0615 0.0611 

[TRAIN] Epoch[1](1871/114412); Loss: 0.057577; Backpropagation: 0.2910 sec; Batch: 2.1216 sec
0.0938 0.0871 0.0714 0.0630 0.0589 0.0549 0.0533 0.0517 0.0504 0.0496 0.0491 0.0483 0.0478 0.0475 0.0472 0.0471 

[TRAIN] Epoch[1](1872/114412); Loss: 0.087708; Backpropagation: 0.2913 sec; Batch: 2.1337 sec
0.1444 0.1173 0.1023 0.0959 0.0893 0.0848 0.0827 0.0809 0.0789 0.0779 0.0766 0.0756 0.0749 0.0744 0.0740 0.0735 

[TRAIN] Epoch[1](1873/114412); Loss: 0.055930; Backpropagation: 0.2909 sec; Batch: 2.1141 sec
0.1257 0.0905 0.0756 0.0644 0.0571 0.0520 0.0494 0.0461 0.0445 0.0436 0.0424 0.0414 0.0411 0.0407 0.0403 0.0401 

[TRAIN] Epoch[1](1874/114412); Loss: 0.071129; Backpropagation: 0.2909 sec; Batch: 2.0780 sec
0.1566 0.1095 0.0952 0.0741 0.0689 0.0669 0.0625 0.0598 0.0586 0.0574 0.0562 0.0555 0.0549 0.0544 0.0540 0.0536 

[TRAIN] Epoch[1](1875/114412); Loss: 0.078538; Backpropagation: 0.2909 sec; Batch: 2.1199 sec
0.1292 0.1047 0.0918 0.0826 0.0778 0.0756 0.0738 0.0720 0.0709 0.0699 0.0691 0.0686 0.0681 0.0679 0.0675 0.0672 

[TRAIN] Epoch[1](1876/114412); Loss: 0.087450; Backpropagation: 0.2913 sec; Batch: 2.1194 sec
0.1426 0.1256 0.1083 0.0959 0.0896 0.0850 0.0819 0.0793 0.0777 0.0764 0.0749 0.0739 0.0732 0.0722 0.0716 0.0711 

[TRAIN] Epoch[1](1877/114412); Loss: 0.072149; Backpropagation: 0.2908 sec; Batch: 2.0838 sec
0.1405 0.1073 0.0830 0.0777 0.0686 0.0656 0.0638 0.0626 0.0621 0.0614 0.0608 0.0606 0.0603 0.0601 0.0601 0.0598 

[TRAIN] Epoch[1](1878/114412); Loss: 0.066166; Backpropagation: 0.2924 sec; Batch: 2.0788 sec
0.1096 0.1105 0.0839 0.0711 0.0657 0.0622 0.0599 0.0580 0.0569 0.0561 0.0551 0.0545 0.0541 0.0538 0.0536 0.0534 

[TRAIN] Epoch[1](1879/114412); Loss: 0.069286; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1485 0.1111 0.0846 0.0826 0.0691 0.0638 0.0604 0.0584 0.0568 0.0553 0.0543 0.0536 0.0531 0.0527 0.0523 0.0521 

[TRAIN] Epoch[1](1880/114412); Loss: 0.076084; Backpropagation: 0.2913 sec; Batch: 2.1203 sec
0.1286 0.1147 0.0937 0.0831 0.0770 0.0727 0.0696 0.0675 0.0663 0.0653 0.0645 0.0639 0.0634 0.0627 0.0623 0.0619 

[TRAIN] Epoch[1](1881/114412); Loss: 0.066713; Backpropagation: 0.2906 sec; Batch: 2.1176 sec
0.1263 0.0992 0.0857 0.0741 0.0682 0.0634 0.0607 0.0582 0.0568 0.0557 0.0545 0.0539 0.0533 0.0528 0.0524 0.0521 

[TRAIN] Epoch[1](1882/114412); Loss: 0.069370; Backpropagation: 0.2913 sec; Batch: 2.1211 sec
0.1188 0.1042 0.0908 0.0779 0.0694 0.0669 0.0635 0.0615 0.0598 0.0585 0.0576 0.0570 0.0567 0.0561 0.0557 0.0554 

[TRAIN] Epoch[1](1883/114412); Loss: 0.080516; Backpropagation: 0.2907 sec; Batch: 2.1202 sec
0.1468 0.1196 0.1070 0.0922 0.0836 0.0791 0.0736 0.0703 0.0688 0.0666 0.0654 0.0644 0.0635 0.0630 0.0623 0.0618 

[TRAIN] Epoch[1](1884/114412); Loss: 0.078599; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1388 0.1295 0.1135 0.0946 0.0864 0.0773 0.0728 0.0685 0.0647 0.0632 0.0611 0.0594 0.0586 0.0571 0.0564 0.0558 

[TRAIN] Epoch[1](1885/114412); Loss: 0.077557; Backpropagation: 0.2913 sec; Batch: 2.1018 sec
0.1430 0.1246 0.1042 0.0876 0.0797 0.0729 0.0694 0.0664 0.0648 0.0633 0.0621 0.0613 0.0609 0.0604 0.0601 0.0599 

[TRAIN] Epoch[1](1886/114412); Loss: 0.072942; Backpropagation: 0.2904 sec; Batch: 2.0945 sec
0.1255 0.1100 0.0949 0.0830 0.0774 0.0713 0.0677 0.0647 0.0624 0.0611 0.0599 0.0589 0.0583 0.0579 0.0573 0.0569 

[TRAIN] Epoch[1](1887/114412); Loss: 0.057846; Backpropagation: 0.2912 sec; Batch: 2.1211 sec
0.1064 0.0987 0.0720 0.0640 0.0589 0.0543 0.0516 0.0498 0.0485 0.0475 0.0468 0.0462 0.0456 0.0454 0.0451 0.0449 

[TRAIN] Epoch[1](1888/114412); Loss: 0.069125; Backpropagation: 0.2909 sec; Batch: 2.1191 sec
0.1326 0.1065 0.0857 0.0747 0.0677 0.0647 0.0622 0.0601 0.0589 0.0575 0.0570 0.0564 0.0559 0.0556 0.0554 0.0552 

[TRAIN] Epoch[1](1889/114412); Loss: 0.071094; Backpropagation: 0.2915 sec; Batch: 2.1203 sec
0.1506 0.1264 0.1053 0.0851 0.0730 0.0663 0.0635 0.0583 0.0561 0.0537 0.0523 0.0511 0.0499 0.0492 0.0486 0.0481 

[TRAIN] Epoch[1](1890/114412); Loss: 0.050309; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1028 0.0859 0.0691 0.0578 0.0501 0.0476 0.0445 0.0416 0.0406 0.0396 0.0384 0.0381 0.0375 0.0372 0.0371 0.0369 

[TRAIN] Epoch[1](1891/114412); Loss: 0.091938; Backpropagation: 0.2905 sec; Batch: 2.1158 sec
0.1641 0.1277 0.1182 0.1065 0.0973 0.0897 0.0870 0.0822 0.0796 0.0785 0.0766 0.0746 0.0733 0.0725 0.0718 0.0714 

[TRAIN] Epoch[1](1892/114412); Loss: 0.080675; Backpropagation: 0.2903 sec; Batch: 2.0769 sec
0.1179 0.1070 0.0995 0.0875 0.0823 0.0790 0.0766 0.0746 0.0734 0.0723 0.0714 0.0707 0.0701 0.0697 0.0694 0.0692 

[TRAIN] Epoch[1](1893/114412); Loss: 0.079011; Backpropagation: 0.2906 sec; Batch: 2.1130 sec
0.1357 0.1114 0.0988 0.0882 0.0805 0.0767 0.0734 0.0708 0.0694 0.0678 0.0668 0.0660 0.0654 0.0648 0.0644 0.0640 

[TRAIN] Epoch[1](1894/114412); Loss: 0.050525; Backpropagation: 0.2951 sec; Batch: 2.1189 sec
0.0947 0.0847 0.0675 0.0571 0.0508 0.0472 0.0445 0.0432 0.0419 0.0407 0.0402 0.0397 0.0393 0.0391 0.0389 0.0389 

[TRAIN] Epoch[1](1895/114412); Loss: 0.057788; Backpropagation: 0.2924 sec; Batch: 2.1268 sec
0.1355 0.0885 0.0757 0.0617 0.0555 0.0520 0.0497 0.0483 0.0469 0.0461 0.0453 0.0447 0.0442 0.0439 0.0435 0.0432 

[TRAIN] Epoch[1](1896/114412); Loss: 0.050691; Backpropagation: 0.2911 sec; Batch: 2.0781 sec
0.1021 0.0867 0.0695 0.0585 0.0510 0.0485 0.0450 0.0424 0.0414 0.0398 0.0391 0.0383 0.0376 0.0372 0.0371 0.0368 

[TRAIN] Epoch[1](1897/114412); Loss: 0.069309; Backpropagation: 0.2905 sec; Batch: 2.1146 sec
0.1098 0.0959 0.0810 0.0736 0.0696 0.0675 0.0651 0.0638 0.0624 0.0615 0.0609 0.0604 0.0599 0.0595 0.0592 0.0590 

[TRAIN] Epoch[1](1898/114412); Loss: 0.075975; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.1362 0.1089 0.0934 0.0834 0.0772 0.0728 0.0701 0.0675 0.0660 0.0644 0.0635 0.0631 0.0629 0.0624 0.0622 0.0617 

[TRAIN] Epoch[1](1899/114412); Loss: 0.094965; Backpropagation: 0.2927 sec; Batch: 2.1184 sec
0.1734 0.1445 0.1200 0.1036 0.0955 0.0899 0.0864 0.0835 0.0817 0.0799 0.0789 0.0779 0.0769 0.0763 0.0758 0.0753 

[TRAIN] Epoch[1](1900/114412); Loss: 0.068357; Backpropagation: 0.2930 sec; Batch: 2.1017 sec
0.1323 0.1021 0.0799 0.0737 0.0683 0.0648 0.0623 0.0596 0.0584 0.0577 0.0568 0.0561 0.0559 0.0555 0.0553 0.0550 

[TRAIN] Epoch[1](1901/114412); Loss: 0.082346; Backpropagation: 0.2930 sec; Batch: 2.1197 sec
0.1358 0.1226 0.1050 0.0925 0.0847 0.0796 0.0760 0.0732 0.0715 0.0703 0.0693 0.0685 0.0678 0.0673 0.0668 0.0664 

[TRAIN] Epoch[1](1902/114412); Loss: 0.051746; Backpropagation: 0.2928 sec; Batch: 2.1195 sec
0.1189 0.0857 0.0706 0.0584 0.0539 0.0492 0.0457 0.0425 0.0408 0.0396 0.0387 0.0378 0.0372 0.0367 0.0363 0.0360 

[TRAIN] Epoch[1](1903/114412); Loss: 0.093955; Backpropagation: 0.2923 sec; Batch: 2.0806 sec
0.1760 0.1414 0.1088 0.0983 0.0907 0.0876 0.0854 0.0830 0.0816 0.0806 0.0796 0.0788 0.0783 0.0780 0.0777 0.0774 

[TRAIN] Epoch[1](1904/114412); Loss: 0.114439; Backpropagation: 0.2927 sec; Batch: 2.1217 sec
0.1595 0.1470 0.1279 0.1214 0.1181 0.1136 0.1097 0.1077 0.1059 0.1044 0.1039 0.1032 0.1025 0.1023 0.1021 0.1018 

[TRAIN] Epoch[1](1905/114412); Loss: 0.063714; Backpropagation: 0.2914 sec; Batch: 2.1218 sec
0.1025 0.0945 0.0810 0.0732 0.0658 0.0623 0.0595 0.0572 0.0555 0.0544 0.0536 0.0529 0.0524 0.0519 0.0515 0.0512 

[TRAIN] Epoch[1](1906/114412); Loss: 0.100797; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1814 0.1394 0.1170 0.1089 0.1011 0.0960 0.0931 0.0903 0.0889 0.0872 0.0864 0.0855 0.0848 0.0845 0.0842 0.0838 

[TRAIN] Epoch[1](1907/114412); Loss: 0.072858; Backpropagation: 0.2930 sec; Batch: 2.1178 sec
0.1672 0.1174 0.0906 0.0815 0.0724 0.0671 0.0637 0.0611 0.0593 0.0576 0.0565 0.0556 0.0548 0.0542 0.0536 0.0532 

[TRAIN] Epoch[1](1908/114412); Loss: 0.068282; Backpropagation: 0.2914 sec; Batch: 2.1151 sec
0.1603 0.1159 0.0839 0.0790 0.0676 0.0617 0.0593 0.0550 0.0535 0.0525 0.0518 0.0511 0.0507 0.0503 0.0501 0.0499 

[TRAIN] Epoch[1](1909/114412); Loss: 0.053417; Backpropagation: 0.2927 sec; Batch: 2.1202 sec
0.1113 0.0877 0.0685 0.0610 0.0525 0.0493 0.0470 0.0447 0.0438 0.0428 0.0422 0.0415 0.0412 0.0406 0.0405 0.0401 

[TRAIN] Epoch[1](1910/114412); Loss: 0.063200; Backpropagation: 0.2909 sec; Batch: 2.1189 sec
0.1162 0.1040 0.0864 0.0743 0.0668 0.0600 0.0565 0.0543 0.0522 0.0507 0.0498 0.0487 0.0484 0.0480 0.0475 0.0474 

[TRAIN] Epoch[1](1911/114412); Loss: 0.062709; Backpropagation: 0.2928 sec; Batch: 2.1178 sec
0.1188 0.0986 0.0844 0.0720 0.0633 0.0591 0.0567 0.0540 0.0527 0.0513 0.0501 0.0495 0.0488 0.0484 0.0480 0.0477 

[TRAIN] Epoch[1](1912/114412); Loss: 0.063689; Backpropagation: 0.2927 sec; Batch: 2.1178 sec
0.1148 0.0968 0.0806 0.0703 0.0638 0.0615 0.0583 0.0557 0.0545 0.0536 0.0527 0.0521 0.0516 0.0513 0.0509 0.0505 

[TRAIN] Epoch[1](1913/114412); Loss: 0.078790; Backpropagation: 0.2912 sec; Batch: 2.1146 sec
0.1518 0.1330 0.1115 0.0907 0.0802 0.0734 0.0692 0.0666 0.0640 0.0625 0.0614 0.0607 0.0598 0.0591 0.0586 0.0582 

[TRAIN] Epoch[1](1914/114412); Loss: 0.042963; Backpropagation: 0.2905 sec; Batch: 2.1226 sec
0.1015 0.0816 0.0606 0.0469 0.0408 0.0377 0.0361 0.0340 0.0328 0.0319 0.0313 0.0309 0.0305 0.0304 0.0303 0.0302 

[TRAIN] Epoch[1](1915/114412); Loss: 0.069995; Backpropagation: 0.2906 sec; Batch: 2.0808 sec
0.1142 0.1121 0.0983 0.0873 0.0727 0.0699 0.0631 0.0611 0.0594 0.0572 0.0561 0.0552 0.0540 0.0536 0.0531 0.0526 

[TRAIN] Epoch[1](1916/114412); Loss: 0.072508; Backpropagation: 0.2905 sec; Batch: 2.1170 sec
0.1249 0.1045 0.0921 0.0808 0.0726 0.0697 0.0670 0.0652 0.0635 0.0622 0.0613 0.0605 0.0599 0.0592 0.0587 0.0583 

[TRAIN] Epoch[1](1917/114412); Loss: 0.071786; Backpropagation: 0.2914 sec; Batch: 2.0793 sec
0.1682 0.1194 0.0918 0.0833 0.0710 0.0668 0.0631 0.0583 0.0574 0.0554 0.0539 0.0533 0.0524 0.0517 0.0515 0.0510 

[TRAIN] Epoch[1](1918/114412); Loss: 0.088433; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1383 0.1112 0.1095 0.0999 0.0915 0.0889 0.0842 0.0815 0.0799 0.0783 0.0771 0.0763 0.0753 0.0748 0.0743 0.0738 

[TRAIN] Epoch[1](1919/114412); Loss: 0.059302; Backpropagation: 0.2932 sec; Batch: 2.1237 sec
0.1295 0.0832 0.0736 0.0643 0.0592 0.0560 0.0530 0.0512 0.0497 0.0485 0.0479 0.0474 0.0468 0.0464 0.0462 0.0459 

[TRAIN] Epoch[1](1920/114412); Loss: 0.070897; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1190 0.1041 0.0923 0.0779 0.0714 0.0689 0.0653 0.0631 0.0616 0.0604 0.0596 0.0590 0.0585 0.0582 0.0577 0.0574 

[TRAIN] Epoch[1](1921/114412); Loss: 0.077004; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1401 0.1197 0.1047 0.0893 0.0783 0.0734 0.0699 0.0673 0.0648 0.0632 0.0620 0.0609 0.0603 0.0598 0.0594 0.0591 

[TRAIN] Epoch[1](1922/114412); Loss: 0.058141; Backpropagation: 0.2917 sec; Batch: 2.0835 sec
0.1571 0.1021 0.0818 0.0637 0.0548 0.0507 0.0475 0.0452 0.0437 0.0422 0.0415 0.0408 0.0402 0.0399 0.0396 0.0395 

[TRAIN] Epoch[1](1923/114412); Loss: 0.065657; Backpropagation: 0.2911 sec; Batch: 2.1770 sec
0.1300 0.1033 0.0826 0.0747 0.0671 0.0618 0.0590 0.0564 0.0550 0.0538 0.0528 0.0522 0.0513 0.0506 0.0502 0.0498 

[TRAIN] Epoch[1](1924/114412); Loss: 0.073070; Backpropagation: 0.2908 sec; Batch: 2.0866 sec
0.1276 0.1117 0.0925 0.0819 0.0739 0.0697 0.0671 0.0645 0.0629 0.0616 0.0606 0.0601 0.0594 0.0589 0.0584 0.0581 

[TRAIN] Epoch[1](1925/114412); Loss: 0.072990; Backpropagation: 0.2913 sec; Batch: 2.1186 sec
0.1461 0.1260 0.1041 0.0873 0.0756 0.0677 0.0638 0.0609 0.0584 0.0569 0.0555 0.0544 0.0535 0.0530 0.0525 0.0521 

[TRAIN] Epoch[1](1926/114412); Loss: 0.050759; Backpropagation: 0.2911 sec; Batch: 2.0842 sec
0.1071 0.0835 0.0645 0.0536 0.0492 0.0473 0.0448 0.0430 0.0419 0.0411 0.0404 0.0398 0.0393 0.0391 0.0389 0.0388 

[TRAIN] Epoch[1](1927/114412); Loss: 0.073387; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.1474 0.1130 0.0904 0.0801 0.0725 0.0695 0.0666 0.0640 0.0623 0.0608 0.0595 0.0588 0.0581 0.0575 0.0570 0.0567 

[TRAIN] Epoch[1](1928/114412); Loss: 0.061250; Backpropagation: 0.2930 sec; Batch: 2.0875 sec
0.1227 0.1054 0.0920 0.0736 0.0622 0.0567 0.0537 0.0505 0.0485 0.0472 0.0460 0.0453 0.0447 0.0442 0.0437 0.0436 

[TRAIN] Epoch[1](1929/114412); Loss: 0.064385; Backpropagation: 0.2932 sec; Batch: 2.1092 sec
0.1204 0.0973 0.0806 0.0719 0.0642 0.0616 0.0588 0.0566 0.0552 0.0539 0.0532 0.0522 0.0516 0.0513 0.0509 0.0505 

[TRAIN] Epoch[1](1930/114412); Loss: 0.055322; Backpropagation: 0.2930 sec; Batch: 2.1253 sec
0.1113 0.0912 0.0770 0.0669 0.0584 0.0535 0.0485 0.0458 0.0441 0.0428 0.0420 0.0415 0.0410 0.0406 0.0404 0.0403 

[TRAIN] Epoch[1](1931/114412); Loss: 0.072321; Backpropagation: 0.2930 sec; Batch: 2.0824 sec
0.1248 0.1097 0.0932 0.0832 0.0748 0.0704 0.0672 0.0643 0.0625 0.0609 0.0596 0.0587 0.0581 0.0573 0.0566 0.0561 

[TRAIN] Epoch[1](1932/114412); Loss: 0.077273; Backpropagation: 0.2913 sec; Batch: 2.1158 sec
0.1443 0.1316 0.1067 0.0912 0.0795 0.0730 0.0671 0.0651 0.0635 0.0622 0.0612 0.0600 0.0590 0.0581 0.0573 0.0567 

[TRAIN] Epoch[1](1933/114412); Loss: 0.086934; Backpropagation: 0.2913 sec; Batch: 2.0848 sec
0.1668 0.1460 0.1167 0.1004 0.0884 0.0821 0.0765 0.0740 0.0721 0.0700 0.0684 0.0674 0.0665 0.0658 0.0652 0.0647 

[TRAIN] Epoch[1](1934/114412); Loss: 0.061769; Backpropagation: 0.2931 sec; Batch: 2.0976 sec
0.1096 0.0975 0.0827 0.0740 0.0653 0.0616 0.0583 0.0547 0.0522 0.0506 0.0493 0.0481 0.0471 0.0463 0.0457 0.0452 

[TRAIN] Epoch[1](1935/114412); Loss: 0.094280; Backpropagation: 0.2930 sec; Batch: 2.0821 sec
0.1715 0.1594 0.1380 0.1230 0.1055 0.0974 0.0847 0.0811 0.0752 0.0724 0.0698 0.0681 0.0668 0.0657 0.0653 0.0645 

[TRAIN] Epoch[1](1936/114412); Loss: 0.077514; Backpropagation: 0.2912 sec; Batch: 2.2942 sec
0.1262 0.1174 0.0940 0.0875 0.0807 0.0761 0.0731 0.0700 0.0680 0.0666 0.0652 0.0645 0.0638 0.0630 0.0623 0.0618 

[TRAIN] Epoch[1](1937/114412); Loss: 0.097014; Backpropagation: 0.2912 sec; Batch: 2.1120 sec
0.1597 0.1468 0.1259 0.1135 0.1031 0.0959 0.0903 0.0875 0.0842 0.0823 0.0802 0.0785 0.0773 0.0764 0.0755 0.0750 

[TRAIN] Epoch[1](1938/114412); Loss: 0.068201; Backpropagation: 0.2911 sec; Batch: 2.1164 sec
0.1125 0.1034 0.0921 0.0791 0.0714 0.0665 0.0627 0.0607 0.0587 0.0571 0.0561 0.0553 0.0546 0.0541 0.0536 0.0533 

[TRAIN] Epoch[1](1939/114412); Loss: 0.076270; Backpropagation: 0.2911 sec; Batch: 2.1141 sec
0.1136 0.1008 0.0917 0.0833 0.0794 0.0763 0.0732 0.0711 0.0695 0.0682 0.0669 0.0662 0.0658 0.0653 0.0647 0.0643 

[TRAIN] Epoch[1](1940/114412); Loss: 0.070795; Backpropagation: 0.2913 sec; Batch: 2.1377 sec
0.1124 0.0981 0.0871 0.0790 0.0731 0.0690 0.0664 0.0649 0.0632 0.0621 0.0610 0.0603 0.0597 0.0593 0.0588 0.0584 

[TRAIN] Epoch[1](1941/114412); Loss: 0.055566; Backpropagation: 0.2931 sec; Batch: 2.1193 sec
0.1008 0.0965 0.0807 0.0716 0.0616 0.0571 0.0519 0.0474 0.0455 0.0432 0.0413 0.0398 0.0388 0.0381 0.0376 0.0371 

[TRAIN] Epoch[1](1942/114412); Loss: 0.036743; Backpropagation: 0.2911 sec; Batch: 2.1149 sec
0.0938 0.0849 0.0604 0.0407 0.0358 0.0309 0.0297 0.0277 0.0257 0.0243 0.0234 0.0226 0.0223 0.0220 0.0218 0.0218 

[TRAIN] Epoch[1](1943/114412); Loss: 0.073903; Backpropagation: 0.2909 sec; Batch: 2.1309 sec
0.1331 0.1192 0.1017 0.0861 0.0770 0.0709 0.0665 0.0642 0.0626 0.0601 0.0589 0.0579 0.0570 0.0562 0.0557 0.0553 

[TRAIN] Epoch[1](1944/114412); Loss: 0.091063; Backpropagation: 0.2934 sec; Batch: 2.1198 sec
0.1455 0.1274 0.1121 0.1002 0.0920 0.0871 0.0844 0.0815 0.0800 0.0792 0.0776 0.0775 0.0780 0.0776 0.0785 0.0786 

[TRAIN] Epoch[1](1945/114412); Loss: 0.066677; Backpropagation: 0.2930 sec; Batch: 2.1158 sec
0.1113 0.0980 0.0864 0.0756 0.0680 0.0644 0.0619 0.0593 0.0578 0.0565 0.0557 0.0551 0.0548 0.0543 0.0540 0.0537 

[TRAIN] Epoch[1](1946/114412); Loss: 0.059772; Backpropagation: 0.2925 sec; Batch: 2.1199 sec
0.1078 0.0940 0.0759 0.0672 0.0601 0.0560 0.0535 0.0522 0.0509 0.0497 0.0491 0.0486 0.0482 0.0479 0.0477 0.0476 

[TRAIN] Epoch[1](1947/114412); Loss: 0.059387; Backpropagation: 0.2914 sec; Batch: 2.1218 sec
0.1038 0.0990 0.0812 0.0676 0.0609 0.0583 0.0547 0.0518 0.0496 0.0482 0.0475 0.0464 0.0458 0.0454 0.0450 0.0450 

[TRAIN] Epoch[1](1948/114412); Loss: 0.081837; Backpropagation: 0.2931 sec; Batch: 2.1192 sec
0.1467 0.1279 0.1117 0.0945 0.0850 0.0779 0.0731 0.0703 0.0682 0.0670 0.0657 0.0648 0.0646 0.0642 0.0639 0.0639 

[TRAIN] Epoch[1](1949/114412); Loss: 0.074212; Backpropagation: 0.2927 sec; Batch: 2.0978 sec
0.1396 0.1214 0.0992 0.0866 0.0780 0.0724 0.0687 0.0651 0.0620 0.0599 0.0582 0.0569 0.0558 0.0551 0.0546 0.0538 

[TRAIN] Epoch[1](1950/114412); Loss: 0.065305; Backpropagation: 0.2909 sec; Batch: 2.1187 sec
0.1207 0.1012 0.0809 0.0723 0.0668 0.0644 0.0606 0.0588 0.0570 0.0545 0.0531 0.0518 0.0513 0.0511 0.0503 0.0500 

[TRAIN] Epoch[1](1951/114412); Loss: 0.056914; Backpropagation: 0.2929 sec; Batch: 2.1196 sec
0.0893 0.0838 0.0662 0.0607 0.0569 0.0550 0.0534 0.0516 0.0509 0.0500 0.0494 0.0491 0.0488 0.0487 0.0485 0.0483 

[TRAIN] Epoch[1](1952/114412); Loss: 0.088394; Backpropagation: 0.2931 sec; Batch: 2.1215 sec
0.1557 0.1459 0.1203 0.1048 0.0946 0.0873 0.0813 0.0785 0.0749 0.0712 0.0690 0.0675 0.0665 0.0661 0.0655 0.0652 

[TRAIN] Epoch[1](1953/114412); Loss: 0.075580; Backpropagation: 0.2908 sec; Batch: 2.1320 sec
0.1389 0.1248 0.1063 0.0935 0.0825 0.0744 0.0685 0.0646 0.0615 0.0594 0.0581 0.0570 0.0560 0.0551 0.0545 0.0542 

[TRAIN] Epoch[1](1954/114412); Loss: 0.069291; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1397 0.1264 0.1005 0.0871 0.0777 0.0649 0.0597 0.0557 0.0534 0.0516 0.0507 0.0495 0.0488 0.0482 0.0475 0.0471 

[TRAIN] Epoch[1](1955/114412); Loss: 0.050159; Backpropagation: 0.2932 sec; Batch: 2.1191 sec
0.0921 0.0798 0.0642 0.0570 0.0526 0.0513 0.0465 0.0437 0.0420 0.0407 0.0398 0.0391 0.0386 0.0384 0.0383 0.0385 

[TRAIN] Epoch[1](1956/114412); Loss: 0.068777; Backpropagation: 0.2906 sec; Batch: 2.0774 sec
0.1110 0.0989 0.0878 0.0762 0.0709 0.0668 0.0639 0.0621 0.0603 0.0594 0.0588 0.0579 0.0573 0.0568 0.0563 0.0560 

[TRAIN] Epoch[1](1957/114412); Loss: 0.078537; Backpropagation: 0.2906 sec; Batch: 2.1189 sec
0.1411 0.1301 0.1069 0.0881 0.0790 0.0739 0.0699 0.0684 0.0664 0.0643 0.0632 0.0621 0.0616 0.0610 0.0604 0.0601 

[TRAIN] Epoch[1](1958/114412); Loss: 0.065351; Backpropagation: 0.2912 sec; Batch: 2.0826 sec
0.1313 0.1048 0.0883 0.0729 0.0664 0.0617 0.0585 0.0559 0.0542 0.0529 0.0512 0.0505 0.0498 0.0493 0.0492 0.0488 

[TRAIN] Epoch[1](1959/114412); Loss: 0.079080; Backpropagation: 0.2909 sec; Batch: 2.1343 sec
0.1503 0.1274 0.1016 0.0854 0.0807 0.0766 0.0713 0.0689 0.0660 0.0643 0.0636 0.0630 0.0623 0.0617 0.0613 0.0610 

[TRAIN] Epoch[1](1960/114412); Loss: 0.068935; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1180 0.1040 0.0824 0.0722 0.0692 0.0653 0.0636 0.0617 0.0604 0.0596 0.0588 0.0583 0.0578 0.0574 0.0572 0.0570 

[TRAIN] Epoch[1](1961/114412); Loss: 0.075493; Backpropagation: 0.2916 sec; Batch: 2.1175 sec
0.1268 0.1135 0.0961 0.0850 0.0781 0.0735 0.0691 0.0675 0.0653 0.0639 0.0631 0.0624 0.0616 0.0612 0.0607 0.0603 

[TRAIN] Epoch[1](1962/114412); Loss: 0.078461; Backpropagation: 0.2910 sec; Batch: 2.1197 sec
0.1472 0.1326 0.1070 0.0932 0.0791 0.0730 0.0685 0.0666 0.0646 0.0630 0.0618 0.0609 0.0602 0.0597 0.0593 0.0587 

[TRAIN] Epoch[1](1963/114412); Loss: 0.097049; Backpropagation: 0.2905 sec; Batch: 2.1008 sec
0.1723 0.1580 0.1316 0.1126 0.0963 0.0913 0.0852 0.0831 0.0814 0.0805 0.0788 0.0780 0.0770 0.0761 0.0757 0.0750 

[TRAIN] Epoch[1](1964/114412); Loss: 0.041426; Backpropagation: 0.2908 sec; Batch: 2.0776 sec
0.0950 0.0688 0.0604 0.0533 0.0435 0.0388 0.0356 0.0333 0.0315 0.0306 0.0297 0.0291 0.0287 0.0284 0.0281 0.0280 

[TRAIN] Epoch[1](1965/114412); Loss: 0.057810; Backpropagation: 0.2930 sec; Batch: 2.0840 sec
0.1058 0.0918 0.0735 0.0651 0.0594 0.0554 0.0526 0.0500 0.0488 0.0480 0.0473 0.0465 0.0459 0.0453 0.0450 0.0447 

[TRAIN] Epoch[1](1966/114412); Loss: 0.065958; Backpropagation: 0.2908 sec; Batch: 2.1159 sec
0.1043 0.0970 0.0804 0.0717 0.0700 0.0657 0.0625 0.0600 0.0581 0.0570 0.0563 0.0555 0.0549 0.0543 0.0539 0.0538 

[TRAIN] Epoch[1](1967/114412); Loss: 0.059249; Backpropagation: 0.2904 sec; Batch: 2.0848 sec
0.1248 0.1007 0.0848 0.0682 0.0598 0.0554 0.0513 0.0489 0.0475 0.0458 0.0450 0.0441 0.0436 0.0432 0.0427 0.0424 

[TRAIN] Epoch[1](1968/114412); Loss: 0.067412; Backpropagation: 0.2909 sec; Batch: 2.0786 sec
0.1196 0.1019 0.0844 0.0739 0.0686 0.0666 0.0615 0.0592 0.0579 0.0565 0.0558 0.0553 0.0547 0.0545 0.0542 0.0540 

[TRAIN] Epoch[1](1969/114412); Loss: 0.065551; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1385 0.1238 0.0955 0.0735 0.0651 0.0605 0.0561 0.0533 0.0514 0.0499 0.0487 0.0478 0.0469 0.0463 0.0459 0.0455 

[TRAIN] Epoch[1](1970/114412); Loss: 0.065795; Backpropagation: 0.2914 sec; Batch: 2.1216 sec
0.1101 0.0940 0.0831 0.0756 0.0679 0.0643 0.0614 0.0587 0.0571 0.0560 0.0554 0.0546 0.0540 0.0538 0.0535 0.0532 

[TRAIN] Epoch[1](1971/114412); Loss: 0.050627; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.0951 0.0812 0.0625 0.0534 0.0501 0.0474 0.0460 0.0446 0.0433 0.0425 0.0419 0.0412 0.0407 0.0403 0.0401 0.0399 

[TRAIN] Epoch[1](1972/114412); Loss: 0.055316; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.0911 0.0867 0.0745 0.0627 0.0577 0.0546 0.0520 0.0488 0.0476 0.0463 0.0450 0.0444 0.0441 0.0435 0.0432 0.0430 

[TRAIN] Epoch[1](1973/114412); Loss: 0.088748; Backpropagation: 0.2909 sec; Batch: 2.0777 sec
0.1622 0.1338 0.1123 0.0995 0.0901 0.0849 0.0806 0.0775 0.0756 0.0744 0.0733 0.0722 0.0715 0.0711 0.0707 0.0705 

[TRAIN] Epoch[1](1974/114412); Loss: 0.065503; Backpropagation: 0.2907 sec; Batch: 2.1235 sec
0.1055 0.0990 0.0894 0.0782 0.0711 0.0667 0.0616 0.0581 0.0560 0.0544 0.0531 0.0523 0.0515 0.0509 0.0503 0.0499 

[TRAIN] Epoch[1](1975/114412); Loss: 0.086916; Backpropagation: 0.2913 sec; Batch: 2.1159 sec
0.1446 0.1394 0.1180 0.1045 0.0831 0.0834 0.0809 0.0773 0.0749 0.0727 0.0715 0.0701 0.0689 0.0680 0.0670 0.0663 

[TRAIN] Epoch[1](1976/114412); Loss: 0.063515; Backpropagation: 0.2908 sec; Batch: 2.1190 sec
0.1214 0.1021 0.0837 0.0719 0.0653 0.0599 0.0572 0.0549 0.0530 0.0517 0.0505 0.0500 0.0493 0.0489 0.0485 0.0480 

[TRAIN] Epoch[1](1977/114412); Loss: 0.042977; Backpropagation: 0.2913 sec; Batch: 2.1158 sec
0.0942 0.0809 0.0571 0.0493 0.0438 0.0407 0.0385 0.0354 0.0335 0.0321 0.0314 0.0308 0.0304 0.0301 0.0298 0.0296 

[TRAIN] Epoch[1](1978/114412); Loss: 0.050672; Backpropagation: 0.2909 sec; Batch: 2.1200 sec
0.0962 0.0766 0.0697 0.0575 0.0505 0.0481 0.0459 0.0441 0.0427 0.0417 0.0409 0.0402 0.0397 0.0393 0.0390 0.0387 

[TRAIN] Epoch[1](1979/114412); Loss: 0.085334; Backpropagation: 0.2907 sec; Batch: 2.1293 sec
0.1443 0.1297 0.0974 0.0916 0.0851 0.0813 0.0789 0.0766 0.0749 0.0738 0.0731 0.0725 0.0721 0.0717 0.0713 0.0710 

[TRAIN] Epoch[1](1980/114412); Loss: 0.094859; Backpropagation: 0.2913 sec; Batch: 2.1054 sec
0.1481 0.1260 0.1121 0.1037 0.0971 0.0930 0.0901 0.0874 0.0859 0.0844 0.0836 0.0826 0.0818 0.0812 0.0807 0.0802 

[TRAIN] Epoch[1](1981/114412); Loss: 0.064676; Backpropagation: 0.2914 sec; Batch: 2.1215 sec
0.1133 0.1005 0.0841 0.0727 0.0666 0.0611 0.0589 0.0574 0.0557 0.0544 0.0532 0.0525 0.0518 0.0513 0.0509 0.0506 

[TRAIN] Epoch[1](1982/114412); Loss: 0.088981; Backpropagation: 0.2902 sec; Batch: 2.0809 sec
0.1478 0.1256 0.1090 0.0990 0.0927 0.0881 0.0841 0.0819 0.0795 0.0774 0.0754 0.0745 0.0735 0.0724 0.0717 0.0712 

[TRAIN] Epoch[1](1983/114412); Loss: 0.087424; Backpropagation: 0.2906 sec; Batch: 2.1136 sec
0.1352 0.1207 0.1057 0.0972 0.0919 0.0873 0.0837 0.0810 0.0785 0.0772 0.0757 0.0745 0.0736 0.0728 0.0722 0.0716 

[TRAIN] Epoch[1](1984/114412); Loss: 0.070412; Backpropagation: 0.2915 sec; Batch: 2.0786 sec
0.1168 0.1018 0.0878 0.0805 0.0746 0.0707 0.0671 0.0646 0.0625 0.0609 0.0594 0.0580 0.0568 0.0559 0.0551 0.0543 

[TRAIN] Epoch[1](1985/114412); Loss: 0.106709; Backpropagation: 0.2914 sec; Batch: 2.1174 sec
0.1328 0.1339 0.1245 0.1188 0.1155 0.1113 0.1070 0.1033 0.1015 0.0987 0.0968 0.0950 0.0938 0.0927 0.0915 0.0903 

[TRAIN] Epoch[1](1986/114412); Loss: 0.080213; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1462 0.1263 0.1041 0.0931 0.0841 0.0796 0.0749 0.0725 0.0692 0.0676 0.0646 0.0634 0.0613 0.0602 0.0585 0.0577 

[TRAIN] Epoch[1](1987/114412); Loss: 0.125510; Backpropagation: 0.2910 sec; Batch: 2.1210 sec
0.1671 0.1606 0.1413 0.1352 0.1288 0.1265 0.1231 0.1210 0.1187 0.1171 0.1147 0.1134 0.1119 0.1108 0.1093 0.1086 

[TRAIN] Epoch[1](1988/114412); Loss: 0.083364; Backpropagation: 0.2907 sec; Batch: 2.0854 sec
0.1288 0.1212 0.0999 0.0930 0.0880 0.0847 0.0812 0.0789 0.0763 0.0742 0.0717 0.0703 0.0685 0.0670 0.0656 0.0645 

[TRAIN] Epoch[1](1989/114412); Loss: 0.166151; Backpropagation: 0.2906 sec; Batch: 2.1241 sec
0.1912 0.1954 0.1883 0.1810 0.1755 0.1710 0.1658 0.1628 0.1604 0.1580 0.1557 0.1540 0.1524 0.1505 0.1489 0.1475 

[TRAIN] Epoch[1](1990/114412); Loss: 0.068081; Backpropagation: 0.2906 sec; Batch: 2.0781 sec
0.1019 0.0979 0.0840 0.0780 0.0732 0.0690 0.0656 0.0634 0.0613 0.0598 0.0584 0.0572 0.0561 0.0552 0.0545 0.0538 

[TRAIN] Epoch[1](1991/114412); Loss: 0.102891; Backpropagation: 0.2915 sec; Batch: 2.0790 sec
0.1641 0.1547 0.1376 0.1258 0.1132 0.1074 0.1007 0.0963 0.0905 0.0875 0.0844 0.0816 0.0786 0.0765 0.0746 0.0729 

[TRAIN] Epoch[1](1992/114412); Loss: 0.074690; Backpropagation: 0.2929 sec; Batch: 2.1184 sec
0.1185 0.1084 0.0877 0.0817 0.0768 0.0739 0.0710 0.0690 0.0671 0.0657 0.0646 0.0636 0.0629 0.0621 0.0613 0.0608 

[TRAIN] Epoch[1](1993/114412); Loss: 0.087720; Backpropagation: 0.2913 sec; Batch: 2.1163 sec
0.1392 0.1257 0.1156 0.1022 0.0936 0.0897 0.0846 0.0804 0.0779 0.0753 0.0731 0.0715 0.0703 0.0691 0.0681 0.0674 

[TRAIN] Epoch[1](1994/114412); Loss: 0.112941; Backpropagation: 0.2913 sec; Batch: 2.1170 sec
0.1708 0.1616 0.1481 0.1365 0.1273 0.1205 0.1137 0.1081 0.1026 0.0979 0.0936 0.0901 0.0872 0.0848 0.0829 0.0812 

[TRAIN] Epoch[1](1995/114412); Loss: 0.101627; Backpropagation: 0.2951 sec; Batch: 2.1211 sec
0.1598 0.1395 0.1284 0.1160 0.1081 0.1036 0.0981 0.0942 0.0909 0.0880 0.0863 0.0850 0.0835 0.0824 0.0815 0.0807 

[TRAIN] Epoch[1](1996/114412); Loss: 0.095752; Backpropagation: 0.2928 sec; Batch: 2.0792 sec
0.1415 0.1345 0.1211 0.1119 0.1035 0.0995 0.0946 0.0903 0.0867 0.0840 0.0814 0.0795 0.0775 0.0762 0.0752 0.0746 

[TRAIN] Epoch[1](1997/114412); Loss: 0.092962; Backpropagation: 0.2987 sec; Batch: 2.1375 sec
0.1430 0.1354 0.1202 0.1084 0.1005 0.0944 0.0901 0.0862 0.0823 0.0800 0.0779 0.0761 0.0747 0.0735 0.0726 0.0720 

[TRAIN] Epoch[1](1998/114412); Loss: 0.124974; Backpropagation: 0.2959 sec; Batch: 2.1250 sec
0.1846 0.1753 0.1586 0.1416 0.1305 0.1233 0.1187 0.1158 0.1140 0.1120 0.1088 0.1059 0.1045 0.1028 0.1022 0.1010 

[TRAIN] Epoch[1](1999/114412); Loss: 0.102295; Backpropagation: 0.2951 sec; Batch: 2.0824 sec
0.1529 0.1433 0.1306 0.1189 0.1106 0.1052 0.0983 0.0940 0.0908 0.0888 0.0879 0.0863 0.0843 0.0830 0.0814 0.0803 

[TRAIN] Epoch[1](2000/114412); Loss: 0.078585; Backpropagation: 0.2955 sec; Batch: 2.1237 sec
0.1317 0.1256 0.1126 0.1008 0.0894 0.0791 0.0715 0.0670 0.0641 0.0624 0.0616 0.0605 0.0588 0.0580 0.0575 0.0569 

[TRAIN] Epoch[1](2001/114412); Loss: 0.078115; Backpropagation: 0.2957 sec; Batch: 2.1385 sec
0.1278 0.1225 0.1051 0.0929 0.0824 0.0766 0.0726 0.0695 0.0679 0.0657 0.0640 0.0626 0.0617 0.0604 0.0595 0.0586 

[TRAIN] Epoch[1](2002/114412); Loss: 0.081343; Backpropagation: 0.3080 sec; Batch: 2.1335 sec
0.1253 0.1199 0.1072 0.0986 0.0869 0.0809 0.0781 0.0733 0.0711 0.0705 0.0685 0.0660 0.0651 0.0642 0.0630 0.0628 

[TRAIN] Epoch[1](2003/114412); Loss: 0.068196; Backpropagation: 0.2976 sec; Batch: 2.1215 sec
0.1224 0.1092 0.0867 0.0732 0.0684 0.0642 0.0612 0.0591 0.0580 0.0572 0.0564 0.0556 0.0552 0.0551 0.0548 0.0544 

[TRAIN] Epoch[1](2004/114412); Loss: 0.099586; Backpropagation: 0.2946 sec; Batch: 2.0979 sec
0.1468 0.1405 0.1218 0.1140 0.1044 0.1000 0.0972 0.0938 0.0909 0.0880 0.0863 0.0845 0.0831 0.0819 0.0808 0.0793 

[TRAIN] Epoch[1](2005/114412); Loss: 0.083165; Backpropagation: 0.2954 sec; Batch: 2.1038 sec
0.1665 0.1488 0.1218 0.1067 0.0887 0.0780 0.0717 0.0678 0.0655 0.0634 0.0624 0.0605 0.0588 0.0577 0.0567 0.0558 

[TRAIN] Epoch[1](2006/114412); Loss: 0.094910; Backpropagation: 0.2956 sec; Batch: 2.1202 sec
0.1527 0.1422 0.1248 0.1116 0.1024 0.0962 0.0904 0.0855 0.0817 0.0799 0.0786 0.0768 0.0758 0.0739 0.0733 0.0730 

[TRAIN] Epoch[1](2007/114412); Loss: 0.075265; Backpropagation: 0.2950 sec; Batch: 2.1212 sec
0.1414 0.1167 0.0959 0.0850 0.0757 0.0717 0.0683 0.0647 0.0628 0.0628 0.0620 0.0600 0.0596 0.0594 0.0592 0.0592 

[TRAIN] Epoch[1](2008/114412); Loss: 0.066193; Backpropagation: 0.2957 sec; Batch: 2.1193 sec
0.1007 0.0998 0.0842 0.0706 0.0664 0.0647 0.0604 0.0598 0.0595 0.0570 0.0567 0.0566 0.0559 0.0555 0.0557 0.0555 

[TRAIN] Epoch[1](2009/114412); Loss: 0.101982; Backpropagation: 0.2956 sec; Batch: 2.1249 sec
0.1657 0.1555 0.1315 0.1120 0.1044 0.1011 0.0955 0.0928 0.0908 0.0878 0.0852 0.0838 0.0825 0.0817 0.0810 0.0802 

[TRAIN] Epoch[1](2010/114412); Loss: 0.089848; Backpropagation: 0.2959 sec; Batch: 2.1351 sec
0.1348 0.1273 0.1164 0.1035 0.0969 0.0944 0.0894 0.0849 0.0809 0.0770 0.0761 0.0744 0.0719 0.0706 0.0697 0.0694 

[TRAIN] Epoch[1](2011/114412); Loss: 0.087355; Backpropagation: 0.2947 sec; Batch: 2.1074 sec
0.1411 0.1230 0.1094 0.0934 0.0867 0.0840 0.0789 0.0777 0.0787 0.0766 0.0758 0.0760 0.0751 0.0743 0.0737 0.0734 

[TRAIN] Epoch[1](2012/114412); Loss: 0.074854; Backpropagation: 0.2955 sec; Batch: 2.1255 sec
0.1507 0.1229 0.1076 0.0920 0.0801 0.0724 0.0663 0.0635 0.0599 0.0575 0.0559 0.0548 0.0534 0.0530 0.0535 0.0541 

[TRAIN] Epoch[1](2013/114412); Loss: 0.087014; Backpropagation: 0.2953 sec; Batch: 2.1218 sec
0.1768 0.1658 0.1319 0.1050 0.0926 0.0842 0.0773 0.0708 0.0685 0.0640 0.0619 0.0613 0.0603 0.0580 0.0570 0.0568 

[TRAIN] Epoch[1](2014/114412); Loss: 0.082612; Backpropagation: 0.2952 sec; Batch: 2.0835 sec
0.1518 0.1338 0.1137 0.0913 0.0803 0.0748 0.0743 0.0719 0.0684 0.0682 0.0674 0.0655 0.0656 0.0655 0.0646 0.0646 

[TRAIN] Epoch[1](2015/114412); Loss: 0.077227; Backpropagation: 0.2954 sec; Batch: 2.1231 sec
0.1603 0.1375 0.1144 0.0950 0.0800 0.0715 0.0653 0.0621 0.0603 0.0584 0.0567 0.0561 0.0553 0.0544 0.0541 0.0540 

[TRAIN] Epoch[1](2016/114412); Loss: 0.074109; Backpropagation: 0.2958 sec; Batch: 2.1342 sec
0.1517 0.1251 0.1057 0.0812 0.0699 0.0673 0.0621 0.0600 0.0598 0.0592 0.0583 0.0574 0.0576 0.0570 0.0567 0.0568 

[TRAIN] Epoch[1](2017/114412); Loss: 0.088825; Backpropagation: 0.2956 sec; Batch: 2.1264 sec
0.1405 0.1313 0.1139 0.1003 0.0913 0.0851 0.0809 0.0793 0.0773 0.0757 0.0748 0.0743 0.0743 0.0742 0.0743 0.0736 

[TRAIN] Epoch[1](2018/114412); Loss: 0.076317; Backpropagation: 0.2959 sec; Batch: 2.1058 sec
0.1326 0.1125 0.1054 0.0880 0.0758 0.0739 0.0710 0.0673 0.0655 0.0644 0.0628 0.0616 0.0609 0.0603 0.0597 0.0593 

[TRAIN] Epoch[1](2019/114412); Loss: 0.083115; Backpropagation: 0.2957 sec; Batch: 2.0839 sec
0.1613 0.1465 0.1087 0.0891 0.0856 0.0791 0.0743 0.0717 0.0684 0.0664 0.0653 0.0643 0.0630 0.0625 0.0619 0.0615 

[TRAIN] Epoch[1](2020/114412); Loss: 0.076458; Backpropagation: 0.2955 sec; Batch: 2.1420 sec
0.1682 0.1370 0.1121 0.0851 0.0742 0.0697 0.0645 0.0629 0.0606 0.0587 0.0576 0.0561 0.0551 0.0545 0.0537 0.0534 

[TRAIN] Epoch[1](2021/114412); Loss: 0.112395; Backpropagation: 0.2982 sec; Batch: 2.1274 sec
0.2223 0.1967 0.1799 0.1390 0.1079 0.1034 0.0942 0.0917 0.0876 0.0856 0.0843 0.0827 0.0819 0.0814 0.0801 0.0796 

[TRAIN] Epoch[1](2022/114412); Loss: 0.069145; Backpropagation: 0.2980 sec; Batch: 2.1211 sec
0.1510 0.1167 0.1003 0.0758 0.0659 0.0624 0.0583 0.0563 0.0565 0.0545 0.0531 0.0524 0.0513 0.0507 0.0508 0.0503 

[TRAIN] Epoch[1](2023/114412); Loss: 0.074897; Backpropagation: 0.2958 sec; Batch: 2.1226 sec
0.1257 0.1013 0.0974 0.0820 0.0766 0.0737 0.0692 0.0668 0.0662 0.0641 0.0632 0.0632 0.0626 0.0624 0.0621 0.0618 

[TRAIN] Epoch[1](2024/114412); Loss: 0.088459; Backpropagation: 0.2956 sec; Batch: 2.1260 sec
0.1599 0.1399 0.1195 0.0999 0.0894 0.0840 0.0806 0.0774 0.0749 0.0729 0.0715 0.0705 0.0696 0.0691 0.0683 0.0679 

[TRAIN] Epoch[1](2025/114412); Loss: 0.060808; Backpropagation: 0.2957 sec; Batch: 2.1209 sec
0.1204 0.0976 0.0803 0.0650 0.0590 0.0570 0.0547 0.0527 0.0516 0.0502 0.0491 0.0483 0.0475 0.0470 0.0465 0.0461 

[TRAIN] Epoch[1](2026/114412); Loss: 0.088360; Backpropagation: 0.2982 sec; Batch: 2.1246 sec
0.1490 0.1283 0.1170 0.0985 0.0904 0.0876 0.0812 0.0794 0.0777 0.0749 0.0735 0.0727 0.0718 0.0713 0.0705 0.0701 

[TRAIN] Epoch[1](2027/114412); Loss: 0.073901; Backpropagation: 0.2955 sec; Batch: 2.1218 sec
0.1493 0.1293 0.1078 0.0881 0.0776 0.0693 0.0632 0.0609 0.0588 0.0568 0.0556 0.0547 0.0537 0.0530 0.0524 0.0518 

[TRAIN] Epoch[1](2028/114412); Loss: 0.048713; Backpropagation: 0.2958 sec; Batch: 2.1227 sec
0.1072 0.0729 0.0678 0.0537 0.0484 0.0455 0.0429 0.0410 0.0400 0.0387 0.0379 0.0374 0.0369 0.0366 0.0364 0.0361 

[TRAIN] Epoch[1](2029/114412); Loss: 0.060217; Backpropagation: 0.2954 sec; Batch: 2.1244 sec
0.1086 0.0930 0.0803 0.0680 0.0609 0.0579 0.0552 0.0528 0.0512 0.0500 0.0490 0.0484 0.0477 0.0471 0.0468 0.0465 

[TRAIN] Epoch[1](2030/114412); Loss: 0.105630; Backpropagation: 0.2956 sec; Batch: 2.1260 sec
0.1554 0.1454 0.1324 0.1208 0.1117 0.1081 0.1031 0.0990 0.0959 0.0931 0.0913 0.0897 0.0881 0.0862 0.0854 0.0844 

[TRAIN] Epoch[1](2031/114412); Loss: 0.102135; Backpropagation: 0.2953 sec; Batch: 2.0828 sec
0.1835 0.1512 0.1320 0.1182 0.1077 0.1006 0.0942 0.0910 0.0878 0.0853 0.0836 0.0817 0.0807 0.0797 0.0788 0.0783 

[TRAIN] Epoch[1](2032/114412); Loss: 0.081586; Backpropagation: 0.2969 sec; Batch: 2.1296 sec
0.1699 0.1602 0.1313 0.1184 0.0931 0.0843 0.0701 0.0634 0.0598 0.0569 0.0545 0.0527 0.0504 0.0487 0.0467 0.0451 

[TRAIN] Epoch[1](2033/114412); Loss: 0.097914; Backpropagation: 0.2956 sec; Batch: 2.1238 sec
0.1596 0.1344 0.1204 0.1103 0.1016 0.0970 0.0926 0.0901 0.0875 0.0855 0.0839 0.0827 0.0816 0.0807 0.0798 0.0791 

[TRAIN] Epoch[1](2034/114412); Loss: 0.074673; Backpropagation: 0.2956 sec; Batch: 2.1220 sec
0.1414 0.1123 0.0952 0.0840 0.0769 0.0714 0.0685 0.0663 0.0638 0.0624 0.0609 0.0597 0.0588 0.0582 0.0576 0.0572 

[TRAIN] Epoch[1](2035/114412); Loss: 0.084228; Backpropagation: 0.2957 sec; Batch: 2.1206 sec
0.1754 0.1370 0.1159 0.1008 0.0859 0.0813 0.0754 0.0720 0.0689 0.0669 0.0644 0.0632 0.0615 0.0607 0.0597 0.0585 

[TRAIN] Epoch[1](2036/114412); Loss: 0.087234; Backpropagation: 0.2959 sec; Batch: 2.1228 sec
0.1382 0.1223 0.1111 0.1016 0.0941 0.0894 0.0850 0.0820 0.0788 0.0761 0.0740 0.0718 0.0701 0.0686 0.0671 0.0656 

[TRAIN] Epoch[1](2037/114412); Loss: 0.063055; Backpropagation: 0.2991 sec; Batch: 2.0930 sec
0.1209 0.1104 0.0879 0.0778 0.0630 0.0596 0.0566 0.0548 0.0526 0.0503 0.0481 0.0473 0.0461 0.0449 0.0445 0.0440 

[TRAIN] Epoch[1](2038/114412); Loss: 0.054076; Backpropagation: 0.2959 sec; Batch: 2.1172 sec
0.1120 0.0828 0.0707 0.0598 0.0560 0.0503 0.0478 0.0460 0.0448 0.0442 0.0434 0.0425 0.0419 0.0414 0.0409 0.0405 

[TRAIN] Epoch[1](2039/114412); Loss: 0.082508; Backpropagation: 0.2957 sec; Batch: 2.1163 sec
0.1693 0.1264 0.1082 0.0931 0.0846 0.0791 0.0747 0.0711 0.0686 0.0669 0.0653 0.0642 0.0632 0.0624 0.0617 0.0613 

[TRAIN] Epoch[1](2040/114412); Loss: 0.093147; Backpropagation: 0.2959 sec; Batch: 2.0842 sec
0.1662 0.1576 0.1315 0.1209 0.1012 0.0938 0.0849 0.0803 0.0760 0.0735 0.0713 0.0693 0.0675 0.0664 0.0655 0.0646 

[TRAIN] Epoch[1](2041/114412); Loss: 0.127003; Backpropagation: 0.2949 sec; Batch: 2.1569 sec
0.2017 0.1717 0.1544 0.1393 0.1281 0.1232 0.1196 0.1165 0.1140 0.1128 0.1112 0.1098 0.1087 0.1079 0.1070 0.1063 

[TRAIN] Epoch[1](2042/114412); Loss: 0.105470; Backpropagation: 0.2953 sec; Batch: 2.1224 sec
0.1818 0.1551 0.1356 0.1257 0.1120 0.1063 0.0994 0.0964 0.0922 0.0895 0.0865 0.0845 0.0825 0.0810 0.0800 0.0790 

[TRAIN] Epoch[1](2043/114412); Loss: 0.092831; Backpropagation: 0.2955 sec; Batch: 2.1214 sec
0.1518 0.1439 0.1263 0.1218 0.1068 0.1026 0.0913 0.0885 0.0798 0.0771 0.0717 0.0699 0.0659 0.0646 0.0620 0.0610 

[TRAIN] Epoch[1](2044/114412); Loss: 0.070780; Backpropagation: 0.2952 sec; Batch: 2.1208 sec
0.1258 0.0982 0.0885 0.0787 0.0729 0.0696 0.0661 0.0642 0.0621 0.0607 0.0597 0.0586 0.0577 0.0571 0.0564 0.0561 

[TRAIN] Epoch[1](2045/114412); Loss: 0.088553; Backpropagation: 0.2956 sec; Batch: 2.1329 sec
0.1382 0.1233 0.1098 0.1013 0.0921 0.0882 0.0836 0.0817 0.0791 0.0775 0.0759 0.0748 0.0739 0.0731 0.0725 0.0720 

[TRAIN] Epoch[1](2046/114412); Loss: 0.097333; Backpropagation: 0.2951 sec; Batch: 2.1258 sec
0.1598 0.1390 0.1210 0.1116 0.1007 0.0968 0.0903 0.0891 0.0856 0.0843 0.0826 0.0818 0.0807 0.0789 0.0779 0.0772 

[TRAIN] Epoch[1](2047/114412); Loss: 0.069930; Backpropagation: 0.2955 sec; Batch: 2.1224 sec
0.1584 0.1029 0.0896 0.0787 0.0689 0.0640 0.0608 0.0588 0.0571 0.0558 0.0552 0.0547 0.0542 0.0535 0.0532 0.0530 

[TRAIN] Epoch[1](2048/114412); Loss: 0.061284; Backpropagation: 0.2949 sec; Batch: 2.1208 sec
0.1254 0.1031 0.0867 0.0802 0.0659 0.0612 0.0529 0.0510 0.0481 0.0465 0.0448 0.0440 0.0434 0.0429 0.0425 0.0421 

[TRAIN] Epoch[1](2049/114412); Loss: 0.109013; Backpropagation: 0.2958 sec; Batch: 2.1280 sec
0.1838 0.1680 0.1473 0.1380 0.1213 0.1147 0.1019 0.0975 0.0901 0.0873 0.0857 0.0844 0.0827 0.0815 0.0804 0.0796 

[TRAIN] Epoch[1](2050/114412); Loss: 0.078578; Backpropagation: 0.2950 sec; Batch: 2.1211 sec
0.1394 0.1208 0.1025 0.0899 0.0794 0.0744 0.0716 0.0685 0.0667 0.0657 0.0645 0.0636 0.0631 0.0626 0.0624 0.0621 

[TRAIN] Epoch[1](2051/114412); Loss: 0.071264; Backpropagation: 0.2957 sec; Batch: 2.1236 sec
0.1603 0.1302 0.0976 0.0869 0.0722 0.0677 0.0619 0.0587 0.0550 0.0535 0.0517 0.0506 0.0496 0.0487 0.0481 0.0474 

[TRAIN] Epoch[1](2052/114412); Loss: 0.079370; Backpropagation: 0.2956 sec; Batch: 2.1230 sec
0.1530 0.1363 0.1117 0.1004 0.0877 0.0808 0.0742 0.0702 0.0648 0.0617 0.0583 0.0566 0.0550 0.0537 0.0531 0.0525 

[TRAIN] Epoch[1](2053/114412); Loss: 0.079004; Backpropagation: 0.2955 sec; Batch: 2.1304 sec
0.1383 0.1190 0.1030 0.0925 0.0845 0.0799 0.0748 0.0711 0.0682 0.0667 0.0647 0.0623 0.0612 0.0600 0.0592 0.0586 

[TRAIN] Epoch[1](2054/114412); Loss: 0.055749; Backpropagation: 0.2982 sec; Batch: 2.1293 sec
0.1479 0.0989 0.0774 0.0650 0.0529 0.0492 0.0471 0.0435 0.0420 0.0413 0.0396 0.0384 0.0377 0.0373 0.0370 0.0367 

[TRAIN] Epoch[1](2055/114412); Loss: 0.106988; Backpropagation: 0.2955 sec; Batch: 2.1218 sec
0.2025 0.1849 0.1543 0.1457 0.1237 0.1171 0.1018 0.0959 0.0874 0.0829 0.0764 0.0733 0.0693 0.0672 0.0652 0.0642 

[TRAIN] Epoch[1](2056/114412); Loss: 0.120818; Backpropagation: 0.2958 sec; Batch: 2.1209 sec
0.2299 0.2110 0.1755 0.1621 0.1352 0.1310 0.1099 0.1062 0.0919 0.0895 0.0852 0.0831 0.0822 0.0812 0.0797 0.0793 

[TRAIN] Epoch[1](2057/114412); Loss: 0.074282; Backpropagation: 0.2953 sec; Batch: 2.1223 sec
0.1461 0.1101 0.0942 0.0803 0.0725 0.0694 0.0667 0.0645 0.0631 0.0619 0.0614 0.0607 0.0600 0.0596 0.0592 0.0588 

[TRAIN] Epoch[1](2058/114412); Loss: 0.077717; Backpropagation: 0.2977 sec; Batch: 2.1291 sec
0.1364 0.1198 0.1030 0.0941 0.0847 0.0813 0.0724 0.0689 0.0647 0.0627 0.0618 0.0605 0.0595 0.0586 0.0577 0.0573 

[TRAIN] Epoch[1](2059/114412); Loss: 0.070916; Backpropagation: 0.2953 sec; Batch: 2.1730 sec
0.1327 0.1132 0.0903 0.0818 0.0717 0.0688 0.0638 0.0608 0.0593 0.0574 0.0566 0.0564 0.0562 0.0557 0.0553 0.0549 

[TRAIN] Epoch[1](2060/114412); Loss: 0.069896; Backpropagation: 0.2951 sec; Batch: 2.1118 sec
0.1286 0.1016 0.0863 0.0738 0.0690 0.0681 0.0646 0.0628 0.0621 0.0601 0.0581 0.0578 0.0576 0.0561 0.0558 0.0558 

[TRAIN] Epoch[1](2061/114412); Loss: 0.064011; Backpropagation: 0.2959 sec; Batch: 2.1208 sec
0.1538 0.0857 0.0765 0.0701 0.0636 0.0590 0.0561 0.0545 0.0524 0.0517 0.0512 0.0505 0.0501 0.0499 0.0495 0.0495 

[TRAIN] Epoch[1](2062/114412); Loss: 0.086595; Backpropagation: 0.2954 sec; Batch: 2.1252 sec
0.2042 0.1681 0.1317 0.1218 0.0941 0.0866 0.0712 0.0675 0.0644 0.0582 0.0559 0.0541 0.0531 0.0524 0.0516 0.0507 

[TRAIN] Epoch[1](2063/114412); Loss: 0.086944; Backpropagation: 0.2956 sec; Batch: 2.1214 sec
0.1394 0.1303 0.1088 0.0988 0.0901 0.0879 0.0819 0.0787 0.0766 0.0746 0.0729 0.0719 0.0707 0.0700 0.0696 0.0689 

[TRAIN] Epoch[1](2064/114412); Loss: 0.086922; Backpropagation: 0.2956 sec; Batch: 2.1200 sec
0.1443 0.1160 0.1022 0.0936 0.0882 0.0846 0.0813 0.0784 0.0777 0.0770 0.0754 0.0751 0.0748 0.0742 0.0740 0.0738 

[TRAIN] Epoch[1](2065/114412); Loss: 0.093311; Backpropagation: 0.2953 sec; Batch: 2.1253 sec
0.1910 0.1801 0.1345 0.1221 0.0949 0.0874 0.0781 0.0745 0.0747 0.0700 0.0676 0.0660 0.0646 0.0634 0.0624 0.0617 

[TRAIN] Epoch[1](2066/114412); Loss: 0.065152; Backpropagation: 0.2950 sec; Batch: 2.1244 sec
0.1351 0.1106 0.0856 0.0739 0.0635 0.0587 0.0573 0.0554 0.0533 0.0524 0.0511 0.0503 0.0497 0.0490 0.0485 0.0482 

[TRAIN] Epoch[1](2067/114412); Loss: 0.061190; Backpropagation: 0.2957 sec; Batch: 2.1191 sec
0.1100 0.0843 0.0773 0.0672 0.0634 0.0604 0.0570 0.0539 0.0528 0.0514 0.0509 0.0507 0.0503 0.0500 0.0499 0.0496 

[TRAIN] Epoch[1](2068/114412); Loss: 0.062942; Backpropagation: 0.2949 sec; Batch: 2.1201 sec
0.1262 0.0966 0.0801 0.0723 0.0632 0.0599 0.0568 0.0542 0.0530 0.0515 0.0503 0.0498 0.0491 0.0484 0.0481 0.0477 

[TRAIN] Epoch[1](2069/114412); Loss: 0.073301; Backpropagation: 0.2975 sec; Batch: 2.1212 sec
0.1582 0.1323 0.1047 0.0895 0.0778 0.0734 0.0633 0.0607 0.0568 0.0544 0.0523 0.0510 0.0504 0.0496 0.0493 0.0490 

[TRAIN] Epoch[1](2070/114412); Loss: 0.063614; Backpropagation: 0.2974 sec; Batch: 2.1255 sec
0.1344 0.1100 0.0889 0.0734 0.0602 0.0588 0.0565 0.0519 0.0506 0.0502 0.0487 0.0480 0.0472 0.0466 0.0464 0.0460 

[TRAIN] Epoch[1](2071/114412); Loss: 0.085638; Backpropagation: 0.2960 sec; Batch: 2.1250 sec
0.1320 0.1211 0.1080 0.0978 0.0933 0.0874 0.0817 0.0787 0.0764 0.0739 0.0722 0.0710 0.0701 0.0691 0.0688 0.0687 

[TRAIN] Epoch[1](2072/114412); Loss: 0.078373; Backpropagation: 0.2959 sec; Batch: 2.1244 sec
0.1553 0.1447 0.1145 0.1040 0.0862 0.0814 0.0695 0.0653 0.0592 0.0568 0.0552 0.0543 0.0528 0.0521 0.0515 0.0510 

[TRAIN] Epoch[1](2073/114412); Loss: 0.056433; Backpropagation: 0.2986 sec; Batch: 2.0872 sec
0.1044 0.0953 0.0697 0.0612 0.0597 0.0555 0.0523 0.0505 0.0478 0.0459 0.0449 0.0443 0.0434 0.0431 0.0425 0.0424 

[TRAIN] Epoch[1](2074/114412); Loss: 0.056476; Backpropagation: 0.2960 sec; Batch: 2.1227 sec
0.0952 0.0986 0.0780 0.0693 0.0659 0.0583 0.0517 0.0486 0.0465 0.0440 0.0433 0.0421 0.0411 0.0408 0.0403 0.0399 

[TRAIN] Epoch[1](2075/114412); Loss: 0.090386; Backpropagation: 0.2959 sec; Batch: 2.1271 sec
0.1634 0.1377 0.1195 0.1021 0.0927 0.0884 0.0831 0.0799 0.0775 0.0748 0.0735 0.0724 0.0713 0.0706 0.0699 0.0693 

[TRAIN] Epoch[1](2076/114412); Loss: 0.087296; Backpropagation: 0.2982 sec; Batch: 2.1251 sec
0.1319 0.1209 0.1094 0.0986 0.0894 0.0861 0.0821 0.0797 0.0784 0.0770 0.0761 0.0749 0.0739 0.0734 0.0727 0.0723 

[TRAIN] Epoch[1](2077/114412); Loss: 0.059023; Backpropagation: 0.2963 sec; Batch: 2.1102 sec
0.1392 0.1190 0.0831 0.0675 0.0574 0.0540 0.0495 0.0463 0.0440 0.0426 0.0415 0.0410 0.0403 0.0399 0.0397 0.0393 

[TRAIN] Epoch[1](2078/114412); Loss: 0.086609; Backpropagation: 0.2954 sec; Batch: 2.1885 sec
0.1360 0.1267 0.1056 0.0939 0.0870 0.0857 0.0815 0.0784 0.0775 0.0760 0.0738 0.0738 0.0732 0.0724 0.0723 0.0718 

[TRAIN] Epoch[1](2079/114412); Loss: 0.059663; Backpropagation: 0.2964 sec; Batch: 2.1268 sec
0.1052 0.0996 0.0795 0.0703 0.0608 0.0564 0.0540 0.0516 0.0504 0.0486 0.0480 0.0470 0.0462 0.0461 0.0459 0.0451 

[TRAIN] Epoch[1](2080/114412); Loss: 0.078786; Backpropagation: 0.2950 sec; Batch: 2.0816 sec
0.1564 0.1404 0.1022 0.0895 0.0821 0.0745 0.0693 0.0663 0.0642 0.0622 0.0606 0.0598 0.0591 0.0584 0.0579 0.0575 

[TRAIN] Epoch[1](2081/114412); Loss: 0.059485; Backpropagation: 0.2956 sec; Batch: 2.1238 sec
0.1083 0.0974 0.0809 0.0695 0.0616 0.0572 0.0531 0.0516 0.0496 0.0484 0.0473 0.0463 0.0456 0.0452 0.0450 0.0448 

[TRAIN] Epoch[1](2082/114412); Loss: 0.071990; Backpropagation: 0.2954 sec; Batch: 2.1337 sec
0.1317 0.1150 0.0920 0.0826 0.0731 0.0678 0.0652 0.0635 0.0606 0.0590 0.0584 0.0575 0.0570 0.0565 0.0561 0.0557 

[TRAIN] Epoch[1](2083/114412); Loss: 0.084075; Backpropagation: 0.2954 sec; Batch: 2.1244 sec
0.1749 0.1496 0.1169 0.1012 0.0854 0.0798 0.0725 0.0687 0.0663 0.0646 0.0627 0.0618 0.0609 0.0604 0.0599 0.0596 

[TRAIN] Epoch[1](2084/114412); Loss: 0.067784; Backpropagation: 0.2968 sec; Batch: 2.1273 sec
0.1178 0.1028 0.0858 0.0759 0.0706 0.0670 0.0644 0.0610 0.0586 0.0568 0.0558 0.0549 0.0540 0.0535 0.0529 0.0525 

[TRAIN] Epoch[1](2085/114412); Loss: 0.081685; Backpropagation: 0.2954 sec; Batch: 2.1191 sec
0.1496 0.1341 0.1011 0.0896 0.0831 0.0781 0.0741 0.0722 0.0699 0.0680 0.0665 0.0656 0.0648 0.0640 0.0635 0.0629 

[TRAIN] Epoch[1](2086/114412); Loss: 0.091847; Backpropagation: 0.2984 sec; Batch: 2.1253 sec
0.1479 0.1319 0.1111 0.0985 0.0943 0.0892 0.0846 0.0827 0.0813 0.0799 0.0792 0.0787 0.0781 0.0776 0.0773 0.0773 

[TRAIN] Epoch[1](2087/114412); Loss: 0.067533; Backpropagation: 0.2954 sec; Batch: 2.1212 sec
0.1535 0.1363 0.1027 0.0943 0.0699 0.0644 0.0482 0.0470 0.0477 0.0458 0.0453 0.0452 0.0451 0.0450 0.0451 0.0450 

[TRAIN] Epoch[1](2088/114412); Loss: 0.073806; Backpropagation: 0.2959 sec; Batch: 2.1045 sec
0.1174 0.1004 0.0890 0.0797 0.0748 0.0723 0.0701 0.0678 0.0663 0.0648 0.0641 0.0635 0.0630 0.0628 0.0626 0.0624 

[TRAIN] Epoch[1](2089/114412); Loss: 0.070598; Backpropagation: 0.2955 sec; Batch: 2.1183 sec
0.1537 0.1365 0.0995 0.0900 0.0680 0.0635 0.0601 0.0557 0.0539 0.0524 0.0508 0.0501 0.0496 0.0489 0.0486 0.0483 

[TRAIN] Epoch[1](2090/114412); Loss: 0.058974; Backpropagation: 0.2955 sec; Batch: 2.1229 sec
0.1196 0.1072 0.0816 0.0705 0.0607 0.0567 0.0532 0.0494 0.0462 0.0446 0.0436 0.0429 0.0424 0.0419 0.0416 0.0414 

[TRAIN] Epoch[1](2091/114412); Loss: 0.065366; Backpropagation: 0.2947 sec; Batch: 2.1238 sec
0.1107 0.0982 0.0851 0.0757 0.0691 0.0638 0.0603 0.0575 0.0559 0.0549 0.0540 0.0530 0.0526 0.0521 0.0516 0.0515 

[TRAIN] Epoch[1](2092/114412); Loss: 0.065286; Backpropagation: 0.2960 sec; Batch: 2.1219 sec
0.1471 0.1317 0.1021 0.0951 0.0658 0.0610 0.0480 0.0471 0.0470 0.0445 0.0436 0.0431 0.0426 0.0422 0.0420 0.0418 

[TRAIN] Epoch[1](2093/114412); Loss: 0.072627; Backpropagation: 0.2978 sec; Batch: 2.1246 sec
0.1356 0.1202 0.0999 0.0846 0.0734 0.0696 0.0634 0.0613 0.0594 0.0580 0.0575 0.0566 0.0561 0.0557 0.0554 0.0552 

[TRAIN] Epoch[1](2094/114412); Loss: 0.079045; Backpropagation: 0.2957 sec; Batch: 2.1232 sec
0.1393 0.1254 0.1078 0.0980 0.0852 0.0796 0.0718 0.0675 0.0651 0.0635 0.0618 0.0612 0.0604 0.0596 0.0594 0.0590 

[TRAIN] Epoch[1](2095/114412); Loss: 0.072600; Backpropagation: 0.2955 sec; Batch: 2.1207 sec
0.1191 0.1024 0.0898 0.0826 0.0747 0.0713 0.0678 0.0654 0.0638 0.0626 0.0615 0.0610 0.0604 0.0599 0.0597 0.0595 

[TRAIN] Epoch[1](2096/114412); Loss: 0.076492; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.1415 0.1314 0.1073 0.0994 0.0841 0.0795 0.0681 0.0641 0.0598 0.0579 0.0570 0.0565 0.0552 0.0545 0.0540 0.0534 

[TRAIN] Epoch[1](2097/114412); Loss: 0.075141; Backpropagation: 0.2952 sec; Batch: 2.1255 sec
0.1327 0.1124 0.0975 0.0833 0.0780 0.0727 0.0697 0.0665 0.0642 0.0628 0.0618 0.0611 0.0605 0.0600 0.0597 0.0594 

[TRAIN] Epoch[1](2098/114412); Loss: 0.078680; Backpropagation: 0.2958 sec; Batch: 2.1219 sec
0.1549 0.1394 0.1075 0.0950 0.0767 0.0721 0.0709 0.0660 0.0634 0.0616 0.0603 0.0593 0.0586 0.0580 0.0576 0.0574 

[TRAIN] Epoch[1](2099/114412); Loss: 0.077345; Backpropagation: 0.2958 sec; Batch: 2.1226 sec
0.1362 0.1283 0.1004 0.0883 0.0789 0.0735 0.0696 0.0669 0.0648 0.0635 0.0626 0.0618 0.0614 0.0608 0.0603 0.0602 

[TRAIN] Epoch[1](2100/114412); Loss: 0.066834; Backpropagation: 0.2982 sec; Batch: 2.1239 sec
0.1082 0.1014 0.0889 0.0765 0.0706 0.0653 0.0619 0.0598 0.0580 0.0562 0.0556 0.0544 0.0539 0.0533 0.0529 0.0526 

[TRAIN] Epoch[1](2101/114412); Loss: 0.094562; Backpropagation: 0.3007 sec; Batch: 2.1285 sec
0.1752 0.1591 0.1293 0.1177 0.0947 0.0896 0.0845 0.0797 0.0778 0.0753 0.0737 0.0731 0.0717 0.0709 0.0706 0.0702 

[TRAIN] Epoch[1](2102/114412); Loss: 0.073809; Backpropagation: 0.2980 sec; Batch: 2.1257 sec
0.1278 0.1117 0.0978 0.0842 0.0750 0.0708 0.0678 0.0651 0.0635 0.0617 0.0607 0.0599 0.0593 0.0588 0.0585 0.0581 

[TRAIN] Epoch[1](2103/114412); Loss: 0.054774; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.0934 0.0793 0.0683 0.0611 0.0594 0.0544 0.0507 0.0488 0.0474 0.0464 0.0455 0.0449 0.0444 0.0442 0.0441 0.0439 

[TRAIN] Epoch[1](2104/114412); Loss: 0.064022; Backpropagation: 0.2949 sec; Batch: 2.1245 sec
0.1076 0.0830 0.0752 0.0684 0.0643 0.0613 0.0599 0.0585 0.0573 0.0565 0.0561 0.0558 0.0554 0.0551 0.0550 0.0548 

[TRAIN] Epoch[1](2105/114412); Loss: 0.082966; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.1360 0.1274 0.0976 0.0887 0.0836 0.0775 0.0767 0.0748 0.0732 0.0722 0.0712 0.0705 0.0700 0.0696 0.0692 0.0691 

[TRAIN] Epoch[1](2106/114412); Loss: 0.075372; Backpropagation: 0.2950 sec; Batch: 2.0827 sec
0.1337 0.1188 0.0979 0.0885 0.0802 0.0744 0.0686 0.0658 0.0638 0.0620 0.0605 0.0595 0.0588 0.0582 0.0578 0.0574 

[TRAIN] Epoch[1](2107/114412); Loss: 0.074305; Backpropagation: 0.2952 sec; Batch: 2.1198 sec
0.1556 0.1466 0.1007 0.0893 0.0735 0.0684 0.0652 0.0604 0.0570 0.0560 0.0547 0.0535 0.0528 0.0522 0.0516 0.0514 

[TRAIN] Epoch[1](2108/114412); Loss: 0.084232; Backpropagation: 0.2978 sec; Batch: 2.1251 sec
0.1348 0.1174 0.1043 0.0931 0.0866 0.0827 0.0792 0.0769 0.0751 0.0734 0.0725 0.0717 0.0707 0.0702 0.0698 0.0693 

[TRAIN] Epoch[1](2109/114412); Loss: 0.049272; Backpropagation: 0.2954 sec; Batch: 2.1181 sec
0.0971 0.0850 0.0723 0.0635 0.0534 0.0486 0.0421 0.0399 0.0390 0.0373 0.0363 0.0357 0.0352 0.0347 0.0343 0.0341 

[TRAIN] Epoch[1](2110/114412); Loss: 0.075269; Backpropagation: 0.2980 sec; Batch: 2.1290 sec
0.1048 0.0918 0.0892 0.0832 0.0777 0.0750 0.0724 0.0705 0.0696 0.0686 0.0681 0.0674 0.0669 0.0667 0.0663 0.0661 

[TRAIN] Epoch[1](2111/114412); Loss: 0.056179; Backpropagation: 0.2981 sec; Batch: 2.1253 sec
0.1102 0.0838 0.0681 0.0605 0.0543 0.0520 0.0503 0.0489 0.0480 0.0473 0.0467 0.0463 0.0460 0.0457 0.0455 0.0453 

[TRAIN] Epoch[1](2112/114412); Loss: 0.054431; Backpropagation: 0.2956 sec; Batch: 2.1305 sec
0.1022 0.0754 0.0696 0.0564 0.0537 0.0517 0.0498 0.0489 0.0473 0.0465 0.0460 0.0451 0.0449 0.0447 0.0443 0.0442 

[TRAIN] Epoch[1](2113/114412); Loss: 0.058860; Backpropagation: 0.2952 sec; Batch: 2.1366 sec
0.0975 0.0794 0.0866 0.0729 0.0598 0.0562 0.0544 0.0530 0.0503 0.0492 0.0484 0.0476 0.0471 0.0468 0.0464 0.0462 

[TRAIN] Epoch[1](2114/114412); Loss: 0.073757; Backpropagation: 0.2954 sec; Batch: 2.1281 sec
0.1720 0.1524 0.1029 0.0885 0.0798 0.0635 0.0606 0.0590 0.0538 0.0531 0.0521 0.0497 0.0493 0.0486 0.0476 0.0473 

[TRAIN] Epoch[1](2115/114412); Loss: 0.056579; Backpropagation: 0.2954 sec; Batch: 2.1198 sec
0.0969 0.0838 0.0750 0.0664 0.0579 0.0563 0.0529 0.0502 0.0486 0.0472 0.0463 0.0456 0.0450 0.0446 0.0444 0.0442 

[TRAIN] Epoch[1](2116/114412); Loss: 0.089661; Backpropagation: 0.2957 sec; Batch: 2.1261 sec
0.1547 0.1477 0.1232 0.1118 0.0982 0.0903 0.0830 0.0771 0.0726 0.0717 0.0702 0.0677 0.0678 0.0670 0.0658 0.0658 

[TRAIN] Epoch[1](2117/114412); Loss: 0.082715; Backpropagation: 0.2956 sec; Batch: 2.1036 sec
0.1447 0.1246 0.1120 0.1002 0.0870 0.0812 0.0766 0.0729 0.0701 0.0679 0.0667 0.0656 0.0646 0.0638 0.0631 0.0625 

[TRAIN] Epoch[1](2118/114412); Loss: 0.057935; Backpropagation: 0.2956 sec; Batch: 2.0910 sec
0.0987 0.0914 0.0795 0.0673 0.0603 0.0568 0.0529 0.0503 0.0488 0.0477 0.0470 0.0464 0.0456 0.0452 0.0447 0.0445 

[TRAIN] Epoch[1](2119/114412); Loss: 0.078629; Backpropagation: 0.2950 sec; Batch: 2.1214 sec
0.1297 0.1105 0.1015 0.0876 0.0786 0.0761 0.0733 0.0709 0.0693 0.0681 0.0670 0.0662 0.0655 0.0649 0.0646 0.0643 

[TRAIN] Epoch[1](2120/114412); Loss: 0.067776; Backpropagation: 0.2955 sec; Batch: 2.0823 sec
0.1484 0.1265 0.0933 0.0815 0.0695 0.0639 0.0591 0.0563 0.0534 0.0509 0.0496 0.0482 0.0471 0.0463 0.0456 0.0450 

[TRAIN] Epoch[1](2121/114412); Loss: 0.088210; Backpropagation: 0.2947 sec; Batch: 2.1228 sec
0.1481 0.1359 0.1126 0.1022 0.0935 0.0896 0.0817 0.0789 0.0773 0.0739 0.0723 0.0710 0.0698 0.0689 0.0682 0.0674 

[TRAIN] Epoch[1](2122/114412); Loss: 0.070724; Backpropagation: 0.2956 sec; Batch: 2.1242 sec
0.1470 0.1347 0.0990 0.0897 0.0699 0.0663 0.0628 0.0596 0.0545 0.0531 0.0519 0.0502 0.0492 0.0485 0.0479 0.0474 

[TRAIN] Epoch[1](2123/114412); Loss: 0.072653; Backpropagation: 0.2956 sec; Batch: 2.1233 sec
0.1191 0.1027 0.0891 0.0815 0.0749 0.0724 0.0679 0.0651 0.0645 0.0628 0.0617 0.0611 0.0605 0.0600 0.0597 0.0595 

[TRAIN] Epoch[1](2124/114412); Loss: 0.060478; Backpropagation: 0.2968 sec; Batch: 2.0914 sec
0.0933 0.0916 0.0812 0.0698 0.0630 0.0599 0.0572 0.0547 0.0532 0.0514 0.0502 0.0495 0.0487 0.0483 0.0479 0.0477 

[TRAIN] Epoch[1](2125/114412); Loss: 0.073875; Backpropagation: 0.2957 sec; Batch: 2.1198 sec
0.1244 0.1079 0.0972 0.0833 0.0749 0.0725 0.0676 0.0647 0.0638 0.0627 0.0616 0.0610 0.0606 0.0602 0.0600 0.0596 

[TRAIN] Epoch[1](2126/114412); Loss: 0.086500; Backpropagation: 0.2959 sec; Batch: 2.1214 sec
0.1426 0.1361 0.1111 0.0977 0.0839 0.0803 0.0779 0.0773 0.0745 0.0733 0.0730 0.0719 0.0716 0.0714 0.0710 0.0705 

[TRAIN] Epoch[1](2127/114412); Loss: 0.056221; Backpropagation: 0.2967 sec; Batch: 2.1240 sec
0.1109 0.0993 0.0841 0.0673 0.0556 0.0535 0.0519 0.0469 0.0451 0.0449 0.0429 0.0409 0.0400 0.0393 0.0386 0.0384 

[TRAIN] Epoch[1](2128/114412); Loss: 0.089913; Backpropagation: 0.2958 sec; Batch: 2.1247 sec
0.1275 0.1214 0.1168 0.1031 0.0933 0.0909 0.0867 0.0833 0.0813 0.0791 0.0779 0.0770 0.0760 0.0753 0.0747 0.0743 

[TRAIN] Epoch[1](2129/114412); Loss: 0.078567; Backpropagation: 0.2958 sec; Batch: 2.1328 sec
0.1511 0.1428 0.1100 0.0983 0.0793 0.0755 0.0708 0.0660 0.0635 0.0609 0.0585 0.0573 0.0566 0.0560 0.0554 0.0551 

[TRAIN] Epoch[1](2130/114412); Loss: 0.100118; Backpropagation: 0.2965 sec; Batch: 2.1212 sec
0.1603 0.1507 0.1148 0.1070 0.1021 0.0951 0.0909 0.0907 0.0891 0.0875 0.0870 0.0862 0.0857 0.0853 0.0848 0.0847 

[TRAIN] Epoch[1](2131/114412); Loss: 0.071474; Backpropagation: 0.2950 sec; Batch: 2.1227 sec
0.1223 0.1064 0.0995 0.0850 0.0766 0.0712 0.0663 0.0630 0.0606 0.0587 0.0572 0.0565 0.0558 0.0552 0.0549 0.0544 

[TRAIN] Epoch[1](2132/114412); Loss: 0.062323; Backpropagation: 0.2976 sec; Batch: 2.0843 sec
0.1342 0.1198 0.0808 0.0708 0.0613 0.0567 0.0540 0.0512 0.0495 0.0480 0.0467 0.0458 0.0452 0.0448 0.0442 0.0440 

[TRAIN] Epoch[1](2133/114412); Loss: 0.083461; Backpropagation: 0.2952 sec; Batch: 2.1404 sec
0.1288 0.1149 0.1072 0.0944 0.0871 0.0809 0.0779 0.0760 0.0739 0.0728 0.0720 0.0711 0.0703 0.0697 0.0694 0.0690 

[TRAIN] Epoch[1](2134/114412); Loss: 0.085402; Backpropagation: 0.2952 sec; Batch: 2.1198 sec
0.1467 0.1331 0.1107 0.1009 0.0870 0.0839 0.0785 0.0751 0.0726 0.0711 0.0698 0.0688 0.0679 0.0672 0.0667 0.0664 

[TRAIN] Epoch[1](2135/114412); Loss: 0.070606; Backpropagation: 0.2950 sec; Batch: 2.2036 sec
0.1225 0.1173 0.0910 0.0794 0.0735 0.0683 0.0638 0.0610 0.0594 0.0581 0.0569 0.0563 0.0560 0.0556 0.0554 0.0552 

[TRAIN] Epoch[1](2136/114412); Loss: 0.055644; Backpropagation: 0.2956 sec; Batch: 2.1180 sec
0.0995 0.0871 0.0859 0.0723 0.0569 0.0504 0.0495 0.0466 0.0449 0.0443 0.0432 0.0425 0.0423 0.0419 0.0415 0.0415 

[TRAIN] Epoch[1](2137/114412); Loss: 0.070161; Backpropagation: 0.2957 sec; Batch: 2.1328 sec
0.1169 0.1029 0.0931 0.0830 0.0731 0.0686 0.0650 0.0624 0.0605 0.0588 0.0577 0.0570 0.0564 0.0559 0.0557 0.0554 

[TRAIN] Epoch[1](2138/114412); Loss: 0.086132; Backpropagation: 0.2956 sec; Batch: 2.1075 sec
0.1514 0.1428 0.1149 0.1020 0.0873 0.0837 0.0785 0.0746 0.0722 0.0707 0.0690 0.0678 0.0669 0.0660 0.0655 0.0647 

[TRAIN] Epoch[1](2139/114412); Loss: 0.064701; Backpropagation: 0.2953 sec; Batch: 2.1198 sec
0.1173 0.0996 0.0854 0.0704 0.0648 0.0627 0.0578 0.0556 0.0547 0.0536 0.0531 0.0525 0.0522 0.0518 0.0518 0.0519 

[TRAIN] Epoch[1](2140/114412); Loss: 0.057137; Backpropagation: 0.3005 sec; Batch: 2.1263 sec
0.1223 0.0988 0.0828 0.0706 0.0560 0.0525 0.0488 0.0463 0.0448 0.0433 0.0424 0.0417 0.0414 0.0410 0.0407 0.0406 

[TRAIN] Epoch[1](2141/114412); Loss: 0.067370; Backpropagation: 0.2981 sec; Batch: 2.1262 sec
0.1124 0.0995 0.0845 0.0730 0.0696 0.0654 0.0624 0.0604 0.0588 0.0577 0.0570 0.0563 0.0558 0.0553 0.0550 0.0549 

[TRAIN] Epoch[1](2142/114412); Loss: 0.090795; Backpropagation: 0.2979 sec; Batch: 2.1272 sec
0.1514 0.1371 0.1250 0.1116 0.0952 0.0872 0.0842 0.0803 0.0774 0.0754 0.0737 0.0726 0.0715 0.0706 0.0700 0.0695 

[TRAIN] Epoch[1](2143/114412); Loss: 0.065311; Backpropagation: 0.2954 sec; Batch: 2.1174 sec
0.1090 0.0993 0.0879 0.0772 0.0677 0.0641 0.0605 0.0578 0.0561 0.0544 0.0531 0.0523 0.0518 0.0514 0.0512 0.0510 

[TRAIN] Epoch[1](2144/114412); Loss: 0.069254; Backpropagation: 0.2957 sec; Batch: 2.1249 sec
0.1076 0.1056 0.0962 0.0817 0.0707 0.0685 0.0631 0.0616 0.0596 0.0582 0.0572 0.0563 0.0559 0.0556 0.0552 0.0551 

[TRAIN] Epoch[1](2145/114412); Loss: 0.084655; Backpropagation: 0.2959 sec; Batch: 2.1320 sec
0.1610 0.1465 0.1119 0.0949 0.0874 0.0802 0.0752 0.0725 0.0700 0.0681 0.0665 0.0654 0.0645 0.0638 0.0634 0.0631 

[TRAIN] Epoch[1](2146/114412); Loss: 0.085625; Backpropagation: 0.2956 sec; Batch: 2.1239 sec
0.1412 0.1305 0.1140 0.1006 0.0870 0.0830 0.0786 0.0756 0.0735 0.0719 0.0709 0.0699 0.0691 0.0686 0.0679 0.0676 

[TRAIN] Epoch[1](2147/114412); Loss: 0.076247; Backpropagation: 0.2982 sec; Batch: 2.1273 sec
0.1257 0.1189 0.0911 0.0889 0.0751 0.0723 0.0701 0.0690 0.0658 0.0647 0.0638 0.0634 0.0630 0.0628 0.0627 0.0628 

[TRAIN] Epoch[1](2148/114412); Loss: 0.071253; Backpropagation: 0.2960 sec; Batch: 2.1196 sec
0.1384 0.1173 0.0991 0.0901 0.0765 0.0712 0.0654 0.0612 0.0589 0.0560 0.0545 0.0527 0.0512 0.0503 0.0489 0.0484 

[TRAIN] Epoch[1](2149/114412); Loss: 0.070101; Backpropagation: 0.2951 sec; Batch: 2.1250 sec
0.1153 0.1019 0.0895 0.0786 0.0706 0.0670 0.0652 0.0629 0.0614 0.0601 0.0593 0.0586 0.0583 0.0579 0.0577 0.0575 

[TRAIN] Epoch[1](2150/114412); Loss: 0.065745; Backpropagation: 0.2959 sec; Batch: 2.1216 sec
0.1093 0.0948 0.0817 0.0751 0.0682 0.0651 0.0602 0.0582 0.0570 0.0565 0.0554 0.0547 0.0543 0.0541 0.0537 0.0535 

[TRAIN] Epoch[1](2151/114412); Loss: 0.073717; Backpropagation: 0.2953 sec; Batch: 2.1230 sec
0.1210 0.1118 0.0905 0.0809 0.0758 0.0715 0.0682 0.0661 0.0642 0.0631 0.0624 0.0615 0.0611 0.0608 0.0605 0.0602 

[TRAIN] Epoch[1](2152/114412); Loss: 0.071235; Backpropagation: 0.2958 sec; Batch: 2.1244 sec
0.1467 0.1311 0.0922 0.0772 0.0761 0.0676 0.0626 0.0588 0.0565 0.0550 0.0542 0.0536 0.0528 0.0521 0.0516 0.0515 

[TRAIN] Epoch[1](2153/114412); Loss: 0.076732; Backpropagation: 0.2955 sec; Batch: 2.1188 sec
0.1395 0.1228 0.1047 0.0884 0.0798 0.0750 0.0695 0.0664 0.0636 0.0620 0.0611 0.0601 0.0594 0.0589 0.0583 0.0580 

[TRAIN] Epoch[1](2154/114412); Loss: 0.100133; Backpropagation: 0.2951 sec; Batch: 2.1213 sec
0.1735 0.1621 0.1430 0.1318 0.1174 0.1003 0.0925 0.0876 0.0807 0.0787 0.0757 0.0733 0.0727 0.0716 0.0708 0.0705 

[TRAIN] Epoch[1](2155/114412); Loss: 0.062205; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.1207 0.1107 0.0792 0.0680 0.0634 0.0570 0.0540 0.0526 0.0514 0.0500 0.0492 0.0486 0.0481 0.0478 0.0475 0.0471 

[TRAIN] Epoch[1](2156/114412); Loss: 0.049631; Backpropagation: 0.2954 sec; Batch: 2.1215 sec
0.1090 0.0948 0.0674 0.0589 0.0516 0.0462 0.0431 0.0404 0.0384 0.0367 0.0358 0.0351 0.0346 0.0343 0.0340 0.0338 

[TRAIN] Epoch[1](2157/114412); Loss: 0.069138; Backpropagation: 0.2957 sec; Batch: 2.1029 sec
0.1411 0.1292 0.0980 0.0827 0.0707 0.0638 0.0590 0.0559 0.0542 0.0524 0.0513 0.0506 0.0498 0.0494 0.0492 0.0489 

[TRAIN] Epoch[1](2158/114412); Loss: 0.055415; Backpropagation: 0.2955 sec; Batch: 2.0822 sec
0.0976 0.0835 0.0753 0.0612 0.0562 0.0522 0.0504 0.0483 0.0473 0.0464 0.0456 0.0452 0.0448 0.0444 0.0442 0.0441 

[TRAIN] Epoch[1](2159/114412); Loss: 0.099096; Backpropagation: 0.2950 sec; Batch: 2.1244 sec
0.1615 0.1503 0.1348 0.1187 0.1023 0.0958 0.0911 0.0875 0.0846 0.0831 0.0816 0.0803 0.0794 0.0788 0.0781 0.0776 

[TRAIN] Epoch[1](2160/114412); Loss: 0.074690; Backpropagation: 0.2948 sec; Batch: 2.1199 sec
0.1341 0.1186 0.0984 0.0817 0.0753 0.0706 0.0678 0.0658 0.0636 0.0622 0.0611 0.0602 0.0595 0.0590 0.0587 0.0585 

[TRAIN] Epoch[1](2161/114412); Loss: 0.065147; Backpropagation: 0.2948 sec; Batch: 2.1186 sec
0.1305 0.1142 0.0911 0.0751 0.0636 0.0598 0.0582 0.0546 0.0523 0.0512 0.0503 0.0495 0.0488 0.0481 0.0476 0.0473 

[TRAIN] Epoch[1](2162/114412); Loss: 0.064521; Backpropagation: 0.2953 sec; Batch: 2.1219 sec
0.1391 0.1251 0.0852 0.0751 0.0622 0.0577 0.0553 0.0525 0.0503 0.0492 0.0482 0.0473 0.0468 0.0463 0.0461 0.0459 

[TRAIN] Epoch[1](2163/114412); Loss: 0.061451; Backpropagation: 0.2955 sec; Batch: 2.1267 sec
0.1162 0.1006 0.0854 0.0730 0.0669 0.0631 0.0569 0.0531 0.0501 0.0480 0.0468 0.0455 0.0451 0.0446 0.0441 0.0437 

[TRAIN] Epoch[1](2164/114412); Loss: 0.068677; Backpropagation: 0.2953 sec; Batch: 2.1248 sec
0.1205 0.1027 0.0869 0.0768 0.0696 0.0676 0.0635 0.0607 0.0592 0.0581 0.0571 0.0562 0.0557 0.0552 0.0547 0.0544 

[TRAIN] Epoch[1](2165/114412); Loss: 0.069409; Backpropagation: 0.2984 sec; Batch: 2.1294 sec
0.1988 0.1884 0.1134 0.0992 0.0563 0.0513 0.0529 0.0507 0.0417 0.0397 0.0383 0.0375 0.0367 0.0357 0.0352 0.0347 

[TRAIN] Epoch[1](2166/114412); Loss: 0.085556; Backpropagation: 0.2980 sec; Batch: 2.1351 sec
0.1801 0.1704 0.1330 0.1147 0.0881 0.0806 0.0697 0.0651 0.0623 0.0611 0.0593 0.0582 0.0574 0.0567 0.0563 0.0559 

[TRAIN] Epoch[1](2167/114412); Loss: 0.079390; Backpropagation: 0.3004 sec; Batch: 2.1283 sec
0.1522 0.1333 0.1065 0.0891 0.0814 0.0744 0.0697 0.0669 0.0651 0.0640 0.0628 0.0619 0.0613 0.0609 0.0605 0.0601 

[TRAIN] Epoch[1](2168/114412); Loss: 0.058249; Backpropagation: 0.2953 sec; Batch: 2.1199 sec
0.1355 0.1175 0.0883 0.0765 0.0570 0.0540 0.0460 0.0440 0.0427 0.0405 0.0396 0.0389 0.0384 0.0380 0.0377 0.0375 

[TRAIN] Epoch[1](2169/114412); Loss: 0.089107; Backpropagation: 0.2958 sec; Batch: 2.1197 sec
0.1919 0.1787 0.1386 0.1263 0.0899 0.0819 0.0748 0.0675 0.0634 0.0628 0.0605 0.0591 0.0586 0.0577 0.0573 0.0568 

[TRAIN] Epoch[1](2170/114412); Loss: 0.079774; Backpropagation: 0.2965 sec; Batch: 2.1206 sec
0.1317 0.1212 0.0996 0.0909 0.0813 0.0774 0.0735 0.0710 0.0693 0.0681 0.0670 0.0663 0.0657 0.0650 0.0643 0.0640 

[TRAIN] Epoch[1](2171/114412); Loss: 0.092117; Backpropagation: 0.2954 sec; Batch: 2.1249 sec
0.1874 0.1689 0.1337 0.1155 0.0979 0.0882 0.0802 0.0740 0.0710 0.0689 0.0672 0.0657 0.0648 0.0640 0.0635 0.0629 

[TRAIN] Epoch[1](2172/114412); Loss: 0.070647; Backpropagation: 0.2959 sec; Batch: 2.1211 sec
0.1660 0.1548 0.1122 0.0981 0.0661 0.0613 0.0563 0.0507 0.0495 0.0490 0.0462 0.0449 0.0444 0.0440 0.0434 0.0433 

[TRAIN] Epoch[1](2173/114412); Loss: 0.067934; Backpropagation: 0.2957 sec; Batch: 2.0863 sec
0.1175 0.1056 0.0903 0.0795 0.0681 0.0647 0.0616 0.0591 0.0575 0.0564 0.0558 0.0551 0.0545 0.0541 0.0537 0.0533 

[TRAIN] Epoch[1](2174/114412); Loss: 0.063088; Backpropagation: 0.2955 sec; Batch: 2.1208 sec
0.1064 0.0920 0.0815 0.0744 0.0643 0.0613 0.0585 0.0563 0.0548 0.0535 0.0526 0.0517 0.0511 0.0506 0.0503 0.0501 

[TRAIN] Epoch[1](2175/114412); Loss: 0.074366; Backpropagation: 0.2955 sec; Batch: 2.1210 sec
0.1150 0.1049 0.0910 0.0841 0.0751 0.0736 0.0698 0.0674 0.0663 0.0651 0.0640 0.0636 0.0631 0.0628 0.0622 0.0619 

[TRAIN] Epoch[1](2176/114412); Loss: 0.102467; Backpropagation: 0.2953 sec; Batch: 2.1294 sec
0.1989 0.1865 0.1404 0.1281 0.1038 0.0980 0.0874 0.0834 0.0814 0.0796 0.0776 0.0763 0.0754 0.0747 0.0743 0.0738 

[TRAIN] Epoch[1](2177/114412); Loss: 0.068637; Backpropagation: 0.2983 sec; Batch: 2.1205 sec
0.1517 0.1397 0.1011 0.0887 0.0632 0.0586 0.0591 0.0525 0.0502 0.0505 0.0489 0.0478 0.0470 0.0465 0.0464 0.0462 

[TRAIN] Epoch[1](2178/114412); Loss: 0.070083; Backpropagation: 0.2980 sec; Batch: 2.1214 sec
0.1382 0.1141 0.0928 0.0849 0.0727 0.0665 0.0639 0.0599 0.0574 0.0560 0.0543 0.0530 0.0527 0.0520 0.0517 0.0512 

[TRAIN] Epoch[1](2179/114412); Loss: 0.087714; Backpropagation: 0.2959 sec; Batch: 2.1232 sec
0.1696 0.1593 0.1219 0.1111 0.0932 0.0857 0.0781 0.0719 0.0697 0.0674 0.0652 0.0640 0.0628 0.0619 0.0611 0.0605 

[TRAIN] Epoch[1](2180/114412); Loss: 0.079765; Backpropagation: 0.2952 sec; Batch: 2.1222 sec
0.1458 0.1376 0.1123 0.0949 0.0833 0.0809 0.0737 0.0693 0.0659 0.0630 0.0611 0.0595 0.0582 0.0578 0.0568 0.0562 

[TRAIN] Epoch[1](2181/114412); Loss: 0.054313; Backpropagation: 0.2957 sec; Batch: 2.1252 sec
0.1232 0.1150 0.0778 0.0606 0.0609 0.0513 0.0448 0.0435 0.0396 0.0381 0.0370 0.0364 0.0358 0.0353 0.0350 0.0348 

[TRAIN] Epoch[1](2182/114412); Loss: 0.098880; Backpropagation: 0.2982 sec; Batch: 2.1244 sec
0.1666 0.1538 0.1265 0.1129 0.0973 0.0921 0.0898 0.0872 0.0851 0.0840 0.0830 0.0821 0.0813 0.0805 0.0802 0.0797 

[TRAIN] Epoch[1](2183/114412); Loss: 0.070869; Backpropagation: 0.2955 sec; Batch: 2.1229 sec
0.1227 0.1075 0.0989 0.0858 0.0722 0.0675 0.0649 0.0617 0.0595 0.0581 0.0572 0.0566 0.0560 0.0555 0.0552 0.0548 

[TRAIN] Epoch[1](2184/114412); Loss: 0.088391; Backpropagation: 0.2961 sec; Batch: 2.0819 sec
0.1826 0.1712 0.1173 0.1040 0.0861 0.0791 0.0752 0.0713 0.0694 0.0674 0.0664 0.0660 0.0653 0.0646 0.0643 0.0640 

[TRAIN] Epoch[1](2185/114412); Loss: 0.095341; Backpropagation: 0.2957 sec; Batch: 2.1244 sec
0.1427 0.1317 0.1170 0.1074 0.0992 0.0933 0.0901 0.0876 0.0855 0.0840 0.0827 0.0818 0.0812 0.0808 0.0803 0.0800 

[TRAIN] Epoch[1](2186/114412); Loss: 0.084523; Backpropagation: 0.2949 sec; Batch: 2.0804 sec
0.1332 0.1238 0.1062 0.0945 0.0872 0.0830 0.0783 0.0762 0.0745 0.0733 0.0720 0.0712 0.0706 0.0699 0.0693 0.0691 

[TRAIN] Epoch[1](2187/114412); Loss: 0.053731; Backpropagation: 0.2998 sec; Batch: 2.1281 sec
0.1105 0.0949 0.0782 0.0637 0.0551 0.0499 0.0470 0.0443 0.0428 0.0410 0.0400 0.0394 0.0387 0.0384 0.0381 0.0378 

[TRAIN] Epoch[1](2188/114412); Loss: 0.109666; Backpropagation: 0.2954 sec; Batch: 2.0822 sec
0.1916 0.1784 0.1572 0.1325 0.1202 0.1102 0.1054 0.0994 0.0933 0.0886 0.0861 0.0823 0.0804 0.0786 0.0763 0.0742 

[TRAIN] Epoch[1](2189/114412); Loss: 0.080655; Backpropagation: 0.2961 sec; Batch: 2.1218 sec
0.1490 0.1349 0.1160 0.0968 0.0863 0.0803 0.0721 0.0669 0.0649 0.0631 0.0620 0.0609 0.0601 0.0595 0.0590 0.0588 

[TRAIN] Epoch[1](2190/114412); Loss: 0.076134; Backpropagation: 0.2959 sec; Batch: 2.1006 sec
0.1583 0.1399 0.1055 0.0921 0.0740 0.0705 0.0649 0.0630 0.0598 0.0583 0.0571 0.0563 0.0554 0.0548 0.0543 0.0539 

[TRAIN] Epoch[1](2191/114412); Loss: 0.071414; Backpropagation: 0.2957 sec; Batch: 2.1220 sec
0.1264 0.1126 0.0915 0.0808 0.0720 0.0682 0.0655 0.0626 0.0606 0.0597 0.0586 0.0576 0.0571 0.0566 0.0564 0.0564 

[TRAIN] Epoch[1](2192/114412); Loss: 0.069940; Backpropagation: 0.2959 sec; Batch: 2.1253 sec
0.1119 0.1069 0.0824 0.0760 0.0748 0.0695 0.0641 0.0629 0.0611 0.0601 0.0594 0.0588 0.0582 0.0578 0.0576 0.0572 

[TRAIN] Epoch[1](2193/114412); Loss: 0.081405; Backpropagation: 0.2959 sec; Batch: 2.1208 sec
0.1133 0.1070 0.0949 0.0888 0.0832 0.0808 0.0783 0.0761 0.0749 0.0741 0.0730 0.0724 0.0720 0.0715 0.0712 0.0710 

[TRAIN] Epoch[1](2194/114412); Loss: 0.075410; Backpropagation: 0.2955 sec; Batch: 2.2219 sec
0.1278 0.1095 0.0971 0.0802 0.0749 0.0716 0.0689 0.0671 0.0663 0.0651 0.0641 0.0635 0.0630 0.0628 0.0625 0.0621 

[TRAIN] Epoch[1](2195/114412); Loss: 0.105878; Backpropagation: 0.2958 sec; Batch: 2.1588 sec
0.1449 0.1354 0.1228 0.1146 0.1080 0.1039 0.1015 0.0997 0.0981 0.0968 0.0959 0.0954 0.0948 0.0944 0.0941 0.0937 

[TRAIN] Epoch[1](2196/114412); Loss: 0.070510; Backpropagation: 0.2958 sec; Batch: 2.1221 sec
0.1126 0.1008 0.0875 0.0751 0.0719 0.0676 0.0655 0.0638 0.0627 0.0618 0.0610 0.0602 0.0598 0.0595 0.0593 0.0591 

[TRAIN] Epoch[1](2197/114412); Loss: 0.063487; Backpropagation: 0.2958 sec; Batch: 2.1226 sec
0.1337 0.1223 0.0864 0.0745 0.0635 0.0585 0.0542 0.0525 0.0499 0.0486 0.0474 0.0462 0.0453 0.0447 0.0442 0.0439 

[TRAIN] Epoch[1](2198/114412); Loss: 0.044900; Backpropagation: 0.2954 sec; Batch: 2.1227 sec
0.1066 0.0746 0.0580 0.0509 0.0448 0.0420 0.0389 0.0369 0.0354 0.0344 0.0337 0.0330 0.0325 0.0326 0.0321 0.0322 

[TRAIN] Epoch[1](2199/114412); Loss: 0.075285; Backpropagation: 0.3009 sec; Batch: 2.1273 sec
0.1709 0.1609 0.1093 0.0933 0.0721 0.0654 0.0605 0.0594 0.0556 0.0536 0.0519 0.0515 0.0508 0.0501 0.0498 0.0496 

[TRAIN] Epoch[1](2200/114412); Loss: 0.070543; Backpropagation: 0.2980 sec; Batch: 2.1229 sec
0.1275 0.1085 0.0900 0.0799 0.0714 0.0680 0.0652 0.0622 0.0603 0.0591 0.0579 0.0570 0.0562 0.0556 0.0550 0.0548 

[TRAIN] Epoch[1](2201/114412); Loss: 0.094783; Backpropagation: 0.2956 sec; Batch: 2.1191 sec
0.2154 0.1867 0.1341 0.1082 0.0909 0.0824 0.0783 0.0771 0.0746 0.0713 0.0695 0.0676 0.0663 0.0655 0.0645 0.0641 

[TRAIN] Epoch[1](2202/114412); Loss: 0.055778; Backpropagation: 0.2954 sec; Batch: 2.1212 sec
0.0973 0.0897 0.0719 0.0622 0.0567 0.0521 0.0500 0.0487 0.0474 0.0464 0.0458 0.0454 0.0450 0.0448 0.0446 0.0444 

[TRAIN] Epoch[1](2203/114412); Loss: 0.064580; Backpropagation: 0.2956 sec; Batch: 2.1218 sec
0.1073 0.0974 0.0809 0.0740 0.0658 0.0623 0.0596 0.0581 0.0563 0.0550 0.0542 0.0534 0.0526 0.0524 0.0521 0.0518 

[TRAIN] Epoch[1](2204/114412); Loss: 0.061799; Backpropagation: 0.2957 sec; Batch: 2.1246 sec
0.1226 0.1032 0.0752 0.0650 0.0638 0.0604 0.0557 0.0531 0.0517 0.0504 0.0494 0.0486 0.0481 0.0475 0.0472 0.0470 

[TRAIN] Epoch[1](2205/114412); Loss: 0.053818; Backpropagation: 0.2955 sec; Batch: 2.1361 sec
0.1100 0.0954 0.0766 0.0620 0.0530 0.0487 0.0464 0.0452 0.0430 0.0420 0.0412 0.0404 0.0399 0.0394 0.0391 0.0388 

[TRAIN] Epoch[1](2206/114412); Loss: 0.053246; Backpropagation: 0.2981 sec; Batch: 2.1034 sec
0.0963 0.0861 0.0736 0.0622 0.0537 0.0507 0.0472 0.0462 0.0444 0.0432 0.0424 0.0417 0.0415 0.0411 0.0410 0.0407 

[TRAIN] Epoch[1](2207/114412); Loss: 0.080907; Backpropagation: 0.2968 sec; Batch: 2.1239 sec
0.1897 0.1754 0.1105 0.0932 0.0733 0.0682 0.0662 0.0624 0.0601 0.0587 0.0576 0.0569 0.0563 0.0557 0.0553 0.0549 

[TRAIN] Epoch[1](2208/114412); Loss: 0.057843; Backpropagation: 0.2953 sec; Batch: 2.1199 sec
0.1306 0.1043 0.0794 0.0733 0.0634 0.0527 0.0483 0.0470 0.0450 0.0427 0.0416 0.0405 0.0399 0.0393 0.0389 0.0386 

[TRAIN] Epoch[1](2209/114412); Loss: 0.085718; Backpropagation: 0.2981 sec; Batch: 2.1279 sec
0.1338 0.1205 0.1106 0.0977 0.0862 0.0828 0.0793 0.0773 0.0761 0.0744 0.0734 0.0730 0.0722 0.0716 0.0714 0.0710 

[TRAIN] Epoch[1](2210/114412); Loss: 0.096892; Backpropagation: 0.2983 sec; Batch: 2.1217 sec
0.1586 0.1484 0.1092 0.1027 0.0985 0.0943 0.0901 0.0873 0.0856 0.0846 0.0835 0.0826 0.0820 0.0813 0.0808 0.0805 

[TRAIN] Epoch[1](2211/114412); Loss: 0.042713; Backpropagation: 0.2948 sec; Batch: 2.1221 sec
0.0831 0.0708 0.0644 0.0542 0.0462 0.0399 0.0376 0.0358 0.0338 0.0327 0.0319 0.0312 0.0309 0.0306 0.0302 0.0301 

[TRAIN] Epoch[1](2212/114412); Loss: 0.081033; Backpropagation: 0.2977 sec; Batch: 2.1130 sec
0.1293 0.1180 0.1028 0.0908 0.0829 0.0790 0.0758 0.0732 0.0715 0.0702 0.0689 0.0680 0.0673 0.0668 0.0662 0.0659 

[TRAIN] Epoch[1](2213/114412); Loss: 0.072836; Backpropagation: 0.2987 sec; Batch: 2.1273 sec
0.1504 0.1316 0.1054 0.0827 0.0693 0.0645 0.0619 0.0604 0.0578 0.0562 0.0554 0.0546 0.0542 0.0539 0.0536 0.0535 

[TRAIN] Epoch[1](2214/114412); Loss: 0.076282; Backpropagation: 0.2957 sec; Batch: 2.1254 sec
0.1120 0.1011 0.0933 0.0840 0.0777 0.0747 0.0720 0.0703 0.0692 0.0681 0.0673 0.0669 0.0664 0.0660 0.0658 0.0656 

[TRAIN] Epoch[1](2215/114412); Loss: 0.060631; Backpropagation: 0.2953 sec; Batch: 2.1212 sec
0.1096 0.0915 0.0742 0.0674 0.0611 0.0593 0.0560 0.0538 0.0523 0.0509 0.0501 0.0495 0.0490 0.0487 0.0484 0.0483 

[TRAIN] Epoch[1](2216/114412); Loss: 0.072066; Backpropagation: 0.2954 sec; Batch: 2.1228 sec
0.1282 0.1157 0.0938 0.0851 0.0738 0.0678 0.0644 0.0623 0.0607 0.0595 0.0584 0.0576 0.0569 0.0565 0.0562 0.0561 

[TRAIN] Epoch[1](2217/114412); Loss: 0.095271; Backpropagation: 0.2957 sec; Batch: 2.1204 sec
0.1426 0.1306 0.1142 0.1030 0.0969 0.0939 0.0907 0.0884 0.0864 0.0849 0.0839 0.0830 0.0823 0.0816 0.0812 0.0808 

[TRAIN] Epoch[1](2218/114412); Loss: 0.058488; Backpropagation: 0.2954 sec; Batch: 2.1236 sec
0.1152 0.1021 0.0778 0.0639 0.0569 0.0542 0.0506 0.0491 0.0474 0.0469 0.0464 0.0456 0.0454 0.0450 0.0446 0.0446 

[TRAIN] Epoch[1](2219/114412); Loss: 0.054862; Backpropagation: 0.2958 sec; Batch: 2.1369 sec
0.0954 0.0830 0.0713 0.0609 0.0569 0.0524 0.0502 0.0486 0.0472 0.0462 0.0454 0.0448 0.0444 0.0439 0.0438 0.0436 

[TRAIN] Epoch[1](2220/114412); Loss: 0.081645; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.1447 0.1304 0.1069 0.0979 0.0839 0.0786 0.0732 0.0698 0.0680 0.0669 0.0658 0.0650 0.0644 0.0640 0.0635 0.0633 

[TRAIN] Epoch[1](2221/114412); Loss: 0.066391; Backpropagation: 0.2956 sec; Batch: 2.1250 sec
0.1174 0.1038 0.0809 0.0715 0.0671 0.0632 0.0602 0.0588 0.0571 0.0563 0.0557 0.0549 0.0544 0.0541 0.0536 0.0533 

[TRAIN] Epoch[1](2222/114412); Loss: 0.070916; Backpropagation: 0.2953 sec; Batch: 2.1336 sec
0.1303 0.1131 0.0912 0.0778 0.0723 0.0687 0.0655 0.0624 0.0603 0.0588 0.0574 0.0566 0.0559 0.0553 0.0549 0.0544 

[TRAIN] Epoch[1](2223/114412); Loss: 0.065114; Backpropagation: 0.2951 sec; Batch: 2.1212 sec
0.1008 0.0875 0.0776 0.0712 0.0671 0.0639 0.0618 0.0604 0.0591 0.0581 0.0573 0.0565 0.0558 0.0554 0.0549 0.0545 

[TRAIN] Epoch[1](2224/114412); Loss: 0.071365; Backpropagation: 0.2954 sec; Batch: 2.1294 sec
0.1425 0.1259 0.1018 0.0809 0.0700 0.0671 0.0629 0.0598 0.0575 0.0557 0.0545 0.0537 0.0530 0.0525 0.0522 0.0518 

[TRAIN] Epoch[1](2225/114412); Loss: 0.058585; Backpropagation: 0.2958 sec; Batch: 2.1256 sec
0.0836 0.0797 0.0705 0.0650 0.0608 0.0573 0.0555 0.0541 0.0530 0.0524 0.0518 0.0513 0.0509 0.0507 0.0504 0.0502 

[TRAIN] Epoch[1](2226/114412); Loss: 0.078675; Backpropagation: 0.2952 sec; Batch: 2.1490 sec
0.1274 0.1090 0.0935 0.0855 0.0800 0.0764 0.0736 0.0719 0.0703 0.0693 0.0683 0.0677 0.0672 0.0667 0.0662 0.0658 

[TRAIN] Epoch[1](2227/114412); Loss: 0.064421; Backpropagation: 0.2953 sec; Batch: 2.1219 sec
0.1294 0.1134 0.0934 0.0787 0.0676 0.0625 0.0580 0.0539 0.0509 0.0489 0.0475 0.0464 0.0457 0.0452 0.0447 0.0443 

[TRAIN] Epoch[1](2228/114412); Loss: 0.084189; Backpropagation: 0.2956 sec; Batch: 2.1219 sec
0.1459 0.1304 0.1025 0.0945 0.0844 0.0807 0.0772 0.0753 0.0727 0.0713 0.0702 0.0694 0.0687 0.0682 0.0679 0.0675 

[TRAIN] Epoch[1](2229/114412); Loss: 0.032654; Backpropagation: 0.2957 sec; Batch: 2.1219 sec
0.0762 0.0576 0.0438 0.0355 0.0315 0.0284 0.0269 0.0260 0.0255 0.0252 0.0247 0.0245 0.0243 0.0242 0.0242 0.0242 

[TRAIN] Epoch[1](2230/114412); Loss: 0.062474; Backpropagation: 0.2961 sec; Batch: 2.1463 sec
0.1197 0.1038 0.0826 0.0677 0.0601 0.0573 0.0547 0.0530 0.0523 0.0514 0.0505 0.0500 0.0496 0.0493 0.0489 0.0487 

[TRAIN] Epoch[1](2231/114412); Loss: 0.053389; Backpropagation: 0.2955 sec; Batch: 2.1243 sec
0.0993 0.0764 0.0647 0.0595 0.0541 0.0510 0.0488 0.0470 0.0459 0.0452 0.0445 0.0441 0.0438 0.0435 0.0433 0.0432 

[TRAIN] Epoch[1](2232/114412); Loss: 0.089095; Backpropagation: 0.2954 sec; Batch: 2.1083 sec
0.1404 0.1347 0.1150 0.1055 0.0921 0.0877 0.0813 0.0795 0.0775 0.0755 0.0744 0.0736 0.0727 0.0724 0.0719 0.0715 

[TRAIN] Epoch[1](2233/114412); Loss: 0.062953; Backpropagation: 0.2959 sec; Batch: 2.1221 sec
0.1221 0.1100 0.0847 0.0712 0.0671 0.0606 0.0556 0.0532 0.0517 0.0497 0.0485 0.0477 0.0471 0.0464 0.0460 0.0457 

[TRAIN] Epoch[1](2234/114412); Loss: 0.064637; Backpropagation: 0.3005 sec; Batch: 2.1283 sec
0.1095 0.0959 0.0811 0.0691 0.0663 0.0627 0.0601 0.0582 0.0564 0.0552 0.0545 0.0538 0.0534 0.0530 0.0527 0.0524 

[TRAIN] Epoch[1](2235/114412); Loss: 0.070399; Backpropagation: 0.2983 sec; Batch: 2.1306 sec
0.1245 0.1137 0.0920 0.0807 0.0731 0.0662 0.0632 0.0608 0.0593 0.0581 0.0572 0.0565 0.0559 0.0556 0.0551 0.0548 

[TRAIN] Epoch[1](2236/114412); Loss: 0.059355; Backpropagation: 0.3006 sec; Batch: 2.1244 sec
0.1085 0.0986 0.0775 0.0679 0.0616 0.0574 0.0534 0.0514 0.0500 0.0483 0.0473 0.0465 0.0458 0.0454 0.0451 0.0448 

[TRAIN] Epoch[1](2237/114412); Loss: 0.058724; Backpropagation: 0.2982 sec; Batch: 2.1266 sec
0.1192 0.0953 0.0703 0.0592 0.0567 0.0545 0.0528 0.0506 0.0493 0.0486 0.0480 0.0475 0.0471 0.0469 0.0468 0.0467 

[TRAIN] Epoch[1](2238/114412); Loss: 0.070921; Backpropagation: 0.2980 sec; Batch: 2.0836 sec
0.1244 0.1044 0.0881 0.0786 0.0707 0.0678 0.0653 0.0630 0.0616 0.0605 0.0596 0.0590 0.0584 0.0580 0.0577 0.0575 

[TRAIN] Epoch[1](2239/114412); Loss: 0.058254; Backpropagation: 0.2982 sec; Batch: 2.1241 sec
0.0993 0.0782 0.0721 0.0631 0.0588 0.0564 0.0548 0.0529 0.0516 0.0506 0.0498 0.0494 0.0490 0.0488 0.0486 0.0486 

[TRAIN] Epoch[1](2240/114412); Loss: 0.063463; Backpropagation: 0.2954 sec; Batch: 2.1298 sec
0.1412 0.1149 0.0995 0.0750 0.0622 0.0565 0.0532 0.0499 0.0482 0.0475 0.0463 0.0453 0.0447 0.0440 0.0436 0.0433 

[TRAIN] Epoch[1](2241/114412); Loss: 0.085286; Backpropagation: 0.2955 sec; Batch: 2.1210 sec
0.1429 0.1299 0.1064 0.0953 0.0874 0.0824 0.0794 0.0772 0.0750 0.0728 0.0713 0.0703 0.0695 0.0688 0.0683 0.0677 

[TRAIN] Epoch[1](2242/114412); Loss: 0.066957; Backpropagation: 0.2954 sec; Batch: 2.1222 sec
0.1271 0.1130 0.0897 0.0784 0.0657 0.0615 0.0581 0.0571 0.0552 0.0538 0.0533 0.0526 0.0518 0.0516 0.0513 0.0511 

[TRAIN] Epoch[1](2243/114412); Loss: 0.067998; Backpropagation: 0.2955 sec; Batch: 2.1221 sec
0.1306 0.1120 0.0995 0.0860 0.0772 0.0693 0.0638 0.0589 0.0553 0.0525 0.0501 0.0485 0.0478 0.0463 0.0455 0.0447 

[TRAIN] Epoch[1](2244/114412); Loss: 0.056778; Backpropagation: 0.2951 sec; Batch: 2.1227 sec
0.1173 0.0996 0.0776 0.0642 0.0582 0.0522 0.0487 0.0477 0.0461 0.0446 0.0436 0.0429 0.0421 0.0416 0.0412 0.0407 

[TRAIN] Epoch[1](2245/114412); Loss: 0.064059; Backpropagation: 0.2949 sec; Batch: 2.1204 sec
0.1233 0.1095 0.0877 0.0755 0.0630 0.0593 0.0571 0.0540 0.0521 0.0509 0.0501 0.0494 0.0488 0.0485 0.0481 0.0477 

[TRAIN] Epoch[1](2246/114412); Loss: 0.074763; Backpropagation: 0.2955 sec; Batch: 2.1217 sec
0.1384 0.1183 0.0965 0.0854 0.0749 0.0707 0.0680 0.0651 0.0633 0.0617 0.0607 0.0598 0.0592 0.0585 0.0581 0.0577 

[TRAIN] Epoch[1](2247/114412); Loss: 0.083974; Backpropagation: 0.2962 sec; Batch: 2.1238 sec
0.1240 0.1105 0.0990 0.0924 0.0860 0.0826 0.0803 0.0771 0.0757 0.0749 0.0743 0.0740 0.0736 0.0733 0.0730 0.0728 

[TRAIN] Epoch[1](2248/114412); Loss: 0.070900; Backpropagation: 0.2949 sec; Batch: 2.1222 sec
0.1351 0.1122 0.0881 0.0773 0.0742 0.0680 0.0647 0.0629 0.0606 0.0593 0.0577 0.0562 0.0554 0.0549 0.0541 0.0536 

[TRAIN] Epoch[1](2249/114412); Loss: 0.078625; Backpropagation: 0.2955 sec; Batch: 2.1239 sec
0.1261 0.1116 0.0958 0.0855 0.0787 0.0754 0.0733 0.0717 0.0704 0.0691 0.0682 0.0675 0.0669 0.0664 0.0660 0.0655 

[TRAIN] Epoch[1](2250/114412); Loss: 0.057845; Backpropagation: 0.2950 sec; Batch: 2.1208 sec
0.1217 0.1039 0.0804 0.0652 0.0571 0.0527 0.0502 0.0476 0.0459 0.0449 0.0440 0.0433 0.0427 0.0423 0.0419 0.0416 

[TRAIN] Epoch[1](2251/114412); Loss: 0.057416; Backpropagation: 0.2956 sec; Batch: 2.1206 sec
0.1477 0.1203 0.0868 0.0713 0.0647 0.0505 0.0477 0.0436 0.0392 0.0376 0.0364 0.0356 0.0350 0.0344 0.0341 0.0338 

[TRAIN] Epoch[1](2252/114412); Loss: 0.068717; Backpropagation: 0.2957 sec; Batch: 2.1180 sec
0.1314 0.1132 0.0826 0.0727 0.0693 0.0649 0.0618 0.0594 0.0580 0.0568 0.0561 0.0556 0.0550 0.0546 0.0542 0.0540 

[TRAIN] Epoch[1](2253/114412); Loss: 0.063293; Backpropagation: 0.2955 sec; Batch: 2.1215 sec
0.1124 0.0954 0.0824 0.0693 0.0643 0.0613 0.0583 0.0555 0.0541 0.0532 0.0522 0.0517 0.0513 0.0508 0.0504 0.0501 

[TRAIN] Epoch[1](2254/114412); Loss: 0.052669; Backpropagation: 0.2954 sec; Batch: 2.1178 sec
0.0838 0.0733 0.0656 0.0571 0.0546 0.0514 0.0498 0.0479 0.0468 0.0460 0.0453 0.0448 0.0444 0.0442 0.0440 0.0439 

[TRAIN] Epoch[1](2255/114412); Loss: 0.056378; Backpropagation: 0.2951 sec; Batch: 2.0818 sec
0.0920 0.0817 0.0752 0.0657 0.0591 0.0559 0.0517 0.0498 0.0485 0.0474 0.0468 0.0464 0.0461 0.0457 0.0453 0.0449 

[TRAIN] Epoch[1](2256/114412); Loss: 0.070356; Backpropagation: 0.2956 sec; Batch: 2.1225 sec
0.1320 0.1124 0.0918 0.0810 0.0751 0.0686 0.0644 0.0610 0.0586 0.0569 0.0557 0.0547 0.0541 0.0535 0.0530 0.0527 

[TRAIN] Epoch[1](2257/114412); Loss: 0.069225; Backpropagation: 0.2954 sec; Batch: 2.1207 sec
0.1207 0.1124 0.0859 0.0740 0.0695 0.0667 0.0636 0.0616 0.0598 0.0582 0.0575 0.0566 0.0561 0.0555 0.0549 0.0545 

[TRAIN] Epoch[1](2258/114412); Loss: 0.081688; Backpropagation: 0.2952 sec; Batch: 2.1324 sec
0.1350 0.1146 0.1006 0.0893 0.0843 0.0797 0.0763 0.0742 0.0726 0.0713 0.0701 0.0692 0.0684 0.0677 0.0671 0.0666 

[TRAIN] Epoch[1](2259/114412); Loss: 0.080849; Backpropagation: 0.2948 sec; Batch: 2.0810 sec
0.1518 0.1361 0.1002 0.0867 0.0805 0.0770 0.0729 0.0708 0.0694 0.0672 0.0656 0.0646 0.0637 0.0629 0.0624 0.0619 

[TRAIN] Epoch[1](2260/114412); Loss: 0.072791; Backpropagation: 0.2952 sec; Batch: 2.1176 sec
0.1449 0.1248 0.1001 0.0860 0.0748 0.0714 0.0667 0.0632 0.0596 0.0577 0.0557 0.0542 0.0531 0.0516 0.0509 0.0500 

[TRAIN] Epoch[1](2261/114412); Loss: 0.058192; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.0996 0.0847 0.0732 0.0631 0.0595 0.0564 0.0534 0.0518 0.0506 0.0497 0.0492 0.0487 0.0481 0.0479 0.0477 0.0475 

[TRAIN] Epoch[1](2262/114412); Loss: 0.047734; Backpropagation: 0.2956 sec; Batch: 2.1209 sec
0.0984 0.0803 0.0606 0.0533 0.0473 0.0443 0.0417 0.0405 0.0392 0.0384 0.0378 0.0371 0.0366 0.0363 0.0361 0.0357 

[TRAIN] Epoch[1](2263/114412); Loss: 0.052832; Backpropagation: 0.2948 sec; Batch: 2.1208 sec
0.0986 0.0818 0.0658 0.0576 0.0552 0.0505 0.0475 0.0462 0.0447 0.0439 0.0434 0.0427 0.0422 0.0420 0.0417 0.0415 

[TRAIN] Epoch[1](2264/114412); Loss: 0.082836; Backpropagation: 0.2953 sec; Batch: 2.1017 sec
0.1406 0.1162 0.1017 0.0907 0.0839 0.0794 0.0770 0.0748 0.0730 0.0717 0.0707 0.0700 0.0695 0.0691 0.0686 0.0684 

[TRAIN] Epoch[1](2265/114412); Loss: 0.063170; Backpropagation: 0.2977 sec; Batch: 2.1038 sec
0.1409 0.1182 0.0971 0.0763 0.0651 0.0583 0.0535 0.0500 0.0475 0.0462 0.0448 0.0438 0.0431 0.0424 0.0419 0.0416 

[TRAIN] Epoch[1](2266/114412); Loss: 0.090397; Backpropagation: 0.3011 sec; Batch: 2.1255 sec
0.2019 0.1834 0.1396 0.1258 0.0969 0.0880 0.0693 0.0659 0.0645 0.0628 0.0608 0.0591 0.0580 0.0573 0.0567 0.0563 

[TRAIN] Epoch[1](2267/114412); Loss: 0.041852; Backpropagation: 0.2980 sec; Batch: 2.1264 sec
0.0722 0.0614 0.0548 0.0500 0.0453 0.0429 0.0396 0.0379 0.0362 0.0349 0.0341 0.0333 0.0325 0.0319 0.0314 0.0311 

[TRAIN] Epoch[1](2268/114412); Loss: 0.065602; Backpropagation: 0.2949 sec; Batch: 2.0825 sec
0.1423 0.1204 0.0882 0.0781 0.0660 0.0621 0.0571 0.0545 0.0515 0.0497 0.0488 0.0475 0.0466 0.0460 0.0454 0.0452 

[TRAIN] Epoch[1](2269/114412); Loss: 0.092364; Backpropagation: 0.2954 sec; Batch: 2.1216 sec
0.1712 0.1509 0.1262 0.1084 0.0936 0.0872 0.0823 0.0790 0.0767 0.0752 0.0737 0.0724 0.0712 0.0706 0.0699 0.0691 

[TRAIN] Epoch[1](2270/114412); Loss: 0.053973; Backpropagation: 0.2955 sec; Batch: 2.1251 sec
0.0982 0.0865 0.0754 0.0687 0.0591 0.0558 0.0491 0.0470 0.0436 0.0427 0.0417 0.0406 0.0396 0.0390 0.0385 0.0382 

[TRAIN] Epoch[1](2271/114412); Loss: 0.102777; Backpropagation: 0.2955 sec; Batch: 2.1230 sec
0.1738 0.1596 0.1386 0.1257 0.1137 0.1040 0.0960 0.0912 0.0860 0.0825 0.0807 0.0798 0.0791 0.0784 0.0778 0.0775 

[TRAIN] Epoch[1](2272/114412); Loss: 0.064578; Backpropagation: 0.2954 sec; Batch: 2.1244 sec
0.1395 0.1241 0.0972 0.0876 0.0717 0.0651 0.0538 0.0500 0.0474 0.0457 0.0443 0.0425 0.0418 0.0413 0.0407 0.0404 

[TRAIN] Epoch[1](2273/114412); Loss: 0.059004; Backpropagation: 0.2980 sec; Batch: 2.1246 sec
0.1090 0.0960 0.0777 0.0684 0.0596 0.0564 0.0531 0.0513 0.0496 0.0479 0.0470 0.0465 0.0458 0.0455 0.0452 0.0449 

[TRAIN] Epoch[1](2274/114412); Loss: 0.038824; Backpropagation: 0.2952 sec; Batch: 2.0817 sec
0.0760 0.0629 0.0481 0.0443 0.0393 0.0367 0.0341 0.0333 0.0320 0.0314 0.0308 0.0306 0.0305 0.0304 0.0303 0.0304 

[TRAIN] Epoch[1](2275/114412); Loss: 0.093754; Backpropagation: 0.2949 sec; Batch: 2.1258 sec
0.1709 0.1652 0.1385 0.1248 0.1054 0.0989 0.0864 0.0819 0.0760 0.0722 0.0688 0.0658 0.0640 0.0618 0.0604 0.0591 

[TRAIN] Epoch[1](2276/114412); Loss: 0.091718; Backpropagation: 0.2955 sec; Batch: 2.1193 sec
0.1444 0.1346 0.1194 0.1091 0.1030 0.0964 0.0908 0.0860 0.0818 0.0780 0.0756 0.0738 0.0715 0.0692 0.0681 0.0658 

[TRAIN] Epoch[1](2277/114412); Loss: 0.084006; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.1706 0.1456 0.1196 0.0996 0.0868 0.0810 0.0743 0.0709 0.0666 0.0652 0.0628 0.0619 0.0611 0.0600 0.0593 0.0588 

[TRAIN] Epoch[1](2278/114412); Loss: 0.057695; Backpropagation: 0.2952 sec; Batch: 2.1221 sec
0.1155 0.1059 0.0866 0.0738 0.0593 0.0540 0.0487 0.0466 0.0443 0.0427 0.0420 0.0414 0.0410 0.0407 0.0404 0.0401 

[TRAIN] Epoch[1](2279/114412); Loss: 0.079797; Backpropagation: 0.2954 sec; Batch: 2.1213 sec
0.1377 0.1213 0.1002 0.0924 0.0838 0.0788 0.0747 0.0722 0.0690 0.0673 0.0654 0.0641 0.0632 0.0627 0.0622 0.0617 

[TRAIN] Epoch[1](2280/114412); Loss: 0.046164; Backpropagation: 0.2982 sec; Batch: 2.1271 sec
0.1194 0.0922 0.0666 0.0484 0.0427 0.0401 0.0368 0.0351 0.0340 0.0331 0.0325 0.0321 0.0318 0.0315 0.0313 0.0311 

[TRAIN] Epoch[1](2281/114412); Loss: 0.062234; Backpropagation: 0.2953 sec; Batch: 2.1231 sec
0.1277 0.1004 0.0799 0.0685 0.0639 0.0578 0.0544 0.0529 0.0515 0.0501 0.0495 0.0489 0.0482 0.0477 0.0474 0.0469 

[TRAIN] Epoch[1](2282/114412); Loss: 0.067807; Backpropagation: 0.2958 sec; Batch: 2.1219 sec
0.1260 0.1029 0.0847 0.0765 0.0702 0.0661 0.0625 0.0601 0.0578 0.0565 0.0553 0.0543 0.0537 0.0532 0.0527 0.0524 

[TRAIN] Epoch[1](2283/114412); Loss: 0.088034; Backpropagation: 0.2982 sec; Batch: 2.1292 sec
0.1604 0.1399 0.1204 0.1033 0.0922 0.0848 0.0786 0.0752 0.0731 0.0708 0.0699 0.0692 0.0684 0.0678 0.0675 0.0671 

[TRAIN] Epoch[1](2284/114412); Loss: 0.054650; Backpropagation: 0.2956 sec; Batch: 2.1260 sec
0.1242 0.1129 0.0684 0.0576 0.0533 0.0486 0.0460 0.0445 0.0425 0.0414 0.0406 0.0398 0.0392 0.0387 0.0384 0.0384 

[TRAIN] Epoch[1](2285/114412); Loss: 0.074203; Backpropagation: 0.2978 sec; Batch: 2.1231 sec
0.1392 0.1287 0.1003 0.0862 0.0761 0.0698 0.0647 0.0623 0.0603 0.0591 0.0580 0.0574 0.0568 0.0564 0.0561 0.0558 

[TRAIN] Epoch[1](2286/114412); Loss: 0.073967; Backpropagation: 0.2981 sec; Batch: 2.1218 sec
0.1130 0.1032 0.0889 0.0826 0.0752 0.0725 0.0699 0.0679 0.0662 0.0654 0.0643 0.0639 0.0633 0.0627 0.0625 0.0621 

[TRAIN] Epoch[1](2287/114412); Loss: 0.069188; Backpropagation: 0.2953 sec; Batch: 2.0844 sec
0.1353 0.1215 0.0910 0.0792 0.0703 0.0649 0.0613 0.0585 0.0570 0.0549 0.0540 0.0532 0.0524 0.0518 0.0511 0.0505 

[TRAIN] Epoch[1](2288/114412); Loss: 0.060983; Backpropagation: 0.3007 sec; Batch: 2.1294 sec
0.1279 0.1179 0.0839 0.0799 0.0659 0.0616 0.0493 0.0487 0.0470 0.0454 0.0434 0.0421 0.0416 0.0407 0.0403 0.0400 

[TRAIN] Epoch[1](2289/114412); Loss: 0.085947; Backpropagation: 0.2955 sec; Batch: 2.1188 sec
0.1713 0.1646 0.1289 0.1208 0.0896 0.0843 0.0703 0.0674 0.0650 0.0639 0.0608 0.0594 0.0594 0.0569 0.0564 0.0561 

[TRAIN] Epoch[1](2290/114412); Loss: 0.091980; Backpropagation: 0.2950 sec; Batch: 2.1235 sec
0.1684 0.1572 0.1340 0.1168 0.0972 0.0911 0.0814 0.0784 0.0736 0.0717 0.0698 0.0686 0.0672 0.0663 0.0653 0.0648 

[TRAIN] Epoch[1](2291/114412); Loss: 0.078420; Backpropagation: 0.2950 sec; Batch: 2.1361 sec
0.1507 0.1262 0.1035 0.0905 0.0797 0.0756 0.0696 0.0673 0.0656 0.0637 0.0628 0.0617 0.0607 0.0598 0.0589 0.0584 

[TRAIN] Epoch[1](2292/114412); Loss: 0.071587; Backpropagation: 0.2950 sec; Batch: 2.1209 sec
0.1313 0.1066 0.0894 0.0836 0.0703 0.0677 0.0638 0.0626 0.0614 0.0599 0.0594 0.0589 0.0581 0.0577 0.0575 0.0571 

[TRAIN] Epoch[1](2293/114412); Loss: 0.070951; Backpropagation: 0.2955 sec; Batch: 2.1221 sec
0.1172 0.1035 0.0846 0.0762 0.0727 0.0685 0.0664 0.0651 0.0626 0.0616 0.0606 0.0599 0.0595 0.0591 0.0588 0.0587 

[TRAIN] Epoch[1](2294/114412); Loss: 0.075445; Backpropagation: 0.2947 sec; Batch: 2.1216 sec
0.1770 0.1650 0.1241 0.1083 0.0767 0.0688 0.0597 0.0539 0.0513 0.0498 0.0475 0.0462 0.0457 0.0449 0.0443 0.0440 

[TRAIN] Epoch[1](2295/114412); Loss: 0.073325; Backpropagation: 0.2958 sec; Batch: 2.1225 sec
0.1160 0.1092 0.0870 0.0825 0.0749 0.0706 0.0675 0.0657 0.0644 0.0636 0.0630 0.0624 0.0621 0.0618 0.0614 0.0612 

[TRAIN] Epoch[1](2296/114412); Loss: 0.062718; Backpropagation: 0.2955 sec; Batch: 2.0843 sec
0.1064 0.0916 0.0766 0.0708 0.0653 0.0611 0.0579 0.0568 0.0551 0.0539 0.0531 0.0522 0.0516 0.0508 0.0503 0.0500 

[TRAIN] Epoch[1](2297/114412); Loss: 0.078623; Backpropagation: 0.2956 sec; Batch: 2.1207 sec
0.1371 0.1305 0.1027 0.0933 0.0800 0.0755 0.0706 0.0683 0.0671 0.0649 0.0634 0.0623 0.0612 0.0606 0.0604 0.0600 

[TRAIN] Epoch[1](2298/114412); Loss: 0.076280; Backpropagation: 0.2995 sec; Batch: 2.0870 sec
0.1246 0.1163 0.0985 0.0902 0.0796 0.0759 0.0707 0.0681 0.0651 0.0638 0.0628 0.0619 0.0614 0.0609 0.0605 0.0601 

[TRAIN] Epoch[1](2299/114412); Loss: 0.059538; Backpropagation: 0.2953 sec; Batch: 2.1243 sec
0.1405 0.1153 0.0819 0.0722 0.0590 0.0544 0.0485 0.0461 0.0444 0.0437 0.0424 0.0417 0.0412 0.0409 0.0404 0.0400 

[TRAIN] Epoch[1](2300/114412); Loss: 0.049244; Backpropagation: 0.2951 sec; Batch: 2.0894 sec
0.1183 0.0932 0.0653 0.0603 0.0517 0.0460 0.0428 0.0388 0.0371 0.0357 0.0345 0.0338 0.0331 0.0327 0.0324 0.0321 

[TRAIN] Epoch[1](2301/114412); Loss: 0.064146; Backpropagation: 0.2950 sec; Batch: 2.1214 sec
0.1090 0.1066 0.0834 0.0739 0.0680 0.0651 0.0597 0.0577 0.0541 0.0529 0.0512 0.0501 0.0493 0.0487 0.0484 0.0481 

[TRAIN] Epoch[1](2302/114412); Loss: 0.078398; Backpropagation: 0.2958 sec; Batch: 2.1214 sec
0.1624 0.1540 0.1102 0.1055 0.0773 0.0725 0.0655 0.0638 0.0601 0.0582 0.0567 0.0549 0.0540 0.0534 0.0529 0.0527 

[TRAIN] Epoch[1](2303/114412); Loss: 0.095440; Backpropagation: 0.2955 sec; Batch: 2.1228 sec
0.1378 0.1252 0.1106 0.1032 0.0971 0.0919 0.0907 0.0888 0.0874 0.0866 0.0858 0.0854 0.0847 0.0843 0.0839 0.0837 

[TRAIN] Epoch[1](2304/114412); Loss: 0.052588; Backpropagation: 0.2955 sec; Batch: 2.1195 sec
0.0911 0.0826 0.0681 0.0590 0.0558 0.0514 0.0483 0.0464 0.0447 0.0436 0.0428 0.0422 0.0417 0.0415 0.0411 0.0410 

[TRAIN] Epoch[1](2305/114412); Loss: 0.097642; Backpropagation: 0.2954 sec; Batch: 2.1260 sec
0.1685 0.1656 0.1438 0.1303 0.1152 0.1069 0.0941 0.0857 0.0805 0.0769 0.0705 0.0686 0.0662 0.0639 0.0631 0.0625 

[TRAIN] Epoch[1](2306/114412); Loss: 0.069453; Backpropagation: 0.2957 sec; Batch: 2.0841 sec
0.1224 0.1095 0.0884 0.0832 0.0719 0.0682 0.0631 0.0614 0.0586 0.0573 0.0562 0.0554 0.0546 0.0540 0.0537 0.0534 

[TRAIN] Epoch[1](2307/114412); Loss: 0.090357; Backpropagation: 0.2956 sec; Batch: 2.1282 sec
0.1784 0.1665 0.1307 0.1217 0.0943 0.0901 0.0778 0.0743 0.0689 0.0673 0.0652 0.0640 0.0628 0.0619 0.0613 0.0606 

[TRAIN] Epoch[1](2308/114412); Loss: 0.070898; Backpropagation: 0.2957 sec; Batch: 2.1220 sec
0.1198 0.1070 0.0933 0.0809 0.0734 0.0711 0.0677 0.0626 0.0609 0.0587 0.0579 0.0574 0.0566 0.0561 0.0556 0.0554 

[TRAIN] Epoch[1](2309/114412); Loss: 0.058921; Backpropagation: 0.2977 sec; Batch: 2.0849 sec
0.1053 0.0972 0.0830 0.0698 0.0636 0.0586 0.0535 0.0504 0.0483 0.0473 0.0459 0.0451 0.0444 0.0438 0.0435 0.0431 

[TRAIN] Epoch[1](2310/114412); Loss: 0.054167; Backpropagation: 0.2953 sec; Batch: 2.1179 sec
0.1096 0.0950 0.0670 0.0588 0.0546 0.0492 0.0477 0.0464 0.0450 0.0439 0.0429 0.0423 0.0417 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](2311/114412); Loss: 0.069946; Backpropagation: 0.2953 sec; Batch: 2.1234 sec
0.1137 0.1032 0.0847 0.0767 0.0702 0.0673 0.0642 0.0625 0.0617 0.0609 0.0600 0.0596 0.0590 0.0586 0.0585 0.0583 

[TRAIN] Epoch[1](2312/114412); Loss: 0.053992; Backpropagation: 0.2956 sec; Batch: 2.0823 sec
0.1091 0.1039 0.0789 0.0677 0.0528 0.0503 0.0469 0.0448 0.0416 0.0406 0.0392 0.0384 0.0379 0.0374 0.0372 0.0369 

[TRAIN] Epoch[1](2313/114412); Loss: 0.069606; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.1200 0.1098 0.0888 0.0826 0.0713 0.0682 0.0647 0.0610 0.0590 0.0577 0.0567 0.0557 0.0550 0.0548 0.0542 0.0541 

[TRAIN] Epoch[1](2314/114412); Loss: 0.088639; Backpropagation: 0.2954 sec; Batch: 2.0836 sec
0.1528 0.1420 0.1185 0.1112 0.0960 0.0898 0.0794 0.0759 0.0727 0.0713 0.0700 0.0691 0.0681 0.0675 0.0671 0.0668 

[TRAIN] Epoch[1](2315/114412); Loss: 0.090836; Backpropagation: 0.2981 sec; Batch: 2.1229 sec
0.1776 0.1749 0.1284 0.1218 0.0933 0.0888 0.0740 0.0720 0.0695 0.0677 0.0664 0.0654 0.0641 0.0636 0.0632 0.0627 

[TRAIN] Epoch[1](2316/114412); Loss: 0.069628; Backpropagation: 0.2981 sec; Batch: 2.1208 sec
0.1237 0.1089 0.0884 0.0817 0.0728 0.0683 0.0643 0.0616 0.0589 0.0575 0.0564 0.0556 0.0549 0.0542 0.0538 0.0531 

[TRAIN] Epoch[1](2317/114412); Loss: 0.077178; Backpropagation: 0.2981 sec; Batch: 2.1251 sec
0.1194 0.1074 0.0913 0.0820 0.0781 0.0752 0.0729 0.0714 0.0696 0.0684 0.0678 0.0671 0.0665 0.0661 0.0659 0.0657 

[TRAIN] Epoch[1](2318/114412); Loss: 0.082660; Backpropagation: 0.2960 sec; Batch: 2.1235 sec
0.1574 0.1446 0.1198 0.1112 0.0923 0.0892 0.0732 0.0719 0.0619 0.0605 0.0607 0.0604 0.0573 0.0549 0.0538 0.0532 

[TRAIN] Epoch[1](2319/114412); Loss: 0.069806; Backpropagation: 0.2975 sec; Batch: 2.1272 sec
0.1265 0.1052 0.0886 0.0817 0.0753 0.0698 0.0640 0.0615 0.0598 0.0582 0.0565 0.0556 0.0546 0.0538 0.0531 0.0525 

[TRAIN] Epoch[1](2320/114412); Loss: 0.075118; Backpropagation: 0.2957 sec; Batch: 2.0835 sec
0.1727 0.1421 0.1139 0.0941 0.0777 0.0726 0.0641 0.0609 0.0538 0.0523 0.0514 0.0505 0.0498 0.0490 0.0487 0.0482 

[TRAIN] Epoch[1](2321/114412); Loss: 0.061248; Backpropagation: 0.2955 sec; Batch: 2.1294 sec
0.1168 0.1035 0.0811 0.0738 0.0646 0.0611 0.0546 0.0528 0.0491 0.0480 0.0473 0.0465 0.0459 0.0454 0.0449 0.0446 

[TRAIN] Epoch[1](2322/114412); Loss: 0.059207; Backpropagation: 0.2953 sec; Batch: 2.1245 sec
0.1126 0.1109 0.0857 0.0742 0.0617 0.0566 0.0514 0.0481 0.0460 0.0448 0.0438 0.0432 0.0426 0.0422 0.0419 0.0416 

[TRAIN] Epoch[1](2323/114412); Loss: 0.054142; Backpropagation: 0.2959 sec; Batch: 2.1241 sec
0.1096 0.0810 0.0696 0.0612 0.0546 0.0510 0.0484 0.0464 0.0451 0.0442 0.0436 0.0431 0.0426 0.0423 0.0419 0.0417 

[TRAIN] Epoch[1](2324/114412); Loss: 0.072737; Backpropagation: 0.2955 sec; Batch: 2.1202 sec
0.1326 0.1172 0.0892 0.0810 0.0759 0.0689 0.0658 0.0643 0.0618 0.0608 0.0596 0.0586 0.0577 0.0572 0.0568 0.0565 

[TRAIN] Epoch[1](2325/114412); Loss: 0.062329; Backpropagation: 0.2960 sec; Batch: 2.1224 sec
0.1543 0.1237 0.1006 0.0732 0.0605 0.0541 0.0519 0.0494 0.0462 0.0434 0.0425 0.0412 0.0398 0.0393 0.0388 0.0384 

[TRAIN] Epoch[1](2326/114412); Loss: 0.066815; Backpropagation: 0.2955 sec; Batch: 2.1204 sec
0.1138 0.1007 0.0855 0.0803 0.0719 0.0682 0.0620 0.0596 0.0556 0.0545 0.0544 0.0537 0.0527 0.0523 0.0520 0.0518 

[TRAIN] Epoch[1](2327/114412); Loss: 0.060561; Backpropagation: 0.2955 sec; Batch: 2.1254 sec
0.1093 0.0928 0.0745 0.0685 0.0628 0.0590 0.0558 0.0539 0.0517 0.0507 0.0499 0.0491 0.0484 0.0479 0.0475 0.0473 

[TRAIN] Epoch[1](2328/114412); Loss: 0.062084; Backpropagation: 0.2982 sec; Batch: 2.1335 sec
0.1078 0.1050 0.0761 0.0692 0.0616 0.0590 0.0573 0.0554 0.0531 0.0520 0.0510 0.0504 0.0496 0.0490 0.0485 0.0483 

[TRAIN] Epoch[1](2329/114412); Loss: 0.091794; Backpropagation: 0.2955 sec; Batch: 2.1267 sec
0.1520 0.1431 0.1169 0.1110 0.0957 0.0929 0.0833 0.0814 0.0779 0.0772 0.0757 0.0737 0.0728 0.0722 0.0716 0.0712 

[TRAIN] Epoch[1](2330/114412); Loss: 0.069068; Backpropagation: 0.2989 sec; Batch: 2.1251 sec
0.1363 0.1193 0.0931 0.0838 0.0701 0.0652 0.0600 0.0574 0.0556 0.0545 0.0530 0.0522 0.0516 0.0513 0.0509 0.0506 

[TRAIN] Epoch[1](2331/114412); Loss: 0.050916; Backpropagation: 0.2962 sec; Batch: 2.1275 sec
0.0905 0.0802 0.0672 0.0565 0.0509 0.0488 0.0463 0.0446 0.0433 0.0424 0.0418 0.0411 0.0407 0.0404 0.0400 0.0399 

[TRAIN] Epoch[1](2332/114412); Loss: 0.043452; Backpropagation: 0.2954 sec; Batch: 2.1195 sec
0.0802 0.0624 0.0554 0.0501 0.0442 0.0421 0.0396 0.0382 0.0373 0.0363 0.0358 0.0353 0.0349 0.0346 0.0344 0.0342 

[TRAIN] Epoch[1](2333/114412); Loss: 0.085969; Backpropagation: 0.2958 sec; Batch: 2.1222 sec
0.1469 0.1352 0.1096 0.1024 0.0897 0.0834 0.0766 0.0743 0.0735 0.0723 0.0705 0.0695 0.0687 0.0682 0.0676 0.0671 

[TRAIN] Epoch[1](2334/114412); Loss: 0.080026; Backpropagation: 0.2956 sec; Batch: 2.0939 sec
0.1273 0.1200 0.0992 0.0896 0.0845 0.0808 0.0761 0.0720 0.0702 0.0685 0.0672 0.0662 0.0655 0.0649 0.0644 0.0639 

[TRAIN] Epoch[1](2335/114412); Loss: 0.069319; Backpropagation: 0.2952 sec; Batch: 2.0820 sec
0.1474 0.1310 0.0999 0.0919 0.0707 0.0645 0.0597 0.0547 0.0524 0.0508 0.0498 0.0487 0.0479 0.0470 0.0464 0.0461 

[TRAIN] Epoch[1](2336/114412); Loss: 0.066297; Backpropagation: 0.2948 sec; Batch: 2.1195 sec
0.1206 0.1088 0.0823 0.0719 0.0663 0.0637 0.0607 0.0579 0.0566 0.0548 0.0540 0.0536 0.0530 0.0525 0.0521 0.0517 

[TRAIN] Epoch[1](2337/114412); Loss: 0.074407; Backpropagation: 0.2957 sec; Batch: 2.1222 sec
0.1252 0.1104 0.0889 0.0800 0.0748 0.0716 0.0687 0.0664 0.0650 0.0642 0.0638 0.0632 0.0625 0.0622 0.0619 0.0616 

[TRAIN] Epoch[1](2338/114412); Loss: 0.081289; Backpropagation: 0.2956 sec; Batch: 2.1256 sec
0.1355 0.1209 0.0953 0.0882 0.0808 0.0767 0.0752 0.0737 0.0720 0.0707 0.0699 0.0693 0.0687 0.0683 0.0679 0.0675 

[TRAIN] Epoch[1](2339/114412); Loss: 0.087128; Backpropagation: 0.2957 sec; Batch: 2.1215 sec
0.1332 0.1253 0.1112 0.1015 0.0923 0.0876 0.0823 0.0787 0.0760 0.0746 0.0736 0.0728 0.0719 0.0714 0.0710 0.0706 

[TRAIN] Epoch[1](2340/114412); Loss: 0.075535; Backpropagation: 0.2951 sec; Batch: 2.1217 sec
0.1457 0.1341 0.0990 0.0910 0.0744 0.0720 0.0665 0.0641 0.0620 0.0593 0.0583 0.0575 0.0569 0.0564 0.0560 0.0556 

[TRAIN] Epoch[1](2341/114412); Loss: 0.059736; Backpropagation: 0.2981 sec; Batch: 2.1259 sec
0.1091 0.0934 0.0755 0.0688 0.0612 0.0578 0.0550 0.0522 0.0507 0.0495 0.0485 0.0478 0.0472 0.0468 0.0464 0.0460 

[TRAIN] Epoch[1](2342/114412); Loss: 0.086846; Backpropagation: 0.2966 sec; Batch: 2.1413 sec
0.1562 0.1415 0.1067 0.1006 0.0882 0.0838 0.0791 0.0759 0.0733 0.0721 0.0709 0.0696 0.0689 0.0682 0.0676 0.0672 

[TRAIN] Epoch[1](2343/114412); Loss: 0.056501; Backpropagation: 0.2957 sec; Batch: 2.1251 sec
0.1176 0.1054 0.0787 0.0710 0.0543 0.0516 0.0497 0.0464 0.0434 0.0425 0.0417 0.0411 0.0406 0.0402 0.0400 0.0398 

[TRAIN] Epoch[1](2344/114412); Loss: 0.072165; Backpropagation: 0.2957 sec; Batch: 2.1084 sec
0.1353 0.1234 0.0959 0.0854 0.0755 0.0698 0.0635 0.0608 0.0589 0.0573 0.0565 0.0556 0.0549 0.0545 0.0538 0.0534 

[TRAIN] Epoch[1](2345/114412); Loss: 0.081114; Backpropagation: 0.2953 sec; Batch: 2.1182 sec
0.1415 0.1203 0.0998 0.0885 0.0823 0.0776 0.0745 0.0722 0.0705 0.0693 0.0684 0.0677 0.0670 0.0665 0.0660 0.0656 

[TRAIN] Epoch[1](2346/114412); Loss: 0.072655; Backpropagation: 0.2959 sec; Batch: 2.1216 sec
0.1179 0.1050 0.0893 0.0803 0.0738 0.0704 0.0675 0.0654 0.0638 0.0628 0.0623 0.0619 0.0611 0.0606 0.0603 0.0600 

[TRAIN] Epoch[1](2347/114412); Loss: 0.053618; Backpropagation: 0.2954 sec; Batch: 2.1243 sec
0.1050 0.0903 0.0655 0.0586 0.0550 0.0508 0.0478 0.0459 0.0448 0.0438 0.0429 0.0424 0.0418 0.0414 0.0411 0.0409 

[TRAIN] Epoch[1](2348/114412); Loss: 0.092369; Backpropagation: 0.2957 sec; Batch: 2.1268 sec
0.1454 0.1334 0.1181 0.1023 0.0932 0.0906 0.0862 0.0835 0.0821 0.0803 0.0790 0.0782 0.0776 0.0767 0.0759 0.0754 

[TRAIN] Epoch[1](2349/114412); Loss: 0.078867; Backpropagation: 0.2982 sec; Batch: 2.1251 sec
0.1443 0.1323 0.1048 0.0933 0.0810 0.0757 0.0706 0.0677 0.0654 0.0636 0.0623 0.0614 0.0608 0.0601 0.0596 0.0590 

[TRAIN] Epoch[1](2350/114412); Loss: 0.070887; Backpropagation: 0.2956 sec; Batch: 2.1209 sec
0.1140 0.1018 0.0873 0.0807 0.0732 0.0697 0.0662 0.0640 0.0623 0.0614 0.0605 0.0597 0.0591 0.0585 0.0580 0.0577 

[TRAIN] Epoch[1](2351/114412); Loss: 0.083918; Backpropagation: 0.2954 sec; Batch: 2.1208 sec
0.1672 0.1519 0.1116 0.1001 0.0764 0.0755 0.0705 0.0676 0.0665 0.0657 0.0652 0.0652 0.0650 0.0648 0.0648 0.0646 

[TRAIN] Epoch[1](2352/114412); Loss: 0.069807; Backpropagation: 0.2956 sec; Batch: 2.1222 sec
0.1113 0.1004 0.0839 0.0772 0.0699 0.0676 0.0651 0.0634 0.0623 0.0611 0.0603 0.0597 0.0592 0.0588 0.0585 0.0581 

[TRAIN] Epoch[1](2353/114412); Loss: 0.068833; Backpropagation: 0.2961 sec; Batch: 2.1263 sec
0.1473 0.1281 0.0932 0.0797 0.0710 0.0646 0.0599 0.0567 0.0546 0.0529 0.0512 0.0501 0.0491 0.0483 0.0476 0.0471 

[TRAIN] Epoch[1](2354/114412); Loss: 0.078677; Backpropagation: 0.2954 sec; Batch: 2.1248 sec
0.1399 0.1284 0.1026 0.0965 0.0848 0.0808 0.0720 0.0690 0.0640 0.0628 0.0618 0.0609 0.0598 0.0590 0.0585 0.0580 

[TRAIN] Epoch[1](2355/114412); Loss: 0.100020; Backpropagation: 0.2955 sec; Batch: 2.1220 sec
0.1487 0.1404 0.1200 0.1120 0.1005 0.0970 0.0932 0.0911 0.0897 0.0890 0.0879 0.0872 0.0866 0.0861 0.0857 0.0853 

[TRAIN] Epoch[1](2356/114412); Loss: 0.062551; Backpropagation: 0.2958 sec; Batch: 2.1217 sec
0.1625 0.1566 0.1075 0.0960 0.0640 0.0557 0.0432 0.0393 0.0369 0.0361 0.0350 0.0342 0.0337 0.0336 0.0332 0.0331 

[TRAIN] Epoch[1](2357/114412); Loss: 0.076666; Backpropagation: 0.2951 sec; Batch: 2.1253 sec
0.1176 0.1081 0.0949 0.0876 0.0795 0.0761 0.0721 0.0701 0.0685 0.0670 0.0659 0.0649 0.0642 0.0638 0.0633 0.0630 

[TRAIN] Epoch[1](2358/114412); Loss: 0.053720; Backpropagation: 0.2952 sec; Batch: 2.1242 sec
0.0952 0.0842 0.0656 0.0596 0.0552 0.0524 0.0495 0.0475 0.0462 0.0451 0.0443 0.0437 0.0432 0.0429 0.0426 0.0424 

[TRAIN] Epoch[1](2359/114412); Loss: 0.080621; Backpropagation: 0.2953 sec; Batch: 2.1219 sec
0.1547 0.1509 0.1057 0.1007 0.0786 0.0737 0.0702 0.0685 0.0656 0.0634 0.0617 0.0606 0.0598 0.0591 0.0586 0.0581 

[TRAIN] Epoch[1](2360/114412); Loss: 0.058194; Backpropagation: 0.2957 sec; Batch: 2.1215 sec
0.0986 0.0844 0.0700 0.0638 0.0599 0.0569 0.0545 0.0528 0.0513 0.0501 0.0494 0.0487 0.0483 0.0478 0.0475 0.0471 

[TRAIN] Epoch[1](2361/114412); Loss: 0.079481; Backpropagation: 0.2952 sec; Batch: 2.1270 sec
0.1524 0.1434 0.1065 0.0979 0.0799 0.0749 0.0684 0.0664 0.0653 0.0625 0.0609 0.0600 0.0592 0.0585 0.0579 0.0576 

[TRAIN] Epoch[1](2362/114412); Loss: 0.053607; Backpropagation: 0.2958 sec; Batch: 2.1252 sec
0.1105 0.0860 0.0680 0.0589 0.0528 0.0502 0.0477 0.0457 0.0443 0.0434 0.0426 0.0421 0.0418 0.0414 0.0413 0.0411 

[TRAIN] Epoch[1](2363/114412); Loss: 0.091993; Backpropagation: 0.2950 sec; Batch: 2.1238 sec
0.1618 0.1419 0.1267 0.1190 0.1090 0.0894 0.0804 0.0769 0.0749 0.0730 0.0715 0.0707 0.0702 0.0694 0.0688 0.0683 

[TRAIN] Epoch[1](2364/114412); Loss: 0.096192; Backpropagation: 0.2955 sec; Batch: 2.1227 sec
0.1512 0.1409 0.1129 0.1036 0.0964 0.0933 0.0898 0.0877 0.0860 0.0848 0.0836 0.0829 0.0823 0.0817 0.0812 0.0807 

[TRAIN] Epoch[1](2365/114412); Loss: 0.072663; Backpropagation: 0.2949 sec; Batch: 2.1251 sec
0.1381 0.1238 0.0985 0.0859 0.0713 0.0675 0.0635 0.0609 0.0596 0.0584 0.0572 0.0565 0.0559 0.0555 0.0552 0.0548 

[TRAIN] Epoch[1](2366/114412); Loss: 0.040602; Backpropagation: 0.2973 sec; Batch: 2.1038 sec
0.0818 0.0729 0.0517 0.0451 0.0419 0.0381 0.0351 0.0339 0.0331 0.0324 0.0316 0.0310 0.0307 0.0303 0.0301 0.0299 

[TRAIN] Epoch[1](2367/114412); Loss: 0.068435; Backpropagation: 0.2959 sec; Batch: 2.1197 sec
0.1244 0.1049 0.0817 0.0750 0.0689 0.0650 0.0625 0.0607 0.0592 0.0581 0.0572 0.0564 0.0559 0.0554 0.0550 0.0548 

[TRAIN] Epoch[1](2368/114412); Loss: 0.065298; Backpropagation: 0.2957 sec; Batch: 2.1213 sec
0.1310 0.1198 0.0805 0.0738 0.0631 0.0590 0.0565 0.0548 0.0532 0.0520 0.0513 0.0507 0.0502 0.0498 0.0496 0.0494 

[TRAIN] Epoch[1](2369/114412); Loss: 0.050522; Backpropagation: 0.2979 sec; Batch: 2.1351 sec
0.0986 0.0809 0.0624 0.0569 0.0505 0.0477 0.0447 0.0436 0.0423 0.0415 0.0407 0.0404 0.0400 0.0397 0.0394 0.0392 

[TRAIN] Epoch[1](2370/114412); Loss: 0.084601; Backpropagation: 0.2978 sec; Batch: 2.1226 sec
0.1293 0.1179 0.0946 0.0898 0.0845 0.0811 0.0789 0.0779 0.0770 0.0762 0.0753 0.0751 0.0745 0.0741 0.0738 0.0735 

[TRAIN] Epoch[1](2371/114412); Loss: 0.061099; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1501 0.1394 0.0834 0.0718 0.0515 0.0506 0.0489 0.0460 0.0442 0.0433 0.0425 0.0419 0.0414 0.0411 0.0409 0.0407 

[TRAIN] Epoch[1](2372/114412); Loss: 0.078673; Backpropagation: 0.2908 sec; Batch: 2.1176 sec
0.1219 0.1112 0.0955 0.0865 0.0795 0.0759 0.0739 0.0721 0.0706 0.0693 0.0685 0.0679 0.0671 0.0666 0.0662 0.0659 

[TRAIN] Epoch[1](2373/114412); Loss: 0.080226; Backpropagation: 0.2904 sec; Batch: 2.0762 sec
0.1393 0.1214 0.1055 0.0925 0.0835 0.0777 0.0737 0.0705 0.0681 0.0669 0.0659 0.0651 0.0643 0.0636 0.0630 0.0626 

[TRAIN] Epoch[1](2374/114412); Loss: 0.071712; Backpropagation: 0.2919 sec; Batch: 2.1166 sec
0.1245 0.1111 0.0903 0.0825 0.0730 0.0687 0.0661 0.0638 0.0612 0.0599 0.0591 0.0583 0.0580 0.0574 0.0570 0.0565 

[TRAIN] Epoch[1](2375/114412); Loss: 0.057285; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1213 0.1032 0.0766 0.0658 0.0572 0.0530 0.0501 0.0481 0.0459 0.0444 0.0435 0.0427 0.0419 0.0414 0.0408 0.0405 

[TRAIN] Epoch[1](2376/114412); Loss: 0.060327; Backpropagation: 0.2908 sec; Batch: 2.1214 sec
0.1158 0.1037 0.0839 0.0724 0.0639 0.0587 0.0541 0.0506 0.0487 0.0472 0.0463 0.0454 0.0447 0.0439 0.0433 0.0428 

[TRAIN] Epoch[1](2377/114412); Loss: 0.055644; Backpropagation: 0.2914 sec; Batch: 2.1269 sec
0.1090 0.1014 0.0816 0.0663 0.0586 0.0524 0.0487 0.0467 0.0445 0.0428 0.0417 0.0406 0.0398 0.0392 0.0387 0.0384 

[TRAIN] Epoch[1](2378/114412); Loss: 0.057704; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1084 0.0914 0.0739 0.0652 0.0575 0.0548 0.0522 0.0503 0.0487 0.0477 0.0468 0.0461 0.0455 0.0452 0.0449 0.0446 

[TRAIN] Epoch[1](2379/114412); Loss: 0.067576; Backpropagation: 0.2913 sec; Batch: 2.1262 sec
0.1433 0.1184 0.0815 0.0731 0.0661 0.0618 0.0583 0.0571 0.0553 0.0542 0.0533 0.0526 0.0521 0.0516 0.0513 0.0512 

[TRAIN] Epoch[1](2380/114412); Loss: 0.050586; Backpropagation: 0.2911 sec; Batch: 2.1004 sec
0.0946 0.0839 0.0647 0.0567 0.0519 0.0482 0.0453 0.0439 0.0424 0.0414 0.0407 0.0400 0.0394 0.0390 0.0387 0.0385 

[TRAIN] Epoch[1](2381/114412); Loss: 0.078556; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1512 0.1355 0.1035 0.0919 0.0795 0.0752 0.0693 0.0668 0.0645 0.0630 0.0617 0.0606 0.0596 0.0588 0.0582 0.0576 

[TRAIN] Epoch[1](2382/114412); Loss: 0.092278; Backpropagation: 0.2908 sec; Batch: 2.0933 sec
0.1578 0.1481 0.1210 0.1133 0.0937 0.0884 0.0833 0.0806 0.0775 0.0761 0.0748 0.0738 0.0729 0.0722 0.0717 0.0713 

[TRAIN] Epoch[1](2383/114412); Loss: 0.060311; Backpropagation: 0.2908 sec; Batch: 2.0947 sec
0.1179 0.0955 0.0770 0.0689 0.0612 0.0573 0.0536 0.0518 0.0501 0.0492 0.0484 0.0477 0.0471 0.0467 0.0464 0.0461 

[TRAIN] Epoch[1](2384/114412); Loss: 0.061834; Backpropagation: 0.2915 sec; Batch: 2.1170 sec
0.1132 0.1001 0.0759 0.0700 0.0634 0.0594 0.0563 0.0545 0.0527 0.0513 0.0502 0.0494 0.0488 0.0483 0.0480 0.0478 

[TRAIN] Epoch[1](2385/114412); Loss: 0.069488; Backpropagation: 0.2909 sec; Batch: 2.1389 sec
0.1247 0.1062 0.0862 0.0761 0.0699 0.0657 0.0631 0.0612 0.0599 0.0588 0.0581 0.0573 0.0566 0.0562 0.0560 0.0557 

[TRAIN] Epoch[1](2386/114412); Loss: 0.091531; Backpropagation: 0.2912 sec; Batch: 2.0773 sec
0.1642 0.1490 0.1199 0.1088 0.0946 0.0870 0.0826 0.0797 0.0762 0.0746 0.0734 0.0723 0.0715 0.0706 0.0703 0.0698 

[TRAIN] Epoch[1](2387/114412); Loss: 0.068060; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1382 0.1172 0.0973 0.0829 0.0707 0.0631 0.0588 0.0562 0.0542 0.0527 0.0515 0.0505 0.0497 0.0491 0.0487 0.0482 

[TRAIN] Epoch[1](2388/114412); Loss: 0.072485; Backpropagation: 0.2912 sec; Batch: 2.1234 sec
0.1470 0.1336 0.1014 0.0928 0.0717 0.0677 0.0612 0.0580 0.0560 0.0552 0.0542 0.0534 0.0526 0.0520 0.0515 0.0513 

[TRAIN] Epoch[1](2389/114412); Loss: 0.087006; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1528 0.1376 0.1144 0.1020 0.0888 0.0832 0.0791 0.0761 0.0739 0.0726 0.0711 0.0698 0.0688 0.0678 0.0673 0.0668 

[TRAIN] Epoch[1](2390/114412); Loss: 0.056408; Backpropagation: 0.2923 sec; Batch: 2.0825 sec
0.1053 0.0981 0.0717 0.0619 0.0569 0.0529 0.0504 0.0486 0.0474 0.0461 0.0453 0.0445 0.0439 0.0435 0.0432 0.0428 

[TRAIN] Epoch[1](2391/114412); Loss: 0.044981; Backpropagation: 0.2906 sec; Batch: 2.0772 sec
0.0961 0.0865 0.0628 0.0513 0.0435 0.0410 0.0382 0.0363 0.0349 0.0344 0.0334 0.0328 0.0324 0.0321 0.0320 0.0318 

[TRAIN] Epoch[1](2392/114412); Loss: 0.064614; Backpropagation: 0.2906 sec; Batch: 2.1311 sec
0.1311 0.1060 0.0843 0.0718 0.0644 0.0597 0.0566 0.0552 0.0538 0.0525 0.0515 0.0506 0.0499 0.0493 0.0488 0.0484 

[TRAIN] Epoch[1](2393/114412); Loss: 0.074147; Backpropagation: 0.2933 sec; Batch: 2.0796 sec
0.1714 0.1594 0.1046 0.0900 0.0765 0.0660 0.0583 0.0561 0.0547 0.0530 0.0515 0.0504 0.0495 0.0488 0.0483 0.0478 

[TRAIN] Epoch[1](2394/114412); Loss: 0.061259; Backpropagation: 0.2912 sec; Batch: 2.1136 sec
0.1167 0.1027 0.0796 0.0708 0.0613 0.0567 0.0550 0.0532 0.0509 0.0497 0.0488 0.0479 0.0473 0.0469 0.0465 0.0462 

[TRAIN] Epoch[1](2395/114412); Loss: 0.058209; Backpropagation: 0.2925 sec; Batch: 2.0872 sec
0.1482 0.1086 0.0805 0.0604 0.0539 0.0500 0.0480 0.0466 0.0449 0.0434 0.0425 0.0419 0.0412 0.0408 0.0404 0.0401 

[TRAIN] Epoch[1](2396/114412); Loss: 0.058651; Backpropagation: 0.2906 sec; Batch: 2.1172 sec
0.1274 0.1157 0.0817 0.0706 0.0622 0.0562 0.0502 0.0464 0.0446 0.0430 0.0416 0.0409 0.0404 0.0396 0.0390 0.0387 

[TRAIN] Epoch[1](2397/114412); Loss: 0.089107; Backpropagation: 0.2906 sec; Batch: 2.0835 sec
0.1761 0.1532 0.1234 0.1041 0.0894 0.0846 0.0781 0.0750 0.0724 0.0705 0.0690 0.0678 0.0666 0.0658 0.0652 0.0647 

[TRAIN] Epoch[1](2398/114412); Loss: 0.074019; Backpropagation: 0.2908 sec; Batch: 2.0775 sec
0.1615 0.1365 0.1031 0.0912 0.0729 0.0677 0.0649 0.0615 0.0581 0.0558 0.0539 0.0527 0.0519 0.0513 0.0508 0.0505 

[TRAIN] Epoch[1](2399/114412); Loss: 0.110846; Backpropagation: 0.2911 sec; Batch: 2.1051 sec
0.2363 0.2052 0.1630 0.1442 0.1172 0.1056 0.0919 0.0872 0.0834 0.0811 0.0793 0.0780 0.0766 0.0757 0.0749 0.0741 

[TRAIN] Epoch[1](2400/114412); Loss: 0.071253; Backpropagation: 0.2908 sec; Batch: 2.0866 sec
0.1672 0.1433 0.1009 0.0900 0.0773 0.0672 0.0592 0.0558 0.0523 0.0501 0.0487 0.0474 0.0463 0.0455 0.0447 0.0443 

[TRAIN] Epoch[1](2401/114412); Loss: 0.058538; Backpropagation: 0.2913 sec; Batch: 2.1041 sec
0.1459 0.1156 0.0964 0.0692 0.0556 0.0534 0.0474 0.0446 0.0423 0.0412 0.0398 0.0383 0.0376 0.0369 0.0364 0.0361 

[TRAIN] Epoch[1](2402/114412); Loss: 0.080369; Backpropagation: 0.2909 sec; Batch: 2.1180 sec
0.1358 0.1240 0.1051 0.0926 0.0834 0.0785 0.0748 0.0716 0.0694 0.0673 0.0661 0.0651 0.0641 0.0633 0.0627 0.0621 

[TRAIN] Epoch[1](2403/114412); Loss: 0.081082; Backpropagation: 0.2955 sec; Batch: 2.1217 sec
0.1781 0.1663 0.1187 0.1011 0.0762 0.0730 0.0661 0.0638 0.0602 0.0587 0.0574 0.0566 0.0558 0.0554 0.0550 0.0549 

[TRAIN] Epoch[1](2404/114412); Loss: 0.068636; Backpropagation: 0.2928 sec; Batch: 2.1194 sec
0.1378 0.1150 0.0839 0.0735 0.0673 0.0636 0.0599 0.0581 0.0567 0.0562 0.0555 0.0549 0.0545 0.0540 0.0536 0.0535 

[TRAIN] Epoch[1](2405/114412); Loss: 0.079016; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.1391 0.1220 0.1007 0.0891 0.0809 0.0768 0.0724 0.0695 0.0678 0.0666 0.0652 0.0641 0.0634 0.0627 0.0622 0.0617 

[TRAIN] Epoch[1](2406/114412); Loss: 0.089447; Backpropagation: 0.2914 sec; Batch: 2.1208 sec
0.1709 0.1581 0.1173 0.1092 0.0853 0.0813 0.0802 0.0766 0.0726 0.0713 0.0701 0.0690 0.0681 0.0677 0.0669 0.0665 

[TRAIN] Epoch[1](2407/114412); Loss: 0.079027; Backpropagation: 0.2914 sec; Batch: 2.1187 sec
0.1584 0.1308 0.0970 0.0890 0.0737 0.0718 0.0720 0.0689 0.0656 0.0643 0.0632 0.0626 0.0622 0.0619 0.0617 0.0614 

[TRAIN] Epoch[1](2408/114412); Loss: 0.086072; Backpropagation: 0.2931 sec; Batch: 2.1168 sec
0.1932 0.1782 0.1134 0.0942 0.0862 0.0790 0.0715 0.0669 0.0656 0.0638 0.0625 0.0617 0.0610 0.0604 0.0599 0.0596 

[TRAIN] Epoch[1](2409/114412); Loss: 0.055074; Backpropagation: 0.2932 sec; Batch: 2.0977 sec
0.1221 0.1063 0.0796 0.0599 0.0531 0.0492 0.0465 0.0442 0.0430 0.0417 0.0407 0.0399 0.0392 0.0389 0.0386 0.0383 

[TRAIN] Epoch[1](2410/114412); Loss: 0.058842; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1055 0.0898 0.0716 0.0637 0.0584 0.0568 0.0540 0.0520 0.0509 0.0500 0.0493 0.0487 0.0482 0.0478 0.0475 0.0473 

[TRAIN] Epoch[1](2411/114412); Loss: 0.079268; Backpropagation: 0.2934 sec; Batch: 2.1351 sec
0.1519 0.1322 0.1053 0.0866 0.0762 0.0729 0.0694 0.0678 0.0662 0.0650 0.0640 0.0633 0.0624 0.0620 0.0617 0.0614 

[TRAIN] Epoch[1](2412/114412); Loss: 0.069160; Backpropagation: 0.2929 sec; Batch: 2.1196 sec
0.1346 0.1142 0.0933 0.0773 0.0691 0.0647 0.0609 0.0587 0.0569 0.0560 0.0550 0.0543 0.0536 0.0530 0.0526 0.0524 

[TRAIN] Epoch[1](2413/114412); Loss: 0.050520; Backpropagation: 0.2912 sec; Batch: 2.1200 sec
0.1105 0.0887 0.0644 0.0546 0.0494 0.0454 0.0434 0.0416 0.0406 0.0397 0.0392 0.0389 0.0383 0.0380 0.0379 0.0377 

[TRAIN] Epoch[1](2414/114412); Loss: 0.064590; Backpropagation: 0.2909 sec; Batch: 2.1008 sec
0.1212 0.1114 0.0848 0.0752 0.0653 0.0617 0.0576 0.0551 0.0533 0.0521 0.0510 0.0501 0.0494 0.0489 0.0485 0.0479 

[TRAIN] Epoch[1](2415/114412); Loss: 0.087672; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1635 0.1472 0.1242 0.1099 0.0934 0.0860 0.0812 0.0757 0.0725 0.0683 0.0664 0.0668 0.0637 0.0615 0.0612 0.0612 

[TRAIN] Epoch[1](2416/114412); Loss: 0.065175; Backpropagation: 0.2908 sec; Batch: 2.1178 sec
0.1388 0.1220 0.0874 0.0758 0.0631 0.0586 0.0559 0.0532 0.0515 0.0502 0.0491 0.0484 0.0477 0.0473 0.0470 0.0467 

[TRAIN] Epoch[1](2417/114412); Loss: 0.078823; Backpropagation: 0.2909 sec; Batch: 2.1129 sec
0.1456 0.1331 0.1038 0.0911 0.0829 0.0758 0.0715 0.0675 0.0650 0.0637 0.0622 0.0612 0.0604 0.0597 0.0590 0.0586 

[TRAIN] Epoch[1](2418/114412); Loss: 0.064632; Backpropagation: 0.2908 sec; Batch: 2.0786 sec
0.1267 0.1114 0.0870 0.0795 0.0652 0.0619 0.0568 0.0539 0.0526 0.0506 0.0496 0.0490 0.0481 0.0478 0.0473 0.0471 

[TRAIN] Epoch[1](2419/114412); Loss: 0.061248; Backpropagation: 0.2909 sec; Batch: 2.0857 sec
0.1087 0.0981 0.0772 0.0685 0.0620 0.0586 0.0560 0.0538 0.0520 0.0511 0.0501 0.0496 0.0491 0.0487 0.0484 0.0482 

[TRAIN] Epoch[1](2420/114412); Loss: 0.071267; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1615 0.1466 0.1121 0.0906 0.0684 0.0607 0.0573 0.0554 0.0521 0.0503 0.0492 0.0484 0.0476 0.0470 0.0466 0.0464 

[TRAIN] Epoch[1](2421/114412); Loss: 0.072907; Backpropagation: 0.2907 sec; Batch: 2.1321 sec
0.1683 0.1199 0.0893 0.0768 0.0698 0.0658 0.0623 0.0615 0.0601 0.0582 0.0573 0.0565 0.0559 0.0554 0.0550 0.0546 

[TRAIN] Epoch[1](2422/114412); Loss: 0.095571; Backpropagation: 0.2904 sec; Batch: 2.0764 sec
0.1577 0.1468 0.1103 0.1007 0.0973 0.0915 0.0878 0.0857 0.0845 0.0830 0.0820 0.0813 0.0807 0.0803 0.0799 0.0796 

[TRAIN] Epoch[1](2423/114412); Loss: 0.063178; Backpropagation: 0.2914 sec; Batch: 2.0899 sec
0.1376 0.1195 0.0800 0.0697 0.0637 0.0608 0.0533 0.0501 0.0503 0.0489 0.0478 0.0469 0.0461 0.0456 0.0454 0.0451 

[TRAIN] Epoch[1](2424/114412); Loss: 0.068953; Backpropagation: 0.2909 sec; Batch: 2.1148 sec
0.1267 0.1001 0.0833 0.0758 0.0690 0.0663 0.0637 0.0617 0.0599 0.0586 0.0578 0.0570 0.0563 0.0560 0.0556 0.0554 

[TRAIN] Epoch[1](2425/114412); Loss: 0.085811; Backpropagation: 0.2929 sec; Batch: 2.1201 sec
0.1835 0.1749 0.1246 0.1133 0.0824 0.0772 0.0755 0.0685 0.0644 0.0622 0.0604 0.0589 0.0579 0.0569 0.0564 0.0559 

[TRAIN] Epoch[1](2426/114412); Loss: 0.081058; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.1218 0.1119 0.0971 0.0909 0.0833 0.0803 0.0769 0.0748 0.0728 0.0715 0.0707 0.0700 0.0692 0.0688 0.0686 0.0682 

[TRAIN] Epoch[1](2427/114412); Loss: 0.083883; Backpropagation: 0.2910 sec; Batch: 2.1186 sec
0.1408 0.1255 0.1042 0.0909 0.0837 0.0804 0.0776 0.0755 0.0738 0.0724 0.0712 0.0702 0.0697 0.0691 0.0688 0.0684 

[TRAIN] Epoch[1](2428/114412); Loss: 0.079740; Backpropagation: 0.2913 sec; Batch: 2.1161 sec
0.1495 0.1315 0.1054 0.0956 0.0833 0.0791 0.0712 0.0683 0.0655 0.0638 0.0623 0.0614 0.0605 0.0600 0.0594 0.0591 

[TRAIN] Epoch[1](2429/114412); Loss: 0.059733; Backpropagation: 0.2912 sec; Batch: 2.1135 sec
0.1614 0.1344 0.0895 0.0684 0.0565 0.0504 0.0460 0.0433 0.0415 0.0399 0.0389 0.0380 0.0374 0.0371 0.0367 0.0365 

[TRAIN] Epoch[1](2430/114412); Loss: 0.071251; Backpropagation: 0.2903 sec; Batch: 2.1125 sec
0.1432 0.1277 0.0938 0.0814 0.0714 0.0671 0.0636 0.0611 0.0586 0.0564 0.0548 0.0539 0.0528 0.0521 0.0514 0.0508 

[TRAIN] Epoch[1](2431/114412); Loss: 0.067112; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1202 0.0998 0.0779 0.0718 0.0681 0.0641 0.0618 0.0598 0.0585 0.0577 0.0571 0.0564 0.0558 0.0553 0.0549 0.0547 

[TRAIN] Epoch[1](2432/114412); Loss: 0.068494; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1246 0.1086 0.0899 0.0755 0.0710 0.0675 0.0643 0.0603 0.0594 0.0574 0.0547 0.0541 0.0530 0.0523 0.0520 0.0513 

[TRAIN] Epoch[1](2433/114412); Loss: 0.068181; Backpropagation: 0.2910 sec; Batch: 2.0781 sec
0.1519 0.1317 0.0980 0.0859 0.0690 0.0633 0.0576 0.0544 0.0518 0.0495 0.0482 0.0473 0.0465 0.0457 0.0452 0.0448 

[TRAIN] Epoch[1](2434/114412); Loss: 0.039949; Backpropagation: 0.2910 sec; Batch: 2.1197 sec
0.0961 0.0646 0.0516 0.0442 0.0395 0.0370 0.0343 0.0324 0.0316 0.0309 0.0303 0.0298 0.0296 0.0293 0.0291 0.0289 

[TRAIN] Epoch[1](2435/114412); Loss: 0.075890; Backpropagation: 0.2912 sec; Batch: 2.0922 sec
0.1337 0.1121 0.0902 0.0820 0.0760 0.0724 0.0701 0.0678 0.0665 0.0653 0.0644 0.0637 0.0630 0.0628 0.0622 0.0619 

[TRAIN] Epoch[1](2436/114412); Loss: 0.050517; Backpropagation: 0.2910 sec; Batch: 2.1144 sec
0.0979 0.0830 0.0629 0.0555 0.0515 0.0485 0.0457 0.0439 0.0425 0.0413 0.0405 0.0399 0.0394 0.0390 0.0386 0.0383 

[TRAIN] Epoch[1](2437/114412); Loss: 0.077362; Backpropagation: 0.2906 sec; Batch: 2.1125 sec
0.1400 0.1190 0.0989 0.0905 0.0810 0.0746 0.0716 0.0681 0.0649 0.0638 0.0625 0.0618 0.0610 0.0604 0.0600 0.0596 

[TRAIN] Epoch[1](2438/114412); Loss: 0.057611; Backpropagation: 0.2905 sec; Batch: 2.1143 sec
0.1264 0.1058 0.0762 0.0633 0.0566 0.0533 0.0504 0.0480 0.0461 0.0449 0.0436 0.0426 0.0419 0.0414 0.0408 0.0404 

[TRAIN] Epoch[1](2439/114412); Loss: 0.064778; Backpropagation: 0.2908 sec; Batch: 2.1144 sec
0.1166 0.1067 0.0855 0.0769 0.0681 0.0632 0.0585 0.0559 0.0539 0.0526 0.0516 0.0506 0.0500 0.0494 0.0488 0.0483 

[TRAIN] Epoch[1](2440/114412); Loss: 0.061057; Backpropagation: 0.2911 sec; Batch: 2.1210 sec
0.1257 0.1106 0.0770 0.0657 0.0604 0.0563 0.0533 0.0513 0.0498 0.0484 0.0477 0.0470 0.0465 0.0461 0.0457 0.0453 

[TRAIN] Epoch[1](2441/114412); Loss: 0.070971; Backpropagation: 0.2931 sec; Batch: 2.1143 sec
0.1680 0.1433 0.0979 0.0868 0.0623 0.0593 0.0575 0.0556 0.0527 0.0518 0.0510 0.0507 0.0502 0.0497 0.0495 0.0492 

[TRAIN] Epoch[1](2442/114412); Loss: 0.052635; Backpropagation: 0.2956 sec; Batch: 2.1048 sec
0.1078 0.0866 0.0648 0.0581 0.0522 0.0486 0.0466 0.0450 0.0438 0.0429 0.0421 0.0415 0.0410 0.0406 0.0404 0.0402 

[TRAIN] Epoch[1](2443/114412); Loss: 0.063018; Backpropagation: 0.2905 sec; Batch: 2.1185 sec
0.1477 0.1196 0.0861 0.0662 0.0590 0.0583 0.0558 0.0507 0.0491 0.0478 0.0464 0.0457 0.0446 0.0443 0.0438 0.0433 

[TRAIN] Epoch[1](2444/114412); Loss: 0.049427; Backpropagation: 0.2912 sec; Batch: 2.0784 sec
0.1183 0.0995 0.0667 0.0579 0.0499 0.0449 0.0417 0.0391 0.0365 0.0357 0.0350 0.0340 0.0334 0.0331 0.0327 0.0325 

[TRAIN] Epoch[1](2445/114412); Loss: 0.061210; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1235 0.1041 0.0799 0.0664 0.0617 0.0579 0.0545 0.0521 0.0507 0.0489 0.0482 0.0475 0.0468 0.0462 0.0457 0.0453 

[TRAIN] Epoch[1](2446/114412); Loss: 0.077324; Backpropagation: 0.2911 sec; Batch: 2.1164 sec
0.1624 0.1363 0.0953 0.0861 0.0764 0.0726 0.0690 0.0655 0.0632 0.0613 0.0601 0.0591 0.0583 0.0576 0.0573 0.0567 

[TRAIN] Epoch[1](2447/114412); Loss: 0.072951; Backpropagation: 0.2908 sec; Batch: 2.1452 sec
0.1315 0.1131 0.0918 0.0818 0.0751 0.0690 0.0659 0.0639 0.0623 0.0609 0.0600 0.0594 0.0588 0.0583 0.0579 0.0576 

[TRAIN] Epoch[1](2448/114412); Loss: 0.050984; Backpropagation: 0.2911 sec; Batch: 2.1024 sec
0.0920 0.0784 0.0603 0.0549 0.0508 0.0486 0.0467 0.0452 0.0441 0.0432 0.0427 0.0423 0.0420 0.0418 0.0416 0.0414 

[TRAIN] Epoch[1](2449/114412); Loss: 0.047248; Backpropagation: 0.2928 sec; Batch: 2.1150 sec
0.1003 0.0862 0.0583 0.0509 0.0484 0.0446 0.0413 0.0393 0.0380 0.0370 0.0364 0.0358 0.0353 0.0350 0.0347 0.0345 

[TRAIN] Epoch[1](2450/114412); Loss: 0.064312; Backpropagation: 0.2928 sec; Batch: 2.1185 sec
0.1324 0.1177 0.0775 0.0693 0.0647 0.0600 0.0566 0.0539 0.0523 0.0513 0.0503 0.0495 0.0489 0.0485 0.0483 0.0477 

[TRAIN] Epoch[1](2451/114412); Loss: 0.088469; Backpropagation: 0.2913 sec; Batch: 2.1198 sec
0.1794 0.1613 0.1225 0.1083 0.0873 0.0838 0.0757 0.0720 0.0703 0.0688 0.0669 0.0655 0.0645 0.0638 0.0630 0.0624 

[TRAIN] Epoch[1](2452/114412); Loss: 0.055103; Backpropagation: 0.2918 sec; Batch: 2.1170 sec
0.1166 0.0988 0.0727 0.0632 0.0571 0.0526 0.0492 0.0467 0.0438 0.0427 0.0416 0.0405 0.0397 0.0392 0.0387 0.0384 

[TRAIN] Epoch[1](2453/114412); Loss: 0.050512; Backpropagation: 0.2907 sec; Batch: 2.0847 sec
0.1282 0.1011 0.0683 0.0576 0.0502 0.0452 0.0416 0.0387 0.0369 0.0359 0.0352 0.0345 0.0340 0.0338 0.0336 0.0334 

[TRAIN] Epoch[1](2454/114412); Loss: 0.081525; Backpropagation: 0.2911 sec; Batch: 2.1017 sec
0.1292 0.1176 0.1044 0.0950 0.0834 0.0780 0.0751 0.0732 0.0712 0.0703 0.0694 0.0685 0.0680 0.0674 0.0670 0.0667 

[TRAIN] Epoch[1](2455/114412); Loss: 0.064114; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1443 0.1353 0.0996 0.0924 0.0646 0.0602 0.0522 0.0482 0.0452 0.0447 0.0429 0.0407 0.0398 0.0391 0.0386 0.0382 

[TRAIN] Epoch[1](2456/114412); Loss: 0.076756; Backpropagation: 0.2911 sec; Batch: 2.1284 sec
0.1637 0.1511 0.1156 0.0948 0.0770 0.0700 0.0648 0.0601 0.0576 0.0562 0.0548 0.0537 0.0529 0.0524 0.0519 0.0514 

[TRAIN] Epoch[1](2457/114412); Loss: 0.063709; Backpropagation: 0.2908 sec; Batch: 2.1172 sec
0.1560 0.1366 0.0813 0.0690 0.0553 0.0511 0.0503 0.0489 0.0479 0.0470 0.0465 0.0462 0.0459 0.0459 0.0458 0.0457 

[TRAIN] Epoch[1](2458/114412); Loss: 0.069168; Backpropagation: 0.2908 sec; Batch: 2.1143 sec
0.1423 0.1282 0.0947 0.0831 0.0687 0.0646 0.0606 0.0574 0.0552 0.0531 0.0517 0.0508 0.0500 0.0492 0.0487 0.0483 

[TRAIN] Epoch[1](2459/114412); Loss: 0.064251; Backpropagation: 0.2930 sec; Batch: 2.0797 sec
0.1168 0.0995 0.0795 0.0715 0.0668 0.0618 0.0590 0.0566 0.0548 0.0535 0.0527 0.0519 0.0514 0.0511 0.0507 0.0505 

[TRAIN] Epoch[1](2460/114412); Loss: 0.068460; Backpropagation: 0.2906 sec; Batch: 2.1148 sec
0.1043 0.0950 0.0816 0.0750 0.0706 0.0671 0.0649 0.0633 0.0616 0.0604 0.0595 0.0590 0.0586 0.0584 0.0581 0.0580 

[TRAIN] Epoch[1](2461/114412); Loss: 0.059090; Backpropagation: 0.2933 sec; Batch: 2.1241 sec
0.1110 0.0978 0.0756 0.0644 0.0605 0.0560 0.0529 0.0507 0.0493 0.0482 0.0476 0.0469 0.0465 0.0463 0.0460 0.0460 

[TRAIN] Epoch[1](2462/114412); Loss: 0.091985; Backpropagation: 0.2928 sec; Batch: 2.1165 sec
0.1486 0.1361 0.1115 0.1060 0.0913 0.0876 0.0885 0.0850 0.0812 0.0798 0.0780 0.0770 0.0762 0.0755 0.0750 0.0745 

[TRAIN] Epoch[1](2463/114412); Loss: 0.060953; Backpropagation: 0.2911 sec; Batch: 2.1152 sec
0.1185 0.1041 0.0763 0.0661 0.0612 0.0577 0.0550 0.0523 0.0506 0.0495 0.0485 0.0479 0.0474 0.0470 0.0467 0.0464 

[TRAIN] Epoch[1](2464/114412); Loss: 0.063173; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1340 0.1214 0.0769 0.0717 0.0612 0.0568 0.0543 0.0531 0.0507 0.0495 0.0482 0.0475 0.0470 0.0466 0.0461 0.0459 

[TRAIN] Epoch[1](2465/114412); Loss: 0.085498; Backpropagation: 0.2911 sec; Batch: 2.1140 sec
0.1361 0.1176 0.1032 0.0961 0.0890 0.0847 0.0813 0.0785 0.0764 0.0747 0.0734 0.0726 0.0719 0.0713 0.0708 0.0703 

[TRAIN] Epoch[1](2466/114412); Loss: 0.070966; Backpropagation: 0.2908 sec; Batch: 2.1230 sec
0.1603 0.1498 0.0933 0.0749 0.0703 0.0636 0.0585 0.0557 0.0538 0.0526 0.0517 0.0510 0.0505 0.0500 0.0498 0.0496 

[TRAIN] Epoch[1](2467/114412); Loss: 0.044520; Backpropagation: 0.2927 sec; Batch: 2.1160 sec
0.0912 0.0752 0.0563 0.0482 0.0460 0.0429 0.0399 0.0377 0.0363 0.0353 0.0346 0.0342 0.0339 0.0337 0.0335 0.0334 

[TRAIN] Epoch[1](2468/114412); Loss: 0.071476; Backpropagation: 0.2932 sec; Batch: 2.1201 sec
0.1115 0.1037 0.0840 0.0793 0.0734 0.0693 0.0669 0.0650 0.0640 0.0629 0.0620 0.0614 0.0607 0.0601 0.0598 0.0594 

[TRAIN] Epoch[1](2469/114412); Loss: 0.070597; Backpropagation: 0.2929 sec; Batch: 2.1160 sec
0.1450 0.1194 0.0914 0.0735 0.0682 0.0660 0.0616 0.0595 0.0578 0.0570 0.0559 0.0557 0.0551 0.0549 0.0544 0.0542 

[TRAIN] Epoch[1](2470/114412); Loss: 0.063838; Backpropagation: 0.2927 sec; Batch: 2.1209 sec
0.1301 0.1099 0.0809 0.0720 0.0630 0.0595 0.0566 0.0542 0.0524 0.0512 0.0499 0.0492 0.0486 0.0482 0.0480 0.0477 

[TRAIN] Epoch[1](2471/114412); Loss: 0.059699; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1323 0.1268 0.0860 0.0782 0.0547 0.0509 0.0523 0.0487 0.0441 0.0428 0.0417 0.0405 0.0396 0.0392 0.0389 0.0385 

[TRAIN] Epoch[1](2472/114412); Loss: 0.069540; Backpropagation: 0.2927 sec; Batch: 2.1504 sec
0.1175 0.1100 0.0851 0.0776 0.0670 0.0647 0.0642 0.0626 0.0605 0.0592 0.0585 0.0579 0.0575 0.0572 0.0567 0.0565 

[TRAIN] Epoch[1](2473/114412); Loss: 0.079117; Backpropagation: 0.2910 sec; Batch: 2.1204 sec
0.1163 0.1069 0.0916 0.0823 0.0789 0.0774 0.0756 0.0738 0.0726 0.0715 0.0709 0.0704 0.0698 0.0695 0.0693 0.0691 

[TRAIN] Epoch[1](2474/114412); Loss: 0.087079; Backpropagation: 0.2909 sec; Batch: 2.1328 sec
0.1406 0.1315 0.1035 0.0953 0.0860 0.0824 0.0801 0.0785 0.0770 0.0759 0.0752 0.0743 0.0738 0.0733 0.0730 0.0727 

[TRAIN] Epoch[1](2475/114412); Loss: 0.064585; Backpropagation: 0.2904 sec; Batch: 2.1158 sec
0.1379 0.1311 0.0762 0.0687 0.0711 0.0643 0.0548 0.0521 0.0500 0.0490 0.0478 0.0471 0.0465 0.0459 0.0455 0.0453 

[TRAIN] Epoch[1](2476/114412); Loss: 0.066174; Backpropagation: 0.2908 sec; Batch: 2.1149 sec
0.1151 0.1002 0.0813 0.0741 0.0693 0.0646 0.0621 0.0595 0.0575 0.0560 0.0549 0.0540 0.0535 0.0527 0.0523 0.0520 

[TRAIN] Epoch[1](2477/114412); Loss: 0.046206; Backpropagation: 0.2923 sec; Batch: 2.1120 sec
0.1032 0.0891 0.0593 0.0509 0.0449 0.0418 0.0390 0.0372 0.0361 0.0353 0.0347 0.0341 0.0338 0.0334 0.0333 0.0331 

[TRAIN] Epoch[1](2478/114412); Loss: 0.063297; Backpropagation: 0.2906 sec; Batch: 2.1147 sec
0.1334 0.1169 0.0913 0.0764 0.0633 0.0570 0.0544 0.0518 0.0494 0.0477 0.0468 0.0460 0.0453 0.0448 0.0444 0.0440 

[TRAIN] Epoch[1](2479/114412); Loss: 0.073567; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1328 0.1243 0.1095 0.0929 0.0771 0.0732 0.0662 0.0624 0.0582 0.0570 0.0554 0.0546 0.0538 0.0534 0.0532 0.0530 

[TRAIN] Epoch[1](2480/114412); Loss: 0.072398; Backpropagation: 0.2910 sec; Batch: 2.1248 sec
0.1293 0.1170 0.0888 0.0798 0.0730 0.0681 0.0651 0.0632 0.0616 0.0605 0.0600 0.0594 0.0588 0.0583 0.0579 0.0577 

[TRAIN] Epoch[1](2481/114412); Loss: 0.062923; Backpropagation: 0.2915 sec; Batch: 2.1149 sec
0.0991 0.0872 0.0760 0.0714 0.0657 0.0618 0.0591 0.0575 0.0560 0.0550 0.0542 0.0535 0.0531 0.0527 0.0524 0.0521 

[TRAIN] Epoch[1](2482/114412); Loss: 0.049560; Backpropagation: 0.2928 sec; Batch: 2.0994 sec
0.1025 0.0927 0.0633 0.0564 0.0518 0.0461 0.0433 0.0410 0.0393 0.0382 0.0375 0.0369 0.0365 0.0361 0.0358 0.0356 

[TRAIN] Epoch[1](2483/114412); Loss: 0.070085; Backpropagation: 0.2915 sec; Batch: 2.0783 sec
0.1111 0.1036 0.0874 0.0804 0.0714 0.0672 0.0649 0.0631 0.0615 0.0605 0.0597 0.0591 0.0585 0.0581 0.0576 0.0574 

[TRAIN] Epoch[1](2484/114412); Loss: 0.067886; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1282 0.1109 0.0864 0.0791 0.0668 0.0627 0.0621 0.0594 0.0570 0.0553 0.0544 0.0537 0.0531 0.0527 0.0525 0.0520 

[TRAIN] Epoch[1](2485/114412); Loss: 0.081901; Backpropagation: 0.2905 sec; Batch: 2.1211 sec
0.1324 0.1248 0.0980 0.0919 0.0831 0.0796 0.0757 0.0736 0.0723 0.0707 0.0695 0.0689 0.0682 0.0676 0.0672 0.0669 

[TRAIN] Epoch[1](2486/114412); Loss: 0.045376; Backpropagation: 0.2931 sec; Batch: 2.1227 sec
0.0978 0.0799 0.0651 0.0548 0.0457 0.0405 0.0383 0.0364 0.0351 0.0343 0.0337 0.0333 0.0330 0.0329 0.0327 0.0326 

[TRAIN] Epoch[1](2487/114412); Loss: 0.072547; Backpropagation: 0.2921 sec; Batch: 2.1184 sec
0.1370 0.1230 0.0984 0.0808 0.0718 0.0680 0.0639 0.0614 0.0598 0.0586 0.0577 0.0571 0.0564 0.0560 0.0556 0.0554 

[TRAIN] Epoch[1](2488/114412); Loss: 0.053229; Backpropagation: 0.2931 sec; Batch: 2.1211 sec
0.0931 0.0850 0.0659 0.0567 0.0531 0.0509 0.0486 0.0467 0.0458 0.0449 0.0442 0.0438 0.0435 0.0433 0.0432 0.0431 

[TRAIN] Epoch[1](2489/114412); Loss: 0.063370; Backpropagation: 0.2951 sec; Batch: 2.1186 sec
0.1140 0.0963 0.0796 0.0711 0.0649 0.0603 0.0574 0.0557 0.0545 0.0534 0.0524 0.0518 0.0513 0.0508 0.0504 0.0501 

[TRAIN] Epoch[1](2490/114412); Loss: 0.059518; Backpropagation: 0.2927 sec; Batch: 2.1120 sec
0.1410 0.1332 0.0857 0.0767 0.0512 0.0453 0.0544 0.0502 0.0431 0.0411 0.0405 0.0393 0.0383 0.0378 0.0373 0.0371 

[TRAIN] Epoch[1](2491/114412); Loss: 0.063685; Backpropagation: 0.2908 sec; Batch: 2.1526 sec
0.1152 0.0967 0.0825 0.0711 0.0665 0.0630 0.0589 0.0564 0.0541 0.0527 0.0516 0.0509 0.0505 0.0500 0.0496 0.0494 

[TRAIN] Epoch[1](2492/114412); Loss: 0.072558; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1590 0.1460 0.0975 0.0824 0.0712 0.0651 0.0616 0.0585 0.0562 0.0543 0.0533 0.0523 0.0517 0.0511 0.0506 0.0502 

[TRAIN] Epoch[1](2493/114412); Loss: 0.097292; Backpropagation: 0.2914 sec; Batch: 2.1148 sec
0.1699 0.1629 0.1322 0.1136 0.0985 0.0929 0.0887 0.0841 0.0815 0.0795 0.0781 0.0768 0.0757 0.0748 0.0741 0.0735 

[TRAIN] Epoch[1](2494/114412); Loss: 0.079967; Backpropagation: 0.2923 sec; Batch: 2.1171 sec
0.1330 0.1163 0.0983 0.0892 0.0810 0.0769 0.0745 0.0721 0.0700 0.0688 0.0680 0.0672 0.0665 0.0662 0.0658 0.0656 

[TRAIN] Epoch[1](2495/114412); Loss: 0.062618; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1218 0.1004 0.0806 0.0714 0.0636 0.0589 0.0556 0.0537 0.0523 0.0511 0.0502 0.0494 0.0489 0.0484 0.0481 0.0476 

[TRAIN] Epoch[1](2496/114412); Loss: 0.088953; Backpropagation: 0.2951 sec; Batch: 2.1216 sec
0.1341 0.1266 0.1057 0.0997 0.0912 0.0867 0.0840 0.0814 0.0797 0.0784 0.0775 0.0767 0.0761 0.0757 0.0751 0.0746 

[TRAIN] Epoch[1](2497/114412); Loss: 0.066855; Backpropagation: 0.2909 sec; Batch: 2.1179 sec
0.1142 0.1082 0.0828 0.0748 0.0692 0.0636 0.0607 0.0587 0.0572 0.0562 0.0553 0.0545 0.0541 0.0537 0.0534 0.0532 

[TRAIN] Epoch[1](2498/114412); Loss: 0.046848; Backpropagation: 0.2907 sec; Batch: 2.1164 sec
0.1207 0.0995 0.0645 0.0520 0.0452 0.0415 0.0379 0.0354 0.0338 0.0329 0.0321 0.0316 0.0311 0.0308 0.0304 0.0301 

[TRAIN] Epoch[1](2499/114412); Loss: 0.058671; Backpropagation: 0.2904 sec; Batch: 2.1137 sec
0.1241 0.1124 0.0722 0.0633 0.0568 0.0525 0.0498 0.0488 0.0471 0.0460 0.0454 0.0449 0.0443 0.0440 0.0437 0.0435 

[TRAIN] Epoch[1](2500/114412); Loss: 0.074141; Backpropagation: 0.2910 sec; Batch: 2.1182 sec
0.1569 0.1414 0.0969 0.0869 0.0707 0.0652 0.0629 0.0605 0.0588 0.0574 0.0564 0.0557 0.0550 0.0543 0.0539 0.0534 

[TRAIN] Epoch[1](2501/114412); Loss: 0.081552; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1348 0.1241 0.1000 0.0899 0.0839 0.0795 0.0761 0.0731 0.0716 0.0700 0.0688 0.0678 0.0671 0.0666 0.0660 0.0654 

[TRAIN] Epoch[1](2502/114412); Loss: 0.066893; Backpropagation: 0.2910 sec; Batch: 2.1260 sec
0.1569 0.1305 0.0828 0.0707 0.0639 0.0590 0.0560 0.0539 0.0523 0.0511 0.0502 0.0495 0.0489 0.0486 0.0482 0.0478 

[TRAIN] Epoch[1](2503/114412); Loss: 0.101743; Backpropagation: 0.2928 sec; Batch: 2.1187 sec
0.1834 0.1669 0.1288 0.1140 0.1039 0.0979 0.0917 0.0880 0.0856 0.0841 0.0828 0.0819 0.0808 0.0800 0.0793 0.0789 

[TRAIN] Epoch[1](2504/114412); Loss: 0.056139; Backpropagation: 0.2912 sec; Batch: 2.0775 sec
0.1400 0.1357 0.0810 0.0750 0.0495 0.0463 0.0430 0.0412 0.0388 0.0375 0.0366 0.0358 0.0351 0.0345 0.0342 0.0339 

[TRAIN] Epoch[1](2505/114412); Loss: 0.049035; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.0948 0.0843 0.0681 0.0595 0.0524 0.0478 0.0442 0.0418 0.0399 0.0383 0.0374 0.0365 0.0357 0.0350 0.0345 0.0341 

[TRAIN] Epoch[1](2506/114412); Loss: 0.068791; Backpropagation: 0.2911 sec; Batch: 2.1134 sec
0.1332 0.1185 0.0831 0.0718 0.0680 0.0637 0.0610 0.0590 0.0574 0.0566 0.0560 0.0552 0.0548 0.0545 0.0541 0.0539 

[TRAIN] Epoch[1](2507/114412); Loss: 0.064194; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.1590 0.1411 0.0863 0.0686 0.0602 0.0560 0.0512 0.0494 0.0476 0.0460 0.0449 0.0441 0.0437 0.0432 0.0429 0.0426 

[TRAIN] Epoch[1](2508/114412); Loss: 0.054843; Backpropagation: 0.2927 sec; Batch: 2.1072 sec
0.1284 0.1121 0.0746 0.0592 0.0529 0.0503 0.0459 0.0432 0.0418 0.0405 0.0394 0.0387 0.0381 0.0377 0.0374 0.0372 

[TRAIN] Epoch[1](2509/114412); Loss: 0.071696; Backpropagation: 0.2921 sec; Batch: 2.1323 sec
0.1331 0.1214 0.0916 0.0766 0.0715 0.0670 0.0645 0.0621 0.0606 0.0593 0.0582 0.0573 0.0567 0.0562 0.0558 0.0554 

[TRAIN] Epoch[1](2510/114412); Loss: 0.066414; Backpropagation: 0.2905 sec; Batch: 2.1168 sec
0.1177 0.1124 0.0830 0.0753 0.0658 0.0626 0.0602 0.0583 0.0564 0.0551 0.0541 0.0533 0.0527 0.0522 0.0519 0.0516 

[TRAIN] Epoch[1](2511/114412); Loss: 0.078177; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1613 0.1420 0.1047 0.0882 0.0778 0.0721 0.0674 0.0639 0.0623 0.0613 0.0603 0.0592 0.0585 0.0577 0.0572 0.0569 

[TRAIN] Epoch[1](2512/114412); Loss: 0.067474; Backpropagation: 0.2912 sec; Batch: 2.1274 sec
0.1500 0.1419 0.0954 0.0744 0.0611 0.0584 0.0561 0.0540 0.0514 0.0494 0.0490 0.0484 0.0479 0.0477 0.0474 0.0471 

[TRAIN] Epoch[1](2513/114412); Loss: 0.065021; Backpropagation: 0.2914 sec; Batch: 2.1161 sec
0.1402 0.1199 0.0897 0.0775 0.0672 0.0623 0.0563 0.0527 0.0507 0.0492 0.0479 0.0466 0.0459 0.0452 0.0446 0.0442 

[TRAIN] Epoch[1](2514/114412); Loss: 0.074678; Backpropagation: 0.2910 sec; Batch: 2.1183 sec
0.1500 0.1328 0.0949 0.0846 0.0741 0.0696 0.0652 0.0629 0.0613 0.0595 0.0585 0.0575 0.0568 0.0562 0.0556 0.0552 

[TRAIN] Epoch[1](2515/114412); Loss: 0.065896; Backpropagation: 0.2913 sec; Batch: 2.0850 sec
0.1348 0.1186 0.0874 0.0759 0.0691 0.0633 0.0575 0.0542 0.0523 0.0513 0.0499 0.0489 0.0484 0.0479 0.0475 0.0473 

[TRAIN] Epoch[1](2516/114412); Loss: 0.062998; Backpropagation: 0.2920 sec; Batch: 2.1311 sec
0.1962 0.1660 0.1027 0.0778 0.0627 0.0549 0.0469 0.0400 0.0355 0.0343 0.0333 0.0325 0.0319 0.0315 0.0311 0.0308 

[TRAIN] Epoch[1](2517/114412); Loss: 0.077475; Backpropagation: 0.2913 sec; Batch: 2.1205 sec
0.1507 0.1340 0.0985 0.0851 0.0778 0.0723 0.0686 0.0661 0.0643 0.0630 0.0616 0.0607 0.0602 0.0594 0.0589 0.0584 

[TRAIN] Epoch[1](2518/114412); Loss: 0.074631; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1652 0.1420 0.0985 0.0876 0.0749 0.0666 0.0644 0.0611 0.0577 0.0563 0.0551 0.0542 0.0535 0.0528 0.0523 0.0520 

[TRAIN] Epoch[1](2519/114412); Loss: 0.073601; Backpropagation: 0.2908 sec; Batch: 2.1317 sec
0.2041 0.1821 0.1273 0.0832 0.0598 0.0578 0.0557 0.0514 0.0483 0.0466 0.0454 0.0445 0.0437 0.0431 0.0426 0.0422 

[TRAIN] Epoch[1](2520/114412); Loss: 0.048851; Backpropagation: 0.2909 sec; Batch: 2.1186 sec
0.1100 0.0960 0.0633 0.0521 0.0479 0.0451 0.0417 0.0393 0.0383 0.0372 0.0362 0.0357 0.0352 0.0349 0.0344 0.0341 

[TRAIN] Epoch[1](2521/114412); Loss: 0.081811; Backpropagation: 0.2909 sec; Batch: 2.1248 sec
0.1675 0.1528 0.1117 0.0970 0.0827 0.0762 0.0724 0.0681 0.0652 0.0628 0.0612 0.0601 0.0589 0.0582 0.0574 0.0568 

[TRAIN] Epoch[1](2522/114412); Loss: 0.083230; Backpropagation: 0.2910 sec; Batch: 2.1184 sec
0.1432 0.1263 0.0977 0.0882 0.0828 0.0795 0.0764 0.0737 0.0727 0.0717 0.0708 0.0703 0.0701 0.0697 0.0695 0.0693 

[TRAIN] Epoch[1](2523/114412); Loss: 0.080010; Backpropagation: 0.2929 sec; Batch: 2.1190 sec
0.1627 0.1491 0.1009 0.0895 0.0788 0.0751 0.0696 0.0664 0.0648 0.0629 0.0618 0.0609 0.0602 0.0596 0.0591 0.0586 

[TRAIN] Epoch[1](2524/114412); Loss: 0.073678; Backpropagation: 0.2909 sec; Batch: 2.1155 sec
0.1569 0.1527 0.0923 0.0829 0.0716 0.0656 0.0618 0.0591 0.0577 0.0565 0.0552 0.0542 0.0538 0.0532 0.0528 0.0525 

[TRAIN] Epoch[1](2525/114412); Loss: 0.065141; Backpropagation: 0.2906 sec; Batch: 2.1186 sec
0.1453 0.1253 0.0828 0.0711 0.0644 0.0601 0.0560 0.0530 0.0513 0.0497 0.0486 0.0478 0.0473 0.0468 0.0465 0.0463 

[TRAIN] Epoch[1](2526/114412); Loss: 0.089268; Backpropagation: 0.2931 sec; Batch: 2.0795 sec
0.1655 0.1453 0.1151 0.0981 0.0890 0.0843 0.0802 0.0779 0.0757 0.0741 0.0727 0.0716 0.0707 0.0699 0.0692 0.0687 

[TRAIN] Epoch[1](2527/114412); Loss: 0.059673; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1091 0.0999 0.0761 0.0668 0.0610 0.0562 0.0532 0.0516 0.0500 0.0490 0.0481 0.0475 0.0470 0.0467 0.0464 0.0461 

[TRAIN] Epoch[1](2528/114412); Loss: 0.068408; Backpropagation: 0.2942 sec; Batch: 2.1217 sec
0.1220 0.1105 0.0810 0.0739 0.0685 0.0650 0.0622 0.0606 0.0590 0.0578 0.0569 0.0563 0.0558 0.0553 0.0550 0.0546 

[TRAIN] Epoch[1](2529/114412); Loss: 0.063479; Backpropagation: 0.2926 sec; Batch: 2.1173 sec
0.1578 0.1456 0.0919 0.0737 0.0577 0.0522 0.0505 0.0475 0.0456 0.0441 0.0429 0.0422 0.0415 0.0412 0.0408 0.0404 

[TRAIN] Epoch[1](2530/114412); Loss: 0.081680; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.1593 0.1416 0.1057 0.0924 0.0796 0.0757 0.0711 0.0692 0.0673 0.0662 0.0647 0.0640 0.0634 0.0628 0.0622 0.0616 

[TRAIN] Epoch[1](2531/114412); Loss: 0.088238; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1474 0.1351 0.1092 0.0992 0.0905 0.0842 0.0806 0.0783 0.0768 0.0755 0.0743 0.0733 0.0726 0.0721 0.0715 0.0711 

[TRAIN] Epoch[1](2532/114412); Loss: 0.056041; Backpropagation: 0.2906 sec; Batch: 2.1167 sec
0.1255 0.1041 0.0636 0.0577 0.0549 0.0503 0.0483 0.0463 0.0451 0.0443 0.0435 0.0432 0.0428 0.0426 0.0424 0.0420 

[TRAIN] Epoch[1](2533/114412); Loss: 0.063878; Backpropagation: 0.2903 sec; Batch: 2.1135 sec
0.1500 0.1340 0.0868 0.0680 0.0587 0.0541 0.0521 0.0495 0.0485 0.0475 0.0467 0.0460 0.0456 0.0451 0.0448 0.0446 

[TRAIN] Epoch[1](2534/114412); Loss: 0.062304; Backpropagation: 0.2905 sec; Batch: 2.1308 sec
0.1432 0.1305 0.0758 0.0650 0.0733 0.0642 0.0530 0.0482 0.0465 0.0446 0.0435 0.0428 0.0422 0.0417 0.0412 0.0410 

[TRAIN] Epoch[1](2535/114412); Loss: 0.066273; Backpropagation: 0.2929 sec; Batch: 2.0809 sec
0.1784 0.1525 0.0792 0.0658 0.0644 0.0596 0.0532 0.0497 0.0477 0.0462 0.0453 0.0447 0.0441 0.0435 0.0431 0.0430 

[TRAIN] Epoch[1](2536/114412); Loss: 0.083531; Backpropagation: 0.2909 sec; Batch: 2.1141 sec
0.1369 0.1266 0.1016 0.0900 0.0835 0.0799 0.0771 0.0749 0.0733 0.0723 0.0714 0.0706 0.0701 0.0698 0.0694 0.0692 

[TRAIN] Epoch[1](2537/114412); Loss: 0.042420; Backpropagation: 0.2900 sec; Batch: 2.1191 sec
0.1214 0.1040 0.0582 0.0461 0.0395 0.0365 0.0331 0.0302 0.0286 0.0273 0.0266 0.0261 0.0257 0.0254 0.0251 0.0250 

[TRAIN] Epoch[1](2538/114412); Loss: 0.071464; Backpropagation: 0.2910 sec; Batch: 2.1187 sec
0.1251 0.1131 0.0902 0.0770 0.0722 0.0672 0.0647 0.0633 0.0616 0.0602 0.0594 0.0589 0.0583 0.0578 0.0574 0.0571 

[TRAIN] Epoch[1](2539/114412); Loss: 0.068728; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1283 0.1158 0.0882 0.0758 0.0699 0.0651 0.0616 0.0593 0.0577 0.0562 0.0553 0.0543 0.0537 0.0532 0.0528 0.0525 

[TRAIN] Epoch[1](2540/114412); Loss: 0.074994; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1264 0.1134 0.0895 0.0814 0.0747 0.0716 0.0691 0.0670 0.0658 0.0643 0.0637 0.0631 0.0627 0.0625 0.0624 0.0623 

[TRAIN] Epoch[1](2541/114412); Loss: 0.073363; Backpropagation: 0.2911 sec; Batch: 2.0981 sec
0.1477 0.1347 0.1051 0.0846 0.0754 0.0679 0.0636 0.0597 0.0581 0.0564 0.0552 0.0542 0.0534 0.0528 0.0526 0.0523 

[TRAIN] Epoch[1](2542/114412); Loss: 0.071751; Backpropagation: 0.2903 sec; Batch: 2.1152 sec
0.1159 0.1058 0.0902 0.0802 0.0740 0.0688 0.0666 0.0647 0.0631 0.0620 0.0609 0.0602 0.0597 0.0591 0.0586 0.0583 

[TRAIN] Epoch[1](2543/114412); Loss: 0.070879; Backpropagation: 0.2913 sec; Batch: 2.1158 sec
0.1392 0.1235 0.0865 0.0717 0.0683 0.0646 0.0629 0.0610 0.0599 0.0582 0.0576 0.0569 0.0564 0.0561 0.0557 0.0555 

[TRAIN] Epoch[1](2544/114412); Loss: 0.074455; Backpropagation: 0.2914 sec; Batch: 2.0788 sec
0.1396 0.1297 0.0946 0.0815 0.0738 0.0697 0.0666 0.0637 0.0627 0.0613 0.0600 0.0590 0.0580 0.0575 0.0571 0.0566 

[TRAIN] Epoch[1](2545/114412); Loss: 0.057435; Backpropagation: 0.2906 sec; Batch: 2.1347 sec
0.1449 0.1371 0.0830 0.0651 0.0531 0.0507 0.0464 0.0426 0.0404 0.0388 0.0379 0.0370 0.0362 0.0357 0.0353 0.0349 

[TRAIN] Epoch[1](2546/114412); Loss: 0.055043; Backpropagation: 0.2907 sec; Batch: 2.0779 sec
0.1476 0.1294 0.0733 0.0566 0.0564 0.0478 0.0443 0.0401 0.0384 0.0370 0.0362 0.0357 0.0350 0.0346 0.0343 0.0340 

[TRAIN] Epoch[1](2547/114412); Loss: 0.067197; Backpropagation: 0.2908 sec; Batch: 2.1050 sec
0.1135 0.1066 0.0868 0.0756 0.0696 0.0646 0.0618 0.0592 0.0575 0.0562 0.0554 0.0547 0.0540 0.0536 0.0531 0.0528 

[TRAIN] Epoch[1](2548/114412); Loss: 0.073460; Backpropagation: 0.2945 sec; Batch: 2.1217 sec
0.1442 0.1303 0.1024 0.0860 0.0760 0.0679 0.0656 0.0623 0.0596 0.0575 0.0560 0.0548 0.0539 0.0534 0.0529 0.0525 

[TRAIN] Epoch[1](2549/114412); Loss: 0.049602; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1009 0.0843 0.0621 0.0557 0.0507 0.0461 0.0437 0.0418 0.0406 0.0397 0.0390 0.0383 0.0379 0.0378 0.0376 0.0376 

[TRAIN] Epoch[1](2550/114412); Loss: 0.080862; Backpropagation: 0.2904 sec; Batch: 2.0918 sec
0.1399 0.1334 0.1081 0.0964 0.0938 0.0846 0.0768 0.0729 0.0684 0.0662 0.0634 0.0611 0.0593 0.0578 0.0563 0.0552 

[TRAIN] Epoch[1](2551/114412); Loss: 0.080711; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.1569 0.1476 0.1181 0.0992 0.0843 0.0762 0.0714 0.0663 0.0641 0.0618 0.0600 0.0588 0.0578 0.0569 0.0563 0.0556 

[TRAIN] Epoch[1](2552/114412); Loss: 0.079092; Backpropagation: 0.2914 sec; Batch: 2.1278 sec
0.1496 0.1390 0.0981 0.0869 0.0805 0.0749 0.0707 0.0678 0.0654 0.0643 0.0631 0.0622 0.0616 0.0609 0.0604 0.0600 

[TRAIN] Epoch[1](2553/114412); Loss: 0.073730; Backpropagation: 0.2925 sec; Batch: 2.1181 sec
0.1215 0.1118 0.0895 0.0807 0.0760 0.0722 0.0701 0.0672 0.0650 0.0634 0.0624 0.0612 0.0604 0.0599 0.0594 0.0590 

[TRAIN] Epoch[1](2554/114412); Loss: 0.060174; Backpropagation: 0.2912 sec; Batch: 2.1154 sec
0.1062 0.0989 0.0818 0.0682 0.0624 0.0567 0.0542 0.0521 0.0504 0.0490 0.0482 0.0476 0.0472 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](2555/114412); Loss: 0.050644; Backpropagation: 0.2920 sec; Batch: 2.0868 sec
0.1142 0.0975 0.0677 0.0568 0.0485 0.0449 0.0423 0.0403 0.0395 0.0383 0.0378 0.0373 0.0368 0.0365 0.0362 0.0358 

[TRAIN] Epoch[1](2556/114412); Loss: 0.071118; Backpropagation: 0.2905 sec; Batch: 2.0764 sec
0.1475 0.1376 0.0940 0.0779 0.0697 0.0647 0.0609 0.0584 0.0561 0.0547 0.0539 0.0532 0.0528 0.0525 0.0521 0.0518 

[TRAIN] Epoch[1](2557/114412); Loss: 0.060473; Backpropagation: 0.2906 sec; Batch: 2.1179 sec
0.1287 0.1138 0.0803 0.0621 0.0575 0.0554 0.0521 0.0500 0.0484 0.0474 0.0465 0.0459 0.0454 0.0451 0.0447 0.0443 

[TRAIN] Epoch[1](2558/114412); Loss: 0.073180; Backpropagation: 0.2913 sec; Batch: 2.1118 sec
0.1219 0.1125 0.0924 0.0805 0.0747 0.0710 0.0678 0.0654 0.0637 0.0626 0.0615 0.0606 0.0599 0.0592 0.0588 0.0583 

[TRAIN] Epoch[1](2559/114412); Loss: 0.068665; Backpropagation: 0.2914 sec; Batch: 2.1459 sec
0.1309 0.1150 0.0926 0.0743 0.0697 0.0656 0.0620 0.0587 0.0567 0.0554 0.0542 0.0534 0.0530 0.0525 0.0525 0.0522 

[TRAIN] Epoch[1](2560/114412); Loss: 0.083229; Backpropagation: 0.2907 sec; Batch: 2.1082 sec
0.1468 0.1350 0.1047 0.0923 0.0859 0.0796 0.0760 0.0726 0.0710 0.0692 0.0680 0.0672 0.0666 0.0661 0.0656 0.0651 

[TRAIN] Epoch[1](2561/114412); Loss: 0.068937; Backpropagation: 0.2911 sec; Batch: 2.1206 sec
0.1164 0.1032 0.0813 0.0756 0.0709 0.0661 0.0638 0.0618 0.0603 0.0593 0.0587 0.0580 0.0575 0.0571 0.0566 0.0564 

[TRAIN] Epoch[1](2562/114412); Loss: 0.054153; Backpropagation: 0.2913 sec; Batch: 2.1056 sec
0.1229 0.1120 0.0707 0.0618 0.0549 0.0474 0.0454 0.0427 0.0408 0.0396 0.0389 0.0383 0.0380 0.0378 0.0376 0.0375 

[TRAIN] Epoch[1](2563/114412); Loss: 0.077483; Backpropagation: 0.2920 sec; Batch: 2.1761 sec
0.1510 0.1345 0.1055 0.0890 0.0794 0.0723 0.0684 0.0648 0.0629 0.0613 0.0602 0.0593 0.0586 0.0578 0.0575 0.0572 

[TRAIN] Epoch[1](2564/114412); Loss: 0.075415; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1354 0.1207 0.0943 0.0843 0.0769 0.0716 0.0685 0.0661 0.0641 0.0628 0.0618 0.0611 0.0604 0.0599 0.0596 0.0592 

[TRAIN] Epoch[1](2565/114412); Loss: 0.060285; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1281 0.1178 0.0919 0.0680 0.0595 0.0546 0.0506 0.0478 0.0460 0.0447 0.0438 0.0434 0.0426 0.0423 0.0419 0.0415 

[TRAIN] Epoch[1](2566/114412); Loss: 0.052905; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.1084 0.1011 0.0669 0.0558 0.0510 0.0473 0.0452 0.0438 0.0427 0.0419 0.0414 0.0409 0.0405 0.0402 0.0399 0.0397 

[TRAIN] Epoch[1](2567/114412); Loss: 0.061644; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.1175 0.1068 0.0832 0.0714 0.0639 0.0592 0.0556 0.0518 0.0498 0.0485 0.0477 0.0471 0.0465 0.0460 0.0458 0.0455 

[TRAIN] Epoch[1](2568/114412); Loss: 0.083877; Backpropagation: 0.2903 sec; Batch: 2.1109 sec
0.1250 0.1175 0.1009 0.0931 0.0859 0.0819 0.0798 0.0775 0.0756 0.0745 0.0734 0.0727 0.0718 0.0712 0.0708 0.0704 

[TRAIN] Epoch[1](2569/114412); Loss: 0.066048; Backpropagation: 0.2929 sec; Batch: 2.1328 sec
0.1201 0.1123 0.0848 0.0758 0.0671 0.0618 0.0586 0.0564 0.0551 0.0539 0.0531 0.0524 0.0519 0.0515 0.0511 0.0508 

[TRAIN] Epoch[1](2570/114412); Loss: 0.067383; Backpropagation: 0.2905 sec; Batch: 2.1146 sec
0.1434 0.1228 0.0847 0.0692 0.0649 0.0609 0.0579 0.0562 0.0548 0.0537 0.0530 0.0521 0.0516 0.0513 0.0509 0.0505 

[TRAIN] Epoch[1](2571/114412); Loss: 0.064050; Backpropagation: 0.2912 sec; Batch: 2.1301 sec
0.1436 0.1243 0.0857 0.0717 0.0632 0.0580 0.0542 0.0516 0.0495 0.0481 0.0471 0.0464 0.0459 0.0455 0.0452 0.0449 

[TRAIN] Epoch[1](2572/114412); Loss: 0.057190; Backpropagation: 0.2911 sec; Batch: 2.1144 sec
0.1068 0.0976 0.0777 0.0635 0.0577 0.0533 0.0508 0.0488 0.0474 0.0463 0.0455 0.0449 0.0443 0.0439 0.0435 0.0431 

[TRAIN] Epoch[1](2573/114412); Loss: 0.073875; Backpropagation: 0.2911 sec; Batch: 2.1352 sec
0.1440 0.1354 0.0964 0.0814 0.0711 0.0664 0.0649 0.0635 0.0607 0.0593 0.0583 0.0574 0.0566 0.0559 0.0557 0.0551 

[TRAIN] Epoch[1](2574/114412); Loss: 0.045943; Backpropagation: 0.2907 sec; Batch: 2.1154 sec
0.0990 0.0850 0.0684 0.0549 0.0483 0.0411 0.0385 0.0370 0.0352 0.0339 0.0331 0.0327 0.0324 0.0322 0.0320 0.0318 

[TRAIN] Epoch[1](2575/114412); Loss: 0.058743; Backpropagation: 0.2908 sec; Batch: 2.0773 sec
0.1070 0.0904 0.0821 0.0701 0.0609 0.0568 0.0531 0.0509 0.0490 0.0481 0.0469 0.0461 0.0453 0.0448 0.0444 0.0440 

[TRAIN] Epoch[1](2576/114412); Loss: 0.042270; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.1012 0.0901 0.0554 0.0425 0.0431 0.0377 0.0379 0.0342 0.0317 0.0312 0.0296 0.0291 0.0285 0.0284 0.0280 0.0277 

[TRAIN] Epoch[1](2577/114412); Loss: 0.076381; Backpropagation: 0.2910 sec; Batch: 2.0779 sec
0.1359 0.1201 0.0936 0.0815 0.0767 0.0721 0.0695 0.0671 0.0658 0.0646 0.0639 0.0632 0.0627 0.0622 0.0618 0.0614 

[TRAIN] Epoch[1](2578/114412); Loss: 0.065942; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1234 0.1110 0.0936 0.0781 0.0683 0.0615 0.0589 0.0558 0.0541 0.0523 0.0511 0.0505 0.0498 0.0493 0.0489 0.0486 

[TRAIN] Epoch[1](2579/114412); Loss: 0.067237; Backpropagation: 0.2926 sec; Batch: 2.1183 sec
0.1252 0.1145 0.0888 0.0750 0.0688 0.0643 0.0603 0.0577 0.0559 0.0544 0.0534 0.0524 0.0518 0.0515 0.0510 0.0508 

[TRAIN] Epoch[1](2580/114412); Loss: 0.043969; Backpropagation: 0.2911 sec; Batch: 2.1009 sec
0.0845 0.0779 0.0597 0.0515 0.0464 0.0418 0.0393 0.0368 0.0352 0.0344 0.0338 0.0332 0.0327 0.0324 0.0320 0.0318 

[TRAIN] Epoch[1](2581/114412); Loss: 0.058199; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1200 0.1040 0.0786 0.0667 0.0612 0.0552 0.0507 0.0491 0.0469 0.0450 0.0439 0.0430 0.0423 0.0418 0.0415 0.0413 

[TRAIN] Epoch[1](2582/114412); Loss: 0.076708; Backpropagation: 0.2911 sec; Batch: 2.0771 sec
0.1334 0.1285 0.0983 0.0846 0.0769 0.0736 0.0696 0.0670 0.0655 0.0636 0.0625 0.0617 0.0611 0.0607 0.0603 0.0600 

[TRAIN] Epoch[1](2583/114412); Loss: 0.050146; Backpropagation: 0.2913 sec; Batch: 2.1202 sec
0.1247 0.1110 0.0608 0.0521 0.0506 0.0444 0.0411 0.0392 0.0373 0.0360 0.0353 0.0346 0.0342 0.0339 0.0336 0.0335 

[TRAIN] Epoch[1](2584/114412); Loss: 0.070558; Backpropagation: 0.2925 sec; Batch: 2.1186 sec
0.1314 0.1150 0.0870 0.0774 0.0687 0.0659 0.0637 0.0613 0.0599 0.0585 0.0576 0.0571 0.0567 0.0565 0.0562 0.0560 

[TRAIN] Epoch[1](2585/114412); Loss: 0.071522; Backpropagation: 0.2926 sec; Batch: 2.1192 sec
0.1527 0.1390 0.0980 0.0809 0.0728 0.0664 0.0608 0.0577 0.0555 0.0543 0.0528 0.0519 0.0510 0.0505 0.0501 0.0498 

[TRAIN] Epoch[1](2586/114412); Loss: 0.055369; Backpropagation: 0.2909 sec; Batch: 2.1180 sec
0.1229 0.1044 0.0717 0.0614 0.0555 0.0522 0.0480 0.0454 0.0434 0.0421 0.0413 0.0403 0.0400 0.0394 0.0390 0.0388 

[TRAIN] Epoch[1](2587/114412); Loss: 0.057623; Backpropagation: 0.2911 sec; Batch: 2.0781 sec
0.1425 0.1226 0.0944 0.0762 0.0596 0.0508 0.0492 0.0443 0.0429 0.0396 0.0371 0.0348 0.0331 0.0324 0.0314 0.0310 

[TRAIN] Epoch[1](2588/114412); Loss: 0.072577; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1533 0.1437 0.0879 0.0746 0.0798 0.0722 0.0632 0.0600 0.0579 0.0559 0.0540 0.0531 0.0522 0.0517 0.0511 0.0507 

[TRAIN] Epoch[1](2589/114412); Loss: 0.068929; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.1364 0.1224 0.0889 0.0725 0.0684 0.0639 0.0609 0.0586 0.0568 0.0557 0.0546 0.0538 0.0531 0.0526 0.0522 0.0520 

[TRAIN] Epoch[1](2590/114412); Loss: 0.067039; Backpropagation: 0.2911 sec; Batch: 2.1221 sec
0.1063 0.0990 0.0802 0.0714 0.0677 0.0648 0.0623 0.0610 0.0597 0.0586 0.0581 0.0575 0.0570 0.0566 0.0563 0.0562 

[TRAIN] Epoch[1](2591/114412); Loss: 0.045821; Backpropagation: 0.2904 sec; Batch: 2.0769 sec
0.0940 0.0851 0.0730 0.0534 0.0473 0.0425 0.0395 0.0368 0.0356 0.0342 0.0334 0.0325 0.0320 0.0316 0.0312 0.0310 

[TRAIN] Epoch[1](2592/114412); Loss: 0.072891; Backpropagation: 0.2913 sec; Batch: 2.1224 sec
0.1420 0.1287 0.1049 0.0845 0.0774 0.0705 0.0634 0.0605 0.0579 0.0563 0.0551 0.0543 0.0533 0.0529 0.0523 0.0522 

[TRAIN] Epoch[1](2593/114412); Loss: 0.060818; Backpropagation: 0.2915 sec; Batch: 2.1207 sec
0.1255 0.1095 0.0804 0.0672 0.0630 0.0557 0.0526 0.0509 0.0490 0.0477 0.0468 0.0458 0.0455 0.0450 0.0444 0.0442 

[TRAIN] Epoch[1](2594/114412); Loss: 0.064137; Backpropagation: 0.2902 sec; Batch: 2.0766 sec
0.1204 0.1071 0.0934 0.0800 0.0695 0.0635 0.0585 0.0542 0.0517 0.0498 0.0482 0.0472 0.0465 0.0459 0.0454 0.0450 

[TRAIN] Epoch[1](2595/114412); Loss: 0.066235; Backpropagation: 0.2907 sec; Batch: 2.1291 sec
0.1256 0.1154 0.0828 0.0710 0.0662 0.0614 0.0585 0.0563 0.0553 0.0540 0.0533 0.0527 0.0523 0.0518 0.0516 0.0514 

[TRAIN] Epoch[1](2596/114412); Loss: 0.081281; Backpropagation: 0.2911 sec; Batch: 2.0781 sec
0.1347 0.1180 0.1009 0.0882 0.0839 0.0773 0.0755 0.0732 0.0712 0.0703 0.0693 0.0685 0.0680 0.0674 0.0671 0.0668 

[TRAIN] Epoch[1](2597/114412); Loss: 0.090287; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1828 0.1668 0.1078 0.0918 0.0871 0.0816 0.0792 0.0764 0.0747 0.0733 0.0722 0.0714 0.0706 0.0700 0.0696 0.0692 

[TRAIN] Epoch[1](2598/114412); Loss: 0.053816; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.1109 0.0955 0.0653 0.0627 0.0528 0.0490 0.0463 0.0447 0.0436 0.0426 0.0420 0.0416 0.0414 0.0409 0.0408 0.0407 

[TRAIN] Epoch[1](2599/114412); Loss: 0.075907; Backpropagation: 0.2913 sec; Batch: 2.1186 sec
0.1381 0.1240 0.0987 0.0866 0.0772 0.0723 0.0683 0.0657 0.0639 0.0624 0.0613 0.0605 0.0597 0.0591 0.0585 0.0581 

[TRAIN] Epoch[1](2600/114412); Loss: 0.057546; Backpropagation: 0.2906 sec; Batch: 2.1182 sec
0.1191 0.1052 0.0754 0.0659 0.0616 0.0534 0.0502 0.0477 0.0457 0.0445 0.0435 0.0427 0.0421 0.0417 0.0412 0.0409 

[TRAIN] Epoch[1](2601/114412); Loss: 0.071751; Backpropagation: 0.2915 sec; Batch: 2.1214 sec
0.1435 0.1332 0.1084 0.0867 0.0774 0.0674 0.0617 0.0574 0.0558 0.0535 0.0525 0.0514 0.0506 0.0500 0.0495 0.0490 

[TRAIN] Epoch[1](2602/114412); Loss: 0.056554; Backpropagation: 0.2908 sec; Batch: 2.1201 sec
0.1101 0.1020 0.0724 0.0621 0.0575 0.0531 0.0502 0.0482 0.0464 0.0452 0.0442 0.0436 0.0429 0.0426 0.0423 0.0420 

[TRAIN] Epoch[1](2603/114412); Loss: 0.088821; Backpropagation: 0.2908 sec; Batch: 2.1191 sec
0.1310 0.1206 0.1045 0.0949 0.0900 0.0862 0.0841 0.0822 0.0810 0.0799 0.0791 0.0785 0.0779 0.0775 0.0770 0.0766 

[TRAIN] Epoch[1](2604/114412); Loss: 0.073480; Backpropagation: 0.2912 sec; Batch: 2.1225 sec
0.1452 0.1300 0.1009 0.0841 0.0732 0.0679 0.0646 0.0614 0.0597 0.0581 0.0569 0.0559 0.0553 0.0546 0.0542 0.0538 

[TRAIN] Epoch[1](2605/114412); Loss: 0.071588; Backpropagation: 0.2911 sec; Batch: 2.1208 sec
0.1573 0.1357 0.0845 0.0793 0.0696 0.0635 0.0608 0.0583 0.0567 0.0559 0.0551 0.0547 0.0541 0.0537 0.0532 0.0530 

[TRAIN] Epoch[1](2606/114412); Loss: 0.078160; Backpropagation: 0.2909 sec; Batch: 2.1199 sec
0.1345 0.1125 0.0911 0.0883 0.0825 0.0779 0.0735 0.0704 0.0683 0.0669 0.0658 0.0651 0.0643 0.0635 0.0632 0.0628 

[TRAIN] Epoch[1](2607/114412); Loss: 0.073311; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1160 0.1006 0.0909 0.0829 0.0777 0.0721 0.0685 0.0666 0.0654 0.0639 0.0633 0.0621 0.0613 0.0609 0.0606 0.0602 

[TRAIN] Epoch[1](2608/114412); Loss: 0.058572; Backpropagation: 0.2908 sec; Batch: 2.1211 sec
0.1226 0.1126 0.0737 0.0680 0.0589 0.0522 0.0508 0.0492 0.0473 0.0455 0.0445 0.0435 0.0428 0.0422 0.0418 0.0415 

[TRAIN] Epoch[1](2609/114412); Loss: 0.085157; Backpropagation: 0.2916 sec; Batch: 2.1062 sec
0.1526 0.1320 0.1085 0.0941 0.0893 0.0825 0.0783 0.0758 0.0733 0.0716 0.0696 0.0685 0.0676 0.0668 0.0663 0.0655 

[TRAIN] Epoch[1](2610/114412); Loss: 0.078787; Backpropagation: 0.2907 sec; Batch: 2.1267 sec
0.1498 0.1201 0.0908 0.0854 0.0826 0.0770 0.0732 0.0698 0.0679 0.0666 0.0652 0.0642 0.0631 0.0624 0.0616 0.0610 

[TRAIN] Epoch[1](2611/114412); Loss: 0.085958; Backpropagation: 0.2929 sec; Batch: 2.1136 sec
0.1446 0.1285 0.1027 0.0961 0.0891 0.0837 0.0800 0.0778 0.0761 0.0745 0.0729 0.0716 0.0703 0.0696 0.0691 0.0687 

[TRAIN] Epoch[1](2612/114412); Loss: 0.082281; Backpropagation: 0.2911 sec; Batch: 2.1432 sec
0.1636 0.1436 0.1009 0.0898 0.0810 0.0756 0.0717 0.0703 0.0687 0.0672 0.0659 0.0650 0.0641 0.0635 0.0630 0.0626 

[TRAIN] Epoch[1](2613/114412); Loss: 0.073334; Backpropagation: 0.2910 sec; Batch: 2.1118 sec
0.1347 0.1191 0.0931 0.0860 0.0769 0.0711 0.0671 0.0640 0.0620 0.0602 0.0587 0.0577 0.0565 0.0560 0.0554 0.0548 

[TRAIN] Epoch[1](2614/114412); Loss: 0.065818; Backpropagation: 0.2913 sec; Batch: 2.1099 sec
0.1099 0.0965 0.0858 0.0785 0.0694 0.0642 0.0601 0.0582 0.0570 0.0555 0.0546 0.0537 0.0530 0.0525 0.0523 0.0520 

[TRAIN] Epoch[1](2615/114412); Loss: 0.063011; Backpropagation: 0.2911 sec; Batch: 2.1878 sec
0.1311 0.1137 0.0849 0.0795 0.0681 0.0606 0.0554 0.0524 0.0506 0.0483 0.0463 0.0451 0.0440 0.0433 0.0426 0.0421 

[TRAIN] Epoch[1](2616/114412); Loss: 0.095526; Backpropagation: 0.2929 sec; Batch: 2.1899 sec
0.1737 0.1498 0.1154 0.1062 0.1003 0.0951 0.0899 0.0863 0.0835 0.0807 0.0782 0.0767 0.0747 0.0738 0.0725 0.0717 

[TRAIN] Epoch[1](2617/114412); Loss: 0.074969; Backpropagation: 0.2920 sec; Batch: 2.2346 sec
0.1533 0.1255 0.0976 0.0884 0.0764 0.0709 0.0663 0.0637 0.0615 0.0598 0.0583 0.0570 0.0562 0.0555 0.0548 0.0543 

[TRAIN] Epoch[1](2618/114412); Loss: 0.078226; Backpropagation: 0.2911 sec; Batch: 2.2362 sec
0.1481 0.1299 0.0979 0.0911 0.0814 0.0751 0.0707 0.0674 0.0650 0.0632 0.0623 0.0612 0.0605 0.0598 0.0592 0.0587 

[TRAIN] Epoch[1](2619/114412); Loss: 0.082290; Backpropagation: 0.2910 sec; Batch: 2.1441 sec
0.1883 0.1652 0.1117 0.0966 0.0874 0.0765 0.0674 0.0661 0.0620 0.0596 0.0584 0.0569 0.0558 0.0552 0.0548 0.0546 

[TRAIN] Epoch[1](2620/114412); Loss: 0.052640; Backpropagation: 0.2912 sec; Batch: 2.1082 sec
0.1392 0.1054 0.0701 0.0568 0.0516 0.0444 0.0431 0.0408 0.0390 0.0378 0.0371 0.0362 0.0357 0.0353 0.0349 0.0347 

[TRAIN] Epoch[1](2621/114412); Loss: 0.074515; Backpropagation: 0.2907 sec; Batch: 2.1180 sec
0.1619 0.1426 0.0966 0.0794 0.0725 0.0664 0.0630 0.0627 0.0593 0.0577 0.0568 0.0558 0.0551 0.0544 0.0542 0.0540 

[TRAIN] Epoch[1](2622/114412); Loss: 0.081513; Backpropagation: 0.2917 sec; Batch: 2.1418 sec
0.1179 0.1087 0.0930 0.0860 0.0821 0.0792 0.0772 0.0756 0.0746 0.0740 0.0733 0.0729 0.0726 0.0725 0.0724 0.0722 

[TRAIN] Epoch[1](2623/114412); Loss: 0.096768; Backpropagation: 0.2911 sec; Batch: 2.4953 sec
0.1499 0.1361 0.1234 0.1127 0.1040 0.0970 0.0928 0.0892 0.0860 0.0836 0.0818 0.0804 0.0791 0.0780 0.0773 0.0766 

[TRAIN] Epoch[1](2624/114412); Loss: 0.064320; Backpropagation: 0.2911 sec; Batch: 2.1752 sec
0.1351 0.1027 0.0813 0.0705 0.0619 0.0583 0.0562 0.0545 0.0533 0.0524 0.0515 0.0509 0.0506 0.0502 0.0499 0.0497 

[TRAIN] Epoch[1](2625/114412); Loss: 0.079846; Backpropagation: 0.2906 sec; Batch: 2.1062 sec
0.1885 0.1683 0.1112 0.0941 0.0761 0.0673 0.0640 0.0617 0.0593 0.0578 0.0565 0.0557 0.0551 0.0544 0.0539 0.0536 

[TRAIN] Epoch[1](2626/114412); Loss: 0.067351; Backpropagation: 0.2911 sec; Batch: 2.3621 sec
0.1472 0.1184 0.0808 0.0755 0.0671 0.0614 0.0588 0.0561 0.0545 0.0533 0.0523 0.0515 0.0508 0.0503 0.0499 0.0496 

[TRAIN] Epoch[1](2627/114412); Loss: 0.079142; Backpropagation: 0.2906 sec; Batch: 2.1086 sec
0.1457 0.1184 0.0955 0.0862 0.0807 0.0757 0.0728 0.0703 0.0689 0.0673 0.0659 0.0651 0.0642 0.0635 0.0632 0.0627 

[TRAIN] Epoch[1](2628/114412); Loss: 0.068000; Backpropagation: 0.2909 sec; Batch: 2.1236 sec
0.1547 0.1281 0.0946 0.0796 0.0705 0.0618 0.0570 0.0556 0.0528 0.0507 0.0493 0.0482 0.0473 0.0464 0.0459 0.0454 

[TRAIN] Epoch[1](2629/114412); Loss: 0.068224; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.1479 0.1214 0.0876 0.0750 0.0700 0.0638 0.0596 0.0571 0.0546 0.0531 0.0519 0.0511 0.0503 0.0499 0.0493 0.0490 

[TRAIN] Epoch[1](2630/114412); Loss: 0.070806; Backpropagation: 0.2908 sec; Batch: 2.1282 sec
0.1660 0.1272 0.0874 0.0861 0.0721 0.0632 0.0603 0.0570 0.0549 0.0536 0.0524 0.0515 0.0511 0.0505 0.0499 0.0497 

[TRAIN] Epoch[1](2631/114412); Loss: 0.064376; Backpropagation: 0.2911 sec; Batch: 2.1228 sec
0.1356 0.1066 0.0840 0.0765 0.0664 0.0599 0.0562 0.0533 0.0515 0.0502 0.0494 0.0487 0.0483 0.0480 0.0477 0.0477 

[TRAIN] Epoch[1](2632/114412); Loss: 0.072473; Backpropagation: 0.2916 sec; Batch: 2.1346 sec
0.1467 0.1208 0.0849 0.0789 0.0729 0.0684 0.0645 0.0625 0.0607 0.0594 0.0583 0.0574 0.0567 0.0562 0.0558 0.0555 

[TRAIN] Epoch[1](2633/114412); Loss: 0.073716; Backpropagation: 0.2913 sec; Batch: 2.1196 sec
0.1327 0.1093 0.0874 0.0803 0.0757 0.0708 0.0677 0.0657 0.0642 0.0629 0.0618 0.0612 0.0606 0.0600 0.0598 0.0596 

[TRAIN] Epoch[1](2634/114412); Loss: 0.071255; Backpropagation: 0.2930 sec; Batch: 2.1320 sec
0.1225 0.1193 0.0904 0.0766 0.0750 0.0693 0.0649 0.0625 0.0606 0.0596 0.0584 0.0573 0.0566 0.0561 0.0558 0.0553 

[TRAIN] Epoch[1](2635/114412); Loss: 0.095321; Backpropagation: 0.2933 sec; Batch: 2.1180 sec
0.1708 0.1484 0.1168 0.1079 0.0990 0.0929 0.0881 0.0848 0.0822 0.0797 0.0783 0.0771 0.0758 0.0751 0.0744 0.0737 

[TRAIN] Epoch[1](2636/114412); Loss: 0.060886; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1176 0.1013 0.0861 0.0717 0.0622 0.0558 0.0539 0.0513 0.0495 0.0483 0.0472 0.0466 0.0461 0.0457 0.0455 0.0452 

[TRAIN] Epoch[1](2637/114412); Loss: 0.086972; Backpropagation: 0.2910 sec; Batch: 2.0783 sec
0.1514 0.1418 0.1089 0.0986 0.0884 0.0834 0.0792 0.0767 0.0743 0.0726 0.0714 0.0703 0.0695 0.0688 0.0683 0.0678 

[TRAIN] Epoch[1](2638/114412); Loss: 0.095586; Backpropagation: 0.2908 sec; Batch: 2.0768 sec
0.1569 0.1357 0.1167 0.1072 0.1001 0.0930 0.0882 0.0860 0.0838 0.0823 0.0812 0.0804 0.0798 0.0796 0.0792 0.0791 

[TRAIN] Epoch[1](2639/114412); Loss: 0.081357; Backpropagation: 0.2933 sec; Batch: 2.1804 sec
0.1684 0.1355 0.1027 0.0907 0.0839 0.0762 0.0729 0.0688 0.0665 0.0650 0.0639 0.0628 0.0620 0.0613 0.0608 0.0603 

[TRAIN] Epoch[1](2640/114412); Loss: 0.061076; Backpropagation: 0.2911 sec; Batch: 2.0768 sec
0.0987 0.0969 0.0786 0.0720 0.0626 0.0588 0.0564 0.0542 0.0530 0.0515 0.0504 0.0499 0.0493 0.0487 0.0483 0.0479 

[TRAIN] Epoch[1](2641/114412); Loss: 0.062705; Backpropagation: 0.2928 sec; Batch: 2.1203 sec
0.1306 0.1153 0.0736 0.0632 0.0598 0.0560 0.0540 0.0525 0.0517 0.0510 0.0503 0.0498 0.0493 0.0489 0.0488 0.0486 

[TRAIN] Epoch[1](2642/114412); Loss: 0.052506; Backpropagation: 0.2954 sec; Batch: 2.1182 sec
0.1365 0.0974 0.0679 0.0573 0.0547 0.0463 0.0434 0.0418 0.0401 0.0385 0.0375 0.0368 0.0362 0.0355 0.0352 0.0350 

[TRAIN] Epoch[1](2643/114412); Loss: 0.061252; Backpropagation: 0.2930 sec; Batch: 2.1348 sec
0.1316 0.1049 0.0758 0.0676 0.0626 0.0568 0.0533 0.0517 0.0499 0.0485 0.0475 0.0468 0.0463 0.0459 0.0455 0.0453 

[TRAIN] Epoch[1](2644/114412); Loss: 0.065476; Backpropagation: 0.2929 sec; Batch: 2.1215 sec
0.1308 0.1095 0.0824 0.0720 0.0668 0.0610 0.0580 0.0560 0.0543 0.0532 0.0522 0.0513 0.0506 0.0501 0.0499 0.0495 

[TRAIN] Epoch[1](2645/114412); Loss: 0.066401; Backpropagation: 0.2913 sec; Batch: 2.1236 sec
0.1775 0.1351 0.0844 0.0746 0.0673 0.0583 0.0535 0.0510 0.0493 0.0470 0.0457 0.0448 0.0441 0.0436 0.0433 0.0429 

[TRAIN] Epoch[1](2646/114412); Loss: 0.071750; Backpropagation: 0.2928 sec; Batch: 2.1197 sec
0.1454 0.1194 0.0916 0.0815 0.0721 0.0667 0.0637 0.0608 0.0585 0.0574 0.0566 0.0558 0.0551 0.0548 0.0544 0.0541 

[TRAIN] Epoch[1](2647/114412); Loss: 0.085992; Backpropagation: 0.2925 sec; Batch: 2.0839 sec
0.1843 0.1681 0.1233 0.1058 0.0874 0.0772 0.0728 0.0694 0.0662 0.0645 0.0627 0.0607 0.0596 0.0587 0.0578 0.0573 

[TRAIN] Epoch[1](2648/114412); Loss: 0.064024; Backpropagation: 0.2912 sec; Batch: 2.0770 sec
0.1403 0.1041 0.0781 0.0675 0.0629 0.0585 0.0558 0.0543 0.0526 0.0517 0.0509 0.0502 0.0498 0.0494 0.0492 0.0490 

[TRAIN] Epoch[1](2649/114412); Loss: 0.053789; Backpropagation: 0.2927 sec; Batch: 2.1184 sec
0.1016 0.0934 0.0696 0.0614 0.0541 0.0500 0.0474 0.0454 0.0442 0.0431 0.0426 0.0421 0.0418 0.0414 0.0412 0.0412 

[TRAIN] Epoch[1](2650/114412); Loss: 0.081579; Backpropagation: 0.2907 sec; Batch: 2.1209 sec
0.1305 0.1115 0.0976 0.0908 0.0838 0.0792 0.0760 0.0742 0.0727 0.0717 0.0708 0.0701 0.0695 0.0692 0.0690 0.0687 

[TRAIN] Epoch[1](2651/114412); Loss: 0.065903; Backpropagation: 0.2927 sec; Batch: 2.0878 sec
0.1458 0.1208 0.0853 0.0756 0.0670 0.0602 0.0569 0.0541 0.0517 0.0506 0.0493 0.0484 0.0479 0.0473 0.0469 0.0466 

[TRAIN] Epoch[1](2652/114412); Loss: 0.060074; Backpropagation: 0.2907 sec; Batch: 2.0799 sec
0.1245 0.0995 0.0740 0.0641 0.0631 0.0572 0.0529 0.0509 0.0494 0.0483 0.0475 0.0466 0.0463 0.0459 0.0456 0.0454 

[TRAIN] Epoch[1](2653/114412); Loss: 0.067941; Backpropagation: 0.2901 sec; Batch: 2.0770 sec
0.1280 0.1140 0.0891 0.0819 0.0727 0.0665 0.0617 0.0585 0.0563 0.0543 0.0528 0.0516 0.0508 0.0502 0.0496 0.0491 

[TRAIN] Epoch[1](2654/114412); Loss: 0.079517; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.1269 0.1113 0.0954 0.0860 0.0820 0.0783 0.0746 0.0723 0.0710 0.0697 0.0690 0.0681 0.0675 0.0670 0.0667 0.0664 

[TRAIN] Epoch[1](2655/114412); Loss: 0.083789; Backpropagation: 0.2908 sec; Batch: 2.0961 sec
0.1506 0.1288 0.1064 0.0949 0.0871 0.0797 0.0760 0.0737 0.0718 0.0703 0.0689 0.0679 0.0670 0.0663 0.0659 0.0654 

[TRAIN] Epoch[1](2656/114412); Loss: 0.069569; Backpropagation: 0.2915 sec; Batch: 2.1147 sec
0.1412 0.1234 0.1024 0.0897 0.0791 0.0695 0.0618 0.0583 0.0567 0.0527 0.0490 0.0478 0.0471 0.0456 0.0447 0.0442 

[TRAIN] Epoch[1](2657/114412); Loss: 0.057891; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1232 0.1023 0.0778 0.0657 0.0600 0.0547 0.0512 0.0486 0.0465 0.0449 0.0436 0.0427 0.0421 0.0415 0.0410 0.0406 

[TRAIN] Epoch[1](2658/114412); Loss: 0.080538; Backpropagation: 0.2931 sec; Batch: 2.0995 sec
0.1663 0.1495 0.1206 0.1064 0.0907 0.0808 0.0732 0.0688 0.0631 0.0591 0.0563 0.0533 0.0518 0.0505 0.0494 0.0487 

[TRAIN] Epoch[1](2659/114412); Loss: 0.065964; Backpropagation: 0.2913 sec; Batch: 2.1153 sec
0.1278 0.1075 0.0825 0.0797 0.0707 0.0654 0.0611 0.0577 0.0552 0.0531 0.0515 0.0502 0.0492 0.0484 0.0480 0.0475 

[TRAIN] Epoch[1](2660/114412); Loss: 0.063725; Backpropagation: 0.2911 sec; Batch: 2.1052 sec
0.1163 0.1143 0.0885 0.0762 0.0661 0.0599 0.0569 0.0545 0.0519 0.0503 0.0492 0.0484 0.0476 0.0471 0.0465 0.0461 

[TRAIN] Epoch[1](2661/114412); Loss: 0.085037; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1609 0.1401 0.1185 0.1018 0.0892 0.0812 0.0764 0.0721 0.0689 0.0675 0.0662 0.0649 0.0641 0.0634 0.0629 0.0624 

[TRAIN] Epoch[1](2662/114412); Loss: 0.069655; Backpropagation: 0.2904 sec; Batch: 2.1165 sec
0.1452 0.1159 0.0838 0.0740 0.0717 0.0659 0.0623 0.0598 0.0579 0.0564 0.0553 0.0545 0.0536 0.0532 0.0527 0.0522 

[TRAIN] Epoch[1](2663/114412); Loss: 0.058466; Backpropagation: 0.2905 sec; Batch: 2.1264 sec
0.1282 0.1035 0.0757 0.0658 0.0596 0.0555 0.0510 0.0489 0.0466 0.0451 0.0442 0.0432 0.0427 0.0422 0.0418 0.0415 

[TRAIN] Epoch[1](2664/114412); Loss: 0.053191; Backpropagation: 0.2909 sec; Batch: 2.1251 sec
0.1009 0.0864 0.0679 0.0609 0.0545 0.0499 0.0473 0.0460 0.0444 0.0433 0.0426 0.0421 0.0417 0.0413 0.0410 0.0408 

[TRAIN] Epoch[1](2665/114412); Loss: 0.061358; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1549 0.1239 0.0980 0.0807 0.0666 0.0578 0.0511 0.0459 0.0423 0.0402 0.0389 0.0378 0.0369 0.0361 0.0355 0.0352 

[TRAIN] Epoch[1](2666/114412); Loss: 0.085525; Backpropagation: 0.2929 sec; Batch: 2.1190 sec
0.1578 0.1457 0.1186 0.1094 0.0898 0.0810 0.0771 0.0718 0.0693 0.0669 0.0654 0.0646 0.0636 0.0629 0.0625 0.0621 

[TRAIN] Epoch[1](2667/114412); Loss: 0.081958; Backpropagation: 0.2913 sec; Batch: 2.1165 sec
0.1932 0.1649 0.1089 0.0884 0.0771 0.0690 0.0672 0.0643 0.0620 0.0623 0.0607 0.0595 0.0589 0.0585 0.0583 0.0581 

[TRAIN] Epoch[1](2668/114412); Loss: 0.076156; Backpropagation: 0.2911 sec; Batch: 2.0849 sec
0.1667 0.1402 0.1166 0.0929 0.0778 0.0699 0.0677 0.0643 0.0600 0.0574 0.0550 0.0528 0.0511 0.0499 0.0486 0.0478 

[TRAIN] Epoch[1](2669/114412); Loss: 0.069796; Backpropagation: 0.2912 sec; Batch: 2.0947 sec
0.1251 0.1137 0.0967 0.0803 0.0742 0.0678 0.0641 0.0611 0.0584 0.0566 0.0553 0.0542 0.0533 0.0525 0.0519 0.0518 

[TRAIN] Epoch[1](2670/114412); Loss: 0.064209; Backpropagation: 0.2909 sec; Batch: 2.1207 sec
0.1126 0.0997 0.0785 0.0717 0.0669 0.0623 0.0584 0.0569 0.0549 0.0539 0.0533 0.0524 0.0519 0.0517 0.0513 0.0511 

[TRAIN] Epoch[1](2671/114412); Loss: 0.105151; Backpropagation: 0.2910 sec; Batch: 2.0973 sec
0.1779 0.1559 0.1313 0.1166 0.1107 0.1055 0.0977 0.0951 0.0926 0.0897 0.0881 0.0863 0.0851 0.0842 0.0831 0.0825 

[TRAIN] Epoch[1](2672/114412); Loss: 0.078432; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1783 0.1457 0.0912 0.0854 0.0762 0.0726 0.0675 0.0658 0.0633 0.0612 0.0598 0.0587 0.0582 0.0574 0.0570 0.0567 

[TRAIN] Epoch[1](2673/114412); Loss: 0.082672; Backpropagation: 0.2909 sec; Batch: 2.0786 sec
0.1970 0.1562 0.1105 0.1016 0.0868 0.0776 0.0695 0.0662 0.0627 0.0603 0.0584 0.0571 0.0559 0.0550 0.0542 0.0537 

[TRAIN] Epoch[1](2674/114412); Loss: 0.058174; Backpropagation: 0.2911 sec; Batch: 2.1150 sec
0.1583 0.1118 0.0832 0.0667 0.0541 0.0499 0.0468 0.0439 0.0424 0.0413 0.0401 0.0397 0.0388 0.0383 0.0380 0.0375 

[TRAIN] Epoch[1](2675/114412); Loss: 0.098786; Backpropagation: 0.2929 sec; Batch: 2.1202 sec
0.2046 0.1698 0.1303 0.1169 0.1029 0.0936 0.0872 0.0823 0.0792 0.0768 0.0752 0.0739 0.0730 0.0721 0.0715 0.0712 

[TRAIN] Epoch[1](2676/114412); Loss: 0.075083; Backpropagation: 0.2908 sec; Batch: 2.1190 sec
0.1599 0.1237 0.0968 0.0848 0.0778 0.0700 0.0660 0.0637 0.0610 0.0593 0.0581 0.0573 0.0565 0.0558 0.0555 0.0551 

[TRAIN] Epoch[1](2677/114412); Loss: 0.078693; Backpropagation: 0.2913 sec; Batch: 2.1170 sec
0.1508 0.1266 0.0996 0.0898 0.0829 0.0745 0.0703 0.0675 0.0654 0.0641 0.0630 0.0620 0.0614 0.0609 0.0604 0.0598 

[TRAIN] Epoch[1](2678/114412); Loss: 0.069237; Backpropagation: 0.2929 sec; Batch: 2.1159 sec
0.1457 0.1174 0.0927 0.0787 0.0717 0.0637 0.0595 0.0569 0.0554 0.0541 0.0533 0.0525 0.0521 0.0518 0.0514 0.0510 

[TRAIN] Epoch[1](2679/114412); Loss: 0.066775; Backpropagation: 0.2908 sec; Batch: 2.1196 sec
0.1354 0.0988 0.0827 0.0724 0.0672 0.0634 0.0598 0.0576 0.0563 0.0552 0.0545 0.0538 0.0533 0.0529 0.0527 0.0526 

[TRAIN] Epoch[1](2680/114412); Loss: 0.049985; Backpropagation: 0.2930 sec; Batch: 2.0796 sec
0.1494 0.0806 0.0599 0.0544 0.0502 0.0431 0.0403 0.0393 0.0378 0.0367 0.0355 0.0350 0.0347 0.0343 0.0343 0.0342 

[TRAIN] Epoch[1](2681/114412); Loss: 0.059346; Backpropagation: 0.2951 sec; Batch: 2.0831 sec
0.1437 0.1061 0.0708 0.0597 0.0547 0.0519 0.0498 0.0485 0.0472 0.0464 0.0459 0.0453 0.0452 0.0450 0.0448 0.0446 

[TRAIN] Epoch[1](2682/114412); Loss: 0.056341; Backpropagation: 0.2911 sec; Batch: 2.1164 sec
0.1225 0.0894 0.0660 0.0594 0.0561 0.0521 0.0500 0.0484 0.0467 0.0459 0.0452 0.0446 0.0442 0.0439 0.0435 0.0433 

[TRAIN] Epoch[1](2683/114412); Loss: 0.060147; Backpropagation: 0.2928 sec; Batch: 2.0790 sec
0.1198 0.1003 0.0783 0.0719 0.0617 0.0571 0.0535 0.0508 0.0492 0.0476 0.0468 0.0461 0.0454 0.0451 0.0446 0.0442 

[TRAIN] Epoch[1](2684/114412); Loss: 0.064631; Backpropagation: 0.2931 sec; Batch: 2.1191 sec
0.1201 0.1093 0.0847 0.0738 0.0672 0.0608 0.0579 0.0552 0.0537 0.0525 0.0514 0.0506 0.0499 0.0494 0.0489 0.0485 

[TRAIN] Epoch[1](2685/114412); Loss: 0.054960; Backpropagation: 0.2919 sec; Batch: 2.1175 sec
0.1083 0.0908 0.0692 0.0617 0.0541 0.0514 0.0485 0.0472 0.0461 0.0449 0.0441 0.0434 0.0430 0.0425 0.0422 0.0419 

[TRAIN] Epoch[1](2686/114412); Loss: 0.087588; Backpropagation: 0.2907 sec; Batch: 2.1255 sec
0.1599 0.1151 0.1047 0.0959 0.0886 0.0856 0.0818 0.0787 0.0771 0.0758 0.0748 0.0739 0.0730 0.0726 0.0721 0.0717 

[TRAIN] Epoch[1](2687/114412); Loss: 0.062684; Backpropagation: 0.2911 sec; Batch: 2.1218 sec
0.1246 0.0946 0.0789 0.0695 0.0638 0.0593 0.0560 0.0541 0.0529 0.0517 0.0508 0.0502 0.0496 0.0493 0.0490 0.0486 

[TRAIN] Epoch[1](2688/114412); Loss: 0.077827; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1309 0.1131 0.1027 0.0861 0.0778 0.0746 0.0705 0.0690 0.0679 0.0663 0.0657 0.0650 0.0645 0.0641 0.0637 0.0633 

[TRAIN] Epoch[1](2689/114412); Loss: 0.073557; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1383 0.1207 0.0974 0.0864 0.0765 0.0698 0.0663 0.0632 0.0613 0.0595 0.0582 0.0571 0.0563 0.0557 0.0552 0.0549 

[TRAIN] Epoch[1](2690/114412); Loss: 0.066938; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.1549 0.1206 0.0849 0.0735 0.0668 0.0595 0.0574 0.0542 0.0521 0.0514 0.0506 0.0499 0.0494 0.0489 0.0486 0.0482 

[TRAIN] Epoch[1](2691/114412); Loss: 0.056814; Backpropagation: 0.2914 sec; Batch: 2.1193 sec
0.1338 0.1160 0.0782 0.0660 0.0532 0.0503 0.0471 0.0439 0.0422 0.0411 0.0406 0.0400 0.0396 0.0393 0.0389 0.0388 

[TRAIN] Epoch[1](2692/114412); Loss: 0.081335; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1297 0.1222 0.1069 0.0955 0.0858 0.0799 0.0769 0.0726 0.0706 0.0687 0.0676 0.0664 0.0654 0.0647 0.0644 0.0638 

[TRAIN] Epoch[1](2693/114412); Loss: 0.074992; Backpropagation: 0.2932 sec; Batch: 2.1228 sec
0.1532 0.1128 0.0936 0.0840 0.0754 0.0714 0.0675 0.0646 0.0630 0.0615 0.0605 0.0597 0.0589 0.0584 0.0579 0.0576 

[TRAIN] Epoch[1](2694/114412); Loss: 0.081861; Backpropagation: 0.2923 sec; Batch: 2.1168 sec
0.1456 0.1190 0.1026 0.0921 0.0813 0.0765 0.0750 0.0726 0.0712 0.0700 0.0690 0.0682 0.0675 0.0668 0.0664 0.0660 

[TRAIN] Epoch[1](2695/114412); Loss: 0.056979; Backpropagation: 0.2929 sec; Batch: 2.1207 sec
0.1492 0.1076 0.0891 0.0689 0.0549 0.0483 0.0450 0.0422 0.0408 0.0395 0.0386 0.0381 0.0376 0.0375 0.0373 0.0372 

[TRAIN] Epoch[1](2696/114412); Loss: 0.077356; Backpropagation: 0.2913 sec; Batch: 2.1195 sec
0.1806 0.1386 0.0984 0.0844 0.0728 0.0687 0.0643 0.0622 0.0608 0.0590 0.0584 0.0579 0.0579 0.0579 0.0579 0.0578 

[TRAIN] Epoch[1](2697/114412); Loss: 0.076061; Backpropagation: 0.2932 sec; Batch: 2.0806 sec
0.1334 0.1128 0.0945 0.0856 0.0785 0.0736 0.0700 0.0672 0.0659 0.0644 0.0633 0.0627 0.0619 0.0614 0.0611 0.0608 

[TRAIN] Epoch[1](2698/114412); Loss: 0.052164; Backpropagation: 0.2912 sec; Batch: 2.1231 sec
0.1176 0.0862 0.0638 0.0584 0.0512 0.0475 0.0453 0.0435 0.0423 0.0413 0.0405 0.0399 0.0396 0.0393 0.0391 0.0389 

[TRAIN] Epoch[1](2699/114412); Loss: 0.058446; Backpropagation: 0.2909 sec; Batch: 2.1316 sec
0.1061 0.0888 0.0738 0.0653 0.0612 0.0565 0.0533 0.0519 0.0499 0.0488 0.0479 0.0471 0.0466 0.0463 0.0459 0.0457 

[TRAIN] Epoch[1](2700/114412); Loss: 0.054198; Backpropagation: 0.2916 sec; Batch: 2.0785 sec
0.1219 0.0961 0.0752 0.0639 0.0576 0.0502 0.0458 0.0435 0.0414 0.0403 0.0397 0.0390 0.0385 0.0382 0.0380 0.0378 

[TRAIN] Epoch[1](2701/114412); Loss: 0.067904; Backpropagation: 0.2912 sec; Batch: 2.1362 sec
0.1290 0.1079 0.0857 0.0746 0.0696 0.0632 0.0602 0.0589 0.0574 0.0560 0.0553 0.0545 0.0540 0.0537 0.0533 0.0532 

[TRAIN] Epoch[1](2702/114412); Loss: 0.075889; Backpropagation: 0.2920 sec; Batch: 2.1395 sec
0.1551 0.1233 0.0923 0.0859 0.0763 0.0717 0.0673 0.0649 0.0634 0.0619 0.0606 0.0597 0.0588 0.0582 0.0576 0.0572 

[TRAIN] Epoch[1](2703/114412); Loss: 0.081180; Backpropagation: 0.2951 sec; Batch: 2.2842 sec
0.1497 0.1293 0.1069 0.0933 0.0824 0.0765 0.0721 0.0699 0.0682 0.0668 0.0657 0.0650 0.0641 0.0635 0.0630 0.0625 

[TRAIN] Epoch[1](2704/114412); Loss: 0.042111; Backpropagation: 0.2911 sec; Batch: 2.1601 sec
0.1080 0.0806 0.0499 0.0475 0.0433 0.0365 0.0343 0.0327 0.0318 0.0307 0.0302 0.0299 0.0298 0.0296 0.0295 0.0295 

[TRAIN] Epoch[1](2705/114412); Loss: 0.069621; Backpropagation: 0.2908 sec; Batch: 2.1508 sec
0.1418 0.1244 0.0882 0.0784 0.0705 0.0641 0.0606 0.0585 0.0567 0.0552 0.0543 0.0533 0.0527 0.0522 0.0517 0.0514 

[TRAIN] Epoch[1](2706/114412); Loss: 0.068636; Backpropagation: 0.2911 sec; Batch: 2.0920 sec
0.1496 0.1141 0.0972 0.0809 0.0661 0.0645 0.0602 0.0573 0.0541 0.0528 0.0515 0.0507 0.0503 0.0499 0.0496 0.0493 

[TRAIN] Epoch[1](2707/114412); Loss: 0.061903; Backpropagation: 0.2906 sec; Batch: 2.1163 sec
0.1399 0.1150 0.0772 0.0674 0.0580 0.0551 0.0522 0.0510 0.0495 0.0483 0.0472 0.0466 0.0462 0.0458 0.0456 0.0455 

[TRAIN] Epoch[1](2708/114412); Loss: 0.073167; Backpropagation: 0.2904 sec; Batch: 2.1203 sec
0.1590 0.1337 0.1024 0.0851 0.0721 0.0661 0.0613 0.0587 0.0567 0.0555 0.0548 0.0541 0.0534 0.0529 0.0527 0.0523 

[TRAIN] Epoch[1](2709/114412); Loss: 0.068303; Backpropagation: 0.2915 sec; Batch: 2.1177 sec
0.1461 0.1112 0.0847 0.0771 0.0701 0.0631 0.0603 0.0578 0.0562 0.0547 0.0536 0.0527 0.0520 0.0515 0.0510 0.0506 

[TRAIN] Epoch[1](2710/114412); Loss: 0.086766; Backpropagation: 0.2911 sec; Batch: 2.1143 sec
0.1478 0.1268 0.1032 0.0946 0.0869 0.0825 0.0799 0.0779 0.0763 0.0751 0.0742 0.0736 0.0730 0.0726 0.0722 0.0718 

[TRAIN] Epoch[1](2711/114412); Loss: 0.079037; Backpropagation: 0.2916 sec; Batch: 2.0933 sec
0.1506 0.1280 0.1002 0.0891 0.0823 0.0763 0.0716 0.0684 0.0661 0.0646 0.0635 0.0623 0.0614 0.0607 0.0600 0.0595 

[TRAIN] Epoch[1](2712/114412); Loss: 0.086380; Backpropagation: 0.2907 sec; Batch: 2.1172 sec
0.1677 0.1313 0.1005 0.0931 0.0889 0.0820 0.0779 0.0756 0.0738 0.0726 0.0713 0.0705 0.0698 0.0694 0.0690 0.0687 

[TRAIN] Epoch[1](2713/114412); Loss: 0.073063; Backpropagation: 0.2953 sec; Batch: 2.1306 sec
0.1724 0.1269 0.0869 0.0835 0.0732 0.0680 0.0645 0.0607 0.0582 0.0565 0.0548 0.0540 0.0533 0.0525 0.0521 0.0516 

[TRAIN] Epoch[1](2714/114412); Loss: 0.067141; Backpropagation: 0.2913 sec; Batch: 2.0846 sec
0.1331 0.1134 0.0903 0.0775 0.0685 0.0641 0.0591 0.0566 0.0546 0.0531 0.0522 0.0514 0.0507 0.0502 0.0498 0.0495 

[TRAIN] Epoch[1](2715/114412); Loss: 0.070794; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1787 0.1251 0.0890 0.0750 0.0702 0.0642 0.0600 0.0574 0.0555 0.0537 0.0524 0.0517 0.0508 0.0502 0.0497 0.0492 

[TRAIN] Epoch[1](2716/114412); Loss: 0.068038; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1311 0.0948 0.0809 0.0739 0.0688 0.0656 0.0631 0.0610 0.0593 0.0579 0.0568 0.0563 0.0555 0.0549 0.0545 0.0542 

[TRAIN] Epoch[1](2717/114412); Loss: 0.082044; Backpropagation: 0.2928 sec; Batch: 2.1463 sec
0.1551 0.1254 0.1026 0.0927 0.0827 0.0774 0.0738 0.0704 0.0690 0.0681 0.0671 0.0666 0.0661 0.0655 0.0653 0.0649 

[TRAIN] Epoch[1](2718/114412); Loss: 0.060665; Backpropagation: 0.2908 sec; Batch: 2.1145 sec
0.1480 0.1109 0.0840 0.0740 0.0593 0.0526 0.0525 0.0485 0.0455 0.0447 0.0434 0.0424 0.0420 0.0414 0.0409 0.0407 

[TRAIN] Epoch[1](2719/114412); Loss: 0.068103; Backpropagation: 0.2910 sec; Batch: 2.1161 sec
0.1448 0.1202 0.0807 0.0714 0.0685 0.0628 0.0592 0.0569 0.0556 0.0544 0.0534 0.0530 0.0526 0.0523 0.0520 0.0519 

[TRAIN] Epoch[1](2720/114412); Loss: 0.059546; Backpropagation: 0.2935 sec; Batch: 2.0888 sec
0.1030 0.0867 0.0743 0.0675 0.0610 0.0577 0.0553 0.0532 0.0522 0.0510 0.0500 0.0492 0.0486 0.0481 0.0477 0.0474 

[TRAIN] Epoch[1](2721/114412); Loss: 0.056374; Backpropagation: 0.2929 sec; Batch: 2.1246 sec
0.1299 0.0837 0.0745 0.0616 0.0561 0.0532 0.0497 0.0475 0.0460 0.0448 0.0439 0.0432 0.0426 0.0422 0.0418 0.0415 

[TRAIN] Epoch[1](2722/114412); Loss: 0.079212; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1763 0.1293 0.1070 0.0931 0.0831 0.0767 0.0730 0.0671 0.0622 0.0607 0.0597 0.0572 0.0564 0.0558 0.0552 0.0547 

[TRAIN] Epoch[1](2723/114412); Loss: 0.070624; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1248 0.1053 0.0910 0.0790 0.0703 0.0666 0.0642 0.0622 0.0610 0.0598 0.0590 0.0583 0.0577 0.0573 0.0570 0.0567 

[TRAIN] Epoch[1](2724/114412); Loss: 0.058222; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1123 0.0871 0.0742 0.0653 0.0599 0.0554 0.0525 0.0506 0.0492 0.0482 0.0473 0.0466 0.0462 0.0458 0.0456 0.0454 

[TRAIN] Epoch[1](2725/114412); Loss: 0.061915; Backpropagation: 0.2909 sec; Batch: 2.1292 sec
0.1376 0.0972 0.0785 0.0676 0.0615 0.0575 0.0548 0.0527 0.0510 0.0496 0.0486 0.0478 0.0472 0.0467 0.0462 0.0459 

[TRAIN] Epoch[1](2726/114412); Loss: 0.060391; Backpropagation: 0.2913 sec; Batch: 2.1151 sec
0.1040 0.0924 0.0759 0.0679 0.0638 0.0586 0.0558 0.0536 0.0519 0.0508 0.0499 0.0493 0.0487 0.0482 0.0479 0.0476 

[TRAIN] Epoch[1](2727/114412); Loss: 0.063265; Backpropagation: 0.2909 sec; Batch: 2.1203 sec
0.1315 0.0965 0.0800 0.0698 0.0644 0.0601 0.0570 0.0545 0.0527 0.0515 0.0504 0.0497 0.0492 0.0487 0.0483 0.0480 

[TRAIN] Epoch[1](2728/114412); Loss: 0.074242; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1600 0.1465 0.0855 0.0800 0.0750 0.0658 0.0645 0.0622 0.0601 0.0576 0.0563 0.0556 0.0554 0.0549 0.0544 0.0540 

[TRAIN] Epoch[1](2729/114412); Loss: 0.057507; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1219 0.0965 0.0808 0.0684 0.0596 0.0537 0.0501 0.0475 0.0456 0.0444 0.0434 0.0427 0.0421 0.0416 0.0411 0.0408 

[TRAIN] Epoch[1](2730/114412); Loss: 0.066841; Backpropagation: 0.2931 sec; Batch: 2.1196 sec
0.1656 0.1340 0.0834 0.0793 0.0638 0.0598 0.0552 0.0527 0.0508 0.0490 0.0480 0.0469 0.0460 0.0455 0.0450 0.0445 

[TRAIN] Epoch[1](2731/114412); Loss: 0.077184; Backpropagation: 0.2908 sec; Batch: 2.1282 sec
0.1356 0.1095 0.0944 0.0886 0.0823 0.0768 0.0727 0.0699 0.0676 0.0656 0.0638 0.0629 0.0622 0.0615 0.0609 0.0605 

[TRAIN] Epoch[1](2732/114412); Loss: 0.071133; Backpropagation: 0.2903 sec; Batch: 2.1171 sec
0.1082 0.0930 0.0852 0.0778 0.0736 0.0694 0.0668 0.0653 0.0642 0.0632 0.0627 0.0623 0.0619 0.0617 0.0614 0.0612 

[TRAIN] Epoch[1](2733/114412); Loss: 0.060003; Backpropagation: 0.2907 sec; Batch: 2.1175 sec
0.1538 0.1279 0.0764 0.0690 0.0584 0.0511 0.0485 0.0463 0.0436 0.0426 0.0416 0.0409 0.0405 0.0401 0.0398 0.0396 

[TRAIN] Epoch[1](2734/114412); Loss: 0.054741; Backpropagation: 0.2914 sec; Batch: 2.1147 sec
0.1023 0.0829 0.0705 0.0641 0.0590 0.0540 0.0510 0.0478 0.0461 0.0446 0.0437 0.0429 0.0424 0.0418 0.0415 0.0412 

[TRAIN] Epoch[1](2735/114412); Loss: 0.088685; Backpropagation: 0.2951 sec; Batch: 2.0815 sec
0.1451 0.1372 0.1139 0.1010 0.0919 0.0872 0.0826 0.0795 0.0770 0.0753 0.0738 0.0725 0.0715 0.0708 0.0701 0.0694 

[TRAIN] Epoch[1](2736/114412); Loss: 0.086523; Backpropagation: 0.2912 sec; Batch: 2.1040 sec
0.1703 0.1510 0.1134 0.1020 0.0842 0.0808 0.0749 0.0720 0.0702 0.0688 0.0677 0.0670 0.0662 0.0657 0.0653 0.0648 

[TRAIN] Epoch[1](2737/114412); Loss: 0.057605; Backpropagation: 0.2908 sec; Batch: 2.1143 sec
0.1386 0.0949 0.0598 0.0589 0.0565 0.0514 0.0490 0.0480 0.0469 0.0460 0.0458 0.0453 0.0453 0.0452 0.0451 0.0451 

[TRAIN] Epoch[1](2738/114412); Loss: 0.073498; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1566 0.1427 0.0897 0.0800 0.0715 0.0674 0.0630 0.0605 0.0586 0.0572 0.0563 0.0554 0.0549 0.0544 0.0540 0.0538 

[TRAIN] Epoch[1](2739/114412); Loss: 0.066942; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1346 0.1208 0.0876 0.0778 0.0680 0.0623 0.0585 0.0558 0.0542 0.0528 0.0516 0.0506 0.0499 0.0493 0.0489 0.0484 

[TRAIN] Epoch[1](2740/114412); Loss: 0.102419; Backpropagation: 0.2945 sec; Batch: 2.1218 sec
0.1840 0.1628 0.1261 0.1177 0.1024 0.0970 0.0908 0.0885 0.0869 0.0855 0.0845 0.0836 0.0830 0.0824 0.0819 0.0817 

[TRAIN] Epoch[1](2741/114412); Loss: 0.093413; Backpropagation: 0.2911 sec; Batch: 2.1417 sec
0.1694 0.1399 0.1086 0.1012 0.0946 0.0895 0.0865 0.0826 0.0804 0.0792 0.0785 0.0778 0.0772 0.0766 0.0765 0.0763 

[TRAIN] Epoch[1](2742/114412); Loss: 0.085271; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1391 0.1231 0.1013 0.0924 0.0892 0.0820 0.0792 0.0768 0.0752 0.0741 0.0732 0.0725 0.0720 0.0716 0.0714 0.0709 

[TRAIN] Epoch[1](2743/114412); Loss: 0.059901; Backpropagation: 0.2904 sec; Batch: 2.1173 sec
0.1011 0.0912 0.0743 0.0679 0.0626 0.0581 0.0558 0.0536 0.0519 0.0505 0.0496 0.0491 0.0486 0.0482 0.0480 0.0479 

[TRAIN] Epoch[1](2744/114412); Loss: 0.061425; Backpropagation: 0.2904 sec; Batch: 2.0761 sec
0.1201 0.0986 0.0748 0.0690 0.0629 0.0573 0.0547 0.0530 0.0513 0.0502 0.0495 0.0490 0.0486 0.0483 0.0480 0.0478 

[TRAIN] Epoch[1](2745/114412); Loss: 0.078787; Backpropagation: 0.2904 sec; Batch: 2.1157 sec
0.1606 0.1264 0.0979 0.0882 0.0806 0.0754 0.0705 0.0678 0.0659 0.0640 0.0627 0.0615 0.0607 0.0601 0.0595 0.0590 

[TRAIN] Epoch[1](2746/114412); Loss: 0.075826; Backpropagation: 0.2903 sec; Batch: 2.0930 sec
0.1583 0.1446 0.0880 0.0823 0.0717 0.0683 0.0649 0.0634 0.0618 0.0605 0.0595 0.0589 0.0583 0.0580 0.0575 0.0572 

[TRAIN] Epoch[1](2747/114412); Loss: 0.054849; Backpropagation: 0.2953 sec; Batch: 2.1181 sec
0.0971 0.0820 0.0688 0.0610 0.0562 0.0529 0.0507 0.0489 0.0473 0.0464 0.0457 0.0449 0.0444 0.0441 0.0437 0.0436 

[TRAIN] Epoch[1](2748/114412); Loss: 0.074295; Backpropagation: 0.2926 sec; Batch: 2.0946 sec
0.1850 0.1371 0.0966 0.0842 0.0759 0.0667 0.0620 0.0589 0.0560 0.0546 0.0534 0.0525 0.0520 0.0516 0.0512 0.0509 

[TRAIN] Epoch[1](2749/114412); Loss: 0.074931; Backpropagation: 0.2923 sec; Batch: 2.1181 sec
0.1542 0.1408 0.0932 0.0824 0.0709 0.0646 0.0634 0.0619 0.0604 0.0597 0.0589 0.0583 0.0579 0.0576 0.0574 0.0571 

[TRAIN] Epoch[1](2750/114412); Loss: 0.057968; Backpropagation: 0.2922 sec; Batch: 2.1184 sec
0.1221 0.0993 0.0806 0.0676 0.0602 0.0532 0.0511 0.0480 0.0458 0.0446 0.0438 0.0430 0.0426 0.0423 0.0419 0.0416 

[TRAIN] Epoch[1](2751/114412); Loss: 0.059154; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.1135 0.0891 0.0785 0.0683 0.0616 0.0566 0.0536 0.0512 0.0495 0.0484 0.0473 0.0466 0.0461 0.0457 0.0453 0.0452 

[TRAIN] Epoch[1](2752/114412); Loss: 0.088310; Backpropagation: 0.2923 sec; Batch: 2.1195 sec
0.1581 0.1291 0.1064 0.0961 0.0909 0.0844 0.0813 0.0785 0.0768 0.0753 0.0742 0.0735 0.0728 0.0722 0.0718 0.0714 

[TRAIN] Epoch[1](2753/114412); Loss: 0.067813; Backpropagation: 0.2912 sec; Batch: 2.1189 sec
0.1328 0.1078 0.0870 0.0755 0.0682 0.0635 0.0603 0.0585 0.0563 0.0551 0.0543 0.0538 0.0534 0.0531 0.0529 0.0526 

[TRAIN] Epoch[1](2754/114412); Loss: 0.063004; Backpropagation: 0.2912 sec; Batch: 2.0874 sec
0.1185 0.1012 0.0796 0.0719 0.0642 0.0593 0.0565 0.0545 0.0530 0.0518 0.0509 0.0503 0.0496 0.0493 0.0489 0.0486 

[TRAIN] Epoch[1](2755/114412); Loss: 0.049869; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1253 0.0917 0.0622 0.0585 0.0498 0.0441 0.0411 0.0394 0.0380 0.0365 0.0360 0.0356 0.0352 0.0350 0.0348 0.0347 

[TRAIN] Epoch[1](2756/114412); Loss: 0.071435; Backpropagation: 0.2909 sec; Batch: 2.1181 sec
0.1350 0.1166 0.0875 0.0803 0.0710 0.0672 0.0635 0.0616 0.0601 0.0591 0.0582 0.0574 0.0569 0.0564 0.0562 0.0559 

[TRAIN] Epoch[1](2757/114412); Loss: 0.056301; Backpropagation: 0.2928 sec; Batch: 2.1227 sec
0.1286 0.1122 0.0717 0.0627 0.0532 0.0492 0.0470 0.0446 0.0436 0.0426 0.0418 0.0413 0.0410 0.0407 0.0404 0.0401 

[TRAIN] Epoch[1](2758/114412); Loss: 0.071171; Backpropagation: 0.2931 sec; Batch: 2.1170 sec
0.1348 0.1172 0.0922 0.0816 0.0719 0.0675 0.0645 0.0611 0.0592 0.0583 0.0570 0.0562 0.0553 0.0546 0.0540 0.0535 

[TRAIN] Epoch[1](2759/114412); Loss: 0.056950; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1231 0.0984 0.0712 0.0627 0.0555 0.0520 0.0494 0.0475 0.0461 0.0451 0.0444 0.0439 0.0435 0.0430 0.0428 0.0426 

[TRAIN] Epoch[1](2760/114412); Loss: 0.065343; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1550 0.1457 0.0779 0.0746 0.0617 0.0555 0.0521 0.0498 0.0484 0.0476 0.0469 0.0465 0.0463 0.0460 0.0458 0.0456 

[TRAIN] Epoch[1](2761/114412); Loss: 0.080989; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1332 0.1111 0.0941 0.0875 0.0823 0.0780 0.0756 0.0738 0.0725 0.0715 0.0706 0.0699 0.0694 0.0689 0.0688 0.0685 

[TRAIN] Epoch[1](2762/114412); Loss: 0.074767; Backpropagation: 0.2927 sec; Batch: 2.1192 sec
0.1260 0.1048 0.0882 0.0794 0.0761 0.0723 0.0693 0.0680 0.0665 0.0653 0.0646 0.0640 0.0635 0.0631 0.0627 0.0625 

[TRAIN] Epoch[1](2763/114412); Loss: 0.046209; Backpropagation: 0.2927 sec; Batch: 2.1211 sec
0.0939 0.0880 0.0627 0.0547 0.0458 0.0416 0.0393 0.0378 0.0362 0.0352 0.0346 0.0345 0.0343 0.0338 0.0336 0.0334 

[TRAIN] Epoch[1](2764/114412); Loss: 0.050450; Backpropagation: 0.2913 sec; Batch: 2.1205 sec
0.1083 0.0828 0.0751 0.0593 0.0523 0.0463 0.0429 0.0411 0.0399 0.0387 0.0380 0.0374 0.0368 0.0364 0.0360 0.0358 

[TRAIN] Epoch[1](2765/114412); Loss: 0.079491; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1357 0.1227 0.0987 0.0859 0.0789 0.0751 0.0727 0.0705 0.0691 0.0679 0.0672 0.0664 0.0658 0.0655 0.0649 0.0647 

[TRAIN] Epoch[1](2766/114412); Loss: 0.071591; Backpropagation: 0.2906 sec; Batch: 2.1183 sec
0.1242 0.1064 0.0873 0.0811 0.0736 0.0690 0.0663 0.0640 0.0621 0.0610 0.0600 0.0590 0.0585 0.0581 0.0576 0.0573 

[TRAIN] Epoch[1](2767/114412); Loss: 0.054582; Backpropagation: 0.2933 sec; Batch: 2.1050 sec
0.1051 0.0888 0.0717 0.0675 0.0565 0.0507 0.0493 0.0469 0.0449 0.0442 0.0428 0.0418 0.0415 0.0408 0.0405 0.0403 

[TRAIN] Epoch[1](2768/114412); Loss: 0.072838; Backpropagation: 0.2929 sec; Batch: 2.1163 sec
0.1346 0.1166 0.0848 0.0785 0.0736 0.0701 0.0664 0.0646 0.0629 0.0613 0.0604 0.0596 0.0587 0.0583 0.0578 0.0573 

[TRAIN] Epoch[1](2769/114412); Loss: 0.049455; Backpropagation: 0.2902 sec; Batch: 2.1144 sec
0.1240 0.0825 0.0669 0.0602 0.0505 0.0452 0.0425 0.0392 0.0378 0.0364 0.0356 0.0351 0.0345 0.0340 0.0336 0.0334 

[TRAIN] Epoch[1](2770/114412); Loss: 0.066635; Backpropagation: 0.2909 sec; Batch: 2.0792 sec
0.1257 0.1071 0.0862 0.0740 0.0692 0.0645 0.0606 0.0581 0.0562 0.0551 0.0534 0.0524 0.0518 0.0510 0.0505 0.0502 

[TRAIN] Epoch[1](2771/114412); Loss: 0.055995; Backpropagation: 0.2911 sec; Batch: 2.0854 sec
0.0988 0.0844 0.0705 0.0645 0.0576 0.0536 0.0516 0.0494 0.0479 0.0472 0.0463 0.0456 0.0451 0.0447 0.0444 0.0441 

[TRAIN] Epoch[1](2772/114412); Loss: 0.085080; Backpropagation: 0.2920 sec; Batch: 2.0853 sec
0.1385 0.1221 0.1003 0.0927 0.0852 0.0819 0.0789 0.0770 0.0755 0.0744 0.0738 0.0730 0.0727 0.0721 0.0717 0.0715 

[TRAIN] Epoch[1](2773/114412); Loss: 0.065059; Backpropagation: 0.2921 sec; Batch: 2.0858 sec
0.1120 0.0973 0.0769 0.0692 0.0652 0.0617 0.0600 0.0585 0.0571 0.0563 0.0555 0.0549 0.0544 0.0541 0.0539 0.0537 

[TRAIN] Epoch[1](2774/114412); Loss: 0.066643; Backpropagation: 0.2951 sec; Batch: 2.1317 sec
0.1125 0.0972 0.0829 0.0739 0.0691 0.0657 0.0625 0.0598 0.0584 0.0571 0.0560 0.0553 0.0547 0.0542 0.0537 0.0535 

[TRAIN] Epoch[1](2775/114412); Loss: 0.070945; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1146 0.1004 0.0939 0.0844 0.0748 0.0710 0.0676 0.0646 0.0620 0.0605 0.0589 0.0580 0.0570 0.0563 0.0559 0.0551 

[TRAIN] Epoch[1](2776/114412); Loss: 0.072910; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1318 0.1171 0.0987 0.0871 0.0741 0.0700 0.0661 0.0631 0.0609 0.0591 0.0582 0.0573 0.0566 0.0559 0.0554 0.0551 

[TRAIN] Epoch[1](2777/114412); Loss: 0.084612; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1565 0.1368 0.1120 0.0991 0.0894 0.0829 0.0775 0.0724 0.0703 0.0684 0.0668 0.0657 0.0648 0.0642 0.0637 0.0634 

[TRAIN] Epoch[1](2778/114412); Loss: 0.045741; Backpropagation: 0.2906 sec; Batch: 2.1178 sec
0.0977 0.0831 0.0574 0.0498 0.0445 0.0425 0.0397 0.0380 0.0372 0.0360 0.0355 0.0348 0.0342 0.0341 0.0337 0.0334 

[TRAIN] Epoch[1](2779/114412); Loss: 0.060690; Backpropagation: 0.2953 sec; Batch: 2.1263 sec
0.1181 0.0991 0.0798 0.0710 0.0630 0.0584 0.0556 0.0522 0.0503 0.0489 0.0474 0.0465 0.0459 0.0454 0.0449 0.0446 

[TRAIN] Epoch[1](2780/114412); Loss: 0.080053; Backpropagation: 0.2947 sec; Batch: 2.1001 sec
0.1342 0.1150 0.0997 0.0887 0.0803 0.0781 0.0745 0.0724 0.0704 0.0692 0.0679 0.0670 0.0664 0.0659 0.0656 0.0654 

[TRAIN] Epoch[1](2781/114412); Loss: 0.068048; Backpropagation: 0.2911 sec; Batch: 2.1222 sec
0.1332 0.1146 0.0910 0.0827 0.0695 0.0657 0.0608 0.0578 0.0554 0.0537 0.0524 0.0514 0.0507 0.0503 0.0500 0.0496 

[TRAIN] Epoch[1](2782/114412); Loss: 0.085745; Backpropagation: 0.2931 sec; Batch: 2.1197 sec
0.1279 0.1116 0.1021 0.0958 0.0893 0.0843 0.0814 0.0793 0.0780 0.0769 0.0758 0.0751 0.0742 0.0737 0.0734 0.0731 

[TRAIN] Epoch[1](2783/114412); Loss: 0.072495; Backpropagation: 0.2911 sec; Batch: 2.1203 sec
0.1355 0.1147 0.0952 0.0854 0.0745 0.0696 0.0654 0.0626 0.0605 0.0591 0.0578 0.0571 0.0563 0.0559 0.0554 0.0550 

[TRAIN] Epoch[1](2784/114412); Loss: 0.063340; Backpropagation: 0.2917 sec; Batch: 2.1422 sec
0.1217 0.1066 0.0841 0.0746 0.0668 0.0602 0.0571 0.0546 0.0522 0.0507 0.0494 0.0484 0.0475 0.0470 0.0464 0.0461 

[TRAIN] Epoch[1](2785/114412); Loss: 0.078036; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1384 0.1236 0.0957 0.0861 0.0803 0.0755 0.0716 0.0693 0.0674 0.0656 0.0644 0.0634 0.0626 0.0620 0.0615 0.0612 

[TRAIN] Epoch[1](2786/114412); Loss: 0.063711; Backpropagation: 0.2905 sec; Batch: 2.1197 sec
0.1288 0.1075 0.0803 0.0719 0.0633 0.0594 0.0566 0.0543 0.0527 0.0515 0.0505 0.0496 0.0489 0.0484 0.0480 0.0477 

[TRAIN] Epoch[1](2787/114412); Loss: 0.079626; Backpropagation: 0.2909 sec; Batch: 2.1249 sec
0.1496 0.1320 0.1105 0.0976 0.0851 0.0790 0.0714 0.0695 0.0651 0.0634 0.0610 0.0598 0.0584 0.0577 0.0570 0.0568 

[TRAIN] Epoch[1](2788/114412); Loss: 0.050985; Backpropagation: 0.2927 sec; Batch: 2.0827 sec
0.1137 0.0898 0.0689 0.0593 0.0520 0.0477 0.0442 0.0419 0.0405 0.0390 0.0380 0.0372 0.0365 0.0360 0.0357 0.0354 

[TRAIN] Epoch[1](2789/114412); Loss: 0.049684; Backpropagation: 0.2905 sec; Batch: 2.1170 sec
0.0960 0.0919 0.0681 0.0589 0.0499 0.0465 0.0429 0.0410 0.0396 0.0387 0.0379 0.0375 0.0370 0.0367 0.0363 0.0361 

[TRAIN] Epoch[1](2790/114412); Loss: 0.087454; Backpropagation: 0.2902 sec; Batch: 2.1251 sec
0.1546 0.1373 0.1090 0.1034 0.0887 0.0838 0.0793 0.0766 0.0747 0.0731 0.0719 0.0707 0.0701 0.0694 0.0686 0.0681 

[TRAIN] Epoch[1](2791/114412); Loss: 0.065598; Backpropagation: 0.2933 sec; Batch: 2.1177 sec
0.1207 0.1016 0.0933 0.0845 0.0743 0.0681 0.0638 0.0580 0.0547 0.0528 0.0499 0.0474 0.0466 0.0458 0.0443 0.0439 

[TRAIN] Epoch[1](2792/114412); Loss: 0.043196; Backpropagation: 0.2914 sec; Batch: 2.0777 sec
0.0804 0.0639 0.0538 0.0524 0.0444 0.0435 0.0401 0.0378 0.0367 0.0354 0.0348 0.0343 0.0338 0.0336 0.0332 0.0330 

[TRAIN] Epoch[1](2793/114412); Loss: 0.057528; Backpropagation: 0.2925 sec; Batch: 2.1193 sec
0.1316 0.1163 0.0784 0.0779 0.0615 0.0561 0.0463 0.0444 0.0420 0.0409 0.0398 0.0383 0.0375 0.0369 0.0365 0.0360 

[TRAIN] Epoch[1](2794/114412); Loss: 0.067741; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1193 0.0998 0.0854 0.0826 0.0730 0.0660 0.0622 0.0606 0.0579 0.0562 0.0553 0.0542 0.0534 0.0530 0.0525 0.0522 

[TRAIN] Epoch[1](2795/114412); Loss: 0.069359; Backpropagation: 0.2912 sec; Batch: 2.1264 sec
0.1259 0.1161 0.0923 0.0827 0.0731 0.0674 0.0631 0.0603 0.0577 0.0559 0.0546 0.0534 0.0526 0.0520 0.0515 0.0511 

[TRAIN] Epoch[1](2796/114412); Loss: 0.096293; Backpropagation: 0.2906 sec; Batch: 2.1166 sec
0.1749 0.1498 0.1224 0.1094 0.0992 0.0905 0.0863 0.0839 0.0817 0.0802 0.0792 0.0782 0.0771 0.0765 0.0759 0.0756 

[TRAIN] Epoch[1](2797/114412); Loss: 0.076598; Backpropagation: 0.2909 sec; Batch: 2.1736 sec
0.1503 0.1338 0.0959 0.0864 0.0810 0.0735 0.0690 0.0655 0.0631 0.0611 0.0595 0.0587 0.0577 0.0572 0.0566 0.0562 

[TRAIN] Epoch[1](2798/114412); Loss: 0.075795; Backpropagation: 0.2914 sec; Batch: 2.0998 sec
0.1390 0.1194 0.0961 0.0850 0.0776 0.0729 0.0691 0.0666 0.0649 0.0629 0.0617 0.0608 0.0600 0.0593 0.0588 0.0585 

[TRAIN] Epoch[1](2799/114412); Loss: 0.049592; Backpropagation: 0.2905 sec; Batch: 2.0804 sec
0.0959 0.0801 0.0685 0.0593 0.0531 0.0475 0.0451 0.0424 0.0407 0.0395 0.0384 0.0376 0.0370 0.0365 0.0361 0.0358 

[TRAIN] Epoch[1](2800/114412); Loss: 0.072741; Backpropagation: 0.2914 sec; Batch: 2.0941 sec
0.1466 0.1226 0.0935 0.0846 0.0753 0.0670 0.0638 0.0620 0.0596 0.0582 0.0567 0.0558 0.0552 0.0547 0.0543 0.0539 

[TRAIN] Epoch[1](2801/114412); Loss: 0.077523; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1260 0.1145 0.0985 0.0906 0.0800 0.0762 0.0716 0.0698 0.0676 0.0663 0.0650 0.0642 0.0634 0.0629 0.0622 0.0618 

[TRAIN] Epoch[1](2802/114412); Loss: 0.057711; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1274 0.1122 0.0760 0.0643 0.0572 0.0527 0.0490 0.0474 0.0452 0.0437 0.0426 0.0420 0.0414 0.0410 0.0407 0.0406 

[TRAIN] Epoch[1](2803/114412); Loss: 0.074867; Backpropagation: 0.2952 sec; Batch: 2.1226 sec
0.1286 0.1125 0.0912 0.0852 0.0760 0.0719 0.0695 0.0671 0.0654 0.0642 0.0628 0.0620 0.0611 0.0607 0.0601 0.0596 

[TRAIN] Epoch[1](2804/114412); Loss: 0.057960; Backpropagation: 0.2926 sec; Batch: 2.1198 sec
0.1174 0.1083 0.0758 0.0725 0.0619 0.0547 0.0513 0.0485 0.0467 0.0448 0.0432 0.0421 0.0408 0.0402 0.0398 0.0394 

[TRAIN] Epoch[1](2805/114412); Loss: 0.057863; Backpropagation: 0.2927 sec; Batch: 2.1210 sec
0.1160 0.0945 0.0756 0.0684 0.0597 0.0556 0.0521 0.0500 0.0477 0.0463 0.0451 0.0441 0.0435 0.0428 0.0423 0.0420 

[TRAIN] Epoch[1](2806/114412); Loss: 0.082441; Backpropagation: 0.2951 sec; Batch: 2.1196 sec
0.1612 0.1406 0.1108 0.0963 0.0842 0.0783 0.0738 0.0705 0.0676 0.0658 0.0642 0.0630 0.0620 0.0610 0.0603 0.0597 

[TRAIN] Epoch[1](2807/114412); Loss: 0.067991; Backpropagation: 0.2935 sec; Batch: 2.1193 sec
0.1126 0.1022 0.0851 0.0775 0.0710 0.0666 0.0632 0.0605 0.0587 0.0575 0.0567 0.0560 0.0556 0.0551 0.0548 0.0546 

[TRAIN] Epoch[1](2808/114412); Loss: 0.071120; Backpropagation: 0.2934 sec; Batch: 2.1195 sec
0.1389 0.1249 0.0939 0.0802 0.0711 0.0666 0.0625 0.0599 0.0583 0.0570 0.0559 0.0550 0.0542 0.0537 0.0530 0.0526 

[TRAIN] Epoch[1](2809/114412); Loss: 0.058939; Backpropagation: 0.2927 sec; Batch: 2.1227 sec
0.1308 0.1209 0.0860 0.0760 0.0595 0.0525 0.0488 0.0465 0.0438 0.0424 0.0411 0.0401 0.0394 0.0388 0.0384 0.0381 

[TRAIN] Epoch[1](2810/114412); Loss: 0.089470; Backpropagation: 0.2932 sec; Batch: 2.1191 sec
0.1443 0.1325 0.1082 0.0998 0.0912 0.0869 0.0835 0.0810 0.0787 0.0774 0.0766 0.0756 0.0749 0.0742 0.0737 0.0732 

[TRAIN] Epoch[1](2811/114412); Loss: 0.051024; Backpropagation: 0.2905 sec; Batch: 2.0770 sec
0.0967 0.0877 0.0761 0.0582 0.0512 0.0460 0.0441 0.0423 0.0412 0.0403 0.0397 0.0392 0.0389 0.0385 0.0382 0.0380 

[TRAIN] Epoch[1](2812/114412); Loss: 0.072468; Backpropagation: 0.2907 sec; Batch: 2.1161 sec
0.1503 0.1329 0.0841 0.0793 0.0696 0.0658 0.0635 0.0611 0.0595 0.0584 0.0574 0.0565 0.0560 0.0555 0.0550 0.0547 

[TRAIN] Epoch[1](2813/114412); Loss: 0.067098; Backpropagation: 0.2903 sec; Batch: 2.0777 sec
0.1256 0.1153 0.0838 0.0771 0.0680 0.0638 0.0598 0.0576 0.0559 0.0545 0.0534 0.0527 0.0521 0.0516 0.0515 0.0510 

[TRAIN] Epoch[1](2814/114412); Loss: 0.077311; Backpropagation: 0.2904 sec; Batch: 2.1199 sec
0.1493 0.1316 0.0940 0.0845 0.0758 0.0711 0.0680 0.0664 0.0646 0.0637 0.0627 0.0620 0.0615 0.0610 0.0605 0.0602 

[TRAIN] Epoch[1](2815/114412); Loss: 0.080028; Backpropagation: 0.2911 sec; Batch: 2.1153 sec
0.1472 0.1332 0.1107 0.0991 0.0851 0.0795 0.0720 0.0686 0.0652 0.0634 0.0614 0.0606 0.0596 0.0589 0.0583 0.0579 

[TRAIN] Epoch[1](2816/114412); Loss: 0.073827; Backpropagation: 0.2928 sec; Batch: 2.1204 sec
0.1152 0.1039 0.0900 0.0811 0.0751 0.0720 0.0690 0.0677 0.0662 0.0651 0.0641 0.0634 0.0628 0.0623 0.0619 0.0616 

[TRAIN] Epoch[1](2817/114412); Loss: 0.067507; Backpropagation: 0.2927 sec; Batch: 2.0833 sec
0.1223 0.1081 0.0893 0.0783 0.0692 0.0649 0.0618 0.0590 0.0568 0.0554 0.0543 0.0532 0.0525 0.0520 0.0517 0.0513 

[TRAIN] Epoch[1](2818/114412); Loss: 0.056887; Backpropagation: 0.2908 sec; Batch: 2.0777 sec
0.1249 0.1077 0.0803 0.0692 0.0612 0.0530 0.0488 0.0453 0.0432 0.0421 0.0408 0.0398 0.0392 0.0386 0.0382 0.0378 

[TRAIN] Epoch[1](2819/114412); Loss: 0.074611; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1440 0.1248 0.1027 0.0871 0.0752 0.0695 0.0654 0.0630 0.0608 0.0598 0.0588 0.0577 0.0571 0.0564 0.0560 0.0556 

[TRAIN] Epoch[1](2820/114412); Loss: 0.058109; Backpropagation: 0.2914 sec; Batch: 2.0990 sec
0.1252 0.1167 0.0754 0.0673 0.0557 0.0516 0.0483 0.0470 0.0457 0.0443 0.0435 0.0427 0.0421 0.0418 0.0413 0.0410 

[TRAIN] Epoch[1](2821/114412); Loss: 0.056100; Backpropagation: 0.2908 sec; Batch: 2.1150 sec
0.1215 0.1051 0.0770 0.0658 0.0569 0.0508 0.0475 0.0456 0.0439 0.0424 0.0416 0.0409 0.0402 0.0398 0.0394 0.0392 

[TRAIN] Epoch[1](2822/114412); Loss: 0.066532; Backpropagation: 0.2910 sec; Batch: 2.1203 sec
0.1099 0.1016 0.0858 0.0755 0.0698 0.0636 0.0610 0.0595 0.0577 0.0566 0.0557 0.0546 0.0540 0.0535 0.0531 0.0527 

[TRAIN] Epoch[1](2823/114412); Loss: 0.069123; Backpropagation: 0.2930 sec; Batch: 2.1193 sec
0.1137 0.1052 0.0904 0.0821 0.0707 0.0659 0.0629 0.0607 0.0590 0.0581 0.0575 0.0569 0.0564 0.0559 0.0554 0.0551 

[TRAIN] Epoch[1](2824/114412); Loss: 0.055359; Backpropagation: 0.2910 sec; Batch: 2.1201 sec
0.1118 0.0837 0.0735 0.0689 0.0595 0.0531 0.0492 0.0473 0.0452 0.0441 0.0430 0.0422 0.0415 0.0412 0.0410 0.0407 

[TRAIN] Epoch[1](2825/114412); Loss: 0.063058; Backpropagation: 0.2929 sec; Batch: 2.0784 sec
0.1478 0.1406 0.0858 0.0803 0.0592 0.0544 0.0526 0.0497 0.0456 0.0448 0.0433 0.0422 0.0413 0.0409 0.0404 0.0402 

[TRAIN] Epoch[1](2826/114412); Loss: 0.047941; Backpropagation: 0.2934 sec; Batch: 2.0833 sec
0.0870 0.0793 0.0629 0.0535 0.0493 0.0465 0.0447 0.0419 0.0401 0.0392 0.0384 0.0378 0.0371 0.0369 0.0364 0.0361 

[TRAIN] Epoch[1](2827/114412); Loss: 0.055170; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1040 0.0958 0.0718 0.0654 0.0569 0.0526 0.0499 0.0474 0.0454 0.0442 0.0433 0.0424 0.0418 0.0411 0.0406 0.0402 

[TRAIN] Epoch[1](2828/114412); Loss: 0.072256; Backpropagation: 0.2907 sec; Batch: 2.0774 sec
0.1456 0.1229 0.0980 0.0819 0.0728 0.0671 0.0640 0.0615 0.0592 0.0574 0.0561 0.0551 0.0543 0.0538 0.0534 0.0531 

[TRAIN] Epoch[1](2829/114412); Loss: 0.054764; Backpropagation: 0.2905 sec; Batch: 2.1163 sec
0.1149 0.0935 0.0679 0.0600 0.0548 0.0511 0.0489 0.0461 0.0449 0.0436 0.0426 0.0423 0.0418 0.0415 0.0412 0.0411 

[TRAIN] Epoch[1](2830/114412); Loss: 0.067756; Backpropagation: 0.2907 sec; Batch: 2.0769 sec
0.1132 0.1038 0.0846 0.0769 0.0696 0.0657 0.0626 0.0608 0.0591 0.0578 0.0566 0.0559 0.0551 0.0545 0.0542 0.0538 

[TRAIN] Epoch[1](2831/114412); Loss: 0.064548; Backpropagation: 0.2905 sec; Batch: 2.0870 sec
0.1158 0.1013 0.0833 0.0724 0.0665 0.0616 0.0575 0.0560 0.0546 0.0535 0.0528 0.0523 0.0518 0.0514 0.0511 0.0509 

[TRAIN] Epoch[1](2832/114412); Loss: 0.055889; Backpropagation: 0.2911 sec; Batch: 2.1123 sec
0.1050 0.0926 0.0794 0.0619 0.0556 0.0533 0.0494 0.0478 0.0463 0.0451 0.0442 0.0436 0.0430 0.0426 0.0423 0.0419 

[TRAIN] Epoch[1](2833/114412); Loss: 0.070440; Backpropagation: 0.2928 sec; Batch: 2.1210 sec
0.1267 0.1175 0.0969 0.0842 0.0744 0.0684 0.0636 0.0605 0.0582 0.0566 0.0554 0.0542 0.0533 0.0528 0.0522 0.0519 

[TRAIN] Epoch[1](2834/114412); Loss: 0.074950; Backpropagation: 0.2910 sec; Batch: 2.1148 sec
0.1547 0.1349 0.0993 0.0867 0.0770 0.0701 0.0662 0.0630 0.0601 0.0584 0.0569 0.0558 0.0550 0.0542 0.0537 0.0532 

[TRAIN] Epoch[1](2835/114412); Loss: 0.069707; Backpropagation: 0.2907 sec; Batch: 2.1179 sec
0.1246 0.1129 0.0832 0.0761 0.0709 0.0660 0.0629 0.0615 0.0600 0.0590 0.0580 0.0572 0.0565 0.0560 0.0555 0.0551 

[TRAIN] Epoch[1](2836/114412); Loss: 0.074192; Backpropagation: 0.2909 sec; Batch: 2.1141 sec
0.1292 0.1155 0.1030 0.0923 0.0838 0.0754 0.0715 0.0663 0.0636 0.0600 0.0585 0.0559 0.0549 0.0532 0.0525 0.0516 

[TRAIN] Epoch[1](2837/114412); Loss: 0.061596; Backpropagation: 0.2906 sec; Batch: 2.1245 sec
0.1014 0.0885 0.0729 0.0685 0.0642 0.0604 0.0577 0.0559 0.0545 0.0533 0.0525 0.0519 0.0513 0.0510 0.0508 0.0506 

[TRAIN] Epoch[1](2838/114412); Loss: 0.070747; Backpropagation: 0.2906 sec; Batch: 2.1177 sec
0.1065 0.1004 0.0868 0.0810 0.0723 0.0690 0.0657 0.0640 0.0628 0.0620 0.0612 0.0607 0.0603 0.0600 0.0598 0.0596 

[TRAIN] Epoch[1](2839/114412); Loss: 0.058428; Backpropagation: 0.2905 sec; Batch: 2.1172 sec
0.1038 0.0998 0.0794 0.0701 0.0626 0.0584 0.0523 0.0500 0.0484 0.0467 0.0455 0.0448 0.0440 0.0434 0.0431 0.0427 

[TRAIN] Epoch[1](2840/114412); Loss: 0.078632; Backpropagation: 0.2909 sec; Batch: 2.1188 sec
0.1174 0.1090 0.0926 0.0888 0.0834 0.0793 0.0756 0.0730 0.0710 0.0694 0.0683 0.0673 0.0665 0.0660 0.0655 0.0651 

[TRAIN] Epoch[1](2841/114412); Loss: 0.072847; Backpropagation: 0.2915 sec; Batch: 2.0857 sec
0.1551 0.1264 0.1079 0.0903 0.0823 0.0743 0.0687 0.0597 0.0564 0.0543 0.0514 0.0498 0.0486 0.0475 0.0468 0.0462 

[TRAIN] Epoch[1](2842/114412); Loss: 0.070543; Backpropagation: 0.2911 sec; Batch: 2.1163 sec
0.1274 0.1172 0.0987 0.0886 0.0765 0.0670 0.0623 0.0598 0.0574 0.0559 0.0548 0.0539 0.0531 0.0525 0.0521 0.0517 

[TRAIN] Epoch[1](2843/114412); Loss: 0.075423; Backpropagation: 0.2931 sec; Batch: 2.1209 sec
0.1467 0.1423 0.1051 0.0951 0.0788 0.0734 0.0656 0.0622 0.0590 0.0573 0.0559 0.0546 0.0537 0.0529 0.0523 0.0518 

[TRAIN] Epoch[1](2844/114412); Loss: 0.078481; Backpropagation: 0.2929 sec; Batch: 2.1198 sec
0.1467 0.1285 0.1065 0.0921 0.0835 0.0761 0.0709 0.0676 0.0647 0.0626 0.0615 0.0606 0.0595 0.0589 0.0583 0.0577 

[TRAIN] Epoch[1](2845/114412); Loss: 0.080463; Backpropagation: 0.2925 sec; Batch: 2.1164 sec
0.1333 0.1250 0.1072 0.0975 0.0880 0.0815 0.0747 0.0711 0.0678 0.0659 0.0645 0.0634 0.0627 0.0622 0.0617 0.0612 

[TRAIN] Epoch[1](2846/114412); Loss: 0.078694; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.1425 0.1226 0.1016 0.0917 0.0835 0.0771 0.0719 0.0684 0.0661 0.0648 0.0634 0.0624 0.0616 0.0608 0.0604 0.0601 

[TRAIN] Epoch[1](2847/114412); Loss: 0.080126; Backpropagation: 0.2916 sec; Batch: 2.1174 sec
0.1631 0.1470 0.1184 0.1025 0.0909 0.0788 0.0689 0.0639 0.0605 0.0583 0.0567 0.0555 0.0548 0.0544 0.0542 0.0540 

[TRAIN] Epoch[1](2848/114412); Loss: 0.069528; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1148 0.0904 0.0863 0.0811 0.0750 0.0684 0.0650 0.0631 0.0614 0.0602 0.0591 0.0584 0.0578 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](2849/114412); Loss: 0.061439; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1147 0.0895 0.0807 0.0725 0.0677 0.0614 0.0586 0.0538 0.0518 0.0498 0.0486 0.0477 0.0471 0.0466 0.0463 0.0460 

[TRAIN] Epoch[1](2850/114412); Loss: 0.064604; Backpropagation: 0.2915 sec; Batch: 2.1254 sec
0.1393 0.1153 0.0908 0.0789 0.0686 0.0616 0.0558 0.0530 0.0507 0.0486 0.0472 0.0461 0.0453 0.0447 0.0441 0.0437 

[TRAIN] Epoch[1](2851/114412); Loss: 0.063541; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1281 0.1164 0.0892 0.0806 0.0698 0.0615 0.0549 0.0531 0.0503 0.0477 0.0458 0.0452 0.0443 0.0435 0.0433 0.0430 

[TRAIN] Epoch[1](2852/114412); Loss: 0.076061; Backpropagation: 0.2906 sec; Batch: 2.1174 sec
0.1265 0.1219 0.1029 0.0913 0.0846 0.0794 0.0722 0.0679 0.0650 0.0622 0.0603 0.0589 0.0573 0.0564 0.0554 0.0547 

[TRAIN] Epoch[1](2853/114412); Loss: 0.087045; Backpropagation: 0.2906 sec; Batch: 2.0777 sec
0.1548 0.1439 0.1244 0.1127 0.0986 0.0908 0.0816 0.0764 0.0715 0.0682 0.0654 0.0633 0.0615 0.0606 0.0599 0.0591 

[TRAIN] Epoch[1](2854/114412); Loss: 0.062014; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.1160 0.0990 0.0814 0.0719 0.0671 0.0615 0.0582 0.0548 0.0526 0.0507 0.0492 0.0480 0.0469 0.0460 0.0450 0.0442 

[TRAIN] Epoch[1](2855/114412); Loss: 0.061268; Backpropagation: 0.2904 sec; Batch: 2.0856 sec
0.1160 0.1083 0.0905 0.0803 0.0712 0.0614 0.0555 0.0510 0.0484 0.0462 0.0445 0.0430 0.0421 0.0412 0.0406 0.0401 

[TRAIN] Epoch[1](2856/114412); Loss: 0.066080; Backpropagation: 0.2909 sec; Batch: 2.1275 sec
0.1145 0.1078 0.0876 0.0792 0.0709 0.0654 0.0607 0.0583 0.0557 0.0540 0.0526 0.0515 0.0506 0.0500 0.0495 0.0492 

[TRAIN] Epoch[1](2857/114412); Loss: 0.044032; Backpropagation: 0.2913 sec; Batch: 2.1115 sec
0.0989 0.0850 0.0661 0.0591 0.0472 0.0408 0.0368 0.0343 0.0326 0.0315 0.0301 0.0294 0.0288 0.0283 0.0280 0.0277 

[TRAIN] Epoch[1](2858/114412); Loss: 0.061958; Backpropagation: 0.2913 sec; Batch: 2.1728 sec
0.1152 0.0953 0.0752 0.0685 0.0638 0.0602 0.0569 0.0549 0.0530 0.0519 0.0509 0.0501 0.0495 0.0490 0.0486 0.0484 

[TRAIN] Epoch[1](2859/114412); Loss: 0.059876; Backpropagation: 0.2909 sec; Batch: 2.1416 sec
0.1144 0.1079 0.0821 0.0753 0.0614 0.0568 0.0521 0.0496 0.0476 0.0466 0.0455 0.0446 0.0442 0.0436 0.0434 0.0429 

[TRAIN] Epoch[1](2860/114412); Loss: 0.094814; Backpropagation: 0.2906 sec; Batch: 2.1721 sec
0.1428 0.1326 0.1195 0.1116 0.1027 0.0966 0.0912 0.0874 0.0844 0.0823 0.0807 0.0792 0.0780 0.0769 0.0759 0.0752 

[TRAIN] Epoch[1](2861/114412); Loss: 0.128925; Backpropagation: 0.2912 sec; Batch: 2.1163 sec
0.2166 0.1985 0.1711 0.1513 0.1351 0.1285 0.1200 0.1157 0.1108 0.1079 0.1047 0.1030 0.1012 0.1002 0.0993 0.0987 

[TRAIN] Epoch[1](2862/114412); Loss: 0.062470; Backpropagation: 0.2951 sec; Batch: 2.1204 sec
0.1117 0.0967 0.0780 0.0711 0.0650 0.0601 0.0579 0.0550 0.0536 0.0522 0.0512 0.0505 0.0497 0.0492 0.0489 0.0486 

[TRAIN] Epoch[1](2863/114412); Loss: 0.059348; Backpropagation: 0.2909 sec; Batch: 2.1184 sec
0.0947 0.0903 0.0753 0.0693 0.0621 0.0584 0.0547 0.0529 0.0514 0.0504 0.0495 0.0489 0.0484 0.0480 0.0477 0.0474 

[TRAIN] Epoch[1](2864/114412); Loss: 0.072086; Backpropagation: 0.2905 sec; Batch: 2.1170 sec
0.1280 0.1056 0.0895 0.0822 0.0781 0.0723 0.0673 0.0649 0.0623 0.0606 0.0593 0.0581 0.0572 0.0565 0.0560 0.0554 

[TRAIN] Epoch[1](2865/114412); Loss: 0.067653; Backpropagation: 0.2908 sec; Batch: 2.1061 sec
0.1161 0.0987 0.0856 0.0795 0.0717 0.0673 0.0630 0.0606 0.0584 0.0571 0.0558 0.0549 0.0542 0.0537 0.0531 0.0527 

[TRAIN] Epoch[1](2866/114412); Loss: 0.070952; Backpropagation: 0.2911 sec; Batch: 2.1745 sec
0.1284 0.1137 0.0950 0.0860 0.0733 0.0681 0.0634 0.0610 0.0589 0.0576 0.0566 0.0557 0.0548 0.0545 0.0542 0.0539 

[TRAIN] Epoch[1](2867/114412); Loss: 0.068772; Backpropagation: 0.2915 sec; Batch: 2.1132 sec
0.1230 0.1138 0.0998 0.0903 0.0782 0.0715 0.0636 0.0595 0.0552 0.0524 0.0508 0.0496 0.0489 0.0484 0.0479 0.0475 

[TRAIN] Epoch[1](2868/114412); Loss: 0.071601; Backpropagation: 0.2909 sec; Batch: 2.0817 sec
0.1204 0.1118 0.0979 0.0902 0.0805 0.0754 0.0684 0.0651 0.0605 0.0582 0.0555 0.0541 0.0529 0.0522 0.0515 0.0510 

[TRAIN] Epoch[1](2869/114412); Loss: 0.081311; Backpropagation: 0.2913 sec; Batch: 2.0812 sec
0.1429 0.1314 0.1102 0.1014 0.0862 0.0806 0.0743 0.0716 0.0679 0.0657 0.0638 0.0624 0.0615 0.0608 0.0602 0.0598 

[TRAIN] Epoch[1](2870/114412); Loss: 0.063522; Backpropagation: 0.2912 sec; Batch: 2.1521 sec
0.1071 0.0931 0.0802 0.0740 0.0663 0.0618 0.0596 0.0567 0.0551 0.0539 0.0528 0.0521 0.0515 0.0510 0.0507 0.0505 

[TRAIN] Epoch[1](2871/114412); Loss: 0.047313; Backpropagation: 0.2907 sec; Batch: 2.1467 sec
0.0966 0.0821 0.0577 0.0525 0.0478 0.0447 0.0422 0.0404 0.0391 0.0380 0.0373 0.0366 0.0361 0.0356 0.0352 0.0351 

[TRAIN] Epoch[1](2872/114412); Loss: 0.059850; Backpropagation: 0.2910 sec; Batch: 2.0924 sec
0.1466 0.1400 0.1028 0.0905 0.0623 0.0545 0.0446 0.0410 0.0384 0.0373 0.0357 0.0345 0.0334 0.0326 0.0319 0.0315 

[TRAIN] Epoch[1](2873/114412); Loss: 0.057473; Backpropagation: 0.2912 sec; Batch: 2.1156 sec
0.1282 0.1070 0.0785 0.0672 0.0574 0.0523 0.0490 0.0463 0.0447 0.0436 0.0425 0.0417 0.0410 0.0405 0.0401 0.0397 

[TRAIN] Epoch[1](2874/114412); Loss: 0.085465; Backpropagation: 0.2908 sec; Batch: 2.1335 sec
0.1427 0.1310 0.1032 0.0950 0.0863 0.0827 0.0800 0.0772 0.0754 0.0734 0.0723 0.0712 0.0702 0.0695 0.0690 0.0683 

[TRAIN] Epoch[1](2875/114412); Loss: 0.061661; Backpropagation: 0.2943 sec; Batch: 2.1457 sec
0.1207 0.1092 0.0785 0.0717 0.0618 0.0577 0.0538 0.0522 0.0505 0.0491 0.0486 0.0476 0.0470 0.0464 0.0460 0.0456 

[TRAIN] Epoch[1](2876/114412); Loss: 0.060384; Backpropagation: 0.2952 sec; Batch: 2.1208 sec
0.1307 0.1038 0.0840 0.0687 0.0601 0.0565 0.0523 0.0500 0.0481 0.0470 0.0460 0.0451 0.0442 0.0437 0.0432 0.0427 

[TRAIN] Epoch[1](2877/114412); Loss: 0.098954; Backpropagation: 0.2928 sec; Batch: 2.1570 sec
0.1646 0.1573 0.1375 0.1297 0.1124 0.1062 0.0918 0.0866 0.0803 0.0777 0.0756 0.0745 0.0736 0.0724 0.0719 0.0711 

[TRAIN] Epoch[1](2878/114412); Loss: 0.058752; Backpropagation: 0.2911 sec; Batch: 2.1125 sec
0.1126 0.1013 0.0828 0.0722 0.0615 0.0565 0.0526 0.0496 0.0476 0.0456 0.0446 0.0436 0.0431 0.0425 0.0420 0.0419 

[TRAIN] Epoch[1](2879/114412); Loss: 0.072495; Backpropagation: 0.2908 sec; Batch: 2.1402 sec
0.1229 0.1130 0.0908 0.0830 0.0723 0.0700 0.0663 0.0651 0.0628 0.0615 0.0604 0.0595 0.0589 0.0582 0.0578 0.0575 

[TRAIN] Epoch[1](2880/114412); Loss: 0.067908; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1145 0.0945 0.0819 0.0753 0.0711 0.0669 0.0642 0.0618 0.0602 0.0590 0.0576 0.0568 0.0563 0.0559 0.0554 0.0550 

[TRAIN] Epoch[1](2881/114412); Loss: 0.064792; Backpropagation: 0.2911 sec; Batch: 2.0776 sec
0.1134 0.1052 0.0878 0.0783 0.0678 0.0630 0.0592 0.0568 0.0549 0.0529 0.0513 0.0505 0.0496 0.0491 0.0487 0.0483 

[TRAIN] Epoch[1](2882/114412); Loss: 0.076877; Backpropagation: 0.2912 sec; Batch: 2.1346 sec
0.1264 0.1102 0.0958 0.0872 0.0797 0.0754 0.0719 0.0702 0.0680 0.0661 0.0651 0.0641 0.0631 0.0628 0.0623 0.0617 

[TRAIN] Epoch[1](2883/114412); Loss: 0.075953; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1614 0.1451 0.1148 0.1011 0.0810 0.0726 0.0669 0.0632 0.0588 0.0555 0.0528 0.0502 0.0490 0.0481 0.0475 0.0473 

[TRAIN] Epoch[1](2884/114412); Loss: 0.069000; Backpropagation: 0.2909 sec; Batch: 2.0908 sec
0.1309 0.1142 0.0957 0.0852 0.0740 0.0685 0.0614 0.0576 0.0550 0.0539 0.0525 0.0521 0.0514 0.0511 0.0504 0.0501 

[TRAIN] Epoch[1](2885/114412); Loss: 0.062469; Backpropagation: 0.2906 sec; Batch: 2.1149 sec
0.1095 0.0969 0.0806 0.0725 0.0638 0.0604 0.0566 0.0552 0.0533 0.0521 0.0514 0.0505 0.0499 0.0495 0.0488 0.0485 

[TRAIN] Epoch[1](2886/114412); Loss: 0.057183; Backpropagation: 0.2912 sec; Batch: 2.0797 sec
0.1113 0.0895 0.0690 0.0648 0.0577 0.0536 0.0523 0.0503 0.0487 0.0476 0.0467 0.0456 0.0450 0.0447 0.0443 0.0439 

[TRAIN] Epoch[1](2887/114412); Loss: 0.059690; Backpropagation: 0.2913 sec; Batch: 2.1167 sec
0.1214 0.0995 0.0779 0.0676 0.0575 0.0543 0.0515 0.0502 0.0490 0.0479 0.0474 0.0468 0.0464 0.0461 0.0459 0.0457 

[TRAIN] Epoch[1](2888/114412); Loss: 0.075561; Backpropagation: 0.2910 sec; Batch: 2.1205 sec
0.1363 0.1086 0.0879 0.0828 0.0761 0.0722 0.0692 0.0675 0.0661 0.0649 0.0641 0.0633 0.0629 0.0625 0.0623 0.0621 

[TRAIN] Epoch[1](2889/114412); Loss: 0.079690; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.1307 0.1062 0.0990 0.0918 0.0826 0.0783 0.0750 0.0718 0.0703 0.0690 0.0683 0.0676 0.0668 0.0663 0.0658 0.0656 

[TRAIN] Epoch[1](2890/114412); Loss: 0.086925; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1489 0.1213 0.1090 0.0955 0.0883 0.0841 0.0807 0.0781 0.0763 0.0749 0.0740 0.0730 0.0724 0.0719 0.0714 0.0711 

[TRAIN] Epoch[1](2891/114412); Loss: 0.065804; Backpropagation: 0.2928 sec; Batch: 2.1202 sec
0.1043 0.0911 0.0812 0.0757 0.0689 0.0652 0.0630 0.0599 0.0583 0.0575 0.0561 0.0552 0.0549 0.0543 0.0538 0.0535 

[TRAIN] Epoch[1](2892/114412); Loss: 0.052811; Backpropagation: 0.2911 sec; Batch: 2.1163 sec
0.1004 0.0807 0.0661 0.0586 0.0538 0.0512 0.0478 0.0459 0.0448 0.0437 0.0431 0.0425 0.0421 0.0417 0.0414 0.0412 

[TRAIN] Epoch[1](2893/114412); Loss: 0.083839; Backpropagation: 0.2908 sec; Batch: 2.1180 sec
0.1671 0.1378 0.1060 0.0960 0.0856 0.0811 0.0752 0.0724 0.0700 0.0680 0.0665 0.0651 0.0640 0.0630 0.0621 0.0615 

[TRAIN] Epoch[1](2894/114412); Loss: 0.071722; Backpropagation: 0.2912 sec; Batch: 2.1803 sec
0.1148 0.0992 0.0841 0.0784 0.0727 0.0697 0.0671 0.0656 0.0645 0.0636 0.0625 0.0619 0.0614 0.0610 0.0607 0.0604 

[TRAIN] Epoch[1](2895/114412); Loss: 0.087884; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1608 0.1329 0.1082 0.0980 0.0889 0.0843 0.0802 0.0774 0.0757 0.0740 0.0729 0.0720 0.0711 0.0704 0.0698 0.0693 

[TRAIN] Epoch[1](2896/114412); Loss: 0.081953; Backpropagation: 0.2928 sec; Batch: 2.1307 sec
0.1594 0.1332 0.1069 0.0949 0.0849 0.0772 0.0729 0.0700 0.0679 0.0664 0.0650 0.0639 0.0631 0.0623 0.0619 0.0614 

[TRAIN] Epoch[1](2897/114412); Loss: 0.071896; Backpropagation: 0.2910 sec; Batch: 2.0779 sec
0.1583 0.1264 0.0955 0.0872 0.0706 0.0675 0.0615 0.0588 0.0562 0.0549 0.0539 0.0531 0.0523 0.0518 0.0514 0.0510 

[TRAIN] Epoch[1](2898/114412); Loss: 0.062541; Backpropagation: 0.2905 sec; Batch: 2.1156 sec
0.1352 0.1126 0.0856 0.0767 0.0663 0.0606 0.0565 0.0528 0.0503 0.0479 0.0459 0.0446 0.0433 0.0419 0.0408 0.0398 

[TRAIN] Epoch[1](2899/114412); Loss: 0.074478; Backpropagation: 0.2908 sec; Batch: 2.1239 sec
0.1427 0.1093 0.0966 0.0858 0.0780 0.0727 0.0684 0.0651 0.0630 0.0616 0.0601 0.0589 0.0582 0.0575 0.0570 0.0566 

[TRAIN] Epoch[1](2900/114412); Loss: 0.074207; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1337 0.1167 0.1042 0.0906 0.0803 0.0756 0.0720 0.0675 0.0621 0.0611 0.0589 0.0549 0.0540 0.0531 0.0517 0.0510 

[TRAIN] Epoch[1](2901/114412); Loss: 0.078138; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1606 0.1414 0.0990 0.0953 0.0817 0.0733 0.0679 0.0665 0.0629 0.0605 0.0593 0.0579 0.0570 0.0563 0.0556 0.0551 

[TRAIN] Epoch[1](2902/114412); Loss: 0.070904; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1504 0.0981 0.0903 0.0765 0.0712 0.0655 0.0627 0.0611 0.0596 0.0589 0.0580 0.0571 0.0566 0.0563 0.0561 0.0558 

[TRAIN] Epoch[1](2903/114412); Loss: 0.067376; Backpropagation: 0.2903 sec; Batch: 2.1129 sec
0.1496 0.1220 0.1012 0.0853 0.0706 0.0652 0.0569 0.0539 0.0510 0.0490 0.0475 0.0465 0.0457 0.0450 0.0446 0.0442 

[TRAIN] Epoch[1](2904/114412); Loss: 0.095047; Backpropagation: 0.2952 sec; Batch: 2.1222 sec
0.1624 0.1443 0.1167 0.1098 0.0967 0.0921 0.0860 0.0840 0.0822 0.0809 0.0797 0.0784 0.0776 0.0771 0.0767 0.0762 

[TRAIN] Epoch[1](2905/114412); Loss: 0.059930; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1104 0.0836 0.0717 0.0648 0.0604 0.0580 0.0558 0.0539 0.0526 0.0514 0.0506 0.0500 0.0495 0.0490 0.0487 0.0485 

[TRAIN] Epoch[1](2906/114412); Loss: 0.076829; Backpropagation: 0.2953 sec; Batch: 2.1257 sec
0.1761 0.1454 0.1026 0.0915 0.0783 0.0708 0.0677 0.0625 0.0595 0.0579 0.0554 0.0540 0.0531 0.0521 0.0513 0.0511 

[TRAIN] Epoch[1](2907/114412); Loss: 0.081634; Backpropagation: 0.2923 sec; Batch: 2.1198 sec
0.1958 0.1604 0.1096 0.1024 0.0798 0.0730 0.0665 0.0636 0.0610 0.0587 0.0572 0.0565 0.0558 0.0556 0.0552 0.0549 

[TRAIN] Epoch[1](2908/114412); Loss: 0.077681; Backpropagation: 0.2902 sec; Batch: 2.1309 sec
0.1480 0.1167 0.0926 0.0829 0.0764 0.0723 0.0696 0.0675 0.0666 0.0656 0.0650 0.0647 0.0642 0.0639 0.0635 0.0633 

[TRAIN] Epoch[1](2909/114412); Loss: 0.084806; Backpropagation: 0.2907 sec; Batch: 2.1172 sec
0.1932 0.1531 0.0987 0.0980 0.0845 0.0788 0.0741 0.0703 0.0675 0.0654 0.0640 0.0630 0.0622 0.0617 0.0614 0.0611 

[TRAIN] Epoch[1](2910/114412); Loss: 0.060405; Backpropagation: 0.2909 sec; Batch: 2.1145 sec
0.1884 0.1315 0.0764 0.0644 0.0570 0.0501 0.0469 0.0438 0.0418 0.0404 0.0392 0.0383 0.0377 0.0372 0.0368 0.0365 

[TRAIN] Epoch[1](2911/114412); Loss: 0.080549; Backpropagation: 0.2910 sec; Batch: 2.1213 sec
0.1526 0.1318 0.1140 0.0964 0.0835 0.0760 0.0711 0.0673 0.0652 0.0638 0.0626 0.0618 0.0612 0.0608 0.0604 0.0603 

[TRAIN] Epoch[1](2912/114412); Loss: 0.060870; Backpropagation: 0.2922 sec; Batch: 2.1190 sec
0.1601 0.1079 0.0716 0.0683 0.0582 0.0544 0.0514 0.0488 0.0470 0.0454 0.0447 0.0440 0.0435 0.0432 0.0429 0.0427 

[TRAIN] Epoch[1](2913/114412); Loss: 0.059879; Backpropagation: 0.2914 sec; Batch: 2.1195 sec
0.1273 0.0891 0.0744 0.0653 0.0601 0.0554 0.0529 0.0507 0.0496 0.0488 0.0481 0.0476 0.0474 0.0472 0.0471 0.0471 

[TRAIN] Epoch[1](2914/114412); Loss: 0.057736; Backpropagation: 0.2954 sec; Batch: 2.1218 sec
0.1482 0.1180 0.0751 0.0640 0.0551 0.0510 0.0474 0.0451 0.0429 0.0417 0.0407 0.0399 0.0393 0.0388 0.0384 0.0381 

[TRAIN] Epoch[1](2915/114412); Loss: 0.069165; Backpropagation: 0.2908 sec; Batch: 2.1148 sec
0.1443 0.1135 0.0876 0.0779 0.0689 0.0642 0.0617 0.0588 0.0571 0.0556 0.0543 0.0536 0.0530 0.0525 0.0520 0.0517 

[TRAIN] Epoch[1](2916/114412); Loss: 0.101664; Backpropagation: 0.2928 sec; Batch: 2.1163 sec
0.1798 0.1437 0.1153 0.1095 0.1021 0.0981 0.0943 0.0920 0.0898 0.0885 0.0872 0.0865 0.0856 0.0852 0.0847 0.0843 

[TRAIN] Epoch[1](2917/114412); Loss: 0.097639; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.2211 0.1940 0.1432 0.1248 0.0965 0.0883 0.0806 0.0773 0.0723 0.0701 0.0682 0.0667 0.0658 0.0651 0.0645 0.0637 

[TRAIN] Epoch[1](2918/114412); Loss: 0.071740; Backpropagation: 0.2910 sec; Batch: 2.0878 sec
0.1856 0.1462 0.0922 0.0803 0.0646 0.0600 0.0571 0.0546 0.0533 0.0520 0.0514 0.0508 0.0504 0.0500 0.0497 0.0494 

[TRAIN] Epoch[1](2919/114412); Loss: 0.078829; Backpropagation: 0.2907 sec; Batch: 2.0778 sec
0.1679 0.1260 0.0996 0.0891 0.0802 0.0748 0.0706 0.0671 0.0650 0.0630 0.0615 0.0606 0.0597 0.0592 0.0586 0.0582 

[TRAIN] Epoch[1](2920/114412); Loss: 0.064097; Backpropagation: 0.2912 sec; Batch: 2.1217 sec
0.1330 0.1113 0.0824 0.0744 0.0618 0.0578 0.0563 0.0540 0.0522 0.0511 0.0500 0.0490 0.0486 0.0482 0.0479 0.0477 

[TRAIN] Epoch[1](2921/114412); Loss: 0.068384; Backpropagation: 0.2906 sec; Batch: 2.0776 sec
0.1593 0.1261 0.0920 0.0757 0.0693 0.0636 0.0582 0.0554 0.0533 0.0516 0.0503 0.0491 0.0484 0.0477 0.0473 0.0469 

[TRAIN] Epoch[1](2922/114412); Loss: 0.083776; Backpropagation: 0.2902 sec; Batch: 2.1152 sec
0.1666 0.1234 0.0940 0.0872 0.0818 0.0778 0.0753 0.0741 0.0724 0.0715 0.0708 0.0700 0.0695 0.0690 0.0686 0.0682 

[TRAIN] Epoch[1](2923/114412); Loss: 0.057687; Backpropagation: 0.2905 sec; Batch: 2.0772 sec
0.1533 0.1034 0.0702 0.0618 0.0552 0.0511 0.0483 0.0464 0.0446 0.0435 0.0424 0.0416 0.0410 0.0404 0.0400 0.0399 

[TRAIN] Epoch[1](2924/114412); Loss: 0.070292; Backpropagation: 0.2907 sec; Batch: 2.0932 sec
0.1536 0.1237 0.0930 0.0792 0.0703 0.0643 0.0603 0.0576 0.0557 0.0545 0.0535 0.0527 0.0521 0.0517 0.0513 0.0511 

[TRAIN] Epoch[1](2925/114412); Loss: 0.067007; Backpropagation: 0.2907 sec; Batch: 2.1170 sec
0.1463 0.1287 0.0771 0.0681 0.0656 0.0613 0.0587 0.0557 0.0540 0.0528 0.0521 0.0512 0.0507 0.0503 0.0499 0.0496 

[TRAIN] Epoch[1](2926/114412); Loss: 0.056983; Backpropagation: 0.2907 sec; Batch: 2.1163 sec
0.1327 0.1055 0.0832 0.0681 0.0602 0.0539 0.0483 0.0451 0.0426 0.0411 0.0401 0.0391 0.0386 0.0381 0.0378 0.0374 

[TRAIN] Epoch[1](2927/114412); Loss: 0.080820; Backpropagation: 0.2906 sec; Batch: 2.1146 sec
0.2050 0.1693 0.1252 0.0998 0.0812 0.0734 0.0667 0.0597 0.0562 0.0542 0.0528 0.0514 0.0504 0.0497 0.0493 0.0488 

[TRAIN] Epoch[1](2928/114412); Loss: 0.112740; Backpropagation: 0.2912 sec; Batch: 2.0773 sec
0.1991 0.1823 0.1388 0.1270 0.1144 0.1087 0.1021 0.0986 0.0958 0.0937 0.0927 0.0917 0.0908 0.0900 0.0896 0.0888 

[TRAIN] Epoch[1](2929/114412); Loss: 0.055771; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.1149 0.0943 0.0767 0.0656 0.0571 0.0520 0.0492 0.0468 0.0447 0.0435 0.0427 0.0419 0.0412 0.0409 0.0405 0.0402 

[TRAIN] Epoch[1](2930/114412); Loss: 0.098761; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1856 0.1633 0.1345 0.1220 0.1099 0.1005 0.0927 0.0867 0.0820 0.0785 0.0757 0.0734 0.0712 0.0696 0.0683 0.0665 

[TRAIN] Epoch[1](2931/114412); Loss: 0.084892; Backpropagation: 0.2908 sec; Batch: 2.1011 sec
0.1637 0.1477 0.1144 0.1007 0.0880 0.0817 0.0765 0.0724 0.0696 0.0672 0.0653 0.0642 0.0628 0.0620 0.0614 0.0608 

[TRAIN] Epoch[1](2932/114412); Loss: 0.090165; Backpropagation: 0.2919 sec; Batch: 2.0983 sec
0.1599 0.1501 0.1141 0.1050 0.0925 0.0866 0.0816 0.0788 0.0760 0.0746 0.0730 0.0716 0.0707 0.0702 0.0693 0.0687 

[TRAIN] Epoch[1](2933/114412); Loss: 0.086306; Backpropagation: 0.2904 sec; Batch: 2.1168 sec
0.2038 0.1715 0.1139 0.0976 0.0804 0.0788 0.0728 0.0689 0.0661 0.0638 0.0623 0.0614 0.0606 0.0601 0.0596 0.0593 

[TRAIN] Epoch[1](2934/114412); Loss: 0.063696; Backpropagation: 0.2915 sec; Batch: 2.1194 sec
0.1976 0.1505 0.0863 0.0651 0.0561 0.0519 0.0463 0.0449 0.0427 0.0417 0.0407 0.0399 0.0393 0.0390 0.0386 0.0384 

[TRAIN] Epoch[1](2935/114412); Loss: 0.076574; Backpropagation: 0.2911 sec; Batch: 2.1155 sec
0.1587 0.1408 0.1075 0.0942 0.0821 0.0756 0.0678 0.0630 0.0596 0.0575 0.0555 0.0543 0.0534 0.0525 0.0517 0.0511 

[TRAIN] Epoch[1](2936/114412); Loss: 0.072050; Backpropagation: 0.2954 sec; Batch: 2.1192 sec
0.1251 0.0967 0.0863 0.0807 0.0754 0.0717 0.0680 0.0653 0.0635 0.0621 0.0612 0.0603 0.0598 0.0594 0.0589 0.0585 

[TRAIN] Epoch[1](2937/114412); Loss: 0.100821; Backpropagation: 0.2929 sec; Batch: 2.1235 sec
0.1896 0.1782 0.1363 0.1212 0.1007 0.0919 0.0878 0.0843 0.0823 0.0804 0.0791 0.0780 0.0770 0.0761 0.0754 0.0749 

[TRAIN] Epoch[1](2938/114412); Loss: 0.074031; Backpropagation: 0.2950 sec; Batch: 2.0873 sec
0.1426 0.1162 0.0928 0.0823 0.0740 0.0688 0.0661 0.0643 0.0624 0.0612 0.0604 0.0598 0.0590 0.0586 0.0582 0.0580 

[TRAIN] Epoch[1](2939/114412); Loss: 0.070554; Backpropagation: 0.2922 sec; Batch: 2.0820 sec
0.1295 0.1031 0.0867 0.0768 0.0718 0.0675 0.0652 0.0629 0.0611 0.0599 0.0590 0.0582 0.0574 0.0569 0.0566 0.0562 

[TRAIN] Epoch[1](2940/114412); Loss: 0.048741; Backpropagation: 0.2911 sec; Batch: 2.0811 sec
0.1313 0.0990 0.0603 0.0505 0.0479 0.0438 0.0394 0.0377 0.0360 0.0350 0.0342 0.0336 0.0331 0.0328 0.0327 0.0326 

[TRAIN] Epoch[1](2941/114412); Loss: 0.079317; Backpropagation: 0.2972 sec; Batch: 2.0856 sec
0.1898 0.1603 0.0941 0.0838 0.0745 0.0700 0.0646 0.0627 0.0616 0.0601 0.0593 0.0587 0.0580 0.0574 0.0572 0.0569 

[TRAIN] Epoch[1](2942/114412); Loss: 0.081389; Backpropagation: 0.2928 sec; Batch: 2.0986 sec
0.1591 0.1289 0.1002 0.0894 0.0824 0.0765 0.0716 0.0692 0.0680 0.0669 0.0662 0.0655 0.0651 0.0647 0.0645 0.0641 

[TRAIN] Epoch[1](2943/114412); Loss: 0.059025; Backpropagation: 0.2929 sec; Batch: 2.1201 sec
0.1152 0.1015 0.0809 0.0739 0.0635 0.0576 0.0526 0.0494 0.0473 0.0459 0.0445 0.0438 0.0428 0.0422 0.0418 0.0415 

[TRAIN] Epoch[1](2944/114412); Loss: 0.063704; Backpropagation: 0.2914 sec; Batch: 2.1226 sec
0.1429 0.1207 0.0879 0.0743 0.0610 0.0555 0.0539 0.0511 0.0491 0.0480 0.0470 0.0464 0.0457 0.0455 0.0453 0.0449 

[TRAIN] Epoch[1](2945/114412); Loss: 0.051383; Backpropagation: 0.2952 sec; Batch: 2.1236 sec
0.1372 0.0957 0.0640 0.0556 0.0477 0.0445 0.0416 0.0399 0.0386 0.0379 0.0373 0.0368 0.0365 0.0364 0.0362 0.0362 

[TRAIN] Epoch[1](2946/114412); Loss: 0.059641; Backpropagation: 0.2915 sec; Batch: 2.0791 sec
0.1495 0.1265 0.0788 0.0682 0.0600 0.0554 0.0492 0.0459 0.0436 0.0419 0.0405 0.0398 0.0393 0.0387 0.0385 0.0384 

[TRAIN] Epoch[1](2947/114412); Loss: 0.059020; Backpropagation: 0.2916 sec; Batch: 2.0824 sec
0.1350 0.1102 0.0806 0.0719 0.0613 0.0554 0.0506 0.0471 0.0451 0.0431 0.0421 0.0411 0.0408 0.0401 0.0399 0.0399 

[TRAIN] Epoch[1](2948/114412); Loss: 0.086273; Backpropagation: 0.2896 sec; Batch: 2.0953 sec
0.1820 0.1669 0.1040 0.0948 0.0801 0.0765 0.0750 0.0725 0.0701 0.0683 0.0669 0.0660 0.0652 0.0646 0.0640 0.0635 

[TRAIN] Epoch[1](2949/114412); Loss: 0.052704; Backpropagation: 0.2904 sec; Batch: 2.1170 sec
0.1091 0.0880 0.0749 0.0647 0.0567 0.0521 0.0468 0.0439 0.0414 0.0401 0.0388 0.0383 0.0377 0.0373 0.0369 0.0367 

[TRAIN] Epoch[1](2950/114412); Loss: 0.057927; Backpropagation: 0.2913 sec; Batch: 2.1190 sec
0.1299 0.0998 0.0760 0.0655 0.0573 0.0525 0.0506 0.0485 0.0462 0.0451 0.0441 0.0432 0.0426 0.0421 0.0418 0.0415 

[TRAIN] Epoch[1](2951/114412); Loss: 0.068431; Backpropagation: 0.2912 sec; Batch: 2.1155 sec
0.1269 0.0993 0.0896 0.0771 0.0672 0.0639 0.0613 0.0595 0.0585 0.0574 0.0568 0.0563 0.0558 0.0553 0.0550 0.0549 

[TRAIN] Epoch[1](2952/114412); Loss: 0.084695; Backpropagation: 0.2912 sec; Batch: 2.1286 sec
0.1410 0.1108 0.0989 0.0907 0.0857 0.0818 0.0793 0.0779 0.0763 0.0752 0.0743 0.0736 0.0730 0.0726 0.0722 0.0719 

[TRAIN] Epoch[1](2953/114412); Loss: 0.056403; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.1625 0.1044 0.0652 0.0573 0.0510 0.0476 0.0450 0.0433 0.0424 0.0417 0.0411 0.0407 0.0403 0.0400 0.0400 0.0399 

[TRAIN] Epoch[1](2954/114412); Loss: 0.072289; Backpropagation: 0.2917 sec; Batch: 2.0794 sec
0.1307 0.1227 0.0868 0.0821 0.0703 0.0667 0.0645 0.0627 0.0612 0.0602 0.0594 0.0586 0.0583 0.0579 0.0574 0.0572 

[TRAIN] Epoch[1](2955/114412); Loss: 0.044511; Backpropagation: 0.2911 sec; Batch: 2.1217 sec
0.1019 0.0788 0.0581 0.0542 0.0451 0.0396 0.0378 0.0360 0.0347 0.0336 0.0328 0.0323 0.0321 0.0318 0.0316 0.0317 

[TRAIN] Epoch[1](2956/114412); Loss: 0.058691; Backpropagation: 0.2912 sec; Batch: 2.1391 sec
0.1197 0.0914 0.0715 0.0656 0.0588 0.0552 0.0530 0.0507 0.0494 0.0482 0.0473 0.0467 0.0461 0.0455 0.0451 0.0448 

[TRAIN] Epoch[1](2957/114412); Loss: 0.057063; Backpropagation: 0.2925 sec; Batch: 2.1557 sec
0.1527 0.1253 0.0768 0.0573 0.0510 0.0470 0.0447 0.0432 0.0417 0.0409 0.0399 0.0393 0.0389 0.0383 0.0381 0.0378 

[TRAIN] Epoch[1](2958/114412); Loss: 0.055103; Backpropagation: 0.2950 sec; Batch: 2.1180 sec
0.1129 0.0883 0.0741 0.0635 0.0566 0.0519 0.0490 0.0468 0.0454 0.0439 0.0429 0.0422 0.0417 0.0412 0.0406 0.0404 

[TRAIN] Epoch[1](2959/114412); Loss: 0.087379; Backpropagation: 0.2929 sec; Batch: 2.1547 sec
0.1581 0.1366 0.1143 0.0982 0.0904 0.0839 0.0795 0.0756 0.0735 0.0723 0.0708 0.0702 0.0694 0.0688 0.0684 0.0681 

[TRAIN] Epoch[1](2960/114412); Loss: 0.081522; Backpropagation: 0.2905 sec; Batch: 2.1092 sec
0.1557 0.1246 0.1037 0.0955 0.0849 0.0776 0.0739 0.0706 0.0686 0.0669 0.0656 0.0646 0.0639 0.0632 0.0627 0.0623 

[TRAIN] Epoch[1](2961/114412); Loss: 0.069634; Backpropagation: 0.2912 sec; Batch: 2.1540 sec
0.1658 0.1151 0.0805 0.0729 0.0686 0.0635 0.0606 0.0585 0.0565 0.0551 0.0543 0.0535 0.0529 0.0524 0.0520 0.0518 

[TRAIN] Epoch[1](2962/114412); Loss: 0.094455; Backpropagation: 0.2911 sec; Batch: 2.1414 sec
0.1861 0.1677 0.1353 0.1161 0.1021 0.0891 0.0817 0.0775 0.0736 0.0720 0.0708 0.0695 0.0686 0.0677 0.0671 0.0667 

[TRAIN] Epoch[1](2963/114412); Loss: 0.060011; Backpropagation: 0.2912 sec; Batch: 2.1495 sec
0.1663 0.1149 0.0665 0.0658 0.0549 0.0510 0.0482 0.0464 0.0452 0.0442 0.0438 0.0431 0.0427 0.0426 0.0423 0.0422 

[TRAIN] Epoch[1](2964/114412); Loss: 0.069248; Backpropagation: 0.2909 sec; Batch: 2.3666 sec
0.1424 0.1158 0.0831 0.0763 0.0688 0.0651 0.0614 0.0593 0.0576 0.0564 0.0553 0.0544 0.0537 0.0531 0.0528 0.0524 

[TRAIN] Epoch[1](2965/114412); Loss: 0.051692; Backpropagation: 0.2912 sec; Batch: 2.1189 sec
0.1327 0.0937 0.0649 0.0557 0.0491 0.0452 0.0431 0.0414 0.0400 0.0388 0.0382 0.0376 0.0371 0.0368 0.0365 0.0363 

[TRAIN] Epoch[1](2966/114412); Loss: 0.051270; Backpropagation: 0.2929 sec; Batch: 2.2127 sec
0.1044 0.0806 0.0700 0.0628 0.0545 0.0476 0.0452 0.0428 0.0412 0.0402 0.0394 0.0389 0.0386 0.0383 0.0379 0.0378 

[TRAIN] Epoch[1](2967/114412); Loss: 0.082561; Backpropagation: 0.2936 sec; Batch: 2.0809 sec
0.1705 0.1346 0.1012 0.0905 0.0826 0.0760 0.0731 0.0708 0.0686 0.0672 0.0658 0.0650 0.0644 0.0638 0.0635 0.0632 

[TRAIN] Epoch[1](2968/114412); Loss: 0.092480; Backpropagation: 0.2911 sec; Batch: 2.1266 sec
0.1484 0.1222 0.1062 0.0989 0.0942 0.0898 0.0873 0.0852 0.0837 0.0825 0.0816 0.0809 0.0803 0.0798 0.0795 0.0792 

[TRAIN] Epoch[1](2969/114412); Loss: 0.087955; Backpropagation: 0.2908 sec; Batch: 2.1062 sec
0.1817 0.1487 0.1143 0.1022 0.0906 0.0831 0.0778 0.0740 0.0715 0.0695 0.0678 0.0668 0.0658 0.0651 0.0644 0.0640 

[TRAIN] Epoch[1](2970/114412); Loss: 0.073785; Backpropagation: 0.2929 sec; Batch: 2.1535 sec
0.1386 0.1190 0.0956 0.0837 0.0736 0.0693 0.0655 0.0632 0.0617 0.0604 0.0596 0.0590 0.0584 0.0580 0.0575 0.0573 

[TRAIN] Epoch[1](2971/114412); Loss: 0.060526; Backpropagation: 0.2928 sec; Batch: 2.1133 sec
0.1368 0.1155 0.0863 0.0727 0.0715 0.0597 0.0511 0.0498 0.0482 0.0436 0.0419 0.0405 0.0390 0.0378 0.0372 0.0368 

[TRAIN] Epoch[1](2972/114412); Loss: 0.080049; Backpropagation: 0.2913 sec; Batch: 2.1472 sec
0.1909 0.1383 0.1120 0.0938 0.0813 0.0723 0.0671 0.0632 0.0610 0.0595 0.0585 0.0576 0.0570 0.0564 0.0560 0.0558 

[TRAIN] Epoch[1](2973/114412); Loss: 0.068302; Backpropagation: 0.2952 sec; Batch: 2.1253 sec
0.1437 0.1107 0.0819 0.0706 0.0667 0.0631 0.0600 0.0580 0.0568 0.0559 0.0553 0.0548 0.0543 0.0539 0.0537 0.0534 

[TRAIN] Epoch[1](2974/114412); Loss: 0.064428; Backpropagation: 0.2929 sec; Batch: 2.1476 sec
0.1673 0.1358 0.0836 0.0743 0.0617 0.0561 0.0515 0.0487 0.0471 0.0459 0.0447 0.0439 0.0432 0.0428 0.0423 0.0420 

[TRAIN] Epoch[1](2975/114412); Loss: 0.105494; Backpropagation: 0.2954 sec; Batch: 2.1167 sec
0.1714 0.1433 0.1213 0.1127 0.1066 0.1023 0.0988 0.0965 0.0951 0.0938 0.0927 0.0918 0.0913 0.0905 0.0900 0.0897 

[TRAIN] Epoch[1](2976/114412); Loss: 0.058099; Backpropagation: 0.2929 sec; Batch: 2.2042 sec
0.1280 0.0867 0.0694 0.0632 0.0580 0.0530 0.0512 0.0496 0.0483 0.0473 0.0469 0.0462 0.0458 0.0455 0.0453 0.0452 

[TRAIN] Epoch[1](2977/114412); Loss: 0.077787; Backpropagation: 0.2932 sec; Batch: 2.1485 sec
0.1403 0.1069 0.0943 0.0866 0.0804 0.0754 0.0722 0.0699 0.0681 0.0668 0.0656 0.0646 0.0641 0.0635 0.0631 0.0627 

[TRAIN] Epoch[1](2978/114412); Loss: 0.055909; Backpropagation: 0.2916 sec; Batch: 2.1129 sec
0.1346 0.1108 0.0808 0.0647 0.0534 0.0503 0.0473 0.0435 0.0417 0.0403 0.0392 0.0384 0.0379 0.0374 0.0371 0.0369 

[TRAIN] Epoch[1](2979/114412); Loss: 0.055551; Backpropagation: 0.2914 sec; Batch: 2.1585 sec
0.1193 0.1060 0.0764 0.0692 0.0567 0.0518 0.0470 0.0450 0.0428 0.0413 0.0403 0.0394 0.0390 0.0385 0.0381 0.0379 

[TRAIN] Epoch[1](2980/114412); Loss: 0.071988; Backpropagation: 0.2951 sec; Batch: 2.1131 sec
0.1557 0.1260 0.0929 0.0797 0.0707 0.0665 0.0624 0.0598 0.0581 0.0567 0.0555 0.0548 0.0541 0.0534 0.0530 0.0526 

[TRAIN] Epoch[1](2981/114412); Loss: 0.052012; Backpropagation: 0.2911 sec; Batch: 2.1114 sec
0.1300 0.0972 0.0645 0.0594 0.0509 0.0473 0.0430 0.0415 0.0399 0.0388 0.0380 0.0373 0.0367 0.0362 0.0359 0.0356 

[TRAIN] Epoch[1](2982/114412); Loss: 0.075896; Backpropagation: 0.2911 sec; Batch: 2.1156 sec
0.1676 0.1405 0.0981 0.0841 0.0732 0.0676 0.0646 0.0617 0.0599 0.0590 0.0580 0.0570 0.0566 0.0560 0.0555 0.0551 

[TRAIN] Epoch[1](2983/114412); Loss: 0.064668; Backpropagation: 0.2918 sec; Batch: 2.1494 sec
0.1696 0.1295 0.0829 0.0675 0.0590 0.0592 0.0516 0.0500 0.0483 0.0472 0.0464 0.0456 0.0451 0.0446 0.0442 0.0440 

[TRAIN] Epoch[1](2984/114412); Loss: 0.070307; Backpropagation: 0.2912 sec; Batch: 2.1081 sec
0.1676 0.1271 0.0892 0.0777 0.0702 0.0639 0.0598 0.0563 0.0548 0.0533 0.0523 0.0516 0.0509 0.0503 0.0500 0.0497 

[TRAIN] Epoch[1](2985/114412); Loss: 0.070118; Backpropagation: 0.2911 sec; Batch: 2.1488 sec
0.1310 0.1016 0.0810 0.0751 0.0707 0.0673 0.0642 0.0625 0.0612 0.0598 0.0592 0.0583 0.0579 0.0576 0.0573 0.0571 

[TRAIN] Epoch[1](2986/114412); Loss: 0.077904; Backpropagation: 0.2913 sec; Batch: 2.1112 sec
0.1258 0.1141 0.0935 0.0846 0.0782 0.0745 0.0717 0.0701 0.0689 0.0680 0.0672 0.0667 0.0663 0.0660 0.0656 0.0654 

[TRAIN] Epoch[1](2987/114412); Loss: 0.060550; Backpropagation: 0.2915 sec; Batch: 2.1487 sec
0.1575 0.1092 0.0778 0.0687 0.0583 0.0529 0.0496 0.0481 0.0460 0.0448 0.0439 0.0432 0.0427 0.0422 0.0420 0.0418 

[TRAIN] Epoch[1](2988/114412); Loss: 0.065368; Backpropagation: 0.2957 sec; Batch: 2.0830 sec
0.1341 0.1141 0.0809 0.0726 0.0630 0.0595 0.0563 0.0548 0.0536 0.0527 0.0518 0.0513 0.0507 0.0503 0.0501 0.0499 

[TRAIN] Epoch[1](2989/114412); Loss: 0.072995; Backpropagation: 0.2928 sec; Batch: 2.1474 sec
0.1649 0.1303 0.0963 0.0859 0.0733 0.0669 0.0624 0.0590 0.0569 0.0556 0.0544 0.0536 0.0527 0.0523 0.0519 0.0515 

[TRAIN] Epoch[1](2990/114412); Loss: 0.069066; Backpropagation: 0.2955 sec; Batch: 2.0830 sec
0.1903 0.1401 0.0860 0.0758 0.0679 0.0603 0.0544 0.0522 0.0506 0.0491 0.0482 0.0472 0.0465 0.0458 0.0455 0.0451 

[TRAIN] Epoch[1](2991/114412); Loss: 0.056021; Backpropagation: 0.2931 sec; Batch: 2.1514 sec
0.1188 0.0854 0.0695 0.0616 0.0550 0.0525 0.0496 0.0479 0.0467 0.0457 0.0449 0.0444 0.0440 0.0437 0.0435 0.0432 

[TRAIN] Epoch[1](2992/114412); Loss: 0.044169; Backpropagation: 0.2908 sec; Batch: 2.1138 sec
0.1066 0.0757 0.0575 0.0512 0.0443 0.0405 0.0381 0.0362 0.0346 0.0335 0.0326 0.0319 0.0314 0.0311 0.0309 0.0307 

[TRAIN] Epoch[1](2993/114412); Loss: 0.050025; Backpropagation: 0.2904 sec; Batch: 2.1183 sec
0.1211 0.0974 0.0663 0.0550 0.0492 0.0446 0.0415 0.0395 0.0381 0.0370 0.0362 0.0357 0.0353 0.0348 0.0344 0.0342 

[TRAIN] Epoch[1](2994/114412); Loss: 0.054834; Backpropagation: 0.2910 sec; Batch: 2.1443 sec
0.1592 0.1076 0.0731 0.0615 0.0597 0.0489 0.0432 0.0410 0.0386 0.0364 0.0357 0.0354 0.0345 0.0343 0.0342 0.0341 

[TRAIN] Epoch[1](2995/114412); Loss: 0.063169; Backpropagation: 0.2921 sec; Batch: 2.0848 sec
0.1096 0.0949 0.0796 0.0699 0.0630 0.0600 0.0571 0.0553 0.0545 0.0537 0.0531 0.0527 0.0523 0.0519 0.0518 0.0516 

[TRAIN] Epoch[1](2996/114412); Loss: 0.071837; Backpropagation: 0.2914 sec; Batch: 2.0883 sec
0.1475 0.1192 0.0931 0.0806 0.0727 0.0681 0.0643 0.0611 0.0588 0.0571 0.0563 0.0552 0.0546 0.0541 0.0536 0.0533 

[TRAIN] Epoch[1](2997/114412); Loss: 0.078117; Backpropagation: 0.2912 sec; Batch: 2.0778 sec
0.1709 0.1513 0.1077 0.0983 0.0746 0.0695 0.0657 0.0628 0.0600 0.0580 0.0566 0.0559 0.0553 0.0549 0.0544 0.0540 

[TRAIN] Epoch[1](2998/114412); Loss: 0.074895; Backpropagation: 0.2910 sec; Batch: 2.0805 sec
0.1737 0.1340 0.1047 0.0876 0.0774 0.0667 0.0630 0.0602 0.0583 0.0557 0.0545 0.0538 0.0529 0.0523 0.0519 0.0515 

[TRAIN] Epoch[1](2999/114412); Loss: 0.065963; Backpropagation: 0.2918 sec; Batch: 2.0858 sec
0.1153 0.0977 0.0847 0.0757 0.0699 0.0635 0.0615 0.0588 0.0565 0.0553 0.0541 0.0533 0.0529 0.0525 0.0520 0.0519 

[TRAIN] Epoch[1](3000/114412); Loss: 0.083705; Backpropagation: 0.2929 sec; Batch: 2.1150 sec
0.1686 0.1412 0.1190 0.1022 0.0865 0.0793 0.0753 0.0704 0.0674 0.0653 0.0633 0.0618 0.0608 0.0600 0.0593 0.0587 

[TRAIN] Epoch[1](3001/114412); Loss: 0.060655; Backpropagation: 0.2917 sec; Batch: 2.1205 sec
0.1338 0.0892 0.0729 0.0634 0.0579 0.0561 0.0543 0.0520 0.0509 0.0498 0.0493 0.0490 0.0485 0.0481 0.0478 0.0475 

[TRAIN] Epoch[1](3002/114412); Loss: 0.067393; Backpropagation: 0.3010 sec; Batch: 2.1074 sec
0.1620 0.1459 0.0991 0.0849 0.0629 0.0555 0.0538 0.0511 0.0483 0.0475 0.0463 0.0454 0.0446 0.0441 0.0437 0.0434 

[TRAIN] Epoch[1](3003/114412); Loss: 0.066816; Backpropagation: 0.2911 sec; Batch: 2.1185 sec
0.1462 0.1324 0.1054 0.0917 0.0673 0.0635 0.0598 0.0517 0.0498 0.0470 0.0443 0.0429 0.0423 0.0420 0.0416 0.0413 

[TRAIN] Epoch[1](3004/114412); Loss: 0.067497; Backpropagation: 0.2917 sec; Batch: 2.0817 sec
0.1541 0.1239 0.0906 0.0775 0.0691 0.0611 0.0567 0.0549 0.0522 0.0508 0.0499 0.0490 0.0482 0.0478 0.0473 0.0468 

[TRAIN] Epoch[1](3005/114412); Loss: 0.071091; Backpropagation: 0.2944 sec; Batch: 2.0839 sec
0.1426 0.1099 0.0856 0.0800 0.0730 0.0670 0.0631 0.0611 0.0597 0.0586 0.0578 0.0570 0.0564 0.0557 0.0553 0.0548 

[TRAIN] Epoch[1](3006/114412); Loss: 0.059262; Backpropagation: 0.2973 sec; Batch: 2.0849 sec
0.1005 0.0851 0.0689 0.0633 0.0592 0.0566 0.0545 0.0534 0.0523 0.0517 0.0512 0.0508 0.0505 0.0503 0.0500 0.0498 

[TRAIN] Epoch[1](3007/114412); Loss: 0.077619; Backpropagation: 0.2950 sec; Batch: 2.1263 sec
0.1489 0.1192 0.1032 0.0931 0.0827 0.0759 0.0712 0.0674 0.0649 0.0628 0.0612 0.0597 0.0589 0.0580 0.0575 0.0571 

[TRAIN] Epoch[1](3008/114412); Loss: 0.100439; Backpropagation: 0.2914 sec; Batch: 2.0776 sec
0.1729 0.1482 0.1216 0.1139 0.1020 0.0962 0.0911 0.0890 0.0875 0.0861 0.0848 0.0840 0.0832 0.0827 0.0821 0.0818 

[TRAIN] Epoch[1](3009/114412); Loss: 0.073001; Backpropagation: 0.2910 sec; Batch: 2.1207 sec
0.1524 0.1097 0.0896 0.0821 0.0712 0.0673 0.0646 0.0624 0.0610 0.0600 0.0593 0.0585 0.0580 0.0576 0.0573 0.0570 

[TRAIN] Epoch[1](3010/114412); Loss: 0.077019; Backpropagation: 0.2910 sec; Batch: 2.0776 sec
0.1652 0.1353 0.0947 0.0854 0.0781 0.0701 0.0666 0.0640 0.0622 0.0609 0.0599 0.0591 0.0586 0.0577 0.0573 0.0570 

[TRAIN] Epoch[1](3011/114412); Loss: 0.070329; Backpropagation: 0.2913 sec; Batch: 2.1340 sec
0.1233 0.1002 0.0814 0.0751 0.0698 0.0669 0.0652 0.0633 0.0619 0.0611 0.0606 0.0601 0.0596 0.0592 0.0589 0.0588 

[TRAIN] Epoch[1](3012/114412); Loss: 0.071046; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1620 0.1333 0.0935 0.0804 0.0698 0.0631 0.0596 0.0573 0.0553 0.0540 0.0529 0.0520 0.0515 0.0510 0.0507 0.0504 

[TRAIN] Epoch[1](3013/114412); Loss: 0.063228; Backpropagation: 0.2912 sec; Batch: 2.1142 sec
0.1334 0.1050 0.0754 0.0656 0.0594 0.0581 0.0549 0.0534 0.0526 0.0515 0.0511 0.0507 0.0503 0.0502 0.0501 0.0500 

[TRAIN] Epoch[1](3014/114412); Loss: 0.063743; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1231 0.0994 0.0815 0.0738 0.0643 0.0601 0.0566 0.0546 0.0530 0.0522 0.0514 0.0509 0.0503 0.0499 0.0495 0.0492 

[TRAIN] Epoch[1](3015/114412); Loss: 0.074986; Backpropagation: 0.2920 sec; Batch: 2.0788 sec
0.1595 0.1407 0.0964 0.0874 0.0710 0.0668 0.0635 0.0610 0.0595 0.0583 0.0576 0.0567 0.0561 0.0555 0.0551 0.0546 

[TRAIN] Epoch[1](3016/114412); Loss: 0.066797; Backpropagation: 0.2931 sec; Batch: 2.1045 sec
0.1762 0.1252 0.0890 0.0719 0.0627 0.0569 0.0544 0.0517 0.0505 0.0493 0.0482 0.0475 0.0468 0.0465 0.0461 0.0458 

[TRAIN] Epoch[1](3017/114412); Loss: 0.047822; Backpropagation: 0.2912 sec; Batch: 2.0958 sec
0.1176 0.0903 0.0674 0.0594 0.0510 0.0434 0.0402 0.0373 0.0355 0.0348 0.0330 0.0320 0.0313 0.0310 0.0306 0.0303 

[TRAIN] Epoch[1](3018/114412); Loss: 0.062694; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1224 0.1053 0.0822 0.0730 0.0649 0.0610 0.0559 0.0533 0.0514 0.0498 0.0487 0.0481 0.0475 0.0469 0.0465 0.0462 

[TRAIN] Epoch[1](3019/114412); Loss: 0.051084; Backpropagation: 0.2933 sec; Batch: 2.1216 sec
0.1357 0.0979 0.0639 0.0551 0.0491 0.0448 0.0416 0.0399 0.0385 0.0374 0.0366 0.0361 0.0356 0.0352 0.0351 0.0349 

[TRAIN] Epoch[1](3020/114412); Loss: 0.070959; Backpropagation: 0.2908 sec; Batch: 2.0780 sec
0.1522 0.1328 0.0959 0.0879 0.0684 0.0646 0.0617 0.0580 0.0550 0.0537 0.0527 0.0519 0.0510 0.0503 0.0499 0.0495 

[TRAIN] Epoch[1](3021/114412); Loss: 0.081359; Backpropagation: 0.2912 sec; Batch: 2.1256 sec
0.1246 0.1098 0.0926 0.0850 0.0808 0.0786 0.0776 0.0757 0.0744 0.0734 0.0727 0.0719 0.0716 0.0712 0.0710 0.0708 

[TRAIN] Epoch[1](3022/114412); Loss: 0.075708; Backpropagation: 0.2916 sec; Batch: 2.1174 sec
0.1405 0.1139 0.0903 0.0808 0.0763 0.0726 0.0698 0.0677 0.0657 0.0645 0.0633 0.0624 0.0618 0.0609 0.0605 0.0601 

[TRAIN] Epoch[1](3023/114412); Loss: 0.061041; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1428 0.1166 0.0806 0.0683 0.0609 0.0532 0.0507 0.0492 0.0477 0.0461 0.0450 0.0445 0.0436 0.0430 0.0424 0.0421 

[TRAIN] Epoch[1](3024/114412); Loss: 0.083227; Backpropagation: 0.2910 sec; Batch: 2.1184 sec
0.1491 0.1364 0.1012 0.0917 0.0840 0.0792 0.0757 0.0730 0.0713 0.0697 0.0685 0.0677 0.0668 0.0663 0.0658 0.0654 

[TRAIN] Epoch[1](3025/114412); Loss: 0.054914; Backpropagation: 0.2931 sec; Batch: 2.1195 sec
0.1412 0.1281 0.0780 0.0674 0.0525 0.0483 0.0430 0.0411 0.0386 0.0369 0.0356 0.0347 0.0340 0.0334 0.0331 0.0328 

[TRAIN] Epoch[1](3026/114412); Loss: 0.067379; Backpropagation: 0.2917 sec; Batch: 2.1193 sec
0.1408 0.1206 0.0820 0.0701 0.0646 0.0601 0.0583 0.0565 0.0555 0.0545 0.0538 0.0532 0.0527 0.0523 0.0517 0.0514 

[TRAIN] Epoch[1](3027/114412); Loss: 0.065188; Backpropagation: 0.2906 sec; Batch: 2.0781 sec
0.1078 0.0966 0.0808 0.0742 0.0676 0.0642 0.0605 0.0578 0.0562 0.0556 0.0548 0.0541 0.0536 0.0534 0.0531 0.0528 

[TRAIN] Epoch[1](3028/114412); Loss: 0.062709; Backpropagation: 0.2903 sec; Batch: 2.1248 sec
0.1217 0.1026 0.0761 0.0675 0.0629 0.0589 0.0556 0.0540 0.0529 0.0520 0.0512 0.0506 0.0500 0.0495 0.0491 0.0488 

[TRAIN] Epoch[1](3029/114412); Loss: 0.062497; Backpropagation: 0.2931 sec; Batch: 2.0924 sec
0.1355 0.1187 0.0790 0.0694 0.0609 0.0564 0.0542 0.0515 0.0497 0.0484 0.0474 0.0466 0.0461 0.0457 0.0454 0.0451 

[TRAIN] Epoch[1](3030/114412); Loss: 0.081957; Backpropagation: 0.2929 sec; Batch: 2.1173 sec
0.1536 0.1368 0.1064 0.0974 0.0844 0.0790 0.0741 0.0708 0.0680 0.0658 0.0645 0.0636 0.0627 0.0619 0.0614 0.0609 

[TRAIN] Epoch[1](3031/114412); Loss: 0.074868; Backpropagation: 0.2954 sec; Batch: 2.1239 sec
0.1373 0.1224 0.0976 0.0903 0.0801 0.0743 0.0689 0.0657 0.0626 0.0608 0.0590 0.0576 0.0563 0.0556 0.0550 0.0545 

[TRAIN] Epoch[1](3032/114412); Loss: 0.077173; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1972 0.1783 0.1110 0.0956 0.0752 0.0654 0.0598 0.0566 0.0542 0.0523 0.0508 0.0492 0.0484 0.0477 0.0469 0.0462 

[TRAIN] Epoch[1](3033/114412); Loss: 0.064091; Backpropagation: 0.2915 sec; Batch: 2.1158 sec
0.1789 0.1651 0.0954 0.0864 0.0586 0.0539 0.0444 0.0422 0.0407 0.0391 0.0383 0.0374 0.0365 0.0362 0.0361 0.0362 

[TRAIN] Epoch[1](3034/114412); Loss: 0.066687; Backpropagation: 0.2914 sec; Batch: 2.1514 sec
0.1253 0.1050 0.0874 0.0775 0.0713 0.0647 0.0613 0.0581 0.0559 0.0542 0.0528 0.0519 0.0512 0.0506 0.0500 0.0496 

[TRAIN] Epoch[1](3035/114412); Loss: 0.066908; Backpropagation: 0.2915 sec; Batch: 2.1080 sec
0.1382 0.1217 0.0888 0.0790 0.0681 0.0623 0.0586 0.0561 0.0542 0.0527 0.0512 0.0495 0.0486 0.0480 0.0470 0.0464 

[TRAIN] Epoch[1](3036/114412); Loss: 0.061141; Backpropagation: 0.2911 sec; Batch: 2.1736 sec
0.1185 0.1005 0.0829 0.0699 0.0646 0.0565 0.0537 0.0519 0.0501 0.0492 0.0482 0.0475 0.0469 0.0463 0.0459 0.0456 

[TRAIN] Epoch[1](3037/114412); Loss: 0.079493; Backpropagation: 0.2918 sec; Batch: 2.3713 sec
0.1660 0.1492 0.1057 0.0929 0.0772 0.0723 0.0685 0.0664 0.0632 0.0617 0.0606 0.0592 0.0582 0.0575 0.0568 0.0565 

[TRAIN] Epoch[1](3038/114412); Loss: 0.084469; Backpropagation: 0.2907 sec; Batch: 2.1128 sec
0.1498 0.1319 0.1032 0.0948 0.0856 0.0814 0.0773 0.0747 0.0730 0.0713 0.0702 0.0691 0.0683 0.0674 0.0670 0.0664 

[TRAIN] Epoch[1](3039/114412); Loss: 0.087429; Backpropagation: 0.2932 sec; Batch: 2.1207 sec
0.1453 0.1351 0.1096 0.1017 0.0911 0.0866 0.0818 0.0784 0.0751 0.0737 0.0723 0.0712 0.0701 0.0695 0.0689 0.0683 

[TRAIN] Epoch[1](3040/114412); Loss: 0.069150; Backpropagation: 0.2931 sec; Batch: 2.1292 sec
0.1320 0.1243 0.0935 0.0833 0.0736 0.0676 0.0642 0.0605 0.0572 0.0550 0.0529 0.0508 0.0492 0.0483 0.0473 0.0466 

[TRAIN] Epoch[1](3041/114412); Loss: 0.072216; Backpropagation: 0.2927 sec; Batch: 2.1198 sec
0.1430 0.1229 0.0970 0.0855 0.0780 0.0705 0.0664 0.0620 0.0596 0.0572 0.0553 0.0537 0.0524 0.0514 0.0507 0.0500 

[TRAIN] Epoch[1](3042/114412); Loss: 0.073407; Backpropagation: 0.2955 sec; Batch: 2.1259 sec
0.1534 0.1366 0.0963 0.0838 0.0717 0.0667 0.0638 0.0621 0.0594 0.0582 0.0557 0.0546 0.0542 0.0532 0.0524 0.0522 

[TRAIN] Epoch[1](3043/114412); Loss: 0.082026; Backpropagation: 0.2931 sec; Batch: 2.1182 sec
0.1421 0.1329 0.1007 0.0913 0.0821 0.0786 0.0746 0.0725 0.0711 0.0693 0.0680 0.0674 0.0665 0.0656 0.0651 0.0647 

[TRAIN] Epoch[1](3044/114412); Loss: 0.096399; Backpropagation: 0.2950 sec; Batch: 2.0835 sec
0.1768 0.1589 0.1280 0.1170 0.0994 0.0923 0.0884 0.0844 0.0816 0.0787 0.0767 0.0749 0.0731 0.0718 0.0705 0.0697 

[TRAIN] Epoch[1](3045/114412); Loss: 0.085520; Backpropagation: 0.2926 sec; Batch: 2.1154 sec
0.1661 0.1479 0.1172 0.0998 0.0828 0.0779 0.0761 0.0732 0.0701 0.0684 0.0671 0.0658 0.0650 0.0642 0.0635 0.0630 

[TRAIN] Epoch[1](3046/114412); Loss: 0.078276; Backpropagation: 0.2902 sec; Batch: 2.1153 sec
0.1798 0.1642 0.0984 0.0870 0.0740 0.0700 0.0669 0.0632 0.0609 0.0589 0.0564 0.0557 0.0550 0.0544 0.0540 0.0536 

[TRAIN] Epoch[1](3047/114412); Loss: 0.063648; Backpropagation: 0.2911 sec; Batch: 2.1131 sec
0.1345 0.1160 0.0916 0.0798 0.0671 0.0601 0.0543 0.0514 0.0491 0.0476 0.0465 0.0454 0.0446 0.0439 0.0434 0.0430 

[TRAIN] Epoch[1](3048/114412); Loss: 0.080065; Backpropagation: 0.2927 sec; Batch: 2.1200 sec
0.1496 0.1245 0.0987 0.0919 0.0823 0.0774 0.0738 0.0703 0.0683 0.0666 0.0651 0.0640 0.0631 0.0624 0.0618 0.0613 

[TRAIN] Epoch[1](3049/114412); Loss: 0.075112; Backpropagation: 0.2930 sec; Batch: 2.0806 sec
0.1811 0.1596 0.1028 0.0868 0.0735 0.0677 0.0619 0.0587 0.0558 0.0544 0.0525 0.0513 0.0502 0.0493 0.0484 0.0477 

[TRAIN] Epoch[1](3050/114412); Loss: 0.070896; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1334 0.1204 0.0854 0.0795 0.0710 0.0684 0.0652 0.0629 0.0602 0.0586 0.0572 0.0562 0.0550 0.0542 0.0537 0.0530 

[TRAIN] Epoch[1](3051/114412); Loss: 0.067438; Backpropagation: 0.2909 sec; Batch: 2.1147 sec
0.1245 0.1103 0.0751 0.0686 0.0651 0.0629 0.0611 0.0593 0.0581 0.0574 0.0569 0.0564 0.0561 0.0559 0.0557 0.0556 

[TRAIN] Epoch[1](3052/114412); Loss: 0.095484; Backpropagation: 0.2913 sec; Batch: 2.1186 sec
0.1695 0.1437 0.1203 0.1083 0.0994 0.0939 0.0884 0.0851 0.0826 0.0804 0.0785 0.0774 0.0764 0.0754 0.0745 0.0740 

[TRAIN] Epoch[1](3053/114412); Loss: 0.092268; Backpropagation: 0.2910 sec; Batch: 2.1241 sec
0.1743 0.1564 0.1183 0.1061 0.0900 0.0862 0.0824 0.0798 0.0776 0.0756 0.0740 0.0728 0.0716 0.0710 0.0704 0.0697 

[TRAIN] Epoch[1](3054/114412); Loss: 0.072598; Backpropagation: 0.2933 sec; Batch: 2.1159 sec
0.1587 0.1380 0.0908 0.0724 0.0686 0.0649 0.0623 0.0600 0.0585 0.0580 0.0563 0.0559 0.0550 0.0544 0.0540 0.0536 

[TRAIN] Epoch[1](3055/114412); Loss: 0.101299; Backpropagation: 0.2930 sec; Batch: 2.1213 sec
0.1768 0.1553 0.1293 0.1163 0.1050 0.1001 0.0929 0.0897 0.0869 0.0847 0.0833 0.0821 0.0805 0.0800 0.0794 0.0786 

[TRAIN] Epoch[1](3056/114412); Loss: 0.092258; Backpropagation: 0.2904 sec; Batch: 2.0760 sec
0.1672 0.1479 0.1125 0.1026 0.0942 0.0892 0.0849 0.0817 0.0788 0.0772 0.0757 0.0744 0.0733 0.0727 0.0722 0.0718 

[TRAIN] Epoch[1](3057/114412); Loss: 0.066239; Backpropagation: 0.2911 sec; Batch: 2.1144 sec
0.1377 0.1174 0.0856 0.0736 0.0641 0.0612 0.0570 0.0548 0.0537 0.0525 0.0516 0.0509 0.0505 0.0500 0.0497 0.0497 

[TRAIN] Epoch[1](3058/114412); Loss: 0.074183; Backpropagation: 0.2927 sec; Batch: 2.1187 sec
0.1691 0.1502 0.1090 0.0857 0.0697 0.0669 0.0622 0.0587 0.0565 0.0538 0.0524 0.0515 0.0508 0.0504 0.0501 0.0497 

[TRAIN] Epoch[1](3059/114412); Loss: 0.096155; Backpropagation: 0.2910 sec; Batch: 2.1163 sec
0.1608 0.1460 0.1181 0.1093 0.0988 0.0935 0.0882 0.0859 0.0839 0.0822 0.0810 0.0796 0.0788 0.0781 0.0774 0.0770 

[TRAIN] Epoch[1](3060/114412); Loss: 0.059988; Backpropagation: 0.2909 sec; Batch: 2.1099 sec
0.1389 0.1269 0.0876 0.0751 0.0614 0.0531 0.0501 0.0471 0.0438 0.0424 0.0411 0.0398 0.0389 0.0383 0.0379 0.0375 

[TRAIN] Epoch[1](3061/114412); Loss: 0.057440; Backpropagation: 0.2931 sec; Batch: 2.0809 sec
0.1239 0.1101 0.0756 0.0649 0.0537 0.0532 0.0504 0.0474 0.0455 0.0440 0.0430 0.0424 0.0418 0.0412 0.0410 0.0408 

[TRAIN] Epoch[1](3062/114412); Loss: 0.078140; Backpropagation: 0.2914 sec; Batch: 2.1192 sec
0.1516 0.1396 0.1008 0.0849 0.0752 0.0715 0.0672 0.0665 0.0649 0.0632 0.0622 0.0617 0.0609 0.0603 0.0600 0.0597 

[TRAIN] Epoch[1](3063/114412); Loss: 0.069307; Backpropagation: 0.2928 sec; Batch: 2.1226 sec
0.1216 0.1082 0.0919 0.0825 0.0723 0.0652 0.0628 0.0611 0.0586 0.0574 0.0562 0.0554 0.0545 0.0540 0.0537 0.0536 

[TRAIN] Epoch[1](3064/114412); Loss: 0.064472; Backpropagation: 0.2952 sec; Batch: 2.1112 sec
0.1504 0.1356 0.0880 0.0777 0.0595 0.0559 0.0522 0.0488 0.0478 0.0471 0.0460 0.0452 0.0449 0.0445 0.0441 0.0439 

[TRAIN] Epoch[1](3065/114412); Loss: 0.070152; Backpropagation: 0.2931 sec; Batch: 2.0792 sec
0.1568 0.1433 0.0926 0.0787 0.0681 0.0621 0.0578 0.0552 0.0531 0.0522 0.0515 0.0507 0.0502 0.0501 0.0501 0.0499 

[TRAIN] Epoch[1](3066/114412); Loss: 0.082820; Backpropagation: 0.2953 sec; Batch: 2.1087 sec
0.1367 0.1255 0.1010 0.0918 0.0832 0.0810 0.0771 0.0742 0.0730 0.0711 0.0703 0.0694 0.0686 0.0678 0.0673 0.0669 

[TRAIN] Epoch[1](3067/114412); Loss: 0.075735; Backpropagation: 0.2952 sec; Batch: 2.1212 sec
0.1402 0.1249 0.0982 0.0873 0.0764 0.0717 0.0682 0.0652 0.0636 0.0621 0.0609 0.0600 0.0592 0.0586 0.0578 0.0575 

[TRAIN] Epoch[1](3068/114412); Loss: 0.055898; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.1049 0.1000 0.0702 0.0633 0.0585 0.0536 0.0487 0.0498 0.0469 0.0449 0.0438 0.0430 0.0424 0.0418 0.0414 0.0411 

[TRAIN] Epoch[1](3069/114412); Loss: 0.057218; Backpropagation: 0.2925 sec; Batch: 2.0969 sec
0.1552 0.1254 0.0767 0.0609 0.0532 0.0476 0.0443 0.0441 0.0408 0.0395 0.0390 0.0384 0.0382 0.0376 0.0374 0.0372 

[TRAIN] Epoch[1](3070/114412); Loss: 0.077639; Backpropagation: 0.2942 sec; Batch: 2.1195 sec
0.1434 0.1337 0.0921 0.0834 0.0789 0.0741 0.0692 0.0678 0.0659 0.0645 0.0634 0.0623 0.0615 0.0612 0.0606 0.0604 

[TRAIN] Epoch[1](3071/114412); Loss: 0.079914; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1697 0.1478 0.0915 0.0881 0.0797 0.0728 0.0667 0.0652 0.0644 0.0639 0.0626 0.0619 0.0613 0.0611 0.0610 0.0609 

[TRAIN] Epoch[1](3072/114412); Loss: 0.059589; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1493 0.1314 0.0763 0.0626 0.0550 0.0532 0.0493 0.0467 0.0445 0.0431 0.0420 0.0414 0.0405 0.0398 0.0393 0.0390 

[TRAIN] Epoch[1](3073/114412); Loss: 0.103186; Backpropagation: 0.2930 sec; Batch: 2.1189 sec
0.1837 0.1775 0.1403 0.1294 0.1123 0.1019 0.0879 0.0841 0.0828 0.0821 0.0803 0.0790 0.0780 0.0778 0.0771 0.0766 

[TRAIN] Epoch[1](3074/114412); Loss: 0.066325; Backpropagation: 0.2918 sec; Batch: 2.1167 sec
0.1246 0.1119 0.0844 0.0773 0.0675 0.0629 0.0589 0.0570 0.0553 0.0541 0.0529 0.0518 0.0513 0.0508 0.0504 0.0502 

[TRAIN] Epoch[1](3075/114412); Loss: 0.084154; Backpropagation: 0.2909 sec; Batch: 2.1214 sec
0.1539 0.1430 0.1116 0.1008 0.0888 0.0835 0.0766 0.0747 0.0706 0.0677 0.0654 0.0637 0.0629 0.0619 0.0610 0.0604 

[TRAIN] Epoch[1](3076/114412); Loss: 0.052653; Backpropagation: 0.2954 sec; Batch: 2.1255 sec
0.1062 0.0984 0.0691 0.0603 0.0514 0.0474 0.0445 0.0427 0.0418 0.0409 0.0406 0.0403 0.0399 0.0397 0.0396 0.0396 

[TRAIN] Epoch[1](3077/114412); Loss: 0.093143; Backpropagation: 0.2927 sec; Batch: 2.1178 sec
0.1770 0.1712 0.1353 0.1208 0.1028 0.0942 0.0811 0.0747 0.0709 0.0695 0.0680 0.0670 0.0656 0.0651 0.0640 0.0632 

[TRAIN] Epoch[1](3078/114412); Loss: 0.067952; Backpropagation: 0.2915 sec; Batch: 2.0780 sec
0.1115 0.1083 0.0849 0.0757 0.0685 0.0657 0.0623 0.0605 0.0593 0.0577 0.0567 0.0562 0.0555 0.0551 0.0549 0.0544 

[TRAIN] Epoch[1](3079/114412); Loss: 0.089630; Backpropagation: 0.2912 sec; Batch: 2.1419 sec
0.1495 0.1406 0.1140 0.1021 0.0931 0.0882 0.0845 0.0812 0.0792 0.0768 0.0742 0.0725 0.0710 0.0700 0.0689 0.0681 

[TRAIN] Epoch[1](3080/114412); Loss: 0.084484; Backpropagation: 0.2904 sec; Batch: 2.0779 sec
0.1540 0.1449 0.1122 0.1036 0.0880 0.0819 0.0760 0.0735 0.0700 0.0674 0.0658 0.0642 0.0634 0.0627 0.0622 0.0619 

[TRAIN] Epoch[1](3081/114412); Loss: 0.084399; Backpropagation: 0.2936 sec; Batch: 2.1198 sec
0.1510 0.1432 0.1073 0.0957 0.0850 0.0807 0.0766 0.0741 0.0718 0.0703 0.0687 0.0672 0.0661 0.0651 0.0641 0.0636 

[TRAIN] Epoch[1](3082/114412); Loss: 0.086063; Backpropagation: 0.2934 sec; Batch: 2.1181 sec
0.1826 0.1765 0.1316 0.1167 0.0929 0.0819 0.0678 0.0651 0.0644 0.0606 0.0590 0.0586 0.0563 0.0550 0.0545 0.0535 

[TRAIN] Epoch[1](3083/114412); Loss: 0.088375; Backpropagation: 0.2953 sec; Batch: 2.1196 sec
0.1545 0.1451 0.1230 0.1109 0.1002 0.0900 0.0854 0.0796 0.0742 0.0702 0.0678 0.0652 0.0635 0.0622 0.0615 0.0605 

[TRAIN] Epoch[1](3084/114412); Loss: 0.083057; Backpropagation: 0.2931 sec; Batch: 2.1227 sec
0.1603 0.1501 0.1067 0.0978 0.0849 0.0781 0.0735 0.0718 0.0676 0.0654 0.0644 0.0630 0.0622 0.0616 0.0610 0.0605 

[TRAIN] Epoch[1](3085/114412); Loss: 0.073987; Backpropagation: 0.2908 sec; Batch: 2.1191 sec
0.1532 0.1423 0.0866 0.0796 0.0753 0.0687 0.0666 0.0640 0.0612 0.0596 0.0575 0.0560 0.0545 0.0536 0.0529 0.0522 

[TRAIN] Epoch[1](3086/114412); Loss: 0.069413; Backpropagation: 0.2919 sec; Batch: 2.1196 sec
0.1588 0.1545 0.0870 0.0749 0.0723 0.0649 0.0579 0.0571 0.0529 0.0507 0.0488 0.0480 0.0466 0.0457 0.0454 0.0449 

[TRAIN] Epoch[1](3087/114412); Loss: 0.084734; Backpropagation: 0.2916 sec; Batch: 2.1198 sec
0.1402 0.1336 0.1094 0.0991 0.0891 0.0838 0.0794 0.0761 0.0721 0.0705 0.0693 0.0680 0.0673 0.0664 0.0659 0.0655 

[TRAIN] Epoch[1](3088/114412); Loss: 0.072093; Backpropagation: 0.2911 sec; Batch: 2.0775 sec
0.1437 0.1378 0.1008 0.0906 0.0728 0.0681 0.0624 0.0593 0.0572 0.0549 0.0532 0.0520 0.0510 0.0505 0.0498 0.0494 

[TRAIN] Epoch[1](3089/114412); Loss: 0.078281; Backpropagation: 0.2901 sec; Batch: 2.0923 sec
0.1527 0.1451 0.1153 0.1028 0.0863 0.0777 0.0709 0.0658 0.0610 0.0577 0.0555 0.0542 0.0530 0.0521 0.0516 0.0508 

[TRAIN] Epoch[1](3090/114412); Loss: 0.094117; Backpropagation: 0.2908 sec; Batch: 2.1016 sec
0.1473 0.1404 0.1178 0.1059 0.0989 0.0930 0.0890 0.0854 0.0826 0.0809 0.0790 0.0783 0.0777 0.0769 0.0766 0.0762 

[TRAIN] Epoch[1](3091/114412); Loss: 0.105617; Backpropagation: 0.2950 sec; Batch: 2.1217 sec
0.1921 0.1845 0.1486 0.1304 0.1144 0.1043 0.0961 0.0915 0.0866 0.0836 0.0809 0.0786 0.0765 0.0750 0.0738 0.0730 

[TRAIN] Epoch[1](3092/114412); Loss: 0.092207; Backpropagation: 0.2930 sec; Batch: 2.1183 sec
0.1721 0.1666 0.1274 0.1140 0.0962 0.0884 0.0802 0.0770 0.0741 0.0726 0.0705 0.0692 0.0679 0.0671 0.0664 0.0658 

[TRAIN] Epoch[1](3093/114412); Loss: 0.099737; Backpropagation: 0.2949 sec; Batch: 2.1210 sec
0.1540 0.1487 0.1212 0.1128 0.1058 0.0995 0.0957 0.0934 0.0890 0.0866 0.0849 0.0832 0.0817 0.0807 0.0797 0.0789 

[TRAIN] Epoch[1](3094/114412); Loss: 0.065770; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1294 0.1198 0.0927 0.0821 0.0721 0.0655 0.0605 0.0560 0.0529 0.0505 0.0481 0.0465 0.0455 0.0443 0.0435 0.0428 

[TRAIN] Epoch[1](3095/114412); Loss: 0.064689; Backpropagation: 0.2910 sec; Batch: 2.1151 sec
0.1321 0.1265 0.0891 0.0771 0.0645 0.0608 0.0567 0.0547 0.0510 0.0493 0.0474 0.0463 0.0457 0.0451 0.0446 0.0442 

[TRAIN] Epoch[1](3096/114412); Loss: 0.055259; Backpropagation: 0.2939 sec; Batch: 2.1164 sec
0.1331 0.1242 0.0803 0.0657 0.0567 0.0520 0.0469 0.0431 0.0399 0.0380 0.0362 0.0351 0.0341 0.0333 0.0329 0.0327 

[TRAIN] Epoch[1](3097/114412); Loss: 0.077935; Backpropagation: 0.2934 sec; Batch: 2.1288 sec
0.1545 0.1487 0.1147 0.0968 0.0779 0.0700 0.0660 0.0638 0.0607 0.0592 0.0576 0.0564 0.0559 0.0554 0.0548 0.0545 

[TRAIN] Epoch[1](3098/114412); Loss: 0.075453; Backpropagation: 0.2910 sec; Batch: 2.0937 sec
0.1321 0.1260 0.0982 0.0868 0.0775 0.0732 0.0693 0.0659 0.0637 0.0622 0.0608 0.0597 0.0590 0.0583 0.0576 0.0569 

[TRAIN] Epoch[1](3099/114412); Loss: 0.076326; Backpropagation: 0.2911 sec; Batch: 2.1360 sec
0.1657 0.1590 0.1247 0.1109 0.0865 0.0730 0.0656 0.0583 0.0542 0.0507 0.0489 0.0472 0.0458 0.0442 0.0435 0.0429 

[TRAIN] Epoch[1](3100/114412); Loss: 0.079092; Backpropagation: 0.2914 sec; Batch: 2.1107 sec
0.1389 0.1317 0.0992 0.0908 0.0826 0.0761 0.0711 0.0691 0.0668 0.0651 0.0642 0.0632 0.0622 0.0618 0.0615 0.0611 

[TRAIN] Epoch[1](3101/114412); Loss: 0.067119; Backpropagation: 0.2911 sec; Batch: 2.1522 sec
0.1204 0.1145 0.0851 0.0789 0.0701 0.0665 0.0619 0.0590 0.0570 0.0551 0.0535 0.0521 0.0508 0.0504 0.0495 0.0491 

[TRAIN] Epoch[1](3102/114412); Loss: 0.064278; Backpropagation: 0.2925 sec; Batch: 2.0927 sec
0.1250 0.1201 0.0943 0.0767 0.0695 0.0628 0.0563 0.0541 0.0517 0.0492 0.0476 0.0459 0.0449 0.0440 0.0433 0.0429 

[TRAIN] Epoch[1](3103/114412); Loss: 0.079158; Backpropagation: 0.2911 sec; Batch: 2.1199 sec
0.1620 0.1498 0.1210 0.1003 0.0858 0.0743 0.0678 0.0633 0.0602 0.0583 0.0562 0.0551 0.0542 0.0533 0.0528 0.0522 

[TRAIN] Epoch[1](3104/114412); Loss: 0.077037; Backpropagation: 0.2907 sec; Batch: 2.1234 sec
0.1328 0.1278 0.0997 0.0932 0.0807 0.0747 0.0700 0.0683 0.0647 0.0627 0.0614 0.0606 0.0598 0.0592 0.0587 0.0582 

[TRAIN] Epoch[1](3105/114412); Loss: 0.065308; Backpropagation: 0.2952 sec; Batch: 2.1210 sec
0.1137 0.1104 0.0845 0.0738 0.0660 0.0622 0.0587 0.0569 0.0552 0.0540 0.0529 0.0522 0.0516 0.0512 0.0510 0.0506 

[TRAIN] Epoch[1](3106/114412); Loss: 0.073761; Backpropagation: 0.2930 sec; Batch: 2.1147 sec
0.1625 0.1531 0.1174 0.1022 0.0804 0.0696 0.0573 0.0545 0.0522 0.0513 0.0491 0.0477 0.0468 0.0459 0.0452 0.0449 

[TRAIN] Epoch[1](3107/114412); Loss: 0.059261; Backpropagation: 0.2926 sec; Batch: 2.1173 sec
0.1226 0.1188 0.0875 0.0703 0.0605 0.0563 0.0519 0.0488 0.0460 0.0437 0.0424 0.0412 0.0403 0.0398 0.0393 0.0389 

[TRAIN] Epoch[1](3108/114412); Loss: 0.060799; Backpropagation: 0.2908 sec; Batch: 2.1160 sec
0.1245 0.1195 0.0855 0.0750 0.0606 0.0552 0.0534 0.0498 0.0479 0.0461 0.0445 0.0433 0.0426 0.0421 0.0416 0.0412 

[TRAIN] Epoch[1](3109/114412); Loss: 0.070371; Backpropagation: 0.2911 sec; Batch: 2.1229 sec
0.1292 0.1211 0.1016 0.0849 0.0714 0.0662 0.0626 0.0601 0.0574 0.0559 0.0546 0.0534 0.0526 0.0520 0.0516 0.0513 

[TRAIN] Epoch[1](3110/114412); Loss: 0.060821; Backpropagation: 0.2910 sec; Batch: 2.0787 sec
0.1312 0.1263 0.0900 0.0760 0.0615 0.0554 0.0496 0.0479 0.0452 0.0438 0.0428 0.0418 0.0411 0.0406 0.0401 0.0398 

[TRAIN] Epoch[1](3111/114412); Loss: 0.055435; Backpropagation: 0.2908 sec; Batch: 2.1185 sec
0.1207 0.1145 0.0727 0.0638 0.0544 0.0515 0.0473 0.0452 0.0432 0.0415 0.0403 0.0396 0.0386 0.0383 0.0380 0.0375 

[TRAIN] Epoch[1](3112/114412); Loss: 0.073802; Backpropagation: 0.2926 sec; Batch: 2.1216 sec
0.1345 0.1261 0.1002 0.0874 0.0779 0.0715 0.0667 0.0630 0.0610 0.0590 0.0576 0.0567 0.0557 0.0550 0.0546 0.0541 

[TRAIN] Epoch[1](3113/114412); Loss: 0.069917; Backpropagation: 0.2930 sec; Batch: 2.1188 sec
0.1479 0.1425 0.1115 0.0924 0.0716 0.0609 0.0556 0.0553 0.0532 0.0495 0.0481 0.0472 0.0464 0.0459 0.0455 0.0451 

[TRAIN] Epoch[1](3114/114412); Loss: 0.064116; Backpropagation: 0.2929 sec; Batch: 2.0801 sec
0.1380 0.1303 0.0893 0.0797 0.0638 0.0582 0.0532 0.0504 0.0487 0.0474 0.0464 0.0453 0.0446 0.0440 0.0435 0.0431 

[TRAIN] Epoch[1](3115/114412); Loss: 0.076991; Backpropagation: 0.2908 sec; Batch: 2.1206 sec
0.1650 0.1514 0.1182 0.0954 0.0795 0.0714 0.0645 0.0588 0.0572 0.0553 0.0544 0.0533 0.0524 0.0520 0.0517 0.0514 

[TRAIN] Epoch[1](3116/114412); Loss: 0.076478; Backpropagation: 0.2912 sec; Batch: 2.1755 sec
0.1559 0.1495 0.1032 0.0898 0.0728 0.0689 0.0644 0.0617 0.0602 0.0591 0.0579 0.0570 0.0565 0.0560 0.0556 0.0552 

[TRAIN] Epoch[1](3117/114412); Loss: 0.081235; Backpropagation: 0.2910 sec; Batch: 2.1191 sec
0.1575 0.1518 0.1129 0.1001 0.0779 0.0722 0.0713 0.0656 0.0641 0.0641 0.0621 0.0609 0.0604 0.0599 0.0596 0.0595 

[TRAIN] Epoch[1](3118/114412); Loss: 0.083095; Backpropagation: 0.2929 sec; Batch: 2.0802 sec
0.1585 0.1510 0.1113 0.0971 0.0824 0.0765 0.0722 0.0699 0.0678 0.0655 0.0643 0.0636 0.0630 0.0625 0.0621 0.0617 

[TRAIN] Epoch[1](3119/114412); Loss: 0.075226; Backpropagation: 0.2909 sec; Batch: 2.0788 sec
0.1389 0.1278 0.0980 0.0874 0.0766 0.0713 0.0674 0.0651 0.0629 0.0609 0.0599 0.0587 0.0579 0.0574 0.0570 0.0565 

[TRAIN] Epoch[1](3120/114412); Loss: 0.068443; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1264 0.1212 0.0906 0.0833 0.0702 0.0657 0.0601 0.0573 0.0555 0.0542 0.0532 0.0524 0.0519 0.0514 0.0510 0.0507 

[TRAIN] Epoch[1](3121/114412); Loss: 0.057166; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1480 0.1401 0.0949 0.0795 0.0543 0.0470 0.0430 0.0396 0.0368 0.0356 0.0345 0.0333 0.0327 0.0321 0.0318 0.0313 

[TRAIN] Epoch[1](3122/114412); Loss: 0.059471; Backpropagation: 0.2907 sec; Batch: 2.1183 sec
0.1317 0.1201 0.0860 0.0737 0.0621 0.0556 0.0489 0.0456 0.0437 0.0426 0.0416 0.0410 0.0402 0.0398 0.0395 0.0393 

[TRAIN] Epoch[1](3123/114412); Loss: 0.059431; Backpropagation: 0.2917 sec; Batch: 2.1183 sec
0.1133 0.1066 0.0772 0.0660 0.0581 0.0544 0.0516 0.0497 0.0483 0.0476 0.0473 0.0467 0.0462 0.0462 0.0458 0.0458 

[TRAIN] Epoch[1](3124/114412); Loss: 0.057144; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.0943 0.0872 0.0749 0.0665 0.0577 0.0553 0.0524 0.0506 0.0494 0.0483 0.0477 0.0469 0.0465 0.0460 0.0455 0.0452 

[TRAIN] Epoch[1](3125/114412); Loss: 0.070797; Backpropagation: 0.2904 sec; Batch: 2.1203 sec
0.1325 0.1268 0.0984 0.0853 0.0707 0.0651 0.0609 0.0588 0.0563 0.0554 0.0545 0.0541 0.0537 0.0535 0.0534 0.0533 

[TRAIN] Epoch[1](3126/114412); Loss: 0.083436; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1345 0.1293 0.1077 0.0975 0.0869 0.0812 0.0765 0.0739 0.0721 0.0703 0.0693 0.0684 0.0676 0.0671 0.0667 0.0662 

[TRAIN] Epoch[1](3127/114412); Loss: 0.081450; Backpropagation: 0.2909 sec; Batch: 2.1181 sec
0.1719 0.1654 0.1195 0.1040 0.0882 0.0779 0.0691 0.0643 0.0602 0.0580 0.0568 0.0554 0.0542 0.0533 0.0527 0.0522 

[TRAIN] Epoch[1](3128/114412); Loss: 0.085149; Backpropagation: 0.2912 sec; Batch: 2.1134 sec
0.1254 0.1216 0.1012 0.0918 0.0865 0.0831 0.0801 0.0785 0.0770 0.0760 0.0750 0.0742 0.0736 0.0731 0.0728 0.0726 

[TRAIN] Epoch[1](3129/114412); Loss: 0.072743; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1415 0.1289 0.1012 0.0859 0.0744 0.0703 0.0666 0.0636 0.0609 0.0579 0.0565 0.0543 0.0529 0.0505 0.0498 0.0487 

[TRAIN] Epoch[1](3130/114412); Loss: 0.089759; Backpropagation: 0.2926 sec; Batch: 2.1182 sec
0.1813 0.1734 0.1424 0.1179 0.0963 0.0868 0.0782 0.0715 0.0674 0.0644 0.0626 0.0608 0.0594 0.0586 0.0579 0.0573 

[TRAIN] Epoch[1](3131/114412); Loss: 0.055444; Backpropagation: 0.2904 sec; Batch: 2.1197 sec
0.0996 0.0955 0.0693 0.0660 0.0577 0.0539 0.0505 0.0480 0.0461 0.0450 0.0442 0.0433 0.0425 0.0421 0.0418 0.0414 

[TRAIN] Epoch[1](3132/114412); Loss: 0.065604; Backpropagation: 0.2903 sec; Batch: 2.1172 sec
0.1431 0.1356 0.0920 0.0793 0.0686 0.0624 0.0585 0.0543 0.0509 0.0482 0.0461 0.0445 0.0429 0.0418 0.0411 0.0404 

[TRAIN] Epoch[1](3133/114412); Loss: 0.058319; Backpropagation: 0.2912 sec; Batch: 2.1201 sec
0.1155 0.1091 0.0745 0.0655 0.0594 0.0549 0.0517 0.0490 0.0474 0.0458 0.0448 0.0440 0.0434 0.0430 0.0426 0.0424 

[TRAIN] Epoch[1](3134/114412); Loss: 0.077484; Backpropagation: 0.2910 sec; Batch: 2.1151 sec
0.1289 0.1229 0.0963 0.0864 0.0802 0.0753 0.0704 0.0681 0.0668 0.0656 0.0647 0.0641 0.0633 0.0627 0.0623 0.0618 

[TRAIN] Epoch[1](3135/114412); Loss: 0.050141; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.0947 0.0900 0.0662 0.0597 0.0550 0.0484 0.0462 0.0430 0.0408 0.0393 0.0380 0.0371 0.0365 0.0361 0.0358 0.0356 

[TRAIN] Epoch[1](3136/114412); Loss: 0.058237; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1175 0.1116 0.0829 0.0713 0.0612 0.0570 0.0505 0.0467 0.0454 0.0432 0.0422 0.0415 0.0407 0.0405 0.0399 0.0398 

[TRAIN] Epoch[1](3137/114412); Loss: 0.059881; Backpropagation: 0.2931 sec; Batch: 2.1345 sec
0.1446 0.1395 0.0958 0.0830 0.0564 0.0496 0.0469 0.0415 0.0405 0.0397 0.0381 0.0373 0.0368 0.0364 0.0362 0.0359 

[TRAIN] Epoch[1](3138/114412); Loss: 0.091440; Backpropagation: 0.2912 sec; Batch: 2.1201 sec
0.1865 0.1779 0.1283 0.1100 0.0893 0.0831 0.0773 0.0741 0.0715 0.0695 0.0679 0.0667 0.0660 0.0653 0.0650 0.0647 

[TRAIN] Epoch[1](3139/114412); Loss: 0.064924; Backpropagation: 0.2909 sec; Batch: 2.1183 sec
0.1691 0.1633 0.1039 0.0847 0.0656 0.0567 0.0464 0.0436 0.0420 0.0403 0.0389 0.0379 0.0373 0.0368 0.0364 0.0359 

[TRAIN] Epoch[1](3140/114412); Loss: 0.070738; Backpropagation: 0.2914 sec; Batch: 2.0822 sec
0.1367 0.1323 0.1016 0.0894 0.0724 0.0673 0.0613 0.0583 0.0556 0.0541 0.0525 0.0514 0.0504 0.0498 0.0494 0.0491 

[TRAIN] Epoch[1](3141/114412); Loss: 0.070537; Backpropagation: 0.2909 sec; Batch: 2.0794 sec
0.1573 0.1473 0.1079 0.0951 0.0727 0.0643 0.0569 0.0532 0.0500 0.0490 0.0478 0.0471 0.0460 0.0452 0.0448 0.0441 

[TRAIN] Epoch[1](3142/114412); Loss: 0.081703; Backpropagation: 0.2907 sec; Batch: 2.0773 sec
0.1457 0.1405 0.1103 0.0988 0.0847 0.0792 0.0747 0.0704 0.0674 0.0656 0.0643 0.0628 0.0618 0.0610 0.0603 0.0597 

[TRAIN] Epoch[1](3143/114412); Loss: 0.081373; Backpropagation: 0.2916 sec; Batch: 2.0786 sec
0.1476 0.1439 0.1139 0.1016 0.0870 0.0818 0.0741 0.0700 0.0653 0.0630 0.0612 0.0602 0.0591 0.0583 0.0576 0.0572 

[TRAIN] Epoch[1](3144/114412); Loss: 0.064500; Backpropagation: 0.2907 sec; Batch: 2.1193 sec
0.1681 0.1595 0.1004 0.0818 0.0627 0.0528 0.0491 0.0479 0.0437 0.0411 0.0391 0.0382 0.0376 0.0370 0.0366 0.0363 

[TRAIN] Epoch[1](3145/114412); Loss: 0.098902; Backpropagation: 0.2910 sec; Batch: 2.1148 sec
0.1738 0.1659 0.1341 0.1157 0.0997 0.0918 0.0883 0.0847 0.0825 0.0806 0.0792 0.0784 0.0777 0.0772 0.0766 0.0762 

[TRAIN] Epoch[1](3146/114412); Loss: 0.060960; Backpropagation: 0.2906 sec; Batch: 2.1179 sec
0.1605 0.1523 0.0984 0.0721 0.0572 0.0507 0.0459 0.0426 0.0401 0.0386 0.0376 0.0367 0.0362 0.0358 0.0354 0.0351 

[TRAIN] Epoch[1](3147/114412); Loss: 0.056080; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.1458 0.1361 0.0807 0.0586 0.0502 0.0457 0.0426 0.0410 0.0396 0.0385 0.0378 0.0370 0.0364 0.0361 0.0358 0.0356 

[TRAIN] Epoch[1](3148/114412); Loss: 0.071810; Backpropagation: 0.2904 sec; Batch: 2.1173 sec
0.1310 0.1244 0.0904 0.0805 0.0728 0.0675 0.0638 0.0612 0.0594 0.0585 0.0578 0.0571 0.0567 0.0563 0.0560 0.0557 

[TRAIN] Epoch[1](3149/114412); Loss: 0.089713; Backpropagation: 0.2930 sec; Batch: 2.0971 sec
0.1590 0.1509 0.1164 0.1046 0.0950 0.0879 0.0819 0.0777 0.0752 0.0730 0.0716 0.0701 0.0691 0.0683 0.0677 0.0670 

[TRAIN] Epoch[1](3150/114412); Loss: 0.072376; Backpropagation: 0.2914 sec; Batch: 2.1199 sec
0.1207 0.1163 0.0959 0.0856 0.0784 0.0725 0.0665 0.0636 0.0604 0.0590 0.0581 0.0574 0.0567 0.0561 0.0556 0.0553 

[TRAIN] Epoch[1](3151/114412); Loss: 0.067852; Backpropagation: 0.2916 sec; Batch: 2.0788 sec
0.1305 0.1242 0.1007 0.0871 0.0706 0.0623 0.0585 0.0555 0.0532 0.0517 0.0503 0.0493 0.0485 0.0482 0.0478 0.0473 

[TRAIN] Epoch[1](3152/114412); Loss: 0.055776; Backpropagation: 0.2905 sec; Batch: 2.0783 sec
0.1169 0.1071 0.0734 0.0620 0.0565 0.0537 0.0499 0.0463 0.0447 0.0424 0.0413 0.0406 0.0401 0.0395 0.0391 0.0389 

[TRAIN] Epoch[1](3153/114412); Loss: 0.057020; Backpropagation: 0.2907 sec; Batch: 2.1196 sec
0.1052 0.0997 0.0750 0.0638 0.0565 0.0546 0.0511 0.0492 0.0478 0.0465 0.0455 0.0446 0.0440 0.0434 0.0429 0.0426 

[TRAIN] Epoch[1](3154/114412); Loss: 0.091960; Backpropagation: 0.2910 sec; Batch: 2.0776 sec
0.1616 0.1556 0.1204 0.1074 0.0961 0.0873 0.0817 0.0779 0.0760 0.0746 0.0736 0.0729 0.0722 0.0717 0.0713 0.0710 

[TRAIN] Epoch[1](3155/114412); Loss: 0.073893; Backpropagation: 0.2908 sec; Batch: 2.0932 sec
0.1346 0.1285 0.0942 0.0824 0.0762 0.0704 0.0670 0.0643 0.0624 0.0607 0.0593 0.0582 0.0572 0.0562 0.0556 0.0552 

[TRAIN] Epoch[1](3156/114412); Loss: 0.071603; Backpropagation: 0.2930 sec; Batch: 2.1171 sec
0.1055 0.1033 0.0931 0.0841 0.0751 0.0713 0.0675 0.0652 0.0634 0.0617 0.0605 0.0598 0.0593 0.0589 0.0586 0.0583 

[TRAIN] Epoch[1](3157/114412); Loss: 0.080244; Backpropagation: 0.2955 sec; Batch: 2.1199 sec
0.1545 0.1431 0.1079 0.0901 0.0787 0.0728 0.0700 0.0670 0.0653 0.0645 0.0632 0.0623 0.0617 0.0612 0.0610 0.0606 

[TRAIN] Epoch[1](3158/114412); Loss: 0.095633; Backpropagation: 0.2932 sec; Batch: 2.1225 sec
0.1754 0.1651 0.1253 0.1092 0.0995 0.0925 0.0856 0.0817 0.0787 0.0768 0.0757 0.0743 0.0735 0.0729 0.0722 0.0718 

[TRAIN] Epoch[1](3159/114412); Loss: 0.085941; Backpropagation: 0.2915 sec; Batch: 2.1153 sec
0.1618 0.1555 0.1151 0.1029 0.0888 0.0829 0.0753 0.0717 0.0690 0.0672 0.0660 0.0650 0.0642 0.0636 0.0632 0.0629 

[TRAIN] Epoch[1](3160/114412); Loss: 0.069331; Backpropagation: 0.2910 sec; Batch: 2.1139 sec
0.1319 0.1257 0.0834 0.0756 0.0728 0.0677 0.0662 0.0618 0.0593 0.0555 0.0537 0.0526 0.0517 0.0512 0.0503 0.0501 

[TRAIN] Epoch[1](3161/114412); Loss: 0.062097; Backpropagation: 0.2905 sec; Batch: 2.1157 sec
0.1188 0.1098 0.0872 0.0762 0.0661 0.0601 0.0558 0.0518 0.0495 0.0481 0.0468 0.0460 0.0452 0.0446 0.0441 0.0437 

[TRAIN] Epoch[1](3162/114412); Loss: 0.085811; Backpropagation: 0.2911 sec; Batch: 2.1196 sec
0.1449 0.1357 0.1050 0.0948 0.0868 0.0821 0.0788 0.0763 0.0745 0.0730 0.0719 0.0710 0.0704 0.0696 0.0692 0.0688 

[TRAIN] Epoch[1](3163/114412); Loss: 0.070253; Backpropagation: 0.2914 sec; Batch: 2.1223 sec
0.1617 0.1545 0.1112 0.0978 0.0771 0.0675 0.0561 0.0522 0.0482 0.0468 0.0445 0.0430 0.0419 0.0411 0.0404 0.0400 

[TRAIN] Epoch[1](3164/114412); Loss: 0.065544; Backpropagation: 0.2910 sec; Batch: 2.1193 sec
0.1489 0.1415 0.0946 0.0805 0.0658 0.0592 0.0542 0.0507 0.0492 0.0472 0.0452 0.0439 0.0429 0.0422 0.0415 0.0412 

[TRAIN] Epoch[1](3165/114412); Loss: 0.074408; Backpropagation: 0.2911 sec; Batch: 2.1141 sec
0.1270 0.1211 0.0985 0.0887 0.0792 0.0735 0.0689 0.0660 0.0632 0.0605 0.0592 0.0581 0.0574 0.0568 0.0564 0.0560 

[TRAIN] Epoch[1](3166/114412); Loss: 0.061800; Backpropagation: 0.2928 sec; Batch: 2.1189 sec
0.1211 0.1126 0.0793 0.0712 0.0618 0.0582 0.0545 0.0521 0.0505 0.0491 0.0480 0.0472 0.0466 0.0460 0.0455 0.0452 

[TRAIN] Epoch[1](3167/114412); Loss: 0.079473; Backpropagation: 0.2917 sec; Batch: 2.1171 sec
0.1639 0.1526 0.1213 0.0988 0.0791 0.0711 0.0662 0.0624 0.0606 0.0588 0.0578 0.0570 0.0562 0.0557 0.0553 0.0549 

[TRAIN] Epoch[1](3168/114412); Loss: 0.074634; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1314 0.1226 0.0898 0.0803 0.0730 0.0701 0.0668 0.0653 0.0641 0.0630 0.0623 0.0617 0.0612 0.0610 0.0608 0.0607 

[TRAIN] Epoch[1](3169/114412); Loss: 0.066296; Backpropagation: 0.2933 sec; Batch: 2.1181 sec
0.1101 0.1051 0.0865 0.0757 0.0687 0.0639 0.0606 0.0586 0.0571 0.0555 0.0546 0.0537 0.0531 0.0528 0.0525 0.0523 

[TRAIN] Epoch[1](3170/114412); Loss: 0.069240; Backpropagation: 0.2928 sec; Batch: 2.1246 sec
0.1370 0.1241 0.0951 0.0812 0.0730 0.0659 0.0625 0.0589 0.0561 0.0540 0.0523 0.0512 0.0501 0.0493 0.0488 0.0484 

[TRAIN] Epoch[1](3171/114412); Loss: 0.074547; Backpropagation: 0.2910 sec; Batch: 2.1020 sec
0.1376 0.1303 0.0981 0.0848 0.0746 0.0690 0.0663 0.0643 0.0620 0.0603 0.0594 0.0584 0.0577 0.0571 0.0566 0.0563 

[TRAIN] Epoch[1](3172/114412); Loss: 0.068722; Backpropagation: 0.2910 sec; Batch: 2.1542 sec
0.1475 0.1398 0.0903 0.0779 0.0616 0.0585 0.0555 0.0550 0.0538 0.0527 0.0521 0.0516 0.0511 0.0509 0.0508 0.0506 

[TRAIN] Epoch[1](3173/114412); Loss: 0.077724; Backpropagation: 0.2913 sec; Batch: 2.1091 sec
0.1517 0.1428 0.1146 0.1011 0.0867 0.0782 0.0715 0.0652 0.0610 0.0581 0.0560 0.0534 0.0523 0.0511 0.0504 0.0497 

[TRAIN] Epoch[1](3174/114412); Loss: 0.110416; Backpropagation: 0.2907 sec; Batch: 2.0839 sec
0.2057 0.1990 0.1605 0.1443 0.1243 0.1161 0.1045 0.0971 0.0885 0.0829 0.0786 0.0757 0.0736 0.0723 0.0720 0.0715 

[TRAIN] Epoch[1](3175/114412); Loss: 0.054041; Backpropagation: 0.2908 sec; Batch: 2.1112 sec
0.1412 0.1324 0.0822 0.0699 0.0503 0.0451 0.0402 0.0372 0.0357 0.0356 0.0344 0.0333 0.0325 0.0319 0.0315 0.0312 

[TRAIN] Epoch[1](3176/114412); Loss: 0.058775; Backpropagation: 0.2932 sec; Batch: 2.2434 sec
0.1224 0.1091 0.0782 0.0712 0.0598 0.0557 0.0506 0.0486 0.0468 0.0448 0.0440 0.0428 0.0422 0.0418 0.0413 0.0412 

[TRAIN] Epoch[1](3177/114412); Loss: 0.081377; Backpropagation: 0.2930 sec; Batch: 2.2305 sec
0.1542 0.1446 0.1123 0.0964 0.0836 0.0772 0.0733 0.0704 0.0677 0.0651 0.0632 0.0620 0.0593 0.0584 0.0575 0.0569 

[TRAIN] Epoch[1](3178/114412); Loss: 0.069298; Backpropagation: 0.2908 sec; Batch: 2.1119 sec
0.1407 0.1298 0.0983 0.0819 0.0713 0.0651 0.0599 0.0569 0.0544 0.0527 0.0512 0.0504 0.0499 0.0492 0.0487 0.0483 

[TRAIN] Epoch[1](3179/114412); Loss: 0.063246; Backpropagation: 0.2914 sec; Batch: 2.1193 sec
0.1172 0.1094 0.0865 0.0783 0.0711 0.0627 0.0556 0.0531 0.0517 0.0497 0.0483 0.0471 0.0462 0.0456 0.0450 0.0446 

[TRAIN] Epoch[1](3180/114412); Loss: 0.079298; Backpropagation: 0.2905 sec; Batch: 2.1425 sec
0.1238 0.1203 0.1031 0.0935 0.0830 0.0787 0.0745 0.0715 0.0688 0.0670 0.0659 0.0651 0.0642 0.0636 0.0632 0.0628 

[TRAIN] Epoch[1](3181/114412); Loss: 0.051721; Backpropagation: 0.2910 sec; Batch: 2.0938 sec
0.1023 0.0934 0.0723 0.0621 0.0547 0.0505 0.0463 0.0438 0.0410 0.0397 0.0384 0.0376 0.0368 0.0365 0.0363 0.0360 

[TRAIN] Epoch[1](3182/114412); Loss: 0.052384; Backpropagation: 0.2938 sec; Batch: 2.1158 sec
0.1197 0.1100 0.0817 0.0606 0.0549 0.0456 0.0422 0.0398 0.0381 0.0369 0.0360 0.0353 0.0348 0.0345 0.0341 0.0339 

[TRAIN] Epoch[1](3183/114412); Loss: 0.074711; Backpropagation: 0.2954 sec; Batch: 2.1201 sec
0.1879 0.1783 0.1228 0.1004 0.0752 0.0673 0.0574 0.0543 0.0502 0.0467 0.0453 0.0434 0.0424 0.0417 0.0413 0.0408 

[TRAIN] Epoch[1](3184/114412); Loss: 0.073992; Backpropagation: 0.2907 sec; Batch: 2.1430 sec
0.1213 0.1163 0.0905 0.0823 0.0750 0.0708 0.0675 0.0656 0.0644 0.0631 0.0623 0.0617 0.0613 0.0608 0.0606 0.0603 

[TRAIN] Epoch[1](3185/114412); Loss: 0.047243; Backpropagation: 0.2907 sec; Batch: 2.1132 sec
0.1132 0.1051 0.0664 0.0510 0.0450 0.0413 0.0387 0.0363 0.0347 0.0335 0.0329 0.0323 0.0318 0.0314 0.0313 0.0310 

[TRAIN] Epoch[1](3186/114412); Loss: 0.094597; Backpropagation: 0.2903 sec; Batch: 2.1176 sec
0.1402 0.1312 0.1138 0.1038 0.0987 0.0939 0.0908 0.0880 0.0856 0.0841 0.0827 0.0818 0.0808 0.0801 0.0793 0.0787 

[TRAIN] Epoch[1](3187/114412); Loss: 0.080591; Backpropagation: 0.2909 sec; Batch: 2.1191 sec
0.1399 0.1364 0.1118 0.0967 0.0831 0.0795 0.0745 0.0695 0.0672 0.0653 0.0635 0.0619 0.0611 0.0603 0.0596 0.0591 

[TRAIN] Epoch[1](3188/114412); Loss: 0.092287; Backpropagation: 0.2908 sec; Batch: 2.1231 sec
0.1607 0.1539 0.1144 0.1048 0.0945 0.0887 0.0837 0.0806 0.0785 0.0769 0.0756 0.0743 0.0735 0.0727 0.0721 0.0717 

[TRAIN] Epoch[1](3189/114412); Loss: 0.072173; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1358 0.1221 0.0939 0.0815 0.0739 0.0690 0.0653 0.0623 0.0603 0.0587 0.0572 0.0564 0.0556 0.0548 0.0543 0.0537 

[TRAIN] Epoch[1](3190/114412); Loss: 0.084909; Backpropagation: 0.2912 sec; Batch: 2.1189 sec
0.1337 0.1260 0.1041 0.0938 0.0862 0.0834 0.0797 0.0770 0.0748 0.0737 0.0727 0.0718 0.0710 0.0707 0.0702 0.0697 

[TRAIN] Epoch[1](3191/114412); Loss: 0.082824; Backpropagation: 0.2908 sec; Batch: 2.0788 sec
0.1495 0.1371 0.1087 0.0944 0.0840 0.0777 0.0739 0.0712 0.0694 0.0677 0.0668 0.0660 0.0652 0.0649 0.0645 0.0641 

[TRAIN] Epoch[1](3192/114412); Loss: 0.074443; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1328 0.1259 0.0938 0.0838 0.0775 0.0722 0.0679 0.0652 0.0628 0.0609 0.0600 0.0591 0.0582 0.0574 0.0571 0.0565 

[TRAIN] Epoch[1](3193/114412); Loss: 0.076231; Backpropagation: 0.2929 sec; Batch: 2.1156 sec
0.1502 0.1384 0.0982 0.0838 0.0755 0.0702 0.0660 0.0634 0.0620 0.0609 0.0600 0.0591 0.0586 0.0581 0.0577 0.0575 

[TRAIN] Epoch[1](3194/114412); Loss: 0.057959; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1192 0.1117 0.0801 0.0706 0.0572 0.0528 0.0491 0.0472 0.0454 0.0440 0.0432 0.0423 0.0417 0.0413 0.0409 0.0407 

[TRAIN] Epoch[1](3195/114412); Loss: 0.053363; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1100 0.0974 0.0736 0.0638 0.0544 0.0498 0.0468 0.0440 0.0419 0.0408 0.0398 0.0392 0.0387 0.0382 0.0380 0.0376 

[TRAIN] Epoch[1](3196/114412); Loss: 0.054114; Backpropagation: 0.2951 sec; Batch: 2.1257 sec
0.1145 0.1032 0.0784 0.0660 0.0536 0.0494 0.0472 0.0439 0.0415 0.0402 0.0391 0.0385 0.0381 0.0378 0.0375 0.0371 

[TRAIN] Epoch[1](3197/114412); Loss: 0.067881; Backpropagation: 0.2931 sec; Batch: 2.1195 sec
0.1201 0.1102 0.0891 0.0760 0.0691 0.0644 0.0617 0.0593 0.0573 0.0561 0.0552 0.0546 0.0538 0.0534 0.0531 0.0527 

[TRAIN] Epoch[1](3198/114412); Loss: 0.058439; Backpropagation: 0.2909 sec; Batch: 2.1185 sec
0.1334 0.1205 0.0867 0.0706 0.0591 0.0541 0.0494 0.0459 0.0435 0.0415 0.0401 0.0391 0.0385 0.0379 0.0375 0.0374 

[TRAIN] Epoch[1](3199/114412); Loss: 0.058769; Backpropagation: 0.2913 sec; Batch: 2.1333 sec
0.1135 0.1044 0.0778 0.0691 0.0602 0.0553 0.0522 0.0496 0.0481 0.0467 0.0458 0.0449 0.0440 0.0433 0.0428 0.0425 

[TRAIN] Epoch[1](3200/114412); Loss: 0.068291; Backpropagation: 0.2910 sec; Batch: 2.1213 sec
0.1198 0.1111 0.0915 0.0796 0.0712 0.0662 0.0624 0.0599 0.0574 0.0559 0.0546 0.0537 0.0530 0.0525 0.0521 0.0517 

[TRAIN] Epoch[1](3201/114412); Loss: 0.084766; Backpropagation: 0.2931 sec; Batch: 2.1355 sec
0.1600 0.1536 0.1224 0.1090 0.0868 0.0811 0.0749 0.0698 0.0667 0.0649 0.0632 0.0621 0.0612 0.0607 0.0601 0.0597 

[TRAIN] Epoch[1](3202/114412); Loss: 0.080977; Backpropagation: 0.2918 sec; Batch: 2.1199 sec
0.1407 0.1294 0.1080 0.0938 0.0852 0.0788 0.0746 0.0711 0.0681 0.0664 0.0654 0.0642 0.0633 0.0627 0.0621 0.0617 

[TRAIN] Epoch[1](3203/114412); Loss: 0.059842; Backpropagation: 0.2911 sec; Batch: 2.0786 sec
0.1260 0.1108 0.0792 0.0678 0.0617 0.0561 0.0519 0.0487 0.0470 0.0458 0.0450 0.0444 0.0437 0.0433 0.0431 0.0429 

[TRAIN] Epoch[1](3204/114412); Loss: 0.073354; Backpropagation: 0.2909 sec; Batch: 2.1199 sec
0.1480 0.1352 0.0994 0.0868 0.0748 0.0688 0.0639 0.0600 0.0583 0.0569 0.0557 0.0548 0.0540 0.0531 0.0522 0.0518 

[TRAIN] Epoch[1](3205/114412); Loss: 0.072555; Backpropagation: 0.2905 sec; Batch: 2.0779 sec
0.1380 0.1330 0.1015 0.0887 0.0711 0.0650 0.0622 0.0599 0.0583 0.0567 0.0558 0.0550 0.0544 0.0541 0.0537 0.0534 

[TRAIN] Epoch[1](3206/114412); Loss: 0.073050; Backpropagation: 0.2908 sec; Batch: 2.1194 sec
0.1156 0.1079 0.0905 0.0817 0.0759 0.0722 0.0697 0.0673 0.0647 0.0636 0.0623 0.0610 0.0601 0.0593 0.0588 0.0583 

[TRAIN] Epoch[1](3207/114412); Loss: 0.057512; Backpropagation: 0.2910 sec; Batch: 2.0800 sec
0.1254 0.1128 0.0809 0.0700 0.0576 0.0522 0.0480 0.0454 0.0437 0.0425 0.0416 0.0409 0.0404 0.0400 0.0396 0.0393 

[TRAIN] Epoch[1](3208/114412); Loss: 0.058933; Backpropagation: 0.2912 sec; Batch: 2.1256 sec
0.1125 0.1037 0.0842 0.0693 0.0633 0.0560 0.0531 0.0499 0.0478 0.0461 0.0449 0.0437 0.0429 0.0424 0.0418 0.0414 

[TRAIN] Epoch[1](3209/114412); Loss: 0.081904; Backpropagation: 0.2908 sec; Batch: 2.1199 sec
0.1344 0.1247 0.1055 0.0918 0.0839 0.0791 0.0758 0.0731 0.0712 0.0696 0.0686 0.0677 0.0670 0.0664 0.0660 0.0657 

[TRAIN] Epoch[1](3210/114412); Loss: 0.066986; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1427 0.1292 0.1005 0.0785 0.0670 0.0614 0.0576 0.0554 0.0526 0.0498 0.0482 0.0474 0.0463 0.0457 0.0450 0.0444 

[TRAIN] Epoch[1](3211/114412); Loss: 0.082915; Backpropagation: 0.2907 sec; Batch: 2.0778 sec
0.1557 0.1485 0.1121 0.0995 0.0864 0.0773 0.0731 0.0689 0.0669 0.0655 0.0638 0.0629 0.0623 0.0616 0.0612 0.0610 

[TRAIN] Epoch[1](3212/114412); Loss: 0.060618; Backpropagation: 0.2908 sec; Batch: 2.0808 sec
0.1215 0.1142 0.0841 0.0725 0.0616 0.0572 0.0529 0.0503 0.0480 0.0466 0.0455 0.0444 0.0436 0.0429 0.0425 0.0421 

[TRAIN] Epoch[1](3213/114412); Loss: 0.082211; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1545 0.1476 0.1174 0.1021 0.0869 0.0803 0.0739 0.0704 0.0667 0.0641 0.0617 0.0604 0.0590 0.0577 0.0567 0.0560 

[TRAIN] Epoch[1](3214/114412); Loss: 0.070856; Backpropagation: 0.2907 sec; Batch: 2.1171 sec
0.1242 0.1173 0.0887 0.0777 0.0694 0.0668 0.0641 0.0621 0.0607 0.0598 0.0590 0.0581 0.0571 0.0566 0.0562 0.0558 

[TRAIN] Epoch[1](3215/114412); Loss: 0.064820; Backpropagation: 0.2905 sec; Batch: 2.0776 sec
0.1195 0.1067 0.0865 0.0770 0.0717 0.0626 0.0592 0.0565 0.0540 0.0521 0.0501 0.0493 0.0485 0.0482 0.0479 0.0475 

[TRAIN] Epoch[1](3216/114412); Loss: 0.064414; Backpropagation: 0.2954 sec; Batch: 2.1228 sec
0.1212 0.1100 0.0847 0.0758 0.0663 0.0617 0.0581 0.0555 0.0537 0.0519 0.0506 0.0496 0.0489 0.0481 0.0475 0.0472 

[TRAIN] Epoch[1](3217/114412); Loss: 0.059792; Backpropagation: 0.2951 sec; Batch: 2.1385 sec
0.1294 0.1156 0.0924 0.0785 0.0641 0.0558 0.0485 0.0459 0.0440 0.0425 0.0414 0.0406 0.0401 0.0395 0.0392 0.0390 

[TRAIN] Epoch[1](3218/114412); Loss: 0.049940; Backpropagation: 0.2952 sec; Batch: 2.1138 sec
0.1044 0.0970 0.0725 0.0634 0.0518 0.0481 0.0414 0.0386 0.0376 0.0372 0.0359 0.0349 0.0344 0.0342 0.0340 0.0338 

[TRAIN] Epoch[1](3219/114412); Loss: 0.060686; Backpropagation: 0.2948 sec; Batch: 2.4073 sec
0.1058 0.0993 0.0833 0.0746 0.0648 0.0579 0.0547 0.0520 0.0503 0.0491 0.0482 0.0474 0.0467 0.0460 0.0456 0.0453 

[TRAIN] Epoch[1](3220/114412); Loss: 0.081439; Backpropagation: 0.2914 sec; Batch: 2.0788 sec
0.1696 0.1510 0.1244 0.1066 0.0900 0.0806 0.0734 0.0676 0.0616 0.0588 0.0562 0.0548 0.0535 0.0524 0.0516 0.0509 

[TRAIN] Epoch[1](3221/114412); Loss: 0.087532; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1515 0.1449 0.1104 0.0984 0.0885 0.0835 0.0800 0.0768 0.0744 0.0728 0.0717 0.0708 0.0699 0.0693 0.0690 0.0686 

[TRAIN] Epoch[1](3222/114412); Loss: 0.084929; Backpropagation: 0.2908 sec; Batch: 2.1129 sec
0.1481 0.1321 0.1084 0.0950 0.0858 0.0813 0.0774 0.0751 0.0729 0.0711 0.0701 0.0693 0.0687 0.0683 0.0678 0.0675 

[TRAIN] Epoch[1](3223/114412); Loss: 0.041479; Backpropagation: 0.2913 sec; Batch: 2.1235 sec
0.0968 0.0868 0.0604 0.0466 0.0396 0.0372 0.0339 0.0320 0.0307 0.0298 0.0291 0.0287 0.0283 0.0280 0.0279 0.0277 

[TRAIN] Epoch[1](3224/114412); Loss: 0.084170; Backpropagation: 0.2915 sec; Batch: 2.0933 sec
0.1509 0.1355 0.1186 0.1021 0.0867 0.0810 0.0763 0.0731 0.0704 0.0684 0.0664 0.0651 0.0642 0.0633 0.0626 0.0622 

[TRAIN] Epoch[1](3225/114412); Loss: 0.065461; Backpropagation: 0.2928 sec; Batch: 2.1562 sec
0.1298 0.1160 0.0847 0.0736 0.0668 0.0623 0.0582 0.0555 0.0533 0.0518 0.0508 0.0501 0.0495 0.0487 0.0484 0.0481 

[TRAIN] Epoch[1](3226/114412); Loss: 0.061421; Backpropagation: 0.2912 sec; Batch: 2.1217 sec
0.1112 0.0995 0.0777 0.0693 0.0644 0.0593 0.0567 0.0537 0.0521 0.0506 0.0495 0.0487 0.0481 0.0477 0.0472 0.0471 

[TRAIN] Epoch[1](3227/114412); Loss: 0.060040; Backpropagation: 0.2911 sec; Batch: 2.0828 sec
0.1227 0.1048 0.0849 0.0717 0.0632 0.0562 0.0515 0.0486 0.0473 0.0461 0.0455 0.0449 0.0440 0.0435 0.0431 0.0428 

[TRAIN] Epoch[1](3228/114412); Loss: 0.063415; Backpropagation: 0.2915 sec; Batch: 2.1502 sec
0.1341 0.1250 0.0882 0.0790 0.0663 0.0589 0.0550 0.0520 0.0493 0.0468 0.0456 0.0442 0.0433 0.0428 0.0422 0.0417 

[TRAIN] Epoch[1](3229/114412); Loss: 0.082816; Backpropagation: 0.2910 sec; Batch: 2.1359 sec
0.1860 0.1677 0.1109 0.0946 0.0822 0.0747 0.0697 0.0651 0.0634 0.0617 0.0603 0.0593 0.0584 0.0576 0.0571 0.0563 

[TRAIN] Epoch[1](3230/114412); Loss: 0.062224; Backpropagation: 0.2914 sec; Batch: 2.0996 sec
0.1188 0.1107 0.0817 0.0675 0.0624 0.0569 0.0546 0.0527 0.0518 0.0504 0.0492 0.0485 0.0481 0.0477 0.0475 0.0472 

[TRAIN] Epoch[1](3231/114412); Loss: 0.073631; Backpropagation: 0.2930 sec; Batch: 2.1212 sec
0.1440 0.1310 0.0971 0.0838 0.0768 0.0710 0.0655 0.0624 0.0597 0.0582 0.0569 0.0559 0.0549 0.0542 0.0536 0.0530 

[TRAIN] Epoch[1](3232/114412); Loss: 0.082545; Backpropagation: 0.2928 sec; Batch: 2.1185 sec
0.1427 0.1288 0.1018 0.0916 0.0830 0.0796 0.0756 0.0740 0.0718 0.0700 0.0689 0.0679 0.0670 0.0664 0.0660 0.0655 

[TRAIN] Epoch[1](3233/114412); Loss: 0.108058; Backpropagation: 0.2927 sec; Batch: 2.1323 sec
0.1779 0.1688 0.1328 0.1200 0.1102 0.1050 0.0998 0.0963 0.0938 0.0923 0.0908 0.0897 0.0890 0.0883 0.0875 0.0868 

[TRAIN] Epoch[1](3234/114412); Loss: 0.089799; Backpropagation: 0.2915 sec; Batch: 2.1167 sec
0.1571 0.1373 0.1128 0.1004 0.0932 0.0874 0.0843 0.0810 0.0786 0.0768 0.0750 0.0729 0.0720 0.0705 0.0694 0.0681 

[TRAIN] Epoch[1](3235/114412); Loss: 0.065704; Backpropagation: 0.2933 sec; Batch: 2.1185 sec
0.1314 0.1048 0.0870 0.0717 0.0663 0.0604 0.0576 0.0558 0.0544 0.0533 0.0526 0.0519 0.0515 0.0511 0.0508 0.0506 

[TRAIN] Epoch[1](3236/114412); Loss: 0.078963; Backpropagation: 0.2909 sec; Batch: 2.1139 sec
0.1502 0.1440 0.0921 0.0849 0.0779 0.0724 0.0701 0.0679 0.0657 0.0646 0.0639 0.0629 0.0623 0.0619 0.0615 0.0612 

[TRAIN] Epoch[1](3237/114412); Loss: 0.077655; Backpropagation: 0.2911 sec; Batch: 2.1218 sec
0.1685 0.1510 0.1083 0.0918 0.0813 0.0732 0.0678 0.0628 0.0600 0.0579 0.0561 0.0547 0.0534 0.0525 0.0518 0.0512 

[TRAIN] Epoch[1](3238/114412); Loss: 0.052638; Backpropagation: 0.2932 sec; Batch: 2.1189 sec
0.1095 0.0941 0.0664 0.0556 0.0540 0.0490 0.0470 0.0441 0.0424 0.0415 0.0408 0.0402 0.0398 0.0395 0.0392 0.0390 

[TRAIN] Epoch[1](3239/114412); Loss: 0.052842; Backpropagation: 0.2906 sec; Batch: 2.1379 sec
0.1006 0.0915 0.0725 0.0591 0.0534 0.0505 0.0465 0.0446 0.0432 0.0419 0.0414 0.0407 0.0403 0.0399 0.0397 0.0395 

[TRAIN] Epoch[1](3240/114412); Loss: 0.060776; Backpropagation: 0.2913 sec; Batch: 2.0844 sec
0.1246 0.1115 0.0880 0.0746 0.0670 0.0593 0.0548 0.0514 0.0480 0.0455 0.0438 0.0427 0.0414 0.0407 0.0400 0.0392 

[TRAIN] Epoch[1](3241/114412); Loss: 0.068074; Backpropagation: 0.2925 sec; Batch: 2.0831 sec
0.1238 0.1137 0.0838 0.0743 0.0698 0.0651 0.0616 0.0594 0.0579 0.0565 0.0555 0.0547 0.0540 0.0534 0.0530 0.0527 

[TRAIN] Epoch[1](3242/114412); Loss: 0.052655; Backpropagation: 0.2931 sec; Batch: 2.0800 sec
0.1149 0.0940 0.0708 0.0571 0.0561 0.0487 0.0460 0.0436 0.0422 0.0405 0.0395 0.0385 0.0381 0.0377 0.0375 0.0372 

[TRAIN] Epoch[1](3243/114412); Loss: 0.071687; Backpropagation: 0.2952 sec; Batch: 2.1264 sec
0.1312 0.1148 0.0949 0.0814 0.0758 0.0691 0.0661 0.0631 0.0604 0.0588 0.0574 0.0564 0.0554 0.0544 0.0541 0.0536 

[TRAIN] Epoch[1](3244/114412); Loss: 0.069696; Backpropagation: 0.2932 sec; Batch: 2.1185 sec
0.1366 0.1175 0.0964 0.0827 0.0740 0.0648 0.0617 0.0587 0.0561 0.0546 0.0533 0.0526 0.0520 0.0518 0.0513 0.0511 

[TRAIN] Epoch[1](3245/114412); Loss: 0.054806; Backpropagation: 0.2929 sec; Batch: 2.1215 sec
0.1195 0.1052 0.0680 0.0560 0.0541 0.0492 0.0473 0.0453 0.0437 0.0426 0.0419 0.0413 0.0410 0.0408 0.0406 0.0405 

[TRAIN] Epoch[1](3246/114412); Loss: 0.074174; Backpropagation: 0.2918 sec; Batch: 2.1173 sec
0.1140 0.1001 0.0882 0.0824 0.0771 0.0739 0.0702 0.0684 0.0670 0.0657 0.0646 0.0640 0.0635 0.0629 0.0625 0.0623 

[TRAIN] Epoch[1](3247/114412); Loss: 0.079010; Backpropagation: 0.2910 sec; Batch: 2.1201 sec
0.1389 0.1275 0.1041 0.0885 0.0805 0.0739 0.0715 0.0688 0.0670 0.0656 0.0646 0.0638 0.0631 0.0625 0.0620 0.0617 

[TRAIN] Epoch[1](3248/114412); Loss: 0.067521; Backpropagation: 0.2956 sec; Batch: 2.1216 sec
0.1095 0.1027 0.0887 0.0765 0.0709 0.0657 0.0634 0.0608 0.0586 0.0572 0.0561 0.0551 0.0544 0.0539 0.0535 0.0531 

[TRAIN] Epoch[1](3249/114412); Loss: 0.078919; Backpropagation: 0.2928 sec; Batch: 2.1220 sec
0.1309 0.1205 0.0967 0.0851 0.0792 0.0767 0.0730 0.0710 0.0691 0.0680 0.0668 0.0661 0.0654 0.0651 0.0648 0.0645 

[TRAIN] Epoch[1](3250/114412); Loss: 0.126828; Backpropagation: 0.2912 sec; Batch: 2.0810 sec
0.1995 0.1873 0.1641 0.1443 0.1346 0.1234 0.1193 0.1133 0.1106 0.1079 0.1065 0.1054 0.1043 0.1034 0.1028 0.1025 

[TRAIN] Epoch[1](3251/114412); Loss: 0.074278; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.1364 0.1186 0.0890 0.0795 0.0755 0.0712 0.0672 0.0652 0.0638 0.0623 0.0613 0.0608 0.0600 0.0595 0.0593 0.0588 

[TRAIN] Epoch[1](3252/114412); Loss: 0.073575; Backpropagation: 0.2906 sec; Batch: 2.0779 sec
0.1361 0.1261 0.0989 0.0852 0.0830 0.0767 0.0674 0.0644 0.0618 0.0585 0.0562 0.0553 0.0534 0.0522 0.0513 0.0505 

[TRAIN] Epoch[1](3253/114412); Loss: 0.082667; Backpropagation: 0.2904 sec; Batch: 2.1157 sec
0.1483 0.1309 0.1070 0.0927 0.0848 0.0787 0.0752 0.0718 0.0698 0.0685 0.0674 0.0664 0.0658 0.0655 0.0651 0.0647 

[TRAIN] Epoch[1](3254/114412); Loss: 0.054384; Backpropagation: 0.2912 sec; Batch: 2.1199 sec
0.1345 0.1229 0.0829 0.0645 0.0562 0.0500 0.0455 0.0399 0.0377 0.0363 0.0348 0.0340 0.0333 0.0329 0.0324 0.0322 

[TRAIN] Epoch[1](3255/114412); Loss: 0.044903; Backpropagation: 0.2913 sec; Batch: 2.1298 sec
0.1046 0.0865 0.0559 0.0467 0.0456 0.0411 0.0380 0.0364 0.0351 0.0342 0.0332 0.0327 0.0324 0.0322 0.0319 0.0318 

[TRAIN] Epoch[1](3256/114412); Loss: 0.063380; Backpropagation: 0.2908 sec; Batch: 2.1556 sec
0.1297 0.1063 0.0863 0.0743 0.0673 0.0624 0.0581 0.0546 0.0523 0.0500 0.0479 0.0469 0.0456 0.0447 0.0442 0.0437 

[TRAIN] Epoch[1](3257/114412); Loss: 0.065786; Backpropagation: 0.2934 sec; Batch: 2.1218 sec
0.1372 0.1252 0.0896 0.0806 0.0724 0.0630 0.0584 0.0546 0.0515 0.0490 0.0475 0.0463 0.0454 0.0446 0.0439 0.0435 

[TRAIN] Epoch[1](3258/114412); Loss: 0.055913; Backpropagation: 0.2956 sec; Batch: 2.1234 sec
0.1477 0.1289 0.0714 0.0574 0.0519 0.0481 0.0453 0.0422 0.0403 0.0393 0.0386 0.0375 0.0370 0.0368 0.0362 0.0360 

[TRAIN] Epoch[1](3259/114412); Loss: 0.050595; Backpropagation: 0.2932 sec; Batch: 2.1233 sec
0.1273 0.1093 0.0666 0.0517 0.0482 0.0442 0.0426 0.0395 0.0377 0.0366 0.0357 0.0348 0.0342 0.0338 0.0335 0.0335 

[TRAIN] Epoch[1](3260/114412); Loss: 0.098874; Backpropagation: 0.2909 sec; Batch: 2.1195 sec
0.1486 0.1396 0.1173 0.1068 0.1006 0.0965 0.0928 0.0909 0.0893 0.0879 0.0868 0.0861 0.0855 0.0849 0.0845 0.0840 

[TRAIN] Epoch[1](3261/114412); Loss: 0.051679; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1046 0.0937 0.0717 0.0614 0.0528 0.0489 0.0452 0.0428 0.0410 0.0398 0.0387 0.0381 0.0376 0.0371 0.0368 0.0366 

[TRAIN] Epoch[1](3262/114412); Loss: 0.059802; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1412 0.1341 0.0864 0.0722 0.0586 0.0519 0.0475 0.0450 0.0430 0.0417 0.0405 0.0399 0.0393 0.0389 0.0385 0.0382 

[TRAIN] Epoch[1](3263/114412); Loss: 0.057959; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1351 0.1163 0.0822 0.0730 0.0598 0.0534 0.0474 0.0441 0.0424 0.0415 0.0401 0.0394 0.0388 0.0384 0.0379 0.0376 

[TRAIN] Epoch[1](3264/114412); Loss: 0.063024; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1121 0.0978 0.0856 0.0714 0.0669 0.0605 0.0576 0.0553 0.0532 0.0520 0.0510 0.0501 0.0494 0.0489 0.0485 0.0482 

[TRAIN] Epoch[1](3265/114412); Loss: 0.079214; Backpropagation: 0.2930 sec; Batch: 2.1228 sec
0.1518 0.1300 0.1111 0.0964 0.0841 0.0733 0.0692 0.0660 0.0636 0.0621 0.0610 0.0605 0.0600 0.0596 0.0596 0.0593 

[TRAIN] Epoch[1](3266/114412); Loss: 0.047006; Backpropagation: 0.2927 sec; Batch: 2.1216 sec
0.1083 0.0881 0.0703 0.0577 0.0499 0.0436 0.0395 0.0367 0.0349 0.0335 0.0327 0.0321 0.0317 0.0313 0.0309 0.0308 

[TRAIN] Epoch[1](3267/114412); Loss: 0.061799; Backpropagation: 0.2930 sec; Batch: 2.1217 sec
0.1403 0.1229 0.0850 0.0728 0.0616 0.0557 0.0508 0.0482 0.0468 0.0454 0.0444 0.0438 0.0433 0.0429 0.0426 0.0422 

[TRAIN] Epoch[1](3268/114412); Loss: 0.063471; Backpropagation: 0.2930 sec; Batch: 2.1223 sec
0.1379 0.1156 0.0934 0.0815 0.0705 0.0633 0.0580 0.0531 0.0492 0.0470 0.0454 0.0416 0.0411 0.0404 0.0390 0.0386 

[TRAIN] Epoch[1](3269/114412); Loss: 0.055423; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1555 0.1443 0.0946 0.0792 0.0527 0.0456 0.0394 0.0340 0.0338 0.0322 0.0305 0.0300 0.0295 0.0288 0.0285 0.0282 

[TRAIN] Epoch[1](3270/114412); Loss: 0.054594; Backpropagation: 0.2928 sec; Batch: 2.1224 sec
0.0984 0.0849 0.0757 0.0603 0.0546 0.0523 0.0492 0.0481 0.0467 0.0455 0.0444 0.0436 0.0430 0.0427 0.0423 0.0419 

[TRAIN] Epoch[1](3271/114412); Loss: 0.083820; Backpropagation: 0.2952 sec; Batch: 2.1242 sec
0.1501 0.1345 0.1030 0.0958 0.0857 0.0823 0.0776 0.0748 0.0724 0.0702 0.0687 0.0673 0.0661 0.0652 0.0640 0.0634 

[TRAIN] Epoch[1](3272/114412); Loss: 0.060118; Backpropagation: 0.2909 sec; Batch: 2.0781 sec
0.1159 0.1047 0.0788 0.0680 0.0613 0.0570 0.0540 0.0515 0.0498 0.0481 0.0471 0.0464 0.0456 0.0450 0.0445 0.0442 

[TRAIN] Epoch[1](3273/114412); Loss: 0.054827; Backpropagation: 0.2913 sec; Batch: 2.1324 sec
0.1138 0.0950 0.0716 0.0601 0.0551 0.0519 0.0489 0.0464 0.0445 0.0434 0.0425 0.0417 0.0412 0.0408 0.0404 0.0401 

[TRAIN] Epoch[1](3274/114412); Loss: 0.074145; Backpropagation: 0.2911 sec; Batch: 2.1333 sec
0.1738 0.1367 0.0876 0.0743 0.0673 0.0637 0.0619 0.0607 0.0594 0.0585 0.0580 0.0574 0.0570 0.0568 0.0567 0.0564 

[TRAIN] Epoch[1](3275/114412); Loss: 0.079741; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.1535 0.1266 0.0948 0.0886 0.0812 0.0768 0.0725 0.0694 0.0673 0.0658 0.0647 0.0640 0.0634 0.0628 0.0624 0.0620 

[TRAIN] Epoch[1](3276/114412); Loss: 0.065228; Backpropagation: 0.2911 sec; Batch: 2.1208 sec
0.1265 0.1100 0.0820 0.0735 0.0682 0.0626 0.0593 0.0561 0.0541 0.0524 0.0513 0.0505 0.0499 0.0495 0.0492 0.0487 

[TRAIN] Epoch[1](3277/114412); Loss: 0.063778; Backpropagation: 0.2909 sec; Batch: 2.1225 sec
0.1379 0.1149 0.0869 0.0729 0.0640 0.0581 0.0551 0.0524 0.0506 0.0493 0.0482 0.0472 0.0464 0.0459 0.0455 0.0451 

[TRAIN] Epoch[1](3278/114412); Loss: 0.088067; Backpropagation: 0.2914 sec; Batch: 2.1170 sec
0.2003 0.1765 0.1307 0.1099 0.0898 0.0792 0.0714 0.0686 0.0675 0.0648 0.0627 0.0598 0.0585 0.0573 0.0563 0.0557 

[TRAIN] Epoch[1](3279/114412); Loss: 0.064534; Backpropagation: 0.2912 sec; Batch: 2.0782 sec
0.1519 0.1400 0.1075 0.0842 0.0610 0.0536 0.0515 0.0476 0.0454 0.0438 0.0427 0.0420 0.0410 0.0404 0.0401 0.0399 

[TRAIN] Epoch[1](3280/114412); Loss: 0.079902; Backpropagation: 0.2952 sec; Batch: 2.1206 sec
0.1356 0.1333 0.0989 0.0890 0.0819 0.0774 0.0723 0.0704 0.0683 0.0671 0.0659 0.0651 0.0641 0.0635 0.0631 0.0626 

[TRAIN] Epoch[1](3281/114412); Loss: 0.099912; Backpropagation: 0.2953 sec; Batch: 2.1265 sec
0.2050 0.1827 0.1480 0.1243 0.1035 0.0955 0.0892 0.0840 0.0788 0.0750 0.0724 0.0708 0.0696 0.0676 0.0668 0.0656 

[TRAIN] Epoch[1](3282/114412); Loss: 0.090235; Backpropagation: 0.2906 sec; Batch: 2.1198 sec
0.1578 0.1402 0.1124 0.1007 0.0929 0.0867 0.0822 0.0793 0.0774 0.0761 0.0750 0.0739 0.0731 0.0725 0.0720 0.0717 

[TRAIN] Epoch[1](3283/114412); Loss: 0.085403; Backpropagation: 0.2906 sec; Batch: 2.1503 sec
0.1741 0.1539 0.1140 0.1010 0.0861 0.0799 0.0741 0.0705 0.0678 0.0661 0.0650 0.0640 0.0633 0.0627 0.0622 0.0619 

[TRAIN] Epoch[1](3284/114412); Loss: 0.056296; Backpropagation: 0.2933 sec; Batch: 2.1157 sec
0.1298 0.0942 0.0711 0.0619 0.0570 0.0528 0.0496 0.0468 0.0452 0.0438 0.0429 0.0421 0.0415 0.0410 0.0407 0.0404 

[TRAIN] Epoch[1](3285/114412); Loss: 0.075801; Backpropagation: 0.2914 sec; Batch: 2.1161 sec
0.1464 0.1261 0.0977 0.0865 0.0788 0.0720 0.0681 0.0649 0.0630 0.0613 0.0600 0.0589 0.0580 0.0575 0.0569 0.0565 

[TRAIN] Epoch[1](3286/114412); Loss: 0.058598; Backpropagation: 0.2910 sec; Batch: 2.1272 sec
0.1276 0.1188 0.0872 0.0683 0.0613 0.0518 0.0485 0.0456 0.0438 0.0424 0.0416 0.0409 0.0404 0.0401 0.0398 0.0395 

[TRAIN] Epoch[1](3287/114412); Loss: 0.053957; Backpropagation: 0.2913 sec; Batch: 2.1078 sec
0.1239 0.0989 0.0761 0.0611 0.0559 0.0493 0.0460 0.0431 0.0414 0.0403 0.0394 0.0384 0.0379 0.0375 0.0372 0.0369 

[TRAIN] Epoch[1](3288/114412); Loss: 0.064544; Backpropagation: 0.2910 sec; Batch: 2.1438 sec
0.1487 0.1321 0.0993 0.0786 0.0681 0.0588 0.0536 0.0504 0.0475 0.0456 0.0443 0.0428 0.0419 0.0410 0.0403 0.0397 

[TRAIN] Epoch[1](3289/114412); Loss: 0.050315; Backpropagation: 0.2914 sec; Batch: 2.1106 sec
0.1074 0.0912 0.0679 0.0570 0.0516 0.0475 0.0441 0.0413 0.0400 0.0388 0.0377 0.0368 0.0363 0.0360 0.0358 0.0356 

[TRAIN] Epoch[1](3290/114412); Loss: 0.083788; Backpropagation: 0.2905 sec; Batch: 2.1279 sec
0.1568 0.1415 0.1115 0.0972 0.0870 0.0799 0.0748 0.0717 0.0690 0.0676 0.0662 0.0649 0.0640 0.0634 0.0628 0.0623 

[TRAIN] Epoch[1](3291/114412); Loss: 0.092853; Backpropagation: 0.2911 sec; Batch: 2.1102 sec
0.1592 0.1465 0.1140 0.1004 0.0940 0.0892 0.0864 0.0823 0.0807 0.0789 0.0776 0.0766 0.0759 0.0752 0.0747 0.0742 

[TRAIN] Epoch[1](3292/114412); Loss: 0.061154; Backpropagation: 0.2909 sec; Batch: 2.1444 sec
0.1562 0.1346 0.0807 0.0638 0.0567 0.0541 0.0504 0.0467 0.0446 0.0435 0.0425 0.0418 0.0412 0.0408 0.0406 0.0402 

[TRAIN] Epoch[1](3293/114412); Loss: 0.092089; Backpropagation: 0.2912 sec; Batch: 2.0805 sec
0.1546 0.1385 0.1159 0.1036 0.0965 0.0910 0.0865 0.0832 0.0801 0.0782 0.0767 0.0753 0.0745 0.0735 0.0728 0.0725 

[TRAIN] Epoch[1](3294/114412); Loss: 0.070989; Backpropagation: 0.2913 sec; Batch: 2.1499 sec
0.1354 0.1192 0.0915 0.0821 0.0753 0.0692 0.0649 0.0612 0.0589 0.0573 0.0557 0.0548 0.0537 0.0529 0.0522 0.0516 

[TRAIN] Epoch[1](3295/114412); Loss: 0.089270; Backpropagation: 0.2905 sec; Batch: 2.1422 sec
0.1774 0.1530 0.1086 0.0955 0.0920 0.0851 0.0797 0.0771 0.0748 0.0728 0.0714 0.0698 0.0687 0.0680 0.0674 0.0670 

[TRAIN] Epoch[1](3296/114412); Loss: 0.076015; Backpropagation: 0.2913 sec; Batch: 2.0845 sec
0.1575 0.1309 0.1022 0.0898 0.0812 0.0742 0.0682 0.0637 0.0605 0.0579 0.0566 0.0557 0.0550 0.0546 0.0542 0.0540 

[TRAIN] Epoch[1](3297/114412); Loss: 0.064056; Backpropagation: 0.2911 sec; Batch: 2.1222 sec
0.1217 0.1011 0.0801 0.0726 0.0669 0.0624 0.0589 0.0557 0.0538 0.0524 0.0515 0.0507 0.0499 0.0495 0.0491 0.0487 

[TRAIN] Epoch[1](3298/114412); Loss: 0.078105; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1351 0.1188 0.0958 0.0852 0.0792 0.0758 0.0728 0.0700 0.0680 0.0664 0.0654 0.0646 0.0639 0.0633 0.0629 0.0625 

[TRAIN] Epoch[1](3299/114412); Loss: 0.067727; Backpropagation: 0.2905 sec; Batch: 2.1203 sec
0.1970 0.1600 0.0834 0.0678 0.0731 0.0616 0.0586 0.0522 0.0483 0.0439 0.0422 0.0405 0.0396 0.0389 0.0385 0.0381 

[TRAIN] Epoch[1](3300/114412); Loss: 0.060220; Backpropagation: 0.2908 sec; Batch: 2.0786 sec
0.1211 0.1074 0.0747 0.0700 0.0621 0.0562 0.0544 0.0518 0.0494 0.0479 0.0465 0.0456 0.0449 0.0442 0.0438 0.0436 

[TRAIN] Epoch[1](3301/114412); Loss: 0.072276; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1340 0.1185 0.0944 0.0833 0.0780 0.0723 0.0665 0.0626 0.0602 0.0587 0.0571 0.0557 0.0548 0.0541 0.0535 0.0528 

[TRAIN] Epoch[1](3302/114412); Loss: 0.076397; Backpropagation: 0.2905 sec; Batch: 2.1129 sec
0.1064 0.0997 0.0893 0.0830 0.0770 0.0751 0.0733 0.0717 0.0705 0.0695 0.0688 0.0684 0.0679 0.0675 0.0673 0.0670 

[TRAIN] Epoch[1](3303/114412); Loss: 0.078614; Backpropagation: 0.2904 sec; Batch: 2.1271 sec
0.1454 0.1354 0.1064 0.0940 0.0819 0.0752 0.0701 0.0669 0.0644 0.0626 0.0614 0.0605 0.0594 0.0585 0.0581 0.0574 

[TRAIN] Epoch[1](3304/114412); Loss: 0.068838; Backpropagation: 0.2909 sec; Batch: 2.1140 sec
0.1406 0.1181 0.0838 0.0716 0.0680 0.0637 0.0608 0.0588 0.0573 0.0561 0.0554 0.0546 0.0540 0.0533 0.0529 0.0525 

[TRAIN] Epoch[1](3305/114412); Loss: 0.081438; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1786 0.1605 0.1165 0.0987 0.0821 0.0752 0.0698 0.0655 0.0617 0.0597 0.0584 0.0571 0.0558 0.0551 0.0544 0.0540 

[TRAIN] Epoch[1](3306/114412); Loss: 0.071329; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1502 0.1325 0.0869 0.0759 0.0682 0.0655 0.0612 0.0592 0.0576 0.0566 0.0556 0.0552 0.0549 0.0544 0.0539 0.0536 

[TRAIN] Epoch[1](3307/114412); Loss: 0.076089; Backpropagation: 0.2907 sec; Batch: 2.0814 sec
0.1470 0.1317 0.1071 0.0898 0.0805 0.0717 0.0673 0.0633 0.0612 0.0594 0.0585 0.0573 0.0566 0.0557 0.0553 0.0549 

[TRAIN] Epoch[1](3308/114412); Loss: 0.086978; Backpropagation: 0.2913 sec; Batch: 2.0770 sec
0.1772 0.1519 0.1135 0.0990 0.0870 0.0819 0.0768 0.0740 0.0712 0.0695 0.0672 0.0658 0.0649 0.0647 0.0639 0.0633 

[TRAIN] Epoch[1](3309/114412); Loss: 0.066174; Backpropagation: 0.2917 sec; Batch: 2.0789 sec
0.1384 0.1272 0.0868 0.0764 0.0638 0.0622 0.0559 0.0535 0.0527 0.0513 0.0505 0.0495 0.0484 0.0478 0.0474 0.0469 

[TRAIN] Epoch[1](3310/114412); Loss: 0.067116; Backpropagation: 0.2910 sec; Batch: 2.1642 sec
0.1229 0.1138 0.0891 0.0798 0.0710 0.0654 0.0603 0.0576 0.0551 0.0539 0.0525 0.0516 0.0509 0.0504 0.0499 0.0497 

[TRAIN] Epoch[1](3311/114412); Loss: 0.084812; Backpropagation: 0.2933 sec; Batch: 2.1285 sec
0.1410 0.1344 0.1073 0.0977 0.0869 0.0820 0.0780 0.0754 0.0735 0.0714 0.0703 0.0695 0.0683 0.0677 0.0670 0.0666 

[TRAIN] Epoch[1](3312/114412); Loss: 0.056518; Backpropagation: 0.2926 sec; Batch: 2.1178 sec
0.1234 0.1132 0.0689 0.0621 0.0519 0.0488 0.0484 0.0459 0.0441 0.0437 0.0434 0.0428 0.0423 0.0420 0.0417 0.0416 

[TRAIN] Epoch[1](3313/114412); Loss: 0.071074; Backpropagation: 0.2922 sec; Batch: 2.1201 sec
0.1709 0.1452 0.0935 0.0778 0.0732 0.0652 0.0611 0.0535 0.0536 0.0523 0.0507 0.0495 0.0485 0.0479 0.0474 0.0469 

[TRAIN] Epoch[1](3314/114412); Loss: 0.062390; Backpropagation: 0.2912 sec; Batch: 2.1210 sec
0.1273 0.1093 0.0872 0.0704 0.0652 0.0581 0.0550 0.0519 0.0498 0.0486 0.0474 0.0464 0.0459 0.0456 0.0453 0.0450 

[TRAIN] Epoch[1](3315/114412); Loss: 0.073540; Backpropagation: 0.2913 sec; Batch: 2.1148 sec
0.1377 0.1230 0.0953 0.0875 0.0767 0.0689 0.0657 0.0616 0.0607 0.0598 0.0582 0.0573 0.0569 0.0562 0.0558 0.0553 

[TRAIN] Epoch[1](3316/114412); Loss: 0.083263; Backpropagation: 0.2927 sec; Batch: 2.1226 sec
0.1220 0.1101 0.0965 0.0913 0.0853 0.0825 0.0792 0.0774 0.0762 0.0755 0.0742 0.0737 0.0730 0.0723 0.0717 0.0715 

[TRAIN] Epoch[1](3317/114412); Loss: 0.062417; Backpropagation: 0.2914 sec; Batch: 2.1001 sec
0.1217 0.1072 0.0818 0.0699 0.0631 0.0585 0.0553 0.0532 0.0518 0.0504 0.0493 0.0482 0.0477 0.0472 0.0468 0.0466 

[TRAIN] Epoch[1](3318/114412); Loss: 0.062890; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1148 0.1051 0.0778 0.0703 0.0652 0.0613 0.0562 0.0547 0.0529 0.0516 0.0508 0.0501 0.0494 0.0489 0.0487 0.0484 

[TRAIN] Epoch[1](3319/114412); Loss: 0.059187; Backpropagation: 0.2932 sec; Batch: 2.1223 sec
0.0944 0.0909 0.0722 0.0657 0.0631 0.0582 0.0558 0.0537 0.0520 0.0505 0.0498 0.0490 0.0485 0.0482 0.0476 0.0472 

[TRAIN] Epoch[1](3320/114412); Loss: 0.076437; Backpropagation: 0.2932 sec; Batch: 2.1177 sec
0.1601 0.1405 0.0948 0.0881 0.0750 0.0681 0.0651 0.0631 0.0616 0.0601 0.0593 0.0586 0.0578 0.0572 0.0569 0.0566 

[TRAIN] Epoch[1](3321/114412); Loss: 0.063166; Backpropagation: 0.2906 sec; Batch: 2.1195 sec
0.1121 0.0968 0.0827 0.0703 0.0637 0.0605 0.0576 0.0558 0.0544 0.0534 0.0522 0.0513 0.0505 0.0501 0.0497 0.0495 

[TRAIN] Epoch[1](3322/114412); Loss: 0.063147; Backpropagation: 0.2924 sec; Batch: 2.1156 sec
0.1262 0.1099 0.0855 0.0744 0.0673 0.0606 0.0551 0.0526 0.0515 0.0492 0.0479 0.0469 0.0464 0.0459 0.0456 0.0453 

[TRAIN] Epoch[1](3323/114412); Loss: 0.075929; Backpropagation: 0.2914 sec; Batch: 2.1204 sec
0.1562 0.1422 0.1121 0.0956 0.0810 0.0716 0.0640 0.0611 0.0581 0.0561 0.0544 0.0536 0.0528 0.0522 0.0521 0.0518 

[TRAIN] Epoch[1](3324/114412); Loss: 0.058478; Backpropagation: 0.2907 sec; Batch: 2.1166 sec
0.1175 0.1017 0.0788 0.0676 0.0609 0.0554 0.0524 0.0502 0.0474 0.0460 0.0448 0.0438 0.0430 0.0425 0.0420 0.0417 

[TRAIN] Epoch[1](3325/114412); Loss: 0.061905; Backpropagation: 0.2907 sec; Batch: 2.0966 sec
0.1287 0.1142 0.0817 0.0698 0.0634 0.0578 0.0545 0.0517 0.0497 0.0481 0.0470 0.0461 0.0453 0.0447 0.0441 0.0436 

[TRAIN] Epoch[1](3326/114412); Loss: 0.067757; Backpropagation: 0.2911 sec; Batch: 2.0793 sec
0.1307 0.1204 0.0885 0.0795 0.0682 0.0637 0.0610 0.0577 0.0556 0.0540 0.0528 0.0517 0.0510 0.0504 0.0498 0.0494 

[TRAIN] Epoch[1](3327/114412); Loss: 0.062955; Backpropagation: 0.2911 sec; Batch: 2.1028 sec
0.1130 0.1020 0.0789 0.0737 0.0670 0.0625 0.0576 0.0556 0.0538 0.0521 0.0504 0.0497 0.0488 0.0480 0.0473 0.0467 

[TRAIN] Epoch[1](3328/114412); Loss: 0.067119; Backpropagation: 0.2913 sec; Batch: 2.1209 sec
0.1105 0.0995 0.0841 0.0760 0.0682 0.0651 0.0619 0.0600 0.0589 0.0580 0.0567 0.0560 0.0554 0.0549 0.0545 0.0542 

[TRAIN] Epoch[1](3329/114412); Loss: 0.053771; Backpropagation: 0.2932 sec; Batch: 2.0798 sec
0.1203 0.1101 0.0714 0.0585 0.0518 0.0501 0.0467 0.0441 0.0422 0.0405 0.0391 0.0382 0.0375 0.0370 0.0365 0.0362 

[TRAIN] Epoch[1](3330/114412); Loss: 0.066497; Backpropagation: 0.2927 sec; Batch: 2.0851 sec
0.1272 0.1148 0.0872 0.0740 0.0663 0.0618 0.0586 0.0566 0.0548 0.0536 0.0526 0.0522 0.0518 0.0511 0.0509 0.0504 

[TRAIN] Epoch[1](3331/114412); Loss: 0.074619; Backpropagation: 0.2913 sec; Batch: 2.0798 sec
0.1514 0.1414 0.1006 0.0888 0.0760 0.0687 0.0653 0.0610 0.0593 0.0573 0.0558 0.0549 0.0541 0.0536 0.0530 0.0526 

[TRAIN] Epoch[1](3332/114412); Loss: 0.059696; Backpropagation: 0.2929 sec; Batch: 2.1235 sec
0.1438 0.1243 0.0778 0.0694 0.0633 0.0540 0.0513 0.0473 0.0446 0.0431 0.0415 0.0404 0.0397 0.0388 0.0382 0.0378 

[TRAIN] Epoch[1](3333/114412); Loss: 0.066137; Backpropagation: 0.2908 sec; Batch: 2.1141 sec
0.1143 0.1067 0.0820 0.0750 0.0747 0.0669 0.0604 0.0580 0.0564 0.0546 0.0531 0.0524 0.0517 0.0512 0.0506 0.0503 

[TRAIN] Epoch[1](3334/114412); Loss: 0.080032; Backpropagation: 0.2926 sec; Batch: 2.1190 sec
0.1746 0.1509 0.1004 0.0895 0.0814 0.0729 0.0694 0.0663 0.0639 0.0618 0.0601 0.0592 0.0584 0.0578 0.0572 0.0567 

[TRAIN] Epoch[1](3335/114412); Loss: 0.068811; Backpropagation: 0.2916 sec; Batch: 2.1186 sec
0.1236 0.1101 0.0878 0.0783 0.0729 0.0663 0.0625 0.0606 0.0585 0.0569 0.0557 0.0547 0.0539 0.0534 0.0530 0.0527 

[TRAIN] Epoch[1](3336/114412); Loss: 0.055630; Backpropagation: 0.2908 sec; Batch: 2.1133 sec
0.1243 0.1057 0.0818 0.0711 0.0591 0.0509 0.0478 0.0442 0.0424 0.0405 0.0389 0.0378 0.0372 0.0365 0.0360 0.0357 

[TRAIN] Epoch[1](3337/114412); Loss: 0.054971; Backpropagation: 0.2908 sec; Batch: 2.1189 sec
0.0900 0.0787 0.0707 0.0650 0.0564 0.0535 0.0510 0.0494 0.0482 0.0472 0.0462 0.0455 0.0450 0.0446 0.0442 0.0439 

[TRAIN] Epoch[1](3338/114412); Loss: 0.066541; Backpropagation: 0.2929 sec; Batch: 2.1234 sec
0.1470 0.1346 0.0946 0.0837 0.0705 0.0607 0.0565 0.0534 0.0503 0.0482 0.0465 0.0454 0.0444 0.0437 0.0429 0.0423 

[TRAIN] Epoch[1](3339/114412); Loss: 0.068669; Backpropagation: 0.2909 sec; Batch: 2.1196 sec
0.1500 0.1357 0.0964 0.0803 0.0642 0.0609 0.0582 0.0549 0.0524 0.0510 0.0505 0.0499 0.0492 0.0488 0.0484 0.0480 

[TRAIN] Epoch[1](3340/114412); Loss: 0.086307; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1414 0.1220 0.1066 0.0980 0.0900 0.0841 0.0810 0.0790 0.0765 0.0744 0.0733 0.0725 0.0715 0.0708 0.0703 0.0697 

[TRAIN] Epoch[1](3341/114412); Loss: 0.086596; Backpropagation: 0.2911 sec; Batch: 2.1187 sec
0.1626 0.1461 0.1228 0.1069 0.0914 0.0815 0.0746 0.0715 0.0696 0.0680 0.0668 0.0660 0.0655 0.0646 0.0641 0.0636 

[TRAIN] Epoch[1](3342/114412); Loss: 0.066151; Backpropagation: 0.2908 sec; Batch: 2.1162 sec
0.1112 0.0997 0.0821 0.0752 0.0685 0.0637 0.0609 0.0589 0.0575 0.0562 0.0553 0.0546 0.0541 0.0538 0.0534 0.0532 

[TRAIN] Epoch[1](3343/114412); Loss: 0.073825; Backpropagation: 0.2907 sec; Batch: 2.1135 sec
0.1243 0.1124 0.0981 0.0863 0.0778 0.0716 0.0679 0.0651 0.0630 0.0616 0.0605 0.0595 0.0589 0.0584 0.0580 0.0577 

[TRAIN] Epoch[1](3344/114412); Loss: 0.078605; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1189 0.1106 0.0966 0.0899 0.0830 0.0776 0.0738 0.0720 0.0705 0.0687 0.0677 0.0668 0.0660 0.0655 0.0652 0.0649 

[TRAIN] Epoch[1](3345/114412); Loss: 0.068615; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1317 0.1197 0.0898 0.0846 0.0729 0.0662 0.0624 0.0585 0.0560 0.0542 0.0528 0.0514 0.0504 0.0496 0.0490 0.0486 

[TRAIN] Epoch[1](3346/114412); Loss: 0.083454; Backpropagation: 0.2928 sec; Batch: 2.1190 sec
0.1543 0.1404 0.1028 0.0943 0.0813 0.0789 0.0754 0.0727 0.0703 0.0688 0.0678 0.0669 0.0662 0.0656 0.0650 0.0645 

[TRAIN] Epoch[1](3347/114412); Loss: 0.063863; Backpropagation: 0.2929 sec; Batch: 2.1254 sec
0.1155 0.1007 0.0771 0.0732 0.0677 0.0622 0.0586 0.0559 0.0539 0.0527 0.0520 0.0515 0.0509 0.0504 0.0500 0.0497 

[TRAIN] Epoch[1](3348/114412); Loss: 0.063318; Backpropagation: 0.2912 sec; Batch: 2.1199 sec
0.1095 0.1009 0.0834 0.0771 0.0671 0.0616 0.0570 0.0551 0.0533 0.0518 0.0507 0.0500 0.0493 0.0490 0.0487 0.0485 

[TRAIN] Epoch[1](3349/114412); Loss: 0.095371; Backpropagation: 0.2925 sec; Batch: 2.1160 sec
0.1614 0.1498 0.1194 0.1103 0.0981 0.0907 0.0869 0.0841 0.0820 0.0804 0.0793 0.0781 0.0772 0.0767 0.0760 0.0754 

[TRAIN] Epoch[1](3350/114412); Loss: 0.083229; Backpropagation: 0.2926 sec; Batch: 2.1215 sec
0.1301 0.1199 0.0995 0.0913 0.0846 0.0806 0.0782 0.0766 0.0750 0.0736 0.0723 0.0714 0.0705 0.0696 0.0693 0.0689 

[TRAIN] Epoch[1](3351/114412); Loss: 0.063656; Backpropagation: 0.2910 sec; Batch: 2.0796 sec
0.1015 0.0913 0.0837 0.0760 0.0650 0.0610 0.0584 0.0568 0.0556 0.0546 0.0537 0.0531 0.0524 0.0520 0.0517 0.0515 

[TRAIN] Epoch[1](3352/114412); Loss: 0.094818; Backpropagation: 0.2912 sec; Batch: 2.1456 sec
0.1563 0.1303 0.1101 0.1032 0.0955 0.0901 0.0876 0.0866 0.0851 0.0840 0.0828 0.0821 0.0814 0.0810 0.0806 0.0803 

[TRAIN] Epoch[1](3353/114412); Loss: 0.080632; Backpropagation: 0.2909 sec; Batch: 2.1212 sec
0.1522 0.1344 0.1083 0.0938 0.0823 0.0755 0.0712 0.0687 0.0670 0.0650 0.0639 0.0629 0.0621 0.0615 0.0610 0.0604 

[TRAIN] Epoch[1](3354/114412); Loss: 0.057387; Backpropagation: 0.2915 sec; Batch: 2.1183 sec
0.1246 0.1004 0.0877 0.0694 0.0591 0.0527 0.0487 0.0462 0.0443 0.0428 0.0419 0.0410 0.0405 0.0400 0.0396 0.0392 

[TRAIN] Epoch[1](3355/114412); Loss: 0.064028; Backpropagation: 0.2911 sec; Batch: 2.1258 sec
0.1177 0.1053 0.0791 0.0684 0.0636 0.0616 0.0591 0.0570 0.0545 0.0533 0.0523 0.0516 0.0508 0.0505 0.0501 0.0498 

[TRAIN] Epoch[1](3356/114412); Loss: 0.065001; Backpropagation: 0.2955 sec; Batch: 2.1254 sec
0.1307 0.1189 0.0877 0.0789 0.0668 0.0605 0.0569 0.0537 0.0518 0.0506 0.0492 0.0482 0.0473 0.0467 0.0462 0.0459 

[TRAIN] Epoch[1](3357/114412); Loss: 0.063503; Backpropagation: 0.2953 sec; Batch: 2.1377 sec
0.1068 0.0996 0.0806 0.0743 0.0660 0.0613 0.0578 0.0560 0.0545 0.0533 0.0524 0.0516 0.0511 0.0506 0.0503 0.0500 

[TRAIN] Epoch[1](3358/114412); Loss: 0.059782; Backpropagation: 0.2952 sec; Batch: 2.1247 sec
0.0934 0.0863 0.0805 0.0731 0.0647 0.0605 0.0570 0.0535 0.0517 0.0501 0.0492 0.0484 0.0478 0.0471 0.0467 0.0464 

[TRAIN] Epoch[1](3359/114412); Loss: 0.053216; Backpropagation: 0.2931 sec; Batch: 2.1380 sec
0.0893 0.0825 0.0700 0.0643 0.0557 0.0516 0.0483 0.0466 0.0454 0.0441 0.0435 0.0429 0.0424 0.0420 0.0416 0.0413 

[TRAIN] Epoch[1](3360/114412); Loss: 0.058926; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1130 0.1044 0.0818 0.0687 0.0623 0.0565 0.0523 0.0496 0.0479 0.0465 0.0453 0.0443 0.0434 0.0428 0.0422 0.0419 

[TRAIN] Epoch[1](3361/114412); Loss: 0.049997; Backpropagation: 0.2915 sec; Batch: 2.1203 sec
0.1093 0.0903 0.0728 0.0645 0.0510 0.0463 0.0435 0.0411 0.0392 0.0374 0.0359 0.0350 0.0341 0.0336 0.0332 0.0327 

[TRAIN] Epoch[1](3362/114412); Loss: 0.074171; Backpropagation: 0.2924 sec; Batch: 2.0812 sec
0.1269 0.1138 0.0955 0.0858 0.0770 0.0716 0.0679 0.0654 0.0636 0.0622 0.0612 0.0603 0.0597 0.0591 0.0586 0.0582 

[TRAIN] Epoch[1](3363/114412); Loss: 0.117357; Backpropagation: 0.2903 sec; Batch: 2.1313 sec
0.2038 0.1800 0.1549 0.1347 0.1265 0.1240 0.1155 0.1105 0.1043 0.1007 0.0963 0.0927 0.0878 0.0850 0.0820 0.0793 

[TRAIN] Epoch[1](3364/114412); Loss: 0.068848; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1417 0.1309 0.0997 0.0865 0.0734 0.0669 0.0605 0.0559 0.0531 0.0511 0.0489 0.0479 0.0472 0.0464 0.0459 0.0457 

[TRAIN] Epoch[1](3365/114412); Loss: 0.094722; Backpropagation: 0.2914 sec; Batch: 2.0786 sec
0.1953 0.1827 0.1435 0.1297 0.1106 0.0961 0.0845 0.0748 0.0699 0.0671 0.0638 0.0615 0.0602 0.0593 0.0586 0.0579 

[TRAIN] Epoch[1](3366/114412); Loss: 0.049543; Backpropagation: 0.2950 sec; Batch: 2.0850 sec
0.0812 0.0722 0.0840 0.0683 0.0586 0.0487 0.0449 0.0424 0.0402 0.0385 0.0373 0.0365 0.0357 0.0353 0.0347 0.0342 

[TRAIN] Epoch[1](3367/114412); Loss: 0.051494; Backpropagation: 0.2925 sec; Batch: 2.1063 sec
0.1032 0.0935 0.0739 0.0580 0.0519 0.0473 0.0453 0.0429 0.0413 0.0400 0.0391 0.0384 0.0379 0.0374 0.0370 0.0367 

[TRAIN] Epoch[1](3368/114412); Loss: 0.070220; Backpropagation: 0.2911 sec; Batch: 2.1250 sec
0.1116 0.1039 0.0850 0.0767 0.0715 0.0684 0.0658 0.0641 0.0625 0.0613 0.0602 0.0594 0.0588 0.0584 0.0580 0.0577 

[TRAIN] Epoch[1](3369/114412); Loss: 0.069275; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1086 0.1004 0.0959 0.0834 0.0710 0.0644 0.0640 0.0618 0.0604 0.0591 0.0579 0.0571 0.0566 0.0562 0.0559 0.0556 

[TRAIN] Epoch[1](3370/114412); Loss: 0.073861; Backpropagation: 0.2955 sec; Batch: 2.1378 sec
0.1334 0.1222 0.0991 0.0869 0.0775 0.0701 0.0667 0.0637 0.0614 0.0601 0.0588 0.0576 0.0569 0.0562 0.0557 0.0554 

[TRAIN] Epoch[1](3371/114412); Loss: 0.061241; Backpropagation: 0.2911 sec; Batch: 2.1209 sec
0.1155 0.1059 0.0806 0.0682 0.0611 0.0585 0.0554 0.0527 0.0507 0.0495 0.0482 0.0476 0.0471 0.0466 0.0463 0.0460 

[TRAIN] Epoch[1](3372/114412); Loss: 0.074581; Backpropagation: 0.2912 sec; Batch: 2.0989 sec
0.1337 0.1216 0.0952 0.0841 0.0748 0.0706 0.0677 0.0651 0.0635 0.0621 0.0612 0.0603 0.0594 0.0586 0.0580 0.0575 

[TRAIN] Epoch[1](3373/114412); Loss: 0.070436; Backpropagation: 0.2911 sec; Batch: 2.0854 sec
0.1222 0.1130 0.0933 0.0881 0.0721 0.0679 0.0638 0.0609 0.0590 0.0572 0.0565 0.0555 0.0549 0.0547 0.0541 0.0538 

[TRAIN] Epoch[1](3374/114412); Loss: 0.069973; Backpropagation: 0.2930 sec; Batch: 2.1183 sec
0.1332 0.1261 0.0952 0.0806 0.0706 0.0644 0.0620 0.0591 0.0573 0.0559 0.0545 0.0535 0.0527 0.0520 0.0516 0.0511 

[TRAIN] Epoch[1](3375/114412); Loss: 0.059567; Backpropagation: 0.2949 sec; Batch: 2.1146 sec
0.1216 0.1124 0.0789 0.0690 0.0605 0.0555 0.0509 0.0487 0.0474 0.0461 0.0451 0.0444 0.0437 0.0433 0.0430 0.0427 

[TRAIN] Epoch[1](3376/114412); Loss: 0.061054; Backpropagation: 0.2954 sec; Batch: 2.1180 sec
0.1072 0.0935 0.0800 0.0698 0.0644 0.0595 0.0564 0.0536 0.0519 0.0506 0.0495 0.0490 0.0485 0.0481 0.0477 0.0473 

[TRAIN] Epoch[1](3377/114412); Loss: 0.095110; Backpropagation: 0.2933 sec; Batch: 2.1215 sec
0.1392 0.1269 0.1135 0.1039 0.0975 0.0932 0.0908 0.0886 0.0871 0.0857 0.0845 0.0836 0.0827 0.0819 0.0815 0.0812 

[TRAIN] Epoch[1](3378/114412); Loss: 0.053461; Backpropagation: 0.2957 sec; Batch: 2.1192 sec
0.1275 0.1141 0.0664 0.0570 0.0526 0.0476 0.0444 0.0425 0.0405 0.0393 0.0385 0.0381 0.0374 0.0370 0.0365 0.0361 

[TRAIN] Epoch[1](3379/114412); Loss: 0.078311; Backpropagation: 0.2930 sec; Batch: 2.1179 sec
0.1921 0.1600 0.1061 0.0923 0.0883 0.0724 0.0686 0.0602 0.0570 0.0539 0.0527 0.0516 0.0504 0.0497 0.0490 0.0487 

[TRAIN] Epoch[1](3380/114412); Loss: 0.069265; Backpropagation: 0.2928 sec; Batch: 2.1199 sec
0.1167 0.1052 0.0877 0.0782 0.0712 0.0675 0.0644 0.0626 0.0605 0.0591 0.0580 0.0568 0.0561 0.0553 0.0546 0.0543 

[TRAIN] Epoch[1](3381/114412); Loss: 0.060405; Backpropagation: 0.2915 sec; Batch: 2.1172 sec
0.0985 0.0845 0.0833 0.0721 0.0643 0.0592 0.0554 0.0533 0.0521 0.0513 0.0503 0.0495 0.0488 0.0484 0.0480 0.0478 

[TRAIN] Epoch[1](3382/114412); Loss: 0.063421; Backpropagation: 0.2907 sec; Batch: 2.0766 sec
0.1188 0.1087 0.0909 0.0777 0.0689 0.0616 0.0567 0.0533 0.0510 0.0495 0.0483 0.0472 0.0464 0.0458 0.0453 0.0448 

[TRAIN] Epoch[1](3383/114412); Loss: 0.057192; Backpropagation: 0.2908 sec; Batch: 2.1293 sec
0.1126 0.1069 0.0805 0.0696 0.0603 0.0538 0.0496 0.0470 0.0454 0.0442 0.0428 0.0418 0.0410 0.0404 0.0398 0.0394 

[TRAIN] Epoch[1](3384/114412); Loss: 0.061101; Backpropagation: 0.2904 sec; Batch: 2.1139 sec
0.1006 0.0950 0.0836 0.0707 0.0646 0.0602 0.0572 0.0543 0.0518 0.0505 0.0497 0.0490 0.0485 0.0479 0.0473 0.0470 

[TRAIN] Epoch[1](3385/114412); Loss: 0.063723; Backpropagation: 0.2956 sec; Batch: 2.1231 sec
0.1248 0.1113 0.0916 0.0774 0.0654 0.0599 0.0570 0.0534 0.0512 0.0498 0.0480 0.0472 0.0463 0.0458 0.0454 0.0451 

[TRAIN] Epoch[1](3386/114412); Loss: 0.059946; Backpropagation: 0.2929 sec; Batch: 2.1260 sec
0.1375 0.1213 0.0886 0.0733 0.0635 0.0579 0.0519 0.0470 0.0441 0.0425 0.0406 0.0394 0.0386 0.0381 0.0376 0.0372 

[TRAIN] Epoch[1](3387/114412); Loss: 0.081575; Backpropagation: 0.2912 sec; Batch: 2.1207 sec
0.1337 0.1227 0.1037 0.0927 0.0850 0.0811 0.0770 0.0736 0.0713 0.0698 0.0684 0.0671 0.0659 0.0650 0.0644 0.0639 

[TRAIN] Epoch[1](3388/114412); Loss: 0.069999; Backpropagation: 0.2931 sec; Batch: 2.1197 sec
0.1492 0.1380 0.1093 0.0938 0.0763 0.0662 0.0595 0.0555 0.0522 0.0490 0.0474 0.0461 0.0453 0.0446 0.0441 0.0436 

[TRAIN] Epoch[1](3389/114412); Loss: 0.088364; Backpropagation: 0.2913 sec; Batch: 2.1158 sec
0.1717 0.1610 0.1159 0.1008 0.0891 0.0829 0.0783 0.0739 0.0716 0.0697 0.0682 0.0672 0.0666 0.0660 0.0656 0.0653 

[TRAIN] Epoch[1](3390/114412); Loss: 0.048523; Backpropagation: 0.2937 sec; Batch: 2.1206 sec
0.1213 0.1084 0.0658 0.0533 0.0451 0.0436 0.0389 0.0368 0.0354 0.0342 0.0334 0.0329 0.0325 0.0320 0.0316 0.0313 

[TRAIN] Epoch[1](3391/114412); Loss: 0.054906; Backpropagation: 0.2934 sec; Batch: 2.1201 sec
0.0925 0.0889 0.0711 0.0601 0.0562 0.0524 0.0502 0.0483 0.0471 0.0462 0.0453 0.0447 0.0443 0.0439 0.0437 0.0435 

[TRAIN] Epoch[1](3392/114412); Loss: 0.048004; Backpropagation: 0.2907 sec; Batch: 2.1146 sec
0.1078 0.0970 0.0666 0.0540 0.0458 0.0423 0.0401 0.0379 0.0371 0.0357 0.0351 0.0345 0.0340 0.0336 0.0334 0.0332 

[TRAIN] Epoch[1](3393/114412); Loss: 0.092943; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1566 0.1460 0.1161 0.1046 0.0960 0.0890 0.0850 0.0822 0.0802 0.0787 0.0774 0.0763 0.0755 0.0747 0.0745 0.0742 

[TRAIN] Epoch[1](3394/114412); Loss: 0.082073; Backpropagation: 0.2914 sec; Batch: 2.0898 sec
0.1357 0.1195 0.1028 0.0924 0.0846 0.0797 0.0762 0.0734 0.0720 0.0707 0.0693 0.0684 0.0676 0.0673 0.0670 0.0667 

[TRAIN] Epoch[1](3395/114412); Loss: 0.052598; Backpropagation: 0.2904 sec; Batch: 2.0777 sec
0.1046 0.0917 0.0618 0.0567 0.0521 0.0493 0.0469 0.0450 0.0437 0.0428 0.0421 0.0416 0.0412 0.0409 0.0407 0.0405 

[TRAIN] Epoch[1](3396/114412); Loss: 0.052146; Backpropagation: 0.2909 sec; Batch: 2.1132 sec
0.1012 0.0943 0.0692 0.0595 0.0550 0.0480 0.0454 0.0434 0.0424 0.0413 0.0405 0.0397 0.0392 0.0387 0.0384 0.0381 

[TRAIN] Epoch[1](3397/114412); Loss: 0.069691; Backpropagation: 0.2921 sec; Batch: 2.0802 sec
0.1053 0.0988 0.0828 0.0749 0.0703 0.0670 0.0651 0.0638 0.0627 0.0621 0.0614 0.0609 0.0605 0.0601 0.0598 0.0596 

[TRAIN] Epoch[1](3398/114412); Loss: 0.068357; Backpropagation: 0.2912 sec; Batch: 2.1225 sec
0.1243 0.1103 0.0831 0.0742 0.0680 0.0643 0.0616 0.0600 0.0585 0.0575 0.0567 0.0559 0.0555 0.0549 0.0546 0.0543 

[TRAIN] Epoch[1](3399/114412); Loss: 0.081425; Backpropagation: 0.2904 sec; Batch: 2.1170 sec
0.1481 0.1321 0.1123 0.0978 0.0852 0.0778 0.0725 0.0691 0.0670 0.0655 0.0644 0.0634 0.0626 0.0621 0.0616 0.0612 

[TRAIN] Epoch[1](3400/114412); Loss: 0.047744; Backpropagation: 0.2910 sec; Batch: 2.1139 sec
0.1038 0.0912 0.0591 0.0533 0.0497 0.0448 0.0408 0.0392 0.0375 0.0367 0.0358 0.0352 0.0348 0.0343 0.0339 0.0336 

[TRAIN] Epoch[1](3401/114412); Loss: 0.049945; Backpropagation: 0.2910 sec; Batch: 2.1147 sec
0.1118 0.1016 0.0684 0.0563 0.0505 0.0443 0.0410 0.0393 0.0380 0.0370 0.0361 0.0357 0.0353 0.0349 0.0346 0.0343 

[TRAIN] Epoch[1](3402/114412); Loss: 0.058130; Backpropagation: 0.2932 sec; Batch: 2.1242 sec
0.1396 0.1185 0.0894 0.0698 0.0597 0.0515 0.0466 0.0443 0.0425 0.0410 0.0396 0.0387 0.0378 0.0374 0.0370 0.0366 

[TRAIN] Epoch[1](3403/114412); Loss: 0.062651; Backpropagation: 0.2922 sec; Batch: 2.1207 sec
0.1290 0.1093 0.0853 0.0729 0.0614 0.0580 0.0554 0.0521 0.0509 0.0490 0.0480 0.0472 0.0466 0.0463 0.0457 0.0452 

[TRAIN] Epoch[1](3404/114412); Loss: 0.068257; Backpropagation: 0.2952 sec; Batch: 2.1239 sec
0.1269 0.1188 0.0830 0.0746 0.0669 0.0630 0.0610 0.0586 0.0575 0.0565 0.0556 0.0549 0.0543 0.0539 0.0535 0.0532 

[TRAIN] Epoch[1](3405/114412); Loss: 0.076993; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1611 0.1499 0.1057 0.0915 0.0785 0.0709 0.0658 0.0623 0.0601 0.0585 0.0568 0.0557 0.0550 0.0541 0.0533 0.0527 

[TRAIN] Epoch[1](3406/114412); Loss: 0.058491; Backpropagation: 0.2905 sec; Batch: 2.1165 sec
0.1255 0.1087 0.0876 0.0743 0.0617 0.0542 0.0494 0.0466 0.0444 0.0425 0.0414 0.0408 0.0402 0.0398 0.0395 0.0392 

[TRAIN] Epoch[1](3407/114412); Loss: 0.066777; Backpropagation: 0.2912 sec; Batch: 2.0780 sec
0.1106 0.0982 0.0843 0.0752 0.0705 0.0651 0.0619 0.0600 0.0584 0.0571 0.0560 0.0552 0.0545 0.0541 0.0537 0.0535 

[TRAIN] Epoch[1](3408/114412); Loss: 0.073936; Backpropagation: 0.2912 sec; Batch: 2.1171 sec
0.1472 0.1300 0.0955 0.0816 0.0730 0.0681 0.0648 0.0622 0.0604 0.0593 0.0582 0.0575 0.0569 0.0564 0.0560 0.0557 

[TRAIN] Epoch[1](3409/114412); Loss: 0.064164; Backpropagation: 0.2904 sec; Batch: 2.1171 sec
0.1367 0.1259 0.0956 0.0862 0.0670 0.0578 0.0505 0.0484 0.0477 0.0466 0.0456 0.0448 0.0441 0.0435 0.0432 0.0429 

[TRAIN] Epoch[1](3410/114412); Loss: 0.063575; Backpropagation: 0.2931 sec; Batch: 2.1155 sec
0.1249 0.1115 0.0830 0.0701 0.0605 0.0577 0.0554 0.0535 0.0524 0.0515 0.0508 0.0499 0.0494 0.0491 0.0489 0.0486 

[TRAIN] Epoch[1](3411/114412); Loss: 0.058006; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.1289 0.1189 0.0756 0.0645 0.0535 0.0512 0.0479 0.0456 0.0445 0.0438 0.0431 0.0425 0.0422 0.0420 0.0420 0.0418 

[TRAIN] Epoch[1](3412/114412); Loss: 0.088299; Backpropagation: 0.2913 sec; Batch: 2.1191 sec
0.1615 0.1419 0.1121 0.0987 0.0874 0.0833 0.0801 0.0775 0.0752 0.0737 0.0721 0.0712 0.0704 0.0696 0.0692 0.0688 

[TRAIN] Epoch[1](3413/114412); Loss: 0.097370; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1543 0.1390 0.1183 0.1090 0.1008 0.0954 0.0911 0.0889 0.0865 0.0849 0.0836 0.0825 0.0818 0.0812 0.0806 0.0801 

[TRAIN] Epoch[1](3414/114412); Loss: 0.042011; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.0857 0.0720 0.0594 0.0486 0.0420 0.0387 0.0372 0.0353 0.0341 0.0331 0.0320 0.0315 0.0310 0.0308 0.0305 0.0304 

[TRAIN] Epoch[1](3415/114412); Loss: 0.079916; Backpropagation: 0.2932 sec; Batch: 2.1047 sec
0.1697 0.1450 0.1031 0.0903 0.0777 0.0719 0.0683 0.0659 0.0642 0.0627 0.0617 0.0610 0.0599 0.0594 0.0590 0.0587 

[TRAIN] Epoch[1](3416/114412); Loss: 0.072787; Backpropagation: 0.2920 sec; Batch: 2.1161 sec
0.1438 0.1235 0.0913 0.0805 0.0731 0.0682 0.0654 0.0627 0.0606 0.0592 0.0580 0.0568 0.0560 0.0557 0.0551 0.0546 

[TRAIN] Epoch[1](3417/114412); Loss: 0.079565; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1410 0.1289 0.1011 0.0864 0.0789 0.0737 0.0715 0.0695 0.0680 0.0668 0.0658 0.0651 0.0646 0.0643 0.0639 0.0637 

[TRAIN] Epoch[1](3418/114412); Loss: 0.096377; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1759 0.1606 0.1251 0.1116 0.0970 0.0904 0.0859 0.0831 0.0811 0.0794 0.0779 0.0766 0.0756 0.0748 0.0738 0.0733 

[TRAIN] Epoch[1](3419/114412); Loss: 0.061008; Backpropagation: 0.2913 sec; Batch: 2.0780 sec
0.1257 0.1120 0.0696 0.0620 0.0563 0.0546 0.0526 0.0515 0.0507 0.0501 0.0494 0.0490 0.0485 0.0482 0.0481 0.0479 

[TRAIN] Epoch[1](3420/114412); Loss: 0.073574; Backpropagation: 0.2927 sec; Batch: 2.1119 sec
0.1658 0.1522 0.1133 0.0923 0.0676 0.0626 0.0587 0.0571 0.0550 0.0529 0.0515 0.0506 0.0499 0.0495 0.0492 0.0490 

[TRAIN] Epoch[1](3421/114412); Loss: 0.067846; Backpropagation: 0.2913 sec; Batch: 2.1157 sec
0.1284 0.1102 0.0837 0.0728 0.0676 0.0635 0.0610 0.0590 0.0575 0.0565 0.0556 0.0548 0.0544 0.0539 0.0535 0.0532 

[TRAIN] Epoch[1](3422/114412); Loss: 0.091139; Backpropagation: 0.2926 sec; Batch: 2.1144 sec
0.1455 0.1263 0.1050 0.0985 0.0926 0.0894 0.0862 0.0837 0.0822 0.0806 0.0797 0.0789 0.0782 0.0778 0.0770 0.0766 

[TRAIN] Epoch[1](3423/114412); Loss: 0.052433; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1051 0.0894 0.0732 0.0618 0.0532 0.0486 0.0457 0.0435 0.0422 0.0413 0.0405 0.0400 0.0393 0.0387 0.0384 0.0380 

[TRAIN] Epoch[1](3424/114412); Loss: 0.048303; Backpropagation: 0.2904 sec; Batch: 2.1174 sec
0.1131 0.0940 0.0639 0.0512 0.0469 0.0429 0.0410 0.0387 0.0373 0.0364 0.0358 0.0351 0.0346 0.0342 0.0339 0.0337 

[TRAIN] Epoch[1](3425/114412); Loss: 0.083142; Backpropagation: 0.2939 sec; Batch: 2.1223 sec
0.1711 0.1478 0.1079 0.0920 0.0809 0.0766 0.0739 0.0707 0.0685 0.0661 0.0651 0.0636 0.0627 0.0616 0.0611 0.0605 

[TRAIN] Epoch[1](3426/114412); Loss: 0.078244; Backpropagation: 0.2929 sec; Batch: 2.1202 sec
0.1379 0.1233 0.0973 0.0856 0.0784 0.0757 0.0722 0.0700 0.0681 0.0666 0.0651 0.0638 0.0630 0.0622 0.0616 0.0611 

[TRAIN] Epoch[1](3427/114412); Loss: 0.079266; Backpropagation: 0.2951 sec; Batch: 2.1189 sec
0.1611 0.1441 0.1122 0.0984 0.0876 0.0791 0.0729 0.0657 0.0614 0.0591 0.0577 0.0556 0.0545 0.0535 0.0528 0.0525 

[TRAIN] Epoch[1](3428/114412); Loss: 0.069738; Backpropagation: 0.2930 sec; Batch: 2.1154 sec
0.1356 0.1203 0.0902 0.0766 0.0695 0.0654 0.0620 0.0598 0.0580 0.0565 0.0556 0.0549 0.0538 0.0531 0.0525 0.0521 

[TRAIN] Epoch[1](3429/114412); Loss: 0.046503; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.1137 0.0905 0.0610 0.0509 0.0436 0.0418 0.0386 0.0366 0.0354 0.0345 0.0339 0.0333 0.0329 0.0327 0.0323 0.0321 

[TRAIN] Epoch[1](3430/114412); Loss: 0.075780; Backpropagation: 0.2910 sec; Batch: 2.0852 sec
0.1381 0.1227 0.0912 0.0813 0.0751 0.0734 0.0697 0.0671 0.0652 0.0638 0.0626 0.0615 0.0609 0.0603 0.0599 0.0596 

[TRAIN] Epoch[1](3431/114412); Loss: 0.082602; Backpropagation: 0.2904 sec; Batch: 2.0833 sec
0.1713 0.1551 0.1186 0.0970 0.0861 0.0776 0.0721 0.0675 0.0648 0.0628 0.0608 0.0597 0.0583 0.0574 0.0565 0.0558 

[TRAIN] Epoch[1](3432/114412); Loss: 0.080940; Backpropagation: 0.2913 sec; Batch: 2.0777 sec
0.1677 0.1445 0.1107 0.0939 0.0838 0.0770 0.0712 0.0680 0.0648 0.0629 0.0612 0.0600 0.0585 0.0576 0.0570 0.0564 

[TRAIN] Epoch[1](3433/114412); Loss: 0.062499; Backpropagation: 0.2912 sec; Batch: 2.0813 sec
0.1286 0.1106 0.0807 0.0710 0.0633 0.0578 0.0543 0.0521 0.0504 0.0491 0.0483 0.0477 0.0471 0.0467 0.0463 0.0460 

[TRAIN] Epoch[1](3434/114412); Loss: 0.075315; Backpropagation: 0.2913 sec; Batch: 2.0776 sec
0.1828 0.1528 0.0964 0.0788 0.0759 0.0666 0.0641 0.0584 0.0562 0.0553 0.0544 0.0536 0.0531 0.0525 0.0522 0.0520 

[TRAIN] Epoch[1](3435/114412); Loss: 0.060481; Backpropagation: 0.2906 sec; Batch: 2.0940 sec
0.1398 0.0994 0.0756 0.0665 0.0623 0.0558 0.0525 0.0506 0.0487 0.0472 0.0460 0.0455 0.0451 0.0447 0.0442 0.0439 

[TRAIN] Epoch[1](3436/114412); Loss: 0.093314; Backpropagation: 0.2910 sec; Batch: 2.1160 sec
0.1705 0.1557 0.1193 0.1079 0.0942 0.0881 0.0828 0.0798 0.0777 0.0763 0.0751 0.0744 0.0737 0.0731 0.0725 0.0721 

[TRAIN] Epoch[1](3437/114412); Loss: 0.051693; Backpropagation: 0.2905 sec; Batch: 2.1174 sec
0.1287 0.1114 0.0703 0.0586 0.0510 0.0475 0.0432 0.0404 0.0386 0.0367 0.0357 0.0345 0.0334 0.0328 0.0324 0.0319 

[TRAIN] Epoch[1](3438/114412); Loss: 0.053140; Backpropagation: 0.2913 sec; Batch: 2.1021 sec
0.1008 0.0894 0.0711 0.0632 0.0557 0.0509 0.0480 0.0459 0.0437 0.0424 0.0415 0.0405 0.0400 0.0395 0.0390 0.0386 

[TRAIN] Epoch[1](3439/114412); Loss: 0.034222; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.0818 0.0696 0.0523 0.0419 0.0371 0.0311 0.0283 0.0264 0.0244 0.0237 0.0230 0.0223 0.0218 0.0215 0.0212 0.0211 

[TRAIN] Epoch[1](3440/114412); Loss: 0.095313; Backpropagation: 0.2929 sec; Batch: 2.1189 sec
0.1530 0.1395 0.1243 0.1126 0.1019 0.0946 0.0897 0.0858 0.0826 0.0805 0.0790 0.0778 0.0769 0.0760 0.0757 0.0752 

[TRAIN] Epoch[1](3441/114412); Loss: 0.066078; Backpropagation: 0.2954 sec; Batch: 2.1196 sec
0.1442 0.1325 0.0948 0.0762 0.0632 0.0593 0.0549 0.0523 0.0505 0.0490 0.0482 0.0475 0.0468 0.0464 0.0459 0.0456 

[TRAIN] Epoch[1](3442/114412); Loss: 0.069075; Backpropagation: 0.2916 sec; Batch: 2.1145 sec
0.1274 0.1155 0.0956 0.0837 0.0720 0.0674 0.0610 0.0585 0.0559 0.0548 0.0537 0.0530 0.0523 0.0519 0.0514 0.0511 

[TRAIN] Epoch[1](3443/114412); Loss: 0.059726; Backpropagation: 0.2910 sec; Batch: 2.1230 sec
0.0944 0.0820 0.0703 0.0647 0.0616 0.0588 0.0567 0.0545 0.0534 0.0528 0.0522 0.0517 0.0511 0.0508 0.0505 0.0501 

[TRAIN] Epoch[1](3444/114412); Loss: 0.066615; Backpropagation: 0.2907 sec; Batch: 2.1224 sec
0.1630 0.1404 0.0949 0.0786 0.0638 0.0566 0.0540 0.0512 0.0487 0.0474 0.0462 0.0452 0.0446 0.0442 0.0437 0.0433 

[TRAIN] Epoch[1](3445/114412); Loss: 0.076677; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1525 0.1368 0.1034 0.0902 0.0776 0.0714 0.0668 0.0639 0.0617 0.0604 0.0593 0.0583 0.0572 0.0565 0.0557 0.0552 

[TRAIN] Epoch[1](3446/114412); Loss: 0.079023; Backpropagation: 0.2913 sec; Batch: 2.1304 sec
0.1565 0.1369 0.1008 0.0874 0.0793 0.0741 0.0698 0.0670 0.0653 0.0638 0.0625 0.0615 0.0606 0.0601 0.0595 0.0592 

[TRAIN] Epoch[1](3447/114412); Loss: 0.052213; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.1076 0.0964 0.0637 0.0565 0.0508 0.0473 0.0450 0.0438 0.0426 0.0419 0.0411 0.0404 0.0400 0.0397 0.0394 0.0392 

[TRAIN] Epoch[1](3448/114412); Loss: 0.080608; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1547 0.1325 0.1037 0.0910 0.0825 0.0775 0.0734 0.0699 0.0676 0.0656 0.0640 0.0629 0.0619 0.0611 0.0608 0.0604 

[TRAIN] Epoch[1](3449/114412); Loss: 0.068202; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1362 0.1204 0.0944 0.0796 0.0702 0.0620 0.0577 0.0559 0.0547 0.0536 0.0524 0.0517 0.0513 0.0508 0.0504 0.0501 

[TRAIN] Epoch[1](3450/114412); Loss: 0.062356; Backpropagation: 0.2905 sec; Batch: 2.0960 sec
0.1286 0.1108 0.0845 0.0701 0.0616 0.0568 0.0538 0.0522 0.0504 0.0492 0.0481 0.0474 0.0468 0.0462 0.0458 0.0454 

[TRAIN] Epoch[1](3451/114412); Loss: 0.062648; Backpropagation: 0.2912 sec; Batch: 2.1188 sec
0.1310 0.1092 0.0892 0.0761 0.0643 0.0587 0.0535 0.0509 0.0494 0.0482 0.0468 0.0461 0.0455 0.0448 0.0445 0.0441 

[TRAIN] Epoch[1](3452/114412); Loss: 0.073349; Backpropagation: 0.2914 sec; Batch: 2.1027 sec
0.1263 0.1094 0.0869 0.0817 0.0740 0.0702 0.0669 0.0653 0.0640 0.0630 0.0622 0.0616 0.0610 0.0606 0.0603 0.0600 

[TRAIN] Epoch[1](3453/114412); Loss: 0.075385; Backpropagation: 0.2911 sec; Batch: 2.1384 sec
0.1233 0.1109 0.0932 0.0861 0.0780 0.0714 0.0690 0.0668 0.0657 0.0646 0.0638 0.0633 0.0627 0.0625 0.0624 0.0623 

[TRAIN] Epoch[1](3454/114412); Loss: 0.095237; Backpropagation: 0.2953 sec; Batch: 2.1201 sec
0.1792 0.1594 0.1305 0.1204 0.1049 0.0977 0.0866 0.0802 0.0767 0.0740 0.0722 0.0704 0.0692 0.0683 0.0674 0.0667 

[TRAIN] Epoch[1](3455/114412); Loss: 0.038776; Backpropagation: 0.2916 sec; Batch: 2.0778 sec
0.0852 0.0693 0.0652 0.0524 0.0426 0.0346 0.0322 0.0307 0.0286 0.0274 0.0267 0.0257 0.0254 0.0250 0.0248 0.0246 

[TRAIN] Epoch[1](3456/114412); Loss: 0.067289; Backpropagation: 0.2913 sec; Batch: 2.1162 sec
0.1161 0.1011 0.1023 0.0875 0.0755 0.0626 0.0605 0.0571 0.0555 0.0540 0.0527 0.0518 0.0508 0.0502 0.0497 0.0491 

[TRAIN] Epoch[1](3457/114412); Loss: 0.049740; Backpropagation: 0.2926 sec; Batch: 2.0792 sec
0.1251 0.1028 0.0673 0.0563 0.0501 0.0442 0.0403 0.0382 0.0366 0.0357 0.0346 0.0338 0.0333 0.0329 0.0324 0.0322 

[TRAIN] Epoch[1](3458/114412); Loss: 0.055246; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1679 0.1323 0.0698 0.0563 0.0541 0.0469 0.0437 0.0389 0.0364 0.0357 0.0348 0.0343 0.0337 0.0333 0.0331 0.0329 

[TRAIN] Epoch[1](3459/114412); Loss: 0.049504; Backpropagation: 0.2952 sec; Batch: 2.1210 sec
0.1087 0.0895 0.0623 0.0542 0.0494 0.0452 0.0422 0.0408 0.0395 0.0384 0.0377 0.0374 0.0370 0.0368 0.0366 0.0364 

[TRAIN] Epoch[1](3460/114412); Loss: 0.077334; Backpropagation: 0.2931 sec; Batch: 2.1203 sec
0.1526 0.1372 0.1014 0.0883 0.0787 0.0719 0.0674 0.0648 0.0630 0.0612 0.0601 0.0592 0.0587 0.0581 0.0576 0.0573 

[TRAIN] Epoch[1](3461/114412); Loss: 0.052987; Backpropagation: 0.2932 sec; Batch: 2.1216 sec
0.1015 0.0938 0.0709 0.0626 0.0540 0.0506 0.0463 0.0445 0.0430 0.0417 0.0411 0.0407 0.0400 0.0394 0.0390 0.0387 

[TRAIN] Epoch[1](3462/114412); Loss: 0.084647; Backpropagation: 0.2929 sec; Batch: 2.1222 sec
0.1565 0.1364 0.1065 0.0980 0.0838 0.0798 0.0759 0.0730 0.0710 0.0696 0.0687 0.0682 0.0674 0.0669 0.0664 0.0660 

[TRAIN] Epoch[1](3463/114412); Loss: 0.070787; Backpropagation: 0.2908 sec; Batch: 2.0782 sec
0.1409 0.1299 0.0990 0.0875 0.0728 0.0672 0.0627 0.0590 0.0567 0.0543 0.0526 0.0515 0.0505 0.0499 0.0494 0.0489 

[TRAIN] Epoch[1](3464/114412); Loss: 0.080481; Backpropagation: 0.2910 sec; Batch: 2.0821 sec
0.1422 0.1267 0.1007 0.0879 0.0815 0.0769 0.0738 0.0710 0.0690 0.0676 0.0666 0.0658 0.0651 0.0646 0.0642 0.0640 

[TRAIN] Epoch[1](3465/114412); Loss: 0.077000; Backpropagation: 0.2908 sec; Batch: 2.1224 sec
0.1237 0.1140 0.0982 0.0875 0.0792 0.0737 0.0707 0.0686 0.0670 0.0659 0.0652 0.0645 0.0641 0.0636 0.0632 0.0629 

[TRAIN] Epoch[1](3466/114412); Loss: 0.046826; Backpropagation: 0.2905 sec; Batch: 2.0781 sec
0.1051 0.0857 0.0646 0.0521 0.0465 0.0427 0.0399 0.0380 0.0368 0.0358 0.0351 0.0343 0.0337 0.0333 0.0330 0.0327 

[TRAIN] Epoch[1](3467/114412); Loss: 0.064580; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1258 0.1064 0.0844 0.0758 0.0660 0.0609 0.0573 0.0549 0.0534 0.0520 0.0509 0.0502 0.0496 0.0489 0.0485 0.0482 

[TRAIN] Epoch[1](3468/114412); Loss: 0.046905; Backpropagation: 0.2912 sec; Batch: 2.1215 sec
0.1040 0.0897 0.0624 0.0550 0.0494 0.0448 0.0411 0.0381 0.0362 0.0351 0.0340 0.0331 0.0325 0.0320 0.0317 0.0314 

[TRAIN] Epoch[1](3469/114412); Loss: 0.065784; Backpropagation: 0.2909 sec; Batch: 2.1212 sec
0.1121 0.0985 0.0811 0.0735 0.0672 0.0634 0.0605 0.0585 0.0572 0.0560 0.0552 0.0546 0.0541 0.0538 0.0535 0.0533 

[TRAIN] Epoch[1](3470/114412); Loss: 0.065374; Backpropagation: 0.2910 sec; Batch: 2.1212 sec
0.1119 0.0987 0.0841 0.0733 0.0675 0.0632 0.0605 0.0584 0.0568 0.0554 0.0544 0.0536 0.0528 0.0523 0.0518 0.0513 

[TRAIN] Epoch[1](3471/114412); Loss: 0.084048; Backpropagation: 0.2932 sec; Batch: 2.1269 sec
0.1307 0.1180 0.1038 0.0934 0.0868 0.0824 0.0797 0.0771 0.0754 0.0738 0.0728 0.0717 0.0709 0.0700 0.0693 0.0689 

[TRAIN] Epoch[1](3472/114412); Loss: 0.070119; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1478 0.1278 0.0875 0.0778 0.0680 0.0634 0.0607 0.0590 0.0568 0.0550 0.0549 0.0537 0.0530 0.0525 0.0521 0.0520 

[TRAIN] Epoch[1](3473/114412); Loss: 0.081830; Backpropagation: 0.2910 sec; Batch: 2.1283 sec
0.1742 0.1513 0.1197 0.1006 0.0909 0.0788 0.0703 0.0642 0.0622 0.0605 0.0585 0.0572 0.0564 0.0554 0.0549 0.0543 

[TRAIN] Epoch[1](3474/114412); Loss: 0.073724; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1318 0.1134 0.0953 0.0831 0.0764 0.0706 0.0679 0.0651 0.0633 0.0618 0.0606 0.0595 0.0587 0.0580 0.0573 0.0567 

[TRAIN] Epoch[1](3475/114412); Loss: 0.077463; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1344 0.1213 0.1000 0.0857 0.0789 0.0750 0.0713 0.0691 0.0671 0.0653 0.0640 0.0631 0.0622 0.0614 0.0607 0.0602 

[TRAIN] Epoch[1](3476/114412); Loss: 0.066948; Backpropagation: 0.2932 sec; Batch: 2.1231 sec
0.1211 0.1066 0.0870 0.0753 0.0680 0.0639 0.0611 0.0586 0.0570 0.0556 0.0545 0.0536 0.0528 0.0524 0.0520 0.0515 

[TRAIN] Epoch[1](3477/114412); Loss: 0.067359; Backpropagation: 0.2929 sec; Batch: 2.1215 sec
0.1582 0.1369 0.0998 0.0853 0.0697 0.0601 0.0550 0.0520 0.0496 0.0479 0.0463 0.0450 0.0439 0.0432 0.0426 0.0421 

[TRAIN] Epoch[1](3478/114412); Loss: 0.081175; Backpropagation: 0.2932 sec; Batch: 2.1169 sec
0.1218 0.1165 0.0957 0.0873 0.0832 0.0792 0.0767 0.0744 0.0731 0.0721 0.0710 0.0704 0.0699 0.0695 0.0691 0.0689 

[TRAIN] Epoch[1](3479/114412); Loss: 0.087963; Backpropagation: 0.2911 sec; Batch: 2.1163 sec
0.1506 0.1329 0.1083 0.1007 0.0880 0.0838 0.0795 0.0777 0.0765 0.0750 0.0741 0.0735 0.0727 0.0720 0.0714 0.0710 

[TRAIN] Epoch[1](3480/114412); Loss: 0.062457; Backpropagation: 0.2929 sec; Batch: 2.1032 sec
0.1221 0.0999 0.0785 0.0704 0.0645 0.0592 0.0559 0.0536 0.0519 0.0510 0.0503 0.0495 0.0489 0.0482 0.0478 0.0476 

[TRAIN] Epoch[1](3481/114412); Loss: 0.066771; Backpropagation: 0.2913 sec; Batch: 2.0884 sec
0.1164 0.1129 0.0870 0.0736 0.0671 0.0628 0.0599 0.0575 0.0560 0.0551 0.0543 0.0539 0.0535 0.0531 0.0528 0.0526 

[TRAIN] Epoch[1](3482/114412); Loss: 0.062820; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1385 0.1203 0.0816 0.0703 0.0649 0.0592 0.0551 0.0524 0.0498 0.0480 0.0463 0.0453 0.0444 0.0438 0.0429 0.0424 

[TRAIN] Epoch[1](3483/114412); Loss: 0.057748; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.1066 0.1035 0.0826 0.0689 0.0603 0.0525 0.0506 0.0483 0.0462 0.0451 0.0443 0.0436 0.0432 0.0430 0.0427 0.0425 

[TRAIN] Epoch[1](3484/114412); Loss: 0.068192; Backpropagation: 0.2913 sec; Batch: 2.1140 sec
0.1478 0.1291 0.0964 0.0816 0.0696 0.0618 0.0568 0.0543 0.0526 0.0512 0.0500 0.0493 0.0486 0.0479 0.0474 0.0467 

[TRAIN] Epoch[1](3485/114412); Loss: 0.063198; Backpropagation: 0.2911 sec; Batch: 2.1140 sec
0.1105 0.1020 0.0825 0.0696 0.0649 0.0600 0.0570 0.0552 0.0536 0.0527 0.0518 0.0512 0.0506 0.0502 0.0498 0.0496 

[TRAIN] Epoch[1](3486/114412); Loss: 0.091484; Backpropagation: 0.2911 sec; Batch: 2.0858 sec
0.1468 0.1318 0.1178 0.1063 0.0967 0.0908 0.0863 0.0832 0.0804 0.0785 0.0771 0.0757 0.0742 0.0733 0.0726 0.0721 

[TRAIN] Epoch[1](3487/114412); Loss: 0.044607; Backpropagation: 0.2905 sec; Batch: 2.0777 sec
0.0977 0.0833 0.0608 0.0500 0.0448 0.0415 0.0384 0.0365 0.0350 0.0336 0.0329 0.0322 0.0322 0.0319 0.0315 0.0314 

[TRAIN] Epoch[1](3488/114412); Loss: 0.080009; Backpropagation: 0.2913 sec; Batch: 2.1209 sec
0.1258 0.1059 0.0991 0.0878 0.0812 0.0781 0.0747 0.0735 0.0721 0.0707 0.0700 0.0692 0.0686 0.0681 0.0679 0.0676 

[TRAIN] Epoch[1](3489/114412); Loss: 0.072678; Backpropagation: 0.2910 sec; Batch: 2.1146 sec
0.1350 0.1238 0.0896 0.0856 0.0754 0.0711 0.0657 0.0624 0.0603 0.0590 0.0578 0.0568 0.0559 0.0552 0.0548 0.0545 

[TRAIN] Epoch[1](3490/114412); Loss: 0.057817; Backpropagation: 0.2913 sec; Batch: 2.1229 sec
0.1132 0.0834 0.0774 0.0679 0.0630 0.0566 0.0511 0.0495 0.0480 0.0467 0.0460 0.0451 0.0446 0.0445 0.0442 0.0439 

[TRAIN] Epoch[1](3491/114412); Loss: 0.077730; Backpropagation: 0.2920 sec; Batch: 2.0789 sec
0.1240 0.1162 0.0835 0.0806 0.0777 0.0752 0.0723 0.0702 0.0693 0.0685 0.0682 0.0678 0.0677 0.0677 0.0675 0.0673 

[TRAIN] Epoch[1](3492/114412); Loss: 0.083943; Backpropagation: 0.2910 sec; Batch: 2.1148 sec
0.1562 0.1338 0.1102 0.0953 0.0872 0.0797 0.0753 0.0720 0.0698 0.0684 0.0675 0.0668 0.0660 0.0655 0.0650 0.0645 

[TRAIN] Epoch[1](3493/114412); Loss: 0.096007; Backpropagation: 0.2954 sec; Batch: 2.1264 sec
0.1498 0.1342 0.1143 0.1026 0.0992 0.0932 0.0899 0.0877 0.0861 0.0849 0.0837 0.0829 0.0825 0.0820 0.0817 0.0813 

[TRAIN] Epoch[1](3494/114412); Loss: 0.052356; Backpropagation: 0.2947 sec; Batch: 2.1200 sec
0.1068 0.1011 0.0705 0.0576 0.0515 0.0481 0.0454 0.0431 0.0415 0.0404 0.0396 0.0390 0.0387 0.0385 0.0381 0.0378 

[TRAIN] Epoch[1](3495/114412); Loss: 0.074750; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.1468 0.1373 0.1016 0.0854 0.0735 0.0688 0.0644 0.0617 0.0602 0.0588 0.0578 0.0568 0.0564 0.0558 0.0554 0.0552 

[TRAIN] Epoch[1](3496/114412); Loss: 0.069622; Backpropagation: 0.2929 sec; Batch: 2.1202 sec
0.1292 0.1108 0.0862 0.0765 0.0719 0.0654 0.0630 0.0604 0.0588 0.0578 0.0568 0.0562 0.0557 0.0553 0.0551 0.0549 

[TRAIN] Epoch[1](3497/114412); Loss: 0.050128; Backpropagation: 0.2954 sec; Batch: 2.1234 sec
0.1232 0.1181 0.0678 0.0520 0.0466 0.0479 0.0415 0.0385 0.0365 0.0346 0.0335 0.0328 0.0324 0.0323 0.0322 0.0321 

[TRAIN] Epoch[1](3498/114412); Loss: 0.081295; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1392 0.1280 0.0996 0.0877 0.0817 0.0787 0.0745 0.0716 0.0702 0.0691 0.0680 0.0674 0.0668 0.0664 0.0660 0.0658 

[TRAIN] Epoch[1](3499/114412); Loss: 0.059973; Backpropagation: 0.2905 sec; Batch: 2.1159 sec
0.1448 0.1137 0.0723 0.0645 0.0594 0.0558 0.0528 0.0489 0.0466 0.0450 0.0439 0.0433 0.0426 0.0423 0.0420 0.0417 

[TRAIN] Epoch[1](3500/114412); Loss: 0.055376; Backpropagation: 0.2910 sec; Batch: 2.1148 sec
0.0966 0.0917 0.0782 0.0656 0.0569 0.0517 0.0496 0.0477 0.0460 0.0448 0.0441 0.0432 0.0427 0.0425 0.0423 0.0422 

[TRAIN] Epoch[1](3501/114412); Loss: 0.080490; Backpropagation: 0.2906 sec; Batch: 2.1210 sec
0.1587 0.1329 0.1090 0.0889 0.0813 0.0760 0.0728 0.0687 0.0664 0.0648 0.0634 0.0623 0.0616 0.0608 0.0603 0.0599 

[TRAIN] Epoch[1](3502/114412); Loss: 0.069904; Backpropagation: 0.2905 sec; Batch: 2.1162 sec
0.1334 0.1145 0.0942 0.0801 0.0727 0.0671 0.0631 0.0600 0.0574 0.0559 0.0551 0.0542 0.0535 0.0529 0.0523 0.0521 

[TRAIN] Epoch[1](3503/114412); Loss: 0.080691; Backpropagation: 0.2926 sec; Batch: 2.1199 sec
0.1357 0.1188 0.0921 0.0889 0.0818 0.0791 0.0746 0.0727 0.0712 0.0699 0.0692 0.0685 0.0677 0.0675 0.0670 0.0666 

[TRAIN] Epoch[1](3504/114412); Loss: 0.096437; Backpropagation: 0.2909 sec; Batch: 2.1206 sec
0.1492 0.1328 0.1191 0.1071 0.1004 0.0942 0.0909 0.0889 0.0871 0.0849 0.0839 0.0830 0.0816 0.0807 0.0799 0.0794 

[TRAIN] Epoch[1](3505/114412); Loss: 0.054163; Backpropagation: 0.2929 sec; Batch: 2.1198 sec
0.1035 0.0820 0.0700 0.0612 0.0561 0.0508 0.0492 0.0468 0.0454 0.0446 0.0438 0.0433 0.0430 0.0426 0.0422 0.0421 

[TRAIN] Epoch[1](3506/114412); Loss: 0.037881; Backpropagation: 0.2929 sec; Batch: 2.1186 sec
0.1045 0.0966 0.0507 0.0380 0.0359 0.0317 0.0298 0.0267 0.0260 0.0245 0.0239 0.0241 0.0238 0.0235 0.0232 0.0234 

[TRAIN] Epoch[1](3507/114412); Loss: 0.064425; Backpropagation: 0.2914 sec; Batch: 2.1299 sec
0.1131 0.0969 0.0883 0.0734 0.0670 0.0616 0.0581 0.0562 0.0546 0.0534 0.0528 0.0520 0.0514 0.0509 0.0506 0.0504 

[TRAIN] Epoch[1](3508/114412); Loss: 0.058910; Backpropagation: 0.2907 sec; Batch: 2.1411 sec
0.1257 0.0941 0.0783 0.0681 0.0591 0.0573 0.0518 0.0493 0.0472 0.0465 0.0455 0.0450 0.0443 0.0439 0.0435 0.0432 

[TRAIN] Epoch[1](3509/114412); Loss: 0.078451; Backpropagation: 0.2916 sec; Batch: 2.1167 sec
0.1371 0.1179 0.1072 0.0956 0.0857 0.0783 0.0700 0.0668 0.0653 0.0636 0.0625 0.0616 0.0612 0.0609 0.0607 0.0605 

[TRAIN] Epoch[1](3510/114412); Loss: 0.075259; Backpropagation: 0.2909 sec; Batch: 2.1318 sec
0.1238 0.1132 0.0958 0.0850 0.0779 0.0740 0.0708 0.0685 0.0657 0.0646 0.0632 0.0620 0.0609 0.0602 0.0597 0.0589 

[TRAIN] Epoch[1](3511/114412); Loss: 0.081542; Backpropagation: 0.2909 sec; Batch: 2.1206 sec
0.1509 0.1320 0.1062 0.0908 0.0830 0.0762 0.0726 0.0704 0.0690 0.0673 0.0665 0.0655 0.0644 0.0638 0.0633 0.0627 

[TRAIN] Epoch[1](3512/114412); Loss: 0.058742; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1346 0.1188 0.0791 0.0710 0.0630 0.0545 0.0499 0.0472 0.0449 0.0421 0.0414 0.0403 0.0389 0.0385 0.0380 0.0375 

[TRAIN] Epoch[1](3513/114412); Loss: 0.078018; Backpropagation: 0.2930 sec; Batch: 2.1239 sec
0.1452 0.1247 0.1077 0.0949 0.0823 0.0752 0.0714 0.0676 0.0654 0.0626 0.0611 0.0602 0.0590 0.0577 0.0569 0.0565 

[TRAIN] Epoch[1](3514/114412); Loss: 0.075923; Backpropagation: 0.2912 sec; Batch: 2.1191 sec
0.1484 0.1291 0.1011 0.0888 0.0775 0.0707 0.0671 0.0644 0.0621 0.0602 0.0592 0.0584 0.0577 0.0572 0.0567 0.0562 

[TRAIN] Epoch[1](3515/114412); Loss: 0.051377; Backpropagation: 0.2910 sec; Batch: 2.1158 sec
0.1206 0.1104 0.0712 0.0548 0.0494 0.0450 0.0424 0.0403 0.0383 0.0370 0.0366 0.0359 0.0355 0.0350 0.0351 0.0345 

[TRAIN] Epoch[1](3516/114412); Loss: 0.083393; Backpropagation: 0.2907 sec; Batch: 2.1185 sec
0.1576 0.1431 0.1052 0.0890 0.0810 0.0785 0.0742 0.0721 0.0700 0.0686 0.0678 0.0668 0.0658 0.0652 0.0649 0.0645 

[TRAIN] Epoch[1](3517/114412); Loss: 0.082645; Backpropagation: 0.2923 sec; Batch: 2.0800 sec
0.1479 0.1275 0.1099 0.0945 0.0860 0.0805 0.0759 0.0725 0.0703 0.0678 0.0668 0.0659 0.0649 0.0644 0.0640 0.0635 

[TRAIN] Epoch[1](3518/114412); Loss: 0.058884; Backpropagation: 0.2908 sec; Batch: 2.1188 sec
0.1060 0.0865 0.0775 0.0684 0.0615 0.0573 0.0539 0.0517 0.0500 0.0487 0.0479 0.0473 0.0469 0.0465 0.0462 0.0458 

[TRAIN] Epoch[1](3519/114412); Loss: 0.057571; Backpropagation: 0.2912 sec; Batch: 2.0772 sec
0.1124 0.0859 0.0873 0.0693 0.0640 0.0554 0.0505 0.0480 0.0464 0.0451 0.0442 0.0435 0.0428 0.0424 0.0422 0.0419 

[TRAIN] Epoch[1](3520/114412); Loss: 0.075770; Backpropagation: 0.2933 sec; Batch: 2.1235 sec
0.1667 0.1464 0.1059 0.0896 0.0747 0.0680 0.0653 0.0619 0.0587 0.0565 0.0553 0.0538 0.0531 0.0526 0.0521 0.0516 

[TRAIN] Epoch[1](3521/114412); Loss: 0.060842; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.1121 0.0853 0.0742 0.0705 0.0623 0.0590 0.0568 0.0542 0.0525 0.0514 0.0506 0.0497 0.0491 0.0489 0.0486 0.0482 

[TRAIN] Epoch[1](3522/114412); Loss: 0.074071; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1495 0.1156 0.0984 0.0882 0.0765 0.0696 0.0662 0.0639 0.0614 0.0593 0.0581 0.0570 0.0562 0.0557 0.0551 0.0545 

[TRAIN] Epoch[1](3523/114412); Loss: 0.079098; Backpropagation: 0.2915 sec; Batch: 2.1186 sec
0.1740 0.1334 0.0896 0.0884 0.0811 0.0737 0.0688 0.0667 0.0644 0.0627 0.0621 0.0613 0.0604 0.0600 0.0596 0.0592 

[TRAIN] Epoch[1](3524/114412); Loss: 0.055758; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.0997 0.0922 0.0793 0.0680 0.0583 0.0528 0.0493 0.0474 0.0458 0.0447 0.0439 0.0431 0.0425 0.0420 0.0417 0.0414 

[TRAIN] Epoch[1](3525/114412); Loss: 0.075032; Backpropagation: 0.2957 sec; Batch: 2.1236 sec
0.1548 0.1313 0.0940 0.0845 0.0741 0.0696 0.0661 0.0633 0.0615 0.0600 0.0588 0.0580 0.0570 0.0563 0.0558 0.0554 

[TRAIN] Epoch[1](3526/114412); Loss: 0.072243; Backpropagation: 0.2929 sec; Batch: 2.1153 sec
0.1262 0.0954 0.0858 0.0784 0.0719 0.0688 0.0669 0.0654 0.0643 0.0634 0.0627 0.0621 0.0616 0.0614 0.0610 0.0606 

[TRAIN] Epoch[1](3527/114412); Loss: 0.061823; Backpropagation: 0.2927 sec; Batch: 2.0901 sec
0.1068 0.0936 0.0793 0.0695 0.0623 0.0593 0.0566 0.0551 0.0534 0.0523 0.0516 0.0507 0.0502 0.0499 0.0494 0.0491 

[TRAIN] Epoch[1](3528/114412); Loss: 0.073092; Backpropagation: 0.2931 sec; Batch: 2.1192 sec
0.1349 0.1205 0.0913 0.0815 0.0738 0.0680 0.0654 0.0630 0.0616 0.0603 0.0593 0.0586 0.0583 0.0580 0.0576 0.0574 

[TRAIN] Epoch[1](3529/114412); Loss: 0.065047; Backpropagation: 0.2929 sec; Batch: 2.0803 sec
0.1150 0.0887 0.0834 0.0733 0.0688 0.0633 0.0590 0.0575 0.0564 0.0553 0.0545 0.0540 0.0534 0.0530 0.0527 0.0524 

[TRAIN] Epoch[1](3530/114412); Loss: 0.079343; Backpropagation: 0.2953 sec; Batch: 2.1278 sec
0.1395 0.1155 0.1032 0.0884 0.0826 0.0777 0.0744 0.0711 0.0687 0.0671 0.0660 0.0646 0.0638 0.0629 0.0622 0.0618 

[TRAIN] Epoch[1](3531/114412); Loss: 0.067635; Backpropagation: 0.2930 sec; Batch: 2.1355 sec
0.1362 0.1156 0.0977 0.0855 0.0743 0.0657 0.0613 0.0578 0.0546 0.0512 0.0494 0.0485 0.0473 0.0464 0.0456 0.0450 

[TRAIN] Epoch[1](3532/114412); Loss: 0.082507; Backpropagation: 0.2910 sec; Batch: 2.1184 sec
0.1514 0.1268 0.1001 0.0876 0.0807 0.0777 0.0746 0.0725 0.0711 0.0700 0.0693 0.0686 0.0680 0.0676 0.0673 0.0670 

[TRAIN] Epoch[1](3533/114412); Loss: 0.052726; Backpropagation: 0.2910 sec; Batch: 2.0771 sec
0.0971 0.0778 0.0751 0.0638 0.0555 0.0504 0.0473 0.0447 0.0437 0.0426 0.0420 0.0414 0.0410 0.0408 0.0403 0.0400 

[TRAIN] Epoch[1](3534/114412); Loss: 0.067786; Backpropagation: 0.2907 sec; Batch: 2.1419 sec
0.1353 0.1139 0.0894 0.0782 0.0665 0.0628 0.0599 0.0581 0.0558 0.0546 0.0538 0.0525 0.0519 0.0512 0.0506 0.0501 

[TRAIN] Epoch[1](3535/114412); Loss: 0.072160; Backpropagation: 0.2929 sec; Batch: 2.1165 sec
0.1554 0.1358 0.1038 0.0865 0.0708 0.0646 0.0625 0.0582 0.0559 0.0546 0.0534 0.0521 0.0509 0.0505 0.0501 0.0495 

[TRAIN] Epoch[1](3536/114412); Loss: 0.056895; Backpropagation: 0.2934 sec; Batch: 2.1173 sec
0.1247 0.1059 0.0791 0.0666 0.0559 0.0517 0.0489 0.0468 0.0445 0.0432 0.0422 0.0413 0.0406 0.0401 0.0395 0.0394 

[TRAIN] Epoch[1](3537/114412); Loss: 0.077976; Backpropagation: 0.2910 sec; Batch: 2.1146 sec
0.1558 0.1335 0.1055 0.0911 0.0795 0.0731 0.0698 0.0663 0.0637 0.0617 0.0602 0.0591 0.0581 0.0574 0.0566 0.0562 

[TRAIN] Epoch[1](3538/114412); Loss: 0.066532; Backpropagation: 0.2909 sec; Batch: 2.1181 sec
0.1302 0.1095 0.0830 0.0734 0.0674 0.0642 0.0592 0.0570 0.0557 0.0540 0.0532 0.0526 0.0518 0.0514 0.0511 0.0507 

[TRAIN] Epoch[1](3539/114412); Loss: 0.088960; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1445 0.1283 0.1122 0.1007 0.0930 0.0868 0.0839 0.0816 0.0790 0.0769 0.0750 0.0740 0.0729 0.0721 0.0715 0.0709 

[TRAIN] Epoch[1](3540/114412); Loss: 0.056289; Backpropagation: 0.2904 sec; Batch: 2.0772 sec
0.1319 0.1125 0.0846 0.0664 0.0560 0.0510 0.0470 0.0441 0.0426 0.0405 0.0392 0.0383 0.0376 0.0369 0.0362 0.0358 

[TRAIN] Epoch[1](3541/114412); Loss: 0.075290; Backpropagation: 0.2912 sec; Batch: 2.1046 sec
0.1274 0.1161 0.0914 0.0810 0.0738 0.0713 0.0692 0.0674 0.0662 0.0649 0.0641 0.0635 0.0628 0.0623 0.0619 0.0614 

[TRAIN] Epoch[1](3542/114412); Loss: 0.086207; Backpropagation: 0.2905 sec; Batch: 2.1176 sec
0.1535 0.1418 0.1165 0.1001 0.0889 0.0834 0.0777 0.0739 0.0719 0.0700 0.0686 0.0678 0.0671 0.0665 0.0660 0.0656 

[TRAIN] Epoch[1](3543/114412); Loss: 0.107849; Backpropagation: 0.2909 sec; Batch: 2.1135 sec
0.1615 0.1492 0.1338 0.1185 0.1095 0.1036 0.1010 0.0984 0.0971 0.0953 0.0946 0.0938 0.0931 0.0926 0.0921 0.0917 

[TRAIN] Epoch[1](3544/114412); Loss: 0.067593; Backpropagation: 0.2908 sec; Batch: 2.1194 sec
0.1320 0.1153 0.0872 0.0743 0.0669 0.0632 0.0603 0.0579 0.0561 0.0546 0.0537 0.0530 0.0524 0.0519 0.0516 0.0512 

[TRAIN] Epoch[1](3545/114412); Loss: 0.062872; Backpropagation: 0.2917 sec; Batch: 2.1162 sec
0.1758 0.1487 0.0862 0.0643 0.0574 0.0521 0.0495 0.0465 0.0445 0.0422 0.0414 0.0403 0.0399 0.0393 0.0390 0.0388 

[TRAIN] Epoch[1](3546/114412); Loss: 0.078296; Backpropagation: 0.2911 sec; Batch: 2.1444 sec
0.1533 0.1378 0.0978 0.0838 0.0761 0.0719 0.0695 0.0669 0.0652 0.0640 0.0626 0.0618 0.0614 0.0608 0.0602 0.0598 

[TRAIN] Epoch[1](3547/114412); Loss: 0.076649; Backpropagation: 0.2929 sec; Batch: 2.1193 sec
0.1396 0.1242 0.0928 0.0819 0.0755 0.0722 0.0697 0.0675 0.0658 0.0647 0.0637 0.0628 0.0623 0.0616 0.0613 0.0609 

[TRAIN] Epoch[1](3548/114412); Loss: 0.095435; Backpropagation: 0.2931 sec; Batch: 2.1231 sec
0.1794 0.1654 0.1359 0.1212 0.1093 0.0986 0.0895 0.0821 0.0758 0.0725 0.0696 0.0676 0.0665 0.0654 0.0645 0.0637 

[TRAIN] Epoch[1](3549/114412); Loss: 0.045050; Backpropagation: 0.2931 sec; Batch: 2.1211 sec
0.1032 0.0810 0.0581 0.0493 0.0470 0.0426 0.0402 0.0377 0.0365 0.0347 0.0336 0.0326 0.0319 0.0313 0.0308 0.0304 

[TRAIN] Epoch[1](3550/114412); Loss: 0.074333; Backpropagation: 0.2926 sec; Batch: 2.1096 sec
0.1547 0.1305 0.0996 0.0851 0.0747 0.0687 0.0654 0.0628 0.0605 0.0585 0.0570 0.0557 0.0549 0.0542 0.0537 0.0532 

[TRAIN] Epoch[1](3551/114412); Loss: 0.062710; Backpropagation: 0.2931 sec; Batch: 2.1167 sec
0.1419 0.1267 0.0812 0.0715 0.0633 0.0581 0.0537 0.0502 0.0481 0.0463 0.0454 0.0445 0.0437 0.0433 0.0430 0.0425 

[TRAIN] Epoch[1](3552/114412); Loss: 0.065665; Backpropagation: 0.2934 sec; Batch: 2.1179 sec
0.1385 0.1167 0.0839 0.0719 0.0667 0.0619 0.0580 0.0551 0.0531 0.0515 0.0506 0.0498 0.0491 0.0484 0.0479 0.0476 

[TRAIN] Epoch[1](3553/114412); Loss: 0.082450; Backpropagation: 0.2915 sec; Batch: 2.0798 sec
0.1689 0.1405 0.1030 0.0863 0.0799 0.0767 0.0736 0.0710 0.0686 0.0669 0.0658 0.0648 0.0639 0.0635 0.0631 0.0627 

[TRAIN] Epoch[1](3554/114412); Loss: 0.080631; Backpropagation: 0.2905 sec; Batch: 2.1212 sec
0.1186 0.1074 0.0949 0.0892 0.0834 0.0803 0.0773 0.0758 0.0739 0.0722 0.0712 0.0702 0.0696 0.0690 0.0687 0.0682 

[TRAIN] Epoch[1](3555/114412); Loss: 0.069804; Backpropagation: 0.2907 sec; Batch: 2.0802 sec
0.1189 0.1183 0.0835 0.0787 0.0695 0.0659 0.0625 0.0605 0.0591 0.0584 0.0578 0.0573 0.0570 0.0567 0.0565 0.0562 

[TRAIN] Epoch[1](3556/114412); Loss: 0.074042; Backpropagation: 0.2914 sec; Batch: 2.1197 sec
0.1360 0.1180 0.1001 0.0879 0.0763 0.0706 0.0677 0.0648 0.0629 0.0607 0.0593 0.0577 0.0568 0.0559 0.0552 0.0547 

[TRAIN] Epoch[1](3557/114412); Loss: 0.080459; Backpropagation: 0.2912 sec; Batch: 2.1202 sec
0.1376 0.1246 0.1014 0.0918 0.0826 0.0774 0.0743 0.0723 0.0699 0.0681 0.0668 0.0657 0.0648 0.0639 0.0633 0.0627 

[TRAIN] Epoch[1](3558/114412); Loss: 0.054968; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1131 0.0969 0.0760 0.0672 0.0610 0.0528 0.0488 0.0458 0.0429 0.0414 0.0405 0.0399 0.0392 0.0384 0.0380 0.0376 

[TRAIN] Epoch[1](3559/114412); Loss: 0.068533; Backpropagation: 0.2931 sec; Batch: 2.0993 sec
0.1234 0.1084 0.0860 0.0763 0.0689 0.0656 0.0628 0.0603 0.0589 0.0572 0.0562 0.0555 0.0549 0.0544 0.0540 0.0537 

[TRAIN] Epoch[1](3560/114412); Loss: 0.075702; Backpropagation: 0.2914 sec; Batch: 2.0936 sec
0.1641 0.1401 0.1062 0.0925 0.0759 0.0719 0.0669 0.0635 0.0601 0.0573 0.0552 0.0535 0.0522 0.0513 0.0505 0.0500 

[TRAIN] Epoch[1](3561/114412); Loss: 0.097338; Backpropagation: 0.2934 sec; Batch: 2.1177 sec
0.1617 0.1416 0.1164 0.1139 0.1042 0.0979 0.0918 0.0890 0.0851 0.0836 0.0813 0.0802 0.0790 0.0781 0.0772 0.0765 

[TRAIN] Epoch[1](3562/114412); Loss: 0.089733; Backpropagation: 0.2909 sec; Batch: 2.1134 sec
0.1693 0.1495 0.1164 0.1008 0.0917 0.0866 0.0820 0.0788 0.0758 0.0737 0.0717 0.0703 0.0690 0.0678 0.0666 0.0658 

[TRAIN] Epoch[1](3563/114412); Loss: 0.078751; Backpropagation: 0.2947 sec; Batch: 2.1227 sec
0.1635 0.1404 0.1128 0.0967 0.0834 0.0740 0.0682 0.0644 0.0618 0.0597 0.0580 0.0568 0.0560 0.0553 0.0547 0.0544 

[TRAIN] Epoch[1](3564/114412); Loss: 0.065029; Backpropagation: 0.2931 sec; Batch: 2.1159 sec
0.1270 0.1094 0.0856 0.0763 0.0695 0.0656 0.0599 0.0568 0.0527 0.0509 0.0495 0.0486 0.0478 0.0473 0.0469 0.0468 

[TRAIN] Epoch[1](3565/114412); Loss: 0.067701; Backpropagation: 0.2930 sec; Batch: 2.0808 sec
0.1230 0.1003 0.0857 0.0798 0.0719 0.0655 0.0618 0.0593 0.0574 0.0562 0.0554 0.0544 0.0537 0.0533 0.0529 0.0526 

[TRAIN] Epoch[1](3566/114412); Loss: 0.050282; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1478 0.1227 0.0777 0.0566 0.0468 0.0417 0.0384 0.0356 0.0332 0.0314 0.0303 0.0294 0.0290 0.0284 0.0279 0.0276 

[TRAIN] Epoch[1](3567/114412); Loss: 0.083892; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1590 0.1354 0.1077 0.0981 0.0874 0.0805 0.0756 0.0721 0.0699 0.0681 0.0669 0.0659 0.0647 0.0641 0.0636 0.0630 

[TRAIN] Epoch[1](3568/114412); Loss: 0.068108; Backpropagation: 0.2908 sec; Batch: 2.1171 sec
0.1451 0.1265 0.0933 0.0862 0.0696 0.0627 0.0584 0.0552 0.0536 0.0515 0.0497 0.0490 0.0481 0.0477 0.0470 0.0465 

[TRAIN] Epoch[1](3569/114412); Loss: 0.086932; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1929 0.1609 0.1268 0.1073 0.0934 0.0801 0.0729 0.0689 0.0652 0.0635 0.0624 0.0609 0.0597 0.0594 0.0588 0.0579 

[TRAIN] Epoch[1](3570/114412); Loss: 0.068821; Backpropagation: 0.2905 sec; Batch: 2.1133 sec
0.1453 0.1215 0.0910 0.0804 0.0702 0.0646 0.0611 0.0584 0.0548 0.0530 0.0518 0.0510 0.0503 0.0497 0.0492 0.0488 

[TRAIN] Epoch[1](3571/114412); Loss: 0.061774; Backpropagation: 0.2929 sec; Batch: 2.1319 sec
0.1189 0.0931 0.0829 0.0742 0.0651 0.0585 0.0545 0.0524 0.0507 0.0497 0.0492 0.0486 0.0481 0.0478 0.0477 0.0472 

[TRAIN] Epoch[1](3572/114412); Loss: 0.067973; Backpropagation: 0.2911 sec; Batch: 2.1202 sec
0.1098 0.0948 0.0814 0.0752 0.0716 0.0671 0.0641 0.0628 0.0607 0.0594 0.0583 0.0574 0.0569 0.0564 0.0560 0.0558 

[TRAIN] Epoch[1](3573/114412); Loss: 0.097670; Backpropagation: 0.2912 sec; Batch: 2.1131 sec
0.1548 0.1399 0.1218 0.1121 0.1039 0.0993 0.0931 0.0893 0.0861 0.0839 0.0825 0.0811 0.0800 0.0791 0.0782 0.0776 

[TRAIN] Epoch[1](3574/114412); Loss: 0.078295; Backpropagation: 0.2906 sec; Batch: 2.0763 sec
0.1381 0.1219 0.1011 0.0884 0.0807 0.0747 0.0712 0.0692 0.0664 0.0654 0.0641 0.0634 0.0627 0.0623 0.0617 0.0614 

[TRAIN] Epoch[1](3575/114412); Loss: 0.109517; Backpropagation: 0.2912 sec; Batch: 2.4514 sec
0.1712 0.1574 0.1331 0.1227 0.1110 0.1046 0.1008 0.0984 0.0974 0.0965 0.0951 0.0943 0.0932 0.0927 0.0923 0.0916 

[TRAIN] Epoch[1](3576/114412); Loss: 0.076420; Backpropagation: 0.2915 sec; Batch: 2.1213 sec
0.1599 0.1415 0.1064 0.0927 0.0804 0.0714 0.0671 0.0625 0.0604 0.0587 0.0566 0.0549 0.0537 0.0526 0.0521 0.0518 

[TRAIN] Epoch[1](3577/114412); Loss: 0.067624; Backpropagation: 0.2913 sec; Batch: 2.1124 sec
0.1378 0.1235 0.0916 0.0825 0.0707 0.0636 0.0591 0.0554 0.0537 0.0526 0.0507 0.0495 0.0489 0.0479 0.0475 0.0470 

[TRAIN] Epoch[1](3578/114412); Loss: 0.108775; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1734 0.1472 0.1298 0.1198 0.1127 0.1084 0.1047 0.1015 0.0990 0.0965 0.0941 0.0927 0.0912 0.0903 0.0899 0.0892 

[TRAIN] Epoch[1](3579/114412); Loss: 0.075390; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1244 0.1045 0.0923 0.0843 0.0778 0.0747 0.0707 0.0685 0.0664 0.0651 0.0640 0.0635 0.0628 0.0626 0.0624 0.0620 

[TRAIN] Epoch[1](3580/114412); Loss: 0.089421; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.1607 0.1402 0.1132 0.1022 0.0913 0.0860 0.0820 0.0787 0.0763 0.0746 0.0729 0.0718 0.0710 0.0703 0.0700 0.0695 

[TRAIN] Epoch[1](3581/114412); Loss: 0.071117; Backpropagation: 0.2906 sec; Batch: 2.1193 sec
0.1774 0.1579 0.1088 0.0955 0.0739 0.0649 0.0553 0.0513 0.0479 0.0462 0.0449 0.0438 0.0433 0.0427 0.0424 0.0418 

[TRAIN] Epoch[1](3582/114412); Loss: 0.077934; Backpropagation: 0.2916 sec; Batch: 2.0843 sec
0.1316 0.1195 0.0987 0.0874 0.0803 0.0735 0.0715 0.0688 0.0671 0.0661 0.0652 0.0646 0.0639 0.0633 0.0630 0.0626 

[TRAIN] Epoch[1](3583/114412); Loss: 0.054059; Backpropagation: 0.2917 sec; Batch: 2.1178 sec
0.1106 0.0871 0.0689 0.0602 0.0522 0.0492 0.0476 0.0466 0.0452 0.0440 0.0434 0.0428 0.0423 0.0419 0.0415 0.0413 

[TRAIN] Epoch[1](3584/114412); Loss: 0.083843; Backpropagation: 0.2912 sec; Batch: 2.1206 sec
0.1520 0.1324 0.1112 0.1017 0.0893 0.0821 0.0760 0.0725 0.0702 0.0683 0.0667 0.0657 0.0645 0.0634 0.0631 0.0624 

[TRAIN] Epoch[1](3585/114412); Loss: 0.072204; Backpropagation: 0.2908 sec; Batch: 2.1248 sec
0.1174 0.1051 0.0926 0.0851 0.0766 0.0718 0.0679 0.0648 0.0629 0.0614 0.0598 0.0591 0.0583 0.0578 0.0575 0.0571 

[TRAIN] Epoch[1](3586/114412); Loss: 0.074985; Backpropagation: 0.2911 sec; Batch: 2.1423 sec
0.1297 0.1164 0.0993 0.0911 0.0818 0.0758 0.0700 0.0658 0.0630 0.0615 0.0597 0.0584 0.0579 0.0572 0.0564 0.0558 

[TRAIN] Epoch[1](3587/114412); Loss: 0.079668; Backpropagation: 0.2911 sec; Batch: 2.1542 sec
0.1352 0.1124 0.0942 0.0873 0.0798 0.0769 0.0737 0.0713 0.0692 0.0686 0.0683 0.0676 0.0677 0.0677 0.0676 0.0674 

[TRAIN] Epoch[1](3588/114412); Loss: 0.067079; Backpropagation: 0.2911 sec; Batch: 2.1418 sec
0.1329 0.0868 0.0790 0.0744 0.0696 0.0653 0.0628 0.0604 0.0588 0.0574 0.0566 0.0556 0.0545 0.0537 0.0531 0.0525 

[TRAIN] Epoch[1](3589/114412); Loss: 0.046777; Backpropagation: 0.2911 sec; Batch: 2.1054 sec
0.0980 0.0798 0.0627 0.0545 0.0469 0.0432 0.0409 0.0389 0.0378 0.0370 0.0361 0.0355 0.0350 0.0343 0.0340 0.0339 

[TRAIN] Epoch[1](3590/114412); Loss: 0.073694; Backpropagation: 0.2908 sec; Batch: 2.1226 sec
0.1604 0.1253 0.1012 0.0840 0.0746 0.0692 0.0658 0.0631 0.0592 0.0574 0.0561 0.0543 0.0532 0.0526 0.0516 0.0511 

[TRAIN] Epoch[1](3591/114412); Loss: 0.066574; Backpropagation: 0.2930 sec; Batch: 2.0815 sec
0.1335 0.1110 0.0814 0.0735 0.0662 0.0616 0.0593 0.0570 0.0554 0.0547 0.0537 0.0526 0.0521 0.0515 0.0510 0.0507 

[TRAIN] Epoch[1](3592/114412); Loss: 0.073419; Backpropagation: 0.2926 sec; Batch: 2.1090 sec
0.1461 0.1251 0.0931 0.0828 0.0717 0.0662 0.0652 0.0621 0.0607 0.0594 0.0585 0.0575 0.0572 0.0568 0.0564 0.0560 

[TRAIN] Epoch[1](3593/114412); Loss: 0.070211; Backpropagation: 0.2950 sec; Batch: 2.1555 sec
0.1401 0.1144 0.0918 0.0843 0.0777 0.0703 0.0647 0.0608 0.0575 0.0551 0.0536 0.0523 0.0512 0.0504 0.0499 0.0492 

[TRAIN] Epoch[1](3594/114412); Loss: 0.082644; Backpropagation: 0.2951 sec; Batch: 2.1215 sec
0.1667 0.1355 0.1108 0.0980 0.0848 0.0785 0.0740 0.0707 0.0691 0.0670 0.0650 0.0635 0.0617 0.0601 0.0591 0.0580 

[TRAIN] Epoch[1](3595/114412); Loss: 0.064127; Backpropagation: 0.2933 sec; Batch: 2.1063 sec
0.1241 0.1141 0.0885 0.0822 0.0712 0.0643 0.0597 0.0546 0.0503 0.0476 0.0466 0.0456 0.0451 0.0445 0.0441 0.0436 

[TRAIN] Epoch[1](3596/114412); Loss: 0.095232; Backpropagation: 0.2928 sec; Batch: 2.1341 sec
0.1596 0.1397 0.1172 0.1024 0.0972 0.0916 0.0880 0.0863 0.0841 0.0826 0.0815 0.0802 0.0796 0.0785 0.0778 0.0774 

[TRAIN] Epoch[1](3597/114412); Loss: 0.083040; Backpropagation: 0.2929 sec; Batch: 2.1227 sec
0.1769 0.1550 0.1270 0.1214 0.1015 0.0938 0.0770 0.0697 0.0571 0.0535 0.0513 0.0501 0.0491 0.0492 0.0484 0.0478 

[TRAIN] Epoch[1](3598/114412); Loss: 0.078289; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1639 0.1369 0.1076 0.0940 0.0846 0.0779 0.0716 0.0673 0.0626 0.0588 0.0568 0.0557 0.0548 0.0536 0.0534 0.0530 

[TRAIN] Epoch[1](3599/114412); Loss: 0.086273; Backpropagation: 0.2927 sec; Batch: 2.1358 sec
0.1553 0.1402 0.1131 0.1047 0.0919 0.0855 0.0786 0.0737 0.0705 0.0688 0.0683 0.0673 0.0664 0.0659 0.0654 0.0648 

[TRAIN] Epoch[1](3600/114412); Loss: 0.130931; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.1859 0.1771 0.1567 0.1496 0.1380 0.1332 0.1269 0.1225 0.1193 0.1168 0.1148 0.1133 0.1117 0.1107 0.1097 0.1088 

[TRAIN] Epoch[1](3601/114412); Loss: 0.102665; Backpropagation: 0.2909 sec; Batch: 2.1157 sec
0.1861 0.1762 0.1482 0.1360 0.1173 0.1058 0.0917 0.0824 0.0781 0.0761 0.0762 0.0748 0.0741 0.0738 0.0730 0.0728 

[TRAIN] Epoch[1](3602/114412); Loss: 0.080843; Backpropagation: 0.2908 sec; Batch: 2.1138 sec
0.1405 0.1190 0.1026 0.0924 0.0839 0.0777 0.0748 0.0726 0.0703 0.0687 0.0677 0.0667 0.0655 0.0645 0.0638 0.0630 

[TRAIN] Epoch[1](3603/114412); Loss: 0.081357; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1474 0.1320 0.1041 0.0944 0.0858 0.0794 0.0750 0.0713 0.0686 0.0668 0.0653 0.0643 0.0631 0.0622 0.0613 0.0607 

[TRAIN] Epoch[1](3604/114412); Loss: 0.048168; Backpropagation: 0.2916 sec; Batch: 2.1139 sec
0.1359 0.1199 0.0718 0.0606 0.0464 0.0421 0.0410 0.0374 0.0333 0.0292 0.0272 0.0260 0.0257 0.0251 0.0247 0.0244 

[TRAIN] Epoch[1](3605/114412); Loss: 0.064119; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.1384 0.1051 0.0876 0.0787 0.0748 0.0627 0.0573 0.0529 0.0504 0.0489 0.0472 0.0462 0.0453 0.0443 0.0435 0.0427 

[TRAIN] Epoch[1](3606/114412); Loss: 0.074703; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1407 0.1197 0.0997 0.0859 0.0784 0.0727 0.0683 0.0660 0.0631 0.0607 0.0596 0.0580 0.0568 0.0561 0.0551 0.0547 

[TRAIN] Epoch[1](3607/114412); Loss: 0.085945; Backpropagation: 0.2912 sec; Batch: 2.0965 sec
0.1409 0.1325 0.1113 0.1028 0.0939 0.0870 0.0815 0.0767 0.0733 0.0716 0.0697 0.0688 0.0675 0.0666 0.0658 0.0652 

[TRAIN] Epoch[1](3608/114412); Loss: 0.084526; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1617 0.1323 0.1111 0.0992 0.0898 0.0836 0.0763 0.0722 0.0705 0.0686 0.0670 0.0656 0.0647 0.0640 0.0631 0.0626 

[TRAIN] Epoch[1](3609/114412); Loss: 0.055104; Backpropagation: 0.2936 sec; Batch: 2.1198 sec
0.0930 0.0846 0.0713 0.0646 0.0575 0.0542 0.0522 0.0496 0.0479 0.0464 0.0450 0.0444 0.0435 0.0430 0.0423 0.0421 

[TRAIN] Epoch[1](3610/114412); Loss: 0.060679; Backpropagation: 0.2967 sec; Batch: 2.0852 sec
0.1178 0.0972 0.0744 0.0643 0.0598 0.0560 0.0538 0.0519 0.0512 0.0507 0.0499 0.0495 0.0490 0.0488 0.0485 0.0483 

[TRAIN] Epoch[1](3611/114412); Loss: 0.065106; Backpropagation: 0.2954 sec; Batch: 2.1217 sec
0.1293 0.1037 0.0893 0.0768 0.0685 0.0629 0.0580 0.0554 0.0536 0.0519 0.0505 0.0497 0.0489 0.0482 0.0477 0.0472 

[TRAIN] Epoch[1](3612/114412); Loss: 0.074059; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1473 0.1295 0.1100 0.0878 0.0776 0.0723 0.0649 0.0625 0.0595 0.0574 0.0559 0.0544 0.0525 0.0518 0.0511 0.0504 

[TRAIN] Epoch[1](3613/114412); Loss: 0.057004; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.0936 0.0917 0.0718 0.0641 0.0564 0.0535 0.0529 0.0515 0.0500 0.0485 0.0480 0.0473 0.0462 0.0460 0.0454 0.0451 

[TRAIN] Epoch[1](3614/114412); Loss: 0.071141; Backpropagation: 0.2916 sec; Batch: 2.1033 sec
0.1351 0.1094 0.0943 0.0763 0.0743 0.0720 0.0681 0.0632 0.0614 0.0585 0.0566 0.0554 0.0545 0.0536 0.0529 0.0527 

[TRAIN] Epoch[1](3615/114412); Loss: 0.080533; Backpropagation: 0.2909 sec; Batch: 2.1162 sec
0.1272 0.1175 0.1036 0.0930 0.0842 0.0789 0.0762 0.0742 0.0713 0.0696 0.0680 0.0667 0.0658 0.0648 0.0641 0.0636 

[TRAIN] Epoch[1](3616/114412); Loss: 0.080387; Backpropagation: 0.2912 sec; Batch: 2.1327 sec
0.1312 0.1209 0.0998 0.0921 0.0855 0.0790 0.0758 0.0731 0.0706 0.0691 0.0675 0.0664 0.0651 0.0641 0.0633 0.0627 

[TRAIN] Epoch[1](3617/114412); Loss: 0.063115; Backpropagation: 0.2905 sec; Batch: 2.1212 sec
0.1360 0.1079 0.0905 0.0776 0.0685 0.0619 0.0564 0.0519 0.0490 0.0476 0.0458 0.0448 0.0442 0.0432 0.0426 0.0421 

[TRAIN] Epoch[1](3618/114412); Loss: 0.066443; Backpropagation: 0.2943 sec; Batch: 2.1242 sec
0.1384 0.1252 0.0849 0.0771 0.0731 0.0607 0.0549 0.0537 0.0519 0.0508 0.0501 0.0495 0.0488 0.0485 0.0480 0.0475 

[TRAIN] Epoch[1](3619/114412); Loss: 0.108899; Backpropagation: 0.2930 sec; Batch: 2.1230 sec
0.1781 0.1536 0.1375 0.1231 0.1129 0.1094 0.1042 0.1002 0.0968 0.0947 0.0924 0.0906 0.0889 0.0877 0.0868 0.0856 

[TRAIN] Epoch[1](3620/114412); Loss: 0.073172; Backpropagation: 0.2906 sec; Batch: 2.1166 sec
0.1485 0.1280 0.0906 0.0830 0.0723 0.0684 0.0640 0.0613 0.0598 0.0588 0.0578 0.0571 0.0561 0.0555 0.0550 0.0544 

[TRAIN] Epoch[1](3621/114412); Loss: 0.083295; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1867 0.1714 0.1287 0.1042 0.0823 0.0754 0.0686 0.0644 0.0614 0.0592 0.0578 0.0564 0.0553 0.0543 0.0536 0.0531 

[TRAIN] Epoch[1](3622/114412); Loss: 0.084498; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1612 0.1431 0.1099 0.0977 0.0859 0.0783 0.0738 0.0717 0.0701 0.0687 0.0672 0.0661 0.0653 0.0647 0.0643 0.0639 

[TRAIN] Epoch[1](3623/114412); Loss: 0.089347; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1520 0.1383 0.1118 0.1047 0.0929 0.0866 0.0821 0.0783 0.0769 0.0750 0.0739 0.0730 0.0721 0.0713 0.0707 0.0700 

[TRAIN] Epoch[1](3624/114412); Loss: 0.092737; Backpropagation: 0.2913 sec; Batch: 2.1134 sec
0.1603 0.1369 0.1205 0.1051 0.0967 0.0895 0.0861 0.0833 0.0812 0.0792 0.0769 0.0754 0.0744 0.0735 0.0728 0.0719 

[TRAIN] Epoch[1](3625/114412); Loss: 0.056648; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.1015 0.0859 0.0731 0.0676 0.0581 0.0533 0.0511 0.0495 0.0481 0.0473 0.0465 0.0458 0.0452 0.0447 0.0444 0.0442 

[TRAIN] Epoch[1](3626/114412); Loss: 0.089307; Backpropagation: 0.2930 sec; Batch: 2.1185 sec
0.1548 0.1386 0.1205 0.1079 0.0976 0.0871 0.0826 0.0788 0.0751 0.0728 0.0711 0.0699 0.0689 0.0682 0.0677 0.0672 

[TRAIN] Epoch[1](3627/114412); Loss: 0.079641; Backpropagation: 0.2911 sec; Batch: 2.1150 sec
0.1358 0.1251 0.0966 0.0887 0.0827 0.0756 0.0723 0.0700 0.0686 0.0675 0.0664 0.0659 0.0653 0.0649 0.0647 0.0643 

[TRAIN] Epoch[1](3628/114412); Loss: 0.086737; Backpropagation: 0.2953 sec; Batch: 2.1210 sec
0.1394 0.1246 0.1105 0.0986 0.0899 0.0883 0.0825 0.0786 0.0757 0.0741 0.0729 0.0721 0.0710 0.0703 0.0698 0.0694 

[TRAIN] Epoch[1](3629/114412); Loss: 0.083034; Backpropagation: 0.2911 sec; Batch: 2.1218 sec
0.1399 0.1269 0.1072 0.0962 0.0873 0.0794 0.0756 0.0733 0.0714 0.0700 0.0688 0.0679 0.0671 0.0663 0.0658 0.0653 

[TRAIN] Epoch[1](3630/114412); Loss: 0.075589; Backpropagation: 0.2909 sec; Batch: 2.1201 sec
0.1412 0.1246 0.0990 0.0864 0.0771 0.0702 0.0676 0.0651 0.0635 0.0616 0.0603 0.0595 0.0589 0.0586 0.0582 0.0578 

[TRAIN] Epoch[1](3631/114412); Loss: 0.051618; Backpropagation: 0.2909 sec; Batch: 2.1137 sec
0.0959 0.0778 0.0642 0.0592 0.0542 0.0500 0.0482 0.0452 0.0435 0.0424 0.0417 0.0411 0.0409 0.0404 0.0405 0.0405 

[TRAIN] Epoch[1](3632/114412); Loss: 0.084081; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1614 0.1453 0.1001 0.0939 0.0955 0.0826 0.0773 0.0726 0.0693 0.0670 0.0656 0.0644 0.0636 0.0629 0.0623 0.0617 

[TRAIN] Epoch[1](3633/114412); Loss: 0.078756; Backpropagation: 0.2913 sec; Batch: 2.0794 sec
0.1365 0.1211 0.1061 0.0928 0.0843 0.0760 0.0724 0.0691 0.0666 0.0648 0.0639 0.0629 0.0618 0.0614 0.0604 0.0599 

[TRAIN] Epoch[1](3634/114412); Loss: 0.061784; Backpropagation: 0.2908 sec; Batch: 2.0959 sec
0.1293 0.1077 0.0928 0.0708 0.0632 0.0634 0.0560 0.0529 0.0491 0.0471 0.0448 0.0436 0.0428 0.0421 0.0417 0.0413 

[TRAIN] Epoch[1](3635/114412); Loss: 0.061237; Backpropagation: 0.2923 sec; Batch: 2.1195 sec
0.1335 0.1251 0.0806 0.0662 0.0603 0.0569 0.0531 0.0503 0.0475 0.0463 0.0450 0.0440 0.0434 0.0429 0.0425 0.0422 

[TRAIN] Epoch[1](3636/114412); Loss: 0.064849; Backpropagation: 0.2909 sec; Batch: 2.0773 sec
0.1482 0.1249 0.0833 0.0748 0.0659 0.0583 0.0556 0.0518 0.0499 0.0485 0.0474 0.0467 0.0462 0.0457 0.0454 0.0450 

[TRAIN] Epoch[1](3637/114412); Loss: 0.055822; Backpropagation: 0.2911 sec; Batch: 2.1118 sec
0.0988 0.0843 0.1026 0.0796 0.0640 0.0559 0.0492 0.0469 0.0424 0.0410 0.0397 0.0389 0.0382 0.0375 0.0372 0.0369 

[TRAIN] Epoch[1](3638/114412); Loss: 0.054572; Backpropagation: 0.2953 sec; Batch: 2.1291 sec
0.1026 0.0861 0.0719 0.0638 0.0584 0.0534 0.0504 0.0484 0.0461 0.0448 0.0432 0.0421 0.0412 0.0407 0.0402 0.0399 

[TRAIN] Epoch[1](3639/114412); Loss: 0.085014; Backpropagation: 0.2926 sec; Batch: 2.1243 sec
0.1169 0.1089 0.1027 0.0944 0.0891 0.0852 0.0824 0.0799 0.0781 0.0773 0.0760 0.0752 0.0744 0.0737 0.0734 0.0726 

[TRAIN] Epoch[1](3640/114412); Loss: 0.100578; Backpropagation: 0.2933 sec; Batch: 2.0799 sec
0.1436 0.1324 0.1171 0.1114 0.1062 0.1002 0.0972 0.0943 0.0924 0.0905 0.0896 0.0885 0.0875 0.0867 0.0860 0.0855 

[TRAIN] Epoch[1](3641/114412); Loss: 0.089289; Backpropagation: 0.2924 sec; Batch: 2.0899 sec
0.1664 0.1517 0.1239 0.1060 0.0940 0.0868 0.0803 0.0768 0.0734 0.0710 0.0685 0.0675 0.0667 0.0659 0.0652 0.0647 

[TRAIN] Epoch[1](3642/114412); Loss: 0.084707; Backpropagation: 0.2932 sec; Batch: 2.1175 sec
0.1472 0.1334 0.1241 0.1039 0.0925 0.0881 0.0806 0.0763 0.0707 0.0681 0.0651 0.0632 0.0620 0.0610 0.0600 0.0590 

[TRAIN] Epoch[1](3643/114412); Loss: 0.063472; Backpropagation: 0.2930 sec; Batch: 2.1173 sec
0.1079 0.0961 0.0784 0.0721 0.0665 0.0617 0.0590 0.0568 0.0546 0.0538 0.0529 0.0520 0.0516 0.0511 0.0507 0.0505 

[TRAIN] Epoch[1](3644/114412); Loss: 0.065994; Backpropagation: 0.2912 sec; Batch: 2.1198 sec
0.1260 0.1055 0.0887 0.0774 0.0683 0.0643 0.0599 0.0573 0.0547 0.0530 0.0520 0.0509 0.0500 0.0496 0.0491 0.0490 

[TRAIN] Epoch[1](3645/114412); Loss: 0.071225; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1287 0.1145 0.0912 0.0815 0.0730 0.0683 0.0640 0.0616 0.0599 0.0586 0.0578 0.0571 0.0565 0.0560 0.0556 0.0554 

[TRAIN] Epoch[1](3646/114412); Loss: 0.068969; Backpropagation: 0.2906 sec; Batch: 2.1163 sec
0.1203 0.1123 0.0986 0.0831 0.0764 0.0726 0.0648 0.0617 0.0572 0.0552 0.0527 0.0512 0.0502 0.0496 0.0491 0.0485 

[TRAIN] Epoch[1](3647/114412); Loss: 0.055457; Backpropagation: 0.2911 sec; Batch: 2.1105 sec
0.1060 0.0972 0.0825 0.0689 0.0614 0.0574 0.0479 0.0463 0.0431 0.0416 0.0407 0.0397 0.0393 0.0387 0.0383 0.0382 

[TRAIN] Epoch[1](3648/114412); Loss: 0.069440; Backpropagation: 0.2906 sec; Batch: 2.1216 sec
0.1336 0.1133 0.0921 0.0814 0.0713 0.0669 0.0618 0.0586 0.0570 0.0557 0.0550 0.0539 0.0533 0.0528 0.0524 0.0519 

[TRAIN] Epoch[1](3649/114412); Loss: 0.083610; Backpropagation: 0.2914 sec; Batch: 2.1057 sec
0.1555 0.1328 0.1111 0.0960 0.0849 0.0793 0.0751 0.0719 0.0702 0.0683 0.0672 0.0664 0.0657 0.0650 0.0645 0.0640 

[TRAIN] Epoch[1](3650/114412); Loss: 0.062386; Backpropagation: 0.2926 sec; Batch: 2.1214 sec
0.1354 0.1133 0.0842 0.0722 0.0643 0.0585 0.0535 0.0525 0.0494 0.0478 0.0463 0.0453 0.0445 0.0442 0.0436 0.0432 

[TRAIN] Epoch[1](3651/114412); Loss: 0.078075; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1450 0.1238 0.1068 0.0903 0.0835 0.0753 0.0694 0.0662 0.0643 0.0632 0.0619 0.0611 0.0603 0.0598 0.0593 0.0591 

[TRAIN] Epoch[1](3652/114412); Loss: 0.086777; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1846 0.1611 0.1231 0.1007 0.0885 0.0787 0.0732 0.0705 0.0678 0.0659 0.0644 0.0636 0.0627 0.0618 0.0611 0.0608 

[TRAIN] Epoch[1](3653/114412); Loss: 0.083157; Backpropagation: 0.2908 sec; Batch: 2.1172 sec
0.1553 0.1426 0.1001 0.0921 0.0911 0.0812 0.0743 0.0711 0.0690 0.0680 0.0670 0.0659 0.0648 0.0637 0.0625 0.0619 

[TRAIN] Epoch[1](3654/114412); Loss: 0.075493; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1614 0.1255 0.1049 0.0890 0.0750 0.0689 0.0640 0.0626 0.0604 0.0591 0.0579 0.0568 0.0562 0.0557 0.0553 0.0550 

[TRAIN] Epoch[1](3655/114412); Loss: 0.075731; Backpropagation: 0.2912 sec; Batch: 2.1210 sec
0.1776 0.1379 0.1416 0.1134 0.0904 0.0799 0.0648 0.0558 0.0492 0.0475 0.0457 0.0451 0.0426 0.0413 0.0401 0.0389 

[TRAIN] Epoch[1](3656/114412); Loss: 0.102722; Backpropagation: 0.2909 sec; Batch: 2.1058 sec
0.2143 0.1799 0.1470 0.1244 0.1072 0.0966 0.0863 0.0827 0.0798 0.0784 0.0766 0.0759 0.0746 0.0739 0.0733 0.0727 

[TRAIN] Epoch[1](3657/114412); Loss: 0.078095; Backpropagation: 0.2907 sec; Batch: 2.4780 sec
0.1352 0.1215 0.1030 0.0880 0.0808 0.0742 0.0706 0.0688 0.0671 0.0656 0.0642 0.0633 0.0623 0.0621 0.0616 0.0612 

[TRAIN] Epoch[1](3658/114412); Loss: 0.086601; Backpropagation: 0.2911 sec; Batch: 2.1258 sec
0.2111 0.1673 0.1343 0.0955 0.0847 0.0779 0.0741 0.0693 0.0656 0.0616 0.0595 0.0583 0.0575 0.0569 0.0562 0.0558 

[TRAIN] Epoch[1](3659/114412); Loss: 0.086463; Backpropagation: 0.2910 sec; Batch: 2.1431 sec
0.1908 0.1572 0.1272 0.1072 0.0854 0.0770 0.0743 0.0702 0.0676 0.0643 0.0630 0.0614 0.0605 0.0599 0.0588 0.0588 

[TRAIN] Epoch[1](3660/114412); Loss: 0.098511; Backpropagation: 0.2907 sec; Batch: 2.1348 sec
0.2237 0.1839 0.1518 0.1279 0.0946 0.0879 0.0868 0.0836 0.0792 0.0728 0.0697 0.0653 0.0638 0.0625 0.0616 0.0610 

[TRAIN] Epoch[1](3661/114412); Loss: 0.084300; Backpropagation: 0.2913 sec; Batch: 2.1151 sec
0.1829 0.1481 0.1155 0.0940 0.0848 0.0768 0.0727 0.0693 0.0670 0.0653 0.0641 0.0634 0.0624 0.0616 0.0608 0.0601 

[TRAIN] Epoch[1](3662/114412); Loss: 0.085579; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1729 0.1345 0.1203 0.1008 0.0863 0.0814 0.0735 0.0705 0.0695 0.0692 0.0670 0.0664 0.0651 0.0645 0.0640 0.0634 

[TRAIN] Epoch[1](3663/114412); Loss: 0.066958; Backpropagation: 0.2905 sec; Batch: 2.1207 sec
0.1774 0.1342 0.1153 0.0797 0.0698 0.0572 0.0538 0.0496 0.0480 0.0447 0.0427 0.0414 0.0402 0.0398 0.0390 0.0386 

[TRAIN] Epoch[1](3664/114412); Loss: 0.086553; Backpropagation: 0.2907 sec; Batch: 2.1134 sec
0.2146 0.1692 0.1151 0.0905 0.0896 0.0788 0.0740 0.0694 0.0660 0.0637 0.0608 0.0608 0.0588 0.0584 0.0578 0.0571 

[TRAIN] Epoch[1](3665/114412); Loss: 0.087901; Backpropagation: 0.2914 sec; Batch: 2.1229 sec
0.1863 0.1421 0.1221 0.0930 0.0857 0.0813 0.0781 0.0746 0.0733 0.0704 0.0689 0.0676 0.0668 0.0663 0.0653 0.0648 

[TRAIN] Epoch[1](3666/114412); Loss: 0.083749; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1870 0.1595 0.1293 0.0979 0.0807 0.0726 0.0696 0.0658 0.0624 0.0613 0.0606 0.0595 0.0589 0.0586 0.0584 0.0579 

[TRAIN] Epoch[1](3667/114412); Loss: 0.057425; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1007 0.0778 0.0866 0.0724 0.0596 0.0572 0.0534 0.0503 0.0484 0.0468 0.0458 0.0451 0.0440 0.0438 0.0434 0.0433 

[TRAIN] Epoch[1](3668/114412); Loss: 0.076181; Backpropagation: 0.2906 sec; Batch: 2.1138 sec
0.1661 0.1322 0.0970 0.0807 0.0745 0.0717 0.0682 0.0643 0.0630 0.0603 0.0587 0.0577 0.0568 0.0564 0.0560 0.0554 

[TRAIN] Epoch[1](3669/114412); Loss: 0.085223; Backpropagation: 0.2912 sec; Batch: 2.1310 sec
0.1605 0.1242 0.1095 0.0947 0.0859 0.0807 0.0789 0.0750 0.0733 0.0707 0.0699 0.0691 0.0684 0.0681 0.0674 0.0673 

[TRAIN] Epoch[1](3670/114412); Loss: 0.066228; Backpropagation: 0.2923 sec; Batch: 2.0820 sec
0.1640 0.1236 0.0893 0.0730 0.0681 0.0594 0.0559 0.0524 0.0508 0.0490 0.0478 0.0466 0.0458 0.0452 0.0447 0.0441 

[TRAIN] Epoch[1](3671/114412); Loss: 0.074937; Backpropagation: 0.2911 sec; Batch: 2.1153 sec
0.1587 0.1359 0.1202 0.0795 0.0765 0.0683 0.0642 0.0616 0.0596 0.0569 0.0548 0.0540 0.0526 0.0526 0.0523 0.0515 

[TRAIN] Epoch[1](3672/114412); Loss: 0.088045; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1560 0.1277 0.1157 0.1007 0.0929 0.0878 0.0837 0.0773 0.0751 0.0726 0.0712 0.0712 0.0698 0.0693 0.0692 0.0685 

[TRAIN] Epoch[1](3673/114412); Loss: 0.084887; Backpropagation: 0.2919 sec; Batch: 2.1228 sec
0.1705 0.1285 0.1121 0.0941 0.0858 0.0786 0.0751 0.0729 0.0714 0.0702 0.0686 0.0673 0.0667 0.0658 0.0655 0.0651 

[TRAIN] Epoch[1](3674/114412); Loss: 0.082443; Backpropagation: 0.2914 sec; Batch: 2.1250 sec
0.1973 0.1679 0.1012 0.0875 0.0926 0.0746 0.0678 0.0646 0.0664 0.0606 0.0582 0.0577 0.0563 0.0557 0.0557 0.0549 

[TRAIN] Epoch[1](3675/114412); Loss: 0.060319; Backpropagation: 0.2954 sec; Batch: 2.1047 sec
0.1167 0.0775 0.0822 0.0768 0.0596 0.0578 0.0559 0.0518 0.0514 0.0502 0.0490 0.0480 0.0474 0.0471 0.0470 0.0467 

[TRAIN] Epoch[1](3676/114412); Loss: 0.065265; Backpropagation: 0.2929 sec; Batch: 2.1226 sec
0.1465 0.1127 0.0895 0.0730 0.0687 0.0633 0.0568 0.0530 0.0513 0.0488 0.0481 0.0473 0.0466 0.0465 0.0461 0.0459 

[TRAIN] Epoch[1](3677/114412); Loss: 0.076521; Backpropagation: 0.2914 sec; Batch: 2.1324 sec
0.1795 0.1374 0.1129 0.0823 0.0714 0.0680 0.0648 0.0619 0.0596 0.0582 0.0568 0.0557 0.0548 0.0542 0.0537 0.0533 

[TRAIN] Epoch[1](3678/114412); Loss: 0.066387; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.1576 0.1264 0.0858 0.0770 0.0687 0.0608 0.0561 0.0528 0.0515 0.0498 0.0478 0.0468 0.0460 0.0454 0.0450 0.0447 

[TRAIN] Epoch[1](3679/114412); Loss: 0.083860; Backpropagation: 0.2910 sec; Batch: 2.0789 sec
0.1598 0.1278 0.1131 0.0968 0.0866 0.0816 0.0775 0.0724 0.0705 0.0680 0.0667 0.0659 0.0646 0.0640 0.0634 0.0631 

[TRAIN] Epoch[1](3680/114412); Loss: 0.066111; Backpropagation: 0.2904 sec; Batch: 2.0809 sec
0.1324 0.1179 0.1021 0.0742 0.0667 0.0623 0.0590 0.0548 0.0529 0.0512 0.0494 0.0484 0.0473 0.0470 0.0462 0.0459 

[TRAIN] Epoch[1](3681/114412); Loss: 0.067146; Backpropagation: 0.2907 sec; Batch: 2.1147 sec
0.1894 0.1504 0.0971 0.0855 0.0548 0.0509 0.0535 0.0498 0.0467 0.0450 0.0434 0.0428 0.0420 0.0413 0.0411 0.0407 

[TRAIN] Epoch[1](3682/114412); Loss: 0.075540; Backpropagation: 0.2949 sec; Batch: 2.1178 sec
0.1529 0.1231 0.1003 0.0901 0.0776 0.0707 0.0665 0.0639 0.0616 0.0597 0.0588 0.0579 0.0571 0.0566 0.0561 0.0558 

[TRAIN] Epoch[1](3683/114412); Loss: 0.052323; Backpropagation: 0.2914 sec; Batch: 2.1212 sec
0.1450 0.1169 0.0827 0.0607 0.0460 0.0429 0.0389 0.0389 0.0372 0.0351 0.0345 0.0332 0.0320 0.0316 0.0310 0.0307 

[TRAIN] Epoch[1](3684/114412); Loss: 0.084337; Backpropagation: 0.2912 sec; Batch: 2.1292 sec
0.1942 0.1376 0.1096 0.0896 0.0822 0.0769 0.0751 0.0714 0.0688 0.0672 0.0656 0.0643 0.0631 0.0616 0.0615 0.0608 

[TRAIN] Epoch[1](3685/114412); Loss: 0.055159; Backpropagation: 0.2930 sec; Batch: 2.1165 sec
0.1090 0.1021 0.0850 0.0745 0.0581 0.0533 0.0462 0.0440 0.0424 0.0404 0.0395 0.0386 0.0379 0.0375 0.0371 0.0369 

[TRAIN] Epoch[1](3686/114412); Loss: 0.070458; Backpropagation: 0.2927 sec; Batch: 2.1213 sec
0.1662 0.1186 0.0979 0.0773 0.0671 0.0623 0.0595 0.0573 0.0565 0.0544 0.0534 0.0525 0.0518 0.0514 0.0508 0.0504 

[TRAIN] Epoch[1](3687/114412); Loss: 0.065673; Backpropagation: 0.2904 sec; Batch: 2.1131 sec
0.1246 0.1039 0.0930 0.0793 0.0664 0.0644 0.0600 0.0564 0.0545 0.0523 0.0507 0.0500 0.0496 0.0488 0.0485 0.0484 

[TRAIN] Epoch[1](3688/114412); Loss: 0.066516; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.1535 0.1098 0.0949 0.0841 0.0664 0.0633 0.0572 0.0526 0.0511 0.0494 0.0489 0.0476 0.0468 0.0466 0.0461 0.0458 

[TRAIN] Epoch[1](3689/114412); Loss: 0.059505; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.1288 0.1113 0.0848 0.0666 0.0575 0.0532 0.0502 0.0478 0.0463 0.0451 0.0447 0.0437 0.0432 0.0430 0.0429 0.0429 

[TRAIN] Epoch[1](3690/114412); Loss: 0.070068; Backpropagation: 0.2955 sec; Batch: 2.1283 sec
0.1142 0.1066 0.0961 0.0834 0.0725 0.0668 0.0632 0.0615 0.0599 0.0587 0.0578 0.0571 0.0563 0.0559 0.0557 0.0553 

[TRAIN] Epoch[1](3691/114412); Loss: 0.062590; Backpropagation: 0.2937 sec; Batch: 2.1214 sec
0.1282 0.1005 0.0829 0.0744 0.0662 0.0619 0.0560 0.0515 0.0505 0.0494 0.0481 0.0476 0.0466 0.0462 0.0459 0.0456 

[TRAIN] Epoch[1](3692/114412); Loss: 0.061027; Backpropagation: 0.2928 sec; Batch: 2.1188 sec
0.1278 0.0908 0.0756 0.0656 0.0601 0.0566 0.0539 0.0528 0.0515 0.0502 0.0496 0.0494 0.0486 0.0483 0.0478 0.0478 

[TRAIN] Epoch[1](3693/114412); Loss: 0.086524; Backpropagation: 0.2911 sec; Batch: 2.1163 sec
0.1735 0.1615 0.1066 0.0928 0.0850 0.0793 0.0768 0.0727 0.0714 0.0690 0.0682 0.0670 0.0661 0.0654 0.0649 0.0644 

[TRAIN] Epoch[1](3694/114412); Loss: 0.072105; Backpropagation: 0.2932 sec; Batch: 2.0802 sec
0.1606 0.1100 0.0938 0.0784 0.0712 0.0678 0.0640 0.0606 0.0592 0.0578 0.0566 0.0559 0.0552 0.0545 0.0542 0.0540 

[TRAIN] Epoch[1](3695/114412); Loss: 0.083419; Backpropagation: 0.2951 sec; Batch: 2.1233 sec
0.1834 0.1484 0.1134 0.1013 0.0817 0.0750 0.0711 0.0687 0.0661 0.0637 0.0624 0.0610 0.0605 0.0597 0.0593 0.0590 

[TRAIN] Epoch[1](3696/114412); Loss: 0.087006; Backpropagation: 0.2929 sec; Batch: 2.1166 sec
0.1491 0.1346 0.1050 0.0926 0.0841 0.0820 0.0791 0.0773 0.0762 0.0749 0.0741 0.0736 0.0729 0.0725 0.0721 0.0719 

[TRAIN] Epoch[1](3697/114412); Loss: 0.082105; Backpropagation: 0.2927 sec; Batch: 2.1267 sec
0.1358 0.1179 0.0986 0.0893 0.0829 0.0798 0.0766 0.0746 0.0732 0.0715 0.0704 0.0698 0.0690 0.0686 0.0681 0.0677 

[TRAIN] Epoch[1](3698/114412); Loss: 0.072008; Backpropagation: 0.2908 sec; Batch: 2.0995 sec
0.1066 0.0933 0.0883 0.0834 0.0763 0.0721 0.0690 0.0664 0.0654 0.0639 0.0628 0.0622 0.0614 0.0609 0.0603 0.0600 

[TRAIN] Epoch[1](3699/114412); Loss: 0.056131; Backpropagation: 0.2912 sec; Batch: 2.0784 sec
0.1515 0.1238 0.0742 0.0623 0.0504 0.0458 0.0441 0.0419 0.0408 0.0395 0.0386 0.0382 0.0376 0.0367 0.0364 0.0362 

[TRAIN] Epoch[1](3700/114412); Loss: 0.060725; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.1517 0.1164 0.0823 0.0734 0.0636 0.0550 0.0506 0.0476 0.0457 0.0438 0.0423 0.0414 0.0404 0.0397 0.0391 0.0386 

[TRAIN] Epoch[1](3701/114412); Loss: 0.069801; Backpropagation: 0.2909 sec; Batch: 2.0789 sec
0.1437 0.1120 0.0867 0.0812 0.0704 0.0658 0.0621 0.0594 0.0579 0.0564 0.0551 0.0545 0.0536 0.0532 0.0526 0.0522 

[TRAIN] Epoch[1](3702/114412); Loss: 0.093177; Backpropagation: 0.2930 sec; Batch: 2.1286 sec
0.1961 0.1608 0.1295 0.1125 0.0951 0.0897 0.0784 0.0758 0.0734 0.0715 0.0702 0.0692 0.0682 0.0674 0.0668 0.0662 

[TRAIN] Epoch[1](3703/114412); Loss: 0.067118; Backpropagation: 0.2915 sec; Batch: 2.0785 sec
0.1255 0.1094 0.0892 0.0775 0.0684 0.0640 0.0606 0.0576 0.0560 0.0545 0.0536 0.0526 0.0520 0.0515 0.0509 0.0506 

[TRAIN] Epoch[1](3704/114412); Loss: 0.063055; Backpropagation: 0.2908 sec; Batch: 2.1004 sec
0.1396 0.1123 0.0803 0.0727 0.0635 0.0576 0.0525 0.0510 0.0499 0.0486 0.0482 0.0475 0.0469 0.0465 0.0460 0.0458 

[TRAIN] Epoch[1](3705/114412); Loss: 0.067369; Backpropagation: 0.2910 sec; Batch: 2.1195 sec
0.1320 0.1087 0.0916 0.0771 0.0682 0.0638 0.0603 0.0576 0.0558 0.0543 0.0532 0.0522 0.0515 0.0510 0.0504 0.0500 

[TRAIN] Epoch[1](3706/114412); Loss: 0.093147; Backpropagation: 0.2908 sec; Batch: 2.0965 sec
0.1709 0.1510 0.1192 0.1066 0.0973 0.0888 0.0861 0.0819 0.0792 0.0772 0.0751 0.0736 0.0724 0.0713 0.0704 0.0694 

[TRAIN] Epoch[1](3707/114412); Loss: 0.072871; Backpropagation: 0.2906 sec; Batch: 2.0767 sec
0.1888 0.1375 0.1154 0.0808 0.0720 0.0669 0.0601 0.0559 0.0538 0.0512 0.0498 0.0486 0.0472 0.0464 0.0458 0.0455 

[TRAIN] Epoch[1](3708/114412); Loss: 0.077839; Backpropagation: 0.2911 sec; Batch: 2.0937 sec
0.1855 0.1301 0.0998 0.0842 0.0761 0.0693 0.0662 0.0638 0.0625 0.0607 0.0596 0.0587 0.0579 0.0574 0.0569 0.0566 

[TRAIN] Epoch[1](3709/114412); Loss: 0.068081; Backpropagation: 0.2914 sec; Batch: 2.1154 sec
0.1757 0.1582 0.0963 0.0749 0.0690 0.0566 0.0528 0.0504 0.0482 0.0464 0.0450 0.0443 0.0435 0.0431 0.0427 0.0422 

[TRAIN] Epoch[1](3710/114412); Loss: 0.068296; Backpropagation: 0.2907 sec; Batch: 2.1273 sec
0.1334 0.0987 0.0867 0.0718 0.0670 0.0660 0.0615 0.0599 0.0584 0.0573 0.0565 0.0557 0.0555 0.0548 0.0549 0.0547 

[TRAIN] Epoch[1](3711/114412); Loss: 0.092114; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.2040 0.1846 0.1337 0.1171 0.0987 0.0889 0.0793 0.0746 0.0711 0.0645 0.0628 0.0609 0.0597 0.0587 0.0579 0.0573 

[TRAIN] Epoch[1](3712/114412); Loss: 0.067778; Backpropagation: 0.2915 sec; Batch: 2.1168 sec
0.1276 0.1126 0.0875 0.0771 0.0704 0.0634 0.0603 0.0577 0.0560 0.0550 0.0540 0.0535 0.0529 0.0525 0.0521 0.0519 

[TRAIN] Epoch[1](3713/114412); Loss: 0.064414; Backpropagation: 0.2913 sec; Batch: 2.1147 sec
0.1378 0.1152 0.0834 0.0701 0.0682 0.0596 0.0560 0.0529 0.0513 0.0504 0.0491 0.0484 0.0478 0.0472 0.0468 0.0465 

[TRAIN] Epoch[1](3714/114412); Loss: 0.057615; Backpropagation: 0.2911 sec; Batch: 2.0782 sec
0.1658 0.1349 0.0870 0.0563 0.0523 0.0455 0.0438 0.0419 0.0397 0.0384 0.0377 0.0368 0.0362 0.0356 0.0352 0.0348 

[TRAIN] Epoch[1](3715/114412); Loss: 0.066118; Backpropagation: 0.2907 sec; Batch: 2.1172 sec
0.1299 0.1118 0.1028 0.0750 0.0698 0.0608 0.0581 0.0537 0.0528 0.0512 0.0501 0.0494 0.0489 0.0483 0.0477 0.0476 

[TRAIN] Epoch[1](3716/114412); Loss: 0.075050; Backpropagation: 0.2904 sec; Batch: 2.0772 sec
0.1782 0.1521 0.0957 0.0860 0.0724 0.0650 0.0635 0.0592 0.0576 0.0555 0.0542 0.0536 0.0529 0.0519 0.0519 0.0511 

[TRAIN] Epoch[1](3717/114412); Loss: 0.065039; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1372 0.1080 0.0924 0.0744 0.0665 0.0607 0.0565 0.0541 0.0519 0.0507 0.0497 0.0489 0.0482 0.0476 0.0471 0.0467 

[TRAIN] Epoch[1](3718/114412); Loss: 0.072188; Backpropagation: 0.2910 sec; Batch: 2.0980 sec
0.1517 0.1188 0.0958 0.0782 0.0696 0.0664 0.0631 0.0615 0.0597 0.0582 0.0572 0.0563 0.0554 0.0548 0.0543 0.0539 

[TRAIN] Epoch[1](3719/114412); Loss: 0.079698; Backpropagation: 0.2912 sec; Batch: 2.1206 sec
0.1888 0.1458 0.1122 0.0962 0.0893 0.0743 0.0683 0.0623 0.0588 0.0565 0.0555 0.0547 0.0539 0.0534 0.0529 0.0525 

[TRAIN] Epoch[1](3720/114412); Loss: 0.057771; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1443 0.1092 0.0874 0.0661 0.0565 0.0511 0.0468 0.0442 0.0429 0.0416 0.0405 0.0398 0.0390 0.0386 0.0383 0.0379 

[TRAIN] Epoch[1](3721/114412); Loss: 0.069680; Backpropagation: 0.2910 sec; Batch: 2.1019 sec
0.1498 0.1216 0.0922 0.0839 0.0729 0.0669 0.0601 0.0576 0.0550 0.0532 0.0521 0.0512 0.0504 0.0498 0.0493 0.0490 

[TRAIN] Epoch[1](3722/114412); Loss: 0.066428; Backpropagation: 0.2915 sec; Batch: 2.1219 sec
0.1714 0.1347 0.0975 0.0857 0.0666 0.0595 0.0525 0.0502 0.0470 0.0455 0.0443 0.0430 0.0422 0.0414 0.0410 0.0406 

[TRAIN] Epoch[1](3723/114412); Loss: 0.070259; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1379 0.1096 0.0902 0.0804 0.0706 0.0673 0.0634 0.0608 0.0590 0.0573 0.0563 0.0554 0.0547 0.0542 0.0537 0.0533 

[TRAIN] Epoch[1](3724/114412); Loss: 0.098065; Backpropagation: 0.2908 sec; Batch: 2.0932 sec
0.1921 0.1549 0.1280 0.1104 0.1006 0.0942 0.0894 0.0854 0.0822 0.0805 0.0780 0.0767 0.0755 0.0745 0.0737 0.0730 

[TRAIN] Epoch[1](3725/114412); Loss: 0.071300; Backpropagation: 0.2912 sec; Batch: 2.1231 sec
0.1358 0.1049 0.0799 0.0767 0.0721 0.0685 0.0654 0.0635 0.0621 0.0608 0.0600 0.0591 0.0586 0.0581 0.0577 0.0574 

[TRAIN] Epoch[1](3726/114412); Loss: 0.066372; Backpropagation: 0.2920 sec; Batch: 2.0801 sec
0.1253 0.1018 0.0814 0.0778 0.0673 0.0636 0.0601 0.0578 0.0561 0.0547 0.0541 0.0535 0.0527 0.0523 0.0519 0.0516 

[TRAIN] Epoch[1](3727/114412); Loss: 0.069826; Backpropagation: 0.2911 sec; Batch: 2.0780 sec
0.1399 0.0987 0.0826 0.0758 0.0711 0.0664 0.0644 0.0618 0.0600 0.0587 0.0577 0.0570 0.0564 0.0558 0.0557 0.0551 

[TRAIN] Epoch[1](3728/114412); Loss: 0.061958; Backpropagation: 0.2929 sec; Batch: 2.0790 sec
0.1320 0.1124 0.0852 0.0736 0.0625 0.0590 0.0533 0.0509 0.0491 0.0472 0.0461 0.0454 0.0445 0.0439 0.0434 0.0429 

[TRAIN] Epoch[1](3729/114412); Loss: 0.070532; Backpropagation: 0.2951 sec; Batch: 2.1195 sec
0.1130 0.1004 0.0884 0.0805 0.0735 0.0687 0.0659 0.0636 0.0620 0.0609 0.0599 0.0592 0.0587 0.0583 0.0579 0.0577 

[TRAIN] Epoch[1](3730/114412); Loss: 0.082175; Backpropagation: 0.2954 sec; Batch: 2.1338 sec
0.1628 0.1338 0.1121 0.0934 0.0798 0.0758 0.0716 0.0691 0.0675 0.0663 0.0653 0.0646 0.0639 0.0633 0.0629 0.0626 

[TRAIN] Epoch[1](3731/114412); Loss: 0.057183; Backpropagation: 0.2907 sec; Batch: 2.1194 sec
0.1227 0.0991 0.0746 0.0706 0.0581 0.0547 0.0499 0.0468 0.0453 0.0444 0.0432 0.0426 0.0414 0.0409 0.0405 0.0401 

[TRAIN] Epoch[1](3732/114412); Loss: 0.061774; Backpropagation: 0.2911 sec; Batch: 2.1372 sec
0.1390 0.1012 0.0771 0.0699 0.0611 0.0569 0.0538 0.0513 0.0501 0.0489 0.0478 0.0473 0.0465 0.0461 0.0459 0.0454 

[TRAIN] Epoch[1](3733/114412); Loss: 0.064957; Backpropagation: 0.2911 sec; Batch: 2.2683 sec
0.1336 0.1039 0.0810 0.0729 0.0666 0.0614 0.0589 0.0562 0.0543 0.0526 0.0516 0.0504 0.0497 0.0492 0.0487 0.0483 

[TRAIN] Epoch[1](3734/114412); Loss: 0.066213; Backpropagation: 0.2948 sec; Batch: 2.1159 sec
0.1587 0.1250 0.0887 0.0746 0.0679 0.0602 0.0560 0.0529 0.0505 0.0492 0.0480 0.0469 0.0461 0.0454 0.0450 0.0444 

[TRAIN] Epoch[1](3735/114412); Loss: 0.078505; Backpropagation: 0.2936 sec; Batch: 2.1253 sec
0.1628 0.1362 0.1027 0.0947 0.0804 0.0759 0.0695 0.0660 0.0630 0.0611 0.0599 0.0585 0.0575 0.0565 0.0560 0.0554 

[TRAIN] Epoch[1](3736/114412); Loss: 0.058662; Backpropagation: 0.2949 sec; Batch: 2.2274 sec
0.1205 0.1057 0.0768 0.0681 0.0607 0.0546 0.0514 0.0484 0.0470 0.0457 0.0447 0.0441 0.0434 0.0428 0.0425 0.0422 

[TRAIN] Epoch[1](3737/114412); Loss: 0.110193; Backpropagation: 0.2932 sec; Batch: 2.0854 sec
0.1892 0.1684 0.1296 0.1179 0.1114 0.1066 0.1018 0.0983 0.0966 0.0944 0.0933 0.0920 0.0915 0.0910 0.0907 0.0904 

[TRAIN] Epoch[1](3738/114412); Loss: 0.071015; Backpropagation: 0.2911 sec; Batch: 2.1234 sec
0.1241 0.1021 0.0901 0.0795 0.0727 0.0690 0.0655 0.0631 0.0615 0.0604 0.0595 0.0587 0.0581 0.0576 0.0574 0.0570 

[TRAIN] Epoch[1](3739/114412); Loss: 0.076269; Backpropagation: 0.2903 sec; Batch: 2.1049 sec
0.1411 0.1126 0.0901 0.0828 0.0762 0.0740 0.0705 0.0680 0.0664 0.0650 0.0639 0.0629 0.0623 0.0619 0.0615 0.0612 

[TRAIN] Epoch[1](3740/114412); Loss: 0.073445; Backpropagation: 0.2908 sec; Batch: 2.0774 sec
0.1421 0.1183 0.0946 0.0825 0.0742 0.0708 0.0662 0.0637 0.0615 0.0601 0.0587 0.0580 0.0570 0.0563 0.0558 0.0554 

[TRAIN] Epoch[1](3741/114412); Loss: 0.079244; Backpropagation: 0.2912 sec; Batch: 2.1139 sec
0.1796 0.1242 0.1007 0.0881 0.0804 0.0743 0.0703 0.0677 0.0655 0.0633 0.0616 0.0603 0.0592 0.0584 0.0575 0.0568 

[TRAIN] Epoch[1](3742/114412); Loss: 0.051384; Backpropagation: 0.2911 sec; Batch: 2.1297 sec
0.0945 0.0782 0.0708 0.0602 0.0519 0.0485 0.0466 0.0446 0.0435 0.0422 0.0415 0.0407 0.0402 0.0399 0.0396 0.0393 

[TRAIN] Epoch[1](3743/114412); Loss: 0.080090; Backpropagation: 0.2908 sec; Batch: 2.1179 sec
0.2217 0.1587 0.1223 0.0869 0.0821 0.0729 0.0681 0.0638 0.0585 0.0560 0.0545 0.0502 0.0487 0.0477 0.0451 0.0442 

[TRAIN] Epoch[1](3744/114412); Loss: 0.067650; Backpropagation: 0.2913 sec; Batch: 2.1170 sec
0.1855 0.1370 0.0978 0.0788 0.0663 0.0599 0.0539 0.0502 0.0476 0.0460 0.0449 0.0442 0.0430 0.0428 0.0424 0.0422 

[TRAIN] Epoch[1](3745/114412); Loss: 0.109297; Backpropagation: 0.2912 sec; Batch: 2.1061 sec
0.1725 0.1484 0.1243 0.1187 0.1107 0.1070 0.1027 0.1006 0.0994 0.0978 0.0965 0.0955 0.0946 0.0938 0.0932 0.0928 

[TRAIN] Epoch[1](3746/114412); Loss: 0.066286; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1497 0.1078 0.0888 0.0729 0.0626 0.0602 0.0568 0.0548 0.0539 0.0524 0.0515 0.0509 0.0502 0.0497 0.0492 0.0491 

[TRAIN] Epoch[1](3747/114412); Loss: 0.081559; Backpropagation: 0.2907 sec; Batch: 2.0768 sec
0.1371 0.1174 0.0969 0.0920 0.0830 0.0802 0.0760 0.0741 0.0720 0.0705 0.0693 0.0682 0.0675 0.0671 0.0669 0.0666 

[TRAIN] Epoch[1](3748/114412); Loss: 0.062982; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1353 0.1052 0.0810 0.0754 0.0656 0.0607 0.0571 0.0538 0.0509 0.0493 0.0479 0.0463 0.0455 0.0450 0.0445 0.0442 

[TRAIN] Epoch[1](3749/114412); Loss: 0.067614; Backpropagation: 0.2939 sec; Batch: 2.1218 sec
0.1283 0.1034 0.0890 0.0770 0.0673 0.0647 0.0607 0.0585 0.0570 0.0556 0.0548 0.0542 0.0534 0.0531 0.0527 0.0523 

[TRAIN] Epoch[1](3750/114412); Loss: 0.075383; Backpropagation: 0.2931 sec; Batch: 2.1220 sec
0.1575 0.1218 0.0970 0.0780 0.0736 0.0692 0.0665 0.0642 0.0627 0.0617 0.0606 0.0597 0.0591 0.0586 0.0580 0.0577 

[TRAIN] Epoch[1](3751/114412); Loss: 0.055733; Backpropagation: 0.2910 sec; Batch: 2.1145 sec
0.1090 0.0891 0.0895 0.0733 0.0607 0.0548 0.0487 0.0461 0.0432 0.0421 0.0407 0.0400 0.0391 0.0388 0.0385 0.0381 

[TRAIN] Epoch[1](3752/114412); Loss: 0.070231; Backpropagation: 0.2910 sec; Batch: 2.0782 sec
0.1522 0.1157 0.0919 0.0778 0.0700 0.0649 0.0628 0.0601 0.0577 0.0559 0.0545 0.0536 0.0526 0.0519 0.0513 0.0508 

[TRAIN] Epoch[1](3753/114412); Loss: 0.060018; Backpropagation: 0.2932 sec; Batch: 2.1235 sec
0.1308 0.1092 0.0819 0.0695 0.0603 0.0548 0.0515 0.0483 0.0465 0.0456 0.0446 0.0441 0.0438 0.0434 0.0430 0.0428 

[TRAIN] Epoch[1](3754/114412); Loss: 0.060305; Backpropagation: 0.2905 sec; Batch: 2.1140 sec
0.1278 0.1068 0.0799 0.0700 0.0596 0.0558 0.0524 0.0500 0.0483 0.0468 0.0460 0.0451 0.0447 0.0442 0.0439 0.0436 

[TRAIN] Epoch[1](3755/114412); Loss: 0.074395; Backpropagation: 0.2907 sec; Batch: 2.1140 sec
0.1524 0.1300 0.0873 0.0854 0.0719 0.0691 0.0663 0.0629 0.0609 0.0599 0.0587 0.0580 0.0574 0.0568 0.0566 0.0565 

[TRAIN] Epoch[1](3756/114412); Loss: 0.061795; Backpropagation: 0.2929 sec; Batch: 2.1155 sec
0.1520 0.1079 0.0902 0.0687 0.0616 0.0558 0.0517 0.0493 0.0469 0.0461 0.0449 0.0439 0.0432 0.0426 0.0420 0.0419 

[TRAIN] Epoch[1](3757/114412); Loss: 0.063869; Backpropagation: 0.2918 sec; Batch: 2.0834 sec
0.1253 0.0996 0.0815 0.0726 0.0649 0.0604 0.0576 0.0551 0.0535 0.0522 0.0512 0.0505 0.0499 0.0495 0.0491 0.0489 

[TRAIN] Epoch[1](3758/114412); Loss: 0.068793; Backpropagation: 0.2928 sec; Batch: 2.0791 sec
0.1468 0.1129 0.0880 0.0810 0.0686 0.0627 0.0615 0.0575 0.0560 0.0545 0.0533 0.0527 0.0519 0.0515 0.0511 0.0507 

[TRAIN] Epoch[1](3759/114412); Loss: 0.064531; Backpropagation: 0.2912 sec; Batch: 2.1161 sec
0.1177 0.0890 0.0766 0.0701 0.0646 0.0611 0.0594 0.0575 0.0564 0.0558 0.0550 0.0546 0.0541 0.0537 0.0536 0.0533 

[TRAIN] Epoch[1](3760/114412); Loss: 0.096598; Backpropagation: 0.2916 sec; Batch: 2.0780 sec
0.1816 0.1360 0.1181 0.1063 0.0983 0.0928 0.0885 0.0854 0.0833 0.0821 0.0807 0.0798 0.0791 0.0783 0.0779 0.0774 

[TRAIN] Epoch[1](3761/114412); Loss: 0.091313; Backpropagation: 0.2909 sec; Batch: 2.1169 sec
0.1743 0.1420 0.1180 0.1025 0.0917 0.0870 0.0827 0.0795 0.0774 0.0752 0.0741 0.0728 0.0719 0.0713 0.0705 0.0700 

[TRAIN] Epoch[1](3762/114412); Loss: 0.077430; Backpropagation: 0.2909 sec; Batch: 2.0975 sec
0.1335 0.1205 0.1037 0.0923 0.0824 0.0760 0.0720 0.0691 0.0653 0.0633 0.0622 0.0609 0.0601 0.0596 0.0591 0.0589 

[TRAIN] Epoch[1](3763/114412); Loss: 0.092775; Backpropagation: 0.2954 sec; Batch: 2.0809 sec
0.1449 0.1335 0.1159 0.1076 0.0991 0.0920 0.0884 0.0853 0.0822 0.0803 0.0791 0.0773 0.0759 0.0749 0.0742 0.0738 

[TRAIN] Epoch[1](3764/114412); Loss: 0.061880; Backpropagation: 0.2930 sec; Batch: 2.1280 sec
0.1158 0.1066 0.0738 0.0709 0.0642 0.0588 0.0553 0.0537 0.0524 0.0505 0.0495 0.0488 0.0482 0.0477 0.0472 0.0468 

[TRAIN] Epoch[1](3765/114412); Loss: 0.059720; Backpropagation: 0.2907 sec; Batch: 2.1182 sec
0.1093 0.0979 0.0753 0.0705 0.0609 0.0574 0.0541 0.0521 0.0504 0.0486 0.0478 0.0471 0.0465 0.0462 0.0458 0.0455 

[TRAIN] Epoch[1](3766/114412); Loss: 0.077623; Backpropagation: 0.2928 sec; Batch: 2.0893 sec
0.1306 0.1188 0.0979 0.0879 0.0781 0.0719 0.0704 0.0688 0.0666 0.0656 0.0651 0.0646 0.0643 0.0639 0.0637 0.0636 

[TRAIN] Epoch[1](3767/114412); Loss: 0.042730; Backpropagation: 0.2916 sec; Batch: 2.0775 sec
0.0987 0.0768 0.0594 0.0522 0.0427 0.0379 0.0358 0.0339 0.0321 0.0318 0.0311 0.0309 0.0304 0.0300 0.0301 0.0299 

[TRAIN] Epoch[1](3768/114412); Loss: 0.057050; Backpropagation: 0.2910 sec; Batch: 2.1193 sec
0.1259 0.0983 0.0708 0.0641 0.0565 0.0534 0.0511 0.0472 0.0454 0.0447 0.0441 0.0433 0.0424 0.0419 0.0419 0.0418 

[TRAIN] Epoch[1](3769/114412); Loss: 0.072510; Backpropagation: 0.2906 sec; Batch: 2.0843 sec
0.1308 0.1027 0.0888 0.0865 0.0763 0.0711 0.0663 0.0633 0.0623 0.0606 0.0599 0.0592 0.0584 0.0582 0.0580 0.0578 

[TRAIN] Epoch[1](3770/114412); Loss: 0.080156; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1277 0.1134 0.1031 0.0918 0.0838 0.0777 0.0747 0.0715 0.0701 0.0688 0.0681 0.0674 0.0666 0.0663 0.0660 0.0657 

[TRAIN] Epoch[1](3771/114412); Loss: 0.069156; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1194 0.1018 0.0818 0.0812 0.0708 0.0668 0.0635 0.0617 0.0605 0.0590 0.0585 0.0574 0.0569 0.0562 0.0557 0.0553 

[TRAIN] Epoch[1](3772/114412); Loss: 0.089750; Backpropagation: 0.2912 sec; Batch: 2.1134 sec
0.1737 0.1421 0.1206 0.1102 0.0958 0.0885 0.0823 0.0784 0.0739 0.0712 0.0694 0.0680 0.0667 0.0659 0.0649 0.0643 

[TRAIN] Epoch[1](3773/114412); Loss: 0.076001; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1323 0.1175 0.0925 0.0897 0.0825 0.0754 0.0702 0.0672 0.0652 0.0630 0.0622 0.0610 0.0600 0.0596 0.0591 0.0586 

[TRAIN] Epoch[1](3774/114412); Loss: 0.069291; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1125 0.1046 0.0901 0.0856 0.0768 0.0711 0.0657 0.0609 0.0596 0.0569 0.0560 0.0552 0.0541 0.0537 0.0530 0.0529 

[TRAIN] Epoch[1](3775/114412); Loss: 0.070022; Backpropagation: 0.2942 sec; Batch: 2.0816 sec
0.1238 0.1074 0.0834 0.0841 0.0739 0.0692 0.0633 0.0609 0.0593 0.0579 0.0574 0.0569 0.0562 0.0558 0.0554 0.0553 

[TRAIN] Epoch[1](3776/114412); Loss: 0.072329; Backpropagation: 0.2914 sec; Batch: 2.1141 sec
0.1466 0.1395 0.1012 0.0973 0.0695 0.0647 0.0632 0.0581 0.0556 0.0543 0.0527 0.0517 0.0509 0.0510 0.0507 0.0503 

[TRAIN] Epoch[1](3777/114412); Loss: 0.054866; Backpropagation: 0.2913 sec; Batch: 2.1163 sec
0.1050 0.1030 0.0796 0.0776 0.0636 0.0572 0.0462 0.0444 0.0402 0.0388 0.0382 0.0371 0.0372 0.0365 0.0366 0.0364 

[TRAIN] Epoch[1](3778/114412); Loss: 0.083035; Backpropagation: 0.2903 sec; Batch: 2.0771 sec
0.1672 0.1474 0.1079 0.1005 0.0865 0.0795 0.0728 0.0698 0.0666 0.0646 0.0641 0.0621 0.0615 0.0599 0.0591 0.0590 

[TRAIN] Epoch[1](3779/114412); Loss: 0.064984; Backpropagation: 0.2914 sec; Batch: 2.1098 sec
0.1043 0.1012 0.0831 0.0792 0.0706 0.0673 0.0599 0.0569 0.0544 0.0535 0.0529 0.0522 0.0516 0.0511 0.0508 0.0507 

[TRAIN] Epoch[1](3780/114412); Loss: 0.073396; Backpropagation: 0.2917 sec; Batch: 2.1058 sec
0.1279 0.1111 0.0914 0.0850 0.0778 0.0728 0.0667 0.0650 0.0627 0.0613 0.0600 0.0596 0.0590 0.0586 0.0580 0.0576 

[TRAIN] Epoch[1](3781/114412); Loss: 0.078440; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.1587 0.1340 0.1025 0.0964 0.0852 0.0791 0.0768 0.0660 0.0636 0.0602 0.0591 0.0571 0.0553 0.0547 0.0535 0.0529 

[TRAIN] Epoch[1](3782/114412); Loss: 0.064023; Backpropagation: 0.2911 sec; Batch: 2.0842 sec
0.1250 0.1155 0.0839 0.0805 0.0695 0.0629 0.0577 0.0530 0.0516 0.0488 0.0480 0.0466 0.0459 0.0457 0.0450 0.0448 

[TRAIN] Epoch[1](3783/114412); Loss: 0.057128; Backpropagation: 0.2910 sec; Batch: 2.1208 sec
0.1162 0.0957 0.0716 0.0645 0.0585 0.0555 0.0511 0.0498 0.0474 0.0459 0.0447 0.0434 0.0429 0.0425 0.0422 0.0420 

[TRAIN] Epoch[1](3784/114412); Loss: 0.072797; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1332 0.1109 0.0834 0.0768 0.0731 0.0701 0.0678 0.0647 0.0635 0.0620 0.0608 0.0604 0.0600 0.0598 0.0593 0.0589 

[TRAIN] Epoch[1](3785/114412); Loss: 0.055105; Backpropagation: 0.2931 sec; Batch: 2.1156 sec
0.1207 0.0884 0.0755 0.0698 0.0581 0.0524 0.0483 0.0447 0.0435 0.0425 0.0411 0.0406 0.0396 0.0391 0.0389 0.0387 

[TRAIN] Epoch[1](3786/114412); Loss: 0.060049; Backpropagation: 0.2914 sec; Batch: 2.1169 sec
0.1329 0.1098 0.0841 0.0673 0.0615 0.0556 0.0509 0.0489 0.0474 0.0462 0.0444 0.0442 0.0428 0.0420 0.0415 0.0414 

[TRAIN] Epoch[1](3787/114412); Loss: 0.068973; Backpropagation: 0.2910 sec; Batch: 2.1279 sec
0.1292 0.1078 0.0932 0.0823 0.0731 0.0684 0.0627 0.0599 0.0577 0.0560 0.0545 0.0533 0.0522 0.0516 0.0510 0.0506 

[TRAIN] Epoch[1](3788/114412); Loss: 0.080522; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1308 0.1180 0.1006 0.0962 0.0888 0.0810 0.0766 0.0733 0.0699 0.0677 0.0661 0.0657 0.0642 0.0637 0.0631 0.0626 

[TRAIN] Epoch[1](3789/114412); Loss: 0.081802; Backpropagation: 0.2911 sec; Batch: 2.1220 sec
0.1550 0.1321 0.1069 0.0943 0.0829 0.0776 0.0736 0.0710 0.0681 0.0665 0.0658 0.0643 0.0636 0.0629 0.0622 0.0620 

[TRAIN] Epoch[1](3790/114412); Loss: 0.076613; Backpropagation: 0.2929 sec; Batch: 2.1236 sec
0.1518 0.1373 0.1026 0.0907 0.0770 0.0706 0.0661 0.0633 0.0616 0.0603 0.0589 0.0583 0.0575 0.0570 0.0566 0.0561 

[TRAIN] Epoch[1](3791/114412); Loss: 0.073717; Backpropagation: 0.2912 sec; Batch: 2.1159 sec
0.1386 0.1196 0.0904 0.0817 0.0782 0.0734 0.0692 0.0649 0.0626 0.0610 0.0587 0.0577 0.0570 0.0561 0.0555 0.0549 

[TRAIN] Epoch[1](3792/114412); Loss: 0.077042; Backpropagation: 0.2916 sec; Batch: 2.1209 sec
0.1091 0.0958 0.0858 0.0833 0.0783 0.0756 0.0745 0.0729 0.0717 0.0709 0.0702 0.0696 0.0692 0.0687 0.0686 0.0685 

[TRAIN] Epoch[1](3793/114412); Loss: 0.087973; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1359 0.1314 0.1132 0.1033 0.0939 0.0874 0.0829 0.0792 0.0772 0.0753 0.0734 0.0725 0.0715 0.0707 0.0701 0.0697 

[TRAIN] Epoch[1](3794/114412); Loss: 0.075148; Backpropagation: 0.2905 sec; Batch: 2.1180 sec
0.1295 0.1168 0.0983 0.0864 0.0773 0.0725 0.0687 0.0660 0.0642 0.0624 0.0613 0.0607 0.0600 0.0595 0.0594 0.0593 

[TRAIN] Epoch[1](3795/114412); Loss: 0.078525; Backpropagation: 0.2907 sec; Batch: 2.0816 sec
0.1376 0.1220 0.0991 0.0871 0.0798 0.0771 0.0726 0.0703 0.0681 0.0661 0.0647 0.0635 0.0629 0.0623 0.0618 0.0614 

[TRAIN] Epoch[1](3796/114412); Loss: 0.074287; Backpropagation: 0.2907 sec; Batch: 2.1259 sec
0.1333 0.1249 0.0959 0.0844 0.0773 0.0727 0.0692 0.0661 0.0635 0.0609 0.0585 0.0575 0.0568 0.0563 0.0560 0.0554 

[TRAIN] Epoch[1](3797/114412); Loss: 0.073062; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1419 0.1366 0.1036 0.0948 0.0772 0.0695 0.0614 0.0593 0.0570 0.0559 0.0542 0.0531 0.0520 0.0514 0.0509 0.0501 

[TRAIN] Epoch[1](3798/114412); Loss: 0.066826; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1326 0.1233 0.0870 0.0798 0.0678 0.0605 0.0591 0.0574 0.0547 0.0531 0.0515 0.0504 0.0488 0.0482 0.0477 0.0471 

[TRAIN] Epoch[1](3799/114412); Loss: 0.070612; Backpropagation: 0.2915 sec; Batch: 2.1181 sec
0.1165 0.1089 0.0883 0.0803 0.0747 0.0674 0.0655 0.0636 0.0619 0.0605 0.0591 0.0581 0.0573 0.0564 0.0558 0.0555 

[TRAIN] Epoch[1](3800/114412); Loss: 0.076171; Backpropagation: 0.2929 sec; Batch: 2.1343 sec
0.1121 0.0994 0.0820 0.0800 0.0776 0.0739 0.0721 0.0708 0.0711 0.0702 0.0697 0.0696 0.0682 0.0676 0.0674 0.0670 

[TRAIN] Epoch[1](3801/114412); Loss: 0.049070; Backpropagation: 0.2928 sec; Batch: 2.1197 sec
0.0868 0.0832 0.0704 0.0620 0.0542 0.0477 0.0444 0.0424 0.0403 0.0391 0.0369 0.0363 0.0361 0.0354 0.0352 0.0348 

[TRAIN] Epoch[1](3802/114412); Loss: 0.084095; Backpropagation: 0.2910 sec; Batch: 2.1137 sec
0.1331 0.1213 0.1134 0.0971 0.0859 0.0800 0.0770 0.0745 0.0732 0.0723 0.0711 0.0706 0.0698 0.0693 0.0688 0.0683 

[TRAIN] Epoch[1](3803/114412); Loss: 0.074521; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1210 0.1153 0.0835 0.0800 0.0763 0.0719 0.0685 0.0666 0.0656 0.0649 0.0635 0.0634 0.0630 0.0628 0.0630 0.0630 

[TRAIN] Epoch[1](3804/114412); Loss: 0.052084; Backpropagation: 0.2913 sec; Batch: 2.1151 sec
0.0986 0.0869 0.0687 0.0602 0.0536 0.0508 0.0482 0.0452 0.0433 0.0421 0.0410 0.0398 0.0396 0.0390 0.0383 0.0381 

[TRAIN] Epoch[1](3805/114412); Loss: 0.050535; Backpropagation: 0.2912 sec; Batch: 2.1222 sec
0.0917 0.0871 0.0659 0.0551 0.0524 0.0479 0.0458 0.0444 0.0426 0.0413 0.0400 0.0395 0.0390 0.0388 0.0385 0.0385 

[TRAIN] Epoch[1](3806/114412); Loss: 0.060346; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.0954 0.0935 0.0725 0.0681 0.0618 0.0585 0.0559 0.0541 0.0533 0.0524 0.0513 0.0508 0.0502 0.0496 0.0493 0.0489 

[TRAIN] Epoch[1](3807/114412); Loss: 0.065761; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1197 0.1080 0.0905 0.0783 0.0707 0.0637 0.0601 0.0586 0.0552 0.0527 0.0517 0.0501 0.0489 0.0485 0.0479 0.0474 

[TRAIN] Epoch[1](3808/114412); Loss: 0.084190; Backpropagation: 0.2910 sec; Batch: 2.0971 sec
0.1436 0.1358 0.1125 0.1003 0.0887 0.0826 0.0790 0.0753 0.0731 0.0698 0.0681 0.0662 0.0648 0.0635 0.0622 0.0616 

[TRAIN] Epoch[1](3809/114412); Loss: 0.069425; Backpropagation: 0.2910 sec; Batch: 2.0980 sec
0.1099 0.1027 0.0821 0.0760 0.0714 0.0682 0.0657 0.0637 0.0622 0.0607 0.0596 0.0591 0.0582 0.0576 0.0570 0.0567 

[TRAIN] Epoch[1](3810/114412); Loss: 0.076923; Backpropagation: 0.2931 sec; Batch: 2.1200 sec
0.1828 0.1725 0.1201 0.1060 0.0788 0.0702 0.0592 0.0544 0.0528 0.0515 0.0495 0.0481 0.0474 0.0465 0.0458 0.0452 

[TRAIN] Epoch[1](3811/114412); Loss: 0.121244; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.1805 0.1653 0.1481 0.1374 0.1312 0.1249 0.1180 0.1139 0.1109 0.1072 0.1051 0.1031 0.1008 0.0992 0.0979 0.0964 

[TRAIN] Epoch[1](3812/114412); Loss: 0.075592; Backpropagation: 0.2911 sec; Batch: 2.1285 sec
0.1242 0.1165 0.0929 0.0812 0.0759 0.0716 0.0696 0.0685 0.0668 0.0655 0.0646 0.0637 0.0628 0.0625 0.0619 0.0614 

[TRAIN] Epoch[1](3813/114412); Loss: 0.069437; Backpropagation: 0.2910 sec; Batch: 2.1132 sec
0.1302 0.1219 0.0882 0.0778 0.0703 0.0643 0.0629 0.0603 0.0578 0.0570 0.0552 0.0542 0.0537 0.0529 0.0524 0.0519 

[TRAIN] Epoch[1](3814/114412); Loss: 0.066012; Backpropagation: 0.2927 sec; Batch: 2.1198 sec
0.1480 0.1367 0.0927 0.0771 0.0644 0.0604 0.0571 0.0528 0.0506 0.0490 0.0465 0.0454 0.0448 0.0440 0.0436 0.0430 

[TRAIN] Epoch[1](3815/114412); Loss: 0.066465; Backpropagation: 0.2948 sec; Batch: 2.0916 sec
0.1076 0.1050 0.0855 0.0767 0.0720 0.0678 0.0624 0.0604 0.0582 0.0564 0.0548 0.0533 0.0524 0.0510 0.0503 0.0497 

[TRAIN] Epoch[1](3816/114412); Loss: 0.072395; Backpropagation: 0.2954 sec; Batch: 2.0828 sec
0.1218 0.1147 0.0935 0.0823 0.0736 0.0699 0.0669 0.0648 0.0630 0.0613 0.0599 0.0588 0.0578 0.0570 0.0567 0.0562 

[TRAIN] Epoch[1](3817/114412); Loss: 0.093999; Backpropagation: 0.2954 sec; Batch: 2.1201 sec
0.1395 0.1310 0.1120 0.1043 0.0981 0.0946 0.0895 0.0872 0.0850 0.0831 0.0821 0.0812 0.0804 0.0793 0.0785 0.0781 

[TRAIN] Epoch[1](3818/114412); Loss: 0.061544; Backpropagation: 0.2952 sec; Batch: 2.1215 sec
0.1195 0.1053 0.0811 0.0705 0.0650 0.0583 0.0547 0.0531 0.0513 0.0492 0.0480 0.0470 0.0462 0.0456 0.0452 0.0447 

[TRAIN] Epoch[1](3819/114412); Loss: 0.095695; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1389 0.1331 0.1156 0.1042 0.0973 0.0943 0.0914 0.0890 0.0880 0.0856 0.0844 0.0834 0.0824 0.0817 0.0812 0.0806 

[TRAIN] Epoch[1](3820/114412); Loss: 0.049429; Backpropagation: 0.2909 sec; Batch: 2.1218 sec
0.1135 0.0965 0.0784 0.0634 0.0547 0.0503 0.0418 0.0386 0.0366 0.0341 0.0325 0.0314 0.0306 0.0298 0.0295 0.0291 

[TRAIN] Epoch[1](3821/114412); Loss: 0.082919; Backpropagation: 0.2923 sec; Batch: 2.0984 sec
0.1336 0.1229 0.1059 0.0944 0.0869 0.0819 0.0776 0.0754 0.0728 0.0708 0.0698 0.0687 0.0675 0.0666 0.0662 0.0657 

[TRAIN] Epoch[1](3822/114412); Loss: 0.052057; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1201 0.1047 0.0775 0.0617 0.0534 0.0484 0.0429 0.0411 0.0391 0.0376 0.0362 0.0353 0.0344 0.0340 0.0334 0.0331 

[TRAIN] Epoch[1](3823/114412); Loss: 0.097048; Backpropagation: 0.2911 sec; Batch: 2.1159 sec
0.1683 0.1574 0.1197 0.1086 0.0971 0.0950 0.0899 0.0865 0.0837 0.0818 0.0797 0.0783 0.0778 0.0769 0.0763 0.0759 

[TRAIN] Epoch[1](3824/114412); Loss: 0.068603; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1460 0.1361 0.0939 0.0828 0.0681 0.0637 0.0592 0.0560 0.0538 0.0514 0.0500 0.0491 0.0480 0.0471 0.0464 0.0459 

[TRAIN] Epoch[1](3825/114412); Loss: 0.069672; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1232 0.1108 0.0878 0.0805 0.0756 0.0694 0.0664 0.0644 0.0601 0.0579 0.0556 0.0542 0.0532 0.0524 0.0519 0.0514 

[TRAIN] Epoch[1](3826/114412); Loss: 0.070422; Backpropagation: 0.2912 sec; Batch: 2.1213 sec
0.1261 0.1089 0.0896 0.0783 0.0724 0.0678 0.0645 0.0622 0.0602 0.0588 0.0576 0.0570 0.0564 0.0558 0.0556 0.0554 

[TRAIN] Epoch[1](3827/114412); Loss: 0.051477; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.0986 0.0870 0.0653 0.0546 0.0530 0.0474 0.0466 0.0442 0.0427 0.0417 0.0413 0.0408 0.0404 0.0403 0.0400 0.0398 

[TRAIN] Epoch[1](3828/114412); Loss: 0.080106; Backpropagation: 0.2918 sec; Batch: 2.0813 sec
0.1462 0.1405 0.1057 0.0931 0.0818 0.0761 0.0715 0.0691 0.0671 0.0651 0.0636 0.0620 0.0609 0.0602 0.0596 0.0592 

[TRAIN] Epoch[1](3829/114412); Loss: 0.093542; Backpropagation: 0.2912 sec; Batch: 2.1203 sec
0.1533 0.1398 0.1153 0.1005 0.0935 0.0892 0.0855 0.0840 0.0825 0.0812 0.0802 0.0795 0.0786 0.0781 0.0779 0.0775 

[TRAIN] Epoch[1](3830/114412); Loss: 0.079106; Backpropagation: 0.2906 sec; Batch: 2.1165 sec
0.1448 0.1316 0.1074 0.0902 0.0803 0.0757 0.0713 0.0684 0.0659 0.0643 0.0630 0.0621 0.0609 0.0604 0.0599 0.0595 

[TRAIN] Epoch[1](3831/114412); Loss: 0.084162; Backpropagation: 0.2904 sec; Batch: 2.1178 sec
0.1475 0.1325 0.1165 0.0984 0.0901 0.0823 0.0778 0.0743 0.0713 0.0697 0.0670 0.0656 0.0647 0.0636 0.0631 0.0623 

[TRAIN] Epoch[1](3832/114412); Loss: 0.078596; Backpropagation: 0.2905 sec; Batch: 2.1173 sec
0.1211 0.1125 0.0970 0.0871 0.0802 0.0763 0.0734 0.0714 0.0701 0.0692 0.0684 0.0673 0.0666 0.0661 0.0657 0.0653 

[TRAIN] Epoch[1](3833/114412); Loss: 0.064848; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1039 0.0992 0.0834 0.0737 0.0673 0.0636 0.0603 0.0578 0.0566 0.0553 0.0542 0.0535 0.0528 0.0524 0.0519 0.0516 

[TRAIN] Epoch[1](3834/114412); Loss: 0.059884; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.1171 0.1034 0.0849 0.0693 0.0604 0.0562 0.0523 0.0502 0.0488 0.0471 0.0462 0.0457 0.0449 0.0444 0.0439 0.0434 

[TRAIN] Epoch[1](3835/114412); Loss: 0.086120; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1416 0.1330 0.1057 0.0957 0.0887 0.0835 0.0799 0.0768 0.0743 0.0733 0.0723 0.0713 0.0711 0.0706 0.0702 0.0700 

[TRAIN] Epoch[1](3836/114412); Loss: 0.072890; Backpropagation: 0.2911 sec; Batch: 2.1126 sec
0.1340 0.1215 0.0981 0.0801 0.0754 0.0707 0.0653 0.0628 0.0613 0.0593 0.0583 0.0574 0.0564 0.0557 0.0552 0.0548 

[TRAIN] Epoch[1](3837/114412); Loss: 0.054436; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1075 0.0972 0.0715 0.0600 0.0524 0.0498 0.0467 0.0457 0.0441 0.0435 0.0430 0.0424 0.0421 0.0419 0.0417 0.0415 

[TRAIN] Epoch[1](3838/114412); Loss: 0.071836; Backpropagation: 0.2907 sec; Batch: 2.1175 sec
0.1485 0.1307 0.0995 0.0830 0.0727 0.0657 0.0627 0.0597 0.0569 0.0560 0.0542 0.0532 0.0526 0.0518 0.0514 0.0509 

[TRAIN] Epoch[1](3839/114412); Loss: 0.062255; Backpropagation: 0.2905 sec; Batch: 2.1177 sec
0.1133 0.0913 0.0810 0.0703 0.0694 0.0624 0.0571 0.0565 0.0529 0.0508 0.0499 0.0493 0.0485 0.0481 0.0477 0.0475 

[TRAIN] Epoch[1](3840/114412); Loss: 0.083565; Backpropagation: 0.2909 sec; Batch: 2.1280 sec
0.1519 0.1396 0.1065 0.0914 0.0874 0.0790 0.0755 0.0724 0.0708 0.0691 0.0678 0.0666 0.0656 0.0649 0.0645 0.0641 

[TRAIN] Epoch[1](3841/114412); Loss: 0.068697; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1133 0.1045 0.0921 0.0766 0.0714 0.0668 0.0629 0.0614 0.0595 0.0579 0.0568 0.0565 0.0557 0.0550 0.0547 0.0542 

[TRAIN] Epoch[1](3842/114412); Loss: 0.053493; Backpropagation: 0.2913 sec; Batch: 2.1144 sec
0.1056 0.0944 0.0676 0.0566 0.0540 0.0503 0.0483 0.0459 0.0443 0.0430 0.0424 0.0416 0.0409 0.0405 0.0403 0.0401 

[TRAIN] Epoch[1](3843/114412); Loss: 0.059188; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1037 0.0968 0.0771 0.0676 0.0619 0.0584 0.0543 0.0518 0.0502 0.0490 0.0477 0.0468 0.0462 0.0456 0.0451 0.0448 

[TRAIN] Epoch[1](3844/114412); Loss: 0.106144; Backpropagation: 0.2913 sec; Batch: 2.1144 sec
0.1880 0.1726 0.1347 0.1186 0.1099 0.1030 0.0982 0.0924 0.0900 0.0883 0.0859 0.0850 0.0840 0.0834 0.0826 0.0818 

[TRAIN] Epoch[1](3845/114412); Loss: 0.102215; Backpropagation: 0.2912 sec; Batch: 2.1225 sec
0.1582 0.1448 0.1215 0.1094 0.1023 0.0991 0.0959 0.0939 0.0922 0.0908 0.0896 0.0889 0.0881 0.0875 0.0869 0.0863 

[TRAIN] Epoch[1](3846/114412); Loss: 0.045208; Backpropagation: 0.2931 sec; Batch: 2.1285 sec
0.1158 0.0939 0.0727 0.0555 0.0460 0.0414 0.0372 0.0337 0.0324 0.0310 0.0289 0.0283 0.0276 0.0267 0.0262 0.0258 

[TRAIN] Epoch[1](3847/114412); Loss: 0.077271; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1765 0.1596 0.1147 0.0972 0.0826 0.0686 0.0625 0.0600 0.0566 0.0544 0.0529 0.0518 0.0509 0.0500 0.0493 0.0487 

[TRAIN] Epoch[1](3848/114412); Loss: 0.075505; Backpropagation: 0.2912 sec; Batch: 2.1247 sec
0.1280 0.1197 0.1028 0.0885 0.0770 0.0740 0.0697 0.0673 0.0645 0.0628 0.0613 0.0600 0.0590 0.0584 0.0578 0.0573 

[TRAIN] Epoch[1](3849/114412); Loss: 0.078916; Backpropagation: 0.2913 sec; Batch: 2.1017 sec
0.1206 0.1118 0.1116 0.0874 0.0809 0.0779 0.0735 0.0707 0.0691 0.0674 0.0666 0.0659 0.0652 0.0649 0.0646 0.0645 

[TRAIN] Epoch[1](3850/114412); Loss: 0.084875; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.1415 0.1285 0.0987 0.0885 0.0836 0.0819 0.0780 0.0763 0.0755 0.0738 0.0729 0.0726 0.0721 0.0718 0.0712 0.0709 

[TRAIN] Epoch[1](3851/114412); Loss: 0.049387; Backpropagation: 0.2909 sec; Batch: 2.1129 sec
0.1024 0.0948 0.0659 0.0544 0.0485 0.0447 0.0420 0.0410 0.0394 0.0384 0.0378 0.0371 0.0364 0.0362 0.0358 0.0355 

[TRAIN] Epoch[1](3852/114412); Loss: 0.092834; Backpropagation: 0.2907 sec; Batch: 2.1178 sec
0.1724 0.1547 0.1243 0.1088 0.0948 0.0878 0.0831 0.0797 0.0774 0.0754 0.0737 0.0726 0.0714 0.0702 0.0697 0.0693 

[TRAIN] Epoch[1](3853/114412); Loss: 0.094460; Backpropagation: 0.2907 sec; Batch: 2.0774 sec
0.1751 0.1568 0.1159 0.1013 0.0924 0.0878 0.0851 0.0823 0.0804 0.0790 0.0776 0.0765 0.0758 0.0755 0.0750 0.0747 

[TRAIN] Epoch[1](3854/114412); Loss: 0.073224; Backpropagation: 0.2950 sec; Batch: 2.1174 sec
0.1332 0.1208 0.0927 0.0817 0.0746 0.0702 0.0668 0.0633 0.0619 0.0606 0.0594 0.0584 0.0578 0.0572 0.0566 0.0563 

[TRAIN] Epoch[1](3855/114412); Loss: 0.070082; Backpropagation: 0.2928 sec; Batch: 2.1198 sec
0.1360 0.1238 0.0946 0.0782 0.0704 0.0645 0.0609 0.0588 0.0570 0.0556 0.0549 0.0542 0.0537 0.0533 0.0529 0.0524 

[TRAIN] Epoch[1](3856/114412); Loss: 0.065443; Backpropagation: 0.2909 sec; Batch: 2.1148 sec
0.1535 0.1308 0.0963 0.0721 0.0626 0.0583 0.0553 0.0511 0.0492 0.0477 0.0465 0.0458 0.0453 0.0446 0.0442 0.0439 

[TRAIN] Epoch[1](3857/114412); Loss: 0.073372; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1529 0.1376 0.1171 0.0969 0.0792 0.0693 0.0640 0.0590 0.0553 0.0529 0.0509 0.0498 0.0485 0.0473 0.0468 0.0464 

[TRAIN] Epoch[1](3858/114412); Loss: 0.063154; Backpropagation: 0.2912 sec; Batch: 2.1328 sec
0.1270 0.1195 0.0867 0.0762 0.0622 0.0580 0.0538 0.0514 0.0501 0.0484 0.0476 0.0469 0.0462 0.0458 0.0455 0.0452 

[TRAIN] Epoch[1](3859/114412); Loss: 0.067021; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.1180 0.1077 0.0873 0.0758 0.0681 0.0630 0.0608 0.0586 0.0568 0.0561 0.0550 0.0542 0.0535 0.0530 0.0526 0.0522 

[TRAIN] Epoch[1](3860/114412); Loss: 0.067897; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1375 0.1221 0.0938 0.0781 0.0702 0.0643 0.0596 0.0565 0.0541 0.0526 0.0511 0.0500 0.0497 0.0491 0.0489 0.0488 

[TRAIN] Epoch[1](3861/114412); Loss: 0.066839; Backpropagation: 0.2910 sec; Batch: 2.1129 sec
0.1276 0.1104 0.0943 0.0752 0.0674 0.0623 0.0585 0.0568 0.0552 0.0539 0.0529 0.0521 0.0515 0.0510 0.0504 0.0501 

[TRAIN] Epoch[1](3862/114412); Loss: 0.068879; Backpropagation: 0.2910 sec; Batch: 2.1137 sec
0.1221 0.1112 0.0888 0.0791 0.0715 0.0667 0.0633 0.0599 0.0580 0.0569 0.0558 0.0548 0.0541 0.0537 0.0532 0.0529 

[TRAIN] Epoch[1](3863/114412); Loss: 0.075626; Backpropagation: 0.2912 sec; Batch: 2.1146 sec
0.1244 0.1132 0.0936 0.0822 0.0763 0.0732 0.0694 0.0677 0.0667 0.0652 0.0643 0.0637 0.0631 0.0627 0.0624 0.0620 

[TRAIN] Epoch[1](3864/114412); Loss: 0.080355; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1449 0.1366 0.1089 0.0930 0.0828 0.0746 0.0706 0.0682 0.0666 0.0652 0.0638 0.0631 0.0627 0.0621 0.0616 0.0610 

[TRAIN] Epoch[1](3865/114412); Loss: 0.087713; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1306 0.1271 0.1071 0.0978 0.0910 0.0868 0.0838 0.0811 0.0789 0.0776 0.0762 0.0747 0.0737 0.0732 0.0723 0.0715 

[TRAIN] Epoch[1](3866/114412); Loss: 0.071397; Backpropagation: 0.2927 sec; Batch: 2.1193 sec
0.1199 0.1065 0.0890 0.0787 0.0751 0.0715 0.0669 0.0640 0.0623 0.0607 0.0596 0.0589 0.0580 0.0574 0.0572 0.0568 

[TRAIN] Epoch[1](3867/114412); Loss: 0.085307; Backpropagation: 0.2928 sec; Batch: 2.1216 sec
0.1524 0.1417 0.1187 0.1021 0.0916 0.0840 0.0777 0.0739 0.0713 0.0687 0.0665 0.0654 0.0643 0.0630 0.0621 0.0614 

[TRAIN] Epoch[1](3868/114412); Loss: 0.079637; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1275 0.1237 0.0993 0.0893 0.0828 0.0775 0.0744 0.0715 0.0696 0.0683 0.0671 0.0660 0.0653 0.0646 0.0638 0.0634 

[TRAIN] Epoch[1](3869/114412); Loss: 0.083075; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1462 0.1372 0.1051 0.0895 0.0838 0.0777 0.0747 0.0728 0.0707 0.0693 0.0684 0.0677 0.0671 0.0666 0.0663 0.0660 

[TRAIN] Epoch[1](3870/114412); Loss: 0.081839; Backpropagation: 0.2911 sec; Batch: 2.1046 sec
0.1417 0.1293 0.1104 0.0960 0.0853 0.0785 0.0735 0.0709 0.0689 0.0672 0.0664 0.0654 0.0647 0.0641 0.0637 0.0634 

[TRAIN] Epoch[1](3871/114412); Loss: 0.100788; Backpropagation: 0.2911 sec; Batch: 2.1219 sec
0.1550 0.1470 0.1284 0.1147 0.1049 0.0985 0.0943 0.0913 0.0891 0.0875 0.0864 0.0851 0.0839 0.0830 0.0821 0.0814 

[TRAIN] Epoch[1](3872/114412); Loss: 0.047988; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1042 0.0968 0.0639 0.0516 0.0466 0.0404 0.0382 0.0380 0.0369 0.0361 0.0359 0.0357 0.0357 0.0359 0.0360 0.0362 

[TRAIN] Epoch[1](3873/114412); Loss: 0.051787; Backpropagation: 0.2930 sec; Batch: 2.1158 sec
0.0737 0.0701 0.0653 0.0596 0.0552 0.0513 0.0490 0.0473 0.0462 0.0456 0.0451 0.0447 0.0442 0.0439 0.0437 0.0437 

[TRAIN] Epoch[1](3874/114412); Loss: 0.085956; Backpropagation: 0.2911 sec; Batch: 2.1129 sec
0.1437 0.1374 0.1096 0.0958 0.0874 0.0822 0.0790 0.0765 0.0743 0.0726 0.0714 0.0704 0.0696 0.0689 0.0684 0.0680 

[TRAIN] Epoch[1](3875/114412); Loss: 0.089349; Backpropagation: 0.2914 sec; Batch: 2.1326 sec
0.1441 0.1344 0.1125 0.1033 0.0939 0.0886 0.0838 0.0805 0.0776 0.0761 0.0745 0.0735 0.0727 0.0718 0.0713 0.0709 

[TRAIN] Epoch[1](3876/114412); Loss: 0.062512; Backpropagation: 0.2928 sec; Batch: 2.0994 sec
0.1090 0.0997 0.0821 0.0730 0.0674 0.0632 0.0589 0.0558 0.0532 0.0512 0.0496 0.0486 0.0480 0.0472 0.0468 0.0464 

[TRAIN] Epoch[1](3877/114412); Loss: 0.074543; Backpropagation: 0.2908 sec; Batch: 2.1198 sec
0.1403 0.1326 0.1091 0.0920 0.0778 0.0720 0.0667 0.0623 0.0603 0.0584 0.0564 0.0550 0.0539 0.0527 0.0520 0.0513 

[TRAIN] Epoch[1](3878/114412); Loss: 0.065829; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1217 0.1126 0.0874 0.0735 0.0665 0.0618 0.0588 0.0563 0.0546 0.0538 0.0526 0.0516 0.0511 0.0506 0.0503 0.0501 

[TRAIN] Epoch[1](3879/114412); Loss: 0.051815; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.0983 0.0879 0.0708 0.0588 0.0540 0.0511 0.0472 0.0441 0.0423 0.0414 0.0402 0.0394 0.0389 0.0385 0.0382 0.0380 

[TRAIN] Epoch[1](3880/114412); Loss: 0.074246; Backpropagation: 0.2924 sec; Batch: 2.1254 sec
0.1185 0.1134 0.0917 0.0839 0.0776 0.0728 0.0692 0.0666 0.0647 0.0637 0.0626 0.0618 0.0611 0.0607 0.0601 0.0597 

[TRAIN] Epoch[1](3881/114412); Loss: 0.078210; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1484 0.1338 0.1109 0.0909 0.0794 0.0740 0.0689 0.0660 0.0644 0.0624 0.0610 0.0598 0.0588 0.0582 0.0575 0.0569 

[TRAIN] Epoch[1](3882/114412); Loss: 0.063896; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1153 0.1056 0.0838 0.0722 0.0670 0.0616 0.0584 0.0559 0.0536 0.0528 0.0511 0.0503 0.0496 0.0488 0.0483 0.0480 

[TRAIN] Epoch[1](3883/114412); Loss: 0.084384; Backpropagation: 0.2910 sec; Batch: 2.0842 sec
0.1453 0.1372 0.1169 0.1061 0.0889 0.0824 0.0765 0.0716 0.0699 0.0674 0.0665 0.0657 0.0648 0.0642 0.0637 0.0631 

[TRAIN] Epoch[1](3884/114412); Loss: 0.082402; Backpropagation: 0.2904 sec; Batch: 2.0772 sec
0.1331 0.1241 0.1019 0.0968 0.0883 0.0819 0.0777 0.0741 0.0719 0.0701 0.0685 0.0673 0.0666 0.0659 0.0652 0.0649 

[TRAIN] Epoch[1](3885/114412); Loss: 0.092387; Backpropagation: 0.2907 sec; Batch: 2.0963 sec
0.1773 0.1703 0.1296 0.1125 0.0963 0.0892 0.0839 0.0790 0.0746 0.0714 0.0692 0.0673 0.0658 0.0649 0.0639 0.0631 

[TRAIN] Epoch[1](3886/114412); Loss: 0.087963; Backpropagation: 0.2909 sec; Batch: 2.1126 sec
0.1507 0.1411 0.1147 0.1036 0.0932 0.0848 0.0808 0.0769 0.0747 0.0729 0.0716 0.0704 0.0692 0.0683 0.0675 0.0669 

[TRAIN] Epoch[1](3887/114412); Loss: 0.085653; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1431 0.1317 0.1054 0.0947 0.0871 0.0827 0.0785 0.0762 0.0756 0.0736 0.0726 0.0712 0.0705 0.0697 0.0693 0.0686 

[TRAIN] Epoch[1](3888/114412); Loss: 0.110745; Backpropagation: 0.2952 sec; Batch: 2.1209 sec
0.1930 0.1819 0.1425 0.1304 0.1215 0.1121 0.1063 0.1009 0.0952 0.0912 0.0882 0.0854 0.0832 0.0817 0.0796 0.0787 

[TRAIN] Epoch[1](3889/114412); Loss: 0.081520; Backpropagation: 0.2916 sec; Batch: 2.1181 sec
0.1309 0.1242 0.1064 0.0938 0.0883 0.0827 0.0778 0.0738 0.0705 0.0686 0.0673 0.0657 0.0646 0.0639 0.0631 0.0628 

[TRAIN] Epoch[1](3890/114412); Loss: 0.069687; Backpropagation: 0.2927 sec; Batch: 2.1186 sec
0.1075 0.1061 0.0911 0.0832 0.0764 0.0703 0.0658 0.0625 0.0603 0.0590 0.0577 0.0565 0.0556 0.0547 0.0543 0.0540 

[TRAIN] Epoch[1](3891/114412); Loss: 0.089554; Backpropagation: 0.2915 sec; Batch: 2.1202 sec
0.1600 0.1474 0.1308 0.1125 0.0987 0.0909 0.0820 0.0766 0.0737 0.0706 0.0686 0.0664 0.0648 0.0638 0.0633 0.0627 

[TRAIN] Epoch[1](3892/114412); Loss: 0.080011; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1321 0.1276 0.0968 0.0902 0.0832 0.0792 0.0753 0.0717 0.0696 0.0685 0.0669 0.0656 0.0646 0.0638 0.0629 0.0622 

[TRAIN] Epoch[1](3893/114412); Loss: 0.068212; Backpropagation: 0.2907 sec; Batch: 2.1132 sec
0.1152 0.1115 0.0911 0.0815 0.0756 0.0701 0.0650 0.0615 0.0592 0.0559 0.0541 0.0526 0.0509 0.0500 0.0489 0.0481 

[TRAIN] Epoch[1](3894/114412); Loss: 0.070776; Backpropagation: 0.2906 sec; Batch: 2.0946 sec
0.1192 0.1069 0.0948 0.0872 0.0774 0.0708 0.0660 0.0622 0.0599 0.0582 0.0571 0.0560 0.0549 0.0544 0.0539 0.0536 

[TRAIN] Epoch[1](3895/114412); Loss: 0.070417; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1374 0.1265 0.0886 0.0852 0.0771 0.0722 0.0658 0.0614 0.0569 0.0541 0.0526 0.0513 0.0503 0.0496 0.0492 0.0487 

[TRAIN] Epoch[1](3896/114412); Loss: 0.085827; Backpropagation: 0.2928 sec; Batch: 2.1196 sec
0.1404 0.1362 0.1151 0.1077 0.0985 0.0899 0.0850 0.0782 0.0719 0.0690 0.0663 0.0650 0.0637 0.0629 0.0622 0.0613 

[TRAIN] Epoch[1](3897/114412); Loss: 0.076400; Backpropagation: 0.2928 sec; Batch: 2.1180 sec
0.1713 0.1474 0.1121 0.0976 0.0767 0.0683 0.0647 0.0604 0.0579 0.0554 0.0538 0.0527 0.0518 0.0513 0.0508 0.0503 

[TRAIN] Epoch[1](3898/114412); Loss: 0.094122; Backpropagation: 0.2907 sec; Batch: 2.1457 sec
0.1361 0.1328 0.1111 0.1065 0.0999 0.0954 0.0913 0.0877 0.0850 0.0829 0.0815 0.0803 0.0795 0.0790 0.0785 0.0784 

[TRAIN] Epoch[1](3899/114412); Loss: 0.081142; Backpropagation: 0.2911 sec; Batch: 2.1149 sec
0.1475 0.1390 0.0984 0.0950 0.0860 0.0813 0.0757 0.0712 0.0680 0.0656 0.0643 0.0629 0.0617 0.0611 0.0604 0.0601 

[TRAIN] Epoch[1](3900/114412); Loss: 0.089629; Backpropagation: 0.2917 sec; Batch: 2.1178 sec
0.1434 0.1387 0.1125 0.1036 0.0950 0.0892 0.0860 0.0825 0.0792 0.0767 0.0749 0.0728 0.0715 0.0705 0.0692 0.0684 

[TRAIN] Epoch[1](3901/114412); Loss: 0.082951; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1318 0.1290 0.1043 0.0989 0.0903 0.0837 0.0788 0.0741 0.0718 0.0696 0.0682 0.0668 0.0659 0.0652 0.0647 0.0642 

[TRAIN] Epoch[1](3902/114412); Loss: 0.090268; Backpropagation: 0.2915 sec; Batch: 2.1267 sec
0.1432 0.1351 0.1167 0.1076 0.0979 0.0921 0.0861 0.0818 0.0787 0.0757 0.0741 0.0727 0.0717 0.0708 0.0702 0.0697 

[TRAIN] Epoch[1](3903/114412); Loss: 0.098324; Backpropagation: 0.2915 sec; Batch: 2.1008 sec
0.1672 0.1583 0.1274 0.1151 0.1022 0.0954 0.0894 0.0869 0.0841 0.0818 0.0799 0.0789 0.0779 0.0771 0.0762 0.0754 

[TRAIN] Epoch[1](3904/114412); Loss: 0.065195; Backpropagation: 0.2910 sec; Batch: 2.0780 sec
0.1340 0.1250 0.0895 0.0813 0.0712 0.0658 0.0608 0.0554 0.0503 0.0486 0.0465 0.0446 0.0436 0.0426 0.0422 0.0417 

[TRAIN] Epoch[1](3905/114412); Loss: 0.094908; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1584 0.1562 0.1318 0.1222 0.1014 0.0923 0.0856 0.0811 0.0785 0.0764 0.0745 0.0734 0.0724 0.0719 0.0713 0.0710 

[TRAIN] Epoch[1](3906/114412); Loss: 0.078653; Backpropagation: 0.2911 sec; Batch: 2.0931 sec
0.1291 0.1191 0.1019 0.0920 0.0816 0.0772 0.0734 0.0701 0.0681 0.0665 0.0654 0.0644 0.0635 0.0626 0.0620 0.0614 

[TRAIN] Epoch[1](3907/114412); Loss: 0.065068; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1282 0.1159 0.0825 0.0743 0.0676 0.0633 0.0597 0.0556 0.0527 0.0509 0.0499 0.0491 0.0485 0.0480 0.0477 0.0473 

[TRAIN] Epoch[1](3908/114412); Loss: 0.071387; Backpropagation: 0.2928 sec; Batch: 2.1147 sec
0.1349 0.1316 0.1087 0.0914 0.0758 0.0672 0.0617 0.0582 0.0556 0.0539 0.0524 0.0512 0.0506 0.0501 0.0497 0.0492 

[TRAIN] Epoch[1](3909/114412); Loss: 0.095864; Backpropagation: 0.2929 sec; Batch: 2.1292 sec
0.1531 0.1489 0.1128 0.1043 0.0966 0.0922 0.0884 0.0857 0.0848 0.0833 0.0823 0.0813 0.0807 0.0802 0.0798 0.0795 

[TRAIN] Epoch[1](3910/114412); Loss: 0.078830; Backpropagation: 0.2912 sec; Batch: 2.0769 sec
0.1313 0.1216 0.0969 0.0922 0.0857 0.0795 0.0750 0.0707 0.0683 0.0666 0.0644 0.0633 0.0623 0.0618 0.0611 0.0605 

[TRAIN] Epoch[1](3911/114412); Loss: 0.098743; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1376 0.1314 0.1110 0.1043 0.1002 0.0971 0.0947 0.0929 0.0911 0.0902 0.0892 0.0889 0.0882 0.0880 0.0877 0.0875 

[TRAIN] Epoch[1](3912/114412); Loss: 0.057902; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.0955 0.0941 0.0764 0.0695 0.0630 0.0563 0.0526 0.0499 0.0487 0.0476 0.0464 0.0457 0.0453 0.0452 0.0452 0.0450 

[TRAIN] Epoch[1](3913/114412); Loss: 0.108215; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.2214 0.2185 0.1632 0.1417 0.1090 0.1039 0.0890 0.0861 0.0828 0.0787 0.0763 0.0739 0.0726 0.0720 0.0715 0.0710 

[TRAIN] Epoch[1](3914/114412); Loss: 0.085521; Backpropagation: 0.2911 sec; Batch: 2.1146 sec
0.1371 0.1305 0.1081 0.0985 0.0854 0.0811 0.0785 0.0757 0.0740 0.0729 0.0719 0.0716 0.0709 0.0708 0.0708 0.0707 

[TRAIN] Epoch[1](3915/114412); Loss: 0.091229; Backpropagation: 0.2907 sec; Batch: 2.1170 sec
0.1362 0.1294 0.1117 0.1024 0.0948 0.0900 0.0857 0.0824 0.0811 0.0799 0.0791 0.0785 0.0778 0.0772 0.0768 0.0765 

[TRAIN] Epoch[1](3916/114412); Loss: 0.069129; Backpropagation: 0.2910 sec; Batch: 2.0955 sec
0.1128 0.1068 0.0827 0.0746 0.0706 0.0674 0.0648 0.0620 0.0602 0.0593 0.0586 0.0580 0.0575 0.0571 0.0569 0.0567 

[TRAIN] Epoch[1](3917/114412); Loss: 0.061079; Backpropagation: 0.2908 sec; Batch: 2.1191 sec
0.1238 0.1205 0.0839 0.0767 0.0629 0.0565 0.0527 0.0492 0.0468 0.0454 0.0444 0.0436 0.0432 0.0429 0.0424 0.0422 

[TRAIN] Epoch[1](3918/114412); Loss: 0.095913; Backpropagation: 0.2912 sec; Batch: 2.0834 sec
0.1412 0.1307 0.1154 0.1067 0.1019 0.0980 0.0927 0.0904 0.0883 0.0851 0.0838 0.0823 0.0810 0.0800 0.0791 0.0781 

[TRAIN] Epoch[1](3919/114412); Loss: 0.052582; Backpropagation: 0.2914 sec; Batch: 2.0777 sec
0.1120 0.1076 0.0683 0.0586 0.0514 0.0476 0.0451 0.0425 0.0410 0.0400 0.0389 0.0383 0.0379 0.0375 0.0374 0.0373 

[TRAIN] Epoch[1](3920/114412); Loss: 0.067841; Backpropagation: 0.2911 sec; Batch: 2.0762 sec
0.1134 0.1099 0.0929 0.0895 0.0792 0.0711 0.0652 0.0585 0.0554 0.0535 0.0517 0.0507 0.0496 0.0488 0.0482 0.0479 

[TRAIN] Epoch[1](3921/114412); Loss: 0.095998; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1742 0.1524 0.1285 0.1140 0.1030 0.0965 0.0889 0.0837 0.0805 0.0774 0.0756 0.0742 0.0727 0.0721 0.0715 0.0707 

[TRAIN] Epoch[1](3922/114412); Loss: 0.074513; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1168 0.1138 0.0882 0.0808 0.0758 0.0725 0.0697 0.0676 0.0660 0.0651 0.0642 0.0632 0.0626 0.0622 0.0620 0.0618 

[TRAIN] Epoch[1](3923/114412); Loss: 0.089588; Backpropagation: 0.2914 sec; Batch: 2.0820 sec
0.1642 0.1585 0.1183 0.1064 0.0919 0.0848 0.0800 0.0771 0.0742 0.0721 0.0701 0.0691 0.0676 0.0670 0.0664 0.0659 

[TRAIN] Epoch[1](3924/114412); Loss: 0.107692; Backpropagation: 0.2912 sec; Batch: 2.1133 sec
0.2058 0.1998 0.1539 0.1359 0.1049 0.0999 0.0921 0.0901 0.0862 0.0852 0.0827 0.0808 0.0790 0.0767 0.0759 0.0741 

[TRAIN] Epoch[1](3925/114412); Loss: 0.128906; Backpropagation: 0.2931 sec; Batch: 2.1185 sec
0.2202 0.2169 0.1844 0.1673 0.1403 0.1302 0.1150 0.1101 0.1039 0.1014 0.0986 0.0970 0.0956 0.0948 0.0938 0.0930 

[TRAIN] Epoch[1](3926/114412); Loss: 0.072890; Backpropagation: 0.2912 sec; Batch: 2.1155 sec
0.1346 0.1288 0.0937 0.0830 0.0752 0.0717 0.0688 0.0662 0.0615 0.0593 0.0569 0.0554 0.0541 0.0531 0.0522 0.0516 

[TRAIN] Epoch[1](3927/114412); Loss: 0.064667; Backpropagation: 0.2911 sec; Batch: 2.1653 sec
0.1146 0.1091 0.0849 0.0735 0.0679 0.0635 0.0591 0.0565 0.0542 0.0527 0.0519 0.0508 0.0498 0.0493 0.0486 0.0480 

[TRAIN] Epoch[1](3928/114412); Loss: 0.083085; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.1409 0.1330 0.1103 0.0998 0.0884 0.0819 0.0776 0.0735 0.0708 0.0686 0.0670 0.0656 0.0644 0.0632 0.0625 0.0618 

[TRAIN] Epoch[1](3929/114412); Loss: 0.071362; Backpropagation: 0.2906 sec; Batch: 2.1154 sec
0.1296 0.1202 0.0951 0.0854 0.0732 0.0678 0.0625 0.0610 0.0590 0.0578 0.0567 0.0559 0.0552 0.0547 0.0541 0.0537 

[TRAIN] Epoch[1](3930/114412); Loss: 0.088441; Backpropagation: 0.2929 sec; Batch: 2.0794 sec
0.1419 0.1386 0.1181 0.1078 0.0948 0.0881 0.0818 0.0780 0.0751 0.0730 0.0721 0.0707 0.0698 0.0690 0.0686 0.0677 

[TRAIN] Epoch[1](3931/114412); Loss: 0.077315; Backpropagation: 0.2912 sec; Batch: 2.1206 sec
0.1140 0.1085 0.0970 0.0905 0.0831 0.0781 0.0745 0.0713 0.0692 0.0677 0.0660 0.0650 0.0641 0.0633 0.0627 0.0620 

[TRAIN] Epoch[1](3932/114412); Loss: 0.071419; Backpropagation: 0.2915 sec; Batch: 2.1016 sec
0.1379 0.1347 0.1019 0.0873 0.0764 0.0682 0.0625 0.0584 0.0562 0.0546 0.0531 0.0520 0.0509 0.0501 0.0495 0.0490 

[TRAIN] Epoch[1](3933/114412); Loss: 0.062898; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.1006 0.0981 0.0784 0.0740 0.0670 0.0621 0.0590 0.0564 0.0550 0.0536 0.0522 0.0514 0.0504 0.0498 0.0494 0.0489 

[TRAIN] Epoch[1](3934/114412); Loss: 0.066269; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1293 0.1171 0.0918 0.0812 0.0706 0.0653 0.0597 0.0560 0.0535 0.0513 0.0497 0.0487 0.0477 0.0467 0.0462 0.0455 

[TRAIN] Epoch[1](3935/114412); Loss: 0.059604; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1352 0.1326 0.0976 0.0789 0.0624 0.0508 0.0452 0.0435 0.0412 0.0398 0.0398 0.0388 0.0378 0.0371 0.0367 0.0363 

[TRAIN] Epoch[1](3936/114412); Loss: 0.066994; Backpropagation: 0.2910 sec; Batch: 2.1065 sec
0.1188 0.1157 0.0895 0.0795 0.0712 0.0654 0.0621 0.0582 0.0557 0.0543 0.0528 0.0516 0.0508 0.0497 0.0486 0.0481 

[TRAIN] Epoch[1](3937/114412); Loss: 0.084485; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1362 0.1359 0.1077 0.0994 0.0866 0.0813 0.0765 0.0748 0.0729 0.0713 0.0702 0.0692 0.0682 0.0677 0.0671 0.0667 

[TRAIN] Epoch[1](3938/114412); Loss: 0.068760; Backpropagation: 0.2908 sec; Batch: 2.1197 sec
0.1274 0.1196 0.0883 0.0820 0.0715 0.0668 0.0625 0.0588 0.0565 0.0550 0.0537 0.0528 0.0520 0.0515 0.0511 0.0508 

[TRAIN] Epoch[1](3939/114412); Loss: 0.083742; Backpropagation: 0.2949 sec; Batch: 2.1206 sec
0.1278 0.1205 0.1094 0.1008 0.0930 0.0870 0.0806 0.0767 0.0735 0.0714 0.0697 0.0681 0.0668 0.0656 0.0648 0.0643 

[TRAIN] Epoch[1](3940/114412); Loss: 0.091236; Backpropagation: 0.2957 sec; Batch: 2.1021 sec
0.1678 0.1542 0.1262 0.1117 0.0997 0.0906 0.0846 0.0798 0.0749 0.0720 0.0701 0.0677 0.0664 0.0654 0.0646 0.0640 

[TRAIN] Epoch[1](3941/114412); Loss: 0.087935; Backpropagation: 0.2913 sec; Batch: 2.1140 sec
0.1477 0.1383 0.1134 0.1061 0.0930 0.0878 0.0816 0.0777 0.0751 0.0729 0.0714 0.0702 0.0689 0.0681 0.0675 0.0672 

[TRAIN] Epoch[1](3942/114412); Loss: 0.056144; Backpropagation: 0.2918 sec; Batch: 2.0792 sec
0.1041 0.0972 0.0801 0.0715 0.0654 0.0609 0.0532 0.0492 0.0457 0.0430 0.0412 0.0389 0.0381 0.0372 0.0366 0.0361 

[TRAIN] Epoch[1](3943/114412); Loss: 0.069173; Backpropagation: 0.2912 sec; Batch: 2.1196 sec
0.1286 0.1190 0.0891 0.0811 0.0727 0.0674 0.0637 0.0603 0.0582 0.0562 0.0542 0.0530 0.0519 0.0510 0.0503 0.0499 

[TRAIN] Epoch[1](3944/114412); Loss: 0.082768; Backpropagation: 0.2917 sec; Batch: 2.1182 sec
0.1485 0.1432 0.1121 0.1034 0.0870 0.0831 0.0742 0.0710 0.0673 0.0652 0.0637 0.0622 0.0614 0.0609 0.0605 0.0604 

[TRAIN] Epoch[1](3945/114412); Loss: 0.080438; Backpropagation: 0.2911 sec; Batch: 2.1205 sec
0.1810 0.1679 0.1275 0.1139 0.0846 0.0735 0.0608 0.0598 0.0596 0.0560 0.0534 0.0518 0.0504 0.0496 0.0489 0.0484 

[TRAIN] Epoch[1](3946/114412); Loss: 0.077486; Backpropagation: 0.2905 sec; Batch: 2.0781 sec
0.1441 0.1350 0.1034 0.0932 0.0784 0.0726 0.0690 0.0663 0.0638 0.0622 0.0607 0.0597 0.0587 0.0581 0.0576 0.0571 

[TRAIN] Epoch[1](3947/114412); Loss: 0.089563; Backpropagation: 0.2895 sec; Batch: 2.1154 sec
0.1396 0.1341 0.1137 0.1059 0.0966 0.0919 0.0862 0.0815 0.0785 0.0763 0.0745 0.0730 0.0716 0.0707 0.0697 0.0692 

[TRAIN] Epoch[1](3948/114412); Loss: 0.098090; Backpropagation: 0.2906 sec; Batch: 2.1144 sec
0.1581 0.1469 0.1199 0.1104 0.0998 0.0947 0.0913 0.0887 0.0870 0.0849 0.0834 0.0823 0.0813 0.0808 0.0801 0.0797 

[TRAIN] Epoch[1](3949/114412); Loss: 0.088816; Backpropagation: 0.2920 sec; Batch: 2.1301 sec
0.1893 0.1794 0.1335 0.1219 0.0905 0.0835 0.0706 0.0680 0.0674 0.0647 0.0618 0.0596 0.0587 0.0579 0.0574 0.0569 

[TRAIN] Epoch[1](3950/114412); Loss: 0.074306; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1401 0.1302 0.1085 0.0994 0.0891 0.0768 0.0700 0.0631 0.0581 0.0556 0.0533 0.0514 0.0499 0.0488 0.0476 0.0469 

[TRAIN] Epoch[1](3951/114412); Loss: 0.064255; Backpropagation: 0.2915 sec; Batch: 2.1172 sec
0.1285 0.1264 0.0882 0.0747 0.0699 0.0603 0.0578 0.0545 0.0523 0.0497 0.0477 0.0457 0.0446 0.0437 0.0423 0.0418 

[TRAIN] Epoch[1](3952/114412); Loss: 0.068285; Backpropagation: 0.2927 sec; Batch: 2.1190 sec
0.1343 0.1192 0.0994 0.0804 0.0706 0.0638 0.0588 0.0564 0.0543 0.0530 0.0522 0.0512 0.0505 0.0499 0.0495 0.0490 

[TRAIN] Epoch[1](3953/114412); Loss: 0.080259; Backpropagation: 0.2921 sec; Batch: 2.1200 sec
0.1591 0.1542 0.0978 0.0867 0.0799 0.0771 0.0704 0.0681 0.0655 0.0641 0.0622 0.0608 0.0604 0.0600 0.0594 0.0585 

[TRAIN] Epoch[1](3954/114412); Loss: 0.068286; Backpropagation: 0.2927 sec; Batch: 2.1184 sec
0.1237 0.1179 0.0910 0.0784 0.0710 0.0652 0.0618 0.0581 0.0563 0.0550 0.0540 0.0531 0.0524 0.0520 0.0515 0.0512 

[TRAIN] Epoch[1](3955/114412); Loss: 0.066230; Backpropagation: 0.2932 sec; Batch: 2.1215 sec
0.1337 0.1307 0.1060 0.0888 0.0739 0.0668 0.0609 0.0536 0.0504 0.0459 0.0436 0.0427 0.0418 0.0408 0.0403 0.0398 

[TRAIN] Epoch[1](3956/114412); Loss: 0.067138; Backpropagation: 0.2911 sec; Batch: 2.1318 sec
0.1183 0.1113 0.0853 0.0777 0.0716 0.0664 0.0633 0.0600 0.0570 0.0554 0.0539 0.0525 0.0514 0.0506 0.0501 0.0493 

[TRAIN] Epoch[1](3957/114412); Loss: 0.069187; Backpropagation: 0.2907 sec; Batch: 2.1167 sec
0.1266 0.1243 0.0917 0.0778 0.0716 0.0667 0.0627 0.0598 0.0579 0.0555 0.0543 0.0532 0.0522 0.0514 0.0510 0.0504 

[TRAIN] Epoch[1](3958/114412); Loss: 0.100493; Backpropagation: 0.2904 sec; Batch: 2.0771 sec
0.1381 0.1321 0.1164 0.1097 0.1035 0.1003 0.0969 0.0946 0.0931 0.0916 0.0905 0.0897 0.0887 0.0881 0.0876 0.0870 

[TRAIN] Epoch[1](3959/114412); Loss: 0.074817; Backpropagation: 0.2910 sec; Batch: 2.1266 sec
0.1367 0.1337 0.1066 0.0902 0.0823 0.0757 0.0695 0.0634 0.0613 0.0586 0.0564 0.0545 0.0533 0.0525 0.0516 0.0508 

[TRAIN] Epoch[1](3960/114412); Loss: 0.071117; Backpropagation: 0.2906 sec; Batch: 2.1131 sec
0.1506 0.1358 0.1018 0.0868 0.0703 0.0647 0.0618 0.0590 0.0563 0.0536 0.0519 0.0505 0.0496 0.0489 0.0483 0.0481 

[TRAIN] Epoch[1](3961/114412); Loss: 0.088866; Backpropagation: 0.2915 sec; Batch: 2.1157 sec
0.1332 0.1284 0.1076 0.0994 0.0912 0.0860 0.0826 0.0807 0.0789 0.0781 0.0772 0.0765 0.0762 0.0755 0.0754 0.0750 

[TRAIN] Epoch[1](3962/114412); Loss: 0.095064; Backpropagation: 0.2930 sec; Batch: 2.1228 sec
0.1537 0.1516 0.1243 0.1160 0.1018 0.0957 0.0887 0.0846 0.0814 0.0790 0.0772 0.0757 0.0741 0.0734 0.0724 0.0713 

[TRAIN] Epoch[1](3963/114412); Loss: 0.074554; Backpropagation: 0.2929 sec; Batch: 2.1207 sec
0.1419 0.1298 0.0979 0.0893 0.0772 0.0708 0.0672 0.0626 0.0606 0.0590 0.0578 0.0568 0.0559 0.0555 0.0553 0.0552 

[TRAIN] Epoch[1](3964/114412); Loss: 0.072939; Backpropagation: 0.2903 sec; Batch: 2.1139 sec
0.1226 0.1224 0.0928 0.0877 0.0795 0.0706 0.0682 0.0646 0.0627 0.0602 0.0581 0.0569 0.0561 0.0554 0.0549 0.0543 

[TRAIN] Epoch[1](3965/114412); Loss: 0.077469; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.1486 0.1418 0.1018 0.0917 0.0761 0.0714 0.0672 0.0649 0.0631 0.0612 0.0603 0.0593 0.0588 0.0581 0.0579 0.0573 

[TRAIN] Epoch[1](3966/114412); Loss: 0.069353; Backpropagation: 0.2899 sec; Batch: 2.1166 sec
0.1228 0.1160 0.0855 0.0797 0.0726 0.0677 0.0629 0.0605 0.0592 0.0574 0.0558 0.0551 0.0541 0.0537 0.0536 0.0531 

[TRAIN] Epoch[1](3967/114412); Loss: 0.079885; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1597 0.1542 0.1196 0.0960 0.0832 0.0760 0.0705 0.0657 0.0625 0.0594 0.0574 0.0561 0.0555 0.0546 0.0540 0.0535 

[TRAIN] Epoch[1](3968/114412); Loss: 0.059338; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1159 0.1122 0.0823 0.0732 0.0634 0.0572 0.0518 0.0491 0.0468 0.0449 0.0438 0.0428 0.0424 0.0415 0.0412 0.0408 

[TRAIN] Epoch[1](3969/114412); Loss: 0.072637; Backpropagation: 0.2914 sec; Batch: 2.1164 sec
0.1186 0.1162 0.0952 0.0863 0.0783 0.0725 0.0673 0.0647 0.0623 0.0603 0.0593 0.0580 0.0570 0.0560 0.0553 0.0549 

[TRAIN] Epoch[1](3970/114412); Loss: 0.072447; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1453 0.1357 0.0960 0.0863 0.0724 0.0677 0.0628 0.0607 0.0586 0.0565 0.0550 0.0539 0.0528 0.0522 0.0516 0.0515 

[TRAIN] Epoch[1](3971/114412); Loss: 0.063995; Backpropagation: 0.2907 sec; Batch: 2.0767 sec
0.1224 0.1234 0.0960 0.0832 0.0656 0.0626 0.0569 0.0522 0.0498 0.0476 0.0463 0.0452 0.0440 0.0435 0.0429 0.0424 

[TRAIN] Epoch[1](3972/114412); Loss: 0.065977; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.1372 0.1278 0.0962 0.0759 0.0688 0.0591 0.0571 0.0547 0.0512 0.0489 0.0476 0.0472 0.0465 0.0461 0.0458 0.0456 

[TRAIN] Epoch[1](3973/114412); Loss: 0.075666; Backpropagation: 0.2919 sec; Batch: 2.0777 sec
0.1209 0.1142 0.0969 0.0873 0.0781 0.0739 0.0691 0.0670 0.0653 0.0645 0.0634 0.0629 0.0627 0.0620 0.0616 0.0609 

[TRAIN] Epoch[1](3974/114412); Loss: 0.084547; Backpropagation: 0.2929 sec; Batch: 2.1186 sec
0.1421 0.1388 0.1177 0.1070 0.0930 0.0865 0.0778 0.0735 0.0696 0.0676 0.0654 0.0644 0.0637 0.0626 0.0618 0.0611 

[TRAIN] Epoch[1](3975/114412); Loss: 0.069532; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1324 0.1204 0.1049 0.0882 0.0801 0.0673 0.0602 0.0558 0.0545 0.0523 0.0507 0.0499 0.0493 0.0492 0.0487 0.0485 

[TRAIN] Epoch[1](3976/114412); Loss: 0.080893; Backpropagation: 0.2914 sec; Batch: 2.1053 sec
0.1282 0.1226 0.1086 0.1019 0.0885 0.0844 0.0758 0.0732 0.0688 0.0666 0.0648 0.0633 0.0629 0.0621 0.0614 0.0611 

[TRAIN] Epoch[1](3977/114412); Loss: 0.057211; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1308 0.1225 0.0854 0.0700 0.0568 0.0491 0.0448 0.0429 0.0432 0.0414 0.0404 0.0388 0.0380 0.0378 0.0368 0.0365 

[TRAIN] Epoch[1](3978/114412); Loss: 0.084197; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1647 0.1587 0.1304 0.1214 0.0886 0.0883 0.0757 0.0717 0.0650 0.0604 0.0570 0.0555 0.0537 0.0526 0.0521 0.0514 

[TRAIN] Epoch[1](3979/114412); Loss: 0.056229; Backpropagation: 0.2932 sec; Batch: 2.1384 sec
0.1067 0.1067 0.0822 0.0668 0.0593 0.0527 0.0497 0.0474 0.0453 0.0437 0.0417 0.0408 0.0404 0.0393 0.0388 0.0383 

[TRAIN] Epoch[1](3980/114412); Loss: 0.095363; Backpropagation: 0.2913 sec; Batch: 2.1207 sec
0.1393 0.1313 0.1174 0.1079 0.1010 0.0954 0.0904 0.0882 0.0858 0.0840 0.0825 0.0815 0.0810 0.0806 0.0799 0.0796 

[TRAIN] Epoch[1](3981/114412); Loss: 0.091004; Backpropagation: 0.2906 sec; Batch: 2.1211 sec
0.1409 0.1380 0.1130 0.1055 0.0946 0.0903 0.0854 0.0820 0.0794 0.0779 0.0768 0.0759 0.0748 0.0743 0.0736 0.0735 

[TRAIN] Epoch[1](3982/114412); Loss: 0.068733; Backpropagation: 0.2908 sec; Batch: 2.1132 sec
0.1471 0.1347 0.1039 0.0823 0.0700 0.0587 0.0556 0.0537 0.0515 0.0508 0.0505 0.0494 0.0488 0.0481 0.0475 0.0471 

[TRAIN] Epoch[1](3983/114412); Loss: 0.114229; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1682 0.1635 0.1391 0.1293 0.1231 0.1221 0.1149 0.1097 0.1052 0.0997 0.0963 0.0941 0.0931 0.0916 0.0894 0.0883 

[TRAIN] Epoch[1](3984/114412); Loss: 0.091077; Backpropagation: 0.2910 sec; Batch: 2.1256 sec
0.1840 0.1733 0.1271 0.1126 0.0890 0.0853 0.0801 0.0750 0.0711 0.0686 0.0674 0.0662 0.0653 0.0645 0.0640 0.0636 

[TRAIN] Epoch[1](3985/114412); Loss: 0.086546; Backpropagation: 0.2904 sec; Batch: 2.1097 sec
0.1436 0.1386 0.1114 0.0978 0.0879 0.0838 0.0791 0.0765 0.0744 0.0727 0.0715 0.0708 0.0700 0.0694 0.0688 0.0684 

[TRAIN] Epoch[1](3986/114412); Loss: 0.075376; Backpropagation: 0.2913 sec; Batch: 2.1018 sec
0.1578 0.1542 0.1042 0.0974 0.0731 0.0700 0.0640 0.0603 0.0577 0.0559 0.0546 0.0532 0.0521 0.0513 0.0504 0.0499 

[TRAIN] Epoch[1](3987/114412); Loss: 0.075090; Backpropagation: 0.2909 sec; Batch: 2.1138 sec
0.1178 0.1166 0.0972 0.0888 0.0797 0.0746 0.0694 0.0669 0.0649 0.0635 0.0622 0.0611 0.0604 0.0599 0.0594 0.0590 

[TRAIN] Epoch[1](3988/114412); Loss: 0.064697; Backpropagation: 0.2909 sec; Batch: 2.0764 sec
0.1048 0.1014 0.0890 0.0758 0.0695 0.0631 0.0608 0.0574 0.0553 0.0539 0.0524 0.0516 0.0512 0.0501 0.0497 0.0492 

[TRAIN] Epoch[1](3989/114412); Loss: 0.070841; Backpropagation: 0.2906 sec; Batch: 2.1174 sec
0.1281 0.1257 0.1002 0.0865 0.0752 0.0701 0.0627 0.0596 0.0567 0.0557 0.0539 0.0530 0.0522 0.0517 0.0514 0.0508 

[TRAIN] Epoch[1](3990/114412); Loss: 0.056991; Backpropagation: 0.2905 sec; Batch: 2.0860 sec
0.1311 0.1285 0.0854 0.0646 0.0531 0.0493 0.0455 0.0440 0.0426 0.0411 0.0398 0.0388 0.0379 0.0372 0.0366 0.0363 

[TRAIN] Epoch[1](3991/114412); Loss: 0.084679; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1473 0.1411 0.1116 0.1077 0.0895 0.0857 0.0778 0.0742 0.0703 0.0683 0.0663 0.0650 0.0637 0.0627 0.0621 0.0614 

[TRAIN] Epoch[1](3992/114412); Loss: 0.064876; Backpropagation: 0.2916 sec; Batch: 2.1178 sec
0.1283 0.1292 0.0957 0.0884 0.0681 0.0625 0.0559 0.0538 0.0495 0.0478 0.0459 0.0445 0.0431 0.0421 0.0417 0.0413 

[TRAIN] Epoch[1](3993/114412); Loss: 0.061676; Backpropagation: 0.2905 sec; Batch: 2.0813 sec
0.1126 0.1053 0.0800 0.0754 0.0633 0.0595 0.0552 0.0533 0.0510 0.0496 0.0485 0.0476 0.0469 0.0465 0.0461 0.0458 

[TRAIN] Epoch[1](3994/114412); Loss: 0.082115; Backpropagation: 0.2908 sec; Batch: 2.0823 sec
0.1502 0.1466 0.1155 0.1099 0.0897 0.0835 0.0736 0.0687 0.0647 0.0625 0.0604 0.0593 0.0583 0.0576 0.0569 0.0565 

[TRAIN] Epoch[1](3995/114412); Loss: 0.122025; Backpropagation: 0.2904 sec; Batch: 2.0854 sec
0.1989 0.1974 0.1641 0.1580 0.1288 0.1250 0.1111 0.1082 0.1034 0.0998 0.0971 0.0945 0.0930 0.0919 0.0909 0.0904 

[TRAIN] Epoch[1](3996/114412); Loss: 0.082582; Backpropagation: 0.2915 sec; Batch: 2.0798 sec
0.1393 0.1328 0.1069 0.1048 0.0894 0.0856 0.0764 0.0725 0.0690 0.0669 0.0651 0.0638 0.0631 0.0624 0.0619 0.0614 

[TRAIN] Epoch[1](3997/114412); Loss: 0.089356; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.2030 0.2036 0.1502 0.1400 0.0947 0.0885 0.0673 0.0648 0.0595 0.0559 0.0533 0.0517 0.0506 0.0495 0.0488 0.0483 

[TRAIN] Epoch[1](3998/114412); Loss: 0.099369; Backpropagation: 0.2953 sec; Batch: 2.1221 sec
0.1849 0.1843 0.1549 0.1553 0.1153 0.1060 0.0847 0.0829 0.0759 0.0720 0.0674 0.0646 0.0625 0.0609 0.0597 0.0587 

[TRAIN] Epoch[1](3999/114412); Loss: 0.087539; Backpropagation: 0.2931 sec; Batch: 2.1197 sec
0.1307 0.1374 0.1295 0.1291 0.1059 0.0997 0.0860 0.0811 0.0743 0.0697 0.0655 0.0619 0.0599 0.0577 0.0567 0.0555 

[TRAIN] Epoch[1](4000/114412); Loss: 0.093861; Backpropagation: 0.2911 sec; Batch: 2.1190 sec
0.1441 0.1452 0.1306 0.1204 0.1036 0.0963 0.0854 0.0833 0.0792 0.0776 0.0755 0.0743 0.0730 0.0721 0.0710 0.0703 

[TRAIN] Epoch[1](4001/114412); Loss: 0.096180; Backpropagation: 0.2931 sec; Batch: 2.1207 sec
0.1504 0.1567 0.1358 0.1290 0.1071 0.0998 0.0895 0.0855 0.0803 0.0785 0.0747 0.0732 0.0711 0.0703 0.0688 0.0683 

[TRAIN] Epoch[1](4002/114412); Loss: 0.108929; Backpropagation: 0.3052 sec; Batch: 2.1149 sec
0.1843 0.1888 0.1591 0.1564 0.1234 0.1143 0.0991 0.0951 0.0874 0.0849 0.0798 0.0783 0.0751 0.0739 0.0717 0.0713 

[TRAIN] Epoch[1](4003/114412); Loss: 0.120836; Backpropagation: 0.2915 sec; Batch: 2.1272 sec
0.1783 0.1795 0.1592 0.1582 0.1316 0.1292 0.1137 0.1120 0.1045 0.1030 0.0985 0.0970 0.0942 0.0929 0.0911 0.0903 

[TRAIN] Epoch[1](4004/114412); Loss: 0.104338; Backpropagation: 0.2905 sec; Batch: 2.0785 sec
0.1536 0.1509 0.1336 0.1279 0.1139 0.1092 0.1000 0.0966 0.0916 0.0894 0.0868 0.0854 0.0840 0.0830 0.0822 0.0815 

[TRAIN] Epoch[1](4005/114412); Loss: 0.109063; Backpropagation: 0.2931 sec; Batch: 2.1046 sec
0.1807 0.1813 0.1525 0.1498 0.1138 0.1106 0.0966 0.0945 0.0900 0.0870 0.0845 0.0828 0.0811 0.0803 0.0798 0.0797 

[TRAIN] Epoch[1](4006/114412); Loss: 0.101398; Backpropagation: 0.2913 sec; Batch: 2.1155 sec
0.1781 0.1825 0.1485 0.1496 0.1060 0.1040 0.0848 0.0845 0.0781 0.0773 0.0739 0.0730 0.0716 0.0711 0.0700 0.0694 

[TRAIN] Epoch[1](4007/114412); Loss: 0.112295; Backpropagation: 0.2921 sec; Batch: 2.0779 sec
0.1725 0.1750 0.1545 0.1542 0.1250 0.1192 0.1021 0.0991 0.0930 0.0913 0.0884 0.0870 0.0853 0.0843 0.0833 0.0825 

[TRAIN] Epoch[1](4008/114412); Loss: 0.074526; Backpropagation: 0.2918 sec; Batch: 2.1172 sec
0.1157 0.1204 0.1051 0.1040 0.0826 0.0814 0.0706 0.0680 0.0634 0.0599 0.0570 0.0553 0.0536 0.0528 0.0515 0.0511 

[TRAIN] Epoch[1](4009/114412); Loss: 0.101141; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1593 0.1645 0.1404 0.1403 0.1075 0.1057 0.0896 0.0887 0.0833 0.0824 0.0790 0.0784 0.0762 0.0755 0.0739 0.0734 

[TRAIN] Epoch[1](4010/114412); Loss: 0.147680; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.2201 0.2240 0.1983 0.1972 0.1623 0.1557 0.1321 0.1296 0.1214 0.1216 0.1185 0.1187 0.1169 0.1165 0.1152 0.1145 

[TRAIN] Epoch[1](4011/114412); Loss: 0.115022; Backpropagation: 0.2914 sec; Batch: 2.1097 sec
0.2093 0.2093 0.1666 0.1598 0.1228 0.1180 0.1046 0.0998 0.0931 0.0888 0.0848 0.0818 0.0784 0.0764 0.0741 0.0727 

[TRAIN] Epoch[1](4012/114412); Loss: 0.102501; Backpropagation: 0.2937 sec; Batch: 2.3988 sec
0.1661 0.1708 0.1454 0.1450 0.1124 0.1072 0.0901 0.0882 0.0830 0.0813 0.0784 0.0766 0.0753 0.0742 0.0734 0.0725 

[TRAIN] Epoch[1](4013/114412); Loss: 0.109961; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1715 0.1737 0.1533 0.1508 0.1211 0.1167 0.0975 0.0966 0.0902 0.0890 0.0860 0.0851 0.0835 0.0826 0.0813 0.0805 

[TRAIN] Epoch[1](4014/114412); Loss: 0.104272; Backpropagation: 0.2909 sec; Batch: 2.1197 sec
0.1794 0.1801 0.1449 0.1407 0.1016 0.0998 0.0882 0.0877 0.0850 0.0840 0.0821 0.0812 0.0798 0.0788 0.0778 0.0774 

[TRAIN] Epoch[1](4015/114412); Loss: 0.095763; Backpropagation: 0.2912 sec; Batch: 2.1141 sec
0.1571 0.1570 0.1383 0.1265 0.1014 0.0975 0.0871 0.0845 0.0795 0.0772 0.0746 0.0730 0.0715 0.0700 0.0688 0.0681 

[TRAIN] Epoch[1](4016/114412); Loss: 0.081866; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1340 0.1329 0.1121 0.1120 0.0876 0.0857 0.0745 0.0726 0.0679 0.0664 0.0636 0.0626 0.0610 0.0601 0.0587 0.0583 

[TRAIN] Epoch[1](4017/114412); Loss: 0.108754; Backpropagation: 0.2914 sec; Batch: 2.1141 sec
0.1612 0.1670 0.1490 0.1509 0.1220 0.1177 0.1000 0.0970 0.0901 0.0885 0.0867 0.0849 0.0832 0.0818 0.0805 0.0795 

[TRAIN] Epoch[1](4018/114412); Loss: 0.115940; Backpropagation: 0.2932 sec; Batch: 2.1187 sec
0.2038 0.2065 0.1711 0.1692 0.1196 0.1161 0.0995 0.0969 0.0915 0.0887 0.0855 0.0840 0.0826 0.0815 0.0799 0.0788 

[TRAIN] Epoch[1](4019/114412); Loss: 0.115926; Backpropagation: 0.2928 sec; Batch: 2.1185 sec
0.2167 0.2208 0.1822 0.1733 0.1276 0.1196 0.0983 0.0954 0.0888 0.0844 0.0806 0.0779 0.0753 0.0730 0.0711 0.0699 

[TRAIN] Epoch[1](4020/114412); Loss: 0.087143; Backpropagation: 0.2906 sec; Batch: 2.1203 sec
0.1631 0.1638 0.1330 0.1270 0.0920 0.0860 0.0757 0.0718 0.0668 0.0634 0.0616 0.0600 0.0591 0.0580 0.0569 0.0561 

[TRAIN] Epoch[1](4021/114412); Loss: 0.076963; Backpropagation: 0.2912 sec; Batch: 2.1196 sec
0.1364 0.1391 0.1182 0.1131 0.0874 0.0788 0.0676 0.0631 0.0593 0.0565 0.0549 0.0530 0.0521 0.0514 0.0505 0.0501 

[TRAIN] Epoch[1](4022/114412); Loss: 0.084708; Backpropagation: 0.2913 sec; Batch: 2.1148 sec
0.1570 0.1576 0.1203 0.1225 0.0944 0.0920 0.0732 0.0715 0.0640 0.0625 0.0594 0.0584 0.0566 0.0562 0.0548 0.0549 

[TRAIN] Epoch[1](4023/114412); Loss: 0.080653; Backpropagation: 0.2929 sec; Batch: 2.1222 sec
0.1485 0.1500 0.1245 0.1223 0.0929 0.0855 0.0742 0.0688 0.0635 0.0605 0.0581 0.0551 0.0515 0.0467 0.0450 0.0435 

[TRAIN] Epoch[1](4024/114412); Loss: 0.130890; Backpropagation: 0.2931 sec; Batch: 2.1292 sec
0.2140 0.2153 0.1757 0.1746 0.1409 0.1361 0.1214 0.1168 0.1102 0.1054 0.1023 0.0997 0.0973 0.0959 0.0947 0.0938 

[TRAIN] Epoch[1](4025/114412); Loss: 0.081111; Backpropagation: 0.2930 sec; Batch: 2.0794 sec
0.1423 0.1416 0.1118 0.1080 0.0850 0.0828 0.0732 0.0705 0.0665 0.0642 0.0623 0.0606 0.0592 0.0576 0.0565 0.0559 

[TRAIN] Epoch[1](4026/114412); Loss: 0.104149; Backpropagation: 0.2916 sec; Batch: 2.1135 sec
0.2105 0.2099 0.1540 0.1450 0.1055 0.0995 0.0877 0.0841 0.0780 0.0753 0.0730 0.0714 0.0697 0.0686 0.0677 0.0665 

[TRAIN] Epoch[1](4027/114412); Loss: 0.085167; Backpropagation: 0.2915 sec; Batch: 2.1184 sec
0.1942 0.1973 0.1403 0.1369 0.0799 0.0801 0.0664 0.0629 0.0568 0.0540 0.0517 0.0503 0.0490 0.0482 0.0475 0.0472 

[TRAIN] Epoch[1](4028/114412); Loss: 0.110222; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.2148 0.2112 0.1615 0.1519 0.1096 0.1024 0.0906 0.0874 0.0842 0.0829 0.0811 0.0787 0.0780 0.0771 0.0764 0.0759 

[TRAIN] Epoch[1](4029/114412); Loss: 0.063048; Backpropagation: 0.2904 sec; Batch: 2.1174 sec
0.1347 0.1345 0.0987 0.0889 0.0615 0.0601 0.0513 0.0486 0.0466 0.0440 0.0427 0.0411 0.0400 0.0392 0.0386 0.0382 

[TRAIN] Epoch[1](4030/114412); Loss: 0.068230; Backpropagation: 0.2913 sec; Batch: 2.1186 sec
0.1358 0.1380 0.0960 0.0904 0.0714 0.0667 0.0614 0.0562 0.0521 0.0494 0.0482 0.0466 0.0461 0.0452 0.0443 0.0439 

[TRAIN] Epoch[1](4031/114412); Loss: 0.079854; Backpropagation: 0.2912 sec; Batch: 2.1201 sec
0.1478 0.1498 0.1151 0.1131 0.0787 0.0759 0.0693 0.0668 0.0638 0.0615 0.0594 0.0575 0.0559 0.0552 0.0544 0.0536 

[TRAIN] Epoch[1](4032/114412); Loss: 0.091992; Backpropagation: 0.2909 sec; Batch: 2.1738 sec
0.1586 0.1584 0.1149 0.1134 0.0894 0.0882 0.0821 0.0800 0.0773 0.0756 0.0744 0.0732 0.0723 0.0718 0.0713 0.0708 

[TRAIN] Epoch[1](4033/114412); Loss: 0.096651; Backpropagation: 0.2935 sec; Batch: 2.1199 sec
0.1804 0.1804 0.1439 0.1367 0.1060 0.0968 0.0873 0.0807 0.0754 0.0714 0.0685 0.0662 0.0648 0.0635 0.0626 0.0617 

[TRAIN] Epoch[1](4034/114412); Loss: 0.076415; Backpropagation: 0.2926 sec; Batch: 2.1182 sec
0.1430 0.1478 0.1078 0.1030 0.0832 0.0768 0.0713 0.0645 0.0607 0.0571 0.0545 0.0530 0.0514 0.0504 0.0494 0.0487 

[TRAIN] Epoch[1](4035/114412); Loss: 0.080517; Backpropagation: 0.2933 sec; Batch: 2.1187 sec
0.1362 0.1374 0.1055 0.1004 0.0864 0.0813 0.0755 0.0715 0.0678 0.0652 0.0632 0.0617 0.0606 0.0595 0.0585 0.0577 

[TRAIN] Epoch[1](4036/114412); Loss: 0.083714; Backpropagation: 0.2909 sec; Batch: 2.1160 sec
0.1580 0.1585 0.1135 0.1085 0.0821 0.0782 0.0729 0.0699 0.0670 0.0654 0.0639 0.0624 0.0615 0.0604 0.0589 0.0581 

[TRAIN] Epoch[1](4037/114412); Loss: 0.095922; Backpropagation: 0.2908 sec; Batch: 2.1137 sec
0.1894 0.1870 0.1373 0.1339 0.0950 0.0915 0.0808 0.0778 0.0741 0.0714 0.0696 0.0676 0.0664 0.0653 0.0643 0.0634 

[TRAIN] Epoch[1](4038/114412); Loss: 0.112520; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1972 0.1985 0.1510 0.1480 0.1141 0.1102 0.0996 0.0952 0.0915 0.0894 0.0870 0.0858 0.0843 0.0837 0.0828 0.0821 

[TRAIN] Epoch[1](4039/114412); Loss: 0.075953; Backpropagation: 0.2912 sec; Batch: 2.1141 sec
0.1340 0.1324 0.0966 0.0938 0.0782 0.0756 0.0690 0.0659 0.0640 0.0616 0.0601 0.0588 0.0577 0.0566 0.0557 0.0551 

[TRAIN] Epoch[1](4040/114412); Loss: 0.126774; Backpropagation: 0.2954 sec; Batch: 2.1183 sec
0.2475 0.2478 0.1725 0.1665 0.1233 0.1182 0.1087 0.1039 0.0998 0.0968 0.0940 0.0924 0.0905 0.0898 0.0887 0.0880 

[TRAIN] Epoch[1](4041/114412); Loss: 0.105330; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1782 0.1794 0.1433 0.1371 0.1095 0.1045 0.0969 0.0927 0.0886 0.0854 0.0825 0.0803 0.0785 0.0771 0.0762 0.0752 

[TRAIN] Epoch[1](4042/114412); Loss: 0.100528; Backpropagation: 0.2954 sec; Batch: 2.1230 sec
0.1768 0.1772 0.1344 0.1299 0.1032 0.0988 0.0919 0.0881 0.0834 0.0800 0.0778 0.0760 0.0741 0.0733 0.0721 0.0714 

[TRAIN] Epoch[1](4043/114412); Loss: 0.092219; Backpropagation: 0.2943 sec; Batch: 2.1208 sec
0.1774 0.1762 0.1266 0.1217 0.0984 0.0902 0.0820 0.0775 0.0750 0.0709 0.0684 0.0657 0.0635 0.0619 0.0610 0.0592 

[TRAIN] Epoch[1](4044/114412); Loss: 0.098001; Backpropagation: 0.2921 sec; Batch: 2.0795 sec
0.1592 0.1582 0.1313 0.1236 0.1098 0.1029 0.0938 0.0878 0.0817 0.0784 0.0767 0.0752 0.0741 0.0730 0.0718 0.0704 

[TRAIN] Epoch[1](4045/114412); Loss: 0.085224; Backpropagation: 0.2932 sec; Batch: 2.0975 sec
0.1484 0.1477 0.1142 0.1112 0.0941 0.0897 0.0818 0.0747 0.0682 0.0652 0.0646 0.0633 0.0618 0.0604 0.0594 0.0591 

[TRAIN] Epoch[1](4046/114412); Loss: 0.089804; Backpropagation: 0.2909 sec; Batch: 2.1148 sec
0.2128 0.2134 0.1430 0.1305 0.0807 0.0735 0.0670 0.0639 0.0607 0.0590 0.0577 0.0570 0.0557 0.0547 0.0540 0.0533 

[TRAIN] Epoch[1](4047/114412); Loss: 0.117192; Backpropagation: 0.2930 sec; Batch: 2.1216 sec
0.2250 0.2290 0.1585 0.1548 0.1088 0.1070 0.0993 0.0962 0.0944 0.0913 0.0892 0.0865 0.0852 0.0842 0.0833 0.0822 

[TRAIN] Epoch[1](4048/114412); Loss: 0.118562; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.2106 0.2063 0.1675 0.1510 0.1236 0.1145 0.1057 0.1028 0.0983 0.0950 0.0919 0.0891 0.0867 0.0855 0.0846 0.0840 

[TRAIN] Epoch[1](4049/114412); Loss: 0.097263; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1776 0.1746 0.1336 0.1299 0.0984 0.0950 0.0866 0.0836 0.0787 0.0764 0.0742 0.0720 0.0706 0.0695 0.0682 0.0673 

[TRAIN] Epoch[1](4050/114412); Loss: 0.092140; Backpropagation: 0.2952 sec; Batch: 2.1208 sec
0.1635 0.1639 0.1204 0.1136 0.0953 0.0898 0.0842 0.0805 0.0774 0.0747 0.0717 0.0699 0.0687 0.0676 0.0669 0.0662 

[TRAIN] Epoch[1](4051/114412); Loss: 0.096188; Backpropagation: 0.2930 sec; Batch: 2.1199 sec
0.1764 0.1768 0.1212 0.1199 0.0967 0.0920 0.0869 0.0839 0.0796 0.0764 0.0747 0.0730 0.0717 0.0705 0.0699 0.0693 

[TRAIN] Epoch[1](4052/114412); Loss: 0.074164; Backpropagation: 0.2912 sec; Batch: 2.1190 sec
0.1529 0.1517 0.1081 0.1022 0.0751 0.0698 0.0624 0.0590 0.0558 0.0538 0.0519 0.0508 0.0496 0.0487 0.0477 0.0472 

[TRAIN] Epoch[1](4053/114412); Loss: 0.069144; Backpropagation: 0.2914 sec; Batch: 2.1293 sec
0.1317 0.1291 0.0961 0.0915 0.0730 0.0678 0.0601 0.0570 0.0551 0.0525 0.0511 0.0498 0.0488 0.0480 0.0475 0.0473 

[TRAIN] Epoch[1](4054/114412); Loss: 0.121358; Backpropagation: 0.2907 sec; Batch: 2.0770 sec
0.2080 0.2047 0.1610 0.1547 0.1295 0.1231 0.1102 0.1068 0.1027 0.0991 0.0955 0.0930 0.0902 0.0891 0.0876 0.0866 

[TRAIN] Epoch[1](4055/114412); Loss: 0.078930; Backpropagation: 0.2912 sec; Batch: 2.1039 sec
0.1480 0.1477 0.1058 0.1019 0.0796 0.0744 0.0716 0.0677 0.0640 0.0613 0.0596 0.0587 0.0569 0.0561 0.0552 0.0544 

[TRAIN] Epoch[1](4056/114412); Loss: 0.069593; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1505 0.1496 0.0993 0.0948 0.0660 0.0624 0.0577 0.0543 0.0521 0.0503 0.0487 0.0475 0.0462 0.0453 0.0448 0.0441 

[TRAIN] Epoch[1](4057/114412); Loss: 0.081792; Backpropagation: 0.2952 sec; Batch: 2.1182 sec
0.1624 0.1604 0.1053 0.1016 0.0852 0.0790 0.0731 0.0667 0.0656 0.0626 0.0609 0.0593 0.0579 0.0572 0.0561 0.0555 

[TRAIN] Epoch[1](4058/114412); Loss: 0.077677; Backpropagation: 0.2928 sec; Batch: 2.1196 sec
0.1411 0.1388 0.0966 0.0911 0.0766 0.0730 0.0702 0.0668 0.0652 0.0633 0.0623 0.0609 0.0601 0.0596 0.0588 0.0582 

[TRAIN] Epoch[1](4059/114412); Loss: 0.088519; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.2187 0.2196 0.1376 0.1250 0.0730 0.0682 0.0679 0.0630 0.0611 0.0585 0.0574 0.0556 0.0542 0.0528 0.0521 0.0517 

[TRAIN] Epoch[1](4060/114412); Loss: 0.120636; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.2022 0.1981 0.1449 0.1398 0.1261 0.1189 0.1127 0.1087 0.1052 0.1019 0.0994 0.0970 0.0953 0.0944 0.0930 0.0926 

[TRAIN] Epoch[1](4061/114412); Loss: 0.090655; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.2041 0.1990 0.1135 0.1142 0.0822 0.0778 0.0733 0.0713 0.0686 0.0666 0.0658 0.0644 0.0639 0.0629 0.0617 0.0611 

[TRAIN] Epoch[1](4062/114412); Loss: 0.096435; Backpropagation: 0.2911 sec; Batch: 2.1292 sec
0.1889 0.1853 0.1203 0.1162 0.0972 0.0917 0.0842 0.0811 0.0783 0.0756 0.0741 0.0724 0.0709 0.0698 0.0689 0.0682 

[TRAIN] Epoch[1](4063/114412); Loss: 0.068506; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1145 0.1129 0.0802 0.0765 0.0716 0.0683 0.0654 0.0627 0.0604 0.0586 0.0568 0.0554 0.0542 0.0535 0.0528 0.0523 

[TRAIN] Epoch[1](4064/114412); Loss: 0.098993; Backpropagation: 0.2911 sec; Batch: 2.1139 sec
0.1822 0.1845 0.1168 0.1135 0.0977 0.0939 0.0908 0.0861 0.0837 0.0807 0.0788 0.0773 0.0758 0.0748 0.0741 0.0732 

[TRAIN] Epoch[1](4065/114412); Loss: 0.086395; Backpropagation: 0.2932 sec; Batch: 2.1209 sec
0.1675 0.1646 0.1207 0.1148 0.0979 0.0884 0.0759 0.0714 0.0674 0.0646 0.0625 0.0601 0.0584 0.0573 0.0558 0.0550 

[TRAIN] Epoch[1](4066/114412); Loss: 0.104553; Backpropagation: 0.2918 sec; Batch: 2.1159 sec
0.1916 0.1912 0.1314 0.1276 0.1117 0.1032 0.0938 0.0899 0.0865 0.0829 0.0810 0.0793 0.0774 0.0762 0.0751 0.0741 

[TRAIN] Epoch[1](4067/114412); Loss: 0.071613; Backpropagation: 0.2912 sec; Batch: 2.1156 sec
0.1275 0.1251 0.0908 0.0867 0.0724 0.0694 0.0649 0.0614 0.0593 0.0584 0.0573 0.0561 0.0554 0.0545 0.0535 0.0530 

[TRAIN] Epoch[1](4068/114412); Loss: 0.088728; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1916 0.1916 0.1155 0.1110 0.0860 0.0802 0.0730 0.0705 0.0683 0.0652 0.0633 0.0625 0.0613 0.0606 0.0600 0.0592 

[TRAIN] Epoch[1](4069/114412); Loss: 0.076190; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1286 0.1266 0.0986 0.0950 0.0848 0.0794 0.0727 0.0681 0.0636 0.0614 0.0594 0.0585 0.0575 0.0557 0.0550 0.0540 

[TRAIN] Epoch[1](4070/114412); Loss: 0.091795; Backpropagation: 0.2908 sec; Batch: 2.1138 sec
0.1663 0.1673 0.1164 0.1114 0.0899 0.0864 0.0823 0.0787 0.0759 0.0739 0.0723 0.0714 0.0703 0.0695 0.0688 0.0680 

[TRAIN] Epoch[1](4071/114412); Loss: 0.054493; Backpropagation: 0.2916 sec; Batch: 2.1147 sec
0.1128 0.1098 0.0721 0.0681 0.0549 0.0520 0.0483 0.0448 0.0433 0.0418 0.0403 0.0385 0.0376 0.0366 0.0357 0.0352 

[TRAIN] Epoch[1](4072/114412); Loss: 0.094936; Backpropagation: 0.2950 sec; Batch: 2.1203 sec
0.1757 0.1746 0.1340 0.1202 0.0994 0.0900 0.0840 0.0803 0.0763 0.0744 0.0721 0.0700 0.0685 0.0674 0.0664 0.0655 

[TRAIN] Epoch[1](4073/114412); Loss: 0.107911; Backpropagation: 0.2918 sec; Batch: 2.1172 sec
0.2092 0.2043 0.1405 0.1339 0.1036 0.0991 0.0932 0.0900 0.0862 0.0848 0.0827 0.0819 0.0807 0.0798 0.0787 0.0780 

[TRAIN] Epoch[1](4074/114412); Loss: 0.101582; Backpropagation: 0.2909 sec; Batch: 2.1103 sec
0.1854 0.1820 0.1243 0.1203 0.1012 0.0971 0.0930 0.0887 0.0857 0.0829 0.0810 0.0791 0.0775 0.0766 0.0756 0.0749 

[TRAIN] Epoch[1](4075/114412); Loss: 0.104832; Backpropagation: 0.2912 sec; Batch: 2.1752 sec
0.1748 0.1721 0.1226 0.1192 0.1072 0.1034 0.0979 0.0944 0.0910 0.0893 0.0874 0.0857 0.0845 0.0835 0.0825 0.0818 

[TRAIN] Epoch[1](4076/114412); Loss: 0.099028; Backpropagation: 0.2910 sec; Batch: 2.1326 sec
0.1683 0.1716 0.1198 0.1143 0.0996 0.0957 0.0910 0.0873 0.0846 0.0824 0.0810 0.0794 0.0785 0.0776 0.0769 0.0765 

[TRAIN] Epoch[1](4077/114412); Loss: 0.102743; Backpropagation: 0.2927 sec; Batch: 2.1236 sec
0.2078 0.2060 0.1352 0.1301 0.0999 0.0952 0.0906 0.0845 0.0806 0.0780 0.0758 0.0743 0.0728 0.0718 0.0709 0.0702 

[TRAIN] Epoch[1](4078/114412); Loss: 0.083227; Backpropagation: 0.2912 sec; Batch: 2.4337 sec
0.1616 0.1612 0.1151 0.1111 0.0890 0.0786 0.0715 0.0656 0.0640 0.0618 0.0606 0.0596 0.0589 0.0584 0.0577 0.0570 

[TRAIN] Epoch[1](4079/114412); Loss: 0.093027; Backpropagation: 0.2912 sec; Batch: 2.0826 sec
0.1786 0.1764 0.1185 0.1124 0.1039 0.0959 0.0861 0.0798 0.0751 0.0712 0.0687 0.0668 0.0653 0.0642 0.0632 0.0622 

[TRAIN] Epoch[1](4080/114412); Loss: 0.102633; Backpropagation: 0.2922 sec; Batch: 2.1504 sec
0.1729 0.1711 0.1218 0.1204 0.1077 0.1029 0.0970 0.0929 0.0893 0.0855 0.0833 0.0815 0.0804 0.0794 0.0784 0.0777 

[TRAIN] Epoch[1](4081/114412); Loss: 0.093717; Backpropagation: 0.2929 sec; Batch: 2.1132 sec
0.1781 0.1752 0.1263 0.1191 0.0952 0.0902 0.0810 0.0776 0.0748 0.0726 0.0713 0.0698 0.0682 0.0673 0.0666 0.0661 

[TRAIN] Epoch[1](4082/114412); Loss: 0.083315; Backpropagation: 0.2916 sec; Batch: 2.1439 sec
0.1548 0.1541 0.1157 0.1066 0.0912 0.0854 0.0768 0.0708 0.0668 0.0630 0.0609 0.0597 0.0584 0.0573 0.0562 0.0553 

[TRAIN] Epoch[1](4083/114412); Loss: 0.084915; Backpropagation: 0.2921 sec; Batch: 2.0836 sec
0.1521 0.1498 0.1099 0.0996 0.0893 0.0836 0.0788 0.0742 0.0712 0.0682 0.0665 0.0651 0.0640 0.0629 0.0621 0.0614 

[TRAIN] Epoch[1](4084/114412); Loss: 0.078541; Backpropagation: 0.2910 sec; Batch: 2.1439 sec
0.1412 0.1364 0.0961 0.0909 0.0787 0.0759 0.0727 0.0696 0.0672 0.0650 0.0635 0.0620 0.0606 0.0596 0.0589 0.0583 

[TRAIN] Epoch[1](4085/114412); Loss: 0.080349; Backpropagation: 0.2928 sec; Batch: 2.1223 sec
0.1573 0.1516 0.0983 0.0888 0.0797 0.0761 0.0700 0.0669 0.0663 0.0644 0.0629 0.0620 0.0612 0.0605 0.0600 0.0595 

[TRAIN] Epoch[1](4086/114412); Loss: 0.070055; Backpropagation: 0.2915 sec; Batch: 2.2695 sec
0.1649 0.1608 0.1033 0.0967 0.0734 0.0641 0.0589 0.0532 0.0501 0.0470 0.0447 0.0429 0.0413 0.0406 0.0397 0.0392 

[TRAIN] Epoch[1](4087/114412); Loss: 0.096576; Backpropagation: 0.2918 sec; Batch: 2.0785 sec
0.1734 0.1659 0.1278 0.1152 0.1004 0.0946 0.0881 0.0846 0.0814 0.0785 0.0757 0.0743 0.0731 0.0717 0.0708 0.0697 

[TRAIN] Epoch[1](4088/114412); Loss: 0.070924; Backpropagation: 0.2909 sec; Batch: 2.1729 sec
0.1338 0.1309 0.0885 0.0846 0.0722 0.0683 0.0651 0.0617 0.0593 0.0563 0.0547 0.0533 0.0526 0.0520 0.0510 0.0505 

[TRAIN] Epoch[1](4089/114412); Loss: 0.095493; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.1432 0.1431 0.1096 0.1092 0.1074 0.0991 0.0950 0.0903 0.0864 0.0823 0.0800 0.0785 0.0769 0.0764 0.0756 0.0749 

[TRAIN] Epoch[1](4090/114412); Loss: 0.085950; Backpropagation: 0.2925 sec; Batch: 2.1229 sec
0.1820 0.1777 0.1044 0.1023 0.0825 0.0792 0.0736 0.0697 0.0681 0.0655 0.0641 0.0633 0.0618 0.0612 0.0601 0.0598 

[TRAIN] Epoch[1](4091/114412); Loss: 0.077952; Backpropagation: 0.2931 sec; Batch: 2.1129 sec
0.1574 0.1586 0.1005 0.0958 0.0820 0.0776 0.0725 0.0684 0.0634 0.0587 0.0554 0.0534 0.0524 0.0517 0.0502 0.0492 

[TRAIN] Epoch[1](4092/114412); Loss: 0.062812; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1069 0.1051 0.0764 0.0762 0.0695 0.0654 0.0603 0.0565 0.0551 0.0523 0.0500 0.0478 0.0467 0.0460 0.0456 0.0451 

[TRAIN] Epoch[1](4093/114412); Loss: 0.088474; Backpropagation: 0.2911 sec; Batch: 2.0913 sec
0.1678 0.1656 0.1147 0.1111 0.0900 0.0829 0.0789 0.0746 0.0711 0.0691 0.0679 0.0662 0.0650 0.0643 0.0635 0.0630 

[TRAIN] Epoch[1](4094/114412); Loss: 0.078651; Backpropagation: 0.2908 sec; Batch: 2.0934 sec
0.1466 0.1440 0.0980 0.0948 0.0830 0.0761 0.0721 0.0668 0.0647 0.0626 0.0608 0.0594 0.0582 0.0578 0.0569 0.0567 

[TRAIN] Epoch[1](4095/114412); Loss: 0.079336; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.1574 0.1511 0.1013 0.0959 0.0768 0.0736 0.0696 0.0663 0.0647 0.0624 0.0613 0.0598 0.0584 0.0576 0.0569 0.0564 

[TRAIN] Epoch[1](4096/114412); Loss: 0.073560; Backpropagation: 0.2951 sec; Batch: 2.1261 sec
0.1433 0.1393 0.0974 0.0894 0.0759 0.0683 0.0647 0.0629 0.0592 0.0565 0.0552 0.0544 0.0538 0.0530 0.0521 0.0515 

[TRAIN] Epoch[1](4097/114412); Loss: 0.098555; Backpropagation: 0.2951 sec; Batch: 2.1190 sec
0.1821 0.1788 0.1289 0.1176 0.1004 0.0949 0.0877 0.0837 0.0810 0.0784 0.0775 0.0760 0.0740 0.0729 0.0717 0.0712 

[TRAIN] Epoch[1](4098/114412); Loss: 0.088005; Backpropagation: 0.2931 sec; Batch: 2.1156 sec
0.1712 0.1661 0.1079 0.1045 0.0942 0.0906 0.0809 0.0737 0.0695 0.0669 0.0656 0.0649 0.0640 0.0632 0.0626 0.0620 

[TRAIN] Epoch[1](4099/114412); Loss: 0.102007; Backpropagation: 0.2931 sec; Batch: 2.1183 sec
0.1806 0.1796 0.1305 0.1253 0.1014 0.0973 0.0920 0.0881 0.0844 0.0825 0.0810 0.0798 0.0788 0.0776 0.0770 0.0764 

[TRAIN] Epoch[1](4100/114412); Loss: 0.087291; Backpropagation: 0.2917 sec; Batch: 2.0841 sec
0.1626 0.1610 0.1090 0.1032 0.0943 0.0895 0.0785 0.0739 0.0720 0.0690 0.0673 0.0655 0.0645 0.0634 0.0618 0.0610 

[TRAIN] Epoch[1](4101/114412); Loss: 0.067746; Backpropagation: 0.2906 sec; Batch: 2.1162 sec
0.1489 0.1478 0.1038 0.0910 0.0681 0.0629 0.0564 0.0516 0.0488 0.0470 0.0456 0.0444 0.0431 0.0422 0.0414 0.0409 

[TRAIN] Epoch[1](4102/114412); Loss: 0.102737; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1724 0.1698 0.1281 0.1228 0.1077 0.1029 0.0954 0.0892 0.0862 0.0849 0.0834 0.0819 0.0810 0.0802 0.0793 0.0787 

[TRAIN] Epoch[1](4103/114412); Loss: 0.112098; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1946 0.1898 0.1442 0.1386 0.1146 0.1110 0.1040 0.0985 0.0950 0.0913 0.0893 0.0871 0.0858 0.0847 0.0830 0.0821 

[TRAIN] Epoch[1](4104/114412); Loss: 0.068871; Backpropagation: 0.2901 sec; Batch: 2.1161 sec
0.1289 0.1274 0.0836 0.0807 0.0727 0.0677 0.0627 0.0585 0.0565 0.0549 0.0532 0.0522 0.0514 0.0508 0.0505 0.0502 

[TRAIN] Epoch[1](4105/114412); Loss: 0.091732; Backpropagation: 0.2913 sec; Batch: 2.1280 sec
0.1616 0.1595 0.1233 0.1156 0.0950 0.0880 0.0812 0.0777 0.0750 0.0733 0.0717 0.0706 0.0699 0.0691 0.0685 0.0677 

[TRAIN] Epoch[1](4106/114412); Loss: 0.102321; Backpropagation: 0.2909 sec; Batch: 2.1209 sec
0.2303 0.2287 0.1433 0.1367 0.0924 0.0897 0.0843 0.0776 0.0737 0.0725 0.0706 0.0693 0.0679 0.0673 0.0666 0.0662 

[TRAIN] Epoch[1](4107/114412); Loss: 0.101129; Backpropagation: 0.2910 sec; Batch: 2.1131 sec
0.2002 0.1985 0.1343 0.1311 0.1157 0.1093 0.0979 0.0868 0.0783 0.0735 0.0707 0.0686 0.0670 0.0634 0.0620 0.0610 

[TRAIN] Epoch[1](4108/114412); Loss: 0.080245; Backpropagation: 0.2913 sec; Batch: 2.1125 sec
0.1508 0.1488 0.1073 0.1038 0.0863 0.0801 0.0724 0.0668 0.0640 0.0621 0.0604 0.0584 0.0570 0.0561 0.0553 0.0546 

[TRAIN] Epoch[1](4109/114412); Loss: 0.075236; Backpropagation: 0.2925 sec; Batch: 2.1168 sec
0.1302 0.1247 0.0922 0.0884 0.0766 0.0734 0.0686 0.0668 0.0643 0.0630 0.0614 0.0606 0.0596 0.0587 0.0579 0.0573 

[TRAIN] Epoch[1](4110/114412); Loss: 0.087570; Backpropagation: 0.2909 sec; Batch: 2.1126 sec
0.1513 0.1507 0.1185 0.1160 0.0925 0.0856 0.0787 0.0751 0.0717 0.0690 0.0677 0.0668 0.0658 0.0646 0.0639 0.0633 

[TRAIN] Epoch[1](4111/114412); Loss: 0.078271; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.1472 0.1443 0.1043 0.0976 0.0841 0.0787 0.0711 0.0667 0.0623 0.0604 0.0586 0.0576 0.0561 0.0551 0.0544 0.0538 

[TRAIN] Epoch[1](4112/114412); Loss: 0.091213; Backpropagation: 0.2908 sec; Batch: 2.1177 sec
0.1779 0.1769 0.1175 0.1148 0.0953 0.0880 0.0807 0.0756 0.0722 0.0696 0.0678 0.0667 0.0654 0.0645 0.0635 0.0631 

[TRAIN] Epoch[1](4113/114412); Loss: 0.119484; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.2251 0.2257 0.1458 0.1416 0.1144 0.1105 0.1048 0.1014 0.0985 0.0958 0.0942 0.0927 0.0914 0.0907 0.0899 0.0892 

[TRAIN] Epoch[1](4114/114412); Loss: 0.068101; Backpropagation: 0.2928 sec; Batch: 2.1193 sec
0.1428 0.1400 0.0960 0.0901 0.0641 0.0598 0.0565 0.0529 0.0513 0.0504 0.0496 0.0486 0.0477 0.0470 0.0466 0.0462 

[TRAIN] Epoch[1](4115/114412); Loss: 0.071693; Backpropagation: 0.2914 sec; Batch: 2.1162 sec
0.1385 0.1322 0.0879 0.0864 0.0731 0.0685 0.0653 0.0624 0.0588 0.0567 0.0553 0.0544 0.0532 0.0520 0.0515 0.0509 

[TRAIN] Epoch[1](4116/114412); Loss: 0.090150; Backpropagation: 0.2909 sec; Batch: 2.1152 sec
0.1702 0.1713 0.1317 0.1282 0.0958 0.0869 0.0782 0.0718 0.0695 0.0660 0.0640 0.0633 0.0625 0.0617 0.0609 0.0603 

[TRAIN] Epoch[1](4117/114412); Loss: 0.099947; Backpropagation: 0.2906 sec; Batch: 2.1152 sec
0.1889 0.1876 0.1324 0.1286 0.1045 0.0996 0.0904 0.0830 0.0796 0.0770 0.0745 0.0729 0.0712 0.0704 0.0697 0.0690 

[TRAIN] Epoch[1](4118/114412); Loss: 0.095843; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1889 0.1853 0.1220 0.1179 0.0947 0.0903 0.0814 0.0796 0.0767 0.0748 0.0735 0.0718 0.0707 0.0694 0.0686 0.0679 

[TRAIN] Epoch[1](4119/114412); Loss: 0.077720; Backpropagation: 0.2927 sec; Batch: 2.1152 sec
0.1597 0.1563 0.0995 0.0935 0.0835 0.0736 0.0708 0.0659 0.0619 0.0586 0.0568 0.0549 0.0537 0.0524 0.0516 0.0507 

[TRAIN] Epoch[1](4120/114412); Loss: 0.078770; Backpropagation: 0.2916 sec; Batch: 2.1163 sec
0.1611 0.1551 0.1087 0.1059 0.0777 0.0729 0.0646 0.0597 0.0583 0.0580 0.0578 0.0567 0.0563 0.0561 0.0558 0.0556 

[TRAIN] Epoch[1](4121/114412); Loss: 0.086386; Backpropagation: 0.2908 sec; Batch: 2.1161 sec
0.1492 0.1445 0.1119 0.1057 0.0888 0.0844 0.0772 0.0748 0.0721 0.0705 0.0692 0.0681 0.0674 0.0666 0.0661 0.0657 

[TRAIN] Epoch[1](4122/114412); Loss: 0.108484; Backpropagation: 0.2915 sec; Batch: 2.1191 sec
0.2344 0.2338 0.1539 0.1489 0.0993 0.0955 0.0910 0.0840 0.0802 0.0767 0.0755 0.0740 0.0732 0.0724 0.0716 0.0713 

[TRAIN] Epoch[1](4123/114412); Loss: 0.081015; Backpropagation: 0.2911 sec; Batch: 2.1187 sec
0.1848 0.1811 0.1097 0.1055 0.0695 0.0682 0.0628 0.0612 0.0596 0.0585 0.0577 0.0566 0.0560 0.0555 0.0549 0.0547 

[TRAIN] Epoch[1](4124/114412); Loss: 0.087077; Backpropagation: 0.2912 sec; Batch: 2.1158 sec
0.1422 0.1393 0.1066 0.1032 0.0890 0.0860 0.0803 0.0777 0.0754 0.0738 0.0724 0.0712 0.0702 0.0693 0.0687 0.0682 

[TRAIN] Epoch[1](4125/114412); Loss: 0.075981; Backpropagation: 0.2908 sec; Batch: 2.1136 sec
0.1487 0.1477 0.0970 0.0934 0.0772 0.0734 0.0659 0.0630 0.0598 0.0579 0.0570 0.0562 0.0554 0.0547 0.0543 0.0538 

[TRAIN] Epoch[1](4126/114412); Loss: 0.101627; Backpropagation: 0.2907 sec; Batch: 2.1230 sec
0.2114 0.2099 0.1350 0.1262 0.0994 0.0936 0.0874 0.0804 0.0769 0.0753 0.0744 0.0730 0.0718 0.0712 0.0704 0.0697 

[TRAIN] Epoch[1](4127/114412); Loss: 0.076173; Backpropagation: 0.2909 sec; Batch: 2.1205 sec
0.1821 0.1827 0.0962 0.0954 0.0688 0.0643 0.0589 0.0564 0.0547 0.0535 0.0526 0.0518 0.0512 0.0506 0.0500 0.0498 

[TRAIN] Epoch[1](4128/114412); Loss: 0.075594; Backpropagation: 0.2909 sec; Batch: 2.1198 sec
0.1575 0.1537 0.0994 0.0958 0.0741 0.0677 0.0634 0.0604 0.0588 0.0565 0.0556 0.0546 0.0540 0.0532 0.0525 0.0522 

[TRAIN] Epoch[1](4129/114412); Loss: 0.073893; Backpropagation: 0.2906 sec; Batch: 2.1161 sec
0.1572 0.1565 0.0957 0.0899 0.0734 0.0675 0.0631 0.0601 0.0581 0.0557 0.0532 0.0521 0.0514 0.0501 0.0494 0.0489 

[TRAIN] Epoch[1](4130/114412); Loss: 0.094621; Backpropagation: 0.2911 sec; Batch: 2.0920 sec
0.1660 0.1627 0.1223 0.1134 0.0973 0.0903 0.0848 0.0817 0.0791 0.0769 0.0758 0.0746 0.0734 0.0727 0.0718 0.0713 

[TRAIN] Epoch[1](4131/114412); Loss: 0.070710; Backpropagation: 0.2912 sec; Batch: 2.1129 sec
0.1450 0.1419 0.0965 0.0951 0.0688 0.0663 0.0604 0.0577 0.0550 0.0527 0.0515 0.0499 0.0490 0.0480 0.0472 0.0465 

[TRAIN] Epoch[1](4132/114412); Loss: 0.082389; Backpropagation: 0.2909 sec; Batch: 2.1135 sec
0.1891 0.1875 0.1152 0.1114 0.0789 0.0731 0.0672 0.0632 0.0583 0.0564 0.0553 0.0543 0.0533 0.0523 0.0517 0.0511 

[TRAIN] Epoch[1](4133/114412); Loss: 0.124739; Backpropagation: 0.2908 sec; Batch: 2.1137 sec
0.1695 0.1575 0.1337 0.1295 0.1256 0.1242 0.1222 0.1201 0.1179 0.1170 0.1158 0.1146 0.1137 0.1125 0.1114 0.1107 

[TRAIN] Epoch[1](4134/114412); Loss: 0.088489; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.1535 0.1501 0.1052 0.1006 0.0892 0.0843 0.0811 0.0781 0.0756 0.0741 0.0730 0.0716 0.0712 0.0701 0.0694 0.0688 

[TRAIN] Epoch[1](4135/114412); Loss: 0.075656; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1951 0.1865 0.0832 0.0837 0.0703 0.0651 0.0589 0.0564 0.0552 0.0531 0.0521 0.0512 0.0506 0.0501 0.0497 0.0491 

[TRAIN] Epoch[1](4136/114412); Loss: 0.105353; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1972 0.1951 0.1321 0.1275 0.1026 0.0986 0.0943 0.0912 0.0875 0.0849 0.0827 0.0803 0.0793 0.0783 0.0775 0.0768 

[TRAIN] Epoch[1](4137/114412); Loss: 0.064269; Backpropagation: 0.2911 sec; Batch: 2.1144 sec
0.1236 0.1230 0.0867 0.0803 0.0701 0.0653 0.0595 0.0553 0.0532 0.0486 0.0470 0.0454 0.0440 0.0427 0.0422 0.0415 

[TRAIN] Epoch[1](4138/114412); Loss: 0.072949; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1319 0.1306 0.0930 0.0895 0.0760 0.0718 0.0655 0.0619 0.0605 0.0583 0.0572 0.0558 0.0548 0.0541 0.0535 0.0528 

[TRAIN] Epoch[1](4139/114412); Loss: 0.103664; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.2051 0.2016 0.1362 0.1313 0.1030 0.0975 0.0917 0.0856 0.0820 0.0790 0.0774 0.0760 0.0744 0.0735 0.0727 0.0717 

[TRAIN] Epoch[1](4140/114412); Loss: 0.101907; Backpropagation: 0.2912 sec; Batch: 2.0818 sec
0.1889 0.1852 0.1309 0.1270 0.1118 0.1027 0.0931 0.0873 0.0833 0.0805 0.0783 0.0750 0.0735 0.0725 0.0706 0.0699 

[TRAIN] Epoch[1](4141/114412); Loss: 0.092989; Backpropagation: 0.2930 sec; Batch: 2.1006 sec
0.2210 0.2185 0.1259 0.1202 0.0879 0.0825 0.0732 0.0679 0.0671 0.0644 0.0626 0.0614 0.0601 0.0594 0.0582 0.0575 

[TRAIN] Epoch[1](4142/114412); Loss: 0.077978; Backpropagation: 0.2911 sec; Batch: 2.1143 sec
0.1448 0.1410 0.1064 0.1021 0.0838 0.0755 0.0673 0.0638 0.0621 0.0603 0.0595 0.0580 0.0572 0.0560 0.0553 0.0547 

[TRAIN] Epoch[1](4143/114412); Loss: 0.085197; Backpropagation: 0.2927 sec; Batch: 2.1147 sec
0.1481 0.1470 0.1090 0.1071 0.0904 0.0832 0.0781 0.0753 0.0715 0.0679 0.0662 0.0652 0.0646 0.0641 0.0632 0.0624 

[TRAIN] Epoch[1](4144/114412); Loss: 0.096633; Backpropagation: 0.2925 sec; Batch: 2.0812 sec
0.1950 0.1904 0.1320 0.1267 0.0970 0.0914 0.0840 0.0780 0.0739 0.0717 0.0699 0.0689 0.0679 0.0671 0.0665 0.0658 

[TRAIN] Epoch[1](4145/114412); Loss: 0.080366; Backpropagation: 0.2918 sec; Batch: 2.0780 sec
0.1406 0.1342 0.1189 0.1141 0.0987 0.0845 0.0737 0.0648 0.0644 0.0618 0.0591 0.0566 0.0549 0.0540 0.0532 0.0525 

[TRAIN] Epoch[1](4146/114412); Loss: 0.077421; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.1559 0.1485 0.0997 0.0972 0.0784 0.0737 0.0676 0.0637 0.0618 0.0596 0.0581 0.0568 0.0555 0.0546 0.0541 0.0533 

[TRAIN] Epoch[1](4147/114412); Loss: 0.077527; Backpropagation: 0.2909 sec; Batch: 2.1162 sec
0.1591 0.1564 0.0972 0.0952 0.0847 0.0767 0.0647 0.0617 0.0590 0.0577 0.0567 0.0552 0.0545 0.0541 0.0539 0.0536 

[TRAIN] Epoch[1](4148/114412); Loss: 0.082379; Backpropagation: 0.2908 sec; Batch: 2.1172 sec
0.1472 0.1433 0.1228 0.1179 0.0885 0.0802 0.0725 0.0688 0.0662 0.0638 0.0613 0.0596 0.0582 0.0568 0.0558 0.0552 

[TRAIN] Epoch[1](4149/114412); Loss: 0.104182; Backpropagation: 0.2911 sec; Batch: 2.1146 sec
0.1856 0.1827 0.1245 0.1195 0.1063 0.1000 0.0942 0.0906 0.0879 0.0857 0.0838 0.0827 0.0818 0.0811 0.0804 0.0801 

[TRAIN] Epoch[1](4150/114412); Loss: 0.093813; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1739 0.1700 0.1089 0.1080 0.0948 0.0896 0.0839 0.0804 0.0777 0.0762 0.0750 0.0740 0.0733 0.0723 0.0718 0.0713 

[TRAIN] Epoch[1](4151/114412); Loss: 0.088919; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1788 0.1771 0.1141 0.1137 0.0895 0.0805 0.0776 0.0752 0.0741 0.0690 0.0659 0.0630 0.0618 0.0613 0.0607 0.0602 

[TRAIN] Epoch[1](4152/114412); Loss: 0.064424; Backpropagation: 0.2908 sec; Batch: 2.1135 sec
0.1268 0.1227 0.0888 0.0839 0.0714 0.0640 0.0580 0.0529 0.0497 0.0480 0.0463 0.0450 0.0443 0.0435 0.0431 0.0424 

[TRAIN] Epoch[1](4153/114412); Loss: 0.081123; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1830 0.1782 0.1053 0.1000 0.0786 0.0740 0.0695 0.0651 0.0617 0.0583 0.0568 0.0554 0.0542 0.0534 0.0524 0.0520 

[TRAIN] Epoch[1](4154/114412); Loss: 0.101839; Backpropagation: 0.2913 sec; Batch: 2.1186 sec
0.2209 0.2106 0.1434 0.1252 0.1015 0.0927 0.0827 0.0791 0.0765 0.0759 0.0740 0.0720 0.0705 0.0691 0.0681 0.0673 

[TRAIN] Epoch[1](4155/114412); Loss: 0.102263; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1993 0.1985 0.1340 0.1261 0.1040 0.0968 0.0897 0.0833 0.0804 0.0788 0.0772 0.0757 0.0745 0.0733 0.0728 0.0719 

[TRAIN] Epoch[1](4156/114412); Loss: 0.093144; Backpropagation: 0.2901 sec; Batch: 2.1123 sec
0.1772 0.1783 0.1345 0.1207 0.0986 0.0910 0.0854 0.0790 0.0743 0.0694 0.0678 0.0656 0.0638 0.0626 0.0614 0.0606 

[TRAIN] Epoch[1](4157/114412); Loss: 0.090608; Backpropagation: 0.2904 sec; Batch: 2.1176 sec
0.1827 0.1800 0.1179 0.1114 0.0897 0.0824 0.0783 0.0754 0.0731 0.0703 0.0687 0.0667 0.0653 0.0637 0.0626 0.0616 

[TRAIN] Epoch[1](4158/114412); Loss: 0.068430; Backpropagation: 0.2928 sec; Batch: 2.1204 sec
0.1451 0.1427 0.0890 0.0861 0.0704 0.0659 0.0600 0.0558 0.0527 0.0504 0.0486 0.0472 0.0462 0.0455 0.0448 0.0445 

[TRAIN] Epoch[1](4159/114412); Loss: 0.123472; Backpropagation: 0.2929 sec; Batch: 2.1608 sec
0.1900 0.1875 0.1425 0.1396 0.1259 0.1222 0.1160 0.1128 0.1098 0.1081 0.1059 0.1048 0.1039 0.1028 0.1021 0.1016 

[TRAIN] Epoch[1](4160/114412); Loss: 0.093207; Backpropagation: 0.2912 sec; Batch: 2.1089 sec
0.1804 0.1726 0.1138 0.1087 0.0941 0.0890 0.0835 0.0799 0.0769 0.0748 0.0729 0.0714 0.0699 0.0688 0.0677 0.0669 

[TRAIN] Epoch[1](4161/114412); Loss: 0.067941; Backpropagation: 0.2911 sec; Batch: 2.1250 sec
0.1740 0.1742 0.0831 0.0811 0.0637 0.0603 0.0536 0.0503 0.0478 0.0457 0.0443 0.0430 0.0423 0.0416 0.0411 0.0409 

[TRAIN] Epoch[1](4162/114412); Loss: 0.093840; Backpropagation: 0.2909 sec; Batch: 2.2932 sec
0.1594 0.1543 0.1068 0.1044 0.0968 0.0928 0.0884 0.0831 0.0805 0.0794 0.0782 0.0772 0.0762 0.0755 0.0747 0.0739 

[TRAIN] Epoch[1](4163/114412); Loss: 0.097602; Backpropagation: 0.2915 sec; Batch: 2.0986 sec
0.1721 0.1684 0.1239 0.1140 0.1030 0.0965 0.0920 0.0868 0.0825 0.0790 0.0770 0.0755 0.0743 0.0733 0.0721 0.0714 

[TRAIN] Epoch[1](4164/114412); Loss: 0.105247; Backpropagation: 0.2915 sec; Batch: 2.1703 sec
0.1532 0.1538 0.1261 0.1225 0.1097 0.1052 0.0993 0.0968 0.0948 0.0918 0.0909 0.0896 0.0887 0.0879 0.0871 0.0865 

[TRAIN] Epoch[1](4165/114412); Loss: 0.091454; Backpropagation: 0.2917 sec; Batch: 2.0781 sec
0.1689 0.1666 0.1273 0.1199 0.1070 0.0966 0.0875 0.0793 0.0723 0.0680 0.0654 0.0633 0.0617 0.0607 0.0598 0.0589 

[TRAIN] Epoch[1](4166/114412); Loss: 0.095058; Backpropagation: 0.2927 sec; Batch: 2.1524 sec
0.1699 0.1670 0.1163 0.1125 0.0985 0.0913 0.0842 0.0813 0.0794 0.0778 0.0764 0.0753 0.0738 0.0732 0.0723 0.0718 

[TRAIN] Epoch[1](4167/114412); Loss: 0.082403; Backpropagation: 0.2929 sec; Batch: 2.1132 sec
0.1487 0.1399 0.1018 0.0969 0.0857 0.0794 0.0756 0.0721 0.0703 0.0681 0.0660 0.0646 0.0635 0.0626 0.0618 0.0613 

[TRAIN] Epoch[1](4168/114412); Loss: 0.068043; Backpropagation: 0.2953 sec; Batch: 2.2207 sec
0.1195 0.1177 0.0955 0.0863 0.0722 0.0665 0.0604 0.0584 0.0560 0.0543 0.0524 0.0514 0.0504 0.0497 0.0492 0.0489 

[TRAIN] Epoch[1](4169/114412); Loss: 0.095529; Backpropagation: 0.2929 sec; Batch: 2.3299 sec
0.1701 0.1693 0.1320 0.1225 0.1002 0.0923 0.0860 0.0808 0.0777 0.0751 0.0735 0.0718 0.0705 0.0696 0.0689 0.0681 

[TRAIN] Epoch[1](4170/114412); Loss: 0.092121; Backpropagation: 0.2927 sec; Batch: 2.2338 sec
0.1587 0.1541 0.1161 0.1096 0.0956 0.0883 0.0828 0.0801 0.0776 0.0759 0.0746 0.0737 0.0729 0.0721 0.0713 0.0708 

[TRAIN] Epoch[1](4171/114412); Loss: 0.073795; Backpropagation: 0.2912 sec; Batch: 2.1502 sec
0.1312 0.1311 0.0995 0.0908 0.0768 0.0705 0.0658 0.0635 0.0617 0.0591 0.0575 0.0562 0.0551 0.0544 0.0539 0.0535 

[TRAIN] Epoch[1](4172/114412); Loss: 0.067568; Backpropagation: 0.2907 sec; Batch: 2.1405 sec
0.1285 0.1255 0.0871 0.0821 0.0780 0.0722 0.0644 0.0583 0.0543 0.0518 0.0494 0.0477 0.0464 0.0457 0.0451 0.0445 

[TRAIN] Epoch[1](4173/114412); Loss: 0.098233; Backpropagation: 0.2929 sec; Batch: 2.1109 sec
0.1765 0.1758 0.1341 0.1243 0.1077 0.1003 0.0915 0.0859 0.0813 0.0775 0.0743 0.0713 0.0697 0.0684 0.0671 0.0660 

[TRAIN] Epoch[1](4174/114412); Loss: 0.094934; Backpropagation: 0.2911 sec; Batch: 2.1427 sec
0.1636 0.1605 0.1268 0.1165 0.1032 0.0950 0.0877 0.0839 0.0803 0.0779 0.0745 0.0729 0.0709 0.0695 0.0682 0.0674 

[TRAIN] Epoch[1](4175/114412); Loss: 0.089983; Backpropagation: 0.2914 sec; Batch: 2.1073 sec
0.1699 0.1672 0.1250 0.1144 0.1041 0.0954 0.0843 0.0789 0.0727 0.0669 0.0646 0.0629 0.0605 0.0589 0.0576 0.0564 

[TRAIN] Epoch[1](4176/114412); Loss: 0.112573; Backpropagation: 0.2910 sec; Batch: 2.1510 sec
0.1928 0.1887 0.1414 0.1340 0.1123 0.1059 0.1022 0.0980 0.0955 0.0932 0.0921 0.0907 0.0897 0.0888 0.0881 0.0876 

[TRAIN] Epoch[1](4177/114412); Loss: 0.105305; Backpropagation: 0.2914 sec; Batch: 2.1159 sec
0.1631 0.1605 0.1318 0.1260 0.1121 0.1078 0.1008 0.0958 0.0927 0.0899 0.0877 0.0862 0.0846 0.0835 0.0817 0.0805 

[TRAIN] Epoch[1](4178/114412); Loss: 0.109073; Backpropagation: 0.2923 sec; Batch: 2.0780 sec
0.1903 0.1834 0.1283 0.1249 0.1072 0.1031 0.0988 0.0957 0.0934 0.0913 0.0899 0.0890 0.0882 0.0878 0.0872 0.0867 

[TRAIN] Epoch[1](4179/114412); Loss: 0.106016; Backpropagation: 0.2912 sec; Batch: 2.1240 sec
0.1990 0.1901 0.1571 0.1401 0.1172 0.1009 0.0910 0.0877 0.0833 0.0801 0.0779 0.0766 0.0752 0.0742 0.0734 0.0725 

[TRAIN] Epoch[1](4180/114412); Loss: 0.083451; Backpropagation: 0.2928 sec; Batch: 2.1806 sec
0.1454 0.1401 0.1084 0.1032 0.0886 0.0824 0.0765 0.0735 0.0707 0.0688 0.0660 0.0646 0.0633 0.0620 0.0613 0.0605 

[TRAIN] Epoch[1](4181/114412); Loss: 0.105393; Backpropagation: 0.2951 sec; Batch: 2.1152 sec
0.1683 0.1679 0.1421 0.1342 0.1179 0.1084 0.0988 0.0928 0.0883 0.0853 0.0835 0.0820 0.0809 0.0796 0.0788 0.0777 

[TRAIN] Epoch[1](4182/114412); Loss: 0.101953; Backpropagation: 0.2923 sec; Batch: 2.2623 sec
0.1749 0.1731 0.1371 0.1309 0.1142 0.1072 0.0989 0.0903 0.0847 0.0808 0.0781 0.0755 0.0736 0.0719 0.0707 0.0695 

[TRAIN] Epoch[1](4183/114412); Loss: 0.085411; Backpropagation: 0.2909 sec; Batch: 2.1760 sec
0.1528 0.1469 0.1090 0.1007 0.0858 0.0829 0.0785 0.0754 0.0726 0.0694 0.0678 0.0669 0.0655 0.0649 0.0642 0.0632 

[TRAIN] Epoch[1](4184/114412); Loss: 0.093003; Backpropagation: 0.2912 sec; Batch: 2.1379 sec
0.1770 0.1742 0.1269 0.1189 0.0970 0.0909 0.0837 0.0782 0.0747 0.0720 0.0693 0.0676 0.0660 0.0648 0.0639 0.0630 

[TRAIN] Epoch[1](4185/114412); Loss: 0.100381; Backpropagation: 0.2912 sec; Batch: 2.1520 sec
0.1693 0.1661 0.1263 0.1179 0.1006 0.0964 0.0911 0.0876 0.0860 0.0843 0.0828 0.0816 0.0803 0.0795 0.0787 0.0777 

[TRAIN] Epoch[1](4186/114412); Loss: 0.072463; Backpropagation: 0.2912 sec; Batch: 2.1082 sec
0.1574 0.1573 0.0948 0.0908 0.0786 0.0711 0.0632 0.0580 0.0542 0.0515 0.0500 0.0487 0.0472 0.0463 0.0454 0.0449 

[TRAIN] Epoch[1](4187/114412); Loss: 0.060241; Backpropagation: 0.2911 sec; Batch: 2.1452 sec
0.1068 0.1022 0.0788 0.0709 0.0637 0.0579 0.0529 0.0514 0.0502 0.0489 0.0484 0.0472 0.0467 0.0463 0.0458 0.0457 

[TRAIN] Epoch[1](4188/114412); Loss: 0.109247; Backpropagation: 0.2923 sec; Batch: 2.0783 sec
0.1742 0.1734 0.1236 0.1209 0.1102 0.1060 0.1008 0.0977 0.0964 0.0949 0.0937 0.0928 0.0919 0.0910 0.0904 0.0899 

[TRAIN] Epoch[1](4189/114412); Loss: 0.089065; Backpropagation: 0.2910 sec; Batch: 2.1469 sec
0.1534 0.1529 0.1346 0.1208 0.0968 0.0866 0.0814 0.0760 0.0723 0.0693 0.0672 0.0655 0.0639 0.0626 0.0615 0.0602 

[TRAIN] Epoch[1](4190/114412); Loss: 0.077525; Backpropagation: 0.2909 sec; Batch: 2.1194 sec
0.1467 0.1458 0.1056 0.0971 0.0770 0.0740 0.0690 0.0655 0.0636 0.0604 0.0589 0.0572 0.0561 0.0553 0.0543 0.0538 

[TRAIN] Epoch[1](4191/114412); Loss: 0.064437; Backpropagation: 0.2924 sec; Batch: 2.2329 sec
0.1377 0.1332 0.0840 0.0781 0.0616 0.0573 0.0541 0.0504 0.0499 0.0481 0.0480 0.0471 0.0463 0.0458 0.0448 0.0446 

[TRAIN] Epoch[1](4192/114412); Loss: 0.070810; Backpropagation: 0.2926 sec; Batch: 2.1079 sec
0.1343 0.1350 0.1077 0.0951 0.0767 0.0701 0.0645 0.0586 0.0547 0.0527 0.0503 0.0485 0.0475 0.0462 0.0459 0.0451 

[TRAIN] Epoch[1](4193/114412); Loss: 0.101849; Backpropagation: 0.2911 sec; Batch: 2.1810 sec
0.1759 0.1717 0.1364 0.1266 0.1128 0.1057 0.0968 0.0888 0.0849 0.0812 0.0795 0.0769 0.0746 0.0737 0.0726 0.0716 

[TRAIN] Epoch[1](4194/114412); Loss: 0.088463; Backpropagation: 0.2912 sec; Batch: 2.1132 sec
0.1636 0.1596 0.1142 0.1078 0.0872 0.0824 0.0786 0.0747 0.0727 0.0708 0.0693 0.0684 0.0675 0.0668 0.0661 0.0657 

[TRAIN] Epoch[1](4195/114412); Loss: 0.104811; Backpropagation: 0.2908 sec; Batch: 2.1464 sec
0.1823 0.1766 0.1332 0.1261 0.1057 0.0999 0.0953 0.0915 0.0889 0.0862 0.0847 0.0833 0.0822 0.0811 0.0806 0.0794 

[TRAIN] Epoch[1](4196/114412); Loss: 0.073637; Backpropagation: 0.2951 sec; Batch: 2.1150 sec
0.1372 0.1359 0.0987 0.0926 0.0768 0.0709 0.0654 0.0627 0.0600 0.0578 0.0563 0.0546 0.0534 0.0527 0.0520 0.0513 

[TRAIN] Epoch[1](4197/114412); Loss: 0.081862; Backpropagation: 0.2931 sec; Batch: 2.1462 sec
0.1669 0.1646 0.1097 0.1000 0.0811 0.0781 0.0716 0.0667 0.0643 0.0618 0.0605 0.0588 0.0574 0.0568 0.0562 0.0553 

[TRAIN] Epoch[1](4198/114412); Loss: 0.077845; Backpropagation: 0.2910 sec; Batch: 2.1111 sec
0.1569 0.1549 0.1046 0.0946 0.0857 0.0807 0.0714 0.0658 0.0607 0.0580 0.0558 0.0536 0.0522 0.0511 0.0501 0.0495 

[TRAIN] Epoch[1](4199/114412); Loss: 0.081202; Backpropagation: 0.2911 sec; Batch: 2.3629 sec
0.1442 0.1419 0.1089 0.1001 0.0825 0.0791 0.0736 0.0703 0.0679 0.0653 0.0638 0.0621 0.0611 0.0603 0.0593 0.0587 

[TRAIN] Epoch[1](4200/114412); Loss: 0.054095; Backpropagation: 0.2916 sec; Batch: 2.1468 sec
0.1137 0.1105 0.0751 0.0681 0.0540 0.0493 0.0462 0.0433 0.0416 0.0397 0.0390 0.0384 0.0372 0.0368 0.0364 0.0361 

[TRAIN] Epoch[1](4201/114412); Loss: 0.081987; Backpropagation: 0.2956 sec; Batch: 2.1023 sec
0.1537 0.1523 0.1035 0.0984 0.0789 0.0749 0.0717 0.0692 0.0682 0.0659 0.0647 0.0633 0.0624 0.0619 0.0614 0.0612 

[TRAIN] Epoch[1](4202/114412); Loss: 0.083861; Backpropagation: 0.2955 sec; Batch: 2.1202 sec
0.1525 0.1501 0.1091 0.1033 0.0867 0.0796 0.0747 0.0713 0.0688 0.0669 0.0653 0.0640 0.0634 0.0627 0.0620 0.0615 

[TRAIN] Epoch[1](4203/114412); Loss: 0.074090; Backpropagation: 0.2930 sec; Batch: 2.1064 sec
0.1549 0.1527 0.1021 0.0993 0.0722 0.0665 0.0613 0.0580 0.0561 0.0545 0.0534 0.0524 0.0514 0.0506 0.0501 0.0498 

[TRAIN] Epoch[1](4204/114412); Loss: 0.091699; Backpropagation: 0.2933 sec; Batch: 2.2740 sec
0.2033 0.2001 0.1180 0.1114 0.0821 0.0792 0.0765 0.0729 0.0699 0.0677 0.0668 0.0657 0.0645 0.0638 0.0630 0.0622 

[TRAIN] Epoch[1](4205/114412); Loss: 0.066054; Backpropagation: 0.2952 sec; Batch: 2.1815 sec
0.1507 0.1503 0.0950 0.0896 0.0588 0.0546 0.0511 0.0491 0.0475 0.0460 0.0454 0.0445 0.0440 0.0436 0.0434 0.0432 

[TRAIN] Epoch[1](4206/114412); Loss: 0.088367; Backpropagation: 0.2950 sec; Batch: 2.1137 sec
0.1804 0.1790 0.1097 0.1051 0.0861 0.0803 0.0762 0.0730 0.0709 0.0685 0.0670 0.0655 0.0644 0.0634 0.0625 0.0618 

[TRAIN] Epoch[1](4207/114412); Loss: 0.070917; Backpropagation: 0.2933 sec; Batch: 2.0969 sec
0.1366 0.1365 0.0906 0.0784 0.0708 0.0706 0.0681 0.0605 0.0569 0.0545 0.0533 0.0526 0.0517 0.0517 0.0509 0.0510 

[TRAIN] Epoch[1](4208/114412); Loss: 0.093711; Backpropagation: 0.2908 sec; Batch: 2.1848 sec
0.1563 0.1541 0.1208 0.1153 0.1009 0.0935 0.0851 0.0823 0.0798 0.0767 0.0756 0.0739 0.0724 0.0717 0.0709 0.0703 

[TRAIN] Epoch[1](4209/114412); Loss: 0.081891; Backpropagation: 0.2909 sec; Batch: 2.2459 sec
0.1620 0.1599 0.1129 0.1055 0.0831 0.0764 0.0706 0.0669 0.0648 0.0621 0.0608 0.0593 0.0581 0.0569 0.0558 0.0551 

[TRAIN] Epoch[1](4210/114412); Loss: 0.074752; Backpropagation: 0.2909 sec; Batch: 2.1112 sec
0.1386 0.1350 0.0943 0.0905 0.0758 0.0729 0.0679 0.0641 0.0619 0.0598 0.0586 0.0574 0.0560 0.0551 0.0544 0.0537 

[TRAIN] Epoch[1](4211/114412); Loss: 0.070528; Backpropagation: 0.2912 sec; Batch: 2.1661 sec
0.1509 0.1494 0.0964 0.0917 0.0724 0.0683 0.0607 0.0559 0.0530 0.0508 0.0491 0.0479 0.0468 0.0459 0.0450 0.0444 

[TRAIN] Epoch[1](4212/114412); Loss: 0.088118; Backpropagation: 0.2914 sec; Batch: 2.1070 sec
0.1638 0.1622 0.1134 0.1102 0.0864 0.0819 0.0771 0.0739 0.0717 0.0695 0.0686 0.0675 0.0668 0.0661 0.0655 0.0651 

[TRAIN] Epoch[1](4213/114412); Loss: 0.103837; Backpropagation: 0.2910 sec; Batch: 2.1461 sec
0.1611 0.1609 0.1218 0.1186 0.1052 0.1019 0.0973 0.0944 0.0926 0.0901 0.0886 0.0872 0.0865 0.0857 0.0851 0.0845 

[TRAIN] Epoch[1](4214/114412); Loss: 0.120423; Backpropagation: 0.2910 sec; Batch: 2.0912 sec
0.2009 0.1953 0.1401 0.1374 0.1206 0.1170 0.1101 0.1068 0.1042 0.1020 0.1013 0.0999 0.0989 0.0982 0.0973 0.0967 

[TRAIN] Epoch[1](4215/114412); Loss: 0.084712; Backpropagation: 0.2915 sec; Batch: 2.1450 sec
0.1827 0.1767 0.1126 0.1010 0.0836 0.0782 0.0723 0.0683 0.0657 0.0635 0.0616 0.0600 0.0585 0.0577 0.0568 0.0562 

[TRAIN] Epoch[1](4216/114412); Loss: 0.089632; Backpropagation: 0.2912 sec; Batch: 2.0786 sec
0.1545 0.1490 0.1119 0.1057 0.0898 0.0861 0.0819 0.0791 0.0767 0.0748 0.0731 0.0719 0.0708 0.0701 0.0697 0.0690 

[TRAIN] Epoch[1](4217/114412); Loss: 0.087154; Backpropagation: 0.2915 sec; Batch: 2.1457 sec
0.1685 0.1619 0.1189 0.1080 0.0895 0.0831 0.0781 0.0728 0.0699 0.0668 0.0656 0.0642 0.0630 0.0621 0.0614 0.0606 

[TRAIN] Epoch[1](4218/114412); Loss: 0.084597; Backpropagation: 0.2914 sec; Batch: 2.0783 sec
0.1392 0.1382 0.1044 0.0968 0.0852 0.0821 0.0793 0.0758 0.0743 0.0718 0.0702 0.0692 0.0675 0.0670 0.0666 0.0660 

[TRAIN] Epoch[1](4219/114412); Loss: 0.099616; Backpropagation: 0.2913 sec; Batch: 2.1547 sec
0.1778 0.1727 0.1309 0.1240 0.1010 0.0964 0.0901 0.0862 0.0830 0.0801 0.0783 0.0766 0.0755 0.0747 0.0735 0.0729 

[TRAIN] Epoch[1](4220/114412); Loss: 0.104205; Backpropagation: 0.2930 sec; Batch: 2.0793 sec
0.2059 0.2042 0.1470 0.1373 0.1068 0.1006 0.0901 0.0853 0.0817 0.0779 0.0757 0.0732 0.0719 0.0709 0.0699 0.0688 

[TRAIN] Epoch[1](4221/114412); Loss: 0.093138; Backpropagation: 0.2913 sec; Batch: 2.1518 sec
0.1751 0.1688 0.1167 0.1092 0.0886 0.0849 0.0812 0.0791 0.0773 0.0757 0.0747 0.0736 0.0730 0.0716 0.0708 0.0700 

[TRAIN] Epoch[1](4222/114412); Loss: 0.079901; Backpropagation: 0.2917 sec; Batch: 2.0795 sec
0.1776 0.1719 0.0980 0.0893 0.0740 0.0705 0.0677 0.0636 0.0620 0.0602 0.0591 0.0583 0.0575 0.0567 0.0563 0.0558 

[TRAIN] Epoch[1](4223/114412); Loss: 0.094464; Backpropagation: 0.2910 sec; Batch: 2.1436 sec
0.1963 0.1922 0.1250 0.1173 0.0960 0.0896 0.0819 0.0780 0.0741 0.0705 0.0684 0.0668 0.0655 0.0643 0.0633 0.0623 

[TRAIN] Epoch[1](4224/114412); Loss: 0.079291; Backpropagation: 0.2913 sec; Batch: 2.5034 sec
0.1351 0.1335 0.1020 0.0942 0.0816 0.0782 0.0737 0.0699 0.0673 0.0653 0.0636 0.0624 0.0614 0.0607 0.0602 0.0596 

[TRAIN] Epoch[1](4225/114412); Loss: 0.087742; Backpropagation: 0.2909 sec; Batch: 2.1030 sec
0.1472 0.1460 0.1093 0.0970 0.0852 0.0814 0.0787 0.0764 0.0752 0.0740 0.0735 0.0730 0.0724 0.0719 0.0716 0.0711 

[TRAIN] Epoch[1](4226/114412); Loss: 0.067964; Backpropagation: 0.2907 sec; Batch: 2.0778 sec
0.1330 0.1293 0.0995 0.0899 0.0745 0.0652 0.0597 0.0548 0.0520 0.0502 0.0490 0.0478 0.0470 0.0459 0.0451 0.0447 

[TRAIN] Epoch[1](4227/114412); Loss: 0.076876; Backpropagation: 0.2909 sec; Batch: 2.1284 sec
0.1390 0.1348 0.0985 0.0949 0.0782 0.0733 0.0698 0.0667 0.0644 0.0624 0.0606 0.0592 0.0581 0.0574 0.0568 0.0561 

[TRAIN] Epoch[1](4228/114412); Loss: 0.092648; Backpropagation: 0.2911 sec; Batch: 2.0767 sec
0.2102 0.2026 0.1305 0.1264 0.0919 0.0866 0.0844 0.0766 0.0704 0.0643 0.0594 0.0587 0.0569 0.0556 0.0545 0.0533 

[TRAIN] Epoch[1](4229/114412); Loss: 0.077921; Backpropagation: 0.2909 sec; Batch: 2.1518 sec
0.1469 0.1421 0.0925 0.0859 0.0758 0.0720 0.0685 0.0667 0.0649 0.0637 0.0630 0.0618 0.0614 0.0608 0.0605 0.0603 

[TRAIN] Epoch[1](4230/114412); Loss: 0.082342; Backpropagation: 0.2906 sec; Batch: 2.1119 sec
0.1582 0.1535 0.1053 0.0973 0.0810 0.0768 0.0730 0.0696 0.0673 0.0659 0.0641 0.0630 0.0619 0.0609 0.0602 0.0595 

[TRAIN] Epoch[1](4231/114412); Loss: 0.096354; Backpropagation: 0.2952 sec; Batch: 2.1595 sec
0.1709 0.1712 0.1293 0.1213 0.1067 0.1015 0.0920 0.0843 0.0799 0.0757 0.0720 0.0700 0.0683 0.0674 0.0660 0.0650 

[TRAIN] Epoch[1](4232/114412); Loss: 0.068828; Backpropagation: 0.2927 sec; Batch: 2.1130 sec
0.1800 0.1694 0.0887 0.0820 0.0645 0.0589 0.0549 0.0504 0.0482 0.0466 0.0455 0.0443 0.0431 0.0422 0.0416 0.0410 

[TRAIN] Epoch[1](4233/114412); Loss: 0.082178; Backpropagation: 0.2913 sec; Batch: 2.1466 sec
0.1317 0.1274 0.0977 0.0940 0.0846 0.0808 0.0770 0.0747 0.0729 0.0710 0.0694 0.0684 0.0673 0.0667 0.0661 0.0654 

[TRAIN] Epoch[1](4234/114412); Loss: 0.078119; Backpropagation: 0.2912 sec; Batch: 2.2394 sec
0.1598 0.1530 0.0996 0.0952 0.0784 0.0750 0.0698 0.0650 0.0618 0.0594 0.0578 0.0566 0.0556 0.0548 0.0542 0.0538 

[TRAIN] Epoch[1](4235/114412); Loss: 0.096115; Backpropagation: 0.2929 sec; Batch: 2.1272 sec
0.1703 0.1628 0.1126 0.1072 0.0970 0.0922 0.0873 0.0845 0.0821 0.0802 0.0787 0.0777 0.0771 0.0764 0.0759 0.0756 

[TRAIN] Epoch[1](4236/114412); Loss: 0.090671; Backpropagation: 0.2910 sec; Batch: 2.2940 sec
0.1449 0.1403 0.1176 0.1106 0.0980 0.0928 0.0862 0.0823 0.0788 0.0760 0.0738 0.0723 0.0710 0.0697 0.0685 0.0679 

[TRAIN] Epoch[1](4237/114412); Loss: 0.083366; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1574 0.1504 0.1064 0.0994 0.0842 0.0786 0.0727 0.0696 0.0680 0.0661 0.0654 0.0644 0.0637 0.0631 0.0626 0.0619 

[TRAIN] Epoch[1](4238/114412); Loss: 0.077212; Backpropagation: 0.2913 sec; Batch: 2.0774 sec
0.1512 0.1418 0.0916 0.0879 0.0771 0.0729 0.0685 0.0651 0.0632 0.0616 0.0610 0.0599 0.0593 0.0587 0.0581 0.0577 

[TRAIN] Epoch[1](4239/114412); Loss: 0.087275; Backpropagation: 0.2911 sec; Batch: 2.1094 sec
0.1867 0.1817 0.1127 0.1067 0.0858 0.0802 0.0711 0.0691 0.0677 0.0655 0.0639 0.0627 0.0618 0.0608 0.0603 0.0597 

[TRAIN] Epoch[1](4240/114412); Loss: 0.093864; Backpropagation: 0.2907 sec; Batch: 2.1198 sec
0.1818 0.1757 0.1185 0.1122 0.0943 0.0896 0.0840 0.0793 0.0767 0.0739 0.0722 0.0708 0.0695 0.0687 0.0678 0.0669 

[TRAIN] Epoch[1](4241/114412); Loss: 0.075172; Backpropagation: 0.2913 sec; Batch: 2.1144 sec
0.1566 0.1516 0.0973 0.0925 0.0734 0.0694 0.0652 0.0614 0.0590 0.0568 0.0555 0.0544 0.0535 0.0527 0.0519 0.0514 

[TRAIN] Epoch[1](4242/114412); Loss: 0.082014; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.1608 0.1534 0.1043 0.1017 0.0844 0.0804 0.0723 0.0692 0.0651 0.0636 0.0618 0.0607 0.0597 0.0589 0.0583 0.0579 

[TRAIN] Epoch[1](4243/114412); Loss: 0.087893; Backpropagation: 0.2915 sec; Batch: 2.1181 sec
0.1745 0.1710 0.1239 0.1074 0.0850 0.0782 0.0724 0.0703 0.0687 0.0670 0.0664 0.0655 0.0649 0.0642 0.0636 0.0633 

[TRAIN] Epoch[1](4244/114412); Loss: 0.098274; Backpropagation: 0.2913 sec; Batch: 2.1145 sec
0.1623 0.1546 0.1192 0.1127 0.1001 0.0953 0.0916 0.0885 0.0865 0.0840 0.0821 0.0808 0.0797 0.0792 0.0784 0.0775 

[TRAIN] Epoch[1](4245/114412); Loss: 0.085261; Backpropagation: 0.2914 sec; Batch: 2.1273 sec
0.1507 0.1476 0.1100 0.1042 0.0868 0.0821 0.0773 0.0742 0.0715 0.0693 0.0676 0.0662 0.0652 0.0644 0.0638 0.0633 

[TRAIN] Epoch[1](4246/114412); Loss: 0.060318; Backpropagation: 0.2935 sec; Batch: 2.1205 sec
0.1243 0.1217 0.0945 0.0795 0.0622 0.0577 0.0504 0.0476 0.0443 0.0427 0.0417 0.0407 0.0400 0.0396 0.0392 0.0390 

[TRAIN] Epoch[1](4247/114412); Loss: 0.071980; Backpropagation: 0.2931 sec; Batch: 2.0848 sec
0.1394 0.1339 0.0957 0.0863 0.0716 0.0679 0.0642 0.0599 0.0581 0.0563 0.0548 0.0540 0.0530 0.0526 0.0522 0.0517 

[TRAIN] Epoch[1](4248/114412); Loss: 0.072233; Backpropagation: 0.2910 sec; Batch: 2.1025 sec
0.1488 0.1430 0.0958 0.0872 0.0751 0.0695 0.0645 0.0595 0.0560 0.0538 0.0524 0.0513 0.0505 0.0499 0.0495 0.0489 

[TRAIN] Epoch[1](4249/114412); Loss: 0.073273; Backpropagation: 0.2912 sec; Batch: 2.1135 sec
0.1415 0.1381 0.0923 0.0855 0.0717 0.0680 0.0649 0.0615 0.0598 0.0579 0.0567 0.0560 0.0553 0.0548 0.0545 0.0540 

[TRAIN] Epoch[1](4250/114412); Loss: 0.094526; Backpropagation: 0.2931 sec; Batch: 2.1154 sec
0.1707 0.1627 0.1225 0.1109 0.0947 0.0901 0.0856 0.0816 0.0789 0.0769 0.0753 0.0740 0.0733 0.0724 0.0718 0.0711 

[TRAIN] Epoch[1](4251/114412); Loss: 0.080907; Backpropagation: 0.2912 sec; Batch: 2.1156 sec
0.1380 0.1349 0.0980 0.0968 0.0819 0.0798 0.0737 0.0720 0.0692 0.0677 0.0661 0.0650 0.0639 0.0631 0.0625 0.0618 

[TRAIN] Epoch[1](4252/114412); Loss: 0.092630; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1776 0.1650 0.1112 0.1060 0.0931 0.0881 0.0817 0.0779 0.0764 0.0745 0.0735 0.0726 0.0718 0.0713 0.0709 0.0706 

[TRAIN] Epoch[1](4253/114412); Loss: 0.083280; Backpropagation: 0.2929 sec; Batch: 2.1160 sec
0.1598 0.1554 0.1007 0.0981 0.0834 0.0795 0.0740 0.0709 0.0685 0.0666 0.0650 0.0636 0.0626 0.0619 0.0613 0.0608 

[TRAIN] Epoch[1](4254/114412); Loss: 0.078015; Backpropagation: 0.2931 sec; Batch: 2.1162 sec
0.1603 0.1523 0.1034 0.0948 0.0763 0.0707 0.0658 0.0632 0.0612 0.0594 0.0582 0.0576 0.0568 0.0564 0.0561 0.0557 

[TRAIN] Epoch[1](4255/114412); Loss: 0.061440; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1340 0.1260 0.0836 0.0736 0.0602 0.0553 0.0507 0.0497 0.0476 0.0457 0.0448 0.0437 0.0428 0.0424 0.0418 0.0412 

[TRAIN] Epoch[1](4256/114412); Loss: 0.073896; Backpropagation: 0.2920 sec; Batch: 2.1195 sec
0.1837 0.1677 0.0962 0.0921 0.0737 0.0645 0.0577 0.0543 0.0523 0.0514 0.0501 0.0490 0.0482 0.0476 0.0472 0.0469 

[TRAIN] Epoch[1](4257/114412); Loss: 0.082080; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.1377 0.1326 0.1019 0.0964 0.0831 0.0800 0.0765 0.0734 0.0712 0.0694 0.0677 0.0665 0.0651 0.0645 0.0639 0.0634 

[TRAIN] Epoch[1](4258/114412); Loss: 0.079417; Backpropagation: 0.2909 sec; Batch: 2.1164 sec
0.2180 0.2034 0.1135 0.1098 0.0736 0.0679 0.0571 0.0540 0.0522 0.0498 0.0481 0.0464 0.0452 0.0444 0.0440 0.0434 

[TRAIN] Epoch[1](4259/114412); Loss: 0.082690; Backpropagation: 0.2910 sec; Batch: 2.1186 sec
0.1844 0.1757 0.1128 0.1038 0.0844 0.0771 0.0701 0.0641 0.0615 0.0598 0.0578 0.0563 0.0552 0.0541 0.0532 0.0526 

[TRAIN] Epoch[1](4260/114412); Loss: 0.067944; Backpropagation: 0.2910 sec; Batch: 2.0938 sec
0.1366 0.1342 0.0853 0.0816 0.0635 0.0616 0.0581 0.0556 0.0545 0.0528 0.0520 0.0511 0.0505 0.0502 0.0498 0.0497 

[TRAIN] Epoch[1](4261/114412); Loss: 0.087239; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1711 0.1654 0.1130 0.1059 0.0853 0.0802 0.0752 0.0731 0.0710 0.0692 0.0673 0.0656 0.0647 0.0636 0.0630 0.0623 

[TRAIN] Epoch[1](4262/114412); Loss: 0.089987; Backpropagation: 0.2908 sec; Batch: 2.1642 sec
0.1579 0.1506 0.1182 0.1121 0.0931 0.0878 0.0817 0.0786 0.0752 0.0730 0.0715 0.0700 0.0690 0.0679 0.0670 0.0663 

[TRAIN] Epoch[1](4263/114412); Loss: 0.084480; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1458 0.1401 0.1038 0.0983 0.0866 0.0827 0.0791 0.0756 0.0734 0.0705 0.0689 0.0675 0.0661 0.0651 0.0644 0.0638 

[TRAIN] Epoch[1](4264/114412); Loss: 0.072401; Backpropagation: 0.2911 sec; Batch: 2.1131 sec
0.1318 0.1241 0.0939 0.0903 0.0774 0.0709 0.0657 0.0623 0.0600 0.0578 0.0561 0.0554 0.0543 0.0534 0.0528 0.0525 

[TRAIN] Epoch[1](4265/114412); Loss: 0.066459; Backpropagation: 0.2927 sec; Batch: 2.1190 sec
0.1418 0.1332 0.0929 0.0836 0.0641 0.0580 0.0540 0.0519 0.0503 0.0491 0.0482 0.0477 0.0476 0.0473 0.0470 0.0468 

[TRAIN] Epoch[1](4266/114412); Loss: 0.080401; Backpropagation: 0.2928 sec; Batch: 2.1179 sec
0.1479 0.1408 0.1029 0.0925 0.0840 0.0797 0.0743 0.0701 0.0678 0.0650 0.0634 0.0617 0.0604 0.0595 0.0586 0.0579 

[TRAIN] Epoch[1](4267/114412); Loss: 0.072323; Backpropagation: 0.2911 sec; Batch: 2.1156 sec
0.1313 0.1279 0.0954 0.0845 0.0726 0.0686 0.0651 0.0627 0.0608 0.0585 0.0572 0.0561 0.0552 0.0543 0.0537 0.0532 

[TRAIN] Epoch[1](4268/114412); Loss: 0.095441; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1748 0.1678 0.1098 0.1080 0.0941 0.0903 0.0845 0.0823 0.0803 0.0784 0.0775 0.0768 0.0763 0.0759 0.0753 0.0750 

[TRAIN] Epoch[1](4269/114412); Loss: 0.084175; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1621 0.1543 0.1083 0.1003 0.0863 0.0820 0.0761 0.0720 0.0689 0.0660 0.0645 0.0628 0.0619 0.0612 0.0603 0.0598 

[TRAIN] Epoch[1](4270/114412); Loss: 0.070617; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1668 0.1601 0.0982 0.0905 0.0645 0.0609 0.0540 0.0531 0.0515 0.0493 0.0482 0.0477 0.0470 0.0466 0.0459 0.0456 

[TRAIN] Epoch[1](4271/114412); Loss: 0.097796; Backpropagation: 0.2917 sec; Batch: 2.1158 sec
0.1731 0.1684 0.1192 0.1147 0.1045 0.0990 0.0928 0.0862 0.0830 0.0797 0.0770 0.0758 0.0744 0.0730 0.0723 0.0715 

[TRAIN] Epoch[1](4272/114412); Loss: 0.112798; Backpropagation: 0.2934 sec; Batch: 2.1175 sec
0.2026 0.1972 0.1349 0.1313 0.1151 0.1075 0.1009 0.0969 0.0949 0.0923 0.0911 0.0900 0.0889 0.0880 0.0869 0.0864 

[TRAIN] Epoch[1](4273/114412); Loss: 0.075446; Backpropagation: 0.2927 sec; Batch: 2.0861 sec
0.1573 0.1505 0.1011 0.0922 0.0779 0.0722 0.0658 0.0620 0.0599 0.0569 0.0549 0.0534 0.0521 0.0512 0.0503 0.0496 

[TRAIN] Epoch[1](4274/114412); Loss: 0.061315; Backpropagation: 0.2918 sec; Batch: 2.0784 sec
0.1278 0.1122 0.0820 0.0750 0.0661 0.0615 0.0566 0.0515 0.0484 0.0457 0.0444 0.0433 0.0428 0.0418 0.0412 0.0407 

[TRAIN] Epoch[1](4275/114412); Loss: 0.083087; Backpropagation: 0.2915 sec; Batch: 2.1172 sec
0.1520 0.1410 0.1056 0.1004 0.0859 0.0806 0.0751 0.0715 0.0696 0.0674 0.0659 0.0647 0.0634 0.0627 0.0621 0.0615 

[TRAIN] Epoch[1](4276/114412); Loss: 0.088392; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1618 0.1552 0.1247 0.1163 0.1026 0.0952 0.0839 0.0766 0.0706 0.0659 0.0633 0.0616 0.0606 0.0596 0.0586 0.0579 

[TRAIN] Epoch[1](4277/114412); Loss: 0.097843; Backpropagation: 0.2914 sec; Batch: 2.1137 sec
0.1518 0.1468 0.1151 0.1107 0.1005 0.0967 0.0927 0.0899 0.0879 0.0859 0.0839 0.0824 0.0813 0.0804 0.0799 0.0795 

[TRAIN] Epoch[1](4278/114412); Loss: 0.071345; Backpropagation: 0.2914 sec; Batch: 2.1141 sec
0.1398 0.1350 0.0958 0.0857 0.0785 0.0697 0.0618 0.0597 0.0581 0.0547 0.0528 0.0518 0.0507 0.0496 0.0491 0.0487 

[TRAIN] Epoch[1](4279/114412); Loss: 0.073278; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1402 0.1380 0.0937 0.0823 0.0744 0.0686 0.0651 0.0620 0.0600 0.0587 0.0573 0.0558 0.0551 0.0543 0.0536 0.0532 

[TRAIN] Epoch[1](4280/114412); Loss: 0.075334; Backpropagation: 0.2909 sec; Batch: 2.1132 sec
0.1734 0.1675 0.0916 0.0832 0.0736 0.0677 0.0627 0.0602 0.0580 0.0557 0.0546 0.0533 0.0520 0.0513 0.0506 0.0501 

[TRAIN] Epoch[1](4281/114412); Loss: 0.065298; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1216 0.1179 0.0808 0.0776 0.0648 0.0619 0.0581 0.0556 0.0541 0.0529 0.0517 0.0507 0.0497 0.0494 0.0492 0.0489 

[TRAIN] Epoch[1](4282/114412); Loss: 0.072775; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1291 0.1258 0.0957 0.0838 0.0765 0.0698 0.0668 0.0632 0.0612 0.0594 0.0577 0.0569 0.0557 0.0548 0.0543 0.0539 

[TRAIN] Epoch[1](4283/114412); Loss: 0.054043; Backpropagation: 0.2913 sec; Batch: 2.1221 sec
0.0984 0.0928 0.0701 0.0603 0.0557 0.0525 0.0496 0.0478 0.0462 0.0446 0.0430 0.0418 0.0411 0.0405 0.0402 0.0400 

[TRAIN] Epoch[1](4284/114412); Loss: 0.066061; Backpropagation: 0.2905 sec; Batch: 2.1240 sec
0.1475 0.1394 0.0926 0.0726 0.0696 0.0641 0.0584 0.0529 0.0494 0.0476 0.0464 0.0448 0.0440 0.0433 0.0426 0.0421 

[TRAIN] Epoch[1](4285/114412); Loss: 0.068978; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1280 0.1269 0.0895 0.0775 0.0692 0.0652 0.0616 0.0589 0.0569 0.0555 0.0540 0.0532 0.0527 0.0520 0.0514 0.0511 

[TRAIN] Epoch[1](4286/114412); Loss: 0.083073; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1263 0.1245 0.1017 0.0987 0.0897 0.0871 0.0810 0.0768 0.0739 0.0717 0.0699 0.0681 0.0669 0.0653 0.0642 0.0634 

[TRAIN] Epoch[1](4287/114412); Loss: 0.086751; Backpropagation: 0.2912 sec; Batch: 2.0784 sec
0.1688 0.1638 0.1077 0.0995 0.0875 0.0823 0.0766 0.0726 0.0704 0.0682 0.0677 0.0662 0.0650 0.0643 0.0640 0.0634 

[TRAIN] Epoch[1](4288/114412); Loss: 0.067000; Backpropagation: 0.2917 sec; Batch: 2.1153 sec
0.1350 0.1318 0.0883 0.0807 0.0686 0.0642 0.0588 0.0557 0.0528 0.0509 0.0499 0.0485 0.0476 0.0469 0.0463 0.0460 

[TRAIN] Epoch[1](4289/114412); Loss: 0.069829; Backpropagation: 0.2922 sec; Batch: 2.1180 sec
0.1108 0.1085 0.0807 0.0804 0.0734 0.0694 0.0656 0.0624 0.0610 0.0594 0.0587 0.0583 0.0578 0.0574 0.0568 0.0565 

[TRAIN] Epoch[1](4290/114412); Loss: 0.102683; Backpropagation: 0.2917 sec; Batch: 2.1235 sec
0.1698 0.1645 0.1236 0.1207 0.1092 0.1013 0.0965 0.0920 0.0888 0.0866 0.0852 0.0837 0.0818 0.0809 0.0796 0.0788 

[TRAIN] Epoch[1](4291/114412); Loss: 0.076675; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1289 0.1244 0.0912 0.0877 0.0793 0.0749 0.0710 0.0678 0.0663 0.0649 0.0638 0.0629 0.0617 0.0612 0.0606 0.0602 

[TRAIN] Epoch[1](4292/114412); Loss: 0.104415; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1798 0.1714 0.1345 0.1242 0.1021 0.0941 0.0917 0.0894 0.0880 0.0871 0.0866 0.0856 0.0847 0.0841 0.0837 0.0834 

[TRAIN] Epoch[1](4293/114412); Loss: 0.071349; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1446 0.1392 0.0968 0.0876 0.0801 0.0744 0.0627 0.0573 0.0549 0.0530 0.0510 0.0500 0.0485 0.0476 0.0471 0.0467 

[TRAIN] Epoch[1](4294/114412); Loss: 0.072485; Backpropagation: 0.2910 sec; Batch: 2.1182 sec
0.1391 0.1350 0.0911 0.0861 0.0736 0.0679 0.0637 0.0611 0.0588 0.0573 0.0560 0.0552 0.0547 0.0539 0.0534 0.0530 

[TRAIN] Epoch[1](4295/114412); Loss: 0.071365; Backpropagation: 0.2913 sec; Batch: 2.1217 sec
0.1479 0.1378 0.0877 0.0825 0.0757 0.0696 0.0640 0.0594 0.0575 0.0551 0.0535 0.0521 0.0512 0.0501 0.0492 0.0486 

[TRAIN] Epoch[1](4296/114412); Loss: 0.073195; Backpropagation: 0.2914 sec; Batch: 2.1312 sec
0.1653 0.1555 0.0918 0.0866 0.0714 0.0659 0.0615 0.0582 0.0566 0.0544 0.0532 0.0520 0.0509 0.0500 0.0493 0.0486 

[TRAIN] Epoch[1](4297/114412); Loss: 0.063446; Backpropagation: 0.2910 sec; Batch: 2.1029 sec
0.1413 0.1360 0.0803 0.0732 0.0617 0.0565 0.0533 0.0509 0.0491 0.0474 0.0465 0.0453 0.0444 0.0436 0.0429 0.0425 

[TRAIN] Epoch[1](4298/114412); Loss: 0.070961; Backpropagation: 0.2905 sec; Batch: 2.1447 sec
0.1598 0.1521 0.0831 0.0744 0.0724 0.0688 0.0649 0.0581 0.0551 0.0525 0.0508 0.0503 0.0491 0.0485 0.0480 0.0475 

[TRAIN] Epoch[1](4299/114412); Loss: 0.073278; Backpropagation: 0.2904 sec; Batch: 2.3291 sec
0.1554 0.1486 0.0835 0.0793 0.0693 0.0661 0.0626 0.0601 0.0588 0.0574 0.0572 0.0558 0.0552 0.0547 0.0544 0.0538 

[TRAIN] Epoch[1](4300/114412); Loss: 0.091990; Backpropagation: 0.2912 sec; Batch: 2.1506 sec
0.1401 0.1346 0.1158 0.1136 0.1028 0.0941 0.0872 0.0821 0.0799 0.0780 0.0764 0.0754 0.0744 0.0735 0.0724 0.0716 

[TRAIN] Epoch[1](4301/114412); Loss: 0.070260; Backpropagation: 0.2913 sec; Batch: 2.1553 sec
0.1568 0.1482 0.0812 0.0751 0.0673 0.0628 0.0599 0.0575 0.0561 0.0545 0.0531 0.0517 0.0507 0.0502 0.0498 0.0492 

[TRAIN] Epoch[1](4302/114412); Loss: 0.070529; Backpropagation: 0.2917 sec; Batch: 2.1120 sec
0.1509 0.1440 0.0945 0.0856 0.0707 0.0673 0.0630 0.0579 0.0547 0.0516 0.0503 0.0493 0.0482 0.0475 0.0468 0.0462 

[TRAIN] Epoch[1](4303/114412); Loss: 0.072617; Backpropagation: 0.2908 sec; Batch: 2.1455 sec
0.1624 0.1546 0.0843 0.0794 0.0735 0.0665 0.0633 0.0600 0.0572 0.0552 0.0535 0.0524 0.0516 0.0502 0.0493 0.0485 

[TRAIN] Epoch[1](4304/114412); Loss: 0.098719; Backpropagation: 0.2910 sec; Batch: 2.1106 sec
0.1568 0.1501 0.1158 0.1104 0.1020 0.0976 0.0924 0.0895 0.0875 0.0854 0.0843 0.0832 0.0822 0.0814 0.0807 0.0802 

[TRAIN] Epoch[1](4305/114412); Loss: 0.096559; Backpropagation: 0.2931 sec; Batch: 2.2782 sec
0.1603 0.1538 0.1186 0.1094 0.1024 0.0968 0.0911 0.0871 0.0843 0.0814 0.0798 0.0786 0.0769 0.0759 0.0750 0.0736 

[TRAIN] Epoch[1](4306/114412); Loss: 0.076638; Backpropagation: 0.2914 sec; Batch: 2.0837 sec
0.1564 0.1516 0.0909 0.0857 0.0782 0.0722 0.0674 0.0644 0.0618 0.0603 0.0588 0.0571 0.0563 0.0555 0.0550 0.0545 

[TRAIN] Epoch[1](4307/114412); Loss: 0.075322; Backpropagation: 0.2952 sec; Batch: 2.1243 sec
0.1462 0.1417 0.0890 0.0855 0.0749 0.0707 0.0669 0.0641 0.0624 0.0605 0.0595 0.0582 0.0575 0.0568 0.0560 0.0553 

[TRAIN] Epoch[1](4308/114412); Loss: 0.063338; Backpropagation: 0.2919 sec; Batch: 2.1044 sec
0.1628 0.1586 0.0847 0.0719 0.0649 0.0553 0.0503 0.0468 0.0448 0.0422 0.0407 0.0393 0.0386 0.0382 0.0375 0.0368 

[TRAIN] Epoch[1](4309/114412); Loss: 0.077593; Backpropagation: 0.2928 sec; Batch: 2.0783 sec
0.1466 0.1416 0.0920 0.0841 0.0807 0.0754 0.0699 0.0670 0.0643 0.0627 0.0613 0.0607 0.0600 0.0591 0.0585 0.0577 

[TRAIN] Epoch[1](4310/114412); Loss: 0.086680; Backpropagation: 0.2953 sec; Batch: 2.0823 sec
0.1533 0.1451 0.1042 0.1007 0.0900 0.0842 0.0796 0.0760 0.0738 0.0719 0.0707 0.0691 0.0680 0.0673 0.0668 0.0661 

[TRAIN] Epoch[1](4311/114412); Loss: 0.091640; Backpropagation: 0.2930 sec; Batch: 2.0824 sec
0.1569 0.1456 0.1072 0.1019 0.0920 0.0878 0.0844 0.0817 0.0796 0.0785 0.0771 0.0761 0.0752 0.0746 0.0740 0.0735 

[TRAIN] Epoch[1](4312/114412); Loss: 0.060837; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1322 0.1238 0.0715 0.0649 0.0576 0.0541 0.0506 0.0493 0.0479 0.0469 0.0465 0.0460 0.0457 0.0456 0.0454 0.0453 

[TRAIN] Epoch[1](4313/114412); Loss: 0.100495; Backpropagation: 0.2910 sec; Batch: 2.1217 sec
0.1900 0.1823 0.1163 0.1100 0.0975 0.0924 0.0905 0.0880 0.0855 0.0830 0.0812 0.0802 0.0789 0.0782 0.0772 0.0767 

[TRAIN] Epoch[1](4314/114412); Loss: 0.089392; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1636 0.1566 0.1106 0.1038 0.0953 0.0888 0.0832 0.0784 0.0750 0.0714 0.0698 0.0688 0.0675 0.0667 0.0656 0.0651 

[TRAIN] Epoch[1](4315/114412); Loss: 0.080559; Backpropagation: 0.2908 sec; Batch: 2.0778 sec
0.1557 0.1485 0.0943 0.0874 0.0821 0.0760 0.0718 0.0690 0.0672 0.0650 0.0638 0.0628 0.0621 0.0615 0.0611 0.0607 

[TRAIN] Epoch[1](4316/114412); Loss: 0.077671; Backpropagation: 0.2907 sec; Batch: 2.1127 sec
0.1468 0.1390 0.1022 0.0926 0.0786 0.0728 0.0681 0.0648 0.0629 0.0615 0.0604 0.0595 0.0590 0.0586 0.0583 0.0577 

[TRAIN] Epoch[1](4317/114412); Loss: 0.057340; Backpropagation: 0.2912 sec; Batch: 2.1158 sec
0.1263 0.1166 0.0775 0.0695 0.0575 0.0541 0.0488 0.0462 0.0441 0.0421 0.0410 0.0401 0.0392 0.0385 0.0381 0.0377 

[TRAIN] Epoch[1](4318/114412); Loss: 0.091404; Backpropagation: 0.2906 sec; Batch: 2.1158 sec
0.1803 0.1694 0.1187 0.1098 0.0910 0.0844 0.0802 0.0755 0.0733 0.0717 0.0704 0.0692 0.0681 0.0672 0.0669 0.0664 

[TRAIN] Epoch[1](4319/114412); Loss: 0.044510; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1047 0.0921 0.0535 0.0489 0.0443 0.0400 0.0386 0.0366 0.0347 0.0333 0.0323 0.0315 0.0309 0.0306 0.0302 0.0300 

[TRAIN] Epoch[1](4320/114412); Loss: 0.066279; Backpropagation: 0.2916 sec; Batch: 2.1183 sec
0.1472 0.1330 0.0792 0.0763 0.0674 0.0618 0.0583 0.0553 0.0540 0.0509 0.0491 0.0475 0.0462 0.0455 0.0445 0.0441 

[TRAIN] Epoch[1](4321/114412); Loss: 0.063808; Backpropagation: 0.2911 sec; Batch: 2.1325 sec
0.1325 0.1287 0.0861 0.0771 0.0666 0.0610 0.0546 0.0520 0.0501 0.0477 0.0465 0.0452 0.0443 0.0435 0.0429 0.0422 

[TRAIN] Epoch[1](4322/114412); Loss: 0.068182; Backpropagation: 0.2953 sec; Batch: 2.1172 sec
0.1343 0.1290 0.0783 0.0747 0.0643 0.0621 0.0604 0.0579 0.0569 0.0555 0.0544 0.0541 0.0531 0.0523 0.0519 0.0516 

[TRAIN] Epoch[1](4323/114412); Loss: 0.090351; Backpropagation: 0.2932 sec; Batch: 2.1197 sec
0.1552 0.1517 0.1122 0.1024 0.0971 0.0912 0.0836 0.0811 0.0768 0.0751 0.0735 0.0708 0.0704 0.0692 0.0677 0.0676 

[TRAIN] Epoch[1](4324/114412); Loss: 0.081522; Backpropagation: 0.2907 sec; Batch: 2.0780 sec
0.1583 0.1471 0.1126 0.1005 0.0836 0.0758 0.0711 0.0679 0.0656 0.0638 0.0623 0.0610 0.0600 0.0591 0.0581 0.0575 

[TRAIN] Epoch[1](4325/114412); Loss: 0.102837; Backpropagation: 0.2909 sec; Batch: 2.1232 sec
0.1661 0.1584 0.1220 0.1140 0.1066 0.1019 0.0966 0.0934 0.0907 0.0888 0.0873 0.0859 0.0848 0.0837 0.0829 0.0822 

[TRAIN] Epoch[1](4326/114412); Loss: 0.069951; Backpropagation: 0.2913 sec; Batch: 2.1275 sec
0.1332 0.1281 0.0899 0.0849 0.0721 0.0648 0.0610 0.0592 0.0572 0.0556 0.0537 0.0530 0.0526 0.0517 0.0512 0.0509 

[TRAIN] Epoch[1](4327/114412); Loss: 0.066151; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.1656 0.1509 0.0808 0.0751 0.0639 0.0575 0.0526 0.0510 0.0489 0.0475 0.0458 0.0448 0.0441 0.0437 0.0433 0.0428 

[TRAIN] Epoch[1](4328/114412); Loss: 0.085734; Backpropagation: 0.2910 sec; Batch: 2.1140 sec
0.1705 0.1659 0.1148 0.1012 0.0872 0.0810 0.0748 0.0704 0.0677 0.0660 0.0644 0.0636 0.0622 0.0614 0.0608 0.0598 

[TRAIN] Epoch[1](4329/114412); Loss: 0.074151; Backpropagation: 0.2933 sec; Batch: 2.1090 sec
0.1648 0.1554 0.0932 0.0844 0.0759 0.0706 0.0641 0.0609 0.0579 0.0548 0.0535 0.0519 0.0507 0.0501 0.0495 0.0489 

[TRAIN] Epoch[1](4330/114412); Loss: 0.069798; Backpropagation: 0.2931 sec; Batch: 2.1204 sec
0.1416 0.1375 0.0858 0.0809 0.0730 0.0681 0.0611 0.0571 0.0552 0.0540 0.0531 0.0517 0.0505 0.0498 0.0491 0.0485 

[TRAIN] Epoch[1](4331/114412); Loss: 0.064215; Backpropagation: 0.2906 sec; Batch: 2.1147 sec
0.1254 0.1155 0.0824 0.0725 0.0686 0.0642 0.0593 0.0548 0.0525 0.0500 0.0493 0.0478 0.0471 0.0464 0.0460 0.0456 

[TRAIN] Epoch[1](4332/114412); Loss: 0.076603; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1418 0.1342 0.0961 0.0883 0.0774 0.0728 0.0678 0.0647 0.0632 0.0617 0.0610 0.0600 0.0595 0.0593 0.0590 0.0588 

[TRAIN] Epoch[1](4333/114412); Loss: 0.048142; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.1101 0.1042 0.0657 0.0540 0.0481 0.0455 0.0419 0.0381 0.0366 0.0347 0.0338 0.0328 0.0321 0.0313 0.0310 0.0305 

[TRAIN] Epoch[1](4334/114412); Loss: 0.073779; Backpropagation: 0.2935 sec; Batch: 2.0799 sec
0.1499 0.1428 0.0943 0.0894 0.0754 0.0714 0.0664 0.0617 0.0595 0.0572 0.0553 0.0536 0.0523 0.0513 0.0504 0.0496 

[TRAIN] Epoch[1](4335/114412); Loss: 0.092071; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1546 0.1482 0.1108 0.1055 0.0959 0.0909 0.0866 0.0826 0.0799 0.0777 0.0761 0.0746 0.0736 0.0726 0.0721 0.0714 

[TRAIN] Epoch[1](4336/114412); Loss: 0.073948; Backpropagation: 0.2913 sec; Batch: 2.0870 sec
0.1508 0.1428 0.0926 0.0880 0.0694 0.0659 0.0634 0.0613 0.0599 0.0576 0.0567 0.0559 0.0553 0.0550 0.0545 0.0542 

[TRAIN] Epoch[1](4337/114412); Loss: 0.070094; Backpropagation: 0.2930 sec; Batch: 2.1189 sec
0.1363 0.1278 0.0957 0.0835 0.0694 0.0661 0.0626 0.0591 0.0571 0.0553 0.0537 0.0526 0.0518 0.0508 0.0501 0.0497 

[TRAIN] Epoch[1](4338/114412); Loss: 0.084614; Backpropagation: 0.2913 sec; Batch: 2.1144 sec
0.1444 0.1381 0.1041 0.0952 0.0863 0.0808 0.0768 0.0746 0.0730 0.0717 0.0707 0.0694 0.0683 0.0674 0.0669 0.0663 

[TRAIN] Epoch[1](4339/114412); Loss: 0.076528; Backpropagation: 0.2915 sec; Batch: 2.1197 sec
0.1494 0.1353 0.0970 0.0914 0.0812 0.0750 0.0671 0.0630 0.0616 0.0601 0.0587 0.0580 0.0572 0.0568 0.0564 0.0562 

[TRAIN] Epoch[1](4340/114412); Loss: 0.106488; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1786 0.1749 0.1437 0.1318 0.1105 0.1044 0.0986 0.0969 0.0920 0.0907 0.0879 0.0817 0.0813 0.0791 0.0762 0.0756 

[TRAIN] Epoch[1](4341/114412); Loss: 0.062580; Backpropagation: 0.2936 sec; Batch: 2.1201 sec
0.1434 0.1346 0.0804 0.0733 0.0597 0.0556 0.0524 0.0500 0.0479 0.0462 0.0452 0.0441 0.0430 0.0424 0.0417 0.0413 

[TRAIN] Epoch[1](4342/114412); Loss: 0.073153; Backpropagation: 0.2928 sec; Batch: 2.1174 sec
0.1513 0.1449 0.1127 0.0883 0.0810 0.0685 0.0620 0.0558 0.0552 0.0530 0.0520 0.0508 0.0498 0.0490 0.0484 0.0478 

[TRAIN] Epoch[1](4343/114412); Loss: 0.086514; Backpropagation: 0.2911 sec; Batch: 2.1264 sec
0.1361 0.1299 0.1002 0.0953 0.0899 0.0856 0.0818 0.0789 0.0773 0.0755 0.0744 0.0733 0.0726 0.0717 0.0710 0.0707 

[TRAIN] Epoch[1](4344/114412); Loss: 0.089100; Backpropagation: 0.2902 sec; Batch: 2.1163 sec
0.1582 0.1509 0.1107 0.1033 0.0921 0.0863 0.0807 0.0775 0.0750 0.0733 0.0720 0.0706 0.0698 0.0691 0.0683 0.0677 

[TRAIN] Epoch[1](4345/114412); Loss: 0.073363; Backpropagation: 0.2914 sec; Batch: 2.1801 sec
0.1571 0.1461 0.0915 0.0817 0.0749 0.0674 0.0627 0.0590 0.0577 0.0562 0.0548 0.0539 0.0533 0.0529 0.0526 0.0521 

[TRAIN] Epoch[1](4346/114412); Loss: 0.075665; Backpropagation: 0.2932 sec; Batch: 2.1250 sec
0.1255 0.1226 0.0947 0.0885 0.0814 0.0777 0.0728 0.0681 0.0649 0.0626 0.0610 0.0599 0.0588 0.0580 0.0573 0.0568 

[TRAIN] Epoch[1](4347/114412); Loss: 0.074314; Backpropagation: 0.2928 sec; Batch: 2.1559 sec
0.1591 0.1531 0.1040 0.0982 0.0813 0.0754 0.0673 0.0612 0.0557 0.0510 0.0496 0.0480 0.0471 0.0465 0.0459 0.0455 

[TRAIN] Epoch[1](4348/114412); Loss: 0.091242; Backpropagation: 0.2915 sec; Batch: 2.2124 sec
0.1597 0.1553 0.1085 0.1025 0.0894 0.0861 0.0821 0.0797 0.0782 0.0764 0.0753 0.0746 0.0740 0.0733 0.0726 0.0722 

[TRAIN] Epoch[1](4349/114412); Loss: 0.101978; Backpropagation: 0.2906 sec; Batch: 2.1110 sec
0.1663 0.1606 0.1219 0.1149 0.1022 0.0972 0.0930 0.0907 0.0888 0.0876 0.0866 0.0858 0.0850 0.0843 0.0837 0.0831 

[TRAIN] Epoch[1](4350/114412); Loss: 0.089975; Backpropagation: 0.2910 sec; Batch: 2.1279 sec
0.1693 0.1629 0.1087 0.1038 0.0923 0.0881 0.0824 0.0779 0.0758 0.0727 0.0707 0.0695 0.0678 0.0666 0.0659 0.0652 

[TRAIN] Epoch[1](4351/114412); Loss: 0.077050; Backpropagation: 0.2918 sec; Batch: 2.0848 sec
0.1367 0.1304 0.0902 0.0864 0.0773 0.0730 0.0700 0.0674 0.0657 0.0648 0.0636 0.0629 0.0619 0.0613 0.0608 0.0603 

[TRAIN] Epoch[1](4352/114412); Loss: 0.060657; Backpropagation: 0.2941 sec; Batch: 2.1387 sec
0.1146 0.1103 0.0786 0.0714 0.0626 0.0590 0.0550 0.0516 0.0490 0.0477 0.0471 0.0461 0.0452 0.0446 0.0440 0.0435 

[TRAIN] Epoch[1](4353/114412); Loss: 0.065362; Backpropagation: 0.2955 sec; Batch: 2.0900 sec
0.1087 0.1066 0.0858 0.0794 0.0684 0.0629 0.0588 0.0565 0.0551 0.0538 0.0528 0.0523 0.0517 0.0514 0.0510 0.0506 

[TRAIN] Epoch[1](4354/114412); Loss: 0.069341; Backpropagation: 0.2911 sec; Batch: 2.1425 sec
0.1202 0.1140 0.1042 0.0923 0.0739 0.0666 0.0632 0.0605 0.0575 0.0547 0.0534 0.0518 0.0505 0.0498 0.0488 0.0481 

[TRAIN] Epoch[1](4355/114412); Loss: 0.070960; Backpropagation: 0.2913 sec; Batch: 2.1157 sec
0.1209 0.1166 0.0828 0.0770 0.0710 0.0679 0.0653 0.0634 0.0621 0.0608 0.0598 0.0590 0.0580 0.0574 0.0568 0.0564 

[TRAIN] Epoch[1](4356/114412); Loss: 0.068003; Backpropagation: 0.2913 sec; Batch: 2.5063 sec
0.1380 0.1298 0.0897 0.0798 0.0661 0.0620 0.0579 0.0562 0.0543 0.0527 0.0518 0.0510 0.0503 0.0498 0.0495 0.0490 

[TRAIN] Epoch[1](4357/114412); Loss: 0.072081; Backpropagation: 0.2910 sec; Batch: 2.1677 sec
0.1317 0.1272 0.0950 0.0846 0.0713 0.0674 0.0644 0.0616 0.0602 0.0585 0.0570 0.0561 0.0553 0.0547 0.0543 0.0540 

[TRAIN] Epoch[1](4358/114412); Loss: 0.072321; Backpropagation: 0.2925 sec; Batch: 2.1835 sec
0.1689 0.1599 0.0884 0.0846 0.0664 0.0616 0.0580 0.0556 0.0545 0.0531 0.0524 0.0517 0.0510 0.0508 0.0503 0.0499 

[TRAIN] Epoch[1](4359/114412); Loss: 0.062093; Backpropagation: 0.2909 sec; Batch: 2.4933 sec
0.1400 0.1347 0.0831 0.0754 0.0576 0.0545 0.0516 0.0491 0.0475 0.0455 0.0439 0.0433 0.0426 0.0420 0.0414 0.0411 

[TRAIN] Epoch[1](4360/114412); Loss: 0.081948; Backpropagation: 0.2910 sec; Batch: 2.1778 sec
0.1554 0.1488 0.1020 0.0950 0.0818 0.0780 0.0741 0.0708 0.0684 0.0667 0.0644 0.0630 0.0619 0.0609 0.0602 0.0596 

[TRAIN] Epoch[1](4361/114412); Loss: 0.091027; Backpropagation: 0.2910 sec; Batch: 2.0836 sec
0.1567 0.1497 0.1045 0.0995 0.0906 0.0868 0.0828 0.0801 0.0788 0.0775 0.0766 0.0757 0.0750 0.0744 0.0740 0.0736 

[TRAIN] Epoch[1](4362/114412); Loss: 0.073255; Backpropagation: 0.2907 sec; Batch: 2.1199 sec
0.1519 0.1440 0.0940 0.0885 0.0754 0.0694 0.0641 0.0605 0.0580 0.0550 0.0536 0.0529 0.0521 0.0513 0.0508 0.0503 

[TRAIN] Epoch[1](4363/114412); Loss: 0.087498; Backpropagation: 0.2914 sec; Batch: 2.1458 sec
0.1568 0.1549 0.1078 0.1017 0.0853 0.0821 0.0799 0.0762 0.0734 0.0724 0.0712 0.0692 0.0684 0.0679 0.0667 0.0660 

[TRAIN] Epoch[1](4364/114412); Loss: 0.080139; Backpropagation: 0.2931 sec; Batch: 2.1231 sec
0.1550 0.1493 0.1058 0.0956 0.0832 0.0776 0.0721 0.0681 0.0648 0.0625 0.0606 0.0594 0.0580 0.0573 0.0567 0.0562 

[TRAIN] Epoch[1](4365/114412); Loss: 0.072495; Backpropagation: 0.2915 sec; Batch: 2.1230 sec
0.1239 0.1200 0.0965 0.0846 0.0748 0.0700 0.0666 0.0639 0.0619 0.0601 0.0587 0.0575 0.0564 0.0555 0.0549 0.0544 

[TRAIN] Epoch[1](4366/114412); Loss: 0.074895; Backpropagation: 0.2931 sec; Batch: 2.1187 sec
0.1456 0.1369 0.1024 0.0922 0.0851 0.0766 0.0687 0.0641 0.0588 0.0567 0.0552 0.0533 0.0516 0.0509 0.0505 0.0498 

[TRAIN] Epoch[1](4367/114412); Loss: 0.075989; Backpropagation: 0.2916 sec; Batch: 2.0794 sec
0.1361 0.1305 0.0918 0.0869 0.0783 0.0729 0.0678 0.0654 0.0636 0.0625 0.0615 0.0609 0.0602 0.0596 0.0591 0.0588 

[TRAIN] Epoch[1](4368/114412); Loss: 0.090305; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1677 0.1609 0.1137 0.1045 0.0892 0.0840 0.0794 0.0774 0.0754 0.0734 0.0722 0.0709 0.0702 0.0694 0.0686 0.0680 

[TRAIN] Epoch[1](4369/114412); Loss: 0.078142; Backpropagation: 0.2910 sec; Batch: 2.1224 sec
0.1579 0.1537 0.1125 0.0995 0.0819 0.0722 0.0670 0.0623 0.0602 0.0579 0.0563 0.0551 0.0544 0.0537 0.0530 0.0526 

[TRAIN] Epoch[1](4370/114412); Loss: 0.067786; Backpropagation: 0.2911 sec; Batch: 2.1207 sec
0.1376 0.1276 0.0908 0.0799 0.0681 0.0637 0.0597 0.0562 0.0541 0.0527 0.0511 0.0500 0.0492 0.0485 0.0480 0.0473 

[TRAIN] Epoch[1](4371/114412); Loss: 0.083117; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1797 0.1731 0.1099 0.1034 0.0788 0.0729 0.0698 0.0664 0.0640 0.0621 0.0605 0.0593 0.0584 0.0578 0.0571 0.0567 

[TRAIN] Epoch[1](4372/114412); Loss: 0.094188; Backpropagation: 0.2911 sec; Batch: 2.1215 sec
0.1889 0.1809 0.1223 0.1122 0.0905 0.0846 0.0792 0.0773 0.0763 0.0750 0.0728 0.0718 0.0703 0.0691 0.0684 0.0673 

[TRAIN] Epoch[1](4373/114412); Loss: 0.071463; Backpropagation: 0.2917 sec; Batch: 2.1174 sec
0.1366 0.1236 0.0870 0.0816 0.0724 0.0673 0.0641 0.0612 0.0594 0.0579 0.0569 0.0560 0.0554 0.0550 0.0547 0.0544 

[TRAIN] Epoch[1](4374/114412); Loss: 0.098490; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1828 0.1745 0.1190 0.1134 0.0961 0.0917 0.0879 0.0853 0.0826 0.0803 0.0789 0.0780 0.0773 0.0766 0.0759 0.0756 

[TRAIN] Epoch[1](4375/114412); Loss: 0.048032; Backpropagation: 0.2915 sec; Batch: 2.1290 sec
0.1315 0.1274 0.0649 0.0615 0.0416 0.0374 0.0352 0.0339 0.0322 0.0307 0.0300 0.0292 0.0287 0.0283 0.0280 0.0278 

[TRAIN] Epoch[1](4376/114412); Loss: 0.085076; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1600 0.1513 0.0984 0.0945 0.0856 0.0776 0.0748 0.0734 0.0722 0.0698 0.0687 0.0680 0.0673 0.0669 0.0666 0.0661 

[TRAIN] Epoch[1](4377/114412); Loss: 0.075945; Backpropagation: 0.2930 sec; Batch: 2.1349 sec
0.1501 0.1447 0.0965 0.0862 0.0725 0.0693 0.0646 0.0624 0.0610 0.0602 0.0593 0.0585 0.0579 0.0575 0.0573 0.0570 

[TRAIN] Epoch[1](4378/114412); Loss: 0.101768; Backpropagation: 0.2914 sec; Batch: 2.1164 sec
0.1774 0.1714 0.1311 0.1249 0.1083 0.0994 0.0932 0.0885 0.0847 0.0824 0.0803 0.0796 0.0788 0.0776 0.0758 0.0749 

[TRAIN] Epoch[1](4379/114412); Loss: 0.062219; Backpropagation: 0.2910 sec; Batch: 2.1208 sec
0.1273 0.1210 0.0782 0.0696 0.0632 0.0590 0.0545 0.0523 0.0505 0.0485 0.0472 0.0461 0.0453 0.0448 0.0442 0.0438 

[TRAIN] Epoch[1](4380/114412); Loss: 0.081516; Backpropagation: 0.2907 sec; Batch: 2.1167 sec
0.1443 0.1406 0.0960 0.0897 0.0801 0.0765 0.0731 0.0708 0.0694 0.0679 0.0671 0.0664 0.0659 0.0657 0.0655 0.0652 

[TRAIN] Epoch[1](4381/114412); Loss: 0.079315; Backpropagation: 0.2913 sec; Batch: 2.1192 sec
0.1437 0.1384 0.1096 0.0971 0.0848 0.0775 0.0729 0.0690 0.0657 0.0630 0.0610 0.0595 0.0580 0.0572 0.0562 0.0555 

[TRAIN] Epoch[1](4382/114412); Loss: 0.089886; Backpropagation: 0.2909 sec; Batch: 2.0777 sec
0.1559 0.1502 0.1160 0.1053 0.0969 0.0905 0.0843 0.0800 0.0771 0.0737 0.0712 0.0697 0.0682 0.0673 0.0664 0.0653 

[TRAIN] Epoch[1](4383/114412); Loss: 0.083398; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1415 0.1382 0.0973 0.0934 0.0850 0.0809 0.0758 0.0737 0.0716 0.0705 0.0694 0.0685 0.0678 0.0672 0.0668 0.0666 

[TRAIN] Epoch[1](4384/114412); Loss: 0.072805; Backpropagation: 0.2930 sec; Batch: 2.1228 sec
0.1241 0.1204 0.0937 0.0843 0.0757 0.0711 0.0664 0.0634 0.0615 0.0600 0.0591 0.0583 0.0575 0.0568 0.0564 0.0560 

[TRAIN] Epoch[1](4385/114412); Loss: 0.097053; Backpropagation: 0.2969 sec; Batch: 2.1102 sec
0.1796 0.1717 0.1191 0.1136 0.1003 0.0948 0.0879 0.0839 0.0807 0.0788 0.0770 0.0754 0.0738 0.0729 0.0721 0.0714 

[TRAIN] Epoch[1](4386/114412); Loss: 0.075243; Backpropagation: 0.2980 sec; Batch: 2.1038 sec
0.1606 0.1547 0.0866 0.0829 0.0765 0.0697 0.0636 0.0609 0.0593 0.0579 0.0569 0.0559 0.0555 0.0548 0.0542 0.0538 

[TRAIN] Epoch[1](4387/114412); Loss: 0.093341; Backpropagation: 0.2960 sec; Batch: 2.0910 sec
0.1725 0.1658 0.1235 0.1125 0.1019 0.0969 0.0889 0.0829 0.0783 0.0737 0.0705 0.0680 0.0663 0.0648 0.0638 0.0632 

[TRAIN] Epoch[1](4388/114412); Loss: 0.085324; Backpropagation: 0.2960 sec; Batch: 2.1414 sec
0.1499 0.1444 0.1056 0.0969 0.0868 0.0832 0.0783 0.0749 0.0727 0.0708 0.0694 0.0684 0.0672 0.0662 0.0656 0.0650 

[TRAIN] Epoch[1](4389/114412); Loss: 0.073600; Backpropagation: 0.2988 sec; Batch: 2.0935 sec
0.1593 0.1536 0.1052 0.0907 0.0765 0.0676 0.0643 0.0605 0.0553 0.0532 0.0516 0.0497 0.0487 0.0480 0.0471 0.0464 

[TRAIN] Epoch[1](4390/114412); Loss: 0.084380; Backpropagation: 0.2953 sec; Batch: 2.1449 sec
0.1405 0.1357 0.1031 0.0980 0.0873 0.0820 0.0773 0.0743 0.0727 0.0713 0.0702 0.0690 0.0680 0.0674 0.0668 0.0664 

[TRAIN] Epoch[1](4391/114412); Loss: 0.062518; Backpropagation: 0.2957 sec; Batch: 2.1210 sec
0.1262 0.1238 0.1068 0.0915 0.0770 0.0600 0.0528 0.0488 0.0450 0.0431 0.0403 0.0387 0.0379 0.0367 0.0358 0.0358 

[TRAIN] Epoch[1](4392/114412); Loss: 0.068162; Backpropagation: 0.2951 sec; Batch: 2.1183 sec
0.1447 0.1382 0.0903 0.0814 0.0687 0.0637 0.0585 0.0555 0.0528 0.0508 0.0495 0.0484 0.0477 0.0472 0.0467 0.0464 

[TRAIN] Epoch[1](4393/114412); Loss: 0.079414; Backpropagation: 0.2960 sec; Batch: 2.1339 sec
0.1724 0.1694 0.1095 0.1034 0.0839 0.0753 0.0637 0.0598 0.0589 0.0563 0.0550 0.0541 0.0531 0.0526 0.0521 0.0510 

[TRAIN] Epoch[1](4394/114412); Loss: 0.073125; Backpropagation: 0.2954 sec; Batch: 2.1211 sec
0.1209 0.1169 0.0876 0.0822 0.0735 0.0706 0.0677 0.0650 0.0635 0.0620 0.0613 0.0606 0.0600 0.0597 0.0594 0.0591 

[TRAIN] Epoch[1](4395/114412); Loss: 0.086375; Backpropagation: 0.2953 sec; Batch: 2.1253 sec
0.1529 0.1485 0.1072 0.0999 0.0894 0.0848 0.0794 0.0755 0.0726 0.0705 0.0695 0.0680 0.0669 0.0663 0.0656 0.0649 

[TRAIN] Epoch[1](4396/114412); Loss: 0.081680; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.1702 0.1601 0.1189 0.1055 0.0889 0.0817 0.0735 0.0671 0.0639 0.0601 0.0565 0.0550 0.0530 0.0521 0.0505 0.0498 

[TRAIN] Epoch[1](4397/114412); Loss: 0.087618; Backpropagation: 0.2953 sec; Batch: 2.0870 sec
0.1540 0.1493 0.1040 0.0988 0.0871 0.0825 0.0793 0.0769 0.0746 0.0732 0.0723 0.0712 0.0705 0.0698 0.0693 0.0691 

[TRAIN] Epoch[1](4398/114412); Loss: 0.091115; Backpropagation: 0.2979 sec; Batch: 2.1028 sec
0.1699 0.1638 0.1176 0.1053 0.0897 0.0860 0.0794 0.0771 0.0753 0.0736 0.0721 0.0711 0.0701 0.0695 0.0689 0.0683 

[TRAIN] Epoch[1](4399/114412); Loss: 0.074402; Backpropagation: 0.2957 sec; Batch: 2.1310 sec
0.1561 0.1531 0.0918 0.0892 0.0729 0.0679 0.0643 0.0614 0.0584 0.0565 0.0549 0.0539 0.0534 0.0527 0.0522 0.0517 

[TRAIN] Epoch[1](4400/114412); Loss: 0.078246; Backpropagation: 0.2980 sec; Batch: 2.1247 sec
0.1572 0.1520 0.0987 0.0942 0.0827 0.0766 0.0674 0.0634 0.0613 0.0593 0.0585 0.0576 0.0568 0.0558 0.0554 0.0548 

[TRAIN] Epoch[1](4401/114412); Loss: 0.093458; Backpropagation: 0.2954 sec; Batch: 2.0822 sec
0.1671 0.1622 0.1151 0.1074 0.0932 0.0893 0.0845 0.0813 0.0793 0.0773 0.0758 0.0745 0.0734 0.0724 0.0717 0.0708 

[TRAIN] Epoch[1](4402/114412); Loss: 0.070285; Backpropagation: 0.2951 sec; Batch: 2.1183 sec
0.1202 0.1172 0.0878 0.0838 0.0744 0.0692 0.0646 0.0616 0.0593 0.0576 0.0567 0.0559 0.0549 0.0542 0.0537 0.0533 

[TRAIN] Epoch[1](4403/114412); Loss: 0.074435; Backpropagation: 0.2960 sec; Batch: 2.1253 sec
0.1517 0.1469 0.0925 0.0848 0.0736 0.0691 0.0641 0.0613 0.0596 0.0579 0.0568 0.0560 0.0551 0.0543 0.0539 0.0534 

[TRAIN] Epoch[1](4404/114412); Loss: 0.089490; Backpropagation: 0.2952 sec; Batch: 2.1251 sec
0.1654 0.1598 0.1087 0.1022 0.0900 0.0853 0.0803 0.0768 0.0744 0.0727 0.0715 0.0704 0.0696 0.0688 0.0682 0.0677 

[TRAIN] Epoch[1](4405/114412); Loss: 0.068125; Backpropagation: 0.2990 sec; Batch: 2.1211 sec
0.1307 0.1257 0.0864 0.0807 0.0690 0.0643 0.0607 0.0580 0.0560 0.0540 0.0528 0.0519 0.0509 0.0502 0.0495 0.0491 

[TRAIN] Epoch[1](4406/114412); Loss: 0.068835; Backpropagation: 0.2951 sec; Batch: 2.1261 sec
0.1406 0.1360 0.0930 0.0861 0.0675 0.0629 0.0595 0.0564 0.0539 0.0517 0.0505 0.0498 0.0492 0.0486 0.0480 0.0477 

[TRAIN] Epoch[1](4407/114412); Loss: 0.074224; Backpropagation: 0.2954 sec; Batch: 2.1348 sec
0.1677 0.1623 0.0921 0.0862 0.0693 0.0656 0.0601 0.0580 0.0565 0.0550 0.0541 0.0531 0.0526 0.0521 0.0516 0.0512 

[TRAIN] Epoch[1](4408/114412); Loss: 0.070064; Backpropagation: 0.2956 sec; Batch: 2.1211 sec
0.1262 0.1232 0.0947 0.0879 0.0744 0.0680 0.0631 0.0599 0.0576 0.0557 0.0543 0.0532 0.0519 0.0511 0.0503 0.0497 

[TRAIN] Epoch[1](4409/114412); Loss: 0.065612; Backpropagation: 0.2979 sec; Batch: 2.1189 sec
0.1270 0.1226 0.0819 0.0772 0.0661 0.0619 0.0575 0.0547 0.0532 0.0521 0.0510 0.0500 0.0494 0.0489 0.0482 0.0482 

[TRAIN] Epoch[1](4410/114412); Loss: 0.076377; Backpropagation: 0.2954 sec; Batch: 2.1207 sec
0.1501 0.1459 0.1017 0.0929 0.0797 0.0726 0.0674 0.0645 0.0614 0.0597 0.0576 0.0560 0.0545 0.0535 0.0526 0.0519 

[TRAIN] Epoch[1](4411/114412); Loss: 0.057920; Backpropagation: 0.2953 sec; Batch: 2.1246 sec
0.1269 0.1257 0.0762 0.0693 0.0586 0.0551 0.0510 0.0476 0.0448 0.0433 0.0412 0.0400 0.0379 0.0372 0.0364 0.0354 

[TRAIN] Epoch[1](4412/114412); Loss: 0.076795; Backpropagation: 0.2953 sec; Batch: 2.1174 sec
0.1522 0.1496 0.0970 0.0904 0.0746 0.0720 0.0660 0.0634 0.0614 0.0597 0.0588 0.0579 0.0572 0.0566 0.0562 0.0558 

[TRAIN] Epoch[1](4413/114412); Loss: 0.078389; Backpropagation: 0.2980 sec; Batch: 2.1250 sec
0.1631 0.1595 0.1192 0.1019 0.0887 0.0820 0.0730 0.0665 0.0610 0.0556 0.0527 0.0492 0.0469 0.0459 0.0449 0.0440 

[TRAIN] Epoch[1](4414/114412); Loss: 0.085439; Backpropagation: 0.2974 sec; Batch: 2.1252 sec
0.1386 0.1334 0.1036 0.0968 0.0883 0.0825 0.0784 0.0758 0.0741 0.0728 0.0718 0.0712 0.0707 0.0702 0.0698 0.0692 

[TRAIN] Epoch[1](4415/114412); Loss: 0.063545; Backpropagation: 0.2978 sec; Batch: 2.1257 sec
0.1416 0.1354 0.0832 0.0780 0.0600 0.0542 0.0507 0.0486 0.0477 0.0468 0.0461 0.0456 0.0452 0.0448 0.0446 0.0444 

[TRAIN] Epoch[1](4416/114412); Loss: 0.090477; Backpropagation: 0.2955 sec; Batch: 2.1184 sec
0.1439 0.1405 0.1157 0.1065 0.0982 0.0929 0.0873 0.0838 0.0805 0.0778 0.0749 0.0726 0.0703 0.0691 0.0672 0.0665 

[TRAIN] Epoch[1](4417/114412); Loss: 0.061867; Backpropagation: 0.2956 sec; Batch: 2.1215 sec
0.1256 0.1229 0.0749 0.0718 0.0614 0.0580 0.0534 0.0508 0.0496 0.0486 0.0474 0.0465 0.0457 0.0450 0.0444 0.0439 

[TRAIN] Epoch[1](4418/114412); Loss: 0.080349; Backpropagation: 0.2957 sec; Batch: 2.1025 sec
0.1434 0.1388 0.0987 0.0888 0.0799 0.0759 0.0723 0.0704 0.0689 0.0669 0.0655 0.0646 0.0637 0.0631 0.0625 0.0622 

[TRAIN] Epoch[1](4419/114412); Loss: 0.093549; Backpropagation: 0.2956 sec; Batch: 2.1262 sec
0.1609 0.1566 0.1187 0.1100 0.0991 0.0892 0.0842 0.0808 0.0781 0.0767 0.0757 0.0746 0.0738 0.0732 0.0728 0.0725 

[TRAIN] Epoch[1](4420/114412); Loss: 0.082302; Backpropagation: 0.2949 sec; Batch: 2.0811 sec
0.1461 0.1416 0.0977 0.0898 0.0830 0.0780 0.0736 0.0712 0.0698 0.0689 0.0679 0.0672 0.0664 0.0659 0.0653 0.0647 

[TRAIN] Epoch[1](4421/114412); Loss: 0.059844; Backpropagation: 0.2967 sec; Batch: 2.1231 sec
0.1284 0.1204 0.0808 0.0715 0.0621 0.0583 0.0540 0.0504 0.0458 0.0444 0.0424 0.0412 0.0405 0.0397 0.0390 0.0385 

[TRAIN] Epoch[1](4422/114412); Loss: 0.081175; Backpropagation: 0.2957 sec; Batch: 2.1223 sec
0.1466 0.1432 0.1036 0.0932 0.0834 0.0787 0.0737 0.0706 0.0683 0.0661 0.0647 0.0635 0.0621 0.0612 0.0604 0.0597 

[TRAIN] Epoch[1](4423/114412); Loss: 0.112427; Backpropagation: 0.2956 sec; Batch: 2.1221 sec
0.1748 0.1699 0.1340 0.1276 0.1169 0.1104 0.1048 0.1022 0.1002 0.0973 0.0964 0.0947 0.0935 0.0926 0.0920 0.0915 

[TRAIN] Epoch[1](4424/114412); Loss: 0.100875; Backpropagation: 0.2957 sec; Batch: 2.1214 sec
0.1784 0.1732 0.1256 0.1156 0.0994 0.0950 0.0900 0.0872 0.0850 0.0834 0.0822 0.0813 0.0804 0.0796 0.0792 0.0786 

[TRAIN] Epoch[1](4425/114412); Loss: 0.081075; Backpropagation: 0.2977 sec; Batch: 2.1234 sec
0.1338 0.1300 0.0940 0.0908 0.0817 0.0780 0.0751 0.0723 0.0708 0.0697 0.0688 0.0678 0.0669 0.0663 0.0658 0.0653 

[TRAIN] Epoch[1](4426/114412); Loss: 0.078883; Backpropagation: 0.2959 sec; Batch: 2.0836 sec
0.1498 0.1438 0.1000 0.0927 0.0789 0.0741 0.0698 0.0671 0.0650 0.0631 0.0618 0.0607 0.0599 0.0591 0.0586 0.0579 

[TRAIN] Epoch[1](4427/114412); Loss: 0.054664; Backpropagation: 0.2958 sec; Batch: 2.1036 sec
0.1097 0.1068 0.0791 0.0676 0.0582 0.0522 0.0488 0.0451 0.0427 0.0407 0.0391 0.0380 0.0375 0.0370 0.0362 0.0358 

[TRAIN] Epoch[1](4428/114412); Loss: 0.077653; Backpropagation: 0.2961 sec; Batch: 2.1222 sec
0.1503 0.1437 0.1027 0.0959 0.0839 0.0781 0.0691 0.0645 0.0622 0.0594 0.0579 0.0568 0.0558 0.0548 0.0539 0.0535 

[TRAIN] Epoch[1](4429/114412); Loss: 0.069139; Backpropagation: 0.2957 sec; Batch: 2.1028 sec
0.1299 0.1266 0.0916 0.0827 0.0711 0.0660 0.0608 0.0578 0.0559 0.0540 0.0534 0.0526 0.0517 0.0513 0.0506 0.0502 

[TRAIN] Epoch[1](4430/114412); Loss: 0.088658; Backpropagation: 0.2979 sec; Batch: 2.1247 sec
0.1721 0.1672 0.1143 0.1008 0.0849 0.0794 0.0772 0.0752 0.0731 0.0709 0.0694 0.0682 0.0674 0.0667 0.0661 0.0656 

[TRAIN] Epoch[1](4431/114412); Loss: 0.093057; Backpropagation: 0.3004 sec; Batch: 2.1242 sec
0.1669 0.1615 0.1263 0.1171 0.1009 0.0931 0.0861 0.0807 0.0762 0.0734 0.0712 0.0697 0.0680 0.0667 0.0657 0.0652 

[TRAIN] Epoch[1](4432/114412); Loss: 0.076762; Backpropagation: 0.2981 sec; Batch: 2.1266 sec
0.1737 0.1701 0.0874 0.0825 0.0686 0.0659 0.0659 0.0605 0.0589 0.0576 0.0569 0.0567 0.0561 0.0561 0.0558 0.0554 

[TRAIN] Epoch[1](4433/114412); Loss: 0.076443; Backpropagation: 0.2978 sec; Batch: 2.1214 sec
0.1734 0.1674 0.1038 0.0983 0.0794 0.0717 0.0615 0.0580 0.0553 0.0536 0.0523 0.0511 0.0502 0.0496 0.0491 0.0485 

[TRAIN] Epoch[1](4434/114412); Loss: 0.095169; Backpropagation: 0.2957 sec; Batch: 2.1223 sec
0.1860 0.1790 0.1087 0.1040 0.0950 0.0901 0.0823 0.0799 0.0785 0.0767 0.0754 0.0747 0.0739 0.0733 0.0728 0.0724 

[TRAIN] Epoch[1](4435/114412); Loss: 0.066722; Backpropagation: 0.2980 sec; Batch: 2.1243 sec
0.1307 0.1201 0.0843 0.0793 0.0691 0.0646 0.0593 0.0562 0.0541 0.0528 0.0518 0.0505 0.0496 0.0488 0.0483 0.0480 

[TRAIN] Epoch[1](4436/114412); Loss: 0.061968; Backpropagation: 0.2958 sec; Batch: 2.1201 sec
0.1329 0.1267 0.0754 0.0699 0.0610 0.0576 0.0536 0.0511 0.0492 0.0479 0.0467 0.0457 0.0445 0.0436 0.0431 0.0426 

[TRAIN] Epoch[1](4437/114412); Loss: 0.079289; Backpropagation: 0.2947 sec; Batch: 2.1240 sec
0.1402 0.1353 0.0940 0.0896 0.0827 0.0785 0.0729 0.0695 0.0674 0.0660 0.0644 0.0633 0.0623 0.0614 0.0608 0.0601 

[TRAIN] Epoch[1](4438/114412); Loss: 0.064396; Backpropagation: 0.2956 sec; Batch: 2.1223 sec
0.1587 0.1525 0.0912 0.0854 0.0684 0.0576 0.0521 0.0498 0.0460 0.0427 0.0405 0.0388 0.0378 0.0369 0.0363 0.0358 

[TRAIN] Epoch[1](4439/114412); Loss: 0.084723; Backpropagation: 0.2955 sec; Batch: 2.1257 sec
0.1390 0.1359 0.1034 0.0973 0.0884 0.0824 0.0788 0.0753 0.0737 0.0719 0.0705 0.0694 0.0683 0.0676 0.0671 0.0665 

[TRAIN] Epoch[1](4440/114412); Loss: 0.081789; Backpropagation: 0.2979 sec; Batch: 2.0847 sec
0.1438 0.1364 0.1009 0.0905 0.0840 0.0782 0.0743 0.0713 0.0691 0.0682 0.0670 0.0662 0.0655 0.0647 0.0644 0.0641 

[TRAIN] Epoch[1](4441/114412); Loss: 0.095190; Backpropagation: 0.2970 sec; Batch: 2.1143 sec
0.1637 0.1595 0.1184 0.1115 0.0962 0.0907 0.0860 0.0827 0.0808 0.0793 0.0780 0.0769 0.0759 0.0751 0.0745 0.0739 

[TRAIN] Epoch[1](4442/114412); Loss: 0.063741; Backpropagation: 0.2955 sec; Batch: 2.0811 sec
0.1549 0.1480 0.0955 0.0833 0.0676 0.0599 0.0508 0.0472 0.0434 0.0419 0.0403 0.0393 0.0380 0.0372 0.0366 0.0359 

[TRAIN] Epoch[1](4443/114412); Loss: 0.075168; Backpropagation: 0.2982 sec; Batch: 2.1220 sec
0.1434 0.1389 0.0957 0.0885 0.0764 0.0719 0.0675 0.0641 0.0616 0.0596 0.0582 0.0569 0.0561 0.0554 0.0546 0.0540 

[TRAIN] Epoch[1](4444/114412); Loss: 0.098356; Backpropagation: 0.2955 sec; Batch: 2.1213 sec
0.1609 0.1568 0.1216 0.1139 0.0991 0.0936 0.0886 0.0860 0.0844 0.0834 0.0827 0.0817 0.0810 0.0805 0.0800 0.0796 

[TRAIN] Epoch[1](4445/114412); Loss: 0.081001; Backpropagation: 0.2956 sec; Batch: 2.0857 sec
0.1652 0.1604 0.0992 0.0942 0.0794 0.0750 0.0720 0.0676 0.0651 0.0631 0.0616 0.0602 0.0593 0.0585 0.0579 0.0574 

[TRAIN] Epoch[1](4446/114412); Loss: 0.068312; Backpropagation: 0.2953 sec; Batch: 2.0857 sec
0.2074 0.2003 0.0981 0.0904 0.0534 0.0489 0.0465 0.0421 0.0416 0.0402 0.0389 0.0381 0.0374 0.0368 0.0365 0.0363 

[TRAIN] Epoch[1](4447/114412); Loss: 0.078929; Backpropagation: 0.2952 sec; Batch: 2.0815 sec
0.1656 0.1597 0.0959 0.0920 0.0743 0.0696 0.0666 0.0652 0.0627 0.0610 0.0602 0.0592 0.0584 0.0580 0.0574 0.0570 

[TRAIN] Epoch[1](4448/114412); Loss: 0.066348; Backpropagation: 0.2980 sec; Batch: 2.1305 sec
0.1586 0.1550 0.0916 0.0817 0.0611 0.0577 0.0529 0.0491 0.0477 0.0460 0.0450 0.0444 0.0434 0.0428 0.0424 0.0421 

[TRAIN] Epoch[1](4449/114412); Loss: 0.072624; Backpropagation: 0.2962 sec; Batch: 2.1204 sec
0.1296 0.1279 0.0981 0.0888 0.0795 0.0727 0.0657 0.0636 0.0606 0.0578 0.0556 0.0544 0.0529 0.0522 0.0516 0.0510 

[TRAIN] Epoch[1](4450/114412); Loss: 0.068673; Backpropagation: 0.2976 sec; Batch: 2.1265 sec
0.1264 0.1225 0.0867 0.0806 0.0700 0.0663 0.0610 0.0595 0.0570 0.0553 0.0542 0.0533 0.0526 0.0518 0.0511 0.0505 

[TRAIN] Epoch[1](4451/114412); Loss: 0.062121; Backpropagation: 0.2953 sec; Batch: 2.1230 sec
0.1287 0.1258 0.0854 0.0771 0.0637 0.0577 0.0533 0.0492 0.0471 0.0458 0.0447 0.0443 0.0434 0.0429 0.0427 0.0423 

[TRAIN] Epoch[1](4452/114412); Loss: 0.074092; Backpropagation: 0.2954 sec; Batch: 2.1226 sec
0.1565 0.1478 0.0990 0.0906 0.0747 0.0696 0.0619 0.0595 0.0570 0.0556 0.0543 0.0532 0.0523 0.0517 0.0510 0.0507 

[TRAIN] Epoch[1](4453/114412); Loss: 0.083900; Backpropagation: 0.2977 sec; Batch: 2.1197 sec
0.1383 0.1334 0.1062 0.0982 0.0880 0.0826 0.0771 0.0745 0.0719 0.0704 0.0688 0.0679 0.0672 0.0664 0.0659 0.0656 

[TRAIN] Epoch[1](4454/114412); Loss: 0.053934; Backpropagation: 0.2957 sec; Batch: 2.1237 sec
0.1297 0.1250 0.0741 0.0593 0.0498 0.0469 0.0430 0.0407 0.0400 0.0385 0.0378 0.0368 0.0360 0.0355 0.0351 0.0348 

[TRAIN] Epoch[1](4455/114412); Loss: 0.061850; Backpropagation: 0.2947 sec; Batch: 2.1191 sec
0.1333 0.1271 0.0820 0.0718 0.0590 0.0568 0.0535 0.0502 0.0485 0.0463 0.0454 0.0444 0.0435 0.0431 0.0426 0.0422 

[TRAIN] Epoch[1](4456/114412); Loss: 0.061165; Backpropagation: 0.2950 sec; Batch: 2.1188 sec
0.1400 0.1373 0.0832 0.0722 0.0580 0.0530 0.0497 0.0476 0.0464 0.0445 0.0430 0.0422 0.0413 0.0406 0.0401 0.0395 

[TRAIN] Epoch[1](4457/114412); Loss: 0.081620; Backpropagation: 0.2958 sec; Batch: 2.1221 sec
0.1747 0.1717 0.1060 0.0992 0.0791 0.0735 0.0685 0.0660 0.0634 0.0613 0.0598 0.0584 0.0570 0.0564 0.0559 0.0550 

[TRAIN] Epoch[1](4458/114412); Loss: 0.086726; Backpropagation: 0.2954 sec; Batch: 2.1256 sec
0.1463 0.1421 0.1076 0.1030 0.0905 0.0846 0.0799 0.0766 0.0737 0.0721 0.0709 0.0695 0.0687 0.0679 0.0674 0.0668 

[TRAIN] Epoch[1](4459/114412); Loss: 0.066581; Backpropagation: 0.2984 sec; Batch: 2.1405 sec
0.1339 0.1290 0.0919 0.0839 0.0672 0.0611 0.0576 0.0537 0.0518 0.0500 0.0489 0.0481 0.0475 0.0472 0.0469 0.0466 

[TRAIN] Epoch[1](4460/114412); Loss: 0.075897; Backpropagation: 0.2957 sec; Batch: 2.1303 sec
0.1433 0.1393 0.1013 0.0922 0.0817 0.0724 0.0682 0.0645 0.0618 0.0597 0.0575 0.0561 0.0552 0.0545 0.0537 0.0528 

[TRAIN] Epoch[1](4461/114412); Loss: 0.070172; Backpropagation: 0.2954 sec; Batch: 2.1212 sec
0.1424 0.1330 0.0901 0.0823 0.0694 0.0647 0.0626 0.0585 0.0564 0.0546 0.0535 0.0524 0.0515 0.0508 0.0505 0.0500 

[TRAIN] Epoch[1](4462/114412); Loss: 0.091616; Backpropagation: 0.2955 sec; Batch: 2.1218 sec
0.1710 0.1671 0.1225 0.1163 0.0973 0.0888 0.0820 0.0767 0.0738 0.0714 0.0697 0.0679 0.0667 0.0656 0.0649 0.0641 

[TRAIN] Epoch[1](4463/114412); Loss: 0.060428; Backpropagation: 0.2982 sec; Batch: 2.1241 sec
0.1218 0.1173 0.0839 0.0732 0.0622 0.0552 0.0529 0.0497 0.0471 0.0456 0.0446 0.0438 0.0430 0.0425 0.0422 0.0419 

[TRAIN] Epoch[1](4464/114412); Loss: 0.064060; Backpropagation: 0.2957 sec; Batch: 2.0920 sec
0.1417 0.1358 0.0940 0.0817 0.0661 0.0574 0.0510 0.0480 0.0474 0.0453 0.0447 0.0438 0.0430 0.0422 0.0416 0.0413 

[TRAIN] Epoch[1](4465/114412); Loss: 0.074451; Backpropagation: 0.2953 sec; Batch: 2.0827 sec
0.1526 0.1485 0.0973 0.0867 0.0762 0.0712 0.0655 0.0632 0.0591 0.0567 0.0546 0.0534 0.0528 0.0519 0.0511 0.0504 

[TRAIN] Epoch[1](4466/114412); Loss: 0.090971; Backpropagation: 0.2953 sec; Batch: 2.1189 sec
0.1595 0.1555 0.1143 0.1090 0.0945 0.0903 0.0826 0.0791 0.0762 0.0740 0.0728 0.0714 0.0702 0.0696 0.0685 0.0679 

[TRAIN] Epoch[1](4467/114412); Loss: 0.089444; Backpropagation: 0.2953 sec; Batch: 2.0835 sec
0.1542 0.1505 0.1111 0.1058 0.0932 0.0874 0.0829 0.0794 0.0760 0.0742 0.0722 0.0709 0.0695 0.0689 0.0679 0.0670 

[TRAIN] Epoch[1](4468/114412); Loss: 0.070540; Backpropagation: 0.2954 sec; Batch: 2.1207 sec
0.1231 0.1191 0.1005 0.0824 0.0768 0.0695 0.0672 0.0605 0.0589 0.0565 0.0546 0.0539 0.0527 0.0519 0.0510 0.0502 

[TRAIN] Epoch[1](4469/114412); Loss: 0.079898; Backpropagation: 0.2955 sec; Batch: 2.1204 sec
0.1590 0.1530 0.0965 0.0902 0.0805 0.0745 0.0713 0.0680 0.0659 0.0633 0.0614 0.0604 0.0597 0.0590 0.0583 0.0575 

[TRAIN] Epoch[1](4470/114412); Loss: 0.100475; Backpropagation: 0.2952 sec; Batch: 2.1371 sec
0.1771 0.1722 0.1190 0.1140 0.1003 0.0950 0.0911 0.0875 0.0855 0.0834 0.0826 0.0816 0.0807 0.0799 0.0792 0.0786 

[TRAIN] Epoch[1](4471/114412); Loss: 0.069116; Backpropagation: 0.2959 sec; Batch: 2.1059 sec
0.1339 0.1271 0.0867 0.0783 0.0719 0.0649 0.0622 0.0582 0.0565 0.0548 0.0539 0.0530 0.0521 0.0514 0.0508 0.0504 

[TRAIN] Epoch[1](4472/114412); Loss: 0.064740; Backpropagation: 0.2958 sec; Batch: 2.1212 sec
0.1205 0.1166 0.0881 0.0803 0.0680 0.0622 0.0585 0.0547 0.0528 0.0507 0.0494 0.0483 0.0473 0.0467 0.0461 0.0457 

[TRAIN] Epoch[1](4473/114412); Loss: 0.100190; Backpropagation: 0.2954 sec; Batch: 2.1260 sec
0.1511 0.1470 0.1241 0.1150 0.1051 0.0997 0.0961 0.0921 0.0892 0.0869 0.0848 0.0838 0.0830 0.0825 0.0816 0.0809 

[TRAIN] Epoch[1](4474/114412); Loss: 0.089202; Backpropagation: 0.2949 sec; Batch: 2.1202 sec
0.1759 0.1689 0.1231 0.1161 0.0989 0.0876 0.0779 0.0713 0.0686 0.0666 0.0651 0.0633 0.0622 0.0614 0.0603 0.0599 

[TRAIN] Epoch[1](4475/114412); Loss: 0.074327; Backpropagation: 0.2953 sec; Batch: 2.1185 sec
0.1618 0.1555 0.0963 0.0881 0.0703 0.0664 0.0617 0.0593 0.0578 0.0569 0.0550 0.0535 0.0523 0.0519 0.0514 0.0509 

[TRAIN] Epoch[1](4476/114412); Loss: 0.101329; Backpropagation: 0.2956 sec; Batch: 2.1017 sec
0.1956 0.1834 0.1334 0.1206 0.1091 0.0979 0.0930 0.0832 0.0809 0.0784 0.0770 0.0757 0.0746 0.0734 0.0729 0.0722 

[TRAIN] Epoch[1](4477/114412); Loss: 0.090283; Backpropagation: 0.2956 sec; Batch: 2.0828 sec
0.1618 0.1547 0.1029 0.0999 0.0896 0.0855 0.0825 0.0804 0.0784 0.0765 0.0747 0.0735 0.0721 0.0713 0.0708 0.0699 

[TRAIN] Epoch[1](4478/114412); Loss: 0.081474; Backpropagation: 0.2956 sec; Batch: 2.1205 sec
0.1613 0.1548 0.1037 0.0943 0.0885 0.0780 0.0745 0.0704 0.0668 0.0632 0.0616 0.0598 0.0579 0.0570 0.0562 0.0554 

[TRAIN] Epoch[1](4479/114412); Loss: 0.071614; Backpropagation: 0.2960 sec; Batch: 2.1205 sec
0.1236 0.1181 0.0884 0.0823 0.0736 0.0676 0.0656 0.0624 0.0613 0.0601 0.0588 0.0579 0.0572 0.0566 0.0563 0.0561 

[TRAIN] Epoch[1](4480/114412); Loss: 0.079001; Backpropagation: 0.2956 sec; Batch: 2.0814 sec
0.1503 0.1468 0.1099 0.1054 0.0931 0.0817 0.0724 0.0659 0.0616 0.0587 0.0568 0.0549 0.0530 0.0520 0.0513 0.0505 

[TRAIN] Epoch[1](4481/114412); Loss: 0.098704; Backpropagation: 0.2953 sec; Batch: 2.1373 sec
0.1735 0.1631 0.1147 0.1084 0.1002 0.0941 0.0920 0.0881 0.0859 0.0840 0.0821 0.0809 0.0795 0.0783 0.0776 0.0769 

[TRAIN] Epoch[1](4482/114412); Loss: 0.073717; Backpropagation: 0.2954 sec; Batch: 2.1218 sec
0.1471 0.1394 0.0998 0.0897 0.0799 0.0728 0.0671 0.0610 0.0583 0.0556 0.0535 0.0526 0.0519 0.0508 0.0503 0.0497 

[TRAIN] Epoch[1](4483/114412); Loss: 0.074065; Backpropagation: 0.2954 sec; Batch: 2.1018 sec
0.1497 0.1308 0.0930 0.0833 0.0737 0.0670 0.0649 0.0621 0.0611 0.0596 0.0583 0.0576 0.0568 0.0562 0.0558 0.0552 

[TRAIN] Epoch[1](4484/114412); Loss: 0.057857; Backpropagation: 0.3007 sec; Batch: 2.1270 sec
0.1113 0.1075 0.0841 0.0760 0.0624 0.0551 0.0530 0.0492 0.0471 0.0444 0.0421 0.0410 0.0395 0.0381 0.0377 0.0371 

[TRAIN] Epoch[1](4485/114412); Loss: 0.066382; Backpropagation: 0.3004 sec; Batch: 2.1248 sec
0.1351 0.1317 0.1050 0.0895 0.0782 0.0653 0.0605 0.0523 0.0498 0.0454 0.0440 0.0425 0.0420 0.0409 0.0403 0.0397 

[TRAIN] Epoch[1](4486/114412); Loss: 0.101798; Backpropagation: 0.2979 sec; Batch: 2.1249 sec
0.1386 0.1355 0.1301 0.1239 0.1030 0.0992 0.0956 0.0937 0.0923 0.0907 0.0898 0.0888 0.0879 0.0872 0.0866 0.0859 

[TRAIN] Epoch[1](4487/114412); Loss: 0.082540; Backpropagation: 0.2980 sec; Batch: 2.0877 sec
0.1808 0.1716 0.1062 0.1022 0.0863 0.0814 0.0747 0.0683 0.0642 0.0605 0.0584 0.0561 0.0554 0.0526 0.0517 0.0501 

[TRAIN] Epoch[1](4488/114412); Loss: 0.078959; Backpropagation: 0.2958 sec; Batch: 2.0829 sec
0.1447 0.1382 0.0995 0.0931 0.0821 0.0757 0.0719 0.0684 0.0658 0.0636 0.0626 0.0611 0.0603 0.0594 0.0587 0.0582 

[TRAIN] Epoch[1](4489/114412); Loss: 0.095265; Backpropagation: 0.2969 sec; Batch: 2.1228 sec
0.1787 0.1710 0.1197 0.1149 0.1014 0.0933 0.0868 0.0817 0.0785 0.0760 0.0738 0.0723 0.0705 0.0695 0.0684 0.0676 

[TRAIN] Epoch[1](4490/114412); Loss: 0.076371; Backpropagation: 0.2973 sec; Batch: 2.1339 sec
0.1342 0.1266 0.0911 0.0963 0.0856 0.0803 0.0721 0.0682 0.0638 0.0617 0.0595 0.0585 0.0577 0.0560 0.0555 0.0550 

[TRAIN] Epoch[1](4491/114412); Loss: 0.093944; Backpropagation: 0.2953 sec; Batch: 2.1310 sec
0.1708 0.1634 0.1219 0.1160 0.0997 0.0924 0.0875 0.0828 0.0791 0.0763 0.0734 0.0713 0.0690 0.0677 0.0664 0.0653 

[TRAIN] Epoch[1](4492/114412); Loss: 0.102437; Backpropagation: 0.2952 sec; Batch: 2.1113 sec
0.2006 0.1858 0.1408 0.1290 0.1065 0.0974 0.0925 0.0869 0.0822 0.0790 0.0769 0.0747 0.0730 0.0720 0.0714 0.0703 

[TRAIN] Epoch[1](4493/114412); Loss: 0.094991; Backpropagation: 0.2952 sec; Batch: 2.1456 sec
0.1530 0.1466 0.1187 0.1117 0.1047 0.0969 0.0916 0.0866 0.0837 0.0805 0.0784 0.0760 0.0748 0.0733 0.0723 0.0712 

[TRAIN] Epoch[1](4494/114412); Loss: 0.074005; Backpropagation: 0.2956 sec; Batch: 2.1447 sec
0.1472 0.1397 0.0888 0.0852 0.0747 0.0701 0.0661 0.0631 0.0606 0.0587 0.0574 0.0562 0.0552 0.0542 0.0538 0.0531 

[TRAIN] Epoch[1](4495/114412); Loss: 0.070151; Backpropagation: 0.2956 sec; Batch: 2.1470 sec
0.1381 0.1308 0.0838 0.0758 0.0702 0.0661 0.0629 0.0602 0.0583 0.0565 0.0555 0.0543 0.0533 0.0528 0.0521 0.0515 

[TRAIN] Epoch[1](4496/114412); Loss: 0.059180; Backpropagation: 0.2958 sec; Batch: 2.1118 sec
0.1385 0.1281 0.0762 0.0680 0.0606 0.0537 0.0511 0.0473 0.0451 0.0429 0.0419 0.0400 0.0394 0.0385 0.0381 0.0374 

[TRAIN] Epoch[1](4497/114412); Loss: 0.110619; Backpropagation: 0.3008 sec; Batch: 2.1550 sec
0.1891 0.1826 0.1305 0.1272 0.1168 0.1094 0.1045 0.1005 0.0963 0.0936 0.0912 0.0891 0.0870 0.0853 0.0839 0.0828 

[TRAIN] Epoch[1](4498/114412); Loss: 0.078990; Backpropagation: 0.2962 sec; Batch: 2.4062 sec
0.1454 0.1380 0.0964 0.0905 0.0834 0.0779 0.0753 0.0712 0.0671 0.0649 0.0626 0.0605 0.0594 0.0580 0.0570 0.0562 

[TRAIN] Epoch[1](4499/114412); Loss: 0.089126; Backpropagation: 0.2955 sec; Batch: 2.1446 sec
0.1630 0.1615 0.1073 0.1046 0.0902 0.0859 0.0804 0.0768 0.0744 0.0724 0.0708 0.0694 0.0685 0.0676 0.0667 0.0663 

[TRAIN] Epoch[1](4500/114412); Loss: 0.079501; Backpropagation: 0.3010 sec; Batch: 2.0881 sec
0.1737 0.1679 0.1073 0.1000 0.0805 0.0706 0.0676 0.0630 0.0604 0.0583 0.0566 0.0550 0.0538 0.0531 0.0524 0.0518 

[TRAIN] Epoch[1](4501/114412); Loss: 0.079522; Backpropagation: 0.2983 sec; Batch: 2.1280 sec
0.1491 0.1465 0.1082 0.1001 0.0848 0.0797 0.0750 0.0692 0.0650 0.0627 0.0600 0.0577 0.0560 0.0544 0.0530 0.0511 

[TRAIN] Epoch[1](4502/114412); Loss: 0.074497; Backpropagation: 0.2934 sec; Batch: 2.0796 sec
0.1716 0.1663 0.0912 0.0864 0.0740 0.0705 0.0641 0.0609 0.0572 0.0548 0.0523 0.0508 0.0494 0.0485 0.0474 0.0465 

[TRAIN] Epoch[1](4503/114412); Loss: 0.088921; Backpropagation: 0.2929 sec; Batch: 2.1181 sec
0.1532 0.1488 0.1124 0.1084 0.0955 0.0897 0.0828 0.0783 0.0747 0.0721 0.0705 0.0691 0.0678 0.0671 0.0663 0.0659 

[TRAIN] Epoch[1](4504/114412); Loss: 0.064651; Backpropagation: 0.2910 sec; Batch: 2.1053 sec
0.1233 0.1158 0.0770 0.0742 0.0649 0.0616 0.0576 0.0555 0.0534 0.0521 0.0513 0.0504 0.0499 0.0495 0.0490 0.0489 

[TRAIN] Epoch[1](4505/114412); Loss: 0.086243; Backpropagation: 0.2915 sec; Batch: 2.1453 sec
0.1831 0.1785 0.1108 0.0988 0.0841 0.0759 0.0738 0.0705 0.0685 0.0659 0.0646 0.0629 0.0617 0.0609 0.0603 0.0599 

[TRAIN] Epoch[1](4506/114412); Loss: 0.069298; Backpropagation: 0.2913 sec; Batch: 2.1108 sec
0.1408 0.1352 0.0907 0.0843 0.0703 0.0651 0.0612 0.0574 0.0552 0.0531 0.0515 0.0501 0.0495 0.0484 0.0482 0.0477 

[TRAIN] Epoch[1](4507/114412); Loss: 0.090684; Backpropagation: 0.2929 sec; Batch: 2.1774 sec
0.1451 0.1395 0.1129 0.1080 0.0977 0.0924 0.0887 0.0844 0.0797 0.0769 0.0754 0.0723 0.0710 0.0694 0.0695 0.0680 

[TRAIN] Epoch[1](4508/114412); Loss: 0.063506; Backpropagation: 0.2929 sec; Batch: 2.1193 sec
0.1447 0.1401 0.0813 0.0749 0.0638 0.0587 0.0551 0.0514 0.0488 0.0461 0.0448 0.0429 0.0421 0.0411 0.0406 0.0397 

[TRAIN] Epoch[1](4509/114412); Loss: 0.062081; Backpropagation: 0.2926 sec; Batch: 2.1174 sec
0.1276 0.1225 0.0697 0.0712 0.0609 0.0575 0.0543 0.0518 0.0506 0.0489 0.0478 0.0474 0.0465 0.0459 0.0454 0.0452 

[TRAIN] Epoch[1](4510/114412); Loss: 0.073329; Backpropagation: 0.2910 sec; Batch: 2.0974 sec
0.1288 0.1230 0.0869 0.0828 0.0761 0.0714 0.0686 0.0657 0.0633 0.0614 0.0599 0.0585 0.0578 0.0571 0.0562 0.0558 

[TRAIN] Epoch[1](4511/114412); Loss: 0.073486; Backpropagation: 0.2912 sec; Batch: 2.1141 sec
0.1401 0.1363 0.0906 0.0879 0.0798 0.0721 0.0682 0.0629 0.0606 0.0574 0.0558 0.0545 0.0535 0.0525 0.0519 0.0514 

[TRAIN] Epoch[1](4512/114412); Loss: 0.098805; Backpropagation: 0.2953 sec; Batch: 2.1365 sec
0.1792 0.1732 0.1253 0.1192 0.1033 0.0959 0.0895 0.0854 0.0821 0.0798 0.0780 0.0761 0.0750 0.0738 0.0730 0.0721 

[TRAIN] Epoch[1](4513/114412); Loss: 0.095194; Backpropagation: 0.2927 sec; Batch: 2.1148 sec
0.1659 0.1557 0.1212 0.1137 0.0972 0.0914 0.0870 0.0837 0.0811 0.0792 0.0774 0.0761 0.0748 0.0737 0.0728 0.0721 

[TRAIN] Epoch[1](4514/114412); Loss: 0.094437; Backpropagation: 0.2933 sec; Batch: 2.1187 sec
0.1747 0.1697 0.1243 0.1126 0.0990 0.0903 0.0850 0.0817 0.0780 0.0753 0.0731 0.0714 0.0701 0.0695 0.0685 0.0678 

[TRAIN] Epoch[1](4515/114412); Loss: 0.098921; Backpropagation: 0.2937 sec; Batch: 2.1224 sec
0.1740 0.1622 0.1271 0.1184 0.1012 0.0952 0.0899 0.0866 0.0840 0.0818 0.0798 0.0785 0.0773 0.0762 0.0756 0.0748 

[TRAIN] Epoch[1](4516/114412); Loss: 0.088403; Backpropagation: 0.2952 sec; Batch: 2.1229 sec
0.1684 0.1583 0.1189 0.1110 0.0951 0.0861 0.0807 0.0755 0.0713 0.0692 0.0669 0.0648 0.0637 0.0623 0.0614 0.0608 

[TRAIN] Epoch[1](4517/114412); Loss: 0.078359; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.1477 0.1425 0.1036 0.0941 0.0850 0.0760 0.0715 0.0679 0.0643 0.0620 0.0595 0.0582 0.0569 0.0557 0.0548 0.0541 

[TRAIN] Epoch[1](4518/114412); Loss: 0.091152; Backpropagation: 0.2913 sec; Batch: 2.1163 sec
0.1550 0.1484 0.1165 0.1092 0.1002 0.0906 0.0858 0.0797 0.0773 0.0747 0.0728 0.0714 0.0705 0.0694 0.0688 0.0682 

[TRAIN] Epoch[1](4519/114412); Loss: 0.078719; Backpropagation: 0.2911 sec; Batch: 2.1227 sec
0.1627 0.1552 0.1014 0.0951 0.0806 0.0744 0.0697 0.0657 0.0630 0.0604 0.0584 0.0570 0.0555 0.0543 0.0534 0.0527 

[TRAIN] Epoch[1](4520/114412); Loss: 0.070393; Backpropagation: 0.2917 sec; Batch: 2.1149 sec
0.1467 0.1368 0.0912 0.0842 0.0721 0.0654 0.0602 0.0564 0.0548 0.0534 0.0522 0.0515 0.0510 0.0505 0.0502 0.0497 

[TRAIN] Epoch[1](4521/114412); Loss: 0.082439; Backpropagation: 0.2912 sec; Batch: 2.1250 sec
0.1634 0.1566 0.0994 0.0957 0.0804 0.0761 0.0732 0.0705 0.0676 0.0661 0.0644 0.0632 0.0622 0.0607 0.0601 0.0593 

[TRAIN] Epoch[1](4522/114412); Loss: 0.065618; Backpropagation: 0.2912 sec; Batch: 2.1135 sec
0.1264 0.1234 0.0864 0.0792 0.0696 0.0635 0.0594 0.0553 0.0527 0.0508 0.0494 0.0483 0.0474 0.0466 0.0460 0.0457 

[TRAIN] Epoch[1](4523/114412); Loss: 0.086238; Backpropagation: 0.2912 sec; Batch: 2.1341 sec
0.1544 0.1510 0.1087 0.1031 0.0965 0.0894 0.0798 0.0755 0.0705 0.0690 0.0662 0.0645 0.0640 0.0631 0.0623 0.0618 

[TRAIN] Epoch[1](4524/114412); Loss: 0.092930; Backpropagation: 0.2930 sec; Batch: 2.1194 sec
0.1537 0.1553 0.1273 0.1199 0.1077 0.0931 0.0856 0.0795 0.0753 0.0728 0.0715 0.0704 0.0697 0.0689 0.0683 0.0679 

[TRAIN] Epoch[1](4525/114412); Loss: 0.090381; Backpropagation: 0.2930 sec; Batch: 2.1165 sec
0.1681 0.1613 0.1272 0.1174 0.1032 0.0934 0.0880 0.0793 0.0738 0.0686 0.0653 0.0630 0.0615 0.0600 0.0586 0.0575 

[TRAIN] Epoch[1](4526/114412); Loss: 0.093517; Backpropagation: 0.2927 sec; Batch: 2.1187 sec
0.2196 0.2138 0.1104 0.1051 0.0891 0.0822 0.0779 0.0738 0.0716 0.0685 0.0667 0.0655 0.0640 0.0631 0.0626 0.0623 

[TRAIN] Epoch[1](4527/114412); Loss: 0.074598; Backpropagation: 0.2918 sec; Batch: 2.1205 sec
0.1676 0.1640 0.0850 0.0825 0.0752 0.0685 0.0638 0.0601 0.0576 0.0556 0.0543 0.0531 0.0524 0.0516 0.0512 0.0510 

[TRAIN] Epoch[1](4528/114412); Loss: 0.107077; Backpropagation: 0.2913 sec; Batch: 2.0898 sec
0.1979 0.1930 0.1387 0.1284 0.1161 0.1074 0.1012 0.0964 0.0897 0.0860 0.0839 0.0787 0.0762 0.0748 0.0732 0.0718 

[TRAIN] Epoch[1](4529/114412); Loss: 0.080310; Backpropagation: 0.2917 sec; Batch: 2.1167 sec
0.1462 0.1428 0.1024 0.0954 0.0845 0.0760 0.0719 0.0687 0.0666 0.0648 0.0634 0.0622 0.0610 0.0603 0.0595 0.0591 

[TRAIN] Epoch[1](4530/114412); Loss: 0.089555; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1689 0.1612 0.1209 0.1044 0.0941 0.0842 0.0806 0.0759 0.0728 0.0704 0.0698 0.0679 0.0668 0.0660 0.0650 0.0640 

[TRAIN] Epoch[1](4531/114412); Loss: 0.072823; Backpropagation: 0.2916 sec; Batch: 2.1133 sec
0.1358 0.1311 0.1125 0.1030 0.0897 0.0803 0.0701 0.0644 0.0553 0.0533 0.0481 0.0466 0.0447 0.0441 0.0432 0.0430 

[TRAIN] Epoch[1](4532/114412); Loss: 0.093108; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1977 0.1969 0.1214 0.1125 0.0949 0.0860 0.0811 0.0747 0.0721 0.0695 0.0672 0.0658 0.0642 0.0630 0.0619 0.0611 

[TRAIN] Epoch[1](4533/114412); Loss: 0.068080; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.1777 0.1694 0.0861 0.0770 0.0639 0.0579 0.0538 0.0498 0.0480 0.0461 0.0450 0.0440 0.0432 0.0428 0.0425 0.0422 

[TRAIN] Epoch[1](4534/114412); Loss: 0.112638; Backpropagation: 0.2930 sec; Batch: 2.1184 sec
0.2011 0.1943 0.1407 0.1315 0.1145 0.1068 0.1012 0.0974 0.0938 0.0916 0.0905 0.0892 0.0883 0.0876 0.0870 0.0867 

[TRAIN] Epoch[1](4535/114412); Loss: 0.058894; Backpropagation: 0.2913 sec; Batch: 2.1233 sec
0.1245 0.1200 0.0787 0.0721 0.0592 0.0526 0.0502 0.0479 0.0458 0.0443 0.0430 0.0418 0.0414 0.0407 0.0402 0.0399 

[TRAIN] Epoch[1](4536/114412); Loss: 0.089326; Backpropagation: 0.2915 sec; Batch: 2.1109 sec
0.1781 0.1798 0.1151 0.1028 0.0884 0.0820 0.0785 0.0745 0.0725 0.0694 0.0674 0.0662 0.0650 0.0639 0.0632 0.0625 

[TRAIN] Epoch[1](4537/114412); Loss: 0.078275; Backpropagation: 0.2923 sec; Batch: 2.1149 sec
0.1636 0.1580 0.0930 0.0814 0.0740 0.0696 0.0682 0.0650 0.0632 0.0617 0.0604 0.0598 0.0593 0.0588 0.0585 0.0580 

[TRAIN] Epoch[1](4538/114412); Loss: 0.069811; Backpropagation: 0.2932 sec; Batch: 2.1219 sec
0.1490 0.1477 0.0999 0.0885 0.0741 0.0671 0.0630 0.0565 0.0529 0.0499 0.0468 0.0459 0.0447 0.0441 0.0436 0.0432 

[TRAIN] Epoch[1](4539/114412); Loss: 0.088245; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.1841 0.1818 0.1192 0.1087 0.0901 0.0820 0.0777 0.0709 0.0690 0.0660 0.0634 0.0615 0.0606 0.0597 0.0589 0.0582 

[TRAIN] Epoch[1](4540/114412); Loss: 0.090156; Backpropagation: 0.2909 sec; Batch: 2.1127 sec
0.1858 0.1820 0.1211 0.1104 0.0923 0.0821 0.0795 0.0741 0.0708 0.0680 0.0664 0.0641 0.0630 0.0617 0.0609 0.0604 

[TRAIN] Epoch[1](4541/114412); Loss: 0.097356; Backpropagation: 0.2953 sec; Batch: 2.1350 sec
0.1816 0.1807 0.1221 0.1145 0.0986 0.0912 0.0869 0.0830 0.0801 0.0782 0.0766 0.0749 0.0734 0.0725 0.0718 0.0713 

[TRAIN] Epoch[1](4542/114412); Loss: 0.071803; Backpropagation: 0.2916 sec; Batch: 2.1212 sec
0.1996 0.1947 0.0993 0.0908 0.0680 0.0582 0.0529 0.0494 0.0466 0.0446 0.0427 0.0420 0.0410 0.0401 0.0396 0.0393 

[TRAIN] Epoch[1](4543/114412); Loss: 0.073622; Backpropagation: 0.2915 sec; Batch: 2.1233 sec
0.1489 0.1530 0.0953 0.0874 0.0756 0.0685 0.0657 0.0607 0.0581 0.0559 0.0540 0.0524 0.0515 0.0506 0.0504 0.0500 

[TRAIN] Epoch[1](4544/114412); Loss: 0.084384; Backpropagation: 0.2931 sec; Batch: 2.1200 sec
0.1733 0.1715 0.1091 0.0991 0.0883 0.0775 0.0728 0.0689 0.0660 0.0639 0.0620 0.0609 0.0601 0.0593 0.0589 0.0583 

[TRAIN] Epoch[1](4545/114412); Loss: 0.078124; Backpropagation: 0.2932 sec; Batch: 2.1223 sec
0.1885 0.1823 0.1215 0.1100 0.0859 0.0742 0.0665 0.0586 0.0537 0.0484 0.0467 0.0447 0.0440 0.0426 0.0416 0.0407 

[TRAIN] Epoch[1](4546/114412); Loss: 0.090973; Backpropagation: 0.2953 sec; Batch: 2.1196 sec
0.1734 0.1697 0.1148 0.1074 0.0940 0.0889 0.0831 0.0776 0.0751 0.0723 0.0696 0.0681 0.0669 0.0655 0.0649 0.0642 

[TRAIN] Epoch[1](4547/114412); Loss: 0.078662; Backpropagation: 0.2931 sec; Batch: 2.1193 sec
0.1457 0.1386 0.1070 0.0994 0.0891 0.0813 0.0751 0.0694 0.0634 0.0609 0.0594 0.0557 0.0542 0.0539 0.0532 0.0522 

[TRAIN] Epoch[1](4548/114412); Loss: 0.097717; Backpropagation: 0.2911 sec; Batch: 2.1148 sec
0.1959 0.1923 0.1350 0.1233 0.1083 0.0962 0.0885 0.0807 0.0744 0.0720 0.0698 0.0674 0.0663 0.0653 0.0645 0.0637 

[TRAIN] Epoch[1](4549/114412); Loss: 0.080183; Backpropagation: 0.2910 sec; Batch: 2.1184 sec
0.1563 0.1546 0.1021 0.0943 0.0819 0.0760 0.0725 0.0679 0.0642 0.0623 0.0607 0.0597 0.0588 0.0578 0.0572 0.0567 

[TRAIN] Epoch[1](4550/114412); Loss: 0.081837; Backpropagation: 0.2908 sec; Batch: 2.0774 sec
0.1837 0.1812 0.1131 0.1020 0.0796 0.0722 0.0675 0.0631 0.0600 0.0580 0.0572 0.0556 0.0548 0.0542 0.0538 0.0533 

[TRAIN] Epoch[1](4551/114412); Loss: 0.074655; Backpropagation: 0.2908 sec; Batch: 2.1136 sec
0.1437 0.1350 0.1027 0.0941 0.0860 0.0777 0.0688 0.0630 0.0590 0.0565 0.0541 0.0526 0.0513 0.0504 0.0502 0.0495 

[TRAIN] Epoch[1](4552/114412); Loss: 0.096962; Backpropagation: 0.2910 sec; Batch: 2.1155 sec
0.1680 0.1688 0.1302 0.1221 0.1124 0.1022 0.0915 0.0842 0.0792 0.0755 0.0724 0.0715 0.0696 0.0687 0.0678 0.0672 

[TRAIN] Epoch[1](4553/114412); Loss: 0.088833; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1668 0.1630 0.1055 0.0977 0.0884 0.0825 0.0787 0.0756 0.0738 0.0725 0.0712 0.0702 0.0696 0.0688 0.0687 0.0682 

[TRAIN] Epoch[1](4554/114412); Loss: 0.081472; Backpropagation: 0.2910 sec; Batch: 2.1188 sec
0.1526 0.1432 0.1133 0.1012 0.0889 0.0794 0.0728 0.0683 0.0643 0.0622 0.0616 0.0606 0.0596 0.0588 0.0584 0.0581 

[TRAIN] Epoch[1](4555/114412); Loss: 0.039410; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1093 0.1041 0.0518 0.0426 0.0342 0.0307 0.0297 0.0290 0.0276 0.0261 0.0254 0.0250 0.0242 0.0239 0.0235 0.0233 

[TRAIN] Epoch[1](4556/114412); Loss: 0.063073; Backpropagation: 0.2931 sec; Batch: 2.1159 sec
0.1323 0.1247 0.0714 0.0671 0.0625 0.0578 0.0553 0.0529 0.0507 0.0498 0.0491 0.0481 0.0475 0.0471 0.0466 0.0463 

[TRAIN] Epoch[1](4557/114412); Loss: 0.082364; Backpropagation: 0.2915 sec; Batch: 2.1195 sec
0.1843 0.1822 0.1013 0.0930 0.0787 0.0739 0.0692 0.0658 0.0636 0.0618 0.0599 0.0586 0.0578 0.0568 0.0559 0.0551 

[TRAIN] Epoch[1](4558/114412); Loss: 0.092739; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1826 0.1793 0.1218 0.1077 0.0970 0.0905 0.0834 0.0767 0.0732 0.0705 0.0696 0.0682 0.0672 0.0660 0.0655 0.0645 

[TRAIN] Epoch[1](4559/114412); Loss: 0.080068; Backpropagation: 0.2928 sec; Batch: 2.1171 sec
0.1741 0.1662 0.1190 0.0998 0.0848 0.0724 0.0685 0.0630 0.0590 0.0571 0.0557 0.0543 0.0530 0.0523 0.0514 0.0505 

[TRAIN] Epoch[1](4560/114412); Loss: 0.092441; Backpropagation: 0.2929 sec; Batch: 2.1205 sec
0.1893 0.1846 0.1318 0.1200 0.1037 0.0929 0.0852 0.0785 0.0711 0.0676 0.0648 0.0607 0.0591 0.0579 0.0563 0.0556 

[TRAIN] Epoch[1](4561/114412); Loss: 0.061537; Backpropagation: 0.2908 sec; Batch: 2.1189 sec
0.1196 0.1145 0.0794 0.0737 0.0648 0.0598 0.0557 0.0531 0.0495 0.0480 0.0470 0.0452 0.0445 0.0438 0.0433 0.0428 

[TRAIN] Epoch[1](4562/114412); Loss: 0.104710; Backpropagation: 0.2912 sec; Batch: 2.0781 sec
0.1919 0.1873 0.1319 0.1253 0.1072 0.0988 0.0940 0.0902 0.0875 0.0852 0.0831 0.0812 0.0795 0.0782 0.0775 0.0766 

[TRAIN] Epoch[1](4563/114412); Loss: 0.067839; Backpropagation: 0.2913 sec; Batch: 2.0852 sec
0.1483 0.1416 0.0906 0.0778 0.0675 0.0638 0.0572 0.0538 0.0529 0.0503 0.0489 0.0482 0.0471 0.0463 0.0457 0.0452 

[TRAIN] Epoch[1](4564/114412); Loss: 0.112516; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1989 0.1916 0.1387 0.1296 0.1181 0.1101 0.1034 0.0983 0.0949 0.0931 0.0908 0.0885 0.0874 0.0863 0.0855 0.0850 

[TRAIN] Epoch[1](4565/114412); Loss: 0.082359; Backpropagation: 0.2909 sec; Batch: 2.0777 sec
0.1732 0.1736 0.1100 0.1033 0.0838 0.0758 0.0693 0.0657 0.0633 0.0607 0.0588 0.0576 0.0568 0.0558 0.0553 0.0548 

[TRAIN] Epoch[1](4566/114412); Loss: 0.065447; Backpropagation: 0.2933 sec; Batch: 2.1345 sec
0.1509 0.1379 0.0936 0.0823 0.0715 0.0602 0.0531 0.0505 0.0474 0.0456 0.0440 0.0432 0.0423 0.0419 0.0415 0.0413 

[TRAIN] Epoch[1](4567/114412); Loss: 0.071118; Backpropagation: 0.2929 sec; Batch: 2.1295 sec
0.1301 0.1226 0.0931 0.0853 0.0751 0.0692 0.0631 0.0603 0.0585 0.0567 0.0556 0.0550 0.0542 0.0535 0.0529 0.0526 

[TRAIN] Epoch[1](4568/114412); Loss: 0.080255; Backpropagation: 0.2909 sec; Batch: 2.1190 sec
0.1843 0.1874 0.1212 0.1082 0.0739 0.0678 0.0647 0.0585 0.0559 0.0543 0.0531 0.0523 0.0514 0.0508 0.0503 0.0500 

[TRAIN] Epoch[1](4569/114412); Loss: 0.097934; Backpropagation: 0.2909 sec; Batch: 2.1350 sec
0.1835 0.1731 0.1178 0.1099 0.1000 0.0920 0.0886 0.0853 0.0822 0.0806 0.0796 0.0780 0.0761 0.0749 0.0736 0.0718 

[TRAIN] Epoch[1](4570/114412); Loss: 0.103588; Backpropagation: 0.2927 sec; Batch: 2.1228 sec
0.2051 0.2020 0.1284 0.1220 0.1024 0.0940 0.0894 0.0856 0.0833 0.0814 0.0793 0.0786 0.0779 0.0766 0.0760 0.0755 

[TRAIN] Epoch[1](4571/114412); Loss: 0.058447; Backpropagation: 0.2913 sec; Batch: 2.1157 sec
0.1239 0.1192 0.0737 0.0663 0.0601 0.0534 0.0501 0.0480 0.0462 0.0448 0.0435 0.0425 0.0416 0.0410 0.0405 0.0404 

[TRAIN] Epoch[1](4572/114412); Loss: 0.060119; Backpropagation: 0.2906 sec; Batch: 2.1133 sec
0.1540 0.1520 0.0780 0.0710 0.0629 0.0553 0.0505 0.0426 0.0411 0.0389 0.0377 0.0369 0.0362 0.0354 0.0349 0.0347 

[TRAIN] Epoch[1](4573/114412); Loss: 0.102549; Backpropagation: 0.2934 sec; Batch: 2.1487 sec
0.1873 0.1831 0.1470 0.1243 0.1110 0.1018 0.0926 0.0878 0.0828 0.0789 0.0774 0.0756 0.0742 0.0733 0.0724 0.0712 

[TRAIN] Epoch[1](4574/114412); Loss: 0.065191; Backpropagation: 0.2912 sec; Batch: 2.0835 sec
0.1785 0.1787 0.0898 0.0813 0.0600 0.0544 0.0498 0.0455 0.0430 0.0408 0.0392 0.0379 0.0367 0.0363 0.0357 0.0353 

[TRAIN] Epoch[1](4575/114412); Loss: 0.076945; Backpropagation: 0.2913 sec; Batch: 2.0795 sec
0.1700 0.1655 0.0826 0.0793 0.0704 0.0677 0.0639 0.0618 0.0607 0.0596 0.0590 0.0588 0.0584 0.0580 0.0578 0.0577 

[TRAIN] Epoch[1](4576/114412); Loss: 0.099162; Backpropagation: 0.2930 sec; Batch: 2.0881 sec
0.2009 0.1982 0.1217 0.1169 0.1001 0.0942 0.0876 0.0831 0.0801 0.0773 0.0743 0.0726 0.0717 0.0701 0.0693 0.0686 

[TRAIN] Epoch[1](4577/114412); Loss: 0.076942; Backpropagation: 0.2913 sec; Batch: 2.0827 sec
0.1859 0.1842 0.0974 0.0894 0.0776 0.0669 0.0625 0.0586 0.0553 0.0532 0.0518 0.0511 0.0502 0.0494 0.0488 0.0484 

[TRAIN] Epoch[1](4578/114412); Loss: 0.103333; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1904 0.1866 0.1189 0.1118 0.1040 0.0974 0.0930 0.0894 0.0865 0.0850 0.0837 0.0825 0.0817 0.0814 0.0807 0.0802 

[TRAIN] Epoch[1](4579/114412); Loss: 0.105180; Backpropagation: 0.2912 sec; Batch: 2.1196 sec
0.2464 0.2459 0.1495 0.1392 0.1156 0.1045 0.0944 0.0849 0.0749 0.0678 0.0641 0.0608 0.0596 0.0593 0.0586 0.0574 

[TRAIN] Epoch[1](4580/114412); Loss: 0.093136; Backpropagation: 0.2912 sec; Batch: 2.0772 sec
0.1734 0.1662 0.1199 0.1136 0.1013 0.0931 0.0859 0.0815 0.0770 0.0739 0.0708 0.0688 0.0673 0.0665 0.0658 0.0651 

[TRAIN] Epoch[1](4581/114412); Loss: 0.085933; Backpropagation: 0.2933 sec; Batch: 2.1236 sec
0.1459 0.1407 0.1139 0.1048 0.0941 0.0870 0.0809 0.0757 0.0725 0.0701 0.0686 0.0669 0.0652 0.0640 0.0627 0.0617 

[TRAIN] Epoch[1](4582/114412); Loss: 0.085698; Backpropagation: 0.2912 sec; Batch: 2.1142 sec
0.1723 0.1672 0.1084 0.1010 0.0866 0.0793 0.0747 0.0716 0.0689 0.0665 0.0650 0.0635 0.0625 0.0619 0.0612 0.0608 

[TRAIN] Epoch[1](4583/114412); Loss: 0.097359; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1766 0.1726 0.1351 0.1213 0.1059 0.0949 0.0889 0.0837 0.0784 0.0762 0.0738 0.0719 0.0712 0.0701 0.0688 0.0683 

[TRAIN] Epoch[1](4584/114412); Loss: 0.063400; Backpropagation: 0.2912 sec; Batch: 2.1134 sec
0.1156 0.1079 0.0808 0.0750 0.0665 0.0604 0.0582 0.0550 0.0529 0.0513 0.0501 0.0492 0.0485 0.0479 0.0477 0.0474 

[TRAIN] Epoch[1](4585/114412); Loss: 0.085749; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1603 0.1569 0.1206 0.1041 0.0900 0.0796 0.0757 0.0724 0.0704 0.0679 0.0652 0.0638 0.0628 0.0614 0.0607 0.0602 

[TRAIN] Epoch[1](4586/114412); Loss: 0.099310; Backpropagation: 0.2938 sec; Batch: 2.1017 sec
0.1829 0.1769 0.1222 0.1172 0.1051 0.0992 0.0929 0.0874 0.0831 0.0803 0.0777 0.0757 0.0739 0.0724 0.0714 0.0707 

[TRAIN] Epoch[1](4587/114412); Loss: 0.067440; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1375 0.1267 0.0956 0.0866 0.0794 0.0694 0.0626 0.0563 0.0534 0.0498 0.0475 0.0451 0.0439 0.0429 0.0416 0.0408 

[TRAIN] Epoch[1](4588/114412); Loss: 0.077966; Backpropagation: 0.2905 sec; Batch: 2.1137 sec
0.1516 0.1478 0.1001 0.0970 0.0790 0.0746 0.0710 0.0654 0.0634 0.0605 0.0587 0.0580 0.0561 0.0556 0.0547 0.0539 

[TRAIN] Epoch[1](4589/114412); Loss: 0.057999; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.0900 0.0882 0.0793 0.0705 0.0667 0.0618 0.0584 0.0526 0.0506 0.0474 0.0463 0.0445 0.0440 0.0427 0.0429 0.0422 

[TRAIN] Epoch[1](4590/114412); Loss: 0.060963; Backpropagation: 0.2915 sec; Batch: 2.1220 sec
0.1277 0.1223 0.0777 0.0732 0.0641 0.0580 0.0546 0.0499 0.0478 0.0458 0.0445 0.0437 0.0427 0.0420 0.0411 0.0404 

[TRAIN] Epoch[1](4591/114412); Loss: 0.073570; Backpropagation: 0.2909 sec; Batch: 2.1528 sec
0.1425 0.1394 0.0982 0.0944 0.0819 0.0742 0.0679 0.0611 0.0579 0.0555 0.0531 0.0521 0.0510 0.0499 0.0494 0.0486 

[TRAIN] Epoch[1](4592/114412); Loss: 0.091303; Backpropagation: 0.2935 sec; Batch: 2.1199 sec
0.2014 0.1935 0.1183 0.1104 0.0920 0.0872 0.0790 0.0745 0.0696 0.0679 0.0642 0.0631 0.0612 0.0603 0.0595 0.0587 

[TRAIN] Epoch[1](4593/114412); Loss: 0.079520; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1547 0.1518 0.1065 0.0946 0.0837 0.0773 0.0723 0.0674 0.0647 0.0615 0.0592 0.0576 0.0564 0.0557 0.0547 0.0541 

[TRAIN] Epoch[1](4594/114412); Loss: 0.105106; Backpropagation: 0.2913 sec; Batch: 2.1555 sec
0.2154 0.2077 0.1507 0.1366 0.1193 0.1008 0.0945 0.0858 0.0817 0.0781 0.0730 0.0713 0.0689 0.0670 0.0661 0.0648 

[TRAIN] Epoch[1](4595/114412); Loss: 0.109261; Backpropagation: 0.2914 sec; Batch: 2.1209 sec
0.2448 0.2395 0.1760 0.1476 0.1132 0.0994 0.0896 0.0821 0.0764 0.0726 0.0716 0.0698 0.0691 0.0670 0.0652 0.0642 

[TRAIN] Epoch[1](4596/114412); Loss: 0.087905; Backpropagation: 0.2923 sec; Batch: 2.1219 sec
0.1681 0.1619 0.1172 0.1054 0.0916 0.0829 0.0791 0.0737 0.0714 0.0695 0.0674 0.0659 0.0648 0.0635 0.0625 0.0617 

[TRAIN] Epoch[1](4597/114412); Loss: 0.089774; Backpropagation: 0.2955 sec; Batch: 2.1192 sec
0.1862 0.1871 0.1206 0.1168 0.0880 0.0836 0.0771 0.0725 0.0708 0.0657 0.0641 0.0629 0.0611 0.0608 0.0599 0.0592 

[TRAIN] Epoch[1](4598/114412); Loss: 0.110391; Backpropagation: 0.2929 sec; Batch: 2.1209 sec
0.2015 0.1977 0.1280 0.1255 0.1116 0.1076 0.1012 0.0953 0.0922 0.0897 0.0882 0.0872 0.0861 0.0855 0.0847 0.0843 

[TRAIN] Epoch[1](4599/114412); Loss: 0.083448; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1460 0.1447 0.1142 0.1052 0.0959 0.0861 0.0802 0.0724 0.0686 0.0652 0.0624 0.0611 0.0597 0.0586 0.0580 0.0569 

[TRAIN] Epoch[1](4600/114412); Loss: 0.090518; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1737 0.1734 0.1141 0.1109 0.0940 0.0862 0.0814 0.0763 0.0740 0.0708 0.0688 0.0674 0.0658 0.0646 0.0639 0.0631 

[TRAIN] Epoch[1](4601/114412); Loss: 0.092112; Backpropagation: 0.2903 sec; Batch: 2.1242 sec
0.1643 0.1586 0.1224 0.1177 0.1077 0.0993 0.0916 0.0836 0.0774 0.0714 0.0683 0.0649 0.0634 0.0621 0.0609 0.0602 

[TRAIN] Epoch[1](4602/114412); Loss: 0.107740; Backpropagation: 0.2910 sec; Batch: 2.1150 sec
0.1816 0.1803 0.1402 0.1342 0.1139 0.1047 0.0980 0.0930 0.0901 0.0876 0.0856 0.0850 0.0838 0.0826 0.0821 0.0812 

[TRAIN] Epoch[1](4603/114412); Loss: 0.103431; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1798 0.1772 0.1360 0.1282 0.1115 0.1063 0.0988 0.0940 0.0908 0.0844 0.0809 0.0783 0.0747 0.0733 0.0712 0.0697 

[TRAIN] Epoch[1](4604/114412); Loss: 0.095869; Backpropagation: 0.2913 sec; Batch: 2.0782 sec
0.1663 0.1620 0.1354 0.1205 0.1119 0.0997 0.0941 0.0840 0.0812 0.0751 0.0718 0.0692 0.0675 0.0665 0.0650 0.0638 

[TRAIN] Epoch[1](4605/114412); Loss: 0.146672; Backpropagation: 0.2917 sec; Batch: 2.0798 sec
0.2315 0.2253 0.1902 0.1803 0.1645 0.1552 0.1444 0.1363 0.1291 0.1230 0.1186 0.1153 0.1126 0.1089 0.1069 0.1047 

[TRAIN] Epoch[1](4606/114412); Loss: 0.094547; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1755 0.1719 0.1280 0.1190 0.1035 0.0959 0.0870 0.0792 0.0752 0.0729 0.0708 0.0694 0.0678 0.0664 0.0655 0.0647 

[TRAIN] Epoch[1](4607/114412); Loss: 0.131786; Backpropagation: 0.2908 sec; Batch: 2.1282 sec
0.2210 0.2201 0.1792 0.1698 0.1521 0.1385 0.1293 0.1197 0.1135 0.1061 0.1026 0.0974 0.0946 0.0916 0.0871 0.0859 

[TRAIN] Epoch[1](4608/114412); Loss: 0.077586; Backpropagation: 0.2912 sec; Batch: 2.2092 sec
0.1448 0.1408 0.1044 0.0927 0.0820 0.0755 0.0710 0.0663 0.0635 0.0612 0.0601 0.0579 0.0569 0.0554 0.0547 0.0542 

[TRAIN] Epoch[1](4609/114412); Loss: 0.093791; Backpropagation: 0.2906 sec; Batch: 2.0802 sec
0.1642 0.1641 0.1207 0.1151 0.0959 0.0897 0.0833 0.0801 0.0776 0.0757 0.0745 0.0733 0.0724 0.0720 0.0712 0.0706 

[TRAIN] Epoch[1](4610/114412); Loss: 0.069730; Backpropagation: 0.2907 sec; Batch: 2.0786 sec
0.1306 0.1305 0.0986 0.0902 0.0755 0.0680 0.0639 0.0593 0.0573 0.0551 0.0522 0.0500 0.0480 0.0464 0.0454 0.0448 

[TRAIN] Epoch[1](4611/114412); Loss: 0.093950; Backpropagation: 0.2915 sec; Batch: 2.0987 sec
0.1702 0.1674 0.1264 0.1168 0.0994 0.0934 0.0870 0.0816 0.0770 0.0749 0.0720 0.0698 0.0685 0.0674 0.0663 0.0653 

[TRAIN] Epoch[1](4612/114412); Loss: 0.089354; Backpropagation: 0.2912 sec; Batch: 2.1267 sec
0.1581 0.1541 0.1189 0.1099 0.0951 0.0882 0.0816 0.0780 0.0747 0.0717 0.0701 0.0678 0.0666 0.0658 0.0649 0.0641 

[TRAIN] Epoch[1](4613/114412); Loss: 0.078874; Backpropagation: 0.2937 sec; Batch: 2.0857 sec
0.1510 0.1491 0.1112 0.1093 0.0912 0.0821 0.0727 0.0657 0.0623 0.0586 0.0558 0.0539 0.0518 0.0503 0.0490 0.0481 

[TRAIN] Epoch[1](4614/114412); Loss: 0.104225; Backpropagation: 0.2918 sec; Batch: 2.0786 sec
0.1703 0.1689 0.1405 0.1345 0.1192 0.1105 0.1023 0.0938 0.0893 0.0846 0.0812 0.0784 0.0758 0.0741 0.0727 0.0714 

[TRAIN] Epoch[1](4615/114412); Loss: 0.100564; Backpropagation: 0.2955 sec; Batch: 2.1207 sec
0.1830 0.1797 0.1383 0.1335 0.1151 0.1021 0.0949 0.0870 0.0824 0.0774 0.0741 0.0717 0.0695 0.0681 0.0668 0.0656 

[TRAIN] Epoch[1](4616/114412); Loss: 0.130808; Backpropagation: 0.2910 sec; Batch: 2.1478 sec
0.2094 0.2041 0.1687 0.1639 0.1461 0.1399 0.1277 0.1221 0.1137 0.1090 0.1049 0.1018 0.0984 0.0963 0.0943 0.0927 

[TRAIN] Epoch[1](4617/114412); Loss: 0.078007; Backpropagation: 0.2915 sec; Batch: 2.0829 sec
0.1493 0.1460 0.0867 0.1019 0.0886 0.0833 0.0761 0.0674 0.0631 0.0617 0.0588 0.0568 0.0540 0.0524 0.0516 0.0504 

[TRAIN] Epoch[1](4618/114412); Loss: 0.110356; Backpropagation: 0.2911 sec; Batch: 2.1459 sec
0.1983 0.1928 0.1504 0.1442 0.1259 0.1140 0.1043 0.0963 0.0906 0.0864 0.0826 0.0801 0.0776 0.0758 0.0739 0.0727 

[TRAIN] Epoch[1](4619/114412); Loss: 0.061525; Backpropagation: 0.2912 sec; Batch: 2.1500 sec
0.1199 0.1150 0.0811 0.0802 0.0672 0.0632 0.0561 0.0515 0.0485 0.0462 0.0447 0.0438 0.0425 0.0422 0.0414 0.0409 

[TRAIN] Epoch[1](4620/114412); Loss: 0.081245; Backpropagation: 0.2929 sec; Batch: 2.1515 sec
0.1346 0.1337 0.1026 0.1012 0.0893 0.0840 0.0783 0.0727 0.0690 0.0660 0.0641 0.0627 0.0615 0.0607 0.0600 0.0595 

[TRAIN] Epoch[1](4621/114412); Loss: 0.096905; Backpropagation: 0.2931 sec; Batch: 2.1084 sec
0.1836 0.1822 0.1232 0.1185 0.0981 0.0922 0.0856 0.0806 0.0780 0.0763 0.0746 0.0733 0.0724 0.0714 0.0705 0.0700 

[TRAIN] Epoch[1](4622/114412); Loss: 0.096670; Backpropagation: 0.2911 sec; Batch: 2.1533 sec
0.1665 0.1632 0.1255 0.1166 0.1049 0.0954 0.0887 0.0834 0.0810 0.0779 0.0768 0.0754 0.0739 0.0731 0.0724 0.0719 

[TRAIN] Epoch[1](4623/114412); Loss: 0.080632; Backpropagation: 0.2912 sec; Batch: 2.0835 sec
0.1496 0.1461 0.1137 0.1013 0.0848 0.0763 0.0706 0.0680 0.0652 0.0628 0.0611 0.0597 0.0589 0.0581 0.0573 0.0567 

[TRAIN] Epoch[1](4624/114412); Loss: 0.073924; Backpropagation: 0.2913 sec; Batch: 2.1473 sec
0.1552 0.1534 0.1017 0.0956 0.0747 0.0698 0.0650 0.0600 0.0568 0.0541 0.0520 0.0508 0.0494 0.0488 0.0481 0.0474 

[TRAIN] Epoch[1](4625/114412); Loss: 0.064819; Backpropagation: 0.2909 sec; Batch: 2.1188 sec
0.1485 0.1438 0.0851 0.0794 0.0627 0.0580 0.0532 0.0499 0.0479 0.0466 0.0451 0.0445 0.0439 0.0430 0.0428 0.0425 

[TRAIN] Epoch[1](4626/114412); Loss: 0.089108; Backpropagation: 0.2918 sec; Batch: 2.0825 sec
0.1498 0.1463 0.1110 0.1086 0.0988 0.0933 0.0855 0.0800 0.0762 0.0730 0.0705 0.0688 0.0675 0.0664 0.0653 0.0647 

[TRAIN] Epoch[1](4627/114412); Loss: 0.078302; Backpropagation: 0.2932 sec; Batch: 2.3146 sec
0.1366 0.1355 0.1025 0.0938 0.0841 0.0764 0.0710 0.0677 0.0647 0.0633 0.0617 0.0605 0.0597 0.0589 0.0584 0.0580 

[TRAIN] Epoch[1](4628/114412); Loss: 0.087942; Backpropagation: 0.2921 sec; Batch: 2.0920 sec
0.1492 0.1448 0.1127 0.1068 0.0965 0.0886 0.0842 0.0779 0.0750 0.0722 0.0700 0.0682 0.0668 0.0656 0.0646 0.0640 

[TRAIN] Epoch[1](4629/114412); Loss: 0.081705; Backpropagation: 0.2912 sec; Batch: 2.1114 sec
0.1651 0.1579 0.1213 0.1058 0.0914 0.0773 0.0708 0.0657 0.0617 0.0592 0.0575 0.0560 0.0553 0.0546 0.0540 0.0537 

[TRAIN] Epoch[1](4630/114412); Loss: 0.078491; Backpropagation: 0.2911 sec; Batch: 2.1510 sec
0.1763 0.1723 0.1045 0.1017 0.0824 0.0745 0.0663 0.0608 0.0579 0.0556 0.0535 0.0518 0.0506 0.0500 0.0491 0.0485 

[TRAIN] Epoch[1](4631/114412); Loss: 0.064031; Backpropagation: 0.2915 sec; Batch: 2.0816 sec
0.1184 0.1169 0.0861 0.0852 0.0737 0.0659 0.0603 0.0543 0.0509 0.0484 0.0469 0.0453 0.0442 0.0436 0.0426 0.0419 

[TRAIN] Epoch[1](4632/114412); Loss: 0.103470; Backpropagation: 0.2914 sec; Batch: 2.1731 sec
0.1756 0.1727 0.1225 0.1156 0.1045 0.1002 0.0966 0.0937 0.0909 0.0882 0.0868 0.0847 0.0827 0.0819 0.0802 0.0787 

[TRAIN] Epoch[1](4633/114412); Loss: 0.095454; Backpropagation: 0.2908 sec; Batch: 2.0821 sec
0.1609 0.1607 0.1337 0.1234 0.1069 0.0959 0.0874 0.0814 0.0782 0.0753 0.0735 0.0723 0.0710 0.0699 0.0686 0.0681 

[TRAIN] Epoch[1](4634/114412); Loss: 0.117581; Backpropagation: 0.2908 sec; Batch: 2.1768 sec
0.2152 0.2105 0.1558 0.1481 0.1251 0.1113 0.1049 0.0988 0.0949 0.0930 0.0902 0.0885 0.0877 0.0867 0.0857 0.0850 

[TRAIN] Epoch[1](4635/114412); Loss: 0.084671; Backpropagation: 0.2911 sec; Batch: 2.1116 sec
0.1724 0.1737 0.1148 0.1041 0.0828 0.0776 0.0721 0.0676 0.0665 0.0641 0.0620 0.0612 0.0602 0.0593 0.0585 0.0581 

[TRAIN] Epoch[1](4636/114412); Loss: 0.088914; Backpropagation: 0.2912 sec; Batch: 2.2565 sec
0.1634 0.1586 0.1192 0.1114 0.0945 0.0853 0.0791 0.0752 0.0727 0.0701 0.0681 0.0672 0.0657 0.0647 0.0641 0.0634 

[TRAIN] Epoch[1](4637/114412); Loss: 0.089104; Backpropagation: 0.2931 sec; Batch: 2.1441 sec
0.1796 0.1747 0.1188 0.1108 0.0938 0.0864 0.0793 0.0736 0.0692 0.0674 0.0653 0.0632 0.0623 0.0611 0.0602 0.0599 

[TRAIN] Epoch[1](4638/114412); Loss: 0.097809; Backpropagation: 0.2939 sec; Batch: 2.1434 sec
0.2014 0.1982 0.1501 0.1310 0.1042 0.0925 0.0855 0.0797 0.0742 0.0703 0.0675 0.0654 0.0636 0.0618 0.0604 0.0591 

[TRAIN] Epoch[1](4639/114412); Loss: 0.091532; Backpropagation: 0.2954 sec; Batch: 2.1613 sec
0.1596 0.1578 0.1171 0.1103 0.0964 0.0888 0.0843 0.0797 0.0774 0.0744 0.0723 0.0711 0.0699 0.0691 0.0684 0.0677 

[TRAIN] Epoch[1](4640/114412); Loss: 0.126920; Backpropagation: 0.2929 sec; Batch: 2.1102 sec
0.1914 0.1885 0.1681 0.1511 0.1419 0.1321 0.1254 0.1205 0.1135 0.1097 0.1057 0.1020 0.0982 0.0964 0.0940 0.0920 

[TRAIN] Epoch[1](4641/114412); Loss: 0.131563; Backpropagation: 0.2913 sec; Batch: 2.3463 sec
0.2073 0.2083 0.1716 0.1607 0.1446 0.1326 0.1274 0.1221 0.1143 0.1120 0.1099 0.1031 0.1017 0.1011 0.0949 0.0936 

[TRAIN] Epoch[1](4642/114412); Loss: 0.100601; Backpropagation: 0.2928 sec; Batch: 2.1152 sec
0.1951 0.1939 0.1377 0.1262 0.1067 0.0970 0.0883 0.0835 0.0799 0.0766 0.0740 0.0723 0.0713 0.0700 0.0690 0.0681 

[TRAIN] Epoch[1](4643/114412); Loss: 0.089650; Backpropagation: 0.2912 sec; Batch: 2.1891 sec
0.1574 0.1577 0.1199 0.1143 0.0997 0.0917 0.0841 0.0782 0.0742 0.0711 0.0686 0.0662 0.0643 0.0630 0.0621 0.0617 

[TRAIN] Epoch[1](4644/114412); Loss: 0.086318; Backpropagation: 0.2910 sec; Batch: 2.1819 sec
0.1825 0.1758 0.1149 0.1067 0.0888 0.0801 0.0752 0.0701 0.0669 0.0641 0.0621 0.0602 0.0593 0.0588 0.0581 0.0575 

[TRAIN] Epoch[1](4645/114412); Loss: 0.078621; Backpropagation: 0.2914 sec; Batch: 2.1454 sec
0.1691 0.1701 0.1106 0.1017 0.0784 0.0705 0.0667 0.0614 0.0597 0.0565 0.0549 0.0539 0.0525 0.0510 0.0507 0.0502 

[TRAIN] Epoch[1](4646/114412); Loss: 0.077859; Backpropagation: 0.2914 sec; Batch: 2.1137 sec
0.1481 0.1425 0.1167 0.1070 0.0887 0.0792 0.0718 0.0652 0.0600 0.0565 0.0546 0.0528 0.0518 0.0509 0.0503 0.0498 

[TRAIN] Epoch[1](4647/114412); Loss: 0.082466; Backpropagation: 0.2912 sec; Batch: 2.1449 sec
0.1715 0.1667 0.1301 0.1165 0.0964 0.0806 0.0704 0.0651 0.0606 0.0567 0.0547 0.0522 0.0504 0.0499 0.0491 0.0487 

[TRAIN] Epoch[1](4648/114412); Loss: 0.090571; Backpropagation: 0.2913 sec; Batch: 2.1110 sec
0.1729 0.1705 0.1181 0.1109 0.0936 0.0855 0.0805 0.0759 0.0729 0.0702 0.0686 0.0675 0.0665 0.0657 0.0652 0.0646 

[TRAIN] Epoch[1](4649/114412); Loss: 0.093553; Backpropagation: 0.2906 sec; Batch: 2.1117 sec
0.1945 0.1913 0.1194 0.1153 0.0954 0.0862 0.0806 0.0768 0.0732 0.0705 0.0684 0.0670 0.0657 0.0649 0.0641 0.0636 

[TRAIN] Epoch[1](4650/114412); Loss: 0.078419; Backpropagation: 0.2953 sec; Batch: 2.1192 sec
0.1907 0.1827 0.1337 0.1115 0.0874 0.0708 0.0604 0.0575 0.0521 0.0494 0.0471 0.0447 0.0433 0.0422 0.0411 0.0403 

[TRAIN] Epoch[1](4651/114412); Loss: 0.073129; Backpropagation: 0.2952 sec; Batch: 2.1209 sec
0.1445 0.1377 0.0954 0.0903 0.0792 0.0719 0.0677 0.0636 0.0607 0.0571 0.0544 0.0520 0.0503 0.0492 0.0482 0.0478 

[TRAIN] Epoch[1](4652/114412); Loss: 0.095353; Backpropagation: 0.2955 sec; Batch: 2.2318 sec
0.1940 0.1911 0.1284 0.1187 0.0944 0.0873 0.0809 0.0772 0.0744 0.0722 0.0702 0.0691 0.0680 0.0672 0.0665 0.0660 

[TRAIN] Epoch[1](4653/114412); Loss: 0.075449; Backpropagation: 0.2913 sec; Batch: 2.1409 sec
0.1429 0.1417 0.1021 0.0932 0.0793 0.0719 0.0670 0.0635 0.0609 0.0583 0.0566 0.0555 0.0543 0.0537 0.0534 0.0528 

[TRAIN] Epoch[1](4654/114412); Loss: 0.068685; Backpropagation: 0.2910 sec; Batch: 2.1459 sec
0.1658 0.1624 0.0952 0.0876 0.0666 0.0600 0.0552 0.0515 0.0488 0.0466 0.0453 0.0444 0.0434 0.0427 0.0421 0.0415 

[TRAIN] Epoch[1](4655/114412); Loss: 0.101797; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1754 0.1677 0.1273 0.1191 0.1067 0.1009 0.0948 0.0900 0.0866 0.0843 0.0822 0.0807 0.0796 0.0784 0.0778 0.0774 

[TRAIN] Epoch[1](4656/114412); Loss: 0.096458; Backpropagation: 0.2911 sec; Batch: 2.5057 sec
0.2012 0.1979 0.1317 0.1215 0.0987 0.0894 0.0808 0.0742 0.0734 0.0714 0.0697 0.0685 0.0675 0.0665 0.0660 0.0650 

[TRAIN] Epoch[1](4657/114412); Loss: 0.083317; Backpropagation: 0.2911 sec; Batch: 2.1456 sec
0.1593 0.1491 0.1032 0.0992 0.0888 0.0805 0.0759 0.0712 0.0686 0.0664 0.0645 0.0632 0.0621 0.0611 0.0602 0.0597 

[TRAIN] Epoch[1](4658/114412); Loss: 0.101208; Backpropagation: 0.2921 sec; Batch: 2.0801 sec
0.1997 0.1915 0.1321 0.1221 0.1050 0.0975 0.0917 0.0858 0.0816 0.0786 0.0760 0.0739 0.0728 0.0714 0.0703 0.0692 

[TRAIN] Epoch[1](4659/114412); Loss: 0.080243; Backpropagation: 0.2914 sec; Batch: 2.1540 sec
0.1564 0.1541 0.1085 0.0977 0.0855 0.0767 0.0714 0.0662 0.0632 0.0618 0.0601 0.0584 0.0572 0.0562 0.0556 0.0549 

[TRAIN] Epoch[1](4660/114412); Loss: 0.092818; Backpropagation: 0.2921 sec; Batch: 2.0783 sec
0.1960 0.1914 0.1269 0.1167 0.0963 0.0868 0.0781 0.0734 0.0704 0.0678 0.0661 0.0650 0.0637 0.0627 0.0622 0.0617 

[TRAIN] Epoch[1](4661/114412); Loss: 0.085273; Backpropagation: 0.2909 sec; Batch: 2.1526 sec
0.1684 0.1626 0.1144 0.1020 0.0949 0.0854 0.0780 0.0707 0.0666 0.0648 0.0619 0.0605 0.0596 0.0590 0.0582 0.0575 

[TRAIN] Epoch[1](4662/114412); Loss: 0.130000; Backpropagation: 0.2908 sec; Batch: 2.1132 sec
0.2275 0.2186 0.1767 0.1622 0.1391 0.1262 0.1199 0.1130 0.1085 0.1044 0.1021 0.0997 0.0979 0.0964 0.0946 0.0934 

[TRAIN] Epoch[1](4663/114412); Loss: 0.107877; Backpropagation: 0.2929 sec; Batch: 2.1499 sec
0.1996 0.2008 0.1457 0.1369 0.1206 0.1108 0.1013 0.0937 0.0872 0.0829 0.0793 0.0769 0.0746 0.0728 0.0718 0.0710 

[TRAIN] Epoch[1](4664/114412); Loss: 0.079041; Backpropagation: 0.2911 sec; Batch: 2.1360 sec
0.1525 0.1489 0.0986 0.0917 0.0829 0.0772 0.0715 0.0671 0.0640 0.0624 0.0606 0.0593 0.0582 0.0570 0.0564 0.0561 

[TRAIN] Epoch[1](4665/114412); Loss: 0.089842; Backpropagation: 0.2912 sec; Batch: 2.2335 sec
0.1538 0.1505 0.1190 0.1115 0.0995 0.0929 0.0861 0.0811 0.0762 0.0724 0.0692 0.0670 0.0657 0.0649 0.0641 0.0636 

[TRAIN] Epoch[1](4666/114412); Loss: 0.082099; Backpropagation: 0.2910 sec; Batch: 2.1465 sec
0.1507 0.1467 0.1141 0.1048 0.0920 0.0821 0.0730 0.0681 0.0652 0.0630 0.0616 0.0603 0.0591 0.0583 0.0576 0.0571 

[TRAIN] Epoch[1](4667/114412); Loss: 0.093394; Backpropagation: 0.2917 sec; Batch: 2.0789 sec
0.1620 0.1583 0.1171 0.1093 0.0981 0.0906 0.0860 0.0833 0.0802 0.0769 0.0753 0.0736 0.0724 0.0713 0.0703 0.0695 

[TRAIN] Epoch[1](4668/114412); Loss: 0.078184; Backpropagation: 0.2931 sec; Batch: 2.1531 sec
0.1534 0.1491 0.1014 0.0974 0.0858 0.0777 0.0708 0.0664 0.0632 0.0594 0.0569 0.0559 0.0545 0.0537 0.0529 0.0524 

[TRAIN] Epoch[1](4669/114412); Loss: 0.058128; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.1155 0.1121 0.0793 0.0709 0.0621 0.0562 0.0527 0.0486 0.0457 0.0442 0.0426 0.0415 0.0406 0.0398 0.0393 0.0387 

[TRAIN] Epoch[1](4670/114412); Loss: 0.073686; Backpropagation: 0.2911 sec; Batch: 2.1575 sec
0.1331 0.1305 0.0979 0.0896 0.0804 0.0746 0.0675 0.0635 0.0616 0.0590 0.0571 0.0562 0.0533 0.0521 0.0515 0.0510 

[TRAIN] Epoch[1](4671/114412); Loss: 0.101117; Backpropagation: 0.2910 sec; Batch: 2.1106 sec
0.1849 0.1834 0.1295 0.1214 0.1111 0.1014 0.0950 0.0880 0.0830 0.0797 0.0773 0.0750 0.0736 0.0726 0.0716 0.0705 

[TRAIN] Epoch[1](4672/114412); Loss: 0.071501; Backpropagation: 0.2915 sec; Batch: 2.1466 sec
0.1441 0.1389 0.0961 0.0900 0.0763 0.0685 0.0619 0.0584 0.0557 0.0538 0.0522 0.0510 0.0502 0.0495 0.0490 0.0485 

[TRAIN] Epoch[1](4673/114412); Loss: 0.083198; Backpropagation: 0.2915 sec; Batch: 2.1135 sec
0.1631 0.1571 0.1130 0.1029 0.0920 0.0793 0.0732 0.0695 0.0644 0.0634 0.0615 0.0595 0.0590 0.0583 0.0577 0.0571 

[TRAIN] Epoch[1](4674/114412); Loss: 0.093678; Backpropagation: 0.2911 sec; Batch: 2.1759 sec
0.1651 0.1506 0.1266 0.1174 0.1093 0.0963 0.0858 0.0795 0.0777 0.0745 0.0726 0.0710 0.0695 0.0685 0.0675 0.0670 

[TRAIN] Epoch[1](4675/114412); Loss: 0.081089; Backpropagation: 0.2946 sec; Batch: 2.1427 sec
0.1496 0.1461 0.1079 0.1003 0.0834 0.0778 0.0717 0.0682 0.0656 0.0638 0.0624 0.0617 0.0607 0.0599 0.0594 0.0591 

[TRAIN] Epoch[1](4676/114412); Loss: 0.100806; Backpropagation: 0.2917 sec; Batch: 2.1434 sec
0.1876 0.1863 0.1389 0.1268 0.1093 0.0983 0.0893 0.0840 0.0798 0.0775 0.0758 0.0740 0.0728 0.0718 0.0707 0.0698 

[TRAIN] Epoch[1](4677/114412); Loss: 0.118041; Backpropagation: 0.2910 sec; Batch: 2.1230 sec
0.2221 0.2164 0.1652 0.1536 0.1379 0.1281 0.1154 0.1052 0.0961 0.0882 0.0832 0.0793 0.0772 0.0752 0.0735 0.0721 

[TRAIN] Epoch[1](4678/114412); Loss: 0.077612; Backpropagation: 0.2910 sec; Batch: 2.1445 sec
0.1822 0.1808 0.1073 0.0941 0.0719 0.0664 0.0620 0.0577 0.0554 0.0542 0.0533 0.0521 0.0517 0.0511 0.0510 0.0505 

[TRAIN] Epoch[1](4679/114412); Loss: 0.082726; Backpropagation: 0.2912 sec; Batch: 2.1404 sec
0.1430 0.1434 0.1254 0.1112 0.0986 0.0880 0.0759 0.0690 0.0649 0.0624 0.0603 0.0586 0.0572 0.0560 0.0552 0.0547 

[TRAIN] Epoch[1](4680/114412); Loss: 0.070733; Backpropagation: 0.2920 sec; Batch: 2.3938 sec
0.1472 0.1438 0.0945 0.0849 0.0706 0.0636 0.0594 0.0564 0.0550 0.0539 0.0521 0.0517 0.0505 0.0501 0.0493 0.0488 

[TRAIN] Epoch[1](4681/114412); Loss: 0.086489; Backpropagation: 0.2915 sec; Batch: 2.1183 sec
0.1591 0.1533 0.1024 0.0971 0.0892 0.0823 0.0777 0.0740 0.0715 0.0701 0.0688 0.0684 0.0680 0.0677 0.0674 0.0668 

[TRAIN] Epoch[1](4682/114412); Loss: 0.077689; Backpropagation: 0.2923 sec; Batch: 2.0783 sec
0.1422 0.1397 0.1093 0.0982 0.0848 0.0767 0.0696 0.0653 0.0615 0.0597 0.0581 0.0572 0.0560 0.0554 0.0549 0.0545 

[TRAIN] Epoch[1](4683/114412); Loss: 0.058174; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1020 0.0974 0.0789 0.0737 0.0669 0.0596 0.0549 0.0503 0.0476 0.0459 0.0442 0.0434 0.0422 0.0417 0.0412 0.0409 

[TRAIN] Epoch[1](4684/114412); Loss: 0.125316; Backpropagation: 0.2907 sec; Batch: 2.0814 sec
0.1929 0.1877 0.1569 0.1493 0.1405 0.1315 0.1263 0.1174 0.1119 0.1083 0.1037 0.1002 0.0982 0.0960 0.0926 0.0916 

[TRAIN] Epoch[1](4685/114412); Loss: 0.082523; Backpropagation: 0.2905 sec; Batch: 2.0770 sec
0.1685 0.1608 0.1073 0.0958 0.0811 0.0766 0.0714 0.0681 0.0661 0.0643 0.0625 0.0612 0.0603 0.0593 0.0588 0.0584 

[TRAIN] Epoch[1](4686/114412); Loss: 0.061292; Backpropagation: 0.2904 sec; Batch: 2.1749 sec
0.1446 0.1405 0.0827 0.0711 0.0605 0.0549 0.0513 0.0457 0.0436 0.0424 0.0420 0.0414 0.0408 0.0400 0.0397 0.0394 

[TRAIN] Epoch[1](4687/114412); Loss: 0.098097; Backpropagation: 0.2914 sec; Batch: 2.1204 sec
0.1673 0.1646 0.1209 0.1157 0.1048 0.0988 0.0925 0.0885 0.0843 0.0807 0.0785 0.0772 0.0755 0.0740 0.0734 0.0729 

[TRAIN] Epoch[1](4688/114412); Loss: 0.091997; Backpropagation: 0.2912 sec; Batch: 2.1145 sec
0.2003 0.1950 0.1255 0.1115 0.0919 0.0814 0.0761 0.0730 0.0704 0.0673 0.0659 0.0646 0.0634 0.0625 0.0619 0.0613 

[TRAIN] Epoch[1](4689/114412); Loss: 0.101338; Backpropagation: 0.2912 sec; Batch: 2.1165 sec
0.1809 0.1768 0.1261 0.1169 0.1056 0.0981 0.0913 0.0875 0.0848 0.0828 0.0814 0.0799 0.0787 0.0777 0.0768 0.0762 

[TRAIN] Epoch[1](4690/114412); Loss: 0.076578; Backpropagation: 0.2957 sec; Batch: 2.1223 sec
0.1464 0.1378 0.1032 0.0940 0.0832 0.0798 0.0707 0.0654 0.0619 0.0589 0.0571 0.0551 0.0540 0.0534 0.0527 0.0516 

[TRAIN] Epoch[1](4691/114412); Loss: 0.071340; Backpropagation: 0.2932 sec; Batch: 2.1190 sec
0.1440 0.1439 0.0896 0.0820 0.0749 0.0680 0.0642 0.0597 0.0577 0.0548 0.0527 0.0520 0.0509 0.0497 0.0490 0.0484 

[TRAIN] Epoch[1](4692/114412); Loss: 0.100187; Backpropagation: 0.2931 sec; Batch: 2.0812 sec
0.2141 0.2091 0.1444 0.1266 0.1024 0.0922 0.0839 0.0772 0.0745 0.0721 0.0710 0.0693 0.0675 0.0668 0.0663 0.0656 

[TRAIN] Epoch[1](4693/114412); Loss: 0.099935; Backpropagation: 0.2922 sec; Batch: 2.0793 sec
0.1864 0.1808 0.1282 0.1185 0.1070 0.0978 0.0918 0.0856 0.0821 0.0786 0.0769 0.0755 0.0739 0.0727 0.0720 0.0712 

[TRAIN] Epoch[1](4694/114412); Loss: 0.082908; Backpropagation: 0.2927 sec; Batch: 2.1188 sec
0.1618 0.1595 0.1119 0.0993 0.0877 0.0788 0.0728 0.0688 0.0660 0.0633 0.0620 0.0611 0.0592 0.0585 0.0581 0.0577 

[TRAIN] Epoch[1](4695/114412); Loss: 0.111599; Backpropagation: 0.2955 sec; Batch: 2.0846 sec
0.2327 0.2258 0.1614 0.1425 0.1117 0.0951 0.0926 0.0861 0.0834 0.0819 0.0809 0.0800 0.0790 0.0782 0.0774 0.0771 

[TRAIN] Epoch[1](4696/114412); Loss: 0.084788; Backpropagation: 0.2912 sec; Batch: 2.1224 sec
0.1682 0.1673 0.1171 0.1052 0.0881 0.0796 0.0736 0.0684 0.0659 0.0626 0.0618 0.0610 0.0602 0.0596 0.0593 0.0587 

[TRAIN] Epoch[1](4697/114412); Loss: 0.073491; Backpropagation: 0.2928 sec; Batch: 2.1222 sec
0.1828 0.1808 0.0956 0.0845 0.0651 0.0609 0.0571 0.0541 0.0522 0.0511 0.0502 0.0490 0.0485 0.0482 0.0480 0.0477 

[TRAIN] Epoch[1](4698/114412); Loss: 0.095239; Backpropagation: 0.2923 sec; Batch: 2.0810 sec
0.1800 0.1714 0.1158 0.1047 0.0947 0.0889 0.0852 0.0818 0.0797 0.0779 0.0762 0.0753 0.0741 0.0733 0.0726 0.0722 

[TRAIN] Epoch[1](4699/114412); Loss: 0.071614; Backpropagation: 0.2909 sec; Batch: 2.1203 sec
0.1420 0.1397 0.0912 0.0858 0.0737 0.0671 0.0626 0.0585 0.0569 0.0556 0.0543 0.0532 0.0523 0.0516 0.0510 0.0503 

[TRAIN] Epoch[1](4700/114412); Loss: 0.085672; Backpropagation: 0.2928 sec; Batch: 2.1205 sec
0.1571 0.1534 0.1153 0.1056 0.0916 0.0829 0.0771 0.0730 0.0697 0.0673 0.0653 0.0641 0.0630 0.0624 0.0618 0.0612 

[TRAIN] Epoch[1](4701/114412); Loss: 0.098737; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.1677 0.1651 0.1166 0.1078 0.0984 0.0942 0.0895 0.0872 0.0860 0.0838 0.0827 0.0816 0.0808 0.0802 0.0795 0.0789 

[TRAIN] Epoch[1](4702/114412); Loss: 0.108147; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.2070 0.1982 0.1477 0.1342 0.1131 0.1032 0.0976 0.0934 0.0880 0.0844 0.0817 0.0797 0.0777 0.0758 0.0748 0.0739 

[TRAIN] Epoch[1](4703/114412); Loss: 0.088391; Backpropagation: 0.2931 sec; Batch: 2.1171 sec
0.1865 0.1788 0.1229 0.1016 0.0891 0.0816 0.0753 0.0712 0.0680 0.0658 0.0646 0.0634 0.0623 0.0617 0.0610 0.0603 

[TRAIN] Epoch[1](4704/114412); Loss: 0.081695; Backpropagation: 0.2912 sec; Batch: 2.0798 sec
0.1680 0.1593 0.1148 0.1012 0.0877 0.0800 0.0723 0.0681 0.0641 0.0605 0.0578 0.0558 0.0559 0.0545 0.0537 0.0534 

[TRAIN] Epoch[1](4705/114412); Loss: 0.071739; Backpropagation: 0.2929 sec; Batch: 2.0844 sec
0.1433 0.1412 0.1007 0.0885 0.0738 0.0676 0.0618 0.0576 0.0556 0.0538 0.0524 0.0514 0.0508 0.0504 0.0498 0.0493 

[TRAIN] Epoch[1](4706/114412); Loss: 0.090905; Backpropagation: 0.2912 sec; Batch: 2.0957 sec
0.1887 0.1859 0.1105 0.1012 0.0937 0.0844 0.0790 0.0741 0.0714 0.0688 0.0676 0.0666 0.0662 0.0658 0.0656 0.0651 

[TRAIN] Epoch[1](4707/114412); Loss: 0.074657; Backpropagation: 0.2933 sec; Batch: 2.1188 sec
0.1626 0.1609 0.0950 0.0889 0.0799 0.0701 0.0652 0.0606 0.0587 0.0542 0.0530 0.0512 0.0500 0.0489 0.0480 0.0472 

[TRAIN] Epoch[1](4708/114412); Loss: 0.096146; Backpropagation: 0.2910 sec; Batch: 2.1029 sec
0.1857 0.1755 0.1224 0.1175 0.1043 0.0959 0.0888 0.0838 0.0793 0.0755 0.0728 0.0708 0.0680 0.0671 0.0663 0.0648 

[TRAIN] Epoch[1](4709/114412); Loss: 0.075740; Backpropagation: 0.2935 sec; Batch: 2.1247 sec
0.1486 0.1437 0.1008 0.0897 0.0820 0.0744 0.0677 0.0636 0.0610 0.0577 0.0561 0.0551 0.0541 0.0531 0.0524 0.0519 

[TRAIN] Epoch[1](4710/114412); Loss: 0.100838; Backpropagation: 0.2929 sec; Batch: 2.0971 sec
0.1868 0.1802 0.1267 0.1195 0.1088 0.0992 0.0933 0.0867 0.0834 0.0799 0.0788 0.0758 0.0746 0.0739 0.0733 0.0725 

[TRAIN] Epoch[1](4711/114412); Loss: 0.075981; Backpropagation: 0.2942 sec; Batch: 2.1189 sec
0.1316 0.1292 0.1011 0.0910 0.0805 0.0759 0.0694 0.0660 0.0636 0.0613 0.0596 0.0586 0.0577 0.0569 0.0566 0.0565 

[TRAIN] Epoch[1](4712/114412); Loss: 0.086760; Backpropagation: 0.2954 sec; Batch: 2.1175 sec
0.1646 0.1526 0.1114 0.1042 0.0906 0.0827 0.0792 0.0751 0.0712 0.0687 0.0672 0.0660 0.0652 0.0639 0.0631 0.0624 

[TRAIN] Epoch[1](4713/114412); Loss: 0.100646; Backpropagation: 0.2932 sec; Batch: 2.1187 sec
0.1881 0.1831 0.1394 0.1274 0.1095 0.0993 0.0903 0.0860 0.0814 0.0782 0.0760 0.0730 0.0716 0.0704 0.0687 0.0679 

[TRAIN] Epoch[1](4714/114412); Loss: 0.072259; Backpropagation: 0.2933 sec; Batch: 2.0821 sec
0.1452 0.1361 0.1068 0.0912 0.0748 0.0662 0.0623 0.0580 0.0558 0.0539 0.0529 0.0521 0.0511 0.0504 0.0498 0.0495 

[TRAIN] Epoch[1](4715/114412); Loss: 0.092935; Backpropagation: 0.2913 sec; Batch: 2.0803 sec
0.1763 0.1772 0.1518 0.1297 0.1106 0.0899 0.0787 0.0727 0.0708 0.0695 0.0681 0.0637 0.0601 0.0577 0.0554 0.0547 

[TRAIN] Epoch[1](4716/114412); Loss: 0.101595; Backpropagation: 0.2909 sec; Batch: 2.1508 sec
0.2023 0.1964 0.1410 0.1262 0.1097 0.1016 0.0912 0.0844 0.0796 0.0760 0.0739 0.0717 0.0699 0.0683 0.0670 0.0662 

[TRAIN] Epoch[1](4717/114412); Loss: 0.091456; Backpropagation: 0.2912 sec; Batch: 2.1200 sec
0.1616 0.1570 0.1189 0.1051 0.0980 0.0938 0.0856 0.0799 0.0763 0.0739 0.0720 0.0702 0.0688 0.0679 0.0675 0.0669 

[TRAIN] Epoch[1](4718/114412); Loss: 0.078131; Backpropagation: 0.2914 sec; Batch: 2.1056 sec
0.1543 0.1510 0.1094 0.0935 0.0750 0.0703 0.0665 0.0636 0.0614 0.0597 0.0589 0.0584 0.0577 0.0572 0.0567 0.0565 

[TRAIN] Epoch[1](4719/114412); Loss: 0.100184; Backpropagation: 0.2911 sec; Batch: 2.1202 sec
0.1725 0.1671 0.1271 0.1183 0.1031 0.0971 0.0918 0.0879 0.0849 0.0820 0.0806 0.0796 0.0792 0.0782 0.0771 0.0763 

[TRAIN] Epoch[1](4720/114412); Loss: 0.087266; Backpropagation: 0.2913 sec; Batch: 2.1150 sec
0.1936 0.1913 0.1336 0.1124 0.0889 0.0785 0.0712 0.0661 0.0624 0.0607 0.0595 0.0578 0.0564 0.0554 0.0544 0.0540 

[TRAIN] Epoch[1](4721/114412); Loss: 0.086808; Backpropagation: 0.2929 sec; Batch: 2.1452 sec
0.1526 0.1546 0.1217 0.1115 0.0977 0.0870 0.0797 0.0734 0.0705 0.0679 0.0658 0.0638 0.0623 0.0612 0.0602 0.0591 

[TRAIN] Epoch[1](4722/114412); Loss: 0.103757; Backpropagation: 0.2953 sec; Batch: 2.1139 sec
0.2145 0.2076 0.1513 0.1339 0.1074 0.0963 0.0900 0.0842 0.0801 0.0762 0.0733 0.0711 0.0699 0.0688 0.0681 0.0672 

[TRAIN] Epoch[1](4723/114412); Loss: 0.081712; Backpropagation: 0.2932 sec; Batch: 2.1192 sec
0.1503 0.1513 0.1134 0.1023 0.0861 0.0785 0.0723 0.0684 0.0656 0.0631 0.0619 0.0606 0.0593 0.0586 0.0582 0.0574 

[TRAIN] Epoch[1](4724/114412); Loss: 0.074994; Backpropagation: 0.2922 sec; Batch: 2.0962 sec
0.1334 0.1325 0.1014 0.0946 0.0804 0.0728 0.0660 0.0630 0.0616 0.0595 0.0587 0.0567 0.0560 0.0551 0.0543 0.0539 

[TRAIN] Epoch[1](4725/114412); Loss: 0.074839; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1692 0.1609 0.1171 0.1037 0.0811 0.0716 0.0635 0.0560 0.0529 0.0505 0.0476 0.0462 0.0453 0.0445 0.0439 0.0434 

[TRAIN] Epoch[1](4726/114412); Loss: 0.064754; Backpropagation: 0.2912 sec; Batch: 2.1108 sec
0.1407 0.1369 0.0995 0.0908 0.0711 0.0590 0.0530 0.0496 0.0473 0.0447 0.0432 0.0416 0.0407 0.0399 0.0393 0.0390 

[TRAIN] Epoch[1](4727/114412); Loss: 0.085564; Backpropagation: 0.2907 sec; Batch: 2.1478 sec
0.1833 0.1793 0.1374 0.1227 0.0986 0.0870 0.0757 0.0668 0.0598 0.0560 0.0536 0.0519 0.0508 0.0497 0.0487 0.0477 

[TRAIN] Epoch[1](4728/114412); Loss: 0.075620; Backpropagation: 0.2914 sec; Batch: 2.1340 sec
0.1528 0.1536 0.1099 0.0984 0.0826 0.0698 0.0642 0.0602 0.0569 0.0552 0.0537 0.0524 0.0513 0.0503 0.0496 0.0493 

[TRAIN] Epoch[1](4729/114412); Loss: 0.079829; Backpropagation: 0.2912 sec; Batch: 2.0786 sec
0.1623 0.1659 0.1077 0.1010 0.0877 0.0824 0.0749 0.0678 0.0613 0.0565 0.0545 0.0532 0.0520 0.0509 0.0499 0.0493 

[TRAIN] Epoch[1](4730/114412); Loss: 0.110565; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.2169 0.2149 0.1612 0.1489 0.1135 0.1048 0.0954 0.0890 0.0850 0.0818 0.0794 0.0778 0.0765 0.0753 0.0746 0.0740 

[TRAIN] Epoch[1](4731/114412); Loss: 0.100921; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1978 0.1913 0.1610 0.1469 0.1218 0.1033 0.0879 0.0786 0.0732 0.0703 0.0678 0.0656 0.0642 0.0629 0.0617 0.0606 

[TRAIN] Epoch[1](4732/114412); Loss: 0.087310; Backpropagation: 0.2914 sec; Batch: 2.1305 sec
0.1512 0.1481 0.1179 0.1097 0.0990 0.0898 0.0850 0.0764 0.0733 0.0682 0.0658 0.0641 0.0634 0.0624 0.0616 0.0610 

[TRAIN] Epoch[1](4733/114412); Loss: 0.080395; Backpropagation: 0.2911 sec; Batch: 2.0816 sec
0.1611 0.1604 0.1134 0.1011 0.0874 0.0765 0.0692 0.0657 0.0622 0.0593 0.0576 0.0561 0.0552 0.0542 0.0536 0.0533 

[TRAIN] Epoch[1](4734/114412); Loss: 0.093423; Backpropagation: 0.2914 sec; Batch: 2.1253 sec
0.1794 0.1778 0.1175 0.1112 0.0953 0.0894 0.0832 0.0795 0.0751 0.0731 0.0718 0.0700 0.0689 0.0682 0.0673 0.0670 

[TRAIN] Epoch[1](4735/114412); Loss: 0.095360; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1797 0.1770 0.1338 0.1215 0.1001 0.0925 0.0862 0.0812 0.0761 0.0731 0.0708 0.0688 0.0677 0.0666 0.0658 0.0651 

[TRAIN] Epoch[1](4736/114412); Loss: 0.087255; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1614 0.1584 0.1186 0.1078 0.0927 0.0860 0.0796 0.0752 0.0712 0.0685 0.0660 0.0645 0.0629 0.0620 0.0609 0.0602 

[TRAIN] Epoch[1](4737/114412); Loss: 0.074435; Backpropagation: 0.2910 sec; Batch: 2.1192 sec
0.1434 0.1404 0.1024 0.0942 0.0782 0.0718 0.0650 0.0617 0.0596 0.0568 0.0551 0.0540 0.0529 0.0523 0.0518 0.0513 

[TRAIN] Epoch[1](4738/114412); Loss: 0.079412; Backpropagation: 0.2914 sec; Batch: 2.1207 sec
0.1559 0.1535 0.1066 0.0967 0.0833 0.0768 0.0728 0.0673 0.0638 0.0600 0.0579 0.0567 0.0558 0.0550 0.0545 0.0541 

[TRAIN] Epoch[1](4739/114412); Loss: 0.099020; Backpropagation: 0.2908 sec; Batch: 2.1183 sec
0.1708 0.1725 0.1304 0.1246 0.1134 0.1031 0.0976 0.0898 0.0841 0.0785 0.0741 0.0726 0.0701 0.0687 0.0673 0.0667 

[TRAIN] Epoch[1](4740/114412); Loss: 0.097360; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1870 0.1829 0.1346 0.1193 0.1015 0.0922 0.0853 0.0817 0.0782 0.0755 0.0737 0.0718 0.0703 0.0690 0.0678 0.0669 

[TRAIN] Epoch[1](4741/114412); Loss: 0.082384; Backpropagation: 0.2913 sec; Batch: 2.1024 sec
0.1409 0.1364 0.1089 0.0990 0.0850 0.0794 0.0736 0.0707 0.0683 0.0670 0.0662 0.0654 0.0650 0.0644 0.0641 0.0638 

[TRAIN] Epoch[1](4742/114412); Loss: 0.087144; Backpropagation: 0.2906 sec; Batch: 2.1153 sec
0.1642 0.1629 0.1267 0.1155 0.0930 0.0841 0.0793 0.0748 0.0693 0.0662 0.0639 0.0612 0.0600 0.0588 0.0576 0.0568 

[TRAIN] Epoch[1](4743/114412); Loss: 0.089631; Backpropagation: 0.2907 sec; Batch: 2.1653 sec
0.1677 0.1681 0.1299 0.1172 0.0941 0.0850 0.0790 0.0738 0.0707 0.0685 0.0665 0.0652 0.0636 0.0625 0.0615 0.0609 

[TRAIN] Epoch[1](4744/114412); Loss: 0.076591; Backpropagation: 0.2914 sec; Batch: 2.1219 sec
0.1422 0.1419 0.1149 0.1021 0.0878 0.0800 0.0724 0.0669 0.0620 0.0575 0.0549 0.0518 0.0499 0.0485 0.0467 0.0460 

[TRAIN] Epoch[1](4745/114412); Loss: 0.054228; Backpropagation: 0.2910 sec; Batch: 2.1237 sec
0.0959 0.0928 0.0863 0.0826 0.0746 0.0661 0.0565 0.0476 0.0414 0.0374 0.0346 0.0326 0.0308 0.0300 0.0294 0.0289 

[TRAIN] Epoch[1](4746/114412); Loss: 0.091309; Backpropagation: 0.2911 sec; Batch: 2.1150 sec
0.1731 0.1716 0.1391 0.1230 0.0992 0.0864 0.0809 0.0741 0.0702 0.0676 0.0657 0.0640 0.0628 0.0619 0.0611 0.0604 

[TRAIN] Epoch[1](4747/114412); Loss: 0.106927; Backpropagation: 0.2906 sec; Batch: 2.1169 sec
0.1708 0.1695 0.1468 0.1386 0.1249 0.1133 0.1049 0.0957 0.0901 0.0860 0.0828 0.0806 0.0788 0.0768 0.0760 0.0751 

[TRAIN] Epoch[1](4748/114412); Loss: 0.071948; Backpropagation: 0.2906 sec; Batch: 2.1130 sec
0.1420 0.1406 0.1027 0.0906 0.0825 0.0728 0.0646 0.0590 0.0558 0.0532 0.0508 0.0494 0.0482 0.0471 0.0463 0.0456 

[TRAIN] Epoch[1](4749/114412); Loss: 0.069778; Backpropagation: 0.2952 sec; Batch: 2.1219 sec
0.1256 0.1241 0.1025 0.0920 0.0841 0.0762 0.0675 0.0599 0.0543 0.0513 0.0493 0.0477 0.0467 0.0458 0.0451 0.0444 

[TRAIN] Epoch[1](4750/114412); Loss: 0.091030; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1831 0.1775 0.1403 0.1239 0.1009 0.0876 0.0801 0.0736 0.0691 0.0660 0.0633 0.0605 0.0594 0.0581 0.0568 0.0563 

[TRAIN] Epoch[1](4751/114412); Loss: 0.118370; Backpropagation: 0.2907 sec; Batch: 2.0782 sec
0.2072 0.2026 0.1612 0.1442 0.1235 0.1155 0.1075 0.1027 0.0995 0.0958 0.0931 0.0908 0.0894 0.0881 0.0870 0.0861 

[TRAIN] Epoch[1](4752/114412); Loss: 0.084301; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.1629 0.1612 0.1241 0.1108 0.0944 0.0852 0.0788 0.0718 0.0671 0.0621 0.0596 0.0583 0.0551 0.0535 0.0526 0.0514 

[TRAIN] Epoch[1](4753/114412); Loss: 0.104718; Backpropagation: 0.2932 sec; Batch: 2.0796 sec
0.1891 0.1919 0.1473 0.1328 0.1098 0.0996 0.0924 0.0879 0.0841 0.0815 0.0798 0.0778 0.0767 0.0757 0.0748 0.0744 

[TRAIN] Epoch[1](4754/114412); Loss: 0.095368; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1716 0.1695 0.1372 0.1241 0.1047 0.0963 0.0891 0.0821 0.0771 0.0726 0.0706 0.0688 0.0671 0.0660 0.0649 0.0644 

[TRAIN] Epoch[1](4755/114412); Loss: 0.066554; Backpropagation: 0.2914 sec; Batch: 2.1304 sec
0.1214 0.1191 0.0930 0.0785 0.0699 0.0655 0.0619 0.0577 0.0545 0.0523 0.0511 0.0494 0.0488 0.0482 0.0472 0.0464 

[TRAIN] Epoch[1](4756/114412); Loss: 0.111846; Backpropagation: 0.2908 sec; Batch: 2.0970 sec
0.2021 0.2055 0.1531 0.1409 0.1137 0.1041 0.0957 0.0914 0.0892 0.0873 0.0862 0.0853 0.0846 0.0841 0.0834 0.0829 

[TRAIN] Epoch[1](4757/114412); Loss: 0.076827; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.1390 0.1393 0.1084 0.0963 0.0827 0.0736 0.0689 0.0643 0.0619 0.0595 0.0579 0.0566 0.0558 0.0553 0.0549 0.0546 

[TRAIN] Epoch[1](4758/114412); Loss: 0.128315; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1998 0.1990 0.1603 0.1456 0.1309 0.1237 0.1181 0.1151 0.1125 0.1102 0.1086 0.1075 0.1062 0.1056 0.1051 0.1047 

[TRAIN] Epoch[1](4759/114412); Loss: 0.105300; Backpropagation: 0.2908 sec; Batch: 2.0823 sec
0.1753 0.1739 0.1393 0.1279 0.1142 0.1051 0.0972 0.0926 0.0892 0.0862 0.0838 0.0822 0.0808 0.0799 0.0791 0.0782 

[TRAIN] Epoch[1](4760/114412); Loss: 0.090283; Backpropagation: 0.2916 sec; Batch: 2.0772 sec
0.1617 0.1607 0.1327 0.1166 0.1017 0.0915 0.0832 0.0769 0.0727 0.0691 0.0670 0.0647 0.0632 0.0620 0.0608 0.0601 

[TRAIN] Epoch[1](4761/114412); Loss: 0.069309; Backpropagation: 0.2955 sec; Batch: 2.0993 sec
0.1326 0.1301 0.0955 0.0841 0.0707 0.0638 0.0587 0.0557 0.0547 0.0531 0.0526 0.0523 0.0518 0.0514 0.0510 0.0507 

[TRAIN] Epoch[1](4762/114412); Loss: 0.063772; Backpropagation: 0.2912 sec; Batch: 2.1212 sec
0.1205 0.1207 0.0942 0.0820 0.0731 0.0647 0.0576 0.0536 0.0502 0.0485 0.0464 0.0441 0.0428 0.0416 0.0407 0.0396 

[TRAIN] Epoch[1](4763/114412); Loss: 0.089352; Backpropagation: 0.2916 sec; Batch: 2.1176 sec
0.1882 0.1881 0.1377 0.1225 0.0899 0.0794 0.0762 0.0701 0.0662 0.0634 0.0610 0.0592 0.0582 0.0573 0.0564 0.0560 

[TRAIN] Epoch[1](4764/114412); Loss: 0.100291; Backpropagation: 0.2920 sec; Batch: 2.1343 sec
0.1652 0.1647 0.1390 0.1257 0.1116 0.1010 0.0935 0.0875 0.0833 0.0804 0.0781 0.0767 0.0756 0.0748 0.0741 0.0736 

[TRAIN] Epoch[1](4765/114412); Loss: 0.072840; Backpropagation: 0.2932 sec; Batch: 2.1192 sec
0.1487 0.1494 0.1125 0.0971 0.0778 0.0695 0.0649 0.0588 0.0556 0.0518 0.0491 0.0478 0.0468 0.0459 0.0451 0.0446 

[TRAIN] Epoch[1](4766/114412); Loss: 0.090757; Backpropagation: 0.2927 sec; Batch: 2.1164 sec
0.1753 0.1720 0.1320 0.1157 0.0987 0.0887 0.0805 0.0746 0.0706 0.0676 0.0652 0.0636 0.0628 0.0620 0.0616 0.0612 

[TRAIN] Epoch[1](4767/114412); Loss: 0.088444; Backpropagation: 0.2911 sec; Batch: 2.1187 sec
0.2010 0.1984 0.1455 0.1267 0.0897 0.0772 0.0709 0.0631 0.0605 0.0579 0.0565 0.0551 0.0541 0.0534 0.0528 0.0523 

[TRAIN] Epoch[1](4768/114412); Loss: 0.067005; Backpropagation: 0.2914 sec; Batch: 2.1178 sec
0.1263 0.1215 0.0927 0.0809 0.0703 0.0651 0.0613 0.0576 0.0532 0.0513 0.0507 0.0497 0.0487 0.0482 0.0476 0.0472 

[TRAIN] Epoch[1](4769/114412); Loss: 0.071007; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1487 0.1479 0.1114 0.0982 0.0790 0.0682 0.0620 0.0556 0.0511 0.0491 0.0468 0.0458 0.0444 0.0433 0.0426 0.0422 

[TRAIN] Epoch[1](4770/114412); Loss: 0.086961; Backpropagation: 0.2911 sec; Batch: 2.1137 sec
0.1751 0.1710 0.1319 0.1138 0.0899 0.0794 0.0758 0.0708 0.0667 0.0642 0.0621 0.0601 0.0589 0.0579 0.0571 0.0566 

[TRAIN] Epoch[1](4771/114412); Loss: 0.073192; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1268 0.1252 0.1066 0.0941 0.0835 0.0754 0.0691 0.0641 0.0602 0.0565 0.0544 0.0530 0.0518 0.0509 0.0501 0.0495 

[TRAIN] Epoch[1](4772/114412); Loss: 0.103494; Backpropagation: 0.2906 sec; Batch: 2.0778 sec
0.1934 0.1922 0.1572 0.1404 0.1182 0.1038 0.0919 0.0862 0.0805 0.0772 0.0746 0.0714 0.0692 0.0679 0.0666 0.0652 

[TRAIN] Epoch[1](4773/114412); Loss: 0.098317; Backpropagation: 0.2912 sec; Batch: 2.1257 sec
0.1608 0.1587 0.1293 0.1174 0.1057 0.0988 0.0929 0.0891 0.0855 0.0817 0.0790 0.0773 0.0754 0.0746 0.0738 0.0731 

[TRAIN] Epoch[1](4774/114412); Loss: 0.085569; Backpropagation: 0.2912 sec; Batch: 2.1163 sec
0.1757 0.1754 0.1384 0.1216 0.1003 0.0858 0.0755 0.0671 0.0618 0.0585 0.0549 0.0532 0.0517 0.0504 0.0498 0.0491 

[TRAIN] Epoch[1](4775/114412); Loss: 0.087880; Backpropagation: 0.2927 sec; Batch: 2.1153 sec
0.1505 0.1506 0.1222 0.1102 0.0985 0.0901 0.0825 0.0774 0.0744 0.0712 0.0678 0.0648 0.0633 0.0621 0.0606 0.0597 

[TRAIN] Epoch[1](4776/114412); Loss: 0.104468; Backpropagation: 0.2950 sec; Batch: 2.1122 sec
0.1734 0.1720 0.1447 0.1310 0.1160 0.1062 0.0990 0.0933 0.0884 0.0848 0.0815 0.0792 0.0774 0.0759 0.0748 0.0740 

[TRAIN] Epoch[1](4777/114412); Loss: 0.094846; Backpropagation: 0.2918 sec; Batch: 2.1294 sec
0.1818 0.1802 0.1453 0.1287 0.1082 0.0929 0.0820 0.0769 0.0727 0.0697 0.0666 0.0646 0.0632 0.0620 0.0615 0.0611 

[TRAIN] Epoch[1](4778/114412); Loss: 0.072119; Backpropagation: 0.2913 sec; Batch: 2.1192 sec
0.1268 0.1250 0.0917 0.0834 0.0731 0.0677 0.0646 0.0629 0.0614 0.0600 0.0585 0.0576 0.0564 0.0557 0.0548 0.0542 

[TRAIN] Epoch[1](4779/114412); Loss: 0.107690; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.1710 0.1693 0.1419 0.1315 0.1177 0.1095 0.1040 0.1005 0.0966 0.0920 0.0880 0.0845 0.0823 0.0800 0.0778 0.0765 

[TRAIN] Epoch[1](4780/114412); Loss: 0.091265; Backpropagation: 0.2904 sec; Batch: 2.1204 sec
0.1647 0.1633 0.1325 0.1204 0.1038 0.0946 0.0859 0.0781 0.0724 0.0689 0.0658 0.0642 0.0627 0.0616 0.0610 0.0604 

[TRAIN] Epoch[1](4781/114412); Loss: 0.098214; Backpropagation: 0.2911 sec; Batch: 2.1147 sec
0.1561 0.1539 0.1274 0.1175 0.1043 0.0980 0.0921 0.0881 0.0851 0.0823 0.0804 0.0790 0.0780 0.0772 0.0763 0.0757 

[TRAIN] Epoch[1](4782/114412); Loss: 0.094375; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1674 0.1669 0.1358 0.1206 0.1036 0.0925 0.0847 0.0805 0.0762 0.0732 0.0712 0.0695 0.0682 0.0672 0.0665 0.0661 

[TRAIN] Epoch[1](4783/114412); Loss: 0.070151; Backpropagation: 0.2916 sec; Batch: 2.1220 sec
0.1519 0.1444 0.1138 0.0932 0.0833 0.0712 0.0642 0.0582 0.0518 0.0480 0.0456 0.0423 0.0407 0.0392 0.0375 0.0369 

[TRAIN] Epoch[1](4784/114412); Loss: 0.082411; Backpropagation: 0.2913 sec; Batch: 2.1205 sec
0.1624 0.1556 0.1237 0.1022 0.0900 0.0794 0.0749 0.0702 0.0656 0.0629 0.0593 0.0569 0.0554 0.0543 0.0533 0.0524 

[TRAIN] Epoch[1](4785/114412); Loss: 0.102610; Backpropagation: 0.2936 sec; Batch: 2.1190 sec
0.1662 0.1649 0.1329 0.1223 0.1096 0.1025 0.0973 0.0935 0.0896 0.0865 0.0839 0.0811 0.0797 0.0784 0.0773 0.0762 

[TRAIN] Epoch[1](4786/114412); Loss: 0.081446; Backpropagation: 0.2931 sec; Batch: 2.1172 sec
0.1464 0.1447 0.1168 0.1021 0.0875 0.0798 0.0740 0.0699 0.0671 0.0644 0.0620 0.0600 0.0589 0.0576 0.0564 0.0556 

[TRAIN] Epoch[1](4787/114412); Loss: 0.072986; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.1269 0.1231 0.0984 0.0877 0.0779 0.0712 0.0674 0.0643 0.0613 0.0590 0.0577 0.0564 0.0549 0.0544 0.0539 0.0533 

[TRAIN] Epoch[1](4788/114412); Loss: 0.078436; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1510 0.1401 0.1162 0.1013 0.0861 0.0761 0.0684 0.0645 0.0615 0.0594 0.0576 0.0562 0.0552 0.0543 0.0537 0.0533 

[TRAIN] Epoch[1](4789/114412); Loss: 0.095578; Backpropagation: 0.2915 sec; Batch: 2.1206 sec
0.1994 0.1884 0.1522 0.1285 0.1077 0.0943 0.0842 0.0756 0.0703 0.0666 0.0640 0.0621 0.0606 0.0596 0.0585 0.0576 

[TRAIN] Epoch[1](4790/114412); Loss: 0.073410; Backpropagation: 0.2928 sec; Batch: 2.1222 sec
0.1575 0.1552 0.1178 0.0999 0.0818 0.0680 0.0604 0.0561 0.0528 0.0501 0.0483 0.0470 0.0462 0.0453 0.0444 0.0438 

[TRAIN] Epoch[1](4791/114412); Loss: 0.093423; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1658 0.1630 0.1404 0.1203 0.1052 0.0967 0.0875 0.0818 0.0756 0.0722 0.0692 0.0665 0.0649 0.0633 0.0615 0.0608 

[TRAIN] Epoch[1](4792/114412); Loss: 0.080650; Backpropagation: 0.2910 sec; Batch: 2.0863 sec
0.1485 0.1500 0.1133 0.1028 0.0891 0.0800 0.0759 0.0700 0.0657 0.0601 0.0587 0.0572 0.0561 0.0552 0.0541 0.0536 

[TRAIN] Epoch[1](4793/114412); Loss: 0.054862; Backpropagation: 0.2913 sec; Batch: 2.0941 sec
0.1115 0.1082 0.0840 0.0669 0.0600 0.0534 0.0502 0.0456 0.0424 0.0402 0.0377 0.0366 0.0359 0.0353 0.0350 0.0350 

[TRAIN] Epoch[1](4794/114412); Loss: 0.101025; Backpropagation: 0.2914 sec; Batch: 2.2189 sec
0.2013 0.1966 0.1534 0.1370 0.1128 0.0965 0.0890 0.0815 0.0761 0.0721 0.0694 0.0685 0.0671 0.0659 0.0649 0.0642 

[TRAIN] Epoch[1](4795/114412); Loss: 0.070787; Backpropagation: 0.2932 sec; Batch: 2.2216 sec
0.1183 0.1142 0.0923 0.0813 0.0732 0.0698 0.0656 0.0627 0.0601 0.0589 0.0579 0.0566 0.0561 0.0556 0.0551 0.0548 

[TRAIN] Epoch[1](4796/114412); Loss: 0.082476; Backpropagation: 0.2914 sec; Batch: 2.1064 sec
0.1527 0.1489 0.1111 0.1033 0.0930 0.0880 0.0797 0.0745 0.0689 0.0636 0.0604 0.0574 0.0563 0.0548 0.0541 0.0530 

[TRAIN] Epoch[1](4797/114412); Loss: 0.071153; Backpropagation: 0.2910 sec; Batch: 2.3191 sec
0.1459 0.1401 0.1029 0.0855 0.0733 0.0657 0.0609 0.0574 0.0551 0.0530 0.0521 0.0507 0.0499 0.0492 0.0486 0.0480 

[TRAIN] Epoch[1](4798/114412); Loss: 0.061939; Backpropagation: 0.2930 sec; Batch: 2.0894 sec
0.1153 0.1120 0.0856 0.0758 0.0654 0.0594 0.0560 0.0519 0.0496 0.0483 0.0469 0.0461 0.0454 0.0449 0.0444 0.0440 

[TRAIN] Epoch[1](4799/114412); Loss: 0.073363; Backpropagation: 0.2933 sec; Batch: 2.1181 sec
0.1564 0.1553 0.1151 0.1006 0.0808 0.0691 0.0603 0.0559 0.0535 0.0502 0.0484 0.0473 0.0462 0.0453 0.0448 0.0444 

[TRAIN] Epoch[1](4800/114412); Loss: 0.109457; Backpropagation: 0.2912 sec; Batch: 2.1258 sec
0.1946 0.1926 0.1499 0.1384 0.1183 0.1060 0.0985 0.0941 0.0895 0.0860 0.0832 0.0816 0.0808 0.0801 0.0793 0.0786 

[TRAIN] Epoch[1](4801/114412); Loss: 0.086200; Backpropagation: 0.2911 sec; Batch: 2.0896 sec
0.1567 0.1545 0.1208 0.1079 0.0938 0.0861 0.0795 0.0738 0.0698 0.0663 0.0648 0.0631 0.0617 0.0608 0.0602 0.0595 

[TRAIN] Epoch[1](4802/114412); Loss: 0.115399; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1694 0.1671 0.1418 0.1316 0.1204 0.1129 0.1078 0.1053 0.1029 0.1012 0.0995 0.0986 0.0977 0.0970 0.0969 0.0962 

[TRAIN] Epoch[1](4803/114412); Loss: 0.097713; Backpropagation: 0.2912 sec; Batch: 2.1205 sec
0.1863 0.1848 0.1425 0.1273 0.1088 0.0991 0.0903 0.0842 0.0778 0.0741 0.0698 0.0664 0.0645 0.0636 0.0624 0.0616 

[TRAIN] Epoch[1](4804/114412); Loss: 0.098282; Backpropagation: 0.2913 sec; Batch: 2.1335 sec
0.1630 0.1588 0.1286 0.1133 0.1022 0.0976 0.0910 0.0858 0.0828 0.0816 0.0804 0.0792 0.0783 0.0774 0.0766 0.0760 

[TRAIN] Epoch[1](4805/114412); Loss: 0.101082; Backpropagation: 0.2906 sec; Batch: 2.0772 sec
0.1766 0.1717 0.1394 0.1252 0.1090 0.0999 0.0905 0.0860 0.0821 0.0800 0.0787 0.0772 0.0760 0.0753 0.0749 0.0749 

[TRAIN] Epoch[1](4806/114412); Loss: 0.085220; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1454 0.1418 0.1128 0.1026 0.0896 0.0843 0.0788 0.0743 0.0713 0.0690 0.0678 0.0666 0.0658 0.0651 0.0645 0.0638 

[TRAIN] Epoch[1](4807/114412); Loss: 0.087523; Backpropagation: 0.2928 sec; Batch: 2.1196 sec
0.1601 0.1588 0.1232 0.1074 0.0915 0.0839 0.0775 0.0753 0.0720 0.0677 0.0663 0.0649 0.0637 0.0632 0.0627 0.0623 

[TRAIN] Epoch[1](4808/114412); Loss: 0.069586; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.1352 0.1323 0.1024 0.0862 0.0723 0.0643 0.0603 0.0567 0.0545 0.0533 0.0522 0.0512 0.0492 0.0485 0.0479 0.0470 

[TRAIN] Epoch[1](4809/114412); Loss: 0.066763; Backpropagation: 0.2913 sec; Batch: 2.1196 sec
0.1686 0.1652 0.1115 0.0974 0.0644 0.0562 0.0533 0.0471 0.0426 0.0397 0.0390 0.0379 0.0370 0.0365 0.0360 0.0357 

[TRAIN] Epoch[1](4810/114412); Loss: 0.081884; Backpropagation: 0.2910 sec; Batch: 2.1340 sec
0.1456 0.1439 0.1140 0.1054 0.0936 0.0860 0.0760 0.0698 0.0661 0.0632 0.0610 0.0592 0.0580 0.0569 0.0560 0.0555 

[TRAIN] Epoch[1](4811/114412); Loss: 0.098087; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1516 0.1508 0.1231 0.1144 0.1045 0.0968 0.0911 0.0886 0.0860 0.0836 0.0818 0.0808 0.0799 0.0793 0.0788 0.0784 

[TRAIN] Epoch[1](4812/114412); Loss: 0.098911; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1789 0.1758 0.1380 0.1250 0.1070 0.0980 0.0902 0.0845 0.0802 0.0769 0.0747 0.0730 0.0720 0.0704 0.0695 0.0688 

[TRAIN] Epoch[1](4813/114412); Loss: 0.085694; Backpropagation: 0.2915 sec; Batch: 2.1031 sec
0.1762 0.1749 0.1258 0.1079 0.0826 0.0725 0.0724 0.0674 0.0649 0.0636 0.0623 0.0613 0.0607 0.0600 0.0596 0.0591 

[TRAIN] Epoch[1](4814/114412); Loss: 0.101439; Backpropagation: 0.2917 sec; Batch: 2.1207 sec
0.1735 0.1675 0.1344 0.1201 0.1081 0.1004 0.0952 0.0902 0.0869 0.0845 0.0810 0.0789 0.0777 0.0759 0.0747 0.0739 

[TRAIN] Epoch[1](4815/114412); Loss: 0.080937; Backpropagation: 0.2956 sec; Batch: 2.0821 sec
0.1322 0.1289 0.1072 0.0976 0.0865 0.0798 0.0750 0.0714 0.0688 0.0668 0.0654 0.0644 0.0637 0.0629 0.0624 0.0621 

[TRAIN] Epoch[1](4816/114412); Loss: 0.081097; Backpropagation: 0.2931 sec; Batch: 2.1218 sec
0.1318 0.1319 0.1048 0.0969 0.0860 0.0797 0.0741 0.0716 0.0697 0.0675 0.0660 0.0647 0.0638 0.0634 0.0630 0.0627 

[TRAIN] Epoch[1](4817/114412); Loss: 0.094164; Backpropagation: 0.2924 sec; Batch: 2.0793 sec
0.1907 0.1861 0.1382 0.1190 0.0960 0.0866 0.0793 0.0748 0.0719 0.0698 0.0678 0.0667 0.0662 0.0652 0.0644 0.0638 

[TRAIN] Epoch[1](4818/114412); Loss: 0.073539; Backpropagation: 0.2916 sec; Batch: 2.1204 sec
0.1633 0.1627 0.1051 0.0875 0.0664 0.0617 0.0586 0.0562 0.0549 0.0546 0.0530 0.0515 0.0508 0.0506 0.0501 0.0497 

[TRAIN] Epoch[1](4819/114412); Loss: 0.081710; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1409 0.1371 0.1049 0.0932 0.0851 0.0786 0.0732 0.0711 0.0692 0.0675 0.0664 0.0651 0.0643 0.0639 0.0636 0.0632 

[TRAIN] Epoch[1](4820/114412); Loss: 0.067536; Backpropagation: 0.2912 sec; Batch: 2.1199 sec
0.1351 0.1336 0.1042 0.0934 0.0776 0.0665 0.0597 0.0511 0.0490 0.0468 0.0456 0.0448 0.0438 0.0435 0.0432 0.0428 

[TRAIN] Epoch[1](4821/114412); Loss: 0.062848; Backpropagation: 0.2912 sec; Batch: 2.1153 sec
0.1219 0.1151 0.0883 0.0797 0.0698 0.0626 0.0572 0.0533 0.0504 0.0478 0.0459 0.0444 0.0434 0.0425 0.0419 0.0414 

[TRAIN] Epoch[1](4822/114412); Loss: 0.118165; Backpropagation: 0.2910 sec; Batch: 2.1204 sec
0.1822 0.1818 0.1569 0.1417 0.1290 0.1191 0.1110 0.1060 0.1032 0.1011 0.0977 0.0967 0.0941 0.0915 0.0900 0.0887 

[TRAIN] Epoch[1](4823/114412); Loss: 0.089432; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1762 0.1743 0.1309 0.1114 0.0947 0.0860 0.0775 0.0727 0.0696 0.0666 0.0647 0.0629 0.0620 0.0611 0.0604 0.0599 

[TRAIN] Epoch[1](4824/114412); Loss: 0.082243; Backpropagation: 0.2906 sec; Batch: 2.0773 sec
0.1651 0.1609 0.1108 0.0959 0.0799 0.0747 0.0704 0.0678 0.0654 0.0645 0.0628 0.0614 0.0601 0.0592 0.0587 0.0584 

[TRAIN] Epoch[1](4825/114412); Loss: 0.080863; Backpropagation: 0.2910 sec; Batch: 2.1163 sec
0.1637 0.1615 0.1220 0.1060 0.0867 0.0761 0.0694 0.0638 0.0598 0.0569 0.0572 0.0564 0.0545 0.0535 0.0535 0.0528 

[TRAIN] Epoch[1](4826/114412); Loss: 0.100330; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.2012 0.1982 0.1477 0.1296 0.1021 0.0917 0.0856 0.0797 0.0759 0.0741 0.0725 0.0713 0.0699 0.0692 0.0687 0.0679 

[TRAIN] Epoch[1](4827/114412); Loss: 0.097706; Backpropagation: 0.2911 sec; Batch: 2.0774 sec
0.1740 0.1701 0.1445 0.1319 0.1157 0.1024 0.0903 0.0806 0.0760 0.0738 0.0709 0.0697 0.0676 0.0664 0.0652 0.0641 

[TRAIN] Epoch[1](4828/114412); Loss: 0.093932; Backpropagation: 0.2906 sec; Batch: 2.1175 sec
0.1884 0.1757 0.1417 0.1194 0.1019 0.0879 0.0785 0.0755 0.0737 0.0709 0.0685 0.0665 0.0651 0.0639 0.0631 0.0623 

[TRAIN] Epoch[1](4829/114412); Loss: 0.096537; Backpropagation: 0.2911 sec; Batch: 2.1136 sec
0.1685 0.1617 0.1236 0.1117 0.0963 0.0885 0.0865 0.0828 0.0813 0.0802 0.0788 0.0781 0.0775 0.0769 0.0763 0.0759 

[TRAIN] Epoch[1](4830/114412); Loss: 0.074102; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1726 0.1665 0.1134 0.0923 0.0724 0.0652 0.0595 0.0532 0.0501 0.0500 0.0512 0.0498 0.0483 0.0475 0.0472 0.0463 

[TRAIN] Epoch[1](4831/114412); Loss: 0.096239; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1555 0.1516 0.1206 0.1101 0.0968 0.0920 0.0876 0.0851 0.0835 0.0823 0.0811 0.0802 0.0793 0.0787 0.0780 0.0775 

[TRAIN] Epoch[1](4832/114412); Loss: 0.087443; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1409 0.1364 0.1169 0.1047 0.0961 0.0893 0.0838 0.0788 0.0748 0.0725 0.0704 0.0688 0.0674 0.0666 0.0659 0.0657 

[TRAIN] Epoch[1](4833/114412); Loss: 0.077067; Backpropagation: 0.2912 sec; Batch: 2.0786 sec
0.1586 0.1483 0.1183 0.0996 0.0846 0.0746 0.0691 0.0615 0.0577 0.0560 0.0540 0.0521 0.0510 0.0500 0.0491 0.0486 

[TRAIN] Epoch[1](4834/114412); Loss: 0.076285; Backpropagation: 0.2913 sec; Batch: 2.1159 sec
0.1555 0.1455 0.1113 0.0876 0.0761 0.0704 0.0652 0.0629 0.0606 0.0585 0.0569 0.0557 0.0546 0.0539 0.0532 0.0526 

[TRAIN] Epoch[1](4835/114412); Loss: 0.085252; Backpropagation: 0.2953 sec; Batch: 2.1223 sec
0.1353 0.1338 0.1113 0.1034 0.0891 0.0820 0.0790 0.0749 0.0726 0.0719 0.0708 0.0694 0.0685 0.0680 0.0673 0.0668 

[TRAIN] Epoch[1](4836/114412); Loss: 0.084461; Backpropagation: 0.2916 sec; Batch: 2.1135 sec
0.1699 0.1609 0.1225 0.1064 0.0902 0.0806 0.0732 0.0677 0.0649 0.0628 0.0611 0.0600 0.0590 0.0581 0.0573 0.0569 

[TRAIN] Epoch[1](4837/114412); Loss: 0.073702; Backpropagation: 0.2927 sec; Batch: 2.1178 sec
0.1529 0.1449 0.1022 0.0852 0.0747 0.0682 0.0623 0.0594 0.0575 0.0558 0.0547 0.0538 0.0529 0.0521 0.0514 0.0512 

[TRAIN] Epoch[1](4838/114412); Loss: 0.068204; Backpropagation: 0.2912 sec; Batch: 2.1200 sec
0.1821 0.1766 0.1191 0.0967 0.0707 0.0558 0.0490 0.0429 0.0405 0.0382 0.0383 0.0377 0.0367 0.0361 0.0358 0.0351 

[TRAIN] Epoch[1](4839/114412); Loss: 0.088399; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.2041 0.2003 0.1576 0.1388 0.1107 0.0914 0.0724 0.0629 0.0579 0.0526 0.0494 0.0457 0.0438 0.0430 0.0422 0.0415 

[TRAIN] Epoch[1](4840/114412); Loss: 0.077870; Backpropagation: 0.2930 sec; Batch: 2.0804 sec
0.1388 0.1345 0.1027 0.0915 0.0783 0.0746 0.0697 0.0664 0.0650 0.0633 0.0623 0.0614 0.0604 0.0597 0.0589 0.0584 

[TRAIN] Epoch[1](4841/114412); Loss: 0.083168; Backpropagation: 0.2915 sec; Batch: 2.1139 sec
0.1482 0.1394 0.1114 0.0983 0.0880 0.0802 0.0748 0.0724 0.0697 0.0676 0.0658 0.0646 0.0637 0.0629 0.0622 0.0614 

[TRAIN] Epoch[1](4842/114412); Loss: 0.097778; Backpropagation: 0.2932 sec; Batch: 2.1197 sec
0.1838 0.1822 0.1421 0.1211 0.1017 0.0933 0.0861 0.0819 0.0781 0.0754 0.0733 0.0717 0.0697 0.0687 0.0679 0.0673 

[TRAIN] Epoch[1](4843/114412); Loss: 0.102812; Backpropagation: 0.2914 sec; Batch: 2.1159 sec
0.1639 0.1591 0.1312 0.1186 0.1069 0.1016 0.0967 0.0917 0.0891 0.0872 0.0857 0.0844 0.0835 0.0826 0.0817 0.0811 

[TRAIN] Epoch[1](4844/114412); Loss: 0.062818; Backpropagation: 0.2912 sec; Batch: 2.1161 sec
0.1234 0.1187 0.0890 0.0752 0.0672 0.0600 0.0554 0.0519 0.0491 0.0474 0.0463 0.0454 0.0448 0.0441 0.0437 0.0435 

[TRAIN] Epoch[1](4845/114412); Loss: 0.056344; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.1070 0.1041 0.0740 0.0628 0.0565 0.0526 0.0496 0.0474 0.0458 0.0447 0.0442 0.0433 0.0428 0.0426 0.0423 0.0419 

[TRAIN] Epoch[1](4846/114412); Loss: 0.078831; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1465 0.1414 0.1063 0.0908 0.0814 0.0747 0.0702 0.0667 0.0649 0.0635 0.0624 0.0609 0.0592 0.0584 0.0573 0.0568 

[TRAIN] Epoch[1](4847/114412); Loss: 0.102854; Backpropagation: 0.2911 sec; Batch: 2.1363 sec
0.1531 0.1485 0.1284 0.1140 0.1077 0.1032 0.0987 0.0955 0.0922 0.0903 0.0881 0.0866 0.0857 0.0854 0.0846 0.0839 

[TRAIN] Epoch[1](4848/114412); Loss: 0.072162; Backpropagation: 0.2910 sec; Batch: 2.1182 sec
0.1326 0.1284 0.1019 0.0901 0.0775 0.0723 0.0663 0.0619 0.0587 0.0563 0.0539 0.0525 0.0516 0.0507 0.0500 0.0497 

[TRAIN] Epoch[1](4849/114412); Loss: 0.064870; Backpropagation: 0.2930 sec; Batch: 2.1197 sec
0.1200 0.1128 0.0867 0.0750 0.0654 0.0614 0.0570 0.0554 0.0543 0.0538 0.0512 0.0493 0.0494 0.0491 0.0487 0.0485 

[TRAIN] Epoch[1](4850/114412); Loss: 0.114104; Backpropagation: 0.2937 sec; Batch: 2.1194 sec
0.1723 0.1656 0.1414 0.1291 0.1185 0.1119 0.1085 0.1042 0.1021 0.1003 0.0979 0.0966 0.0956 0.0944 0.0938 0.0933 

[TRAIN] Epoch[1](4851/114412); Loss: 0.071084; Backpropagation: 0.2951 sec; Batch: 2.1383 sec
0.1150 0.1093 0.0906 0.0815 0.0745 0.0700 0.0662 0.0633 0.0614 0.0599 0.0590 0.0583 0.0578 0.0573 0.0568 0.0565 

[TRAIN] Epoch[1](4852/114412); Loss: 0.075542; Backpropagation: 0.2929 sec; Batch: 2.1215 sec
0.2004 0.1897 0.1417 0.1117 0.0829 0.0621 0.0497 0.0498 0.0442 0.0417 0.0415 0.0406 0.0392 0.0384 0.0378 0.0372 

[TRAIN] Epoch[1](4853/114412); Loss: 0.085829; Backpropagation: 0.2913 sec; Batch: 2.1203 sec
0.1598 0.1531 0.1235 0.1081 0.0914 0.0828 0.0781 0.0717 0.0692 0.0675 0.0646 0.0640 0.0619 0.0601 0.0592 0.0584 

[TRAIN] Epoch[1](4854/114412); Loss: 0.126206; Backpropagation: 0.2914 sec; Batch: 2.1216 sec
0.1983 0.1907 0.1652 0.1536 0.1407 0.1303 0.1226 0.1153 0.1100 0.1051 0.1019 0.0995 0.0980 0.0968 0.0959 0.0953 

[TRAIN] Epoch[1](4855/114412); Loss: 0.069379; Backpropagation: 0.2913 sec; Batch: 2.1754 sec
0.1408 0.1328 0.1028 0.0827 0.0695 0.0609 0.0571 0.0546 0.0533 0.0524 0.0520 0.0512 0.0504 0.0502 0.0499 0.0495 

[TRAIN] Epoch[1](4856/114412); Loss: 0.047061; Backpropagation: 0.2913 sec; Batch: 2.1559 sec
0.1065 0.1003 0.0760 0.0605 0.0506 0.0411 0.0368 0.0347 0.0334 0.0323 0.0313 0.0307 0.0302 0.0298 0.0295 0.0293 

[TRAIN] Epoch[1](4857/114412); Loss: 0.082088; Backpropagation: 0.2915 sec; Batch: 2.1180 sec
0.1247 0.1191 0.1055 0.0978 0.0891 0.0818 0.0772 0.0747 0.0724 0.0706 0.0692 0.0680 0.0668 0.0662 0.0654 0.0649 

[TRAIN] Epoch[1](4858/114412); Loss: 0.092124; Backpropagation: 0.2920 sec; Batch: 2.1184 sec
0.1801 0.1738 0.1393 0.1181 0.0984 0.0880 0.0821 0.0766 0.0715 0.0689 0.0668 0.0642 0.0630 0.0617 0.0610 0.0605 

[TRAIN] Epoch[1](4859/114412); Loss: 0.076079; Backpropagation: 0.2914 sec; Batch: 2.1230 sec
0.1151 0.1140 0.0987 0.0895 0.0820 0.0765 0.0721 0.0685 0.0658 0.0640 0.0629 0.0623 0.0616 0.0615 0.0615 0.0614 

[TRAIN] Epoch[1](4860/114412); Loss: 0.087922; Backpropagation: 0.2914 sec; Batch: 2.1096 sec
0.1379 0.1335 0.1154 0.1065 0.1011 0.0923 0.0861 0.0797 0.0769 0.0741 0.0708 0.0690 0.0673 0.0663 0.0652 0.0645 

[TRAIN] Epoch[1](4861/114412); Loss: 0.061311; Backpropagation: 0.2907 sec; Batch: 2.1144 sec
0.1209 0.1087 0.0833 0.0716 0.0615 0.0577 0.0544 0.0516 0.0498 0.0486 0.0472 0.0464 0.0455 0.0448 0.0446 0.0443 

[TRAIN] Epoch[1](4862/114412); Loss: 0.093793; Backpropagation: 0.2915 sec; Batch: 2.1099 sec
0.1567 0.1481 0.1253 0.1113 0.0993 0.0930 0.0883 0.0838 0.0801 0.0777 0.0759 0.0742 0.0731 0.0721 0.0711 0.0707 

[TRAIN] Epoch[1](4863/114412); Loss: 0.087907; Backpropagation: 0.2909 sec; Batch: 2.0916 sec
0.1507 0.1439 0.1206 0.1038 0.0948 0.0878 0.0818 0.0769 0.0739 0.0713 0.0692 0.0683 0.0671 0.0661 0.0654 0.0649 

[TRAIN] Epoch[1](4864/114412); Loss: 0.092535; Backpropagation: 0.2929 sec; Batch: 2.0909 sec
0.1591 0.1531 0.1266 0.1128 0.0974 0.0874 0.0830 0.0795 0.0777 0.0747 0.0733 0.0724 0.0717 0.0713 0.0706 0.0702 

[TRAIN] Epoch[1](4865/114412); Loss: 0.083162; Backpropagation: 0.2932 sec; Batch: 2.1244 sec
0.1401 0.1372 0.1081 0.0971 0.0879 0.0820 0.0792 0.0744 0.0712 0.0685 0.0669 0.0653 0.0644 0.0635 0.0628 0.0622 

[TRAIN] Epoch[1](4866/114412); Loss: 0.064209; Backpropagation: 0.2931 sec; Batch: 2.0810 sec
0.1366 0.1313 0.0928 0.0788 0.0696 0.0613 0.0572 0.0511 0.0483 0.0467 0.0442 0.0433 0.0426 0.0419 0.0412 0.0407 

[TRAIN] Epoch[1](4867/114412); Loss: 0.084957; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1598 0.1539 0.1176 0.1004 0.0843 0.0777 0.0743 0.0713 0.0682 0.0668 0.0656 0.0645 0.0642 0.0637 0.0636 0.0634 

[TRAIN] Epoch[1](4868/114412); Loss: 0.084777; Backpropagation: 0.2909 sec; Batch: 2.1608 sec
0.1421 0.1345 0.1128 0.1000 0.0902 0.0832 0.0781 0.0754 0.0731 0.0701 0.0683 0.0670 0.0663 0.0656 0.0649 0.0647 

[TRAIN] Epoch[1](4869/114412); Loss: 0.085309; Backpropagation: 0.2907 sec; Batch: 2.0976 sec
0.1299 0.1244 0.1040 0.0928 0.0898 0.0852 0.0809 0.0780 0.0760 0.0747 0.0733 0.0725 0.0719 0.0710 0.0704 0.0701 

[TRAIN] Epoch[1](4870/114412); Loss: 0.104426; Backpropagation: 0.2911 sec; Batch: 2.1212 sec
0.1758 0.1708 0.1381 0.1249 0.1110 0.1011 0.0943 0.0909 0.0884 0.0864 0.0842 0.0826 0.0819 0.0807 0.0800 0.0796 

[TRAIN] Epoch[1](4871/114412); Loss: 0.082137; Backpropagation: 0.2912 sec; Batch: 2.0967 sec
0.1358 0.1304 0.1040 0.0953 0.0868 0.0809 0.0758 0.0728 0.0706 0.0687 0.0673 0.0664 0.0656 0.0650 0.0647 0.0640 

[TRAIN] Epoch[1](4872/114412); Loss: 0.105486; Backpropagation: 0.2903 sec; Batch: 2.0769 sec
0.1657 0.1621 0.1289 0.1166 0.1074 0.1021 0.0982 0.0958 0.0937 0.0921 0.0905 0.0889 0.0878 0.0868 0.0860 0.0851 

[TRAIN] Epoch[1](4873/114412); Loss: 0.070548; Backpropagation: 0.2907 sec; Batch: 2.1179 sec
0.1259 0.1149 0.0958 0.0870 0.0784 0.0708 0.0628 0.0596 0.0573 0.0556 0.0546 0.0541 0.0536 0.0531 0.0526 0.0526 

[TRAIN] Epoch[1](4874/114412); Loss: 0.070833; Backpropagation: 0.2912 sec; Batch: 2.0776 sec
0.1442 0.1377 0.1015 0.0781 0.0699 0.0650 0.0615 0.0584 0.0562 0.0547 0.0529 0.0521 0.0511 0.0503 0.0500 0.0498 

[TRAIN] Epoch[1](4875/114412); Loss: 0.090763; Backpropagation: 0.2912 sec; Batch: 2.1189 sec
0.1559 0.1488 0.1226 0.1142 0.1029 0.0942 0.0862 0.0811 0.0776 0.0748 0.0712 0.0681 0.0662 0.0642 0.0626 0.0618 

[TRAIN] Epoch[1](4876/114412); Loss: 0.078463; Backpropagation: 0.2914 sec; Batch: 2.1172 sec
0.1536 0.1428 0.1080 0.0892 0.0823 0.0770 0.0748 0.0708 0.0633 0.0607 0.0583 0.0572 0.0563 0.0546 0.0536 0.0530 

[TRAIN] Epoch[1](4877/114412); Loss: 0.080288; Backpropagation: 0.2912 sec; Batch: 2.1223 sec
0.1312 0.1290 0.1103 0.1010 0.0888 0.0824 0.0775 0.0722 0.0684 0.0656 0.0632 0.0624 0.0614 0.0580 0.0572 0.0561 

[TRAIN] Epoch[1](4878/114412); Loss: 0.070417; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.1202 0.1185 0.0941 0.0841 0.0725 0.0672 0.0650 0.0619 0.0594 0.0571 0.0558 0.0553 0.0548 0.0541 0.0535 0.0531 

[TRAIN] Epoch[1](4879/114412); Loss: 0.092123; Backpropagation: 0.2913 sec; Batch: 2.0779 sec
0.1451 0.1418 0.1176 0.1070 0.0952 0.0894 0.0844 0.0822 0.0809 0.0789 0.0777 0.0766 0.0755 0.0747 0.0737 0.0733 

[TRAIN] Epoch[1](4880/114412); Loss: 0.085287; Backpropagation: 0.2917 sec; Batch: 2.1185 sec
0.1427 0.1360 0.1095 0.0953 0.0889 0.0837 0.0797 0.0753 0.0730 0.0715 0.0702 0.0690 0.0682 0.0676 0.0672 0.0668 

[TRAIN] Epoch[1](4881/114412); Loss: 0.077105; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1587 0.1530 0.1126 0.0969 0.0827 0.0727 0.0643 0.0617 0.0594 0.0565 0.0542 0.0532 0.0527 0.0522 0.0516 0.0513 

[TRAIN] Epoch[1](4882/114412); Loss: 0.095675; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1463 0.1411 0.1144 0.1079 0.0992 0.0943 0.0899 0.0873 0.0852 0.0839 0.0825 0.0814 0.0803 0.0796 0.0791 0.0784 

[TRAIN] Epoch[1](4883/114412); Loss: 0.074902; Backpropagation: 0.2905 sec; Batch: 2.0799 sec
0.1221 0.1175 0.1050 0.0946 0.0854 0.0780 0.0718 0.0676 0.0632 0.0601 0.0589 0.0576 0.0555 0.0545 0.0537 0.0530 

[TRAIN] Epoch[1](4884/114412); Loss: 0.070745; Backpropagation: 0.2934 sec; Batch: 2.1018 sec
0.1278 0.1233 0.1000 0.0884 0.0746 0.0689 0.0651 0.0618 0.0586 0.0553 0.0537 0.0525 0.0514 0.0507 0.0501 0.0495 

[TRAIN] Epoch[1](4885/114412); Loss: 0.076241; Backpropagation: 0.2911 sec; Batch: 2.1155 sec
0.1410 0.1341 0.1095 0.0882 0.0804 0.0750 0.0707 0.0664 0.0627 0.0605 0.0583 0.0560 0.0552 0.0546 0.0540 0.0533 

[TRAIN] Epoch[1](4886/114412); Loss: 0.076504; Backpropagation: 0.2916 sec; Batch: 2.1235 sec
0.1301 0.1269 0.1028 0.0926 0.0826 0.0762 0.0708 0.0662 0.0631 0.0615 0.0603 0.0592 0.0584 0.0579 0.0579 0.0576 

[TRAIN] Epoch[1](4887/114412); Loss: 0.083494; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1419 0.1342 0.1042 0.0933 0.0862 0.0824 0.0783 0.0742 0.0720 0.0705 0.0687 0.0675 0.0667 0.0658 0.0652 0.0647 

[TRAIN] Epoch[1](4888/114412); Loss: 0.079908; Backpropagation: 0.2908 sec; Batch: 2.1196 sec
0.1421 0.1347 0.1056 0.0919 0.0816 0.0752 0.0704 0.0680 0.0662 0.0648 0.0643 0.0636 0.0632 0.0627 0.0623 0.0619 

[TRAIN] Epoch[1](4889/114412); Loss: 0.088370; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.1580 0.1525 0.1327 0.1163 0.1063 0.0988 0.0873 0.0758 0.0688 0.0644 0.0622 0.0601 0.0591 0.0580 0.0571 0.0566 

[TRAIN] Epoch[1](4890/114412); Loss: 0.065467; Backpropagation: 0.2914 sec; Batch: 2.1135 sec
0.1243 0.1162 0.0877 0.0718 0.0679 0.0624 0.0590 0.0560 0.0547 0.0529 0.0511 0.0501 0.0489 0.0486 0.0482 0.0478 

[TRAIN] Epoch[1](4891/114412); Loss: 0.108909; Backpropagation: 0.2931 sec; Batch: 2.1205 sec
0.1856 0.1756 0.1433 0.1230 0.1095 0.1032 0.0988 0.0965 0.0935 0.0912 0.0895 0.0885 0.0874 0.0865 0.0856 0.0849 

[TRAIN] Epoch[1](4892/114412); Loss: 0.084802; Backpropagation: 0.2914 sec; Batch: 2.1145 sec
0.1790 0.1701 0.1336 0.1143 0.0857 0.0752 0.0687 0.0636 0.0616 0.0611 0.0608 0.0585 0.0574 0.0561 0.0558 0.0553 

[TRAIN] Epoch[1](4893/114412); Loss: 0.083797; Backpropagation: 0.2914 sec; Batch: 2.1145 sec
0.1600 0.1419 0.1176 0.0984 0.0845 0.0772 0.0729 0.0702 0.0684 0.0670 0.0656 0.0647 0.0640 0.0632 0.0627 0.0623 

[TRAIN] Epoch[1](4894/114412); Loss: 0.096026; Backpropagation: 0.2926 sec; Batch: 2.0879 sec
0.1794 0.1599 0.1348 0.1146 0.1008 0.0910 0.0858 0.0821 0.0788 0.0771 0.0757 0.0738 0.0721 0.0710 0.0700 0.0695 

[TRAIN] Epoch[1](4895/114412); Loss: 0.095563; Backpropagation: 0.2932 sec; Batch: 2.1180 sec
0.1449 0.1342 0.1218 0.1107 0.1066 0.1000 0.0933 0.0886 0.0854 0.0825 0.0807 0.0789 0.0770 0.0757 0.0747 0.0739 

[TRAIN] Epoch[1](4896/114412); Loss: 0.076860; Backpropagation: 0.2902 sec; Batch: 2.1165 sec
0.1660 0.1552 0.1164 0.0972 0.0787 0.0707 0.0644 0.0594 0.0554 0.0546 0.0541 0.0527 0.0523 0.0514 0.0508 0.0503 

[TRAIN] Epoch[1](4897/114412); Loss: 0.070965; Backpropagation: 0.2909 sec; Batch: 2.1194 sec
0.1268 0.1170 0.0952 0.0834 0.0737 0.0680 0.0647 0.0613 0.0593 0.0577 0.0564 0.0557 0.0549 0.0542 0.0538 0.0534 

[TRAIN] Epoch[1](4898/114412); Loss: 0.111137; Backpropagation: 0.2909 sec; Batch: 2.1184 sec
0.1582 0.1520 0.1354 0.1248 0.1177 0.1113 0.1071 0.1036 0.1009 0.0996 0.0973 0.0957 0.0947 0.0939 0.0933 0.0926 

[TRAIN] Epoch[1](4899/114412); Loss: 0.098335; Backpropagation: 0.2909 sec; Batch: 2.0830 sec
0.2052 0.1835 0.1529 0.1273 0.1063 0.0914 0.0799 0.0763 0.0729 0.0716 0.0697 0.0687 0.0679 0.0672 0.0666 0.0660 

[TRAIN] Epoch[1](4900/114412); Loss: 0.088101; Backpropagation: 0.2906 sec; Batch: 2.0777 sec
0.1952 0.1751 0.1355 0.1070 0.0858 0.0758 0.0723 0.0691 0.0666 0.0648 0.0630 0.0617 0.0607 0.0598 0.0589 0.0585 

[TRAIN] Epoch[1](4901/114412); Loss: 0.103987; Backpropagation: 0.2933 sec; Batch: 2.1178 sec
0.1666 0.1547 0.1349 0.1214 0.1082 0.1012 0.0967 0.0933 0.0907 0.0892 0.0874 0.0858 0.0847 0.0837 0.0829 0.0824 

[TRAIN] Epoch[1](4902/114412); Loss: 0.093981; Backpropagation: 0.2914 sec; Batch: 2.1192 sec
0.1532 0.1393 0.1170 0.1063 0.0983 0.0922 0.0882 0.0850 0.0814 0.0800 0.0791 0.0779 0.0772 0.0767 0.0762 0.0758 

[TRAIN] Epoch[1](4903/114412); Loss: 0.092914; Backpropagation: 0.2937 sec; Batch: 2.1169 sec
0.1715 0.1543 0.1319 0.1168 0.1025 0.0916 0.0830 0.0779 0.0739 0.0722 0.0709 0.0695 0.0687 0.0678 0.0673 0.0669 

[TRAIN] Epoch[1](4904/114412); Loss: 0.098204; Backpropagation: 0.2914 sec; Batch: 2.1198 sec
0.2017 0.1788 0.1503 0.1205 0.1046 0.0912 0.0808 0.0779 0.0755 0.0737 0.0719 0.0707 0.0695 0.0686 0.0680 0.0675 

[TRAIN] Epoch[1](4905/114412); Loss: 0.059460; Backpropagation: 0.2932 sec; Batch: 2.1179 sec
0.1090 0.0979 0.0767 0.0681 0.0619 0.0575 0.0550 0.0525 0.0501 0.0487 0.0473 0.0464 0.0457 0.0454 0.0449 0.0444 

[TRAIN] Epoch[1](4906/114412); Loss: 0.062758; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1252 0.1127 0.0934 0.0771 0.0691 0.0629 0.0572 0.0528 0.0497 0.0474 0.0452 0.0439 0.0428 0.0421 0.0414 0.0411 

[TRAIN] Epoch[1](4907/114412); Loss: 0.062406; Backpropagation: 0.2907 sec; Batch: 2.1165 sec
0.1345 0.1136 0.0919 0.0735 0.0637 0.0575 0.0538 0.0500 0.0485 0.0470 0.0461 0.0451 0.0444 0.0436 0.0429 0.0424 

[TRAIN] Epoch[1](4908/114412); Loss: 0.108561; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.2217 0.1963 0.1703 0.1443 0.1234 0.1054 0.0912 0.0846 0.0803 0.0784 0.0768 0.0751 0.0736 0.0726 0.0718 0.0712 

[TRAIN] Epoch[1](4909/114412); Loss: 0.095323; Backpropagation: 0.2915 sec; Batch: 2.1138 sec
0.1583 0.1539 0.1278 0.1104 0.0966 0.0893 0.0853 0.0828 0.0815 0.0793 0.0784 0.0772 0.0768 0.0761 0.0758 0.0755 

[TRAIN] Epoch[1](4910/114412); Loss: 0.072108; Backpropagation: 0.2928 sec; Batch: 2.1264 sec
0.1299 0.1166 0.0974 0.0825 0.0732 0.0678 0.0635 0.0614 0.0598 0.0591 0.0585 0.0579 0.0573 0.0568 0.0563 0.0560 

[TRAIN] Epoch[1](4911/114412); Loss: 0.096765; Backpropagation: 0.2913 sec; Batch: 2.1041 sec
0.1694 0.1598 0.1323 0.1185 0.1015 0.0887 0.0835 0.0806 0.0795 0.0783 0.0778 0.0772 0.0762 0.0754 0.0747 0.0746 

[TRAIN] Epoch[1](4912/114412); Loss: 0.083061; Backpropagation: 0.2912 sec; Batch: 2.0859 sec
0.1349 0.1271 0.1155 0.1019 0.0925 0.0837 0.0779 0.0734 0.0705 0.0684 0.0666 0.0652 0.0641 0.0632 0.0624 0.0617 

[TRAIN] Epoch[1](4913/114412); Loss: 0.099837; Backpropagation: 0.2906 sec; Batch: 2.1046 sec
0.1685 0.1512 0.1276 0.1116 0.1016 0.0953 0.0919 0.0888 0.0864 0.0849 0.0836 0.0827 0.0818 0.0810 0.0805 0.0799 

[TRAIN] Epoch[1](4914/114412); Loss: 0.116176; Backpropagation: 0.2903 sec; Batch: 2.1166 sec
0.2165 0.1988 0.1713 0.1516 0.1303 0.1159 0.1031 0.0949 0.0904 0.0881 0.0860 0.0845 0.0834 0.0822 0.0812 0.0805 

[TRAIN] Epoch[1](4915/114412); Loss: 0.083581; Backpropagation: 0.2910 sec; Batch: 2.1143 sec
0.1744 0.1606 0.1356 0.1145 0.0922 0.0756 0.0666 0.0642 0.0610 0.0586 0.0572 0.0565 0.0560 0.0553 0.0547 0.0543 

[TRAIN] Epoch[1](4916/114412); Loss: 0.095679; Backpropagation: 0.2907 sec; Batch: 2.0768 sec
0.1981 0.1803 0.1437 0.1222 0.1029 0.0908 0.0824 0.0784 0.0732 0.0695 0.0681 0.0664 0.0650 0.0641 0.0633 0.0625 

[TRAIN] Epoch[1](4917/114412); Loss: 0.106256; Backpropagation: 0.2909 sec; Batch: 2.1212 sec
0.1964 0.1774 0.1544 0.1347 0.1193 0.1066 0.0964 0.0898 0.0860 0.0835 0.0810 0.0784 0.0765 0.0747 0.0733 0.0720 

[TRAIN] Epoch[1](4918/114412); Loss: 0.127245; Backpropagation: 0.2911 sec; Batch: 2.1308 sec
0.2712 0.2454 0.2093 0.1801 0.1474 0.1231 0.1062 0.0974 0.0932 0.0896 0.0868 0.0826 0.0792 0.0769 0.0747 0.0727 

[TRAIN] Epoch[1](4919/114412); Loss: 0.125243; Backpropagation: 0.2905 sec; Batch: 2.1206 sec
0.2122 0.2040 0.1791 0.1592 0.1413 0.1275 0.1152 0.1075 0.1025 0.0991 0.0961 0.0941 0.0929 0.0921 0.0910 0.0901 

[TRAIN] Epoch[1](4920/114412); Loss: 0.097498; Backpropagation: 0.2913 sec; Batch: 2.1353 sec
0.1793 0.1593 0.1327 0.1149 0.1008 0.0933 0.0884 0.0834 0.0805 0.0783 0.0770 0.0761 0.0753 0.0742 0.0734 0.0729 

[TRAIN] Epoch[1](4921/114412); Loss: 0.065742; Backpropagation: 0.2909 sec; Batch: 2.1214 sec
0.1522 0.1444 0.1142 0.0981 0.0784 0.0658 0.0556 0.0490 0.0450 0.0414 0.0384 0.0357 0.0343 0.0336 0.0331 0.0327 

[TRAIN] Epoch[1](4922/114412); Loss: 0.079917; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1679 0.1452 0.1200 0.0995 0.0850 0.0750 0.0684 0.0646 0.0615 0.0594 0.0581 0.0566 0.0555 0.0547 0.0540 0.0535 

[TRAIN] Epoch[1](4923/114412); Loss: 0.101312; Backpropagation: 0.2896 sec; Batch: 2.0837 sec
0.1658 0.1532 0.1394 0.1264 0.1144 0.1073 0.0995 0.0914 0.0876 0.0843 0.0815 0.0766 0.0755 0.0746 0.0719 0.0716 

[TRAIN] Epoch[1](4924/114412); Loss: 0.103031; Backpropagation: 0.2907 sec; Batch: 2.1190 sec
0.1699 0.1621 0.1406 0.1230 0.1104 0.1002 0.0938 0.0917 0.0900 0.0862 0.0842 0.0825 0.0806 0.0792 0.0776 0.0765 

[TRAIN] Epoch[1](4925/114412); Loss: 0.079157; Backpropagation: 0.2916 sec; Batch: 2.0791 sec
0.1550 0.1418 0.1267 0.1081 0.0958 0.0812 0.0704 0.0650 0.0598 0.0567 0.0545 0.0526 0.0513 0.0504 0.0492 0.0479 

[TRAIN] Epoch[1](4926/114412); Loss: 0.081465; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1486 0.1352 0.1153 0.0964 0.0874 0.0805 0.0731 0.0693 0.0668 0.0653 0.0634 0.0621 0.0611 0.0601 0.0596 0.0590 

[TRAIN] Epoch[1](4927/114412); Loss: 0.078809; Backpropagation: 0.2937 sec; Batch: 2.1070 sec
0.1498 0.1297 0.1214 0.1090 0.0988 0.0863 0.0750 0.0653 0.0596 0.0563 0.0541 0.0528 0.0517 0.0510 0.0502 0.0498 

[TRAIN] Epoch[1](4928/114412); Loss: 0.113443; Backpropagation: 0.2931 sec; Batch: 2.1186 sec
0.2212 0.1919 0.1615 0.1360 0.1176 0.1075 0.0986 0.0943 0.0915 0.0893 0.0877 0.0858 0.0845 0.0835 0.0825 0.0819 

[TRAIN] Epoch[1](4929/114412); Loss: 0.109723; Backpropagation: 0.2912 sec; Batch: 2.1165 sec
0.1741 0.1633 0.1458 0.1304 0.1187 0.1101 0.1025 0.0979 0.0952 0.0928 0.0908 0.0890 0.0877 0.0866 0.0856 0.0848 

[TRAIN] Epoch[1](4930/114412); Loss: 0.085315; Backpropagation: 0.2911 sec; Batch: 2.1160 sec
0.1581 0.1397 0.1165 0.1026 0.0926 0.0831 0.0783 0.0746 0.0715 0.0684 0.0665 0.0647 0.0634 0.0625 0.0615 0.0609 

[TRAIN] Epoch[1](4931/114412); Loss: 0.088006; Backpropagation: 0.2915 sec; Batch: 2.0795 sec
0.1956 0.1700 0.1380 0.1069 0.0841 0.0785 0.0753 0.0724 0.0674 0.0644 0.0619 0.0602 0.0593 0.0585 0.0581 0.0574 

[TRAIN] Epoch[1](4932/114412); Loss: 0.075792; Backpropagation: 0.2911 sec; Batch: 2.1492 sec
0.1537 0.1331 0.1114 0.0913 0.0789 0.0690 0.0652 0.0630 0.0604 0.0582 0.0569 0.0560 0.0550 0.0541 0.0534 0.0529 

[TRAIN] Epoch[1](4933/114412); Loss: 0.115407; Backpropagation: 0.2910 sec; Batch: 2.2585 sec
0.2122 0.1939 0.1666 0.1464 0.1253 0.1137 0.1054 0.0981 0.0936 0.0903 0.0875 0.0857 0.0845 0.0823 0.0809 0.0801 

[TRAIN] Epoch[1](4934/114412); Loss: 0.091535; Backpropagation: 0.2913 sec; Batch: 2.0845 sec
0.1852 0.1696 0.1421 0.1174 0.0956 0.0801 0.0739 0.0712 0.0699 0.0685 0.0670 0.0659 0.0653 0.0648 0.0643 0.0638 

[TRAIN] Epoch[1](4935/114412); Loss: 0.109475; Backpropagation: 0.2914 sec; Batch: 2.1171 sec
0.1934 0.1799 0.1510 0.1349 0.1186 0.1067 0.0974 0.0930 0.0905 0.0882 0.0864 0.0850 0.0836 0.0821 0.0809 0.0797 

[TRAIN] Epoch[1](4936/114412); Loss: 0.081043; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.1611 0.1477 0.1166 0.0966 0.0831 0.0764 0.0707 0.0663 0.0643 0.0630 0.0608 0.0601 0.0584 0.0578 0.0571 0.0567 

[TRAIN] Epoch[1](4937/114412); Loss: 0.108852; Backpropagation: 0.2914 sec; Batch: 2.1195 sec
0.2365 0.2019 0.1684 0.1379 0.1155 0.0970 0.0881 0.0848 0.0831 0.0811 0.0780 0.0761 0.0747 0.0736 0.0728 0.0721 

[TRAIN] Epoch[1](4938/114412); Loss: 0.112103; Backpropagation: 0.2931 sec; Batch: 2.1170 sec
0.2081 0.1835 0.1630 0.1392 0.1187 0.1086 0.1005 0.0952 0.0921 0.0891 0.0868 0.0850 0.0833 0.0816 0.0802 0.0788 

[TRAIN] Epoch[1](4939/114412); Loss: 0.135633; Backpropagation: 0.2930 sec; Batch: 2.1177 sec
0.2947 0.2642 0.2298 0.1921 0.1606 0.1327 0.1100 0.0991 0.0940 0.0910 0.0877 0.0850 0.0837 0.0828 0.0818 0.0810 

[TRAIN] Epoch[1](4940/114412); Loss: 0.105692; Backpropagation: 0.2916 sec; Batch: 2.1157 sec
0.1767 0.1601 0.1396 0.1246 0.1134 0.1053 0.0982 0.0940 0.0907 0.0882 0.0864 0.0847 0.0836 0.0828 0.0818 0.0810 

[TRAIN] Epoch[1](4941/114412); Loss: 0.085626; Backpropagation: 0.2911 sec; Batch: 2.0968 sec
0.1799 0.1623 0.1289 0.1027 0.0870 0.0787 0.0739 0.0704 0.0673 0.0640 0.0623 0.0607 0.0595 0.0583 0.0574 0.0567 

[TRAIN] Epoch[1](4942/114412); Loss: 0.121066; Backpropagation: 0.2913 sec; Batch: 2.1334 sec
0.2237 0.2077 0.1810 0.1581 0.1405 0.1262 0.1128 0.1012 0.0960 0.0911 0.0874 0.0852 0.0825 0.0825 0.0813 0.0800 

[TRAIN] Epoch[1](4943/114412); Loss: 0.088721; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1780 0.1585 0.1309 0.1068 0.0947 0.0864 0.0791 0.0748 0.0704 0.0679 0.0661 0.0636 0.0620 0.0610 0.0602 0.0593 

[TRAIN] Epoch[1](4944/114412); Loss: 0.053815; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1272 0.1183 0.0776 0.0621 0.0524 0.0486 0.0452 0.0418 0.0394 0.0382 0.0369 0.0361 0.0350 0.0345 0.0340 0.0336 

[TRAIN] Epoch[1](4945/114412); Loss: 0.091754; Backpropagation: 0.2929 sec; Batch: 2.1206 sec
0.2009 0.1757 0.1418 0.1124 0.0921 0.0814 0.0763 0.0715 0.0685 0.0673 0.0658 0.0649 0.0634 0.0625 0.0620 0.0617 

[TRAIN] Epoch[1](4946/114412); Loss: 0.077990; Backpropagation: 0.2911 sec; Batch: 2.1191 sec
0.1414 0.1265 0.1039 0.0897 0.0826 0.0754 0.0706 0.0681 0.0663 0.0644 0.0630 0.0613 0.0601 0.0591 0.0582 0.0573 

[TRAIN] Epoch[1](4947/114412); Loss: 0.087579; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1433 0.1336 0.1235 0.1094 0.0985 0.0863 0.0801 0.0767 0.0732 0.0709 0.0696 0.0688 0.0682 0.0670 0.0664 0.0658 

[TRAIN] Epoch[1](4948/114412); Loss: 0.066873; Backpropagation: 0.2917 sec; Batch: 2.1171 sec
0.1298 0.1121 0.0850 0.0712 0.0671 0.0633 0.0606 0.0582 0.0565 0.0553 0.0539 0.0530 0.0521 0.0513 0.0507 0.0500 

[TRAIN] Epoch[1](4949/114412); Loss: 0.104033; Backpropagation: 0.2914 sec; Batch: 2.1271 sec
0.1493 0.1388 0.1276 0.1186 0.1138 0.1060 0.1006 0.0965 0.0937 0.0922 0.0908 0.0891 0.0882 0.0874 0.0863 0.0857 

[TRAIN] Epoch[1](4950/114412); Loss: 0.075879; Backpropagation: 0.2910 sec; Batch: 2.1194 sec
0.1370 0.1258 0.1059 0.0917 0.0843 0.0761 0.0708 0.0678 0.0643 0.0610 0.0587 0.0567 0.0555 0.0537 0.0527 0.0520 

[TRAIN] Epoch[1](4951/114412); Loss: 0.090996; Backpropagation: 0.2912 sec; Batch: 2.1304 sec
0.1633 0.1389 0.1177 0.1007 0.0907 0.0871 0.0833 0.0806 0.0785 0.0766 0.0750 0.0739 0.0731 0.0726 0.0721 0.0717 

[TRAIN] Epoch[1](4952/114412); Loss: 0.076949; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1374 0.1181 0.1001 0.0860 0.0780 0.0744 0.0713 0.0680 0.0657 0.0641 0.0633 0.0625 0.0615 0.0610 0.0602 0.0597 

[TRAIN] Epoch[1](4953/114412); Loss: 0.090126; Backpropagation: 0.2942 sec; Batch: 2.1205 sec
0.1728 0.1537 0.1238 0.1010 0.0916 0.0854 0.0814 0.0777 0.0742 0.0722 0.0705 0.0694 0.0689 0.0679 0.0660 0.0654 

[TRAIN] Epoch[1](4954/114412); Loss: 0.069684; Backpropagation: 0.2950 sec; Batch: 2.1215 sec
0.1657 0.1530 0.1096 0.0911 0.0733 0.0686 0.0650 0.0583 0.0498 0.0432 0.0423 0.0407 0.0398 0.0387 0.0381 0.0376 

[TRAIN] Epoch[1](4955/114412); Loss: 0.092173; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.2287 0.2085 0.1554 0.1224 0.0894 0.0773 0.0687 0.0655 0.0615 0.0600 0.0587 0.0575 0.0564 0.0557 0.0547 0.0544 

[TRAIN] Epoch[1](4956/114412); Loss: 0.073891; Backpropagation: 0.2919 sec; Batch: 2.1308 sec
0.1990 0.1698 0.1120 0.0801 0.0643 0.0646 0.0630 0.0589 0.0530 0.0512 0.0476 0.0450 0.0442 0.0436 0.0432 0.0429 

[TRAIN] Epoch[1](4957/114412); Loss: 0.069477; Backpropagation: 0.2907 sec; Batch: 2.1159 sec
0.1342 0.1204 0.0967 0.0804 0.0723 0.0662 0.0617 0.0582 0.0566 0.0553 0.0541 0.0529 0.0516 0.0508 0.0502 0.0500 

[TRAIN] Epoch[1](4958/114412); Loss: 0.084437; Backpropagation: 0.2907 sec; Batch: 2.1335 sec
0.1354 0.1179 0.1054 0.0941 0.0859 0.0811 0.0784 0.0762 0.0745 0.0737 0.0725 0.0719 0.0715 0.0710 0.0707 0.0708 

[TRAIN] Epoch[1](4959/114412); Loss: 0.089562; Backpropagation: 0.2911 sec; Batch: 2.0790 sec
0.1795 0.1689 0.1324 0.1156 0.0970 0.0838 0.0741 0.0715 0.0696 0.0664 0.0642 0.0632 0.0626 0.0619 0.0614 0.0610 

[TRAIN] Epoch[1](4960/114412); Loss: 0.088570; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.2349 0.2137 0.1603 0.1267 0.0901 0.0770 0.0654 0.0593 0.0536 0.0516 0.0496 0.0491 0.0476 0.0464 0.0461 0.0457 

[TRAIN] Epoch[1](4961/114412); Loss: 0.064504; Backpropagation: 0.2914 sec; Batch: 2.1162 sec
0.0986 0.0943 0.0779 0.0733 0.0697 0.0655 0.0613 0.0594 0.0574 0.0563 0.0551 0.0536 0.0531 0.0526 0.0521 0.0516 

[TRAIN] Epoch[1](4962/114412); Loss: 0.109898; Backpropagation: 0.2910 sec; Batch: 2.0781 sec
0.1817 0.1627 0.1408 0.1262 0.1190 0.1109 0.1050 0.1017 0.0967 0.0940 0.0914 0.0884 0.0869 0.0858 0.0844 0.0829 

[TRAIN] Epoch[1](4963/114412); Loss: 0.090711; Backpropagation: 0.2913 sec; Batch: 2.1340 sec
0.1664 0.1513 0.1270 0.1085 0.0957 0.0891 0.0825 0.0781 0.0749 0.0727 0.0708 0.0692 0.0680 0.0666 0.0657 0.0648 

[TRAIN] Epoch[1](4964/114412); Loss: 0.076403; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1934 0.1691 0.1295 0.0988 0.0728 0.0668 0.0630 0.0594 0.0545 0.0503 0.0480 0.0457 0.0439 0.0431 0.0424 0.0418 

[TRAIN] Epoch[1](4965/114412); Loss: 0.074476; Backpropagation: 0.2952 sec; Batch: 2.0819 sec
0.1295 0.1177 0.1020 0.0881 0.0807 0.0745 0.0706 0.0661 0.0629 0.0603 0.0586 0.0572 0.0564 0.0562 0.0555 0.0553 

[TRAIN] Epoch[1](4966/114412); Loss: 0.082050; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.2055 0.1673 0.1347 0.0986 0.0741 0.0677 0.0653 0.0619 0.0593 0.0570 0.0555 0.0543 0.0536 0.0531 0.0525 0.0524 

[TRAIN] Epoch[1](4967/114412); Loss: 0.079086; Backpropagation: 0.2919 sec; Batch: 2.0791 sec
0.1780 0.1663 0.1229 0.0978 0.0758 0.0708 0.0654 0.0615 0.0582 0.0562 0.0548 0.0534 0.0523 0.0513 0.0507 0.0502 

[TRAIN] Epoch[1](4968/114412); Loss: 0.098080; Backpropagation: 0.2904 sec; Batch: 2.1147 sec
0.1882 0.1663 0.1397 0.1175 0.1042 0.0955 0.0905 0.0867 0.0819 0.0785 0.0755 0.0721 0.0705 0.0685 0.0674 0.0664 

[TRAIN] Epoch[1](4969/114412); Loss: 0.101889; Backpropagation: 0.2907 sec; Batch: 2.1258 sec
0.1690 0.1513 0.1293 0.1150 0.1078 0.1031 0.0976 0.0945 0.0903 0.0878 0.0849 0.0832 0.0810 0.0796 0.0783 0.0776 

[TRAIN] Epoch[1](4970/114412); Loss: 0.086019; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1991 0.1844 0.1369 0.1136 0.0815 0.0681 0.0687 0.0642 0.0621 0.0601 0.0586 0.0572 0.0564 0.0556 0.0552 0.0548 

[TRAIN] Epoch[1](4971/114412); Loss: 0.069995; Backpropagation: 0.2914 sec; Batch: 2.1145 sec
0.1521 0.1310 0.1025 0.0805 0.0716 0.0663 0.0605 0.0578 0.0559 0.0524 0.0508 0.0494 0.0481 0.0478 0.0470 0.0463 

[TRAIN] Epoch[1](4972/114412); Loss: 0.082351; Backpropagation: 0.2914 sec; Batch: 2.1213 sec
0.1571 0.1384 0.1105 0.0969 0.0847 0.0790 0.0740 0.0716 0.0689 0.0670 0.0646 0.0629 0.0615 0.0610 0.0600 0.0595 

[TRAIN] Epoch[1](4973/114412); Loss: 0.080607; Backpropagation: 0.2914 sec; Batch: 2.0771 sec
0.1452 0.1271 0.1161 0.0998 0.0897 0.0800 0.0752 0.0716 0.0674 0.0643 0.0627 0.0611 0.0586 0.0574 0.0569 0.0564 

[TRAIN] Epoch[1](4974/114412); Loss: 0.086674; Backpropagation: 0.2932 sec; Batch: 2.1194 sec
0.1776 0.1523 0.1231 0.1017 0.0884 0.0820 0.0768 0.0734 0.0696 0.0672 0.0654 0.0637 0.0628 0.0617 0.0609 0.0601 

[TRAIN] Epoch[1](4975/114412); Loss: 0.091349; Backpropagation: 0.2919 sec; Batch: 2.1157 sec
0.1366 0.1197 0.1081 0.0988 0.0928 0.0888 0.0858 0.0843 0.0832 0.0820 0.0812 0.0807 0.0801 0.0799 0.0797 0.0797 

[TRAIN] Epoch[1](4976/114412); Loss: 0.094353; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.2341 0.1863 0.1537 0.1218 0.1007 0.0861 0.0723 0.0709 0.0670 0.0641 0.0619 0.0598 0.0590 0.0584 0.0569 0.0565 

[TRAIN] Epoch[1](4977/114412); Loss: 0.091862; Backpropagation: 0.2914 sec; Batch: 2.1171 sec
0.2168 0.1720 0.1430 0.1150 0.0943 0.0791 0.0708 0.0694 0.0678 0.0656 0.0643 0.0636 0.0630 0.0621 0.0617 0.0612 

[TRAIN] Epoch[1](4978/114412); Loss: 0.087376; Backpropagation: 0.2908 sec; Batch: 2.1261 sec
0.2054 0.1565 0.1366 0.1159 0.0978 0.0838 0.0719 0.0670 0.0638 0.0612 0.0595 0.0580 0.0565 0.0555 0.0545 0.0541 

[TRAIN] Epoch[1](4979/114412); Loss: 0.099534; Backpropagation: 0.2907 sec; Batch: 2.0770 sec
0.2067 0.1654 0.1419 0.1148 0.0980 0.0901 0.0859 0.0828 0.0802 0.0780 0.0771 0.0755 0.0749 0.0741 0.0737 0.0735 

[TRAIN] Epoch[1](4980/114412); Loss: 0.073605; Backpropagation: 0.2907 sec; Batch: 2.1253 sec
0.1506 0.1357 0.0977 0.0798 0.0728 0.0651 0.0631 0.0610 0.0595 0.0582 0.0575 0.0563 0.0558 0.0554 0.0546 0.0545 

[TRAIN] Epoch[1](4981/114412); Loss: 0.093363; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1765 0.1727 0.1424 0.1221 0.1004 0.0897 0.0811 0.0754 0.0717 0.0696 0.0678 0.0662 0.0654 0.0648 0.0642 0.0637 

[TRAIN] Epoch[1](4982/114412); Loss: 0.082315; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.1576 0.1327 0.1121 0.0958 0.0859 0.0801 0.0745 0.0703 0.0667 0.0655 0.0643 0.0634 0.0627 0.0621 0.0618 0.0615 

[TRAIN] Epoch[1](4983/114412); Loss: 0.103294; Backpropagation: 0.2912 sec; Batch: 2.1327 sec
0.1548 0.1374 0.1225 0.1113 0.1076 0.1042 0.1001 0.0972 0.0942 0.0924 0.0906 0.0892 0.0884 0.0879 0.0876 0.0874 

[TRAIN] Epoch[1](4984/114412); Loss: 0.087589; Backpropagation: 0.2935 sec; Batch: 2.1182 sec
0.2311 0.1813 0.1471 0.1072 0.0803 0.0699 0.0680 0.0647 0.0613 0.0591 0.0575 0.0560 0.0549 0.0547 0.0543 0.0539 

[TRAIN] Epoch[1](4985/114412); Loss: 0.070705; Backpropagation: 0.2922 sec; Batch: 2.1218 sec
0.1269 0.1037 0.0909 0.0812 0.0746 0.0685 0.0653 0.0631 0.0611 0.0598 0.0576 0.0564 0.0566 0.0557 0.0551 0.0549 

[TRAIN] Epoch[1](4986/114412); Loss: 0.082047; Backpropagation: 0.2913 sec; Batch: 2.1108 sec
0.1773 0.1251 0.1089 0.0935 0.0867 0.0786 0.0748 0.0715 0.0679 0.0658 0.0639 0.0623 0.0609 0.0597 0.0583 0.0574 

[TRAIN] Epoch[1](4987/114412); Loss: 0.081952; Backpropagation: 0.2952 sec; Batch: 2.1193 sec
0.2056 0.1410 0.1171 0.0865 0.0795 0.0760 0.0724 0.0673 0.0635 0.0611 0.0586 0.0576 0.0572 0.0566 0.0560 0.0553 

[TRAIN] Epoch[1](4988/114412); Loss: 0.087490; Backpropagation: 0.2911 sec; Batch: 2.1335 sec
0.1234 0.1157 0.1089 0.0989 0.0907 0.0849 0.0816 0.0796 0.0784 0.0780 0.0776 0.0773 0.0770 0.0767 0.0760 0.0752 

[TRAIN] Epoch[1](4989/114412); Loss: 0.083960; Backpropagation: 0.2930 sec; Batch: 2.1188 sec
0.1784 0.1303 0.1172 0.0963 0.0854 0.0801 0.0753 0.0710 0.0683 0.0663 0.0646 0.0634 0.0626 0.0619 0.0615 0.0609 

[TRAIN] Epoch[1](4990/114412); Loss: 0.090510; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.2179 0.1650 0.1470 0.1113 0.0899 0.0776 0.0727 0.0702 0.0682 0.0657 0.0639 0.0624 0.0609 0.0594 0.0585 0.0578 

[TRAIN] Epoch[1](4991/114412); Loss: 0.105268; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1850 0.1719 0.1458 0.1301 0.1134 0.1034 0.0962 0.0925 0.0892 0.0862 0.0836 0.0798 0.0788 0.0778 0.0759 0.0747 

[TRAIN] Epoch[1](4992/114412); Loss: 0.088531; Backpropagation: 0.2952 sec; Batch: 2.1231 sec
0.2132 0.1553 0.1279 0.0960 0.0879 0.0808 0.0752 0.0724 0.0682 0.0653 0.0640 0.0634 0.0627 0.0620 0.0614 0.0607 

[TRAIN] Epoch[1](4993/114412); Loss: 0.087171; Backpropagation: 0.2919 sec; Batch: 2.1170 sec
0.1765 0.1335 0.1114 0.0959 0.0877 0.0829 0.0782 0.0751 0.0724 0.0705 0.0695 0.0686 0.0684 0.0681 0.0681 0.0678 

[TRAIN] Epoch[1](4994/114412); Loss: 0.101297; Backpropagation: 0.2956 sec; Batch: 2.0821 sec
0.1469 0.1394 0.1342 0.1223 0.1125 0.1040 0.0985 0.0939 0.0908 0.0881 0.0855 0.0839 0.0822 0.0805 0.0796 0.0785 

[TRAIN] Epoch[1](4995/114412); Loss: 0.080809; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1680 0.1242 0.1074 0.0888 0.0811 0.0750 0.0703 0.0686 0.0674 0.0658 0.0644 0.0634 0.0630 0.0625 0.0619 0.0612 

[TRAIN] Epoch[1](4996/114412); Loss: 0.088382; Backpropagation: 0.2906 sec; Batch: 2.1163 sec
0.1783 0.1381 0.1204 0.1030 0.0958 0.0903 0.0835 0.0786 0.0737 0.0705 0.0680 0.0654 0.0638 0.0626 0.0614 0.0606 

[TRAIN] Epoch[1](4997/114412); Loss: 0.075468; Backpropagation: 0.2933 sec; Batch: 2.1752 sec
0.1441 0.1015 0.0968 0.0888 0.0830 0.0772 0.0726 0.0682 0.0656 0.0635 0.0614 0.0595 0.0581 0.0567 0.0556 0.0549 

[TRAIN] Epoch[1](4998/114412); Loss: 0.101286; Backpropagation: 0.2924 sec; Batch: 2.1429 sec
0.1849 0.1541 0.1367 0.1195 0.1130 0.1038 0.0978 0.0932 0.0883 0.0849 0.0806 0.0773 0.0748 0.0723 0.0705 0.0691 

[TRAIN] Epoch[1](4999/114412); Loss: 0.099258; Backpropagation: 0.2911 sec; Batch: 2.1564 sec
0.1554 0.1398 0.1282 0.1136 0.1057 0.0992 0.0939 0.0908 0.0883 0.0860 0.0845 0.0827 0.0814 0.0804 0.0794 0.0788 

[TRAIN] Epoch[1](5000/114412); Loss: 0.108522; Backpropagation: 0.2906 sec; Batch: 2.0834 sec
0.1759 0.1655 0.1406 0.1256 0.1133 0.1060 0.1020 0.0986 0.0954 0.0925 0.0898 0.0886 0.0870 0.0861 0.0851 0.0843 

[TRAIN] Epoch[1](5001/114412); Loss: 0.114296; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1844 0.1679 0.1540 0.1355 0.1230 0.1143 0.1086 0.1045 0.0998 0.0971 0.0955 0.0920 0.0904 0.0889 0.0870 0.0856 

[TRAIN] Epoch[1](5002/114412); Loss: 0.081428; Backpropagation: 0.3004 sec; Batch: 2.1264 sec
0.2136 0.1631 0.1286 0.0965 0.0799 0.0677 0.0638 0.0606 0.0585 0.0570 0.0551 0.0535 0.0522 0.0515 0.0509 0.0504 

[TRAIN] Epoch[1](5003/114412); Loss: 0.075149; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1235 0.1050 0.0958 0.0883 0.0808 0.0760 0.0712 0.0694 0.0668 0.0647 0.0633 0.0617 0.0602 0.0595 0.0584 0.0578 

[TRAIN] Epoch[1](5004/114412); Loss: 0.070090; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1588 0.1182 0.0944 0.0818 0.0760 0.0699 0.0636 0.0592 0.0560 0.0537 0.0515 0.0499 0.0484 0.0473 0.0466 0.0461 

[TRAIN] Epoch[1](5005/114412); Loss: 0.092334; Backpropagation: 0.2914 sec; Batch: 2.0831 sec
0.1885 0.1660 0.1371 0.1117 0.0934 0.0860 0.0796 0.0765 0.0733 0.0705 0.0688 0.0671 0.0658 0.0649 0.0643 0.0636 

[TRAIN] Epoch[1](5006/114412); Loss: 0.085910; Backpropagation: 0.2914 sec; Batch: 2.0787 sec
0.1583 0.1424 0.1224 0.1044 0.0942 0.0855 0.0768 0.0727 0.0696 0.0674 0.0663 0.0646 0.0635 0.0628 0.0621 0.0615 

[TRAIN] Epoch[1](5007/114412); Loss: 0.075679; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1045 0.1018 0.1074 0.0992 0.0890 0.0802 0.0706 0.0671 0.0655 0.0635 0.0622 0.0612 0.0606 0.0600 0.0592 0.0588 

[TRAIN] Epoch[1](5008/114412); Loss: 0.086502; Backpropagation: 0.2908 sec; Batch: 2.0818 sec
0.1922 0.1453 0.1255 0.0990 0.0890 0.0799 0.0748 0.0708 0.0676 0.0659 0.0647 0.0635 0.0626 0.0617 0.0611 0.0605 

[TRAIN] Epoch[1](5009/114412); Loss: 0.090152; Backpropagation: 0.2907 sec; Batch: 2.1174 sec
0.2219 0.1668 0.1391 0.0917 0.0797 0.0768 0.0744 0.0721 0.0701 0.0682 0.0666 0.0650 0.0637 0.0628 0.0621 0.0614 

[TRAIN] Epoch[1](5010/114412); Loss: 0.087724; Backpropagation: 0.2906 sec; Batch: 2.1182 sec
0.1913 0.1636 0.1395 0.1086 0.0889 0.0785 0.0741 0.0715 0.0679 0.0651 0.0632 0.0608 0.0594 0.0582 0.0569 0.0561 

[TRAIN] Epoch[1](5011/114412); Loss: 0.110616; Backpropagation: 0.2915 sec; Batch: 2.1217 sec
0.2179 0.1603 0.1387 0.1203 0.1103 0.1044 0.1004 0.0974 0.0948 0.0933 0.0915 0.0902 0.0889 0.0881 0.0871 0.0863 

[TRAIN] Epoch[1](5012/114412); Loss: 0.082064; Backpropagation: 0.2912 sec; Batch: 2.0785 sec
0.2215 0.1535 0.1298 0.0912 0.0838 0.0755 0.0684 0.0627 0.0590 0.0567 0.0550 0.0530 0.0520 0.0509 0.0502 0.0497 

[TRAIN] Epoch[1](5013/114412); Loss: 0.110134; Backpropagation: 0.2930 sec; Batch: 2.1180 sec
0.2499 0.1783 0.1580 0.1277 0.1087 0.0966 0.0918 0.0892 0.0866 0.0853 0.0841 0.0828 0.0819 0.0812 0.0804 0.0796 

[TRAIN] Epoch[1](5014/114412); Loss: 0.081858; Backpropagation: 0.2905 sec; Batch: 2.1159 sec
0.1991 0.1487 0.1239 0.0967 0.0818 0.0745 0.0702 0.0667 0.0624 0.0597 0.0572 0.0557 0.0548 0.0536 0.0529 0.0519 

[TRAIN] Epoch[1](5015/114412); Loss: 0.100699; Backpropagation: 0.2911 sec; Batch: 2.1346 sec
0.2425 0.1782 0.1495 0.1123 0.0970 0.0891 0.0845 0.0806 0.0773 0.0748 0.0731 0.0721 0.0710 0.0703 0.0697 0.0691 

[TRAIN] Epoch[1](5016/114412); Loss: 0.076184; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1919 0.1242 0.1168 0.0881 0.0845 0.0758 0.0681 0.0616 0.0579 0.0551 0.0526 0.0504 0.0493 0.0483 0.0477 0.0468 

[TRAIN] Epoch[1](5017/114412); Loss: 0.081079; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1633 0.1269 0.1078 0.0914 0.0861 0.0789 0.0742 0.0705 0.0677 0.0661 0.0641 0.0621 0.0611 0.0597 0.0590 0.0583 

[TRAIN] Epoch[1](5018/114412); Loss: 0.099991; Backpropagation: 0.2911 sec; Batch: 2.1146 sec
0.1825 0.1608 0.1379 0.1202 0.1073 0.0979 0.0916 0.0876 0.0841 0.0811 0.0792 0.0768 0.0748 0.0736 0.0726 0.0718 

[TRAIN] Epoch[1](5019/114412); Loss: 0.111902; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1788 0.1599 0.1453 0.1322 0.1214 0.1120 0.1057 0.1015 0.0978 0.0951 0.0934 0.0916 0.0901 0.0892 0.0886 0.0879 

[TRAIN] Epoch[1](5020/114412); Loss: 0.094885; Backpropagation: 0.2913 sec; Batch: 2.1141 sec
0.2279 0.1756 0.1451 0.1118 0.0997 0.0907 0.0828 0.0765 0.0710 0.0670 0.0648 0.0631 0.0618 0.0610 0.0601 0.0594 

[TRAIN] Epoch[1](5021/114412); Loss: 0.092654; Backpropagation: 0.2952 sec; Batch: 2.1217 sec
0.1761 0.1532 0.1227 0.1042 0.0952 0.0883 0.0845 0.0807 0.0774 0.0752 0.0736 0.0722 0.0708 0.0701 0.0694 0.0688 

[TRAIN] Epoch[1](5022/114412); Loss: 0.085517; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1918 0.1413 0.1186 0.0987 0.0885 0.0815 0.0743 0.0703 0.0671 0.0653 0.0641 0.0631 0.0624 0.0611 0.0606 0.0595 

[TRAIN] Epoch[1](5023/114412); Loss: 0.081604; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.2515 0.1877 0.1470 0.0970 0.0886 0.0769 0.0664 0.0585 0.0515 0.0466 0.0437 0.0402 0.0393 0.0381 0.0366 0.0361 

[TRAIN] Epoch[1](5024/114412); Loss: 0.072257; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1633 0.1262 0.0944 0.0832 0.0730 0.0658 0.0625 0.0598 0.0576 0.0562 0.0549 0.0537 0.0527 0.0517 0.0509 0.0503 

[TRAIN] Epoch[1](5025/114412); Loss: 0.115376; Backpropagation: 0.2912 sec; Batch: 2.0781 sec
0.1968 0.1593 0.1432 0.1289 0.1221 0.1158 0.1103 0.1059 0.1027 0.0998 0.0971 0.0952 0.0941 0.0927 0.0914 0.0906 

[TRAIN] Epoch[1](5026/114412); Loss: 0.095474; Backpropagation: 0.2932 sec; Batch: 2.1199 sec
0.2264 0.1974 0.1504 0.1175 0.0942 0.0847 0.0806 0.0766 0.0710 0.0668 0.0634 0.0615 0.0604 0.0594 0.0588 0.0584 

[TRAIN] Epoch[1](5027/114412); Loss: 0.072715; Backpropagation: 0.2931 sec; Batch: 2.1212 sec
0.1817 0.1355 0.1007 0.0802 0.0745 0.0682 0.0625 0.0584 0.0552 0.0527 0.0510 0.0499 0.0490 0.0485 0.0479 0.0475 

[TRAIN] Epoch[1](5028/114412); Loss: 0.107858; Backpropagation: 0.2909 sec; Batch: 2.1149 sec
0.2267 0.1868 0.1568 0.1344 0.1214 0.1083 0.0978 0.0900 0.0841 0.0811 0.0776 0.0751 0.0735 0.0721 0.0706 0.0696 

[TRAIN] Epoch[1](5029/114412); Loss: 0.089716; Backpropagation: 0.2910 sec; Batch: 2.1352 sec
0.1625 0.1426 0.1233 0.1161 0.1036 0.0954 0.0876 0.0809 0.0745 0.0713 0.0684 0.0651 0.0636 0.0620 0.0596 0.0588 

[TRAIN] Epoch[1](5030/114412); Loss: 0.079993; Backpropagation: 0.2927 sec; Batch: 2.0853 sec
0.2001 0.1398 0.1194 0.0945 0.0806 0.0738 0.0684 0.0647 0.0618 0.0587 0.0564 0.0548 0.0533 0.0520 0.0511 0.0504 

[TRAIN] Epoch[1](5031/114412); Loss: 0.077951; Backpropagation: 0.2926 sec; Batch: 2.1181 sec
0.1553 0.1334 0.1077 0.0933 0.0831 0.0769 0.0711 0.0664 0.0632 0.0606 0.0591 0.0574 0.0563 0.0553 0.0544 0.0537 

[TRAIN] Epoch[1](5032/114412); Loss: 0.124911; Backpropagation: 0.2914 sec; Batch: 2.1865 sec
0.2244 0.2065 0.1761 0.1522 0.1330 0.1167 0.1085 0.1054 0.1018 0.0993 0.0977 0.0968 0.0958 0.0953 0.0948 0.0944 

[TRAIN] Epoch[1](5033/114412); Loss: 0.086246; Backpropagation: 0.2911 sec; Batch: 2.1125 sec
0.2037 0.1561 0.1301 0.1021 0.0864 0.0785 0.0738 0.0697 0.0669 0.0635 0.0610 0.0596 0.0585 0.0573 0.0566 0.0561 

[TRAIN] Epoch[1](5034/114412); Loss: 0.089839; Backpropagation: 0.2912 sec; Batch: 2.1252 sec
0.1593 0.1383 0.1214 0.1024 0.0923 0.0881 0.0846 0.0809 0.0780 0.0755 0.0736 0.0713 0.0697 0.0682 0.0674 0.0664 

[TRAIN] Epoch[1](5035/114412); Loss: 0.100715; Backpropagation: 0.2916 sec; Batch: 2.1129 sec
0.2370 0.1680 0.1455 0.1095 0.1021 0.0958 0.0887 0.0841 0.0803 0.0770 0.0742 0.0724 0.0707 0.0694 0.0686 0.0681 

[TRAIN] Epoch[1](5036/114412); Loss: 0.069064; Backpropagation: 0.2913 sec; Batch: 2.1435 sec
0.1397 0.1027 0.0912 0.0814 0.0754 0.0689 0.0649 0.0610 0.0586 0.0563 0.0544 0.0526 0.0512 0.0502 0.0487 0.0478 

[TRAIN] Epoch[1](5037/114412); Loss: 0.093701; Backpropagation: 0.2910 sec; Batch: 2.3125 sec
0.2119 0.1604 0.1268 0.1101 0.1000 0.0934 0.0865 0.0804 0.0754 0.0716 0.0684 0.0658 0.0641 0.0625 0.0615 0.0604 

[TRAIN] Epoch[1](5038/114412); Loss: 0.108732; Backpropagation: 0.2911 sec; Batch: 2.1100 sec
0.2300 0.1896 0.1650 0.1390 0.1176 0.1034 0.0936 0.0882 0.0837 0.0809 0.0782 0.0765 0.0755 0.0738 0.0728 0.0719 

[TRAIN] Epoch[1](5039/114412); Loss: 0.109463; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.2101 0.1895 0.1717 0.1472 0.1254 0.1148 0.1041 0.0918 0.0867 0.0829 0.0785 0.0749 0.0723 0.0695 0.0669 0.0652 

[TRAIN] Epoch[1](5040/114412); Loss: 0.090313; Backpropagation: 0.2913 sec; Batch: 2.1627 sec
0.2062 0.1500 0.1228 0.1117 0.0984 0.0903 0.0824 0.0777 0.0725 0.0691 0.0668 0.0626 0.0608 0.0594 0.0576 0.0566 

[TRAIN] Epoch[1](5041/114412); Loss: 0.091498; Backpropagation: 0.2913 sec; Batch: 2.1079 sec
0.2092 0.1619 0.1309 0.1096 0.0965 0.0838 0.0766 0.0732 0.0710 0.0692 0.0666 0.0651 0.0640 0.0628 0.0621 0.0614 

[TRAIN] Epoch[1](5042/114412); Loss: 0.086902; Backpropagation: 0.2912 sec; Batch: 2.1611 sec
0.1668 0.1340 0.1227 0.1049 0.0918 0.0846 0.0780 0.0738 0.0720 0.0698 0.0688 0.0671 0.0658 0.0645 0.0633 0.0628 

[TRAIN] Epoch[1](5043/114412); Loss: 0.098549; Backpropagation: 0.2915 sec; Batch: 2.1191 sec
0.2320 0.1873 0.1499 0.1181 0.1028 0.0925 0.0864 0.0805 0.0752 0.0709 0.0673 0.0658 0.0642 0.0623 0.0613 0.0602 

[TRAIN] Epoch[1](5044/114412); Loss: 0.065445; Backpropagation: 0.2914 sec; Batch: 2.0836 sec
0.2049 0.1307 0.1023 0.0746 0.0646 0.0574 0.0519 0.0473 0.0442 0.0422 0.0403 0.0391 0.0379 0.0372 0.0364 0.0360 

[TRAIN] Epoch[1](5045/114412); Loss: 0.080147; Backpropagation: 0.2912 sec; Batch: 2.1136 sec
0.1952 0.1514 0.1306 0.1030 0.0816 0.0710 0.0653 0.0613 0.0578 0.0558 0.0541 0.0527 0.0519 0.0510 0.0502 0.0497 

[TRAIN] Epoch[1](5046/114412); Loss: 0.104298; Backpropagation: 0.2930 sec; Batch: 2.1083 sec
0.2067 0.1575 0.1272 0.1134 0.1055 0.0989 0.0950 0.0911 0.0883 0.0870 0.0856 0.0844 0.0833 0.0823 0.0816 0.0810 

[TRAIN] Epoch[1](5047/114412); Loss: 0.120764; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.2027 0.1854 0.1644 0.1497 0.1361 0.1251 0.1171 0.1110 0.1056 0.1016 0.0968 0.0929 0.0899 0.0869 0.0842 0.0827 

[TRAIN] Epoch[1](5048/114412); Loss: 0.105700; Backpropagation: 0.2929 sec; Batch: 2.1215 sec
0.2292 0.1651 0.1391 0.1210 0.1124 0.1049 0.0988 0.0943 0.0890 0.0850 0.0818 0.0787 0.0760 0.0741 0.0718 0.0702 

[TRAIN] Epoch[1](5049/114412); Loss: 0.084118; Backpropagation: 0.2911 sec; Batch: 2.1192 sec
0.2059 0.1478 0.1211 0.0977 0.0889 0.0800 0.0756 0.0699 0.0645 0.0625 0.0601 0.0576 0.0557 0.0543 0.0530 0.0513 

[TRAIN] Epoch[1](5050/114412); Loss: 0.082116; Backpropagation: 0.2906 sec; Batch: 2.1185 sec
0.1588 0.1319 0.1170 0.0984 0.0888 0.0808 0.0751 0.0707 0.0683 0.0661 0.0633 0.0610 0.0596 0.0588 0.0580 0.0572 

[TRAIN] Epoch[1](5051/114412); Loss: 0.120279; Backpropagation: 0.2911 sec; Batch: 2.0769 sec
0.2705 0.1936 0.1619 0.1344 0.1200 0.1118 0.1065 0.1019 0.0985 0.0948 0.0923 0.0905 0.0884 0.0872 0.0865 0.0857 

[TRAIN] Epoch[1](5052/114412); Loss: 0.087229; Backpropagation: 0.2908 sec; Batch: 2.1203 sec
0.1854 0.1719 0.1338 0.1085 0.0898 0.0809 0.0752 0.0703 0.0660 0.0636 0.0619 0.0596 0.0585 0.0576 0.0567 0.0559 

[TRAIN] Epoch[1](5053/114412); Loss: 0.085729; Backpropagation: 0.2908 sec; Batch: 2.0771 sec
0.1758 0.1354 0.1126 0.0955 0.0855 0.0798 0.0754 0.0732 0.0712 0.0698 0.0685 0.0672 0.0664 0.0658 0.0650 0.0645 

[TRAIN] Epoch[1](5054/114412); Loss: 0.070252; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1598 0.1189 0.0957 0.0768 0.0708 0.0654 0.0617 0.0585 0.0566 0.0547 0.0532 0.0519 0.0509 0.0501 0.0497 0.0494 

[TRAIN] Epoch[1](5055/114412); Loss: 0.090730; Backpropagation: 0.2913 sec; Batch: 2.1587 sec
0.1887 0.1396 0.1216 0.1030 0.0923 0.0879 0.0831 0.0797 0.0761 0.0735 0.0713 0.0695 0.0678 0.0669 0.0656 0.0651 

[TRAIN] Epoch[1](5056/114412); Loss: 0.081241; Backpropagation: 0.2915 sec; Batch: 2.1134 sec
0.1678 0.1394 0.1212 0.1023 0.0904 0.0808 0.0722 0.0675 0.0631 0.0604 0.0585 0.0569 0.0558 0.0551 0.0545 0.0541 

[TRAIN] Epoch[1](5057/114412); Loss: 0.086043; Backpropagation: 0.2908 sec; Batch: 2.1123 sec
0.1446 0.1312 0.1135 0.0999 0.0917 0.0850 0.0806 0.0776 0.0746 0.0724 0.0706 0.0691 0.0679 0.0667 0.0659 0.0653 

[TRAIN] Epoch[1](5058/114412); Loss: 0.073325; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1978 0.1328 0.1068 0.0834 0.0790 0.0737 0.0659 0.0594 0.0545 0.0504 0.0477 0.0459 0.0446 0.0441 0.0438 0.0433 

[TRAIN] Epoch[1](5059/114412); Loss: 0.073843; Backpropagation: 0.2929 sec; Batch: 2.1243 sec
0.1522 0.1098 0.0945 0.0811 0.0758 0.0710 0.0669 0.0643 0.0617 0.0608 0.0592 0.0580 0.0575 0.0568 0.0561 0.0558 

[TRAIN] Epoch[1](5060/114412); Loss: 0.095646; Backpropagation: 0.2911 sec; Batch: 2.0776 sec
0.1985 0.1681 0.1500 0.1195 0.0979 0.0864 0.0824 0.0785 0.0761 0.0726 0.0702 0.0683 0.0667 0.0658 0.0649 0.0643 

[TRAIN] Epoch[1](5061/114412); Loss: 0.090010; Backpropagation: 0.2909 sec; Batch: 2.1181 sec
0.1889 0.1471 0.1229 0.0987 0.0884 0.0833 0.0792 0.0763 0.0734 0.0713 0.0702 0.0692 0.0685 0.0679 0.0675 0.0674 

[TRAIN] Epoch[1](5062/114412); Loss: 0.118590; Backpropagation: 0.2909 sec; Batch: 2.1001 sec
0.2079 0.1921 0.1696 0.1515 0.1345 0.1196 0.1074 0.1012 0.0962 0.0926 0.0903 0.0884 0.0875 0.0867 0.0864 0.0858 

[TRAIN] Epoch[1](5063/114412); Loss: 0.102385; Backpropagation: 0.2911 sec; Batch: 2.1137 sec
0.1765 0.1385 0.1239 0.1110 0.1050 0.0999 0.0960 0.0928 0.0906 0.0889 0.0878 0.0870 0.0860 0.0853 0.0847 0.0843 

[TRAIN] Epoch[1](5064/114412); Loss: 0.080457; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1526 0.1233 0.1095 0.0933 0.0850 0.0774 0.0716 0.0692 0.0676 0.0663 0.0650 0.0635 0.0621 0.0610 0.0603 0.0598 

[TRAIN] Epoch[1](5065/114412); Loss: 0.073353; Backpropagation: 0.2928 sec; Batch: 2.1199 sec
0.1529 0.1258 0.1069 0.0859 0.0745 0.0698 0.0652 0.0621 0.0591 0.0571 0.0551 0.0538 0.0527 0.0517 0.0509 0.0502 

[TRAIN] Epoch[1](5066/114412); Loss: 0.080066; Backpropagation: 0.2909 sec; Batch: 2.0777 sec
0.1316 0.1256 0.1159 0.0999 0.0911 0.0822 0.0743 0.0698 0.0669 0.0645 0.0627 0.0617 0.0604 0.0592 0.0579 0.0573 

[TRAIN] Epoch[1](5067/114412); Loss: 0.080859; Backpropagation: 0.2911 sec; Batch: 2.1191 sec
0.1809 0.1274 0.1035 0.0885 0.0825 0.0769 0.0728 0.0682 0.0648 0.0638 0.0624 0.0616 0.0607 0.0602 0.0598 0.0594 

[TRAIN] Epoch[1](5068/114412); Loss: 0.096614; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.2058 0.1590 0.1445 0.1182 0.1076 0.0951 0.0868 0.0793 0.0749 0.0721 0.0702 0.0688 0.0676 0.0663 0.0649 0.0645 

[TRAIN] Epoch[1](5069/114412); Loss: 0.080433; Backpropagation: 0.2912 sec; Batch: 2.1224 sec
0.1359 0.1093 0.1187 0.1046 0.0927 0.0798 0.0721 0.0697 0.0670 0.0650 0.0632 0.0627 0.0620 0.0617 0.0612 0.0611 

[TRAIN] Epoch[1](5070/114412); Loss: 0.079711; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1663 0.1256 0.1115 0.0960 0.0872 0.0788 0.0721 0.0692 0.0646 0.0631 0.0607 0.0584 0.0574 0.0559 0.0548 0.0538 

[TRAIN] Epoch[1](5071/114412); Loss: 0.085178; Backpropagation: 0.2914 sec; Batch: 2.1204 sec
0.1508 0.1319 0.1149 0.1021 0.0933 0.0860 0.0791 0.0755 0.0720 0.0697 0.0678 0.0659 0.0650 0.0638 0.0628 0.0621 

[TRAIN] Epoch[1](5072/114412); Loss: 0.093426; Backpropagation: 0.2920 sec; Batch: 2.1190 sec
0.1738 0.1449 0.1214 0.1040 0.0946 0.0882 0.0839 0.0814 0.0792 0.0775 0.0765 0.0754 0.0744 0.0738 0.0732 0.0726 

[TRAIN] Epoch[1](5073/114412); Loss: 0.070091; Backpropagation: 0.2911 sec; Batch: 2.1217 sec
0.1099 0.0989 0.0929 0.0820 0.0759 0.0692 0.0656 0.0635 0.0617 0.0599 0.0586 0.0578 0.0572 0.0566 0.0560 0.0557 

[TRAIN] Epoch[1](5074/114412); Loss: 0.077429; Backpropagation: 0.2909 sec; Batch: 2.1213 sec
0.1175 0.1100 0.0989 0.0892 0.0810 0.0761 0.0731 0.0704 0.0683 0.0671 0.0659 0.0653 0.0647 0.0641 0.0638 0.0635 

[TRAIN] Epoch[1](5075/114412); Loss: 0.101100; Backpropagation: 0.2956 sec; Batch: 2.1290 sec
0.1847 0.1650 0.1406 0.1255 0.1128 0.1025 0.0940 0.0881 0.0836 0.0801 0.0782 0.0750 0.0735 0.0725 0.0712 0.0703 

[TRAIN] Epoch[1](5076/114412); Loss: 0.088639; Backpropagation: 0.2931 sec; Batch: 2.1199 sec
0.1543 0.1299 0.1123 0.1055 0.0979 0.0890 0.0823 0.0777 0.0757 0.0729 0.0722 0.0712 0.0703 0.0695 0.0691 0.0685 

[TRAIN] Epoch[1](5077/114412); Loss: 0.082644; Backpropagation: 0.2913 sec; Batch: 2.1191 sec
0.1968 0.1486 0.1219 0.0974 0.0893 0.0813 0.0734 0.0677 0.0618 0.0588 0.0572 0.0560 0.0545 0.0533 0.0525 0.0518 

[TRAIN] Epoch[1](5078/114412); Loss: 0.090422; Backpropagation: 0.2952 sec; Batch: 2.1639 sec
0.2115 0.1560 0.1311 0.1086 0.0930 0.0818 0.0789 0.0743 0.0696 0.0682 0.0658 0.0638 0.0625 0.0616 0.0604 0.0596 

[TRAIN] Epoch[1](5079/114412); Loss: 0.075534; Backpropagation: 0.2951 sec; Batch: 2.1187 sec
0.1816 0.1237 0.1014 0.0817 0.0757 0.0709 0.0666 0.0634 0.0607 0.0582 0.0565 0.0550 0.0542 0.0535 0.0529 0.0525 

[TRAIN] Epoch[1](5080/114412); Loss: 0.074038; Backpropagation: 0.2928 sec; Batch: 2.1185 sec
0.1647 0.1119 0.0996 0.0795 0.0744 0.0689 0.0667 0.0639 0.0623 0.0598 0.0584 0.0567 0.0557 0.0549 0.0539 0.0534 

[TRAIN] Epoch[1](5081/114412); Loss: 0.085980; Backpropagation: 0.2931 sec; Batch: 2.0796 sec
0.1982 0.1465 0.1220 0.1010 0.0875 0.0845 0.0778 0.0723 0.0682 0.0645 0.0625 0.0607 0.0586 0.0579 0.0572 0.0564 

[TRAIN] Epoch[1](5082/114412); Loss: 0.090807; Backpropagation: 0.2931 sec; Batch: 2.1166 sec
0.2120 0.1451 0.1259 0.1034 0.0932 0.0890 0.0850 0.0794 0.0755 0.0703 0.0670 0.0658 0.0629 0.0609 0.0594 0.0583 

[TRAIN] Epoch[1](5083/114412); Loss: 0.110402; Backpropagation: 0.2908 sec; Batch: 2.1144 sec
0.2963 0.2043 0.1650 0.1150 0.1083 0.1021 0.0951 0.0880 0.0816 0.0775 0.0749 0.0740 0.0730 0.0711 0.0704 0.0697 

[TRAIN] Epoch[1](5084/114412); Loss: 0.082893; Backpropagation: 0.2913 sec; Batch: 2.1137 sec
0.2000 0.1449 0.1212 0.0922 0.0815 0.0752 0.0704 0.0666 0.0641 0.0618 0.0605 0.0593 0.0584 0.0576 0.0567 0.0561 

[TRAIN] Epoch[1](5085/114412); Loss: 0.098812; Backpropagation: 0.2930 sec; Batch: 2.1227 sec
0.2157 0.1885 0.1587 0.1326 0.1121 0.0943 0.0801 0.0712 0.0720 0.0682 0.0672 0.0661 0.0648 0.0635 0.0631 0.0627 

[TRAIN] Epoch[1](5086/114412); Loss: 0.068978; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.1217 0.1196 0.0946 0.0809 0.0706 0.0662 0.0625 0.0604 0.0581 0.0567 0.0553 0.0532 0.0532 0.0514 0.0499 0.0494 

[TRAIN] Epoch[1](5087/114412); Loss: 0.066048; Backpropagation: 0.2915 sec; Batch: 2.1150 sec
0.1054 0.1117 0.0980 0.0828 0.0705 0.0638 0.0622 0.0575 0.0554 0.0530 0.0517 0.0500 0.0495 0.0489 0.0482 0.0480 

[TRAIN] Epoch[1](5088/114412); Loss: 0.074239; Backpropagation: 0.2909 sec; Batch: 2.1136 sec
0.1527 0.1304 0.1076 0.0939 0.0828 0.0748 0.0703 0.0637 0.0596 0.0550 0.0524 0.0504 0.0494 0.0488 0.0482 0.0478 

[TRAIN] Epoch[1](5089/114412); Loss: 0.085002; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.1754 0.1427 0.1242 0.0985 0.0879 0.0826 0.0768 0.0731 0.0705 0.0672 0.0643 0.0623 0.0607 0.0590 0.0580 0.0569 

[TRAIN] Epoch[1](5090/114412); Loss: 0.089061; Backpropagation: 0.2921 sec; Batch: 2.1186 sec
0.2072 0.1585 0.1251 0.0954 0.0845 0.0785 0.0749 0.0722 0.0697 0.0683 0.0673 0.0659 0.0654 0.0647 0.0639 0.0635 

[TRAIN] Epoch[1](5091/114412); Loss: 0.108272; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1995 0.1822 0.1547 0.1367 0.1211 0.1087 0.0970 0.0901 0.0876 0.0846 0.0820 0.0803 0.0784 0.0772 0.0764 0.0758 

[TRAIN] Epoch[1](5092/114412); Loss: 0.105355; Backpropagation: 0.2916 sec; Batch: 2.1566 sec
0.1974 0.1677 0.1500 0.1261 0.1132 0.1049 0.0980 0.0937 0.0901 0.0868 0.0837 0.0801 0.0778 0.0741 0.0717 0.0703 

[TRAIN] Epoch[1](5093/114412); Loss: 0.085449; Backpropagation: 0.2916 sec; Batch: 2.1340 sec
0.1690 0.1434 0.1168 0.1028 0.0896 0.0787 0.0725 0.0705 0.0685 0.0671 0.0662 0.0653 0.0646 0.0643 0.0639 0.0638 

[TRAIN] Epoch[1](5094/114412); Loss: 0.093458; Backpropagation: 0.2916 sec; Batch: 2.0779 sec
0.1627 0.1483 0.1196 0.1037 0.0935 0.0873 0.0844 0.0817 0.0803 0.0793 0.0783 0.0773 0.0764 0.0751 0.0742 0.0733 

[TRAIN] Epoch[1](5095/114412); Loss: 0.073385; Backpropagation: 0.2956 sec; Batch: 2.1359 sec
0.1481 0.1069 0.0998 0.0855 0.0753 0.0705 0.0688 0.0641 0.0616 0.0605 0.0585 0.0565 0.0555 0.0547 0.0542 0.0535 

[TRAIN] Epoch[1](5096/114412); Loss: 0.120193; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.2429 0.2107 0.1763 0.1481 0.1324 0.1218 0.1111 0.1030 0.0937 0.0891 0.0852 0.0845 0.0829 0.0818 0.0805 0.0792 

[TRAIN] Epoch[1](5097/114412); Loss: 0.078922; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1701 0.1210 0.1053 0.0879 0.0815 0.0738 0.0694 0.0675 0.0650 0.0633 0.0616 0.0603 0.0597 0.0592 0.0588 0.0585 

[TRAIN] Epoch[1](5098/114412); Loss: 0.077327; Backpropagation: 0.2915 sec; Batch: 2.1178 sec
0.1921 0.1308 0.0999 0.0863 0.0783 0.0709 0.0671 0.0648 0.0611 0.0581 0.0568 0.0558 0.0546 0.0539 0.0536 0.0532 

[TRAIN] Epoch[1](5099/114412); Loss: 0.084892; Backpropagation: 0.2911 sec; Batch: 2.1133 sec
0.1573 0.1453 0.1183 0.1060 0.0926 0.0827 0.0774 0.0729 0.0684 0.0654 0.0637 0.0624 0.0621 0.0619 0.0612 0.0606 

[TRAIN] Epoch[1](5100/114412); Loss: 0.117744; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.2330 0.1695 0.1435 0.1212 0.1124 0.1098 0.1071 0.1034 0.1024 0.1011 0.0987 0.0980 0.0974 0.0958 0.0954 0.0950 

[TRAIN] Epoch[1](5101/114412); Loss: 0.084079; Backpropagation: 0.2930 sec; Batch: 2.1208 sec
0.1780 0.1448 0.1149 0.0987 0.0897 0.0819 0.0761 0.0717 0.0675 0.0649 0.0627 0.0607 0.0596 0.0587 0.0580 0.0573 

[TRAIN] Epoch[1](5102/114412); Loss: 0.093079; Backpropagation: 0.2910 sec; Batch: 2.1204 sec
0.2591 0.1794 0.1363 0.0951 0.0838 0.0784 0.0748 0.0726 0.0703 0.0670 0.0653 0.0639 0.0623 0.0611 0.0602 0.0597 

[TRAIN] Epoch[1](5103/114412); Loss: 0.084803; Backpropagation: 0.2907 sec; Batch: 2.1133 sec
0.1595 0.1257 0.1163 0.1000 0.0925 0.0860 0.0808 0.0761 0.0717 0.0693 0.0662 0.0649 0.0639 0.0623 0.0612 0.0605 

[TRAIN] Epoch[1](5104/114412); Loss: 0.086226; Backpropagation: 0.2913 sec; Batch: 2.1150 sec
0.1574 0.1292 0.1149 0.1007 0.0916 0.0851 0.0803 0.0760 0.0732 0.0714 0.0703 0.0683 0.0668 0.0657 0.0648 0.0638 

[TRAIN] Epoch[1](5105/114412); Loss: 0.066275; Backpropagation: 0.2930 sec; Batch: 2.1129 sec
0.1190 0.1094 0.0940 0.0807 0.0709 0.0639 0.0594 0.0566 0.0550 0.0534 0.0517 0.0509 0.0501 0.0492 0.0484 0.0477 

[TRAIN] Epoch[1](5106/114412); Loss: 0.102514; Backpropagation: 0.2913 sec; Batch: 2.1133 sec
0.1572 0.1330 0.1179 0.1088 0.1040 0.1001 0.0985 0.0961 0.0937 0.0924 0.0911 0.0905 0.0900 0.0894 0.0889 0.0887 

[TRAIN] Epoch[1](5107/114412); Loss: 0.085969; Backpropagation: 0.2928 sec; Batch: 2.1191 sec
0.1600 0.1438 0.1203 0.1028 0.0931 0.0854 0.0786 0.0732 0.0705 0.0680 0.0660 0.0647 0.0634 0.0625 0.0618 0.0613 

[TRAIN] Epoch[1](5108/114412); Loss: 0.100161; Backpropagation: 0.2928 sec; Batch: 2.1169 sec
0.2435 0.1991 0.1643 0.1287 0.1103 0.0988 0.0879 0.0797 0.0728 0.0677 0.0645 0.0609 0.0584 0.0572 0.0553 0.0534 

[TRAIN] Epoch[1](5109/114412); Loss: 0.083166; Backpropagation: 0.2928 sec; Batch: 2.0986 sec
0.2147 0.1849 0.1411 0.1056 0.0854 0.0686 0.0619 0.0592 0.0565 0.0540 0.0520 0.0509 0.0499 0.0492 0.0487 0.0481 

[TRAIN] Epoch[1](5110/114412); Loss: 0.087235; Backpropagation: 0.2924 sec; Batch: 2.1166 sec
0.1926 0.1351 0.1094 0.0991 0.0889 0.0822 0.0774 0.0745 0.0720 0.0702 0.0679 0.0671 0.0662 0.0653 0.0644 0.0634 

[TRAIN] Epoch[1](5111/114412); Loss: 0.077644; Backpropagation: 0.2932 sec; Batch: 2.1186 sec
0.1861 0.1337 0.1071 0.0802 0.0745 0.0709 0.0675 0.0647 0.0608 0.0597 0.0586 0.0570 0.0563 0.0558 0.0550 0.0545 

[TRAIN] Epoch[1](5112/114412); Loss: 0.068935; Backpropagation: 0.2923 sec; Batch: 2.1203 sec
0.1138 0.1080 0.0928 0.0809 0.0743 0.0690 0.0645 0.0618 0.0596 0.0575 0.0559 0.0545 0.0535 0.0527 0.0524 0.0517 

[TRAIN] Epoch[1](5113/114412); Loss: 0.079493; Backpropagation: 0.2913 sec; Batch: 2.1191 sec
0.1505 0.1264 0.1026 0.0884 0.0801 0.0749 0.0723 0.0700 0.0673 0.0658 0.0645 0.0631 0.0623 0.0617 0.0611 0.0608 

[TRAIN] Epoch[1](5114/114412); Loss: 0.098043; Backpropagation: 0.2929 sec; Batch: 2.0814 sec
0.1477 0.1451 0.1371 0.1239 0.1121 0.1025 0.0930 0.0876 0.0846 0.0813 0.0797 0.0771 0.0758 0.0747 0.0736 0.0728 

[TRAIN] Epoch[1](5115/114412); Loss: 0.102986; Backpropagation: 0.2909 sec; Batch: 2.1189 sec
0.1645 0.1447 0.1295 0.1184 0.1101 0.1040 0.0993 0.0948 0.0919 0.0890 0.0870 0.0850 0.0840 0.0826 0.0819 0.0810 

[TRAIN] Epoch[1](5116/114412); Loss: 0.092600; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1601 0.1387 0.1244 0.1117 0.1021 0.0936 0.0879 0.0832 0.0797 0.0761 0.0741 0.0721 0.0709 0.0698 0.0690 0.0683 

[TRAIN] Epoch[1](5117/114412); Loss: 0.082019; Backpropagation: 0.2911 sec; Batch: 2.1294 sec
0.1484 0.1231 0.1193 0.1013 0.0889 0.0802 0.0739 0.0704 0.0678 0.0659 0.0643 0.0631 0.0624 0.0616 0.0610 0.0607 

[TRAIN] Epoch[1](5118/114412); Loss: 0.065327; Backpropagation: 0.2911 sec; Batch: 2.0974 sec
0.1213 0.1072 0.0945 0.0782 0.0701 0.0629 0.0582 0.0550 0.0527 0.0513 0.0504 0.0497 0.0492 0.0485 0.0481 0.0478 

[TRAIN] Epoch[1](5119/114412); Loss: 0.088393; Backpropagation: 0.2912 sec; Batch: 2.0776 sec
0.1450 0.1244 0.1104 0.0962 0.0936 0.0906 0.0849 0.0820 0.0784 0.0765 0.0754 0.0733 0.0724 0.0713 0.0702 0.0697 

[TRAIN] Epoch[1](5120/114412); Loss: 0.097417; Backpropagation: 0.2911 sec; Batch: 2.0928 sec
0.1655 0.1510 0.1300 0.1165 0.1062 0.0964 0.0893 0.0854 0.0821 0.0797 0.0783 0.0770 0.0762 0.0756 0.0750 0.0745 

[TRAIN] Epoch[1](5121/114412); Loss: 0.055887; Backpropagation: 0.2914 sec; Batch: 2.1212 sec
0.1173 0.0926 0.0796 0.0655 0.0582 0.0541 0.0510 0.0471 0.0442 0.0433 0.0419 0.0408 0.0403 0.0397 0.0393 0.0391 

[TRAIN] Epoch[1](5122/114412); Loss: 0.070304; Backpropagation: 0.2905 sec; Batch: 2.0763 sec
0.1228 0.1109 0.0918 0.0811 0.0737 0.0659 0.0632 0.0615 0.0599 0.0581 0.0572 0.0565 0.0561 0.0557 0.0553 0.0553 

[TRAIN] Epoch[1](5123/114412); Loss: 0.087953; Backpropagation: 0.2911 sec; Batch: 2.1190 sec
0.1866 0.1579 0.1319 0.1028 0.0851 0.0789 0.0745 0.0718 0.0698 0.0672 0.0660 0.0646 0.0636 0.0630 0.0620 0.0615 

[TRAIN] Epoch[1](5124/114412); Loss: 0.071119; Backpropagation: 0.2954 sec; Batch: 2.1025 sec
0.1816 0.1275 0.0949 0.0847 0.0742 0.0665 0.0596 0.0557 0.0540 0.0517 0.0500 0.0490 0.0481 0.0471 0.0468 0.0463 

[TRAIN] Epoch[1](5125/114412); Loss: 0.114792; Backpropagation: 0.2929 sec; Batch: 2.1210 sec
0.2054 0.1685 0.1460 0.1204 0.1102 0.1062 0.1028 0.1005 0.0997 0.0984 0.0978 0.0971 0.0963 0.0960 0.0958 0.0956 

[TRAIN] Epoch[1](5126/114412); Loss: 0.077940; Backpropagation: 0.2931 sec; Batch: 2.1183 sec
0.1288 0.1098 0.0996 0.0910 0.0838 0.0774 0.0730 0.0700 0.0680 0.0661 0.0652 0.0642 0.0634 0.0628 0.0622 0.0618 

[TRAIN] Epoch[1](5127/114412); Loss: 0.067660; Backpropagation: 0.2955 sec; Batch: 2.1195 sec
0.1848 0.1371 0.1010 0.0814 0.0667 0.0577 0.0529 0.0511 0.0483 0.0464 0.0447 0.0435 0.0428 0.0421 0.0413 0.0408 

[TRAIN] Epoch[1](5128/114412); Loss: 0.117838; Backpropagation: 0.2929 sec; Batch: 2.1317 sec
0.1919 0.1636 0.1441 0.1317 0.1246 0.1173 0.1123 0.1083 0.1051 0.1027 0.1006 0.0986 0.0976 0.0965 0.0955 0.0951 

[TRAIN] Epoch[1](5129/114412); Loss: 0.092824; Backpropagation: 0.2952 sec; Batch: 2.0840 sec
0.1938 0.1461 0.1241 0.1052 0.0984 0.0925 0.0858 0.0807 0.0758 0.0733 0.0711 0.0694 0.0685 0.0676 0.0669 0.0661 

[TRAIN] Epoch[1](5130/114412); Loss: 0.087090; Backpropagation: 0.2928 sec; Batch: 2.0954 sec
0.1855 0.1338 0.1138 0.0989 0.0919 0.0819 0.0773 0.0748 0.0717 0.0694 0.0685 0.0675 0.0659 0.0648 0.0641 0.0637 

[TRAIN] Epoch[1](5131/114412); Loss: 0.084073; Backpropagation: 0.2913 sec; Batch: 2.1266 sec
0.1605 0.1288 0.1137 0.0999 0.0902 0.0836 0.0785 0.0744 0.0696 0.0683 0.0659 0.0641 0.0635 0.0623 0.0612 0.0608 

[TRAIN] Epoch[1](5132/114412); Loss: 0.092971; Backpropagation: 0.2932 sec; Batch: 2.1155 sec
0.2344 0.1771 0.1385 0.1038 0.0903 0.0812 0.0762 0.0717 0.0697 0.0669 0.0652 0.0643 0.0632 0.0621 0.0618 0.0612 

[TRAIN] Epoch[1](5133/114412); Loss: 0.077378; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1508 0.1194 0.0994 0.0895 0.0819 0.0762 0.0725 0.0697 0.0648 0.0633 0.0619 0.0594 0.0586 0.0578 0.0566 0.0563 

[TRAIN] Epoch[1](5134/114412); Loss: 0.068786; Backpropagation: 0.2913 sec; Batch: 2.1141 sec
0.1264 0.1190 0.0994 0.0855 0.0768 0.0661 0.0618 0.0583 0.0552 0.0535 0.0521 0.0509 0.0498 0.0492 0.0486 0.0480 

[TRAIN] Epoch[1](5135/114412); Loss: 0.093375; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.2283 0.1646 0.1274 0.1039 0.0924 0.0812 0.0778 0.0746 0.0727 0.0701 0.0702 0.0681 0.0667 0.0659 0.0655 0.0647 

[TRAIN] Epoch[1](5136/114412); Loss: 0.091103; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1963 0.1593 0.1335 0.1082 0.0941 0.0851 0.0785 0.0736 0.0709 0.0689 0.0673 0.0663 0.0653 0.0642 0.0635 0.0626 

[TRAIN] Epoch[1](5137/114412); Loss: 0.086303; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.1880 0.1440 0.1131 0.0934 0.0863 0.0802 0.0769 0.0722 0.0699 0.0681 0.0668 0.0655 0.0650 0.0643 0.0638 0.0633 

[TRAIN] Epoch[1](5138/114412); Loss: 0.078690; Backpropagation: 0.2914 sec; Batch: 2.1187 sec
0.1571 0.1207 0.1016 0.0881 0.0809 0.0766 0.0729 0.0698 0.0660 0.0632 0.0618 0.0609 0.0604 0.0599 0.0598 0.0594 

[TRAIN] Epoch[1](5139/114412); Loss: 0.065115; Backpropagation: 0.2935 sec; Batch: 2.1197 sec
0.1553 0.1087 0.0852 0.0720 0.0658 0.0599 0.0567 0.0541 0.0515 0.0501 0.0489 0.0480 0.0472 0.0466 0.0462 0.0458 

[TRAIN] Epoch[1](5140/114412); Loss: 0.085499; Backpropagation: 0.2928 sec; Batch: 2.1184 sec
0.1550 0.1338 0.1078 0.0928 0.0884 0.0830 0.0801 0.0764 0.0741 0.0719 0.0700 0.0687 0.0676 0.0666 0.0662 0.0657 

[TRAIN] Epoch[1](5141/114412); Loss: 0.078921; Backpropagation: 0.2931 sec; Batch: 2.1151 sec
0.1646 0.1337 0.1183 0.0937 0.0819 0.0724 0.0679 0.0645 0.0619 0.0602 0.0594 0.0584 0.0573 0.0566 0.0561 0.0558 

[TRAIN] Epoch[1](5142/114412); Loss: 0.080569; Backpropagation: 0.2915 sec; Batch: 2.2812 sec
0.1726 0.1371 0.1208 0.0980 0.0817 0.0749 0.0717 0.0685 0.0646 0.0613 0.0599 0.0581 0.0563 0.0553 0.0547 0.0535 

[TRAIN] Epoch[1](5143/114412); Loss: 0.072101; Backpropagation: 0.2908 sec; Batch: 2.0885 sec
0.1653 0.1291 0.0976 0.0760 0.0676 0.0651 0.0626 0.0597 0.0580 0.0559 0.0548 0.0537 0.0528 0.0522 0.0517 0.0515 

[TRAIN] Epoch[1](5144/114412); Loss: 0.077790; Backpropagation: 0.2907 sec; Batch: 2.1187 sec
0.2112 0.1619 0.1280 0.0900 0.0705 0.0641 0.0600 0.0567 0.0544 0.0521 0.0513 0.0506 0.0493 0.0487 0.0482 0.0475 

[TRAIN] Epoch[1](5145/114412); Loss: 0.062363; Backpropagation: 0.2911 sec; Batch: 2.1067 sec
0.1525 0.1090 0.0893 0.0694 0.0635 0.0572 0.0528 0.0498 0.0474 0.0461 0.0450 0.0443 0.0436 0.0431 0.0427 0.0423 

[TRAIN] Epoch[1](5146/114412); Loss: 0.078450; Backpropagation: 0.2914 sec; Batch: 2.2773 sec
0.1851 0.1274 0.0986 0.0864 0.0789 0.0747 0.0703 0.0660 0.0635 0.0615 0.0596 0.0583 0.0576 0.0566 0.0558 0.0551 

[TRAIN] Epoch[1](5147/114412); Loss: 0.072243; Backpropagation: 0.2911 sec; Batch: 2.1052 sec
0.1386 0.1303 0.1056 0.0857 0.0742 0.0665 0.0614 0.0594 0.0579 0.0561 0.0550 0.0542 0.0534 0.0529 0.0525 0.0520 

[TRAIN] Epoch[1](5148/114412); Loss: 0.085935; Backpropagation: 0.2912 sec; Batch: 2.1260 sec
0.2199 0.1536 0.1181 0.0946 0.0845 0.0785 0.0733 0.0693 0.0657 0.0630 0.0615 0.0601 0.0590 0.0584 0.0579 0.0575 

[TRAIN] Epoch[1](5149/114412); Loss: 0.083512; Backpropagation: 0.2913 sec; Batch: 2.1213 sec
0.1486 0.1302 0.1084 0.0976 0.0880 0.0809 0.0760 0.0726 0.0708 0.0691 0.0678 0.0667 0.0659 0.0651 0.0645 0.0640 

[TRAIN] Epoch[1](5150/114412); Loss: 0.090699; Backpropagation: 0.2907 sec; Batch: 2.1149 sec
0.1926 0.1760 0.1474 0.1178 0.0963 0.0827 0.0779 0.0737 0.0710 0.0658 0.0632 0.0597 0.0582 0.0573 0.0562 0.0556 

[TRAIN] Epoch[1](5151/114412); Loss: 0.075312; Backpropagation: 0.2932 sec; Batch: 2.1197 sec
0.1634 0.1434 0.1124 0.0933 0.0797 0.0690 0.0628 0.0602 0.0580 0.0553 0.0537 0.0522 0.0515 0.0508 0.0502 0.0493 

[TRAIN] Epoch[1](5152/114412); Loss: 0.090691; Backpropagation: 0.2918 sec; Batch: 2.1161 sec
0.1762 0.1450 0.1256 0.1036 0.0932 0.0844 0.0810 0.0769 0.0745 0.0729 0.0718 0.0707 0.0700 0.0689 0.0683 0.0679 

[TRAIN] Epoch[1](5153/114412); Loss: 0.089030; Backpropagation: 0.2905 sec; Batch: 2.1155 sec
0.1508 0.1285 0.1065 0.0969 0.0908 0.0881 0.0848 0.0808 0.0789 0.0774 0.0760 0.0746 0.0737 0.0728 0.0720 0.0717 

[TRAIN] Epoch[1](5154/114412); Loss: 0.063318; Backpropagation: 0.2930 sec; Batch: 2.1080 sec
0.1102 0.1002 0.0902 0.0772 0.0689 0.0598 0.0557 0.0539 0.0526 0.0512 0.0505 0.0498 0.0489 0.0484 0.0479 0.0477 

[TRAIN] Epoch[1](5155/114412); Loss: 0.081476; Backpropagation: 0.2930 sec; Batch: 2.1205 sec
0.2002 0.1628 0.1284 0.0951 0.0785 0.0704 0.0676 0.0638 0.0598 0.0582 0.0560 0.0544 0.0530 0.0524 0.0519 0.0511 

[TRAIN] Epoch[1](5156/114412); Loss: 0.094915; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1514 0.1352 0.1222 0.1109 0.1017 0.0938 0.0897 0.0868 0.0834 0.0815 0.0799 0.0780 0.0769 0.0764 0.0758 0.0751 

[TRAIN] Epoch[1](5157/114412); Loss: 0.101375; Backpropagation: 0.2916 sec; Batch: 2.1137 sec
0.2089 0.1714 0.1395 0.1201 0.1065 0.0939 0.0875 0.0840 0.0813 0.0792 0.0777 0.0762 0.0751 0.0742 0.0735 0.0729 

[TRAIN] Epoch[1](5158/114412); Loss: 0.085741; Backpropagation: 0.2953 sec; Batch: 2.1218 sec
0.2111 0.1817 0.1398 0.1043 0.0797 0.0732 0.0682 0.0637 0.0603 0.0580 0.0574 0.0563 0.0553 0.0547 0.0545 0.0536 

[TRAIN] Epoch[1](5159/114412); Loss: 0.093850; Backpropagation: 0.2913 sec; Batch: 2.1135 sec
0.2206 0.1770 0.1439 0.1079 0.0878 0.0809 0.0778 0.0727 0.0707 0.0700 0.0678 0.0666 0.0655 0.0647 0.0642 0.0636 

[TRAIN] Epoch[1](5160/114412); Loss: 0.095085; Backpropagation: 0.2911 sec; Batch: 2.1285 sec
0.1473 0.1222 0.1113 0.1015 0.0960 0.0918 0.0899 0.0878 0.0870 0.0860 0.0847 0.0839 0.0836 0.0831 0.0826 0.0824 

[TRAIN] Epoch[1](5161/114412); Loss: 0.062048; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1227 0.1058 0.1044 0.0865 0.0721 0.0613 0.0528 0.0485 0.0461 0.0442 0.0432 0.0422 0.0416 0.0409 0.0403 0.0401 

[TRAIN] Epoch[1](5162/114412); Loss: 0.086306; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1958 0.1551 0.1227 0.1003 0.0873 0.0796 0.0743 0.0722 0.0684 0.0653 0.0634 0.0614 0.0602 0.0591 0.0583 0.0574 

[TRAIN] Epoch[1](5163/114412); Loss: 0.075043; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1756 0.1710 0.1321 0.1086 0.0794 0.0672 0.0595 0.0547 0.0490 0.0467 0.0452 0.0445 0.0431 0.0420 0.0413 0.0409 

[TRAIN] Epoch[1](5164/114412); Loss: 0.096481; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.2226 0.1735 0.1356 0.1002 0.0923 0.0892 0.0833 0.0783 0.0761 0.0739 0.0727 0.0714 0.0699 0.0687 0.0681 0.0678 

[TRAIN] Epoch[1](5165/114412); Loss: 0.097879; Backpropagation: 0.2930 sec; Batch: 2.1162 sec
0.2133 0.1740 0.1411 0.1064 0.0947 0.0885 0.0850 0.0802 0.0784 0.0760 0.0737 0.0723 0.0717 0.0710 0.0702 0.0696 

[TRAIN] Epoch[1](5166/114412); Loss: 0.089234; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1713 0.1314 0.1121 0.0952 0.0897 0.0847 0.0821 0.0791 0.0767 0.0751 0.0739 0.0725 0.0718 0.0712 0.0708 0.0703 

[TRAIN] Epoch[1](5167/114412); Loss: 0.099976; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.2295 0.1832 0.1500 0.1172 0.1086 0.0977 0.0888 0.0815 0.0761 0.0716 0.0689 0.0666 0.0661 0.0649 0.0647 0.0643 

[TRAIN] Epoch[1](5168/114412); Loss: 0.070864; Backpropagation: 0.2907 sec; Batch: 2.0774 sec
0.1349 0.1252 0.1092 0.0922 0.0802 0.0709 0.0626 0.0585 0.0544 0.0527 0.0508 0.0498 0.0489 0.0483 0.0478 0.0474 

[TRAIN] Epoch[1](5169/114412); Loss: 0.098167; Backpropagation: 0.2918 sec; Batch: 2.1177 sec
0.1924 0.1612 0.1342 0.1132 0.1003 0.0938 0.0884 0.0840 0.0802 0.0785 0.0767 0.0752 0.0743 0.0736 0.0727 0.0722 

[TRAIN] Epoch[1](5170/114412); Loss: 0.069016; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1330 0.1184 0.0966 0.0803 0.0726 0.0660 0.0621 0.0587 0.0562 0.0548 0.0535 0.0519 0.0509 0.0502 0.0498 0.0492 

[TRAIN] Epoch[1](5171/114412); Loss: 0.073929; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1720 0.1196 0.0987 0.0789 0.0721 0.0671 0.0643 0.0613 0.0591 0.0581 0.0569 0.0562 0.0555 0.0548 0.0544 0.0540 

[TRAIN] Epoch[1](5172/114412); Loss: 0.067493; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.2067 0.1444 0.1123 0.0756 0.0608 0.0589 0.0541 0.0495 0.0443 0.0409 0.0397 0.0395 0.0389 0.0384 0.0383 0.0377 

[TRAIN] Epoch[1](5173/114412); Loss: 0.095224; Backpropagation: 0.2913 sec; Batch: 2.0787 sec
0.1811 0.1593 0.1350 0.1136 0.1002 0.0917 0.0845 0.0792 0.0767 0.0749 0.0734 0.0722 0.0715 0.0708 0.0700 0.0695 

[TRAIN] Epoch[1](5174/114412); Loss: 0.076979; Backpropagation: 0.2913 sec; Batch: 2.1197 sec
0.1761 0.1336 0.1018 0.0833 0.0754 0.0702 0.0658 0.0633 0.0609 0.0595 0.0583 0.0578 0.0572 0.0569 0.0560 0.0556 

[TRAIN] Epoch[1](5175/114412); Loss: 0.077731; Backpropagation: 0.2908 sec; Batch: 2.0780 sec
0.1540 0.1284 0.1059 0.0866 0.0794 0.0743 0.0700 0.0667 0.0637 0.0626 0.0616 0.0597 0.0590 0.0579 0.0571 0.0569 

[TRAIN] Epoch[1](5176/114412); Loss: 0.072654; Backpropagation: 0.2931 sec; Batch: 2.1285 sec
0.1665 0.1309 0.1140 0.0898 0.0758 0.0641 0.0591 0.0568 0.0553 0.0533 0.0517 0.0504 0.0495 0.0490 0.0484 0.0479 

[TRAIN] Epoch[1](5177/114412); Loss: 0.092617; Backpropagation: 0.2911 sec; Batch: 2.0970 sec
0.2489 0.1976 0.1617 0.1116 0.0889 0.0756 0.0691 0.0654 0.0616 0.0602 0.0586 0.0576 0.0570 0.0565 0.0558 0.0557 

[TRAIN] Epoch[1](5178/114412); Loss: 0.070343; Backpropagation: 0.2951 sec; Batch: 2.1038 sec
0.1810 0.1321 0.0953 0.0793 0.0696 0.0625 0.0574 0.0549 0.0525 0.0510 0.0498 0.0489 0.0482 0.0479 0.0476 0.0472 

[TRAIN] Epoch[1](5179/114412); Loss: 0.072721; Backpropagation: 0.2912 sec; Batch: 2.1154 sec
0.2324 0.1603 0.1246 0.0786 0.0664 0.0554 0.0527 0.0491 0.0472 0.0453 0.0445 0.0436 0.0421 0.0410 0.0406 0.0398 

[TRAIN] Epoch[1](5180/114412); Loss: 0.074735; Backpropagation: 0.2928 sec; Batch: 2.1197 sec
0.1747 0.1419 0.1134 0.0844 0.0765 0.0684 0.0624 0.0577 0.0559 0.0545 0.0528 0.0520 0.0514 0.0508 0.0498 0.0493 

[TRAIN] Epoch[1](5181/114412); Loss: 0.077496; Backpropagation: 0.2909 sec; Batch: 2.1151 sec
0.2470 0.1612 0.1066 0.0709 0.0670 0.0632 0.0599 0.0565 0.0549 0.0534 0.0520 0.0510 0.0500 0.0492 0.0489 0.0484 

[TRAIN] Epoch[1](5182/114412); Loss: 0.077238; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.1680 0.1328 0.1106 0.0902 0.0799 0.0738 0.0673 0.0630 0.0612 0.0587 0.0573 0.0565 0.0550 0.0544 0.0536 0.0531 

[TRAIN] Epoch[1](5183/114412); Loss: 0.063719; Backpropagation: 0.2915 sec; Batch: 2.1214 sec
0.1243 0.0998 0.0796 0.0728 0.0663 0.0616 0.0586 0.0552 0.0544 0.0528 0.0512 0.0499 0.0494 0.0484 0.0478 0.0476 

[TRAIN] Epoch[1](5184/114412); Loss: 0.080131; Backpropagation: 0.2914 sec; Batch: 2.1220 sec
0.1489 0.1178 0.1084 0.0940 0.0851 0.0781 0.0722 0.0693 0.0675 0.0654 0.0643 0.0636 0.0629 0.0621 0.0615 0.0611 

[TRAIN] Epoch[1](5185/114412); Loss: 0.076304; Backpropagation: 0.2914 sec; Batch: 2.1665 sec
0.1390 0.1251 0.1022 0.0855 0.0780 0.0706 0.0683 0.0659 0.0642 0.0630 0.0619 0.0609 0.0599 0.0591 0.0587 0.0584 

[TRAIN] Epoch[1](5186/114412); Loss: 0.084494; Backpropagation: 0.2913 sec; Batch: 2.1152 sec
0.1668 0.1311 0.1061 0.0940 0.0872 0.0804 0.0760 0.0739 0.0713 0.0691 0.0681 0.0673 0.0662 0.0655 0.0648 0.0642 

[TRAIN] Epoch[1](5187/114412); Loss: 0.074159; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1401 0.1333 0.1067 0.0890 0.0815 0.0726 0.0661 0.0629 0.0609 0.0570 0.0557 0.0539 0.0528 0.0522 0.0512 0.0506 

[TRAIN] Epoch[1](5188/114412); Loss: 0.096979; Backpropagation: 0.2914 sec; Batch: 2.1215 sec
0.1782 0.1688 0.1416 0.1180 0.1012 0.0910 0.0864 0.0826 0.0791 0.0767 0.0744 0.0726 0.0716 0.0707 0.0696 0.0690 

[TRAIN] Epoch[1](5189/114412); Loss: 0.072942; Backpropagation: 0.2913 sec; Batch: 2.0862 sec
0.1151 0.1092 0.1131 0.0960 0.0861 0.0783 0.0711 0.0630 0.0605 0.0581 0.0549 0.0540 0.0535 0.0519 0.0513 0.0510 

[TRAIN] Epoch[1](5190/114412); Loss: 0.049669; Backpropagation: 0.2913 sec; Batch: 2.0767 sec
0.1580 0.0968 0.0667 0.0512 0.0464 0.0420 0.0386 0.0359 0.0338 0.0333 0.0328 0.0324 0.0322 0.0319 0.0314 0.0313 

[TRAIN] Epoch[1](5191/114412); Loss: 0.071432; Backpropagation: 0.2907 sec; Batch: 2.1131 sec
0.1638 0.1259 0.1041 0.0810 0.0705 0.0639 0.0616 0.0584 0.0559 0.0546 0.0532 0.0519 0.0508 0.0499 0.0491 0.0485 

[TRAIN] Epoch[1](5192/114412); Loss: 0.082972; Backpropagation: 0.2910 sec; Batch: 2.1095 sec
0.1954 0.1666 0.1203 0.0954 0.0803 0.0737 0.0689 0.0657 0.0631 0.0600 0.0581 0.0574 0.0568 0.0559 0.0553 0.0548 

[TRAIN] Epoch[1](5193/114412); Loss: 0.084313; Backpropagation: 0.2905 sec; Batch: 2.1168 sec
0.1597 0.1336 0.1163 0.1001 0.0900 0.0820 0.0771 0.0724 0.0693 0.0670 0.0656 0.0646 0.0641 0.0630 0.0622 0.0619 

[TRAIN] Epoch[1](5194/114412); Loss: 0.081546; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1967 0.1376 0.1050 0.0845 0.0781 0.0732 0.0699 0.0676 0.0654 0.0637 0.0625 0.0612 0.0606 0.0601 0.0594 0.0590 

[TRAIN] Epoch[1](5195/114412); Loss: 0.075430; Backpropagation: 0.2911 sec; Batch: 2.0776 sec
0.1756 0.1199 0.0891 0.0863 0.0786 0.0730 0.0662 0.0625 0.0615 0.0598 0.0582 0.0569 0.0557 0.0551 0.0546 0.0539 

[TRAIN] Epoch[1](5196/114412); Loss: 0.069830; Backpropagation: 0.2912 sec; Batch: 2.1295 sec
0.1483 0.1189 0.1028 0.0865 0.0727 0.0665 0.0622 0.0584 0.0550 0.0525 0.0504 0.0501 0.0493 0.0483 0.0478 0.0475 

[TRAIN] Epoch[1](5197/114412); Loss: 0.078816; Backpropagation: 0.2914 sec; Batch: 2.0786 sec
0.1219 0.1209 0.1059 0.0912 0.0824 0.0769 0.0733 0.0704 0.0684 0.0674 0.0661 0.0649 0.0639 0.0631 0.0625 0.0620 

[TRAIN] Epoch[1](5198/114412); Loss: 0.082348; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1776 0.1651 0.1367 0.1063 0.0832 0.0769 0.0695 0.0655 0.0603 0.0579 0.0571 0.0537 0.0532 0.0527 0.0513 0.0504 

[TRAIN] Epoch[1](5199/114412); Loss: 0.079079; Backpropagation: 0.2906 sec; Batch: 2.0768 sec
0.1460 0.1246 0.1019 0.0900 0.0813 0.0771 0.0720 0.0690 0.0670 0.0651 0.0641 0.0628 0.0619 0.0614 0.0608 0.0603 

[TRAIN] Epoch[1](5200/114412); Loss: 0.074496; Backpropagation: 0.2907 sec; Batch: 2.0845 sec
0.1317 0.1181 0.0982 0.0859 0.0751 0.0701 0.0685 0.0656 0.0633 0.0619 0.0606 0.0598 0.0590 0.0585 0.0581 0.0576 

[TRAIN] Epoch[1](5201/114412); Loss: 0.068550; Backpropagation: 0.2911 sec; Batch: 2.1144 sec
0.1437 0.1233 0.0911 0.0757 0.0710 0.0655 0.0612 0.0583 0.0552 0.0533 0.0521 0.0508 0.0500 0.0491 0.0484 0.0481 

[TRAIN] Epoch[1](5202/114412); Loss: 0.079901; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1464 0.1285 0.1083 0.0917 0.0807 0.0757 0.0725 0.0695 0.0673 0.0659 0.0639 0.0627 0.0621 0.0615 0.0611 0.0608 

[TRAIN] Epoch[1](5203/114412); Loss: 0.080404; Backpropagation: 0.2955 sec; Batch: 2.1071 sec
0.1640 0.1298 0.1089 0.0916 0.0840 0.0763 0.0725 0.0690 0.0664 0.0642 0.0631 0.0614 0.0599 0.0593 0.0584 0.0576 

[TRAIN] Epoch[1](5204/114412); Loss: 0.081702; Backpropagation: 0.2932 sec; Batch: 2.1211 sec
0.1846 0.1449 0.1190 0.0911 0.0823 0.0759 0.0719 0.0670 0.0637 0.0615 0.0602 0.0590 0.0577 0.0568 0.0561 0.0556 

[TRAIN] Epoch[1](5205/114412); Loss: 0.077977; Backpropagation: 0.2906 sec; Batch: 2.0764 sec
0.2060 0.1433 0.1122 0.0850 0.0739 0.0688 0.0645 0.0611 0.0590 0.0567 0.0550 0.0540 0.0530 0.0522 0.0517 0.0511 

[TRAIN] Epoch[1](5206/114412); Loss: 0.112070; Backpropagation: 0.2905 sec; Batch: 2.1162 sec
0.2114 0.1708 0.1497 0.1252 0.1130 0.1062 0.1025 0.0987 0.0953 0.0925 0.0913 0.0894 0.0881 0.0871 0.0865 0.0855 

[TRAIN] Epoch[1](5207/114412); Loss: 0.085025; Backpropagation: 0.2912 sec; Batch: 2.0768 sec
0.2080 0.1498 0.1199 0.0935 0.0805 0.0771 0.0735 0.0697 0.0661 0.0637 0.0625 0.0608 0.0597 0.0592 0.0584 0.0578 

[TRAIN] Epoch[1](5208/114412); Loss: 0.098182; Backpropagation: 0.2915 sec; Batch: 2.1148 sec
0.2489 0.1785 0.1464 0.1098 0.0926 0.0864 0.0851 0.0795 0.0742 0.0721 0.0700 0.0681 0.0667 0.0651 0.0641 0.0633 

[TRAIN] Epoch[1](5209/114412); Loss: 0.080222; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.1460 0.1315 0.1041 0.0892 0.0826 0.0765 0.0724 0.0697 0.0674 0.0658 0.0648 0.0640 0.0631 0.0626 0.0621 0.0618 

[TRAIN] Epoch[1](5210/114412); Loss: 0.075503; Backpropagation: 0.2918 sec; Batch: 2.1261 sec
0.2174 0.1619 0.1130 0.0755 0.0677 0.0617 0.0582 0.0562 0.0523 0.0510 0.0504 0.0492 0.0487 0.0486 0.0482 0.0480 

[TRAIN] Epoch[1](5211/114412); Loss: 0.055903; Backpropagation: 0.2916 sec; Batch: 2.1176 sec
0.1335 0.0833 0.0655 0.0585 0.0545 0.0522 0.0490 0.0482 0.0469 0.0459 0.0439 0.0433 0.0431 0.0427 0.0423 0.0419 

[TRAIN] Epoch[1](5212/114412); Loss: 0.073463; Backpropagation: 0.2913 sec; Batch: 2.1203 sec
0.2238 0.1502 0.1115 0.0781 0.0717 0.0652 0.0586 0.0545 0.0505 0.0484 0.0465 0.0444 0.0437 0.0433 0.0427 0.0422 

[TRAIN] Epoch[1](5213/114412); Loss: 0.064476; Backpropagation: 0.2911 sec; Batch: 2.1138 sec
0.1441 0.1321 0.0984 0.0827 0.0684 0.0573 0.0544 0.0491 0.0472 0.0453 0.0444 0.0433 0.0423 0.0415 0.0408 0.0404 

[TRAIN] Epoch[1](5214/114412); Loss: 0.078860; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.2115 0.1513 0.1179 0.0892 0.0775 0.0715 0.0667 0.0612 0.0586 0.0559 0.0535 0.0523 0.0502 0.0492 0.0481 0.0472 

[TRAIN] Epoch[1](5215/114412); Loss: 0.063864; Backpropagation: 0.2952 sec; Batch: 2.1559 sec
0.1281 0.1121 0.0900 0.0698 0.0628 0.0578 0.0564 0.0542 0.0519 0.0508 0.0501 0.0487 0.0480 0.0473 0.0470 0.0468 

[TRAIN] Epoch[1](5216/114412); Loss: 0.053531; Backpropagation: 0.2929 sec; Batch: 2.0791 sec
0.1005 0.0957 0.0768 0.0648 0.0569 0.0519 0.0478 0.0451 0.0426 0.0412 0.0405 0.0397 0.0390 0.0384 0.0379 0.0378 

[TRAIN] Epoch[1](5217/114412); Loss: 0.089892; Backpropagation: 0.2911 sec; Batch: 2.1211 sec
0.1854 0.1458 0.1141 0.0956 0.0880 0.0820 0.0796 0.0776 0.0754 0.0739 0.0726 0.0715 0.0702 0.0695 0.0689 0.0683 

[TRAIN] Epoch[1](5218/114412); Loss: 0.076219; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1350 0.1031 0.0928 0.0828 0.0767 0.0734 0.0715 0.0693 0.0670 0.0661 0.0649 0.0642 0.0637 0.0632 0.0630 0.0627 

[TRAIN] Epoch[1](5219/114412); Loss: 0.067793; Backpropagation: 0.2912 sec; Batch: 2.1200 sec
0.1362 0.1167 0.1049 0.0843 0.0725 0.0631 0.0591 0.0546 0.0522 0.0510 0.0496 0.0490 0.0483 0.0479 0.0477 0.0476 

[TRAIN] Epoch[1](5220/114412); Loss: 0.077836; Backpropagation: 0.2915 sec; Batch: 2.1160 sec
0.1908 0.1474 0.1220 0.0838 0.0775 0.0662 0.0629 0.0599 0.0580 0.0567 0.0548 0.0540 0.0535 0.0530 0.0526 0.0522 

[TRAIN] Epoch[1](5221/114412); Loss: 0.093721; Backpropagation: 0.2915 sec; Batch: 2.1216 sec
0.1350 0.1333 0.1165 0.1049 0.0959 0.0908 0.0876 0.0855 0.0841 0.0829 0.0822 0.0813 0.0806 0.0801 0.0796 0.0793 

[TRAIN] Epoch[1](5222/114412); Loss: 0.076542; Backpropagation: 0.2912 sec; Batch: 2.1200 sec
0.2234 0.1634 0.1235 0.0824 0.0674 0.0624 0.0592 0.0568 0.0529 0.0509 0.0493 0.0479 0.0470 0.0465 0.0460 0.0456 

[TRAIN] Epoch[1](5223/114412); Loss: 0.093399; Backpropagation: 0.2915 sec; Batch: 2.1305 sec
0.2064 0.1695 0.1306 0.1005 0.0871 0.0825 0.0787 0.0760 0.0745 0.0725 0.0712 0.0705 0.0694 0.0686 0.0683 0.0678 

[TRAIN] Epoch[1](5224/114412); Loss: 0.050902; Backpropagation: 0.2912 sec; Batch: 2.1221 sec
0.1372 0.1013 0.0755 0.0562 0.0441 0.0424 0.0398 0.0385 0.0371 0.0360 0.0353 0.0347 0.0344 0.0341 0.0339 0.0339 

[TRAIN] Epoch[1](5225/114412); Loss: 0.088743; Backpropagation: 0.2912 sec; Batch: 2.1203 sec
0.1586 0.1281 0.1107 0.1004 0.0919 0.0860 0.0811 0.0781 0.0765 0.0752 0.0741 0.0732 0.0723 0.0717 0.0712 0.0709 

[TRAIN] Epoch[1](5226/114412); Loss: 0.070319; Backpropagation: 0.2912 sec; Batch: 2.1254 sec
0.1484 0.1296 0.1063 0.0858 0.0743 0.0632 0.0587 0.0563 0.0540 0.0527 0.0514 0.0505 0.0497 0.0487 0.0480 0.0475 

[TRAIN] Epoch[1](5227/114412); Loss: 0.077218; Backpropagation: 0.2911 sec; Batch: 2.1112 sec
0.1777 0.1392 0.1058 0.0874 0.0776 0.0722 0.0681 0.0631 0.0599 0.0581 0.0568 0.0557 0.0547 0.0537 0.0530 0.0526 

[TRAIN] Epoch[1](5228/114412); Loss: 0.078036; Backpropagation: 0.2912 sec; Batch: 2.1073 sec
0.1792 0.1439 0.1089 0.0934 0.0765 0.0691 0.0666 0.0628 0.0600 0.0583 0.0569 0.0559 0.0553 0.0545 0.0539 0.0534 

[TRAIN] Epoch[1](5229/114412); Loss: 0.082537; Backpropagation: 0.2934 sec; Batch: 2.0798 sec
0.1247 0.1177 0.1046 0.0945 0.0880 0.0820 0.0773 0.0744 0.0724 0.0713 0.0705 0.0700 0.0695 0.0686 0.0680 0.0673 

[TRAIN] Epoch[1](5230/114412); Loss: 0.087201; Backpropagation: 0.2907 sec; Batch: 2.1152 sec
0.2161 0.1552 0.1066 0.0849 0.0782 0.0777 0.0746 0.0726 0.0707 0.0685 0.0672 0.0660 0.0650 0.0644 0.0640 0.0636 

[TRAIN] Epoch[1](5231/114412); Loss: 0.068970; Backpropagation: 0.2904 sec; Batch: 2.1045 sec
0.1257 0.1181 0.1165 0.0967 0.0822 0.0705 0.0629 0.0562 0.0535 0.0509 0.0487 0.0470 0.0451 0.0441 0.0436 0.0420 

[TRAIN] Epoch[1](5232/114412); Loss: 0.086097; Backpropagation: 0.2930 sec; Batch: 2.1179 sec
0.1583 0.1291 0.1066 0.0941 0.0865 0.0806 0.0778 0.0759 0.0744 0.0732 0.0722 0.0712 0.0703 0.0696 0.0689 0.0686 

[TRAIN] Epoch[1](5233/114412); Loss: 0.086620; Backpropagation: 0.2912 sec; Batch: 2.1154 sec
0.1543 0.1353 0.1155 0.1061 0.0971 0.0904 0.0837 0.0775 0.0722 0.0699 0.0675 0.0658 0.0644 0.0631 0.0620 0.0610 

[TRAIN] Epoch[1](5234/114412); Loss: 0.061429; Backpropagation: 0.2912 sec; Batch: 2.0847 sec
0.1401 0.1163 0.0743 0.0655 0.0610 0.0553 0.0528 0.0510 0.0492 0.0480 0.0466 0.0456 0.0448 0.0444 0.0442 0.0438 

[TRAIN] Epoch[1](5235/114412); Loss: 0.078718; Backpropagation: 0.2904 sec; Batch: 2.1153 sec
0.1760 0.1485 0.1033 0.0885 0.0799 0.0743 0.0685 0.0650 0.0613 0.0593 0.0582 0.0572 0.0562 0.0552 0.0543 0.0537 

[TRAIN] Epoch[1](5236/114412); Loss: 0.084060; Backpropagation: 0.2911 sec; Batch: 2.1156 sec
0.1746 0.1649 0.1348 0.1099 0.0894 0.0798 0.0716 0.0659 0.0606 0.0584 0.0585 0.0569 0.0563 0.0551 0.0544 0.0539 

[TRAIN] Epoch[1](5237/114412); Loss: 0.091511; Backpropagation: 0.2952 sec; Batch: 2.0824 sec
0.1914 0.1611 0.1249 0.1044 0.0927 0.0826 0.0785 0.0755 0.0725 0.0709 0.0698 0.0691 0.0685 0.0679 0.0675 0.0669 

[TRAIN] Epoch[1](5238/114412); Loss: 0.075879; Backpropagation: 0.2909 sec; Batch: 2.1156 sec
0.1677 0.1457 0.1028 0.0875 0.0788 0.0719 0.0673 0.0628 0.0602 0.0576 0.0551 0.0535 0.0520 0.0511 0.0505 0.0496 

[TRAIN] Epoch[1](5239/114412); Loss: 0.073557; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1410 0.1077 0.0917 0.0805 0.0745 0.0697 0.0664 0.0643 0.0629 0.0615 0.0609 0.0600 0.0594 0.0591 0.0587 0.0584 

[TRAIN] Epoch[1](5240/114412); Loss: 0.079946; Backpropagation: 0.2909 sec; Batch: 2.1142 sec
0.1692 0.1495 0.1207 0.0973 0.0855 0.0752 0.0693 0.0640 0.0610 0.0588 0.0570 0.0562 0.0550 0.0542 0.0534 0.0528 

[TRAIN] Epoch[1](5241/114412); Loss: 0.062272; Backpropagation: 0.2913 sec; Batch: 2.1210 sec
0.1217 0.0973 0.0957 0.0804 0.0699 0.0598 0.0560 0.0509 0.0488 0.0469 0.0462 0.0458 0.0448 0.0444 0.0440 0.0437 

[TRAIN] Epoch[1](5242/114412); Loss: 0.068994; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1879 0.1251 0.0914 0.0710 0.0626 0.0595 0.0564 0.0542 0.0524 0.0514 0.0504 0.0494 0.0487 0.0482 0.0478 0.0474 

[TRAIN] Epoch[1](5243/114412); Loss: 0.074117; Backpropagation: 0.2906 sec; Batch: 2.1174 sec
0.1449 0.1249 0.1131 0.0914 0.0758 0.0681 0.0646 0.0613 0.0589 0.0575 0.0561 0.0552 0.0542 0.0537 0.0533 0.0527 

[TRAIN] Epoch[1](5244/114412); Loss: 0.076953; Backpropagation: 0.2911 sec; Batch: 2.1100 sec
0.1394 0.1251 0.1105 0.0893 0.0801 0.0737 0.0684 0.0660 0.0640 0.0628 0.0616 0.0603 0.0590 0.0580 0.0569 0.0562 

[TRAIN] Epoch[1](5245/114412); Loss: 0.081011; Backpropagation: 0.2916 sec; Batch: 2.1147 sec
0.2346 0.1707 0.1299 0.0888 0.0672 0.0651 0.0619 0.0584 0.0572 0.0552 0.0536 0.0524 0.0513 0.0505 0.0499 0.0493 

[TRAIN] Epoch[1](5246/114412); Loss: 0.088304; Backpropagation: 0.2913 sec; Batch: 2.0775 sec
0.1720 0.1494 0.1213 0.1038 0.0927 0.0865 0.0799 0.0760 0.0722 0.0695 0.0679 0.0665 0.0652 0.0642 0.0633 0.0625 

[TRAIN] Epoch[1](5247/114412); Loss: 0.078382; Backpropagation: 0.2954 sec; Batch: 2.1212 sec
0.1975 0.1688 0.1237 0.0915 0.0769 0.0698 0.0635 0.0578 0.0543 0.0526 0.0517 0.0505 0.0497 0.0492 0.0485 0.0481 

[TRAIN] Epoch[1](5248/114412); Loss: 0.111592; Backpropagation: 0.2914 sec; Batch: 2.0991 sec
0.1914 0.1726 0.1477 0.1296 0.1173 0.1088 0.1040 0.0988 0.0954 0.0936 0.0915 0.0887 0.0879 0.0869 0.0858 0.0854 

[TRAIN] Epoch[1](5249/114412); Loss: 0.108736; Backpropagation: 0.2915 sec; Batch: 2.1038 sec
0.1822 0.1585 0.1347 0.1180 0.1081 0.1027 0.1002 0.0980 0.0962 0.0947 0.0934 0.0921 0.0914 0.0904 0.0898 0.0892 

[TRAIN] Epoch[1](5250/114412); Loss: 0.092909; Backpropagation: 0.2913 sec; Batch: 2.1206 sec
0.1438 0.1268 0.1122 0.1034 0.0958 0.0906 0.0886 0.0863 0.0838 0.0826 0.0807 0.0800 0.0791 0.0783 0.0776 0.0770 

[TRAIN] Epoch[1](5251/114412); Loss: 0.076044; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1754 0.1498 0.1217 0.0939 0.0750 0.0671 0.0634 0.0592 0.0558 0.0536 0.0522 0.0514 0.0504 0.0498 0.0492 0.0488 

[TRAIN] Epoch[1](5252/114412); Loss: 0.060496; Backpropagation: 0.2909 sec; Batch: 2.1133 sec
0.1168 0.1065 0.0857 0.0723 0.0653 0.0593 0.0543 0.0507 0.0481 0.0467 0.0456 0.0445 0.0438 0.0432 0.0428 0.0424 

[TRAIN] Epoch[1](5253/114412); Loss: 0.074781; Backpropagation: 0.2913 sec; Batch: 2.1619 sec
0.1534 0.1141 0.0980 0.0826 0.0763 0.0713 0.0683 0.0654 0.0633 0.0617 0.0598 0.0582 0.0571 0.0563 0.0556 0.0552 

[TRAIN] Epoch[1](5254/114412); Loss: 0.075986; Backpropagation: 0.2916 sec; Batch: 2.1255 sec
0.1023 0.1059 0.0925 0.0823 0.0779 0.0736 0.0723 0.0706 0.0697 0.0688 0.0679 0.0673 0.0668 0.0663 0.0659 0.0657 

[TRAIN] Epoch[1](5255/114412); Loss: 0.086394; Backpropagation: 0.2912 sec; Batch: 2.1132 sec
0.1965 0.1609 0.1306 0.0994 0.0826 0.0780 0.0731 0.0703 0.0668 0.0644 0.0629 0.0617 0.0600 0.0591 0.0583 0.0577 

[TRAIN] Epoch[1](5256/114412); Loss: 0.084374; Backpropagation: 0.2912 sec; Batch: 2.0825 sec
0.1739 0.1408 0.1191 0.0980 0.0813 0.0764 0.0739 0.0703 0.0683 0.0668 0.0657 0.0644 0.0636 0.0629 0.0624 0.0621 

[TRAIN] Epoch[1](5257/114412); Loss: 0.084600; Backpropagation: 0.2903 sec; Batch: 2.0764 sec
0.1803 0.1396 0.1148 0.0949 0.0842 0.0775 0.0731 0.0715 0.0690 0.0670 0.0653 0.0647 0.0638 0.0630 0.0626 0.0623 

[TRAIN] Epoch[1](5258/114412); Loss: 0.110280; Backpropagation: 0.2910 sec; Batch: 2.1192 sec
0.2355 0.2051 0.1728 0.1369 0.1060 0.0907 0.0882 0.0856 0.0835 0.0824 0.0814 0.0805 0.0799 0.0791 0.0786 0.0783 

[TRAIN] Epoch[1](5259/114412); Loss: 0.098258; Backpropagation: 0.2911 sec; Batch: 2.0773 sec
0.2018 0.1631 0.1350 0.1072 0.0917 0.0869 0.0857 0.0826 0.0810 0.0800 0.0782 0.0770 0.0763 0.0756 0.0752 0.0748 

[TRAIN] Epoch[1](5260/114412); Loss: 0.079616; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1769 0.1521 0.1147 0.0921 0.0819 0.0758 0.0680 0.0649 0.0609 0.0582 0.0571 0.0553 0.0545 0.0544 0.0538 0.0532 

[TRAIN] Epoch[1](5261/114412); Loss: 0.072518; Backpropagation: 0.2909 sec; Batch: 2.0793 sec
0.1219 0.1090 0.0949 0.0860 0.0784 0.0728 0.0683 0.0661 0.0630 0.0609 0.0596 0.0576 0.0566 0.0558 0.0549 0.0543 

[TRAIN] Epoch[1](5262/114412); Loss: 0.084597; Backpropagation: 0.2907 sec; Batch: 2.0812 sec
0.1617 0.1375 0.1084 0.0911 0.0851 0.0802 0.0771 0.0739 0.0716 0.0698 0.0684 0.0671 0.0663 0.0657 0.0650 0.0644 

[TRAIN] Epoch[1](5263/114412); Loss: 0.083497; Backpropagation: 0.2912 sec; Batch: 2.0971 sec
0.1476 0.1221 0.1055 0.0930 0.0833 0.0785 0.0761 0.0743 0.0730 0.0720 0.0705 0.0695 0.0684 0.0678 0.0673 0.0670 

[TRAIN] Epoch[1](5264/114412); Loss: 0.090658; Backpropagation: 0.2912 sec; Batch: 2.1129 sec
0.1663 0.1513 0.1233 0.1069 0.0949 0.0871 0.0822 0.0781 0.0752 0.0734 0.0716 0.0698 0.0690 0.0679 0.0672 0.0664 

[TRAIN] Epoch[1](5265/114412); Loss: 0.085369; Backpropagation: 0.2914 sec; Batch: 2.1067 sec
0.1666 0.1566 0.1229 0.1102 0.0968 0.0874 0.0762 0.0697 0.0656 0.0634 0.0610 0.0596 0.0593 0.0581 0.0568 0.0558 

[TRAIN] Epoch[1](5266/114412); Loss: 0.076932; Backpropagation: 0.2954 sec; Batch: 2.1197 sec
0.1581 0.1261 0.1055 0.0910 0.0818 0.0742 0.0688 0.0644 0.0620 0.0599 0.0584 0.0575 0.0567 0.0559 0.0555 0.0551 

[TRAIN] Epoch[1](5267/114412); Loss: 0.074171; Backpropagation: 0.2920 sec; Batch: 2.1154 sec
0.1538 0.1263 0.1070 0.0897 0.0760 0.0684 0.0643 0.0605 0.0586 0.0572 0.0559 0.0549 0.0542 0.0538 0.0533 0.0529 

[TRAIN] Epoch[1](5268/114412); Loss: 0.072395; Backpropagation: 0.2914 sec; Batch: 2.0963 sec
0.1774 0.1511 0.1081 0.0855 0.0692 0.0609 0.0582 0.0571 0.0542 0.0518 0.0500 0.0487 0.0476 0.0468 0.0461 0.0457 

[TRAIN] Epoch[1](5269/114412); Loss: 0.077315; Backpropagation: 0.2952 sec; Batch: 2.1208 sec
0.1867 0.1686 0.1242 0.0927 0.0725 0.0627 0.0601 0.0588 0.0546 0.0535 0.0523 0.0511 0.0506 0.0500 0.0495 0.0492 

[TRAIN] Epoch[1](5270/114412); Loss: 0.066945; Backpropagation: 0.2927 sec; Batch: 2.1315 sec
0.1428 0.1372 0.0871 0.0691 0.0671 0.0615 0.0584 0.0567 0.0528 0.0517 0.0507 0.0489 0.0477 0.0470 0.0465 0.0458 

[TRAIN] Epoch[1](5271/114412); Loss: 0.092048; Backpropagation: 0.2908 sec; Batch: 2.1195 sec
0.1369 0.1236 0.1106 0.0978 0.0931 0.0904 0.0874 0.0850 0.0838 0.0823 0.0814 0.0810 0.0804 0.0799 0.0797 0.0794 

[TRAIN] Epoch[1](5272/114412); Loss: 0.070131; Backpropagation: 0.2910 sec; Batch: 2.1489 sec
0.1156 0.1036 0.1068 0.0901 0.0796 0.0710 0.0652 0.0620 0.0581 0.0567 0.0551 0.0534 0.0522 0.0516 0.0508 0.0502 

[TRAIN] Epoch[1](5273/114412); Loss: 0.119320; Backpropagation: 0.2910 sec; Batch: 2.1142 sec
0.1992 0.1801 0.1538 0.1375 0.1261 0.1194 0.1139 0.1067 0.1036 0.1008 0.0987 0.0969 0.0948 0.0936 0.0927 0.0914 

[TRAIN] Epoch[1](5274/114412); Loss: 0.056480; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1137 0.0900 0.0713 0.0610 0.0550 0.0525 0.0505 0.0486 0.0473 0.0463 0.0457 0.0450 0.0446 0.0443 0.0440 0.0438 

[TRAIN] Epoch[1](5275/114412); Loss: 0.076257; Backpropagation: 0.2913 sec; Batch: 2.1154 sec
0.1945 0.1627 0.1229 0.0925 0.0707 0.0635 0.0604 0.0564 0.0540 0.0524 0.0504 0.0492 0.0485 0.0478 0.0473 0.0470 

[TRAIN] Epoch[1](5276/114412); Loss: 0.076823; Backpropagation: 0.2914 sec; Batch: 2.1140 sec
0.1519 0.1312 0.0995 0.0884 0.0796 0.0727 0.0683 0.0653 0.0633 0.0616 0.0601 0.0587 0.0580 0.0574 0.0568 0.0562 

[TRAIN] Epoch[1](5277/114412); Loss: 0.065662; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1401 0.1170 0.0920 0.0747 0.0629 0.0578 0.0560 0.0537 0.0521 0.0512 0.0503 0.0495 0.0489 0.0485 0.0480 0.0477 

[TRAIN] Epoch[1](5278/114412); Loss: 0.082443; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1609 0.1355 0.1203 0.1012 0.0879 0.0792 0.0724 0.0693 0.0653 0.0640 0.0627 0.0619 0.0605 0.0598 0.0593 0.0588 

[TRAIN] Epoch[1](5279/114412); Loss: 0.105863; Backpropagation: 0.2932 sec; Batch: 2.1205 sec
0.1936 0.1703 0.1424 0.1241 0.1113 0.1003 0.0954 0.0924 0.0882 0.0849 0.0842 0.0835 0.0815 0.0809 0.0807 0.0799 

[TRAIN] Epoch[1](5280/114412); Loss: 0.075888; Backpropagation: 0.2914 sec; Batch: 2.1188 sec
0.1604 0.1305 0.1040 0.0844 0.0741 0.0685 0.0659 0.0634 0.0616 0.0599 0.0588 0.0579 0.0570 0.0563 0.0559 0.0555 

[TRAIN] Epoch[1](5281/114412); Loss: 0.071744; Backpropagation: 0.2930 sec; Batch: 2.0791 sec
0.1663 0.1361 0.1031 0.0829 0.0717 0.0637 0.0605 0.0574 0.0551 0.0532 0.0519 0.0506 0.0498 0.0493 0.0486 0.0480 

[TRAIN] Epoch[1](5282/114412); Loss: 0.074118; Backpropagation: 0.2930 sec; Batch: 2.1249 sec
0.2005 0.1425 0.1106 0.0793 0.0657 0.0626 0.0591 0.0568 0.0553 0.0537 0.0524 0.0512 0.0501 0.0493 0.0486 0.0480 

[TRAIN] Epoch[1](5283/114412); Loss: 0.079894; Backpropagation: 0.2929 sec; Batch: 2.1463 sec
0.1784 0.1458 0.1124 0.0887 0.0763 0.0720 0.0696 0.0663 0.0634 0.0614 0.0601 0.0587 0.0575 0.0566 0.0558 0.0553 

[TRAIN] Epoch[1](5284/114412); Loss: 0.104240; Backpropagation: 0.2909 sec; Batch: 2.1225 sec
0.1882 0.1625 0.1425 0.1228 0.1090 0.1005 0.0973 0.0930 0.0885 0.0868 0.0841 0.0809 0.0802 0.0788 0.0767 0.0761 

[TRAIN] Epoch[1](5285/114412); Loss: 0.066367; Backpropagation: 0.2904 sec; Batch: 2.1369 sec
0.1608 0.1307 0.1006 0.0754 0.0629 0.0601 0.0549 0.0521 0.0497 0.0480 0.0464 0.0456 0.0448 0.0440 0.0433 0.0427 

[TRAIN] Epoch[1](5286/114412); Loss: 0.084687; Backpropagation: 0.2914 sec; Batch: 2.1261 sec
0.1923 0.1589 0.1343 0.1082 0.0874 0.0736 0.0694 0.0675 0.0641 0.0616 0.0592 0.0575 0.0565 0.0554 0.0549 0.0542 

[TRAIN] Epoch[1](5287/114412); Loss: 0.107865; Backpropagation: 0.2907 sec; Batch: 2.1174 sec
0.1789 0.1570 0.1361 0.1246 0.1136 0.1070 0.1029 0.0979 0.0952 0.0923 0.0901 0.0888 0.0873 0.0856 0.0847 0.0839 

[TRAIN] Epoch[1](5288/114412); Loss: 0.077296; Backpropagation: 0.2931 sec; Batch: 2.1492 sec
0.2026 0.1614 0.1195 0.0883 0.0715 0.0651 0.0618 0.0593 0.0564 0.0540 0.0523 0.0508 0.0498 0.0489 0.0479 0.0471 

[TRAIN] Epoch[1](5289/114412); Loss: 0.073441; Backpropagation: 0.2913 sec; Batch: 2.0918 sec
0.2177 0.1686 0.1254 0.0882 0.0653 0.0585 0.0557 0.0498 0.0470 0.0460 0.0444 0.0431 0.0423 0.0415 0.0410 0.0406 

[TRAIN] Epoch[1](5290/114412); Loss: 0.093201; Backpropagation: 0.2907 sec; Batch: 2.1036 sec
0.1976 0.1665 0.1381 0.1086 0.0915 0.0830 0.0789 0.0760 0.0729 0.0710 0.0699 0.0688 0.0680 0.0674 0.0669 0.0662 

[TRAIN] Epoch[1](5291/114412); Loss: 0.081762; Backpropagation: 0.2909 sec; Batch: 2.1162 sec
0.1749 0.1405 0.1105 0.0912 0.0803 0.0747 0.0716 0.0691 0.0665 0.0649 0.0636 0.0621 0.0610 0.0599 0.0591 0.0585 

[TRAIN] Epoch[1](5292/114412); Loss: 0.089541; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.2091 0.1768 0.1496 0.1179 0.0964 0.0772 0.0686 0.0653 0.0648 0.0610 0.0600 0.0593 0.0580 0.0571 0.0562 0.0554 

[TRAIN] Epoch[1](5293/114412); Loss: 0.074430; Backpropagation: 0.2913 sec; Batch: 2.1151 sec
0.1483 0.1315 0.0978 0.0847 0.0760 0.0706 0.0674 0.0636 0.0608 0.0589 0.0576 0.0566 0.0553 0.0545 0.0540 0.0533 

[TRAIN] Epoch[1](5294/114412); Loss: 0.076430; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1522 0.1347 0.1036 0.0904 0.0812 0.0728 0.0694 0.0651 0.0611 0.0594 0.0581 0.0566 0.0557 0.0547 0.0542 0.0537 

[TRAIN] Epoch[1](5295/114412); Loss: 0.085714; Backpropagation: 0.2907 sec; Batch: 2.0766 sec
0.1755 0.1409 0.1216 0.0978 0.0871 0.0796 0.0742 0.0717 0.0699 0.0681 0.0664 0.0655 0.0645 0.0634 0.0629 0.0623 

[TRAIN] Epoch[1](5296/114412); Loss: 0.075404; Backpropagation: 0.2936 sec; Batch: 2.1191 sec
0.1646 0.1377 0.1199 0.0993 0.0794 0.0737 0.0676 0.0641 0.0596 0.0559 0.0511 0.0500 0.0492 0.0469 0.0448 0.0428 

[TRAIN] Epoch[1](5297/114412); Loss: 0.073196; Backpropagation: 0.2926 sec; Batch: 2.1122 sec
0.1886 0.1450 0.1118 0.0868 0.0729 0.0650 0.0588 0.0557 0.0527 0.0508 0.0491 0.0483 0.0472 0.0466 0.0461 0.0458 

[TRAIN] Epoch[1](5298/114412); Loss: 0.074765; Backpropagation: 0.2928 sec; Batch: 2.1227 sec
0.1820 0.1438 0.1003 0.0776 0.0701 0.0675 0.0628 0.0595 0.0577 0.0561 0.0548 0.0538 0.0533 0.0528 0.0523 0.0518 

[TRAIN] Epoch[1](5299/114412); Loss: 0.057355; Backpropagation: 0.2912 sec; Batch: 2.1154 sec
0.1355 0.1287 0.0844 0.0652 0.0566 0.0521 0.0460 0.0437 0.0407 0.0396 0.0392 0.0384 0.0375 0.0370 0.0368 0.0363 

[TRAIN] Epoch[1](5300/114412); Loss: 0.069068; Backpropagation: 0.2930 sec; Batch: 2.1195 sec
0.1242 0.1096 0.0962 0.0832 0.0722 0.0664 0.0618 0.0593 0.0577 0.0559 0.0547 0.0539 0.0534 0.0528 0.0521 0.0516 

[TRAIN] Epoch[1](5301/114412); Loss: 0.097958; Backpropagation: 0.2931 sec; Batch: 2.1190 sec
0.1615 0.1504 0.1361 0.1188 0.1072 0.0977 0.0914 0.0881 0.0853 0.0825 0.0798 0.0773 0.0755 0.0738 0.0717 0.0702 

[TRAIN] Epoch[1](5302/114412); Loss: 0.088391; Backpropagation: 0.2912 sec; Batch: 2.1263 sec
0.1699 0.1460 0.1237 0.1063 0.0915 0.0843 0.0784 0.0749 0.0721 0.0700 0.0684 0.0673 0.0662 0.0656 0.0651 0.0645 

[TRAIN] Epoch[1](5303/114412); Loss: 0.075702; Backpropagation: 0.2909 sec; Batch: 2.1248 sec
0.1617 0.1282 0.0978 0.0810 0.0701 0.0678 0.0652 0.0631 0.0621 0.0609 0.0603 0.0595 0.0589 0.0585 0.0582 0.0579 

[TRAIN] Epoch[1](5304/114412); Loss: 0.074206; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1701 0.1404 0.1023 0.0854 0.0724 0.0652 0.0622 0.0600 0.0570 0.0559 0.0544 0.0535 0.0529 0.0524 0.0519 0.0515 

[TRAIN] Epoch[1](5305/114412); Loss: 0.084362; Backpropagation: 0.2904 sec; Batch: 2.0763 sec
0.2173 0.1465 0.1099 0.0833 0.0773 0.0748 0.0705 0.0676 0.0666 0.0654 0.0641 0.0628 0.0619 0.0610 0.0607 0.0603 

[TRAIN] Epoch[1](5306/114412); Loss: 0.090993; Backpropagation: 0.2909 sec; Batch: 2.1139 sec
0.1574 0.1406 0.1270 0.1113 0.0980 0.0909 0.0849 0.0797 0.0769 0.0743 0.0725 0.0710 0.0690 0.0680 0.0676 0.0669 

[TRAIN] Epoch[1](5307/114412); Loss: 0.072578; Backpropagation: 0.2908 sec; Batch: 2.1179 sec
0.1620 0.1430 0.1103 0.0855 0.0688 0.0641 0.0619 0.0587 0.0547 0.0532 0.0518 0.0507 0.0498 0.0493 0.0488 0.0486 

[TRAIN] Epoch[1](5308/114412); Loss: 0.098360; Backpropagation: 0.2910 sec; Batch: 2.1143 sec
0.1826 0.1582 0.1326 0.1116 0.0977 0.0918 0.0888 0.0853 0.0832 0.0811 0.0796 0.0781 0.0770 0.0761 0.0754 0.0747 

[TRAIN] Epoch[1](5309/114412); Loss: 0.087687; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1588 0.1412 0.1128 0.1006 0.0920 0.0854 0.0814 0.0769 0.0738 0.0718 0.0704 0.0693 0.0682 0.0675 0.0668 0.0664 

[TRAIN] Epoch[1](5310/114412); Loss: 0.077607; Backpropagation: 0.2909 sec; Batch: 2.1313 sec
0.1285 0.1064 0.0925 0.0857 0.0786 0.0744 0.0728 0.0708 0.0695 0.0682 0.0673 0.0664 0.0658 0.0654 0.0648 0.0645 

[TRAIN] Epoch[1](5311/114412); Loss: 0.079997; Backpropagation: 0.2928 sec; Batch: 2.0868 sec
0.1517 0.1279 0.1045 0.0923 0.0844 0.0758 0.0725 0.0702 0.0656 0.0648 0.0636 0.0619 0.0621 0.0617 0.0605 0.0604 

[TRAIN] Epoch[1](5312/114412); Loss: 0.078300; Backpropagation: 0.2931 sec; Batch: 2.0861 sec
0.1704 0.1444 0.1095 0.0931 0.0797 0.0729 0.0672 0.0642 0.0613 0.0595 0.0576 0.0564 0.0553 0.0544 0.0537 0.0532 

[TRAIN] Epoch[1](5313/114412); Loss: 0.073620; Backpropagation: 0.2911 sec; Batch: 2.1143 sec
0.1300 0.1169 0.0946 0.0809 0.0763 0.0705 0.0675 0.0652 0.0625 0.0613 0.0603 0.0591 0.0589 0.0584 0.0578 0.0575 

[TRAIN] Epoch[1](5314/114412); Loss: 0.068963; Backpropagation: 0.2906 sec; Batch: 2.1137 sec
0.1256 0.1053 0.0920 0.0787 0.0718 0.0649 0.0629 0.0606 0.0583 0.0569 0.0562 0.0551 0.0543 0.0540 0.0536 0.0532 

[TRAIN] Epoch[1](5315/114412); Loss: 0.081594; Backpropagation: 0.2908 sec; Batch: 2.1143 sec
0.1624 0.1497 0.1267 0.1062 0.0888 0.0760 0.0698 0.0656 0.0627 0.0600 0.0580 0.0570 0.0562 0.0558 0.0555 0.0550 

[TRAIN] Epoch[1](5316/114412); Loss: 0.061114; Backpropagation: 0.2925 sec; Batch: 2.1226 sec
0.1138 0.1012 0.0774 0.0669 0.0605 0.0567 0.0545 0.0524 0.0513 0.0505 0.0497 0.0491 0.0490 0.0485 0.0483 0.0481 

[TRAIN] Epoch[1](5317/114412); Loss: 0.069809; Backpropagation: 0.2933 sec; Batch: 2.1182 sec
0.1663 0.1445 0.0904 0.0768 0.0707 0.0627 0.0579 0.0556 0.0536 0.0513 0.0503 0.0485 0.0479 0.0474 0.0468 0.0463 

[TRAIN] Epoch[1](5318/114412); Loss: 0.072979; Backpropagation: 0.2952 sec; Batch: 2.1189 sec
0.1553 0.1345 0.0960 0.0760 0.0717 0.0671 0.0631 0.0610 0.0588 0.0575 0.0563 0.0550 0.0544 0.0541 0.0536 0.0533 

[TRAIN] Epoch[1](5319/114412); Loss: 0.107617; Backpropagation: 0.2926 sec; Batch: 2.1199 sec
0.1907 0.1714 0.1521 0.1291 0.1122 0.1064 0.1032 0.0959 0.0930 0.0892 0.0846 0.0824 0.0808 0.0785 0.0768 0.0755 

[TRAIN] Epoch[1](5320/114412); Loss: 0.078122; Backpropagation: 0.2955 sec; Batch: 2.1194 sec
0.1368 0.1167 0.1011 0.0890 0.0794 0.0736 0.0709 0.0693 0.0673 0.0658 0.0651 0.0641 0.0635 0.0630 0.0624 0.0620 

[TRAIN] Epoch[1](5321/114412); Loss: 0.089515; Backpropagation: 0.2925 sec; Batch: 2.1194 sec
0.1841 0.1585 0.1163 0.0974 0.0892 0.0839 0.0793 0.0741 0.0730 0.0716 0.0698 0.0687 0.0679 0.0669 0.0662 0.0655 

[TRAIN] Epoch[1](5322/114412); Loss: 0.074161; Backpropagation: 0.2910 sec; Batch: 2.1155 sec
0.1569 0.1189 0.0935 0.0813 0.0732 0.0685 0.0652 0.0630 0.0612 0.0598 0.0590 0.0583 0.0574 0.0571 0.0569 0.0566 

[TRAIN] Epoch[1](5323/114412); Loss: 0.073433; Backpropagation: 0.2907 sec; Batch: 2.0974 sec
0.1395 0.1210 0.0991 0.0837 0.0752 0.0718 0.0666 0.0638 0.0611 0.0594 0.0580 0.0564 0.0557 0.0550 0.0546 0.0542 

[TRAIN] Epoch[1](5324/114412); Loss: 0.076791; Backpropagation: 0.2908 sec; Batch: 2.0769 sec
0.1506 0.1298 0.1170 0.0958 0.0840 0.0756 0.0709 0.0642 0.0610 0.0585 0.0568 0.0552 0.0531 0.0528 0.0523 0.0512 

[TRAIN] Epoch[1](5325/114412); Loss: 0.066245; Backpropagation: 0.2913 sec; Batch: 2.1186 sec
0.1843 0.1327 0.0899 0.0693 0.0598 0.0625 0.0543 0.0506 0.0478 0.0465 0.0455 0.0445 0.0439 0.0431 0.0428 0.0424 

[TRAIN] Epoch[1](5326/114412); Loss: 0.070158; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1968 0.1484 0.1003 0.0695 0.0648 0.0595 0.0584 0.0542 0.0510 0.0486 0.0473 0.0461 0.0456 0.0445 0.0440 0.0435 

[TRAIN] Epoch[1](5327/114412); Loss: 0.075622; Backpropagation: 0.2928 sec; Batch: 2.1063 sec
0.1522 0.1319 0.1039 0.0865 0.0753 0.0703 0.0658 0.0631 0.0611 0.0598 0.0584 0.0576 0.0568 0.0563 0.0558 0.0553 

[TRAIN] Epoch[1](5328/114412); Loss: 0.083120; Backpropagation: 0.2909 sec; Batch: 2.1191 sec
0.1521 0.1343 0.1133 0.0976 0.0883 0.0807 0.0758 0.0722 0.0699 0.0677 0.0659 0.0646 0.0631 0.0623 0.0614 0.0606 

[TRAIN] Epoch[1](5329/114412); Loss: 0.063018; Backpropagation: 0.2908 sec; Batch: 2.1073 sec
0.1495 0.1152 0.0865 0.0699 0.0605 0.0561 0.0529 0.0507 0.0491 0.0471 0.0463 0.0458 0.0451 0.0448 0.0445 0.0442 

[TRAIN] Epoch[1](5330/114412); Loss: 0.078724; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1626 0.1372 0.1045 0.0833 0.0768 0.0732 0.0696 0.0669 0.0651 0.0633 0.0621 0.0606 0.0596 0.0589 0.0582 0.0575 

[TRAIN] Epoch[1](5331/114412); Loss: 0.091908; Backpropagation: 0.2907 sec; Batch: 2.1131 sec
0.1628 0.1416 0.1242 0.1086 0.0956 0.0900 0.0853 0.0814 0.0788 0.0762 0.0741 0.0720 0.0713 0.0707 0.0693 0.0687 

[TRAIN] Epoch[1](5332/114412); Loss: 0.100533; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.1595 0.1466 0.1257 0.1135 0.1046 0.0992 0.0943 0.0911 0.0891 0.0871 0.0857 0.0842 0.0832 0.0823 0.0816 0.0809 

[TRAIN] Epoch[1](5333/114412); Loss: 0.095393; Backpropagation: 0.2930 sec; Batch: 2.1244 sec
0.1988 0.1553 0.1293 0.1111 0.1011 0.0924 0.0862 0.0839 0.0779 0.0747 0.0728 0.0711 0.0691 0.0684 0.0675 0.0667 

[TRAIN] Epoch[1](5334/114412); Loss: 0.091730; Backpropagation: 0.2908 sec; Batch: 2.1181 sec
0.1531 0.1395 0.1180 0.1043 0.0961 0.0913 0.0852 0.0823 0.0798 0.0776 0.0761 0.0748 0.0737 0.0728 0.0718 0.0712 

[TRAIN] Epoch[1](5335/114412); Loss: 0.083206; Backpropagation: 0.2905 sec; Batch: 2.1453 sec
0.1623 0.1290 0.1028 0.0914 0.0866 0.0806 0.0770 0.0736 0.0707 0.0690 0.0674 0.0659 0.0648 0.0640 0.0634 0.0628 

[TRAIN] Epoch[1](5336/114412); Loss: 0.064844; Backpropagation: 0.2907 sec; Batch: 2.1142 sec
0.1238 0.1123 0.0895 0.0794 0.0682 0.0608 0.0582 0.0564 0.0533 0.0512 0.0499 0.0487 0.0472 0.0467 0.0462 0.0456 

[TRAIN] Epoch[1](5337/114412); Loss: 0.086962; Backpropagation: 0.2910 sec; Batch: 2.1206 sec
0.1622 0.1445 0.1127 0.0990 0.0844 0.0796 0.0770 0.0746 0.0731 0.0713 0.0701 0.0696 0.0689 0.0684 0.0682 0.0678 

[TRAIN] Epoch[1](5338/114412); Loss: 0.070447; Backpropagation: 0.2932 sec; Batch: 2.1209 sec
0.1585 0.1287 0.0930 0.0785 0.0692 0.0643 0.0603 0.0579 0.0554 0.0538 0.0526 0.0518 0.0513 0.0508 0.0505 0.0504 

[TRAIN] Epoch[1](5339/114412); Loss: 0.067902; Backpropagation: 0.2914 sec; Batch: 2.1189 sec
0.1524 0.1350 0.1093 0.0862 0.0759 0.0667 0.0586 0.0528 0.0490 0.0465 0.0449 0.0435 0.0425 0.0418 0.0410 0.0405 

[TRAIN] Epoch[1](5340/114412); Loss: 0.088078; Backpropagation: 0.2931 sec; Batch: 2.1190 sec
0.1485 0.1338 0.1171 0.1044 0.0941 0.0878 0.0821 0.0777 0.0750 0.0729 0.0714 0.0702 0.0693 0.0688 0.0682 0.0679 

[TRAIN] Epoch[1](5341/114412); Loss: 0.090953; Backpropagation: 0.2910 sec; Batch: 2.1191 sec
0.1757 0.1543 0.1131 0.0988 0.0880 0.0839 0.0810 0.0783 0.0762 0.0750 0.0739 0.0725 0.0716 0.0711 0.0710 0.0708 

[TRAIN] Epoch[1](5342/114412); Loss: 0.067612; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1640 0.1236 0.0875 0.0783 0.0685 0.0611 0.0577 0.0557 0.0523 0.0506 0.0493 0.0478 0.0469 0.0465 0.0461 0.0458 

[TRAIN] Epoch[1](5343/114412); Loss: 0.070089; Backpropagation: 0.2914 sec; Batch: 2.1139 sec
0.1532 0.1251 0.1019 0.0800 0.0712 0.0640 0.0609 0.0580 0.0555 0.0533 0.0515 0.0505 0.0501 0.0493 0.0486 0.0484 

[TRAIN] Epoch[1](5344/114412); Loss: 0.094119; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1871 0.1633 0.1383 0.1162 0.0961 0.0872 0.0796 0.0762 0.0748 0.0731 0.0718 0.0705 0.0692 0.0684 0.0674 0.0665 

[TRAIN] Epoch[1](5345/114412); Loss: 0.092711; Backpropagation: 0.2933 sec; Batch: 2.1286 sec
0.1844 0.1567 0.1185 0.0991 0.0932 0.0874 0.0833 0.0785 0.0768 0.0755 0.0738 0.0725 0.0719 0.0711 0.0706 0.0702 

[TRAIN] Epoch[1](5346/114412); Loss: 0.082737; Backpropagation: 0.2911 sec; Batch: 2.1227 sec
0.1885 0.1420 0.1142 0.0919 0.0820 0.0765 0.0715 0.0675 0.0651 0.0635 0.0625 0.0612 0.0605 0.0596 0.0590 0.0585 

[TRAIN] Epoch[1](5347/114412); Loss: 0.075320; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1376 0.1214 0.1044 0.0921 0.0779 0.0721 0.0685 0.0657 0.0633 0.0608 0.0591 0.0578 0.0571 0.0563 0.0557 0.0552 

[TRAIN] Epoch[1](5348/114412); Loss: 0.075161; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1471 0.1138 0.1069 0.0936 0.0796 0.0730 0.0684 0.0648 0.0629 0.0608 0.0580 0.0565 0.0553 0.0545 0.0538 0.0535 

[TRAIN] Epoch[1](5349/114412); Loss: 0.086854; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.1535 0.1383 0.1203 0.1050 0.0895 0.0826 0.0795 0.0766 0.0735 0.0702 0.0690 0.0680 0.0668 0.0661 0.0657 0.0652 

[TRAIN] Epoch[1](5350/114412); Loss: 0.068855; Backpropagation: 0.2910 sec; Batch: 2.1147 sec
0.1153 0.0933 0.0831 0.0771 0.0718 0.0680 0.0653 0.0633 0.0612 0.0599 0.0589 0.0580 0.0572 0.0568 0.0564 0.0560 

[TRAIN] Epoch[1](5351/114412); Loss: 0.059271; Backpropagation: 0.2904 sec; Batch: 2.1158 sec
0.1386 0.1165 0.0960 0.0722 0.0619 0.0544 0.0484 0.0460 0.0433 0.0414 0.0402 0.0392 0.0384 0.0377 0.0373 0.0370 

[TRAIN] Epoch[1](5352/114412); Loss: 0.084348; Backpropagation: 0.2911 sec; Batch: 2.0782 sec
0.1292 0.1162 0.1047 0.0945 0.0878 0.0816 0.0787 0.0770 0.0757 0.0742 0.0733 0.0726 0.0719 0.0712 0.0706 0.0703 

[TRAIN] Epoch[1](5353/114412); Loss: 0.082077; Backpropagation: 0.2913 sec; Batch: 2.1219 sec
0.1462 0.1383 0.1072 0.0944 0.0847 0.0789 0.0756 0.0723 0.0687 0.0668 0.0656 0.0645 0.0635 0.0629 0.0621 0.0614 

[TRAIN] Epoch[1](5354/114412); Loss: 0.056546; Backpropagation: 0.2908 sec; Batch: 2.1246 sec
0.1168 0.1100 0.0903 0.0775 0.0630 0.0533 0.0482 0.0449 0.0420 0.0401 0.0382 0.0371 0.0365 0.0360 0.0355 0.0351 

[TRAIN] Epoch[1](5355/114412); Loss: 0.092089; Backpropagation: 0.2951 sec; Batch: 2.1224 sec
0.1716 0.1426 0.1240 0.1075 0.0969 0.0888 0.0829 0.0794 0.0764 0.0746 0.0734 0.0724 0.0715 0.0709 0.0705 0.0700 

[TRAIN] Epoch[1](5356/114412); Loss: 0.058840; Backpropagation: 0.2930 sec; Batch: 2.1232 sec
0.1447 0.1044 0.0811 0.0678 0.0604 0.0550 0.0505 0.0469 0.0443 0.0427 0.0423 0.0412 0.0405 0.0402 0.0400 0.0396 

[TRAIN] Epoch[1](5357/114412); Loss: 0.100997; Backpropagation: 0.2931 sec; Batch: 2.1177 sec
0.1725 0.1476 0.1217 0.1092 0.1018 0.0973 0.0943 0.0917 0.0892 0.0876 0.0862 0.0850 0.0840 0.0832 0.0826 0.0821 

[TRAIN] Epoch[1](5358/114412); Loss: 0.086557; Backpropagation: 0.2906 sec; Batch: 2.1389 sec
0.2324 0.1626 0.1166 0.0885 0.0777 0.0726 0.0709 0.0687 0.0657 0.0638 0.0624 0.0614 0.0608 0.0605 0.0603 0.0600 

[TRAIN] Epoch[1](5359/114412); Loss: 0.093906; Backpropagation: 0.2907 sec; Batch: 2.1178 sec
0.1501 0.1366 0.1222 0.1087 0.1010 0.0944 0.0886 0.0855 0.0827 0.0805 0.0783 0.0770 0.0756 0.0747 0.0737 0.0729 

[TRAIN] Epoch[1](5360/114412); Loss: 0.059833; Backpropagation: 0.2951 sec; Batch: 2.1225 sec
0.1073 0.0930 0.0995 0.0849 0.0696 0.0573 0.0529 0.0495 0.0468 0.0453 0.0440 0.0426 0.0418 0.0413 0.0409 0.0405 

[TRAIN] Epoch[1](5361/114412); Loss: 0.074674; Backpropagation: 0.2916 sec; Batch: 2.0803 sec
0.1744 0.1422 0.1103 0.0854 0.0717 0.0680 0.0629 0.0594 0.0568 0.0544 0.0536 0.0524 0.0516 0.0511 0.0505 0.0501 

[TRAIN] Epoch[1](5362/114412); Loss: 0.084176; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.1564 0.1322 0.1119 0.0980 0.0888 0.0823 0.0771 0.0737 0.0698 0.0682 0.0670 0.0658 0.0645 0.0640 0.0637 0.0633 

[TRAIN] Epoch[1](5363/114412); Loss: 0.076499; Backpropagation: 0.2907 sec; Batch: 2.1224 sec
0.1259 0.1232 0.1039 0.0895 0.0792 0.0727 0.0687 0.0666 0.0648 0.0635 0.0623 0.0615 0.0611 0.0607 0.0603 0.0600 

[TRAIN] Epoch[1](5364/114412); Loss: 0.083956; Backpropagation: 0.2913 sec; Batch: 2.0781 sec
0.1963 0.1465 0.1260 0.1021 0.0945 0.0855 0.0779 0.0689 0.0636 0.0600 0.0573 0.0548 0.0535 0.0529 0.0520 0.0515 

[TRAIN] Epoch[1](5365/114412); Loss: 0.089120; Backpropagation: 0.2909 sec; Batch: 2.0834 sec
0.2425 0.2062 0.1449 0.1062 0.0848 0.0820 0.0707 0.0655 0.0606 0.0576 0.0558 0.0533 0.0508 0.0492 0.0486 0.0473 

[TRAIN] Epoch[1](5366/114412); Loss: 0.086203; Backpropagation: 0.2904 sec; Batch: 2.0771 sec
0.1598 0.1372 0.1212 0.1075 0.0887 0.0791 0.0759 0.0735 0.0704 0.0688 0.0678 0.0667 0.0661 0.0657 0.0655 0.0653 

[TRAIN] Epoch[1](5367/114412); Loss: 0.076749; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1522 0.1158 0.0965 0.0859 0.0794 0.0739 0.0700 0.0669 0.0642 0.0630 0.0616 0.0606 0.0602 0.0595 0.0592 0.0591 

[TRAIN] Epoch[1](5368/114412); Loss: 0.073783; Backpropagation: 0.2910 sec; Batch: 2.1149 sec
0.1627 0.1173 0.0924 0.0812 0.0725 0.0676 0.0641 0.0619 0.0603 0.0592 0.0584 0.0575 0.0570 0.0565 0.0561 0.0560 

[TRAIN] Epoch[1](5369/114412); Loss: 0.043817; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1115 0.0847 0.0662 0.0511 0.0447 0.0399 0.0364 0.0334 0.0318 0.0308 0.0298 0.0290 0.0285 0.0281 0.0277 0.0275 

[TRAIN] Epoch[1](5370/114412); Loss: 0.091845; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1597 0.1378 0.1152 0.1036 0.0965 0.0905 0.0854 0.0828 0.0793 0.0777 0.0762 0.0746 0.0739 0.0731 0.0721 0.0712 

[TRAIN] Epoch[1](5371/114412); Loss: 0.077978; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.2111 0.1513 0.1085 0.0873 0.0762 0.0676 0.0627 0.0591 0.0576 0.0547 0.0539 0.0531 0.0519 0.0513 0.0509 0.0503 

[TRAIN] Epoch[1](5372/114412); Loss: 0.090359; Backpropagation: 0.2910 sec; Batch: 2.1154 sec
0.1490 0.1300 0.1078 0.0971 0.0926 0.0889 0.0863 0.0831 0.0807 0.0789 0.0774 0.0766 0.0752 0.0746 0.0741 0.0734 

[TRAIN] Epoch[1](5373/114412); Loss: 0.082094; Backpropagation: 0.2905 sec; Batch: 2.1335 sec
0.1443 0.1212 0.1037 0.0931 0.0870 0.0806 0.0769 0.0740 0.0707 0.0687 0.0675 0.0665 0.0657 0.0650 0.0645 0.0641 

[TRAIN] Epoch[1](5374/114412); Loss: 0.091363; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.2007 0.1487 0.1138 0.0878 0.0849 0.0828 0.0798 0.0781 0.0754 0.0747 0.0738 0.0731 0.0726 0.0722 0.0719 0.0717 

[TRAIN] Epoch[1](5375/114412); Loss: 0.061025; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1076 0.0933 0.0797 0.0727 0.0642 0.0590 0.0565 0.0537 0.0517 0.0505 0.0495 0.0486 0.0478 0.0475 0.0471 0.0468 

[TRAIN] Epoch[1](5376/114412); Loss: 0.096738; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1522 0.1328 0.1139 0.1061 0.0993 0.0938 0.0911 0.0888 0.0867 0.0854 0.0844 0.0836 0.0830 0.0826 0.0822 0.0819 

[TRAIN] Epoch[1](5377/114412); Loss: 0.063484; Backpropagation: 0.2908 sec; Batch: 2.1220 sec
0.1389 0.1255 0.0943 0.0745 0.0643 0.0563 0.0526 0.0500 0.0479 0.0471 0.0463 0.0453 0.0443 0.0434 0.0428 0.0422 

[TRAIN] Epoch[1](5378/114412); Loss: 0.088462; Backpropagation: 0.2914 sec; Batch: 2.1293 sec
0.1692 0.1481 0.1234 0.1035 0.0940 0.0875 0.0817 0.0782 0.0748 0.0707 0.0683 0.0663 0.0639 0.0632 0.0619 0.0607 

[TRAIN] Epoch[1](5379/114412); Loss: 0.072682; Backpropagation: 0.2910 sec; Batch: 2.0797 sec
0.1610 0.1087 0.0883 0.0790 0.0713 0.0692 0.0662 0.0628 0.0604 0.0590 0.0579 0.0569 0.0560 0.0557 0.0554 0.0551 

[TRAIN] Epoch[1](5380/114412); Loss: 0.055048; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1350 0.1025 0.0808 0.0661 0.0571 0.0503 0.0460 0.0428 0.0409 0.0397 0.0385 0.0376 0.0369 0.0361 0.0354 0.0349 

[TRAIN] Epoch[1](5381/114412); Loss: 0.085497; Backpropagation: 0.2907 sec; Batch: 2.1213 sec
0.1440 0.1266 0.1182 0.0979 0.0883 0.0839 0.0789 0.0765 0.0736 0.0723 0.0705 0.0689 0.0682 0.0671 0.0666 0.0663 

[TRAIN] Epoch[1](5382/114412); Loss: 0.067424; Backpropagation: 0.2927 sec; Batch: 2.1225 sec
0.1471 0.1287 0.0850 0.0731 0.0676 0.0623 0.0581 0.0552 0.0537 0.0526 0.0512 0.0500 0.0494 0.0487 0.0483 0.0478 

[TRAIN] Epoch[1](5383/114412); Loss: 0.060622; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1076 0.0896 0.0832 0.0703 0.0644 0.0586 0.0562 0.0538 0.0512 0.0499 0.0489 0.0481 0.0475 0.0472 0.0469 0.0464 

[TRAIN] Epoch[1](5384/114412); Loss: 0.059055; Backpropagation: 0.2907 sec; Batch: 2.0776 sec
0.1105 0.0995 0.0832 0.0707 0.0623 0.0562 0.0529 0.0499 0.0481 0.0467 0.0455 0.0448 0.0443 0.0439 0.0434 0.0432 

[TRAIN] Epoch[1](5385/114412); Loss: 0.068594; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.2002 0.1694 0.1013 0.0690 0.0612 0.0567 0.0525 0.0483 0.0463 0.0442 0.0430 0.0421 0.0414 0.0411 0.0405 0.0403 

[TRAIN] Epoch[1](5386/114412); Loss: 0.080347; Backpropagation: 0.2919 sec; Batch: 2.0786 sec
0.2144 0.1568 0.1066 0.0839 0.0794 0.0708 0.0653 0.0628 0.0604 0.0583 0.0565 0.0556 0.0545 0.0538 0.0534 0.0530 

[TRAIN] Epoch[1](5387/114412); Loss: 0.076268; Backpropagation: 0.2905 sec; Batch: 2.1037 sec
0.1453 0.1223 0.0914 0.0831 0.0765 0.0719 0.0681 0.0663 0.0647 0.0633 0.0623 0.0617 0.0612 0.0609 0.0607 0.0606 

[TRAIN] Epoch[1](5388/114412); Loss: 0.071142; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.1308 0.1137 0.0898 0.0794 0.0718 0.0678 0.0648 0.0620 0.0601 0.0590 0.0579 0.0571 0.0566 0.0560 0.0557 0.0555 

[TRAIN] Epoch[1](5389/114412); Loss: 0.061700; Backpropagation: 0.2913 sec; Batch: 2.1196 sec
0.1702 0.1378 0.0880 0.0669 0.0568 0.0522 0.0477 0.0447 0.0424 0.0414 0.0406 0.0403 0.0401 0.0395 0.0393 0.0392 

[TRAIN] Epoch[1](5390/114412); Loss: 0.088078; Backpropagation: 0.2907 sec; Batch: 2.1204 sec
0.1409 0.1194 0.1031 0.0950 0.0895 0.0854 0.0836 0.0809 0.0795 0.0784 0.0773 0.0763 0.0759 0.0751 0.0747 0.0743 

[TRAIN] Epoch[1](5391/114412); Loss: 0.080746; Backpropagation: 0.2931 sec; Batch: 2.1198 sec
0.1813 0.1296 0.0943 0.0836 0.0784 0.0753 0.0713 0.0687 0.0671 0.0658 0.0643 0.0635 0.0630 0.0623 0.0619 0.0615 

[TRAIN] Epoch[1](5392/114412); Loss: 0.085241; Backpropagation: 0.2908 sec; Batch: 2.1149 sec
0.1880 0.1370 0.1089 0.0946 0.0853 0.0795 0.0753 0.0721 0.0697 0.0678 0.0663 0.0653 0.0644 0.0637 0.0632 0.0629 

[TRAIN] Epoch[1](5393/114412); Loss: 0.068220; Backpropagation: 0.2905 sec; Batch: 2.0772 sec
0.1829 0.1235 0.0919 0.0779 0.0675 0.0617 0.0573 0.0541 0.0511 0.0494 0.0478 0.0467 0.0458 0.0451 0.0446 0.0442 

[TRAIN] Epoch[1](5394/114412); Loss: 0.066033; Backpropagation: 0.2906 sec; Batch: 2.1146 sec
0.1313 0.1170 0.1010 0.0850 0.0717 0.0604 0.0559 0.0531 0.0512 0.0501 0.0484 0.0475 0.0469 0.0460 0.0456 0.0454 

[TRAIN] Epoch[1](5395/114412); Loss: 0.073415; Backpropagation: 0.2907 sec; Batch: 2.1296 sec
0.1359 0.1198 0.1004 0.0837 0.0740 0.0698 0.0659 0.0633 0.0614 0.0599 0.0586 0.0577 0.0566 0.0563 0.0560 0.0555 

[TRAIN] Epoch[1](5396/114412); Loss: 0.082524; Backpropagation: 0.2907 sec; Batch: 2.0774 sec
0.1699 0.1338 0.1055 0.0927 0.0837 0.0782 0.0747 0.0724 0.0681 0.0666 0.0649 0.0635 0.0625 0.0619 0.0614 0.0608 

[TRAIN] Epoch[1](5397/114412); Loss: 0.078764; Backpropagation: 0.2905 sec; Batch: 2.1179 sec
0.1614 0.1306 0.1036 0.0868 0.0796 0.0744 0.0701 0.0670 0.0642 0.0628 0.0615 0.0606 0.0600 0.0596 0.0592 0.0589 

[TRAIN] Epoch[1](5398/114412); Loss: 0.065840; Backpropagation: 0.2905 sec; Batch: 2.0774 sec
0.1253 0.1166 0.0909 0.0773 0.0694 0.0619 0.0588 0.0560 0.0535 0.0519 0.0504 0.0494 0.0488 0.0481 0.0477 0.0474 

[TRAIN] Epoch[1](5399/114412); Loss: 0.090810; Backpropagation: 0.2916 sec; Batch: 2.1188 sec
0.1439 0.1276 0.1256 0.1145 0.1025 0.0924 0.0866 0.0830 0.0793 0.0765 0.0743 0.0719 0.0704 0.0694 0.0680 0.0670 

[TRAIN] Epoch[1](5400/114412); Loss: 0.085020; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1816 0.1476 0.1181 0.1047 0.0932 0.0814 0.0735 0.0689 0.0664 0.0640 0.0625 0.0611 0.0604 0.0596 0.0589 0.0585 

[TRAIN] Epoch[1](5401/114412); Loss: 0.081110; Backpropagation: 0.2908 sec; Batch: 2.0778 sec
0.1449 0.1237 0.1001 0.0910 0.0853 0.0792 0.0751 0.0720 0.0695 0.0678 0.0667 0.0658 0.0649 0.0643 0.0639 0.0636 

[TRAIN] Epoch[1](5402/114412); Loss: 0.072329; Backpropagation: 0.2913 sec; Batch: 2.1191 sec
0.1346 0.1132 0.1036 0.0899 0.0792 0.0694 0.0647 0.0608 0.0591 0.0573 0.0561 0.0551 0.0544 0.0537 0.0532 0.0528 

[TRAIN] Epoch[1](5403/114412); Loss: 0.080688; Backpropagation: 0.2907 sec; Batch: 2.0813 sec
0.1701 0.1490 0.1192 0.1037 0.0917 0.0792 0.0723 0.0683 0.0656 0.0628 0.0588 0.0565 0.0522 0.0492 0.0470 0.0453 

[TRAIN] Epoch[1](5404/114412); Loss: 0.079696; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.1550 0.1327 0.1073 0.0941 0.0877 0.0818 0.0745 0.0696 0.0666 0.0632 0.0606 0.0584 0.0572 0.0562 0.0554 0.0549 

[TRAIN] Epoch[1](5405/114412); Loss: 0.087171; Backpropagation: 0.2907 sec; Batch: 2.1166 sec
0.1913 0.1408 0.1141 0.0996 0.0909 0.0833 0.0780 0.0744 0.0709 0.0687 0.0672 0.0647 0.0637 0.0630 0.0623 0.0618 

[TRAIN] Epoch[1](5406/114412); Loss: 0.070643; Backpropagation: 0.2936 sec; Batch: 2.1211 sec
0.1421 0.1184 0.0962 0.0797 0.0724 0.0659 0.0618 0.0601 0.0581 0.0562 0.0548 0.0539 0.0534 0.0528 0.0524 0.0521 

[TRAIN] Epoch[1](5407/114412); Loss: 0.046504; Backpropagation: 0.2909 sec; Batch: 2.1359 sec
0.1388 0.0811 0.0629 0.0504 0.0445 0.0429 0.0376 0.0356 0.0340 0.0327 0.0316 0.0310 0.0308 0.0303 0.0301 0.0298 

[TRAIN] Epoch[1](5408/114412); Loss: 0.059424; Backpropagation: 0.2958 sec; Batch: 2.1025 sec
0.1547 0.1226 0.0778 0.0644 0.0559 0.0505 0.0491 0.0455 0.0444 0.0426 0.0419 0.0410 0.0405 0.0401 0.0400 0.0397 

[TRAIN] Epoch[1](5409/114412); Loss: 0.075139; Backpropagation: 0.2905 sec; Batch: 2.0773 sec
0.1461 0.1361 0.1228 0.1067 0.0876 0.0770 0.0650 0.0596 0.0567 0.0547 0.0513 0.0497 0.0487 0.0474 0.0467 0.0461 

[TRAIN] Epoch[1](5410/114412); Loss: 0.074671; Backpropagation: 0.2905 sec; Batch: 2.1150 sec
0.1624 0.1165 0.0960 0.0839 0.0763 0.0708 0.0665 0.0640 0.0614 0.0598 0.0583 0.0570 0.0562 0.0558 0.0552 0.0545 

[TRAIN] Epoch[1](5411/114412); Loss: 0.079516; Backpropagation: 0.2905 sec; Batch: 2.1164 sec
0.1505 0.1266 0.1076 0.0920 0.0841 0.0767 0.0724 0.0691 0.0659 0.0643 0.0631 0.0613 0.0605 0.0602 0.0591 0.0589 

[TRAIN] Epoch[1](5412/114412); Loss: 0.096542; Backpropagation: 0.2904 sec; Batch: 2.1143 sec
0.1999 0.1667 0.1359 0.1076 0.0995 0.0929 0.0872 0.0821 0.0800 0.0770 0.0731 0.0714 0.0699 0.0680 0.0673 0.0662 

[TRAIN] Epoch[1](5413/114412); Loss: 0.079143; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.1675 0.1201 0.0944 0.0862 0.0803 0.0747 0.0712 0.0684 0.0664 0.0649 0.0637 0.0626 0.0620 0.0617 0.0612 0.0609 

[TRAIN] Epoch[1](5414/114412); Loss: 0.062717; Backpropagation: 0.2925 sec; Batch: 2.1241 sec
0.1219 0.1066 0.0858 0.0746 0.0648 0.0602 0.0564 0.0533 0.0513 0.0499 0.0481 0.0473 0.0465 0.0461 0.0455 0.0452 

[TRAIN] Epoch[1](5415/114412); Loss: 0.068931; Backpropagation: 0.2907 sec; Batch: 2.0771 sec
0.1838 0.1490 0.0973 0.0722 0.0604 0.0565 0.0541 0.0517 0.0497 0.0487 0.0478 0.0471 0.0467 0.0463 0.0459 0.0457 

[TRAIN] Epoch[1](5416/114412); Loss: 0.083328; Backpropagation: 0.2912 sec; Batch: 2.1302 sec
0.1757 0.1451 0.1099 0.0947 0.0857 0.0792 0.0733 0.0696 0.0675 0.0656 0.0638 0.0621 0.0613 0.0605 0.0598 0.0595 

[TRAIN] Epoch[1](5417/114412); Loss: 0.077817; Backpropagation: 0.2909 sec; Batch: 2.1181 sec
0.1315 0.1176 0.0973 0.0858 0.0790 0.0742 0.0728 0.0701 0.0680 0.0670 0.0654 0.0645 0.0637 0.0629 0.0629 0.0624 

[TRAIN] Epoch[1](5418/114412); Loss: 0.071988; Backpropagation: 0.2916 sec; Batch: 2.1175 sec
0.1810 0.1381 0.0973 0.0810 0.0700 0.0627 0.0586 0.0558 0.0548 0.0529 0.0514 0.0505 0.0498 0.0495 0.0492 0.0492 

[TRAIN] Epoch[1](5419/114412); Loss: 0.079521; Backpropagation: 0.2908 sec; Batch: 2.0807 sec
0.1914 0.1437 0.1091 0.0864 0.0793 0.0713 0.0666 0.0635 0.0618 0.0600 0.0584 0.0574 0.0563 0.0562 0.0556 0.0552 

[TRAIN] Epoch[1](5420/114412); Loss: 0.083898; Backpropagation: 0.2906 sec; Batch: 2.0781 sec
0.1649 0.1421 0.1195 0.1079 0.0943 0.0831 0.0744 0.0694 0.0655 0.0639 0.0622 0.0606 0.0597 0.0589 0.0584 0.0576 

[TRAIN] Epoch[1](5421/114412); Loss: 0.079088; Backpropagation: 0.2908 sec; Batch: 2.0777 sec
0.1978 0.1650 0.1153 0.0921 0.0734 0.0707 0.0650 0.0619 0.0568 0.0550 0.0548 0.0531 0.0520 0.0513 0.0507 0.0503 

[TRAIN] Epoch[1](5422/114412); Loss: 0.103707; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1938 0.1715 0.1360 0.1166 0.1061 0.0993 0.0936 0.0882 0.0859 0.0845 0.0832 0.0819 0.0807 0.0801 0.0793 0.0786 

[TRAIN] Epoch[1](5423/114412); Loss: 0.076764; Backpropagation: 0.2909 sec; Batch: 2.0844 sec
0.1531 0.1192 0.1001 0.0890 0.0799 0.0743 0.0691 0.0657 0.0634 0.0616 0.0604 0.0596 0.0591 0.0584 0.0579 0.0575 

[TRAIN] Epoch[1](5424/114412); Loss: 0.069781; Backpropagation: 0.2903 sec; Batch: 2.1176 sec
0.1514 0.1159 0.0898 0.0758 0.0684 0.0634 0.0609 0.0585 0.0572 0.0558 0.0548 0.0540 0.0533 0.0527 0.0525 0.0520 

[TRAIN] Epoch[1](5425/114412); Loss: 0.067962; Backpropagation: 0.2931 sec; Batch: 2.1155 sec
0.1478 0.1290 0.1051 0.0810 0.0657 0.0614 0.0573 0.0541 0.0522 0.0506 0.0493 0.0483 0.0474 0.0467 0.0461 0.0455 

[TRAIN] Epoch[1](5426/114412); Loss: 0.072857; Backpropagation: 0.2932 sec; Batch: 2.1142 sec
0.1784 0.1514 0.0989 0.0786 0.0710 0.0639 0.0587 0.0564 0.0546 0.0533 0.0519 0.0510 0.0502 0.0495 0.0491 0.0488 

[TRAIN] Epoch[1](5427/114412); Loss: 0.064134; Backpropagation: 0.2915 sec; Batch: 2.1199 sec
0.1726 0.1220 0.1061 0.0807 0.0647 0.0529 0.0495 0.0471 0.0447 0.0434 0.0419 0.0411 0.0404 0.0397 0.0396 0.0394 

[TRAIN] Epoch[1](5428/114412); Loss: 0.050988; Backpropagation: 0.2926 sec; Batch: 2.1226 sec
0.1501 0.0930 0.0687 0.0558 0.0495 0.0443 0.0412 0.0387 0.0372 0.0358 0.0351 0.0341 0.0334 0.0331 0.0330 0.0328 

[TRAIN] Epoch[1](5429/114412); Loss: 0.072858; Backpropagation: 0.2910 sec; Batch: 2.0936 sec
0.1227 0.1155 0.1065 0.0953 0.0818 0.0720 0.0679 0.0628 0.0599 0.0573 0.0561 0.0548 0.0542 0.0536 0.0530 0.0524 

[TRAIN] Epoch[1](5430/114412); Loss: 0.084883; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1589 0.1217 0.1055 0.0956 0.0895 0.0838 0.0794 0.0767 0.0739 0.0716 0.0696 0.0682 0.0671 0.0662 0.0655 0.0649 

[TRAIN] Epoch[1](5431/114412); Loss: 0.062728; Backpropagation: 0.2940 sec; Batch: 2.0807 sec
0.1686 0.1329 0.0851 0.0725 0.0660 0.0587 0.0520 0.0461 0.0441 0.0420 0.0410 0.0401 0.0395 0.0389 0.0383 0.0380 

[TRAIN] Epoch[1](5432/114412); Loss: 0.083118; Backpropagation: 0.2927 sec; Batch: 2.1359 sec
0.1851 0.1658 0.1418 0.1141 0.0958 0.0851 0.0682 0.0629 0.0588 0.0571 0.0541 0.0516 0.0493 0.0478 0.0462 0.0458 

[TRAIN] Epoch[1](5433/114412); Loss: 0.059717; Backpropagation: 0.2907 sec; Batch: 2.1182 sec
0.1649 0.1511 0.0998 0.0672 0.0563 0.0473 0.0435 0.0403 0.0395 0.0370 0.0364 0.0359 0.0348 0.0343 0.0337 0.0334 

[TRAIN] Epoch[1](5434/114412); Loss: 0.081156; Backpropagation: 0.2907 sec; Batch: 2.1169 sec
0.1632 0.1308 0.1032 0.0926 0.0843 0.0778 0.0731 0.0695 0.0674 0.0650 0.0641 0.0628 0.0620 0.0613 0.0609 0.0604 

[TRAIN] Epoch[1](5435/114412); Loss: 0.094909; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.2016 0.1657 0.1383 0.0996 0.0965 0.0915 0.0839 0.0808 0.0771 0.0762 0.0726 0.0690 0.0679 0.0672 0.0658 0.0648 

[TRAIN] Epoch[1](5436/114412); Loss: 0.078024; Backpropagation: 0.2913 sec; Batch: 2.1401 sec
0.1831 0.1426 0.1087 0.0933 0.0831 0.0726 0.0651 0.0611 0.0589 0.0571 0.0558 0.0548 0.0539 0.0532 0.0527 0.0523 

[TRAIN] Epoch[1](5437/114412); Loss: 0.066898; Backpropagation: 0.2909 sec; Batch: 2.3095 sec
0.1730 0.1550 0.1023 0.0805 0.0662 0.0555 0.0499 0.0483 0.0471 0.0443 0.0434 0.0423 0.0413 0.0410 0.0403 0.0400 

[TRAIN] Epoch[1](5438/114412); Loss: 0.090542; Backpropagation: 0.2955 sec; Batch: 2.4346 sec
0.2000 0.1658 0.1246 0.1031 0.0912 0.0839 0.0780 0.0748 0.0716 0.0694 0.0673 0.0657 0.0646 0.0635 0.0630 0.0621 

[TRAIN] Epoch[1](5439/114412); Loss: 0.075250; Backpropagation: 0.2929 sec; Batch: 2.1240 sec
0.1303 0.1059 0.0916 0.0824 0.0793 0.0737 0.0706 0.0675 0.0658 0.0647 0.0636 0.0628 0.0621 0.0617 0.0612 0.0608 

[TRAIN] Epoch[1](5440/114412); Loss: 0.080412; Backpropagation: 0.2906 sec; Batch: 2.1404 sec
0.1315 0.1108 0.1085 0.0998 0.0911 0.0779 0.0744 0.0704 0.0687 0.0674 0.0659 0.0650 0.0644 0.0638 0.0635 0.0632 

[TRAIN] Epoch[1](5441/114412); Loss: 0.076233; Backpropagation: 0.2914 sec; Batch: 2.1452 sec
0.1274 0.1230 0.1056 0.0915 0.0842 0.0753 0.0707 0.0662 0.0639 0.0615 0.0606 0.0594 0.0586 0.0579 0.0572 0.0568 

[TRAIN] Epoch[1](5442/114412); Loss: 0.088260; Backpropagation: 0.2910 sec; Batch: 2.2155 sec
0.1429 0.1209 0.1054 0.0980 0.0911 0.0860 0.0834 0.0805 0.0788 0.0773 0.0762 0.0753 0.0747 0.0743 0.0738 0.0736 

[TRAIN] Epoch[1](5443/114412); Loss: 0.084728; Backpropagation: 0.2908 sec; Batch: 2.1448 sec
0.1457 0.1279 0.1149 0.0964 0.0915 0.0815 0.0772 0.0744 0.0721 0.0708 0.0695 0.0682 0.0674 0.0667 0.0659 0.0656 

[TRAIN] Epoch[1](5444/114412); Loss: 0.105803; Backpropagation: 0.2905 sec; Batch: 2.2332 sec
0.1674 0.1541 0.1336 0.1226 0.1107 0.1054 0.1009 0.0961 0.0934 0.0912 0.0891 0.0878 0.0863 0.0853 0.0849 0.0840 

[TRAIN] Epoch[1](5445/114412); Loss: 0.107555; Backpropagation: 0.2929 sec; Batch: 2.1181 sec
0.1440 0.1322 0.1265 0.1176 0.1112 0.1081 0.1046 0.1031 0.1012 0.0989 0.0984 0.0969 0.0953 0.0951 0.0941 0.0936 

[TRAIN] Epoch[1](5446/114412); Loss: 0.071477; Backpropagation: 0.2952 sec; Batch: 2.0942 sec
0.1489 0.1240 0.1023 0.0842 0.0786 0.0693 0.0623 0.0586 0.0559 0.0542 0.0532 0.0518 0.0511 0.0504 0.0497 0.0493 

[TRAIN] Epoch[1](5447/114412); Loss: 0.085048; Backpropagation: 0.2912 sec; Batch: 2.1225 sec
0.1818 0.1363 0.1094 0.0949 0.0853 0.0786 0.0750 0.0715 0.0693 0.0676 0.0667 0.0660 0.0654 0.0647 0.0643 0.0640 

[TRAIN] Epoch[1](5448/114412); Loss: 0.050633; Backpropagation: 0.2908 sec; Batch: 2.1176 sec
0.1336 0.0915 0.0668 0.0590 0.0519 0.0446 0.0426 0.0394 0.0381 0.0374 0.0354 0.0349 0.0344 0.0338 0.0335 0.0332 

[TRAIN] Epoch[1](5449/114412); Loss: 0.073738; Backpropagation: 0.2910 sec; Batch: 2.1145 sec
0.1638 0.1232 0.0934 0.0803 0.0739 0.0690 0.0651 0.0618 0.0594 0.0581 0.0568 0.0559 0.0553 0.0550 0.0547 0.0544 

[TRAIN] Epoch[1](5450/114412); Loss: 0.059529; Backpropagation: 0.2911 sec; Batch: 2.1311 sec
0.1202 0.1121 0.0883 0.0743 0.0640 0.0537 0.0504 0.0478 0.0458 0.0444 0.0435 0.0425 0.0419 0.0415 0.0411 0.0410 

[TRAIN] Epoch[1](5451/114412); Loss: 0.070983; Backpropagation: 0.2910 sec; Batch: 2.1196 sec
0.1479 0.1192 0.0924 0.0776 0.0714 0.0674 0.0637 0.0600 0.0580 0.0564 0.0552 0.0544 0.0538 0.0532 0.0527 0.0524 

[TRAIN] Epoch[1](5452/114412); Loss: 0.074071; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1519 0.1348 0.0936 0.0812 0.0743 0.0704 0.0635 0.0608 0.0590 0.0581 0.0576 0.0570 0.0563 0.0560 0.0556 0.0552 

[TRAIN] Epoch[1](5453/114412); Loss: 0.076365; Backpropagation: 0.2932 sec; Batch: 2.1276 sec
0.2169 0.1465 0.1069 0.0873 0.0724 0.0670 0.0611 0.0587 0.0556 0.0539 0.0523 0.0501 0.0493 0.0484 0.0480 0.0477 

[TRAIN] Epoch[1](5454/114412); Loss: 0.083768; Backpropagation: 0.2925 sec; Batch: 2.1241 sec
0.1596 0.1401 0.1103 0.0943 0.0867 0.0821 0.0753 0.0735 0.0710 0.0681 0.0662 0.0644 0.0633 0.0623 0.0618 0.0614 

[TRAIN] Epoch[1](5455/114412); Loss: 0.070862; Backpropagation: 0.2942 sec; Batch: 2.0800 sec
0.1560 0.1088 0.0888 0.0782 0.0725 0.0666 0.0640 0.0610 0.0578 0.0564 0.0556 0.0546 0.0541 0.0535 0.0531 0.0528 

[TRAIN] Epoch[1](5456/114412); Loss: 0.081494; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1655 0.1465 0.1142 0.0973 0.0833 0.0746 0.0702 0.0667 0.0644 0.0632 0.0621 0.0608 0.0598 0.0590 0.0584 0.0579 

[TRAIN] Epoch[1](5457/114412); Loss: 0.073487; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1748 0.1301 0.0928 0.0804 0.0728 0.0672 0.0628 0.0600 0.0579 0.0563 0.0553 0.0541 0.0534 0.0531 0.0526 0.0523 

[TRAIN] Epoch[1](5458/114412); Loss: 0.074162; Backpropagation: 0.2911 sec; Batch: 2.1249 sec
0.1703 0.1291 0.1025 0.0839 0.0736 0.0687 0.0626 0.0609 0.0590 0.0572 0.0556 0.0542 0.0534 0.0525 0.0518 0.0514 

[TRAIN] Epoch[1](5459/114412); Loss: 0.060620; Backpropagation: 0.2905 sec; Batch: 2.1208 sec
0.1569 0.1261 0.0925 0.0698 0.0590 0.0533 0.0490 0.0454 0.0433 0.0419 0.0406 0.0397 0.0390 0.0383 0.0378 0.0373 

[TRAIN] Epoch[1](5460/114412); Loss: 0.085458; Backpropagation: 0.2904 sec; Batch: 2.0768 sec
0.1475 0.1349 0.1152 0.1009 0.0929 0.0832 0.0776 0.0747 0.0718 0.0705 0.0692 0.0675 0.0666 0.0657 0.0650 0.0643 

[TRAIN] Epoch[1](5461/114412); Loss: 0.084942; Backpropagation: 0.2920 sec; Batch: 2.1165 sec
0.2139 0.1769 0.1260 0.0909 0.0811 0.0742 0.0690 0.0647 0.0618 0.0603 0.0588 0.0578 0.0570 0.0561 0.0555 0.0551 

[TRAIN] Epoch[1](5462/114412); Loss: 0.053852; Backpropagation: 0.2906 sec; Batch: 2.0767 sec
0.1766 0.1214 0.0773 0.0576 0.0489 0.0445 0.0397 0.0368 0.0354 0.0340 0.0331 0.0323 0.0316 0.0311 0.0308 0.0305 

[TRAIN] Epoch[1](5463/114412); Loss: 0.070879; Backpropagation: 0.2932 sec; Batch: 2.1180 sec
0.1532 0.1288 0.0992 0.0848 0.0717 0.0656 0.0617 0.0586 0.0553 0.0535 0.0525 0.0514 0.0503 0.0497 0.0491 0.0486 

[TRAIN] Epoch[1](5464/114412); Loss: 0.068540; Backpropagation: 0.2931 sec; Batch: 2.1170 sec
0.1830 0.1205 0.0883 0.0861 0.0733 0.0651 0.0597 0.0557 0.0518 0.0493 0.0478 0.0450 0.0438 0.0433 0.0422 0.0416 

[TRAIN] Epoch[1](5465/114412); Loss: 0.072703; Backpropagation: 0.2908 sec; Batch: 2.1204 sec
0.1222 0.1148 0.0966 0.0839 0.0753 0.0703 0.0671 0.0637 0.0612 0.0600 0.0591 0.0586 0.0582 0.0577 0.0574 0.0572 

[TRAIN] Epoch[1](5466/114412); Loss: 0.075211; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.1271 0.1186 0.0985 0.0850 0.0767 0.0714 0.0685 0.0666 0.0649 0.0633 0.0622 0.0613 0.0607 0.0599 0.0595 0.0591 

[TRAIN] Epoch[1](5467/114412); Loss: 0.056436; Backpropagation: 0.2905 sec; Batch: 2.1221 sec
0.1176 0.0981 0.0812 0.0688 0.0604 0.0538 0.0491 0.0464 0.0445 0.0430 0.0418 0.0409 0.0401 0.0395 0.0389 0.0387 

[TRAIN] Epoch[1](5468/114412); Loss: 0.066407; Backpropagation: 0.2954 sec; Batch: 2.1213 sec
0.1151 0.1032 0.1138 0.0952 0.0822 0.0653 0.0558 0.0531 0.0507 0.0494 0.0480 0.0471 0.0464 0.0461 0.0457 0.0454 

[TRAIN] Epoch[1](5469/114412); Loss: 0.091141; Backpropagation: 0.2932 sec; Batch: 2.0798 sec
0.1957 0.1278 0.1044 0.0958 0.0906 0.0856 0.0821 0.0802 0.0777 0.0764 0.0751 0.0742 0.0734 0.0731 0.0732 0.0730 

[TRAIN] Epoch[1](5470/114412); Loss: 0.091739; Backpropagation: 0.2927 sec; Batch: 2.1156 sec
0.1766 0.1579 0.1273 0.1065 0.0917 0.0849 0.0797 0.0765 0.0738 0.0727 0.0716 0.0709 0.0702 0.0696 0.0692 0.0688 

[TRAIN] Epoch[1](5471/114412); Loss: 0.071420; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1392 0.1121 0.0944 0.0813 0.0744 0.0690 0.0642 0.0607 0.0588 0.0578 0.0569 0.0560 0.0554 0.0547 0.0541 0.0536 

[TRAIN] Epoch[1](5472/114412); Loss: 0.054325; Backpropagation: 0.2931 sec; Batch: 2.1152 sec
0.1402 0.0889 0.0804 0.0657 0.0588 0.0489 0.0445 0.0429 0.0401 0.0391 0.0384 0.0372 0.0368 0.0363 0.0356 0.0353 

[TRAIN] Epoch[1](5473/114412); Loss: 0.072083; Backpropagation: 0.2929 sec; Batch: 2.1207 sec
0.1414 0.1140 0.0888 0.0831 0.0759 0.0704 0.0664 0.0633 0.0604 0.0588 0.0572 0.0561 0.0553 0.0546 0.0540 0.0537 

[TRAIN] Epoch[1](5474/114412); Loss: 0.053792; Backpropagation: 0.2913 sec; Batch: 2.1203 sec
0.1125 0.1071 0.0788 0.0667 0.0571 0.0501 0.0460 0.0433 0.0409 0.0394 0.0381 0.0373 0.0365 0.0359 0.0355 0.0353 

[TRAIN] Epoch[1](5475/114412); Loss: 0.057749; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1630 0.1113 0.0770 0.0613 0.0537 0.0485 0.0469 0.0448 0.0430 0.0419 0.0405 0.0395 0.0389 0.0383 0.0381 0.0374 

[TRAIN] Epoch[1](5476/114412); Loss: 0.087469; Backpropagation: 0.2910 sec; Batch: 2.1130 sec
0.1928 0.1536 0.1231 0.1049 0.0921 0.0845 0.0776 0.0744 0.0683 0.0668 0.0654 0.0618 0.0604 0.0594 0.0579 0.0564 

[TRAIN] Epoch[1](5477/114412); Loss: 0.072447; Backpropagation: 0.2911 sec; Batch: 2.1185 sec
0.1349 0.1303 0.1007 0.0837 0.0722 0.0656 0.0628 0.0606 0.0591 0.0577 0.0569 0.0558 0.0553 0.0549 0.0545 0.0541 

[TRAIN] Epoch[1](5478/114412); Loss: 0.079178; Backpropagation: 0.2912 sec; Batch: 2.1223 sec
0.2012 0.1539 0.1224 0.0866 0.0788 0.0730 0.0661 0.0616 0.0575 0.0556 0.0534 0.0525 0.0521 0.0513 0.0507 0.0502 

[TRAIN] Epoch[1](5479/114412); Loss: 0.045284; Backpropagation: 0.2907 sec; Batch: 2.1159 sec
0.1300 0.0802 0.0590 0.0484 0.0439 0.0420 0.0381 0.0351 0.0337 0.0327 0.0315 0.0309 0.0304 0.0300 0.0294 0.0291 

[TRAIN] Epoch[1](5480/114412); Loss: 0.063467; Backpropagation: 0.2914 sec; Batch: 2.0821 sec
0.1602 0.1085 0.0894 0.0710 0.0635 0.0558 0.0544 0.0513 0.0480 0.0477 0.0457 0.0451 0.0446 0.0437 0.0435 0.0430 

[TRAIN] Epoch[1](5481/114412); Loss: 0.093155; Backpropagation: 0.2914 sec; Batch: 2.1208 sec
0.1827 0.1640 0.1329 0.1062 0.0907 0.0840 0.0807 0.0773 0.0751 0.0735 0.0725 0.0717 0.0705 0.0700 0.0695 0.0692 

[TRAIN] Epoch[1](5482/114412); Loss: 0.119190; Backpropagation: 0.2930 sec; Batch: 2.0961 sec
0.1873 0.1708 0.1468 0.1357 0.1255 0.1161 0.1118 0.1094 0.1048 0.1034 0.1020 0.1000 0.0992 0.0988 0.0979 0.0975 

[TRAIN] Epoch[1](5483/114412); Loss: 0.072553; Backpropagation: 0.2916 sec; Batch: 2.1159 sec
0.1331 0.1134 0.0991 0.0828 0.0784 0.0688 0.0655 0.0629 0.0605 0.0595 0.0582 0.0572 0.0563 0.0556 0.0551 0.0546 

[TRAIN] Epoch[1](5484/114412); Loss: 0.088514; Backpropagation: 0.2909 sec; Batch: 2.1154 sec
0.1648 0.1358 0.1100 0.0989 0.0923 0.0866 0.0819 0.0787 0.0762 0.0741 0.0723 0.0710 0.0698 0.0687 0.0678 0.0673 

[TRAIN] Epoch[1](5485/114412); Loss: 0.077363; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.1656 0.1198 0.0936 0.0861 0.0789 0.0732 0.0691 0.0661 0.0641 0.0625 0.0616 0.0605 0.0599 0.0594 0.0589 0.0585 

[TRAIN] Epoch[1](5486/114412); Loss: 0.074101; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1379 0.1222 0.0940 0.0829 0.0756 0.0707 0.0668 0.0650 0.0625 0.0608 0.0601 0.0590 0.0582 0.0572 0.0566 0.0561 

[TRAIN] Epoch[1](5487/114412); Loss: 0.067689; Backpropagation: 0.2912 sec; Batch: 2.1146 sec
0.1726 0.1133 0.0781 0.0708 0.0673 0.0602 0.0574 0.0550 0.0536 0.0523 0.0516 0.0508 0.0505 0.0502 0.0499 0.0496 

[TRAIN] Epoch[1](5488/114412); Loss: 0.078061; Backpropagation: 0.2907 sec; Batch: 2.1205 sec
0.1598 0.1131 0.0915 0.0861 0.0808 0.0755 0.0712 0.0684 0.0662 0.0648 0.0637 0.0627 0.0620 0.0615 0.0610 0.0607 

[TRAIN] Epoch[1](5489/114412); Loss: 0.091531; Backpropagation: 0.2908 sec; Batch: 2.1226 sec
0.2289 0.1536 0.1098 0.1042 0.0884 0.0815 0.0780 0.0761 0.0734 0.0708 0.0691 0.0678 0.0669 0.0659 0.0652 0.0648 

[TRAIN] Epoch[1](5490/114412); Loss: 0.074748; Backpropagation: 0.2928 sec; Batch: 2.0800 sec
0.1509 0.1074 0.0911 0.0822 0.0774 0.0719 0.0694 0.0666 0.0639 0.0623 0.0609 0.0597 0.0589 0.0583 0.0578 0.0573 

[TRAIN] Epoch[1](5491/114412); Loss: 0.079966; Backpropagation: 0.2930 sec; Batch: 2.1311 sec
0.1496 0.1183 0.1039 0.0926 0.0849 0.0789 0.0753 0.0713 0.0681 0.0664 0.0643 0.0630 0.0620 0.0609 0.0600 0.0597 

[TRAIN] Epoch[1](5492/114412); Loss: 0.083868; Backpropagation: 0.2905 sec; Batch: 2.1157 sec
0.1433 0.1188 0.1038 0.0927 0.0859 0.0810 0.0780 0.0756 0.0743 0.0729 0.0713 0.0704 0.0694 0.0687 0.0682 0.0676 

[TRAIN] Epoch[1](5493/114412); Loss: 0.076278; Backpropagation: 0.2915 sec; Batch: 2.1186 sec
0.1591 0.1395 0.1100 0.0868 0.0775 0.0713 0.0662 0.0629 0.0595 0.0580 0.0570 0.0557 0.0551 0.0544 0.0538 0.0535 

[TRAIN] Epoch[1](5494/114412); Loss: 0.088146; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1631 0.1361 0.1103 0.0976 0.0897 0.0842 0.0802 0.0773 0.0754 0.0739 0.0724 0.0712 0.0707 0.0701 0.0692 0.0689 

[TRAIN] Epoch[1](5495/114412); Loss: 0.076650; Backpropagation: 0.2904 sec; Batch: 2.0770 sec
0.1601 0.1250 0.1048 0.0888 0.0795 0.0719 0.0667 0.0648 0.0622 0.0608 0.0594 0.0580 0.0574 0.0563 0.0556 0.0551 

[TRAIN] Epoch[1](5496/114412); Loss: 0.074716; Backpropagation: 0.2913 sec; Batch: 2.0816 sec
0.1837 0.1337 0.0950 0.0763 0.0719 0.0660 0.0617 0.0595 0.0584 0.0574 0.0569 0.0561 0.0554 0.0550 0.0544 0.0542 

[TRAIN] Epoch[1](5497/114412); Loss: 0.094400; Backpropagation: 0.2912 sec; Batch: 2.0781 sec
0.1417 0.1309 0.1148 0.1081 0.0970 0.0916 0.0888 0.0864 0.0848 0.0834 0.0821 0.0812 0.0806 0.0802 0.0796 0.0794 

[TRAIN] Epoch[1](5498/114412); Loss: 0.058100; Backpropagation: 0.2913 sec; Batch: 2.1101 sec
0.1650 0.0983 0.0745 0.0591 0.0557 0.0502 0.0480 0.0458 0.0442 0.0431 0.0422 0.0415 0.0410 0.0406 0.0404 0.0401 

[TRAIN] Epoch[1](5499/114412); Loss: 0.061700; Backpropagation: 0.2905 sec; Batch: 2.1194 sec
0.1705 0.1191 0.0767 0.0668 0.0600 0.0541 0.0502 0.0476 0.0460 0.0444 0.0435 0.0427 0.0421 0.0416 0.0411 0.0407 

[TRAIN] Epoch[1](5500/114412); Loss: 0.084682; Backpropagation: 0.2914 sec; Batch: 2.1264 sec
0.1685 0.1611 0.1307 0.1095 0.0905 0.0794 0.0705 0.0666 0.0640 0.0622 0.0607 0.0598 0.0589 0.0581 0.0574 0.0570 

[TRAIN] Epoch[1](5501/114412); Loss: 0.060009; Backpropagation: 0.2914 sec; Batch: 2.1187 sec
0.1100 0.1001 0.0786 0.0658 0.0601 0.0564 0.0540 0.0521 0.0507 0.0494 0.0484 0.0478 0.0472 0.0469 0.0466 0.0462 

[TRAIN] Epoch[1](5502/114412); Loss: 0.058233; Backpropagation: 0.2913 sec; Batch: 2.0823 sec
0.1429 0.1334 0.0978 0.0700 0.0555 0.0497 0.0443 0.0432 0.0403 0.0386 0.0379 0.0368 0.0362 0.0357 0.0350 0.0347 

[TRAIN] Epoch[1](5503/114412); Loss: 0.067067; Backpropagation: 0.2914 sec; Batch: 2.1161 sec
0.1451 0.1157 0.0990 0.0791 0.0688 0.0604 0.0567 0.0535 0.0517 0.0509 0.0500 0.0492 0.0488 0.0483 0.0480 0.0478 

[TRAIN] Epoch[1](5504/114412); Loss: 0.083960; Backpropagation: 0.2953 sec; Batch: 2.1226 sec
0.1625 0.1333 0.0985 0.0888 0.0833 0.0792 0.0759 0.0736 0.0721 0.0704 0.0693 0.0686 0.0677 0.0670 0.0666 0.0665 

[TRAIN] Epoch[1](5505/114412); Loss: 0.064461; Backpropagation: 0.2922 sec; Batch: 2.1180 sec
0.1303 0.0971 0.0870 0.0724 0.0659 0.0612 0.0576 0.0550 0.0537 0.0524 0.0512 0.0504 0.0500 0.0495 0.0490 0.0488 

[TRAIN] Epoch[1](5506/114412); Loss: 0.057925; Backpropagation: 0.2915 sec; Batch: 2.0966 sec
0.1079 0.0977 0.0780 0.0674 0.0589 0.0546 0.0518 0.0494 0.0482 0.0468 0.0456 0.0450 0.0445 0.0439 0.0438 0.0435 

[TRAIN] Epoch[1](5507/114412); Loss: 0.096292; Backpropagation: 0.2940 sec; Batch: 2.1202 sec
0.2177 0.1569 0.1185 0.0969 0.0904 0.0862 0.0835 0.0812 0.0793 0.0781 0.0771 0.0762 0.0755 0.0750 0.0744 0.0739 

[TRAIN] Epoch[1](5508/114412); Loss: 0.067739; Backpropagation: 0.2936 sec; Batch: 2.1168 sec
0.1163 0.1079 0.0863 0.0767 0.0696 0.0648 0.0619 0.0598 0.0583 0.0569 0.0561 0.0551 0.0544 0.0537 0.0532 0.0528 

[TRAIN] Epoch[1](5509/114412); Loss: 0.083466; Backpropagation: 0.2949 sec; Batch: 2.1201 sec
0.1636 0.1254 0.1050 0.0948 0.0881 0.0812 0.0773 0.0733 0.0706 0.0689 0.0672 0.0659 0.0648 0.0638 0.0629 0.0624 

[TRAIN] Epoch[1](5510/114412); Loss: 0.062035; Backpropagation: 0.2942 sec; Batch: 2.1219 sec
0.1092 0.0982 0.0950 0.0776 0.0696 0.0624 0.0558 0.0532 0.0506 0.0484 0.0474 0.0464 0.0455 0.0448 0.0445 0.0439 

[TRAIN] Epoch[1](5511/114412); Loss: 0.088770; Backpropagation: 0.2933 sec; Batch: 2.1188 sec
0.1491 0.1232 0.1090 0.1017 0.0938 0.0878 0.0844 0.0800 0.0782 0.0767 0.0751 0.0739 0.0729 0.0721 0.0714 0.0709 

[TRAIN] Epoch[1](5512/114412); Loss: 0.075301; Backpropagation: 0.2910 sec; Batch: 2.1446 sec
0.2222 0.1474 0.0994 0.0831 0.0700 0.0634 0.0596 0.0570 0.0547 0.0528 0.0514 0.0503 0.0491 0.0484 0.0482 0.0477 

[TRAIN] Epoch[1](5513/114412); Loss: 0.067809; Backpropagation: 0.2913 sec; Batch: 2.1457 sec
0.1594 0.1241 0.0980 0.0809 0.0693 0.0611 0.0575 0.0544 0.0506 0.0495 0.0485 0.0474 0.0469 0.0462 0.0457 0.0453 

[TRAIN] Epoch[1](5514/114412); Loss: 0.070014; Backpropagation: 0.2912 sec; Batch: 2.1379 sec
0.1636 0.1254 0.0988 0.0849 0.0756 0.0645 0.0580 0.0560 0.0530 0.0513 0.0502 0.0490 0.0482 0.0477 0.0472 0.0468 

[TRAIN] Epoch[1](5515/114412); Loss: 0.106565; Backpropagation: 0.2911 sec; Batch: 2.0971 sec
0.1837 0.1567 0.1345 0.1243 0.1168 0.1090 0.1019 0.0965 0.0932 0.0898 0.0872 0.0850 0.0831 0.0821 0.0810 0.0803 

[TRAIN] Epoch[1](5516/114412); Loss: 0.076628; Backpropagation: 0.2904 sec; Batch: 2.1204 sec
0.2047 0.1499 0.0935 0.0941 0.0773 0.0688 0.0600 0.0594 0.0561 0.0541 0.0530 0.0522 0.0516 0.0509 0.0504 0.0500 

[TRAIN] Epoch[1](5517/114412); Loss: 0.074502; Backpropagation: 0.2909 sec; Batch: 2.0774 sec
0.1784 0.1273 0.1056 0.0905 0.0758 0.0705 0.0652 0.0626 0.0572 0.0548 0.0540 0.0523 0.0512 0.0500 0.0488 0.0478 

[TRAIN] Epoch[1](5518/114412); Loss: 0.102627; Backpropagation: 0.2913 sec; Batch: 2.1205 sec
0.1826 0.1590 0.1394 0.1240 0.1170 0.1073 0.0980 0.0916 0.0872 0.0830 0.0797 0.0772 0.0756 0.0744 0.0733 0.0726 

[TRAIN] Epoch[1](5519/114412); Loss: 0.082813; Backpropagation: 0.2933 sec; Batch: 2.1327 sec
0.1830 0.1596 0.1166 0.0859 0.0760 0.0698 0.0679 0.0662 0.0648 0.0640 0.0629 0.0623 0.0620 0.0616 0.0613 0.0611 

[TRAIN] Epoch[1](5520/114412); Loss: 0.060690; Backpropagation: 0.2930 sec; Batch: 2.0795 sec
0.1248 0.1004 0.0814 0.0697 0.0634 0.0597 0.0546 0.0514 0.0503 0.0482 0.0470 0.0456 0.0448 0.0438 0.0433 0.0427 

[TRAIN] Epoch[1](5521/114412); Loss: 0.062804; Backpropagation: 0.2909 sec; Batch: 2.1754 sec
0.1392 0.1178 0.0878 0.0735 0.0660 0.0591 0.0555 0.0517 0.0491 0.0475 0.0458 0.0439 0.0432 0.0422 0.0416 0.0412 

[TRAIN] Epoch[1](5522/114412); Loss: 0.066039; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1256 0.1153 0.0874 0.0721 0.0653 0.0604 0.0572 0.0560 0.0543 0.0536 0.0528 0.0521 0.0517 0.0512 0.0509 0.0508 

[TRAIN] Epoch[1](5523/114412); Loss: 0.078235; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1699 0.1428 0.1126 0.0940 0.0779 0.0685 0.0652 0.0619 0.0604 0.0592 0.0583 0.0576 0.0566 0.0560 0.0556 0.0553 

[TRAIN] Epoch[1](5524/114412); Loss: 0.105533; Backpropagation: 0.2929 sec; Batch: 2.1192 sec
0.2066 0.1956 0.1571 0.1365 0.1150 0.1038 0.0935 0.0866 0.0818 0.0771 0.0755 0.0742 0.0724 0.0717 0.0711 0.0700 

[TRAIN] Epoch[1](5525/114412); Loss: 0.063968; Backpropagation: 0.2914 sec; Batch: 2.1165 sec
0.1346 0.1052 0.0910 0.0753 0.0663 0.0601 0.0583 0.0540 0.0518 0.0499 0.0487 0.0474 0.0462 0.0454 0.0449 0.0444 

[TRAIN] Epoch[1](5526/114412); Loss: 0.076511; Backpropagation: 0.2932 sec; Batch: 2.1183 sec
0.1582 0.1267 0.1070 0.0914 0.0800 0.0731 0.0687 0.0647 0.0612 0.0596 0.0585 0.0566 0.0557 0.0549 0.0542 0.0536 

[TRAIN] Epoch[1](5527/114412); Loss: 0.067273; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1375 0.1121 0.0880 0.0763 0.0695 0.0634 0.0594 0.0570 0.0550 0.0537 0.0526 0.0517 0.0509 0.0502 0.0497 0.0493 

[TRAIN] Epoch[1](5528/114412); Loss: 0.065526; Backpropagation: 0.2910 sec; Batch: 2.1089 sec
0.1514 0.1115 0.0897 0.0742 0.0669 0.0615 0.0572 0.0543 0.0523 0.0502 0.0489 0.0476 0.0468 0.0459 0.0452 0.0448 

[TRAIN] Epoch[1](5529/114412); Loss: 0.065666; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1405 0.1106 0.0879 0.0766 0.0658 0.0603 0.0574 0.0558 0.0530 0.0518 0.0502 0.0495 0.0487 0.0479 0.0475 0.0472 

[TRAIN] Epoch[1](5530/114412); Loss: 0.056545; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1726 0.1298 0.0762 0.0614 0.0545 0.0457 0.0429 0.0402 0.0383 0.0369 0.0359 0.0351 0.0345 0.0339 0.0335 0.0333 

[TRAIN] Epoch[1](5531/114412); Loss: 0.137837; Backpropagation: 0.2909 sec; Batch: 2.0771 sec
0.2351 0.2081 0.1908 0.1655 0.1495 0.1411 0.1302 0.1230 0.1184 0.1133 0.1098 0.1101 0.1070 0.1045 0.1010 0.0978 

[TRAIN] Epoch[1](5532/114412); Loss: 0.055049; Backpropagation: 0.2905 sec; Batch: 2.1178 sec
0.1577 0.1035 0.0627 0.0530 0.0508 0.0478 0.0459 0.0441 0.0422 0.0411 0.0403 0.0392 0.0386 0.0382 0.0379 0.0377 

[TRAIN] Epoch[1](5533/114412); Loss: 0.076447; Backpropagation: 0.2906 sec; Batch: 2.1292 sec
0.2245 0.1525 0.1165 0.0820 0.0675 0.0627 0.0575 0.0551 0.0539 0.0523 0.0514 0.0506 0.0497 0.0494 0.0490 0.0487 

[TRAIN] Epoch[1](5534/114412); Loss: 0.072940; Backpropagation: 0.2904 sec; Batch: 2.1190 sec
0.1598 0.1287 0.0977 0.0778 0.0722 0.0683 0.0637 0.0607 0.0586 0.0571 0.0556 0.0547 0.0539 0.0532 0.0527 0.0523 

[TRAIN] Epoch[1](5535/114412); Loss: 0.069248; Backpropagation: 0.2907 sec; Batch: 2.1173 sec
0.1739 0.1174 0.0935 0.0786 0.0710 0.0626 0.0586 0.0561 0.0541 0.0523 0.0507 0.0494 0.0484 0.0477 0.0470 0.0466 

[TRAIN] Epoch[1](5536/114412); Loss: 0.070003; Backpropagation: 0.2908 sec; Batch: 2.0767 sec
0.1830 0.1246 0.0819 0.0751 0.0661 0.0621 0.0576 0.0568 0.0553 0.0531 0.0518 0.0512 0.0507 0.0506 0.0503 0.0499 

[TRAIN] Epoch[1](5537/114412); Loss: 0.051891; Backpropagation: 0.2907 sec; Batch: 2.1169 sec
0.1470 0.1018 0.0685 0.0640 0.0477 0.0419 0.0404 0.0384 0.0372 0.0363 0.0353 0.0350 0.0345 0.0343 0.0340 0.0338 

[TRAIN] Epoch[1](5538/114412); Loss: 0.079844; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1526 0.1237 0.1015 0.0915 0.0812 0.0763 0.0713 0.0692 0.0672 0.0658 0.0646 0.0637 0.0630 0.0624 0.0619 0.0616 

[TRAIN] Epoch[1](5539/114412); Loss: 0.074593; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1609 0.1230 0.0864 0.0799 0.0737 0.0685 0.0656 0.0630 0.0619 0.0608 0.0597 0.0590 0.0584 0.0580 0.0575 0.0572 

[TRAIN] Epoch[1](5540/114412); Loss: 0.095848; Backpropagation: 0.2916 sec; Batch: 2.1147 sec
0.1961 0.1564 0.1272 0.1071 0.0953 0.0882 0.0840 0.0808 0.0787 0.0772 0.0759 0.0748 0.0739 0.0732 0.0726 0.0722 

[TRAIN] Epoch[1](5541/114412); Loss: 0.079452; Backpropagation: 0.2948 sec; Batch: 2.1173 sec
0.1471 0.1273 0.1026 0.0885 0.0807 0.0760 0.0719 0.0696 0.0674 0.0654 0.0643 0.0632 0.0626 0.0620 0.0615 0.0611 

[TRAIN] Epoch[1](5542/114412); Loss: 0.063937; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.2006 0.1324 0.0844 0.0698 0.0607 0.0526 0.0487 0.0456 0.0444 0.0431 0.0420 0.0409 0.0402 0.0396 0.0391 0.0389 

[TRAIN] Epoch[1](5543/114412); Loss: 0.067938; Backpropagation: 0.2929 sec; Batch: 2.1162 sec
0.1578 0.1266 0.0928 0.0759 0.0650 0.0601 0.0572 0.0546 0.0529 0.0516 0.0505 0.0497 0.0488 0.0482 0.0478 0.0474 

[TRAIN] Epoch[1](5544/114412); Loss: 0.079413; Backpropagation: 0.2948 sec; Batch: 2.1229 sec
0.1816 0.1278 0.0928 0.0829 0.0779 0.0729 0.0701 0.0675 0.0655 0.0643 0.0631 0.0621 0.0613 0.0607 0.0602 0.0599 

[TRAIN] Epoch[1](5545/114412); Loss: 0.092473; Backpropagation: 0.2928 sec; Batch: 2.1152 sec
0.1961 0.1473 0.1080 0.0961 0.0890 0.0853 0.0833 0.0810 0.0783 0.0763 0.0751 0.0741 0.0735 0.0726 0.0720 0.0717 

[TRAIN] Epoch[1](5546/114412); Loss: 0.054606; Backpropagation: 0.2928 sec; Batch: 2.1175 sec
0.2000 0.1230 0.0628 0.0537 0.0480 0.0433 0.0407 0.0378 0.0362 0.0349 0.0337 0.0329 0.0324 0.0318 0.0314 0.0310 

[TRAIN] Epoch[1](5547/114412); Loss: 0.056841; Backpropagation: 0.2911 sec; Batch: 2.1160 sec
0.1217 0.0938 0.0754 0.0639 0.0570 0.0531 0.0502 0.0478 0.0465 0.0451 0.0440 0.0432 0.0425 0.0421 0.0417 0.0414 

[TRAIN] Epoch[1](5548/114412); Loss: 0.066486; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1435 0.1270 0.1023 0.0879 0.0737 0.0615 0.0549 0.0536 0.0505 0.0477 0.0462 0.0448 0.0437 0.0428 0.0421 0.0416 

[TRAIN] Epoch[1](5549/114412); Loss: 0.082412; Backpropagation: 0.2928 sec; Batch: 2.1190 sec
0.1696 0.1357 0.1019 0.0907 0.0841 0.0742 0.0722 0.0706 0.0672 0.0666 0.0659 0.0649 0.0643 0.0638 0.0634 0.0635 

[TRAIN] Epoch[1](5550/114412); Loss: 0.056650; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1075 0.1015 0.0778 0.0659 0.0613 0.0520 0.0504 0.0485 0.0459 0.0443 0.0433 0.0426 0.0420 0.0415 0.0412 0.0410 

[TRAIN] Epoch[1](5551/114412); Loss: 0.058308; Backpropagation: 0.2907 sec; Batch: 2.1010 sec
0.1633 0.0827 0.0720 0.0632 0.0573 0.0540 0.0513 0.0479 0.0459 0.0448 0.0434 0.0427 0.0418 0.0413 0.0409 0.0407 

[TRAIN] Epoch[1](5552/114412); Loss: 0.052515; Backpropagation: 0.2910 sec; Batch: 2.1137 sec
0.1258 0.1059 0.0800 0.0664 0.0571 0.0467 0.0417 0.0401 0.0382 0.0362 0.0353 0.0344 0.0338 0.0333 0.0329 0.0327 

[TRAIN] Epoch[1](5553/114412); Loss: 0.071740; Backpropagation: 0.2907 sec; Batch: 2.1179 sec
0.1432 0.1174 0.0833 0.0768 0.0722 0.0675 0.0644 0.0619 0.0606 0.0595 0.0584 0.0575 0.0570 0.0565 0.0559 0.0556 

[TRAIN] Epoch[1](5554/114412); Loss: 0.060382; Backpropagation: 0.2910 sec; Batch: 2.1254 sec
0.1202 0.1057 0.0878 0.0739 0.0650 0.0586 0.0541 0.0499 0.0477 0.0461 0.0444 0.0437 0.0431 0.0424 0.0419 0.0416 

[TRAIN] Epoch[1](5555/114412); Loss: 0.085007; Backpropagation: 0.2904 sec; Batch: 2.0771 sec
0.2002 0.1294 0.1086 0.0931 0.0859 0.0811 0.0766 0.0737 0.0701 0.0676 0.0658 0.0637 0.0623 0.0615 0.0605 0.0597 

[TRAIN] Epoch[1](5556/114412); Loss: 0.083904; Backpropagation: 0.2929 sec; Batch: 2.1194 sec
0.1714 0.1237 0.1035 0.0943 0.0870 0.0815 0.0767 0.0737 0.0709 0.0689 0.0673 0.0660 0.0655 0.0646 0.0640 0.0636 

[TRAIN] Epoch[1](5557/114412); Loss: 0.053051; Backpropagation: 0.2909 sec; Batch: 2.1192 sec
0.1217 0.0974 0.0650 0.0604 0.0521 0.0479 0.0457 0.0436 0.0422 0.0405 0.0398 0.0392 0.0386 0.0385 0.0382 0.0380 

[TRAIN] Epoch[1](5558/114412); Loss: 0.094797; Backpropagation: 0.2925 sec; Batch: 2.1191 sec
0.1821 0.1380 0.1141 0.1009 0.0946 0.0900 0.0870 0.0843 0.0821 0.0807 0.0794 0.0781 0.0773 0.0765 0.0761 0.0756 

[TRAIN] Epoch[1](5559/114412); Loss: 0.076566; Backpropagation: 0.2952 sec; Batch: 2.1214 sec
0.1740 0.1321 0.0877 0.0874 0.0769 0.0685 0.0656 0.0640 0.0615 0.0602 0.0593 0.0585 0.0580 0.0574 0.0572 0.0568 

[TRAIN] Epoch[1](5560/114412); Loss: 0.074595; Backpropagation: 0.2952 sec; Batch: 2.1254 sec
0.1601 0.1240 0.0974 0.0865 0.0738 0.0681 0.0653 0.0632 0.0606 0.0590 0.0579 0.0570 0.0560 0.0553 0.0549 0.0544 

[TRAIN] Epoch[1](5561/114412); Loss: 0.066688; Backpropagation: 0.2951 sec; Batch: 2.1207 sec
0.1314 0.1121 0.0892 0.0766 0.0688 0.0632 0.0602 0.0572 0.0544 0.0525 0.0520 0.0511 0.0502 0.0498 0.0494 0.0489 

[TRAIN] Epoch[1](5562/114412); Loss: 0.076382; Backpropagation: 0.2931 sec; Batch: 2.1203 sec
0.1422 0.1215 0.1021 0.0886 0.0828 0.0734 0.0693 0.0672 0.0647 0.0621 0.0610 0.0589 0.0583 0.0572 0.0565 0.0563 

[TRAIN] Epoch[1](5563/114412); Loss: 0.059811; Backpropagation: 0.2932 sec; Batch: 2.1203 sec
0.1698 0.1001 0.0722 0.0617 0.0571 0.0536 0.0504 0.0479 0.0468 0.0451 0.0439 0.0430 0.0422 0.0417 0.0410 0.0405 

[TRAIN] Epoch[1](5564/114412); Loss: 0.077127; Backpropagation: 0.2942 sec; Batch: 2.1194 sec
0.1336 0.1258 0.1049 0.0941 0.0824 0.0753 0.0698 0.0657 0.0635 0.0621 0.0610 0.0603 0.0597 0.0590 0.0586 0.0581 

[TRAIN] Epoch[1](5565/114412); Loss: 0.069418; Backpropagation: 0.2927 sec; Batch: 2.1197 sec
0.1679 0.1171 0.0840 0.0710 0.0663 0.0625 0.0589 0.0567 0.0562 0.0547 0.0536 0.0533 0.0526 0.0523 0.0519 0.0516 

[TRAIN] Epoch[1](5566/114412); Loss: 0.104928; Backpropagation: 0.2927 sec; Batch: 2.1249 sec
0.1701 0.1466 0.1293 0.1142 0.1056 0.0989 0.0959 0.0940 0.0927 0.0918 0.0908 0.0903 0.0901 0.0896 0.0895 0.0894 

[TRAIN] Epoch[1](5567/114412); Loss: 0.073357; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1832 0.1586 0.0918 0.0837 0.0677 0.0643 0.0603 0.0574 0.0549 0.0532 0.0516 0.0506 0.0498 0.0494 0.0489 0.0484 

[TRAIN] Epoch[1](5568/114412); Loss: 0.065333; Backpropagation: 0.2954 sec; Batch: 2.1195 sec
0.1341 0.1022 0.0814 0.0713 0.0659 0.0614 0.0572 0.0557 0.0544 0.0533 0.0525 0.0521 0.0515 0.0510 0.0509 0.0504 

[TRAIN] Epoch[1](5569/114412); Loss: 0.089599; Backpropagation: 0.2930 sec; Batch: 2.1208 sec
0.1779 0.1573 0.1284 0.1095 0.0959 0.0855 0.0815 0.0773 0.0723 0.0689 0.0669 0.0647 0.0636 0.0622 0.0611 0.0603 

[TRAIN] Epoch[1](5570/114412); Loss: 0.073765; Backpropagation: 0.2912 sec; Batch: 2.1132 sec
0.1746 0.1445 0.1045 0.0831 0.0733 0.0681 0.0624 0.0585 0.0554 0.0537 0.0528 0.0514 0.0505 0.0499 0.0490 0.0485 

[TRAIN] Epoch[1](5571/114412); Loss: 0.072329; Backpropagation: 0.2952 sec; Batch: 2.1223 sec
0.1517 0.1228 0.0889 0.0801 0.0741 0.0684 0.0647 0.0620 0.0597 0.0580 0.0567 0.0555 0.0546 0.0539 0.0534 0.0529 

[TRAIN] Epoch[1](5572/114412); Loss: 0.086163; Backpropagation: 0.2930 sec; Batch: 2.0797 sec
0.1375 0.1139 0.1028 0.0935 0.0875 0.0836 0.0810 0.0797 0.0778 0.0766 0.0757 0.0749 0.0743 0.0736 0.0732 0.0729 

[TRAIN] Epoch[1](5573/114412); Loss: 0.069873; Backpropagation: 0.2908 sec; Batch: 2.1145 sec
0.1617 0.1189 0.0862 0.0727 0.0682 0.0635 0.0611 0.0586 0.0567 0.0552 0.0541 0.0532 0.0526 0.0522 0.0518 0.0513 

[TRAIN] Epoch[1](5574/114412); Loss: 0.066690; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1644 0.1145 0.0791 0.0701 0.0665 0.0586 0.0571 0.0544 0.0525 0.0515 0.0508 0.0500 0.0496 0.0496 0.0493 0.0492 

[TRAIN] Epoch[1](5575/114412); Loss: 0.076555; Backpropagation: 0.2930 sec; Batch: 2.1115 sec
0.1634 0.1229 0.0915 0.0781 0.0737 0.0699 0.0679 0.0661 0.0643 0.0631 0.0625 0.0614 0.0607 0.0602 0.0597 0.0595 

[TRAIN] Epoch[1](5576/114412); Loss: 0.079123; Backpropagation: 0.2906 sec; Batch: 2.1166 sec
0.1453 0.1198 0.0969 0.0838 0.0775 0.0748 0.0723 0.0699 0.0683 0.0670 0.0664 0.0656 0.0651 0.0648 0.0644 0.0641 

[TRAIN] Epoch[1](5577/114412); Loss: 0.063267; Backpropagation: 0.2911 sec; Batch: 2.1095 sec
0.1767 0.1334 0.0923 0.0728 0.0564 0.0532 0.0497 0.0468 0.0449 0.0434 0.0424 0.0409 0.0404 0.0401 0.0396 0.0392 

[TRAIN] Epoch[1](5578/114412); Loss: 0.063567; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1203 0.0967 0.0779 0.0710 0.0642 0.0607 0.0585 0.0561 0.0548 0.0535 0.0522 0.0514 0.0508 0.0502 0.0496 0.0493 

[TRAIN] Epoch[1](5579/114412); Loss: 0.092689; Backpropagation: 0.2928 sec; Batch: 2.1227 sec
0.2009 0.1487 0.1132 0.0996 0.0909 0.0852 0.0827 0.0796 0.0768 0.0754 0.0740 0.0729 0.0718 0.0712 0.0705 0.0697 

[TRAIN] Epoch[1](5580/114412); Loss: 0.064140; Backpropagation: 0.2931 sec; Batch: 2.1182 sec
0.1400 0.1121 0.0881 0.0795 0.0678 0.0593 0.0559 0.0526 0.0506 0.0489 0.0477 0.0461 0.0452 0.0448 0.0439 0.0436 

[TRAIN] Epoch[1](5581/114412); Loss: 0.084105; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.1656 0.1435 0.1092 0.0971 0.0868 0.0786 0.0750 0.0712 0.0686 0.0671 0.0658 0.0645 0.0640 0.0633 0.0629 0.0625 

[TRAIN] Epoch[1](5582/114412); Loss: 0.070850; Backpropagation: 0.2907 sec; Batch: 2.1204 sec
0.1723 0.1300 0.0958 0.0812 0.0680 0.0613 0.0586 0.0571 0.0540 0.0527 0.0517 0.0512 0.0509 0.0499 0.0496 0.0493 

[TRAIN] Epoch[1](5583/114412); Loss: 0.067913; Backpropagation: 0.2909 sec; Batch: 2.1187 sec
0.1254 0.1036 0.0799 0.0739 0.0690 0.0663 0.0630 0.0606 0.0591 0.0576 0.0563 0.0555 0.0547 0.0543 0.0540 0.0536 

[TRAIN] Epoch[1](5584/114412); Loss: 0.083892; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.1494 0.1378 0.1112 0.0965 0.0878 0.0823 0.0773 0.0744 0.0717 0.0695 0.0671 0.0655 0.0640 0.0633 0.0626 0.0619 

[TRAIN] Epoch[1](5585/114412); Loss: 0.064773; Backpropagation: 0.2910 sec; Batch: 2.1310 sec
0.1443 0.1225 0.0972 0.0782 0.0722 0.0598 0.0559 0.0540 0.0490 0.0469 0.0457 0.0438 0.0426 0.0419 0.0414 0.0410 

[TRAIN] Epoch[1](5586/114412); Loss: 0.074311; Backpropagation: 0.2910 sec; Batch: 2.1213 sec
0.1382 0.1181 0.0956 0.0857 0.0789 0.0728 0.0685 0.0646 0.0621 0.0609 0.0589 0.0583 0.0578 0.0568 0.0562 0.0556 

[TRAIN] Epoch[1](5587/114412); Loss: 0.067461; Backpropagation: 0.2904 sec; Batch: 2.1167 sec
0.1855 0.1228 0.0801 0.0696 0.0648 0.0582 0.0555 0.0533 0.0516 0.0502 0.0494 0.0485 0.0480 0.0476 0.0472 0.0471 

[TRAIN] Epoch[1](5588/114412); Loss: 0.072661; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1524 0.1186 0.0947 0.0838 0.0767 0.0687 0.0643 0.0614 0.0592 0.0578 0.0564 0.0553 0.0543 0.0537 0.0529 0.0524 

[TRAIN] Epoch[1](5589/114412); Loss: 0.067444; Backpropagation: 0.2909 sec; Batch: 2.0825 sec
0.1559 0.1422 0.1042 0.0780 0.0630 0.0570 0.0537 0.0519 0.0495 0.0485 0.0475 0.0466 0.0459 0.0454 0.0450 0.0447 

[TRAIN] Epoch[1](5590/114412); Loss: 0.079937; Backpropagation: 0.2915 sec; Batch: 2.1171 sec
0.1303 0.1214 0.1023 0.0919 0.0829 0.0769 0.0726 0.0706 0.0690 0.0677 0.0669 0.0662 0.0657 0.0653 0.0649 0.0646 

[TRAIN] Epoch[1](5591/114412); Loss: 0.089070; Backpropagation: 0.2908 sec; Batch: 2.1182 sec
0.1779 0.1391 0.1067 0.0919 0.0856 0.0819 0.0794 0.0772 0.0759 0.0747 0.0738 0.0731 0.0726 0.0721 0.0717 0.0714 

[TRAIN] Epoch[1](5592/114412); Loss: 0.075074; Backpropagation: 0.2905 sec; Batch: 2.1169 sec
0.1476 0.1207 0.0976 0.0829 0.0763 0.0711 0.0679 0.0648 0.0629 0.0614 0.0598 0.0589 0.0582 0.0574 0.0570 0.0566 

[TRAIN] Epoch[1](5593/114412); Loss: 0.079882; Backpropagation: 0.2909 sec; Batch: 2.1207 sec
0.1409 0.1171 0.0972 0.0892 0.0830 0.0763 0.0736 0.0714 0.0696 0.0683 0.0671 0.0661 0.0654 0.0648 0.0643 0.0639 

[TRAIN] Epoch[1](5594/114412); Loss: 0.097448; Backpropagation: 0.2906 sec; Batch: 2.0769 sec
0.1680 0.1435 0.1181 0.1086 0.1016 0.0953 0.0909 0.0880 0.0851 0.0835 0.0823 0.0807 0.0795 0.0790 0.0780 0.0771 

[TRAIN] Epoch[1](5595/114412); Loss: 0.082678; Backpropagation: 0.2950 sec; Batch: 2.1188 sec
0.1691 0.1364 0.1049 0.0888 0.0819 0.0781 0.0745 0.0717 0.0694 0.0676 0.0662 0.0648 0.0636 0.0626 0.0619 0.0613 

[TRAIN] Epoch[1](5596/114412); Loss: 0.078680; Backpropagation: 0.2912 sec; Batch: 2.1193 sec
0.2268 0.1711 0.1083 0.0949 0.0823 0.0712 0.0625 0.0581 0.0544 0.0513 0.0493 0.0477 0.0465 0.0455 0.0448 0.0441 

[TRAIN] Epoch[1](5597/114412); Loss: 0.076514; Backpropagation: 0.2914 sec; Batch: 2.1200 sec
0.1840 0.1605 0.1137 0.0949 0.0760 0.0685 0.0630 0.0580 0.0553 0.0539 0.0523 0.0507 0.0495 0.0487 0.0479 0.0475 

[TRAIN] Epoch[1](5598/114412); Loss: 0.086158; Backpropagation: 0.2931 sec; Batch: 2.1192 sec
0.1967 0.1565 0.1201 0.0991 0.0874 0.0809 0.0746 0.0707 0.0684 0.0662 0.0640 0.0612 0.0598 0.0587 0.0577 0.0565 

[TRAIN] Epoch[1](5599/114412); Loss: 0.106537; Backpropagation: 0.2908 sec; Batch: 2.0819 sec
0.1940 0.1719 0.1364 0.1220 0.1094 0.1012 0.0959 0.0922 0.0900 0.0880 0.0863 0.0853 0.0841 0.0834 0.0827 0.0818 

[TRAIN] Epoch[1](5600/114412); Loss: 0.079998; Backpropagation: 0.2927 sec; Batch: 2.0784 sec
0.1630 0.1291 0.0988 0.0863 0.0802 0.0748 0.0717 0.0689 0.0668 0.0653 0.0644 0.0633 0.0627 0.0620 0.0615 0.0611 

[TRAIN] Epoch[1](5601/114412); Loss: 0.063864; Backpropagation: 0.2923 sec; Batch: 2.1119 sec
0.1678 0.1226 0.0829 0.0750 0.0615 0.0558 0.0535 0.0497 0.0485 0.0470 0.0449 0.0442 0.0432 0.0422 0.0418 0.0412 

[TRAIN] Epoch[1](5602/114412); Loss: 0.061013; Backpropagation: 0.2927 sec; Batch: 2.1234 sec
0.1177 0.1098 0.0882 0.0717 0.0612 0.0569 0.0541 0.0509 0.0490 0.0475 0.0464 0.0457 0.0450 0.0444 0.0441 0.0437 

[TRAIN] Epoch[1](5603/114412); Loss: 0.066542; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.1094 0.0987 0.0829 0.0721 0.0682 0.0652 0.0621 0.0596 0.0583 0.0572 0.0563 0.0558 0.0553 0.0549 0.0544 0.0542 

[TRAIN] Epoch[1](5604/114412); Loss: 0.055362; Backpropagation: 0.2907 sec; Batch: 2.1186 sec
0.1851 0.0963 0.0722 0.0591 0.0536 0.0457 0.0419 0.0401 0.0386 0.0379 0.0371 0.0365 0.0360 0.0355 0.0352 0.0351 

[TRAIN] Epoch[1](5605/114412); Loss: 0.066110; Backpropagation: 0.2912 sec; Batch: 2.1204 sec
0.1301 0.1116 0.0882 0.0760 0.0689 0.0641 0.0594 0.0563 0.0542 0.0528 0.0513 0.0501 0.0495 0.0488 0.0483 0.0480 

[TRAIN] Epoch[1](5606/114412); Loss: 0.085003; Backpropagation: 0.2914 sec; Batch: 2.1178 sec
0.1828 0.1420 0.1002 0.0914 0.0856 0.0781 0.0750 0.0720 0.0694 0.0684 0.0674 0.0663 0.0661 0.0655 0.0651 0.0648 

[TRAIN] Epoch[1](5607/114412); Loss: 0.079736; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1757 0.1496 0.1118 0.0900 0.0790 0.0724 0.0683 0.0652 0.0625 0.0609 0.0592 0.0578 0.0567 0.0560 0.0556 0.0551 

[TRAIN] Epoch[1](5608/114412); Loss: 0.081696; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1481 0.1286 0.1094 0.0926 0.0836 0.0783 0.0745 0.0715 0.0697 0.0677 0.0661 0.0650 0.0640 0.0632 0.0627 0.0622 

[TRAIN] Epoch[1](5609/114412); Loss: 0.062135; Backpropagation: 0.2914 sec; Batch: 2.1143 sec
0.1477 0.1147 0.0822 0.0725 0.0634 0.0579 0.0538 0.0505 0.0483 0.0465 0.0451 0.0437 0.0430 0.0421 0.0416 0.0413 

[TRAIN] Epoch[1](5610/114412); Loss: 0.083964; Backpropagation: 0.2914 sec; Batch: 2.1263 sec
0.1521 0.1175 0.1007 0.0905 0.0836 0.0797 0.0772 0.0754 0.0737 0.0724 0.0716 0.0709 0.0703 0.0697 0.0693 0.0690 

[TRAIN] Epoch[1](5611/114412); Loss: 0.084915; Backpropagation: 0.2915 sec; Batch: 2.1130 sec
0.1542 0.1372 0.1071 0.1012 0.0901 0.0816 0.0789 0.0767 0.0709 0.0696 0.0688 0.0663 0.0654 0.0647 0.0633 0.0626 

[TRAIN] Epoch[1](5612/114412); Loss: 0.064749; Backpropagation: 0.2933 sec; Batch: 2.1360 sec
0.1702 0.1194 0.0844 0.0710 0.0640 0.0571 0.0530 0.0502 0.0488 0.0477 0.0464 0.0458 0.0452 0.0447 0.0443 0.0439 

[TRAIN] Epoch[1](5613/114412); Loss: 0.136720; Backpropagation: 0.2973 sec; Batch: 2.1108 sec
0.2069 0.1909 0.1692 0.1484 0.1405 0.1372 0.1343 0.1333 0.1282 0.1219 0.1191 0.1161 0.1137 0.1120 0.1094 0.1064 

[TRAIN] Epoch[1](5614/114412); Loss: 0.084206; Backpropagation: 0.3008 sec; Batch: 2.1298 sec
0.1492 0.1208 0.1007 0.0916 0.0860 0.0810 0.0778 0.0752 0.0740 0.0726 0.0713 0.0706 0.0700 0.0693 0.0689 0.0685 

[TRAIN] Epoch[1](5615/114412); Loss: 0.071113; Backpropagation: 0.3006 sec; Batch: 2.1236 sec
0.1428 0.1182 0.0939 0.0850 0.0767 0.0705 0.0647 0.0614 0.0581 0.0559 0.0545 0.0532 0.0520 0.0511 0.0503 0.0495 

[TRAIN] Epoch[1](5616/114412); Loss: 0.065810; Backpropagation: 0.3005 sec; Batch: 2.1293 sec
0.1343 0.1194 0.0903 0.0727 0.0661 0.0602 0.0567 0.0547 0.0530 0.0518 0.0506 0.0498 0.0491 0.0485 0.0480 0.0475 

[TRAIN] Epoch[1](5617/114412); Loss: 0.085566; Backpropagation: 0.2952 sec; Batch: 2.1327 sec
0.1641 0.1382 0.1179 0.1016 0.0933 0.0838 0.0775 0.0742 0.0707 0.0685 0.0660 0.0648 0.0638 0.0625 0.0616 0.0606 

[TRAIN] Epoch[1](5618/114412); Loss: 0.059499; Backpropagation: 0.2964 sec; Batch: 2.1233 sec
0.1314 0.1091 0.0689 0.0614 0.0564 0.0534 0.0522 0.0502 0.0485 0.0474 0.0465 0.0460 0.0456 0.0453 0.0450 0.0447 

[TRAIN] Epoch[1](5619/114412); Loss: 0.063408; Backpropagation: 0.2954 sec; Batch: 2.1236 sec
0.1440 0.1191 0.0896 0.0736 0.0636 0.0582 0.0540 0.0509 0.0488 0.0472 0.0461 0.0450 0.0445 0.0438 0.0432 0.0429 

[TRAIN] Epoch[1](5620/114412); Loss: 0.083206; Backpropagation: 0.2954 sec; Batch: 2.1243 sec
0.1637 0.1442 0.1033 0.0884 0.0815 0.0778 0.0753 0.0709 0.0695 0.0684 0.0665 0.0657 0.0649 0.0642 0.0637 0.0632 

[TRAIN] Epoch[1](5621/114412); Loss: 0.078747; Backpropagation: 0.2958 sec; Batch: 2.1297 sec
0.1862 0.1308 0.1020 0.0853 0.0775 0.0713 0.0678 0.0647 0.0625 0.0614 0.0604 0.0594 0.0586 0.0579 0.0573 0.0569 

[TRAIN] Epoch[1](5622/114412); Loss: 0.092758; Backpropagation: 0.2956 sec; Batch: 2.1416 sec
0.1455 0.1240 0.1117 0.1030 0.0961 0.0927 0.0886 0.0861 0.0842 0.0824 0.0806 0.0797 0.0785 0.0776 0.0769 0.0766 

[TRAIN] Epoch[1](5623/114412); Loss: 0.065880; Backpropagation: 0.2960 sec; Batch: 2.1230 sec
0.1442 0.0997 0.0897 0.0735 0.0673 0.0624 0.0586 0.0557 0.0541 0.0525 0.0513 0.0502 0.0495 0.0489 0.0484 0.0481 

[TRAIN] Epoch[1](5624/114412); Loss: 0.088619; Backpropagation: 0.2956 sec; Batch: 2.1198 sec
0.1600 0.1328 0.1074 0.0976 0.0904 0.0847 0.0818 0.0791 0.0768 0.0752 0.0742 0.0731 0.0723 0.0715 0.0708 0.0702 

[TRAIN] Epoch[1](5625/114412); Loss: 0.086085; Backpropagation: 0.2950 sec; Batch: 2.1221 sec
0.1519 0.1230 0.1024 0.0950 0.0875 0.0830 0.0799 0.0772 0.0758 0.0745 0.0734 0.0723 0.0712 0.0706 0.0701 0.0696 

[TRAIN] Epoch[1](5626/114412); Loss: 0.095740; Backpropagation: 0.2958 sec; Batch: 2.1018 sec
0.1730 0.1371 0.1063 0.1015 0.0949 0.0915 0.0878 0.0865 0.0849 0.0837 0.0824 0.0814 0.0810 0.0806 0.0799 0.0796 

[TRAIN] Epoch[1](5627/114412); Loss: 0.068509; Backpropagation: 0.2954 sec; Batch: 2.1206 sec
0.1405 0.1231 0.0918 0.0771 0.0701 0.0640 0.0611 0.0586 0.0551 0.0539 0.0526 0.0509 0.0503 0.0495 0.0489 0.0485 

[TRAIN] Epoch[1](5628/114412); Loss: 0.061369; Backpropagation: 0.2956 sec; Batch: 2.1214 sec
0.1582 0.1037 0.0767 0.0685 0.0593 0.0562 0.0528 0.0504 0.0487 0.0469 0.0456 0.0442 0.0435 0.0429 0.0424 0.0419 

[TRAIN] Epoch[1](5629/114412); Loss: 0.054810; Backpropagation: 0.2959 sec; Batch: 2.1229 sec
0.1046 0.0834 0.0640 0.0601 0.0553 0.0541 0.0513 0.0480 0.0472 0.0458 0.0450 0.0445 0.0439 0.0436 0.0431 0.0429 

[TRAIN] Epoch[1](5630/114412); Loss: 0.066192; Backpropagation: 0.2961 sec; Batch: 2.1415 sec
0.1248 0.1165 0.0888 0.0770 0.0683 0.0640 0.0610 0.0593 0.0550 0.0523 0.0515 0.0493 0.0489 0.0482 0.0473 0.0469 

[TRAIN] Epoch[1](5631/114412); Loss: 0.100127; Backpropagation: 0.2954 sec; Batch: 2.1195 sec
0.2210 0.1929 0.1360 0.1169 0.0950 0.0858 0.0812 0.0789 0.0779 0.0765 0.0748 0.0739 0.0735 0.0730 0.0726 0.0722 

[TRAIN] Epoch[1](5632/114412); Loss: 0.117068; Backpropagation: 0.2977 sec; Batch: 2.1278 sec
0.2060 0.1772 0.1465 0.1301 0.1157 0.1089 0.1060 0.1036 0.1013 0.0999 0.0987 0.0973 0.0964 0.0958 0.0952 0.0945 

[TRAIN] Epoch[1](5633/114412); Loss: 0.087570; Backpropagation: 0.2957 sec; Batch: 2.1249 sec
0.1489 0.1343 0.1157 0.1023 0.0939 0.0870 0.0817 0.0776 0.0745 0.0729 0.0712 0.0696 0.0687 0.0682 0.0674 0.0673 

[TRAIN] Epoch[1](5634/114412); Loss: 0.082557; Backpropagation: 0.2957 sec; Batch: 2.0828 sec
0.1602 0.1264 0.1012 0.0864 0.0815 0.0781 0.0754 0.0728 0.0710 0.0695 0.0680 0.0673 0.0665 0.0660 0.0655 0.0650 

[TRAIN] Epoch[1](5635/114412); Loss: 0.080524; Backpropagation: 0.3007 sec; Batch: 2.1300 sec
0.1747 0.1367 0.0915 0.0878 0.0790 0.0746 0.0713 0.0677 0.0662 0.0648 0.0641 0.0632 0.0623 0.0620 0.0614 0.0610 

[TRAIN] Epoch[1](5636/114412); Loss: 0.081455; Backpropagation: 0.2959 sec; Batch: 2.1230 sec
0.1825 0.1500 0.1141 0.1048 0.0862 0.0816 0.0792 0.0678 0.0633 0.0621 0.0571 0.0538 0.0532 0.0502 0.0490 0.0483 

[TRAIN] Epoch[1](5637/114412); Loss: 0.063745; Backpropagation: 0.2957 sec; Batch: 2.1209 sec
0.1287 0.1063 0.0884 0.0736 0.0670 0.0609 0.0562 0.0544 0.0514 0.0502 0.0489 0.0480 0.0476 0.0466 0.0461 0.0459 

[TRAIN] Epoch[1](5638/114412); Loss: 0.088097; Backpropagation: 0.2958 sec; Batch: 2.1221 sec
0.1549 0.1206 0.1045 0.0945 0.0875 0.0840 0.0822 0.0798 0.0781 0.0774 0.0760 0.0749 0.0744 0.0740 0.0736 0.0732 

[TRAIN] Epoch[1](5639/114412); Loss: 0.064203; Backpropagation: 0.2956 sec; Batch: 2.1213 sec
0.1625 0.1020 0.0798 0.0735 0.0627 0.0578 0.0546 0.0531 0.0504 0.0494 0.0484 0.0475 0.0470 0.0465 0.0462 0.0460 

[TRAIN] Epoch[1](5640/114412); Loss: 0.069675; Backpropagation: 0.2956 sec; Batch: 2.1219 sec
0.1508 0.1362 0.0951 0.0834 0.0730 0.0636 0.0581 0.0550 0.0533 0.0522 0.0508 0.0499 0.0491 0.0485 0.0482 0.0475 

[TRAIN] Epoch[1](5641/114412); Loss: 0.082973; Backpropagation: 0.2955 sec; Batch: 2.1247 sec
0.1605 0.1300 0.1093 0.0998 0.0875 0.0791 0.0743 0.0707 0.0689 0.0667 0.0656 0.0642 0.0636 0.0630 0.0624 0.0621 

[TRAIN] Epoch[1](5642/114412); Loss: 0.087716; Backpropagation: 0.2982 sec; Batch: 2.1271 sec
0.1454 0.1202 0.0987 0.0946 0.0869 0.0851 0.0823 0.0804 0.0789 0.0777 0.0769 0.0762 0.0755 0.0752 0.0748 0.0745 

[TRAIN] Epoch[1](5643/114412); Loss: 0.068520; Backpropagation: 0.2954 sec; Batch: 2.1269 sec
0.1568 0.1208 0.0800 0.0736 0.0677 0.0632 0.0596 0.0571 0.0550 0.0540 0.0530 0.0522 0.0515 0.0509 0.0506 0.0503 

[TRAIN] Epoch[1](5644/114412); Loss: 0.088366; Backpropagation: 0.2956 sec; Batch: 2.1228 sec
0.1707 0.1413 0.1181 0.1026 0.0894 0.0820 0.0796 0.0788 0.0747 0.0723 0.0702 0.0686 0.0677 0.0666 0.0659 0.0653 

[TRAIN] Epoch[1](5645/114412); Loss: 0.061231; Backpropagation: 0.2957 sec; Batch: 2.1069 sec
0.1236 0.1120 0.0868 0.0721 0.0627 0.0580 0.0544 0.0515 0.0492 0.0479 0.0461 0.0445 0.0438 0.0429 0.0423 0.0418 

[TRAIN] Epoch[1](5646/114412); Loss: 0.070165; Backpropagation: 0.2949 sec; Batch: 2.1230 sec
0.1410 0.1153 0.0954 0.0822 0.0726 0.0650 0.0622 0.0589 0.0572 0.0557 0.0551 0.0538 0.0527 0.0523 0.0518 0.0515 

[TRAIN] Epoch[1](5647/114412); Loss: 0.078358; Backpropagation: 0.2979 sec; Batch: 2.1255 sec
0.1533 0.1338 0.1059 0.0923 0.0781 0.0767 0.0703 0.0673 0.0650 0.0621 0.0608 0.0596 0.0583 0.0574 0.0566 0.0561 

[TRAIN] Epoch[1](5648/114412); Loss: 0.059829; Backpropagation: 0.2956 sec; Batch: 2.1257 sec
0.1617 0.1236 0.0747 0.0677 0.0597 0.0540 0.0480 0.0451 0.0437 0.0420 0.0414 0.0405 0.0395 0.0390 0.0385 0.0381 

[TRAIN] Epoch[1](5649/114412); Loss: 0.079810; Backpropagation: 0.2956 sec; Batch: 2.1338 sec
0.1335 0.1253 0.0974 0.0888 0.0821 0.0795 0.0753 0.0720 0.0696 0.0685 0.0667 0.0654 0.0645 0.0636 0.0626 0.0620 

[TRAIN] Epoch[1](5650/114412); Loss: 0.070247; Backpropagation: 0.2957 sec; Batch: 2.1223 sec
0.1293 0.1101 0.0858 0.0792 0.0719 0.0685 0.0652 0.0625 0.0606 0.0586 0.0575 0.0568 0.0555 0.0546 0.0541 0.0537 

[TRAIN] Epoch[1](5651/114412); Loss: 0.087083; Backpropagation: 0.2955 sec; Batch: 2.1230 sec
0.1961 0.1449 0.0975 0.0930 0.0844 0.0795 0.0762 0.0727 0.0718 0.0704 0.0696 0.0687 0.0679 0.0674 0.0668 0.0665 

[TRAIN] Epoch[1](5652/114412); Loss: 0.080337; Backpropagation: 0.2981 sec; Batch: 2.1328 sec
0.1547 0.1294 0.1007 0.0922 0.0823 0.0771 0.0741 0.0708 0.0674 0.0661 0.0642 0.0630 0.0619 0.0611 0.0604 0.0599 

[TRAIN] Epoch[1](5653/114412); Loss: 0.069867; Backpropagation: 0.2981 sec; Batch: 2.1245 sec
0.1564 0.1052 0.0831 0.0755 0.0691 0.0648 0.0619 0.0597 0.0580 0.0568 0.0558 0.0554 0.0548 0.0543 0.0537 0.0534 

[TRAIN] Epoch[1](5654/114412); Loss: 0.093526; Backpropagation: 0.2955 sec; Batch: 2.1293 sec
0.2043 0.1732 0.1343 0.1162 0.0940 0.0846 0.0768 0.0752 0.0727 0.0699 0.0680 0.0671 0.0659 0.0654 0.0648 0.0640 

[TRAIN] Epoch[1](5655/114412); Loss: 0.086196; Backpropagation: 0.2957 sec; Batch: 2.0845 sec
0.1490 0.1200 0.1104 0.1006 0.0941 0.0802 0.0807 0.0794 0.0750 0.0723 0.0714 0.0706 0.0696 0.0691 0.0684 0.0682 

[TRAIN] Epoch[1](5656/114412); Loss: 0.072408; Backpropagation: 0.2952 sec; Batch: 2.1252 sec
0.1514 0.1289 0.0996 0.0855 0.0753 0.0706 0.0657 0.0612 0.0579 0.0556 0.0538 0.0523 0.0513 0.0504 0.0497 0.0492 

[TRAIN] Epoch[1](5657/114412); Loss: 0.065479; Backpropagation: 0.2948 sec; Batch: 2.1235 sec
0.1526 0.1090 0.0849 0.0797 0.0662 0.0610 0.0573 0.0539 0.0518 0.0505 0.0488 0.0475 0.0470 0.0463 0.0457 0.0454 

[TRAIN] Epoch[1](5658/114412); Loss: 0.079900; Backpropagation: 0.2955 sec; Batch: 2.1040 sec
0.1355 0.1211 0.1006 0.0891 0.0818 0.0776 0.0738 0.0709 0.0694 0.0677 0.0667 0.0660 0.0652 0.0647 0.0642 0.0639 

[TRAIN] Epoch[1](5659/114412); Loss: 0.068325; Backpropagation: 0.2955 sec; Batch: 2.1380 sec
0.1553 0.1051 0.0830 0.0769 0.0688 0.0637 0.0594 0.0579 0.0568 0.0551 0.0538 0.0528 0.0522 0.0512 0.0509 0.0503 

[TRAIN] Epoch[1](5660/114412); Loss: 0.067270; Backpropagation: 0.2956 sec; Batch: 2.0949 sec
0.1520 0.1280 0.0947 0.0824 0.0737 0.0612 0.0567 0.0522 0.0500 0.0489 0.0477 0.0468 0.0462 0.0456 0.0453 0.0449 

[TRAIN] Epoch[1](5661/114412); Loss: 0.060531; Backpropagation: 0.2955 sec; Batch: 2.0827 sec
0.1673 0.1306 0.0969 0.0714 0.0607 0.0540 0.0505 0.0453 0.0440 0.0400 0.0378 0.0360 0.0345 0.0339 0.0331 0.0324 

[TRAIN] Epoch[1](5662/114412); Loss: 0.072878; Backpropagation: 0.3011 sec; Batch: 2.1279 sec
0.1416 0.1161 0.0867 0.0777 0.0723 0.0694 0.0662 0.0642 0.0623 0.0612 0.0599 0.0590 0.0581 0.0575 0.0572 0.0567 

[TRAIN] Epoch[1](5663/114412); Loss: 0.075529; Backpropagation: 0.2958 sec; Batch: 2.1234 sec
0.1430 0.1165 0.0920 0.0848 0.0768 0.0728 0.0688 0.0660 0.0645 0.0628 0.0617 0.0608 0.0601 0.0597 0.0592 0.0589 

[TRAIN] Epoch[1](5664/114412); Loss: 0.109316; Backpropagation: 0.2955 sec; Batch: 2.1216 sec
0.1877 0.1655 0.1351 0.1215 0.1125 0.1064 0.1021 0.0990 0.0959 0.0933 0.0911 0.0897 0.0884 0.0875 0.0869 0.0863 

[TRAIN] Epoch[1](5665/114412); Loss: 0.100728; Backpropagation: 0.2957 sec; Batch: 2.0830 sec
0.1953 0.1647 0.1459 0.1277 0.1124 0.0997 0.0925 0.0844 0.0800 0.0781 0.0749 0.0736 0.0723 0.0711 0.0698 0.0691 

[TRAIN] Epoch[1](5666/114412); Loss: 0.098705; Backpropagation: 0.3009 sec; Batch: 2.1300 sec
0.1662 0.1477 0.1200 0.1120 0.1011 0.0964 0.0924 0.0900 0.0875 0.0850 0.0828 0.0814 0.0802 0.0795 0.0788 0.0781 

[TRAIN] Epoch[1](5667/114412); Loss: 0.084308; Backpropagation: 0.3008 sec; Batch: 2.1372 sec
0.1819 0.1383 0.1030 0.0949 0.0833 0.0787 0.0750 0.0718 0.0694 0.0677 0.0663 0.0653 0.0643 0.0636 0.0628 0.0624 

[TRAIN] Epoch[1](5668/114412); Loss: 0.090251; Backpropagation: 0.3011 sec; Batch: 2.1250 sec
0.1541 0.1287 0.1154 0.1043 0.0960 0.0894 0.0844 0.0809 0.0780 0.0765 0.0750 0.0740 0.0729 0.0723 0.0714 0.0708 

[TRAIN] Epoch[1](5669/114412); Loss: 0.085218; Backpropagation: 0.3008 sec; Batch: 2.1247 sec
0.1832 0.1502 0.1202 0.1074 0.0950 0.0831 0.0743 0.0685 0.0653 0.0629 0.0615 0.0603 0.0591 0.0583 0.0576 0.0569 

[TRAIN] Epoch[1](5670/114412); Loss: 0.068543; Backpropagation: 0.3005 sec; Batch: 2.1290 sec
0.1651 0.1149 0.0765 0.0741 0.0692 0.0659 0.0620 0.0587 0.0557 0.0539 0.0524 0.0515 0.0500 0.0495 0.0488 0.0485 

[TRAIN] Epoch[1](5671/114412); Loss: 0.095915; Backpropagation: 0.2955 sec; Batch: 2.1243 sec
0.1723 0.1329 0.1116 0.1040 0.0962 0.0920 0.0886 0.0864 0.0849 0.0833 0.0821 0.0813 0.0806 0.0800 0.0793 0.0792 

[TRAIN] Epoch[1](5672/114412); Loss: 0.054227; Backpropagation: 0.3006 sec; Batch: 2.1227 sec
0.1014 0.0796 0.0681 0.0621 0.0560 0.0524 0.0496 0.0476 0.0459 0.0451 0.0445 0.0439 0.0433 0.0429 0.0427 0.0425 

[TRAIN] Epoch[1](5673/114412); Loss: 0.078999; Backpropagation: 0.2982 sec; Batch: 2.1265 sec
0.1528 0.1291 0.1028 0.0923 0.0812 0.0732 0.0696 0.0672 0.0649 0.0637 0.0631 0.0621 0.0612 0.0607 0.0602 0.0598 

[TRAIN] Epoch[1](5674/114412); Loss: 0.074019; Backpropagation: 0.2956 sec; Batch: 2.0836 sec
0.1574 0.1131 0.0940 0.0822 0.0754 0.0702 0.0659 0.0632 0.0617 0.0599 0.0587 0.0578 0.0571 0.0565 0.0559 0.0555 

[TRAIN] Epoch[1](5675/114412); Loss: 0.063924; Backpropagation: 0.2952 sec; Batch: 2.1234 sec
0.1288 0.0963 0.0803 0.0713 0.0655 0.0629 0.0583 0.0560 0.0546 0.0525 0.0509 0.0502 0.0495 0.0490 0.0486 0.0483 

[TRAIN] Epoch[1](5676/114412); Loss: 0.085336; Backpropagation: 0.2979 sec; Batch: 2.0854 sec
0.1940 0.1726 0.1372 0.1092 0.0904 0.0808 0.0723 0.0674 0.0619 0.0594 0.0571 0.0548 0.0532 0.0525 0.0517 0.0509 

[TRAIN] Epoch[1](5677/114412); Loss: 0.087676; Backpropagation: 0.2982 sec; Batch: 2.1254 sec
0.1379 0.1236 0.0978 0.0928 0.0883 0.0849 0.0825 0.0808 0.0793 0.0783 0.0776 0.0768 0.0762 0.0757 0.0753 0.0749 

[TRAIN] Epoch[1](5678/114412); Loss: 0.064563; Backpropagation: 0.2953 sec; Batch: 2.0827 sec
0.1621 0.1190 0.0802 0.0715 0.0610 0.0567 0.0531 0.0518 0.0506 0.0492 0.0477 0.0474 0.0465 0.0457 0.0453 0.0453 

[TRAIN] Epoch[1](5679/114412); Loss: 0.084357; Backpropagation: 0.2957 sec; Batch: 2.1256 sec
0.1628 0.1341 0.1066 0.0964 0.0893 0.0853 0.0773 0.0752 0.0721 0.0685 0.0671 0.0654 0.0637 0.0627 0.0619 0.0612 

[TRAIN] Epoch[1](5680/114412); Loss: 0.066662; Backpropagation: 0.2957 sec; Batch: 2.1209 sec
0.1200 0.1073 0.0844 0.0776 0.0711 0.0665 0.0626 0.0596 0.0567 0.0548 0.0533 0.0519 0.0511 0.0504 0.0499 0.0495 

[TRAIN] Epoch[1](5681/114412); Loss: 0.081130; Backpropagation: 0.2956 sec; Batch: 2.0838 sec
0.1435 0.1209 0.1005 0.0916 0.0823 0.0774 0.0741 0.0720 0.0702 0.0691 0.0680 0.0670 0.0661 0.0657 0.0650 0.0645 

[TRAIN] Epoch[1](5682/114412); Loss: 0.080503; Backpropagation: 0.2952 sec; Batch: 2.1625 sec
0.1591 0.1136 0.0968 0.0884 0.0821 0.0776 0.0745 0.0713 0.0694 0.0679 0.0668 0.0656 0.0647 0.0640 0.0633 0.0629 

[TRAIN] Epoch[1](5683/114412); Loss: 0.071499; Backpropagation: 0.2947 sec; Batch: 2.1253 sec
0.1526 0.1196 0.0912 0.0877 0.0747 0.0677 0.0657 0.0611 0.0567 0.0560 0.0539 0.0526 0.0518 0.0514 0.0508 0.0505 

[TRAIN] Epoch[1](5684/114412); Loss: 0.072298; Backpropagation: 0.3006 sec; Batch: 2.1317 sec
0.1674 0.1248 0.0914 0.0811 0.0726 0.0674 0.0625 0.0601 0.0576 0.0560 0.0549 0.0535 0.0527 0.0521 0.0516 0.0511 

[TRAIN] Epoch[1](5685/114412); Loss: 0.069654; Backpropagation: 0.2977 sec; Batch: 2.1275 sec
0.1138 0.1021 0.0869 0.0809 0.0738 0.0680 0.0665 0.0638 0.0608 0.0595 0.0581 0.0572 0.0565 0.0559 0.0556 0.0552 

[TRAIN] Epoch[1](5686/114412); Loss: 0.080664; Backpropagation: 0.2979 sec; Batch: 2.1242 sec
0.1475 0.1329 0.1061 0.0948 0.0800 0.0760 0.0719 0.0695 0.0679 0.0665 0.0651 0.0641 0.0629 0.0625 0.0618 0.0612 

[TRAIN] Epoch[1](5687/114412); Loss: 0.093921; Backpropagation: 0.2971 sec; Batch: 2.1219 sec
0.1638 0.1566 0.1184 0.1043 0.0943 0.0865 0.0858 0.0826 0.0807 0.0790 0.0776 0.0766 0.0752 0.0744 0.0739 0.0730 

[TRAIN] Epoch[1](5688/114412); Loss: 0.083702; Backpropagation: 0.3010 sec; Batch: 2.1273 sec
0.1864 0.1470 0.1083 0.0967 0.0863 0.0775 0.0707 0.0687 0.0658 0.0646 0.0633 0.0620 0.0614 0.0606 0.0601 0.0599 

[TRAIN] Epoch[1](5689/114412); Loss: 0.098220; Backpropagation: 0.2980 sec; Batch: 2.0891 sec
0.1752 0.1385 0.1176 0.1070 0.1004 0.0964 0.0924 0.0893 0.0865 0.0848 0.0833 0.0821 0.0810 0.0799 0.0789 0.0784 

[TRAIN] Epoch[1](5690/114412); Loss: 0.073189; Backpropagation: 0.2958 sec; Batch: 2.1222 sec
0.1304 0.1150 0.0966 0.0880 0.0775 0.0710 0.0652 0.0634 0.0616 0.0597 0.0588 0.0578 0.0572 0.0566 0.0563 0.0559 

[TRAIN] Epoch[1](5691/114412); Loss: 0.070795; Backpropagation: 0.2957 sec; Batch: 2.1252 sec
0.1139 0.1008 0.0815 0.0760 0.0721 0.0695 0.0674 0.0651 0.0637 0.0626 0.0616 0.0607 0.0601 0.0596 0.0593 0.0589 

[TRAIN] Epoch[1](5692/114412); Loss: 0.076626; Backpropagation: 0.2953 sec; Batch: 2.1253 sec
0.1577 0.1344 0.1102 0.0913 0.0783 0.0700 0.0664 0.0632 0.0608 0.0591 0.0576 0.0567 0.0560 0.0552 0.0548 0.0544 

[TRAIN] Epoch[1](5693/114412); Loss: 0.087941; Backpropagation: 0.2953 sec; Batch: 2.1252 sec
0.1300 0.1120 0.0994 0.0954 0.0898 0.0867 0.0847 0.0826 0.0808 0.0798 0.0789 0.0783 0.0777 0.0773 0.0769 0.0766 

[TRAIN] Epoch[1](5694/114412); Loss: 0.053810; Backpropagation: 0.2959 sec; Batch: 2.1699 sec
0.1065 0.0925 0.0742 0.0599 0.0555 0.0523 0.0492 0.0471 0.0443 0.0424 0.0413 0.0403 0.0397 0.0390 0.0384 0.0382 

[TRAIN] Epoch[1](5695/114412); Loss: 0.076226; Backpropagation: 0.2958 sec; Batch: 2.1260 sec
0.1688 0.1229 0.0947 0.0835 0.0744 0.0697 0.0661 0.0643 0.0630 0.0613 0.0602 0.0593 0.0586 0.0580 0.0575 0.0571 

[TRAIN] Epoch[1](5696/114412); Loss: 0.090110; Backpropagation: 0.2950 sec; Batch: 2.1244 sec
0.1711 0.1431 0.1229 0.1122 0.0996 0.0889 0.0854 0.0811 0.0730 0.0714 0.0692 0.0663 0.0656 0.0649 0.0641 0.0631 

[TRAIN] Epoch[1](5697/114412); Loss: 0.088646; Backpropagation: 0.2959 sec; Batch: 2.1231 sec
0.1401 0.1314 0.1091 0.1010 0.0928 0.0872 0.0834 0.0815 0.0785 0.0768 0.0755 0.0739 0.0728 0.0722 0.0713 0.0708 

[TRAIN] Epoch[1](5698/114412); Loss: 0.092362; Backpropagation: 0.2954 sec; Batch: 2.0830 sec
0.1775 0.1302 0.1119 0.1027 0.0933 0.0872 0.0845 0.0820 0.0797 0.0783 0.0773 0.0761 0.0752 0.0744 0.0740 0.0735 

[TRAIN] Epoch[1](5699/114412); Loss: 0.056523; Backpropagation: 0.2952 sec; Batch: 2.1247 sec
0.1145 0.1030 0.0822 0.0682 0.0594 0.0523 0.0495 0.0462 0.0446 0.0437 0.0422 0.0417 0.0402 0.0395 0.0389 0.0383 

[TRAIN] Epoch[1](5700/114412); Loss: 0.062977; Backpropagation: 0.2955 sec; Batch: 2.1263 sec
0.1498 0.0957 0.0858 0.0677 0.0602 0.0569 0.0536 0.0519 0.0504 0.0495 0.0488 0.0481 0.0477 0.0474 0.0472 0.0470 

[TRAIN] Epoch[1](5701/114412); Loss: 0.076059; Backpropagation: 0.2968 sec; Batch: 2.1272 sec
0.1280 0.0999 0.0890 0.0837 0.0788 0.0753 0.0727 0.0698 0.0684 0.0669 0.0657 0.0650 0.0642 0.0637 0.0632 0.0629 

[TRAIN] Epoch[1](5702/114412); Loss: 0.066457; Backpropagation: 0.2957 sec; Batch: 2.1234 sec
0.1356 0.1109 0.0793 0.0719 0.0675 0.0638 0.0602 0.0571 0.0551 0.0537 0.0527 0.0521 0.0515 0.0510 0.0506 0.0504 

[TRAIN] Epoch[1](5703/114412); Loss: 0.086966; Backpropagation: 0.2957 sec; Batch: 2.1229 sec
0.1724 0.1357 0.1118 0.0965 0.0886 0.0843 0.0794 0.0757 0.0730 0.0707 0.0696 0.0684 0.0673 0.0667 0.0659 0.0654 

[TRAIN] Epoch[1](5704/114412); Loss: 0.075826; Backpropagation: 0.2957 sec; Batch: 2.0999 sec
0.1483 0.1197 0.0971 0.0878 0.0792 0.0727 0.0686 0.0656 0.0636 0.0620 0.0608 0.0594 0.0582 0.0573 0.0567 0.0561 

[TRAIN] Epoch[1](5705/114412); Loss: 0.064860; Backpropagation: 0.2957 sec; Batch: 2.1254 sec
0.1414 0.1010 0.0869 0.0739 0.0666 0.0608 0.0575 0.0551 0.0531 0.0517 0.0504 0.0493 0.0485 0.0478 0.0472 0.0467 

[TRAIN] Epoch[1](5706/114412); Loss: 0.066472; Backpropagation: 0.2971 sec; Batch: 2.1270 sec
0.1173 0.1031 0.0843 0.0731 0.0664 0.0636 0.0611 0.0592 0.0574 0.0560 0.0552 0.0545 0.0538 0.0533 0.0528 0.0524 

[TRAIN] Epoch[1](5707/114412); Loss: 0.066436; Backpropagation: 0.2989 sec; Batch: 2.1292 sec
0.1562 0.1083 0.0904 0.0772 0.0674 0.0597 0.0567 0.0542 0.0525 0.0511 0.0498 0.0489 0.0481 0.0477 0.0476 0.0473 

[TRAIN] Epoch[1](5708/114412); Loss: 0.080440; Backpropagation: 0.2968 sec; Batch: 2.1205 sec
0.1835 0.1674 0.1181 0.0958 0.0771 0.0689 0.0652 0.0623 0.0598 0.0581 0.0571 0.0560 0.0553 0.0547 0.0540 0.0538 

[TRAIN] Epoch[1](5709/114412); Loss: 0.081414; Backpropagation: 0.2971 sec; Batch: 2.1228 sec
0.1797 0.1320 0.0989 0.0881 0.0821 0.0767 0.0716 0.0691 0.0671 0.0654 0.0637 0.0629 0.0623 0.0616 0.0609 0.0605 

[TRAIN] Epoch[1](5710/114412); Loss: 0.085656; Backpropagation: 0.2970 sec; Batch: 2.1255 sec
0.1842 0.1406 0.1047 0.0978 0.0894 0.0823 0.0771 0.0722 0.0703 0.0684 0.0663 0.0652 0.0643 0.0632 0.0627 0.0619 

[TRAIN] Epoch[1](5711/114412); Loss: 0.077102; Backpropagation: 0.2979 sec; Batch: 2.0956 sec
0.1329 0.1040 0.0907 0.0814 0.0778 0.0747 0.0726 0.0709 0.0691 0.0678 0.0667 0.0662 0.0655 0.0649 0.0644 0.0641 

[TRAIN] Epoch[1](5712/114412); Loss: 0.077035; Backpropagation: 0.2955 sec; Batch: 2.1007 sec
0.1682 0.1329 0.0940 0.0900 0.0803 0.0710 0.0663 0.0639 0.0619 0.0604 0.0589 0.0583 0.0576 0.0567 0.0563 0.0558 

[TRAIN] Epoch[1](5713/114412); Loss: 0.087928; Backpropagation: 0.2981 sec; Batch: 2.1253 sec
0.2021 0.1639 0.1223 0.1014 0.0849 0.0791 0.0737 0.0701 0.0680 0.0655 0.0643 0.0635 0.0627 0.0622 0.0617 0.0614 

[TRAIN] Epoch[1](5714/114412); Loss: 0.054887; Backpropagation: 0.2959 sec; Batch: 2.1231 sec
0.1473 0.1280 0.0845 0.0649 0.0567 0.0490 0.0416 0.0392 0.0384 0.0357 0.0343 0.0329 0.0321 0.0317 0.0311 0.0309 

[TRAIN] Epoch[1](5715/114412); Loss: 0.077118; Backpropagation: 0.2957 sec; Batch: 2.1397 sec
0.1690 0.1294 0.1104 0.0941 0.0800 0.0692 0.0675 0.0640 0.0602 0.0586 0.0574 0.0561 0.0553 0.0547 0.0543 0.0538 

[TRAIN] Epoch[1](5716/114412); Loss: 0.093654; Backpropagation: 0.2957 sec; Batch: 2.1227 sec
0.1827 0.1485 0.1093 0.1013 0.0926 0.0874 0.0847 0.0824 0.0800 0.0781 0.0773 0.0762 0.0754 0.0749 0.0742 0.0735 

[TRAIN] Epoch[1](5717/114412); Loss: 0.084089; Backpropagation: 0.2953 sec; Batch: 2.1241 sec
0.1859 0.1635 0.1323 0.1096 0.0891 0.0755 0.0680 0.0637 0.0612 0.0596 0.0581 0.0570 0.0562 0.0555 0.0553 0.0549 

[TRAIN] Epoch[1](5718/114412); Loss: 0.105449; Backpropagation: 0.2954 sec; Batch: 2.1259 sec
0.1977 0.1710 0.1394 0.1326 0.1181 0.1049 0.0989 0.0943 0.0866 0.0846 0.0834 0.0787 0.0759 0.0757 0.0741 0.0712 

[TRAIN] Epoch[1](5719/114412); Loss: 0.093084; Backpropagation: 0.2962 sec; Batch: 2.1272 sec
0.1856 0.1504 0.1201 0.1121 0.0997 0.0918 0.0875 0.0834 0.0778 0.0752 0.0731 0.0699 0.0669 0.0666 0.0658 0.0634 

[TRAIN] Epoch[1](5720/114412); Loss: 0.061435; Backpropagation: 0.2956 sec; Batch: 2.1246 sec
0.1579 0.1115 0.0695 0.0675 0.0593 0.0536 0.0515 0.0491 0.0475 0.0466 0.0457 0.0452 0.0450 0.0446 0.0443 0.0442 

[TRAIN] Epoch[1](5721/114412); Loss: 0.066776; Backpropagation: 0.2953 sec; Batch: 2.1244 sec
0.1497 0.1178 0.0895 0.0810 0.0712 0.0617 0.0567 0.0541 0.0522 0.0504 0.0491 0.0481 0.0474 0.0470 0.0464 0.0461 

[TRAIN] Epoch[1](5722/114412); Loss: 0.074340; Backpropagation: 0.2953 sec; Batch: 2.1022 sec
0.1766 0.1224 0.1021 0.0818 0.0743 0.0673 0.0632 0.0606 0.0586 0.0571 0.0561 0.0550 0.0545 0.0538 0.0534 0.0529 

[TRAIN] Epoch[1](5723/114412); Loss: 0.078849; Backpropagation: 0.2961 sec; Batch: 2.1257 sec
0.1246 0.1104 0.0950 0.0895 0.0801 0.0762 0.0748 0.0721 0.0701 0.0692 0.0680 0.0673 0.0667 0.0662 0.0658 0.0656 

[TRAIN] Epoch[1](5724/114412); Loss: 0.052642; Backpropagation: 0.2958 sec; Batch: 2.1257 sec
0.1305 0.0899 0.0765 0.0596 0.0531 0.0507 0.0459 0.0426 0.0415 0.0388 0.0372 0.0364 0.0356 0.0350 0.0345 0.0341 

[TRAIN] Epoch[1](5725/114412); Loss: 0.075002; Backpropagation: 0.2959 sec; Batch: 2.0836 sec
0.1561 0.1339 0.0989 0.0899 0.0746 0.0709 0.0678 0.0630 0.0611 0.0591 0.0576 0.0560 0.0542 0.0533 0.0521 0.0514 

[TRAIN] Epoch[1](5726/114412); Loss: 0.074882; Backpropagation: 0.2972 sec; Batch: 2.1251 sec
0.1444 0.1142 0.0920 0.0835 0.0760 0.0713 0.0680 0.0655 0.0638 0.0620 0.0613 0.0603 0.0596 0.0592 0.0587 0.0583 

[TRAIN] Epoch[1](5727/114412); Loss: 0.068043; Backpropagation: 0.2960 sec; Batch: 2.1245 sec
0.1469 0.1172 0.0911 0.0788 0.0670 0.0619 0.0591 0.0566 0.0544 0.0530 0.0520 0.0512 0.0505 0.0501 0.0495 0.0495 

[TRAIN] Epoch[1](5728/114412); Loss: 0.084823; Backpropagation: 0.2983 sec; Batch: 2.1224 sec
0.2207 0.1614 0.1145 0.0937 0.0762 0.0672 0.0654 0.0629 0.0629 0.0623 0.0615 0.0617 0.0616 0.0617 0.0618 0.0617 

[TRAIN] Epoch[1](5729/114412); Loss: 0.065658; Backpropagation: 0.2996 sec; Batch: 2.1271 sec
0.1162 0.1030 0.0802 0.0716 0.0686 0.0636 0.0614 0.0585 0.0571 0.0550 0.0540 0.0532 0.0526 0.0523 0.0519 0.0515 

[TRAIN] Epoch[1](5730/114412); Loss: 0.073787; Backpropagation: 0.2967 sec; Batch: 2.1277 sec
0.1513 0.1111 0.0948 0.0828 0.0760 0.0701 0.0662 0.0636 0.0619 0.0604 0.0589 0.0579 0.0572 0.0567 0.0561 0.0556 

[TRAIN] Epoch[1](5731/114412); Loss: 0.083198; Backpropagation: 0.2968 sec; Batch: 2.1242 sec
0.1473 0.1284 0.1034 0.0902 0.0824 0.0791 0.0755 0.0739 0.0719 0.0707 0.0698 0.0687 0.0682 0.0676 0.0671 0.0669 

[TRAIN] Epoch[1](5732/114412); Loss: 0.065699; Backpropagation: 0.2968 sec; Batch: 2.1262 sec
0.1496 0.1065 0.0851 0.0724 0.0650 0.0593 0.0571 0.0549 0.0530 0.0521 0.0509 0.0502 0.0496 0.0490 0.0485 0.0481 

[TRAIN] Epoch[1](5733/114412); Loss: 0.077033; Backpropagation: 0.2994 sec; Batch: 2.1426 sec
0.1368 0.1146 0.0937 0.0851 0.0814 0.0756 0.0718 0.0681 0.0669 0.0648 0.0636 0.0630 0.0624 0.0619 0.0617 0.0613 

[TRAIN] Epoch[1](5734/114412); Loss: 0.066501; Backpropagation: 0.2984 sec; Batch: 2.1258 sec
0.1336 0.1192 0.1005 0.0847 0.0731 0.0665 0.0592 0.0549 0.0507 0.0500 0.0485 0.0465 0.0452 0.0443 0.0436 0.0435 

[TRAIN] Epoch[1](5735/114412); Loss: 0.064609; Backpropagation: 0.2980 sec; Batch: 2.1289 sec
0.1508 0.1161 0.0825 0.0712 0.0633 0.0583 0.0555 0.0535 0.0512 0.0497 0.0487 0.0478 0.0472 0.0464 0.0460 0.0455 

[TRAIN] Epoch[1](5736/114412); Loss: 0.069404; Backpropagation: 0.2959 sec; Batch: 2.1229 sec
0.1934 0.1445 0.0998 0.0801 0.0661 0.0602 0.0554 0.0528 0.0489 0.0477 0.0456 0.0446 0.0435 0.0429 0.0426 0.0423 

[TRAIN] Epoch[1](5737/114412); Loss: 0.055953; Backpropagation: 0.2953 sec; Batch: 2.1212 sec
0.1584 0.1020 0.0634 0.0580 0.0532 0.0490 0.0457 0.0430 0.0422 0.0415 0.0407 0.0401 0.0398 0.0395 0.0393 0.0392 

[TRAIN] Epoch[1](5738/114412); Loss: 0.077563; Backpropagation: 0.2957 sec; Batch: 2.1220 sec
0.1340 0.1213 0.0936 0.0848 0.0776 0.0737 0.0705 0.0684 0.0673 0.0664 0.0653 0.0646 0.0640 0.0634 0.0632 0.0629 

[TRAIN] Epoch[1](5739/114412); Loss: 0.077864; Backpropagation: 0.2954 sec; Batch: 2.1206 sec
0.1618 0.1226 0.0962 0.0854 0.0792 0.0754 0.0714 0.0678 0.0652 0.0636 0.0621 0.0607 0.0597 0.0589 0.0582 0.0577 

[TRAIN] Epoch[1](5740/114412); Loss: 0.065996; Backpropagation: 0.3005 sec; Batch: 2.1266 sec
0.1209 0.1012 0.0784 0.0714 0.0687 0.0635 0.0610 0.0585 0.0571 0.0558 0.0548 0.0540 0.0533 0.0528 0.0524 0.0520 

[TRAIN] Epoch[1](5741/114412); Loss: 0.086493; Backpropagation: 0.3007 sec; Batch: 2.1270 sec
0.1589 0.1351 0.1048 0.0960 0.0897 0.0827 0.0791 0.0767 0.0741 0.0724 0.0710 0.0698 0.0691 0.0686 0.0681 0.0676 

[TRAIN] Epoch[1](5742/114412); Loss: 0.088141; Backpropagation: 0.2982 sec; Batch: 2.1299 sec
0.1673 0.1487 0.1133 0.1020 0.0898 0.0814 0.0773 0.0740 0.0730 0.0712 0.0701 0.0693 0.0688 0.0683 0.0680 0.0677 

[TRAIN] Epoch[1](5743/114412); Loss: 0.071088; Backpropagation: 0.2967 sec; Batch: 2.1090 sec
0.1254 0.0988 0.0879 0.0758 0.0711 0.0684 0.0662 0.0641 0.0627 0.0614 0.0606 0.0598 0.0593 0.0589 0.0586 0.0583 

[TRAIN] Epoch[1](5744/114412); Loss: 0.079592; Backpropagation: 0.2967 sec; Batch: 2.1241 sec
0.1698 0.1329 0.1052 0.0953 0.0847 0.0759 0.0712 0.0664 0.0641 0.0619 0.0606 0.0590 0.0581 0.0570 0.0560 0.0554 

[TRAIN] Epoch[1](5745/114412); Loss: 0.072338; Backpropagation: 0.2971 sec; Batch: 2.1537 sec
0.1562 0.1399 0.1016 0.0827 0.0675 0.0640 0.0591 0.0572 0.0561 0.0548 0.0542 0.0536 0.0529 0.0527 0.0525 0.0523 

[TRAIN] Epoch[1](5746/114412); Loss: 0.055041; Backpropagation: 0.2992 sec; Batch: 2.1233 sec
0.1084 0.0850 0.0696 0.0630 0.0574 0.0522 0.0507 0.0468 0.0456 0.0451 0.0441 0.0434 0.0428 0.0425 0.0421 0.0419 

[TRAIN] Epoch[1](5747/114412); Loss: 0.077538; Backpropagation: 0.2995 sec; Batch: 2.1261 sec
0.1634 0.1404 0.1000 0.0881 0.0779 0.0709 0.0673 0.0641 0.0628 0.0607 0.0592 0.0586 0.0577 0.0570 0.0565 0.0559 

[TRAIN] Epoch[1](5748/114412); Loss: 0.100601; Backpropagation: 0.2965 sec; Batch: 2.1234 sec
0.1557 0.1339 0.1154 0.1082 0.1032 0.0983 0.0960 0.0948 0.0924 0.0907 0.0894 0.0881 0.0869 0.0863 0.0854 0.0848 

[TRAIN] Epoch[1](5749/114412); Loss: 0.082560; Backpropagation: 0.2965 sec; Batch: 2.1194 sec
0.1331 0.1102 0.0995 0.0912 0.0856 0.0809 0.0782 0.0758 0.0737 0.0726 0.0716 0.0708 0.0702 0.0696 0.0691 0.0689 

[TRAIN] Epoch[1](5750/114412); Loss: 0.092440; Backpropagation: 0.2963 sec; Batch: 2.1223 sec
0.1721 0.1441 0.1202 0.1068 0.0949 0.0882 0.0857 0.0818 0.0781 0.0771 0.0750 0.0737 0.0721 0.0710 0.0695 0.0686 

[TRAIN] Epoch[1](5751/114412); Loss: 0.065341; Backpropagation: 0.2956 sec; Batch: 2.1009 sec
0.1228 0.1095 0.0841 0.0772 0.0687 0.0607 0.0588 0.0564 0.0543 0.0529 0.0517 0.0508 0.0501 0.0496 0.0491 0.0488 

[TRAIN] Epoch[1](5752/114412); Loss: 0.052006; Backpropagation: 0.2953 sec; Batch: 2.1204 sec
0.1256 0.1099 0.0879 0.0634 0.0535 0.0424 0.0401 0.0385 0.0370 0.0358 0.0345 0.0337 0.0332 0.0325 0.0322 0.0319 

[TRAIN] Epoch[1](5753/114412); Loss: 0.058389; Backpropagation: 0.2964 sec; Batch: 2.1269 sec
0.1162 0.0928 0.0888 0.0721 0.0626 0.0551 0.0517 0.0496 0.0462 0.0452 0.0442 0.0430 0.0424 0.0419 0.0413 0.0410 

[TRAIN] Epoch[1](5754/114412); Loss: 0.096952; Backpropagation: 0.2955 sec; Batch: 2.1207 sec
0.2119 0.1801 0.1262 0.1022 0.0896 0.0830 0.0816 0.0804 0.0781 0.0767 0.0753 0.0745 0.0738 0.0729 0.0726 0.0724 

[TRAIN] Epoch[1](5755/114412); Loss: 0.078507; Backpropagation: 0.2953 sec; Batch: 2.1254 sec
0.1882 0.1322 0.0943 0.0875 0.0770 0.0726 0.0693 0.0653 0.0625 0.0614 0.0599 0.0584 0.0579 0.0570 0.0566 0.0560 

[TRAIN] Epoch[1](5756/114412); Loss: 0.081023; Backpropagation: 0.2966 sec; Batch: 2.1120 sec
0.1332 0.1130 0.0979 0.0881 0.0833 0.0789 0.0768 0.0741 0.0717 0.0706 0.0696 0.0690 0.0682 0.0676 0.0673 0.0669 

[TRAIN] Epoch[1](5757/114412); Loss: 0.092270; Backpropagation: 0.2966 sec; Batch: 2.1250 sec
0.1593 0.1329 0.1149 0.1066 0.0976 0.0902 0.0851 0.0817 0.0798 0.0783 0.0771 0.0760 0.0750 0.0745 0.0738 0.0734 

[TRAIN] Epoch[1](5758/114412); Loss: 0.085442; Backpropagation: 0.3008 sec; Batch: 2.1306 sec
0.1648 0.1473 0.1096 0.0936 0.0825 0.0779 0.0753 0.0735 0.0714 0.0702 0.0688 0.0679 0.0670 0.0663 0.0657 0.0653 

[TRAIN] Epoch[1](5759/114412); Loss: 0.083103; Backpropagation: 0.2969 sec; Batch: 2.1280 sec
0.1418 0.1225 0.0985 0.0897 0.0838 0.0794 0.0765 0.0751 0.0736 0.0719 0.0711 0.0703 0.0695 0.0691 0.0686 0.0684 

[TRAIN] Epoch[1](5760/114412); Loss: 0.091993; Backpropagation: 0.2958 sec; Batch: 2.1251 sec
0.2026 0.1618 0.1141 0.1003 0.0936 0.0856 0.0813 0.0769 0.0744 0.0725 0.0710 0.0693 0.0682 0.0675 0.0667 0.0659 

[TRAIN] Epoch[1](5761/114412); Loss: 0.072239; Backpropagation: 0.2953 sec; Batch: 2.1540 sec
0.1620 0.1381 0.0953 0.0809 0.0707 0.0648 0.0605 0.0576 0.0562 0.0550 0.0538 0.0532 0.0525 0.0521 0.0517 0.0513 

[TRAIN] Epoch[1](5762/114412); Loss: 0.070200; Backpropagation: 0.2978 sec; Batch: 2.1680 sec
0.1457 0.1150 0.0953 0.0796 0.0726 0.0683 0.0620 0.0585 0.0570 0.0554 0.0539 0.0532 0.0524 0.0518 0.0514 0.0510 

[TRAIN] Epoch[1](5763/114412); Loss: 0.061250; Backpropagation: 0.2959 sec; Batch: 2.1224 sec
0.1800 0.1462 0.0847 0.0684 0.0593 0.0504 0.0471 0.0442 0.0422 0.0401 0.0384 0.0372 0.0365 0.0356 0.0350 0.0347 

[TRAIN] Epoch[1](5764/114412); Loss: 0.087421; Backpropagation: 0.2958 sec; Batch: 2.1466 sec
0.1688 0.1442 0.1099 0.0993 0.0864 0.0815 0.0785 0.0752 0.0731 0.0717 0.0704 0.0695 0.0683 0.0679 0.0672 0.0669 

[TRAIN] Epoch[1](5765/114412); Loss: 0.087172; Backpropagation: 0.2969 sec; Batch: 2.0840 sec
0.1692 0.1395 0.1105 0.0956 0.0866 0.0817 0.0778 0.0749 0.0737 0.0716 0.0706 0.0700 0.0690 0.0684 0.0681 0.0676 

[TRAIN] Epoch[1](5766/114412); Loss: 0.076145; Backpropagation: 0.2947 sec; Batch: 2.1203 sec
0.1927 0.1570 0.1154 0.0912 0.0801 0.0684 0.0626 0.0590 0.0544 0.0527 0.0509 0.0488 0.0476 0.0467 0.0457 0.0451 

[TRAIN] Epoch[1](5767/114412); Loss: 0.097584; Backpropagation: 0.2952 sec; Batch: 2.0831 sec
0.1589 0.1355 0.1136 0.1053 0.0981 0.0948 0.0920 0.0898 0.0878 0.0863 0.0850 0.0843 0.0835 0.0828 0.0821 0.0816 

[TRAIN] Epoch[1](5768/114412); Loss: 0.056996; Backpropagation: 0.3008 sec; Batch: 2.1262 sec
0.1266 0.0987 0.0806 0.0685 0.0592 0.0524 0.0498 0.0466 0.0443 0.0432 0.0421 0.0410 0.0404 0.0400 0.0396 0.0392 

[TRAIN] Epoch[1](5769/114412); Loss: 0.065444; Backpropagation: 0.2984 sec; Batch: 2.1157 sec
0.1694 0.1433 0.0820 0.0650 0.0617 0.0582 0.0538 0.0499 0.0490 0.0470 0.0459 0.0452 0.0449 0.0443 0.0439 0.0437 

[TRAIN] Epoch[1](5770/114412); Loss: 0.085518; Backpropagation: 0.2982 sec; Batch: 2.1434 sec
0.2484 0.1955 0.1204 0.0925 0.0774 0.0702 0.0647 0.0612 0.0592 0.0573 0.0557 0.0547 0.0537 0.0529 0.0525 0.0520 

[TRAIN] Epoch[1](5771/114412); Loss: 0.070645; Backpropagation: 0.2956 sec; Batch: 2.1102 sec
0.1773 0.1479 0.1053 0.0841 0.0736 0.0650 0.0588 0.0532 0.0502 0.0483 0.0468 0.0455 0.0447 0.0439 0.0431 0.0428 

[TRAIN] Epoch[1](5772/114412); Loss: 0.057007; Backpropagation: 0.2957 sec; Batch: 2.1483 sec
0.1312 0.1126 0.0772 0.0667 0.0580 0.0507 0.0476 0.0452 0.0435 0.0423 0.0411 0.0403 0.0397 0.0391 0.0386 0.0382 

[TRAIN] Epoch[1](5773/114412); Loss: 0.083379; Backpropagation: 0.2984 sec; Batch: 2.1268 sec
0.1876 0.1523 0.1075 0.0976 0.0845 0.0775 0.0726 0.0674 0.0658 0.0636 0.0623 0.0610 0.0599 0.0589 0.0581 0.0575 

[TRAIN] Epoch[1](5774/114412); Loss: 0.071072; Backpropagation: 0.2955 sec; Batch: 2.2281 sec
0.1623 0.1185 0.0933 0.0787 0.0716 0.0651 0.0618 0.0591 0.0568 0.0551 0.0542 0.0533 0.0526 0.0520 0.0516 0.0513 

[TRAIN] Epoch[1](5775/114412); Loss: 0.089876; Backpropagation: 0.2953 sec; Batch: 2.2399 sec
0.1564 0.1409 0.1133 0.0991 0.0922 0.0861 0.0822 0.0796 0.0776 0.0761 0.0745 0.0735 0.0726 0.0718 0.0711 0.0707 

[TRAIN] Epoch[1](5776/114412); Loss: 0.064695; Backpropagation: 0.2956 sec; Batch: 2.1127 sec
0.1191 0.1010 0.0732 0.0725 0.0666 0.0613 0.0588 0.0570 0.0560 0.0547 0.0538 0.0530 0.0526 0.0522 0.0518 0.0516 

[TRAIN] Epoch[1](5777/114412); Loss: 0.064661; Backpropagation: 0.2956 sec; Batch: 2.1223 sec
0.1795 0.1386 0.0865 0.0746 0.0614 0.0548 0.0516 0.0484 0.0453 0.0443 0.0433 0.0424 0.0417 0.0411 0.0407 0.0403 

[TRAIN] Epoch[1](5778/114412); Loss: 0.091561; Backpropagation: 0.2958 sec; Batch: 2.1182 sec
0.1711 0.1516 0.1282 0.1118 0.0985 0.0900 0.0825 0.0778 0.0748 0.0720 0.0701 0.0689 0.0679 0.0670 0.0665 0.0662 

[TRAIN] Epoch[1](5779/114412); Loss: 0.055057; Backpropagation: 0.2979 sec; Batch: 2.1502 sec
0.1718 0.1301 0.0779 0.0565 0.0570 0.0505 0.0432 0.0389 0.0352 0.0338 0.0324 0.0317 0.0312 0.0307 0.0301 0.0299 

[TRAIN] Epoch[1](5780/114412); Loss: 0.056163; Backpropagation: 0.3006 sec; Batch: 2.1768 sec
0.1418 0.1065 0.0799 0.0595 0.0543 0.0507 0.0464 0.0443 0.0424 0.0409 0.0401 0.0393 0.0385 0.0382 0.0381 0.0379 

[TRAIN] Epoch[1](5781/114412); Loss: 0.089636; Backpropagation: 0.2980 sec; Batch: 2.1460 sec
0.1746 0.1512 0.1166 0.1022 0.0934 0.0857 0.0800 0.0766 0.0736 0.0716 0.0700 0.0690 0.0682 0.0676 0.0672 0.0667 

[TRAIN] Epoch[1](5782/114412); Loss: 0.069502; Backpropagation: 0.2977 sec; Batch: 2.1785 sec
0.1510 0.1303 0.0919 0.0755 0.0672 0.0624 0.0591 0.0567 0.0555 0.0543 0.0531 0.0523 0.0516 0.0509 0.0503 0.0500 

[TRAIN] Epoch[1](5783/114412); Loss: 0.059893; Backpropagation: 0.2955 sec; Batch: 2.1464 sec
0.1484 0.1303 0.0885 0.0685 0.0563 0.0504 0.0475 0.0454 0.0436 0.0422 0.0409 0.0402 0.0395 0.0391 0.0388 0.0386 

[TRAIN] Epoch[1](5784/114412); Loss: 0.088792; Backpropagation: 0.2955 sec; Batch: 2.1494 sec
0.1643 0.1385 0.1071 0.0980 0.0905 0.0847 0.0812 0.0782 0.0765 0.0743 0.0730 0.0722 0.0714 0.0709 0.0702 0.0696 

[TRAIN] Epoch[1](5785/114412); Loss: 0.060129; Backpropagation: 0.3013 sec; Batch: 2.1232 sec
0.1107 0.0960 0.0827 0.0660 0.0615 0.0586 0.0538 0.0519 0.0507 0.0492 0.0483 0.0476 0.0468 0.0465 0.0460 0.0458 

[TRAIN] Epoch[1](5786/114412); Loss: 0.054452; Backpropagation: 0.2979 sec; Batch: 2.1277 sec
0.1189 0.1021 0.0669 0.0553 0.0550 0.0495 0.0478 0.0457 0.0442 0.0427 0.0418 0.0411 0.0406 0.0401 0.0399 0.0397 

[TRAIN] Epoch[1](5787/114412); Loss: 0.069423; Backpropagation: 0.2985 sec; Batch: 2.0863 sec
0.1360 0.1160 0.0907 0.0762 0.0714 0.0655 0.0628 0.0602 0.0579 0.0562 0.0548 0.0538 0.0532 0.0524 0.0520 0.0515 

[TRAIN] Epoch[1](5788/114412); Loss: 0.089970; Backpropagation: 0.3006 sec; Batch: 2.1232 sec
0.1733 0.1458 0.1152 0.0988 0.0913 0.0836 0.0807 0.0778 0.0760 0.0738 0.0724 0.0715 0.0706 0.0700 0.0695 0.0690 

[TRAIN] Epoch[1](5789/114412); Loss: 0.068988; Backpropagation: 0.2978 sec; Batch: 2.1257 sec
0.1704 0.1363 0.0895 0.0766 0.0681 0.0615 0.0579 0.0546 0.0528 0.0510 0.0496 0.0486 0.0476 0.0469 0.0464 0.0461 

[TRAIN] Epoch[1](5790/114412); Loss: 0.091298; Backpropagation: 0.2982 sec; Batch: 2.0886 sec
0.1602 0.1496 0.1215 0.1125 0.0981 0.0898 0.0830 0.0791 0.0754 0.0740 0.0724 0.0708 0.0699 0.0691 0.0680 0.0674 

[TRAIN] Epoch[1](5791/114412); Loss: 0.094339; Backpropagation: 0.2955 sec; Batch: 2.0920 sec
0.1478 0.1406 0.1137 0.1049 0.0963 0.0922 0.0887 0.0859 0.0843 0.0826 0.0811 0.0799 0.0790 0.0781 0.0775 0.0769 

[TRAIN] Epoch[1](5792/114412); Loss: 0.088962; Backpropagation: 0.2955 sec; Batch: 2.1240 sec
0.1641 0.1426 0.1125 0.0981 0.0906 0.0840 0.0800 0.0778 0.0754 0.0740 0.0727 0.0718 0.0709 0.0703 0.0696 0.0692 

[TRAIN] Epoch[1](5793/114412); Loss: 0.074413; Backpropagation: 0.2983 sec; Batch: 2.2203 sec
0.1569 0.1323 0.0948 0.0810 0.0747 0.0688 0.0656 0.0632 0.0607 0.0591 0.0577 0.0567 0.0558 0.0550 0.0544 0.0538 

[TRAIN] Epoch[1](5794/114412); Loss: 0.073075; Backpropagation: 0.2961 sec; Batch: 2.1452 sec
0.1237 0.1047 0.0864 0.0791 0.0765 0.0730 0.0676 0.0658 0.0642 0.0627 0.0620 0.0612 0.0610 0.0606 0.0603 0.0602 

[TRAIN] Epoch[1](5795/114412); Loss: 0.071607; Backpropagation: 0.2952 sec; Batch: 2.1281 sec
0.1539 0.1355 0.0894 0.0758 0.0705 0.0658 0.0620 0.0597 0.0577 0.0563 0.0548 0.0540 0.0534 0.0529 0.0523 0.0520 

[TRAIN] Epoch[1](5796/114412); Loss: 0.072770; Backpropagation: 0.2957 sec; Batch: 2.3232 sec
0.1320 0.1151 0.0902 0.0787 0.0715 0.0685 0.0655 0.0632 0.0624 0.0613 0.0606 0.0600 0.0593 0.0589 0.0586 0.0584 

[TRAIN] Epoch[1](5797/114412); Loss: 0.052998; Backpropagation: 0.2952 sec; Batch: 2.1684 sec
0.1327 0.1088 0.0691 0.0588 0.0497 0.0475 0.0453 0.0411 0.0397 0.0386 0.0378 0.0370 0.0363 0.0357 0.0350 0.0348 

[TRAIN] Epoch[1](5798/114412); Loss: 0.067916; Backpropagation: 0.2953 sec; Batch: 2.1245 sec
0.1523 0.1281 0.0969 0.0765 0.0685 0.0627 0.0579 0.0547 0.0528 0.0512 0.0500 0.0485 0.0476 0.0469 0.0463 0.0458 

[TRAIN] Epoch[1](5799/114412); Loss: 0.053286; Backpropagation: 0.2958 sec; Batch: 2.1240 sec
0.1129 0.0891 0.0686 0.0596 0.0551 0.0497 0.0477 0.0456 0.0437 0.0423 0.0413 0.0403 0.0399 0.0393 0.0390 0.0387 

[TRAIN] Epoch[1](5800/114412); Loss: 0.078330; Backpropagation: 0.2955 sec; Batch: 2.1273 sec
0.1743 0.1416 0.0930 0.0849 0.0745 0.0721 0.0693 0.0649 0.0634 0.0615 0.0607 0.0600 0.0588 0.0584 0.0580 0.0578 

[TRAIN] Epoch[1](5801/114412); Loss: 0.094780; Backpropagation: 0.2962 sec; Batch: 2.1829 sec
0.1745 0.1604 0.1145 0.1017 0.0939 0.0887 0.0865 0.0830 0.0809 0.0786 0.0775 0.0766 0.0758 0.0751 0.0745 0.0744 

[TRAIN] Epoch[1](5802/114412); Loss: 0.078479; Backpropagation: 0.2953 sec; Batch: 2.0845 sec
0.1959 0.1710 0.1093 0.0868 0.0727 0.0684 0.0614 0.0618 0.0589 0.0560 0.0540 0.0528 0.0525 0.0519 0.0512 0.0511 

[TRAIN] Epoch[1](5803/114412); Loss: 0.081434; Backpropagation: 0.3003 sec; Batch: 2.0885 sec
0.1527 0.1383 0.1143 0.0959 0.0808 0.0741 0.0705 0.0679 0.0666 0.0651 0.0640 0.0631 0.0626 0.0626 0.0623 0.0623 

[TRAIN] Epoch[1](5804/114412); Loss: 0.067025; Backpropagation: 0.2954 sec; Batch: 2.1233 sec
0.1371 0.1173 0.0892 0.0738 0.0675 0.0621 0.0586 0.0564 0.0546 0.0531 0.0522 0.0512 0.0506 0.0500 0.0497 0.0492 

[TRAIN] Epoch[1](5805/114412); Loss: 0.091481; Backpropagation: 0.2955 sec; Batch: 2.0821 sec
0.1893 0.1598 0.1219 0.1029 0.0941 0.0881 0.0837 0.0803 0.0764 0.0738 0.0711 0.0684 0.0662 0.0643 0.0625 0.0612 

[TRAIN] Epoch[1](5806/114412); Loss: 0.099985; Backpropagation: 0.2955 sec; Batch: 2.1193 sec
0.1902 0.1774 0.1531 0.1276 0.1119 0.0975 0.0881 0.0809 0.0770 0.0748 0.0730 0.0716 0.0704 0.0694 0.0688 0.0681 

[TRAIN] Epoch[1](5807/114412); Loss: 0.083621; Backpropagation: 0.2981 sec; Batch: 2.1049 sec
0.1318 0.1222 0.1026 0.0940 0.0880 0.0835 0.0804 0.0762 0.0741 0.0724 0.0709 0.0698 0.0687 0.0682 0.0677 0.0673 

[TRAIN] Epoch[1](5808/114412); Loss: 0.084699; Backpropagation: 0.2957 sec; Batch: 2.0921 sec
0.1804 0.1589 0.1210 0.0993 0.0881 0.0804 0.0741 0.0694 0.0666 0.0640 0.0618 0.0604 0.0590 0.0580 0.0574 0.0567 

[TRAIN] Epoch[1](5809/114412); Loss: 0.074793; Backpropagation: 0.2955 sec; Batch: 2.1208 sec
0.1376 0.1230 0.0944 0.0855 0.0781 0.0712 0.0670 0.0645 0.0621 0.0611 0.0601 0.0592 0.0589 0.0583 0.0581 0.0578 

[TRAIN] Epoch[1](5810/114412); Loss: 0.061371; Backpropagation: 0.2953 sec; Batch: 2.1483 sec
0.1323 0.1047 0.0770 0.0690 0.0628 0.0567 0.0538 0.0509 0.0495 0.0483 0.0475 0.0467 0.0463 0.0458 0.0455 0.0452 

[TRAIN] Epoch[1](5811/114412); Loss: 0.085366; Backpropagation: 0.2950 sec; Batch: 2.1248 sec
0.1792 0.1583 0.1055 0.0954 0.0849 0.0791 0.0747 0.0712 0.0682 0.0669 0.0654 0.0647 0.0640 0.0631 0.0628 0.0625 

[TRAIN] Epoch[1](5812/114412); Loss: 0.063796; Backpropagation: 0.2959 sec; Batch: 2.1222 sec
0.1330 0.1151 0.0907 0.0707 0.0678 0.0630 0.0562 0.0532 0.0508 0.0485 0.0471 0.0461 0.0453 0.0447 0.0444 0.0440 

[TRAIN] Epoch[1](5813/114412); Loss: 0.069986; Backpropagation: 0.2970 sec; Batch: 2.1238 sec
0.1764 0.1506 0.1091 0.0825 0.0632 0.0591 0.0545 0.0520 0.0500 0.0484 0.0473 0.0464 0.0459 0.0452 0.0448 0.0444 

[TRAIN] Epoch[1](5814/114412); Loss: 0.075707; Backpropagation: 0.2977 sec; Batch: 2.1320 sec
0.1542 0.1337 0.1027 0.0859 0.0735 0.0683 0.0663 0.0632 0.0615 0.0599 0.0586 0.0579 0.0571 0.0566 0.0561 0.0558 

[TRAIN] Epoch[1](5815/114412); Loss: 0.077744; Backpropagation: 0.3014 sec; Batch: 2.1281 sec
0.1653 0.1386 0.0966 0.0855 0.0772 0.0733 0.0679 0.0650 0.0629 0.0615 0.0602 0.0593 0.0585 0.0577 0.0574 0.0571 

[TRAIN] Epoch[1](5816/114412); Loss: 0.078653; Backpropagation: 0.2998 sec; Batch: 2.1689 sec
0.1270 0.1106 0.0904 0.0839 0.0782 0.0754 0.0734 0.0717 0.0704 0.0697 0.0688 0.0684 0.0681 0.0677 0.0675 0.0674 

[TRAIN] Epoch[1](5817/114412); Loss: 0.080135; Backpropagation: 0.3013 sec; Batch: 2.1293 sec
0.1524 0.1300 0.0977 0.0882 0.0789 0.0758 0.0722 0.0696 0.0681 0.0663 0.0654 0.0647 0.0639 0.0635 0.0629 0.0624 

[TRAIN] Epoch[1](5818/114412); Loss: 0.059114; Backpropagation: 0.2986 sec; Batch: 2.1274 sec
0.1447 0.1117 0.0728 0.0631 0.0579 0.0538 0.0511 0.0479 0.0459 0.0448 0.0434 0.0426 0.0423 0.0417 0.0413 0.0409 

[TRAIN] Epoch[1](5819/114412); Loss: 0.066766; Backpropagation: 0.2949 sec; Batch: 2.0836 sec
0.1696 0.1379 0.0876 0.0778 0.0709 0.0631 0.0568 0.0522 0.0488 0.0468 0.0450 0.0438 0.0429 0.0422 0.0416 0.0412 

[TRAIN] Epoch[1](5820/114412); Loss: 0.071523; Backpropagation: 0.2962 sec; Batch: 2.1226 sec
0.1570 0.1362 0.0977 0.0767 0.0698 0.0638 0.0610 0.0582 0.0563 0.0549 0.0536 0.0527 0.0521 0.0517 0.0514 0.0511 

[TRAIN] Epoch[1](5821/114412); Loss: 0.096547; Backpropagation: 0.2956 sec; Batch: 2.1220 sec
0.1582 0.1481 0.1187 0.1051 0.0963 0.0925 0.0895 0.0872 0.0848 0.0832 0.0822 0.0810 0.0803 0.0796 0.0792 0.0790 

[TRAIN] Epoch[1](5822/114412); Loss: 0.063786; Backpropagation: 0.2952 sec; Batch: 2.1109 sec
0.1696 0.1409 0.0795 0.0630 0.0595 0.0531 0.0509 0.0484 0.0464 0.0457 0.0449 0.0447 0.0441 0.0437 0.0433 0.0431 

[TRAIN] Epoch[1](5823/114412); Loss: 0.086362; Backpropagation: 0.2958 sec; Batch: 2.1592 sec
0.1662 0.1455 0.1112 0.0946 0.0849 0.0808 0.0781 0.0744 0.0726 0.0707 0.0691 0.0682 0.0672 0.0664 0.0661 0.0656 

[TRAIN] Epoch[1](5824/114412); Loss: 0.062372; Backpropagation: 0.2984 sec; Batch: 2.1188 sec
0.1429 0.1155 0.0759 0.0724 0.0603 0.0576 0.0531 0.0504 0.0485 0.0473 0.0465 0.0462 0.0457 0.0454 0.0452 0.0450 

[TRAIN] Epoch[1](5825/114412); Loss: 0.094809; Backpropagation: 0.3007 sec; Batch: 2.1631 sec
0.1590 0.1433 0.1184 0.1058 0.0966 0.0919 0.0882 0.0857 0.0829 0.0811 0.0794 0.0784 0.0775 0.0769 0.0762 0.0757 

[TRAIN] Epoch[1](5826/114412); Loss: 0.062363; Backpropagation: 0.2984 sec; Batch: 2.1198 sec
0.1477 0.1305 0.0829 0.0660 0.0610 0.0550 0.0514 0.0491 0.0477 0.0460 0.0450 0.0441 0.0435 0.0430 0.0426 0.0423 

[TRAIN] Epoch[1](5827/114412); Loss: 0.067615; Backpropagation: 0.3005 sec; Batch: 2.0933 sec
0.1151 0.0962 0.0799 0.0757 0.0691 0.0658 0.0632 0.0610 0.0597 0.0587 0.0577 0.0569 0.0563 0.0559 0.0555 0.0552 

[TRAIN] Epoch[1](5828/114412); Loss: 0.063499; Backpropagation: 0.3012 sec; Batch: 2.0884 sec
0.1295 0.1177 0.0902 0.0772 0.0678 0.0587 0.0549 0.0516 0.0488 0.0480 0.0466 0.0461 0.0453 0.0449 0.0444 0.0442 

[TRAIN] Epoch[1](5829/114412); Loss: 0.062768; Backpropagation: 0.2958 sec; Batch: 2.1304 sec
0.1412 0.1220 0.0797 0.0672 0.0605 0.0558 0.0538 0.0515 0.0498 0.0485 0.0473 0.0468 0.0459 0.0453 0.0447 0.0443 

[TRAIN] Epoch[1](5830/114412); Loss: 0.074258; Backpropagation: 0.2950 sec; Batch: 2.1160 sec
0.2009 0.1731 0.1080 0.0786 0.0658 0.0608 0.0566 0.0548 0.0522 0.0511 0.0491 0.0485 0.0478 0.0472 0.0470 0.0466 

[TRAIN] Epoch[1](5831/114412); Loss: 0.097484; Backpropagation: 0.2954 sec; Batch: 2.1780 sec
0.1681 0.1479 0.1164 0.1041 0.0963 0.0919 0.0886 0.0866 0.0848 0.0839 0.0832 0.0826 0.0822 0.0815 0.0811 0.0806 

[TRAIN] Epoch[1](5832/114412); Loss: 0.077920; Backpropagation: 0.2956 sec; Batch: 2.1150 sec
0.1962 0.1556 0.1007 0.0855 0.0730 0.0688 0.0662 0.0631 0.0599 0.0577 0.0559 0.0544 0.0534 0.0529 0.0519 0.0514 

[TRAIN] Epoch[1](5833/114412); Loss: 0.066481; Backpropagation: 0.2955 sec; Batch: 2.1727 sec
0.1315 0.1127 0.0861 0.0746 0.0672 0.0615 0.0586 0.0560 0.0547 0.0537 0.0527 0.0519 0.0513 0.0507 0.0504 0.0501 

[TRAIN] Epoch[1](5834/114412); Loss: 0.073130; Backpropagation: 0.2957 sec; Batch: 2.0921 sec
0.1489 0.1341 0.0920 0.0802 0.0739 0.0682 0.0650 0.0615 0.0601 0.0579 0.0568 0.0557 0.0550 0.0542 0.0535 0.0530 

[TRAIN] Epoch[1](5835/114412); Loss: 0.103271; Backpropagation: 0.2954 sec; Batch: 2.1815 sec
0.2103 0.1877 0.1421 0.1165 0.0992 0.0913 0.0863 0.0844 0.0823 0.0810 0.0801 0.0792 0.0787 0.0783 0.0777 0.0773 

[TRAIN] Epoch[1](5836/114412); Loss: 0.076149; Backpropagation: 0.2955 sec; Batch: 2.1496 sec
0.1632 0.1496 0.1142 0.0991 0.0833 0.0737 0.0676 0.0613 0.0573 0.0541 0.0520 0.0504 0.0494 0.0486 0.0477 0.0470 

[TRAIN] Epoch[1](5837/114412); Loss: 0.103189; Backpropagation: 0.2957 sec; Batch: 2.1547 sec
0.2520 0.2343 0.1721 0.1368 0.0940 0.0833 0.0773 0.0741 0.0695 0.0681 0.0669 0.0658 0.0648 0.0644 0.0640 0.0637 

[TRAIN] Epoch[1](5838/114412); Loss: 0.075478; Backpropagation: 0.2953 sec; Batch: 2.3136 sec
0.1572 0.1427 0.0962 0.0802 0.0743 0.0685 0.0651 0.0630 0.0612 0.0597 0.0584 0.0576 0.0567 0.0561 0.0556 0.0552 

[TRAIN] Epoch[1](5839/114412); Loss: 0.097394; Backpropagation: 0.2957 sec; Batch: 2.1196 sec
0.1432 0.1339 0.1143 0.1066 0.1002 0.0961 0.0934 0.0903 0.0888 0.0873 0.0861 0.0849 0.0844 0.0836 0.0829 0.0823 

[TRAIN] Epoch[1](5840/114412); Loss: 0.099603; Backpropagation: 0.2951 sec; Batch: 2.1219 sec
0.1821 0.1670 0.1335 0.1181 0.1032 0.0955 0.0902 0.0859 0.0846 0.0827 0.0783 0.0767 0.0757 0.0741 0.0734 0.0727 

[TRAIN] Epoch[1](5841/114412); Loss: 0.057629; Backpropagation: 0.2948 sec; Batch: 2.0814 sec
0.1516 0.1399 0.1004 0.0767 0.0515 0.0469 0.0441 0.0380 0.0369 0.0356 0.0347 0.0339 0.0335 0.0331 0.0327 0.0326 

[TRAIN] Epoch[1](5842/114412); Loss: 0.066726; Backpropagation: 0.2955 sec; Batch: 2.1213 sec
0.1455 0.1348 0.0853 0.0703 0.0649 0.0602 0.0563 0.0546 0.0530 0.0515 0.0501 0.0492 0.0486 0.0481 0.0477 0.0474 

[TRAIN] Epoch[1](5843/114412); Loss: 0.065644; Backpropagation: 0.2982 sec; Batch: 2.1251 sec
0.1644 0.1505 0.1019 0.0824 0.0600 0.0513 0.0489 0.0483 0.0473 0.0448 0.0436 0.0428 0.0419 0.0413 0.0408 0.0402 

[TRAIN] Epoch[1](5844/114412); Loss: 0.061420; Backpropagation: 0.2980 sec; Batch: 2.1241 sec
0.1197 0.1096 0.0788 0.0685 0.0610 0.0561 0.0539 0.0520 0.0510 0.0495 0.0485 0.0478 0.0470 0.0467 0.0464 0.0461 

[TRAIN] Epoch[1](5845/114412); Loss: 0.069359; Backpropagation: 0.2950 sec; Batch: 2.0821 sec
0.1356 0.1217 0.0956 0.0803 0.0714 0.0661 0.0612 0.0582 0.0561 0.0547 0.0533 0.0524 0.0516 0.0509 0.0505 0.0500 

[TRAIN] Epoch[1](5846/114412); Loss: 0.066691; Backpropagation: 0.2956 sec; Batch: 2.1273 sec
0.1255 0.1118 0.0897 0.0778 0.0695 0.0649 0.0616 0.0577 0.0556 0.0536 0.0521 0.0510 0.0501 0.0492 0.0487 0.0482 

[TRAIN] Epoch[1](5847/114412); Loss: 0.079444; Backpropagation: 0.2952 sec; Batch: 2.1206 sec
0.1595 0.1493 0.1156 0.0980 0.0811 0.0757 0.0689 0.0640 0.0625 0.0596 0.0581 0.0571 0.0563 0.0558 0.0551 0.0544 

[TRAIN] Epoch[1](5848/114412); Loss: 0.072556; Backpropagation: 0.2950 sec; Batch: 2.1234 sec
0.1398 0.1320 0.1037 0.0900 0.0766 0.0694 0.0641 0.0606 0.0580 0.0558 0.0541 0.0529 0.0520 0.0511 0.0506 0.0501 

[TRAIN] Epoch[1](5849/114412); Loss: 0.072208; Backpropagation: 0.2952 sec; Batch: 2.1357 sec
0.1199 0.1100 0.0891 0.0819 0.0763 0.0711 0.0677 0.0644 0.0622 0.0610 0.0602 0.0594 0.0587 0.0582 0.0578 0.0574 

[TRAIN] Epoch[1](5850/114412); Loss: 0.094880; Backpropagation: 0.2953 sec; Batch: 2.1267 sec
0.1546 0.1469 0.1174 0.1071 0.0966 0.0922 0.0870 0.0846 0.0820 0.0810 0.0799 0.0791 0.0784 0.0776 0.0771 0.0767 

[TRAIN] Epoch[1](5851/114412); Loss: 0.069494; Backpropagation: 0.2956 sec; Batch: 2.1203 sec
0.1585 0.1458 0.0828 0.0741 0.0652 0.0604 0.0571 0.0550 0.0538 0.0531 0.0523 0.0515 0.0510 0.0506 0.0505 0.0501 

[TRAIN] Epoch[1](5852/114412); Loss: 0.092054; Backpropagation: 0.2980 sec; Batch: 2.1237 sec
0.1729 0.1656 0.1280 0.1112 0.0947 0.0887 0.0830 0.0794 0.0758 0.0733 0.0710 0.0687 0.0669 0.0654 0.0646 0.0637 

[TRAIN] Epoch[1](5853/114412); Loss: 0.092670; Backpropagation: 0.2980 sec; Batch: 2.1251 sec
0.1775 0.1706 0.1241 0.1082 0.0914 0.0841 0.0797 0.0772 0.0753 0.0738 0.0722 0.0713 0.0703 0.0696 0.0690 0.0685 

[TRAIN] Epoch[1](5854/114412); Loss: 0.102925; Backpropagation: 0.2980 sec; Batch: 2.1338 sec
0.1989 0.1904 0.1399 0.1217 0.1049 0.0913 0.0872 0.0836 0.0813 0.0806 0.0797 0.0784 0.0779 0.0773 0.0770 0.0767 

[TRAIN] Epoch[1](5855/114412); Loss: 0.072387; Backpropagation: 0.3008 sec; Batch: 2.0893 sec
0.1457 0.1330 0.0936 0.0801 0.0713 0.0668 0.0631 0.0617 0.0590 0.0575 0.0561 0.0553 0.0546 0.0540 0.0534 0.0530 

[TRAIN] Epoch[1](5856/114412); Loss: 0.059456; Backpropagation: 0.2980 sec; Batch: 2.1162 sec
0.1122 0.1022 0.0766 0.0685 0.0643 0.0576 0.0529 0.0511 0.0490 0.0475 0.0464 0.0457 0.0450 0.0445 0.0441 0.0438 

[TRAIN] Epoch[1](5857/114412); Loss: 0.092686; Backpropagation: 0.2957 sec; Batch: 2.0840 sec
0.2233 0.2104 0.1424 0.1110 0.0830 0.0796 0.0707 0.0678 0.0650 0.0641 0.0634 0.0615 0.0606 0.0604 0.0601 0.0596 

[TRAIN] Epoch[1](5858/114412); Loss: 0.076714; Backpropagation: 0.2950 sec; Batch: 2.1238 sec
0.1423 0.1358 0.1007 0.0847 0.0753 0.0714 0.0677 0.0657 0.0640 0.0624 0.0611 0.0603 0.0597 0.0592 0.0588 0.0584 

[TRAIN] Epoch[1](5859/114412); Loss: 0.076015; Backpropagation: 0.2977 sec; Batch: 2.1251 sec
0.1766 0.1709 0.1140 0.0968 0.0710 0.0639 0.0607 0.0572 0.0551 0.0533 0.0518 0.0505 0.0495 0.0487 0.0484 0.0479 

[TRAIN] Epoch[1](5860/114412); Loss: 0.065550; Backpropagation: 0.2977 sec; Batch: 2.1213 sec
0.1211 0.1138 0.0833 0.0736 0.0660 0.0618 0.0585 0.0566 0.0546 0.0536 0.0524 0.0515 0.0511 0.0507 0.0503 0.0499 

[TRAIN] Epoch[1](5861/114412); Loss: 0.075998; Backpropagation: 0.2952 sec; Batch: 2.1221 sec
0.1468 0.1345 0.1030 0.0879 0.0791 0.0721 0.0687 0.0652 0.0606 0.0591 0.0581 0.0573 0.0566 0.0561 0.0557 0.0552 

[TRAIN] Epoch[1](5862/114412); Loss: 0.067381; Backpropagation: 0.2982 sec; Batch: 2.1279 sec
0.1375 0.1289 0.0925 0.0794 0.0711 0.0630 0.0583 0.0553 0.0537 0.0511 0.0500 0.0489 0.0480 0.0474 0.0468 0.0462 

[TRAIN] Epoch[1](5863/114412); Loss: 0.068991; Backpropagation: 0.2956 sec; Batch: 2.1230 sec
0.1457 0.1382 0.1012 0.0880 0.0722 0.0617 0.0572 0.0542 0.0517 0.0509 0.0492 0.0483 0.0473 0.0465 0.0461 0.0455 

[TRAIN] Epoch[1](5864/114412); Loss: 0.071808; Backpropagation: 0.2980 sec; Batch: 2.1255 sec
0.1324 0.1216 0.0937 0.0837 0.0754 0.0687 0.0628 0.0609 0.0593 0.0584 0.0570 0.0563 0.0554 0.0550 0.0544 0.0540 

[TRAIN] Epoch[1](5865/114412); Loss: 0.095274; Backpropagation: 0.2974 sec; Batch: 2.1260 sec
0.1917 0.1825 0.1375 0.1149 0.0954 0.0844 0.0792 0.0782 0.0751 0.0732 0.0716 0.0701 0.0689 0.0679 0.0672 0.0667 

[TRAIN] Epoch[1](5866/114412); Loss: 0.075091; Backpropagation: 0.2929 sec; Batch: 2.1186 sec
0.1347 0.1252 0.0997 0.0851 0.0732 0.0665 0.0670 0.0650 0.0642 0.0626 0.0613 0.0604 0.0598 0.0594 0.0588 0.0584 

[TRAIN] Epoch[1](5867/114412); Loss: 0.052060; Backpropagation: 0.2956 sec; Batch: 2.1205 sec
0.1237 0.1137 0.0764 0.0622 0.0479 0.0447 0.0441 0.0414 0.0384 0.0366 0.0355 0.0347 0.0341 0.0335 0.0332 0.0328 

[TRAIN] Epoch[1](5868/114412); Loss: 0.070128; Backpropagation: 0.2933 sec; Batch: 2.1222 sec
0.1367 0.1223 0.0873 0.0788 0.0728 0.0678 0.0647 0.0605 0.0582 0.0564 0.0548 0.0539 0.0529 0.0522 0.0517 0.0510 

[TRAIN] Epoch[1](5869/114412); Loss: 0.083999; Backpropagation: 0.2954 sec; Batch: 2.1294 sec
0.1836 0.1791 0.1356 0.1110 0.0847 0.0721 0.0685 0.0633 0.0607 0.0583 0.0569 0.0555 0.0547 0.0539 0.0534 0.0527 

[TRAIN] Epoch[1](5870/114412); Loss: 0.075364; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1399 0.1323 0.1066 0.0917 0.0775 0.0713 0.0660 0.0635 0.0608 0.0590 0.0581 0.0574 0.0565 0.0555 0.0551 0.0547 

[TRAIN] Epoch[1](5871/114412); Loss: 0.078947; Backpropagation: 0.2914 sec; Batch: 2.1163 sec
0.1549 0.1476 0.1042 0.0861 0.0752 0.0710 0.0679 0.0661 0.0646 0.0634 0.0622 0.0611 0.0605 0.0599 0.0596 0.0592 

[TRAIN] Epoch[1](5872/114412); Loss: 0.074853; Backpropagation: 0.2903 sec; Batch: 2.0916 sec
0.1675 0.1602 0.1131 0.0975 0.0782 0.0669 0.0634 0.0586 0.0545 0.0518 0.0502 0.0488 0.0478 0.0471 0.0464 0.0457 

[TRAIN] Epoch[1](5873/114412); Loss: 0.062224; Backpropagation: 0.2909 sec; Batch: 2.1204 sec
0.1314 0.1215 0.0862 0.0747 0.0610 0.0556 0.0530 0.0516 0.0493 0.0470 0.0457 0.0448 0.0440 0.0436 0.0432 0.0429 

[TRAIN] Epoch[1](5874/114412); Loss: 0.096790; Backpropagation: 0.2912 sec; Batch: 2.1004 sec
0.2133 0.2018 0.1532 0.1283 0.0989 0.0847 0.0774 0.0729 0.0707 0.0691 0.0675 0.0646 0.0631 0.0620 0.0610 0.0602 

[TRAIN] Epoch[1](5875/114412); Loss: 0.073297; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1453 0.1332 0.0983 0.0888 0.0781 0.0703 0.0644 0.0617 0.0585 0.0569 0.0553 0.0539 0.0530 0.0521 0.0516 0.0512 

[TRAIN] Epoch[1](5876/114412); Loss: 0.076602; Backpropagation: 0.2932 sec; Batch: 2.1192 sec
0.1713 0.1587 0.1191 0.0922 0.0745 0.0673 0.0621 0.0596 0.0572 0.0550 0.0535 0.0525 0.0515 0.0509 0.0503 0.0499 

[TRAIN] Epoch[1](5877/114412); Loss: 0.084425; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1473 0.1385 0.1088 0.0950 0.0854 0.0799 0.0764 0.0738 0.0718 0.0705 0.0693 0.0683 0.0674 0.0667 0.0661 0.0657 

[TRAIN] Epoch[1](5878/114412); Loss: 0.071986; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.1514 0.1446 0.0955 0.0750 0.0683 0.0637 0.0609 0.0584 0.0572 0.0559 0.0551 0.0542 0.0536 0.0529 0.0526 0.0524 

[TRAIN] Epoch[1](5879/114412); Loss: 0.092847; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1600 0.1551 0.1130 0.1003 0.0913 0.0867 0.0843 0.0817 0.0799 0.0784 0.0774 0.0764 0.0758 0.0755 0.0750 0.0748 

[TRAIN] Epoch[1](5880/114412); Loss: 0.102802; Backpropagation: 0.2918 sec; Batch: 2.0782 sec
0.1619 0.1549 0.1239 0.1148 0.1050 0.0989 0.0965 0.0936 0.0908 0.0892 0.0880 0.0867 0.0860 0.0853 0.0850 0.0842 

[TRAIN] Epoch[1](5881/114412); Loss: 0.056485; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1268 0.1227 0.0777 0.0646 0.0535 0.0487 0.0475 0.0450 0.0434 0.0417 0.0404 0.0395 0.0388 0.0382 0.0378 0.0375 

[TRAIN] Epoch[1](5882/114412); Loss: 0.078897; Backpropagation: 0.2915 sec; Batch: 2.1497 sec
0.1625 0.1575 0.1187 0.0978 0.0764 0.0684 0.0655 0.0615 0.0600 0.0588 0.0580 0.0570 0.0558 0.0553 0.0548 0.0544 

[TRAIN] Epoch[1](5883/114412); Loss: 0.097898; Backpropagation: 0.2912 sec; Batch: 2.1203 sec
0.1747 0.1629 0.1247 0.1087 0.0969 0.0922 0.0884 0.0849 0.0826 0.0811 0.0800 0.0792 0.0783 0.0777 0.0772 0.0768 

[TRAIN] Epoch[1](5884/114412); Loss: 0.088774; Backpropagation: 0.2929 sec; Batch: 2.1191 sec
0.1483 0.1412 0.1107 0.0971 0.0876 0.0828 0.0806 0.0792 0.0777 0.0760 0.0749 0.0741 0.0734 0.0728 0.0722 0.0718 

[TRAIN] Epoch[1](5885/114412); Loss: 0.067036; Backpropagation: 0.2931 sec; Batch: 2.1206 sec
0.1152 0.1067 0.0861 0.0749 0.0697 0.0658 0.0623 0.0591 0.0573 0.0560 0.0552 0.0541 0.0532 0.0527 0.0523 0.0520 

[TRAIN] Epoch[1](5886/114412); Loss: 0.081388; Backpropagation: 0.2909 sec; Batch: 2.1188 sec
0.1445 0.1321 0.1022 0.0916 0.0825 0.0770 0.0739 0.0709 0.0695 0.0681 0.0668 0.0660 0.0652 0.0646 0.0639 0.0634 

[TRAIN] Epoch[1](5887/114412); Loss: 0.074668; Backpropagation: 0.2951 sec; Batch: 2.1210 sec
0.1643 0.1450 0.0985 0.0909 0.0773 0.0688 0.0636 0.0605 0.0580 0.0562 0.0541 0.0533 0.0521 0.0514 0.0506 0.0500 

[TRAIN] Epoch[1](5888/114412); Loss: 0.077155; Backpropagation: 0.2930 sec; Batch: 2.0837 sec
0.1459 0.1399 0.1056 0.0921 0.0720 0.0676 0.0660 0.0656 0.0632 0.0615 0.0606 0.0598 0.0593 0.0589 0.0585 0.0581 

[TRAIN] Epoch[1](5889/114412); Loss: 0.065558; Backpropagation: 0.2907 sec; Batch: 2.0987 sec
0.1736 0.1631 0.1013 0.0785 0.0567 0.0497 0.0485 0.0471 0.0447 0.0431 0.0423 0.0412 0.0406 0.0400 0.0394 0.0391 

[TRAIN] Epoch[1](5890/114412); Loss: 0.073015; Backpropagation: 0.2905 sec; Batch: 2.0777 sec
0.1474 0.1363 0.0960 0.0878 0.0730 0.0656 0.0627 0.0606 0.0588 0.0568 0.0559 0.0547 0.0540 0.0534 0.0528 0.0524 

[TRAIN] Epoch[1](5891/114412); Loss: 0.087099; Backpropagation: 0.2910 sec; Batch: 2.0785 sec
0.1412 0.1343 0.1098 0.0980 0.0872 0.0815 0.0802 0.0784 0.0765 0.0747 0.0738 0.0728 0.0720 0.0717 0.0710 0.0705 

[TRAIN] Epoch[1](5892/114412); Loss: 0.054227; Backpropagation: 0.2908 sec; Batch: 2.1177 sec
0.1105 0.1040 0.0762 0.0643 0.0566 0.0511 0.0479 0.0448 0.0426 0.0412 0.0400 0.0390 0.0383 0.0376 0.0370 0.0365 

[TRAIN] Epoch[1](5893/114412); Loss: 0.090332; Backpropagation: 0.2911 sec; Batch: 2.0970 sec
0.1863 0.1742 0.1230 0.1020 0.0894 0.0806 0.0766 0.0747 0.0716 0.0695 0.0682 0.0673 0.0664 0.0659 0.0651 0.0645 

[TRAIN] Epoch[1](5894/114412); Loss: 0.068493; Backpropagation: 0.2916 sec; Batch: 2.1185 sec
0.1431 0.1313 0.0846 0.0699 0.0657 0.0614 0.0572 0.0567 0.0556 0.0548 0.0538 0.0531 0.0527 0.0522 0.0520 0.0517 

[TRAIN] Epoch[1](5895/114412); Loss: 0.087843; Backpropagation: 0.2906 sec; Batch: 2.0908 sec
0.2135 0.2018 0.1434 0.1114 0.0865 0.0725 0.0657 0.0635 0.0601 0.0588 0.0570 0.0558 0.0549 0.0542 0.0534 0.0529 

[TRAIN] Epoch[1](5896/114412); Loss: 0.080902; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1459 0.1445 0.0940 0.0847 0.0796 0.0742 0.0714 0.0701 0.0681 0.0677 0.0669 0.0662 0.0658 0.0654 0.0651 0.0649 

[TRAIN] Epoch[1](5897/114412); Loss: 0.083194; Backpropagation: 0.2911 sec; Batch: 2.1205 sec
0.1754 0.1593 0.0996 0.0826 0.0784 0.0734 0.0706 0.0702 0.0683 0.0664 0.0658 0.0650 0.0647 0.0642 0.0638 0.0635 

[TRAIN] Epoch[1](5898/114412); Loss: 0.074642; Backpropagation: 0.2910 sec; Batch: 2.0784 sec
0.1209 0.1149 0.0903 0.0812 0.0780 0.0725 0.0695 0.0674 0.0654 0.0641 0.0631 0.0624 0.0619 0.0613 0.0609 0.0605 

[TRAIN] Epoch[1](5899/114412); Loss: 0.065927; Backpropagation: 0.2913 sec; Batch: 2.1234 sec
0.1200 0.1103 0.0867 0.0763 0.0676 0.0626 0.0592 0.0573 0.0561 0.0538 0.0526 0.0516 0.0509 0.0503 0.0499 0.0495 

[TRAIN] Epoch[1](5900/114412); Loss: 0.078375; Backpropagation: 0.2914 sec; Batch: 2.0779 sec
0.1351 0.1236 0.0895 0.0846 0.0792 0.0746 0.0723 0.0698 0.0686 0.0675 0.0663 0.0655 0.0649 0.0645 0.0642 0.0638 

[TRAIN] Epoch[1](5901/114412); Loss: 0.083124; Backpropagation: 0.2927 sec; Batch: 2.1196 sec
0.1815 0.1631 0.1071 0.0860 0.0786 0.0710 0.0699 0.0674 0.0661 0.0652 0.0638 0.0633 0.0625 0.0618 0.0617 0.0611 

[TRAIN] Epoch[1](5902/114412); Loss: 0.097658; Backpropagation: 0.2915 sec; Batch: 2.1164 sec
0.1616 0.1513 0.1201 0.1093 0.1035 0.0962 0.0929 0.0888 0.0842 0.0836 0.0817 0.0789 0.0787 0.0775 0.0771 0.0769 

[TRAIN] Epoch[1](5903/114412); Loss: 0.089399; Backpropagation: 0.2928 sec; Batch: 2.0837 sec
0.1642 0.1542 0.1124 0.1007 0.0903 0.0833 0.0798 0.0768 0.0755 0.0734 0.0722 0.0710 0.0702 0.0693 0.0687 0.0683 

[TRAIN] Epoch[1](5904/114412); Loss: 0.069890; Backpropagation: 0.2905 sec; Batch: 2.1143 sec
0.1422 0.1363 0.0924 0.0789 0.0672 0.0630 0.0581 0.0581 0.0560 0.0550 0.0535 0.0527 0.0519 0.0516 0.0510 0.0504 

[TRAIN] Epoch[1](5905/114412); Loss: 0.085521; Backpropagation: 0.2906 sec; Batch: 2.0768 sec
0.1793 0.1667 0.1121 0.0923 0.0814 0.0778 0.0735 0.0707 0.0686 0.0667 0.0654 0.0641 0.0634 0.0626 0.0621 0.0615 

[TRAIN] Epoch[1](5906/114412); Loss: 0.082368; Backpropagation: 0.2951 sec; Batch: 2.1233 sec
0.1410 0.1303 0.1024 0.0917 0.0839 0.0781 0.0756 0.0731 0.0714 0.0697 0.0685 0.0679 0.0669 0.0663 0.0658 0.0653 

[TRAIN] Epoch[1](5907/114412); Loss: 0.097604; Backpropagation: 0.2926 sec; Batch: 2.1237 sec
0.1596 0.1527 0.1201 0.1065 0.0976 0.0928 0.0902 0.0874 0.0853 0.0839 0.0828 0.0820 0.0809 0.0805 0.0799 0.0794 

[TRAIN] Epoch[1](5908/114412); Loss: 0.074987; Backpropagation: 0.2954 sec; Batch: 2.1204 sec
0.1575 0.1518 0.1063 0.0906 0.0703 0.0651 0.0625 0.0607 0.0578 0.0559 0.0553 0.0543 0.0540 0.0532 0.0526 0.0521 

[TRAIN] Epoch[1](5909/114412); Loss: 0.076760; Backpropagation: 0.2929 sec; Batch: 2.1206 sec
0.1401 0.1313 0.1017 0.0878 0.0770 0.0735 0.0698 0.0667 0.0649 0.0623 0.0609 0.0599 0.0588 0.0583 0.0577 0.0573 

[TRAIN] Epoch[1](5910/114412); Loss: 0.056926; Backpropagation: 0.2906 sec; Batch: 2.1174 sec
0.1340 0.1186 0.0699 0.0595 0.0542 0.0510 0.0477 0.0456 0.0441 0.0428 0.0419 0.0412 0.0407 0.0403 0.0399 0.0396 

[TRAIN] Epoch[1](5911/114412); Loss: 0.075271; Backpropagation: 0.2955 sec; Batch: 2.1220 sec
0.1312 0.1104 0.0923 0.0864 0.0784 0.0736 0.0697 0.0677 0.0659 0.0641 0.0628 0.0617 0.0609 0.0603 0.0598 0.0593 

[TRAIN] Epoch[1](5912/114412); Loss: 0.079770; Backpropagation: 0.2930 sec; Batch: 2.1219 sec
0.2091 0.1972 0.1296 0.0936 0.0715 0.0619 0.0567 0.0545 0.0535 0.0524 0.0512 0.0504 0.0496 0.0489 0.0483 0.0481 

[TRAIN] Epoch[1](5913/114412); Loss: 0.073406; Backpropagation: 0.2953 sec; Batch: 2.1222 sec
0.1752 0.1600 0.1020 0.0861 0.0681 0.0609 0.0574 0.0560 0.0554 0.0529 0.0517 0.0511 0.0501 0.0496 0.0492 0.0487 

[TRAIN] Epoch[1](5914/114412); Loss: 0.062152; Backpropagation: 0.2927 sec; Batch: 2.1173 sec
0.1120 0.1070 0.0808 0.0688 0.0644 0.0609 0.0565 0.0552 0.0524 0.0508 0.0495 0.0485 0.0477 0.0470 0.0466 0.0462 

[TRAIN] Epoch[1](5915/114412); Loss: 0.073538; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1234 0.1178 0.0944 0.0777 0.0726 0.0695 0.0670 0.0658 0.0640 0.0626 0.0618 0.0610 0.0603 0.0599 0.0596 0.0593 

[TRAIN] Epoch[1](5916/114412); Loss: 0.064490; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1268 0.1160 0.0840 0.0740 0.0681 0.0618 0.0578 0.0538 0.0530 0.0516 0.0496 0.0486 0.0476 0.0471 0.0462 0.0458 

[TRAIN] Epoch[1](5917/114412); Loss: 0.055381; Backpropagation: 0.2909 sec; Batch: 2.1159 sec
0.1239 0.1216 0.0700 0.0594 0.0505 0.0483 0.0453 0.0441 0.0425 0.0417 0.0411 0.0403 0.0397 0.0395 0.0392 0.0391 

[TRAIN] Epoch[1](5918/114412); Loss: 0.073941; Backpropagation: 0.2952 sec; Batch: 2.1185 sec
0.1309 0.1220 0.0960 0.0861 0.0760 0.0699 0.0661 0.0644 0.0618 0.0606 0.0598 0.0589 0.0583 0.0578 0.0575 0.0571 

[TRAIN] Epoch[1](5919/114412); Loss: 0.093838; Backpropagation: 0.2929 sec; Batch: 2.1229 sec
0.1700 0.1595 0.1269 0.1086 0.0906 0.0866 0.0813 0.0810 0.0782 0.0757 0.0751 0.0744 0.0738 0.0733 0.0732 0.0732 

[TRAIN] Epoch[1](5920/114412); Loss: 0.082400; Backpropagation: 0.2908 sec; Batch: 2.1189 sec
0.1496 0.1322 0.1058 0.0972 0.0832 0.0779 0.0745 0.0717 0.0696 0.0682 0.0667 0.0658 0.0647 0.0641 0.0636 0.0634 

[TRAIN] Epoch[1](5921/114412); Loss: 0.071212; Backpropagation: 0.2927 sec; Batch: 2.1164 sec
0.1143 0.1070 0.0873 0.0807 0.0756 0.0733 0.0681 0.0648 0.0625 0.0609 0.0593 0.0585 0.0577 0.0570 0.0565 0.0560 

[TRAIN] Epoch[1](5922/114412); Loss: 0.078627; Backpropagation: 0.2915 sec; Batch: 2.1192 sec
0.1338 0.1296 0.0952 0.0837 0.0791 0.0753 0.0727 0.0706 0.0681 0.0668 0.0658 0.0649 0.0642 0.0634 0.0628 0.0620 

[TRAIN] Epoch[1](5923/114412); Loss: 0.072028; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1309 0.1230 0.0925 0.0817 0.0759 0.0720 0.0654 0.0625 0.0597 0.0583 0.0575 0.0561 0.0552 0.0545 0.0539 0.0535 

[TRAIN] Epoch[1](5924/114412); Loss: 0.077606; Backpropagation: 0.2913 sec; Batch: 2.1231 sec
0.1510 0.1454 0.1017 0.0881 0.0769 0.0722 0.0674 0.0645 0.0626 0.0612 0.0600 0.0592 0.0586 0.0580 0.0576 0.0572 

[TRAIN] Epoch[1](5925/114412); Loss: 0.074069; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.1316 0.1227 0.0947 0.0917 0.0831 0.0736 0.0692 0.0643 0.0618 0.0602 0.0581 0.0566 0.0554 0.0546 0.0540 0.0536 

[TRAIN] Epoch[1](5926/114412); Loss: 0.081482; Backpropagation: 0.2909 sec; Batch: 2.0979 sec
0.1707 0.1587 0.1119 0.0905 0.0793 0.0742 0.0705 0.0675 0.0648 0.0631 0.0613 0.0602 0.0591 0.0580 0.0573 0.0567 

[TRAIN] Epoch[1](5927/114412); Loss: 0.067901; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1410 0.1233 0.0806 0.0744 0.0671 0.0634 0.0595 0.0574 0.0562 0.0542 0.0532 0.0524 0.0515 0.0512 0.0507 0.0502 

[TRAIN] Epoch[1](5928/114412); Loss: 0.058395; Backpropagation: 0.2953 sec; Batch: 2.1208 sec
0.1105 0.1009 0.0672 0.0655 0.0606 0.0558 0.0527 0.0508 0.0491 0.0482 0.0469 0.0462 0.0459 0.0451 0.0448 0.0443 

[TRAIN] Epoch[1](5929/114412); Loss: 0.073708; Backpropagation: 0.2954 sec; Batch: 2.1260 sec
0.1519 0.1433 0.0959 0.0887 0.0691 0.0658 0.0628 0.0600 0.0583 0.0570 0.0559 0.0553 0.0548 0.0540 0.0534 0.0532 

[TRAIN] Epoch[1](5930/114412); Loss: 0.060438; Backpropagation: 0.2909 sec; Batch: 2.1015 sec
0.1319 0.1277 0.0858 0.0677 0.0577 0.0540 0.0520 0.0473 0.0460 0.0448 0.0436 0.0428 0.0422 0.0415 0.0411 0.0409 

[TRAIN] Epoch[1](5931/114412); Loss: 0.081664; Backpropagation: 0.2909 sec; Batch: 2.1134 sec
0.1569 0.1465 0.1059 0.0929 0.0825 0.0760 0.0718 0.0689 0.0671 0.0653 0.0644 0.0633 0.0625 0.0615 0.0608 0.0602 

[TRAIN] Epoch[1](5932/114412); Loss: 0.067102; Backpropagation: 0.2911 sec; Batch: 2.1199 sec
0.1167 0.1101 0.0844 0.0766 0.0688 0.0642 0.0618 0.0593 0.0579 0.0562 0.0549 0.0539 0.0530 0.0523 0.0519 0.0516 

[TRAIN] Epoch[1](5933/114412); Loss: 0.047056; Backpropagation: 0.2915 sec; Batch: 2.1177 sec
0.1084 0.0818 0.0702 0.0536 0.0490 0.0436 0.0393 0.0382 0.0366 0.0352 0.0343 0.0337 0.0328 0.0323 0.0321 0.0317 

[TRAIN] Epoch[1](5934/114412); Loss: 0.070826; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1339 0.1246 0.0980 0.0835 0.0706 0.0660 0.0629 0.0599 0.0576 0.0561 0.0549 0.0541 0.0535 0.0529 0.0525 0.0523 

[TRAIN] Epoch[1](5935/114412); Loss: 0.061053; Backpropagation: 0.2914 sec; Batch: 2.1176 sec
0.2034 0.1816 0.1037 0.0575 0.0487 0.0430 0.0401 0.0354 0.0361 0.0357 0.0341 0.0328 0.0322 0.0316 0.0308 0.0302 

[TRAIN] Epoch[1](5936/114412); Loss: 0.063093; Backpropagation: 0.2913 sec; Batch: 2.1215 sec
0.1451 0.1357 0.0788 0.0650 0.0600 0.0551 0.0537 0.0514 0.0499 0.0474 0.0465 0.0454 0.0446 0.0441 0.0436 0.0432 

[TRAIN] Epoch[1](5937/114412); Loss: 0.058963; Backpropagation: 0.2907 sec; Batch: 2.0853 sec
0.1221 0.1160 0.0826 0.0677 0.0621 0.0582 0.0523 0.0485 0.0462 0.0443 0.0429 0.0418 0.0408 0.0401 0.0393 0.0385 

[TRAIN] Epoch[1](5938/114412); Loss: 0.069965; Backpropagation: 0.2905 sec; Batch: 2.1210 sec
0.1269 0.1174 0.0951 0.0770 0.0692 0.0666 0.0629 0.0609 0.0588 0.0574 0.0563 0.0554 0.0546 0.0542 0.0537 0.0534 

[TRAIN] Epoch[1](5939/114412); Loss: 0.095367; Backpropagation: 0.2908 sec; Batch: 2.1177 sec
0.1610 0.1544 0.1141 0.0984 0.0951 0.0891 0.0912 0.0856 0.0816 0.0814 0.0803 0.0799 0.0794 0.0784 0.0783 0.0778 

[TRAIN] Epoch[1](5940/114412); Loss: 0.083591; Backpropagation: 0.2955 sec; Batch: 2.1217 sec
0.1582 0.1549 0.1126 0.1021 0.0870 0.0782 0.0767 0.0714 0.0691 0.0666 0.0631 0.0625 0.0609 0.0592 0.0579 0.0571 

[TRAIN] Epoch[1](5941/114412); Loss: 0.065928; Backpropagation: 0.2931 sec; Batch: 2.0811 sec
0.1150 0.1098 0.0853 0.0726 0.0668 0.0648 0.0611 0.0589 0.0566 0.0547 0.0538 0.0524 0.0516 0.0510 0.0505 0.0501 

[TRAIN] Epoch[1](5942/114412); Loss: 0.078031; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1361 0.1268 0.1014 0.0900 0.0800 0.0753 0.0701 0.0680 0.0662 0.0650 0.0635 0.0626 0.0618 0.0611 0.0606 0.0601 

[TRAIN] Epoch[1](5943/114412); Loss: 0.083263; Backpropagation: 0.2914 sec; Batch: 2.1231 sec
0.1324 0.1264 0.0995 0.0916 0.0851 0.0817 0.0785 0.0757 0.0739 0.0720 0.0709 0.0701 0.0694 0.0688 0.0684 0.0679 

[TRAIN] Epoch[1](5944/114412); Loss: 0.064724; Backpropagation: 0.2914 sec; Batch: 2.1210 sec
0.1095 0.0962 0.0780 0.0701 0.0687 0.0622 0.0624 0.0592 0.0568 0.0557 0.0546 0.0536 0.0530 0.0523 0.0518 0.0515 

[TRAIN] Epoch[1](5945/114412); Loss: 0.065497; Backpropagation: 0.2913 sec; Batch: 2.1221 sec
0.1314 0.1273 0.0866 0.0746 0.0665 0.0599 0.0564 0.0537 0.0522 0.0507 0.0498 0.0488 0.0482 0.0478 0.0472 0.0469 

[TRAIN] Epoch[1](5946/114412); Loss: 0.092941; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1585 0.1513 0.1174 0.1067 0.0977 0.0912 0.0864 0.0824 0.0798 0.0778 0.0757 0.0742 0.0731 0.0722 0.0716 0.0711 

[TRAIN] Epoch[1](5947/114412); Loss: 0.085997; Backpropagation: 0.2943 sec; Batch: 2.1225 sec
0.1738 0.1698 0.1341 0.1064 0.0894 0.0763 0.0698 0.0683 0.0657 0.0636 0.0615 0.0610 0.0601 0.0593 0.0587 0.0580 

[TRAIN] Epoch[1](5948/114412); Loss: 0.063889; Backpropagation: 0.2910 sec; Batch: 2.1191 sec
0.1089 0.1007 0.0855 0.0737 0.0668 0.0628 0.0602 0.0568 0.0549 0.0532 0.0517 0.0509 0.0499 0.0493 0.0486 0.0483 

[TRAIN] Epoch[1](5949/114412); Loss: 0.084222; Backpropagation: 0.2909 sec; Batch: 2.1320 sec
0.1635 0.1538 0.1143 0.0998 0.0825 0.0758 0.0715 0.0716 0.0692 0.0670 0.0651 0.0644 0.0632 0.0627 0.0620 0.0612 

[TRAIN] Epoch[1](5950/114412); Loss: 0.095922; Backpropagation: 0.2908 sec; Batch: 2.0795 sec
0.1646 0.1549 0.1282 0.1151 0.1042 0.0979 0.0914 0.0853 0.0818 0.0794 0.0763 0.0735 0.0724 0.0708 0.0698 0.0692 

[TRAIN] Epoch[1](5951/114412); Loss: 0.069466; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.1219 0.1174 0.0965 0.0849 0.0746 0.0692 0.0635 0.0596 0.0573 0.0556 0.0539 0.0528 0.0520 0.0511 0.0508 0.0503 

[TRAIN] Epoch[1](5952/114412); Loss: 0.060883; Backpropagation: 0.2911 sec; Batch: 2.1204 sec
0.1289 0.1228 0.0855 0.0749 0.0585 0.0533 0.0516 0.0509 0.0475 0.0456 0.0441 0.0432 0.0425 0.0420 0.0415 0.0413 

[TRAIN] Epoch[1](5953/114412); Loss: 0.071253; Backpropagation: 0.2905 sec; Batch: 2.1181 sec
0.1193 0.1140 0.0893 0.0817 0.0738 0.0695 0.0661 0.0633 0.0617 0.0601 0.0590 0.0578 0.0570 0.0563 0.0558 0.0554 

[TRAIN] Epoch[1](5954/114412); Loss: 0.062138; Backpropagation: 0.2905 sec; Batch: 2.2341 sec
0.1208 0.1107 0.0730 0.0751 0.0682 0.0597 0.0575 0.0528 0.0516 0.0497 0.0476 0.0467 0.0460 0.0453 0.0451 0.0445 

[TRAIN] Epoch[1](5955/114412); Loss: 0.087433; Backpropagation: 0.2927 sec; Batch: 2.1181 sec
0.1712 0.1673 0.1097 0.0974 0.0934 0.0856 0.0782 0.0747 0.0714 0.0686 0.0667 0.0651 0.0639 0.0627 0.0618 0.0612 

[TRAIN] Epoch[1](5956/114412); Loss: 0.055273; Backpropagation: 0.2913 sec; Batch: 2.2514 sec
0.1160 0.1071 0.0889 0.0700 0.0651 0.0519 0.0428 0.0432 0.0436 0.0408 0.0368 0.0381 0.0363 0.0353 0.0345 0.0341 

[TRAIN] Epoch[1](5957/114412); Loss: 0.096967; Backpropagation: 0.2932 sec; Batch: 2.1406 sec
0.1708 0.1617 0.1291 0.1140 0.1016 0.0942 0.0881 0.0840 0.0817 0.0798 0.0780 0.0759 0.0746 0.0735 0.0726 0.0718 

[TRAIN] Epoch[1](5958/114412); Loss: 0.054887; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.0942 0.0856 0.0647 0.0638 0.0573 0.0538 0.0508 0.0484 0.0475 0.0465 0.0452 0.0448 0.0444 0.0440 0.0437 0.0435 

[TRAIN] Epoch[1](5959/114412); Loss: 0.070530; Backpropagation: 0.2910 sec; Batch: 2.1163 sec
0.1133 0.1082 0.0910 0.0781 0.0726 0.0686 0.0650 0.0632 0.0620 0.0602 0.0591 0.0585 0.0579 0.0574 0.0569 0.0566 

[TRAIN] Epoch[1](5960/114412); Loss: 0.073264; Backpropagation: 0.2908 sec; Batch: 2.1501 sec
0.1219 0.1192 0.0899 0.0813 0.0730 0.0693 0.0676 0.0650 0.0634 0.0620 0.0613 0.0605 0.0601 0.0596 0.0592 0.0590 

[TRAIN] Epoch[1](5961/114412); Loss: 0.062960; Backpropagation: 0.2905 sec; Batch: 2.1090 sec
0.1061 0.0957 0.0759 0.0675 0.0693 0.0636 0.0599 0.0571 0.0547 0.0534 0.0525 0.0514 0.0508 0.0503 0.0498 0.0494 

[TRAIN] Epoch[1](5962/114412); Loss: 0.071819; Backpropagation: 0.2911 sec; Batch: 2.1142 sec
0.1505 0.1419 0.0979 0.0843 0.0716 0.0646 0.0614 0.0588 0.0561 0.0543 0.0531 0.0522 0.0514 0.0507 0.0503 0.0499 

[TRAIN] Epoch[1](5963/114412); Loss: 0.078131; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1586 0.1482 0.1102 0.0917 0.0809 0.0731 0.0675 0.0660 0.0630 0.0600 0.0586 0.0567 0.0556 0.0540 0.0531 0.0527 

[TRAIN] Epoch[1](5964/114412); Loss: 0.067727; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1396 0.1313 0.0975 0.0833 0.0697 0.0634 0.0568 0.0542 0.0528 0.0505 0.0494 0.0484 0.0475 0.0469 0.0464 0.0459 

[TRAIN] Epoch[1](5965/114412); Loss: 0.104443; Backpropagation: 0.2906 sec; Batch: 2.1175 sec
0.1729 0.1629 0.1321 0.1155 0.1057 0.1003 0.0961 0.0930 0.0917 0.0891 0.0882 0.0866 0.0857 0.0846 0.0837 0.0830 

[TRAIN] Epoch[1](5966/114412); Loss: 0.061361; Backpropagation: 0.2910 sec; Batch: 2.1257 sec
0.1189 0.1137 0.0799 0.0695 0.0628 0.0584 0.0548 0.0521 0.0500 0.0484 0.0476 0.0466 0.0457 0.0449 0.0444 0.0441 

[TRAIN] Epoch[1](5967/114412); Loss: 0.065637; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1126 0.1068 0.0814 0.0725 0.0677 0.0621 0.0611 0.0578 0.0562 0.0551 0.0541 0.0534 0.0529 0.0525 0.0521 0.0519 

[TRAIN] Epoch[1](5968/114412); Loss: 0.071434; Backpropagation: 0.2913 sec; Batch: 2.1249 sec
0.1268 0.1205 0.0892 0.0820 0.0732 0.0670 0.0638 0.0617 0.0603 0.0594 0.0583 0.0573 0.0566 0.0560 0.0556 0.0552 

[TRAIN] Epoch[1](5969/114412); Loss: 0.063263; Backpropagation: 0.2907 sec; Batch: 2.1184 sec
0.1459 0.1367 0.0888 0.0837 0.0639 0.0573 0.0528 0.0480 0.0460 0.0446 0.0428 0.0418 0.0408 0.0401 0.0397 0.0392 

[TRAIN] Epoch[1](5970/114412); Loss: 0.067815; Backpropagation: 0.2906 sec; Batch: 2.1162 sec
0.1270 0.1115 0.0886 0.0809 0.0732 0.0673 0.0611 0.0596 0.0564 0.0543 0.0535 0.0518 0.0512 0.0503 0.0493 0.0489 

[TRAIN] Epoch[1](5971/114412); Loss: 0.072798; Backpropagation: 0.2907 sec; Batch: 2.0778 sec
0.1547 0.1445 0.0939 0.0802 0.0732 0.0685 0.0633 0.0603 0.0573 0.0561 0.0548 0.0531 0.0523 0.0513 0.0508 0.0505 

[TRAIN] Epoch[1](5972/114412); Loss: 0.070811; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.1269 0.1225 0.0923 0.0826 0.0758 0.0679 0.0641 0.0618 0.0594 0.0578 0.0554 0.0549 0.0542 0.0525 0.0527 0.0524 

[TRAIN] Epoch[1](5973/114412); Loss: 0.071368; Backpropagation: 0.2916 sec; Batch: 2.1185 sec
0.1283 0.1147 0.0943 0.0853 0.0767 0.0686 0.0643 0.0622 0.0596 0.0581 0.0569 0.0557 0.0551 0.0544 0.0541 0.0537 

[TRAIN] Epoch[1](5974/114412); Loss: 0.067908; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1525 0.1421 0.0932 0.0847 0.0711 0.0633 0.0590 0.0521 0.0504 0.0479 0.0471 0.0462 0.0451 0.0445 0.0439 0.0435 

[TRAIN] Epoch[1](5975/114412); Loss: 0.067539; Backpropagation: 0.2927 sec; Batch: 2.1192 sec
0.1892 0.1786 0.0998 0.0741 0.0548 0.0502 0.0492 0.0469 0.0456 0.0439 0.0424 0.0420 0.0415 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](5976/114412); Loss: 0.080970; Backpropagation: 0.2932 sec; Batch: 2.1194 sec
0.1609 0.1549 0.1174 0.1031 0.0848 0.0754 0.0697 0.0654 0.0623 0.0601 0.0590 0.0579 0.0569 0.0562 0.0558 0.0556 

[TRAIN] Epoch[1](5977/114412); Loss: 0.078951; Backpropagation: 0.2915 sec; Batch: 2.1183 sec
0.1582 0.1464 0.1009 0.0847 0.0793 0.0751 0.0690 0.0674 0.0642 0.0622 0.0616 0.0598 0.0592 0.0588 0.0584 0.0582 

[TRAIN] Epoch[1](5978/114412); Loss: 0.079106; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1561 0.1481 0.1129 0.0932 0.0848 0.0778 0.0723 0.0672 0.0634 0.0596 0.0583 0.0570 0.0550 0.0544 0.0534 0.0525 

[TRAIN] Epoch[1](5979/114412); Loss: 0.093571; Backpropagation: 0.2906 sec; Batch: 2.1171 sec
0.1654 0.1504 0.1289 0.1178 0.1049 0.0962 0.0906 0.0865 0.0805 0.0766 0.0742 0.0691 0.0670 0.0658 0.0619 0.0611 

[TRAIN] Epoch[1](5980/114412); Loss: 0.100977; Backpropagation: 0.2926 sec; Batch: 2.1194 sec
0.1463 0.1404 0.1187 0.1116 0.1059 0.0999 0.0966 0.0936 0.0916 0.0903 0.0888 0.0878 0.0868 0.0861 0.0858 0.0853 

[TRAIN] Epoch[1](5981/114412); Loss: 0.083000; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1690 0.1622 0.1088 0.0922 0.0814 0.0769 0.0707 0.0683 0.0658 0.0648 0.0634 0.0620 0.0614 0.0609 0.0602 0.0601 

[TRAIN] Epoch[1](5982/114412); Loss: 0.059045; Backpropagation: 0.2912 sec; Batch: 2.1190 sec
0.1569 0.1501 0.0932 0.0799 0.0492 0.0461 0.0428 0.0426 0.0394 0.0370 0.0361 0.0353 0.0347 0.0342 0.0337 0.0334 

[TRAIN] Epoch[1](5983/114412); Loss: 0.074464; Backpropagation: 0.2912 sec; Batch: 2.1222 sec
0.1460 0.1387 0.0951 0.0785 0.0739 0.0687 0.0661 0.0632 0.0611 0.0592 0.0580 0.0573 0.0568 0.0565 0.0562 0.0561 

[TRAIN] Epoch[1](5984/114412); Loss: 0.046355; Backpropagation: 0.2932 sec; Batch: 2.1648 sec
0.1236 0.1175 0.0617 0.0516 0.0435 0.0400 0.0355 0.0337 0.0316 0.0310 0.0299 0.0293 0.0288 0.0283 0.0280 0.0276 

[TRAIN] Epoch[1](5985/114412); Loss: 0.075032; Backpropagation: 0.2905 sec; Batch: 2.1165 sec
0.1434 0.1349 0.0919 0.0780 0.0741 0.0709 0.0667 0.0648 0.0626 0.0617 0.0606 0.0596 0.0587 0.0580 0.0575 0.0570 

[TRAIN] Epoch[1](5986/114412); Loss: 0.059475; Backpropagation: 0.2907 sec; Batch: 2.1139 sec
0.1211 0.1086 0.0754 0.0682 0.0599 0.0584 0.0528 0.0500 0.0487 0.0461 0.0454 0.0446 0.0440 0.0432 0.0428 0.0424 

[TRAIN] Epoch[1](5987/114412); Loss: 0.073947; Backpropagation: 0.2917 sec; Batch: 2.1157 sec
0.1477 0.1381 0.0980 0.0839 0.0752 0.0678 0.0654 0.0616 0.0606 0.0587 0.0563 0.0555 0.0545 0.0536 0.0532 0.0529 

[TRAIN] Epoch[1](5988/114412); Loss: 0.050782; Backpropagation: 0.2930 sec; Batch: 2.1218 sec
0.1135 0.1018 0.0664 0.0600 0.0572 0.0497 0.0432 0.0400 0.0391 0.0370 0.0355 0.0348 0.0346 0.0335 0.0332 0.0330 

[TRAIN] Epoch[1](5989/114412); Loss: 0.059287; Backpropagation: 0.2912 sec; Batch: 2.1198 sec
0.1807 0.1665 0.0806 0.0649 0.0474 0.0451 0.0449 0.0396 0.0384 0.0373 0.0356 0.0346 0.0345 0.0334 0.0328 0.0324 

[TRAIN] Epoch[1](5990/114412); Loss: 0.078239; Backpropagation: 0.2931 sec; Batch: 2.0839 sec
0.1841 0.1430 0.0988 0.0868 0.0714 0.0713 0.0699 0.0751 0.0664 0.0616 0.0562 0.0552 0.0539 0.0530 0.0530 0.0523 

[TRAIN] Epoch[1](5991/114412); Loss: 0.090415; Backpropagation: 0.2914 sec; Batch: 2.1145 sec
0.1535 0.1392 0.1095 0.1004 0.0911 0.0875 0.0843 0.0811 0.0788 0.0770 0.0763 0.0755 0.0742 0.0732 0.0727 0.0725 

[TRAIN] Epoch[1](5992/114412); Loss: 0.118598; Backpropagation: 0.2906 sec; Batch: 2.1175 sec
0.1787 0.1610 0.1355 0.1262 0.1197 0.1178 0.1141 0.1118 0.1078 0.1060 0.1043 0.1045 0.1038 0.1024 0.1024 0.1017 

[TRAIN] Epoch[1](5993/114412); Loss: 0.085708; Backpropagation: 0.2913 sec; Batch: 2.1216 sec
0.1884 0.1620 0.1150 0.0965 0.0819 0.0761 0.0674 0.0670 0.0704 0.0667 0.0659 0.0635 0.0634 0.0626 0.0622 0.0624 

[TRAIN] Epoch[1](5994/114412); Loss: 0.078415; Backpropagation: 0.2911 sec; Batch: 2.1219 sec
0.1565 0.1312 0.1094 0.0887 0.0750 0.0700 0.0668 0.0656 0.0624 0.0632 0.0631 0.0618 0.0616 0.0603 0.0596 0.0594 

[TRAIN] Epoch[1](5995/114412); Loss: 0.078967; Backpropagation: 0.2955 sec; Batch: 2.1260 sec
0.1324 0.1198 0.0879 0.0794 0.0809 0.0792 0.0746 0.0708 0.0706 0.0695 0.0675 0.0678 0.0663 0.0659 0.0659 0.0650 

[TRAIN] Epoch[1](5996/114412); Loss: 0.063465; Backpropagation: 0.2926 sec; Batch: 2.1178 sec
0.1060 0.0822 0.0762 0.0683 0.0691 0.0625 0.0633 0.0573 0.0560 0.0549 0.0549 0.0540 0.0536 0.0529 0.0522 0.0522 

[TRAIN] Epoch[1](5997/114412); Loss: 0.082273; Backpropagation: 0.2923 sec; Batch: 2.0804 sec
0.1641 0.1513 0.1029 0.0880 0.0766 0.0763 0.0728 0.0713 0.0684 0.0669 0.0638 0.0646 0.0638 0.0619 0.0617 0.0619 

[TRAIN] Epoch[1](5998/114412); Loss: 0.079947; Backpropagation: 0.2910 sec; Batch: 2.1204 sec
0.1536 0.1426 0.1067 0.0889 0.0758 0.0677 0.0682 0.0679 0.0650 0.0664 0.0654 0.0634 0.0624 0.0621 0.0619 0.0611 

[TRAIN] Epoch[1](5999/114412); Loss: 0.101039; Backpropagation: 0.2929 sec; Batch: 2.0805 sec
0.1753 0.1539 0.1252 0.1043 0.0946 0.0903 0.0898 0.0890 0.0872 0.0902 0.0880 0.0860 0.0872 0.0849 0.0848 0.0860 

[TRAIN] Epoch[1](6000/114412); Loss: 0.100720; Backpropagation: 0.2915 sec; Batch: 2.1150 sec
0.1925 0.1769 0.1349 0.1175 0.0977 0.0869 0.0826 0.0839 0.0808 0.0817 0.0801 0.0788 0.0801 0.0788 0.0788 0.0796 

[TRAIN] Epoch[1](6001/114412); Loss: 0.097567; Backpropagation: 0.2912 sec; Batch: 2.1526 sec
0.1614 0.1452 0.1117 0.0956 0.0882 0.0889 0.0872 0.0861 0.0885 0.0871 0.0880 0.0871 0.0858 0.0865 0.0875 0.0861 

[TRAIN] Epoch[1](6002/114412); Loss: 0.082461; Backpropagation: 0.3043 sec; Batch: 2.1354 sec
0.1179 0.1067 0.0956 0.0970 0.0842 0.0807 0.0810 0.0744 0.0718 0.0726 0.0733 0.0717 0.0726 0.0740 0.0730 0.0728 

[TRAIN] Epoch[1](6003/114412); Loss: 0.090609; Backpropagation: 0.2908 sec; Batch: 2.1153 sec
0.1228 0.1165 0.1052 0.0920 0.0909 0.0890 0.0844 0.0841 0.0839 0.0843 0.0817 0.0841 0.0822 0.0822 0.0837 0.0829 

[TRAIN] Epoch[1](6004/114412); Loss: 0.076714; Backpropagation: 0.2913 sec; Batch: 2.1204 sec
0.1016 0.0993 0.0839 0.0838 0.0842 0.0773 0.0748 0.0720 0.0688 0.0722 0.0690 0.0687 0.0689 0.0679 0.0673 0.0675 

[TRAIN] Epoch[1](6005/114412); Loss: 0.090015; Backpropagation: 0.2904 sec; Batch: 2.0782 sec
0.1510 0.1260 0.1178 0.1025 0.0966 0.0874 0.0845 0.0801 0.0761 0.0753 0.0740 0.0749 0.0747 0.0734 0.0730 0.0729 

[TRAIN] Epoch[1](6006/114412); Loss: 0.086837; Backpropagation: 0.2908 sec; Batch: 2.1171 sec
0.1345 0.1215 0.0968 0.0927 0.0908 0.0828 0.0805 0.0798 0.0778 0.0786 0.0757 0.0748 0.0755 0.0755 0.0755 0.0766 

[TRAIN] Epoch[1](6007/114412); Loss: 0.107392; Backpropagation: 0.2931 sec; Batch: 2.0819 sec
0.1671 0.1469 0.1305 0.1129 0.1070 0.1023 0.0975 0.1026 0.0961 0.0920 0.0967 0.0933 0.0921 0.0935 0.0948 0.0929 

[TRAIN] Epoch[1](6008/114412); Loss: 0.096142; Backpropagation: 0.2932 sec; Batch: 2.0813 sec
0.1384 0.1089 0.1188 0.0973 0.0984 0.0971 0.0969 0.0945 0.0899 0.0840 0.0841 0.0867 0.0858 0.0851 0.0860 0.0863 

[TRAIN] Epoch[1](6009/114412); Loss: 0.114444; Backpropagation: 0.2905 sec; Batch: 2.1160 sec
0.1535 0.1389 0.1251 0.1210 0.1176 0.1190 0.1164 0.1136 0.1091 0.1060 0.1039 0.1024 0.1013 0.1009 0.1014 0.1010 

[TRAIN] Epoch[1](6010/114412); Loss: 0.140330; Backpropagation: 0.2909 sec; Batch: 2.0773 sec
0.1688 0.1480 0.1452 0.1321 0.1342 0.1320 0.1338 0.1340 0.1356 0.1379 0.1403 0.1400 0.1399 0.1403 0.1414 0.1415 

[TRAIN] Epoch[1](6011/114412); Loss: 0.101654; Backpropagation: 0.2907 sec; Batch: 2.1178 sec
0.1771 0.1610 0.1174 0.1082 0.0967 0.0940 0.0902 0.0890 0.0878 0.0895 0.0874 0.0869 0.0851 0.0849 0.0854 0.0858 

[TRAIN] Epoch[1](6012/114412); Loss: 0.089990; Backpropagation: 0.2915 sec; Batch: 2.1219 sec
0.1326 0.1232 0.1015 0.0915 0.0893 0.0903 0.0854 0.0862 0.0825 0.0819 0.0818 0.0797 0.0790 0.0786 0.0784 0.0780 

[TRAIN] Epoch[1](6013/114412); Loss: 0.105915; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1651 0.1464 0.1248 0.1120 0.1053 0.1046 0.0977 0.0960 0.0950 0.0941 0.0923 0.0936 0.0918 0.0915 0.0930 0.0914 

[TRAIN] Epoch[1](6014/114412); Loss: 0.120445; Backpropagation: 0.2928 sec; Batch: 2.1202 sec
0.2180 0.1872 0.1377 0.1365 0.1200 0.1107 0.1106 0.1044 0.1043 0.1024 0.0996 0.1004 0.0988 0.0986 0.0991 0.0986 

[TRAIN] Epoch[1](6015/114412); Loss: 0.072285; Backpropagation: 0.2927 sec; Batch: 2.1161 sec
0.1084 0.1080 0.0936 0.0852 0.0687 0.0682 0.0654 0.0666 0.0639 0.0619 0.0619 0.0611 0.0628 0.0615 0.0598 0.0595 

[TRAIN] Epoch[1](6016/114412); Loss: 0.108752; Backpropagation: 0.2929 sec; Batch: 2.1226 sec
0.1389 0.1331 0.1198 0.1109 0.1156 0.1114 0.1084 0.1045 0.1039 0.1008 0.0995 0.1008 0.0972 0.0975 0.0985 0.0992 

[TRAIN] Epoch[1](6017/114412); Loss: 0.124330; Backpropagation: 0.2931 sec; Batch: 2.1179 sec
0.1695 0.1540 0.1399 0.1264 0.1219 0.1219 0.1231 0.1198 0.1175 0.1174 0.1154 0.1145 0.1129 0.1123 0.1115 0.1114 

[TRAIN] Epoch[1](6018/114412); Loss: 0.108050; Backpropagation: 0.2930 sec; Batch: 2.1208 sec
0.1907 0.1576 0.1231 0.1114 0.1075 0.1075 0.1014 0.0985 0.0941 0.0931 0.0939 0.0907 0.0907 0.0899 0.0896 0.0892 

[TRAIN] Epoch[1](6019/114412); Loss: 0.110500; Backpropagation: 0.2913 sec; Batch: 2.1282 sec
0.1303 0.1209 0.1241 0.1215 0.1143 0.1109 0.1131 0.1098 0.1074 0.1071 0.1059 0.1037 0.1015 0.1003 0.0990 0.0982 

[TRAIN] Epoch[1](6020/114412); Loss: 0.165841; Backpropagation: 0.2910 sec; Batch: 2.0812 sec
0.2539 0.2277 0.1990 0.1822 0.1668 0.1494 0.1376 0.1350 0.1362 0.1404 0.1424 0.1430 0.1509 0.1573 0.1641 0.1678 

[TRAIN] Epoch[1](6021/114412); Loss: 0.133651; Backpropagation: 0.2928 sec; Batch: 2.1253 sec
0.1742 0.1742 0.1612 0.1462 0.1375 0.1356 0.1307 0.1255 0.1241 0.1199 0.1184 0.1192 0.1188 0.1179 0.1172 0.1177 

[TRAIN] Epoch[1](6022/114412); Loss: 0.117057; Backpropagation: 0.2934 sec; Batch: 2.1235 sec
0.1445 0.1314 0.1267 0.1198 0.1213 0.1257 0.1238 0.1181 0.1129 0.1117 0.1081 0.1067 0.1067 0.1054 0.1052 0.1049 

[TRAIN] Epoch[1](6023/114412); Loss: 0.088128; Backpropagation: 0.2930 sec; Batch: 2.0799 sec
0.1162 0.1096 0.0920 0.0857 0.0863 0.0921 0.0909 0.0889 0.0841 0.0846 0.0806 0.0801 0.0795 0.0793 0.0804 0.0798 

[TRAIN] Epoch[1](6024/114412); Loss: 0.122614; Backpropagation: 0.2914 sec; Batch: 2.1165 sec
0.1662 0.1476 0.1243 0.1228 0.1160 0.1164 0.1188 0.1184 0.1169 0.1147 0.1142 0.1160 0.1177 0.1189 0.1177 0.1152 

[TRAIN] Epoch[1](6025/114412); Loss: 0.080889; Backpropagation: 0.2914 sec; Batch: 2.1204 sec
0.1307 0.0988 0.1086 0.0936 0.0823 0.0811 0.0747 0.0743 0.0742 0.0715 0.0702 0.0686 0.0671 0.0668 0.0661 0.0656 

[TRAIN] Epoch[1](6026/114412); Loss: 0.100994; Backpropagation: 0.2937 sec; Batch: 2.1008 sec
0.1569 0.1446 0.1178 0.1090 0.1025 0.0996 0.0927 0.0920 0.0894 0.0889 0.0888 0.0875 0.0875 0.0867 0.0863 0.0855 

[TRAIN] Epoch[1](6027/114412); Loss: 0.143412; Backpropagation: 0.2909 sec; Batch: 2.1189 sec
0.2182 0.1930 0.1419 0.1325 0.1276 0.1309 0.1381 0.1427 0.1418 0.1400 0.1352 0.1324 0.1313 0.1297 0.1293 0.1300 

[TRAIN] Epoch[1](6028/114412); Loss: 0.134376; Backpropagation: 0.2933 sec; Batch: 2.1195 sec
0.1567 0.1496 0.1372 0.1226 0.1212 0.1227 0.1264 0.1276 0.1261 0.1321 0.1353 0.1388 0.1438 0.1405 0.1368 0.1326 

[TRAIN] Epoch[1](6029/114412); Loss: 0.143550; Backpropagation: 0.2910 sec; Batch: 2.1189 sec
0.2237 0.2049 0.1680 0.1541 0.1397 0.1401 0.1403 0.1395 0.1350 0.1312 0.1280 0.1237 0.1196 0.1168 0.1160 0.1161 

[TRAIN] Epoch[1](6030/114412); Loss: 0.175849; Backpropagation: 0.2909 sec; Batch: 2.1155 sec
0.2060 0.1878 0.1688 0.1720 0.1756 0.1796 0.1798 0.1830 0.1829 0.1773 0.1731 0.1690 0.1668 0.1658 0.1640 0.1622 

[TRAIN] Epoch[1](6031/114412); Loss: 0.124947; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1696 0.1571 0.1391 0.1345 0.1281 0.1261 0.1197 0.1197 0.1163 0.1157 0.1142 0.1127 0.1132 0.1141 0.1104 0.1084 

[TRAIN] Epoch[1](6032/114412); Loss: 0.149590; Backpropagation: 0.2913 sec; Batch: 2.0854 sec
0.1641 0.1515 0.1385 0.1393 0.1435 0.1481 0.1471 0.1464 0.1451 0.1475 0.1490 0.1506 0.1545 0.1557 0.1557 0.1569 

[TRAIN] Epoch[1](6033/114412); Loss: 0.154388; Backpropagation: 0.2911 sec; Batch: 2.0780 sec
0.1458 0.1380 0.1321 0.1295 0.1324 0.1426 0.1488 0.1595 0.1667 0.1753 0.1756 0.1706 0.1652 0.1633 0.1614 0.1635 

[TRAIN] Epoch[1](6034/114412); Loss: 0.144459; Backpropagation: 0.2935 sec; Batch: 2.0925 sec
0.1496 0.1493 0.1329 0.1304 0.1304 0.1308 0.1352 0.1404 0.1419 0.1456 0.1458 0.1486 0.1533 0.1563 0.1591 0.1617 

[TRAIN] Epoch[1](6035/114412); Loss: 0.129943; Backpropagation: 0.2926 sec; Batch: 2.1141 sec
0.2110 0.1732 0.1518 0.1324 0.1260 0.1250 0.1237 0.1198 0.1184 0.1161 0.1166 0.1171 0.1145 0.1118 0.1117 0.1100 

[TRAIN] Epoch[1](6036/114412); Loss: 0.116508; Backpropagation: 0.2914 sec; Batch: 2.1211 sec
0.1402 0.1183 0.1129 0.1128 0.1148 0.1133 0.1127 0.1144 0.1144 0.1155 0.1176 0.1173 0.1161 0.1152 0.1145 0.1142 

[TRAIN] Epoch[1](6037/114412); Loss: 0.132177; Backpropagation: 0.2906 sec; Batch: 2.0792 sec
0.2283 0.2021 0.1558 0.1431 0.1303 0.1207 0.1211 0.1173 0.1123 0.1131 0.1129 0.1115 0.1142 0.1136 0.1105 0.1081 

[TRAIN] Epoch[1](6038/114412); Loss: 0.289470; Backpropagation: 0.2912 sec; Batch: 2.1048 sec
0.2266 0.2144 0.1986 0.1986 0.2118 0.2287 0.2486 0.2653 0.2843 0.3037 0.3238 0.3453 0.3661 0.3860 0.4053 0.4244 

[TRAIN] Epoch[1](6039/114412); Loss: 0.216565; Backpropagation: 0.2920 sec; Batch: 2.1194 sec
0.1276 0.1192 0.1082 0.1159 0.1364 0.1518 0.1788 0.2013 0.2260 0.2457 0.2642 0.2821 0.3010 0.3185 0.3354 0.3528 

[TRAIN] Epoch[1](6040/114412); Loss: 0.164647; Backpropagation: 0.2927 sec; Batch: 2.1214 sec
0.1522 0.1419 0.1454 0.1495 0.1545 0.1572 0.1594 0.1622 0.1654 0.1698 0.1756 0.1765 0.1812 0.1831 0.1812 0.1793 

[TRAIN] Epoch[1](6041/114412); Loss: 0.183965; Backpropagation: 0.2930 sec; Batch: 2.1171 sec
0.1533 0.1471 0.1571 0.1759 0.1753 0.1792 0.1814 0.1926 0.1999 0.2030 0.2019 0.2023 0.1998 0.1955 0.1907 0.1884 

[TRAIN] Epoch[1](6042/114412); Loss: 0.243150; Backpropagation: 0.2933 sec; Batch: 2.0823 sec
0.2180 0.2089 0.1990 0.2006 0.2083 0.2194 0.2311 0.2409 0.2516 0.2638 0.2713 0.2753 0.2762 0.2775 0.2756 0.2728 

[TRAIN] Epoch[1](6043/114412); Loss: 0.258904; Backpropagation: 0.2913 sec; Batch: 2.1192 sec
0.2198 0.2075 0.1674 0.1637 0.1720 0.1855 0.2072 0.2268 0.2530 0.2775 0.2990 0.3178 0.3359 0.3524 0.3702 0.3868 

[TRAIN] Epoch[1](6044/114412); Loss: 0.298222; Backpropagation: 0.2905 sec; Batch: 2.0782 sec
0.1826 0.1781 0.1728 0.1830 0.2055 0.2288 0.2552 0.2816 0.3077 0.3305 0.3523 0.3740 0.3965 0.4194 0.4403 0.4635 

[TRAIN] Epoch[1](6045/114412); Loss: 0.240505; Backpropagation: 0.2929 sec; Batch: 2.1020 sec
0.1912 0.1862 0.1671 0.1684 0.1799 0.1931 0.2127 0.2305 0.2473 0.2645 0.2768 0.2863 0.2983 0.3080 0.3151 0.3227 

[TRAIN] Epoch[1](6046/114412); Loss: 0.236468; Backpropagation: 0.2954 sec; Batch: 2.1249 sec
0.2074 0.2130 0.2132 0.2038 0.2014 0.2086 0.2185 0.2258 0.2353 0.2433 0.2535 0.2629 0.2644 0.2691 0.2774 0.2860 

[TRAIN] Epoch[1](6047/114412); Loss: 0.289341; Backpropagation: 0.2933 sec; Batch: 2.0821 sec
0.1786 0.1755 0.1919 0.2040 0.2271 0.2434 0.2607 0.2793 0.3002 0.3193 0.3380 0.3537 0.3692 0.3818 0.3960 0.4107 

[TRAIN] Epoch[1](6048/114412); Loss: 0.287570; Backpropagation: 0.2949 sec; Batch: 2.0873 sec
0.2642 0.2523 0.2277 0.2283 0.2366 0.2505 0.2592 0.2698 0.2833 0.2977 0.3096 0.3207 0.3332 0.3449 0.3548 0.3681 

[TRAIN] Epoch[1](6049/114412); Loss: 0.165681; Backpropagation: 0.2912 sec; Batch: 2.0795 sec
0.1684 0.1577 0.1549 0.1561 0.1601 0.1626 0.1617 0.1634 0.1663 0.1676 0.1681 0.1679 0.1687 0.1724 0.1757 0.1791 

[TRAIN] Epoch[1](6050/114412); Loss: 0.270965; Backpropagation: 0.2934 sec; Batch: 2.0817 sec
0.1445 0.1450 0.1590 0.1787 0.2020 0.2253 0.2479 0.2662 0.2884 0.3095 0.3245 0.3379 0.3538 0.3681 0.3839 0.4008 

[TRAIN] Epoch[1](6051/114412); Loss: 0.138723; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.1876 0.1781 0.1593 0.1602 0.1409 0.1376 0.1331 0.1275 0.1269 0.1262 0.1272 0.1271 0.1266 0.1243 0.1205 0.1164 

[TRAIN] Epoch[1](6052/114412); Loss: 0.138066; Backpropagation: 0.2915 sec; Batch: 2.0799 sec
0.2091 0.2035 0.1746 0.1572 0.1323 0.1239 0.1199 0.1172 0.1152 0.1182 0.1233 0.1224 0.1221 0.1228 0.1231 0.1242 

[TRAIN] Epoch[1](6053/114412); Loss: 0.217930; Backpropagation: 0.2911 sec; Batch: 2.1277 sec
0.2009 0.1997 0.2045 0.2133 0.2167 0.2202 0.2156 0.2159 0.2203 0.2231 0.2237 0.2244 0.2262 0.2265 0.2281 0.2278 

[TRAIN] Epoch[1](6054/114412); Loss: 0.207962; Backpropagation: 0.2909 sec; Batch: 2.1209 sec
0.1672 0.1615 0.1687 0.1782 0.1880 0.1946 0.2023 0.2094 0.2180 0.2246 0.2281 0.2318 0.2356 0.2376 0.2396 0.2423 

[TRAIN] Epoch[1](6055/114412); Loss: 0.119738; Backpropagation: 0.2927 sec; Batch: 2.1377 sec
0.1079 0.1185 0.1049 0.0998 0.1001 0.1084 0.1150 0.1211 0.1230 0.1245 0.1275 0.1276 0.1297 0.1329 0.1366 0.1383 

[TRAIN] Epoch[1](6056/114412); Loss: 0.153727; Backpropagation: 0.2910 sec; Batch: 2.1402 sec
0.1899 0.1643 0.1370 0.1303 0.1236 0.1271 0.1338 0.1402 0.1472 0.1516 0.1556 0.1617 0.1669 0.1729 0.1783 0.1793 

[TRAIN] Epoch[1](6057/114412); Loss: 0.253411; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.2060 0.1905 0.1620 0.1639 0.1843 0.1982 0.2196 0.2330 0.2562 0.2757 0.2945 0.3074 0.3213 0.3331 0.3466 0.3622 

[TRAIN] Epoch[1](6058/114412); Loss: 0.223210; Backpropagation: 0.2937 sec; Batch: 2.0822 sec
0.2010 0.1926 0.1920 0.1901 0.1960 0.1984 0.2066 0.2138 0.2242 0.2292 0.2346 0.2403 0.2485 0.2576 0.2682 0.2782 

[TRAIN] Epoch[1](6059/114412); Loss: 0.165976; Backpropagation: 0.2916 sec; Batch: 2.1223 sec
0.2007 0.1906 0.1565 0.1486 0.1458 0.1514 0.1502 0.1538 0.1548 0.1580 0.1642 0.1665 0.1720 0.1773 0.1810 0.1841 

[TRAIN] Epoch[1](6060/114412); Loss: 0.166817; Backpropagation: 0.2921 sec; Batch: 2.0869 sec
0.1450 0.1333 0.1365 0.1308 0.1317 0.1337 0.1430 0.1487 0.1605 0.1689 0.1820 0.1917 0.2021 0.2104 0.2202 0.2307 

[TRAIN] Epoch[1](6061/114412); Loss: 0.291706; Backpropagation: 0.2911 sec; Batch: 2.2383 sec
0.1768 0.1745 0.1902 0.1979 0.2164 0.2298 0.2571 0.2746 0.3009 0.3179 0.3416 0.3612 0.3807 0.3990 0.4168 0.4320 

[TRAIN] Epoch[1](6062/114412); Loss: 0.151587; Backpropagation: 0.2910 sec; Batch: 2.2169 sec
0.1460 0.1392 0.1334 0.1284 0.1271 0.1356 0.1414 0.1490 0.1555 0.1609 0.1654 0.1675 0.1684 0.1676 0.1698 0.1702 

[TRAIN] Epoch[1](6063/114412); Loss: 0.160488; Backpropagation: 0.2953 sec; Batch: 2.2449 sec
0.2341 0.2108 0.1763 0.1648 0.1524 0.1510 0.1490 0.1498 0.1489 0.1479 0.1510 0.1526 0.1502 0.1455 0.1433 0.1403 

[TRAIN] Epoch[1](6064/114412); Loss: 0.181371; Backpropagation: 0.2924 sec; Batch: 2.3005 sec
0.1351 0.1272 0.1565 0.1586 0.1657 0.1717 0.1748 0.1798 0.1865 0.1898 0.1969 0.2012 0.2057 0.2121 0.2186 0.2216 

[TRAIN] Epoch[1](6065/114412); Loss: 0.203982; Backpropagation: 0.2984 sec; Batch: 2.2372 sec
0.1664 0.1570 0.1751 0.1878 0.1980 0.2047 0.2095 0.2104 0.2108 0.2133 0.2140 0.2175 0.2203 0.2235 0.2259 0.2296 

[TRAIN] Epoch[1](6066/114412); Loss: 0.154368; Backpropagation: 0.2951 sec; Batch: 2.1164 sec
0.1706 0.1506 0.1501 0.1427 0.1406 0.1412 0.1469 0.1506 0.1546 0.1601 0.1635 0.1626 0.1613 0.1591 0.1580 0.1574 

[TRAIN] Epoch[1](6067/114412); Loss: 0.260740; Backpropagation: 0.2955 sec; Batch: 2.1465 sec
0.2033 0.1988 0.2062 0.2100 0.2166 0.2296 0.2390 0.2504 0.2629 0.2730 0.2845 0.2948 0.3077 0.3203 0.3323 0.3424 

[TRAIN] Epoch[1](6068/114412); Loss: 0.198678; Backpropagation: 0.2979 sec; Batch: 2.1157 sec
0.2304 0.2086 0.1647 0.1574 0.1563 0.1596 0.1661 0.1723 0.1806 0.1942 0.2094 0.2225 0.2315 0.2386 0.2427 0.2440 

[TRAIN] Epoch[1](6069/114412); Loss: 0.273457; Backpropagation: 0.2956 sec; Batch: 2.1457 sec
0.2467 0.2453 0.2551 0.2566 0.2620 0.2611 0.2662 0.2687 0.2759 0.2814 0.2837 0.2847 0.2890 0.2942 0.3003 0.3044 

[TRAIN] Epoch[1](6070/114412); Loss: 0.436664; Backpropagation: 0.2957 sec; Batch: 2.1198 sec
0.2645 0.2652 0.2920 0.3038 0.3328 0.3520 0.3862 0.4094 0.4445 0.4713 0.5056 0.5345 0.5662 0.5938 0.6195 0.6453 

[TRAIN] Epoch[1](6071/114412); Loss: 0.119541; Backpropagation: 0.2981 sec; Batch: 2.1497 sec
0.1238 0.1189 0.0929 0.0888 0.0931 0.1007 0.1066 0.1137 0.1211 0.1273 0.1311 0.1357 0.1383 0.1397 0.1397 0.1411 

[TRAIN] Epoch[1](6072/114412); Loss: 0.298127; Backpropagation: 0.2953 sec; Batch: 2.2504 sec
0.2650 0.2464 0.2450 0.2446 0.2569 0.2657 0.2808 0.2889 0.3005 0.3088 0.3183 0.3297 0.3400 0.3516 0.3601 0.3677 

[TRAIN] Epoch[1](6073/114412); Loss: 0.319667; Backpropagation: 0.2991 sec; Batch: 2.2590 sec
0.2038 0.1951 0.2025 0.2098 0.2321 0.2508 0.2795 0.3016 0.3278 0.3509 0.3733 0.3951 0.4176 0.4378 0.4586 0.4783 

[TRAIN] Epoch[1](6074/114412); Loss: 0.187753; Backpropagation: 0.2974 sec; Batch: 2.1504 sec
0.1430 0.1433 0.1503 0.1538 0.1608 0.1688 0.1775 0.1836 0.1910 0.1982 0.2060 0.2135 0.2194 0.2259 0.2315 0.2376 

[TRAIN] Epoch[1](6075/114412); Loss: 0.199755; Backpropagation: 0.2981 sec; Batch: 2.0876 sec
0.1357 0.1538 0.1730 0.1805 0.1885 0.1913 0.1995 0.2014 0.2064 0.2099 0.2131 0.2192 0.2236 0.2281 0.2331 0.2390 

[TRAIN] Epoch[1](6076/114412); Loss: 0.224899; Backpropagation: 0.2957 sec; Batch: 2.2762 sec
0.2166 0.1933 0.1803 0.1778 0.1764 0.1877 0.2010 0.2112 0.2226 0.2370 0.2499 0.2576 0.2646 0.2695 0.2742 0.2786 

[TRAIN] Epoch[1](6077/114412); Loss: 0.243710; Backpropagation: 0.2957 sec; Batch: 2.0860 sec
0.2225 0.2148 0.2000 0.1894 0.1919 0.1980 0.2145 0.2263 0.2412 0.2517 0.2652 0.2766 0.2888 0.2977 0.3064 0.3144 

[TRAIN] Epoch[1](6078/114412); Loss: 0.258257; Backpropagation: 0.3006 sec; Batch: 2.1367 sec
0.2104 0.2002 0.1999 0.2019 0.2082 0.2198 0.2338 0.2462 0.2579 0.2701 0.2808 0.2940 0.3091 0.3213 0.3331 0.3453 

[TRAIN] Epoch[1](6079/114412); Loss: 0.177023; Backpropagation: 0.2981 sec; Batch: 2.1013 sec
0.2009 0.1866 0.1709 0.1614 0.1539 0.1546 0.1565 0.1629 0.1694 0.1713 0.1762 0.1836 0.1910 0.1938 0.1986 0.2007 

[TRAIN] Epoch[1](6080/114412); Loss: 0.364569; Backpropagation: 0.2980 sec; Batch: 2.1370 sec
0.2055 0.2005 0.2267 0.2348 0.2627 0.2846 0.3166 0.3435 0.3751 0.4054 0.4341 0.4581 0.4839 0.5093 0.5343 0.5581 

[TRAIN] Epoch[1](6081/114412); Loss: 0.361689; Backpropagation: 0.2950 sec; Batch: 2.1230 sec
0.2668 0.2668 0.2731 0.2724 0.2914 0.3047 0.3244 0.3382 0.3605 0.3789 0.4005 0.4204 0.4415 0.4620 0.4832 0.5024 

[TRAIN] Epoch[1](6082/114412); Loss: 0.303611; Backpropagation: 0.2957 sec; Batch: 2.1104 sec
0.1896 0.1906 0.1998 0.2027 0.2220 0.2397 0.2622 0.2828 0.3062 0.3267 0.3512 0.3720 0.3959 0.4180 0.4384 0.4600 

[TRAIN] Epoch[1](6083/114412); Loss: 0.407643; Backpropagation: 0.2949 sec; Batch: 2.1231 sec
0.1901 0.2058 0.2523 0.2715 0.3087 0.3341 0.3678 0.3960 0.4293 0.4564 0.4855 0.5126 0.5393 0.5656 0.5912 0.6161 

[TRAIN] Epoch[1](6084/114412); Loss: 0.428226; Backpropagation: 0.2951 sec; Batch: 2.0818 sec
0.2904 0.2945 0.3033 0.3185 0.3411 0.3646 0.3885 0.4107 0.4371 0.4630 0.4876 0.5090 0.5303 0.5503 0.5715 0.5912 

[TRAIN] Epoch[1](6085/114412); Loss: 0.429672; Backpropagation: 0.2988 sec; Batch: 2.1258 sec
0.2766 0.2816 0.3129 0.3205 0.3430 0.3618 0.3898 0.4143 0.4401 0.4631 0.4869 0.5082 0.5321 0.5567 0.5805 0.6066 

[TRAIN] Epoch[1](6086/114412); Loss: 0.372262; Backpropagation: 0.2956 sec; Batch: 2.1248 sec
0.2150 0.2131 0.2296 0.2409 0.2686 0.2929 0.3211 0.3460 0.3730 0.4023 0.4320 0.4627 0.4939 0.5254 0.5554 0.5846 

[TRAIN] Epoch[1](6087/114412); Loss: 0.282381; Backpropagation: 0.2956 sec; Batch: 2.1257 sec
0.1947 0.1884 0.1897 0.1934 0.2033 0.2172 0.2367 0.2579 0.2806 0.3028 0.3261 0.3474 0.3682 0.3866 0.4026 0.4225 

[TRAIN] Epoch[1](6088/114412); Loss: 0.280412; Backpropagation: 0.2957 sec; Batch: 2.1250 sec
0.1783 0.1789 0.2024 0.2091 0.2266 0.2411 0.2586 0.2739 0.2906 0.3074 0.3231 0.3369 0.3481 0.3611 0.3698 0.3807 

[TRAIN] Epoch[1](6089/114412); Loss: 0.495594; Backpropagation: 0.2958 sec; Batch: 2.1136 sec
0.3139 0.3195 0.3548 0.3636 0.3925 0.4133 0.4473 0.4735 0.5062 0.5338 0.5639 0.5923 0.6208 0.6487 0.6785 0.7071 

[TRAIN] Epoch[1](6090/114412); Loss: 0.277065; Backpropagation: 0.2956 sec; Batch: 2.1078 sec
0.2671 0.2593 0.2463 0.2406 0.2380 0.2440 0.2505 0.2584 0.2641 0.2762 0.2881 0.2987 0.3089 0.3205 0.3315 0.3409 

[TRAIN] Epoch[1](6091/114412); Loss: 0.295124; Backpropagation: 0.3006 sec; Batch: 2.1270 sec
0.2335 0.2277 0.2313 0.2312 0.2380 0.2509 0.2622 0.2773 0.2920 0.3066 0.3238 0.3399 0.3539 0.3695 0.3845 0.3996 

[TRAIN] Epoch[1](6092/114412); Loss: 0.214459; Backpropagation: 0.2955 sec; Batch: 2.1253 sec
0.1817 0.1781 0.1704 0.1710 0.1746 0.1818 0.1903 0.1972 0.2058 0.2180 0.2314 0.2429 0.2536 0.2667 0.2785 0.2894 

[TRAIN] Epoch[1](6093/114412); Loss: 0.507858; Backpropagation: 0.2955 sec; Batch: 2.1240 sec
0.2885 0.2942 0.3289 0.3479 0.3813 0.4118 0.4481 0.4832 0.5173 0.5536 0.5880 0.6250 0.6616 0.6967 0.7328 0.7668 

[TRAIN] Epoch[1](6094/114412); Loss: 0.280188; Backpropagation: 0.2954 sec; Batch: 2.1028 sec
0.1765 0.1812 0.2038 0.2143 0.2348 0.2499 0.2631 0.2761 0.2890 0.3004 0.3146 0.3296 0.3428 0.3551 0.3693 0.3825 

[TRAIN] Epoch[1](6095/114412); Loss: 0.292610; Backpropagation: 0.2956 sec; Batch: 2.1228 sec
0.2490 0.2469 0.2524 0.2501 0.2528 0.2577 0.2663 0.2759 0.2874 0.3004 0.3134 0.3249 0.3359 0.3456 0.3560 0.3671 

[TRAIN] Epoch[1](6096/114412); Loss: 0.217157; Backpropagation: 0.2989 sec; Batch: 2.1287 sec
0.2279 0.2144 0.2034 0.1969 0.1941 0.1937 0.1994 0.2054 0.2111 0.2183 0.2233 0.2268 0.2314 0.2372 0.2422 0.2489 

[TRAIN] Epoch[1](6097/114412); Loss: 0.245199; Backpropagation: 0.2957 sec; Batch: 2.1234 sec
0.2043 0.1943 0.1999 0.2030 0.2115 0.2200 0.2282 0.2401 0.2485 0.2571 0.2661 0.2749 0.2832 0.2905 0.2977 0.3038 

[TRAIN] Epoch[1](6098/114412); Loss: 0.292054; Backpropagation: 0.2961 sec; Batch: 2.1241 sec
0.3280 0.3157 0.2882 0.2755 0.2663 0.2627 0.2669 0.2679 0.2737 0.2780 0.2869 0.2955 0.3045 0.3119 0.3209 0.3302 

[TRAIN] Epoch[1](6099/114412); Loss: 0.193893; Backpropagation: 0.2954 sec; Batch: 2.1207 sec
0.2191 0.2091 0.1940 0.1833 0.1781 0.1811 0.1848 0.1894 0.1912 0.1926 0.1941 0.1962 0.1979 0.1982 0.1972 0.1960 

[TRAIN] Epoch[1](6100/114412); Loss: 0.324752; Backpropagation: 0.2953 sec; Batch: 2.1253 sec
0.3038 0.2972 0.2833 0.2738 0.2746 0.2803 0.2894 0.2979 0.3112 0.3246 0.3415 0.3585 0.3720 0.3845 0.3957 0.4077 

[TRAIN] Epoch[1](6101/114412); Loss: 0.221549; Backpropagation: 0.2959 sec; Batch: 2.1222 sec
0.2032 0.1989 0.2040 0.1995 0.2017 0.2016 0.2074 0.2152 0.2215 0.2251 0.2309 0.2344 0.2401 0.2468 0.2530 0.2614 

[TRAIN] Epoch[1](6102/114412); Loss: 0.245249; Backpropagation: 0.2957 sec; Batch: 2.1209 sec
0.2339 0.2302 0.2256 0.2246 0.2248 0.2233 0.2276 0.2369 0.2418 0.2477 0.2536 0.2599 0.2650 0.2703 0.2765 0.2823 

[TRAIN] Epoch[1](6103/114412); Loss: 0.154979; Backpropagation: 0.2957 sec; Batch: 2.1213 sec
0.2045 0.2018 0.1864 0.1736 0.1620 0.1511 0.1446 0.1423 0.1388 0.1368 0.1351 0.1336 0.1372 0.1402 0.1436 0.1480 

[TRAIN] Epoch[1](6104/114412); Loss: 0.271467; Backpropagation: 0.2950 sec; Batch: 2.1210 sec
0.2236 0.2233 0.2267 0.2292 0.2381 0.2465 0.2542 0.2642 0.2705 0.2806 0.2892 0.3013 0.3123 0.3204 0.3284 0.3349 

[TRAIN] Epoch[1](6105/114412); Loss: 0.298149; Backpropagation: 0.2979 sec; Batch: 2.1235 sec
0.2809 0.2791 0.2739 0.2710 0.2698 0.2770 0.2823 0.2905 0.2950 0.3017 0.3066 0.3152 0.3213 0.3291 0.3343 0.3426 

[TRAIN] Epoch[1](6106/114412); Loss: 0.184771; Backpropagation: 0.2957 sec; Batch: 2.0815 sec
0.1947 0.1815 0.1678 0.1658 0.1674 0.1703 0.1714 0.1782 0.1844 0.1884 0.1917 0.1939 0.1960 0.1986 0.2015 0.2049 

[TRAIN] Epoch[1](6107/114412); Loss: 0.258072; Backpropagation: 0.2956 sec; Batch: 2.1234 sec
0.2065 0.2042 0.2134 0.2167 0.2309 0.2375 0.2477 0.2581 0.2664 0.2736 0.2812 0.2875 0.2924 0.2972 0.3045 0.3112 

[TRAIN] Epoch[1](6108/114412); Loss: 0.363795; Backpropagation: 0.2994 sec; Batch: 2.0852 sec
0.2451 0.2457 0.2720 0.2790 0.2999 0.3175 0.3395 0.3588 0.3749 0.3904 0.4049 0.4231 0.4400 0.4589 0.4776 0.4936 

[TRAIN] Epoch[1](6109/114412); Loss: 0.368317; Backpropagation: 0.2947 sec; Batch: 2.1202 sec
0.2501 0.2522 0.2758 0.2876 0.3074 0.3234 0.3382 0.3546 0.3714 0.3891 0.4085 0.4267 0.4474 0.4682 0.4871 0.5055 

[TRAIN] Epoch[1](6110/114412); Loss: 0.240187; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.2090 0.2003 0.2129 0.2108 0.2176 0.2223 0.2285 0.2364 0.2426 0.2479 0.2539 0.2589 0.2648 0.2714 0.2791 0.2865 

[TRAIN] Epoch[1](6111/114412); Loss: 0.393261; Backpropagation: 0.2954 sec; Batch: 2.1214 sec
0.3397 0.3362 0.3402 0.3414 0.3481 0.3586 0.3688 0.3792 0.3905 0.4025 0.4150 0.4269 0.4401 0.4544 0.4689 0.4818 

[TRAIN] Epoch[1](6112/114412); Loss: 0.205508; Backpropagation: 0.2958 sec; Batch: 2.1340 sec
0.1805 0.1860 0.1941 0.1954 0.1953 0.1971 0.1987 0.2027 0.2066 0.2112 0.2144 0.2167 0.2180 0.2213 0.2238 0.2265 

[TRAIN] Epoch[1](6113/114412); Loss: 0.179960; Backpropagation: 0.3006 sec; Batch: 2.1290 sec
0.2389 0.2341 0.2143 0.2005 0.1875 0.1801 0.1728 0.1699 0.1658 0.1626 0.1616 0.1602 0.1589 0.1569 0.1568 0.1586 

[TRAIN] Epoch[1](6114/114412); Loss: 0.211117; Backpropagation: 0.2951 sec; Batch: 2.1190 sec
0.2114 0.2138 0.2096 0.2063 0.2037 0.2047 0.2032 0.2037 0.2073 0.2097 0.2125 0.2147 0.2160 0.2184 0.2205 0.2222 

[TRAIN] Epoch[1](6115/114412); Loss: 0.185495; Backpropagation: 0.2959 sec; Batch: 2.1224 sec
0.2759 0.2645 0.2384 0.2271 0.2113 0.1979 0.1844 0.1737 0.1630 0.1550 0.1509 0.1472 0.1446 0.1434 0.1453 0.1452 

[TRAIN] Epoch[1](6116/114412); Loss: 0.280370; Backpropagation: 0.2956 sec; Batch: 2.1211 sec
0.2282 0.2279 0.2415 0.2436 0.2514 0.2573 0.2653 0.2743 0.2817 0.2914 0.2995 0.3065 0.3168 0.3248 0.3335 0.3422 

[TRAIN] Epoch[1](6117/114412); Loss: 0.278438; Backpropagation: 0.2954 sec; Batch: 2.1214 sec
0.2191 0.2182 0.2200 0.2275 0.2375 0.2471 0.2580 0.2689 0.2794 0.2893 0.3005 0.3121 0.3254 0.3382 0.3508 0.3629 

[TRAIN] Epoch[1](6118/114412); Loss: 0.202765; Backpropagation: 0.2953 sec; Batch: 2.0940 sec
0.1894 0.1936 0.1879 0.1850 0.1859 0.1893 0.1929 0.1963 0.2006 0.2044 0.2081 0.2114 0.2154 0.2220 0.2279 0.2341 

[TRAIN] Epoch[1](6119/114412); Loss: 0.226113; Backpropagation: 0.2952 sec; Batch: 2.1208 sec
0.2339 0.2273 0.2137 0.2095 0.2091 0.2089 0.2144 0.2189 0.2228 0.2278 0.2332 0.2343 0.2368 0.2385 0.2421 0.2463 

[TRAIN] Epoch[1](6120/114412); Loss: 0.210921; Backpropagation: 0.2953 sec; Batch: 2.1202 sec
0.1879 0.1808 0.1922 0.1937 0.1990 0.2056 0.2109 0.2153 0.2178 0.2195 0.2213 0.2228 0.2268 0.2271 0.2269 0.2273 

[TRAIN] Epoch[1](6121/114412); Loss: 0.219533; Backpropagation: 0.2957 sec; Batch: 2.1228 sec
0.2296 0.2237 0.2126 0.2049 0.2026 0.2016 0.2039 0.2099 0.2141 0.2172 0.2210 0.2264 0.2295 0.2339 0.2385 0.2432 

[TRAIN] Epoch[1](6122/114412); Loss: 0.233235; Backpropagation: 0.2954 sec; Batch: 2.1168 sec
0.2217 0.2131 0.2075 0.2044 0.2061 0.2111 0.2147 0.2208 0.2256 0.2353 0.2424 0.2499 0.2581 0.2664 0.2737 0.2807 

[TRAIN] Epoch[1](6123/114412); Loss: 0.199808; Backpropagation: 0.2967 sec; Batch: 2.1215 sec
0.2098 0.2038 0.1965 0.1894 0.1842 0.1859 0.1844 0.1856 0.1902 0.1932 0.1982 0.2043 0.2088 0.2159 0.2207 0.2259 

[TRAIN] Epoch[1](6124/114412); Loss: 0.237438; Backpropagation: 0.2956 sec; Batch: 2.1253 sec
0.2276 0.2260 0.2276 0.2235 0.2200 0.2217 0.2248 0.2297 0.2338 0.2381 0.2438 0.2478 0.2526 0.2566 0.2611 0.2641 

[TRAIN] Epoch[1](6125/114412); Loss: 0.241799; Backpropagation: 0.2977 sec; Batch: 2.1266 sec
0.2759 0.2696 0.2561 0.2511 0.2467 0.2420 0.2415 0.2396 0.2336 0.2309 0.2278 0.2263 0.2275 0.2289 0.2330 0.2381 

[TRAIN] Epoch[1](6126/114412); Loss: 0.149487; Backpropagation: 0.2973 sec; Batch: 2.1252 sec
0.1714 0.1649 0.1568 0.1514 0.1467 0.1446 0.1425 0.1431 0.1436 0.1463 0.1475 0.1482 0.1476 0.1464 0.1458 0.1451 

[TRAIN] Epoch[1](6127/114412); Loss: 0.156244; Backpropagation: 0.2956 sec; Batch: 2.1222 sec
0.2220 0.2130 0.1906 0.1800 0.1644 0.1560 0.1463 0.1367 0.1315 0.1320 0.1337 0.1339 0.1366 0.1401 0.1406 0.1425 

[TRAIN] Epoch[1](6128/114412); Loss: 0.229276; Backpropagation: 0.2969 sec; Batch: 2.1237 sec
0.1656 0.1737 0.1902 0.1979 0.2059 0.2128 0.2184 0.2277 0.2318 0.2387 0.2468 0.2548 0.2638 0.2716 0.2808 0.2880 

[TRAIN] Epoch[1](6129/114412); Loss: 0.154862; Backpropagation: 0.2956 sec; Batch: 2.1199 sec
0.1972 0.1897 0.1801 0.1671 0.1565 0.1528 0.1463 0.1447 0.1445 0.1438 0.1438 0.1424 0.1423 0.1428 0.1421 0.1419 

[TRAIN] Epoch[1](6130/114412); Loss: 0.197286; Backpropagation: 0.2984 sec; Batch: 2.1394 sec
0.2014 0.1940 0.1864 0.1835 0.1830 0.1887 0.1922 0.1942 0.1974 0.1990 0.1996 0.2025 0.2055 0.2061 0.2097 0.2132 

[TRAIN] Epoch[1](6131/114412); Loss: 0.265711; Backpropagation: 0.2981 sec; Batch: 2.1396 sec
0.2350 0.2355 0.2378 0.2338 0.2338 0.2411 0.2474 0.2571 0.2637 0.2715 0.2804 0.2863 0.2957 0.3032 0.3103 0.3188 

[TRAIN] Epoch[1](6132/114412); Loss: 0.216920; Backpropagation: 0.2959 sec; Batch: 2.0918 sec
0.2023 0.1940 0.1921 0.1929 0.1915 0.1926 0.1942 0.2009 0.2049 0.2150 0.2234 0.2334 0.2445 0.2542 0.2633 0.2715 

[TRAIN] Epoch[1](6133/114412); Loss: 0.350154; Backpropagation: 0.2956 sec; Batch: 2.1184 sec
0.2314 0.2292 0.2571 0.2645 0.2840 0.2991 0.3180 0.3378 0.3565 0.3746 0.3937 0.4124 0.4319 0.4512 0.4709 0.4902 

[TRAIN] Epoch[1](6134/114412); Loss: 0.219889; Backpropagation: 0.2951 sec; Batch: 2.1223 sec
0.2316 0.2252 0.2177 0.2140 0.2117 0.2168 0.2185 0.2188 0.2175 0.2164 0.2171 0.2174 0.2194 0.2217 0.2262 0.2282 

[TRAIN] Epoch[1](6135/114412); Loss: 0.210887; Backpropagation: 0.2958 sec; Batch: 2.1153 sec
0.2275 0.2224 0.2131 0.2094 0.2042 0.2038 0.2034 0.2022 0.2029 0.2053 0.2073 0.2093 0.2122 0.2153 0.2173 0.2186 

[TRAIN] Epoch[1](6136/114412); Loss: 0.181726; Backpropagation: 0.2954 sec; Batch: 2.1178 sec
0.2327 0.2157 0.1976 0.1872 0.1788 0.1729 0.1682 0.1668 0.1658 0.1667 0.1690 0.1703 0.1746 0.1773 0.1806 0.1834 

[TRAIN] Epoch[1](6137/114412); Loss: 0.298791; Backpropagation: 0.2958 sec; Batch: 2.1084 sec
0.2497 0.2461 0.2574 0.2597 0.2668 0.2736 0.2827 0.2929 0.3015 0.3122 0.3203 0.3284 0.3351 0.3416 0.3515 0.3612 

[TRAIN] Epoch[1](6138/114412); Loss: 0.276367; Backpropagation: 0.2958 sec; Batch: 2.1198 sec
0.2094 0.2092 0.2180 0.2223 0.2384 0.2488 0.2625 0.2754 0.2866 0.2966 0.3057 0.3148 0.3227 0.3301 0.3369 0.3447 

[TRAIN] Epoch[1](6139/114412); Loss: 0.165315; Backpropagation: 0.2949 sec; Batch: 2.1248 sec
0.2201 0.2081 0.1958 0.1839 0.1733 0.1699 0.1647 0.1634 0.1579 0.1518 0.1475 0.1443 0.1430 0.1405 0.1404 0.1405 

[TRAIN] Epoch[1](6140/114412); Loss: 0.219231; Backpropagation: 0.2959 sec; Batch: 2.1178 sec
0.2219 0.2103 0.2054 0.1973 0.1943 0.1955 0.1989 0.2061 0.2107 0.2180 0.2253 0.2328 0.2385 0.2444 0.2516 0.2566 

[TRAIN] Epoch[1](6141/114412); Loss: 0.155060; Backpropagation: 0.2958 sec; Batch: 2.1065 sec
0.1878 0.1736 0.1675 0.1556 0.1511 0.1473 0.1464 0.1465 0.1471 0.1493 0.1493 0.1518 0.1518 0.1519 0.1522 0.1516 

[TRAIN] Epoch[1](6142/114412); Loss: 0.170565; Backpropagation: 0.2980 sec; Batch: 2.1298 sec
0.2100 0.1991 0.1859 0.1748 0.1688 0.1657 0.1627 0.1599 0.1585 0.1590 0.1580 0.1594 0.1617 0.1649 0.1686 0.1719 

[TRAIN] Epoch[1](6143/114412); Loss: 0.204217; Backpropagation: 0.2958 sec; Batch: 2.0907 sec
0.1950 0.1914 0.1966 0.1955 0.1958 0.1974 0.1990 0.2023 0.2018 0.2037 0.2071 0.2097 0.2129 0.2166 0.2195 0.2233 

[TRAIN] Epoch[1](6144/114412); Loss: 0.243962; Backpropagation: 0.2952 sec; Batch: 2.0815 sec
0.2228 0.2259 0.2334 0.2350 0.2366 0.2374 0.2369 0.2418 0.2453 0.2481 0.2509 0.2523 0.2539 0.2575 0.2611 0.2644 

[TRAIN] Epoch[1](6145/114412); Loss: 0.181760; Backpropagation: 0.2947 sec; Batch: 2.1793 sec
0.2037 0.1977 0.1874 0.1815 0.1759 0.1775 0.1750 0.1752 0.1758 0.1774 0.1790 0.1795 0.1802 0.1807 0.1804 0.1812 

[TRAIN] Epoch[1](6146/114412); Loss: 0.309286; Backpropagation: 0.2953 sec; Batch: 2.1222 sec
0.2549 0.2574 0.2711 0.2763 0.2843 0.2940 0.2995 0.3069 0.3138 0.3193 0.3254 0.3326 0.3407 0.3486 0.3577 0.3661 

[TRAIN] Epoch[1](6147/114412); Loss: 0.247818; Backpropagation: 0.2978 sec; Batch: 2.1343 sec
0.2592 0.2570 0.2479 0.2427 0.2338 0.2284 0.2276 0.2308 0.2329 0.2368 0.2439 0.2510 0.2590 0.2662 0.2721 0.2759 

[TRAIN] Epoch[1](6148/114412); Loss: 0.225455; Backpropagation: 0.2962 sec; Batch: 2.1217 sec
0.2296 0.2220 0.2055 0.2023 0.2011 0.2024 0.2049 0.2091 0.2147 0.2213 0.2291 0.2372 0.2448 0.2527 0.2613 0.2693 

[TRAIN] Epoch[1](6149/114412); Loss: 0.277204; Backpropagation: 0.2952 sec; Batch: 2.1208 sec
0.2546 0.2495 0.2477 0.2458 0.2474 0.2510 0.2587 0.2653 0.2745 0.2791 0.2877 0.2968 0.3066 0.3147 0.3238 0.3321 

[TRAIN] Epoch[1](6150/114412); Loss: 0.222416; Backpropagation: 0.2983 sec; Batch: 2.1279 sec
0.1907 0.1903 0.1969 0.1984 0.2002 0.2007 0.2086 0.2180 0.2271 0.2334 0.2391 0.2430 0.2479 0.2511 0.2554 0.2579 

[TRAIN] Epoch[1](6151/114412); Loss: 0.295865; Backpropagation: 0.2958 sec; Batch: 2.1221 sec
0.3037 0.2964 0.2815 0.2751 0.2688 0.2683 0.2714 0.2767 0.2840 0.2921 0.2992 0.3071 0.3148 0.3231 0.3312 0.3404 

[TRAIN] Epoch[1](6152/114412); Loss: 0.160318; Backpropagation: 0.2982 sec; Batch: 2.1351 sec
0.2222 0.2047 0.1763 0.1641 0.1537 0.1511 0.1476 0.1479 0.1471 0.1477 0.1482 0.1482 0.1500 0.1506 0.1523 0.1532 

[TRAIN] Epoch[1](6153/114412); Loss: 0.273532; Backpropagation: 0.2980 sec; Batch: 2.1222 sec
0.2361 0.2297 0.2307 0.2308 0.2339 0.2410 0.2484 0.2592 0.2692 0.2800 0.2918 0.3024 0.3140 0.3252 0.3369 0.3473 

[TRAIN] Epoch[1](6154/114412); Loss: 0.234976; Backpropagation: 0.2951 sec; Batch: 2.0816 sec
0.2311 0.2225 0.2168 0.2118 0.2147 0.2185 0.2206 0.2255 0.2291 0.2333 0.2391 0.2470 0.2548 0.2612 0.2652 0.2683 

[TRAIN] Epoch[1](6155/114412); Loss: 0.342658; Backpropagation: 0.2958 sec; Batch: 2.1219 sec
0.2418 0.2465 0.2690 0.2760 0.2895 0.3017 0.3160 0.3324 0.3487 0.3647 0.3796 0.3936 0.4086 0.4231 0.4384 0.4529 

[TRAIN] Epoch[1](6156/114412); Loss: 0.284201; Backpropagation: 0.2959 sec; Batch: 2.1213 sec
0.2403 0.2524 0.2562 0.2598 0.2672 0.2722 0.2749 0.2784 0.2821 0.2897 0.2962 0.3032 0.3087 0.3154 0.3213 0.3293 

[TRAIN] Epoch[1](6157/114412); Loss: 0.195348; Backpropagation: 0.2979 sec; Batch: 2.1445 sec
0.1723 0.1708 0.1698 0.1689 0.1702 0.1734 0.1788 0.1872 0.1933 0.2004 0.2077 0.2150 0.2208 0.2266 0.2329 0.2375 

[TRAIN] Epoch[1](6158/114412); Loss: 0.156959; Backpropagation: 0.2975 sec; Batch: 2.1101 sec
0.1724 0.1622 0.1596 0.1522 0.1464 0.1484 0.1476 0.1503 0.1529 0.1538 0.1554 0.1576 0.1601 0.1611 0.1642 0.1672 

[TRAIN] Epoch[1](6159/114412); Loss: 0.175593; Backpropagation: 0.3008 sec; Batch: 2.1042 sec
0.2455 0.2280 0.2048 0.1876 0.1746 0.1675 0.1634 0.1613 0.1585 0.1573 0.1569 0.1574 0.1584 0.1602 0.1628 0.1654 

[TRAIN] Epoch[1](6160/114412); Loss: 0.277585; Backpropagation: 0.2964 sec; Batch: 2.1239 sec
0.2291 0.2251 0.2356 0.2367 0.2460 0.2526 0.2620 0.2711 0.2799 0.2885 0.2988 0.3069 0.3157 0.3242 0.3309 0.3383 

[TRAIN] Epoch[1](6161/114412); Loss: 0.269390; Backpropagation: 0.2952 sec; Batch: 2.1243 sec
0.2180 0.2123 0.2144 0.2128 0.2183 0.2289 0.2401 0.2549 0.2697 0.2836 0.2970 0.3102 0.3223 0.3317 0.3424 0.3537 

[TRAIN] Epoch[1](6162/114412); Loss: 0.217293; Backpropagation: 0.2955 sec; Batch: 2.0994 sec
0.2105 0.2085 0.2030 0.2018 0.2006 0.2034 0.2031 0.2073 0.2116 0.2159 0.2221 0.2269 0.2316 0.2372 0.2428 0.2504 

[TRAIN] Epoch[1](6163/114412); Loss: 0.173931; Backpropagation: 0.2953 sec; Batch: 2.1246 sec
0.2160 0.2061 0.1909 0.1821 0.1726 0.1673 0.1633 0.1583 0.1563 0.1587 0.1615 0.1651 0.1693 0.1704 0.1719 0.1731 

[TRAIN] Epoch[1](6164/114412); Loss: 0.262298; Backpropagation: 0.2948 sec; Batch: 2.1184 sec
0.2121 0.2086 0.2142 0.2220 0.2307 0.2412 0.2510 0.2599 0.2676 0.2748 0.2817 0.2903 0.2981 0.3069 0.3152 0.3224 

[TRAIN] Epoch[1](6165/114412); Loss: 0.198382; Backpropagation: 0.2954 sec; Batch: 2.1295 sec
0.2053 0.1962 0.1893 0.1839 0.1819 0.1825 0.1846 0.1892 0.1928 0.1976 0.2016 0.2062 0.2101 0.2140 0.2177 0.2211 

[TRAIN] Epoch[1](6166/114412); Loss: 0.216029; Backpropagation: 0.2983 sec; Batch: 2.1221 sec
0.2189 0.2130 0.2030 0.1994 0.1934 0.1956 0.1953 0.1983 0.2050 0.2108 0.2169 0.2249 0.2327 0.2411 0.2501 0.2580 

[TRAIN] Epoch[1](6167/114412); Loss: 0.384479; Backpropagation: 0.2954 sec; Batch: 2.1220 sec
0.2630 0.2763 0.3036 0.3185 0.3361 0.3519 0.3660 0.3823 0.3966 0.4086 0.4237 0.4367 0.4512 0.4662 0.4791 0.4920 

[TRAIN] Epoch[1](6168/114412); Loss: 0.222372; Backpropagation: 0.2949 sec; Batch: 2.1198 sec
0.2589 0.2451 0.2324 0.2183 0.2119 0.2042 0.2009 0.2024 0.2045 0.2087 0.2141 0.2191 0.2248 0.2304 0.2374 0.2448 

[TRAIN] Epoch[1](6169/114412); Loss: 0.225894; Backpropagation: 0.2957 sec; Batch: 2.1224 sec
0.2400 0.2338 0.2238 0.2197 0.2174 0.2171 0.2168 0.2175 0.2204 0.2225 0.2254 0.2278 0.2313 0.2332 0.2336 0.2341 

[TRAIN] Epoch[1](6170/114412); Loss: 0.198317; Backpropagation: 0.2957 sec; Batch: 2.1253 sec
0.2146 0.2041 0.1952 0.1893 0.1838 0.1826 0.1824 0.1847 0.1877 0.1922 0.1976 0.2013 0.2067 0.2122 0.2167 0.2219 

[TRAIN] Epoch[1](6171/114412); Loss: 0.409171; Backpropagation: 0.2978 sec; Batch: 2.1392 sec
0.3823 0.3826 0.3800 0.3842 0.3840 0.3881 0.3914 0.3969 0.4023 0.4085 0.4164 0.4254 0.4342 0.4453 0.4568 0.4685 

[TRAIN] Epoch[1](6172/114412); Loss: 0.217359; Backpropagation: 0.2956 sec; Batch: 2.0993 sec
0.1826 0.1818 0.1832 0.1846 0.1886 0.1959 0.2041 0.2124 0.2193 0.2269 0.2334 0.2411 0.2468 0.2529 0.2586 0.2656 

[TRAIN] Epoch[1](6173/114412); Loss: 0.214920; Backpropagation: 0.2955 sec; Batch: 2.0922 sec
0.2250 0.2155 0.2035 0.1988 0.1976 0.2012 0.2013 0.2043 0.2072 0.2108 0.2158 0.2220 0.2263 0.2319 0.2368 0.2406 

[TRAIN] Epoch[1](6174/114412); Loss: 0.240007; Backpropagation: 0.3007 sec; Batch: 2.1263 sec
0.2302 0.2235 0.2264 0.2216 0.2175 0.2145 0.2157 0.2220 0.2294 0.2381 0.2461 0.2544 0.2627 0.2710 0.2793 0.2877 

[TRAIN] Epoch[1](6175/114412); Loss: 0.234530; Backpropagation: 0.2981 sec; Batch: 2.1232 sec
0.1811 0.1879 0.1998 0.2051 0.2122 0.2168 0.2242 0.2312 0.2379 0.2442 0.2513 0.2577 0.2650 0.2725 0.2792 0.2863 

[TRAIN] Epoch[1](6176/114412); Loss: 0.167072; Backpropagation: 0.2951 sec; Batch: 2.1436 sec
0.1918 0.1621 0.1496 0.1419 0.1349 0.1379 0.1393 0.1457 0.1520 0.1612 0.1706 0.1800 0.1891 0.1976 0.2057 0.2138 

[TRAIN] Epoch[1](6177/114412); Loss: 0.250470; Backpropagation: 0.3007 sec; Batch: 2.1502 sec
0.2288 0.2274 0.2273 0.2266 0.2262 0.2281 0.2319 0.2374 0.2438 0.2511 0.2591 0.2671 0.2758 0.2840 0.2924 0.3003 

[TRAIN] Epoch[1](6178/114412); Loss: 0.211206; Backpropagation: 0.2979 sec; Batch: 2.1429 sec
0.2487 0.2361 0.2255 0.2194 0.2113 0.2076 0.2007 0.1973 0.1952 0.1956 0.1972 0.2001 0.2044 0.2089 0.2140 0.2174 

[TRAIN] Epoch[1](6179/114412); Loss: 0.182396; Backpropagation: 0.3008 sec; Batch: 2.1179 sec
0.2158 0.2076 0.1955 0.1883 0.1807 0.1764 0.1736 0.1728 0.1715 0.1714 0.1717 0.1725 0.1745 0.1774 0.1823 0.1863 

[TRAIN] Epoch[1](6180/114412); Loss: 0.198881; Backpropagation: 0.2981 sec; Batch: 2.3260 sec
0.2030 0.1864 0.1918 0.1902 0.1883 0.1899 0.1895 0.1923 0.1943 0.1975 0.2007 0.2043 0.2081 0.2118 0.2152 0.2188 

[TRAIN] Epoch[1](6181/114412); Loss: 0.232310; Backpropagation: 0.2948 sec; Batch: 2.1212 sec
0.2494 0.2491 0.2409 0.2363 0.2326 0.2340 0.2302 0.2273 0.2267 0.2258 0.2260 0.2248 0.2252 0.2271 0.2293 0.2321 

[TRAIN] Epoch[1](6182/114412); Loss: 0.179916; Backpropagation: 0.2979 sec; Batch: 2.1183 sec
0.1848 0.1820 0.1837 0.1807 0.1770 0.1754 0.1740 0.1770 0.1772 0.1773 0.1785 0.1792 0.1796 0.1823 0.1836 0.1862 

[TRAIN] Epoch[1](6183/114412); Loss: 0.207319; Backpropagation: 0.2961 sec; Batch: 2.1262 sec
0.1943 0.1932 0.1910 0.1886 0.1923 0.1975 0.1999 0.2040 0.2068 0.2109 0.2142 0.2179 0.2207 0.2242 0.2281 0.2336 

[TRAIN] Epoch[1](6184/114412); Loss: 0.245253; Backpropagation: 0.2955 sec; Batch: 2.0932 sec
0.2638 0.2572 0.2516 0.2456 0.2408 0.2362 0.2344 0.2343 0.2334 0.2337 0.2360 0.2399 0.2450 0.2522 0.2570 0.2631 

[TRAIN] Epoch[1](6185/114412); Loss: 0.255087; Backpropagation: 0.2954 sec; Batch: 2.2340 sec
0.2203 0.2258 0.2277 0.2315 0.2370 0.2462 0.2500 0.2561 0.2591 0.2624 0.2671 0.2707 0.2743 0.2796 0.2845 0.2892 

[TRAIN] Epoch[1](6186/114412); Loss: 0.157059; Backpropagation: 0.2955 sec; Batch: 2.0860 sec
0.2109 0.1990 0.1827 0.1737 0.1667 0.1613 0.1558 0.1520 0.1472 0.1438 0.1396 0.1368 0.1361 0.1353 0.1359 0.1362 

[TRAIN] Epoch[1](6187/114412); Loss: 0.196586; Backpropagation: 0.3004 sec; Batch: 2.1243 sec
0.1828 0.1828 0.1889 0.1897 0.1892 0.1923 0.1940 0.1970 0.1977 0.1991 0.2018 0.2036 0.2045 0.2057 0.2071 0.2092 

[TRAIN] Epoch[1](6188/114412); Loss: 0.200794; Backpropagation: 0.2978 sec; Batch: 2.1255 sec
0.2298 0.2151 0.1932 0.1862 0.1815 0.1830 0.1858 0.1901 0.1935 0.1978 0.2012 0.2054 0.2082 0.2109 0.2141 0.2169 

[TRAIN] Epoch[1](6189/114412); Loss: 0.175265; Backpropagation: 0.3004 sec; Batch: 2.1282 sec
0.2107 0.2025 0.1847 0.1797 0.1740 0.1723 0.1694 0.1679 0.1665 0.1663 0.1670 0.1672 0.1676 0.1688 0.1693 0.1704 

[TRAIN] Epoch[1](6190/114412); Loss: 0.265610; Backpropagation: 0.3007 sec; Batch: 2.1343 sec
0.2498 0.2451 0.2446 0.2464 0.2486 0.2538 0.2559 0.2596 0.2645 0.2682 0.2731 0.2778 0.2827 0.2878 0.2930 0.2988 

[TRAIN] Epoch[1](6191/114412); Loss: 0.186908; Backpropagation: 0.3008 sec; Batch: 2.1267 sec
0.1489 0.1438 0.1567 0.1582 0.1630 0.1690 0.1758 0.1827 0.1884 0.1958 0.2029 0.2096 0.2152 0.2209 0.2265 0.2331 

[TRAIN] Epoch[1](6192/114412); Loss: 0.256792; Backpropagation: 0.3013 sec; Batch: 2.1121 sec
0.2202 0.2229 0.2312 0.2362 0.2378 0.2418 0.2442 0.2504 0.2571 0.2628 0.2680 0.2744 0.2807 0.2874 0.2938 0.2998 

[TRAIN] Epoch[1](6193/114412); Loss: 0.220587; Backpropagation: 0.2980 sec; Batch: 2.1220 sec
0.2533 0.2341 0.2249 0.2197 0.2139 0.2126 0.2110 0.2107 0.2105 0.2120 0.2140 0.2158 0.2190 0.2227 0.2254 0.2296 

[TRAIN] Epoch[1](6194/114412); Loss: 0.225180; Backpropagation: 0.2981 sec; Batch: 2.1257 sec
0.2303 0.2192 0.2180 0.2139 0.2141 0.2150 0.2151 0.2183 0.2205 0.2236 0.2261 0.2292 0.2330 0.2373 0.2420 0.2473 

[TRAIN] Epoch[1](6195/114412); Loss: 0.200286; Backpropagation: 0.2954 sec; Batch: 2.1184 sec
0.1924 0.1924 0.1988 0.1953 0.1941 0.1943 0.1925 0.1956 0.1960 0.1979 0.2009 0.2047 0.2074 0.2108 0.2142 0.2173 

[TRAIN] Epoch[1](6196/114412); Loss: 0.174641; Backpropagation: 0.2959 sec; Batch: 2.1089 sec
0.2196 0.2077 0.1960 0.1884 0.1787 0.1735 0.1681 0.1654 0.1625 0.1600 0.1605 0.1606 0.1622 0.1631 0.1639 0.1642 

[TRAIN] Epoch[1](6197/114412); Loss: 0.244259; Backpropagation: 0.2909 sec; Batch: 2.1196 sec
0.2343 0.2334 0.2345 0.2358 0.2373 0.2392 0.2388 0.2402 0.2425 0.2444 0.2468 0.2499 0.2521 0.2554 0.2598 0.2638 

[TRAIN] Epoch[1](6198/114412); Loss: 0.297788; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.3117 0.3027 0.2985 0.2967 0.2939 0.2944 0.2932 0.2932 0.2918 0.2932 0.2947 0.2966 0.2981 0.3005 0.3020 0.3034 

[TRAIN] Epoch[1](6199/114412); Loss: 0.211087; Backpropagation: 0.2913 sec; Batch: 2.1570 sec
0.2142 0.2030 0.2008 0.1982 0.1964 0.1964 0.1974 0.2005 0.2045 0.2082 0.2132 0.2177 0.2233 0.2288 0.2345 0.2403 

[TRAIN] Epoch[1](6200/114412); Loss: 0.192384; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.2231 0.2106 0.2009 0.1938 0.1860 0.1827 0.1809 0.1800 0.1826 0.1834 0.1855 0.1876 0.1898 0.1933 0.1970 0.2008 

[TRAIN] Epoch[1](6201/114412); Loss: 0.210558; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.2686 0.2551 0.2369 0.2246 0.2121 0.2054 0.1976 0.1951 0.1940 0.1931 0.1938 0.1940 0.1966 0.1989 0.2004 0.2029 

[TRAIN] Epoch[1](6202/114412); Loss: 0.321742; Backpropagation: 0.2906 sec; Batch: 2.1193 sec
0.2569 0.2600 0.2784 0.2818 0.2928 0.3014 0.3100 0.3189 0.3270 0.3342 0.3424 0.3514 0.3603 0.3683 0.3779 0.3863 

[TRAIN] Epoch[1](6203/114412); Loss: 0.236731; Backpropagation: 0.2910 sec; Batch: 2.1150 sec
0.2246 0.2272 0.2311 0.2326 0.2333 0.2348 0.2356 0.2358 0.2354 0.2365 0.2382 0.2396 0.2422 0.2447 0.2475 0.2486 

[TRAIN] Epoch[1](6204/114412); Loss: 0.311580; Backpropagation: 0.2912 sec; Batch: 2.0785 sec
0.3057 0.3056 0.3034 0.3019 0.2981 0.2976 0.2981 0.3008 0.3037 0.3074 0.3127 0.3174 0.3230 0.3301 0.3366 0.3433 

[TRAIN] Epoch[1](6205/114412); Loss: 0.239631; Backpropagation: 0.2907 sec; Batch: 2.1169 sec
0.2445 0.2443 0.2421 0.2383 0.2326 0.2304 0.2296 0.2301 0.2303 0.2328 0.2371 0.2407 0.2445 0.2479 0.2521 0.2567 

[TRAIN] Epoch[1](6206/114412); Loss: 0.168238; Backpropagation: 0.2929 sec; Batch: 2.1193 sec
0.2168 0.2056 0.1927 0.1838 0.1749 0.1686 0.1641 0.1614 0.1579 0.1552 0.1527 0.1516 0.1513 0.1511 0.1516 0.1523 

[TRAIN] Epoch[1](6207/114412); Loss: 0.161776; Backpropagation: 0.2919 sec; Batch: 2.1163 sec
0.2047 0.1881 0.1759 0.1636 0.1527 0.1519 0.1501 0.1516 0.1509 0.1511 0.1520 0.1538 0.1565 0.1592 0.1618 0.1644 

[TRAIN] Epoch[1](6208/114412); Loss: 0.180621; Backpropagation: 0.2905 sec; Batch: 2.0906 sec
0.2283 0.2109 0.1977 0.1908 0.1833 0.1779 0.1749 0.1730 0.1707 0.1683 0.1684 0.1683 0.1684 0.1688 0.1700 0.1703 

[TRAIN] Epoch[1](6209/114412); Loss: 0.173521; Backpropagation: 0.2957 sec; Batch: 2.1085 sec
0.2254 0.2151 0.1917 0.1808 0.1724 0.1685 0.1655 0.1642 0.1617 0.1606 0.1601 0.1597 0.1605 0.1617 0.1632 0.1651 

[TRAIN] Epoch[1](6210/114412); Loss: 0.221187; Backpropagation: 0.2931 sec; Batch: 2.1479 sec
0.2643 0.2509 0.2396 0.2314 0.2212 0.2181 0.2140 0.2139 0.2116 0.2099 0.2087 0.2083 0.2086 0.2101 0.2130 0.2153 

[TRAIN] Epoch[1](6211/114412); Loss: 0.206374; Backpropagation: 0.2909 sec; Batch: 2.1185 sec
0.2463 0.2264 0.2236 0.2152 0.2069 0.2045 0.2017 0.2000 0.1980 0.1977 0.1968 0.1967 0.1966 0.1965 0.1970 0.1980 

[TRAIN] Epoch[1](6212/114412); Loss: 0.244221; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.2270 0.2270 0.2258 0.2272 0.2276 0.2301 0.2329 0.2382 0.2444 0.2495 0.2545 0.2586 0.2622 0.2652 0.2675 0.2698 

[TRAIN] Epoch[1](6213/114412); Loss: 0.261551; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.2765 0.2760 0.2615 0.2574 0.2525 0.2500 0.2491 0.2499 0.2510 0.2535 0.2572 0.2611 0.2655 0.2700 0.2746 0.2790 

[TRAIN] Epoch[1](6214/114412); Loss: 0.232641; Backpropagation: 0.2933 sec; Batch: 2.1201 sec
0.2212 0.2169 0.2248 0.2225 0.2232 0.2237 0.2227 0.2245 0.2273 0.2308 0.2367 0.2418 0.2465 0.2500 0.2536 0.2561 

[TRAIN] Epoch[1](6215/114412); Loss: 0.261701; Backpropagation: 0.2930 sec; Batch: 2.1206 sec
0.2538 0.2459 0.2461 0.2456 0.2472 0.2511 0.2532 0.2558 0.2588 0.2611 0.2652 0.2702 0.2751 0.2801 0.2860 0.2918 

[TRAIN] Epoch[1](6216/114412); Loss: 0.208259; Backpropagation: 0.2957 sec; Batch: 2.1254 sec
0.2243 0.2218 0.2138 0.2088 0.2063 0.2072 0.2056 0.2070 0.2066 0.2056 0.2051 0.2046 0.2047 0.2038 0.2033 0.2036 

[TRAIN] Epoch[1](6217/114412); Loss: 0.149383; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.2071 0.1880 0.1757 0.1642 0.1553 0.1506 0.1437 0.1382 0.1344 0.1320 0.1313 0.1318 0.1328 0.1339 0.1350 0.1361 

[TRAIN] Epoch[1](6218/114412); Loss: 0.227157; Backpropagation: 0.2911 sec; Batch: 2.1106 sec
0.1932 0.1994 0.2069 0.2119 0.2142 0.2196 0.2236 0.2274 0.2306 0.2334 0.2373 0.2403 0.2442 0.2479 0.2509 0.2535 

[TRAIN] Epoch[1](6219/114412); Loss: 0.161367; Backpropagation: 0.2928 sec; Batch: 2.1197 sec
0.2155 0.1999 0.1913 0.1804 0.1685 0.1634 0.1578 0.1556 0.1521 0.1495 0.1468 0.1437 0.1410 0.1394 0.1389 0.1382 

[TRAIN] Epoch[1](6220/114412); Loss: 0.246460; Backpropagation: 0.2913 sec; Batch: 2.0785 sec
0.2264 0.2405 0.2375 0.2340 0.2343 0.2381 0.2395 0.2429 0.2450 0.2473 0.2503 0.2529 0.2566 0.2608 0.2660 0.2712 

[TRAIN] Epoch[1](6221/114412); Loss: 0.223783; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.2010 0.2033 0.2159 0.2165 0.2151 0.2171 0.2175 0.2177 0.2201 0.2233 0.2270 0.2321 0.2372 0.2412 0.2461 0.2496 

[TRAIN] Epoch[1](6222/114412); Loss: 0.278849; Backpropagation: 0.2909 sec; Batch: 2.1164 sec
0.2575 0.2532 0.2562 0.2569 0.2600 0.2642 0.2696 0.2761 0.2808 0.2855 0.2907 0.2943 0.2977 0.3018 0.3061 0.3109 

[TRAIN] Epoch[1](6223/114412); Loss: 0.247019; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.2550 0.2441 0.2415 0.2396 0.2372 0.2370 0.2378 0.2409 0.2440 0.2466 0.2492 0.2512 0.2535 0.2558 0.2581 0.2610 

[TRAIN] Epoch[1](6224/114412); Loss: 0.202480; Backpropagation: 0.2904 sec; Batch: 2.1130 sec
0.2198 0.2072 0.2052 0.2032 0.2003 0.1984 0.1968 0.1968 0.1976 0.1984 0.1994 0.2010 0.2024 0.2039 0.2044 0.2050 

[TRAIN] Epoch[1](6225/114412); Loss: 0.334440; Backpropagation: 0.2905 sec; Batch: 2.1138 sec
0.2809 0.2887 0.3040 0.3097 0.3164 0.3230 0.3286 0.3346 0.3406 0.3453 0.3511 0.3560 0.3609 0.3656 0.3701 0.3756 

[TRAIN] Epoch[1](6226/114412); Loss: 0.239446; Backpropagation: 0.2929 sec; Batch: 2.1197 sec
0.2069 0.2110 0.2175 0.2227 0.2287 0.2323 0.2355 0.2403 0.2434 0.2467 0.2494 0.2527 0.2565 0.2601 0.2625 0.2651 

[TRAIN] Epoch[1](6227/114412); Loss: 0.112091; Backpropagation: 0.2930 sec; Batch: 2.1179 sec
0.1630 0.1525 0.1379 0.1296 0.1208 0.1151 0.1097 0.1053 0.1027 0.0994 0.0969 0.0945 0.0933 0.0917 0.0913 0.0897 

[TRAIN] Epoch[1](6228/114412); Loss: 0.165523; Backpropagation: 0.2906 sec; Batch: 2.1026 sec
0.1866 0.1830 0.1822 0.1770 0.1700 0.1654 0.1612 0.1599 0.1591 0.1586 0.1579 0.1579 0.1576 0.1570 0.1571 0.1578 

[TRAIN] Epoch[1](6229/114412); Loss: 0.187890; Backpropagation: 0.2907 sec; Batch: 2.1145 sec
0.2144 0.2042 0.2036 0.2001 0.1968 0.1949 0.1894 0.1865 0.1843 0.1824 0.1805 0.1781 0.1764 0.1734 0.1713 0.1699 

[TRAIN] Epoch[1](6230/114412); Loss: 0.256192; Backpropagation: 0.2907 sec; Batch: 2.1135 sec
0.2398 0.2423 0.2501 0.2493 0.2480 0.2516 0.2518 0.2541 0.2563 0.2585 0.2602 0.2625 0.2653 0.2672 0.2697 0.2723 

[TRAIN] Epoch[1](6231/114412); Loss: 0.137105; Backpropagation: 0.2911 sec; Batch: 2.1266 sec
0.1990 0.1724 0.1615 0.1497 0.1385 0.1358 0.1323 0.1294 0.1267 0.1242 0.1224 0.1215 0.1204 0.1198 0.1198 0.1202 

[TRAIN] Epoch[1](6232/114412); Loss: 0.269140; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.2625 0.2651 0.2647 0.2649 0.2628 0.2624 0.2621 0.2640 0.2662 0.2684 0.2703 0.2723 0.2754 0.2786 0.2818 0.2847 

[TRAIN] Epoch[1](6233/114412); Loss: 0.202664; Backpropagation: 0.2904 sec; Batch: 2.1165 sec
0.2553 0.2383 0.2263 0.2160 0.2074 0.2024 0.1977 0.1932 0.1905 0.1880 0.1869 0.1874 0.1874 0.1883 0.1887 0.1888 

[TRAIN] Epoch[1](6234/114412); Loss: 0.237421; Backpropagation: 0.2931 sec; Batch: 2.1214 sec
0.2335 0.2357 0.2418 0.2434 0.2403 0.2381 0.2358 0.2359 0.2344 0.2336 0.2353 0.2363 0.2368 0.2382 0.2391 0.2404 

[TRAIN] Epoch[1](6235/114412); Loss: 0.190868; Backpropagation: 0.2936 sec; Batch: 2.1026 sec
0.2159 0.2101 0.2025 0.1994 0.1969 0.1940 0.1890 0.1872 0.1850 0.1837 0.1828 0.1819 0.1815 0.1811 0.1811 0.1818 

[TRAIN] Epoch[1](6236/114412); Loss: 0.275909; Backpropagation: 0.2948 sec; Batch: 2.1232 sec
0.2705 0.2680 0.2693 0.2703 0.2695 0.2717 0.2720 0.2732 0.2729 0.2742 0.2761 0.2786 0.2815 0.2852 0.2894 0.2920 

[TRAIN] Epoch[1](6237/114412); Loss: 0.179579; Backpropagation: 0.2952 sec; Batch: 2.1234 sec
0.2516 0.2345 0.2136 0.2000 0.1857 0.1800 0.1742 0.1711 0.1689 0.1653 0.1618 0.1588 0.1559 0.1532 0.1505 0.1481 

[TRAIN] Epoch[1](6238/114412); Loss: 0.227524; Backpropagation: 0.2957 sec; Batch: 2.0833 sec
0.2263 0.2278 0.2301 0.2295 0.2274 0.2260 0.2246 0.2257 0.2246 0.2253 0.2255 0.2273 0.2280 0.2291 0.2309 0.2324 

[TRAIN] Epoch[1](6239/114412); Loss: 0.170751; Backpropagation: 0.2939 sec; Batch: 2.0849 sec
0.1758 0.1712 0.1659 0.1632 0.1619 0.1646 0.1654 0.1682 0.1722 0.1738 0.1746 0.1757 0.1756 0.1747 0.1745 0.1746 

[TRAIN] Epoch[1](6240/114412); Loss: 0.173037; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1803 0.1769 0.1809 0.1799 0.1772 0.1744 0.1729 0.1725 0.1714 0.1713 0.1699 0.1684 0.1684 0.1681 0.1680 0.1682 

[TRAIN] Epoch[1](6241/114412); Loss: 0.212169; Backpropagation: 0.2914 sec; Batch: 2.1217 sec
0.2162 0.2121 0.2129 0.2096 0.2062 0.2052 0.2047 0.2056 0.2076 0.2095 0.2113 0.2136 0.2162 0.2187 0.2213 0.2240 

[TRAIN] Epoch[1](6242/114412); Loss: 0.140275; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.2053 0.1811 0.1665 0.1545 0.1435 0.1399 0.1354 0.1323 0.1302 0.1285 0.1255 0.1239 0.1222 0.1204 0.1187 0.1165 

[TRAIN] Epoch[1](6243/114412); Loss: 0.177863; Backpropagation: 0.2930 sec; Batch: 2.1211 sec
0.2087 0.2022 0.1946 0.1875 0.1815 0.1798 0.1747 0.1728 0.1714 0.1688 0.1683 0.1681 0.1671 0.1667 0.1671 0.1666 

[TRAIN] Epoch[1](6244/114412); Loss: 0.287880; Backpropagation: 0.2930 sec; Batch: 2.1233 sec
0.2856 0.2868 0.2898 0.2903 0.2889 0.2891 0.2883 0.2876 0.2870 0.2863 0.2866 0.2865 0.2872 0.2875 0.2883 0.2903 

[TRAIN] Epoch[1](6245/114412); Loss: 0.174087; Backpropagation: 0.2932 sec; Batch: 2.0815 sec
0.2346 0.2183 0.2082 0.2000 0.1902 0.1838 0.1753 0.1699 0.1635 0.1586 0.1557 0.1516 0.1482 0.1448 0.1424 0.1403 

[TRAIN] Epoch[1](6246/114412); Loss: 0.205179; Backpropagation: 0.2954 sec; Batch: 2.1201 sec
0.2085 0.2065 0.2079 0.2074 0.2047 0.2039 0.2008 0.2008 0.2011 0.2021 0.2035 0.2049 0.2062 0.2072 0.2083 0.2093 

[TRAIN] Epoch[1](6247/114412); Loss: 0.246260; Backpropagation: 0.2935 sec; Batch: 2.0994 sec
0.2472 0.2534 0.2477 0.2486 0.2451 0.2439 0.2422 0.2415 0.2429 0.2436 0.2448 0.2460 0.2472 0.2480 0.2487 0.2495 

[TRAIN] Epoch[1](6248/114412); Loss: 0.294644; Backpropagation: 0.2955 sec; Batch: 2.1439 sec
0.2919 0.2934 0.2968 0.2981 0.2973 0.2986 0.2972 0.2952 0.2940 0.2918 0.2906 0.2897 0.2905 0.2929 0.2966 0.2997 

[TRAIN] Epoch[1](6249/114412); Loss: 0.129597; Backpropagation: 0.2927 sec; Batch: 2.1168 sec
0.1882 0.1756 0.1655 0.1520 0.1423 0.1338 0.1244 0.1189 0.1155 0.1128 0.1107 0.1091 0.1077 0.1065 0.1056 0.1050 

[TRAIN] Epoch[1](6250/114412); Loss: 0.158170; Backpropagation: 0.2948 sec; Batch: 2.1778 sec
0.1541 0.1612 0.1689 0.1664 0.1606 0.1595 0.1567 0.1566 0.1560 0.1556 0.1559 0.1558 0.1556 0.1556 0.1557 0.1564 

[TRAIN] Epoch[1](6251/114412); Loss: 0.179218; Backpropagation: 0.2931 sec; Batch: 2.2950 sec
0.2356 0.2252 0.2113 0.2021 0.1930 0.1852 0.1780 0.1737 0.1694 0.1651 0.1614 0.1582 0.1555 0.1533 0.1511 0.1494 

[TRAIN] Epoch[1](6252/114412); Loss: 0.195417; Backpropagation: 0.2913 sec; Batch: 2.1073 sec
0.2194 0.2141 0.2129 0.2079 0.2035 0.1998 0.1951 0.1927 0.1903 0.1880 0.1865 0.1852 0.1836 0.1830 0.1828 0.1820 

[TRAIN] Epoch[1](6253/114412); Loss: 0.207808; Backpropagation: 0.2947 sec; Batch: 2.1517 sec
0.2369 0.2256 0.2161 0.2101 0.2051 0.2031 0.2016 0.2005 0.2009 0.2016 0.2023 0.2031 0.2038 0.2041 0.2046 0.2057 

[TRAIN] Epoch[1](6254/114412); Loss: 0.165253; Backpropagation: 0.2913 sec; Batch: 2.1115 sec
0.2299 0.2217 0.2019 0.1928 0.1822 0.1729 0.1654 0.1590 0.1532 0.1486 0.1446 0.1405 0.1372 0.1341 0.1315 0.1286 

[TRAIN] Epoch[1](6255/114412); Loss: 0.180960; Backpropagation: 0.2930 sec; Batch: 2.1385 sec
0.1959 0.1919 0.1906 0.1869 0.1836 0.1794 0.1778 0.1772 0.1764 0.1765 0.1765 0.1763 0.1762 0.1764 0.1767 0.1772 

[TRAIN] Epoch[1](6256/114412); Loss: 0.222176; Backpropagation: 0.2929 sec; Batch: 2.1203 sec
0.3063 0.2875 0.2714 0.2592 0.2455 0.2343 0.2236 0.2140 0.2076 0.2008 0.1953 0.1898 0.1847 0.1806 0.1780 0.1763 

[TRAIN] Epoch[1](6257/114412); Loss: 0.237691; Backpropagation: 0.2931 sec; Batch: 2.1010 sec
0.3069 0.2913 0.2813 0.2663 0.2560 0.2456 0.2364 0.2303 0.2261 0.2203 0.2166 0.2130 0.2098 0.2051 0.2011 0.1971 

[TRAIN] Epoch[1](6258/114412); Loss: 0.218796; Backpropagation: 0.2941 sec; Batch: 2.1287 sec
0.2150 0.2115 0.2117 0.2117 0.2088 0.2086 0.2109 0.2139 0.2167 0.2190 0.2217 0.2252 0.2281 0.2301 0.2326 0.2352 

[TRAIN] Epoch[1](6259/114412); Loss: 0.207689; Backpropagation: 0.2944 sec; Batch: 2.0815 sec
0.2349 0.2213 0.2211 0.2138 0.2098 0.2063 0.2041 0.2022 0.2000 0.1989 0.1988 0.2003 0.2019 0.2030 0.2034 0.2031 

[TRAIN] Epoch[1](6260/114412); Loss: 0.279632; Backpropagation: 0.2908 sec; Batch: 2.1179 sec
0.2579 0.2635 0.2731 0.2756 0.2790 0.2789 0.2790 0.2795 0.2798 0.2815 0.2829 0.2849 0.2868 0.2884 0.2909 0.2925 

[TRAIN] Epoch[1](6261/114412); Loss: 0.134918; Backpropagation: 0.2921 sec; Batch: 2.0801 sec
0.1705 0.1520 0.1443 0.1353 0.1298 0.1282 0.1279 0.1271 0.1280 0.1283 0.1290 0.1292 0.1310 0.1319 0.1328 0.1332 

[TRAIN] Epoch[1](6262/114412); Loss: 0.200433; Backpropagation: 0.2908 sec; Batch: 2.1201 sec
0.2298 0.2249 0.2146 0.2120 0.2055 0.2007 0.1956 0.1940 0.1927 0.1923 0.1916 0.1916 0.1910 0.1898 0.1899 0.1909 

[TRAIN] Epoch[1](6263/114412); Loss: 0.166124; Backpropagation: 0.2908 sec; Batch: 2.0769 sec
0.1634 0.1657 0.1671 0.1680 0.1654 0.1657 0.1649 0.1661 0.1672 0.1663 0.1662 0.1668 0.1665 0.1668 0.1665 0.1655 

[TRAIN] Epoch[1](6264/114412); Loss: 0.136360; Backpropagation: 0.2913 sec; Batch: 2.1229 sec
0.1659 0.1556 0.1527 0.1473 0.1422 0.1397 0.1351 0.1327 0.1332 0.1315 0.1287 0.1268 0.1249 0.1227 0.1215 0.1213 

[TRAIN] Epoch[1](6265/114412); Loss: 0.255635; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.2519 0.2515 0.2565 0.2574 0.2589 0.2576 0.2578 0.2575 0.2552 0.2544 0.2542 0.2545 0.2558 0.2554 0.2555 0.2561 

[TRAIN] Epoch[1](6266/114412); Loss: 0.109103; Backpropagation: 0.2918 sec; Batch: 2.1306 sec
0.1363 0.1316 0.1302 0.1173 0.1147 0.1117 0.1075 0.1050 0.1024 0.1006 0.0993 0.0984 0.0980 0.0978 0.0974 0.0975 

[TRAIN] Epoch[1](6267/114412); Loss: 0.151269; Backpropagation: 0.2909 sec; Batch: 2.1216 sec
0.2265 0.2085 0.1889 0.1716 0.1597 0.1471 0.1406 0.1384 0.1360 0.1343 0.1314 0.1296 0.1286 0.1276 0.1264 0.1252 

[TRAIN] Epoch[1](6268/114412); Loss: 0.150256; Backpropagation: 0.2933 sec; Batch: 2.1193 sec
0.2004 0.1851 0.1707 0.1624 0.1539 0.1483 0.1431 0.1408 0.1395 0.1387 0.1374 0.1372 0.1372 0.1367 0.1363 0.1364 

[TRAIN] Epoch[1](6269/114412); Loss: 0.234609; Backpropagation: 0.2929 sec; Batch: 2.1206 sec
0.2384 0.2364 0.2366 0.2363 0.2329 0.2312 0.2283 0.2283 0.2291 0.2303 0.2326 0.2347 0.2365 0.2389 0.2410 0.2422 

[TRAIN] Epoch[1](6270/114412); Loss: 0.138481; Backpropagation: 0.2932 sec; Batch: 2.1188 sec
0.1441 0.1423 0.1477 0.1468 0.1436 0.1415 0.1394 0.1382 0.1368 0.1360 0.1353 0.1346 0.1338 0.1328 0.1317 0.1311 

[TRAIN] Epoch[1](6271/114412); Loss: 0.259557; Backpropagation: 0.2918 sec; Batch: 2.1192 sec
0.2738 0.2638 0.2653 0.2615 0.2580 0.2545 0.2531 0.2540 0.2547 0.2555 0.2574 0.2583 0.2595 0.2602 0.2608 0.2626 

[TRAIN] Epoch[1](6272/114412); Loss: 0.145459; Backpropagation: 0.2909 sec; Batch: 2.1169 sec
0.2267 0.2053 0.1813 0.1680 0.1556 0.1509 0.1427 0.1379 0.1335 0.1284 0.1248 0.1212 0.1172 0.1141 0.1113 0.1086 

[TRAIN] Epoch[1](6273/114412); Loss: 0.231671; Backpropagation: 0.2909 sec; Batch: 2.1179 sec
0.2423 0.2421 0.2377 0.2354 0.2310 0.2292 0.2282 0.2294 0.2289 0.2279 0.2279 0.2278 0.2289 0.2301 0.2303 0.2297 

[TRAIN] Epoch[1](6274/114412); Loss: 0.187663; Backpropagation: 0.2912 sec; Batch: 2.1385 sec
0.2433 0.2220 0.2129 0.2029 0.1929 0.1880 0.1829 0.1809 0.1789 0.1774 0.1755 0.1735 0.1713 0.1695 0.1668 0.1642 

[TRAIN] Epoch[1](6275/114412); Loss: 0.171347; Backpropagation: 0.2929 sec; Batch: 2.0804 sec
0.2356 0.2330 0.2222 0.2034 0.1890 0.1802 0.1693 0.1630 0.1588 0.1536 0.1493 0.1445 0.1401 0.1364 0.1330 0.1302 

[TRAIN] Epoch[1](6276/114412); Loss: 0.168135; Backpropagation: 0.2915 sec; Batch: 2.0874 sec
0.2055 0.1946 0.1869 0.1806 0.1759 0.1707 0.1670 0.1633 0.1611 0.1588 0.1572 0.1566 0.1555 0.1537 0.1523 0.1505 

[TRAIN] Epoch[1](6277/114412); Loss: 0.169173; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.2143 0.1991 0.1977 0.1907 0.1820 0.1761 0.1696 0.1656 0.1616 0.1579 0.1551 0.1516 0.1491 0.1471 0.1455 0.1436 

[TRAIN] Epoch[1](6278/114412); Loss: 0.178768; Backpropagation: 0.2913 sec; Batch: 2.1213 sec
0.2428 0.2245 0.2094 0.1985 0.1879 0.1820 0.1767 0.1720 0.1688 0.1650 0.1621 0.1595 0.1567 0.1542 0.1515 0.1486 

[TRAIN] Epoch[1](6279/114412); Loss: 0.194842; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.2283 0.2218 0.2104 0.2041 0.2000 0.1983 0.1950 0.1920 0.1907 0.1886 0.1861 0.1843 0.1825 0.1802 0.1785 0.1766 

[TRAIN] Epoch[1](6280/114412); Loss: 0.141372; Backpropagation: 0.2912 sec; Batch: 2.1254 sec
0.2148 0.1971 0.1753 0.1608 0.1489 0.1452 0.1390 0.1350 0.1305 0.1258 0.1221 0.1191 0.1155 0.1132 0.1109 0.1088 

[TRAIN] Epoch[1](6281/114412); Loss: 0.174208; Backpropagation: 0.2919 sec; Batch: 2.0984 sec
0.2033 0.1908 0.1842 0.1795 0.1731 0.1721 0.1695 0.1703 0.1693 0.1673 0.1671 0.1669 0.1674 0.1685 0.1688 0.1692 

[TRAIN] Epoch[1](6282/114412); Loss: 0.136111; Backpropagation: 0.2951 sec; Batch: 2.1293 sec
0.1919 0.1710 0.1591 0.1482 0.1404 0.1373 0.1333 0.1308 0.1281 0.1258 0.1229 0.1207 0.1190 0.1177 0.1163 0.1152 

[TRAIN] Epoch[1](6283/114412); Loss: 0.190521; Backpropagation: 0.3010 sec; Batch: 2.1279 sec
0.2403 0.2285 0.2182 0.2099 0.2018 0.1962 0.1902 0.1863 0.1831 0.1801 0.1766 0.1731 0.1704 0.1673 0.1645 0.1618 

[TRAIN] Epoch[1](6284/114412); Loss: 0.219870; Backpropagation: 0.2981 sec; Batch: 2.1274 sec
0.2595 0.2505 0.2415 0.2381 0.2313 0.2271 0.2220 0.2161 0.2113 0.2073 0.2049 0.2030 0.2020 0.2019 0.2009 0.2004 

[TRAIN] Epoch[1](6285/114412); Loss: 0.160850; Backpropagation: 0.3009 sec; Batch: 2.0877 sec
0.2012 0.1855 0.1780 0.1712 0.1648 0.1623 0.1578 0.1548 0.1529 0.1517 0.1514 0.1506 0.1490 0.1482 0.1475 0.1467 

[TRAIN] Epoch[1](6286/114412); Loss: 0.212020; Backpropagation: 0.3004 sec; Batch: 2.1313 sec
0.2418 0.2373 0.2304 0.2247 0.2177 0.2125 0.2086 0.2064 0.2042 0.2027 0.2020 0.2013 0.2004 0.2002 0.2009 0.2013 

[TRAIN] Epoch[1](6287/114412); Loss: 0.270239; Backpropagation: 0.2981 sec; Batch: 2.0842 sec
0.2633 0.2615 0.2677 0.2669 0.2644 0.2658 0.2660 0.2694 0.2708 0.2716 0.2730 0.2737 0.2751 0.2767 0.2781 0.2796 

[TRAIN] Epoch[1](6288/114412); Loss: 0.125477; Backpropagation: 0.3027 sec; Batch: 2.0881 sec
0.1519 0.1392 0.1411 0.1385 0.1310 0.1281 0.1245 0.1227 0.1215 0.1196 0.1180 0.1166 0.1152 0.1140 0.1132 0.1125 

[TRAIN] Epoch[1](6289/114412); Loss: 0.278291; Backpropagation: 0.2982 sec; Batch: 2.1260 sec
0.2999 0.2940 0.2919 0.2878 0.2833 0.2809 0.2778 0.2748 0.2729 0.2719 0.2703 0.2697 0.2694 0.2695 0.2692 0.2694 

[TRAIN] Epoch[1](6290/114412); Loss: 0.186655; Backpropagation: 0.3010 sec; Batch: 2.0866 sec
0.2253 0.2142 0.2074 0.1993 0.1910 0.1886 0.1845 0.1836 0.1805 0.1771 0.1749 0.1737 0.1727 0.1721 0.1713 0.1705 

[TRAIN] Epoch[1](6291/114412); Loss: 0.242163; Backpropagation: 0.2980 sec; Batch: 2.1047 sec
0.2473 0.2400 0.2395 0.2413 0.2413 0.2432 0.2449 0.2451 0.2449 0.2431 0.2417 0.2401 0.2391 0.2392 0.2412 0.2427 

[TRAIN] Epoch[1](6292/114412); Loss: 0.212624; Backpropagation: 0.2911 sec; Batch: 2.0944 sec
0.2463 0.2373 0.2305 0.2240 0.2162 0.2110 0.2068 0.2053 0.2032 0.2018 0.2021 0.2021 0.2027 0.2033 0.2046 0.2049 

[TRAIN] Epoch[1](6293/114412); Loss: 0.167292; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.2466 0.2260 0.2011 0.1874 0.1706 0.1647 0.1581 0.1532 0.1512 0.1490 0.1475 0.1461 0.1449 0.1437 0.1433 0.1432 

[TRAIN] Epoch[1](6294/114412); Loss: 0.133284; Backpropagation: 0.2911 sec; Batch: 2.0816 sec
0.2304 0.2192 0.1880 0.1650 0.1467 0.1347 0.1279 0.1207 0.1155 0.1092 0.1040 0.1003 0.0965 0.0939 0.0915 0.0890 

[TRAIN] Epoch[1](6295/114412); Loss: 0.226775; Backpropagation: 0.2941 sec; Batch: 2.1239 sec
0.2209 0.2219 0.2215 0.2219 0.2205 0.2217 0.2220 0.2237 0.2260 0.2262 0.2267 0.2290 0.2311 0.2344 0.2388 0.2422 

[TRAIN] Epoch[1](6296/114412); Loss: 0.127978; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1663 0.1563 0.1497 0.1409 0.1342 0.1284 0.1241 0.1225 0.1209 0.1188 0.1169 0.1155 0.1145 0.1135 0.1130 0.1120 

[TRAIN] Epoch[1](6297/114412); Loss: 0.125191; Backpropagation: 0.2926 sec; Batch: 2.1199 sec
0.1648 0.1523 0.1442 0.1388 0.1287 0.1249 0.1212 0.1194 0.1167 0.1158 0.1149 0.1139 0.1127 0.1122 0.1116 0.1111 

[TRAIN] Epoch[1](6298/114412); Loss: 0.151893; Backpropagation: 0.2931 sec; Batch: 2.0836 sec
0.2298 0.2099 0.1936 0.1811 0.1677 0.1581 0.1491 0.1435 0.1376 0.1322 0.1282 0.1242 0.1218 0.1195 0.1178 0.1163 

[TRAIN] Epoch[1](6299/114412); Loss: 0.182563; Backpropagation: 0.2933 sec; Batch: 2.0802 sec
0.2130 0.2166 0.2071 0.2003 0.1932 0.1871 0.1817 0.1803 0.1774 0.1756 0.1734 0.1707 0.1674 0.1627 0.1589 0.1555 

[TRAIN] Epoch[1](6300/114412); Loss: 0.145867; Backpropagation: 0.2902 sec; Batch: 2.1166 sec
0.2013 0.1837 0.1728 0.1632 0.1529 0.1475 0.1434 0.1414 0.1389 0.1349 0.1310 0.1283 0.1262 0.1244 0.1227 0.1213 

[TRAIN] Epoch[1](6301/114412); Loss: 0.173038; Backpropagation: 0.2904 sec; Batch: 2.1163 sec
0.2344 0.2191 0.2009 0.1862 0.1750 0.1696 0.1682 0.1664 0.1635 0.1600 0.1582 0.1557 0.1547 0.1534 0.1523 0.1512 

[TRAIN] Epoch[1](6302/114412); Loss: 0.148771; Backpropagation: 0.2911 sec; Batch: 2.1231 sec
0.2039 0.1925 0.1817 0.1720 0.1617 0.1546 0.1490 0.1438 0.1387 0.1352 0.1319 0.1288 0.1260 0.1229 0.1201 0.1178 

[TRAIN] Epoch[1](6303/114412); Loss: 0.105716; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1486 0.1263 0.1265 0.1208 0.1115 0.1087 0.1034 0.1017 0.0988 0.0966 0.0955 0.0933 0.0914 0.0908 0.0891 0.0885 

[TRAIN] Epoch[1](6304/114412); Loss: 0.230986; Backpropagation: 0.2909 sec; Batch: 2.1184 sec
0.2343 0.2342 0.2352 0.2334 0.2309 0.2310 0.2294 0.2296 0.2299 0.2294 0.2289 0.2290 0.2292 0.2293 0.2307 0.2313 

[TRAIN] Epoch[1](6305/114412); Loss: 0.178522; Backpropagation: 0.2904 sec; Batch: 2.0809 sec
0.2177 0.2102 0.2056 0.2037 0.1956 0.1880 0.1806 0.1746 0.1691 0.1650 0.1619 0.1598 0.1583 0.1566 0.1554 0.1541 

[TRAIN] Epoch[1](6306/114412); Loss: 0.149202; Backpropagation: 0.2906 sec; Batch: 2.0854 sec
0.2190 0.2002 0.1853 0.1744 0.1631 0.1547 0.1467 0.1413 0.1364 0.1322 0.1288 0.1258 0.1233 0.1208 0.1186 0.1167 

[TRAIN] Epoch[1](6307/114412); Loss: 0.208213; Backpropagation: 0.2916 sec; Batch: 2.0796 sec
0.2363 0.2329 0.2215 0.2148 0.2080 0.2057 0.2031 0.2018 0.2006 0.1992 0.1994 0.2003 0.2015 0.2015 0.2018 0.2031 

[TRAIN] Epoch[1](6308/114412); Loss: 0.145576; Backpropagation: 0.2909 sec; Batch: 2.1156 sec
0.1776 0.1632 0.1565 0.1499 0.1439 0.1438 0.1400 0.1384 0.1382 0.1378 0.1375 0.1386 0.1394 0.1405 0.1420 0.1417 

[TRAIN] Epoch[1](6309/114412); Loss: 0.147264; Backpropagation: 0.2911 sec; Batch: 2.0792 sec
0.2341 0.2207 0.1998 0.1838 0.1673 0.1560 0.1454 0.1369 0.1289 0.1229 0.1183 0.1140 0.1103 0.1078 0.1060 0.1039 

[TRAIN] Epoch[1](6310/114412); Loss: 0.266955; Backpropagation: 0.2908 sec; Batch: 2.0940 sec
0.3161 0.3010 0.2940 0.2825 0.2735 0.2646 0.2575 0.2523 0.2502 0.2511 0.2522 0.2541 0.2551 0.2551 0.2555 0.2564 

[TRAIN] Epoch[1](6311/114412); Loss: 0.231880; Backpropagation: 0.2910 sec; Batch: 2.1189 sec
0.2359 0.2250 0.2344 0.2317 0.2295 0.2298 0.2297 0.2306 0.2308 0.2310 0.2316 0.2319 0.2327 0.2342 0.2349 0.2362 

[TRAIN] Epoch[1](6312/114412); Loss: 0.160053; Backpropagation: 0.2909 sec; Batch: 2.1181 sec
0.1788 0.1747 0.1704 0.1685 0.1630 0.1617 0.1604 0.1598 0.1580 0.1555 0.1529 0.1526 0.1520 0.1514 0.1510 0.1502 

[TRAIN] Epoch[1](6313/114412); Loss: 0.142968; Backpropagation: 0.2906 sec; Batch: 2.1170 sec
0.1879 0.1817 0.1784 0.1687 0.1598 0.1516 0.1430 0.1376 0.1331 0.1290 0.1262 0.1233 0.1204 0.1176 0.1151 0.1140 

[TRAIN] Epoch[1](6314/114412); Loss: 0.245503; Backpropagation: 0.2950 sec; Batch: 2.1267 sec
0.2519 0.2473 0.2497 0.2503 0.2474 0.2477 0.2455 0.2446 0.2433 0.2423 0.2417 0.2427 0.2438 0.2436 0.2431 0.2430 

[TRAIN] Epoch[1](6315/114412); Loss: 0.135979; Backpropagation: 0.2929 sec; Batch: 2.1189 sec
0.2139 0.1953 0.1724 0.1548 0.1421 0.1339 0.1265 0.1228 0.1199 0.1182 0.1165 0.1147 0.1126 0.1113 0.1105 0.1103 

[TRAIN] Epoch[1](6316/114412); Loss: 0.139376; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.1844 0.1714 0.1559 0.1487 0.1415 0.1370 0.1336 0.1319 0.1301 0.1288 0.1284 0.1280 0.1281 0.1279 0.1274 0.1270 

[TRAIN] Epoch[1](6317/114412); Loss: 0.246491; Backpropagation: 0.2903 sec; Batch: 2.1176 sec
0.3049 0.2905 0.2807 0.2713 0.2603 0.2521 0.2456 0.2399 0.2350 0.2307 0.2273 0.2241 0.2221 0.2207 0.2197 0.2189 

[TRAIN] Epoch[1](6318/114412); Loss: 0.171473; Backpropagation: 0.2907 sec; Batch: 2.1185 sec
0.2401 0.2244 0.2114 0.1973 0.1854 0.1774 0.1705 0.1645 0.1592 0.1550 0.1511 0.1476 0.1442 0.1411 0.1384 0.1360 

[TRAIN] Epoch[1](6319/114412); Loss: 0.212162; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.2386 0.2295 0.2252 0.2212 0.2135 0.2119 0.2091 0.2068 0.2053 0.2042 0.2036 0.2046 0.2044 0.2047 0.2056 0.2066 

[TRAIN] Epoch[1](6320/114412); Loss: 0.128844; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1942 0.1783 0.1656 0.1545 0.1400 0.1311 0.1247 0.1200 0.1161 0.1124 0.1094 0.1070 0.1044 0.1025 0.1014 0.0998 

[TRAIN] Epoch[1](6321/114412); Loss: 0.129954; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1787 0.1599 0.1510 0.1426 0.1365 0.1331 0.1287 0.1251 0.1217 0.1189 0.1166 0.1149 0.1136 0.1128 0.1127 0.1124 

[TRAIN] Epoch[1](6322/114412); Loss: 0.113315; Backpropagation: 0.2908 sec; Batch: 2.1238 sec
0.1949 0.1750 0.1551 0.1405 0.1259 0.1145 0.1066 0.1003 0.0960 0.0928 0.0900 0.0875 0.0855 0.0839 0.0827 0.0816 

[TRAIN] Epoch[1](6323/114412); Loss: 0.280102; Backpropagation: 0.2904 sec; Batch: 2.1181 sec
0.2955 0.3055 0.3004 0.2970 0.2894 0.2859 0.2799 0.2777 0.2757 0.2721 0.2702 0.2683 0.2662 0.2660 0.2656 0.2662 

[TRAIN] Epoch[1](6324/114412); Loss: 0.130267; Backpropagation: 0.2933 sec; Batch: 2.1175 sec
0.1533 0.1466 0.1398 0.1330 0.1285 0.1276 0.1262 0.1264 0.1262 0.1254 0.1245 0.1245 0.1252 0.1253 0.1258 0.1261 

[TRAIN] Epoch[1](6325/114412); Loss: 0.124826; Backpropagation: 0.2928 sec; Batch: 2.1160 sec
0.1939 0.1817 0.1606 0.1445 0.1308 0.1231 0.1175 0.1139 0.1108 0.1073 0.1057 0.1041 0.1025 0.1015 0.1001 0.0991 

[TRAIN] Epoch[1](6326/114412); Loss: 0.183333; Backpropagation: 0.2929 sec; Batch: 2.1042 sec
0.2190 0.2125 0.2038 0.1976 0.1916 0.1869 0.1825 0.1796 0.1778 0.1751 0.1728 0.1693 0.1673 0.1662 0.1657 0.1658 

[TRAIN] Epoch[1](6327/114412); Loss: 0.178831; Backpropagation: 0.2900 sec; Batch: 2.1162 sec
0.2748 0.2487 0.2279 0.2113 0.1953 0.1837 0.1731 0.1654 0.1589 0.1533 0.1492 0.1467 0.1450 0.1435 0.1426 0.1419 

[TRAIN] Epoch[1](6328/114412); Loss: 0.143063; Backpropagation: 0.2905 sec; Batch: 2.1143 sec
0.1782 0.1764 0.1723 0.1671 0.1577 0.1513 0.1459 0.1405 0.1345 0.1318 0.1289 0.1262 0.1232 0.1203 0.1181 0.1166 

[TRAIN] Epoch[1](6329/114412); Loss: 0.129675; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1764 0.1663 0.1525 0.1433 0.1365 0.1318 0.1280 0.1246 0.1213 0.1185 0.1162 0.1148 0.1136 0.1119 0.1104 0.1087 

[TRAIN] Epoch[1](6330/114412); Loss: 0.129592; Backpropagation: 0.2911 sec; Batch: 2.1425 sec
0.1880 0.1671 0.1544 0.1420 0.1347 0.1295 0.1253 0.1224 0.1198 0.1174 0.1151 0.1136 0.1121 0.1111 0.1106 0.1105 

[TRAIN] Epoch[1](6331/114412); Loss: 0.226140; Backpropagation: 0.2910 sec; Batch: 2.1145 sec
0.2397 0.2380 0.2424 0.2399 0.2366 0.2330 0.2290 0.2264 0.2232 0.2210 0.2191 0.2173 0.2155 0.2136 0.2119 0.2117 

[TRAIN] Epoch[1](6332/114412); Loss: 0.275133; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.2647 0.2667 0.2754 0.2786 0.2799 0.2814 0.2807 0.2795 0.2777 0.2751 0.2729 0.2724 0.2729 0.2739 0.2748 0.2754 

[TRAIN] Epoch[1](6333/114412); Loss: 0.210204; Backpropagation: 0.2916 sec; Batch: 2.1196 sec
0.2276 0.2228 0.2234 0.2208 0.2174 0.2145 0.2121 0.2104 0.2070 0.2037 0.2012 0.2000 0.1995 0.2000 0.2010 0.2019 

[TRAIN] Epoch[1](6334/114412); Loss: 0.148471; Backpropagation: 0.2908 sec; Batch: 2.0765 sec
0.1943 0.1899 0.1770 0.1716 0.1622 0.1557 0.1491 0.1454 0.1405 0.1365 0.1334 0.1303 0.1272 0.1237 0.1210 0.1177 

[TRAIN] Epoch[1](6335/114412); Loss: 0.199263; Backpropagation: 0.2912 sec; Batch: 2.1220 sec
0.2521 0.2414 0.2297 0.2193 0.2102 0.2031 0.1965 0.1921 0.1886 0.1857 0.1828 0.1801 0.1783 0.1770 0.1761 0.1752 

[TRAIN] Epoch[1](6336/114412); Loss: 0.222813; Backpropagation: 0.2913 sec; Batch: 2.1167 sec
0.2616 0.2513 0.2446 0.2353 0.2258 0.2211 0.2195 0.2194 0.2180 0.2169 0.2153 0.2112 0.2082 0.2062 0.2053 0.2052 

[TRAIN] Epoch[1](6337/114412); Loss: 0.270588; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.3196 0.3132 0.3019 0.2973 0.2874 0.2795 0.2724 0.2668 0.2628 0.2576 0.2541 0.2491 0.2450 0.2430 0.2408 0.2388 

[TRAIN] Epoch[1](6338/114412); Loss: 0.159772; Backpropagation: 0.2914 sec; Batch: 2.1160 sec
0.2026 0.1937 0.1833 0.1756 0.1667 0.1621 0.1569 0.1550 0.1518 0.1481 0.1462 0.1448 0.1435 0.1427 0.1421 0.1412 

[TRAIN] Epoch[1](6339/114412); Loss: 0.169637; Backpropagation: 0.2914 sec; Batch: 2.1145 sec
0.1948 0.1928 0.1885 0.1852 0.1788 0.1755 0.1725 0.1703 0.1664 0.1615 0.1587 0.1565 0.1553 0.1536 0.1522 0.1513 

[TRAIN] Epoch[1](6340/114412); Loss: 0.141403; Backpropagation: 0.2916 sec; Batch: 2.1295 sec
0.2108 0.2019 0.1881 0.1748 0.1591 0.1510 0.1397 0.1321 0.1271 0.1203 0.1165 0.1131 0.1100 0.1077 0.1060 0.1044 

[TRAIN] Epoch[1](6341/114412); Loss: 0.181831; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.2853 0.2639 0.2444 0.2250 0.2094 0.1930 0.1809 0.1711 0.1633 0.1559 0.1485 0.1427 0.1379 0.1331 0.1293 0.1256 

[TRAIN] Epoch[1](6342/114412); Loss: 0.190371; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.2242 0.2137 0.2103 0.2057 0.1976 0.1930 0.1884 0.1860 0.1826 0.1812 0.1798 0.1789 0.1774 0.1759 0.1757 0.1755 

[TRAIN] Epoch[1](6343/114412); Loss: 0.169984; Backpropagation: 0.2917 sec; Batch: 2.1184 sec
0.1848 0.1917 0.1892 0.1881 0.1837 0.1787 0.1731 0.1691 0.1667 0.1633 0.1601 0.1572 0.1550 0.1539 0.1531 0.1520 

[TRAIN] Epoch[1](6344/114412); Loss: 0.180067; Backpropagation: 0.2930 sec; Batch: 2.1190 sec
0.2392 0.2238 0.2110 0.2028 0.1920 0.1867 0.1795 0.1738 0.1692 0.1653 0.1619 0.1593 0.1574 0.1548 0.1529 0.1513 

[TRAIN] Epoch[1](6345/114412); Loss: 0.161375; Backpropagation: 0.2929 sec; Batch: 2.1175 sec
0.2128 0.2042 0.1915 0.1827 0.1757 0.1696 0.1627 0.1570 0.1522 0.1483 0.1449 0.1415 0.1384 0.1357 0.1333 0.1316 

[TRAIN] Epoch[1](6346/114412); Loss: 0.184006; Backpropagation: 0.2913 sec; Batch: 2.0787 sec
0.2150 0.2091 0.1988 0.1963 0.1916 0.1882 0.1852 0.1821 0.1793 0.1766 0.1743 0.1721 0.1700 0.1688 0.1684 0.1683 

[TRAIN] Epoch[1](6347/114412); Loss: 0.189512; Backpropagation: 0.2907 sec; Batch: 2.0776 sec
0.2338 0.2258 0.2152 0.2067 0.1985 0.1919 0.1857 0.1833 0.1816 0.1806 0.1781 0.1754 0.1725 0.1695 0.1674 0.1662 

[TRAIN] Epoch[1](6348/114412); Loss: 0.167946; Backpropagation: 0.2913 sec; Batch: 2.1191 sec
0.2499 0.2259 0.2141 0.1998 0.1835 0.1718 0.1619 0.1549 0.1499 0.1452 0.1423 0.1411 0.1384 0.1368 0.1358 0.1356 

[TRAIN] Epoch[1](6349/114412); Loss: 0.166292; Backpropagation: 0.2911 sec; Batch: 2.1206 sec
0.1938 0.1882 0.1854 0.1827 0.1779 0.1723 0.1661 0.1619 0.1590 0.1569 0.1550 0.1539 0.1531 0.1524 0.1515 0.1506 

[TRAIN] Epoch[1](6350/114412); Loss: 0.202592; Backpropagation: 0.2903 sec; Batch: 2.1248 sec
0.2004 0.2030 0.2100 0.2077 0.2050 0.2021 0.2007 0.2013 0.2012 0.2011 0.2017 0.2012 0.2014 0.2015 0.2013 0.2019 

[TRAIN] Epoch[1](6351/114412); Loss: 0.166104; Backpropagation: 0.2909 sec; Batch: 2.0770 sec
0.1951 0.1923 0.1870 0.1818 0.1759 0.1700 0.1646 0.1627 0.1603 0.1580 0.1553 0.1528 0.1512 0.1506 0.1500 0.1498 

[TRAIN] Epoch[1](6352/114412); Loss: 0.176581; Backpropagation: 0.2917 sec; Batch: 2.1182 sec
0.2006 0.1973 0.1897 0.1855 0.1821 0.1800 0.1767 0.1750 0.1722 0.1702 0.1684 0.1669 0.1661 0.1655 0.1649 0.1642 

[TRAIN] Epoch[1](6353/114412); Loss: 0.224423; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.2667 0.2586 0.2499 0.2426 0.2332 0.2269 0.2209 0.2166 0.2141 0.2131 0.2128 0.2108 0.2087 0.2072 0.2051 0.2038 

[TRAIN] Epoch[1](6354/114412); Loss: 0.137692; Backpropagation: 0.2928 sec; Batch: 2.0851 sec
0.2302 0.2053 0.1833 0.1680 0.1534 0.1412 0.1315 0.1247 0.1187 0.1145 0.1113 0.1083 0.1061 0.1044 0.1018 0.1004 

[TRAIN] Epoch[1](6355/114412); Loss: 0.207049; Backpropagation: 0.2911 sec; Batch: 2.0788 sec
0.2334 0.2271 0.2227 0.2187 0.2120 0.2108 0.2073 0.2048 0.2018 0.1988 0.1970 0.1953 0.1952 0.1957 0.1955 0.1967 

[TRAIN] Epoch[1](6356/114412); Loss: 0.233007; Backpropagation: 0.2917 sec; Batch: 2.0776 sec
0.2620 0.2615 0.2525 0.2476 0.2403 0.2365 0.2335 0.2318 0.2290 0.2256 0.2230 0.2199 0.2172 0.2155 0.2160 0.2164 

[TRAIN] Epoch[1](6357/114412); Loss: 0.134485; Backpropagation: 0.2909 sec; Batch: 2.1156 sec
0.1847 0.1774 0.1637 0.1558 0.1467 0.1393 0.1336 0.1295 0.1255 0.1223 0.1191 0.1163 0.1137 0.1107 0.1078 0.1056 

[TRAIN] Epoch[1](6358/114412); Loss: 0.175968; Backpropagation: 0.2911 sec; Batch: 2.1153 sec
0.2323 0.2233 0.2138 0.2044 0.1918 0.1819 0.1742 0.1688 0.1637 0.1593 0.1560 0.1529 0.1507 0.1490 0.1478 0.1457 

[TRAIN] Epoch[1](6359/114412); Loss: 0.143797; Backpropagation: 0.2914 sec; Batch: 2.1154 sec
0.2205 0.2018 0.1886 0.1772 0.1601 0.1513 0.1426 0.1356 0.1292 0.1246 0.1201 0.1159 0.1129 0.1095 0.1066 0.1043 

[TRAIN] Epoch[1](6360/114412); Loss: 0.153534; Backpropagation: 0.2912 sec; Batch: 2.1199 sec
0.2341 0.2185 0.1900 0.1770 0.1654 0.1568 0.1495 0.1439 0.1390 0.1355 0.1325 0.1296 0.1262 0.1228 0.1195 0.1162 

[TRAIN] Epoch[1](6361/114412); Loss: 0.156382; Backpropagation: 0.2929 sec; Batch: 2.1189 sec
0.1931 0.1870 0.1800 0.1729 0.1661 0.1609 0.1562 0.1529 0.1500 0.1466 0.1437 0.1412 0.1401 0.1391 0.1372 0.1352 

[TRAIN] Epoch[1](6362/114412); Loss: 0.135010; Backpropagation: 0.2909 sec; Batch: 2.1154 sec
0.2016 0.1885 0.1654 0.1532 0.1430 0.1386 0.1329 0.1287 0.1248 0.1216 0.1170 0.1133 0.1101 0.1084 0.1072 0.1059 

[TRAIN] Epoch[1](6363/114412); Loss: 0.157840; Backpropagation: 0.2909 sec; Batch: 2.1260 sec
0.2127 0.2049 0.1903 0.1842 0.1738 0.1671 0.1598 0.1543 0.1482 0.1439 0.1395 0.1357 0.1318 0.1285 0.1263 0.1244 

[TRAIN] Epoch[1](6364/114412); Loss: 0.223915; Backpropagation: 0.2917 sec; Batch: 2.1144 sec
0.2973 0.2837 0.2689 0.2585 0.2452 0.2351 0.2237 0.2168 0.2105 0.2046 0.2003 0.1958 0.1914 0.1872 0.1832 0.1802 

[TRAIN] Epoch[1](6365/114412); Loss: 0.160745; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.2094 0.2039 0.1953 0.1877 0.1801 0.1737 0.1652 0.1594 0.1525 0.1448 0.1404 0.1367 0.1335 0.1315 0.1299 0.1279 

[TRAIN] Epoch[1](6366/114412); Loss: 0.144349; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.1987 0.1941 0.1820 0.1730 0.1596 0.1520 0.1445 0.1386 0.1335 0.1291 0.1250 0.1214 0.1181 0.1158 0.1133 0.1108 

[TRAIN] Epoch[1](6367/114412); Loss: 0.113262; Backpropagation: 0.2916 sec; Batch: 2.1158 sec
0.1862 0.1644 0.1540 0.1385 0.1258 0.1170 0.1078 0.1004 0.0961 0.0935 0.0920 0.0904 0.0886 0.0871 0.0860 0.0847 

[TRAIN] Epoch[1](6368/114412); Loss: 0.255052; Backpropagation: 0.2910 sec; Batch: 2.1195 sec
0.3160 0.3100 0.2945 0.2886 0.2766 0.2665 0.2588 0.2534 0.2463 0.2386 0.2326 0.2271 0.2235 0.2199 0.2160 0.2126 

[TRAIN] Epoch[1](6369/114412); Loss: 0.138266; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.2163 0.1976 0.1793 0.1630 0.1483 0.1391 0.1316 0.1272 0.1227 0.1193 0.1163 0.1138 0.1117 0.1100 0.1086 0.1075 

[TRAIN] Epoch[1](6370/114412); Loss: 0.204996; Backpropagation: 0.2930 sec; Batch: 2.1156 sec
0.2578 0.2499 0.2368 0.2300 0.2215 0.2161 0.2091 0.2035 0.1983 0.1930 0.1883 0.1825 0.1782 0.1748 0.1713 0.1688 

[TRAIN] Epoch[1](6371/114412); Loss: 0.215965; Backpropagation: 0.2952 sec; Batch: 2.1211 sec
0.3005 0.2799 0.2640 0.2535 0.2394 0.2309 0.2193 0.2100 0.2021 0.1950 0.1884 0.1830 0.1779 0.1738 0.1703 0.1675 

[TRAIN] Epoch[1](6372/114412); Loss: 0.270690; Backpropagation: 0.2912 sec; Batch: 2.1240 sec
0.2989 0.2954 0.2963 0.2926 0.2853 0.2792 0.2728 0.2698 0.2660 0.2617 0.2591 0.2557 0.2538 0.2511 0.2481 0.2453 

[TRAIN] Epoch[1](6373/114412); Loss: 0.215194; Backpropagation: 0.2910 sec; Batch: 2.1196 sec
0.2763 0.2605 0.2450 0.2375 0.2269 0.2215 0.2145 0.2096 0.2044 0.1997 0.1961 0.1931 0.1906 0.1900 0.1891 0.1883 

[TRAIN] Epoch[1](6374/114412); Loss: 0.123726; Backpropagation: 0.2905 sec; Batch: 2.0764 sec
0.1575 0.1490 0.1478 0.1435 0.1349 0.1279 0.1229 0.1204 0.1178 0.1144 0.1115 0.1090 0.1078 0.1064 0.1049 0.1038 

[TRAIN] Epoch[1](6375/114412); Loss: 0.167660; Backpropagation: 0.2909 sec; Batch: 2.1164 sec
0.2687 0.2416 0.2170 0.1990 0.1796 0.1664 0.1586 0.1528 0.1479 0.1437 0.1403 0.1375 0.1354 0.1336 0.1314 0.1292 

[TRAIN] Epoch[1](6376/114412); Loss: 0.114769; Backpropagation: 0.2921 sec; Batch: 2.1188 sec
0.1738 0.1578 0.1481 0.1380 0.1267 0.1197 0.1130 0.1084 0.1034 0.0992 0.0960 0.0936 0.0916 0.0900 0.0891 0.0880 

[TRAIN] Epoch[1](6377/114412); Loss: 0.150971; Backpropagation: 0.2909 sec; Batch: 2.1116 sec
0.2016 0.1865 0.1764 0.1697 0.1629 0.1564 0.1507 0.1478 0.1440 0.1404 0.1370 0.1337 0.1309 0.1280 0.1255 0.1239 

[TRAIN] Epoch[1](6378/114412); Loss: 0.179732; Backpropagation: 0.2912 sec; Batch: 2.1153 sec
0.2420 0.2382 0.2188 0.2075 0.1933 0.1851 0.1768 0.1713 0.1666 0.1630 0.1598 0.1567 0.1530 0.1502 0.1480 0.1455 

[TRAIN] Epoch[1](6379/114412); Loss: 0.111927; Backpropagation: 0.2916 sec; Batch: 2.1138 sec
0.1723 0.1648 0.1524 0.1400 0.1275 0.1180 0.1097 0.1039 0.0995 0.0951 0.0910 0.0882 0.0852 0.0829 0.0807 0.0797 

[TRAIN] Epoch[1](6380/114412); Loss: 0.118586; Backpropagation: 0.2930 sec; Batch: 2.1193 sec
0.2151 0.1924 0.1649 0.1494 0.1349 0.1243 0.1146 0.1069 0.1000 0.0952 0.0910 0.0868 0.0840 0.0810 0.0794 0.0775 

[TRAIN] Epoch[1](6381/114412); Loss: 0.183465; Backpropagation: 0.2911 sec; Batch: 2.1154 sec
0.2447 0.2326 0.2165 0.2045 0.1948 0.1880 0.1828 0.1782 0.1740 0.1700 0.1662 0.1626 0.1593 0.1567 0.1537 0.1509 

[TRAIN] Epoch[1](6382/114412); Loss: 0.161917; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1846 0.1832 0.1823 0.1779 0.1711 0.1657 0.1618 0.1594 0.1568 0.1546 0.1522 0.1507 0.1491 0.1476 0.1471 0.1466 

[TRAIN] Epoch[1](6383/114412); Loss: 0.130087; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.2003 0.1836 0.1647 0.1549 0.1449 0.1378 0.1291 0.1221 0.1169 0.1122 0.1086 0.1052 0.1035 0.1015 0.0992 0.0971 

[TRAIN] Epoch[1](6384/114412); Loss: 0.124971; Backpropagation: 0.2907 sec; Batch: 2.0809 sec
0.1843 0.1729 0.1625 0.1501 0.1368 0.1280 0.1216 0.1179 0.1129 0.1099 0.1070 0.1041 0.1020 0.0991 0.0963 0.0941 

[TRAIN] Epoch[1](6385/114412); Loss: 0.188095; Backpropagation: 0.2930 sec; Batch: 2.1127 sec
0.1944 0.1944 0.2016 0.2023 0.1990 0.1974 0.1938 0.1909 0.1870 0.1840 0.1814 0.1800 0.1786 0.1765 0.1747 0.1735 

[TRAIN] Epoch[1](6386/114412); Loss: 0.187884; Backpropagation: 0.2917 sec; Batch: 2.0785 sec
0.2447 0.2392 0.2325 0.2230 0.2093 0.1978 0.1881 0.1813 0.1750 0.1703 0.1663 0.1622 0.1587 0.1553 0.1523 0.1502 

[TRAIN] Epoch[1](6387/114412); Loss: 0.167064; Backpropagation: 0.2929 sec; Batch: 2.1196 sec
0.2471 0.2299 0.2096 0.1950 0.1819 0.1719 0.1638 0.1580 0.1533 0.1496 0.1463 0.1423 0.1374 0.1324 0.1287 0.1257 

[TRAIN] Epoch[1](6388/114412); Loss: 0.188621; Backpropagation: 0.2912 sec; Batch: 2.1146 sec
0.2535 0.2418 0.2226 0.2137 0.2013 0.1939 0.1857 0.1804 0.1761 0.1727 0.1695 0.1663 0.1631 0.1610 0.1592 0.1572 

[TRAIN] Epoch[1](6389/114412); Loss: 0.134687; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.1615 0.1602 0.1595 0.1522 0.1446 0.1380 0.1338 0.1314 0.1285 0.1273 0.1241 0.1213 0.1196 0.1184 0.1175 0.1169 

[TRAIN] Epoch[1](6390/114412); Loss: 0.120837; Backpropagation: 0.2927 sec; Batch: 2.1192 sec
0.1872 0.1702 0.1587 0.1462 0.1363 0.1280 0.1201 0.1120 0.1049 0.1010 0.0983 0.0970 0.0957 0.0938 0.0925 0.0913 

[TRAIN] Epoch[1](6391/114412); Loss: 0.116959; Backpropagation: 0.2909 sec; Batch: 2.1161 sec
0.1666 0.1549 0.1533 0.1446 0.1336 0.1271 0.1199 0.1141 0.1072 0.1016 0.0981 0.0947 0.0916 0.0896 0.0877 0.0867 

[TRAIN] Epoch[1](6392/114412); Loss: 0.153684; Backpropagation: 0.2914 sec; Batch: 2.1141 sec
0.2176 0.2068 0.1987 0.1897 0.1740 0.1618 0.1528 0.1449 0.1391 0.1356 0.1317 0.1277 0.1244 0.1211 0.1178 0.1151 

[TRAIN] Epoch[1](6393/114412); Loss: 0.124490; Backpropagation: 0.2914 sec; Batch: 2.1180 sec
0.1910 0.1677 0.1520 0.1396 0.1315 0.1254 0.1208 0.1172 0.1150 0.1115 0.1087 0.1062 0.1042 0.1024 0.1004 0.0983 

[TRAIN] Epoch[1](6394/114412); Loss: 0.171371; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.2308 0.2199 0.2098 0.2031 0.1930 0.1847 0.1749 0.1674 0.1613 0.1556 0.1505 0.1458 0.1415 0.1375 0.1348 0.1316 

[TRAIN] Epoch[1](6395/114412); Loss: 0.187167; Backpropagation: 0.2933 sec; Batch: 2.1193 sec
0.2800 0.2601 0.2444 0.2312 0.2139 0.1995 0.1856 0.1748 0.1661 0.1600 0.1548 0.1508 0.1474 0.1443 0.1423 0.1395 

[TRAIN] Epoch[1](6396/114412); Loss: 0.207892; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.2757 0.2621 0.2437 0.2355 0.2213 0.2144 0.2068 0.2013 0.1962 0.1910 0.1862 0.1826 0.1800 0.1779 0.1764 0.1750 

[TRAIN] Epoch[1](6397/114412); Loss: 0.175979; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.2260 0.2200 0.2065 0.1973 0.1893 0.1812 0.1753 0.1713 0.1667 0.1633 0.1601 0.1564 0.1546 0.1518 0.1488 0.1472 

[TRAIN] Epoch[1](6398/114412); Loss: 0.117953; Backpropagation: 0.2976 sec; Batch: 2.1318 sec
0.1817 0.1666 0.1554 0.1422 0.1281 0.1199 0.1125 0.1083 0.1054 0.1018 0.0990 0.0963 0.0946 0.0933 0.0917 0.0903 

[TRAIN] Epoch[1](6399/114412); Loss: 0.146570; Backpropagation: 0.2926 sec; Batch: 2.1170 sec
0.1926 0.1792 0.1658 0.1615 0.1559 0.1506 0.1470 0.1439 0.1408 0.1373 0.1346 0.1318 0.1290 0.1264 0.1251 0.1236 

[TRAIN] Epoch[1](6400/114412); Loss: 0.106568; Backpropagation: 0.2914 sec; Batch: 2.1157 sec
0.2295 0.1957 0.1653 0.1422 0.1210 0.1074 0.0970 0.0886 0.0829 0.0775 0.0730 0.0703 0.0677 0.0649 0.0620 0.0601 

[TRAIN] Epoch[1](6401/114412); Loss: 0.133587; Backpropagation: 0.2914 sec; Batch: 2.1185 sec
0.1880 0.1868 0.1743 0.1626 0.1479 0.1401 0.1322 0.1266 0.1215 0.1172 0.1136 0.1102 0.1070 0.1047 0.1032 0.1015 

[TRAIN] Epoch[1](6402/114412); Loss: 0.213087; Backpropagation: 0.2929 sec; Batch: 2.1146 sec
0.2170 0.2094 0.2114 0.2114 0.2111 0.2120 0.2119 0.2125 0.2121 0.2121 0.2133 0.2143 0.2146 0.2149 0.2155 0.2156 

[TRAIN] Epoch[1](6403/114412); Loss: 0.168902; Backpropagation: 0.2915 sec; Batch: 2.1165 sec
0.2164 0.2110 0.2012 0.1924 0.1823 0.1753 0.1679 0.1628 0.1575 0.1537 0.1510 0.1501 0.1479 0.1456 0.1443 0.1429 

[TRAIN] Epoch[1](6404/114412); Loss: 0.188123; Backpropagation: 0.2906 sec; Batch: 2.1166 sec
0.2679 0.2664 0.2469 0.2329 0.2126 0.1971 0.1844 0.1759 0.1708 0.1664 0.1604 0.1548 0.1499 0.1451 0.1409 0.1374 

[TRAIN] Epoch[1](6405/114412); Loss: 0.135943; Backpropagation: 0.2908 sec; Batch: 2.1137 sec
0.1835 0.1781 0.1715 0.1634 0.1532 0.1458 0.1364 0.1317 0.1266 0.1212 0.1175 0.1139 0.1114 0.1091 0.1070 0.1048 

[TRAIN] Epoch[1](6406/114412); Loss: 0.181503; Backpropagation: 0.2914 sec; Batch: 2.1148 sec
0.2317 0.2246 0.2097 0.2022 0.1931 0.1884 0.1820 0.1759 0.1710 0.1666 0.1638 0.1617 0.1596 0.1590 0.1577 0.1570 

[TRAIN] Epoch[1](6407/114412); Loss: 0.111448; Backpropagation: 0.2911 sec; Batch: 2.1200 sec
0.1714 0.1535 0.1405 0.1317 0.1234 0.1181 0.1120 0.1073 0.1025 0.0983 0.0950 0.0912 0.0888 0.0860 0.0827 0.0809 

[TRAIN] Epoch[1](6408/114412); Loss: 0.157603; Backpropagation: 0.2911 sec; Batch: 2.1160 sec
0.2180 0.2022 0.1898 0.1818 0.1698 0.1633 0.1543 0.1490 0.1445 0.1411 0.1397 0.1380 0.1350 0.1333 0.1317 0.1300 

[TRAIN] Epoch[1](6409/114412); Loss: 0.147853; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.2022 0.1943 0.1842 0.1751 0.1638 0.1539 0.1463 0.1412 0.1367 0.1329 0.1295 0.1262 0.1233 0.1205 0.1183 0.1173 

[TRAIN] Epoch[1](6410/114412); Loss: 0.172264; Backpropagation: 0.2911 sec; Batch: 2.1187 sec
0.2892 0.2645 0.2312 0.2090 0.1914 0.1788 0.1676 0.1580 0.1495 0.1436 0.1392 0.1353 0.1305 0.1258 0.1227 0.1201 

[TRAIN] Epoch[1](6411/114412); Loss: 0.103370; Backpropagation: 0.2908 sec; Batch: 2.1226 sec
0.1822 0.1594 0.1414 0.1279 0.1161 0.1072 0.0984 0.0932 0.0884 0.0842 0.0809 0.0784 0.0767 0.0743 0.0732 0.0720 

[TRAIN] Epoch[1](6412/114412); Loss: 0.137109; Backpropagation: 0.2917 sec; Batch: 2.1261 sec
0.2216 0.1965 0.1806 0.1669 0.1518 0.1419 0.1334 0.1257 0.1209 0.1171 0.1124 0.1095 0.1066 0.1045 0.1030 0.1014 

[TRAIN] Epoch[1](6413/114412); Loss: 0.118213; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.1812 0.1638 0.1525 0.1396 0.1275 0.1196 0.1124 0.1088 0.1060 0.1024 0.1004 0.0981 0.0963 0.0951 0.0942 0.0935 

[TRAIN] Epoch[1](6414/114412); Loss: 0.196015; Backpropagation: 0.2930 sec; Batch: 2.1197 sec
0.2350 0.2279 0.2220 0.2149 0.2076 0.2018 0.1964 0.1917 0.1879 0.1848 0.1823 0.1794 0.1780 0.1763 0.1752 0.1750 

[TRAIN] Epoch[1](6415/114412); Loss: 0.124488; Backpropagation: 0.2914 sec; Batch: 2.1190 sec
0.1778 0.1631 0.1519 0.1441 0.1377 0.1311 0.1246 0.1199 0.1158 0.1114 0.1082 0.1051 0.1030 0.1010 0.0991 0.0980 

[TRAIN] Epoch[1](6416/114412); Loss: 0.182675; Backpropagation: 0.2919 sec; Batch: 2.1186 sec
0.2539 0.2429 0.2305 0.2196 0.2065 0.1955 0.1840 0.1766 0.1687 0.1638 0.1570 0.1516 0.1480 0.1441 0.1413 0.1388 

[TRAIN] Epoch[1](6417/114412); Loss: 0.131546; Backpropagation: 0.2914 sec; Batch: 2.0808 sec
0.2017 0.1876 0.1784 0.1657 0.1527 0.1402 0.1301 0.1221 0.1158 0.1117 0.1065 0.1034 0.1007 0.0981 0.0961 0.0941 

[TRAIN] Epoch[1](6418/114412); Loss: 0.258986; Backpropagation: 0.2913 sec; Batch: 2.1167 sec
0.3112 0.2971 0.2873 0.2834 0.2737 0.2666 0.2587 0.2533 0.2497 0.2468 0.2433 0.2396 0.2364 0.2341 0.2320 0.2306 

[TRAIN] Epoch[1](6419/114412); Loss: 0.118325; Backpropagation: 0.2907 sec; Batch: 2.0770 sec
0.1717 0.1706 0.1528 0.1371 0.1246 0.1174 0.1127 0.1099 0.1078 0.1043 0.1026 0.1003 0.0982 0.0963 0.0942 0.0927 

[TRAIN] Epoch[1](6420/114412); Loss: 0.197683; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.2302 0.2190 0.2085 0.1987 0.1924 0.1917 0.1908 0.1911 0.1910 0.1911 0.1916 0.1924 0.1929 0.1933 0.1938 0.1945 

[TRAIN] Epoch[1](6421/114412); Loss: 0.167674; Backpropagation: 0.2917 sec; Batch: 2.0783 sec
0.2197 0.2033 0.1978 0.1862 0.1755 0.1685 0.1628 0.1585 0.1563 0.1539 0.1528 0.1519 0.1508 0.1492 0.1483 0.1475 

[TRAIN] Epoch[1](6422/114412); Loss: 0.161835; Backpropagation: 0.2905 sec; Batch: 2.1172 sec
0.2300 0.2269 0.2106 0.2029 0.1881 0.1756 0.1643 0.1581 0.1514 0.1443 0.1380 0.1309 0.1249 0.1192 0.1140 0.1102 

[TRAIN] Epoch[1](6423/114412); Loss: 0.123749; Backpropagation: 0.2913 sec; Batch: 2.1167 sec
0.1719 0.1588 0.1528 0.1430 0.1339 0.1281 0.1226 0.1186 0.1157 0.1122 0.1087 0.1064 0.1038 0.1021 0.1011 0.1002 

[TRAIN] Epoch[1](6424/114412); Loss: 0.166374; Backpropagation: 0.2914 sec; Batch: 2.0780 sec
0.2067 0.1992 0.1950 0.1908 0.1824 0.1760 0.1684 0.1625 0.1575 0.1535 0.1506 0.1478 0.1452 0.1436 0.1419 0.1409 

[TRAIN] Epoch[1](6425/114412); Loss: 0.124691; Backpropagation: 0.2911 sec; Batch: 2.0786 sec
0.1895 0.1696 0.1539 0.1460 0.1353 0.1287 0.1223 0.1182 0.1137 0.1093 0.1065 0.1046 0.1026 0.1001 0.0983 0.0965 

[TRAIN] Epoch[1](6426/114412); Loss: 0.157219; Backpropagation: 0.2909 sec; Batch: 2.1253 sec
0.2201 0.2083 0.2003 0.1930 0.1818 0.1727 0.1633 0.1539 0.1461 0.1399 0.1330 0.1278 0.1240 0.1200 0.1169 0.1146 

[TRAIN] Epoch[1](6427/114412); Loss: 0.207757; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.3031 0.2862 0.2614 0.2473 0.2268 0.2150 0.2030 0.1945 0.1888 0.1824 0.1777 0.1736 0.1698 0.1675 0.1645 0.1628 

[TRAIN] Epoch[1](6428/114412); Loss: 0.117124; Backpropagation: 0.2918 sec; Batch: 2.0785 sec
0.1745 0.1608 0.1531 0.1431 0.1304 0.1211 0.1131 0.1086 0.1028 0.0995 0.0970 0.0957 0.0946 0.0938 0.0933 0.0928 

[TRAIN] Epoch[1](6429/114412); Loss: 0.115862; Backpropagation: 0.2904 sec; Batch: 2.1023 sec
0.1871 0.1767 0.1558 0.1428 0.1312 0.1239 0.1153 0.1080 0.1019 0.0963 0.0932 0.0894 0.0868 0.0843 0.0817 0.0794 

[TRAIN] Epoch[1](6430/114412); Loss: 0.174822; Backpropagation: 0.2910 sec; Batch: 2.0771 sec
0.2301 0.2150 0.2061 0.1918 0.1804 0.1722 0.1661 0.1626 0.1597 0.1587 0.1587 0.1589 0.1586 0.1586 0.1591 0.1606 

[TRAIN] Epoch[1](6431/114412); Loss: 0.140869; Backpropagation: 0.2916 sec; Batch: 2.1150 sec
0.2155 0.1982 0.1824 0.1687 0.1549 0.1468 0.1378 0.1332 0.1269 0.1212 0.1177 0.1149 0.1126 0.1102 0.1076 0.1052 

[TRAIN] Epoch[1](6432/114412); Loss: 0.142436; Backpropagation: 0.2935 sec; Batch: 2.1192 sec
0.2091 0.2020 0.1842 0.1719 0.1582 0.1485 0.1414 0.1351 0.1289 0.1241 0.1205 0.1165 0.1136 0.1107 0.1086 0.1057 

[TRAIN] Epoch[1](6433/114412); Loss: 0.149506; Backpropagation: 0.2912 sec; Batch: 2.1193 sec
0.1723 0.1770 0.1756 0.1725 0.1634 0.1576 0.1516 0.1481 0.1437 0.1400 0.1378 0.1352 0.1329 0.1302 0.1281 0.1263 

[TRAIN] Epoch[1](6434/114412); Loss: 0.101570; Backpropagation: 0.2931 sec; Batch: 2.1192 sec
0.1916 0.1676 0.1386 0.1225 0.1093 0.1003 0.0938 0.0900 0.0859 0.0829 0.0795 0.0768 0.0742 0.0720 0.0708 0.0694 

[TRAIN] Epoch[1](6435/114412); Loss: 0.134631; Backpropagation: 0.2914 sec; Batch: 2.1166 sec
0.2232 0.2006 0.1809 0.1639 0.1484 0.1369 0.1284 0.1218 0.1163 0.1113 0.1082 0.1057 0.1040 0.1026 0.1013 0.1006 

[TRAIN] Epoch[1](6436/114412); Loss: 0.162602; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.2374 0.2193 0.2002 0.1881 0.1761 0.1698 0.1616 0.1544 0.1489 0.1441 0.1405 0.1366 0.1337 0.1318 0.1302 0.1290 

[TRAIN] Epoch[1](6437/114412); Loss: 0.183747; Backpropagation: 0.2910 sec; Batch: 2.1245 sec
0.2271 0.2198 0.2208 0.2124 0.2013 0.1921 0.1846 0.1793 0.1736 0.1685 0.1654 0.1629 0.1607 0.1594 0.1574 0.1547 

[TRAIN] Epoch[1](6438/114412); Loss: 0.128221; Backpropagation: 0.2906 sec; Batch: 2.1136 sec
0.1850 0.1744 0.1601 0.1497 0.1386 0.1314 0.1253 0.1212 0.1176 0.1144 0.1113 0.1086 0.1062 0.1042 0.1024 0.1009 

[TRAIN] Epoch[1](6439/114412); Loss: 0.170949; Backpropagation: 0.2905 sec; Batch: 2.1128 sec
0.2262 0.2140 0.2015 0.1921 0.1817 0.1749 0.1698 0.1653 0.1610 0.1574 0.1550 0.1524 0.1499 0.1470 0.1447 0.1422 

[TRAIN] Epoch[1](6440/114412); Loss: 0.139876; Backpropagation: 0.2911 sec; Batch: 2.1146 sec
0.1991 0.1878 0.1728 0.1623 0.1495 0.1421 0.1357 0.1315 0.1288 0.1257 0.1232 0.1203 0.1181 0.1160 0.1135 0.1117 

[TRAIN] Epoch[1](6441/114412); Loss: 0.186336; Backpropagation: 0.2926 sec; Batch: 2.1186 sec
0.2058 0.2018 0.2011 0.1993 0.1929 0.1909 0.1868 0.1850 0.1822 0.1805 0.1785 0.1770 0.1754 0.1746 0.1749 0.1747 

[TRAIN] Epoch[1](6442/114412); Loss: 0.146869; Backpropagation: 0.2914 sec; Batch: 2.0843 sec
0.2684 0.2468 0.2158 0.1945 0.1718 0.1535 0.1389 0.1267 0.1163 0.1113 0.1082 0.1053 0.1022 0.0991 0.0965 0.0945 

[TRAIN] Epoch[1](6443/114412); Loss: 0.164879; Backpropagation: 0.2911 sec; Batch: 2.0776 sec
0.1768 0.1698 0.1709 0.1670 0.1657 0.1642 0.1616 0.1604 0.1600 0.1605 0.1603 0.1615 0.1628 0.1639 0.1654 0.1675 

[TRAIN] Epoch[1](6444/114412); Loss: 0.149782; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1891 0.1935 0.1838 0.1785 0.1706 0.1625 0.1531 0.1482 0.1423 0.1371 0.1327 0.1280 0.1233 0.1199 0.1176 0.1163 

[TRAIN] Epoch[1](6445/114412); Loss: 0.121196; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.2388 0.2124 0.1903 0.1685 0.1505 0.1322 0.1166 0.1015 0.0916 0.0839 0.0798 0.0781 0.0764 0.0742 0.0728 0.0715 

[TRAIN] Epoch[1](6446/114412); Loss: 0.116187; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.1817 0.1670 0.1595 0.1460 0.1334 0.1223 0.1139 0.1079 0.1025 0.0975 0.0932 0.0902 0.0880 0.0863 0.0854 0.0842 

[TRAIN] Epoch[1](6447/114412); Loss: 0.166985; Backpropagation: 0.2910 sec; Batch: 2.1191 sec
0.2499 0.2280 0.2081 0.1916 0.1782 0.1711 0.1644 0.1592 0.1536 0.1489 0.1443 0.1406 0.1379 0.1343 0.1316 0.1301 

[TRAIN] Epoch[1](6448/114412); Loss: 0.133680; Backpropagation: 0.2911 sec; Batch: 2.1244 sec
0.2330 0.2028 0.1823 0.1622 0.1449 0.1332 0.1245 0.1191 0.1137 0.1102 0.1073 0.1046 0.1024 0.1006 0.0994 0.0987 

[TRAIN] Epoch[1](6449/114412); Loss: 0.180795; Backpropagation: 0.2908 sec; Batch: 2.1135 sec
0.2133 0.2073 0.2077 0.2029 0.1957 0.1900 0.1843 0.1785 0.1731 0.1690 0.1652 0.1627 0.1618 0.1610 0.1603 0.1600 

[TRAIN] Epoch[1](6450/114412); Loss: 0.140010; Backpropagation: 0.2905 sec; Batch: 2.1182 sec
0.1696 0.1622 0.1600 0.1536 0.1479 0.1428 0.1393 0.1368 0.1335 0.1314 0.1297 0.1289 0.1282 0.1270 0.1252 0.1239 

[TRAIN] Epoch[1](6451/114412); Loss: 0.107763; Backpropagation: 0.2913 sec; Batch: 2.1248 sec
0.2230 0.1896 0.1607 0.1346 0.1159 0.1024 0.0924 0.0864 0.0836 0.0812 0.0793 0.0776 0.0758 0.0748 0.0738 0.0730 

[TRAIN] Epoch[1](6452/114412); Loss: 0.161899; Backpropagation: 0.2911 sec; Batch: 2.1148 sec
0.2053 0.1950 0.1911 0.1894 0.1805 0.1749 0.1662 0.1594 0.1538 0.1496 0.1459 0.1421 0.1383 0.1352 0.1328 0.1308 

[TRAIN] Epoch[1](6453/114412); Loss: 0.200684; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.2429 0.2379 0.2342 0.2245 0.2138 0.2069 0.2024 0.1990 0.1945 0.1894 0.1849 0.1816 0.1788 0.1761 0.1733 0.1707 

[TRAIN] Epoch[1](6454/114412); Loss: 0.148933; Backpropagation: 0.2928 sec; Batch: 2.1185 sec
0.2116 0.1954 0.1804 0.1700 0.1576 0.1499 0.1453 0.1421 0.1385 0.1356 0.1329 0.1297 0.1268 0.1245 0.1221 0.1205 

[TRAIN] Epoch[1](6455/114412); Loss: 0.130424; Backpropagation: 0.2910 sec; Batch: 2.1202 sec
0.2100 0.1931 0.1732 0.1589 0.1454 0.1355 0.1263 0.1189 0.1134 0.1088 0.1045 0.1028 0.1015 0.0999 0.0981 0.0965 

[TRAIN] Epoch[1](6456/114412); Loss: 0.160203; Backpropagation: 0.2909 sec; Batch: 2.1179 sec
0.2309 0.2134 0.1894 0.1785 0.1687 0.1637 0.1585 0.1554 0.1499 0.1449 0.1416 0.1375 0.1348 0.1337 0.1317 0.1305 

[TRAIN] Epoch[1](6457/114412); Loss: 0.127159; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.2700 0.2430 0.2069 0.1791 0.1534 0.1336 0.1150 0.1026 0.0928 0.0851 0.0814 0.0791 0.0765 0.0739 0.0722 0.0701 

[TRAIN] Epoch[1](6458/114412); Loss: 0.123443; Backpropagation: 0.2908 sec; Batch: 2.1162 sec
0.2158 0.1914 0.1692 0.1530 0.1356 0.1239 0.1144 0.1081 0.1035 0.1002 0.0970 0.0952 0.0938 0.0924 0.0912 0.0903 

[TRAIN] Epoch[1](6459/114412); Loss: 0.114835; Backpropagation: 0.2933 sec; Batch: 2.1207 sec
0.2103 0.1856 0.1577 0.1431 0.1261 0.1151 0.1070 0.1018 0.0969 0.0931 0.0896 0.0868 0.0843 0.0819 0.0799 0.0780 

[TRAIN] Epoch[1](6460/114412); Loss: 0.166076; Backpropagation: 0.2915 sec; Batch: 2.1187 sec
0.2162 0.2067 0.1880 0.1801 0.1693 0.1646 0.1600 0.1569 0.1555 0.1542 0.1530 0.1516 0.1509 0.1504 0.1500 0.1499 

[TRAIN] Epoch[1](6461/114412); Loss: 0.121831; Backpropagation: 0.2907 sec; Batch: 2.1146 sec
0.1888 0.1734 0.1583 0.1419 0.1303 0.1227 0.1160 0.1120 0.1079 0.1055 0.1030 0.1008 0.0988 0.0978 0.0966 0.0953 

[TRAIN] Epoch[1](6462/114412); Loss: 0.117600; Backpropagation: 0.2914 sec; Batch: 2.1136 sec
0.1989 0.1863 0.1633 0.1488 0.1340 0.1228 0.1138 0.1052 0.1001 0.0961 0.0922 0.0883 0.0853 0.0841 0.0820 0.0805 

[TRAIN] Epoch[1](6463/114412); Loss: 0.143750; Backpropagation: 0.2931 sec; Batch: 2.1193 sec
0.2204 0.2047 0.1855 0.1696 0.1518 0.1430 0.1360 0.1315 0.1281 0.1249 0.1225 0.1201 0.1180 0.1161 0.1148 0.1133 

[TRAIN] Epoch[1](6464/114412); Loss: 0.140774; Backpropagation: 0.2916 sec; Batch: 2.1202 sec
0.1887 0.1769 0.1701 0.1623 0.1535 0.1473 0.1420 0.1384 0.1342 0.1301 0.1253 0.1217 0.1186 0.1165 0.1144 0.1124 

[TRAIN] Epoch[1](6465/114412); Loss: 0.115467; Backpropagation: 0.2914 sec; Batch: 2.0774 sec
0.1809 0.1639 0.1490 0.1377 0.1263 0.1175 0.1099 0.1051 0.1010 0.0975 0.0950 0.0942 0.0936 0.0928 0.0919 0.0912 

[TRAIN] Epoch[1](6466/114412); Loss: 0.212516; Backpropagation: 0.2906 sec; Batch: 2.1220 sec
0.2526 0.2566 0.2508 0.2494 0.2398 0.2310 0.2208 0.2125 0.2041 0.1974 0.1917 0.1864 0.1822 0.1787 0.1750 0.1713 

[TRAIN] Epoch[1](6467/114412); Loss: 0.109955; Backpropagation: 0.2911 sec; Batch: 2.1374 sec
0.1523 0.1480 0.1482 0.1434 0.1317 0.1224 0.1137 0.1071 0.1000 0.0944 0.0894 0.0854 0.0831 0.0813 0.0801 0.0788 

[TRAIN] Epoch[1](6468/114412); Loss: 0.205737; Backpropagation: 0.2909 sec; Batch: 2.1547 sec
0.2809 0.2744 0.2547 0.2434 0.2263 0.2131 0.2026 0.1960 0.1892 0.1834 0.1791 0.1769 0.1744 0.1688 0.1654 0.1632 

[TRAIN] Epoch[1](6469/114412); Loss: 0.120720; Backpropagation: 0.2929 sec; Batch: 2.1903 sec
0.1767 0.1665 0.1591 0.1460 0.1341 0.1259 0.1170 0.1123 0.1083 0.1049 0.1021 0.0995 0.0971 0.0956 0.0937 0.0928 

[TRAIN] Epoch[1](6470/114412); Loss: 0.137232; Backpropagation: 0.2909 sec; Batch: 2.1573 sec
0.2090 0.1907 0.1769 0.1640 0.1507 0.1419 0.1353 0.1305 0.1261 0.1213 0.1163 0.1122 0.1089 0.1064 0.1039 0.1016 

[TRAIN] Epoch[1](6471/114412); Loss: 0.120320; Backpropagation: 0.2909 sec; Batch: 2.1143 sec
0.2032 0.1841 0.1639 0.1485 0.1333 0.1228 0.1152 0.1101 0.1052 0.1004 0.0967 0.0929 0.0904 0.0880 0.0862 0.0845 

[TRAIN] Epoch[1](6472/114412); Loss: 0.125478; Backpropagation: 0.2904 sec; Batch: 2.0808 sec
0.2076 0.1929 0.1717 0.1570 0.1411 0.1313 0.1227 0.1168 0.1113 0.1054 0.1005 0.0963 0.0930 0.0893 0.0865 0.0842 

[TRAIN] Epoch[1](6473/114412); Loss: 0.169787; Backpropagation: 0.2910 sec; Batch: 2.0988 sec
0.2390 0.2228 0.2026 0.1924 0.1829 0.1757 0.1691 0.1639 0.1586 0.1544 0.1501 0.1461 0.1431 0.1405 0.1385 0.1370 

[TRAIN] Epoch[1](6474/114412); Loss: 0.139173; Backpropagation: 0.2908 sec; Batch: 2.1162 sec
0.1917 0.1837 0.1713 0.1646 0.1524 0.1462 0.1395 0.1353 0.1301 0.1255 0.1216 0.1175 0.1153 0.1130 0.1103 0.1085 

[TRAIN] Epoch[1](6475/114412); Loss: 0.105986; Backpropagation: 0.2907 sec; Batch: 2.1182 sec
0.1725 0.1600 0.1428 0.1329 0.1172 0.1085 0.1009 0.0959 0.0911 0.0884 0.0856 0.0833 0.0810 0.0791 0.0785 0.0780 

[TRAIN] Epoch[1](6476/114412); Loss: 0.132892; Backpropagation: 0.2906 sec; Batch: 2.1133 sec
0.2480 0.2245 0.1983 0.1754 0.1564 0.1396 0.1267 0.1152 0.1071 0.1003 0.0957 0.0922 0.0901 0.0877 0.0856 0.0835 

[TRAIN] Epoch[1](6477/114412); Loss: 0.140941; Backpropagation: 0.2912 sec; Batch: 2.1464 sec
0.2511 0.2131 0.1905 0.1687 0.1502 0.1360 0.1261 0.1216 0.1185 0.1159 0.1137 0.1121 0.1101 0.1094 0.1091 0.1089 

[TRAIN] Epoch[1](6478/114412); Loss: 0.194739; Backpropagation: 0.2907 sec; Batch: 2.1136 sec
0.2624 0.2576 0.2425 0.2322 0.2164 0.2052 0.1969 0.1898 0.1838 0.1777 0.1720 0.1658 0.1600 0.1552 0.1512 0.1470 

[TRAIN] Epoch[1](6479/114412); Loss: 0.156140; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.2178 0.2129 0.1986 0.1867 0.1731 0.1644 0.1556 0.1489 0.1423 0.1378 0.1333 0.1298 0.1273 0.1247 0.1230 0.1221 

[TRAIN] Epoch[1](6480/114412); Loss: 0.119843; Backpropagation: 0.2912 sec; Batch: 2.1126 sec
0.1895 0.1707 0.1534 0.1396 0.1259 0.1174 0.1124 0.1091 0.1066 0.1042 0.1016 0.0998 0.0984 0.0969 0.0961 0.0955 

[TRAIN] Epoch[1](6481/114412); Loss: 0.157178; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1883 0.1830 0.1769 0.1726 0.1678 0.1646 0.1598 0.1572 0.1549 0.1511 0.1483 0.1459 0.1413 0.1376 0.1345 0.1314 

[TRAIN] Epoch[1](6482/114412); Loss: 0.143807; Backpropagation: 0.2907 sec; Batch: 2.1158 sec
0.2125 0.1982 0.1817 0.1719 0.1596 0.1518 0.1430 0.1361 0.1305 0.1248 0.1214 0.1183 0.1157 0.1137 0.1118 0.1099 

[TRAIN] Epoch[1](6483/114412); Loss: 0.159925; Backpropagation: 0.2909 sec; Batch: 2.0776 sec
0.2284 0.2137 0.2027 0.1931 0.1780 0.1665 0.1572 0.1506 0.1444 0.1400 0.1368 0.1332 0.1310 0.1289 0.1274 0.1269 

[TRAIN] Epoch[1](6484/114412); Loss: 0.132381; Backpropagation: 0.2910 sec; Batch: 2.1297 sec
0.2165 0.1922 0.1679 0.1528 0.1399 0.1323 0.1262 0.1200 0.1160 0.1131 0.1110 0.1087 0.1073 0.1060 0.1046 0.1036 

[TRAIN] Epoch[1](6485/114412); Loss: 0.165564; Backpropagation: 0.2904 sec; Batch: 2.1170 sec
0.2160 0.2086 0.1961 0.1872 0.1767 0.1701 0.1613 0.1568 0.1540 0.1510 0.1497 0.1475 0.1461 0.1443 0.1424 0.1413 

[TRAIN] Epoch[1](6486/114412); Loss: 0.114077; Backpropagation: 0.2929 sec; Batch: 2.1158 sec
0.1644 0.1585 0.1503 0.1408 0.1286 0.1189 0.1120 0.1072 0.1033 0.0989 0.0961 0.0938 0.0912 0.0890 0.0869 0.0851 

[TRAIN] Epoch[1](6487/114412); Loss: 0.119698; Backpropagation: 0.2928 sec; Batch: 2.1220 sec
0.1744 0.1614 0.1508 0.1417 0.1312 0.1244 0.1180 0.1145 0.1100 0.1065 0.1028 0.0999 0.0975 0.0953 0.0939 0.0928 

[TRAIN] Epoch[1](6488/114412); Loss: 0.122902; Backpropagation: 0.2904 sec; Batch: 2.1188 sec
0.1826 0.1753 0.1656 0.1560 0.1442 0.1345 0.1240 0.1173 0.1115 0.1047 0.0998 0.0962 0.0926 0.0892 0.0872 0.0857 

[TRAIN] Epoch[1](6489/114412); Loss: 0.133683; Backpropagation: 0.2910 sec; Batch: 2.0972 sec
0.1981 0.1875 0.1732 0.1671 0.1534 0.1424 0.1322 0.1241 0.1176 0.1134 0.1103 0.1067 0.1051 0.1037 0.1029 0.1013 

[TRAIN] Epoch[1](6490/114412); Loss: 0.119922; Backpropagation: 0.2909 sec; Batch: 2.1140 sec
0.2101 0.1891 0.1623 0.1481 0.1334 0.1224 0.1139 0.1071 0.1020 0.0980 0.0944 0.0916 0.0894 0.0876 0.0856 0.0840 

[TRAIN] Epoch[1](6491/114412); Loss: 0.105868; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1451 0.1430 0.1379 0.1296 0.1169 0.1089 0.1021 0.0980 0.0948 0.0928 0.0906 0.0888 0.0877 0.0868 0.0858 0.0850 

[TRAIN] Epoch[1](6492/114412); Loss: 0.140921; Backpropagation: 0.2913 sec; Batch: 2.1127 sec
0.2169 0.2042 0.1830 0.1718 0.1563 0.1465 0.1374 0.1317 0.1258 0.1207 0.1162 0.1131 0.1105 0.1087 0.1066 0.1052 

[TRAIN] Epoch[1](6493/114412); Loss: 0.094296; Backpropagation: 0.2915 sec; Batch: 2.0771 sec
0.1453 0.1396 0.1272 0.1178 0.1071 0.0994 0.0926 0.0876 0.0826 0.0790 0.0759 0.0739 0.0721 0.0709 0.0695 0.0683 

[TRAIN] Epoch[1](6494/114412); Loss: 0.135405; Backpropagation: 0.2905 sec; Batch: 2.1257 sec
0.1939 0.1872 0.1766 0.1666 0.1530 0.1416 0.1328 0.1266 0.1218 0.1174 0.1140 0.1111 0.1087 0.1069 0.1051 0.1031 

[TRAIN] Epoch[1](6495/114412); Loss: 0.193460; Backpropagation: 0.2911 sec; Batch: 2.1134 sec
0.2560 0.2465 0.2328 0.2117 0.2071 0.2045 0.1988 0.1913 0.1857 0.1794 0.1736 0.1699 0.1650 0.1615 0.1577 0.1537 

[TRAIN] Epoch[1](6496/114412); Loss: 0.154895; Backpropagation: 0.2931 sec; Batch: 2.1157 sec
0.2417 0.2370 0.2145 0.2008 0.1788 0.1643 0.1508 0.1407 0.1336 0.1273 0.1234 0.1195 0.1158 0.1129 0.1104 0.1069 

[TRAIN] Epoch[1](6497/114412); Loss: 0.166045; Backpropagation: 0.2911 sec; Batch: 2.1154 sec
0.2576 0.2378 0.2133 0.1993 0.1830 0.1723 0.1629 0.1549 0.1484 0.1424 0.1381 0.1352 0.1323 0.1290 0.1264 0.1237 

[TRAIN] Epoch[1](6498/114412); Loss: 0.113491; Backpropagation: 0.2927 sec; Batch: 2.1240 sec
0.1818 0.1663 0.1543 0.1437 0.1295 0.1205 0.1107 0.1040 0.0989 0.0951 0.0910 0.0882 0.0858 0.0834 0.0819 0.0808 

[TRAIN] Epoch[1](6499/114412); Loss: 0.095875; Backpropagation: 0.2930 sec; Batch: 2.1211 sec
0.2011 0.1776 0.1425 0.1208 0.1038 0.0935 0.0830 0.0760 0.0726 0.0702 0.0684 0.0672 0.0660 0.0645 0.0638 0.0630 

[TRAIN] Epoch[1](6500/114412); Loss: 0.110013; Backpropagation: 0.2928 sec; Batch: 2.1168 sec
0.1586 0.1479 0.1410 0.1323 0.1229 0.1150 0.1090 0.1046 0.0997 0.0971 0.0942 0.0915 0.0897 0.0875 0.0854 0.0839 

[TRAIN] Epoch[1](6501/114412); Loss: 0.124517; Backpropagation: 0.2953 sec; Batch: 2.1211 sec
0.1769 0.1713 0.1612 0.1513 0.1403 0.1318 0.1235 0.1177 0.1121 0.1085 0.1052 0.1026 0.1001 0.0981 0.0964 0.0953 

[TRAIN] Epoch[1](6502/114412); Loss: 0.145515; Backpropagation: 0.2912 sec; Batch: 2.1206 sec
0.2377 0.2133 0.1933 0.1772 0.1608 0.1491 0.1391 0.1316 0.1254 0.1213 0.1184 0.1162 0.1137 0.1120 0.1107 0.1085 

[TRAIN] Epoch[1](6503/114412); Loss: 0.131129; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.2316 0.2164 0.1847 0.1685 0.1483 0.1345 0.1232 0.1159 0.1093 0.1037 0.1003 0.0975 0.0943 0.0919 0.0899 0.0882 

[TRAIN] Epoch[1](6504/114412); Loss: 0.183530; Backpropagation: 0.2910 sec; Batch: 2.1165 sec
0.2383 0.2321 0.2233 0.2170 0.2054 0.1969 0.1877 0.1806 0.1732 0.1670 0.1621 0.1579 0.1542 0.1504 0.1468 0.1435 

[TRAIN] Epoch[1](6505/114412); Loss: 0.103184; Backpropagation: 0.2949 sec; Batch: 2.0981 sec
0.1350 0.1361 0.1309 0.1270 0.1183 0.1100 0.1042 0.0989 0.0937 0.0906 0.0876 0.0857 0.0845 0.0840 0.0825 0.0819 

[TRAIN] Epoch[1](6506/114412); Loss: 0.115171; Backpropagation: 0.2915 sec; Batch: 2.1179 sec
0.1605 0.1573 0.1461 0.1397 0.1302 0.1226 0.1161 0.1107 0.1049 0.1008 0.0977 0.0949 0.0925 0.0909 0.0895 0.0885 

[TRAIN] Epoch[1](6507/114412); Loss: 0.146744; Backpropagation: 0.2902 sec; Batch: 2.1149 sec
0.2316 0.2169 0.1955 0.1803 0.1647 0.1544 0.1425 0.1352 0.1276 0.1218 0.1177 0.1147 0.1131 0.1116 0.1108 0.1097 

[TRAIN] Epoch[1](6508/114412); Loss: 0.141332; Backpropagation: 0.2903 sec; Batch: 2.1182 sec
0.2250 0.2109 0.1934 0.1813 0.1644 0.1517 0.1399 0.1302 0.1229 0.1178 0.1126 0.1078 0.1046 0.1021 0.0992 0.0975 

[TRAIN] Epoch[1](6509/114412); Loss: 0.134092; Backpropagation: 0.2904 sec; Batch: 2.1164 sec
0.1936 0.1867 0.1756 0.1680 0.1579 0.1466 0.1362 0.1284 0.1221 0.1149 0.1104 0.1075 0.1038 0.1006 0.0978 0.0955 

[TRAIN] Epoch[1](6510/114412); Loss: 0.109839; Backpropagation: 0.2911 sec; Batch: 2.1196 sec
0.1964 0.1746 0.1515 0.1353 0.1199 0.1098 0.1029 0.0986 0.0932 0.0890 0.0863 0.0841 0.0823 0.0796 0.0778 0.0762 

[TRAIN] Epoch[1](6511/114412); Loss: 0.182010; Backpropagation: 0.2908 sec; Batch: 2.1171 sec
0.2240 0.2152 0.2037 0.1985 0.1920 0.1870 0.1818 0.1778 0.1739 0.1709 0.1686 0.1668 0.1655 0.1640 0.1619 0.1606 

[TRAIN] Epoch[1](6512/114412); Loss: 0.162051; Backpropagation: 0.2910 sec; Batch: 2.0767 sec
0.2396 0.2250 0.2022 0.1906 0.1765 0.1662 0.1576 0.1509 0.1469 0.1434 0.1395 0.1370 0.1328 0.1305 0.1284 0.1256 

[TRAIN] Epoch[1](6513/114412); Loss: 0.157184; Backpropagation: 0.2907 sec; Batch: 2.1175 sec
0.2594 0.2440 0.2242 0.2108 0.1885 0.1726 0.1579 0.1447 0.1342 0.1265 0.1197 0.1138 0.1095 0.1063 0.1029 0.0999 

[TRAIN] Epoch[1](6514/114412); Loss: 0.142447; Backpropagation: 0.2910 sec; Batch: 2.1257 sec
0.2166 0.2036 0.1853 0.1682 0.1540 0.1431 0.1359 0.1318 0.1289 0.1243 0.1213 0.1175 0.1149 0.1128 0.1108 0.1100 

[TRAIN] Epoch[1](6515/114412); Loss: 0.161352; Backpropagation: 0.2912 sec; Batch: 2.1424 sec
0.2087 0.2044 0.2006 0.1954 0.1835 0.1735 0.1643 0.1564 0.1511 0.1459 0.1413 0.1383 0.1344 0.1304 0.1282 0.1251 

[TRAIN] Epoch[1](6516/114412); Loss: 0.119167; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1721 0.1655 0.1516 0.1431 0.1323 0.1236 0.1174 0.1130 0.1088 0.1046 0.1014 0.0986 0.0965 0.0942 0.0926 0.0915 

[TRAIN] Epoch[1](6517/114412); Loss: 0.095048; Backpropagation: 0.2913 sec; Batch: 2.1262 sec
0.1620 0.1372 0.1237 0.1103 0.1006 0.0943 0.0886 0.0853 0.0829 0.0805 0.0788 0.0771 0.0758 0.0751 0.0744 0.0740 

[TRAIN] Epoch[1](6518/114412); Loss: 0.181642; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.2628 0.2551 0.2390 0.2284 0.2110 0.1983 0.1846 0.1725 0.1628 0.1558 0.1498 0.1456 0.1409 0.1366 0.1335 0.1295 

[TRAIN] Epoch[1](6519/114412); Loss: 0.108274; Backpropagation: 0.2912 sec; Batch: 2.1288 sec
0.1730 0.1579 0.1368 0.1257 0.1157 0.1085 0.1039 0.1005 0.0967 0.0940 0.0910 0.0890 0.0868 0.0853 0.0843 0.0834 

[TRAIN] Epoch[1](6520/114412); Loss: 0.134071; Backpropagation: 0.2910 sec; Batch: 2.1134 sec
0.1877 0.1760 0.1668 0.1589 0.1475 0.1399 0.1334 0.1292 0.1247 0.1196 0.1161 0.1138 0.1110 0.1086 0.1067 0.1052 

[TRAIN] Epoch[1](6521/114412); Loss: 0.126373; Backpropagation: 0.2910 sec; Batch: 2.1055 sec
0.1797 0.1739 0.1665 0.1573 0.1435 0.1361 0.1272 0.1200 0.1153 0.1106 0.1054 0.1028 0.0998 0.0966 0.0946 0.0927 

[TRAIN] Epoch[1](6522/114412); Loss: 0.113188; Backpropagation: 0.2914 sec; Batch: 2.1187 sec
0.1801 0.1707 0.1554 0.1465 0.1318 0.1223 0.1123 0.1050 0.0988 0.0938 0.0894 0.0862 0.0839 0.0808 0.0783 0.0758 

[TRAIN] Epoch[1](6523/114412); Loss: 0.099234; Backpropagation: 0.2914 sec; Batch: 2.1329 sec
0.1618 0.1528 0.1266 0.1184 0.1095 0.1015 0.0949 0.0901 0.0863 0.0833 0.0812 0.0787 0.0769 0.0762 0.0751 0.0745 

[TRAIN] Epoch[1](6524/114412); Loss: 0.245297; Backpropagation: 0.2911 sec; Batch: 2.1286 sec
0.3000 0.2821 0.2806 0.2777 0.2644 0.2599 0.2520 0.2428 0.2346 0.2288 0.2250 0.2214 0.2181 0.2153 0.2124 0.2094 

[TRAIN] Epoch[1](6525/114412); Loss: 0.097774; Backpropagation: 0.2911 sec; Batch: 2.0942 sec
0.1680 0.1596 0.1309 0.1192 0.1060 0.0984 0.0919 0.0875 0.0831 0.0794 0.0770 0.0753 0.0732 0.0721 0.0716 0.0709 

[TRAIN] Epoch[1](6526/114412); Loss: 0.129714; Backpropagation: 0.2909 sec; Batch: 2.1185 sec
0.2033 0.1914 0.1785 0.1663 0.1540 0.1403 0.1282 0.1219 0.1144 0.1084 0.1028 0.0975 0.0950 0.0931 0.0910 0.0892 

[TRAIN] Epoch[1](6527/114412); Loss: 0.191353; Backpropagation: 0.2925 sec; Batch: 2.0792 sec
0.2570 0.2438 0.2274 0.2152 0.2042 0.1969 0.1912 0.1879 0.1833 0.1789 0.1734 0.1680 0.1634 0.1594 0.1568 0.1548 

[TRAIN] Epoch[1](6528/114412); Loss: 0.113263; Backpropagation: 0.2927 sec; Batch: 2.1187 sec
0.1705 0.1591 0.1465 0.1362 0.1243 0.1149 0.1086 0.1052 0.1012 0.0983 0.0956 0.0932 0.0913 0.0903 0.0889 0.0882 

[TRAIN] Epoch[1](6529/114412); Loss: 0.100034; Backpropagation: 0.2979 sec; Batch: 2.1249 sec
0.1558 0.1407 0.1343 0.1231 0.1123 0.1043 0.0971 0.0921 0.0875 0.0852 0.0828 0.0803 0.0783 0.0768 0.0755 0.0743 

[TRAIN] Epoch[1](6530/114412); Loss: 0.121034; Backpropagation: 0.2955 sec; Batch: 2.1234 sec
0.1740 0.1521 0.1451 0.1389 0.1288 0.1236 0.1178 0.1146 0.1112 0.1095 0.1069 0.1052 0.1040 0.1025 0.1015 0.1009 

[TRAIN] Epoch[1](6531/114412); Loss: 0.108893; Backpropagation: 0.2947 sec; Batch: 2.1197 sec
0.2098 0.1750 0.1480 0.1300 0.1135 0.1074 0.0995 0.0954 0.0914 0.0873 0.0843 0.0824 0.0812 0.0802 0.0790 0.0780 

[TRAIN] Epoch[1](6532/114412); Loss: 0.113571; Backpropagation: 0.2953 sec; Batch: 2.1222 sec
0.2225 0.1927 0.1620 0.1378 0.1224 0.1119 0.1046 0.0969 0.0919 0.0875 0.0844 0.0827 0.0814 0.0804 0.0793 0.0787 

[TRAIN] Epoch[1](6533/114412); Loss: 0.114461; Backpropagation: 0.2958 sec; Batch: 2.0831 sec
0.1742 0.1633 0.1466 0.1364 0.1259 0.1164 0.1109 0.1068 0.1037 0.0998 0.0967 0.0938 0.0913 0.0894 0.0885 0.0876 

[TRAIN] Epoch[1](6534/114412); Loss: 0.112843; Backpropagation: 0.2957 sec; Batch: 2.1616 sec
0.1551 0.1463 0.1431 0.1357 0.1266 0.1192 0.1117 0.1075 0.1032 0.1005 0.0977 0.0953 0.0937 0.0918 0.0896 0.0885 

[TRAIN] Epoch[1](6535/114412); Loss: 0.144845; Backpropagation: 0.2952 sec; Batch: 2.1099 sec
0.2648 0.2465 0.2101 0.1924 0.1701 0.1522 0.1388 0.1274 0.1182 0.1120 0.1063 0.1021 0.0985 0.0950 0.0926 0.0905 

[TRAIN] Epoch[1](6536/114412); Loss: 0.112280; Backpropagation: 0.2923 sec; Batch: 2.1748 sec
0.2290 0.2089 0.1660 0.1431 0.1218 0.1075 0.0979 0.0907 0.0862 0.0831 0.0807 0.0788 0.0775 0.0760 0.0748 0.0742 

[TRAIN] Epoch[1](6537/114412); Loss: 0.136185; Backpropagation: 0.2910 sec; Batch: 2.1265 sec
0.2116 0.1947 0.1748 0.1592 0.1463 0.1387 0.1320 0.1270 0.1219 0.1172 0.1148 0.1124 0.1100 0.1077 0.1059 0.1047 

[TRAIN] Epoch[1](6538/114412); Loss: 0.117427; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1880 0.1725 0.1610 0.1506 0.1374 0.1261 0.1155 0.1074 0.1012 0.0964 0.0929 0.0899 0.0874 0.0856 0.0841 0.0829 

[TRAIN] Epoch[1](6539/114412); Loss: 0.128796; Backpropagation: 0.2913 sec; Batch: 2.0778 sec
0.2000 0.1902 0.1701 0.1556 0.1442 0.1321 0.1230 0.1189 0.1150 0.1102 0.1065 0.1038 0.1003 0.0983 0.0967 0.0959 

[TRAIN] Epoch[1](6540/114412); Loss: 0.106217; Backpropagation: 0.2925 sec; Batch: 2.0795 sec
0.1781 0.1672 0.1573 0.1446 0.1276 0.1148 0.1043 0.0964 0.0892 0.0830 0.0791 0.0754 0.0728 0.0709 0.0701 0.0686 

[TRAIN] Epoch[1](6541/114412); Loss: 0.150106; Backpropagation: 0.2911 sec; Batch: 2.1229 sec
0.2430 0.2343 0.2122 0.1938 0.1744 0.1582 0.1459 0.1357 0.1277 0.1230 0.1179 0.1143 0.1100 0.1068 0.1035 0.1009 

[TRAIN] Epoch[1](6542/114412); Loss: 0.144637; Backpropagation: 0.2972 sec; Batch: 2.0832 sec
0.2769 0.2520 0.2241 0.2026 0.1794 0.1594 0.1421 0.1300 0.1157 0.1067 0.0983 0.0919 0.0883 0.0846 0.0822 0.0801 

[TRAIN] Epoch[1](6543/114412); Loss: 0.102156; Backpropagation: 0.2932 sec; Batch: 2.1234 sec
0.1582 0.1484 0.1365 0.1238 0.1122 0.1045 0.0987 0.0954 0.0901 0.0876 0.0849 0.0821 0.0801 0.0785 0.0770 0.0765 

[TRAIN] Epoch[1](6544/114412); Loss: 0.105156; Backpropagation: 0.2919 sec; Batch: 2.0785 sec
0.2004 0.1812 0.1531 0.1367 0.1166 0.1051 0.0941 0.0891 0.0835 0.0806 0.0784 0.0759 0.0738 0.0723 0.0712 0.0704 

[TRAIN] Epoch[1](6545/114412); Loss: 0.122786; Backpropagation: 0.2909 sec; Batch: 2.1148 sec
0.1812 0.1733 0.1575 0.1504 0.1398 0.1290 0.1204 0.1150 0.1100 0.1059 0.1027 0.0997 0.0976 0.0954 0.0938 0.0928 

[TRAIN] Epoch[1](6546/114412); Loss: 0.100962; Backpropagation: 0.2903 sec; Batch: 2.1172 sec
0.1823 0.1679 0.1446 0.1280 0.1124 0.1033 0.0945 0.0888 0.0832 0.0794 0.0769 0.0742 0.0725 0.0702 0.0691 0.0680 

[TRAIN] Epoch[1](6547/114412); Loss: 0.103103; Backpropagation: 0.2944 sec; Batch: 2.0811 sec
0.1686 0.1527 0.1346 0.1256 0.1139 0.1052 0.0999 0.0950 0.0905 0.0865 0.0835 0.0812 0.0798 0.0788 0.0775 0.0764 

[TRAIN] Epoch[1](6548/114412); Loss: 0.126485; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1918 0.1805 0.1623 0.1497 0.1375 0.1292 0.1227 0.1188 0.1144 0.1106 0.1070 0.1042 0.1020 0.0999 0.0975 0.0956 

[TRAIN] Epoch[1](6549/114412); Loss: 0.119677; Backpropagation: 0.2951 sec; Batch: 2.0815 sec
0.1633 0.1616 0.1506 0.1425 0.1327 0.1245 0.1169 0.1138 0.1097 0.1054 0.1035 0.1008 0.0991 0.0981 0.0965 0.0958 

[TRAIN] Epoch[1](6550/114412); Loss: 0.119370; Backpropagation: 0.2929 sec; Batch: 2.0805 sec
0.2157 0.1918 0.1633 0.1455 0.1263 0.1161 0.1080 0.1036 0.1003 0.0967 0.0947 0.0931 0.0909 0.0891 0.0880 0.0870 

[TRAIN] Epoch[1](6551/114412); Loss: 0.162342; Backpropagation: 0.2913 sec; Batch: 2.0952 sec
0.2615 0.2461 0.2236 0.2118 0.1923 0.1754 0.1595 0.1488 0.1390 0.1312 0.1263 0.1221 0.1189 0.1152 0.1134 0.1122 

[TRAIN] Epoch[1](6552/114412); Loss: 0.123410; Backpropagation: 0.2934 sec; Batch: 2.1150 sec
0.1912 0.1798 0.1590 0.1462 0.1337 0.1243 0.1168 0.1124 0.1083 0.1054 0.1035 0.1018 0.1000 0.0984 0.0973 0.0966 

[TRAIN] Epoch[1](6553/114412); Loss: 0.078697; Backpropagation: 0.2913 sec; Batch: 2.1200 sec
0.1718 0.1435 0.1249 0.1036 0.0826 0.0720 0.0673 0.0647 0.0601 0.0565 0.0543 0.0534 0.0522 0.0512 0.0507 0.0504 

[TRAIN] Epoch[1](6554/114412); Loss: 0.099940; Backpropagation: 0.2914 sec; Batch: 2.1194 sec
0.1618 0.1462 0.1338 0.1198 0.1072 0.0984 0.0924 0.0903 0.0874 0.0856 0.0836 0.0815 0.0800 0.0781 0.0769 0.0759 

[TRAIN] Epoch[1](6555/114412); Loss: 0.173918; Backpropagation: 0.2945 sec; Batch: 2.1200 sec
0.2522 0.2434 0.2272 0.2183 0.2028 0.1905 0.1770 0.1676 0.1582 0.1506 0.1456 0.1401 0.1335 0.1295 0.1250 0.1214 

[TRAIN] Epoch[1](6556/114412); Loss: 0.112763; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.2016 0.1822 0.1580 0.1434 0.1259 0.1154 0.1057 0.0998 0.0945 0.0903 0.0870 0.0844 0.0818 0.0798 0.0781 0.0763 

[TRAIN] Epoch[1](6557/114412); Loss: 0.190117; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.2545 0.2522 0.2468 0.2439 0.2265 0.2129 0.1980 0.1866 0.1762 0.1685 0.1616 0.1542 0.1478 0.1420 0.1373 0.1328 

[TRAIN] Epoch[1](6558/114412); Loss: 0.196584; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.2846 0.2735 0.2546 0.2479 0.2314 0.2172 0.2026 0.1916 0.1815 0.1729 0.1652 0.1573 0.1510 0.1432 0.1379 0.1331 

[TRAIN] Epoch[1](6559/114412); Loss: 0.131267; Backpropagation: 0.2914 sec; Batch: 2.1281 sec
0.1943 0.1892 0.1733 0.1626 0.1475 0.1366 0.1254 0.1198 0.1165 0.1122 0.1091 0.1064 0.1044 0.1022 0.1008 0.0999 

[TRAIN] Epoch[1](6560/114412); Loss: 0.155824; Backpropagation: 0.2943 sec; Batch: 2.1447 sec
0.2189 0.2119 0.1928 0.1782 0.1679 0.1637 0.1574 0.1532 0.1461 0.1396 0.1350 0.1308 0.1281 0.1255 0.1230 0.1213 

[TRAIN] Epoch[1](6561/114412); Loss: 0.149068; Backpropagation: 0.2951 sec; Batch: 2.1557 sec
0.1901 0.1935 0.1834 0.1801 0.1668 0.1564 0.1476 0.1419 0.1372 0.1331 0.1314 0.1288 0.1264 0.1243 0.1226 0.1215 

[TRAIN] Epoch[1](6562/114412); Loss: 0.177852; Backpropagation: 0.2908 sec; Batch: 2.1081 sec
0.2347 0.2256 0.2200 0.2134 0.2037 0.1955 0.1853 0.1773 0.1690 0.1618 0.1552 0.1485 0.1437 0.1397 0.1377 0.1345 

[TRAIN] Epoch[1](6563/114412); Loss: 0.104971; Backpropagation: 0.2908 sec; Batch: 2.1175 sec
0.2038 0.1812 0.1535 0.1322 0.1141 0.1005 0.0912 0.0870 0.0837 0.0810 0.0793 0.0774 0.0755 0.0743 0.0730 0.0720 

[TRAIN] Epoch[1](6564/114412); Loss: 0.112745; Backpropagation: 0.2907 sec; Batch: 2.1143 sec
0.2001 0.1833 0.1630 0.1464 0.1286 0.1162 0.1056 0.0993 0.0941 0.0895 0.0870 0.0835 0.0800 0.0771 0.0755 0.0747 

[TRAIN] Epoch[1](6565/114412); Loss: 0.102202; Backpropagation: 0.2913 sec; Batch: 2.0938 sec
0.1486 0.1401 0.1307 0.1198 0.1102 0.1022 0.0978 0.0955 0.0919 0.0890 0.0871 0.0856 0.0848 0.0844 0.0839 0.0836 

[TRAIN] Epoch[1](6566/114412); Loss: 0.134999; Backpropagation: 0.2913 sec; Batch: 2.0979 sec
0.1831 0.1764 0.1719 0.1634 0.1514 0.1439 0.1355 0.1301 0.1245 0.1205 0.1166 0.1140 0.1102 0.1077 0.1062 0.1046 

[TRAIN] Epoch[1](6567/114412); Loss: 0.142497; Backpropagation: 0.2908 sec; Batch: 2.1229 sec
0.2457 0.2269 0.2036 0.1878 0.1675 0.1527 0.1386 0.1278 0.1192 0.1131 0.1073 0.1029 0.0999 0.0973 0.0956 0.0941 

[TRAIN] Epoch[1](6568/114412); Loss: 0.116253; Backpropagation: 0.2906 sec; Batch: 2.0767 sec
0.1660 0.1609 0.1567 0.1466 0.1338 0.1245 0.1165 0.1118 0.1053 0.1004 0.0966 0.0931 0.0903 0.0880 0.0856 0.0840 

[TRAIN] Epoch[1](6569/114412); Loss: 0.185425; Backpropagation: 0.2906 sec; Batch: 2.1150 sec
0.2773 0.2632 0.2364 0.2256 0.2058 0.1940 0.1824 0.1759 0.1676 0.1613 0.1549 0.1490 0.1458 0.1436 0.1425 0.1416 

[TRAIN] Epoch[1](6570/114412); Loss: 0.186730; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.2560 0.2542 0.2427 0.2324 0.2110 0.1963 0.1842 0.1768 0.1717 0.1671 0.1609 0.1548 0.1501 0.1465 0.1430 0.1399 

[TRAIN] Epoch[1](6571/114412); Loss: 0.105793; Backpropagation: 0.2928 sec; Batch: 2.1202 sec
0.1662 0.1569 0.1402 0.1328 0.1185 0.1093 0.1007 0.0949 0.0907 0.0882 0.0861 0.0836 0.0823 0.0815 0.0807 0.0802 

[TRAIN] Epoch[1](6572/114412); Loss: 0.145354; Backpropagation: 0.2905 sec; Batch: 2.1190 sec
0.2364 0.2300 0.2153 0.1985 0.1761 0.1566 0.1427 0.1323 0.1237 0.1165 0.1101 0.1047 0.1006 0.0972 0.0941 0.0910 

[TRAIN] Epoch[1](6573/114412); Loss: 0.127882; Backpropagation: 0.2911 sec; Batch: 2.1190 sec
0.2142 0.1938 0.1686 0.1544 0.1408 0.1316 0.1210 0.1166 0.1104 0.1059 0.1031 0.1006 0.0989 0.0968 0.0952 0.0942 

[TRAIN] Epoch[1](6574/114412); Loss: 0.204318; Backpropagation: 0.2909 sec; Batch: 2.1141 sec
0.2902 0.2790 0.2588 0.2464 0.2264 0.2139 0.2039 0.1943 0.1872 0.1803 0.1750 0.1700 0.1655 0.1624 0.1594 0.1564 

[TRAIN] Epoch[1](6575/114412); Loss: 0.171871; Backpropagation: 0.2910 sec; Batch: 2.1161 sec
0.2402 0.2379 0.2196 0.2102 0.1945 0.1836 0.1713 0.1645 0.1572 0.1497 0.1457 0.1419 0.1376 0.1345 0.1318 0.1296 

[TRAIN] Epoch[1](6576/114412); Loss: 0.124172; Backpropagation: 0.2911 sec; Batch: 2.1132 sec
0.1903 0.1767 0.1565 0.1455 0.1346 0.1278 0.1208 0.1158 0.1114 0.1093 0.1059 0.1023 0.1003 0.0980 0.0963 0.0954 

[TRAIN] Epoch[1](6577/114412); Loss: 0.116816; Backpropagation: 0.2927 sec; Batch: 2.1145 sec
0.2431 0.2133 0.1713 0.1437 0.1273 0.1154 0.1038 0.0946 0.0900 0.0860 0.0830 0.0812 0.0801 0.0789 0.0786 0.0787 

[TRAIN] Epoch[1](6578/114412); Loss: 0.093022; Backpropagation: 0.2912 sec; Batch: 2.1129 sec
0.1595 0.1335 0.1231 0.1118 0.1005 0.0937 0.0883 0.0850 0.0800 0.0776 0.0756 0.0738 0.0727 0.0718 0.0709 0.0705 

[TRAIN] Epoch[1](6579/114412); Loss: 0.109584; Backpropagation: 0.2928 sec; Batch: 2.1199 sec
0.1625 0.1593 0.1437 0.1332 0.1219 0.1151 0.1042 0.0998 0.0960 0.0934 0.0928 0.0890 0.0867 0.0860 0.0853 0.0843 

[TRAIN] Epoch[1](6580/114412); Loss: 0.183254; Backpropagation: 0.2912 sec; Batch: 2.0772 sec
0.2419 0.2405 0.2270 0.2148 0.2016 0.1924 0.1838 0.1770 0.1716 0.1659 0.1615 0.1568 0.1525 0.1502 0.1484 0.1462 

[TRAIN] Epoch[1](6581/114412); Loss: 0.186442; Backpropagation: 0.2953 sec; Batch: 2.1032 sec
0.3205 0.3071 0.2758 0.2607 0.2297 0.2054 0.1827 0.1649 0.1525 0.1430 0.1360 0.1294 0.1255 0.1215 0.1161 0.1122 

[TRAIN] Epoch[1](6582/114412); Loss: 0.129278; Backpropagation: 0.2932 sec; Batch: 2.1163 sec
0.1919 0.1866 0.1712 0.1644 0.1500 0.1405 0.1304 0.1229 0.1161 0.1103 0.1062 0.1016 0.0979 0.0950 0.0928 0.0907 

[TRAIN] Epoch[1](6583/114412); Loss: 0.123110; Backpropagation: 0.2909 sec; Batch: 2.1142 sec
0.2109 0.1917 0.1615 0.1430 0.1326 0.1238 0.1170 0.1107 0.1071 0.1024 0.0996 0.0970 0.0949 0.0934 0.0921 0.0919 

[TRAIN] Epoch[1](6584/114412); Loss: 0.149651; Backpropagation: 0.2911 sec; Batch: 2.1138 sec
0.2277 0.2172 0.1995 0.1908 0.1737 0.1623 0.1525 0.1440 0.1349 0.1267 0.1215 0.1157 0.1118 0.1081 0.1055 0.1026 

[TRAIN] Epoch[1](6585/114412); Loss: 0.150374; Backpropagation: 0.2910 sec; Batch: 2.1160 sec
0.2557 0.2403 0.2177 0.2024 0.1824 0.1635 0.1472 0.1325 0.1234 0.1180 0.1117 0.1070 0.1037 0.1019 0.1007 0.0980 

[TRAIN] Epoch[1](6586/114412); Loss: 0.100817; Backpropagation: 0.2912 sec; Batch: 2.0783 sec
0.1636 0.1574 0.1308 0.1216 0.1124 0.1019 0.0938 0.0903 0.0858 0.0830 0.0810 0.0797 0.0789 0.0782 0.0777 0.0769 

[TRAIN] Epoch[1](6587/114412); Loss: 0.153122; Backpropagation: 0.2917 sec; Batch: 2.1195 sec
0.2362 0.2173 0.1993 0.1870 0.1701 0.1598 0.1497 0.1411 0.1340 0.1294 0.1260 0.1241 0.1216 0.1194 0.1183 0.1168 

[TRAIN] Epoch[1](6588/114412); Loss: 0.098059; Backpropagation: 0.2911 sec; Batch: 2.1155 sec
0.1457 0.1480 0.1395 0.1280 0.1131 0.1011 0.0935 0.0884 0.0854 0.0809 0.0789 0.0767 0.0748 0.0732 0.0717 0.0700 

[TRAIN] Epoch[1](6589/114412); Loss: 0.113730; Backpropagation: 0.2913 sec; Batch: 2.1191 sec
0.2054 0.1833 0.1605 0.1492 0.1324 0.1199 0.1094 0.1012 0.0948 0.0884 0.0847 0.0821 0.0795 0.0777 0.0762 0.0752 

[TRAIN] Epoch[1](6590/114412); Loss: 0.104081; Backpropagation: 0.2907 sec; Batch: 2.0766 sec
0.1698 0.1459 0.1363 0.1256 0.1161 0.1075 0.1013 0.0969 0.0919 0.0884 0.0857 0.0834 0.0819 0.0799 0.0780 0.0766 

[TRAIN] Epoch[1](6591/114412); Loss: 0.093899; Backpropagation: 0.2927 sec; Batch: 2.1188 sec
0.1603 0.1516 0.1315 0.1203 0.1069 0.0965 0.0872 0.0829 0.0787 0.0753 0.0732 0.0703 0.0689 0.0671 0.0658 0.0658 

[TRAIN] Epoch[1](6592/114412); Loss: 0.148995; Backpropagation: 0.2913 sec; Batch: 2.0786 sec
0.2681 0.2471 0.2202 0.1993 0.1740 0.1543 0.1394 0.1283 0.1198 0.1137 0.1101 0.1065 0.1035 0.1015 0.0995 0.0985 

[TRAIN] Epoch[1](6593/114412); Loss: 0.113890; Backpropagation: 0.2909 sec; Batch: 2.0793 sec
0.1787 0.1713 0.1553 0.1454 0.1295 0.1207 0.1110 0.1042 0.0982 0.0942 0.0910 0.0878 0.0860 0.0841 0.0829 0.0818 

[TRAIN] Epoch[1](6594/114412); Loss: 0.115568; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1846 0.1749 0.1537 0.1445 0.1300 0.1188 0.1095 0.1035 0.0980 0.0957 0.0932 0.0920 0.0903 0.0879 0.0868 0.0858 

[TRAIN] Epoch[1](6595/114412); Loss: 0.139425; Backpropagation: 0.2910 sec; Batch: 2.1183 sec
0.2165 0.2054 0.1820 0.1732 0.1570 0.1465 0.1367 0.1298 0.1229 0.1182 0.1150 0.1118 0.1083 0.1050 0.1022 0.1003 

[TRAIN] Epoch[1](6596/114412); Loss: 0.130924; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1774 0.1690 0.1654 0.1571 0.1436 0.1350 0.1282 0.1231 0.1208 0.1178 0.1149 0.1127 0.1101 0.1076 0.1068 0.1053 

[TRAIN] Epoch[1](6597/114412); Loss: 0.126309; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1960 0.1819 0.1701 0.1578 0.1419 0.1299 0.1222 0.1154 0.1111 0.1077 0.1035 0.1005 0.0983 0.0966 0.0946 0.0933 

[TRAIN] Epoch[1](6598/114412); Loss: 0.129313; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.2189 0.2044 0.1833 0.1700 0.1515 0.1385 0.1239 0.1154 0.1089 0.1028 0.0991 0.0956 0.0924 0.0907 0.0880 0.0856 

[TRAIN] Epoch[1](6599/114412); Loss: 0.140410; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.2207 0.2052 0.1863 0.1743 0.1579 0.1476 0.1371 0.1306 0.1259 0.1182 0.1134 0.1095 0.1074 0.1064 0.1038 0.1021 

[TRAIN] Epoch[1](6600/114412); Loss: 0.145896; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.2419 0.2162 0.1930 0.1785 0.1589 0.1478 0.1381 0.1311 0.1260 0.1216 0.1185 0.1161 0.1141 0.1127 0.1108 0.1092 

[TRAIN] Epoch[1](6601/114412); Loss: 0.134760; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1919 0.1867 0.1763 0.1674 0.1542 0.1442 0.1360 0.1293 0.1227 0.1169 0.1125 0.1082 0.1052 0.1030 0.1017 0.0999 

[TRAIN] Epoch[1](6602/114412); Loss: 0.103922; Backpropagation: 0.2911 sec; Batch: 2.1211 sec
0.1648 0.1572 0.1323 0.1181 0.1095 0.1028 0.0978 0.0936 0.0908 0.0883 0.0869 0.0855 0.0846 0.0840 0.0834 0.0830 

[TRAIN] Epoch[1](6603/114412); Loss: 0.158518; Backpropagation: 0.2915 sec; Batch: 2.1179 sec
0.2161 0.2137 0.2045 0.1972 0.1837 0.1741 0.1630 0.1536 0.1451 0.1387 0.1334 0.1289 0.1248 0.1214 0.1195 0.1185 

[TRAIN] Epoch[1](6604/114412); Loss: 0.194317; Backpropagation: 0.2916 sec; Batch: 2.1220 sec
0.2700 0.2623 0.2472 0.2389 0.2220 0.2093 0.1954 0.1850 0.1773 0.1710 0.1653 0.1604 0.1561 0.1526 0.1493 0.1469 

[TRAIN] Epoch[1](6605/114412); Loss: 0.088247; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1725 0.1464 0.1291 0.1111 0.0958 0.0854 0.0779 0.0741 0.0703 0.0675 0.0657 0.0646 0.0640 0.0630 0.0622 0.0622 

[TRAIN] Epoch[1](6606/114412); Loss: 0.097285; Backpropagation: 0.2949 sec; Batch: 2.1248 sec
0.1510 0.1449 0.1333 0.1269 0.1162 0.1065 0.0965 0.0885 0.0841 0.0808 0.0761 0.0737 0.0716 0.0696 0.0686 0.0682 

[TRAIN] Epoch[1](6607/114412); Loss: 0.162128; Backpropagation: 0.2930 sec; Batch: 2.1192 sec
0.2555 0.2481 0.2276 0.2187 0.1930 0.1766 0.1626 0.1511 0.1429 0.1353 0.1266 0.1194 0.1145 0.1105 0.1074 0.1044 

[TRAIN] Epoch[1](6608/114412); Loss: 0.112313; Backpropagation: 0.2914 sec; Batch: 2.0778 sec
0.1857 0.1756 0.1540 0.1418 0.1277 0.1171 0.1066 0.1006 0.0956 0.0915 0.0890 0.0861 0.0841 0.0816 0.0803 0.0796 

[TRAIN] Epoch[1](6609/114412); Loss: 0.095604; Backpropagation: 0.2929 sec; Batch: 2.1170 sec
0.2043 0.1856 0.1447 0.1209 0.0995 0.0888 0.0801 0.0758 0.0729 0.0703 0.0675 0.0658 0.0645 0.0635 0.0632 0.0624 

[TRAIN] Epoch[1](6610/114412); Loss: 0.115962; Backpropagation: 0.2914 sec; Batch: 2.1274 sec
0.1630 0.1557 0.1514 0.1416 0.1302 0.1209 0.1139 0.1104 0.1060 0.1025 0.0994 0.0964 0.0936 0.0916 0.0901 0.0888 

[TRAIN] Epoch[1](6611/114412); Loss: 0.150296; Backpropagation: 0.2911 sec; Batch: 2.1134 sec
0.2232 0.2011 0.1874 0.1764 0.1612 0.1545 0.1449 0.1394 0.1346 0.1304 0.1288 0.1276 0.1258 0.1244 0.1231 0.1219 

[TRAIN] Epoch[1](6612/114412); Loss: 0.137809; Backpropagation: 0.2910 sec; Batch: 2.1165 sec
0.2211 0.2058 0.1826 0.1725 0.1579 0.1466 0.1362 0.1278 0.1203 0.1141 0.1097 0.1064 0.1045 0.1021 0.0995 0.0978 

[TRAIN] Epoch[1](6613/114412); Loss: 0.090138; Backpropagation: 0.2930 sec; Batch: 2.1371 sec
0.1711 0.1607 0.1310 0.1207 0.1058 0.0958 0.0866 0.0804 0.0741 0.0677 0.0635 0.0601 0.0580 0.0566 0.0557 0.0543 

[TRAIN] Epoch[1](6614/114412); Loss: 0.114323; Backpropagation: 0.2919 sec; Batch: 2.0789 sec
0.1902 0.1759 0.1569 0.1455 0.1339 0.1245 0.1168 0.1075 0.0999 0.0945 0.0895 0.0848 0.0809 0.0782 0.0759 0.0745 

[TRAIN] Epoch[1](6615/114412); Loss: 0.135392; Backpropagation: 0.2934 sec; Batch: 2.1146 sec
0.1895 0.1822 0.1710 0.1643 0.1489 0.1408 0.1339 0.1284 0.1243 0.1207 0.1171 0.1137 0.1110 0.1087 0.1068 0.1049 

[TRAIN] Epoch[1](6616/114412); Loss: 0.106026; Backpropagation: 0.2910 sec; Batch: 2.1197 sec
0.1926 0.1644 0.1429 0.1261 0.1116 0.1055 0.0992 0.0938 0.0891 0.0855 0.0833 0.0820 0.0812 0.0806 0.0797 0.0790 

[TRAIN] Epoch[1](6617/114412); Loss: 0.138892; Backpropagation: 0.2907 sec; Batch: 2.1193 sec
0.2065 0.1970 0.1838 0.1769 0.1631 0.1518 0.1388 0.1305 0.1225 0.1182 0.1138 0.1097 0.1061 0.1033 0.1012 0.0990 

[TRAIN] Epoch[1](6618/114412); Loss: 0.152011; Backpropagation: 0.2908 sec; Batch: 2.1150 sec
0.2251 0.2151 0.2001 0.1928 0.1750 0.1622 0.1508 0.1435 0.1368 0.1303 0.1260 0.1219 0.1179 0.1138 0.1110 0.1099 

[TRAIN] Epoch[1](6619/114412); Loss: 0.089648; Backpropagation: 0.2908 sec; Batch: 2.1171 sec
0.1464 0.1345 0.1174 0.1080 0.0980 0.0896 0.0848 0.0825 0.0787 0.0758 0.0739 0.0713 0.0695 0.0686 0.0679 0.0675 

[TRAIN] Epoch[1](6620/114412); Loss: 0.120846; Backpropagation: 0.2921 sec; Batch: 2.1231 sec
0.1822 0.1761 0.1559 0.1454 0.1349 0.1282 0.1190 0.1122 0.1075 0.1030 0.0994 0.0977 0.0957 0.0937 0.0920 0.0905 

[TRAIN] Epoch[1](6621/114412); Loss: 0.144630; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.2120 0.2026 0.1914 0.1820 0.1664 0.1544 0.1430 0.1355 0.1300 0.1246 0.1200 0.1162 0.1130 0.1101 0.1074 0.1055 

[TRAIN] Epoch[1](6622/114412); Loss: 0.137742; Backpropagation: 0.2907 sec; Batch: 2.1137 sec
0.1831 0.1889 0.1843 0.1771 0.1634 0.1514 0.1404 0.1318 0.1244 0.1185 0.1147 0.1111 0.1078 0.1051 0.1023 0.0994 

[TRAIN] Epoch[1](6623/114412); Loss: 0.147563; Backpropagation: 0.2911 sec; Batch: 2.1256 sec
0.2248 0.2171 0.2016 0.1958 0.1804 0.1655 0.1532 0.1423 0.1307 0.1232 0.1164 0.1097 0.1056 0.1014 0.0982 0.0951 

[TRAIN] Epoch[1](6624/114412); Loss: 0.133849; Backpropagation: 0.2909 sec; Batch: 2.0984 sec
0.2394 0.2131 0.1908 0.1701 0.1472 0.1337 0.1224 0.1168 0.1123 0.1077 0.1050 0.1013 0.0983 0.0964 0.0943 0.0929 

[TRAIN] Epoch[1](6625/114412); Loss: 0.132749; Backpropagation: 0.2924 sec; Batch: 2.1205 sec
0.1928 0.1855 0.1718 0.1677 0.1554 0.1448 0.1339 0.1262 0.1196 0.1129 0.1088 0.1052 0.1017 0.1009 0.0995 0.0972 

[TRAIN] Epoch[1](6626/114412); Loss: 0.137712; Backpropagation: 0.2920 sec; Batch: 2.1187 sec
0.2113 0.2035 0.1781 0.1673 0.1533 0.1454 0.1381 0.1312 0.1241 0.1179 0.1131 0.1091 0.1060 0.1031 0.1015 0.1002 

[TRAIN] Epoch[1](6627/114412); Loss: 0.111417; Backpropagation: 0.2927 sec; Batch: 2.1275 sec
0.1821 0.1753 0.1533 0.1420 0.1265 0.1148 0.1056 0.1005 0.0958 0.0912 0.0877 0.0857 0.0831 0.0814 0.0797 0.0781 

[TRAIN] Epoch[1](6628/114412); Loss: 0.148017; Backpropagation: 0.2942 sec; Batch: 2.1306 sec
0.2187 0.2149 0.1962 0.1872 0.1710 0.1596 0.1496 0.1409 0.1332 0.1261 0.1211 0.1162 0.1128 0.1095 0.1064 0.1048 

[TRAIN] Epoch[1](6629/114412); Loss: 0.111184; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.1674 0.1620 0.1524 0.1444 0.1314 0.1220 0.1114 0.1040 0.0980 0.0924 0.0892 0.0858 0.0828 0.0803 0.0787 0.0768 

[TRAIN] Epoch[1](6630/114412); Loss: 0.118139; Backpropagation: 0.2928 sec; Batch: 2.1196 sec
0.1913 0.1793 0.1570 0.1465 0.1315 0.1227 0.1124 0.1063 0.1008 0.0974 0.0949 0.0930 0.0910 0.0896 0.0884 0.0879 

[TRAIN] Epoch[1](6631/114412); Loss: 0.116068; Backpropagation: 0.2914 sec; Batch: 2.1154 sec
0.1761 0.1723 0.1525 0.1438 0.1324 0.1236 0.1152 0.1089 0.1027 0.0983 0.0950 0.0918 0.0886 0.0870 0.0852 0.0836 

[TRAIN] Epoch[1](6632/114412); Loss: 0.163335; Backpropagation: 0.2910 sec; Batch: 2.0963 sec
0.2543 0.2522 0.2184 0.2063 0.1882 0.1756 0.1641 0.1534 0.1445 0.1370 0.1311 0.1265 0.1217 0.1166 0.1131 0.1103 

[TRAIN] Epoch[1](6633/114412); Loss: 0.105912; Backpropagation: 0.2904 sec; Batch: 2.1184 sec
0.1600 0.1540 0.1308 0.1210 0.1135 0.1072 0.1007 0.0979 0.0942 0.0917 0.0895 0.0885 0.0877 0.0864 0.0858 0.0858 

[TRAIN] Epoch[1](6634/114412); Loss: 0.079602; Backpropagation: 0.2909 sec; Batch: 2.1366 sec
0.1299 0.1188 0.1079 0.1000 0.0885 0.0818 0.0752 0.0713 0.0683 0.0658 0.0637 0.0622 0.0609 0.0602 0.0598 0.0596 

[TRAIN] Epoch[1](6635/114412); Loss: 0.156565; Backpropagation: 0.2917 sec; Batch: 2.1113 sec
0.2465 0.2200 0.2055 0.1947 0.1780 0.1688 0.1590 0.1504 0.1412 0.1333 0.1275 0.1224 0.1184 0.1155 0.1130 0.1110 

[TRAIN] Epoch[1](6636/114412); Loss: 0.108062; Backpropagation: 0.2923 sec; Batch: 2.1127 sec
0.1698 0.1591 0.1460 0.1342 0.1207 0.1097 0.1040 0.0989 0.0940 0.0903 0.0875 0.0853 0.0839 0.0825 0.0819 0.0811 

[TRAIN] Epoch[1](6637/114412); Loss: 0.124281; Backpropagation: 0.2924 sec; Batch: 2.1071 sec
0.2218 0.2067 0.1715 0.1589 0.1401 0.1274 0.1182 0.1101 0.1035 0.0977 0.0942 0.0915 0.0890 0.0871 0.0857 0.0851 

[TRAIN] Epoch[1](6638/114412); Loss: 0.172269; Backpropagation: 0.2925 sec; Batch: 2.1001 sec
0.2364 0.2334 0.2223 0.2163 0.1962 0.1838 0.1738 0.1668 0.1601 0.1521 0.1466 0.1427 0.1361 0.1331 0.1305 0.1262 

[TRAIN] Epoch[1](6639/114412); Loss: 0.100886; Backpropagation: 0.2932 sec; Batch: 2.1226 sec
0.1611 0.1495 0.1325 0.1228 0.1104 0.1048 0.0970 0.0928 0.0890 0.0847 0.0821 0.0802 0.0785 0.0775 0.0762 0.0750 

[TRAIN] Epoch[1](6640/114412); Loss: 0.120675; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1715 0.1685 0.1533 0.1423 0.1301 0.1212 0.1143 0.1112 0.1083 0.1053 0.1033 0.1015 0.1009 0.1003 0.0997 0.0992 

[TRAIN] Epoch[1](6641/114412); Loss: 0.104462; Backpropagation: 0.2919 sec; Batch: 2.1304 sec
0.1724 0.1669 0.1397 0.1345 0.1202 0.1116 0.1028 0.0966 0.0909 0.0865 0.0832 0.0795 0.0758 0.0726 0.0701 0.0681 

[TRAIN] Epoch[1](6642/114412); Loss: 0.111729; Backpropagation: 0.2908 sec; Batch: 2.0773 sec
0.1729 0.1641 0.1430 0.1368 0.1272 0.1173 0.1094 0.1036 0.0993 0.0953 0.0927 0.0892 0.0873 0.0853 0.0828 0.0815 

[TRAIN] Epoch[1](6643/114412); Loss: 0.150703; Backpropagation: 0.2950 sec; Batch: 2.0846 sec
0.2367 0.2285 0.2051 0.1948 0.1763 0.1634 0.1505 0.1399 0.1323 0.1256 0.1203 0.1161 0.1110 0.1069 0.1037 0.1001 

[TRAIN] Epoch[1](6644/114412); Loss: 0.162318; Backpropagation: 0.2932 sec; Batch: 2.1349 sec
0.2227 0.2220 0.2035 0.1958 0.1814 0.1704 0.1601 0.1519 0.1462 0.1419 0.1388 0.1362 0.1336 0.1317 0.1308 0.1300 

[TRAIN] Epoch[1](6645/114412); Loss: 0.099799; Backpropagation: 0.2906 sec; Batch: 2.1165 sec
0.1605 0.1524 0.1401 0.1276 0.1134 0.1037 0.0955 0.0901 0.0854 0.0810 0.0783 0.0764 0.0748 0.0732 0.0725 0.0721 

[TRAIN] Epoch[1](6646/114412); Loss: 0.127598; Backpropagation: 0.2907 sec; Batch: 2.1042 sec
0.1944 0.1817 0.1680 0.1576 0.1430 0.1355 0.1269 0.1197 0.1140 0.1097 0.1057 0.1020 0.0991 0.0969 0.0945 0.0928 

[TRAIN] Epoch[1](6647/114412); Loss: 0.119692; Backpropagation: 0.2935 sec; Batch: 2.1205 sec
0.1726 0.1682 0.1583 0.1533 0.1409 0.1314 0.1217 0.1133 0.1069 0.1008 0.0971 0.0942 0.0913 0.0895 0.0883 0.0873 

[TRAIN] Epoch[1](6648/114412); Loss: 0.088401; Backpropagation: 0.2932 sec; Batch: 2.1165 sec
0.1570 0.1537 0.1229 0.1122 0.0961 0.0869 0.0793 0.0747 0.0719 0.0690 0.0673 0.0659 0.0650 0.0644 0.0641 0.0639 

[TRAIN] Epoch[1](6649/114412); Loss: 0.121633; Backpropagation: 0.2930 sec; Batch: 2.1230 sec
0.1696 0.1622 0.1502 0.1442 0.1341 0.1264 0.1191 0.1133 0.1098 0.1075 0.1052 0.1030 0.1020 0.1009 0.0995 0.0993 

[TRAIN] Epoch[1](6650/114412); Loss: 0.106934; Backpropagation: 0.2955 sec; Batch: 2.1200 sec
0.1550 0.1527 0.1369 0.1336 0.1224 0.1131 0.1062 0.1014 0.0968 0.0918 0.0884 0.0854 0.0837 0.0823 0.0807 0.0804 

[TRAIN] Epoch[1](6651/114412); Loss: 0.100356; Backpropagation: 0.2934 sec; Batch: 2.1183 sec
0.1780 0.1687 0.1368 0.1248 0.1131 0.1040 0.0935 0.0878 0.0826 0.0792 0.0766 0.0753 0.0731 0.0714 0.0705 0.0703 

[TRAIN] Epoch[1](6652/114412); Loss: 0.120787; Backpropagation: 0.2933 sec; Batch: 2.1287 sec
0.1725 0.1677 0.1546 0.1481 0.1353 0.1267 0.1187 0.1133 0.1087 0.1053 0.1031 0.1005 0.0976 0.0955 0.0935 0.0914 

[TRAIN] Epoch[1](6653/114412); Loss: 0.124172; Backpropagation: 0.2947 sec; Batch: 2.1242 sec
0.1695 0.1632 0.1550 0.1480 0.1370 0.1294 0.1221 0.1170 0.1132 0.1096 0.1067 0.1049 0.1035 0.1028 0.1026 0.1021 

[TRAIN] Epoch[1](6654/114412); Loss: 0.107063; Backpropagation: 0.2913 sec; Batch: 2.0779 sec
0.1747 0.1562 0.1413 0.1277 0.1156 0.1083 0.1016 0.0968 0.0932 0.0908 0.0885 0.0867 0.0849 0.0832 0.0822 0.0813 

[TRAIN] Epoch[1](6655/114412); Loss: 0.143231; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.2297 0.2229 0.1842 0.1735 0.1556 0.1461 0.1389 0.1335 0.1286 0.1234 0.1194 0.1154 0.1116 0.1070 0.1030 0.0990 

[TRAIN] Epoch[1](6656/114412); Loss: 0.153636; Backpropagation: 0.2908 sec; Batch: 2.1205 sec
0.2025 0.2003 0.1875 0.1824 0.1717 0.1633 0.1546 0.1494 0.1432 0.1377 0.1337 0.1310 0.1274 0.1254 0.1248 0.1233 

[TRAIN] Epoch[1](6657/114412); Loss: 0.139073; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.2272 0.2219 0.1929 0.1823 0.1586 0.1467 0.1349 0.1268 0.1190 0.1132 0.1081 0.1051 0.1008 0.0976 0.0959 0.0942 

[TRAIN] Epoch[1](6658/114412); Loss: 0.078043; Backpropagation: 0.2925 sec; Batch: 2.1155 sec
0.1576 0.1437 0.1137 0.0987 0.0808 0.0720 0.0669 0.0639 0.0607 0.0585 0.0568 0.0562 0.0553 0.0548 0.0548 0.0543 

[TRAIN] Epoch[1](6659/114412); Loss: 0.153569; Backpropagation: 0.2914 sec; Batch: 2.1187 sec
0.2179 0.2149 0.1995 0.1937 0.1781 0.1679 0.1565 0.1479 0.1408 0.1335 0.1285 0.1242 0.1199 0.1156 0.1112 0.1069 

[TRAIN] Epoch[1](6660/114412); Loss: 0.086131; Backpropagation: 0.2932 sec; Batch: 2.1192 sec
0.1293 0.1283 0.1213 0.1110 0.0987 0.0907 0.0830 0.0794 0.0753 0.0714 0.0688 0.0661 0.0650 0.0639 0.0631 0.0628 

[TRAIN] Epoch[1](6661/114412); Loss: 0.125123; Backpropagation: 0.2913 sec; Batch: 2.0886 sec
0.2097 0.1957 0.1738 0.1597 0.1423 0.1287 0.1194 0.1113 0.1066 0.1023 0.0990 0.0960 0.0934 0.0902 0.0877 0.0863 

[TRAIN] Epoch[1](6662/114412); Loss: 0.097838; Backpropagation: 0.2913 sec; Batch: 2.0809 sec
0.1783 0.1688 0.1431 0.1315 0.1127 0.0981 0.0881 0.0815 0.0776 0.0742 0.0724 0.0702 0.0688 0.0673 0.0666 0.0662 

[TRAIN] Epoch[1](6663/114412); Loss: 0.087547; Backpropagation: 0.2903 sec; Batch: 2.1202 sec
0.1364 0.1271 0.1160 0.1075 0.0989 0.0895 0.0832 0.0790 0.0756 0.0725 0.0712 0.0701 0.0691 0.0688 0.0681 0.0678 

[TRAIN] Epoch[1](6664/114412); Loss: 0.150839; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.2245 0.2157 0.1990 0.1893 0.1713 0.1599 0.1484 0.1401 0.1335 0.1285 0.1247 0.1210 0.1176 0.1151 0.1135 0.1113 

[TRAIN] Epoch[1](6665/114412); Loss: 0.113938; Backpropagation: 0.2934 sec; Batch: 2.1239 sec
0.1796 0.1664 0.1514 0.1407 0.1259 0.1182 0.1115 0.1077 0.1011 0.0962 0.0931 0.0900 0.0884 0.0856 0.0840 0.0831 

[TRAIN] Epoch[1](6666/114412); Loss: 0.110994; Backpropagation: 0.2929 sec; Batch: 2.0855 sec
0.1863 0.1771 0.1535 0.1396 0.1231 0.1155 0.1065 0.1003 0.0954 0.0906 0.0867 0.0836 0.0814 0.0796 0.0786 0.0781 

[TRAIN] Epoch[1](6667/114412); Loss: 0.157670; Backpropagation: 0.2911 sec; Batch: 2.1033 sec
0.2415 0.2290 0.2079 0.1979 0.1791 0.1659 0.1541 0.1451 0.1378 0.1335 0.1301 0.1255 0.1218 0.1200 0.1175 0.1161 

[TRAIN] Epoch[1](6668/114412); Loss: 0.120838; Backpropagation: 0.2912 sec; Batch: 2.1258 sec
0.1744 0.1678 0.1583 0.1528 0.1401 0.1307 0.1211 0.1151 0.1098 0.1045 0.0992 0.0954 0.0933 0.0916 0.0900 0.0891 

[TRAIN] Epoch[1](6669/114412); Loss: 0.089614; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1454 0.1419 0.1156 0.1046 0.0932 0.0862 0.0818 0.0798 0.0772 0.0751 0.0741 0.0733 0.0721 0.0715 0.0712 0.0709 

[TRAIN] Epoch[1](6670/114412); Loss: 0.111737; Backpropagation: 0.2905 sec; Batch: 2.0925 sec
0.1792 0.1650 0.1472 0.1374 0.1254 0.1161 0.1081 0.1033 0.0969 0.0932 0.0906 0.0881 0.0863 0.0847 0.0836 0.0827 

[TRAIN] Epoch[1](6671/114412); Loss: 0.136922; Backpropagation: 0.2909 sec; Batch: 2.1342 sec
0.2306 0.2232 0.2021 0.1922 0.1653 0.1470 0.1331 0.1216 0.1126 0.1065 0.1019 0.0969 0.0935 0.0906 0.0879 0.0857 

[TRAIN] Epoch[1](6672/114412); Loss: 0.194682; Backpropagation: 0.2912 sec; Batch: 2.1198 sec
0.2786 0.2522 0.2203 0.2160 0.2036 0.1960 0.1891 0.1845 0.1801 0.1763 0.1737 0.1713 0.1697 0.1685 0.1675 0.1676 

[TRAIN] Epoch[1](6673/114412); Loss: 0.132634; Backpropagation: 0.2909 sec; Batch: 2.0774 sec
0.2130 0.2064 0.1904 0.1773 0.1544 0.1429 0.1306 0.1209 0.1134 0.1062 0.1006 0.0977 0.0948 0.0924 0.0912 0.0899 

[TRAIN] Epoch[1](6674/114412); Loss: 0.124895; Backpropagation: 0.2913 sec; Batch: 2.0783 sec
0.2089 0.1810 0.1641 0.1493 0.1353 0.1261 0.1176 0.1117 0.1087 0.1052 0.1018 0.1000 0.0988 0.0977 0.0965 0.0959 

[TRAIN] Epoch[1](6675/114412); Loss: 0.086286; Backpropagation: 0.2954 sec; Batch: 2.1192 sec
0.1569 0.1443 0.1076 0.0960 0.0868 0.0814 0.0775 0.0751 0.0720 0.0704 0.0697 0.0695 0.0692 0.0685 0.0679 0.0678 

[TRAIN] Epoch[1](6676/114412); Loss: 0.123993; Backpropagation: 0.2931 sec; Batch: 2.1035 sec
0.2417 0.2197 0.1951 0.1721 0.1466 0.1268 0.1085 0.0985 0.0943 0.0900 0.0870 0.0840 0.0813 0.0802 0.0797 0.0785 

[TRAIN] Epoch[1](6677/114412); Loss: 0.096504; Backpropagation: 0.2913 sec; Batch: 2.0829 sec
0.1678 0.1460 0.1274 0.1135 0.1009 0.0945 0.0884 0.0860 0.0820 0.0804 0.0780 0.0772 0.0760 0.0754 0.0754 0.0753 

[TRAIN] Epoch[1](6678/114412); Loss: 0.169419; Backpropagation: 0.2914 sec; Batch: 2.1495 sec
0.2644 0.2551 0.2324 0.2236 0.2022 0.1845 0.1678 0.1576 0.1472 0.1383 0.1321 0.1270 0.1229 0.1202 0.1183 0.1170 

[TRAIN] Epoch[1](6679/114412); Loss: 0.132242; Backpropagation: 0.2914 sec; Batch: 2.1028 sec
0.2083 0.1947 0.1734 0.1619 0.1445 0.1347 0.1259 0.1188 0.1148 0.1120 0.1080 0.1061 0.1044 0.1036 0.1027 0.1020 

[TRAIN] Epoch[1](6680/114412); Loss: 0.115477; Backpropagation: 0.2940 sec; Batch: 2.1197 sec
0.1816 0.1585 0.1392 0.1306 0.1193 0.1134 0.1086 0.1067 0.1033 0.1016 0.1004 0.0985 0.0972 0.0968 0.0961 0.0960 

[TRAIN] Epoch[1](6681/114412); Loss: 0.113505; Backpropagation: 0.2932 sec; Batch: 2.0878 sec
0.1902 0.1837 0.1658 0.1542 0.1351 0.1195 0.1067 0.0992 0.0924 0.0887 0.0854 0.0823 0.0806 0.0789 0.0771 0.0761 

[TRAIN] Epoch[1](6682/114412); Loss: 0.140735; Backpropagation: 0.2953 sec; Batch: 2.1197 sec
0.2688 0.2532 0.2220 0.2048 0.1737 0.1520 0.1297 0.1157 0.1062 0.1000 0.0945 0.0901 0.0883 0.0855 0.0842 0.0829 

[TRAIN] Epoch[1](6683/114412); Loss: 0.196541; Backpropagation: 0.2931 sec; Batch: 2.1015 sec
0.2998 0.2903 0.2700 0.2592 0.2378 0.2216 0.2021 0.1876 0.1744 0.1624 0.1541 0.1471 0.1413 0.1358 0.1322 0.1289 

[TRAIN] Epoch[1](6684/114412); Loss: 0.113642; Backpropagation: 0.2930 sec; Batch: 2.1231 sec
0.1922 0.1846 0.1683 0.1591 0.1396 0.1257 0.1129 0.1030 0.0957 0.0885 0.0828 0.0784 0.0751 0.0720 0.0708 0.0696 

[TRAIN] Epoch[1](6685/114412); Loss: 0.117928; Backpropagation: 0.2924 sec; Batch: 2.1214 sec
0.2095 0.1968 0.1652 0.1508 0.1323 0.1197 0.1091 0.1026 0.0962 0.0920 0.0902 0.0877 0.0856 0.0846 0.0830 0.0816 

[TRAIN] Epoch[1](6686/114412); Loss: 0.116093; Backpropagation: 0.2929 sec; Batch: 2.1219 sec
0.2115 0.2076 0.1722 0.1591 0.1315 0.1173 0.1070 0.0999 0.0933 0.0889 0.0845 0.0811 0.0787 0.0771 0.0746 0.0731 

[TRAIN] Epoch[1](6687/114412); Loss: 0.122380; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.2185 0.2010 0.1718 0.1591 0.1353 0.1218 0.1130 0.1080 0.1021 0.0955 0.0926 0.0900 0.0894 0.0875 0.0865 0.0860 

[TRAIN] Epoch[1](6688/114412); Loss: 0.088959; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.1412 0.1345 0.1151 0.1069 0.0936 0.0880 0.0818 0.0790 0.0763 0.0749 0.0739 0.0730 0.0721 0.0715 0.0710 0.0705 

[TRAIN] Epoch[1](6689/114412); Loss: 0.129424; Backpropagation: 0.2903 sec; Batch: 2.1166 sec
0.2475 0.2282 0.1941 0.1774 0.1492 0.1307 0.1154 0.1077 0.0997 0.0955 0.0940 0.0907 0.0882 0.0863 0.0840 0.0822 

[TRAIN] Epoch[1](6690/114412); Loss: 0.125653; Backpropagation: 0.2907 sec; Batch: 2.1055 sec
0.1779 0.1755 0.1624 0.1549 0.1402 0.1283 0.1204 0.1165 0.1129 0.1089 0.1062 0.1047 0.1023 0.1011 0.0998 0.0983 

[TRAIN] Epoch[1](6691/114412); Loss: 0.132645; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1883 0.1811 0.1670 0.1607 0.1454 0.1366 0.1302 0.1245 0.1207 0.1183 0.1151 0.1118 0.1090 0.1065 0.1042 0.1029 

[TRAIN] Epoch[1](6692/114412); Loss: 0.150760; Backpropagation: 0.2915 sec; Batch: 2.1197 sec
0.2691 0.2550 0.2190 0.2051 0.1749 0.1552 0.1417 0.1326 0.1224 0.1156 0.1112 0.1076 0.1044 0.1019 0.0997 0.0967 

[TRAIN] Epoch[1](6693/114412); Loss: 0.082700; Backpropagation: 0.2916 sec; Batch: 2.1174 sec
0.1388 0.1290 0.1082 0.0986 0.0856 0.0799 0.0749 0.0726 0.0699 0.0689 0.0681 0.0668 0.0659 0.0654 0.0654 0.0653 

[TRAIN] Epoch[1](6694/114412); Loss: 0.181169; Backpropagation: 0.2927 sec; Batch: 2.1208 sec
0.2385 0.2334 0.2215 0.2170 0.2042 0.1963 0.1862 0.1789 0.1718 0.1637 0.1575 0.1527 0.1489 0.1457 0.1424 0.1400 

[TRAIN] Epoch[1](6695/114412); Loss: 0.131504; Backpropagation: 0.2928 sec; Batch: 2.1188 sec
0.2245 0.2216 0.1955 0.1857 0.1592 0.1391 0.1225 0.1134 0.1054 0.0990 0.0953 0.0933 0.0912 0.0881 0.0859 0.0843 

[TRAIN] Epoch[1](6696/114412); Loss: 0.107846; Backpropagation: 0.2912 sec; Batch: 2.0844 sec
0.1996 0.1707 0.1464 0.1348 0.1162 0.1077 0.1000 0.0943 0.0902 0.0867 0.0841 0.0816 0.0797 0.0782 0.0778 0.0774 

[TRAIN] Epoch[1](6697/114412); Loss: 0.090292; Backpropagation: 0.2914 sec; Batch: 2.1165 sec
0.1289 0.1267 0.1128 0.1010 0.0940 0.0889 0.0832 0.0823 0.0801 0.0802 0.0794 0.0786 0.0778 0.0771 0.0770 0.0768 

[TRAIN] Epoch[1](6698/114412); Loss: 0.095779; Backpropagation: 0.2908 sec; Batch: 2.0864 sec
0.1478 0.1318 0.1153 0.1044 0.0963 0.0927 0.0913 0.0887 0.0858 0.0846 0.0834 0.0829 0.0829 0.0818 0.0815 0.0813 

[TRAIN] Epoch[1](6699/114412); Loss: 0.077429; Backpropagation: 0.2905 sec; Batch: 2.1003 sec
0.1621 0.1595 0.1164 0.1026 0.0817 0.0731 0.0657 0.0604 0.0568 0.0554 0.0532 0.0520 0.0509 0.0501 0.0496 0.0495 

[TRAIN] Epoch[1](6700/114412); Loss: 0.072845; Backpropagation: 0.2907 sec; Batch: 2.0808 sec
0.1403 0.1363 0.1014 0.0916 0.0760 0.0683 0.0629 0.0600 0.0566 0.0553 0.0538 0.0532 0.0527 0.0521 0.0525 0.0525 

[TRAIN] Epoch[1](6701/114412); Loss: 0.113682; Backpropagation: 0.2907 sec; Batch: 2.0870 sec
0.1646 0.1568 0.1484 0.1416 0.1290 0.1198 0.1108 0.1065 0.1013 0.0971 0.0947 0.0926 0.0909 0.0896 0.0878 0.0874 

[TRAIN] Epoch[1](6702/114412); Loss: 0.078402; Backpropagation: 0.2913 sec; Batch: 2.1210 sec
0.1418 0.1392 0.1074 0.0990 0.0850 0.0766 0.0686 0.0654 0.0620 0.0608 0.0600 0.0590 0.0583 0.0575 0.0570 0.0568 

[TRAIN] Epoch[1](6703/114412); Loss: 0.132077; Backpropagation: 0.2907 sec; Batch: 2.1221 sec
0.2079 0.1980 0.1761 0.1658 0.1503 0.1402 0.1296 0.1214 0.1140 0.1093 0.1060 0.1027 0.1005 0.0991 0.0969 0.0954 

[TRAIN] Epoch[1](6704/114412); Loss: 0.133032; Backpropagation: 0.2909 sec; Batch: 2.1159 sec
0.2136 0.2073 0.1875 0.1767 0.1561 0.1414 0.1301 0.1184 0.1113 0.1065 0.1032 0.1002 0.0977 0.0950 0.0928 0.0907 

[TRAIN] Epoch[1](6705/114412); Loss: 0.104679; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1838 0.1761 0.1495 0.1403 0.1233 0.1107 0.0998 0.0916 0.0858 0.0802 0.0763 0.0747 0.0727 0.0711 0.0699 0.0691 

[TRAIN] Epoch[1](6706/114412); Loss: 0.115026; Backpropagation: 0.2903 sec; Batch: 2.1163 sec
0.1805 0.1758 0.1578 0.1495 0.1330 0.1204 0.1105 0.1049 0.0991 0.0951 0.0913 0.0886 0.0858 0.0834 0.0827 0.0821 

[TRAIN] Epoch[1](6707/114412); Loss: 0.117536; Backpropagation: 0.2912 sec; Batch: 2.1225 sec
0.1832 0.1775 0.1660 0.1573 0.1366 0.1252 0.1146 0.1075 0.1017 0.0974 0.0928 0.0888 0.0862 0.0839 0.0817 0.0802 

[TRAIN] Epoch[1](6708/114412); Loss: 0.110788; Backpropagation: 0.2908 sec; Batch: 2.0808 sec
0.1894 0.1738 0.1449 0.1281 0.1177 0.1133 0.1043 0.0994 0.0938 0.0915 0.0894 0.0879 0.0869 0.0853 0.0838 0.0832 

[TRAIN] Epoch[1](6709/114412); Loss: 0.095721; Backpropagation: 0.2950 sec; Batch: 2.1009 sec
0.2042 0.1934 0.1348 0.1187 0.1056 0.0934 0.0838 0.0751 0.0706 0.0670 0.0653 0.0651 0.0638 0.0634 0.0639 0.0636 

[TRAIN] Epoch[1](6710/114412); Loss: 0.079627; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1404 0.1346 0.1058 0.0977 0.0850 0.0773 0.0710 0.0684 0.0656 0.0639 0.0627 0.0618 0.0606 0.0602 0.0598 0.0592 

[TRAIN] Epoch[1](6711/114412); Loss: 0.086709; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1402 0.1375 0.1179 0.1110 0.0950 0.0866 0.0806 0.0782 0.0739 0.0712 0.0685 0.0668 0.0660 0.0653 0.0646 0.0640 

[TRAIN] Epoch[1](6712/114412); Loss: 0.080864; Backpropagation: 0.2904 sec; Batch: 2.1162 sec
0.1441 0.1410 0.1064 0.0977 0.0869 0.0775 0.0730 0.0698 0.0671 0.0650 0.0634 0.0616 0.0604 0.0601 0.0599 0.0598 

[TRAIN] Epoch[1](6713/114412); Loss: 0.126435; Backpropagation: 0.2909 sec; Batch: 2.1185 sec
0.1912 0.1820 0.1663 0.1566 0.1417 0.1318 0.1246 0.1190 0.1124 0.1068 0.1041 0.1010 0.0991 0.0972 0.0953 0.0940 

[TRAIN] Epoch[1](6714/114412); Loss: 0.129706; Backpropagation: 0.2948 sec; Batch: 2.1233 sec
0.2065 0.1939 0.1727 0.1655 0.1485 0.1356 0.1259 0.1209 0.1131 0.1078 0.1028 0.0999 0.0976 0.0963 0.0947 0.0934 

[TRAIN] Epoch[1](6715/114412); Loss: 0.133436; Backpropagation: 0.2928 sec; Batch: 2.1021 sec
0.2080 0.1953 0.1762 0.1642 0.1487 0.1389 0.1307 0.1260 0.1188 0.1135 0.1095 0.1064 0.1032 0.1008 0.0985 0.0963 

[TRAIN] Epoch[1](6716/114412); Loss: 0.098221; Backpropagation: 0.2923 sec; Batch: 2.0969 sec
0.1478 0.1329 0.1148 0.1087 0.1031 0.0983 0.0946 0.0927 0.0886 0.0870 0.0860 0.0848 0.0843 0.0831 0.0826 0.0822 

[TRAIN] Epoch[1](6717/114412); Loss: 0.112679; Backpropagation: 0.2984 sec; Batch: 2.1003 sec
0.2106 0.2011 0.1617 0.1470 0.1253 0.1126 0.1021 0.0946 0.0893 0.0862 0.0830 0.0805 0.0788 0.0774 0.0765 0.0760 

[TRAIN] Epoch[1](6718/114412); Loss: 0.115700; Backpropagation: 0.2981 sec; Batch: 2.1374 sec
0.1809 0.1785 0.1655 0.1574 0.1378 0.1242 0.1129 0.1042 0.0974 0.0923 0.0884 0.0860 0.0835 0.0818 0.0807 0.0796 

[TRAIN] Epoch[1](6719/114412); Loss: 0.131908; Backpropagation: 0.3009 sec; Batch: 2.0915 sec
0.2006 0.1967 0.1842 0.1760 0.1619 0.1459 0.1319 0.1221 0.1131 0.1065 0.1018 0.0985 0.0953 0.0928 0.0923 0.0909 

[TRAIN] Epoch[1](6720/114412); Loss: 0.080546; Backpropagation: 0.2980 sec; Batch: 2.0872 sec
0.1483 0.1441 0.1186 0.1074 0.0913 0.0813 0.0731 0.0677 0.0640 0.0610 0.0587 0.0571 0.0557 0.0540 0.0535 0.0531 

[TRAIN] Epoch[1](6721/114412); Loss: 0.141294; Backpropagation: 0.3006 sec; Batch: 2.1270 sec
0.2207 0.2222 0.2062 0.1999 0.1745 0.1559 0.1402 0.1290 0.1210 0.1138 0.1082 0.1024 0.0981 0.0934 0.0892 0.0861 

[TRAIN] Epoch[1](6722/114412); Loss: 0.093944; Backpropagation: 0.2979 sec; Batch: 2.1273 sec
0.1852 0.1697 0.1414 0.1209 0.1055 0.0918 0.0824 0.0759 0.0707 0.0674 0.0668 0.0662 0.0655 0.0650 0.0644 0.0642 

[TRAIN] Epoch[1](6723/114412); Loss: 0.094541; Backpropagation: 0.3004 sec; Batch: 2.1236 sec
0.1425 0.1357 0.1179 0.1079 0.0984 0.0922 0.0891 0.0870 0.0840 0.0819 0.0805 0.0797 0.0794 0.0792 0.0787 0.0785 

[TRAIN] Epoch[1](6724/114412); Loss: 0.114761; Backpropagation: 0.3007 sec; Batch: 2.1252 sec
0.1751 0.1643 0.1381 0.1335 0.1243 0.1152 0.1110 0.1066 0.1039 0.1010 0.0983 0.0963 0.0945 0.0929 0.0913 0.0898 

[TRAIN] Epoch[1](6725/114412); Loss: 0.085120; Backpropagation: 0.2981 sec; Batch: 2.1272 sec
0.1431 0.1288 0.1049 0.0966 0.0869 0.0831 0.0783 0.0764 0.0746 0.0728 0.0715 0.0703 0.0694 0.0689 0.0683 0.0682 

[TRAIN] Epoch[1](6726/114412); Loss: 0.109720; Backpropagation: 0.2978 sec; Batch: 2.1270 sec
0.1544 0.1562 0.1431 0.1352 0.1227 0.1140 0.1057 0.1004 0.0967 0.0934 0.0913 0.0901 0.0887 0.0881 0.0878 0.0876 

[TRAIN] Epoch[1](6727/114412); Loss: 0.102070; Backpropagation: 0.2957 sec; Batch: 2.1202 sec
0.1718 0.1650 0.1448 0.1342 0.1156 0.1026 0.0946 0.0908 0.0859 0.0816 0.0787 0.0752 0.0734 0.0728 0.0729 0.0731 

[TRAIN] Epoch[1](6728/114412); Loss: 0.110082; Backpropagation: 0.2981 sec; Batch: 2.1279 sec
0.1773 0.1672 0.1403 0.1307 0.1189 0.1123 0.1029 0.1018 0.0978 0.0935 0.0913 0.0883 0.0863 0.0850 0.0838 0.0838 

[TRAIN] Epoch[1](6729/114412); Loss: 0.097893; Backpropagation: 0.2977 sec; Batch: 2.1246 sec
0.1471 0.1420 0.1248 0.1164 0.1048 0.0970 0.0911 0.0879 0.0855 0.0837 0.0822 0.0815 0.0808 0.0805 0.0804 0.0805 

[TRAIN] Epoch[1](6730/114412); Loss: 0.118549; Backpropagation: 0.2956 sec; Batch: 2.1240 sec
0.1725 0.1643 0.1498 0.1423 0.1287 0.1197 0.1124 0.1095 0.1060 0.1034 0.1011 0.0990 0.0982 0.0970 0.0966 0.0962 

[TRAIN] Epoch[1](6731/114412); Loss: 0.087557; Backpropagation: 0.2957 sec; Batch: 2.1201 sec
0.1327 0.1323 0.1092 0.1025 0.0984 0.0901 0.0837 0.0820 0.0773 0.0742 0.0721 0.0705 0.0692 0.0689 0.0687 0.0689 

[TRAIN] Epoch[1](6732/114412); Loss: 0.077748; Backpropagation: 0.2949 sec; Batch: 2.1209 sec
0.1101 0.1031 0.0946 0.0883 0.0840 0.0774 0.0743 0.0740 0.0704 0.0689 0.0676 0.0668 0.0666 0.0661 0.0659 0.0659 

[TRAIN] Epoch[1](6733/114412); Loss: 0.100784; Backpropagation: 0.2953 sec; Batch: 2.1257 sec
0.1591 0.1561 0.1342 0.1224 0.1104 0.1019 0.0939 0.0906 0.0866 0.0833 0.0818 0.0802 0.0792 0.0786 0.0777 0.0766 

[TRAIN] Epoch[1](6734/114412); Loss: 0.106284; Backpropagation: 0.2956 sec; Batch: 2.1257 sec
0.1923 0.1695 0.1414 0.1265 0.1131 0.1069 0.0986 0.0925 0.0888 0.0854 0.0834 0.0820 0.0812 0.0803 0.0797 0.0789 

[TRAIN] Epoch[1](6735/114412); Loss: 0.083997; Backpropagation: 0.2955 sec; Batch: 2.1252 sec
0.1486 0.1382 0.1181 0.1091 0.0947 0.0840 0.0755 0.0720 0.0677 0.0654 0.0641 0.0629 0.0622 0.0609 0.0605 0.0601 

[TRAIN] Epoch[1](6736/114412); Loss: 0.119257; Backpropagation: 0.2959 sec; Batch: 2.1222 sec
0.1862 0.1714 0.1486 0.1409 0.1279 0.1202 0.1134 0.1093 0.1048 0.1020 0.0998 0.0982 0.0974 0.0964 0.0961 0.0955 

[TRAIN] Epoch[1](6737/114412); Loss: 0.128083; Backpropagation: 0.2956 sec; Batch: 2.1220 sec
0.1811 0.1752 0.1532 0.1448 0.1363 0.1306 0.1251 0.1216 0.1178 0.1138 0.1110 0.1095 0.1087 0.1076 0.1066 0.1064 

[TRAIN] Epoch[1](6738/114412); Loss: 0.109796; Backpropagation: 0.2955 sec; Batch: 2.1215 sec
0.1805 0.1709 0.1455 0.1346 0.1209 0.1131 0.1038 0.0973 0.0932 0.0887 0.0868 0.0856 0.0850 0.0842 0.0835 0.0831 

[TRAIN] Epoch[1](6739/114412); Loss: 0.114974; Backpropagation: 0.2958 sec; Batch: 2.0854 sec
0.1836 0.1749 0.1489 0.1361 0.1225 0.1134 0.1063 0.1026 0.1000 0.0975 0.0959 0.0940 0.0923 0.0914 0.0905 0.0896 

[TRAIN] Epoch[1](6740/114412); Loss: 0.082650; Backpropagation: 0.2949 sec; Batch: 2.0821 sec
0.1458 0.1347 0.1080 0.0968 0.0853 0.0774 0.0723 0.0723 0.0695 0.0675 0.0673 0.0665 0.0656 0.0650 0.0643 0.0643 

[TRAIN] Epoch[1](6741/114412); Loss: 0.109420; Backpropagation: 0.2957 sec; Batch: 2.1262 sec
0.1508 0.1428 0.1330 0.1261 0.1139 0.1106 0.1049 0.1027 0.1002 0.0982 0.0970 0.0961 0.0944 0.0937 0.0934 0.0930 

[TRAIN] Epoch[1](6742/114412); Loss: 0.118933; Backpropagation: 0.2953 sec; Batch: 2.0818 sec
0.2241 0.2112 0.1736 0.1562 0.1302 0.1139 0.1035 0.0998 0.0972 0.0925 0.0896 0.0862 0.0833 0.0819 0.0806 0.0794 

[TRAIN] Epoch[1](6743/114412); Loss: 0.097345; Backpropagation: 0.2959 sec; Batch: 2.0840 sec
0.1748 0.1593 0.1315 0.1166 0.0995 0.0939 0.0874 0.0849 0.0817 0.0794 0.0774 0.0757 0.0750 0.0742 0.0734 0.0728 

[TRAIN] Epoch[1](6744/114412); Loss: 0.093847; Backpropagation: 0.2952 sec; Batch: 2.1203 sec
0.1355 0.1264 0.1158 0.1083 0.0983 0.0937 0.0885 0.0868 0.0837 0.0821 0.0814 0.0805 0.0803 0.0802 0.0800 0.0801 

[TRAIN] Epoch[1](6745/114412); Loss: 0.090520; Backpropagation: 0.2950 sec; Batch: 2.1253 sec
0.1559 0.1508 0.1343 0.1272 0.1087 0.0970 0.0868 0.0792 0.0716 0.0684 0.0655 0.0625 0.0612 0.0605 0.0596 0.0590 

[TRAIN] Epoch[1](6746/114412); Loss: 0.116031; Backpropagation: 0.2977 sec; Batch: 2.1238 sec
0.2242 0.2077 0.1665 0.1507 0.1292 0.1183 0.1074 0.1015 0.0938 0.0884 0.0840 0.0811 0.0779 0.0762 0.0754 0.0742 

[TRAIN] Epoch[1](6747/114412); Loss: 0.090534; Backpropagation: 0.2982 sec; Batch: 2.1097 sec
0.1338 0.1185 0.1051 0.0981 0.0910 0.0892 0.0852 0.0846 0.0833 0.0815 0.0805 0.0795 0.0792 0.0796 0.0797 0.0798 

[TRAIN] Epoch[1](6748/114412); Loss: 0.113142; Backpropagation: 0.2978 sec; Batch: 2.1216 sec
0.1773 0.1620 0.1444 0.1338 0.1187 0.1098 0.1007 0.0985 0.0969 0.0958 0.0951 0.0945 0.0948 0.0953 0.0960 0.0966 

[TRAIN] Epoch[1](6749/114412); Loss: 0.081674; Backpropagation: 0.2982 sec; Batch: 2.1362 sec
0.1639 0.1470 0.1085 0.0940 0.0867 0.0782 0.0715 0.0673 0.0642 0.0627 0.0617 0.0611 0.0603 0.0601 0.0598 0.0597 

[TRAIN] Epoch[1](6750/114412); Loss: 0.097332; Backpropagation: 0.2956 sec; Batch: 2.1245 sec
0.1582 0.1488 0.1401 0.1266 0.1097 0.1005 0.0908 0.0851 0.0804 0.0771 0.0753 0.0742 0.0732 0.0728 0.0724 0.0720 

[TRAIN] Epoch[1](6751/114412); Loss: 0.130855; Backpropagation: 0.2982 sec; Batch: 2.1259 sec
0.2136 0.2021 0.1799 0.1743 0.1541 0.1427 0.1301 0.1211 0.1123 0.1065 0.1024 0.0975 0.0936 0.0904 0.0875 0.0859 

[TRAIN] Epoch[1](6752/114412); Loss: 0.144333; Backpropagation: 0.2956 sec; Batch: 2.1204 sec
0.2336 0.2222 0.2045 0.1964 0.1772 0.1637 0.1490 0.1362 0.1238 0.1147 0.1087 0.1035 0.0994 0.0952 0.0920 0.0892 

[TRAIN] Epoch[1](6753/114412); Loss: 0.092698; Backpropagation: 0.2954 sec; Batch: 2.1217 sec
0.1502 0.1423 0.1243 0.1161 0.1043 0.0964 0.0879 0.0837 0.0787 0.0753 0.0738 0.0722 0.0707 0.0696 0.0691 0.0688 

[TRAIN] Epoch[1](6754/114412); Loss: 0.091090; Backpropagation: 0.2953 sec; Batch: 2.1210 sec
0.1519 0.1413 0.1144 0.1049 0.0944 0.0868 0.0809 0.0806 0.0781 0.0767 0.0759 0.0748 0.0749 0.0743 0.0737 0.0737 

[TRAIN] Epoch[1](6755/114412); Loss: 0.112674; Backpropagation: 0.2957 sec; Batch: 2.1235 sec
0.1745 0.1632 0.1484 0.1399 0.1254 0.1158 0.1077 0.1027 0.0981 0.0945 0.0917 0.0903 0.0889 0.0882 0.0872 0.0863 

[TRAIN] Epoch[1](6756/114412); Loss: 0.150189; Backpropagation: 0.2950 sec; Batch: 2.1225 sec
0.2719 0.2592 0.2293 0.2205 0.1910 0.1690 0.1491 0.1339 0.1207 0.1122 0.1051 0.0977 0.0919 0.0868 0.0836 0.0813 

[TRAIN] Epoch[1](6757/114412); Loss: 0.157930; Backpropagation: 0.2955 sec; Batch: 2.1118 sec
0.2439 0.2376 0.2087 0.2022 0.1828 0.1721 0.1595 0.1486 0.1396 0.1314 0.1258 0.1215 0.1179 0.1143 0.1117 0.1094 

[TRAIN] Epoch[1](6758/114412); Loss: 0.085727; Backpropagation: 0.3005 sec; Batch: 2.1304 sec
0.1607 0.1536 0.1194 0.1045 0.0923 0.0859 0.0762 0.0722 0.0700 0.0660 0.0649 0.0629 0.0619 0.0609 0.0602 0.0598 

[TRAIN] Epoch[1](6759/114412); Loss: 0.066297; Backpropagation: 0.2978 sec; Batch: 2.1218 sec
0.1304 0.1242 0.0833 0.0744 0.0646 0.0582 0.0559 0.0538 0.0524 0.0523 0.0517 0.0522 0.0522 0.0517 0.0517 0.0517 

[TRAIN] Epoch[1](6760/114412); Loss: 0.106922; Backpropagation: 0.2958 sec; Batch: 2.1236 sec
0.1973 0.1866 0.1547 0.1358 0.1173 0.1042 0.0951 0.0890 0.0851 0.0822 0.0805 0.0781 0.0771 0.0761 0.0759 0.0755 

[TRAIN] Epoch[1](6761/114412); Loss: 0.112146; Backpropagation: 0.2978 sec; Batch: 2.1237 sec
0.1828 0.1709 0.1452 0.1334 0.1198 0.1098 0.1030 0.1005 0.0966 0.0942 0.0925 0.0906 0.0895 0.0890 0.0885 0.0881 

[TRAIN] Epoch[1](6762/114412); Loss: 0.099503; Backpropagation: 0.2982 sec; Batch: 2.1157 sec
0.1455 0.1453 0.1305 0.1222 0.1109 0.1019 0.0964 0.0917 0.0882 0.0850 0.0825 0.0805 0.0790 0.0783 0.0773 0.0767 

[TRAIN] Epoch[1](6763/114412); Loss: 0.099291; Backpropagation: 0.2955 sec; Batch: 2.1203 sec
0.1380 0.1325 0.1203 0.1101 0.1004 0.0936 0.0906 0.0920 0.0903 0.0904 0.0911 0.0904 0.0890 0.0875 0.0867 0.0858 

[TRAIN] Epoch[1](6764/114412); Loss: 0.112600; Backpropagation: 0.2952 sec; Batch: 2.1212 sec
0.1553 0.1489 0.1358 0.1292 0.1208 0.1133 0.1078 0.1054 0.1014 0.1000 0.0990 0.0984 0.0977 0.0967 0.0961 0.0959 

[TRAIN] Epoch[1](6765/114412); Loss: 0.107266; Backpropagation: 0.3009 sec; Batch: 2.1231 sec
0.1834 0.1770 0.1523 0.1419 0.1224 0.1084 0.0975 0.0916 0.0865 0.0831 0.0819 0.0802 0.0791 0.0781 0.0768 0.0760 

[TRAIN] Epoch[1](6766/114412); Loss: 0.107640; Backpropagation: 0.2953 sec; Batch: 2.1243 sec
0.1606 0.1475 0.1366 0.1260 0.1149 0.1082 0.1030 0.1000 0.0964 0.0932 0.0916 0.0900 0.0891 0.0886 0.0882 0.0882 

[TRAIN] Epoch[1](6767/114412); Loss: 0.080925; Backpropagation: 0.2956 sec; Batch: 2.0836 sec
0.1355 0.1214 0.1051 0.0983 0.0882 0.0817 0.0748 0.0729 0.0699 0.0668 0.0651 0.0643 0.0638 0.0629 0.0623 0.0617 

[TRAIN] Epoch[1](6768/114412); Loss: 0.113793; Backpropagation: 0.3006 sec; Batch: 2.1283 sec
0.1909 0.1776 0.1527 0.1421 0.1250 0.1134 0.1053 0.1002 0.0961 0.0933 0.0906 0.0888 0.0877 0.0866 0.0856 0.0848 

[TRAIN] Epoch[1](6769/114412); Loss: 0.118864; Backpropagation: 0.2956 sec; Batch: 2.1236 sec
0.1999 0.1832 0.1552 0.1448 0.1307 0.1201 0.1110 0.1055 0.1011 0.0982 0.0965 0.0944 0.0919 0.0911 0.0895 0.0888 

[TRAIN] Epoch[1](6770/114412); Loss: 0.127255; Backpropagation: 0.2959 sec; Batch: 2.1690 sec
0.1840 0.1701 0.1592 0.1499 0.1362 0.1248 0.1179 0.1159 0.1135 0.1116 0.1105 0.1099 0.1091 0.1082 0.1078 0.1073 

[TRAIN] Epoch[1](6771/114412); Loss: 0.095830; Backpropagation: 0.2962 sec; Batch: 2.1245 sec
0.1545 0.1363 0.1144 0.1059 0.0980 0.0940 0.0904 0.0886 0.0855 0.0833 0.0820 0.0811 0.0806 0.0801 0.0795 0.0792 

[TRAIN] Epoch[1](6772/114412); Loss: 0.085848; Backpropagation: 0.2956 sec; Batch: 2.1232 sec
0.1254 0.1189 0.1078 0.0987 0.0899 0.0858 0.0818 0.0800 0.0774 0.0752 0.0739 0.0731 0.0723 0.0717 0.0712 0.0704 

[TRAIN] Epoch[1](6773/114412); Loss: 0.109990; Backpropagation: 0.2952 sec; Batch: 2.0910 sec
0.1982 0.1863 0.1576 0.1459 0.1245 0.1112 0.1000 0.0932 0.0881 0.0850 0.0818 0.0801 0.0783 0.0773 0.0766 0.0756 

[TRAIN] Epoch[1](6774/114412); Loss: 0.176165; Backpropagation: 0.2951 sec; Batch: 2.0923 sec
0.2628 0.2524 0.2243 0.2138 0.1944 0.1822 0.1711 0.1633 0.1590 0.1526 0.1481 0.1440 0.1403 0.1388 0.1367 0.1348 

[TRAIN] Epoch[1](6775/114412); Loss: 0.104823; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1712 0.1631 0.1410 0.1314 0.1132 0.1029 0.0960 0.0924 0.0891 0.0862 0.0844 0.0826 0.0818 0.0813 0.0806 0.0802 

[TRAIN] Epoch[1](6776/114412); Loss: 0.132052; Backpropagation: 0.2913 sec; Batch: 2.0767 sec
0.2149 0.2061 0.1827 0.1774 0.1573 0.1413 0.1312 0.1206 0.1129 0.1056 0.1008 0.0969 0.0943 0.0919 0.0902 0.0888 

[TRAIN] Epoch[1](6777/114412); Loss: 0.105497; Backpropagation: 0.2916 sec; Batch: 2.1011 sec
0.1748 0.1642 0.1408 0.1294 0.1150 0.1064 0.0995 0.0945 0.0903 0.0871 0.0851 0.0830 0.0810 0.0799 0.0786 0.0783 

[TRAIN] Epoch[1](6778/114412); Loss: 0.106121; Backpropagation: 0.2954 sec; Batch: 2.1316 sec
0.1595 0.1529 0.1296 0.1206 0.1131 0.1037 0.0985 0.0964 0.0941 0.0925 0.0914 0.0902 0.0895 0.0892 0.0885 0.0880 

[TRAIN] Epoch[1](6779/114412); Loss: 0.112383; Backpropagation: 0.2926 sec; Batch: 2.1228 sec
0.1591 0.1471 0.1422 0.1347 0.1258 0.1181 0.1109 0.1062 0.1017 0.0992 0.0963 0.0936 0.0921 0.0908 0.0904 0.0899 

[TRAIN] Epoch[1](6780/114412); Loss: 0.148723; Backpropagation: 0.2951 sec; Batch: 2.1199 sec
0.2294 0.2155 0.1888 0.1800 0.1630 0.1496 0.1395 0.1342 0.1298 0.1264 0.1252 0.1237 0.1213 0.1196 0.1176 0.1160 

[TRAIN] Epoch[1](6781/114412); Loss: 0.108325; Backpropagation: 0.2928 sec; Batch: 2.1204 sec
0.1753 0.1627 0.1394 0.1270 0.1138 0.1055 0.0991 0.0976 0.0945 0.0911 0.0902 0.0887 0.0882 0.0873 0.0867 0.0864 

[TRAIN] Epoch[1](6782/114412); Loss: 0.083992; Backpropagation: 0.2954 sec; Batch: 2.1032 sec
0.1602 0.1549 0.1157 0.1003 0.0884 0.0792 0.0733 0.0697 0.0671 0.0655 0.0637 0.0627 0.0615 0.0608 0.0606 0.0604 

[TRAIN] Epoch[1](6783/114412); Loss: 0.105686; Backpropagation: 0.2910 sec; Batch: 2.1122 sec
0.1620 0.1536 0.1378 0.1298 0.1144 0.1051 0.0986 0.0956 0.0919 0.0897 0.0882 0.0871 0.0856 0.0847 0.0840 0.0832 

[TRAIN] Epoch[1](6784/114412); Loss: 0.143520; Backpropagation: 0.2906 sec; Batch: 2.1178 sec
0.2245 0.2178 0.2007 0.1909 0.1675 0.1511 0.1373 0.1287 0.1224 0.1174 0.1135 0.1097 0.1065 0.1040 0.1026 0.1017 

[TRAIN] Epoch[1](6785/114412); Loss: 0.136091; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.2021 0.1953 0.1767 0.1657 0.1513 0.1421 0.1327 0.1261 0.1206 0.1161 0.1131 0.1105 0.1084 0.1069 0.1052 0.1047 

[TRAIN] Epoch[1](6786/114412); Loss: 0.112836; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1767 0.1643 0.1467 0.1352 0.1227 0.1192 0.1089 0.1012 0.0983 0.0942 0.0932 0.0911 0.0895 0.0892 0.0878 0.0871 

[TRAIN] Epoch[1](6787/114412); Loss: 0.111250; Backpropagation: 0.2928 sec; Batch: 2.1462 sec
0.1876 0.1786 0.1547 0.1430 0.1238 0.1140 0.1023 0.0967 0.0919 0.0884 0.0875 0.0853 0.0835 0.0815 0.0809 0.0801 

[TRAIN] Epoch[1](6788/114412); Loss: 0.130068; Backpropagation: 0.2911 sec; Batch: 2.1155 sec
0.2586 0.2431 0.2015 0.1889 0.1584 0.1410 0.1204 0.1053 0.0969 0.0898 0.0870 0.0834 0.0802 0.0776 0.0755 0.0738 

[TRAIN] Epoch[1](6789/114412); Loss: 0.119198; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.1819 0.1703 0.1539 0.1446 0.1318 0.1238 0.1166 0.1114 0.1052 0.1020 0.0994 0.0974 0.0953 0.0936 0.0910 0.0889 

[TRAIN] Epoch[1](6790/114412); Loss: 0.079772; Backpropagation: 0.2910 sec; Batch: 2.1188 sec
0.1554 0.1397 0.1165 0.1035 0.0885 0.0785 0.0704 0.0668 0.0625 0.0588 0.0571 0.0561 0.0557 0.0555 0.0556 0.0556 

[TRAIN] Epoch[1](6791/114412); Loss: 0.086255; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1394 0.1271 0.1146 0.1068 0.0953 0.0866 0.0802 0.0777 0.0753 0.0731 0.0712 0.0693 0.0674 0.0665 0.0654 0.0640 

[TRAIN] Epoch[1](6792/114412); Loss: 0.138818; Backpropagation: 0.2952 sec; Batch: 2.1243 sec
0.2143 0.2036 0.1848 0.1765 0.1602 0.1481 0.1351 0.1278 0.1201 0.1145 0.1119 0.1084 0.1062 0.1048 0.1031 0.1018 

[TRAIN] Epoch[1](6793/114412); Loss: 0.109637; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.2137 0.2009 0.1717 0.1574 0.1314 0.1120 0.0978 0.0884 0.0810 0.0769 0.0741 0.0719 0.0708 0.0695 0.0684 0.0682 

[TRAIN] Epoch[1](6794/114412); Loss: 0.091979; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1596 0.1523 0.1171 0.1032 0.0937 0.0862 0.0818 0.0796 0.0772 0.0759 0.0749 0.0742 0.0740 0.0743 0.0739 0.0738 

[TRAIN] Epoch[1](6795/114412); Loss: 0.125721; Backpropagation: 0.2954 sec; Batch: 2.1224 sec
0.2372 0.2175 0.1830 0.1689 0.1436 0.1239 0.1105 0.1024 0.0985 0.0944 0.0920 0.0908 0.0890 0.0873 0.0866 0.0859 

[TRAIN] Epoch[1](6796/114412); Loss: 0.122888; Backpropagation: 0.2915 sec; Batch: 2.0813 sec
0.1959 0.1821 0.1679 0.1574 0.1397 0.1255 0.1160 0.1104 0.1055 0.1014 0.0979 0.0961 0.0939 0.0929 0.0920 0.0916 

[TRAIN] Epoch[1](6797/114412); Loss: 0.149600; Backpropagation: 0.2910 sec; Batch: 2.0787 sec
0.2512 0.2393 0.2187 0.2115 0.1845 0.1674 0.1509 0.1365 0.1265 0.1181 0.1115 0.1046 0.0990 0.0936 0.0906 0.0897 

[TRAIN] Epoch[1](6798/114412); Loss: 0.081167; Backpropagation: 0.2906 sec; Batch: 2.1161 sec
0.1481 0.1405 0.1046 0.0926 0.0820 0.0763 0.0712 0.0690 0.0671 0.0655 0.0642 0.0640 0.0639 0.0635 0.0631 0.0633 

[TRAIN] Epoch[1](6799/114412); Loss: 0.147791; Backpropagation: 0.2912 sec; Batch: 2.0774 sec
0.2486 0.2361 0.2115 0.1950 0.1711 0.1550 0.1408 0.1308 0.1229 0.1160 0.1114 0.1077 0.1065 0.1052 0.1038 0.1024 

[TRAIN] Epoch[1](6800/114412); Loss: 0.096452; Backpropagation: 0.2911 sec; Batch: 2.1153 sec
0.1644 0.1533 0.1289 0.1178 0.1042 0.0964 0.0897 0.0866 0.0821 0.0793 0.0771 0.0749 0.0735 0.0726 0.0715 0.0708 

[TRAIN] Epoch[1](6801/114412); Loss: 0.087879; Backpropagation: 0.2908 sec; Batch: 2.1157 sec
0.1667 0.1575 0.1196 0.1081 0.0938 0.0841 0.0762 0.0726 0.0696 0.0679 0.0665 0.0654 0.0652 0.0647 0.0642 0.0641 

[TRAIN] Epoch[1](6802/114412); Loss: 0.139195; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.2322 0.2255 0.2080 0.2012 0.1762 0.1593 0.1425 0.1298 0.1162 0.1053 0.0986 0.0935 0.0898 0.0857 0.0832 0.0800 

[TRAIN] Epoch[1](6803/114412); Loss: 0.091185; Backpropagation: 0.2905 sec; Batch: 2.1185 sec
0.1647 0.1569 0.1334 0.1235 0.1031 0.0899 0.0812 0.0768 0.0730 0.0702 0.0680 0.0654 0.0642 0.0633 0.0629 0.0623 

[TRAIN] Epoch[1](6804/114412); Loss: 0.101369; Backpropagation: 0.2934 sec; Batch: 2.1793 sec
0.1598 0.1519 0.1315 0.1206 0.1086 0.1021 0.0970 0.0928 0.0874 0.0847 0.0834 0.0816 0.0809 0.0800 0.0798 0.0798 

[TRAIN] Epoch[1](6805/114412); Loss: 0.115729; Backpropagation: 0.2923 sec; Batch: 2.1210 sec
0.1903 0.1767 0.1535 0.1442 0.1314 0.1197 0.1087 0.1049 0.0994 0.0949 0.0917 0.0902 0.0889 0.0871 0.0855 0.0844 

[TRAIN] Epoch[1](6806/114412); Loss: 0.099655; Backpropagation: 0.2912 sec; Batch: 2.1271 sec
0.1440 0.1357 0.1233 0.1171 0.1089 0.1025 0.0963 0.0925 0.0899 0.0880 0.0853 0.0838 0.0824 0.0819 0.0815 0.0814 

[TRAIN] Epoch[1](6807/114412); Loss: 0.089935; Backpropagation: 0.2945 sec; Batch: 2.1246 sec
0.1712 0.1550 0.1239 0.1132 0.0975 0.0882 0.0803 0.0766 0.0729 0.0706 0.0683 0.0661 0.0649 0.0642 0.0634 0.0629 

[TRAIN] Epoch[1](6808/114412); Loss: 0.126624; Backpropagation: 0.2907 sec; Batch: 2.1147 sec
0.2096 0.1996 0.1647 0.1510 0.1365 0.1251 0.1183 0.1124 0.1077 0.1052 0.1029 0.1008 0.0994 0.0983 0.0975 0.0968 

[TRAIN] Epoch[1](6809/114412); Loss: 0.079629; Backpropagation: 0.2910 sec; Batch: 2.1196 sec
0.1305 0.1216 0.1049 0.0958 0.0852 0.0776 0.0721 0.0707 0.0680 0.0658 0.0647 0.0642 0.0635 0.0634 0.0630 0.0630 

[TRAIN] Epoch[1](6810/114412); Loss: 0.110843; Backpropagation: 0.2913 sec; Batch: 2.1101 sec
0.1982 0.1827 0.1586 0.1505 0.1284 0.1143 0.1042 0.0968 0.0912 0.0862 0.0819 0.0791 0.0773 0.0758 0.0746 0.0736 

[TRAIN] Epoch[1](6811/114412); Loss: 0.090391; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1675 0.1583 0.1252 0.1092 0.0915 0.0836 0.0786 0.0759 0.0719 0.0713 0.0702 0.0694 0.0692 0.0686 0.0681 0.0679 

[TRAIN] Epoch[1](6812/114412); Loss: 0.098338; Backpropagation: 0.2930 sec; Batch: 2.1221 sec
0.1532 0.1382 0.1191 0.1148 0.1034 0.0964 0.0904 0.0897 0.0867 0.0852 0.0842 0.0834 0.0830 0.0825 0.0818 0.0816 

[TRAIN] Epoch[1](6813/114412); Loss: 0.091507; Backpropagation: 0.2932 sec; Batch: 2.1186 sec
0.1786 0.1611 0.1274 0.1163 0.0995 0.0902 0.0814 0.0777 0.0729 0.0698 0.0679 0.0662 0.0651 0.0641 0.0631 0.0626 

[TRAIN] Epoch[1](6814/114412); Loss: 0.133131; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.2187 0.2071 0.1871 0.1762 0.1591 0.1460 0.1339 0.1248 0.1153 0.1078 0.1024 0.0972 0.0931 0.0896 0.0868 0.0849 

[TRAIN] Epoch[1](6815/114412); Loss: 0.129056; Backpropagation: 0.2907 sec; Batch: 2.1129 sec
0.2050 0.1898 0.1660 0.1540 0.1366 0.1268 0.1195 0.1152 0.1122 0.1090 0.1071 0.1064 0.1057 0.1045 0.1039 0.1033 

[TRAIN] Epoch[1](6816/114412); Loss: 0.083729; Backpropagation: 0.2909 sec; Batch: 2.1147 sec
0.1371 0.1265 0.1052 0.0960 0.0886 0.0819 0.0777 0.0790 0.0739 0.0711 0.0697 0.0684 0.0675 0.0665 0.0655 0.0650 

[TRAIN] Epoch[1](6817/114412); Loss: 0.132607; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.2238 0.2139 0.1887 0.1758 0.1542 0.1378 0.1245 0.1152 0.1090 0.1035 0.1004 0.0975 0.0963 0.0949 0.0933 0.0930 

[TRAIN] Epoch[1](6818/114412); Loss: 0.086311; Backpropagation: 0.2917 sec; Batch: 2.1221 sec
0.1678 0.1528 0.1213 0.1113 0.0936 0.0827 0.0763 0.0725 0.0682 0.0663 0.0636 0.0626 0.0615 0.0608 0.0601 0.0596 

[TRAIN] Epoch[1](6819/114412); Loss: 0.086006; Backpropagation: 0.2908 sec; Batch: 2.0778 sec
0.1338 0.1213 0.1080 0.0980 0.0909 0.0834 0.0802 0.0791 0.0763 0.0754 0.0739 0.0730 0.0718 0.0709 0.0703 0.0699 

[TRAIN] Epoch[1](6820/114412); Loss: 0.122997; Backpropagation: 0.2909 sec; Batch: 2.1119 sec
0.1881 0.1808 0.1606 0.1509 0.1341 0.1242 0.1165 0.1114 0.1081 0.1044 0.1022 0.0999 0.0979 0.0969 0.0963 0.0957 

[TRAIN] Epoch[1](6821/114412); Loss: 0.122591; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.2155 0.2030 0.1767 0.1680 0.1480 0.1300 0.1190 0.1096 0.1019 0.0953 0.0895 0.0856 0.0826 0.0803 0.0786 0.0779 

[TRAIN] Epoch[1](6822/114412); Loss: 0.071276; Backpropagation: 0.2931 sec; Batch: 2.1229 sec
0.1190 0.1112 0.0934 0.0881 0.0761 0.0704 0.0648 0.0628 0.0598 0.0587 0.0576 0.0565 0.0561 0.0555 0.0552 0.0552 

[TRAIN] Epoch[1](6823/114412); Loss: 0.181353; Backpropagation: 0.2911 sec; Batch: 2.1220 sec
0.2822 0.2800 0.2490 0.2342 0.2095 0.1882 0.1790 0.1666 0.1585 0.1500 0.1443 0.1404 0.1371 0.1326 0.1277 0.1223 

[TRAIN] Epoch[1](6824/114412); Loss: 0.095990; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1618 0.1501 0.1346 0.1253 0.1091 0.0955 0.0869 0.0843 0.0793 0.0762 0.0741 0.0725 0.0721 0.0719 0.0712 0.0709 

[TRAIN] Epoch[1](6825/114412); Loss: 0.112268; Backpropagation: 0.2914 sec; Batch: 2.1137 sec
0.1754 0.1628 0.1461 0.1367 0.1232 0.1139 0.1065 0.1034 0.0987 0.0956 0.0926 0.0903 0.0893 0.0879 0.0871 0.0867 

[TRAIN] Epoch[1](6826/114412); Loss: 0.114083; Backpropagation: 0.2915 sec; Batch: 2.1216 sec
0.2102 0.1799 0.1524 0.1399 0.1194 0.1098 0.1032 0.0995 0.0960 0.0922 0.0907 0.0879 0.0873 0.0864 0.0855 0.0849 

[TRAIN] Epoch[1](6827/114412); Loss: 0.095875; Backpropagation: 0.2914 sec; Batch: 2.1494 sec
0.1757 0.1723 0.1434 0.1299 0.1113 0.0984 0.0881 0.0803 0.0737 0.0704 0.0681 0.0663 0.0652 0.0643 0.0636 0.0631 

[TRAIN] Epoch[1](6828/114412); Loss: 0.109006; Backpropagation: 0.2910 sec; Batch: 2.1170 sec
0.1831 0.1723 0.1497 0.1404 0.1222 0.1107 0.1011 0.0955 0.0911 0.0875 0.0848 0.0840 0.0826 0.0801 0.0798 0.0793 

[TRAIN] Epoch[1](6829/114412); Loss: 0.080395; Backpropagation: 0.2914 sec; Batch: 2.1180 sec
0.1506 0.1370 0.1139 0.1011 0.0879 0.0784 0.0691 0.0669 0.0637 0.0622 0.0611 0.0602 0.0595 0.0589 0.0585 0.0575 

[TRAIN] Epoch[1](6830/114412); Loss: 0.096879; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1641 0.1464 0.1161 0.1025 0.0941 0.0905 0.0900 0.0884 0.0861 0.0844 0.0828 0.0822 0.0817 0.0810 0.0801 0.0797 

[TRAIN] Epoch[1](6831/114412); Loss: 0.105168; Backpropagation: 0.2955 sec; Batch: 2.1232 sec
0.1770 0.1569 0.1361 0.1242 0.1140 0.1038 0.0971 0.0938 0.0908 0.0874 0.0861 0.0848 0.0838 0.0827 0.0821 0.0821 

[TRAIN] Epoch[1](6832/114412); Loss: 0.119428; Backpropagation: 0.2952 sec; Batch: 2.1239 sec
0.2059 0.1932 0.1710 0.1601 0.1391 0.1244 0.1133 0.1047 0.0975 0.0929 0.0896 0.0867 0.0846 0.0838 0.0826 0.0815 

[TRAIN] Epoch[1](6833/114412); Loss: 0.102260; Backpropagation: 0.2931 sec; Batch: 2.1178 sec
0.1402 0.1289 0.1225 0.1151 0.1048 0.1020 0.0970 0.0952 0.0953 0.0924 0.0917 0.0908 0.0901 0.0900 0.0898 0.0901 

[TRAIN] Epoch[1](6834/114412); Loss: 0.105715; Backpropagation: 0.2913 sec; Batch: 2.1248 sec
0.1846 0.1691 0.1453 0.1323 0.1147 0.1062 0.0979 0.0948 0.0887 0.0852 0.0828 0.0801 0.0786 0.0776 0.0770 0.0765 

[TRAIN] Epoch[1](6835/114412); Loss: 0.076727; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.1225 0.1122 0.0971 0.0913 0.0811 0.0748 0.0707 0.0701 0.0671 0.0657 0.0642 0.0631 0.0624 0.0623 0.0617 0.0615 

[TRAIN] Epoch[1](6836/114412); Loss: 0.095302; Backpropagation: 0.2914 sec; Batch: 2.1174 sec
0.1529 0.1497 0.1279 0.1159 0.1033 0.0949 0.0875 0.0852 0.0804 0.0787 0.0773 0.0756 0.0749 0.0739 0.0734 0.0732 

[TRAIN] Epoch[1](6837/114412); Loss: 0.144529; Backpropagation: 0.2912 sec; Batch: 2.1292 sec
0.2350 0.2283 0.2029 0.1923 0.1691 0.1516 0.1374 0.1280 0.1216 0.1141 0.1120 0.1093 0.1058 0.1038 0.1016 0.0997 

[TRAIN] Epoch[1](6838/114412); Loss: 0.112547; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1975 0.1795 0.1513 0.1377 0.1235 0.1102 0.1026 0.0999 0.0960 0.0925 0.0894 0.0869 0.0847 0.0838 0.0827 0.0826 

[TRAIN] Epoch[1](6839/114412); Loss: 0.111796; Backpropagation: 0.2913 sec; Batch: 2.1200 sec
0.2151 0.1996 0.1695 0.1541 0.1245 0.1045 0.0946 0.0921 0.0872 0.0851 0.0815 0.0790 0.0772 0.0762 0.0749 0.0738 

[TRAIN] Epoch[1](6840/114412); Loss: 0.114239; Backpropagation: 0.2911 sec; Batch: 2.1138 sec
0.1854 0.1738 0.1567 0.1468 0.1305 0.1181 0.1085 0.1039 0.0985 0.0934 0.0905 0.0879 0.0856 0.0840 0.0827 0.0816 

[TRAIN] Epoch[1](6841/114412); Loss: 0.114501; Backpropagation: 0.2907 sec; Batch: 2.1145 sec
0.2110 0.1917 0.1620 0.1465 0.1271 0.1140 0.1034 0.0959 0.0927 0.0886 0.0860 0.0844 0.0834 0.0824 0.0818 0.0809 

[TRAIN] Epoch[1](6842/114412); Loss: 0.098781; Backpropagation: 0.2914 sec; Batch: 2.1192 sec
0.1649 0.1441 0.1216 0.1075 0.0988 0.0934 0.0897 0.0896 0.0870 0.0855 0.0847 0.0835 0.0829 0.0827 0.0823 0.0821 

[TRAIN] Epoch[1](6843/114412); Loss: 0.083970; Backpropagation: 0.2915 sec; Batch: 2.1204 sec
0.1517 0.1416 0.1144 0.1031 0.0896 0.0778 0.0742 0.0715 0.0684 0.0662 0.0656 0.0650 0.0642 0.0633 0.0633 0.0635 

[TRAIN] Epoch[1](6844/114412); Loss: 0.116672; Backpropagation: 0.2925 sec; Batch: 2.1178 sec
0.1950 0.1815 0.1554 0.1378 0.1277 0.1150 0.1069 0.1040 0.0994 0.0968 0.0951 0.0925 0.0911 0.0904 0.0893 0.0889 

[TRAIN] Epoch[1](6845/114412); Loss: 0.094098; Backpropagation: 0.2912 sec; Batch: 2.1197 sec
0.1398 0.1266 0.1213 0.1105 0.1002 0.0945 0.0909 0.0877 0.0842 0.0823 0.0808 0.0791 0.0781 0.0772 0.0765 0.0759 

[TRAIN] Epoch[1](6846/114412); Loss: 0.090533; Backpropagation: 0.2929 sec; Batch: 2.1191 sec
0.1462 0.1229 0.1128 0.1032 0.0942 0.0883 0.0837 0.0818 0.0799 0.0789 0.0778 0.0769 0.0761 0.0756 0.0751 0.0749 

[TRAIN] Epoch[1](6847/114412); Loss: 0.102574; Backpropagation: 0.2917 sec; Batch: 2.1172 sec
0.1740 0.1623 0.1402 0.1279 0.1085 0.0986 0.0918 0.0912 0.0867 0.0842 0.0827 0.0801 0.0798 0.0785 0.0774 0.0773 

[TRAIN] Epoch[1](6848/114412); Loss: 0.088284; Backpropagation: 0.2912 sec; Batch: 2.1214 sec
0.1473 0.1443 0.1160 0.1035 0.0901 0.0839 0.0797 0.0772 0.0758 0.0735 0.0720 0.0713 0.0707 0.0697 0.0688 0.0685 

[TRAIN] Epoch[1](6849/114412); Loss: 0.098062; Backpropagation: 0.2909 sec; Batch: 2.0967 sec
0.1571 0.1483 0.1358 0.1209 0.1052 0.0960 0.0882 0.0866 0.0843 0.0815 0.0799 0.0788 0.0780 0.0772 0.0763 0.0749 

[TRAIN] Epoch[1](6850/114412); Loss: 0.099837; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1821 0.1613 0.1360 0.1244 0.1082 0.0953 0.0886 0.0852 0.0815 0.0794 0.0781 0.0767 0.0758 0.0753 0.0748 0.0746 

[TRAIN] Epoch[1](6851/114412); Loss: 0.100489; Backpropagation: 0.2907 sec; Batch: 2.1171 sec
0.1777 0.1657 0.1377 0.1225 0.1082 0.1007 0.0896 0.0848 0.0829 0.0793 0.0791 0.0774 0.0762 0.0760 0.0753 0.0748 

[TRAIN] Epoch[1](6852/114412); Loss: 0.113778; Backpropagation: 0.2913 sec; Batch: 2.1205 sec
0.1756 0.1639 0.1455 0.1340 0.1235 0.1157 0.1093 0.1040 0.1002 0.0966 0.0948 0.0932 0.0921 0.0912 0.0907 0.0903 

[TRAIN] Epoch[1](6853/114412); Loss: 0.111388; Backpropagation: 0.2911 sec; Batch: 2.0797 sec
0.1841 0.1734 0.1504 0.1377 0.1224 0.1126 0.1038 0.0987 0.0940 0.0914 0.0892 0.0872 0.0863 0.0846 0.0836 0.0830 

[TRAIN] Epoch[1](6854/114412); Loss: 0.092319; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.1722 0.1638 0.1209 0.1127 0.0915 0.0851 0.0807 0.0764 0.0756 0.0743 0.0727 0.0712 0.0706 0.0698 0.0699 0.0697 

[TRAIN] Epoch[1](6855/114412); Loss: 0.078379; Backpropagation: 0.2910 sec; Batch: 2.1186 sec
0.1457 0.1338 0.1005 0.0890 0.0765 0.0716 0.0670 0.0663 0.0648 0.0638 0.0628 0.0623 0.0624 0.0624 0.0627 0.0625 

[TRAIN] Epoch[1](6856/114412); Loss: 0.138139; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.2316 0.2186 0.1969 0.1834 0.1643 0.1511 0.1392 0.1299 0.1205 0.1109 0.1049 0.1009 0.0955 0.0912 0.0876 0.0838 

[TRAIN] Epoch[1](6857/114412); Loss: 0.071497; Backpropagation: 0.2915 sec; Batch: 2.1168 sec
0.1215 0.1110 0.0931 0.0833 0.0742 0.0687 0.0645 0.0645 0.0605 0.0593 0.0582 0.0578 0.0571 0.0570 0.0567 0.0566 

[TRAIN] Epoch[1](6858/114412); Loss: 0.093852; Backpropagation: 0.2911 sec; Batch: 2.1285 sec
0.1972 0.1846 0.1372 0.1214 0.0946 0.0831 0.0774 0.0735 0.0708 0.0689 0.0671 0.0663 0.0657 0.0652 0.0645 0.0640 

[TRAIN] Epoch[1](6859/114412); Loss: 0.097613; Backpropagation: 0.2917 sec; Batch: 2.0784 sec
0.1679 0.1567 0.1303 0.1188 0.1058 0.0966 0.0905 0.0850 0.0825 0.0790 0.0766 0.0757 0.0749 0.0742 0.0739 0.0734 

[TRAIN] Epoch[1](6860/114412); Loss: 0.076778; Backpropagation: 0.2904 sec; Batch: 2.1002 sec
0.1250 0.1131 0.0964 0.0865 0.0807 0.0745 0.0733 0.0703 0.0674 0.0653 0.0642 0.0633 0.0627 0.0622 0.0619 0.0615 

[TRAIN] Epoch[1](6861/114412); Loss: 0.112555; Backpropagation: 0.2909 sec; Batch: 2.1147 sec
0.2388 0.2154 0.1753 0.1528 0.1230 0.1016 0.0881 0.0830 0.0817 0.0797 0.0784 0.0777 0.0771 0.0765 0.0761 0.0755 

[TRAIN] Epoch[1](6862/114412); Loss: 0.085691; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1278 0.1251 0.1094 0.1016 0.0933 0.0852 0.0810 0.0784 0.0751 0.0743 0.0726 0.0712 0.0702 0.0691 0.0685 0.0681 

[TRAIN] Epoch[1](6863/114412); Loss: 0.099554; Backpropagation: 0.2908 sec; Batch: 2.1176 sec
0.1513 0.1415 0.1231 0.1164 0.1060 0.0963 0.0913 0.0913 0.0884 0.0857 0.0853 0.0843 0.0833 0.0834 0.0828 0.0825 

[TRAIN] Epoch[1](6864/114412); Loss: 0.079318; Backpropagation: 0.2913 sec; Batch: 2.0980 sec
0.1446 0.1392 0.1008 0.0887 0.0810 0.0736 0.0703 0.0680 0.0665 0.0649 0.0631 0.0629 0.0621 0.0616 0.0612 0.0608 

[TRAIN] Epoch[1](6865/114412); Loss: 0.099696; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1662 0.1543 0.1182 0.1082 0.1010 0.0943 0.0909 0.0899 0.0873 0.0861 0.0850 0.0837 0.0829 0.0829 0.0824 0.0818 

[TRAIN] Epoch[1](6866/114412); Loss: 0.061443; Backpropagation: 0.2927 sec; Batch: 2.1188 sec
0.1052 0.0957 0.0828 0.0730 0.0645 0.0590 0.0552 0.0558 0.0526 0.0504 0.0496 0.0488 0.0480 0.0478 0.0475 0.0475 

[TRAIN] Epoch[1](6867/114412); Loss: 0.130830; Backpropagation: 0.2910 sec; Batch: 2.1206 sec
0.2641 0.2487 0.2014 0.1861 0.1535 0.1318 0.1154 0.1055 0.0994 0.0926 0.0881 0.0842 0.0819 0.0811 0.0801 0.0795 

[TRAIN] Epoch[1](6868/114412); Loss: 0.111368; Backpropagation: 0.2907 sec; Batch: 2.1213 sec
0.1770 0.1620 0.1366 0.1231 0.1119 0.1069 0.1029 0.1009 0.0989 0.0974 0.0960 0.0954 0.0942 0.0932 0.0928 0.0928 

[TRAIN] Epoch[1](6869/114412); Loss: 0.089848; Backpropagation: 0.2917 sec; Batch: 2.1179 sec
0.1642 0.1498 0.1247 0.1092 0.0952 0.0864 0.0797 0.0775 0.0734 0.0709 0.0702 0.0689 0.0678 0.0670 0.0664 0.0663 

[TRAIN] Epoch[1](6870/114412); Loss: 0.095296; Backpropagation: 0.2950 sec; Batch: 2.1216 sec
0.1761 0.1569 0.1240 0.1081 0.0960 0.0883 0.0845 0.0814 0.0791 0.0783 0.0768 0.0756 0.0753 0.0749 0.0747 0.0746 

[TRAIN] Epoch[1](6871/114412); Loss: 0.112250; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1976 0.1828 0.1524 0.1366 0.1187 0.1075 0.0997 0.0949 0.0918 0.0901 0.0887 0.0876 0.0874 0.0870 0.0868 0.0864 

[TRAIN] Epoch[1](6872/114412); Loss: 0.112647; Backpropagation: 0.2911 sec; Batch: 2.1213 sec
0.1929 0.1702 0.1395 0.1275 0.1162 0.1078 0.1029 0.1006 0.0977 0.0953 0.0939 0.0932 0.0923 0.0911 0.0907 0.0905 

[TRAIN] Epoch[1](6873/114412); Loss: 0.088729; Backpropagation: 0.2907 sec; Batch: 2.1205 sec
0.1760 0.1484 0.1099 0.0956 0.0852 0.0805 0.0792 0.0761 0.0741 0.0728 0.0715 0.0706 0.0702 0.0698 0.0698 0.0700 

[TRAIN] Epoch[1](6874/114412); Loss: 0.074924; Backpropagation: 0.2907 sec; Batch: 2.1134 sec
0.1343 0.1249 0.0971 0.0924 0.0769 0.0670 0.0654 0.0641 0.0622 0.0616 0.0602 0.0588 0.0584 0.0584 0.0585 0.0586 

[TRAIN] Epoch[1](6875/114412); Loss: 0.079425; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1369 0.1293 0.1090 0.0993 0.0872 0.0757 0.0705 0.0672 0.0649 0.0632 0.0623 0.0617 0.0611 0.0608 0.0608 0.0609 

[TRAIN] Epoch[1](6876/114412); Loss: 0.094657; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1637 0.1531 0.1321 0.1193 0.1034 0.0926 0.0846 0.0803 0.0781 0.0760 0.0749 0.0731 0.0719 0.0713 0.0703 0.0698 

[TRAIN] Epoch[1](6877/114412); Loss: 0.087846; Backpropagation: 0.2915 sec; Batch: 2.1187 sec
0.1362 0.1275 0.1086 0.1035 0.0925 0.0871 0.0821 0.0814 0.0780 0.0756 0.0746 0.0729 0.0721 0.0716 0.0710 0.0708 

[TRAIN] Epoch[1](6878/114412); Loss: 0.125480; Backpropagation: 0.2932 sec; Batch: 2.1232 sec
0.2151 0.1920 0.1638 0.1491 0.1340 0.1211 0.1155 0.1116 0.1066 0.1041 0.1019 0.1002 0.0992 0.0983 0.0978 0.0974 

[TRAIN] Epoch[1](6879/114412); Loss: 0.088873; Backpropagation: 0.2934 sec; Batch: 2.1184 sec
0.1528 0.1349 0.1127 0.1018 0.0911 0.0852 0.0818 0.0788 0.0767 0.0753 0.0742 0.0727 0.0720 0.0712 0.0706 0.0703 

[TRAIN] Epoch[1](6880/114412); Loss: 0.110583; Backpropagation: 0.2929 sec; Batch: 2.1188 sec
0.1717 0.1652 0.1430 0.1315 0.1172 0.1117 0.1058 0.1011 0.0968 0.0938 0.0917 0.0905 0.0890 0.0875 0.0867 0.0860 

[TRAIN] Epoch[1](6881/114412); Loss: 0.084497; Backpropagation: 0.2952 sec; Batch: 2.1211 sec
0.1229 0.1167 0.1027 0.0922 0.0862 0.0807 0.0769 0.0771 0.0760 0.0755 0.0752 0.0745 0.0737 0.0736 0.0738 0.0741 

[TRAIN] Epoch[1](6882/114412); Loss: 0.076504; Backpropagation: 0.2953 sec; Batch: 2.1203 sec
0.1540 0.1343 0.0998 0.0888 0.0794 0.0723 0.0665 0.0633 0.0601 0.0586 0.0587 0.0581 0.0574 0.0576 0.0577 0.0574 

[TRAIN] Epoch[1](6883/114412); Loss: 0.093217; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1386 0.1332 0.1124 0.1075 0.0988 0.0934 0.0885 0.0866 0.0836 0.0820 0.0805 0.0790 0.0783 0.0770 0.0762 0.0759 

[TRAIN] Epoch[1](6884/114412); Loss: 0.079112; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1225 0.1176 0.1009 0.0908 0.0826 0.0763 0.0709 0.0736 0.0703 0.0675 0.0669 0.0659 0.0653 0.0650 0.0649 0.0648 

[TRAIN] Epoch[1](6885/114412); Loss: 0.103821; Backpropagation: 0.2929 sec; Batch: 2.1170 sec
0.1832 0.1633 0.1366 0.1232 0.1095 0.1002 0.0939 0.0906 0.0876 0.0855 0.0829 0.0820 0.0815 0.0811 0.0804 0.0799 

[TRAIN] Epoch[1](6886/114412); Loss: 0.084636; Backpropagation: 0.2951 sec; Batch: 2.1224 sec
0.1518 0.1312 0.1077 0.0974 0.0870 0.0827 0.0778 0.0753 0.0723 0.0695 0.0695 0.0681 0.0670 0.0660 0.0655 0.0652 

[TRAIN] Epoch[1](6887/114412); Loss: 0.079416; Backpropagation: 0.2928 sec; Batch: 2.1260 sec
0.1387 0.1258 0.1002 0.0884 0.0811 0.0740 0.0713 0.0707 0.0678 0.0664 0.0664 0.0653 0.0644 0.0639 0.0632 0.0631 

[TRAIN] Epoch[1](6888/114412); Loss: 0.067500; Backpropagation: 0.2953 sec; Batch: 2.1246 sec
0.1238 0.1165 0.0901 0.0850 0.0703 0.0646 0.0584 0.0598 0.0549 0.0535 0.0525 0.0511 0.0505 0.0500 0.0496 0.0494 

[TRAIN] Epoch[1](6889/114412); Loss: 0.099289; Backpropagation: 0.2928 sec; Batch: 2.0985 sec
0.1983 0.1803 0.1520 0.1342 0.1151 0.1005 0.0886 0.0803 0.0760 0.0721 0.0693 0.0672 0.0654 0.0641 0.0632 0.0623 

[TRAIN] Epoch[1](6890/114412); Loss: 0.124747; Backpropagation: 0.2929 sec; Batch: 2.1177 sec
0.2175 0.2067 0.1733 0.1602 0.1422 0.1300 0.1179 0.1098 0.1040 0.0983 0.0943 0.0915 0.0896 0.0876 0.0870 0.0862 

[TRAIN] Epoch[1](6891/114412); Loss: 0.115452; Backpropagation: 0.2907 sec; Batch: 2.1184 sec
0.1911 0.1789 0.1545 0.1439 0.1288 0.1157 0.1075 0.1034 0.0995 0.0960 0.0930 0.0902 0.0883 0.0869 0.0851 0.0846 

[TRAIN] Epoch[1](6892/114412); Loss: 0.093735; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.2027 0.1892 0.1400 0.1266 0.0982 0.0853 0.0765 0.0725 0.0694 0.0670 0.0647 0.0631 0.0621 0.0612 0.0608 0.0605 

[TRAIN] Epoch[1](6893/114412); Loss: 0.085020; Backpropagation: 0.2911 sec; Batch: 2.1247 sec
0.1629 0.1553 0.1256 0.1145 0.0975 0.0832 0.0739 0.0702 0.0660 0.0620 0.0603 0.0592 0.0582 0.0577 0.0572 0.0567 

[TRAIN] Epoch[1](6894/114412); Loss: 0.089122; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1654 0.1487 0.1098 0.0995 0.0856 0.0796 0.0765 0.0766 0.0759 0.0746 0.0734 0.0730 0.0722 0.0720 0.0717 0.0715 

[TRAIN] Epoch[1](6895/114412); Loss: 0.078781; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1629 0.1521 0.1035 0.0927 0.0781 0.0701 0.0661 0.0630 0.0611 0.0606 0.0594 0.0586 0.0581 0.0578 0.0580 0.0584 

[TRAIN] Epoch[1](6896/114412); Loss: 0.102428; Backpropagation: 0.2909 sec; Batch: 2.0804 sec
0.1613 0.1511 0.1268 0.1163 0.1063 0.0986 0.0935 0.0915 0.0890 0.0879 0.0869 0.0861 0.0862 0.0858 0.0857 0.0857 

[TRAIN] Epoch[1](6897/114412); Loss: 0.068570; Backpropagation: 0.2904 sec; Batch: 2.0774 sec
0.1307 0.1140 0.0854 0.0788 0.0687 0.0642 0.0628 0.0599 0.0573 0.0559 0.0547 0.0541 0.0533 0.0529 0.0526 0.0520 

[TRAIN] Epoch[1](6898/114412); Loss: 0.079559; Backpropagation: 0.2931 sec; Batch: 2.1203 sec
0.1340 0.1196 0.1049 0.0916 0.0841 0.0784 0.0728 0.0704 0.0679 0.0668 0.0656 0.0643 0.0636 0.0632 0.0630 0.0628 

[TRAIN] Epoch[1](6899/114412); Loss: 0.083253; Backpropagation: 0.2912 sec; Batch: 2.1048 sec
0.1676 0.1514 0.1211 0.1063 0.0868 0.0776 0.0702 0.0674 0.0644 0.0618 0.0608 0.0604 0.0597 0.0594 0.0588 0.0583 

[TRAIN] Epoch[1](6900/114412); Loss: 0.082498; Backpropagation: 0.2912 sec; Batch: 2.0775 sec
0.1506 0.1403 0.1124 0.1003 0.0858 0.0784 0.0723 0.0694 0.0667 0.0649 0.0643 0.0637 0.0629 0.0624 0.0627 0.0629 

[TRAIN] Epoch[1](6901/114412); Loss: 0.073065; Backpropagation: 0.2907 sec; Batch: 2.0779 sec
0.1057 0.1020 0.0905 0.0832 0.0757 0.0722 0.0690 0.0677 0.0657 0.0646 0.0636 0.0626 0.0618 0.0618 0.0615 0.0615 

[TRAIN] Epoch[1](6902/114412); Loss: 0.106228; Backpropagation: 0.2910 sec; Batch: 2.1189 sec
0.1586 0.1509 0.1349 0.1248 0.1139 0.1053 0.1002 0.0968 0.0943 0.0924 0.0905 0.0891 0.0878 0.0875 0.0872 0.0855 

[TRAIN] Epoch[1](6903/114412); Loss: 0.083897; Backpropagation: 0.2957 sec; Batch: 2.1064 sec
0.1579 0.1459 0.1114 0.0968 0.0897 0.0812 0.0758 0.0727 0.0693 0.0674 0.0653 0.0638 0.0628 0.0615 0.0608 0.0599 

[TRAIN] Epoch[1](6904/114412); Loss: 0.088337; Backpropagation: 0.2930 sec; Batch: 2.1358 sec
0.1368 0.1270 0.1103 0.1039 0.0938 0.0879 0.0839 0.0805 0.0777 0.0762 0.0745 0.0734 0.0728 0.0722 0.0714 0.0712 

[TRAIN] Epoch[1](6905/114412); Loss: 0.096701; Backpropagation: 0.2915 sec; Batch: 2.1182 sec
0.1488 0.1370 0.1158 0.1058 0.0974 0.0940 0.0896 0.0880 0.0867 0.0849 0.0836 0.0831 0.0832 0.0833 0.0831 0.0831 

[TRAIN] Epoch[1](6906/114412); Loss: 0.069592; Backpropagation: 0.2912 sec; Batch: 2.0789 sec
0.1205 0.1110 0.0870 0.0773 0.0720 0.0668 0.0625 0.0615 0.0592 0.0582 0.0574 0.0565 0.0562 0.0558 0.0557 0.0558 

[TRAIN] Epoch[1](6907/114412); Loss: 0.113893; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.2027 0.1898 0.1600 0.1461 0.1259 0.1131 0.1029 0.0975 0.0942 0.0922 0.0894 0.0863 0.0835 0.0810 0.0798 0.0780 

[TRAIN] Epoch[1](6908/114412); Loss: 0.086634; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1408 0.1316 0.1117 0.1038 0.0927 0.0869 0.0800 0.0774 0.0740 0.0723 0.0710 0.0700 0.0694 0.0687 0.0684 0.0676 

[TRAIN] Epoch[1](6909/114412); Loss: 0.089010; Backpropagation: 0.2908 sec; Batch: 2.1185 sec
0.1553 0.1387 0.1165 0.1018 0.0928 0.0861 0.0810 0.0778 0.0749 0.0732 0.0721 0.0718 0.0714 0.0706 0.0704 0.0701 

[TRAIN] Epoch[1](6910/114412); Loss: 0.101746; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1721 0.1676 0.1410 0.1250 0.1094 0.0989 0.0919 0.0866 0.0839 0.0816 0.0804 0.0787 0.0783 0.0777 0.0773 0.0775 

[TRAIN] Epoch[1](6911/114412); Loss: 0.089607; Backpropagation: 0.2914 sec; Batch: 2.1178 sec
0.1626 0.1518 0.1207 0.1102 0.0950 0.0854 0.0799 0.0770 0.0731 0.0711 0.0698 0.0687 0.0680 0.0673 0.0667 0.0664 

[TRAIN] Epoch[1](6912/114412); Loss: 0.096195; Backpropagation: 0.2912 sec; Batch: 2.0816 sec
0.1752 0.1618 0.1389 0.1267 0.1081 0.0971 0.0876 0.0813 0.0770 0.0736 0.0713 0.0702 0.0691 0.0681 0.0670 0.0661 

[TRAIN] Epoch[1](6913/114412); Loss: 0.099733; Backpropagation: 0.2905 sec; Batch: 2.0777 sec
0.2102 0.1927 0.1492 0.1284 0.1037 0.0899 0.0818 0.0769 0.0740 0.0723 0.0712 0.0700 0.0695 0.0689 0.0686 0.0683 

[TRAIN] Epoch[1](6914/114412); Loss: 0.106635; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.2090 0.1840 0.1460 0.1312 0.1152 0.1032 0.0953 0.0889 0.0840 0.0816 0.0800 0.0784 0.0779 0.0774 0.0771 0.0769 

[TRAIN] Epoch[1](6915/114412); Loss: 0.099899; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.1476 0.1320 0.1172 0.1082 0.1029 0.0972 0.0955 0.0946 0.0917 0.0897 0.0888 0.0873 0.0866 0.0865 0.0865 0.0861 

[TRAIN] Epoch[1](6916/114412); Loss: 0.077613; Backpropagation: 0.2915 sec; Batch: 2.1177 sec
0.1350 0.1278 0.1103 0.0985 0.0845 0.0771 0.0706 0.0668 0.0627 0.0608 0.0595 0.0589 0.0581 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](6917/114412); Loss: 0.094194; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1828 0.1583 0.1262 0.1121 0.0986 0.0895 0.0852 0.0828 0.0772 0.0743 0.0727 0.0712 0.0702 0.0691 0.0685 0.0682 

[TRAIN] Epoch[1](6918/114412); Loss: 0.116890; Backpropagation: 0.2914 sec; Batch: 2.1187 sec
0.2162 0.1930 0.1536 0.1365 0.1207 0.1097 0.1040 0.1002 0.0968 0.0945 0.0934 0.0917 0.0911 0.0902 0.0894 0.0892 

[TRAIN] Epoch[1](6919/114412); Loss: 0.089647; Backpropagation: 0.2913 sec; Batch: 2.1208 sec
0.1544 0.1474 0.1168 0.1071 0.0975 0.0897 0.0829 0.0779 0.0746 0.0721 0.0708 0.0695 0.0690 0.0684 0.0681 0.0680 

[TRAIN] Epoch[1](6920/114412); Loss: 0.124340; Backpropagation: 0.2910 sec; Batch: 2.1170 sec
0.2723 0.2456 0.1964 0.1771 0.1452 0.1225 0.1081 0.0956 0.0882 0.0835 0.0795 0.0779 0.0765 0.0747 0.0734 0.0730 

[TRAIN] Epoch[1](6921/114412); Loss: 0.125152; Backpropagation: 0.2911 sec; Batch: 2.1332 sec
0.2081 0.1806 0.1524 0.1415 0.1286 0.1187 0.1138 0.1105 0.1100 0.1078 0.1063 0.1061 0.1052 0.1043 0.1042 0.1042 

[TRAIN] Epoch[1](6922/114412); Loss: 0.102360; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1965 0.1789 0.1407 0.1228 0.1074 0.0973 0.0895 0.0862 0.0819 0.0796 0.0782 0.0771 0.0763 0.0753 0.0750 0.0750 

[TRAIN] Epoch[1](6923/114412); Loss: 0.091288; Backpropagation: 0.2915 sec; Batch: 2.1177 sec
0.1677 0.1565 0.1189 0.1079 0.0925 0.0869 0.0821 0.0790 0.0753 0.0734 0.0720 0.0710 0.0707 0.0692 0.0688 0.0686 

[TRAIN] Epoch[1](6924/114412); Loss: 0.082267; Backpropagation: 0.2911 sec; Batch: 2.1205 sec
0.1555 0.1452 0.1078 0.0962 0.0842 0.0770 0.0741 0.0694 0.0678 0.0657 0.0650 0.0632 0.0623 0.0615 0.0609 0.0604 

[TRAIN] Epoch[1](6925/114412); Loss: 0.103950; Backpropagation: 0.2912 sec; Batch: 2.1199 sec
0.2004 0.1810 0.1441 0.1276 0.1092 0.0999 0.0921 0.0889 0.0860 0.0823 0.0788 0.0772 0.0759 0.0743 0.0731 0.0723 

[TRAIN] Epoch[1](6926/114412); Loss: 0.088482; Backpropagation: 0.2905 sec; Batch: 2.1143 sec
0.1660 0.1539 0.1245 0.1124 0.0940 0.0864 0.0792 0.0750 0.0711 0.0682 0.0669 0.0655 0.0642 0.0636 0.0629 0.0620 

[TRAIN] Epoch[1](6927/114412); Loss: 0.111260; Backpropagation: 0.2906 sec; Batch: 2.0772 sec
0.1669 0.1589 0.1480 0.1369 0.1229 0.1136 0.1053 0.1017 0.0975 0.0949 0.0923 0.0902 0.0888 0.0879 0.0877 0.0866 

[TRAIN] Epoch[1](6928/114412); Loss: 0.084141; Backpropagation: 0.2909 sec; Batch: 2.1423 sec
0.1649 0.1352 0.1101 0.0995 0.0874 0.0809 0.0757 0.0732 0.0698 0.0678 0.0663 0.0644 0.0633 0.0630 0.0625 0.0622 

[TRAIN] Epoch[1](6929/114412); Loss: 0.143943; Backpropagation: 0.2911 sec; Batch: 2.0813 sec
0.2749 0.2525 0.2065 0.1849 0.1568 0.1388 0.1268 0.1199 0.1154 0.1104 0.1077 0.1046 0.1022 0.1013 0.1006 0.0997 

[TRAIN] Epoch[1](6930/114412); Loss: 0.087471; Backpropagation: 0.2910 sec; Batch: 2.0824 sec
0.1520 0.1330 0.1121 0.1004 0.0911 0.0843 0.0792 0.0770 0.0751 0.0727 0.0717 0.0713 0.0707 0.0701 0.0696 0.0694 

[TRAIN] Epoch[1](6931/114412); Loss: 0.077653; Backpropagation: 0.2905 sec; Batch: 2.0804 sec
0.1211 0.1141 0.0966 0.0889 0.0811 0.0764 0.0715 0.0696 0.0677 0.0666 0.0657 0.0650 0.0648 0.0646 0.0643 0.0645 

[TRAIN] Epoch[1](6932/114412); Loss: 0.090440; Backpropagation: 0.2911 sec; Batch: 2.0855 sec
0.1407 0.1326 0.1165 0.1066 0.0944 0.0892 0.0839 0.0813 0.0787 0.0779 0.0765 0.0752 0.0740 0.0735 0.0731 0.0727 

[TRAIN] Epoch[1](6933/114412); Loss: 0.061865; Backpropagation: 0.2913 sec; Batch: 2.1406 sec
0.1169 0.1168 0.0773 0.0703 0.0664 0.0587 0.0522 0.0528 0.0501 0.0484 0.0481 0.0472 0.0461 0.0463 0.0462 0.0460 

[TRAIN] Epoch[1](6934/114412); Loss: 0.071680; Backpropagation: 0.2913 sec; Batch: 2.0780 sec
0.1545 0.1434 0.1034 0.0890 0.0734 0.0646 0.0584 0.0555 0.0536 0.0519 0.0510 0.0501 0.0494 0.0497 0.0495 0.0494 

[TRAIN] Epoch[1](6935/114412); Loss: 0.088092; Backpropagation: 0.2955 sec; Batch: 2.1073 sec
0.1641 0.1531 0.1205 0.1066 0.0910 0.0821 0.0773 0.0741 0.0709 0.0691 0.0682 0.0671 0.0666 0.0663 0.0662 0.0662 

[TRAIN] Epoch[1](6936/114412); Loss: 0.096662; Backpropagation: 0.2913 sec; Batch: 2.1192 sec
0.2226 0.1942 0.1502 0.1308 0.1016 0.0870 0.0765 0.0710 0.0689 0.0664 0.0652 0.0642 0.0633 0.0622 0.0614 0.0611 

[TRAIN] Epoch[1](6937/114412); Loss: 0.074169; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1358 0.1322 0.1012 0.0907 0.0764 0.0729 0.0657 0.0623 0.0610 0.0580 0.0569 0.0561 0.0552 0.0545 0.0540 0.0537 

[TRAIN] Epoch[1](6938/114412); Loss: 0.096599; Backpropagation: 0.2911 sec; Batch: 2.1185 sec
0.1765 0.1417 0.1152 0.1038 0.0985 0.0939 0.0895 0.0875 0.0845 0.0816 0.0810 0.0793 0.0785 0.0785 0.0780 0.0776 

[TRAIN] Epoch[1](6939/114412); Loss: 0.084319; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1325 0.1215 0.1032 0.0944 0.0870 0.0844 0.0791 0.0763 0.0748 0.0727 0.0720 0.0712 0.0704 0.0701 0.0697 0.0697 

[TRAIN] Epoch[1](6940/114412); Loss: 0.085899; Backpropagation: 0.2914 sec; Batch: 2.1135 sec
0.1424 0.1295 0.1077 0.0973 0.0886 0.0822 0.0793 0.0780 0.0749 0.0733 0.0718 0.0710 0.0704 0.0698 0.0695 0.0688 

[TRAIN] Epoch[1](6941/114412); Loss: 0.110694; Backpropagation: 0.2913 sec; Batch: 2.1144 sec
0.1844 0.1625 0.1348 0.1253 0.1152 0.1079 0.1036 0.1017 0.0984 0.0953 0.0933 0.0917 0.0906 0.0896 0.0888 0.0881 

[TRAIN] Epoch[1](6942/114412); Loss: 0.093445; Backpropagation: 0.2915 sec; Batch: 2.1212 sec
0.1595 0.1418 0.1197 0.1075 0.0988 0.0906 0.0851 0.0841 0.0809 0.0791 0.0775 0.0757 0.0747 0.0739 0.0733 0.0730 

[TRAIN] Epoch[1](6943/114412); Loss: 0.080977; Backpropagation: 0.2907 sec; Batch: 2.1160 sec
0.1399 0.1225 0.1059 0.0938 0.0868 0.0797 0.0746 0.0718 0.0693 0.0675 0.0660 0.0646 0.0642 0.0635 0.0629 0.0626 

[TRAIN] Epoch[1](6944/114412); Loss: 0.092241; Backpropagation: 0.2916 sec; Batch: 2.1187 sec
0.1794 0.1661 0.1279 0.1123 0.0923 0.0810 0.0783 0.0766 0.0729 0.0731 0.0709 0.0701 0.0695 0.0688 0.0683 0.0684 

[TRAIN] Epoch[1](6945/114412); Loss: 0.064206; Backpropagation: 0.2914 sec; Batch: 2.1257 sec
0.1174 0.1116 0.0863 0.0737 0.0646 0.0584 0.0557 0.0554 0.0527 0.0513 0.0510 0.0501 0.0500 0.0498 0.0495 0.0497 

[TRAIN] Epoch[1](6946/114412); Loss: 0.103841; Backpropagation: 0.2912 sec; Batch: 2.1159 sec
0.2059 0.1923 0.1571 0.1426 0.1196 0.1053 0.0946 0.0861 0.0788 0.0743 0.0709 0.0686 0.0676 0.0668 0.0658 0.0652 

[TRAIN] Epoch[1](6947/114412); Loss: 0.110145; Backpropagation: 0.2932 sec; Batch: 2.1168 sec
0.1625 0.1471 0.1348 0.1261 0.1176 0.1093 0.1045 0.1019 0.0995 0.0975 0.0960 0.0948 0.0935 0.0928 0.0923 0.0923 

[TRAIN] Epoch[1](6948/114412); Loss: 0.087915; Backpropagation: 0.2913 sec; Batch: 2.1187 sec
0.1578 0.1482 0.1250 0.1125 0.0968 0.0865 0.0784 0.0743 0.0702 0.0681 0.0667 0.0656 0.0651 0.0643 0.0638 0.0633 

[TRAIN] Epoch[1](6949/114412); Loss: 0.095145; Backpropagation: 0.2931 sec; Batch: 2.1195 sec
0.1816 0.1632 0.1345 0.1181 0.0992 0.0910 0.0842 0.0792 0.0763 0.0738 0.0720 0.0713 0.0704 0.0698 0.0691 0.0687 

[TRAIN] Epoch[1](6950/114412); Loss: 0.086458; Backpropagation: 0.2930 sec; Batch: 2.0901 sec
0.1301 0.1195 0.1059 0.0983 0.0904 0.0843 0.0810 0.0810 0.0780 0.0772 0.0755 0.0737 0.0730 0.0724 0.0717 0.0713 

[TRAIN] Epoch[1](6951/114412); Loss: 0.111344; Backpropagation: 0.2907 sec; Batch: 2.1080 sec
0.2081 0.1913 0.1604 0.1418 0.1193 0.1089 0.0998 0.0925 0.0879 0.0846 0.0837 0.0820 0.0809 0.0805 0.0801 0.0797 

[TRAIN] Epoch[1](6952/114412); Loss: 0.074347; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1167 0.1085 0.0969 0.0886 0.0799 0.0729 0.0682 0.0668 0.0645 0.0628 0.0617 0.0614 0.0605 0.0602 0.0601 0.0599 

[TRAIN] Epoch[1](6953/114412); Loss: 0.078813; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.1442 0.1345 0.1094 0.0969 0.0836 0.0761 0.0711 0.0684 0.0639 0.0616 0.0600 0.0590 0.0585 0.0581 0.0577 0.0581 

[TRAIN] Epoch[1](6954/114412); Loss: 0.119921; Backpropagation: 0.2927 sec; Batch: 2.0796 sec
0.1811 0.1624 0.1461 0.1356 0.1247 0.1191 0.1143 0.1116 0.1084 0.1064 0.1044 0.1028 0.1015 0.1008 0.1001 0.0995 

[TRAIN] Epoch[1](6955/114412); Loss: 0.110226; Backpropagation: 0.2931 sec; Batch: 2.1179 sec
0.1519 0.1421 0.1256 0.1183 0.1144 0.1111 0.1069 0.1053 0.1038 0.1009 0.0997 0.0980 0.0969 0.0963 0.0961 0.0962 

[TRAIN] Epoch[1](6956/114412); Loss: 0.114846; Backpropagation: 0.2907 sec; Batch: 2.1191 sec
0.2100 0.1962 0.1714 0.1577 0.1318 0.1161 0.1060 0.0993 0.0933 0.0881 0.0831 0.0796 0.0776 0.0766 0.0761 0.0747 

[TRAIN] Epoch[1](6957/114412); Loss: 0.091272; Backpropagation: 0.2911 sec; Batch: 2.1241 sec
0.1417 0.1328 0.1120 0.1021 0.0965 0.0904 0.0853 0.0836 0.0809 0.0788 0.0779 0.0770 0.0763 0.0756 0.0749 0.0746 

[TRAIN] Epoch[1](6958/114412); Loss: 0.087217; Backpropagation: 0.2913 sec; Batch: 2.0936 sec
0.1522 0.1386 0.1125 0.1021 0.0955 0.0879 0.0820 0.0782 0.0743 0.0716 0.0699 0.0681 0.0668 0.0662 0.0652 0.0645 

[TRAIN] Epoch[1](6959/114412); Loss: 0.090806; Backpropagation: 0.2909 sec; Batch: 2.1140 sec
0.1350 0.1303 0.1144 0.1098 0.0998 0.0939 0.0876 0.0845 0.0811 0.0787 0.0760 0.0741 0.0728 0.0722 0.0715 0.0710 

[TRAIN] Epoch[1](6960/114412); Loss: 0.110983; Backpropagation: 0.2904 sec; Batch: 2.0775 sec
0.1777 0.1676 0.1411 0.1283 0.1187 0.1083 0.1039 0.0993 0.0963 0.0944 0.0929 0.0918 0.0900 0.0889 0.0886 0.0881 

[TRAIN] Epoch[1](6961/114412); Loss: 0.087664; Backpropagation: 0.2919 sec; Batch: 2.1149 sec
0.1675 0.1571 0.1285 0.1127 0.0961 0.0846 0.0772 0.0731 0.0689 0.0666 0.0644 0.0627 0.0619 0.0609 0.0604 0.0601 

[TRAIN] Epoch[1](6962/114412); Loss: 0.088543; Backpropagation: 0.2919 sec; Batch: 2.1194 sec
0.1545 0.1438 0.1148 0.1037 0.0912 0.0846 0.0800 0.0766 0.0748 0.0736 0.0720 0.0706 0.0700 0.0694 0.0690 0.0682 

[TRAIN] Epoch[1](6963/114412); Loss: 0.091486; Backpropagation: 0.2934 sec; Batch: 2.0964 sec
0.1269 0.1202 0.1135 0.1035 0.0961 0.0921 0.0872 0.0862 0.0836 0.0817 0.0807 0.0796 0.0786 0.0782 0.0779 0.0779 

[TRAIN] Epoch[1](6964/114412); Loss: 0.092452; Backpropagation: 0.2929 sec; Batch: 2.1284 sec
0.1365 0.1306 0.1089 0.1017 0.0964 0.0907 0.0869 0.0857 0.0828 0.0814 0.0803 0.0797 0.0799 0.0794 0.0793 0.0791 

[TRAIN] Epoch[1](6965/114412); Loss: 0.101254; Backpropagation: 0.2913 sec; Batch: 2.0995 sec
0.1835 0.1767 0.1464 0.1352 0.1167 0.1039 0.0940 0.0886 0.0825 0.0778 0.0742 0.0708 0.0689 0.0675 0.0669 0.0664 

[TRAIN] Epoch[1](6966/114412); Loss: 0.113923; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.1806 0.1641 0.1464 0.1318 0.1211 0.1143 0.1073 0.1032 0.0996 0.0974 0.0958 0.0943 0.0932 0.0922 0.0911 0.0905 

[TRAIN] Epoch[1](6967/114412); Loss: 0.084337; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1274 0.1210 0.1045 0.0988 0.0873 0.0836 0.0788 0.0765 0.0754 0.0731 0.0728 0.0717 0.0706 0.0697 0.0692 0.0691 

[TRAIN] Epoch[1](6968/114412); Loss: 0.087911; Backpropagation: 0.2907 sec; Batch: 2.1159 sec
0.1301 0.1210 0.1058 0.0994 0.0934 0.0887 0.0846 0.0819 0.0801 0.0779 0.0765 0.0754 0.0740 0.0733 0.0726 0.0719 

[TRAIN] Epoch[1](6969/114412); Loss: 0.099095; Backpropagation: 0.2915 sec; Batch: 2.1178 sec
0.1620 0.1516 0.1261 0.1159 0.1047 0.0981 0.0928 0.0890 0.0860 0.0834 0.0815 0.0803 0.0795 0.0787 0.0781 0.0778 

[TRAIN] Epoch[1](6970/114412); Loss: 0.093748; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1858 0.1661 0.1275 0.1083 0.0949 0.0879 0.0818 0.0777 0.0760 0.0735 0.0726 0.0715 0.0701 0.0693 0.0688 0.0684 

[TRAIN] Epoch[1](6971/114412); Loss: 0.094449; Backpropagation: 0.2929 sec; Batch: 2.0792 sec
0.1723 0.1582 0.1243 0.1090 0.0954 0.0870 0.0831 0.0798 0.0788 0.0775 0.0757 0.0749 0.0744 0.0736 0.0737 0.0736 

[TRAIN] Epoch[1](6972/114412); Loss: 0.104713; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1688 0.1536 0.1317 0.1190 0.1092 0.1038 0.0983 0.0954 0.0920 0.0899 0.0882 0.0871 0.0858 0.0848 0.0842 0.0834 

[TRAIN] Epoch[1](6973/114412); Loss: 0.116990; Backpropagation: 0.2907 sec; Batch: 2.1041 sec
0.1963 0.1876 0.1602 0.1519 0.1361 0.1232 0.1132 0.1068 0.1000 0.0945 0.0902 0.0867 0.0838 0.0814 0.0803 0.0797 

[TRAIN] Epoch[1](6974/114412); Loss: 0.117728; Backpropagation: 0.2913 sec; Batch: 2.1197 sec
0.1731 0.1630 0.1459 0.1379 0.1280 0.1188 0.1117 0.1081 0.1049 0.1037 0.1015 0.0990 0.0975 0.0971 0.0969 0.0966 

[TRAIN] Epoch[1](6975/114412); Loss: 0.096610; Backpropagation: 0.2910 sec; Batch: 2.0771 sec
0.1703 0.1567 0.1301 0.1179 0.1042 0.0947 0.0883 0.0840 0.0815 0.0786 0.0763 0.0748 0.0735 0.0722 0.0715 0.0711 

[TRAIN] Epoch[1](6976/114412); Loss: 0.081613; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1456 0.1334 0.1089 0.0940 0.0818 0.0765 0.0728 0.0714 0.0692 0.0674 0.0662 0.0650 0.0641 0.0637 0.0631 0.0628 

[TRAIN] Epoch[1](6977/114412); Loss: 0.086285; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1409 0.1323 0.1141 0.1045 0.0938 0.0861 0.0796 0.0766 0.0745 0.0718 0.0703 0.0690 0.0677 0.0671 0.0665 0.0658 

[TRAIN] Epoch[1](6978/114412); Loss: 0.093952; Backpropagation: 0.2913 sec; Batch: 2.1128 sec
0.1449 0.1386 0.1245 0.1148 0.1033 0.0957 0.0899 0.0854 0.0823 0.0798 0.0767 0.0752 0.0744 0.0734 0.0726 0.0718 

[TRAIN] Epoch[1](6979/114412); Loss: 0.102658; Backpropagation: 0.2917 sec; Batch: 2.1181 sec
0.1574 0.1443 0.1310 0.1202 0.1097 0.1019 0.0966 0.0929 0.0908 0.0884 0.0869 0.0856 0.0848 0.0842 0.0839 0.0838 

[TRAIN] Epoch[1](6980/114412); Loss: 0.125061; Backpropagation: 0.2910 sec; Batch: 2.1170 sec
0.2355 0.2127 0.1742 0.1541 0.1323 0.1203 0.1115 0.1072 0.1039 0.0993 0.0957 0.0929 0.0921 0.0907 0.0895 0.0891 

[TRAIN] Epoch[1](6981/114412); Loss: 0.079773; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1415 0.1261 0.1028 0.0928 0.0819 0.0773 0.0735 0.0704 0.0676 0.0656 0.0648 0.0639 0.0627 0.0620 0.0618 0.0617 

[TRAIN] Epoch[1](6982/114412); Loss: 0.099234; Backpropagation: 0.2914 sec; Batch: 2.1005 sec
0.1953 0.1867 0.1461 0.1275 0.1053 0.0945 0.0873 0.0814 0.0778 0.0743 0.0713 0.0694 0.0686 0.0681 0.0674 0.0669 

[TRAIN] Epoch[1](6983/114412); Loss: 0.107516; Backpropagation: 0.2909 sec; Batch: 2.0784 sec
0.1898 0.1780 0.1530 0.1379 0.1175 0.1048 0.0970 0.0925 0.0875 0.0844 0.0827 0.0805 0.0791 0.0789 0.0786 0.0781 

[TRAIN] Epoch[1](6984/114412); Loss: 0.078742; Backpropagation: 0.2907 sec; Batch: 2.1324 sec
0.1564 0.1442 0.1115 0.0992 0.0880 0.0765 0.0679 0.0650 0.0615 0.0592 0.0577 0.0562 0.0551 0.0543 0.0538 0.0531 

[TRAIN] Epoch[1](6985/114412); Loss: 0.099726; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1700 0.1582 0.1275 0.1147 0.1037 0.0979 0.0912 0.0870 0.0846 0.0829 0.0812 0.0807 0.0798 0.0791 0.0786 0.0784 

[TRAIN] Epoch[1](6986/114412); Loss: 0.132984; Backpropagation: 0.2913 sec; Batch: 2.1214 sec
0.2591 0.2422 0.2029 0.1839 0.1564 0.1343 0.1196 0.1094 0.1013 0.0959 0.0914 0.0885 0.0870 0.0859 0.0852 0.0847 

[TRAIN] Epoch[1](6987/114412); Loss: 0.075891; Backpropagation: 0.2910 sec; Batch: 2.1140 sec
0.1642 0.1450 0.1002 0.0867 0.0695 0.0713 0.0644 0.0616 0.0596 0.0575 0.0569 0.0559 0.0552 0.0552 0.0556 0.0555 

[TRAIN] Epoch[1](6988/114412); Loss: 0.091349; Backpropagation: 0.2913 sec; Batch: 2.1294 sec
0.1501 0.1449 0.1220 0.1108 0.1002 0.0930 0.0866 0.0806 0.0773 0.0740 0.0720 0.0714 0.0703 0.0701 0.0695 0.0687 

[TRAIN] Epoch[1](6989/114412); Loss: 0.086042; Backpropagation: 0.2917 sec; Batch: 2.1085 sec
0.1855 0.1624 0.1218 0.1068 0.0903 0.0783 0.0720 0.0672 0.0650 0.0629 0.0621 0.0616 0.0607 0.0604 0.0599 0.0599 

[TRAIN] Epoch[1](6990/114412); Loss: 0.149545; Backpropagation: 0.2930 sec; Batch: 2.1199 sec
0.2452 0.2298 0.1991 0.1871 0.1652 0.1498 0.1401 0.1350 0.1289 0.1240 0.1201 0.1171 0.1144 0.1129 0.1125 0.1115 

[TRAIN] Epoch[1](6991/114412); Loss: 0.122041; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1867 0.1763 0.1582 0.1476 0.1358 0.1256 0.1185 0.1135 0.1089 0.1053 0.1018 0.0986 0.0964 0.0947 0.0929 0.0918 

[TRAIN] Epoch[1](6992/114412); Loss: 0.087069; Backpropagation: 0.2911 sec; Batch: 2.1123 sec
0.1591 0.1476 0.1197 0.1060 0.0916 0.0838 0.0776 0.0748 0.0718 0.0692 0.0681 0.0666 0.0655 0.0646 0.0640 0.0634 

[TRAIN] Epoch[1](6993/114412); Loss: 0.094329; Backpropagation: 0.2932 sec; Batch: 2.0786 sec
0.1571 0.1448 0.1229 0.1113 0.0990 0.0934 0.0884 0.0840 0.0813 0.0790 0.0768 0.0754 0.0749 0.0740 0.0737 0.0733 

[TRAIN] Epoch[1](6994/114412); Loss: 0.094851; Backpropagation: 0.2928 sec; Batch: 2.1095 sec
0.1479 0.1384 0.1317 0.1187 0.1046 0.0978 0.0904 0.0856 0.0815 0.0782 0.0768 0.0753 0.0736 0.0728 0.0724 0.0718 

[TRAIN] Epoch[1](6995/114412); Loss: 0.074956; Backpropagation: 0.2911 sec; Batch: 2.1220 sec
0.1237 0.1084 0.0946 0.0868 0.0791 0.0748 0.0705 0.0684 0.0662 0.0637 0.0625 0.0613 0.0604 0.0602 0.0594 0.0592 

[TRAIN] Epoch[1](6996/114412); Loss: 0.106531; Backpropagation: 0.2929 sec; Batch: 2.1178 sec
0.2044 0.1872 0.1554 0.1421 0.1215 0.1072 0.0958 0.0877 0.0832 0.0792 0.0769 0.0757 0.0741 0.0725 0.0712 0.0702 

[TRAIN] Epoch[1](6997/114412); Loss: 0.094141; Backpropagation: 0.2914 sec; Batch: 2.0896 sec
0.2033 0.1729 0.1318 0.1163 0.0970 0.0883 0.0802 0.0759 0.0723 0.0701 0.0688 0.0671 0.0663 0.0658 0.0652 0.0648 

[TRAIN] Epoch[1](6998/114412); Loss: 0.102134; Backpropagation: 0.2929 sec; Batch: 2.0834 sec
0.2070 0.1773 0.1454 0.1271 0.1094 0.0998 0.0906 0.0832 0.0790 0.0769 0.0757 0.0744 0.0730 0.0723 0.0719 0.0711 

[TRAIN] Epoch[1](6999/114412); Loss: 0.123692; Backpropagation: 0.2911 sec; Batch: 2.0840 sec
0.2533 0.2087 0.1716 0.1478 0.1247 0.1192 0.1096 0.1040 0.1005 0.0973 0.0942 0.0920 0.0903 0.0892 0.0887 0.0881 

[TRAIN] Epoch[1](7000/114412); Loss: 0.098697; Backpropagation: 0.2906 sec; Batch: 2.0780 sec
0.1572 0.1472 0.1185 0.1095 0.0987 0.0950 0.0925 0.0900 0.0890 0.0864 0.0848 0.0839 0.0826 0.0820 0.0812 0.0807 

[TRAIN] Epoch[1](7001/114412); Loss: 0.104983; Backpropagation: 0.2913 sec; Batch: 2.1187 sec
0.1878 0.1750 0.1454 0.1329 0.1118 0.1006 0.0930 0.0879 0.0864 0.0843 0.0826 0.0809 0.0794 0.0784 0.0771 0.0762 

[TRAIN] Epoch[1](7002/114412); Loss: 0.092225; Backpropagation: 0.2960 sec; Batch: 2.0970 sec
0.1846 0.1756 0.1316 0.1173 0.0994 0.0921 0.0826 0.0762 0.0716 0.0675 0.0652 0.0644 0.0628 0.0622 0.0616 0.0611 

[TRAIN] Epoch[1](7003/114412); Loss: 0.090220; Backpropagation: 0.2912 sec; Batch: 2.1196 sec
0.1314 0.1197 0.1099 0.1009 0.0951 0.0910 0.0874 0.0843 0.0818 0.0802 0.0789 0.0776 0.0771 0.0767 0.0759 0.0756 

[TRAIN] Epoch[1](7004/114412); Loss: 0.077468; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1348 0.1247 0.0998 0.0915 0.0799 0.0759 0.0705 0.0675 0.0661 0.0642 0.0628 0.0615 0.0607 0.0602 0.0597 0.0596 

[TRAIN] Epoch[1](7005/114412); Loss: 0.072373; Backpropagation: 0.2912 sec; Batch: 2.0782 sec
0.1424 0.1242 0.1003 0.0885 0.0745 0.0674 0.0620 0.0608 0.0584 0.0566 0.0553 0.0545 0.0540 0.0534 0.0530 0.0526 

[TRAIN] Epoch[1](7006/114412); Loss: 0.088476; Backpropagation: 0.2906 sec; Batch: 2.1166 sec
0.1647 0.1550 0.1232 0.1107 0.0929 0.0853 0.0780 0.0744 0.0713 0.0704 0.0677 0.0663 0.0652 0.0642 0.0636 0.0628 

[TRAIN] Epoch[1](7007/114412); Loss: 0.120242; Backpropagation: 0.2912 sec; Batch: 2.0791 sec
0.1700 0.1639 0.1513 0.1413 0.1289 0.1261 0.1192 0.1153 0.1116 0.1076 0.1048 0.1018 0.0988 0.0963 0.0944 0.0928 

[TRAIN] Epoch[1](7008/114412); Loss: 0.113122; Backpropagation: 0.2914 sec; Batch: 2.1211 sec
0.1970 0.1782 0.1549 0.1448 0.1266 0.1154 0.1076 0.1011 0.0957 0.0911 0.0877 0.0843 0.0825 0.0819 0.0811 0.0799 

[TRAIN] Epoch[1](7009/114412); Loss: 0.089467; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1475 0.1453 0.1257 0.1122 0.0965 0.0906 0.0826 0.0778 0.0746 0.0724 0.0707 0.0690 0.0681 0.0670 0.0661 0.0654 

[TRAIN] Epoch[1](7010/114412); Loss: 0.104063; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1742 0.1636 0.1425 0.1291 0.1139 0.1039 0.0970 0.0937 0.0891 0.0843 0.0820 0.0802 0.0785 0.0782 0.0777 0.0771 

[TRAIN] Epoch[1](7011/114412); Loss: 0.111883; Backpropagation: 0.2918 sec; Batch: 2.1387 sec
0.2318 0.2096 0.1635 0.1446 0.1201 0.1046 0.0941 0.0877 0.0842 0.0819 0.0799 0.0789 0.0778 0.0775 0.0773 0.0766 

[TRAIN] Epoch[1](7012/114412); Loss: 0.118256; Backpropagation: 0.2935 sec; Batch: 2.1027 sec
0.2196 0.1937 0.1571 0.1394 0.1219 0.1101 0.1040 0.1005 0.0981 0.0954 0.0943 0.0935 0.0924 0.0914 0.0907 0.0901 

[TRAIN] Epoch[1](7013/114412); Loss: 0.115443; Backpropagation: 0.2954 sec; Batch: 2.1044 sec
0.1907 0.1810 0.1548 0.1428 0.1299 0.1198 0.1088 0.1013 0.0964 0.0926 0.0908 0.0898 0.0882 0.0874 0.0868 0.0860 

[TRAIN] Epoch[1](7014/114412); Loss: 0.119832; Backpropagation: 0.2935 sec; Batch: 2.1222 sec
0.2278 0.2017 0.1610 0.1501 0.1290 0.1139 0.1060 0.1022 0.0988 0.0953 0.0927 0.0900 0.0884 0.0878 0.0868 0.0859 

[TRAIN] Epoch[1](7015/114412); Loss: 0.081498; Backpropagation: 0.2933 sec; Batch: 2.1199 sec
0.1710 0.1559 0.1276 0.1141 0.0907 0.0764 0.0693 0.0639 0.0597 0.0573 0.0554 0.0542 0.0531 0.0522 0.0517 0.0515 

[TRAIN] Epoch[1](7016/114412); Loss: 0.111678; Backpropagation: 0.2915 sec; Batch: 2.1320 sec
0.1911 0.1704 0.1434 0.1291 0.1155 0.1076 0.1010 0.0957 0.0918 0.0899 0.0897 0.0901 0.0906 0.0922 0.0937 0.0949 

[TRAIN] Epoch[1](7017/114412); Loss: 0.096350; Backpropagation: 0.2911 sec; Batch: 2.1131 sec
0.1745 0.1633 0.1271 0.1127 0.0981 0.0897 0.0839 0.0818 0.0798 0.0780 0.0773 0.0763 0.0756 0.0750 0.0745 0.0741 

[TRAIN] Epoch[1](7018/114412); Loss: 0.107273; Backpropagation: 0.2916 sec; Batch: 2.1139 sec
0.1673 0.1579 0.1393 0.1324 0.1204 0.1087 0.1035 0.0995 0.0960 0.0892 0.0870 0.0858 0.0842 0.0829 0.0815 0.0807 

[TRAIN] Epoch[1](7019/114412); Loss: 0.096675; Backpropagation: 0.2910 sec; Batch: 2.0850 sec
0.1714 0.1626 0.1346 0.1152 0.0992 0.0886 0.0855 0.0822 0.0810 0.0791 0.0768 0.0754 0.0746 0.0741 0.0736 0.0729 

[TRAIN] Epoch[1](7020/114412); Loss: 0.089347; Backpropagation: 0.2911 sec; Batch: 2.1045 sec
0.1465 0.1400 0.1214 0.1115 0.0977 0.0898 0.0827 0.0783 0.0752 0.0730 0.0715 0.0701 0.0690 0.0684 0.0675 0.0669 

[TRAIN] Epoch[1](7021/114412); Loss: 0.126180; Backpropagation: 0.2914 sec; Batch: 2.1176 sec
0.2240 0.2101 0.1766 0.1636 0.1439 0.1304 0.1175 0.1101 0.1047 0.1001 0.0971 0.0933 0.0900 0.0876 0.0857 0.0841 

[TRAIN] Epoch[1](7022/114412); Loss: 0.106635; Backpropagation: 0.2911 sec; Batch: 2.1194 sec
0.1486 0.1408 0.1276 0.1173 0.1122 0.1078 0.1028 0.1001 0.0983 0.0960 0.0943 0.0934 0.0927 0.0919 0.0914 0.0911 

[TRAIN] Epoch[1](7023/114412); Loss: 0.096066; Backpropagation: 0.2910 sec; Batch: 2.0784 sec
0.1724 0.1639 0.1310 0.1160 0.1015 0.0911 0.0840 0.0807 0.0784 0.0766 0.0756 0.0744 0.0733 0.0730 0.0727 0.0725 

[TRAIN] Epoch[1](7024/114412); Loss: 0.085279; Backpropagation: 0.2932 sec; Batch: 2.1458 sec
0.1568 0.1440 0.1168 0.1066 0.0936 0.0833 0.0764 0.0718 0.0691 0.0667 0.0652 0.0640 0.0629 0.0625 0.0624 0.0623 

[TRAIN] Epoch[1](7025/114412); Loss: 0.097866; Backpropagation: 0.2912 sec; Batch: 2.1190 sec
0.1866 0.1732 0.1395 0.1260 0.1079 0.0973 0.0876 0.0813 0.0775 0.0740 0.0722 0.0706 0.0692 0.0682 0.0677 0.0673 

[TRAIN] Epoch[1](7026/114412); Loss: 0.124628; Backpropagation: 0.2913 sec; Batch: 2.1170 sec
0.2153 0.2012 0.1599 0.1437 0.1295 0.1214 0.1120 0.1069 0.1059 0.1032 0.1013 0.0999 0.0985 0.0984 0.0986 0.0982 

[TRAIN] Epoch[1](7027/114412); Loss: 0.117706; Backpropagation: 0.2930 sec; Batch: 2.1149 sec
0.2047 0.1917 0.1646 0.1520 0.1318 0.1199 0.1083 0.1013 0.0970 0.0925 0.0902 0.0889 0.0869 0.0854 0.0844 0.0837 

[TRAIN] Epoch[1](7028/114412); Loss: 0.078789; Backpropagation: 0.2905 sec; Batch: 2.1435 sec
0.1266 0.1212 0.1071 0.0970 0.0874 0.0826 0.0754 0.0712 0.0676 0.0643 0.0626 0.0612 0.0602 0.0597 0.0588 0.0577 

[TRAIN] Epoch[1](7029/114412); Loss: 0.100669; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1908 0.1716 0.1437 0.1318 0.1137 0.1030 0.0931 0.0851 0.0799 0.0756 0.0729 0.0710 0.0701 0.0697 0.0695 0.0693 

[TRAIN] Epoch[1](7030/114412); Loss: 0.124891; Backpropagation: 0.2910 sec; Batch: 2.1244 sec
0.2084 0.1925 0.1709 0.1573 0.1380 0.1240 0.1137 0.1088 0.1050 0.1021 0.0996 0.0981 0.0967 0.0954 0.0943 0.0936 

[TRAIN] Epoch[1](7031/114412); Loss: 0.085234; Backpropagation: 0.2910 sec; Batch: 2.0880 sec
0.1372 0.1248 0.1132 0.1040 0.0923 0.0846 0.0793 0.0763 0.0737 0.0720 0.0702 0.0691 0.0682 0.0669 0.0662 0.0656 

[TRAIN] Epoch[1](7032/114412); Loss: 0.086836; Backpropagation: 0.2928 sec; Batch: 2.1185 sec
0.1325 0.1243 0.1126 0.1033 0.0924 0.0858 0.0813 0.0780 0.0759 0.0745 0.0732 0.0723 0.0715 0.0712 0.0705 0.0701 

[TRAIN] Epoch[1](7033/114412); Loss: 0.076857; Backpropagation: 0.2915 sec; Batch: 2.1163 sec
0.1434 0.1289 0.1033 0.0928 0.0819 0.0735 0.0685 0.0663 0.0631 0.0612 0.0599 0.0586 0.0577 0.0575 0.0568 0.0564 

[TRAIN] Epoch[1](7034/114412); Loss: 0.089915; Backpropagation: 0.2930 sec; Batch: 2.1189 sec
0.1508 0.1403 0.1221 0.1141 0.1007 0.0911 0.0833 0.0787 0.0752 0.0735 0.0706 0.0690 0.0687 0.0677 0.0667 0.0661 

[TRAIN] Epoch[1](7035/114412); Loss: 0.095455; Backpropagation: 0.2954 sec; Batch: 2.1239 sec
0.1603 0.1352 0.1188 0.1089 0.1001 0.0944 0.0897 0.0870 0.0839 0.0814 0.0801 0.0790 0.0780 0.0773 0.0766 0.0765 

[TRAIN] Epoch[1](7036/114412); Loss: 0.066831; Backpropagation: 0.2928 sec; Batch: 2.1224 sec
0.1353 0.1292 0.0907 0.0809 0.0684 0.0618 0.0569 0.0543 0.0519 0.0498 0.0489 0.0483 0.0483 0.0482 0.0481 0.0482 

[TRAIN] Epoch[1](7037/114412); Loss: 0.083969; Backpropagation: 0.2930 sec; Batch: 2.1207 sec
0.1198 0.1145 0.1037 0.0976 0.0915 0.0856 0.0805 0.0780 0.0757 0.0739 0.0724 0.0714 0.0703 0.0701 0.0694 0.0691 

[TRAIN] Epoch[1](7038/114412); Loss: 0.100977; Backpropagation: 0.2914 sec; Batch: 2.1042 sec
0.1981 0.1859 0.1557 0.1388 0.1165 0.1019 0.0902 0.0826 0.0775 0.0732 0.0697 0.0675 0.0661 0.0649 0.0639 0.0631 

[TRAIN] Epoch[1](7039/114412); Loss: 0.114485; Backpropagation: 0.2911 sec; Batch: 2.1253 sec
0.2085 0.1861 0.1569 0.1452 0.1269 0.1153 0.1065 0.0996 0.0945 0.0906 0.0876 0.0855 0.0839 0.0828 0.0815 0.0807 

[TRAIN] Epoch[1](7040/114412); Loss: 0.114016; Backpropagation: 0.2930 sec; Batch: 2.1185 sec
0.1948 0.1841 0.1548 0.1430 0.1261 0.1140 0.1063 0.1015 0.0969 0.0926 0.0896 0.0865 0.0850 0.0841 0.0829 0.0821 

[TRAIN] Epoch[1](7041/114412); Loss: 0.086478; Backpropagation: 0.2910 sec; Batch: 2.1189 sec
0.1452 0.1385 0.1134 0.1054 0.0913 0.0847 0.0798 0.0759 0.0730 0.0714 0.0697 0.0684 0.0674 0.0670 0.0667 0.0660 

[TRAIN] Epoch[1](7042/114412); Loss: 0.131087; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.2145 0.2049 0.1743 0.1671 0.1501 0.1385 0.1292 0.1208 0.1147 0.1084 0.1033 0.0999 0.0966 0.0941 0.0917 0.0890 

[TRAIN] Epoch[1](7043/114412); Loss: 0.111025; Backpropagation: 0.2908 sec; Batch: 2.1145 sec
0.2097 0.1917 0.1590 0.1449 0.1257 0.1122 0.1021 0.0920 0.0873 0.0842 0.0805 0.0791 0.0781 0.0774 0.0767 0.0760 

[TRAIN] Epoch[1](7044/114412); Loss: 0.081868; Backpropagation: 0.2933 sec; Batch: 2.1196 sec
0.1266 0.1184 0.1077 0.0973 0.0852 0.0804 0.0762 0.0736 0.0717 0.0700 0.0689 0.0682 0.0675 0.0666 0.0660 0.0656 

[TRAIN] Epoch[1](7045/114412); Loss: 0.098635; Backpropagation: 0.2911 sec; Batch: 2.1349 sec
0.1635 0.1536 0.1366 0.1250 0.1099 0.0996 0.0932 0.0879 0.0834 0.0801 0.0778 0.0760 0.0744 0.0732 0.0723 0.0717 

[TRAIN] Epoch[1](7046/114412); Loss: 0.121194; Backpropagation: 0.2902 sec; Batch: 2.1166 sec
0.2101 0.2031 0.1645 0.1514 0.1322 0.1197 0.1115 0.1060 0.1022 0.0968 0.0941 0.0922 0.0898 0.0892 0.0889 0.0874 

[TRAIN] Epoch[1](7047/114412); Loss: 0.114780; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1818 0.1693 0.1476 0.1399 0.1248 0.1143 0.1080 0.1039 0.1001 0.0965 0.0945 0.0928 0.0918 0.0908 0.0904 0.0900 

[TRAIN] Epoch[1](7048/114412); Loss: 0.088764; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.1720 0.1595 0.1258 0.1130 0.0969 0.0843 0.0777 0.0735 0.0697 0.0674 0.0656 0.0645 0.0639 0.0628 0.0620 0.0617 

[TRAIN] Epoch[1](7049/114412); Loss: 0.085695; Backpropagation: 0.2914 sec; Batch: 2.1219 sec
0.1602 0.1429 0.1152 0.1045 0.0909 0.0832 0.0770 0.0734 0.0704 0.0682 0.0665 0.0652 0.0644 0.0635 0.0631 0.0627 

[TRAIN] Epoch[1](7050/114412); Loss: 0.106238; Backpropagation: 0.2912 sec; Batch: 2.0780 sec
0.2005 0.1863 0.1500 0.1365 0.1172 0.1032 0.0949 0.0885 0.0846 0.0816 0.0789 0.0773 0.0761 0.0753 0.0747 0.0743 

[TRAIN] Epoch[1](7051/114412); Loss: 0.129127; Backpropagation: 0.2912 sec; Batch: 2.1208 sec
0.2726 0.2471 0.2059 0.1840 0.1548 0.1317 0.1151 0.1057 0.0937 0.0869 0.0834 0.0802 0.0781 0.0769 0.0756 0.0744 

[TRAIN] Epoch[1](7052/114412); Loss: 0.103112; Backpropagation: 0.2919 sec; Batch: 2.0784 sec
0.2034 0.1934 0.1539 0.1382 0.1160 0.1020 0.0922 0.0849 0.0786 0.0751 0.0724 0.0701 0.0690 0.0678 0.0667 0.0660 

[TRAIN] Epoch[1](7053/114412); Loss: 0.094128; Backpropagation: 0.2908 sec; Batch: 2.1162 sec
0.1767 0.1656 0.1361 0.1192 0.1031 0.0897 0.0828 0.0795 0.0747 0.0716 0.0702 0.0691 0.0682 0.0671 0.0665 0.0658 

[TRAIN] Epoch[1](7054/114412); Loss: 0.093513; Backpropagation: 0.2927 sec; Batch: 2.0796 sec
0.1739 0.1647 0.1283 0.1168 0.1005 0.0901 0.0835 0.0785 0.0748 0.0727 0.0710 0.0696 0.0686 0.0682 0.0677 0.0673 

[TRAIN] Epoch[1](7055/114412); Loss: 0.080340; Backpropagation: 0.2930 sec; Batch: 2.0792 sec
0.1353 0.1199 0.1032 0.0949 0.0855 0.0799 0.0771 0.0728 0.0693 0.0673 0.0657 0.0644 0.0634 0.0627 0.0621 0.0619 

[TRAIN] Epoch[1](7056/114412); Loss: 0.090828; Backpropagation: 0.2910 sec; Batch: 2.0864 sec
0.1455 0.1317 0.1112 0.0996 0.0916 0.0894 0.0852 0.0825 0.0807 0.0790 0.0776 0.0770 0.0764 0.0756 0.0752 0.0750 

[TRAIN] Epoch[1](7057/114412); Loss: 0.095307; Backpropagation: 0.2929 sec; Batch: 2.1181 sec
0.1599 0.1451 0.1170 0.1067 0.0954 0.0903 0.0866 0.0852 0.0827 0.0816 0.0807 0.0795 0.0789 0.0786 0.0784 0.0783 

[TRAIN] Epoch[1](7058/114412); Loss: 0.099782; Backpropagation: 0.2911 sec; Batch: 2.0962 sec
0.1750 0.1691 0.1320 0.1211 0.1029 0.0927 0.0875 0.0838 0.0820 0.0806 0.0796 0.0789 0.0782 0.0778 0.0777 0.0775 

[TRAIN] Epoch[1](7059/114412); Loss: 0.104988; Backpropagation: 0.2952 sec; Batch: 2.1216 sec
0.1497 0.1472 0.1238 0.1171 0.1089 0.1039 0.0995 0.0981 0.0958 0.0933 0.0922 0.0912 0.0905 0.0899 0.0895 0.0892 

[TRAIN] Epoch[1](7060/114412); Loss: 0.119816; Backpropagation: 0.2927 sec; Batch: 2.1312 sec
0.2510 0.2317 0.1707 0.1469 0.1245 0.1125 0.1023 0.0955 0.0931 0.0881 0.0867 0.0851 0.0837 0.0830 0.0813 0.0810 

[TRAIN] Epoch[1](7061/114412); Loss: 0.127094; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.2320 0.2119 0.1770 0.1590 0.1393 0.1259 0.1146 0.1088 0.1031 0.0989 0.0978 0.0961 0.0940 0.0930 0.0915 0.0908 

[TRAIN] Epoch[1](7062/114412); Loss: 0.065696; Backpropagation: 0.2928 sec; Batch: 2.1157 sec
0.1395 0.1323 0.0921 0.0753 0.0628 0.0572 0.0535 0.0519 0.0502 0.0497 0.0488 0.0481 0.0478 0.0475 0.0473 0.0471 

[TRAIN] Epoch[1](7063/114412); Loss: 0.123613; Backpropagation: 0.2914 sec; Batch: 2.1202 sec
0.1882 0.1777 0.1519 0.1407 0.1311 0.1239 0.1172 0.1129 0.1096 0.1071 0.1053 0.1041 0.1032 0.1023 0.1015 0.1009 

[TRAIN] Epoch[1](7064/114412); Loss: 0.086641; Backpropagation: 0.2911 sec; Batch: 2.1281 sec
0.1392 0.1264 0.1044 0.0973 0.0910 0.0850 0.0809 0.0790 0.0769 0.0749 0.0736 0.0724 0.0718 0.0712 0.0711 0.0709 

[TRAIN] Epoch[1](7065/114412); Loss: 0.113796; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.2276 0.2058 0.1614 0.1499 0.1279 0.1153 0.1043 0.0947 0.0897 0.0852 0.0814 0.0791 0.0766 0.0748 0.0738 0.0732 

[TRAIN] Epoch[1](7066/114412); Loss: 0.100094; Backpropagation: 0.2931 sec; Batch: 2.1205 sec
0.1646 0.1433 0.1261 0.1119 0.1032 0.0979 0.0924 0.0903 0.0878 0.0865 0.0851 0.0838 0.0831 0.0823 0.0819 0.0814 

[TRAIN] Epoch[1](7067/114412); Loss: 0.092265; Backpropagation: 0.2914 sec; Batch: 2.0789 sec
0.1782 0.1679 0.1308 0.1215 0.1004 0.0881 0.0805 0.0761 0.0721 0.0697 0.0683 0.0663 0.0653 0.0645 0.0637 0.0630 

[TRAIN] Epoch[1](7068/114412); Loss: 0.085626; Backpropagation: 0.2913 sec; Batch: 2.0872 sec
0.1752 0.1557 0.1292 0.1082 0.0933 0.0831 0.0716 0.0687 0.0657 0.0629 0.0612 0.0600 0.0591 0.0587 0.0588 0.0584 

[TRAIN] Epoch[1](7069/114412); Loss: 0.111160; Backpropagation: 0.2942 sec; Batch: 2.1712 sec
0.1914 0.1706 0.1447 0.1338 0.1218 0.1108 0.1022 0.0976 0.0939 0.0920 0.0901 0.0885 0.0873 0.0859 0.0845 0.0834 

[TRAIN] Epoch[1](7070/114412); Loss: 0.090337; Backpropagation: 0.2917 sec; Batch: 2.0807 sec
0.1504 0.1406 0.1233 0.1137 0.0993 0.0896 0.0840 0.0805 0.0770 0.0738 0.0716 0.0698 0.0689 0.0683 0.0675 0.0671 

[TRAIN] Epoch[1](7071/114412); Loss: 0.086191; Backpropagation: 0.2910 sec; Batch: 2.0936 sec
0.2044 0.1768 0.1132 0.1007 0.0896 0.0795 0.0720 0.0672 0.0633 0.0617 0.0601 0.0590 0.0585 0.0580 0.0577 0.0573 

[TRAIN] Epoch[1](7072/114412); Loss: 0.117348; Backpropagation: 0.2906 sec; Batch: 2.1350 sec
0.2228 0.2029 0.1716 0.1424 0.1290 0.1170 0.1012 0.0985 0.0953 0.0897 0.0883 0.0864 0.0843 0.0834 0.0826 0.0822 

[TRAIN] Epoch[1](7073/114412); Loss: 0.071906; Backpropagation: 0.2927 sec; Batch: 2.0837 sec
0.1331 0.1197 0.0884 0.0862 0.0770 0.0687 0.0639 0.0621 0.0603 0.0582 0.0573 0.0566 0.0555 0.0550 0.0544 0.0542 

[TRAIN] Epoch[1](7074/114412); Loss: 0.115093; Backpropagation: 0.2915 sec; Batch: 2.1184 sec
0.1979 0.1852 0.1607 0.1474 0.1280 0.1151 0.1067 0.0995 0.0948 0.0915 0.0891 0.0875 0.0855 0.0846 0.0841 0.0838 

[TRAIN] Epoch[1](7075/114412); Loss: 0.097523; Backpropagation: 0.2905 sec; Batch: 2.1167 sec
0.1677 0.1396 0.1199 0.1111 0.1036 0.0964 0.0907 0.0883 0.0850 0.0828 0.0814 0.0799 0.0794 0.0787 0.0782 0.0778 

[TRAIN] Epoch[1](7076/114412); Loss: 0.078097; Backpropagation: 0.2914 sec; Batch: 2.1189 sec
0.1453 0.1403 0.1124 0.0989 0.0840 0.0762 0.0697 0.0652 0.0617 0.0592 0.0579 0.0567 0.0560 0.0557 0.0553 0.0550 

[TRAIN] Epoch[1](7077/114412); Loss: 0.079606; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1236 0.1121 0.0932 0.0861 0.0817 0.0777 0.0747 0.0735 0.0712 0.0701 0.0695 0.0688 0.0682 0.0679 0.0677 0.0678 

[TRAIN] Epoch[1](7078/114412); Loss: 0.120338; Backpropagation: 0.2903 sec; Batch: 2.1163 sec
0.2148 0.2023 0.1668 0.1535 0.1306 0.1179 0.1095 0.1021 0.0970 0.0941 0.0918 0.0903 0.0895 0.0887 0.0882 0.0882 

[TRAIN] Epoch[1](7079/114412); Loss: 0.087703; Backpropagation: 0.2911 sec; Batch: 2.1142 sec
0.1506 0.1391 0.1174 0.1070 0.0943 0.0860 0.0806 0.0767 0.0736 0.0714 0.0700 0.0689 0.0679 0.0672 0.0666 0.0660 

[TRAIN] Epoch[1](7080/114412); Loss: 0.071875; Backpropagation: 0.2912 sec; Batch: 2.1022 sec
0.1539 0.1399 0.1103 0.0924 0.0743 0.0660 0.0582 0.0552 0.0538 0.0518 0.0511 0.0500 0.0490 0.0485 0.0480 0.0476 

[TRAIN] Epoch[1](7081/114412); Loss: 0.131780; Backpropagation: 0.2952 sec; Batch: 2.1200 sec
0.1951 0.1924 0.1616 0.1508 0.1390 0.1299 0.1242 0.1210 0.1180 0.1157 0.1139 0.1120 0.1104 0.1091 0.1082 0.1072 

[TRAIN] Epoch[1](7082/114412); Loss: 0.092761; Backpropagation: 0.2928 sec; Batch: 2.0796 sec
0.1673 0.1508 0.1190 0.1079 0.0946 0.0886 0.0840 0.0803 0.0782 0.0758 0.0750 0.0739 0.0730 0.0724 0.0718 0.0716 

[TRAIN] Epoch[1](7083/114412); Loss: 0.067855; Backpropagation: 0.2911 sec; Batch: 2.1198 sec
0.1347 0.1221 0.0892 0.0783 0.0662 0.0622 0.0590 0.0564 0.0551 0.0544 0.0528 0.0518 0.0515 0.0511 0.0506 0.0504 

[TRAIN] Epoch[1](7084/114412); Loss: 0.105178; Backpropagation: 0.2928 sec; Batch: 2.1194 sec
0.1627 0.1523 0.1325 0.1258 0.1134 0.1048 0.0989 0.0958 0.0927 0.0904 0.0881 0.0868 0.0857 0.0849 0.0843 0.0838 

[TRAIN] Epoch[1](7085/114412); Loss: 0.100021; Backpropagation: 0.2912 sec; Batch: 2.1165 sec
0.1626 0.1546 0.1314 0.1201 0.1065 0.0973 0.0913 0.0890 0.0858 0.0839 0.0821 0.0808 0.0800 0.0789 0.0782 0.0779 

[TRAIN] Epoch[1](7086/114412); Loss: 0.096613; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.1633 0.1587 0.1228 0.1110 0.0984 0.0934 0.0894 0.0861 0.0831 0.0808 0.0790 0.0776 0.0766 0.0757 0.0751 0.0747 

[TRAIN] Epoch[1](7087/114412); Loss: 0.106514; Backpropagation: 0.2914 sec; Batch: 2.1166 sec
0.1574 0.1489 0.1341 0.1251 0.1134 0.1049 0.1000 0.0964 0.0941 0.0927 0.0914 0.0907 0.0900 0.0891 0.0883 0.0879 

[TRAIN] Epoch[1](7088/114412); Loss: 0.127834; Backpropagation: 0.2907 sec; Batch: 2.1209 sec
0.2031 0.1834 0.1602 0.1499 0.1356 0.1261 0.1195 0.1146 0.1109 0.1087 0.1074 0.1069 0.1059 0.1050 0.1044 0.1037 

[TRAIN] Epoch[1](7089/114412); Loss: 0.111691; Backpropagation: 0.2912 sec; Batch: 2.0945 sec
0.1910 0.1797 0.1516 0.1392 0.1212 0.1108 0.1012 0.0977 0.0946 0.0911 0.0886 0.0868 0.0851 0.0838 0.0827 0.0820 

[TRAIN] Epoch[1](7090/114412); Loss: 0.103777; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.1914 0.1791 0.1449 0.1354 0.1155 0.1024 0.0935 0.0874 0.0839 0.0800 0.0773 0.0760 0.0747 0.0739 0.0729 0.0722 

[TRAIN] Epoch[1](7091/114412); Loss: 0.101243; Backpropagation: 0.2928 sec; Batch: 2.1189 sec
0.2047 0.1786 0.1516 0.1397 0.1208 0.1042 0.0931 0.0850 0.0777 0.0734 0.0699 0.0669 0.0648 0.0639 0.0632 0.0626 

[TRAIN] Epoch[1](7092/114412); Loss: 0.113945; Backpropagation: 0.2910 sec; Batch: 2.1161 sec
0.1801 0.1665 0.1446 0.1351 0.1206 0.1137 0.1068 0.1021 0.0993 0.0969 0.0954 0.0940 0.0931 0.0922 0.0916 0.0911 

[TRAIN] Epoch[1](7093/114412); Loss: 0.098788; Backpropagation: 0.2928 sec; Batch: 2.1149 sec
0.1786 0.1702 0.1413 0.1275 0.1072 0.0961 0.0871 0.0821 0.0802 0.0783 0.0751 0.0732 0.0719 0.0708 0.0705 0.0705 

[TRAIN] Epoch[1](7094/114412); Loss: 0.089492; Backpropagation: 0.2926 sec; Batch: 2.1179 sec
0.1671 0.1556 0.1214 0.1089 0.0982 0.0885 0.0813 0.0765 0.0722 0.0695 0.0675 0.0662 0.0655 0.0649 0.0643 0.0642 

[TRAIN] Epoch[1](7095/114412); Loss: 0.098778; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.1515 0.1461 0.1261 0.1155 0.1055 0.0982 0.0920 0.0884 0.0856 0.0838 0.0828 0.0819 0.0813 0.0809 0.0805 0.0803 

[TRAIN] Epoch[1](7096/114412); Loss: 0.103454; Backpropagation: 0.2929 sec; Batch: 2.1218 sec
0.1854 0.1759 0.1402 0.1269 0.1126 0.1008 0.0939 0.0891 0.0854 0.0825 0.0800 0.0786 0.0774 0.0762 0.0755 0.0748 

[TRAIN] Epoch[1](7097/114412); Loss: 0.118630; Backpropagation: 0.2914 sec; Batch: 2.1208 sec
0.1928 0.1775 0.1540 0.1419 0.1304 0.1225 0.1140 0.1077 0.1031 0.0997 0.0963 0.0941 0.0923 0.0913 0.0905 0.0898 

[TRAIN] Epoch[1](7098/114412); Loss: 0.068937; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.1291 0.1218 0.0896 0.0794 0.0683 0.0652 0.0608 0.0581 0.0571 0.0553 0.0544 0.0537 0.0531 0.0527 0.0522 0.0522 

[TRAIN] Epoch[1](7099/114412); Loss: 0.132355; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.2942 0.2623 0.2068 0.1854 0.1526 0.1311 0.1155 0.1044 0.0951 0.0899 0.0855 0.0824 0.0805 0.0785 0.0772 0.0762 

[TRAIN] Epoch[1](7100/114412); Loss: 0.078135; Backpropagation: 0.2915 sec; Batch: 2.1336 sec
0.1438 0.1255 0.1038 0.0939 0.0816 0.0740 0.0695 0.0669 0.0654 0.0636 0.0622 0.0611 0.0604 0.0600 0.0594 0.0592 

[TRAIN] Epoch[1](7101/114412); Loss: 0.129927; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.2137 0.1969 0.1741 0.1624 0.1448 0.1347 0.1250 0.1169 0.1110 0.1063 0.1035 0.1012 0.0992 0.0973 0.0962 0.0955 

[TRAIN] Epoch[1](7102/114412); Loss: 0.081488; Backpropagation: 0.2907 sec; Batch: 2.1133 sec
0.1628 0.1481 0.1203 0.1076 0.0906 0.0796 0.0710 0.0672 0.0632 0.0605 0.0585 0.0568 0.0557 0.0546 0.0540 0.0535 

[TRAIN] Epoch[1](7103/114412); Loss: 0.113345; Backpropagation: 0.2907 sec; Batch: 2.1178 sec
0.1915 0.1785 0.1606 0.1499 0.1323 0.1212 0.1075 0.0994 0.0943 0.0893 0.0869 0.0846 0.0824 0.0802 0.0783 0.0766 

[TRAIN] Epoch[1](7104/114412); Loss: 0.096961; Backpropagation: 0.2912 sec; Batch: 2.1190 sec
0.1772 0.1699 0.1360 0.1200 0.1033 0.0916 0.0865 0.0824 0.0788 0.0763 0.0742 0.0728 0.0716 0.0709 0.0703 0.0697 

[TRAIN] Epoch[1](7105/114412); Loss: 0.082668; Backpropagation: 0.2925 sec; Batch: 2.1188 sec
0.1479 0.1292 0.1184 0.1027 0.0895 0.0811 0.0734 0.0711 0.0688 0.0661 0.0646 0.0632 0.0625 0.0620 0.0613 0.0607 

[TRAIN] Epoch[1](7106/114412); Loss: 0.097670; Backpropagation: 0.2932 sec; Batch: 2.1174 sec
0.1783 0.1624 0.1383 0.1247 0.1087 0.0973 0.0880 0.0820 0.0790 0.0765 0.0742 0.0726 0.0713 0.0704 0.0698 0.0692 

[TRAIN] Epoch[1](7107/114412); Loss: 0.114048; Backpropagation: 0.2927 sec; Batch: 2.1007 sec
0.2425 0.2247 0.1807 0.1610 0.1311 0.1114 0.0974 0.0887 0.0825 0.0784 0.0756 0.0730 0.0712 0.0700 0.0688 0.0679 

[TRAIN] Epoch[1](7108/114412); Loss: 0.075940; Backpropagation: 0.2951 sec; Batch: 2.1197 sec
0.1165 0.1118 0.0960 0.0873 0.0802 0.0745 0.0701 0.0687 0.0671 0.0654 0.0644 0.0637 0.0628 0.0624 0.0623 0.0619 

[TRAIN] Epoch[1](7109/114412); Loss: 0.089493; Backpropagation: 0.2926 sec; Batch: 2.1270 sec
0.1604 0.1467 0.1228 0.1103 0.0955 0.0861 0.0800 0.0764 0.0734 0.0715 0.0699 0.0693 0.0685 0.0676 0.0669 0.0666 

[TRAIN] Epoch[1](7110/114412); Loss: 0.089315; Backpropagation: 0.2932 sec; Batch: 2.1224 sec
0.1361 0.1224 0.1075 0.1008 0.0942 0.0876 0.0843 0.0828 0.0802 0.0786 0.0778 0.0766 0.0758 0.0753 0.0747 0.0746 

[TRAIN] Epoch[1](7111/114412); Loss: 0.107720; Backpropagation: 0.2928 sec; Batch: 2.1174 sec
0.1724 0.1607 0.1393 0.1237 0.1111 0.1031 0.0992 0.0964 0.0940 0.0931 0.0909 0.0894 0.0887 0.0877 0.0871 0.0865 

[TRAIN] Epoch[1](7112/114412); Loss: 0.103271; Backpropagation: 0.2910 sec; Batch: 2.1186 sec
0.1760 0.1613 0.1345 0.1234 0.1109 0.1025 0.0980 0.0934 0.0895 0.0866 0.0835 0.0808 0.0798 0.0787 0.0772 0.0762 

[TRAIN] Epoch[1](7113/114412); Loss: 0.117044; Backpropagation: 0.2931 sec; Batch: 2.1281 sec
0.1628 0.1548 0.1438 0.1356 0.1249 0.1167 0.1118 0.1089 0.1062 0.1042 0.1025 0.1015 0.1008 0.1000 0.0994 0.0988 

[TRAIN] Epoch[1](7114/114412); Loss: 0.090269; Backpropagation: 0.2913 sec; Batch: 2.1200 sec
0.1300 0.1187 0.1073 0.0996 0.0935 0.0887 0.0853 0.0843 0.0823 0.0809 0.0799 0.0792 0.0790 0.0787 0.0785 0.0783 

[TRAIN] Epoch[1](7115/114412); Loss: 0.106551; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.2129 0.1980 0.1505 0.1262 0.1105 0.0987 0.0901 0.0868 0.0845 0.0819 0.0802 0.0788 0.0779 0.0767 0.0758 0.0755 

[TRAIN] Epoch[1](7116/114412); Loss: 0.095667; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1573 0.1416 0.1197 0.1105 0.1011 0.0939 0.0887 0.0850 0.0829 0.0814 0.0803 0.0795 0.0783 0.0775 0.0768 0.0761 

[TRAIN] Epoch[1](7117/114412); Loss: 0.107708; Backpropagation: 0.2916 sec; Batch: 2.1187 sec
0.1721 0.1622 0.1360 0.1231 0.1126 0.1042 0.0981 0.0949 0.0926 0.0908 0.0901 0.0899 0.0896 0.0892 0.0889 0.0889 

[TRAIN] Epoch[1](7118/114412); Loss: 0.094260; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1680 0.1586 0.1352 0.1262 0.1088 0.0962 0.0878 0.0818 0.0778 0.0741 0.0701 0.0678 0.0658 0.0643 0.0634 0.0624 

[TRAIN] Epoch[1](7119/114412); Loss: 0.094791; Backpropagation: 0.2912 sec; Batch: 2.1132 sec
0.1568 0.1464 0.1215 0.1117 0.1014 0.0942 0.0889 0.0849 0.0814 0.0787 0.0772 0.0762 0.0752 0.0744 0.0739 0.0738 

[TRAIN] Epoch[1](7120/114412); Loss: 0.112576; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.2055 0.1934 0.1631 0.1534 0.1330 0.1189 0.1066 0.0976 0.0915 0.0861 0.0813 0.0783 0.0758 0.0737 0.0721 0.0709 

[TRAIN] Epoch[1](7121/114412); Loss: 0.087323; Backpropagation: 0.2906 sec; Batch: 2.0771 sec
0.1628 0.1467 0.1253 0.1117 0.0971 0.0856 0.0774 0.0725 0.0691 0.0671 0.0657 0.0648 0.0642 0.0631 0.0624 0.0616 

[TRAIN] Epoch[1](7122/114412); Loss: 0.101063; Backpropagation: 0.2909 sec; Batch: 2.1250 sec
0.1911 0.1803 0.1420 0.1225 0.1057 0.0948 0.0885 0.0857 0.0811 0.0786 0.0778 0.0758 0.0738 0.0736 0.0733 0.0725 

[TRAIN] Epoch[1](7123/114412); Loss: 0.069299; Backpropagation: 0.2904 sec; Batch: 2.1130 sec
0.1417 0.1301 0.0962 0.0863 0.0710 0.0627 0.0591 0.0555 0.0533 0.0523 0.0511 0.0502 0.0501 0.0500 0.0496 0.0497 

[TRAIN] Epoch[1](7124/114412); Loss: 0.077659; Backpropagation: 0.2903 sec; Batch: 2.1129 sec
0.1698 0.1506 0.1091 0.0926 0.0771 0.0702 0.0644 0.0626 0.0597 0.0581 0.0565 0.0555 0.0550 0.0544 0.0537 0.0533 

[TRAIN] Epoch[1](7125/114412); Loss: 0.090886; Backpropagation: 0.2926 sec; Batch: 2.1207 sec
0.1682 0.1561 0.1310 0.1198 0.1044 0.0928 0.0843 0.0779 0.0721 0.0686 0.0665 0.0647 0.0633 0.0622 0.0615 0.0609 

[TRAIN] Epoch[1](7126/114412); Loss: 0.127392; Backpropagation: 0.2919 sec; Batch: 2.1178 sec
0.1838 0.1763 0.1601 0.1483 0.1384 0.1281 0.1226 0.1198 0.1159 0.1125 0.1098 0.1077 0.1061 0.1044 0.1029 0.1016 

[TRAIN] Epoch[1](7127/114412); Loss: 0.106821; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1936 0.1813 0.1552 0.1367 0.1143 0.1010 0.0941 0.0897 0.0848 0.0818 0.0810 0.0808 0.0800 0.0794 0.0780 0.0774 

[TRAIN] Epoch[1](7128/114412); Loss: 0.093187; Backpropagation: 0.2914 sec; Batch: 2.1210 sec
0.1676 0.1522 0.1193 0.1060 0.0960 0.0888 0.0844 0.0822 0.0797 0.0762 0.0750 0.0741 0.0730 0.0726 0.0722 0.0717 

[TRAIN] Epoch[1](7129/114412); Loss: 0.096385; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1844 0.1682 0.1398 0.1228 0.1063 0.0942 0.0863 0.0805 0.0762 0.0732 0.0717 0.0699 0.0682 0.0675 0.0668 0.0661 

[TRAIN] Epoch[1](7130/114412); Loss: 0.081928; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.1685 0.1570 0.1185 0.1022 0.0893 0.0773 0.0715 0.0666 0.0625 0.0596 0.0581 0.0570 0.0562 0.0557 0.0554 0.0553 

[TRAIN] Epoch[1](7131/114412); Loss: 0.066482; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.1283 0.1223 0.0888 0.0785 0.0684 0.0618 0.0580 0.0564 0.0537 0.0522 0.0508 0.0499 0.0494 0.0489 0.0484 0.0481 

[TRAIN] Epoch[1](7132/114412); Loss: 0.077196; Backpropagation: 0.2933 sec; Batch: 2.1228 sec
0.1574 0.1494 0.1130 0.0950 0.0760 0.0686 0.0653 0.0612 0.0597 0.0588 0.0567 0.0559 0.0554 0.0547 0.0542 0.0538 

[TRAIN] Epoch[1](7133/114412); Loss: 0.090351; Backpropagation: 0.2911 sec; Batch: 2.1151 sec
0.1397 0.1283 0.1113 0.1013 0.0951 0.0884 0.0845 0.0821 0.0802 0.0787 0.0778 0.0767 0.0761 0.0755 0.0751 0.0748 

[TRAIN] Epoch[1](7134/114412); Loss: 0.096950; Backpropagation: 0.2915 sec; Batch: 2.1186 sec
0.1647 0.1520 0.1282 0.1186 0.1042 0.0977 0.0908 0.0868 0.0832 0.0800 0.0775 0.0755 0.0743 0.0731 0.0726 0.0721 

[TRAIN] Epoch[1](7135/114412); Loss: 0.098896; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1704 0.1502 0.1273 0.1103 0.1009 0.0960 0.0906 0.0873 0.0847 0.0829 0.0817 0.0808 0.0804 0.0802 0.0797 0.0789 

[TRAIN] Epoch[1](7136/114412); Loss: 0.091791; Backpropagation: 0.2911 sec; Batch: 2.1221 sec
0.1380 0.1335 0.1180 0.1132 0.1029 0.0942 0.0881 0.0835 0.0803 0.0777 0.0762 0.0746 0.0733 0.0724 0.0715 0.0711 

[TRAIN] Epoch[1](7137/114412); Loss: 0.112498; Backpropagation: 0.2911 sec; Batch: 2.0785 sec
0.2148 0.1869 0.1596 0.1486 0.1267 0.1100 0.1003 0.0930 0.0889 0.0859 0.0836 0.0829 0.0810 0.0800 0.0792 0.0785 

[TRAIN] Epoch[1](7138/114412); Loss: 0.117403; Backpropagation: 0.2953 sec; Batch: 2.1198 sec
0.2128 0.1980 0.1641 0.1547 0.1352 0.1183 0.1071 0.0985 0.0936 0.0904 0.0874 0.0855 0.0840 0.0832 0.0830 0.0825 

[TRAIN] Epoch[1](7139/114412); Loss: 0.088097; Backpropagation: 0.2948 sec; Batch: 2.1171 sec
0.1685 0.1523 0.1300 0.1166 0.1001 0.0859 0.0787 0.0715 0.0683 0.0660 0.0640 0.0632 0.0623 0.0612 0.0607 0.0604 

[TRAIN] Epoch[1](7140/114412); Loss: 0.100059; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.2157 0.1851 0.1438 0.1227 0.1064 0.0965 0.0868 0.0816 0.0777 0.0744 0.0722 0.0699 0.0691 0.0673 0.0661 0.0655 

[TRAIN] Epoch[1](7141/114412); Loss: 0.070484; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1344 0.1207 0.0970 0.0828 0.0738 0.0679 0.0638 0.0606 0.0576 0.0559 0.0546 0.0531 0.0522 0.0516 0.0510 0.0507 

[TRAIN] Epoch[1](7142/114412); Loss: 0.088319; Backpropagation: 0.2912 sec; Batch: 2.1213 sec
0.1480 0.1374 0.1157 0.1058 0.0944 0.0881 0.0813 0.0801 0.0758 0.0737 0.0719 0.0702 0.0691 0.0680 0.0672 0.0665 

[TRAIN] Epoch[1](7143/114412); Loss: 0.111748; Backpropagation: 0.2918 sec; Batch: 2.0781 sec
0.1968 0.1830 0.1536 0.1393 0.1259 0.1144 0.1046 0.0985 0.0934 0.0888 0.0860 0.0839 0.0820 0.0803 0.0792 0.0782 

[TRAIN] Epoch[1](7144/114412); Loss: 0.108183; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.2047 0.1907 0.1562 0.1412 0.1220 0.1096 0.0992 0.0913 0.0874 0.0830 0.0795 0.0768 0.0743 0.0729 0.0715 0.0706 

[TRAIN] Epoch[1](7145/114412); Loss: 0.129414; Backpropagation: 0.2952 sec; Batch: 2.1225 sec
0.2799 0.2569 0.2023 0.1815 0.1466 0.1261 0.1099 0.1011 0.0949 0.0885 0.0846 0.0823 0.0803 0.0792 0.0784 0.0779 

[TRAIN] Epoch[1](7146/114412); Loss: 0.093869; Backpropagation: 0.2934 sec; Batch: 2.1195 sec
0.1679 0.1458 0.1284 0.1146 0.1001 0.0907 0.0844 0.0810 0.0780 0.0759 0.0744 0.0735 0.0727 0.0720 0.0715 0.0712 

[TRAIN] Epoch[1](7147/114412); Loss: 0.122669; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.2323 0.2192 0.1781 0.1592 0.1401 0.1245 0.1132 0.1048 0.0983 0.0928 0.0887 0.0857 0.0832 0.0823 0.0808 0.0795 

[TRAIN] Epoch[1](7148/114412); Loss: 0.093547; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1788 0.1621 0.1376 0.1238 0.1059 0.0954 0.0851 0.0773 0.0722 0.0692 0.0675 0.0660 0.0646 0.0643 0.0641 0.0630 

[TRAIN] Epoch[1](7149/114412); Loss: 0.104692; Backpropagation: 0.2906 sec; Batch: 2.1287 sec
0.1544 0.1476 0.1393 0.1290 0.1160 0.1062 0.1013 0.0968 0.0940 0.0911 0.0876 0.0856 0.0838 0.0813 0.0808 0.0802 

[TRAIN] Epoch[1](7150/114412); Loss: 0.056946; Backpropagation: 0.2905 sec; Batch: 2.1183 sec
0.1101 0.1088 0.0742 0.0637 0.0544 0.0497 0.0480 0.0473 0.0459 0.0454 0.0448 0.0441 0.0441 0.0438 0.0434 0.0435 

[TRAIN] Epoch[1](7151/114412); Loss: 0.090036; Backpropagation: 0.2910 sec; Batch: 2.1129 sec
0.1571 0.1581 0.1308 0.1253 0.1022 0.0909 0.0823 0.0774 0.0730 0.0694 0.0666 0.0642 0.0622 0.0611 0.0603 0.0596 

[TRAIN] Epoch[1](7152/114412); Loss: 0.069466; Backpropagation: 0.2926 sec; Batch: 2.1194 sec
0.1319 0.1167 0.1018 0.0908 0.0767 0.0671 0.0612 0.0583 0.0553 0.0534 0.0522 0.0506 0.0498 0.0490 0.0485 0.0481 

[TRAIN] Epoch[1](7153/114412); Loss: 0.100083; Backpropagation: 0.2922 sec; Batch: 2.1177 sec
0.1611 0.1476 0.1261 0.1133 0.1021 0.0964 0.0922 0.0897 0.0881 0.0862 0.0850 0.0837 0.0831 0.0827 0.0822 0.0819 

[TRAIN] Epoch[1](7154/114412); Loss: 0.106754; Backpropagation: 0.2911 sec; Batch: 2.0846 sec
0.1731 0.1618 0.1420 0.1314 0.1184 0.1084 0.1003 0.0952 0.0912 0.0882 0.0862 0.0848 0.0830 0.0821 0.0813 0.0805 

[TRAIN] Epoch[1](7155/114412); Loss: 0.071674; Backpropagation: 0.2932 sec; Batch: 2.1071 sec
0.1152 0.1047 0.0901 0.0829 0.0746 0.0707 0.0665 0.0643 0.0629 0.0610 0.0599 0.0592 0.0590 0.0588 0.0586 0.0585 

[TRAIN] Epoch[1](7156/114412); Loss: 0.094461; Backpropagation: 0.2910 sec; Batch: 2.1203 sec
0.1917 0.1688 0.1307 0.1111 0.0943 0.0881 0.0803 0.0794 0.0766 0.0742 0.0728 0.0709 0.0698 0.0683 0.0675 0.0668 

[TRAIN] Epoch[1](7157/114412); Loss: 0.075765; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.1201 0.1051 0.0879 0.0834 0.0786 0.0726 0.0721 0.0693 0.0672 0.0662 0.0655 0.0651 0.0648 0.0647 0.0647 0.0649 

[TRAIN] Epoch[1](7158/114412); Loss: 0.084913; Backpropagation: 0.2911 sec; Batch: 2.1150 sec
0.1388 0.1340 0.1106 0.1014 0.0889 0.0831 0.0782 0.0749 0.0723 0.0704 0.0692 0.0684 0.0679 0.0673 0.0668 0.0664 

[TRAIN] Epoch[1](7159/114412); Loss: 0.108542; Backpropagation: 0.2908 sec; Batch: 2.1178 sec
0.2414 0.2156 0.1728 0.1587 0.1328 0.1110 0.0971 0.0859 0.0778 0.0718 0.0674 0.0647 0.0623 0.0602 0.0589 0.0582 

[TRAIN] Epoch[1](7160/114412); Loss: 0.166555; Backpropagation: 0.2910 sec; Batch: 2.1206 sec
0.2845 0.2746 0.2408 0.2289 0.2009 0.1816 0.1639 0.1493 0.1383 0.1296 0.1239 0.1195 0.1138 0.1087 0.1047 0.1020 

[TRAIN] Epoch[1](7161/114412); Loss: 0.113206; Backpropagation: 0.2914 sec; Batch: 2.0781 sec
0.2032 0.1908 0.1629 0.1445 0.1263 0.1134 0.1026 0.0958 0.0914 0.0876 0.0857 0.0837 0.0824 0.0811 0.0802 0.0795 

[TRAIN] Epoch[1](7162/114412); Loss: 0.094736; Backpropagation: 0.2930 sec; Batch: 2.1184 sec
0.1534 0.1419 0.1146 0.1056 0.0976 0.0929 0.0892 0.0865 0.0841 0.0818 0.0798 0.0788 0.0782 0.0775 0.0771 0.0768 

[TRAIN] Epoch[1](7163/114412); Loss: 0.082382; Backpropagation: 0.2911 sec; Batch: 2.1199 sec
0.1462 0.1402 0.1201 0.1048 0.0916 0.0826 0.0747 0.0703 0.0669 0.0635 0.0614 0.0603 0.0595 0.0591 0.0585 0.0583 

[TRAIN] Epoch[1](7164/114412); Loss: 0.081718; Backpropagation: 0.2907 sec; Batch: 2.1145 sec
0.1458 0.1319 0.1118 0.1008 0.0896 0.0811 0.0750 0.0709 0.0674 0.0654 0.0638 0.0625 0.0614 0.0605 0.0600 0.0595 

[TRAIN] Epoch[1](7165/114412); Loss: 0.101224; Backpropagation: 0.2930 sec; Batch: 2.1189 sec
0.1731 0.1667 0.1366 0.1214 0.1058 0.0965 0.0902 0.0871 0.0854 0.0833 0.0811 0.0799 0.0789 0.0784 0.0779 0.0773 

[TRAIN] Epoch[1](7166/114412); Loss: 0.095769; Backpropagation: 0.2915 sec; Batch: 2.0882 sec
0.1791 0.1458 0.1198 0.1092 0.0961 0.0912 0.0862 0.0846 0.0818 0.0802 0.0786 0.0773 0.0764 0.0757 0.0752 0.0749 

[TRAIN] Epoch[1](7167/114412); Loss: 0.095181; Backpropagation: 0.2915 sec; Batch: 2.1207 sec
0.1613 0.1527 0.1249 0.1107 0.0986 0.0913 0.0881 0.0837 0.0810 0.0790 0.0778 0.0768 0.0756 0.0743 0.0738 0.0732 

[TRAIN] Epoch[1](7168/114412); Loss: 0.088757; Backpropagation: 0.2910 sec; Batch: 2.1240 sec
0.1388 0.1307 0.1110 0.1020 0.0906 0.0845 0.0816 0.0800 0.0780 0.0768 0.0757 0.0751 0.0745 0.0740 0.0736 0.0733 

[TRAIN] Epoch[1](7169/114412); Loss: 0.120658; Backpropagation: 0.2914 sec; Batch: 2.1190 sec
0.2025 0.1852 0.1649 0.1519 0.1394 0.1261 0.1152 0.1080 0.1029 0.0981 0.0952 0.0921 0.0895 0.0878 0.0865 0.0851 

[TRAIN] Epoch[1](7170/114412); Loss: 0.107230; Backpropagation: 0.2925 sec; Batch: 2.0941 sec
0.1855 0.1744 0.1445 0.1363 0.1219 0.1098 0.0994 0.0931 0.0884 0.0841 0.0821 0.0809 0.0799 0.0790 0.0785 0.0780 

[TRAIN] Epoch[1](7171/114412); Loss: 0.090439; Backpropagation: 0.2921 sec; Batch: 2.1325 sec
0.1810 0.1609 0.1252 0.1045 0.0913 0.0834 0.0784 0.0754 0.0727 0.0712 0.0693 0.0681 0.0673 0.0665 0.0660 0.0657 

[TRAIN] Epoch[1](7172/114412); Loss: 0.096793; Backpropagation: 0.2925 sec; Batch: 2.1183 sec
0.1573 0.1426 0.1189 0.1093 0.0992 0.0944 0.0897 0.0873 0.0850 0.0835 0.0821 0.0810 0.0805 0.0797 0.0793 0.0790 

[TRAIN] Epoch[1](7173/114412); Loss: 0.103741; Backpropagation: 0.2912 sec; Batch: 2.1078 sec
0.1889 0.1722 0.1551 0.1329 0.1145 0.1017 0.0903 0.0838 0.0816 0.0797 0.0784 0.0774 0.0767 0.0761 0.0755 0.0751 

[TRAIN] Epoch[1](7174/114412); Loss: 0.109253; Backpropagation: 0.2947 sec; Batch: 2.1179 sec
0.2203 0.2008 0.1634 0.1465 0.1229 0.1061 0.0962 0.0891 0.0834 0.0798 0.0768 0.0742 0.0734 0.0723 0.0716 0.0712 

[TRAIN] Epoch[1](7175/114412); Loss: 0.080658; Backpropagation: 0.2914 sec; Batch: 2.1183 sec
0.1567 0.1534 0.1154 0.1019 0.0869 0.0768 0.0699 0.0649 0.0625 0.0604 0.0590 0.0577 0.0568 0.0565 0.0561 0.0558 

[TRAIN] Epoch[1](7176/114412); Loss: 0.069805; Backpropagation: 0.2903 sec; Batch: 2.1163 sec
0.1523 0.1491 0.1113 0.0950 0.0758 0.0630 0.0565 0.0535 0.0500 0.0474 0.0461 0.0445 0.0437 0.0433 0.0428 0.0426 

[TRAIN] Epoch[1](7177/114412); Loss: 0.065932; Backpropagation: 0.2904 sec; Batch: 2.1177 sec
0.1383 0.1288 0.0989 0.0831 0.0690 0.0618 0.0549 0.0525 0.0502 0.0483 0.0468 0.0458 0.0450 0.0443 0.0438 0.0435 

[TRAIN] Epoch[1](7178/114412); Loss: 0.099116; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1655 0.1579 0.1238 0.1139 0.1026 0.0951 0.0910 0.0877 0.0850 0.0828 0.0815 0.0807 0.0799 0.0796 0.0795 0.0795 

[TRAIN] Epoch[1](7179/114412); Loss: 0.098496; Backpropagation: 0.2916 sec; Batch: 2.0776 sec
0.2065 0.1840 0.1447 0.1296 0.1104 0.0969 0.0878 0.0825 0.0769 0.0729 0.0691 0.0663 0.0643 0.0627 0.0611 0.0600 

[TRAIN] Epoch[1](7180/114412); Loss: 0.082543; Backpropagation: 0.2908 sec; Batch: 2.0933 sec
0.1678 0.1564 0.1212 0.1048 0.0882 0.0766 0.0679 0.0651 0.0632 0.0615 0.0601 0.0590 0.0580 0.0574 0.0569 0.0566 

[TRAIN] Epoch[1](7181/114412); Loss: 0.067350; Backpropagation: 0.2904 sec; Batch: 2.1118 sec
0.1368 0.1321 0.1049 0.0906 0.0738 0.0619 0.0551 0.0525 0.0494 0.0479 0.0468 0.0460 0.0454 0.0450 0.0448 0.0445 

[TRAIN] Epoch[1](7182/114412); Loss: 0.110456; Backpropagation: 0.2928 sec; Batch: 2.1199 sec
0.2171 0.1939 0.1551 0.1376 0.1160 0.1035 0.0972 0.0918 0.0881 0.0849 0.0831 0.0817 0.0805 0.0795 0.0789 0.0783 

[TRAIN] Epoch[1](7183/114412); Loss: 0.090830; Backpropagation: 0.2915 sec; Batch: 2.1213 sec
0.2135 0.1952 0.1381 0.1195 0.0931 0.0822 0.0760 0.0686 0.0646 0.0620 0.0602 0.0578 0.0568 0.0559 0.0550 0.0546 

[TRAIN] Epoch[1](7184/114412); Loss: 0.095275; Backpropagation: 0.2907 sec; Batch: 2.1157 sec
0.1538 0.1441 0.1196 0.1104 0.1019 0.0948 0.0892 0.0862 0.0836 0.0809 0.0794 0.0777 0.0768 0.0759 0.0752 0.0747 

[TRAIN] Epoch[1](7185/114412); Loss: 0.109342; Backpropagation: 0.2908 sec; Batch: 2.1197 sec
0.1641 0.1475 0.1346 0.1234 0.1155 0.1098 0.1048 0.1017 0.0993 0.0968 0.0948 0.0934 0.0922 0.0912 0.0906 0.0898 

[TRAIN] Epoch[1](7186/114412); Loss: 0.084682; Backpropagation: 0.2914 sec; Batch: 2.0978 sec
0.1742 0.1685 0.1302 0.1126 0.0911 0.0769 0.0681 0.0646 0.0623 0.0601 0.0589 0.0583 0.0577 0.0573 0.0570 0.0569 

[TRAIN] Epoch[1](7187/114412); Loss: 0.076052; Backpropagation: 0.2910 sec; Batch: 2.1206 sec
0.1176 0.1031 0.0988 0.0902 0.0818 0.0776 0.0741 0.0708 0.0686 0.0661 0.0644 0.0630 0.0618 0.0606 0.0595 0.0588 

[TRAIN] Epoch[1](7188/114412); Loss: 0.088087; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1532 0.1449 0.1112 0.1025 0.0909 0.0840 0.0792 0.0771 0.0745 0.0730 0.0718 0.0709 0.0700 0.0694 0.0688 0.0682 

[TRAIN] Epoch[1](7189/114412); Loss: 0.101304; Backpropagation: 0.2929 sec; Batch: 2.1205 sec
0.1912 0.1872 0.1439 0.1310 0.1154 0.1017 0.0928 0.0860 0.0824 0.0775 0.0737 0.0712 0.0692 0.0671 0.0657 0.0648 

[TRAIN] Epoch[1](7190/114412); Loss: 0.112860; Backpropagation: 0.2929 sec; Batch: 2.1207 sec
0.1945 0.1846 0.1600 0.1499 0.1346 0.1226 0.1114 0.1026 0.0950 0.0889 0.0838 0.0796 0.0768 0.0749 0.0740 0.0726 

[TRAIN] Epoch[1](7191/114412); Loss: 0.080356; Backpropagation: 0.2909 sec; Batch: 2.1193 sec
0.1351 0.1251 0.1030 0.0973 0.0864 0.0815 0.0769 0.0713 0.0681 0.0655 0.0640 0.0633 0.0626 0.0621 0.0619 0.0616 

[TRAIN] Epoch[1](7192/114412); Loss: 0.096149; Backpropagation: 0.2933 sec; Batch: 2.1161 sec
0.1620 0.1413 0.1237 0.1132 0.1032 0.0950 0.0913 0.0872 0.0840 0.0815 0.0790 0.0776 0.0761 0.0752 0.0743 0.0738 

[TRAIN] Epoch[1](7193/114412); Loss: 0.085521; Backpropagation: 0.2929 sec; Batch: 2.1220 sec
0.1533 0.1418 0.1116 0.0994 0.0889 0.0819 0.0767 0.0739 0.0715 0.0700 0.0684 0.0673 0.0664 0.0662 0.0657 0.0653 

[TRAIN] Epoch[1](7194/114412); Loss: 0.085716; Backpropagation: 0.2928 sec; Batch: 2.1208 sec
0.1315 0.1222 0.1099 0.1001 0.0910 0.0837 0.0800 0.0787 0.0759 0.0741 0.0731 0.0716 0.0707 0.0702 0.0696 0.0693 

[TRAIN] Epoch[1](7195/114412); Loss: 0.123247; Backpropagation: 0.2939 sec; Batch: 2.1027 sec
0.2141 0.2046 0.1763 0.1660 0.1454 0.1305 0.1186 0.1092 0.1019 0.0958 0.0914 0.0883 0.0847 0.0829 0.0815 0.0806 

[TRAIN] Epoch[1](7196/114412); Loss: 0.116426; Backpropagation: 0.3003 sec; Batch: 2.1295 sec
0.1925 0.1765 0.1521 0.1406 0.1259 0.1149 0.1072 0.1028 0.0989 0.0970 0.0950 0.0935 0.0922 0.0919 0.0911 0.0906 

[TRAIN] Epoch[1](7197/114412); Loss: 0.104497; Backpropagation: 0.2959 sec; Batch: 2.1234 sec
0.1832 0.1648 0.1431 0.1244 0.1108 0.1017 0.0957 0.0909 0.0872 0.0848 0.0829 0.0817 0.0811 0.0805 0.0798 0.0793 

[TRAIN] Epoch[1](7198/114412); Loss: 0.097403; Backpropagation: 0.2956 sec; Batch: 2.1256 sec
0.1673 0.1566 0.1379 0.1270 0.1104 0.1002 0.0906 0.0836 0.0797 0.0765 0.0742 0.0730 0.0717 0.0706 0.0699 0.0692 

[TRAIN] Epoch[1](7199/114412); Loss: 0.095553; Backpropagation: 0.2981 sec; Batch: 2.1238 sec
0.1897 0.1641 0.1305 0.1154 0.1021 0.0925 0.0851 0.0800 0.0765 0.0738 0.0723 0.0710 0.0697 0.0692 0.0688 0.0681 

[TRAIN] Epoch[1](7200/114412); Loss: 0.105809; Backpropagation: 0.2956 sec; Batch: 2.1220 sec
0.1985 0.1811 0.1465 0.1356 0.1167 0.1038 0.0963 0.0906 0.0857 0.0819 0.0794 0.0775 0.0764 0.0753 0.0741 0.0736 

[TRAIN] Epoch[1](7201/114412); Loss: 0.083515; Backpropagation: 0.2953 sec; Batch: 2.1209 sec
0.1345 0.1245 0.1052 0.0935 0.0876 0.0818 0.0778 0.0755 0.0733 0.0719 0.0709 0.0695 0.0686 0.0678 0.0671 0.0667 

[TRAIN] Epoch[1](7202/114412); Loss: 0.080176; Backpropagation: 0.2974 sec; Batch: 2.1247 sec
0.1286 0.1187 0.0997 0.0921 0.0847 0.0789 0.0749 0.0724 0.0705 0.0691 0.0678 0.0665 0.0657 0.0650 0.0644 0.0638 

[TRAIN] Epoch[1](7203/114412); Loss: 0.095788; Backpropagation: 0.2980 sec; Batch: 2.1259 sec
0.1984 0.1713 0.1357 0.1201 0.1031 0.0922 0.0835 0.0776 0.0738 0.0715 0.0700 0.0688 0.0676 0.0668 0.0663 0.0659 

[TRAIN] Epoch[1](7204/114412); Loss: 0.087950; Backpropagation: 0.2957 sec; Batch: 2.1183 sec
0.1621 0.1548 0.1244 0.1133 0.0962 0.0856 0.0780 0.0742 0.0702 0.0675 0.0659 0.0644 0.0633 0.0628 0.0624 0.0623 

[TRAIN] Epoch[1](7205/114412); Loss: 0.097269; Backpropagation: 0.2948 sec; Batch: 2.1169 sec
0.1600 0.1484 0.1258 0.1139 0.1045 0.0951 0.0902 0.0865 0.0838 0.0819 0.0800 0.0789 0.0781 0.0770 0.0763 0.0759 

[TRAIN] Epoch[1](7206/114412); Loss: 0.095753; Backpropagation: 0.2946 sec; Batch: 2.1204 sec
0.1551 0.1451 0.1214 0.1094 0.0992 0.0927 0.0884 0.0850 0.0837 0.0822 0.0805 0.0795 0.0784 0.0776 0.0771 0.0767 

[TRAIN] Epoch[1](7207/114412); Loss: 0.090005; Backpropagation: 0.2949 sec; Batch: 2.1271 sec
0.1469 0.1338 0.1112 0.1000 0.0952 0.0898 0.0846 0.0811 0.0787 0.0768 0.0756 0.0746 0.0737 0.0731 0.0727 0.0724 

[TRAIN] Epoch[1](7208/114412); Loss: 0.124963; Backpropagation: 0.2957 sec; Batch: 2.1215 sec
0.2020 0.1941 0.1640 0.1514 0.1341 0.1233 0.1163 0.1113 0.1074 0.1038 0.1017 0.0999 0.0986 0.0978 0.0971 0.0967 

[TRAIN] Epoch[1](7209/114412); Loss: 0.103233; Backpropagation: 0.3006 sec; Batch: 2.0866 sec
0.2024 0.1836 0.1440 0.1245 0.1067 0.0957 0.0897 0.0854 0.0827 0.0806 0.0784 0.0773 0.0764 0.0754 0.0748 0.0742 

[TRAIN] Epoch[1](7210/114412); Loss: 0.091474; Backpropagation: 0.2983 sec; Batch: 2.1313 sec
0.1565 0.1434 0.1197 0.1086 0.0982 0.0898 0.0852 0.0805 0.0771 0.0750 0.0735 0.0726 0.0716 0.0710 0.0707 0.0702 

[TRAIN] Epoch[1](7211/114412); Loss: 0.087592; Backpropagation: 0.2955 sec; Batch: 2.1221 sec
0.1645 0.1458 0.1172 0.1043 0.0926 0.0864 0.0804 0.0753 0.0721 0.0697 0.0680 0.0670 0.0658 0.0647 0.0641 0.0637 

[TRAIN] Epoch[1](7212/114412); Loss: 0.086975; Backpropagation: 0.2957 sec; Batch: 2.1304 sec
0.1542 0.1424 0.1103 0.1024 0.0937 0.0871 0.0802 0.0766 0.0737 0.0706 0.0698 0.0688 0.0671 0.0657 0.0650 0.0641 

[TRAIN] Epoch[1](7213/114412); Loss: 0.064320; Backpropagation: 0.2954 sec; Batch: 2.0830 sec
0.1424 0.1371 0.0969 0.0824 0.0651 0.0564 0.0519 0.0489 0.0468 0.0451 0.0441 0.0435 0.0429 0.0422 0.0418 0.0416 

[TRAIN] Epoch[1](7214/114412); Loss: 0.099910; Backpropagation: 0.2982 sec; Batch: 2.1179 sec
0.1946 0.1721 0.1351 0.1190 0.1047 0.0958 0.0884 0.0840 0.0813 0.0786 0.0766 0.0757 0.0744 0.0734 0.0726 0.0723 

[TRAIN] Epoch[1](7215/114412); Loss: 0.083306; Backpropagation: 0.2980 sec; Batch: 2.1287 sec
0.1515 0.1364 0.1125 0.1019 0.0881 0.0804 0.0756 0.0727 0.0686 0.0668 0.0657 0.0641 0.0632 0.0625 0.0616 0.0611 

[TRAIN] Epoch[1](7216/114412); Loss: 0.080968; Backpropagation: 0.3009 sec; Batch: 2.1284 sec
0.1550 0.1396 0.1038 0.0914 0.0868 0.0801 0.0735 0.0707 0.0676 0.0649 0.0633 0.0618 0.0604 0.0594 0.0589 0.0582 

[TRAIN] Epoch[1](7217/114412); Loss: 0.081144; Backpropagation: 0.2977 sec; Batch: 2.1255 sec
0.1647 0.1539 0.1210 0.1076 0.0917 0.0803 0.0729 0.0667 0.0607 0.0570 0.0557 0.0547 0.0538 0.0531 0.0523 0.0520 

[TRAIN] Epoch[1](7218/114412); Loss: 0.081320; Backpropagation: 0.2955 sec; Batch: 2.1109 sec
0.1407 0.1243 0.0972 0.0959 0.0844 0.0777 0.0743 0.0725 0.0705 0.0689 0.0678 0.0665 0.0659 0.0654 0.0647 0.0644 

[TRAIN] Epoch[1](7219/114412); Loss: 0.108538; Backpropagation: 0.2955 sec; Batch: 2.1111 sec
0.1764 0.1685 0.1383 0.1248 0.1111 0.1025 0.0993 0.0971 0.0939 0.0923 0.0910 0.0902 0.0891 0.0881 0.0871 0.0870 

[TRAIN] Epoch[1](7220/114412); Loss: 0.080071; Backpropagation: 0.2953 sec; Batch: 2.1318 sec
0.1531 0.1412 0.1081 0.0952 0.0809 0.0739 0.0690 0.0662 0.0646 0.0637 0.0622 0.0615 0.0610 0.0605 0.0601 0.0599 

[TRAIN] Epoch[1](7221/114412); Loss: 0.082513; Backpropagation: 0.2980 sec; Batch: 2.1265 sec
0.1285 0.1198 0.1044 0.0960 0.0884 0.0819 0.0774 0.0740 0.0718 0.0706 0.0695 0.0688 0.0681 0.0673 0.0669 0.0668 

[TRAIN] Epoch[1](7222/114412); Loss: 0.093765; Backpropagation: 0.2979 sec; Batch: 2.1241 sec
0.1940 0.1842 0.1417 0.1264 0.1009 0.0849 0.0779 0.0737 0.0691 0.0662 0.0646 0.0635 0.0632 0.0634 0.0633 0.0632 

[TRAIN] Epoch[1](7223/114412); Loss: 0.080322; Backpropagation: 0.2949 sec; Batch: 2.0825 sec
0.1466 0.1348 0.1080 0.0922 0.0804 0.0754 0.0714 0.0687 0.0678 0.0657 0.0644 0.0633 0.0626 0.0618 0.0611 0.0608 

[TRAIN] Epoch[1](7224/114412); Loss: 0.068097; Backpropagation: 0.2951 sec; Batch: 2.1251 sec
0.1047 0.0994 0.0879 0.0813 0.0737 0.0672 0.0640 0.0627 0.0595 0.0580 0.0572 0.0561 0.0551 0.0546 0.0542 0.0539 

[TRAIN] Epoch[1](7225/114412); Loss: 0.106293; Backpropagation: 0.2968 sec; Batch: 2.0846 sec
0.1840 0.1686 0.1481 0.1335 0.1174 0.1059 0.0970 0.0910 0.0874 0.0844 0.0829 0.0820 0.0812 0.0797 0.0790 0.0787 

[TRAIN] Epoch[1](7226/114412); Loss: 0.085532; Backpropagation: 0.2955 sec; Batch: 2.1096 sec
0.1490 0.1419 0.1146 0.1041 0.0934 0.0846 0.0790 0.0755 0.0720 0.0693 0.0673 0.0655 0.0647 0.0634 0.0624 0.0619 

[TRAIN] Epoch[1](7227/114412); Loss: 0.072458; Backpropagation: 0.2952 sec; Batch: 2.0834 sec
0.1249 0.1141 0.0932 0.0859 0.0754 0.0710 0.0667 0.0636 0.0615 0.0602 0.0586 0.0577 0.0572 0.0569 0.0563 0.0562 

[TRAIN] Epoch[1](7228/114412); Loss: 0.079306; Backpropagation: 0.2959 sec; Batch: 2.1211 sec
0.1448 0.1298 0.1056 0.0988 0.0849 0.0769 0.0714 0.0681 0.0656 0.0635 0.0620 0.0609 0.0600 0.0594 0.0588 0.0584 

[TRAIN] Epoch[1](7229/114412); Loss: 0.080488; Backpropagation: 0.2996 sec; Batch: 2.0875 sec
0.1337 0.1221 0.1035 0.0935 0.0825 0.0778 0.0744 0.0718 0.0695 0.0677 0.0666 0.0658 0.0654 0.0649 0.0644 0.0642 

[TRAIN] Epoch[1](7230/114412); Loss: 0.120123; Backpropagation: 0.2983 sec; Batch: 2.1220 sec
0.2236 0.2093 0.1767 0.1651 0.1361 0.1205 0.1078 0.0992 0.0922 0.0890 0.0867 0.0851 0.0838 0.0829 0.0822 0.0817 

[TRAIN] Epoch[1](7231/114412); Loss: 0.096283; Backpropagation: 0.2950 sec; Batch: 2.0826 sec
0.1452 0.1358 0.1160 0.1063 0.1014 0.0949 0.0912 0.0895 0.0869 0.0850 0.0837 0.0823 0.0815 0.0809 0.0802 0.0799 

[TRAIN] Epoch[1](7232/114412); Loss: 0.069295; Backpropagation: 0.2951 sec; Batch: 2.1231 sec
0.1263 0.1156 0.0992 0.0892 0.0752 0.0663 0.0613 0.0586 0.0563 0.0547 0.0533 0.0520 0.0511 0.0503 0.0498 0.0495 

[TRAIN] Epoch[1](7233/114412); Loss: 0.111843; Backpropagation: 0.2963 sec; Batch: 2.1032 sec
0.2674 0.2328 0.1749 0.1526 0.1222 0.1027 0.0904 0.0831 0.0772 0.0747 0.0722 0.0702 0.0687 0.0673 0.0667 0.0665 

[TRAIN] Epoch[1](7234/114412); Loss: 0.105396; Backpropagation: 0.2978 sec; Batch: 2.1230 sec
0.2269 0.2033 0.1512 0.1397 0.1186 0.1014 0.0916 0.0846 0.0794 0.0759 0.0718 0.0698 0.0693 0.0680 0.0675 0.0673 

[TRAIN] Epoch[1](7235/114412); Loss: 0.111274; Backpropagation: 0.2981 sec; Batch: 2.1287 sec
0.2105 0.2025 0.1691 0.1582 0.1360 0.1201 0.1059 0.0945 0.0865 0.0814 0.0763 0.0723 0.0694 0.0673 0.0654 0.0649 

[TRAIN] Epoch[1](7236/114412); Loss: 0.088592; Backpropagation: 0.2958 sec; Batch: 2.1192 sec
0.1587 0.1529 0.1363 0.1162 0.0965 0.0842 0.0787 0.0739 0.0705 0.0685 0.0661 0.0644 0.0634 0.0630 0.0623 0.0619 

[TRAIN] Epoch[1](7237/114412); Loss: 0.104709; Backpropagation: 0.2958 sec; Batch: 2.1253 sec
0.2046 0.1827 0.1476 0.1327 0.1087 0.0981 0.0916 0.0864 0.0837 0.0813 0.0796 0.0777 0.0766 0.0754 0.0747 0.0739 

[TRAIN] Epoch[1](7238/114412); Loss: 0.119482; Backpropagation: 0.2981 sec; Batch: 2.1235 sec
0.2252 0.1975 0.1512 0.1334 0.1239 0.1110 0.1072 0.1028 0.0998 0.0979 0.0963 0.0951 0.0939 0.0928 0.0921 0.0918 

[TRAIN] Epoch[1](7239/114412); Loss: 0.091071; Backpropagation: 0.2981 sec; Batch: 2.1495 sec
0.1788 0.1725 0.1304 0.1155 0.0915 0.0819 0.0778 0.0740 0.0715 0.0691 0.0673 0.0669 0.0658 0.0651 0.0648 0.0642 

[TRAIN] Epoch[1](7240/114412); Loss: 0.064092; Backpropagation: 0.2979 sec; Batch: 2.1270 sec
0.0986 0.0874 0.0820 0.0729 0.0691 0.0643 0.0607 0.0594 0.0574 0.0560 0.0547 0.0536 0.0530 0.0525 0.0521 0.0518 

[TRAIN] Epoch[1](7241/114412); Loss: 0.099791; Backpropagation: 0.2953 sec; Batch: 2.0831 sec
0.1575 0.1468 0.1231 0.1130 0.1061 0.0995 0.0944 0.0918 0.0884 0.0859 0.0842 0.0829 0.0818 0.0810 0.0803 0.0799 

[TRAIN] Epoch[1](7242/114412); Loss: 0.080451; Backpropagation: 0.2955 sec; Batch: 2.1238 sec
0.1649 0.1411 0.1060 0.0962 0.0835 0.0752 0.0692 0.0668 0.0648 0.0625 0.0614 0.0602 0.0593 0.0588 0.0586 0.0586 

[TRAIN] Epoch[1](7243/114412); Loss: 0.108259; Backpropagation: 0.2953 sec; Batch: 2.1220 sec
0.1612 0.1467 0.1288 0.1197 0.1120 0.1078 0.1037 0.1010 0.0986 0.0964 0.0949 0.0939 0.0928 0.0921 0.0914 0.0910 

[TRAIN] Epoch[1](7244/114412); Loss: 0.123784; Backpropagation: 0.2959 sec; Batch: 2.0853 sec
0.2437 0.2265 0.1773 0.1638 0.1402 0.1216 0.1098 0.1019 0.0957 0.0917 0.0886 0.0861 0.0848 0.0836 0.0828 0.0823 

[TRAIN] Epoch[1](7245/114412); Loss: 0.101569; Backpropagation: 0.2955 sec; Batch: 2.1210 sec
0.1810 0.1596 0.1307 0.1178 0.1064 0.0977 0.0921 0.0887 0.0859 0.0841 0.0823 0.0812 0.0806 0.0795 0.0789 0.0786 

[TRAIN] Epoch[1](7246/114412); Loss: 0.088752; Backpropagation: 0.2950 sec; Batch: 2.1255 sec
0.1474 0.1399 0.1183 0.1075 0.0978 0.0879 0.0822 0.0789 0.0753 0.0728 0.0713 0.0698 0.0689 0.0681 0.0673 0.0667 

[TRAIN] Epoch[1](7247/114412); Loss: 0.092624; Backpropagation: 0.2970 sec; Batch: 2.0847 sec
0.1453 0.1301 0.1149 0.1053 0.0959 0.0909 0.0869 0.0841 0.0818 0.0807 0.0796 0.0786 0.0775 0.0772 0.0769 0.0764 

[TRAIN] Epoch[1](7248/114412); Loss: 0.089949; Backpropagation: 0.2957 sec; Batch: 2.1220 sec
0.1491 0.1396 0.1197 0.1069 0.0972 0.0886 0.0830 0.0807 0.0767 0.0748 0.0728 0.0715 0.0708 0.0700 0.0693 0.0685 

[TRAIN] Epoch[1](7249/114412); Loss: 0.109822; Backpropagation: 0.2947 sec; Batch: 2.1207 sec
0.2024 0.1905 0.1604 0.1418 0.1223 0.1083 0.0982 0.0901 0.0866 0.0839 0.0816 0.0799 0.0788 0.0780 0.0779 0.0766 

[TRAIN] Epoch[1](7250/114412); Loss: 0.072474; Backpropagation: 0.2948 sec; Batch: 2.0894 sec
0.1468 0.1210 0.0849 0.0749 0.0723 0.0700 0.0662 0.0635 0.0602 0.0582 0.0574 0.0572 0.0571 0.0567 0.0567 0.0566 

[TRAIN] Epoch[1](7251/114412); Loss: 0.082196; Backpropagation: 0.2949 sec; Batch: 2.1222 sec
0.1298 0.1197 0.0973 0.0861 0.0798 0.0785 0.0746 0.0738 0.0732 0.0728 0.0720 0.0715 0.0714 0.0712 0.0716 0.0719 

[TRAIN] Epoch[1](7252/114412); Loss: 0.087541; Backpropagation: 0.2949 sec; Batch: 2.1204 sec
0.1451 0.1338 0.1097 0.1010 0.0915 0.0852 0.0808 0.0784 0.0761 0.0742 0.0734 0.0722 0.0708 0.0699 0.0694 0.0691 

[TRAIN] Epoch[1](7253/114412); Loss: 0.120400; Backpropagation: 0.2954 sec; Batch: 2.1098 sec
0.2038 0.1919 0.1645 0.1490 0.1332 0.1221 0.1120 0.1060 0.1018 0.0978 0.0949 0.0930 0.0912 0.0893 0.0883 0.0875 

[TRAIN] Epoch[1](7254/114412); Loss: 0.076874; Backpropagation: 0.2952 sec; Batch: 2.1212 sec
0.1439 0.1218 0.1049 0.0925 0.0828 0.0742 0.0681 0.0657 0.0634 0.0618 0.0605 0.0594 0.0585 0.0580 0.0575 0.0571 

[TRAIN] Epoch[1](7255/114412); Loss: 0.087433; Backpropagation: 0.2947 sec; Batch: 2.1216 sec
0.1453 0.1388 0.1159 0.1075 0.0967 0.0875 0.0810 0.0770 0.0735 0.0710 0.0693 0.0683 0.0676 0.0668 0.0665 0.0662 

[TRAIN] Epoch[1](7256/114412); Loss: 0.076183; Backpropagation: 0.2954 sec; Batch: 2.1229 sec
0.1505 0.1400 0.0981 0.0844 0.0771 0.0696 0.0657 0.0636 0.0617 0.0602 0.0596 0.0588 0.0582 0.0575 0.0570 0.0568 

[TRAIN] Epoch[1](7257/114412); Loss: 0.105840; Backpropagation: 0.2957 sec; Batch: 2.1258 sec
0.1984 0.1860 0.1539 0.1458 0.1243 0.1088 0.0977 0.0887 0.0832 0.0775 0.0745 0.0727 0.0721 0.0707 0.0697 0.0696 

[TRAIN] Epoch[1](7258/114412); Loss: 0.128155; Backpropagation: 0.2982 sec; Batch: 2.1235 sec
0.1973 0.1834 0.1566 0.1450 0.1327 0.1273 0.1211 0.1165 0.1161 0.1124 0.1106 0.1089 0.1070 0.1062 0.1050 0.1044 

[TRAIN] Epoch[1](7259/114412); Loss: 0.088321; Backpropagation: 0.2957 sec; Batch: 2.1224 sec
0.1568 0.1492 0.1208 0.1091 0.0933 0.0815 0.0757 0.0751 0.0725 0.0701 0.0697 0.0690 0.0684 0.0678 0.0673 0.0672 

[TRAIN] Epoch[1](7260/114412); Loss: 0.088294; Backpropagation: 0.2953 sec; Batch: 2.1245 sec
0.1576 0.1484 0.1194 0.1099 0.0952 0.0848 0.0787 0.0756 0.0724 0.0703 0.0690 0.0678 0.0664 0.0660 0.0657 0.0653 

[TRAIN] Epoch[1](7261/114412); Loss: 0.075238; Backpropagation: 0.2956 sec; Batch: 2.1215 sec
0.1286 0.1217 0.0903 0.0819 0.0759 0.0727 0.0688 0.0664 0.0650 0.0635 0.0626 0.0619 0.0615 0.0612 0.0612 0.0607 

[TRAIN] Epoch[1](7262/114412); Loss: 0.064661; Backpropagation: 0.2954 sec; Batch: 2.1210 sec
0.1425 0.1337 0.0955 0.0835 0.0657 0.0584 0.0519 0.0497 0.0477 0.0460 0.0447 0.0442 0.0435 0.0430 0.0424 0.0421 

[TRAIN] Epoch[1](7263/114412); Loss: 0.100320; Backpropagation: 0.2956 sec; Batch: 2.1220 sec
0.1524 0.1422 0.1246 0.1166 0.1060 0.1004 0.0942 0.0901 0.0884 0.0867 0.0856 0.0849 0.0842 0.0834 0.0829 0.0825 

[TRAIN] Epoch[1](7264/114412); Loss: 0.098654; Backpropagation: 0.2953 sec; Batch: 2.0892 sec
0.1518 0.1439 0.1211 0.1122 0.1033 0.0961 0.0927 0.0901 0.0876 0.0863 0.0846 0.0834 0.0824 0.0817 0.0809 0.0802 

[TRAIN] Epoch[1](7265/114412); Loss: 0.084704; Backpropagation: 0.2958 sec; Batch: 2.1226 sec
0.1554 0.1408 0.1103 0.1022 0.0898 0.0806 0.0758 0.0709 0.0694 0.0683 0.0668 0.0659 0.0652 0.0651 0.0645 0.0643 

[TRAIN] Epoch[1](7266/114412); Loss: 0.085576; Backpropagation: 0.2955 sec; Batch: 2.1199 sec
0.1296 0.1228 0.1035 0.0966 0.0905 0.0840 0.0806 0.0784 0.0762 0.0750 0.0735 0.0728 0.0722 0.0716 0.0710 0.0707 

[TRAIN] Epoch[1](7267/114412); Loss: 0.087061; Backpropagation: 0.2958 sec; Batch: 2.1336 sec
0.1515 0.1411 0.1137 0.1040 0.0912 0.0843 0.0794 0.0770 0.0739 0.0713 0.0699 0.0687 0.0679 0.0669 0.0663 0.0659 

[TRAIN] Epoch[1](7268/114412); Loss: 0.110141; Backpropagation: 0.2979 sec; Batch: 2.1243 sec
0.1778 0.1710 0.1450 0.1334 0.1195 0.1109 0.1026 0.0971 0.0946 0.0914 0.0895 0.0877 0.0864 0.0858 0.0849 0.0844 

[TRAIN] Epoch[1](7269/114412); Loss: 0.090002; Backpropagation: 0.2956 sec; Batch: 2.1229 sec
0.1696 0.1518 0.1210 0.1068 0.0918 0.0847 0.0803 0.0769 0.0744 0.0721 0.0708 0.0700 0.0688 0.0678 0.0669 0.0665 

[TRAIN] Epoch[1](7270/114412); Loss: 0.078887; Backpropagation: 0.2978 sec; Batch: 2.1240 sec
0.1347 0.1229 0.1044 0.0925 0.0814 0.0761 0.0718 0.0693 0.0677 0.0658 0.0645 0.0635 0.0626 0.0621 0.0617 0.0613 

[TRAIN] Epoch[1](7271/114412); Loss: 0.097541; Backpropagation: 0.2956 sec; Batch: 2.1195 sec
0.1616 0.1522 0.1268 0.1179 0.1059 0.0973 0.0914 0.0866 0.0833 0.0803 0.0786 0.0773 0.0763 0.0756 0.0750 0.0744 

[TRAIN] Epoch[1](7272/114412); Loss: 0.071912; Backpropagation: 0.2955 sec; Batch: 2.0821 sec
0.1453 0.1370 0.1007 0.0933 0.0803 0.0689 0.0629 0.0597 0.0563 0.0532 0.0511 0.0500 0.0486 0.0480 0.0478 0.0475 

[TRAIN] Epoch[1](7273/114412); Loss: 0.076830; Backpropagation: 0.2950 sec; Batch: 2.1293 sec
0.1058 0.1042 0.1048 0.0946 0.0861 0.0793 0.0734 0.0709 0.0682 0.0661 0.0646 0.0635 0.0625 0.0621 0.0616 0.0615 

[TRAIN] Epoch[1](7274/114412); Loss: 0.078687; Backpropagation: 0.2952 sec; Batch: 2.0871 sec
0.1321 0.1242 0.1032 0.0932 0.0839 0.0763 0.0719 0.0694 0.0676 0.0653 0.0639 0.0628 0.0620 0.0614 0.0610 0.0610 

[TRAIN] Epoch[1](7275/114412); Loss: 0.102804; Backpropagation: 0.2956 sec; Batch: 2.1062 sec
0.1967 0.1806 0.1455 0.1316 0.1138 0.1018 0.0944 0.0888 0.0837 0.0788 0.0755 0.0728 0.0715 0.0706 0.0697 0.0690 

[TRAIN] Epoch[1](7276/114412); Loss: 0.082585; Backpropagation: 0.2957 sec; Batch: 2.0825 sec
0.1185 0.1111 0.1048 0.0979 0.0907 0.0844 0.0796 0.0776 0.0748 0.0727 0.0708 0.0696 0.0685 0.0675 0.0666 0.0662 

[TRAIN] Epoch[1](7277/114412); Loss: 0.121403; Backpropagation: 0.2979 sec; Batch: 2.1228 sec
0.2607 0.2276 0.1711 0.1535 0.1295 0.1140 0.1030 0.0988 0.0954 0.0901 0.0876 0.0857 0.0829 0.0821 0.0811 0.0795 

[TRAIN] Epoch[1](7278/114412); Loss: 0.100668; Backpropagation: 0.2952 sec; Batch: 2.0822 sec
0.2050 0.1959 0.1547 0.1411 0.1207 0.1038 0.0915 0.0840 0.0773 0.0709 0.0668 0.0635 0.0610 0.0593 0.0580 0.0570 

[TRAIN] Epoch[1](7279/114412); Loss: 0.093381; Backpropagation: 0.2949 sec; Batch: 2.1218 sec
0.1604 0.1462 0.1241 0.1141 0.1030 0.0941 0.0866 0.0821 0.0779 0.0758 0.0745 0.0732 0.0718 0.0710 0.0700 0.0694 

[TRAIN] Epoch[1](7280/114412); Loss: 0.100320; Backpropagation: 0.2956 sec; Batch: 2.1193 sec
0.1570 0.1468 0.1254 0.1175 0.1061 0.1001 0.0947 0.0912 0.0884 0.0864 0.0846 0.0833 0.0821 0.0811 0.0805 0.0798 

[TRAIN] Epoch[1](7281/114412); Loss: 0.098956; Backpropagation: 0.2958 sec; Batch: 2.1325 sec
0.2307 0.2170 0.1626 0.1445 0.1119 0.0907 0.0794 0.0711 0.0670 0.0640 0.0600 0.0584 0.0577 0.0566 0.0560 0.0556 

[TRAIN] Epoch[1](7282/114412); Loss: 0.109040; Backpropagation: 0.2981 sec; Batch: 2.1275 sec
0.1983 0.1868 0.1484 0.1326 0.1159 0.1056 0.0989 0.0939 0.0893 0.0861 0.0837 0.0824 0.0817 0.0808 0.0803 0.0799 

[TRAIN] Epoch[1](7283/114412); Loss: 0.105472; Backpropagation: 0.2963 sec; Batch: 2.1218 sec
0.2076 0.1887 0.1479 0.1335 0.1182 0.1040 0.0922 0.0879 0.0834 0.0784 0.0771 0.0756 0.0742 0.0736 0.0728 0.0725 

[TRAIN] Epoch[1](7284/114412); Loss: 0.084879; Backpropagation: 0.2954 sec; Batch: 2.1227 sec
0.1361 0.1237 0.1084 0.0984 0.0911 0.0832 0.0792 0.0774 0.0746 0.0720 0.0709 0.0697 0.0691 0.0686 0.0679 0.0678 

[TRAIN] Epoch[1](7285/114412); Loss: 0.117247; Backpropagation: 0.2982 sec; Batch: 2.1252 sec
0.2582 0.2272 0.1671 0.1482 0.1287 0.1121 0.1010 0.0937 0.0897 0.0849 0.0816 0.0790 0.0777 0.0764 0.0757 0.0749 

[TRAIN] Epoch[1](7286/114412); Loss: 0.104043; Backpropagation: 0.2981 sec; Batch: 2.1246 sec
0.1632 0.1480 0.1279 0.1191 0.1111 0.1041 0.0993 0.0949 0.0926 0.0903 0.0883 0.0869 0.0861 0.0850 0.0844 0.0837 

[TRAIN] Epoch[1](7287/114412); Loss: 0.070869; Backpropagation: 0.2957 sec; Batch: 2.1228 sec
0.1410 0.1320 0.1008 0.0850 0.0699 0.0660 0.0608 0.0573 0.0553 0.0539 0.0533 0.0527 0.0521 0.0517 0.0512 0.0509 

[TRAIN] Epoch[1](7288/114412); Loss: 0.064800; Backpropagation: 0.2960 sec; Batch: 2.0837 sec
0.1177 0.1074 0.0809 0.0732 0.0674 0.0623 0.0594 0.0570 0.0544 0.0530 0.0520 0.0513 0.0508 0.0503 0.0500 0.0498 

[TRAIN] Epoch[1](7289/114412); Loss: 0.085877; Backpropagation: 0.2981 sec; Batch: 2.1256 sec
0.1396 0.1299 0.1155 0.1024 0.0917 0.0869 0.0792 0.0751 0.0732 0.0715 0.0709 0.0692 0.0681 0.0674 0.0669 0.0665 

[TRAIN] Epoch[1](7290/114412); Loss: 0.090648; Backpropagation: 0.2981 sec; Batch: 2.1211 sec
0.1754 0.1577 0.1225 0.1145 0.0966 0.0843 0.0782 0.0755 0.0730 0.0705 0.0692 0.0681 0.0671 0.0664 0.0659 0.0654 

[TRAIN] Epoch[1](7291/114412); Loss: 0.093239; Backpropagation: 0.2954 sec; Batch: 2.1238 sec
0.1575 0.1408 0.1139 0.1028 0.0939 0.0892 0.0855 0.0836 0.0817 0.0801 0.0789 0.0778 0.0772 0.0768 0.0762 0.0759 

[TRAIN] Epoch[1](7292/114412); Loss: 0.090142; Backpropagation: 0.2953 sec; Batch: 2.1202 sec
0.1580 0.1523 0.1258 0.1104 0.0972 0.0873 0.0805 0.0768 0.0738 0.0709 0.0698 0.0685 0.0682 0.0678 0.0674 0.0675 

[TRAIN] Epoch[1](7293/114412); Loss: 0.101815; Backpropagation: 0.2957 sec; Batch: 2.1222 sec
0.1702 0.1617 0.1395 0.1271 0.1112 0.1002 0.0932 0.0887 0.0848 0.0821 0.0803 0.0790 0.0783 0.0777 0.0775 0.0773 

[TRAIN] Epoch[1](7294/114412); Loss: 0.095487; Backpropagation: 0.2949 sec; Batch: 2.0820 sec
0.1387 0.1366 0.1116 0.1022 0.0991 0.0944 0.0911 0.0890 0.0869 0.0854 0.0844 0.0831 0.0825 0.0814 0.0811 0.0804 

[TRAIN] Epoch[1](7295/114412); Loss: 0.089111; Backpropagation: 0.2957 sec; Batch: 2.1251 sec
0.1396 0.1279 0.1104 0.1015 0.0936 0.0877 0.0835 0.0816 0.0790 0.0773 0.0760 0.0749 0.0741 0.0734 0.0728 0.0724 

[TRAIN] Epoch[1](7296/114412); Loss: 0.082728; Backpropagation: 0.2953 sec; Batch: 2.1312 sec
0.1532 0.1399 0.1143 0.1091 0.0955 0.0839 0.0763 0.0691 0.0644 0.0625 0.0615 0.0602 0.0596 0.0589 0.0579 0.0574 

[TRAIN] Epoch[1](7297/114412); Loss: 0.079501; Backpropagation: 0.2980 sec; Batch: 2.0864 sec
0.1351 0.1165 0.1027 0.0935 0.0839 0.0779 0.0744 0.0710 0.0683 0.0669 0.0657 0.0646 0.0638 0.0631 0.0624 0.0620 

[TRAIN] Epoch[1](7298/114412); Loss: 0.072756; Backpropagation: 0.2959 sec; Batch: 2.0851 sec
0.1240 0.1115 0.0931 0.0845 0.0733 0.0697 0.0664 0.0655 0.0635 0.0616 0.0601 0.0592 0.0586 0.0580 0.0577 0.0574 

[TRAIN] Epoch[1](7299/114412); Loss: 0.102208; Backpropagation: 0.2947 sec; Batch: 2.1185 sec
0.1561 0.1440 0.1298 0.1173 0.1080 0.1018 0.0972 0.0947 0.0916 0.0888 0.0870 0.0855 0.0846 0.0837 0.0829 0.0824 

[TRAIN] Epoch[1](7300/114412); Loss: 0.082387; Backpropagation: 0.3029 sec; Batch: 2.0917 sec
0.1295 0.1208 0.1044 0.0965 0.0879 0.0824 0.0790 0.0757 0.0724 0.0698 0.0686 0.0677 0.0668 0.0659 0.0656 0.0651 

[TRAIN] Epoch[1](7301/114412); Loss: 0.106517; Backpropagation: 0.2977 sec; Batch: 2.1272 sec
0.1927 0.1748 0.1457 0.1294 0.1126 0.1032 0.0960 0.0917 0.0878 0.0852 0.0835 0.0822 0.0810 0.0802 0.0794 0.0789 

[TRAIN] Epoch[1](7302/114412); Loss: 0.098524; Backpropagation: 0.2946 sec; Batch: 2.1072 sec
0.1707 0.1616 0.1413 0.1255 0.1106 0.0973 0.0886 0.0849 0.0803 0.0776 0.0762 0.0740 0.0729 0.0721 0.0714 0.0714 

[TRAIN] Epoch[1](7303/114412); Loss: 0.086829; Backpropagation: 0.2959 sec; Batch: 2.1225 sec
0.1303 0.1210 0.1070 0.1018 0.0952 0.0895 0.0847 0.0817 0.0786 0.0755 0.0737 0.0724 0.0708 0.0698 0.0690 0.0682 

[TRAIN] Epoch[1](7304/114412); Loss: 0.100208; Backpropagation: 0.2981 sec; Batch: 2.1230 sec
0.1767 0.1549 0.1265 0.1148 0.1043 0.0954 0.0912 0.0884 0.0864 0.0841 0.0821 0.0810 0.0803 0.0795 0.0791 0.0785 

[TRAIN] Epoch[1](7305/114412); Loss: 0.106741; Backpropagation: 0.2954 sec; Batch: 2.1192 sec
0.2023 0.1801 0.1506 0.1517 0.1286 0.1141 0.1034 0.0951 0.0885 0.0825 0.0766 0.0717 0.0692 0.0660 0.0641 0.0634 

[TRAIN] Epoch[1](7306/114412); Loss: 0.098959; Backpropagation: 0.2947 sec; Batch: 2.1197 sec
0.1658 0.1507 0.1282 0.1159 0.1059 0.0978 0.0922 0.0890 0.0854 0.0829 0.0810 0.0793 0.0782 0.0777 0.0769 0.0764 

[TRAIN] Epoch[1](7307/114412); Loss: 0.087950; Backpropagation: 0.2982 sec; Batch: 2.1258 sec
0.1504 0.1394 0.1166 0.1082 0.0954 0.0875 0.0824 0.0785 0.0753 0.0724 0.0698 0.0680 0.0668 0.0658 0.0656 0.0651 

[TRAIN] Epoch[1](7308/114412); Loss: 0.110814; Backpropagation: 0.2983 sec; Batch: 2.1253 sec
0.2048 0.1901 0.1586 0.1405 0.1222 0.1085 0.1003 0.0943 0.0897 0.0853 0.0833 0.0818 0.0802 0.0788 0.0776 0.0770 

[TRAIN] Epoch[1](7309/114412); Loss: 0.085389; Backpropagation: 0.2956 sec; Batch: 2.1112 sec
0.1243 0.1206 0.1087 0.1014 0.0930 0.0866 0.0816 0.0787 0.0763 0.0741 0.0728 0.0715 0.0705 0.0695 0.0687 0.0680 

[TRAIN] Epoch[1](7310/114412); Loss: 0.108925; Backpropagation: 0.2982 sec; Batch: 2.1120 sec
0.1988 0.1811 0.1490 0.1383 0.1211 0.1109 0.1007 0.0951 0.0895 0.0853 0.0834 0.0809 0.0788 0.0777 0.0766 0.0758 

[TRAIN] Epoch[1](7311/114412); Loss: 0.097075; Backpropagation: 0.2980 sec; Batch: 2.1269 sec
0.1833 0.1747 0.1336 0.1234 0.1094 0.0967 0.0871 0.0837 0.0792 0.0756 0.0726 0.0701 0.0680 0.0664 0.0651 0.0642 

[TRAIN] Epoch[1](7312/114412); Loss: 0.106315; Backpropagation: 0.2966 sec; Batch: 2.0858 sec
0.1868 0.1791 0.1461 0.1366 0.1205 0.1079 0.0977 0.0925 0.0878 0.0839 0.0810 0.0790 0.0774 0.0758 0.0749 0.0741 

[TRAIN] Epoch[1](7313/114412); Loss: 0.070228; Backpropagation: 0.2955 sec; Batch: 2.1077 sec
0.1415 0.1347 0.0986 0.0863 0.0736 0.0659 0.0595 0.0572 0.0541 0.0526 0.0518 0.0507 0.0500 0.0495 0.0490 0.0488 

[TRAIN] Epoch[1](7314/114412); Loss: 0.092608; Backpropagation: 0.2980 sec; Batch: 2.1241 sec
0.1480 0.1388 0.1193 0.1092 0.0974 0.0920 0.0868 0.0834 0.0806 0.0781 0.0763 0.0751 0.0747 0.0743 0.0740 0.0738 

[TRAIN] Epoch[1](7315/114412); Loss: 0.087610; Backpropagation: 0.2971 sec; Batch: 2.1538 sec
0.1470 0.1388 0.1197 0.1088 0.0953 0.0887 0.0826 0.0780 0.0744 0.0717 0.0694 0.0674 0.0660 0.0653 0.0646 0.0641 

[TRAIN] Epoch[1](7316/114412); Loss: 0.093723; Backpropagation: 0.3005 sec; Batch: 2.1048 sec
0.1711 0.1553 0.1250 0.1125 0.0990 0.0932 0.0867 0.0822 0.0780 0.0760 0.0734 0.0720 0.0703 0.0691 0.0682 0.0676 

[TRAIN] Epoch[1](7317/114412); Loss: 0.129795; Backpropagation: 0.2982 sec; Batch: 2.1218 sec
0.2501 0.2349 0.1900 0.1757 0.1480 0.1273 0.1167 0.1064 0.0987 0.0948 0.0926 0.0907 0.0890 0.0880 0.0873 0.0865 

[TRAIN] Epoch[1](7318/114412); Loss: 0.082924; Backpropagation: 0.2960 sec; Batch: 2.1285 sec
0.1478 0.1347 0.1106 0.0980 0.0863 0.0828 0.0774 0.0733 0.0704 0.0681 0.0661 0.0647 0.0630 0.0620 0.0611 0.0604 

[TRAIN] Epoch[1](7319/114412); Loss: 0.107692; Backpropagation: 0.2951 sec; Batch: 2.1241 sec
0.2064 0.1904 0.1539 0.1387 0.1181 0.1043 0.0964 0.0919 0.0875 0.0823 0.0786 0.0768 0.0755 0.0747 0.0741 0.0735 

[TRAIN] Epoch[1](7320/114412); Loss: 0.103290; Backpropagation: 0.2956 sec; Batch: 2.1212 sec
0.1889 0.1736 0.1383 0.1279 0.1100 0.0971 0.0909 0.0889 0.0848 0.0821 0.0810 0.0794 0.0786 0.0777 0.0769 0.0766 

[TRAIN] Epoch[1](7321/114412); Loss: 0.091703; Backpropagation: 0.2954 sec; Batch: 2.1371 sec
0.1744 0.1586 0.1288 0.1178 0.0992 0.0887 0.0819 0.0767 0.0737 0.0708 0.0691 0.0674 0.0661 0.0652 0.0647 0.0643 

[TRAIN] Epoch[1](7322/114412); Loss: 0.108866; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.2113 0.1902 0.1524 0.1364 0.1184 0.1070 0.0984 0.0920 0.0873 0.0844 0.0819 0.0795 0.0779 0.0761 0.0747 0.0738 

[TRAIN] Epoch[1](7323/114412); Loss: 0.090163; Backpropagation: 0.2950 sec; Batch: 2.1329 sec
0.1846 0.1779 0.1356 0.1204 0.0950 0.0820 0.0752 0.0721 0.0688 0.0660 0.0641 0.0623 0.0610 0.0599 0.0591 0.0586 

[TRAIN] Epoch[1](7324/114412); Loss: 0.071959; Backpropagation: 0.2982 sec; Batch: 2.0940 sec
0.1350 0.1224 0.0945 0.0857 0.0756 0.0691 0.0648 0.0610 0.0594 0.0572 0.0557 0.0551 0.0546 0.0540 0.0536 0.0535 

[TRAIN] Epoch[1](7325/114412); Loss: 0.072707; Backpropagation: 0.2978 sec; Batch: 2.1211 sec
0.1248 0.1137 0.0925 0.0854 0.0760 0.0711 0.0670 0.0640 0.0620 0.0603 0.0594 0.0586 0.0576 0.0572 0.0570 0.0569 

[TRAIN] Epoch[1](7326/114412); Loss: 0.076703; Backpropagation: 0.2953 sec; Batch: 2.1212 sec
0.1430 0.1342 0.1093 0.0973 0.0821 0.0733 0.0675 0.0641 0.0615 0.0586 0.0575 0.0566 0.0558 0.0557 0.0554 0.0555 

[TRAIN] Epoch[1](7327/114412); Loss: 0.093003; Backpropagation: 0.2953 sec; Batch: 2.1228 sec
0.1331 0.1258 0.1129 0.1032 0.0963 0.0929 0.0884 0.0866 0.0850 0.0832 0.0821 0.0809 0.0801 0.0796 0.0792 0.0788 

[TRAIN] Epoch[1](7328/114412); Loss: 0.104848; Backpropagation: 0.2951 sec; Batch: 2.1209 sec
0.1595 0.1490 0.1298 0.1221 0.1128 0.1053 0.1003 0.0962 0.0931 0.0913 0.0898 0.0882 0.0865 0.0854 0.0846 0.0836 

[TRAIN] Epoch[1](7329/114412); Loss: 0.081659; Backpropagation: 0.2957 sec; Batch: 2.1280 sec
0.1483 0.1395 0.1108 0.0994 0.0866 0.0772 0.0722 0.0702 0.0675 0.0656 0.0641 0.0626 0.0616 0.0608 0.0603 0.0599 

[TRAIN] Epoch[1](7330/114412); Loss: 0.111746; Backpropagation: 0.2957 sec; Batch: 2.1272 sec
0.1696 0.1576 0.1369 0.1252 0.1171 0.1124 0.1063 0.1032 0.1004 0.0980 0.0962 0.0949 0.0939 0.0927 0.0921 0.0916 

[TRAIN] Epoch[1](7331/114412); Loss: 0.086644; Backpropagation: 0.2949 sec; Batch: 2.1248 sec
0.1341 0.1256 0.1084 0.1000 0.0930 0.0865 0.0815 0.0791 0.0761 0.0745 0.0733 0.0722 0.0715 0.0706 0.0700 0.0697 

[TRAIN] Epoch[1](7332/114412); Loss: 0.095596; Backpropagation: 0.2959 sec; Batch: 2.0841 sec
0.1543 0.1405 0.1135 0.1040 0.0978 0.0932 0.0896 0.0875 0.0853 0.0838 0.0824 0.0810 0.0801 0.0794 0.0787 0.0783 

[TRAIN] Epoch[1](7333/114412); Loss: 0.097429; Backpropagation: 0.2960 sec; Batch: 2.1241 sec
0.1705 0.1578 0.1265 0.1160 0.1028 0.0939 0.0884 0.0856 0.0823 0.0796 0.0782 0.0773 0.0761 0.0751 0.0746 0.0741 

[TRAIN] Epoch[1](7334/114412); Loss: 0.101106; Backpropagation: 0.2998 sec; Batch: 2.0878 sec
0.1629 0.1495 0.1260 0.1168 0.1056 0.1007 0.0955 0.0933 0.0903 0.0871 0.0851 0.0832 0.0817 0.0808 0.0798 0.0794 

[TRAIN] Epoch[1](7335/114412); Loss: 0.096722; Backpropagation: 0.2958 sec; Batch: 2.1231 sec
0.1540 0.1475 0.1257 0.1120 0.1012 0.0939 0.0882 0.0858 0.0834 0.0815 0.0807 0.0800 0.0791 0.0786 0.0781 0.0778 

[TRAIN] Epoch[1](7336/114412); Loss: 0.121686; Backpropagation: 0.2951 sec; Batch: 2.0819 sec
0.2263 0.2132 0.1829 0.1669 0.1436 0.1268 0.1131 0.1027 0.0955 0.0900 0.0866 0.0840 0.0814 0.0794 0.0778 0.0765 

[TRAIN] Epoch[1](7337/114412); Loss: 0.065957; Backpropagation: 0.2980 sec; Batch: 2.1230 sec
0.1111 0.1055 0.0969 0.0876 0.0759 0.0675 0.0603 0.0583 0.0545 0.0519 0.0508 0.0490 0.0477 0.0468 0.0459 0.0455 

[TRAIN] Epoch[1](7338/114412); Loss: 0.104195; Backpropagation: 0.2981 sec; Batch: 2.1258 sec
0.1989 0.1832 0.1477 0.1350 0.1170 0.1050 0.0945 0.0884 0.0842 0.0804 0.0770 0.0746 0.0724 0.0706 0.0696 0.0684 

[TRAIN] Epoch[1](7339/114412); Loss: 0.105430; Backpropagation: 0.2958 sec; Batch: 2.1408 sec
0.2038 0.1915 0.1548 0.1413 0.1183 0.1020 0.0907 0.0847 0.0815 0.0784 0.0768 0.0747 0.0733 0.0726 0.0715 0.0709 

[TRAIN] Epoch[1](7340/114412); Loss: 0.126645; Backpropagation: 0.2953 sec; Batch: 2.1161 sec
0.1969 0.1898 0.1663 0.1456 0.1337 0.1259 0.1185 0.1163 0.1118 0.1093 0.1067 0.1050 0.1030 0.1004 0.0994 0.0977 

[TRAIN] Epoch[1](7341/114412); Loss: 0.135253; Backpropagation: 0.2981 sec; Batch: 2.0925 sec
0.2838 0.2623 0.2115 0.1948 0.1615 0.1376 0.1209 0.1084 0.0994 0.0921 0.0880 0.0843 0.0816 0.0805 0.0792 0.0780 

[TRAIN] Epoch[1](7342/114412); Loss: 0.076827; Backpropagation: 0.2958 sec; Batch: 2.1559 sec
0.1380 0.1302 0.1043 0.0990 0.0855 0.0778 0.0708 0.0653 0.0627 0.0604 0.0586 0.0571 0.0559 0.0552 0.0545 0.0539 

[TRAIN] Epoch[1](7343/114412); Loss: 0.091313; Backpropagation: 0.2956 sec; Batch: 2.1159 sec
0.1678 0.1572 0.1261 0.1171 0.0987 0.0881 0.0808 0.0766 0.0732 0.0705 0.0690 0.0682 0.0676 0.0672 0.0667 0.0662 

[TRAIN] Epoch[1](7344/114412); Loss: 0.090478; Backpropagation: 0.2952 sec; Batch: 2.1579 sec
0.1734 0.1575 0.1334 0.1218 0.0997 0.0887 0.0792 0.0728 0.0716 0.0679 0.0660 0.0654 0.0641 0.0629 0.0620 0.0612 

[TRAIN] Epoch[1](7345/114412); Loss: 0.083749; Backpropagation: 0.2955 sec; Batch: 2.1201 sec
0.1351 0.1249 0.1040 0.0944 0.0860 0.0819 0.0775 0.0750 0.0735 0.0721 0.0715 0.0703 0.0694 0.0687 0.0680 0.0676 

[TRAIN] Epoch[1](7346/114412); Loss: 0.089576; Backpropagation: 0.2952 sec; Batch: 2.1466 sec
0.1315 0.1220 0.1121 0.1030 0.0937 0.0879 0.0841 0.0832 0.0804 0.0786 0.0777 0.0770 0.0762 0.0756 0.0752 0.0751 

[TRAIN] Epoch[1](7347/114412); Loss: 0.075535; Backpropagation: 0.2967 sec; Batch: 2.1634 sec
0.1283 0.1213 0.0992 0.0898 0.0791 0.0726 0.0678 0.0660 0.0640 0.0622 0.0608 0.0600 0.0595 0.0593 0.0593 0.0594 

[TRAIN] Epoch[1](7348/114412); Loss: 0.099358; Backpropagation: 0.2960 sec; Batch: 2.2187 sec
0.1948 0.1693 0.1387 0.1224 0.1053 0.0943 0.0880 0.0834 0.0807 0.0772 0.0756 0.0738 0.0726 0.0718 0.0712 0.0705 

[TRAIN] Epoch[1](7349/114412); Loss: 0.092333; Backpropagation: 0.2956 sec; Batch: 2.1548 sec
0.1671 0.1585 0.1300 0.1183 0.1021 0.0910 0.0846 0.0792 0.0754 0.0728 0.0704 0.0684 0.0667 0.0653 0.0642 0.0632 

[TRAIN] Epoch[1](7350/114412); Loss: 0.079403; Backpropagation: 0.2955 sec; Batch: 2.2527 sec
0.1542 0.1442 0.1058 0.0958 0.0836 0.0766 0.0713 0.0674 0.0649 0.0621 0.0600 0.0587 0.0577 0.0566 0.0559 0.0556 

[TRAIN] Epoch[1](7351/114412); Loss: 0.123658; Backpropagation: 0.2979 sec; Batch: 2.1160 sec
0.2121 0.1975 0.1662 0.1552 0.1384 0.1255 0.1138 0.1061 0.1013 0.0980 0.0959 0.0951 0.0943 0.0938 0.0932 0.0922 

[TRAIN] Epoch[1](7352/114412); Loss: 0.096449; Backpropagation: 0.2956 sec; Batch: 2.1180 sec
0.1980 0.1875 0.1474 0.1358 0.1138 0.0985 0.0854 0.0796 0.0749 0.0689 0.0646 0.0607 0.0584 0.0576 0.0564 0.0558 

[TRAIN] Epoch[1](7353/114412); Loss: 0.075736; Backpropagation: 0.2955 sec; Batch: 2.1160 sec
0.1431 0.1308 0.1020 0.0933 0.0815 0.0734 0.0677 0.0638 0.0617 0.0593 0.0575 0.0566 0.0559 0.0555 0.0551 0.0546 

[TRAIN] Epoch[1](7354/114412); Loss: 0.103178; Backpropagation: 0.3006 sec; Batch: 2.2117 sec
0.1712 0.1587 0.1355 0.1229 0.1114 0.1022 0.0949 0.0928 0.0892 0.0863 0.0845 0.0824 0.0811 0.0802 0.0792 0.0785 

[TRAIN] Epoch[1](7355/114412); Loss: 0.115979; Backpropagation: 0.2982 sec; Batch: 2.1230 sec
0.2107 0.1983 0.1617 0.1551 0.1344 0.1219 0.1119 0.1036 0.0966 0.0918 0.0868 0.0817 0.0787 0.0765 0.0738 0.0722 

[TRAIN] Epoch[1](7356/114412); Loss: 0.083558; Backpropagation: 0.2948 sec; Batch: 2.1500 sec
0.1511 0.1430 0.1154 0.1072 0.0917 0.0830 0.0752 0.0705 0.0677 0.0649 0.0633 0.0622 0.0613 0.0607 0.0601 0.0598 

[TRAIN] Epoch[1](7357/114412); Loss: 0.078161; Backpropagation: 0.2956 sec; Batch: 2.1270 sec
0.1253 0.1186 0.1033 0.0963 0.0815 0.0774 0.0727 0.0697 0.0675 0.0656 0.0644 0.0632 0.0623 0.0614 0.0610 0.0606 

[TRAIN] Epoch[1](7358/114412); Loss: 0.082506; Backpropagation: 0.2961 sec; Batch: 2.1252 sec
0.1451 0.1364 0.1074 0.1007 0.0894 0.0813 0.0763 0.0719 0.0692 0.0669 0.0650 0.0639 0.0630 0.0620 0.0612 0.0606 

[TRAIN] Epoch[1](7359/114412); Loss: 0.068736; Backpropagation: 0.2951 sec; Batch: 2.1254 sec
0.1291 0.1245 0.0963 0.0826 0.0710 0.0649 0.0609 0.0579 0.0555 0.0538 0.0525 0.0516 0.0507 0.0499 0.0495 0.0490 

[TRAIN] Epoch[1](7360/114412); Loss: 0.085708; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.1762 0.1637 0.1195 0.1161 0.0922 0.0800 0.0713 0.0695 0.0656 0.0632 0.0618 0.0605 0.0593 0.0583 0.0576 0.0566 

[TRAIN] Epoch[1](7361/114412); Loss: 0.092009; Backpropagation: 0.2984 sec; Batch: 2.1246 sec
0.1364 0.1292 0.1143 0.1065 0.0985 0.0922 0.0875 0.0843 0.0822 0.0805 0.0789 0.0777 0.0769 0.0763 0.0756 0.0751 

[TRAIN] Epoch[1](7362/114412); Loss: 0.098008; Backpropagation: 0.2970 sec; Batch: 2.1240 sec
0.1733 0.1515 0.1229 0.1092 0.0962 0.0901 0.0871 0.0856 0.0842 0.0832 0.0821 0.0816 0.0811 0.0805 0.0800 0.0796 

[TRAIN] Epoch[1](7363/114412); Loss: 0.083351; Backpropagation: 0.2955 sec; Batch: 2.1272 sec
0.1427 0.1326 0.1113 0.1036 0.0908 0.0822 0.0769 0.0744 0.0700 0.0676 0.0657 0.0646 0.0637 0.0631 0.0625 0.0620 

[TRAIN] Epoch[1](7364/114412); Loss: 0.094733; Backpropagation: 0.2954 sec; Batch: 2.1304 sec
0.1504 0.1469 0.1180 0.1075 0.1010 0.0927 0.0883 0.0855 0.0829 0.0812 0.0794 0.0782 0.0769 0.0762 0.0756 0.0750 

[TRAIN] Epoch[1](7365/114412); Loss: 0.111536; Backpropagation: 0.2956 sec; Batch: 2.1259 sec
0.1798 0.1719 0.1442 0.1383 0.1223 0.1122 0.1046 0.1000 0.0960 0.0926 0.0899 0.0884 0.0871 0.0864 0.0857 0.0851 

[TRAIN] Epoch[1](7366/114412); Loss: 0.126877; Backpropagation: 0.2957 sec; Batch: 2.1207 sec
0.2218 0.2117 0.1783 0.1683 0.1467 0.1324 0.1213 0.1116 0.1044 0.0995 0.0955 0.0922 0.0895 0.0871 0.0855 0.0842 

[TRAIN] Epoch[1](7367/114412); Loss: 0.099603; Backpropagation: 0.2958 sec; Batch: 2.1221 sec
0.1542 0.1441 0.1268 0.1192 0.1085 0.1007 0.0973 0.0928 0.0877 0.0852 0.0830 0.0814 0.0798 0.0784 0.0776 0.0769 

[TRAIN] Epoch[1](7368/114412); Loss: 0.106511; Backpropagation: 0.2954 sec; Batch: 2.1255 sec
0.2086 0.1898 0.1550 0.1363 0.1143 0.1034 0.0910 0.0863 0.0844 0.0802 0.0780 0.0769 0.0765 0.0752 0.0744 0.0739 

[TRAIN] Epoch[1](7369/114412); Loss: 0.079342; Backpropagation: 0.3006 sec; Batch: 2.1129 sec
0.1432 0.1373 0.1098 0.0967 0.0848 0.0759 0.0710 0.0686 0.0654 0.0626 0.0611 0.0596 0.0590 0.0586 0.0581 0.0577 

[TRAIN] Epoch[1](7370/114412); Loss: 0.073765; Backpropagation: 0.2984 sec; Batch: 2.1245 sec
0.1484 0.1398 0.1046 0.0940 0.0765 0.0686 0.0626 0.0599 0.0577 0.0560 0.0546 0.0532 0.0520 0.0513 0.0507 0.0503 

[TRAIN] Epoch[1](7371/114412); Loss: 0.066699; Backpropagation: 0.2958 sec; Batch: 2.1196 sec
0.1184 0.1012 0.0852 0.0817 0.0762 0.0672 0.0614 0.0582 0.0563 0.0544 0.0530 0.0520 0.0512 0.0507 0.0502 0.0500 

[TRAIN] Epoch[1](7372/114412); Loss: 0.085940; Backpropagation: 0.2960 sec; Batch: 2.1211 sec
0.1529 0.1405 0.1138 0.1038 0.0918 0.0858 0.0798 0.0756 0.0728 0.0689 0.0676 0.0662 0.0647 0.0641 0.0636 0.0632 

[TRAIN] Epoch[1](7373/114412); Loss: 0.125629; Backpropagation: 0.2955 sec; Batch: 2.1227 sec
0.2147 0.2060 0.1791 0.1685 0.1471 0.1309 0.1176 0.1094 0.1026 0.0976 0.0939 0.0915 0.0899 0.0883 0.0867 0.0863 

[TRAIN] Epoch[1](7374/114412); Loss: 0.081999; Backpropagation: 0.2982 sec; Batch: 2.1316 sec
0.1229 0.1201 0.1066 0.0991 0.0890 0.0824 0.0771 0.0743 0.0721 0.0692 0.0683 0.0674 0.0666 0.0660 0.0656 0.0652 

[TRAIN] Epoch[1](7375/114412); Loss: 0.108068; Backpropagation: 0.2955 sec; Batch: 2.1262 sec
0.2166 0.2036 0.1631 0.1491 0.1230 0.1073 0.0956 0.0878 0.0823 0.0782 0.0750 0.0726 0.0705 0.0693 0.0680 0.0672 

[TRAIN] Epoch[1](7376/114412); Loss: 0.085262; Backpropagation: 0.2955 sec; Batch: 2.0820 sec
0.1678 0.1537 0.1263 0.1102 0.0937 0.0830 0.0746 0.0688 0.0651 0.0629 0.0613 0.0606 0.0600 0.0594 0.0586 0.0583 

[TRAIN] Epoch[1](7377/114412); Loss: 0.114892; Backpropagation: 0.2953 sec; Batch: 2.1164 sec
0.1839 0.1805 0.1531 0.1460 0.1310 0.1205 0.1112 0.1038 0.0980 0.0941 0.0910 0.0884 0.0863 0.0852 0.0836 0.0817 

[TRAIN] Epoch[1](7378/114412); Loss: 0.119690; Backpropagation: 0.2954 sec; Batch: 2.1178 sec
0.2256 0.2126 0.1779 0.1666 0.1407 0.1210 0.1067 0.0957 0.0910 0.0871 0.0853 0.0844 0.0818 0.0802 0.0795 0.0789 

[TRAIN] Epoch[1](7379/114412); Loss: 0.091004; Backpropagation: 0.2956 sec; Batch: 2.1213 sec
0.1702 0.1632 0.1270 0.1110 0.0907 0.0834 0.0801 0.0765 0.0738 0.0719 0.0704 0.0690 0.0684 0.0674 0.0668 0.0664 

[TRAIN] Epoch[1](7380/114412); Loss: 0.099263; Backpropagation: 0.2958 sec; Batch: 2.1262 sec
0.1787 0.1718 0.1331 0.1197 0.1041 0.0956 0.0895 0.0848 0.0810 0.0793 0.0777 0.0761 0.0753 0.0743 0.0737 0.0734 

[TRAIN] Epoch[1](7381/114412); Loss: 0.071921; Backpropagation: 0.2955 sec; Batch: 2.1206 sec
0.1387 0.1257 0.1000 0.0885 0.0769 0.0698 0.0649 0.0607 0.0574 0.0557 0.0540 0.0528 0.0521 0.0514 0.0512 0.0508 

[TRAIN] Epoch[1](7382/114412); Loss: 0.093740; Backpropagation: 0.2957 sec; Batch: 2.1212 sec
0.1748 0.1667 0.1371 0.1259 0.1049 0.0934 0.0851 0.0797 0.0752 0.0716 0.0687 0.0667 0.0642 0.0629 0.0622 0.0608 

[TRAIN] Epoch[1](7383/114412); Loss: 0.091659; Backpropagation: 0.2955 sec; Batch: 2.1216 sec
0.1682 0.1576 0.1266 0.1137 0.0981 0.0890 0.0819 0.0770 0.0741 0.0721 0.0706 0.0694 0.0681 0.0673 0.0667 0.0662 

[TRAIN] Epoch[1](7384/114412); Loss: 0.115754; Backpropagation: 0.3011 sec; Batch: 2.1313 sec
0.2111 0.1991 0.1727 0.1630 0.1392 0.1219 0.1071 0.0980 0.0916 0.0861 0.0826 0.0794 0.0772 0.0755 0.0741 0.0735 

[TRAIN] Epoch[1](7385/114412); Loss: 0.082907; Backpropagation: 0.2984 sec; Batch: 2.0855 sec
0.1681 0.1599 0.1193 0.1075 0.0869 0.0773 0.0717 0.0672 0.0637 0.0612 0.0592 0.0584 0.0577 0.0565 0.0561 0.0558 

[TRAIN] Epoch[1](7386/114412); Loss: 0.097846; Backpropagation: 0.2959 sec; Batch: 2.1194 sec
0.1494 0.1420 0.1242 0.1155 0.1056 0.0987 0.0943 0.0895 0.0856 0.0838 0.0822 0.0809 0.0798 0.0787 0.0780 0.0773 

[TRAIN] Epoch[1](7387/114412); Loss: 0.134035; Backpropagation: 0.2956 sec; Batch: 2.1220 sec
0.2734 0.2626 0.2158 0.2036 0.1683 0.1454 0.1254 0.1077 0.0952 0.0875 0.0821 0.0785 0.0768 0.0754 0.0741 0.0728 

[TRAIN] Epoch[1](7388/114412); Loss: 0.070401; Backpropagation: 0.2983 sec; Batch: 2.1238 sec
0.1357 0.1240 0.1026 0.0957 0.0797 0.0695 0.0635 0.0602 0.0554 0.0527 0.0506 0.0490 0.0482 0.0471 0.0464 0.0461 

[TRAIN] Epoch[1](7389/114412); Loss: 0.115785; Backpropagation: 0.2963 sec; Batch: 2.1225 sec
0.2068 0.1939 0.1678 0.1544 0.1348 0.1208 0.1097 0.1023 0.0962 0.0900 0.0858 0.0820 0.0798 0.0774 0.0757 0.0751 

[TRAIN] Epoch[1](7390/114412); Loss: 0.135894; Backpropagation: 0.2978 sec; Batch: 2.1361 sec
0.2216 0.2092 0.1804 0.1706 0.1539 0.1449 0.1334 0.1237 0.1171 0.1111 0.1071 0.1041 0.1018 0.0999 0.0985 0.0971 

[TRAIN] Epoch[1](7391/114412); Loss: 0.086497; Backpropagation: 0.3007 sec; Batch: 2.1288 sec
0.1752 0.1586 0.1220 0.1043 0.0895 0.0807 0.0751 0.0718 0.0685 0.0668 0.0648 0.0632 0.0618 0.0611 0.0605 0.0599 

[TRAIN] Epoch[1](7392/114412); Loss: 0.109817; Backpropagation: 0.2981 sec; Batch: 2.1229 sec
0.1653 0.1619 0.1499 0.1401 0.1242 0.1139 0.1051 0.0983 0.0941 0.0910 0.0888 0.0868 0.0856 0.0848 0.0841 0.0832 

[TRAIN] Epoch[1](7393/114412); Loss: 0.074865; Backpropagation: 0.2955 sec; Batch: 2.1026 sec
0.1446 0.1380 0.1075 0.0874 0.0748 0.0703 0.0659 0.0630 0.0607 0.0585 0.0565 0.0552 0.0545 0.0541 0.0540 0.0531 

[TRAIN] Epoch[1](7394/114412); Loss: 0.105837; Backpropagation: 0.2956 sec; Batch: 2.1223 sec
0.1987 0.1852 0.1455 0.1361 0.1180 0.1062 0.0953 0.0895 0.0856 0.0828 0.0797 0.0770 0.0755 0.0741 0.0726 0.0717 

[TRAIN] Epoch[1](7395/114412); Loss: 0.096737; Backpropagation: 0.2985 sec; Batch: 2.1277 sec
0.1431 0.1367 0.1221 0.1125 0.1020 0.0977 0.0924 0.0896 0.0868 0.0848 0.0834 0.0818 0.0802 0.0791 0.0782 0.0775 

[TRAIN] Epoch[1](7396/114412); Loss: 0.093537; Backpropagation: 0.2960 sec; Batch: 2.1212 sec
0.1570 0.1503 0.1160 0.1053 0.0952 0.0890 0.0851 0.0832 0.0811 0.0791 0.0779 0.0769 0.0763 0.0754 0.0747 0.0742 

[TRAIN] Epoch[1](7397/114412); Loss: 0.081612; Backpropagation: 0.2956 sec; Batch: 2.1269 sec
0.1783 0.1739 0.1243 0.1110 0.0834 0.0716 0.0665 0.0631 0.0595 0.0568 0.0556 0.0537 0.0529 0.0522 0.0517 0.0514 

[TRAIN] Epoch[1](7398/114412); Loss: 0.120855; Backpropagation: 0.2958 sec; Batch: 2.0847 sec
0.1976 0.1892 0.1598 0.1464 0.1301 0.1223 0.1150 0.1080 0.1030 0.0999 0.0975 0.0951 0.0941 0.0930 0.0916 0.0910 

[TRAIN] Epoch[1](7399/114412); Loss: 0.112490; Backpropagation: 0.2948 sec; Batch: 2.0837 sec
0.1698 0.1607 0.1338 0.1270 0.1193 0.1122 0.1074 0.1036 0.1012 0.0994 0.0967 0.0953 0.0944 0.0936 0.0930 0.0925 

[TRAIN] Epoch[1](7400/114412); Loss: 0.141253; Backpropagation: 0.2956 sec; Batch: 2.1354 sec
0.2449 0.2132 0.1872 0.1709 0.1533 0.1397 0.1307 0.1244 0.1190 0.1160 0.1147 0.1122 0.1103 0.1091 0.1077 0.1068 

[TRAIN] Epoch[1](7401/114412); Loss: 0.078734; Backpropagation: 0.2955 sec; Batch: 2.1249 sec
0.1353 0.1322 0.1055 0.0979 0.0845 0.0769 0.0714 0.0682 0.0651 0.0635 0.0620 0.0610 0.0597 0.0591 0.0588 0.0585 

[TRAIN] Epoch[1](7402/114412); Loss: 0.090918; Backpropagation: 0.2953 sec; Batch: 2.1238 sec
0.1751 0.1662 0.1315 0.1130 0.0962 0.0865 0.0795 0.0756 0.0722 0.0693 0.0674 0.0660 0.0650 0.0642 0.0637 0.0632 

[TRAIN] Epoch[1](7403/114412); Loss: 0.076604; Backpropagation: 0.2959 sec; Batch: 2.1304 sec
0.1362 0.1251 0.1012 0.0905 0.0806 0.0747 0.0705 0.0683 0.0655 0.0633 0.0615 0.0600 0.0583 0.0575 0.0568 0.0557 

[TRAIN] Epoch[1](7404/114412); Loss: 0.086187; Backpropagation: 0.2957 sec; Batch: 2.1257 sec
0.1414 0.1299 0.1068 0.0982 0.0902 0.0844 0.0802 0.0771 0.0749 0.0736 0.0722 0.0711 0.0706 0.0698 0.0694 0.0692 

[TRAIN] Epoch[1](7405/114412); Loss: 0.088853; Backpropagation: 0.2954 sec; Batch: 2.0826 sec
0.1598 0.1464 0.1197 0.1073 0.0942 0.0856 0.0794 0.0761 0.0740 0.0719 0.0703 0.0690 0.0679 0.0672 0.0667 0.0662 

[TRAIN] Epoch[1](7406/114412); Loss: 0.146119; Backpropagation: 0.2956 sec; Batch: 2.1222 sec
0.2193 0.2138 0.1894 0.1806 0.1621 0.1534 0.1462 0.1389 0.1321 0.1256 0.1211 0.1175 0.1141 0.1106 0.1075 0.1056 

[TRAIN] Epoch[1](7407/114412); Loss: 0.131322; Backpropagation: 0.2958 sec; Batch: 2.1207 sec
0.2596 0.2503 0.2182 0.2087 0.1768 0.1517 0.1294 0.1096 0.0958 0.0855 0.0798 0.0739 0.0704 0.0678 0.0628 0.0607 

[TRAIN] Epoch[1](7408/114412); Loss: 0.103525; Backpropagation: 0.2956 sec; Batch: 2.1214 sec
0.1866 0.1811 0.1365 0.1273 0.1136 0.1033 0.0979 0.0917 0.0867 0.0825 0.0786 0.0765 0.0754 0.0736 0.0727 0.0724 

[TRAIN] Epoch[1](7409/114412); Loss: 0.105756; Backpropagation: 0.2960 sec; Batch: 2.1277 sec
0.1800 0.1725 0.1460 0.1310 0.1146 0.1042 0.0972 0.0913 0.0876 0.0850 0.0832 0.0819 0.0808 0.0797 0.0788 0.0784 

[TRAIN] Epoch[1](7410/114412); Loss: 0.095504; Backpropagation: 0.2956 sec; Batch: 2.0826 sec
0.1709 0.1657 0.1377 0.1248 0.1085 0.0977 0.0900 0.0833 0.0772 0.0732 0.0707 0.0686 0.0666 0.0651 0.0646 0.0636 

[TRAIN] Epoch[1](7411/114412); Loss: 0.088775; Backpropagation: 0.2965 sec; Batch: 2.0902 sec
0.1500 0.1457 0.1158 0.1064 0.0946 0.0874 0.0821 0.0779 0.0748 0.0727 0.0712 0.0699 0.0690 0.0682 0.0676 0.0671 

[TRAIN] Epoch[1](7412/114412); Loss: 0.083734; Backpropagation: 0.2959 sec; Batch: 2.1208 sec
0.1461 0.1453 0.1146 0.1036 0.0901 0.0803 0.0719 0.0694 0.0677 0.0664 0.0655 0.0646 0.0641 0.0635 0.0633 0.0632 

[TRAIN] Epoch[1](7413/114412); Loss: 0.096623; Backpropagation: 0.2950 sec; Batch: 2.0852 sec
0.1646 0.1532 0.1306 0.1186 0.1052 0.0963 0.0879 0.0834 0.0805 0.0786 0.0765 0.0755 0.0745 0.0739 0.0736 0.0730 

[TRAIN] Epoch[1](7414/114412); Loss: 0.115955; Backpropagation: 0.2950 sec; Batch: 2.1358 sec
0.2142 0.2043 0.1753 0.1635 0.1418 0.1262 0.1138 0.1031 0.0934 0.0862 0.0807 0.0764 0.0727 0.0696 0.0678 0.0662 

[TRAIN] Epoch[1](7415/114412); Loss: 0.091329; Backpropagation: 0.3005 sec; Batch: 2.1428 sec
0.1488 0.1351 0.1184 0.1089 0.0976 0.0889 0.0842 0.0814 0.0790 0.0771 0.0758 0.0745 0.0735 0.0731 0.0727 0.0723 

[TRAIN] Epoch[1](7416/114412); Loss: 0.069206; Backpropagation: 0.2989 sec; Batch: 2.1182 sec
0.1381 0.1326 0.0946 0.0810 0.0692 0.0625 0.0587 0.0562 0.0543 0.0531 0.0524 0.0518 0.0510 0.0507 0.0505 0.0504 

[TRAIN] Epoch[1](7417/114412); Loss: 0.128187; Backpropagation: 0.3008 sec; Batch: 2.1530 sec
0.2106 0.2028 0.1725 0.1627 0.1421 0.1304 0.1201 0.1137 0.1094 0.1061 0.1027 0.0999 0.0975 0.0950 0.0933 0.0922 

[TRAIN] Epoch[1](7418/114412); Loss: 0.068515; Backpropagation: 0.2982 sec; Batch: 2.1199 sec
0.1300 0.1242 0.0933 0.0797 0.0679 0.0628 0.0602 0.0572 0.0561 0.0544 0.0530 0.0522 0.0517 0.0513 0.0512 0.0510 

[TRAIN] Epoch[1](7419/114412); Loss: 0.088792; Backpropagation: 0.2958 sec; Batch: 2.1195 sec
0.1648 0.1502 0.1161 0.1082 0.0964 0.0859 0.0793 0.0755 0.0730 0.0710 0.0692 0.0678 0.0669 0.0660 0.0655 0.0649 

[TRAIN] Epoch[1](7420/114412); Loss: 0.106620; Backpropagation: 0.2952 sec; Batch: 2.1216 sec
0.1786 0.1723 0.1434 0.1366 0.1201 0.1083 0.1001 0.0938 0.0891 0.0863 0.0838 0.0814 0.0797 0.0783 0.0774 0.0767 

[TRAIN] Epoch[1](7421/114412); Loss: 0.097783; Backpropagation: 0.2953 sec; Batch: 2.1255 sec
0.1836 0.1740 0.1337 0.1232 0.1044 0.0920 0.0845 0.0809 0.0782 0.0766 0.0744 0.0735 0.0724 0.0717 0.0710 0.0703 

[TRAIN] Epoch[1](7422/114412); Loss: 0.133276; Backpropagation: 0.2959 sec; Batch: 2.0843 sec
0.2013 0.1958 0.1753 0.1699 0.1524 0.1420 0.1315 0.1236 0.1165 0.1117 0.1082 0.1049 0.1024 0.1002 0.0988 0.0979 

[TRAIN] Epoch[1](7423/114412); Loss: 0.057006; Backpropagation: 0.3030 sec; Batch: 2.0974 sec
0.1254 0.1103 0.0785 0.0678 0.0595 0.0524 0.0486 0.0457 0.0436 0.0417 0.0410 0.0403 0.0397 0.0392 0.0391 0.0390 

[TRAIN] Epoch[1](7424/114412); Loss: 0.101534; Backpropagation: 0.2979 sec; Batch: 2.1356 sec
0.1779 0.1665 0.1374 0.1271 0.1131 0.1035 0.0951 0.0890 0.0841 0.0808 0.0784 0.0767 0.0754 0.0739 0.0731 0.0725 

[TRAIN] Epoch[1](7425/114412); Loss: 0.084680; Backpropagation: 0.2984 sec; Batch: 2.1162 sec
0.1547 0.1442 0.1159 0.1080 0.0931 0.0814 0.0753 0.0716 0.0684 0.0660 0.0646 0.0636 0.0628 0.0622 0.0616 0.0614 

[TRAIN] Epoch[1](7426/114412); Loss: 0.092139; Backpropagation: 0.2983 sec; Batch: 2.0892 sec
0.1557 0.1490 0.1150 0.1087 0.0966 0.0912 0.0848 0.0814 0.0788 0.0765 0.0749 0.0741 0.0728 0.0720 0.0717 0.0712 

[TRAIN] Epoch[1](7427/114412); Loss: 0.097530; Backpropagation: 0.2954 sec; Batch: 2.0826 sec
0.1618 0.1529 0.1263 0.1177 0.1044 0.0967 0.0900 0.0863 0.0833 0.0812 0.0792 0.0778 0.0770 0.0761 0.0752 0.0745 

[TRAIN] Epoch[1](7428/114412); Loss: 0.082169; Backpropagation: 0.2957 sec; Batch: 2.1242 sec
0.1347 0.1295 0.1164 0.1045 0.0930 0.0813 0.0778 0.0723 0.0689 0.0668 0.0652 0.0635 0.0619 0.0606 0.0594 0.0588 

[TRAIN] Epoch[1](7429/114412); Loss: 0.086492; Backpropagation: 0.2961 sec; Batch: 2.0880 sec
0.1401 0.1355 0.1180 0.1090 0.0956 0.0865 0.0797 0.0760 0.0733 0.0707 0.0686 0.0677 0.0668 0.0659 0.0653 0.0649 

[TRAIN] Epoch[1](7430/114412); Loss: 0.103985; Backpropagation: 0.2957 sec; Batch: 2.1454 sec
0.1877 0.1781 0.1404 0.1301 0.1137 0.1018 0.0944 0.0897 0.0858 0.0822 0.0799 0.0780 0.0768 0.0758 0.0749 0.0746 

[TRAIN] Epoch[1](7431/114412); Loss: 0.090587; Backpropagation: 0.2954 sec; Batch: 2.1270 sec
0.1546 0.1483 0.1250 0.1115 0.0955 0.0871 0.0820 0.0786 0.0754 0.0735 0.0721 0.0710 0.0700 0.0690 0.0683 0.0677 

[TRAIN] Epoch[1](7432/114412); Loss: 0.138039; Backpropagation: 0.2949 sec; Batch: 2.0884 sec
0.2507 0.2381 0.2060 0.1960 0.1700 0.1503 0.1351 0.1210 0.1098 0.1019 0.0958 0.0911 0.0881 0.0858 0.0852 0.0835 

[TRAIN] Epoch[1](7433/114412); Loss: 0.086022; Backpropagation: 0.2954 sec; Batch: 2.1185 sec
0.1577 0.1501 0.1166 0.1057 0.0901 0.0824 0.0754 0.0721 0.0702 0.0685 0.0664 0.0656 0.0647 0.0641 0.0636 0.0633 

[TRAIN] Epoch[1](7434/114412); Loss: 0.082122; Backpropagation: 0.2953 sec; Batch: 2.1211 sec
0.1415 0.1361 0.1107 0.1005 0.0869 0.0785 0.0736 0.0711 0.0689 0.0671 0.0656 0.0641 0.0636 0.0626 0.0618 0.0614 

[TRAIN] Epoch[1](7435/114412); Loss: 0.106488; Backpropagation: 0.3006 sec; Batch: 2.1306 sec
0.2209 0.2080 0.1689 0.1508 0.1242 0.1078 0.0958 0.0858 0.0783 0.0736 0.0705 0.0675 0.0650 0.0632 0.0621 0.0615 

[TRAIN] Epoch[1](7436/114412); Loss: 0.069552; Backpropagation: 0.2978 sec; Batch: 2.1223 sec
0.1256 0.1166 0.0985 0.0892 0.0770 0.0677 0.0619 0.0595 0.0565 0.0543 0.0527 0.0517 0.0511 0.0506 0.0501 0.0498 

[TRAIN] Epoch[1](7437/114412); Loss: 0.079358; Backpropagation: 0.2948 sec; Batch: 2.1187 sec
0.1372 0.1330 0.0979 0.0886 0.0809 0.0750 0.0718 0.0701 0.0677 0.0663 0.0652 0.0641 0.0636 0.0631 0.0627 0.0625 

[TRAIN] Epoch[1](7438/114412); Loss: 0.102075; Backpropagation: 0.2983 sec; Batch: 2.0870 sec
0.1631 0.1504 0.1296 0.1203 0.1095 0.1022 0.0959 0.0929 0.0900 0.0867 0.0849 0.0833 0.0826 0.0814 0.0806 0.0799 

[TRAIN] Epoch[1](7439/114412); Loss: 0.102573; Backpropagation: 0.2979 sec; Batch: 2.1247 sec
0.1944 0.1751 0.1501 0.1421 0.1213 0.1065 0.0920 0.0829 0.0782 0.0757 0.0735 0.0720 0.0707 0.0697 0.0688 0.0681 

[TRAIN] Epoch[1](7440/114412); Loss: 0.095250; Backpropagation: 0.2964 sec; Batch: 2.0837 sec
0.1585 0.1521 0.1271 0.1149 0.1007 0.0918 0.0860 0.0823 0.0803 0.0789 0.0775 0.0764 0.0754 0.0745 0.0740 0.0736 

[TRAIN] Epoch[1](7441/114412); Loss: 0.102014; Backpropagation: 0.2957 sec; Batch: 2.1246 sec
0.2015 0.1859 0.1537 0.1404 0.1163 0.1021 0.0895 0.0825 0.0787 0.0741 0.0715 0.0698 0.0683 0.0669 0.0659 0.0651 

[TRAIN] Epoch[1](7442/114412); Loss: 0.067674; Backpropagation: 0.2947 sec; Batch: 2.1259 sec
0.1029 0.1006 0.0912 0.0848 0.0737 0.0693 0.0626 0.0602 0.0578 0.0562 0.0553 0.0545 0.0539 0.0535 0.0532 0.0531 

[TRAIN] Epoch[1](7443/114412); Loss: 0.118527; Backpropagation: 0.2997 sec; Batch: 2.1303 sec
0.2112 0.1958 0.1624 0.1479 0.1259 0.1151 0.1044 0.0998 0.0976 0.0956 0.0931 0.0914 0.0904 0.0896 0.0884 0.0880 

[TRAIN] Epoch[1](7444/114412); Loss: 0.097942; Backpropagation: 0.2981 sec; Batch: 2.1237 sec
0.1721 0.1567 0.1268 0.1146 0.1025 0.0956 0.0896 0.0864 0.0829 0.0806 0.0792 0.0777 0.0765 0.0758 0.0752 0.0746 

[TRAIN] Epoch[1](7445/114412); Loss: 0.109109; Backpropagation: 0.2979 sec; Batch: 2.1251 sec
0.1782 0.1668 0.1402 0.1279 0.1162 0.1078 0.1016 0.0985 0.0946 0.0917 0.0900 0.0883 0.0873 0.0864 0.0854 0.0847 

[TRAIN] Epoch[1](7446/114412); Loss: 0.085902; Backpropagation: 0.2978 sec; Batch: 2.1011 sec
0.1442 0.1334 0.1103 0.1013 0.0893 0.0827 0.0783 0.0758 0.0733 0.0718 0.0707 0.0697 0.0693 0.0686 0.0680 0.0677 

[TRAIN] Epoch[1](7447/114412); Loss: 0.084557; Backpropagation: 0.2975 sec; Batch: 2.1180 sec
0.1431 0.1325 0.1035 0.0951 0.0868 0.0821 0.0785 0.0759 0.0733 0.0716 0.0702 0.0692 0.0685 0.0680 0.0676 0.0671 

[TRAIN] Epoch[1](7448/114412); Loss: 0.106974; Backpropagation: 0.2955 sec; Batch: 2.0824 sec
0.2315 0.2019 0.1602 0.1447 0.1187 0.1029 0.0929 0.0860 0.0806 0.0768 0.0734 0.0709 0.0696 0.0681 0.0672 0.0661 

[TRAIN] Epoch[1](7449/114412); Loss: 0.101713; Backpropagation: 0.2949 sec; Batch: 2.1170 sec
0.1610 0.1526 0.1290 0.1192 0.1100 0.1003 0.0946 0.0907 0.0880 0.0864 0.0848 0.0836 0.0828 0.0819 0.0814 0.0808 

[TRAIN] Epoch[1](7450/114412); Loss: 0.076853; Backpropagation: 0.2956 sec; Batch: 2.1202 sec
0.1406 0.1329 0.1090 0.0974 0.0826 0.0752 0.0686 0.0646 0.0617 0.0596 0.0583 0.0571 0.0560 0.0557 0.0553 0.0550 

[TRAIN] Epoch[1](7451/114412); Loss: 0.101889; Backpropagation: 0.2954 sec; Batch: 2.1239 sec
0.1571 0.1488 0.1311 0.1222 0.1107 0.1031 0.0977 0.0925 0.0892 0.0873 0.0856 0.0836 0.0820 0.0805 0.0797 0.0790 

[TRAIN] Epoch[1](7452/114412); Loss: 0.076700; Backpropagation: 0.2952 sec; Batch: 2.1258 sec
0.1626 0.1510 0.1096 0.1013 0.0829 0.0744 0.0669 0.0601 0.0570 0.0552 0.0531 0.0518 0.0511 0.0505 0.0500 0.0496 

[TRAIN] Epoch[1](7453/114412); Loss: 0.098197; Backpropagation: 0.2960 sec; Batch: 2.1251 sec
0.1714 0.1642 0.1358 0.1314 0.1122 0.1009 0.0934 0.0870 0.0823 0.0782 0.0744 0.0718 0.0700 0.0677 0.0659 0.0646 

[TRAIN] Epoch[1](7454/114412); Loss: 0.093488; Backpropagation: 0.2956 sec; Batch: 2.0818 sec
0.1948 0.1701 0.1340 0.1185 0.0968 0.0861 0.0795 0.0748 0.0718 0.0701 0.0686 0.0675 0.0669 0.0660 0.0653 0.0650 

[TRAIN] Epoch[1](7455/114412); Loss: 0.097796; Backpropagation: 0.2954 sec; Batch: 2.1211 sec
0.1964 0.1861 0.1457 0.1344 0.1154 0.1034 0.0910 0.0822 0.0763 0.0707 0.0664 0.0626 0.0602 0.0590 0.0580 0.0570 

[TRAIN] Epoch[1](7456/114412); Loss: 0.077868; Backpropagation: 0.2956 sec; Batch: 2.0826 sec
0.1477 0.1413 0.1105 0.1008 0.0843 0.0766 0.0706 0.0668 0.0626 0.0601 0.0587 0.0561 0.0541 0.0532 0.0518 0.0506 

[TRAIN] Epoch[1](7457/114412); Loss: 0.076576; Backpropagation: 0.2957 sec; Batch: 2.1198 sec
0.1175 0.1147 0.0990 0.0924 0.0805 0.0756 0.0709 0.0684 0.0664 0.0651 0.0639 0.0630 0.0626 0.0620 0.0617 0.0615 

[TRAIN] Epoch[1](7458/114412); Loss: 0.094176; Backpropagation: 0.2957 sec; Batch: 2.1227 sec
0.1620 0.1544 0.1320 0.1224 0.1075 0.0974 0.0882 0.0830 0.0790 0.0749 0.0718 0.0693 0.0677 0.0667 0.0657 0.0648 

[TRAIN] Epoch[1](7459/114412); Loss: 0.088043; Backpropagation: 0.3008 sec; Batch: 2.1667 sec
0.1703 0.1633 0.1330 0.1223 0.1044 0.0912 0.0794 0.0726 0.0664 0.0633 0.0615 0.0585 0.0571 0.0561 0.0551 0.0543 

[TRAIN] Epoch[1](7460/114412); Loss: 0.077313; Backpropagation: 0.3008 sec; Batch: 2.1262 sec
0.1588 0.1400 0.1033 0.0930 0.0819 0.0753 0.0703 0.0675 0.0627 0.0596 0.0577 0.0560 0.0542 0.0531 0.0521 0.0514 

[TRAIN] Epoch[1](7461/114412); Loss: 0.090604; Backpropagation: 0.3006 sec; Batch: 2.1250 sec
0.1492 0.1433 0.1237 0.1121 0.1007 0.0913 0.0841 0.0801 0.0770 0.0742 0.0720 0.0704 0.0690 0.0682 0.0674 0.0668 

[TRAIN] Epoch[1](7462/114412); Loss: 0.091342; Backpropagation: 0.3010 sec; Batch: 2.1054 sec
0.1634 0.1595 0.1228 0.1113 0.0973 0.0896 0.0831 0.0782 0.0749 0.0733 0.0711 0.0692 0.0681 0.0673 0.0665 0.0660 

[TRAIN] Epoch[1](7463/114412); Loss: 0.110281; Backpropagation: 0.2980 sec; Batch: 2.1229 sec
0.1821 0.1755 0.1544 0.1364 0.1208 0.1107 0.1046 0.1001 0.0955 0.0916 0.0878 0.0848 0.0824 0.0807 0.0792 0.0776 

[TRAIN] Epoch[1](7464/114412); Loss: 0.087484; Backpropagation: 0.2981 sec; Batch: 2.1211 sec
0.1373 0.1276 0.1063 0.0956 0.0863 0.0845 0.0810 0.0798 0.0775 0.0766 0.0759 0.0750 0.0745 0.0742 0.0738 0.0736 

[TRAIN] Epoch[1](7465/114412); Loss: 0.132067; Backpropagation: 0.2958 sec; Batch: 2.1038 sec
0.2119 0.2059 0.1819 0.1710 0.1523 0.1380 0.1275 0.1194 0.1125 0.1071 0.1030 0.1004 0.0984 0.0965 0.0942 0.0929 

[TRAIN] Epoch[1](7466/114412); Loss: 0.065505; Backpropagation: 0.2955 sec; Batch: 2.1252 sec
0.1170 0.1128 0.0909 0.0827 0.0701 0.0642 0.0595 0.0563 0.0536 0.0521 0.0503 0.0491 0.0483 0.0475 0.0470 0.0465 

[TRAIN] Epoch[1](7467/114412); Loss: 0.070451; Backpropagation: 0.2978 sec; Batch: 2.1274 sec
0.1349 0.1217 0.0938 0.0845 0.0715 0.0657 0.0617 0.0594 0.0578 0.0562 0.0551 0.0540 0.0533 0.0528 0.0525 0.0522 

[TRAIN] Epoch[1](7468/114412); Loss: 0.081470; Backpropagation: 0.2981 sec; Batch: 2.1261 sec
0.1363 0.1252 0.1074 0.0984 0.0862 0.0804 0.0754 0.0727 0.0700 0.0681 0.0666 0.0653 0.0640 0.0631 0.0623 0.0619 

[TRAIN] Epoch[1](7469/114412); Loss: 0.099208; Backpropagation: 0.3004 sec; Batch: 2.1596 sec
0.1649 0.1570 0.1292 0.1190 0.1077 0.0988 0.0924 0.0893 0.0853 0.0822 0.0799 0.0782 0.0768 0.0759 0.0755 0.0752 

[TRAIN] Epoch[1](7470/114412); Loss: 0.134334; Backpropagation: 0.2989 sec; Batch: 2.1171 sec
0.1893 0.1831 0.1651 0.1563 0.1450 0.1362 0.1302 0.1278 0.1230 0.1192 0.1170 0.1144 0.1123 0.1110 0.1102 0.1091 

[TRAIN] Epoch[1](7471/114412); Loss: 0.108957; Backpropagation: 0.2956 sec; Batch: 2.1247 sec
0.1865 0.1741 0.1476 0.1334 0.1181 0.1070 0.1009 0.0971 0.0922 0.0887 0.0868 0.0847 0.0828 0.0817 0.0813 0.0805 

[TRAIN] Epoch[1](7472/114412); Loss: 0.110524; Backpropagation: 0.2980 sec; Batch: 2.1246 sec
0.1829 0.1710 0.1406 0.1283 0.1139 0.1074 0.1016 0.0970 0.0945 0.0940 0.0919 0.0907 0.0895 0.0888 0.0885 0.0877 

[TRAIN] Epoch[1](7473/114412); Loss: 0.094602; Backpropagation: 0.2979 sec; Batch: 2.1154 sec
0.1649 0.1588 0.1361 0.1278 0.1104 0.0966 0.0866 0.0813 0.0770 0.0729 0.0700 0.0683 0.0670 0.0660 0.0653 0.0648 

[TRAIN] Epoch[1](7474/114412); Loss: 0.071663; Backpropagation: 0.3005 sec; Batch: 2.1298 sec
0.1387 0.1301 0.0987 0.0867 0.0741 0.0640 0.0597 0.0587 0.0570 0.0560 0.0554 0.0545 0.0537 0.0535 0.0530 0.0529 

[TRAIN] Epoch[1](7475/114412); Loss: 0.097264; Backpropagation: 0.2964 sec; Batch: 2.1221 sec
0.1599 0.1540 0.1259 0.1141 0.1027 0.0959 0.0893 0.0852 0.0824 0.0807 0.0793 0.0784 0.0779 0.0772 0.0769 0.0764 

[TRAIN] Epoch[1](7476/114412); Loss: 0.082810; Backpropagation: 0.2957 sec; Batch: 2.1241 sec
0.1467 0.1339 0.1040 0.0943 0.0856 0.0799 0.0758 0.0731 0.0706 0.0691 0.0677 0.0668 0.0656 0.0645 0.0639 0.0634 

[TRAIN] Epoch[1](7477/114412); Loss: 0.162758; Backpropagation: 0.2956 sec; Batch: 2.0835 sec
0.2571 0.2434 0.2106 0.2038 0.1829 0.1670 0.1580 0.1468 0.1408 0.1347 0.1301 0.1278 0.1262 0.1251 0.1249 0.1248 

[TRAIN] Epoch[1](7478/114412); Loss: 0.074421; Backpropagation: 0.2955 sec; Batch: 2.1224 sec
0.1169 0.1065 0.0906 0.0833 0.0781 0.0727 0.0698 0.0679 0.0660 0.0650 0.0639 0.0630 0.0624 0.0618 0.0616 0.0612 

[TRAIN] Epoch[1](7479/114412); Loss: 0.090615; Backpropagation: 0.2978 sec; Batch: 2.1233 sec
0.1504 0.1420 0.1198 0.1109 0.0983 0.0904 0.0852 0.0817 0.0780 0.0753 0.0727 0.0708 0.0696 0.0688 0.0681 0.0677 

[TRAIN] Epoch[1](7480/114412); Loss: 0.078699; Backpropagation: 0.2975 sec; Batch: 2.1228 sec
0.1382 0.1305 0.1031 0.0927 0.0830 0.0764 0.0723 0.0686 0.0660 0.0645 0.0630 0.0618 0.0608 0.0600 0.0594 0.0587 

[TRAIN] Epoch[1](7481/114412); Loss: 0.105382; Backpropagation: 0.2950 sec; Batch: 2.1223 sec
0.1736 0.1690 0.1466 0.1368 0.1183 0.1086 0.0992 0.0928 0.0886 0.0848 0.0822 0.0801 0.0784 0.0768 0.0755 0.0748 

[TRAIN] Epoch[1](7482/114412); Loss: 0.065996; Backpropagation: 0.2950 sec; Batch: 2.1223 sec
0.1511 0.1373 0.0995 0.0869 0.0695 0.0608 0.0545 0.0506 0.0484 0.0459 0.0438 0.0426 0.0417 0.0415 0.0411 0.0407 

[TRAIN] Epoch[1](7483/114412); Loss: 0.085982; Backpropagation: 0.2958 sec; Batch: 2.1262 sec
0.1541 0.1511 0.1212 0.1126 0.0977 0.0893 0.0806 0.0742 0.0697 0.0669 0.0641 0.0616 0.0599 0.0585 0.0576 0.0567 

[TRAIN] Epoch[1](7484/114412); Loss: 0.092891; Backpropagation: 0.2958 sec; Batch: 2.1205 sec
0.1742 0.1634 0.1265 0.1101 0.0953 0.0863 0.0811 0.0787 0.0760 0.0739 0.0723 0.0710 0.0702 0.0695 0.0691 0.0687 

[TRAIN] Epoch[1](7485/114412); Loss: 0.095519; Backpropagation: 0.2956 sec; Batch: 2.1179 sec
0.1956 0.1801 0.1561 0.1434 0.1206 0.1005 0.0844 0.0750 0.0696 0.0646 0.0604 0.0587 0.0564 0.0548 0.0545 0.0537 

[TRAIN] Epoch[1](7486/114412); Loss: 0.079848; Backpropagation: 0.3004 sec; Batch: 2.1254 sec
0.1286 0.1222 0.1023 0.0943 0.0850 0.0805 0.0750 0.0717 0.0694 0.0669 0.0656 0.0645 0.0637 0.0631 0.0625 0.0623 

[TRAIN] Epoch[1](7487/114412); Loss: 0.098877; Backpropagation: 0.2954 sec; Batch: 2.1174 sec
0.1907 0.1690 0.1332 0.1178 0.1060 0.0998 0.0928 0.0865 0.0813 0.0770 0.0744 0.0724 0.0715 0.0705 0.0699 0.0692 

[TRAIN] Epoch[1](7488/114412); Loss: 0.091242; Backpropagation: 0.2955 sec; Batch: 2.1590 sec
0.1544 0.1477 0.1223 0.1158 0.1019 0.0917 0.0850 0.0797 0.0759 0.0732 0.0715 0.0697 0.0690 0.0679 0.0673 0.0669 

[TRAIN] Epoch[1](7489/114412); Loss: 0.076415; Backpropagation: 0.2953 sec; Batch: 2.1210 sec
0.1260 0.1174 0.0958 0.0855 0.0821 0.0761 0.0710 0.0691 0.0670 0.0651 0.0637 0.0625 0.0617 0.0606 0.0598 0.0591 

[TRAIN] Epoch[1](7490/114412); Loss: 0.155006; Backpropagation: 0.2955 sec; Batch: 2.1172 sec
0.2718 0.2582 0.2226 0.2115 0.1863 0.1698 0.1565 0.1425 0.1318 0.1209 0.1121 0.1067 0.1020 0.0986 0.0956 0.0930 

[TRAIN] Epoch[1](7491/114412); Loss: 0.109695; Backpropagation: 0.2950 sec; Batch: 2.1215 sec
0.1668 0.1582 0.1408 0.1324 0.1226 0.1140 0.1063 0.1004 0.0956 0.0922 0.0901 0.0888 0.0880 0.0871 0.0863 0.0858 

[TRAIN] Epoch[1](7492/114412); Loss: 0.101153; Backpropagation: 0.2979 sec; Batch: 2.1243 sec
0.1707 0.1611 0.1359 0.1231 0.1107 0.1025 0.0952 0.0906 0.0867 0.0829 0.0799 0.0778 0.0767 0.0758 0.0748 0.0741 

[TRAIN] Epoch[1](7493/114412); Loss: 0.068328; Backpropagation: 0.2977 sec; Batch: 2.1263 sec
0.1151 0.1072 0.0905 0.0821 0.0734 0.0668 0.0623 0.0595 0.0572 0.0561 0.0552 0.0543 0.0539 0.0536 0.0532 0.0529 

[TRAIN] Epoch[1](7494/114412); Loss: 0.089116; Backpropagation: 0.2958 sec; Batch: 2.0818 sec
0.1390 0.1288 0.1134 0.1013 0.0916 0.0867 0.0829 0.0804 0.0786 0.0771 0.0761 0.0753 0.0745 0.0740 0.0733 0.0729 

[TRAIN] Epoch[1](7495/114412); Loss: 0.103338; Backpropagation: 0.2959 sec; Batch: 2.1189 sec
0.1715 0.1642 0.1335 0.1243 0.1123 0.1055 0.0985 0.0937 0.0903 0.0864 0.0834 0.0814 0.0789 0.0776 0.0766 0.0755 

[TRAIN] Epoch[1](7496/114412); Loss: 0.121606; Backpropagation: 0.2980 sec; Batch: 2.1281 sec
0.2152 0.2085 0.1769 0.1658 0.1425 0.1249 0.1118 0.1040 0.0987 0.0943 0.0899 0.0867 0.0842 0.0818 0.0808 0.0797 

[TRAIN] Epoch[1](7497/114412); Loss: 0.105869; Backpropagation: 0.2979 sec; Batch: 2.1216 sec
0.2026 0.1944 0.1575 0.1456 0.1258 0.1126 0.1011 0.0914 0.0850 0.0792 0.0735 0.0702 0.0675 0.0643 0.0624 0.0607 

[TRAIN] Epoch[1](7498/114412); Loss: 0.090026; Backpropagation: 0.2955 sec; Batch: 2.1234 sec
0.1614 0.1503 0.1290 0.1111 0.0967 0.0834 0.0777 0.0756 0.0743 0.0730 0.0702 0.0691 0.0682 0.0671 0.0669 0.0663 

[TRAIN] Epoch[1](7499/114412); Loss: 0.077083; Backpropagation: 0.2980 sec; Batch: 2.1242 sec
0.1573 0.1438 0.1038 0.0871 0.0794 0.0739 0.0675 0.0634 0.0605 0.0594 0.0582 0.0568 0.0561 0.0558 0.0553 0.0550 

[TRAIN] Epoch[1](7500/114412); Loss: 0.075680; Backpropagation: 0.2962 sec; Batch: 2.1229 sec
0.1384 0.1337 0.1006 0.0906 0.0796 0.0732 0.0685 0.0661 0.0633 0.0613 0.0589 0.0574 0.0561 0.0550 0.0543 0.0540 

[TRAIN] Epoch[1](7501/114412); Loss: 0.112906; Backpropagation: 0.2956 sec; Batch: 2.1410 sec
0.1813 0.1741 0.1402 0.1316 0.1181 0.1113 0.1062 0.1007 0.0981 0.0955 0.0934 0.0922 0.0915 0.0911 0.0908 0.0904 

[TRAIN] Epoch[1](7502/114412); Loss: 0.105832; Backpropagation: 0.3007 sec; Batch: 2.1279 sec
0.1533 0.1546 0.1381 0.1254 0.1159 0.1076 0.1022 0.0977 0.0942 0.0912 0.0887 0.0873 0.0857 0.0847 0.0839 0.0827 

[TRAIN] Epoch[1](7503/114412); Loss: 0.088913; Backpropagation: 0.2984 sec; Batch: 2.1545 sec
0.1534 0.1457 0.1127 0.1024 0.0933 0.0872 0.0831 0.0794 0.0765 0.0742 0.0721 0.0708 0.0696 0.0680 0.0673 0.0669 

[TRAIN] Epoch[1](7504/114412); Loss: 0.070982; Backpropagation: 0.2954 sec; Batch: 2.1212 sec
0.1303 0.1213 0.0948 0.0852 0.0744 0.0683 0.0637 0.0609 0.0586 0.0569 0.0558 0.0544 0.0537 0.0531 0.0524 0.0519 

[TRAIN] Epoch[1](7505/114412); Loss: 0.088935; Backpropagation: 0.2956 sec; Batch: 2.1219 sec
0.2009 0.1840 0.1399 0.1177 0.0891 0.0764 0.0705 0.0675 0.0653 0.0625 0.0606 0.0592 0.0583 0.0577 0.0571 0.0565 

[TRAIN] Epoch[1](7506/114412); Loss: 0.136234; Backpropagation: 0.2979 sec; Batch: 2.1238 sec
0.2209 0.2069 0.1788 0.1655 0.1472 0.1354 0.1264 0.1213 0.1170 0.1136 0.1112 0.1095 0.1083 0.1069 0.1057 0.1051 

[TRAIN] Epoch[1](7507/114412); Loss: 0.103671; Backpropagation: 0.2970 sec; Batch: 2.1205 sec
0.1935 0.1864 0.1447 0.1281 0.1144 0.0987 0.0901 0.0867 0.0848 0.0811 0.0781 0.0764 0.0749 0.0742 0.0736 0.0730 

[TRAIN] Epoch[1](7508/114412); Loss: 0.086774; Backpropagation: 0.2982 sec; Batch: 2.1242 sec
0.1841 0.1774 0.1372 0.1241 0.1036 0.0884 0.0763 0.0671 0.0609 0.0581 0.0553 0.0533 0.0520 0.0509 0.0502 0.0496 

[TRAIN] Epoch[1](7509/114412); Loss: 0.069583; Backpropagation: 0.2948 sec; Batch: 2.1208 sec
0.1293 0.1240 0.0993 0.0865 0.0708 0.0653 0.0616 0.0593 0.0566 0.0545 0.0531 0.0517 0.0511 0.0505 0.0500 0.0497 

[TRAIN] Epoch[1](7510/114412); Loss: 0.080397; Backpropagation: 0.2949 sec; Batch: 2.1099 sec
0.1482 0.1455 0.1116 0.0967 0.0854 0.0775 0.0716 0.0680 0.0648 0.0629 0.0616 0.0600 0.0593 0.0586 0.0576 0.0571 

[TRAIN] Epoch[1](7511/114412); Loss: 0.110737; Backpropagation: 0.2957 sec; Batch: 2.1214 sec
0.1969 0.1827 0.1479 0.1375 0.1246 0.1133 0.1058 0.0990 0.0933 0.0887 0.0853 0.0830 0.0808 0.0787 0.0777 0.0766 

[TRAIN] Epoch[1](7512/114412); Loss: 0.099154; Backpropagation: 0.2951 sec; Batch: 2.1223 sec
0.2186 0.2095 0.1623 0.1457 0.1121 0.0920 0.0792 0.0753 0.0711 0.0675 0.0643 0.0618 0.0588 0.0573 0.0561 0.0550 

[TRAIN] Epoch[1](7513/114412); Loss: 0.087482; Backpropagation: 0.2960 sec; Batch: 2.1218 sec
0.1487 0.1456 0.1116 0.0980 0.0895 0.0843 0.0793 0.0770 0.0739 0.0723 0.0713 0.0702 0.0698 0.0697 0.0693 0.0692 

[TRAIN] Epoch[1](7514/114412); Loss: 0.066806; Backpropagation: 0.2981 sec; Batch: 2.1240 sec
0.1210 0.1142 0.0929 0.0828 0.0715 0.0640 0.0590 0.0567 0.0544 0.0525 0.0515 0.0506 0.0500 0.0497 0.0492 0.0489 

[TRAIN] Epoch[1](7515/114412); Loss: 0.104588; Backpropagation: 0.2958 sec; Batch: 2.1025 sec
0.1650 0.1587 0.1299 0.1221 0.1123 0.1053 0.1004 0.0967 0.0927 0.0891 0.0875 0.0849 0.0835 0.0825 0.0816 0.0811 

[TRAIN] Epoch[1](7516/114412); Loss: 0.081230; Backpropagation: 0.2982 sec; Batch: 2.1207 sec
0.1489 0.1401 0.1063 0.0946 0.0879 0.0797 0.0753 0.0704 0.0672 0.0650 0.0631 0.0617 0.0608 0.0601 0.0596 0.0592 

[TRAIN] Epoch[1](7517/114412); Loss: 0.119239; Backpropagation: 0.2958 sec; Batch: 2.0836 sec
0.2135 0.2004 0.1710 0.1550 0.1356 0.1195 0.1078 0.1007 0.0960 0.0921 0.0897 0.0878 0.0861 0.0850 0.0842 0.0833 

[TRAIN] Epoch[1](7518/114412); Loss: 0.119802; Backpropagation: 0.2981 sec; Batch: 2.1234 sec
0.2168 0.2003 0.1680 0.1552 0.1373 0.1239 0.1125 0.1035 0.0978 0.0931 0.0898 0.0868 0.0848 0.0835 0.0822 0.0811 

[TRAIN] Epoch[1](7519/114412); Loss: 0.099253; Backpropagation: 0.3006 sec; Batch: 2.0870 sec
0.1489 0.1409 0.1227 0.1122 0.1042 0.0984 0.0947 0.0917 0.0888 0.0876 0.0856 0.0844 0.0834 0.0821 0.0813 0.0811 

[TRAIN] Epoch[1](7520/114412); Loss: 0.113680; Backpropagation: 0.2960 sec; Batch: 2.1224 sec
0.1913 0.1818 0.1523 0.1419 0.1275 0.1181 0.1096 0.1022 0.0962 0.0917 0.0887 0.0867 0.0845 0.0832 0.0821 0.0810 

[TRAIN] Epoch[1](7521/114412); Loss: 0.112689; Backpropagation: 0.2951 sec; Batch: 2.0829 sec
0.1893 0.1771 0.1481 0.1355 0.1206 0.1114 0.1034 0.0987 0.0955 0.0930 0.0912 0.0900 0.0885 0.0875 0.0869 0.0862 

[TRAIN] Epoch[1](7522/114412); Loss: 0.102374; Backpropagation: 0.2949 sec; Batch: 2.1780 sec
0.1774 0.1699 0.1363 0.1225 0.1076 0.0982 0.0926 0.0896 0.0859 0.0842 0.0817 0.0803 0.0793 0.0782 0.0774 0.0769 

[TRAIN] Epoch[1](7523/114412); Loss: 0.096343; Backpropagation: 0.2954 sec; Batch: 2.1197 sec
0.1492 0.1418 0.1266 0.1165 0.1059 0.0980 0.0913 0.0870 0.0833 0.0805 0.0790 0.0780 0.0768 0.0761 0.0759 0.0756 

[TRAIN] Epoch[1](7524/114412); Loss: 0.070094; Backpropagation: 0.2959 sec; Batch: 2.1194 sec
0.1352 0.1238 0.0905 0.0838 0.0734 0.0679 0.0637 0.0595 0.0572 0.0552 0.0539 0.0531 0.0520 0.0512 0.0507 0.0503 

[TRAIN] Epoch[1](7525/114412); Loss: 0.102428; Backpropagation: 0.2959 sec; Batch: 2.1262 sec
0.1711 0.1605 0.1324 0.1216 0.1078 0.0996 0.0939 0.0913 0.0884 0.0856 0.0836 0.0824 0.0813 0.0805 0.0797 0.0791 

[TRAIN] Epoch[1](7526/114412); Loss: 0.095825; Backpropagation: 0.2955 sec; Batch: 2.1206 sec
0.1635 0.1570 0.1172 0.1099 0.1008 0.0952 0.0896 0.0856 0.0817 0.0795 0.0775 0.0764 0.0756 0.0750 0.0745 0.0741 

[TRAIN] Epoch[1](7527/114412); Loss: 0.088166; Backpropagation: 0.2958 sec; Batch: 2.1230 sec
0.1718 0.1546 0.1186 0.1062 0.0966 0.0867 0.0786 0.0747 0.0716 0.0692 0.0671 0.0648 0.0634 0.0629 0.0622 0.0617 

[TRAIN] Epoch[1](7528/114412); Loss: 0.071082; Backpropagation: 0.2955 sec; Batch: 2.1222 sec
0.1134 0.1097 0.0901 0.0848 0.0814 0.0750 0.0702 0.0656 0.0619 0.0593 0.0573 0.0556 0.0545 0.0536 0.0527 0.0524 

[TRAIN] Epoch[1](7529/114412); Loss: 0.109455; Backpropagation: 0.2956 sec; Batch: 2.1034 sec
0.1892 0.1750 0.1386 0.1256 0.1117 0.1049 0.0993 0.0964 0.0937 0.0912 0.0890 0.0882 0.0875 0.0873 0.0870 0.0868 

[TRAIN] Epoch[1](7530/114412); Loss: 0.097887; Backpropagation: 0.2957 sec; Batch: 2.1222 sec
0.1673 0.1613 0.1328 0.1199 0.1077 0.0997 0.0913 0.0851 0.0829 0.0790 0.0762 0.0754 0.0733 0.0719 0.0716 0.0707 

[TRAIN] Epoch[1](7531/114412); Loss: 0.097823; Backpropagation: 0.2958 sec; Batch: 2.1258 sec
0.1555 0.1514 0.1262 0.1141 0.1033 0.0972 0.0916 0.0879 0.0848 0.0827 0.0813 0.0795 0.0784 0.0779 0.0769 0.0765 

[TRAIN] Epoch[1](7532/114412); Loss: 0.099249; Backpropagation: 0.2952 sec; Batch: 2.1213 sec
0.1821 0.1712 0.1446 0.1303 0.1135 0.1003 0.0891 0.0831 0.0786 0.0750 0.0729 0.0714 0.0702 0.0692 0.0684 0.0681 

[TRAIN] Epoch[1](7533/114412); Loss: 0.096526; Backpropagation: 0.2956 sec; Batch: 2.1225 sec
0.1844 0.1584 0.1308 0.1150 0.1003 0.0925 0.0861 0.0829 0.0793 0.0769 0.0757 0.0742 0.0731 0.0722 0.0715 0.0711 

[TRAIN] Epoch[1](7534/114412); Loss: 0.090461; Backpropagation: 0.2951 sec; Batch: 2.1231 sec
0.1450 0.1382 0.1226 0.1135 0.1008 0.0907 0.0833 0.0785 0.0758 0.0739 0.0728 0.0717 0.0709 0.0703 0.0699 0.0693 

[TRAIN] Epoch[1](7535/114412); Loss: 0.078707; Backpropagation: 0.2955 sec; Batch: 2.1184 sec
0.1457 0.1367 0.1070 0.0983 0.0866 0.0788 0.0710 0.0672 0.0636 0.0606 0.0590 0.0580 0.0571 0.0569 0.0565 0.0564 

[TRAIN] Epoch[1](7536/114412); Loss: 0.072326; Backpropagation: 0.2953 sec; Batch: 2.1219 sec
0.1467 0.1412 0.1032 0.0840 0.0737 0.0662 0.0619 0.0585 0.0560 0.0548 0.0532 0.0525 0.0519 0.0514 0.0511 0.0511 

[TRAIN] Epoch[1](7537/114412); Loss: 0.086555; Backpropagation: 0.2956 sec; Batch: 2.1224 sec
0.1449 0.1343 0.1141 0.1011 0.0891 0.0836 0.0783 0.0759 0.0736 0.0720 0.0712 0.0704 0.0697 0.0691 0.0688 0.0685 

[TRAIN] Epoch[1](7538/114412); Loss: 0.103133; Backpropagation: 0.2956 sec; Batch: 2.1206 sec
0.2162 0.2000 0.1584 0.1479 0.1226 0.1044 0.0903 0.0807 0.0760 0.0717 0.0680 0.0660 0.0640 0.0624 0.0611 0.0606 

[TRAIN] Epoch[1](7539/114412); Loss: 0.096395; Backpropagation: 0.2972 sec; Batch: 2.1242 sec
0.1766 0.1591 0.1319 0.1192 0.1078 0.0976 0.0883 0.0832 0.0795 0.0767 0.0741 0.0721 0.0706 0.0696 0.0684 0.0677 

[TRAIN] Epoch[1](7540/114412); Loss: 0.086764; Backpropagation: 0.2955 sec; Batch: 2.1584 sec
0.1606 0.1477 0.1222 0.1093 0.0924 0.0829 0.0765 0.0720 0.0693 0.0676 0.0666 0.0656 0.0647 0.0640 0.0636 0.0632 

[TRAIN] Epoch[1](7541/114412); Loss: 0.095604; Backpropagation: 0.3009 sec; Batch: 2.1240 sec
0.1745 0.1657 0.1266 0.1151 0.1015 0.0934 0.0868 0.0820 0.0783 0.0758 0.0743 0.0731 0.0716 0.0707 0.0702 0.0699 

[TRAIN] Epoch[1](7542/114412); Loss: 0.078813; Backpropagation: 0.2980 sec; Batch: 2.1610 sec
0.1416 0.1334 0.1044 0.0916 0.0811 0.0749 0.0703 0.0685 0.0660 0.0642 0.0627 0.0617 0.0609 0.0603 0.0599 0.0595 

[TRAIN] Epoch[1](7543/114412); Loss: 0.088960; Backpropagation: 0.2983 sec; Batch: 2.0864 sec
0.1630 0.1513 0.1205 0.1104 0.0954 0.0858 0.0784 0.0754 0.0722 0.0701 0.0690 0.0678 0.0668 0.0663 0.0657 0.0653 

[TRAIN] Epoch[1](7544/114412); Loss: 0.118798; Backpropagation: 0.2994 sec; Batch: 2.1283 sec
0.2047 0.2008 0.1730 0.1586 0.1374 0.1234 0.1120 0.1035 0.0974 0.0924 0.0886 0.0859 0.0831 0.0810 0.0798 0.0791 

[TRAIN] Epoch[1](7545/114412); Loss: 0.102208; Backpropagation: 0.3009 sec; Batch: 2.1255 sec
0.2371 0.2133 0.1571 0.1343 0.1060 0.0935 0.0856 0.0783 0.0730 0.0689 0.0676 0.0663 0.0642 0.0641 0.0635 0.0626 

[TRAIN] Epoch[1](7546/114412); Loss: 0.067314; Backpropagation: 0.2955 sec; Batch: 2.1311 sec
0.1414 0.1338 0.1000 0.0829 0.0686 0.0583 0.0544 0.0520 0.0500 0.0489 0.0483 0.0481 0.0476 0.0477 0.0476 0.0475 

[TRAIN] Epoch[1](7547/114412); Loss: 0.068362; Backpropagation: 0.2957 sec; Batch: 2.1223 sec
0.1292 0.1199 0.0971 0.0833 0.0694 0.0634 0.0598 0.0569 0.0549 0.0536 0.0526 0.0517 0.0512 0.0506 0.0501 0.0500 

[TRAIN] Epoch[1](7548/114412); Loss: 0.089719; Backpropagation: 0.3005 sec; Batch: 2.1340 sec
0.1635 0.1470 0.1237 0.1104 0.0934 0.0852 0.0810 0.0773 0.0737 0.0718 0.0701 0.0690 0.0684 0.0675 0.0670 0.0665 

[TRAIN] Epoch[1](7549/114412); Loss: 0.093202; Backpropagation: 0.2981 sec; Batch: 2.1233 sec
0.1584 0.1526 0.1240 0.1128 0.0997 0.0890 0.0828 0.0804 0.0784 0.0762 0.0749 0.0740 0.0729 0.0723 0.0716 0.0712 

[TRAIN] Epoch[1](7550/114412); Loss: 0.088907; Backpropagation: 0.2980 sec; Batch: 2.1211 sec
0.1839 0.1741 0.1443 0.1277 0.1044 0.0885 0.0757 0.0684 0.0635 0.0617 0.0592 0.0563 0.0552 0.0541 0.0531 0.0526 

[TRAIN] Epoch[1](7551/114412); Loss: 0.091547; Backpropagation: 0.2953 sec; Batch: 2.1189 sec
0.1348 0.1316 0.1110 0.1019 0.0969 0.0907 0.0860 0.0842 0.0817 0.0802 0.0791 0.0784 0.0777 0.0774 0.0767 0.0764 

[TRAIN] Epoch[1](7552/114412); Loss: 0.088239; Backpropagation: 0.2907 sec; Batch: 2.1220 sec
0.1389 0.1259 0.1093 0.0987 0.0916 0.0860 0.0821 0.0804 0.0782 0.0767 0.0756 0.0748 0.0741 0.0735 0.0731 0.0729 

[TRAIN] Epoch[1](7553/114412); Loss: 0.094933; Backpropagation: 0.2933 sec; Batch: 2.1206 sec
0.2155 0.1890 0.1473 0.1274 0.1060 0.0916 0.0792 0.0726 0.0686 0.0647 0.0622 0.0606 0.0591 0.0586 0.0583 0.0580 

[TRAIN] Epoch[1](7554/114412); Loss: 0.124237; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1962 0.1963 0.1639 0.1540 0.1424 0.1330 0.1255 0.1191 0.1134 0.1055 0.0987 0.0944 0.0899 0.0865 0.0849 0.0843 

[TRAIN] Epoch[1](7555/114412); Loss: 0.076752; Backpropagation: 0.2908 sec; Batch: 2.1293 sec
0.1199 0.1113 0.0934 0.0847 0.0808 0.0748 0.0720 0.0698 0.0680 0.0668 0.0659 0.0649 0.0644 0.0642 0.0637 0.0635 

[TRAIN] Epoch[1](7556/114412); Loss: 0.075398; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1217 0.1173 0.0973 0.0897 0.0832 0.0758 0.0699 0.0676 0.0643 0.0626 0.0616 0.0605 0.0595 0.0590 0.0583 0.0581 

[TRAIN] Epoch[1](7557/114412); Loss: 0.080145; Backpropagation: 0.2913 sec; Batch: 2.1133 sec
0.1446 0.1356 0.1104 0.0997 0.0856 0.0779 0.0724 0.0695 0.0661 0.0642 0.0625 0.0604 0.0595 0.0586 0.0578 0.0576 

[TRAIN] Epoch[1](7558/114412); Loss: 0.073906; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1351 0.1182 0.0960 0.0846 0.0772 0.0703 0.0664 0.0650 0.0624 0.0609 0.0595 0.0584 0.0576 0.0573 0.0570 0.0567 

[TRAIN] Epoch[1](7559/114412); Loss: 0.089392; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.1742 0.1570 0.1208 0.1115 0.0970 0.0859 0.0794 0.0747 0.0716 0.0699 0.0677 0.0665 0.0654 0.0637 0.0628 0.0621 

[TRAIN] Epoch[1](7560/114412); Loss: 0.084224; Backpropagation: 0.2908 sec; Batch: 2.1288 sec
0.1690 0.1576 0.1201 0.1028 0.0849 0.0745 0.0694 0.0690 0.0668 0.0645 0.0638 0.0623 0.0612 0.0609 0.0604 0.0603 

[TRAIN] Epoch[1](7561/114412); Loss: 0.093456; Backpropagation: 0.2954 sec; Batch: 2.1193 sec
0.2051 0.1881 0.1599 0.1422 0.1143 0.0893 0.0757 0.0685 0.0662 0.0633 0.0589 0.0556 0.0540 0.0522 0.0516 0.0506 

[TRAIN] Epoch[1](7562/114412); Loss: 0.096854; Backpropagation: 0.2914 sec; Batch: 2.1169 sec
0.2137 0.1907 0.1517 0.1302 0.1072 0.0931 0.0836 0.0766 0.0708 0.0660 0.0642 0.0624 0.0612 0.0601 0.0594 0.0588 

[TRAIN] Epoch[1](7563/114412); Loss: 0.078649; Backpropagation: 0.2956 sec; Batch: 2.1026 sec
0.1418 0.1356 0.1050 0.0928 0.0806 0.0738 0.0702 0.0677 0.0649 0.0634 0.0619 0.0609 0.0605 0.0600 0.0597 0.0594 

[TRAIN] Epoch[1](7564/114412); Loss: 0.090300; Backpropagation: 0.2953 sec; Batch: 2.1208 sec
0.1435 0.1394 0.1129 0.1030 0.0968 0.0897 0.0848 0.0815 0.0787 0.0764 0.0751 0.0737 0.0730 0.0726 0.0721 0.0716 

[TRAIN] Epoch[1](7565/114412); Loss: 0.087826; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1599 0.1531 0.1162 0.1042 0.0895 0.0821 0.0776 0.0748 0.0723 0.0704 0.0692 0.0684 0.0676 0.0670 0.0667 0.0662 

[TRAIN] Epoch[1](7566/114412); Loss: 0.098194; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.1775 0.1668 0.1451 0.1311 0.1130 0.1009 0.0913 0.0852 0.0788 0.0747 0.0720 0.0694 0.0678 0.0665 0.0657 0.0653 

[TRAIN] Epoch[1](7567/114412); Loss: 0.080737; Backpropagation: 0.2911 sec; Batch: 2.1125 sec
0.1864 0.1704 0.1171 0.1002 0.0761 0.0692 0.0655 0.0626 0.0597 0.0579 0.0568 0.0554 0.0548 0.0538 0.0532 0.0529 

[TRAIN] Epoch[1](7568/114412); Loss: 0.103891; Backpropagation: 0.2932 sec; Batch: 2.1192 sec
0.1983 0.1905 0.1524 0.1408 0.1170 0.1031 0.0935 0.0858 0.0808 0.0772 0.0750 0.0722 0.0703 0.0693 0.0684 0.0675 

[TRAIN] Epoch[1](7569/114412); Loss: 0.085291; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.1562 0.1437 0.1135 0.1052 0.0921 0.0834 0.0772 0.0730 0.0692 0.0667 0.0656 0.0648 0.0639 0.0637 0.0634 0.0630 

[TRAIN] Epoch[1](7570/114412); Loss: 0.103004; Backpropagation: 0.2914 sec; Batch: 2.1139 sec
0.1618 0.1564 0.1366 0.1282 0.1148 0.1061 0.0994 0.0943 0.0901 0.0863 0.0831 0.0808 0.0792 0.0778 0.0771 0.0760 

[TRAIN] Epoch[1](7571/114412); Loss: 0.075844; Backpropagation: 0.2929 sec; Batch: 2.1166 sec
0.1437 0.1337 0.0974 0.0829 0.0752 0.0704 0.0668 0.0649 0.0629 0.0616 0.0604 0.0596 0.0591 0.0586 0.0582 0.0580 

[TRAIN] Epoch[1](7572/114412); Loss: 0.113043; Backpropagation: 0.2931 sec; Batch: 2.1211 sec
0.1845 0.1772 0.1416 0.1295 0.1208 0.1090 0.1039 0.1006 0.0978 0.0953 0.0936 0.0929 0.0916 0.0906 0.0902 0.0894 

[TRAIN] Epoch[1](7573/114412); Loss: 0.087137; Backpropagation: 0.2933 sec; Batch: 2.1210 sec
0.1842 0.1665 0.1268 0.1064 0.0867 0.0779 0.0741 0.0700 0.0666 0.0656 0.0637 0.0622 0.0617 0.0609 0.0606 0.0602 

[TRAIN] Epoch[1](7574/114412); Loss: 0.070165; Backpropagation: 0.2931 sec; Batch: 2.1178 sec
0.1523 0.1436 0.1012 0.0870 0.0708 0.0635 0.0593 0.0559 0.0522 0.0507 0.0493 0.0484 0.0479 0.0473 0.0468 0.0466 

[TRAIN] Epoch[1](7575/114412); Loss: 0.088466; Backpropagation: 0.2916 sec; Batch: 2.1164 sec
0.1673 0.1566 0.1262 0.1118 0.0979 0.0885 0.0809 0.0753 0.0708 0.0677 0.0650 0.0635 0.0623 0.0612 0.0605 0.0600 

[TRAIN] Epoch[1](7576/114412); Loss: 0.090815; Backpropagation: 0.2909 sec; Batch: 2.0981 sec
0.1708 0.1577 0.1292 0.1186 0.1042 0.0930 0.0824 0.0764 0.0728 0.0686 0.0663 0.0646 0.0633 0.0623 0.0616 0.0613 

[TRAIN] Epoch[1](7577/114412); Loss: 0.088311; Backpropagation: 0.2913 sec; Batch: 2.0781 sec
0.1582 0.1535 0.1256 0.1133 0.0973 0.0845 0.0775 0.0739 0.0712 0.0692 0.0675 0.0661 0.0650 0.0639 0.0632 0.0630 

[TRAIN] Epoch[1](7578/114412); Loss: 0.103953; Backpropagation: 0.2913 sec; Batch: 2.1199 sec
0.1928 0.1760 0.1446 0.1291 0.1123 0.1010 0.0930 0.0886 0.0844 0.0810 0.0792 0.0781 0.0768 0.0761 0.0754 0.0751 

[TRAIN] Epoch[1](7579/114412); Loss: 0.089012; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1645 0.1600 0.1220 0.1091 0.0962 0.0850 0.0790 0.0755 0.0718 0.0701 0.0680 0.0664 0.0656 0.0647 0.0636 0.0628 

[TRAIN] Epoch[1](7580/114412); Loss: 0.083025; Backpropagation: 0.2915 sec; Batch: 2.1171 sec
0.1983 0.1851 0.1394 0.1266 0.0933 0.0735 0.0659 0.0604 0.0547 0.0512 0.0495 0.0477 0.0465 0.0459 0.0453 0.0450 

[TRAIN] Epoch[1](7581/114412); Loss: 0.078166; Backpropagation: 0.2908 sec; Batch: 2.1183 sec
0.1580 0.1490 0.1158 0.1008 0.0855 0.0756 0.0674 0.0640 0.0609 0.0586 0.0565 0.0539 0.0524 0.0514 0.0508 0.0502 

[TRAIN] Epoch[1](7582/114412); Loss: 0.107584; Backpropagation: 0.2908 sec; Batch: 2.1211 sec
0.1962 0.1793 0.1506 0.1346 0.1122 0.1020 0.0968 0.0934 0.0899 0.0865 0.0837 0.0814 0.0800 0.0790 0.0781 0.0776 

[TRAIN] Epoch[1](7583/114412); Loss: 0.117894; Backpropagation: 0.2912 sec; Batch: 2.1133 sec
0.2030 0.1888 0.1579 0.1465 0.1276 0.1176 0.1081 0.1033 0.0994 0.0956 0.0938 0.0920 0.0902 0.0887 0.0875 0.0862 

[TRAIN] Epoch[1](7584/114412); Loss: 0.101425; Backpropagation: 0.2914 sec; Batch: 2.1165 sec
0.1636 0.1564 0.1350 0.1182 0.1063 0.0986 0.0921 0.0888 0.0872 0.0848 0.0840 0.0830 0.0823 0.0813 0.0808 0.0802 

[TRAIN] Epoch[1](7585/114412); Loss: 0.094021; Backpropagation: 0.2914 sec; Batch: 2.1157 sec
0.1922 0.1764 0.1476 0.1243 0.1003 0.0851 0.0770 0.0740 0.0702 0.0690 0.0664 0.0652 0.0645 0.0643 0.0640 0.0638 

[TRAIN] Epoch[1](7586/114412); Loss: 0.095029; Backpropagation: 0.2912 sec; Batch: 2.1033 sec
0.1776 0.1629 0.1283 0.1127 0.1011 0.0921 0.0846 0.0805 0.0774 0.0752 0.0735 0.0724 0.0716 0.0707 0.0702 0.0698 

[TRAIN] Epoch[1](7587/114412); Loss: 0.061685; Backpropagation: 0.2915 sec; Batch: 2.1146 sec
0.1403 0.1270 0.0985 0.0805 0.0616 0.0563 0.0500 0.0466 0.0450 0.0433 0.0416 0.0407 0.0397 0.0390 0.0386 0.0383 

[TRAIN] Epoch[1](7588/114412); Loss: 0.105397; Backpropagation: 0.2930 sec; Batch: 2.1310 sec
0.2465 0.2213 0.1615 0.1309 0.1028 0.0908 0.0835 0.0807 0.0765 0.0742 0.0722 0.0708 0.0698 0.0690 0.0683 0.0677 

[TRAIN] Epoch[1](7589/114412); Loss: 0.100965; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1780 0.1646 0.1271 0.1158 0.1037 0.0969 0.0916 0.0884 0.0856 0.0835 0.0822 0.0811 0.0803 0.0795 0.0789 0.0783 

[TRAIN] Epoch[1](7590/114412); Loss: 0.107425; Backpropagation: 0.2914 sec; Batch: 2.1056 sec
0.1925 0.1684 0.1394 0.1221 0.1091 0.1005 0.0956 0.0932 0.0911 0.0896 0.0885 0.0874 0.0865 0.0855 0.0850 0.0845 

[TRAIN] Epoch[1](7591/114412); Loss: 0.075049; Backpropagation: 0.2907 sec; Batch: 2.1188 sec
0.1333 0.1233 0.0977 0.0872 0.0750 0.0698 0.0673 0.0652 0.0634 0.0617 0.0609 0.0602 0.0598 0.0592 0.0586 0.0582 

[TRAIN] Epoch[1](7592/114412); Loss: 0.092956; Backpropagation: 0.2928 sec; Batch: 2.0823 sec
0.2174 0.1933 0.1464 0.1170 0.0908 0.0771 0.0709 0.0698 0.0687 0.0674 0.0650 0.0630 0.0616 0.0605 0.0597 0.0589 

[TRAIN] Epoch[1](7593/114412); Loss: 0.089601; Backpropagation: 0.2951 sec; Batch: 2.1228 sec
0.1431 0.1411 0.1168 0.1074 0.0994 0.0906 0.0849 0.0815 0.0771 0.0743 0.0730 0.0713 0.0699 0.0687 0.0675 0.0671 

[TRAIN] Epoch[1](7594/114412); Loss: 0.113695; Backpropagation: 0.2913 sec; Batch: 2.1313 sec
0.1940 0.1833 0.1592 0.1421 0.1227 0.1100 0.1019 0.0978 0.0940 0.0908 0.0899 0.0885 0.0870 0.0862 0.0859 0.0857 

[TRAIN] Epoch[1](7595/114412); Loss: 0.102809; Backpropagation: 0.2931 sec; Batch: 2.1278 sec
0.1714 0.1609 0.1337 0.1212 0.1107 0.1010 0.0947 0.0908 0.0875 0.0855 0.0837 0.0825 0.0815 0.0805 0.0799 0.0795 

[TRAIN] Epoch[1](7596/114412); Loss: 0.093821; Backpropagation: 0.2913 sec; Batch: 2.1196 sec
0.1979 0.1811 0.1431 0.1265 0.1088 0.0926 0.0814 0.0750 0.0706 0.0666 0.0639 0.0616 0.0595 0.0584 0.0573 0.0568 

[TRAIN] Epoch[1](7597/114412); Loss: 0.089970; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1477 0.1454 0.1164 0.1056 0.0943 0.0872 0.0829 0.0792 0.0757 0.0745 0.0735 0.0724 0.0716 0.0713 0.0711 0.0707 

[TRAIN] Epoch[1](7598/114412); Loss: 0.143638; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.2609 0.2522 0.2236 0.2098 0.1808 0.1592 0.1422 0.1269 0.1153 0.1052 0.0969 0.0916 0.0885 0.0857 0.0812 0.0781 

[TRAIN] Epoch[1](7599/114412); Loss: 0.096402; Backpropagation: 0.2908 sec; Batch: 2.1122 sec
0.1883 0.1675 0.1318 0.1165 0.1009 0.0939 0.0889 0.0841 0.0814 0.0771 0.0736 0.0711 0.0687 0.0673 0.0661 0.0653 

[TRAIN] Epoch[1](7600/114412); Loss: 0.085678; Backpropagation: 0.2955 sec; Batch: 2.1220 sec
0.2046 0.1925 0.1415 0.1182 0.0957 0.0767 0.0669 0.0607 0.0574 0.0557 0.0535 0.0515 0.0501 0.0491 0.0486 0.0480 

[TRAIN] Epoch[1](7601/114412); Loss: 0.067505; Backpropagation: 0.2955 sec; Batch: 2.1296 sec
0.1397 0.1210 0.0901 0.0787 0.0703 0.0622 0.0580 0.0569 0.0539 0.0523 0.0511 0.0501 0.0497 0.0490 0.0487 0.0483 

[TRAIN] Epoch[1](7602/114412); Loss: 0.091092; Backpropagation: 0.2950 sec; Batch: 2.1169 sec
0.1715 0.1625 0.1307 0.1141 0.0978 0.0861 0.0796 0.0755 0.0721 0.0699 0.0684 0.0672 0.0662 0.0657 0.0653 0.0648 

[TRAIN] Epoch[1](7603/114412); Loss: 0.137392; Backpropagation: 0.2941 sec; Batch: 2.1178 sec
0.2602 0.2403 0.2035 0.1889 0.1599 0.1398 0.1251 0.1153 0.1086 0.1057 0.1022 0.0967 0.0921 0.0891 0.0865 0.0844 

[TRAIN] Epoch[1](7604/114412); Loss: 0.079785; Backpropagation: 0.2954 sec; Batch: 2.1225 sec
0.1657 0.1603 0.1206 0.1070 0.0871 0.0759 0.0680 0.0636 0.0594 0.0566 0.0551 0.0534 0.0523 0.0511 0.0504 0.0500 

[TRAIN] Epoch[1](7605/114412); Loss: 0.064468; Backpropagation: 0.2910 sec; Batch: 2.1249 sec
0.1154 0.1045 0.0859 0.0768 0.0667 0.0631 0.0587 0.0560 0.0538 0.0520 0.0509 0.0504 0.0498 0.0494 0.0492 0.0489 

[TRAIN] Epoch[1](7606/114412); Loss: 0.078656; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1030 0.0998 0.0976 0.0931 0.0888 0.0799 0.0761 0.0742 0.0720 0.0702 0.0693 0.0684 0.0674 0.0667 0.0662 0.0658 

[TRAIN] Epoch[1](7607/114412); Loss: 0.098667; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.2104 0.1977 0.1482 0.1316 0.1088 0.0922 0.0822 0.0752 0.0715 0.0694 0.0675 0.0663 0.0654 0.0648 0.0640 0.0634 

[TRAIN] Epoch[1](7608/114412); Loss: 0.050749; Backpropagation: 0.2913 sec; Batch: 2.1165 sec
0.1042 0.0993 0.0664 0.0567 0.0510 0.0463 0.0431 0.0415 0.0401 0.0390 0.0380 0.0374 0.0372 0.0372 0.0372 0.0372 

[TRAIN] Epoch[1](7609/114412); Loss: 0.083497; Backpropagation: 0.2904 sec; Batch: 2.1277 sec
0.1362 0.1287 0.1053 0.0937 0.0859 0.0806 0.0770 0.0748 0.0728 0.0712 0.0702 0.0691 0.0683 0.0678 0.0674 0.0672 

[TRAIN] Epoch[1](7610/114412); Loss: 0.134039; Backpropagation: 0.2911 sec; Batch: 2.1158 sec
0.2152 0.2095 0.1722 0.1574 0.1437 0.1330 0.1263 0.1224 0.1176 0.1141 0.1115 0.1080 0.1055 0.1046 0.1026 0.1010 

[TRAIN] Epoch[1](7611/114412); Loss: 0.076236; Backpropagation: 0.2914 sec; Batch: 2.1130 sec
0.1192 0.1141 0.0925 0.0839 0.0781 0.0739 0.0716 0.0695 0.0677 0.0663 0.0652 0.0645 0.0639 0.0634 0.0632 0.0629 

[TRAIN] Epoch[1](7612/114412); Loss: 0.080692; Backpropagation: 0.2931 sec; Batch: 2.1047 sec
0.1673 0.1611 0.1221 0.1104 0.0914 0.0789 0.0712 0.0655 0.0613 0.0578 0.0546 0.0523 0.0508 0.0497 0.0487 0.0480 

[TRAIN] Epoch[1](7613/114412); Loss: 0.079586; Backpropagation: 0.2928 sec; Batch: 2.0999 sec
0.1437 0.1298 0.1079 0.0958 0.0813 0.0765 0.0719 0.0688 0.0671 0.0643 0.0633 0.0620 0.0607 0.0605 0.0601 0.0597 

[TRAIN] Epoch[1](7614/114412); Loss: 0.063365; Backpropagation: 0.2912 sec; Batch: 2.1198 sec
0.1285 0.1194 0.0820 0.0695 0.0611 0.0563 0.0536 0.0526 0.0511 0.0497 0.0490 0.0486 0.0484 0.0480 0.0479 0.0479 

[TRAIN] Epoch[1](7615/114412); Loss: 0.114464; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1792 0.1635 0.1414 0.1291 0.1178 0.1120 0.1079 0.1045 0.1012 0.0993 0.0982 0.0969 0.0961 0.0953 0.0947 0.0943 

[TRAIN] Epoch[1](7616/114412); Loss: 0.099251; Backpropagation: 0.2906 sec; Batch: 2.1169 sec
0.1953 0.1821 0.1532 0.1413 0.1188 0.0999 0.0843 0.0758 0.0716 0.0699 0.0691 0.0671 0.0659 0.0652 0.0645 0.0640 

[TRAIN] Epoch[1](7617/114412); Loss: 0.104059; Backpropagation: 0.2928 sec; Batch: 2.1198 sec
0.2072 0.1968 0.1669 0.1533 0.1301 0.1087 0.0941 0.0834 0.0757 0.0705 0.0670 0.0643 0.0634 0.0622 0.0611 0.0602 

[TRAIN] Epoch[1](7618/114412); Loss: 0.095529; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1535 0.1465 0.1238 0.1148 0.1028 0.0953 0.0899 0.0866 0.0831 0.0805 0.0784 0.0769 0.0756 0.0743 0.0737 0.0729 

[TRAIN] Epoch[1](7619/114412); Loss: 0.097015; Backpropagation: 0.2955 sec; Batch: 2.1178 sec
0.2058 0.1880 0.1502 0.1318 0.1086 0.0922 0.0827 0.0765 0.0728 0.0689 0.0655 0.0641 0.0628 0.0615 0.0608 0.0601 

[TRAIN] Epoch[1](7620/114412); Loss: 0.089996; Backpropagation: 0.2928 sec; Batch: 2.1200 sec
0.1815 0.1737 0.1326 0.1226 0.0994 0.0843 0.0758 0.0713 0.0671 0.0648 0.0633 0.0620 0.0612 0.0606 0.0600 0.0598 

[TRAIN] Epoch[1](7621/114412); Loss: 0.099697; Backpropagation: 0.2913 sec; Batch: 2.1200 sec
0.2192 0.1994 0.1639 0.1432 0.1131 0.0949 0.0816 0.0763 0.0707 0.0671 0.0647 0.0628 0.0612 0.0599 0.0589 0.0582 

[TRAIN] Epoch[1](7622/114412); Loss: 0.085906; Backpropagation: 0.2909 sec; Batch: 2.1180 sec
0.1533 0.1394 0.1117 0.0995 0.0890 0.0819 0.0778 0.0758 0.0736 0.0719 0.0699 0.0682 0.0672 0.0660 0.0652 0.0642 

[TRAIN] Epoch[1](7623/114412); Loss: 0.088122; Backpropagation: 0.2918 sec; Batch: 2.1174 sec
0.1423 0.1304 0.1038 0.0945 0.0923 0.0869 0.0834 0.0817 0.0786 0.0766 0.0752 0.0744 0.0735 0.0727 0.0720 0.0718 

[TRAIN] Epoch[1](7624/114412); Loss: 0.115232; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.2040 0.1934 0.1616 0.1448 0.1255 0.1155 0.1075 0.1022 0.0969 0.0911 0.0886 0.0866 0.0836 0.0820 0.0807 0.0794 

[TRAIN] Epoch[1](7625/114412); Loss: 0.087387; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1755 0.1701 0.1252 0.1161 0.0997 0.0866 0.0767 0.0693 0.0659 0.0638 0.0610 0.0593 0.0581 0.0578 0.0570 0.0562 

[TRAIN] Epoch[1](7626/114412); Loss: 0.111423; Backpropagation: 0.2913 sec; Batch: 2.1147 sec
0.1934 0.1850 0.1541 0.1411 0.1250 0.1147 0.1056 0.0985 0.0914 0.0868 0.0847 0.0827 0.0811 0.0803 0.0794 0.0790 

[TRAIN] Epoch[1](7627/114412); Loss: 0.118299; Backpropagation: 0.2930 sec; Batch: 2.1216 sec
0.2020 0.1932 0.1677 0.1561 0.1405 0.1274 0.1173 0.1075 0.0990 0.0927 0.0882 0.0851 0.0819 0.0800 0.0780 0.0764 

[TRAIN] Epoch[1](7628/114412); Loss: 0.066170; Backpropagation: 0.2927 sec; Batch: 2.1184 sec
0.1136 0.1015 0.0805 0.0758 0.0693 0.0637 0.0604 0.0598 0.0572 0.0556 0.0548 0.0541 0.0536 0.0532 0.0529 0.0525 

[TRAIN] Epoch[1](7629/114412); Loss: 0.115356; Backpropagation: 0.2928 sec; Batch: 2.1280 sec
0.2015 0.1920 0.1567 0.1425 0.1237 0.1117 0.1033 0.0986 0.0954 0.0927 0.0907 0.0891 0.0881 0.0872 0.0864 0.0859 

[TRAIN] Epoch[1](7630/114412); Loss: 0.093939; Backpropagation: 0.2909 sec; Batch: 2.1330 sec
0.1699 0.1498 0.1195 0.1026 0.0941 0.0889 0.0846 0.0823 0.0795 0.0781 0.0772 0.0763 0.0756 0.0751 0.0747 0.0746 

[TRAIN] Epoch[1](7631/114412); Loss: 0.073508; Backpropagation: 0.2914 sec; Batch: 2.1190 sec
0.1595 0.1499 0.1074 0.0899 0.0737 0.0636 0.0586 0.0569 0.0548 0.0536 0.0531 0.0520 0.0514 0.0510 0.0506 0.0503 

[TRAIN] Epoch[1](7632/114412); Loss: 0.093293; Backpropagation: 0.2929 sec; Batch: 2.1175 sec
0.1712 0.1611 0.1321 0.1253 0.1061 0.0937 0.0836 0.0779 0.0741 0.0715 0.0691 0.0675 0.0666 0.0651 0.0643 0.0634 

[TRAIN] Epoch[1](7633/114412); Loss: 0.113894; Backpropagation: 0.2913 sec; Batch: 2.1147 sec
0.1687 0.1598 0.1331 0.1253 0.1179 0.1110 0.1076 0.1061 0.1038 0.1022 0.1005 0.0993 0.0983 0.0970 0.0963 0.0955 

[TRAIN] Epoch[1](7634/114412); Loss: 0.116277; Backpropagation: 0.2930 sec; Batch: 2.1275 sec
0.2162 0.2016 0.1710 0.1587 0.1347 0.1205 0.1082 0.1002 0.0938 0.0887 0.0841 0.0806 0.0782 0.0762 0.0744 0.0734 

[TRAIN] Epoch[1](7635/114412); Loss: 0.101975; Backpropagation: 0.2927 sec; Batch: 2.1455 sec
0.1937 0.1822 0.1477 0.1364 0.1142 0.0992 0.0880 0.0827 0.0781 0.0761 0.0746 0.0733 0.0725 0.0715 0.0709 0.0704 

[TRAIN] Epoch[1](7636/114412); Loss: 0.098838; Backpropagation: 0.2911 sec; Batch: 2.1196 sec
0.1782 0.1562 0.1251 0.1093 0.1002 0.0930 0.0895 0.0867 0.0846 0.0829 0.0813 0.0802 0.0793 0.0788 0.0784 0.0778 

[TRAIN] Epoch[1](7637/114412); Loss: 0.063313; Backpropagation: 0.2932 sec; Batch: 2.1198 sec
0.1268 0.1235 0.0886 0.0766 0.0631 0.0567 0.0536 0.0510 0.0494 0.0483 0.0472 0.0467 0.0460 0.0454 0.0452 0.0449 

[TRAIN] Epoch[1](7638/114412); Loss: 0.110161; Backpropagation: 0.2914 sec; Batch: 2.1201 sec
0.1670 0.1551 0.1348 0.1243 0.1136 0.1077 0.1034 0.1010 0.0990 0.0971 0.0956 0.0945 0.0935 0.0926 0.0920 0.0914 

[TRAIN] Epoch[1](7639/114412); Loss: 0.081120; Backpropagation: 0.2913 sec; Batch: 2.1168 sec
0.1280 0.1206 0.1044 0.0964 0.0893 0.0813 0.0767 0.0743 0.0708 0.0686 0.0670 0.0657 0.0646 0.0639 0.0634 0.0629 

[TRAIN] Epoch[1](7640/114412); Loss: 0.089786; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1502 0.1437 0.1185 0.1115 0.0987 0.0900 0.0826 0.0783 0.0751 0.0737 0.0719 0.0703 0.0691 0.0684 0.0676 0.0670 

[TRAIN] Epoch[1](7641/114412); Loss: 0.099452; Backpropagation: 0.2912 sec; Batch: 2.1171 sec
0.1693 0.1629 0.1312 0.1185 0.1090 0.0984 0.0931 0.0892 0.0848 0.0828 0.0794 0.0777 0.0759 0.0743 0.0731 0.0717 

[TRAIN] Epoch[1](7642/114412); Loss: 0.088245; Backpropagation: 0.2958 sec; Batch: 2.1182 sec
0.1749 0.1658 0.1294 0.1172 0.1022 0.0882 0.0784 0.0730 0.0688 0.0649 0.0620 0.0598 0.0583 0.0572 0.0562 0.0556 

[TRAIN] Epoch[1](7643/114412); Loss: 0.081354; Backpropagation: 0.2929 sec; Batch: 2.1221 sec
0.1620 0.1438 0.1106 0.0964 0.0852 0.0765 0.0723 0.0698 0.0655 0.0633 0.0621 0.0609 0.0598 0.0586 0.0577 0.0574 

[TRAIN] Epoch[1](7644/114412); Loss: 0.066750; Backpropagation: 0.2934 sec; Batch: 2.1175 sec
0.1249 0.1127 0.0936 0.0841 0.0729 0.0643 0.0587 0.0565 0.0542 0.0522 0.0509 0.0499 0.0491 0.0485 0.0479 0.0477 

[TRAIN] Epoch[1](7645/114412); Loss: 0.087178; Backpropagation: 0.2911 sec; Batch: 2.1163 sec
0.1396 0.1331 0.1148 0.1048 0.0950 0.0871 0.0800 0.0776 0.0748 0.0732 0.0715 0.0700 0.0693 0.0686 0.0679 0.0675 

[TRAIN] Epoch[1](7646/114412); Loss: 0.101205; Backpropagation: 0.2910 sec; Batch: 2.1370 sec
0.1818 0.1711 0.1368 0.1201 0.1072 0.0991 0.0923 0.0884 0.0868 0.0833 0.0805 0.0782 0.0758 0.0742 0.0725 0.0713 

[TRAIN] Epoch[1](7647/114412); Loss: 0.086669; Backpropagation: 0.2915 sec; Batch: 2.1399 sec
0.1569 0.1492 0.1194 0.1103 0.0976 0.0873 0.0806 0.0751 0.0715 0.0682 0.0655 0.0637 0.0619 0.0609 0.0598 0.0588 

[TRAIN] Epoch[1](7648/114412); Loss: 0.087089; Backpropagation: 0.2909 sec; Batch: 2.1197 sec
0.1505 0.1452 0.1215 0.1119 0.0982 0.0868 0.0795 0.0748 0.0714 0.0691 0.0672 0.0648 0.0637 0.0634 0.0629 0.0626 

[TRAIN] Epoch[1](7649/114412); Loss: 0.102468; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.1615 0.1574 0.1304 0.1225 0.1111 0.1031 0.0970 0.0927 0.0885 0.0856 0.0836 0.0828 0.0818 0.0811 0.0804 0.0799 

[TRAIN] Epoch[1](7650/114412); Loss: 0.088685; Backpropagation: 0.2909 sec; Batch: 2.1155 sec
0.1390 0.1347 0.1087 0.1012 0.0932 0.0873 0.0825 0.0804 0.0779 0.0764 0.0753 0.0740 0.0733 0.0724 0.0717 0.0710 

[TRAIN] Epoch[1](7651/114412); Loss: 0.101079; Backpropagation: 0.2906 sec; Batch: 2.1177 sec
0.1755 0.1662 0.1382 0.1265 0.1134 0.1013 0.0920 0.0871 0.0822 0.0802 0.0786 0.0772 0.0761 0.0752 0.0742 0.0735 

[TRAIN] Epoch[1](7652/114412); Loss: 0.097217; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1552 0.1454 0.1229 0.1158 0.1033 0.0945 0.0907 0.0879 0.0846 0.0827 0.0813 0.0797 0.0791 0.0784 0.0771 0.0767 

[TRAIN] Epoch[1](7653/114412); Loss: 0.085446; Backpropagation: 0.2906 sec; Batch: 2.1174 sec
0.1519 0.1454 0.1153 0.1003 0.0872 0.0797 0.0761 0.0736 0.0710 0.0702 0.0683 0.0672 0.0665 0.0655 0.0648 0.0642 

[TRAIN] Epoch[1](7654/114412); Loss: 0.062089; Backpropagation: 0.2932 sec; Batch: 2.1202 sec
0.1294 0.1282 0.0888 0.0798 0.0662 0.0563 0.0509 0.0485 0.0457 0.0448 0.0435 0.0427 0.0426 0.0420 0.0419 0.0421 

[TRAIN] Epoch[1](7655/114412); Loss: 0.152485; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.3448 0.3284 0.2724 0.2565 0.2167 0.1850 0.1555 0.1263 0.1028 0.0853 0.0721 0.0659 0.0606 0.0583 0.0560 0.0533 

[TRAIN] Epoch[1](7656/114412); Loss: 0.093444; Backpropagation: 0.2914 sec; Batch: 2.1142 sec
0.1774 0.1690 0.1377 0.1280 0.1093 0.0964 0.0842 0.0757 0.0706 0.0681 0.0664 0.0646 0.0632 0.0623 0.0614 0.0607 

[TRAIN] Epoch[1](7657/114412); Loss: 0.098646; Backpropagation: 0.2923 sec; Batch: 2.1188 sec
0.1918 0.1760 0.1412 0.1292 0.1082 0.0954 0.0867 0.0824 0.0771 0.0751 0.0731 0.0713 0.0697 0.0679 0.0669 0.0663 

[TRAIN] Epoch[1](7658/114412); Loss: 0.083497; Backpropagation: 0.2914 sec; Batch: 2.1159 sec
0.1380 0.1332 0.1081 0.0993 0.0902 0.0829 0.0779 0.0743 0.0713 0.0690 0.0675 0.0666 0.0654 0.0647 0.0642 0.0634 

[TRAIN] Epoch[1](7659/114412); Loss: 0.087648; Backpropagation: 0.2905 sec; Batch: 2.1127 sec
0.1484 0.1409 0.1140 0.1035 0.0940 0.0856 0.0802 0.0775 0.0744 0.0724 0.0712 0.0699 0.0687 0.0679 0.0672 0.0665 

[TRAIN] Epoch[1](7660/114412); Loss: 0.079667; Backpropagation: 0.2906 sec; Batch: 2.1148 sec
0.1629 0.1602 0.1234 0.1117 0.0908 0.0785 0.0678 0.0607 0.0570 0.0554 0.0537 0.0517 0.0510 0.0504 0.0499 0.0495 

[TRAIN] Epoch[1](7661/114412); Loss: 0.098336; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1678 0.1597 0.1333 0.1238 0.1084 0.0996 0.0927 0.0878 0.0831 0.0785 0.0759 0.0742 0.0730 0.0724 0.0719 0.0713 

[TRAIN] Epoch[1](7662/114412); Loss: 0.078788; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1277 0.1237 0.0970 0.0877 0.0805 0.0746 0.0716 0.0706 0.0685 0.0675 0.0666 0.0656 0.0653 0.0648 0.0645 0.0644 

[TRAIN] Epoch[1](7663/114412); Loss: 0.078106; Backpropagation: 0.2906 sec; Batch: 2.1162 sec
0.1541 0.1319 0.1024 0.0917 0.0788 0.0718 0.0671 0.0660 0.0642 0.0628 0.0616 0.0606 0.0599 0.0594 0.0589 0.0586 

[TRAIN] Epoch[1](7664/114412); Loss: 0.072597; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1443 0.1347 0.1049 0.0937 0.0768 0.0678 0.0617 0.0593 0.0568 0.0546 0.0533 0.0519 0.0512 0.0505 0.0502 0.0497 

[TRAIN] Epoch[1](7665/114412); Loss: 0.078949; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1231 0.1164 0.0952 0.0871 0.0833 0.0768 0.0739 0.0729 0.0707 0.0690 0.0679 0.0667 0.0660 0.0653 0.0646 0.0644 

[TRAIN] Epoch[1](7666/114412); Loss: 0.104650; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.1682 0.1591 0.1401 0.1298 0.1157 0.1053 0.0980 0.0922 0.0889 0.0862 0.0841 0.0831 0.0819 0.0811 0.0805 0.0802 

[TRAIN] Epoch[1](7667/114412); Loss: 0.077071; Backpropagation: 0.2913 sec; Batch: 2.0773 sec
0.1514 0.1391 0.1080 0.0990 0.0834 0.0732 0.0666 0.0633 0.0606 0.0586 0.0571 0.0557 0.0551 0.0545 0.0540 0.0536 

[TRAIN] Epoch[1](7668/114412); Loss: 0.070113; Backpropagation: 0.2914 sec; Batch: 2.0825 sec
0.1217 0.1157 0.0951 0.0850 0.0735 0.0678 0.0637 0.0607 0.0579 0.0564 0.0551 0.0544 0.0541 0.0537 0.0534 0.0534 

[TRAIN] Epoch[1](7669/114412); Loss: 0.091201; Backpropagation: 0.2912 sec; Batch: 2.0778 sec
0.1769 0.1674 0.1319 0.1180 0.0954 0.0866 0.0777 0.0746 0.0716 0.0687 0.0680 0.0664 0.0653 0.0643 0.0635 0.0630 

[TRAIN] Epoch[1](7670/114412); Loss: 0.096955; Backpropagation: 0.2914 sec; Batch: 2.1205 sec
0.1853 0.1798 0.1417 0.1310 0.1140 0.1012 0.0899 0.0811 0.0751 0.0716 0.0681 0.0657 0.0637 0.0621 0.0609 0.0601 

[TRAIN] Epoch[1](7671/114412); Loss: 0.080173; Backpropagation: 0.2910 sec; Batch: 2.1157 sec
0.1456 0.1359 0.1097 0.1027 0.0908 0.0804 0.0731 0.0683 0.0645 0.0623 0.0603 0.0594 0.0584 0.0576 0.0571 0.0567 

[TRAIN] Epoch[1](7672/114412); Loss: 0.090994; Backpropagation: 0.2911 sec; Batch: 2.1142 sec
0.1523 0.1441 0.1248 0.1180 0.1026 0.0928 0.0852 0.0809 0.0788 0.0767 0.0726 0.0692 0.0666 0.0649 0.0637 0.0628 

[TRAIN] Epoch[1](7673/114412); Loss: 0.067950; Backpropagation: 0.2909 sec; Batch: 2.1179 sec
0.1481 0.1437 0.1062 0.0940 0.0771 0.0663 0.0564 0.0513 0.0474 0.0449 0.0437 0.0426 0.0419 0.0415 0.0412 0.0408 

[TRAIN] Epoch[1](7674/114412); Loss: 0.095073; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1650 0.1536 0.1324 0.1204 0.1030 0.0908 0.0841 0.0812 0.0784 0.0767 0.0749 0.0738 0.0728 0.0720 0.0713 0.0707 

[TRAIN] Epoch[1](7675/114412); Loss: 0.146804; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.2755 0.2576 0.2206 0.2049 0.1751 0.1530 0.1358 0.1215 0.1125 0.1064 0.1023 0.1001 0.0979 0.0968 0.0953 0.0937 

[TRAIN] Epoch[1](7676/114412); Loss: 0.077563; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1452 0.1271 0.1068 0.0951 0.0813 0.0733 0.0684 0.0655 0.0627 0.0617 0.0611 0.0598 0.0589 0.0586 0.0578 0.0575 

[TRAIN] Epoch[1](7677/114412); Loss: 0.089109; Backpropagation: 0.2906 sec; Batch: 2.1173 sec
0.1345 0.1250 0.1125 0.1064 0.0973 0.0908 0.0854 0.0819 0.0785 0.0769 0.0751 0.0737 0.0730 0.0722 0.0715 0.0711 

[TRAIN] Epoch[1](7678/114412); Loss: 0.117451; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1894 0.1760 0.1490 0.1395 0.1294 0.1179 0.1103 0.1056 0.1028 0.0995 0.0970 0.0951 0.0936 0.0920 0.0913 0.0908 

[TRAIN] Epoch[1](7679/114412); Loss: 0.113047; Backpropagation: 0.2910 sec; Batch: 2.1182 sec
0.1916 0.1730 0.1396 0.1272 0.1163 0.1104 0.1047 0.1007 0.0980 0.0958 0.0941 0.0929 0.0921 0.0916 0.0907 0.0901 

[TRAIN] Epoch[1](7680/114412); Loss: 0.078538; Backpropagation: 0.2908 sec; Batch: 2.1177 sec
0.1374 0.1192 0.1016 0.0906 0.0806 0.0752 0.0714 0.0695 0.0673 0.0658 0.0646 0.0638 0.0631 0.0625 0.0620 0.0619 

[TRAIN] Epoch[1](7681/114412); Loss: 0.081468; Backpropagation: 0.2924 sec; Batch: 2.1212 sec
0.1555 0.1428 0.1129 0.0994 0.0867 0.0785 0.0719 0.0680 0.0655 0.0632 0.0623 0.0612 0.0601 0.0590 0.0586 0.0580 

[TRAIN] Epoch[1](7682/114412); Loss: 0.116598; Backpropagation: 0.2913 sec; Batch: 2.0942 sec
0.2085 0.1934 0.1641 0.1517 0.1308 0.1187 0.1084 0.1015 0.0964 0.0916 0.0886 0.0861 0.0841 0.0820 0.0805 0.0794 

[TRAIN] Epoch[1](7683/114412); Loss: 0.092510; Backpropagation: 0.2914 sec; Batch: 2.1221 sec
0.1466 0.1351 0.1239 0.1157 0.1045 0.0957 0.0880 0.0834 0.0794 0.0768 0.0745 0.0729 0.0719 0.0711 0.0706 0.0700 

[TRAIN] Epoch[1](7684/114412); Loss: 0.085139; Backpropagation: 0.2907 sec; Batch: 2.1170 sec
0.1485 0.1446 0.1134 0.0997 0.0859 0.0789 0.0745 0.0724 0.0708 0.0698 0.0688 0.0680 0.0674 0.0668 0.0665 0.0662 

[TRAIN] Epoch[1](7685/114412); Loss: 0.106780; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.2355 0.2236 0.1717 0.1564 0.1299 0.1112 0.0932 0.0797 0.0703 0.0669 0.0644 0.0630 0.0620 0.0608 0.0602 0.0596 

[TRAIN] Epoch[1](7686/114412); Loss: 0.067517; Backpropagation: 0.2937 sec; Batch: 2.1225 sec
0.1160 0.1098 0.0935 0.0834 0.0735 0.0656 0.0609 0.0579 0.0558 0.0540 0.0530 0.0521 0.0516 0.0513 0.0510 0.0510 

[TRAIN] Epoch[1](7687/114412); Loss: 0.090553; Backpropagation: 0.2912 sec; Batch: 2.1158 sec
0.1837 0.1708 0.1359 0.1212 0.1049 0.0897 0.0788 0.0723 0.0684 0.0650 0.0622 0.0612 0.0596 0.0589 0.0585 0.0577 

[TRAIN] Epoch[1](7688/114412); Loss: 0.124337; Backpropagation: 0.2910 sec; Batch: 2.1292 sec
0.2226 0.2106 0.1779 0.1644 0.1448 0.1319 0.1196 0.1090 0.1007 0.0952 0.0912 0.0883 0.0860 0.0839 0.0824 0.0807 

[TRAIN] Epoch[1](7689/114412); Loss: 0.087292; Backpropagation: 0.2914 sec; Batch: 2.1299 sec
0.1499 0.1433 0.1183 0.1046 0.0915 0.0825 0.0782 0.0752 0.0735 0.0712 0.0698 0.0687 0.0681 0.0675 0.0673 0.0671 

[TRAIN] Epoch[1](7690/114412); Loss: 0.100162; Backpropagation: 0.2909 sec; Batch: 2.1198 sec
0.1456 0.1411 0.1247 0.1184 0.1123 0.1022 0.0951 0.0929 0.0902 0.0875 0.0855 0.0834 0.0821 0.0813 0.0804 0.0799 

[TRAIN] Epoch[1](7691/114412); Loss: 0.114904; Backpropagation: 0.2934 sec; Batch: 2.1122 sec
0.1828 0.1758 0.1504 0.1424 0.1282 0.1161 0.1099 0.1053 0.0988 0.0951 0.0928 0.0904 0.0888 0.0879 0.0870 0.0866 

[TRAIN] Epoch[1](7692/114412); Loss: 0.096741; Backpropagation: 0.2929 sec; Batch: 2.2470 sec
0.1729 0.1590 0.1322 0.1251 0.1064 0.0952 0.0878 0.0832 0.0795 0.0770 0.0752 0.0734 0.0717 0.0707 0.0697 0.0689 

[TRAIN] Epoch[1](7693/114412); Loss: 0.085106; Backpropagation: 0.2932 sec; Batch: 2.1174 sec
0.1845 0.1682 0.1345 0.1254 0.1035 0.0874 0.0750 0.0661 0.0598 0.0564 0.0541 0.0519 0.0504 0.0491 0.0479 0.0473 

[TRAIN] Epoch[1](7694/114412); Loss: 0.072319; Backpropagation: 0.2917 sec; Batch: 2.1445 sec
0.1346 0.1321 0.0995 0.0872 0.0732 0.0655 0.0615 0.0602 0.0584 0.0570 0.0562 0.0552 0.0547 0.0545 0.0539 0.0534 

[TRAIN] Epoch[1](7695/114412); Loss: 0.098360; Backpropagation: 0.2912 sec; Batch: 2.1404 sec
0.1643 0.1596 0.1241 0.1175 0.1046 0.0971 0.0902 0.0875 0.0847 0.0810 0.0805 0.0788 0.0769 0.0764 0.0756 0.0748 

[TRAIN] Epoch[1](7696/114412); Loss: 0.073285; Backpropagation: 0.2952 sec; Batch: 2.1795 sec
0.1005 0.0936 0.0945 0.0873 0.0814 0.0747 0.0709 0.0687 0.0663 0.0650 0.0637 0.0625 0.0617 0.0612 0.0605 0.0600 

[TRAIN] Epoch[1](7697/114412); Loss: 0.085204; Backpropagation: 0.2933 sec; Batch: 2.3094 sec
0.1571 0.1529 0.1177 0.1070 0.0950 0.0847 0.0764 0.0715 0.0677 0.0652 0.0637 0.0624 0.0614 0.0607 0.0602 0.0596 

[TRAIN] Epoch[1](7698/114412); Loss: 0.092626; Backpropagation: 0.2955 sec; Batch: 2.1145 sec
0.1580 0.1502 0.1259 0.1148 0.1029 0.0921 0.0847 0.0797 0.0765 0.0741 0.0726 0.0715 0.0706 0.0700 0.0695 0.0689 

[TRAIN] Epoch[1](7699/114412); Loss: 0.124262; Backpropagation: 0.2924 sec; Batch: 2.1254 sec
0.2277 0.2123 0.1814 0.1690 0.1434 0.1262 0.1122 0.1036 0.0981 0.0940 0.0907 0.0890 0.0873 0.0856 0.0845 0.0831 

[TRAIN] Epoch[1](7700/114412); Loss: 0.130611; Backpropagation: 0.2928 sec; Batch: 2.1136 sec
0.2284 0.2231 0.1957 0.1821 0.1594 0.1427 0.1288 0.1155 0.1045 0.0973 0.0916 0.0879 0.0858 0.0840 0.0823 0.0809 

[TRAIN] Epoch[1](7701/114412); Loss: 0.134878; Backpropagation: 0.2913 sec; Batch: 2.2868 sec
0.2313 0.2210 0.1891 0.1795 0.1637 0.1520 0.1405 0.1288 0.1181 0.1085 0.0989 0.0926 0.0882 0.0847 0.0815 0.0797 

[TRAIN] Epoch[1](7702/114412); Loss: 0.100466; Backpropagation: 0.2911 sec; Batch: 2.1457 sec
0.1866 0.1751 0.1427 0.1344 0.1155 0.1007 0.0904 0.0840 0.0788 0.0757 0.0730 0.0721 0.0711 0.0696 0.0691 0.0685 

[TRAIN] Epoch[1](7703/114412); Loss: 0.092359; Backpropagation: 0.2929 sec; Batch: 2.1217 sec
0.1742 0.1690 0.1357 0.1243 0.1093 0.0979 0.0874 0.0782 0.0734 0.0691 0.0654 0.0634 0.0607 0.0583 0.0568 0.0546 

[TRAIN] Epoch[1](7704/114412); Loss: 0.077921; Backpropagation: 0.2915 sec; Batch: 2.1132 sec
0.1247 0.1178 0.1032 0.0943 0.0827 0.0756 0.0716 0.0699 0.0671 0.0660 0.0644 0.0634 0.0625 0.0618 0.0612 0.0606 

[TRAIN] Epoch[1](7705/114412); Loss: 0.111757; Backpropagation: 0.2913 sec; Batch: 2.1730 sec
0.1905 0.1835 0.1537 0.1486 0.1351 0.1185 0.1052 0.0962 0.0904 0.0869 0.0834 0.0815 0.0799 0.0793 0.0782 0.0775 

[TRAIN] Epoch[1](7706/114412); Loss: 0.112195; Backpropagation: 0.2911 sec; Batch: 2.1104 sec
0.2001 0.1932 0.1682 0.1591 0.1373 0.1208 0.1071 0.0968 0.0900 0.0839 0.0790 0.0758 0.0732 0.0712 0.0704 0.0690 

[TRAIN] Epoch[1](7707/114412); Loss: 0.085204; Backpropagation: 0.2915 sec; Batch: 2.1254 sec
0.1429 0.1341 0.1139 0.1058 0.0932 0.0843 0.0784 0.0763 0.0713 0.0693 0.0680 0.0667 0.0658 0.0650 0.0644 0.0638 

[TRAIN] Epoch[1](7708/114412); Loss: 0.084578; Backpropagation: 0.2929 sec; Batch: 2.1175 sec
0.1613 0.1568 0.1278 0.1141 0.0963 0.0833 0.0745 0.0688 0.0656 0.0628 0.0601 0.0583 0.0572 0.0563 0.0554 0.0548 

[TRAIN] Epoch[1](7709/114412); Loss: 0.067236; Backpropagation: 0.2936 sec; Batch: 2.1486 sec
0.1358 0.1210 0.0933 0.0847 0.0755 0.0657 0.0609 0.0572 0.0533 0.0506 0.0491 0.0478 0.0464 0.0453 0.0447 0.0443 

[TRAIN] Epoch[1](7710/114412); Loss: 0.108567; Backpropagation: 0.2928 sec; Batch: 2.1625 sec
0.1691 0.1622 0.1430 0.1339 0.1208 0.1114 0.1026 0.0968 0.0929 0.0904 0.0881 0.0868 0.0858 0.0853 0.0849 0.0832 

[TRAIN] Epoch[1](7711/114412); Loss: 0.090846; Backpropagation: 0.2931 sec; Batch: 2.1170 sec
0.1526 0.1461 0.1251 0.1153 0.1004 0.0894 0.0819 0.0787 0.0760 0.0731 0.0714 0.0702 0.0693 0.0685 0.0680 0.0677 

[TRAIN] Epoch[1](7712/114412); Loss: 0.113721; Backpropagation: 0.2951 sec; Batch: 2.1475 sec
0.2274 0.2151 0.1825 0.1683 0.1367 0.1137 0.1005 0.0906 0.0830 0.0791 0.0754 0.0724 0.0709 0.0693 0.0678 0.0669 

[TRAIN] Epoch[1](7713/114412); Loss: 0.100449; Backpropagation: 0.2929 sec; Batch: 2.1083 sec
0.1607 0.1433 0.1229 0.1170 0.1060 0.0989 0.0935 0.0900 0.0880 0.0861 0.0852 0.0844 0.0835 0.0829 0.0827 0.0822 

[TRAIN] Epoch[1](7714/114412); Loss: 0.102461; Backpropagation: 0.2908 sec; Batch: 2.1446 sec
0.1875 0.1722 0.1371 0.1270 0.1153 0.1053 0.0979 0.0908 0.0856 0.0806 0.0778 0.0760 0.0732 0.0720 0.0712 0.0697 

[TRAIN] Epoch[1](7715/114412); Loss: 0.077607; Backpropagation: 0.2912 sec; Batch: 2.0964 sec
0.1294 0.1182 0.0931 0.0883 0.0817 0.0750 0.0720 0.0698 0.0681 0.0662 0.0650 0.0641 0.0633 0.0629 0.0625 0.0623 

[TRAIN] Epoch[1](7716/114412); Loss: 0.095122; Backpropagation: 0.2907 sec; Batch: 2.1577 sec
0.1646 0.1533 0.1350 0.1270 0.1111 0.1020 0.0916 0.0829 0.0769 0.0733 0.0706 0.0682 0.0677 0.0665 0.0659 0.0654 

[TRAIN] Epoch[1](7717/114412); Loss: 0.088876; Backpropagation: 0.2912 sec; Batch: 2.1135 sec
0.1456 0.1387 0.1115 0.1049 0.0948 0.0875 0.0808 0.0775 0.0753 0.0740 0.0731 0.0724 0.0720 0.0716 0.0712 0.0710 

[TRAIN] Epoch[1](7718/114412); Loss: 0.073082; Backpropagation: 0.2906 sec; Batch: 2.1169 sec
0.1342 0.1221 0.0917 0.0836 0.0735 0.0693 0.0660 0.0636 0.0614 0.0602 0.0589 0.0581 0.0573 0.0569 0.0565 0.0562 

[TRAIN] Epoch[1](7719/114412); Loss: 0.089326; Backpropagation: 0.2913 sec; Batch: 2.1206 sec
0.1526 0.1448 0.1164 0.1063 0.0951 0.0865 0.0819 0.0800 0.0770 0.0738 0.0721 0.0704 0.0693 0.0682 0.0677 0.0672 

[TRAIN] Epoch[1](7720/114412); Loss: 0.075124; Backpropagation: 0.2909 sec; Batch: 2.1133 sec
0.1232 0.1185 0.0949 0.0874 0.0818 0.0748 0.0693 0.0667 0.0644 0.0628 0.0617 0.0604 0.0597 0.0592 0.0586 0.0584 

[TRAIN] Epoch[1](7721/114412); Loss: 0.108096; Backpropagation: 0.2929 sec; Batch: 2.1156 sec
0.2255 0.2155 0.1734 0.1594 0.1345 0.1144 0.0965 0.0832 0.0749 0.0709 0.0683 0.0657 0.0644 0.0621 0.0606 0.0602 

[TRAIN] Epoch[1](7722/114412); Loss: 0.080112; Backpropagation: 0.2932 sec; Batch: 2.1141 sec
0.1239 0.1180 0.0976 0.0941 0.0862 0.0791 0.0747 0.0725 0.0700 0.0687 0.0677 0.0667 0.0661 0.0657 0.0654 0.0654 

[TRAIN] Epoch[1](7723/114412); Loss: 0.116163; Backpropagation: 0.2907 sec; Batch: 2.1159 sec
0.2237 0.2133 0.1710 0.1579 0.1352 0.1173 0.1053 0.0962 0.0903 0.0856 0.0819 0.0795 0.0770 0.0762 0.0746 0.0735 

[TRAIN] Epoch[1](7724/114412); Loss: 0.084195; Backpropagation: 0.2910 sec; Batch: 2.1113 sec
0.1503 0.1424 0.1237 0.1097 0.0971 0.0853 0.0784 0.0729 0.0674 0.0642 0.0617 0.0603 0.0593 0.0585 0.0580 0.0577 

[TRAIN] Epoch[1](7725/114412); Loss: 0.094175; Backpropagation: 0.2927 sec; Batch: 2.1217 sec
0.1823 0.1680 0.1281 0.1156 0.0992 0.0871 0.0784 0.0759 0.0755 0.0732 0.0721 0.0717 0.0710 0.0702 0.0695 0.0689 

[TRAIN] Epoch[1](7726/114412); Loss: 0.068190; Backpropagation: 0.2951 sec; Batch: 2.1190 sec
0.1443 0.1348 0.0999 0.0857 0.0698 0.0619 0.0570 0.0539 0.0518 0.0497 0.0484 0.0478 0.0471 0.0467 0.0463 0.0460 

[TRAIN] Epoch[1](7727/114412); Loss: 0.093310; Backpropagation: 0.2951 sec; Batch: 2.1211 sec
0.1554 0.1426 0.1186 0.1102 0.0992 0.0932 0.0874 0.0836 0.0802 0.0778 0.0762 0.0751 0.0742 0.0735 0.0732 0.0727 

[TRAIN] Epoch[1](7728/114412); Loss: 0.083790; Backpropagation: 0.2913 sec; Batch: 2.1132 sec
0.1526 0.1445 0.1149 0.1053 0.0913 0.0804 0.0731 0.0718 0.0685 0.0663 0.0647 0.0634 0.0623 0.0613 0.0604 0.0596 

[TRAIN] Epoch[1](7729/114412); Loss: 0.091143; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1662 0.1556 0.1173 0.1075 0.0932 0.0865 0.0813 0.0781 0.0754 0.0737 0.0724 0.0714 0.0708 0.0700 0.0695 0.0693 

[TRAIN] Epoch[1](7730/114412); Loss: 0.129171; Backpropagation: 0.2909 sec; Batch: 2.1135 sec
0.2381 0.2251 0.1915 0.1802 0.1574 0.1378 0.1228 0.1120 0.1038 0.0972 0.0916 0.0874 0.0848 0.0814 0.0784 0.0772 

[TRAIN] Epoch[1](7731/114412); Loss: 0.100651; Backpropagation: 0.2955 sec; Batch: 2.0830 sec
0.1706 0.1625 0.1308 0.1205 0.1099 0.1016 0.0961 0.0898 0.0853 0.0823 0.0792 0.0777 0.0769 0.0765 0.0757 0.0751 

[TRAIN] Epoch[1](7732/114412); Loss: 0.080831; Backpropagation: 0.2953 sec; Batch: 2.0908 sec
0.1406 0.1331 0.1098 0.1002 0.0880 0.0784 0.0732 0.0692 0.0666 0.0651 0.0635 0.0625 0.0617 0.0611 0.0603 0.0599 

[TRAIN] Epoch[1](7733/114412); Loss: 0.084868; Backpropagation: 0.2904 sec; Batch: 2.0786 sec
0.1468 0.1373 0.1059 0.0962 0.0888 0.0843 0.0791 0.0758 0.0731 0.0706 0.0688 0.0676 0.0668 0.0662 0.0655 0.0651 

[TRAIN] Epoch[1](7734/114412); Loss: 0.105499; Backpropagation: 0.2909 sec; Batch: 2.0766 sec
0.1722 0.1655 0.1416 0.1304 0.1148 0.1055 0.0992 0.0949 0.0906 0.0879 0.0857 0.0838 0.0811 0.0793 0.0781 0.0773 

[TRAIN] Epoch[1](7735/114412); Loss: 0.083956; Backpropagation: 0.2931 sec; Batch: 2.1134 sec
0.1393 0.1324 0.1103 0.0991 0.0910 0.0818 0.0772 0.0736 0.0703 0.0688 0.0678 0.0669 0.0666 0.0662 0.0658 0.0658 

[TRAIN] Epoch[1](7736/114412); Loss: 0.128095; Backpropagation: 0.2924 sec; Batch: 2.1055 sec
0.2224 0.2133 0.1837 0.1735 0.1558 0.1411 0.1282 0.1200 0.1082 0.0987 0.0914 0.0880 0.0849 0.0819 0.0796 0.0786 

[TRAIN] Epoch[1](7737/114412); Loss: 0.075988; Backpropagation: 0.2912 sec; Batch: 2.1134 sec
0.1268 0.1220 0.0986 0.0900 0.0828 0.0756 0.0714 0.0684 0.0652 0.0631 0.0613 0.0596 0.0587 0.0580 0.0573 0.0568 

[TRAIN] Epoch[1](7738/114412); Loss: 0.092704; Backpropagation: 0.2927 sec; Batch: 2.1060 sec
0.1675 0.1579 0.1333 0.1226 0.1073 0.0953 0.0860 0.0797 0.0748 0.0707 0.0682 0.0659 0.0648 0.0639 0.0632 0.0622 

[TRAIN] Epoch[1](7739/114412); Loss: 0.092069; Backpropagation: 0.2909 sec; Batch: 2.1194 sec
0.1656 0.1498 0.1244 0.1111 0.0973 0.0870 0.0816 0.0788 0.0759 0.0743 0.0735 0.0722 0.0714 0.0707 0.0701 0.0695 

[TRAIN] Epoch[1](7740/114412); Loss: 0.073115; Backpropagation: 0.2930 sec; Batch: 2.1161 sec
0.1375 0.1335 0.0975 0.0893 0.0776 0.0687 0.0636 0.0613 0.0584 0.0564 0.0555 0.0548 0.0542 0.0540 0.0538 0.0537 

[TRAIN] Epoch[1](7741/114412); Loss: 0.073925; Backpropagation: 0.2929 sec; Batch: 2.0861 sec
0.1618 0.1571 0.1079 0.0921 0.0748 0.0661 0.0609 0.0576 0.0553 0.0526 0.0513 0.0504 0.0493 0.0487 0.0486 0.0483 

[TRAIN] Epoch[1](7742/114412); Loss: 0.097644; Backpropagation: 0.2930 sec; Batch: 2.1210 sec
0.2228 0.2114 0.1625 0.1408 0.1069 0.0852 0.0765 0.0713 0.0675 0.0642 0.0619 0.0601 0.0587 0.0581 0.0574 0.0570 

[TRAIN] Epoch[1](7743/114412); Loss: 0.090113; Backpropagation: 0.2910 sec; Batch: 2.1149 sec
0.1283 0.1240 0.1106 0.1025 0.0959 0.0892 0.0855 0.0843 0.0818 0.0799 0.0786 0.0774 0.0769 0.0761 0.0756 0.0753 

[TRAIN] Epoch[1](7744/114412); Loss: 0.116212; Backpropagation: 0.2930 sec; Batch: 2.1035 sec
0.2255 0.2103 0.1774 0.1604 0.1353 0.1171 0.1054 0.0967 0.0899 0.0860 0.0822 0.0790 0.0760 0.0741 0.0724 0.0716 

[TRAIN] Epoch[1](7745/114412); Loss: 0.104157; Backpropagation: 0.2914 sec; Batch: 2.1208 sec
0.2084 0.1984 0.1668 0.1523 0.1278 0.1081 0.0942 0.0840 0.0773 0.0732 0.0685 0.0652 0.0630 0.0608 0.0597 0.0589 

[TRAIN] Epoch[1](7746/114412); Loss: 0.064876; Backpropagation: 0.2905 sec; Batch: 2.1139 sec
0.1407 0.1348 0.0839 0.0751 0.0631 0.0575 0.0548 0.0524 0.0498 0.0483 0.0477 0.0467 0.0464 0.0458 0.0456 0.0454 

[TRAIN] Epoch[1](7747/114412); Loss: 0.106058; Backpropagation: 0.2932 sec; Batch: 2.0798 sec
0.2367 0.2223 0.1727 0.1495 0.1207 0.1044 0.0922 0.0826 0.0750 0.0710 0.0684 0.0642 0.0614 0.0600 0.0584 0.0576 

[TRAIN] Epoch[1](7748/114412); Loss: 0.102721; Backpropagation: 0.2904 sec; Batch: 2.1167 sec
0.1746 0.1682 0.1429 0.1349 0.1212 0.1083 0.0981 0.0905 0.0849 0.0804 0.0775 0.0754 0.0734 0.0721 0.0711 0.0701 

[TRAIN] Epoch[1](7749/114412); Loss: 0.093705; Backpropagation: 0.2905 sec; Batch: 2.1144 sec
0.1573 0.1520 0.1315 0.1198 0.1076 0.0954 0.0879 0.0828 0.0785 0.0744 0.0714 0.0700 0.0689 0.0680 0.0672 0.0666 

[TRAIN] Epoch[1](7750/114412); Loss: 0.075062; Backpropagation: 0.2915 sec; Batch: 2.1149 sec
0.1549 0.1344 0.1060 0.0957 0.0829 0.0712 0.0653 0.0615 0.0590 0.0563 0.0544 0.0533 0.0523 0.0517 0.0512 0.0507 

[TRAIN] Epoch[1](7751/114412); Loss: 0.078612; Backpropagation: 0.2913 sec; Batch: 2.1121 sec
0.1687 0.1559 0.1156 0.1055 0.0853 0.0739 0.0677 0.0629 0.0604 0.0568 0.0544 0.0522 0.0507 0.0498 0.0492 0.0489 

[TRAIN] Epoch[1](7752/114412); Loss: 0.091424; Backpropagation: 0.2930 sec; Batch: 2.0793 sec
0.1783 0.1688 0.1345 0.1230 0.1056 0.0930 0.0846 0.0787 0.0730 0.0678 0.0644 0.0616 0.0597 0.0579 0.0562 0.0556 

[TRAIN] Epoch[1](7753/114412); Loss: 0.121704; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.2421 0.2298 0.1954 0.1759 0.1428 0.1200 0.1045 0.0946 0.0881 0.0845 0.0817 0.0802 0.0785 0.0773 0.0763 0.0757 

[TRAIN] Epoch[1](7754/114412); Loss: 0.069310; Backpropagation: 0.2907 sec; Batch: 2.0763 sec
0.1175 0.1135 0.0904 0.0813 0.0735 0.0659 0.0625 0.0610 0.0587 0.0573 0.0559 0.0551 0.0545 0.0541 0.0540 0.0538 

[TRAIN] Epoch[1](7755/114412); Loss: 0.094207; Backpropagation: 0.2930 sec; Batch: 2.1204 sec
0.1760 0.1606 0.1356 0.1247 0.1075 0.0951 0.0855 0.0801 0.0748 0.0711 0.0690 0.0676 0.0663 0.0652 0.0645 0.0638 

[TRAIN] Epoch[1](7756/114412); Loss: 0.085399; Backpropagation: 0.2928 sec; Batch: 2.1041 sec
0.1374 0.1286 0.1009 0.0913 0.0861 0.0796 0.0778 0.0776 0.0760 0.0747 0.0738 0.0732 0.0729 0.0724 0.0722 0.0721 

[TRAIN] Epoch[1](7757/114412); Loss: 0.085655; Backpropagation: 0.2911 sec; Batch: 2.1126 sec
0.1437 0.1326 0.1080 0.0949 0.0862 0.0818 0.0783 0.0766 0.0748 0.0730 0.0718 0.0711 0.0702 0.0695 0.0692 0.0686 

[TRAIN] Epoch[1](7758/114412); Loss: 0.085932; Backpropagation: 0.2911 sec; Batch: 2.1148 sec
0.1483 0.1411 0.1102 0.1017 0.0905 0.0830 0.0778 0.0748 0.0724 0.0706 0.0694 0.0685 0.0674 0.0667 0.0664 0.0660 

[TRAIN] Epoch[1](7759/114412); Loss: 0.129598; Backpropagation: 0.2911 sec; Batch: 2.1063 sec
0.2478 0.2307 0.1978 0.1851 0.1577 0.1386 0.1235 0.1096 0.0998 0.0927 0.0880 0.0845 0.0819 0.0801 0.0787 0.0770 

[TRAIN] Epoch[1](7760/114412); Loss: 0.078724; Backpropagation: 0.2929 sec; Batch: 2.1169 sec
0.1452 0.1360 0.1042 0.0946 0.0830 0.0760 0.0694 0.0665 0.0650 0.0625 0.0618 0.0609 0.0597 0.0588 0.0582 0.0579 

[TRAIN] Epoch[1](7761/114412); Loss: 0.084081; Backpropagation: 0.2934 sec; Batch: 2.1129 sec
0.1536 0.1495 0.1123 0.1048 0.0934 0.0841 0.0778 0.0730 0.0683 0.0653 0.0632 0.0612 0.0603 0.0598 0.0595 0.0593 

[TRAIN] Epoch[1](7762/114412); Loss: 0.082695; Backpropagation: 0.2915 sec; Batch: 2.1161 sec
0.1785 0.1671 0.1238 0.1075 0.0886 0.0749 0.0673 0.0631 0.0603 0.0584 0.0570 0.0563 0.0557 0.0553 0.0548 0.0544 

[TRAIN] Epoch[1](7763/114412); Loss: 0.107513; Backpropagation: 0.2911 sec; Batch: 2.1129 sec
0.1909 0.1802 0.1463 0.1324 0.1155 0.1065 0.0961 0.0909 0.0882 0.0858 0.0846 0.0828 0.0814 0.0805 0.0794 0.0787 

[TRAIN] Epoch[1](7764/114412); Loss: 0.103295; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1758 0.1589 0.1319 0.1196 0.1057 0.0995 0.0952 0.0923 0.0899 0.0873 0.0856 0.0841 0.0827 0.0819 0.0814 0.0810 

[TRAIN] Epoch[1](7765/114412); Loss: 0.077571; Backpropagation: 0.2909 sec; Batch: 2.0780 sec
0.1408 0.1310 0.1073 0.0994 0.0852 0.0778 0.0700 0.0664 0.0630 0.0609 0.0592 0.0579 0.0566 0.0558 0.0552 0.0547 

[TRAIN] Epoch[1](7766/114412); Loss: 0.103547; Backpropagation: 0.2906 sec; Batch: 2.1199 sec
0.1684 0.1644 0.1399 0.1326 0.1188 0.1073 0.1001 0.0939 0.0887 0.0847 0.0816 0.0789 0.0764 0.0751 0.0736 0.0724 

[TRAIN] Epoch[1](7767/114412); Loss: 0.084500; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1397 0.1314 0.1091 0.1009 0.0902 0.0834 0.0782 0.0750 0.0722 0.0700 0.0689 0.0676 0.0668 0.0664 0.0662 0.0659 

[TRAIN] Epoch[1](7768/114412); Loss: 0.095085; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1985 0.1857 0.1493 0.1318 0.1068 0.0900 0.0778 0.0722 0.0684 0.0665 0.0654 0.0643 0.0628 0.0616 0.0605 0.0598 

[TRAIN] Epoch[1](7769/114412); Loss: 0.091832; Backpropagation: 0.2902 sec; Batch: 2.0819 sec
0.1944 0.1779 0.1287 0.1204 0.0956 0.0863 0.0787 0.0730 0.0701 0.0677 0.0653 0.0642 0.0628 0.0620 0.0614 0.0608 

[TRAIN] Epoch[1](7770/114412); Loss: 0.071780; Backpropagation: 0.2931 sec; Batch: 2.0785 sec
0.1374 0.1316 0.1037 0.0930 0.0779 0.0677 0.0620 0.0588 0.0562 0.0543 0.0529 0.0519 0.0510 0.0504 0.0500 0.0496 

[TRAIN] Epoch[1](7771/114412); Loss: 0.112679; Backpropagation: 0.2931 sec; Batch: 2.1176 sec
0.2107 0.1924 0.1612 0.1483 0.1241 0.1107 0.1001 0.0929 0.0890 0.0863 0.0846 0.0828 0.0815 0.0804 0.0794 0.0783 

[TRAIN] Epoch[1](7772/114412); Loss: 0.101084; Backpropagation: 0.2948 sec; Batch: 2.1227 sec
0.1712 0.1603 0.1321 0.1218 0.1119 0.1016 0.0942 0.0903 0.0860 0.0835 0.0806 0.0784 0.0773 0.0765 0.0760 0.0757 

[TRAIN] Epoch[1](7773/114412); Loss: 0.104225; Backpropagation: 0.2929 sec; Batch: 2.1160 sec
0.1415 0.1384 0.1248 0.1200 0.1122 0.1067 0.1014 0.0984 0.0954 0.0936 0.0917 0.0903 0.0893 0.0885 0.0879 0.0876 

[TRAIN] Epoch[1](7774/114412); Loss: 0.083420; Backpropagation: 0.2906 sec; Batch: 2.0844 sec
0.1442 0.1354 0.1134 0.1035 0.0899 0.0797 0.0750 0.0720 0.0700 0.0680 0.0665 0.0654 0.0643 0.0632 0.0626 0.0619 

[TRAIN] Epoch[1](7775/114412); Loss: 0.122705; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.2291 0.2133 0.1813 0.1668 0.1434 0.1221 0.1099 0.1002 0.0946 0.0908 0.0891 0.0870 0.0854 0.0846 0.0834 0.0822 

[TRAIN] Epoch[1](7776/114412); Loss: 0.099933; Backpropagation: 0.2913 sec; Batch: 2.1146 sec
0.1544 0.1453 0.1267 0.1185 0.1052 0.0987 0.0931 0.0909 0.0882 0.0857 0.0841 0.0831 0.0822 0.0815 0.0808 0.0805 

[TRAIN] Epoch[1](7777/114412); Loss: 0.090839; Backpropagation: 0.2912 sec; Batch: 2.1161 sec
0.1497 0.1396 0.1155 0.1057 0.0947 0.0878 0.0836 0.0813 0.0791 0.0769 0.0756 0.0742 0.0735 0.0728 0.0720 0.0714 

[TRAIN] Epoch[1](7778/114412); Loss: 0.072554; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1159 0.1115 0.0914 0.0849 0.0753 0.0711 0.0674 0.0655 0.0630 0.0615 0.0607 0.0597 0.0589 0.0584 0.0580 0.0578 

[TRAIN] Epoch[1](7779/114412); Loss: 0.102800; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1651 0.1539 0.1305 0.1214 0.1101 0.1026 0.0973 0.0939 0.0892 0.0866 0.0847 0.0831 0.0823 0.0819 0.0813 0.0809 

[TRAIN] Epoch[1](7780/114412); Loss: 0.104973; Backpropagation: 0.2906 sec; Batch: 2.1262 sec
0.1886 0.1724 0.1431 0.1281 0.1128 0.1032 0.0954 0.0932 0.0887 0.0839 0.0825 0.0804 0.0784 0.0774 0.0764 0.0752 

[TRAIN] Epoch[1](7781/114412); Loss: 0.076249; Backpropagation: 0.2915 sec; Batch: 2.0780 sec
0.1555 0.1477 0.1067 0.0965 0.0803 0.0701 0.0638 0.0600 0.0576 0.0566 0.0558 0.0550 0.0544 0.0536 0.0532 0.0529 

[TRAIN] Epoch[1](7782/114412); Loss: 0.110107; Backpropagation: 0.2954 sec; Batch: 2.1168 sec
0.2106 0.2000 0.1711 0.1590 0.1353 0.1176 0.1003 0.0881 0.0808 0.0763 0.0745 0.0729 0.0704 0.0692 0.0682 0.0673 

[TRAIN] Epoch[1](7783/114412); Loss: 0.077243; Backpropagation: 0.2932 sec; Batch: 2.1138 sec
0.1457 0.1415 0.1084 0.0930 0.0775 0.0711 0.0663 0.0645 0.0623 0.0602 0.0595 0.0584 0.0574 0.0570 0.0567 0.0564 

[TRAIN] Epoch[1](7784/114412); Loss: 0.073673; Backpropagation: 0.2934 sec; Batch: 2.1193 sec
0.1301 0.1254 0.1005 0.0872 0.0769 0.0705 0.0660 0.0635 0.0608 0.0596 0.0583 0.0573 0.0566 0.0558 0.0553 0.0549 

[TRAIN] Epoch[1](7785/114412); Loss: 0.118999; Backpropagation: 0.2932 sec; Batch: 2.1173 sec
0.2390 0.2270 0.1875 0.1732 0.1481 0.1279 0.1109 0.0961 0.0855 0.0797 0.0760 0.0737 0.0719 0.0702 0.0692 0.0682 

[TRAIN] Epoch[1](7786/114412); Loss: 0.087215; Backpropagation: 0.2952 sec; Batch: 2.1223 sec
0.1355 0.1322 0.1135 0.1018 0.0888 0.0854 0.0803 0.0779 0.0757 0.0744 0.0733 0.0725 0.0718 0.0711 0.0708 0.0703 

[TRAIN] Epoch[1](7787/114412); Loss: 0.099615; Backpropagation: 0.2956 sec; Batch: 2.0828 sec
0.1701 0.1640 0.1320 0.1206 0.1054 0.0962 0.0904 0.0868 0.0833 0.0814 0.0797 0.0782 0.0774 0.0768 0.0762 0.0755 

[TRAIN] Epoch[1](7788/114412); Loss: 0.116497; Backpropagation: 0.2929 sec; Batch: 2.1198 sec
0.1749 0.1697 0.1423 0.1334 0.1238 0.1144 0.1099 0.1059 0.1027 0.1011 0.0997 0.0987 0.0983 0.0972 0.0964 0.0956 

[TRAIN] Epoch[1](7789/114412); Loss: 0.079366; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1778 0.1678 0.1223 0.1020 0.0790 0.0692 0.0629 0.0601 0.0577 0.0561 0.0547 0.0535 0.0527 0.0519 0.0513 0.0510 

[TRAIN] Epoch[1](7790/114412); Loss: 0.090938; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1730 0.1669 0.1315 0.1237 0.1027 0.0898 0.0808 0.0735 0.0705 0.0684 0.0672 0.0650 0.0629 0.0613 0.0594 0.0584 

[TRAIN] Epoch[1](7791/114412); Loss: 0.077075; Backpropagation: 0.2917 sec; Batch: 2.1157 sec
0.1543 0.1407 0.1088 0.1013 0.0840 0.0758 0.0668 0.0635 0.0592 0.0576 0.0561 0.0546 0.0536 0.0528 0.0524 0.0517 

[TRAIN] Epoch[1](7792/114412); Loss: 0.093946; Backpropagation: 0.2949 sec; Batch: 2.1200 sec
0.2036 0.1856 0.1517 0.1390 0.1160 0.0983 0.0843 0.0730 0.0668 0.0627 0.0594 0.0566 0.0538 0.0516 0.0507 0.0500 

[TRAIN] Epoch[1](7793/114412); Loss: 0.119763; Backpropagation: 0.2932 sec; Batch: 2.1155 sec
0.2200 0.1999 0.1691 0.1579 0.1322 0.1180 0.1060 0.0999 0.0954 0.0927 0.0906 0.0886 0.0876 0.0867 0.0860 0.0857 

[TRAIN] Epoch[1](7794/114412); Loss: 0.090493; Backpropagation: 0.2908 sec; Batch: 2.1185 sec
0.1496 0.1381 0.1160 0.1051 0.0956 0.0880 0.0829 0.0792 0.0771 0.0752 0.0748 0.0744 0.0736 0.0732 0.0728 0.0722 

[TRAIN] Epoch[1](7795/114412); Loss: 0.083780; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.1482 0.1362 0.1112 0.1009 0.0882 0.0809 0.0763 0.0724 0.0704 0.0687 0.0668 0.0656 0.0648 0.0640 0.0632 0.0628 

[TRAIN] Epoch[1](7796/114412); Loss: 0.111260; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1873 0.1718 0.1486 0.1390 0.1250 0.1132 0.1048 0.0990 0.0945 0.0913 0.0886 0.0860 0.0843 0.0831 0.0820 0.0815 

[TRAIN] Epoch[1](7797/114412); Loss: 0.091717; Backpropagation: 0.2930 sec; Batch: 2.1187 sec
0.1682 0.1595 0.1312 0.1180 0.0977 0.0872 0.0810 0.0777 0.0736 0.0712 0.0695 0.0681 0.0672 0.0664 0.0655 0.0652 

[TRAIN] Epoch[1](7798/114412); Loss: 0.106076; Backpropagation: 0.2924 sec; Batch: 2.0786 sec
0.2067 0.1940 0.1555 0.1508 0.1335 0.1201 0.1081 0.0947 0.0837 0.0758 0.0713 0.0665 0.0626 0.0604 0.0581 0.0554 

[TRAIN] Epoch[1](7799/114412); Loss: 0.078782; Backpropagation: 0.2912 sec; Batch: 2.1305 sec
0.1520 0.1413 0.1045 0.0921 0.0800 0.0731 0.0679 0.0654 0.0642 0.0622 0.0612 0.0605 0.0595 0.0589 0.0588 0.0589 

[TRAIN] Epoch[1](7800/114412); Loss: 0.087384; Backpropagation: 0.2953 sec; Batch: 2.1225 sec
0.1571 0.1522 0.1222 0.1155 0.0984 0.0878 0.0790 0.0738 0.0701 0.0671 0.0649 0.0634 0.0623 0.0618 0.0614 0.0611 

[TRAIN] Epoch[1](7801/114412); Loss: 0.086758; Backpropagation: 0.2914 sec; Batch: 2.1197 sec
0.1592 0.1442 0.1183 0.1051 0.0940 0.0841 0.0786 0.0748 0.0716 0.0694 0.0678 0.0663 0.0649 0.0639 0.0633 0.0628 

[TRAIN] Epoch[1](7802/114412); Loss: 0.109349; Backpropagation: 0.2917 sec; Batch: 2.1141 sec
0.2396 0.2241 0.1779 0.1613 0.1291 0.1109 0.0949 0.0826 0.0742 0.0704 0.0682 0.0660 0.0644 0.0632 0.0619 0.0610 

[TRAIN] Epoch[1](7803/114412); Loss: 0.097659; Backpropagation: 0.2914 sec; Batch: 2.1158 sec
0.1497 0.1391 0.1162 0.1084 0.1009 0.0952 0.0914 0.0897 0.0875 0.0863 0.0850 0.0840 0.0832 0.0824 0.0819 0.0815 

[TRAIN] Epoch[1](7804/114412); Loss: 0.081414; Backpropagation: 0.2907 sec; Batch: 2.1249 sec
0.1698 0.1588 0.1177 0.1004 0.0850 0.0765 0.0700 0.0647 0.0634 0.0599 0.0581 0.0571 0.0561 0.0556 0.0551 0.0545 

[TRAIN] Epoch[1](7805/114412); Loss: 0.073478; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1358 0.1216 0.0951 0.0851 0.0747 0.0685 0.0645 0.0631 0.0613 0.0601 0.0589 0.0582 0.0578 0.0574 0.0569 0.0567 

[TRAIN] Epoch[1](7806/114412); Loss: 0.114061; Backpropagation: 0.2929 sec; Batch: 2.0989 sec
0.1828 0.1738 0.1535 0.1422 0.1287 0.1210 0.1117 0.1055 0.0990 0.0943 0.0911 0.0878 0.0858 0.0843 0.0823 0.0813 

[TRAIN] Epoch[1](7807/114412); Loss: 0.064771; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1274 0.1135 0.0885 0.0738 0.0675 0.0610 0.0568 0.0551 0.0525 0.0514 0.0502 0.0489 0.0482 0.0475 0.0472 0.0468 

[TRAIN] Epoch[1](7808/114412); Loss: 0.085877; Backpropagation: 0.2914 sec; Batch: 2.1135 sec
0.1257 0.1225 0.1003 0.0950 0.0884 0.0836 0.0808 0.0801 0.0782 0.0766 0.0755 0.0743 0.0738 0.0734 0.0730 0.0727 

[TRAIN] Epoch[1](7809/114412); Loss: 0.087749; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1685 0.1609 0.1180 0.1058 0.0927 0.0824 0.0759 0.0726 0.0697 0.0683 0.0671 0.0657 0.0648 0.0643 0.0638 0.0635 

[TRAIN] Epoch[1](7810/114412); Loss: 0.117918; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.2034 0.1928 0.1615 0.1498 0.1310 0.1189 0.1110 0.1028 0.0985 0.0954 0.0917 0.0900 0.0876 0.0854 0.0840 0.0829 

[TRAIN] Epoch[1](7811/114412); Loss: 0.125466; Backpropagation: 0.2911 sec; Batch: 2.1113 sec
0.2017 0.1895 0.1655 0.1554 0.1376 0.1256 0.1177 0.1114 0.1068 0.1047 0.1020 0.1002 0.0989 0.0976 0.0967 0.0958 

[TRAIN] Epoch[1](7812/114412); Loss: 0.108287; Backpropagation: 0.2909 sec; Batch: 2.1012 sec
0.1946 0.1866 0.1598 0.1481 0.1249 0.1078 0.0973 0.0914 0.0863 0.0829 0.0799 0.0777 0.0758 0.0741 0.0732 0.0723 

[TRAIN] Epoch[1](7813/114412); Loss: 0.093351; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1494 0.1339 0.1144 0.1015 0.0961 0.0910 0.0868 0.0844 0.0821 0.0807 0.0802 0.0795 0.0790 0.0785 0.0781 0.0778 

[TRAIN] Epoch[1](7814/114412); Loss: 0.104473; Backpropagation: 0.2907 sec; Batch: 2.0813 sec
0.1972 0.1902 0.1567 0.1456 0.1252 0.1095 0.0965 0.0870 0.0797 0.0749 0.0722 0.0705 0.0684 0.0670 0.0658 0.0651 

[TRAIN] Epoch[1](7815/114412); Loss: 0.081031; Backpropagation: 0.2908 sec; Batch: 2.0783 sec
0.1345 0.1282 0.1035 0.0972 0.0868 0.0784 0.0744 0.0726 0.0693 0.0673 0.0659 0.0648 0.0642 0.0635 0.0630 0.0627 

[TRAIN] Epoch[1](7816/114412); Loss: 0.094083; Backpropagation: 0.2906 sec; Batch: 2.1158 sec
0.1525 0.1410 0.1176 0.1078 0.0959 0.0912 0.0878 0.0848 0.0831 0.0806 0.0792 0.0783 0.0773 0.0765 0.0760 0.0758 

[TRAIN] Epoch[1](7817/114412); Loss: 0.094359; Backpropagation: 0.2909 sec; Batch: 2.1189 sec
0.1908 0.1812 0.1418 0.1301 0.1059 0.0882 0.0767 0.0739 0.0708 0.0685 0.0664 0.0649 0.0636 0.0630 0.0621 0.0617 

[TRAIN] Epoch[1](7818/114412); Loss: 0.103211; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1738 0.1636 0.1391 0.1277 0.1125 0.1010 0.0938 0.0895 0.0870 0.0841 0.0828 0.0813 0.0803 0.0790 0.0781 0.0776 

[TRAIN] Epoch[1](7819/114412); Loss: 0.080112; Backpropagation: 0.2912 sec; Batch: 2.0821 sec
0.1612 0.1446 0.1145 0.0983 0.0813 0.0737 0.0702 0.0663 0.0628 0.0610 0.0601 0.0592 0.0581 0.0572 0.0568 0.0564 

[TRAIN] Epoch[1](7820/114412); Loss: 0.094909; Backpropagation: 0.2912 sec; Batch: 2.1050 sec
0.1660 0.1585 0.1314 0.1213 0.1048 0.0938 0.0890 0.0843 0.0785 0.0762 0.0735 0.0712 0.0695 0.0678 0.0667 0.0659 

[TRAIN] Epoch[1](7821/114412); Loss: 0.067701; Backpropagation: 0.2949 sec; Batch: 2.1244 sec
0.1394 0.1300 0.0976 0.0853 0.0716 0.0639 0.0573 0.0553 0.0524 0.0507 0.0494 0.0479 0.0470 0.0458 0.0451 0.0446 

[TRAIN] Epoch[1](7822/114412); Loss: 0.130585; Backpropagation: 0.2911 sec; Batch: 2.1241 sec
0.2432 0.2319 0.1988 0.1876 0.1638 0.1477 0.1293 0.1130 0.1011 0.0919 0.0870 0.0825 0.0801 0.0786 0.0770 0.0759 

[TRAIN] Epoch[1](7823/114412); Loss: 0.090418; Backpropagation: 0.2912 sec; Batch: 2.1268 sec
0.1407 0.1371 0.1144 0.1081 0.0968 0.0894 0.0838 0.0805 0.0782 0.0768 0.0756 0.0744 0.0733 0.0728 0.0725 0.0723 

[TRAIN] Epoch[1](7824/114412); Loss: 0.097500; Backpropagation: 0.2951 sec; Batch: 2.1013 sec
0.1674 0.1568 0.1276 0.1165 0.1011 0.0932 0.0883 0.0853 0.0821 0.0802 0.0792 0.0776 0.0770 0.0764 0.0758 0.0755 

[TRAIN] Epoch[1](7825/114412); Loss: 0.076237; Backpropagation: 0.2952 sec; Batch: 2.1177 sec
0.1484 0.1328 0.1029 0.0906 0.0785 0.0712 0.0664 0.0648 0.0623 0.0604 0.0589 0.0576 0.0569 0.0564 0.0559 0.0556 

[TRAIN] Epoch[1](7826/114412); Loss: 0.077670; Backpropagation: 0.2957 sec; Batch: 2.1252 sec
0.1282 0.1232 0.1076 0.0959 0.0829 0.0769 0.0699 0.0667 0.0649 0.0634 0.0624 0.0616 0.0607 0.0600 0.0594 0.0589 

[TRAIN] Epoch[1](7827/114412); Loss: 0.118390; Backpropagation: 0.2929 sec; Batch: 2.1147 sec
0.2084 0.1909 0.1571 0.1450 0.1277 0.1167 0.1078 0.1034 0.0994 0.0965 0.0939 0.0917 0.0905 0.0893 0.0884 0.0876 

[TRAIN] Epoch[1](7828/114412); Loss: 0.084411; Backpropagation: 0.2915 sec; Batch: 2.1160 sec
0.1341 0.1260 0.1013 0.0953 0.0867 0.0825 0.0790 0.0763 0.0746 0.0730 0.0719 0.0710 0.0704 0.0698 0.0695 0.0693 

[TRAIN] Epoch[1](7829/114412); Loss: 0.070020; Backpropagation: 0.2911 sec; Batch: 2.1133 sec
0.1347 0.1277 0.0953 0.0866 0.0753 0.0665 0.0624 0.0590 0.0564 0.0539 0.0522 0.0510 0.0504 0.0497 0.0496 0.0494 

[TRAIN] Epoch[1](7830/114412); Loss: 0.106666; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1422 0.1353 0.1317 0.1239 0.1158 0.1098 0.1038 0.1009 0.0980 0.0961 0.0950 0.0929 0.0914 0.0907 0.0899 0.0893 

[TRAIN] Epoch[1](7831/114412); Loss: 0.096119; Backpropagation: 0.2913 sec; Batch: 2.1142 sec
0.1739 0.1537 0.1298 0.1174 0.1000 0.0916 0.0863 0.0829 0.0806 0.0784 0.0766 0.0751 0.0741 0.0731 0.0724 0.0719 

[TRAIN] Epoch[1](7832/114412); Loss: 0.077433; Backpropagation: 0.2910 sec; Batch: 2.1124 sec
0.1154 0.1097 0.1002 0.0927 0.0845 0.0780 0.0733 0.0708 0.0683 0.0666 0.0651 0.0641 0.0633 0.0627 0.0623 0.0619 

[TRAIN] Epoch[1](7833/114412); Loss: 0.080792; Backpropagation: 0.2953 sec; Batch: 2.1183 sec
0.1501 0.1340 0.1096 0.0986 0.0847 0.0763 0.0711 0.0693 0.0669 0.0648 0.0634 0.0621 0.0612 0.0607 0.0601 0.0596 

[TRAIN] Epoch[1](7834/114412); Loss: 0.104723; Backpropagation: 0.2948 sec; Batch: 2.1164 sec
0.1954 0.1829 0.1565 0.1471 0.1233 0.1086 0.0940 0.0855 0.0813 0.0765 0.0740 0.0727 0.0708 0.0699 0.0690 0.0679 

[TRAIN] Epoch[1](7835/114412); Loss: 0.098218; Backpropagation: 0.2928 sec; Batch: 2.1201 sec
0.1800 0.1648 0.1448 0.1353 0.1109 0.0958 0.0865 0.0819 0.0790 0.0758 0.0734 0.0712 0.0696 0.0684 0.0675 0.0666 

[TRAIN] Epoch[1](7836/114412); Loss: 0.103606; Backpropagation: 0.2909 sec; Batch: 2.1200 sec
0.2038 0.1918 0.1507 0.1340 0.1150 0.1002 0.0915 0.0850 0.0796 0.0770 0.0747 0.0730 0.0718 0.0706 0.0698 0.0692 

[TRAIN] Epoch[1](7837/114412); Loss: 0.086429; Backpropagation: 0.2915 sec; Batch: 2.1178 sec
0.1449 0.1344 0.1129 0.1028 0.0927 0.0844 0.0795 0.0775 0.0739 0.0720 0.0703 0.0690 0.0681 0.0674 0.0668 0.0662 

[TRAIN] Epoch[1](7838/114412); Loss: 0.080520; Backpropagation: 0.2919 sec; Batch: 2.3924 sec
0.1581 0.1484 0.1117 0.1025 0.0852 0.0762 0.0689 0.0658 0.0641 0.0617 0.0599 0.0586 0.0578 0.0570 0.0564 0.0561 

[TRAIN] Epoch[1](7839/114412); Loss: 0.069270; Backpropagation: 0.2926 sec; Batch: 2.1215 sec
0.1461 0.1311 0.0998 0.0887 0.0689 0.0621 0.0585 0.0561 0.0535 0.0521 0.0506 0.0498 0.0488 0.0479 0.0473 0.0469 

[TRAIN] Epoch[1](7840/114412); Loss: 0.090226; Backpropagation: 0.2960 sec; Batch: 2.1230 sec
0.1500 0.1430 0.1141 0.1081 0.0965 0.0880 0.0834 0.0794 0.0774 0.0751 0.0735 0.0722 0.0716 0.0711 0.0703 0.0701 

[TRAIN] Epoch[1](7841/114412); Loss: 0.072215; Backpropagation: 0.2955 sec; Batch: 2.0829 sec
0.1189 0.1125 0.0936 0.0832 0.0750 0.0691 0.0666 0.0652 0.0621 0.0605 0.0594 0.0586 0.0581 0.0578 0.0575 0.0574 

[TRAIN] Epoch[1](7842/114412); Loss: 0.072817; Backpropagation: 0.2914 sec; Batch: 2.1200 sec
0.1185 0.1128 0.0993 0.0915 0.0806 0.0733 0.0682 0.0652 0.0615 0.0598 0.0580 0.0567 0.0557 0.0550 0.0547 0.0542 

[TRAIN] Epoch[1](7843/114412); Loss: 0.113083; Backpropagation: 0.2927 sec; Batch: 2.1218 sec
0.2000 0.1874 0.1610 0.1500 0.1258 0.1097 0.1000 0.0954 0.0916 0.0890 0.0870 0.0848 0.0834 0.0825 0.0813 0.0806 

[TRAIN] Epoch[1](7844/114412); Loss: 0.097505; Backpropagation: 0.2930 sec; Batch: 2.1164 sec
0.1789 0.1662 0.1340 0.1225 0.1041 0.0936 0.0863 0.0827 0.0799 0.0770 0.0753 0.0738 0.0724 0.0717 0.0711 0.0707 

[TRAIN] Epoch[1](7845/114412); Loss: 0.089124; Backpropagation: 0.2915 sec; Batch: 2.1192 sec
0.1734 0.1626 0.1329 0.1206 0.1023 0.0896 0.0803 0.0729 0.0687 0.0655 0.0631 0.0608 0.0595 0.0585 0.0579 0.0575 

[TRAIN] Epoch[1](7846/114412); Loss: 0.095419; Backpropagation: 0.2909 sec; Batch: 2.1202 sec
0.1567 0.1510 0.1232 0.1149 0.1025 0.0922 0.0871 0.0837 0.0806 0.0794 0.0781 0.0767 0.0757 0.0754 0.0748 0.0747 

[TRAIN] Epoch[1](7847/114412); Loss: 0.086822; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1484 0.1437 0.1168 0.1046 0.0932 0.0842 0.0786 0.0762 0.0726 0.0707 0.0694 0.0680 0.0666 0.0658 0.0653 0.0651 

[TRAIN] Epoch[1](7848/114412); Loss: 0.097883; Backpropagation: 0.2926 sec; Batch: 2.1197 sec
0.1656 0.1586 0.1358 0.1250 0.1069 0.0958 0.0882 0.0835 0.0809 0.0786 0.0768 0.0758 0.0746 0.0737 0.0733 0.0729 

[TRAIN] Epoch[1](7849/114412); Loss: 0.074025; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1519 0.1390 0.1032 0.0904 0.0792 0.0703 0.0650 0.0616 0.0583 0.0552 0.0537 0.0528 0.0517 0.0512 0.0507 0.0502 

[TRAIN] Epoch[1](7850/114412); Loss: 0.134234; Backpropagation: 0.2911 sec; Batch: 2.1209 sec
0.2446 0.2299 0.2031 0.1892 0.1660 0.1489 0.1322 0.1190 0.1082 0.0992 0.0935 0.0892 0.0855 0.0826 0.0795 0.0771 

[TRAIN] Epoch[1](7851/114412); Loss: 0.075782; Backpropagation: 0.2914 sec; Batch: 2.1222 sec
0.1554 0.1450 0.1089 0.0978 0.0780 0.0694 0.0633 0.0604 0.0583 0.0564 0.0548 0.0540 0.0534 0.0529 0.0525 0.0520 

[TRAIN] Epoch[1](7852/114412); Loss: 0.102865; Backpropagation: 0.2911 sec; Batch: 2.1133 sec
0.2094 0.1970 0.1584 0.1406 0.1157 0.0962 0.0856 0.0801 0.0757 0.0731 0.0716 0.0696 0.0689 0.0682 0.0679 0.0677 

[TRAIN] Epoch[1](7853/114412); Loss: 0.094539; Backpropagation: 0.2950 sec; Batch: 2.1366 sec
0.1851 0.1764 0.1392 0.1222 0.1014 0.0903 0.0819 0.0787 0.0736 0.0710 0.0692 0.0668 0.0655 0.0646 0.0637 0.0629 

[TRAIN] Epoch[1](7854/114412); Loss: 0.106346; Backpropagation: 0.2913 sec; Batch: 2.1140 sec
0.1695 0.1643 0.1442 0.1312 0.1185 0.1052 0.0971 0.0931 0.0894 0.0875 0.0866 0.0846 0.0835 0.0830 0.0822 0.0816 

[TRAIN] Epoch[1](7855/114412); Loss: 0.081757; Backpropagation: 0.2906 sec; Batch: 2.1084 sec
0.2077 0.1804 0.1090 0.0909 0.0813 0.0729 0.0665 0.0622 0.0588 0.0576 0.0557 0.0546 0.0536 0.0528 0.0522 0.0519 

[TRAIN] Epoch[1](7856/114412); Loss: 0.088439; Backpropagation: 0.2909 sec; Batch: 2.0776 sec
0.1320 0.1279 0.1121 0.1052 0.0955 0.0881 0.0833 0.0805 0.0780 0.0763 0.0748 0.0739 0.0729 0.0720 0.0714 0.0711 

[TRAIN] Epoch[1](7857/114412); Loss: 0.095683; Backpropagation: 0.2907 sec; Batch: 2.1137 sec
0.1475 0.1371 0.1169 0.1104 0.1012 0.0963 0.0914 0.0884 0.0853 0.0830 0.0817 0.0802 0.0790 0.0782 0.0775 0.0768 

[TRAIN] Epoch[1](7858/114412); Loss: 0.090167; Backpropagation: 0.2954 sec; Batch: 2.1233 sec
0.1877 0.1836 0.1415 0.1271 0.1025 0.0882 0.0769 0.0697 0.0638 0.0617 0.0602 0.0581 0.0567 0.0554 0.0549 0.0549 

[TRAIN] Epoch[1](7859/114412); Loss: 0.119245; Backpropagation: 0.2911 sec; Batch: 2.4679 sec
0.2785 0.2570 0.1975 0.1760 0.1390 0.1192 0.1035 0.0922 0.0835 0.0768 0.0727 0.0674 0.0645 0.0620 0.0598 0.0583 

[TRAIN] Epoch[1](7860/114412); Loss: 0.067620; Backpropagation: 0.2931 sec; Batch: 2.1340 sec
0.1375 0.1279 0.0959 0.0862 0.0703 0.0629 0.0587 0.0552 0.0523 0.0507 0.0495 0.0482 0.0473 0.0468 0.0464 0.0461 

[TRAIN] Epoch[1](7861/114412); Loss: 0.085518; Backpropagation: 0.2953 sec; Batch: 2.1258 sec
0.1488 0.1442 0.1103 0.0992 0.0873 0.0795 0.0754 0.0738 0.0715 0.0704 0.0694 0.0684 0.0679 0.0676 0.0673 0.0673 

[TRAIN] Epoch[1](7862/114412); Loss: 0.084901; Backpropagation: 0.2931 sec; Batch: 2.1192 sec
0.1319 0.1232 0.1062 0.0972 0.0895 0.0846 0.0809 0.0769 0.0749 0.0732 0.0719 0.0709 0.0702 0.0697 0.0689 0.0684 

[TRAIN] Epoch[1](7863/114412); Loss: 0.066281; Backpropagation: 0.2910 sec; Batch: 2.0774 sec
0.1318 0.1225 0.0949 0.0835 0.0683 0.0614 0.0574 0.0544 0.0520 0.0508 0.0494 0.0480 0.0471 0.0467 0.0463 0.0459 

[TRAIN] Epoch[1](7864/114412); Loss: 0.083111; Backpropagation: 0.2905 sec; Batch: 2.1144 sec
0.1317 0.1237 0.0999 0.0927 0.0876 0.0804 0.0772 0.0755 0.0724 0.0715 0.0704 0.0701 0.0696 0.0690 0.0690 0.0690 

[TRAIN] Epoch[1](7865/114412); Loss: 0.062229; Backpropagation: 0.2910 sec; Batch: 2.0775 sec
0.1465 0.1444 0.0884 0.0766 0.0623 0.0555 0.0499 0.0474 0.0446 0.0427 0.0414 0.0401 0.0396 0.0392 0.0388 0.0384 

[TRAIN] Epoch[1](7866/114412); Loss: 0.093123; Backpropagation: 0.2933 sec; Batch: 2.1173 sec
0.1626 0.1542 0.1310 0.1181 0.1015 0.0913 0.0838 0.0792 0.0770 0.0743 0.0723 0.0708 0.0696 0.0685 0.0681 0.0677 

[TRAIN] Epoch[1](7867/114412); Loss: 0.092639; Backpropagation: 0.2914 sec; Batch: 2.1157 sec
0.1674 0.1516 0.1246 0.1094 0.0961 0.0892 0.0846 0.0817 0.0789 0.0765 0.0741 0.0718 0.0705 0.0695 0.0686 0.0678 

[TRAIN] Epoch[1](7868/114412); Loss: 0.091799; Backpropagation: 0.2928 sec; Batch: 2.0790 sec
0.1894 0.1731 0.1392 0.1217 0.1026 0.0883 0.0793 0.0735 0.0695 0.0656 0.0640 0.0626 0.0612 0.0603 0.0595 0.0590 

[TRAIN] Epoch[1](7869/114412); Loss: 0.051993; Backpropagation: 0.2916 sec; Batch: 2.1158 sec
0.1154 0.1123 0.0767 0.0659 0.0548 0.0459 0.0416 0.0389 0.0370 0.0363 0.0358 0.0349 0.0346 0.0340 0.0339 0.0339 

[TRAIN] Epoch[1](7870/114412); Loss: 0.104406; Backpropagation: 0.2956 sec; Batch: 2.1217 sec
0.1648 0.1600 0.1363 0.1230 0.1107 0.1005 0.0952 0.0928 0.0901 0.0883 0.0868 0.0859 0.0849 0.0842 0.0837 0.0833 

[TRAIN] Epoch[1](7871/114412); Loss: 0.063993; Backpropagation: 0.2912 sec; Batch: 2.0770 sec
0.1375 0.1206 0.0904 0.0814 0.0681 0.0604 0.0552 0.0523 0.0492 0.0472 0.0457 0.0443 0.0435 0.0430 0.0426 0.0424 

[TRAIN] Epoch[1](7872/114412); Loss: 0.088877; Backpropagation: 0.2913 sec; Batch: 2.1136 sec
0.1463 0.1290 0.1153 0.1039 0.0943 0.0876 0.0821 0.0792 0.0776 0.0754 0.0740 0.0728 0.0719 0.0714 0.0709 0.0703 

[TRAIN] Epoch[1](7873/114412); Loss: 0.099091; Backpropagation: 0.2909 sec; Batch: 2.1184 sec
0.1558 0.1442 0.1269 0.1181 0.1070 0.1000 0.0942 0.0909 0.0875 0.0846 0.0829 0.0812 0.0799 0.0784 0.0773 0.0765 

[TRAIN] Epoch[1](7874/114412); Loss: 0.107641; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1898 0.1798 0.1448 0.1356 0.1233 0.1130 0.1031 0.0962 0.0909 0.0861 0.0821 0.0796 0.0772 0.0750 0.0733 0.0723 

[TRAIN] Epoch[1](7875/114412); Loss: 0.077703; Backpropagation: 0.2913 sec; Batch: 2.0934 sec
0.1424 0.1338 0.1082 0.1018 0.0891 0.0767 0.0687 0.0643 0.0615 0.0594 0.0579 0.0570 0.0562 0.0557 0.0555 0.0552 

[TRAIN] Epoch[1](7876/114412); Loss: 0.122581; Backpropagation: 0.2914 sec; Batch: 2.0940 sec
0.2060 0.1953 0.1714 0.1566 0.1372 0.1237 0.1137 0.1072 0.1019 0.0981 0.0949 0.0936 0.0921 0.0908 0.0899 0.0889 

[TRAIN] Epoch[1](7877/114412); Loss: 0.084466; Backpropagation: 0.2912 sec; Batch: 2.1132 sec
0.1792 0.1726 0.1250 0.1135 0.0958 0.0803 0.0712 0.0674 0.0634 0.0602 0.0580 0.0556 0.0536 0.0525 0.0519 0.0513 

[TRAIN] Epoch[1](7878/114412); Loss: 0.067901; Backpropagation: 0.2910 sec; Batch: 2.1129 sec
0.1452 0.1338 0.1048 0.0864 0.0682 0.0600 0.0549 0.0527 0.0506 0.0493 0.0485 0.0473 0.0468 0.0462 0.0460 0.0458 

[TRAIN] Epoch[1](7879/114412); Loss: 0.095966; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1889 0.1803 0.1538 0.1405 0.1122 0.0947 0.0839 0.0783 0.0709 0.0664 0.0648 0.0619 0.0607 0.0600 0.0593 0.0587 

[TRAIN] Epoch[1](7880/114412); Loss: 0.092471; Backpropagation: 0.2908 sec; Batch: 2.0817 sec
0.1672 0.1561 0.1298 0.1190 0.0992 0.0881 0.0804 0.0776 0.0754 0.0733 0.0712 0.0701 0.0690 0.0680 0.0676 0.0674 

[TRAIN] Epoch[1](7881/114412); Loss: 0.103799; Backpropagation: 0.2917 sec; Batch: 2.0785 sec
0.1800 0.1712 0.1376 0.1275 0.1144 0.1069 0.0983 0.0928 0.0874 0.0834 0.0803 0.0785 0.0768 0.0757 0.0753 0.0748 

[TRAIN] Epoch[1](7882/114412); Loss: 0.100846; Backpropagation: 0.2927 sec; Batch: 2.1159 sec
0.1601 0.1560 0.1306 0.1190 0.1054 0.0982 0.0910 0.0879 0.0860 0.0850 0.0842 0.0833 0.0827 0.0819 0.0812 0.0809 

[TRAIN] Epoch[1](7883/114412); Loss: 0.089296; Backpropagation: 0.2905 sec; Batch: 2.0750 sec
0.1845 0.1742 0.1354 0.1181 0.0937 0.0820 0.0744 0.0704 0.0670 0.0648 0.0632 0.0617 0.0606 0.0600 0.0597 0.0590 

[TRAIN] Epoch[1](7884/114412); Loss: 0.125985; Backpropagation: 0.2909 sec; Batch: 2.1157 sec
0.2575 0.2455 0.2126 0.1984 0.1679 0.1472 0.1260 0.1066 0.0910 0.0801 0.0743 0.0675 0.0632 0.0612 0.0589 0.0580 

[TRAIN] Epoch[1](7885/114412); Loss: 0.098575; Backpropagation: 0.2914 sec; Batch: 2.0760 sec
0.1713 0.1586 0.1331 0.1246 0.1085 0.0991 0.0915 0.0862 0.0832 0.0804 0.0777 0.0755 0.0740 0.0721 0.0711 0.0705 

[TRAIN] Epoch[1](7886/114412); Loss: 0.086459; Backpropagation: 0.2913 sec; Batch: 2.1162 sec
0.1345 0.1275 0.1030 0.0941 0.0878 0.0828 0.0807 0.0791 0.0770 0.0759 0.0749 0.0742 0.0737 0.0730 0.0727 0.0724 

[TRAIN] Epoch[1](7887/114412); Loss: 0.082618; Backpropagation: 0.2954 sec; Batch: 2.1179 sec
0.1524 0.1410 0.1140 0.1043 0.0887 0.0784 0.0721 0.0692 0.0666 0.0651 0.0634 0.0626 0.0617 0.0612 0.0608 0.0606 

[TRAIN] Epoch[1](7888/114412); Loss: 0.079053; Backpropagation: 0.2946 sec; Batch: 2.1174 sec
0.1506 0.1397 0.1112 0.1000 0.0843 0.0763 0.0703 0.0661 0.0634 0.0615 0.0592 0.0575 0.0567 0.0562 0.0560 0.0558 

[TRAIN] Epoch[1](7889/114412); Loss: 0.075483; Backpropagation: 0.2929 sec; Batch: 2.1149 sec
0.1498 0.1418 0.1139 0.1042 0.0848 0.0723 0.0643 0.0601 0.0573 0.0547 0.0532 0.0518 0.0508 0.0502 0.0495 0.0491 

[TRAIN] Epoch[1](7890/114412); Loss: 0.091244; Backpropagation: 0.2952 sec; Batch: 2.1250 sec
0.2107 0.1875 0.1489 0.1289 0.1011 0.0836 0.0730 0.0663 0.0628 0.0609 0.0589 0.0573 0.0562 0.0554 0.0546 0.0539 

[TRAIN] Epoch[1](7891/114412); Loss: 0.089965; Backpropagation: 0.2909 sec; Batch: 2.1154 sec
0.1362 0.1314 0.1121 0.1040 0.0954 0.0886 0.0835 0.0806 0.0791 0.0781 0.0765 0.0758 0.0754 0.0745 0.0741 0.0740 

[TRAIN] Epoch[1](7892/114412); Loss: 0.071841; Backpropagation: 0.2909 sec; Batch: 2.1147 sec
0.1345 0.1263 0.1039 0.0974 0.0822 0.0732 0.0647 0.0591 0.0565 0.0536 0.0520 0.0508 0.0496 0.0488 0.0486 0.0482 

[TRAIN] Epoch[1](7893/114412); Loss: 0.077675; Backpropagation: 0.2916 sec; Batch: 2.1155 sec
0.1477 0.1322 0.1050 0.0900 0.0780 0.0714 0.0681 0.0665 0.0642 0.0625 0.0613 0.0602 0.0594 0.0590 0.0588 0.0584 

[TRAIN] Epoch[1](7894/114412); Loss: 0.071528; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1269 0.1243 0.0969 0.0893 0.0776 0.0697 0.0633 0.0596 0.0578 0.0566 0.0554 0.0546 0.0539 0.0533 0.0528 0.0524 

[TRAIN] Epoch[1](7895/114412); Loss: 0.094412; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1598 0.1419 0.1269 0.1104 0.0995 0.0900 0.0860 0.0837 0.0820 0.0792 0.0775 0.0767 0.0751 0.0745 0.0738 0.0733 

[TRAIN] Epoch[1](7896/114412); Loss: 0.097931; Backpropagation: 0.2913 sec; Batch: 2.1200 sec
0.1619 0.1508 0.1300 0.1224 0.1119 0.1016 0.0923 0.0872 0.0829 0.0793 0.0772 0.0755 0.0746 0.0737 0.0730 0.0727 

[TRAIN] Epoch[1](7897/114412); Loss: 0.096170; Backpropagation: 0.2906 sec; Batch: 2.0763 sec
0.1637 0.1491 0.1282 0.1151 0.0989 0.0931 0.0879 0.0852 0.0826 0.0800 0.0784 0.0773 0.0761 0.0751 0.0743 0.0736 

[TRAIN] Epoch[1](7898/114412); Loss: 0.070797; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.1477 0.1319 0.0961 0.0837 0.0710 0.0652 0.0607 0.0578 0.0561 0.0546 0.0532 0.0520 0.0514 0.0509 0.0503 0.0501 

[TRAIN] Epoch[1](7899/114412); Loss: 0.111620; Backpropagation: 0.2933 sec; Batch: 2.0795 sec
0.1600 0.1431 0.1287 0.1230 0.1148 0.1099 0.1069 0.1051 0.1029 0.1012 0.1002 0.0993 0.0987 0.0980 0.0974 0.0970 

[TRAIN] Epoch[1](7900/114412); Loss: 0.113202; Backpropagation: 0.2930 sec; Batch: 2.1185 sec
0.1936 0.1806 0.1543 0.1440 0.1275 0.1149 0.1061 0.0995 0.0948 0.0909 0.0880 0.0861 0.0843 0.0831 0.0822 0.0815 

[TRAIN] Epoch[1](7901/114412); Loss: 0.099309; Backpropagation: 0.2932 sec; Batch: 2.1164 sec
0.1767 0.1667 0.1235 0.1125 0.0956 0.0918 0.0889 0.0874 0.0848 0.0826 0.0815 0.0806 0.0800 0.0793 0.0786 0.0783 

[TRAIN] Epoch[1](7902/114412); Loss: 0.124598; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.2533 0.2292 0.1865 0.1680 0.1399 0.1208 0.1084 0.0991 0.0931 0.0894 0.0872 0.0858 0.0845 0.0838 0.0826 0.0821 

[TRAIN] Epoch[1](7903/114412); Loss: 0.100772; Backpropagation: 0.2913 sec; Batch: 2.1132 sec
0.1783 0.1614 0.1299 0.1198 0.1058 0.0981 0.0913 0.0878 0.0849 0.0828 0.0812 0.0797 0.0788 0.0780 0.0775 0.0770 

[TRAIN] Epoch[1](7904/114412); Loss: 0.078640; Backpropagation: 0.2926 sec; Batch: 2.1145 sec
0.1530 0.1448 0.1053 0.0918 0.0772 0.0719 0.0676 0.0656 0.0632 0.0618 0.0613 0.0601 0.0595 0.0588 0.0583 0.0580 

[TRAIN] Epoch[1](7905/114412); Loss: 0.118427; Backpropagation: 0.2913 sec; Batch: 2.1131 sec
0.2130 0.2008 0.1726 0.1619 0.1409 0.1265 0.1150 0.1041 0.0951 0.0886 0.0851 0.0829 0.0813 0.0777 0.0751 0.0742 

[TRAIN] Epoch[1](7906/114412); Loss: 0.091649; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.1785 0.1598 0.1339 0.1189 0.0936 0.0843 0.0768 0.0744 0.0721 0.0703 0.0693 0.0680 0.0672 0.0670 0.0663 0.0658 

[TRAIN] Epoch[1](7907/114412); Loss: 0.085957; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1867 0.1646 0.1326 0.1157 0.0958 0.0831 0.0704 0.0648 0.0631 0.0615 0.0591 0.0579 0.0566 0.0552 0.0544 0.0537 

[TRAIN] Epoch[1](7908/114412); Loss: 0.094395; Backpropagation: 0.2913 sec; Batch: 2.0778 sec
0.1836 0.1794 0.1451 0.1256 0.1029 0.0853 0.0762 0.0736 0.0709 0.0687 0.0681 0.0671 0.0665 0.0661 0.0658 0.0654 

[TRAIN] Epoch[1](7909/114412); Loss: 0.083699; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1601 0.1451 0.1148 0.1033 0.0870 0.0765 0.0724 0.0711 0.0685 0.0661 0.0647 0.0639 0.0622 0.0620 0.0611 0.0605 

[TRAIN] Epoch[1](7910/114412); Loss: 0.105598; Backpropagation: 0.2912 sec; Batch: 2.1255 sec
0.2205 0.2056 0.1651 0.1506 0.1232 0.1048 0.0911 0.0822 0.0767 0.0725 0.0697 0.0678 0.0665 0.0651 0.0644 0.0639 

[TRAIN] Epoch[1](7911/114412); Loss: 0.063817; Backpropagation: 0.2911 sec; Batch: 2.1147 sec
0.1470 0.1330 0.0921 0.0808 0.0634 0.0567 0.0534 0.0500 0.0482 0.0458 0.0443 0.0430 0.0419 0.0409 0.0405 0.0401 

[TRAIN] Epoch[1](7912/114412); Loss: 0.105727; Backpropagation: 0.2930 sec; Batch: 2.1219 sec
0.1854 0.1789 0.1555 0.1436 0.1218 0.1047 0.0942 0.0879 0.0838 0.0807 0.0785 0.0769 0.0757 0.0751 0.0746 0.0744 

[TRAIN] Epoch[1](7913/114412); Loss: 0.073288; Backpropagation: 0.2933 sec; Batch: 2.1301 sec
0.1393 0.1220 0.1030 0.0904 0.0789 0.0706 0.0646 0.0617 0.0595 0.0572 0.0562 0.0550 0.0544 0.0536 0.0533 0.0531 

[TRAIN] Epoch[1](7914/114412); Loss: 0.094795; Backpropagation: 0.2953 sec; Batch: 2.1001 sec
0.1441 0.1358 0.1170 0.1078 0.0985 0.0918 0.0885 0.0871 0.0845 0.0832 0.0815 0.0805 0.0799 0.0790 0.0789 0.0786 

[TRAIN] Epoch[1](7915/114412); Loss: 0.098339; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.1714 0.1626 0.1430 0.1304 0.1087 0.0939 0.0864 0.0822 0.0796 0.0768 0.0753 0.0742 0.0733 0.0725 0.0718 0.0714 

[TRAIN] Epoch[1](7916/114412); Loss: 0.070563; Backpropagation: 0.2908 sec; Batch: 2.1115 sec
0.1138 0.1122 0.0921 0.0856 0.0758 0.0701 0.0659 0.0626 0.0605 0.0589 0.0574 0.0562 0.0553 0.0547 0.0542 0.0538 

[TRAIN] Epoch[1](7917/114412); Loss: 0.099094; Backpropagation: 0.2951 sec; Batch: 2.1190 sec
0.1866 0.1715 0.1427 0.1310 0.1107 0.0975 0.0875 0.0816 0.0788 0.0757 0.0736 0.0715 0.0705 0.0696 0.0686 0.0681 

[TRAIN] Epoch[1](7918/114412); Loss: 0.061178; Backpropagation: 0.2930 sec; Batch: 2.1152 sec
0.1083 0.0994 0.0833 0.0765 0.0656 0.0585 0.0546 0.0528 0.0508 0.0492 0.0482 0.0474 0.0467 0.0463 0.0457 0.0455 

[TRAIN] Epoch[1](7919/114412); Loss: 0.099662; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1763 0.1594 0.1342 0.1219 0.1082 0.0989 0.0918 0.0876 0.0837 0.0803 0.0786 0.0769 0.0755 0.0745 0.0738 0.0730 

[TRAIN] Epoch[1](7920/114412); Loss: 0.096879; Backpropagation: 0.2909 sec; Batch: 2.1157 sec
0.2181 0.1942 0.1496 0.1282 0.0996 0.0862 0.0776 0.0738 0.0710 0.0684 0.0668 0.0650 0.0639 0.0630 0.0625 0.0622 

[TRAIN] Epoch[1](7921/114412); Loss: 0.061221; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1158 0.1048 0.0817 0.0748 0.0648 0.0578 0.0539 0.0518 0.0497 0.0484 0.0477 0.0466 0.0460 0.0456 0.0453 0.0449 

[TRAIN] Epoch[1](7922/114412); Loss: 0.124796; Backpropagation: 0.2910 sec; Batch: 2.1041 sec
0.1782 0.1615 0.1473 0.1364 0.1297 0.1227 0.1188 0.1166 0.1146 0.1128 0.1115 0.1105 0.1099 0.1093 0.1087 0.1081 

[TRAIN] Epoch[1](7923/114412); Loss: 0.083472; Backpropagation: 0.2906 sec; Batch: 2.1126 sec
0.1430 0.1364 0.1120 0.1038 0.0892 0.0813 0.0749 0.0722 0.0698 0.0682 0.0667 0.0653 0.0644 0.0634 0.0627 0.0622 

[TRAIN] Epoch[1](7924/114412); Loss: 0.107619; Backpropagation: 0.2904 sec; Batch: 2.1133 sec
0.2043 0.1939 0.1546 0.1412 0.1187 0.1036 0.0951 0.0910 0.0857 0.0817 0.0793 0.0769 0.0756 0.0745 0.0731 0.0725 

[TRAIN] Epoch[1](7925/114412); Loss: 0.075943; Backpropagation: 0.2906 sec; Batch: 2.1177 sec
0.1404 0.1218 0.0972 0.0859 0.0775 0.0733 0.0693 0.0668 0.0645 0.0623 0.0611 0.0602 0.0594 0.0590 0.0587 0.0579 

[TRAIN] Epoch[1](7926/114412); Loss: 0.077590; Backpropagation: 0.2910 sec; Batch: 2.4492 sec
0.1479 0.1415 0.1046 0.0972 0.0777 0.0712 0.0660 0.0635 0.0617 0.0609 0.0593 0.0581 0.0583 0.0580 0.0578 0.0575 

[TRAIN] Epoch[1](7927/114412); Loss: 0.073060; Backpropagation: 0.2913 sec; Batch: 2.1221 sec
0.1574 0.1386 0.0992 0.0864 0.0724 0.0656 0.0610 0.0588 0.0570 0.0550 0.0534 0.0533 0.0529 0.0526 0.0526 0.0526 

[TRAIN] Epoch[1](7928/114412); Loss: 0.081071; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1835 0.1695 0.1266 0.1094 0.0848 0.0712 0.0630 0.0602 0.0577 0.0559 0.0547 0.0534 0.0528 0.0520 0.0513 0.0511 

[TRAIN] Epoch[1](7929/114412); Loss: 0.094015; Backpropagation: 0.2930 sec; Batch: 2.1170 sec
0.1417 0.1349 0.1134 0.1079 0.0972 0.0919 0.0883 0.0856 0.0841 0.0825 0.0815 0.0804 0.0798 0.0791 0.0783 0.0779 

[TRAIN] Epoch[1](7930/114412); Loss: 0.075557; Backpropagation: 0.2931 sec; Batch: 2.1563 sec
0.1318 0.1235 0.1006 0.0913 0.0789 0.0730 0.0675 0.0650 0.0632 0.0615 0.0602 0.0595 0.0587 0.0583 0.0581 0.0579 

[TRAIN] Epoch[1](7931/114412); Loss: 0.104064; Backpropagation: 0.2952 sec; Batch: 2.1243 sec
0.2318 0.2162 0.1709 0.1535 0.1238 0.1039 0.0886 0.0777 0.0696 0.0674 0.0640 0.0621 0.0606 0.0591 0.0583 0.0575 

[TRAIN] Epoch[1](7932/114412); Loss: 0.099580; Backpropagation: 0.2945 sec; Batch: 2.0807 sec
0.1730 0.1637 0.1348 0.1212 0.1055 0.0976 0.0903 0.0870 0.0839 0.0809 0.0792 0.0771 0.0760 0.0750 0.0743 0.0739 

[TRAIN] Epoch[1](7933/114412); Loss: 0.114981; Backpropagation: 0.2930 sec; Batch: 2.1204 sec
0.2227 0.1982 0.1648 0.1519 0.1323 0.1181 0.1037 0.0950 0.0902 0.0860 0.0837 0.0814 0.0793 0.0782 0.0776 0.0767 

[TRAIN] Epoch[1](7934/114412); Loss: 0.092182; Backpropagation: 0.2905 sec; Batch: 2.1147 sec
0.1647 0.1584 0.1160 0.0990 0.0928 0.0876 0.0835 0.0817 0.0785 0.0762 0.0749 0.0738 0.0729 0.0719 0.0717 0.0713 

[TRAIN] Epoch[1](7935/114412); Loss: 0.077402; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.1336 0.1261 0.1064 0.0969 0.0849 0.0753 0.0705 0.0665 0.0636 0.0619 0.0608 0.0596 0.0588 0.0582 0.0580 0.0577 

[TRAIN] Epoch[1](7936/114412); Loss: 0.058744; Backpropagation: 0.2909 sec; Batch: 2.1181 sec
0.1237 0.1155 0.0864 0.0741 0.0610 0.0527 0.0488 0.0468 0.0443 0.0430 0.0419 0.0411 0.0409 0.0402 0.0398 0.0397 

[TRAIN] Epoch[1](7937/114412); Loss: 0.088494; Backpropagation: 0.2926 sec; Batch: 2.1185 sec
0.1700 0.1606 0.1293 0.1203 0.0960 0.0834 0.0758 0.0725 0.0691 0.0669 0.0649 0.0630 0.0621 0.0612 0.0606 0.0602 

[TRAIN] Epoch[1](7938/114412); Loss: 0.077472; Backpropagation: 0.2918 sec; Batch: 2.1444 sec
0.1315 0.1213 0.1052 0.0943 0.0839 0.0749 0.0704 0.0673 0.0647 0.0634 0.0620 0.0610 0.0604 0.0600 0.0597 0.0594 

[TRAIN] Epoch[1](7939/114412); Loss: 0.151950; Backpropagation: 0.2932 sec; Batch: 2.1193 sec
0.2532 0.2376 0.2104 0.1973 0.1763 0.1590 0.1436 0.1323 0.1250 0.1204 0.1168 0.1145 0.1128 0.1116 0.1106 0.1097 

[TRAIN] Epoch[1](7940/114412); Loss: 0.063604; Backpropagation: 0.2916 sec; Batch: 2.1168 sec
0.1322 0.1084 0.0840 0.0767 0.0675 0.0664 0.0599 0.0556 0.0510 0.0483 0.0473 0.0458 0.0449 0.0436 0.0433 0.0428 

[TRAIN] Epoch[1](7941/114412); Loss: 0.128703; Backpropagation: 0.2954 sec; Batch: 2.1197 sec
0.2034 0.1891 0.1626 0.1489 0.1343 0.1244 0.1186 0.1156 0.1121 0.1096 0.1082 0.1076 0.1068 0.1063 0.1060 0.1056 

[TRAIN] Epoch[1](7942/114412); Loss: 0.091997; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1525 0.1414 0.1153 0.1054 0.0942 0.0885 0.0848 0.0814 0.0792 0.0777 0.0764 0.0758 0.0755 0.0749 0.0746 0.0744 

[TRAIN] Epoch[1](7943/114412); Loss: 0.068326; Backpropagation: 0.2908 sec; Batch: 2.0866 sec
0.1283 0.1160 0.0870 0.0773 0.0701 0.0650 0.0609 0.0589 0.0568 0.0554 0.0546 0.0535 0.0529 0.0525 0.0520 0.0518 

[TRAIN] Epoch[1](7944/114412); Loss: 0.080888; Backpropagation: 0.2909 sec; Batch: 2.1019 sec
0.1340 0.1275 0.1055 0.0970 0.0852 0.0788 0.0748 0.0724 0.0693 0.0674 0.0658 0.0647 0.0638 0.0632 0.0626 0.0622 

[TRAIN] Epoch[1](7945/114412); Loss: 0.079552; Backpropagation: 0.2911 sec; Batch: 2.1139 sec
0.1602 0.1489 0.1184 0.1051 0.0877 0.0785 0.0701 0.0647 0.0606 0.0578 0.0566 0.0546 0.0532 0.0528 0.0520 0.0516 

[TRAIN] Epoch[1](7946/114412); Loss: 0.108891; Backpropagation: 0.2919 sec; Batch: 2.1209 sec
0.2200 0.2084 0.1710 0.1530 0.1259 0.1068 0.0932 0.0847 0.0783 0.0751 0.0733 0.0721 0.0711 0.0705 0.0697 0.0693 

[TRAIN] Epoch[1](7947/114412); Loss: 0.067791; Backpropagation: 0.3554 sec; Batch: 2.5349 sec
0.1222 0.1176 0.0917 0.0856 0.0715 0.0649 0.0602 0.0584 0.0556 0.0549 0.0531 0.0510 0.0504 0.0498 0.0489 0.0487 

[TRAIN] Epoch[1](7948/114412); Loss: 0.114948; Backpropagation: 0.2910 sec; Batch: 2.0785 sec
0.2217 0.2070 0.1627 0.1465 0.1252 0.1092 0.0992 0.0940 0.0908 0.0880 0.0864 0.0845 0.0826 0.0815 0.0807 0.0793 

[TRAIN] Epoch[1](7949/114412); Loss: 0.087000; Backpropagation: 0.2907 sec; Batch: 2.0902 sec
0.1413 0.1308 0.1111 0.1019 0.0933 0.0845 0.0800 0.0774 0.0747 0.0730 0.0720 0.0713 0.0707 0.0702 0.0700 0.0697 

[TRAIN] Epoch[1](7950/114412); Loss: 0.077251; Backpropagation: 0.2906 sec; Batch: 2.1176 sec
0.1493 0.1432 0.1087 0.1001 0.0850 0.0764 0.0692 0.0645 0.0608 0.0582 0.0564 0.0547 0.0534 0.0525 0.0520 0.0516 

[TRAIN] Epoch[1](7951/114412); Loss: 0.090738; Backpropagation: 0.2948 sec; Batch: 2.0847 sec
0.1548 0.1482 0.1206 0.1105 0.0975 0.0905 0.0843 0.0798 0.0761 0.0740 0.0722 0.0706 0.0695 0.0684 0.0678 0.0669 

[TRAIN] Epoch[1](7952/114412); Loss: 0.068720; Backpropagation: 0.2951 sec; Batch: 2.0829 sec
0.1610 0.1556 0.1050 0.0906 0.0698 0.0579 0.0527 0.0499 0.0482 0.0464 0.0450 0.0444 0.0437 0.0432 0.0430 0.0429 

[TRAIN] Epoch[1](7953/114412); Loss: 0.128388; Backpropagation: 0.2913 sec; Batch: 2.1059 sec
0.2513 0.2297 0.1895 0.1727 0.1437 0.1243 0.1115 0.1045 0.0987 0.0957 0.0935 0.0902 0.0886 0.0879 0.0866 0.0857 

[TRAIN] Epoch[1](7954/114412); Loss: 0.093143; Backpropagation: 0.2926 sec; Batch: 2.1217 sec
0.1660 0.1472 0.1206 0.1133 0.1015 0.0924 0.0870 0.0825 0.0795 0.0765 0.0745 0.0729 0.0708 0.0696 0.0686 0.0675 

[TRAIN] Epoch[1](7955/114412); Loss: 0.114184; Backpropagation: 0.2926 sec; Batch: 2.1197 sec
0.1957 0.1888 0.1600 0.1484 0.1310 0.1183 0.1080 0.0997 0.0946 0.0896 0.0858 0.0839 0.0822 0.0810 0.0807 0.0794 

[TRAIN] Epoch[1](7956/114412); Loss: 0.127393; Backpropagation: 0.2913 sec; Batch: 2.1137 sec
0.2531 0.2299 0.1902 0.1693 0.1454 0.1293 0.1154 0.1063 0.0989 0.0937 0.0904 0.0869 0.0847 0.0833 0.0813 0.0803 

[TRAIN] Epoch[1](7957/114412); Loss: 0.076938; Backpropagation: 0.2910 sec; Batch: 2.1133 sec
0.1428 0.1265 0.0977 0.0864 0.0786 0.0725 0.0692 0.0667 0.0649 0.0633 0.0623 0.0612 0.0604 0.0600 0.0594 0.0590 

[TRAIN] Epoch[1](7958/114412); Loss: 0.126869; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.2269 0.2179 0.1859 0.1759 0.1548 0.1409 0.1248 0.1125 0.1020 0.0945 0.0892 0.0861 0.0828 0.0805 0.0786 0.0764 

[TRAIN] Epoch[1](7959/114412); Loss: 0.080032; Backpropagation: 0.2909 sec; Batch: 2.1150 sec
0.1784 0.1678 0.1218 0.1109 0.0890 0.0745 0.0664 0.0606 0.0564 0.0539 0.0520 0.0510 0.0504 0.0496 0.0491 0.0487 

[TRAIN] Epoch[1](7960/114412); Loss: 0.092641; Backpropagation: 0.2913 sec; Batch: 2.1130 sec
0.1737 0.1573 0.1276 0.1165 0.1010 0.0899 0.0844 0.0792 0.0747 0.0727 0.0708 0.0688 0.0677 0.0667 0.0659 0.0653 

[TRAIN] Epoch[1](7961/114412); Loss: 0.093620; Backpropagation: 0.2929 sec; Batch: 2.1227 sec
0.1695 0.1512 0.1217 0.1083 0.0976 0.0909 0.0853 0.0812 0.0788 0.0771 0.0753 0.0738 0.0730 0.0721 0.0713 0.0708 

[TRAIN] Epoch[1](7962/114412); Loss: 0.152913; Backpropagation: 0.2927 sec; Batch: 2.0986 sec
0.2298 0.2158 0.1941 0.1800 0.1611 0.1504 0.1450 0.1395 0.1353 0.1328 0.1307 0.1289 0.1275 0.1263 0.1252 0.1243 

[TRAIN] Epoch[1](7963/114412); Loss: 0.087394; Backpropagation: 0.2914 sec; Batch: 2.1162 sec
0.1721 0.1527 0.1236 0.1086 0.0955 0.0839 0.0761 0.0727 0.0700 0.0679 0.0662 0.0638 0.0625 0.0617 0.0607 0.0602 

[TRAIN] Epoch[1](7964/114412); Loss: 0.067902; Backpropagation: 0.2909 sec; Batch: 2.1203 sec
0.1240 0.1056 0.0826 0.0785 0.0731 0.0660 0.0630 0.0608 0.0588 0.0570 0.0554 0.0540 0.0530 0.0521 0.0515 0.0511 

[TRAIN] Epoch[1](7965/114412); Loss: 0.092399; Backpropagation: 0.2909 sec; Batch: 2.1133 sec
0.1869 0.1629 0.1321 0.1186 0.0988 0.0885 0.0811 0.0762 0.0722 0.0697 0.0677 0.0661 0.0655 0.0647 0.0639 0.0635 

[TRAIN] Epoch[1](7966/114412); Loss: 0.074378; Backpropagation: 0.2906 sec; Batch: 2.1142 sec
0.1561 0.1458 0.1074 0.0946 0.0778 0.0672 0.0613 0.0589 0.0566 0.0550 0.0535 0.0522 0.0517 0.0511 0.0506 0.0503 

[TRAIN] Epoch[1](7967/114412); Loss: 0.095531; Backpropagation: 0.2913 sec; Batch: 2.1221 sec
0.2274 0.2000 0.1551 0.1348 0.1090 0.0947 0.0831 0.0732 0.0664 0.0612 0.0592 0.0565 0.0543 0.0530 0.0511 0.0497 

[TRAIN] Epoch[1](7968/114412); Loss: 0.073400; Backpropagation: 0.2929 sec; Batch: 2.0807 sec
0.1302 0.1166 0.0955 0.0877 0.0765 0.0712 0.0670 0.0646 0.0626 0.0604 0.0588 0.0578 0.0570 0.0566 0.0562 0.0558 

[TRAIN] Epoch[1](7969/114412); Loss: 0.113298; Backpropagation: 0.2955 sec; Batch: 2.1026 sec
0.2232 0.2098 0.1849 0.1708 0.1467 0.1232 0.1001 0.0858 0.0791 0.0743 0.0736 0.0714 0.0687 0.0680 0.0671 0.0661 

[TRAIN] Epoch[1](7970/114412); Loss: 0.087209; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1834 0.1650 0.1320 0.1239 0.1014 0.0850 0.0751 0.0685 0.0640 0.0608 0.0590 0.0571 0.0557 0.0554 0.0548 0.0542 

[TRAIN] Epoch[1](7971/114412); Loss: 0.082925; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1798 0.1724 0.1276 0.1088 0.0859 0.0740 0.0673 0.0629 0.0592 0.0578 0.0573 0.0562 0.0554 0.0548 0.0541 0.0534 

[TRAIN] Epoch[1](7972/114412); Loss: 0.091614; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1635 0.1510 0.1164 0.1064 0.0950 0.0879 0.0816 0.0792 0.0772 0.0754 0.0741 0.0729 0.0722 0.0716 0.0710 0.0705 

[TRAIN] Epoch[1](7973/114412); Loss: 0.092742; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.2120 0.1920 0.1462 0.1264 0.0975 0.0789 0.0727 0.0688 0.0656 0.0635 0.0621 0.0611 0.0601 0.0593 0.0590 0.0587 

[TRAIN] Epoch[1](7974/114412); Loss: 0.092384; Backpropagation: 0.2905 sec; Batch: 2.1163 sec
0.1833 0.1692 0.1312 0.1192 0.1011 0.0898 0.0827 0.0775 0.0729 0.0697 0.0673 0.0651 0.0635 0.0626 0.0617 0.0612 

[TRAIN] Epoch[1](7975/114412); Loss: 0.116806; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.2103 0.1958 0.1664 0.1524 0.1249 0.1110 0.1009 0.0980 0.0944 0.0920 0.0900 0.0888 0.0874 0.0863 0.0856 0.0849 

[TRAIN] Epoch[1](7976/114412); Loss: 0.125653; Backpropagation: 0.2955 sec; Batch: 2.1195 sec
0.2257 0.2022 0.1694 0.1448 0.1313 0.1224 0.1121 0.1098 0.1055 0.1021 0.1007 0.0985 0.0973 0.0968 0.0962 0.0959 

[TRAIN] Epoch[1](7977/114412); Loss: 0.082648; Backpropagation: 0.2932 sec; Batch: 2.1222 sec
0.1293 0.1228 0.1059 0.0969 0.0880 0.0813 0.0765 0.0747 0.0719 0.0706 0.0694 0.0682 0.0674 0.0669 0.0666 0.0662 

[TRAIN] Epoch[1](7978/114412); Loss: 0.091648; Backpropagation: 0.2908 sec; Batch: 2.1183 sec
0.1618 0.1550 0.1237 0.1110 0.0955 0.0867 0.0804 0.0775 0.0748 0.0737 0.0727 0.0717 0.0712 0.0707 0.0701 0.0698 

[TRAIN] Epoch[1](7979/114412); Loss: 0.078043; Backpropagation: 0.2910 sec; Batch: 2.0785 sec
0.1700 0.1586 0.1288 0.1153 0.0881 0.0744 0.0650 0.0584 0.0548 0.0518 0.0495 0.0480 0.0471 0.0467 0.0462 0.0459 

[TRAIN] Epoch[1](7980/114412); Loss: 0.090722; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1703 0.1622 0.1289 0.1173 0.0978 0.0851 0.0782 0.0749 0.0717 0.0696 0.0680 0.0671 0.0662 0.0653 0.0647 0.0641 

[TRAIN] Epoch[1](7981/114412); Loss: 0.117837; Backpropagation: 0.2919 sec; Batch: 2.0790 sec
0.1796 0.1716 0.1438 0.1360 0.1214 0.1147 0.1093 0.1072 0.1055 0.1032 0.1017 0.1003 0.0990 0.0981 0.0975 0.0968 

[TRAIN] Epoch[1](7982/114412); Loss: 0.089255; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1417 0.1330 0.1129 0.1038 0.0916 0.0860 0.0821 0.0801 0.0782 0.0765 0.0755 0.0745 0.0739 0.0732 0.0728 0.0724 

[TRAIN] Epoch[1](7983/114412); Loss: 0.073778; Backpropagation: 0.2912 sec; Batch: 2.0783 sec
0.1543 0.1314 0.1082 0.0924 0.0770 0.0684 0.0631 0.0595 0.0583 0.0553 0.0541 0.0532 0.0522 0.0514 0.0510 0.0506 

[TRAIN] Epoch[1](7984/114412); Loss: 0.093464; Backpropagation: 0.2907 sec; Batch: 2.0788 sec
0.1497 0.1421 0.1210 0.1113 0.1016 0.0950 0.0890 0.0858 0.0824 0.0789 0.0764 0.0750 0.0734 0.0718 0.0713 0.0707 

[TRAIN] Epoch[1](7985/114412); Loss: 0.095703; Backpropagation: 0.2905 sec; Batch: 2.0775 sec
0.1804 0.1617 0.1327 0.1202 0.1015 0.0913 0.0840 0.0798 0.0773 0.0748 0.0736 0.0723 0.0714 0.0708 0.0700 0.0694 

[TRAIN] Epoch[1](7986/114412); Loss: 0.089079; Backpropagation: 0.2907 sec; Batch: 2.0775 sec
0.1839 0.1754 0.1504 0.1322 0.1118 0.0943 0.0783 0.0675 0.0606 0.0567 0.0550 0.0531 0.0523 0.0522 0.0512 0.0505 

[TRAIN] Epoch[1](7987/114412); Loss: 0.068353; Backpropagation: 0.2909 sec; Batch: 2.1142 sec
0.1364 0.1323 0.1001 0.0826 0.0652 0.0610 0.0566 0.0554 0.0534 0.0519 0.0515 0.0505 0.0498 0.0494 0.0491 0.0485 

[TRAIN] Epoch[1](7988/114412); Loss: 0.077119; Backpropagation: 0.2909 sec; Batch: 2.1213 sec
0.1423 0.1299 0.1036 0.0952 0.0834 0.0748 0.0695 0.0661 0.0636 0.0617 0.0600 0.0585 0.0573 0.0565 0.0560 0.0555 

[TRAIN] Epoch[1](7989/114412); Loss: 0.074646; Backpropagation: 0.2910 sec; Batch: 2.1140 sec
0.1432 0.1354 0.1057 0.0896 0.0760 0.0690 0.0641 0.0617 0.0591 0.0578 0.0570 0.0562 0.0556 0.0550 0.0546 0.0542 

[TRAIN] Epoch[1](7990/114412); Loss: 0.107398; Backpropagation: 0.2912 sec; Batch: 2.0772 sec
0.1795 0.1669 0.1433 0.1323 0.1195 0.1100 0.1015 0.0956 0.0905 0.0873 0.0854 0.0837 0.0822 0.0813 0.0801 0.0793 

[TRAIN] Epoch[1](7991/114412); Loss: 0.099460; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.2148 0.1977 0.1552 0.1402 0.1142 0.0942 0.0815 0.0755 0.0709 0.0675 0.0660 0.0645 0.0634 0.0624 0.0620 0.0614 

[TRAIN] Epoch[1](7992/114412); Loss: 0.073054; Backpropagation: 0.2911 sec; Batch: 2.0818 sec
0.1382 0.1080 0.0861 0.0813 0.0735 0.0703 0.0672 0.0649 0.0633 0.0616 0.0604 0.0597 0.0591 0.0587 0.0584 0.0581 

[TRAIN] Epoch[1](7993/114412); Loss: 0.067749; Backpropagation: 0.2959 sec; Batch: 2.1156 sec
0.1554 0.1371 0.0915 0.0781 0.0664 0.0604 0.0561 0.0542 0.0515 0.0498 0.0490 0.0479 0.0471 0.0468 0.0464 0.0461 

[TRAIN] Epoch[1](7994/114412); Loss: 0.086382; Backpropagation: 0.2955 sec; Batch: 2.1255 sec
0.1654 0.1576 0.1314 0.1197 0.0935 0.0779 0.0699 0.0666 0.0652 0.0640 0.0634 0.0624 0.0620 0.0613 0.0610 0.0607 

[TRAIN] Epoch[1](7995/114412); Loss: 0.083338; Backpropagation: 0.2951 sec; Batch: 2.0849 sec
0.1583 0.1483 0.1139 0.1023 0.0859 0.0783 0.0721 0.0691 0.0668 0.0652 0.0640 0.0629 0.0622 0.0618 0.0613 0.0608 

[TRAIN] Epoch[1](7996/114412); Loss: 0.089465; Backpropagation: 0.2979 sec; Batch: 2.0860 sec
0.1726 0.1622 0.1268 0.1122 0.0951 0.0854 0.0789 0.0744 0.0717 0.0689 0.0667 0.0651 0.0640 0.0630 0.0625 0.0618 

[TRAIN] Epoch[1](7997/114412); Loss: 0.085018; Backpropagation: 0.2956 sec; Batch: 2.0824 sec
0.1617 0.1428 0.1129 0.1040 0.0886 0.0792 0.0743 0.0721 0.0695 0.0675 0.0664 0.0655 0.0647 0.0640 0.0637 0.0634 

[TRAIN] Epoch[1](7998/114412); Loss: 0.058220; Backpropagation: 0.3010 sec; Batch: 2.1270 sec
0.1201 0.1113 0.0771 0.0687 0.0570 0.0522 0.0495 0.0478 0.0460 0.0450 0.0443 0.0436 0.0430 0.0423 0.0419 0.0416 

[TRAIN] Epoch[1](7999/114412); Loss: 0.093891; Backpropagation: 0.2981 sec; Batch: 2.0853 sec
0.1732 0.1675 0.1349 0.1214 0.1003 0.0873 0.0808 0.0771 0.0745 0.0724 0.0712 0.0700 0.0689 0.0681 0.0675 0.0671 

[TRAIN] Epoch[1](8000/114412); Loss: 0.077804; Backpropagation: 0.3007 sec; Batch: 2.1047 sec
0.1545 0.1346 0.1038 0.0945 0.0821 0.0738 0.0684 0.0661 0.0637 0.0611 0.0596 0.0583 0.0572 0.0562 0.0557 0.0553 

[TRAIN] Epoch[1](8001/114412); Loss: 0.105341; Backpropagation: 0.2961 sec; Batch: 2.1209 sec
0.1900 0.1864 0.1574 0.1449 0.1245 0.1109 0.1004 0.0909 0.0820 0.0779 0.0741 0.0722 0.0707 0.0689 0.0676 0.0668 

[TRAIN] Epoch[1](8002/114412); Loss: 0.088023; Backpropagation: 0.3091 sec; Batch: 2.1174 sec
0.1515 0.1429 0.1165 0.1051 0.0921 0.0841 0.0790 0.0758 0.0736 0.0721 0.0712 0.0701 0.0693 0.0686 0.0683 0.0680 

[TRAIN] Epoch[1](8003/114412); Loss: 0.083801; Backpropagation: 0.3007 sec; Batch: 2.0888 sec
0.1418 0.1294 0.1088 0.1002 0.0897 0.0822 0.0788 0.0758 0.0718 0.0706 0.0686 0.0666 0.0656 0.0642 0.0637 0.0630 

[TRAIN] Epoch[1](8004/114412); Loss: 0.076628; Backpropagation: 0.3010 sec; Batch: 2.1139 sec
0.1449 0.1309 0.1014 0.0919 0.0807 0.0747 0.0696 0.0669 0.0631 0.0605 0.0595 0.0579 0.0568 0.0564 0.0557 0.0551 

[TRAIN] Epoch[1](8005/114412); Loss: 0.092310; Backpropagation: 0.2976 sec; Batch: 2.0853 sec
0.1467 0.1367 0.1146 0.1068 0.0982 0.0918 0.0873 0.0840 0.0813 0.0792 0.0777 0.0764 0.0750 0.0745 0.0736 0.0731 

[TRAIN] Epoch[1](8006/114412); Loss: 0.082310; Backpropagation: 0.2956 sec; Batch: 2.1198 sec
0.1487 0.1391 0.1104 0.0984 0.0834 0.0777 0.0733 0.0703 0.0686 0.0670 0.0655 0.0644 0.0635 0.0628 0.0621 0.0619 

[TRAIN] Epoch[1](8007/114412); Loss: 0.096594; Backpropagation: 0.2962 sec; Batch: 2.1226 sec
0.1663 0.1558 0.1277 0.1139 0.1011 0.0924 0.0873 0.0842 0.0816 0.0794 0.0782 0.0773 0.0763 0.0752 0.0746 0.0743 

[TRAIN] Epoch[1](8008/114412); Loss: 0.083495; Backpropagation: 0.2956 sec; Batch: 2.1205 sec
0.1785 0.1709 0.1173 0.1040 0.0865 0.0773 0.0711 0.0661 0.0632 0.0604 0.0591 0.0581 0.0568 0.0560 0.0556 0.0553 

[TRAIN] Epoch[1](8009/114412); Loss: 0.059792; Backpropagation: 0.2958 sec; Batch: 2.1217 sec
0.1353 0.1272 0.0845 0.0723 0.0581 0.0525 0.0485 0.0459 0.0440 0.0432 0.0423 0.0415 0.0409 0.0405 0.0402 0.0398 

[TRAIN] Epoch[1](8010/114412); Loss: 0.078321; Backpropagation: 0.2955 sec; Batch: 2.1224 sec
0.1391 0.1244 0.0969 0.0883 0.0789 0.0738 0.0708 0.0694 0.0673 0.0658 0.0646 0.0638 0.0631 0.0628 0.0623 0.0619 

[TRAIN] Epoch[1](8011/114412); Loss: 0.130671; Backpropagation: 0.2951 sec; Batch: 2.1207 sec
0.1959 0.1902 0.1684 0.1590 0.1434 0.1344 0.1269 0.1218 0.1167 0.1131 0.1103 0.1068 0.1035 0.1013 0.0999 0.0991 

[TRAIN] Epoch[1](8012/114412); Loss: 0.101222; Backpropagation: 0.2961 sec; Batch: 2.1270 sec
0.1874 0.1798 0.1463 0.1317 0.1116 0.0971 0.0856 0.0825 0.0792 0.0781 0.0764 0.0748 0.0735 0.0724 0.0719 0.0713 

[TRAIN] Epoch[1](8013/114412); Loss: 0.084781; Backpropagation: 0.2957 sec; Batch: 2.1214 sec
0.1727 0.1560 0.1182 0.1014 0.0892 0.0808 0.0744 0.0709 0.0669 0.0647 0.0629 0.0612 0.0605 0.0596 0.0588 0.0583 

[TRAIN] Epoch[1](8014/114412); Loss: 0.111853; Backpropagation: 0.2960 sec; Batch: 2.1215 sec
0.2022 0.1857 0.1515 0.1365 0.1202 0.1087 0.1022 0.0967 0.0924 0.0904 0.0880 0.0856 0.0841 0.0828 0.0817 0.0809 

[TRAIN] Epoch[1](8015/114412); Loss: 0.101521; Backpropagation: 0.2980 sec; Batch: 2.1286 sec
0.1798 0.1655 0.1402 0.1306 0.1108 0.0982 0.0893 0.0872 0.0833 0.0808 0.0790 0.0775 0.0765 0.0758 0.0752 0.0747 

[TRAIN] Epoch[1](8016/114412); Loss: 0.073701; Backpropagation: 0.2980 sec; Batch: 2.0848 sec
0.1318 0.1214 0.0958 0.0857 0.0753 0.0693 0.0658 0.0639 0.0618 0.0605 0.0598 0.0587 0.0579 0.0575 0.0572 0.0569 

[TRAIN] Epoch[1](8017/114412); Loss: 0.115251; Backpropagation: 0.2957 sec; Batch: 2.1222 sec
0.2487 0.2260 0.1839 0.1646 0.1324 0.1074 0.0926 0.0862 0.0814 0.0788 0.0767 0.0753 0.0738 0.0727 0.0721 0.0714 

[TRAIN] Epoch[1](8018/114412); Loss: 0.079534; Backpropagation: 0.2948 sec; Batch: 2.0809 sec
0.1585 0.1436 0.1112 0.0987 0.0847 0.0758 0.0690 0.0664 0.0628 0.0602 0.0590 0.0579 0.0571 0.0566 0.0559 0.0553 

[TRAIN] Epoch[1](8019/114412); Loss: 0.087071; Backpropagation: 0.2948 sec; Batch: 2.1401 sec
0.2105 0.1973 0.1534 0.1365 0.1072 0.0851 0.0683 0.0576 0.0526 0.0497 0.0481 0.0470 0.0458 0.0451 0.0447 0.0442 

[TRAIN] Epoch[1](8020/114412); Loss: 0.106036; Backpropagation: 0.2959 sec; Batch: 2.1248 sec
0.1890 0.1700 0.1429 0.1301 0.1133 0.1041 0.0980 0.0930 0.0892 0.0860 0.0837 0.0817 0.0808 0.0797 0.0781 0.0771 

[TRAIN] Epoch[1](8021/114412); Loss: 0.095447; Backpropagation: 0.2958 sec; Batch: 2.0844 sec
0.1786 0.1641 0.1359 0.1224 0.1047 0.0923 0.0845 0.0800 0.0768 0.0743 0.0725 0.0709 0.0691 0.0679 0.0669 0.0662 

[TRAIN] Epoch[1](8022/114412); Loss: 0.069221; Backpropagation: 0.2956 sec; Batch: 2.0828 sec
0.1392 0.1238 0.0895 0.0796 0.0665 0.0651 0.0602 0.0591 0.0568 0.0549 0.0538 0.0530 0.0522 0.0516 0.0512 0.0508 

[TRAIN] Epoch[1](8023/114412); Loss: 0.094271; Backpropagation: 0.2956 sec; Batch: 2.1102 sec
0.1768 0.1592 0.1350 0.1214 0.1040 0.0931 0.0843 0.0791 0.0744 0.0721 0.0711 0.0694 0.0682 0.0674 0.0667 0.0661 

[TRAIN] Epoch[1](8024/114412); Loss: 0.104036; Backpropagation: 0.2959 sec; Batch: 2.1209 sec
0.1825 0.1754 0.1425 0.1351 0.1144 0.1037 0.0960 0.0898 0.0854 0.0822 0.0796 0.0780 0.0765 0.0753 0.0744 0.0737 

[TRAIN] Epoch[1](8025/114412); Loss: 0.094377; Backpropagation: 0.3008 sec; Batch: 2.1271 sec
0.1457 0.1354 0.1175 0.1065 0.0968 0.0922 0.0873 0.0858 0.0839 0.0823 0.0812 0.0802 0.0795 0.0790 0.0785 0.0782 

[TRAIN] Epoch[1](8026/114412); Loss: 0.114846; Backpropagation: 0.2964 sec; Batch: 2.1328 sec
0.2233 0.2002 0.1565 0.1393 0.1239 0.1130 0.1026 0.0958 0.0914 0.0886 0.0874 0.0855 0.0837 0.0831 0.0821 0.0812 

[TRAIN] Epoch[1](8027/114412); Loss: 0.093389; Backpropagation: 0.3008 sec; Batch: 2.1104 sec
0.1621 0.1549 0.1268 0.1138 0.0986 0.0898 0.0842 0.0813 0.0780 0.0759 0.0741 0.0729 0.0718 0.0710 0.0701 0.0692 

[TRAIN] Epoch[1](8028/114412); Loss: 0.088318; Backpropagation: 0.3007 sec; Batch: 2.1257 sec
0.1505 0.1298 0.1100 0.1013 0.0912 0.0853 0.0808 0.0791 0.0765 0.0747 0.0742 0.0730 0.0725 0.0719 0.0713 0.0711 

[TRAIN] Epoch[1](8029/114412); Loss: 0.085849; Backpropagation: 0.2954 sec; Batch: 2.1241 sec
0.1422 0.1386 0.1096 0.0990 0.0893 0.0841 0.0791 0.0766 0.0739 0.0718 0.0702 0.0692 0.0683 0.0677 0.0671 0.0669 

[TRAIN] Epoch[1](8030/114412); Loss: 0.086776; Backpropagation: 0.2946 sec; Batch: 2.0810 sec
0.1368 0.1304 0.1039 0.0946 0.0870 0.0828 0.0801 0.0790 0.0769 0.0754 0.0751 0.0741 0.0737 0.0730 0.0728 0.0726 

[TRAIN] Epoch[1](8031/114412); Loss: 0.070475; Backpropagation: 0.2956 sec; Batch: 2.1262 sec
0.1259 0.1145 0.0903 0.0832 0.0733 0.0667 0.0638 0.0618 0.0596 0.0580 0.0566 0.0557 0.0552 0.0547 0.0543 0.0541 

[TRAIN] Epoch[1](8032/114412); Loss: 0.073847; Backpropagation: 0.2978 sec; Batch: 2.0844 sec
0.1420 0.1283 0.0883 0.0819 0.0745 0.0700 0.0665 0.0638 0.0613 0.0601 0.0588 0.0581 0.0576 0.0569 0.0567 0.0568 

[TRAIN] Epoch[1](8033/114412); Loss: 0.074383; Backpropagation: 0.2978 sec; Batch: 2.0855 sec
0.1175 0.1159 0.0924 0.0850 0.0780 0.0733 0.0692 0.0669 0.0651 0.0635 0.0623 0.0614 0.0606 0.0600 0.0596 0.0596 

[TRAIN] Epoch[1](8034/114412); Loss: 0.087366; Backpropagation: 0.2983 sec; Batch: 2.1209 sec
0.1549 0.1489 0.1206 0.1105 0.0931 0.0850 0.0780 0.0739 0.0719 0.0697 0.0678 0.0666 0.0654 0.0645 0.0639 0.0631 

[TRAIN] Epoch[1](8035/114412); Loss: 0.106451; Backpropagation: 0.2980 sec; Batch: 2.1215 sec
0.2339 0.2015 0.1638 0.1432 0.1107 0.0933 0.0861 0.0821 0.0789 0.0765 0.0749 0.0733 0.0723 0.0716 0.0708 0.0702 

[TRAIN] Epoch[1](8036/114412); Loss: 0.082662; Backpropagation: 0.2954 sec; Batch: 2.1196 sec
0.1312 0.1267 0.1044 0.0966 0.0848 0.0801 0.0765 0.0743 0.0722 0.0707 0.0693 0.0683 0.0677 0.0670 0.0665 0.0661 

[TRAIN] Epoch[1](8037/114412); Loss: 0.085501; Backpropagation: 0.2982 sec; Batch: 2.1232 sec
0.1801 0.1514 0.1254 0.1117 0.0960 0.0844 0.0741 0.0700 0.0658 0.0628 0.0608 0.0590 0.0579 0.0570 0.0561 0.0555 

[TRAIN] Epoch[1](8038/114412); Loss: 0.073451; Backpropagation: 0.3123 sec; Batch: 2.1540 sec
0.1405 0.1232 0.0978 0.0875 0.0759 0.0698 0.0649 0.0623 0.0603 0.0588 0.0577 0.0566 0.0557 0.0553 0.0548 0.0542 

[TRAIN] Epoch[1](8039/114412); Loss: 0.107100; Backpropagation: 0.2949 sec; Batch: 2.1474 sec
0.2003 0.1919 0.1530 0.1385 0.1152 0.1011 0.0917 0.0871 0.0853 0.0827 0.0809 0.0788 0.0780 0.0771 0.0763 0.0757 

[TRAIN] Epoch[1](8040/114412); Loss: 0.108189; Backpropagation: 0.2959 sec; Batch: 2.1223 sec
0.2273 0.2115 0.1726 0.1477 0.1181 0.0997 0.0891 0.0835 0.0798 0.0768 0.0739 0.0723 0.0712 0.0699 0.0691 0.0685 

[TRAIN] Epoch[1](8041/114412); Loss: 0.096739; Backpropagation: 0.2948 sec; Batch: 2.1230 sec
0.1925 0.1754 0.1471 0.1306 0.1061 0.0907 0.0803 0.0758 0.0732 0.0711 0.0700 0.0685 0.0675 0.0667 0.0663 0.0660 

[TRAIN] Epoch[1](8042/114412); Loss: 0.089760; Backpropagation: 0.2982 sec; Batch: 2.4302 sec
0.1559 0.1455 0.1037 0.0949 0.0889 0.0858 0.0824 0.0802 0.0779 0.0765 0.0756 0.0748 0.0742 0.0735 0.0732 0.0731 

[TRAIN] Epoch[1](8043/114412); Loss: 0.079104; Backpropagation: 0.3007 sec; Batch: 2.1271 sec
0.1524 0.1413 0.1118 0.0977 0.0814 0.0736 0.0680 0.0651 0.0628 0.0614 0.0598 0.0589 0.0585 0.0580 0.0577 0.0575 

[TRAIN] Epoch[1](8044/114412); Loss: 0.062794; Backpropagation: 0.2989 sec; Batch: 2.1228 sec
0.1340 0.1305 0.0999 0.0834 0.0680 0.0566 0.0506 0.0472 0.0438 0.0430 0.0424 0.0417 0.0415 0.0409 0.0406 0.0405 

[TRAIN] Epoch[1](8045/114412); Loss: 0.073667; Backpropagation: 0.3010 sec; Batch: 2.1125 sec
0.1482 0.1398 0.1043 0.0901 0.0722 0.0671 0.0619 0.0589 0.0567 0.0559 0.0552 0.0546 0.0541 0.0534 0.0532 0.0530 

[TRAIN] Epoch[1](8046/114412); Loss: 0.082060; Backpropagation: 0.2975 sec; Batch: 2.1370 sec
0.1305 0.1256 0.1086 0.0985 0.0876 0.0789 0.0744 0.0731 0.0706 0.0691 0.0679 0.0665 0.0659 0.0656 0.0652 0.0650 

[TRAIN] Epoch[1](8047/114412); Loss: 0.084533; Backpropagation: 0.3004 sec; Batch: 2.1249 sec
0.1856 0.1604 0.1245 0.1057 0.0857 0.0752 0.0699 0.0673 0.0656 0.0621 0.0604 0.0595 0.0587 0.0577 0.0572 0.0568 

[TRAIN] Epoch[1](8048/114412); Loss: 0.082838; Backpropagation: 0.3009 sec; Batch: 2.1255 sec
0.1765 0.1672 0.1311 0.1155 0.0936 0.0775 0.0671 0.0625 0.0586 0.0568 0.0557 0.0541 0.0531 0.0527 0.0520 0.0514 

[TRAIN] Epoch[1](8049/114412); Loss: 0.070992; Backpropagation: 0.3006 sec; Batch: 2.1259 sec
0.1442 0.1376 0.1087 0.0909 0.0778 0.0688 0.0615 0.0556 0.0523 0.0509 0.0500 0.0486 0.0479 0.0474 0.0470 0.0467 

[TRAIN] Epoch[1](8050/114412); Loss: 0.104352; Backpropagation: 0.3010 sec; Batch: 2.1249 sec
0.2574 0.2204 0.1583 0.1230 0.1043 0.0896 0.0825 0.0778 0.0736 0.0718 0.0708 0.0696 0.0686 0.0680 0.0672 0.0666 

[TRAIN] Epoch[1](8051/114412); Loss: 0.071053; Backpropagation: 0.3000 sec; Batch: 2.1278 sec
0.1346 0.1258 0.0942 0.0839 0.0706 0.0658 0.0627 0.0606 0.0581 0.0568 0.0556 0.0547 0.0541 0.0535 0.0531 0.0528 

[TRAIN] Epoch[1](8052/114412); Loss: 0.097916; Backpropagation: 0.2959 sec; Batch: 2.1216 sec
0.1877 0.1791 0.1432 0.1239 0.1016 0.0913 0.0843 0.0788 0.0761 0.0742 0.0730 0.0720 0.0713 0.0707 0.0700 0.0695 

[TRAIN] Epoch[1](8053/114412); Loss: 0.132601; Backpropagation: 0.2952 sec; Batch: 2.0894 sec
0.2341 0.2186 0.1937 0.1760 0.1527 0.1353 0.1229 0.1127 0.1074 0.1024 0.0986 0.0964 0.0943 0.0930 0.0921 0.0914 

[TRAIN] Epoch[1](8054/114412); Loss: 0.095538; Backpropagation: 0.2952 sec; Batch: 2.1303 sec
0.1557 0.1460 0.1205 0.1110 0.0988 0.0926 0.0880 0.0856 0.0836 0.0816 0.0799 0.0787 0.0777 0.0770 0.0764 0.0757 

[TRAIN] Epoch[1](8055/114412); Loss: 0.087858; Backpropagation: 0.2974 sec; Batch: 2.1239 sec
0.1527 0.1378 0.1129 0.1030 0.0919 0.0860 0.0816 0.0784 0.0753 0.0726 0.0708 0.0697 0.0689 0.0685 0.0679 0.0677 

[TRAIN] Epoch[1](8056/114412); Loss: 0.101161; Backpropagation: 0.2980 sec; Batch: 2.1257 sec
0.1801 0.1567 0.1282 0.1160 0.1037 0.0964 0.0920 0.0892 0.0864 0.0851 0.0837 0.0821 0.0807 0.0801 0.0794 0.0788 

[TRAIN] Epoch[1](8057/114412); Loss: 0.074569; Backpropagation: 0.3007 sec; Batch: 2.1277 sec
0.1373 0.1284 0.1005 0.0899 0.0778 0.0705 0.0675 0.0647 0.0613 0.0596 0.0579 0.0568 0.0560 0.0554 0.0550 0.0545 

[TRAIN] Epoch[1](8058/114412); Loss: 0.080377; Backpropagation: 0.2982 sec; Batch: 2.1240 sec
0.1437 0.1348 0.1106 0.0996 0.0868 0.0782 0.0722 0.0687 0.0655 0.0634 0.0625 0.0612 0.0607 0.0601 0.0594 0.0588 

[TRAIN] Epoch[1](8059/114412); Loss: 0.088016; Backpropagation: 0.2951 sec; Batch: 2.1269 sec
0.1600 0.1503 0.1210 0.1116 0.0962 0.0906 0.0832 0.0779 0.0718 0.0681 0.0658 0.0643 0.0632 0.0622 0.0614 0.0607 

[TRAIN] Epoch[1](8060/114412); Loss: 0.089559; Backpropagation: 0.2960 sec; Batch: 2.1221 sec
0.1520 0.1361 0.1151 0.1024 0.0922 0.0870 0.0827 0.0797 0.0773 0.0754 0.0744 0.0731 0.0724 0.0717 0.0710 0.0705 

[TRAIN] Epoch[1](8061/114412); Loss: 0.104801; Backpropagation: 0.2958 sec; Batch: 2.1206 sec
0.1830 0.1733 0.1408 0.1299 0.1131 0.1038 0.0969 0.0909 0.0877 0.0844 0.0829 0.0818 0.0796 0.0779 0.0762 0.0745 

[TRAIN] Epoch[1](8062/114412); Loss: 0.087962; Backpropagation: 0.3003 sec; Batch: 2.1315 sec
0.1411 0.1232 0.1039 0.0961 0.0886 0.0847 0.0816 0.0798 0.0785 0.0774 0.0765 0.0760 0.0754 0.0751 0.0748 0.0746 

[TRAIN] Epoch[1](8063/114412); Loss: 0.060524; Backpropagation: 0.2981 sec; Batch: 2.1289 sec
0.1214 0.1165 0.0801 0.0656 0.0582 0.0535 0.0508 0.0494 0.0486 0.0484 0.0476 0.0466 0.0460 0.0455 0.0452 0.0451 

[TRAIN] Epoch[1](8064/114412); Loss: 0.104021; Backpropagation: 0.2979 sec; Batch: 2.1275 sec
0.1938 0.1850 0.1499 0.1331 0.1113 0.0989 0.0890 0.0845 0.0822 0.0803 0.0797 0.0776 0.0759 0.0749 0.0744 0.0739 

[TRAIN] Epoch[1](8065/114412); Loss: 0.070817; Backpropagation: 0.2952 sec; Batch: 2.1198 sec
0.1374 0.1297 0.0949 0.0857 0.0759 0.0682 0.0636 0.0605 0.0570 0.0549 0.0535 0.0520 0.0513 0.0503 0.0494 0.0488 

[TRAIN] Epoch[1](8066/114412); Loss: 0.064684; Backpropagation: 0.2957 sec; Batch: 2.1250 sec
0.1290 0.1226 0.0873 0.0726 0.0648 0.0596 0.0553 0.0528 0.0513 0.0505 0.0491 0.0486 0.0482 0.0479 0.0476 0.0476 

[TRAIN] Epoch[1](8067/114412); Loss: 0.109222; Backpropagation: 0.2982 sec; Batch: 2.1436 sec
0.1882 0.1789 0.1490 0.1366 0.1172 0.1059 0.0983 0.0947 0.0919 0.0889 0.0864 0.0847 0.0833 0.0820 0.0811 0.0804 

[TRAIN] Epoch[1](8068/114412); Loss: 0.078525; Backpropagation: 0.2981 sec; Batch: 2.1262 sec
0.1577 0.1378 0.1046 0.0920 0.0778 0.0721 0.0680 0.0658 0.0638 0.0620 0.0608 0.0599 0.0592 0.0586 0.0583 0.0579 

[TRAIN] Epoch[1](8069/114412); Loss: 0.108180; Backpropagation: 0.2956 sec; Batch: 2.1189 sec
0.1771 0.1669 0.1366 0.1250 0.1127 0.1060 0.0994 0.0973 0.0942 0.0918 0.0900 0.0886 0.0875 0.0869 0.0858 0.0852 

[TRAIN] Epoch[1](8070/114412); Loss: 0.125006; Backpropagation: 0.2948 sec; Batch: 2.1213 sec
0.2686 0.2504 0.2030 0.1823 0.1412 0.1172 0.1041 0.0932 0.0872 0.0842 0.0820 0.0801 0.0784 0.0772 0.0760 0.0750 

[TRAIN] Epoch[1](8071/114412); Loss: 0.065922; Backpropagation: 0.2962 sec; Batch: 2.0835 sec
0.1492 0.1417 0.0895 0.0735 0.0606 0.0563 0.0531 0.0528 0.0503 0.0490 0.0482 0.0468 0.0464 0.0461 0.0458 0.0456 

[TRAIN] Epoch[1](8072/114412); Loss: 0.067513; Backpropagation: 0.2976 sec; Batch: 2.1226 sec
0.1555 0.1460 0.0955 0.0754 0.0664 0.0591 0.0544 0.0510 0.0497 0.0485 0.0479 0.0470 0.0462 0.0461 0.0458 0.0456 

[TRAIN] Epoch[1](8073/114412); Loss: 0.066786; Backpropagation: 0.2979 sec; Batch: 2.1248 sec
0.1396 0.1339 0.0834 0.0713 0.0650 0.0606 0.0568 0.0546 0.0529 0.0517 0.0509 0.0501 0.0497 0.0495 0.0494 0.0490 

[TRAIN] Epoch[1](8074/114412); Loss: 0.079060; Backpropagation: 0.2979 sec; Batch: 2.1271 sec
0.1350 0.1158 0.0965 0.0884 0.0818 0.0783 0.0736 0.0707 0.0688 0.0677 0.0668 0.0654 0.0650 0.0643 0.0637 0.0632 

[TRAIN] Epoch[1](8075/114412); Loss: 0.069378; Backpropagation: 0.2955 sec; Batch: 2.0987 sec
0.1732 0.1483 0.1027 0.0854 0.0682 0.0584 0.0549 0.0523 0.0496 0.0481 0.0471 0.0457 0.0451 0.0443 0.0437 0.0432 

[TRAIN] Epoch[1](8076/114412); Loss: 0.060682; Backpropagation: 0.2981 sec; Batch: 2.1288 sec
0.1253 0.1148 0.0789 0.0671 0.0654 0.0579 0.0530 0.0508 0.0483 0.0468 0.0453 0.0444 0.0439 0.0433 0.0430 0.0428 

[TRAIN] Epoch[1](8077/114412); Loss: 0.061463; Backpropagation: 0.2980 sec; Batch: 2.1294 sec
0.1290 0.1030 0.0815 0.0668 0.0593 0.0572 0.0538 0.0516 0.0501 0.0487 0.0480 0.0476 0.0472 0.0468 0.0465 0.0464 

[TRAIN] Epoch[1](8078/114412); Loss: 0.101159; Backpropagation: 0.2952 sec; Batch: 2.1174 sec
0.2015 0.1854 0.1362 0.1180 0.1018 0.0929 0.0875 0.0839 0.0809 0.0785 0.0772 0.0764 0.0754 0.0746 0.0743 0.0740 

[TRAIN] Epoch[1](8079/114412); Loss: 0.109207; Backpropagation: 0.2953 sec; Batch: 2.1230 sec
0.1661 0.1544 0.1332 0.1238 0.1110 0.1054 0.1018 0.1000 0.0979 0.0963 0.0951 0.0940 0.0931 0.0923 0.0917 0.0913 

[TRAIN] Epoch[1](8080/114412); Loss: 0.083631; Backpropagation: 0.2954 sec; Batch: 2.1244 sec
0.1782 0.1627 0.1218 0.1069 0.0867 0.0746 0.0682 0.0654 0.0627 0.0610 0.0600 0.0587 0.0582 0.0579 0.0576 0.0574 

[TRAIN] Epoch[1](8081/114412); Loss: 0.105006; Backpropagation: 0.2978 sec; Batch: 2.0843 sec
0.2022 0.1853 0.1551 0.1375 0.1123 0.0965 0.0879 0.0841 0.0808 0.0789 0.0784 0.0773 0.0769 0.0762 0.0755 0.0751 

[TRAIN] Epoch[1](8082/114412); Loss: 0.082627; Backpropagation: 0.3010 sec; Batch: 2.1279 sec
0.1547 0.1407 0.1105 0.0963 0.0859 0.0789 0.0740 0.0705 0.0681 0.0661 0.0647 0.0639 0.0628 0.0622 0.0616 0.0613 

[TRAIN] Epoch[1](8083/114412); Loss: 0.098231; Backpropagation: 0.3021 sec; Batch: 2.0881 sec
0.1742 0.1524 0.1275 0.1133 0.1028 0.0957 0.0896 0.0867 0.0839 0.0819 0.0802 0.0785 0.0776 0.0765 0.0759 0.0751 

[TRAIN] Epoch[1](8084/114412); Loss: 0.080783; Backpropagation: 0.2950 sec; Batch: 2.1178 sec
0.1343 0.1195 0.0966 0.0892 0.0818 0.0781 0.0760 0.0735 0.0718 0.0700 0.0684 0.0677 0.0671 0.0665 0.0662 0.0659 

[TRAIN] Epoch[1](8085/114412); Loss: 0.063399; Backpropagation: 0.2949 sec; Batch: 2.0828 sec
0.1291 0.1219 0.0920 0.0779 0.0646 0.0592 0.0539 0.0517 0.0493 0.0473 0.0462 0.0453 0.0446 0.0442 0.0438 0.0434 

[TRAIN] Epoch[1](8086/114412); Loss: 0.105473; Backpropagation: 0.2951 sec; Batch: 2.1165 sec
0.1718 0.1620 0.1333 0.1215 0.1102 0.1015 0.0962 0.0929 0.0908 0.0895 0.0883 0.0873 0.0867 0.0857 0.0851 0.0848 

[TRAIN] Epoch[1](8087/114412); Loss: 0.073546; Backpropagation: 0.2946 sec; Batch: 2.0887 sec
0.1347 0.1232 0.1015 0.0903 0.0776 0.0702 0.0656 0.0628 0.0606 0.0590 0.0576 0.0562 0.0553 0.0547 0.0539 0.0535 

[TRAIN] Epoch[1](8088/114412); Loss: 0.081781; Backpropagation: 0.2958 sec; Batch: 2.1140 sec
0.1343 0.1254 0.1007 0.0929 0.0848 0.0793 0.0761 0.0740 0.0716 0.0699 0.0685 0.0673 0.0668 0.0662 0.0657 0.0651 

[TRAIN] Epoch[1](8089/114412); Loss: 0.091615; Backpropagation: 0.2949 sec; Batch: 2.0811 sec
0.1703 0.1575 0.1194 0.1059 0.0911 0.0827 0.0780 0.0766 0.0749 0.0747 0.0742 0.0730 0.0725 0.0720 0.0716 0.0713 

[TRAIN] Epoch[1](8090/114412); Loss: 0.097633; Backpropagation: 0.2959 sec; Batch: 2.1201 sec
0.1731 0.1606 0.1373 0.1264 0.1079 0.0962 0.0887 0.0836 0.0797 0.0767 0.0745 0.0729 0.0721 0.0714 0.0707 0.0702 

[TRAIN] Epoch[1](8091/114412); Loss: 0.067585; Backpropagation: 0.2950 sec; Batch: 2.0812 sec
0.1146 0.1100 0.0835 0.0749 0.0689 0.0644 0.0611 0.0597 0.0590 0.0576 0.0565 0.0557 0.0548 0.0541 0.0535 0.0531 

[TRAIN] Epoch[1](8092/114412); Loss: 0.086958; Backpropagation: 0.2963 sec; Batch: 2.1026 sec
0.1811 0.1651 0.1296 0.1114 0.0945 0.0805 0.0732 0.0687 0.0661 0.0642 0.0620 0.0609 0.0601 0.0591 0.0579 0.0570 

[TRAIN] Epoch[1](8093/114412); Loss: 0.095304; Backpropagation: 0.2982 sec; Batch: 2.1229 sec
0.1833 0.1717 0.1376 0.1231 0.1042 0.0900 0.0826 0.0794 0.0743 0.0710 0.0698 0.0688 0.0683 0.0674 0.0669 0.0665 

[TRAIN] Epoch[1](8094/114412); Loss: 0.082451; Backpropagation: 0.2953 sec; Batch: 2.1264 sec
0.1821 0.1573 0.1105 0.0900 0.0830 0.0747 0.0702 0.0677 0.0652 0.0629 0.0615 0.0603 0.0593 0.0586 0.0583 0.0578 

[TRAIN] Epoch[1](8095/114412); Loss: 0.097271; Backpropagation: 0.2954 sec; Batch: 2.1180 sec
0.2353 0.2084 0.1525 0.1257 0.0955 0.0800 0.0751 0.0708 0.0684 0.0664 0.0648 0.0641 0.0632 0.0625 0.0620 0.0618 

[TRAIN] Epoch[1](8096/114412); Loss: 0.070428; Backpropagation: 0.2960 sec; Batch: 2.1220 sec
0.1528 0.1355 0.0946 0.0833 0.0712 0.0636 0.0590 0.0576 0.0548 0.0533 0.0521 0.0510 0.0503 0.0497 0.0492 0.0489 

[TRAIN] Epoch[1](8097/114412); Loss: 0.088741; Backpropagation: 0.2955 sec; Batch: 2.1213 sec
0.2376 0.2065 0.1491 0.1204 0.0861 0.0738 0.0656 0.0602 0.0569 0.0549 0.0533 0.0523 0.0518 0.0511 0.0503 0.0500 

[TRAIN] Epoch[1](8098/114412); Loss: 0.110406; Backpropagation: 0.2984 sec; Batch: 2.1242 sec
0.2064 0.1862 0.1472 0.1352 0.1210 0.1092 0.1005 0.0936 0.0902 0.0875 0.0851 0.0835 0.0819 0.0805 0.0796 0.0788 

[TRAIN] Epoch[1](8099/114412); Loss: 0.091360; Backpropagation: 0.2956 sec; Batch: 2.1224 sec
0.1574 0.1492 0.1246 0.1124 0.1019 0.0915 0.0851 0.0800 0.0759 0.0736 0.0714 0.0696 0.0685 0.0675 0.0669 0.0664 

[TRAIN] Epoch[1](8100/114412); Loss: 0.083009; Backpropagation: 0.2957 sec; Batch: 2.1292 sec
0.1562 0.1401 0.1082 0.0943 0.0840 0.0782 0.0738 0.0714 0.0692 0.0676 0.0662 0.0651 0.0643 0.0637 0.0632 0.0626 

[TRAIN] Epoch[1](8101/114412); Loss: 0.093695; Backpropagation: 0.2952 sec; Batch: 2.0820 sec
0.2216 0.2002 0.1548 0.1365 0.1122 0.0941 0.0798 0.0682 0.0605 0.0587 0.0551 0.0531 0.0522 0.0514 0.0507 0.0500 

[TRAIN] Epoch[1](8102/114412); Loss: 0.055073; Backpropagation: 0.2952 sec; Batch: 2.0822 sec
0.1057 0.0930 0.0671 0.0608 0.0558 0.0516 0.0495 0.0482 0.0460 0.0447 0.0441 0.0433 0.0431 0.0431 0.0427 0.0427 

[TRAIN] Epoch[1](8103/114412); Loss: 0.108208; Backpropagation: 0.2980 sec; Batch: 2.1209 sec
0.1736 0.1634 0.1430 0.1332 0.1201 0.1116 0.1032 0.0966 0.0923 0.0895 0.0870 0.0855 0.0843 0.0833 0.0827 0.0821 

[TRAIN] Epoch[1](8104/114412); Loss: 0.079807; Backpropagation: 0.2954 sec; Batch: 2.1224 sec
0.1494 0.1365 0.1037 0.0951 0.0783 0.0753 0.0706 0.0689 0.0673 0.0649 0.0634 0.0620 0.0613 0.0605 0.0600 0.0598 

[TRAIN] Epoch[1](8105/114412); Loss: 0.079082; Backpropagation: 0.2958 sec; Batch: 2.1215 sec
0.1478 0.1301 0.1089 0.0974 0.0841 0.0755 0.0706 0.0679 0.0652 0.0627 0.0613 0.0600 0.0592 0.0587 0.0581 0.0579 

[TRAIN] Epoch[1](8106/114412); Loss: 0.075018; Backpropagation: 0.2979 sec; Batch: 2.1090 sec
0.1185 0.1012 0.0956 0.0779 0.0752 0.0732 0.0706 0.0695 0.0670 0.0660 0.0656 0.0647 0.0645 0.0638 0.0635 0.0635 

[TRAIN] Epoch[1](8107/114412); Loss: 0.132066; Backpropagation: 0.2978 sec; Batch: 2.1259 sec
0.2361 0.2195 0.1847 0.1724 0.1537 0.1362 0.1215 0.1096 0.1042 0.1017 0.0987 0.0972 0.0955 0.0947 0.0939 0.0934 

[TRAIN] Epoch[1](8108/114412); Loss: 0.073623; Backpropagation: 0.2955 sec; Batch: 2.1186 sec
0.1508 0.1405 0.1086 0.0904 0.0728 0.0654 0.0601 0.0588 0.0571 0.0562 0.0548 0.0536 0.0530 0.0523 0.0520 0.0516 

[TRAIN] Epoch[1](8109/114412); Loss: 0.073704; Backpropagation: 0.2956 sec; Batch: 2.1215 sec
0.1442 0.1333 0.0960 0.0858 0.0741 0.0680 0.0632 0.0616 0.0593 0.0581 0.0574 0.0565 0.0560 0.0556 0.0551 0.0550 

[TRAIN] Epoch[1](8110/114412); Loss: 0.066090; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.1543 0.1478 0.1027 0.0835 0.0634 0.0546 0.0511 0.0486 0.0473 0.0457 0.0444 0.0436 0.0429 0.0428 0.0425 0.0423 

[TRAIN] Epoch[1](8111/114412); Loss: 0.097612; Backpropagation: 0.2957 sec; Batch: 2.1246 sec
0.1497 0.1325 0.1142 0.1058 0.0997 0.0952 0.0912 0.0894 0.0877 0.0871 0.0862 0.0853 0.0848 0.0846 0.0844 0.0840 

[TRAIN] Epoch[1](8112/114412); Loss: 0.084129; Backpropagation: 0.2955 sec; Batch: 2.1228 sec
0.1591 0.1430 0.1086 0.0977 0.0857 0.0808 0.0760 0.0724 0.0699 0.0681 0.0659 0.0652 0.0645 0.0634 0.0631 0.0627 

[TRAIN] Epoch[1](8113/114412); Loss: 0.065584; Backpropagation: 0.2979 sec; Batch: 2.1028 sec
0.1249 0.1244 0.0839 0.0724 0.0662 0.0576 0.0551 0.0561 0.0537 0.0525 0.0516 0.0507 0.0506 0.0500 0.0498 0.0497 

[TRAIN] Epoch[1](8114/114412); Loss: 0.095111; Backpropagation: 0.2956 sec; Batch: 2.1207 sec
0.1497 0.1390 0.1145 0.1053 0.0980 0.0928 0.0891 0.0874 0.0847 0.0828 0.0819 0.0806 0.0798 0.0792 0.0787 0.0784 

[TRAIN] Epoch[1](8115/114412); Loss: 0.061071; Backpropagation: 0.2955 sec; Batch: 2.1223 sec
0.1165 0.1067 0.0828 0.0735 0.0655 0.0607 0.0553 0.0523 0.0495 0.0479 0.0464 0.0451 0.0444 0.0439 0.0435 0.0432 

[TRAIN] Epoch[1](8116/114412); Loss: 0.126647; Backpropagation: 0.2980 sec; Batch: 2.1239 sec
0.3058 0.2647 0.1934 0.1561 0.1267 0.1097 0.1032 0.0982 0.0945 0.0891 0.0863 0.0834 0.0810 0.0795 0.0778 0.0769 

[TRAIN] Epoch[1](8117/114412); Loss: 0.088298; Backpropagation: 0.2954 sec; Batch: 2.1210 sec
0.1379 0.1231 0.1054 0.0972 0.0929 0.0874 0.0837 0.0815 0.0789 0.0779 0.0768 0.0754 0.0745 0.0739 0.0732 0.0730 

[TRAIN] Epoch[1](8118/114412); Loss: 0.071462; Backpropagation: 0.3006 sec; Batch: 2.1242 sec
0.1298 0.1216 0.0956 0.0831 0.0741 0.0675 0.0636 0.0617 0.0596 0.0580 0.0567 0.0557 0.0550 0.0542 0.0538 0.0534 

[TRAIN] Epoch[1](8119/114412); Loss: 0.094388; Backpropagation: 0.2991 sec; Batch: 2.1282 sec
0.1587 0.1374 0.1202 0.1096 0.0988 0.0915 0.0868 0.0846 0.0824 0.0808 0.0794 0.0777 0.0766 0.0759 0.0752 0.0746 

[TRAIN] Epoch[1](8120/114412); Loss: 0.078052; Backpropagation: 0.2955 sec; Batch: 2.1335 sec
0.1282 0.1208 0.0993 0.0892 0.0819 0.0763 0.0716 0.0695 0.0675 0.0658 0.0649 0.0640 0.0632 0.0627 0.0622 0.0618 

[TRAIN] Epoch[1](8121/114412); Loss: 0.066931; Backpropagation: 0.2983 sec; Batch: 2.0854 sec
0.1038 0.0953 0.0803 0.0757 0.0717 0.0654 0.0621 0.0612 0.0596 0.0582 0.0574 0.0569 0.0562 0.0558 0.0557 0.0555 

[TRAIN] Epoch[1](8122/114412); Loss: 0.091801; Backpropagation: 0.2955 sec; Batch: 2.0815 sec
0.2062 0.1750 0.1375 0.1174 0.0956 0.0800 0.0735 0.0701 0.0677 0.0665 0.0652 0.0639 0.0632 0.0626 0.0623 0.0620 

[TRAIN] Epoch[1](8123/114412); Loss: 0.093726; Backpropagation: 0.2954 sec; Batch: 2.1352 sec
0.1684 0.1548 0.1268 0.1144 0.1007 0.0912 0.0851 0.0804 0.0773 0.0750 0.0732 0.0719 0.0711 0.0704 0.0697 0.0694 

[TRAIN] Epoch[1](8124/114412); Loss: 0.070923; Backpropagation: 0.2957 sec; Batch: 2.1199 sec
0.1569 0.1399 0.0934 0.0783 0.0689 0.0634 0.0598 0.0570 0.0548 0.0537 0.0528 0.0522 0.0516 0.0510 0.0506 0.0505 

[TRAIN] Epoch[1](8125/114412); Loss: 0.108969; Backpropagation: 0.2953 sec; Batch: 2.1226 sec
0.1860 0.1701 0.1380 0.1274 0.1139 0.1054 0.0984 0.0950 0.0926 0.0905 0.0892 0.0881 0.0872 0.0871 0.0873 0.0875 

[TRAIN] Epoch[1](8126/114412); Loss: 0.096359; Backpropagation: 0.3005 sec; Batch: 2.1260 sec
0.1916 0.1723 0.1339 0.1170 0.0983 0.0873 0.0820 0.0789 0.0763 0.0743 0.0732 0.0722 0.0717 0.0713 0.0709 0.0706 

[TRAIN] Epoch[1](8127/114412); Loss: 0.067344; Backpropagation: 0.2981 sec; Batch: 2.1355 sec
0.1404 0.1336 0.0988 0.0825 0.0661 0.0591 0.0557 0.0539 0.0512 0.0498 0.0490 0.0483 0.0477 0.0473 0.0470 0.0470 

[TRAIN] Epoch[1](8128/114412); Loss: 0.100111; Backpropagation: 0.2951 sec; Batch: 2.1181 sec
0.1911 0.1744 0.1409 0.1218 0.1051 0.0939 0.0879 0.0831 0.0813 0.0784 0.0767 0.0752 0.0742 0.0732 0.0724 0.0721 

[TRAIN] Epoch[1](8129/114412); Loss: 0.069243; Backpropagation: 0.2954 sec; Batch: 2.1199 sec
0.1272 0.1265 0.0896 0.0837 0.0715 0.0645 0.0604 0.0599 0.0574 0.0555 0.0539 0.0528 0.0520 0.0515 0.0509 0.0505 

[TRAIN] Epoch[1](8130/114412); Loss: 0.077138; Backpropagation: 0.2958 sec; Batch: 2.1242 sec
0.1722 0.1545 0.1191 0.1022 0.0765 0.0696 0.0633 0.0598 0.0567 0.0549 0.0532 0.0520 0.0510 0.0502 0.0498 0.0494 

[TRAIN] Epoch[1](8131/114412); Loss: 0.078503; Backpropagation: 0.2958 sec; Batch: 2.1188 sec
0.1665 0.1522 0.1154 0.0991 0.0806 0.0736 0.0674 0.0640 0.0608 0.0582 0.0559 0.0543 0.0531 0.0522 0.0516 0.0511 

[TRAIN] Epoch[1](8132/114412); Loss: 0.096523; Backpropagation: 0.2955 sec; Batch: 2.1205 sec
0.1674 0.1539 0.1264 0.1153 0.1046 0.0961 0.0895 0.0852 0.0811 0.0787 0.0772 0.0754 0.0743 0.0737 0.0731 0.0725 

[TRAIN] Epoch[1](8133/114412); Loss: 0.122118; Backpropagation: 0.2985 sec; Batch: 2.1261 sec
0.2428 0.2208 0.1840 0.1670 0.1395 0.1191 0.1063 0.0972 0.0915 0.0886 0.0862 0.0842 0.0830 0.0820 0.0813 0.0804 

[TRAIN] Epoch[1](8134/114412); Loss: 0.065955; Backpropagation: 0.2957 sec; Batch: 2.1212 sec
0.1000 0.0921 0.0782 0.0730 0.0697 0.0651 0.0620 0.0602 0.0594 0.0584 0.0572 0.0566 0.0562 0.0559 0.0556 0.0553 

[TRAIN] Epoch[1](8135/114412); Loss: 0.083709; Backpropagation: 0.2983 sec; Batch: 2.1262 sec
0.1457 0.1358 0.1040 0.0925 0.0850 0.0810 0.0767 0.0747 0.0723 0.0706 0.0693 0.0681 0.0671 0.0662 0.0653 0.0650 

[TRAIN] Epoch[1](8136/114412); Loss: 0.117190; Backpropagation: 0.2951 sec; Batch: 2.1208 sec
0.2298 0.2120 0.1647 0.1489 0.1235 0.1093 0.0993 0.0929 0.0907 0.0900 0.0886 0.0872 0.0857 0.0849 0.0843 0.0833 

[TRAIN] Epoch[1](8137/114412); Loss: 0.099156; Backpropagation: 0.2957 sec; Batch: 2.1237 sec
0.1536 0.1400 0.1251 0.1142 0.1063 0.0982 0.0947 0.0912 0.0884 0.0862 0.0844 0.0828 0.0817 0.0807 0.0797 0.0791 

[TRAIN] Epoch[1](8138/114412); Loss: 0.082751; Backpropagation: 0.2979 sec; Batch: 2.1235 sec
0.1624 0.1451 0.1119 0.0981 0.0866 0.0784 0.0723 0.0696 0.0669 0.0649 0.0635 0.0624 0.0614 0.0607 0.0601 0.0597 

[TRAIN] Epoch[1](8139/114412); Loss: 0.061543; Backpropagation: 0.2955 sec; Batch: 2.1236 sec
0.1246 0.1083 0.0843 0.0703 0.0607 0.0574 0.0538 0.0516 0.0498 0.0484 0.0475 0.0464 0.0459 0.0455 0.0451 0.0450 

[TRAIN] Epoch[1](8140/114412); Loss: 0.089183; Backpropagation: 0.2957 sec; Batch: 2.1211 sec
0.1867 0.1745 0.1407 0.1234 0.0991 0.0820 0.0758 0.0712 0.0660 0.0630 0.0606 0.0589 0.0576 0.0566 0.0559 0.0550 

[TRAIN] Epoch[1](8141/114412); Loss: 0.151397; Backpropagation: 0.2954 sec; Batch: 2.1177 sec
0.2090 0.1923 0.1686 0.1622 0.1557 0.1514 0.1469 0.1440 0.1413 0.1391 0.1376 0.1366 0.1355 0.1347 0.1341 0.1334 

[TRAIN] Epoch[1](8142/114412); Loss: 0.067281; Backpropagation: 0.2956 sec; Batch: 2.1214 sec
0.1383 0.1320 0.0866 0.0770 0.0636 0.0586 0.0566 0.0550 0.0535 0.0523 0.0516 0.0507 0.0503 0.0502 0.0502 0.0499 

[TRAIN] Epoch[1](8143/114412); Loss: 0.074884; Backpropagation: 0.2956 sec; Batch: 2.1222 sec
0.1309 0.1226 0.0973 0.0860 0.0770 0.0717 0.0671 0.0647 0.0627 0.0615 0.0608 0.0601 0.0596 0.0590 0.0587 0.0585 

[TRAIN] Epoch[1](8144/114412); Loss: 0.063403; Backpropagation: 0.2958 sec; Batch: 2.1181 sec
0.1208 0.1189 0.0796 0.0715 0.0633 0.0585 0.0550 0.0547 0.0529 0.0508 0.0494 0.0488 0.0484 0.0475 0.0472 0.0472 

[TRAIN] Epoch[1](8145/114412); Loss: 0.074532; Backpropagation: 0.2957 sec; Batch: 2.0872 sec
0.1461 0.1381 0.0980 0.0880 0.0772 0.0720 0.0654 0.0624 0.0609 0.0576 0.0562 0.0553 0.0545 0.0541 0.0536 0.0531 

[TRAIN] Epoch[1](8146/114412); Loss: 0.095822; Backpropagation: 0.2954 sec; Batch: 2.0826 sec
0.1814 0.1652 0.1304 0.1094 0.0956 0.0921 0.0868 0.0826 0.0797 0.0768 0.0753 0.0736 0.0722 0.0714 0.0708 0.0698 

[TRAIN] Epoch[1](8147/114412); Loss: 0.110007; Backpropagation: 0.2954 sec; Batch: 2.1215 sec
0.2102 0.1976 0.1521 0.1351 0.1104 0.0996 0.0936 0.0897 0.0875 0.0863 0.0850 0.0840 0.0832 0.0824 0.0818 0.0815 

[TRAIN] Epoch[1](8148/114412); Loss: 0.083014; Backpropagation: 0.3004 sec; Batch: 2.1278 sec
0.1398 0.1355 0.1066 0.0985 0.0859 0.0796 0.0752 0.0728 0.0711 0.0688 0.0676 0.0666 0.0658 0.0652 0.0648 0.0644 

[TRAIN] Epoch[1](8149/114412); Loss: 0.091205; Backpropagation: 0.2980 sec; Batch: 2.1260 sec
0.1476 0.1307 0.1111 0.1016 0.0938 0.0889 0.0845 0.0828 0.0808 0.0794 0.0785 0.0775 0.0764 0.0757 0.0752 0.0748 

[TRAIN] Epoch[1](8150/114412); Loss: 0.089913; Backpropagation: 0.2982 sec; Batch: 2.1232 sec
0.1935 0.1707 0.1267 0.1051 0.0847 0.0787 0.0751 0.0736 0.0710 0.0690 0.0677 0.0663 0.0652 0.0644 0.0636 0.0631 

[TRAIN] Epoch[1](8151/114412); Loss: 0.081190; Backpropagation: 0.2962 sec; Batch: 2.1199 sec
0.1939 0.1664 0.1242 0.0995 0.0776 0.0691 0.0639 0.0615 0.0593 0.0578 0.0566 0.0554 0.0543 0.0536 0.0532 0.0527 

[TRAIN] Epoch[1](8152/114412); Loss: 0.113423; Backpropagation: 0.2948 sec; Batch: 2.1227 sec
0.2167 0.1837 0.1385 0.1159 0.1093 0.1066 0.1027 0.0987 0.0970 0.0951 0.0931 0.0926 0.0925 0.0915 0.0907 0.0902 

[TRAIN] Epoch[1](8153/114412); Loss: 0.095932; Backpropagation: 0.3010 sec; Batch: 2.1246 sec
0.1642 0.1508 0.1214 0.1120 0.1035 0.0960 0.0903 0.0859 0.0823 0.0798 0.0780 0.0766 0.0750 0.0740 0.0730 0.0721 

[TRAIN] Epoch[1](8154/114412); Loss: 0.085472; Backpropagation: 0.3011 sec; Batch: 2.1302 sec
0.1733 0.1560 0.1210 0.1050 0.0889 0.0794 0.0737 0.0703 0.0674 0.0653 0.0638 0.0621 0.0612 0.0606 0.0600 0.0596 

[TRAIN] Epoch[1](8155/114412); Loss: 0.117145; Backpropagation: 0.3004 sec; Batch: 2.1276 sec
0.2266 0.2053 0.1643 0.1465 0.1198 0.1058 0.0996 0.0960 0.0937 0.0912 0.0894 0.0885 0.0880 0.0871 0.0864 0.0862 

[TRAIN] Epoch[1](8156/114412); Loss: 0.075131; Backpropagation: 0.2981 sec; Batch: 2.1283 sec
0.1675 0.1537 0.1211 0.1056 0.0834 0.0702 0.0609 0.0563 0.0524 0.0495 0.0485 0.0480 0.0471 0.0464 0.0460 0.0457 

[TRAIN] Epoch[1](8157/114412); Loss: 0.097490; Backpropagation: 0.2982 sec; Batch: 2.1227 sec
0.1937 0.1847 0.1485 0.1338 0.1075 0.0923 0.0833 0.0773 0.0735 0.0709 0.0687 0.0670 0.0659 0.0649 0.0642 0.0635 

[TRAIN] Epoch[1](8158/114412); Loss: 0.090879; Backpropagation: 0.2951 sec; Batch: 2.1205 sec
0.1491 0.1402 0.1274 0.1159 0.1020 0.0923 0.0851 0.0801 0.0755 0.0731 0.0717 0.0703 0.0690 0.0681 0.0674 0.0668 

[TRAIN] Epoch[1](8159/114412); Loss: 0.073605; Backpropagation: 0.2955 sec; Batch: 2.1240 sec
0.1576 0.1403 0.1040 0.0896 0.0757 0.0676 0.0632 0.0597 0.0575 0.0552 0.0534 0.0522 0.0514 0.0507 0.0501 0.0496 

[TRAIN] Epoch[1](8160/114412); Loss: 0.077013; Backpropagation: 0.2978 sec; Batch: 2.1218 sec
0.1779 0.1602 0.1046 0.0929 0.0739 0.0678 0.0652 0.0608 0.0579 0.0560 0.0540 0.0531 0.0524 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](8161/114412); Loss: 0.050589; Backpropagation: 0.2965 sec; Batch: 2.1217 sec
0.1056 0.0998 0.0652 0.0585 0.0498 0.0463 0.0434 0.0409 0.0397 0.0387 0.0378 0.0374 0.0368 0.0366 0.0366 0.0363 

[TRAIN] Epoch[1](8162/114412); Loss: 0.080761; Backpropagation: 0.2978 sec; Batch: 2.1225 sec
0.1338 0.1273 0.1027 0.0930 0.0839 0.0787 0.0742 0.0719 0.0696 0.0677 0.0668 0.0657 0.0650 0.0644 0.0639 0.0635 

[TRAIN] Epoch[1](8163/114412); Loss: 0.091557; Backpropagation: 0.2953 sec; Batch: 2.1244 sec
0.2075 0.1879 0.1503 0.1364 0.1055 0.0842 0.0722 0.0655 0.0628 0.0599 0.0583 0.0567 0.0555 0.0546 0.0541 0.0534 

[TRAIN] Epoch[1](8164/114412); Loss: 0.076103; Backpropagation: 0.2954 sec; Batch: 2.1251 sec
0.1635 0.1451 0.1197 0.1046 0.0825 0.0696 0.0606 0.0569 0.0552 0.0535 0.0531 0.0520 0.0510 0.0505 0.0501 0.0498 

[TRAIN] Epoch[1](8165/114412); Loss: 0.106640; Backpropagation: 0.2981 sec; Batch: 2.1243 sec
0.1921 0.1719 0.1435 0.1284 0.1175 0.1038 0.0979 0.0927 0.0874 0.0847 0.0835 0.0822 0.0811 0.0805 0.0797 0.0792 

[TRAIN] Epoch[1](8166/114412); Loss: 0.076652; Backpropagation: 0.2951 sec; Batch: 2.1244 sec
0.1416 0.1321 0.1072 0.0912 0.0821 0.0711 0.0680 0.0652 0.0636 0.0618 0.0594 0.0586 0.0574 0.0565 0.0557 0.0550 

[TRAIN] Epoch[1](8167/114412); Loss: 0.077179; Backpropagation: 0.2957 sec; Batch: 2.1238 sec
0.1459 0.1373 0.1003 0.0894 0.0801 0.0737 0.0683 0.0659 0.0637 0.0615 0.0602 0.0591 0.0582 0.0576 0.0570 0.0566 

[TRAIN] Epoch[1](8168/114412); Loss: 0.078815; Backpropagation: 0.2981 sec; Batch: 2.1245 sec
0.1384 0.1199 0.0924 0.0860 0.0813 0.0770 0.0749 0.0713 0.0690 0.0667 0.0658 0.0652 0.0641 0.0633 0.0629 0.0627 

[TRAIN] Epoch[1](8169/114412); Loss: 0.074361; Backpropagation: 0.2976 sec; Batch: 2.1221 sec
0.1258 0.1156 0.0950 0.0856 0.0794 0.0741 0.0688 0.0657 0.0640 0.0620 0.0610 0.0597 0.0590 0.0584 0.0579 0.0576 

[TRAIN] Epoch[1](8170/114412); Loss: 0.103862; Backpropagation: 0.2951 sec; Batch: 2.1181 sec
0.1697 0.1593 0.1384 0.1302 0.1170 0.1056 0.0971 0.0927 0.0891 0.0861 0.0835 0.0813 0.0796 0.0783 0.0774 0.0765 

[TRAIN] Epoch[1](8171/114412); Loss: 0.081346; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.1311 0.1239 0.0991 0.0902 0.0835 0.0785 0.0752 0.0732 0.0713 0.0700 0.0691 0.0683 0.0677 0.0672 0.0669 0.0665 

[TRAIN] Epoch[1](8172/114412); Loss: 0.076113; Backpropagation: 0.2954 sec; Batch: 2.0815 sec
0.1428 0.1239 0.1018 0.0884 0.0817 0.0721 0.0670 0.0648 0.0629 0.0614 0.0605 0.0594 0.0587 0.0580 0.0574 0.0570 

[TRAIN] Epoch[1](8173/114412); Loss: 0.076242; Backpropagation: 0.2995 sec; Batch: 2.0867 sec
0.1199 0.1127 0.0920 0.0837 0.0764 0.0730 0.0705 0.0692 0.0679 0.0665 0.0658 0.0652 0.0646 0.0643 0.0642 0.0641 

[TRAIN] Epoch[1](8174/114412); Loss: 0.074375; Backpropagation: 0.3004 sec; Batch: 2.1299 sec
0.1320 0.1174 0.0961 0.0869 0.0794 0.0700 0.0668 0.0662 0.0625 0.0611 0.0602 0.0589 0.0588 0.0583 0.0578 0.0577 

[TRAIN] Epoch[1](8175/114412); Loss: 0.073329; Backpropagation: 0.2948 sec; Batch: 2.0815 sec
0.1299 0.1189 0.0936 0.0869 0.0774 0.0707 0.0669 0.0646 0.0620 0.0602 0.0587 0.0578 0.0572 0.0566 0.0561 0.0558 

[TRAIN] Epoch[1](8176/114412); Loss: 0.089496; Backpropagation: 0.2953 sec; Batch: 2.1209 sec
0.1401 0.1334 0.1074 0.0970 0.0945 0.0887 0.0838 0.0832 0.0795 0.0770 0.0765 0.0758 0.0746 0.0741 0.0735 0.0729 

[TRAIN] Epoch[1](8177/114412); Loss: 0.085677; Backpropagation: 0.2957 sec; Batch: 2.0823 sec
0.1445 0.1361 0.1122 0.1012 0.0912 0.0830 0.0779 0.0756 0.0732 0.0712 0.0700 0.0688 0.0676 0.0666 0.0661 0.0657 

[TRAIN] Epoch[1](8178/114412); Loss: 0.084831; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.1526 0.1428 0.1123 0.1017 0.0865 0.0790 0.0760 0.0735 0.0712 0.0691 0.0675 0.0663 0.0656 0.0649 0.0644 0.0639 

[TRAIN] Epoch[1](8179/114412); Loss: 0.077448; Backpropagation: 0.2982 sec; Batch: 2.1246 sec
0.1457 0.1338 0.1020 0.0897 0.0781 0.0720 0.0688 0.0658 0.0636 0.0624 0.0614 0.0602 0.0596 0.0591 0.0587 0.0585 

[TRAIN] Epoch[1](8180/114412); Loss: 0.088253; Backpropagation: 0.2977 sec; Batch: 2.1254 sec
0.1969 0.1789 0.1254 0.1020 0.0825 0.0781 0.0722 0.0702 0.0669 0.0652 0.0645 0.0632 0.0622 0.0618 0.0614 0.0605 

[TRAIN] Epoch[1](8181/114412); Loss: 0.092369; Backpropagation: 0.2984 sec; Batch: 2.1251 sec
0.1696 0.1594 0.1230 0.1140 0.1020 0.0955 0.0907 0.0842 0.0765 0.0731 0.0697 0.0667 0.0649 0.0637 0.0627 0.0624 

[TRAIN] Epoch[1](8182/114412); Loss: 0.082224; Backpropagation: 0.3007 sec; Batch: 2.1283 sec
0.1556 0.1391 0.1114 0.0965 0.0879 0.0765 0.0748 0.0707 0.0674 0.0655 0.0642 0.0626 0.0619 0.0609 0.0605 0.0600 

[TRAIN] Epoch[1](8183/114412); Loss: 0.072019; Backpropagation: 0.2985 sec; Batch: 2.1276 sec
0.1240 0.1188 0.0988 0.0879 0.0738 0.0681 0.0642 0.0620 0.0598 0.0586 0.0577 0.0567 0.0561 0.0555 0.0552 0.0550 

[TRAIN] Epoch[1](8184/114412); Loss: 0.086905; Backpropagation: 0.2952 sec; Batch: 2.1208 sec
0.1400 0.1341 0.1123 0.1008 0.0905 0.0842 0.0793 0.0769 0.0751 0.0734 0.0726 0.0716 0.0706 0.0703 0.0697 0.0691 

[TRAIN] Epoch[1](8185/114412); Loss: 0.117643; Backpropagation: 0.2956 sec; Batch: 2.1199 sec
0.2198 0.2051 0.1709 0.1602 0.1374 0.1217 0.1069 0.0943 0.0890 0.0857 0.0849 0.0840 0.0817 0.0807 0.0802 0.0798 

[TRAIN] Epoch[1](8186/114412); Loss: 0.092399; Backpropagation: 0.2957 sec; Batch: 2.1200 sec
0.1848 0.1514 0.1146 0.0976 0.0900 0.0852 0.0815 0.0807 0.0783 0.0762 0.0749 0.0738 0.0730 0.0725 0.0721 0.0718 

[TRAIN] Epoch[1](8187/114412); Loss: 0.087542; Backpropagation: 0.2955 sec; Batch: 2.1221 sec
0.1256 0.1255 0.1075 0.0972 0.0919 0.0881 0.0835 0.0812 0.0790 0.0772 0.0760 0.0749 0.0742 0.0736 0.0729 0.0725 

[TRAIN] Epoch[1](8188/114412); Loss: 0.119044; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.2592 0.2217 0.1722 0.1464 0.1159 0.1059 0.1004 0.0956 0.0921 0.0895 0.0878 0.0856 0.0845 0.0836 0.0825 0.0816 

[TRAIN] Epoch[1](8189/114412); Loss: 0.116003; Backpropagation: 0.3005 sec; Batch: 2.1272 sec
0.2334 0.2077 0.1652 0.1483 0.1274 0.1133 0.1019 0.0945 0.0900 0.0875 0.0850 0.0827 0.0815 0.0800 0.0791 0.0785 

[TRAIN] Epoch[1](8190/114412); Loss: 0.069146; Backpropagation: 0.3008 sec; Batch: 2.1294 sec
0.1458 0.1328 0.0988 0.0877 0.0711 0.0641 0.0589 0.0565 0.0542 0.0511 0.0497 0.0484 0.0476 0.0469 0.0466 0.0463 

[TRAIN] Epoch[1](8191/114412); Loss: 0.081498; Backpropagation: 0.2979 sec; Batch: 2.1246 sec
0.1565 0.1347 0.1032 0.0925 0.0785 0.0757 0.0736 0.0719 0.0699 0.0669 0.0656 0.0644 0.0634 0.0629 0.0623 0.0619 

[TRAIN] Epoch[1](8192/114412); Loss: 0.111268; Backpropagation: 0.2949 sec; Batch: 2.0806 sec
0.2001 0.1898 0.1542 0.1419 0.1211 0.1096 0.0999 0.0946 0.0900 0.0867 0.0852 0.0835 0.0822 0.0812 0.0804 0.0797 

[TRAIN] Epoch[1](8193/114412); Loss: 0.088785; Backpropagation: 0.2952 sec; Batch: 2.1232 sec
0.1867 0.1661 0.1271 0.1086 0.0928 0.0832 0.0754 0.0710 0.0691 0.0662 0.0646 0.0636 0.0625 0.0617 0.0612 0.0605 

[TRAIN] Epoch[1](8194/114412); Loss: 0.106111; Backpropagation: 0.2956 sec; Batch: 2.0823 sec
0.1867 0.1681 0.1450 0.1324 0.1158 0.1048 0.0970 0.0921 0.0889 0.0860 0.0837 0.0821 0.0804 0.0793 0.0782 0.0772 

[TRAIN] Epoch[1](8195/114412); Loss: 0.077979; Backpropagation: 0.2950 sec; Batch: 2.1190 sec
0.1381 0.1217 0.0945 0.0872 0.0805 0.0761 0.0719 0.0688 0.0669 0.0657 0.0645 0.0634 0.0629 0.0623 0.0617 0.0615 

[TRAIN] Epoch[1](8196/114412); Loss: 0.081990; Backpropagation: 0.2958 sec; Batch: 2.1200 sec
0.1347 0.1270 0.0964 0.0902 0.0839 0.0784 0.0748 0.0741 0.0723 0.0710 0.0700 0.0691 0.0682 0.0676 0.0673 0.0668 

[TRAIN] Epoch[1](8197/114412); Loss: 0.055592; Backpropagation: 0.2947 sec; Batch: 2.1237 sec
0.1084 0.0999 0.0710 0.0628 0.0542 0.0516 0.0491 0.0482 0.0464 0.0443 0.0436 0.0428 0.0421 0.0420 0.0418 0.0415 

[TRAIN] Epoch[1](8198/114412); Loss: 0.075869; Backpropagation: 0.2955 sec; Batch: 2.1240 sec
0.1828 0.1649 0.1268 0.1073 0.0768 0.0643 0.0587 0.0544 0.0512 0.0503 0.0482 0.0471 0.0465 0.0454 0.0449 0.0445 

[TRAIN] Epoch[1](8199/114412); Loss: 0.063855; Backpropagation: 0.2956 sec; Batch: 2.1215 sec
0.1180 0.1139 0.0881 0.0777 0.0662 0.0620 0.0567 0.0545 0.0520 0.0502 0.0494 0.0479 0.0472 0.0465 0.0458 0.0455 

[TRAIN] Epoch[1](8200/114412); Loss: 0.074002; Backpropagation: 0.2967 sec; Batch: 2.1265 sec
0.1679 0.1572 0.1081 0.0905 0.0795 0.0641 0.0589 0.0567 0.0533 0.0515 0.0506 0.0501 0.0497 0.0491 0.0486 0.0483 

[TRAIN] Epoch[1](8201/114412); Loss: 0.156068; Backpropagation: 0.2956 sec; Batch: 2.1269 sec
0.2696 0.2533 0.2241 0.2103 0.1848 0.1651 0.1480 0.1351 0.1270 0.1206 0.1162 0.1135 0.1111 0.1085 0.1055 0.1045 

[TRAIN] Epoch[1](8202/114412); Loss: 0.079698; Backpropagation: 0.3012 sec; Batch: 2.1287 sec
0.1667 0.1484 0.1123 0.0967 0.0856 0.0736 0.0673 0.0640 0.0633 0.0601 0.0586 0.0573 0.0559 0.0555 0.0550 0.0549 

[TRAIN] Epoch[1](8203/114412); Loss: 0.073579; Backpropagation: 0.2983 sec; Batch: 2.1219 sec
0.1450 0.1328 0.0933 0.0760 0.0711 0.0671 0.0636 0.0628 0.0604 0.0592 0.0585 0.0583 0.0579 0.0574 0.0570 0.0568 

[TRAIN] Epoch[1](8204/114412); Loss: 0.075532; Backpropagation: 0.2988 sec; Batch: 2.1258 sec
0.1138 0.1056 0.0919 0.0827 0.0766 0.0739 0.0709 0.0692 0.0678 0.0665 0.0658 0.0653 0.0648 0.0647 0.0645 0.0646 

[TRAIN] Epoch[1](8205/114412); Loss: 0.083058; Backpropagation: 0.2957 sec; Batch: 2.1118 sec
0.1544 0.1380 0.1148 0.0958 0.0863 0.0804 0.0734 0.0716 0.0696 0.0665 0.0657 0.0637 0.0628 0.0628 0.0620 0.0612 

[TRAIN] Epoch[1](8206/114412); Loss: 0.073895; Backpropagation: 0.2952 sec; Batch: 2.1211 sec
0.1124 0.1063 0.0965 0.0889 0.0808 0.0747 0.0719 0.0681 0.0657 0.0636 0.0623 0.0603 0.0590 0.0581 0.0572 0.0565 

[TRAIN] Epoch[1](8207/114412); Loss: 0.106860; Backpropagation: 0.2951 sec; Batch: 2.1167 sec
0.2206 0.1852 0.1485 0.1247 0.1060 0.0988 0.0915 0.0888 0.0854 0.0836 0.0818 0.0805 0.0796 0.0789 0.0781 0.0778 

[TRAIN] Epoch[1](8208/114412); Loss: 0.074738; Backpropagation: 0.2957 sec; Batch: 2.1108 sec
0.1362 0.1254 0.0922 0.0831 0.0741 0.0702 0.0675 0.0649 0.0635 0.0618 0.0608 0.0601 0.0595 0.0591 0.0587 0.0587 

[TRAIN] Epoch[1](8209/114412); Loss: 0.058048; Backpropagation: 0.2937 sec; Batch: 2.0801 sec
0.1179 0.1088 0.0701 0.0630 0.0564 0.0540 0.0506 0.0483 0.0470 0.0464 0.0457 0.0448 0.0444 0.0442 0.0437 0.0435 

[TRAIN] Epoch[1](8210/114412); Loss: 0.073003; Backpropagation: 0.2960 sec; Batch: 2.1205 sec
0.1344 0.1335 0.0900 0.0810 0.0715 0.0674 0.0649 0.0634 0.0606 0.0596 0.0586 0.0575 0.0571 0.0566 0.0561 0.0559 

[TRAIN] Epoch[1](8211/114412); Loss: 0.071960; Backpropagation: 0.3008 sec; Batch: 2.1257 sec
0.1176 0.1153 0.0910 0.0823 0.0717 0.0679 0.0651 0.0642 0.0622 0.0608 0.0601 0.0593 0.0587 0.0584 0.0583 0.0584 

[TRAIN] Epoch[1](8212/114412); Loss: 0.080648; Backpropagation: 0.3007 sec; Batch: 2.1286 sec
0.1519 0.1395 0.1078 0.0954 0.0825 0.0755 0.0710 0.0683 0.0662 0.0645 0.0633 0.0624 0.0614 0.0607 0.0602 0.0598 

[TRAIN] Epoch[1](8213/114412); Loss: 0.069989; Backpropagation: 0.2976 sec; Batch: 2.1275 sec
0.1226 0.1124 0.0877 0.0789 0.0758 0.0668 0.0633 0.0613 0.0593 0.0586 0.0573 0.0560 0.0556 0.0550 0.0547 0.0545 

[TRAIN] Epoch[1](8214/114412); Loss: 0.081071; Backpropagation: 0.3008 sec; Batch: 2.1236 sec
0.1432 0.1341 0.1091 0.1029 0.0889 0.0803 0.0745 0.0711 0.0673 0.0650 0.0633 0.0618 0.0604 0.0591 0.0583 0.0578 

[TRAIN] Epoch[1](8215/114412); Loss: 0.134301; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.2254 0.2156 0.1878 0.1728 0.1505 0.1342 0.1201 0.1139 0.1115 0.1066 0.1045 0.1034 0.1020 0.1010 0.1001 0.0994 

[TRAIN] Epoch[1](8216/114412); Loss: 0.072388; Backpropagation: 0.2953 sec; Batch: 2.1237 sec
0.1611 0.1465 0.0993 0.0842 0.0690 0.0637 0.0602 0.0580 0.0562 0.0545 0.0533 0.0520 0.0509 0.0504 0.0497 0.0492 

[TRAIN] Epoch[1](8217/114412); Loss: 0.078168; Backpropagation: 0.2910 sec; Batch: 2.1228 sec
0.1460 0.1372 0.1095 0.0945 0.0819 0.0728 0.0669 0.0639 0.0626 0.0618 0.0602 0.0599 0.0589 0.0586 0.0582 0.0579 

[TRAIN] Epoch[1](8218/114412); Loss: 0.119490; Backpropagation: 0.2915 sec; Batch: 2.1186 sec
0.2085 0.1895 0.1527 0.1368 0.1264 0.1155 0.1092 0.1052 0.1019 0.0998 0.0977 0.0962 0.0946 0.0936 0.0926 0.0916 

[TRAIN] Epoch[1](8219/114412); Loss: 0.076707; Backpropagation: 0.2930 sec; Batch: 2.1195 sec
0.1353 0.1233 0.0984 0.0849 0.0770 0.0733 0.0700 0.0674 0.0656 0.0641 0.0631 0.0621 0.0615 0.0609 0.0603 0.0599 

[TRAIN] Epoch[1](8220/114412); Loss: 0.073483; Backpropagation: 0.2932 sec; Batch: 2.1202 sec
0.1219 0.1120 0.0953 0.0881 0.0794 0.0740 0.0682 0.0648 0.0620 0.0601 0.0593 0.0584 0.0582 0.0581 0.0580 0.0580 

[TRAIN] Epoch[1](8221/114412); Loss: 0.089301; Backpropagation: 0.2908 sec; Batch: 2.1165 sec
0.1573 0.1454 0.1085 0.0973 0.0881 0.0851 0.0817 0.0794 0.0772 0.0755 0.0742 0.0732 0.0724 0.0718 0.0711 0.0708 

[TRAIN] Epoch[1](8222/114412); Loss: 0.104768; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.2264 0.2050 0.1681 0.1500 0.1230 0.1045 0.0894 0.0800 0.0751 0.0710 0.0683 0.0659 0.0641 0.0630 0.0618 0.0608 

[TRAIN] Epoch[1](8223/114412); Loss: 0.103342; Backpropagation: 0.2939 sec; Batch: 2.1219 sec
0.2445 0.2167 0.1532 0.1370 0.1042 0.0913 0.0826 0.0771 0.0735 0.0718 0.0702 0.0687 0.0670 0.0662 0.0652 0.0644 

[TRAIN] Epoch[1](8224/114412); Loss: 0.079473; Backpropagation: 0.2932 sec; Batch: 2.1191 sec
0.1581 0.1498 0.1192 0.1059 0.0899 0.0768 0.0704 0.0649 0.0609 0.0576 0.0555 0.0543 0.0532 0.0523 0.0517 0.0509 

[TRAIN] Epoch[1](8225/114412); Loss: 0.073408; Backpropagation: 0.2914 sec; Batch: 2.1190 sec
0.1247 0.1171 0.0956 0.0874 0.0773 0.0717 0.0672 0.0648 0.0629 0.0610 0.0596 0.0586 0.0577 0.0570 0.0564 0.0559 

[TRAIN] Epoch[1](8226/114412); Loss: 0.103395; Backpropagation: 0.2936 sec; Batch: 2.1169 sec
0.2163 0.1983 0.1617 0.1399 0.1159 0.0974 0.0859 0.0803 0.0760 0.0736 0.0717 0.0702 0.0687 0.0673 0.0660 0.0652 

[TRAIN] Epoch[1](8227/114412); Loss: 0.095475; Backpropagation: 0.2915 sec; Batch: 2.1148 sec
0.1687 0.1600 0.1189 0.1061 0.0961 0.0920 0.0874 0.0837 0.0815 0.0795 0.0783 0.0768 0.0758 0.0749 0.0742 0.0737 

[TRAIN] Epoch[1](8228/114412); Loss: 0.071201; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1400 0.1200 0.0840 0.0827 0.0717 0.0684 0.0652 0.0610 0.0593 0.0582 0.0565 0.0559 0.0547 0.0543 0.0539 0.0535 

[TRAIN] Epoch[1](8229/114412); Loss: 0.062128; Backpropagation: 0.2931 sec; Batch: 2.0829 sec
0.1187 0.1083 0.0782 0.0692 0.0647 0.0581 0.0550 0.0530 0.0510 0.0500 0.0491 0.0485 0.0480 0.0476 0.0473 0.0473 

[TRAIN] Epoch[1](8230/114412); Loss: 0.087216; Backpropagation: 0.2931 sec; Batch: 2.1180 sec
0.1855 0.1693 0.1262 0.1091 0.0870 0.0772 0.0715 0.0688 0.0675 0.0643 0.0635 0.0623 0.0616 0.0609 0.0606 0.0604 

[TRAIN] Epoch[1](8231/114412); Loss: 0.070699; Backpropagation: 0.2913 sec; Batch: 2.0784 sec
0.1351 0.1114 0.0909 0.0785 0.0741 0.0681 0.0631 0.0613 0.0593 0.0577 0.0569 0.0556 0.0552 0.0548 0.0545 0.0546 

[TRAIN] Epoch[1](8232/114412); Loss: 0.080164; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1548 0.1482 0.1087 0.0948 0.0797 0.0729 0.0681 0.0660 0.0645 0.0633 0.0619 0.0610 0.0604 0.0600 0.0594 0.0590 

[TRAIN] Epoch[1](8233/114412); Loss: 0.084151; Backpropagation: 0.2904 sec; Batch: 2.1044 sec
0.1446 0.1285 0.1057 0.0940 0.0867 0.0811 0.0788 0.0752 0.0735 0.0712 0.0695 0.0686 0.0678 0.0673 0.0671 0.0666 

[TRAIN] Epoch[1](8234/114412); Loss: 0.068309; Backpropagation: 0.2915 sec; Batch: 2.1202 sec
0.1112 0.1058 0.0864 0.0783 0.0707 0.0667 0.0631 0.0613 0.0592 0.0577 0.0568 0.0560 0.0554 0.0549 0.0547 0.0547 

[TRAIN] Epoch[1](8235/114412); Loss: 0.090687; Backpropagation: 0.2913 sec; Batch: 2.1205 sec
0.1597 0.1459 0.1200 0.1044 0.0935 0.0855 0.0813 0.0787 0.0772 0.0752 0.0736 0.0725 0.0715 0.0710 0.0706 0.0703 

[TRAIN] Epoch[1](8236/114412); Loss: 0.104745; Backpropagation: 0.2914 sec; Batch: 2.0988 sec
0.1704 0.1594 0.1350 0.1230 0.1105 0.1022 0.0969 0.0928 0.0903 0.0879 0.0866 0.0857 0.0848 0.0841 0.0835 0.0829 

[TRAIN] Epoch[1](8237/114412); Loss: 0.097449; Backpropagation: 0.2916 sec; Batch: 2.1170 sec
0.1742 0.1552 0.1204 0.1093 0.0995 0.0937 0.0893 0.0864 0.0838 0.0819 0.0803 0.0790 0.0779 0.0768 0.0761 0.0753 

[TRAIN] Epoch[1](8238/114412); Loss: 0.086510; Backpropagation: 0.2919 sec; Batch: 2.1171 sec
0.1960 0.1818 0.1184 0.1026 0.0831 0.0745 0.0709 0.0671 0.0653 0.0637 0.0621 0.0611 0.0602 0.0595 0.0592 0.0588 

[TRAIN] Epoch[1](8239/114412); Loss: 0.111901; Backpropagation: 0.2915 sec; Batch: 2.1182 sec
0.1794 0.1504 0.1322 0.1223 0.1136 0.1086 0.1056 0.1028 0.1004 0.0994 0.0980 0.0970 0.0962 0.0954 0.0948 0.0944 

[TRAIN] Epoch[1](8240/114412); Loss: 0.075732; Backpropagation: 0.2904 sec; Batch: 2.1164 sec
0.1508 0.1312 0.1024 0.0887 0.0785 0.0710 0.0664 0.0630 0.0613 0.0594 0.0584 0.0572 0.0566 0.0562 0.0555 0.0551 

[TRAIN] Epoch[1](8241/114412); Loss: 0.068515; Backpropagation: 0.2911 sec; Batch: 2.0774 sec
0.1321 0.1276 0.0947 0.0859 0.0727 0.0648 0.0598 0.0570 0.0552 0.0535 0.0516 0.0502 0.0489 0.0480 0.0473 0.0468 

[TRAIN] Epoch[1](8242/114412); Loss: 0.071889; Backpropagation: 0.2912 sec; Batch: 2.1143 sec
0.1349 0.1301 0.0936 0.0817 0.0711 0.0664 0.0633 0.0615 0.0592 0.0577 0.0566 0.0558 0.0550 0.0547 0.0545 0.0541 

[TRAIN] Epoch[1](8243/114412); Loss: 0.076480; Backpropagation: 0.2907 sec; Batch: 2.1174 sec
0.1361 0.1243 0.0936 0.0869 0.0786 0.0728 0.0685 0.0661 0.0644 0.0635 0.0627 0.0620 0.0615 0.0611 0.0608 0.0607 

[TRAIN] Epoch[1](8244/114412); Loss: 0.070803; Backpropagation: 0.2913 sec; Batch: 2.1196 sec
0.1079 0.1039 0.0831 0.0777 0.0741 0.0698 0.0665 0.0650 0.0629 0.0619 0.0611 0.0606 0.0601 0.0598 0.0594 0.0591 

[TRAIN] Epoch[1](8245/114412); Loss: 0.084607; Backpropagation: 0.2914 sec; Batch: 2.1169 sec
0.1371 0.1285 0.1054 0.0972 0.0873 0.0813 0.0770 0.0752 0.0738 0.0725 0.0713 0.0704 0.0697 0.0692 0.0691 0.0688 

[TRAIN] Epoch[1](8246/114412); Loss: 0.096398; Backpropagation: 0.2933 sec; Batch: 2.1195 sec
0.1799 0.1666 0.1315 0.1188 0.1029 0.0903 0.0836 0.0809 0.0777 0.0760 0.0744 0.0735 0.0725 0.0720 0.0712 0.0705 

[TRAIN] Epoch[1](8247/114412); Loss: 0.072693; Backpropagation: 0.2929 sec; Batch: 2.0786 sec
0.1122 0.1058 0.0950 0.0824 0.0751 0.0690 0.0667 0.0657 0.0636 0.0628 0.0619 0.0613 0.0609 0.0604 0.0602 0.0600 

[TRAIN] Epoch[1](8248/114412); Loss: 0.095276; Backpropagation: 0.2917 sec; Batch: 2.0787 sec
0.1382 0.1319 0.1166 0.1083 0.1022 0.0951 0.0903 0.0882 0.0859 0.0841 0.0828 0.0815 0.0807 0.0802 0.0795 0.0789 

[TRAIN] Epoch[1](8249/114412); Loss: 0.085301; Backpropagation: 0.2912 sec; Batch: 2.0895 sec
0.1388 0.1321 0.1052 0.0958 0.0873 0.0825 0.0788 0.0776 0.0749 0.0734 0.0720 0.0704 0.0699 0.0692 0.0687 0.0682 

[TRAIN] Epoch[1](8250/114412); Loss: 0.095603; Backpropagation: 0.2938 sec; Batch: 2.0808 sec
0.1629 0.1438 0.1197 0.1104 0.1002 0.0944 0.0897 0.0854 0.0824 0.0807 0.0789 0.0778 0.0770 0.0761 0.0755 0.0748 

[TRAIN] Epoch[1](8251/114412); Loss: 0.087873; Backpropagation: 0.2955 sec; Batch: 2.0828 sec
0.1797 0.1620 0.1244 0.1077 0.0880 0.0817 0.0756 0.0722 0.0697 0.0667 0.0651 0.0643 0.0632 0.0624 0.0619 0.0613 

[TRAIN] Epoch[1](8252/114412); Loss: 0.063085; Backpropagation: 0.2944 sec; Batch: 2.1193 sec
0.1240 0.1208 0.0827 0.0696 0.0611 0.0574 0.0549 0.0530 0.0512 0.0496 0.0487 0.0479 0.0476 0.0472 0.0469 0.0468 

[TRAIN] Epoch[1](8253/114412); Loss: 0.079989; Backpropagation: 0.2912 sec; Batch: 2.1278 sec
0.1325 0.1175 0.0980 0.0855 0.0824 0.0773 0.0735 0.0718 0.0700 0.0690 0.0681 0.0673 0.0671 0.0668 0.0665 0.0664 

[TRAIN] Epoch[1](8254/114412); Loss: 0.093487; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1848 0.1606 0.1192 0.0999 0.0879 0.0864 0.0820 0.0814 0.0788 0.0763 0.0753 0.0738 0.0731 0.0724 0.0719 0.0717 

[TRAIN] Epoch[1](8255/114412); Loss: 0.106160; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1596 0.1512 0.1331 0.1229 0.1142 0.1064 0.1010 0.0970 0.0941 0.0922 0.0904 0.0891 0.0881 0.0870 0.0863 0.0859 

[TRAIN] Epoch[1](8256/114412); Loss: 0.080780; Backpropagation: 0.2918 sec; Batch: 2.1239 sec
0.1454 0.1298 0.1005 0.0891 0.0788 0.0757 0.0743 0.0715 0.0697 0.0682 0.0668 0.0660 0.0650 0.0644 0.0638 0.0634 

[TRAIN] Epoch[1](8257/114412); Loss: 0.111320; Backpropagation: 0.2914 sec; Batch: 2.1195 sec
0.1976 0.1895 0.1549 0.1406 0.1162 0.1061 0.0979 0.0939 0.0909 0.0886 0.0873 0.0858 0.0845 0.0836 0.0825 0.0813 

[TRAIN] Epoch[1](8258/114412); Loss: 0.076731; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1358 0.1262 0.0975 0.0867 0.0781 0.0734 0.0708 0.0680 0.0651 0.0633 0.0623 0.0612 0.0605 0.0600 0.0595 0.0592 

[TRAIN] Epoch[1](8259/114412); Loss: 0.091311; Backpropagation: 0.2917 sec; Batch: 2.1180 sec
0.1446 0.1378 0.1130 0.1031 0.0943 0.0897 0.0851 0.0826 0.0804 0.0787 0.0773 0.0763 0.0754 0.0746 0.0742 0.0738 

[TRAIN] Epoch[1](8260/114412); Loss: 0.089510; Backpropagation: 0.2954 sec; Batch: 2.1224 sec
0.1400 0.1352 0.1184 0.1079 0.0977 0.0901 0.0843 0.0801 0.0771 0.0748 0.0735 0.0722 0.0713 0.0706 0.0697 0.0694 

[TRAIN] Epoch[1](8261/114412); Loss: 0.093065; Backpropagation: 0.2913 sec; Batch: 2.1161 sec
0.1553 0.1408 0.1133 0.1027 0.0952 0.0888 0.0860 0.0832 0.0815 0.0794 0.0787 0.0779 0.0773 0.0766 0.0763 0.0759 

[TRAIN] Epoch[1](8262/114412); Loss: 0.061541; Backpropagation: 0.2913 sec; Batch: 2.0780 sec
0.1180 0.1080 0.0804 0.0757 0.0646 0.0591 0.0552 0.0515 0.0496 0.0479 0.0469 0.0462 0.0458 0.0456 0.0453 0.0450 

[TRAIN] Epoch[1](8263/114412); Loss: 0.078710; Backpropagation: 0.2940 sec; Batch: 2.1211 sec
0.1489 0.1404 0.1010 0.0869 0.0789 0.0736 0.0692 0.0667 0.0650 0.0633 0.0624 0.0616 0.0611 0.0605 0.0601 0.0598 

[TRAIN] Epoch[1](8264/114412); Loss: 0.075756; Backpropagation: 0.2933 sec; Batch: 2.1200 sec
0.1369 0.1337 0.0994 0.0884 0.0762 0.0708 0.0661 0.0642 0.0625 0.0611 0.0600 0.0593 0.0588 0.0585 0.0583 0.0580 

[TRAIN] Epoch[1](8265/114412); Loss: 0.088390; Backpropagation: 0.2932 sec; Batch: 2.1178 sec
0.2310 0.2150 0.1567 0.1363 0.1030 0.0781 0.0644 0.0551 0.0525 0.0502 0.0494 0.0462 0.0447 0.0440 0.0440 0.0435 

[TRAIN] Epoch[1](8266/114412); Loss: 0.065142; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1034 0.0954 0.0851 0.0775 0.0697 0.0653 0.0603 0.0580 0.0565 0.0551 0.0539 0.0532 0.0527 0.0523 0.0520 0.0518 

[TRAIN] Epoch[1](8267/114412); Loss: 0.088067; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.2020 0.1746 0.1298 0.1066 0.0826 0.0755 0.0704 0.0685 0.0662 0.0644 0.0629 0.0624 0.0616 0.0609 0.0606 0.0601 

[TRAIN] Epoch[1](8268/114412); Loss: 0.097988; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1808 0.1670 0.1327 0.1149 0.1007 0.0903 0.0861 0.0827 0.0802 0.0787 0.0780 0.0767 0.0757 0.0750 0.0744 0.0739 

[TRAIN] Epoch[1](8269/114412); Loss: 0.074019; Backpropagation: 0.2913 sec; Batch: 2.1168 sec
0.1540 0.1338 0.0966 0.0869 0.0748 0.0676 0.0648 0.0609 0.0590 0.0576 0.0563 0.0555 0.0550 0.0541 0.0538 0.0536 

[TRAIN] Epoch[1](8270/114412); Loss: 0.096094; Backpropagation: 0.2911 sec; Batch: 2.0772 sec
0.1926 0.1728 0.1296 0.1107 0.0986 0.0902 0.0850 0.0816 0.0785 0.0757 0.0738 0.0721 0.0707 0.0693 0.0684 0.0680 

[TRAIN] Epoch[1](8271/114412); Loss: 0.094908; Backpropagation: 0.2913 sec; Batch: 2.1194 sec
0.1393 0.1299 0.1128 0.1069 0.0989 0.0942 0.0906 0.0877 0.0856 0.0842 0.0830 0.0821 0.0816 0.0810 0.0805 0.0804 

[TRAIN] Epoch[1](8272/114412); Loss: 0.068123; Backpropagation: 0.2915 sec; Batch: 2.0778 sec
0.1342 0.1167 0.0969 0.0810 0.0744 0.0671 0.0616 0.0578 0.0543 0.0520 0.0509 0.0501 0.0492 0.0485 0.0478 0.0475 

[TRAIN] Epoch[1](8273/114412); Loss: 0.090285; Backpropagation: 0.2917 sec; Batch: 2.1138 sec
0.1643 0.1546 0.1183 0.1038 0.0899 0.0841 0.0794 0.0769 0.0749 0.0735 0.0725 0.0713 0.0708 0.0702 0.0700 0.0700 

[TRAIN] Epoch[1](8274/114412); Loss: 0.088772; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.1579 0.1459 0.1146 0.1057 0.0963 0.0882 0.0824 0.0779 0.0740 0.0713 0.0699 0.0685 0.0675 0.0670 0.0667 0.0665 

[TRAIN] Epoch[1](8275/114412); Loss: 0.071756; Backpropagation: 0.2914 sec; Batch: 2.1170 sec
0.1218 0.1128 0.0910 0.0842 0.0753 0.0691 0.0657 0.0644 0.0622 0.0603 0.0588 0.0578 0.0571 0.0563 0.0559 0.0555 

[TRAIN] Epoch[1](8276/114412); Loss: 0.080433; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1748 0.1512 0.1031 0.0852 0.0772 0.0725 0.0696 0.0668 0.0648 0.0629 0.0615 0.0606 0.0599 0.0593 0.0589 0.0587 

[TRAIN] Epoch[1](8277/114412); Loss: 0.087237; Backpropagation: 0.2912 sec; Batch: 2.1451 sec
0.2093 0.1740 0.1281 0.1031 0.0892 0.0840 0.0748 0.0713 0.0661 0.0618 0.0595 0.0582 0.0563 0.0543 0.0533 0.0524 

[TRAIN] Epoch[1](8278/114412); Loss: 0.097445; Backpropagation: 0.2952 sec; Batch: 2.1180 sec
0.1850 0.1685 0.1379 0.1223 0.1100 0.0997 0.0909 0.0850 0.0782 0.0752 0.0729 0.0689 0.0676 0.0666 0.0656 0.0649 

[TRAIN] Epoch[1](8279/114412); Loss: 0.071753; Backpropagation: 0.2942 sec; Batch: 2.1207 sec
0.1493 0.1301 0.1038 0.0856 0.0711 0.0663 0.0610 0.0584 0.0572 0.0553 0.0536 0.0527 0.0519 0.0511 0.0506 0.0502 

[TRAIN] Epoch[1](8280/114412); Loss: 0.084420; Backpropagation: 0.2916 sec; Batch: 2.1177 sec
0.1595 0.1483 0.1186 0.1035 0.0903 0.0806 0.0741 0.0712 0.0678 0.0658 0.0642 0.0626 0.0620 0.0614 0.0607 0.0603 

[TRAIN] Epoch[1](8281/114412); Loss: 0.110041; Backpropagation: 0.2932 sec; Batch: 2.1203 sec
0.1901 0.1778 0.1539 0.1383 0.1230 0.1105 0.1024 0.0948 0.0907 0.0872 0.0847 0.0836 0.0823 0.0813 0.0805 0.0796 

[TRAIN] Epoch[1](8282/114412); Loss: 0.077377; Backpropagation: 0.2929 sec; Batch: 2.1219 sec
0.1509 0.1336 0.1015 0.0896 0.0803 0.0729 0.0681 0.0654 0.0632 0.0615 0.0602 0.0593 0.0585 0.0581 0.0577 0.0573 

[TRAIN] Epoch[1](8283/114412); Loss: 0.079106; Backpropagation: 0.2909 sec; Batch: 2.1148 sec
0.1894 0.1647 0.1155 0.0983 0.0801 0.0672 0.0610 0.0575 0.0572 0.0566 0.0553 0.0541 0.0535 0.0525 0.0516 0.0512 

[TRAIN] Epoch[1](8284/114412); Loss: 0.074776; Backpropagation: 0.2911 sec; Batch: 2.1137 sec
0.1710 0.1513 0.1045 0.0915 0.0762 0.0676 0.0620 0.0587 0.0557 0.0538 0.0524 0.0515 0.0504 0.0502 0.0499 0.0497 

[TRAIN] Epoch[1](8285/114412); Loss: 0.085169; Backpropagation: 0.2928 sec; Batch: 2.1206 sec
0.1399 0.1280 0.1067 0.0990 0.0874 0.0842 0.0796 0.0763 0.0740 0.0721 0.0713 0.0702 0.0694 0.0687 0.0680 0.0677 

[TRAIN] Epoch[1](8286/114412); Loss: 0.100734; Backpropagation: 0.2913 sec; Batch: 2.1115 sec
0.1808 0.1713 0.1425 0.1307 0.1093 0.0972 0.0891 0.0850 0.0812 0.0784 0.0769 0.0756 0.0745 0.0736 0.0731 0.0727 

[TRAIN] Epoch[1](8287/114412); Loss: 0.074688; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1608 0.1465 0.1066 0.0906 0.0753 0.0666 0.0631 0.0590 0.0566 0.0547 0.0540 0.0531 0.0524 0.0521 0.0519 0.0518 

[TRAIN] Epoch[1](8288/114412); Loss: 0.056080; Backpropagation: 0.3141 sec; Batch: 2.1521 sec
0.1028 0.0976 0.0700 0.0646 0.0586 0.0532 0.0505 0.0484 0.0468 0.0457 0.0446 0.0437 0.0433 0.0428 0.0425 0.0423 

[TRAIN] Epoch[1](8289/114412); Loss: 0.102019; Backpropagation: 0.2910 sec; Batch: 2.1143 sec
0.1648 0.1545 0.1284 0.1179 0.1083 0.0976 0.0935 0.0907 0.0885 0.0872 0.0856 0.0843 0.0837 0.0829 0.0823 0.0820 

[TRAIN] Epoch[1](8290/114412); Loss: 0.068586; Backpropagation: 0.2930 sec; Batch: 2.0842 sec
0.1317 0.1213 0.0905 0.0786 0.0701 0.0648 0.0599 0.0581 0.0564 0.0545 0.0536 0.0528 0.0519 0.0514 0.0511 0.0505 

[TRAIN] Epoch[1](8291/114412); Loss: 0.083147; Backpropagation: 0.2911 sec; Batch: 2.0942 sec
0.1486 0.1349 0.1069 0.0962 0.0847 0.0782 0.0745 0.0721 0.0704 0.0687 0.0670 0.0664 0.0660 0.0656 0.0652 0.0650 

[TRAIN] Epoch[1](8292/114412); Loss: 0.087906; Backpropagation: 0.2912 sec; Batch: 2.0861 sec
0.1523 0.1431 0.1070 0.0961 0.0900 0.0830 0.0796 0.0773 0.0754 0.0742 0.0729 0.0722 0.0713 0.0710 0.0708 0.0704 

[TRAIN] Epoch[1](8293/114412); Loss: 0.105877; Backpropagation: 0.2952 sec; Batch: 2.0822 sec
0.2084 0.1938 0.1586 0.1441 0.1228 0.1032 0.0965 0.0877 0.0810 0.0758 0.0736 0.0714 0.0701 0.0693 0.0690 0.0686 

[TRAIN] Epoch[1](8294/114412); Loss: 0.074425; Backpropagation: 0.2932 sec; Batch: 2.1187 sec
0.1114 0.1071 0.0925 0.0868 0.0793 0.0749 0.0708 0.0683 0.0660 0.0645 0.0633 0.0624 0.0617 0.0610 0.0605 0.0603 

[TRAIN] Epoch[1](8295/114412); Loss: 0.078471; Backpropagation: 0.2956 sec; Batch: 2.1180 sec
0.1441 0.1259 0.1101 0.0961 0.0828 0.0750 0.0708 0.0669 0.0644 0.0629 0.0616 0.0605 0.0597 0.0590 0.0582 0.0576 

[TRAIN] Epoch[1](8296/114412); Loss: 0.084146; Backpropagation: 0.2930 sec; Batch: 2.1154 sec
0.1528 0.1325 0.1034 0.0939 0.0865 0.0815 0.0800 0.0761 0.0740 0.0714 0.0685 0.0672 0.0660 0.0648 0.0642 0.0638 

[TRAIN] Epoch[1](8297/114412); Loss: 0.138345; Backpropagation: 0.2911 sec; Batch: 2.1156 sec
0.2874 0.2695 0.2291 0.2100 0.1720 0.1423 0.1222 0.1076 0.0978 0.0912 0.0875 0.0844 0.0811 0.0792 0.0769 0.0752 

[TRAIN] Epoch[1](8298/114412); Loss: 0.082968; Backpropagation: 0.2915 sec; Batch: 2.1182 sec
0.1527 0.1424 0.1032 0.0898 0.0840 0.0803 0.0761 0.0721 0.0703 0.0679 0.0664 0.0657 0.0650 0.0642 0.0641 0.0635 

[TRAIN] Epoch[1](8299/114412); Loss: 0.083118; Backpropagation: 0.2916 sec; Batch: 2.0796 sec
0.1560 0.1426 0.1056 0.0970 0.0853 0.0794 0.0736 0.0709 0.0688 0.0670 0.0658 0.0648 0.0642 0.0636 0.0629 0.0622 

[TRAIN] Epoch[1](8300/114412); Loss: 0.066316; Backpropagation: 0.2952 sec; Batch: 2.1202 sec
0.1396 0.1360 0.0924 0.0773 0.0646 0.0585 0.0551 0.0530 0.0519 0.0502 0.0489 0.0479 0.0472 0.0465 0.0460 0.0458 

[TRAIN] Epoch[1](8301/114412); Loss: 0.089181; Backpropagation: 0.2955 sec; Batch: 2.0817 sec
0.1473 0.1351 0.1212 0.1120 0.0976 0.0900 0.0823 0.0775 0.0751 0.0734 0.0714 0.0702 0.0695 0.0689 0.0679 0.0674 

[TRAIN] Epoch[1](8302/114412); Loss: 0.072324; Backpropagation: 0.2950 sec; Batch: 2.0809 sec
0.1552 0.1458 0.1037 0.0915 0.0803 0.0695 0.0615 0.0566 0.0531 0.0513 0.0502 0.0489 0.0482 0.0477 0.0471 0.0467 

[TRAIN] Epoch[1](8303/114412); Loss: 0.090961; Backpropagation: 0.2945 sec; Batch: 2.1218 sec
0.1674 0.1513 0.1194 0.1066 0.0951 0.0874 0.0824 0.0786 0.0756 0.0735 0.0720 0.0707 0.0698 0.0691 0.0686 0.0680 

[TRAIN] Epoch[1](8304/114412); Loss: 0.064852; Backpropagation: 0.2954 sec; Batch: 2.1181 sec
0.1174 0.1114 0.0898 0.0796 0.0693 0.0626 0.0584 0.0554 0.0529 0.0513 0.0506 0.0493 0.0486 0.0477 0.0469 0.0463 

[TRAIN] Epoch[1](8305/114412); Loss: 0.104607; Backpropagation: 0.2906 sec; Batch: 2.1130 sec
0.1809 0.1676 0.1404 0.1287 0.1157 0.1049 0.0972 0.0915 0.0867 0.0842 0.0825 0.0810 0.0796 0.0785 0.0778 0.0768 

[TRAIN] Epoch[1](8306/114412); Loss: 0.080666; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1449 0.1291 0.1080 0.0973 0.0859 0.0770 0.0723 0.0699 0.0674 0.0658 0.0644 0.0631 0.0622 0.0616 0.0611 0.0607 

[TRAIN] Epoch[1](8307/114412); Loss: 0.107237; Backpropagation: 0.2957 sec; Batch: 2.1197 sec
0.2058 0.1827 0.1478 0.1282 0.1132 0.1004 0.0933 0.0893 0.0863 0.0841 0.0829 0.0816 0.0809 0.0802 0.0797 0.0793 

[TRAIN] Epoch[1](8308/114412); Loss: 0.082173; Backpropagation: 0.2929 sec; Batch: 2.1225 sec
0.1530 0.1372 0.1014 0.0888 0.0811 0.0781 0.0750 0.0728 0.0704 0.0682 0.0672 0.0658 0.0649 0.0640 0.0636 0.0632 

[TRAIN] Epoch[1](8309/114412); Loss: 0.103477; Backpropagation: 0.2933 sec; Batch: 2.1223 sec
0.1931 0.1710 0.1334 0.1194 0.1025 0.0952 0.0906 0.0870 0.0854 0.0845 0.0834 0.0830 0.0825 0.0821 0.0816 0.0812 

[TRAIN] Epoch[1](8310/114412); Loss: 0.090771; Backpropagation: 0.2907 sec; Batch: 2.1147 sec
0.1563 0.1407 0.1178 0.1064 0.0928 0.0878 0.0815 0.0792 0.0772 0.0754 0.0745 0.0734 0.0729 0.0724 0.0721 0.0719 

[TRAIN] Epoch[1](8311/114412); Loss: 0.096851; Backpropagation: 0.2914 sec; Batch: 2.1150 sec
0.1673 0.1499 0.1185 0.1068 0.0971 0.0941 0.0902 0.0875 0.0852 0.0832 0.0814 0.0797 0.0785 0.0777 0.0767 0.0760 

[TRAIN] Epoch[1](8312/114412); Loss: 0.089722; Backpropagation: 0.2931 sec; Batch: 2.1195 sec
0.1691 0.1571 0.1196 0.1041 0.0873 0.0812 0.0785 0.0753 0.0734 0.0723 0.0712 0.0706 0.0698 0.0689 0.0687 0.0685 

[TRAIN] Epoch[1](8313/114412); Loss: 0.094063; Backpropagation: 0.2933 sec; Batch: 2.1182 sec
0.1949 0.1694 0.1326 0.1129 0.0929 0.0854 0.0804 0.0772 0.0742 0.0727 0.0712 0.0696 0.0687 0.0682 0.0676 0.0672 

[TRAIN] Epoch[1](8314/114412); Loss: 0.101210; Backpropagation: 0.2951 sec; Batch: 2.1206 sec
0.2086 0.1830 0.1401 0.1164 0.0968 0.0911 0.0866 0.0833 0.0808 0.0789 0.0777 0.0765 0.0758 0.0752 0.0746 0.0741 

[TRAIN] Epoch[1](8315/114412); Loss: 0.066826; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.1560 0.1376 0.0900 0.0721 0.0636 0.0604 0.0555 0.0531 0.0510 0.0492 0.0484 0.0475 0.0467 0.0463 0.0461 0.0458 

[TRAIN] Epoch[1](8316/114412); Loss: 0.058470; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1098 0.1048 0.0773 0.0692 0.0611 0.0552 0.0515 0.0495 0.0474 0.0458 0.0448 0.0444 0.0441 0.0437 0.0436 0.0433 

[TRAIN] Epoch[1](8317/114412); Loss: 0.080760; Backpropagation: 0.2932 sec; Batch: 2.1180 sec
0.1516 0.1344 0.1034 0.0896 0.0823 0.0773 0.0742 0.0701 0.0680 0.0661 0.0646 0.0637 0.0626 0.0620 0.0615 0.0610 

[TRAIN] Epoch[1](8318/114412); Loss: 0.081619; Backpropagation: 0.2929 sec; Batch: 2.1152 sec
0.1497 0.1384 0.1129 0.0983 0.0837 0.0766 0.0728 0.0689 0.0671 0.0652 0.0640 0.0629 0.0622 0.0616 0.0611 0.0607 

[TRAIN] Epoch[1](8319/114412); Loss: 0.078747; Backpropagation: 0.2954 sec; Batch: 2.1195 sec
0.1434 0.1338 0.1065 0.0934 0.0817 0.0747 0.0702 0.0672 0.0648 0.0635 0.0620 0.0610 0.0601 0.0597 0.0591 0.0588 

[TRAIN] Epoch[1](8320/114412); Loss: 0.098616; Backpropagation: 0.2904 sec; Batch: 2.1123 sec
0.1465 0.1369 0.1178 0.1085 0.1016 0.0966 0.0934 0.0914 0.0894 0.0877 0.0867 0.0857 0.0849 0.0842 0.0835 0.0831 

[TRAIN] Epoch[1](8321/114412); Loss: 0.093239; Backpropagation: 0.2911 sec; Batch: 2.1158 sec
0.1967 0.1733 0.1255 0.1089 0.1008 0.0884 0.0809 0.0738 0.0724 0.0706 0.0694 0.0680 0.0667 0.0659 0.0656 0.0649 

[TRAIN] Epoch[1](8322/114412); Loss: 0.084910; Backpropagation: 0.2929 sec; Batch: 2.0791 sec
0.1861 0.1716 0.1321 0.1157 0.0940 0.0801 0.0710 0.0648 0.0606 0.0583 0.0564 0.0552 0.0543 0.0534 0.0526 0.0523 

[TRAIN] Epoch[1](8323/114412); Loss: 0.070991; Backpropagation: 0.2928 sec; Batch: 2.1291 sec
0.1239 0.1095 0.0883 0.0793 0.0727 0.0696 0.0657 0.0633 0.0616 0.0602 0.0585 0.0575 0.0571 0.0567 0.0562 0.0559 

[TRAIN] Epoch[1](8324/114412); Loss: 0.096559; Backpropagation: 0.2955 sec; Batch: 2.0859 sec
0.1387 0.1303 0.1150 0.1069 0.1004 0.0954 0.0924 0.0911 0.0882 0.0866 0.0854 0.0842 0.0836 0.0828 0.0822 0.0818 

[TRAIN] Epoch[1](8325/114412); Loss: 0.065875; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.0966 0.0983 0.0855 0.0819 0.0742 0.0677 0.0631 0.0590 0.0566 0.0551 0.0541 0.0533 0.0526 0.0522 0.0519 0.0518 

[TRAIN] Epoch[1](8326/114412); Loss: 0.094920; Backpropagation: 0.2909 sec; Batch: 2.0772 sec
0.1647 0.1532 0.1266 0.1147 0.1010 0.0932 0.0880 0.0836 0.0796 0.0770 0.0752 0.0738 0.0731 0.0722 0.0716 0.0712 

[TRAIN] Epoch[1](8327/114412); Loss: 0.067671; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1263 0.1160 0.0876 0.0769 0.0682 0.0627 0.0599 0.0580 0.0561 0.0548 0.0538 0.0533 0.0527 0.0525 0.0521 0.0518 

[TRAIN] Epoch[1](8328/114412); Loss: 0.078931; Backpropagation: 0.2909 sec; Batch: 2.1138 sec
0.1385 0.1340 0.1020 0.0922 0.0805 0.0741 0.0707 0.0688 0.0661 0.0649 0.0637 0.0624 0.0620 0.0614 0.0608 0.0606 

[TRAIN] Epoch[1](8329/114412); Loss: 0.091308; Backpropagation: 0.2913 sec; Batch: 2.0782 sec
0.1569 0.1444 0.1220 0.1101 0.0970 0.0897 0.0831 0.0787 0.0764 0.0744 0.0731 0.0721 0.0716 0.0710 0.0704 0.0700 

[TRAIN] Epoch[1](8330/114412); Loss: 0.088381; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1709 0.1525 0.1204 0.1043 0.0935 0.0845 0.0788 0.0749 0.0723 0.0697 0.0681 0.0667 0.0656 0.0647 0.0640 0.0634 

[TRAIN] Epoch[1](8331/114412); Loss: 0.076939; Backpropagation: 0.2912 sec; Batch: 2.1154 sec
0.1373 0.1175 0.0927 0.0842 0.0789 0.0746 0.0710 0.0682 0.0663 0.0652 0.0642 0.0633 0.0628 0.0620 0.0615 0.0612 

[TRAIN] Epoch[1](8332/114412); Loss: 0.084737; Backpropagation: 0.2907 sec; Batch: 2.2118 sec
0.1577 0.1403 0.1141 0.1031 0.0888 0.0800 0.0761 0.0727 0.0695 0.0679 0.0663 0.0653 0.0645 0.0638 0.0631 0.0627 

[TRAIN] Epoch[1](8333/114412); Loss: 0.074079; Backpropagation: 0.2909 sec; Batch: 2.1147 sec
0.1437 0.1350 0.0975 0.0866 0.0760 0.0696 0.0656 0.0623 0.0596 0.0579 0.0567 0.0560 0.0553 0.0547 0.0545 0.0543 

[TRAIN] Epoch[1](8334/114412); Loss: 0.086176; Backpropagation: 0.2914 sec; Batch: 2.0785 sec
0.1485 0.1386 0.1107 0.0991 0.0890 0.0816 0.0778 0.0749 0.0732 0.0716 0.0706 0.0699 0.0689 0.0684 0.0682 0.0678 

[TRAIN] Epoch[1](8335/114412); Loss: 0.058624; Backpropagation: 0.2931 sec; Batch: 2.1192 sec
0.1222 0.1104 0.0784 0.0679 0.0599 0.0531 0.0497 0.0477 0.0462 0.0450 0.0440 0.0434 0.0430 0.0426 0.0423 0.0420 

[TRAIN] Epoch[1](8336/114412); Loss: 0.085917; Backpropagation: 0.2938 sec; Batch: 2.1026 sec
0.1632 0.1546 0.1162 0.1057 0.0880 0.0794 0.0738 0.0717 0.0687 0.0672 0.0660 0.0648 0.0643 0.0639 0.0636 0.0633 

[TRAIN] Epoch[1](8337/114412); Loss: 0.080031; Backpropagation: 0.2912 sec; Batch: 2.1141 sec
0.1571 0.1207 0.1072 0.0979 0.0886 0.0812 0.0731 0.0678 0.0654 0.0627 0.0614 0.0605 0.0598 0.0594 0.0590 0.0587 

[TRAIN] Epoch[1](8338/114412); Loss: 0.082278; Backpropagation: 0.2946 sec; Batch: 2.1195 sec
0.1554 0.1425 0.0964 0.0858 0.0812 0.0762 0.0741 0.0722 0.0696 0.0688 0.0676 0.0663 0.0657 0.0652 0.0647 0.0645 

[TRAIN] Epoch[1](8339/114412); Loss: 0.077846; Backpropagation: 0.2952 sec; Batch: 2.1238 sec
0.1948 0.1774 0.1263 0.1010 0.0735 0.0638 0.0596 0.0578 0.0536 0.0508 0.0501 0.0492 0.0478 0.0475 0.0464 0.0460 

[TRAIN] Epoch[1](8340/114412); Loss: 0.080696; Backpropagation: 0.2930 sec; Batch: 2.1179 sec
0.1444 0.1363 0.1006 0.0919 0.0828 0.0767 0.0736 0.0701 0.0681 0.0664 0.0651 0.0641 0.0636 0.0631 0.0623 0.0619 

[TRAIN] Epoch[1](8341/114412); Loss: 0.084873; Backpropagation: 0.2932 sec; Batch: 2.1222 sec
0.1545 0.1429 0.1092 0.0983 0.0885 0.0817 0.0763 0.0741 0.0712 0.0691 0.0677 0.0666 0.0653 0.0648 0.0642 0.0637 

[TRAIN] Epoch[1](8342/114412); Loss: 0.066106; Backpropagation: 0.2913 sec; Batch: 2.1194 sec
0.1096 0.1017 0.0829 0.0762 0.0687 0.0634 0.0608 0.0592 0.0573 0.0562 0.0551 0.0541 0.0537 0.0532 0.0530 0.0527 

[TRAIN] Epoch[1](8343/114412); Loss: 0.077609; Backpropagation: 0.2914 sec; Batch: 2.1144 sec
0.1626 0.1506 0.1097 0.0934 0.0811 0.0719 0.0662 0.0618 0.0597 0.0580 0.0563 0.0551 0.0543 0.0539 0.0537 0.0533 

[TRAIN] Epoch[1](8344/114412); Loss: 0.061927; Backpropagation: 0.2914 sec; Batch: 2.1178 sec
0.1463 0.1267 0.0794 0.0650 0.0596 0.0546 0.0512 0.0499 0.0480 0.0469 0.0456 0.0445 0.0439 0.0436 0.0430 0.0427 

[TRAIN] Epoch[1](8345/114412); Loss: 0.112187; Backpropagation: 0.2913 sec; Batch: 2.1207 sec
0.1937 0.1806 0.1522 0.1390 0.1203 0.1121 0.1040 0.0973 0.0932 0.0907 0.0884 0.0871 0.0854 0.0847 0.0834 0.0829 

[TRAIN] Epoch[1](8346/114412); Loss: 0.069789; Backpropagation: 0.2914 sec; Batch: 2.0780 sec
0.1358 0.1223 0.0960 0.0850 0.0702 0.0646 0.0610 0.0594 0.0574 0.0550 0.0534 0.0525 0.0519 0.0510 0.0507 0.0503 

[TRAIN] Epoch[1](8347/114412); Loss: 0.058192; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1447 0.1329 0.0839 0.0704 0.0553 0.0481 0.0453 0.0434 0.0413 0.0398 0.0389 0.0383 0.0376 0.0372 0.0370 0.0370 

[TRAIN] Epoch[1](8348/114412); Loss: 0.075528; Backpropagation: 0.2915 sec; Batch: 2.1123 sec
0.1826 0.1480 0.1033 0.0825 0.0720 0.0666 0.0629 0.0596 0.0579 0.0558 0.0547 0.0536 0.0529 0.0525 0.0520 0.0515 

[TRAIN] Epoch[1](8349/114412); Loss: 0.090861; Backpropagation: 0.2917 sec; Batch: 2.1159 sec
0.1264 0.1192 0.1070 0.1002 0.0941 0.0934 0.0875 0.0850 0.0838 0.0820 0.0809 0.0802 0.0793 0.0786 0.0782 0.0779 

[TRAIN] Epoch[1](8350/114412); Loss: 0.066620; Backpropagation: 0.2906 sec; Batch: 2.1165 sec
0.1347 0.1137 0.0871 0.0780 0.0699 0.0624 0.0591 0.0571 0.0547 0.0525 0.0516 0.0506 0.0495 0.0488 0.0484 0.0478 

[TRAIN] Epoch[1](8351/114412); Loss: 0.081277; Backpropagation: 0.2952 sec; Batch: 2.1187 sec
0.1675 0.1596 0.1197 0.1051 0.0878 0.0766 0.0696 0.0648 0.0617 0.0594 0.0574 0.0559 0.0547 0.0540 0.0534 0.0531 

[TRAIN] Epoch[1](8352/114412); Loss: 0.087981; Backpropagation: 0.2908 sec; Batch: 2.0856 sec
0.1613 0.1345 0.1062 0.0953 0.0887 0.0838 0.0808 0.0780 0.0757 0.0745 0.0730 0.0723 0.0718 0.0710 0.0705 0.0702 

[TRAIN] Epoch[1](8353/114412); Loss: 0.087961; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1370 0.1291 0.1063 0.0972 0.0891 0.0848 0.0816 0.0800 0.0788 0.0772 0.0762 0.0753 0.0745 0.0740 0.0733 0.0730 

[TRAIN] Epoch[1](8354/114412); Loss: 0.063355; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1253 0.1220 0.0851 0.0768 0.0630 0.0552 0.0541 0.0521 0.0500 0.0488 0.0480 0.0472 0.0469 0.0464 0.0463 0.0462 

[TRAIN] Epoch[1](8355/114412); Loss: 0.083102; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1464 0.1321 0.0987 0.0893 0.0830 0.0796 0.0760 0.0735 0.0716 0.0704 0.0692 0.0686 0.0682 0.0680 0.0676 0.0675 

[TRAIN] Epoch[1](8356/114412); Loss: 0.071516; Backpropagation: 0.2927 sec; Batch: 2.2147 sec
0.1397 0.1213 0.0977 0.0859 0.0736 0.0682 0.0634 0.0612 0.0588 0.0569 0.0551 0.0540 0.0529 0.0523 0.0518 0.0514 

[TRAIN] Epoch[1](8357/114412); Loss: 0.064593; Backpropagation: 0.2956 sec; Batch: 2.1224 sec
0.1430 0.1316 0.0939 0.0797 0.0667 0.0564 0.0520 0.0503 0.0483 0.0467 0.0458 0.0449 0.0442 0.0437 0.0433 0.0431 

[TRAIN] Epoch[1](8358/114412); Loss: 0.071438; Backpropagation: 0.2905 sec; Batch: 2.1135 sec
0.1262 0.1162 0.0865 0.0783 0.0729 0.0684 0.0647 0.0636 0.0616 0.0600 0.0589 0.0580 0.0575 0.0571 0.0566 0.0565 

[TRAIN] Epoch[1](8359/114412); Loss: 0.079684; Backpropagation: 0.2909 sec; Batch: 2.1146 sec
0.1501 0.1390 0.1033 0.0939 0.0806 0.0751 0.0713 0.0678 0.0656 0.0643 0.0626 0.0615 0.0608 0.0600 0.0596 0.0593 

[TRAIN] Epoch[1](8360/114412); Loss: 0.078081; Backpropagation: 0.2910 sec; Batch: 2.1133 sec
0.1595 0.1464 0.1155 0.1029 0.0881 0.0772 0.0686 0.0629 0.0598 0.0567 0.0546 0.0534 0.0518 0.0511 0.0505 0.0501 

[TRAIN] Epoch[1](8361/114412); Loss: 0.106815; Backpropagation: 0.2911 sec; Batch: 2.0780 sec
0.2078 0.1882 0.1482 0.1333 0.1113 0.0970 0.0910 0.0873 0.0845 0.0829 0.0819 0.0808 0.0799 0.0790 0.0782 0.0777 

[TRAIN] Epoch[1](8362/114412); Loss: 0.075854; Backpropagation: 0.2908 sec; Batch: 2.1146 sec
0.1447 0.1338 0.1005 0.0924 0.0769 0.0704 0.0672 0.0641 0.0624 0.0605 0.0590 0.0577 0.0568 0.0560 0.0556 0.0555 

[TRAIN] Epoch[1](8363/114412); Loss: 0.056788; Backpropagation: 0.2913 sec; Batch: 2.1207 sec
0.0907 0.0856 0.0725 0.0646 0.0620 0.0580 0.0544 0.0520 0.0498 0.0482 0.0472 0.0461 0.0453 0.0445 0.0440 0.0435 

[TRAIN] Epoch[1](8364/114412); Loss: 0.088204; Backpropagation: 0.2930 sec; Batch: 2.1201 sec
0.1666 0.1543 0.1199 0.1048 0.0924 0.0844 0.0779 0.0742 0.0714 0.0695 0.0683 0.0669 0.0661 0.0653 0.0648 0.0643 

[TRAIN] Epoch[1](8365/114412); Loss: 0.087585; Backpropagation: 0.2931 sec; Batch: 2.1182 sec
0.1653 0.1510 0.1117 0.1012 0.0869 0.0802 0.0753 0.0739 0.0721 0.0710 0.0708 0.0696 0.0689 0.0684 0.0678 0.0673 

[TRAIN] Epoch[1](8366/114412); Loss: 0.132003; Backpropagation: 0.2950 sec; Batch: 2.1231 sec
0.1778 0.1697 0.1504 0.1410 0.1383 0.1333 0.1280 0.1263 0.1238 0.1212 0.1197 0.1184 0.1174 0.1164 0.1155 0.1148 

[TRAIN] Epoch[1](8367/114412); Loss: 0.082278; Backpropagation: 0.2931 sec; Batch: 2.1235 sec
0.1277 0.1225 0.1033 0.0929 0.0877 0.0798 0.0764 0.0740 0.0724 0.0713 0.0697 0.0686 0.0683 0.0676 0.0673 0.0669 

[TRAIN] Epoch[1](8368/114412); Loss: 0.093522; Backpropagation: 0.2956 sec; Batch: 2.1069 sec
0.1654 0.1470 0.1162 0.1067 0.0942 0.0904 0.0848 0.0825 0.0797 0.0780 0.0770 0.0760 0.0754 0.0748 0.0743 0.0740 

[TRAIN] Epoch[1](8369/114412); Loss: 0.082785; Backpropagation: 0.3500 sec; Batch: 2.2453 sec
0.1530 0.1389 0.1151 0.1048 0.0923 0.0831 0.0758 0.0702 0.0681 0.0643 0.0628 0.0618 0.0598 0.0593 0.0582 0.0571 

[TRAIN] Epoch[1](8370/114412); Loss: 0.093148; Backpropagation: 0.2910 sec; Batch: 2.0961 sec
0.1847 0.1716 0.1266 0.1093 0.0953 0.0895 0.0825 0.0783 0.0740 0.0719 0.0703 0.0691 0.0684 0.0670 0.0663 0.0656 

[TRAIN] Epoch[1](8371/114412); Loss: 0.103749; Backpropagation: 0.2928 sec; Batch: 2.1180 sec
0.1878 0.1735 0.1420 0.1265 0.1059 0.0972 0.0909 0.0880 0.0854 0.0836 0.0821 0.0809 0.0799 0.0793 0.0787 0.0782 

[TRAIN] Epoch[1](8372/114412); Loss: 0.093037; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1991 0.1797 0.1348 0.1160 0.0974 0.0862 0.0790 0.0758 0.0716 0.0686 0.0671 0.0650 0.0635 0.0627 0.0615 0.0606 

[TRAIN] Epoch[1](8373/114412); Loss: 0.081643; Backpropagation: 0.2960 sec; Batch: 2.1356 sec
0.1605 0.1385 0.1099 0.0978 0.0849 0.0783 0.0723 0.0689 0.0655 0.0637 0.0627 0.0617 0.0611 0.0606 0.0601 0.0598 

[TRAIN] Epoch[1](8374/114412); Loss: 0.063160; Backpropagation: 0.2954 sec; Batch: 2.0827 sec
0.1411 0.1286 0.0891 0.0747 0.0650 0.0561 0.0530 0.0497 0.0474 0.0466 0.0451 0.0440 0.0433 0.0426 0.0423 0.0420 

[TRAIN] Epoch[1](8375/114412); Loss: 0.084247; Backpropagation: 0.2952 sec; Batch: 2.0855 sec
0.1623 0.1398 0.1063 0.0930 0.0863 0.0794 0.0753 0.0731 0.0708 0.0689 0.0676 0.0665 0.0657 0.0649 0.0643 0.0638 

[TRAIN] Epoch[1](8376/114412); Loss: 0.106610; Backpropagation: 0.2955 sec; Batch: 2.1171 sec
0.1686 0.1484 0.1256 0.1156 0.1078 0.1039 0.0999 0.0977 0.0958 0.0944 0.0931 0.0921 0.0915 0.0909 0.0904 0.0900 

[TRAIN] Epoch[1](8377/114412); Loss: 0.094103; Backpropagation: 0.2949 sec; Batch: 2.1162 sec
0.1835 0.1621 0.1207 0.1033 0.0956 0.0899 0.0856 0.0811 0.0775 0.0758 0.0737 0.0726 0.0718 0.0713 0.0707 0.0704 

[TRAIN] Epoch[1](8378/114412); Loss: 0.067553; Backpropagation: 0.2906 sec; Batch: 2.0762 sec
0.1122 0.1070 0.0884 0.0817 0.0724 0.0686 0.0641 0.0599 0.0578 0.0556 0.0544 0.0532 0.0522 0.0516 0.0510 0.0507 

[TRAIN] Epoch[1](8379/114412); Loss: 0.106863; Backpropagation: 0.2917 sec; Batch: 2.1174 sec
0.2917 0.2461 0.1745 0.1316 0.1001 0.0961 0.0813 0.0746 0.0702 0.0681 0.0648 0.0635 0.0625 0.0620 0.0615 0.0612 

[TRAIN] Epoch[1](8380/114412); Loss: 0.077588; Backpropagation: 0.2912 sec; Batch: 2.0770 sec
0.1315 0.1244 0.0941 0.0875 0.0789 0.0745 0.0711 0.0686 0.0673 0.0658 0.0643 0.0635 0.0630 0.0625 0.0622 0.0620 

[TRAIN] Epoch[1](8381/114412); Loss: 0.064547; Backpropagation: 0.2919 sec; Batch: 2.1179 sec
0.1155 0.0952 0.0782 0.0733 0.0675 0.0635 0.0609 0.0580 0.0565 0.0547 0.0535 0.0526 0.0515 0.0511 0.0505 0.0501 

[TRAIN] Epoch[1](8382/114412); Loss: 0.111019; Backpropagation: 0.2911 sec; Batch: 2.0804 sec
0.1952 0.1754 0.1441 0.1283 0.1154 0.1062 0.1014 0.0963 0.0940 0.0924 0.0907 0.0892 0.0881 0.0873 0.0865 0.0859 

[TRAIN] Epoch[1](8383/114412); Loss: 0.094226; Backpropagation: 0.2905 sec; Batch: 2.1172 sec
0.1844 0.1659 0.1299 0.1158 0.0968 0.0891 0.0852 0.0815 0.0766 0.0730 0.0708 0.0695 0.0684 0.0676 0.0668 0.0662 

[TRAIN] Epoch[1](8384/114412); Loss: 0.082195; Backpropagation: 0.2917 sec; Batch: 2.1056 sec
0.1684 0.1481 0.1082 0.0916 0.0818 0.0747 0.0715 0.0681 0.0668 0.0649 0.0639 0.0627 0.0615 0.0613 0.0609 0.0606 

[TRAIN] Epoch[1](8385/114412); Loss: 0.095696; Backpropagation: 0.2907 sec; Batch: 2.3538 sec
0.1630 0.1480 0.1212 0.1100 0.0994 0.0936 0.0876 0.0843 0.0829 0.0803 0.0786 0.0777 0.0770 0.0763 0.0758 0.0754 

[TRAIN] Epoch[1](8386/114412); Loss: 0.080023; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1440 0.1276 0.0975 0.0889 0.0795 0.0765 0.0732 0.0710 0.0690 0.0672 0.0660 0.0646 0.0644 0.0640 0.0635 0.0634 

[TRAIN] Epoch[1](8387/114412); Loss: 0.073711; Backpropagation: 0.2928 sec; Batch: 2.1238 sec
0.1219 0.1156 0.0901 0.0803 0.0744 0.0712 0.0676 0.0659 0.0648 0.0634 0.0626 0.0615 0.0608 0.0602 0.0598 0.0593 

[TRAIN] Epoch[1](8388/114412); Loss: 0.091887; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1606 0.1462 0.1236 0.1127 0.0973 0.0881 0.0828 0.0786 0.0766 0.0749 0.0737 0.0727 0.0716 0.0708 0.0701 0.0697 

[TRAIN] Epoch[1](8389/114412); Loss: 0.077717; Backpropagation: 0.2925 sec; Batch: 2.1184 sec
0.1600 0.1409 0.1064 0.0954 0.0792 0.0717 0.0662 0.0634 0.0618 0.0597 0.0581 0.0569 0.0564 0.0560 0.0558 0.0554 

[TRAIN] Epoch[1](8390/114412); Loss: 0.081753; Backpropagation: 0.2912 sec; Batch: 2.1296 sec
0.1585 0.1434 0.1137 0.1005 0.0889 0.0822 0.0753 0.0694 0.0660 0.0629 0.0606 0.0593 0.0579 0.0571 0.0563 0.0559 

[TRAIN] Epoch[1](8391/114412); Loss: 0.060433; Backpropagation: 0.2919 sec; Batch: 2.1060 sec
0.1153 0.1052 0.0846 0.0763 0.0654 0.0567 0.0518 0.0507 0.0480 0.0463 0.0458 0.0450 0.0443 0.0443 0.0437 0.0434 

[TRAIN] Epoch[1](8392/114412); Loss: 0.097096; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.1513 0.1382 0.1152 0.1069 0.0991 0.0945 0.0910 0.0889 0.0872 0.0854 0.0842 0.0834 0.0828 0.0822 0.0818 0.0813 

[TRAIN] Epoch[1](8393/114412); Loss: 0.073215; Backpropagation: 0.2955 sec; Batch: 2.1195 sec
0.1459 0.1185 0.0884 0.0798 0.0748 0.0724 0.0676 0.0646 0.0624 0.0604 0.0589 0.0575 0.0564 0.0555 0.0547 0.0537 

[TRAIN] Epoch[1](8394/114412); Loss: 0.097231; Backpropagation: 0.3008 sec; Batch: 2.0881 sec
0.1543 0.1346 0.1180 0.1069 0.0993 0.0939 0.0904 0.0891 0.0872 0.0858 0.0845 0.0837 0.0831 0.0821 0.0816 0.0812 

[TRAIN] Epoch[1](8395/114412); Loss: 0.095002; Backpropagation: 0.3006 sec; Batch: 2.1288 sec
0.1501 0.1370 0.1175 0.1067 0.0972 0.0920 0.0873 0.0861 0.0837 0.0822 0.0817 0.0810 0.0802 0.0796 0.0791 0.0786 

[TRAIN] Epoch[1](8396/114412); Loss: 0.060777; Backpropagation: 0.2952 sec; Batch: 2.1196 sec
0.1353 0.1317 0.0772 0.0636 0.0556 0.0542 0.0507 0.0490 0.0478 0.0459 0.0451 0.0439 0.0434 0.0434 0.0429 0.0426 

[TRAIN] Epoch[1](8397/114412); Loss: 0.069602; Backpropagation: 0.2948 sec; Batch: 2.0813 sec
0.1498 0.1354 0.0893 0.0775 0.0693 0.0624 0.0578 0.0567 0.0546 0.0535 0.0527 0.0517 0.0512 0.0510 0.0506 0.0502 

[TRAIN] Epoch[1](8398/114412); Loss: 0.063703; Backpropagation: 0.2947 sec; Batch: 2.1029 sec
0.1232 0.1116 0.0823 0.0730 0.0674 0.0610 0.0564 0.0541 0.0525 0.0504 0.0495 0.0487 0.0479 0.0475 0.0470 0.0467 

[TRAIN] Epoch[1](8399/114412); Loss: 0.083363; Backpropagation: 0.2958 sec; Batch: 2.1227 sec
0.1674 0.1528 0.1103 0.0978 0.0858 0.0803 0.0744 0.0695 0.0660 0.0638 0.0625 0.0616 0.0612 0.0607 0.0600 0.0598 

[TRAIN] Epoch[1](8400/114412); Loss: 0.083524; Backpropagation: 0.3008 sec; Batch: 2.1300 sec
0.1579 0.1443 0.1124 0.0977 0.0847 0.0768 0.0731 0.0705 0.0681 0.0669 0.0656 0.0647 0.0641 0.0636 0.0630 0.0629 

[TRAIN] Epoch[1](8401/114412); Loss: 0.069746; Backpropagation: 0.2957 sec; Batch: 2.1203 sec
0.1702 0.1440 0.1144 0.0994 0.0783 0.0632 0.0545 0.0501 0.0475 0.0455 0.0437 0.0424 0.0414 0.0409 0.0404 0.0400 

[TRAIN] Epoch[1](8402/114412); Loss: 0.095499; Backpropagation: 0.2957 sec; Batch: 2.1209 sec
0.1590 0.1563 0.1234 0.1120 0.0999 0.0927 0.0876 0.0851 0.0815 0.0794 0.0780 0.0763 0.0752 0.0745 0.0738 0.0735 

[TRAIN] Epoch[1](8403/114412); Loss: 0.095210; Backpropagation: 0.3005 sec; Batch: 2.1267 sec
0.1626 0.1498 0.1277 0.1180 0.1013 0.0921 0.0859 0.0823 0.0798 0.0776 0.0762 0.0753 0.0747 0.0740 0.0734 0.0729 

[TRAIN] Epoch[1](8404/114412); Loss: 0.084815; Backpropagation: 0.2980 sec; Batch: 2.1227 sec
0.1327 0.1267 0.1096 0.0996 0.0907 0.0849 0.0801 0.0767 0.0737 0.0719 0.0706 0.0693 0.0686 0.0678 0.0673 0.0669 

[TRAIN] Epoch[1](8405/114412); Loss: 0.073827; Backpropagation: 0.2978 sec; Batch: 2.1210 sec
0.1614 0.1471 0.1042 0.0876 0.0729 0.0662 0.0619 0.0595 0.0565 0.0551 0.0538 0.0525 0.0517 0.0509 0.0502 0.0499 

[TRAIN] Epoch[1](8406/114412); Loss: 0.070357; Backpropagation: 0.2955 sec; Batch: 2.1189 sec
0.1332 0.1290 0.0909 0.0784 0.0695 0.0646 0.0622 0.0600 0.0579 0.0566 0.0556 0.0544 0.0539 0.0535 0.0530 0.0530 

[TRAIN] Epoch[1](8407/114412); Loss: 0.110497; Backpropagation: 0.2951 sec; Batch: 2.1224 sec
0.1924 0.1798 0.1492 0.1353 0.1188 0.1071 0.1010 0.0950 0.0924 0.0896 0.0877 0.0861 0.0846 0.0838 0.0830 0.0822 

[TRAIN] Epoch[1](8408/114412); Loss: 0.092553; Backpropagation: 0.2958 sec; Batch: 2.0813 sec
0.1981 0.1789 0.1338 0.1108 0.0899 0.0830 0.0775 0.0749 0.0724 0.0705 0.0685 0.0668 0.0653 0.0643 0.0634 0.0628 

[TRAIN] Epoch[1](8409/114412); Loss: 0.097836; Backpropagation: 0.2956 sec; Batch: 2.1316 sec
0.1669 0.1518 0.1160 0.1047 0.0967 0.0928 0.0889 0.0875 0.0854 0.0839 0.0833 0.0823 0.0820 0.0817 0.0810 0.0806 

[TRAIN] Epoch[1](8410/114412); Loss: 0.077110; Backpropagation: 0.3009 sec; Batch: 2.1252 sec
0.1481 0.1337 0.1005 0.0887 0.0792 0.0727 0.0683 0.0655 0.0630 0.0616 0.0608 0.0596 0.0588 0.0582 0.0578 0.0575 

[TRAIN] Epoch[1](8411/114412); Loss: 0.068418; Backpropagation: 0.2966 sec; Batch: 2.1301 sec
0.1479 0.1269 0.0895 0.0781 0.0678 0.0621 0.0592 0.0570 0.0543 0.0525 0.0517 0.0507 0.0500 0.0496 0.0490 0.0485 

[TRAIN] Epoch[1](8412/114412); Loss: 0.098548; Backpropagation: 0.2957 sec; Batch: 2.1208 sec
0.1788 0.1640 0.1327 0.1189 0.1009 0.0940 0.0876 0.0845 0.0816 0.0797 0.0779 0.0768 0.0758 0.0750 0.0745 0.0740 

[TRAIN] Epoch[1](8413/114412); Loss: 0.075305; Backpropagation: 0.2960 sec; Batch: 2.1228 sec
0.1329 0.1255 0.1038 0.0916 0.0813 0.0736 0.0695 0.0649 0.0623 0.0600 0.0585 0.0575 0.0567 0.0561 0.0555 0.0551 

[TRAIN] Epoch[1](8414/114412); Loss: 0.111072; Backpropagation: 0.2962 sec; Batch: 2.1227 sec
0.2257 0.2136 0.1647 0.1418 0.1166 0.0993 0.0925 0.0884 0.0856 0.0833 0.0811 0.0797 0.0780 0.0767 0.0757 0.0746 

[TRAIN] Epoch[1](8415/114412); Loss: 0.120922; Backpropagation: 0.2979 sec; Batch: 2.1273 sec
0.2149 0.1977 0.1671 0.1505 0.1299 0.1160 0.1069 0.1025 0.0991 0.0970 0.0951 0.0938 0.0925 0.0914 0.0904 0.0899 

[TRAIN] Epoch[1](8416/114412); Loss: 0.068642; Backpropagation: 0.2964 sec; Batch: 2.1253 sec
0.1396 0.1290 0.0989 0.0869 0.0685 0.0649 0.0584 0.0555 0.0530 0.0513 0.0505 0.0496 0.0490 0.0481 0.0478 0.0473 

[TRAIN] Epoch[1](8417/114412); Loss: 0.079309; Backpropagation: 0.2967 sec; Batch: 2.1255 sec
0.1548 0.1377 0.0967 0.0846 0.0776 0.0736 0.0701 0.0681 0.0667 0.0652 0.0641 0.0632 0.0623 0.0618 0.0613 0.0610 

[TRAIN] Epoch[1](8418/114412); Loss: 0.097474; Backpropagation: 0.2933 sec; Batch: 2.1165 sec
0.1510 0.1427 0.1145 0.1056 0.0980 0.0938 0.0911 0.0895 0.0874 0.0860 0.0851 0.0841 0.0834 0.0829 0.0824 0.0821 

[TRAIN] Epoch[1](8419/114412); Loss: 0.074438; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.1384 0.1290 0.0967 0.0855 0.0748 0.0698 0.0663 0.0642 0.0618 0.0605 0.0590 0.0580 0.0574 0.0568 0.0565 0.0563 

[TRAIN] Epoch[1](8420/114412); Loss: 0.088763; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1900 0.1635 0.1188 0.1021 0.0928 0.0852 0.0750 0.0720 0.0701 0.0674 0.0658 0.0650 0.0642 0.0634 0.0627 0.0622 

[TRAIN] Epoch[1](8421/114412); Loss: 0.097418; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1744 0.1575 0.1171 0.1039 0.0926 0.0914 0.0884 0.0873 0.0849 0.0828 0.0818 0.0810 0.0799 0.0792 0.0785 0.0780 

[TRAIN] Epoch[1](8422/114412); Loss: 0.077917; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1442 0.1211 0.0993 0.0890 0.0815 0.0761 0.0710 0.0685 0.0661 0.0643 0.0627 0.0618 0.0609 0.0604 0.0601 0.0597 

[TRAIN] Epoch[1](8423/114412); Loss: 0.087601; Backpropagation: 0.2953 sec; Batch: 2.0811 sec
0.1589 0.1491 0.1205 0.1093 0.0915 0.0800 0.0762 0.0729 0.0720 0.0703 0.0689 0.0680 0.0671 0.0662 0.0656 0.0652 

[TRAIN] Epoch[1](8424/114412); Loss: 0.080897; Backpropagation: 0.2932 sec; Batch: 2.0839 sec
0.1604 0.1431 0.1085 0.0954 0.0821 0.0749 0.0713 0.0689 0.0664 0.0642 0.0622 0.0612 0.0602 0.0594 0.0583 0.0578 

[TRAIN] Epoch[1](8425/114412); Loss: 0.084963; Backpropagation: 0.2951 sec; Batch: 2.1077 sec
0.1656 0.1507 0.1141 0.1009 0.0882 0.0816 0.0770 0.0721 0.0696 0.0673 0.0650 0.0634 0.0622 0.0612 0.0604 0.0600 

[TRAIN] Epoch[1](8426/114412); Loss: 0.082356; Backpropagation: 0.2928 sec; Batch: 2.1195 sec
0.1404 0.1201 0.1008 0.0962 0.0891 0.0831 0.0779 0.0738 0.0719 0.0698 0.0683 0.0669 0.0660 0.0651 0.0644 0.0638 

[TRAIN] Epoch[1](8427/114412); Loss: 0.057035; Backpropagation: 0.2935 sec; Batch: 2.0796 sec
0.1283 0.1173 0.0767 0.0691 0.0551 0.0527 0.0488 0.0465 0.0439 0.0421 0.0406 0.0392 0.0388 0.0381 0.0376 0.0377 

[TRAIN] Epoch[1](8428/114412); Loss: 0.064732; Backpropagation: 0.2932 sec; Batch: 2.1160 sec
0.1213 0.0994 0.0749 0.0715 0.0642 0.0620 0.0600 0.0569 0.0552 0.0542 0.0534 0.0531 0.0526 0.0524 0.0524 0.0521 

[TRAIN] Epoch[1](8429/114412); Loss: 0.088494; Backpropagation: 0.2911 sec; Batch: 2.1148 sec
0.1392 0.1316 0.1075 0.0964 0.0898 0.0863 0.0817 0.0800 0.0784 0.0769 0.0761 0.0755 0.0747 0.0743 0.0739 0.0735 

[TRAIN] Epoch[1](8430/114412); Loss: 0.096666; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.1594 0.1547 0.1246 0.1155 0.1007 0.0910 0.0868 0.0852 0.0832 0.0809 0.0796 0.0784 0.0775 0.0770 0.0763 0.0758 

[TRAIN] Epoch[1](8431/114412); Loss: 0.063625; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1175 0.1059 0.0915 0.0725 0.0666 0.0596 0.0568 0.0547 0.0519 0.0510 0.0500 0.0488 0.0484 0.0478 0.0476 0.0474 

[TRAIN] Epoch[1](8432/114412); Loss: 0.090011; Backpropagation: 0.2950 sec; Batch: 2.1270 sec
0.1617 0.1323 0.1078 0.1006 0.0933 0.0862 0.0829 0.0804 0.0782 0.0766 0.0754 0.0744 0.0735 0.0728 0.0722 0.0718 

[TRAIN] Epoch[1](8433/114412); Loss: 0.075402; Backpropagation: 0.2926 sec; Batch: 2.1176 sec
0.1530 0.1328 0.0986 0.0890 0.0770 0.0698 0.0660 0.0635 0.0615 0.0598 0.0580 0.0570 0.0561 0.0553 0.0547 0.0542 

[TRAIN] Epoch[1](8434/114412); Loss: 0.084624; Backpropagation: 0.2929 sec; Batch: 2.1172 sec
0.1397 0.1337 0.1165 0.1029 0.0917 0.0799 0.0764 0.0738 0.0711 0.0699 0.0684 0.0672 0.0667 0.0660 0.0654 0.0649 

[TRAIN] Epoch[1](8435/114412); Loss: 0.086829; Backpropagation: 0.2909 sec; Batch: 2.1153 sec
0.2248 0.2001 0.1436 0.1277 0.0946 0.0759 0.0652 0.0597 0.0559 0.0529 0.0511 0.0501 0.0482 0.0474 0.0464 0.0457 

[TRAIN] Epoch[1](8436/114412); Loss: 0.066173; Backpropagation: 0.2911 sec; Batch: 2.1213 sec
0.1580 0.1367 0.0889 0.0727 0.0646 0.0580 0.0546 0.0523 0.0502 0.0487 0.0474 0.0464 0.0459 0.0452 0.0448 0.0445 

[TRAIN] Epoch[1](8437/114412); Loss: 0.085942; Backpropagation: 0.2919 sec; Batch: 2.1306 sec
0.1682 0.1613 0.1138 0.1011 0.0881 0.0800 0.0748 0.0734 0.0691 0.0668 0.0651 0.0641 0.0632 0.0624 0.0619 0.0619 

[TRAIN] Epoch[1](8438/114412); Loss: 0.057121; Backpropagation: 0.2913 sec; Batch: 2.1106 sec
0.1258 0.0940 0.0818 0.0711 0.0685 0.0568 0.0487 0.0472 0.0446 0.0431 0.0411 0.0396 0.0389 0.0381 0.0376 0.0371 

[TRAIN] Epoch[1](8439/114412); Loss: 0.068013; Backpropagation: 0.2911 sec; Batch: 2.1120 sec
0.1481 0.1313 0.0949 0.0763 0.0654 0.0604 0.0566 0.0546 0.0529 0.0514 0.0508 0.0500 0.0493 0.0490 0.0487 0.0484 

[TRAIN] Epoch[1](8440/114412); Loss: 0.060956; Backpropagation: 0.2908 sec; Batch: 2.1196 sec
0.1349 0.1295 0.0926 0.0756 0.0669 0.0558 0.0524 0.0465 0.0454 0.0423 0.0406 0.0399 0.0388 0.0385 0.0380 0.0377 

[TRAIN] Epoch[1](8441/114412); Loss: 0.072937; Backpropagation: 0.2912 sec; Batch: 2.1237 sec
0.1329 0.1260 0.0973 0.0863 0.0754 0.0702 0.0657 0.0625 0.0601 0.0587 0.0571 0.0559 0.0554 0.0550 0.0543 0.0542 

[TRAIN] Epoch[1](8442/114412); Loss: 0.071900; Backpropagation: 0.2909 sec; Batch: 2.1132 sec
0.1488 0.1282 0.0946 0.0801 0.0708 0.0649 0.0631 0.0612 0.0587 0.0569 0.0557 0.0546 0.0539 0.0534 0.0529 0.0526 

[TRAIN] Epoch[1](8443/114412); Loss: 0.083277; Backpropagation: 0.2924 sec; Batch: 2.1260 sec
0.1584 0.1444 0.1117 0.0995 0.0854 0.0791 0.0729 0.0706 0.0685 0.0663 0.0649 0.0638 0.0626 0.0620 0.0614 0.0607 

[TRAIN] Epoch[1](8444/114412); Loss: 0.085694; Backpropagation: 0.2930 sec; Batch: 2.1166 sec
0.1399 0.1246 0.1004 0.0966 0.0903 0.0844 0.0819 0.0787 0.0760 0.0746 0.0728 0.0716 0.0707 0.0700 0.0696 0.0690 

[TRAIN] Epoch[1](8445/114412); Loss: 0.105313; Backpropagation: 0.2926 sec; Batch: 2.1196 sec
0.1630 0.1431 0.1258 0.1177 0.1088 0.1013 0.0988 0.0962 0.0942 0.0927 0.0918 0.0911 0.0906 0.0903 0.0899 0.0897 

[TRAIN] Epoch[1](8446/114412); Loss: 0.088709; Backpropagation: 0.2922 sec; Batch: 2.1213 sec
0.1574 0.1441 0.1157 0.1043 0.0902 0.0846 0.0792 0.0771 0.0757 0.0729 0.0717 0.0709 0.0699 0.0691 0.0685 0.0680 

[TRAIN] Epoch[1](8447/114412); Loss: 0.074055; Backpropagation: 0.2910 sec; Batch: 2.1256 sec
0.1328 0.1190 0.0951 0.0825 0.0737 0.0723 0.0674 0.0650 0.0633 0.0619 0.0605 0.0594 0.0588 0.0583 0.0576 0.0573 

[TRAIN] Epoch[1](8448/114412); Loss: 0.070751; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1504 0.1406 0.1027 0.0851 0.0682 0.0625 0.0594 0.0573 0.0542 0.0522 0.0516 0.0506 0.0499 0.0495 0.0492 0.0489 

[TRAIN] Epoch[1](8449/114412); Loss: 0.092496; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1407 0.1301 0.1098 0.1016 0.0963 0.0924 0.0882 0.0855 0.0834 0.0814 0.0803 0.0795 0.0785 0.0778 0.0774 0.0770 

[TRAIN] Epoch[1](8450/114412); Loss: 0.075836; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1793 0.1541 0.0994 0.0891 0.0785 0.0681 0.0644 0.0584 0.0564 0.0556 0.0539 0.0531 0.0517 0.0508 0.0504 0.0502 

[TRAIN] Epoch[1](8451/114412); Loss: 0.082181; Backpropagation: 0.2913 sec; Batch: 2.1218 sec
0.1275 0.1141 0.1003 0.0934 0.0875 0.0819 0.0783 0.0763 0.0736 0.0714 0.0701 0.0691 0.0687 0.0681 0.0676 0.0670 

[TRAIN] Epoch[1](8452/114412); Loss: 0.103205; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1606 0.1453 0.1214 0.1123 0.1044 0.1008 0.0971 0.0947 0.0929 0.0915 0.0903 0.0893 0.0887 0.0878 0.0874 0.0870 

[TRAIN] Epoch[1](8453/114412); Loss: 0.083796; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.1791 0.1513 0.1120 0.0979 0.0811 0.0754 0.0711 0.0691 0.0666 0.0651 0.0638 0.0627 0.0620 0.0615 0.0611 0.0609 

[TRAIN] Epoch[1](8454/114412); Loss: 0.080457; Backpropagation: 0.2907 sec; Batch: 2.1139 sec
0.1398 0.1257 0.1021 0.0924 0.0829 0.0791 0.0737 0.0718 0.0692 0.0674 0.0658 0.0649 0.0640 0.0633 0.0628 0.0623 

[TRAIN] Epoch[1](8455/114412); Loss: 0.083193; Backpropagation: 0.2931 sec; Batch: 2.1151 sec
0.1705 0.1614 0.1044 0.0872 0.0787 0.0742 0.0704 0.0688 0.0674 0.0659 0.0650 0.0645 0.0639 0.0632 0.0629 0.0626 

[TRAIN] Epoch[1](8456/114412); Loss: 0.077538; Backpropagation: 0.2920 sec; Batch: 2.1163 sec
0.1735 0.1427 0.0979 0.0824 0.0808 0.0685 0.0676 0.0647 0.0624 0.0605 0.0587 0.0576 0.0566 0.0559 0.0553 0.0554 

[TRAIN] Epoch[1](8457/114412); Loss: 0.088295; Backpropagation: 0.2954 sec; Batch: 2.1220 sec
0.1824 0.1523 0.1101 0.0981 0.0864 0.0815 0.0778 0.0739 0.0724 0.0706 0.0698 0.0688 0.0680 0.0674 0.0669 0.0664 

[TRAIN] Epoch[1](8458/114412); Loss: 0.059996; Backpropagation: 0.2918 sec; Batch: 2.1267 sec
0.1167 0.1083 0.0741 0.0683 0.0601 0.0563 0.0527 0.0509 0.0494 0.0482 0.0473 0.0464 0.0460 0.0454 0.0450 0.0449 

[TRAIN] Epoch[1](8459/114412); Loss: 0.073521; Backpropagation: 0.2915 sec; Batch: 2.0772 sec
0.1436 0.1337 0.1000 0.0844 0.0730 0.0677 0.0643 0.0614 0.0590 0.0579 0.0565 0.0558 0.0552 0.0547 0.0546 0.0544 

[TRAIN] Epoch[1](8460/114412); Loss: 0.065747; Backpropagation: 0.2914 sec; Batch: 2.0802 sec
0.1304 0.1159 0.0887 0.0744 0.0705 0.0631 0.0585 0.0559 0.0528 0.0518 0.0502 0.0489 0.0483 0.0480 0.0474 0.0471 

[TRAIN] Epoch[1](8461/114412); Loss: 0.094056; Backpropagation: 0.2930 sec; Batch: 2.1078 sec
0.1697 0.1597 0.1172 0.1012 0.0934 0.0877 0.0850 0.0817 0.0802 0.0778 0.0766 0.0761 0.0753 0.0747 0.0745 0.0741 

[TRAIN] Epoch[1](8462/114412); Loss: 0.072599; Backpropagation: 0.2953 sec; Batch: 2.1230 sec
0.1338 0.1100 0.0926 0.0859 0.0753 0.0702 0.0663 0.0642 0.0623 0.0605 0.0589 0.0579 0.0568 0.0561 0.0557 0.0553 

[TRAIN] Epoch[1](8463/114412); Loss: 0.084240; Backpropagation: 0.2929 sec; Batch: 2.1172 sec
0.1247 0.1204 0.1006 0.0917 0.0875 0.0819 0.0785 0.0773 0.0760 0.0748 0.0738 0.0730 0.0725 0.0721 0.0719 0.0712 

[TRAIN] Epoch[1](8464/114412); Loss: 0.090053; Backpropagation: 0.2915 sec; Batch: 2.0776 sec
0.1773 0.1581 0.1256 0.1094 0.0962 0.0840 0.0770 0.0738 0.0714 0.0699 0.0686 0.0673 0.0663 0.0657 0.0653 0.0650 

[TRAIN] Epoch[1](8465/114412); Loss: 0.081777; Backpropagation: 0.2914 sec; Batch: 2.1158 sec
0.1206 0.1077 0.0978 0.0937 0.0913 0.0838 0.0785 0.0756 0.0737 0.0719 0.0709 0.0700 0.0691 0.0684 0.0679 0.0676 

[TRAIN] Epoch[1](8466/114412); Loss: 0.080274; Backpropagation: 0.2911 sec; Batch: 2.1209 sec
0.2324 0.1958 0.1230 0.0844 0.0675 0.0621 0.0582 0.0582 0.0558 0.0535 0.0515 0.0498 0.0489 0.0482 0.0478 0.0474 

[TRAIN] Epoch[1](8467/114412); Loss: 0.077437; Backpropagation: 0.2915 sec; Batch: 2.0786 sec
0.1299 0.1199 0.0955 0.0873 0.0777 0.0734 0.0703 0.0691 0.0673 0.0658 0.0650 0.0644 0.0639 0.0635 0.0631 0.0629 

[TRAIN] Epoch[1](8468/114412); Loss: 0.063924; Backpropagation: 0.2909 sec; Batch: 2.1763 sec
0.1273 0.1110 0.0795 0.0731 0.0666 0.0610 0.0573 0.0546 0.0527 0.0511 0.0499 0.0489 0.0481 0.0476 0.0473 0.0468 

[TRAIN] Epoch[1](8469/114412); Loss: 0.090044; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.1442 0.1339 0.1093 0.0995 0.0926 0.0879 0.0840 0.0811 0.0794 0.0778 0.0767 0.0758 0.0753 0.0747 0.0744 0.0739 

[TRAIN] Epoch[1](8470/114412); Loss: 0.077427; Backpropagation: 0.2910 sec; Batch: 2.1299 sec
0.1200 0.1164 0.0939 0.0863 0.0810 0.0771 0.0727 0.0705 0.0685 0.0668 0.0657 0.0650 0.0645 0.0640 0.0634 0.0631 

[TRAIN] Epoch[1](8471/114412); Loss: 0.067571; Backpropagation: 0.2910 sec; Batch: 2.0786 sec
0.1156 0.1032 0.0835 0.0758 0.0699 0.0655 0.0626 0.0612 0.0588 0.0570 0.0561 0.0552 0.0549 0.0542 0.0539 0.0536 

[TRAIN] Epoch[1](8472/114412); Loss: 0.071531; Backpropagation: 0.2915 sec; Batch: 2.1173 sec
0.1362 0.1273 0.0901 0.0803 0.0715 0.0670 0.0642 0.0619 0.0591 0.0571 0.0561 0.0556 0.0550 0.0545 0.0543 0.0542 

[TRAIN] Epoch[1](8473/114412); Loss: 0.073583; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1625 0.1470 0.1043 0.0899 0.0753 0.0657 0.0636 0.0592 0.0558 0.0536 0.0519 0.0508 0.0502 0.0496 0.0492 0.0488 

[TRAIN] Epoch[1](8474/114412); Loss: 0.097838; Backpropagation: 0.2933 sec; Batch: 2.1163 sec
0.2115 0.1777 0.1300 0.1070 0.0962 0.0893 0.0844 0.0808 0.0787 0.0769 0.0748 0.0736 0.0722 0.0713 0.0707 0.0702 

[TRAIN] Epoch[1](8475/114412); Loss: 0.068002; Backpropagation: 0.2914 sec; Batch: 2.1277 sec
0.1401 0.1250 0.0893 0.0803 0.0676 0.0622 0.0594 0.0570 0.0547 0.0530 0.0519 0.0508 0.0499 0.0494 0.0489 0.0485 

[TRAIN] Epoch[1](8476/114412); Loss: 0.094795; Backpropagation: 0.2910 sec; Batch: 2.1216 sec
0.1777 0.1593 0.1133 0.1003 0.0923 0.0855 0.0835 0.0820 0.0802 0.0796 0.0786 0.0779 0.0773 0.0765 0.0765 0.0760 

[TRAIN] Epoch[1](8477/114412); Loss: 0.082904; Backpropagation: 0.2908 sec; Batch: 2.1215 sec
0.1411 0.1209 0.0987 0.0907 0.0853 0.0810 0.0773 0.0759 0.0743 0.0719 0.0705 0.0694 0.0684 0.0677 0.0670 0.0664 

[TRAIN] Epoch[1](8478/114412); Loss: 0.070686; Backpropagation: 0.2912 sec; Batch: 2.0831 sec
0.1484 0.1266 0.0842 0.0730 0.0708 0.0656 0.0620 0.0611 0.0582 0.0567 0.0557 0.0548 0.0545 0.0536 0.0531 0.0528 

[TRAIN] Epoch[1](8479/114412); Loss: 0.079685; Backpropagation: 0.2926 sec; Batch: 2.1182 sec
0.1410 0.1288 0.1002 0.0879 0.0823 0.0755 0.0727 0.0702 0.0681 0.0666 0.0656 0.0644 0.0637 0.0632 0.0626 0.0623 

[TRAIN] Epoch[1](8480/114412); Loss: 0.071678; Backpropagation: 0.2931 sec; Batch: 2.1170 sec
0.1188 0.1129 0.0936 0.0855 0.0733 0.0696 0.0659 0.0634 0.0613 0.0598 0.0585 0.0579 0.0574 0.0568 0.0564 0.0560 

[TRAIN] Epoch[1](8481/114412); Loss: 0.086862; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.1468 0.1381 0.1092 0.0993 0.0936 0.0852 0.0809 0.0773 0.0747 0.0726 0.0711 0.0697 0.0689 0.0681 0.0674 0.0670 

[TRAIN] Epoch[1](8482/114412); Loss: 0.060715; Backpropagation: 0.2932 sec; Batch: 2.1170 sec
0.1536 0.1505 0.0851 0.0712 0.0579 0.0512 0.0468 0.0443 0.0415 0.0399 0.0393 0.0388 0.0384 0.0378 0.0375 0.0374 

[TRAIN] Epoch[1](8483/114412); Loss: 0.069315; Backpropagation: 0.2932 sec; Batch: 2.0857 sec
0.1370 0.1141 0.0944 0.0833 0.0734 0.0676 0.0615 0.0583 0.0557 0.0540 0.0532 0.0523 0.0517 0.0514 0.0507 0.0505 

[TRAIN] Epoch[1](8484/114412); Loss: 0.084157; Backpropagation: 0.2952 sec; Batch: 2.1189 sec
0.1668 0.1463 0.1124 0.0978 0.0860 0.0795 0.0748 0.0714 0.0690 0.0671 0.0655 0.0638 0.0628 0.0620 0.0609 0.0604 

[TRAIN] Epoch[1](8485/114412); Loss: 0.072722; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.1737 0.1322 0.0888 0.0725 0.0728 0.0652 0.0637 0.0594 0.0588 0.0569 0.0554 0.0543 0.0537 0.0525 0.0522 0.0516 

[TRAIN] Epoch[1](8486/114412); Loss: 0.077543; Backpropagation: 0.2915 sec; Batch: 2.1154 sec
0.1741 0.1609 0.1163 0.0961 0.0774 0.0680 0.0630 0.0597 0.0572 0.0549 0.0539 0.0529 0.0524 0.0518 0.0513 0.0509 

[TRAIN] Epoch[1](8487/114412); Loss: 0.093044; Backpropagation: 0.2915 sec; Batch: 2.1118 sec
0.1821 0.1449 0.1147 0.1011 0.0928 0.0896 0.0866 0.0839 0.0802 0.0771 0.0748 0.0735 0.0726 0.0719 0.0716 0.0713 

[TRAIN] Epoch[1](8488/114412); Loss: 0.083108; Backpropagation: 0.2906 sec; Batch: 2.1148 sec
0.1779 0.1610 0.1260 0.1053 0.0878 0.0755 0.0682 0.0652 0.0621 0.0599 0.0590 0.0577 0.0569 0.0563 0.0556 0.0553 

[TRAIN] Epoch[1](8489/114412); Loss: 0.070684; Backpropagation: 0.2913 sec; Batch: 2.1136 sec
0.1301 0.1068 0.0900 0.0814 0.0760 0.0701 0.0649 0.0618 0.0600 0.0585 0.0573 0.0561 0.0554 0.0547 0.0542 0.0538 

[TRAIN] Epoch[1](8490/114412); Loss: 0.110730; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1865 0.1668 0.1350 0.1210 0.1111 0.1049 0.1016 0.0987 0.0970 0.0956 0.0941 0.0930 0.0925 0.0916 0.0913 0.0909 

[TRAIN] Epoch[1](8491/114412); Loss: 0.071674; Backpropagation: 0.2929 sec; Batch: 2.1161 sec
0.1316 0.1188 0.0872 0.0803 0.0743 0.0696 0.0646 0.0629 0.0606 0.0591 0.0582 0.0570 0.0563 0.0560 0.0553 0.0549 

[TRAIN] Epoch[1](8492/114412); Loss: 0.079727; Backpropagation: 0.2924 sec; Batch: 2.1171 sec
0.1655 0.1468 0.1121 0.0933 0.0773 0.0721 0.0676 0.0654 0.0630 0.0617 0.0602 0.0593 0.0585 0.0580 0.0576 0.0573 

[TRAIN] Epoch[1](8493/114412); Loss: 0.103567; Backpropagation: 0.2933 sec; Batch: 2.1198 sec
0.1718 0.1490 0.1203 0.1144 0.1067 0.1014 0.0962 0.0941 0.0926 0.0900 0.0887 0.0877 0.0867 0.0862 0.0859 0.0854 

[TRAIN] Epoch[1](8494/114412); Loss: 0.077874; Backpropagation: 0.2951 sec; Batch: 2.1187 sec
0.1596 0.1336 0.0874 0.0920 0.0829 0.0748 0.0687 0.0669 0.0641 0.0622 0.0612 0.0598 0.0590 0.0584 0.0579 0.0577 

[TRAIN] Epoch[1](8495/114412); Loss: 0.075187; Backpropagation: 0.2949 sec; Batch: 2.1199 sec
0.1494 0.1236 0.0953 0.0819 0.0788 0.0717 0.0669 0.0642 0.0619 0.0605 0.0597 0.0590 0.0581 0.0576 0.0573 0.0570 

[TRAIN] Epoch[1](8496/114412); Loss: 0.075223; Backpropagation: 0.2915 sec; Batch: 2.1190 sec
0.1229 0.1179 0.0895 0.0824 0.0771 0.0724 0.0693 0.0678 0.0660 0.0646 0.0635 0.0628 0.0623 0.0619 0.0616 0.0614 

[TRAIN] Epoch[1](8497/114412); Loss: 0.089111; Backpropagation: 0.2909 sec; Batch: 2.1201 sec
0.2068 0.1832 0.1386 0.1157 0.0883 0.0713 0.0719 0.0692 0.0663 0.0623 0.0605 0.0599 0.0591 0.0583 0.0574 0.0570 

[TRAIN] Epoch[1](8498/114412); Loss: 0.064124; Backpropagation: 0.2911 sec; Batch: 2.1134 sec
0.1302 0.1138 0.0901 0.0772 0.0661 0.0600 0.0565 0.0538 0.0510 0.0493 0.0481 0.0468 0.0463 0.0459 0.0456 0.0453 

[TRAIN] Epoch[1](8499/114412); Loss: 0.086037; Backpropagation: 0.2931 sec; Batch: 2.1191 sec
0.1710 0.1473 0.1094 0.0933 0.0851 0.0818 0.0768 0.0737 0.0712 0.0695 0.0684 0.0672 0.0663 0.0656 0.0651 0.0648 

[TRAIN] Epoch[1](8500/114412); Loss: 0.050777; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1137 0.0975 0.0691 0.0576 0.0514 0.0449 0.0421 0.0406 0.0393 0.0381 0.0374 0.0368 0.0363 0.0361 0.0358 0.0359 

[TRAIN] Epoch[1](8501/114412); Loss: 0.095348; Backpropagation: 0.2931 sec; Batch: 2.0888 sec
0.1899 0.1814 0.1376 0.1226 0.1028 0.0890 0.0817 0.0771 0.0731 0.0707 0.0688 0.0676 0.0667 0.0661 0.0655 0.0649 

[TRAIN] Epoch[1](8502/114412); Loss: 0.075375; Backpropagation: 0.2927 sec; Batch: 2.1165 sec
0.1304 0.1085 0.0987 0.0869 0.0795 0.0746 0.0693 0.0675 0.0651 0.0634 0.0625 0.0613 0.0604 0.0599 0.0593 0.0588 

[TRAIN] Epoch[1](8503/114412); Loss: 0.073795; Backpropagation: 0.2952 sec; Batch: 2.1204 sec
0.1478 0.1340 0.0966 0.0812 0.0730 0.0671 0.0644 0.0623 0.0600 0.0588 0.0575 0.0565 0.0560 0.0555 0.0551 0.0551 

[TRAIN] Epoch[1](8504/114412); Loss: 0.060400; Backpropagation: 0.2934 sec; Batch: 2.1200 sec
0.1185 0.1103 0.0817 0.0673 0.0606 0.0558 0.0528 0.0507 0.0494 0.0478 0.0468 0.0461 0.0454 0.0449 0.0445 0.0440 

[TRAIN] Epoch[1](8505/114412); Loss: 0.103001; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.1598 0.1487 0.1256 0.1157 0.1066 0.1006 0.0956 0.0931 0.0908 0.0896 0.0888 0.0878 0.0870 0.0865 0.0860 0.0858 

[TRAIN] Epoch[1](8506/114412); Loss: 0.081931; Backpropagation: 0.2908 sec; Batch: 2.1182 sec
0.1598 0.1401 0.1099 0.0970 0.0846 0.0770 0.0721 0.0691 0.0668 0.0651 0.0640 0.0626 0.0616 0.0609 0.0605 0.0599 

[TRAIN] Epoch[1](8507/114412); Loss: 0.096938; Backpropagation: 0.2911 sec; Batch: 2.1232 sec
0.1736 0.1580 0.1248 0.1070 0.0983 0.0906 0.0864 0.0847 0.0822 0.0809 0.0796 0.0784 0.0777 0.0768 0.0763 0.0758 

[TRAIN] Epoch[1](8508/114412); Loss: 0.085362; Backpropagation: 0.2953 sec; Batch: 2.1205 sec
0.1888 0.1616 0.1131 0.1058 0.0894 0.0788 0.0723 0.0677 0.0651 0.0637 0.0620 0.0608 0.0600 0.0594 0.0588 0.0583 

[TRAIN] Epoch[1](8509/114412); Loss: 0.087056; Backpropagation: 0.2912 sec; Batch: 2.1218 sec
0.1526 0.1424 0.1122 0.0991 0.0913 0.0841 0.0798 0.0764 0.0735 0.0717 0.0707 0.0693 0.0682 0.0678 0.0670 0.0666 

[TRAIN] Epoch[1](8510/114412); Loss: 0.097821; Backpropagation: 0.2907 sec; Batch: 2.0957 sec
0.2444 0.2196 0.1671 0.1389 0.1007 0.0758 0.0698 0.0660 0.0637 0.0626 0.0614 0.0604 0.0594 0.0589 0.0585 0.0581 

[TRAIN] Epoch[1](8511/114412); Loss: 0.051379; Backpropagation: 0.2913 sec; Batch: 2.1192 sec
0.1187 0.1033 0.0683 0.0623 0.0530 0.0472 0.0428 0.0414 0.0389 0.0373 0.0365 0.0353 0.0348 0.0345 0.0338 0.0339 

[TRAIN] Epoch[1](8512/114412); Loss: 0.099067; Backpropagation: 0.2910 sec; Batch: 2.1208 sec
0.2124 0.1779 0.1339 0.1092 0.0968 0.0924 0.0841 0.0852 0.0822 0.0771 0.0748 0.0738 0.0722 0.0717 0.0711 0.0704 

[TRAIN] Epoch[1](8513/114412); Loss: 0.078303; Backpropagation: 0.2949 sec; Batch: 2.1633 sec
0.1556 0.1351 0.0955 0.0860 0.0773 0.0753 0.0724 0.0683 0.0648 0.0631 0.0617 0.0610 0.0601 0.0594 0.0588 0.0586 

[TRAIN] Epoch[1](8514/114412); Loss: 0.105142; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.2080 0.1736 0.1390 0.1284 0.1123 0.1015 0.0962 0.0912 0.0870 0.0830 0.0806 0.0787 0.0771 0.0761 0.0751 0.0744 

[TRAIN] Epoch[1](8515/114412); Loss: 0.068938; Backpropagation: 0.2910 sec; Batch: 2.1247 sec
0.1316 0.1297 0.0882 0.0735 0.0702 0.0613 0.0595 0.0586 0.0569 0.0554 0.0542 0.0535 0.0529 0.0526 0.0525 0.0524 

[TRAIN] Epoch[1](8516/114412); Loss: 0.069812; Backpropagation: 0.2954 sec; Batch: 2.1186 sec
0.1378 0.1285 0.0956 0.0846 0.0686 0.0625 0.0599 0.0587 0.0565 0.0545 0.0535 0.0525 0.0518 0.0509 0.0507 0.0505 

[TRAIN] Epoch[1](8517/114412); Loss: 0.064691; Backpropagation: 0.2951 sec; Batch: 2.1212 sec
0.1288 0.1080 0.0785 0.0708 0.0659 0.0604 0.0579 0.0553 0.0532 0.0529 0.0519 0.0510 0.0507 0.0502 0.0497 0.0497 

[TRAIN] Epoch[1](8518/114412); Loss: 0.096801; Backpropagation: 0.2953 sec; Batch: 2.1288 sec
0.2043 0.1855 0.1398 0.1191 0.0952 0.0859 0.0809 0.0771 0.0745 0.0723 0.0713 0.0699 0.0692 0.0686 0.0679 0.0675 

[TRAIN] Epoch[1](8519/114412); Loss: 0.077778; Backpropagation: 0.2932 sec; Batch: 2.1128 sec
0.1449 0.1284 0.1092 0.0945 0.0834 0.0729 0.0678 0.0647 0.0629 0.0613 0.0606 0.0598 0.0589 0.0588 0.0583 0.0580 

[TRAIN] Epoch[1](8520/114412); Loss: 0.097534; Backpropagation: 0.2928 sec; Batch: 2.1202 sec
0.1912 0.1748 0.1404 0.1259 0.1040 0.0913 0.0859 0.0801 0.0769 0.0739 0.0722 0.0708 0.0695 0.0687 0.0678 0.0672 

[TRAIN] Epoch[1](8521/114412); Loss: 0.104066; Backpropagation: 0.2927 sec; Batch: 2.0804 sec
0.1730 0.1547 0.1262 0.1148 0.1055 0.0997 0.0966 0.0937 0.0919 0.0900 0.0887 0.0879 0.0864 0.0859 0.0854 0.0847 

[TRAIN] Epoch[1](8522/114412); Loss: 0.074179; Backpropagation: 0.2909 sec; Batch: 2.1301 sec
0.1361 0.1198 0.1004 0.0881 0.0768 0.0694 0.0654 0.0637 0.0614 0.0598 0.0591 0.0582 0.0577 0.0572 0.0570 0.0568 

[TRAIN] Epoch[1](8523/114412); Loss: 0.091261; Backpropagation: 0.2929 sec; Batch: 2.1229 sec
0.1572 0.1392 0.1114 0.1020 0.0925 0.0872 0.0831 0.0810 0.0794 0.0777 0.0767 0.0759 0.0753 0.0744 0.0737 0.0734 

[TRAIN] Epoch[1](8524/114412); Loss: 0.062552; Backpropagation: 0.2915 sec; Batch: 2.1195 sec
0.1328 0.1222 0.0886 0.0800 0.0641 0.0564 0.0531 0.0507 0.0479 0.0463 0.0447 0.0438 0.0431 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](8525/114412); Loss: 0.083442; Backpropagation: 0.2912 sec; Batch: 2.0776 sec
0.1457 0.1332 0.1004 0.0885 0.0827 0.0796 0.0761 0.0739 0.0722 0.0708 0.0700 0.0692 0.0687 0.0683 0.0678 0.0678 

[TRAIN] Epoch[1](8526/114412); Loss: 0.066511; Backpropagation: 0.2927 sec; Batch: 2.1191 sec
0.1537 0.1511 0.1021 0.0803 0.0676 0.0594 0.0537 0.0508 0.0477 0.0454 0.0441 0.0431 0.0422 0.0416 0.0409 0.0405 

[TRAIN] Epoch[1](8527/114412); Loss: 0.075864; Backpropagation: 0.2932 sec; Batch: 2.1173 sec
0.1424 0.1286 0.1005 0.0865 0.0789 0.0709 0.0676 0.0644 0.0622 0.0609 0.0598 0.0590 0.0587 0.0582 0.0578 0.0575 

[TRAIN] Epoch[1](8528/114412); Loss: 0.080337; Backpropagation: 0.2914 sec; Batch: 2.1162 sec
0.1414 0.1232 0.0990 0.0895 0.0831 0.0787 0.0756 0.0720 0.0694 0.0677 0.0664 0.0652 0.0645 0.0637 0.0631 0.0628 

[TRAIN] Epoch[1](8529/114412); Loss: 0.082835; Backpropagation: 0.2908 sec; Batch: 2.0896 sec
0.1334 0.1295 0.1040 0.0968 0.0860 0.0803 0.0754 0.0737 0.0719 0.0706 0.0690 0.0680 0.0672 0.0668 0.0664 0.0662 

[TRAIN] Epoch[1](8530/114412); Loss: 0.074129; Backpropagation: 0.2915 sec; Batch: 2.1295 sec
0.1506 0.1224 0.0990 0.0871 0.0769 0.0713 0.0658 0.0629 0.0600 0.0588 0.0576 0.0563 0.0551 0.0543 0.0541 0.0539 

[TRAIN] Epoch[1](8531/114412); Loss: 0.067658; Backpropagation: 0.2915 sec; Batch: 2.1167 sec
0.1326 0.1097 0.0877 0.0796 0.0719 0.0645 0.0609 0.0574 0.0554 0.0537 0.0528 0.0521 0.0518 0.0512 0.0507 0.0506 

[TRAIN] Epoch[1](8532/114412); Loss: 0.053662; Backpropagation: 0.2918 sec; Batch: 2.1196 sec
0.1398 0.1298 0.0831 0.0655 0.0531 0.0454 0.0412 0.0390 0.0363 0.0345 0.0336 0.0325 0.0321 0.0314 0.0307 0.0305 

[TRAIN] Epoch[1](8533/114412); Loss: 0.084508; Backpropagation: 0.2927 sec; Batch: 2.1177 sec
0.1998 0.1651 0.1167 0.1060 0.0894 0.0748 0.0693 0.0660 0.0630 0.0604 0.0590 0.0578 0.0571 0.0564 0.0559 0.0557 

[TRAIN] Epoch[1](8534/114412); Loss: 0.089862; Backpropagation: 0.2927 sec; Batch: 2.0813 sec
0.1648 0.1370 0.1047 0.0983 0.0905 0.0834 0.0818 0.0808 0.0783 0.0770 0.0754 0.0741 0.0736 0.0730 0.0727 0.0725 

[TRAIN] Epoch[1](8535/114412); Loss: 0.068078; Backpropagation: 0.2952 sec; Batch: 2.0814 sec
0.1308 0.1190 0.0919 0.0807 0.0716 0.0642 0.0597 0.0580 0.0550 0.0536 0.0525 0.0516 0.0511 0.0503 0.0498 0.0495 

[TRAIN] Epoch[1](8536/114412); Loss: 0.105704; Backpropagation: 0.2956 sec; Batch: 2.0909 sec
0.1575 0.1511 0.1277 0.1177 0.1096 0.1033 0.0985 0.0968 0.0945 0.0927 0.0919 0.0910 0.0905 0.0899 0.0894 0.0891 

[TRAIN] Epoch[1](8537/114412); Loss: 0.097198; Backpropagation: 0.2953 sec; Batch: 2.1226 sec
0.2006 0.1783 0.1344 0.1052 0.0922 0.0872 0.0826 0.0806 0.0778 0.0763 0.0750 0.0741 0.0734 0.0729 0.0724 0.0722 

[TRAIN] Epoch[1](8538/114412); Loss: 0.089082; Backpropagation: 0.2913 sec; Batch: 2.1259 sec
0.1494 0.1376 0.1095 0.0992 0.0912 0.0868 0.0823 0.0803 0.0780 0.0757 0.0745 0.0735 0.0728 0.0721 0.0714 0.0709 

[TRAIN] Epoch[1](8539/114412); Loss: 0.094229; Backpropagation: 0.2911 sec; Batch: 2.1012 sec
0.1509 0.1385 0.1174 0.1062 0.0976 0.0925 0.0874 0.0849 0.0828 0.0812 0.0801 0.0790 0.0782 0.0774 0.0771 0.0767 

[TRAIN] Epoch[1](8540/114412); Loss: 0.072450; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.1445 0.1222 0.0974 0.0845 0.0747 0.0682 0.0633 0.0610 0.0588 0.0574 0.0561 0.0552 0.0546 0.0540 0.0537 0.0534 

[TRAIN] Epoch[1](8541/114412); Loss: 0.083717; Backpropagation: 0.2912 sec; Batch: 2.1121 sec
0.1432 0.1276 0.1078 0.0972 0.0881 0.0818 0.0775 0.0748 0.0718 0.0703 0.0689 0.0676 0.0667 0.0660 0.0653 0.0647 

[TRAIN] Epoch[1](8542/114412); Loss: 0.073141; Backpropagation: 0.2908 sec; Batch: 2.1147 sec
0.1693 0.1517 0.1009 0.0834 0.0731 0.0642 0.0589 0.0566 0.0550 0.0537 0.0525 0.0514 0.0505 0.0500 0.0496 0.0494 

[TRAIN] Epoch[1](8543/114412); Loss: 0.088220; Backpropagation: 0.2913 sec; Batch: 2.1159 sec
0.1536 0.1379 0.1062 0.0921 0.0835 0.0817 0.0805 0.0787 0.0768 0.0752 0.0746 0.0743 0.0742 0.0740 0.0740 0.0741 

[TRAIN] Epoch[1](8544/114412); Loss: 0.088665; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.2042 0.1854 0.1352 0.1156 0.0909 0.0753 0.0683 0.0655 0.0648 0.0619 0.0605 0.0599 0.0587 0.0581 0.0574 0.0569 

[TRAIN] Epoch[1](8545/114412); Loss: 0.088631; Backpropagation: 0.2925 sec; Batch: 2.1188 sec
0.1595 0.1449 0.1169 0.1079 0.0956 0.0873 0.0814 0.0765 0.0730 0.0709 0.0694 0.0681 0.0674 0.0669 0.0664 0.0660 

[TRAIN] Epoch[1](8546/114412); Loss: 0.096089; Backpropagation: 0.2912 sec; Batch: 2.1208 sec
0.1481 0.1269 0.1110 0.1062 0.0997 0.0954 0.0912 0.0883 0.0870 0.0855 0.0845 0.0839 0.0833 0.0827 0.0822 0.0817 

[TRAIN] Epoch[1](8547/114412); Loss: 0.087472; Backpropagation: 0.2912 sec; Batch: 2.0766 sec
0.1637 0.1502 0.1163 0.1050 0.0910 0.0843 0.0773 0.0744 0.0721 0.0697 0.0683 0.0669 0.0660 0.0653 0.0647 0.0642 

[TRAIN] Epoch[1](8548/114412); Loss: 0.075435; Backpropagation: 0.2930 sec; Batch: 2.0797 sec
0.1596 0.1287 0.0946 0.0845 0.0763 0.0692 0.0666 0.0645 0.0621 0.0601 0.0590 0.0578 0.0569 0.0562 0.0557 0.0552 

[TRAIN] Epoch[1](8549/114412); Loss: 0.073287; Backpropagation: 0.2910 sec; Batch: 2.0766 sec
0.1435 0.1250 0.0942 0.0839 0.0729 0.0665 0.0643 0.0625 0.0614 0.0596 0.0582 0.0572 0.0564 0.0559 0.0556 0.0556 

[TRAIN] Epoch[1](8550/114412); Loss: 0.070621; Backpropagation: 0.2910 sec; Batch: 2.0825 sec
0.1580 0.1308 0.1018 0.0828 0.0685 0.0608 0.0583 0.0565 0.0545 0.0534 0.0522 0.0513 0.0508 0.0504 0.0500 0.0498 

[TRAIN] Epoch[1](8551/114412); Loss: 0.080561; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1783 0.1525 0.1117 0.0905 0.0776 0.0704 0.0679 0.0665 0.0638 0.0620 0.0603 0.0589 0.0581 0.0576 0.0567 0.0562 

[TRAIN] Epoch[1](8552/114412); Loss: 0.079076; Backpropagation: 0.2910 sec; Batch: 2.0779 sec
0.1612 0.1371 0.1063 0.0893 0.0761 0.0730 0.0689 0.0662 0.0643 0.0628 0.0617 0.0607 0.0601 0.0595 0.0591 0.0588 

[TRAIN] Epoch[1](8553/114412); Loss: 0.104324; Backpropagation: 0.2957 sec; Batch: 2.0820 sec
0.2041 0.1863 0.1482 0.1319 0.1122 0.0976 0.0912 0.0857 0.0822 0.0792 0.0779 0.0768 0.0754 0.0744 0.0735 0.0726 

[TRAIN] Epoch[1](8554/114412); Loss: 0.063111; Backpropagation: 0.2931 sec; Batch: 2.1780 sec
0.1527 0.1299 0.0857 0.0701 0.0621 0.0559 0.0521 0.0501 0.0476 0.0459 0.0447 0.0439 0.0430 0.0424 0.0420 0.0416 

[TRAIN] Epoch[1](8555/114412); Loss: 0.081382; Backpropagation: 0.2910 sec; Batch: 2.0779 sec
0.1660 0.1394 0.1166 0.1019 0.0921 0.0778 0.0742 0.0679 0.0641 0.0616 0.0596 0.0584 0.0567 0.0558 0.0554 0.0546 

[TRAIN] Epoch[1](8556/114412); Loss: 0.085781; Backpropagation: 0.2910 sec; Batch: 2.1253 sec
0.1509 0.1454 0.1081 0.0965 0.0856 0.0802 0.0761 0.0742 0.0723 0.0712 0.0704 0.0692 0.0687 0.0683 0.0680 0.0673 

[TRAIN] Epoch[1](8557/114412); Loss: 0.087780; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1575 0.1468 0.1176 0.1041 0.0918 0.0830 0.0772 0.0749 0.0725 0.0710 0.0697 0.0688 0.0682 0.0676 0.0671 0.0667 

[TRAIN] Epoch[1](8558/114412); Loss: 0.078889; Backpropagation: 0.2929 sec; Batch: 2.0791 sec
0.1375 0.1215 0.0999 0.0922 0.0814 0.0783 0.0719 0.0689 0.0669 0.0653 0.0646 0.0639 0.0632 0.0625 0.0621 0.0619 

[TRAIN] Epoch[1](8559/114412); Loss: 0.091192; Backpropagation: 0.2931 sec; Batch: 2.0796 sec
0.1401 0.1326 0.1051 0.0991 0.0930 0.0881 0.0855 0.0839 0.0824 0.0806 0.0797 0.0787 0.0781 0.0777 0.0774 0.0772 

[TRAIN] Epoch[1](8560/114412); Loss: 0.098103; Backpropagation: 0.2915 sec; Batch: 2.0813 sec
0.1709 0.1547 0.1281 0.1142 0.0996 0.0931 0.0891 0.0860 0.0836 0.0819 0.0804 0.0792 0.0783 0.0773 0.0768 0.0764 

[TRAIN] Epoch[1](8561/114412); Loss: 0.083615; Backpropagation: 0.2913 sec; Batch: 2.0775 sec
0.1812 0.1609 0.1265 0.1077 0.0920 0.0825 0.0736 0.0667 0.0623 0.0590 0.0567 0.0554 0.0543 0.0536 0.0530 0.0524 

[TRAIN] Epoch[1](8562/114412); Loss: 0.073525; Backpropagation: 0.2917 sec; Batch: 2.0807 sec
0.1762 0.1668 0.1140 0.0950 0.0759 0.0628 0.0572 0.0532 0.0516 0.0492 0.0480 0.0466 0.0459 0.0452 0.0445 0.0443 

[TRAIN] Epoch[1](8563/114412); Loss: 0.078517; Backpropagation: 0.2910 sec; Batch: 2.0778 sec
0.1495 0.1280 0.1025 0.0883 0.0792 0.0740 0.0707 0.0685 0.0661 0.0643 0.0630 0.0615 0.0610 0.0605 0.0598 0.0595 

[TRAIN] Epoch[1](8564/114412); Loss: 0.068599; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1243 0.1100 0.0884 0.0795 0.0736 0.0666 0.0631 0.0602 0.0578 0.0563 0.0548 0.0539 0.0531 0.0526 0.0519 0.0515 

[TRAIN] Epoch[1](8565/114412); Loss: 0.072191; Backpropagation: 0.2913 sec; Batch: 2.1134 sec
0.1220 0.1030 0.0845 0.0768 0.0715 0.0690 0.0668 0.0653 0.0639 0.0631 0.0625 0.0619 0.0615 0.0613 0.0611 0.0609 

[TRAIN] Epoch[1](8566/114412); Loss: 0.074323; Backpropagation: 0.2903 sec; Batch: 2.0771 sec
0.1244 0.1172 0.0917 0.0834 0.0806 0.0729 0.0695 0.0676 0.0646 0.0629 0.0614 0.0601 0.0592 0.0585 0.0579 0.0573 

[TRAIN] Epoch[1](8567/114412); Loss: 0.091783; Backpropagation: 0.2914 sec; Batch: 2.1170 sec
0.1902 0.1681 0.1303 0.1142 0.0927 0.0840 0.0778 0.0757 0.0715 0.0696 0.0682 0.0668 0.0659 0.0651 0.0644 0.0638 

[TRAIN] Epoch[1](8568/114412); Loss: 0.075417; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.1270 0.1051 0.0925 0.0818 0.0792 0.0722 0.0698 0.0689 0.0666 0.0653 0.0644 0.0637 0.0631 0.0627 0.0623 0.0621 

[TRAIN] Epoch[1](8569/114412); Loss: 0.085900; Backpropagation: 0.2909 sec; Batch: 2.1142 sec
0.1372 0.1285 0.1044 0.0962 0.0891 0.0842 0.0804 0.0781 0.0763 0.0746 0.0732 0.0721 0.0710 0.0704 0.0697 0.0690 

[TRAIN] Epoch[1](8570/114412); Loss: 0.070097; Backpropagation: 0.2930 sec; Batch: 2.1161 sec
0.1165 0.1058 0.0890 0.0803 0.0736 0.0695 0.0663 0.0636 0.0609 0.0592 0.0581 0.0569 0.0562 0.0557 0.0551 0.0549 

[TRAIN] Epoch[1](8571/114412); Loss: 0.077813; Backpropagation: 0.2927 sec; Batch: 2.1205 sec
0.1439 0.1268 0.0948 0.0864 0.0778 0.0726 0.0693 0.0670 0.0656 0.0647 0.0637 0.0631 0.0626 0.0624 0.0622 0.0621 

[TRAIN] Epoch[1](8572/114412); Loss: 0.096920; Backpropagation: 0.2910 sec; Batch: 2.1165 sec
0.1507 0.1415 0.1193 0.1092 0.1007 0.0948 0.0908 0.0883 0.0860 0.0844 0.0831 0.0820 0.0811 0.0803 0.0794 0.0790 

[TRAIN] Epoch[1](8573/114412); Loss: 0.076865; Backpropagation: 0.2908 sec; Batch: 2.0895 sec
0.1576 0.1469 0.0960 0.0819 0.0754 0.0694 0.0666 0.0646 0.0623 0.0611 0.0600 0.0590 0.0581 0.0574 0.0571 0.0564 

[TRAIN] Epoch[1](8574/114412); Loss: 0.075685; Backpropagation: 0.2929 sec; Batch: 2.1192 sec
0.1482 0.1333 0.0987 0.0878 0.0757 0.0707 0.0668 0.0635 0.0622 0.0603 0.0590 0.0582 0.0575 0.0568 0.0563 0.0559 

[TRAIN] Epoch[1](8575/114412); Loss: 0.100395; Backpropagation: 0.2949 sec; Batch: 2.1209 sec
0.2098 0.1869 0.1471 0.1254 0.1091 0.0936 0.0878 0.0822 0.0780 0.0743 0.0717 0.0709 0.0691 0.0677 0.0667 0.0660 

[TRAIN] Epoch[1](8576/114412); Loss: 0.081342; Backpropagation: 0.2963 sec; Batch: 2.1218 sec
0.1445 0.1306 0.1017 0.0903 0.0830 0.0786 0.0744 0.0722 0.0701 0.0683 0.0670 0.0659 0.0648 0.0640 0.0634 0.0628 

[TRAIN] Epoch[1](8577/114412); Loss: 0.059739; Backpropagation: 0.2914 sec; Batch: 2.1205 sec
0.1058 0.0939 0.0745 0.0676 0.0618 0.0574 0.0548 0.0525 0.0507 0.0497 0.0492 0.0484 0.0480 0.0476 0.0471 0.0469 

[TRAIN] Epoch[1](8578/114412); Loss: 0.084018; Backpropagation: 0.2918 sec; Batch: 2.1144 sec
0.1816 0.1601 0.1117 0.0970 0.0835 0.0762 0.0727 0.0701 0.0670 0.0643 0.0626 0.0612 0.0602 0.0593 0.0588 0.0582 

[TRAIN] Epoch[1](8579/114412); Loss: 0.096318; Backpropagation: 0.2910 sec; Batch: 2.1163 sec
0.2185 0.1893 0.1406 0.1159 0.0955 0.0871 0.0782 0.0762 0.0727 0.0701 0.0688 0.0671 0.0661 0.0657 0.0649 0.0645 

[TRAIN] Epoch[1](8580/114412); Loss: 0.072381; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1522 0.1354 0.0964 0.0842 0.0733 0.0656 0.0606 0.0600 0.0582 0.0559 0.0543 0.0534 0.0528 0.0525 0.0519 0.0512 

[TRAIN] Epoch[1](8581/114412); Loss: 0.084294; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1469 0.1190 0.1045 0.0969 0.0878 0.0857 0.0806 0.0756 0.0740 0.0715 0.0699 0.0687 0.0678 0.0671 0.0666 0.0661 

[TRAIN] Epoch[1](8582/114412); Loss: 0.054281; Backpropagation: 0.2954 sec; Batch: 2.1192 sec
0.0996 0.0764 0.0719 0.0618 0.0594 0.0523 0.0507 0.0487 0.0466 0.0452 0.0441 0.0431 0.0425 0.0422 0.0423 0.0417 

[TRAIN] Epoch[1](8583/114412); Loss: 0.087876; Backpropagation: 0.2955 sec; Batch: 2.1224 sec
0.1423 0.1237 0.1044 0.0956 0.0897 0.0855 0.0829 0.0813 0.0788 0.0773 0.0760 0.0749 0.0741 0.0736 0.0731 0.0727 

[TRAIN] Epoch[1](8584/114412); Loss: 0.085294; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.1614 0.1409 0.1115 0.0996 0.0908 0.0816 0.0774 0.0744 0.0706 0.0684 0.0670 0.0657 0.0649 0.0641 0.0634 0.0628 

[TRAIN] Epoch[1](8585/114412); Loss: 0.053953; Backpropagation: 0.2908 sec; Batch: 2.1134 sec
0.0966 0.0948 0.0733 0.0663 0.0553 0.0511 0.0476 0.0460 0.0440 0.0433 0.0420 0.0413 0.0407 0.0405 0.0405 0.0400 

[TRAIN] Epoch[1](8586/114412); Loss: 0.089536; Backpropagation: 0.2912 sec; Batch: 2.1258 sec
0.1754 0.1590 0.1222 0.1065 0.0897 0.0825 0.0765 0.0743 0.0720 0.0703 0.0692 0.0682 0.0675 0.0669 0.0664 0.0661 

[TRAIN] Epoch[1](8587/114412); Loss: 0.075845; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1612 0.1288 0.0938 0.0900 0.0776 0.0723 0.0684 0.0647 0.0619 0.0597 0.0582 0.0572 0.0560 0.0553 0.0544 0.0540 

[TRAIN] Epoch[1](8588/114412); Loss: 0.075113; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1516 0.1453 0.1009 0.0835 0.0684 0.0658 0.0640 0.0626 0.0608 0.0589 0.0579 0.0573 0.0567 0.0564 0.0561 0.0557 

[TRAIN] Epoch[1](8589/114412); Loss: 0.063929; Backpropagation: 0.2909 sec; Batch: 2.1197 sec
0.1290 0.1213 0.0833 0.0744 0.0660 0.0587 0.0552 0.0528 0.0512 0.0495 0.0483 0.0475 0.0470 0.0465 0.0462 0.0460 

[TRAIN] Epoch[1](8590/114412); Loss: 0.073806; Backpropagation: 0.2911 sec; Batch: 2.1038 sec
0.1326 0.1223 0.0967 0.0854 0.0783 0.0715 0.0668 0.0644 0.0619 0.0601 0.0586 0.0577 0.0571 0.0564 0.0558 0.0554 

[TRAIN] Epoch[1](8591/114412); Loss: 0.088102; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1409 0.1246 0.1113 0.0997 0.0906 0.0867 0.0821 0.0806 0.0790 0.0767 0.0748 0.0739 0.0730 0.0724 0.0719 0.0714 

[TRAIN] Epoch[1](8592/114412); Loss: 0.057707; Backpropagation: 0.2907 sec; Batch: 2.1166 sec
0.1331 0.1240 0.0868 0.0721 0.0531 0.0466 0.0482 0.0451 0.0422 0.0413 0.0398 0.0394 0.0387 0.0379 0.0376 0.0374 

[TRAIN] Epoch[1](8593/114412); Loss: 0.075396; Backpropagation: 0.2915 sec; Batch: 2.1148 sec
0.1302 0.1128 0.0885 0.0814 0.0786 0.0752 0.0727 0.0673 0.0655 0.0641 0.0631 0.0625 0.0616 0.0612 0.0609 0.0608 

[TRAIN] Epoch[1](8594/114412); Loss: 0.068806; Backpropagation: 0.2927 sec; Batch: 2.1186 sec
0.1505 0.1337 0.1000 0.0821 0.0678 0.0617 0.0562 0.0536 0.0532 0.0510 0.0500 0.0491 0.0484 0.0482 0.0479 0.0474 

[TRAIN] Epoch[1](8595/114412); Loss: 0.089190; Backpropagation: 0.2932 sec; Batch: 2.1178 sec
0.1630 0.1560 0.1121 0.0976 0.0920 0.0831 0.0789 0.0771 0.0741 0.0723 0.0715 0.0707 0.0700 0.0695 0.0695 0.0695 

[TRAIN] Epoch[1](8596/114412); Loss: 0.081229; Backpropagation: 0.2911 sec; Batch: 2.1152 sec
0.1369 0.1205 0.1028 0.0910 0.0843 0.0780 0.0750 0.0725 0.0707 0.0697 0.0682 0.0673 0.0668 0.0659 0.0653 0.0649 

[TRAIN] Epoch[1](8597/114412); Loss: 0.070136; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1348 0.1049 0.0813 0.0779 0.0738 0.0682 0.0642 0.0618 0.0599 0.0588 0.0577 0.0567 0.0563 0.0556 0.0552 0.0550 

[TRAIN] Epoch[1](8598/114412); Loss: 0.091350; Backpropagation: 0.2913 sec; Batch: 2.0836 sec
0.1504 0.1369 0.1117 0.1008 0.0926 0.0883 0.0861 0.0835 0.0806 0.0788 0.0776 0.0763 0.0754 0.0748 0.0741 0.0738 

[TRAIN] Epoch[1](8599/114412); Loss: 0.068314; Backpropagation: 0.2919 sec; Batch: 2.0791 sec
0.1296 0.1238 0.0891 0.0781 0.0691 0.0627 0.0591 0.0579 0.0558 0.0549 0.0537 0.0528 0.0523 0.0518 0.0514 0.0510 

[TRAIN] Epoch[1](8600/114412); Loss: 0.065852; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1370 0.1053 0.0745 0.0709 0.0665 0.0617 0.0608 0.0569 0.0553 0.0539 0.0530 0.0524 0.0518 0.0515 0.0513 0.0511 

[TRAIN] Epoch[1](8601/114412); Loss: 0.105125; Backpropagation: 0.2911 sec; Batch: 2.1203 sec
0.2392 0.1949 0.1484 0.1273 0.1105 0.0973 0.0900 0.0842 0.0799 0.0778 0.0751 0.0735 0.0722 0.0713 0.0704 0.0698 

[TRAIN] Epoch[1](8602/114412); Loss: 0.095300; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1868 0.1752 0.1310 0.1075 0.0968 0.0878 0.0849 0.0803 0.0774 0.0749 0.0730 0.0717 0.0703 0.0697 0.0690 0.0686 

[TRAIN] Epoch[1](8603/114412); Loss: 0.073587; Backpropagation: 0.2907 sec; Batch: 2.1131 sec
0.1809 0.1581 0.1035 0.0838 0.0707 0.0620 0.0590 0.0557 0.0538 0.0525 0.0514 0.0502 0.0496 0.0492 0.0486 0.0484 

[TRAIN] Epoch[1](8604/114412); Loss: 0.066071; Backpropagation: 0.2910 sec; Batch: 2.1137 sec
0.1035 0.0954 0.0835 0.0773 0.0697 0.0643 0.0626 0.0609 0.0585 0.0570 0.0556 0.0549 0.0542 0.0535 0.0533 0.0530 

[TRAIN] Epoch[1](8605/114412); Loss: 0.066068; Backpropagation: 0.2910 sec; Batch: 2.0776 sec
0.1249 0.1170 0.0948 0.0809 0.0711 0.0629 0.0591 0.0552 0.0531 0.0511 0.0497 0.0487 0.0480 0.0473 0.0468 0.0465 

[TRAIN] Epoch[1](8606/114412); Loss: 0.083336; Backpropagation: 0.2913 sec; Batch: 2.1145 sec
0.1451 0.1299 0.1139 0.0990 0.0895 0.0812 0.0756 0.0723 0.0699 0.0678 0.0667 0.0657 0.0650 0.0645 0.0639 0.0633 

[TRAIN] Epoch[1](8607/114412); Loss: 0.085527; Backpropagation: 0.2924 sec; Batch: 2.1200 sec
0.1496 0.1345 0.1123 0.0996 0.0890 0.0825 0.0785 0.0757 0.0730 0.0709 0.0692 0.0686 0.0674 0.0665 0.0660 0.0651 

[TRAIN] Epoch[1](8608/114412); Loss: 0.079548; Backpropagation: 0.2931 sec; Batch: 2.1204 sec
0.1349 0.1136 0.0947 0.0878 0.0823 0.0771 0.0742 0.0724 0.0701 0.0687 0.0676 0.0669 0.0663 0.0658 0.0654 0.0649 

[TRAIN] Epoch[1](8609/114412); Loss: 0.103619; Backpropagation: 0.2912 sec; Batch: 2.1163 sec
0.1820 0.1793 0.1278 0.1116 0.1027 0.0965 0.0932 0.0900 0.0875 0.0863 0.0851 0.0841 0.0838 0.0830 0.0826 0.0824 

[TRAIN] Epoch[1](8610/114412); Loss: 0.073626; Backpropagation: 0.2913 sec; Batch: 2.1299 sec
0.1509 0.1245 0.0991 0.0869 0.0764 0.0702 0.0650 0.0628 0.0597 0.0579 0.0564 0.0549 0.0541 0.0535 0.0530 0.0528 

[TRAIN] Epoch[1](8611/114412); Loss: 0.083372; Backpropagation: 0.2931 sec; Batch: 2.0829 sec
0.1463 0.1320 0.1048 0.0958 0.0867 0.0819 0.0766 0.0733 0.0704 0.0691 0.0680 0.0670 0.0663 0.0656 0.0652 0.0650 

[TRAIN] Epoch[1](8612/114412); Loss: 0.093113; Backpropagation: 0.2912 sec; Batch: 2.1204 sec
0.1617 0.1512 0.1158 0.1028 0.0957 0.0895 0.0853 0.0824 0.0797 0.0780 0.0768 0.0752 0.0747 0.0743 0.0736 0.0732 

[TRAIN] Epoch[1](8613/114412); Loss: 0.080925; Backpropagation: 0.2913 sec; Batch: 2.1163 sec
0.1498 0.1205 0.1017 0.0927 0.0846 0.0804 0.0754 0.0716 0.0694 0.0675 0.0659 0.0649 0.0638 0.0629 0.0622 0.0615 

[TRAIN] Epoch[1](8614/114412); Loss: 0.116339; Backpropagation: 0.2914 sec; Batch: 2.1135 sec
0.2141 0.1826 0.1436 0.1255 0.1174 0.1100 0.1059 0.1029 0.0999 0.0980 0.0964 0.0952 0.0940 0.0928 0.0920 0.0912 

[TRAIN] Epoch[1](8615/114412); Loss: 0.074819; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1302 0.1144 0.0899 0.0821 0.0768 0.0719 0.0691 0.0665 0.0650 0.0637 0.0627 0.0620 0.0615 0.0608 0.0605 0.0601 

[TRAIN] Epoch[1](8616/114412); Loss: 0.085854; Backpropagation: 0.2906 sec; Batch: 2.1163 sec
0.1654 0.1452 0.1125 0.0967 0.0873 0.0803 0.0764 0.0741 0.0716 0.0696 0.0682 0.0668 0.0659 0.0651 0.0645 0.0640 

[TRAIN] Epoch[1](8617/114412); Loss: 0.076649; Backpropagation: 0.2914 sec; Batch: 2.1505 sec
0.1424 0.1343 0.1001 0.0821 0.0763 0.0716 0.0686 0.0657 0.0638 0.0625 0.0614 0.0606 0.0600 0.0594 0.0590 0.0587 

[TRAIN] Epoch[1](8618/114412); Loss: 0.085896; Backpropagation: 0.2912 sec; Batch: 2.0763 sec
0.1869 0.1575 0.1208 0.0975 0.0817 0.0750 0.0704 0.0686 0.0676 0.0669 0.0652 0.0645 0.0635 0.0631 0.0629 0.0622 

[TRAIN] Epoch[1](8619/114412); Loss: 0.082951; Backpropagation: 0.2902 sec; Batch: 2.1199 sec
0.1534 0.1382 0.1108 0.0973 0.0848 0.0784 0.0739 0.0709 0.0689 0.0668 0.0659 0.0651 0.0642 0.0636 0.0629 0.0623 

[TRAIN] Epoch[1](8620/114412); Loss: 0.087293; Backpropagation: 0.2912 sec; Batch: 2.1143 sec
0.1890 0.1633 0.1214 0.1009 0.0855 0.0807 0.0753 0.0717 0.0691 0.0665 0.0649 0.0636 0.0624 0.0613 0.0608 0.0602 

[TRAIN] Epoch[1](8621/114412); Loss: 0.082527; Backpropagation: 0.2953 sec; Batch: 2.1220 sec
0.1619 0.1444 0.1280 0.1102 0.0933 0.0841 0.0775 0.0682 0.0628 0.0610 0.0575 0.0557 0.0553 0.0540 0.0534 0.0530 

[TRAIN] Epoch[1](8622/114412); Loss: 0.085849; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1418 0.1316 0.1049 0.0949 0.0876 0.0829 0.0796 0.0770 0.0752 0.0738 0.0724 0.0715 0.0710 0.0704 0.0697 0.0693 

[TRAIN] Epoch[1](8623/114412); Loss: 0.067553; Backpropagation: 0.2910 sec; Batch: 2.1242 sec
0.1071 0.0946 0.0795 0.0762 0.0707 0.0663 0.0634 0.0627 0.0605 0.0591 0.0581 0.0573 0.0570 0.0565 0.0561 0.0558 

[TRAIN] Epoch[1](8624/114412); Loss: 0.092611; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1743 0.1570 0.1267 0.1133 0.0964 0.0861 0.0808 0.0771 0.0748 0.0730 0.0717 0.0712 0.0704 0.0700 0.0696 0.0692 

[TRAIN] Epoch[1](8625/114412); Loss: 0.071303; Backpropagation: 0.2907 sec; Batch: 2.1175 sec
0.1309 0.1234 0.0923 0.0794 0.0720 0.0672 0.0630 0.0625 0.0599 0.0579 0.0570 0.0563 0.0555 0.0549 0.0546 0.0542 

[TRAIN] Epoch[1](8626/114412); Loss: 0.071370; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1448 0.1314 0.1044 0.0900 0.0743 0.0631 0.0593 0.0575 0.0552 0.0537 0.0528 0.0520 0.0516 0.0512 0.0505 0.0503 

[TRAIN] Epoch[1](8627/114412); Loss: 0.063610; Backpropagation: 0.2910 sec; Batch: 2.1133 sec
0.1156 0.1025 0.0779 0.0709 0.0664 0.0618 0.0583 0.0564 0.0544 0.0524 0.0517 0.0507 0.0502 0.0499 0.0494 0.0491 

[TRAIN] Epoch[1](8628/114412); Loss: 0.084919; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1949 0.1639 0.1193 0.1057 0.0863 0.0772 0.0708 0.0665 0.0631 0.0614 0.0598 0.0590 0.0585 0.0579 0.0573 0.0570 

[TRAIN] Epoch[1](8629/114412); Loss: 0.096586; Backpropagation: 0.2913 sec; Batch: 2.1071 sec
0.1720 0.1519 0.1208 0.1086 0.0984 0.0918 0.0870 0.0853 0.0831 0.0810 0.0798 0.0788 0.0777 0.0772 0.0763 0.0758 

[TRAIN] Epoch[1](8630/114412); Loss: 0.107448; Backpropagation: 0.2916 sec; Batch: 2.1161 sec
0.1919 0.1683 0.1387 0.1189 0.1119 0.1046 0.1002 0.0972 0.0939 0.0901 0.0877 0.0860 0.0842 0.0829 0.0818 0.0809 

[TRAIN] Epoch[1](8631/114412); Loss: 0.061182; Backpropagation: 0.2910 sec; Batch: 2.1127 sec
0.1268 0.1185 0.0878 0.0736 0.0616 0.0549 0.0515 0.0498 0.0475 0.0462 0.0453 0.0441 0.0435 0.0431 0.0426 0.0423 

[TRAIN] Epoch[1](8632/114412); Loss: 0.072142; Backpropagation: 0.2911 sec; Batch: 2.1140 sec
0.1543 0.1363 0.0986 0.0825 0.0703 0.0647 0.0609 0.0587 0.0568 0.0552 0.0542 0.0535 0.0527 0.0522 0.0519 0.0515 

[TRAIN] Epoch[1](8633/114412); Loss: 0.082654; Backpropagation: 0.2909 sec; Batch: 2.1138 sec
0.1450 0.1348 0.1057 0.0960 0.0848 0.0776 0.0746 0.0724 0.0702 0.0690 0.0678 0.0662 0.0655 0.0650 0.0642 0.0636 

[TRAIN] Epoch[1](8634/114412); Loss: 0.058300; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1259 0.1176 0.0677 0.0619 0.0570 0.0525 0.0495 0.0479 0.0460 0.0452 0.0445 0.0438 0.0435 0.0433 0.0433 0.0432 

[TRAIN] Epoch[1](8635/114412); Loss: 0.055801; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1311 0.0946 0.0729 0.0623 0.0569 0.0518 0.0481 0.0455 0.0442 0.0430 0.0418 0.0411 0.0406 0.0401 0.0397 0.0392 

[TRAIN] Epoch[1](8636/114412); Loss: 0.075506; Backpropagation: 0.2932 sec; Batch: 2.1188 sec
0.1526 0.1368 0.1008 0.0866 0.0774 0.0685 0.0652 0.0633 0.0608 0.0594 0.0580 0.0569 0.0562 0.0558 0.0551 0.0548 

[TRAIN] Epoch[1](8637/114412); Loss: 0.064786; Backpropagation: 0.2908 sec; Batch: 2.1151 sec
0.1292 0.1251 0.0858 0.0703 0.0633 0.0607 0.0574 0.0539 0.0519 0.0506 0.0496 0.0488 0.0482 0.0476 0.0472 0.0469 

[TRAIN] Epoch[1](8638/114412); Loss: 0.124693; Backpropagation: 0.2904 sec; Batch: 2.1165 sec
0.2098 0.1983 0.1609 0.1445 0.1330 0.1221 0.1171 0.1117 0.1077 0.1054 0.1022 0.1000 0.0979 0.0961 0.0947 0.0936 

[TRAIN] Epoch[1](8639/114412); Loss: 0.075470; Backpropagation: 0.2913 sec; Batch: 2.1143 sec
0.1332 0.1146 0.0926 0.0834 0.0786 0.0739 0.0702 0.0680 0.0656 0.0640 0.0628 0.0616 0.0606 0.0600 0.0594 0.0591 

[TRAIN] Epoch[1](8640/114412); Loss: 0.071598; Backpropagation: 0.2932 sec; Batch: 2.0790 sec
0.1106 0.0980 0.0862 0.0816 0.0760 0.0717 0.0685 0.0665 0.0643 0.0627 0.0615 0.0607 0.0600 0.0596 0.0590 0.0587 

[TRAIN] Epoch[1](8641/114412); Loss: 0.071295; Backpropagation: 0.2905 sec; Batch: 2.1157 sec
0.1558 0.1298 0.0885 0.0779 0.0659 0.0656 0.0617 0.0601 0.0579 0.0563 0.0550 0.0541 0.0535 0.0533 0.0528 0.0525 

[TRAIN] Epoch[1](8642/114412); Loss: 0.094385; Backpropagation: 0.2908 sec; Batch: 2.1134 sec
0.1616 0.1416 0.1133 0.1031 0.0956 0.0899 0.0867 0.0847 0.0827 0.0816 0.0804 0.0793 0.0783 0.0777 0.0770 0.0766 

[TRAIN] Epoch[1](8643/114412); Loss: 0.062964; Backpropagation: 0.2911 sec; Batch: 2.0760 sec
0.1261 0.1093 0.0767 0.0640 0.0629 0.0599 0.0561 0.0543 0.0525 0.0513 0.0503 0.0495 0.0491 0.0488 0.0484 0.0482 

[TRAIN] Epoch[1](8644/114412); Loss: 0.081644; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1393 0.1248 0.1015 0.0922 0.0859 0.0802 0.0758 0.0732 0.0709 0.0688 0.0675 0.0666 0.0658 0.0651 0.0645 0.0641 

[TRAIN] Epoch[1](8645/114412); Loss: 0.062754; Backpropagation: 0.2908 sec; Batch: 2.1198 sec
0.1271 0.1192 0.0771 0.0648 0.0597 0.0558 0.0546 0.0527 0.0512 0.0502 0.0496 0.0490 0.0486 0.0484 0.0480 0.0480 

[TRAIN] Epoch[1](8646/114412); Loss: 0.076091; Backpropagation: 0.2908 sec; Batch: 2.0785 sec
0.1159 0.1006 0.0908 0.0811 0.0775 0.0733 0.0715 0.0706 0.0692 0.0680 0.0673 0.0670 0.0666 0.0662 0.0660 0.0658 

[TRAIN] Epoch[1](8647/114412); Loss: 0.070150; Backpropagation: 0.2912 sec; Batch: 2.0782 sec
0.1592 0.1388 0.0950 0.0788 0.0654 0.0630 0.0593 0.0573 0.0539 0.0522 0.0516 0.0505 0.0502 0.0494 0.0489 0.0487 

[TRAIN] Epoch[1](8648/114412); Loss: 0.083924; Backpropagation: 0.2952 sec; Batch: 2.0993 sec
0.1453 0.1255 0.1039 0.0938 0.0877 0.0813 0.0787 0.0748 0.0724 0.0708 0.0699 0.0689 0.0682 0.0676 0.0672 0.0668 

[TRAIN] Epoch[1](8649/114412); Loss: 0.101000; Backpropagation: 0.2931 sec; Batch: 2.1176 sec
0.2025 0.1760 0.1385 0.1169 0.1037 0.0957 0.0880 0.0842 0.0819 0.0793 0.0774 0.0759 0.0750 0.0744 0.0736 0.0730 

[TRAIN] Epoch[1](8650/114412); Loss: 0.088039; Backpropagation: 0.2912 sec; Batch: 2.1193 sec
0.1489 0.1400 0.1170 0.1005 0.0913 0.0849 0.0796 0.0778 0.0752 0.0733 0.0721 0.0712 0.0703 0.0694 0.0688 0.0682 

[TRAIN] Epoch[1](8651/114412); Loss: 0.069122; Backpropagation: 0.2911 sec; Batch: 2.1071 sec
0.1184 0.1122 0.0924 0.0814 0.0719 0.0669 0.0632 0.0607 0.0588 0.0570 0.0557 0.0549 0.0538 0.0532 0.0530 0.0524 

[TRAIN] Epoch[1](8652/114412); Loss: 0.062970; Backpropagation: 0.2914 sec; Batch: 2.1166 sec
0.1279 0.1240 0.0893 0.0734 0.0625 0.0572 0.0533 0.0508 0.0489 0.0475 0.0465 0.0458 0.0454 0.0452 0.0449 0.0448 

[TRAIN] Epoch[1](8653/114412); Loss: 0.086589; Backpropagation: 0.2912 sec; Batch: 2.1256 sec
0.1538 0.1372 0.1062 0.0974 0.0902 0.0828 0.0800 0.0761 0.0736 0.0726 0.0711 0.0699 0.0694 0.0689 0.0684 0.0679 

[TRAIN] Epoch[1](8654/114412); Loss: 0.072093; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1407 0.1213 0.0921 0.0810 0.0735 0.0683 0.0641 0.0617 0.0597 0.0582 0.0570 0.0563 0.0556 0.0551 0.0546 0.0543 

[TRAIN] Epoch[1](8655/114412); Loss: 0.074953; Backpropagation: 0.2911 sec; Batch: 2.1103 sec
0.1580 0.1483 0.1026 0.0908 0.0743 0.0691 0.0641 0.0609 0.0586 0.0560 0.0546 0.0538 0.0529 0.0521 0.0518 0.0512 

[TRAIN] Epoch[1](8656/114412); Loss: 0.082744; Backpropagation: 0.2916 sec; Batch: 2.0784 sec
0.1290 0.1200 0.1009 0.0931 0.0855 0.0807 0.0775 0.0754 0.0735 0.0720 0.0711 0.0701 0.0694 0.0691 0.0686 0.0681 

[TRAIN] Epoch[1](8657/114412); Loss: 0.076703; Backpropagation: 0.2903 sec; Batch: 2.1158 sec
0.1360 0.1169 0.0957 0.0863 0.0781 0.0726 0.0701 0.0681 0.0661 0.0647 0.0637 0.0628 0.0621 0.0616 0.0613 0.0611 

[TRAIN] Epoch[1](8658/114412); Loss: 0.089158; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.1718 0.1588 0.1239 0.1096 0.0960 0.0859 0.0781 0.0740 0.0707 0.0690 0.0672 0.0658 0.0649 0.0641 0.0634 0.0631 

[TRAIN] Epoch[1](8659/114412); Loss: 0.093261; Backpropagation: 0.2917 sec; Batch: 2.1172 sec
0.1794 0.1581 0.1235 0.1114 0.0986 0.0896 0.0834 0.0805 0.0777 0.0742 0.0726 0.0707 0.0694 0.0686 0.0677 0.0668 

[TRAIN] Epoch[1](8660/114412); Loss: 0.083672; Backpropagation: 0.2931 sec; Batch: 2.1213 sec
0.1359 0.1165 0.1033 0.0964 0.0888 0.0831 0.0802 0.0771 0.0740 0.0722 0.0712 0.0696 0.0685 0.0679 0.0673 0.0668 

[TRAIN] Epoch[1](8661/114412); Loss: 0.060435; Backpropagation: 0.2925 sec; Batch: 2.1227 sec
0.1124 0.1070 0.0810 0.0684 0.0608 0.0566 0.0538 0.0505 0.0497 0.0485 0.0476 0.0471 0.0466 0.0461 0.0456 0.0452 

[TRAIN] Epoch[1](8662/114412); Loss: 0.086899; Backpropagation: 0.2954 sec; Batch: 2.1210 sec
0.1779 0.1581 0.1255 0.1018 0.0895 0.0790 0.0747 0.0721 0.0695 0.0669 0.0654 0.0637 0.0625 0.0619 0.0613 0.0606 

[TRAIN] Epoch[1](8663/114412); Loss: 0.089077; Backpropagation: 0.2928 sec; Batch: 2.1214 sec
0.1659 0.1501 0.1203 0.1056 0.0931 0.0847 0.0803 0.0761 0.0740 0.0716 0.0697 0.0687 0.0676 0.0665 0.0659 0.0652 

[TRAIN] Epoch[1](8664/114412); Loss: 0.077524; Backpropagation: 0.2920 sec; Batch: 2.0798 sec
0.1258 0.1121 0.0972 0.0888 0.0799 0.0746 0.0712 0.0696 0.0680 0.0667 0.0657 0.0651 0.0645 0.0641 0.0637 0.0635 

[TRAIN] Epoch[1](8665/114412); Loss: 0.096592; Backpropagation: 0.2913 sec; Batch: 2.1292 sec
0.1642 0.1501 0.1245 0.1103 0.0989 0.0931 0.0894 0.0871 0.0832 0.0813 0.0796 0.0783 0.0773 0.0766 0.0759 0.0755 

[TRAIN] Epoch[1](8666/114412); Loss: 0.109437; Backpropagation: 0.2957 sec; Batch: 2.0835 sec
0.1851 0.1624 0.1350 0.1228 0.1122 0.1068 0.1019 0.0977 0.0950 0.0933 0.0919 0.0908 0.0899 0.0892 0.0887 0.0883 

[TRAIN] Epoch[1](8667/114412); Loss: 0.078678; Backpropagation: 0.2930 sec; Batch: 2.1778 sec
0.1367 0.1212 0.1000 0.0908 0.0834 0.0774 0.0734 0.0711 0.0681 0.0661 0.0644 0.0630 0.0621 0.0611 0.0603 0.0597 

[TRAIN] Epoch[1](8668/114412); Loss: 0.074553; Backpropagation: 0.2913 sec; Batch: 2.0796 sec
0.1403 0.1339 0.1003 0.0783 0.0748 0.0674 0.0637 0.0628 0.0614 0.0602 0.0595 0.0588 0.0584 0.0580 0.0576 0.0574 

[TRAIN] Epoch[1](8669/114412); Loss: 0.083595; Backpropagation: 0.2905 sec; Batch: 2.1166 sec
0.1533 0.1334 0.1076 0.0952 0.0853 0.0801 0.0770 0.0739 0.0712 0.0688 0.0676 0.0665 0.0654 0.0646 0.0641 0.0637 

[TRAIN] Epoch[1](8670/114412); Loss: 0.070081; Backpropagation: 0.2908 sec; Batch: 2.1149 sec
0.1161 0.1068 0.0946 0.0856 0.0759 0.0683 0.0647 0.0636 0.0605 0.0584 0.0570 0.0556 0.0544 0.0539 0.0533 0.0526 

[TRAIN] Epoch[1](8671/114412); Loss: 0.073188; Backpropagation: 0.2914 sec; Batch: 2.1171 sec
0.1168 0.1054 0.0925 0.0848 0.0784 0.0721 0.0675 0.0657 0.0641 0.0625 0.0617 0.0607 0.0601 0.0599 0.0596 0.0592 

[TRAIN] Epoch[1](8672/114412); Loss: 0.095659; Backpropagation: 0.2917 sec; Batch: 2.1191 sec
0.2038 0.1813 0.1358 0.1163 0.0933 0.0913 0.0813 0.0787 0.0753 0.0718 0.0704 0.0684 0.0672 0.0664 0.0649 0.0642 

[TRAIN] Epoch[1](8673/114412); Loss: 0.102082; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1964 0.1703 0.1262 0.1115 0.1035 0.0973 0.0936 0.0900 0.0863 0.0840 0.0822 0.0801 0.0790 0.0783 0.0777 0.0771 

[TRAIN] Epoch[1](8674/114412); Loss: 0.090384; Backpropagation: 0.2915 sec; Batch: 2.1217 sec
0.1862 0.1645 0.1263 0.1031 0.0893 0.0817 0.0768 0.0741 0.0717 0.0703 0.0690 0.0680 0.0673 0.0665 0.0658 0.0655 

[TRAIN] Epoch[1](8675/114412); Loss: 0.095324; Backpropagation: 0.2914 sec; Batch: 2.1184 sec
0.1458 0.1312 0.1149 0.1059 0.0995 0.0947 0.0912 0.0885 0.0861 0.0843 0.0831 0.0817 0.0807 0.0799 0.0792 0.0785 

[TRAIN] Epoch[1](8676/114412); Loss: 0.094551; Backpropagation: 0.2921 sec; Batch: 2.0860 sec
0.2128 0.1813 0.1401 0.1119 0.0940 0.0874 0.0795 0.0763 0.0722 0.0695 0.0675 0.0662 0.0648 0.0638 0.0632 0.0623 

[TRAIN] Epoch[1](8677/114412); Loss: 0.078745; Backpropagation: 0.2905 sec; Batch: 2.1020 sec
0.1449 0.1379 0.0984 0.0876 0.0801 0.0734 0.0705 0.0681 0.0662 0.0647 0.0633 0.0623 0.0615 0.0608 0.0603 0.0599 

[TRAIN] Epoch[1](8678/114412); Loss: 0.099374; Backpropagation: 0.2930 sec; Batch: 2.1211 sec
0.1817 0.1592 0.1306 0.1160 0.1011 0.0948 0.0904 0.0879 0.0850 0.0822 0.0807 0.0789 0.0772 0.0758 0.0747 0.0737 

[TRAIN] Epoch[1](8679/114412); Loss: 0.073511; Backpropagation: 0.2930 sec; Batch: 2.1020 sec
0.1422 0.1247 0.0968 0.0863 0.0768 0.0702 0.0668 0.0635 0.0607 0.0591 0.0574 0.0557 0.0550 0.0543 0.0536 0.0532 

[TRAIN] Epoch[1](8680/114412); Loss: 0.104230; Backpropagation: 0.2932 sec; Batch: 2.1173 sec
0.1615 0.1462 0.1235 0.1148 0.1064 0.1011 0.0975 0.0953 0.0932 0.0919 0.0910 0.0902 0.0895 0.0888 0.0886 0.0883 

[TRAIN] Epoch[1](8681/114412); Loss: 0.083988; Backpropagation: 0.2932 sec; Batch: 2.1319 sec
0.1932 0.1756 0.1317 0.1145 0.0893 0.0717 0.0682 0.0633 0.0595 0.0579 0.0567 0.0545 0.0534 0.0525 0.0512 0.0505 

[TRAIN] Epoch[1](8682/114412); Loss: 0.099259; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1738 0.1521 0.1256 0.1134 0.1026 0.0960 0.0914 0.0869 0.0856 0.0845 0.0819 0.0811 0.0798 0.0789 0.0777 0.0768 

[TRAIN] Epoch[1](8683/114412); Loss: 0.085591; Backpropagation: 0.2909 sec; Batch: 2.0958 sec
0.1997 0.1616 0.1154 0.1016 0.0840 0.0775 0.0717 0.0684 0.0659 0.0637 0.0625 0.0611 0.0600 0.0593 0.0588 0.0583 

[TRAIN] Epoch[1](8684/114412); Loss: 0.059831; Backpropagation: 0.2911 sec; Batch: 2.0834 sec
0.1203 0.0998 0.0782 0.0709 0.0618 0.0577 0.0529 0.0503 0.0483 0.0473 0.0461 0.0454 0.0450 0.0446 0.0444 0.0442 

[TRAIN] Epoch[1](8685/114412); Loss: 0.074411; Backpropagation: 0.2920 sec; Batch: 2.0809 sec
0.1154 0.1091 0.0957 0.0875 0.0791 0.0724 0.0695 0.0670 0.0652 0.0640 0.0629 0.0618 0.0611 0.0604 0.0600 0.0596 

[TRAIN] Epoch[1](8686/114412); Loss: 0.102153; Backpropagation: 0.2916 sec; Batch: 2.1197 sec
0.1529 0.1389 0.1202 0.1105 0.1038 0.0995 0.0962 0.0944 0.0929 0.0915 0.0905 0.0898 0.0889 0.0885 0.0882 0.0878 

[TRAIN] Epoch[1](8687/114412); Loss: 0.088091; Backpropagation: 0.2935 sec; Batch: 2.0926 sec
0.1407 0.1211 0.1047 0.0949 0.0886 0.0853 0.0832 0.0806 0.0788 0.0775 0.0766 0.0761 0.0758 0.0754 0.0751 0.0750 

[TRAIN] Epoch[1](8688/114412); Loss: 0.080641; Backpropagation: 0.2917 sec; Batch: 2.1278 sec
0.1497 0.1351 0.1072 0.0938 0.0818 0.0768 0.0717 0.0686 0.0666 0.0654 0.0641 0.0629 0.0624 0.0620 0.0612 0.0610 

[TRAIN] Epoch[1](8689/114412); Loss: 0.096140; Backpropagation: 0.2919 sec; Batch: 2.1159 sec
0.2399 0.2098 0.1686 0.1459 0.1111 0.0827 0.0688 0.0645 0.0617 0.0592 0.0572 0.0556 0.0547 0.0536 0.0528 0.0521 

[TRAIN] Epoch[1](8690/114412); Loss: 0.074939; Backpropagation: 0.2908 sec; Batch: 2.0786 sec
0.1587 0.1431 0.0973 0.0770 0.0719 0.0677 0.0648 0.0614 0.0608 0.0588 0.0577 0.0571 0.0563 0.0560 0.0555 0.0550 

[TRAIN] Epoch[1](8691/114412); Loss: 0.092139; Backpropagation: 0.2907 sec; Batch: 2.1157 sec
0.1565 0.1412 0.1142 0.1020 0.0920 0.0887 0.0851 0.0827 0.0805 0.0787 0.0777 0.0766 0.0756 0.0749 0.0741 0.0737 

[TRAIN] Epoch[1](8692/114412); Loss: 0.079239; Backpropagation: 0.2913 sec; Batch: 2.1150 sec
0.1279 0.1157 0.0999 0.0907 0.0831 0.0797 0.0753 0.0722 0.0698 0.0678 0.0664 0.0652 0.0644 0.0637 0.0632 0.0627 

[TRAIN] Epoch[1](8693/114412); Loss: 0.109542; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.2118 0.1902 0.1508 0.1285 0.1090 0.1006 0.0946 0.0923 0.0901 0.0870 0.0856 0.0845 0.0832 0.0823 0.0814 0.0806 

[TRAIN] Epoch[1](8694/114412); Loss: 0.069901; Backpropagation: 0.2928 sec; Batch: 2.1179 sec
0.1177 0.0982 0.0801 0.0776 0.0723 0.0687 0.0655 0.0637 0.0620 0.0608 0.0601 0.0592 0.0586 0.0583 0.0579 0.0577 

[TRAIN] Epoch[1](8695/114412); Loss: 0.064416; Backpropagation: 0.2932 sec; Batch: 2.1180 sec
0.1384 0.1177 0.0867 0.0690 0.0668 0.0592 0.0562 0.0535 0.0509 0.0494 0.0483 0.0475 0.0471 0.0469 0.0467 0.0466 

[TRAIN] Epoch[1](8696/114412); Loss: 0.078034; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1271 0.1178 0.0976 0.0879 0.0797 0.0737 0.0717 0.0706 0.0680 0.0671 0.0661 0.0653 0.0647 0.0641 0.0638 0.0635 

[TRAIN] Epoch[1](8697/114412); Loss: 0.072315; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.1480 0.1286 0.1001 0.0870 0.0760 0.0667 0.0615 0.0591 0.0568 0.0555 0.0547 0.0538 0.0532 0.0525 0.0519 0.0516 

[TRAIN] Epoch[1](8698/114412); Loss: 0.109704; Backpropagation: 0.2916 sec; Batch: 2.1184 sec
0.1945 0.1715 0.1407 0.1293 0.1170 0.1073 0.1010 0.0958 0.0928 0.0906 0.0887 0.0874 0.0862 0.0850 0.0842 0.0834 

[TRAIN] Epoch[1](8699/114412); Loss: 0.085355; Backpropagation: 0.2953 sec; Batch: 2.1207 sec
0.1353 0.1234 0.1104 0.0994 0.0899 0.0840 0.0799 0.0778 0.0750 0.0731 0.0718 0.0705 0.0696 0.0690 0.0685 0.0680 

[TRAIN] Epoch[1](8700/114412); Loss: 0.090998; Backpropagation: 0.2931 sec; Batch: 2.1154 sec
0.1551 0.1429 0.1125 0.1020 0.0945 0.0875 0.0828 0.0808 0.0787 0.0768 0.0758 0.0748 0.0739 0.0733 0.0726 0.0720 

[TRAIN] Epoch[1](8701/114412); Loss: 0.089379; Backpropagation: 0.2912 sec; Batch: 2.1159 sec
0.1533 0.1322 0.1178 0.1060 0.0960 0.0894 0.0826 0.0792 0.0757 0.0735 0.0726 0.0720 0.0711 0.0702 0.0695 0.0688 

[TRAIN] Epoch[1](8702/114412); Loss: 0.075395; Backpropagation: 0.2905 sec; Batch: 2.1242 sec
0.1385 0.1303 0.0936 0.0834 0.0754 0.0707 0.0672 0.0651 0.0631 0.0620 0.0609 0.0600 0.0597 0.0591 0.0587 0.0586 

[TRAIN] Epoch[1](8703/114412); Loss: 0.080029; Backpropagation: 0.2915 sec; Batch: 2.0868 sec
0.1342 0.1046 0.0949 0.0875 0.0856 0.0797 0.0754 0.0730 0.0713 0.0701 0.0691 0.0681 0.0676 0.0669 0.0664 0.0661 

[TRAIN] Epoch[1](8704/114412); Loss: 0.066019; Backpropagation: 0.2933 sec; Batch: 2.1220 sec
0.1218 0.1141 0.0838 0.0753 0.0673 0.0621 0.0587 0.0571 0.0546 0.0534 0.0526 0.0519 0.0515 0.0510 0.0506 0.0504 

[TRAIN] Epoch[1](8705/114412); Loss: 0.083267; Backpropagation: 0.2937 sec; Batch: 2.1208 sec
0.1751 0.1585 0.1202 0.1018 0.0830 0.0748 0.0706 0.0671 0.0646 0.0627 0.0611 0.0600 0.0592 0.0583 0.0578 0.0574 

[TRAIN] Epoch[1](8706/114412); Loss: 0.059230; Backpropagation: 0.2911 sec; Batch: 2.1031 sec
0.0933 0.0912 0.0757 0.0665 0.0617 0.0567 0.0551 0.0532 0.0517 0.0509 0.0498 0.0491 0.0488 0.0483 0.0479 0.0477 

[TRAIN] Epoch[1](8707/114412); Loss: 0.073786; Backpropagation: 0.2951 sec; Batch: 2.1223 sec
0.1612 0.1363 0.1012 0.0823 0.0722 0.0667 0.0623 0.0599 0.0582 0.0562 0.0552 0.0544 0.0540 0.0537 0.0535 0.0533 

[TRAIN] Epoch[1](8708/114412); Loss: 0.074864; Backpropagation: 0.2917 sec; Batch: 2.1142 sec
0.1572 0.1459 0.1135 0.0911 0.0696 0.0648 0.0617 0.0597 0.0572 0.0561 0.0553 0.0544 0.0536 0.0530 0.0525 0.0523 

[TRAIN] Epoch[1](8709/114412); Loss: 0.087973; Backpropagation: 0.2915 sec; Batch: 2.1169 sec
0.1539 0.1401 0.1137 0.1020 0.0904 0.0829 0.0796 0.0763 0.0749 0.0735 0.0717 0.0709 0.0702 0.0697 0.0690 0.0688 

[TRAIN] Epoch[1](8710/114412); Loss: 0.074278; Backpropagation: 0.2913 sec; Batch: 2.1213 sec
0.1225 0.1094 0.0904 0.0819 0.0778 0.0740 0.0694 0.0675 0.0658 0.0639 0.0628 0.0618 0.0610 0.0606 0.0601 0.0597 

[TRAIN] Epoch[1](8711/114412); Loss: 0.094207; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1754 0.1575 0.1198 0.1047 0.0928 0.0884 0.0840 0.0806 0.0787 0.0775 0.0764 0.0754 0.0747 0.0742 0.0737 0.0734 

[TRAIN] Epoch[1](8712/114412); Loss: 0.079493; Backpropagation: 0.2914 sec; Batch: 2.0804 sec
0.1523 0.1331 0.0977 0.0901 0.0805 0.0778 0.0719 0.0692 0.0668 0.0645 0.0633 0.0622 0.0616 0.0608 0.0602 0.0599 

[TRAIN] Epoch[1](8713/114412); Loss: 0.065622; Backpropagation: 0.2914 sec; Batch: 2.0841 sec
0.1268 0.1196 0.0920 0.0772 0.0679 0.0613 0.0580 0.0547 0.0528 0.0511 0.0497 0.0489 0.0484 0.0477 0.0471 0.0466 

[TRAIN] Epoch[1](8714/114412); Loss: 0.063213; Backpropagation: 0.2954 sec; Batch: 2.0884 sec
0.1080 0.0968 0.0850 0.0744 0.0681 0.0604 0.0570 0.0551 0.0529 0.0522 0.0515 0.0508 0.0503 0.0497 0.0496 0.0496 

[TRAIN] Epoch[1](8715/114412); Loss: 0.086709; Backpropagation: 0.2915 sec; Batch: 2.1162 sec
0.1915 0.1542 0.1131 0.0954 0.0853 0.0797 0.0760 0.0723 0.0694 0.0676 0.0658 0.0646 0.0638 0.0633 0.0629 0.0625 

[TRAIN] Epoch[1](8716/114412); Loss: 0.074577; Backpropagation: 0.2934 sec; Batch: 2.0842 sec
0.1521 0.1386 0.1156 0.0987 0.0812 0.0668 0.0597 0.0570 0.0550 0.0542 0.0533 0.0529 0.0526 0.0522 0.0518 0.0516 

[TRAIN] Epoch[1](8717/114412); Loss: 0.078683; Backpropagation: 0.2911 sec; Batch: 2.0831 sec
0.1644 0.1414 0.1046 0.0827 0.0761 0.0723 0.0684 0.0673 0.0637 0.0621 0.0612 0.0603 0.0594 0.0589 0.0582 0.0579 

[TRAIN] Epoch[1](8718/114412); Loss: 0.061472; Backpropagation: 0.2906 sec; Batch: 2.0820 sec
0.1150 0.1013 0.0789 0.0693 0.0624 0.0577 0.0550 0.0536 0.0517 0.0502 0.0494 0.0487 0.0482 0.0477 0.0473 0.0469 

[TRAIN] Epoch[1](8719/114412); Loss: 0.073879; Backpropagation: 0.2930 sec; Batch: 2.0819 sec
0.1514 0.1255 0.0976 0.0825 0.0742 0.0685 0.0649 0.0624 0.0600 0.0583 0.0575 0.0567 0.0559 0.0557 0.0556 0.0553 

[TRAIN] Epoch[1](8720/114412); Loss: 0.096022; Backpropagation: 0.2910 sec; Batch: 2.1151 sec
0.1730 0.1498 0.1288 0.1164 0.1048 0.0946 0.0875 0.0822 0.0787 0.0769 0.0756 0.0746 0.0741 0.0736 0.0732 0.0727 

[TRAIN] Epoch[1](8721/114412); Loss: 0.079396; Backpropagation: 0.2917 sec; Batch: 2.0777 sec
0.2000 0.1588 0.1141 0.0904 0.0769 0.0700 0.0649 0.0623 0.0591 0.0567 0.0551 0.0540 0.0532 0.0522 0.0517 0.0511 

[TRAIN] Epoch[1](8722/114412); Loss: 0.081337; Backpropagation: 0.2908 sec; Batch: 2.1218 sec
0.1595 0.1459 0.1079 0.0877 0.0830 0.0806 0.0741 0.0721 0.0704 0.0644 0.0637 0.0625 0.0585 0.0584 0.0576 0.0550 

[TRAIN] Epoch[1](8723/114412); Loss: 0.090908; Backpropagation: 0.2911 sec; Batch: 2.1227 sec
0.1530 0.1409 0.1152 0.1031 0.0920 0.0863 0.0821 0.0802 0.0782 0.0767 0.0757 0.0750 0.0745 0.0740 0.0739 0.0736 

[TRAIN] Epoch[1](8724/114412); Loss: 0.077420; Backpropagation: 0.2915 sec; Batch: 2.1215 sec
0.1511 0.1227 0.0944 0.0888 0.0763 0.0741 0.0694 0.0668 0.0652 0.0632 0.0626 0.0617 0.0612 0.0609 0.0604 0.0600 

[TRAIN] Epoch[1](8725/114412); Loss: 0.083801; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1442 0.1315 0.0999 0.0901 0.0841 0.0805 0.0762 0.0748 0.0730 0.0715 0.0707 0.0698 0.0693 0.0689 0.0684 0.0680 

[TRAIN] Epoch[1](8726/114412); Loss: 0.075486; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1352 0.1272 0.0945 0.0812 0.0741 0.0706 0.0673 0.0654 0.0642 0.0630 0.0619 0.0613 0.0610 0.0606 0.0602 0.0601 

[TRAIN] Epoch[1](8727/114412); Loss: 0.082798; Backpropagation: 0.2918 sec; Batch: 2.1153 sec
0.1442 0.1233 0.0989 0.0900 0.0831 0.0809 0.0772 0.0754 0.0731 0.0713 0.0704 0.0695 0.0682 0.0672 0.0665 0.0657 

[TRAIN] Epoch[1](8728/114412); Loss: 0.089552; Backpropagation: 0.2917 sec; Batch: 2.0795 sec
0.1684 0.1412 0.1125 0.1054 0.0925 0.0856 0.0804 0.0774 0.0749 0.0735 0.0720 0.0710 0.0703 0.0696 0.0691 0.0689 

[TRAIN] Epoch[1](8729/114412); Loss: 0.076127; Backpropagation: 0.2908 sec; Batch: 2.1132 sec
0.1706 0.1618 0.1167 0.0933 0.0705 0.0618 0.0600 0.0579 0.0559 0.0549 0.0538 0.0530 0.0526 0.0522 0.0516 0.0514 

[TRAIN] Epoch[1](8730/114412); Loss: 0.079752; Backpropagation: 0.2910 sec; Batch: 2.1099 sec
0.1699 0.1460 0.1131 0.0951 0.0825 0.0749 0.0688 0.0664 0.0631 0.0602 0.0586 0.0572 0.0562 0.0554 0.0546 0.0541 

[TRAIN] Epoch[1](8731/114412); Loss: 0.074651; Backpropagation: 0.2930 sec; Batch: 2.0798 sec
0.1574 0.1411 0.1019 0.0869 0.0763 0.0671 0.0626 0.0606 0.0591 0.0574 0.0558 0.0548 0.0541 0.0534 0.0532 0.0528 

[TRAIN] Epoch[1](8732/114412); Loss: 0.065529; Backpropagation: 0.2921 sec; Batch: 2.0797 sec
0.1151 0.1040 0.0832 0.0777 0.0688 0.0655 0.0599 0.0573 0.0553 0.0536 0.0529 0.0520 0.0513 0.0510 0.0506 0.0504 

[TRAIN] Epoch[1](8733/114412); Loss: 0.073504; Backpropagation: 0.2914 sec; Batch: 2.0961 sec
0.1168 0.1030 0.0906 0.0830 0.0767 0.0723 0.0696 0.0664 0.0645 0.0634 0.0628 0.0621 0.0616 0.0613 0.0611 0.0609 

[TRAIN] Epoch[1](8734/114412); Loss: 0.089375; Backpropagation: 0.2910 sec; Batch: 2.1140 sec
0.1670 0.1535 0.1171 0.0999 0.0885 0.0833 0.0799 0.0765 0.0747 0.0736 0.0722 0.0702 0.0696 0.0689 0.0680 0.0672 

[TRAIN] Epoch[1](8735/114412); Loss: 0.084946; Backpropagation: 0.2911 sec; Batch: 2.1048 sec
0.1784 0.1628 0.1187 0.0994 0.0837 0.0761 0.0709 0.0688 0.0667 0.0645 0.0631 0.0624 0.0616 0.0609 0.0608 0.0601 

[TRAIN] Epoch[1](8736/114412); Loss: 0.071466; Backpropagation: 0.2915 sec; Batch: 2.1125 sec
0.1389 0.1228 0.0906 0.0780 0.0697 0.0663 0.0634 0.0620 0.0594 0.0580 0.0569 0.0561 0.0559 0.0556 0.0550 0.0549 

[TRAIN] Epoch[1](8737/114412); Loss: 0.100214; Backpropagation: 0.2917 sec; Batch: 2.1267 sec
0.1639 0.1363 0.1145 0.1058 0.1042 0.1007 0.0976 0.0949 0.0918 0.0895 0.0874 0.0857 0.0843 0.0831 0.0822 0.0814 

[TRAIN] Epoch[1](8738/114412); Loss: 0.070754; Backpropagation: 0.2913 sec; Batch: 2.0788 sec
0.1612 0.1304 0.0972 0.0811 0.0684 0.0627 0.0595 0.0571 0.0548 0.0536 0.0526 0.0516 0.0512 0.0505 0.0501 0.0499 

[TRAIN] Epoch[1](8739/114412); Loss: 0.059730; Backpropagation: 0.2921 sec; Batch: 2.1166 sec
0.1222 0.0938 0.0738 0.0675 0.0638 0.0609 0.0566 0.0519 0.0496 0.0475 0.0466 0.0455 0.0446 0.0443 0.0438 0.0435 

[TRAIN] Epoch[1](8740/114412); Loss: 0.072255; Backpropagation: 0.2907 sec; Batch: 2.0774 sec
0.1535 0.1325 0.0966 0.0872 0.0741 0.0666 0.0634 0.0597 0.0563 0.0549 0.0537 0.0528 0.0519 0.0514 0.0510 0.0503 

[TRAIN] Epoch[1](8741/114412); Loss: 0.067448; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1754 0.1489 0.0998 0.0729 0.0645 0.0586 0.0525 0.0504 0.0484 0.0462 0.0451 0.0446 0.0439 0.0432 0.0427 0.0423 

[TRAIN] Epoch[1](8742/114412); Loss: 0.073112; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.1330 0.1121 0.0943 0.0822 0.0767 0.0705 0.0665 0.0643 0.0622 0.0609 0.0594 0.0586 0.0580 0.0576 0.0569 0.0566 

[TRAIN] Epoch[1](8743/114412); Loss: 0.067664; Backpropagation: 0.2905 sec; Batch: 2.1169 sec
0.1459 0.1263 0.0945 0.0808 0.0689 0.0630 0.0575 0.0548 0.0529 0.0511 0.0498 0.0486 0.0478 0.0473 0.0469 0.0464 

[TRAIN] Epoch[1](8744/114412); Loss: 0.069179; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1152 0.1034 0.0867 0.0785 0.0733 0.0681 0.0654 0.0622 0.0601 0.0585 0.0573 0.0565 0.0560 0.0554 0.0552 0.0550 

[TRAIN] Epoch[1](8745/114412); Loss: 0.114795; Backpropagation: 0.2915 sec; Batch: 2.0798 sec
0.1946 0.1758 0.1463 0.1350 0.1241 0.1106 0.1103 0.1031 0.1006 0.0993 0.0941 0.0931 0.0903 0.0878 0.0870 0.0846 

[TRAIN] Epoch[1](8746/114412); Loss: 0.076421; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1423 0.1279 0.0941 0.0850 0.0758 0.0705 0.0674 0.0662 0.0647 0.0633 0.0622 0.0615 0.0610 0.0606 0.0603 0.0599 

[TRAIN] Epoch[1](8747/114412); Loss: 0.071125; Backpropagation: 0.2914 sec; Batch: 2.1057 sec
0.1196 0.1010 0.0895 0.0824 0.0747 0.0717 0.0671 0.0638 0.0622 0.0604 0.0592 0.0583 0.0577 0.0572 0.0569 0.0564 

[TRAIN] Epoch[1](8748/114412); Loss: 0.068938; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1030 0.0926 0.0847 0.0803 0.0756 0.0695 0.0656 0.0632 0.0616 0.0602 0.0592 0.0585 0.0579 0.0575 0.0569 0.0567 

[TRAIN] Epoch[1](8749/114412); Loss: 0.068812; Backpropagation: 0.2917 sec; Batch: 2.1280 sec
0.1450 0.1362 0.0904 0.0792 0.0673 0.0613 0.0587 0.0561 0.0540 0.0529 0.0517 0.0508 0.0501 0.0495 0.0492 0.0487 

[TRAIN] Epoch[1](8750/114412); Loss: 0.068909; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1134 0.1064 0.0849 0.0772 0.0707 0.0662 0.0641 0.0628 0.0603 0.0587 0.0578 0.0570 0.0563 0.0559 0.0556 0.0553 

[TRAIN] Epoch[1](8751/114412); Loss: 0.063413; Backpropagation: 0.2914 sec; Batch: 2.1155 sec
0.1730 0.1372 0.0995 0.0778 0.0689 0.0515 0.0505 0.0446 0.0421 0.0403 0.0392 0.0390 0.0384 0.0378 0.0376 0.0373 

[TRAIN] Epoch[1](8752/114412); Loss: 0.074757; Backpropagation: 0.2915 sec; Batch: 2.1149 sec
0.1310 0.1163 0.0941 0.0850 0.0778 0.0723 0.0681 0.0666 0.0641 0.0626 0.0614 0.0604 0.0598 0.0593 0.0588 0.0584 

[TRAIN] Epoch[1](8753/114412); Loss: 0.086133; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1499 0.1329 0.1041 0.0895 0.0843 0.0810 0.0781 0.0767 0.0752 0.0739 0.0733 0.0726 0.0722 0.0717 0.0715 0.0713 

[TRAIN] Epoch[1](8754/114412); Loss: 0.095317; Backpropagation: 0.2914 sec; Batch: 2.1214 sec
0.1449 0.1303 0.1117 0.1030 0.0986 0.0933 0.0923 0.0890 0.0862 0.0846 0.0835 0.0828 0.0820 0.0812 0.0809 0.0806 

[TRAIN] Epoch[1](8755/114412); Loss: 0.055544; Backpropagation: 0.2909 sec; Batch: 2.1481 sec
0.1085 0.0838 0.0733 0.0632 0.0606 0.0550 0.0494 0.0477 0.0458 0.0448 0.0438 0.0432 0.0429 0.0425 0.0422 0.0420 

[TRAIN] Epoch[1](8756/114412); Loss: 0.106606; Backpropagation: 0.2913 sec; Batch: 2.0786 sec
0.1679 0.1418 0.1260 0.1178 0.1100 0.1037 0.1024 0.1010 0.0976 0.0956 0.0937 0.0917 0.0905 0.0897 0.0886 0.0878 

[TRAIN] Epoch[1](8757/114412); Loss: 0.076302; Backpropagation: 0.2906 sec; Batch: 2.1234 sec
0.1481 0.1407 0.1073 0.0933 0.0793 0.0720 0.0670 0.0631 0.0602 0.0588 0.0572 0.0559 0.0553 0.0547 0.0542 0.0537 

[TRAIN] Epoch[1](8758/114412); Loss: 0.069178; Backpropagation: 0.2907 sec; Batch: 2.1158 sec
0.1237 0.1010 0.0830 0.0760 0.0749 0.0687 0.0640 0.0606 0.0593 0.0585 0.0575 0.0568 0.0563 0.0558 0.0554 0.0553 

[TRAIN] Epoch[1](8759/114412); Loss: 0.081663; Backpropagation: 0.2917 sec; Batch: 2.1175 sec
0.1607 0.1401 0.1009 0.0919 0.0857 0.0775 0.0736 0.0696 0.0670 0.0652 0.0640 0.0631 0.0625 0.0620 0.0614 0.0613 

[TRAIN] Epoch[1](8760/114412); Loss: 0.087606; Backpropagation: 0.2909 sec; Batch: 2.1204 sec
0.1444 0.1304 0.1078 0.0957 0.0879 0.0837 0.0813 0.0795 0.0774 0.0760 0.0749 0.0737 0.0729 0.0725 0.0720 0.0717 

[TRAIN] Epoch[1](8761/114412); Loss: 0.081749; Backpropagation: 0.2908 sec; Batch: 2.1146 sec
0.1473 0.1243 0.0960 0.0900 0.0827 0.0790 0.0753 0.0730 0.0713 0.0693 0.0680 0.0673 0.0668 0.0663 0.0660 0.0654 

[TRAIN] Epoch[1](8762/114412); Loss: 0.068277; Backpropagation: 0.2908 sec; Batch: 2.0796 sec
0.1271 0.1082 0.0902 0.0778 0.0690 0.0672 0.0618 0.0598 0.0572 0.0559 0.0547 0.0536 0.0531 0.0528 0.0523 0.0520 

[TRAIN] Epoch[1](8763/114412); Loss: 0.058922; Backpropagation: 0.2913 sec; Batch: 2.0792 sec
0.1396 0.1251 0.0774 0.0627 0.0569 0.0539 0.0497 0.0482 0.0445 0.0427 0.0417 0.0410 0.0404 0.0399 0.0397 0.0394 

[TRAIN] Epoch[1](8764/114412); Loss: 0.096229; Backpropagation: 0.2909 sec; Batch: 2.1162 sec
0.1516 0.1380 0.1123 0.1025 0.0951 0.0907 0.0880 0.0879 0.0871 0.0860 0.0848 0.0844 0.0833 0.0830 0.0827 0.0824 

[TRAIN] Epoch[1](8765/114412); Loss: 0.064414; Backpropagation: 0.2906 sec; Batch: 2.0786 sec
0.1634 0.1307 0.0856 0.0754 0.0616 0.0530 0.0544 0.0513 0.0483 0.0464 0.0453 0.0443 0.0435 0.0430 0.0424 0.0419 

[TRAIN] Epoch[1](8766/114412); Loss: 0.082160; Backpropagation: 0.2924 sec; Batch: 2.0892 sec
0.1518 0.1285 0.0989 0.0897 0.0827 0.0805 0.0764 0.0735 0.0702 0.0687 0.0679 0.0667 0.0658 0.0650 0.0644 0.0639 

[TRAIN] Epoch[1](8767/114412); Loss: 0.097857; Backpropagation: 0.2928 sec; Batch: 2.0811 sec
0.1588 0.1480 0.1241 0.1133 0.1006 0.0938 0.0887 0.0866 0.0847 0.0832 0.0821 0.0814 0.0807 0.0801 0.0799 0.0796 

[TRAIN] Epoch[1](8768/114412); Loss: 0.081490; Backpropagation: 0.2905 sec; Batch: 2.1230 sec
0.1791 0.1598 0.1235 0.0952 0.0818 0.0714 0.0664 0.0640 0.0614 0.0596 0.0588 0.0577 0.0570 0.0566 0.0559 0.0556 

[TRAIN] Epoch[1](8769/114412); Loss: 0.080372; Backpropagation: 0.2908 sec; Batch: 2.0799 sec
0.1776 0.1519 0.1092 0.0935 0.0796 0.0729 0.0677 0.0649 0.0624 0.0607 0.0595 0.0587 0.0578 0.0570 0.0565 0.0561 

[TRAIN] Epoch[1](8770/114412); Loss: 0.087649; Backpropagation: 0.2917 sec; Batch: 2.0782 sec
0.1913 0.1646 0.1218 0.0965 0.0826 0.0812 0.0705 0.0740 0.0707 0.0694 0.0662 0.0646 0.0634 0.0624 0.0618 0.0613 

[TRAIN] Epoch[1](8771/114412); Loss: 0.114526; Backpropagation: 0.2921 sec; Batch: 2.0830 sec
0.2226 0.1888 0.1522 0.1370 0.1179 0.1094 0.1035 0.0987 0.0944 0.0916 0.0899 0.0879 0.0865 0.0851 0.0839 0.0830 

[TRAIN] Epoch[1](8772/114412); Loss: 0.076590; Backpropagation: 0.2908 sec; Batch: 2.1162 sec
0.1676 0.1461 0.1123 0.0910 0.0733 0.0650 0.0617 0.0613 0.0594 0.0578 0.0573 0.0557 0.0549 0.0544 0.0540 0.0537 

[TRAIN] Epoch[1](8773/114412); Loss: 0.080569; Backpropagation: 0.2912 sec; Batch: 2.0784 sec
0.1940 0.1588 0.1196 0.1016 0.0920 0.0773 0.0682 0.0611 0.0570 0.0547 0.0534 0.0521 0.0509 0.0499 0.0496 0.0490 

[TRAIN] Epoch[1](8774/114412); Loss: 0.084572; Backpropagation: 0.2911 sec; Batch: 2.0992 sec
0.1527 0.1272 0.1033 0.0930 0.0849 0.0807 0.0775 0.0756 0.0735 0.0719 0.0706 0.0696 0.0688 0.0683 0.0679 0.0675 

[TRAIN] Epoch[1](8775/114412); Loss: 0.064752; Backpropagation: 0.2918 sec; Batch: 2.0809 sec
0.1236 0.1136 0.0830 0.0775 0.0648 0.0603 0.0582 0.0558 0.0531 0.0516 0.0506 0.0499 0.0492 0.0487 0.0483 0.0479 

[TRAIN] Epoch[1](8776/114412); Loss: 0.075996; Backpropagation: 0.2915 sec; Batch: 2.0950 sec
0.1553 0.1377 0.0961 0.0846 0.0754 0.0698 0.0681 0.0641 0.0620 0.0603 0.0593 0.0580 0.0571 0.0565 0.0558 0.0558 

[TRAIN] Epoch[1](8777/114412); Loss: 0.070283; Backpropagation: 0.2909 sec; Batch: 2.1250 sec
0.1511 0.1285 0.0922 0.0764 0.0713 0.0648 0.0601 0.0576 0.0561 0.0544 0.0533 0.0529 0.0522 0.0516 0.0511 0.0508 

[TRAIN] Epoch[1](8778/114412); Loss: 0.066960; Backpropagation: 0.2907 sec; Batch: 2.1146 sec
0.1311 0.1198 0.0787 0.0722 0.0666 0.0642 0.0594 0.0577 0.0553 0.0542 0.0534 0.0529 0.0521 0.0515 0.0513 0.0510 

[TRAIN] Epoch[1](8779/114412); Loss: 0.076735; Backpropagation: 0.2914 sec; Batch: 2.0832 sec
0.1308 0.1235 0.0978 0.0879 0.0793 0.0731 0.0690 0.0671 0.0653 0.0639 0.0629 0.0622 0.0618 0.0614 0.0610 0.0609 

[TRAIN] Epoch[1](8780/114412); Loss: 0.090425; Backpropagation: 0.2912 sec; Batch: 2.0789 sec
0.1612 0.1455 0.1128 0.1016 0.0911 0.0848 0.0819 0.0788 0.0770 0.0758 0.0746 0.0735 0.0727 0.0722 0.0717 0.0715 

[TRAIN] Epoch[1](8781/114412); Loss: 0.085682; Backpropagation: 0.2911 sec; Batch: 2.0827 sec
0.1341 0.1279 0.1067 0.0957 0.0876 0.0829 0.0794 0.0777 0.0752 0.0740 0.0728 0.0723 0.0715 0.0712 0.0710 0.0709 

[TRAIN] Epoch[1](8782/114412); Loss: 0.066519; Backpropagation: 0.2908 sec; Batch: 2.1002 sec
0.1305 0.1165 0.0822 0.0736 0.0657 0.0624 0.0596 0.0568 0.0549 0.0541 0.0531 0.0521 0.0514 0.0509 0.0504 0.0500 

[TRAIN] Epoch[1](8783/114412); Loss: 0.061171; Backpropagation: 0.2914 sec; Batch: 2.0826 sec
0.1233 0.1048 0.0747 0.0691 0.0617 0.0585 0.0556 0.0527 0.0510 0.0492 0.0479 0.0472 0.0465 0.0459 0.0454 0.0451 

[TRAIN] Epoch[1](8784/114412); Loss: 0.062022; Backpropagation: 0.2913 sec; Batch: 2.1260 sec
0.1334 0.1206 0.0805 0.0709 0.0603 0.0576 0.0526 0.0499 0.0485 0.0470 0.0463 0.0457 0.0450 0.0448 0.0446 0.0445 

[TRAIN] Epoch[1](8785/114412); Loss: 0.075928; Backpropagation: 0.2913 sec; Batch: 2.1223 sec
0.1234 0.1142 0.0948 0.0871 0.0796 0.0757 0.0717 0.0691 0.0666 0.0647 0.0637 0.0625 0.0613 0.0606 0.0601 0.0595 

[TRAIN] Epoch[1](8786/114412); Loss: 0.078474; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1263 0.1182 0.0952 0.0862 0.0790 0.0750 0.0729 0.0713 0.0694 0.0684 0.0672 0.0665 0.0658 0.0651 0.0648 0.0643 

[TRAIN] Epoch[1](8787/114412); Loss: 0.089976; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1658 0.1467 0.1164 0.1003 0.0894 0.0850 0.0806 0.0788 0.0760 0.0742 0.0730 0.0722 0.0712 0.0706 0.0700 0.0694 

[TRAIN] Epoch[1](8788/114412); Loss: 0.086555; Backpropagation: 0.2914 sec; Batch: 2.0792 sec
0.1487 0.1225 0.1003 0.0932 0.0882 0.0856 0.0815 0.0784 0.0761 0.0750 0.0741 0.0734 0.0726 0.0720 0.0720 0.0714 

[TRAIN] Epoch[1](8789/114412); Loss: 0.053029; Backpropagation: 0.2912 sec; Batch: 2.0781 sec
0.1019 0.0910 0.0660 0.0580 0.0532 0.0503 0.0474 0.0458 0.0443 0.0432 0.0423 0.0417 0.0414 0.0409 0.0406 0.0404 

[TRAIN] Epoch[1](8790/114412); Loss: 0.059824; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1100 0.0988 0.0785 0.0704 0.0606 0.0567 0.0540 0.0523 0.0499 0.0485 0.0475 0.0467 0.0463 0.0459 0.0456 0.0453 

[TRAIN] Epoch[1](8791/114412); Loss: 0.096885; Backpropagation: 0.2917 sec; Batch: 2.1127 sec
0.1935 0.1757 0.1378 0.1121 0.0947 0.0870 0.0845 0.0804 0.0772 0.0749 0.0741 0.0728 0.0722 0.0716 0.0710 0.0706 

[TRAIN] Epoch[1](8792/114412); Loss: 0.084032; Backpropagation: 0.2915 sec; Batch: 2.1151 sec
0.1646 0.1523 0.1169 0.0992 0.0860 0.0783 0.0726 0.0703 0.0675 0.0654 0.0640 0.0628 0.0619 0.0612 0.0609 0.0603 

[TRAIN] Epoch[1](8793/114412); Loss: 0.066055; Backpropagation: 0.2913 sec; Batch: 2.1203 sec
0.1253 0.1158 0.0916 0.0787 0.0694 0.0637 0.0583 0.0558 0.0535 0.0518 0.0507 0.0497 0.0489 0.0483 0.0478 0.0474 

[TRAIN] Epoch[1](8794/114412); Loss: 0.075960; Backpropagation: 0.2929 sec; Batch: 2.1213 sec
0.1581 0.1508 0.0970 0.0820 0.0727 0.0673 0.0636 0.0628 0.0600 0.0587 0.0586 0.0576 0.0570 0.0566 0.0564 0.0561 

[TRAIN] Epoch[1](8795/114412); Loss: 0.074392; Backpropagation: 0.2929 sec; Batch: 2.1162 sec
0.1419 0.1194 0.0912 0.0859 0.0772 0.0715 0.0677 0.0648 0.0629 0.0609 0.0598 0.0588 0.0581 0.0573 0.0568 0.0561 

[TRAIN] Epoch[1](8796/114412); Loss: 0.053857; Backpropagation: 0.2915 sec; Batch: 2.1202 sec
0.1074 0.0987 0.0762 0.0669 0.0582 0.0509 0.0475 0.0451 0.0428 0.0411 0.0397 0.0388 0.0379 0.0371 0.0368 0.0366 

[TRAIN] Epoch[1](8797/114412); Loss: 0.068489; Backpropagation: 0.2931 sec; Batch: 2.1164 sec
0.1629 0.1360 0.0956 0.0802 0.0700 0.0582 0.0567 0.0540 0.0518 0.0500 0.0486 0.0475 0.0470 0.0462 0.0457 0.0452 

[TRAIN] Epoch[1](8798/114412); Loss: 0.069700; Backpropagation: 0.2931 sec; Batch: 2.1241 sec
0.1400 0.1231 0.0830 0.0739 0.0693 0.0644 0.0617 0.0611 0.0579 0.0563 0.0555 0.0550 0.0541 0.0536 0.0532 0.0530 

[TRAIN] Epoch[1](8799/114412); Loss: 0.094611; Backpropagation: 0.2932 sec; Batch: 2.0820 sec
0.1583 0.1465 0.1124 0.0994 0.0923 0.0883 0.0865 0.0853 0.0834 0.0821 0.0813 0.0805 0.0800 0.0796 0.0791 0.0788 

[TRAIN] Epoch[1](8800/114412); Loss: 0.094208; Backpropagation: 0.2931 sec; Batch: 2.1216 sec
0.1350 0.1270 0.1127 0.1071 0.1017 0.0948 0.0915 0.0885 0.0856 0.0839 0.0824 0.0810 0.0800 0.0795 0.0786 0.0781 

[TRAIN] Epoch[1](8801/114412); Loss: 0.079447; Backpropagation: 0.2933 sec; Batch: 2.1214 sec
0.1594 0.1484 0.1094 0.0929 0.0810 0.0731 0.0675 0.0652 0.0630 0.0611 0.0601 0.0596 0.0584 0.0578 0.0573 0.0568 

[TRAIN] Epoch[1](8802/114412); Loss: 0.095284; Backpropagation: 0.2940 sec; Batch: 2.1232 sec
0.1510 0.1361 0.1183 0.1089 0.1011 0.0935 0.0903 0.0877 0.0843 0.0827 0.0812 0.0796 0.0786 0.0778 0.0770 0.0765 

[TRAIN] Epoch[1](8803/114412); Loss: 0.081977; Backpropagation: 0.2915 sec; Batch: 2.0961 sec
0.1654 0.1287 0.0969 0.0979 0.0870 0.0791 0.0747 0.0702 0.0674 0.0661 0.0646 0.0638 0.0632 0.0625 0.0622 0.0620 

[TRAIN] Epoch[1](8804/114412); Loss: 0.077769; Backpropagation: 0.2957 sec; Batch: 2.1237 sec
0.1550 0.1147 0.0958 0.0862 0.0828 0.0792 0.0728 0.0681 0.0655 0.0634 0.0623 0.0611 0.0602 0.0595 0.0589 0.0586 

[TRAIN] Epoch[1](8805/114412); Loss: 0.091764; Backpropagation: 0.2923 sec; Batch: 2.1156 sec
0.1507 0.1301 0.1105 0.1008 0.0933 0.0885 0.0857 0.0834 0.0817 0.0805 0.0794 0.0781 0.0772 0.0766 0.0760 0.0757 

[TRAIN] Epoch[1](8806/114412); Loss: 0.059404; Backpropagation: 0.2932 sec; Batch: 2.1169 sec
0.0923 0.0794 0.0751 0.0686 0.0634 0.0593 0.0575 0.0548 0.0530 0.0517 0.0507 0.0499 0.0492 0.0488 0.0486 0.0483 

[TRAIN] Epoch[1](8807/114412); Loss: 0.084316; Backpropagation: 0.2953 sec; Batch: 2.1438 sec
0.1539 0.1450 0.1078 0.0983 0.0856 0.0819 0.0758 0.0730 0.0704 0.0680 0.0670 0.0660 0.0649 0.0644 0.0637 0.0633 

[TRAIN] Epoch[1](8808/114412); Loss: 0.057242; Backpropagation: 0.2917 sec; Batch: 2.0789 sec
0.1003 0.0925 0.0747 0.0669 0.0628 0.0580 0.0525 0.0499 0.0485 0.0472 0.0458 0.0449 0.0438 0.0432 0.0426 0.0422 

[TRAIN] Epoch[1](8809/114412); Loss: 0.054639; Backpropagation: 0.2932 sec; Batch: 2.0807 sec
0.1192 0.1127 0.0704 0.0590 0.0549 0.0497 0.0468 0.0455 0.0424 0.0412 0.0403 0.0394 0.0388 0.0381 0.0379 0.0377 

[TRAIN] Epoch[1](8810/114412); Loss: 0.053653; Backpropagation: 0.2909 sec; Batch: 2.0795 sec
0.1279 0.0999 0.0575 0.0599 0.0549 0.0513 0.0478 0.0449 0.0421 0.0406 0.0400 0.0391 0.0387 0.0384 0.0379 0.0376 

[TRAIN] Epoch[1](8811/114412); Loss: 0.075670; Backpropagation: 0.2911 sec; Batch: 2.0792 sec
0.1416 0.1257 0.1014 0.0897 0.0763 0.0701 0.0650 0.0652 0.0634 0.0617 0.0603 0.0593 0.0585 0.0580 0.0576 0.0571 

[TRAIN] Epoch[1](8812/114412); Loss: 0.082819; Backpropagation: 0.2954 sec; Batch: 2.1102 sec
0.1143 0.1101 0.1007 0.0959 0.0878 0.0841 0.0799 0.0768 0.0755 0.0737 0.0727 0.0717 0.0710 0.0707 0.0702 0.0699 

[TRAIN] Epoch[1](8813/114412); Loss: 0.065063; Backpropagation: 0.2920 sec; Batch: 2.1182 sec
0.1288 0.1138 0.0879 0.0749 0.0629 0.0598 0.0566 0.0550 0.0529 0.0515 0.0508 0.0503 0.0497 0.0492 0.0487 0.0483 

[TRAIN] Epoch[1](8814/114412); Loss: 0.075983; Backpropagation: 0.2930 sec; Batch: 2.1182 sec
0.1520 0.1322 0.0893 0.0788 0.0743 0.0710 0.0671 0.0646 0.0632 0.0632 0.0613 0.0605 0.0602 0.0595 0.0594 0.0593 

[TRAIN] Epoch[1](8815/114412); Loss: 0.101736; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1832 0.1604 0.1259 0.1183 0.1068 0.0968 0.0925 0.0892 0.0864 0.0847 0.0834 0.0821 0.0805 0.0798 0.0791 0.0786 

[TRAIN] Epoch[1](8816/114412); Loss: 0.083099; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1421 0.1219 0.0976 0.0916 0.0840 0.0811 0.0770 0.0749 0.0728 0.0716 0.0705 0.0699 0.0694 0.0687 0.0684 0.0681 

[TRAIN] Epoch[1](8817/114412); Loss: 0.057013; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1172 0.1066 0.0719 0.0658 0.0543 0.0542 0.0505 0.0479 0.0463 0.0445 0.0436 0.0429 0.0422 0.0417 0.0415 0.0411 

[TRAIN] Epoch[1](8818/114412); Loss: 0.086627; Backpropagation: 0.2912 sec; Batch: 2.0794 sec
0.1790 0.1718 0.1257 0.1126 0.0895 0.0785 0.0721 0.0687 0.0658 0.0639 0.0626 0.0609 0.0599 0.0592 0.0581 0.0578 

[TRAIN] Epoch[1](8819/114412); Loss: 0.057595; Backpropagation: 0.2912 sec; Batch: 2.1365 sec
0.1106 0.0863 0.0707 0.0641 0.0604 0.0554 0.0521 0.0505 0.0491 0.0477 0.0468 0.0465 0.0461 0.0453 0.0450 0.0449 

[TRAIN] Epoch[1](8820/114412); Loss: 0.075359; Backpropagation: 0.2913 sec; Batch: 2.1168 sec
0.1612 0.1298 0.1081 0.0902 0.0801 0.0685 0.0651 0.0613 0.0588 0.0570 0.0560 0.0551 0.0544 0.0539 0.0534 0.0531 

[TRAIN] Epoch[1](8821/114412); Loss: 0.058937; Backpropagation: 0.2909 sec; Batch: 2.0829 sec
0.1241 0.1001 0.0705 0.0644 0.0629 0.0582 0.0538 0.0496 0.0478 0.0471 0.0456 0.0446 0.0440 0.0436 0.0433 0.0432 

[TRAIN] Epoch[1](8822/114412); Loss: 0.074353; Backpropagation: 0.2902 sec; Batch: 2.1156 sec
0.1485 0.1337 0.0951 0.0817 0.0724 0.0680 0.0655 0.0628 0.0610 0.0594 0.0583 0.0576 0.0571 0.0566 0.0563 0.0558 

[TRAIN] Epoch[1](8823/114412); Loss: 0.068798; Backpropagation: 0.2907 sec; Batch: 2.1212 sec
0.1331 0.1268 0.0902 0.0751 0.0659 0.0633 0.0595 0.0579 0.0563 0.0549 0.0543 0.0536 0.0530 0.0525 0.0524 0.0521 

[TRAIN] Epoch[1](8824/114412); Loss: 0.071358; Backpropagation: 0.2957 sec; Batch: 2.0825 sec
0.1500 0.1372 0.0957 0.0836 0.0699 0.0641 0.0592 0.0586 0.0569 0.0548 0.0541 0.0531 0.0518 0.0514 0.0509 0.0504 

[TRAIN] Epoch[1](8825/114412); Loss: 0.105827; Backpropagation: 0.2910 sec; Batch: 2.1191 sec
0.1833 0.1598 0.1296 0.1175 0.1068 0.1033 0.0980 0.0943 0.0921 0.0901 0.0886 0.0876 0.0868 0.0859 0.0851 0.0846 

[TRAIN] Epoch[1](8826/114412); Loss: 0.083121; Backpropagation: 0.2939 sec; Batch: 2.0874 sec
0.1488 0.1289 0.1039 0.0936 0.0835 0.0785 0.0758 0.0739 0.0720 0.0703 0.0689 0.0677 0.0669 0.0662 0.0658 0.0655 

[TRAIN] Epoch[1](8827/114412); Loss: 0.070142; Backpropagation: 0.2922 sec; Batch: 2.1538 sec
0.1263 0.1098 0.0867 0.0797 0.0720 0.0675 0.0647 0.0624 0.0606 0.0589 0.0575 0.0566 0.0558 0.0552 0.0547 0.0541 

[TRAIN] Epoch[1](8828/114412); Loss: 0.101657; Backpropagation: 0.2930 sec; Batch: 2.1167 sec
0.1746 0.1442 0.1218 0.1123 0.1042 0.0996 0.0962 0.0924 0.0903 0.0883 0.0866 0.0852 0.0841 0.0830 0.0823 0.0815 

[TRAIN] Epoch[1](8829/114412); Loss: 0.094730; Backpropagation: 0.2936 sec; Batch: 2.1210 sec
0.2137 0.1863 0.1440 0.1229 0.0991 0.0785 0.0768 0.0710 0.0700 0.0670 0.0655 0.0649 0.0646 0.0640 0.0639 0.0638 

[TRAIN] Epoch[1](8830/114412); Loss: 0.074778; Backpropagation: 0.2929 sec; Batch: 2.1210 sec
0.1542 0.1355 0.0965 0.0884 0.0766 0.0716 0.0661 0.0624 0.0597 0.0582 0.0569 0.0555 0.0547 0.0540 0.0534 0.0527 

[TRAIN] Epoch[1](8831/114412); Loss: 0.062524; Backpropagation: 0.2913 sec; Batch: 2.0794 sec
0.1246 0.0987 0.0764 0.0692 0.0688 0.0614 0.0567 0.0545 0.0517 0.0504 0.0495 0.0487 0.0480 0.0477 0.0473 0.0468 

[TRAIN] Epoch[1](8832/114412); Loss: 0.084873; Backpropagation: 0.2934 sec; Batch: 2.1184 sec
0.1529 0.1436 0.1039 0.0889 0.0804 0.0777 0.0753 0.0741 0.0723 0.0712 0.0706 0.0702 0.0697 0.0693 0.0690 0.0688 

[TRAIN] Epoch[1](8833/114412); Loss: 0.059474; Backpropagation: 0.2921 sec; Batch: 2.0790 sec
0.1304 0.1234 0.0811 0.0700 0.0551 0.0520 0.0508 0.0475 0.0454 0.0443 0.0432 0.0427 0.0419 0.0413 0.0412 0.0410 

[TRAIN] Epoch[1](8834/114412); Loss: 0.070278; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1374 0.1258 0.0981 0.0859 0.0749 0.0681 0.0624 0.0580 0.0562 0.0541 0.0526 0.0517 0.0507 0.0500 0.0496 0.0491 

[TRAIN] Epoch[1](8835/114412); Loss: 0.135811; Backpropagation: 0.2905 sec; Batch: 2.1202 sec
0.2213 0.2034 0.1725 0.1577 0.1460 0.1360 0.1281 0.1234 0.1190 0.1143 0.1119 0.1105 0.1092 0.1077 0.1066 0.1054 

[TRAIN] Epoch[1](8836/114412); Loss: 0.083638; Backpropagation: 0.2932 sec; Batch: 2.1173 sec
0.1541 0.1448 0.1050 0.0937 0.0825 0.0776 0.0728 0.0715 0.0699 0.0687 0.0676 0.0670 0.0664 0.0659 0.0656 0.0651 

[TRAIN] Epoch[1](8837/114412); Loss: 0.094216; Backpropagation: 0.2910 sec; Batch: 2.1188 sec
0.1406 0.1319 0.1127 0.1046 0.0972 0.0921 0.0887 0.0869 0.0850 0.0836 0.0826 0.0816 0.0808 0.0803 0.0797 0.0792 

[TRAIN] Epoch[1](8838/114412); Loss: 0.066247; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1266 0.1204 0.0837 0.0742 0.0664 0.0633 0.0582 0.0564 0.0543 0.0530 0.0521 0.0514 0.0507 0.0501 0.0497 0.0494 

[TRAIN] Epoch[1](8839/114412); Loss: 0.082100; Backpropagation: 0.2915 sec; Batch: 2.1168 sec
0.1538 0.1359 0.0978 0.0879 0.0821 0.0786 0.0752 0.0724 0.0701 0.0687 0.0673 0.0663 0.0653 0.0645 0.0641 0.0636 

[TRAIN] Epoch[1](8840/114412); Loss: 0.069221; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1611 0.1224 0.0867 0.0871 0.0682 0.0636 0.0585 0.0561 0.0539 0.0525 0.0512 0.0503 0.0496 0.0494 0.0488 0.0483 

[TRAIN] Epoch[1](8841/114412); Loss: 0.063317; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1192 0.0924 0.0771 0.0715 0.0685 0.0646 0.0599 0.0563 0.0538 0.0522 0.0515 0.0505 0.0497 0.0490 0.0485 0.0483 

[TRAIN] Epoch[1](8842/114412); Loss: 0.075046; Backpropagation: 0.2912 sec; Batch: 2.1196 sec
0.1243 0.1077 0.0894 0.0812 0.0779 0.0732 0.0709 0.0681 0.0661 0.0649 0.0641 0.0632 0.0629 0.0626 0.0623 0.0620 

[TRAIN] Epoch[1](8843/114412); Loss: 0.076829; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1467 0.1199 0.1004 0.0888 0.0773 0.0743 0.0691 0.0674 0.0649 0.0626 0.0614 0.0608 0.0599 0.0592 0.0585 0.0580 

[TRAIN] Epoch[1](8844/114412); Loss: 0.081835; Backpropagation: 0.2913 sec; Batch: 2.1190 sec
0.1313 0.1170 0.1000 0.0913 0.0852 0.0811 0.0778 0.0756 0.0731 0.0713 0.0695 0.0686 0.0678 0.0670 0.0665 0.0662 

[TRAIN] Epoch[1](8845/114412); Loss: 0.089701; Backpropagation: 0.2917 sec; Batch: 2.1162 sec
0.1497 0.1301 0.1086 0.0998 0.0946 0.0874 0.0840 0.0811 0.0795 0.0781 0.0760 0.0752 0.0743 0.0729 0.0721 0.0716 

[TRAIN] Epoch[1](8846/114412); Loss: 0.092983; Backpropagation: 0.2953 sec; Batch: 2.1075 sec
0.1693 0.1397 0.1157 0.0986 0.0935 0.0892 0.0882 0.0839 0.0808 0.0788 0.0773 0.0761 0.0753 0.0743 0.0737 0.0734 

[TRAIN] Epoch[1](8847/114412); Loss: 0.099676; Backpropagation: 0.2912 sec; Batch: 2.1223 sec
0.1588 0.1388 0.1206 0.1109 0.1038 0.0973 0.0930 0.0901 0.0885 0.0875 0.0862 0.0853 0.0845 0.0839 0.0831 0.0825 

[TRAIN] Epoch[1](8848/114412); Loss: 0.073594; Backpropagation: 0.2951 sec; Batch: 2.1313 sec
0.1269 0.1208 0.0917 0.0828 0.0740 0.0698 0.0669 0.0647 0.0632 0.0616 0.0609 0.0601 0.0593 0.0588 0.0582 0.0578 

[TRAIN] Epoch[1](8849/114412); Loss: 0.065601; Backpropagation: 0.2929 sec; Batch: 2.1142 sec
0.1335 0.1099 0.0897 0.0757 0.0662 0.0607 0.0580 0.0555 0.0537 0.0519 0.0506 0.0499 0.0492 0.0488 0.0483 0.0480 

[TRAIN] Epoch[1](8850/114412); Loss: 0.090371; Backpropagation: 0.2912 sec; Batch: 2.1758 sec
0.1617 0.1442 0.1178 0.1062 0.0953 0.0870 0.0816 0.0790 0.0759 0.0741 0.0727 0.0717 0.0708 0.0699 0.0694 0.0686 

[TRAIN] Epoch[1](8851/114412); Loss: 0.087897; Backpropagation: 0.2953 sec; Batch: 2.1236 sec
0.1441 0.1271 0.1120 0.0996 0.0929 0.0857 0.0826 0.0795 0.0772 0.0749 0.0737 0.0728 0.0721 0.0715 0.0706 0.0702 

[TRAIN] Epoch[1](8852/114412); Loss: 0.067562; Backpropagation: 0.2929 sec; Batch: 2.1190 sec
0.1338 0.1140 0.0857 0.0758 0.0680 0.0638 0.0612 0.0590 0.0563 0.0543 0.0535 0.0524 0.0515 0.0510 0.0505 0.0500 

[TRAIN] Epoch[1](8853/114412); Loss: 0.074876; Backpropagation: 0.2949 sec; Batch: 2.0805 sec
0.1703 0.1347 0.0986 0.0785 0.0755 0.0668 0.0653 0.0620 0.0597 0.0578 0.0568 0.0556 0.0550 0.0545 0.0537 0.0532 

[TRAIN] Epoch[1](8854/114412); Loss: 0.084782; Backpropagation: 0.2907 sec; Batch: 2.1176 sec
0.1412 0.1241 0.1083 0.0990 0.0889 0.0815 0.0782 0.0761 0.0737 0.0721 0.0713 0.0699 0.0689 0.0683 0.0678 0.0671 

[TRAIN] Epoch[1](8855/114412); Loss: 0.071912; Backpropagation: 0.2915 sec; Batch: 2.0805 sec
0.1899 0.1753 0.1122 0.0796 0.0751 0.0633 0.0525 0.0524 0.0487 0.0458 0.0443 0.0434 0.0426 0.0424 0.0418 0.0412 

[TRAIN] Epoch[1](8856/114412); Loss: 0.104534; Backpropagation: 0.2937 sec; Batch: 2.1207 sec
0.1695 0.1600 0.1305 0.1202 0.1097 0.1017 0.0964 0.0932 0.0905 0.0886 0.0871 0.0859 0.0855 0.0851 0.0846 0.0841 

[TRAIN] Epoch[1](8857/114412); Loss: 0.087648; Backpropagation: 0.2916 sec; Batch: 2.1026 sec
0.1437 0.1258 0.1070 0.0972 0.0896 0.0863 0.0823 0.0798 0.0778 0.0758 0.0746 0.0738 0.0731 0.0723 0.0718 0.0714 

[TRAIN] Epoch[1](8858/114412); Loss: 0.080525; Backpropagation: 0.2981 sec; Batch: 2.1295 sec
0.1532 0.1387 0.1026 0.0891 0.0792 0.0764 0.0724 0.0703 0.0672 0.0655 0.0643 0.0633 0.0625 0.0618 0.0612 0.0608 

[TRAIN] Epoch[1](8859/114412); Loss: 0.057059; Backpropagation: 0.2983 sec; Batch: 2.1235 sec
0.1136 0.1029 0.0726 0.0684 0.0565 0.0540 0.0499 0.0478 0.0462 0.0451 0.0439 0.0431 0.0427 0.0424 0.0421 0.0417 

[TRAIN] Epoch[1](8860/114412); Loss: 0.086943; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1448 0.1245 0.1055 0.0952 0.0892 0.0853 0.0813 0.0784 0.0766 0.0750 0.0741 0.0734 0.0726 0.0722 0.0718 0.0713 

[TRAIN] Epoch[1](8861/114412); Loss: 0.071584; Backpropagation: 0.2917 sec; Batch: 2.0779 sec
0.1540 0.1307 0.0855 0.0757 0.0676 0.0656 0.0627 0.0599 0.0584 0.0568 0.0561 0.0555 0.0550 0.0543 0.0540 0.0535 

[TRAIN] Epoch[1](8862/114412); Loss: 0.082941; Backpropagation: 0.2923 sec; Batch: 2.0813 sec
0.1315 0.1230 0.0988 0.0919 0.0845 0.0822 0.0787 0.0757 0.0744 0.0718 0.0705 0.0701 0.0692 0.0688 0.0683 0.0677 

[TRAIN] Epoch[1](8863/114412); Loss: 0.070593; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1138 0.1020 0.0915 0.0844 0.0744 0.0697 0.0653 0.0635 0.0616 0.0599 0.0590 0.0579 0.0574 0.0568 0.0564 0.0559 

[TRAIN] Epoch[1](8864/114412); Loss: 0.075322; Backpropagation: 0.2909 sec; Batch: 2.1186 sec
0.1340 0.1232 0.0979 0.0879 0.0787 0.0727 0.0679 0.0654 0.0628 0.0616 0.0604 0.0597 0.0589 0.0585 0.0580 0.0577 

[TRAIN] Epoch[1](8865/114412); Loss: 0.065372; Backpropagation: 0.2911 sec; Batch: 2.1206 sec
0.1244 0.1083 0.0859 0.0761 0.0661 0.0619 0.0584 0.0577 0.0548 0.0527 0.0518 0.0507 0.0500 0.0496 0.0489 0.0487 

[TRAIN] Epoch[1](8866/114412); Loss: 0.062086; Backpropagation: 0.2915 sec; Batch: 2.1217 sec
0.1388 0.1250 0.0826 0.0720 0.0603 0.0555 0.0527 0.0500 0.0479 0.0466 0.0454 0.0445 0.0440 0.0432 0.0427 0.0423 

[TRAIN] Epoch[1](8867/114412); Loss: 0.091016; Backpropagation: 0.2914 sec; Batch: 2.1222 sec
0.1435 0.1280 0.1133 0.1027 0.0964 0.0908 0.0856 0.0828 0.0802 0.0783 0.0776 0.0766 0.0758 0.0754 0.0749 0.0743 

[TRAIN] Epoch[1](8868/114412); Loss: 0.091043; Backpropagation: 0.2923 sec; Batch: 2.1131 sec
0.1619 0.1437 0.1079 0.0962 0.0892 0.0874 0.0840 0.0809 0.0789 0.0775 0.0763 0.0756 0.0749 0.0745 0.0741 0.0736 

[TRAIN] Epoch[1](8869/114412); Loss: 0.067721; Backpropagation: 0.2913 sec; Batch: 2.1132 sec
0.1438 0.1195 0.0798 0.0782 0.0688 0.0629 0.0592 0.0565 0.0550 0.0536 0.0525 0.0517 0.0512 0.0506 0.0501 0.0498 

[TRAIN] Epoch[1](8870/114412); Loss: 0.082643; Backpropagation: 0.2911 sec; Batch: 2.1188 sec
0.1581 0.1297 0.0954 0.0876 0.0801 0.0772 0.0745 0.0744 0.0710 0.0695 0.0690 0.0681 0.0676 0.0671 0.0666 0.0663 

[TRAIN] Epoch[1](8871/114412); Loss: 0.065333; Backpropagation: 0.2940 sec; Batch: 2.1204 sec
0.1198 0.1003 0.0771 0.0720 0.0671 0.0656 0.0616 0.0582 0.0557 0.0545 0.0537 0.0530 0.0523 0.0518 0.0514 0.0511 

[TRAIN] Epoch[1](8872/114412); Loss: 0.068473; Backpropagation: 0.2929 sec; Batch: 2.1202 sec
0.1442 0.1326 0.0986 0.0788 0.0684 0.0598 0.0574 0.0553 0.0536 0.0522 0.0510 0.0500 0.0492 0.0485 0.0482 0.0477 

[TRAIN] Epoch[1](8873/114412); Loss: 0.062586; Backpropagation: 0.2904 sec; Batch: 2.1258 sec
0.1388 0.1250 0.0868 0.0800 0.0657 0.0566 0.0499 0.0477 0.0470 0.0455 0.0444 0.0436 0.0431 0.0429 0.0423 0.0421 

[TRAIN] Epoch[1](8874/114412); Loss: 0.086768; Backpropagation: 0.2913 sec; Batch: 2.0796 sec
0.1695 0.1429 0.1152 0.1031 0.0900 0.0814 0.0755 0.0727 0.0713 0.0700 0.0685 0.0671 0.0662 0.0656 0.0650 0.0645 

[TRAIN] Epoch[1](8875/114412); Loss: 0.083156; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1775 0.1420 0.1091 0.0943 0.0831 0.0759 0.0731 0.0695 0.0673 0.0653 0.0640 0.0631 0.0625 0.0618 0.0613 0.0609 

[TRAIN] Epoch[1](8876/114412); Loss: 0.078122; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1587 0.1344 0.1010 0.0888 0.0798 0.0723 0.0692 0.0656 0.0642 0.0624 0.0610 0.0600 0.0592 0.0583 0.0577 0.0573 

[TRAIN] Epoch[1](8877/114412); Loss: 0.051822; Backpropagation: 0.2915 sec; Batch: 2.1262 sec
0.1004 0.0815 0.0632 0.0595 0.0568 0.0495 0.0473 0.0459 0.0434 0.0423 0.0415 0.0403 0.0399 0.0396 0.0390 0.0388 

[TRAIN] Epoch[1](8878/114412); Loss: 0.087054; Backpropagation: 0.2912 sec; Batch: 2.1219 sec
0.1227 0.1122 0.0996 0.0952 0.0926 0.0882 0.0834 0.0821 0.0798 0.0788 0.0779 0.0767 0.0765 0.0761 0.0755 0.0755 

[TRAIN] Epoch[1](8879/114412); Loss: 0.079287; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1292 0.1193 0.0995 0.0880 0.0827 0.0767 0.0733 0.0715 0.0695 0.0680 0.0670 0.0660 0.0651 0.0646 0.0643 0.0639 

[TRAIN] Epoch[1](8880/114412); Loss: 0.102331; Backpropagation: 0.2915 sec; Batch: 2.1348 sec
0.1580 0.1503 0.1296 0.1145 0.1097 0.1021 0.0961 0.0929 0.0905 0.0883 0.0863 0.0850 0.0842 0.0837 0.0834 0.0829 

[TRAIN] Epoch[1](8881/114412); Loss: 0.109094; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1765 0.1596 0.1326 0.1226 0.1163 0.1095 0.1044 0.1007 0.0958 0.0943 0.0929 0.0901 0.0893 0.0879 0.0868 0.0863 

[TRAIN] Epoch[1](8882/114412); Loss: 0.075708; Backpropagation: 0.2910 sec; Batch: 2.0820 sec
0.1563 0.1253 0.0950 0.0871 0.0791 0.0739 0.0683 0.0655 0.0621 0.0602 0.0587 0.0574 0.0567 0.0560 0.0551 0.0547 

[TRAIN] Epoch[1](8883/114412); Loss: 0.080650; Backpropagation: 0.2916 sec; Batch: 2.1199 sec
0.1457 0.1335 0.1058 0.0915 0.0816 0.0755 0.0722 0.0692 0.0675 0.0660 0.0649 0.0643 0.0637 0.0633 0.0630 0.0626 

[TRAIN] Epoch[1](8884/114412); Loss: 0.067234; Backpropagation: 0.2905 sec; Batch: 2.0770 sec
0.1118 0.0883 0.0801 0.0744 0.0703 0.0693 0.0652 0.0616 0.0597 0.0583 0.0572 0.0568 0.0562 0.0558 0.0555 0.0552 

[TRAIN] Epoch[1](8885/114412); Loss: 0.087664; Backpropagation: 0.2910 sec; Batch: 2.1225 sec
0.1360 0.1226 0.1033 0.0956 0.0881 0.0865 0.0834 0.0816 0.0790 0.0774 0.0764 0.0755 0.0749 0.0745 0.0741 0.0737 

[TRAIN] Epoch[1](8886/114412); Loss: 0.058386; Backpropagation: 0.2907 sec; Batch: 2.0773 sec
0.1030 0.0951 0.0744 0.0655 0.0627 0.0572 0.0540 0.0511 0.0492 0.0480 0.0468 0.0461 0.0459 0.0453 0.0450 0.0448 

[TRAIN] Epoch[1](8887/114412); Loss: 0.091242; Backpropagation: 0.2909 sec; Batch: 2.0810 sec
0.1691 0.1494 0.1155 0.0992 0.0914 0.0849 0.0810 0.0789 0.0776 0.0758 0.0748 0.0738 0.0730 0.0723 0.0718 0.0714 

[TRAIN] Epoch[1](8888/114412); Loss: 0.080359; Backpropagation: 0.2906 sec; Batch: 2.0808 sec
0.1434 0.1263 0.0990 0.0884 0.0790 0.0760 0.0726 0.0709 0.0694 0.0682 0.0672 0.0662 0.0654 0.0649 0.0646 0.0643 

[TRAIN] Epoch[1](8889/114412); Loss: 0.097211; Backpropagation: 0.2905 sec; Batch: 2.0768 sec
0.1755 0.1600 0.1241 0.1103 0.1006 0.0930 0.0875 0.0849 0.0825 0.0800 0.0787 0.0775 0.0763 0.0754 0.0748 0.0742 

[TRAIN] Epoch[1](8890/114412); Loss: 0.101027; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.1720 0.1549 0.1278 0.1187 0.1076 0.0982 0.0943 0.0892 0.0866 0.0851 0.0834 0.0817 0.0807 0.0797 0.0786 0.0780 

[TRAIN] Epoch[1](8891/114412); Loss: 0.080127; Backpropagation: 0.2909 sec; Batch: 2.1692 sec
0.1558 0.1425 0.1018 0.0921 0.0817 0.0759 0.0711 0.0682 0.0655 0.0639 0.0626 0.0613 0.0608 0.0602 0.0595 0.0591 

[TRAIN] Epoch[1](8892/114412); Loss: 0.080154; Backpropagation: 0.2915 sec; Batch: 2.1064 sec
0.1689 0.1512 0.1166 0.0976 0.0811 0.0705 0.0658 0.0648 0.0623 0.0612 0.0593 0.0582 0.0573 0.0566 0.0560 0.0554 

[TRAIN] Epoch[1](8893/114412); Loss: 0.083035; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1566 0.1421 0.1087 0.0972 0.0875 0.0809 0.0756 0.0721 0.0690 0.0664 0.0649 0.0632 0.0622 0.0615 0.0606 0.0599 

[TRAIN] Epoch[1](8894/114412); Loss: 0.091868; Backpropagation: 0.2906 sec; Batch: 2.0767 sec
0.1407 0.1283 0.1117 0.1017 0.0940 0.0888 0.0854 0.0832 0.0815 0.0806 0.0799 0.0793 0.0790 0.0787 0.0786 0.0785 

[TRAIN] Epoch[1](8895/114412); Loss: 0.084683; Backpropagation: 0.2950 sec; Batch: 2.1301 sec
0.1483 0.1429 0.1033 0.0905 0.0855 0.0791 0.0766 0.0744 0.0723 0.0711 0.0700 0.0692 0.0686 0.0680 0.0677 0.0674 

[TRAIN] Epoch[1](8896/114412); Loss: 0.069057; Backpropagation: 0.2930 sec; Batch: 2.1168 sec
0.1254 0.1119 0.0858 0.0810 0.0725 0.0652 0.0630 0.0604 0.0582 0.0568 0.0560 0.0549 0.0541 0.0536 0.0532 0.0529 

[TRAIN] Epoch[1](8897/114412); Loss: 0.097558; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1841 0.1592 0.1362 0.1198 0.1053 0.0977 0.0875 0.0835 0.0804 0.0771 0.0753 0.0736 0.0719 0.0707 0.0699 0.0687 

[TRAIN] Epoch[1](8898/114412); Loss: 0.069412; Backpropagation: 0.2910 sec; Batch: 2.0783 sec
0.1369 0.1206 0.0801 0.0743 0.0707 0.0674 0.0623 0.0603 0.0581 0.0572 0.0560 0.0546 0.0536 0.0532 0.0528 0.0524 

[TRAIN] Epoch[1](8899/114412); Loss: 0.076352; Backpropagation: 0.2909 sec; Batch: 2.0931 sec
0.1280 0.1181 0.0907 0.0827 0.0762 0.0738 0.0702 0.0680 0.0666 0.0657 0.0647 0.0642 0.0637 0.0631 0.0630 0.0629 

[TRAIN] Epoch[1](8900/114412); Loss: 0.097123; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.2078 0.1715 0.1395 0.1256 0.1016 0.0891 0.0821 0.0780 0.0747 0.0724 0.0708 0.0698 0.0688 0.0680 0.0674 0.0669 

[TRAIN] Epoch[1](8901/114412); Loss: 0.087217; Backpropagation: 0.2911 sec; Batch: 2.0793 sec
0.1494 0.1353 0.1074 0.0973 0.0876 0.0825 0.0802 0.0779 0.0757 0.0743 0.0731 0.0722 0.0714 0.0708 0.0704 0.0700 

[TRAIN] Epoch[1](8902/114412); Loss: 0.083663; Backpropagation: 0.2910 sec; Batch: 2.0975 sec
0.1453 0.1293 0.1082 0.0976 0.0892 0.0808 0.0762 0.0726 0.0711 0.0697 0.0681 0.0674 0.0666 0.0659 0.0655 0.0650 

[TRAIN] Epoch[1](8903/114412); Loss: 0.072389; Backpropagation: 0.2906 sec; Batch: 2.0780 sec
0.1190 0.1081 0.0871 0.0784 0.0739 0.0695 0.0671 0.0653 0.0641 0.0631 0.0621 0.0610 0.0605 0.0600 0.0596 0.0594 

[TRAIN] Epoch[1](8904/114412); Loss: 0.084963; Backpropagation: 0.2910 sec; Batch: 2.1194 sec
0.1284 0.1142 0.0996 0.0952 0.0897 0.0839 0.0812 0.0794 0.0773 0.0758 0.0744 0.0733 0.0726 0.0720 0.0713 0.0710 

[TRAIN] Epoch[1](8905/114412); Loss: 0.081935; Backpropagation: 0.2932 sec; Batch: 2.1234 sec
0.1560 0.1298 0.0991 0.0887 0.0821 0.0786 0.0749 0.0720 0.0703 0.0683 0.0673 0.0661 0.0652 0.0647 0.0642 0.0635 

[TRAIN] Epoch[1](8906/114412); Loss: 0.075435; Backpropagation: 0.2916 sec; Batch: 2.1196 sec
0.1209 0.1063 0.0878 0.0832 0.0776 0.0735 0.0713 0.0688 0.0676 0.0665 0.0655 0.0647 0.0640 0.0635 0.0630 0.0628 

[TRAIN] Epoch[1](8907/114412); Loss: 0.073268; Backpropagation: 0.2909 sec; Batch: 2.1041 sec
0.1354 0.1116 0.0915 0.0836 0.0750 0.0715 0.0672 0.0645 0.0627 0.0610 0.0598 0.0589 0.0580 0.0575 0.0572 0.0568 

[TRAIN] Epoch[1](8908/114412); Loss: 0.062219; Backpropagation: 0.2952 sec; Batch: 2.1225 sec
0.1068 0.0962 0.0847 0.0755 0.0667 0.0600 0.0564 0.0540 0.0524 0.0513 0.0501 0.0493 0.0486 0.0481 0.0477 0.0475 

[TRAIN] Epoch[1](8909/114412); Loss: 0.066050; Backpropagation: 0.2953 sec; Batch: 2.1207 sec
0.1092 0.1025 0.0841 0.0733 0.0675 0.0636 0.0606 0.0587 0.0571 0.0558 0.0551 0.0544 0.0540 0.0538 0.0536 0.0535 

[TRAIN] Epoch[1](8910/114412); Loss: 0.085713; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.1430 0.1311 0.1084 0.0991 0.0902 0.0872 0.0807 0.0777 0.0755 0.0721 0.0704 0.0691 0.0679 0.0668 0.0665 0.0659 

[TRAIN] Epoch[1](8911/114412); Loss: 0.096173; Backpropagation: 0.2913 sec; Batch: 2.0773 sec
0.1690 0.1467 0.1231 0.1045 0.0953 0.0938 0.0870 0.0861 0.0829 0.0811 0.0798 0.0791 0.0781 0.0777 0.0774 0.0773 

[TRAIN] Epoch[1](8912/114412); Loss: 0.070694; Backpropagation: 0.2971 sec; Batch: 2.0923 sec
0.1315 0.1149 0.0926 0.0791 0.0715 0.0676 0.0645 0.0625 0.0599 0.0581 0.0567 0.0555 0.0549 0.0544 0.0539 0.0536 

[TRAIN] Epoch[1](8913/114412); Loss: 0.077409; Backpropagation: 0.2930 sec; Batch: 2.0846 sec
0.1370 0.1180 0.0975 0.0917 0.0793 0.0748 0.0712 0.0692 0.0669 0.0652 0.0635 0.0625 0.0617 0.0606 0.0599 0.0596 

[TRAIN] Epoch[1](8914/114412); Loss: 0.074318; Backpropagation: 0.2906 sec; Batch: 2.0768 sec
0.1504 0.1305 0.0954 0.0853 0.0749 0.0698 0.0656 0.0633 0.0604 0.0587 0.0577 0.0567 0.0560 0.0555 0.0547 0.0544 

[TRAIN] Epoch[1](8915/114412); Loss: 0.065125; Backpropagation: 0.2908 sec; Batch: 2.1167 sec
0.1445 0.1231 0.0934 0.0728 0.0636 0.0604 0.0526 0.0546 0.0506 0.0490 0.0478 0.0470 0.0461 0.0459 0.0455 0.0450 

[TRAIN] Epoch[1](8916/114412); Loss: 0.077600; Backpropagation: 0.2908 sec; Batch: 2.0777 sec
0.1984 0.1636 0.1072 0.0825 0.0745 0.0625 0.0687 0.0619 0.0585 0.0553 0.0535 0.0527 0.0519 0.0506 0.0499 0.0497 

[TRAIN] Epoch[1](8917/114412); Loss: 0.071348; Backpropagation: 0.2905 sec; Batch: 2.1245 sec
0.1393 0.1218 0.0961 0.0823 0.0723 0.0670 0.0635 0.0609 0.0581 0.0564 0.0555 0.0546 0.0539 0.0536 0.0532 0.0529 

[TRAIN] Epoch[1](8918/114412); Loss: 0.069812; Backpropagation: 0.2902 sec; Batch: 2.0779 sec
0.1320 0.1205 0.0878 0.0768 0.0683 0.0650 0.0624 0.0605 0.0583 0.0572 0.0562 0.0554 0.0548 0.0542 0.0540 0.0537 

[TRAIN] Epoch[1](8919/114412); Loss: 0.081576; Backpropagation: 0.2910 sec; Batch: 2.0769 sec
0.1340 0.1118 0.0916 0.0877 0.0826 0.0827 0.0766 0.0747 0.0729 0.0719 0.0710 0.0702 0.0699 0.0696 0.0691 0.0689 

[TRAIN] Epoch[1](8920/114412); Loss: 0.066073; Backpropagation: 0.2910 sec; Batch: 2.0783 sec
0.1211 0.1138 0.0826 0.0747 0.0657 0.0621 0.0586 0.0565 0.0553 0.0541 0.0534 0.0528 0.0521 0.0518 0.0516 0.0511 

[TRAIN] Epoch[1](8921/114412); Loss: 0.071422; Backpropagation: 0.2912 sec; Batch: 2.0901 sec
0.1350 0.1235 0.0899 0.0795 0.0715 0.0660 0.0633 0.0618 0.0599 0.0583 0.0572 0.0563 0.0557 0.0554 0.0549 0.0544 

[TRAIN] Epoch[1](8922/114412); Loss: 0.067413; Backpropagation: 0.2904 sec; Batch: 2.1208 sec
0.1361 0.1228 0.0894 0.0800 0.0719 0.0625 0.0598 0.0562 0.0537 0.0523 0.0510 0.0498 0.0491 0.0484 0.0480 0.0477 

[TRAIN] Epoch[1](8923/114412); Loss: 0.060872; Backpropagation: 0.2952 sec; Batch: 2.1185 sec
0.1527 0.1346 0.0954 0.0639 0.0611 0.0581 0.0475 0.0458 0.0428 0.0409 0.0397 0.0394 0.0388 0.0379 0.0378 0.0376 

[TRAIN] Epoch[1](8924/114412); Loss: 0.089710; Backpropagation: 0.2952 sec; Batch: 2.1175 sec
0.1716 0.1405 0.1190 0.1112 0.0946 0.0875 0.0807 0.0761 0.0737 0.0718 0.0703 0.0693 0.0681 0.0675 0.0670 0.0667 

[TRAIN] Epoch[1](8925/114412); Loss: 0.081302; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1703 0.1622 0.1188 0.1007 0.0802 0.0718 0.0665 0.0640 0.0616 0.0600 0.0590 0.0583 0.0575 0.0571 0.0566 0.0562 

[TRAIN] Epoch[1](8926/114412); Loss: 0.074023; Backpropagation: 0.2913 sec; Batch: 2.0795 sec
0.1617 0.1387 0.1021 0.0915 0.0742 0.0665 0.0643 0.0605 0.0570 0.0554 0.0542 0.0529 0.0521 0.0515 0.0511 0.0508 

[TRAIN] Epoch[1](8927/114412); Loss: 0.099039; Backpropagation: 0.2910 sec; Batch: 2.1155 sec
0.1497 0.1301 0.1133 0.1085 0.1020 0.0973 0.0944 0.0927 0.0907 0.0889 0.0877 0.0872 0.0863 0.0857 0.0854 0.0849 

[TRAIN] Epoch[1](8928/114412); Loss: 0.080063; Backpropagation: 0.2907 sec; Batch: 2.0870 sec
0.1150 0.1044 0.0901 0.0864 0.0822 0.0788 0.0769 0.0753 0.0739 0.0729 0.0721 0.0714 0.0709 0.0705 0.0702 0.0700 

[TRAIN] Epoch[1](8929/114412); Loss: 0.056110; Backpropagation: 0.2919 sec; Batch: 2.1002 sec
0.1141 0.1055 0.0670 0.0618 0.0563 0.0521 0.0497 0.0473 0.0459 0.0449 0.0437 0.0429 0.0422 0.0417 0.0414 0.0412 

[TRAIN] Epoch[1](8930/114412); Loss: 0.084823; Backpropagation: 0.2909 sec; Batch: 2.1207 sec
0.2040 0.1611 0.1140 0.0829 0.0848 0.0717 0.0722 0.0688 0.0670 0.0642 0.0631 0.0618 0.0609 0.0606 0.0602 0.0598 

[TRAIN] Epoch[1](8931/114412); Loss: 0.053367; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.0954 0.0893 0.0766 0.0642 0.0572 0.0519 0.0487 0.0464 0.0438 0.0426 0.0412 0.0404 0.0398 0.0392 0.0387 0.0384 

[TRAIN] Epoch[1](8932/114412); Loss: 0.067085; Backpropagation: 0.2914 sec; Batch: 2.0843 sec
0.1621 0.1496 0.0978 0.0713 0.0624 0.0556 0.0536 0.0536 0.0497 0.0475 0.0466 0.0457 0.0449 0.0446 0.0442 0.0440 

[TRAIN] Epoch[1](8933/114412); Loss: 0.084692; Backpropagation: 0.2952 sec; Batch: 2.1220 sec
0.1351 0.1175 0.1013 0.0929 0.0890 0.0844 0.0805 0.0780 0.0758 0.0744 0.0733 0.0721 0.0713 0.0705 0.0698 0.0693 

[TRAIN] Epoch[1](8934/114412); Loss: 0.068929; Backpropagation: 0.2906 sec; Batch: 2.1201 sec
0.1460 0.1301 0.0957 0.0827 0.0719 0.0612 0.0584 0.0557 0.0533 0.0517 0.0508 0.0501 0.0494 0.0490 0.0487 0.0482 

[TRAIN] Epoch[1](8935/114412); Loss: 0.078059; Backpropagation: 0.2912 sec; Batch: 2.1133 sec
0.1231 0.1138 0.1000 0.0879 0.0811 0.0759 0.0729 0.0709 0.0687 0.0673 0.0663 0.0654 0.0646 0.0640 0.0638 0.0634 

[TRAIN] Epoch[1](8936/114412); Loss: 0.067600; Backpropagation: 0.2927 sec; Batch: 2.1159 sec
0.1318 0.1172 0.0916 0.0800 0.0712 0.0619 0.0583 0.0576 0.0548 0.0534 0.0523 0.0512 0.0507 0.0503 0.0498 0.0496 

[TRAIN] Epoch[1](8937/114412); Loss: 0.075642; Backpropagation: 0.2911 sec; Batch: 2.1208 sec
0.1365 0.1254 0.0940 0.0849 0.0758 0.0710 0.0680 0.0666 0.0646 0.0631 0.0622 0.0609 0.0601 0.0595 0.0591 0.0587 

[TRAIN] Epoch[1](8938/114412); Loss: 0.075578; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1677 0.1521 0.1101 0.0926 0.0771 0.0662 0.0621 0.0582 0.0560 0.0546 0.0535 0.0529 0.0522 0.0517 0.0513 0.0509 

[TRAIN] Epoch[1](8939/114412); Loss: 0.059196; Backpropagation: 0.2905 sec; Batch: 2.1132 sec
0.1146 0.0993 0.0756 0.0667 0.0603 0.0568 0.0536 0.0523 0.0500 0.0482 0.0466 0.0457 0.0450 0.0445 0.0442 0.0438 

[TRAIN] Epoch[1](8940/114412); Loss: 0.073835; Backpropagation: 0.2911 sec; Batch: 2.1150 sec
0.1211 0.1061 0.0881 0.0836 0.0761 0.0714 0.0688 0.0671 0.0652 0.0639 0.0629 0.0621 0.0617 0.0613 0.0610 0.0609 

[TRAIN] Epoch[1](8941/114412); Loss: 0.073748; Backpropagation: 0.2926 sec; Batch: 2.1150 sec
0.1514 0.1412 0.0988 0.0838 0.0686 0.0640 0.0637 0.0605 0.0589 0.0575 0.0565 0.0559 0.0553 0.0550 0.0547 0.0543 

[TRAIN] Epoch[1](8942/114412); Loss: 0.093465; Backpropagation: 0.2911 sec; Batch: 2.1122 sec
0.1573 0.1372 0.1160 0.1044 0.0964 0.0907 0.0863 0.0840 0.0818 0.0805 0.0792 0.0779 0.0770 0.0763 0.0756 0.0749 

[TRAIN] Epoch[1](8943/114412); Loss: 0.077010; Backpropagation: 0.2911 sec; Batch: 2.1129 sec
0.1671 0.1449 0.1017 0.0852 0.0695 0.0679 0.0639 0.0627 0.0608 0.0597 0.0590 0.0585 0.0581 0.0578 0.0577 0.0576 

[TRAIN] Epoch[1](8944/114412); Loss: 0.058418; Backpropagation: 0.2902 sec; Batch: 2.1128 sec
0.1463 0.1429 0.0812 0.0612 0.0510 0.0480 0.0439 0.0420 0.0415 0.0405 0.0397 0.0395 0.0393 0.0392 0.0393 0.0393 

[TRAIN] Epoch[1](8945/114412); Loss: 0.063722; Backpropagation: 0.2908 sec; Batch: 2.1192 sec
0.1292 0.1201 0.0796 0.0697 0.0624 0.0583 0.0557 0.0538 0.0520 0.0504 0.0495 0.0488 0.0481 0.0476 0.0473 0.0470 

[TRAIN] Epoch[1](8946/114412); Loss: 0.061286; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.1523 0.1360 0.0939 0.0777 0.0622 0.0534 0.0480 0.0452 0.0429 0.0409 0.0396 0.0388 0.0382 0.0376 0.0371 0.0368 

[TRAIN] Epoch[1](8947/114412); Loss: 0.074563; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1435 0.1239 0.0923 0.0798 0.0760 0.0710 0.0663 0.0645 0.0626 0.0614 0.0604 0.0595 0.0588 0.0582 0.0577 0.0572 

[TRAIN] Epoch[1](8948/114412); Loss: 0.069359; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1479 0.1365 0.1012 0.0827 0.0668 0.0591 0.0572 0.0554 0.0528 0.0521 0.0512 0.0502 0.0496 0.0492 0.0489 0.0487 

[TRAIN] Epoch[1](8949/114412); Loss: 0.081932; Backpropagation: 0.2953 sec; Batch: 2.1293 sec
0.1499 0.1279 0.0955 0.0893 0.0793 0.0773 0.0749 0.0738 0.0714 0.0700 0.0686 0.0678 0.0671 0.0666 0.0661 0.0656 

[TRAIN] Epoch[1](8950/114412); Loss: 0.088015; Backpropagation: 0.2953 sec; Batch: 2.1246 sec
0.1817 0.1593 0.1229 0.1034 0.0859 0.0794 0.0748 0.0720 0.0705 0.0682 0.0669 0.0660 0.0651 0.0645 0.0641 0.0636 

[TRAIN] Epoch[1](8951/114412); Loss: 0.060181; Backpropagation: 0.2928 sec; Batch: 2.1196 sec
0.1244 0.1161 0.0864 0.0742 0.0592 0.0525 0.0495 0.0487 0.0463 0.0454 0.0444 0.0438 0.0434 0.0431 0.0428 0.0427 

[TRAIN] Epoch[1](8952/114412); Loss: 0.068614; Backpropagation: 0.2927 sec; Batch: 2.1189 sec
0.1562 0.1398 0.1013 0.0792 0.0633 0.0590 0.0553 0.0539 0.0518 0.0502 0.0495 0.0488 0.0479 0.0475 0.0472 0.0469 

[TRAIN] Epoch[1](8953/114412); Loss: 0.064452; Backpropagation: 0.2905 sec; Batch: 2.0767 sec
0.1094 0.1024 0.0871 0.0790 0.0668 0.0619 0.0579 0.0561 0.0543 0.0529 0.0521 0.0513 0.0508 0.0502 0.0497 0.0493 

[TRAIN] Epoch[1](8954/114412); Loss: 0.091333; Backpropagation: 0.2904 sec; Batch: 2.0794 sec
0.1530 0.1372 0.1033 0.1010 0.0918 0.0885 0.0856 0.0825 0.0809 0.0796 0.0783 0.0772 0.0765 0.0758 0.0753 0.0748 

[TRAIN] Epoch[1](8955/114412); Loss: 0.068930; Backpropagation: 0.2913 sec; Batch: 2.0782 sec
0.1858 0.1400 0.0958 0.0739 0.0808 0.0685 0.0537 0.0528 0.0473 0.0458 0.0444 0.0435 0.0431 0.0426 0.0425 0.0423 

[TRAIN] Epoch[1](8956/114412); Loss: 0.076195; Backpropagation: 0.2928 sec; Batch: 2.1199 sec
0.1337 0.1212 0.0955 0.0842 0.0764 0.0726 0.0692 0.0673 0.0652 0.0640 0.0632 0.0624 0.0617 0.0612 0.0608 0.0605 

[TRAIN] Epoch[1](8957/114412); Loss: 0.075423; Backpropagation: 0.2927 sec; Batch: 2.1185 sec
0.1826 0.1504 0.1067 0.0842 0.0730 0.0670 0.0602 0.0584 0.0569 0.0551 0.0539 0.0529 0.0522 0.0515 0.0510 0.0505 

[TRAIN] Epoch[1](8958/114412); Loss: 0.071148; Backpropagation: 0.2909 sec; Batch: 2.1140 sec
0.1330 0.1077 0.0939 0.0884 0.0789 0.0718 0.0665 0.0619 0.0587 0.0570 0.0556 0.0545 0.0536 0.0527 0.0524 0.0520 

[TRAIN] Epoch[1](8959/114412); Loss: 0.087699; Backpropagation: 0.2912 sec; Batch: 2.1333 sec
0.1549 0.1453 0.1085 0.0955 0.0868 0.0826 0.0792 0.0769 0.0752 0.0740 0.0726 0.0716 0.0710 0.0701 0.0698 0.0693 

[TRAIN] Epoch[1](8960/114412); Loss: 0.080450; Backpropagation: 0.2926 sec; Batch: 2.1142 sec
0.1692 0.1525 0.1110 0.0909 0.0772 0.0713 0.0687 0.0671 0.0643 0.0632 0.0609 0.0595 0.0586 0.0581 0.0576 0.0572 

[TRAIN] Epoch[1](8961/114412); Loss: 0.067494; Backpropagation: 0.2953 sec; Batch: 2.1178 sec
0.1276 0.1103 0.0833 0.0747 0.0681 0.0636 0.0617 0.0591 0.0568 0.0560 0.0548 0.0537 0.0531 0.0528 0.0522 0.0521 

[TRAIN] Epoch[1](8962/114412); Loss: 0.091356; Backpropagation: 0.2929 sec; Batch: 2.0798 sec
0.1782 0.1562 0.1324 0.1052 0.0904 0.0911 0.0806 0.0761 0.0733 0.0711 0.0699 0.0687 0.0681 0.0673 0.0667 0.0664 

[TRAIN] Epoch[1](8963/114412); Loss: 0.084949; Backpropagation: 0.2954 sec; Batch: 2.1039 sec
0.1738 0.1550 0.1094 0.0934 0.0820 0.0788 0.0727 0.0714 0.0683 0.0663 0.0658 0.0652 0.0647 0.0644 0.0641 0.0639 

[TRAIN] Epoch[1](8964/114412); Loss: 0.088974; Backpropagation: 0.2950 sec; Batch: 2.1208 sec
0.1353 0.1253 0.1046 0.0989 0.0919 0.0871 0.0841 0.0820 0.0800 0.0786 0.0776 0.0768 0.0760 0.0756 0.0751 0.0748 

[TRAIN] Epoch[1](8965/114412); Loss: 0.075373; Backpropagation: 0.2949 sec; Batch: 2.1160 sec
0.1232 0.1138 0.0924 0.0847 0.0793 0.0741 0.0701 0.0680 0.0660 0.0645 0.0635 0.0625 0.0617 0.0612 0.0607 0.0604 

[TRAIN] Epoch[1](8966/114412); Loss: 0.076036; Backpropagation: 0.2910 sec; Batch: 2.1192 sec
0.1198 0.1118 0.0892 0.0824 0.0774 0.0731 0.0709 0.0692 0.0675 0.0664 0.0658 0.0653 0.0650 0.0645 0.0642 0.0640 

[TRAIN] Epoch[1](8967/114412); Loss: 0.085411; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.2091 0.1826 0.1296 0.0954 0.0700 0.0688 0.0689 0.0661 0.0638 0.0624 0.0601 0.0592 0.0583 0.0578 0.0574 0.0572 

[TRAIN] Epoch[1](8968/114412); Loss: 0.064474; Backpropagation: 0.2912 sec; Batch: 2.1255 sec
0.1366 0.1103 0.0849 0.0717 0.0652 0.0608 0.0574 0.0547 0.0526 0.0506 0.0498 0.0487 0.0479 0.0472 0.0467 0.0464 

[TRAIN] Epoch[1](8969/114412); Loss: 0.111756; Backpropagation: 0.2909 sec; Batch: 2.1138 sec
0.1653 0.1434 0.1244 0.1174 0.1129 0.1097 0.1066 0.1049 0.1033 0.1020 0.1014 0.1005 0.0997 0.0994 0.0988 0.0984 

[TRAIN] Epoch[1](8970/114412); Loss: 0.101811; Backpropagation: 0.2908 sec; Batch: 2.1165 sec
0.1595 0.1425 0.1193 0.1100 0.1042 0.1001 0.0958 0.0942 0.0917 0.0901 0.0892 0.0879 0.0871 0.0863 0.0856 0.0853 

[TRAIN] Epoch[1](8971/114412); Loss: 0.089747; Backpropagation: 0.2930 sec; Batch: 2.1168 sec
0.1806 0.1558 0.1201 0.0980 0.0865 0.0821 0.0779 0.0769 0.0737 0.0717 0.0708 0.0696 0.0688 0.0684 0.0677 0.0673 

[TRAIN] Epoch[1](8972/114412); Loss: 0.100942; Backpropagation: 0.2927 sec; Batch: 2.1208 sec
0.1457 0.1351 0.1210 0.1102 0.1064 0.0995 0.0968 0.0946 0.0919 0.0907 0.0896 0.0880 0.0873 0.0867 0.0861 0.0856 

[TRAIN] Epoch[1](8973/114412); Loss: 0.073979; Backpropagation: 0.2954 sec; Batch: 2.0827 sec
0.1347 0.1286 0.0930 0.0782 0.0712 0.0691 0.0651 0.0637 0.0629 0.0614 0.0603 0.0599 0.0594 0.0589 0.0586 0.0586 

[TRAIN] Epoch[1](8974/114412); Loss: 0.086423; Backpropagation: 0.2930 sec; Batch: 2.1217 sec
0.1698 0.1535 0.1167 0.1007 0.0875 0.0812 0.0774 0.0740 0.0706 0.0678 0.0662 0.0651 0.0641 0.0634 0.0628 0.0621 

[TRAIN] Epoch[1](8975/114412); Loss: 0.087881; Backpropagation: 0.2903 sec; Batch: 2.0996 sec
0.1592 0.1477 0.1180 0.1072 0.0939 0.0846 0.0784 0.0750 0.0722 0.0701 0.0688 0.0677 0.0667 0.0660 0.0656 0.0650 

[TRAIN] Epoch[1](8976/114412); Loss: 0.064761; Backpropagation: 0.2923 sec; Batch: 2.1185 sec
0.1163 0.1114 0.0842 0.0738 0.0641 0.0607 0.0575 0.0559 0.0540 0.0528 0.0521 0.0515 0.0509 0.0505 0.0505 0.0501 

[TRAIN] Epoch[1](8977/114412); Loss: 0.078675; Backpropagation: 0.2928 sec; Batch: 2.1201 sec
0.1720 0.1423 0.1038 0.0891 0.0754 0.0700 0.0684 0.0660 0.0629 0.0612 0.0603 0.0588 0.0580 0.0574 0.0568 0.0564 

[TRAIN] Epoch[1](8978/114412); Loss: 0.066768; Backpropagation: 0.2950 sec; Batch: 2.1205 sec
0.1331 0.1189 0.0946 0.0791 0.0698 0.0651 0.0584 0.0554 0.0539 0.0512 0.0498 0.0489 0.0482 0.0476 0.0473 0.0469 

[TRAIN] Epoch[1](8979/114412); Loss: 0.120234; Backpropagation: 0.2956 sec; Batch: 2.1228 sec
0.1915 0.1798 0.1550 0.1398 0.1227 0.1233 0.1198 0.1160 0.1107 0.1038 0.1036 0.0971 0.0946 0.0919 0.0870 0.0871 

[TRAIN] Epoch[1](8980/114412); Loss: 0.095929; Backpropagation: 0.2926 sec; Batch: 2.1217 sec
0.1726 0.1625 0.1220 0.1035 0.0930 0.0885 0.0849 0.0820 0.0819 0.0800 0.0789 0.0785 0.0772 0.0769 0.0765 0.0759 

[TRAIN] Epoch[1](8981/114412); Loss: 0.063034; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.1226 0.1092 0.0757 0.0736 0.0632 0.0586 0.0565 0.0547 0.0523 0.0510 0.0503 0.0493 0.0486 0.0481 0.0475 0.0473 

[TRAIN] Epoch[1](8982/114412); Loss: 0.066053; Backpropagation: 0.2902 sec; Batch: 2.1178 sec
0.1213 0.1100 0.0876 0.0774 0.0697 0.0631 0.0590 0.0569 0.0548 0.0532 0.0522 0.0514 0.0508 0.0503 0.0498 0.0494 

[TRAIN] Epoch[1](8983/114412); Loss: 0.069736; Backpropagation: 0.2929 sec; Batch: 2.1339 sec
0.1366 0.1204 0.0918 0.0772 0.0691 0.0651 0.0612 0.0589 0.0575 0.0561 0.0550 0.0544 0.0539 0.0533 0.0529 0.0524 

[TRAIN] Epoch[1](8984/114412); Loss: 0.082061; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1371 0.1207 0.1001 0.0927 0.0858 0.0805 0.0769 0.0743 0.0719 0.0702 0.0691 0.0682 0.0672 0.0666 0.0660 0.0656 

[TRAIN] Epoch[1](8985/114412); Loss: 0.084057; Backpropagation: 0.2903 sec; Batch: 2.1129 sec
0.1533 0.1468 0.1085 0.0979 0.0870 0.0812 0.0759 0.0718 0.0700 0.0676 0.0666 0.0654 0.0642 0.0634 0.0630 0.0624 

[TRAIN] Epoch[1](8986/114412); Loss: 0.071888; Backpropagation: 0.2910 sec; Batch: 2.1147 sec
0.1517 0.1345 0.0999 0.0808 0.0704 0.0651 0.0606 0.0583 0.0566 0.0549 0.0542 0.0534 0.0530 0.0525 0.0522 0.0519 

[TRAIN] Epoch[1](8987/114412); Loss: 0.072328; Backpropagation: 0.2929 sec; Batch: 2.1188 sec
0.1460 0.1282 0.0962 0.0894 0.0763 0.0717 0.0644 0.0599 0.0576 0.0557 0.0541 0.0529 0.0520 0.0514 0.0510 0.0505 

[TRAIN] Epoch[1](8988/114412); Loss: 0.078431; Backpropagation: 0.2912 sec; Batch: 2.1203 sec
0.1502 0.1258 0.1063 0.0924 0.0844 0.0744 0.0699 0.0664 0.0646 0.0628 0.0618 0.0606 0.0597 0.0591 0.0585 0.0579 

[TRAIN] Epoch[1](8989/114412); Loss: 0.114453; Backpropagation: 0.2908 sec; Batch: 2.1331 sec
0.2216 0.1963 0.1542 0.1310 0.1187 0.1079 0.1024 0.0982 0.0947 0.0918 0.0897 0.0876 0.0859 0.0849 0.0835 0.0827 

[TRAIN] Epoch[1](8990/114412); Loss: 0.089983; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1657 0.1450 0.1156 0.0993 0.0904 0.0847 0.0810 0.0779 0.0756 0.0750 0.0738 0.0727 0.0718 0.0710 0.0703 0.0699 

[TRAIN] Epoch[1](8991/114412); Loss: 0.097588; Backpropagation: 0.2910 sec; Batch: 2.1253 sec
0.1518 0.1395 0.1195 0.1085 0.0988 0.0937 0.0912 0.0890 0.0869 0.0854 0.0846 0.0836 0.0832 0.0825 0.0818 0.0815 

[TRAIN] Epoch[1](8992/114412); Loss: 0.078658; Backpropagation: 0.2904 sec; Batch: 2.0779 sec
0.1742 0.1589 0.1108 0.0935 0.0738 0.0661 0.0634 0.0618 0.0605 0.0587 0.0577 0.0568 0.0562 0.0560 0.0552 0.0550 

[TRAIN] Epoch[1](8993/114412); Loss: 0.065727; Backpropagation: 0.2909 sec; Batch: 2.1170 sec
0.1167 0.1043 0.0814 0.0732 0.0678 0.0634 0.0598 0.0578 0.0562 0.0551 0.0540 0.0534 0.0527 0.0523 0.0519 0.0516 

[TRAIN] Epoch[1](8994/114412); Loss: 0.088360; Backpropagation: 0.2912 sec; Batch: 2.1188 sec
0.1828 0.1507 0.1160 0.0981 0.0901 0.0824 0.0771 0.0742 0.0720 0.0703 0.0690 0.0679 0.0667 0.0661 0.0654 0.0650 

[TRAIN] Epoch[1](8995/114412); Loss: 0.082628; Backpropagation: 0.2910 sec; Batch: 2.1212 sec
0.1614 0.1523 0.1166 0.0987 0.0812 0.0723 0.0688 0.0666 0.0654 0.0643 0.0638 0.0630 0.0623 0.0622 0.0618 0.0614 

[TRAIN] Epoch[1](8996/114412); Loss: 0.087608; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1370 0.1189 0.1024 0.0936 0.0887 0.0877 0.0832 0.0812 0.0791 0.0776 0.0768 0.0761 0.0756 0.0752 0.0746 0.0742 

[TRAIN] Epoch[1](8997/114412); Loss: 0.096807; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.1666 0.1399 0.1181 0.1072 0.0987 0.0945 0.0904 0.0875 0.0850 0.0833 0.0820 0.0806 0.0800 0.0791 0.0784 0.0777 

[TRAIN] Epoch[1](8998/114412); Loss: 0.103829; Backpropagation: 0.2926 sec; Batch: 2.1315 sec
0.1788 0.1578 0.1287 0.1214 0.1101 0.1039 0.0964 0.0924 0.0908 0.0875 0.0858 0.0841 0.0826 0.0812 0.0802 0.0796 

[TRAIN] Epoch[1](8999/114412); Loss: 0.097562; Backpropagation: 0.2929 sec; Batch: 2.1178 sec
0.1888 0.1659 0.1274 0.1031 0.0959 0.0889 0.0884 0.0844 0.0814 0.0794 0.0785 0.0774 0.0764 0.0757 0.0749 0.0745 

[TRAIN] Epoch[1](9000/114412); Loss: 0.049875; Backpropagation: 0.2948 sec; Batch: 2.1234 sec
0.0974 0.0882 0.0692 0.0609 0.0535 0.0482 0.0437 0.0420 0.0398 0.0388 0.0377 0.0366 0.0362 0.0357 0.0352 0.0349 

[TRAIN] Epoch[1](9001/114412); Loss: 0.077376; Backpropagation: 0.2928 sec; Batch: 2.1195 sec
0.1411 0.1306 0.0970 0.0836 0.0767 0.0717 0.0695 0.0674 0.0653 0.0641 0.0630 0.0623 0.0619 0.0616 0.0612 0.0610 

[TRAIN] Epoch[1](9002/114412); Loss: 0.083855; Backpropagation: 0.3017 sec; Batch: 2.1274 sec
0.1733 0.1501 0.1153 0.0927 0.0845 0.0749 0.0712 0.0691 0.0668 0.0655 0.0646 0.0636 0.0632 0.0624 0.0623 0.0621 

[TRAIN] Epoch[1](9003/114412); Loss: 0.098745; Backpropagation: 0.2909 sec; Batch: 2.1157 sec
0.2036 0.1728 0.1251 0.1036 0.0962 0.0889 0.0874 0.0838 0.0816 0.0801 0.0780 0.0769 0.0765 0.0755 0.0750 0.0749 

[TRAIN] Epoch[1](9004/114412); Loss: 0.088002; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.1856 0.1625 0.1306 0.1031 0.0948 0.0837 0.0757 0.0708 0.0684 0.0660 0.0638 0.0624 0.0614 0.0602 0.0596 0.0594 

[TRAIN] Epoch[1](9005/114412); Loss: 0.089645; Backpropagation: 0.2933 sec; Batch: 2.0802 sec
0.1564 0.1358 0.1080 0.0967 0.0898 0.0850 0.0821 0.0801 0.0781 0.0768 0.0759 0.0752 0.0745 0.0739 0.0733 0.0727 

[TRAIN] Epoch[1](9006/114412); Loss: 0.057774; Backpropagation: 0.2935 sec; Batch: 2.1178 sec
0.1309 0.1079 0.0765 0.0682 0.0598 0.0529 0.0499 0.0478 0.0453 0.0432 0.0423 0.0411 0.0404 0.0400 0.0393 0.0389 

[TRAIN] Epoch[1](9007/114412); Loss: 0.098984; Backpropagation: 0.2904 sec; Batch: 2.1198 sec
0.2203 0.1944 0.1382 0.1114 0.0932 0.0829 0.0796 0.0773 0.0754 0.0745 0.0735 0.0732 0.0729 0.0725 0.0723 0.0722 

[TRAIN] Epoch[1](9008/114412); Loss: 0.056114; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1151 0.1034 0.0751 0.0646 0.0575 0.0519 0.0494 0.0468 0.0449 0.0433 0.0424 0.0418 0.0412 0.0406 0.0401 0.0398 

[TRAIN] Epoch[1](9009/114412); Loss: 0.062826; Backpropagation: 0.2914 sec; Batch: 2.1151 sec
0.1406 0.1275 0.0842 0.0759 0.0611 0.0531 0.0504 0.0482 0.0473 0.0465 0.0458 0.0455 0.0452 0.0448 0.0447 0.0445 

[TRAIN] Epoch[1](9010/114412); Loss: 0.078269; Backpropagation: 0.2912 sec; Batch: 2.1002 sec
0.1597 0.1352 0.1102 0.0841 0.0807 0.0731 0.0704 0.0682 0.0652 0.0610 0.0602 0.0591 0.0572 0.0569 0.0562 0.0550 

[TRAIN] Epoch[1](9011/114412); Loss: 0.070877; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.1359 0.1123 0.0911 0.0798 0.0732 0.0672 0.0642 0.0618 0.0597 0.0579 0.0570 0.0560 0.0553 0.0546 0.0541 0.0539 

[TRAIN] Epoch[1](9012/114412); Loss: 0.081763; Backpropagation: 0.2914 sec; Batch: 2.1200 sec
0.1551 0.1353 0.1038 0.0893 0.0810 0.0750 0.0727 0.0710 0.0687 0.0673 0.0666 0.0654 0.0650 0.0645 0.0640 0.0636 

[TRAIN] Epoch[1](9013/114412); Loss: 0.097449; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1848 0.1648 0.1263 0.1173 0.1020 0.0949 0.0866 0.0820 0.0782 0.0772 0.0759 0.0750 0.0744 0.0736 0.0732 0.0728 

[TRAIN] Epoch[1](9014/114412); Loss: 0.086134; Backpropagation: 0.2913 sec; Batch: 2.1144 sec
0.1304 0.1131 0.1038 0.0940 0.0880 0.0841 0.0818 0.0806 0.0784 0.0770 0.0758 0.0749 0.0746 0.0743 0.0737 0.0734 

[TRAIN] Epoch[1](9015/114412); Loss: 0.067901; Backpropagation: 0.2913 sec; Batch: 2.1129 sec
0.1394 0.1216 0.0846 0.0776 0.0685 0.0639 0.0620 0.0588 0.0550 0.0535 0.0526 0.0513 0.0504 0.0498 0.0489 0.0486 

[TRAIN] Epoch[1](9016/114412); Loss: 0.062247; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1189 0.1000 0.0800 0.0740 0.0650 0.0609 0.0570 0.0544 0.0518 0.0501 0.0490 0.0481 0.0475 0.0468 0.0465 0.0460 

[TRAIN] Epoch[1](9017/114412); Loss: 0.081844; Backpropagation: 0.2931 sec; Batch: 2.0800 sec
0.1499 0.1396 0.1013 0.0914 0.0832 0.0775 0.0727 0.0721 0.0686 0.0669 0.0662 0.0651 0.0644 0.0641 0.0635 0.0632 

[TRAIN] Epoch[1](9018/114412); Loss: 0.090388; Backpropagation: 0.2912 sec; Batch: 2.1145 sec
0.1366 0.1164 0.1019 0.0982 0.0937 0.0904 0.0866 0.0838 0.0824 0.0816 0.0804 0.0797 0.0792 0.0788 0.0783 0.0781 

[TRAIN] Epoch[1](9019/114412); Loss: 0.067033; Backpropagation: 0.2923 sec; Batch: 2.1144 sec
0.1456 0.1388 0.0878 0.0759 0.0678 0.0620 0.0569 0.0546 0.0519 0.0504 0.0489 0.0479 0.0470 0.0463 0.0457 0.0452 

[TRAIN] Epoch[1](9020/114412); Loss: 0.091801; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1606 0.1366 0.1123 0.1034 0.0955 0.0891 0.0853 0.0817 0.0790 0.0772 0.0763 0.0754 0.0746 0.0744 0.0739 0.0734 

[TRAIN] Epoch[1](9021/114412); Loss: 0.086824; Backpropagation: 0.2914 sec; Batch: 2.1009 sec
0.1332 0.1222 0.1030 0.0955 0.0898 0.0853 0.0821 0.0796 0.0781 0.0768 0.0757 0.0748 0.0741 0.0735 0.0730 0.0726 

[TRAIN] Epoch[1](9022/114412); Loss: 0.078323; Backpropagation: 0.2931 sec; Batch: 2.0796 sec
0.1556 0.1349 0.0942 0.0828 0.0796 0.0734 0.0700 0.0682 0.0656 0.0638 0.0628 0.0618 0.0609 0.0603 0.0599 0.0595 

[TRAIN] Epoch[1](9023/114412); Loss: 0.065706; Backpropagation: 0.2933 sec; Batch: 2.1224 sec
0.1303 0.1062 0.0855 0.0746 0.0686 0.0631 0.0601 0.0563 0.0544 0.0529 0.0515 0.0505 0.0500 0.0494 0.0490 0.0488 

[TRAIN] Epoch[1](9024/114412); Loss: 0.070506; Backpropagation: 0.2928 sec; Batch: 2.1157 sec
0.1242 0.1142 0.0904 0.0824 0.0733 0.0672 0.0637 0.0620 0.0598 0.0582 0.0572 0.0563 0.0555 0.0550 0.0545 0.0541 

[TRAIN] Epoch[1](9025/114412); Loss: 0.078462; Backpropagation: 0.2929 sec; Batch: 2.1231 sec
0.2062 0.1563 0.1101 0.0942 0.0813 0.0651 0.0618 0.0579 0.0553 0.0543 0.0537 0.0532 0.0522 0.0517 0.0514 0.0508 

[TRAIN] Epoch[1](9026/114412); Loss: 0.085399; Backpropagation: 0.2955 sec; Batch: 2.1197 sec
0.1544 0.1353 0.1142 0.0999 0.0877 0.0831 0.0792 0.0767 0.0742 0.0702 0.0689 0.0668 0.0652 0.0642 0.0636 0.0629 

[TRAIN] Epoch[1](9027/114412); Loss: 0.094639; Backpropagation: 0.2903 sec; Batch: 2.1148 sec
0.1787 0.1667 0.1305 0.1189 0.1009 0.0888 0.0834 0.0813 0.0757 0.0737 0.0722 0.0708 0.0694 0.0684 0.0677 0.0670 

[TRAIN] Epoch[1](9028/114412); Loss: 0.069336; Backpropagation: 0.2912 sec; Batch: 2.1761 sec
0.1099 0.0981 0.0851 0.0807 0.0726 0.0677 0.0657 0.0627 0.0611 0.0598 0.0590 0.0581 0.0578 0.0573 0.0570 0.0567 

[TRAIN] Epoch[1](9029/114412); Loss: 0.071668; Backpropagation: 0.2910 sec; Batch: 2.1187 sec
0.1247 0.1111 0.0895 0.0799 0.0738 0.0701 0.0663 0.0641 0.0623 0.0607 0.0591 0.0585 0.0577 0.0570 0.0562 0.0558 

[TRAIN] Epoch[1](9030/114412); Loss: 0.049751; Backpropagation: 0.2910 sec; Batch: 2.1133 sec
0.1367 0.1175 0.0624 0.0571 0.0434 0.0399 0.0379 0.0359 0.0349 0.0341 0.0335 0.0331 0.0328 0.0325 0.0322 0.0321 

[TRAIN] Epoch[1](9031/114412); Loss: 0.092949; Backpropagation: 0.2915 sec; Batch: 2.0766 sec
0.1644 0.1554 0.1202 0.1075 0.0995 0.0918 0.0866 0.0822 0.0781 0.0756 0.0741 0.0721 0.0711 0.0704 0.0694 0.0689 

[TRAIN] Epoch[1](9032/114412); Loss: 0.081946; Backpropagation: 0.2895 sec; Batch: 2.1117 sec
0.1559 0.1443 0.1069 0.0890 0.0798 0.0733 0.0718 0.0702 0.0687 0.0666 0.0654 0.0650 0.0641 0.0637 0.0635 0.0630 

[TRAIN] Epoch[1](9033/114412); Loss: 0.102741; Backpropagation: 0.2907 sec; Batch: 2.1151 sec
0.1882 0.1612 0.1362 0.1206 0.1109 0.1012 0.0947 0.0908 0.0873 0.0850 0.0821 0.0810 0.0780 0.0768 0.0757 0.0741 

[TRAIN] Epoch[1](9034/114412); Loss: 0.071062; Backpropagation: 0.2901 sec; Batch: 2.1132 sec
0.1459 0.1236 0.0889 0.0790 0.0735 0.0684 0.0634 0.0611 0.0587 0.0568 0.0552 0.0540 0.0532 0.0523 0.0517 0.0512 

[TRAIN] Epoch[1](9035/114412); Loss: 0.105876; Backpropagation: 0.2906 sec; Batch: 2.1188 sec
0.1656 0.1470 0.1237 0.1149 0.1087 0.1035 0.1004 0.0981 0.0959 0.0939 0.0927 0.0914 0.0906 0.0899 0.0890 0.0886 

[TRAIN] Epoch[1](9036/114412); Loss: 0.071589; Backpropagation: 0.2905 sec; Batch: 2.1141 sec
0.1271 0.1175 0.0881 0.0773 0.0709 0.0670 0.0643 0.0632 0.0617 0.0602 0.0594 0.0587 0.0580 0.0577 0.0574 0.0571 

[TRAIN] Epoch[1](9037/114412); Loss: 0.069434; Backpropagation: 0.2910 sec; Batch: 2.1224 sec
0.1401 0.1310 0.0937 0.0833 0.0676 0.0650 0.0595 0.0575 0.0551 0.0534 0.0525 0.0517 0.0508 0.0503 0.0499 0.0494 

[TRAIN] Epoch[1](9038/114412); Loss: 0.095871; Backpropagation: 0.2912 sec; Batch: 2.1246 sec
0.1480 0.1263 0.1143 0.1025 0.0950 0.0932 0.0913 0.0896 0.0878 0.0861 0.0850 0.0842 0.0834 0.0829 0.0824 0.0821 

[TRAIN] Epoch[1](9039/114412); Loss: 0.072385; Backpropagation: 0.2911 sec; Batch: 2.1164 sec
0.1353 0.1287 0.0936 0.0837 0.0730 0.0687 0.0644 0.0622 0.0600 0.0583 0.0569 0.0561 0.0553 0.0545 0.0540 0.0537 

[TRAIN] Epoch[1](9040/114412); Loss: 0.061930; Backpropagation: 0.2909 sec; Batch: 2.1154 sec
0.1008 0.0916 0.0841 0.0723 0.0628 0.0605 0.0567 0.0547 0.0534 0.0523 0.0516 0.0509 0.0503 0.0500 0.0496 0.0493 

[TRAIN] Epoch[1](9041/114412); Loss: 0.090625; Backpropagation: 0.2929 sec; Batch: 2.1314 sec
0.1591 0.1471 0.1098 0.0991 0.0898 0.0864 0.0828 0.0803 0.0781 0.0769 0.0755 0.0743 0.0736 0.0728 0.0723 0.0720 

[TRAIN] Epoch[1](9042/114412); Loss: 0.063481; Backpropagation: 0.2923 sec; Batch: 2.1132 sec
0.1226 0.1064 0.0851 0.0797 0.0682 0.0611 0.0558 0.0529 0.0514 0.0501 0.0489 0.0480 0.0473 0.0466 0.0460 0.0456 

[TRAIN] Epoch[1](9043/114412); Loss: 0.096872; Backpropagation: 0.2914 sec; Batch: 2.1122 sec
0.1586 0.1459 0.1223 0.1115 0.0976 0.0937 0.0888 0.0865 0.0847 0.0828 0.0814 0.0805 0.0797 0.0791 0.0786 0.0781 

[TRAIN] Epoch[1](9044/114412); Loss: 0.092819; Backpropagation: 0.2932 sec; Batch: 2.1156 sec
0.1566 0.1343 0.1081 0.1043 0.0945 0.0894 0.0864 0.0839 0.0818 0.0804 0.0791 0.0784 0.0777 0.0772 0.0767 0.0764 

[TRAIN] Epoch[1](9045/114412); Loss: 0.062692; Backpropagation: 0.2914 sec; Batch: 2.1164 sec
0.1232 0.1006 0.0783 0.0680 0.0608 0.0578 0.0560 0.0543 0.0529 0.0516 0.0510 0.0504 0.0499 0.0497 0.0494 0.0492 

[TRAIN] Epoch[1](9046/114412); Loss: 0.067319; Backpropagation: 0.2955 sec; Batch: 2.1203 sec
0.1181 0.1103 0.0801 0.0718 0.0674 0.0646 0.0609 0.0594 0.0577 0.0568 0.0559 0.0555 0.0551 0.0547 0.0544 0.0543 

[TRAIN] Epoch[1](9047/114412); Loss: 0.091236; Backpropagation: 0.2934 sec; Batch: 2.1212 sec
0.1343 0.1211 0.1114 0.1019 0.0939 0.0880 0.0861 0.0847 0.0824 0.0815 0.0804 0.0797 0.0793 0.0788 0.0784 0.0780 

[TRAIN] Epoch[1](9048/114412); Loss: 0.070730; Backpropagation: 0.2908 sec; Batch: 2.0762 sec
0.1296 0.1158 0.0884 0.0833 0.0724 0.0679 0.0639 0.0616 0.0596 0.0581 0.0570 0.0560 0.0553 0.0547 0.0542 0.0538 

[TRAIN] Epoch[1](9049/114412); Loss: 0.075074; Backpropagation: 0.2911 sec; Batch: 2.1366 sec
0.1360 0.1227 0.0914 0.0825 0.0764 0.0716 0.0687 0.0665 0.0642 0.0627 0.0614 0.0606 0.0599 0.0593 0.0588 0.0583 

[TRAIN] Epoch[1](9050/114412); Loss: 0.074189; Backpropagation: 0.2913 sec; Batch: 2.0766 sec
0.1408 0.1297 0.0955 0.0803 0.0767 0.0703 0.0670 0.0642 0.0613 0.0599 0.0587 0.0579 0.0569 0.0563 0.0560 0.0557 

[TRAIN] Epoch[1](9051/114412); Loss: 0.096408; Backpropagation: 0.2911 sec; Batch: 2.1110 sec
0.1812 0.1580 0.1235 0.1063 0.0973 0.0918 0.0885 0.0832 0.0813 0.0791 0.0773 0.0767 0.0757 0.0749 0.0742 0.0736 

[TRAIN] Epoch[1](9052/114412); Loss: 0.092255; Backpropagation: 0.2912 sec; Batch: 2.0776 sec
0.1513 0.1345 0.1121 0.1028 0.0951 0.0896 0.0865 0.0835 0.0816 0.0800 0.0785 0.0775 0.0768 0.0760 0.0754 0.0748 

[TRAIN] Epoch[1](9053/114412); Loss: 0.067913; Backpropagation: 0.2930 sec; Batch: 2.1003 sec
0.1359 0.1250 0.0890 0.0802 0.0651 0.0612 0.0591 0.0568 0.0546 0.0533 0.0522 0.0517 0.0512 0.0506 0.0504 0.0502 

[TRAIN] Epoch[1](9054/114412); Loss: 0.085873; Backpropagation: 0.2914 sec; Batch: 2.1161 sec
0.1645 0.1452 0.1034 0.0863 0.0824 0.0792 0.0760 0.0742 0.0727 0.0723 0.0712 0.0703 0.0698 0.0693 0.0688 0.0685 

[TRAIN] Epoch[1](9055/114412); Loss: 0.062515; Backpropagation: 0.2904 sec; Batch: 2.1202 sec
0.1155 0.0994 0.0872 0.0761 0.0709 0.0621 0.0576 0.0536 0.0509 0.0489 0.0480 0.0470 0.0464 0.0460 0.0455 0.0451 

[TRAIN] Epoch[1](9056/114412); Loss: 0.102858; Backpropagation: 0.2908 sec; Batch: 2.1172 sec
0.1512 0.1388 0.1191 0.1109 0.1066 0.1015 0.0986 0.0966 0.0939 0.0925 0.0915 0.0904 0.0896 0.0888 0.0882 0.0876 

[TRAIN] Epoch[1](9057/114412); Loss: 0.066859; Backpropagation: 0.2906 sec; Batch: 2.0773 sec
0.1186 0.0912 0.0768 0.0754 0.0692 0.0681 0.0637 0.0607 0.0588 0.0575 0.0565 0.0558 0.0549 0.0546 0.0540 0.0539 

[TRAIN] Epoch[1](9058/114412); Loss: 0.081811; Backpropagation: 0.2934 sec; Batch: 2.0785 sec
0.1504 0.1367 0.0995 0.0868 0.0832 0.0810 0.0751 0.0739 0.0714 0.0687 0.0674 0.0649 0.0641 0.0631 0.0617 0.0611 

[TRAIN] Epoch[1](9059/114412); Loss: 0.069131; Backpropagation: 0.2908 sec; Batch: 2.1138 sec
0.1353 0.1148 0.0869 0.0784 0.0717 0.0673 0.0623 0.0598 0.0574 0.0562 0.0546 0.0538 0.0528 0.0521 0.0515 0.0512 

[TRAIN] Epoch[1](9060/114412); Loss: 0.091520; Backpropagation: 0.2909 sec; Batch: 2.1130 sec
0.1519 0.1408 0.1115 0.1001 0.0923 0.0877 0.0846 0.0826 0.0806 0.0788 0.0775 0.0765 0.0757 0.0752 0.0747 0.0740 

[TRAIN] Epoch[1](9061/114412); Loss: 0.076112; Backpropagation: 0.2907 sec; Batch: 2.1135 sec
0.1495 0.1370 0.1019 0.0872 0.0752 0.0698 0.0664 0.0647 0.0625 0.0608 0.0593 0.0583 0.0574 0.0566 0.0559 0.0554 

[TRAIN] Epoch[1](9062/114412); Loss: 0.065376; Backpropagation: 0.2907 sec; Batch: 2.1168 sec
0.1443 0.1225 0.0851 0.0748 0.0663 0.0597 0.0576 0.0532 0.0501 0.0493 0.0484 0.0475 0.0474 0.0468 0.0465 0.0464 

[TRAIN] Epoch[1](9063/114412); Loss: 0.070418; Backpropagation: 0.2911 sec; Batch: 2.1239 sec
0.1464 0.1179 0.0883 0.0766 0.0708 0.0654 0.0614 0.0593 0.0577 0.0567 0.0557 0.0550 0.0544 0.0539 0.0537 0.0535 

[TRAIN] Epoch[1](9064/114412); Loss: 0.088758; Backpropagation: 0.2914 sec; Batch: 2.0769 sec
0.1280 0.1251 0.1097 0.0992 0.0913 0.0870 0.0841 0.0832 0.0802 0.0789 0.0781 0.0763 0.0757 0.0752 0.0743 0.0739 

[TRAIN] Epoch[1](9065/114412); Loss: 0.061425; Backpropagation: 0.2913 sec; Batch: 2.1131 sec
0.1167 0.0922 0.0741 0.0703 0.0633 0.0597 0.0569 0.0540 0.0523 0.0512 0.0499 0.0493 0.0488 0.0483 0.0481 0.0478 

[TRAIN] Epoch[1](9066/114412); Loss: 0.091577; Backpropagation: 0.2952 sec; Batch: 2.1182 sec
0.1806 0.1642 0.1256 0.1069 0.0942 0.0862 0.0797 0.0772 0.0730 0.0714 0.0698 0.0684 0.0678 0.0672 0.0667 0.0663 

[TRAIN] Epoch[1](9067/114412); Loss: 0.087054; Backpropagation: 0.2930 sec; Batch: 2.1183 sec
0.1333 0.1292 0.0975 0.0914 0.0879 0.0840 0.0819 0.0804 0.0785 0.0773 0.0766 0.0756 0.0753 0.0749 0.0745 0.0743 

[TRAIN] Epoch[1](9068/114412); Loss: 0.069728; Backpropagation: 0.2908 sec; Batch: 2.1264 sec
0.1391 0.1194 0.0917 0.0764 0.0728 0.0657 0.0615 0.0594 0.0572 0.0558 0.0541 0.0536 0.0530 0.0523 0.0520 0.0517 

[TRAIN] Epoch[1](9069/114412); Loss: 0.074611; Backpropagation: 0.2905 sec; Batch: 2.1056 sec
0.1328 0.1215 0.0952 0.0863 0.0767 0.0722 0.0676 0.0651 0.0633 0.0611 0.0603 0.0594 0.0587 0.0582 0.0578 0.0575 

[TRAIN] Epoch[1](9070/114412); Loss: 0.070908; Backpropagation: 0.2905 sec; Batch: 2.0771 sec
0.1417 0.1139 0.0915 0.0795 0.0721 0.0657 0.0643 0.0612 0.0592 0.0575 0.0565 0.0555 0.0547 0.0542 0.0537 0.0533 

[TRAIN] Epoch[1](9071/114412); Loss: 0.107488; Backpropagation: 0.2927 sec; Batch: 2.1185 sec
0.1723 0.1543 0.1275 0.1199 0.1120 0.1058 0.1019 0.0984 0.0955 0.0939 0.0923 0.0909 0.0898 0.0891 0.0884 0.0878 

[TRAIN] Epoch[1](9072/114412); Loss: 0.090745; Backpropagation: 0.2929 sec; Batch: 2.1146 sec
0.1859 0.1558 0.1295 0.1035 0.0924 0.0830 0.0786 0.0759 0.0726 0.0709 0.0695 0.0683 0.0674 0.0668 0.0662 0.0655 

[TRAIN] Epoch[1](9073/114412); Loss: 0.086643; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1323 0.1260 0.1032 0.0963 0.0907 0.0860 0.0826 0.0802 0.0779 0.0762 0.0750 0.0734 0.0726 0.0720 0.0712 0.0707 

[TRAIN] Epoch[1](9074/114412); Loss: 0.081704; Backpropagation: 0.2911 sec; Batch: 2.1185 sec
0.1720 0.1340 0.1077 0.0901 0.0839 0.0749 0.0721 0.0699 0.0675 0.0660 0.0641 0.0628 0.0618 0.0608 0.0602 0.0595 

[TRAIN] Epoch[1](9075/114412); Loss: 0.090376; Backpropagation: 0.2913 sec; Batch: 2.0764 sec
0.1536 0.1327 0.1111 0.1025 0.0932 0.0878 0.0843 0.0817 0.0797 0.0778 0.0762 0.0748 0.0741 0.0730 0.0722 0.0715 

[TRAIN] Epoch[1](9076/114412); Loss: 0.086531; Backpropagation: 0.2932 sec; Batch: 2.1163 sec
0.1528 0.1441 0.1075 0.0974 0.0834 0.0790 0.0773 0.0760 0.0739 0.0726 0.0715 0.0706 0.0701 0.0696 0.0693 0.0693 

[TRAIN] Epoch[1](9077/114412); Loss: 0.078622; Backpropagation: 0.2930 sec; Batch: 2.1213 sec
0.1691 0.1570 0.1075 0.0892 0.0743 0.0684 0.0636 0.0639 0.0615 0.0599 0.0590 0.0580 0.0573 0.0569 0.0563 0.0560 

[TRAIN] Epoch[1](9078/114412); Loss: 0.069639; Backpropagation: 0.2908 sec; Batch: 2.1123 sec
0.1366 0.1118 0.0835 0.0800 0.0717 0.0653 0.0625 0.0604 0.0586 0.0571 0.0561 0.0552 0.0546 0.0539 0.0535 0.0534 

[TRAIN] Epoch[1](9079/114412); Loss: 0.068788; Backpropagation: 0.2917 sec; Batch: 2.1143 sec
0.1494 0.1243 0.0850 0.0751 0.0686 0.0602 0.0597 0.0566 0.0551 0.0541 0.0535 0.0526 0.0523 0.0518 0.0514 0.0512 

[TRAIN] Epoch[1](9080/114412); Loss: 0.074219; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1581 0.1381 0.1044 0.0853 0.0731 0.0665 0.0617 0.0602 0.0580 0.0568 0.0556 0.0551 0.0543 0.0538 0.0534 0.0531 

[TRAIN] Epoch[1](9081/114412); Loss: 0.088560; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1623 0.1387 0.1140 0.1005 0.0892 0.0842 0.0807 0.0778 0.0757 0.0737 0.0721 0.0711 0.0702 0.0695 0.0689 0.0685 

[TRAIN] Epoch[1](9082/114412); Loss: 0.088448; Backpropagation: 0.2913 sec; Batch: 2.0778 sec
0.1717 0.1608 0.1250 0.1106 0.0989 0.0880 0.0778 0.0730 0.0687 0.0666 0.0651 0.0638 0.0624 0.0615 0.0610 0.0602 

[TRAIN] Epoch[1](9083/114412); Loss: 0.097167; Backpropagation: 0.2912 sec; Batch: 2.1222 sec
0.1516 0.1377 0.1144 0.1039 0.0972 0.0937 0.0906 0.0890 0.0876 0.0865 0.0854 0.0846 0.0840 0.0832 0.0828 0.0824 

[TRAIN] Epoch[1](9084/114412); Loss: 0.072290; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1351 0.1048 0.0829 0.0802 0.0734 0.0685 0.0667 0.0641 0.0623 0.0613 0.0605 0.0599 0.0596 0.0592 0.0591 0.0592 

[TRAIN] Epoch[1](9085/114412); Loss: 0.079737; Backpropagation: 0.2932 sec; Batch: 2.1184 sec
0.1391 0.1161 0.0940 0.0854 0.0810 0.0767 0.0752 0.0727 0.0704 0.0692 0.0682 0.0671 0.0660 0.0653 0.0649 0.0646 

[TRAIN] Epoch[1](9086/114412); Loss: 0.055878; Backpropagation: 0.2915 sec; Batch: 2.1142 sec
0.1227 0.0894 0.0724 0.0655 0.0550 0.0512 0.0485 0.0464 0.0452 0.0441 0.0431 0.0427 0.0424 0.0421 0.0418 0.0416 

[TRAIN] Epoch[1](9087/114412); Loss: 0.067327; Backpropagation: 0.2913 sec; Batch: 2.1257 sec
0.1346 0.1068 0.0878 0.0758 0.0676 0.0626 0.0597 0.0576 0.0558 0.0550 0.0538 0.0531 0.0524 0.0519 0.0515 0.0511 

[TRAIN] Epoch[1](9088/114412); Loss: 0.089901; Backpropagation: 0.2912 sec; Batch: 2.1123 sec
0.1612 0.1454 0.1164 0.1002 0.0915 0.0858 0.0810 0.0774 0.0760 0.0741 0.0731 0.0721 0.0716 0.0713 0.0709 0.0706 

[TRAIN] Epoch[1](9089/114412); Loss: 0.067289; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1215 0.1084 0.0851 0.0751 0.0673 0.0642 0.0607 0.0587 0.0569 0.0556 0.0551 0.0543 0.0538 0.0536 0.0533 0.0530 

[TRAIN] Epoch[1](9090/114412); Loss: 0.070887; Backpropagation: 0.2912 sec; Batch: 2.1171 sec
0.1458 0.1373 0.1017 0.0805 0.0743 0.0671 0.0605 0.0589 0.0557 0.0533 0.0523 0.0510 0.0497 0.0495 0.0487 0.0479 

[TRAIN] Epoch[1](9091/114412); Loss: 0.070596; Backpropagation: 0.2916 sec; Batch: 2.1143 sec
0.1309 0.1217 0.0896 0.0812 0.0715 0.0663 0.0631 0.0610 0.0589 0.0574 0.0563 0.0553 0.0547 0.0542 0.0538 0.0536 

[TRAIN] Epoch[1](9092/114412); Loss: 0.081516; Backpropagation: 0.2908 sec; Batch: 2.1126 sec
0.1860 0.1752 0.1259 0.1062 0.0838 0.0705 0.0652 0.0624 0.0590 0.0560 0.0550 0.0537 0.0526 0.0516 0.0509 0.0503 

[TRAIN] Epoch[1](9093/114412); Loss: 0.082832; Backpropagation: 0.2930 sec; Batch: 2.1154 sec
0.1932 0.1698 0.1268 0.1008 0.0793 0.0697 0.0674 0.0650 0.0628 0.0591 0.0574 0.0564 0.0553 0.0546 0.0542 0.0535 

[TRAIN] Epoch[1](9094/114412); Loss: 0.073838; Backpropagation: 0.2911 sec; Batch: 2.1123 sec
0.1579 0.1442 0.0969 0.0779 0.0718 0.0664 0.0647 0.0612 0.0585 0.0570 0.0560 0.0550 0.0543 0.0537 0.0531 0.0528 

[TRAIN] Epoch[1](9095/114412); Loss: 0.083055; Backpropagation: 0.2906 sec; Batch: 2.1129 sec
0.1322 0.1198 0.1011 0.0920 0.0854 0.0813 0.0786 0.0757 0.0736 0.0722 0.0711 0.0702 0.0697 0.0692 0.0686 0.0682 

[TRAIN] Epoch[1](9096/114412); Loss: 0.055258; Backpropagation: 0.2906 sec; Batch: 2.1106 sec
0.1207 0.1142 0.0711 0.0607 0.0551 0.0500 0.0471 0.0449 0.0429 0.0415 0.0409 0.0401 0.0394 0.0388 0.0385 0.0383 

[TRAIN] Epoch[1](9097/114412); Loss: 0.082425; Backpropagation: 0.2914 sec; Batch: 2.1142 sec
0.1770 0.1493 0.1049 0.0920 0.0799 0.0742 0.0711 0.0680 0.0662 0.0645 0.0636 0.0629 0.0621 0.0614 0.0609 0.0607 

[TRAIN] Epoch[1](9098/114412); Loss: 0.077037; Backpropagation: 0.2916 sec; Batch: 2.1174 sec
0.1359 0.1236 0.0963 0.0879 0.0783 0.0738 0.0706 0.0674 0.0656 0.0642 0.0631 0.0623 0.0617 0.0611 0.0606 0.0602 

[TRAIN] Epoch[1](9099/114412); Loss: 0.065030; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1452 0.1258 0.0853 0.0807 0.0691 0.0589 0.0555 0.0522 0.0494 0.0483 0.0468 0.0460 0.0449 0.0445 0.0442 0.0437 

[TRAIN] Epoch[1](9100/114412); Loss: 0.093390; Backpropagation: 0.2911 sec; Batch: 2.1144 sec
0.1645 0.1499 0.1098 0.0969 0.0940 0.0886 0.0859 0.0824 0.0808 0.0796 0.0786 0.0777 0.0771 0.0766 0.0760 0.0758 

[TRAIN] Epoch[1](9101/114412); Loss: 0.071262; Backpropagation: 0.2912 sec; Batch: 2.1132 sec
0.1483 0.1385 0.0915 0.0769 0.0692 0.0647 0.0614 0.0584 0.0568 0.0554 0.0540 0.0539 0.0533 0.0526 0.0527 0.0525 

[TRAIN] Epoch[1](9102/114412); Loss: 0.074133; Backpropagation: 0.2915 sec; Batch: 2.1141 sec
0.1316 0.1228 0.0912 0.0809 0.0747 0.0706 0.0671 0.0646 0.0632 0.0617 0.0609 0.0604 0.0598 0.0592 0.0590 0.0587 

[TRAIN] Epoch[1](9103/114412); Loss: 0.089946; Backpropagation: 0.2913 sec; Batch: 2.1183 sec
0.1711 0.1470 0.1187 0.1051 0.0912 0.0848 0.0796 0.0766 0.0750 0.0729 0.0712 0.0706 0.0695 0.0688 0.0688 0.0682 

[TRAIN] Epoch[1](9104/114412); Loss: 0.059176; Backpropagation: 0.2910 sec; Batch: 2.0848 sec
0.1253 0.1134 0.0731 0.0654 0.0589 0.0547 0.0512 0.0490 0.0471 0.0462 0.0455 0.0444 0.0438 0.0434 0.0429 0.0425 

[TRAIN] Epoch[1](9105/114412); Loss: 0.082425; Backpropagation: 0.2908 sec; Batch: 2.0752 sec
0.1887 0.1456 0.1105 0.1007 0.0830 0.0732 0.0698 0.0668 0.0643 0.0623 0.0611 0.0599 0.0591 0.0585 0.0578 0.0575 

[TRAIN] Epoch[1](9106/114412); Loss: 0.122281; Backpropagation: 0.2910 sec; Batch: 2.1131 sec
0.1994 0.1836 0.1491 0.1369 0.1261 0.1181 0.1143 0.1100 0.1071 0.1050 0.1036 0.1025 0.1013 0.1004 0.0999 0.0992 

[TRAIN] Epoch[1](9107/114412); Loss: 0.095784; Backpropagation: 0.3380 sec; Batch: 2.2025 sec
0.1770 0.1522 0.1246 0.1023 0.0990 0.0896 0.0841 0.0831 0.0817 0.0795 0.0784 0.0774 0.0767 0.0761 0.0755 0.0751 

[TRAIN] Epoch[1](9108/114412); Loss: 0.085975; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1578 0.1423 0.1160 0.1010 0.0891 0.0829 0.0778 0.0743 0.0722 0.0692 0.0684 0.0670 0.0655 0.0647 0.0640 0.0635 

[TRAIN] Epoch[1](9109/114412); Loss: 0.084659; Backpropagation: 0.2915 sec; Batch: 2.1188 sec
0.1630 0.1373 0.1118 0.0958 0.0852 0.0830 0.0778 0.0736 0.0706 0.0689 0.0672 0.0656 0.0647 0.0640 0.0632 0.0628 

[TRAIN] Epoch[1](9110/114412); Loss: 0.067590; Backpropagation: 0.2929 sec; Batch: 2.1204 sec
0.1317 0.1099 0.0831 0.0803 0.0680 0.0651 0.0608 0.0583 0.0560 0.0547 0.0536 0.0530 0.0523 0.0520 0.0515 0.0513 

[TRAIN] Epoch[1](9111/114412); Loss: 0.069304; Backpropagation: 0.2955 sec; Batch: 2.1235 sec
0.1376 0.1283 0.0899 0.0782 0.0655 0.0616 0.0605 0.0587 0.0564 0.0555 0.0546 0.0537 0.0531 0.0521 0.0518 0.0512 

[TRAIN] Epoch[1](9112/114412); Loss: 0.070146; Backpropagation: 0.2924 sec; Batch: 2.2843 sec
0.1778 0.1668 0.1192 0.0895 0.0642 0.0554 0.0510 0.0498 0.0473 0.0456 0.0442 0.0432 0.0428 0.0422 0.0417 0.0415 

[TRAIN] Epoch[1](9113/114412); Loss: 0.065666; Backpropagation: 0.2939 sec; Batch: 2.0897 sec
0.1268 0.1155 0.0804 0.0703 0.0644 0.0617 0.0585 0.0565 0.0551 0.0536 0.0528 0.0519 0.0514 0.0509 0.0505 0.0503 

[TRAIN] Epoch[1](9114/114412); Loss: 0.105244; Backpropagation: 0.2937 sec; Batch: 2.0915 sec
0.1673 0.1545 0.1224 0.1119 0.1056 0.1014 0.0983 0.0960 0.0941 0.0926 0.0916 0.0908 0.0901 0.0895 0.0890 0.0886 

[TRAIN] Epoch[1](9115/114412); Loss: 0.072584; Backpropagation: 0.2992 sec; Batch: 2.1063 sec
0.1476 0.1407 0.1014 0.0832 0.0736 0.0655 0.0616 0.0594 0.0569 0.0557 0.0544 0.0533 0.0525 0.0522 0.0519 0.0516 

[TRAIN] Epoch[1](9116/114412); Loss: 0.092836; Backpropagation: 0.2968 sec; Batch: 2.1299 sec
0.1744 0.1546 0.1276 0.1060 0.0937 0.0858 0.0805 0.0798 0.0779 0.0755 0.0740 0.0729 0.0719 0.0708 0.0702 0.0698 

[TRAIN] Epoch[1](9117/114412); Loss: 0.081205; Backpropagation: 0.2931 sec; Batch: 2.1205 sec
0.1479 0.1305 0.1013 0.0895 0.0820 0.0774 0.0752 0.0722 0.0698 0.0679 0.0664 0.0653 0.0645 0.0637 0.0631 0.0626 

[TRAIN] Epoch[1](9118/114412); Loss: 0.072572; Backpropagation: 0.2939 sec; Batch: 2.1183 sec
0.1838 0.1555 0.0981 0.0782 0.0674 0.0621 0.0573 0.0541 0.0529 0.0520 0.0508 0.0504 0.0500 0.0496 0.0495 0.0493 

[TRAIN] Epoch[1](9119/114412); Loss: 0.081193; Backpropagation: 0.2930 sec; Batch: 2.1162 sec
0.1306 0.1250 0.0953 0.0892 0.0830 0.0792 0.0756 0.0736 0.0716 0.0702 0.0693 0.0686 0.0679 0.0672 0.0666 0.0661 

[TRAIN] Epoch[1](9120/114412); Loss: 0.081909; Backpropagation: 0.2936 sec; Batch: 2.1187 sec
0.1836 0.1707 0.1122 0.0939 0.0793 0.0740 0.0691 0.0651 0.0622 0.0603 0.0589 0.0577 0.0569 0.0562 0.0555 0.0551 

[TRAIN] Epoch[1](9121/114412); Loss: 0.084785; Backpropagation: 0.2918 sec; Batch: 2.1095 sec
0.1440 0.1296 0.1049 0.0940 0.0857 0.0812 0.0774 0.0756 0.0741 0.0723 0.0714 0.0703 0.0697 0.0692 0.0687 0.0684 

[TRAIN] Epoch[1](9122/114412); Loss: 0.095219; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.1470 0.1374 0.1168 0.1070 0.0966 0.0926 0.0891 0.0866 0.0848 0.0833 0.0823 0.0814 0.0806 0.0799 0.0794 0.0789 

[TRAIN] Epoch[1](9123/114412); Loss: 0.089187; Backpropagation: 0.2922 sec; Batch: 2.1315 sec
0.1528 0.1453 0.1113 0.1008 0.0891 0.0838 0.0793 0.0778 0.0766 0.0754 0.0742 0.0734 0.0725 0.0720 0.0716 0.0712 

[TRAIN] Epoch[1](9124/114412); Loss: 0.079812; Backpropagation: 0.2916 sec; Batch: 2.1159 sec
0.1840 0.1515 0.1078 0.0919 0.0767 0.0737 0.0651 0.0654 0.0622 0.0596 0.0581 0.0573 0.0566 0.0559 0.0557 0.0555 

[TRAIN] Epoch[1](9125/114412); Loss: 0.068903; Backpropagation: 0.2952 sec; Batch: 2.1341 sec
0.1228 0.1158 0.0891 0.0790 0.0700 0.0651 0.0613 0.0591 0.0578 0.0568 0.0559 0.0551 0.0543 0.0538 0.0535 0.0532 

[TRAIN] Epoch[1](9126/114412); Loss: 0.070825; Backpropagation: 0.2906 sec; Batch: 2.1228 sec
0.1422 0.1255 0.0947 0.0845 0.0753 0.0673 0.0627 0.0600 0.0573 0.0550 0.0537 0.0526 0.0517 0.0508 0.0503 0.0498 

[TRAIN] Epoch[1](9127/114412); Loss: 0.066453; Backpropagation: 0.2915 sec; Batch: 2.0793 sec
0.1279 0.1071 0.0832 0.0732 0.0667 0.0631 0.0598 0.0571 0.0557 0.0547 0.0537 0.0531 0.0524 0.0521 0.0519 0.0515 

[TRAIN] Epoch[1](9128/114412); Loss: 0.074898; Backpropagation: 0.2914 sec; Batch: 2.0989 sec
0.1201 0.1046 0.0823 0.0835 0.0756 0.0736 0.0714 0.0689 0.0676 0.0665 0.0655 0.0649 0.0641 0.0637 0.0633 0.0629 

[TRAIN] Epoch[1](9129/114412); Loss: 0.108495; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1610 0.1462 0.1263 0.1176 0.1123 0.1092 0.1044 0.1019 0.0996 0.0970 0.0959 0.0946 0.0935 0.0930 0.0920 0.0914 

[TRAIN] Epoch[1](9130/114412); Loss: 0.078748; Backpropagation: 0.2934 sec; Batch: 2.1194 sec
0.1489 0.1369 0.0947 0.0823 0.0766 0.0748 0.0716 0.0680 0.0662 0.0649 0.0638 0.0631 0.0626 0.0621 0.0618 0.0615 

[TRAIN] Epoch[1](9131/114412); Loss: 0.093604; Backpropagation: 0.2915 sec; Batch: 2.1211 sec
0.1408 0.1253 0.1134 0.1042 0.0947 0.0931 0.0886 0.0863 0.0848 0.0830 0.0819 0.0812 0.0808 0.0802 0.0799 0.0795 

[TRAIN] Epoch[1](9132/114412); Loss: 0.060065; Backpropagation: 0.2919 sec; Batch: 2.1241 sec
0.1471 0.1184 0.0779 0.0656 0.0586 0.0566 0.0511 0.0484 0.0459 0.0442 0.0433 0.0422 0.0414 0.0405 0.0402 0.0397 

[TRAIN] Epoch[1](9133/114412); Loss: 0.079926; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1301 0.1185 0.0997 0.0935 0.0857 0.0802 0.0760 0.0730 0.0705 0.0675 0.0664 0.0649 0.0641 0.0633 0.0629 0.0625 

[TRAIN] Epoch[1](9134/114412); Loss: 0.103611; Backpropagation: 0.2909 sec; Batch: 2.1379 sec
0.1642 0.1511 0.1244 0.1145 0.1064 0.1001 0.0967 0.0935 0.0911 0.0902 0.0892 0.0884 0.0878 0.0873 0.0868 0.0861 

[TRAIN] Epoch[1](9135/114412); Loss: 0.072670; Backpropagation: 0.2910 sec; Batch: 2.0986 sec
0.1358 0.1117 0.0842 0.0885 0.0746 0.0673 0.0647 0.0630 0.0610 0.0607 0.0594 0.0591 0.0587 0.0581 0.0580 0.0578 

[TRAIN] Epoch[1](9136/114412); Loss: 0.076813; Backpropagation: 0.2909 sec; Batch: 2.1195 sec
0.1683 0.1341 0.0979 0.0849 0.0754 0.0696 0.0666 0.0649 0.0630 0.0606 0.0592 0.0582 0.0573 0.0568 0.0564 0.0559 

[TRAIN] Epoch[1](9137/114412); Loss: 0.065430; Backpropagation: 0.2916 sec; Batch: 2.0799 sec
0.1672 0.1271 0.0813 0.0753 0.0656 0.0577 0.0564 0.0525 0.0501 0.0475 0.0465 0.0452 0.0443 0.0438 0.0432 0.0430 

[TRAIN] Epoch[1](9138/114412); Loss: 0.077383; Backpropagation: 0.2954 sec; Batch: 2.1358 sec
0.1337 0.1194 0.0985 0.0876 0.0799 0.0747 0.0705 0.0682 0.0663 0.0649 0.0641 0.0630 0.0625 0.0620 0.0616 0.0613 

[TRAIN] Epoch[1](9139/114412); Loss: 0.065349; Backpropagation: 0.2903 sec; Batch: 2.1234 sec
0.1103 0.1072 0.0758 0.0713 0.0672 0.0663 0.0620 0.0586 0.0566 0.0551 0.0541 0.0534 0.0526 0.0520 0.0515 0.0513 

[TRAIN] Epoch[1](9140/114412); Loss: 0.072341; Backpropagation: 0.2928 sec; Batch: 2.1162 sec
0.1154 0.1058 0.0872 0.0791 0.0733 0.0698 0.0669 0.0653 0.0638 0.0627 0.0622 0.0617 0.0613 0.0611 0.0609 0.0608 

[TRAIN] Epoch[1](9141/114412); Loss: 0.085849; Backpropagation: 0.2930 sec; Batch: 2.1016 sec
0.1552 0.1323 0.1057 0.0910 0.0893 0.0810 0.0799 0.0767 0.0745 0.0728 0.0713 0.0702 0.0692 0.0686 0.0680 0.0676 

[TRAIN] Epoch[1](9142/114412); Loss: 0.065750; Backpropagation: 0.2951 sec; Batch: 2.1230 sec
0.1632 0.1246 0.0921 0.0775 0.0680 0.0603 0.0542 0.0521 0.0494 0.0472 0.0460 0.0447 0.0440 0.0434 0.0428 0.0424 

[TRAIN] Epoch[1](9143/114412); Loss: 0.067831; Backpropagation: 0.2930 sec; Batch: 2.0800 sec
0.1293 0.1083 0.0886 0.0807 0.0729 0.0666 0.0615 0.0583 0.0566 0.0547 0.0533 0.0526 0.0514 0.0506 0.0502 0.0496 

[TRAIN] Epoch[1](9144/114412); Loss: 0.118510; Backpropagation: 0.2915 sec; Batch: 2.0797 sec
0.2083 0.1814 0.1470 0.1263 0.1159 0.1108 0.1076 0.1060 0.1028 0.1012 0.1000 0.0992 0.0983 0.0976 0.0969 0.0967 

[TRAIN] Epoch[1](9145/114412); Loss: 0.068798; Backpropagation: 0.2923 sec; Batch: 2.1189 sec
0.1579 0.1451 0.0893 0.0760 0.0701 0.0641 0.0584 0.0545 0.0522 0.0495 0.0488 0.0480 0.0472 0.0470 0.0466 0.0462 

[TRAIN] Epoch[1](9146/114412); Loss: 0.095155; Backpropagation: 0.2929 sec; Batch: 2.1180 sec
0.2260 0.2034 0.1421 0.1050 0.0834 0.0788 0.0755 0.0739 0.0701 0.0688 0.0677 0.0668 0.0658 0.0653 0.0651 0.0648 

[TRAIN] Epoch[1](9147/114412); Loss: 0.096146; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1667 0.1446 0.1162 0.1068 0.0975 0.0922 0.0927 0.0901 0.0862 0.0835 0.0810 0.0785 0.0772 0.0763 0.0749 0.0740 

[TRAIN] Epoch[1](9148/114412); Loss: 0.097945; Backpropagation: 0.2910 sec; Batch: 2.1154 sec
0.1837 0.1565 0.1209 0.1054 0.0946 0.0925 0.0879 0.0851 0.0830 0.0819 0.0810 0.0802 0.0795 0.0788 0.0783 0.0779 

[TRAIN] Epoch[1](9149/114412); Loss: 0.080016; Backpropagation: 0.2915 sec; Batch: 2.0969 sec
0.1234 0.1107 0.0972 0.0888 0.0840 0.0792 0.0758 0.0734 0.0719 0.0705 0.0694 0.0687 0.0678 0.0671 0.0665 0.0660 

[TRAIN] Epoch[1](9150/114412); Loss: 0.077552; Backpropagation: 0.2917 sec; Batch: 2.1441 sec
0.1491 0.1285 0.0968 0.0859 0.0792 0.0743 0.0700 0.0676 0.0653 0.0631 0.0622 0.0611 0.0603 0.0598 0.0591 0.0587 

[TRAIN] Epoch[1](9151/114412); Loss: 0.076907; Backpropagation: 0.2955 sec; Batch: 2.1218 sec
0.1385 0.1233 0.0959 0.0870 0.0793 0.0744 0.0711 0.0682 0.0654 0.0638 0.0627 0.0617 0.0608 0.0600 0.0594 0.0591 

[TRAIN] Epoch[1](9152/114412); Loss: 0.071014; Backpropagation: 0.2971 sec; Batch: 2.0841 sec
0.1284 0.1100 0.0865 0.0794 0.0740 0.0689 0.0663 0.0638 0.0613 0.0596 0.0581 0.0570 0.0565 0.0559 0.0554 0.0552 

[TRAIN] Epoch[1](9153/114412); Loss: 0.066883; Backpropagation: 0.2931 sec; Batch: 2.1333 sec
0.1192 0.1099 0.0812 0.0763 0.0691 0.0626 0.0599 0.0582 0.0564 0.0556 0.0548 0.0540 0.0537 0.0533 0.0530 0.0528 

[TRAIN] Epoch[1](9154/114412); Loss: 0.085427; Backpropagation: 0.2953 sec; Batch: 2.0813 sec
0.1409 0.1302 0.1056 0.0968 0.0887 0.0826 0.0793 0.0758 0.0741 0.0731 0.0718 0.0707 0.0699 0.0695 0.0691 0.0688 

[TRAIN] Epoch[1](9155/114412); Loss: 0.084292; Backpropagation: 0.2933 sec; Batch: 2.1174 sec
0.1450 0.1283 0.1071 0.0952 0.0941 0.0852 0.0781 0.0738 0.0715 0.0698 0.0685 0.0673 0.0669 0.0665 0.0659 0.0656 

[TRAIN] Epoch[1](9156/114412); Loss: 0.067527; Backpropagation: 0.2954 sec; Batch: 2.1194 sec
0.1245 0.1205 0.0831 0.0744 0.0668 0.0647 0.0601 0.0581 0.0562 0.0551 0.0543 0.0536 0.0530 0.0525 0.0519 0.0516 

[TRAIN] Epoch[1](9157/114412); Loss: 0.059042; Backpropagation: 0.2954 sec; Batch: 2.1018 sec
0.1196 0.1105 0.0744 0.0642 0.0571 0.0573 0.0522 0.0492 0.0480 0.0466 0.0455 0.0451 0.0444 0.0439 0.0435 0.0431 

[TRAIN] Epoch[1](9158/114412); Loss: 0.064136; Backpropagation: 0.2930 sec; Batch: 2.1144 sec
0.1254 0.1196 0.0787 0.0702 0.0626 0.0591 0.0560 0.0543 0.0526 0.0512 0.0503 0.0499 0.0494 0.0491 0.0489 0.0488 

[TRAIN] Epoch[1](9159/114412); Loss: 0.072871; Backpropagation: 0.2957 sec; Batch: 2.1255 sec
0.1258 0.1087 0.0888 0.0774 0.0731 0.0695 0.0673 0.0652 0.0636 0.0626 0.0618 0.0612 0.0606 0.0604 0.0600 0.0599 

[TRAIN] Epoch[1](9160/114412); Loss: 0.099841; Backpropagation: 0.2930 sec; Batch: 2.1229 sec
0.1647 0.1475 0.1263 0.1130 0.1022 0.0956 0.0919 0.0899 0.0869 0.0856 0.0843 0.0833 0.0826 0.0819 0.0811 0.0809 

[TRAIN] Epoch[1](9161/114412); Loss: 0.076882; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.1602 0.1406 0.1059 0.0913 0.0802 0.0709 0.0669 0.0630 0.0602 0.0584 0.0574 0.0564 0.0557 0.0550 0.0544 0.0539 

[TRAIN] Epoch[1](9162/114412); Loss: 0.090387; Backpropagation: 0.2955 sec; Batch: 2.1194 sec
0.1530 0.1391 0.1066 0.1029 0.0936 0.0882 0.0844 0.0813 0.0790 0.0769 0.0755 0.0746 0.0737 0.0730 0.0724 0.0719 

[TRAIN] Epoch[1](9163/114412); Loss: 0.078281; Backpropagation: 0.2927 sec; Batch: 2.1181 sec
0.1219 0.1155 0.0990 0.0912 0.0809 0.0765 0.0742 0.0721 0.0695 0.0678 0.0662 0.0648 0.0640 0.0635 0.0629 0.0624 

[TRAIN] Epoch[1](9164/114412); Loss: 0.067619; Backpropagation: 0.2929 sec; Batch: 2.1183 sec
0.1486 0.1406 0.0896 0.0738 0.0624 0.0579 0.0551 0.0538 0.0525 0.0513 0.0505 0.0498 0.0494 0.0491 0.0489 0.0487 

[TRAIN] Epoch[1](9165/114412); Loss: 0.076474; Backpropagation: 0.2908 sec; Batch: 2.1153 sec
0.1808 0.1448 0.1053 0.0787 0.0731 0.0654 0.0653 0.0621 0.0589 0.0572 0.0567 0.0562 0.0556 0.0547 0.0545 0.0543 

[TRAIN] Epoch[1](9166/114412); Loss: 0.091199; Backpropagation: 0.2916 sec; Batch: 2.1223 sec
0.1597 0.1338 0.1087 0.0969 0.0899 0.0874 0.0841 0.0820 0.0804 0.0784 0.0775 0.0769 0.0764 0.0760 0.0756 0.0755 

[TRAIN] Epoch[1](9167/114412); Loss: 0.059876; Backpropagation: 0.2907 sec; Batch: 2.1213 sec
0.1165 0.0979 0.0804 0.0694 0.0664 0.0573 0.0528 0.0502 0.0482 0.0474 0.0463 0.0457 0.0453 0.0450 0.0447 0.0446 

[TRAIN] Epoch[1](9168/114412); Loss: 0.053874; Backpropagation: 0.2909 sec; Batch: 2.1180 sec
0.1162 0.0958 0.0721 0.0668 0.0600 0.0556 0.0478 0.0440 0.0419 0.0402 0.0388 0.0380 0.0373 0.0365 0.0358 0.0353 

[TRAIN] Epoch[1](9169/114412); Loss: 0.069040; Backpropagation: 0.2910 sec; Batch: 2.1226 sec
0.1246 0.1155 0.0822 0.0759 0.0695 0.0662 0.0628 0.0607 0.0588 0.0574 0.0564 0.0557 0.0553 0.0548 0.0546 0.0543 

[TRAIN] Epoch[1](9170/114412); Loss: 0.082588; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.1692 0.1333 0.1054 0.0912 0.0842 0.0773 0.0756 0.0710 0.0689 0.0671 0.0654 0.0643 0.0633 0.0625 0.0617 0.0610 

[TRAIN] Epoch[1](9171/114412); Loss: 0.066175; Backpropagation: 0.3445 sec; Batch: 2.1354 sec
0.1595 0.1304 0.0908 0.0672 0.0678 0.0605 0.0589 0.0536 0.0501 0.0485 0.0471 0.0461 0.0454 0.0447 0.0443 0.0439 

[TRAIN] Epoch[1](9172/114412); Loss: 0.067169; Backpropagation: 0.2955 sec; Batch: 2.0826 sec
0.1441 0.1242 0.0900 0.0761 0.0682 0.0620 0.0579 0.0554 0.0534 0.0514 0.0504 0.0494 0.0487 0.0483 0.0478 0.0474 

[TRAIN] Epoch[1](9173/114412); Loss: 0.085959; Backpropagation: 0.2915 sec; Batch: 2.1642 sec
0.1577 0.1382 0.1097 0.0990 0.0879 0.0815 0.0772 0.0749 0.0729 0.0711 0.0696 0.0684 0.0676 0.0670 0.0665 0.0661 

[TRAIN] Epoch[1](9174/114412); Loss: 0.080203; Backpropagation: 0.2908 sec; Batch: 2.0774 sec
0.1629 0.1470 0.1205 0.0956 0.0812 0.0716 0.0683 0.0657 0.0620 0.0610 0.0595 0.0587 0.0579 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](9175/114412); Loss: 0.071916; Backpropagation: 0.2915 sec; Batch: 2.1272 sec
0.1403 0.1272 0.0961 0.0835 0.0747 0.0684 0.0637 0.0604 0.0584 0.0567 0.0553 0.0546 0.0537 0.0531 0.0525 0.0520 

[TRAIN] Epoch[1](9176/114412); Loss: 0.083708; Backpropagation: 0.2911 sec; Batch: 2.3577 sec
0.1475 0.1397 0.1060 0.0946 0.0843 0.0794 0.0760 0.0736 0.0719 0.0697 0.0682 0.0670 0.0663 0.0656 0.0649 0.0646 

[TRAIN] Epoch[1](9177/114412); Loss: 0.078016; Backpropagation: 0.2913 sec; Batch: 2.0864 sec
0.1401 0.1214 0.0992 0.0856 0.0799 0.0760 0.0710 0.0690 0.0671 0.0653 0.0642 0.0631 0.0624 0.0618 0.0613 0.0610 

[TRAIN] Epoch[1](9178/114412); Loss: 0.072309; Backpropagation: 0.2909 sec; Batch: 2.1589 sec
0.1287 0.1150 0.0915 0.0786 0.0728 0.0687 0.0655 0.0634 0.0621 0.0607 0.0597 0.0590 0.0584 0.0580 0.0576 0.0572 

[TRAIN] Epoch[1](9179/114412); Loss: 0.078558; Backpropagation: 0.2915 sec; Batch: 2.1207 sec
0.1915 0.1627 0.1198 0.0924 0.0858 0.0722 0.0637 0.0593 0.0558 0.0539 0.0521 0.0510 0.0502 0.0495 0.0488 0.0482 

[TRAIN] Epoch[1](9180/114412); Loss: 0.098124; Backpropagation: 0.2911 sec; Batch: 2.0805 sec
0.1521 0.1334 0.1158 0.1062 0.1027 0.0966 0.0933 0.0908 0.0889 0.0871 0.0858 0.0848 0.0839 0.0832 0.0829 0.0825 

[TRAIN] Epoch[1](9181/114412); Loss: 0.075818; Backpropagation: 0.2907 sec; Batch: 2.1339 sec
0.1219 0.1068 0.0957 0.0852 0.0799 0.0750 0.0711 0.0694 0.0669 0.0655 0.0644 0.0634 0.0627 0.0621 0.0617 0.0612 

[TRAIN] Epoch[1](9182/114412); Loss: 0.074613; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1183 0.1097 0.0873 0.0792 0.0750 0.0720 0.0697 0.0684 0.0666 0.0656 0.0648 0.0642 0.0637 0.0633 0.0630 0.0629 

[TRAIN] Epoch[1](9183/114412); Loss: 0.055351; Backpropagation: 0.2911 sec; Batch: 2.1199 sec
0.1144 0.1017 0.0735 0.0624 0.0564 0.0522 0.0489 0.0459 0.0443 0.0429 0.0417 0.0412 0.0405 0.0401 0.0400 0.0395 

[TRAIN] Epoch[1](9184/114412); Loss: 0.089034; Backpropagation: 0.2930 sec; Batch: 2.1195 sec
0.1491 0.1294 0.1086 0.1008 0.0904 0.0858 0.0825 0.0797 0.0787 0.0767 0.0752 0.0747 0.0741 0.0733 0.0730 0.0727 

[TRAIN] Epoch[1](9185/114412); Loss: 0.068796; Backpropagation: 0.2928 sec; Batch: 2.1175 sec
0.1432 0.1262 0.0890 0.0766 0.0705 0.0632 0.0595 0.0573 0.0552 0.0538 0.0528 0.0518 0.0511 0.0506 0.0502 0.0499 

[TRAIN] Epoch[1](9186/114412); Loss: 0.074795; Backpropagation: 0.2949 sec; Batch: 2.1067 sec
0.1377 0.1179 0.0941 0.0826 0.0750 0.0713 0.0682 0.0657 0.0640 0.0626 0.0616 0.0607 0.0596 0.0591 0.0586 0.0582 

[TRAIN] Epoch[1](9187/114412); Loss: 0.087256; Backpropagation: 0.2932 sec; Batch: 2.1157 sec
0.1426 0.1339 0.1041 0.0949 0.0898 0.0849 0.0813 0.0788 0.0765 0.0753 0.0742 0.0734 0.0725 0.0720 0.0712 0.0708 

[TRAIN] Epoch[1](9188/114412); Loss: 0.087138; Backpropagation: 0.2922 sec; Batch: 2.1162 sec
0.1580 0.1209 0.1089 0.0970 0.0892 0.0843 0.0806 0.0772 0.0755 0.0742 0.0729 0.0722 0.0716 0.0710 0.0704 0.0702 

[TRAIN] Epoch[1](9189/114412); Loss: 0.064616; Backpropagation: 0.2911 sec; Batch: 2.1158 sec
0.1291 0.1175 0.0850 0.0753 0.0654 0.0609 0.0578 0.0544 0.0525 0.0510 0.0494 0.0486 0.0478 0.0468 0.0465 0.0460 

[TRAIN] Epoch[1](9190/114412); Loss: 0.083105; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1597 0.1479 0.0986 0.0861 0.0802 0.0761 0.0734 0.0714 0.0695 0.0686 0.0675 0.0669 0.0666 0.0660 0.0657 0.0655 

[TRAIN] Epoch[1](9191/114412); Loss: 0.097970; Backpropagation: 0.2923 sec; Batch: 2.1191 sec
0.1683 0.1482 0.1210 0.1102 0.1057 0.1010 0.0927 0.0908 0.0878 0.0816 0.0805 0.0784 0.0766 0.0758 0.0749 0.0742 

[TRAIN] Epoch[1](9192/114412); Loss: 0.085662; Backpropagation: 0.2911 sec; Batch: 2.1152 sec
0.1511 0.1316 0.1075 0.0953 0.0847 0.0805 0.0775 0.0753 0.0735 0.0728 0.0717 0.0709 0.0702 0.0697 0.0693 0.0690 

[TRAIN] Epoch[1](9193/114412); Loss: 0.074172; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1506 0.1215 0.0910 0.0870 0.0724 0.0666 0.0644 0.0632 0.0610 0.0600 0.0592 0.0585 0.0581 0.0579 0.0577 0.0575 

[TRAIN] Epoch[1](9194/114412); Loss: 0.078283; Backpropagation: 0.2915 sec; Batch: 2.1172 sec
0.1453 0.1218 0.0917 0.0849 0.0786 0.0739 0.0711 0.0691 0.0670 0.0660 0.0654 0.0646 0.0639 0.0634 0.0630 0.0628 

[TRAIN] Epoch[1](9195/114412); Loss: 0.106267; Backpropagation: 0.2913 sec; Batch: 2.1218 sec
0.1580 0.1507 0.1177 0.1088 0.1062 0.1022 0.0995 0.0986 0.0969 0.0960 0.0952 0.0947 0.0945 0.0940 0.0936 0.0934 

[TRAIN] Epoch[1](9196/114412); Loss: 0.050617; Backpropagation: 0.2914 sec; Batch: 2.1203 sec
0.1133 0.1006 0.0730 0.0573 0.0519 0.0454 0.0416 0.0403 0.0381 0.0373 0.0363 0.0355 0.0352 0.0348 0.0346 0.0344 

[TRAIN] Epoch[1](9197/114412); Loss: 0.076998; Backpropagation: 0.2912 sec; Batch: 2.0946 sec
0.1410 0.1371 0.0912 0.0879 0.0749 0.0714 0.0687 0.0662 0.0646 0.0631 0.0622 0.0617 0.0611 0.0606 0.0603 0.0600 

[TRAIN] Epoch[1](9198/114412); Loss: 0.114883; Backpropagation: 0.2948 sec; Batch: 2.1367 sec
0.1810 0.1624 0.1424 0.1312 0.1233 0.1134 0.1098 0.1057 0.1036 0.1002 0.0983 0.0962 0.0944 0.0931 0.0920 0.0910 

[TRAIN] Epoch[1](9199/114412); Loss: 0.078016; Backpropagation: 0.2924 sec; Batch: 2.1193 sec
0.1266 0.1104 0.0908 0.0864 0.0801 0.0764 0.0733 0.0709 0.0693 0.0682 0.0672 0.0666 0.0661 0.0656 0.0653 0.0651 

[TRAIN] Epoch[1](9200/114412); Loss: 0.057383; Backpropagation: 0.2912 sec; Batch: 2.1191 sec
0.1280 0.1141 0.0751 0.0661 0.0558 0.0531 0.0492 0.0457 0.0442 0.0428 0.0416 0.0411 0.0407 0.0403 0.0401 0.0401 

[TRAIN] Epoch[1](9201/114412); Loss: 0.100557; Backpropagation: 0.2928 sec; Batch: 2.1305 sec
0.1969 0.1819 0.1401 0.1261 0.1070 0.0992 0.0922 0.0827 0.0768 0.0771 0.0744 0.0734 0.0716 0.0705 0.0699 0.0692 

[TRAIN] Epoch[1](9202/114412); Loss: 0.079492; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1469 0.1283 0.1074 0.0924 0.0821 0.0721 0.0684 0.0666 0.0658 0.0650 0.0640 0.0634 0.0628 0.0625 0.0623 0.0620 

[TRAIN] Epoch[1](9203/114412); Loss: 0.102769; Backpropagation: 0.2930 sec; Batch: 2.1176 sec
0.1915 0.1646 0.1218 0.1067 0.1005 0.0971 0.0938 0.0907 0.0887 0.0867 0.0855 0.0846 0.0840 0.0833 0.0828 0.0823 

[TRAIN] Epoch[1](9204/114412); Loss: 0.073570; Backpropagation: 0.2916 sec; Batch: 2.1170 sec
0.1424 0.1168 0.0935 0.0832 0.0732 0.0687 0.0661 0.0634 0.0613 0.0602 0.0592 0.0587 0.0582 0.0577 0.0574 0.0570 

[TRAIN] Epoch[1](9205/114412); Loss: 0.067967; Backpropagation: 0.2916 sec; Batch: 2.1165 sec
0.1373 0.1276 0.0935 0.0833 0.0700 0.0635 0.0600 0.0562 0.0541 0.0520 0.0504 0.0494 0.0484 0.0476 0.0472 0.0468 

[TRAIN] Epoch[1](9206/114412); Loss: 0.062448; Backpropagation: 0.2932 sec; Batch: 2.1179 sec
0.1765 0.1641 0.0820 0.0597 0.0513 0.0517 0.0460 0.0442 0.0422 0.0409 0.0412 0.0402 0.0398 0.0403 0.0396 0.0395 

[TRAIN] Epoch[1](9207/114412); Loss: 0.063590; Backpropagation: 0.2915 sec; Batch: 2.0875 sec
0.1472 0.1220 0.0851 0.0790 0.0692 0.0592 0.0544 0.0503 0.0477 0.0459 0.0449 0.0436 0.0430 0.0424 0.0418 0.0414 

[TRAIN] Epoch[1](9208/114412); Loss: 0.074612; Backpropagation: 0.2904 sec; Batch: 2.1187 sec
0.1350 0.1195 0.0924 0.0835 0.0756 0.0710 0.0677 0.0651 0.0635 0.0622 0.0612 0.0605 0.0599 0.0594 0.0588 0.0585 

[TRAIN] Epoch[1](9209/114412); Loss: 0.072587; Backpropagation: 0.2910 sec; Batch: 2.0787 sec
0.1357 0.1145 0.0956 0.0833 0.0737 0.0700 0.0646 0.0625 0.0607 0.0595 0.0585 0.0577 0.0569 0.0564 0.0561 0.0558 

[TRAIN] Epoch[1](9210/114412); Loss: 0.086118; Backpropagation: 0.2914 sec; Batch: 2.0770 sec
0.1817 0.1704 0.1085 0.0963 0.0836 0.0778 0.0751 0.0708 0.0682 0.0666 0.0653 0.0644 0.0634 0.0624 0.0619 0.0616 

[TRAIN] Epoch[1](9211/114412); Loss: 0.083044; Backpropagation: 0.2905 sec; Batch: 2.1155 sec
0.1307 0.1175 0.1069 0.0940 0.0852 0.0804 0.0772 0.0751 0.0734 0.0719 0.0709 0.0701 0.0696 0.0691 0.0686 0.0681 

[TRAIN] Epoch[1](9212/114412); Loss: 0.086551; Backpropagation: 0.2914 sec; Batch: 2.1209 sec
0.1658 0.1401 0.0993 0.0963 0.0876 0.0822 0.0792 0.0761 0.0735 0.0726 0.0709 0.0696 0.0690 0.0681 0.0673 0.0672 

[TRAIN] Epoch[1](9213/114412); Loss: 0.099794; Backpropagation: 0.2906 sec; Batch: 2.1082 sec
0.1624 0.1450 0.1201 0.1108 0.1015 0.0973 0.1016 0.0961 0.0908 0.0871 0.0831 0.0816 0.0807 0.0803 0.0798 0.0784 

[TRAIN] Epoch[1](9214/114412); Loss: 0.069599; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1098 0.1060 0.0888 0.0826 0.0741 0.0696 0.0656 0.0624 0.0607 0.0590 0.0578 0.0569 0.0559 0.0553 0.0549 0.0542 

[TRAIN] Epoch[1](9215/114412); Loss: 0.064975; Backpropagation: 0.2926 sec; Batch: 2.1189 sec
0.1391 0.1239 0.0751 0.0677 0.0635 0.0578 0.0556 0.0534 0.0525 0.0516 0.0509 0.0505 0.0499 0.0497 0.0493 0.0491 

[TRAIN] Epoch[1](9216/114412); Loss: 0.090451; Backpropagation: 0.2912 sec; Batch: 2.1570 sec
0.1447 0.1222 0.0995 0.0973 0.0937 0.0945 0.0883 0.0835 0.0817 0.0798 0.0786 0.0782 0.0772 0.0764 0.0761 0.0756 

[TRAIN] Epoch[1](9217/114412); Loss: 0.071898; Backpropagation: 0.2913 sec; Batch: 2.1300 sec
0.1139 0.1096 0.0874 0.0808 0.0731 0.0695 0.0663 0.0644 0.0632 0.0621 0.0613 0.0606 0.0601 0.0597 0.0594 0.0590 

[TRAIN] Epoch[1](9218/114412); Loss: 0.073876; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1290 0.1130 0.0910 0.0815 0.0761 0.0711 0.0681 0.0652 0.0635 0.0622 0.0613 0.0607 0.0602 0.0599 0.0597 0.0595 

[TRAIN] Epoch[1](9219/114412); Loss: 0.097928; Backpropagation: 0.2909 sec; Batch: 2.1161 sec
0.1878 0.1752 0.1378 0.1256 0.1086 0.0945 0.0846 0.0775 0.0761 0.0746 0.0736 0.0717 0.0705 0.0700 0.0696 0.0691 

[TRAIN] Epoch[1](9220/114412); Loss: 0.088815; Backpropagation: 0.2908 sec; Batch: 2.1137 sec
0.1587 0.1436 0.1102 0.0935 0.0882 0.0837 0.0809 0.0791 0.0768 0.0758 0.0740 0.0726 0.0719 0.0713 0.0705 0.0701 

[TRAIN] Epoch[1](9221/114412); Loss: 0.059430; Backpropagation: 0.2929 sec; Batch: 2.0814 sec
0.1435 0.1207 0.0879 0.0637 0.0646 0.0501 0.0482 0.0444 0.0431 0.0426 0.0420 0.0408 0.0404 0.0400 0.0395 0.0394 

[TRAIN] Epoch[1](9222/114412); Loss: 0.051878; Backpropagation: 0.2915 sec; Batch: 2.1023 sec
0.1135 0.0880 0.0715 0.0589 0.0527 0.0475 0.0441 0.0426 0.0414 0.0404 0.0395 0.0388 0.0383 0.0379 0.0376 0.0373 

[TRAIN] Epoch[1](9223/114412); Loss: 0.073132; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1486 0.1190 0.0856 0.0766 0.0726 0.0695 0.0665 0.0638 0.0620 0.0604 0.0592 0.0585 0.0577 0.0572 0.0567 0.0563 

[TRAIN] Epoch[1](9224/114412); Loss: 0.079414; Backpropagation: 0.2910 sec; Batch: 2.0768 sec
0.1706 0.1410 0.1054 0.1006 0.0898 0.0746 0.0709 0.0684 0.0618 0.0606 0.0581 0.0555 0.0549 0.0541 0.0522 0.0520 

[TRAIN] Epoch[1](9225/114412); Loss: 0.084836; Backpropagation: 0.2909 sec; Batch: 2.1142 sec
0.1469 0.1273 0.1047 0.0967 0.0889 0.0841 0.0817 0.0766 0.0733 0.0708 0.0696 0.0686 0.0677 0.0673 0.0669 0.0664 

[TRAIN] Epoch[1](9226/114412); Loss: 0.078907; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1478 0.1323 0.0945 0.0883 0.0782 0.0742 0.0710 0.0684 0.0671 0.0654 0.0642 0.0636 0.0627 0.0619 0.0616 0.0612 

[TRAIN] Epoch[1](9227/114412); Loss: 0.103837; Backpropagation: 0.2910 sec; Batch: 2.1150 sec
0.2195 0.1883 0.1454 0.1221 0.1092 0.0948 0.0877 0.0836 0.0807 0.0792 0.0779 0.0767 0.0749 0.0743 0.0739 0.0734 

[TRAIN] Epoch[1](9228/114412); Loss: 0.059244; Backpropagation: 0.2932 sec; Batch: 2.1217 sec
0.1013 0.0877 0.0691 0.0662 0.0616 0.0571 0.0547 0.0533 0.0516 0.0508 0.0501 0.0495 0.0493 0.0489 0.0485 0.0483 

[TRAIN] Epoch[1](9229/114412); Loss: 0.101166; Backpropagation: 0.2911 sec; Batch: 2.1197 sec
0.1727 0.1526 0.1243 0.1152 0.1013 0.0957 0.0990 0.0980 0.0936 0.0865 0.0831 0.0814 0.0804 0.0791 0.0782 0.0775 

[TRAIN] Epoch[1](9230/114412); Loss: 0.065474; Backpropagation: 0.2927 sec; Batch: 2.1179 sec
0.1091 0.0987 0.0791 0.0726 0.0708 0.0662 0.0609 0.0586 0.0569 0.0558 0.0550 0.0537 0.0533 0.0528 0.0522 0.0520 

[TRAIN] Epoch[1](9231/114412); Loss: 0.068497; Backpropagation: 0.2935 sec; Batch: 2.1186 sec
0.1356 0.1187 0.0913 0.0743 0.0688 0.0639 0.0595 0.0580 0.0562 0.0548 0.0539 0.0532 0.0526 0.0521 0.0516 0.0514 

[TRAIN] Epoch[1](9232/114412); Loss: 0.074433; Backpropagation: 0.2951 sec; Batch: 2.1236 sec
0.1426 0.1297 0.0952 0.0863 0.0761 0.0702 0.0662 0.0641 0.0617 0.0596 0.0583 0.0574 0.0567 0.0560 0.0556 0.0553 

[TRAIN] Epoch[1](9233/114412); Loss: 0.077591; Backpropagation: 0.2908 sec; Batch: 2.1287 sec
0.1243 0.1144 0.0998 0.0880 0.0814 0.0755 0.0719 0.0698 0.0679 0.0662 0.0654 0.0644 0.0638 0.0634 0.0628 0.0625 

[TRAIN] Epoch[1](9234/114412); Loss: 0.078970; Backpropagation: 0.2906 sec; Batch: 2.0923 sec
0.1391 0.1294 0.1014 0.0871 0.0823 0.0758 0.0714 0.0696 0.0667 0.0654 0.0641 0.0633 0.0626 0.0622 0.0616 0.0615 

[TRAIN] Epoch[1](9235/114412); Loss: 0.077438; Backpropagation: 0.2906 sec; Batch: 2.1152 sec
0.1291 0.1168 0.0999 0.0880 0.0805 0.0744 0.0711 0.0689 0.0667 0.0655 0.0645 0.0638 0.0632 0.0626 0.0622 0.0617 

[TRAIN] Epoch[1](9236/114412); Loss: 0.079038; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1503 0.1317 0.0999 0.0856 0.0795 0.0747 0.0708 0.0686 0.0665 0.0649 0.0637 0.0628 0.0622 0.0616 0.0611 0.0607 

[TRAIN] Epoch[1](9237/114412); Loss: 0.055015; Backpropagation: 0.2909 sec; Batch: 2.1438 sec
0.1078 0.0857 0.0650 0.0603 0.0574 0.0537 0.0506 0.0481 0.0463 0.0451 0.0444 0.0437 0.0433 0.0430 0.0429 0.0429 

[TRAIN] Epoch[1](9238/114412); Loss: 0.076588; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1689 0.1591 0.1179 0.1046 0.0873 0.0718 0.0615 0.0574 0.0544 0.0516 0.0508 0.0497 0.0483 0.0478 0.0475 0.0468 

[TRAIN] Epoch[1](9239/114412); Loss: 0.073894; Backpropagation: 0.2914 sec; Batch: 2.0848 sec
0.1577 0.1445 0.1000 0.0854 0.0709 0.0664 0.0624 0.0599 0.0574 0.0562 0.0551 0.0541 0.0537 0.0532 0.0528 0.0525 

[TRAIN] Epoch[1](9240/114412); Loss: 0.059315; Backpropagation: 0.2928 sec; Batch: 2.1197 sec
0.1246 0.1069 0.0821 0.0700 0.0602 0.0563 0.0521 0.0492 0.0463 0.0456 0.0443 0.0432 0.0428 0.0422 0.0417 0.0415 

[TRAIN] Epoch[1](9241/114412); Loss: 0.094516; Backpropagation: 0.2913 sec; Batch: 2.1239 sec
0.1867 0.1553 0.1187 0.1080 0.0950 0.0885 0.0829 0.0800 0.0783 0.0772 0.0758 0.0748 0.0737 0.0731 0.0724 0.0720 

[TRAIN] Epoch[1](9242/114412); Loss: 0.079453; Backpropagation: 0.2940 sec; Batch: 2.1010 sec
0.1517 0.1262 0.0973 0.0907 0.0816 0.0760 0.0720 0.0693 0.0674 0.0655 0.0641 0.0630 0.0623 0.0617 0.0613 0.0610 

[TRAIN] Epoch[1](9243/114412); Loss: 0.061048; Backpropagation: 0.2961 sec; Batch: 2.1290 sec
0.1375 0.1334 0.0808 0.0708 0.0568 0.0522 0.0498 0.0480 0.0462 0.0448 0.0438 0.0432 0.0428 0.0424 0.0421 0.0421 

[TRAIN] Epoch[1](9244/114412); Loss: 0.065452; Backpropagation: 0.2949 sec; Batch: 2.0816 sec
0.1101 0.1015 0.0811 0.0731 0.0672 0.0618 0.0603 0.0585 0.0567 0.0557 0.0546 0.0540 0.0539 0.0532 0.0528 0.0527 

[TRAIN] Epoch[1](9245/114412); Loss: 0.070552; Backpropagation: 0.2957 sec; Batch: 2.0823 sec
0.1357 0.1254 0.0945 0.0814 0.0711 0.0652 0.0618 0.0603 0.0577 0.0564 0.0551 0.0540 0.0535 0.0528 0.0522 0.0518 

[TRAIN] Epoch[1](9246/114412); Loss: 0.107501; Backpropagation: 0.2949 sec; Batch: 2.1190 sec
0.1655 0.1550 0.1307 0.1170 0.1086 0.1035 0.0992 0.0970 0.0955 0.0944 0.0936 0.0929 0.0923 0.0919 0.0916 0.0913 

[TRAIN] Epoch[1](9247/114412); Loss: 0.054161; Backpropagation: 0.2955 sec; Batch: 2.1239 sec
0.1012 0.0826 0.0673 0.0633 0.0598 0.0532 0.0505 0.0486 0.0459 0.0444 0.0433 0.0424 0.0418 0.0412 0.0407 0.0404 

[TRAIN] Epoch[1](9248/114412); Loss: 0.068269; Backpropagation: 0.2955 sec; Batch: 2.0832 sec
0.1119 0.1027 0.0937 0.0807 0.0732 0.0667 0.0633 0.0605 0.0586 0.0573 0.0559 0.0547 0.0541 0.0534 0.0530 0.0526 

[TRAIN] Epoch[1](9249/114412); Loss: 0.059644; Backpropagation: 0.2957 sec; Batch: 2.1196 sec
0.1271 0.1113 0.0806 0.0681 0.0636 0.0545 0.0514 0.0485 0.0461 0.0448 0.0440 0.0432 0.0431 0.0430 0.0426 0.0425 

[TRAIN] Epoch[1](9250/114412); Loss: 0.073607; Backpropagation: 0.2980 sec; Batch: 2.1279 sec
0.1355 0.1198 0.0885 0.0823 0.0742 0.0713 0.0668 0.0641 0.0629 0.0611 0.0600 0.0593 0.0585 0.0580 0.0578 0.0576 

[TRAIN] Epoch[1](9251/114412); Loss: 0.064372; Backpropagation: 0.2980 sec; Batch: 2.1219 sec
0.1116 0.1009 0.0777 0.0745 0.0657 0.0623 0.0596 0.0572 0.0554 0.0542 0.0530 0.0523 0.0521 0.0515 0.0511 0.0509 

[TRAIN] Epoch[1](9252/114412); Loss: 0.057378; Backpropagation: 0.2978 sec; Batch: 2.1240 sec
0.1011 0.0934 0.0678 0.0677 0.0594 0.0539 0.0521 0.0508 0.0488 0.0479 0.0469 0.0463 0.0460 0.0455 0.0453 0.0450 

[TRAIN] Epoch[1](9253/114412); Loss: 0.069206; Backpropagation: 0.2975 sec; Batch: 2.1225 sec
0.1491 0.1285 0.0854 0.0762 0.0689 0.0635 0.0601 0.0571 0.0554 0.0541 0.0530 0.0522 0.0515 0.0511 0.0508 0.0504 

[TRAIN] Epoch[1](9254/114412); Loss: 0.081274; Backpropagation: 0.2981 sec; Batch: 2.1255 sec
0.1590 0.1388 0.1038 0.0927 0.0832 0.0776 0.0731 0.0696 0.0672 0.0655 0.0638 0.0627 0.0618 0.0610 0.0604 0.0601 

[TRAIN] Epoch[1](9255/114412); Loss: 0.077465; Backpropagation: 0.2951 sec; Batch: 2.1190 sec
0.1363 0.1137 0.0882 0.0845 0.0788 0.0751 0.0718 0.0697 0.0681 0.0670 0.0660 0.0650 0.0644 0.0641 0.0636 0.0632 

[TRAIN] Epoch[1](9256/114412); Loss: 0.076662; Backpropagation: 0.2954 sec; Batch: 2.1208 sec
0.1329 0.1268 0.0904 0.0808 0.0744 0.0717 0.0696 0.0686 0.0667 0.0654 0.0646 0.0639 0.0633 0.0629 0.0625 0.0621 

[TRAIN] Epoch[1](9257/114412); Loss: 0.090136; Backpropagation: 0.2980 sec; Batch: 2.1246 sec
0.1371 0.1227 0.1028 0.0964 0.0916 0.0886 0.0859 0.0837 0.0820 0.0808 0.0800 0.0791 0.0786 0.0780 0.0776 0.0773 

[TRAIN] Epoch[1](9258/114412); Loss: 0.086869; Backpropagation: 0.2974 sec; Batch: 2.1355 sec
0.1680 0.1522 0.1150 0.0987 0.0870 0.0802 0.0755 0.0729 0.0707 0.0694 0.0684 0.0675 0.0668 0.0664 0.0658 0.0655 

[TRAIN] Epoch[1](9259/114412); Loss: 0.062063; Backpropagation: 0.3009 sec; Batch: 2.1277 sec
0.1133 0.0997 0.0756 0.0687 0.0627 0.0597 0.0553 0.0541 0.0531 0.0517 0.0507 0.0502 0.0498 0.0497 0.0493 0.0494 

[TRAIN] Epoch[1](9260/114412); Loss: 0.053345; Backpropagation: 0.2978 sec; Batch: 2.0938 sec
0.1439 0.1110 0.0688 0.0645 0.0485 0.0438 0.0413 0.0408 0.0382 0.0376 0.0366 0.0361 0.0361 0.0356 0.0354 0.0354 

[TRAIN] Epoch[1](9261/114412); Loss: 0.094666; Backpropagation: 0.2950 sec; Batch: 2.1220 sec
0.1725 0.1574 0.1195 0.1047 0.0961 0.0883 0.0843 0.0813 0.0798 0.0784 0.0770 0.0764 0.0757 0.0748 0.0745 0.0741 

[TRAIN] Epoch[1](9262/114412); Loss: 0.053260; Backpropagation: 0.2980 sec; Batch: 2.1247 sec
0.1212 0.1026 0.0681 0.0616 0.0533 0.0487 0.0453 0.0423 0.0410 0.0400 0.0393 0.0387 0.0381 0.0376 0.0373 0.0370 

[TRAIN] Epoch[1](9263/114412); Loss: 0.092214; Backpropagation: 0.2978 sec; Batch: 2.1335 sec
0.1704 0.1519 0.1181 0.1063 0.0959 0.0887 0.0820 0.0789 0.0771 0.0754 0.0741 0.0731 0.0719 0.0712 0.0706 0.0699 

[TRAIN] Epoch[1](9264/114412); Loss: 0.064536; Backpropagation: 0.2957 sec; Batch: 2.1229 sec
0.1138 0.1027 0.0820 0.0719 0.0657 0.0618 0.0585 0.0567 0.0557 0.0541 0.0534 0.0527 0.0515 0.0511 0.0508 0.0502 

[TRAIN] Epoch[1](9265/114412); Loss: 0.086127; Backpropagation: 0.2954 sec; Batch: 2.1211 sec
0.1585 0.1443 0.1085 0.0984 0.0874 0.0817 0.0768 0.0747 0.0730 0.0708 0.0698 0.0687 0.0673 0.0667 0.0659 0.0655 

[TRAIN] Epoch[1](9266/114412); Loss: 0.063320; Backpropagation: 0.2957 sec; Batch: 2.1268 sec
0.1437 0.1116 0.0823 0.0815 0.0634 0.0568 0.0531 0.0499 0.0489 0.0477 0.0466 0.0461 0.0458 0.0456 0.0452 0.0451 

[TRAIN] Epoch[1](9267/114412); Loss: 0.060107; Backpropagation: 0.2956 sec; Batch: 2.1245 sec
0.1128 0.1059 0.0774 0.0685 0.0616 0.0561 0.0534 0.0516 0.0498 0.0486 0.0477 0.0468 0.0460 0.0456 0.0451 0.0448 

[TRAIN] Epoch[1](9268/114412); Loss: 0.059008; Backpropagation: 0.2959 sec; Batch: 2.1226 sec
0.1195 0.1106 0.0771 0.0689 0.0598 0.0545 0.0512 0.0489 0.0472 0.0459 0.0448 0.0440 0.0435 0.0431 0.0428 0.0423 

[TRAIN] Epoch[1](9269/114412); Loss: 0.077816; Backpropagation: 0.2959 sec; Batch: 2.1212 sec
0.1722 0.1444 0.1038 0.0901 0.0808 0.0739 0.0676 0.0643 0.0604 0.0588 0.0571 0.0560 0.0551 0.0542 0.0534 0.0530 

[TRAIN] Epoch[1](9270/114412); Loss: 0.063544; Backpropagation: 0.2953 sec; Batch: 2.1209 sec
0.1401 0.1314 0.0880 0.0711 0.0626 0.0559 0.0530 0.0506 0.0485 0.0476 0.0463 0.0455 0.0447 0.0443 0.0438 0.0435 

[TRAIN] Epoch[1](9271/114412); Loss: 0.069730; Backpropagation: 0.2956 sec; Batch: 2.1294 sec
0.1395 0.1289 0.0850 0.0737 0.0675 0.0626 0.0602 0.0587 0.0574 0.0563 0.0555 0.0548 0.0544 0.0540 0.0538 0.0535 

[TRAIN] Epoch[1](9272/114412); Loss: 0.090958; Backpropagation: 0.2956 sec; Batch: 2.0823 sec
0.1556 0.1453 0.1114 0.1003 0.0915 0.0867 0.0834 0.0802 0.0779 0.0767 0.0760 0.0751 0.0744 0.0740 0.0736 0.0732 

[TRAIN] Epoch[1](9273/114412); Loss: 0.077885; Backpropagation: 0.2953 sec; Batch: 2.1044 sec
0.1569 0.1478 0.1105 0.0950 0.0839 0.0732 0.0680 0.0645 0.0601 0.0588 0.0574 0.0556 0.0549 0.0539 0.0530 0.0527 

[TRAIN] Epoch[1](9274/114412); Loss: 0.072949; Backpropagation: 0.3006 sec; Batch: 2.1266 sec
0.1159 0.1110 0.0918 0.0854 0.0782 0.0717 0.0682 0.0656 0.0634 0.0620 0.0608 0.0598 0.0592 0.0584 0.0580 0.0577 

[TRAIN] Epoch[1](9275/114412); Loss: 0.081607; Backpropagation: 0.2978 sec; Batch: 2.1241 sec
0.1302 0.1168 0.1012 0.0880 0.0818 0.0790 0.0758 0.0739 0.0729 0.0714 0.0705 0.0701 0.0691 0.0688 0.0683 0.0679 

[TRAIN] Epoch[1](9276/114412); Loss: 0.064033; Backpropagation: 0.2979 sec; Batch: 2.0902 sec
0.1163 0.1007 0.0829 0.0714 0.0644 0.0612 0.0582 0.0565 0.0545 0.0532 0.0523 0.0514 0.0510 0.0504 0.0500 0.0498 

[TRAIN] Epoch[1](9277/114412); Loss: 0.094528; Backpropagation: 0.2948 sec; Batch: 2.0820 sec
0.1575 0.1353 0.1126 0.1036 0.0958 0.0915 0.0881 0.0853 0.0835 0.0822 0.0811 0.0803 0.0796 0.0790 0.0786 0.0784 

[TRAIN] Epoch[1](9278/114412); Loss: 0.075220; Backpropagation: 0.2951 sec; Batch: 2.1189 sec
0.1399 0.1280 0.0951 0.0853 0.0790 0.0739 0.0693 0.0662 0.0632 0.0610 0.0597 0.0585 0.0572 0.0564 0.0557 0.0552 

[TRAIN] Epoch[1](9279/114412); Loss: 0.062845; Backpropagation: 0.2981 sec; Batch: 2.0854 sec
0.1509 0.1292 0.0819 0.0750 0.0621 0.0581 0.0526 0.0488 0.0474 0.0453 0.0439 0.0430 0.0424 0.0419 0.0415 0.0414 

[TRAIN] Epoch[1](9280/114412); Loss: 0.055555; Backpropagation: 0.2964 sec; Batch: 2.1012 sec
0.1164 0.1012 0.0721 0.0610 0.0573 0.0514 0.0486 0.0462 0.0445 0.0432 0.0424 0.0418 0.0413 0.0409 0.0404 0.0403 

[TRAIN] Epoch[1](9281/114412); Loss: 0.054613; Backpropagation: 0.2958 sec; Batch: 2.1280 sec
0.1235 0.1157 0.0684 0.0580 0.0513 0.0476 0.0451 0.0436 0.0422 0.0413 0.0404 0.0400 0.0396 0.0392 0.0391 0.0388 

[TRAIN] Epoch[1](9282/114412); Loss: 0.103174; Backpropagation: 0.2957 sec; Batch: 2.1230 sec
0.1615 0.1472 0.1204 0.1129 0.1057 0.1013 0.0971 0.0949 0.0928 0.0912 0.0900 0.0887 0.0877 0.0870 0.0864 0.0858 

[TRAIN] Epoch[1](9283/114412); Loss: 0.084749; Backpropagation: 0.2954 sec; Batch: 2.0843 sec
0.1580 0.1457 0.1087 0.0946 0.0876 0.0813 0.0758 0.0728 0.0700 0.0677 0.0672 0.0665 0.0656 0.0653 0.0648 0.0643 

[TRAIN] Epoch[1](9284/114412); Loss: 0.071927; Backpropagation: 0.2957 sec; Batch: 2.1215 sec
0.1335 0.1201 0.0925 0.0813 0.0741 0.0690 0.0642 0.0613 0.0597 0.0583 0.0576 0.0569 0.0562 0.0558 0.0554 0.0549 

[TRAIN] Epoch[1](9285/114412); Loss: 0.075394; Backpropagation: 0.2956 sec; Batch: 2.1223 sec
0.1565 0.1506 0.1030 0.0920 0.0763 0.0685 0.0636 0.0608 0.0583 0.0564 0.0554 0.0543 0.0534 0.0529 0.0523 0.0519 

[TRAIN] Epoch[1](9286/114412); Loss: 0.083458; Backpropagation: 0.2954 sec; Batch: 2.1208 sec
0.1196 0.1147 0.0981 0.0939 0.0868 0.0821 0.0803 0.0775 0.0758 0.0745 0.0733 0.0726 0.0722 0.0717 0.0713 0.0710 

[TRAIN] Epoch[1](9287/114412); Loss: 0.059859; Backpropagation: 0.2954 sec; Batch: 2.1217 sec
0.1003 0.0898 0.0752 0.0702 0.0622 0.0582 0.0555 0.0533 0.0519 0.0506 0.0497 0.0492 0.0487 0.0480 0.0476 0.0473 

[TRAIN] Epoch[1](9288/114412); Loss: 0.070305; Backpropagation: 0.2955 sec; Batch: 2.1252 sec
0.1224 0.1062 0.0913 0.0780 0.0721 0.0673 0.0637 0.0619 0.0604 0.0593 0.0581 0.0575 0.0572 0.0567 0.0565 0.0562 

[TRAIN] Epoch[1](9289/114412); Loss: 0.079974; Backpropagation: 0.2953 sec; Batch: 2.1222 sec
0.1281 0.1105 0.0929 0.0864 0.0829 0.0814 0.0764 0.0736 0.0713 0.0705 0.0692 0.0681 0.0677 0.0672 0.0668 0.0666 

[TRAIN] Epoch[1](9290/114412); Loss: 0.063207; Backpropagation: 0.2951 sec; Batch: 2.1205 sec
0.1438 0.1243 0.0833 0.0752 0.0618 0.0540 0.0534 0.0515 0.0489 0.0477 0.0464 0.0452 0.0449 0.0441 0.0435 0.0433 

[TRAIN] Epoch[1](9291/114412); Loss: 0.073155; Backpropagation: 0.2948 sec; Batch: 2.0891 sec
0.1369 0.1211 0.0943 0.0840 0.0781 0.0685 0.0655 0.0629 0.0604 0.0592 0.0582 0.0573 0.0568 0.0563 0.0556 0.0554 

[TRAIN] Epoch[1](9292/114412); Loss: 0.061277; Backpropagation: 0.2951 sec; Batch: 2.1176 sec
0.1089 0.0984 0.0861 0.0733 0.0647 0.0591 0.0547 0.0532 0.0510 0.0492 0.0484 0.0475 0.0471 0.0466 0.0462 0.0460 

[TRAIN] Epoch[1](9293/114412); Loss: 0.062241; Backpropagation: 0.2951 sec; Batch: 2.1385 sec
0.1099 0.0974 0.0863 0.0754 0.0687 0.0622 0.0569 0.0540 0.0516 0.0505 0.0493 0.0482 0.0474 0.0467 0.0460 0.0455 

[TRAIN] Epoch[1](9294/114412); Loss: 0.067645; Backpropagation: 0.2982 sec; Batch: 2.1251 sec
0.1197 0.1080 0.0820 0.0754 0.0676 0.0640 0.0613 0.0591 0.0579 0.0571 0.0561 0.0557 0.0551 0.0547 0.0544 0.0541 

[TRAIN] Epoch[1](9295/114412); Loss: 0.068806; Backpropagation: 0.2960 sec; Batch: 2.1193 sec
0.1297 0.1218 0.0823 0.0740 0.0676 0.0618 0.0607 0.0590 0.0575 0.0564 0.0559 0.0555 0.0550 0.0547 0.0545 0.0544 

[TRAIN] Epoch[1](9296/114412); Loss: 0.068822; Backpropagation: 0.2949 sec; Batch: 2.0816 sec
0.1478 0.1256 0.0892 0.0765 0.0686 0.0634 0.0594 0.0572 0.0550 0.0537 0.0528 0.0515 0.0509 0.0503 0.0498 0.0495 

[TRAIN] Epoch[1](9297/114412); Loss: 0.058009; Backpropagation: 0.2979 sec; Batch: 2.1259 sec
0.1194 0.1053 0.0743 0.0660 0.0609 0.0546 0.0520 0.0489 0.0460 0.0447 0.0438 0.0432 0.0429 0.0422 0.0421 0.0420 

[TRAIN] Epoch[1](9298/114412); Loss: 0.107393; Backpropagation: 0.2955 sec; Batch: 2.1226 sec
0.1741 0.1658 0.1336 0.1207 0.1112 0.1039 0.0994 0.0960 0.0936 0.0919 0.0902 0.0891 0.0882 0.0874 0.0867 0.0864 

[TRAIN] Epoch[1](9299/114412); Loss: 0.073054; Backpropagation: 0.2956 sec; Batch: 2.1339 sec
0.1469 0.1334 0.0883 0.0795 0.0704 0.0662 0.0637 0.0617 0.0601 0.0589 0.0580 0.0572 0.0567 0.0564 0.0559 0.0556 

[TRAIN] Epoch[1](9300/114412); Loss: 0.075666; Backpropagation: 0.2959 sec; Batch: 2.1180 sec
0.1316 0.1199 0.0934 0.0854 0.0776 0.0725 0.0685 0.0670 0.0647 0.0633 0.0625 0.0615 0.0612 0.0608 0.0605 0.0604 

[TRAIN] Epoch[1](9301/114412); Loss: 0.079649; Backpropagation: 0.2978 sec; Batch: 2.1122 sec
0.1432 0.1289 0.1009 0.0880 0.0802 0.0743 0.0719 0.0699 0.0676 0.0664 0.0654 0.0645 0.0639 0.0635 0.0631 0.0626 

[TRAIN] Epoch[1](9302/114412); Loss: 0.069422; Backpropagation: 0.3006 sec; Batch: 2.1296 sec
0.1229 0.1091 0.0948 0.0823 0.0721 0.0643 0.0623 0.0599 0.0579 0.0570 0.0556 0.0551 0.0548 0.0544 0.0540 0.0540 

[TRAIN] Epoch[1](9303/114412); Loss: 0.066865; Backpropagation: 0.3006 sec; Batch: 2.1122 sec
0.1349 0.1201 0.0935 0.0817 0.0705 0.0618 0.0578 0.0542 0.0528 0.0517 0.0500 0.0494 0.0489 0.0480 0.0475 0.0471 

[TRAIN] Epoch[1](9304/114412); Loss: 0.051781; Backpropagation: 0.3008 sec; Batch: 2.1215 sec
0.0986 0.0914 0.0683 0.0622 0.0543 0.0501 0.0468 0.0440 0.0423 0.0409 0.0396 0.0389 0.0385 0.0379 0.0376 0.0374 

[TRAIN] Epoch[1](9305/114412); Loss: 0.065855; Backpropagation: 0.2980 sec; Batch: 2.1223 sec
0.1371 0.1050 0.0812 0.0740 0.0666 0.0626 0.0596 0.0564 0.0544 0.0533 0.0522 0.0513 0.0508 0.0501 0.0495 0.0493 

[TRAIN] Epoch[1](9306/114412); Loss: 0.067728; Backpropagation: 0.3007 sec; Batch: 2.1281 sec
0.1265 0.1146 0.0844 0.0747 0.0685 0.0633 0.0610 0.0586 0.0568 0.0559 0.0547 0.0538 0.0535 0.0529 0.0523 0.0521 

[TRAIN] Epoch[1](9307/114412); Loss: 0.064817; Backpropagation: 0.2958 sec; Batch: 2.1000 sec
0.1326 0.1148 0.0855 0.0715 0.0629 0.0585 0.0575 0.0544 0.0532 0.0523 0.0509 0.0497 0.0492 0.0484 0.0479 0.0476 

[TRAIN] Epoch[1](9308/114412); Loss: 0.056651; Backpropagation: 0.2949 sec; Batch: 2.1207 sec
0.1343 0.1140 0.0708 0.0658 0.0544 0.0511 0.0466 0.0454 0.0434 0.0421 0.0412 0.0405 0.0401 0.0393 0.0388 0.0386 

[TRAIN] Epoch[1](9309/114412); Loss: 0.081313; Backpropagation: 0.2952 sec; Batch: 2.1182 sec
0.1773 0.1468 0.0945 0.0866 0.0784 0.0740 0.0710 0.0681 0.0660 0.0646 0.0637 0.0630 0.0623 0.0620 0.0616 0.0611 

[TRAIN] Epoch[1](9310/114412); Loss: 0.067320; Backpropagation: 0.2954 sec; Batch: 2.1217 sec
0.1301 0.1236 0.0842 0.0743 0.0672 0.0637 0.0592 0.0568 0.0553 0.0537 0.0528 0.0522 0.0516 0.0511 0.0508 0.0504 

[TRAIN] Epoch[1](9311/114412); Loss: 0.082750; Backpropagation: 0.2982 sec; Batch: 2.1243 sec
0.1437 0.1243 0.1017 0.0920 0.0849 0.0805 0.0761 0.0733 0.0722 0.0703 0.0692 0.0686 0.0675 0.0670 0.0666 0.0660 

[TRAIN] Epoch[1](9312/114412); Loss: 0.054214; Backpropagation: 0.2967 sec; Batch: 2.1272 sec
0.1089 0.0846 0.0672 0.0611 0.0567 0.0533 0.0493 0.0468 0.0452 0.0440 0.0429 0.0422 0.0419 0.0413 0.0411 0.0410 

[TRAIN] Epoch[1](9313/114412); Loss: 0.061306; Backpropagation: 0.2960 sec; Batch: 2.1471 sec
0.1252 0.1111 0.0786 0.0702 0.0620 0.0581 0.0542 0.0519 0.0495 0.0478 0.0474 0.0462 0.0453 0.0450 0.0445 0.0441 

[TRAIN] Epoch[1](9314/114412); Loss: 0.064644; Backpropagation: 0.3007 sec; Batch: 2.0968 sec
0.1238 0.1202 0.0764 0.0690 0.0640 0.0603 0.0574 0.0549 0.0534 0.0523 0.0515 0.0510 0.0505 0.0500 0.0497 0.0497 

[TRAIN] Epoch[1](9315/114412); Loss: 0.063177; Backpropagation: 0.2979 sec; Batch: 2.1268 sec
0.1392 0.1178 0.0841 0.0701 0.0645 0.0575 0.0554 0.0519 0.0496 0.0482 0.0474 0.0462 0.0455 0.0448 0.0444 0.0440 

[TRAIN] Epoch[1](9316/114412); Loss: 0.076364; Backpropagation: 0.2983 sec; Batch: 2.1388 sec
0.1461 0.1173 0.0902 0.0824 0.0775 0.0724 0.0696 0.0671 0.0653 0.0642 0.0632 0.0625 0.0619 0.0612 0.0606 0.0603 

[TRAIN] Epoch[1](9317/114412); Loss: 0.047176; Backpropagation: 0.2983 sec; Batch: 2.1210 sec
0.1128 0.1062 0.0673 0.0514 0.0433 0.0408 0.0378 0.0357 0.0347 0.0334 0.0328 0.0324 0.0319 0.0317 0.0314 0.0313 

[TRAIN] Epoch[1](9318/114412); Loss: 0.071979; Backpropagation: 0.2980 sec; Batch: 2.1210 sec
0.1273 0.1159 0.0865 0.0781 0.0762 0.0703 0.0660 0.0635 0.0615 0.0600 0.0591 0.0583 0.0578 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](9319/114412); Loss: 0.078783; Backpropagation: 0.2957 sec; Batch: 2.1221 sec
0.1241 0.1083 0.0911 0.0843 0.0798 0.0760 0.0742 0.0723 0.0711 0.0702 0.0693 0.0688 0.0683 0.0678 0.0675 0.0672 

[TRAIN] Epoch[1](9320/114412); Loss: 0.072640; Backpropagation: 0.2951 sec; Batch: 2.1181 sec
0.1535 0.1469 0.0931 0.0815 0.0720 0.0637 0.0614 0.0590 0.0567 0.0555 0.0548 0.0539 0.0533 0.0528 0.0523 0.0521 

[TRAIN] Epoch[1](9321/114412); Loss: 0.087025; Backpropagation: 0.2955 sec; Batch: 2.1205 sec
0.1373 0.1251 0.1107 0.1010 0.0901 0.0836 0.0799 0.0779 0.0763 0.0750 0.0739 0.0732 0.0728 0.0723 0.0719 0.0716 

[TRAIN] Epoch[1](9322/114412); Loss: 0.079506; Backpropagation: 0.2960 sec; Batch: 2.1225 sec
0.1244 0.1112 0.0953 0.0880 0.0810 0.0780 0.0747 0.0728 0.0714 0.0697 0.0689 0.0685 0.0676 0.0673 0.0669 0.0665 

[TRAIN] Epoch[1](9323/114412); Loss: 0.072969; Backpropagation: 0.2958 sec; Batch: 2.1226 sec
0.1544 0.1299 0.0897 0.0713 0.0686 0.0649 0.0644 0.0613 0.0599 0.0589 0.0583 0.0577 0.0573 0.0571 0.0570 0.0568 

[TRAIN] Epoch[1](9324/114412); Loss: 0.075304; Backpropagation: 0.2981 sec; Batch: 2.1239 sec
0.1548 0.1339 0.1004 0.0874 0.0789 0.0730 0.0678 0.0636 0.0605 0.0585 0.0570 0.0557 0.0546 0.0536 0.0530 0.0523 

[TRAIN] Epoch[1](9325/114412); Loss: 0.082107; Backpropagation: 0.2953 sec; Batch: 2.1190 sec
0.1641 0.1506 0.1110 0.0943 0.0809 0.0770 0.0700 0.0672 0.0654 0.0641 0.0630 0.0623 0.0616 0.0611 0.0607 0.0605 

[TRAIN] Epoch[1](9326/114412); Loss: 0.078718; Backpropagation: 0.3003 sec; Batch: 2.1250 sec
0.1385 0.1263 0.1006 0.0930 0.0831 0.0779 0.0725 0.0684 0.0666 0.0648 0.0634 0.0624 0.0612 0.0608 0.0604 0.0597 

[TRAIN] Epoch[1](9327/114412); Loss: 0.063094; Backpropagation: 0.2979 sec; Batch: 2.1309 sec
0.1349 0.1091 0.0767 0.0740 0.0636 0.0575 0.0550 0.0529 0.0511 0.0499 0.0489 0.0480 0.0476 0.0472 0.0466 0.0465 

[TRAIN] Epoch[1](9328/114412); Loss: 0.070609; Backpropagation: 0.2956 sec; Batch: 2.1246 sec
0.1290 0.1141 0.0933 0.0773 0.0698 0.0668 0.0635 0.0623 0.0605 0.0587 0.0579 0.0565 0.0558 0.0554 0.0547 0.0544 

[TRAIN] Epoch[1](9329/114412); Loss: 0.081191; Backpropagation: 0.2957 sec; Batch: 2.0818 sec
0.1621 0.1395 0.1022 0.0916 0.0801 0.0741 0.0716 0.0689 0.0671 0.0654 0.0642 0.0637 0.0631 0.0623 0.0618 0.0614 

[TRAIN] Epoch[1](9330/114412); Loss: 0.078226; Backpropagation: 0.2954 sec; Batch: 2.1206 sec
0.1757 0.1496 0.1103 0.0884 0.0819 0.0720 0.0671 0.0633 0.0604 0.0585 0.0568 0.0553 0.0543 0.0535 0.0525 0.0521 

[TRAIN] Epoch[1](9331/114412); Loss: 0.069226; Backpropagation: 0.2955 sec; Batch: 2.1225 sec
0.1379 0.1283 0.0869 0.0814 0.0687 0.0636 0.0605 0.0579 0.0556 0.0546 0.0535 0.0527 0.0520 0.0517 0.0513 0.0509 

[TRAIN] Epoch[1](9332/114412); Loss: 0.082723; Backpropagation: 0.2955 sec; Batch: 2.1355 sec
0.1444 0.1264 0.1058 0.0946 0.0850 0.0796 0.0761 0.0735 0.0712 0.0696 0.0683 0.0673 0.0664 0.0659 0.0649 0.0644 

[TRAIN] Epoch[1](9333/114412); Loss: 0.076280; Backpropagation: 0.2976 sec; Batch: 2.1294 sec
0.1366 0.1181 0.0934 0.0852 0.0790 0.0740 0.0702 0.0672 0.0652 0.0642 0.0631 0.0620 0.0613 0.0608 0.0602 0.0598 

[TRAIN] Epoch[1](9334/114412); Loss: 0.058139; Backpropagation: 0.3005 sec; Batch: 2.1286 sec
0.1156 0.0912 0.0837 0.0669 0.0628 0.0591 0.0535 0.0506 0.0474 0.0457 0.0447 0.0432 0.0423 0.0417 0.0412 0.0408 

[TRAIN] Epoch[1](9335/114412); Loss: 0.073241; Backpropagation: 0.2981 sec; Batch: 2.1218 sec
0.1261 0.1166 0.0882 0.0815 0.0750 0.0708 0.0672 0.0652 0.0632 0.0618 0.0608 0.0600 0.0594 0.0590 0.0586 0.0583 

[TRAIN] Epoch[1](9336/114412); Loss: 0.074790; Backpropagation: 0.2956 sec; Batch: 2.1227 sec
0.1419 0.1307 0.0994 0.0838 0.0759 0.0717 0.0677 0.0651 0.0619 0.0600 0.0588 0.0574 0.0565 0.0558 0.0552 0.0547 

[TRAIN] Epoch[1](9337/114412); Loss: 0.065744; Backpropagation: 0.2952 sec; Batch: 2.1212 sec
0.1237 0.1136 0.0856 0.0759 0.0671 0.0604 0.0581 0.0561 0.0540 0.0531 0.0524 0.0515 0.0509 0.0502 0.0497 0.0495 

[TRAIN] Epoch[1](9338/114412); Loss: 0.088585; Backpropagation: 0.2948 sec; Batch: 2.1185 sec
0.1435 0.1279 0.1076 0.0955 0.0888 0.0847 0.0828 0.0807 0.0790 0.0778 0.0765 0.0759 0.0751 0.0744 0.0739 0.0733 

[TRAIN] Epoch[1](9339/114412); Loss: 0.069208; Backpropagation: 0.2979 sec; Batch: 2.1246 sec
0.1172 0.1052 0.0851 0.0749 0.0696 0.0668 0.0637 0.0619 0.0604 0.0593 0.0586 0.0578 0.0572 0.0568 0.0565 0.0563 

[TRAIN] Epoch[1](9340/114412); Loss: 0.055463; Backpropagation: 0.2981 sec; Batch: 2.1252 sec
0.1189 0.1129 0.0782 0.0681 0.0564 0.0486 0.0462 0.0433 0.0418 0.0411 0.0402 0.0390 0.0388 0.0383 0.0379 0.0377 

[TRAIN] Epoch[1](9341/114412); Loss: 0.069211; Backpropagation: 0.2958 sec; Batch: 2.1210 sec
0.1351 0.1129 0.0860 0.0806 0.0728 0.0644 0.0621 0.0599 0.0576 0.0563 0.0553 0.0539 0.0534 0.0528 0.0523 0.0520 

[TRAIN] Epoch[1](9342/114412); Loss: 0.091393; Backpropagation: 0.2956 sec; Batch: 2.0825 sec
0.1574 0.1423 0.1085 0.0994 0.0920 0.0871 0.0844 0.0823 0.0801 0.0784 0.0773 0.0762 0.0753 0.0745 0.0738 0.0733 

[TRAIN] Epoch[1](9343/114412); Loss: 0.061710; Backpropagation: 0.2957 sec; Batch: 2.1190 sec
0.1112 0.0940 0.0757 0.0705 0.0655 0.0624 0.0588 0.0556 0.0530 0.0514 0.0500 0.0489 0.0484 0.0477 0.0473 0.0469 

[TRAIN] Epoch[1](9344/114412); Loss: 0.101828; Backpropagation: 0.2966 sec; Batch: 2.1233 sec
0.1482 0.1324 0.1215 0.1147 0.1064 0.1010 0.0963 0.0941 0.0925 0.0909 0.0900 0.0893 0.0887 0.0882 0.0876 0.0874 

[TRAIN] Epoch[1](9345/114412); Loss: 0.086666; Backpropagation: 0.2956 sec; Batch: 2.1193 sec
0.1512 0.1367 0.1130 0.1020 0.0886 0.0822 0.0777 0.0753 0.0732 0.0717 0.0708 0.0701 0.0694 0.0687 0.0682 0.0678 

[TRAIN] Epoch[1](9346/114412); Loss: 0.058691; Backpropagation: 0.2955 sec; Batch: 2.1209 sec
0.1051 0.0964 0.0724 0.0698 0.0619 0.0556 0.0534 0.0507 0.0489 0.0480 0.0472 0.0466 0.0462 0.0458 0.0456 0.0456 

[TRAIN] Epoch[1](9347/114412); Loss: 0.062140; Backpropagation: 0.2957 sec; Batch: 2.1183 sec
0.1155 0.1065 0.0744 0.0691 0.0622 0.0583 0.0556 0.0538 0.0526 0.0511 0.0503 0.0497 0.0493 0.0490 0.0486 0.0484 

[TRAIN] Epoch[1](9348/114412); Loss: 0.101511; Backpropagation: 0.2955 sec; Batch: 2.1179 sec
0.1725 0.1687 0.1239 0.1119 0.0975 0.0935 0.0915 0.0893 0.0874 0.0863 0.0853 0.0845 0.0836 0.0831 0.0827 0.0823 

[TRAIN] Epoch[1](9349/114412); Loss: 0.081772; Backpropagation: 0.2951 sec; Batch: 2.1216 sec
0.1413 0.1215 0.0992 0.0894 0.0821 0.0780 0.0753 0.0732 0.0717 0.0705 0.0693 0.0684 0.0678 0.0673 0.0669 0.0666 

[TRAIN] Epoch[1](9350/114412); Loss: 0.086810; Backpropagation: 0.2966 sec; Batch: 2.1227 sec
0.1357 0.1283 0.1078 0.0960 0.0888 0.0823 0.0791 0.0786 0.0769 0.0762 0.0748 0.0739 0.0735 0.0727 0.0722 0.0721 

[TRAIN] Epoch[1](9351/114412); Loss: 0.066723; Backpropagation: 0.2957 sec; Batch: 2.1258 sec
0.1123 0.1086 0.0818 0.0748 0.0682 0.0635 0.0609 0.0587 0.0577 0.0566 0.0557 0.0548 0.0542 0.0536 0.0533 0.0530 

[TRAIN] Epoch[1](9352/114412); Loss: 0.086818; Backpropagation: 0.2952 sec; Batch: 2.1205 sec
0.1634 0.1433 0.1071 0.0949 0.0880 0.0816 0.0777 0.0757 0.0740 0.0719 0.0706 0.0698 0.0685 0.0681 0.0676 0.0669 

[TRAIN] Epoch[1](9353/114412); Loss: 0.078893; Backpropagation: 0.2957 sec; Batch: 2.0814 sec
0.1350 0.1251 0.0965 0.0889 0.0802 0.0754 0.0723 0.0698 0.0683 0.0668 0.0657 0.0650 0.0641 0.0635 0.0631 0.0626 

[TRAIN] Epoch[1](9354/114412); Loss: 0.078448; Backpropagation: 0.2957 sec; Batch: 2.1178 sec
0.1668 0.1414 0.1009 0.0814 0.0755 0.0716 0.0691 0.0654 0.0637 0.0625 0.0612 0.0604 0.0597 0.0590 0.0585 0.0581 

[TRAIN] Epoch[1](9355/114412); Loss: 0.064020; Backpropagation: 0.2982 sec; Batch: 2.1133 sec
0.1218 0.1044 0.0741 0.0695 0.0639 0.0605 0.0572 0.0559 0.0546 0.0536 0.0528 0.0521 0.0515 0.0512 0.0507 0.0504 

[TRAIN] Epoch[1](9356/114412); Loss: 0.081720; Backpropagation: 0.2957 sec; Batch: 2.1195 sec
0.1768 0.1393 0.0983 0.0963 0.0828 0.0788 0.0718 0.0671 0.0665 0.0639 0.0627 0.0617 0.0610 0.0605 0.0603 0.0598 

[TRAIN] Epoch[1](9357/114412); Loss: 0.087645; Backpropagation: 0.2960 sec; Batch: 2.1250 sec
0.1502 0.1409 0.1150 0.0976 0.0866 0.0813 0.0782 0.0764 0.0749 0.0739 0.0726 0.0718 0.0714 0.0708 0.0705 0.0702 

[TRAIN] Epoch[1](9358/114412); Loss: 0.089744; Backpropagation: 0.2957 sec; Batch: 2.0910 sec
0.1438 0.1360 0.1128 0.1017 0.0908 0.0861 0.0828 0.0803 0.0782 0.0771 0.0759 0.0752 0.0745 0.0740 0.0736 0.0731 

[TRAIN] Epoch[1](9359/114412); Loss: 0.070564; Backpropagation: 0.2958 sec; Batch: 2.0828 sec
0.1548 0.1373 0.0859 0.0791 0.0679 0.0619 0.0597 0.0577 0.0564 0.0551 0.0537 0.0530 0.0523 0.0517 0.0515 0.0511 

[TRAIN] Epoch[1](9360/114412); Loss: 0.066902; Backpropagation: 0.2972 sec; Batch: 2.0998 sec
0.1353 0.1222 0.0844 0.0766 0.0670 0.0627 0.0588 0.0563 0.0541 0.0529 0.0515 0.0508 0.0503 0.0496 0.0492 0.0488 

[TRAIN] Epoch[1](9361/114412); Loss: 0.058442; Backpropagation: 0.2947 sec; Batch: 2.1186 sec
0.1553 0.1251 0.0704 0.0670 0.0570 0.0509 0.0474 0.0443 0.0431 0.0416 0.0405 0.0397 0.0389 0.0384 0.0379 0.0376 

[TRAIN] Epoch[1](9362/114412); Loss: 0.080656; Backpropagation: 0.2953 sec; Batch: 2.1210 sec
0.1288 0.1143 0.0978 0.0869 0.0811 0.0774 0.0752 0.0736 0.0720 0.0710 0.0698 0.0693 0.0689 0.0683 0.0681 0.0679 

[TRAIN] Epoch[1](9363/114412); Loss: 0.074802; Backpropagation: 0.2950 sec; Batch: 2.1041 sec
0.1492 0.1308 0.0998 0.0821 0.0731 0.0670 0.0645 0.0623 0.0614 0.0603 0.0592 0.0582 0.0578 0.0573 0.0570 0.0568 

[TRAIN] Epoch[1](9364/114412); Loss: 0.100955; Backpropagation: 0.2954 sec; Batch: 2.1262 sec
0.2077 0.1899 0.1397 0.1183 0.1031 0.0912 0.0883 0.0842 0.0786 0.0777 0.0756 0.0742 0.0729 0.0721 0.0711 0.0707 

[TRAIN] Epoch[1](9365/114412); Loss: 0.087493; Backpropagation: 0.2951 sec; Batch: 2.1209 sec
0.1801 0.1510 0.1113 0.0976 0.0890 0.0811 0.0774 0.0750 0.0718 0.0697 0.0686 0.0673 0.0664 0.0655 0.0645 0.0637 

[TRAIN] Epoch[1](9366/114412); Loss: 0.079747; Backpropagation: 0.2949 sec; Batch: 2.1310 sec
0.1566 0.1315 0.1028 0.0885 0.0806 0.0742 0.0707 0.0682 0.0661 0.0646 0.0636 0.0629 0.0623 0.0616 0.0612 0.0607 

[TRAIN] Epoch[1](9367/114412); Loss: 0.081977; Backpropagation: 0.2953 sec; Batch: 2.1516 sec
0.1307 0.1185 0.0977 0.0938 0.0852 0.0805 0.0773 0.0743 0.0727 0.0714 0.0702 0.0692 0.0685 0.0678 0.0671 0.0668 

[TRAIN] Epoch[1](9368/114412); Loss: 0.075250; Backpropagation: 0.2981 sec; Batch: 2.1213 sec
0.1328 0.1226 0.0959 0.0857 0.0765 0.0709 0.0684 0.0658 0.0639 0.0625 0.0614 0.0607 0.0600 0.0594 0.0589 0.0587 

[TRAIN] Epoch[1](9369/114412); Loss: 0.067102; Backpropagation: 0.2980 sec; Batch: 2.1208 sec
0.1277 0.1187 0.0907 0.0722 0.0689 0.0622 0.0594 0.0567 0.0549 0.0538 0.0529 0.0522 0.0516 0.0510 0.0505 0.0502 

[TRAIN] Epoch[1](9370/114412); Loss: 0.071249; Backpropagation: 0.2955 sec; Batch: 2.1194 sec
0.1514 0.1235 0.0911 0.0765 0.0699 0.0635 0.0619 0.0589 0.0575 0.0568 0.0559 0.0553 0.0550 0.0545 0.0543 0.0540 

[TRAIN] Epoch[1](9371/114412); Loss: 0.086111; Backpropagation: 0.2953 sec; Batch: 2.1224 sec
0.1552 0.1336 0.1110 0.0980 0.0887 0.0821 0.0790 0.0761 0.0733 0.0712 0.0702 0.0692 0.0685 0.0678 0.0672 0.0667 

[TRAIN] Epoch[1](9372/114412); Loss: 0.089331; Backpropagation: 0.2947 sec; Batch: 2.1238 sec
0.1477 0.1389 0.1107 0.0996 0.0911 0.0856 0.0828 0.0801 0.0778 0.0764 0.0751 0.0741 0.0734 0.0725 0.0719 0.0715 

[TRAIN] Epoch[1](9373/114412); Loss: 0.091701; Backpropagation: 0.2958 sec; Batch: 2.1181 sec
0.1381 0.1268 0.1113 0.1022 0.0994 0.0927 0.0880 0.0858 0.0816 0.0806 0.0785 0.0777 0.0768 0.0764 0.0758 0.0755 

[TRAIN] Epoch[1](9374/114412); Loss: 0.097074; Backpropagation: 0.2956 sec; Batch: 2.1218 sec
0.1632 0.1483 0.1212 0.1095 0.0999 0.0938 0.0900 0.0864 0.0839 0.0825 0.0812 0.0801 0.0791 0.0786 0.0779 0.0774 

[TRAIN] Epoch[1](9375/114412); Loss: 0.073760; Backpropagation: 0.2959 sec; Batch: 2.1231 sec
0.1446 0.1350 0.1006 0.0815 0.0710 0.0655 0.0642 0.0617 0.0601 0.0590 0.0574 0.0568 0.0564 0.0558 0.0555 0.0552 

[TRAIN] Epoch[1](9376/114412); Loss: 0.083632; Backpropagation: 0.2965 sec; Batch: 2.0870 sec
0.1541 0.1330 0.1060 0.0939 0.0853 0.0783 0.0749 0.0724 0.0707 0.0694 0.0685 0.0674 0.0669 0.0662 0.0657 0.0654 

[TRAIN] Epoch[1](9377/114412); Loss: 0.073700; Backpropagation: 0.2954 sec; Batch: 2.1239 sec
0.1130 0.0997 0.1008 0.0884 0.0770 0.0721 0.0695 0.0665 0.0647 0.0630 0.0621 0.0613 0.0608 0.0604 0.0601 0.0598 

[TRAIN] Epoch[1](9378/114412); Loss: 0.103003; Backpropagation: 0.2981 sec; Batch: 2.1275 sec
0.1727 0.1463 0.1215 0.1117 0.1049 0.1008 0.0973 0.0930 0.0916 0.0898 0.0883 0.0872 0.0864 0.0859 0.0854 0.0849 

[TRAIN] Epoch[1](9379/114412); Loss: 0.083247; Backpropagation: 0.2977 sec; Batch: 2.1228 sec
0.1328 0.1198 0.1039 0.0948 0.0885 0.0812 0.0779 0.0757 0.0733 0.0720 0.0704 0.0692 0.0688 0.0682 0.0678 0.0676 

[TRAIN] Epoch[1](9380/114412); Loss: 0.107729; Backpropagation: 0.2992 sec; Batch: 2.1263 sec
0.1953 0.1703 0.1372 0.1250 0.1120 0.1034 0.0960 0.0937 0.0916 0.0892 0.0878 0.0864 0.0855 0.0842 0.0835 0.0825 

[TRAIN] Epoch[1](9381/114412); Loss: 0.054976; Backpropagation: 0.2958 sec; Batch: 2.1214 sec
0.1142 0.1027 0.0665 0.0591 0.0576 0.0526 0.0496 0.0464 0.0439 0.0429 0.0421 0.0411 0.0407 0.0403 0.0401 0.0400 

[TRAIN] Epoch[1](9382/114412); Loss: 0.085875; Backpropagation: 0.2957 sec; Batch: 2.1213 sec
0.1423 0.1381 0.1118 0.1006 0.0851 0.0795 0.0771 0.0751 0.0737 0.0719 0.0711 0.0704 0.0697 0.0694 0.0692 0.0690 

[TRAIN] Epoch[1](9383/114412); Loss: 0.075168; Backpropagation: 0.2986 sec; Batch: 2.1411 sec
0.1279 0.1155 0.0916 0.0852 0.0784 0.0742 0.0714 0.0678 0.0653 0.0636 0.0620 0.0612 0.0605 0.0598 0.0594 0.0590 

[TRAIN] Epoch[1](9384/114412); Loss: 0.062812; Backpropagation: 0.2957 sec; Batch: 2.1210 sec
0.1261 0.1123 0.0854 0.0776 0.0670 0.0572 0.0543 0.0522 0.0496 0.0483 0.0473 0.0463 0.0459 0.0455 0.0451 0.0451 

[TRAIN] Epoch[1](9385/114412); Loss: 0.059316; Backpropagation: 0.3008 sec; Batch: 2.1268 sec
0.0872 0.0896 0.0929 0.0771 0.0666 0.0589 0.0552 0.0514 0.0491 0.0478 0.0469 0.0461 0.0456 0.0450 0.0449 0.0448 

[TRAIN] Epoch[1](9386/114412); Loss: 0.068520; Backpropagation: 0.2953 sec; Batch: 2.1206 sec
0.1386 0.1170 0.0867 0.0845 0.0758 0.0662 0.0624 0.0582 0.0555 0.0537 0.0520 0.0507 0.0497 0.0491 0.0484 0.0478 

[TRAIN] Epoch[1](9387/114412); Loss: 0.072414; Backpropagation: 0.2949 sec; Batch: 2.1209 sec
0.1545 0.1275 0.1010 0.0894 0.0787 0.0710 0.0630 0.0598 0.0572 0.0545 0.0535 0.0516 0.0503 0.0497 0.0488 0.0481 

[TRAIN] Epoch[1](9388/114412); Loss: 0.067012; Backpropagation: 0.2955 sec; Batch: 2.0819 sec
0.1320 0.1054 0.0785 0.0692 0.0680 0.0631 0.0616 0.0590 0.0570 0.0556 0.0548 0.0541 0.0537 0.0535 0.0534 0.0532 

[TRAIN] Epoch[1](9389/114412); Loss: 0.074536; Backpropagation: 0.2950 sec; Batch: 2.0868 sec
0.1400 0.1224 0.0967 0.0860 0.0759 0.0716 0.0676 0.0646 0.0623 0.0606 0.0592 0.0584 0.0577 0.0570 0.0564 0.0560 

[TRAIN] Epoch[1](9390/114412); Loss: 0.096100; Backpropagation: 0.2980 sec; Batch: 2.1196 sec
0.1723 0.1587 0.1206 0.1051 0.0975 0.0908 0.0878 0.0855 0.0823 0.0804 0.0787 0.0771 0.0764 0.0754 0.0747 0.0743 

[TRAIN] Epoch[1](9391/114412); Loss: 0.083754; Backpropagation: 0.2958 sec; Batch: 2.1196 sec
0.1389 0.1207 0.1056 0.0951 0.0860 0.0814 0.0782 0.0755 0.0735 0.0719 0.0709 0.0697 0.0689 0.0685 0.0679 0.0674 

[TRAIN] Epoch[1](9392/114412); Loss: 0.065680; Backpropagation: 0.2958 sec; Batch: 2.1253 sec
0.1289 0.1147 0.0906 0.0773 0.0702 0.0623 0.0583 0.0546 0.0525 0.0508 0.0499 0.0492 0.0487 0.0480 0.0476 0.0474 

[TRAIN] Epoch[1](9393/114412); Loss: 0.083949; Backpropagation: 0.2957 sec; Batch: 2.1202 sec
0.1749 0.1538 0.1068 0.0905 0.0858 0.0769 0.0723 0.0701 0.0674 0.0662 0.0649 0.0639 0.0632 0.0628 0.0621 0.0616 

[TRAIN] Epoch[1](9394/114412); Loss: 0.057680; Backpropagation: 0.2962 sec; Batch: 2.1217 sec
0.1021 0.0910 0.0715 0.0641 0.0613 0.0551 0.0530 0.0510 0.0491 0.0481 0.0473 0.0465 0.0460 0.0459 0.0456 0.0453 

[TRAIN] Epoch[1](9395/114412); Loss: 0.073430; Backpropagation: 0.2957 sec; Batch: 2.0826 sec
0.1318 0.1217 0.0926 0.0858 0.0761 0.0700 0.0668 0.0643 0.0618 0.0606 0.0590 0.0579 0.0575 0.0568 0.0562 0.0558 

[TRAIN] Epoch[1](9396/114412); Loss: 0.088285; Backpropagation: 0.2952 sec; Batch: 2.1273 sec
0.1348 0.1240 0.1005 0.0953 0.0910 0.0866 0.0837 0.0822 0.0801 0.0787 0.0775 0.0767 0.0760 0.0755 0.0752 0.0749 

[TRAIN] Epoch[1](9397/114412); Loss: 0.068583; Backpropagation: 0.3005 sec; Batch: 2.1240 sec
0.1504 0.1212 0.0870 0.0746 0.0672 0.0631 0.0594 0.0567 0.0551 0.0542 0.0532 0.0526 0.0516 0.0508 0.0502 0.0500 

[TRAIN] Epoch[1](9398/114412); Loss: 0.078050; Backpropagation: 0.2962 sec; Batch: 2.1207 sec
0.1364 0.1270 0.1007 0.0892 0.0803 0.0742 0.0707 0.0680 0.0662 0.0650 0.0637 0.0629 0.0619 0.0613 0.0609 0.0605 

[TRAIN] Epoch[1](9399/114412); Loss: 0.078657; Backpropagation: 0.2958 sec; Batch: 2.0851 sec
0.1649 0.1460 0.1121 0.0947 0.0837 0.0736 0.0670 0.0649 0.0623 0.0590 0.0577 0.0564 0.0551 0.0544 0.0536 0.0531 

[TRAIN] Epoch[1](9400/114412); Loss: 0.077431; Backpropagation: 0.2960 sec; Batch: 2.0829 sec
0.1664 0.1383 0.0996 0.0848 0.0771 0.0718 0.0676 0.0641 0.0618 0.0605 0.0596 0.0587 0.0580 0.0573 0.0567 0.0565 

[TRAIN] Epoch[1](9401/114412); Loss: 0.062511; Backpropagation: 0.2958 sec; Batch: 2.1317 sec
0.1014 0.0940 0.0806 0.0759 0.0657 0.0627 0.0574 0.0543 0.0535 0.0522 0.0514 0.0509 0.0504 0.0500 0.0499 0.0498 

[TRAIN] Epoch[1](9402/114412); Loss: 0.071243; Backpropagation: 0.2977 sec; Batch: 2.1229 sec
0.1468 0.1370 0.1002 0.0846 0.0715 0.0634 0.0606 0.0576 0.0558 0.0548 0.0532 0.0522 0.0514 0.0507 0.0503 0.0499 

[TRAIN] Epoch[1](9403/114412); Loss: 0.085462; Backpropagation: 0.2970 sec; Batch: 2.1296 sec
0.1958 0.1637 0.1101 0.0889 0.0837 0.0731 0.0712 0.0685 0.0667 0.0655 0.0647 0.0641 0.0635 0.0630 0.0626 0.0621 

[TRAIN] Epoch[1](9404/114412); Loss: 0.064687; Backpropagation: 0.2983 sec; Batch: 2.1233 sec
0.1354 0.1142 0.0787 0.0689 0.0631 0.0596 0.0574 0.0549 0.0533 0.0521 0.0509 0.0503 0.0497 0.0494 0.0488 0.0485 

[TRAIN] Epoch[1](9405/114412); Loss: 0.063822; Backpropagation: 0.2960 sec; Batch: 2.0829 sec
0.1344 0.1104 0.0803 0.0759 0.0680 0.0600 0.0552 0.0525 0.0512 0.0498 0.0486 0.0478 0.0473 0.0468 0.0465 0.0463 

[TRAIN] Epoch[1](9406/114412); Loss: 0.073455; Backpropagation: 0.2958 sec; Batch: 2.1204 sec
0.1314 0.1183 0.0907 0.0817 0.0744 0.0691 0.0663 0.0640 0.0628 0.0616 0.0605 0.0598 0.0592 0.0588 0.0586 0.0582 

[TRAIN] Epoch[1](9407/114412); Loss: 0.072096; Backpropagation: 0.3011 sec; Batch: 2.0878 sec
0.1508 0.1254 0.0901 0.0781 0.0712 0.0660 0.0631 0.0613 0.0591 0.0580 0.0567 0.0558 0.0551 0.0545 0.0542 0.0540 

[TRAIN] Epoch[1](9408/114412); Loss: 0.094824; Backpropagation: 0.2986 sec; Batch: 2.1231 sec
0.1777 0.1582 0.1206 0.1048 0.0938 0.0881 0.0846 0.0817 0.0796 0.0781 0.0768 0.0759 0.0752 0.0746 0.0740 0.0734 

[TRAIN] Epoch[1](9409/114412); Loss: 0.115906; Backpropagation: 0.2976 sec; Batch: 2.1234 sec
0.1980 0.1716 0.1370 0.1192 0.1148 0.1090 0.1064 0.1038 0.1027 0.1011 0.0999 0.0993 0.0987 0.0982 0.0977 0.0973 

[TRAIN] Epoch[1](9410/114412); Loss: 0.082558; Backpropagation: 0.3011 sec; Batch: 2.0886 sec
0.1479 0.1409 0.1087 0.0981 0.0887 0.0819 0.0773 0.0725 0.0695 0.0667 0.0645 0.0632 0.0615 0.0608 0.0594 0.0592 

[TRAIN] Epoch[1](9411/114412); Loss: 0.072304; Backpropagation: 0.3008 sec; Batch: 2.1290 sec
0.1432 0.1327 0.0955 0.0793 0.0697 0.0654 0.0630 0.0612 0.0594 0.0577 0.0566 0.0557 0.0551 0.0545 0.0541 0.0537 

[TRAIN] Epoch[1](9412/114412); Loss: 0.055725; Backpropagation: 0.2953 sec; Batch: 2.0822 sec
0.1168 0.1035 0.0723 0.0606 0.0550 0.0509 0.0481 0.0462 0.0446 0.0436 0.0427 0.0422 0.0418 0.0414 0.0411 0.0408 

[TRAIN] Epoch[1](9413/114412); Loss: 0.060880; Backpropagation: 0.2952 sec; Batch: 2.1229 sec
0.1181 0.1060 0.0810 0.0731 0.0631 0.0570 0.0536 0.0514 0.0497 0.0486 0.0472 0.0464 0.0456 0.0449 0.0444 0.0440 

[TRAIN] Epoch[1](9414/114412); Loss: 0.056914; Backpropagation: 0.2979 sec; Batch: 2.1215 sec
0.1298 0.1148 0.0792 0.0639 0.0547 0.0497 0.0479 0.0454 0.0439 0.0419 0.0411 0.0403 0.0398 0.0396 0.0393 0.0392 

[TRAIN] Epoch[1](9415/114412); Loss: 0.065210; Backpropagation: 0.2953 sec; Batch: 2.1183 sec
0.1678 0.1439 0.0840 0.0725 0.0617 0.0570 0.0545 0.0505 0.0472 0.0460 0.0447 0.0438 0.0431 0.0427 0.0421 0.0419 

[TRAIN] Epoch[1](9416/114412); Loss: 0.069937; Backpropagation: 0.2952 sec; Batch: 2.1209 sec
0.1222 0.1151 0.0854 0.0771 0.0713 0.0663 0.0632 0.0615 0.0598 0.0588 0.0579 0.0570 0.0564 0.0560 0.0557 0.0554 

[TRAIN] Epoch[1](9417/114412); Loss: 0.053949; Backpropagation: 0.3004 sec; Batch: 2.1346 sec
0.1253 0.1074 0.0719 0.0601 0.0532 0.0505 0.0456 0.0437 0.0412 0.0403 0.0388 0.0380 0.0373 0.0369 0.0365 0.0363 

[TRAIN] Epoch[1](9418/114412); Loss: 0.071194; Backpropagation: 0.2982 sec; Batch: 2.1238 sec
0.1377 0.1315 0.0979 0.0816 0.0688 0.0648 0.0614 0.0599 0.0575 0.0562 0.0552 0.0544 0.0537 0.0532 0.0529 0.0525 

[TRAIN] Epoch[1](9419/114412); Loss: 0.087891; Backpropagation: 0.2951 sec; Batch: 2.1671 sec
0.2101 0.1673 0.1131 0.0940 0.0871 0.0774 0.0735 0.0702 0.0679 0.0665 0.0651 0.0642 0.0634 0.0627 0.0621 0.0616 

[TRAIN] Epoch[1](9420/114412); Loss: 0.052962; Backpropagation: 0.2956 sec; Batch: 2.1055 sec
0.1261 0.1188 0.0752 0.0582 0.0463 0.0446 0.0437 0.0408 0.0390 0.0373 0.0369 0.0364 0.0362 0.0361 0.0359 0.0357 

[TRAIN] Epoch[1](9421/114412); Loss: 0.067801; Backpropagation: 0.2953 sec; Batch: 2.1203 sec
0.1131 0.1033 0.0819 0.0781 0.0706 0.0654 0.0631 0.0611 0.0590 0.0580 0.0567 0.0559 0.0553 0.0549 0.0544 0.0539 

[TRAIN] Epoch[1](9422/114412); Loss: 0.072978; Backpropagation: 0.2948 sec; Batch: 2.0817 sec
0.1265 0.1167 0.0925 0.0795 0.0734 0.0684 0.0656 0.0638 0.0623 0.0615 0.0607 0.0602 0.0598 0.0591 0.0590 0.0586 

[TRAIN] Epoch[1](9423/114412); Loss: 0.058703; Backpropagation: 0.2948 sec; Batch: 2.1220 sec
0.1183 0.1144 0.0750 0.0647 0.0574 0.0529 0.0509 0.0485 0.0468 0.0461 0.0452 0.0445 0.0442 0.0438 0.0433 0.0432 

[TRAIN] Epoch[1](9424/114412); Loss: 0.060023; Backpropagation: 0.2950 sec; Batch: 2.0909 sec
0.1199 0.1061 0.0840 0.0719 0.0591 0.0541 0.0514 0.0502 0.0484 0.0474 0.0463 0.0453 0.0448 0.0442 0.0438 0.0436 

[TRAIN] Epoch[1](9425/114412); Loss: 0.073097; Backpropagation: 0.2957 sec; Batch: 2.1166 sec
0.1335 0.1209 0.0937 0.0811 0.0727 0.0691 0.0647 0.0625 0.0616 0.0601 0.0592 0.0590 0.0582 0.0579 0.0578 0.0575 

[TRAIN] Epoch[1](9426/114412); Loss: 0.085605; Backpropagation: 0.2949 sec; Batch: 2.0815 sec
0.1543 0.1443 0.1093 0.1001 0.0903 0.0812 0.0778 0.0749 0.0714 0.0698 0.0684 0.0669 0.0662 0.0654 0.0650 0.0644 

[TRAIN] Epoch[1](9427/114412); Loss: 0.065682; Backpropagation: 0.2981 sec; Batch: 2.0856 sec
0.1497 0.1343 0.0941 0.0772 0.0639 0.0571 0.0535 0.0519 0.0493 0.0476 0.0466 0.0460 0.0455 0.0450 0.0446 0.0445 

[TRAIN] Epoch[1](9428/114412); Loss: 0.067769; Backpropagation: 0.2981 sec; Batch: 2.1272 sec
0.1271 0.1095 0.0873 0.0778 0.0703 0.0642 0.0609 0.0595 0.0571 0.0556 0.0545 0.0534 0.0528 0.0520 0.0514 0.0509 

[TRAIN] Epoch[1](9429/114412); Loss: 0.088408; Backpropagation: 0.2982 sec; Batch: 2.1242 sec
0.1685 0.1504 0.1102 0.0956 0.0860 0.0814 0.0776 0.0759 0.0738 0.0728 0.0720 0.0711 0.0707 0.0701 0.0695 0.0689 

[TRAIN] Epoch[1](9430/114412); Loss: 0.061812; Backpropagation: 0.2960 sec; Batch: 2.0856 sec
0.1215 0.1117 0.0762 0.0676 0.0615 0.0573 0.0544 0.0527 0.0509 0.0497 0.0489 0.0482 0.0477 0.0472 0.0468 0.0467 

[TRAIN] Epoch[1](9431/114412); Loss: 0.063663; Backpropagation: 0.2975 sec; Batch: 2.0866 sec
0.1793 0.1542 0.0932 0.0719 0.0560 0.0494 0.0462 0.0441 0.0427 0.0418 0.0411 0.0405 0.0401 0.0396 0.0393 0.0391 

[TRAIN] Epoch[1](9432/114412); Loss: 0.100717; Backpropagation: 0.2956 sec; Batch: 2.1190 sec
0.1837 0.1583 0.1179 0.1063 0.0988 0.0926 0.0905 0.0879 0.0865 0.0856 0.0850 0.0844 0.0840 0.0838 0.0833 0.0830 

[TRAIN] Epoch[1](9433/114412); Loss: 0.072788; Backpropagation: 0.2957 sec; Batch: 2.1228 sec
0.1424 0.1226 0.1079 0.0900 0.0783 0.0665 0.0635 0.0604 0.0576 0.0566 0.0550 0.0541 0.0534 0.0527 0.0520 0.0516 

[TRAIN] Epoch[1](9434/114412); Loss: 0.113984; Backpropagation: 0.2956 sec; Batch: 2.1206 sec
0.2076 0.1839 0.1458 0.1250 0.1146 0.1067 0.1020 0.0988 0.0965 0.0948 0.0935 0.0925 0.0914 0.0907 0.0902 0.0896 

[TRAIN] Epoch[1](9435/114412); Loss: 0.071009; Backpropagation: 0.2956 sec; Batch: 2.1212 sec
0.1347 0.1230 0.0910 0.0798 0.0730 0.0658 0.0638 0.0614 0.0583 0.0576 0.0565 0.0549 0.0548 0.0543 0.0535 0.0535 

[TRAIN] Epoch[1](9436/114412); Loss: 0.075111; Backpropagation: 0.2957 sec; Batch: 2.1221 sec
0.1256 0.1122 0.0927 0.0828 0.0781 0.0748 0.0697 0.0682 0.0661 0.0640 0.0630 0.0621 0.0614 0.0608 0.0603 0.0598 

[TRAIN] Epoch[1](9437/114412); Loss: 0.097298; Backpropagation: 0.2951 sec; Batch: 2.1246 sec
0.1895 0.1642 0.1209 0.1006 0.0953 0.0893 0.0887 0.0851 0.0822 0.0801 0.0789 0.0778 0.0769 0.0764 0.0757 0.0752 

[TRAIN] Epoch[1](9438/114412); Loss: 0.067653; Backpropagation: 0.2951 sec; Batch: 2.1224 sec
0.1333 0.1190 0.0873 0.0770 0.0681 0.0623 0.0594 0.0574 0.0552 0.0540 0.0531 0.0524 0.0517 0.0511 0.0508 0.0505 

[TRAIN] Epoch[1](9439/114412); Loss: 0.078939; Backpropagation: 0.2979 sec; Batch: 2.1254 sec
0.1370 0.1248 0.0982 0.0855 0.0785 0.0757 0.0724 0.0699 0.0681 0.0670 0.0661 0.0651 0.0644 0.0639 0.0633 0.0631 

[TRAIN] Epoch[1](9440/114412); Loss: 0.083460; Backpropagation: 0.2956 sec; Batch: 2.1202 sec
0.1457 0.1254 0.1113 0.0999 0.0872 0.0783 0.0748 0.0723 0.0704 0.0692 0.0685 0.0674 0.0668 0.0665 0.0661 0.0657 

[TRAIN] Epoch[1](9441/114412); Loss: 0.071045; Backpropagation: 0.2959 sec; Batch: 2.1220 sec
0.1580 0.1273 0.0823 0.0752 0.0673 0.0622 0.0609 0.0588 0.0573 0.0568 0.0559 0.0557 0.0552 0.0549 0.0547 0.0544 

[TRAIN] Epoch[1](9442/114412); Loss: 0.094576; Backpropagation: 0.2960 sec; Batch: 2.1209 sec
0.1503 0.1389 0.1159 0.1071 0.0981 0.0933 0.0894 0.0859 0.0836 0.0823 0.0805 0.0792 0.0786 0.0774 0.0766 0.0760 

[TRAIN] Epoch[1](9443/114412); Loss: 0.087080; Backpropagation: 0.2955 sec; Batch: 2.2690 sec
0.1663 0.1564 0.1127 0.1007 0.0887 0.0813 0.0778 0.0746 0.0715 0.0697 0.0682 0.0668 0.0657 0.0648 0.0642 0.0638 

[TRAIN] Epoch[1](9444/114412); Loss: 0.067769; Backpropagation: 0.2955 sec; Batch: 2.1136 sec
0.1084 0.0903 0.0827 0.0769 0.0725 0.0672 0.0641 0.0618 0.0605 0.0590 0.0583 0.0574 0.0570 0.0565 0.0561 0.0556 

[TRAIN] Epoch[1](9445/114412); Loss: 0.069395; Backpropagation: 0.2956 sec; Batch: 2.1226 sec
0.1252 0.1078 0.0871 0.0808 0.0761 0.0681 0.0649 0.0618 0.0588 0.0576 0.0564 0.0547 0.0540 0.0531 0.0522 0.0518 

[TRAIN] Epoch[1](9446/114412); Loss: 0.087366; Backpropagation: 0.2980 sec; Batch: 2.1227 sec
0.1755 0.1423 0.1163 0.0970 0.0870 0.0807 0.0767 0.0741 0.0717 0.0700 0.0690 0.0682 0.0677 0.0675 0.0673 0.0671 

[TRAIN] Epoch[1](9447/114412); Loss: 0.083782; Backpropagation: 0.3007 sec; Batch: 2.1272 sec
0.1449 0.1364 0.1038 0.0945 0.0863 0.0824 0.0769 0.0740 0.0722 0.0697 0.0686 0.0677 0.0667 0.0659 0.0654 0.0650 

[TRAIN] Epoch[1](9448/114412); Loss: 0.087777; Backpropagation: 0.2981 sec; Batch: 2.1281 sec
0.1452 0.1306 0.1060 0.0990 0.0912 0.0867 0.0825 0.0789 0.0771 0.0754 0.0741 0.0730 0.0722 0.0715 0.0708 0.0703 

[TRAIN] Epoch[1](9449/114412); Loss: 0.076142; Backpropagation: 0.2955 sec; Batch: 2.1230 sec
0.1556 0.1172 0.0943 0.0851 0.0760 0.0702 0.0680 0.0653 0.0638 0.0625 0.0616 0.0608 0.0602 0.0597 0.0592 0.0587 

[TRAIN] Epoch[1](9450/114412); Loss: 0.056834; Backpropagation: 0.2955 sec; Batch: 2.1207 sec
0.1425 0.1334 0.0758 0.0608 0.0521 0.0496 0.0457 0.0435 0.0419 0.0403 0.0391 0.0382 0.0374 0.0368 0.0362 0.0359 

[TRAIN] Epoch[1](9451/114412); Loss: 0.087274; Backpropagation: 0.2957 sec; Batch: 2.1183 sec
0.1600 0.1404 0.1056 0.0933 0.0844 0.0809 0.0791 0.0760 0.0747 0.0736 0.0725 0.0718 0.0714 0.0711 0.0708 0.0707 

[TRAIN] Epoch[1](9452/114412); Loss: 0.098116; Backpropagation: 0.2975 sec; Batch: 2.1244 sec
0.1578 0.1382 0.1171 0.1064 0.0991 0.0956 0.0923 0.0904 0.0885 0.0864 0.0853 0.0842 0.0832 0.0825 0.0817 0.0812 

[TRAIN] Epoch[1](9453/114412); Loss: 0.095796; Backpropagation: 0.2977 sec; Batch: 2.1201 sec
0.1697 0.1596 0.1142 0.0993 0.0960 0.0914 0.0883 0.0850 0.0828 0.0810 0.0796 0.0787 0.0777 0.0771 0.0765 0.0760 

[TRAIN] Epoch[1](9454/114412); Loss: 0.068594; Backpropagation: 0.2952 sec; Batch: 2.1194 sec
0.1534 0.1377 0.0965 0.0784 0.0679 0.0601 0.0563 0.0543 0.0525 0.0507 0.0497 0.0491 0.0484 0.0479 0.0475 0.0471 

[TRAIN] Epoch[1](9455/114412); Loss: 0.062316; Backpropagation: 0.2958 sec; Batch: 2.1215 sec
0.1236 0.1150 0.0846 0.0741 0.0609 0.0569 0.0541 0.0515 0.0497 0.0486 0.0477 0.0470 0.0464 0.0461 0.0456 0.0453 

[TRAIN] Epoch[1](9456/114412); Loss: 0.084916; Backpropagation: 0.2956 sec; Batch: 2.1295 sec
0.1395 0.1266 0.0981 0.0907 0.0851 0.0808 0.0780 0.0764 0.0750 0.0742 0.0735 0.0729 0.0725 0.0721 0.0718 0.0716 

[TRAIN] Epoch[1](9457/114412); Loss: 0.078712; Backpropagation: 0.2958 sec; Batch: 2.1225 sec
0.1498 0.1147 0.0923 0.0839 0.0774 0.0743 0.0722 0.0698 0.0684 0.0673 0.0663 0.0656 0.0649 0.0645 0.0641 0.0639 

[TRAIN] Epoch[1](9458/114412); Loss: 0.081898; Backpropagation: 0.2949 sec; Batch: 2.0808 sec
0.1367 0.1245 0.1044 0.0944 0.0853 0.0790 0.0748 0.0725 0.0707 0.0693 0.0682 0.0672 0.0665 0.0661 0.0657 0.0652 

[TRAIN] Epoch[1](9459/114412); Loss: 0.069357; Backpropagation: 0.3006 sec; Batch: 2.1260 sec
0.1365 0.1284 0.0930 0.0740 0.0664 0.0632 0.0607 0.0584 0.0572 0.0550 0.0543 0.0534 0.0526 0.0525 0.0520 0.0521 

[TRAIN] Epoch[1](9460/114412); Loss: 0.070870; Backpropagation: 0.2977 sec; Batch: 2.0839 sec
0.1310 0.1167 0.0878 0.0789 0.0731 0.0665 0.0630 0.0606 0.0594 0.0584 0.0576 0.0569 0.0564 0.0561 0.0558 0.0556 

[TRAIN] Epoch[1](9461/114412); Loss: 0.058151; Backpropagation: 0.2960 sec; Batch: 2.1196 sec
0.1086 0.1033 0.0777 0.0692 0.0567 0.0523 0.0506 0.0487 0.0478 0.0467 0.0460 0.0454 0.0449 0.0444 0.0441 0.0439 

[TRAIN] Epoch[1](9462/114412); Loss: 0.074704; Backpropagation: 0.2957 sec; Batch: 2.0863 sec
0.1685 0.1467 0.1022 0.0859 0.0777 0.0691 0.0658 0.0600 0.0569 0.0548 0.0538 0.0520 0.0514 0.0507 0.0501 0.0497 

[TRAIN] Epoch[1](9463/114412); Loss: 0.055835; Backpropagation: 0.2952 sec; Batch: 2.1234 sec
0.0962 0.0832 0.0743 0.0606 0.0578 0.0542 0.0519 0.0506 0.0485 0.0473 0.0467 0.0453 0.0448 0.0444 0.0439 0.0437 

[TRAIN] Epoch[1](9464/114412); Loss: 0.060739; Backpropagation: 0.2953 sec; Batch: 2.0819 sec
0.1163 0.1092 0.0790 0.0668 0.0595 0.0560 0.0531 0.0513 0.0501 0.0490 0.0482 0.0475 0.0470 0.0466 0.0461 0.0458 

[TRAIN] Epoch[1](9465/114412); Loss: 0.062327; Backpropagation: 0.2949 sec; Batch: 2.1195 sec
0.1221 0.1136 0.0803 0.0725 0.0636 0.0579 0.0550 0.0524 0.0507 0.0494 0.0483 0.0475 0.0466 0.0461 0.0457 0.0456 

[TRAIN] Epoch[1](9466/114412); Loss: 0.092039; Backpropagation: 0.2959 sec; Batch: 2.0824 sec
0.1389 0.1289 0.1071 0.0989 0.0933 0.0895 0.0872 0.0850 0.0836 0.0823 0.0812 0.0805 0.0798 0.0794 0.0788 0.0784 

[TRAIN] Epoch[1](9467/114412); Loss: 0.067498; Backpropagation: 0.2952 sec; Batch: 2.0820 sec
0.1235 0.1161 0.0827 0.0752 0.0671 0.0630 0.0604 0.0585 0.0570 0.0557 0.0550 0.0542 0.0535 0.0531 0.0527 0.0524 

[TRAIN] Epoch[1](9468/114412); Loss: 0.088699; Backpropagation: 0.2958 sec; Batch: 2.1226 sec
0.1400 0.1275 0.1065 0.0971 0.0903 0.0845 0.0818 0.0805 0.0791 0.0781 0.0771 0.0764 0.0757 0.0753 0.0748 0.0745 

[TRAIN] Epoch[1](9469/114412); Loss: 0.047276; Backpropagation: 0.2955 sec; Batch: 2.1203 sec
0.1185 0.1092 0.0753 0.0610 0.0452 0.0379 0.0359 0.0334 0.0322 0.0312 0.0304 0.0299 0.0295 0.0291 0.0290 0.0288 

[TRAIN] Epoch[1](9470/114412); Loss: 0.078655; Backpropagation: 0.2959 sec; Batch: 2.1215 sec
0.1432 0.1307 0.1084 0.0948 0.0828 0.0753 0.0709 0.0673 0.0641 0.0629 0.0614 0.0604 0.0600 0.0592 0.0587 0.0585 

[TRAIN] Epoch[1](9471/114412); Loss: 0.082717; Backpropagation: 0.2959 sec; Batch: 2.1296 sec
0.1293 0.1114 0.0972 0.0900 0.0861 0.0815 0.0787 0.0761 0.0745 0.0733 0.0725 0.0718 0.0709 0.0704 0.0700 0.0698 

[TRAIN] Epoch[1](9472/114412); Loss: 0.078139; Backpropagation: 0.2958 sec; Batch: 2.1028 sec
0.1533 0.1341 0.1042 0.0908 0.0799 0.0735 0.0696 0.0661 0.0633 0.0619 0.0605 0.0598 0.0589 0.0586 0.0582 0.0578 

[TRAIN] Epoch[1](9473/114412); Loss: 0.075344; Backpropagation: 0.2956 sec; Batch: 2.1215 sec
0.1456 0.1331 0.1008 0.0902 0.0759 0.0691 0.0652 0.0629 0.0609 0.0595 0.0586 0.0578 0.0572 0.0566 0.0562 0.0559 

[TRAIN] Epoch[1](9474/114412); Loss: 0.089349; Backpropagation: 0.3008 sec; Batch: 2.1264 sec
0.1479 0.1285 0.1055 0.0960 0.0889 0.0860 0.0832 0.0816 0.0795 0.0777 0.0773 0.0765 0.0757 0.0754 0.0750 0.0747 

[TRAIN] Epoch[1](9475/114412); Loss: 0.062139; Backpropagation: 0.2979 sec; Batch: 2.1212 sec
0.1091 0.0986 0.0794 0.0712 0.0657 0.0606 0.0565 0.0550 0.0529 0.0516 0.0506 0.0496 0.0491 0.0484 0.0481 0.0479 

[TRAIN] Epoch[1](9476/114412); Loss: 0.068499; Backpropagation: 0.2960 sec; Batch: 2.1199 sec
0.1319 0.1109 0.0825 0.0755 0.0703 0.0650 0.0623 0.0603 0.0582 0.0567 0.0557 0.0547 0.0537 0.0533 0.0527 0.0522 

[TRAIN] Epoch[1](9477/114412); Loss: 0.062257; Backpropagation: 0.2946 sec; Batch: 2.1203 sec
0.1321 0.1234 0.0870 0.0740 0.0611 0.0560 0.0517 0.0499 0.0480 0.0470 0.0459 0.0450 0.0444 0.0440 0.0436 0.0432 

[TRAIN] Epoch[1](9478/114412); Loss: 0.100641; Backpropagation: 0.2954 sec; Batch: 2.1224 sec
0.1525 0.1406 0.1193 0.1119 0.1026 0.0974 0.0947 0.0924 0.0909 0.0895 0.0883 0.0874 0.0865 0.0859 0.0854 0.0850 

[TRAIN] Epoch[1](9479/114412); Loss: 0.064991; Backpropagation: 0.2966 sec; Batch: 2.1228 sec
0.1291 0.1104 0.0845 0.0746 0.0651 0.0608 0.0573 0.0549 0.0534 0.0520 0.0513 0.0505 0.0497 0.0492 0.0487 0.0484 

[TRAIN] Epoch[1](9480/114412); Loss: 0.075404; Backpropagation: 0.2956 sec; Batch: 2.1195 sec
0.1323 0.1160 0.0965 0.0842 0.0777 0.0734 0.0708 0.0682 0.0647 0.0637 0.0619 0.0608 0.0601 0.0593 0.0587 0.0582 

[TRAIN] Epoch[1](9481/114412); Loss: 0.076017; Backpropagation: 0.2952 sec; Batch: 2.1367 sec
0.1440 0.1278 0.1005 0.0891 0.0799 0.0751 0.0697 0.0663 0.0630 0.0609 0.0591 0.0579 0.0569 0.0559 0.0555 0.0548 

[TRAIN] Epoch[1](9482/114412); Loss: 0.070695; Backpropagation: 0.2957 sec; Batch: 2.1244 sec
0.1318 0.1151 0.0879 0.0751 0.0723 0.0676 0.0641 0.0627 0.0600 0.0588 0.0577 0.0568 0.0562 0.0555 0.0550 0.0545 

[TRAIN] Epoch[1](9483/114412); Loss: 0.056015; Backpropagation: 0.3005 sec; Batch: 2.1248 sec
0.1085 0.0926 0.0725 0.0663 0.0589 0.0529 0.0510 0.0479 0.0464 0.0455 0.0440 0.0434 0.0424 0.0416 0.0413 0.0411 

[TRAIN] Epoch[1](9484/114412); Loss: 0.088131; Backpropagation: 0.2981 sec; Batch: 2.1037 sec
0.1455 0.1295 0.1075 0.0996 0.0909 0.0856 0.0821 0.0796 0.0774 0.0759 0.0748 0.0736 0.0730 0.0723 0.0715 0.0713 

[TRAIN] Epoch[1](9485/114412); Loss: 0.080065; Backpropagation: 0.3006 sec; Batch: 2.1266 sec
0.1332 0.1214 0.1040 0.0904 0.0843 0.0779 0.0740 0.0713 0.0692 0.0675 0.0664 0.0655 0.0648 0.0641 0.0638 0.0631 

[TRAIN] Epoch[1](9486/114412); Loss: 0.084262; Backpropagation: 0.2952 sec; Batch: 2.1243 sec
0.1882 0.1490 0.1187 0.0977 0.0875 0.0791 0.0733 0.0697 0.0660 0.0635 0.0621 0.0603 0.0594 0.0586 0.0578 0.0571 

[TRAIN] Epoch[1](9487/114412); Loss: 0.115072; Backpropagation: 0.2955 sec; Batch: 2.1218 sec
0.1795 0.1632 0.1285 0.1237 0.1169 0.1110 0.1092 0.1053 0.1036 0.1022 0.1011 0.1004 0.0998 0.0994 0.0989 0.0984 

[TRAIN] Epoch[1](9488/114412); Loss: 0.094694; Backpropagation: 0.2984 sec; Batch: 2.1327 sec
0.1719 0.1545 0.1141 0.1017 0.0936 0.0885 0.0858 0.0837 0.0817 0.0797 0.0785 0.0774 0.0768 0.0762 0.0757 0.0752 

[TRAIN] Epoch[1](9489/114412); Loss: 0.064984; Backpropagation: 0.2960 sec; Batch: 2.1218 sec
0.1244 0.1088 0.0841 0.0725 0.0646 0.0615 0.0584 0.0558 0.0540 0.0527 0.0518 0.0513 0.0505 0.0501 0.0498 0.0496 

[TRAIN] Epoch[1](9490/114412); Loss: 0.053439; Backpropagation: 0.2956 sec; Batch: 2.1228 sec
0.1053 0.0965 0.0758 0.0658 0.0559 0.0488 0.0463 0.0437 0.0422 0.0409 0.0401 0.0393 0.0390 0.0387 0.0384 0.0384 

[TRAIN] Epoch[1](9491/114412); Loss: 0.119637; Backpropagation: 0.2954 sec; Batch: 2.1008 sec
0.1861 0.1698 0.1350 0.1205 0.1189 0.1141 0.1127 0.1107 0.1087 0.1077 0.1065 0.1057 0.1050 0.1045 0.1042 0.1040 

[TRAIN] Epoch[1](9492/114412); Loss: 0.082361; Backpropagation: 0.2954 sec; Batch: 2.1242 sec
0.1425 0.1282 0.1035 0.0916 0.0838 0.0791 0.0762 0.0737 0.0714 0.0698 0.0686 0.0673 0.0663 0.0658 0.0652 0.0648 

[TRAIN] Epoch[1](9493/114412); Loss: 0.063382; Backpropagation: 0.2985 sec; Batch: 2.1211 sec
0.1283 0.1178 0.0860 0.0761 0.0648 0.0584 0.0552 0.0521 0.0503 0.0487 0.0476 0.0468 0.0461 0.0458 0.0451 0.0448 

[TRAIN] Epoch[1](9494/114412); Loss: 0.098083; Backpropagation: 0.2959 sec; Batch: 2.1343 sec
0.1694 0.1560 0.1212 0.1077 0.0977 0.0934 0.0893 0.0862 0.0847 0.0830 0.0817 0.0810 0.0803 0.0796 0.0794 0.0788 

[TRAIN] Epoch[1](9495/114412); Loss: 0.092192; Backpropagation: 0.3009 sec; Batch: 2.1268 sec
0.1510 0.1365 0.1130 0.1007 0.0937 0.0882 0.0849 0.0821 0.0806 0.0796 0.0788 0.0782 0.0777 0.0771 0.0767 0.0763 

[TRAIN] Epoch[1](9496/114412); Loss: 0.110583; Backpropagation: 0.2951 sec; Batch: 2.1234 sec
0.1693 0.1574 0.1365 0.1265 0.1177 0.1104 0.1046 0.1009 0.0976 0.0960 0.0946 0.0930 0.0922 0.0914 0.0908 0.0903 

[TRAIN] Epoch[1](9497/114412); Loss: 0.101354; Backpropagation: 0.2956 sec; Batch: 2.1262 sec
0.1712 0.1574 0.1213 0.1100 0.1018 0.0958 0.0930 0.0909 0.0887 0.0870 0.0858 0.0849 0.0841 0.0835 0.0833 0.0829 

[TRAIN] Epoch[1](9498/114412); Loss: 0.064457; Backpropagation: 0.2956 sec; Batch: 2.1179 sec
0.1225 0.1044 0.0836 0.0746 0.0650 0.0608 0.0592 0.0567 0.0545 0.0529 0.0514 0.0505 0.0495 0.0490 0.0485 0.0481 

[TRAIN] Epoch[1](9499/114412); Loss: 0.068775; Backpropagation: 0.2951 sec; Batch: 2.1216 sec
0.1355 0.1232 0.0872 0.0771 0.0682 0.0642 0.0607 0.0583 0.0562 0.0549 0.0539 0.0531 0.0526 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](9500/114412); Loss: 0.074645; Backpropagation: 0.2980 sec; Batch: 2.1233 sec
0.1333 0.1226 0.0991 0.0891 0.0801 0.0731 0.0677 0.0641 0.0626 0.0604 0.0595 0.0583 0.0569 0.0565 0.0558 0.0552 

[TRAIN] Epoch[1](9501/114412); Loss: 0.084821; Backpropagation: 0.2958 sec; Batch: 2.1241 sec
0.1313 0.1155 0.1026 0.0923 0.0864 0.0829 0.0794 0.0779 0.0761 0.0752 0.0741 0.0735 0.0729 0.0727 0.0723 0.0721 

[TRAIN] Epoch[1](9502/114412); Loss: 0.086463; Backpropagation: 0.2955 sec; Batch: 2.1255 sec
0.1455 0.1375 0.1100 0.0988 0.0900 0.0838 0.0794 0.0760 0.0739 0.0726 0.0713 0.0702 0.0697 0.0688 0.0681 0.0677 

[TRAIN] Epoch[1](9503/114412); Loss: 0.067534; Backpropagation: 0.2951 sec; Batch: 2.0816 sec
0.1448 0.1293 0.0850 0.0717 0.0699 0.0623 0.0588 0.0558 0.0534 0.0521 0.0510 0.0502 0.0495 0.0492 0.0490 0.0485 

[TRAIN] Epoch[1](9504/114412); Loss: 0.074722; Backpropagation: 0.2951 sec; Batch: 2.0855 sec
0.1159 0.1040 0.0914 0.0813 0.0774 0.0733 0.0704 0.0685 0.0673 0.0658 0.0648 0.0641 0.0635 0.0629 0.0626 0.0623 

[TRAIN] Epoch[1](9505/114412); Loss: 0.070091; Backpropagation: 0.2980 sec; Batch: 2.0849 sec
0.1432 0.1310 0.0963 0.0821 0.0730 0.0659 0.0625 0.0578 0.0558 0.0538 0.0526 0.0511 0.0502 0.0493 0.0487 0.0482 

[TRAIN] Epoch[1](9506/114412); Loss: 0.064607; Backpropagation: 0.2983 sec; Batch: 2.0853 sec
0.1175 0.1018 0.0821 0.0722 0.0667 0.0614 0.0588 0.0564 0.0551 0.0539 0.0528 0.0522 0.0514 0.0508 0.0504 0.0499 

[TRAIN] Epoch[1](9507/114412); Loss: 0.075591; Backpropagation: 0.2980 sec; Batch: 2.1239 sec
0.1681 0.1427 0.1037 0.0853 0.0723 0.0689 0.0631 0.0602 0.0588 0.0572 0.0563 0.0555 0.0550 0.0544 0.0541 0.0539 

[TRAIN] Epoch[1](9508/114412); Loss: 0.084584; Backpropagation: 0.2952 sec; Batch: 2.1220 sec
0.1724 0.1555 0.1165 0.0996 0.0847 0.0767 0.0725 0.0691 0.0669 0.0653 0.0641 0.0630 0.0625 0.0620 0.0615 0.0612 

[TRAIN] Epoch[1](9509/114412); Loss: 0.096407; Backpropagation: 0.2958 sec; Batch: 2.1222 sec
0.1773 0.1535 0.1194 0.1043 0.0961 0.0905 0.0874 0.0843 0.0824 0.0809 0.0795 0.0786 0.0780 0.0772 0.0767 0.0764 

[TRAIN] Epoch[1](9510/114412); Loss: 0.073165; Backpropagation: 0.2954 sec; Batch: 2.1221 sec
0.1192 0.1093 0.0906 0.0822 0.0764 0.0710 0.0682 0.0659 0.0637 0.0627 0.0619 0.0610 0.0604 0.0599 0.0594 0.0590 

[TRAIN] Epoch[1](9511/114412); Loss: 0.080817; Backpropagation: 0.2966 sec; Batch: 2.1230 sec
0.1334 0.1232 0.1025 0.0904 0.0835 0.0777 0.0739 0.0708 0.0693 0.0683 0.0673 0.0670 0.0665 0.0664 0.0665 0.0663 

[TRAIN] Epoch[1](9512/114412); Loss: 0.074654; Backpropagation: 0.2954 sec; Batch: 2.1195 sec
0.1417 0.1284 0.0932 0.0808 0.0751 0.0684 0.0656 0.0645 0.0631 0.0617 0.0603 0.0594 0.0586 0.0582 0.0580 0.0577 

[TRAIN] Epoch[1](9513/114412); Loss: 0.102906; Backpropagation: 0.3009 sec; Batch: 2.1266 sec
0.1584 0.1517 0.1359 0.1217 0.1095 0.1007 0.0956 0.0925 0.0894 0.0878 0.0866 0.0848 0.0840 0.0832 0.0824 0.0820 

[TRAIN] Epoch[1](9514/114412); Loss: 0.061647; Backpropagation: 0.2982 sec; Batch: 2.1221 sec
0.1506 0.1236 0.0851 0.0687 0.0624 0.0541 0.0505 0.0492 0.0465 0.0451 0.0442 0.0424 0.0421 0.0412 0.0404 0.0403 

[TRAIN] Epoch[1](9515/114412); Loss: 0.079671; Backpropagation: 0.3006 sec; Batch: 2.1280 sec
0.1584 0.1390 0.1058 0.0896 0.0798 0.0756 0.0703 0.0677 0.0650 0.0634 0.0621 0.0610 0.0600 0.0593 0.0590 0.0586 

[TRAIN] Epoch[1](9516/114412); Loss: 0.065535; Backpropagation: 0.2969 sec; Batch: 2.1214 sec
0.1327 0.1204 0.0859 0.0673 0.0637 0.0596 0.0576 0.0558 0.0534 0.0524 0.0514 0.0510 0.0500 0.0494 0.0492 0.0487 

[TRAIN] Epoch[1](9517/114412); Loss: 0.073722; Backpropagation: 0.2955 sec; Batch: 2.1205 sec
0.1479 0.1372 0.0919 0.0838 0.0739 0.0682 0.0653 0.0618 0.0598 0.0587 0.0572 0.0562 0.0554 0.0544 0.0539 0.0537 

[TRAIN] Epoch[1](9518/114412); Loss: 0.078640; Backpropagation: 0.2955 sec; Batch: 2.1131 sec
0.1223 0.1146 0.0963 0.0869 0.0801 0.0767 0.0738 0.0717 0.0699 0.0687 0.0676 0.0671 0.0664 0.0658 0.0654 0.0650 

[TRAIN] Epoch[1](9519/114412); Loss: 0.071893; Backpropagation: 0.2984 sec; Batch: 2.1531 sec
0.1326 0.1219 0.1016 0.0924 0.0816 0.0741 0.0664 0.0637 0.0602 0.0552 0.0547 0.0523 0.0495 0.0489 0.0479 0.0474 

[TRAIN] Epoch[1](9520/114412); Loss: 0.079496; Backpropagation: 0.2953 sec; Batch: 2.1212 sec
0.1275 0.1213 0.1048 0.0928 0.0845 0.0758 0.0732 0.0707 0.0683 0.0674 0.0659 0.0649 0.0644 0.0638 0.0635 0.0632 

[TRAIN] Epoch[1](9521/114412); Loss: 0.085528; Backpropagation: 0.2951 sec; Batch: 2.1176 sec
0.1512 0.1349 0.1004 0.0937 0.0884 0.0824 0.0788 0.0763 0.0744 0.0729 0.0713 0.0702 0.0695 0.0687 0.0680 0.0675 

[TRAIN] Epoch[1](9522/114412); Loss: 0.074337; Backpropagation: 0.2959 sec; Batch: 2.1808 sec
0.1464 0.1242 0.0919 0.0818 0.0752 0.0708 0.0666 0.0638 0.0617 0.0602 0.0592 0.0584 0.0578 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](9523/114412); Loss: 0.061087; Backpropagation: 0.2980 sec; Batch: 2.1258 sec
0.1487 0.1229 0.0784 0.0648 0.0586 0.0535 0.0507 0.0480 0.0464 0.0452 0.0446 0.0439 0.0436 0.0429 0.0427 0.0425 

[TRAIN] Epoch[1](9524/114412); Loss: 0.080898; Backpropagation: 0.2958 sec; Batch: 2.1111 sec
0.1443 0.1290 0.1082 0.0930 0.0847 0.0796 0.0755 0.0711 0.0680 0.0662 0.0646 0.0634 0.0626 0.0618 0.0613 0.0609 

[TRAIN] Epoch[1](9525/114412); Loss: 0.072763; Backpropagation: 0.2960 sec; Batch: 2.1325 sec
0.1823 0.1416 0.0934 0.0782 0.0664 0.0616 0.0603 0.0575 0.0555 0.0545 0.0534 0.0526 0.0523 0.0517 0.0515 0.0513 

[TRAIN] Epoch[1](9526/114412); Loss: 0.061303; Backpropagation: 0.2952 sec; Batch: 2.1226 sec
0.1414 0.1326 0.0849 0.0667 0.0579 0.0537 0.0502 0.0482 0.0461 0.0449 0.0438 0.0429 0.0424 0.0420 0.0418 0.0414 

[TRAIN] Epoch[1](9527/114412); Loss: 0.073814; Backpropagation: 0.2957 sec; Batch: 2.1202 sec
0.1607 0.1384 0.1096 0.0954 0.0906 0.0764 0.0663 0.0602 0.0534 0.0522 0.0492 0.0466 0.0464 0.0457 0.0450 0.0448 

[TRAIN] Epoch[1](9528/114412); Loss: 0.069864; Backpropagation: 0.2979 sec; Batch: 2.1247 sec
0.1275 0.1114 0.0903 0.0749 0.0698 0.0648 0.0624 0.0605 0.0592 0.0585 0.0576 0.0571 0.0564 0.0561 0.0558 0.0557 

[TRAIN] Epoch[1](9529/114412); Loss: 0.064474; Backpropagation: 0.2956 sec; Batch: 2.1180 sec
0.1634 0.1141 0.0818 0.0708 0.0628 0.0568 0.0530 0.0519 0.0496 0.0486 0.0479 0.0470 0.0466 0.0463 0.0457 0.0454 

[TRAIN] Epoch[1](9530/114412); Loss: 0.060293; Backpropagation: 0.2957 sec; Batch: 2.1190 sec
0.1209 0.1031 0.0770 0.0674 0.0614 0.0574 0.0533 0.0519 0.0500 0.0478 0.0472 0.0466 0.0457 0.0454 0.0450 0.0446 

[TRAIN] Epoch[1](9531/114412); Loss: 0.087232; Backpropagation: 0.2958 sec; Batch: 2.1087 sec
0.1656 0.1434 0.1146 0.0975 0.0872 0.0826 0.0776 0.0744 0.0724 0.0709 0.0698 0.0692 0.0684 0.0679 0.0673 0.0669 

[TRAIN] Epoch[1](9532/114412); Loss: 0.075528; Backpropagation: 0.2982 sec; Batch: 2.0849 sec
0.1383 0.1143 0.1025 0.0881 0.0784 0.0727 0.0686 0.0665 0.0645 0.0626 0.0614 0.0596 0.0589 0.0580 0.0572 0.0568 

[TRAIN] Epoch[1](9533/114412); Loss: 0.067794; Backpropagation: 0.2983 sec; Batch: 2.1252 sec
0.1306 0.1184 0.0871 0.0793 0.0715 0.0671 0.0615 0.0580 0.0556 0.0538 0.0523 0.0514 0.0505 0.0496 0.0493 0.0488 

[TRAIN] Epoch[1](9534/114412); Loss: 0.063113; Backpropagation: 0.2979 sec; Batch: 2.1249 sec
0.1190 0.0975 0.0805 0.0691 0.0623 0.0595 0.0568 0.0551 0.0536 0.0524 0.0519 0.0512 0.0506 0.0504 0.0501 0.0499 

[TRAIN] Epoch[1](9535/114412); Loss: 0.071959; Backpropagation: 0.2957 sec; Batch: 2.1224 sec
0.1554 0.1443 0.0921 0.0786 0.0714 0.0656 0.0620 0.0589 0.0571 0.0553 0.0540 0.0527 0.0518 0.0511 0.0506 0.0501 

[TRAIN] Epoch[1](9536/114412); Loss: 0.101212; Backpropagation: 0.2958 sec; Batch: 2.1217 sec
0.1551 0.1373 0.1204 0.1109 0.1037 0.0982 0.0948 0.0934 0.0911 0.0901 0.0891 0.0880 0.0876 0.0870 0.0865 0.0862 

[TRAIN] Epoch[1](9537/114412); Loss: 0.087264; Backpropagation: 0.2955 sec; Batch: 2.1216 sec
0.1413 0.1234 0.1012 0.0941 0.0872 0.0841 0.0818 0.0803 0.0785 0.0770 0.0761 0.0752 0.0746 0.0741 0.0737 0.0735 

[TRAIN] Epoch[1](9538/114412); Loss: 0.080047; Backpropagation: 0.2948 sec; Batch: 2.0816 sec
0.1122 0.0972 0.1045 0.0892 0.0847 0.0809 0.0783 0.0754 0.0737 0.0717 0.0707 0.0695 0.0689 0.0683 0.0679 0.0678 

[TRAIN] Epoch[1](9539/114412); Loss: 0.105780; Backpropagation: 0.2951 sec; Batch: 2.1221 sec
0.1727 0.1659 0.1305 0.1150 0.1065 0.1009 0.0976 0.0951 0.0926 0.0911 0.0896 0.0885 0.0875 0.0869 0.0862 0.0858 

[TRAIN] Epoch[1](9540/114412); Loss: 0.079627; Backpropagation: 0.3007 sec; Batch: 2.1293 sec
0.1388 0.1135 0.0949 0.0853 0.0818 0.0787 0.0752 0.0722 0.0704 0.0691 0.0676 0.0668 0.0659 0.0652 0.0646 0.0640 

[TRAIN] Epoch[1](9541/114412); Loss: 0.058816; Backpropagation: 0.2979 sec; Batch: 2.0839 sec
0.1350 0.1214 0.0776 0.0652 0.0570 0.0534 0.0499 0.0468 0.0451 0.0435 0.0426 0.0420 0.0412 0.0406 0.0402 0.0397 

[TRAIN] Epoch[1](9542/114412); Loss: 0.077501; Backpropagation: 0.2980 sec; Batch: 2.1241 sec
0.1278 0.1166 0.0932 0.0850 0.0801 0.0739 0.0711 0.0694 0.0676 0.0666 0.0661 0.0655 0.0650 0.0644 0.0639 0.0638 

[TRAIN] Epoch[1](9543/114412); Loss: 0.074014; Backpropagation: 0.2957 sec; Batch: 2.1258 sec
0.1430 0.1291 0.1029 0.0880 0.0777 0.0697 0.0645 0.0624 0.0602 0.0579 0.0571 0.0559 0.0548 0.0544 0.0536 0.0531 

[TRAIN] Epoch[1](9544/114412); Loss: 0.062867; Backpropagation: 0.2951 sec; Batch: 2.1226 sec
0.1206 0.1040 0.0851 0.0732 0.0641 0.0587 0.0555 0.0534 0.0515 0.0500 0.0493 0.0488 0.0483 0.0479 0.0479 0.0477 

[TRAIN] Epoch[1](9545/114412); Loss: 0.066776; Backpropagation: 0.2959 sec; Batch: 2.1216 sec
0.1219 0.1035 0.0852 0.0750 0.0679 0.0641 0.0612 0.0586 0.0570 0.0557 0.0548 0.0538 0.0530 0.0527 0.0522 0.0517 

[TRAIN] Epoch[1](9546/114412); Loss: 0.095101; Backpropagation: 0.2957 sec; Batch: 2.1340 sec
0.1484 0.1377 0.1197 0.1051 0.0989 0.0929 0.0897 0.0868 0.0844 0.0828 0.0815 0.0804 0.0794 0.0786 0.0779 0.0775 

[TRAIN] Epoch[1](9547/114412); Loss: 0.066173; Backpropagation: 0.2956 sec; Batch: 2.1218 sec
0.1200 0.1066 0.0927 0.0799 0.0703 0.0645 0.0594 0.0569 0.0548 0.0528 0.0519 0.0509 0.0502 0.0496 0.0492 0.0489 

[TRAIN] Epoch[1](9548/114412); Loss: 0.062320; Backpropagation: 0.2907 sec; Batch: 2.1190 sec
0.1192 0.0942 0.0814 0.0673 0.0624 0.0586 0.0563 0.0545 0.0526 0.0518 0.0509 0.0504 0.0500 0.0494 0.0491 0.0488 

[TRAIN] Epoch[1](9549/114412); Loss: 0.080176; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1572 0.1417 0.1002 0.0885 0.0775 0.0742 0.0721 0.0686 0.0669 0.0651 0.0636 0.0630 0.0620 0.0613 0.0608 0.0600 

[TRAIN] Epoch[1](9550/114412); Loss: 0.083499; Backpropagation: 0.2910 sec; Batch: 2.1379 sec
0.1520 0.1339 0.1145 0.0997 0.0887 0.0812 0.0760 0.0726 0.0691 0.0666 0.0656 0.0645 0.0638 0.0632 0.0624 0.0623 

[TRAIN] Epoch[1](9551/114412); Loss: 0.074493; Backpropagation: 0.2906 sec; Batch: 2.1171 sec
0.1741 0.1492 0.1113 0.0789 0.0795 0.0657 0.0595 0.0582 0.0549 0.0534 0.0526 0.0517 0.0512 0.0509 0.0506 0.0503 

[TRAIN] Epoch[1](9552/114412); Loss: 0.084702; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1707 0.1299 0.1028 0.0908 0.0826 0.0797 0.0756 0.0730 0.0715 0.0703 0.0693 0.0687 0.0682 0.0678 0.0673 0.0671 

[TRAIN] Epoch[1](9553/114412); Loss: 0.086112; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1437 0.1259 0.1015 0.0930 0.0862 0.0813 0.0790 0.0772 0.0761 0.0750 0.0742 0.0738 0.0732 0.0729 0.0725 0.0724 

[TRAIN] Epoch[1](9554/114412); Loss: 0.057331; Backpropagation: 0.2907 sec; Batch: 2.0762 sec
0.1279 0.1131 0.0825 0.0679 0.0583 0.0536 0.0495 0.0476 0.0440 0.0420 0.0408 0.0393 0.0386 0.0379 0.0373 0.0369 

[TRAIN] Epoch[1](9555/114412); Loss: 0.061832; Backpropagation: 0.2912 sec; Batch: 2.0987 sec
0.1143 0.0982 0.0809 0.0685 0.0631 0.0591 0.0565 0.0545 0.0526 0.0511 0.0501 0.0493 0.0485 0.0480 0.0475 0.0470 

[TRAIN] Epoch[1](9556/114412); Loss: 0.061629; Backpropagation: 0.2911 sec; Batch: 2.1126 sec
0.1234 0.1106 0.0850 0.0739 0.0655 0.0580 0.0528 0.0507 0.0488 0.0474 0.0467 0.0459 0.0449 0.0445 0.0442 0.0438 

[TRAIN] Epoch[1](9557/114412); Loss: 0.073541; Backpropagation: 0.2907 sec; Batch: 2.1127 sec
0.1701 0.1460 0.0992 0.0775 0.0704 0.0647 0.0612 0.0590 0.0569 0.0553 0.0544 0.0534 0.0529 0.0522 0.0518 0.0515 

[TRAIN] Epoch[1](9558/114412); Loss: 0.054469; Backpropagation: 0.2911 sec; Batch: 2.1149 sec
0.1106 0.0927 0.0708 0.0616 0.0544 0.0513 0.0491 0.0464 0.0445 0.0436 0.0426 0.0419 0.0412 0.0406 0.0402 0.0399 

[TRAIN] Epoch[1](9559/114412); Loss: 0.093592; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1724 0.1495 0.1146 0.1047 0.0956 0.0898 0.0848 0.0820 0.0802 0.0782 0.0766 0.0754 0.0744 0.0738 0.0730 0.0724 

[TRAIN] Epoch[1](9560/114412); Loss: 0.084116; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1567 0.1367 0.1054 0.0969 0.0836 0.0786 0.0751 0.0732 0.0711 0.0697 0.0682 0.0673 0.0666 0.0660 0.0655 0.0651 

[TRAIN] Epoch[1](9561/114412); Loss: 0.071823; Backpropagation: 0.2911 sec; Batch: 2.1270 sec
0.1601 0.1271 0.0969 0.0796 0.0718 0.0664 0.0625 0.0602 0.0575 0.0559 0.0543 0.0530 0.0521 0.0513 0.0503 0.0501 

[TRAIN] Epoch[1](9562/114412); Loss: 0.099613; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1665 0.1451 0.1201 0.1078 0.1010 0.0962 0.0922 0.0904 0.0880 0.0865 0.0855 0.0842 0.0834 0.0829 0.0822 0.0818 

[TRAIN] Epoch[1](9563/114412); Loss: 0.064440; Backpropagation: 0.2905 sec; Batch: 2.1170 sec
0.1413 0.1340 0.0819 0.0700 0.0623 0.0575 0.0548 0.0512 0.0501 0.0490 0.0475 0.0476 0.0465 0.0460 0.0458 0.0454 

[TRAIN] Epoch[1](9564/114412); Loss: 0.091977; Backpropagation: 0.2912 sec; Batch: 2.1133 sec
0.1558 0.1461 0.1209 0.1063 0.0979 0.0902 0.0852 0.0820 0.0789 0.0764 0.0745 0.0731 0.0720 0.0713 0.0707 0.0702 

[TRAIN] Epoch[1](9565/114412); Loss: 0.054361; Backpropagation: 0.2907 sec; Batch: 2.0770 sec
0.1175 0.1102 0.0681 0.0597 0.0552 0.0504 0.0473 0.0443 0.0424 0.0419 0.0403 0.0393 0.0389 0.0384 0.0382 0.0377 

[TRAIN] Epoch[1](9566/114412); Loss: 0.062770; Backpropagation: 0.2910 sec; Batch: 2.1144 sec
0.1588 0.1278 0.0837 0.0769 0.0593 0.0546 0.0503 0.0481 0.0459 0.0447 0.0437 0.0430 0.0424 0.0420 0.0416 0.0414 

[TRAIN] Epoch[1](9567/114412); Loss: 0.068991; Backpropagation: 0.2917 sec; Batch: 2.1139 sec
0.1420 0.1218 0.0831 0.0737 0.0684 0.0635 0.0606 0.0587 0.0570 0.0556 0.0545 0.0539 0.0534 0.0528 0.0525 0.0523 

[TRAIN] Epoch[1](9568/114412); Loss: 0.081665; Backpropagation: 0.2911 sec; Batch: 2.1326 sec
0.1521 0.1376 0.0973 0.0850 0.0804 0.0774 0.0735 0.0713 0.0693 0.0683 0.0671 0.0667 0.0660 0.0654 0.0649 0.0644 

[TRAIN] Epoch[1](9569/114412); Loss: 0.070439; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1222 0.1138 0.0893 0.0770 0.0714 0.0674 0.0645 0.0622 0.0605 0.0590 0.0579 0.0572 0.0568 0.0563 0.0559 0.0556 

[TRAIN] Epoch[1](9570/114412); Loss: 0.085002; Backpropagation: 0.2915 sec; Batch: 2.0796 sec
0.1608 0.1484 0.1083 0.0993 0.0851 0.0787 0.0752 0.0725 0.0701 0.0689 0.0674 0.0663 0.0656 0.0649 0.0644 0.0642 

[TRAIN] Epoch[1](9571/114412); Loss: 0.067240; Backpropagation: 0.2911 sec; Batch: 2.1198 sec
0.1439 0.1313 0.0962 0.0764 0.0698 0.0641 0.0590 0.0556 0.0522 0.0502 0.0487 0.0473 0.0466 0.0455 0.0448 0.0442 

[TRAIN] Epoch[1](9572/114412); Loss: 0.079202; Backpropagation: 0.2912 sec; Batch: 2.1138 sec
0.1413 0.1308 0.0966 0.0862 0.0800 0.0758 0.0723 0.0694 0.0677 0.0663 0.0651 0.0643 0.0637 0.0632 0.0624 0.0623 

[TRAIN] Epoch[1](9573/114412); Loss: 0.068177; Backpropagation: 0.2908 sec; Batch: 2.1127 sec
0.1474 0.1363 0.0782 0.0668 0.0662 0.0626 0.0604 0.0575 0.0554 0.0538 0.0526 0.0523 0.0511 0.0506 0.0502 0.0496 

[TRAIN] Epoch[1](9574/114412); Loss: 0.091945; Backpropagation: 0.2909 sec; Batch: 2.1185 sec
0.1594 0.1400 0.1188 0.1063 0.0936 0.0878 0.0842 0.0805 0.0785 0.0771 0.0757 0.0749 0.0742 0.0737 0.0734 0.0731 

[TRAIN] Epoch[1](9575/114412); Loss: 0.078162; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1356 0.1269 0.0937 0.0847 0.0778 0.0742 0.0716 0.0691 0.0675 0.0662 0.0653 0.0646 0.0641 0.0635 0.0631 0.0627 

[TRAIN] Epoch[1](9576/114412); Loss: 0.070027; Backpropagation: 0.2912 sec; Batch: 2.1287 sec
0.1218 0.1096 0.0853 0.0758 0.0689 0.0673 0.0643 0.0625 0.0609 0.0596 0.0587 0.0581 0.0576 0.0570 0.0568 0.0564 

[TRAIN] Epoch[1](9577/114412); Loss: 0.076385; Backpropagation: 0.2928 sec; Batch: 2.1149 sec
0.1604 0.1342 0.1026 0.0903 0.0787 0.0714 0.0670 0.0633 0.0609 0.0593 0.0580 0.0570 0.0562 0.0550 0.0544 0.0537 

[TRAIN] Epoch[1](9578/114412); Loss: 0.068936; Backpropagation: 0.2909 sec; Batch: 2.1152 sec
0.1404 0.1161 0.0860 0.0781 0.0722 0.0652 0.0607 0.0582 0.0569 0.0555 0.0543 0.0530 0.0522 0.0518 0.0514 0.0511 

[TRAIN] Epoch[1](9579/114412); Loss: 0.092518; Backpropagation: 0.2929 sec; Batch: 2.0782 sec
0.1565 0.1384 0.1151 0.1070 0.1071 0.0916 0.0863 0.0813 0.0789 0.0774 0.0762 0.0750 0.0736 0.0728 0.0717 0.0712 

[TRAIN] Epoch[1](9580/114412); Loss: 0.077764; Backpropagation: 0.2911 sec; Batch: 2.1133 sec
0.1206 0.1075 0.0959 0.0866 0.0793 0.0751 0.0725 0.0711 0.0695 0.0684 0.0677 0.0670 0.0664 0.0659 0.0655 0.0653 

[TRAIN] Epoch[1](9581/114412); Loss: 0.060489; Backpropagation: 0.2925 sec; Batch: 2.0779 sec
0.0998 0.0881 0.0844 0.0723 0.0643 0.0578 0.0545 0.0530 0.0513 0.0505 0.0498 0.0492 0.0487 0.0483 0.0481 0.0478 

[TRAIN] Epoch[1](9582/114412); Loss: 0.098847; Backpropagation: 0.2953 sec; Batch: 2.1177 sec
0.1513 0.1308 0.1154 0.1073 0.1005 0.0961 0.0929 0.0912 0.0899 0.0888 0.0877 0.0868 0.0863 0.0859 0.0855 0.0851 

[TRAIN] Epoch[1](9583/114412); Loss: 0.063188; Backpropagation: 0.2933 sec; Batch: 2.1199 sec
0.1215 0.1034 0.0759 0.0700 0.0646 0.0603 0.0572 0.0544 0.0531 0.0518 0.0509 0.0503 0.0498 0.0495 0.0492 0.0490 

[TRAIN] Epoch[1](9584/114412); Loss: 0.057674; Backpropagation: 0.2905 sec; Batch: 2.1189 sec
0.1278 0.1061 0.0672 0.0628 0.0583 0.0551 0.0532 0.0492 0.0463 0.0448 0.0434 0.0426 0.0422 0.0415 0.0412 0.0411 

[TRAIN] Epoch[1](9585/114412); Loss: 0.107716; Backpropagation: 0.2911 sec; Batch: 2.1147 sec
0.1696 0.1612 0.1462 0.1304 0.1177 0.1115 0.1040 0.0982 0.0942 0.0912 0.0880 0.0849 0.0837 0.0817 0.0808 0.0801 

[TRAIN] Epoch[1](9586/114412); Loss: 0.059796; Backpropagation: 0.2912 sec; Batch: 2.1165 sec
0.1311 0.1199 0.0735 0.0618 0.0567 0.0534 0.0506 0.0489 0.0473 0.0463 0.0455 0.0450 0.0447 0.0442 0.0441 0.0439 

[TRAIN] Epoch[1](9587/114412); Loss: 0.071229; Backpropagation: 0.2907 sec; Batch: 2.1138 sec
0.1300 0.1218 0.0938 0.0800 0.0698 0.0660 0.0628 0.0610 0.0596 0.0584 0.0575 0.0566 0.0560 0.0558 0.0553 0.0550 

[TRAIN] Epoch[1](9588/114412); Loss: 0.084625; Backpropagation: 0.2912 sec; Batch: 2.1217 sec
0.1461 0.1371 0.1007 0.0892 0.0849 0.0803 0.0775 0.0748 0.0733 0.0722 0.0712 0.0705 0.0698 0.0693 0.0688 0.0684 

[TRAIN] Epoch[1](9589/114412); Loss: 0.064523; Backpropagation: 0.2929 sec; Batch: 2.1770 sec
0.1297 0.0991 0.0795 0.0734 0.0786 0.0688 0.0583 0.0537 0.0521 0.0512 0.0496 0.0489 0.0482 0.0476 0.0470 0.0466 

[TRAIN] Epoch[1](9590/114412); Loss: 0.068027; Backpropagation: 0.2917 sec; Batch: 2.0790 sec
0.1313 0.1139 0.0903 0.0761 0.0709 0.0648 0.0605 0.0581 0.0559 0.0547 0.0535 0.0529 0.0522 0.0515 0.0511 0.0508 

[TRAIN] Epoch[1](9591/114412); Loss: 0.064701; Backpropagation: 0.2904 sec; Batch: 2.1157 sec
0.1211 0.1061 0.0809 0.0716 0.0651 0.0618 0.0586 0.0564 0.0547 0.0534 0.0524 0.0517 0.0510 0.0506 0.0500 0.0497 

[TRAIN] Epoch[1](9592/114412); Loss: 0.071745; Backpropagation: 0.2921 sec; Batch: 2.1035 sec
0.1348 0.1172 0.0890 0.0821 0.0749 0.0679 0.0644 0.0619 0.0601 0.0589 0.0575 0.0568 0.0563 0.0557 0.0554 0.0550 

[TRAIN] Epoch[1](9593/114412); Loss: 0.075030; Backpropagation: 0.2929 sec; Batch: 2.1227 sec
0.1406 0.1117 0.0900 0.0817 0.0747 0.0713 0.0686 0.0662 0.0649 0.0634 0.0625 0.0618 0.0613 0.0609 0.0605 0.0603 

[TRAIN] Epoch[1](9594/114412); Loss: 0.073302; Backpropagation: 0.2911 sec; Batch: 2.0768 sec
0.1448 0.1249 0.0919 0.0818 0.0726 0.0682 0.0655 0.0626 0.0608 0.0595 0.0583 0.0576 0.0568 0.0563 0.0558 0.0553 

[TRAIN] Epoch[1](9595/114412); Loss: 0.067760; Backpropagation: 0.2911 sec; Batch: 2.1236 sec
0.1210 0.1037 0.0809 0.0755 0.0676 0.0640 0.0616 0.0597 0.0586 0.0577 0.0568 0.0562 0.0558 0.0554 0.0550 0.0548 

[TRAIN] Epoch[1](9596/114412); Loss: 0.096168; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1438 0.1373 0.1152 0.1065 0.0986 0.0929 0.0904 0.0885 0.0867 0.0851 0.0840 0.0831 0.0824 0.0819 0.0814 0.0809 

[TRAIN] Epoch[1](9597/114412); Loss: 0.070053; Backpropagation: 0.2907 sec; Batch: 2.1195 sec
0.1276 0.1197 0.0899 0.0780 0.0716 0.0670 0.0628 0.0601 0.0582 0.0569 0.0559 0.0553 0.0548 0.0546 0.0543 0.0541 

[TRAIN] Epoch[1](9598/114412); Loss: 0.087869; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1530 0.1367 0.1058 0.0961 0.0883 0.0847 0.0810 0.0781 0.0762 0.0748 0.0737 0.0727 0.0718 0.0715 0.0709 0.0705 

[TRAIN] Epoch[1](9599/114412); Loss: 0.058521; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1310 0.1199 0.0729 0.0619 0.0570 0.0523 0.0498 0.0475 0.0460 0.0446 0.0437 0.0429 0.0423 0.0420 0.0416 0.0411 

[TRAIN] Epoch[1](9600/114412); Loss: 0.082950; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1473 0.1216 0.1007 0.0940 0.0834 0.0807 0.0762 0.0738 0.0720 0.0705 0.0692 0.0686 0.0682 0.0674 0.0670 0.0665 

[TRAIN] Epoch[1](9601/114412); Loss: 0.076241; Backpropagation: 0.2911 sec; Batch: 2.1020 sec
0.1542 0.1297 0.1007 0.0867 0.0804 0.0735 0.0700 0.0654 0.0622 0.0605 0.0586 0.0574 0.0564 0.0554 0.0548 0.0541 

[TRAIN] Epoch[1](9602/114412); Loss: 0.078551; Backpropagation: 0.2909 sec; Batch: 2.1179 sec
0.1497 0.1292 0.1052 0.0888 0.0815 0.0744 0.0706 0.0669 0.0648 0.0636 0.0622 0.0613 0.0606 0.0598 0.0593 0.0589 

[TRAIN] Epoch[1](9603/114412); Loss: 0.079432; Backpropagation: 0.2910 sec; Batch: 2.1340 sec
0.1363 0.1136 0.0960 0.0887 0.0833 0.0764 0.0733 0.0709 0.0692 0.0684 0.0670 0.0664 0.0659 0.0654 0.0651 0.0649 

[TRAIN] Epoch[1](9604/114412); Loss: 0.085761; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1604 0.1348 0.1027 0.0928 0.0866 0.0815 0.0771 0.0751 0.0734 0.0719 0.0707 0.0700 0.0694 0.0689 0.0686 0.0683 

[TRAIN] Epoch[1](9605/114412); Loss: 0.070503; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1578 0.1406 0.0883 0.0727 0.0639 0.0618 0.0594 0.0577 0.0559 0.0545 0.0536 0.0530 0.0526 0.0523 0.0520 0.0518 

[TRAIN] Epoch[1](9606/114412); Loss: 0.092298; Backpropagation: 0.2902 sec; Batch: 2.1124 sec
0.1696 0.1527 0.1284 0.1079 0.0963 0.0900 0.0849 0.0797 0.0779 0.0749 0.0729 0.0710 0.0690 0.0682 0.0669 0.0663 

[TRAIN] Epoch[1](9607/114412); Loss: 0.111104; Backpropagation: 0.2912 sec; Batch: 2.1189 sec
0.1664 0.1525 0.1295 0.1196 0.1131 0.1089 0.1050 0.1028 0.1008 0.0993 0.0982 0.0975 0.0967 0.0962 0.0957 0.0954 

[TRAIN] Epoch[1](9608/114412); Loss: 0.076868; Backpropagation: 0.2913 sec; Batch: 2.1143 sec
0.1298 0.1190 0.0945 0.0843 0.0787 0.0740 0.0704 0.0686 0.0667 0.0658 0.0646 0.0636 0.0631 0.0627 0.0623 0.0617 

[TRAIN] Epoch[1](9609/114412); Loss: 0.064249; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1143 0.0955 0.0846 0.0734 0.0677 0.0617 0.0585 0.0564 0.0548 0.0536 0.0525 0.0519 0.0513 0.0510 0.0505 0.0503 

[TRAIN] Epoch[1](9610/114412); Loss: 0.107240; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1706 0.1527 0.1283 0.1182 0.1104 0.1058 0.1015 0.0993 0.0963 0.0939 0.0928 0.0913 0.0899 0.0890 0.0882 0.0876 

[TRAIN] Epoch[1](9611/114412); Loss: 0.070944; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.1398 0.1226 0.0950 0.0795 0.0726 0.0669 0.0624 0.0598 0.0582 0.0564 0.0557 0.0549 0.0538 0.0532 0.0525 0.0519 

[TRAIN] Epoch[1](9612/114412); Loss: 0.062495; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1207 0.1166 0.0796 0.0701 0.0635 0.0589 0.0549 0.0531 0.0510 0.0498 0.0486 0.0477 0.0470 0.0467 0.0460 0.0458 

[TRAIN] Epoch[1](9613/114412); Loss: 0.080421; Backpropagation: 0.2915 sec; Batch: 2.1147 sec
0.1627 0.1415 0.0999 0.0885 0.0804 0.0748 0.0702 0.0673 0.0658 0.0646 0.0634 0.0627 0.0621 0.0615 0.0608 0.0605 

[TRAIN] Epoch[1](9614/114412); Loss: 0.085005; Backpropagation: 0.2909 sec; Batch: 2.1111 sec
0.1606 0.1462 0.1163 0.1009 0.0910 0.0826 0.0767 0.0731 0.0695 0.0674 0.0650 0.0640 0.0628 0.0621 0.0613 0.0607 

[TRAIN] Epoch[1](9615/114412); Loss: 0.063137; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1095 0.1053 0.0817 0.0703 0.0615 0.0589 0.0565 0.0550 0.0537 0.0525 0.0519 0.0512 0.0509 0.0506 0.0504 0.0503 

[TRAIN] Epoch[1](9616/114412); Loss: 0.075843; Backpropagation: 0.2951 sec; Batch: 2.1207 sec
0.1457 0.1369 0.1012 0.0862 0.0761 0.0710 0.0674 0.0638 0.0612 0.0601 0.0589 0.0582 0.0574 0.0569 0.0565 0.0560 

[TRAIN] Epoch[1](9617/114412); Loss: 0.060342; Backpropagation: 0.2955 sec; Batch: 2.1228 sec
0.1245 0.1171 0.0768 0.0658 0.0596 0.0559 0.0525 0.0503 0.0486 0.0472 0.0460 0.0453 0.0447 0.0442 0.0437 0.0434 

[TRAIN] Epoch[1](9618/114412); Loss: 0.056901; Backpropagation: 0.2918 sec; Batch: 2.0773 sec
0.1260 0.1187 0.0777 0.0690 0.0584 0.0513 0.0468 0.0449 0.0429 0.0415 0.0405 0.0397 0.0389 0.0384 0.0380 0.0376 

[TRAIN] Epoch[1](9619/114412); Loss: 0.076292; Backpropagation: 0.2916 sec; Batch: 2.0776 sec
0.1276 0.1199 0.0974 0.0838 0.0775 0.0731 0.0699 0.0672 0.0659 0.0646 0.0638 0.0630 0.0623 0.0618 0.0615 0.0612 

[TRAIN] Epoch[1](9620/114412); Loss: 0.059579; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1251 0.1031 0.0710 0.0648 0.0586 0.0553 0.0529 0.0509 0.0494 0.0484 0.0471 0.0464 0.0458 0.0453 0.0449 0.0445 

[TRAIN] Epoch[1](9621/114412); Loss: 0.068599; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1529 0.1441 0.0989 0.0778 0.0707 0.0613 0.0551 0.0538 0.0505 0.0499 0.0492 0.0476 0.0473 0.0466 0.0460 0.0457 

[TRAIN] Epoch[1](9622/114412); Loss: 0.070450; Backpropagation: 0.2910 sec; Batch: 2.1134 sec
0.1661 0.1463 0.0856 0.0699 0.0651 0.0635 0.0606 0.0572 0.0548 0.0533 0.0525 0.0516 0.0510 0.0503 0.0500 0.0496 

[TRAIN] Epoch[1](9623/114412); Loss: 0.075477; Backpropagation: 0.2912 sec; Batch: 2.0780 sec
0.1291 0.1222 0.0954 0.0843 0.0787 0.0729 0.0693 0.0668 0.0647 0.0630 0.0618 0.0612 0.0604 0.0598 0.0592 0.0587 

[TRAIN] Epoch[1](9624/114412); Loss: 0.094810; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1622 0.1511 0.1188 0.1078 0.0961 0.0909 0.0869 0.0842 0.0816 0.0799 0.0787 0.0774 0.0764 0.0756 0.0749 0.0744 

[TRAIN] Epoch[1](9625/114412); Loss: 0.058344; Backpropagation: 0.2913 sec; Batch: 2.1257 sec
0.0989 0.0975 0.0772 0.0668 0.0580 0.0572 0.0538 0.0518 0.0496 0.0478 0.0469 0.0462 0.0459 0.0456 0.0453 0.0451 

[TRAIN] Epoch[1](9626/114412); Loss: 0.082567; Backpropagation: 0.2934 sec; Batch: 2.1160 sec
0.1492 0.1333 0.1043 0.0926 0.0836 0.0786 0.0753 0.0722 0.0701 0.0689 0.0673 0.0664 0.0656 0.0650 0.0645 0.0642 

[TRAIN] Epoch[1](9627/114412); Loss: 0.081158; Backpropagation: 0.2927 sec; Batch: 2.1203 sec
0.1846 0.1741 0.1137 0.0923 0.0749 0.0706 0.0656 0.0628 0.0611 0.0597 0.0592 0.0577 0.0564 0.0558 0.0552 0.0547 

[TRAIN] Epoch[1](9628/114412); Loss: 0.077870; Backpropagation: 0.2929 sec; Batch: 2.1177 sec
0.1529 0.1410 0.1018 0.0875 0.0770 0.0713 0.0679 0.0651 0.0634 0.0620 0.0609 0.0600 0.0594 0.0589 0.0585 0.0582 

[TRAIN] Epoch[1](9629/114412); Loss: 0.083288; Backpropagation: 0.2912 sec; Batch: 2.1159 sec
0.1669 0.1519 0.1151 0.1000 0.0860 0.0780 0.0743 0.0684 0.0659 0.0644 0.0625 0.0611 0.0603 0.0597 0.0592 0.0587 

[TRAIN] Epoch[1](9630/114412); Loss: 0.080021; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1329 0.1249 0.1007 0.0900 0.0840 0.0778 0.0739 0.0710 0.0690 0.0675 0.0664 0.0655 0.0649 0.0644 0.0640 0.0636 

[TRAIN] Epoch[1](9631/114412); Loss: 0.061518; Backpropagation: 0.2904 sec; Batch: 2.1182 sec
0.1172 0.1095 0.0801 0.0666 0.0606 0.0573 0.0545 0.0521 0.0507 0.0496 0.0489 0.0481 0.0477 0.0472 0.0472 0.0469 

[TRAIN] Epoch[1](9632/114412); Loss: 0.055780; Backpropagation: 0.2908 sec; Batch: 2.0788 sec
0.1108 0.0967 0.0705 0.0672 0.0578 0.0527 0.0491 0.0467 0.0452 0.0442 0.0432 0.0425 0.0420 0.0417 0.0414 0.0409 

[TRAIN] Epoch[1](9633/114412); Loss: 0.082054; Backpropagation: 0.2915 sec; Batch: 2.0768 sec
0.1342 0.1283 0.0984 0.0885 0.0833 0.0790 0.0758 0.0736 0.0715 0.0705 0.0695 0.0687 0.0684 0.0678 0.0677 0.0675 

[TRAIN] Epoch[1](9634/114412); Loss: 0.049854; Backpropagation: 0.2913 sec; Batch: 2.0773 sec
0.1280 0.1140 0.0643 0.0513 0.0463 0.0428 0.0404 0.0378 0.0362 0.0354 0.0347 0.0340 0.0335 0.0332 0.0330 0.0328 

[TRAIN] Epoch[1](9635/114412); Loss: 0.075151; Backpropagation: 0.2914 sec; Batch: 2.1197 sec
0.1279 0.1171 0.0936 0.0826 0.0761 0.0720 0.0686 0.0667 0.0653 0.0640 0.0631 0.0624 0.0617 0.0609 0.0604 0.0600 

[TRAIN] Epoch[1](9636/114412); Loss: 0.082885; Backpropagation: 0.2911 sec; Batch: 2.0762 sec
0.1301 0.1253 0.1019 0.0925 0.0841 0.0812 0.0774 0.0748 0.0730 0.0717 0.0706 0.0696 0.0692 0.0685 0.0682 0.0679 

[TRAIN] Epoch[1](9637/114412); Loss: 0.064897; Backpropagation: 0.2906 sec; Batch: 2.1175 sec
0.1346 0.1126 0.0837 0.0706 0.0653 0.0597 0.0576 0.0552 0.0531 0.0517 0.0505 0.0497 0.0492 0.0488 0.0482 0.0477 

[TRAIN] Epoch[1](9638/114412); Loss: 0.078498; Backpropagation: 0.2907 sec; Batch: 2.1176 sec
0.1252 0.1144 0.0947 0.0870 0.0787 0.0755 0.0729 0.0707 0.0695 0.0687 0.0678 0.0673 0.0665 0.0661 0.0657 0.0654 

[TRAIN] Epoch[1](9639/114412); Loss: 0.085594; Backpropagation: 0.2909 sec; Batch: 2.1144 sec
0.1403 0.1274 0.1119 0.0929 0.0892 0.0869 0.0811 0.0786 0.0753 0.0735 0.0719 0.0697 0.0690 0.0680 0.0670 0.0667 

[TRAIN] Epoch[1](9640/114412); Loss: 0.105873; Backpropagation: 0.2914 sec; Batch: 2.0761 sec
0.1843 0.1688 0.1338 0.1169 0.1051 0.0993 0.0953 0.0926 0.0911 0.0895 0.0880 0.0872 0.0863 0.0855 0.0853 0.0851 

[TRAIN] Epoch[1](9641/114412); Loss: 0.075999; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1586 0.1530 0.0986 0.0838 0.0754 0.0676 0.0640 0.0617 0.0599 0.0586 0.0573 0.0566 0.0561 0.0553 0.0549 0.0546 

[TRAIN] Epoch[1](9642/114412); Loss: 0.062368; Backpropagation: 0.2907 sec; Batch: 2.0795 sec
0.1143 0.1070 0.0840 0.0723 0.0651 0.0606 0.0564 0.0533 0.0517 0.0498 0.0487 0.0479 0.0474 0.0469 0.0464 0.0461 

[TRAIN] Epoch[1](9643/114412); Loss: 0.056204; Backpropagation: 0.2911 sec; Batch: 2.1212 sec
0.1184 0.1044 0.0709 0.0622 0.0560 0.0525 0.0495 0.0470 0.0451 0.0441 0.0433 0.0423 0.0416 0.0410 0.0406 0.0403 

[TRAIN] Epoch[1](9644/114412); Loss: 0.077559; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1552 0.1429 0.0940 0.0863 0.0761 0.0709 0.0686 0.0652 0.0634 0.0619 0.0609 0.0602 0.0595 0.0589 0.0585 0.0582 

[TRAIN] Epoch[1](9645/114412); Loss: 0.065574; Backpropagation: 0.2930 sec; Batch: 2.1156 sec
0.1143 0.1071 0.0811 0.0738 0.0668 0.0620 0.0597 0.0577 0.0562 0.0550 0.0540 0.0532 0.0526 0.0522 0.0519 0.0517 

[TRAIN] Epoch[1](9646/114412); Loss: 0.073867; Backpropagation: 0.2932 sec; Batch: 2.1217 sec
0.1426 0.1308 0.1027 0.0885 0.0772 0.0700 0.0648 0.0604 0.0593 0.0576 0.0564 0.0557 0.0546 0.0541 0.0538 0.0534 

[TRAIN] Epoch[1](9647/114412); Loss: 0.056495; Backpropagation: 0.2901 sec; Batch: 2.1184 sec
0.1344 0.1249 0.0724 0.0582 0.0527 0.0477 0.0459 0.0440 0.0424 0.0418 0.0408 0.0404 0.0400 0.0395 0.0394 0.0392 

[TRAIN] Epoch[1](9648/114412); Loss: 0.118667; Backpropagation: 0.2914 sec; Batch: 2.1189 sec
0.1794 0.1638 0.1421 0.1323 0.1242 0.1166 0.1127 0.1092 0.1063 0.1049 0.1033 0.1020 0.1013 0.1007 0.1002 0.0999 

[TRAIN] Epoch[1](9649/114412); Loss: 0.070215; Backpropagation: 0.2910 sec; Batch: 2.0937 sec
0.1275 0.1124 0.0863 0.0779 0.0715 0.0666 0.0639 0.0616 0.0600 0.0591 0.0577 0.0569 0.0563 0.0557 0.0552 0.0549 

[TRAIN] Epoch[1](9650/114412); Loss: 0.076022; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1506 0.1382 0.1127 0.0918 0.0820 0.0698 0.0657 0.0618 0.0588 0.0579 0.0565 0.0553 0.0548 0.0540 0.0532 0.0532 

[TRAIN] Epoch[1](9651/114412); Loss: 0.093381; Backpropagation: 0.2903 sec; Batch: 2.0746 sec
0.1497 0.1377 0.1159 0.1062 0.0956 0.0908 0.0868 0.0840 0.0818 0.0804 0.0794 0.0783 0.0777 0.0771 0.0766 0.0763 

[TRAIN] Epoch[1](9652/114412); Loss: 0.070990; Backpropagation: 0.2927 sec; Batch: 2.1227 sec
0.1228 0.1118 0.0900 0.0800 0.0732 0.0685 0.0652 0.0631 0.0609 0.0596 0.0582 0.0575 0.0568 0.0564 0.0560 0.0557 

[TRAIN] Epoch[1](9653/114412); Loss: 0.091019; Backpropagation: 0.2930 sec; Batch: 2.0790 sec
0.1778 0.1662 0.1188 0.1093 0.0908 0.0819 0.0776 0.0745 0.0728 0.0714 0.0706 0.0698 0.0693 0.0689 0.0685 0.0682 

[TRAIN] Epoch[1](9654/114412); Loss: 0.080168; Backpropagation: 0.2932 sec; Batch: 2.1173 sec
0.1628 0.1403 0.1055 0.0904 0.0796 0.0741 0.0692 0.0682 0.0654 0.0638 0.0626 0.0614 0.0607 0.0600 0.0594 0.0591 

[TRAIN] Epoch[1](9655/114412); Loss: 0.078906; Backpropagation: 0.2926 sec; Batch: 2.0776 sec
0.1301 0.1151 0.0996 0.0877 0.0803 0.0764 0.0729 0.0710 0.0692 0.0680 0.0670 0.0660 0.0655 0.0649 0.0645 0.0642 

[TRAIN] Epoch[1](9656/114412); Loss: 0.069398; Backpropagation: 0.2928 sec; Batch: 2.1043 sec
0.1247 0.1148 0.0903 0.0791 0.0710 0.0660 0.0626 0.0601 0.0581 0.0570 0.0561 0.0552 0.0546 0.0540 0.0535 0.0532 

[TRAIN] Epoch[1](9657/114412); Loss: 0.090475; Backpropagation: 0.2932 sec; Batch: 2.0802 sec
0.1493 0.1392 0.1123 0.1018 0.0926 0.0867 0.0829 0.0806 0.0787 0.0774 0.0763 0.0754 0.0745 0.0737 0.0733 0.0729 

[TRAIN] Epoch[1](9658/114412); Loss: 0.069225; Backpropagation: 0.2924 sec; Batch: 2.1199 sec
0.1037 0.0951 0.0882 0.0762 0.0727 0.0679 0.0647 0.0633 0.0620 0.0607 0.0601 0.0594 0.0588 0.0585 0.0583 0.0579 

[TRAIN] Epoch[1](9659/114412); Loss: 0.099229; Backpropagation: 0.2928 sec; Batch: 2.1204 sec
0.1665 0.1449 0.1151 0.1056 0.0987 0.0964 0.0930 0.0901 0.0891 0.0870 0.0857 0.0846 0.0837 0.0829 0.0825 0.0818 

[TRAIN] Epoch[1](9660/114412); Loss: 0.057817; Backpropagation: 0.2908 sec; Batch: 2.0846 sec
0.1158 0.1051 0.0768 0.0676 0.0592 0.0537 0.0505 0.0478 0.0462 0.0453 0.0442 0.0436 0.0429 0.0425 0.0420 0.0418 

[TRAIN] Epoch[1](9661/114412); Loss: 0.109217; Backpropagation: 0.2914 sec; Batch: 2.1146 sec
0.1585 0.1508 0.1288 0.1218 0.1144 0.1097 0.1061 0.1024 0.0999 0.0976 0.0959 0.0944 0.0933 0.0921 0.0913 0.0904 

[TRAIN] Epoch[1](9662/114412); Loss: 0.081362; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1520 0.1356 0.0983 0.0889 0.0810 0.0770 0.0739 0.0705 0.0688 0.0677 0.0662 0.0655 0.0647 0.0644 0.0638 0.0636 

[TRAIN] Epoch[1](9663/114412); Loss: 0.080329; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1437 0.1356 0.1091 0.0948 0.0892 0.0800 0.0744 0.0713 0.0678 0.0629 0.0621 0.0610 0.0593 0.0583 0.0581 0.0576 

[TRAIN] Epoch[1](9664/114412); Loss: 0.072635; Backpropagation: 0.2911 sec; Batch: 2.1138 sec
0.1679 0.1450 0.0887 0.0753 0.0687 0.0634 0.0610 0.0587 0.0572 0.0560 0.0549 0.0543 0.0534 0.0530 0.0526 0.0521 

[TRAIN] Epoch[1](9665/114412); Loss: 0.088133; Backpropagation: 0.2912 sec; Batch: 2.1143 sec
0.1563 0.1436 0.1064 0.0963 0.0892 0.0834 0.0802 0.0771 0.0755 0.0741 0.0730 0.0723 0.0715 0.0709 0.0704 0.0700 

[TRAIN] Epoch[1](9666/114412); Loss: 0.066347; Backpropagation: 0.2911 sec; Batch: 2.0929 sec
0.1206 0.1167 0.0942 0.0851 0.0744 0.0666 0.0609 0.0568 0.0537 0.0513 0.0493 0.0480 0.0470 0.0462 0.0456 0.0452 

[TRAIN] Epoch[1](9667/114412); Loss: 0.083795; Backpropagation: 0.2932 sec; Batch: 2.1197 sec
0.1372 0.1242 0.1013 0.0915 0.0848 0.0814 0.0786 0.0760 0.0741 0.0725 0.0715 0.0704 0.0698 0.0695 0.0690 0.0688 

[TRAIN] Epoch[1](9668/114412); Loss: 0.069661; Backpropagation: 0.2930 sec; Batch: 2.1179 sec
0.1767 0.1581 0.1154 0.0860 0.0685 0.0569 0.0533 0.0502 0.0477 0.0458 0.0444 0.0433 0.0427 0.0421 0.0418 0.0415 

[TRAIN] Epoch[1](9669/114412); Loss: 0.099729; Backpropagation: 0.2912 sec; Batch: 2.1327 sec
0.1715 0.1597 0.1290 0.1095 0.1009 0.0975 0.0909 0.0901 0.0868 0.0828 0.0823 0.0809 0.0790 0.0789 0.0782 0.0775 

[TRAIN] Epoch[1](9670/114412); Loss: 0.049766; Backpropagation: 0.2911 sec; Batch: 2.1159 sec
0.1130 0.1008 0.0670 0.0544 0.0475 0.0436 0.0416 0.0394 0.0384 0.0372 0.0366 0.0361 0.0357 0.0353 0.0350 0.0348 

[TRAIN] Epoch[1](9671/114412); Loss: 0.072748; Backpropagation: 0.2916 sec; Batch: 2.1029 sec
0.1371 0.1177 0.0915 0.0816 0.0750 0.0687 0.0665 0.0635 0.0618 0.0601 0.0588 0.0578 0.0570 0.0563 0.0556 0.0551 

[TRAIN] Epoch[1](9672/114412); Loss: 0.074396; Backpropagation: 0.2915 sec; Batch: 2.1167 sec
0.1667 0.1507 0.0952 0.0763 0.0708 0.0659 0.0624 0.0605 0.0584 0.0569 0.0558 0.0552 0.0545 0.0540 0.0537 0.0533 

[TRAIN] Epoch[1](9673/114412); Loss: 0.078519; Backpropagation: 0.2910 sec; Batch: 2.0773 sec
0.1649 0.1477 0.1125 0.0854 0.0814 0.0711 0.0654 0.0634 0.0614 0.0598 0.0586 0.0579 0.0573 0.0567 0.0564 0.0563 

[TRAIN] Epoch[1](9674/114412); Loss: 0.074640; Backpropagation: 0.2909 sec; Batch: 2.0824 sec
0.1430 0.1287 0.0993 0.0860 0.0776 0.0707 0.0668 0.0635 0.0612 0.0597 0.0583 0.0572 0.0563 0.0557 0.0552 0.0549 

[TRAIN] Epoch[1](9675/114412); Loss: 0.085230; Backpropagation: 0.2914 sec; Batch: 2.0767 sec
0.1283 0.1217 0.1027 0.0955 0.0874 0.0828 0.0802 0.0781 0.0765 0.0752 0.0743 0.0734 0.0727 0.0721 0.0717 0.0712 

[TRAIN] Epoch[1](9676/114412); Loss: 0.061010; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1265 0.1139 0.0799 0.0696 0.0601 0.0552 0.0526 0.0508 0.0494 0.0478 0.0469 0.0460 0.0449 0.0447 0.0442 0.0437 

[TRAIN] Epoch[1](9677/114412); Loss: 0.060410; Backpropagation: 0.2931 sec; Batch: 2.0785 sec
0.1245 0.1102 0.0840 0.0688 0.0612 0.0568 0.0524 0.0499 0.0481 0.0465 0.0456 0.0446 0.0441 0.0436 0.0432 0.0429 

[TRAIN] Epoch[1](9678/114412); Loss: 0.061873; Backpropagation: 0.2912 sec; Batch: 2.0774 sec
0.1665 0.1458 0.0723 0.0717 0.0547 0.0499 0.0479 0.0456 0.0445 0.0434 0.0426 0.0419 0.0413 0.0409 0.0406 0.0404 

[TRAIN] Epoch[1](9679/114412); Loss: 0.096412; Backpropagation: 0.2933 sec; Batch: 2.0848 sec
0.1546 0.1417 0.1166 0.1056 0.0995 0.0933 0.0906 0.0876 0.0855 0.0837 0.0825 0.0815 0.0809 0.0803 0.0796 0.0791 

[TRAIN] Epoch[1](9680/114412); Loss: 0.070177; Backpropagation: 0.2937 sec; Batch: 2.1211 sec
0.1283 0.1158 0.0906 0.0819 0.0727 0.0673 0.0640 0.0609 0.0588 0.0573 0.0560 0.0550 0.0542 0.0537 0.0533 0.0530 

[TRAIN] Epoch[1](9681/114412); Loss: 0.087055; Backpropagation: 0.2928 sec; Batch: 2.0786 sec
0.1756 0.1432 0.1078 0.0935 0.0866 0.0805 0.0770 0.0753 0.0727 0.0714 0.0705 0.0689 0.0682 0.0677 0.0670 0.0668 

[TRAIN] Epoch[1](9682/114412); Loss: 0.071342; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.1259 0.1096 0.0858 0.0769 0.0727 0.0698 0.0668 0.0642 0.0621 0.0608 0.0596 0.0588 0.0580 0.0572 0.0568 0.0563 

[TRAIN] Epoch[1](9683/114412); Loss: 0.093017; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1487 0.1419 0.1241 0.1075 0.0959 0.0875 0.0837 0.0815 0.0802 0.0789 0.0778 0.0772 0.0766 0.0760 0.0755 0.0752 

[TRAIN] Epoch[1](9684/114412); Loss: 0.064429; Backpropagation: 0.2915 sec; Batch: 2.1147 sec
0.1398 0.1199 0.0873 0.0789 0.0656 0.0597 0.0563 0.0529 0.0507 0.0484 0.0478 0.0464 0.0452 0.0447 0.0439 0.0433 

[TRAIN] Epoch[1](9685/114412); Loss: 0.084632; Backpropagation: 0.2919 sec; Batch: 2.1191 sec
0.1960 0.1744 0.1246 0.0968 0.0752 0.0715 0.0674 0.0654 0.0644 0.0629 0.0614 0.0601 0.0593 0.0586 0.0582 0.0579 

[TRAIN] Epoch[1](9686/114412); Loss: 0.063337; Backpropagation: 0.2911 sec; Batch: 2.1311 sec
0.1087 0.1047 0.0817 0.0737 0.0643 0.0605 0.0585 0.0565 0.0548 0.0530 0.0515 0.0504 0.0497 0.0490 0.0485 0.0480 

[TRAIN] Epoch[1](9687/114412); Loss: 0.075447; Backpropagation: 0.2907 sec; Batch: 2.1166 sec
0.1370 0.1219 0.0888 0.0827 0.0763 0.0709 0.0675 0.0656 0.0642 0.0632 0.0625 0.0622 0.0615 0.0611 0.0610 0.0607 

[TRAIN] Epoch[1](9688/114412); Loss: 0.068626; Backpropagation: 0.2910 sec; Batch: 2.1266 sec
0.1454 0.1296 0.1019 0.0831 0.0728 0.0646 0.0577 0.0552 0.0535 0.0505 0.0495 0.0483 0.0473 0.0469 0.0460 0.0457 

[TRAIN] Epoch[1](9689/114412); Loss: 0.068447; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1201 0.1124 0.0869 0.0783 0.0701 0.0657 0.0619 0.0600 0.0578 0.0567 0.0556 0.0549 0.0543 0.0539 0.0535 0.0532 

[TRAIN] Epoch[1](9690/114412); Loss: 0.078950; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1412 0.1216 0.0974 0.0870 0.0800 0.0749 0.0717 0.0697 0.0682 0.0669 0.0656 0.0650 0.0642 0.0638 0.0633 0.0628 

[TRAIN] Epoch[1](9691/114412); Loss: 0.088134; Backpropagation: 0.2923 sec; Batch: 2.1181 sec
0.1333 0.1249 0.1072 0.0962 0.0914 0.0863 0.0824 0.0810 0.0794 0.0779 0.0767 0.0758 0.0752 0.0746 0.0742 0.0737 

[TRAIN] Epoch[1](9692/114412); Loss: 0.066781; Backpropagation: 0.2950 sec; Batch: 2.1201 sec
0.1115 0.1085 0.0877 0.0756 0.0692 0.0647 0.0626 0.0593 0.0577 0.0559 0.0550 0.0537 0.0530 0.0519 0.0514 0.0507 

[TRAIN] Epoch[1](9693/114412); Loss: 0.052837; Backpropagation: 0.2938 sec; Batch: 2.1001 sec
0.1056 0.0888 0.0691 0.0623 0.0556 0.0500 0.0470 0.0441 0.0425 0.0416 0.0408 0.0402 0.0398 0.0394 0.0393 0.0392 

[TRAIN] Epoch[1](9694/114412); Loss: 0.080732; Backpropagation: 0.2955 sec; Batch: 2.1199 sec
0.1547 0.1420 0.0941 0.0864 0.0799 0.0745 0.0717 0.0696 0.0680 0.0667 0.0659 0.0647 0.0641 0.0637 0.0631 0.0628 

[TRAIN] Epoch[1](9695/114412); Loss: 0.087682; Backpropagation: 0.2932 sec; Batch: 2.1152 sec
0.1630 0.1533 0.1192 0.1051 0.0896 0.0822 0.0793 0.0752 0.0719 0.0694 0.0681 0.0671 0.0659 0.0651 0.0646 0.0639 

[TRAIN] Epoch[1](9696/114412); Loss: 0.083339; Backpropagation: 0.2907 sec; Batch: 2.1147 sec
0.1913 0.1637 0.1156 0.0894 0.0863 0.0729 0.0674 0.0661 0.0637 0.0625 0.0608 0.0598 0.0590 0.0587 0.0582 0.0580 

[TRAIN] Epoch[1](9697/114412); Loss: 0.078901; Backpropagation: 0.2913 sec; Batch: 2.0773 sec
0.1568 0.1410 0.1009 0.0867 0.0761 0.0722 0.0682 0.0659 0.0646 0.0634 0.0624 0.0619 0.0612 0.0608 0.0603 0.0601 

[TRAIN] Epoch[1](9698/114412); Loss: 0.058829; Backpropagation: 0.2915 sec; Batch: 2.0786 sec
0.1131 0.0984 0.0759 0.0665 0.0589 0.0545 0.0522 0.0505 0.0493 0.0482 0.0471 0.0462 0.0456 0.0453 0.0450 0.0447 

[TRAIN] Epoch[1](9699/114412); Loss: 0.067238; Backpropagation: 0.2945 sec; Batch: 2.0798 sec
0.1219 0.1115 0.0877 0.0757 0.0668 0.0627 0.0602 0.0581 0.0563 0.0552 0.0545 0.0540 0.0533 0.0530 0.0526 0.0524 

[TRAIN] Epoch[1](9700/114412); Loss: 0.077455; Backpropagation: 0.2928 sec; Batch: 2.0787 sec
0.1218 0.1168 0.0984 0.0827 0.0791 0.0770 0.0725 0.0704 0.0686 0.0671 0.0661 0.0651 0.0645 0.0635 0.0630 0.0626 

[TRAIN] Epoch[1](9701/114412); Loss: 0.111471; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.1996 0.1858 0.1384 0.1183 0.1071 0.1029 0.0995 0.0967 0.0955 0.0942 0.0925 0.0917 0.0911 0.0905 0.0900 0.0897 

[TRAIN] Epoch[1](9702/114412); Loss: 0.088831; Backpropagation: 0.2911 sec; Batch: 2.1131 sec
0.1875 0.1600 0.1006 0.0994 0.0820 0.0776 0.0754 0.0745 0.0728 0.0723 0.0709 0.0705 0.0699 0.0696 0.0692 0.0692 

[TRAIN] Epoch[1](9703/114412); Loss: 0.061040; Backpropagation: 0.2931 sec; Batch: 2.1212 sec
0.1405 0.1197 0.0859 0.0689 0.0580 0.0542 0.0518 0.0494 0.0468 0.0452 0.0443 0.0435 0.0429 0.0422 0.0417 0.0414 

[TRAIN] Epoch[1](9704/114412); Loss: 0.068823; Backpropagation: 0.2949 sec; Batch: 2.1177 sec
0.1337 0.1113 0.0851 0.0757 0.0676 0.0632 0.0616 0.0592 0.0578 0.0567 0.0560 0.0555 0.0550 0.0546 0.0542 0.0540 

[TRAIN] Epoch[1](9705/114412); Loss: 0.072241; Backpropagation: 0.2934 sec; Batch: 2.1200 sec
0.1403 0.1283 0.0971 0.0833 0.0749 0.0679 0.0643 0.0614 0.0588 0.0574 0.0561 0.0546 0.0540 0.0531 0.0523 0.0519 

[TRAIN] Epoch[1](9706/114412); Loss: 0.050063; Backpropagation: 0.2905 sec; Batch: 2.0766 sec
0.0907 0.0872 0.0647 0.0567 0.0516 0.0476 0.0449 0.0427 0.0414 0.0405 0.0398 0.0393 0.0389 0.0386 0.0383 0.0383 

[TRAIN] Epoch[1](9707/114412); Loss: 0.089075; Backpropagation: 0.2906 sec; Batch: 2.1160 sec
0.1517 0.1396 0.1112 0.1006 0.0918 0.0862 0.0824 0.0788 0.0769 0.0753 0.0737 0.0729 0.0720 0.0713 0.0707 0.0702 

[TRAIN] Epoch[1](9708/114412); Loss: 0.072859; Backpropagation: 0.2909 sec; Batch: 2.1144 sec
0.1575 0.1349 0.1074 0.0898 0.0788 0.0701 0.0635 0.0585 0.0564 0.0536 0.0516 0.0503 0.0492 0.0486 0.0481 0.0475 

[TRAIN] Epoch[1](9709/114412); Loss: 0.098570; Backpropagation: 0.2929 sec; Batch: 2.1274 sec
0.1499 0.1414 0.1150 0.1073 0.0999 0.0959 0.0928 0.0906 0.0888 0.0875 0.0863 0.0855 0.0847 0.0843 0.0838 0.0834 

[TRAIN] Epoch[1](9710/114412); Loss: 0.072041; Backpropagation: 0.2930 sec; Batch: 2.1189 sec
0.1384 0.1263 0.0969 0.0841 0.0745 0.0679 0.0648 0.0620 0.0589 0.0575 0.0556 0.0543 0.0538 0.0531 0.0525 0.0522 

[TRAIN] Epoch[1](9711/114412); Loss: 0.092811; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1536 0.1340 0.1114 0.1021 0.0949 0.0895 0.0874 0.0842 0.0820 0.0806 0.0789 0.0782 0.0776 0.0770 0.0767 0.0767 

[TRAIN] Epoch[1](9712/114412); Loss: 0.077656; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1541 0.1350 0.1084 0.0951 0.0818 0.0747 0.0699 0.0660 0.0627 0.0597 0.0583 0.0569 0.0561 0.0552 0.0545 0.0541 

[TRAIN] Epoch[1](9713/114412); Loss: 0.117268; Backpropagation: 0.2909 sec; Batch: 2.1249 sec
0.1736 0.1664 0.1388 0.1279 0.1205 0.1147 0.1110 0.1081 0.1061 0.1045 0.1030 0.1020 0.1010 0.1001 0.0996 0.0990 

[TRAIN] Epoch[1](9714/114412); Loss: 0.085519; Backpropagation: 0.2913 sec; Batch: 2.1140 sec
0.1456 0.1341 0.1093 0.0989 0.0892 0.0830 0.0785 0.0751 0.0733 0.0716 0.0702 0.0696 0.0686 0.0677 0.0671 0.0665 

[TRAIN] Epoch[1](9715/114412); Loss: 0.062985; Backpropagation: 0.2912 sec; Batch: 2.1136 sec
0.1028 0.0989 0.0842 0.0739 0.0657 0.0609 0.0575 0.0554 0.0538 0.0526 0.0518 0.0510 0.0505 0.0501 0.0495 0.0491 

[TRAIN] Epoch[1](9716/114412); Loss: 0.067947; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1315 0.1127 0.0823 0.0754 0.0666 0.0638 0.0607 0.0585 0.0573 0.0559 0.0550 0.0543 0.0538 0.0535 0.0531 0.0528 

[TRAIN] Epoch[1](9717/114412); Loss: 0.077125; Backpropagation: 0.2913 sec; Batch: 2.1137 sec
0.1224 0.1140 0.0916 0.0835 0.0776 0.0742 0.0717 0.0699 0.0687 0.0678 0.0669 0.0662 0.0655 0.0649 0.0646 0.0644 

[TRAIN] Epoch[1](9718/114412); Loss: 0.075812; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1349 0.1240 0.0997 0.0848 0.0769 0.0724 0.0686 0.0665 0.0643 0.0630 0.0616 0.0606 0.0597 0.0592 0.0587 0.0583 

[TRAIN] Epoch[1](9719/114412); Loss: 0.086885; Backpropagation: 0.2911 sec; Batch: 2.1142 sec
0.1386 0.1246 0.1033 0.0967 0.0901 0.0847 0.0813 0.0792 0.0771 0.0758 0.0747 0.0738 0.0733 0.0727 0.0722 0.0720 

[TRAIN] Epoch[1](9720/114412); Loss: 0.074628; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1380 0.1230 0.1000 0.0850 0.0773 0.0704 0.0662 0.0638 0.0619 0.0604 0.0591 0.0584 0.0580 0.0577 0.0574 0.0573 

[TRAIN] Epoch[1](9721/114412); Loss: 0.090229; Backpropagation: 0.2929 sec; Batch: 2.0781 sec
0.1451 0.1324 0.1100 0.0972 0.0909 0.0862 0.0835 0.0816 0.0799 0.0789 0.0780 0.0773 0.0766 0.0759 0.0754 0.0747 

[TRAIN] Epoch[1](9722/114412); Loss: 0.051098; Backpropagation: 0.2929 sec; Batch: 2.1235 sec
0.1141 0.1022 0.0709 0.0590 0.0511 0.0476 0.0440 0.0410 0.0390 0.0377 0.0367 0.0358 0.0353 0.0348 0.0343 0.0340 

[TRAIN] Epoch[1](9723/114412); Loss: 0.060757; Backpropagation: 0.2908 sec; Batch: 2.1150 sec
0.1265 0.1052 0.0766 0.0650 0.0619 0.0560 0.0549 0.0516 0.0493 0.0487 0.0473 0.0465 0.0462 0.0457 0.0455 0.0452 

[TRAIN] Epoch[1](9724/114412); Loss: 0.044222; Backpropagation: 0.2924 sec; Batch: 2.0792 sec
0.1018 0.0854 0.0593 0.0514 0.0435 0.0397 0.0366 0.0351 0.0338 0.0328 0.0321 0.0316 0.0315 0.0311 0.0310 0.0308 

[TRAIN] Epoch[1](9725/114412); Loss: 0.073581; Backpropagation: 0.2952 sec; Batch: 2.1256 sec
0.1320 0.1175 0.0919 0.0819 0.0740 0.0692 0.0671 0.0649 0.0632 0.0617 0.0608 0.0598 0.0590 0.0584 0.0581 0.0578 

[TRAIN] Epoch[1](9726/114412); Loss: 0.074103; Backpropagation: 0.2957 sec; Batch: 2.0854 sec
0.1211 0.1168 0.0916 0.0875 0.0762 0.0719 0.0686 0.0660 0.0644 0.0628 0.0615 0.0606 0.0599 0.0593 0.0589 0.0585 

[TRAIN] Epoch[1](9727/114412); Loss: 0.079068; Backpropagation: 0.2928 sec; Batch: 2.1022 sec
0.1530 0.1219 0.0853 0.0837 0.0789 0.0746 0.0728 0.0696 0.0682 0.0670 0.0663 0.0654 0.0649 0.0646 0.0644 0.0644 

[TRAIN] Epoch[1](9728/114412); Loss: 0.062909; Backpropagation: 0.2912 sec; Batch: 2.1321 sec
0.1315 0.1095 0.0814 0.0720 0.0666 0.0598 0.0564 0.0537 0.0511 0.0496 0.0482 0.0470 0.0458 0.0452 0.0446 0.0441 

[TRAIN] Epoch[1](9729/114412); Loss: 0.053082; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1301 0.1214 0.0799 0.0583 0.0477 0.0450 0.0413 0.0391 0.0377 0.0370 0.0364 0.0357 0.0353 0.0350 0.0347 0.0346 

[TRAIN] Epoch[1](9730/114412); Loss: 0.098841; Backpropagation: 0.2914 sec; Batch: 2.1135 sec
0.2200 0.1977 0.1318 0.1041 0.0920 0.0850 0.0819 0.0790 0.0768 0.0756 0.0746 0.0736 0.0731 0.0723 0.0720 0.0717 

[TRAIN] Epoch[1](9731/114412); Loss: 0.084043; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1494 0.1420 0.1087 0.0944 0.0844 0.0795 0.0759 0.0734 0.0712 0.0697 0.0680 0.0672 0.0663 0.0655 0.0649 0.0642 

[TRAIN] Epoch[1](9732/114412); Loss: 0.074220; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1446 0.1248 0.0972 0.0817 0.0707 0.0673 0.0647 0.0631 0.0613 0.0603 0.0594 0.0591 0.0587 0.0584 0.0581 0.0581 

[TRAIN] Epoch[1](9733/114412); Loss: 0.064105; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.1260 0.1163 0.0910 0.0799 0.0691 0.0608 0.0558 0.0525 0.0501 0.0486 0.0475 0.0469 0.0460 0.0454 0.0451 0.0448 

[TRAIN] Epoch[1](9734/114412); Loss: 0.073488; Backpropagation: 0.2908 sec; Batch: 2.1165 sec
0.1348 0.1247 0.0881 0.0786 0.0723 0.0685 0.0660 0.0637 0.0623 0.0614 0.0604 0.0596 0.0592 0.0589 0.0587 0.0585 

[TRAIN] Epoch[1](9735/114412); Loss: 0.069638; Backpropagation: 0.2911 sec; Batch: 2.1261 sec
0.1289 0.1229 0.0881 0.0837 0.0712 0.0651 0.0619 0.0589 0.0575 0.0558 0.0548 0.0540 0.0534 0.0530 0.0526 0.0524 

[TRAIN] Epoch[1](9736/114412); Loss: 0.063069; Backpropagation: 0.2955 sec; Batch: 2.1303 sec
0.1302 0.1135 0.0786 0.0700 0.0632 0.0582 0.0561 0.0530 0.0515 0.0504 0.0490 0.0481 0.0475 0.0469 0.0466 0.0462 

[TRAIN] Epoch[1](9737/114412); Loss: 0.078898; Backpropagation: 0.2929 sec; Batch: 2.1178 sec
0.1330 0.1211 0.0946 0.0856 0.0799 0.0749 0.0722 0.0708 0.0688 0.0677 0.0670 0.0662 0.0657 0.0653 0.0650 0.0647 

[TRAIN] Epoch[1](9738/114412); Loss: 0.088029; Backpropagation: 0.2913 sec; Batch: 2.1120 sec
0.1470 0.1365 0.1023 0.0931 0.0871 0.0835 0.0819 0.0788 0.0774 0.0766 0.0755 0.0749 0.0743 0.0738 0.0731 0.0727 

[TRAIN] Epoch[1](9739/114412); Loss: 0.070396; Backpropagation: 0.2908 sec; Batch: 2.1183 sec
0.1480 0.1355 0.0939 0.0774 0.0701 0.0634 0.0602 0.0575 0.0556 0.0544 0.0532 0.0525 0.0519 0.0512 0.0509 0.0506 

[TRAIN] Epoch[1](9740/114412); Loss: 0.061193; Backpropagation: 0.2908 sec; Batch: 2.1182 sec
0.1579 0.1372 0.0872 0.0715 0.0614 0.0536 0.0480 0.0463 0.0435 0.0416 0.0406 0.0392 0.0384 0.0383 0.0374 0.0371 

[TRAIN] Epoch[1](9741/114412); Loss: 0.070646; Backpropagation: 0.2909 sec; Batch: 2.1169 sec
0.1434 0.1261 0.0988 0.0839 0.0724 0.0661 0.0610 0.0587 0.0563 0.0545 0.0534 0.0523 0.0516 0.0509 0.0506 0.0504 

[TRAIN] Epoch[1](9742/114412); Loss: 0.080068; Backpropagation: 0.2904 sec; Batch: 2.0760 sec
0.1366 0.1280 0.0959 0.0868 0.0805 0.0758 0.0734 0.0710 0.0695 0.0679 0.0672 0.0665 0.0660 0.0656 0.0653 0.0652 

[TRAIN] Epoch[1](9743/114412); Loss: 0.069705; Backpropagation: 0.2930 sec; Batch: 2.1171 sec
0.1589 0.1337 0.0816 0.0780 0.0696 0.0623 0.0609 0.0573 0.0551 0.0538 0.0521 0.0514 0.0509 0.0503 0.0499 0.0494 

[TRAIN] Epoch[1](9744/114412); Loss: 0.070477; Backpropagation: 0.2929 sec; Batch: 2.1176 sec
0.1599 0.1262 0.0875 0.0791 0.0698 0.0659 0.0603 0.0585 0.0563 0.0540 0.0531 0.0524 0.0517 0.0514 0.0510 0.0506 

[TRAIN] Epoch[1](9745/114412); Loss: 0.060730; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1274 0.1170 0.0768 0.0684 0.0597 0.0560 0.0538 0.0508 0.0491 0.0473 0.0462 0.0452 0.0445 0.0438 0.0430 0.0428 

[TRAIN] Epoch[1](9746/114412); Loss: 0.081112; Backpropagation: 0.2939 sec; Batch: 2.1177 sec
0.1646 0.1372 0.1057 0.0861 0.0828 0.0760 0.0705 0.0683 0.0661 0.0649 0.0641 0.0633 0.0627 0.0622 0.0618 0.0616 

[TRAIN] Epoch[1](9747/114412); Loss: 0.057072; Backpropagation: 0.2928 sec; Batch: 2.1156 sec
0.1087 0.1031 0.0752 0.0636 0.0565 0.0528 0.0506 0.0486 0.0469 0.0460 0.0450 0.0444 0.0438 0.0431 0.0426 0.0422 

[TRAIN] Epoch[1](9748/114412); Loss: 0.078837; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1430 0.1312 0.0969 0.0888 0.0816 0.0752 0.0720 0.0684 0.0673 0.0654 0.0639 0.0628 0.0621 0.0613 0.0608 0.0606 

[TRAIN] Epoch[1](9749/114412); Loss: 0.086727; Backpropagation: 0.2913 sec; Batch: 2.0948 sec
0.1468 0.1316 0.1036 0.0980 0.0907 0.0850 0.0817 0.0786 0.0763 0.0744 0.0730 0.0716 0.0704 0.0695 0.0684 0.0679 

[TRAIN] Epoch[1](9750/114412); Loss: 0.063132; Backpropagation: 0.2916 sec; Batch: 2.0778 sec
0.1130 0.1082 0.0839 0.0741 0.0687 0.0634 0.0575 0.0552 0.0531 0.0505 0.0491 0.0483 0.0471 0.0465 0.0460 0.0456 

[TRAIN] Epoch[1](9751/114412); Loss: 0.073464; Backpropagation: 0.2940 sec; Batch: 2.1346 sec
0.1938 0.1678 0.1151 0.0755 0.0762 0.0619 0.0557 0.0534 0.0507 0.0487 0.0479 0.0468 0.0463 0.0457 0.0450 0.0450 

[TRAIN] Epoch[1](9752/114412); Loss: 0.076609; Backpropagation: 0.2951 sec; Batch: 2.0840 sec
0.1678 0.1507 0.1004 0.0860 0.0743 0.0679 0.0649 0.0623 0.0601 0.0586 0.0573 0.0562 0.0555 0.0550 0.0545 0.0541 

[TRAIN] Epoch[1](9753/114412); Loss: 0.081908; Backpropagation: 0.2908 sec; Batch: 2.0767 sec
0.1465 0.1376 0.1023 0.0956 0.0879 0.0799 0.0762 0.0737 0.0699 0.0677 0.0662 0.0634 0.0626 0.0617 0.0602 0.0593 

[TRAIN] Epoch[1](9754/114412); Loss: 0.075264; Backpropagation: 0.2897 sec; Batch: 2.1155 sec
0.1452 0.1203 0.0918 0.0821 0.0749 0.0713 0.0680 0.0656 0.0636 0.0622 0.0611 0.0605 0.0600 0.0595 0.0592 0.0590 

[TRAIN] Epoch[1](9755/114412); Loss: 0.070015; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1302 0.1028 0.0840 0.0766 0.0708 0.0665 0.0633 0.0622 0.0602 0.0592 0.0586 0.0580 0.0575 0.0571 0.0568 0.0565 

[TRAIN] Epoch[1](9756/114412); Loss: 0.077130; Backpropagation: 0.2914 sec; Batch: 2.0793 sec
0.1322 0.1244 0.0964 0.0877 0.0799 0.0746 0.0709 0.0676 0.0662 0.0644 0.0632 0.0625 0.0617 0.0613 0.0608 0.0603 

[TRAIN] Epoch[1](9757/114412); Loss: 0.069005; Backpropagation: 0.2914 sec; Batch: 2.0773 sec
0.1414 0.1314 0.0943 0.0775 0.0693 0.0641 0.0601 0.0576 0.0550 0.0533 0.0522 0.0510 0.0503 0.0495 0.0488 0.0483 

[TRAIN] Epoch[1](9758/114412); Loss: 0.081399; Backpropagation: 0.2952 sec; Batch: 2.1497 sec
0.1505 0.1314 0.1029 0.0906 0.0841 0.0773 0.0750 0.0721 0.0684 0.0669 0.0658 0.0647 0.0638 0.0633 0.0629 0.0626 

[TRAIN] Epoch[1](9759/114412); Loss: 0.067734; Backpropagation: 0.2932 sec; Batch: 2.1154 sec
0.1206 0.1067 0.0843 0.0775 0.0690 0.0645 0.0618 0.0607 0.0589 0.0566 0.0556 0.0548 0.0541 0.0534 0.0529 0.0524 

[TRAIN] Epoch[1](9760/114412); Loss: 0.075784; Backpropagation: 0.2953 sec; Batch: 2.0833 sec
0.1507 0.1433 0.1039 0.0872 0.0798 0.0727 0.0689 0.0635 0.0608 0.0587 0.0562 0.0549 0.0541 0.0533 0.0525 0.0521 

[TRAIN] Epoch[1](9761/114412); Loss: 0.069416; Backpropagation: 0.2929 sec; Batch: 2.1201 sec
0.1601 0.1377 0.0963 0.0831 0.0753 0.0659 0.0585 0.0538 0.0514 0.0492 0.0483 0.0473 0.0467 0.0461 0.0457 0.0453 

[TRAIN] Epoch[1](9762/114412); Loss: 0.063688; Backpropagation: 0.2905 sec; Batch: 2.0936 sec
0.1239 0.1065 0.0810 0.0707 0.0656 0.0606 0.0564 0.0544 0.0526 0.0514 0.0506 0.0500 0.0494 0.0490 0.0486 0.0484 

[TRAIN] Epoch[1](9763/114412); Loss: 0.049945; Backpropagation: 0.2912 sec; Batch: 2.0792 sec
0.1221 0.0886 0.0626 0.0543 0.0492 0.0462 0.0425 0.0403 0.0393 0.0380 0.0373 0.0365 0.0361 0.0356 0.0353 0.0352 

[TRAIN] Epoch[1](9764/114412); Loss: 0.087931; Backpropagation: 0.2904 sec; Batch: 2.0765 sec
0.1523 0.1361 0.1122 0.1004 0.0910 0.0853 0.0810 0.0782 0.0762 0.0737 0.0722 0.0716 0.0704 0.0695 0.0686 0.0683 

[TRAIN] Epoch[1](9765/114412); Loss: 0.064257; Backpropagation: 0.2928 sec; Batch: 2.1203 sec
0.1219 0.1140 0.0799 0.0730 0.0667 0.0594 0.0567 0.0556 0.0527 0.0516 0.0507 0.0502 0.0495 0.0490 0.0488 0.0485 

[TRAIN] Epoch[1](9766/114412); Loss: 0.068504; Backpropagation: 0.2932 sec; Batch: 2.1135 sec
0.1703 0.1364 0.1002 0.0790 0.0671 0.0585 0.0556 0.0528 0.0506 0.0491 0.0479 0.0469 0.0460 0.0455 0.0452 0.0449 

[TRAIN] Epoch[1](9767/114412); Loss: 0.079340; Backpropagation: 0.2910 sec; Batch: 2.1123 sec
0.1496 0.1274 0.1013 0.0895 0.0817 0.0757 0.0729 0.0699 0.0673 0.0652 0.0639 0.0624 0.0617 0.0610 0.0603 0.0598 

[TRAIN] Epoch[1](9768/114412); Loss: 0.080181; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1402 0.1316 0.0998 0.0882 0.0802 0.0767 0.0734 0.0704 0.0689 0.0672 0.0660 0.0651 0.0645 0.0640 0.0636 0.0632 

[TRAIN] Epoch[1](9769/114412); Loss: 0.078203; Backpropagation: 0.2907 sec; Batch: 2.1170 sec
0.1473 0.1363 0.0933 0.0819 0.0756 0.0716 0.0696 0.0675 0.0662 0.0653 0.0642 0.0634 0.0629 0.0624 0.0620 0.0619 

[TRAIN] Epoch[1](9770/114412); Loss: 0.056462; Backpropagation: 0.2913 sec; Batch: 2.0768 sec
0.1102 0.1039 0.0805 0.0687 0.0573 0.0528 0.0496 0.0470 0.0447 0.0436 0.0424 0.0417 0.0409 0.0405 0.0400 0.0396 

[TRAIN] Epoch[1](9771/114412); Loss: 0.070688; Backpropagation: 0.2913 sec; Batch: 2.1152 sec
0.1319 0.1184 0.0953 0.0820 0.0725 0.0672 0.0632 0.0619 0.0592 0.0570 0.0564 0.0548 0.0539 0.0533 0.0522 0.0518 

[TRAIN] Epoch[1](9772/114412); Loss: 0.062535; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1220 0.1095 0.0877 0.0719 0.0627 0.0584 0.0551 0.0524 0.0508 0.0492 0.0479 0.0476 0.0470 0.0464 0.0462 0.0458 

[TRAIN] Epoch[1](9773/114412); Loss: 0.070364; Backpropagation: 0.2929 sec; Batch: 2.1187 sec
0.1197 0.1157 0.0861 0.0779 0.0716 0.0673 0.0648 0.0627 0.0608 0.0592 0.0583 0.0574 0.0569 0.0562 0.0558 0.0555 

[TRAIN] Epoch[1](9774/114412); Loss: 0.053157; Backpropagation: 0.2922 sec; Batch: 2.0770 sec
0.1101 0.0966 0.0718 0.0659 0.0560 0.0506 0.0462 0.0434 0.0416 0.0402 0.0392 0.0387 0.0381 0.0375 0.0375 0.0373 

[TRAIN] Epoch[1](9775/114412); Loss: 0.065605; Backpropagation: 0.2912 sec; Batch: 2.1201 sec
0.1567 0.1486 0.0911 0.0706 0.0618 0.0552 0.0522 0.0506 0.0482 0.0471 0.0460 0.0452 0.0447 0.0442 0.0438 0.0436 

[TRAIN] Epoch[1](9776/114412); Loss: 0.063154; Backpropagation: 0.2912 sec; Batch: 2.0972 sec
0.1582 0.1215 0.0834 0.0693 0.0611 0.0565 0.0528 0.0501 0.0480 0.0463 0.0454 0.0446 0.0438 0.0436 0.0431 0.0428 

[TRAIN] Epoch[1](9777/114412); Loss: 0.065179; Backpropagation: 0.2909 sec; Batch: 2.0769 sec
0.1499 0.1348 0.0770 0.0730 0.0643 0.0605 0.0558 0.0522 0.0507 0.0489 0.0475 0.0469 0.0462 0.0457 0.0449 0.0445 

[TRAIN] Epoch[1](9778/114412); Loss: 0.074416; Backpropagation: 0.2914 sec; Batch: 2.1151 sec
0.1364 0.1171 0.0928 0.0832 0.0783 0.0716 0.0678 0.0651 0.0632 0.0620 0.0606 0.0597 0.0591 0.0583 0.0578 0.0576 

[TRAIN] Epoch[1](9779/114412); Loss: 0.072013; Backpropagation: 0.2927 sec; Batch: 2.1424 sec
0.1201 0.1127 0.0904 0.0790 0.0720 0.0685 0.0661 0.0639 0.0628 0.0617 0.0607 0.0599 0.0593 0.0589 0.0585 0.0580 

[TRAIN] Epoch[1](9780/114412); Loss: 0.101941; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1766 0.1625 0.1307 0.1134 0.1050 0.0990 0.0940 0.0897 0.0883 0.0869 0.0837 0.0830 0.0818 0.0795 0.0789 0.0780 

[TRAIN] Epoch[1](9781/114412); Loss: 0.071652; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1478 0.1418 0.0923 0.0770 0.0700 0.0649 0.0613 0.0591 0.0571 0.0562 0.0549 0.0540 0.0533 0.0526 0.0523 0.0519 

[TRAIN] Epoch[1](9782/114412); Loss: 0.073994; Backpropagation: 0.2910 sec; Batch: 2.1197 sec
0.1687 0.1500 0.1063 0.0890 0.0782 0.0685 0.0626 0.0584 0.0552 0.0528 0.0515 0.0500 0.0491 0.0483 0.0479 0.0475 

[TRAIN] Epoch[1](9783/114412); Loss: 0.070887; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.1168 0.1082 0.0905 0.0796 0.0744 0.0692 0.0654 0.0638 0.0618 0.0602 0.0592 0.0583 0.0574 0.0569 0.0565 0.0560 

[TRAIN] Epoch[1](9784/114412); Loss: 0.069316; Backpropagation: 0.2906 sec; Batch: 2.1168 sec
0.1380 0.1231 0.0895 0.0763 0.0681 0.0640 0.0607 0.0583 0.0571 0.0557 0.0546 0.0540 0.0532 0.0526 0.0521 0.0518 

[TRAIN] Epoch[1](9785/114412); Loss: 0.064064; Backpropagation: 0.2912 sec; Batch: 2.0799 sec
0.1217 0.0980 0.0916 0.0695 0.0650 0.0599 0.0574 0.0557 0.0534 0.0525 0.0514 0.0508 0.0502 0.0496 0.0494 0.0490 

[TRAIN] Epoch[1](9786/114412); Loss: 0.073939; Backpropagation: 0.2916 sec; Batch: 2.1170 sec
0.1333 0.1254 0.0933 0.0820 0.0742 0.0697 0.0665 0.0638 0.0626 0.0612 0.0602 0.0593 0.0586 0.0580 0.0576 0.0572 

[TRAIN] Epoch[1](9787/114412); Loss: 0.084277; Backpropagation: 0.2926 sec; Batch: 2.0783 sec
0.1667 0.1451 0.1110 0.0991 0.0868 0.0789 0.0750 0.0706 0.0688 0.0667 0.0651 0.0644 0.0634 0.0627 0.0623 0.0619 

[TRAIN] Epoch[1](9788/114412); Loss: 0.071305; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1212 0.1076 0.0926 0.0794 0.0730 0.0689 0.0662 0.0636 0.0614 0.0603 0.0594 0.0585 0.0579 0.0573 0.0570 0.0566 

[TRAIN] Epoch[1](9789/114412); Loss: 0.090137; Backpropagation: 0.2915 sec; Batch: 2.0774 sec
0.1481 0.1394 0.1135 0.1033 0.0923 0.0863 0.0832 0.0802 0.0785 0.0771 0.0757 0.0745 0.0736 0.0728 0.0721 0.0714 

[TRAIN] Epoch[1](9790/114412); Loss: 0.063169; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1360 0.1243 0.0839 0.0702 0.0617 0.0576 0.0546 0.0517 0.0498 0.0481 0.0470 0.0462 0.0455 0.0450 0.0446 0.0444 

[TRAIN] Epoch[1](9791/114412); Loss: 0.084747; Backpropagation: 0.2908 sec; Batch: 2.0764 sec
0.1344 0.1235 0.1005 0.0933 0.0854 0.0838 0.0793 0.0767 0.0753 0.0740 0.0729 0.0723 0.0717 0.0712 0.0709 0.0706 

[TRAIN] Epoch[1](9792/114412); Loss: 0.085546; Backpropagation: 0.2919 sec; Batch: 2.0777 sec
0.1539 0.1419 0.1067 0.0906 0.0853 0.0801 0.0762 0.0741 0.0725 0.0713 0.0707 0.0700 0.0693 0.0690 0.0687 0.0684 

[TRAIN] Epoch[1](9793/114412); Loss: 0.055621; Backpropagation: 0.2911 sec; Batch: 2.1261 sec
0.1415 0.1174 0.0721 0.0593 0.0518 0.0492 0.0448 0.0429 0.0416 0.0402 0.0393 0.0387 0.0382 0.0379 0.0377 0.0374 

[TRAIN] Epoch[1](9794/114412); Loss: 0.064566; Backpropagation: 0.2906 sec; Batch: 2.0767 sec
0.1232 0.1075 0.0882 0.0746 0.0672 0.0602 0.0586 0.0551 0.0530 0.0514 0.0504 0.0496 0.0492 0.0488 0.0483 0.0479 

[TRAIN] Epoch[1](9795/114412); Loss: 0.090505; Backpropagation: 0.2916 sec; Batch: 2.1204 sec
0.1721 0.1612 0.1154 0.1041 0.0905 0.0857 0.0814 0.0780 0.0750 0.0729 0.0712 0.0700 0.0688 0.0681 0.0671 0.0665 

[TRAIN] Epoch[1](9796/114412); Loss: 0.076181; Backpropagation: 0.2898 sec; Batch: 2.0755 sec
0.1351 0.1224 0.1025 0.0851 0.0763 0.0718 0.0692 0.0665 0.0649 0.0630 0.0620 0.0612 0.0605 0.0598 0.0595 0.0591 

[TRAIN] Epoch[1](9797/114412); Loss: 0.060193; Backpropagation: 0.2932 sec; Batch: 2.0817 sec
0.1471 0.1242 0.0847 0.0687 0.0594 0.0525 0.0491 0.0463 0.0444 0.0433 0.0421 0.0413 0.0406 0.0402 0.0398 0.0395 

[TRAIN] Epoch[1](9798/114412); Loss: 0.071548; Backpropagation: 0.2931 sec; Batch: 2.1167 sec
0.1155 0.1014 0.0835 0.0770 0.0719 0.0694 0.0670 0.0649 0.0641 0.0631 0.0623 0.0617 0.0612 0.0609 0.0606 0.0603 

[TRAIN] Epoch[1](9799/114412); Loss: 0.067354; Backpropagation: 0.2928 sec; Batch: 2.1174 sec
0.1617 0.1448 0.0959 0.0800 0.0618 0.0558 0.0535 0.0516 0.0498 0.0483 0.0473 0.0465 0.0461 0.0454 0.0448 0.0445 

[TRAIN] Epoch[1](9800/114412); Loss: 0.090299; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1469 0.1407 0.1092 0.0963 0.0895 0.0855 0.0829 0.0806 0.0792 0.0783 0.0773 0.0766 0.0761 0.0756 0.0752 0.0748 

[TRAIN] Epoch[1](9801/114412); Loss: 0.064295; Backpropagation: 0.2915 sec; Batch: 2.0955 sec
0.1055 0.1022 0.0828 0.0708 0.0684 0.0638 0.0630 0.0585 0.0566 0.0539 0.0528 0.0514 0.0508 0.0500 0.0495 0.0489 

[TRAIN] Epoch[1](9802/114412); Loss: 0.073162; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.1433 0.1295 0.0947 0.0803 0.0731 0.0675 0.0645 0.0616 0.0604 0.0589 0.0577 0.0571 0.0562 0.0557 0.0553 0.0549 

[TRAIN] Epoch[1](9803/114412); Loss: 0.075299; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1520 0.1278 0.1053 0.0878 0.0775 0.0715 0.0660 0.0636 0.0612 0.0588 0.0574 0.0564 0.0559 0.0550 0.0544 0.0542 

[TRAIN] Epoch[1](9804/114412); Loss: 0.064306; Backpropagation: 0.2911 sec; Batch: 2.1148 sec
0.1302 0.1214 0.0899 0.0777 0.0662 0.0617 0.0569 0.0535 0.0511 0.0488 0.0476 0.0464 0.0453 0.0447 0.0440 0.0437 

[TRAIN] Epoch[1](9805/114412); Loss: 0.056242; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1196 0.0912 0.0702 0.0608 0.0561 0.0527 0.0501 0.0479 0.0467 0.0453 0.0444 0.0438 0.0432 0.0428 0.0425 0.0425 

[TRAIN] Epoch[1](9806/114412); Loss: 0.083636; Backpropagation: 0.2911 sec; Batch: 2.1130 sec
0.1652 0.1479 0.1220 0.1055 0.0926 0.0817 0.0726 0.0689 0.0655 0.0634 0.0618 0.0603 0.0591 0.0581 0.0573 0.0564 

[TRAIN] Epoch[1](9807/114412); Loss: 0.080285; Backpropagation: 0.2912 sec; Batch: 2.1103 sec
0.1761 0.1434 0.1124 0.0934 0.0835 0.0761 0.0682 0.0670 0.0632 0.0604 0.0597 0.0578 0.0567 0.0564 0.0554 0.0549 

[TRAIN] Epoch[1](9808/114412); Loss: 0.081897; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1410 0.1245 0.0987 0.0892 0.0816 0.0781 0.0751 0.0731 0.0714 0.0701 0.0693 0.0687 0.0681 0.0675 0.0671 0.0668 

[TRAIN] Epoch[1](9809/114412); Loss: 0.101804; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1552 0.1430 0.1234 0.1143 0.1066 0.1004 0.0960 0.0931 0.0910 0.0895 0.0882 0.0873 0.0862 0.0855 0.0848 0.0843 

[TRAIN] Epoch[1](9810/114412); Loss: 0.071654; Backpropagation: 0.2911 sec; Batch: 2.1141 sec
0.1379 0.1337 0.0940 0.0799 0.0673 0.0629 0.0615 0.0595 0.0586 0.0575 0.0568 0.0563 0.0557 0.0554 0.0548 0.0546 

[TRAIN] Epoch[1](9811/114412); Loss: 0.097804; Backpropagation: 0.2951 sec; Batch: 2.0809 sec
0.1633 0.1498 0.1266 0.1130 0.1016 0.0941 0.0904 0.0867 0.0841 0.0827 0.0811 0.0798 0.0789 0.0782 0.0775 0.0769 

[TRAIN] Epoch[1](9812/114412); Loss: 0.086031; Backpropagation: 0.2949 sec; Batch: 2.1186 sec
0.1522 0.1373 0.1110 0.0962 0.0871 0.0800 0.0772 0.0752 0.0734 0.0719 0.0708 0.0699 0.0691 0.0687 0.0685 0.0682 

[TRAIN] Epoch[1](9813/114412); Loss: 0.086410; Backpropagation: 0.2906 sec; Batch: 2.1213 sec
0.1525 0.1349 0.1090 0.0970 0.0897 0.0822 0.0783 0.0767 0.0746 0.0719 0.0711 0.0701 0.0694 0.0689 0.0682 0.0680 

[TRAIN] Epoch[1](9814/114412); Loss: 0.092456; Backpropagation: 0.2911 sec; Batch: 2.0761 sec
0.1834 0.1640 0.1159 0.1013 0.0917 0.0853 0.0816 0.0777 0.0752 0.0739 0.0731 0.0722 0.0716 0.0712 0.0708 0.0704 

[TRAIN] Epoch[1](9815/114412); Loss: 0.061641; Backpropagation: 0.2917 sec; Batch: 2.1204 sec
0.1286 0.1059 0.0802 0.0674 0.0617 0.0564 0.0542 0.0520 0.0505 0.0495 0.0483 0.0475 0.0468 0.0461 0.0459 0.0455 

[TRAIN] Epoch[1](9816/114412); Loss: 0.056821; Backpropagation: 0.2907 sec; Batch: 2.0777 sec
0.1117 0.1095 0.0677 0.0607 0.0544 0.0511 0.0488 0.0475 0.0464 0.0457 0.0448 0.0447 0.0445 0.0440 0.0438 0.0438 

[TRAIN] Epoch[1](9817/114412); Loss: 0.092610; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1627 0.1480 0.1107 0.1014 0.0916 0.0871 0.0843 0.0820 0.0798 0.0788 0.0775 0.0766 0.0761 0.0755 0.0750 0.0747 

[TRAIN] Epoch[1](9818/114412); Loss: 0.084740; Backpropagation: 0.2916 sec; Batch: 2.1167 sec
0.1764 0.1496 0.1225 0.0994 0.0882 0.0831 0.0765 0.0713 0.0684 0.0650 0.0634 0.0609 0.0596 0.0582 0.0570 0.0564 

[TRAIN] Epoch[1](9819/114412); Loss: 0.074559; Backpropagation: 0.2913 sec; Batch: 2.0771 sec
0.1239 0.1139 0.0958 0.0863 0.0769 0.0715 0.0686 0.0659 0.0647 0.0632 0.0620 0.0609 0.0605 0.0598 0.0596 0.0593 

[TRAIN] Epoch[1](9820/114412); Loss: 0.086784; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1673 0.1556 0.1106 0.0976 0.0869 0.0817 0.0772 0.0741 0.0713 0.0694 0.0681 0.0671 0.0663 0.0656 0.0651 0.0647 

[TRAIN] Epoch[1](9821/114412); Loss: 0.080032; Backpropagation: 0.2929 sec; Batch: 2.0795 sec
0.1480 0.1300 0.1034 0.0931 0.0872 0.0812 0.0772 0.0714 0.0687 0.0667 0.0636 0.0606 0.0599 0.0586 0.0556 0.0554 

[TRAIN] Epoch[1](9822/114412); Loss: 0.065608; Backpropagation: 0.2928 sec; Batch: 2.1251 sec
0.1327 0.1247 0.1006 0.0845 0.0733 0.0653 0.0584 0.0539 0.0497 0.0473 0.0458 0.0439 0.0432 0.0426 0.0419 0.0417 

[TRAIN] Epoch[1](9823/114412); Loss: 0.066000; Backpropagation: 0.2908 sec; Batch: 2.0786 sec
0.1288 0.1112 0.0884 0.0756 0.0669 0.0609 0.0586 0.0561 0.0542 0.0528 0.0519 0.0510 0.0505 0.0500 0.0497 0.0494 

[TRAIN] Epoch[1](9824/114412); Loss: 0.102982; Backpropagation: 0.2954 sec; Batch: 2.1239 sec
0.1607 0.1512 0.1255 0.1135 0.1035 0.0983 0.0957 0.0934 0.0917 0.0903 0.0891 0.0882 0.0874 0.0868 0.0863 0.0860 

[TRAIN] Epoch[1](9825/114412); Loss: 0.069467; Backpropagation: 0.2930 sec; Batch: 2.1196 sec
0.1223 0.1085 0.0862 0.0770 0.0717 0.0675 0.0641 0.0616 0.0594 0.0581 0.0574 0.0566 0.0560 0.0554 0.0549 0.0547 

[TRAIN] Epoch[1](9826/114412); Loss: 0.113556; Backpropagation: 0.2933 sec; Batch: 2.1154 sec
0.1648 0.1552 0.1377 0.1262 0.1172 0.1116 0.1072 0.1048 0.1027 0.1008 0.0998 0.0990 0.0980 0.0977 0.0974 0.0969 

[TRAIN] Epoch[1](9827/114412); Loss: 0.062772; Backpropagation: 0.2926 sec; Batch: 2.1175 sec
0.1468 0.1311 0.0739 0.0659 0.0611 0.0577 0.0541 0.0513 0.0494 0.0476 0.0462 0.0452 0.0443 0.0438 0.0432 0.0428 

[TRAIN] Epoch[1](9828/114412); Loss: 0.067416; Backpropagation: 0.2906 sec; Batch: 2.1310 sec
0.1593 0.1248 0.0928 0.0690 0.0652 0.0616 0.0567 0.0544 0.0517 0.0506 0.0499 0.0492 0.0488 0.0485 0.0482 0.0480 

[TRAIN] Epoch[1](9829/114412); Loss: 0.052533; Backpropagation: 0.2913 sec; Batch: 2.1197 sec
0.1278 0.1114 0.0710 0.0601 0.0492 0.0444 0.0423 0.0396 0.0383 0.0376 0.0371 0.0366 0.0365 0.0362 0.0362 0.0363 

[TRAIN] Epoch[1](9830/114412); Loss: 0.076803; Backpropagation: 0.2904 sec; Batch: 2.0768 sec
0.1521 0.1371 0.1019 0.0825 0.0771 0.0739 0.0673 0.0655 0.0623 0.0606 0.0599 0.0589 0.0581 0.0576 0.0571 0.0570 

[TRAIN] Epoch[1](9831/114412); Loss: 0.064382; Backpropagation: 0.2914 sec; Batch: 2.1211 sec
0.1789 0.1540 0.0939 0.0655 0.0617 0.0503 0.0484 0.0465 0.0443 0.0432 0.0418 0.0411 0.0406 0.0402 0.0402 0.0396 

[TRAIN] Epoch[1](9832/114412); Loss: 0.075579; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1331 0.1130 0.0924 0.0836 0.0757 0.0718 0.0691 0.0669 0.0658 0.0643 0.0634 0.0630 0.0624 0.0620 0.0616 0.0612 

[TRAIN] Epoch[1](9833/114412); Loss: 0.060815; Backpropagation: 0.2912 sec; Batch: 2.1133 sec
0.1336 0.1180 0.0847 0.0701 0.0607 0.0557 0.0528 0.0493 0.0472 0.0455 0.0444 0.0436 0.0426 0.0421 0.0416 0.0412 

[TRAIN] Epoch[1](9834/114412); Loss: 0.062192; Backpropagation: 0.2911 sec; Batch: 2.0786 sec
0.1180 0.1002 0.0790 0.0693 0.0630 0.0590 0.0558 0.0543 0.0525 0.0514 0.0501 0.0493 0.0488 0.0484 0.0481 0.0479 

[TRAIN] Epoch[1](9835/114412); Loss: 0.084338; Backpropagation: 0.2910 sec; Batch: 2.1089 sec
0.1524 0.1340 0.1056 0.0933 0.0846 0.0789 0.0761 0.0739 0.0722 0.0710 0.0695 0.0686 0.0680 0.0674 0.0671 0.0667 

[TRAIN] Epoch[1](9836/114412); Loss: 0.066227; Backpropagation: 0.2956 sec; Batch: 2.1212 sec
0.1414 0.1309 0.0968 0.0821 0.0675 0.0596 0.0557 0.0528 0.0511 0.0490 0.0472 0.0466 0.0456 0.0449 0.0445 0.0439 

[TRAIN] Epoch[1](9837/114412); Loss: 0.075764; Backpropagation: 0.2955 sec; Batch: 2.0820 sec
0.1619 0.1425 0.1031 0.0878 0.0759 0.0682 0.0641 0.0614 0.0596 0.0580 0.0567 0.0558 0.0551 0.0545 0.0539 0.0537 

[TRAIN] Epoch[1](9838/114412); Loss: 0.069821; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1539 0.1378 0.0981 0.0896 0.0769 0.0690 0.0625 0.0564 0.0517 0.0488 0.0471 0.0461 0.0454 0.0448 0.0446 0.0444 

[TRAIN] Epoch[1](9839/114412); Loss: 0.097544; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.1620 0.1517 0.1167 0.1059 0.0973 0.0929 0.0902 0.0874 0.0855 0.0842 0.0830 0.0821 0.0813 0.0806 0.0803 0.0798 

[TRAIN] Epoch[1](9840/114412); Loss: 0.068618; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1351 0.1276 0.0989 0.0797 0.0697 0.0627 0.0599 0.0566 0.0546 0.0531 0.0518 0.0510 0.0502 0.0497 0.0490 0.0486 

[TRAIN] Epoch[1](9841/114412); Loss: 0.065849; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1381 0.1239 0.0898 0.0719 0.0667 0.0599 0.0564 0.0539 0.0523 0.0508 0.0496 0.0490 0.0484 0.0480 0.0476 0.0472 

[TRAIN] Epoch[1](9842/114412); Loss: 0.106587; Backpropagation: 0.2915 sec; Batch: 2.1267 sec
0.1692 0.1532 0.1258 0.1143 0.1055 0.1013 0.0993 0.0974 0.0959 0.0944 0.0933 0.0924 0.0916 0.0911 0.0906 0.0901 

[TRAIN] Epoch[1](9843/114412); Loss: 0.072777; Backpropagation: 0.2914 sec; Batch: 2.1189 sec
0.1793 0.1543 0.1100 0.0832 0.0658 0.0621 0.0583 0.0561 0.0531 0.0510 0.0501 0.0495 0.0486 0.0482 0.0476 0.0471 

[TRAIN] Epoch[1](9844/114412); Loss: 0.064959; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1204 0.1085 0.0810 0.0700 0.0647 0.0615 0.0589 0.0566 0.0552 0.0539 0.0531 0.0521 0.0514 0.0511 0.0507 0.0505 

[TRAIN] Epoch[1](9845/114412); Loss: 0.071415; Backpropagation: 0.2911 sec; Batch: 2.1147 sec
0.1272 0.1196 0.0876 0.0806 0.0703 0.0668 0.0638 0.0620 0.0606 0.0594 0.0586 0.0581 0.0575 0.0572 0.0568 0.0566 

[TRAIN] Epoch[1](9846/114412); Loss: 0.068668; Backpropagation: 0.2927 sec; Batch: 2.1207 sec
0.1270 0.1199 0.0852 0.0766 0.0688 0.0646 0.0616 0.0591 0.0578 0.0567 0.0553 0.0544 0.0538 0.0531 0.0526 0.0523 

[TRAIN] Epoch[1](9847/114412); Loss: 0.061528; Backpropagation: 0.2928 sec; Batch: 2.1042 sec
0.1125 0.1060 0.0791 0.0711 0.0627 0.0580 0.0548 0.0528 0.0514 0.0501 0.0490 0.0484 0.0476 0.0473 0.0469 0.0467 

[TRAIN] Epoch[1](9848/114412); Loss: 0.076515; Backpropagation: 0.2931 sec; Batch: 2.1188 sec
0.1480 0.1296 0.1028 0.0907 0.0832 0.0732 0.0679 0.0649 0.0619 0.0605 0.0590 0.0578 0.0569 0.0565 0.0559 0.0556 

[TRAIN] Epoch[1](9849/114412); Loss: 0.073283; Backpropagation: 0.2930 sec; Batch: 2.1189 sec
0.1450 0.1315 0.0947 0.0857 0.0746 0.0680 0.0647 0.0616 0.0594 0.0579 0.0567 0.0557 0.0551 0.0544 0.0540 0.0536 

[TRAIN] Epoch[1](9850/114412); Loss: 0.074933; Backpropagation: 0.2908 sec; Batch: 2.1145 sec
0.1500 0.1381 0.0957 0.0812 0.0738 0.0692 0.0652 0.0636 0.0610 0.0599 0.0584 0.0576 0.0571 0.0565 0.0560 0.0557 

[TRAIN] Epoch[1](9851/114412); Loss: 0.071594; Backpropagation: 0.2910 sec; Batch: 2.1182 sec
0.1525 0.1412 0.0897 0.0736 0.0690 0.0649 0.0615 0.0589 0.0573 0.0559 0.0549 0.0542 0.0536 0.0530 0.0528 0.0523 

[TRAIN] Epoch[1](9852/114412); Loss: 0.125422; Backpropagation: 0.2911 sec; Batch: 2.0774 sec
0.1864 0.1774 0.1488 0.1302 0.1230 0.1189 0.1170 0.1160 0.1140 0.1124 0.1119 0.1110 0.1105 0.1102 0.1097 0.1095 

[TRAIN] Epoch[1](9853/114412); Loss: 0.048287; Backpropagation: 0.2908 sec; Batch: 2.1181 sec
0.1076 0.1003 0.0649 0.0576 0.0483 0.0437 0.0404 0.0383 0.0366 0.0353 0.0344 0.0339 0.0333 0.0329 0.0326 0.0325 

[TRAIN] Epoch[1](9854/114412); Loss: 0.075567; Backpropagation: 0.2908 sec; Batch: 2.1180 sec
0.1445 0.1217 0.0999 0.0836 0.0765 0.0711 0.0675 0.0653 0.0629 0.0618 0.0608 0.0596 0.0590 0.0585 0.0582 0.0581 

[TRAIN] Epoch[1](9855/114412); Loss: 0.058707; Backpropagation: 0.2909 sec; Batch: 2.1166 sec
0.1102 0.1021 0.0794 0.0662 0.0602 0.0551 0.0519 0.0497 0.0480 0.0471 0.0461 0.0455 0.0450 0.0445 0.0443 0.0441 

[TRAIN] Epoch[1](9856/114412); Loss: 0.060272; Backpropagation: 0.2915 sec; Batch: 2.1146 sec
0.1689 0.1515 0.0826 0.0656 0.0551 0.0484 0.0458 0.0436 0.0414 0.0395 0.0388 0.0375 0.0371 0.0364 0.0362 0.0360 

[TRAIN] Epoch[1](9857/114412); Loss: 0.081248; Backpropagation: 0.2903 sec; Batch: 2.0768 sec
0.1484 0.1344 0.1031 0.0897 0.0821 0.0761 0.0724 0.0698 0.0685 0.0673 0.0663 0.0655 0.0648 0.0643 0.0638 0.0636 

[TRAIN] Epoch[1](9858/114412); Loss: 0.082591; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1551 0.1408 0.1083 0.0918 0.0817 0.0769 0.0730 0.0701 0.0685 0.0669 0.0660 0.0654 0.0647 0.0642 0.0641 0.0639 

[TRAIN] Epoch[1](9859/114412); Loss: 0.067570; Backpropagation: 0.2910 sec; Batch: 2.0765 sec
0.1296 0.1202 0.0880 0.0788 0.0684 0.0638 0.0600 0.0570 0.0550 0.0536 0.0528 0.0518 0.0512 0.0507 0.0503 0.0499 

[TRAIN] Epoch[1](9860/114412); Loss: 0.087482; Backpropagation: 0.2914 sec; Batch: 2.0989 sec
0.1520 0.1438 0.1094 0.0940 0.0856 0.0816 0.0789 0.0769 0.0755 0.0742 0.0731 0.0721 0.0714 0.0710 0.0704 0.0700 

[TRAIN] Epoch[1](9861/114412); Loss: 0.087081; Backpropagation: 0.2933 sec; Batch: 2.1188 sec
0.1371 0.1309 0.1063 0.0972 0.0896 0.0850 0.0815 0.0787 0.0773 0.0757 0.0743 0.0731 0.0725 0.0716 0.0713 0.0710 

[TRAIN] Epoch[1](9862/114412); Loss: 0.101897; Backpropagation: 0.2928 sec; Batch: 2.1168 sec
0.1713 0.1489 0.1259 0.1134 0.1077 0.1002 0.0974 0.0939 0.0901 0.0882 0.0861 0.0838 0.0830 0.0813 0.0802 0.0791 

[TRAIN] Epoch[1](9863/114412); Loss: 0.076734; Backpropagation: 0.2951 sec; Batch: 2.1232 sec
0.1246 0.1146 0.0978 0.0889 0.0792 0.0743 0.0708 0.0686 0.0667 0.0653 0.0643 0.0635 0.0629 0.0625 0.0621 0.0618 

[TRAIN] Epoch[1](9864/114412); Loss: 0.085767; Backpropagation: 0.2924 sec; Batch: 2.0867 sec
0.1487 0.1345 0.1041 0.0972 0.0886 0.0826 0.0784 0.0758 0.0743 0.0724 0.0714 0.0702 0.0695 0.0688 0.0682 0.0677 

[TRAIN] Epoch[1](9865/114412); Loss: 0.063996; Backpropagation: 0.2952 sec; Batch: 2.1247 sec
0.1236 0.1086 0.0898 0.0751 0.0655 0.0600 0.0570 0.0538 0.0522 0.0505 0.0496 0.0488 0.0480 0.0476 0.0470 0.0467 

[TRAIN] Epoch[1](9866/114412); Loss: 0.071823; Backpropagation: 0.2930 sec; Batch: 2.1186 sec
0.1324 0.1169 0.0850 0.0801 0.0731 0.0683 0.0651 0.0629 0.0615 0.0601 0.0588 0.0580 0.0574 0.0569 0.0565 0.0562 

[TRAIN] Epoch[1](9867/114412); Loss: 0.092098; Backpropagation: 0.2949 sec; Batch: 2.1233 sec
0.1579 0.1459 0.1072 0.0964 0.0903 0.0864 0.0841 0.0814 0.0803 0.0792 0.0784 0.0779 0.0774 0.0770 0.0769 0.0768 

[TRAIN] Epoch[1](9868/114412); Loss: 0.078871; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1388 0.1297 0.0999 0.0865 0.0792 0.0757 0.0717 0.0693 0.0672 0.0659 0.0646 0.0638 0.0631 0.0625 0.0621 0.0618 

[TRAIN] Epoch[1](9869/114412); Loss: 0.077683; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1475 0.1261 0.0952 0.0893 0.0823 0.0744 0.0703 0.0676 0.0653 0.0636 0.0625 0.0612 0.0605 0.0596 0.0591 0.0586 

[TRAIN] Epoch[1](9870/114412); Loss: 0.074067; Backpropagation: 0.2909 sec; Batch: 2.1133 sec
0.1377 0.1282 0.0943 0.0851 0.0741 0.0702 0.0665 0.0636 0.0616 0.0600 0.0589 0.0581 0.0576 0.0569 0.0564 0.0559 

[TRAIN] Epoch[1](9871/114412); Loss: 0.063405; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1444 0.1254 0.0855 0.0705 0.0622 0.0579 0.0549 0.0512 0.0487 0.0474 0.0461 0.0452 0.0444 0.0440 0.0436 0.0432 

[TRAIN] Epoch[1](9872/114412); Loss: 0.069692; Backpropagation: 0.2911 sec; Batch: 2.1153 sec
0.1175 0.1095 0.0883 0.0775 0.0716 0.0678 0.0645 0.0621 0.0603 0.0584 0.0576 0.0568 0.0563 0.0559 0.0555 0.0553 

[TRAIN] Epoch[1](9873/114412); Loss: 0.081659; Backpropagation: 0.2940 sec; Batch: 2.1004 sec
0.1621 0.1352 0.1080 0.0957 0.0854 0.0771 0.0729 0.0691 0.0665 0.0647 0.0638 0.0625 0.0617 0.0612 0.0604 0.0600 

[TRAIN] Epoch[1](9874/114412); Loss: 0.071353; Backpropagation: 0.2926 sec; Batch: 2.1195 sec
0.1487 0.1311 0.0935 0.0812 0.0750 0.0675 0.0632 0.0599 0.0573 0.0551 0.0531 0.0523 0.0518 0.0510 0.0505 0.0505 

[TRAIN] Epoch[1](9875/114412); Loss: 0.058843; Backpropagation: 0.2951 sec; Batch: 2.1195 sec
0.1109 0.0987 0.0763 0.0675 0.0607 0.0558 0.0530 0.0507 0.0491 0.0479 0.0466 0.0460 0.0452 0.0447 0.0445 0.0439 

[TRAIN] Epoch[1](9876/114412); Loss: 0.072420; Backpropagation: 0.2927 sec; Batch: 2.1101 sec
0.1399 0.1223 0.0946 0.0781 0.0764 0.0667 0.0627 0.0616 0.0593 0.0585 0.0574 0.0567 0.0564 0.0563 0.0558 0.0558 

[TRAIN] Epoch[1](9877/114412); Loss: 0.097439; Backpropagation: 0.2926 sec; Batch: 2.1177 sec
0.1837 0.1734 0.1235 0.1028 0.0959 0.0892 0.0848 0.0824 0.0811 0.0797 0.0788 0.0779 0.0771 0.0766 0.0763 0.0759 

[TRAIN] Epoch[1](9878/114412); Loss: 0.052718; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1181 0.1083 0.0684 0.0562 0.0514 0.0471 0.0438 0.0415 0.0404 0.0402 0.0391 0.0383 0.0381 0.0377 0.0375 0.0373 

[TRAIN] Epoch[1](9879/114412); Loss: 0.088551; Backpropagation: 0.2950 sec; Batch: 2.1210 sec
0.1483 0.1389 0.1085 0.0976 0.0891 0.0840 0.0815 0.0789 0.0770 0.0754 0.0746 0.0737 0.0730 0.0724 0.0720 0.0717 

[TRAIN] Epoch[1](9880/114412); Loss: 0.069347; Backpropagation: 0.2955 sec; Batch: 2.1218 sec
0.1235 0.1155 0.0823 0.0743 0.0688 0.0653 0.0630 0.0607 0.0592 0.0582 0.0575 0.0570 0.0564 0.0561 0.0559 0.0557 

[TRAIN] Epoch[1](9881/114412); Loss: 0.073907; Backpropagation: 0.2931 sec; Batch: 2.1191 sec
0.1854 0.1621 0.1004 0.0758 0.0673 0.0617 0.0587 0.0567 0.0543 0.0536 0.0526 0.0517 0.0513 0.0507 0.0502 0.0500 

[TRAIN] Epoch[1](9882/114412); Loss: 0.068908; Backpropagation: 0.2929 sec; Batch: 2.1167 sec
0.1300 0.1189 0.0845 0.0748 0.0696 0.0646 0.0615 0.0595 0.0576 0.0562 0.0554 0.0547 0.0542 0.0540 0.0536 0.0534 

[TRAIN] Epoch[1](9883/114412); Loss: 0.081370; Backpropagation: 0.2931 sec; Batch: 2.1301 sec
0.1513 0.1445 0.1118 0.0969 0.0870 0.0783 0.0732 0.0686 0.0655 0.0637 0.0622 0.0613 0.0605 0.0596 0.0592 0.0585 

[TRAIN] Epoch[1](9884/114412); Loss: 0.069396; Backpropagation: 0.2905 sec; Batch: 2.1187 sec
0.1339 0.1212 0.0852 0.0785 0.0726 0.0670 0.0631 0.0592 0.0572 0.0560 0.0546 0.0536 0.0527 0.0523 0.0517 0.0516 

[TRAIN] Epoch[1](9885/114412); Loss: 0.103294; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1679 0.1563 0.1311 0.1182 0.1071 0.1037 0.0971 0.0920 0.0901 0.0878 0.0863 0.0853 0.0837 0.0828 0.0821 0.0812 

[TRAIN] Epoch[1](9886/114412); Loss: 0.083734; Backpropagation: 0.2906 sec; Batch: 2.1182 sec
0.1437 0.1326 0.1064 0.0950 0.0851 0.0804 0.0764 0.0739 0.0715 0.0703 0.0691 0.0682 0.0676 0.0670 0.0664 0.0661 

[TRAIN] Epoch[1](9887/114412); Loss: 0.102124; Backpropagation: 0.2912 sec; Batch: 2.0772 sec
0.1620 0.1468 0.1262 0.1196 0.1084 0.1010 0.0968 0.0930 0.0897 0.0880 0.0861 0.0853 0.0841 0.0830 0.0825 0.0816 

[TRAIN] Epoch[1](9888/114412); Loss: 0.079015; Backpropagation: 0.2907 sec; Batch: 2.0771 sec
0.1319 0.1189 0.0955 0.0855 0.0798 0.0768 0.0737 0.0713 0.0693 0.0680 0.0670 0.0664 0.0657 0.0653 0.0648 0.0643 

[TRAIN] Epoch[1](9889/114412); Loss: 0.065350; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.1292 0.1228 0.0823 0.0710 0.0634 0.0597 0.0569 0.0547 0.0532 0.0519 0.0513 0.0507 0.0502 0.0497 0.0494 0.0492 

[TRAIN] Epoch[1](9890/114412); Loss: 0.074894; Backpropagation: 0.2955 sec; Batch: 2.1216 sec
0.1607 0.1535 0.1053 0.0865 0.0704 0.0652 0.0626 0.0600 0.0578 0.0565 0.0555 0.0542 0.0535 0.0528 0.0523 0.0516 

[TRAIN] Epoch[1](9891/114412); Loss: 0.053147; Backpropagation: 0.2951 sec; Batch: 2.1248 sec
0.1280 0.1186 0.0722 0.0598 0.0505 0.0458 0.0430 0.0410 0.0392 0.0380 0.0371 0.0364 0.0358 0.0354 0.0349 0.0348 

[TRAIN] Epoch[1](9892/114412); Loss: 0.083374; Backpropagation: 0.2954 sec; Batch: 2.1016 sec
0.2011 0.1816 0.1226 0.0948 0.0799 0.0753 0.0708 0.0655 0.0630 0.0599 0.0574 0.0555 0.0531 0.0521 0.0512 0.0502 

[TRAIN] Epoch[1](9893/114412); Loss: 0.071270; Backpropagation: 0.2933 sec; Batch: 2.1196 sec
0.1410 0.1208 0.0885 0.0754 0.0710 0.0669 0.0640 0.0614 0.0598 0.0583 0.0572 0.0563 0.0557 0.0551 0.0546 0.0544 

[TRAIN] Epoch[1](9894/114412); Loss: 0.083316; Backpropagation: 0.2926 sec; Batch: 2.1184 sec
0.1364 0.1241 0.0952 0.0882 0.0827 0.0797 0.0778 0.0757 0.0743 0.0732 0.0722 0.0715 0.0711 0.0707 0.0702 0.0699 

[TRAIN] Epoch[1](9895/114412); Loss: 0.054989; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.0992 0.0964 0.0737 0.0660 0.0585 0.0514 0.0493 0.0473 0.0454 0.0442 0.0431 0.0421 0.0415 0.0410 0.0405 0.0403 

[TRAIN] Epoch[1](9896/114412); Loss: 0.074619; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1296 0.1213 0.0920 0.0845 0.0778 0.0711 0.0691 0.0657 0.0636 0.0622 0.0610 0.0602 0.0597 0.0590 0.0587 0.0584 

[TRAIN] Epoch[1](9897/114412); Loss: 0.078654; Backpropagation: 0.2927 sec; Batch: 2.1192 sec
0.1464 0.1305 0.0978 0.0829 0.0777 0.0734 0.0698 0.0679 0.0664 0.0653 0.0645 0.0638 0.0634 0.0632 0.0628 0.0626 

[TRAIN] Epoch[1](9898/114412); Loss: 0.064368; Backpropagation: 0.2912 sec; Batch: 2.0961 sec
0.1408 0.1361 0.0918 0.0813 0.0671 0.0595 0.0535 0.0500 0.0476 0.0462 0.0449 0.0438 0.0426 0.0420 0.0415 0.0411 

[TRAIN] Epoch[1](9899/114412); Loss: 0.071584; Backpropagation: 0.2927 sec; Batch: 2.1193 sec
0.1264 0.1130 0.0902 0.0826 0.0756 0.0694 0.0663 0.0633 0.0612 0.0596 0.0584 0.0574 0.0565 0.0558 0.0551 0.0545 

[TRAIN] Epoch[1](9900/114412); Loss: 0.079622; Backpropagation: 0.2917 sec; Batch: 2.1165 sec
0.1249 0.1198 0.0996 0.0894 0.0818 0.0775 0.0746 0.0725 0.0704 0.0690 0.0678 0.0667 0.0660 0.0653 0.0646 0.0642 

[TRAIN] Epoch[1](9901/114412); Loss: 0.055982; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1067 0.0950 0.0763 0.0677 0.0611 0.0546 0.0501 0.0472 0.0453 0.0438 0.0427 0.0419 0.0414 0.0410 0.0405 0.0403 

[TRAIN] Epoch[1](9902/114412); Loss: 0.077049; Backpropagation: 0.2929 sec; Batch: 2.1160 sec
0.1426 0.1361 0.0961 0.0843 0.0742 0.0700 0.0681 0.0659 0.0644 0.0636 0.0623 0.0618 0.0613 0.0609 0.0607 0.0605 

[TRAIN] Epoch[1](9903/114412); Loss: 0.067223; Backpropagation: 0.2934 sec; Batch: 2.1179 sec
0.1361 0.1251 0.0855 0.0755 0.0665 0.0608 0.0584 0.0561 0.0543 0.0528 0.0520 0.0513 0.0508 0.0504 0.0500 0.0497 

[TRAIN] Epoch[1](9904/114412); Loss: 0.095884; Backpropagation: 0.2929 sec; Batch: 2.1212 sec
0.2221 0.1998 0.1437 0.1160 0.1001 0.0863 0.0779 0.0736 0.0712 0.0684 0.0660 0.0642 0.0627 0.0615 0.0605 0.0600 

[TRAIN] Epoch[1](9905/114412); Loss: 0.066870; Backpropagation: 0.2915 sec; Batch: 2.1148 sec
0.1429 0.1259 0.0818 0.0693 0.0630 0.0594 0.0571 0.0553 0.0540 0.0532 0.0523 0.0519 0.0513 0.0510 0.0508 0.0507 

[TRAIN] Epoch[1](9906/114412); Loss: 0.073486; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1540 0.1377 0.0979 0.0785 0.0745 0.0669 0.0636 0.0612 0.0587 0.0578 0.0566 0.0549 0.0544 0.0536 0.0530 0.0523 

[TRAIN] Epoch[1](9907/114412); Loss: 0.053948; Backpropagation: 0.2910 sec; Batch: 2.0773 sec
0.0960 0.0777 0.0721 0.0613 0.0544 0.0508 0.0488 0.0481 0.0462 0.0452 0.0446 0.0441 0.0438 0.0435 0.0434 0.0433 

[TRAIN] Epoch[1](9908/114412); Loss: 0.056686; Backpropagation: 0.2915 sec; Batch: 2.1220 sec
0.1153 0.1086 0.0833 0.0710 0.0581 0.0498 0.0471 0.0449 0.0433 0.0423 0.0415 0.0411 0.0405 0.0403 0.0400 0.0398 

[TRAIN] Epoch[1](9909/114412); Loss: 0.066863; Backpropagation: 0.2927 sec; Batch: 2.1190 sec
0.1168 0.1131 0.0789 0.0727 0.0647 0.0637 0.0615 0.0597 0.0576 0.0566 0.0555 0.0545 0.0541 0.0536 0.0535 0.0532 

[TRAIN] Epoch[1](9910/114412); Loss: 0.053684; Backpropagation: 0.2916 sec; Batch: 2.1178 sec
0.1161 0.1046 0.0712 0.0600 0.0514 0.0482 0.0458 0.0435 0.0423 0.0412 0.0404 0.0398 0.0391 0.0387 0.0385 0.0383 

[TRAIN] Epoch[1](9911/114412); Loss: 0.086028; Backpropagation: 0.2910 sec; Batch: 2.0773 sec
0.1561 0.1402 0.1230 0.1049 0.0911 0.0842 0.0773 0.0732 0.0701 0.0685 0.0671 0.0661 0.0649 0.0641 0.0632 0.0626 

[TRAIN] Epoch[1](9912/114412); Loss: 0.088427; Backpropagation: 0.2909 sec; Batch: 2.0795 sec
0.1273 0.1179 0.1074 0.0986 0.0915 0.0873 0.0839 0.0820 0.0804 0.0791 0.0783 0.0773 0.0767 0.0760 0.0757 0.0754 

[TRAIN] Epoch[1](9913/114412); Loss: 0.063966; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.1367 0.1240 0.0875 0.0738 0.0619 0.0577 0.0547 0.0516 0.0500 0.0486 0.0476 0.0468 0.0463 0.0458 0.0454 0.0451 

[TRAIN] Epoch[1](9914/114412); Loss: 0.071093; Backpropagation: 0.2929 sec; Batch: 2.1198 sec
0.1399 0.1151 0.0941 0.0827 0.0749 0.0705 0.0643 0.0609 0.0593 0.0570 0.0554 0.0543 0.0533 0.0526 0.0519 0.0514 

[TRAIN] Epoch[1](9915/114412); Loss: 0.056683; Backpropagation: 0.2907 sec; Batch: 2.1115 sec
0.1234 0.1010 0.0796 0.0655 0.0589 0.0523 0.0490 0.0466 0.0446 0.0432 0.0420 0.0411 0.0404 0.0401 0.0398 0.0394 

[TRAIN] Epoch[1](9916/114412); Loss: 0.063730; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1367 0.1302 0.0802 0.0713 0.0612 0.0554 0.0528 0.0510 0.0499 0.0486 0.0480 0.0475 0.0471 0.0467 0.0465 0.0465 

[TRAIN] Epoch[1](9917/114412); Loss: 0.083095; Backpropagation: 0.2916 sec; Batch: 2.1136 sec
0.1654 0.1393 0.1076 0.0927 0.0833 0.0766 0.0732 0.0710 0.0689 0.0673 0.0662 0.0650 0.0643 0.0635 0.0629 0.0624 

[TRAIN] Epoch[1](9918/114412); Loss: 0.072638; Backpropagation: 0.2914 sec; Batch: 2.1178 sec
0.1289 0.1215 0.0838 0.0762 0.0711 0.0685 0.0667 0.0643 0.0628 0.0615 0.0606 0.0601 0.0596 0.0592 0.0588 0.0586 

[TRAIN] Epoch[1](9919/114412); Loss: 0.062190; Backpropagation: 0.2913 sec; Batch: 2.0774 sec
0.1209 0.0982 0.0760 0.0681 0.0630 0.0586 0.0555 0.0536 0.0523 0.0512 0.0504 0.0499 0.0496 0.0494 0.0492 0.0490 

[TRAIN] Epoch[1](9920/114412); Loss: 0.085908; Backpropagation: 0.2911 sec; Batch: 2.1137 sec
0.1589 0.1472 0.1122 0.0953 0.0854 0.0797 0.0760 0.0736 0.0715 0.0703 0.0692 0.0683 0.0676 0.0669 0.0665 0.0659 

[TRAIN] Epoch[1](9921/114412); Loss: 0.074360; Backpropagation: 0.2931 sec; Batch: 2.0798 sec
0.1327 0.1221 0.0964 0.0853 0.0746 0.0703 0.0674 0.0648 0.0629 0.0612 0.0603 0.0595 0.0588 0.0582 0.0578 0.0575 

[TRAIN] Epoch[1](9922/114412); Loss: 0.071887; Backpropagation: 0.2911 sec; Batch: 2.0927 sec
0.1149 0.1022 0.0896 0.0815 0.0760 0.0718 0.0685 0.0660 0.0638 0.0625 0.0613 0.0600 0.0591 0.0585 0.0575 0.0569 

[TRAIN] Epoch[1](9923/114412); Loss: 0.058559; Backpropagation: 0.2910 sec; Batch: 2.0763 sec
0.1337 0.1253 0.0803 0.0617 0.0528 0.0496 0.0472 0.0457 0.0445 0.0435 0.0428 0.0425 0.0421 0.0420 0.0417 0.0415 

[TRAIN] Epoch[1](9924/114412); Loss: 0.051750; Backpropagation: 0.2904 sec; Batch: 2.0759 sec
0.1147 0.1067 0.0715 0.0590 0.0503 0.0465 0.0431 0.0411 0.0395 0.0384 0.0375 0.0368 0.0362 0.0359 0.0355 0.0353 

[TRAIN] Epoch[1](9925/114412); Loss: 0.075073; Backpropagation: 0.2904 sec; Batch: 2.1182 sec
0.1707 0.1483 0.0984 0.0824 0.0711 0.0654 0.0632 0.0605 0.0585 0.0570 0.0559 0.0551 0.0545 0.0539 0.0534 0.0528 

[TRAIN] Epoch[1](9926/114412); Loss: 0.077019; Backpropagation: 0.2911 sec; Batch: 2.1004 sec
0.1678 0.1561 0.0996 0.0800 0.0715 0.0664 0.0647 0.0626 0.0609 0.0597 0.0587 0.0579 0.0574 0.0568 0.0563 0.0560 

[TRAIN] Epoch[1](9927/114412); Loss: 0.061410; Backpropagation: 0.2910 sec; Batch: 2.1314 sec
0.1320 0.1113 0.0858 0.0727 0.0627 0.0562 0.0534 0.0504 0.0482 0.0464 0.0454 0.0447 0.0439 0.0434 0.0430 0.0429 

[TRAIN] Epoch[1](9928/114412); Loss: 0.059080; Backpropagation: 0.2911 sec; Batch: 2.1136 sec
0.1312 0.1202 0.0842 0.0665 0.0568 0.0526 0.0501 0.0474 0.0451 0.0441 0.0428 0.0421 0.0414 0.0407 0.0402 0.0398 

[TRAIN] Epoch[1](9929/114412); Loss: 0.055653; Backpropagation: 0.2931 sec; Batch: 2.1193 sec
0.1181 0.1060 0.0735 0.0599 0.0529 0.0499 0.0474 0.0458 0.0445 0.0433 0.0426 0.0420 0.0417 0.0413 0.0409 0.0407 

[TRAIN] Epoch[1](9930/114412); Loss: 0.050634; Backpropagation: 0.2928 sec; Batch: 2.1222 sec
0.0926 0.0825 0.0664 0.0582 0.0520 0.0482 0.0459 0.0435 0.0423 0.0413 0.0407 0.0400 0.0396 0.0393 0.0389 0.0388 

[TRAIN] Epoch[1](9931/114412); Loss: 0.067312; Backpropagation: 0.2906 sec; Batch: 2.0771 sec
0.1373 0.1317 0.0934 0.0801 0.0712 0.0612 0.0579 0.0554 0.0528 0.0511 0.0497 0.0487 0.0479 0.0468 0.0460 0.0456 

[TRAIN] Epoch[1](9932/114412); Loss: 0.074104; Backpropagation: 0.2907 sec; Batch: 2.1346 sec
0.1299 0.1182 0.0932 0.0840 0.0763 0.0726 0.0695 0.0662 0.0645 0.0621 0.0604 0.0595 0.0583 0.0576 0.0570 0.0562 

[TRAIN] Epoch[1](9933/114412); Loss: 0.076894; Backpropagation: 0.2929 sec; Batch: 2.1201 sec
0.1671 0.1490 0.1049 0.0847 0.0760 0.0690 0.0659 0.0634 0.0615 0.0596 0.0580 0.0563 0.0551 0.0540 0.0532 0.0525 

[TRAIN] Epoch[1](9934/114412); Loss: 0.084125; Backpropagation: 0.2951 sec; Batch: 2.1210 sec
0.1858 0.1712 0.1179 0.1010 0.0847 0.0740 0.0695 0.0658 0.0638 0.0618 0.0604 0.0594 0.0586 0.0579 0.0573 0.0570 

[TRAIN] Epoch[1](9935/114412); Loss: 0.056381; Backpropagation: 0.2953 sec; Batch: 2.1179 sec
0.0977 0.0899 0.0835 0.0671 0.0604 0.0559 0.0521 0.0487 0.0466 0.0452 0.0441 0.0434 0.0426 0.0422 0.0415 0.0413 

[TRAIN] Epoch[1](9936/114412); Loss: 0.096689; Backpropagation: 0.2952 sec; Batch: 2.0805 sec
0.1541 0.1469 0.1182 0.1043 0.0960 0.0915 0.0891 0.0865 0.0852 0.0843 0.0830 0.0825 0.0819 0.0815 0.0812 0.0810 

[TRAIN] Epoch[1](9937/114412); Loss: 0.069544; Backpropagation: 0.2930 sec; Batch: 2.1145 sec
0.1235 0.1099 0.0852 0.0794 0.0731 0.0678 0.0636 0.0611 0.0593 0.0578 0.0568 0.0561 0.0553 0.0549 0.0547 0.0544 

[TRAIN] Epoch[1](9938/114412); Loss: 0.077414; Backpropagation: 0.2909 sec; Batch: 2.1248 sec
0.1823 0.1535 0.1178 0.0971 0.0823 0.0659 0.0623 0.0593 0.0568 0.0547 0.0533 0.0523 0.0513 0.0505 0.0499 0.0495 

[TRAIN] Epoch[1](9939/114412); Loss: 0.077273; Backpropagation: 0.2916 sec; Batch: 2.1063 sec
0.1692 0.1473 0.1043 0.0848 0.0735 0.0701 0.0667 0.0632 0.0608 0.0591 0.0579 0.0572 0.0563 0.0559 0.0553 0.0548 

[TRAIN] Epoch[1](9940/114412); Loss: 0.059715; Backpropagation: 0.2910 sec; Batch: 2.0786 sec
0.1437 0.1287 0.0821 0.0693 0.0537 0.0501 0.0497 0.0466 0.0444 0.0432 0.0421 0.0414 0.0406 0.0403 0.0398 0.0395 

[TRAIN] Epoch[1](9941/114412); Loss: 0.114295; Backpropagation: 0.2942 sec; Batch: 2.1279 sec
0.1656 0.1515 0.1384 0.1274 0.1205 0.1149 0.1121 0.1080 0.1058 0.1033 0.1006 0.0989 0.0974 0.0959 0.0947 0.0938 

[TRAIN] Epoch[1](9942/114412); Loss: 0.102680; Backpropagation: 0.2929 sec; Batch: 2.1201 sec
0.1744 0.1605 0.1313 0.1150 0.1044 0.0982 0.0937 0.0908 0.0882 0.0866 0.0855 0.0845 0.0834 0.0827 0.0821 0.0813 

[TRAIN] Epoch[1](9943/114412); Loss: 0.066313; Backpropagation: 0.2953 sec; Batch: 2.0806 sec
0.1273 0.1156 0.0936 0.0838 0.0739 0.0647 0.0589 0.0557 0.0527 0.0511 0.0493 0.0484 0.0474 0.0467 0.0461 0.0458 

[TRAIN] Epoch[1](9944/114412); Loss: 0.067401; Backpropagation: 0.2925 sec; Batch: 2.1208 sec
0.1437 0.1379 0.1011 0.0837 0.0717 0.0633 0.0579 0.0529 0.0498 0.0477 0.0465 0.0457 0.0449 0.0444 0.0438 0.0435 

[TRAIN] Epoch[1](9945/114412); Loss: 0.065936; Backpropagation: 0.2904 sec; Batch: 2.1127 sec
0.1393 0.1259 0.0902 0.0765 0.0647 0.0600 0.0563 0.0537 0.0522 0.0505 0.0496 0.0485 0.0476 0.0471 0.0468 0.0463 

[TRAIN] Epoch[1](9946/114412); Loss: 0.074245; Backpropagation: 0.2910 sec; Batch: 2.0764 sec
0.1694 0.1502 0.0990 0.0819 0.0683 0.0657 0.0623 0.0595 0.0572 0.0560 0.0548 0.0540 0.0532 0.0526 0.0520 0.0518 

[TRAIN] Epoch[1](9947/114412); Loss: 0.037262; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.0768 0.0671 0.0500 0.0441 0.0367 0.0338 0.0326 0.0313 0.0303 0.0290 0.0282 0.0276 0.0273 0.0272 0.0271 0.0270 

[TRAIN] Epoch[1](9948/114412); Loss: 0.082264; Backpropagation: 0.2918 sec; Batch: 2.1263 sec
0.1541 0.1459 0.1106 0.0966 0.0842 0.0767 0.0729 0.0684 0.0673 0.0655 0.0639 0.0632 0.0626 0.0620 0.0614 0.0609 

[TRAIN] Epoch[1](9949/114412); Loss: 0.070821; Backpropagation: 0.2912 sec; Batch: 2.1131 sec
0.1341 0.1244 0.0928 0.0837 0.0745 0.0664 0.0625 0.0594 0.0575 0.0563 0.0553 0.0546 0.0536 0.0531 0.0526 0.0522 

[TRAIN] Epoch[1](9950/114412); Loss: 0.051789; Backpropagation: 0.2913 sec; Batch: 2.1147 sec
0.0965 0.0926 0.0696 0.0594 0.0537 0.0495 0.0467 0.0440 0.0424 0.0410 0.0401 0.0395 0.0390 0.0386 0.0382 0.0379 

[TRAIN] Epoch[1](9951/114412); Loss: 0.096115; Backpropagation: 0.2915 sec; Batch: 2.1180 sec
0.1734 0.1598 0.1193 0.1043 0.0941 0.0892 0.0861 0.0836 0.0821 0.0801 0.0792 0.0783 0.0778 0.0773 0.0768 0.0765 

[TRAIN] Epoch[1](9952/114412); Loss: 0.065563; Backpropagation: 0.2914 sec; Batch: 2.1141 sec
0.1461 0.1411 0.0862 0.0677 0.0615 0.0559 0.0545 0.0519 0.0502 0.0493 0.0484 0.0479 0.0476 0.0471 0.0469 0.0467 

[TRAIN] Epoch[1](9953/114412); Loss: 0.071025; Backpropagation: 0.2931 sec; Batch: 2.1186 sec
0.1613 0.1505 0.0928 0.0806 0.0646 0.0596 0.0580 0.0555 0.0541 0.0532 0.0524 0.0519 0.0511 0.0506 0.0502 0.0501 

[TRAIN] Epoch[1](9954/114412); Loss: 0.084638; Backpropagation: 0.2931 sec; Batch: 2.1220 sec
0.1479 0.1382 0.1063 0.0970 0.0863 0.0819 0.0777 0.0744 0.0723 0.0705 0.0689 0.0679 0.0671 0.0665 0.0659 0.0654 

[TRAIN] Epoch[1](9955/114412); Loss: 0.066809; Backpropagation: 0.2906 sec; Batch: 2.1303 sec
0.1105 0.0957 0.0793 0.0730 0.0673 0.0638 0.0617 0.0598 0.0589 0.0584 0.0576 0.0572 0.0568 0.0564 0.0564 0.0562 

[TRAIN] Epoch[1](9956/114412); Loss: 0.090200; Backpropagation: 0.2930 sec; Batch: 2.1201 sec
0.1520 0.1396 0.1111 0.1016 0.0919 0.0862 0.0817 0.0797 0.0778 0.0765 0.0754 0.0747 0.0742 0.0739 0.0735 0.0734 

[TRAIN] Epoch[1](9957/114412); Loss: 0.073389; Backpropagation: 0.2946 sec; Batch: 2.1205 sec
0.1399 0.1252 0.0900 0.0802 0.0731 0.0682 0.0649 0.0629 0.0613 0.0602 0.0594 0.0587 0.0582 0.0577 0.0572 0.0570 

[TRAIN] Epoch[1](9958/114412); Loss: 0.062596; Backpropagation: 0.2949 sec; Batch: 2.1197 sec
0.1367 0.1188 0.0881 0.0790 0.0659 0.0591 0.0553 0.0514 0.0479 0.0462 0.0446 0.0432 0.0420 0.0415 0.0411 0.0407 

[TRAIN] Epoch[1](9959/114412); Loss: 0.088342; Backpropagation: 0.2912 sec; Batch: 2.1154 sec
0.1492 0.1330 0.1104 0.1023 0.0937 0.0868 0.0827 0.0794 0.0767 0.0745 0.0731 0.0720 0.0709 0.0702 0.0695 0.0691 

[TRAIN] Epoch[1](9960/114412); Loss: 0.072543; Backpropagation: 0.2912 sec; Batch: 2.1163 sec
0.1333 0.1198 0.0968 0.0841 0.0722 0.0671 0.0645 0.0629 0.0610 0.0596 0.0584 0.0574 0.0566 0.0560 0.0556 0.0552 

[TRAIN] Epoch[1](9961/114412); Loss: 0.116017; Backpropagation: 0.2908 sec; Batch: 2.1151 sec
0.2049 0.1856 0.1397 0.1259 0.1181 0.1121 0.1071 0.1031 0.1010 0.0987 0.0972 0.0953 0.0938 0.0921 0.0914 0.0903 

[TRAIN] Epoch[1](9962/114412); Loss: 0.073834; Backpropagation: 0.2912 sec; Batch: 2.1142 sec
0.1407 0.1285 0.0870 0.0802 0.0754 0.0702 0.0666 0.0643 0.0621 0.0609 0.0596 0.0585 0.0578 0.0570 0.0564 0.0560 

[TRAIN] Epoch[1](9963/114412); Loss: 0.091609; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1532 0.1381 0.1165 0.1051 0.0953 0.0895 0.0857 0.0815 0.0794 0.0778 0.0764 0.0753 0.0741 0.0734 0.0724 0.0718 

[TRAIN] Epoch[1](9964/114412); Loss: 0.090521; Backpropagation: 0.2931 sec; Batch: 2.1242 sec
0.1553 0.1360 0.1157 0.1019 0.0939 0.0870 0.0825 0.0807 0.0782 0.0766 0.0755 0.0741 0.0734 0.0729 0.0725 0.0721 

[TRAIN] Epoch[1](9965/114412); Loss: 0.086591; Backpropagation: 0.2909 sec; Batch: 2.1195 sec
0.1358 0.1261 0.1010 0.0924 0.0882 0.0843 0.0812 0.0789 0.0778 0.0765 0.0754 0.0746 0.0741 0.0734 0.0731 0.0727 

[TRAIN] Epoch[1](9966/114412); Loss: 0.094766; Backpropagation: 0.2915 sec; Batch: 2.1218 sec
0.1438 0.1361 0.1213 0.1107 0.1015 0.0934 0.0893 0.0862 0.0838 0.0816 0.0801 0.0792 0.0783 0.0775 0.0770 0.0765 

[TRAIN] Epoch[1](9967/114412); Loss: 0.075925; Backpropagation: 0.2905 sec; Batch: 2.0752 sec
0.1715 0.1480 0.1071 0.0857 0.0742 0.0669 0.0624 0.0600 0.0580 0.0563 0.0552 0.0544 0.0542 0.0539 0.0537 0.0534 

[TRAIN] Epoch[1](9968/114412); Loss: 0.094259; Backpropagation: 0.2952 sec; Batch: 2.1203 sec
0.1446 0.1319 0.1152 0.1037 0.0975 0.0913 0.0883 0.0859 0.0845 0.0832 0.0821 0.0811 0.0806 0.0799 0.0794 0.0791 

[TRAIN] Epoch[1](9969/114412); Loss: 0.094831; Backpropagation: 0.2930 sec; Batch: 2.0778 sec
0.2047 0.1888 0.1405 0.1212 0.1079 0.0934 0.0840 0.0767 0.0702 0.0681 0.0638 0.0628 0.0612 0.0589 0.0581 0.0569 

[TRAIN] Epoch[1](9970/114412); Loss: 0.078899; Backpropagation: 0.2906 sec; Batch: 2.1159 sec
0.1558 0.1357 0.1027 0.0891 0.0804 0.0733 0.0701 0.0668 0.0647 0.0633 0.0621 0.0611 0.0603 0.0595 0.0589 0.0584 

[TRAIN] Epoch[1](9971/114412); Loss: 0.073427; Backpropagation: 0.2912 sec; Batch: 2.1738 sec
0.1246 0.1034 0.0921 0.0801 0.0766 0.0704 0.0681 0.0657 0.0642 0.0632 0.0623 0.0618 0.0610 0.0608 0.0605 0.0601 

[TRAIN] Epoch[1](9972/114412); Loss: 0.071047; Backpropagation: 0.2930 sec; Batch: 2.0831 sec
0.1355 0.1280 0.0953 0.0811 0.0709 0.0652 0.0628 0.0602 0.0580 0.0567 0.0556 0.0549 0.0541 0.0534 0.0527 0.0524 

[TRAIN] Epoch[1](9973/114412); Loss: 0.071262; Backpropagation: 0.2913 sec; Batch: 2.1135 sec
0.1313 0.1186 0.0980 0.0850 0.0752 0.0670 0.0639 0.0607 0.0590 0.0574 0.0559 0.0550 0.0541 0.0535 0.0529 0.0526 

[TRAIN] Epoch[1](9974/114412); Loss: 0.084343; Backpropagation: 0.2907 sec; Batch: 2.1163 sec
0.1315 0.1223 0.1008 0.0911 0.0858 0.0825 0.0798 0.0772 0.0754 0.0743 0.0733 0.0724 0.0716 0.0710 0.0705 0.0700 

[TRAIN] Epoch[1](9975/114412); Loss: 0.070336; Backpropagation: 0.2909 sec; Batch: 2.0778 sec
0.1206 0.1101 0.0913 0.0804 0.0734 0.0686 0.0648 0.0626 0.0602 0.0586 0.0578 0.0568 0.0560 0.0553 0.0546 0.0542 

[TRAIN] Epoch[1](9976/114412); Loss: 0.079235; Backpropagation: 0.2910 sec; Batch: 2.0786 sec
0.1447 0.1335 0.0954 0.0828 0.0780 0.0737 0.0708 0.0686 0.0678 0.0666 0.0658 0.0649 0.0642 0.0640 0.0637 0.0634 

[TRAIN] Epoch[1](9977/114412); Loss: 0.069066; Backpropagation: 0.2954 sec; Batch: 2.0803 sec
0.1753 0.1439 0.0965 0.0818 0.0671 0.0564 0.0554 0.0526 0.0508 0.0491 0.0477 0.0469 0.0461 0.0457 0.0452 0.0448 

[TRAIN] Epoch[1](9978/114412); Loss: 0.075805; Backpropagation: 0.2950 sec; Batch: 2.1226 sec
0.1348 0.1200 0.1020 0.0861 0.0784 0.0729 0.0687 0.0657 0.0642 0.0626 0.0615 0.0605 0.0596 0.0590 0.0586 0.0583 

[TRAIN] Epoch[1](9979/114412); Loss: 0.043139; Backpropagation: 0.2929 sec; Batch: 2.1160 sec
0.0939 0.0881 0.0569 0.0479 0.0429 0.0388 0.0364 0.0346 0.0331 0.0323 0.0318 0.0315 0.0309 0.0306 0.0302 0.0303 

[TRAIN] Epoch[1](9980/114412); Loss: 0.093705; Backpropagation: 0.2958 sec; Batch: 2.1211 sec
0.1571 0.1411 0.1150 0.1052 0.0951 0.0904 0.0862 0.0838 0.0816 0.0801 0.0790 0.0781 0.0773 0.0768 0.0763 0.0760 

[TRAIN] Epoch[1](9981/114412); Loss: 0.073981; Backpropagation: 0.2932 sec; Batch: 2.1173 sec
0.1168 0.1026 0.0907 0.0826 0.0745 0.0715 0.0696 0.0678 0.0660 0.0647 0.0640 0.0633 0.0629 0.0625 0.0622 0.0620 

[TRAIN] Epoch[1](9982/114412); Loss: 0.060194; Backpropagation: 0.2926 sec; Batch: 2.1207 sec
0.1339 0.1149 0.0811 0.0733 0.0628 0.0554 0.0511 0.0485 0.0462 0.0446 0.0436 0.0426 0.0419 0.0413 0.0410 0.0408 

[TRAIN] Epoch[1](9983/114412); Loss: 0.109197; Backpropagation: 0.2904 sec; Batch: 2.0915 sec
0.1626 0.1502 0.1321 0.1201 0.1121 0.1071 0.1033 0.1009 0.0992 0.0971 0.0960 0.0949 0.0939 0.0930 0.0925 0.0920 

[TRAIN] Epoch[1](9984/114412); Loss: 0.068398; Backpropagation: 0.2914 sec; Batch: 2.1172 sec
0.1138 0.1004 0.0830 0.0737 0.0684 0.0660 0.0637 0.0619 0.0603 0.0594 0.0585 0.0580 0.0573 0.0570 0.0565 0.0562 

[TRAIN] Epoch[1](9985/114412); Loss: 0.081002; Backpropagation: 0.2919 sec; Batch: 2.0764 sec
0.1746 0.1555 0.1078 0.0840 0.0769 0.0708 0.0688 0.0666 0.0646 0.0632 0.0621 0.0612 0.0605 0.0602 0.0599 0.0594 

[TRAIN] Epoch[1](9986/114412); Loss: 0.058954; Backpropagation: 0.2903 sec; Batch: 2.1178 sec
0.1306 0.1143 0.0765 0.0624 0.0566 0.0531 0.0503 0.0480 0.0461 0.0451 0.0444 0.0439 0.0433 0.0431 0.0428 0.0426 

[TRAIN] Epoch[1](9987/114412); Loss: 0.068179; Backpropagation: 0.2906 sec; Batch: 2.1232 sec
0.1483 0.1353 0.0971 0.0884 0.0668 0.0656 0.0563 0.0522 0.0519 0.0494 0.0486 0.0474 0.0466 0.0461 0.0455 0.0453 

[TRAIN] Epoch[1](9988/114412); Loss: 0.074969; Backpropagation: 0.2913 sec; Batch: 2.1133 sec
0.1478 0.1291 0.0975 0.0830 0.0745 0.0691 0.0661 0.0637 0.0616 0.0604 0.0593 0.0585 0.0577 0.0573 0.0570 0.0566 

[TRAIN] Epoch[1](9989/114412); Loss: 0.081018; Backpropagation: 0.2905 sec; Batch: 2.1127 sec
0.1501 0.1348 0.1033 0.0908 0.0798 0.0748 0.0716 0.0695 0.0679 0.0665 0.0659 0.0652 0.0646 0.0642 0.0639 0.0635 

[TRAIN] Epoch[1](9990/114412); Loss: 0.062468; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.1168 0.1051 0.0738 0.0691 0.0625 0.0590 0.0569 0.0546 0.0532 0.0522 0.0510 0.0502 0.0495 0.0489 0.0485 0.0483 

[TRAIN] Epoch[1](9991/114412); Loss: 0.079397; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1480 0.1390 0.1020 0.0855 0.0761 0.0718 0.0694 0.0677 0.0663 0.0655 0.0645 0.0639 0.0633 0.0629 0.0624 0.0620 

[TRAIN] Epoch[1](9992/114412); Loss: 0.091357; Backpropagation: 0.2906 sec; Batch: 2.1169 sec
0.1848 0.1768 0.1243 0.1104 0.0891 0.0796 0.0763 0.0739 0.0719 0.0703 0.0692 0.0684 0.0676 0.0670 0.0664 0.0658 

[TRAIN] Epoch[1](9993/114412); Loss: 0.086464; Backpropagation: 0.2910 sec; Batch: 2.0759 sec
0.1531 0.1438 0.1116 0.0985 0.0895 0.0832 0.0789 0.0754 0.0733 0.0719 0.0700 0.0687 0.0675 0.0666 0.0659 0.0653 

[TRAIN] Epoch[1](9994/114412); Loss: 0.079941; Backpropagation: 0.2905 sec; Batch: 2.0986 sec
0.1434 0.1290 0.1025 0.0924 0.0818 0.0751 0.0714 0.0689 0.0676 0.0660 0.0651 0.0644 0.0638 0.0630 0.0625 0.0621 

[TRAIN] Epoch[1](9995/114412); Loss: 0.066880; Backpropagation: 0.2916 sec; Batch: 2.0773 sec
0.1644 0.1307 0.0950 0.0776 0.0652 0.0577 0.0540 0.0521 0.0499 0.0485 0.0477 0.0465 0.0459 0.0454 0.0449 0.0445 

[TRAIN] Epoch[1](9996/114412); Loss: 0.052379; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.1072 0.1022 0.0644 0.0565 0.0533 0.0488 0.0462 0.0438 0.0427 0.0413 0.0404 0.0396 0.0389 0.0381 0.0376 0.0371 

[TRAIN] Epoch[1](9997/114412); Loss: 0.089622; Backpropagation: 0.2912 sec; Batch: 2.0788 sec
0.1597 0.1454 0.1182 0.1019 0.0891 0.0844 0.0802 0.0780 0.0758 0.0743 0.0730 0.0720 0.0713 0.0707 0.0701 0.0697 

[TRAIN] Epoch[1](9998/114412); Loss: 0.081774; Backpropagation: 0.2908 sec; Batch: 2.0780 sec
0.1385 0.1300 0.1031 0.0892 0.0811 0.0783 0.0749 0.0724 0.0704 0.0691 0.0682 0.0676 0.0670 0.0665 0.0661 0.0659 

[TRAIN] Epoch[1](9999/114412); Loss: 0.065411; Backpropagation: 0.2931 sec; Batch: 2.0788 sec
0.1237 0.1142 0.0867 0.0705 0.0637 0.0610 0.0575 0.0554 0.0542 0.0529 0.0523 0.0516 0.0512 0.0508 0.0507 0.0504 

[TRAIN] Epoch[1](10000/114412); Loss: 0.050270; Backpropagation: 0.2953 sec; Batch: 2.1249 sec
0.1236 0.1195 0.0748 0.0546 0.0473 0.0419 0.0395 0.0366 0.0354 0.0347 0.0336 0.0332 0.0328 0.0324 0.0322 0.0320 

[TRAIN] Epoch[1](10001/114412); Loss: 0.081146; Backpropagation: 0.2927 sec; Batch: 2.0793 sec
0.1385 0.1314 0.1052 0.0887 0.0800 0.0757 0.0732 0.0712 0.0695 0.0684 0.0674 0.0665 0.0662 0.0657 0.0655 0.0653 

[TRAIN] Epoch[1](10002/114412); Loss: 0.064366; Backpropagation: 0.3073 sec; Batch: 2.1384 sec
0.1610 0.1275 0.0837 0.0669 0.0617 0.0569 0.0538 0.0507 0.0487 0.0476 0.0465 0.0458 0.0452 0.0449 0.0447 0.0444 

[TRAIN] Epoch[1](10003/114412); Loss: 0.068594; Backpropagation: 0.2954 sec; Batch: 2.0874 sec
0.1326 0.1254 0.0921 0.0761 0.0681 0.0628 0.0601 0.0573 0.0556 0.0545 0.0536 0.0530 0.0524 0.0517 0.0513 0.0510 

[TRAIN] Epoch[1](10004/114412); Loss: 0.066591; Backpropagation: 0.2906 sec; Batch: 2.0752 sec
0.1281 0.1145 0.0941 0.0815 0.0709 0.0646 0.0597 0.0567 0.0540 0.0524 0.0507 0.0494 0.0483 0.0476 0.0468 0.0461 

[TRAIN] Epoch[1](10005/114412); Loss: 0.065726; Backpropagation: 0.2899 sec; Batch: 2.0779 sec
0.1582 0.1461 0.0921 0.0715 0.0671 0.0584 0.0536 0.0510 0.0490 0.0467 0.0454 0.0440 0.0431 0.0423 0.0416 0.0414 

[TRAIN] Epoch[1](10006/114412); Loss: 0.089508; Backpropagation: 0.2906 sec; Batch: 2.1218 sec
0.1842 0.1655 0.1281 0.1083 0.0951 0.0851 0.0780 0.0723 0.0694 0.0675 0.0658 0.0645 0.0633 0.0623 0.0617 0.0609 

[TRAIN] Epoch[1](10007/114412); Loss: 0.095508; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.1863 0.1632 0.1326 0.1111 0.0968 0.0882 0.0827 0.0800 0.0772 0.0757 0.0742 0.0734 0.0726 0.0718 0.0713 0.0708 

[TRAIN] Epoch[1](10008/114412); Loss: 0.059737; Backpropagation: 0.2912 sec; Batch: 2.0767 sec
0.1459 0.1255 0.0712 0.0603 0.0562 0.0537 0.0492 0.0473 0.0459 0.0448 0.0439 0.0432 0.0426 0.0423 0.0419 0.0417 

[TRAIN] Epoch[1](10009/114412); Loss: 0.096542; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1538 0.1410 0.1204 0.1081 0.0989 0.0937 0.0903 0.0877 0.0854 0.0840 0.0825 0.0815 0.0804 0.0796 0.0789 0.0783 

[TRAIN] Epoch[1](10010/114412); Loss: 0.072685; Backpropagation: 0.2911 sec; Batch: 2.1163 sec
0.1294 0.1207 0.0918 0.0813 0.0736 0.0679 0.0652 0.0629 0.0615 0.0604 0.0594 0.0587 0.0581 0.0577 0.0573 0.0569 

[TRAIN] Epoch[1](10011/114412); Loss: 0.076161; Backpropagation: 0.2929 sec; Batch: 2.1196 sec
0.1519 0.1344 0.1006 0.0872 0.0771 0.0710 0.0666 0.0638 0.0623 0.0602 0.0590 0.0581 0.0572 0.0568 0.0563 0.0561 

[TRAIN] Epoch[1](10012/114412); Loss: 0.090083; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1523 0.1395 0.1127 0.0999 0.0919 0.0889 0.0837 0.0815 0.0791 0.0766 0.0755 0.0739 0.0727 0.0719 0.0710 0.0703 

[TRAIN] Epoch[1](10013/114412); Loss: 0.077944; Backpropagation: 0.2914 sec; Batch: 2.1143 sec
0.1444 0.1318 0.0997 0.0883 0.0796 0.0738 0.0700 0.0670 0.0648 0.0633 0.0622 0.0615 0.0609 0.0604 0.0598 0.0596 

[TRAIN] Epoch[1](10014/114412); Loss: 0.086289; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.1546 0.1399 0.1099 0.0956 0.0864 0.0811 0.0776 0.0744 0.0729 0.0716 0.0707 0.0698 0.0694 0.0691 0.0689 0.0688 

[TRAIN] Epoch[1](10015/114412); Loss: 0.069387; Backpropagation: 0.2929 sec; Batch: 2.1164 sec
0.1262 0.1183 0.0903 0.0780 0.0692 0.0645 0.0619 0.0601 0.0582 0.0569 0.0560 0.0551 0.0546 0.0541 0.0535 0.0534 

[TRAIN] Epoch[1](10016/114412); Loss: 0.094104; Backpropagation: 0.2915 sec; Batch: 2.1197 sec
0.1374 0.1279 0.1105 0.1028 0.0962 0.0927 0.0896 0.0872 0.0855 0.0843 0.0835 0.0826 0.0820 0.0815 0.0811 0.0808 

[TRAIN] Epoch[1](10017/114412); Loss: 0.086355; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1486 0.1449 0.1104 0.0973 0.0865 0.0822 0.0778 0.0755 0.0736 0.0722 0.0709 0.0697 0.0689 0.0681 0.0677 0.0674 

[TRAIN] Epoch[1](10018/114412); Loss: 0.081118; Backpropagation: 0.2911 sec; Batch: 2.1139 sec
0.1864 0.1660 0.1258 0.1007 0.0810 0.0749 0.0665 0.0622 0.0587 0.0565 0.0553 0.0542 0.0534 0.0527 0.0520 0.0516 

[TRAIN] Epoch[1](10019/114412); Loss: 0.101675; Backpropagation: 0.2927 sec; Batch: 2.1211 sec
0.1442 0.1341 0.1237 0.1106 0.1040 0.1002 0.0967 0.0944 0.0930 0.0916 0.0905 0.0897 0.0891 0.0888 0.0883 0.0879 

[TRAIN] Epoch[1](10020/114412); Loss: 0.070789; Backpropagation: 0.2930 sec; Batch: 2.1163 sec
0.1496 0.1320 0.1040 0.0872 0.0742 0.0653 0.0614 0.0581 0.0547 0.0526 0.0508 0.0501 0.0490 0.0483 0.0479 0.0474 

[TRAIN] Epoch[1](10021/114412); Loss: 0.078207; Backpropagation: 0.2912 sec; Batch: 2.1198 sec
0.1390 0.1290 0.1017 0.0901 0.0805 0.0734 0.0701 0.0674 0.0656 0.0641 0.0632 0.0626 0.0619 0.0615 0.0610 0.0604 

[TRAIN] Epoch[1](10022/114412); Loss: 0.094401; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1504 0.1360 0.1115 0.1020 0.0951 0.0913 0.0878 0.0859 0.0842 0.0831 0.0820 0.0812 0.0806 0.0802 0.0798 0.0795 

[TRAIN] Epoch[1](10023/114412); Loss: 0.065380; Backpropagation: 0.2935 sec; Batch: 2.1778 sec
0.1432 0.1190 0.0868 0.0740 0.0650 0.0599 0.0560 0.0535 0.0514 0.0503 0.0490 0.0483 0.0479 0.0475 0.0472 0.0470 

[TRAIN] Epoch[1](10024/114412); Loss: 0.089332; Backpropagation: 0.2951 sec; Batch: 2.1212 sec
0.1872 0.1685 0.1292 0.1054 0.0868 0.0812 0.0756 0.0731 0.0702 0.0681 0.0665 0.0654 0.0640 0.0632 0.0626 0.0621 

[TRAIN] Epoch[1](10025/114412); Loss: 0.077498; Backpropagation: 0.2933 sec; Batch: 2.1197 sec
0.1551 0.1456 0.1021 0.0891 0.0756 0.0701 0.0665 0.0647 0.0625 0.0611 0.0597 0.0587 0.0581 0.0575 0.0570 0.0566 

[TRAIN] Epoch[1](10026/114412); Loss: 0.079077; Backpropagation: 0.2930 sec; Batch: 2.1169 sec
0.1406 0.1269 0.0990 0.0882 0.0805 0.0752 0.0729 0.0698 0.0680 0.0661 0.0648 0.0639 0.0632 0.0626 0.0620 0.0616 

[TRAIN] Epoch[1](10027/114412); Loss: 0.093667; Backpropagation: 0.2930 sec; Batch: 2.1185 sec
0.1455 0.1365 0.1118 0.1038 0.0950 0.0911 0.0878 0.0857 0.0839 0.0823 0.0812 0.0801 0.0793 0.0788 0.0782 0.0778 

[TRAIN] Epoch[1](10028/114412); Loss: 0.082220; Backpropagation: 0.2913 sec; Batch: 2.1146 sec
0.1460 0.1338 0.1049 0.0942 0.0829 0.0788 0.0748 0.0718 0.0695 0.0682 0.0670 0.0661 0.0653 0.0647 0.0639 0.0636 

[TRAIN] Epoch[1](10029/114412); Loss: 0.078472; Backpropagation: 0.2929 sec; Batch: 2.1209 sec
0.1397 0.1197 0.0975 0.0868 0.0797 0.0752 0.0716 0.0692 0.0674 0.0661 0.0652 0.0645 0.0640 0.0635 0.0630 0.0626 

[TRAIN] Epoch[1](10030/114412); Loss: 0.089908; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1468 0.1345 0.1074 0.0996 0.0925 0.0872 0.0828 0.0808 0.0790 0.0777 0.0767 0.0759 0.0752 0.0746 0.0741 0.0738 

[TRAIN] Epoch[1](10031/114412); Loss: 0.064468; Backpropagation: 0.2911 sec; Batch: 2.1017 sec
0.1249 0.1170 0.0851 0.0716 0.0637 0.0590 0.0563 0.0543 0.0528 0.0513 0.0507 0.0501 0.0493 0.0488 0.0485 0.0483 

[TRAIN] Epoch[1](10032/114412); Loss: 0.067133; Backpropagation: 0.2914 sec; Batch: 2.1176 sec
0.1284 0.1149 0.0819 0.0713 0.0676 0.0646 0.0615 0.0584 0.0565 0.0550 0.0537 0.0531 0.0526 0.0518 0.0515 0.0513 

[TRAIN] Epoch[1](10033/114412); Loss: 0.080654; Backpropagation: 0.2910 sec; Batch: 2.1165 sec
0.1857 0.1654 0.1202 0.0950 0.0841 0.0714 0.0660 0.0624 0.0592 0.0575 0.0558 0.0549 0.0541 0.0534 0.0530 0.0524 

[TRAIN] Epoch[1](10034/114412); Loss: 0.113007; Backpropagation: 0.2907 sec; Batch: 2.1136 sec
0.1956 0.1764 0.1545 0.1387 0.1247 0.1149 0.1088 0.1007 0.0955 0.0918 0.0894 0.0868 0.0848 0.0834 0.0817 0.0804 

[TRAIN] Epoch[1](10035/114412); Loss: 0.064438; Backpropagation: 0.2906 sec; Batch: 2.1141 sec
0.1402 0.1239 0.0877 0.0696 0.0588 0.0621 0.0559 0.0527 0.0508 0.0493 0.0483 0.0474 0.0468 0.0462 0.0457 0.0455 

[TRAIN] Epoch[1](10036/114412); Loss: 0.054443; Backpropagation: 0.2911 sec; Batch: 2.0766 sec
0.1091 0.1011 0.0703 0.0624 0.0548 0.0521 0.0475 0.0455 0.0438 0.0424 0.0416 0.0408 0.0403 0.0401 0.0398 0.0395 

[TRAIN] Epoch[1](10037/114412); Loss: 0.070741; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.1689 0.1452 0.0976 0.0787 0.0735 0.0634 0.0591 0.0552 0.0530 0.0507 0.0495 0.0487 0.0479 0.0473 0.0468 0.0463 

[TRAIN] Epoch[1](10038/114412); Loss: 0.072887; Backpropagation: 0.2951 sec; Batch: 2.1222 sec
0.1439 0.1260 0.0956 0.0809 0.0736 0.0676 0.0651 0.0627 0.0603 0.0585 0.0572 0.0563 0.0553 0.0549 0.0543 0.0539 

[TRAIN] Epoch[1](10039/114412); Loss: 0.073490; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1471 0.1384 0.0923 0.0834 0.0737 0.0682 0.0650 0.0619 0.0600 0.0579 0.0568 0.0556 0.0547 0.0540 0.0535 0.0533 

[TRAIN] Epoch[1](10040/114412); Loss: 0.075070; Backpropagation: 0.2908 sec; Batch: 2.1178 sec
0.1478 0.1283 0.1032 0.0866 0.0773 0.0694 0.0667 0.0634 0.0612 0.0599 0.0583 0.0571 0.0564 0.0558 0.0551 0.0547 

[TRAIN] Epoch[1](10041/114412); Loss: 0.072553; Backpropagation: 0.2955 sec; Batch: 2.1236 sec
0.1385 0.1277 0.0908 0.0798 0.0735 0.0688 0.0647 0.0618 0.0600 0.0587 0.0575 0.0567 0.0562 0.0558 0.0553 0.0551 

[TRAIN] Epoch[1](10042/114412); Loss: 0.082121; Backpropagation: 0.2931 sec; Batch: 2.0801 sec
0.1493 0.1357 0.0994 0.0909 0.0823 0.0779 0.0747 0.0719 0.0701 0.0688 0.0675 0.0665 0.0656 0.0651 0.0644 0.0639 

[TRAIN] Epoch[1](10043/114412); Loss: 0.065046; Backpropagation: 0.2913 sec; Batch: 2.0859 sec
0.1383 0.1209 0.0869 0.0774 0.0681 0.0617 0.0570 0.0527 0.0503 0.0491 0.0480 0.0473 0.0464 0.0459 0.0455 0.0452 

[TRAIN] Epoch[1](10044/114412); Loss: 0.075900; Backpropagation: 0.2914 sec; Batch: 2.0772 sec
0.1584 0.1437 0.0975 0.0823 0.0711 0.0686 0.0645 0.0627 0.0618 0.0598 0.0592 0.0582 0.0574 0.0567 0.0564 0.0561 

[TRAIN] Epoch[1](10045/114412); Loss: 0.068152; Backpropagation: 0.2905 sec; Batch: 2.0770 sec
0.1427 0.1320 0.0894 0.0766 0.0667 0.0624 0.0584 0.0557 0.0539 0.0525 0.0514 0.0508 0.0501 0.0495 0.0493 0.0489 

[TRAIN] Epoch[1](10046/114412); Loss: 0.072928; Backpropagation: 0.2903 sec; Batch: 2.1173 sec
0.1579 0.1375 0.0936 0.0722 0.0702 0.0661 0.0618 0.0599 0.0583 0.0570 0.0564 0.0558 0.0555 0.0551 0.0548 0.0544 

[TRAIN] Epoch[1](10047/114412); Loss: 0.113827; Backpropagation: 0.2907 sec; Batch: 2.0771 sec
0.1901 0.1757 0.1452 0.1283 0.1166 0.1083 0.1038 0.1009 0.0988 0.0965 0.0954 0.0942 0.0932 0.0923 0.0913 0.0905 

[TRAIN] Epoch[1](10048/114412); Loss: 0.095333; Backpropagation: 0.2909 sec; Batch: 2.0778 sec
0.1509 0.1428 0.1206 0.1075 0.0979 0.0908 0.0880 0.0862 0.0834 0.0821 0.0811 0.0799 0.0791 0.0788 0.0784 0.0779 

[TRAIN] Epoch[1](10049/114412); Loss: 0.094087; Backpropagation: 0.2913 sec; Batch: 2.1200 sec
0.2289 0.2037 0.1555 0.1208 0.1013 0.0848 0.0755 0.0672 0.0655 0.0638 0.0598 0.0588 0.0568 0.0550 0.0544 0.0536 

[TRAIN] Epoch[1](10050/114412); Loss: 0.085675; Backpropagation: 0.2911 sec; Batch: 2.1242 sec
0.1369 0.1242 0.1049 0.0957 0.0885 0.0832 0.0804 0.0780 0.0757 0.0741 0.0730 0.0722 0.0716 0.0712 0.0708 0.0705 

[TRAIN] Epoch[1](10051/114412); Loss: 0.088733; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1646 0.1551 0.1199 0.1051 0.0940 0.0824 0.0775 0.0749 0.0720 0.0707 0.0693 0.0682 0.0674 0.0667 0.0662 0.0658 

[TRAIN] Epoch[1](10052/114412); Loss: 0.067643; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1145 0.1063 0.0874 0.0759 0.0694 0.0651 0.0620 0.0598 0.0583 0.0569 0.0559 0.0552 0.0546 0.0542 0.0536 0.0534 

[TRAIN] Epoch[1](10053/114412); Loss: 0.086690; Backpropagation: 0.2911 sec; Batch: 2.1129 sec
0.1454 0.1268 0.1036 0.0942 0.0890 0.0851 0.0810 0.0785 0.0765 0.0748 0.0740 0.0729 0.0724 0.0716 0.0709 0.0703 

[TRAIN] Epoch[1](10054/114412); Loss: 0.064513; Backpropagation: 0.2912 sec; Batch: 2.1094 sec
0.1454 0.1224 0.0865 0.0744 0.0667 0.0595 0.0550 0.0521 0.0501 0.0482 0.0470 0.0461 0.0454 0.0449 0.0444 0.0441 

[TRAIN] Epoch[1](10055/114412); Loss: 0.089697; Backpropagation: 0.2912 sec; Batch: 2.0762 sec
0.1586 0.1475 0.1067 0.0933 0.0878 0.0846 0.0822 0.0793 0.0774 0.0760 0.0752 0.0743 0.0738 0.0733 0.0728 0.0725 

[TRAIN] Epoch[1](10056/114412); Loss: 0.100422; Backpropagation: 0.2908 sec; Batch: 2.1134 sec
0.1640 0.1522 0.1272 0.1144 0.1031 0.0955 0.0921 0.0899 0.0876 0.0857 0.0845 0.0834 0.0825 0.0819 0.0814 0.0813 

[TRAIN] Epoch[1](10057/114412); Loss: 0.069718; Backpropagation: 0.2912 sec; Batch: 2.0769 sec
0.1813 0.1469 0.1051 0.0700 0.0612 0.0614 0.0565 0.0538 0.0510 0.0490 0.0483 0.0471 0.0464 0.0461 0.0456 0.0455 

[TRAIN] Epoch[1](10058/114412); Loss: 0.059760; Backpropagation: 0.2927 sec; Batch: 2.1169 sec
0.1092 0.0933 0.0772 0.0684 0.0603 0.0561 0.0539 0.0522 0.0505 0.0498 0.0487 0.0480 0.0475 0.0472 0.0470 0.0468 

[TRAIN] Epoch[1](10059/114412); Loss: 0.081849; Backpropagation: 0.2928 sec; Batch: 2.1137 sec
0.1399 0.1291 0.1166 0.1029 0.0918 0.0823 0.0747 0.0709 0.0675 0.0656 0.0634 0.0624 0.0614 0.0610 0.0603 0.0598 

[TRAIN] Epoch[1](10060/114412); Loss: 0.077612; Backpropagation: 0.2954 sec; Batch: 2.1191 sec
0.1572 0.1441 0.1009 0.0821 0.0753 0.0708 0.0682 0.0658 0.0627 0.0615 0.0607 0.0597 0.0590 0.0583 0.0579 0.0575 

[TRAIN] Epoch[1](10061/114412); Loss: 0.077465; Backpropagation: 0.2914 sec; Batch: 2.1093 sec
0.1398 0.1278 0.1028 0.0908 0.0797 0.0736 0.0695 0.0667 0.0647 0.0632 0.0620 0.0608 0.0603 0.0598 0.0591 0.0588 

[TRAIN] Epoch[1](10062/114412); Loss: 0.050425; Backpropagation: 0.2909 sec; Batch: 2.1162 sec
0.1210 0.1072 0.0768 0.0562 0.0457 0.0431 0.0397 0.0385 0.0365 0.0359 0.0354 0.0348 0.0344 0.0340 0.0338 0.0338 

[TRAIN] Epoch[1](10063/114412); Loss: 0.078918; Backpropagation: 0.2915 sec; Batch: 2.1152 sec
0.1331 0.1173 0.0959 0.0873 0.0802 0.0763 0.0727 0.0703 0.0687 0.0674 0.0666 0.0660 0.0657 0.0653 0.0651 0.0648 

[TRAIN] Epoch[1](10064/114412); Loss: 0.065570; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1208 0.1112 0.0807 0.0744 0.0669 0.0618 0.0590 0.0563 0.0549 0.0538 0.0528 0.0522 0.0517 0.0511 0.0509 0.0506 

[TRAIN] Epoch[1](10065/114412); Loss: 0.077341; Backpropagation: 0.2910 sec; Batch: 2.1250 sec
0.1198 0.1112 0.0981 0.0861 0.0796 0.0754 0.0730 0.0706 0.0691 0.0675 0.0663 0.0653 0.0647 0.0641 0.0635 0.0631 

[TRAIN] Epoch[1](10066/114412); Loss: 0.071309; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1569 0.1334 0.0980 0.0844 0.0714 0.0630 0.0602 0.0578 0.0557 0.0542 0.0526 0.0521 0.0509 0.0503 0.0500 0.0498 

[TRAIN] Epoch[1](10067/114412); Loss: 0.054921; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1059 0.0907 0.0675 0.0630 0.0554 0.0518 0.0491 0.0472 0.0458 0.0446 0.0440 0.0433 0.0430 0.0427 0.0425 0.0424 

[TRAIN] Epoch[1](10068/114412); Loss: 0.089346; Backpropagation: 0.2929 sec; Batch: 2.1271 sec
0.1556 0.1422 0.1170 0.0992 0.0881 0.0823 0.0790 0.0777 0.0756 0.0744 0.0740 0.0735 0.0731 0.0728 0.0727 0.0725 

[TRAIN] Epoch[1](10069/114412); Loss: 0.094068; Backpropagation: 0.2930 sec; Batch: 2.1196 sec
0.1479 0.1382 0.1138 0.1040 0.0988 0.0931 0.0888 0.0866 0.0834 0.0817 0.0805 0.0793 0.0782 0.0776 0.0768 0.0763 

[TRAIN] Epoch[1](10070/114412); Loss: 0.052867; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1045 0.0960 0.0663 0.0563 0.0536 0.0494 0.0457 0.0451 0.0430 0.0421 0.0415 0.0409 0.0406 0.0404 0.0404 0.0401 

[TRAIN] Epoch[1](10071/114412); Loss: 0.087120; Backpropagation: 0.2906 sec; Batch: 2.1168 sec
0.1532 0.1402 0.1097 0.0954 0.0837 0.0807 0.0783 0.0762 0.0748 0.0735 0.0727 0.0719 0.0715 0.0710 0.0707 0.0704 

[TRAIN] Epoch[1](10072/114412); Loss: 0.058895; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1207 0.1113 0.0860 0.0697 0.0597 0.0543 0.0507 0.0481 0.0460 0.0445 0.0434 0.0425 0.0420 0.0414 0.0410 0.0408 

[TRAIN] Epoch[1](10073/114412); Loss: 0.061978; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1280 0.1086 0.0784 0.0688 0.0618 0.0580 0.0560 0.0531 0.0511 0.0496 0.0484 0.0474 0.0465 0.0459 0.0453 0.0447 

[TRAIN] Epoch[1](10074/114412); Loss: 0.098222; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1467 0.1382 0.1179 0.1105 0.1011 0.0960 0.0922 0.0903 0.0884 0.0869 0.0859 0.0849 0.0840 0.0834 0.0828 0.0823 

[TRAIN] Epoch[1](10075/114412); Loss: 0.069734; Backpropagation: 0.2930 sec; Batch: 2.1155 sec
0.1431 0.1354 0.1026 0.0889 0.0763 0.0680 0.0603 0.0573 0.0534 0.0515 0.0492 0.0482 0.0465 0.0457 0.0450 0.0444 

[TRAIN] Epoch[1](10076/114412); Loss: 0.069930; Backpropagation: 0.2911 sec; Batch: 2.1149 sec
0.1216 0.1130 0.0863 0.0794 0.0732 0.0661 0.0621 0.0606 0.0590 0.0581 0.0575 0.0569 0.0566 0.0562 0.0562 0.0561 

[TRAIN] Epoch[1](10077/114412); Loss: 0.075254; Backpropagation: 0.2914 sec; Batch: 2.1159 sec
0.1426 0.1228 0.0947 0.0844 0.0759 0.0708 0.0673 0.0651 0.0635 0.0621 0.0608 0.0599 0.0593 0.0587 0.0582 0.0580 

[TRAIN] Epoch[1](10078/114412); Loss: 0.101304; Backpropagation: 0.2911 sec; Batch: 2.1154 sec
0.1542 0.1439 0.1199 0.1082 0.1034 0.0996 0.0956 0.0934 0.0914 0.0901 0.0887 0.0877 0.0871 0.0864 0.0859 0.0854 

[TRAIN] Epoch[1](10079/114412); Loss: 0.070086; Backpropagation: 0.2912 sec; Batch: 2.1257 sec
0.1333 0.1164 0.0845 0.0752 0.0695 0.0664 0.0630 0.0610 0.0592 0.0579 0.0570 0.0564 0.0559 0.0555 0.0552 0.0550 

[TRAIN] Epoch[1](10080/114412); Loss: 0.061700; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.1264 0.1128 0.0899 0.0717 0.0634 0.0561 0.0534 0.0519 0.0495 0.0476 0.0461 0.0450 0.0442 0.0436 0.0430 0.0426 

[TRAIN] Epoch[1](10081/114412); Loss: 0.059921; Backpropagation: 0.2911 sec; Batch: 2.1123 sec
0.1282 0.1207 0.0906 0.0689 0.0563 0.0520 0.0494 0.0468 0.0455 0.0446 0.0438 0.0432 0.0426 0.0422 0.0420 0.0418 

[TRAIN] Epoch[1](10082/114412); Loss: 0.082644; Backpropagation: 0.2934 sec; Batch: 2.1172 sec
0.1349 0.1263 0.1067 0.0926 0.0852 0.0818 0.0765 0.0735 0.0718 0.0703 0.0691 0.0681 0.0672 0.0665 0.0660 0.0657 

[TRAIN] Epoch[1](10083/114412); Loss: 0.077422; Backpropagation: 0.2956 sec; Batch: 2.1229 sec
0.1713 0.1578 0.0998 0.0850 0.0767 0.0700 0.0659 0.0624 0.0593 0.0579 0.0572 0.0563 0.0555 0.0548 0.0546 0.0544 

[TRAIN] Epoch[1](10084/114412); Loss: 0.101797; Backpropagation: 0.2955 sec; Batch: 2.1170 sec
0.1690 0.1559 0.1313 0.1132 0.1048 0.0990 0.0955 0.0917 0.0894 0.0868 0.0855 0.0836 0.0825 0.0813 0.0801 0.0793 

[TRAIN] Epoch[1](10085/114412); Loss: 0.075435; Backpropagation: 0.2911 sec; Batch: 2.0770 sec
0.1288 0.1138 0.0921 0.0825 0.0762 0.0723 0.0699 0.0677 0.0660 0.0645 0.0635 0.0629 0.0622 0.0618 0.0615 0.0611 

[TRAIN] Epoch[1](10086/114412); Loss: 0.076470; Backpropagation: 0.2903 sec; Batch: 2.1125 sec
0.1353 0.1240 0.0995 0.0873 0.0790 0.0740 0.0698 0.0665 0.0644 0.0629 0.0618 0.0609 0.0601 0.0597 0.0595 0.0589 

[TRAIN] Epoch[1](10087/114412); Loss: 0.075070; Backpropagation: 0.2911 sec; Batch: 2.0825 sec
0.1733 0.1522 0.1107 0.0843 0.0710 0.0689 0.0641 0.0628 0.0582 0.0543 0.0535 0.0513 0.0501 0.0497 0.0485 0.0481 

[TRAIN] Epoch[1](10088/114412); Loss: 0.057273; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1295 0.1102 0.0809 0.0686 0.0541 0.0503 0.0482 0.0459 0.0440 0.0429 0.0419 0.0409 0.0403 0.0400 0.0395 0.0392 

[TRAIN] Epoch[1](10089/114412); Loss: 0.068675; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1247 0.1092 0.0892 0.0760 0.0701 0.0659 0.0622 0.0600 0.0584 0.0568 0.0558 0.0549 0.0544 0.0542 0.0537 0.0535 

[TRAIN] Epoch[1](10090/114412); Loss: 0.055125; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1198 0.1080 0.0730 0.0586 0.0514 0.0486 0.0465 0.0448 0.0433 0.0426 0.0417 0.0412 0.0409 0.0406 0.0405 0.0404 

[TRAIN] Epoch[1](10091/114412); Loss: 0.076206; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1390 0.1314 0.0864 0.0768 0.0740 0.0706 0.0691 0.0668 0.0657 0.0646 0.0637 0.0629 0.0627 0.0623 0.0618 0.0616 

[TRAIN] Epoch[1](10092/114412); Loss: 0.054891; Backpropagation: 0.2902 sec; Batch: 2.1283 sec
0.1301 0.1129 0.0732 0.0580 0.0535 0.0493 0.0463 0.0433 0.0416 0.0407 0.0397 0.0389 0.0383 0.0378 0.0377 0.0370 

[TRAIN] Epoch[1](10093/114412); Loss: 0.066147; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.1412 0.1319 0.0882 0.0787 0.0623 0.0589 0.0576 0.0540 0.0522 0.0507 0.0493 0.0484 0.0473 0.0466 0.0459 0.0454 

[TRAIN] Epoch[1](10094/114412); Loss: 0.055608; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1270 0.0967 0.0771 0.0617 0.0527 0.0511 0.0482 0.0457 0.0439 0.0423 0.0417 0.0412 0.0408 0.0402 0.0398 0.0395 

[TRAIN] Epoch[1](10095/114412); Loss: 0.102647; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1689 0.1562 0.1253 0.1167 0.1066 0.1005 0.0965 0.0921 0.0902 0.0881 0.0861 0.0850 0.0841 0.0830 0.0819 0.0813 

[TRAIN] Epoch[1](10096/114412); Loss: 0.069558; Backpropagation: 0.2912 sec; Batch: 2.1135 sec
0.1129 0.1018 0.0875 0.0753 0.0709 0.0668 0.0643 0.0623 0.0610 0.0599 0.0592 0.0588 0.0583 0.0580 0.0580 0.0578 

[TRAIN] Epoch[1](10097/114412); Loss: 0.087141; Backpropagation: 0.2907 sec; Batch: 2.0775 sec
0.1706 0.1602 0.1086 0.0924 0.0855 0.0810 0.0768 0.0737 0.0715 0.0705 0.0690 0.0679 0.0672 0.0669 0.0664 0.0661 

[TRAIN] Epoch[1](10098/114412); Loss: 0.076953; Backpropagation: 0.2901 sec; Batch: 2.1283 sec
0.1578 0.1424 0.1051 0.0888 0.0749 0.0693 0.0664 0.0639 0.0621 0.0603 0.0585 0.0576 0.0569 0.0562 0.0556 0.0553 

[TRAIN] Epoch[1](10099/114412); Loss: 0.073854; Backpropagation: 0.2929 sec; Batch: 2.0790 sec
0.1341 0.1252 0.0889 0.0796 0.0746 0.0696 0.0679 0.0654 0.0632 0.0617 0.0603 0.0594 0.0586 0.0581 0.0576 0.0573 

[TRAIN] Epoch[1](10100/114412); Loss: 0.073938; Backpropagation: 0.2951 sec; Batch: 2.0808 sec
0.1369 0.1236 0.1048 0.0866 0.0765 0.0712 0.0661 0.0623 0.0603 0.0588 0.0574 0.0566 0.0562 0.0555 0.0553 0.0549 

[TRAIN] Epoch[1](10101/114412); Loss: 0.074362; Backpropagation: 0.2927 sec; Batch: 2.1040 sec
0.1472 0.1323 0.0994 0.0898 0.0777 0.0701 0.0642 0.0619 0.0597 0.0579 0.0565 0.0557 0.0551 0.0546 0.0541 0.0536 

[TRAIN] Epoch[1](10102/114412); Loss: 0.074524; Backpropagation: 0.2930 sec; Batch: 2.1206 sec
0.1258 0.1162 0.0909 0.0820 0.0771 0.0737 0.0692 0.0667 0.0649 0.0637 0.0624 0.0615 0.0605 0.0598 0.0592 0.0588 

[TRAIN] Epoch[1](10103/114412); Loss: 0.080638; Backpropagation: 0.2929 sec; Batch: 2.1167 sec
0.1435 0.1255 0.0963 0.0873 0.0792 0.0761 0.0732 0.0710 0.0700 0.0685 0.0675 0.0670 0.0665 0.0664 0.0662 0.0660 

[TRAIN] Epoch[1](10104/114412); Loss: 0.068999; Backpropagation: 0.2912 sec; Batch: 2.1153 sec
0.1268 0.1137 0.0839 0.0788 0.0693 0.0654 0.0629 0.0601 0.0589 0.0573 0.0560 0.0551 0.0545 0.0542 0.0538 0.0533 

[TRAIN] Epoch[1](10105/114412); Loss: 0.072370; Backpropagation: 0.2931 sec; Batch: 2.1156 sec
0.1368 0.1265 0.0881 0.0800 0.0714 0.0685 0.0646 0.0621 0.0604 0.0589 0.0579 0.0574 0.0569 0.0565 0.0561 0.0559 

[TRAIN] Epoch[1](10106/114412); Loss: 0.078271; Backpropagation: 0.2929 sec; Batch: 2.1140 sec
0.1512 0.1344 0.1048 0.0938 0.0788 0.0727 0.0683 0.0658 0.0638 0.0626 0.0612 0.0603 0.0594 0.0588 0.0584 0.0580 

[TRAIN] Epoch[1](10107/114412); Loss: 0.088849; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.1752 0.1534 0.1149 0.1008 0.0885 0.0805 0.0769 0.0747 0.0730 0.0712 0.0703 0.0695 0.0687 0.0684 0.0679 0.0677 

[TRAIN] Epoch[1](10108/114412); Loss: 0.093523; Backpropagation: 0.2913 sec; Batch: 2.1224 sec
0.1767 0.1598 0.1216 0.1111 0.0972 0.0898 0.0843 0.0804 0.0768 0.0748 0.0731 0.0718 0.0709 0.0702 0.0693 0.0687 

[TRAIN] Epoch[1](10109/114412); Loss: 0.055233; Backpropagation: 0.2910 sec; Batch: 2.1199 sec
0.1076 0.0989 0.0733 0.0625 0.0556 0.0522 0.0488 0.0471 0.0455 0.0442 0.0431 0.0422 0.0415 0.0408 0.0404 0.0401 

[TRAIN] Epoch[1](10110/114412); Loss: 0.059905; Backpropagation: 0.2907 sec; Batch: 2.0951 sec
0.1395 0.1015 0.0891 0.0713 0.0627 0.0553 0.0506 0.0480 0.0462 0.0445 0.0436 0.0424 0.0417 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](10111/114412); Loss: 0.079106; Backpropagation: 0.2908 sec; Batch: 2.1132 sec
0.1369 0.1259 0.0989 0.0833 0.0789 0.0743 0.0719 0.0700 0.0683 0.0673 0.0663 0.0655 0.0649 0.0647 0.0643 0.0641 

[TRAIN] Epoch[1](10112/114412); Loss: 0.078857; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1472 0.1335 0.0990 0.0870 0.0797 0.0736 0.0700 0.0677 0.0659 0.0647 0.0638 0.0628 0.0624 0.0618 0.0615 0.0612 

[TRAIN] Epoch[1](10113/114412); Loss: 0.064100; Backpropagation: 0.2910 sec; Batch: 2.1127 sec
0.1532 0.1312 0.0832 0.0701 0.0645 0.0592 0.0555 0.0509 0.0486 0.0464 0.0455 0.0446 0.0440 0.0432 0.0429 0.0425 

[TRAIN] Epoch[1](10114/114412); Loss: 0.068864; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1739 0.1464 0.1054 0.0764 0.0634 0.0587 0.0536 0.0515 0.0499 0.0484 0.0472 0.0466 0.0457 0.0453 0.0450 0.0446 

[TRAIN] Epoch[1](10115/114412); Loss: 0.050412; Backpropagation: 0.2909 sec; Batch: 2.1023 sec
0.1043 0.0973 0.0636 0.0540 0.0482 0.0477 0.0445 0.0417 0.0406 0.0391 0.0386 0.0381 0.0375 0.0373 0.0370 0.0369 

[TRAIN] Epoch[1](10116/114412); Loss: 0.056737; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1240 0.1069 0.0681 0.0607 0.0553 0.0528 0.0493 0.0472 0.0455 0.0442 0.0434 0.0428 0.0425 0.0420 0.0416 0.0414 

[TRAIN] Epoch[1](10117/114412); Loss: 0.064019; Backpropagation: 0.2911 sec; Batch: 2.0767 sec
0.1217 0.1078 0.0890 0.0736 0.0659 0.0601 0.0572 0.0550 0.0525 0.0510 0.0502 0.0492 0.0484 0.0480 0.0475 0.0472 

[TRAIN] Epoch[1](10118/114412); Loss: 0.067479; Backpropagation: 0.2911 sec; Batch: 2.1216 sec
0.1290 0.1001 0.0835 0.0726 0.0695 0.0643 0.0617 0.0591 0.0574 0.0564 0.0556 0.0549 0.0543 0.0539 0.0537 0.0536 

[TRAIN] Epoch[1](10119/114412); Loss: 0.071818; Backpropagation: 0.2911 sec; Batch: 2.0770 sec
0.1438 0.1242 0.0934 0.0800 0.0721 0.0669 0.0644 0.0614 0.0588 0.0577 0.0565 0.0554 0.0543 0.0538 0.0533 0.0530 

[TRAIN] Epoch[1](10120/114412); Loss: 0.079569; Backpropagation: 0.2911 sec; Batch: 2.1111 sec
0.1498 0.1317 0.1085 0.0934 0.0841 0.0770 0.0725 0.0692 0.0661 0.0640 0.0622 0.0607 0.0598 0.0588 0.0581 0.0573 

[TRAIN] Epoch[1](10121/114412); Loss: 0.088857; Backpropagation: 0.2905 sec; Batch: 2.1122 sec
0.1613 0.1456 0.1120 0.0980 0.0888 0.0824 0.0798 0.0777 0.0753 0.0741 0.0727 0.0718 0.0714 0.0707 0.0703 0.0699 

[TRAIN] Epoch[1](10122/114412); Loss: 0.061919; Backpropagation: 0.2928 sec; Batch: 2.1152 sec
0.1170 0.1128 0.0816 0.0661 0.0595 0.0563 0.0539 0.0526 0.0513 0.0502 0.0496 0.0490 0.0483 0.0477 0.0475 0.0472 

[TRAIN] Epoch[1](10123/114412); Loss: 0.098473; Backpropagation: 0.2930 sec; Batch: 2.1132 sec
0.1705 0.1546 0.1235 0.1109 0.1006 0.0941 0.0898 0.0868 0.0842 0.0828 0.0815 0.0804 0.0797 0.0791 0.0786 0.0783 

[TRAIN] Epoch[1](10124/114412); Loss: 0.074655; Backpropagation: 0.2929 sec; Batch: 2.1178 sec
0.1431 0.1277 0.0872 0.0803 0.0761 0.0701 0.0670 0.0643 0.0625 0.0609 0.0600 0.0597 0.0592 0.0589 0.0588 0.0587 

[TRAIN] Epoch[1](10125/114412); Loss: 0.072531; Backpropagation: 0.2909 sec; Batch: 2.1164 sec
0.1349 0.1166 0.0836 0.0794 0.0721 0.0678 0.0650 0.0633 0.0620 0.0609 0.0601 0.0595 0.0592 0.0589 0.0587 0.0584 

[TRAIN] Epoch[1](10126/114412); Loss: 0.075246; Backpropagation: 0.2915 sec; Batch: 2.1082 sec
0.1103 0.1034 0.0924 0.0852 0.0788 0.0741 0.0709 0.0696 0.0679 0.0665 0.0655 0.0648 0.0642 0.0638 0.0634 0.0631 

[TRAIN] Epoch[1](10127/114412); Loss: 0.090474; Backpropagation: 0.2915 sec; Batch: 2.1179 sec
0.1806 0.1640 0.1126 0.0998 0.0902 0.0838 0.0793 0.0764 0.0745 0.0722 0.0710 0.0699 0.0693 0.0684 0.0679 0.0675 

[TRAIN] Epoch[1](10128/114412); Loss: 0.084778; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1426 0.1315 0.1071 0.0962 0.0862 0.0818 0.0789 0.0762 0.0745 0.0723 0.0707 0.0693 0.0684 0.0676 0.0668 0.0663 

[TRAIN] Epoch[1](10129/114412); Loss: 0.080128; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1526 0.1410 0.0996 0.0875 0.0793 0.0740 0.0714 0.0684 0.0668 0.0654 0.0642 0.0636 0.0626 0.0621 0.0619 0.0615 

[TRAIN] Epoch[1](10130/114412); Loss: 0.054751; Backpropagation: 0.2911 sec; Batch: 2.0778 sec
0.1038 0.0945 0.0671 0.0596 0.0556 0.0522 0.0495 0.0471 0.0456 0.0446 0.0437 0.0434 0.0427 0.0425 0.0422 0.0421 

[TRAIN] Epoch[1](10131/114412); Loss: 0.067339; Backpropagation: 0.2931 sec; Batch: 2.1352 sec
0.1508 0.1223 0.0818 0.0719 0.0651 0.0630 0.0573 0.0551 0.0539 0.0527 0.0514 0.0510 0.0506 0.0503 0.0502 0.0499 

[TRAIN] Epoch[1](10132/114412); Loss: 0.075478; Backpropagation: 0.2933 sec; Batch: 2.0786 sec
0.1327 0.1145 0.0911 0.0831 0.0774 0.0720 0.0697 0.0671 0.0655 0.0643 0.0632 0.0624 0.0619 0.0613 0.0608 0.0605 

[TRAIN] Epoch[1](10133/114412); Loss: 0.091143; Backpropagation: 0.2915 sec; Batch: 2.1155 sec
0.1649 0.1402 0.1125 0.0994 0.0915 0.0860 0.0831 0.0802 0.0783 0.0772 0.0761 0.0751 0.0743 0.0736 0.0731 0.0728 

[TRAIN] Epoch[1](10134/114412); Loss: 0.078895; Backpropagation: 0.2929 sec; Batch: 2.0827 sec
0.1525 0.1353 0.1063 0.0915 0.0792 0.0728 0.0699 0.0673 0.0652 0.0636 0.0618 0.0608 0.0597 0.0592 0.0587 0.0585 

[TRAIN] Epoch[1](10135/114412); Loss: 0.057218; Backpropagation: 0.2931 sec; Batch: 2.1217 sec
0.1202 0.1093 0.0794 0.0665 0.0593 0.0538 0.0498 0.0470 0.0451 0.0438 0.0420 0.0412 0.0403 0.0397 0.0392 0.0389 

[TRAIN] Epoch[1](10136/114412); Loss: 0.081521; Backpropagation: 0.2928 sec; Batch: 2.0783 sec
0.1437 0.1269 0.0982 0.0881 0.0829 0.0787 0.0761 0.0728 0.0706 0.0696 0.0679 0.0670 0.0663 0.0656 0.0651 0.0648 

[TRAIN] Epoch[1](10137/114412); Loss: 0.070864; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.1415 0.1225 0.0875 0.0783 0.0712 0.0659 0.0632 0.0613 0.0587 0.0572 0.0560 0.0553 0.0546 0.0541 0.0535 0.0531 

[TRAIN] Epoch[1](10138/114412); Loss: 0.062179; Backpropagation: 0.2908 sec; Batch: 2.0767 sec
0.1599 0.1408 0.0847 0.0633 0.0559 0.0518 0.0501 0.0474 0.0454 0.0444 0.0434 0.0425 0.0420 0.0414 0.0410 0.0408 

[TRAIN] Epoch[1](10139/114412); Loss: 0.064449; Backpropagation: 0.2911 sec; Batch: 2.1139 sec
0.1096 0.0972 0.0890 0.0736 0.0651 0.0608 0.0582 0.0568 0.0552 0.0543 0.0532 0.0524 0.0519 0.0515 0.0514 0.0511 

[TRAIN] Epoch[1](10140/114412); Loss: 0.060028; Backpropagation: 0.2912 sec; Batch: 2.1212 sec
0.1195 0.1103 0.0855 0.0731 0.0632 0.0558 0.0520 0.0499 0.0475 0.0457 0.0446 0.0437 0.0433 0.0426 0.0422 0.0415 

[TRAIN] Epoch[1](10141/114412); Loss: 0.117438; Backpropagation: 0.2910 sec; Batch: 2.0772 sec
0.1757 0.1631 0.1428 0.1290 0.1217 0.1165 0.1117 0.1092 0.1058 0.1042 0.1027 0.1009 0.1000 0.0993 0.0986 0.0977 

[TRAIN] Epoch[1](10142/114412); Loss: 0.066371; Backpropagation: 0.2913 sec; Batch: 2.0801 sec
0.1340 0.1220 0.0919 0.0729 0.0639 0.0611 0.0578 0.0549 0.0534 0.0521 0.0511 0.0503 0.0495 0.0494 0.0490 0.0487 

[TRAIN] Epoch[1](10143/114412); Loss: 0.082045; Backpropagation: 0.2928 sec; Batch: 2.0855 sec
0.1580 0.1386 0.1094 0.0909 0.0840 0.0761 0.0728 0.0693 0.0678 0.0662 0.0649 0.0641 0.0634 0.0629 0.0625 0.0620 

[TRAIN] Epoch[1](10144/114412); Loss: 0.077988; Backpropagation: 0.2951 sec; Batch: 2.1193 sec
0.1376 0.1204 0.0982 0.0865 0.0808 0.0734 0.0708 0.0684 0.0670 0.0654 0.0644 0.0637 0.0634 0.0630 0.0625 0.0622 

[TRAIN] Epoch[1](10145/114412); Loss: 0.085816; Backpropagation: 0.2926 sec; Batch: 2.1186 sec
0.1646 0.1336 0.1071 0.0984 0.0904 0.0859 0.0802 0.0753 0.0712 0.0695 0.0680 0.0669 0.0662 0.0657 0.0652 0.0648 

[TRAIN] Epoch[1](10146/114412); Loss: 0.078066; Backpropagation: 0.2954 sec; Batch: 2.1364 sec
0.1337 0.1182 0.1002 0.0872 0.0793 0.0741 0.0709 0.0694 0.0677 0.0663 0.0653 0.0644 0.0638 0.0633 0.0629 0.0625 

[TRAIN] Epoch[1](10147/114412); Loss: 0.072271; Backpropagation: 0.2931 sec; Batch: 2.1160 sec
0.1413 0.1256 0.0975 0.0818 0.0707 0.0678 0.0641 0.0614 0.0593 0.0577 0.0566 0.0556 0.0547 0.0543 0.0540 0.0538 

[TRAIN] Epoch[1](10148/114412); Loss: 0.066746; Backpropagation: 0.2907 sec; Batch: 2.1141 sec
0.1234 0.1106 0.0862 0.0748 0.0684 0.0638 0.0614 0.0581 0.0566 0.0547 0.0536 0.0527 0.0518 0.0511 0.0506 0.0501 

[TRAIN] Epoch[1](10149/114412); Loss: 0.078007; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1535 0.1393 0.1041 0.0892 0.0803 0.0721 0.0681 0.0657 0.0638 0.0616 0.0604 0.0593 0.0584 0.0577 0.0574 0.0572 

[TRAIN] Epoch[1](10150/114412); Loss: 0.104029; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1770 0.1564 0.1292 0.1152 0.1055 0.0987 0.0950 0.0926 0.0905 0.0890 0.0878 0.0869 0.0859 0.0854 0.0849 0.0844 

[TRAIN] Epoch[1](10151/114412); Loss: 0.070730; Backpropagation: 0.2908 sec; Batch: 2.0769 sec
0.1376 0.1224 0.0897 0.0772 0.0738 0.0683 0.0646 0.0619 0.0594 0.0570 0.0555 0.0543 0.0532 0.0528 0.0522 0.0515 

[TRAIN] Epoch[1](10152/114412); Loss: 0.059208; Backpropagation: 0.2910 sec; Batch: 2.0820 sec
0.1182 0.1017 0.0716 0.0661 0.0604 0.0545 0.0522 0.0501 0.0489 0.0478 0.0469 0.0463 0.0460 0.0457 0.0455 0.0454 

[TRAIN] Epoch[1](10153/114412); Loss: 0.078046; Backpropagation: 0.2929 sec; Batch: 2.1196 sec
0.1404 0.1231 0.1004 0.0880 0.0787 0.0737 0.0707 0.0684 0.0667 0.0654 0.0640 0.0630 0.0622 0.0617 0.0612 0.0610 

[TRAIN] Epoch[1](10154/114412); Loss: 0.088732; Backpropagation: 0.2946 sec; Batch: 2.1193 sec
0.1382 0.1265 0.1072 0.0959 0.0898 0.0860 0.0831 0.0812 0.0795 0.0781 0.0771 0.0763 0.0758 0.0753 0.0750 0.0748 

[TRAIN] Epoch[1](10155/114412); Loss: 0.074931; Backpropagation: 0.2958 sec; Batch: 2.1304 sec
0.1447 0.1276 0.0888 0.0810 0.0736 0.0702 0.0671 0.0646 0.0629 0.0617 0.0605 0.0599 0.0596 0.0591 0.0588 0.0587 

[TRAIN] Epoch[1](10156/114412); Loss: 0.074041; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1649 0.1488 0.0909 0.0779 0.0718 0.0659 0.0621 0.0597 0.0580 0.0567 0.0560 0.0553 0.0549 0.0542 0.0539 0.0537 

[TRAIN] Epoch[1](10157/114412); Loss: 0.060489; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.1276 0.1087 0.0749 0.0655 0.0607 0.0560 0.0524 0.0507 0.0488 0.0478 0.0470 0.0464 0.0459 0.0455 0.0451 0.0449 

[TRAIN] Epoch[1](10158/114412); Loss: 0.084464; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1633 0.1369 0.1063 0.0940 0.0852 0.0797 0.0762 0.0732 0.0709 0.0694 0.0681 0.0672 0.0661 0.0655 0.0650 0.0643 

[TRAIN] Epoch[1](10159/114412); Loss: 0.055977; Backpropagation: 0.2908 sec; Batch: 2.1118 sec
0.0956 0.0820 0.0799 0.0661 0.0609 0.0544 0.0515 0.0491 0.0475 0.0460 0.0449 0.0442 0.0440 0.0436 0.0431 0.0428 

[TRAIN] Epoch[1](10160/114412); Loss: 0.078484; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1679 0.1486 0.1074 0.0903 0.0756 0.0691 0.0657 0.0632 0.0610 0.0596 0.0590 0.0585 0.0581 0.0578 0.0572 0.0569 

[TRAIN] Epoch[1](10161/114412); Loss: 0.079474; Backpropagation: 0.2914 sec; Batch: 2.1175 sec
0.1641 0.1516 0.1025 0.0859 0.0756 0.0703 0.0681 0.0655 0.0640 0.0627 0.0615 0.0610 0.0603 0.0599 0.0594 0.0593 

[TRAIN] Epoch[1](10162/114412); Loss: 0.081690; Backpropagation: 0.2916 sec; Batch: 2.1189 sec
0.1579 0.1438 0.1066 0.0955 0.0811 0.0760 0.0712 0.0683 0.0665 0.0650 0.0641 0.0632 0.0626 0.0621 0.0617 0.0614 

[TRAIN] Epoch[1](10163/114412); Loss: 0.071437; Backpropagation: 0.2907 sec; Batch: 2.0878 sec
0.1407 0.1206 0.0906 0.0827 0.0741 0.0695 0.0640 0.0617 0.0591 0.0575 0.0561 0.0550 0.0540 0.0532 0.0524 0.0517 

[TRAIN] Epoch[1](10164/114412); Loss: 0.078366; Backpropagation: 0.2913 sec; Batch: 2.1170 sec
0.1624 0.1464 0.1082 0.0955 0.0805 0.0702 0.0669 0.0649 0.0618 0.0603 0.0582 0.0572 0.0564 0.0556 0.0549 0.0545 

[TRAIN] Epoch[1](10165/114412); Loss: 0.064157; Backpropagation: 0.2909 sec; Batch: 2.1164 sec
0.1191 0.1056 0.0785 0.0724 0.0667 0.0626 0.0593 0.0563 0.0544 0.0528 0.0515 0.0507 0.0498 0.0494 0.0489 0.0485 

[TRAIN] Epoch[1](10166/114412); Loss: 0.065118; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1551 0.1288 0.1031 0.0818 0.0667 0.0593 0.0549 0.0518 0.0473 0.0458 0.0440 0.0423 0.0413 0.0404 0.0398 0.0394 

[TRAIN] Epoch[1](10167/114412); Loss: 0.080569; Backpropagation: 0.2914 sec; Batch: 2.1192 sec
0.1440 0.1337 0.1040 0.0919 0.0822 0.0774 0.0735 0.0708 0.0684 0.0668 0.0652 0.0639 0.0630 0.0622 0.0614 0.0607 

[TRAIN] Epoch[1](10168/114412); Loss: 0.059529; Backpropagation: 0.2905 sec; Batch: 2.1159 sec
0.1051 0.0962 0.0733 0.0683 0.0610 0.0572 0.0545 0.0524 0.0508 0.0497 0.0488 0.0481 0.0473 0.0470 0.0466 0.0464 

[TRAIN] Epoch[1](10169/114412); Loss: 0.076797; Backpropagation: 0.2905 sec; Batch: 2.1134 sec
0.1930 0.1827 0.1071 0.0799 0.0719 0.0652 0.0607 0.0577 0.0557 0.0541 0.0522 0.0511 0.0503 0.0495 0.0490 0.0486 

[TRAIN] Epoch[1](10170/114412); Loss: 0.070590; Backpropagation: 0.2911 sec; Batch: 2.1262 sec
0.1744 0.1597 0.0994 0.0820 0.0688 0.0613 0.0556 0.0524 0.0500 0.0486 0.0476 0.0468 0.0464 0.0458 0.0454 0.0451 

[TRAIN] Epoch[1](10171/114412); Loss: 0.074569; Backpropagation: 0.2907 sec; Batch: 2.1173 sec
0.1608 0.1540 0.1141 0.0935 0.0746 0.0621 0.0592 0.0578 0.0558 0.0541 0.0529 0.0520 0.0514 0.0507 0.0503 0.0498 

[TRAIN] Epoch[1](10172/114412); Loss: 0.063252; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1182 0.1120 0.0780 0.0716 0.0634 0.0603 0.0573 0.0539 0.0524 0.0511 0.0502 0.0497 0.0491 0.0486 0.0483 0.0480 

[TRAIN] Epoch[1](10173/114412); Loss: 0.071148; Backpropagation: 0.2951 sec; Batch: 2.1503 sec
0.1413 0.1176 0.0893 0.0787 0.0711 0.0672 0.0632 0.0606 0.0590 0.0577 0.0568 0.0562 0.0555 0.0550 0.0547 0.0544 

[TRAIN] Epoch[1](10174/114412); Loss: 0.073963; Backpropagation: 0.2932 sec; Batch: 2.1192 sec
0.1430 0.1300 0.1016 0.0872 0.0754 0.0686 0.0650 0.0616 0.0597 0.0583 0.0573 0.0564 0.0555 0.0550 0.0546 0.0542 

[TRAIN] Epoch[1](10175/114412); Loss: 0.071595; Backpropagation: 0.2912 sec; Batch: 2.1193 sec
0.1385 0.1173 0.0839 0.0763 0.0720 0.0658 0.0635 0.0617 0.0603 0.0595 0.0587 0.0582 0.0578 0.0576 0.0574 0.0572 

[TRAIN] Epoch[1](10176/114412); Loss: 0.058865; Backpropagation: 0.2912 sec; Batch: 2.1209 sec
0.1197 0.1128 0.0776 0.0650 0.0575 0.0539 0.0511 0.0489 0.0473 0.0457 0.0447 0.0441 0.0437 0.0434 0.0432 0.0432 

[TRAIN] Epoch[1](10177/114412); Loss: 0.076023; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1297 0.1230 0.0969 0.0870 0.0794 0.0731 0.0696 0.0664 0.0644 0.0631 0.0620 0.0613 0.0608 0.0603 0.0599 0.0596 

[TRAIN] Epoch[1](10178/114412); Loss: 0.059945; Backpropagation: 0.2914 sec; Batch: 2.0778 sec
0.1225 0.1179 0.0768 0.0661 0.0593 0.0539 0.0514 0.0491 0.0477 0.0466 0.0457 0.0451 0.0447 0.0443 0.0441 0.0440 

[TRAIN] Epoch[1](10179/114412); Loss: 0.059262; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1197 0.1055 0.0815 0.0679 0.0597 0.0554 0.0525 0.0498 0.0479 0.0467 0.0455 0.0443 0.0436 0.0430 0.0426 0.0424 

[TRAIN] Epoch[1](10180/114412); Loss: 0.083532; Backpropagation: 0.2910 sec; Batch: 2.0772 sec
0.1529 0.1463 0.0973 0.0874 0.0850 0.0786 0.0747 0.0722 0.0708 0.0692 0.0682 0.0677 0.0671 0.0668 0.0663 0.0662 

[TRAIN] Epoch[1](10181/114412); Loss: 0.068108; Backpropagation: 0.2914 sec; Batch: 2.0781 sec
0.1454 0.1314 0.0894 0.0760 0.0673 0.0648 0.0608 0.0571 0.0541 0.0524 0.0508 0.0497 0.0487 0.0479 0.0473 0.0467 

[TRAIN] Epoch[1](10182/114412); Loss: 0.069498; Backpropagation: 0.2902 sec; Batch: 2.1186 sec
0.1183 0.1103 0.0857 0.0788 0.0729 0.0678 0.0646 0.0621 0.0604 0.0586 0.0572 0.0563 0.0555 0.0551 0.0544 0.0540 

[TRAIN] Epoch[1](10183/114412); Loss: 0.066505; Backpropagation: 0.2931 sec; Batch: 2.1037 sec
0.1354 0.1228 0.0877 0.0767 0.0674 0.0627 0.0583 0.0555 0.0533 0.0518 0.0506 0.0496 0.0489 0.0484 0.0477 0.0472 

[TRAIN] Epoch[1](10184/114412); Loss: 0.082272; Backpropagation: 0.2928 sec; Batch: 2.1311 sec
0.1760 0.1590 0.1109 0.0923 0.0831 0.0756 0.0708 0.0671 0.0641 0.0622 0.0608 0.0597 0.0592 0.0588 0.0585 0.0582 

[TRAIN] Epoch[1](10185/114412); Loss: 0.064605; Backpropagation: 0.2933 sec; Batch: 2.1184 sec
0.1216 0.1080 0.0811 0.0721 0.0656 0.0620 0.0587 0.0559 0.0540 0.0530 0.0519 0.0511 0.0503 0.0498 0.0494 0.0492 

[TRAIN] Epoch[1](10186/114412); Loss: 0.086711; Backpropagation: 0.2908 sec; Batch: 2.1153 sec
0.1332 0.1222 0.1089 0.0956 0.0883 0.0835 0.0808 0.0788 0.0772 0.0763 0.0753 0.0745 0.0739 0.0732 0.0730 0.0726 

[TRAIN] Epoch[1](10187/114412); Loss: 0.085786; Backpropagation: 0.2912 sec; Batch: 2.1023 sec
0.1571 0.1381 0.1071 0.0983 0.0850 0.0806 0.0770 0.0744 0.0727 0.0714 0.0703 0.0694 0.0685 0.0680 0.0675 0.0672 

[TRAIN] Epoch[1](10188/114412); Loss: 0.088745; Backpropagation: 0.2915 sec; Batch: 2.1200 sec
0.1610 0.1473 0.1170 0.1036 0.0900 0.0835 0.0792 0.0765 0.0742 0.0724 0.0711 0.0700 0.0694 0.0687 0.0682 0.0678 

[TRAIN] Epoch[1](10189/114412); Loss: 0.078105; Backpropagation: 0.2912 sec; Batch: 2.1215 sec
0.1417 0.1222 0.0954 0.0899 0.0830 0.0744 0.0699 0.0674 0.0659 0.0649 0.0635 0.0629 0.0626 0.0623 0.0619 0.0617 

[TRAIN] Epoch[1](10190/114412); Loss: 0.080153; Backpropagation: 0.2915 sec; Batch: 2.1185 sec
0.1337 0.1229 0.0973 0.0896 0.0851 0.0793 0.0753 0.0722 0.0703 0.0680 0.0668 0.0659 0.0650 0.0643 0.0637 0.0632 

[TRAIN] Epoch[1](10191/114412); Loss: 0.080548; Backpropagation: 0.2911 sec; Batch: 2.1165 sec
0.1401 0.1310 0.0926 0.0863 0.0789 0.0759 0.0732 0.0713 0.0702 0.0689 0.0681 0.0676 0.0668 0.0665 0.0659 0.0655 

[TRAIN] Epoch[1](10192/114412); Loss: 0.090936; Backpropagation: 0.2907 sec; Batch: 2.0766 sec
0.1777 0.1679 0.1276 0.1112 0.0920 0.0804 0.0762 0.0732 0.0720 0.0701 0.0693 0.0685 0.0679 0.0674 0.0670 0.0666 

[TRAIN] Epoch[1](10193/114412); Loss: 0.071085; Backpropagation: 0.2931 sec; Batch: 2.0802 sec
0.1260 0.1128 0.0836 0.0729 0.0703 0.0669 0.0649 0.0633 0.0618 0.0607 0.0600 0.0596 0.0592 0.0588 0.0584 0.0582 

[TRAIN] Epoch[1](10194/114412); Loss: 0.085658; Backpropagation: 0.2915 sec; Batch: 2.0783 sec
0.1704 0.1428 0.1058 0.0945 0.0843 0.0795 0.0764 0.0735 0.0714 0.0702 0.0689 0.0679 0.0671 0.0664 0.0658 0.0655 

[TRAIN] Epoch[1](10195/114412); Loss: 0.081328; Backpropagation: 0.2931 sec; Batch: 2.1198 sec
0.1521 0.1397 0.1062 0.0938 0.0839 0.0766 0.0718 0.0689 0.0672 0.0660 0.0646 0.0639 0.0627 0.0620 0.0613 0.0607 

[TRAIN] Epoch[1](10196/114412); Loss: 0.090022; Backpropagation: 0.2924 sec; Batch: 2.1171 sec
0.1543 0.1381 0.1109 0.0993 0.0908 0.0856 0.0823 0.0799 0.0785 0.0768 0.0758 0.0748 0.0740 0.0735 0.0732 0.0727 

[TRAIN] Epoch[1](10197/114412); Loss: 0.078492; Backpropagation: 0.2908 sec; Batch: 2.1121 sec
0.1857 0.1669 0.1054 0.0866 0.0730 0.0705 0.0653 0.0622 0.0594 0.0575 0.0560 0.0548 0.0540 0.0535 0.0528 0.0523 

[TRAIN] Epoch[1](10198/114412); Loss: 0.092789; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1858 0.1740 0.1215 0.1002 0.0855 0.0820 0.0779 0.0762 0.0749 0.0738 0.0731 0.0726 0.0721 0.0719 0.0716 0.0714 

[TRAIN] Epoch[1](10199/114412); Loss: 0.072214; Backpropagation: 0.2906 sec; Batch: 2.0803 sec
0.1425 0.1320 0.0865 0.0780 0.0713 0.0658 0.0635 0.0613 0.0596 0.0584 0.0572 0.0567 0.0562 0.0558 0.0555 0.0552 

[TRAIN] Epoch[1](10200/114412); Loss: 0.061217; Backpropagation: 0.2933 sec; Batch: 2.1201 sec
0.1256 0.1121 0.0786 0.0681 0.0628 0.0572 0.0531 0.0511 0.0492 0.0478 0.0470 0.0461 0.0455 0.0453 0.0450 0.0450 

[TRAIN] Epoch[1](10201/114412); Loss: 0.090271; Backpropagation: 0.2911 sec; Batch: 2.0795 sec
0.1695 0.1573 0.1263 0.1060 0.0946 0.0813 0.0795 0.0754 0.0728 0.0713 0.0696 0.0693 0.0685 0.0681 0.0678 0.0672 

[TRAIN] Epoch[1](10202/114412); Loss: 0.078355; Backpropagation: 0.2951 sec; Batch: 2.0807 sec
0.1576 0.1378 0.0999 0.0831 0.0794 0.0722 0.0700 0.0666 0.0647 0.0628 0.0612 0.0604 0.0599 0.0595 0.0594 0.0591 

[TRAIN] Epoch[1](10203/114412); Loss: 0.079046; Backpropagation: 0.2937 sec; Batch: 2.0795 sec
0.1461 0.1340 0.0985 0.0898 0.0832 0.0764 0.0730 0.0691 0.0656 0.0648 0.0632 0.0615 0.0609 0.0602 0.0594 0.0591 

[TRAIN] Epoch[1](10204/114412); Loss: 0.053846; Backpropagation: 0.2913 sec; Batch: 2.0775 sec
0.1229 0.1131 0.0663 0.0557 0.0517 0.0481 0.0451 0.0436 0.0416 0.0404 0.0397 0.0392 0.0387 0.0386 0.0384 0.0385 

[TRAIN] Epoch[1](10205/114412); Loss: 0.072682; Backpropagation: 0.2904 sec; Batch: 2.1147 sec
0.1658 0.1419 0.0821 0.0729 0.0729 0.0665 0.0637 0.0607 0.0586 0.0568 0.0555 0.0544 0.0536 0.0531 0.0524 0.0520 

[TRAIN] Epoch[1](10206/114412); Loss: 0.075046; Backpropagation: 0.2912 sec; Batch: 2.1145 sec
0.1281 0.1127 0.0943 0.0860 0.0787 0.0741 0.0705 0.0667 0.0648 0.0635 0.0621 0.0610 0.0604 0.0597 0.0593 0.0590 

[TRAIN] Epoch[1](10207/114412); Loss: 0.055101; Backpropagation: 0.2907 sec; Batch: 2.1173 sec
0.1478 0.1414 0.0705 0.0582 0.0508 0.0461 0.0427 0.0397 0.0384 0.0368 0.0359 0.0355 0.0348 0.0345 0.0342 0.0341 

[TRAIN] Epoch[1](10208/114412); Loss: 0.106929; Backpropagation: 0.2914 sec; Batch: 2.1757 sec
0.1767 0.1631 0.1250 0.1107 0.1053 0.1010 0.0986 0.0968 0.0950 0.0938 0.0926 0.0916 0.0909 0.0903 0.0900 0.0895 

[TRAIN] Epoch[1](10209/114412); Loss: 0.094695; Backpropagation: 0.2913 sec; Batch: 2.1151 sec
0.1515 0.1424 0.1144 0.1026 0.0952 0.0921 0.0890 0.0865 0.0844 0.0823 0.0812 0.0801 0.0791 0.0785 0.0779 0.0778 

[TRAIN] Epoch[1](10210/114412); Loss: 0.073188; Backpropagation: 0.2931 sec; Batch: 2.1193 sec
0.1547 0.1365 0.0832 0.0799 0.0738 0.0689 0.0633 0.0606 0.0594 0.0580 0.0568 0.0561 0.0555 0.0550 0.0548 0.0545 

[TRAIN] Epoch[1](10211/114412); Loss: 0.060451; Backpropagation: 0.2926 sec; Batch: 2.1164 sec
0.1063 0.0997 0.0897 0.0742 0.0663 0.0566 0.0536 0.0504 0.0490 0.0478 0.0469 0.0461 0.0456 0.0453 0.0449 0.0447 

[TRAIN] Epoch[1](10212/114412); Loss: 0.071339; Backpropagation: 0.2912 sec; Batch: 2.1204 sec
0.1348 0.1273 0.0921 0.0802 0.0693 0.0658 0.0625 0.0597 0.0583 0.0573 0.0565 0.0561 0.0558 0.0555 0.0553 0.0550 

[TRAIN] Epoch[1](10213/114412); Loss: 0.079575; Backpropagation: 0.2914 sec; Batch: 2.1136 sec
0.1458 0.1316 0.0916 0.0848 0.0793 0.0753 0.0726 0.0701 0.0682 0.0667 0.0659 0.0652 0.0647 0.0642 0.0639 0.0635 

[TRAIN] Epoch[1](10214/114412); Loss: 0.070107; Backpropagation: 0.2928 sec; Batch: 2.1271 sec
0.1523 0.1363 0.0873 0.0765 0.0675 0.0632 0.0594 0.0570 0.0553 0.0542 0.0534 0.0527 0.0521 0.0518 0.0514 0.0512 

[TRAIN] Epoch[1](10215/114412); Loss: 0.069718; Backpropagation: 0.2913 sec; Batch: 2.1150 sec
0.1501 0.1243 0.0847 0.0736 0.0658 0.0633 0.0612 0.0588 0.0574 0.0552 0.0547 0.0541 0.0536 0.0533 0.0529 0.0527 

[TRAIN] Epoch[1](10216/114412); Loss: 0.085630; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1463 0.1349 0.1153 0.1030 0.0927 0.0844 0.0798 0.0755 0.0725 0.0705 0.0682 0.0673 0.0662 0.0650 0.0646 0.0638 

[TRAIN] Epoch[1](10217/114412); Loss: 0.075697; Backpropagation: 0.2905 sec; Batch: 2.1201 sec
0.1351 0.1155 0.0922 0.0825 0.0753 0.0720 0.0697 0.0674 0.0656 0.0644 0.0634 0.0626 0.0620 0.0615 0.0611 0.0608 

[TRAIN] Epoch[1](10218/114412); Loss: 0.057953; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1262 0.1157 0.0687 0.0635 0.0564 0.0527 0.0503 0.0477 0.0462 0.0449 0.0439 0.0434 0.0426 0.0421 0.0416 0.0414 

[TRAIN] Epoch[1](10219/114412); Loss: 0.094905; Backpropagation: 0.2909 sec; Batch: 2.1138 sec
0.1961 0.1757 0.1247 0.0998 0.0864 0.0853 0.0821 0.0800 0.0777 0.0760 0.0743 0.0734 0.0725 0.0720 0.0715 0.0710 

[TRAIN] Epoch[1](10220/114412); Loss: 0.074136; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1281 0.1153 0.0933 0.0868 0.0792 0.0743 0.0700 0.0665 0.0637 0.0618 0.0606 0.0590 0.0580 0.0574 0.0564 0.0559 

[TRAIN] Epoch[1](10221/114412); Loss: 0.073876; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1563 0.1415 0.0987 0.0825 0.0743 0.0694 0.0630 0.0612 0.0591 0.0573 0.0558 0.0542 0.0533 0.0524 0.0517 0.0513 

[TRAIN] Epoch[1](10222/114412); Loss: 0.074132; Backpropagation: 0.2915 sec; Batch: 2.1130 sec
0.1473 0.1345 0.0957 0.0862 0.0754 0.0691 0.0651 0.0621 0.0600 0.0586 0.0569 0.0562 0.0554 0.0549 0.0545 0.0541 

[TRAIN] Epoch[1](10223/114412); Loss: 0.070751; Backpropagation: 0.2909 sec; Batch: 2.1132 sec
0.1276 0.1151 0.0871 0.0789 0.0702 0.0658 0.0635 0.0612 0.0602 0.0592 0.0584 0.0577 0.0573 0.0569 0.0566 0.0563 

[TRAIN] Epoch[1](10224/114412); Loss: 0.071606; Backpropagation: 0.2911 sec; Batch: 2.1132 sec
0.1433 0.1282 0.0921 0.0815 0.0732 0.0666 0.0629 0.0602 0.0582 0.0567 0.0553 0.0545 0.0539 0.0534 0.0529 0.0527 

[TRAIN] Epoch[1](10225/114412); Loss: 0.073104; Backpropagation: 0.2906 sec; Batch: 2.1140 sec
0.1455 0.1333 0.0919 0.0794 0.0714 0.0673 0.0648 0.0619 0.0595 0.0586 0.0573 0.0564 0.0560 0.0557 0.0554 0.0553 

[TRAIN] Epoch[1](10226/114412); Loss: 0.074325; Backpropagation: 0.2907 sec; Batch: 2.1166 sec
0.1455 0.1242 0.1068 0.0940 0.0846 0.0769 0.0691 0.0635 0.0602 0.0569 0.0545 0.0532 0.0513 0.0503 0.0494 0.0488 

[TRAIN] Epoch[1](10227/114412); Loss: 0.067931; Backpropagation: 0.2929 sec; Batch: 2.1159 sec
0.1416 0.1306 0.0866 0.0772 0.0684 0.0625 0.0579 0.0554 0.0539 0.0523 0.0514 0.0508 0.0501 0.0497 0.0495 0.0492 

[TRAIN] Epoch[1](10228/114412); Loss: 0.099316; Backpropagation: 0.2909 sec; Batch: 2.1190 sec
0.1710 0.1549 0.1244 0.1095 0.1015 0.0958 0.0929 0.0900 0.0865 0.0851 0.0833 0.0807 0.0799 0.0790 0.0776 0.0771 

[TRAIN] Epoch[1](10229/114412); Loss: 0.112366; Backpropagation: 0.2931 sec; Batch: 2.1195 sec
0.2383 0.2161 0.1474 0.1161 0.1052 0.0970 0.0934 0.0912 0.0893 0.0882 0.0876 0.0869 0.0863 0.0854 0.0849 0.0844 

[TRAIN] Epoch[1](10230/114412); Loss: 0.050055; Backpropagation: 0.2927 sec; Batch: 2.0791 sec
0.1260 0.1166 0.0608 0.0535 0.0470 0.0437 0.0406 0.0384 0.0365 0.0353 0.0347 0.0339 0.0338 0.0336 0.0334 0.0332 

[TRAIN] Epoch[1](10231/114412); Loss: 0.087900; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1765 0.1576 0.1227 0.1019 0.0861 0.0794 0.0753 0.0727 0.0702 0.0686 0.0673 0.0665 0.0660 0.0655 0.0652 0.0649 

[TRAIN] Epoch[1](10232/114412); Loss: 0.062402; Backpropagation: 0.2931 sec; Batch: 2.1189 sec
0.1438 0.1338 0.0931 0.0826 0.0657 0.0570 0.0499 0.0462 0.0444 0.0421 0.0414 0.0407 0.0401 0.0394 0.0392 0.0390 

[TRAIN] Epoch[1](10233/114412); Loss: 0.065978; Backpropagation: 0.2930 sec; Batch: 2.0785 sec
0.1518 0.1420 0.0952 0.0801 0.0682 0.0594 0.0574 0.0513 0.0483 0.0468 0.0449 0.0436 0.0427 0.0418 0.0413 0.0409 

[TRAIN] Epoch[1](10234/114412); Loss: 0.074028; Backpropagation: 0.2931 sec; Batch: 2.1172 sec
0.1498 0.1415 0.0880 0.0747 0.0690 0.0665 0.0649 0.0628 0.0614 0.0600 0.0590 0.0582 0.0577 0.0573 0.0569 0.0567 

[TRAIN] Epoch[1](10235/114412); Loss: 0.072235; Backpropagation: 0.2931 sec; Batch: 2.1205 sec
0.1603 0.1388 0.1074 0.0906 0.0780 0.0672 0.0612 0.0575 0.0542 0.0519 0.0503 0.0492 0.0482 0.0474 0.0469 0.0465 

[TRAIN] Epoch[1](10236/114412); Loss: 0.075729; Backpropagation: 0.2910 sec; Batch: 2.0771 sec
0.1531 0.1351 0.0985 0.0834 0.0754 0.0697 0.0661 0.0633 0.0614 0.0600 0.0590 0.0582 0.0577 0.0572 0.0569 0.0565 

[TRAIN] Epoch[1](10237/114412); Loss: 0.092845; Backpropagation: 0.2911 sec; Batch: 2.1155 sec
0.1445 0.1328 0.1153 0.1073 0.0959 0.0920 0.0870 0.0849 0.0826 0.0806 0.0798 0.0783 0.0773 0.0764 0.0757 0.0751 

[TRAIN] Epoch[1](10238/114412); Loss: 0.073547; Backpropagation: 0.2927 sec; Batch: 2.1115 sec
0.1516 0.1404 0.1030 0.0821 0.0680 0.0652 0.0628 0.0603 0.0587 0.0569 0.0561 0.0553 0.0546 0.0542 0.0538 0.0535 

[TRAIN] Epoch[1](10239/114412); Loss: 0.081837; Backpropagation: 0.2912 sec; Batch: 2.1197 sec
0.1443 0.1281 0.0954 0.0879 0.0811 0.0773 0.0755 0.0730 0.0712 0.0701 0.0689 0.0681 0.0677 0.0672 0.0669 0.0667 

[TRAIN] Epoch[1](10240/114412); Loss: 0.069951; Backpropagation: 0.2908 sec; Batch: 2.0768 sec
0.1471 0.1386 0.0957 0.0758 0.0678 0.0630 0.0597 0.0571 0.0551 0.0537 0.0528 0.0517 0.0511 0.0504 0.0500 0.0497 

[TRAIN] Epoch[1](10241/114412); Loss: 0.076234; Backpropagation: 0.2930 sec; Batch: 2.0784 sec
0.1422 0.1314 0.0940 0.0853 0.0771 0.0727 0.0690 0.0658 0.0641 0.0624 0.0611 0.0603 0.0594 0.0588 0.0583 0.0579 

[TRAIN] Epoch[1](10242/114412); Loss: 0.079493; Backpropagation: 0.2931 sec; Batch: 2.1231 sec
0.1449 0.1305 0.0940 0.0842 0.0810 0.0757 0.0736 0.0701 0.0680 0.0666 0.0653 0.0646 0.0640 0.0634 0.0631 0.0629 

[TRAIN] Epoch[1](10243/114412); Loss: 0.093870; Backpropagation: 0.2910 sec; Batch: 2.0768 sec
0.1615 0.1541 0.1226 0.1098 0.0972 0.0912 0.0865 0.0833 0.0801 0.0781 0.0760 0.0745 0.0735 0.0720 0.0711 0.0707 

[TRAIN] Epoch[1](10244/114412); Loss: 0.056077; Backpropagation: 0.2954 sec; Batch: 2.1241 sec
0.1226 0.1131 0.0724 0.0642 0.0566 0.0513 0.0476 0.0458 0.0434 0.0421 0.0412 0.0404 0.0398 0.0394 0.0390 0.0385 

[TRAIN] Epoch[1](10245/114412); Loss: 0.067460; Backpropagation: 0.2932 sec; Batch: 2.1154 sec
0.1318 0.1210 0.0904 0.0762 0.0685 0.0618 0.0590 0.0567 0.0545 0.0536 0.0524 0.0516 0.0510 0.0506 0.0502 0.0501 

[TRAIN] Epoch[1](10246/114412); Loss: 0.069152; Backpropagation: 0.2953 sec; Batch: 2.1224 sec
0.1215 0.1038 0.0859 0.0787 0.0712 0.0667 0.0646 0.0614 0.0599 0.0583 0.0573 0.0563 0.0557 0.0552 0.0549 0.0548 

[TRAIN] Epoch[1](10247/114412); Loss: 0.069354; Backpropagation: 0.2924 sec; Batch: 2.1150 sec
0.1317 0.1151 0.0850 0.0780 0.0699 0.0660 0.0624 0.0598 0.0578 0.0567 0.0558 0.0551 0.0545 0.0542 0.0540 0.0537 

[TRAIN] Epoch[1](10248/114412); Loss: 0.066144; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1261 0.1169 0.0909 0.0706 0.0647 0.0608 0.0582 0.0567 0.0545 0.0534 0.0522 0.0514 0.0508 0.0506 0.0504 0.0500 

[TRAIN] Epoch[1](10249/114412); Loss: 0.071183; Backpropagation: 0.2930 sec; Batch: 2.1154 sec
0.1445 0.1368 0.0862 0.0763 0.0724 0.0664 0.0630 0.0595 0.0577 0.0560 0.0549 0.0540 0.0532 0.0531 0.0526 0.0523 

[TRAIN] Epoch[1](10250/114412); Loss: 0.075528; Backpropagation: 0.2932 sec; Batch: 2.0790 sec
0.1631 0.1515 0.1086 0.0859 0.0704 0.0667 0.0634 0.0612 0.0590 0.0565 0.0557 0.0546 0.0538 0.0532 0.0527 0.0522 

[TRAIN] Epoch[1](10251/114412); Loss: 0.091392; Backpropagation: 0.2911 sec; Batch: 2.0765 sec
0.1485 0.1351 0.1117 0.1009 0.0933 0.0885 0.0860 0.0829 0.0810 0.0790 0.0779 0.0766 0.0759 0.0754 0.0750 0.0744 

[TRAIN] Epoch[1](10252/114412); Loss: 0.072681; Backpropagation: 0.2908 sec; Batch: 2.0781 sec
0.1278 0.1149 0.0935 0.0769 0.0732 0.0686 0.0659 0.0638 0.0624 0.0613 0.0602 0.0597 0.0591 0.0588 0.0585 0.0584 

[TRAIN] Epoch[1](10253/114412); Loss: 0.065305; Backpropagation: 0.2908 sec; Batch: 2.0766 sec
0.1818 0.1470 0.0999 0.0653 0.0605 0.0571 0.0527 0.0497 0.0453 0.0435 0.0423 0.0410 0.0403 0.0398 0.0395 0.0392 

[TRAIN] Epoch[1](10254/114412); Loss: 0.081146; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1515 0.1408 0.1002 0.0879 0.0797 0.0753 0.0721 0.0695 0.0680 0.0671 0.0660 0.0652 0.0645 0.0640 0.0634 0.0631 

[TRAIN] Epoch[1](10255/114412); Loss: 0.068023; Backpropagation: 0.2911 sec; Batch: 2.0771 sec
0.1335 0.1294 0.0909 0.0847 0.0717 0.0663 0.0613 0.0567 0.0535 0.0514 0.0498 0.0490 0.0483 0.0476 0.0472 0.0470 

[TRAIN] Epoch[1](10256/114412); Loss: 0.085865; Backpropagation: 0.2953 sec; Batch: 2.1219 sec
0.1554 0.1429 0.1111 0.0980 0.0884 0.0828 0.0775 0.0745 0.0722 0.0706 0.0692 0.0679 0.0669 0.0662 0.0654 0.0649 

[TRAIN] Epoch[1](10257/114412); Loss: 0.126645; Backpropagation: 0.2930 sec; Batch: 2.1186 sec
0.1726 0.1636 0.1406 0.1349 0.1283 0.1245 0.1217 0.1195 0.1184 0.1168 0.1159 0.1150 0.1145 0.1139 0.1134 0.1128 

[TRAIN] Epoch[1](10258/114412); Loss: 0.061943; Backpropagation: 0.2952 sec; Batch: 2.1238 sec
0.1218 0.1058 0.0774 0.0730 0.0641 0.0580 0.0557 0.0528 0.0511 0.0496 0.0486 0.0478 0.0471 0.0465 0.0461 0.0456 

[TRAIN] Epoch[1](10259/114412); Loss: 0.077005; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1450 0.1303 0.1027 0.0860 0.0782 0.0722 0.0688 0.0660 0.0642 0.0624 0.0612 0.0602 0.0594 0.0589 0.0585 0.0581 

[TRAIN] Epoch[1](10260/114412); Loss: 0.069345; Backpropagation: 0.2913 sec; Batch: 2.1255 sec
0.1214 0.1118 0.0899 0.0772 0.0698 0.0662 0.0625 0.0607 0.0590 0.0579 0.0568 0.0562 0.0556 0.0551 0.0548 0.0547 

[TRAIN] Epoch[1](10261/114412); Loss: 0.086119; Backpropagation: 0.2927 sec; Batch: 2.1156 sec
0.1792 0.1597 0.1101 0.0874 0.0824 0.0783 0.0737 0.0722 0.0701 0.0689 0.0676 0.0668 0.0659 0.0655 0.0653 0.0649 

[TRAIN] Epoch[1](10262/114412); Loss: 0.068042; Backpropagation: 0.2929 sec; Batch: 2.1170 sec
0.1065 0.0950 0.0798 0.0775 0.0716 0.0657 0.0639 0.0618 0.0611 0.0597 0.0590 0.0581 0.0576 0.0574 0.0570 0.0570 

[TRAIN] Epoch[1](10263/114412); Loss: 0.066177; Backpropagation: 0.2909 sec; Batch: 2.1159 sec
0.1418 0.1278 0.0841 0.0724 0.0638 0.0599 0.0566 0.0541 0.0521 0.0508 0.0502 0.0497 0.0493 0.0490 0.0487 0.0486 

[TRAIN] Epoch[1](10264/114412); Loss: 0.078539; Backpropagation: 0.2915 sec; Batch: 2.1174 sec
0.1574 0.1494 0.0947 0.0822 0.0770 0.0723 0.0694 0.0662 0.0641 0.0625 0.0616 0.0611 0.0603 0.0598 0.0595 0.0592 

[TRAIN] Epoch[1](10265/114412); Loss: 0.069435; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.1601 0.1509 0.1007 0.0801 0.0672 0.0629 0.0576 0.0540 0.0521 0.0497 0.0484 0.0475 0.0464 0.0450 0.0444 0.0438 

[TRAIN] Epoch[1](10266/114412); Loss: 0.071260; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1115 0.1127 0.0905 0.0827 0.0728 0.0678 0.0656 0.0631 0.0619 0.0605 0.0599 0.0593 0.0586 0.0581 0.0577 0.0574 

[TRAIN] Epoch[1](10267/114412); Loss: 0.061918; Backpropagation: 0.2911 sec; Batch: 2.1132 sec
0.1105 0.1015 0.0808 0.0703 0.0638 0.0582 0.0553 0.0537 0.0521 0.0510 0.0502 0.0494 0.0489 0.0485 0.0483 0.0481 

[TRAIN] Epoch[1](10268/114412); Loss: 0.076203; Backpropagation: 0.2908 sec; Batch: 2.1167 sec
0.1524 0.1433 0.0960 0.0826 0.0728 0.0680 0.0658 0.0633 0.0622 0.0608 0.0599 0.0594 0.0587 0.0583 0.0580 0.0578 

[TRAIN] Epoch[1](10269/114412); Loss: 0.080355; Backpropagation: 0.2910 sec; Batch: 2.1029 sec
0.1367 0.1213 0.1010 0.0888 0.0823 0.0783 0.0748 0.0721 0.0699 0.0686 0.0673 0.0661 0.0654 0.0649 0.0643 0.0639 

[TRAIN] Epoch[1](10270/114412); Loss: 0.083552; Backpropagation: 0.2911 sec; Batch: 2.1215 sec
0.1479 0.1401 0.1057 0.0900 0.0823 0.0773 0.0751 0.0723 0.0707 0.0695 0.0687 0.0681 0.0677 0.0672 0.0671 0.0670 

[TRAIN] Epoch[1](10271/114412); Loss: 0.070657; Backpropagation: 0.2933 sec; Batch: 2.1193 sec
0.1373 0.1233 0.0860 0.0769 0.0699 0.0656 0.0625 0.0601 0.0585 0.0577 0.0567 0.0560 0.0555 0.0551 0.0548 0.0546 

[TRAIN] Epoch[1](10272/114412); Loss: 0.086281; Backpropagation: 0.2913 sec; Batch: 2.1198 sec
0.1470 0.1368 0.1108 0.1034 0.0930 0.0859 0.0805 0.0761 0.0730 0.0709 0.0697 0.0683 0.0673 0.0666 0.0660 0.0654 

[TRAIN] Epoch[1](10273/114412); Loss: 0.058851; Backpropagation: 0.2908 sec; Batch: 2.1159 sec
0.1155 0.1084 0.0862 0.0724 0.0641 0.0566 0.0513 0.0480 0.0461 0.0443 0.0431 0.0421 0.0416 0.0410 0.0407 0.0402 

[TRAIN] Epoch[1](10274/114412); Loss: 0.059507; Backpropagation: 0.2911 sec; Batch: 2.1241 sec
0.1091 0.0971 0.0793 0.0707 0.0610 0.0566 0.0532 0.0512 0.0501 0.0485 0.0473 0.0465 0.0460 0.0455 0.0451 0.0448 

[TRAIN] Epoch[1](10275/114412); Loss: 0.088177; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1564 0.1499 0.1104 0.0958 0.0872 0.0829 0.0802 0.0771 0.0750 0.0734 0.0721 0.0711 0.0705 0.0699 0.0696 0.0693 

[TRAIN] Epoch[1](10276/114412); Loss: 0.079720; Backpropagation: 0.2912 sec; Batch: 2.0769 sec
0.1607 0.1520 0.1091 0.0923 0.0765 0.0719 0.0680 0.0656 0.0637 0.0617 0.0607 0.0598 0.0591 0.0586 0.0581 0.0577 

[TRAIN] Epoch[1](10277/114412); Loss: 0.081105; Backpropagation: 0.2912 sec; Batch: 2.1288 sec
0.1564 0.1371 0.1049 0.0900 0.0782 0.0742 0.0711 0.0692 0.0677 0.0665 0.0653 0.0645 0.0637 0.0633 0.0629 0.0627 

[TRAIN] Epoch[1](10278/114412); Loss: 0.080244; Backpropagation: 0.2932 sec; Batch: 2.1191 sec
0.2092 0.1978 0.1443 0.1045 0.0777 0.0646 0.0588 0.0523 0.0505 0.0489 0.0476 0.0464 0.0458 0.0455 0.0451 0.0447 

[TRAIN] Epoch[1](10279/114412); Loss: 0.077592; Backpropagation: 0.2930 sec; Batch: 2.1180 sec
0.1424 0.1228 0.0993 0.0863 0.0796 0.0740 0.0704 0.0677 0.0655 0.0643 0.0631 0.0622 0.0616 0.0610 0.0608 0.0606 

[TRAIN] Epoch[1](10280/114412); Loss: 0.069430; Backpropagation: 0.2912 sec; Batch: 2.1159 sec
0.1384 0.1288 0.0913 0.0799 0.0704 0.0651 0.0612 0.0579 0.0557 0.0541 0.0529 0.0520 0.0514 0.0509 0.0505 0.0502 

[TRAIN] Epoch[1](10281/114412); Loss: 0.102229; Backpropagation: 0.2907 sec; Batch: 2.1249 sec
0.1570 0.1429 0.1249 0.1133 0.1042 0.0977 0.0946 0.0922 0.0911 0.0901 0.0892 0.0885 0.0880 0.0876 0.0873 0.0870 

[TRAIN] Epoch[1](10282/114412); Loss: 0.090313; Backpropagation: 0.2908 sec; Batch: 2.1131 sec
0.1531 0.1407 0.1146 0.1010 0.0915 0.0865 0.0820 0.0793 0.0775 0.0764 0.0755 0.0745 0.0739 0.0733 0.0729 0.0724 

[TRAIN] Epoch[1](10283/114412); Loss: 0.064412; Backpropagation: 0.2912 sec; Batch: 2.1138 sec
0.1222 0.1086 0.0813 0.0691 0.0652 0.0614 0.0582 0.0559 0.0540 0.0527 0.0517 0.0509 0.0504 0.0499 0.0497 0.0493 

[TRAIN] Epoch[1](10284/114412); Loss: 0.050751; Backpropagation: 0.2911 sec; Batch: 2.1250 sec
0.1115 0.0996 0.0668 0.0543 0.0498 0.0462 0.0438 0.0409 0.0396 0.0385 0.0379 0.0373 0.0368 0.0366 0.0363 0.0361 

[TRAIN] Epoch[1](10285/114412); Loss: 0.074429; Backpropagation: 0.2904 sec; Batch: 2.1141 sec
0.1561 0.1466 0.0987 0.0819 0.0744 0.0670 0.0635 0.0593 0.0579 0.0563 0.0557 0.0554 0.0549 0.0547 0.0543 0.0541 

[TRAIN] Epoch[1](10286/114412); Loss: 0.074067; Backpropagation: 0.2928 sec; Batch: 2.1183 sec
0.1492 0.1383 0.0996 0.0855 0.0752 0.0682 0.0647 0.0616 0.0591 0.0573 0.0563 0.0554 0.0545 0.0538 0.0534 0.0532 

[TRAIN] Epoch[1](10287/114412); Loss: 0.098616; Backpropagation: 0.2910 sec; Batch: 2.1190 sec
0.1459 0.1352 0.1165 0.1086 0.1006 0.0975 0.0935 0.0919 0.0898 0.0881 0.0869 0.0861 0.0852 0.0846 0.0840 0.0835 

[TRAIN] Epoch[1](10288/114412); Loss: 0.057257; Backpropagation: 0.2911 sec; Batch: 2.1187 sec
0.1249 0.1126 0.0802 0.0658 0.0588 0.0523 0.0487 0.0457 0.0441 0.0427 0.0417 0.0410 0.0402 0.0395 0.0391 0.0389 

[TRAIN] Epoch[1](10289/114412); Loss: 0.063489; Backpropagation: 0.2914 sec; Batch: 2.1256 sec
0.1361 0.1248 0.0850 0.0690 0.0618 0.0584 0.0549 0.0520 0.0500 0.0485 0.0475 0.0465 0.0459 0.0455 0.0452 0.0448 

[TRAIN] Epoch[1](10290/114412); Loss: 0.069694; Backpropagation: 0.2930 sec; Batch: 2.1202 sec
0.1310 0.1109 0.0871 0.0789 0.0703 0.0664 0.0631 0.0608 0.0589 0.0575 0.0567 0.0557 0.0550 0.0545 0.0542 0.0540 

[TRAIN] Epoch[1](10291/114412); Loss: 0.058996; Backpropagation: 0.2954 sec; Batch: 2.1184 sec
0.1276 0.1113 0.0834 0.0698 0.0583 0.0535 0.0502 0.0481 0.0462 0.0447 0.0434 0.0425 0.0418 0.0413 0.0410 0.0407 

[TRAIN] Epoch[1](10292/114412); Loss: 0.112731; Backpropagation: 0.2931 sec; Batch: 2.1156 sec
0.1842 0.1768 0.1462 0.1317 0.1177 0.1072 0.1034 0.1001 0.0969 0.0948 0.0932 0.0920 0.0911 0.0900 0.0895 0.0888 

[TRAIN] Epoch[1](10293/114412); Loss: 0.052949; Backpropagation: 0.2953 sec; Batch: 2.1238 sec
0.1334 0.1234 0.0787 0.0623 0.0488 0.0441 0.0403 0.0384 0.0369 0.0358 0.0349 0.0346 0.0341 0.0340 0.0337 0.0335 

[TRAIN] Epoch[1](10294/114412); Loss: 0.060709; Backpropagation: 0.2925 sec; Batch: 2.1180 sec
0.1231 0.1076 0.0750 0.0639 0.0587 0.0556 0.0534 0.0512 0.0498 0.0488 0.0481 0.0477 0.0474 0.0471 0.0470 0.0470 

[TRAIN] Epoch[1](10295/114412); Loss: 0.067025; Backpropagation: 0.2949 sec; Batch: 2.1196 sec
0.1167 0.1066 0.0868 0.0759 0.0687 0.0636 0.0613 0.0589 0.0571 0.0558 0.0548 0.0542 0.0536 0.0531 0.0528 0.0523 

[TRAIN] Epoch[1](10296/114412); Loss: 0.054317; Backpropagation: 0.2922 sec; Batch: 2.1143 sec
0.1369 0.1304 0.0729 0.0559 0.0534 0.0465 0.0430 0.0402 0.0386 0.0373 0.0366 0.0359 0.0356 0.0353 0.0352 0.0352 

[TRAIN] Epoch[1](10297/114412); Loss: 0.071481; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1404 0.1243 0.0930 0.0861 0.0741 0.0680 0.0634 0.0604 0.0584 0.0565 0.0553 0.0542 0.0532 0.0527 0.0520 0.0517 

[TRAIN] Epoch[1](10298/114412); Loss: 0.065190; Backpropagation: 0.2907 sec; Batch: 2.1149 sec
0.1232 0.1049 0.0816 0.0758 0.0673 0.0611 0.0578 0.0559 0.0550 0.0535 0.0525 0.0518 0.0513 0.0509 0.0505 0.0501 

[TRAIN] Epoch[1](10299/114412); Loss: 0.082121; Backpropagation: 0.2906 sec; Batch: 2.1168 sec
0.1568 0.1459 0.1124 0.0963 0.0841 0.0768 0.0720 0.0694 0.0664 0.0647 0.0635 0.0623 0.0618 0.0609 0.0606 0.0602 

[TRAIN] Epoch[1](10300/114412); Loss: 0.069036; Backpropagation: 0.2928 sec; Batch: 2.1164 sec
0.1260 0.1133 0.0917 0.0791 0.0719 0.0670 0.0627 0.0595 0.0576 0.0561 0.0549 0.0540 0.0533 0.0529 0.0525 0.0520 

[TRAIN] Epoch[1](10301/114412); Loss: 0.050663; Backpropagation: 0.2913 sec; Batch: 2.1159 sec
0.1028 0.0984 0.0652 0.0578 0.0507 0.0470 0.0439 0.0416 0.0398 0.0390 0.0385 0.0380 0.0374 0.0371 0.0369 0.0367 

[TRAIN] Epoch[1](10302/114412); Loss: 0.102367; Backpropagation: 0.2906 sec; Batch: 2.1127 sec
0.1590 0.1457 0.1282 0.1150 0.1010 0.0975 0.0953 0.0927 0.0916 0.0898 0.0888 0.0878 0.0871 0.0865 0.0861 0.0860 

[TRAIN] Epoch[1](10303/114412); Loss: 0.068238; Backpropagation: 0.2915 sec; Batch: 2.1312 sec
0.1179 0.1135 0.0880 0.0822 0.0760 0.0683 0.0636 0.0592 0.0564 0.0545 0.0535 0.0526 0.0520 0.0517 0.0514 0.0511 

[TRAIN] Epoch[1](10304/114412); Loss: 0.083134; Backpropagation: 0.2911 sec; Batch: 2.1151 sec
0.1512 0.1344 0.1028 0.0916 0.0845 0.0795 0.0750 0.0733 0.0711 0.0694 0.0683 0.0672 0.0663 0.0656 0.0652 0.0646 

[TRAIN] Epoch[1](10305/114412); Loss: 0.080431; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.1494 0.1344 0.1026 0.0876 0.0784 0.0750 0.0719 0.0692 0.0674 0.0663 0.0654 0.0646 0.0642 0.0639 0.0634 0.0632 

[TRAIN] Epoch[1](10306/114412); Loss: 0.074423; Backpropagation: 0.2914 sec; Batch: 2.1136 sec
0.1214 0.1124 0.0943 0.0842 0.0788 0.0723 0.0695 0.0668 0.0650 0.0636 0.0622 0.0613 0.0606 0.0599 0.0594 0.0590 

[TRAIN] Epoch[1](10307/114412); Loss: 0.058665; Backpropagation: 0.2914 sec; Batch: 2.1160 sec
0.1492 0.1359 0.0800 0.0619 0.0533 0.0496 0.0466 0.0440 0.0423 0.0410 0.0402 0.0397 0.0391 0.0388 0.0386 0.0384 

[TRAIN] Epoch[1](10308/114412); Loss: 0.091735; Backpropagation: 0.2929 sec; Batch: 2.1194 sec
0.1653 0.1473 0.1125 0.0988 0.0910 0.0866 0.0831 0.0812 0.0789 0.0772 0.0762 0.0752 0.0744 0.0739 0.0735 0.0729 

[TRAIN] Epoch[1](10309/114412); Loss: 0.076171; Backpropagation: 0.2930 sec; Batch: 2.1186 sec
0.1268 0.1154 0.0998 0.0891 0.0788 0.0736 0.0695 0.0672 0.0650 0.0640 0.0631 0.0622 0.0617 0.0612 0.0608 0.0606 

[TRAIN] Epoch[1](10310/114412); Loss: 0.063500; Backpropagation: 0.2928 sec; Batch: 2.1216 sec
0.1239 0.1103 0.0816 0.0692 0.0619 0.0586 0.0564 0.0544 0.0525 0.0514 0.0505 0.0498 0.0493 0.0490 0.0487 0.0486 

[TRAIN] Epoch[1](10311/114412); Loss: 0.069444; Backpropagation: 0.2913 sec; Batch: 2.1160 sec
0.1307 0.1160 0.0904 0.0808 0.0723 0.0666 0.0626 0.0595 0.0573 0.0560 0.0549 0.0540 0.0533 0.0526 0.0522 0.0518 

[TRAIN] Epoch[1](10312/114412); Loss: 0.069438; Backpropagation: 0.2932 sec; Batch: 2.1191 sec
0.1534 0.1451 0.0966 0.0785 0.0639 0.0593 0.0567 0.0546 0.0528 0.0519 0.0508 0.0503 0.0498 0.0494 0.0490 0.0489 

[TRAIN] Epoch[1](10313/114412); Loss: 0.073866; Backpropagation: 0.2909 sec; Batch: 2.1139 sec
0.1448 0.1353 0.0926 0.0788 0.0713 0.0660 0.0633 0.0613 0.0602 0.0597 0.0591 0.0585 0.0581 0.0578 0.0577 0.0575 

[TRAIN] Epoch[1](10314/114412); Loss: 0.053440; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1376 0.1227 0.0768 0.0589 0.0509 0.0457 0.0418 0.0395 0.0381 0.0366 0.0355 0.0349 0.0345 0.0342 0.0338 0.0336 

[TRAIN] Epoch[1](10315/114412); Loss: 0.083720; Backpropagation: 0.2907 sec; Batch: 2.1165 sec
0.1535 0.1422 0.0972 0.0852 0.0826 0.0779 0.0765 0.0734 0.0719 0.0709 0.0696 0.0688 0.0681 0.0676 0.0673 0.0668 

[TRAIN] Epoch[1](10316/114412); Loss: 0.091010; Backpropagation: 0.2917 sec; Batch: 2.1156 sec
0.1578 0.1420 0.1118 0.0986 0.0924 0.0885 0.0852 0.0816 0.0789 0.0772 0.0757 0.0744 0.0740 0.0731 0.0726 0.0722 

[TRAIN] Epoch[1](10317/114412); Loss: 0.080935; Backpropagation: 0.2904 sec; Batch: 2.1162 sec
0.1339 0.1161 0.1031 0.0920 0.0841 0.0800 0.0759 0.0728 0.0706 0.0690 0.0678 0.0669 0.0661 0.0657 0.0655 0.0654 

[TRAIN] Epoch[1](10318/114412); Loss: 0.080046; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.1482 0.1237 0.0961 0.0868 0.0801 0.0760 0.0733 0.0708 0.0692 0.0676 0.0665 0.0658 0.0649 0.0644 0.0638 0.0634 

[TRAIN] Epoch[1](10319/114412); Loss: 0.075774; Backpropagation: 0.2914 sec; Batch: 2.1149 sec
0.1553 0.1508 0.0983 0.0822 0.0741 0.0702 0.0650 0.0617 0.0596 0.0587 0.0574 0.0567 0.0563 0.0556 0.0553 0.0551 

[TRAIN] Epoch[1](10320/114412); Loss: 0.104993; Backpropagation: 0.2908 sec; Batch: 2.1116 sec
0.2341 0.2023 0.1399 0.1083 0.0997 0.0921 0.0877 0.0865 0.0836 0.0824 0.0799 0.0789 0.0773 0.0764 0.0758 0.0751 

[TRAIN] Epoch[1](10321/114412); Loss: 0.068441; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.1224 0.1106 0.0828 0.0757 0.0680 0.0645 0.0617 0.0598 0.0587 0.0573 0.0566 0.0562 0.0556 0.0553 0.0550 0.0549 

[TRAIN] Epoch[1](10322/114412); Loss: 0.079025; Backpropagation: 0.2930 sec; Batch: 2.1202 sec
0.1705 0.1549 0.1082 0.0882 0.0783 0.0710 0.0667 0.0640 0.0620 0.0602 0.0589 0.0578 0.0570 0.0561 0.0556 0.0552 

[TRAIN] Epoch[1](10323/114412); Loss: 0.079677; Backpropagation: 0.2938 sec; Batch: 2.1212 sec
0.1612 0.1521 0.1006 0.0823 0.0753 0.0717 0.0684 0.0665 0.0650 0.0639 0.0629 0.0619 0.0614 0.0609 0.0605 0.0602 

[TRAIN] Epoch[1](10324/114412); Loss: 0.076159; Backpropagation: 0.2931 sec; Batch: 2.1201 sec
0.1258 0.1220 0.0980 0.0889 0.0794 0.0718 0.0689 0.0672 0.0652 0.0638 0.0629 0.0619 0.0613 0.0609 0.0605 0.0602 

[TRAIN] Epoch[1](10325/114412); Loss: 0.067853; Backpropagation: 0.2910 sec; Batch: 2.1208 sec
0.1242 0.1070 0.0897 0.0785 0.0695 0.0642 0.0614 0.0587 0.0569 0.0559 0.0548 0.0541 0.0534 0.0528 0.0525 0.0519 

[TRAIN] Epoch[1](10326/114412); Loss: 0.044260; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.0796 0.0765 0.0560 0.0485 0.0450 0.0417 0.0402 0.0383 0.0375 0.0363 0.0357 0.0351 0.0347 0.0345 0.0343 0.0342 

[TRAIN] Epoch[1](10327/114412); Loss: 0.066996; Backpropagation: 0.2913 sec; Batch: 2.1141 sec
0.1676 0.1453 0.0972 0.0719 0.0634 0.0555 0.0528 0.0507 0.0485 0.0473 0.0464 0.0457 0.0453 0.0449 0.0448 0.0447 

[TRAIN] Epoch[1](10328/114412); Loss: 0.061519; Backpropagation: 0.2918 sec; Batch: 2.1169 sec
0.1266 0.1122 0.0775 0.0663 0.0586 0.0557 0.0532 0.0513 0.0501 0.0489 0.0483 0.0479 0.0473 0.0469 0.0467 0.0467 

[TRAIN] Epoch[1](10329/114412); Loss: 0.076357; Backpropagation: 0.2928 sec; Batch: 2.1185 sec
0.1540 0.1416 0.0910 0.0834 0.0720 0.0669 0.0650 0.0630 0.0619 0.0614 0.0609 0.0605 0.0602 0.0602 0.0600 0.0599 

[TRAIN] Epoch[1](10330/114412); Loss: 0.065449; Backpropagation: 0.2955 sec; Batch: 2.1172 sec
0.1346 0.1278 0.0950 0.0782 0.0664 0.0599 0.0556 0.0529 0.0507 0.0489 0.0479 0.0470 0.0462 0.0457 0.0454 0.0449 

[TRAIN] Epoch[1](10331/114412); Loss: 0.082925; Backpropagation: 0.2955 sec; Batch: 2.1253 sec
0.1421 0.1254 0.0994 0.0910 0.0841 0.0803 0.0770 0.0747 0.0726 0.0711 0.0699 0.0688 0.0683 0.0678 0.0673 0.0670 

[TRAIN] Epoch[1](10332/114412); Loss: 0.103378; Backpropagation: 0.2971 sec; Batch: 2.0907 sec
0.1722 0.1683 0.1349 0.1234 0.1074 0.1015 0.0967 0.0936 0.0892 0.0861 0.0838 0.0815 0.0805 0.0796 0.0781 0.0773 

[TRAIN] Epoch[1](10333/114412); Loss: 0.071811; Backpropagation: 0.2932 sec; Batch: 2.1179 sec
0.1325 0.1224 0.0950 0.0867 0.0760 0.0701 0.0647 0.0623 0.0595 0.0573 0.0557 0.0545 0.0538 0.0533 0.0528 0.0524 

[TRAIN] Epoch[1](10334/114412); Loss: 0.076306; Backpropagation: 0.2950 sec; Batch: 2.0805 sec
0.1498 0.1384 0.0895 0.0794 0.0726 0.0700 0.0671 0.0649 0.0635 0.0623 0.0618 0.0611 0.0605 0.0603 0.0600 0.0596 

[TRAIN] Epoch[1](10335/114412); Loss: 0.075058; Backpropagation: 0.2903 sec; Batch: 2.1141 sec
0.1393 0.1210 0.0898 0.0811 0.0767 0.0720 0.0688 0.0661 0.0641 0.0628 0.0614 0.0605 0.0599 0.0595 0.0591 0.0590 

[TRAIN] Epoch[1](10336/114412); Loss: 0.080396; Backpropagation: 0.2903 sec; Batch: 2.1142 sec
0.1319 0.1219 0.1003 0.0905 0.0813 0.0775 0.0745 0.0722 0.0706 0.0689 0.0680 0.0670 0.0664 0.0657 0.0651 0.0647 

[TRAIN] Epoch[1](10337/114412); Loss: 0.056023; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.1300 0.0970 0.0693 0.0654 0.0594 0.0543 0.0492 0.0460 0.0442 0.0425 0.0414 0.0405 0.0399 0.0395 0.0391 0.0388 

[TRAIN] Epoch[1](10338/114412); Loss: 0.079794; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1423 0.1292 0.1014 0.0907 0.0798 0.0762 0.0718 0.0695 0.0678 0.0663 0.0654 0.0643 0.0636 0.0631 0.0627 0.0626 

[TRAIN] Epoch[1](10339/114412); Loss: 0.083434; Backpropagation: 0.2910 sec; Batch: 2.1139 sec
0.1458 0.1320 0.1070 0.0920 0.0843 0.0784 0.0757 0.0732 0.0717 0.0705 0.0694 0.0683 0.0675 0.0669 0.0663 0.0660 

[TRAIN] Epoch[1](10340/114412); Loss: 0.086225; Backpropagation: 0.2930 sec; Batch: 2.1193 sec
0.1430 0.1249 0.1054 0.0948 0.0887 0.0839 0.0807 0.0783 0.0763 0.0748 0.0736 0.0725 0.0716 0.0709 0.0703 0.0698 

[TRAIN] Epoch[1](10341/114412); Loss: 0.068738; Backpropagation: 0.2911 sec; Batch: 2.0774 sec
0.1370 0.1176 0.0865 0.0764 0.0706 0.0652 0.0616 0.0581 0.0562 0.0550 0.0537 0.0531 0.0527 0.0522 0.0520 0.0519 

[TRAIN] Epoch[1](10342/114412); Loss: 0.077487; Backpropagation: 0.2912 sec; Batch: 2.1166 sec
0.1294 0.1208 0.0884 0.0835 0.0779 0.0737 0.0712 0.0689 0.0679 0.0669 0.0661 0.0657 0.0652 0.0649 0.0646 0.0646 

[TRAIN] Epoch[1](10343/114412); Loss: 0.072723; Backpropagation: 0.2908 sec; Batch: 2.0760 sec
0.1272 0.1175 0.0892 0.0828 0.0741 0.0693 0.0660 0.0639 0.0622 0.0607 0.0597 0.0589 0.0585 0.0581 0.0579 0.0578 

[TRAIN] Epoch[1](10344/114412); Loss: 0.066746; Backpropagation: 0.2911 sec; Batch: 2.1143 sec
0.1160 0.1003 0.0837 0.0729 0.0676 0.0634 0.0605 0.0587 0.0577 0.0565 0.0560 0.0557 0.0553 0.0548 0.0545 0.0544 

[TRAIN] Epoch[1](10345/114412); Loss: 0.086798; Backpropagation: 0.2916 sec; Batch: 2.1138 sec
0.1538 0.1387 0.1047 0.0929 0.0872 0.0837 0.0800 0.0766 0.0749 0.0733 0.0720 0.0712 0.0706 0.0701 0.0697 0.0694 

[TRAIN] Epoch[1](10346/114412); Loss: 0.062947; Backpropagation: 0.2908 sec; Batch: 2.0768 sec
0.1315 0.1072 0.0851 0.0721 0.0658 0.0606 0.0562 0.0536 0.0511 0.0491 0.0480 0.0467 0.0459 0.0453 0.0446 0.0443 

[TRAIN] Epoch[1](10347/114412); Loss: 0.066025; Backpropagation: 0.2956 sec; Batch: 2.1284 sec
0.1226 0.1144 0.0852 0.0769 0.0678 0.0637 0.0597 0.0570 0.0549 0.0533 0.0518 0.0512 0.0502 0.0497 0.0491 0.0488 

[TRAIN] Epoch[1](10348/114412); Loss: 0.083424; Backpropagation: 0.2932 sec; Batch: 2.1215 sec
0.1734 0.1546 0.1177 0.0956 0.0813 0.0751 0.0706 0.0682 0.0660 0.0649 0.0634 0.0623 0.0615 0.0607 0.0600 0.0595 

[TRAIN] Epoch[1](10349/114412); Loss: 0.071459; Backpropagation: 0.2953 sec; Batch: 2.1197 sec
0.1417 0.1241 0.0958 0.0803 0.0711 0.0649 0.0622 0.0598 0.0582 0.0572 0.0562 0.0555 0.0548 0.0542 0.0539 0.0536 

[TRAIN] Epoch[1](10350/114412); Loss: 0.057664; Backpropagation: 0.2914 sec; Batch: 2.1222 sec
0.1125 0.1031 0.0749 0.0624 0.0574 0.0528 0.0506 0.0479 0.0466 0.0460 0.0457 0.0452 0.0446 0.0445 0.0443 0.0441 

[TRAIN] Epoch[1](10351/114412); Loss: 0.078227; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1817 0.1636 0.1054 0.0796 0.0696 0.0686 0.0650 0.0625 0.0602 0.0590 0.0578 0.0569 0.0563 0.0555 0.0551 0.0550 

[TRAIN] Epoch[1](10352/114412); Loss: 0.073327; Backpropagation: 0.2912 sec; Batch: 2.1125 sec
0.1276 0.1191 0.0888 0.0816 0.0748 0.0703 0.0670 0.0644 0.0631 0.0617 0.0606 0.0597 0.0592 0.0588 0.0584 0.0580 

[TRAIN] Epoch[1](10353/114412); Loss: 0.071568; Backpropagation: 0.2911 sec; Batch: 2.1173 sec
0.1470 0.1377 0.0949 0.0808 0.0688 0.0641 0.0617 0.0590 0.0571 0.0559 0.0546 0.0537 0.0531 0.0527 0.0522 0.0518 

[TRAIN] Epoch[1](10354/114412); Loss: 0.064035; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.1207 0.1154 0.0821 0.0709 0.0624 0.0598 0.0565 0.0547 0.0528 0.0516 0.0507 0.0500 0.0495 0.0492 0.0491 0.0490 

[TRAIN] Epoch[1](10355/114412); Loss: 0.098200; Backpropagation: 0.2923 sec; Batch: 2.1161 sec
0.1678 0.1574 0.1290 0.1149 0.1036 0.0958 0.0908 0.0871 0.0840 0.0813 0.0796 0.0780 0.0769 0.0757 0.0751 0.0743 

[TRAIN] Epoch[1](10356/114412); Loss: 0.077052; Backpropagation: 0.2931 sec; Batch: 2.1173 sec
0.1472 0.1320 0.0977 0.0864 0.0784 0.0744 0.0706 0.0668 0.0645 0.0624 0.0613 0.0599 0.0589 0.0581 0.0572 0.0568 

[TRAIN] Epoch[1](10357/114412); Loss: 0.066449; Backpropagation: 0.2953 sec; Batch: 2.1245 sec
0.1392 0.1266 0.0805 0.0721 0.0670 0.0619 0.0579 0.0550 0.0531 0.0519 0.0509 0.0502 0.0496 0.0493 0.0490 0.0489 

[TRAIN] Epoch[1](10358/114412); Loss: 0.091724; Backpropagation: 0.2928 sec; Batch: 2.1183 sec
0.1767 0.1562 0.1317 0.1138 0.1016 0.0921 0.0817 0.0762 0.0738 0.0705 0.0691 0.0668 0.0658 0.0645 0.0638 0.0633 

[TRAIN] Epoch[1](10359/114412); Loss: 0.077842; Backpropagation: 0.2953 sec; Batch: 2.1194 sec
0.1404 0.1250 0.0984 0.0875 0.0792 0.0738 0.0698 0.0676 0.0658 0.0646 0.0638 0.0630 0.0624 0.0619 0.0615 0.0610 

[TRAIN] Epoch[1](10360/114412); Loss: 0.078188; Backpropagation: 0.2934 sec; Batch: 2.1204 sec
0.1679 0.1532 0.0996 0.0852 0.0751 0.0704 0.0674 0.0643 0.0621 0.0605 0.0593 0.0584 0.0576 0.0571 0.0565 0.0562 

[TRAIN] Epoch[1](10361/114412); Loss: 0.079562; Backpropagation: 0.2951 sec; Batch: 2.1193 sec
0.1561 0.1428 0.1010 0.0880 0.0759 0.0727 0.0695 0.0669 0.0655 0.0644 0.0633 0.0624 0.0617 0.0613 0.0610 0.0605 

[TRAIN] Epoch[1](10362/114412); Loss: 0.103360; Backpropagation: 0.2950 sec; Batch: 2.1220 sec
0.1619 0.1539 0.1257 0.1155 0.1047 0.1009 0.0977 0.0945 0.0924 0.0901 0.0889 0.0872 0.0865 0.0853 0.0846 0.0839 

[TRAIN] Epoch[1](10363/114412); Loss: 0.070824; Backpropagation: 0.2932 sec; Batch: 2.1203 sec
0.1542 0.1412 0.0979 0.0789 0.0693 0.0646 0.0604 0.0570 0.0550 0.0529 0.0519 0.0511 0.0502 0.0497 0.0495 0.0494 

[TRAIN] Epoch[1](10364/114412); Loss: 0.061023; Backpropagation: 0.2952 sec; Batch: 2.1230 sec
0.1054 0.1042 0.0906 0.0708 0.0617 0.0582 0.0542 0.0516 0.0501 0.0488 0.0481 0.0473 0.0467 0.0463 0.0462 0.0461 

[TRAIN] Epoch[1](10365/114412); Loss: 0.070876; Backpropagation: 0.2928 sec; Batch: 2.1147 sec
0.1220 0.1130 0.0947 0.0814 0.0724 0.0677 0.0647 0.0621 0.0604 0.0590 0.0576 0.0568 0.0562 0.0556 0.0553 0.0550 

[TRAIN] Epoch[1](10366/114412); Loss: 0.069659; Backpropagation: 0.2949 sec; Batch: 2.1185 sec
0.1254 0.1189 0.0891 0.0768 0.0688 0.0653 0.0623 0.0601 0.0585 0.0573 0.0565 0.0559 0.0554 0.0549 0.0547 0.0546 

[TRAIN] Epoch[1](10367/114412); Loss: 0.077387; Backpropagation: 0.2951 sec; Batch: 2.1175 sec
0.1284 0.1131 0.0961 0.0850 0.0787 0.0746 0.0711 0.0693 0.0675 0.0666 0.0659 0.0654 0.0648 0.0643 0.0639 0.0636 

[TRAIN] Epoch[1](10368/114412); Loss: 0.057510; Backpropagation: 0.2924 sec; Batch: 2.1159 sec
0.1274 0.1185 0.0809 0.0670 0.0574 0.0531 0.0488 0.0460 0.0440 0.0423 0.0409 0.0399 0.0393 0.0386 0.0382 0.0378 

[TRAIN] Epoch[1](10369/114412); Loss: 0.065419; Backpropagation: 0.2930 sec; Batch: 2.1155 sec
0.1403 0.1254 0.0914 0.0726 0.0624 0.0584 0.0552 0.0527 0.0511 0.0497 0.0489 0.0484 0.0480 0.0477 0.0473 0.0471 

[TRAIN] Epoch[1](10370/114412); Loss: 0.089041; Backpropagation: 0.2929 sec; Batch: 2.1199 sec
0.1992 0.1831 0.1255 0.1003 0.0876 0.0762 0.0732 0.0694 0.0672 0.0658 0.0647 0.0638 0.0629 0.0624 0.0619 0.0615 

[TRAIN] Epoch[1](10371/114412); Loss: 0.064854; Backpropagation: 0.2931 sec; Batch: 2.1234 sec
0.1314 0.1117 0.0768 0.0719 0.0643 0.0609 0.0578 0.0551 0.0538 0.0524 0.0512 0.0508 0.0503 0.0499 0.0498 0.0495 

[TRAIN] Epoch[1](10372/114412); Loss: 0.076531; Backpropagation: 0.2913 sec; Batch: 2.0770 sec
0.1517 0.1360 0.1046 0.0923 0.0791 0.0724 0.0665 0.0627 0.0605 0.0592 0.0579 0.0573 0.0567 0.0561 0.0558 0.0556 

[TRAIN] Epoch[1](10373/114412); Loss: 0.092729; Backpropagation: 0.2912 sec; Batch: 2.1223 sec
0.1501 0.1442 0.1163 0.1028 0.0917 0.0875 0.0851 0.0831 0.0814 0.0798 0.0788 0.0778 0.0769 0.0764 0.0760 0.0757 

[TRAIN] Epoch[1](10374/114412); Loss: 0.071499; Backpropagation: 0.2912 sec; Batch: 2.1307 sec
0.1653 0.1400 0.0968 0.0776 0.0694 0.0644 0.0612 0.0575 0.0553 0.0536 0.0522 0.0514 0.0507 0.0500 0.0494 0.0492 

[TRAIN] Epoch[1](10375/114412); Loss: 0.071117; Backpropagation: 0.2931 sec; Batch: 2.0794 sec
0.1211 0.1091 0.0886 0.0794 0.0733 0.0684 0.0658 0.0633 0.0618 0.0602 0.0595 0.0586 0.0579 0.0574 0.0568 0.0566 

[TRAIN] Epoch[1](10376/114412); Loss: 0.073894; Backpropagation: 0.2929 sec; Batch: 2.1206 sec
0.1646 0.1478 0.0954 0.0772 0.0698 0.0671 0.0626 0.0602 0.0579 0.0563 0.0556 0.0546 0.0541 0.0535 0.0530 0.0528 

[TRAIN] Epoch[1](10377/114412); Loss: 0.065325; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1260 0.1202 0.0838 0.0756 0.0639 0.0598 0.0573 0.0553 0.0538 0.0521 0.0511 0.0503 0.0498 0.0491 0.0488 0.0486 

[TRAIN] Epoch[1](10378/114412); Loss: 0.063991; Backpropagation: 0.2914 sec; Batch: 2.1184 sec
0.1275 0.1136 0.0781 0.0695 0.0627 0.0591 0.0565 0.0544 0.0527 0.0516 0.0507 0.0502 0.0499 0.0494 0.0491 0.0488 

[TRAIN] Epoch[1](10379/114412); Loss: 0.082228; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.1820 0.1603 0.1105 0.0903 0.0801 0.0723 0.0692 0.0667 0.0649 0.0632 0.0615 0.0603 0.0596 0.0588 0.0580 0.0577 

[TRAIN] Epoch[1](10380/114412); Loss: 0.061342; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1408 0.1295 0.0852 0.0738 0.0597 0.0540 0.0503 0.0476 0.0456 0.0440 0.0430 0.0424 0.0419 0.0415 0.0412 0.0409 

[TRAIN] Epoch[1](10381/114412); Loss: 0.072592; Backpropagation: 0.2909 sec; Batch: 2.1151 sec
0.1487 0.1290 0.1003 0.0829 0.0721 0.0674 0.0628 0.0598 0.0586 0.0566 0.0553 0.0545 0.0539 0.0534 0.0531 0.0530 

[TRAIN] Epoch[1](10382/114412); Loss: 0.055818; Backpropagation: 0.2908 sec; Batch: 2.1217 sec
0.1068 0.0986 0.0768 0.0672 0.0567 0.0528 0.0495 0.0467 0.0454 0.0436 0.0427 0.0422 0.0415 0.0411 0.0408 0.0406 

[TRAIN] Epoch[1](10383/114412); Loss: 0.054386; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1059 0.0949 0.0788 0.0626 0.0543 0.0508 0.0481 0.0460 0.0441 0.0428 0.0418 0.0411 0.0403 0.0400 0.0395 0.0392 

[TRAIN] Epoch[1](10384/114412); Loss: 0.068061; Backpropagation: 0.2929 sec; Batch: 2.1182 sec
0.1118 0.1041 0.0827 0.0758 0.0698 0.0670 0.0637 0.0613 0.0596 0.0582 0.0574 0.0565 0.0560 0.0554 0.0550 0.0547 

[TRAIN] Epoch[1](10385/114412); Loss: 0.078958; Backpropagation: 0.2930 sec; Batch: 2.1190 sec
0.1222 0.1136 0.0972 0.0891 0.0811 0.0767 0.0736 0.0716 0.0701 0.0689 0.0680 0.0671 0.0666 0.0662 0.0659 0.0655 

[TRAIN] Epoch[1](10386/114412); Loss: 0.071673; Backpropagation: 0.2929 sec; Batch: 2.1211 sec
0.1413 0.1209 0.0983 0.0817 0.0729 0.0673 0.0633 0.0610 0.0592 0.0573 0.0560 0.0550 0.0540 0.0535 0.0528 0.0524 

[TRAIN] Epoch[1](10387/114412); Loss: 0.086614; Backpropagation: 0.2931 sec; Batch: 2.0859 sec
0.1537 0.1394 0.1081 0.0969 0.0886 0.0836 0.0797 0.0766 0.0746 0.0726 0.0711 0.0699 0.0689 0.0678 0.0674 0.0670 

[TRAIN] Epoch[1](10388/114412); Loss: 0.086792; Backpropagation: 0.2910 sec; Batch: 2.0802 sec
0.1592 0.1437 0.1173 0.1009 0.0900 0.0816 0.0779 0.0749 0.0725 0.0707 0.0695 0.0678 0.0670 0.0659 0.0652 0.0647 

[TRAIN] Epoch[1](10389/114412); Loss: 0.092416; Backpropagation: 0.2923 sec; Batch: 2.1124 sec
0.1352 0.1325 0.1086 0.1016 0.0951 0.0915 0.0884 0.0853 0.0838 0.0821 0.0813 0.0801 0.0792 0.0786 0.0780 0.0775 

[TRAIN] Epoch[1](10390/114412); Loss: 0.061789; Backpropagation: 0.2910 sec; Batch: 2.1215 sec
0.1263 0.1136 0.0797 0.0664 0.0598 0.0565 0.0533 0.0517 0.0502 0.0490 0.0480 0.0476 0.0472 0.0467 0.0464 0.0461 

[TRAIN] Epoch[1](10391/114412); Loss: 0.066466; Backpropagation: 0.2915 sec; Batch: 2.1180 sec
0.1234 0.1120 0.0854 0.0727 0.0660 0.0626 0.0596 0.0576 0.0558 0.0548 0.0538 0.0531 0.0523 0.0518 0.0514 0.0511 

[TRAIN] Epoch[1](10392/114412); Loss: 0.080325; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.1741 0.1561 0.1097 0.0884 0.0772 0.0717 0.0683 0.0650 0.0630 0.0611 0.0601 0.0593 0.0587 0.0580 0.0575 0.0570 

[TRAIN] Epoch[1](10393/114412); Loss: 0.090133; Backpropagation: 0.2927 sec; Batch: 2.1197 sec
0.1568 0.1463 0.1122 0.1008 0.0916 0.0871 0.0826 0.0801 0.0772 0.0750 0.0737 0.0727 0.0722 0.0716 0.0713 0.0709 

[TRAIN] Epoch[1](10394/114412); Loss: 0.064645; Backpropagation: 0.2911 sec; Batch: 2.1136 sec
0.1410 0.1196 0.0913 0.0756 0.0650 0.0589 0.0569 0.0534 0.0506 0.0487 0.0473 0.0467 0.0457 0.0451 0.0444 0.0440 

[TRAIN] Epoch[1](10395/114412); Loss: 0.086969; Backpropagation: 0.2911 sec; Batch: 2.1147 sec
0.1661 0.1459 0.1105 0.0939 0.0870 0.0807 0.0769 0.0746 0.0724 0.0710 0.0699 0.0693 0.0688 0.0684 0.0681 0.0679 

[TRAIN] Epoch[1](10396/114412); Loss: 0.107771; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.1928 0.1766 0.1292 0.1098 0.1036 0.0999 0.0968 0.0945 0.0928 0.0916 0.0908 0.0899 0.0895 0.0890 0.0889 0.0886 

[TRAIN] Epoch[1](10397/114412); Loss: 0.081550; Backpropagation: 0.2912 sec; Batch: 2.1163 sec
0.1632 0.1562 0.0933 0.0805 0.0770 0.0731 0.0702 0.0684 0.0674 0.0665 0.0658 0.0652 0.0648 0.0645 0.0645 0.0643 

[TRAIN] Epoch[1](10398/114412); Loss: 0.078276; Backpropagation: 0.2926 sec; Batch: 2.1193 sec
0.1394 0.1303 0.0923 0.0825 0.0780 0.0734 0.0703 0.0687 0.0671 0.0659 0.0651 0.0644 0.0640 0.0638 0.0636 0.0635 

[TRAIN] Epoch[1](10399/114412); Loss: 0.102262; Backpropagation: 0.2925 sec; Batch: 2.1214 sec
0.2161 0.1957 0.1536 0.1263 0.1031 0.0903 0.0847 0.0806 0.0783 0.0759 0.0743 0.0728 0.0721 0.0716 0.0708 0.0700 

[TRAIN] Epoch[1](10400/114412); Loss: 0.090092; Backpropagation: 0.2927 sec; Batch: 2.1177 sec
0.1629 0.1506 0.1161 0.1016 0.0915 0.0865 0.0817 0.0782 0.0760 0.0741 0.0729 0.0715 0.0706 0.0697 0.0691 0.0683 

[TRAIN] Epoch[1](10401/114412); Loss: 0.086522; Backpropagation: 0.2928 sec; Batch: 2.1344 sec
0.1626 0.1496 0.1066 0.1001 0.0891 0.0818 0.0767 0.0735 0.0716 0.0700 0.0689 0.0680 0.0673 0.0665 0.0661 0.0659 

[TRAIN] Epoch[1](10402/114412); Loss: 0.060487; Backpropagation: 0.2931 sec; Batch: 2.1234 sec
0.1448 0.1269 0.0822 0.0670 0.0592 0.0547 0.0514 0.0477 0.0459 0.0438 0.0429 0.0417 0.0409 0.0402 0.0395 0.0391 

[TRAIN] Epoch[1](10403/114412); Loss: 0.080671; Backpropagation: 0.2931 sec; Batch: 2.1203 sec
0.1445 0.1341 0.0968 0.0868 0.0796 0.0750 0.0722 0.0705 0.0689 0.0681 0.0672 0.0663 0.0657 0.0654 0.0650 0.0647 

[TRAIN] Epoch[1](10404/114412); Loss: 0.066365; Backpropagation: 0.2909 sec; Batch: 2.1168 sec
0.1367 0.1057 0.0905 0.0772 0.0677 0.0632 0.0589 0.0565 0.0542 0.0527 0.0520 0.0507 0.0499 0.0491 0.0487 0.0481 

[TRAIN] Epoch[1](10405/114412); Loss: 0.095960; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1653 0.1541 0.1176 0.1050 0.0972 0.0914 0.0872 0.0846 0.0826 0.0809 0.0801 0.0791 0.0784 0.0777 0.0772 0.0768 

[TRAIN] Epoch[1](10406/114412); Loss: 0.058087; Backpropagation: 0.2909 sec; Batch: 2.1018 sec
0.1171 0.1078 0.0748 0.0623 0.0544 0.0530 0.0494 0.0478 0.0469 0.0460 0.0455 0.0452 0.0450 0.0448 0.0447 0.0447 

[TRAIN] Epoch[1](10407/114412); Loss: 0.081360; Backpropagation: 0.2912 sec; Batch: 2.1213 sec
0.1463 0.1288 0.1078 0.0949 0.0864 0.0801 0.0756 0.0717 0.0684 0.0664 0.0646 0.0634 0.0627 0.0618 0.0616 0.0612 

[TRAIN] Epoch[1](10408/114412); Loss: 0.049339; Backpropagation: 0.2913 sec; Batch: 2.1244 sec
0.1187 0.1128 0.0661 0.0523 0.0440 0.0427 0.0398 0.0385 0.0367 0.0354 0.0346 0.0340 0.0338 0.0335 0.0334 0.0332 

[TRAIN] Epoch[1](10409/114412); Loss: 0.059784; Backpropagation: 0.2911 sec; Batch: 2.1156 sec
0.1247 0.1156 0.0829 0.0700 0.0580 0.0548 0.0506 0.0490 0.0471 0.0454 0.0446 0.0436 0.0432 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](10410/114412); Loss: 0.084584; Backpropagation: 0.2913 sec; Batch: 2.1182 sec
0.1704 0.1557 0.1153 0.0933 0.0829 0.0763 0.0729 0.0695 0.0680 0.0665 0.0653 0.0646 0.0638 0.0633 0.0630 0.0626 

[TRAIN] Epoch[1](10411/114412); Loss: 0.073272; Backpropagation: 0.2909 sec; Batch: 2.0769 sec
0.1392 0.1281 0.0839 0.0790 0.0715 0.0690 0.0655 0.0630 0.0614 0.0604 0.0597 0.0591 0.0586 0.0583 0.0579 0.0578 

[TRAIN] Epoch[1](10412/114412); Loss: 0.054145; Backpropagation: 0.2924 sec; Batch: 2.0793 sec
0.1235 0.1100 0.0777 0.0638 0.0535 0.0483 0.0453 0.0424 0.0406 0.0394 0.0383 0.0375 0.0370 0.0367 0.0364 0.0359 

[TRAIN] Epoch[1](10413/114412); Loss: 0.082033; Backpropagation: 0.2911 sec; Batch: 2.1205 sec
0.1559 0.1458 0.1023 0.0893 0.0833 0.0773 0.0722 0.0694 0.0678 0.0660 0.0651 0.0643 0.0638 0.0636 0.0633 0.0632 

[TRAIN] Epoch[1](10414/114412); Loss: 0.087403; Backpropagation: 0.2911 sec; Batch: 2.1201 sec
0.1488 0.1370 0.1064 0.0986 0.0903 0.0850 0.0798 0.0772 0.0753 0.0735 0.0725 0.0718 0.0713 0.0708 0.0702 0.0698 

[TRAIN] Epoch[1](10415/114412); Loss: 0.074784; Backpropagation: 0.2911 sec; Batch: 2.1026 sec
0.1412 0.1269 0.0994 0.0863 0.0767 0.0705 0.0667 0.0631 0.0613 0.0604 0.0593 0.0583 0.0575 0.0568 0.0563 0.0560 

[TRAIN] Epoch[1](10416/114412); Loss: 0.076739; Backpropagation: 0.2951 sec; Batch: 2.1236 sec
0.1736 0.1523 0.1074 0.0817 0.0712 0.0684 0.0649 0.0624 0.0594 0.0578 0.0568 0.0559 0.0550 0.0541 0.0537 0.0533 

[TRAIN] Epoch[1](10417/114412); Loss: 0.079284; Backpropagation: 0.2929 sec; Batch: 2.1169 sec
0.1373 0.1246 0.1014 0.0885 0.0801 0.0774 0.0734 0.0708 0.0686 0.0670 0.0653 0.0644 0.0632 0.0626 0.0622 0.0618 

[TRAIN] Epoch[1](10418/114412); Loss: 0.066006; Backpropagation: 0.2953 sec; Batch: 2.1235 sec
0.1447 0.1300 0.0886 0.0726 0.0634 0.0594 0.0559 0.0534 0.0517 0.0505 0.0494 0.0485 0.0478 0.0472 0.0466 0.0465 

[TRAIN] Epoch[1](10419/114412); Loss: 0.072997; Backpropagation: 0.2929 sec; Batch: 2.1206 sec
0.1448 0.1317 0.0971 0.0820 0.0724 0.0669 0.0639 0.0612 0.0596 0.0577 0.0566 0.0557 0.0552 0.0548 0.0543 0.0539 

[TRAIN] Epoch[1](10420/114412); Loss: 0.084863; Backpropagation: 0.2931 sec; Batch: 2.1085 sec
0.1480 0.1404 0.1086 0.0965 0.0848 0.0800 0.0769 0.0746 0.0725 0.0707 0.0693 0.0685 0.0676 0.0669 0.0665 0.0662 

[TRAIN] Epoch[1](10421/114412); Loss: 0.074097; Backpropagation: 0.2915 sec; Batch: 2.1157 sec
0.1234 0.1140 0.0852 0.0776 0.0726 0.0697 0.0679 0.0662 0.0652 0.0644 0.0638 0.0633 0.0631 0.0631 0.0630 0.0630 

[TRAIN] Epoch[1](10422/114412); Loss: 0.074838; Backpropagation: 0.2910 sec; Batch: 2.1290 sec
0.1218 0.1135 0.0888 0.0820 0.0756 0.0710 0.0689 0.0676 0.0658 0.0649 0.0640 0.0633 0.0630 0.0627 0.0624 0.0620 

[TRAIN] Epoch[1](10423/114412); Loss: 0.086039; Backpropagation: 0.2930 sec; Batch: 2.1204 sec
0.1545 0.1448 0.1083 0.0934 0.0852 0.0808 0.0777 0.0748 0.0730 0.0714 0.0706 0.0695 0.0688 0.0684 0.0680 0.0675 

[TRAIN] Epoch[1](10424/114412); Loss: 0.067767; Backpropagation: 0.2913 sec; Batch: 2.1151 sec
0.1357 0.1241 0.0938 0.0806 0.0688 0.0632 0.0590 0.0562 0.0542 0.0526 0.0513 0.0504 0.0495 0.0488 0.0483 0.0477 

[TRAIN] Epoch[1](10425/114412); Loss: 0.069354; Backpropagation: 0.2928 sec; Batch: 2.1270 sec
0.1193 0.1107 0.0880 0.0793 0.0718 0.0665 0.0629 0.0608 0.0592 0.0582 0.0572 0.0563 0.0556 0.0551 0.0546 0.0542 

[TRAIN] Epoch[1](10426/114412); Loss: 0.078552; Backpropagation: 0.2914 sec; Batch: 2.1164 sec
0.1395 0.1262 0.0995 0.0900 0.0814 0.0754 0.0724 0.0692 0.0671 0.0653 0.0638 0.0628 0.0620 0.0613 0.0607 0.0602 

[TRAIN] Epoch[1](10427/114412); Loss: 0.071911; Backpropagation: 0.2908 sec; Batch: 2.0771 sec
0.1439 0.1369 0.0890 0.0787 0.0724 0.0665 0.0635 0.0608 0.0585 0.0567 0.0555 0.0548 0.0541 0.0536 0.0530 0.0526 

[TRAIN] Epoch[1](10428/114412); Loss: 0.082401; Backpropagation: 0.2951 sec; Batch: 2.1226 sec
0.1305 0.1194 0.1000 0.0907 0.0838 0.0805 0.0776 0.0753 0.0735 0.0720 0.0709 0.0699 0.0693 0.0688 0.0683 0.0680 

[TRAIN] Epoch[1](10429/114412); Loss: 0.072047; Backpropagation: 0.2930 sec; Batch: 2.1195 sec
0.1431 0.1263 0.0982 0.0871 0.0762 0.0696 0.0640 0.0600 0.0576 0.0560 0.0545 0.0535 0.0525 0.0519 0.0514 0.0510 

[TRAIN] Epoch[1](10430/114412); Loss: 0.090011; Backpropagation: 0.2933 sec; Batch: 2.1227 sec
0.1521 0.1432 0.1159 0.1043 0.0942 0.0872 0.0832 0.0800 0.0772 0.0757 0.0742 0.0728 0.0714 0.0703 0.0697 0.0687 

[TRAIN] Epoch[1](10431/114412); Loss: 0.073472; Backpropagation: 0.2916 sec; Batch: 2.1201 sec
0.1663 0.1489 0.1061 0.0888 0.0725 0.0647 0.0612 0.0589 0.0551 0.0532 0.0519 0.0510 0.0502 0.0494 0.0490 0.0484 

[TRAIN] Epoch[1](10432/114412); Loss: 0.045018; Backpropagation: 0.2909 sec; Batch: 2.1192 sec
0.0817 0.0776 0.0619 0.0522 0.0479 0.0437 0.0402 0.0387 0.0371 0.0358 0.0352 0.0345 0.0340 0.0336 0.0332 0.0331 

[TRAIN] Epoch[1](10433/114412); Loss: 0.058128; Backpropagation: 0.2908 sec; Batch: 2.1188 sec
0.1144 0.1059 0.0809 0.0698 0.0628 0.0538 0.0506 0.0476 0.0465 0.0449 0.0438 0.0428 0.0421 0.0419 0.0413 0.0410 

[TRAIN] Epoch[1](10434/114412); Loss: 0.071534; Backpropagation: 0.2906 sec; Batch: 2.0761 sec
0.1395 0.1293 0.1001 0.0855 0.0733 0.0675 0.0627 0.0598 0.0574 0.0555 0.0545 0.0533 0.0525 0.0518 0.0512 0.0507 

[TRAIN] Epoch[1](10435/114412); Loss: 0.113204; Backpropagation: 0.2952 sec; Batch: 2.0858 sec
0.1983 0.1790 0.1465 0.1319 0.1183 0.1086 0.1039 0.0996 0.0966 0.0945 0.0923 0.0908 0.0892 0.0882 0.0872 0.0864 

[TRAIN] Epoch[1](10436/114412); Loss: 0.055911; Backpropagation: 0.2952 sec; Batch: 2.0830 sec
0.1338 0.1103 0.0815 0.0666 0.0553 0.0498 0.0467 0.0447 0.0426 0.0399 0.0389 0.0379 0.0373 0.0368 0.0364 0.0361 

[TRAIN] Epoch[1](10437/114412); Loss: 0.066075; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1188 0.1129 0.0809 0.0742 0.0707 0.0648 0.0619 0.0577 0.0551 0.0539 0.0525 0.0515 0.0510 0.0506 0.0505 0.0503 

[TRAIN] Epoch[1](10438/114412); Loss: 0.081107; Backpropagation: 0.2908 sec; Batch: 2.1179 sec
0.1519 0.1395 0.1131 0.0986 0.0859 0.0766 0.0723 0.0684 0.0658 0.0641 0.0626 0.0616 0.0604 0.0596 0.0589 0.0584 

[TRAIN] Epoch[1](10439/114412); Loss: 0.073230; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1239 0.1128 0.0942 0.0836 0.0738 0.0701 0.0670 0.0649 0.0631 0.0618 0.0609 0.0602 0.0595 0.0591 0.0586 0.0582 

[TRAIN] Epoch[1](10440/114412); Loss: 0.072701; Backpropagation: 0.2932 sec; Batch: 2.1235 sec
0.1524 0.1337 0.0974 0.0816 0.0736 0.0675 0.0635 0.0607 0.0582 0.0562 0.0548 0.0537 0.0531 0.0525 0.0523 0.0520 

[TRAIN] Epoch[1](10441/114412); Loss: 0.091642; Backpropagation: 0.2914 sec; Batch: 2.1191 sec
0.1636 0.1506 0.1140 0.1011 0.0942 0.0877 0.0830 0.0802 0.0782 0.0763 0.0750 0.0738 0.0731 0.0725 0.0717 0.0711 

[TRAIN] Epoch[1](10442/114412); Loss: 0.056568; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1359 0.1221 0.0767 0.0659 0.0573 0.0525 0.0475 0.0442 0.0419 0.0400 0.0387 0.0377 0.0370 0.0363 0.0358 0.0356 

[TRAIN] Epoch[1](10443/114412); Loss: 0.084773; Backpropagation: 0.2913 sec; Batch: 2.1165 sec
0.1405 0.1267 0.1060 0.0949 0.0856 0.0819 0.0789 0.0770 0.0749 0.0730 0.0714 0.0705 0.0696 0.0690 0.0684 0.0680 

[TRAIN] Epoch[1](10444/114412); Loss: 0.077137; Backpropagation: 0.2913 sec; Batch: 2.1152 sec
0.1834 0.1649 0.1156 0.0907 0.0714 0.0648 0.0601 0.0578 0.0561 0.0546 0.0538 0.0530 0.0525 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](10445/114412); Loss: 0.081612; Backpropagation: 0.2930 sec; Batch: 2.1343 sec
0.1473 0.1400 0.1009 0.0906 0.0805 0.0779 0.0733 0.0711 0.0687 0.0671 0.0662 0.0654 0.0647 0.0642 0.0639 0.0638 

[TRAIN] Epoch[1](10446/114412); Loss: 0.080267; Backpropagation: 0.2928 sec; Batch: 2.1217 sec
0.1641 0.1460 0.1141 0.0942 0.0764 0.0717 0.0690 0.0663 0.0639 0.0625 0.0611 0.0601 0.0593 0.0588 0.0584 0.0582 

[TRAIN] Epoch[1](10447/114412); Loss: 0.070919; Backpropagation: 0.2912 sec; Batch: 2.1158 sec
0.1252 0.1164 0.0783 0.0733 0.0696 0.0677 0.0659 0.0640 0.0624 0.0609 0.0597 0.0592 0.0586 0.0582 0.0578 0.0575 

[TRAIN] Epoch[1](10448/114412); Loss: 0.066244; Backpropagation: 0.2904 sec; Batch: 2.1167 sec
0.1329 0.1255 0.0892 0.0778 0.0670 0.0614 0.0569 0.0546 0.0524 0.0511 0.0501 0.0493 0.0486 0.0481 0.0477 0.0474 

[TRAIN] Epoch[1](10449/114412); Loss: 0.063648; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.1221 0.1154 0.0814 0.0733 0.0636 0.0594 0.0553 0.0534 0.0518 0.0508 0.0499 0.0492 0.0487 0.0483 0.0480 0.0477 

[TRAIN] Epoch[1](10450/114412); Loss: 0.116482; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1878 0.1746 0.1433 0.1305 0.1220 0.1150 0.1100 0.1061 0.1024 0.1006 0.0982 0.0970 0.0955 0.0944 0.0935 0.0929 

[TRAIN] Epoch[1](10451/114412); Loss: 0.079767; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.1371 0.1202 0.0995 0.0905 0.0834 0.0784 0.0740 0.0710 0.0689 0.0671 0.0661 0.0652 0.0645 0.0638 0.0633 0.0630 

[TRAIN] Epoch[1](10452/114412); Loss: 0.072922; Backpropagation: 0.2916 sec; Batch: 2.1172 sec
0.1371 0.1282 0.0958 0.0812 0.0736 0.0673 0.0642 0.0619 0.0601 0.0589 0.0580 0.0570 0.0565 0.0561 0.0555 0.0553 

[TRAIN] Epoch[1](10453/114412); Loss: 0.073400; Backpropagation: 0.2916 sec; Batch: 2.1130 sec
0.1348 0.1187 0.0958 0.0845 0.0763 0.0702 0.0667 0.0637 0.0617 0.0603 0.0590 0.0579 0.0569 0.0564 0.0562 0.0556 

[TRAIN] Epoch[1](10454/114412); Loss: 0.072514; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.1440 0.1338 0.0953 0.0853 0.0732 0.0667 0.0629 0.0595 0.0577 0.0563 0.0553 0.0546 0.0542 0.0540 0.0538 0.0535 

[TRAIN] Epoch[1](10455/114412); Loss: 0.090614; Backpropagation: 0.2954 sec; Batch: 2.1011 sec
0.1604 0.1494 0.1192 0.1065 0.0912 0.0859 0.0817 0.0789 0.0766 0.0746 0.0732 0.0719 0.0711 0.0704 0.0697 0.0691 

[TRAIN] Epoch[1](10456/114412); Loss: 0.070988; Backpropagation: 0.2953 sec; Batch: 2.1187 sec
0.1336 0.1218 0.0957 0.0840 0.0733 0.0668 0.0630 0.0604 0.0581 0.0568 0.0552 0.0544 0.0539 0.0533 0.0530 0.0525 

[TRAIN] Epoch[1](10457/114412); Loss: 0.089045; Backpropagation: 0.2916 sec; Batch: 2.1180 sec
0.1370 0.1259 0.1064 0.0994 0.0918 0.0867 0.0836 0.0814 0.0795 0.0784 0.0774 0.0767 0.0759 0.0753 0.0749 0.0744 

[TRAIN] Epoch[1](10458/114412); Loss: 0.079158; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1443 0.1285 0.1011 0.0931 0.0832 0.0760 0.0710 0.0677 0.0657 0.0645 0.0634 0.0626 0.0620 0.0614 0.0611 0.0610 

[TRAIN] Epoch[1](10459/114412); Loss: 0.061401; Backpropagation: 0.2908 sec; Batch: 2.0760 sec
0.1260 0.1166 0.0812 0.0711 0.0618 0.0566 0.0530 0.0502 0.0486 0.0471 0.0463 0.0458 0.0451 0.0446 0.0443 0.0440 

[TRAIN] Epoch[1](10460/114412); Loss: 0.064724; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1548 0.1414 0.0881 0.0731 0.0582 0.0549 0.0523 0.0502 0.0484 0.0467 0.0457 0.0450 0.0446 0.0443 0.0440 0.0437 

[TRAIN] Epoch[1](10461/114412); Loss: 0.072517; Backpropagation: 0.2911 sec; Batch: 2.1159 sec
0.1431 0.1284 0.0957 0.0836 0.0716 0.0670 0.0635 0.0609 0.0584 0.0574 0.0565 0.0557 0.0551 0.0549 0.0543 0.0540 

[TRAIN] Epoch[1](10462/114412); Loss: 0.078251; Backpropagation: 0.2911 sec; Batch: 2.1141 sec
0.1371 0.1248 0.1030 0.0902 0.0813 0.0758 0.0717 0.0693 0.0665 0.0649 0.0633 0.0622 0.0613 0.0607 0.0602 0.0598 

[TRAIN] Epoch[1](10463/114412); Loss: 0.063572; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1263 0.1139 0.0868 0.0747 0.0637 0.0587 0.0551 0.0531 0.0512 0.0498 0.0489 0.0481 0.0475 0.0469 0.0464 0.0461 

[TRAIN] Epoch[1](10464/114412); Loss: 0.078012; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1317 0.1225 0.0920 0.0852 0.0796 0.0750 0.0719 0.0697 0.0680 0.0667 0.0658 0.0650 0.0644 0.0639 0.0635 0.0632 

[TRAIN] Epoch[1](10465/114412); Loss: 0.070016; Backpropagation: 0.2911 sec; Batch: 2.1159 sec
0.1332 0.1237 0.0919 0.0847 0.0702 0.0664 0.0618 0.0598 0.0570 0.0559 0.0545 0.0535 0.0526 0.0524 0.0515 0.0511 

[TRAIN] Epoch[1](10466/114412); Loss: 0.089622; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.1963 0.1723 0.1382 0.1098 0.0933 0.0830 0.0737 0.0687 0.0682 0.0654 0.0639 0.0620 0.0611 0.0601 0.0593 0.0584 

[TRAIN] Epoch[1](10467/114412); Loss: 0.083901; Backpropagation: 0.2911 sec; Batch: 2.1020 sec
0.1351 0.1300 0.1061 0.0985 0.0880 0.0820 0.0786 0.0755 0.0733 0.0713 0.0698 0.0687 0.0676 0.0667 0.0659 0.0653 

[TRAIN] Epoch[1](10468/114412); Loss: 0.069481; Backpropagation: 0.2904 sec; Batch: 2.1135 sec
0.1317 0.1112 0.0832 0.0759 0.0699 0.0655 0.0621 0.0603 0.0589 0.0578 0.0571 0.0565 0.0560 0.0555 0.0552 0.0549 

[TRAIN] Epoch[1](10469/114412); Loss: 0.065836; Backpropagation: 0.2911 sec; Batch: 2.1140 sec
0.1368 0.1134 0.0923 0.0812 0.0727 0.0652 0.0578 0.0531 0.0510 0.0496 0.0485 0.0475 0.0467 0.0462 0.0459 0.0456 

[TRAIN] Epoch[1](10470/114412); Loss: 0.064241; Backpropagation: 0.2906 sec; Batch: 2.0762 sec
0.1385 0.1330 0.0893 0.0742 0.0612 0.0617 0.0569 0.0523 0.0491 0.0473 0.0459 0.0449 0.0444 0.0437 0.0429 0.0425 

[TRAIN] Epoch[1](10471/114412); Loss: 0.062673; Backpropagation: 0.2907 sec; Batch: 2.0771 sec
0.1140 0.1043 0.0829 0.0747 0.0650 0.0601 0.0558 0.0539 0.0521 0.0505 0.0496 0.0489 0.0483 0.0478 0.0475 0.0473 

[TRAIN] Epoch[1](10472/114412); Loss: 0.060839; Backpropagation: 0.2898 sec; Batch: 2.0762 sec
0.1294 0.1121 0.0862 0.0747 0.0643 0.0580 0.0543 0.0501 0.0477 0.0453 0.0438 0.0427 0.0420 0.0413 0.0408 0.0405 

[TRAIN] Epoch[1](10473/114412); Loss: 0.077067; Backpropagation: 0.2906 sec; Batch: 2.1176 sec
0.1588 0.1460 0.1095 0.0900 0.0743 0.0681 0.0648 0.0624 0.0607 0.0592 0.0580 0.0573 0.0567 0.0562 0.0559 0.0553 

[TRAIN] Epoch[1](10474/114412); Loss: 0.096379; Backpropagation: 0.2910 sec; Batch: 2.0970 sec
0.1393 0.1215 0.1146 0.1058 0.1002 0.0958 0.0922 0.0900 0.0884 0.0873 0.0863 0.0855 0.0846 0.0839 0.0835 0.0831 

[TRAIN] Epoch[1](10475/114412); Loss: 0.101525; Backpropagation: 0.2912 sec; Batch: 2.1153 sec
0.1536 0.1524 0.1244 0.1144 0.1069 0.1016 0.0971 0.0930 0.0891 0.0874 0.0864 0.0853 0.0845 0.0835 0.0828 0.0820 

[TRAIN] Epoch[1](10476/114412); Loss: 0.083264; Backpropagation: 0.2907 sec; Batch: 2.0763 sec
0.1625 0.1499 0.1131 0.0974 0.0839 0.0764 0.0726 0.0697 0.0673 0.0656 0.0643 0.0636 0.0624 0.0618 0.0612 0.0605 

[TRAIN] Epoch[1](10477/114412); Loss: 0.093870; Backpropagation: 0.2913 sec; Batch: 2.1154 sec
0.1463 0.1353 0.1078 0.1026 0.0983 0.0929 0.0893 0.0858 0.0839 0.0821 0.0812 0.0804 0.0799 0.0792 0.0787 0.0784 

[TRAIN] Epoch[1](10478/114412); Loss: 0.076634; Backpropagation: 0.2910 sec; Batch: 2.1170 sec
0.1426 0.1301 0.0943 0.0855 0.0774 0.0720 0.0683 0.0659 0.0641 0.0627 0.0617 0.0610 0.0605 0.0603 0.0600 0.0598 

[TRAIN] Epoch[1](10479/114412); Loss: 0.065483; Backpropagation: 0.2930 sec; Batch: 2.1158 sec
0.1189 0.1137 0.0832 0.0759 0.0683 0.0638 0.0596 0.0563 0.0541 0.0527 0.0516 0.0508 0.0502 0.0498 0.0495 0.0492 

[TRAIN] Epoch[1](10480/114412); Loss: 0.071407; Backpropagation: 0.2936 sec; Batch: 2.1178 sec
0.1301 0.1217 0.0945 0.0822 0.0727 0.0683 0.0649 0.0626 0.0598 0.0582 0.0568 0.0557 0.0546 0.0539 0.0533 0.0529 

[TRAIN] Epoch[1](10481/114412); Loss: 0.083484; Backpropagation: 0.2909 sec; Batch: 2.1148 sec
0.1440 0.1405 0.1050 0.0906 0.0835 0.0789 0.0754 0.0729 0.0711 0.0697 0.0688 0.0683 0.0674 0.0669 0.0666 0.0663 

[TRAIN] Epoch[1](10482/114412); Loss: 0.080806; Backpropagation: 0.2915 sec; Batch: 2.1181 sec
0.2185 0.1993 0.1167 0.0785 0.0698 0.0667 0.0630 0.0597 0.0563 0.0547 0.0533 0.0521 0.0517 0.0512 0.0508 0.0505 

[TRAIN] Epoch[1](10483/114412); Loss: 0.072018; Backpropagation: 0.2906 sec; Batch: 2.1161 sec
0.1436 0.1263 0.0979 0.0865 0.0723 0.0689 0.0643 0.0611 0.0583 0.0565 0.0550 0.0539 0.0528 0.0521 0.0515 0.0512 

[TRAIN] Epoch[1](10484/114412); Loss: 0.093064; Backpropagation: 0.2911 sec; Batch: 2.1158 sec
0.1746 0.1608 0.1220 0.1078 0.0938 0.0863 0.0820 0.0798 0.0776 0.0751 0.0736 0.0725 0.0718 0.0710 0.0704 0.0700 

[TRAIN] Epoch[1](10485/114412); Loss: 0.074144; Backpropagation: 0.2911 sec; Batch: 2.1152 sec
0.1341 0.1314 0.0979 0.0888 0.0755 0.0704 0.0655 0.0628 0.0603 0.0590 0.0580 0.0574 0.0569 0.0564 0.0561 0.0559 

[TRAIN] Epoch[1](10486/114412); Loss: 0.085010; Backpropagation: 0.2912 sec; Batch: 2.1155 sec
0.1556 0.1364 0.1007 0.0924 0.0853 0.0811 0.0771 0.0748 0.0731 0.0715 0.0706 0.0697 0.0688 0.0683 0.0677 0.0672 

[TRAIN] Epoch[1](10487/114412); Loss: 0.081052; Backpropagation: 0.2952 sec; Batch: 2.1212 sec
0.1573 0.1463 0.1150 0.1010 0.0857 0.0760 0.0700 0.0673 0.0651 0.0628 0.0611 0.0596 0.0585 0.0578 0.0569 0.0563 

[TRAIN] Epoch[1](10488/114412); Loss: 0.064135; Backpropagation: 0.2936 sec; Batch: 2.1213 sec
0.1146 0.1104 0.0908 0.0803 0.0702 0.0641 0.0586 0.0548 0.0522 0.0499 0.0488 0.0476 0.0469 0.0462 0.0457 0.0451 

[TRAIN] Epoch[1](10489/114412); Loss: 0.067536; Backpropagation: 0.2933 sec; Batch: 2.1203 sec
0.1297 0.1227 0.0803 0.0694 0.0645 0.0626 0.0609 0.0581 0.0570 0.0559 0.0551 0.0545 0.0534 0.0528 0.0520 0.0516 

[TRAIN] Epoch[1](10490/114412); Loss: 0.074634; Backpropagation: 0.2955 sec; Batch: 2.1245 sec
0.1221 0.1146 0.0908 0.0842 0.0776 0.0725 0.0688 0.0671 0.0649 0.0637 0.0627 0.0619 0.0614 0.0609 0.0606 0.0603 

[TRAIN] Epoch[1](10491/114412); Loss: 0.069314; Backpropagation: 0.2926 sec; Batch: 2.1173 sec
0.1278 0.1097 0.0872 0.0796 0.0701 0.0665 0.0627 0.0610 0.0588 0.0575 0.0561 0.0556 0.0549 0.0543 0.0538 0.0534 

[TRAIN] Epoch[1](10492/114412); Loss: 0.074979; Backpropagation: 0.2908 sec; Batch: 2.1152 sec
0.1480 0.1266 0.1001 0.0859 0.0777 0.0712 0.0666 0.0647 0.0617 0.0601 0.0583 0.0575 0.0563 0.0555 0.0550 0.0545 

[TRAIN] Epoch[1](10493/114412); Loss: 0.082653; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1458 0.1411 0.1056 0.0942 0.0829 0.0780 0.0740 0.0716 0.0694 0.0683 0.0671 0.0661 0.0653 0.0648 0.0644 0.0639 

[TRAIN] Epoch[1](10494/114412); Loss: 0.069857; Backpropagation: 0.2909 sec; Batch: 2.1190 sec
0.1155 0.1162 0.0965 0.0878 0.0744 0.0681 0.0635 0.0606 0.0584 0.0566 0.0552 0.0542 0.0535 0.0528 0.0524 0.0520 

[TRAIN] Epoch[1](10495/114412); Loss: 0.077700; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1298 0.1166 0.0990 0.0923 0.0823 0.0772 0.0722 0.0693 0.0674 0.0659 0.0643 0.0630 0.0621 0.0611 0.0606 0.0601 

[TRAIN] Epoch[1](10496/114412); Loss: 0.069576; Backpropagation: 0.2909 sec; Batch: 2.1162 sec
0.1491 0.1321 0.0920 0.0797 0.0701 0.0640 0.0604 0.0574 0.0553 0.0535 0.0521 0.0510 0.0500 0.0494 0.0489 0.0482 

[TRAIN] Epoch[1](10497/114412); Loss: 0.115717; Backpropagation: 0.2924 sec; Batch: 2.1157 sec
0.2067 0.1867 0.1396 0.1285 0.1129 0.1060 0.1037 0.1008 0.0995 0.0976 0.0968 0.0957 0.0951 0.0946 0.0939 0.0935 

[TRAIN] Epoch[1](10498/114412); Loss: 0.075360; Backpropagation: 0.2926 sec; Batch: 2.1176 sec
0.1717 0.1586 0.1112 0.0885 0.0727 0.0666 0.0607 0.0578 0.0558 0.0543 0.0529 0.0521 0.0513 0.0508 0.0505 0.0502 

[TRAIN] Epoch[1](10499/114412); Loss: 0.076421; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1381 0.1252 0.0924 0.0826 0.0770 0.0722 0.0698 0.0675 0.0657 0.0642 0.0630 0.0623 0.0614 0.0609 0.0605 0.0601 

[TRAIN] Epoch[1](10500/114412); Loss: 0.075857; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1516 0.1452 0.0958 0.0886 0.0763 0.0699 0.0657 0.0631 0.0609 0.0590 0.0579 0.0570 0.0565 0.0559 0.0553 0.0551 

[TRAIN] Epoch[1](10501/114412); Loss: 0.090503; Backpropagation: 0.2913 sec; Batch: 2.1180 sec
0.1594 0.1505 0.1174 0.1032 0.0891 0.0839 0.0806 0.0790 0.0766 0.0753 0.0740 0.0729 0.0723 0.0718 0.0713 0.0707 

[TRAIN] Epoch[1](10502/114412); Loss: 0.085257; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.1491 0.1371 0.1017 0.0932 0.0837 0.0806 0.0775 0.0752 0.0736 0.0723 0.0714 0.0707 0.0700 0.0697 0.0693 0.0690 

[TRAIN] Epoch[1](10503/114412); Loss: 0.074933; Backpropagation: 0.2911 sec; Batch: 2.1209 sec
0.1564 0.1435 0.0943 0.0803 0.0741 0.0701 0.0666 0.0633 0.0610 0.0590 0.0573 0.0561 0.0551 0.0545 0.0539 0.0535 

[TRAIN] Epoch[1](10504/114412); Loss: 0.127173; Backpropagation: 0.2930 sec; Batch: 2.1204 sec
0.2016 0.1922 0.1616 0.1447 0.1325 0.1240 0.1188 0.1151 0.1116 0.1090 0.1071 0.1058 0.1044 0.1032 0.1021 0.1012 

[TRAIN] Epoch[1](10505/114412); Loss: 0.067646; Backpropagation: 0.2911 sec; Batch: 2.1193 sec
0.1461 0.1349 0.0959 0.0808 0.0675 0.0614 0.0563 0.0543 0.0521 0.0504 0.0491 0.0479 0.0472 0.0467 0.0462 0.0456 

[TRAIN] Epoch[1](10506/114412); Loss: 0.063231; Backpropagation: 0.2930 sec; Batch: 2.1200 sec
0.1220 0.1169 0.0812 0.0735 0.0642 0.0598 0.0569 0.0533 0.0516 0.0500 0.0488 0.0478 0.0473 0.0466 0.0462 0.0458 

[TRAIN] Epoch[1](10507/114412); Loss: 0.067581; Backpropagation: 0.2919 sec; Batch: 2.1202 sec
0.1337 0.1323 0.0838 0.0786 0.0666 0.0621 0.0588 0.0559 0.0543 0.0525 0.0514 0.0509 0.0506 0.0503 0.0498 0.0497 

[TRAIN] Epoch[1](10508/114412); Loss: 0.066230; Backpropagation: 0.2930 sec; Batch: 2.1268 sec
0.1586 0.1518 0.0940 0.0725 0.0635 0.0568 0.0529 0.0505 0.0484 0.0464 0.0455 0.0447 0.0441 0.0437 0.0434 0.0429 

[TRAIN] Epoch[1](10509/114412); Loss: 0.098773; Backpropagation: 0.2910 sec; Batch: 2.1207 sec
0.1722 0.1581 0.1283 0.1140 0.0995 0.0931 0.0888 0.0856 0.0833 0.0821 0.0809 0.0801 0.0794 0.0787 0.0783 0.0778 

[TRAIN] Epoch[1](10510/114412); Loss: 0.076022; Backpropagation: 0.2911 sec; Batch: 2.0967 sec
0.1309 0.1258 0.0957 0.0853 0.0802 0.0764 0.0710 0.0675 0.0647 0.0628 0.0617 0.0604 0.0596 0.0587 0.0581 0.0576 

[TRAIN] Epoch[1](10511/114412); Loss: 0.066193; Backpropagation: 0.2913 sec; Batch: 2.0760 sec
0.1358 0.1181 0.0855 0.0763 0.0656 0.0607 0.0574 0.0552 0.0534 0.0522 0.0512 0.0505 0.0498 0.0495 0.0491 0.0487 

[TRAIN] Epoch[1](10512/114412); Loss: 0.076000; Backpropagation: 0.2908 sec; Batch: 2.1155 sec
0.1570 0.1425 0.1025 0.0898 0.0769 0.0687 0.0657 0.0618 0.0599 0.0583 0.0572 0.0564 0.0556 0.0549 0.0545 0.0542 

[TRAIN] Epoch[1](10513/114412); Loss: 0.070619; Backpropagation: 0.2929 sec; Batch: 2.1157 sec
0.1431 0.1320 0.0957 0.0835 0.0695 0.0646 0.0609 0.0581 0.0560 0.0544 0.0535 0.0527 0.0520 0.0515 0.0513 0.0509 

[TRAIN] Epoch[1](10514/114412); Loss: 0.067521; Backpropagation: 0.2953 sec; Batch: 2.1231 sec
0.1665 0.1539 0.1017 0.0750 0.0658 0.0568 0.0526 0.0501 0.0482 0.0467 0.0452 0.0445 0.0439 0.0434 0.0431 0.0428 

[TRAIN] Epoch[1](10515/114412); Loss: 0.059999; Backpropagation: 0.2915 sec; Batch: 2.1196 sec
0.1236 0.1196 0.0898 0.0727 0.0593 0.0537 0.0501 0.0475 0.0458 0.0446 0.0435 0.0429 0.0424 0.0419 0.0415 0.0411 

[TRAIN] Epoch[1](10516/114412); Loss: 0.062738; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1292 0.1238 0.0848 0.0697 0.0606 0.0565 0.0536 0.0514 0.0498 0.0485 0.0475 0.0468 0.0460 0.0457 0.0452 0.0448 

[TRAIN] Epoch[1](10517/114412); Loss: 0.070283; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1242 0.1162 0.0883 0.0775 0.0731 0.0674 0.0637 0.0614 0.0598 0.0584 0.0573 0.0567 0.0559 0.0553 0.0548 0.0545 

[TRAIN] Epoch[1](10518/114412); Loss: 0.074010; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1349 0.1218 0.0967 0.0873 0.0768 0.0710 0.0674 0.0643 0.0620 0.0602 0.0589 0.0579 0.0571 0.0565 0.0559 0.0555 

[TRAIN] Epoch[1](10519/114412); Loss: 0.074881; Backpropagation: 0.2913 sec; Batch: 2.1032 sec
0.1378 0.1233 0.0931 0.0854 0.0756 0.0709 0.0672 0.0646 0.0630 0.0618 0.0609 0.0601 0.0593 0.0588 0.0582 0.0580 

[TRAIN] Epoch[1](10520/114412); Loss: 0.077617; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1424 0.1285 0.0922 0.0851 0.0776 0.0739 0.0703 0.0683 0.0667 0.0653 0.0642 0.0629 0.0621 0.0612 0.0608 0.0603 

[TRAIN] Epoch[1](10521/114412); Loss: 0.066391; Backpropagation: 0.2909 sec; Batch: 2.0819 sec
0.1327 0.1256 0.0946 0.0762 0.0696 0.0630 0.0572 0.0553 0.0526 0.0509 0.0496 0.0485 0.0476 0.0468 0.0463 0.0460 

[TRAIN] Epoch[1](10522/114412); Loss: 0.063074; Backpropagation: 0.2908 sec; Batch: 2.0766 sec
0.1307 0.1214 0.0833 0.0726 0.0620 0.0577 0.0545 0.0519 0.0496 0.0484 0.0475 0.0468 0.0462 0.0458 0.0454 0.0452 

[TRAIN] Epoch[1](10523/114412); Loss: 0.060417; Backpropagation: 0.2909 sec; Batch: 2.0786 sec
0.1218 0.1086 0.0819 0.0706 0.0630 0.0569 0.0528 0.0507 0.0485 0.0471 0.0458 0.0449 0.0442 0.0438 0.0432 0.0428 

[TRAIN] Epoch[1](10524/114412); Loss: 0.064491; Backpropagation: 0.2933 sec; Batch: 2.1186 sec
0.1060 0.1011 0.0880 0.0795 0.0697 0.0639 0.0594 0.0563 0.0542 0.0528 0.0518 0.0510 0.0503 0.0498 0.0492 0.0488 

[TRAIN] Epoch[1](10525/114412); Loss: 0.087866; Backpropagation: 0.2956 sec; Batch: 2.1371 sec
0.1968 0.1682 0.1268 0.1063 0.0885 0.0800 0.0749 0.0702 0.0677 0.0654 0.0635 0.0618 0.0604 0.0594 0.0583 0.0576 

[TRAIN] Epoch[1](10526/114412); Loss: 0.079196; Backpropagation: 0.2906 sec; Batch: 2.1188 sec
0.1857 0.1692 0.1170 0.0963 0.0774 0.0681 0.0648 0.0614 0.0583 0.0562 0.0543 0.0533 0.0524 0.0515 0.0509 0.0502 

[TRAIN] Epoch[1](10527/114412); Loss: 0.061657; Backpropagation: 0.2910 sec; Batch: 2.1161 sec
0.1355 0.1135 0.0846 0.0733 0.0611 0.0557 0.0527 0.0501 0.0480 0.0469 0.0458 0.0451 0.0444 0.0438 0.0432 0.0428 

[TRAIN] Epoch[1](10528/114412); Loss: 0.071248; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1246 0.1130 0.0950 0.0845 0.0747 0.0697 0.0647 0.0620 0.0596 0.0582 0.0570 0.0564 0.0557 0.0552 0.0550 0.0546 

[TRAIN] Epoch[1](10529/114412); Loss: 0.089159; Backpropagation: 0.2929 sec; Batch: 2.1190 sec
0.1411 0.1296 0.1105 0.1017 0.0923 0.0882 0.0835 0.0809 0.0788 0.0771 0.0758 0.0747 0.0738 0.0733 0.0727 0.0724 

[TRAIN] Epoch[1](10530/114412); Loss: 0.043196; Backpropagation: 0.2914 sec; Batch: 2.1204 sec
0.0916 0.0813 0.0640 0.0515 0.0422 0.0404 0.0358 0.0347 0.0326 0.0321 0.0316 0.0310 0.0309 0.0305 0.0305 0.0304 

[TRAIN] Epoch[1](10531/114412); Loss: 0.085097; Backpropagation: 0.2913 sec; Batch: 2.0774 sec
0.1533 0.1433 0.1120 0.1005 0.0885 0.0839 0.0787 0.0742 0.0719 0.0693 0.0670 0.0660 0.0646 0.0638 0.0626 0.0620 

[TRAIN] Epoch[1](10532/114412); Loss: 0.078871; Backpropagation: 0.2910 sec; Batch: 2.1158 sec
0.1661 0.1473 0.1081 0.0916 0.0769 0.0708 0.0675 0.0645 0.0625 0.0608 0.0595 0.0585 0.0577 0.0572 0.0566 0.0565 

[TRAIN] Epoch[1](10533/114412); Loss: 0.096149; Backpropagation: 0.2953 sec; Batch: 2.1180 sec
0.1734 0.1629 0.1185 0.1074 0.0951 0.0900 0.0860 0.0830 0.0811 0.0800 0.0787 0.0776 0.0771 0.0764 0.0759 0.0754 

[TRAIN] Epoch[1](10534/114412); Loss: 0.089895; Backpropagation: 0.2952 sec; Batch: 2.1221 sec
0.1599 0.1465 0.1149 0.1056 0.0937 0.0866 0.0818 0.0784 0.0759 0.0742 0.0728 0.0715 0.0704 0.0694 0.0687 0.0678 

[TRAIN] Epoch[1](10535/114412); Loss: 0.060819; Backpropagation: 0.2954 sec; Batch: 2.0901 sec
0.1194 0.1095 0.0829 0.0744 0.0665 0.0584 0.0544 0.0509 0.0488 0.0475 0.0460 0.0447 0.0434 0.0427 0.0420 0.0415 

[TRAIN] Epoch[1](10536/114412); Loss: 0.100884; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1527 0.1462 0.1212 0.1147 0.1084 0.1016 0.0967 0.0926 0.0903 0.0879 0.0869 0.0851 0.0842 0.0828 0.0818 0.0810 

[TRAIN] Epoch[1](10537/114412); Loss: 0.095802; Backpropagation: 0.2907 sec; Batch: 2.1159 sec
0.1513 0.1462 0.1158 0.1072 0.0996 0.0939 0.0900 0.0874 0.0847 0.0832 0.0813 0.0802 0.0790 0.0783 0.0776 0.0772 

[TRAIN] Epoch[1](10538/114412); Loss: 0.093268; Backpropagation: 0.2930 sec; Batch: 2.1220 sec
0.2315 0.2108 0.1493 0.1184 0.0938 0.0795 0.0728 0.0676 0.0641 0.0614 0.0597 0.0586 0.0573 0.0565 0.0558 0.0552 

[TRAIN] Epoch[1](10539/114412); Loss: 0.080737; Backpropagation: 0.2910 sec; Batch: 2.1144 sec
0.1314 0.1222 0.0970 0.0899 0.0835 0.0787 0.0748 0.0723 0.0704 0.0692 0.0683 0.0677 0.0671 0.0668 0.0664 0.0661 

[TRAIN] Epoch[1](10540/114412); Loss: 0.070308; Backpropagation: 0.2910 sec; Batch: 2.1186 sec
0.1303 0.1110 0.0966 0.0828 0.0752 0.0682 0.0647 0.0611 0.0585 0.0564 0.0550 0.0544 0.0535 0.0529 0.0525 0.0520 

[TRAIN] Epoch[1](10541/114412); Loss: 0.072967; Backpropagation: 0.2911 sec; Batch: 2.1174 sec
0.1219 0.1166 0.0956 0.0852 0.0779 0.0713 0.0663 0.0641 0.0616 0.0603 0.0592 0.0583 0.0578 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](10542/114412); Loss: 0.103675; Backpropagation: 0.2914 sec; Batch: 2.1144 sec
0.1869 0.1706 0.1379 0.1230 0.1084 0.0984 0.0929 0.0898 0.0868 0.0846 0.0826 0.0814 0.0802 0.0791 0.0783 0.0776 

[TRAIN] Epoch[1](10543/114412); Loss: 0.056277; Backpropagation: 0.2912 sec; Batch: 2.1212 sec
0.1039 0.0999 0.0682 0.0627 0.0572 0.0527 0.0498 0.0478 0.0465 0.0456 0.0450 0.0447 0.0444 0.0441 0.0441 0.0439 

[TRAIN] Epoch[1](10544/114412); Loss: 0.060304; Backpropagation: 0.2906 sec; Batch: 2.0764 sec
0.1271 0.1255 0.0794 0.0694 0.0596 0.0542 0.0511 0.0488 0.0472 0.0456 0.0445 0.0436 0.0430 0.0422 0.0419 0.0417 

[TRAIN] Epoch[1](10545/114412); Loss: 0.063184; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1425 0.1310 0.0887 0.0736 0.0630 0.0564 0.0528 0.0502 0.0478 0.0463 0.0450 0.0441 0.0433 0.0425 0.0420 0.0418 

[TRAIN] Epoch[1](10546/114412); Loss: 0.091810; Backpropagation: 0.2912 sec; Batch: 2.1084 sec
0.1634 0.1578 0.1283 0.1118 0.0951 0.0847 0.0799 0.0767 0.0749 0.0735 0.0724 0.0714 0.0705 0.0699 0.0695 0.0692 

[TRAIN] Epoch[1](10547/114412); Loss: 0.085277; Backpropagation: 0.2911 sec; Batch: 2.1164 sec
0.1280 0.1231 0.1104 0.1003 0.0873 0.0817 0.0784 0.0764 0.0750 0.0741 0.0731 0.0725 0.0717 0.0712 0.0707 0.0704 

[TRAIN] Epoch[1](10548/114412); Loss: 0.071473; Backpropagation: 0.2927 sec; Batch: 2.1185 sec
0.1301 0.1190 0.0839 0.0778 0.0731 0.0683 0.0655 0.0636 0.0616 0.0598 0.0585 0.0577 0.0569 0.0563 0.0558 0.0555 

[TRAIN] Epoch[1](10549/114412); Loss: 0.057211; Backpropagation: 0.2930 sec; Batch: 2.1170 sec
0.1218 0.1121 0.0805 0.0710 0.0568 0.0537 0.0492 0.0466 0.0440 0.0425 0.0411 0.0401 0.0396 0.0392 0.0388 0.0384 

[TRAIN] Epoch[1](10550/114412); Loss: 0.087453; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.2037 0.1834 0.1125 0.0819 0.0832 0.0753 0.0733 0.0699 0.0677 0.0659 0.0650 0.0643 0.0637 0.0632 0.0632 0.0629 

[TRAIN] Epoch[1](10551/114412); Loss: 0.081449; Backpropagation: 0.2920 sec; Batch: 2.1195 sec
0.1360 0.1288 0.1078 0.0950 0.0841 0.0786 0.0750 0.0720 0.0699 0.0682 0.0669 0.0656 0.0648 0.0640 0.0634 0.0631 

[TRAIN] Epoch[1](10552/114412); Loss: 0.068203; Backpropagation: 0.2923 sec; Batch: 2.1204 sec
0.1267 0.1105 0.0885 0.0803 0.0702 0.0654 0.0619 0.0593 0.0570 0.0557 0.0545 0.0536 0.0528 0.0521 0.0516 0.0512 

[TRAIN] Epoch[1](10553/114412); Loss: 0.060303; Backpropagation: 0.2911 sec; Batch: 2.1137 sec
0.1423 0.1260 0.0828 0.0714 0.0620 0.0539 0.0487 0.0461 0.0438 0.0427 0.0418 0.0414 0.0412 0.0406 0.0404 0.0399 

[TRAIN] Epoch[1](10554/114412); Loss: 0.080918; Backpropagation: 0.2911 sec; Batch: 2.1187 sec
0.1633 0.1498 0.1023 0.0841 0.0748 0.0725 0.0695 0.0675 0.0656 0.0652 0.0642 0.0638 0.0634 0.0631 0.0630 0.0628 

[TRAIN] Epoch[1](10555/114412); Loss: 0.079116; Backpropagation: 0.2932 sec; Batch: 2.1199 sec
0.1472 0.1403 0.1005 0.0845 0.0760 0.0722 0.0700 0.0678 0.0660 0.0650 0.0640 0.0634 0.0628 0.0625 0.0621 0.0616 

[TRAIN] Epoch[1](10556/114412); Loss: 0.084524; Backpropagation: 0.2910 sec; Batch: 2.1170 sec
0.1544 0.1423 0.1106 0.0963 0.0856 0.0804 0.0756 0.0727 0.0707 0.0686 0.0675 0.0670 0.0658 0.0654 0.0650 0.0646 

[TRAIN] Epoch[1](10557/114412); Loss: 0.085728; Backpropagation: 0.2951 sec; Batch: 2.1207 sec
0.1507 0.1317 0.1113 0.0984 0.0893 0.0824 0.0779 0.0750 0.0731 0.0716 0.0705 0.0696 0.0684 0.0677 0.0671 0.0668 

[TRAIN] Epoch[1](10558/114412); Loss: 0.082861; Backpropagation: 0.2953 sec; Batch: 2.1204 sec
0.1412 0.1307 0.1010 0.0918 0.0842 0.0797 0.0770 0.0742 0.0723 0.0705 0.0692 0.0682 0.0673 0.0666 0.0662 0.0658 

[TRAIN] Epoch[1](10559/114412); Loss: 0.063539; Backpropagation: 0.2926 sec; Batch: 2.1201 sec
0.1229 0.1148 0.0916 0.0744 0.0667 0.0600 0.0562 0.0533 0.0508 0.0491 0.0479 0.0471 0.0461 0.0457 0.0452 0.0447 

[TRAIN] Epoch[1](10560/114412); Loss: 0.085735; Backpropagation: 0.2905 sec; Batch: 2.1202 sec
0.1452 0.1333 0.1054 0.0947 0.0898 0.0830 0.0794 0.0767 0.0745 0.0732 0.0715 0.0706 0.0696 0.0689 0.0682 0.0676 

[TRAIN] Epoch[1](10561/114412); Loss: 0.079765; Backpropagation: 0.2906 sec; Batch: 2.1170 sec
0.1455 0.1306 0.1094 0.0874 0.0814 0.0767 0.0722 0.0697 0.0672 0.0654 0.0640 0.0632 0.0620 0.0612 0.0605 0.0599 

[TRAIN] Epoch[1](10562/114412); Loss: 0.075498; Backpropagation: 0.2906 sec; Batch: 2.0772 sec
0.1301 0.1139 0.0938 0.0853 0.0773 0.0731 0.0690 0.0665 0.0651 0.0638 0.0630 0.0623 0.0619 0.0613 0.0610 0.0605 

[TRAIN] Epoch[1](10563/114412); Loss: 0.074563; Backpropagation: 0.2949 sec; Batch: 2.1199 sec
0.1415 0.1314 0.0961 0.0843 0.0726 0.0675 0.0646 0.0628 0.0615 0.0605 0.0594 0.0589 0.0584 0.0581 0.0578 0.0576 

[TRAIN] Epoch[1](10564/114412); Loss: 0.074068; Backpropagation: 0.2930 sec; Batch: 2.1220 sec
0.1390 0.1316 0.0954 0.0846 0.0739 0.0687 0.0651 0.0631 0.0611 0.0598 0.0586 0.0580 0.0573 0.0568 0.0563 0.0560 

[TRAIN] Epoch[1](10565/114412); Loss: 0.073788; Backpropagation: 0.2912 sec; Batch: 2.1159 sec
0.1291 0.1189 0.0923 0.0836 0.0766 0.0714 0.0676 0.0653 0.0633 0.0618 0.0604 0.0594 0.0585 0.0579 0.0575 0.0570 

[TRAIN] Epoch[1](10566/114412); Loss: 0.064556; Backpropagation: 0.2906 sec; Batch: 2.0789 sec
0.1147 0.1055 0.0822 0.0734 0.0652 0.0611 0.0582 0.0559 0.0541 0.0531 0.0525 0.0519 0.0516 0.0514 0.0511 0.0510 

[TRAIN] Epoch[1](10567/114412); Loss: 0.085112; Backpropagation: 0.2909 sec; Batch: 2.1242 sec
0.1788 0.1648 0.1187 0.0932 0.0791 0.0740 0.0707 0.0690 0.0674 0.0660 0.0652 0.0641 0.0635 0.0627 0.0623 0.0620 

[TRAIN] Epoch[1](10568/114412); Loss: 0.066547; Backpropagation: 0.2910 sec; Batch: 2.1228 sec
0.1161 0.1152 0.0888 0.0748 0.0683 0.0622 0.0591 0.0570 0.0553 0.0544 0.0535 0.0530 0.0523 0.0518 0.0516 0.0514 

[TRAIN] Epoch[1](10569/114412); Loss: 0.069775; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1179 0.1113 0.0899 0.0827 0.0726 0.0673 0.0638 0.0615 0.0598 0.0585 0.0570 0.0561 0.0553 0.0547 0.0542 0.0538 

[TRAIN] Epoch[1](10570/114412); Loss: 0.100555; Backpropagation: 0.2905 sec; Batch: 2.1169 sec
0.1711 0.1576 0.1250 0.1101 0.1003 0.0949 0.0918 0.0892 0.0876 0.0860 0.0846 0.0835 0.0829 0.0820 0.0815 0.0810 

[TRAIN] Epoch[1](10571/114412); Loss: 0.084006; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1617 0.1528 0.1123 0.0951 0.0840 0.0787 0.0736 0.0702 0.0681 0.0665 0.0653 0.0644 0.0635 0.0630 0.0626 0.0623 

[TRAIN] Epoch[1](10572/114412); Loss: 0.100345; Backpropagation: 0.2930 sec; Batch: 2.1197 sec
0.1521 0.1443 0.1148 0.1065 0.1015 0.0974 0.0948 0.0927 0.0908 0.0895 0.0881 0.0873 0.0867 0.0866 0.0863 0.0861 

[TRAIN] Epoch[1](10573/114412); Loss: 0.069477; Backpropagation: 0.2915 sec; Batch: 2.1214 sec
0.1310 0.1190 0.0960 0.0848 0.0713 0.0670 0.0617 0.0591 0.0573 0.0549 0.0536 0.0526 0.0516 0.0511 0.0506 0.0501 

[TRAIN] Epoch[1](10574/114412); Loss: 0.066430; Backpropagation: 0.2902 sec; Batch: 2.1156 sec
0.1263 0.1103 0.0882 0.0781 0.0679 0.0616 0.0590 0.0559 0.0546 0.0533 0.0527 0.0520 0.0513 0.0508 0.0505 0.0503 

[TRAIN] Epoch[1](10575/114412); Loss: 0.086645; Backpropagation: 0.2931 sec; Batch: 2.1160 sec
0.1648 0.1466 0.1134 0.0974 0.0885 0.0816 0.0774 0.0740 0.0719 0.0701 0.0689 0.0679 0.0670 0.0663 0.0656 0.0650 

[TRAIN] Epoch[1](10576/114412); Loss: 0.070016; Backpropagation: 0.2908 sec; Batch: 2.1143 sec
0.1229 0.1117 0.0921 0.0848 0.0718 0.0682 0.0641 0.0613 0.0590 0.0575 0.0561 0.0554 0.0546 0.0541 0.0536 0.0531 

[TRAIN] Epoch[1](10577/114412); Loss: 0.099415; Backpropagation: 0.2911 sec; Batch: 2.0774 sec
0.1824 0.1665 0.1291 0.1153 0.1018 0.0951 0.0904 0.0862 0.0834 0.0812 0.0792 0.0779 0.0768 0.0760 0.0750 0.0743 

[TRAIN] Epoch[1](10578/114412); Loss: 0.087286; Backpropagation: 0.2917 sec; Batch: 2.1167 sec
0.1402 0.1389 0.1091 0.0992 0.0905 0.0858 0.0810 0.0789 0.0762 0.0742 0.0726 0.0716 0.0705 0.0698 0.0695 0.0687 

[TRAIN] Epoch[1](10579/114412); Loss: 0.101178; Backpropagation: 0.2914 sec; Batch: 2.0783 sec
0.1547 0.1440 0.1262 0.1177 0.1046 0.1008 0.0955 0.0922 0.0903 0.0879 0.0865 0.0852 0.0844 0.0836 0.0829 0.0823 

[TRAIN] Epoch[1](10580/114412); Loss: 0.063650; Backpropagation: 0.2929 sec; Batch: 2.1173 sec
0.1415 0.1299 0.0849 0.0682 0.0612 0.0568 0.0541 0.0508 0.0488 0.0476 0.0469 0.0462 0.0458 0.0455 0.0452 0.0450 

[TRAIN] Epoch[1](10581/114412); Loss: 0.057232; Backpropagation: 0.2929 sec; Batch: 2.1223 sec
0.0993 0.0974 0.0769 0.0679 0.0599 0.0551 0.0514 0.0492 0.0474 0.0461 0.0454 0.0448 0.0442 0.0439 0.0435 0.0432 

[TRAIN] Epoch[1](10582/114412); Loss: 0.070748; Backpropagation: 0.2909 sec; Batch: 2.1161 sec
0.1550 0.1398 0.0970 0.0816 0.0702 0.0640 0.0599 0.0571 0.0549 0.0526 0.0516 0.0507 0.0501 0.0496 0.0491 0.0487 

[TRAIN] Epoch[1](10583/114412); Loss: 0.093151; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1883 0.1756 0.1295 0.1076 0.0929 0.0848 0.0808 0.0768 0.0743 0.0720 0.0703 0.0692 0.0684 0.0674 0.0665 0.0660 

[TRAIN] Epoch[1](10584/114412); Loss: 0.094732; Backpropagation: 0.2909 sec; Batch: 2.0892 sec
0.1490 0.1375 0.1127 0.1041 0.0958 0.0910 0.0879 0.0861 0.0844 0.0831 0.0822 0.0814 0.0808 0.0803 0.0799 0.0796 

[TRAIN] Epoch[1](10585/114412); Loss: 0.077271; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1524 0.1292 0.1045 0.0841 0.0740 0.0707 0.0673 0.0661 0.0638 0.0626 0.0618 0.0612 0.0604 0.0598 0.0594 0.0591 

[TRAIN] Epoch[1](10586/114412); Loss: 0.053557; Backpropagation: 0.2908 sec; Batch: 2.1177 sec
0.1013 0.0944 0.0722 0.0625 0.0549 0.0513 0.0478 0.0457 0.0438 0.0425 0.0416 0.0408 0.0402 0.0398 0.0393 0.0390 

[TRAIN] Epoch[1](10587/114412); Loss: 0.094640; Backpropagation: 0.2926 sec; Batch: 2.1188 sec
0.1750 0.1656 0.1252 0.1062 0.0952 0.0884 0.0841 0.0807 0.0785 0.0767 0.0753 0.0741 0.0732 0.0724 0.0720 0.0716 

[TRAIN] Epoch[1](10588/114412); Loss: 0.061323; Backpropagation: 0.2928 sec; Batch: 2.1172 sec
0.1204 0.1073 0.0798 0.0683 0.0610 0.0568 0.0538 0.0514 0.0500 0.0489 0.0482 0.0476 0.0471 0.0471 0.0468 0.0468 

[TRAIN] Epoch[1](10589/114412); Loss: 0.086206; Backpropagation: 0.2912 sec; Batch: 2.1205 sec
0.1563 0.1341 0.1090 0.0999 0.0908 0.0865 0.0817 0.0775 0.0740 0.0717 0.0697 0.0679 0.0667 0.0654 0.0643 0.0637 

[TRAIN] Epoch[1](10590/114412); Loss: 0.064692; Backpropagation: 0.2910 sec; Batch: 2.1137 sec
0.1246 0.1108 0.0778 0.0723 0.0647 0.0619 0.0586 0.0558 0.0541 0.0526 0.0520 0.0512 0.0503 0.0498 0.0494 0.0490 

[TRAIN] Epoch[1](10591/114412); Loss: 0.081750; Backpropagation: 0.2911 sec; Batch: 2.1214 sec
0.1541 0.1352 0.1053 0.0994 0.0852 0.0780 0.0729 0.0699 0.0675 0.0657 0.0645 0.0633 0.0625 0.0619 0.0615 0.0611 

[TRAIN] Epoch[1](10592/114412); Loss: 0.087598; Backpropagation: 0.2908 sec; Batch: 2.1081 sec
0.2141 0.2030 0.1372 0.1054 0.0774 0.0693 0.0680 0.0649 0.0616 0.0599 0.0586 0.0578 0.0570 0.0562 0.0556 0.0553 

[TRAIN] Epoch[1](10593/114412); Loss: 0.060990; Backpropagation: 0.2909 sec; Batch: 2.1153 sec
0.1267 0.1137 0.0828 0.0739 0.0618 0.0568 0.0521 0.0498 0.0480 0.0467 0.0457 0.0447 0.0440 0.0435 0.0429 0.0427 

[TRAIN] Epoch[1](10594/114412); Loss: 0.077740; Backpropagation: 0.2930 sec; Batch: 2.1188 sec
0.1380 0.1297 0.1000 0.0918 0.0816 0.0752 0.0702 0.0681 0.0652 0.0635 0.0622 0.0612 0.0602 0.0595 0.0588 0.0584 

[TRAIN] Epoch[1](10595/114412); Loss: 0.087081; Backpropagation: 0.2909 sec; Batch: 2.1161 sec
0.1786 0.1641 0.1186 0.0976 0.0853 0.0780 0.0742 0.0721 0.0699 0.0679 0.0666 0.0655 0.0647 0.0640 0.0635 0.0628 

[TRAIN] Epoch[1](10596/114412); Loss: 0.083626; Backpropagation: 0.2910 sec; Batch: 2.1125 sec
0.1321 0.1108 0.1012 0.0935 0.0871 0.0817 0.0801 0.0774 0.0752 0.0741 0.0727 0.0716 0.0710 0.0703 0.0698 0.0694 

[TRAIN] Epoch[1](10597/114412); Loss: 0.060845; Backpropagation: 0.2913 sec; Batch: 2.1148 sec
0.1212 0.1142 0.0933 0.0742 0.0615 0.0582 0.0530 0.0501 0.0474 0.0454 0.0445 0.0433 0.0426 0.0419 0.0415 0.0411 

[TRAIN] Epoch[1](10598/114412); Loss: 0.066213; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1125 0.1076 0.0875 0.0736 0.0690 0.0639 0.0606 0.0583 0.0565 0.0550 0.0540 0.0531 0.0524 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](10599/114412); Loss: 0.078543; Backpropagation: 0.2928 sec; Batch: 2.1195 sec
0.1389 0.1252 0.0954 0.0875 0.0806 0.0756 0.0720 0.0692 0.0675 0.0662 0.0652 0.0642 0.0631 0.0626 0.0620 0.0615 

[TRAIN] Epoch[1](10600/114412); Loss: 0.110473; Backpropagation: 0.2915 sec; Batch: 2.1199 sec
0.1785 0.1717 0.1395 0.1254 0.1105 0.1038 0.0999 0.0969 0.0953 0.0941 0.0933 0.0927 0.0921 0.0916 0.0913 0.0910 

[TRAIN] Epoch[1](10601/114412); Loss: 0.059964; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1184 0.1055 0.0827 0.0739 0.0659 0.0593 0.0545 0.0504 0.0476 0.0455 0.0444 0.0435 0.0428 0.0421 0.0417 0.0413 

[TRAIN] Epoch[1](10602/114412); Loss: 0.093000; Backpropagation: 0.2930 sec; Batch: 2.1206 sec
0.1485 0.1356 0.1091 0.1034 0.0968 0.0912 0.0872 0.0844 0.0824 0.0808 0.0797 0.0788 0.0782 0.0777 0.0773 0.0768 

[TRAIN] Epoch[1](10603/114412); Loss: 0.061989; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.1210 0.1179 0.0852 0.0733 0.0612 0.0567 0.0530 0.0512 0.0496 0.0485 0.0474 0.0464 0.0458 0.0452 0.0448 0.0444 

[TRAIN] Epoch[1](10604/114412); Loss: 0.084430; Backpropagation: 0.2928 sec; Batch: 2.1192 sec
0.1412 0.1363 0.0988 0.0892 0.0831 0.0794 0.0772 0.0746 0.0732 0.0724 0.0719 0.0714 0.0711 0.0707 0.0704 0.0701 

[TRAIN] Epoch[1](10605/114412); Loss: 0.089285; Backpropagation: 0.2910 sec; Batch: 2.1154 sec
0.1656 0.1506 0.1211 0.1065 0.0924 0.0854 0.0804 0.0776 0.0742 0.0716 0.0699 0.0689 0.0675 0.0664 0.0656 0.0650 

[TRAIN] Epoch[1](10606/114412); Loss: 0.084141; Backpropagation: 0.2909 sec; Batch: 2.1260 sec
0.1418 0.1385 0.1045 0.0946 0.0844 0.0782 0.0766 0.0736 0.0719 0.0708 0.0701 0.0693 0.0687 0.0682 0.0678 0.0674 

[TRAIN] Epoch[1](10607/114412); Loss: 0.082292; Backpropagation: 0.2906 sec; Batch: 2.1171 sec
0.1552 0.1429 0.1022 0.0907 0.0854 0.0788 0.0746 0.0712 0.0686 0.0670 0.0653 0.0644 0.0636 0.0628 0.0622 0.0616 

[TRAIN] Epoch[1](10608/114412); Loss: 0.072832; Backpropagation: 0.2907 sec; Batch: 2.1120 sec
0.1703 0.1518 0.1038 0.0860 0.0749 0.0659 0.0605 0.0569 0.0544 0.0522 0.0508 0.0490 0.0481 0.0473 0.0469 0.0466 

[TRAIN] Epoch[1](10609/114412); Loss: 0.076295; Backpropagation: 0.2928 sec; Batch: 2.1010 sec
0.1569 0.1408 0.0979 0.0843 0.0756 0.0707 0.0669 0.0641 0.0616 0.0600 0.0589 0.0580 0.0571 0.0565 0.0559 0.0555 

[TRAIN] Epoch[1](10610/114412); Loss: 0.070204; Backpropagation: 0.2929 sec; Batch: 2.1179 sec
0.1163 0.1068 0.0921 0.0820 0.0714 0.0678 0.0646 0.0629 0.0609 0.0593 0.0581 0.0573 0.0566 0.0561 0.0556 0.0553 

[TRAIN] Epoch[1](10611/114412); Loss: 0.087972; Backpropagation: 0.2910 sec; Batch: 2.1326 sec
0.1493 0.1389 0.1095 0.0975 0.0906 0.0848 0.0812 0.0785 0.0762 0.0744 0.0731 0.0720 0.0711 0.0705 0.0701 0.0699 

[TRAIN] Epoch[1](10612/114412); Loss: 0.083298; Backpropagation: 0.2952 sec; Batch: 2.1214 sec
0.1393 0.1301 0.1046 0.0922 0.0847 0.0795 0.0763 0.0743 0.0726 0.0709 0.0697 0.0689 0.0680 0.0676 0.0672 0.0669 

[TRAIN] Epoch[1](10613/114412); Loss: 0.071462; Backpropagation: 0.2950 sec; Batch: 2.1203 sec
0.1279 0.1222 0.0985 0.0842 0.0737 0.0680 0.0636 0.0615 0.0591 0.0577 0.0566 0.0556 0.0547 0.0539 0.0534 0.0528 

[TRAIN] Epoch[1](10614/114412); Loss: 0.086486; Backpropagation: 0.2906 sec; Batch: 2.0791 sec
0.1632 0.1495 0.1146 0.1012 0.0899 0.0839 0.0798 0.0760 0.0723 0.0692 0.0669 0.0654 0.0644 0.0633 0.0624 0.0618 

[TRAIN] Epoch[1](10615/114412); Loss: 0.039738; Backpropagation: 0.2912 sec; Batch: 2.1133 sec
0.0923 0.0902 0.0534 0.0453 0.0376 0.0346 0.0319 0.0300 0.0289 0.0282 0.0279 0.0276 0.0272 0.0269 0.0268 0.0268 

[TRAIN] Epoch[1](10616/114412); Loss: 0.056842; Backpropagation: 0.2911 sec; Batch: 2.0758 sec
0.0975 0.0976 0.0806 0.0674 0.0588 0.0549 0.0513 0.0485 0.0470 0.0452 0.0444 0.0438 0.0433 0.0433 0.0429 0.0429 

[TRAIN] Epoch[1](10617/114412); Loss: 0.067124; Backpropagation: 0.2954 sec; Batch: 2.1228 sec
0.1422 0.1299 0.0857 0.0751 0.0673 0.0630 0.0591 0.0561 0.0536 0.0518 0.0504 0.0496 0.0485 0.0478 0.0472 0.0468 

[TRAIN] Epoch[1](10618/114412); Loss: 0.059189; Backpropagation: 0.2928 sec; Batch: 2.1189 sec
0.1251 0.1129 0.0756 0.0682 0.0611 0.0554 0.0521 0.0487 0.0469 0.0456 0.0441 0.0434 0.0426 0.0421 0.0418 0.0414 

[TRAIN] Epoch[1](10619/114412); Loss: 0.071835; Backpropagation: 0.2906 sec; Batch: 2.1140 sec
0.1353 0.1199 0.0966 0.0854 0.0724 0.0659 0.0632 0.0607 0.0592 0.0580 0.0568 0.0561 0.0556 0.0551 0.0548 0.0544 

[TRAIN] Epoch[1](10620/114412); Loss: 0.112337; Backpropagation: 0.2910 sec; Batch: 2.1075 sec
0.1859 0.1772 0.1421 0.1279 0.1145 0.1068 0.1022 0.0990 0.0970 0.0951 0.0933 0.0924 0.0918 0.0911 0.0907 0.0903 

[TRAIN] Epoch[1](10621/114412); Loss: 0.092623; Backpropagation: 0.2929 sec; Batch: 2.0802 sec
0.1568 0.1380 0.1141 0.1040 0.0950 0.0892 0.0855 0.0827 0.0806 0.0796 0.0782 0.0772 0.0763 0.0755 0.0750 0.0743 

[TRAIN] Epoch[1](10622/114412); Loss: 0.069298; Backpropagation: 0.2909 sec; Batch: 2.1209 sec
0.1328 0.1247 0.0883 0.0841 0.0691 0.0630 0.0596 0.0580 0.0564 0.0549 0.0542 0.0534 0.0528 0.0526 0.0525 0.0523 

[TRAIN] Epoch[1](10623/114412); Loss: 0.061002; Backpropagation: 0.2904 sec; Batch: 2.0780 sec
0.1162 0.0913 0.0741 0.0685 0.0610 0.0579 0.0557 0.0538 0.0523 0.0511 0.0503 0.0497 0.0491 0.0486 0.0483 0.0480 

[TRAIN] Epoch[1](10624/114412); Loss: 0.080658; Backpropagation: 0.2902 sec; Batch: 2.0762 sec
0.1801 0.1689 0.1077 0.0797 0.0741 0.0710 0.0684 0.0652 0.0629 0.0615 0.0604 0.0594 0.0586 0.0580 0.0576 0.0571 

[TRAIN] Epoch[1](10625/114412); Loss: 0.072708; Backpropagation: 0.2914 sec; Batch: 2.1146 sec
0.1318 0.1236 0.0841 0.0782 0.0723 0.0686 0.0660 0.0633 0.0619 0.0608 0.0601 0.0593 0.0589 0.0585 0.0580 0.0578 

[TRAIN] Epoch[1](10626/114412); Loss: 0.080696; Backpropagation: 0.2911 sec; Batch: 2.1204 sec
0.1422 0.1301 0.1033 0.0928 0.0853 0.0784 0.0737 0.0709 0.0687 0.0670 0.0657 0.0642 0.0633 0.0625 0.0617 0.0612 

[TRAIN] Epoch[1](10627/114412); Loss: 0.086485; Backpropagation: 0.2912 sec; Batch: 2.0838 sec
0.1538 0.1414 0.1051 0.0953 0.0858 0.0815 0.0794 0.0765 0.0745 0.0725 0.0713 0.0707 0.0699 0.0693 0.0686 0.0682 

[TRAIN] Epoch[1](10628/114412); Loss: 0.083840; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1305 0.1211 0.0969 0.0926 0.0864 0.0819 0.0790 0.0769 0.0749 0.0736 0.0727 0.0721 0.0714 0.0709 0.0704 0.0701 

[TRAIN] Epoch[1](10629/114412); Loss: 0.050620; Backpropagation: 0.2911 sec; Batch: 2.1185 sec
0.1095 0.0998 0.0745 0.0624 0.0518 0.0454 0.0413 0.0392 0.0379 0.0367 0.0361 0.0356 0.0351 0.0350 0.0349 0.0348 

[TRAIN] Epoch[1](10630/114412); Loss: 0.048959; Backpropagation: 0.2917 sec; Batch: 2.1006 sec
0.1092 0.1045 0.0676 0.0547 0.0480 0.0435 0.0414 0.0390 0.0369 0.0360 0.0349 0.0343 0.0338 0.0335 0.0331 0.0329 

[TRAIN] Epoch[1](10631/114412); Loss: 0.072166; Backpropagation: 0.2905 sec; Batch: 2.0759 sec
0.1548 0.1392 0.0874 0.0739 0.0678 0.0639 0.0614 0.0594 0.0579 0.0570 0.0563 0.0557 0.0553 0.0550 0.0549 0.0547 

[TRAIN] Epoch[1](10632/114412); Loss: 0.061293; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1573 0.1411 0.0904 0.0678 0.0592 0.0531 0.0492 0.0450 0.0435 0.0416 0.0402 0.0396 0.0389 0.0383 0.0380 0.0375 

[TRAIN] Epoch[1](10633/114412); Loss: 0.070730; Backpropagation: 0.2916 sec; Batch: 2.1134 sec
0.1252 0.1104 0.0876 0.0775 0.0733 0.0680 0.0650 0.0631 0.0606 0.0591 0.0583 0.0576 0.0572 0.0566 0.0563 0.0559 

[TRAIN] Epoch[1](10634/114412); Loss: 0.063417; Backpropagation: 0.2910 sec; Batch: 2.1134 sec
0.1376 0.1197 0.0876 0.0741 0.0651 0.0585 0.0544 0.0524 0.0496 0.0478 0.0465 0.0455 0.0448 0.0442 0.0436 0.0432 

[TRAIN] Epoch[1](10635/114412); Loss: 0.075795; Backpropagation: 0.2909 sec; Batch: 2.1150 sec
0.1234 0.1176 0.0987 0.0876 0.0785 0.0743 0.0705 0.0681 0.0659 0.0641 0.0628 0.0617 0.0609 0.0602 0.0596 0.0590 

[TRAIN] Epoch[1](10636/114412); Loss: 0.082031; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1303 0.1148 0.0985 0.0917 0.0843 0.0806 0.0770 0.0748 0.0732 0.0719 0.0710 0.0701 0.0695 0.0688 0.0683 0.0679 

[TRAIN] Epoch[1](10637/114412); Loss: 0.065627; Backpropagation: 0.2912 sec; Batch: 2.1010 sec
0.1272 0.1198 0.0858 0.0763 0.0659 0.0609 0.0573 0.0552 0.0533 0.0519 0.0509 0.0502 0.0495 0.0490 0.0485 0.0482 

[TRAIN] Epoch[1](10638/114412); Loss: 0.069462; Backpropagation: 0.2944 sec; Batch: 2.1176 sec
0.1476 0.1341 0.0964 0.0811 0.0673 0.0628 0.0589 0.0568 0.0545 0.0528 0.0515 0.0506 0.0499 0.0493 0.0490 0.0486 

[TRAIN] Epoch[1](10639/114412); Loss: 0.095562; Backpropagation: 0.2911 sec; Batch: 2.1144 sec
0.1692 0.1598 0.1276 0.1136 0.1021 0.0933 0.0872 0.0823 0.0792 0.0770 0.0752 0.0741 0.0731 0.0723 0.0717 0.0714 

[TRAIN] Epoch[1](10640/114412); Loss: 0.064952; Backpropagation: 0.2904 sec; Batch: 2.1166 sec
0.1354 0.1344 0.0951 0.0844 0.0695 0.0601 0.0564 0.0519 0.0493 0.0471 0.0455 0.0439 0.0428 0.0417 0.0412 0.0407 

[TRAIN] Epoch[1](10641/114412); Loss: 0.090715; Backpropagation: 0.2910 sec; Batch: 2.1186 sec
0.1459 0.1397 0.1276 0.1084 0.0970 0.0877 0.0830 0.0795 0.0772 0.0752 0.0736 0.0727 0.0719 0.0711 0.0707 0.0704 

[TRAIN] Epoch[1](10642/114412); Loss: 0.071282; Backpropagation: 0.2912 sec; Batch: 2.0943 sec
0.1298 0.1170 0.1018 0.0853 0.0760 0.0669 0.0623 0.0597 0.0580 0.0567 0.0558 0.0551 0.0547 0.0543 0.0538 0.0534 

[TRAIN] Epoch[1](10643/114412); Loss: 0.065316; Backpropagation: 0.2954 sec; Batch: 2.0802 sec
0.1236 0.1166 0.0821 0.0709 0.0648 0.0610 0.0578 0.0556 0.0540 0.0529 0.0520 0.0514 0.0510 0.0506 0.0505 0.0503 

[TRAIN] Epoch[1](10644/114412); Loss: 0.087238; Backpropagation: 0.2938 sec; Batch: 2.1213 sec
0.1526 0.1397 0.1090 0.1006 0.0903 0.0845 0.0800 0.0767 0.0743 0.0727 0.0714 0.0703 0.0696 0.0687 0.0681 0.0675 

[TRAIN] Epoch[1](10645/114412); Loss: 0.062573; Backpropagation: 0.2902 sec; Batch: 2.1181 sec
0.1236 0.1072 0.0811 0.0719 0.0645 0.0597 0.0557 0.0527 0.0512 0.0498 0.0486 0.0479 0.0473 0.0470 0.0466 0.0464 

[TRAIN] Epoch[1](10646/114412); Loss: 0.079275; Backpropagation: 0.2928 sec; Batch: 2.1169 sec
0.1569 0.1463 0.0964 0.0850 0.0801 0.0746 0.0704 0.0675 0.0651 0.0637 0.0625 0.0614 0.0607 0.0598 0.0592 0.0588 

[TRAIN] Epoch[1](10647/114412); Loss: 0.056471; Backpropagation: 0.2926 sec; Batch: 2.1206 sec
0.1095 0.1037 0.0731 0.0625 0.0562 0.0526 0.0497 0.0480 0.0461 0.0449 0.0441 0.0434 0.0430 0.0426 0.0423 0.0422 

[TRAIN] Epoch[1](10648/114412); Loss: 0.066597; Backpropagation: 0.2933 sec; Batch: 2.1111 sec
0.1282 0.1172 0.0804 0.0736 0.0647 0.0609 0.0580 0.0564 0.0550 0.0541 0.0535 0.0531 0.0528 0.0527 0.0527 0.0524 

[TRAIN] Epoch[1](10649/114412); Loss: 0.097644; Backpropagation: 0.2923 sec; Batch: 2.1192 sec
0.2317 0.2174 0.1519 0.1200 0.0906 0.0814 0.0766 0.0734 0.0702 0.0673 0.0660 0.0648 0.0638 0.0629 0.0624 0.0619 

[TRAIN] Epoch[1](10650/114412); Loss: 0.099449; Backpropagation: 0.2911 sec; Batch: 2.1170 sec
0.1554 0.1474 0.1158 0.1079 0.1016 0.0961 0.0932 0.0906 0.0888 0.0873 0.0863 0.0855 0.0847 0.0841 0.0835 0.0830 

[TRAIN] Epoch[1](10651/114412); Loss: 0.062637; Backpropagation: 0.2915 sec; Batch: 2.1177 sec
0.1299 0.1087 0.0816 0.0749 0.0645 0.0587 0.0548 0.0518 0.0502 0.0489 0.0478 0.0469 0.0464 0.0460 0.0457 0.0454 

[TRAIN] Epoch[1](10652/114412); Loss: 0.072297; Backpropagation: 0.2907 sec; Batch: 2.1166 sec
0.1269 0.1168 0.0889 0.0803 0.0726 0.0684 0.0659 0.0638 0.0620 0.0606 0.0597 0.0591 0.0585 0.0581 0.0576 0.0574 

[TRAIN] Epoch[1](10653/114412); Loss: 0.067369; Backpropagation: 0.2932 sec; Batch: 2.1191 sec
0.1117 0.0976 0.0863 0.0794 0.0699 0.0661 0.0627 0.0602 0.0586 0.0571 0.0563 0.0555 0.0547 0.0543 0.0538 0.0537 

[TRAIN] Epoch[1](10654/114412); Loss: 0.058071; Backpropagation: 0.2912 sec; Batch: 2.0850 sec
0.1202 0.1089 0.0776 0.0674 0.0591 0.0555 0.0518 0.0481 0.0459 0.0443 0.0434 0.0424 0.0418 0.0413 0.0408 0.0406 

[TRAIN] Epoch[1](10655/114412); Loss: 0.057953; Backpropagation: 0.2953 sec; Batch: 2.1212 sec
0.1229 0.1183 0.0727 0.0621 0.0563 0.0529 0.0494 0.0471 0.0459 0.0447 0.0439 0.0431 0.0426 0.0421 0.0417 0.0414 

[TRAIN] Epoch[1](10656/114412); Loss: 0.067808; Backpropagation: 0.2953 sec; Batch: 2.1212 sec
0.1227 0.1176 0.0857 0.0768 0.0689 0.0650 0.0607 0.0585 0.0560 0.0549 0.0543 0.0535 0.0530 0.0526 0.0524 0.0523 

[TRAIN] Epoch[1](10657/114412); Loss: 0.087010; Backpropagation: 0.2930 sec; Batch: 2.1317 sec
0.1686 0.1605 0.1162 0.1054 0.0857 0.0795 0.0753 0.0725 0.0702 0.0684 0.0671 0.0660 0.0650 0.0644 0.0639 0.0635 

[TRAIN] Epoch[1](10658/114412); Loss: 0.083610; Backpropagation: 0.2909 sec; Batch: 2.1197 sec
0.1509 0.1429 0.1062 0.0941 0.0838 0.0784 0.0748 0.0722 0.0702 0.0689 0.0680 0.0669 0.0661 0.0655 0.0647 0.0641 

[TRAIN] Epoch[1](10659/114412); Loss: 0.075439; Backpropagation: 0.2928 sec; Batch: 2.0825 sec
0.1322 0.1273 0.0902 0.0850 0.0744 0.0700 0.0672 0.0660 0.0643 0.0633 0.0627 0.0619 0.0613 0.0609 0.0605 0.0602 

[TRAIN] Epoch[1](10660/114412); Loss: 0.061984; Backpropagation: 0.2910 sec; Batch: 2.0759 sec
0.1064 0.0965 0.0808 0.0679 0.0626 0.0589 0.0564 0.0547 0.0533 0.0523 0.0515 0.0509 0.0504 0.0500 0.0497 0.0495 

[TRAIN] Epoch[1](10661/114412); Loss: 0.075147; Backpropagation: 0.2915 sec; Batch: 2.1204 sec
0.1358 0.1285 0.0990 0.0866 0.0770 0.0715 0.0679 0.0655 0.0633 0.0613 0.0601 0.0590 0.0578 0.0570 0.0562 0.0555 

[TRAIN] Epoch[1](10662/114412); Loss: 0.066903; Backpropagation: 0.2911 sec; Batch: 2.0796 sec
0.1023 0.0955 0.0815 0.0765 0.0696 0.0657 0.0630 0.0611 0.0593 0.0581 0.0575 0.0568 0.0563 0.0561 0.0556 0.0555 

[TRAIN] Epoch[1](10663/114412); Loss: 0.070713; Backpropagation: 0.2950 sec; Batch: 2.1193 sec
0.1746 0.1590 0.1044 0.0953 0.0693 0.0592 0.0545 0.0504 0.0491 0.0473 0.0462 0.0455 0.0448 0.0443 0.0440 0.0437 

[TRAIN] Epoch[1](10664/114412); Loss: 0.068352; Backpropagation: 0.2957 sec; Batch: 2.1180 sec
0.1280 0.1189 0.0834 0.0741 0.0684 0.0651 0.0622 0.0596 0.0577 0.0559 0.0551 0.0542 0.0535 0.0529 0.0525 0.0522 

[TRAIN] Epoch[1](10665/114412); Loss: 0.076556; Backpropagation: 0.2930 sec; Batch: 2.1154 sec
0.1467 0.1337 0.0991 0.0872 0.0768 0.0719 0.0680 0.0652 0.0630 0.0617 0.0604 0.0597 0.0588 0.0582 0.0575 0.0570 

[TRAIN] Epoch[1](10666/114412); Loss: 0.049380; Backpropagation: 0.2931 sec; Batch: 2.0798 sec
0.1069 0.0994 0.0670 0.0577 0.0504 0.0460 0.0426 0.0398 0.0380 0.0367 0.0356 0.0349 0.0343 0.0338 0.0336 0.0334 

[TRAIN] Epoch[1](10667/114412); Loss: 0.067051; Backpropagation: 0.2930 sec; Batch: 2.1278 sec
0.1366 0.1239 0.0851 0.0731 0.0675 0.0632 0.0595 0.0565 0.0542 0.0529 0.0520 0.0510 0.0502 0.0495 0.0490 0.0487 

[TRAIN] Epoch[1](10668/114412); Loss: 0.078247; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1691 0.1579 0.1127 0.0813 0.0714 0.0685 0.0644 0.0622 0.0605 0.0597 0.0588 0.0580 0.0574 0.0568 0.0567 0.0565 

[TRAIN] Epoch[1](10669/114412); Loss: 0.072849; Backpropagation: 0.2917 sec; Batch: 2.1196 sec
0.1374 0.1326 0.0915 0.0823 0.0724 0.0680 0.0650 0.0624 0.0605 0.0587 0.0575 0.0568 0.0559 0.0553 0.0549 0.0545 

[TRAIN] Epoch[1](10670/114412); Loss: 0.073025; Backpropagation: 0.2913 sec; Batch: 2.1165 sec
0.1200 0.1066 0.0912 0.0841 0.0746 0.0713 0.0674 0.0654 0.0638 0.0625 0.0617 0.0611 0.0604 0.0597 0.0595 0.0592 

[TRAIN] Epoch[1](10671/114412); Loss: 0.081289; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1547 0.1460 0.1024 0.0909 0.0809 0.0755 0.0718 0.0687 0.0670 0.0656 0.0646 0.0638 0.0629 0.0624 0.0619 0.0616 

[TRAIN] Epoch[1](10672/114412); Loss: 0.056020; Backpropagation: 0.2908 sec; Batch: 2.1121 sec
0.1085 0.0953 0.0743 0.0644 0.0581 0.0519 0.0490 0.0473 0.0459 0.0447 0.0440 0.0432 0.0429 0.0425 0.0422 0.0420 

[TRAIN] Epoch[1](10673/114412); Loss: 0.093252; Backpropagation: 0.2927 sec; Batch: 2.1176 sec
0.1333 0.1286 0.1087 0.1017 0.0955 0.0914 0.0892 0.0870 0.0855 0.0841 0.0829 0.0819 0.0812 0.0808 0.0803 0.0799 

[TRAIN] Epoch[1](10674/114412); Loss: 0.091437; Backpropagation: 0.2912 sec; Batch: 2.1139 sec
0.1484 0.1392 0.1109 0.1018 0.0914 0.0868 0.0835 0.0815 0.0803 0.0793 0.0784 0.0773 0.0766 0.0763 0.0758 0.0754 

[TRAIN] Epoch[1](10675/114412); Loss: 0.063026; Backpropagation: 0.2907 sec; Batch: 2.0807 sec
0.1128 0.1033 0.0798 0.0712 0.0646 0.0602 0.0576 0.0551 0.0534 0.0518 0.0511 0.0503 0.0498 0.0494 0.0491 0.0488 

[TRAIN] Epoch[1](10676/114412); Loss: 0.069905; Backpropagation: 0.2911 sec; Batch: 2.1231 sec
0.1274 0.1209 0.0886 0.0769 0.0710 0.0665 0.0631 0.0606 0.0587 0.0572 0.0561 0.0553 0.0547 0.0542 0.0538 0.0536 

[TRAIN] Epoch[1](10677/114412); Loss: 0.066631; Backpropagation: 0.2903 sec; Batch: 2.1172 sec
0.1246 0.1139 0.0807 0.0752 0.0686 0.0631 0.0601 0.0574 0.0557 0.0545 0.0532 0.0526 0.0521 0.0518 0.0514 0.0511 

[TRAIN] Epoch[1](10678/114412); Loss: 0.082300; Backpropagation: 0.2910 sec; Batch: 2.1132 sec
0.1669 0.1529 0.1131 0.0957 0.0847 0.0765 0.0715 0.0679 0.0650 0.0633 0.0619 0.0609 0.0599 0.0596 0.0589 0.0581 

[TRAIN] Epoch[1](10679/114412); Loss: 0.059414; Backpropagation: 0.2904 sec; Batch: 2.1171 sec
0.1593 0.1461 0.0793 0.0657 0.0555 0.0511 0.0463 0.0444 0.0415 0.0395 0.0388 0.0377 0.0371 0.0365 0.0362 0.0359 

[TRAIN] Epoch[1](10680/114412); Loss: 0.085836; Backpropagation: 0.2909 sec; Batch: 2.0769 sec
0.1464 0.1325 0.1108 0.0975 0.0877 0.0820 0.0785 0.0760 0.0742 0.0728 0.0714 0.0703 0.0694 0.0685 0.0680 0.0676 

[TRAIN] Epoch[1](10681/114412); Loss: 0.063206; Backpropagation: 0.2911 sec; Batch: 2.1156 sec
0.1208 0.1163 0.0833 0.0697 0.0643 0.0594 0.0549 0.0536 0.0521 0.0506 0.0493 0.0485 0.0477 0.0473 0.0470 0.0466 

[TRAIN] Epoch[1](10682/114412); Loss: 0.064320; Backpropagation: 0.2952 sec; Batch: 2.1217 sec
0.1070 0.0986 0.0805 0.0729 0.0681 0.0623 0.0595 0.0575 0.0557 0.0541 0.0532 0.0527 0.0523 0.0518 0.0516 0.0513 

[TRAIN] Epoch[1](10683/114412); Loss: 0.071300; Backpropagation: 0.2930 sec; Batch: 2.1153 sec
0.1266 0.1176 0.0862 0.0796 0.0741 0.0683 0.0653 0.0633 0.0610 0.0595 0.0581 0.0573 0.0567 0.0561 0.0557 0.0553 

[TRAIN] Epoch[1](10684/114412); Loss: 0.063163; Backpropagation: 0.2931 sec; Batch: 2.1185 sec
0.1402 0.1181 0.0819 0.0753 0.0664 0.0591 0.0545 0.0514 0.0495 0.0478 0.0464 0.0452 0.0444 0.0439 0.0434 0.0429 

[TRAIN] Epoch[1](10685/114412); Loss: 0.069061; Backpropagation: 0.2950 sec; Batch: 2.1151 sec
0.1279 0.1214 0.0858 0.0747 0.0693 0.0642 0.0615 0.0595 0.0578 0.0566 0.0557 0.0549 0.0544 0.0540 0.0538 0.0535 

[TRAIN] Epoch[1](10686/114412); Loss: 0.065398; Backpropagation: 0.2929 sec; Batch: 2.1159 sec
0.1368 0.1065 0.0826 0.0713 0.0676 0.0629 0.0601 0.0564 0.0545 0.0523 0.0512 0.0501 0.0493 0.0487 0.0483 0.0477 

[TRAIN] Epoch[1](10687/114412); Loss: 0.084887; Backpropagation: 0.2929 sec; Batch: 2.1224 sec
0.1781 0.1562 0.1114 0.0934 0.0795 0.0763 0.0730 0.0702 0.0683 0.0668 0.0656 0.0649 0.0642 0.0637 0.0635 0.0632 

[TRAIN] Epoch[1](10688/114412); Loss: 0.089309; Backpropagation: 0.2917 sec; Batch: 2.1172 sec
0.1507 0.1365 0.1042 0.0976 0.0904 0.0857 0.0824 0.0800 0.0782 0.0768 0.0758 0.0752 0.0746 0.0741 0.0736 0.0732 

[TRAIN] Epoch[1](10689/114412); Loss: 0.067627; Backpropagation: 0.2915 sec; Batch: 2.1161 sec
0.1235 0.1134 0.0913 0.0796 0.0733 0.0669 0.0623 0.0587 0.0560 0.0543 0.0527 0.0517 0.0508 0.0498 0.0491 0.0487 

[TRAIN] Epoch[1](10690/114412); Loss: 0.081251; Backpropagation: 0.2912 sec; Batch: 2.1212 sec
0.1398 0.1291 0.0977 0.0903 0.0846 0.0795 0.0753 0.0728 0.0704 0.0687 0.0675 0.0666 0.0655 0.0646 0.0641 0.0636 

[TRAIN] Epoch[1](10691/114412); Loss: 0.065860; Backpropagation: 0.2914 sec; Batch: 2.1137 sec
0.1455 0.1229 0.0900 0.0683 0.0625 0.0584 0.0560 0.0539 0.0513 0.0505 0.0497 0.0494 0.0492 0.0489 0.0487 0.0485 

[TRAIN] Epoch[1](10692/114412); Loss: 0.054060; Backpropagation: 0.2914 sec; Batch: 2.1136 sec
0.1326 0.1126 0.0731 0.0630 0.0516 0.0485 0.0438 0.0414 0.0398 0.0385 0.0377 0.0372 0.0367 0.0364 0.0362 0.0359 

[TRAIN] Epoch[1](10693/114412); Loss: 0.073330; Backpropagation: 0.2908 sec; Batch: 2.1181 sec
0.1198 0.1022 0.0875 0.0806 0.0759 0.0728 0.0699 0.0670 0.0651 0.0636 0.0629 0.0622 0.0617 0.0611 0.0607 0.0604 

[TRAIN] Epoch[1](10694/114412); Loss: 0.069866; Backpropagation: 0.2913 sec; Batch: 2.0943 sec
0.1226 0.1183 0.0811 0.0714 0.0692 0.0649 0.0640 0.0615 0.0601 0.0595 0.0585 0.0582 0.0575 0.0572 0.0571 0.0568 

[TRAIN] Epoch[1](10695/114412); Loss: 0.063103; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1054 0.1012 0.0843 0.0712 0.0632 0.0588 0.0561 0.0543 0.0535 0.0526 0.0520 0.0518 0.0514 0.0513 0.0512 0.0511 

[TRAIN] Epoch[1](10696/114412); Loss: 0.081270; Backpropagation: 0.2908 sec; Batch: 2.1014 sec
0.1510 0.1351 0.1009 0.0885 0.0821 0.0768 0.0731 0.0707 0.0686 0.0673 0.0661 0.0652 0.0643 0.0638 0.0635 0.0631 

[TRAIN] Epoch[1](10697/114412); Loss: 0.067185; Backpropagation: 0.2904 sec; Batch: 2.0770 sec
0.1359 0.1239 0.0893 0.0727 0.0658 0.0604 0.0573 0.0560 0.0545 0.0533 0.0525 0.0516 0.0510 0.0507 0.0501 0.0499 

[TRAIN] Epoch[1](10698/114412); Loss: 0.081166; Backpropagation: 0.2910 sec; Batch: 2.1143 sec
0.1567 0.1349 0.0992 0.0887 0.0811 0.0749 0.0717 0.0704 0.0687 0.0670 0.0655 0.0647 0.0643 0.0639 0.0636 0.0634 

[TRAIN] Epoch[1](10699/114412); Loss: 0.091344; Backpropagation: 0.2908 sec; Batch: 2.0779 sec
0.1843 0.1627 0.1183 0.0970 0.0881 0.0842 0.0808 0.0772 0.0751 0.0731 0.0719 0.0709 0.0702 0.0696 0.0692 0.0688 

[TRAIN] Epoch[1](10700/114412); Loss: 0.081623; Backpropagation: 0.2912 sec; Batch: 2.1141 sec
0.1412 0.1253 0.1017 0.0938 0.0862 0.0807 0.0760 0.0727 0.0704 0.0685 0.0670 0.0659 0.0649 0.0645 0.0640 0.0633 

[TRAIN] Epoch[1](10701/114412); Loss: 0.068377; Backpropagation: 0.2905 sec; Batch: 2.1157 sec
0.1214 0.1164 0.0882 0.0766 0.0698 0.0642 0.0614 0.0592 0.0572 0.0562 0.0552 0.0545 0.0540 0.0535 0.0532 0.0529 

[TRAIN] Epoch[1](10702/114412); Loss: 0.096445; Backpropagation: 0.2951 sec; Batch: 2.1192 sec
0.1525 0.1425 0.1130 0.1041 0.0973 0.0934 0.0901 0.0882 0.0864 0.0848 0.0836 0.0826 0.0819 0.0814 0.0809 0.0805 

[TRAIN] Epoch[1](10703/114412); Loss: 0.059209; Backpropagation: 0.2905 sec; Batch: 2.1164 sec
0.1388 0.1250 0.0848 0.0711 0.0604 0.0530 0.0480 0.0454 0.0433 0.0420 0.0408 0.0399 0.0392 0.0389 0.0387 0.0383 

[TRAIN] Epoch[1](10704/114412); Loss: 0.079061; Backpropagation: 0.2913 sec; Batch: 2.1260 sec
0.1611 0.1487 0.1047 0.0873 0.0760 0.0716 0.0679 0.0650 0.0635 0.0621 0.0613 0.0603 0.0596 0.0591 0.0586 0.0582 

[TRAIN] Epoch[1](10705/114412); Loss: 0.107030; Backpropagation: 0.2929 sec; Batch: 2.1192 sec
0.1816 0.1551 0.1312 0.1244 0.1105 0.1068 0.1006 0.0965 0.0938 0.0914 0.0897 0.0880 0.0870 0.0860 0.0853 0.0847 

[TRAIN] Epoch[1](10706/114412); Loss: 0.121116; Backpropagation: 0.2910 sec; Batch: 2.1157 sec
0.2368 0.2093 0.1694 0.1534 0.1315 0.1178 0.1080 0.1012 0.0971 0.0928 0.0902 0.0887 0.0870 0.0857 0.0849 0.0840 

[TRAIN] Epoch[1](10707/114412); Loss: 0.088491; Backpropagation: 0.2953 sec; Batch: 2.1221 sec
0.1539 0.1424 0.1123 0.1007 0.0923 0.0853 0.0810 0.0783 0.0761 0.0742 0.0732 0.0715 0.0702 0.0692 0.0680 0.0674 

[TRAIN] Epoch[1](10708/114412); Loss: 0.083437; Backpropagation: 0.2926 sec; Batch: 2.1143 sec
0.1593 0.1492 0.1094 0.0984 0.0849 0.0796 0.0742 0.0713 0.0681 0.0662 0.0647 0.0634 0.0627 0.0618 0.0612 0.0607 

[TRAIN] Epoch[1](10709/114412); Loss: 0.077385; Backpropagation: 0.2929 sec; Batch: 2.1145 sec
0.1450 0.1276 0.0987 0.0889 0.0788 0.0739 0.0697 0.0669 0.0647 0.0632 0.0621 0.0610 0.0603 0.0596 0.0592 0.0587 

[TRAIN] Epoch[1](10710/114412); Loss: 0.082911; Backpropagation: 0.2910 sec; Batch: 2.1150 sec
0.1855 0.1745 0.1122 0.0853 0.0762 0.0725 0.0693 0.0662 0.0641 0.0626 0.0614 0.0606 0.0599 0.0592 0.0587 0.0584 

[TRAIN] Epoch[1](10711/114412); Loss: 0.106879; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.1790 0.1696 0.1373 0.1221 0.1090 0.1015 0.0972 0.0940 0.0924 0.0903 0.0887 0.0876 0.0865 0.0856 0.0849 0.0843 

[TRAIN] Epoch[1](10712/114412); Loss: 0.068203; Backpropagation: 0.2930 sec; Batch: 2.1203 sec
0.1200 0.1123 0.0850 0.0761 0.0701 0.0651 0.0623 0.0597 0.0581 0.0566 0.0557 0.0549 0.0542 0.0540 0.0537 0.0534 

[TRAIN] Epoch[1](10713/114412); Loss: 0.082446; Backpropagation: 0.2930 sec; Batch: 2.1214 sec
0.1819 0.1770 0.1188 0.1009 0.0790 0.0683 0.0647 0.0622 0.0606 0.0593 0.0587 0.0582 0.0578 0.0574 0.0573 0.0570 

[TRAIN] Epoch[1](10714/114412); Loss: 0.077279; Backpropagation: 0.2912 sec; Batch: 2.1191 sec
0.1345 0.1205 0.0929 0.0855 0.0785 0.0745 0.0710 0.0687 0.0671 0.0657 0.0646 0.0637 0.0630 0.0625 0.0621 0.0617 

[TRAIN] Epoch[1](10715/114412); Loss: 0.065049; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1116 0.1076 0.0858 0.0744 0.0663 0.0618 0.0589 0.0567 0.0552 0.0538 0.0528 0.0521 0.0515 0.0511 0.0507 0.0505 

[TRAIN] Epoch[1](10716/114412); Loss: 0.059805; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1037 0.0922 0.0748 0.0667 0.0624 0.0580 0.0553 0.0527 0.0510 0.0498 0.0493 0.0487 0.0483 0.0481 0.0480 0.0478 

[TRAIN] Epoch[1](10717/114412); Loss: 0.069566; Backpropagation: 0.2951 sec; Batch: 2.1228 sec
0.1447 0.1206 0.0974 0.0864 0.0698 0.0638 0.0601 0.0581 0.0560 0.0538 0.0525 0.0513 0.0506 0.0499 0.0493 0.0489 

[TRAIN] Epoch[1](10718/114412); Loss: 0.067003; Backpropagation: 0.2950 sec; Batch: 2.1177 sec
0.1324 0.1212 0.0882 0.0757 0.0673 0.0615 0.0577 0.0560 0.0546 0.0531 0.0520 0.0514 0.0509 0.0504 0.0500 0.0497 

[TRAIN] Epoch[1](10719/114412); Loss: 0.087977; Backpropagation: 0.2929 sec; Batch: 2.1207 sec
0.1531 0.1384 0.1129 0.1008 0.0900 0.0847 0.0805 0.0779 0.0758 0.0737 0.0725 0.0712 0.0703 0.0694 0.0686 0.0679 

[TRAIN] Epoch[1](10720/114412); Loss: 0.089581; Backpropagation: 0.2931 sec; Batch: 2.1185 sec
0.1447 0.1319 0.1084 0.0991 0.0924 0.0870 0.0832 0.0809 0.0791 0.0777 0.0764 0.0757 0.0749 0.0743 0.0740 0.0735 

[TRAIN] Epoch[1](10721/114412); Loss: 0.061821; Backpropagation: 0.2905 sec; Batch: 2.1144 sec
0.1162 0.1060 0.0806 0.0719 0.0626 0.0584 0.0550 0.0523 0.0512 0.0498 0.0491 0.0481 0.0475 0.0471 0.0468 0.0466 

[TRAIN] Epoch[1](10722/114412); Loss: 0.092244; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1960 0.1711 0.1250 0.0988 0.0878 0.0833 0.0801 0.0753 0.0734 0.0719 0.0710 0.0696 0.0689 0.0684 0.0679 0.0675 

[TRAIN] Epoch[1](10723/114412); Loss: 0.062262; Backpropagation: 0.2914 sec; Batch: 2.1142 sec
0.1305 0.1244 0.0843 0.0660 0.0599 0.0559 0.0535 0.0514 0.0492 0.0480 0.0469 0.0464 0.0455 0.0451 0.0446 0.0445 

[TRAIN] Epoch[1](10724/114412); Loss: 0.075089; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1230 0.1145 0.0927 0.0851 0.0767 0.0719 0.0701 0.0675 0.0658 0.0643 0.0636 0.0626 0.0616 0.0611 0.0608 0.0602 

[TRAIN] Epoch[1](10725/114412); Loss: 0.085010; Backpropagation: 0.2908 sec; Batch: 2.1187 sec
0.1499 0.1335 0.1086 0.0947 0.0847 0.0796 0.0769 0.0749 0.0731 0.0714 0.0703 0.0697 0.0689 0.0684 0.0680 0.0675 

[TRAIN] Epoch[1](10726/114412); Loss: 0.075340; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1319 0.1187 0.0958 0.0870 0.0781 0.0732 0.0690 0.0661 0.0641 0.0626 0.0615 0.0607 0.0600 0.0593 0.0590 0.0585 

[TRAIN] Epoch[1](10727/114412); Loss: 0.063416; Backpropagation: 0.2954 sec; Batch: 2.1281 sec
0.1264 0.1156 0.0867 0.0715 0.0640 0.0586 0.0553 0.0534 0.0513 0.0496 0.0484 0.0477 0.0472 0.0467 0.0463 0.0461 

[TRAIN] Epoch[1](10728/114412); Loss: 0.057016; Backpropagation: 0.2930 sec; Batch: 2.0968 sec
0.1229 0.1142 0.0638 0.0571 0.0538 0.0508 0.0493 0.0474 0.0462 0.0455 0.0446 0.0440 0.0435 0.0431 0.0430 0.0430 

[TRAIN] Epoch[1](10729/114412); Loss: 0.089218; Backpropagation: 0.2955 sec; Batch: 2.1201 sec
0.1637 0.1486 0.1164 0.0960 0.0885 0.0829 0.0796 0.0770 0.0748 0.0737 0.0729 0.0720 0.0713 0.0706 0.0700 0.0694 

[TRAIN] Epoch[1](10730/114412); Loss: 0.080813; Backpropagation: 0.2931 sec; Batch: 2.1225 sec
0.1346 0.1256 0.0993 0.0915 0.0832 0.0778 0.0743 0.0721 0.0703 0.0688 0.0676 0.0668 0.0662 0.0655 0.0649 0.0645 

[TRAIN] Epoch[1](10731/114412); Loss: 0.050041; Backpropagation: 0.2952 sec; Batch: 2.1202 sec
0.1028 0.0976 0.0710 0.0608 0.0505 0.0453 0.0414 0.0399 0.0385 0.0374 0.0368 0.0362 0.0360 0.0357 0.0355 0.0353 

[TRAIN] Epoch[1](10732/114412); Loss: 0.081991; Backpropagation: 0.2951 sec; Batch: 2.1249 sec
0.1372 0.1278 0.1017 0.0913 0.0843 0.0787 0.0748 0.0725 0.0707 0.0693 0.0685 0.0677 0.0672 0.0669 0.0667 0.0664 

[TRAIN] Epoch[1](10733/114412); Loss: 0.050976; Backpropagation: 0.2911 sec; Batch: 2.1282 sec
0.0899 0.0803 0.0669 0.0603 0.0525 0.0493 0.0468 0.0447 0.0431 0.0417 0.0410 0.0406 0.0402 0.0398 0.0394 0.0393 

[TRAIN] Epoch[1](10734/114412); Loss: 0.087530; Backpropagation: 0.2906 sec; Batch: 2.1146 sec
0.1585 0.1426 0.1007 0.0949 0.0857 0.0809 0.0782 0.0768 0.0752 0.0743 0.0732 0.0724 0.0722 0.0718 0.0716 0.0714 

[TRAIN] Epoch[1](10735/114412); Loss: 0.072019; Backpropagation: 0.2905 sec; Batch: 2.1127 sec
0.1396 0.1327 0.0953 0.0816 0.0711 0.0668 0.0629 0.0607 0.0590 0.0572 0.0562 0.0550 0.0542 0.0538 0.0533 0.0529 

[TRAIN] Epoch[1](10736/114412); Loss: 0.076685; Backpropagation: 0.2906 sec; Batch: 2.1135 sec
0.1286 0.1224 0.0962 0.0855 0.0786 0.0737 0.0704 0.0675 0.0659 0.0647 0.0637 0.0630 0.0622 0.0618 0.0615 0.0611 

[TRAIN] Epoch[1](10737/114412); Loss: 0.068426; Backpropagation: 0.2953 sec; Batch: 2.1187 sec
0.1212 0.1138 0.0896 0.0807 0.0725 0.0648 0.0613 0.0592 0.0571 0.0557 0.0548 0.0540 0.0533 0.0528 0.0522 0.0518 

[TRAIN] Epoch[1](10738/114412); Loss: 0.071290; Backpropagation: 0.2931 sec; Batch: 2.1186 sec
0.1325 0.1254 0.0930 0.0805 0.0735 0.0677 0.0633 0.0611 0.0586 0.0573 0.0562 0.0554 0.0548 0.0542 0.0537 0.0533 

[TRAIN] Epoch[1](10739/114412); Loss: 0.067974; Backpropagation: 0.2952 sec; Batch: 2.1197 sec
0.1461 0.1313 0.0855 0.0769 0.0693 0.0628 0.0589 0.0564 0.0534 0.0521 0.0509 0.0498 0.0492 0.0487 0.0482 0.0479 

[TRAIN] Epoch[1](10740/114412); Loss: 0.063071; Backpropagation: 0.2914 sec; Batch: 2.1178 sec
0.1362 0.1219 0.0873 0.0730 0.0630 0.0577 0.0529 0.0508 0.0488 0.0476 0.0467 0.0457 0.0451 0.0446 0.0441 0.0437 

[TRAIN] Epoch[1](10741/114412); Loss: 0.080271; Backpropagation: 0.2934 sec; Batch: 2.1513 sec
0.1429 0.1345 0.1110 0.1008 0.0885 0.0859 0.0779 0.0740 0.0681 0.0644 0.0613 0.0582 0.0566 0.0541 0.0533 0.0526 

[TRAIN] Epoch[1](10742/114412); Loss: 0.074970; Backpropagation: 0.2915 sec; Batch: 2.1156 sec
0.1216 0.1113 0.0925 0.0843 0.0775 0.0715 0.0687 0.0673 0.0657 0.0646 0.0637 0.0630 0.0624 0.0621 0.0618 0.0616 

[TRAIN] Epoch[1](10743/114412); Loss: 0.076038; Backpropagation: 0.2905 sec; Batch: 2.0766 sec
0.1374 0.1228 0.0975 0.0868 0.0775 0.0716 0.0697 0.0662 0.0644 0.0631 0.0617 0.0608 0.0600 0.0596 0.0590 0.0586 

[TRAIN] Epoch[1](10744/114412); Loss: 0.066928; Backpropagation: 0.2932 sec; Batch: 2.1182 sec
0.1458 0.1333 0.0935 0.0797 0.0660 0.0605 0.0557 0.0530 0.0513 0.0500 0.0489 0.0478 0.0470 0.0465 0.0460 0.0457 

[TRAIN] Epoch[1](10745/114412); Loss: 0.091083; Backpropagation: 0.2926 sec; Batch: 2.1189 sec
0.1587 0.1432 0.1105 0.0987 0.0912 0.0859 0.0836 0.0807 0.0790 0.0774 0.0763 0.0755 0.0748 0.0743 0.0739 0.0737 

[TRAIN] Epoch[1](10746/114412); Loss: 0.101054; Backpropagation: 0.2954 sec; Batch: 2.1289 sec
0.1668 0.1534 0.1280 0.1127 0.1027 0.0967 0.0926 0.0899 0.0881 0.0864 0.0852 0.0843 0.0832 0.0826 0.0822 0.0819 

[TRAIN] Epoch[1](10747/114412); Loss: 0.059939; Backpropagation: 0.2940 sec; Batch: 2.1080 sec
0.1295 0.1221 0.0795 0.0631 0.0561 0.0518 0.0497 0.0481 0.0469 0.0461 0.0455 0.0451 0.0445 0.0439 0.0438 0.0435 

[TRAIN] Epoch[1](10748/114412); Loss: 0.084452; Backpropagation: 0.2928 sec; Batch: 2.1193 sec
0.1639 0.1395 0.1131 0.1000 0.0882 0.0800 0.0752 0.0724 0.0701 0.0676 0.0659 0.0648 0.0638 0.0630 0.0621 0.0616 

[TRAIN] Epoch[1](10749/114412); Loss: 0.065918; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1481 0.1383 0.0883 0.0693 0.0642 0.0584 0.0548 0.0526 0.0506 0.0494 0.0484 0.0476 0.0469 0.0463 0.0459 0.0456 

[TRAIN] Epoch[1](10750/114412); Loss: 0.073838; Backpropagation: 0.2912 sec; Batch: 2.1178 sec
0.1255 0.1176 0.0952 0.0852 0.0758 0.0707 0.0679 0.0657 0.0637 0.0621 0.0608 0.0597 0.0588 0.0582 0.0575 0.0571 

[TRAIN] Epoch[1](10751/114412); Loss: 0.091353; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1673 0.1550 0.1141 0.0999 0.0887 0.0850 0.0816 0.0793 0.0772 0.0758 0.0748 0.0737 0.0731 0.0724 0.0721 0.0716 

[TRAIN] Epoch[1](10752/114412); Loss: 0.086230; Backpropagation: 0.2934 sec; Batch: 2.1187 sec
0.1295 0.1163 0.1001 0.0951 0.0880 0.0851 0.0816 0.0794 0.0779 0.0767 0.0761 0.0755 0.0751 0.0749 0.0745 0.0742 

[TRAIN] Epoch[1](10753/114412); Loss: 0.082593; Backpropagation: 0.2910 sec; Batch: 2.1150 sec
0.1318 0.1195 0.0981 0.0922 0.0849 0.0809 0.0774 0.0747 0.0730 0.0719 0.0709 0.0703 0.0696 0.0691 0.0688 0.0683 

[TRAIN] Epoch[1](10754/114412); Loss: 0.048356; Backpropagation: 0.2933 sec; Batch: 2.1193 sec
0.1261 0.1238 0.0774 0.0584 0.0436 0.0385 0.0349 0.0332 0.0315 0.0305 0.0299 0.0296 0.0292 0.0290 0.0290 0.0290 

[TRAIN] Epoch[1](10755/114412); Loss: 0.066864; Backpropagation: 0.2932 sec; Batch: 2.1162 sec
0.1362 0.1216 0.0952 0.0835 0.0699 0.0635 0.0588 0.0554 0.0522 0.0505 0.0490 0.0480 0.0473 0.0467 0.0462 0.0459 

[TRAIN] Epoch[1](10756/114412); Loss: 0.067872; Backpropagation: 0.2910 sec; Batch: 2.1247 sec
0.1081 0.0984 0.0868 0.0759 0.0723 0.0674 0.0642 0.0612 0.0595 0.0583 0.0571 0.0564 0.0556 0.0552 0.0550 0.0545 

[TRAIN] Epoch[1](10757/114412); Loss: 0.070614; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1703 0.1395 0.0957 0.0889 0.0693 0.0609 0.0577 0.0545 0.0525 0.0517 0.0503 0.0493 0.0483 0.0475 0.0469 0.0464 

[TRAIN] Epoch[1](10758/114412); Loss: 0.073346; Backpropagation: 0.2907 sec; Batch: 2.0767 sec
0.1437 0.1214 0.1026 0.0882 0.0758 0.0706 0.0653 0.0618 0.0592 0.0580 0.0565 0.0555 0.0548 0.0540 0.0533 0.0528 

[TRAIN] Epoch[1](10759/114412); Loss: 0.065326; Backpropagation: 0.2907 sec; Batch: 2.1160 sec
0.1168 0.1114 0.0825 0.0775 0.0666 0.0608 0.0578 0.0559 0.0547 0.0534 0.0524 0.0518 0.0514 0.0511 0.0507 0.0505 

[TRAIN] Epoch[1](10760/114412); Loss: 0.088678; Backpropagation: 0.2905 sec; Batch: 2.0777 sec
0.1523 0.1458 0.1172 0.1058 0.0917 0.0831 0.0797 0.0761 0.0744 0.0732 0.0719 0.0710 0.0700 0.0694 0.0688 0.0685 

[TRAIN] Epoch[1](10761/114412); Loss: 0.080655; Backpropagation: 0.2911 sec; Batch: 2.1270 sec
0.1495 0.1383 0.0989 0.0847 0.0787 0.0744 0.0718 0.0698 0.0683 0.0671 0.0664 0.0655 0.0649 0.0644 0.0640 0.0637 

[TRAIN] Epoch[1](10762/114412); Loss: 0.073490; Backpropagation: 0.2915 sec; Batch: 2.0773 sec
0.1453 0.1373 0.1072 0.0893 0.0725 0.0660 0.0621 0.0596 0.0575 0.0563 0.0552 0.0543 0.0538 0.0534 0.0531 0.0528 

[TRAIN] Epoch[1](10763/114412); Loss: 0.112204; Backpropagation: 0.2955 sec; Batch: 2.1278 sec
0.1574 0.1455 0.1285 0.1211 0.1141 0.1100 0.1069 0.1052 0.1037 0.1026 0.1016 0.1009 0.1002 0.0996 0.0992 0.0989 

[TRAIN] Epoch[1](10764/114412); Loss: 0.089588; Backpropagation: 0.2950 sec; Batch: 2.1006 sec
0.1710 0.1566 0.1195 0.1033 0.0875 0.0810 0.0775 0.0752 0.0737 0.0723 0.0711 0.0701 0.0694 0.0690 0.0683 0.0678 

[TRAIN] Epoch[1](10765/114412); Loss: 0.051255; Backpropagation: 0.2929 sec; Batch: 2.0785 sec
0.1006 0.0937 0.0632 0.0575 0.0510 0.0476 0.0456 0.0434 0.0418 0.0411 0.0401 0.0395 0.0392 0.0387 0.0386 0.0384 

[TRAIN] Epoch[1](10766/114412); Loss: 0.076913; Backpropagation: 0.2905 sec; Batch: 2.1195 sec
0.1545 0.1296 0.1055 0.0921 0.0807 0.0738 0.0687 0.0649 0.0624 0.0607 0.0586 0.0576 0.0565 0.0557 0.0551 0.0543 

[TRAIN] Epoch[1](10767/114412); Loss: 0.064738; Backpropagation: 0.2904 sec; Batch: 2.0765 sec
0.1403 0.1228 0.0797 0.0746 0.0624 0.0587 0.0558 0.0530 0.0513 0.0500 0.0491 0.0483 0.0480 0.0477 0.0473 0.0469 

[TRAIN] Epoch[1](10768/114412); Loss: 0.093957; Backpropagation: 0.2954 sec; Batch: 2.0813 sec
0.1510 0.1400 0.1188 0.1076 0.0974 0.0918 0.0872 0.0845 0.0823 0.0806 0.0789 0.0780 0.0773 0.0765 0.0759 0.0754 

[TRAIN] Epoch[1](10769/114412); Loss: 0.064336; Backpropagation: 0.2924 sec; Batch: 2.0818 sec
0.1180 0.1038 0.0810 0.0715 0.0644 0.0609 0.0576 0.0559 0.0545 0.0535 0.0525 0.0519 0.0514 0.0510 0.0509 0.0506 

[TRAIN] Epoch[1](10770/114412); Loss: 0.074178; Backpropagation: 0.2951 sec; Batch: 2.1162 sec
0.1422 0.1253 0.1059 0.0891 0.0779 0.0708 0.0674 0.0637 0.0591 0.0578 0.0570 0.0556 0.0548 0.0539 0.0534 0.0529 

[TRAIN] Epoch[1](10771/114412); Loss: 0.062748; Backpropagation: 0.2905 sec; Batch: 2.1183 sec
0.1227 0.1128 0.0888 0.0748 0.0649 0.0583 0.0539 0.0513 0.0497 0.0484 0.0475 0.0469 0.0464 0.0461 0.0458 0.0455 

[TRAIN] Epoch[1](10772/114412); Loss: 0.073288; Backpropagation: 0.2906 sec; Batch: 2.1150 sec
0.1257 0.1121 0.0922 0.0814 0.0743 0.0713 0.0678 0.0651 0.0634 0.0620 0.0611 0.0603 0.0596 0.0591 0.0587 0.0585 

[TRAIN] Epoch[1](10773/114412); Loss: 0.064156; Backpropagation: 0.2956 sec; Batch: 2.1191 sec
0.1209 0.1035 0.0812 0.0748 0.0669 0.0621 0.0570 0.0543 0.0529 0.0519 0.0512 0.0506 0.0501 0.0500 0.0497 0.0496 

[TRAIN] Epoch[1](10774/114412); Loss: 0.065894; Backpropagation: 0.2928 sec; Batch: 2.1187 sec
0.1253 0.1129 0.0938 0.0809 0.0710 0.0635 0.0583 0.0555 0.0531 0.0520 0.0502 0.0492 0.0482 0.0474 0.0467 0.0462 

[TRAIN] Epoch[1](10775/114412); Loss: 0.078168; Backpropagation: 0.2927 sec; Batch: 2.1214 sec
0.1296 0.1170 0.0979 0.0883 0.0824 0.0760 0.0721 0.0693 0.0675 0.0663 0.0654 0.0647 0.0641 0.0637 0.0633 0.0631 

[TRAIN] Epoch[1](10776/114412); Loss: 0.080339; Backpropagation: 0.2916 sec; Batch: 2.1275 sec
0.1428 0.1271 0.1036 0.0918 0.0831 0.0759 0.0728 0.0706 0.0688 0.0670 0.0656 0.0647 0.0637 0.0631 0.0626 0.0623 

[TRAIN] Epoch[1](10777/114412); Loss: 0.053814; Backpropagation: 0.2909 sec; Batch: 2.1144 sec
0.1116 0.1063 0.0784 0.0686 0.0543 0.0496 0.0458 0.0429 0.0411 0.0400 0.0385 0.0376 0.0370 0.0368 0.0365 0.0362 

[TRAIN] Epoch[1](10778/114412); Loss: 0.063190; Backpropagation: 0.2954 sec; Batch: 2.1176 sec
0.1222 0.1117 0.0857 0.0710 0.0642 0.0605 0.0569 0.0536 0.0523 0.0504 0.0489 0.0483 0.0471 0.0464 0.0461 0.0458 

[TRAIN] Epoch[1](10779/114412); Loss: 0.068988; Backpropagation: 0.2955 sec; Batch: 2.1296 sec
0.1357 0.1186 0.0880 0.0802 0.0699 0.0651 0.0616 0.0591 0.0571 0.0551 0.0541 0.0531 0.0524 0.0519 0.0512 0.0508 

[TRAIN] Epoch[1](10780/114412); Loss: 0.057813; Backpropagation: 0.2954 sec; Batch: 2.0812 sec
0.1404 0.1368 0.0798 0.0612 0.0558 0.0510 0.0471 0.0437 0.0419 0.0402 0.0394 0.0387 0.0379 0.0375 0.0369 0.0367 

[TRAIN] Epoch[1](10781/114412); Loss: 0.086969; Backpropagation: 0.2906 sec; Batch: 2.1178 sec
0.1476 0.1421 0.1158 0.1056 0.0944 0.0867 0.0800 0.0751 0.0719 0.0700 0.0687 0.0677 0.0671 0.0667 0.0662 0.0659 

[TRAIN] Epoch[1](10782/114412); Loss: 0.077164; Backpropagation: 0.2906 sec; Batch: 2.0772 sec
0.1332 0.1119 0.0965 0.0857 0.0798 0.0749 0.0710 0.0686 0.0670 0.0656 0.0647 0.0641 0.0634 0.0632 0.0626 0.0622 

[TRAIN] Epoch[1](10783/114412); Loss: 0.071924; Backpropagation: 0.2910 sec; Batch: 2.1220 sec
0.1868 0.1627 0.1036 0.0770 0.0656 0.0596 0.0560 0.0536 0.0514 0.0502 0.0491 0.0483 0.0476 0.0469 0.0464 0.0461 

[TRAIN] Epoch[1](10784/114412); Loss: 0.079263; Backpropagation: 0.2910 sec; Batch: 2.1126 sec
0.1930 0.1685 0.1177 0.0852 0.0696 0.0638 0.0614 0.0598 0.0576 0.0567 0.0564 0.0559 0.0556 0.0556 0.0556 0.0556 

[TRAIN] Epoch[1](10785/114412); Loss: 0.081129; Backpropagation: 0.2906 sec; Batch: 2.0760 sec
0.1353 0.1212 0.1011 0.0922 0.0831 0.0780 0.0743 0.0718 0.0702 0.0690 0.0683 0.0677 0.0670 0.0666 0.0663 0.0660 

[TRAIN] Epoch[1](10786/114412); Loss: 0.079446; Backpropagation: 0.2906 sec; Batch: 2.1153 sec
0.1185 0.1110 0.0955 0.0882 0.0827 0.0791 0.0757 0.0737 0.0716 0.0702 0.0692 0.0684 0.0676 0.0671 0.0665 0.0661 

[TRAIN] Epoch[1](10787/114412); Loss: 0.062939; Backpropagation: 0.2907 sec; Batch: 2.1137 sec
0.1134 0.1046 0.0815 0.0722 0.0631 0.0584 0.0555 0.0542 0.0530 0.0517 0.0509 0.0504 0.0498 0.0495 0.0494 0.0493 

[TRAIN] Epoch[1](10788/114412); Loss: 0.084945; Backpropagation: 0.2914 sec; Batch: 2.1138 sec
0.1259 0.1152 0.1003 0.0937 0.0875 0.0840 0.0810 0.0787 0.0772 0.0759 0.0749 0.0741 0.0734 0.0729 0.0724 0.0722 

[TRAIN] Epoch[1](10789/114412); Loss: 0.070521; Backpropagation: 0.2912 sec; Batch: 2.1229 sec
0.1255 0.1148 0.0882 0.0803 0.0711 0.0673 0.0638 0.0618 0.0602 0.0588 0.0577 0.0570 0.0562 0.0556 0.0551 0.0548 

[TRAIN] Epoch[1](10790/114412); Loss: 0.064640; Backpropagation: 0.2903 sec; Batch: 2.1166 sec
0.1365 0.1184 0.0866 0.0760 0.0663 0.0604 0.0560 0.0534 0.0514 0.0501 0.0487 0.0476 0.0468 0.0459 0.0453 0.0447 

[TRAIN] Epoch[1](10791/114412); Loss: 0.069172; Backpropagation: 0.2913 sec; Batch: 2.1142 sec
0.1140 0.1013 0.0861 0.0780 0.0709 0.0675 0.0647 0.0625 0.0608 0.0596 0.0586 0.0577 0.0571 0.0565 0.0560 0.0555 

[TRAIN] Epoch[1](10792/114412); Loss: 0.079845; Backpropagation: 0.2910 sec; Batch: 2.0786 sec
0.1460 0.1319 0.1055 0.0933 0.0836 0.0773 0.0721 0.0687 0.0663 0.0646 0.0634 0.0623 0.0615 0.0609 0.0602 0.0599 

[TRAIN] Epoch[1](10793/114412); Loss: 0.069831; Backpropagation: 0.2913 sec; Batch: 2.0777 sec
0.1360 0.1108 0.0870 0.0782 0.0696 0.0655 0.0623 0.0602 0.0585 0.0575 0.0564 0.0560 0.0553 0.0551 0.0544 0.0544 

[TRAIN] Epoch[1](10794/114412); Loss: 0.083864; Backpropagation: 0.2908 sec; Batch: 2.1207 sec
0.1726 0.1583 0.1216 0.1026 0.0852 0.0765 0.0715 0.0683 0.0651 0.0631 0.0620 0.0606 0.0596 0.0588 0.0582 0.0576 

[TRAIN] Epoch[1](10795/114412); Loss: 0.069676; Backpropagation: 0.2930 sec; Batch: 2.0784 sec
0.1283 0.1142 0.0922 0.0830 0.0720 0.0668 0.0635 0.0599 0.0578 0.0562 0.0552 0.0544 0.0536 0.0531 0.0526 0.0521 

[TRAIN] Epoch[1](10796/114412); Loss: 0.088487; Backpropagation: 0.2931 sec; Batch: 2.1416 sec
0.1615 0.1482 0.1138 0.0991 0.0912 0.0878 0.0804 0.0775 0.0758 0.0718 0.0709 0.0696 0.0681 0.0672 0.0667 0.0662 

[TRAIN] Epoch[1](10797/114412); Loss: 0.072745; Backpropagation: 0.2930 sec; Batch: 2.0787 sec
0.1477 0.1294 0.0969 0.0861 0.0734 0.0670 0.0637 0.0608 0.0589 0.0572 0.0557 0.0549 0.0540 0.0533 0.0527 0.0523 

[TRAIN] Epoch[1](10798/114412); Loss: 0.088742; Backpropagation: 0.2930 sec; Batch: 2.1163 sec
0.1440 0.1316 0.1104 0.1013 0.0927 0.0863 0.0824 0.0798 0.0775 0.0760 0.0746 0.0738 0.0733 0.0725 0.0719 0.0715 

[TRAIN] Epoch[1](10799/114412); Loss: 0.077935; Backpropagation: 0.2931 sec; Batch: 2.0903 sec
0.1522 0.1466 0.1148 0.0997 0.0878 0.0804 0.0739 0.0682 0.0634 0.0593 0.0563 0.0533 0.0506 0.0484 0.0468 0.0453 

[TRAIN] Epoch[1](10800/114412); Loss: 0.075126; Backpropagation: 0.2903 sec; Batch: 2.1136 sec
0.1410 0.1180 0.0983 0.0900 0.0808 0.0722 0.0674 0.0641 0.0625 0.0607 0.0596 0.0588 0.0580 0.0574 0.0568 0.0564 

[TRAIN] Epoch[1](10801/114412); Loss: 0.078513; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1468 0.1248 0.0995 0.0900 0.0794 0.0741 0.0700 0.0677 0.0658 0.0645 0.0635 0.0629 0.0625 0.0620 0.0616 0.0612 

[TRAIN] Epoch[1](10802/114412); Loss: 0.069978; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1346 0.1192 0.0899 0.0856 0.0755 0.0688 0.0645 0.0610 0.0579 0.0555 0.0536 0.0523 0.0513 0.0505 0.0498 0.0495 

[TRAIN] Epoch[1](10803/114412); Loss: 0.076401; Backpropagation: 0.2911 sec; Batch: 2.1099 sec
0.1599 0.1329 0.0988 0.0852 0.0757 0.0710 0.0676 0.0647 0.0620 0.0605 0.0591 0.0585 0.0574 0.0569 0.0562 0.0558 

[TRAIN] Epoch[1](10804/114412); Loss: 0.077124; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1333 0.1232 0.0990 0.0889 0.0795 0.0748 0.0703 0.0674 0.0655 0.0641 0.0629 0.0621 0.0613 0.0609 0.0605 0.0601 

[TRAIN] Epoch[1](10805/114412); Loss: 0.083825; Backpropagation: 0.2929 sec; Batch: 2.1346 sec
0.1522 0.1460 0.1123 0.0964 0.0853 0.0782 0.0748 0.0718 0.0696 0.0679 0.0667 0.0655 0.0646 0.0639 0.0631 0.0627 

[TRAIN] Epoch[1](10806/114412); Loss: 0.056814; Backpropagation: 0.2931 sec; Batch: 2.1216 sec
0.1154 0.0972 0.0748 0.0652 0.0581 0.0529 0.0504 0.0481 0.0460 0.0453 0.0440 0.0432 0.0428 0.0423 0.0420 0.0417 

[TRAIN] Epoch[1](10807/114412); Loss: 0.082894; Backpropagation: 0.2905 sec; Batch: 2.1150 sec
0.1627 0.1451 0.1093 0.0958 0.0851 0.0773 0.0717 0.0693 0.0683 0.0663 0.0647 0.0637 0.0627 0.0619 0.0615 0.0609 

[TRAIN] Epoch[1](10808/114412); Loss: 0.081410; Backpropagation: 0.2912 sec; Batch: 2.0788 sec
0.1480 0.1349 0.1001 0.0883 0.0811 0.0761 0.0729 0.0706 0.0691 0.0677 0.0670 0.0663 0.0658 0.0654 0.0648 0.0644 

[TRAIN] Epoch[1](10809/114412); Loss: 0.068526; Backpropagation: 0.2903 sec; Batch: 2.0853 sec
0.1145 0.1049 0.0873 0.0792 0.0706 0.0662 0.0630 0.0612 0.0593 0.0575 0.0566 0.0561 0.0556 0.0551 0.0548 0.0546 

[TRAIN] Epoch[1](10810/114412); Loss: 0.071339; Backpropagation: 0.2907 sec; Batch: 2.0769 sec
0.1218 0.1093 0.0964 0.0854 0.0769 0.0706 0.0667 0.0630 0.0603 0.0591 0.0576 0.0565 0.0556 0.0548 0.0541 0.0535 

[TRAIN] Epoch[1](10811/114412); Loss: 0.091116; Backpropagation: 0.2904 sec; Batch: 2.1126 sec
0.1410 0.1285 0.1034 0.0974 0.0923 0.0884 0.0856 0.0837 0.0823 0.0812 0.0804 0.0795 0.0791 0.0787 0.0783 0.0781 

[TRAIN] Epoch[1](10812/114412); Loss: 0.078806; Backpropagation: 0.2915 sec; Batch: 2.0777 sec
0.1469 0.1334 0.1067 0.0907 0.0790 0.0733 0.0698 0.0678 0.0657 0.0642 0.0626 0.0613 0.0605 0.0601 0.0596 0.0592 

[TRAIN] Epoch[1](10813/114412); Loss: 0.082132; Backpropagation: 0.2910 sec; Batch: 2.0954 sec
0.1879 0.1703 0.1128 0.0822 0.0770 0.0720 0.0691 0.0650 0.0630 0.0617 0.0606 0.0594 0.0589 0.0584 0.0581 0.0577 

[TRAIN] Epoch[1](10814/114412); Loss: 0.083769; Backpropagation: 0.2953 sec; Batch: 2.1172 sec
0.1497 0.1422 0.1035 0.0968 0.0866 0.0802 0.0760 0.0725 0.0706 0.0689 0.0675 0.0665 0.0656 0.0650 0.0646 0.0642 

[TRAIN] Epoch[1](10815/114412); Loss: 0.103933; Backpropagation: 0.2954 sec; Batch: 2.1224 sec
0.1945 0.1750 0.1434 0.1275 0.1114 0.1013 0.0936 0.0887 0.0839 0.0820 0.0801 0.0785 0.0773 0.0761 0.0752 0.0746 

[TRAIN] Epoch[1](10816/114412); Loss: 0.072762; Backpropagation: 0.2952 sec; Batch: 2.0848 sec
0.1276 0.1132 0.0956 0.0845 0.0757 0.0711 0.0670 0.0641 0.0618 0.0602 0.0587 0.0581 0.0574 0.0569 0.0564 0.0560 

[TRAIN] Epoch[1](10817/114412); Loss: 0.100833; Backpropagation: 0.2908 sec; Batch: 2.0771 sec
0.1570 0.1465 0.1282 0.1131 0.1028 0.0978 0.0942 0.0922 0.0896 0.0878 0.0867 0.0851 0.0842 0.0835 0.0826 0.0820 

[TRAIN] Epoch[1](10818/114412); Loss: 0.063097; Backpropagation: 0.2903 sec; Batch: 2.1136 sec
0.1183 0.1087 0.0834 0.0708 0.0661 0.0598 0.0564 0.0539 0.0519 0.0507 0.0498 0.0489 0.0484 0.0479 0.0474 0.0471 

[TRAIN] Epoch[1](10819/114412); Loss: 0.050468; Backpropagation: 0.2905 sec; Batch: 2.0767 sec
0.0854 0.0834 0.0742 0.0618 0.0514 0.0467 0.0442 0.0430 0.0416 0.0406 0.0399 0.0395 0.0391 0.0390 0.0389 0.0389 

[TRAIN] Epoch[1](10820/114412); Loss: 0.059191; Backpropagation: 0.2905 sec; Batch: 2.1144 sec
0.1295 0.1172 0.0777 0.0732 0.0598 0.0549 0.0493 0.0477 0.0454 0.0441 0.0426 0.0420 0.0414 0.0410 0.0408 0.0405 

[TRAIN] Epoch[1](10821/114412); Loss: 0.070167; Backpropagation: 0.2910 sec; Batch: 2.0775 sec
0.1271 0.1170 0.0888 0.0778 0.0699 0.0657 0.0630 0.0607 0.0590 0.0580 0.0572 0.0565 0.0561 0.0557 0.0553 0.0550 

[TRAIN] Epoch[1](10822/114412); Loss: 0.084557; Backpropagation: 0.2908 sec; Batch: 2.1318 sec
0.1680 0.1506 0.1170 0.0967 0.0873 0.0797 0.0756 0.0720 0.0687 0.0662 0.0647 0.0632 0.0621 0.0614 0.0603 0.0594 

[TRAIN] Epoch[1](10823/114412); Loss: 0.074972; Backpropagation: 0.2909 sec; Batch: 2.1150 sec
0.1371 0.1294 0.1010 0.0843 0.0756 0.0715 0.0670 0.0639 0.0620 0.0607 0.0594 0.0585 0.0579 0.0575 0.0569 0.0567 

[TRAIN] Epoch[1](10824/114412); Loss: 0.064287; Backpropagation: 0.2907 sec; Batch: 2.1143 sec
0.1280 0.1124 0.0838 0.0743 0.0645 0.0605 0.0566 0.0540 0.0525 0.0509 0.0500 0.0492 0.0485 0.0482 0.0478 0.0474 

[TRAIN] Epoch[1](10825/114412); Loss: 0.075179; Backpropagation: 0.2928 sec; Batch: 2.1173 sec
0.1519 0.1244 0.0940 0.0860 0.0771 0.0696 0.0652 0.0629 0.0614 0.0604 0.0595 0.0588 0.0584 0.0579 0.0577 0.0576 

[TRAIN] Epoch[1](10826/114412); Loss: 0.086484; Backpropagation: 0.2928 sec; Batch: 2.1174 sec
0.1376 0.1234 0.1055 0.0969 0.0892 0.0846 0.0806 0.0783 0.0767 0.0757 0.0745 0.0734 0.0727 0.0720 0.0716 0.0711 

[TRAIN] Epoch[1](10827/114412); Loss: 0.072002; Backpropagation: 0.2911 sec; Batch: 2.0948 sec
0.1694 0.1457 0.0881 0.0791 0.0708 0.0635 0.0602 0.0579 0.0558 0.0542 0.0532 0.0521 0.0512 0.0507 0.0502 0.0498 

[TRAIN] Epoch[1](10828/114412); Loss: 0.063707; Backpropagation: 0.2909 sec; Batch: 2.1172 sec
0.1372 0.1206 0.0825 0.0694 0.0618 0.0582 0.0548 0.0523 0.0504 0.0492 0.0484 0.0478 0.0471 0.0468 0.0464 0.0463 

[TRAIN] Epoch[1](10829/114412); Loss: 0.068118; Backpropagation: 0.2910 sec; Batch: 2.0783 sec
0.1347 0.1247 0.0942 0.0843 0.0712 0.0628 0.0582 0.0552 0.0535 0.0522 0.0512 0.0506 0.0498 0.0494 0.0490 0.0488 

[TRAIN] Epoch[1](10830/114412); Loss: 0.073016; Backpropagation: 0.2914 sec; Batch: 2.0785 sec
0.1409 0.1229 0.0953 0.0865 0.0757 0.0697 0.0653 0.0624 0.0601 0.0585 0.0572 0.0560 0.0552 0.0547 0.0542 0.0535 

[TRAIN] Epoch[1](10831/114412); Loss: 0.058386; Backpropagation: 0.2906 sec; Batch: 2.0783 sec
0.1311 0.1237 0.0767 0.0617 0.0541 0.0503 0.0481 0.0463 0.0450 0.0441 0.0433 0.0427 0.0424 0.0420 0.0416 0.0413 

[TRAIN] Epoch[1](10832/114412); Loss: 0.078604; Backpropagation: 0.2909 sec; Batch: 2.1169 sec
0.1542 0.1233 0.1023 0.0860 0.0783 0.0742 0.0705 0.0679 0.0659 0.0643 0.0634 0.0624 0.0618 0.0613 0.0611 0.0607 

[TRAIN] Epoch[1](10833/114412); Loss: 0.079383; Backpropagation: 0.2910 sec; Batch: 2.1057 sec
0.1459 0.1381 0.1052 0.0911 0.0792 0.0751 0.0716 0.0677 0.0665 0.0646 0.0628 0.0618 0.0610 0.0602 0.0599 0.0595 

[TRAIN] Epoch[1](10834/114412); Loss: 0.078465; Backpropagation: 0.2916 sec; Batch: 2.1172 sec
0.1419 0.1341 0.0941 0.0806 0.0777 0.0730 0.0716 0.0688 0.0673 0.0656 0.0644 0.0641 0.0635 0.0635 0.0628 0.0623 

[TRAIN] Epoch[1](10835/114412); Loss: 0.073816; Backpropagation: 0.2914 sec; Batch: 2.1176 sec
0.1619 0.1467 0.1094 0.0939 0.0772 0.0659 0.0622 0.0577 0.0553 0.0537 0.0521 0.0507 0.0496 0.0488 0.0483 0.0478 

[TRAIN] Epoch[1](10836/114412); Loss: 0.058779; Backpropagation: 0.2908 sec; Batch: 2.1155 sec
0.1160 0.1050 0.0771 0.0658 0.0572 0.0535 0.0509 0.0489 0.0477 0.0468 0.0460 0.0456 0.0455 0.0450 0.0448 0.0447 

[TRAIN] Epoch[1](10837/114412); Loss: 0.083333; Backpropagation: 0.2914 sec; Batch: 2.1171 sec
0.1384 0.1291 0.1061 0.0955 0.0851 0.0793 0.0755 0.0731 0.0717 0.0705 0.0695 0.0688 0.0683 0.0678 0.0674 0.0674 

[TRAIN] Epoch[1](10838/114412); Loss: 0.059709; Backpropagation: 0.2906 sec; Batch: 2.0915 sec
0.1093 0.0950 0.0815 0.0699 0.0617 0.0575 0.0534 0.0514 0.0500 0.0487 0.0475 0.0466 0.0462 0.0458 0.0455 0.0453 

[TRAIN] Epoch[1](10839/114412); Loss: 0.068843; Backpropagation: 0.2905 sec; Batch: 2.1220 sec
0.1478 0.1269 0.0854 0.0818 0.0690 0.0625 0.0586 0.0565 0.0547 0.0535 0.0522 0.0513 0.0507 0.0504 0.0501 0.0501 

[TRAIN] Epoch[1](10840/114412); Loss: 0.077387; Backpropagation: 0.2911 sec; Batch: 2.0896 sec
0.1396 0.1264 0.0993 0.0869 0.0776 0.0716 0.0693 0.0674 0.0655 0.0642 0.0631 0.0623 0.0618 0.0614 0.0611 0.0609 

[TRAIN] Epoch[1](10841/114412); Loss: 0.085331; Backpropagation: 0.2907 sec; Batch: 2.1139 sec
0.1826 0.1528 0.1124 0.0929 0.0840 0.0766 0.0723 0.0702 0.0684 0.0670 0.0659 0.0652 0.0644 0.0638 0.0636 0.0633 

[TRAIN] Epoch[1](10842/114412); Loss: 0.045911; Backpropagation: 0.2911 sec; Batch: 2.1225 sec
0.1071 0.1038 0.0674 0.0591 0.0484 0.0403 0.0373 0.0340 0.0321 0.0311 0.0300 0.0296 0.0289 0.0286 0.0284 0.0284 

[TRAIN] Epoch[1](10843/114412); Loss: 0.063958; Backpropagation: 0.2908 sec; Batch: 2.1170 sec
0.1460 0.1098 0.0899 0.0793 0.0683 0.0582 0.0542 0.0504 0.0490 0.0476 0.0466 0.0458 0.0452 0.0447 0.0443 0.0440 

[TRAIN] Epoch[1](10844/114412); Loss: 0.063505; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1249 0.1019 0.0799 0.0681 0.0621 0.0589 0.0565 0.0548 0.0533 0.0524 0.0515 0.0508 0.0504 0.0503 0.0502 0.0501 

[TRAIN] Epoch[1](10845/114412); Loss: 0.104057; Backpropagation: 0.2914 sec; Batch: 2.1162 sec
0.1790 0.1650 0.1383 0.1238 0.1115 0.1042 0.0979 0.0938 0.0900 0.0864 0.0838 0.0813 0.0795 0.0779 0.0766 0.0760 

[TRAIN] Epoch[1](10846/114412); Loss: 0.050491; Backpropagation: 0.2907 sec; Batch: 2.0765 sec
0.1208 0.0979 0.0739 0.0586 0.0536 0.0459 0.0423 0.0392 0.0379 0.0365 0.0352 0.0343 0.0337 0.0330 0.0326 0.0323 

[TRAIN] Epoch[1](10847/114412); Loss: 0.065093; Backpropagation: 0.2943 sec; Batch: 2.1198 sec
0.1661 0.1495 0.1066 0.0731 0.0538 0.0523 0.0495 0.0476 0.0458 0.0443 0.0434 0.0427 0.0421 0.0419 0.0416 0.0412 

[TRAIN] Epoch[1](10848/114412); Loss: 0.111563; Backpropagation: 0.2943 sec; Batch: 2.1179 sec
0.2018 0.1820 0.1420 0.1337 0.1151 0.1068 0.1003 0.0965 0.0939 0.0916 0.0895 0.0885 0.0871 0.0863 0.0854 0.0846 

[TRAIN] Epoch[1](10849/114412); Loss: 0.070580; Backpropagation: 0.2952 sec; Batch: 2.1226 sec
0.1407 0.1349 0.0985 0.0817 0.0696 0.0630 0.0596 0.0579 0.0559 0.0544 0.0537 0.0529 0.0522 0.0516 0.0513 0.0511 

[TRAIN] Epoch[1](10850/114412); Loss: 0.059218; Backpropagation: 0.2932 sec; Batch: 2.1174 sec
0.1116 0.0963 0.0814 0.0690 0.0624 0.0568 0.0529 0.0498 0.0486 0.0477 0.0467 0.0459 0.0452 0.0447 0.0443 0.0442 

[TRAIN] Epoch[1](10851/114412); Loss: 0.063392; Backpropagation: 0.2914 sec; Batch: 2.1153 sec
0.1175 0.1015 0.0815 0.0715 0.0662 0.0615 0.0574 0.0553 0.0534 0.0519 0.0509 0.0500 0.0494 0.0490 0.0487 0.0484 

[TRAIN] Epoch[1](10852/114412); Loss: 0.076186; Backpropagation: 0.2919 sec; Batch: 2.1200 sec
0.1255 0.1153 0.0953 0.0859 0.0783 0.0738 0.0706 0.0684 0.0670 0.0655 0.0640 0.0632 0.0624 0.0617 0.0612 0.0609 

[TRAIN] Epoch[1](10853/114412); Loss: 0.075628; Backpropagation: 0.2910 sec; Batch: 2.0782 sec
0.1662 0.1413 0.1058 0.0879 0.0790 0.0703 0.0669 0.0627 0.0588 0.0572 0.0551 0.0537 0.0524 0.0516 0.0508 0.0503 

[TRAIN] Epoch[1](10854/114412); Loss: 0.085287; Backpropagation: 0.2906 sec; Batch: 2.1166 sec
0.1699 0.1575 0.1112 0.0893 0.0816 0.0786 0.0755 0.0718 0.0699 0.0686 0.0669 0.0660 0.0653 0.0646 0.0641 0.0638 

[TRAIN] Epoch[1](10855/114412); Loss: 0.097648; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.1804 0.1614 0.1314 0.1137 0.1017 0.0919 0.0871 0.0836 0.0809 0.0788 0.0775 0.0763 0.0754 0.0747 0.0741 0.0735 

[TRAIN] Epoch[1](10856/114412); Loss: 0.067173; Backpropagation: 0.2925 sec; Batch: 2.1192 sec
0.1298 0.1183 0.0847 0.0724 0.0657 0.0622 0.0597 0.0572 0.0555 0.0544 0.0536 0.0529 0.0525 0.0522 0.0519 0.0517 

[TRAIN] Epoch[1](10857/114412); Loss: 0.090150; Backpropagation: 0.2915 sec; Batch: 2.1124 sec
0.1803 0.1576 0.1150 0.0978 0.0877 0.0832 0.0798 0.0766 0.0744 0.0728 0.0715 0.0705 0.0697 0.0690 0.0685 0.0681 

[TRAIN] Epoch[1](10858/114412); Loss: 0.082258; Backpropagation: 0.2912 sec; Batch: 2.1144 sec
0.1369 0.1205 0.0982 0.0911 0.0848 0.0809 0.0772 0.0746 0.0725 0.0709 0.0699 0.0689 0.0681 0.0676 0.0672 0.0668 

[TRAIN] Epoch[1](10859/114412); Loss: 0.055813; Backpropagation: 0.2907 sec; Batch: 2.1190 sec
0.0965 0.0947 0.0759 0.0646 0.0596 0.0545 0.0512 0.0485 0.0466 0.0453 0.0441 0.0433 0.0427 0.0422 0.0417 0.0415 

[TRAIN] Epoch[1](10860/114412); Loss: 0.067647; Backpropagation: 0.2912 sec; Batch: 2.1198 sec
0.1323 0.1198 0.0931 0.0780 0.0699 0.0643 0.0606 0.0571 0.0550 0.0530 0.0517 0.0508 0.0499 0.0494 0.0489 0.0485 

[TRAIN] Epoch[1](10861/114412); Loss: 0.106791; Backpropagation: 0.2916 sec; Batch: 2.1152 sec
0.1576 0.1493 0.1383 0.1243 0.1168 0.1081 0.1014 0.0978 0.0942 0.0926 0.0910 0.0896 0.0885 0.0872 0.0865 0.0855 

[TRAIN] Epoch[1](10862/114412); Loss: 0.062691; Backpropagation: 0.2913 sec; Batch: 2.1195 sec
0.1452 0.1306 0.0903 0.0742 0.0624 0.0550 0.0518 0.0486 0.0467 0.0448 0.0438 0.0431 0.0425 0.0419 0.0413 0.0409 

[TRAIN] Epoch[1](10863/114412); Loss: 0.061856; Backpropagation: 0.2906 sec; Batch: 2.1138 sec
0.1048 0.0926 0.0876 0.0729 0.0661 0.0618 0.0586 0.0546 0.0519 0.0502 0.0493 0.0486 0.0482 0.0478 0.0474 0.0472 

[TRAIN] Epoch[1](10864/114412); Loss: 0.086510; Backpropagation: 0.2908 sec; Batch: 2.1135 sec
0.1634 0.1515 0.1144 0.1018 0.0880 0.0788 0.0769 0.0737 0.0717 0.0699 0.0681 0.0670 0.0660 0.0648 0.0643 0.0638 

[TRAIN] Epoch[1](10865/114412); Loss: 0.053328; Backpropagation: 0.2911 sec; Batch: 2.1140 sec
0.1127 0.0961 0.0711 0.0604 0.0529 0.0492 0.0468 0.0440 0.0424 0.0414 0.0404 0.0399 0.0394 0.0390 0.0388 0.0388 

[TRAIN] Epoch[1](10866/114412); Loss: 0.081776; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.1463 0.1388 0.1064 0.0953 0.0831 0.0771 0.0739 0.0707 0.0685 0.0669 0.0655 0.0645 0.0637 0.0631 0.0626 0.0621 

[TRAIN] Epoch[1](10867/114412); Loss: 0.070850; Backpropagation: 0.2910 sec; Batch: 2.1127 sec
0.1355 0.1263 0.0883 0.0815 0.0719 0.0669 0.0635 0.0598 0.0579 0.0568 0.0556 0.0548 0.0542 0.0538 0.0535 0.0534 

[TRAIN] Epoch[1](10868/114412); Loss: 0.108819; Backpropagation: 0.2899 sec; Batch: 2.0758 sec
0.1906 0.1793 0.1415 0.1173 0.1058 0.1024 0.0986 0.0944 0.0925 0.0909 0.0900 0.0891 0.0882 0.0874 0.0868 0.0863 

[TRAIN] Epoch[1](10869/114412); Loss: 0.110450; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.1651 0.1534 0.1284 0.1219 0.1147 0.1084 0.1050 0.1014 0.0998 0.0985 0.0972 0.0962 0.0952 0.0946 0.0938 0.0934 

[TRAIN] Epoch[1](10870/114412); Loss: 0.088805; Backpropagation: 0.2905 sec; Batch: 2.1170 sec
0.1648 0.1552 0.1316 0.1133 0.0998 0.0872 0.0796 0.0749 0.0715 0.0695 0.0666 0.0654 0.0628 0.0609 0.0595 0.0584 

[TRAIN] Epoch[1](10871/114412); Loss: 0.066931; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1230 0.1048 0.0887 0.0767 0.0687 0.0646 0.0612 0.0586 0.0569 0.0553 0.0541 0.0531 0.0523 0.0515 0.0509 0.0504 

[TRAIN] Epoch[1](10872/114412); Loss: 0.085878; Backpropagation: 0.2911 sec; Batch: 2.1143 sec
0.1709 0.1582 0.1223 0.1006 0.0886 0.0787 0.0745 0.0709 0.0682 0.0666 0.0647 0.0634 0.0625 0.0618 0.0613 0.0609 

[TRAIN] Epoch[1](10873/114412); Loss: 0.068808; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1279 0.1208 0.0861 0.0771 0.0687 0.0651 0.0607 0.0586 0.0572 0.0556 0.0549 0.0543 0.0541 0.0535 0.0533 0.0530 

[TRAIN] Epoch[1](10874/114412); Loss: 0.098453; Backpropagation: 0.2915 sec; Batch: 2.1159 sec
0.1791 0.1596 0.1225 0.1066 0.0961 0.0914 0.0882 0.0855 0.0837 0.0820 0.0816 0.0808 0.0800 0.0797 0.0793 0.0791 

[TRAIN] Epoch[1](10875/114412); Loss: 0.051154; Backpropagation: 0.2929 sec; Batch: 2.1181 sec
0.0952 0.0912 0.0704 0.0607 0.0529 0.0479 0.0449 0.0425 0.0411 0.0401 0.0394 0.0390 0.0387 0.0384 0.0381 0.0381 

[TRAIN] Epoch[1](10876/114412); Loss: 0.067723; Backpropagation: 0.2950 sec; Batch: 2.1040 sec
0.1369 0.1205 0.0912 0.0766 0.0688 0.0618 0.0589 0.0564 0.0551 0.0535 0.0523 0.0513 0.0507 0.0502 0.0499 0.0495 

[TRAIN] Epoch[1](10877/114412); Loss: 0.066085; Backpropagation: 0.2929 sec; Batch: 2.1275 sec
0.1407 0.1199 0.0890 0.0741 0.0664 0.0610 0.0561 0.0538 0.0522 0.0506 0.0499 0.0493 0.0489 0.0486 0.0485 0.0484 

[TRAIN] Epoch[1](10878/114412); Loss: 0.079333; Backpropagation: 0.2950 sec; Batch: 2.1229 sec
0.1459 0.1336 0.0993 0.0888 0.0814 0.0753 0.0716 0.0689 0.0664 0.0651 0.0637 0.0630 0.0623 0.0617 0.0613 0.0610 

[TRAIN] Epoch[1](10879/114412); Loss: 0.082680; Backpropagation: 0.2940 sec; Batch: 2.1158 sec
0.1340 0.1227 0.1078 0.0926 0.0851 0.0798 0.0765 0.0735 0.0720 0.0707 0.0696 0.0688 0.0682 0.0676 0.0671 0.0666 

[TRAIN] Epoch[1](10880/114412); Loss: 0.052680; Backpropagation: 0.2931 sec; Batch: 2.1175 sec
0.1093 0.1013 0.0755 0.0589 0.0535 0.0479 0.0448 0.0430 0.0409 0.0399 0.0389 0.0386 0.0381 0.0376 0.0375 0.0373 

[TRAIN] Epoch[1](10881/114412); Loss: 0.067088; Backpropagation: 0.2923 sec; Batch: 2.1202 sec
0.1486 0.1347 0.0955 0.0820 0.0702 0.0625 0.0565 0.0520 0.0498 0.0483 0.0471 0.0465 0.0457 0.0450 0.0446 0.0442 

[TRAIN] Epoch[1](10882/114412); Loss: 0.077311; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1340 0.1223 0.0982 0.0876 0.0801 0.0750 0.0705 0.0679 0.0664 0.0647 0.0638 0.0628 0.0620 0.0611 0.0605 0.0601 

[TRAIN] Epoch[1](10883/114412); Loss: 0.081098; Backpropagation: 0.2927 sec; Batch: 2.1165 sec
0.1357 0.1249 0.0999 0.0910 0.0837 0.0795 0.0754 0.0731 0.0710 0.0692 0.0678 0.0668 0.0658 0.0652 0.0644 0.0640 

[TRAIN] Epoch[1](10884/114412); Loss: 0.084583; Backpropagation: 0.2934 sec; Batch: 2.0875 sec
0.1383 0.1184 0.1067 0.0968 0.0877 0.0834 0.0794 0.0766 0.0745 0.0731 0.0720 0.0709 0.0700 0.0692 0.0685 0.0678 

[TRAIN] Epoch[1](10885/114412); Loss: 0.057493; Backpropagation: 0.2926 sec; Batch: 2.1139 sec
0.1130 0.1026 0.0933 0.0759 0.0610 0.0566 0.0527 0.0480 0.0432 0.0419 0.0404 0.0392 0.0387 0.0382 0.0378 0.0376 

[TRAIN] Epoch[1](10886/114412); Loss: 0.059282; Backpropagation: 0.2905 sec; Batch: 2.1114 sec
0.1216 0.1130 0.0818 0.0705 0.0590 0.0536 0.0511 0.0483 0.0463 0.0450 0.0443 0.0436 0.0431 0.0427 0.0424 0.0422 

[TRAIN] Epoch[1](10887/114412); Loss: 0.061475; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1460 0.1313 0.0873 0.0727 0.0630 0.0570 0.0505 0.0469 0.0452 0.0429 0.0421 0.0410 0.0403 0.0396 0.0392 0.0388 

[TRAIN] Epoch[1](10888/114412); Loss: 0.061411; Backpropagation: 0.2911 sec; Batch: 2.1149 sec
0.1034 0.0989 0.0801 0.0737 0.0644 0.0599 0.0568 0.0540 0.0527 0.0510 0.0495 0.0487 0.0478 0.0475 0.0472 0.0468 

[TRAIN] Epoch[1](10889/114412); Loss: 0.085275; Backpropagation: 0.2909 sec; Batch: 2.1455 sec
0.1481 0.1356 0.1047 0.0945 0.0877 0.0823 0.0786 0.0756 0.0735 0.0722 0.0708 0.0697 0.0688 0.0680 0.0674 0.0669 

[TRAIN] Epoch[1](10890/114412); Loss: 0.087871; Backpropagation: 0.2929 sec; Batch: 2.1172 sec
0.1829 0.1625 0.1145 0.0984 0.0899 0.0828 0.0771 0.0725 0.0698 0.0679 0.0669 0.0656 0.0648 0.0638 0.0634 0.0630 

[TRAIN] Epoch[1](10891/114412); Loss: 0.077828; Backpropagation: 0.2915 sec; Batch: 2.1134 sec
0.1357 0.1207 0.0932 0.0844 0.0800 0.0750 0.0713 0.0694 0.0674 0.0661 0.0652 0.0644 0.0639 0.0633 0.0629 0.0625 

[TRAIN] Epoch[1](10892/114412); Loss: 0.058980; Backpropagation: 0.2909 sec; Batch: 2.1169 sec
0.1052 0.0916 0.0784 0.0663 0.0590 0.0563 0.0536 0.0512 0.0499 0.0489 0.0481 0.0476 0.0471 0.0469 0.0468 0.0467 

[TRAIN] Epoch[1](10893/114412); Loss: 0.071392; Backpropagation: 0.2905 sec; Batch: 2.1135 sec
0.1498 0.1282 0.0832 0.0840 0.0716 0.0668 0.0632 0.0601 0.0580 0.0565 0.0552 0.0543 0.0536 0.0530 0.0526 0.0521 

[TRAIN] Epoch[1](10894/114412); Loss: 0.065804; Backpropagation: 0.2906 sec; Batch: 2.1133 sec
0.1350 0.1226 0.0911 0.0788 0.0670 0.0611 0.0573 0.0539 0.0519 0.0506 0.0495 0.0482 0.0475 0.0467 0.0460 0.0456 

[TRAIN] Epoch[1](10895/114412); Loss: 0.069220; Backpropagation: 0.2952 sec; Batch: 2.1185 sec
0.1163 0.1141 0.0880 0.0797 0.0708 0.0651 0.0621 0.0604 0.0593 0.0580 0.0570 0.0562 0.0556 0.0553 0.0550 0.0547 

[TRAIN] Epoch[1](10896/114412); Loss: 0.067753; Backpropagation: 0.2906 sec; Batch: 2.0775 sec
0.1212 0.1123 0.0903 0.0791 0.0692 0.0643 0.0608 0.0585 0.0569 0.0555 0.0543 0.0536 0.0527 0.0521 0.0518 0.0514 

[TRAIN] Epoch[1](10897/114412); Loss: 0.107512; Backpropagation: 0.2912 sec; Batch: 2.1146 sec
0.1450 0.1325 0.1338 0.1160 0.1103 0.1068 0.1043 0.1007 0.0994 0.0982 0.0973 0.0965 0.0956 0.0952 0.0946 0.0940 

[TRAIN] Epoch[1](10898/114412); Loss: 0.092117; Backpropagation: 0.2913 sec; Batch: 2.0784 sec
0.1559 0.1467 0.1206 0.1095 0.0992 0.0922 0.0865 0.0817 0.0790 0.0763 0.0743 0.0728 0.0711 0.0701 0.0694 0.0684 

[TRAIN] Epoch[1](10899/114412); Loss: 0.086169; Backpropagation: 0.2910 sec; Batch: 2.1202 sec
0.1498 0.1238 0.1058 0.0975 0.0864 0.0837 0.0801 0.0778 0.0756 0.0739 0.0728 0.0717 0.0709 0.0702 0.0696 0.0692 

[TRAIN] Epoch[1](10900/114412); Loss: 0.092648; Backpropagation: 0.2953 sec; Batch: 2.0805 sec
0.1753 0.1650 0.1194 0.1023 0.0916 0.0868 0.0824 0.0789 0.0764 0.0748 0.0737 0.0725 0.0717 0.0709 0.0706 0.0702 

[TRAIN] Epoch[1](10901/114412); Loss: 0.071591; Backpropagation: 0.2953 sec; Batch: 2.0997 sec
0.1670 0.1515 0.1025 0.0814 0.0641 0.0591 0.0574 0.0556 0.0541 0.0529 0.0514 0.0508 0.0502 0.0495 0.0492 0.0489 

[TRAIN] Epoch[1](10902/114412); Loss: 0.062416; Backpropagation: 0.2928 sec; Batch: 2.0800 sec
0.1320 0.1254 0.0844 0.0730 0.0622 0.0573 0.0533 0.0502 0.0485 0.0470 0.0458 0.0451 0.0443 0.0438 0.0433 0.0430 

[TRAIN] Epoch[1](10903/114412); Loss: 0.064380; Backpropagation: 0.2910 sec; Batch: 2.1194 sec
0.1441 0.1249 0.0895 0.0752 0.0655 0.0576 0.0535 0.0510 0.0493 0.0480 0.0468 0.0460 0.0454 0.0449 0.0444 0.0441 

[TRAIN] Epoch[1](10904/114412); Loss: 0.066307; Backpropagation: 0.2912 sec; Batch: 2.1212 sec
0.1148 0.1036 0.0950 0.0775 0.0710 0.0628 0.0601 0.0572 0.0552 0.0542 0.0530 0.0524 0.0516 0.0512 0.0509 0.0504 

[TRAIN] Epoch[1](10905/114412); Loss: 0.073118; Backpropagation: 0.2910 sec; Batch: 2.1153 sec
0.1289 0.1166 0.0971 0.0845 0.0757 0.0698 0.0656 0.0633 0.0615 0.0601 0.0592 0.0582 0.0579 0.0575 0.0572 0.0568 

[TRAIN] Epoch[1](10906/114412); Loss: 0.074800; Backpropagation: 0.2904 sec; Batch: 2.1136 sec
0.1342 0.1236 0.0993 0.0900 0.0775 0.0701 0.0666 0.0642 0.0620 0.0608 0.0599 0.0588 0.0581 0.0574 0.0572 0.0570 

[TRAIN] Epoch[1](10907/114412); Loss: 0.054490; Backpropagation: 0.2909 sec; Batch: 2.1157 sec
0.1171 0.1087 0.0759 0.0618 0.0568 0.0508 0.0467 0.0437 0.0419 0.0406 0.0394 0.0386 0.0380 0.0375 0.0373 0.0371 

[TRAIN] Epoch[1](10908/114412); Loss: 0.062534; Backpropagation: 0.2911 sec; Batch: 2.1166 sec
0.1052 0.0985 0.0841 0.0721 0.0652 0.0606 0.0573 0.0552 0.0530 0.0518 0.0508 0.0502 0.0497 0.0493 0.0489 0.0487 

[TRAIN] Epoch[1](10909/114412); Loss: 0.055316; Backpropagation: 0.2907 sec; Batch: 2.1158 sec
0.1052 0.0981 0.0732 0.0601 0.0554 0.0507 0.0483 0.0468 0.0454 0.0443 0.0436 0.0433 0.0429 0.0426 0.0426 0.0425 

[TRAIN] Epoch[1](10910/114412); Loss: 0.071460; Backpropagation: 0.2912 sec; Batch: 2.0768 sec
0.1542 0.1366 0.0965 0.0814 0.0733 0.0652 0.0602 0.0572 0.0554 0.0540 0.0530 0.0522 0.0516 0.0512 0.0509 0.0506 

[TRAIN] Epoch[1](10911/114412); Loss: 0.078769; Backpropagation: 0.2910 sec; Batch: 2.1178 sec
0.1774 0.1587 0.1157 0.0973 0.0792 0.0709 0.0656 0.0620 0.0592 0.0571 0.0551 0.0538 0.0531 0.0523 0.0516 0.0512 

[TRAIN] Epoch[1](10912/114412); Loss: 0.079216; Backpropagation: 0.2906 sec; Batch: 2.0765 sec
0.1558 0.1364 0.1007 0.0932 0.0813 0.0750 0.0701 0.0680 0.0647 0.0632 0.0618 0.0606 0.0599 0.0595 0.0588 0.0584 

[TRAIN] Epoch[1](10913/114412); Loss: 0.065273; Backpropagation: 0.2913 sec; Batch: 2.1181 sec
0.1222 0.1118 0.0860 0.0776 0.0678 0.0625 0.0594 0.0567 0.0537 0.0519 0.0508 0.0499 0.0492 0.0488 0.0483 0.0479 

[TRAIN] Epoch[1](10914/114412); Loss: 0.088546; Backpropagation: 0.2927 sec; Batch: 2.1150 sec
0.1428 0.1362 0.1141 0.1032 0.0947 0.0867 0.0836 0.0791 0.0767 0.0748 0.0731 0.0720 0.0710 0.0701 0.0695 0.0690 

[TRAIN] Epoch[1](10915/114412); Loss: 0.081987; Backpropagation: 0.2950 sec; Batch: 2.1213 sec
0.1621 0.1594 0.1113 0.0927 0.0780 0.0737 0.0698 0.0673 0.0654 0.0639 0.0629 0.0622 0.0614 0.0610 0.0606 0.0603 

[TRAIN] Epoch[1](10916/114412); Loss: 0.071122; Backpropagation: 0.2932 sec; Batch: 2.1146 sec
0.1308 0.1206 0.0865 0.0782 0.0715 0.0671 0.0642 0.0614 0.0599 0.0588 0.0577 0.0571 0.0566 0.0562 0.0559 0.0555 

[TRAIN] Epoch[1](10917/114412); Loss: 0.061461; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1181 0.1109 0.0791 0.0693 0.0592 0.0558 0.0536 0.0515 0.0503 0.0493 0.0486 0.0482 0.0478 0.0475 0.0473 0.0471 

[TRAIN] Epoch[1](10918/114412); Loss: 0.066742; Backpropagation: 0.2908 sec; Batch: 2.1205 sec
0.1422 0.1367 0.0876 0.0742 0.0658 0.0606 0.0571 0.0542 0.0519 0.0503 0.0494 0.0487 0.0480 0.0475 0.0471 0.0467 

[TRAIN] Epoch[1](10919/114412); Loss: 0.058557; Backpropagation: 0.2913 sec; Batch: 2.1188 sec
0.1019 0.0951 0.0782 0.0688 0.0602 0.0563 0.0528 0.0505 0.0491 0.0481 0.0474 0.0467 0.0459 0.0456 0.0452 0.0451 

[TRAIN] Epoch[1](10920/114412); Loss: 0.095917; Backpropagation: 0.2907 sec; Batch: 2.1160 sec
0.1455 0.1298 0.1160 0.1074 0.1008 0.0966 0.0918 0.0881 0.0860 0.0843 0.0832 0.0821 0.0816 0.0809 0.0805 0.0800 

[TRAIN] Epoch[1](10921/114412); Loss: 0.070014; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1504 0.1336 0.0958 0.0839 0.0714 0.0656 0.0619 0.0575 0.0545 0.0524 0.0512 0.0500 0.0489 0.0482 0.0478 0.0471 

[TRAIN] Epoch[1](10922/114412); Loss: 0.068362; Backpropagation: 0.2910 sec; Batch: 2.1144 sec
0.0977 0.0919 0.0874 0.0763 0.0705 0.0672 0.0643 0.0627 0.0613 0.0604 0.0599 0.0592 0.0591 0.0587 0.0586 0.0584 

[TRAIN] Epoch[1](10923/114412); Loss: 0.060214; Backpropagation: 0.2912 sec; Batch: 2.1200 sec
0.0985 0.0928 0.0773 0.0705 0.0640 0.0598 0.0558 0.0534 0.0518 0.0504 0.0494 0.0489 0.0483 0.0478 0.0475 0.0473 

[TRAIN] Epoch[1](10924/114412); Loss: 0.082993; Backpropagation: 0.2910 sec; Batch: 2.0776 sec
0.1619 0.1447 0.1206 0.1051 0.0902 0.0806 0.0726 0.0684 0.0652 0.0631 0.0615 0.0605 0.0595 0.0586 0.0580 0.0575 

[TRAIN] Epoch[1](10925/114412); Loss: 0.094379; Backpropagation: 0.2925 sec; Batch: 2.1229 sec
0.1902 0.1799 0.1351 0.1141 0.0944 0.0855 0.0807 0.0761 0.0735 0.0716 0.0702 0.0691 0.0683 0.0676 0.0670 0.0668 

[TRAIN] Epoch[1](10926/114412); Loss: 0.083586; Backpropagation: 0.2909 sec; Batch: 2.0769 sec
0.1607 0.1452 0.1144 0.1015 0.0881 0.0805 0.0752 0.0708 0.0681 0.0656 0.0637 0.0626 0.0614 0.0605 0.0599 0.0593 

[TRAIN] Epoch[1](10927/114412); Loss: 0.087916; Backpropagation: 0.2910 sec; Batch: 2.1236 sec
0.1404 0.1305 0.1093 0.0953 0.0908 0.0857 0.0819 0.0794 0.0776 0.0762 0.0750 0.0742 0.0734 0.0727 0.0723 0.0720 

[TRAIN] Epoch[1](10928/114412); Loss: 0.075892; Backpropagation: 0.2903 sec; Batch: 2.1088 sec
0.1326 0.1196 0.1021 0.0882 0.0776 0.0715 0.0682 0.0660 0.0640 0.0627 0.0618 0.0610 0.0604 0.0598 0.0594 0.0591 

[TRAIN] Epoch[1](10929/114412); Loss: 0.072168; Backpropagation: 0.2907 sec; Batch: 2.0991 sec
0.1386 0.1263 0.0927 0.0819 0.0719 0.0680 0.0639 0.0610 0.0591 0.0581 0.0570 0.0564 0.0558 0.0551 0.0547 0.0543 

[TRAIN] Epoch[1](10930/114412); Loss: 0.061254; Backpropagation: 0.2905 sec; Batch: 2.1127 sec
0.1101 0.1103 0.0833 0.0755 0.0643 0.0575 0.0545 0.0514 0.0498 0.0484 0.0473 0.0464 0.0459 0.0454 0.0451 0.0449 

[TRAIN] Epoch[1](10931/114412); Loss: 0.085994; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1552 0.1464 0.1106 0.0993 0.0879 0.0818 0.0773 0.0735 0.0717 0.0702 0.0687 0.0679 0.0670 0.0666 0.0661 0.0657 

[TRAIN] Epoch[1](10932/114412); Loss: 0.073579; Backpropagation: 0.2928 sec; Batch: 2.0963 sec
0.1438 0.1313 0.0977 0.0903 0.0795 0.0705 0.0666 0.0622 0.0597 0.0572 0.0557 0.0541 0.0532 0.0523 0.0517 0.0514 

[TRAIN] Epoch[1](10933/114412); Loss: 0.095526; Backpropagation: 0.2917 sec; Batch: 2.1154 sec
0.1634 0.1451 0.1231 0.1103 0.0974 0.0916 0.0868 0.0845 0.0822 0.0806 0.0793 0.0783 0.0774 0.0767 0.0761 0.0755 

[TRAIN] Epoch[1](10934/114412); Loss: 0.076916; Backpropagation: 0.2908 sec; Batch: 2.0774 sec
0.1512 0.1294 0.1139 0.0945 0.0800 0.0735 0.0696 0.0644 0.0614 0.0598 0.0582 0.0569 0.0558 0.0548 0.0540 0.0533 

[TRAIN] Epoch[1](10935/114412); Loss: 0.073788; Backpropagation: 0.2914 sec; Batch: 2.1172 sec
0.1391 0.1335 0.1002 0.0871 0.0769 0.0706 0.0652 0.0622 0.0598 0.0580 0.0568 0.0557 0.0547 0.0541 0.0536 0.0531 

[TRAIN] Epoch[1](10936/114412); Loss: 0.072185; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1377 0.1294 0.0977 0.0881 0.0769 0.0685 0.0640 0.0601 0.0583 0.0562 0.0550 0.0541 0.0532 0.0524 0.0518 0.0515 

[TRAIN] Epoch[1](10937/114412); Loss: 0.080082; Backpropagation: 0.2904 sec; Batch: 2.1131 sec
0.1684 0.1622 0.1149 0.0936 0.0758 0.0690 0.0664 0.0638 0.0621 0.0605 0.0591 0.0582 0.0576 0.0571 0.0566 0.0561 

[TRAIN] Epoch[1](10938/114412); Loss: 0.077673; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1355 0.1270 0.0986 0.0903 0.0799 0.0744 0.0700 0.0673 0.0655 0.0642 0.0630 0.0623 0.0618 0.0613 0.0610 0.0606 

[TRAIN] Epoch[1](10939/114412); Loss: 0.080715; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1521 0.1423 0.1081 0.0933 0.0817 0.0771 0.0723 0.0685 0.0663 0.0647 0.0635 0.0623 0.0610 0.0602 0.0594 0.0589 

[TRAIN] Epoch[1](10940/114412); Loss: 0.058262; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1153 0.1016 0.0797 0.0682 0.0603 0.0554 0.0521 0.0498 0.0479 0.0465 0.0451 0.0439 0.0428 0.0418 0.0412 0.0408 

[TRAIN] Epoch[1](10941/114412); Loss: 0.062213; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.0947 0.0954 0.0762 0.0719 0.0637 0.0604 0.0578 0.0555 0.0540 0.0534 0.0528 0.0523 0.0521 0.0519 0.0517 0.0516 

[TRAIN] Epoch[1](10942/114412); Loss: 0.079822; Backpropagation: 0.2910 sec; Batch: 2.1157 sec
0.1364 0.1275 0.1032 0.0933 0.0834 0.0757 0.0715 0.0696 0.0683 0.0672 0.0658 0.0647 0.0636 0.0629 0.0623 0.0618 

[TRAIN] Epoch[1](10943/114412); Loss: 0.069934; Backpropagation: 0.2910 sec; Batch: 2.1257 sec
0.2043 0.1953 0.1278 0.0976 0.0660 0.0521 0.0442 0.0414 0.0396 0.0380 0.0371 0.0360 0.0357 0.0350 0.0346 0.0341 

[TRAIN] Epoch[1](10944/114412); Loss: 0.071647; Backpropagation: 0.2930 sec; Batch: 2.1149 sec
0.1455 0.1259 0.1014 0.0850 0.0732 0.0670 0.0618 0.0591 0.0571 0.0557 0.0544 0.0534 0.0527 0.0520 0.0514 0.0507 

[TRAIN] Epoch[1](10945/114412); Loss: 0.079687; Backpropagation: 0.2927 sec; Batch: 2.1170 sec
0.1375 0.1312 0.1065 0.0918 0.0805 0.0751 0.0713 0.0690 0.0670 0.0659 0.0648 0.0640 0.0632 0.0627 0.0624 0.0620 

[TRAIN] Epoch[1](10946/114412); Loss: 0.083628; Backpropagation: 0.2906 sec; Batch: 2.1115 sec
0.1498 0.1370 0.1036 0.0930 0.0845 0.0794 0.0763 0.0735 0.0719 0.0700 0.0686 0.0674 0.0667 0.0661 0.0653 0.0648 

[TRAIN] Epoch[1](10947/114412); Loss: 0.084767; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1558 0.1443 0.1121 0.0988 0.0856 0.0799 0.0754 0.0728 0.0708 0.0691 0.0674 0.0664 0.0653 0.0647 0.0641 0.0636 

[TRAIN] Epoch[1](10948/114412); Loss: 0.075083; Backpropagation: 0.2932 sec; Batch: 2.0785 sec
0.1476 0.1399 0.0987 0.0847 0.0739 0.0684 0.0651 0.0623 0.0605 0.0592 0.0584 0.0576 0.0570 0.0565 0.0559 0.0555 

[TRAIN] Epoch[1](10949/114412); Loss: 0.068721; Backpropagation: 0.2903 sec; Batch: 2.1141 sec
0.1212 0.1088 0.0882 0.0802 0.0714 0.0661 0.0628 0.0600 0.0580 0.0567 0.0558 0.0552 0.0545 0.0541 0.0535 0.0530 

[TRAIN] Epoch[1](10950/114412); Loss: 0.070737; Backpropagation: 0.2904 sec; Batch: 2.1159 sec
0.1144 0.1109 0.0957 0.0878 0.0767 0.0693 0.0645 0.0618 0.0599 0.0582 0.0572 0.0562 0.0555 0.0550 0.0545 0.0541 

[TRAIN] Epoch[1](10951/114412); Loss: 0.080656; Backpropagation: 0.2905 sec; Batch: 2.0923 sec
0.1396 0.1251 0.1005 0.0897 0.0818 0.0774 0.0732 0.0712 0.0698 0.0686 0.0673 0.0666 0.0658 0.0650 0.0646 0.0644 

[TRAIN] Epoch[1](10952/114412); Loss: 0.072575; Backpropagation: 0.2908 sec; Batch: 2.1181 sec
0.1348 0.1283 0.0962 0.0906 0.0751 0.0684 0.0635 0.0605 0.0586 0.0573 0.0561 0.0553 0.0549 0.0544 0.0538 0.0534 

[TRAIN] Epoch[1](10953/114412); Loss: 0.061346; Backpropagation: 0.2904 sec; Batch: 2.1052 sec
0.1370 0.1228 0.0978 0.0803 0.0644 0.0540 0.0489 0.0462 0.0444 0.0431 0.0420 0.0412 0.0404 0.0400 0.0396 0.0392 

[TRAIN] Epoch[1](10954/114412); Loss: 0.107463; Backpropagation: 0.2906 sec; Batch: 2.1135 sec
0.1983 0.1801 0.1422 0.1283 0.1142 0.1037 0.0964 0.0927 0.0890 0.0862 0.0841 0.0825 0.0814 0.0807 0.0801 0.0796 

[TRAIN] Epoch[1](10955/114412); Loss: 0.082842; Backpropagation: 0.2904 sec; Batch: 2.0768 sec
0.1389 0.1295 0.1049 0.0948 0.0861 0.0799 0.0753 0.0723 0.0707 0.0692 0.0684 0.0679 0.0675 0.0670 0.0668 0.0664 

[TRAIN] Epoch[1](10956/114412); Loss: 0.071089; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1305 0.1098 0.0876 0.0807 0.0743 0.0705 0.0657 0.0635 0.0605 0.0589 0.0577 0.0568 0.0562 0.0553 0.0549 0.0545 

[TRAIN] Epoch[1](10957/114412); Loss: 0.078016; Backpropagation: 0.2951 sec; Batch: 2.1297 sec
0.1643 0.1376 0.1030 0.0913 0.0755 0.0697 0.0668 0.0645 0.0630 0.0615 0.0602 0.0594 0.0586 0.0580 0.0575 0.0571 

[TRAIN] Epoch[1](10958/114412); Loss: 0.065942; Backpropagation: 0.2929 sec; Batch: 2.1214 sec
0.1101 0.1013 0.0880 0.0744 0.0686 0.0637 0.0605 0.0585 0.0565 0.0552 0.0542 0.0536 0.0531 0.0526 0.0524 0.0523 

[TRAIN] Epoch[1](10959/114412); Loss: 0.067253; Backpropagation: 0.2907 sec; Batch: 2.1191 sec
0.1320 0.1199 0.0844 0.0788 0.0679 0.0617 0.0589 0.0567 0.0551 0.0535 0.0527 0.0518 0.0513 0.0508 0.0505 0.0501 

[TRAIN] Epoch[1](10960/114412); Loss: 0.095315; Backpropagation: 0.2909 sec; Batch: 2.1135 sec
0.1562 0.1464 0.1161 0.1051 0.0984 0.0918 0.0891 0.0864 0.0836 0.0820 0.0807 0.0796 0.0785 0.0777 0.0771 0.0765 

[TRAIN] Epoch[1](10961/114412); Loss: 0.080013; Backpropagation: 0.2908 sec; Batch: 2.1137 sec
0.1850 0.1695 0.1252 0.0953 0.0843 0.0698 0.0642 0.0609 0.0572 0.0564 0.0547 0.0534 0.0529 0.0513 0.0504 0.0498 

[TRAIN] Epoch[1](10962/114412); Loss: 0.083197; Backpropagation: 0.2936 sec; Batch: 2.0837 sec
0.1395 0.1252 0.1061 0.0959 0.0876 0.0814 0.0779 0.0748 0.0722 0.0708 0.0692 0.0681 0.0671 0.0660 0.0651 0.0645 

[TRAIN] Epoch[1](10963/114412); Loss: 0.080627; Backpropagation: 0.2920 sec; Batch: 2.1210 sec
0.1350 0.1288 0.1040 0.0928 0.0836 0.0764 0.0728 0.0704 0.0684 0.0675 0.0664 0.0657 0.0652 0.0648 0.0644 0.0639 

[TRAIN] Epoch[1](10964/114412); Loss: 0.072465; Backpropagation: 0.2928 sec; Batch: 2.1206 sec
0.1327 0.1202 0.0984 0.0863 0.0766 0.0694 0.0653 0.0628 0.0605 0.0584 0.0570 0.0559 0.0549 0.0542 0.0536 0.0532 

[TRAIN] Epoch[1](10965/114412); Loss: 0.077992; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.1463 0.1416 0.1144 0.0993 0.0843 0.0759 0.0704 0.0670 0.0635 0.0614 0.0581 0.0567 0.0541 0.0531 0.0513 0.0505 

[TRAIN] Epoch[1](10966/114412); Loss: 0.058507; Backpropagation: 0.2904 sec; Batch: 2.1189 sec
0.1173 0.1039 0.0821 0.0751 0.0602 0.0568 0.0519 0.0484 0.0466 0.0449 0.0436 0.0425 0.0415 0.0409 0.0405 0.0401 

[TRAIN] Epoch[1](10967/114412); Loss: 0.057941; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1124 0.1087 0.0773 0.0650 0.0569 0.0527 0.0497 0.0479 0.0464 0.0456 0.0449 0.0445 0.0441 0.0438 0.0436 0.0434 

[TRAIN] Epoch[1](10968/114412); Loss: 0.094701; Backpropagation: 0.2909 sec; Batch: 2.1159 sec
0.1933 0.1782 0.1339 0.1129 0.0953 0.0852 0.0805 0.0765 0.0741 0.0721 0.0707 0.0698 0.0688 0.0682 0.0680 0.0676 

[TRAIN] Epoch[1](10969/114412); Loss: 0.088244; Backpropagation: 0.2909 sec; Batch: 2.1178 sec
0.1769 0.1595 0.1214 0.1061 0.0938 0.0907 0.0827 0.0758 0.0710 0.0669 0.0646 0.0634 0.0616 0.0602 0.0591 0.0582 

[TRAIN] Epoch[1](10970/114412); Loss: 0.073515; Backpropagation: 0.2914 sec; Batch: 2.1169 sec
0.1328 0.1276 0.0997 0.0864 0.0744 0.0682 0.0648 0.0625 0.0608 0.0593 0.0583 0.0575 0.0568 0.0562 0.0556 0.0553 

[TRAIN] Epoch[1](10971/114412); Loss: 0.081434; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1497 0.1355 0.1026 0.0959 0.0825 0.0767 0.0734 0.0700 0.0685 0.0668 0.0655 0.0646 0.0636 0.0631 0.0625 0.0620 

[TRAIN] Epoch[1](10972/114412); Loss: 0.074100; Backpropagation: 0.2913 sec; Batch: 2.1096 sec
0.1483 0.1335 0.0965 0.0856 0.0753 0.0683 0.0640 0.0614 0.0596 0.0587 0.0575 0.0565 0.0556 0.0553 0.0549 0.0546 

[TRAIN] Epoch[1](10973/114412); Loss: 0.084382; Backpropagation: 0.2955 sec; Batch: 2.1171 sec
0.1323 0.1233 0.1062 0.0949 0.0873 0.0827 0.0784 0.0764 0.0745 0.0730 0.0719 0.0709 0.0703 0.0698 0.0693 0.0689 

[TRAIN] Epoch[1](10974/114412); Loss: 0.068610; Backpropagation: 0.2927 sec; Batch: 2.1186 sec
0.1129 0.1040 0.0880 0.0770 0.0706 0.0665 0.0635 0.0620 0.0605 0.0586 0.0575 0.0565 0.0558 0.0552 0.0549 0.0545 

[TRAIN] Epoch[1](10975/114412); Loss: 0.072679; Backpropagation: 0.2926 sec; Batch: 2.1197 sec
0.1106 0.1042 0.0906 0.0811 0.0752 0.0717 0.0678 0.0661 0.0645 0.0632 0.0624 0.0619 0.0615 0.0609 0.0607 0.0604 

[TRAIN] Epoch[1](10976/114412); Loss: 0.063279; Backpropagation: 0.2950 sec; Batch: 2.1183 sec
0.1204 0.1106 0.0791 0.0672 0.0633 0.0585 0.0563 0.0545 0.0530 0.0519 0.0510 0.0503 0.0496 0.0492 0.0489 0.0485 

[TRAIN] Epoch[1](10977/114412); Loss: 0.067741; Backpropagation: 0.2914 sec; Batch: 2.1197 sec
0.1750 0.1569 0.1026 0.0724 0.0624 0.0536 0.0509 0.0495 0.0480 0.0466 0.0455 0.0449 0.0442 0.0440 0.0437 0.0436 

[TRAIN] Epoch[1](10978/114412); Loss: 0.085687; Backpropagation: 0.2928 sec; Batch: 2.1152 sec
0.1526 0.1354 0.1111 0.0971 0.0863 0.0814 0.0777 0.0753 0.0731 0.0717 0.0706 0.0694 0.0685 0.0677 0.0668 0.0662 

[TRAIN] Epoch[1](10979/114412); Loss: 0.103622; Backpropagation: 0.2954 sec; Batch: 2.1202 sec
0.1694 0.1622 0.1332 0.1215 0.1113 0.1030 0.0952 0.0914 0.0888 0.0866 0.0849 0.0836 0.0828 0.0819 0.0814 0.0807 

[TRAIN] Epoch[1](10980/114412); Loss: 0.069274; Backpropagation: 0.2953 sec; Batch: 2.1204 sec
0.1182 0.1095 0.0876 0.0799 0.0735 0.0683 0.0633 0.0611 0.0593 0.0577 0.0567 0.0558 0.0550 0.0546 0.0541 0.0538 

[TRAIN] Epoch[1](10981/114412); Loss: 0.052839; Backpropagation: 0.2931 sec; Batch: 2.1032 sec
0.0987 0.0988 0.0818 0.0713 0.0603 0.0518 0.0466 0.0430 0.0401 0.0386 0.0373 0.0365 0.0358 0.0354 0.0349 0.0345 

[TRAIN] Epoch[1](10982/114412); Loss: 0.085065; Backpropagation: 0.2924 sec; Batch: 2.1210 sec
0.1270 0.1199 0.1059 0.0972 0.0892 0.0842 0.0807 0.0780 0.0760 0.0746 0.0732 0.0724 0.0716 0.0709 0.0703 0.0699 

[TRAIN] Epoch[1](10983/114412); Loss: 0.073708; Backpropagation: 0.2910 sec; Batch: 2.1195 sec
0.1300 0.1171 0.0998 0.0850 0.0757 0.0705 0.0667 0.0640 0.0624 0.0610 0.0598 0.0588 0.0580 0.0573 0.0568 0.0565 

[TRAIN] Epoch[1](10984/114412); Loss: 0.066253; Backpropagation: 0.2912 sec; Batch: 2.1125 sec
0.1379 0.1270 0.0939 0.0791 0.0665 0.0600 0.0563 0.0535 0.0516 0.0503 0.0492 0.0481 0.0474 0.0469 0.0464 0.0460 

[TRAIN] Epoch[1](10985/114412); Loss: 0.081187; Backpropagation: 0.2917 sec; Batch: 2.1143 sec
0.1812 0.1727 0.1229 0.0990 0.0826 0.0716 0.0662 0.0631 0.0599 0.0578 0.0564 0.0545 0.0537 0.0532 0.0523 0.0520 

[TRAIN] Epoch[1](10986/114412); Loss: 0.064755; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1179 0.1075 0.0851 0.0735 0.0652 0.0615 0.0585 0.0559 0.0545 0.0530 0.0521 0.0512 0.0506 0.0503 0.0498 0.0495 

[TRAIN] Epoch[1](10987/114412); Loss: 0.068740; Backpropagation: 0.2907 sec; Batch: 2.0754 sec
0.1073 0.0962 0.0850 0.0767 0.0707 0.0669 0.0646 0.0625 0.0612 0.0604 0.0594 0.0586 0.0581 0.0577 0.0573 0.0571 

[TRAIN] Epoch[1](10988/114412); Loss: 0.080933; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1416 0.1387 0.1139 0.1047 0.0906 0.0793 0.0706 0.0670 0.0649 0.0632 0.0621 0.0611 0.0602 0.0594 0.0590 0.0585 

[TRAIN] Epoch[1](10989/114412); Loss: 0.085873; Backpropagation: 0.2911 sec; Batch: 2.1139 sec
0.1731 0.1571 0.1272 0.1098 0.0914 0.0831 0.0751 0.0704 0.0675 0.0646 0.0618 0.0605 0.0598 0.0581 0.0574 0.0570 

[TRAIN] Epoch[1](10990/114412); Loss: 0.067809; Backpropagation: 0.2913 sec; Batch: 2.1215 sec
0.1142 0.1039 0.0844 0.0757 0.0693 0.0642 0.0621 0.0604 0.0587 0.0578 0.0569 0.0563 0.0558 0.0554 0.0550 0.0548 

[TRAIN] Epoch[1](10991/114412); Loss: 0.078504; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1872 0.1778 0.1228 0.1032 0.0786 0.0666 0.0593 0.0556 0.0537 0.0525 0.0519 0.0511 0.0500 0.0491 0.0485 0.0481 

[TRAIN] Epoch[1](10992/114412); Loss: 0.081757; Backpropagation: 0.2906 sec; Batch: 2.1174 sec
0.1362 0.1125 0.0985 0.0900 0.0829 0.0792 0.0760 0.0736 0.0723 0.0711 0.0704 0.0698 0.0693 0.0690 0.0687 0.0684 

[TRAIN] Epoch[1](10993/114412); Loss: 0.097702; Backpropagation: 0.2954 sec; Batch: 2.1219 sec
0.1666 0.1548 0.1214 0.1076 0.0971 0.0922 0.0884 0.0862 0.0844 0.0831 0.0819 0.0814 0.0805 0.0798 0.0792 0.0788 

[TRAIN] Epoch[1](10994/114412); Loss: 0.073522; Backpropagation: 0.2929 sec; Batch: 2.1147 sec
0.1292 0.1188 0.0900 0.0818 0.0724 0.0696 0.0661 0.0641 0.0631 0.0619 0.0613 0.0606 0.0599 0.0595 0.0591 0.0590 

[TRAIN] Epoch[1](10995/114412); Loss: 0.064432; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1218 0.0975 0.0808 0.0721 0.0658 0.0615 0.0592 0.0568 0.0550 0.0537 0.0525 0.0520 0.0513 0.0507 0.0503 0.0498 

[TRAIN] Epoch[1](10996/114412); Loss: 0.074151; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1289 0.1152 0.0959 0.0837 0.0756 0.0709 0.0676 0.0649 0.0633 0.0621 0.0611 0.0604 0.0598 0.0593 0.0590 0.0588 

[TRAIN] Epoch[1](10997/114412); Loss: 0.086567; Backpropagation: 0.2954 sec; Batch: 2.1215 sec
0.1712 0.1477 0.1327 0.1097 0.0950 0.0836 0.0778 0.0718 0.0684 0.0658 0.0635 0.0617 0.0605 0.0592 0.0584 0.0579 

[TRAIN] Epoch[1](10998/114412); Loss: 0.077061; Backpropagation: 0.2954 sec; Batch: 2.1218 sec
0.1909 0.1732 0.1198 0.0886 0.0709 0.0641 0.0603 0.0569 0.0546 0.0528 0.0518 0.0512 0.0503 0.0498 0.0492 0.0487 

[TRAIN] Epoch[1](10999/114412); Loss: 0.112838; Backpropagation: 0.2931 sec; Batch: 2.1229 sec
0.1739 0.1682 0.1466 0.1319 0.1184 0.1109 0.1050 0.1007 0.0985 0.0964 0.0952 0.0940 0.0925 0.0919 0.0909 0.0905 

[TRAIN] Epoch[1](11000/114412); Loss: 0.079851; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1344 0.1158 0.0927 0.0808 0.0775 0.0758 0.0742 0.0722 0.0711 0.0705 0.0701 0.0695 0.0689 0.0684 0.0680 0.0678 

[TRAIN] Epoch[1](11001/114412); Loss: 0.076990; Backpropagation: 0.2912 sec; Batch: 2.1166 sec
0.1541 0.1315 0.1115 0.0971 0.0814 0.0751 0.0690 0.0632 0.0609 0.0584 0.0572 0.0562 0.0550 0.0542 0.0536 0.0532 

[TRAIN] Epoch[1](11002/114412); Loss: 0.066169; Backpropagation: 0.3096 sec; Batch: 2.1397 sec
0.1043 0.0989 0.0856 0.0777 0.0686 0.0656 0.0619 0.0591 0.0576 0.0562 0.0550 0.0545 0.0539 0.0537 0.0533 0.0528 

[TRAIN] Epoch[1](11003/114412); Loss: 0.082446; Backpropagation: 0.2913 sec; Batch: 2.0776 sec
0.1138 0.1073 0.1016 0.0924 0.0866 0.0816 0.0783 0.0766 0.0752 0.0740 0.0730 0.0726 0.0720 0.0717 0.0714 0.0711 

[TRAIN] Epoch[1](11004/114412); Loss: 0.055325; Backpropagation: 0.2908 sec; Batch: 2.0771 sec
0.1092 0.0966 0.0746 0.0629 0.0589 0.0529 0.0498 0.0473 0.0452 0.0439 0.0427 0.0417 0.0409 0.0399 0.0396 0.0390 

[TRAIN] Epoch[1](11005/114412); Loss: 0.095718; Backpropagation: 0.2929 sec; Batch: 2.1213 sec
0.1556 0.1356 0.1181 0.1044 0.0991 0.0943 0.0902 0.0870 0.0846 0.0829 0.0816 0.0810 0.0800 0.0795 0.0790 0.0786 

[TRAIN] Epoch[1](11006/114412); Loss: 0.062817; Backpropagation: 0.2920 sec; Batch: 2.1175 sec
0.1311 0.1123 0.0835 0.0716 0.0630 0.0591 0.0569 0.0538 0.0508 0.0490 0.0473 0.0466 0.0458 0.0452 0.0446 0.0444 

[TRAIN] Epoch[1](11007/114412); Loss: 0.060694; Backpropagation: 0.2908 sec; Batch: 2.1215 sec
0.1286 0.1199 0.0918 0.0795 0.0667 0.0573 0.0507 0.0462 0.0440 0.0429 0.0421 0.0414 0.0408 0.0403 0.0397 0.0394 

[TRAIN] Epoch[1](11008/114412); Loss: 0.095643; Backpropagation: 0.2909 sec; Batch: 2.1179 sec
0.1800 0.1706 0.1292 0.1129 0.0961 0.0886 0.0846 0.0811 0.0783 0.0763 0.0749 0.0735 0.0724 0.0714 0.0705 0.0699 

[TRAIN] Epoch[1](11009/114412); Loss: 0.074451; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.1269 0.1182 0.0928 0.0816 0.0753 0.0705 0.0680 0.0658 0.0640 0.0631 0.0622 0.0616 0.0610 0.0604 0.0600 0.0597 

[TRAIN] Epoch[1](11010/114412); Loss: 0.068258; Backpropagation: 0.2907 sec; Batch: 2.1144 sec
0.1327 0.1159 0.0918 0.0768 0.0699 0.0636 0.0601 0.0579 0.0561 0.0546 0.0535 0.0527 0.0521 0.0518 0.0515 0.0513 

[TRAIN] Epoch[1](11011/114412); Loss: 0.073578; Backpropagation: 0.2910 sec; Batch: 2.1004 sec
0.1216 0.1076 0.0918 0.0851 0.0772 0.0729 0.0696 0.0671 0.0649 0.0631 0.0618 0.0606 0.0597 0.0588 0.0581 0.0574 

[TRAIN] Epoch[1](11012/114412); Loss: 0.101052; Backpropagation: 0.2933 sec; Batch: 2.0808 sec
0.1840 0.1672 0.1361 0.1168 0.1022 0.0944 0.0899 0.0864 0.0841 0.0825 0.0807 0.0798 0.0793 0.0783 0.0778 0.0773 

[TRAIN] Epoch[1](11013/114412); Loss: 0.068262; Backpropagation: 0.2904 sec; Batch: 2.1160 sec
0.1405 0.1295 0.0999 0.0807 0.0677 0.0640 0.0591 0.0559 0.0538 0.0518 0.0504 0.0490 0.0484 0.0476 0.0471 0.0469 

[TRAIN] Epoch[1](11014/114412); Loss: 0.054551; Backpropagation: 0.2907 sec; Batch: 2.1221 sec
0.1395 0.1157 0.0732 0.0637 0.0548 0.0483 0.0434 0.0406 0.0394 0.0380 0.0372 0.0368 0.0360 0.0356 0.0354 0.0352 

[TRAIN] Epoch[1](11015/114412); Loss: 0.102250; Backpropagation: 0.2993 sec; Batch: 2.1316 sec
0.1904 0.1745 0.1363 0.1201 0.1064 0.0978 0.0916 0.0879 0.0845 0.0821 0.0799 0.0787 0.0778 0.0767 0.0759 0.0754 

[TRAIN] Epoch[1](11016/114412); Loss: 0.069385; Backpropagation: 0.2912 sec; Batch: 2.1276 sec
0.1258 0.1117 0.0860 0.0792 0.0701 0.0661 0.0628 0.0604 0.0586 0.0574 0.0565 0.0560 0.0555 0.0549 0.0548 0.0545 

[TRAIN] Epoch[1](11017/114412); Loss: 0.087383; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1602 0.1505 0.1116 0.1014 0.0890 0.0835 0.0789 0.0751 0.0730 0.0710 0.0698 0.0687 0.0675 0.0667 0.0659 0.0653 

[TRAIN] Epoch[1](11018/114412); Loss: 0.094977; Backpropagation: 0.2952 sec; Batch: 2.1210 sec
0.1703 0.1451 0.1158 0.1102 0.1042 0.0949 0.0895 0.0830 0.0811 0.0792 0.0772 0.0762 0.0748 0.0739 0.0727 0.0719 

[TRAIN] Epoch[1](11019/114412); Loss: 0.072376; Backpropagation: 0.2931 sec; Batch: 2.1214 sec
0.1213 0.1062 0.0981 0.0858 0.0750 0.0725 0.0667 0.0649 0.0624 0.0608 0.0595 0.0586 0.0575 0.0568 0.0562 0.0557 

[TRAIN] Epoch[1](11020/114412); Loss: 0.062015; Backpropagation: 0.2910 sec; Batch: 2.0781 sec
0.1227 0.1122 0.0855 0.0745 0.0643 0.0586 0.0544 0.0521 0.0495 0.0482 0.0469 0.0461 0.0453 0.0444 0.0440 0.0434 

[TRAIN] Epoch[1](11021/114412); Loss: 0.062320; Backpropagation: 0.2906 sec; Batch: 2.1163 sec
0.1394 0.1236 0.0792 0.0757 0.0613 0.0559 0.0526 0.0497 0.0477 0.0466 0.0461 0.0448 0.0442 0.0437 0.0433 0.0432 

[TRAIN] Epoch[1](11022/114412); Loss: 0.070782; Backpropagation: 0.2909 sec; Batch: 2.1463 sec
0.1329 0.1187 0.0957 0.0845 0.0731 0.0676 0.0632 0.0602 0.0581 0.0565 0.0557 0.0547 0.0539 0.0530 0.0526 0.0523 

[TRAIN] Epoch[1](11023/114412); Loss: 0.089376; Backpropagation: 0.2907 sec; Batch: 2.0782 sec
0.1751 0.1585 0.1194 0.1016 0.0899 0.0833 0.0793 0.0759 0.0731 0.0713 0.0697 0.0686 0.0672 0.0662 0.0657 0.0651 

[TRAIN] Epoch[1](11024/114412); Loss: 0.082930; Backpropagation: 0.2912 sec; Batch: 2.1208 sec
0.1465 0.1270 0.0990 0.0923 0.0844 0.0790 0.0755 0.0727 0.0715 0.0705 0.0696 0.0689 0.0682 0.0678 0.0672 0.0668 

[TRAIN] Epoch[1](11025/114412); Loss: 0.062983; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1187 0.1022 0.0747 0.0696 0.0628 0.0595 0.0574 0.0544 0.0533 0.0525 0.0515 0.0511 0.0504 0.0502 0.0499 0.0497 

[TRAIN] Epoch[1](11026/114412); Loss: 0.070040; Backpropagation: 0.2936 sec; Batch: 2.1185 sec
0.1398 0.1323 0.1016 0.0860 0.0691 0.0627 0.0591 0.0568 0.0549 0.0536 0.0522 0.0517 0.0508 0.0503 0.0500 0.0498 

[TRAIN] Epoch[1](11027/114412); Loss: 0.066278; Backpropagation: 0.2950 sec; Batch: 2.0819 sec
0.1161 0.0978 0.0842 0.0733 0.0673 0.0634 0.0613 0.0590 0.0575 0.0562 0.0553 0.0547 0.0541 0.0536 0.0535 0.0533 

[TRAIN] Epoch[1](11028/114412); Loss: 0.090984; Backpropagation: 0.2916 sec; Batch: 2.1200 sec
0.2075 0.1951 0.1299 0.1111 0.0858 0.0793 0.0724 0.0687 0.0677 0.0654 0.0638 0.0631 0.0623 0.0617 0.0612 0.0609 

[TRAIN] Epoch[1](11029/114412); Loss: 0.062802; Backpropagation: 0.2907 sec; Batch: 2.0767 sec
0.1101 0.1042 0.0841 0.0740 0.0655 0.0617 0.0588 0.0550 0.0532 0.0513 0.0501 0.0492 0.0481 0.0473 0.0465 0.0459 

[TRAIN] Epoch[1](11030/114412); Loss: 0.076214; Backpropagation: 0.2946 sec; Batch: 2.1178 sec
0.1455 0.1356 0.0910 0.0832 0.0732 0.0693 0.0662 0.0643 0.0633 0.0625 0.0616 0.0614 0.0609 0.0607 0.0605 0.0602 

[TRAIN] Epoch[1](11031/114412); Loss: 0.076280; Backpropagation: 0.2931 sec; Batch: 2.1221 sec
0.1552 0.1406 0.1070 0.0902 0.0750 0.0698 0.0651 0.0624 0.0605 0.0588 0.0577 0.0568 0.0562 0.0556 0.0551 0.0546 

[TRAIN] Epoch[1](11032/114412); Loss: 0.079175; Backpropagation: 0.2910 sec; Batch: 2.1154 sec
0.1468 0.1306 0.1040 0.0921 0.0816 0.0754 0.0717 0.0690 0.0669 0.0647 0.0631 0.0617 0.0607 0.0602 0.0594 0.0587 

[TRAIN] Epoch[1](11033/114412); Loss: 0.074234; Backpropagation: 0.2919 sec; Batch: 2.0806 sec
0.1488 0.1400 0.1060 0.0879 0.0753 0.0691 0.0646 0.0617 0.0589 0.0567 0.0561 0.0543 0.0533 0.0525 0.0516 0.0511 

[TRAIN] Epoch[1](11034/114412); Loss: 0.068746; Backpropagation: 0.2954 sec; Batch: 2.0826 sec
0.1420 0.1312 0.0979 0.0832 0.0706 0.0620 0.0580 0.0547 0.0533 0.0518 0.0507 0.0497 0.0492 0.0488 0.0485 0.0483 

[TRAIN] Epoch[1](11035/114412); Loss: 0.099847; Backpropagation: 0.2955 sec; Batch: 2.1261 sec
0.1559 0.1527 0.1213 0.1115 0.1038 0.0982 0.0947 0.0913 0.0880 0.0864 0.0848 0.0835 0.0826 0.0817 0.0811 0.0803 

[TRAIN] Epoch[1](11036/114412); Loss: 0.102601; Backpropagation: 0.2950 sec; Batch: 2.1257 sec
0.1703 0.1615 0.1318 0.1188 0.1041 0.0974 0.0929 0.0903 0.0879 0.0862 0.0850 0.0842 0.0836 0.0829 0.0825 0.0820 

[TRAIN] Epoch[1](11037/114412); Loss: 0.072394; Backpropagation: 0.2950 sec; Batch: 2.0851 sec
0.1263 0.1214 0.0889 0.0827 0.0728 0.0684 0.0651 0.0628 0.0618 0.0606 0.0597 0.0587 0.0580 0.0574 0.0571 0.0568 

[TRAIN] Epoch[1](11038/114412); Loss: 0.074568; Backpropagation: 0.2949 sec; Batch: 2.1218 sec
0.1478 0.1337 0.0953 0.0830 0.0735 0.0671 0.0647 0.0623 0.0606 0.0597 0.0587 0.0582 0.0579 0.0573 0.0568 0.0566 

[TRAIN] Epoch[1](11039/114412); Loss: 0.067691; Backpropagation: 0.2953 sec; Batch: 2.1219 sec
0.1276 0.1162 0.0978 0.0794 0.0723 0.0659 0.0624 0.0569 0.0548 0.0529 0.0515 0.0505 0.0495 0.0489 0.0484 0.0480 

[TRAIN] Epoch[1](11040/114412); Loss: 0.086640; Backpropagation: 0.2953 sec; Batch: 2.0831 sec
0.1611 0.1485 0.1249 0.1138 0.1011 0.0915 0.0846 0.0766 0.0708 0.0655 0.0634 0.0600 0.0574 0.0565 0.0558 0.0546 

[TRAIN] Epoch[1](11041/114412); Loss: 0.068548; Backpropagation: 0.2930 sec; Batch: 2.1219 sec
0.1243 0.1154 0.0887 0.0785 0.0687 0.0643 0.0611 0.0587 0.0573 0.0560 0.0552 0.0545 0.0539 0.0535 0.0534 0.0531 

[TRAIN] Epoch[1](11042/114412); Loss: 0.104467; Backpropagation: 0.2927 sec; Batch: 2.1206 sec
0.1804 0.1703 0.1378 0.1216 0.1108 0.1050 0.0996 0.0923 0.0907 0.0871 0.0835 0.0817 0.0800 0.0778 0.0771 0.0758 

[TRAIN] Epoch[1](11043/114412); Loss: 0.078286; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1334 0.1191 0.1041 0.0905 0.0814 0.0760 0.0716 0.0691 0.0675 0.0656 0.0645 0.0632 0.0624 0.0619 0.0613 0.0609 

[TRAIN] Epoch[1](11044/114412); Loss: 0.086814; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1530 0.1362 0.1089 0.1001 0.0897 0.0838 0.0793 0.0765 0.0741 0.0724 0.0711 0.0701 0.0693 0.0687 0.0681 0.0676 

[TRAIN] Epoch[1](11045/114412); Loss: 0.070612; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1303 0.1177 0.0901 0.0814 0.0717 0.0679 0.0636 0.0616 0.0598 0.0577 0.0566 0.0554 0.0547 0.0541 0.0538 0.0534 

[TRAIN] Epoch[1](11046/114412); Loss: 0.084578; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.1628 0.1576 0.1085 0.0893 0.0815 0.0756 0.0731 0.0709 0.0697 0.0685 0.0675 0.0668 0.0661 0.0655 0.0650 0.0648 

[TRAIN] Epoch[1](11047/114412); Loss: 0.074251; Backpropagation: 0.2911 sec; Batch: 2.1176 sec
0.1430 0.1336 0.1033 0.0852 0.0738 0.0690 0.0650 0.0626 0.0605 0.0588 0.0579 0.0566 0.0557 0.0550 0.0543 0.0538 

[TRAIN] Epoch[1](11048/114412); Loss: 0.079873; Backpropagation: 0.2928 sec; Batch: 2.1229 sec
0.1300 0.1215 0.1026 0.0876 0.0829 0.0778 0.0754 0.0725 0.0700 0.0681 0.0672 0.0661 0.0652 0.0646 0.0636 0.0629 

[TRAIN] Epoch[1](11049/114412); Loss: 0.067733; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1118 0.1036 0.0858 0.0763 0.0691 0.0661 0.0637 0.0611 0.0593 0.0579 0.0565 0.0557 0.0550 0.0544 0.0539 0.0536 

[TRAIN] Epoch[1](11050/114412); Loss: 0.074926; Backpropagation: 0.2911 sec; Batch: 2.1151 sec
0.1831 0.1581 0.1129 0.0979 0.0800 0.0660 0.0615 0.0566 0.0534 0.0518 0.0493 0.0478 0.0466 0.0455 0.0444 0.0438 

[TRAIN] Epoch[1](11051/114412); Loss: 0.064655; Backpropagation: 0.2909 sec; Batch: 2.1237 sec
0.1079 0.1004 0.0865 0.0710 0.0664 0.0627 0.0600 0.0575 0.0558 0.0546 0.0535 0.0528 0.0521 0.0515 0.0510 0.0507 

[TRAIN] Epoch[1](11052/114412); Loss: 0.074492; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1421 0.1262 0.1015 0.0869 0.0762 0.0706 0.0667 0.0637 0.0612 0.0597 0.0584 0.0574 0.0563 0.0557 0.0550 0.0543 

[TRAIN] Epoch[1](11053/114412); Loss: 0.066913; Backpropagation: 0.2909 sec; Batch: 2.1184 sec
0.1194 0.1104 0.0872 0.0798 0.0701 0.0642 0.0604 0.0574 0.0560 0.0544 0.0533 0.0524 0.0519 0.0515 0.0513 0.0511 

[TRAIN] Epoch[1](11054/114412); Loss: 0.065312; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1195 0.1111 0.0811 0.0759 0.0673 0.0634 0.0595 0.0562 0.0549 0.0532 0.0522 0.0513 0.0505 0.0501 0.0495 0.0492 

[TRAIN] Epoch[1](11055/114412); Loss: 0.075120; Backpropagation: 0.2910 sec; Batch: 2.1214 sec
0.1236 0.1118 0.0960 0.0865 0.0771 0.0737 0.0698 0.0677 0.0659 0.0644 0.0628 0.0617 0.0610 0.0604 0.0599 0.0595 

[TRAIN] Epoch[1](11056/114412); Loss: 0.075935; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1300 0.1171 0.0942 0.0853 0.0766 0.0716 0.0703 0.0675 0.0660 0.0643 0.0632 0.0626 0.0621 0.0617 0.0613 0.0611 

[TRAIN] Epoch[1](11057/114412); Loss: 0.077034; Backpropagation: 0.2928 sec; Batch: 2.1198 sec
0.1407 0.1324 0.0970 0.0831 0.0767 0.0719 0.0689 0.0667 0.0649 0.0638 0.0627 0.0620 0.0612 0.0607 0.0601 0.0597 

[TRAIN] Epoch[1](11058/114412); Loss: 0.083672; Backpropagation: 0.2928 sec; Batch: 2.1291 sec
0.1609 0.1520 0.1028 0.0972 0.0812 0.0766 0.0735 0.0701 0.0695 0.0675 0.0665 0.0655 0.0648 0.0642 0.0634 0.0631 

[TRAIN] Epoch[1](11059/114412); Loss: 0.089929; Backpropagation: 0.2911 sec; Batch: 2.0780 sec
0.1930 0.1708 0.1242 0.1056 0.0901 0.0810 0.0773 0.0727 0.0711 0.0687 0.0669 0.0656 0.0643 0.0634 0.0623 0.0619 

[TRAIN] Epoch[1](11060/114412); Loss: 0.075509; Backpropagation: 0.2915 sec; Batch: 2.0803 sec
0.1501 0.1305 0.0974 0.0865 0.0749 0.0696 0.0659 0.0632 0.0616 0.0603 0.0593 0.0587 0.0580 0.0577 0.0574 0.0571 

[TRAIN] Epoch[1](11061/114412); Loss: 0.085633; Backpropagation: 0.2951 sec; Batch: 2.1170 sec
0.1793 0.1654 0.1269 0.1047 0.0853 0.0775 0.0718 0.0686 0.0659 0.0646 0.0622 0.0611 0.0603 0.0596 0.0589 0.0581 

[TRAIN] Epoch[1](11062/114412); Loss: 0.081544; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1630 0.1436 0.1063 0.0882 0.0788 0.0753 0.0716 0.0691 0.0674 0.0657 0.0645 0.0637 0.0630 0.0622 0.0615 0.0609 

[TRAIN] Epoch[1](11063/114412); Loss: 0.064343; Backpropagation: 0.2914 sec; Batch: 2.1217 sec
0.1122 0.1045 0.0780 0.0737 0.0636 0.0604 0.0585 0.0558 0.0548 0.0541 0.0532 0.0527 0.0522 0.0520 0.0519 0.0519 

[TRAIN] Epoch[1](11064/114412); Loss: 0.058931; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1292 0.1180 0.0858 0.0700 0.0584 0.0525 0.0495 0.0466 0.0444 0.0434 0.0421 0.0416 0.0410 0.0406 0.0401 0.0397 

[TRAIN] Epoch[1](11065/114412); Loss: 0.075417; Backpropagation: 0.2915 sec; Batch: 2.1243 sec
0.1368 0.1185 0.0965 0.0860 0.0777 0.0724 0.0687 0.0660 0.0641 0.0628 0.0614 0.0606 0.0597 0.0591 0.0585 0.0581 

[TRAIN] Epoch[1](11066/114412); Loss: 0.085378; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1969 0.1722 0.1287 0.1054 0.0888 0.0779 0.0724 0.0672 0.0645 0.0616 0.0590 0.0576 0.0549 0.0541 0.0529 0.0519 

[TRAIN] Epoch[1](11067/114412); Loss: 0.082508; Backpropagation: 0.2909 sec; Batch: 2.1199 sec
0.1897 0.1561 0.0994 0.0892 0.0793 0.0734 0.0705 0.0672 0.0654 0.0638 0.0627 0.0617 0.0611 0.0606 0.0603 0.0597 

[TRAIN] Epoch[1](11068/114412); Loss: 0.083251; Backpropagation: 0.2908 sec; Batch: 2.1212 sec
0.1811 0.1692 0.1169 0.0926 0.0808 0.0722 0.0684 0.0662 0.0642 0.0628 0.0615 0.0604 0.0597 0.0591 0.0585 0.0584 

[TRAIN] Epoch[1](11069/114412); Loss: 0.064073; Backpropagation: 0.2930 sec; Batch: 2.1236 sec
0.1412 0.1275 0.0875 0.0729 0.0638 0.0574 0.0548 0.0512 0.0497 0.0482 0.0469 0.0460 0.0453 0.0448 0.0442 0.0438 

[TRAIN] Epoch[1](11070/114412); Loss: 0.084393; Backpropagation: 0.2910 sec; Batch: 2.1206 sec
0.1423 0.1232 0.1046 0.0944 0.0872 0.0809 0.0780 0.0751 0.0737 0.0723 0.0716 0.0705 0.0699 0.0692 0.0689 0.0684 

[TRAIN] Epoch[1](11071/114412); Loss: 0.086616; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1481 0.1222 0.1028 0.0944 0.0884 0.0832 0.0804 0.0783 0.0765 0.0755 0.0743 0.0736 0.0727 0.0723 0.0718 0.0713 

[TRAIN] Epoch[1](11072/114412); Loss: 0.100759; Backpropagation: 0.2928 sec; Batch: 2.1183 sec
0.1585 0.1445 0.1220 0.1133 0.1033 0.0981 0.0952 0.0920 0.0903 0.0882 0.0871 0.0856 0.0851 0.0837 0.0831 0.0823 

[TRAIN] Epoch[1](11073/114412); Loss: 0.066175; Backpropagation: 0.2930 sec; Batch: 2.1174 sec
0.1256 0.1148 0.0870 0.0758 0.0668 0.0617 0.0589 0.0566 0.0550 0.0534 0.0521 0.0513 0.0507 0.0502 0.0497 0.0493 

[TRAIN] Epoch[1](11074/114412); Loss: 0.081328; Backpropagation: 0.2953 sec; Batch: 2.1208 sec
0.1818 0.1631 0.1179 0.0908 0.0766 0.0731 0.0691 0.0650 0.0622 0.0601 0.0589 0.0580 0.0571 0.0564 0.0557 0.0554 

[TRAIN] Epoch[1](11075/114412); Loss: 0.066880; Backpropagation: 0.2926 sec; Batch: 2.1184 sec
0.1317 0.1218 0.0848 0.0752 0.0666 0.0609 0.0580 0.0557 0.0541 0.0533 0.0524 0.0518 0.0513 0.0511 0.0508 0.0507 

[TRAIN] Epoch[1](11076/114412); Loss: 0.091471; Backpropagation: 0.2930 sec; Batch: 2.0816 sec
0.1478 0.1397 0.1138 0.1048 0.0935 0.0881 0.0847 0.0827 0.0802 0.0784 0.0773 0.0761 0.0753 0.0745 0.0737 0.0730 

[TRAIN] Epoch[1](11077/114412); Loss: 0.071675; Backpropagation: 0.2908 sec; Batch: 2.1157 sec
0.1249 0.1135 0.0930 0.0820 0.0733 0.0677 0.0646 0.0626 0.0608 0.0598 0.0589 0.0582 0.0576 0.0573 0.0566 0.0562 

[TRAIN] Epoch[1](11078/114412); Loss: 0.068636; Backpropagation: 0.2908 sec; Batch: 2.0783 sec
0.1435 0.1318 0.1041 0.0741 0.0679 0.0588 0.0567 0.0549 0.0528 0.0526 0.0512 0.0508 0.0502 0.0498 0.0496 0.0495 

[TRAIN] Epoch[1](11079/114412); Loss: 0.070155; Backpropagation: 0.2929 sec; Batch: 2.1196 sec
0.1460 0.1306 0.0949 0.0812 0.0685 0.0644 0.0598 0.0571 0.0552 0.0541 0.0533 0.0525 0.0518 0.0515 0.0510 0.0506 

[TRAIN] Epoch[1](11080/114412); Loss: 0.073358; Backpropagation: 0.2928 sec; Batch: 2.1168 sec
0.1436 0.1249 0.0970 0.0837 0.0744 0.0702 0.0650 0.0627 0.0602 0.0585 0.0574 0.0565 0.0556 0.0550 0.0546 0.0543 

[TRAIN] Epoch[1](11081/114412); Loss: 0.074950; Backpropagation: 0.2910 sec; Batch: 2.1202 sec
0.1358 0.1214 0.0950 0.0829 0.0775 0.0722 0.0688 0.0660 0.0641 0.0625 0.0614 0.0600 0.0591 0.0582 0.0575 0.0569 

[TRAIN] Epoch[1](11082/114412); Loss: 0.083467; Backpropagation: 0.2916 sec; Batch: 2.1176 sec
0.1455 0.1248 0.1035 0.0917 0.0851 0.0798 0.0766 0.0745 0.0729 0.0720 0.0703 0.0692 0.0683 0.0674 0.0673 0.0667 

[TRAIN] Epoch[1](11083/114412); Loss: 0.069774; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.1320 0.1206 0.0922 0.0794 0.0698 0.0662 0.0631 0.0602 0.0583 0.0564 0.0552 0.0539 0.0532 0.0522 0.0519 0.0517 

[TRAIN] Epoch[1](11084/114412); Loss: 0.075649; Backpropagation: 0.2910 sec; Batch: 2.1210 sec
0.1555 0.1448 0.0971 0.0858 0.0748 0.0687 0.0644 0.0619 0.0604 0.0589 0.0581 0.0573 0.0564 0.0558 0.0554 0.0551 

[TRAIN] Epoch[1](11085/114412); Loss: 0.057379; Backpropagation: 0.2911 sec; Batch: 2.1135 sec
0.1132 0.1001 0.0731 0.0644 0.0567 0.0533 0.0507 0.0488 0.0473 0.0462 0.0453 0.0446 0.0442 0.0437 0.0434 0.0431 

[TRAIN] Epoch[1](11086/114412); Loss: 0.064403; Backpropagation: 0.2910 sec; Batch: 2.1295 sec
0.1293 0.1180 0.0903 0.0778 0.0673 0.0605 0.0560 0.0528 0.0507 0.0497 0.0482 0.0474 0.0466 0.0458 0.0453 0.0447 

[TRAIN] Epoch[1](11087/114412); Loss: 0.073516; Backpropagation: 0.2922 sec; Batch: 2.1194 sec
0.1491 0.1287 0.0980 0.0844 0.0738 0.0666 0.0639 0.0617 0.0600 0.0586 0.0574 0.0561 0.0552 0.0547 0.0543 0.0539 

[TRAIN] Epoch[1](11088/114412); Loss: 0.055599; Backpropagation: 0.2927 sec; Batch: 2.1209 sec
0.1152 0.1044 0.0783 0.0687 0.0572 0.0506 0.0469 0.0444 0.0429 0.0419 0.0409 0.0402 0.0398 0.0396 0.0393 0.0391 

[TRAIN] Epoch[1](11089/114412); Loss: 0.071171; Backpropagation: 0.2928 sec; Batch: 2.0832 sec
0.1152 0.1067 0.0921 0.0830 0.0747 0.0692 0.0654 0.0632 0.0614 0.0601 0.0593 0.0586 0.0581 0.0575 0.0572 0.0570 

[TRAIN] Epoch[1](11090/114412); Loss: 0.081258; Backpropagation: 0.2914 sec; Batch: 2.0947 sec
0.1842 0.1551 0.1176 0.0975 0.0796 0.0718 0.0676 0.0644 0.0621 0.0601 0.0588 0.0576 0.0568 0.0562 0.0557 0.0552 

[TRAIN] Epoch[1](11091/114412); Loss: 0.067490; Backpropagation: 0.2924 sec; Batch: 2.1178 sec
0.1176 0.1049 0.0869 0.0777 0.0697 0.0652 0.0624 0.0597 0.0580 0.0563 0.0553 0.0544 0.0538 0.0531 0.0527 0.0522 

[TRAIN] Epoch[1](11092/114412); Loss: 0.067997; Backpropagation: 0.2928 sec; Batch: 2.1144 sec
0.1298 0.1195 0.0896 0.0777 0.0650 0.0622 0.0600 0.0582 0.0566 0.0554 0.0539 0.0531 0.0524 0.0520 0.0514 0.0511 

[TRAIN] Epoch[1](11093/114412); Loss: 0.071922; Backpropagation: 0.2907 sec; Batch: 2.1197 sec
0.1503 0.1401 0.0889 0.0757 0.0688 0.0651 0.0617 0.0593 0.0581 0.0566 0.0558 0.0550 0.0543 0.0541 0.0537 0.0534 

[TRAIN] Epoch[1](11094/114412); Loss: 0.076455; Backpropagation: 0.2930 sec; Batch: 2.1200 sec
0.1630 0.1310 0.1030 0.0835 0.0750 0.0696 0.0662 0.0634 0.0614 0.0604 0.0591 0.0583 0.0579 0.0575 0.0572 0.0568 

[TRAIN] Epoch[1](11095/114412); Loss: 0.099369; Backpropagation: 0.2913 sec; Batch: 2.1142 sec
0.1754 0.1621 0.1307 0.1165 0.1028 0.0942 0.0900 0.0867 0.0838 0.0818 0.0802 0.0789 0.0776 0.0770 0.0763 0.0758 

[TRAIN] Epoch[1](11096/114412); Loss: 0.095345; Backpropagation: 0.2930 sec; Batch: 2.1203 sec
0.1561 0.1493 0.1240 0.1116 0.1006 0.0940 0.0892 0.0851 0.0837 0.0809 0.0783 0.0771 0.0755 0.0742 0.0733 0.0725 

[TRAIN] Epoch[1](11097/114412); Loss: 0.086790; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1536 0.1344 0.1099 0.0978 0.0879 0.0831 0.0800 0.0769 0.0750 0.0734 0.0720 0.0706 0.0696 0.0688 0.0681 0.0675 

[TRAIN] Epoch[1](11098/114412); Loss: 0.055920; Backpropagation: 0.2952 sec; Batch: 2.1188 sec
0.1009 0.0939 0.0739 0.0644 0.0562 0.0521 0.0493 0.0479 0.0465 0.0457 0.0449 0.0444 0.0439 0.0438 0.0435 0.0432 

[TRAIN] Epoch[1](11099/114412); Loss: 0.055688; Backpropagation: 0.2946 sec; Batch: 2.1291 sec
0.1158 0.1119 0.0818 0.0698 0.0556 0.0502 0.0473 0.0450 0.0427 0.0412 0.0398 0.0391 0.0385 0.0378 0.0375 0.0371 

[TRAIN] Epoch[1](11100/114412); Loss: 0.068616; Backpropagation: 0.2932 sec; Batch: 2.1220 sec
0.1383 0.1294 0.0904 0.0748 0.0652 0.0617 0.0592 0.0572 0.0557 0.0542 0.0533 0.0525 0.0519 0.0516 0.0513 0.0511 

[TRAIN] Epoch[1](11101/114412); Loss: 0.062032; Backpropagation: 0.2952 sec; Batch: 2.1245 sec
0.1095 0.0958 0.0767 0.0697 0.0630 0.0591 0.0567 0.0545 0.0534 0.0522 0.0515 0.0509 0.0503 0.0500 0.0497 0.0495 

[TRAIN] Epoch[1](11102/114412); Loss: 0.085675; Backpropagation: 0.2949 sec; Batch: 2.1210 sec
0.1595 0.1477 0.1181 0.1024 0.0871 0.0804 0.0757 0.0731 0.0701 0.0683 0.0669 0.0658 0.0649 0.0642 0.0636 0.0630 

[TRAIN] Epoch[1](11103/114412); Loss: 0.080111; Backpropagation: 0.2950 sec; Batch: 2.1214 sec
0.1793 0.1617 0.1215 0.1007 0.0811 0.0725 0.0669 0.0627 0.0600 0.0577 0.0563 0.0543 0.0532 0.0520 0.0514 0.0506 

[TRAIN] Epoch[1](11104/114412); Loss: 0.071517; Backpropagation: 0.2913 sec; Batch: 2.1153 sec
0.1502 0.1363 0.0948 0.0808 0.0699 0.0648 0.0608 0.0585 0.0564 0.0553 0.0542 0.0535 0.0528 0.0524 0.0519 0.0517 

[TRAIN] Epoch[1](11105/114412); Loss: 0.105239; Backpropagation: 0.2904 sec; Batch: 2.1161 sec
0.1816 0.1580 0.1250 0.1146 0.1046 0.0995 0.0979 0.0950 0.0929 0.0910 0.0899 0.0885 0.0874 0.0866 0.0860 0.0854 

[TRAIN] Epoch[1](11106/114412); Loss: 0.071660; Backpropagation: 0.2904 sec; Batch: 2.1174 sec
0.1633 0.1532 0.0918 0.0790 0.0672 0.0619 0.0596 0.0563 0.0550 0.0537 0.0526 0.0519 0.0510 0.0506 0.0500 0.0497 

[TRAIN] Epoch[1](11107/114412); Loss: 0.094287; Backpropagation: 0.2914 sec; Batch: 2.1214 sec
0.1498 0.1397 0.1145 0.1063 0.0971 0.0934 0.0891 0.0858 0.0836 0.0818 0.0802 0.0791 0.0781 0.0774 0.0767 0.0760 

[TRAIN] Epoch[1](11108/114412); Loss: 0.077929; Backpropagation: 0.2911 sec; Batch: 2.1214 sec
0.1714 0.1511 0.1002 0.0792 0.0746 0.0706 0.0685 0.0643 0.0623 0.0609 0.0595 0.0585 0.0574 0.0565 0.0560 0.0556 

[TRAIN] Epoch[1](11109/114412); Loss: 0.076382; Backpropagation: 0.2907 sec; Batch: 2.1145 sec
0.1508 0.1429 0.1009 0.0825 0.0762 0.0711 0.0679 0.0640 0.0623 0.0606 0.0593 0.0582 0.0573 0.0566 0.0561 0.0554 

[TRAIN] Epoch[1](11110/114412); Loss: 0.048605; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1059 0.0986 0.0628 0.0562 0.0493 0.0451 0.0421 0.0392 0.0380 0.0365 0.0357 0.0346 0.0339 0.0335 0.0332 0.0331 

[TRAIN] Epoch[1](11111/114412); Loss: 0.050222; Backpropagation: 0.2906 sec; Batch: 2.1291 sec
0.0809 0.0750 0.0693 0.0608 0.0532 0.0490 0.0461 0.0445 0.0434 0.0423 0.0414 0.0404 0.0397 0.0394 0.0391 0.0391 

[TRAIN] Epoch[1](11112/114412); Loss: 0.078658; Backpropagation: 0.2903 sec; Batch: 2.1161 sec
0.1369 0.1321 0.1051 0.0908 0.0798 0.0743 0.0703 0.0684 0.0668 0.0650 0.0637 0.0627 0.0616 0.0607 0.0603 0.0599 

[TRAIN] Epoch[1](11113/114412); Loss: 0.064606; Backpropagation: 0.2912 sec; Batch: 2.1188 sec
0.1083 0.0935 0.0836 0.0750 0.0666 0.0623 0.0594 0.0576 0.0561 0.0551 0.0541 0.0535 0.0529 0.0523 0.0520 0.0515 

[TRAIN] Epoch[1](11114/114412); Loss: 0.059972; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1410 0.1208 0.0748 0.0662 0.0557 0.0522 0.0497 0.0474 0.0460 0.0452 0.0445 0.0440 0.0436 0.0432 0.0426 0.0427 

[TRAIN] Epoch[1](11115/114412); Loss: 0.056279; Backpropagation: 0.2906 sec; Batch: 2.1174 sec
0.1048 0.0909 0.0741 0.0669 0.0583 0.0538 0.0506 0.0481 0.0469 0.0454 0.0447 0.0441 0.0435 0.0431 0.0428 0.0426 

[TRAIN] Epoch[1](11116/114412); Loss: 0.111831; Backpropagation: 0.2911 sec; Batch: 2.1223 sec
0.1922 0.1660 0.1388 0.1255 0.1139 0.1087 0.1032 0.1001 0.0971 0.0951 0.0937 0.0928 0.0917 0.0909 0.0901 0.0895 

[TRAIN] Epoch[1](11117/114412); Loss: 0.064417; Backpropagation: 0.2910 sec; Batch: 2.0777 sec
0.1159 0.1097 0.0845 0.0730 0.0664 0.0612 0.0583 0.0558 0.0544 0.0527 0.0513 0.0506 0.0499 0.0495 0.0489 0.0485 

[TRAIN] Epoch[1](11118/114412); Loss: 0.052727; Backpropagation: 0.2908 sec; Batch: 2.1173 sec
0.1144 0.1087 0.0703 0.0578 0.0490 0.0463 0.0437 0.0421 0.0406 0.0398 0.0393 0.0388 0.0385 0.0384 0.0381 0.0379 

[TRAIN] Epoch[1](11119/114412); Loss: 0.081703; Backpropagation: 0.2908 sec; Batch: 2.1168 sec
0.1454 0.1305 0.1008 0.0925 0.0848 0.0787 0.0747 0.0720 0.0700 0.0684 0.0669 0.0659 0.0651 0.0644 0.0639 0.0634 

[TRAIN] Epoch[1](11120/114412); Loss: 0.078094; Backpropagation: 0.2908 sec; Batch: 2.1214 sec
0.1475 0.1297 0.1000 0.0872 0.0774 0.0735 0.0695 0.0669 0.0650 0.0641 0.0628 0.0624 0.0614 0.0612 0.0606 0.0603 

[TRAIN] Epoch[1](11121/114412); Loss: 0.065662; Backpropagation: 0.2918 sec; Batch: 2.1225 sec
0.1658 0.1398 0.0891 0.0660 0.0572 0.0548 0.0518 0.0505 0.0487 0.0482 0.0474 0.0468 0.0465 0.0462 0.0460 0.0459 

[TRAIN] Epoch[1](11122/114412); Loss: 0.096484; Backpropagation: 0.2914 sec; Batch: 2.1164 sec
0.1530 0.1401 0.1180 0.1061 0.0964 0.0926 0.0900 0.0875 0.0858 0.0845 0.0833 0.0823 0.0817 0.0811 0.0807 0.0805 

[TRAIN] Epoch[1](11123/114412); Loss: 0.069457; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1303 0.1247 0.0853 0.0767 0.0679 0.0638 0.0608 0.0592 0.0579 0.0567 0.0559 0.0551 0.0548 0.0544 0.0539 0.0538 

[TRAIN] Epoch[1](11124/114412); Loss: 0.074890; Backpropagation: 0.2923 sec; Batch: 2.1067 sec
0.1858 0.1513 0.0981 0.0782 0.0688 0.0652 0.0614 0.0599 0.0575 0.0557 0.0545 0.0536 0.0529 0.0523 0.0516 0.0514 

[TRAIN] Epoch[1](11125/114412); Loss: 0.059487; Backpropagation: 0.2920 sec; Batch: 2.5086 sec
0.1134 0.0991 0.0813 0.0723 0.0627 0.0567 0.0535 0.0505 0.0486 0.0473 0.0461 0.0452 0.0445 0.0439 0.0435 0.0432 

[TRAIN] Epoch[1](11126/114412); Loss: 0.074973; Backpropagation: 0.2945 sec; Batch: 2.4106 sec
0.1248 0.1086 0.0917 0.0843 0.0773 0.0739 0.0710 0.0685 0.0669 0.0648 0.0634 0.0622 0.0615 0.0609 0.0600 0.0597 

[TRAIN] Epoch[1](11127/114412); Loss: 0.090350; Backpropagation: 0.2912 sec; Batch: 2.1415 sec
0.1428 0.1192 0.1104 0.0997 0.0931 0.0890 0.0860 0.0834 0.0816 0.0798 0.0784 0.0776 0.0768 0.0763 0.0758 0.0754 

[TRAIN] Epoch[1](11128/114412); Loss: 0.064455; Backpropagation: 0.2910 sec; Batch: 2.1204 sec
0.1368 0.1266 0.0873 0.0798 0.0672 0.0619 0.0566 0.0534 0.0503 0.0482 0.0461 0.0446 0.0439 0.0430 0.0430 0.0427 

[TRAIN] Epoch[1](11129/114412); Loss: 0.073900; Backpropagation: 0.2928 sec; Batch: 2.1218 sec
0.1832 0.1611 0.1022 0.0752 0.0724 0.0612 0.0570 0.0556 0.0543 0.0537 0.0524 0.0517 0.0511 0.0508 0.0504 0.0500 

[TRAIN] Epoch[1](11130/114412); Loss: 0.059900; Backpropagation: 0.2910 sec; Batch: 2.1197 sec
0.1254 0.1170 0.0885 0.0613 0.0551 0.0524 0.0501 0.0489 0.0477 0.0463 0.0455 0.0449 0.0444 0.0439 0.0436 0.0435 

[TRAIN] Epoch[1](11131/114412); Loss: 0.076818; Backpropagation: 0.2904 sec; Batch: 2.0782 sec
0.1507 0.1423 0.1089 0.0949 0.0772 0.0680 0.0647 0.0623 0.0613 0.0594 0.0585 0.0574 0.0568 0.0559 0.0555 0.0552 

[TRAIN] Epoch[1](11132/114412); Loss: 0.064602; Backpropagation: 0.2907 sec; Batch: 2.1285 sec
0.1089 0.1043 0.0877 0.0783 0.0683 0.0625 0.0591 0.0560 0.0542 0.0528 0.0517 0.0512 0.0504 0.0498 0.0494 0.0490 

[TRAIN] Epoch[1](11133/114412); Loss: 0.062542; Backpropagation: 0.2910 sec; Batch: 2.0797 sec
0.1251 0.1141 0.0816 0.0702 0.0617 0.0583 0.0551 0.0524 0.0505 0.0491 0.0482 0.0476 0.0472 0.0467 0.0465 0.0462 

[TRAIN] Epoch[1](11134/114412); Loss: 0.065589; Backpropagation: 0.2908 sec; Batch: 2.1158 sec
0.1413 0.1331 0.0920 0.0744 0.0663 0.0588 0.0546 0.0515 0.0499 0.0489 0.0477 0.0470 0.0465 0.0459 0.0459 0.0456 

[TRAIN] Epoch[1](11135/114412); Loss: 0.071250; Backpropagation: 0.2911 sec; Batch: 2.1210 sec
0.1248 0.1162 0.0883 0.0786 0.0739 0.0697 0.0664 0.0629 0.0611 0.0594 0.0582 0.0572 0.0565 0.0560 0.0556 0.0551 

[TRAIN] Epoch[1](11136/114412); Loss: 0.079846; Backpropagation: 0.2909 sec; Batch: 2.1203 sec
0.1421 0.1279 0.0954 0.0896 0.0817 0.0774 0.0744 0.0710 0.0692 0.0675 0.0658 0.0647 0.0637 0.0628 0.0624 0.0620 

[TRAIN] Epoch[1](11137/114412); Loss: 0.062754; Backpropagation: 0.2938 sec; Batch: 2.1260 sec
0.1098 0.0999 0.0800 0.0706 0.0644 0.0599 0.0578 0.0551 0.0538 0.0522 0.0514 0.0508 0.0500 0.0498 0.0495 0.0492 

[TRAIN] Epoch[1](11138/114412); Loss: 0.110134; Backpropagation: 0.2949 sec; Batch: 2.1206 sec
0.1907 0.1702 0.1416 0.1263 0.1150 0.1082 0.1022 0.0978 0.0956 0.0921 0.0904 0.0887 0.0873 0.0864 0.0854 0.0843 

[TRAIN] Epoch[1](11139/114412); Loss: 0.068684; Backpropagation: 0.2931 sec; Batch: 2.0808 sec
0.1346 0.1095 0.0859 0.0760 0.0694 0.0664 0.0630 0.0603 0.0580 0.0562 0.0547 0.0539 0.0534 0.0529 0.0525 0.0522 

[TRAIN] Epoch[1](11140/114412); Loss: 0.082305; Backpropagation: 0.2953 sec; Batch: 2.1234 sec
0.1537 0.1344 0.1006 0.0888 0.0815 0.0767 0.0740 0.0719 0.0704 0.0689 0.0677 0.0671 0.0660 0.0656 0.0651 0.0646 

[TRAIN] Epoch[1](11141/114412); Loss: 0.069682; Backpropagation: 0.2907 sec; Batch: 2.0784 sec
0.1425 0.1322 0.0983 0.0855 0.0719 0.0642 0.0588 0.0556 0.0539 0.0525 0.0513 0.0504 0.0500 0.0495 0.0493 0.0491 

[TRAIN] Epoch[1](11142/114412); Loss: 0.080341; Backpropagation: 0.2901 sec; Batch: 2.1200 sec
0.1663 0.1564 0.1094 0.0920 0.0800 0.0725 0.0667 0.0642 0.0629 0.0613 0.0603 0.0596 0.0591 0.0586 0.0582 0.0580 

[TRAIN] Epoch[1](11143/114412); Loss: 0.103115; Backpropagation: 0.2907 sec; Batch: 2.0784 sec
0.1939 0.1824 0.1311 0.1127 0.1007 0.0937 0.0897 0.0874 0.0858 0.0843 0.0830 0.0822 0.0815 0.0809 0.0804 0.0800 

[TRAIN] Epoch[1](11144/114412); Loss: 0.059294; Backpropagation: 0.2907 sec; Batch: 2.0803 sec
0.1070 0.0976 0.0744 0.0651 0.0614 0.0579 0.0553 0.0519 0.0504 0.0485 0.0478 0.0471 0.0464 0.0462 0.0459 0.0456 

[TRAIN] Epoch[1](11145/114412); Loss: 0.051030; Backpropagation: 0.2925 sec; Batch: 2.0794 sec
0.1154 0.1075 0.0696 0.0572 0.0509 0.0460 0.0421 0.0397 0.0383 0.0371 0.0365 0.0360 0.0355 0.0351 0.0348 0.0346 

[TRAIN] Epoch[1](11146/114412); Loss: 0.066226; Backpropagation: 0.2912 sec; Batch: 2.1163 sec
0.1251 0.1150 0.0841 0.0755 0.0673 0.0630 0.0592 0.0565 0.0548 0.0532 0.0525 0.0518 0.0511 0.0507 0.0502 0.0498 

[TRAIN] Epoch[1](11147/114412); Loss: 0.085427; Backpropagation: 0.2909 sec; Batch: 2.0963 sec
0.1659 0.1496 0.1227 0.1041 0.0883 0.0793 0.0759 0.0720 0.0688 0.0666 0.0650 0.0638 0.0625 0.0616 0.0607 0.0600 

[TRAIN] Epoch[1](11148/114412); Loss: 0.053698; Backpropagation: 0.2927 sec; Batch: 2.1160 sec
0.1086 0.0933 0.0718 0.0656 0.0545 0.0510 0.0475 0.0446 0.0433 0.0417 0.0409 0.0402 0.0396 0.0392 0.0389 0.0387 

[TRAIN] Epoch[1](11149/114412); Loss: 0.070785; Backpropagation: 0.2910 sec; Batch: 2.0803 sec
0.1399 0.1270 0.0907 0.0827 0.0722 0.0672 0.0623 0.0591 0.0575 0.0561 0.0548 0.0539 0.0528 0.0523 0.0523 0.0518 

[TRAIN] Epoch[1](11150/114412); Loss: 0.080629; Backpropagation: 0.2941 sec; Batch: 2.0815 sec
0.1549 0.1232 0.1068 0.0900 0.0819 0.0762 0.0735 0.0703 0.0685 0.0665 0.0649 0.0641 0.0633 0.0626 0.0619 0.0613 

[TRAIN] Epoch[1](11151/114412); Loss: 0.099505; Backpropagation: 0.2925 sec; Batch: 2.1378 sec
0.1649 0.1530 0.1152 0.1092 0.1014 0.0962 0.0916 0.0888 0.0874 0.0859 0.0849 0.0840 0.0830 0.0827 0.0820 0.0818 

[TRAIN] Epoch[1](11152/114412); Loss: 0.085973; Backpropagation: 0.2915 sec; Batch: 2.1185 sec
0.1793 0.1576 0.1219 0.1053 0.0905 0.0819 0.0744 0.0704 0.0689 0.0655 0.0637 0.0612 0.0600 0.0590 0.0583 0.0577 

[TRAIN] Epoch[1](11153/114412); Loss: 0.074408; Backpropagation: 0.2911 sec; Batch: 2.1150 sec
0.1513 0.1451 0.1022 0.0857 0.0756 0.0700 0.0658 0.0619 0.0603 0.0583 0.0576 0.0554 0.0542 0.0511 0.0492 0.0469 

[TRAIN] Epoch[1](11154/114412); Loss: 0.074260; Backpropagation: 0.2911 sec; Batch: 2.1222 sec
0.1282 0.1199 0.0902 0.0816 0.0766 0.0727 0.0687 0.0660 0.0641 0.0626 0.0615 0.0606 0.0598 0.0590 0.0585 0.0581 

[TRAIN] Epoch[1](11155/114412); Loss: 0.068460; Backpropagation: 0.2928 sec; Batch: 2.0795 sec
0.1466 0.1391 0.0831 0.0724 0.0641 0.0616 0.0583 0.0557 0.0542 0.0532 0.0523 0.0517 0.0512 0.0506 0.0506 0.0505 

[TRAIN] Epoch[1](11156/114412); Loss: 0.074190; Backpropagation: 0.2912 sec; Batch: 2.0836 sec
0.1480 0.1261 0.0958 0.0812 0.0724 0.0688 0.0651 0.0636 0.0611 0.0601 0.0590 0.0584 0.0579 0.0571 0.0565 0.0561 

[TRAIN] Epoch[1](11157/114412); Loss: 0.070505; Backpropagation: 0.2906 sec; Batch: 2.1198 sec
0.1318 0.1228 0.0968 0.0826 0.0725 0.0661 0.0627 0.0595 0.0577 0.0560 0.0551 0.0541 0.0534 0.0529 0.0523 0.0518 

[TRAIN] Epoch[1](11158/114412); Loss: 0.073687; Backpropagation: 0.2915 sec; Batch: 2.1031 sec
0.1501 0.1453 0.1081 0.0953 0.0752 0.0689 0.0631 0.0600 0.0571 0.0546 0.0531 0.0515 0.0504 0.0495 0.0488 0.0481 

[TRAIN] Epoch[1](11159/114412); Loss: 0.080431; Backpropagation: 0.2908 sec; Batch: 2.1161 sec
0.1305 0.1159 0.0976 0.0924 0.0832 0.0790 0.0753 0.0724 0.0706 0.0692 0.0685 0.0677 0.0670 0.0662 0.0657 0.0656 

[TRAIN] Epoch[1](11160/114412); Loss: 0.048660; Backpropagation: 0.2945 sec; Batch: 2.0821 sec
0.1180 0.1142 0.0736 0.0594 0.0432 0.0417 0.0374 0.0366 0.0339 0.0328 0.0322 0.0317 0.0315 0.0309 0.0307 0.0306 

[TRAIN] Epoch[1](11161/114412); Loss: 0.062725; Backpropagation: 0.2929 sec; Batch: 2.1194 sec
0.1229 0.1236 0.0837 0.0755 0.0626 0.0570 0.0544 0.0524 0.0496 0.0482 0.0469 0.0463 0.0460 0.0453 0.0449 0.0446 

[TRAIN] Epoch[1](11162/114412); Loss: 0.072450; Backpropagation: 0.2906 sec; Batch: 2.1232 sec
0.1268 0.1252 0.0883 0.0797 0.0734 0.0696 0.0659 0.0638 0.0621 0.0605 0.0593 0.0584 0.0576 0.0567 0.0564 0.0558 

[TRAIN] Epoch[1](11163/114412); Loss: 0.079387; Backpropagation: 0.2908 sec; Batch: 2.0816 sec
0.1388 0.1286 0.1021 0.0927 0.0828 0.0775 0.0737 0.0702 0.0678 0.0658 0.0644 0.0632 0.0622 0.0607 0.0601 0.0594 

[TRAIN] Epoch[1](11164/114412); Loss: 0.088675; Backpropagation: 0.2913 sec; Batch: 2.1187 sec
0.1598 0.1465 0.1150 0.1039 0.0887 0.0845 0.0783 0.0762 0.0744 0.0731 0.0718 0.0708 0.0697 0.0691 0.0686 0.0682 

[TRAIN] Epoch[1](11165/114412); Loss: 0.083988; Backpropagation: 0.2950 sec; Batch: 2.1241 sec
0.1385 0.1253 0.1059 0.0950 0.0853 0.0817 0.0778 0.0755 0.0737 0.0719 0.0710 0.0700 0.0690 0.0683 0.0677 0.0673 

[TRAIN] Epoch[1](11166/114412); Loss: 0.070209; Backpropagation: 0.2930 sec; Batch: 2.1191 sec
0.1193 0.1106 0.0864 0.0800 0.0724 0.0675 0.0647 0.0620 0.0605 0.0589 0.0579 0.0574 0.0569 0.0565 0.0562 0.0561 

[TRAIN] Epoch[1](11167/114412); Loss: 0.086082; Backpropagation: 0.2903 sec; Batch: 2.1191 sec
0.1144 0.1105 0.1017 0.0941 0.0891 0.0855 0.0832 0.0818 0.0800 0.0786 0.0778 0.0771 0.0765 0.0761 0.0756 0.0754 

[TRAIN] Epoch[1](11168/114412); Loss: 0.090966; Backpropagation: 0.2926 sec; Batch: 2.1195 sec
0.1638 0.1559 0.1155 0.1048 0.0905 0.0852 0.0813 0.0785 0.0767 0.0747 0.0737 0.0726 0.0716 0.0708 0.0701 0.0697 

[TRAIN] Epoch[1](11169/114412); Loss: 0.054907; Backpropagation: 0.2930 sec; Batch: 2.1218 sec
0.1129 0.0893 0.0714 0.0648 0.0576 0.0523 0.0490 0.0472 0.0451 0.0432 0.0422 0.0414 0.0409 0.0407 0.0404 0.0400 

[TRAIN] Epoch[1](11170/114412); Loss: 0.066860; Backpropagation: 0.2912 sec; Batch: 2.1226 sec
0.1092 0.1038 0.0899 0.0808 0.0714 0.0648 0.0609 0.0589 0.0565 0.0553 0.0544 0.0537 0.0530 0.0527 0.0522 0.0520 

[TRAIN] Epoch[1](11171/114412); Loss: 0.066711; Backpropagation: 0.2910 sec; Batch: 2.1228 sec
0.1708 0.1618 0.0985 0.0730 0.0592 0.0538 0.0511 0.0490 0.0464 0.0450 0.0444 0.0437 0.0432 0.0428 0.0424 0.0423 

[TRAIN] Epoch[1](11172/114412); Loss: 0.066067; Backpropagation: 0.2937 sec; Batch: 2.1231 sec
0.1474 0.1369 0.0874 0.0744 0.0607 0.0562 0.0543 0.0518 0.0509 0.0497 0.0489 0.0482 0.0479 0.0476 0.0474 0.0473 

[TRAIN] Epoch[1](11173/114412); Loss: 0.065238; Backpropagation: 0.2920 sec; Batch: 2.1152 sec
0.1244 0.1168 0.0794 0.0712 0.0655 0.0616 0.0576 0.0556 0.0541 0.0531 0.0519 0.0513 0.0508 0.0505 0.0501 0.0499 

[TRAIN] Epoch[1](11174/114412); Loss: 0.074781; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1298 0.1222 0.0946 0.0852 0.0765 0.0716 0.0680 0.0655 0.0639 0.0623 0.0612 0.0601 0.0595 0.0591 0.0587 0.0582 

[TRAIN] Epoch[1](11175/114412); Loss: 0.076339; Backpropagation: 0.2919 sec; Batch: 2.2785 sec
0.1309 0.1167 0.0959 0.0854 0.0789 0.0740 0.0705 0.0682 0.0664 0.0647 0.0634 0.0625 0.0618 0.0611 0.0608 0.0603 

[TRAIN] Epoch[1](11176/114412); Loss: 0.091940; Backpropagation: 0.2909 sec; Batch: 2.1232 sec
0.1458 0.1313 0.1129 0.1013 0.0952 0.0903 0.0866 0.0840 0.0820 0.0802 0.0790 0.0780 0.0769 0.0765 0.0757 0.0753 

[TRAIN] Epoch[1](11177/114412); Loss: 0.065553; Backpropagation: 0.2945 sec; Batch: 2.1258 sec
0.1242 0.1188 0.0774 0.0716 0.0654 0.0617 0.0577 0.0561 0.0545 0.0531 0.0524 0.0518 0.0514 0.0511 0.0508 0.0507 

[TRAIN] Epoch[1](11178/114412); Loss: 0.086110; Backpropagation: 0.2940 sec; Batch: 2.0816 sec
0.1502 0.1353 0.1060 0.0934 0.0863 0.0837 0.0792 0.0769 0.0741 0.0726 0.0717 0.0708 0.0700 0.0696 0.0690 0.0689 

[TRAIN] Epoch[1](11179/114412); Loss: 0.063430; Backpropagation: 0.2924 sec; Batch: 2.1140 sec
0.1151 0.1103 0.0860 0.0771 0.0656 0.0620 0.0573 0.0543 0.0524 0.0501 0.0489 0.0482 0.0474 0.0470 0.0466 0.0465 

[TRAIN] Epoch[1](11180/114412); Loss: 0.081955; Backpropagation: 0.2909 sec; Batch: 2.3749 sec
0.1757 0.1684 0.1131 0.0939 0.0823 0.0751 0.0691 0.0657 0.0632 0.0608 0.0595 0.0585 0.0573 0.0567 0.0562 0.0558 

[TRAIN] Epoch[1](11181/114412); Loss: 0.065916; Backpropagation: 0.2913 sec; Batch: 2.1151 sec
0.1402 0.1308 0.0832 0.0737 0.0670 0.0609 0.0565 0.0539 0.0515 0.0502 0.0489 0.0486 0.0476 0.0473 0.0471 0.0470 

[TRAIN] Epoch[1](11182/114412); Loss: 0.078195; Backpropagation: 0.2910 sec; Batch: 2.1182 sec
0.1539 0.1462 0.1050 0.0927 0.0789 0.0707 0.0666 0.0640 0.0626 0.0609 0.0599 0.0591 0.0583 0.0579 0.0574 0.0571 

[TRAIN] Epoch[1](11183/114412); Loss: 0.056074; Backpropagation: 0.2960 sec; Batch: 2.1210 sec
0.1206 0.1112 0.0706 0.0641 0.0556 0.0518 0.0488 0.0463 0.0447 0.0426 0.0417 0.0411 0.0400 0.0397 0.0392 0.0389 

[TRAIN] Epoch[1](11184/114412); Loss: 0.072339; Backpropagation: 0.2926 sec; Batch: 2.1216 sec
0.1850 0.1752 0.1069 0.0847 0.0658 0.0585 0.0543 0.0517 0.0502 0.0490 0.0473 0.0467 0.0458 0.0456 0.0453 0.0452 

[TRAIN] Epoch[1](11185/114412); Loss: 0.061551; Backpropagation: 0.2955 sec; Batch: 2.1192 sec
0.1061 0.1002 0.0864 0.0697 0.0656 0.0583 0.0559 0.0537 0.0521 0.0505 0.0494 0.0484 0.0478 0.0473 0.0468 0.0466 

[TRAIN] Epoch[1](11186/114412); Loss: 0.068932; Backpropagation: 0.2955 sec; Batch: 2.1188 sec
0.1208 0.1142 0.0845 0.0820 0.0753 0.0695 0.0634 0.0599 0.0574 0.0561 0.0548 0.0541 0.0534 0.0529 0.0523 0.0520 

[TRAIN] Epoch[1](11187/114412); Loss: 0.050961; Backpropagation: 0.2909 sec; Batch: 2.0774 sec
0.1305 0.1206 0.0727 0.0584 0.0485 0.0426 0.0410 0.0372 0.0359 0.0342 0.0335 0.0331 0.0321 0.0318 0.0315 0.0316 

[TRAIN] Epoch[1](11188/114412); Loss: 0.074932; Backpropagation: 0.2920 sec; Batch: 2.0784 sec
0.1409 0.1292 0.0989 0.0885 0.0765 0.0696 0.0671 0.0639 0.0618 0.0601 0.0590 0.0578 0.0573 0.0566 0.0560 0.0557 

[TRAIN] Epoch[1](11189/114412); Loss: 0.079538; Backpropagation: 0.2931 sec; Batch: 2.1220 sec
0.1281 0.1250 0.1025 0.0944 0.0856 0.0787 0.0752 0.0714 0.0696 0.0669 0.0649 0.0638 0.0624 0.0620 0.0613 0.0608 

[TRAIN] Epoch[1](11190/114412); Loss: 0.072850; Backpropagation: 0.2906 sec; Batch: 2.1139 sec
0.1498 0.1272 0.0959 0.0899 0.0743 0.0680 0.0636 0.0604 0.0584 0.0567 0.0553 0.0545 0.0536 0.0530 0.0526 0.0523 

[TRAIN] Epoch[1](11191/114412); Loss: 0.063629; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1153 0.1037 0.0852 0.0758 0.0673 0.0611 0.0574 0.0549 0.0531 0.0517 0.0505 0.0498 0.0488 0.0482 0.0478 0.0473 

[TRAIN] Epoch[1](11192/114412); Loss: 0.090919; Backpropagation: 0.2911 sec; Batch: 2.0853 sec
0.1701 0.1570 0.1227 0.1103 0.0982 0.0915 0.0824 0.0775 0.0736 0.0713 0.0694 0.0681 0.0668 0.0659 0.0653 0.0645 

[TRAIN] Epoch[1](11193/114412); Loss: 0.064349; Backpropagation: 0.2910 sec; Batch: 2.1219 sec
0.1447 0.1331 0.0791 0.0745 0.0633 0.0574 0.0541 0.0510 0.0493 0.0478 0.0470 0.0464 0.0460 0.0456 0.0453 0.0451 

[TRAIN] Epoch[1](11194/114412); Loss: 0.081319; Backpropagation: 0.2951 sec; Batch: 2.1209 sec
0.1425 0.1238 0.0941 0.0865 0.0836 0.0796 0.0762 0.0732 0.0713 0.0698 0.0685 0.0675 0.0667 0.0664 0.0658 0.0656 

[TRAIN] Epoch[1](11195/114412); Loss: 0.095685; Backpropagation: 0.2905 sec; Batch: 2.1160 sec
0.1646 0.1482 0.1204 0.1047 0.0981 0.0912 0.0880 0.0845 0.0826 0.0814 0.0801 0.0788 0.0780 0.0772 0.0768 0.0763 

[TRAIN] Epoch[1](11196/114412); Loss: 0.061312; Backpropagation: 0.2903 sec; Batch: 2.1169 sec
0.1111 0.1016 0.0767 0.0711 0.0634 0.0589 0.0548 0.0531 0.0517 0.0506 0.0496 0.0487 0.0479 0.0476 0.0472 0.0470 

[TRAIN] Epoch[1](11197/114412); Loss: 0.094163; Backpropagation: 0.2911 sec; Batch: 2.1199 sec
0.1466 0.1401 0.1157 0.1056 0.0983 0.0938 0.0898 0.0866 0.0839 0.0817 0.0799 0.0786 0.0775 0.0768 0.0758 0.0756 

[TRAIN] Epoch[1](11198/114412); Loss: 0.079193; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.1693 0.1475 0.1162 0.1058 0.0957 0.0813 0.0742 0.0661 0.0593 0.0551 0.0540 0.0511 0.0504 0.0488 0.0465 0.0457 

[TRAIN] Epoch[1](11199/114412); Loss: 0.059344; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1055 0.1024 0.0920 0.0707 0.0646 0.0579 0.0514 0.0497 0.0478 0.0462 0.0450 0.0439 0.0437 0.0432 0.0428 0.0428 

[TRAIN] Epoch[1](11200/114412); Loss: 0.060846; Backpropagation: 0.2929 sec; Batch: 2.1145 sec
0.1117 0.1010 0.0818 0.0736 0.0638 0.0585 0.0546 0.0521 0.0499 0.0488 0.0478 0.0470 0.0462 0.0457 0.0457 0.0454 

[TRAIN] Epoch[1](11201/114412); Loss: 0.077496; Backpropagation: 0.2929 sec; Batch: 2.1187 sec
0.1374 0.1328 0.0896 0.0858 0.0807 0.0749 0.0710 0.0674 0.0660 0.0643 0.0632 0.0624 0.0617 0.0611 0.0608 0.0607 

[TRAIN] Epoch[1](11202/114412); Loss: 0.056487; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1044 0.1005 0.0765 0.0665 0.0599 0.0534 0.0504 0.0479 0.0465 0.0445 0.0435 0.0430 0.0425 0.0420 0.0413 0.0410 

[TRAIN] Epoch[1](11203/114412); Loss: 0.064174; Backpropagation: 0.2904 sec; Batch: 2.0781 sec
0.1079 0.0967 0.0802 0.0741 0.0679 0.0630 0.0600 0.0571 0.0553 0.0543 0.0530 0.0524 0.0518 0.0514 0.0511 0.0505 

[TRAIN] Epoch[1](11204/114412); Loss: 0.057445; Backpropagation: 0.2913 sec; Batch: 2.1150 sec
0.1382 0.1370 0.0749 0.0614 0.0524 0.0493 0.0457 0.0436 0.0422 0.0410 0.0403 0.0394 0.0390 0.0385 0.0382 0.0380 

[TRAIN] Epoch[1](11205/114412); Loss: 0.105073; Backpropagation: 0.2953 sec; Batch: 2.1226 sec
0.1742 0.1649 0.1292 0.1188 0.1071 0.1022 0.0976 0.0948 0.0919 0.0899 0.0878 0.0865 0.0852 0.0845 0.0836 0.0829 

[TRAIN] Epoch[1](11206/114412); Loss: 0.086005; Backpropagation: 0.2928 sec; Batch: 2.1211 sec
0.1443 0.1335 0.1010 0.0917 0.0869 0.0819 0.0790 0.0773 0.0757 0.0742 0.0734 0.0724 0.0717 0.0713 0.0709 0.0708 

[TRAIN] Epoch[1](11207/114412); Loss: 0.080312; Backpropagation: 0.2922 sec; Batch: 2.1211 sec
0.1446 0.1329 0.1038 0.0918 0.0809 0.0764 0.0724 0.0697 0.0675 0.0658 0.0651 0.0641 0.0633 0.0628 0.0622 0.0618 

[TRAIN] Epoch[1](11208/114412); Loss: 0.074429; Backpropagation: 0.2914 sec; Batch: 2.1170 sec
0.1299 0.1208 0.0881 0.0788 0.0747 0.0701 0.0679 0.0653 0.0637 0.0626 0.0625 0.0622 0.0615 0.0613 0.0608 0.0606 

[TRAIN] Epoch[1](11209/114412); Loss: 0.059597; Backpropagation: 0.2912 sec; Batch: 2.0972 sec
0.1427 0.1311 0.0814 0.0676 0.0568 0.0527 0.0507 0.0456 0.0431 0.0417 0.0411 0.0405 0.0401 0.0398 0.0394 0.0393 

[TRAIN] Epoch[1](11210/114412); Loss: 0.073506; Backpropagation: 0.2909 sec; Batch: 2.0760 sec
0.1331 0.1295 0.0944 0.0819 0.0723 0.0676 0.0651 0.0632 0.0614 0.0600 0.0591 0.0585 0.0581 0.0576 0.0573 0.0571 

[TRAIN] Epoch[1](11211/114412); Loss: 0.085245; Backpropagation: 0.2914 sec; Batch: 2.1199 sec
0.1595 0.1485 0.1124 0.1027 0.0895 0.0830 0.0768 0.0721 0.0696 0.0675 0.0662 0.0650 0.0639 0.0630 0.0624 0.0618 

[TRAIN] Epoch[1](11212/114412); Loss: 0.078387; Backpropagation: 0.2926 sec; Batch: 2.1179 sec
0.1195 0.1238 0.1002 0.0904 0.0822 0.0756 0.0723 0.0701 0.0675 0.0663 0.0656 0.0648 0.0644 0.0640 0.0639 0.0636 

[TRAIN] Epoch[1](11213/114412); Loss: 0.051680; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.1126 0.1088 0.0643 0.0577 0.0522 0.0482 0.0449 0.0412 0.0398 0.0383 0.0379 0.0371 0.0365 0.0361 0.0357 0.0355 

[TRAIN] Epoch[1](11214/114412); Loss: 0.092738; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1435 0.1348 0.1170 0.1039 0.0981 0.0921 0.0879 0.0849 0.0824 0.0803 0.0789 0.0776 0.0767 0.0763 0.0748 0.0747 

[TRAIN] Epoch[1](11215/114412); Loss: 0.066850; Backpropagation: 0.2917 sec; Batch: 2.1169 sec
0.1547 0.1446 0.0991 0.0783 0.0637 0.0592 0.0558 0.0525 0.0495 0.0474 0.0460 0.0450 0.0442 0.0437 0.0431 0.0428 

[TRAIN] Epoch[1](11216/114412); Loss: 0.076050; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.1304 0.1233 0.0899 0.0842 0.0793 0.0739 0.0705 0.0677 0.0661 0.0641 0.0632 0.0619 0.0613 0.0609 0.0603 0.0599 

[TRAIN] Epoch[1](11217/114412); Loss: 0.075515; Backpropagation: 0.2954 sec; Batch: 2.1175 sec
0.1385 0.1287 0.0959 0.0873 0.0796 0.0753 0.0683 0.0655 0.0627 0.0609 0.0596 0.0584 0.0578 0.0571 0.0566 0.0561 

[TRAIN] Epoch[1](11218/114412); Loss: 0.061942; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1282 0.1129 0.0793 0.0704 0.0605 0.0571 0.0544 0.0520 0.0505 0.0489 0.0478 0.0473 0.0461 0.0456 0.0453 0.0448 

[TRAIN] Epoch[1](11219/114412); Loss: 0.072382; Backpropagation: 0.2909 sec; Batch: 2.1338 sec
0.1244 0.1175 0.0923 0.0827 0.0741 0.0695 0.0662 0.0637 0.0620 0.0603 0.0591 0.0581 0.0575 0.0571 0.0568 0.0566 

[TRAIN] Epoch[1](11220/114412); Loss: 0.057648; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1141 0.1021 0.0768 0.0702 0.0617 0.0545 0.0496 0.0476 0.0460 0.0447 0.0441 0.0431 0.0426 0.0421 0.0417 0.0414 

[TRAIN] Epoch[1](11221/114412); Loss: 0.088352; Backpropagation: 0.2916 sec; Batch: 2.0868 sec
0.1594 0.1483 0.1059 0.0957 0.0875 0.0823 0.0788 0.0765 0.0748 0.0732 0.0728 0.0724 0.0720 0.0716 0.0713 0.0712 

[TRAIN] Epoch[1](11222/114412); Loss: 0.086403; Backpropagation: 0.2913 sec; Batch: 2.0779 sec
0.1429 0.1374 0.1068 0.0945 0.0863 0.0833 0.0802 0.0769 0.0749 0.0738 0.0727 0.0718 0.0711 0.0704 0.0700 0.0696 

[TRAIN] Epoch[1](11223/114412); Loss: 0.085831; Backpropagation: 0.2913 sec; Batch: 2.1010 sec
0.1529 0.1417 0.1056 0.0960 0.0895 0.0830 0.0789 0.0753 0.0735 0.0714 0.0697 0.0688 0.0678 0.0669 0.0664 0.0660 

[TRAIN] Epoch[1](11224/114412); Loss: 0.104602; Backpropagation: 0.2930 sec; Batch: 2.1333 sec
0.1663 0.1657 0.1256 0.1222 0.1079 0.1026 0.0968 0.0945 0.0915 0.0899 0.0880 0.0866 0.0852 0.0844 0.0834 0.0830 

[TRAIN] Epoch[1](11225/114412); Loss: 0.099966; Backpropagation: 0.2933 sec; Batch: 2.1217 sec
0.1694 0.1533 0.1270 0.1120 0.1026 0.0925 0.0903 0.0879 0.0858 0.0854 0.0841 0.0833 0.0821 0.0816 0.0813 0.0808 

[TRAIN] Epoch[1](11226/114412); Loss: 0.059528; Backpropagation: 0.2911 sec; Batch: 2.1161 sec
0.1431 0.1342 0.0761 0.0656 0.0601 0.0541 0.0486 0.0460 0.0432 0.0420 0.0412 0.0405 0.0401 0.0395 0.0393 0.0389 

[TRAIN] Epoch[1](11227/114412); Loss: 0.081095; Backpropagation: 0.2931 sec; Batch: 2.1179 sec
0.1420 0.1307 0.1024 0.0980 0.0832 0.0782 0.0725 0.0702 0.0687 0.0672 0.0661 0.0652 0.0642 0.0634 0.0628 0.0626 

[TRAIN] Epoch[1](11228/114412); Loss: 0.068607; Backpropagation: 0.2907 sec; Batch: 2.1115 sec
0.1299 0.1211 0.0888 0.0757 0.0718 0.0665 0.0617 0.0582 0.0567 0.0547 0.0538 0.0527 0.0521 0.0516 0.0512 0.0511 

[TRAIN] Epoch[1](11229/114412); Loss: 0.088199; Backpropagation: 0.2907 sec; Batch: 2.1144 sec
0.1486 0.1401 0.1174 0.1030 0.0895 0.0856 0.0809 0.0771 0.0752 0.0735 0.0719 0.0711 0.0703 0.0694 0.0691 0.0685 

[TRAIN] Epoch[1](11230/114412); Loss: 0.070001; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1694 0.1440 0.1007 0.0842 0.0664 0.0620 0.0570 0.0539 0.0522 0.0503 0.0485 0.0477 0.0467 0.0461 0.0456 0.0452 

[TRAIN] Epoch[1](11231/114412); Loss: 0.074948; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1386 0.1288 0.0987 0.0897 0.0786 0.0718 0.0670 0.0637 0.0615 0.0599 0.0585 0.0580 0.0569 0.0564 0.0558 0.0553 

[TRAIN] Epoch[1](11232/114412); Loss: 0.070337; Backpropagation: 0.2909 sec; Batch: 2.1128 sec
0.1589 0.1498 0.0977 0.0873 0.0650 0.0614 0.0578 0.0558 0.0527 0.0509 0.0500 0.0491 0.0484 0.0474 0.0468 0.0464 

[TRAIN] Epoch[1](11233/114412); Loss: 0.088866; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1586 0.1457 0.1130 0.1012 0.0917 0.0856 0.0821 0.0784 0.0755 0.0737 0.0718 0.0708 0.0695 0.0688 0.0680 0.0675 

[TRAIN] Epoch[1](11234/114412); Loss: 0.090980; Backpropagation: 0.2933 sec; Batch: 2.1176 sec
0.1493 0.1431 0.1140 0.1029 0.0931 0.0871 0.0838 0.0811 0.0789 0.0777 0.0761 0.0748 0.0742 0.0735 0.0732 0.0729 

[TRAIN] Epoch[1](11235/114412); Loss: 0.084059; Backpropagation: 0.2929 sec; Batch: 2.1158 sec
0.1424 0.1354 0.0999 0.0924 0.0869 0.0816 0.0778 0.0744 0.0727 0.0710 0.0699 0.0692 0.0686 0.0679 0.0676 0.0673 

[TRAIN] Epoch[1](11236/114412); Loss: 0.095524; Backpropagation: 0.2951 sec; Batch: 2.1206 sec
0.1814 0.1603 0.1286 0.1070 0.0968 0.0895 0.0845 0.0818 0.0790 0.0778 0.0759 0.0752 0.0738 0.0730 0.0721 0.0717 

[TRAIN] Epoch[1](11237/114412); Loss: 0.066332; Backpropagation: 0.2943 sec; Batch: 2.1039 sec
0.1461 0.1407 0.0831 0.0719 0.0661 0.0609 0.0558 0.0529 0.0509 0.0497 0.0487 0.0479 0.0473 0.0467 0.0465 0.0462 

[TRAIN] Epoch[1](11238/114412); Loss: 0.076298; Backpropagation: 0.2951 sec; Batch: 2.1178 sec
0.1818 0.1669 0.1211 0.0955 0.0767 0.0646 0.0615 0.0573 0.0537 0.0524 0.0503 0.0493 0.0483 0.0475 0.0471 0.0466 

[TRAIN] Epoch[1](11239/114412); Loss: 0.086638; Backpropagation: 0.2910 sec; Batch: 2.1173 sec
0.1661 0.1569 0.1129 0.0964 0.0841 0.0808 0.0772 0.0740 0.0712 0.0698 0.0681 0.0674 0.0662 0.0655 0.0650 0.0646 

[TRAIN] Epoch[1](11240/114412); Loss: 0.080846; Backpropagation: 0.2910 sec; Batch: 2.1167 sec
0.1553 0.1493 0.1068 0.0982 0.0833 0.0768 0.0716 0.0674 0.0658 0.0638 0.0618 0.0604 0.0593 0.0589 0.0577 0.0573 

[TRAIN] Epoch[1](11241/114412); Loss: 0.069775; Backpropagation: 0.2910 sec; Batch: 2.1180 sec
0.1298 0.1163 0.0888 0.0781 0.0717 0.0672 0.0635 0.0611 0.0591 0.0572 0.0560 0.0550 0.0540 0.0533 0.0528 0.0523 

[TRAIN] Epoch[1](11242/114412); Loss: 0.075772; Backpropagation: 0.2912 sec; Batch: 2.1108 sec
0.1227 0.1174 0.0937 0.0836 0.0776 0.0749 0.0708 0.0687 0.0665 0.0650 0.0635 0.0626 0.0620 0.0615 0.0611 0.0608 

[TRAIN] Epoch[1](11243/114412); Loss: 0.073617; Backpropagation: 0.2912 sec; Batch: 2.1246 sec
0.1512 0.1441 0.0927 0.0864 0.0741 0.0671 0.0646 0.0612 0.0589 0.0567 0.0558 0.0546 0.0535 0.0529 0.0521 0.0518 

[TRAIN] Epoch[1](11244/114412); Loss: 0.078115; Backpropagation: 0.2914 sec; Batch: 2.1166 sec
0.1517 0.1374 0.1034 0.0906 0.0795 0.0739 0.0685 0.0653 0.0631 0.0624 0.0610 0.0601 0.0590 0.0584 0.0580 0.0576 

[TRAIN] Epoch[1](11245/114412); Loss: 0.071618; Backpropagation: 0.2911 sec; Batch: 2.1149 sec
0.1291 0.1202 0.0800 0.0762 0.0700 0.0676 0.0647 0.0624 0.0621 0.0608 0.0602 0.0595 0.0586 0.0586 0.0582 0.0579 

[TRAIN] Epoch[1](11246/114412); Loss: 0.055814; Backpropagation: 0.2906 sec; Batch: 2.1181 sec
0.1237 0.1184 0.0710 0.0636 0.0553 0.0498 0.0462 0.0441 0.0425 0.0418 0.0406 0.0399 0.0395 0.0390 0.0388 0.0388 

[TRAIN] Epoch[1](11247/114412); Loss: 0.083560; Backpropagation: 0.2903 sec; Batch: 2.1174 sec
0.1565 0.1461 0.1000 0.0941 0.0827 0.0769 0.0726 0.0709 0.0699 0.0684 0.0678 0.0670 0.0665 0.0664 0.0657 0.0654 

[TRAIN] Epoch[1](11248/114412); Loss: 0.075030; Backpropagation: 0.2911 sec; Batch: 2.1322 sec
0.1445 0.1314 0.0918 0.0851 0.0747 0.0709 0.0683 0.0644 0.0625 0.0606 0.0589 0.0585 0.0578 0.0574 0.0569 0.0567 

[TRAIN] Epoch[1](11249/114412); Loss: 0.086805; Backpropagation: 0.2909 sec; Batch: 2.1209 sec
0.1632 0.1441 0.1072 0.0930 0.0843 0.0817 0.0771 0.0755 0.0736 0.0720 0.0711 0.0702 0.0696 0.0693 0.0687 0.0683 

[TRAIN] Epoch[1](11250/114412); Loss: 0.073842; Backpropagation: 0.2909 sec; Batch: 2.1132 sec
0.1556 0.1420 0.0971 0.0887 0.0760 0.0682 0.0633 0.0597 0.0573 0.0557 0.0547 0.0538 0.0531 0.0525 0.0520 0.0518 

[TRAIN] Epoch[1](11251/114412); Loss: 0.090117; Backpropagation: 0.2948 sec; Batch: 2.1297 sec
0.1659 0.1575 0.1159 0.1058 0.0899 0.0852 0.0804 0.0773 0.0749 0.0733 0.0719 0.0706 0.0695 0.0686 0.0679 0.0672 

[TRAIN] Epoch[1](11252/114412); Loss: 0.080551; Backpropagation: 0.2913 sec; Batch: 2.0768 sec
0.1533 0.1460 0.1010 0.0907 0.0841 0.0791 0.0716 0.0693 0.0660 0.0643 0.0625 0.0618 0.0608 0.0601 0.0594 0.0588 

[TRAIN] Epoch[1](11253/114412); Loss: 0.059131; Backpropagation: 0.2904 sec; Batch: 2.1137 sec
0.1181 0.1104 0.0728 0.0702 0.0615 0.0565 0.0518 0.0490 0.0471 0.0455 0.0448 0.0444 0.0440 0.0434 0.0434 0.0432 

[TRAIN] Epoch[1](11254/114412); Loss: 0.068934; Backpropagation: 0.2909 sec; Batch: 2.1152 sec
0.1453 0.1357 0.0866 0.0760 0.0684 0.0648 0.0612 0.0571 0.0548 0.0529 0.0519 0.0510 0.0501 0.0494 0.0490 0.0487 

[TRAIN] Epoch[1](11255/114412); Loss: 0.068654; Backpropagation: 0.2907 sec; Batch: 2.1191 sec
0.1683 0.1616 0.0862 0.0711 0.0625 0.0574 0.0558 0.0518 0.0506 0.0487 0.0483 0.0478 0.0477 0.0471 0.0469 0.0468 

[TRAIN] Epoch[1](11256/114412); Loss: 0.072337; Backpropagation: 0.2904 sec; Batch: 2.0821 sec
0.1525 0.1407 0.1026 0.0903 0.0806 0.0721 0.0668 0.0607 0.0572 0.0531 0.0499 0.0484 0.0472 0.0458 0.0452 0.0442 

[TRAIN] Epoch[1](11257/114412); Loss: 0.067649; Backpropagation: 0.2912 sec; Batch: 2.1191 sec
0.1509 0.1443 0.0743 0.0762 0.0722 0.0657 0.0578 0.0541 0.0516 0.0500 0.0487 0.0484 0.0478 0.0473 0.0468 0.0465 

[TRAIN] Epoch[1](11258/114412); Loss: 0.071208; Backpropagation: 0.2956 sec; Batch: 2.0924 sec
0.1534 0.1482 0.0994 0.0895 0.0702 0.0624 0.0595 0.0562 0.0539 0.0520 0.0509 0.0500 0.0493 0.0486 0.0482 0.0478 

[TRAIN] Epoch[1](11259/114412); Loss: 0.090377; Backpropagation: 0.2916 sec; Batch: 2.0843 sec
0.1698 0.1565 0.1233 0.1061 0.0903 0.0841 0.0800 0.0767 0.0735 0.0722 0.0710 0.0701 0.0691 0.0681 0.0677 0.0676 

[TRAIN] Epoch[1](11260/114412); Loss: 0.079166; Backpropagation: 0.2907 sec; Batch: 2.1148 sec
0.1315 0.1239 0.0982 0.0921 0.0821 0.0769 0.0730 0.0703 0.0685 0.0671 0.0658 0.0649 0.0638 0.0633 0.0628 0.0623 

[TRAIN] Epoch[1](11261/114412); Loss: 0.092922; Backpropagation: 0.2911 sec; Batch: 2.1422 sec
0.1531 0.1453 0.1170 0.1038 0.0936 0.0884 0.0850 0.0828 0.0808 0.0794 0.0779 0.0771 0.0763 0.0758 0.0753 0.0749 

[TRAIN] Epoch[1](11262/114412); Loss: 0.053928; Backpropagation: 0.2908 sec; Batch: 2.0785 sec
0.1157 0.1072 0.0651 0.0605 0.0533 0.0501 0.0461 0.0431 0.0416 0.0410 0.0408 0.0399 0.0397 0.0397 0.0395 0.0395 

[TRAIN] Epoch[1](11263/114412); Loss: 0.075405; Backpropagation: 0.2907 sec; Batch: 2.0768 sec
0.1711 0.1597 0.1152 0.0930 0.0668 0.0651 0.0593 0.0567 0.0549 0.0534 0.0527 0.0523 0.0517 0.0517 0.0513 0.0515 

[TRAIN] Epoch[1](11264/114412); Loss: 0.071207; Backpropagation: 0.2902 sec; Batch: 2.1049 sec
0.1465 0.1375 0.0892 0.0813 0.0731 0.0667 0.0625 0.0594 0.0567 0.0551 0.0537 0.0527 0.0521 0.0514 0.0510 0.0505 

[TRAIN] Epoch[1](11265/114412); Loss: 0.077006; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1445 0.1350 0.1006 0.0895 0.0766 0.0722 0.0680 0.0652 0.0635 0.0619 0.0609 0.0601 0.0593 0.0588 0.0582 0.0578 

[TRAIN] Epoch[1](11266/114412); Loss: 0.085522; Backpropagation: 0.2930 sec; Batch: 2.1164 sec
0.1635 0.1307 0.1086 0.0981 0.0880 0.0840 0.0778 0.0748 0.0723 0.0703 0.0689 0.0675 0.0668 0.0662 0.0657 0.0654 

[TRAIN] Epoch[1](11267/114412); Loss: 0.090519; Backpropagation: 0.2952 sec; Batch: 2.1182 sec
0.1286 0.1230 0.1048 0.0985 0.0932 0.0888 0.0868 0.0841 0.0830 0.0815 0.0807 0.0798 0.0793 0.0791 0.0787 0.0785 

[TRAIN] Epoch[1](11268/114412); Loss: 0.069694; Backpropagation: 0.2907 sec; Batch: 2.1178 sec
0.1407 0.1277 0.0955 0.0823 0.0707 0.0638 0.0597 0.0580 0.0554 0.0544 0.0528 0.0520 0.0514 0.0507 0.0504 0.0499 

[TRAIN] Epoch[1](11269/114412); Loss: 0.068401; Backpropagation: 0.2909 sec; Batch: 2.1130 sec
0.1617 0.1485 0.0904 0.0728 0.0677 0.0605 0.0568 0.0538 0.0516 0.0501 0.0487 0.0478 0.0470 0.0461 0.0457 0.0454 

[TRAIN] Epoch[1](11270/114412); Loss: 0.088699; Backpropagation: 0.2911 sec; Batch: 2.1284 sec
0.1839 0.1632 0.1172 0.0991 0.0828 0.0784 0.0764 0.0736 0.0714 0.0699 0.0687 0.0684 0.0675 0.0667 0.0662 0.0659 

[TRAIN] Epoch[1](11271/114412); Loss: 0.068574; Backpropagation: 0.2908 sec; Batch: 2.0787 sec
0.1179 0.1150 0.0870 0.0792 0.0714 0.0660 0.0630 0.0603 0.0581 0.0568 0.0553 0.0546 0.0538 0.0534 0.0529 0.0524 

[TRAIN] Epoch[1](11272/114412); Loss: 0.059786; Backpropagation: 0.2904 sec; Batch: 2.1139 sec
0.1258 0.1174 0.0791 0.0682 0.0607 0.0553 0.0513 0.0487 0.0466 0.0453 0.0445 0.0437 0.0432 0.0427 0.0422 0.0419 

[TRAIN] Epoch[1](11273/114412); Loss: 0.073046; Backpropagation: 0.2909 sec; Batch: 2.1171 sec
0.1428 0.1222 0.0997 0.0869 0.0756 0.0690 0.0649 0.0613 0.0592 0.0583 0.0567 0.0557 0.0549 0.0541 0.0539 0.0536 

[TRAIN] Epoch[1](11274/114412); Loss: 0.066021; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.1388 0.1320 0.0822 0.0737 0.0663 0.0605 0.0564 0.0543 0.0523 0.0510 0.0498 0.0490 0.0482 0.0478 0.0472 0.0469 

[TRAIN] Epoch[1](11275/114412); Loss: 0.056718; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.1233 0.1163 0.0799 0.0663 0.0656 0.0562 0.0503 0.0464 0.0427 0.0403 0.0381 0.0372 0.0368 0.0363 0.0360 0.0357 

[TRAIN] Epoch[1](11276/114412); Loss: 0.060207; Backpropagation: 0.2908 sec; Batch: 2.1209 sec
0.1257 0.1199 0.0914 0.0767 0.0613 0.0547 0.0505 0.0479 0.0453 0.0438 0.0427 0.0414 0.0409 0.0404 0.0402 0.0404 

[TRAIN] Epoch[1](11277/114412); Loss: 0.086814; Backpropagation: 0.2909 sec; Batch: 2.1128 sec
0.1261 0.1219 0.1043 0.0974 0.0907 0.0880 0.0835 0.0810 0.0784 0.0765 0.0757 0.0745 0.0738 0.0729 0.0723 0.0720 

[TRAIN] Epoch[1](11278/114412); Loss: 0.071007; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1490 0.1357 0.0929 0.0794 0.0762 0.0678 0.0623 0.0577 0.0553 0.0534 0.0524 0.0517 0.0511 0.0508 0.0503 0.0501 

[TRAIN] Epoch[1](11279/114412); Loss: 0.079383; Backpropagation: 0.2910 sec; Batch: 2.1244 sec
0.1329 0.1290 0.0994 0.0925 0.0834 0.0775 0.0724 0.0695 0.0674 0.0662 0.0648 0.0645 0.0635 0.0627 0.0624 0.0619 

[TRAIN] Epoch[1](11280/114412); Loss: 0.072833; Backpropagation: 0.2913 sec; Batch: 2.1101 sec
0.1315 0.1212 0.0896 0.0827 0.0769 0.0720 0.0669 0.0639 0.0612 0.0597 0.0585 0.0576 0.0569 0.0563 0.0555 0.0550 

[TRAIN] Epoch[1](11281/114412); Loss: 0.071365; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.1350 0.1270 0.0835 0.0796 0.0727 0.0692 0.0643 0.0615 0.0590 0.0581 0.0567 0.0561 0.0554 0.0550 0.0545 0.0541 

[TRAIN] Epoch[1](11282/114412); Loss: 0.079603; Backpropagation: 0.2911 sec; Batch: 2.1138 sec
0.1695 0.1573 0.1104 0.0917 0.0769 0.0704 0.0669 0.0642 0.0625 0.0606 0.0588 0.0582 0.0572 0.0569 0.0565 0.0558 

[TRAIN] Epoch[1](11283/114412); Loss: 0.082014; Backpropagation: 0.2930 sec; Batch: 2.1272 sec
0.1568 0.1453 0.1013 0.0965 0.0810 0.0758 0.0722 0.0694 0.0676 0.0662 0.0649 0.0641 0.0635 0.0630 0.0625 0.0622 

[TRAIN] Epoch[1](11284/114412); Loss: 0.082297; Backpropagation: 0.2909 sec; Batch: 2.1153 sec
0.1297 0.1206 0.1044 0.0943 0.0872 0.0804 0.0769 0.0741 0.0721 0.0708 0.0694 0.0684 0.0677 0.0673 0.0669 0.0665 

[TRAIN] Epoch[1](11285/114412); Loss: 0.075736; Backpropagation: 0.2913 sec; Batch: 2.0769 sec
0.1272 0.1153 0.0949 0.0878 0.0808 0.0750 0.0698 0.0665 0.0651 0.0635 0.0626 0.0617 0.0610 0.0605 0.0603 0.0599 

[TRAIN] Epoch[1](11286/114412); Loss: 0.088514; Backpropagation: 0.2905 sec; Batch: 2.0777 sec
0.1560 0.1449 0.1108 0.1012 0.0878 0.0835 0.0802 0.0775 0.0757 0.0743 0.0729 0.0718 0.0710 0.0702 0.0694 0.0690 

[TRAIN] Epoch[1](11287/114412); Loss: 0.084668; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1389 0.1247 0.1038 0.0979 0.0880 0.0836 0.0782 0.0757 0.0736 0.0721 0.0710 0.0703 0.0699 0.0695 0.0690 0.0687 

[TRAIN] Epoch[1](11288/114412); Loss: 0.068187; Backpropagation: 0.2909 sec; Batch: 2.1167 sec
0.1319 0.1214 0.0819 0.0752 0.0702 0.0630 0.0605 0.0578 0.0565 0.0548 0.0543 0.0534 0.0529 0.0527 0.0524 0.0522 

[TRAIN] Epoch[1](11289/114412); Loss: 0.062043; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1231 0.1095 0.0769 0.0698 0.0635 0.0594 0.0562 0.0530 0.0511 0.0495 0.0488 0.0475 0.0467 0.0464 0.0458 0.0455 

[TRAIN] Epoch[1](11290/114412); Loss: 0.080788; Backpropagation: 0.2918 sec; Batch: 2.1185 sec
0.1284 0.1254 0.0985 0.0908 0.0824 0.0788 0.0749 0.0728 0.0709 0.0692 0.0682 0.0673 0.0671 0.0663 0.0659 0.0655 

[TRAIN] Epoch[1](11291/114412); Loss: 0.080566; Backpropagation: 0.2912 sec; Batch: 2.1012 sec
0.1408 0.1325 0.1004 0.0904 0.0826 0.0784 0.0738 0.0707 0.0685 0.0670 0.0656 0.0647 0.0639 0.0635 0.0631 0.0630 

[TRAIN] Epoch[1](11292/114412); Loss: 0.059322; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1329 0.1303 0.0655 0.0638 0.0605 0.0552 0.0504 0.0477 0.0461 0.0444 0.0433 0.0428 0.0423 0.0418 0.0413 0.0409 

[TRAIN] Epoch[1](11293/114412); Loss: 0.058098; Backpropagation: 0.2912 sec; Batch: 2.1226 sec
0.1334 0.1289 0.0842 0.0702 0.0585 0.0510 0.0455 0.0451 0.0425 0.0412 0.0395 0.0390 0.0384 0.0376 0.0374 0.0371 

[TRAIN] Epoch[1](11294/114412); Loss: 0.074796; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1327 0.1274 0.0888 0.0818 0.0763 0.0706 0.0671 0.0659 0.0637 0.0624 0.0611 0.0604 0.0599 0.0597 0.0596 0.0592 

[TRAIN] Epoch[1](11295/114412); Loss: 0.092864; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1826 0.1730 0.1193 0.1062 0.1020 0.0880 0.0828 0.0779 0.0755 0.0725 0.0713 0.0693 0.0678 0.0668 0.0657 0.0651 

[TRAIN] Epoch[1](11296/114412); Loss: 0.071873; Backpropagation: 0.2916 sec; Batch: 2.1466 sec
0.1438 0.1297 0.1004 0.0855 0.0728 0.0662 0.0623 0.0594 0.0574 0.0556 0.0546 0.0538 0.0528 0.0523 0.0518 0.0514 

[TRAIN] Epoch[1](11297/114412); Loss: 0.077674; Backpropagation: 0.2950 sec; Batch: 2.1331 sec
0.1595 0.1456 0.0862 0.0786 0.0820 0.0756 0.0695 0.0644 0.0627 0.0614 0.0607 0.0602 0.0597 0.0595 0.0588 0.0584 

[TRAIN] Epoch[1](11298/114412); Loss: 0.069845; Backpropagation: 0.2919 sec; Batch: 2.1145 sec
0.1637 0.1570 0.0976 0.0834 0.0664 0.0621 0.0569 0.0536 0.0514 0.0492 0.0479 0.0470 0.0461 0.0456 0.0450 0.0448 

[TRAIN] Epoch[1](11299/114412); Loss: 0.056971; Backpropagation: 0.2907 sec; Batch: 2.1209 sec
0.0970 0.0883 0.0722 0.0642 0.0600 0.0548 0.0523 0.0504 0.0488 0.0476 0.0470 0.0465 0.0460 0.0458 0.0455 0.0452 

[TRAIN] Epoch[1](11300/114412); Loss: 0.072215; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1325 0.1217 0.0953 0.0847 0.0757 0.0699 0.0655 0.0627 0.0602 0.0579 0.0570 0.0558 0.0550 0.0545 0.0538 0.0535 

[TRAIN] Epoch[1](11301/114412); Loss: 0.079057; Backpropagation: 0.2927 sec; Batch: 2.0836 sec
0.1419 0.1316 0.1001 0.0887 0.0828 0.0771 0.0736 0.0696 0.0675 0.0652 0.0636 0.0622 0.0610 0.0605 0.0599 0.0596 

[TRAIN] Epoch[1](11302/114412); Loss: 0.082308; Backpropagation: 0.2931 sec; Batch: 2.1200 sec
0.1375 0.1196 0.0977 0.0906 0.0844 0.0795 0.0768 0.0742 0.0728 0.0714 0.0702 0.0696 0.0688 0.0685 0.0680 0.0676 

[TRAIN] Epoch[1](11303/114412); Loss: 0.062789; Backpropagation: 0.2909 sec; Batch: 2.0799 sec
0.1300 0.1140 0.0861 0.0755 0.0620 0.0583 0.0539 0.0517 0.0500 0.0483 0.0473 0.0467 0.0460 0.0455 0.0449 0.0446 

[TRAIN] Epoch[1](11304/114412); Loss: 0.073938; Backpropagation: 0.2909 sec; Batch: 2.0780 sec
0.1456 0.1397 0.0931 0.0839 0.0716 0.0677 0.0662 0.0618 0.0596 0.0583 0.0571 0.0567 0.0560 0.0555 0.0551 0.0549 

[TRAIN] Epoch[1](11305/114412); Loss: 0.069481; Backpropagation: 0.2913 sec; Batch: 2.1410 sec
0.1248 0.1095 0.0845 0.0799 0.0712 0.0673 0.0630 0.0612 0.0592 0.0581 0.0571 0.0562 0.0557 0.0551 0.0545 0.0545 

[TRAIN] Epoch[1](11306/114412); Loss: 0.060790; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1193 0.1088 0.0788 0.0701 0.0618 0.0568 0.0528 0.0505 0.0493 0.0479 0.0470 0.0464 0.0460 0.0458 0.0456 0.0456 

[TRAIN] Epoch[1](11307/114412); Loss: 0.071371; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1392 0.1318 0.0917 0.0810 0.0714 0.0664 0.0628 0.0589 0.0575 0.0559 0.0553 0.0549 0.0542 0.0538 0.0536 0.0534 

[TRAIN] Epoch[1](11308/114412); Loss: 0.114496; Backpropagation: 0.2919 sec; Batch: 2.1214 sec
0.1708 0.1600 0.1323 0.1244 0.1170 0.1130 0.1091 0.1068 0.1042 0.1026 0.1014 0.0998 0.0988 0.0979 0.0971 0.0966 

[TRAIN] Epoch[1](11309/114412); Loss: 0.071841; Backpropagation: 0.2931 sec; Batch: 2.1144 sec
0.1438 0.1269 0.0870 0.0817 0.0725 0.0688 0.0641 0.0615 0.0587 0.0573 0.0561 0.0553 0.0546 0.0541 0.0537 0.0534 

[TRAIN] Epoch[1](11310/114412); Loss: 0.082289; Backpropagation: 0.2910 sec; Batch: 2.1206 sec
0.1437 0.1291 0.1040 0.0953 0.0861 0.0792 0.0750 0.0724 0.0700 0.0684 0.0673 0.0663 0.0655 0.0651 0.0648 0.0645 

[TRAIN] Epoch[1](11311/114412); Loss: 0.079185; Backpropagation: 0.2909 sec; Batch: 2.1137 sec
0.1589 0.1496 0.0965 0.0825 0.0807 0.0743 0.0702 0.0660 0.0639 0.0627 0.0617 0.0612 0.0603 0.0599 0.0595 0.0592 

[TRAIN] Epoch[1](11312/114412); Loss: 0.077970; Backpropagation: 0.2928 sec; Batch: 2.0902 sec
0.1573 0.1503 0.0923 0.0832 0.0744 0.0716 0.0675 0.0664 0.0638 0.0623 0.0609 0.0602 0.0598 0.0593 0.0591 0.0589 

[TRAIN] Epoch[1](11313/114412); Loss: 0.083321; Backpropagation: 0.2924 sec; Batch: 2.1097 sec
0.1417 0.1344 0.1019 0.0898 0.0873 0.0816 0.0781 0.0744 0.0723 0.0703 0.0689 0.0679 0.0672 0.0664 0.0658 0.0651 

[TRAIN] Epoch[1](11314/114412); Loss: 0.074046; Backpropagation: 0.2953 sec; Batch: 2.0819 sec
0.1344 0.1234 0.0931 0.0838 0.0749 0.0701 0.0670 0.0641 0.0626 0.0613 0.0601 0.0590 0.0586 0.0579 0.0574 0.0570 

[TRAIN] Epoch[1](11315/114412); Loss: 0.061310; Backpropagation: 0.2901 sec; Batch: 2.1137 sec
0.1204 0.1100 0.0877 0.0769 0.0660 0.0602 0.0544 0.0511 0.0486 0.0466 0.0453 0.0441 0.0432 0.0427 0.0421 0.0416 

[TRAIN] Epoch[1](11316/114412); Loss: 0.077689; Backpropagation: 0.2907 sec; Batch: 2.1135 sec
0.1425 0.1330 0.0989 0.0862 0.0788 0.0747 0.0699 0.0678 0.0649 0.0638 0.0622 0.0613 0.0604 0.0599 0.0594 0.0591 

[TRAIN] Epoch[1](11317/114412); Loss: 0.103051; Backpropagation: 0.2929 sec; Batch: 2.1167 sec
0.1699 0.1532 0.1271 0.1153 0.1068 0.1012 0.0978 0.0938 0.0911 0.0892 0.0871 0.0858 0.0840 0.0831 0.0822 0.0811 

[TRAIN] Epoch[1](11318/114412); Loss: 0.071291; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1396 0.1235 0.0964 0.0849 0.0723 0.0668 0.0634 0.0604 0.0582 0.0564 0.0552 0.0542 0.0533 0.0524 0.0520 0.0517 

[TRAIN] Epoch[1](11319/114412); Loss: 0.079765; Backpropagation: 0.2913 sec; Batch: 2.0783 sec
0.1629 0.1528 0.1044 0.0927 0.0780 0.0735 0.0685 0.0660 0.0634 0.0618 0.0604 0.0595 0.0590 0.0583 0.0578 0.0572 

[TRAIN] Epoch[1](11320/114412); Loss: 0.083498; Backpropagation: 0.2927 sec; Batch: 2.1280 sec
0.1560 0.1511 0.1067 0.0979 0.0866 0.0800 0.0751 0.0710 0.0681 0.0660 0.0647 0.0640 0.0630 0.0624 0.0619 0.0616 

[TRAIN] Epoch[1](11321/114412); Loss: 0.070537; Backpropagation: 0.2914 sec; Batch: 2.0771 sec
0.1617 0.1442 0.0919 0.0797 0.0717 0.0632 0.0591 0.0563 0.0543 0.0523 0.0510 0.0498 0.0491 0.0486 0.0481 0.0476 

[TRAIN] Epoch[1](11322/114412); Loss: 0.057248; Backpropagation: 0.2930 sec; Batch: 2.1360 sec
0.1318 0.1110 0.0660 0.0600 0.0579 0.0510 0.0489 0.0465 0.0454 0.0441 0.0434 0.0428 0.0421 0.0418 0.0418 0.0416 

[TRAIN] Epoch[1](11323/114412); Loss: 0.055860; Backpropagation: 0.2908 sec; Batch: 2.0780 sec
0.1367 0.1192 0.0639 0.0563 0.0561 0.0504 0.0469 0.0437 0.0422 0.0412 0.0402 0.0399 0.0396 0.0394 0.0390 0.0390 

[TRAIN] Epoch[1](11324/114412); Loss: 0.055935; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1166 0.0997 0.0788 0.0669 0.0555 0.0533 0.0480 0.0460 0.0441 0.0426 0.0416 0.0411 0.0405 0.0402 0.0400 0.0398 

[TRAIN] Epoch[1](11325/114412); Loss: 0.074411; Backpropagation: 0.2907 sec; Batch: 2.0779 sec
0.1426 0.1198 0.1049 0.0900 0.0753 0.0706 0.0661 0.0630 0.0606 0.0591 0.0579 0.0570 0.0564 0.0561 0.0557 0.0555 

[TRAIN] Epoch[1](11326/114412); Loss: 0.058851; Backpropagation: 0.2907 sec; Batch: 2.1184 sec
0.1261 0.1144 0.0780 0.0695 0.0639 0.0588 0.0522 0.0478 0.0455 0.0437 0.0422 0.0411 0.0403 0.0398 0.0393 0.0390 

[TRAIN] Epoch[1](11327/114412); Loss: 0.067773; Backpropagation: 0.2955 sec; Batch: 2.1200 sec
0.1087 0.1078 0.0912 0.0829 0.0692 0.0655 0.0609 0.0597 0.0579 0.0566 0.0557 0.0546 0.0540 0.0536 0.0531 0.0529 

[TRAIN] Epoch[1](11328/114412); Loss: 0.076777; Backpropagation: 0.2929 sec; Batch: 2.1164 sec
0.1435 0.1226 0.0880 0.0830 0.0782 0.0742 0.0708 0.0685 0.0662 0.0647 0.0634 0.0625 0.0614 0.0611 0.0603 0.0601 

[TRAIN] Epoch[1](11329/114412); Loss: 0.087598; Backpropagation: 0.2952 sec; Batch: 2.1249 sec
0.1366 0.1289 0.1054 0.1002 0.0919 0.0869 0.0827 0.0806 0.0781 0.0760 0.0745 0.0734 0.0725 0.0718 0.0712 0.0709 

[TRAIN] Epoch[1](11330/114412); Loss: 0.093228; Backpropagation: 0.2921 sec; Batch: 2.1177 sec
0.1548 0.1516 0.1161 0.1080 0.0974 0.0916 0.0857 0.0831 0.0796 0.0783 0.0764 0.0756 0.0744 0.0737 0.0729 0.0725 

[TRAIN] Epoch[1](11331/114412); Loss: 0.084490; Backpropagation: 0.2915 sec; Batch: 2.1301 sec
0.1447 0.1349 0.1057 0.0944 0.0862 0.0815 0.0775 0.0746 0.0725 0.0706 0.0700 0.0686 0.0683 0.0679 0.0673 0.0673 

[TRAIN] Epoch[1](11332/114412); Loss: 0.081263; Backpropagation: 0.2905 sec; Batch: 2.1191 sec
0.1622 0.1371 0.1024 0.0954 0.0860 0.0801 0.0735 0.0690 0.0667 0.0643 0.0626 0.0619 0.0609 0.0601 0.0595 0.0585 

[TRAIN] Epoch[1](11333/114412); Loss: 0.092945; Backpropagation: 0.2908 sec; Batch: 2.1268 sec
0.1970 0.1873 0.1315 0.1119 0.0871 0.0833 0.0774 0.0744 0.0719 0.0701 0.0682 0.0669 0.0661 0.0651 0.0647 0.0642 

[TRAIN] Epoch[1](11334/114412); Loss: 0.095770; Backpropagation: 0.2953 sec; Batch: 2.0862 sec
0.1649 0.1488 0.1184 0.1110 0.0983 0.0935 0.0881 0.0846 0.0817 0.0802 0.0794 0.0781 0.0771 0.0765 0.0761 0.0756 

[TRAIN] Epoch[1](11335/114412); Loss: 0.078477; Backpropagation: 0.2930 sec; Batch: 2.1287 sec
0.1330 0.1259 0.0982 0.0908 0.0836 0.0768 0.0726 0.0697 0.0683 0.0662 0.0645 0.0630 0.0619 0.0611 0.0603 0.0597 

[TRAIN] Epoch[1](11336/114412); Loss: 0.076818; Backpropagation: 0.2909 sec; Batch: 2.1125 sec
0.1357 0.1216 0.1032 0.0912 0.0792 0.0735 0.0696 0.0663 0.0643 0.0627 0.0619 0.0611 0.0604 0.0598 0.0594 0.0591 

[TRAIN] Epoch[1](11337/114412); Loss: 0.062249; Backpropagation: 0.2913 sec; Batch: 2.1152 sec
0.1407 0.1276 0.0798 0.0719 0.0608 0.0556 0.0516 0.0487 0.0470 0.0463 0.0455 0.0450 0.0445 0.0440 0.0437 0.0434 

[TRAIN] Epoch[1](11338/114412); Loss: 0.084934; Backpropagation: 0.2909 sec; Batch: 2.1223 sec
0.1472 0.1389 0.1034 0.0967 0.0863 0.0821 0.0780 0.0754 0.0730 0.0711 0.0698 0.0686 0.0680 0.0674 0.0668 0.0664 

[TRAIN] Epoch[1](11339/114412); Loss: 0.074559; Backpropagation: 0.2909 sec; Batch: 2.0771 sec
0.1535 0.1368 0.0979 0.0885 0.0771 0.0693 0.0654 0.0615 0.0593 0.0574 0.0561 0.0554 0.0544 0.0538 0.0534 0.0531 

[TRAIN] Epoch[1](11340/114412); Loss: 0.066211; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1573 0.1522 0.0957 0.0795 0.0697 0.0643 0.0579 0.0530 0.0487 0.0450 0.0424 0.0409 0.0396 0.0384 0.0376 0.0370 

[TRAIN] Epoch[1](11341/114412); Loss: 0.085080; Backpropagation: 0.2908 sec; Batch: 2.0767 sec
0.1511 0.1401 0.1092 0.0988 0.0859 0.0817 0.0765 0.0740 0.0718 0.0701 0.0689 0.0680 0.0669 0.0665 0.0661 0.0658 

[TRAIN] Epoch[1](11342/114412); Loss: 0.066696; Backpropagation: 0.2909 sec; Batch: 2.1138 sec
0.1329 0.1238 0.0836 0.0748 0.0677 0.0637 0.0598 0.0564 0.0541 0.0525 0.0513 0.0506 0.0498 0.0493 0.0487 0.0483 

[TRAIN] Epoch[1](11343/114412); Loss: 0.091451; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1687 0.1605 0.1137 0.1013 0.0900 0.0831 0.0805 0.0780 0.0764 0.0748 0.0743 0.0736 0.0727 0.0723 0.0718 0.0715 

[TRAIN] Epoch[1](11344/114412); Loss: 0.055222; Backpropagation: 0.2920 sec; Batch: 2.1144 sec
0.1227 0.1125 0.0791 0.0692 0.0582 0.0506 0.0464 0.0435 0.0417 0.0399 0.0388 0.0375 0.0367 0.0360 0.0355 0.0351 

[TRAIN] Epoch[1](11345/114412); Loss: 0.070194; Backpropagation: 0.2927 sec; Batch: 2.1175 sec
0.1492 0.1202 0.0950 0.0825 0.0746 0.0662 0.0618 0.0580 0.0561 0.0547 0.0531 0.0518 0.0508 0.0501 0.0496 0.0492 

[TRAIN] Epoch[1](11346/114412); Loss: 0.068195; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1275 0.1159 0.0849 0.0782 0.0696 0.0639 0.0611 0.0581 0.0567 0.0555 0.0547 0.0536 0.0533 0.0528 0.0526 0.0525 

[TRAIN] Epoch[1](11347/114412); Loss: 0.081682; Backpropagation: 0.2912 sec; Batch: 2.1175 sec
0.1542 0.1435 0.0997 0.0910 0.0809 0.0768 0.0754 0.0722 0.0692 0.0668 0.0655 0.0637 0.0630 0.0625 0.0616 0.0610 

[TRAIN] Epoch[1](11348/114412); Loss: 0.061262; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1373 0.1093 0.0813 0.0711 0.0596 0.0568 0.0523 0.0498 0.0478 0.0463 0.0457 0.0453 0.0448 0.0446 0.0442 0.0440 

[TRAIN] Epoch[1](11349/114412); Loss: 0.080463; Backpropagation: 0.2911 sec; Batch: 2.1139 sec
0.1671 0.1557 0.1024 0.0959 0.0796 0.0747 0.0701 0.0674 0.0646 0.0622 0.0610 0.0594 0.0581 0.0572 0.0563 0.0558 

[TRAIN] Epoch[1](11350/114412); Loss: 0.076803; Backpropagation: 0.2913 sec; Batch: 2.1152 sec
0.1554 0.1403 0.1009 0.0875 0.0763 0.0711 0.0670 0.0650 0.0621 0.0603 0.0593 0.0579 0.0573 0.0567 0.0560 0.0558 

[TRAIN] Epoch[1](11351/114412); Loss: 0.086714; Backpropagation: 0.2933 sec; Batch: 2.1217 sec
0.1906 0.1684 0.1116 0.0881 0.0824 0.0812 0.0770 0.0732 0.0688 0.0672 0.0651 0.0644 0.0635 0.0624 0.0620 0.0614 

[TRAIN] Epoch[1](11352/114412); Loss: 0.082535; Backpropagation: 0.2907 sec; Batch: 2.1158 sec
0.1573 0.1494 0.1082 0.0977 0.0851 0.0793 0.0739 0.0709 0.0674 0.0655 0.0634 0.0622 0.0611 0.0603 0.0598 0.0592 

[TRAIN] Epoch[1](11353/114412); Loss: 0.073475; Backpropagation: 0.2908 sec; Batch: 2.0764 sec
0.1223 0.1167 0.0882 0.0825 0.0748 0.0709 0.0674 0.0646 0.0632 0.0621 0.0614 0.0610 0.0604 0.0602 0.0600 0.0599 

[TRAIN] Epoch[1](11354/114412); Loss: 0.065314; Backpropagation: 0.2931 sec; Batch: 2.1159 sec
0.1491 0.1309 0.0916 0.0727 0.0672 0.0615 0.0566 0.0531 0.0510 0.0481 0.0463 0.0450 0.0439 0.0432 0.0427 0.0423 

[TRAIN] Epoch[1](11355/114412); Loss: 0.064350; Backpropagation: 0.2930 sec; Batch: 2.1190 sec
0.1244 0.1080 0.0843 0.0757 0.0650 0.0601 0.0562 0.0548 0.0533 0.0517 0.0507 0.0498 0.0493 0.0490 0.0487 0.0484 

[TRAIN] Epoch[1](11356/114412); Loss: 0.084630; Backpropagation: 0.2908 sec; Batch: 2.1147 sec
0.1476 0.1319 0.1066 0.0952 0.0880 0.0829 0.0780 0.0747 0.0724 0.0709 0.0699 0.0688 0.0677 0.0671 0.0663 0.0660 

[TRAIN] Epoch[1](11357/114412); Loss: 0.059677; Backpropagation: 0.2938 sec; Batch: 2.1166 sec
0.1096 0.0906 0.0799 0.0701 0.0648 0.0582 0.0545 0.0516 0.0496 0.0484 0.0477 0.0467 0.0464 0.0459 0.0455 0.0453 

[TRAIN] Epoch[1](11358/114412); Loss: 0.075865; Backpropagation: 0.2951 sec; Batch: 2.1188 sec
0.1228 0.1138 0.0972 0.0874 0.0807 0.0745 0.0711 0.0681 0.0658 0.0643 0.0632 0.0623 0.0616 0.0610 0.0604 0.0597 

[TRAIN] Epoch[1](11359/114412); Loss: 0.075326; Backpropagation: 0.2913 sec; Batch: 2.1134 sec
0.1827 0.1661 0.1056 0.0884 0.0678 0.0661 0.0624 0.0589 0.0564 0.0533 0.0520 0.0502 0.0497 0.0492 0.0485 0.0480 

[TRAIN] Epoch[1](11360/114412); Loss: 0.077818; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1565 0.1430 0.1050 0.0856 0.0780 0.0727 0.0699 0.0657 0.0635 0.0610 0.0597 0.0584 0.0575 0.0568 0.0560 0.0557 

[TRAIN] Epoch[1](11361/114412); Loss: 0.090893; Backpropagation: 0.2911 sec; Batch: 2.1125 sec
0.1856 0.1745 0.1255 0.1081 0.0870 0.0812 0.0775 0.0734 0.0713 0.0697 0.0686 0.0672 0.0666 0.0662 0.0659 0.0661 

[TRAIN] Epoch[1](11362/114412); Loss: 0.113336; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1552 0.1461 0.1356 0.1252 0.1185 0.1130 0.1096 0.1069 0.1045 0.1029 0.1015 0.1003 0.0995 0.0990 0.0981 0.0975 

[TRAIN] Epoch[1](11363/114412); Loss: 0.072598; Backpropagation: 0.2955 sec; Batch: 2.1181 sec
0.1491 0.1440 0.0937 0.0768 0.0692 0.0675 0.0644 0.0616 0.0596 0.0565 0.0549 0.0540 0.0532 0.0526 0.0523 0.0521 

[TRAIN] Epoch[1](11364/114412); Loss: 0.082954; Backpropagation: 0.2954 sec; Batch: 2.1171 sec
0.1486 0.1389 0.0997 0.0914 0.0830 0.0794 0.0753 0.0728 0.0708 0.0695 0.0681 0.0670 0.0664 0.0657 0.0655 0.0651 

[TRAIN] Epoch[1](11365/114412); Loss: 0.070501; Backpropagation: 0.2929 sec; Batch: 2.1203 sec
0.1432 0.1247 0.0932 0.0801 0.0731 0.0675 0.0632 0.0606 0.0581 0.0557 0.0544 0.0528 0.0516 0.0505 0.0498 0.0493 

[TRAIN] Epoch[1](11366/114412); Loss: 0.085869; Backpropagation: 0.2951 sec; Batch: 2.1239 sec
0.1429 0.1298 0.1070 0.0946 0.0888 0.0847 0.0814 0.0769 0.0748 0.0731 0.0718 0.0709 0.0700 0.0695 0.0689 0.0688 

[TRAIN] Epoch[1](11367/114412); Loss: 0.085907; Backpropagation: 0.2912 sec; Batch: 2.1237 sec
0.1691 0.1531 0.1155 0.1017 0.0884 0.0820 0.0756 0.0732 0.0693 0.0676 0.0654 0.0642 0.0634 0.0624 0.0620 0.0615 

[TRAIN] Epoch[1](11368/114412); Loss: 0.077458; Backpropagation: 0.2916 sec; Batch: 2.1202 sec
0.1416 0.1291 0.0961 0.0858 0.0790 0.0733 0.0698 0.0672 0.0652 0.0640 0.0628 0.0620 0.0615 0.0610 0.0606 0.0603 

[TRAIN] Epoch[1](11369/114412); Loss: 0.079801; Backpropagation: 0.2910 sec; Batch: 2.1152 sec
0.1280 0.1250 0.0999 0.0900 0.0839 0.0779 0.0736 0.0710 0.0686 0.0674 0.0665 0.0658 0.0653 0.0647 0.0646 0.0644 

[TRAIN] Epoch[1](11370/114412); Loss: 0.108525; Backpropagation: 0.2907 sec; Batch: 2.1183 sec
0.1930 0.1708 0.1396 0.1257 0.1091 0.1034 0.0983 0.0957 0.0930 0.0905 0.0892 0.0875 0.0863 0.0854 0.0849 0.0842 

[TRAIN] Epoch[1](11371/114412); Loss: 0.061001; Backpropagation: 0.2908 sec; Batch: 2.1186 sec
0.1311 0.1262 0.0818 0.0670 0.0593 0.0538 0.0508 0.0487 0.0476 0.0461 0.0455 0.0446 0.0438 0.0435 0.0431 0.0431 

[TRAIN] Epoch[1](11372/114412); Loss: 0.075052; Backpropagation: 0.2911 sec; Batch: 2.1124 sec
0.1379 0.1199 0.1002 0.0898 0.0800 0.0726 0.0672 0.0649 0.0621 0.0608 0.0595 0.0584 0.0577 0.0570 0.0567 0.0562 

[TRAIN] Epoch[1](11373/114412); Loss: 0.085160; Backpropagation: 0.2931 sec; Batch: 2.1194 sec
0.2014 0.1991 0.1286 0.1127 0.0813 0.0702 0.0652 0.0624 0.0592 0.0573 0.0560 0.0552 0.0545 0.0536 0.0531 0.0527 

[TRAIN] Epoch[1](11374/114412); Loss: 0.057955; Backpropagation: 0.2906 sec; Batch: 2.4295 sec
0.1138 0.1209 0.0730 0.0683 0.0580 0.0523 0.0469 0.0476 0.0453 0.0450 0.0440 0.0430 0.0428 0.0423 0.0421 0.0420 

[TRAIN] Epoch[1](11375/114412); Loss: 0.106180; Backpropagation: 0.2920 sec; Batch: 2.1159 sec
0.1863 0.1779 0.1422 0.1278 0.1143 0.1036 0.0952 0.0904 0.0872 0.0856 0.0837 0.0828 0.0814 0.0809 0.0800 0.0796 

[TRAIN] Epoch[1](11376/114412); Loss: 0.067281; Backpropagation: 0.2914 sec; Batch: 2.1215 sec
0.1082 0.0979 0.0917 0.0832 0.0735 0.0677 0.0632 0.0607 0.0579 0.0560 0.0546 0.0535 0.0526 0.0522 0.0518 0.0517 

[TRAIN] Epoch[1](11377/114412); Loss: 0.067231; Backpropagation: 0.2941 sec; Batch: 2.1196 sec
0.1400 0.1232 0.0802 0.0756 0.0691 0.0635 0.0591 0.0565 0.0542 0.0529 0.0519 0.0510 0.0504 0.0499 0.0494 0.0489 

[TRAIN] Epoch[1](11378/114412); Loss: 0.077603; Backpropagation: 0.2908 sec; Batch: 2.1178 sec
0.1815 0.1682 0.1132 0.0929 0.0755 0.0658 0.0613 0.0576 0.0553 0.0543 0.0533 0.0532 0.0529 0.0526 0.0522 0.0521 

[TRAIN] Epoch[1](11379/114412); Loss: 0.080092; Backpropagation: 0.2913 sec; Batch: 2.1140 sec
0.1761 0.1626 0.1151 0.0972 0.0802 0.0723 0.0679 0.0636 0.0602 0.0585 0.0568 0.0559 0.0547 0.0540 0.0534 0.0529 

[TRAIN] Epoch[1](11380/114412); Loss: 0.062928; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.1476 0.1427 0.0826 0.0686 0.0610 0.0567 0.0537 0.0500 0.0462 0.0451 0.0432 0.0429 0.0422 0.0417 0.0413 0.0413 

[TRAIN] Epoch[1](11381/114412); Loss: 0.130034; Backpropagation: 0.2928 sec; Batch: 2.0807 sec
0.2185 0.2067 0.1721 0.1623 0.1445 0.1358 0.1273 0.1179 0.1140 0.1073 0.1052 0.1001 0.0967 0.0932 0.0901 0.0887 

[TRAIN] Epoch[1](11382/114412); Loss: 0.087581; Backpropagation: 0.2905 sec; Batch: 2.1135 sec
0.1456 0.1305 0.0999 0.0968 0.0900 0.0862 0.0829 0.0790 0.0776 0.0757 0.0750 0.0737 0.0729 0.0724 0.0717 0.0713 

[TRAIN] Epoch[1](11383/114412); Loss: 0.091550; Backpropagation: 0.2950 sec; Batch: 2.1190 sec
0.1753 0.1626 0.1163 0.1044 0.0931 0.0876 0.0828 0.0786 0.0755 0.0737 0.0718 0.0705 0.0693 0.0685 0.0677 0.0671 

[TRAIN] Epoch[1](11384/114412); Loss: 0.079303; Backpropagation: 0.2950 sec; Batch: 2.0821 sec
0.1492 0.1324 0.1034 0.0925 0.0819 0.0777 0.0716 0.0690 0.0666 0.0643 0.0625 0.0610 0.0601 0.0596 0.0588 0.0583 

[TRAIN] Epoch[1](11385/114412); Loss: 0.066766; Backpropagation: 0.2955 sec; Batch: 2.1199 sec
0.1617 0.1445 0.0898 0.0745 0.0664 0.0602 0.0551 0.0517 0.0500 0.0472 0.0463 0.0452 0.0445 0.0442 0.0437 0.0434 

[TRAIN] Epoch[1](11386/114412); Loss: 0.062419; Backpropagation: 0.2955 sec; Batch: 2.1209 sec
0.1129 0.1065 0.0810 0.0750 0.0662 0.0609 0.0560 0.0533 0.0511 0.0499 0.0489 0.0481 0.0478 0.0473 0.0470 0.0468 

[TRAIN] Epoch[1](11387/114412); Loss: 0.090360; Backpropagation: 0.2910 sec; Batch: 2.3073 sec
0.1451 0.1253 0.1068 0.0985 0.0939 0.0893 0.0862 0.0832 0.0811 0.0793 0.0780 0.0772 0.0761 0.0757 0.0751 0.0748 

[TRAIN] Epoch[1](11388/114412); Loss: 0.075381; Backpropagation: 0.2911 sec; Batch: 2.0993 sec
0.1476 0.1351 0.0977 0.0924 0.0819 0.0747 0.0671 0.0626 0.0603 0.0583 0.0570 0.0560 0.0549 0.0540 0.0534 0.0530 

[TRAIN] Epoch[1](11389/114412); Loss: 0.080400; Backpropagation: 0.2939 sec; Batch: 2.1201 sec
0.1349 0.1252 0.0989 0.0902 0.0825 0.0802 0.0757 0.0726 0.0694 0.0677 0.0666 0.0657 0.0650 0.0645 0.0639 0.0634 

[TRAIN] Epoch[1](11390/114412); Loss: 0.059889; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1471 0.1401 0.0766 0.0656 0.0592 0.0539 0.0489 0.0458 0.0438 0.0422 0.0409 0.0402 0.0392 0.0387 0.0381 0.0377 

[TRAIN] Epoch[1](11391/114412); Loss: 0.066622; Backpropagation: 0.2918 sec; Batch: 2.1046 sec
0.1212 0.1176 0.0821 0.0704 0.0655 0.0611 0.0587 0.0573 0.0564 0.0552 0.0547 0.0541 0.0534 0.0530 0.0527 0.0524 

[TRAIN] Epoch[1](11392/114412); Loss: 0.089455; Backpropagation: 0.2952 sec; Batch: 2.1188 sec
0.1431 0.1410 0.1132 0.1012 0.0919 0.0865 0.0825 0.0791 0.0775 0.0758 0.0751 0.0741 0.0733 0.0727 0.0723 0.0719 

[TRAIN] Epoch[1](11393/114412); Loss: 0.068005; Backpropagation: 0.2910 sec; Batch: 2.1152 sec
0.1313 0.1239 0.0901 0.0768 0.0694 0.0637 0.0601 0.0576 0.0556 0.0538 0.0527 0.0519 0.0511 0.0505 0.0499 0.0496 

[TRAIN] Epoch[1](11394/114412); Loss: 0.080055; Backpropagation: 0.2910 sec; Batch: 2.1158 sec
0.1336 0.1254 0.0952 0.0881 0.0826 0.0785 0.0744 0.0717 0.0696 0.0680 0.0669 0.0663 0.0656 0.0653 0.0650 0.0647 

[TRAIN] Epoch[1](11395/114412); Loss: 0.085766; Backpropagation: 0.2919 sec; Batch: 2.0787 sec
0.1567 0.1401 0.1102 0.0990 0.0883 0.0828 0.0788 0.0752 0.0727 0.0704 0.0683 0.0672 0.0664 0.0657 0.0653 0.0651 

[TRAIN] Epoch[1](11396/114412); Loss: 0.104448; Backpropagation: 0.2917 sec; Batch: 2.1156 sec
0.1657 0.1477 0.1232 0.1146 0.1056 0.1020 0.0977 0.0953 0.0924 0.0913 0.0903 0.0898 0.0892 0.0890 0.0886 0.0885 

[TRAIN] Epoch[1](11397/114412); Loss: 0.058704; Backpropagation: 0.2912 sec; Batch: 2.1267 sec
0.1431 0.1327 0.0867 0.0698 0.0552 0.0495 0.0457 0.0435 0.0423 0.0408 0.0397 0.0388 0.0383 0.0379 0.0376 0.0374 

[TRAIN] Epoch[1](11398/114412); Loss: 0.059694; Backpropagation: 0.2914 sec; Batch: 2.0812 sec
0.1577 0.1428 0.0952 0.0660 0.0599 0.0465 0.0450 0.0415 0.0394 0.0392 0.0383 0.0379 0.0367 0.0366 0.0361 0.0361 

[TRAIN] Epoch[1](11399/114412); Loss: 0.064994; Backpropagation: 0.2912 sec; Batch: 2.0775 sec
0.1409 0.1344 0.0837 0.0735 0.0665 0.0598 0.0570 0.0528 0.0505 0.0485 0.0474 0.0463 0.0452 0.0448 0.0443 0.0442 

[TRAIN] Epoch[1](11400/114412); Loss: 0.068200; Backpropagation: 0.2931 sec; Batch: 2.1311 sec
0.1489 0.1372 0.0929 0.0826 0.0700 0.0647 0.0576 0.0541 0.0514 0.0497 0.0486 0.0477 0.0473 0.0465 0.0462 0.0459 

[TRAIN] Epoch[1](11401/114412); Loss: 0.069896; Backpropagation: 0.2907 sec; Batch: 2.1142 sec
0.1247 0.1148 0.0840 0.0795 0.0705 0.0669 0.0628 0.0613 0.0591 0.0581 0.0572 0.0569 0.0562 0.0555 0.0554 0.0552 

[TRAIN] Epoch[1](11402/114412); Loss: 0.058755; Backpropagation: 0.2912 sec; Batch: 2.0830 sec
0.0868 0.0835 0.0784 0.0718 0.0633 0.0574 0.0547 0.0528 0.0511 0.0500 0.0494 0.0487 0.0484 0.0481 0.0478 0.0477 

[TRAIN] Epoch[1](11403/114412); Loss: 0.083648; Backpropagation: 0.2930 sec; Batch: 2.1164 sec
0.1498 0.1350 0.1027 0.0923 0.0849 0.0804 0.0769 0.0744 0.0718 0.0702 0.0686 0.0677 0.0668 0.0661 0.0656 0.0652 

[TRAIN] Epoch[1](11404/114412); Loss: 0.047268; Backpropagation: 0.2930 sec; Batch: 2.1159 sec
0.0946 0.0929 0.0599 0.0555 0.0493 0.0453 0.0414 0.0392 0.0377 0.0362 0.0354 0.0345 0.0340 0.0338 0.0333 0.0331 

[TRAIN] Epoch[1](11405/114412); Loss: 0.080913; Backpropagation: 0.2911 sec; Batch: 2.1154 sec
0.1325 0.1259 0.0966 0.0862 0.0864 0.0809 0.0771 0.0733 0.0706 0.0691 0.0678 0.0671 0.0661 0.0655 0.0648 0.0646 

[TRAIN] Epoch[1](11406/114412); Loss: 0.061167; Backpropagation: 0.2911 sec; Batch: 2.1127 sec
0.1324 0.1316 0.0756 0.0621 0.0578 0.0550 0.0513 0.0496 0.0481 0.0469 0.0462 0.0452 0.0446 0.0443 0.0440 0.0440 

[TRAIN] Epoch[1](11407/114412); Loss: 0.066209; Backpropagation: 0.2916 sec; Batch: 2.1181 sec
0.1143 0.1082 0.0922 0.0767 0.0701 0.0640 0.0606 0.0579 0.0551 0.0537 0.0523 0.0517 0.0511 0.0508 0.0504 0.0502 

[TRAIN] Epoch[1](11408/114412); Loss: 0.082705; Backpropagation: 0.2928 sec; Batch: 2.1154 sec
0.1771 0.1566 0.1098 0.0924 0.0796 0.0755 0.0722 0.0685 0.0659 0.0632 0.0623 0.0612 0.0603 0.0599 0.0595 0.0594 

[TRAIN] Epoch[1](11409/114412); Loss: 0.093642; Backpropagation: 0.2929 sec; Batch: 2.1348 sec
0.1564 0.1470 0.1182 0.1084 0.0968 0.0909 0.0856 0.0830 0.0805 0.0791 0.0776 0.0763 0.0757 0.0748 0.0742 0.0736 

[TRAIN] Epoch[1](11410/114412); Loss: 0.063286; Backpropagation: 0.2911 sec; Batch: 2.1197 sec
0.1391 0.1258 0.0816 0.0678 0.0659 0.0583 0.0547 0.0511 0.0494 0.0478 0.0468 0.0458 0.0454 0.0447 0.0444 0.0440 

[TRAIN] Epoch[1](11411/114412); Loss: 0.069289; Backpropagation: 0.2928 sec; Batch: 2.1459 sec
0.1539 0.1438 0.0844 0.0749 0.0643 0.0613 0.0578 0.0558 0.0540 0.0528 0.0520 0.0518 0.0512 0.0507 0.0499 0.0497 

[TRAIN] Epoch[1](11412/114412); Loss: 0.072933; Backpropagation: 0.2911 sec; Batch: 2.1109 sec
0.1300 0.1138 0.0891 0.0818 0.0766 0.0719 0.0675 0.0646 0.0623 0.0608 0.0597 0.0589 0.0581 0.0577 0.0571 0.0569 

[TRAIN] Epoch[1](11413/114412); Loss: 0.057891; Backpropagation: 0.2920 sec; Batch: 2.1182 sec
0.1035 0.0949 0.0824 0.0701 0.0616 0.0575 0.0531 0.0502 0.0482 0.0463 0.0451 0.0440 0.0429 0.0425 0.0420 0.0418 

[TRAIN] Epoch[1](11414/114412); Loss: 0.107554; Backpropagation: 0.2913 sec; Batch: 2.1153 sec
0.1780 0.1723 0.1297 0.1213 0.1123 0.1088 0.1016 0.0977 0.0940 0.0911 0.0888 0.0869 0.0858 0.0848 0.0842 0.0837 

[TRAIN] Epoch[1](11415/114412); Loss: 0.076485; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1367 0.1136 0.0908 0.0831 0.0788 0.0752 0.0718 0.0684 0.0664 0.0649 0.0638 0.0632 0.0623 0.0619 0.0616 0.0613 

[TRAIN] Epoch[1](11416/114412); Loss: 0.085834; Backpropagation: 0.2914 sec; Batch: 2.1109 sec
0.1388 0.1261 0.1003 0.0953 0.0888 0.0856 0.0821 0.0786 0.0761 0.0744 0.0732 0.0724 0.0713 0.0706 0.0701 0.0696 

[TRAIN] Epoch[1](11417/114412); Loss: 0.053564; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1072 0.1019 0.0688 0.0638 0.0554 0.0508 0.0465 0.0445 0.0426 0.0411 0.0405 0.0399 0.0393 0.0386 0.0382 0.0380 

[TRAIN] Epoch[1](11418/114412); Loss: 0.067773; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1286 0.1263 0.0864 0.0749 0.0685 0.0625 0.0597 0.0568 0.0555 0.0542 0.0533 0.0524 0.0519 0.0513 0.0511 0.0509 

[TRAIN] Epoch[1](11419/114412); Loss: 0.066697; Backpropagation: 0.2904 sec; Batch: 2.1179 sec
0.1233 0.1176 0.0789 0.0705 0.0703 0.0644 0.0606 0.0577 0.0559 0.0545 0.0534 0.0526 0.0523 0.0521 0.0517 0.0512 

[TRAIN] Epoch[1](11420/114412); Loss: 0.070131; Backpropagation: 0.2914 sec; Batch: 2.1146 sec
0.1326 0.1204 0.0962 0.0817 0.0752 0.0687 0.0629 0.0599 0.0570 0.0550 0.0541 0.0531 0.0523 0.0514 0.0510 0.0506 

[TRAIN] Epoch[1](11421/114412); Loss: 0.076497; Backpropagation: 0.2912 sec; Batch: 2.0829 sec
0.1432 0.1323 0.0977 0.0885 0.0793 0.0736 0.0688 0.0661 0.0635 0.0617 0.0599 0.0591 0.0583 0.0577 0.0573 0.0569 

[TRAIN] Epoch[1](11422/114412); Loss: 0.065016; Backpropagation: 0.2917 sec; Batch: 2.0782 sec
0.1113 0.1032 0.0820 0.0817 0.0715 0.0668 0.0602 0.0578 0.0549 0.0531 0.0514 0.0505 0.0498 0.0491 0.0487 0.0484 

[TRAIN] Epoch[1](11423/114412); Loss: 0.050219; Backpropagation: 0.2913 sec; Batch: 2.1098 sec
0.1127 0.1029 0.0651 0.0560 0.0492 0.0442 0.0418 0.0399 0.0385 0.0374 0.0369 0.0364 0.0361 0.0356 0.0355 0.0354 

[TRAIN] Epoch[1](11424/114412); Loss: 0.076667; Backpropagation: 0.2911 sec; Batch: 2.1142 sec
0.1362 0.1259 0.0912 0.0834 0.0779 0.0738 0.0700 0.0677 0.0657 0.0643 0.0635 0.0625 0.0619 0.0613 0.0608 0.0605 

[TRAIN] Epoch[1](11425/114412); Loss: 0.063441; Backpropagation: 0.2913 sec; Batch: 2.1145 sec
0.1275 0.1209 0.0761 0.0697 0.0648 0.0601 0.0558 0.0535 0.0512 0.0501 0.0489 0.0482 0.0475 0.0471 0.0470 0.0467 

[TRAIN] Epoch[1](11426/114412); Loss: 0.065793; Backpropagation: 0.2918 sec; Batch: 2.1136 sec
0.1463 0.1311 0.0802 0.0705 0.0652 0.0605 0.0567 0.0537 0.0514 0.0499 0.0488 0.0483 0.0479 0.0476 0.0472 0.0473 

[TRAIN] Epoch[1](11427/114412); Loss: 0.088517; Backpropagation: 0.2932 sec; Batch: 2.1208 sec
0.1385 0.1290 0.1081 0.1000 0.0918 0.0877 0.0835 0.0810 0.0786 0.0769 0.0757 0.0745 0.0736 0.0731 0.0724 0.0720 

[TRAIN] Epoch[1](11428/114412); Loss: 0.048572; Backpropagation: 0.2953 sec; Batch: 2.1225 sec
0.0797 0.0843 0.0746 0.0628 0.0503 0.0455 0.0418 0.0403 0.0388 0.0380 0.0378 0.0372 0.0368 0.0365 0.0363 0.0363 

[TRAIN] Epoch[1](11429/114412); Loss: 0.088366; Backpropagation: 0.2955 sec; Batch: 2.1212 sec
0.1408 0.1307 0.1074 0.0991 0.0912 0.0870 0.0832 0.0810 0.0787 0.0768 0.0753 0.0742 0.0733 0.0725 0.0716 0.0710 

[TRAIN] Epoch[1](11430/114412); Loss: 0.086658; Backpropagation: 0.2904 sec; Batch: 2.1129 sec
0.1451 0.1394 0.1142 0.0994 0.0917 0.0848 0.0794 0.0760 0.0742 0.0719 0.0704 0.0694 0.0686 0.0677 0.0674 0.0668 

[TRAIN] Epoch[1](11431/114412); Loss: 0.072492; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1379 0.1244 0.0936 0.0817 0.0764 0.0688 0.0644 0.0621 0.0596 0.0580 0.0571 0.0564 0.0556 0.0552 0.0546 0.0543 

[TRAIN] Epoch[1](11432/114412); Loss: 0.069060; Backpropagation: 0.2911 sec; Batch: 2.1101 sec
0.1289 0.1206 0.0946 0.0818 0.0732 0.0655 0.0611 0.0583 0.0565 0.0546 0.0534 0.0523 0.0518 0.0513 0.0507 0.0504 

[TRAIN] Epoch[1](11433/114412); Loss: 0.094241; Backpropagation: 0.2912 sec; Batch: 2.1177 sec
0.2086 0.1930 0.1353 0.1095 0.0821 0.0781 0.0760 0.0742 0.0729 0.0706 0.0699 0.0687 0.0680 0.0673 0.0670 0.0669 

[TRAIN] Epoch[1](11434/114412); Loss: 0.080182; Backpropagation: 0.2914 sec; Batch: 2.1171 sec
0.1768 0.1637 0.1158 0.0914 0.0705 0.0668 0.0676 0.0658 0.0627 0.0605 0.0598 0.0577 0.0567 0.0562 0.0556 0.0551 

[TRAIN] Epoch[1](11435/114412); Loss: 0.052167; Backpropagation: 0.2908 sec; Batch: 2.1136 sec
0.1122 0.0876 0.0846 0.0679 0.0540 0.0493 0.0439 0.0415 0.0398 0.0381 0.0370 0.0366 0.0360 0.0358 0.0353 0.0352 

[TRAIN] Epoch[1](11436/114412); Loss: 0.083978; Backpropagation: 0.2907 sec; Batch: 2.1135 sec
0.1583 0.1474 0.0976 0.0916 0.0882 0.0791 0.0748 0.0716 0.0697 0.0685 0.0678 0.0671 0.0663 0.0658 0.0650 0.0647 

[TRAIN] Epoch[1](11437/114412); Loss: 0.078097; Backpropagation: 0.2917 sec; Batch: 2.1140 sec
0.1422 0.1281 0.1054 0.0913 0.0794 0.0737 0.0700 0.0680 0.0655 0.0637 0.0621 0.0613 0.0606 0.0599 0.0594 0.0588 

[TRAIN] Epoch[1](11438/114412); Loss: 0.068575; Backpropagation: 0.2953 sec; Batch: 2.0824 sec
0.1325 0.1186 0.0851 0.0758 0.0725 0.0653 0.0615 0.0589 0.0565 0.0552 0.0540 0.0532 0.0525 0.0522 0.0518 0.0515 

[TRAIN] Epoch[1](11439/114412); Loss: 0.053353; Backpropagation: 0.2953 sec; Batch: 2.1235 sec
0.0937 0.0868 0.0685 0.0607 0.0554 0.0522 0.0497 0.0474 0.0456 0.0438 0.0430 0.0424 0.0417 0.0412 0.0407 0.0407 

[TRAIN] Epoch[1](11440/114412); Loss: 0.081600; Backpropagation: 0.2904 sec; Batch: 2.1159 sec
0.1673 0.1627 0.1153 0.1020 0.0862 0.0766 0.0681 0.0638 0.0618 0.0602 0.0588 0.0579 0.0571 0.0564 0.0559 0.0555 

[TRAIN] Epoch[1](11441/114412); Loss: 0.074250; Backpropagation: 0.2913 sec; Batch: 2.1171 sec
0.1408 0.1326 0.0895 0.0805 0.0739 0.0698 0.0664 0.0641 0.0624 0.0606 0.0595 0.0586 0.0580 0.0575 0.0571 0.0566 

[TRAIN] Epoch[1](11442/114412); Loss: 0.082651; Backpropagation: 0.2912 sec; Batch: 2.1203 sec
0.1439 0.1309 0.0963 0.0924 0.0885 0.0810 0.0770 0.0732 0.0713 0.0698 0.0683 0.0674 0.0662 0.0658 0.0654 0.0650 

[TRAIN] Epoch[1](11443/114412); Loss: 0.078048; Backpropagation: 0.2909 sec; Batch: 2.1176 sec
0.1596 0.1487 0.0978 0.0851 0.0802 0.0723 0.0678 0.0646 0.0627 0.0608 0.0594 0.0587 0.0581 0.0578 0.0576 0.0575 

[TRAIN] Epoch[1](11444/114412); Loss: 0.065602; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1406 0.1148 0.0844 0.0753 0.0684 0.0622 0.0577 0.0550 0.0523 0.0510 0.0495 0.0487 0.0481 0.0476 0.0473 0.0469 

[TRAIN] Epoch[1](11445/114412); Loss: 0.054325; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1333 0.1272 0.0632 0.0538 0.0497 0.0466 0.0439 0.0418 0.0406 0.0398 0.0392 0.0386 0.0383 0.0380 0.0376 0.0375 

[TRAIN] Epoch[1](11446/114412); Loss: 0.082789; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.1388 0.1329 0.1052 0.0936 0.0840 0.0787 0.0750 0.0726 0.0708 0.0698 0.0687 0.0678 0.0673 0.0667 0.0664 0.0663 

[TRAIN] Epoch[1](11447/114412); Loss: 0.053325; Backpropagation: 0.2914 sec; Batch: 2.1166 sec
0.1027 0.0852 0.0720 0.0626 0.0554 0.0516 0.0483 0.0457 0.0438 0.0425 0.0416 0.0409 0.0407 0.0403 0.0401 0.0398 

[TRAIN] Epoch[1](11448/114412); Loss: 0.106222; Backpropagation: 0.2920 sec; Batch: 2.1196 sec
0.1639 0.1546 0.1278 0.1186 0.1111 0.1048 0.1009 0.0982 0.0960 0.0939 0.0922 0.0901 0.0888 0.0874 0.0860 0.0851 

[TRAIN] Epoch[1](11449/114412); Loss: 0.065289; Backpropagation: 0.2932 sec; Batch: 2.1313 sec
0.1482 0.1436 0.0925 0.0785 0.0639 0.0568 0.0527 0.0501 0.0477 0.0465 0.0455 0.0448 0.0442 0.0437 0.0431 0.0429 

[TRAIN] Epoch[1](11450/114412); Loss: 0.071435; Backpropagation: 0.2905 sec; Batch: 2.1219 sec
0.1146 0.1100 0.0990 0.0875 0.0800 0.0712 0.0671 0.0631 0.0609 0.0586 0.0576 0.0564 0.0553 0.0544 0.0540 0.0534 

[TRAIN] Epoch[1](11451/114412); Loss: 0.077856; Backpropagation: 0.2910 sec; Batch: 2.1346 sec
0.1530 0.1417 0.1077 0.0942 0.0825 0.0749 0.0689 0.0653 0.0622 0.0600 0.0585 0.0571 0.0561 0.0551 0.0546 0.0538 

[TRAIN] Epoch[1](11452/114412); Loss: 0.087271; Backpropagation: 0.2912 sec; Batch: 2.1212 sec
0.1456 0.1249 0.1001 0.0985 0.0899 0.0866 0.0823 0.0802 0.0776 0.0762 0.0744 0.0735 0.0724 0.0719 0.0713 0.0710 

[TRAIN] Epoch[1](11453/114412); Loss: 0.093708; Backpropagation: 0.2910 sec; Batch: 2.1174 sec
0.1662 0.1529 0.1202 0.1059 0.0905 0.0866 0.0831 0.0814 0.0799 0.0787 0.0779 0.0766 0.0757 0.0752 0.0745 0.0741 

[TRAIN] Epoch[1](11454/114412); Loss: 0.095589; Backpropagation: 0.2910 sec; Batch: 2.2882 sec
0.1426 0.1345 0.1118 0.1058 0.0988 0.0942 0.0909 0.0881 0.0862 0.0846 0.0836 0.0827 0.0822 0.0816 0.0812 0.0807 

[TRAIN] Epoch[1](11455/114412); Loss: 0.065203; Backpropagation: 0.2928 sec; Batch: 2.1200 sec
0.1175 0.1048 0.0813 0.0750 0.0680 0.0633 0.0600 0.0573 0.0557 0.0540 0.0529 0.0518 0.0512 0.0506 0.0501 0.0497 

[TRAIN] Epoch[1](11456/114412); Loss: 0.064491; Backpropagation: 0.2948 sec; Batch: 2.1211 sec
0.1215 0.1153 0.0880 0.0759 0.0676 0.0575 0.0562 0.0539 0.0520 0.0508 0.0499 0.0495 0.0489 0.0486 0.0483 0.0481 

[TRAIN] Epoch[1](11457/114412); Loss: 0.088425; Backpropagation: 0.2953 sec; Batch: 2.0811 sec
0.1959 0.1789 0.1236 0.1004 0.0869 0.0798 0.0742 0.0699 0.0675 0.0656 0.0643 0.0629 0.0621 0.0616 0.0608 0.0604 

[TRAIN] Epoch[1](11458/114412); Loss: 0.082179; Backpropagation: 0.2929 sec; Batch: 2.1220 sec
0.1419 0.1310 0.1074 0.0957 0.0863 0.0802 0.0754 0.0722 0.0696 0.0678 0.0666 0.0656 0.0647 0.0641 0.0635 0.0629 

[TRAIN] Epoch[1](11459/114412); Loss: 0.064470; Backpropagation: 0.2907 sec; Batch: 2.1194 sec
0.1201 0.1114 0.0829 0.0663 0.0666 0.0618 0.0585 0.0557 0.0541 0.0528 0.0517 0.0509 0.0502 0.0497 0.0496 0.0492 

[TRAIN] Epoch[1](11460/114412); Loss: 0.071173; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1174 0.1079 0.0942 0.0828 0.0758 0.0690 0.0654 0.0633 0.0615 0.0600 0.0586 0.0575 0.0570 0.0565 0.0561 0.0557 

[TRAIN] Epoch[1](11461/114412); Loss: 0.065696; Backpropagation: 0.2905 sec; Batch: 2.1205 sec
0.1217 0.1152 0.0853 0.0747 0.0659 0.0616 0.0574 0.0556 0.0542 0.0530 0.0524 0.0516 0.0511 0.0508 0.0504 0.0503 

[TRAIN] Epoch[1](11462/114412); Loss: 0.084184; Backpropagation: 0.2932 sec; Batch: 2.1207 sec
0.1300 0.1180 0.0995 0.0919 0.0873 0.0834 0.0800 0.0777 0.0753 0.0741 0.0732 0.0724 0.0718 0.0711 0.0708 0.0704 

[TRAIN] Epoch[1](11463/114412); Loss: 0.084905; Backpropagation: 0.2926 sec; Batch: 2.0795 sec
0.1755 0.1634 0.1139 0.0992 0.0841 0.0764 0.0714 0.0692 0.0667 0.0652 0.0642 0.0632 0.0625 0.0617 0.0612 0.0608 

[TRAIN] Epoch[1](11464/114412); Loss: 0.073454; Backpropagation: 0.2910 sec; Batch: 2.1162 sec
0.1674 0.1555 0.1082 0.0907 0.0723 0.0640 0.0598 0.0554 0.0540 0.0520 0.0510 0.0500 0.0493 0.0489 0.0486 0.0483 

[TRAIN] Epoch[1](11465/114412); Loss: 0.071380; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1343 0.1269 0.0827 0.0771 0.0697 0.0657 0.0629 0.0609 0.0596 0.0586 0.0583 0.0577 0.0573 0.0570 0.0567 0.0567 

[TRAIN] Epoch[1](11466/114412); Loss: 0.073249; Backpropagation: 0.2911 sec; Batch: 2.1136 sec
0.1471 0.1371 0.0924 0.0846 0.0742 0.0700 0.0641 0.0617 0.0591 0.0573 0.0559 0.0550 0.0542 0.0536 0.0531 0.0526 

[TRAIN] Epoch[1](11467/114412); Loss: 0.064670; Backpropagation: 0.2953 sec; Batch: 2.1213 sec
0.1386 0.1300 0.0851 0.0727 0.0670 0.0613 0.0569 0.0525 0.0502 0.0484 0.0472 0.0462 0.0454 0.0450 0.0443 0.0439 

[TRAIN] Epoch[1](11468/114412); Loss: 0.077678; Backpropagation: 0.2928 sec; Batch: 2.0871 sec
0.1385 0.1281 0.0955 0.0868 0.0803 0.0748 0.0716 0.0688 0.0665 0.0648 0.0632 0.0623 0.0613 0.0607 0.0600 0.0596 

[TRAIN] Epoch[1](11469/114412); Loss: 0.074119; Backpropagation: 0.2950 sec; Batch: 2.0814 sec
0.1247 0.1143 0.0914 0.0821 0.0760 0.0722 0.0684 0.0660 0.0640 0.0629 0.0619 0.0613 0.0606 0.0603 0.0599 0.0597 

[TRAIN] Epoch[1](11470/114412); Loss: 0.078738; Backpropagation: 0.2906 sec; Batch: 2.1151 sec
0.1403 0.1292 0.0987 0.0887 0.0814 0.0767 0.0721 0.0690 0.0666 0.0647 0.0635 0.0627 0.0621 0.0616 0.0614 0.0611 

[TRAIN] Epoch[1](11471/114412); Loss: 0.088423; Backpropagation: 0.2920 sec; Batch: 2.0788 sec
0.1792 0.1592 0.1094 0.0996 0.0880 0.0816 0.0785 0.0763 0.0733 0.0708 0.0694 0.0679 0.0668 0.0658 0.0650 0.0641 

[TRAIN] Epoch[1](11472/114412); Loss: 0.076426; Backpropagation: 0.2909 sec; Batch: 2.1137 sec
0.1465 0.1336 0.0939 0.0848 0.0765 0.0720 0.0682 0.0658 0.0637 0.0624 0.0610 0.0601 0.0594 0.0588 0.0583 0.0579 

[TRAIN] Epoch[1](11473/114412); Loss: 0.063942; Backpropagation: 0.2902 sec; Batch: 2.1120 sec
0.1442 0.1238 0.0844 0.0721 0.0644 0.0589 0.0552 0.0522 0.0497 0.0482 0.0469 0.0459 0.0451 0.0445 0.0440 0.0435 

[TRAIN] Epoch[1](11474/114412); Loss: 0.067582; Backpropagation: 0.2930 sec; Batch: 2.1170 sec
0.1268 0.1174 0.0826 0.0766 0.0694 0.0650 0.0619 0.0591 0.0566 0.0549 0.0538 0.0527 0.0519 0.0513 0.0508 0.0505 

[TRAIN] Epoch[1](11475/114412); Loss: 0.074911; Backpropagation: 0.2907 sec; Batch: 2.0782 sec
0.1428 0.1290 0.1022 0.0871 0.0770 0.0699 0.0662 0.0626 0.0610 0.0596 0.0586 0.0577 0.0569 0.0564 0.0559 0.0556 

[TRAIN] Epoch[1](11476/114412); Loss: 0.063807; Backpropagation: 0.2904 sec; Batch: 2.1130 sec
0.1335 0.1213 0.0763 0.0666 0.0604 0.0586 0.0563 0.0534 0.0519 0.0505 0.0495 0.0490 0.0487 0.0486 0.0482 0.0481 

[TRAIN] Epoch[1](11477/114412); Loss: 0.067918; Backpropagation: 0.2904 sec; Batch: 2.0991 sec
0.1186 0.1084 0.0834 0.0760 0.0691 0.0650 0.0632 0.0603 0.0588 0.0571 0.0561 0.0551 0.0544 0.0541 0.0536 0.0535 

[TRAIN] Epoch[1](11478/114412); Loss: 0.093365; Backpropagation: 0.2905 sec; Batch: 2.1220 sec
0.1833 0.1649 0.1226 0.1072 0.0961 0.0894 0.0830 0.0789 0.0769 0.0748 0.0726 0.0705 0.0695 0.0686 0.0681 0.0675 

[TRAIN] Epoch[1](11479/114412); Loss: 0.074767; Backpropagation: 0.2925 sec; Batch: 2.0796 sec
0.1410 0.1302 0.0995 0.0861 0.0762 0.0709 0.0663 0.0636 0.0616 0.0599 0.0587 0.0576 0.0571 0.0564 0.0558 0.0553 

[TRAIN] Epoch[1](11480/114412); Loss: 0.083739; Backpropagation: 0.2912 sec; Batch: 2.1208 sec
0.1451 0.1363 0.0979 0.0903 0.0829 0.0801 0.0761 0.0743 0.0725 0.0714 0.0700 0.0694 0.0688 0.0686 0.0681 0.0680 

[TRAIN] Epoch[1](11481/114412); Loss: 0.084699; Backpropagation: 0.2912 sec; Batch: 2.0785 sec
0.1482 0.1379 0.1042 0.0951 0.0851 0.0804 0.0774 0.0744 0.0727 0.0711 0.0699 0.0690 0.0682 0.0676 0.0672 0.0668 

[TRAIN] Epoch[1](11482/114412); Loss: 0.062136; Backpropagation: 0.2907 sec; Batch: 2.1156 sec
0.1429 0.1289 0.0840 0.0692 0.0577 0.0533 0.0510 0.0489 0.0471 0.0463 0.0453 0.0447 0.0441 0.0438 0.0436 0.0434 

[TRAIN] Epoch[1](11483/114412); Loss: 0.086291; Backpropagation: 0.2907 sec; Batch: 2.1169 sec
0.1303 0.1238 0.1023 0.0970 0.0901 0.0861 0.0821 0.0793 0.0774 0.0758 0.0745 0.0736 0.0728 0.0723 0.0718 0.0714 

[TRAIN] Epoch[1](11484/114412); Loss: 0.088400; Backpropagation: 0.2953 sec; Batch: 2.1226 sec
0.1672 0.1540 0.1199 0.0983 0.0870 0.0819 0.0783 0.0748 0.0727 0.0713 0.0701 0.0693 0.0683 0.0678 0.0669 0.0666 

[TRAIN] Epoch[1](11485/114412); Loss: 0.059738; Backpropagation: 0.2949 sec; Batch: 2.1007 sec
0.1246 0.1155 0.0680 0.0634 0.0589 0.0559 0.0517 0.0497 0.0479 0.0470 0.0463 0.0460 0.0456 0.0455 0.0450 0.0448 

[TRAIN] Epoch[1](11486/114412); Loss: 0.098108; Backpropagation: 0.2928 sec; Batch: 2.1227 sec
0.2053 0.1855 0.1292 0.1097 0.0981 0.0907 0.0848 0.0807 0.0776 0.0758 0.0744 0.0729 0.0721 0.0712 0.0709 0.0707 

[TRAIN] Epoch[1](11487/114412); Loss: 0.074833; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1402 0.1232 0.0870 0.0809 0.0753 0.0704 0.0668 0.0649 0.0637 0.0628 0.0618 0.0610 0.0603 0.0600 0.0597 0.0593 

[TRAIN] Epoch[1](11488/114412); Loss: 0.075684; Backpropagation: 0.2911 sec; Batch: 2.1211 sec
0.1268 0.1177 0.0959 0.0865 0.0790 0.0735 0.0695 0.0674 0.0653 0.0636 0.0627 0.0619 0.0610 0.0605 0.0601 0.0596 

[TRAIN] Epoch[1](11489/114412); Loss: 0.075093; Backpropagation: 0.2909 sec; Batch: 2.1214 sec
0.1602 0.1484 0.0990 0.0860 0.0714 0.0660 0.0617 0.0602 0.0586 0.0576 0.0569 0.0560 0.0554 0.0550 0.0547 0.0546 

[TRAIN] Epoch[1](11490/114412); Loss: 0.077831; Backpropagation: 0.2907 sec; Batch: 2.1173 sec
0.1265 0.1210 0.0899 0.0825 0.0804 0.0762 0.0738 0.0708 0.0693 0.0675 0.0663 0.0655 0.0647 0.0641 0.0636 0.0632 

[TRAIN] Epoch[1](11491/114412); Loss: 0.078727; Backpropagation: 0.2912 sec; Batch: 2.1181 sec
0.1651 0.1532 0.1079 0.0988 0.0850 0.0773 0.0688 0.0649 0.0606 0.0582 0.0562 0.0548 0.0535 0.0527 0.0517 0.0510 

[TRAIN] Epoch[1](11492/114412); Loss: 0.070571; Backpropagation: 0.2902 sec; Batch: 2.1172 sec
0.1599 0.1485 0.1020 0.0867 0.0678 0.0639 0.0588 0.0569 0.0535 0.0512 0.0490 0.0478 0.0469 0.0460 0.0454 0.0448 

[TRAIN] Epoch[1](11493/114412); Loss: 0.094158; Backpropagation: 0.2912 sec; Batch: 2.0792 sec
0.1749 0.1608 0.1206 0.1069 0.0886 0.0846 0.0810 0.0799 0.0785 0.0774 0.0771 0.0762 0.0757 0.0752 0.0748 0.0744 

[TRAIN] Epoch[1](11494/114412); Loss: 0.075352; Backpropagation: 0.2904 sec; Batch: 2.0777 sec
0.1513 0.1392 0.1026 0.0924 0.0802 0.0736 0.0671 0.0634 0.0597 0.0572 0.0558 0.0543 0.0535 0.0524 0.0517 0.0512 

[TRAIN] Epoch[1](11495/114412); Loss: 0.081633; Backpropagation: 0.2904 sec; Batch: 2.1190 sec
0.1693 0.1566 0.1053 0.0918 0.0786 0.0724 0.0682 0.0670 0.0652 0.0636 0.0628 0.0623 0.0614 0.0609 0.0606 0.0603 

[TRAIN] Epoch[1](11496/114412); Loss: 0.066539; Backpropagation: 0.2901 sec; Batch: 2.0766 sec
0.1361 0.1207 0.0917 0.0786 0.0689 0.0635 0.0599 0.0558 0.0528 0.0514 0.0491 0.0482 0.0478 0.0473 0.0466 0.0462 

[TRAIN] Epoch[1](11497/114412); Loss: 0.087622; Backpropagation: 0.2906 sec; Batch: 2.0834 sec
0.1660 0.1525 0.1063 0.0964 0.0872 0.0823 0.0783 0.0754 0.0734 0.0717 0.0707 0.0696 0.0688 0.0682 0.0678 0.0675 

[TRAIN] Epoch[1](11498/114412); Loss: 0.114272; Backpropagation: 0.2907 sec; Batch: 2.0782 sec
0.1857 0.1716 0.1491 0.1390 0.1274 0.1186 0.1108 0.1046 0.0989 0.0954 0.0919 0.0903 0.0882 0.0869 0.0854 0.0846 

[TRAIN] Epoch[1](11499/114412); Loss: 0.065526; Backpropagation: 0.2906 sec; Batch: 2.0788 sec
0.1420 0.1303 0.0862 0.0733 0.0663 0.0590 0.0555 0.0528 0.0509 0.0497 0.0488 0.0479 0.0473 0.0465 0.0462 0.0459 

[TRAIN] Epoch[1](11500/114412); Loss: 0.058290; Backpropagation: 0.2908 sec; Batch: 2.0779 sec
0.1026 0.0974 0.0751 0.0663 0.0598 0.0564 0.0530 0.0510 0.0491 0.0481 0.0469 0.0461 0.0457 0.0453 0.0451 0.0448 

[TRAIN] Epoch[1](11501/114412); Loss: 0.075403; Backpropagation: 0.2908 sec; Batch: 2.1074 sec
0.1491 0.1354 0.0912 0.0820 0.0742 0.0708 0.0669 0.0642 0.0622 0.0609 0.0598 0.0591 0.0585 0.0578 0.0573 0.0570 

[TRAIN] Epoch[1](11502/114412); Loss: 0.098375; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1855 0.1681 0.1315 0.1146 0.1028 0.0944 0.0884 0.0837 0.0816 0.0786 0.0769 0.0754 0.0743 0.0736 0.0726 0.0720 

[TRAIN] Epoch[1](11503/114412); Loss: 0.080900; Backpropagation: 0.2946 sec; Batch: 2.0811 sec
0.1367 0.1304 0.0966 0.0935 0.0836 0.0794 0.0743 0.0718 0.0692 0.0681 0.0666 0.0659 0.0651 0.0647 0.0643 0.0639 

[TRAIN] Epoch[1](11504/114412); Loss: 0.124230; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.2240 0.2155 0.1725 0.1527 0.1355 0.1244 0.1125 0.1072 0.1038 0.0990 0.0967 0.0933 0.0909 0.0886 0.0863 0.0847 

[TRAIN] Epoch[1](11505/114412); Loss: 0.085878; Backpropagation: 0.2905 sec; Batch: 2.1145 sec
0.1582 0.1465 0.1076 0.0995 0.0881 0.0819 0.0765 0.0735 0.0718 0.0698 0.0687 0.0678 0.0667 0.0662 0.0658 0.0655 

[TRAIN] Epoch[1](11506/114412); Loss: 0.071425; Backpropagation: 0.2908 sec; Batch: 2.1166 sec
0.1337 0.1224 0.0870 0.0785 0.0741 0.0697 0.0663 0.0622 0.0601 0.0582 0.0570 0.0559 0.0551 0.0546 0.0542 0.0538 

[TRAIN] Epoch[1](11507/114412); Loss: 0.066491; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1290 0.1142 0.0846 0.0780 0.0688 0.0643 0.0597 0.0572 0.0548 0.0531 0.0521 0.0510 0.0501 0.0495 0.0490 0.0487 

[TRAIN] Epoch[1](11508/114412); Loss: 0.069731; Backpropagation: 0.2911 sec; Batch: 2.1206 sec
0.1241 0.1139 0.0943 0.0837 0.0739 0.0684 0.0639 0.0603 0.0581 0.0563 0.0551 0.0541 0.0531 0.0526 0.0521 0.0517 

[TRAIN] Epoch[1](11509/114412); Loss: 0.082133; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.1756 0.1611 0.1143 0.0980 0.0844 0.0746 0.0695 0.0654 0.0634 0.0616 0.0599 0.0587 0.0579 0.0572 0.0566 0.0560 

[TRAIN] Epoch[1](11510/114412); Loss: 0.079127; Backpropagation: 0.2912 sec; Batch: 2.1261 sec
0.1507 0.1361 0.1008 0.0907 0.0803 0.0739 0.0703 0.0676 0.0654 0.0636 0.0627 0.0618 0.0612 0.0608 0.0603 0.0600 

[TRAIN] Epoch[1](11511/114412); Loss: 0.067253; Backpropagation: 0.2909 sec; Batch: 2.1130 sec
0.1549 0.1296 0.0962 0.0839 0.0689 0.0612 0.0548 0.0519 0.0497 0.0483 0.0475 0.0467 0.0462 0.0457 0.0455 0.0450 

[TRAIN] Epoch[1](11512/114412); Loss: 0.085952; Backpropagation: 0.2905 sec; Batch: 2.1175 sec
0.1412 0.1275 0.0998 0.0946 0.0872 0.0835 0.0801 0.0777 0.0764 0.0747 0.0735 0.0728 0.0722 0.0716 0.0714 0.0711 

[TRAIN] Epoch[1](11513/114412); Loss: 0.050163; Backpropagation: 0.2909 sec; Batch: 2.1129 sec
0.1436 0.1337 0.0661 0.0607 0.0457 0.0391 0.0359 0.0343 0.0333 0.0313 0.0307 0.0302 0.0297 0.0297 0.0294 0.0293 

[TRAIN] Epoch[1](11514/114412); Loss: 0.064411; Backpropagation: 0.2925 sec; Batch: 2.1120 sec
0.1392 0.1244 0.0894 0.0796 0.0677 0.0588 0.0542 0.0528 0.0498 0.0481 0.0468 0.0452 0.0444 0.0438 0.0434 0.0430 

[TRAIN] Epoch[1](11515/114412); Loss: 0.071775; Backpropagation: 0.2930 sec; Batch: 2.1206 sec
0.1516 0.1432 0.1033 0.0860 0.0678 0.0623 0.0588 0.0568 0.0550 0.0538 0.0530 0.0524 0.0517 0.0512 0.0509 0.0506 

[TRAIN] Epoch[1](11516/114412); Loss: 0.087770; Backpropagation: 0.2908 sec; Batch: 2.1125 sec
0.1701 0.1569 0.1061 0.0949 0.0852 0.0799 0.0777 0.0754 0.0731 0.0714 0.0709 0.0696 0.0691 0.0685 0.0680 0.0676 

[TRAIN] Epoch[1](11517/114412); Loss: 0.088576; Backpropagation: 0.2903 sec; Batch: 2.0772 sec
0.1785 0.1657 0.1159 0.1040 0.0919 0.0828 0.0769 0.0733 0.0706 0.0687 0.0670 0.0658 0.0650 0.0642 0.0636 0.0632 

[TRAIN] Epoch[1](11518/114412); Loss: 0.044349; Backpropagation: 0.2912 sec; Batch: 2.1153 sec
0.0782 0.0731 0.0632 0.0559 0.0477 0.0433 0.0393 0.0378 0.0361 0.0352 0.0343 0.0338 0.0333 0.0329 0.0327 0.0326 

[TRAIN] Epoch[1](11519/114412); Loss: 0.088173; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1560 0.1453 0.1065 0.0987 0.0893 0.0833 0.0791 0.0771 0.0752 0.0739 0.0727 0.0719 0.0712 0.0706 0.0702 0.0697 

[TRAIN] Epoch[1](11520/114412); Loss: 0.071210; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1451 0.1320 0.0958 0.0840 0.0729 0.0664 0.0616 0.0586 0.0562 0.0547 0.0536 0.0528 0.0520 0.0515 0.0512 0.0509 

[TRAIN] Epoch[1](11521/114412); Loss: 0.087274; Backpropagation: 0.2923 sec; Batch: 2.0882 sec
0.1430 0.1319 0.1016 0.0930 0.0887 0.0841 0.0811 0.0786 0.0770 0.0756 0.0750 0.0743 0.0737 0.0733 0.0729 0.0725 

[TRAIN] Epoch[1](11522/114412); Loss: 0.054514; Backpropagation: 0.2909 sec; Batch: 2.0956 sec
0.1199 0.1067 0.0777 0.0662 0.0544 0.0492 0.0461 0.0438 0.0421 0.0405 0.0393 0.0384 0.0376 0.0371 0.0367 0.0364 

[TRAIN] Epoch[1](11523/114412); Loss: 0.105622; Backpropagation: 0.2954 sec; Batch: 2.1231 sec
0.1734 0.1590 0.1285 0.1174 0.1075 0.1038 0.0995 0.0970 0.0936 0.0914 0.0889 0.0880 0.0869 0.0860 0.0849 0.0841 

[TRAIN] Epoch[1](11524/114412); Loss: 0.107339; Backpropagation: 0.2938 sec; Batch: 2.1185 sec
0.1689 0.1591 0.1357 0.1246 0.1165 0.1111 0.1035 0.0993 0.0946 0.0920 0.0892 0.0873 0.0856 0.0843 0.0833 0.0825 

[TRAIN] Epoch[1](11525/114412); Loss: 0.062243; Backpropagation: 0.2950 sec; Batch: 2.1229 sec
0.1219 0.1126 0.0855 0.0746 0.0672 0.0596 0.0558 0.0516 0.0494 0.0477 0.0464 0.0455 0.0450 0.0446 0.0443 0.0442 

[TRAIN] Epoch[1](11526/114412); Loss: 0.064567; Backpropagation: 0.2949 sec; Batch: 2.0820 sec
0.1577 0.1368 0.0925 0.0739 0.0626 0.0583 0.0535 0.0494 0.0475 0.0457 0.0443 0.0434 0.0424 0.0421 0.0417 0.0413 

[TRAIN] Epoch[1](11527/114412); Loss: 0.093730; Backpropagation: 0.2953 sec; Batch: 2.1161 sec
0.1514 0.1374 0.1205 0.1063 0.0966 0.0914 0.0883 0.0849 0.0826 0.0806 0.0790 0.0781 0.0768 0.0760 0.0752 0.0747 

[TRAIN] Epoch[1](11528/114412); Loss: 0.061543; Backpropagation: 0.2901 sec; Batch: 2.1127 sec
0.1420 0.1257 0.0875 0.0692 0.0608 0.0556 0.0507 0.0479 0.0463 0.0449 0.0437 0.0428 0.0422 0.0421 0.0417 0.0415 

[TRAIN] Epoch[1](11529/114412); Loss: 0.094142; Backpropagation: 0.2904 sec; Batch: 2.0767 sec
0.1518 0.1458 0.1171 0.1091 0.0985 0.0925 0.0886 0.0852 0.0824 0.0802 0.0786 0.0772 0.0761 0.0751 0.0744 0.0738 

[TRAIN] Epoch[1](11530/114412); Loss: 0.079289; Backpropagation: 0.2928 sec; Batch: 2.1163 sec
0.1421 0.1262 0.0934 0.0874 0.0799 0.0765 0.0726 0.0699 0.0682 0.0666 0.0656 0.0650 0.0642 0.0640 0.0636 0.0634 

[TRAIN] Epoch[1](11531/114412); Loss: 0.079966; Backpropagation: 0.2927 sec; Batch: 2.1152 sec
0.1435 0.1308 0.1007 0.0927 0.0837 0.0789 0.0740 0.0708 0.0681 0.0659 0.0643 0.0628 0.0619 0.0611 0.0604 0.0599 

[TRAIN] Epoch[1](11532/114412); Loss: 0.072378; Backpropagation: 0.2926 sec; Batch: 2.0965 sec
0.1445 0.1355 0.0901 0.0790 0.0743 0.0679 0.0638 0.0607 0.0585 0.0570 0.0560 0.0550 0.0546 0.0540 0.0538 0.0534 

[TRAIN] Epoch[1](11533/114412); Loss: 0.070913; Backpropagation: 0.2953 sec; Batch: 2.1206 sec
0.1454 0.1390 0.0930 0.0816 0.0721 0.0643 0.0612 0.0577 0.0561 0.0544 0.0532 0.0524 0.0517 0.0512 0.0509 0.0504 

[TRAIN] Epoch[1](11534/114412); Loss: 0.076831; Backpropagation: 0.2950 sec; Batch: 2.1219 sec
0.1304 0.1185 0.0991 0.0885 0.0787 0.0748 0.0715 0.0685 0.0660 0.0645 0.0632 0.0622 0.0616 0.0610 0.0606 0.0603 

[TRAIN] Epoch[1](11535/114412); Loss: 0.116056; Backpropagation: 0.2927 sec; Batch: 2.1185 sec
0.2340 0.2157 0.1654 0.1426 0.1171 0.1064 0.0985 0.0941 0.0911 0.0883 0.0865 0.0853 0.0841 0.0833 0.0825 0.0819 

[TRAIN] Epoch[1](11536/114412); Loss: 0.076456; Backpropagation: 0.2943 sec; Batch: 2.1198 sec
0.1108 0.1042 0.0984 0.0911 0.0828 0.0765 0.0719 0.0697 0.0672 0.0662 0.0653 0.0646 0.0642 0.0639 0.0634 0.0631 

[TRAIN] Epoch[1](11537/114412); Loss: 0.081189; Backpropagation: 0.2947 sec; Batch: 2.1287 sec
0.1300 0.1186 0.0996 0.0910 0.0843 0.0793 0.0764 0.0734 0.0715 0.0702 0.0690 0.0681 0.0676 0.0670 0.0667 0.0664 

[TRAIN] Epoch[1](11538/114412); Loss: 0.082665; Backpropagation: 0.2951 sec; Batch: 2.0908 sec
0.1289 0.1222 0.0978 0.0910 0.0839 0.0812 0.0777 0.0755 0.0735 0.0722 0.0713 0.0704 0.0700 0.0693 0.0690 0.0687 

[TRAIN] Epoch[1](11539/114412); Loss: 0.082989; Backpropagation: 0.2942 sec; Batch: 2.0806 sec
0.1869 0.1772 0.1223 0.1024 0.0770 0.0678 0.0642 0.0627 0.0615 0.0601 0.0590 0.0583 0.0577 0.0573 0.0569 0.0567 

[TRAIN] Epoch[1](11540/114412); Loss: 0.081447; Backpropagation: 0.2908 sec; Batch: 2.1172 sec
0.1388 0.1329 0.1097 0.0991 0.0849 0.0805 0.0752 0.0718 0.0687 0.0667 0.0649 0.0637 0.0626 0.0617 0.0613 0.0609 

[TRAIN] Epoch[1](11541/114412); Loss: 0.066671; Backpropagation: 0.2922 sec; Batch: 2.1157 sec
0.1399 0.1281 0.0869 0.0766 0.0677 0.0614 0.0575 0.0551 0.0527 0.0512 0.0500 0.0491 0.0484 0.0479 0.0474 0.0469 

[TRAIN] Epoch[1](11542/114412); Loss: 0.060939; Backpropagation: 0.2904 sec; Batch: 2.1183 sec
0.1183 0.1066 0.0781 0.0675 0.0612 0.0569 0.0533 0.0518 0.0498 0.0490 0.0479 0.0475 0.0471 0.0468 0.0466 0.0465 

[TRAIN] Epoch[1](11543/114412); Loss: 0.062841; Backpropagation: 0.2906 sec; Batch: 2.1169 sec
0.1228 0.1123 0.0798 0.0690 0.0634 0.0600 0.0565 0.0537 0.0517 0.0509 0.0495 0.0485 0.0474 0.0471 0.0466 0.0461 

[TRAIN] Epoch[1](11544/114412); Loss: 0.067165; Backpropagation: 0.2909 sec; Batch: 2.1152 sec
0.1593 0.1520 0.0966 0.0814 0.0668 0.0594 0.0554 0.0515 0.0492 0.0469 0.0448 0.0437 0.0427 0.0421 0.0415 0.0410 

[TRAIN] Epoch[1](11545/114412); Loss: 0.075133; Backpropagation: 0.2910 sec; Batch: 2.1177 sec
0.1464 0.1371 0.1022 0.0919 0.0815 0.0748 0.0695 0.0644 0.0612 0.0578 0.0556 0.0539 0.0527 0.0517 0.0510 0.0503 

[TRAIN] Epoch[1](11546/114412); Loss: 0.077290; Backpropagation: 0.2908 sec; Batch: 2.1169 sec
0.1414 0.1360 0.1006 0.0921 0.0803 0.0727 0.0687 0.0652 0.0627 0.0614 0.0605 0.0596 0.0592 0.0588 0.0587 0.0587 

[TRAIN] Epoch[1](11547/114412); Loss: 0.075671; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.1258 0.1103 0.0937 0.0857 0.0795 0.0745 0.0699 0.0680 0.0657 0.0644 0.0634 0.0628 0.0622 0.0620 0.0615 0.0614 

[TRAIN] Epoch[1](11548/114412); Loss: 0.055323; Backpropagation: 0.2910 sec; Batch: 2.1054 sec
0.1072 0.1005 0.0696 0.0628 0.0557 0.0533 0.0490 0.0469 0.0450 0.0439 0.0431 0.0426 0.0420 0.0415 0.0412 0.0410 

[TRAIN] Epoch[1](11549/114412); Loss: 0.059281; Backpropagation: 0.2910 sec; Batch: 2.1214 sec
0.1250 0.1179 0.0697 0.0634 0.0577 0.0539 0.0507 0.0489 0.0473 0.0462 0.0455 0.0452 0.0448 0.0443 0.0441 0.0438 

[TRAIN] Epoch[1](11550/114412); Loss: 0.081396; Backpropagation: 0.2908 sec; Batch: 2.1165 sec
0.1437 0.1363 0.0973 0.0889 0.0838 0.0800 0.0745 0.0715 0.0692 0.0676 0.0665 0.0655 0.0649 0.0645 0.0643 0.0639 

[TRAIN] Epoch[1](11551/114412); Loss: 0.054767; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1077 0.0988 0.0797 0.0678 0.0579 0.0522 0.0479 0.0450 0.0430 0.0414 0.0405 0.0398 0.0394 0.0388 0.0384 0.0381 

[TRAIN] Epoch[1](11552/114412); Loss: 0.074972; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1767 0.1582 0.1103 0.0864 0.0719 0.0647 0.0602 0.0573 0.0550 0.0534 0.0524 0.0515 0.0510 0.0505 0.0501 0.0498 

[TRAIN] Epoch[1](11553/114412); Loss: 0.073818; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1509 0.1427 0.1020 0.0929 0.0787 0.0731 0.0654 0.0619 0.0576 0.0548 0.0529 0.0513 0.0503 0.0496 0.0488 0.0482 

[TRAIN] Epoch[1](11554/114412); Loss: 0.073025; Backpropagation: 0.2914 sec; Batch: 2.1176 sec
0.1485 0.1293 0.0975 0.0821 0.0758 0.0696 0.0661 0.0626 0.0595 0.0573 0.0557 0.0543 0.0535 0.0528 0.0521 0.0517 

[TRAIN] Epoch[1](11555/114412); Loss: 0.067443; Backpropagation: 0.2952 sec; Batch: 2.1343 sec
0.1432 0.1339 0.0923 0.0775 0.0674 0.0616 0.0579 0.0546 0.0526 0.0507 0.0496 0.0488 0.0479 0.0475 0.0470 0.0467 

[TRAIN] Epoch[1](11556/114412); Loss: 0.076671; Backpropagation: 0.2908 sec; Batch: 2.1327 sec
0.1714 0.1636 0.1103 0.0921 0.0762 0.0669 0.0622 0.0590 0.0560 0.0545 0.0533 0.0528 0.0523 0.0523 0.0520 0.0520 

[TRAIN] Epoch[1](11557/114412); Loss: 0.085687; Backpropagation: 0.2912 sec; Batch: 2.1075 sec
0.1565 0.1433 0.1128 0.1021 0.0864 0.0811 0.0770 0.0748 0.0718 0.0701 0.0686 0.0672 0.0662 0.0651 0.0643 0.0638 

[TRAIN] Epoch[1](11558/114412); Loss: 0.070982; Backpropagation: 0.2926 sec; Batch: 2.0788 sec
0.1448 0.1357 0.0965 0.0839 0.0732 0.0675 0.0608 0.0574 0.0551 0.0541 0.0530 0.0521 0.0512 0.0506 0.0500 0.0498 

[TRAIN] Epoch[1](11559/114412); Loss: 0.078580; Backpropagation: 0.2915 sec; Batch: 2.1034 sec
0.1421 0.1310 0.1034 0.0913 0.0827 0.0773 0.0722 0.0687 0.0655 0.0640 0.0623 0.0608 0.0596 0.0592 0.0586 0.0585 

[TRAIN] Epoch[1](11560/114412); Loss: 0.083828; Backpropagation: 0.2905 sec; Batch: 2.1178 sec
0.1532 0.1416 0.1059 0.0942 0.0871 0.0805 0.0756 0.0736 0.0707 0.0693 0.0675 0.0663 0.0651 0.0643 0.0635 0.0630 

[TRAIN] Epoch[1](11561/114412); Loss: 0.081946; Backpropagation: 0.2895 sec; Batch: 2.0761 sec
0.1225 0.1170 0.1001 0.0916 0.0845 0.0811 0.0773 0.0750 0.0729 0.0716 0.0707 0.0702 0.0696 0.0693 0.0690 0.0688 

[TRAIN] Epoch[1](11562/114412); Loss: 0.061214; Backpropagation: 0.2910 sec; Batch: 2.1062 sec
0.1179 0.1084 0.0902 0.0804 0.0626 0.0566 0.0525 0.0506 0.0481 0.0464 0.0458 0.0447 0.0442 0.0438 0.0436 0.0436 

[TRAIN] Epoch[1](11563/114412); Loss: 0.065310; Backpropagation: 0.2911 sec; Batch: 2.1152 sec
0.1292 0.1181 0.0846 0.0737 0.0669 0.0593 0.0567 0.0545 0.0530 0.0517 0.0512 0.0504 0.0496 0.0490 0.0487 0.0484 

[TRAIN] Epoch[1](11564/114412); Loss: 0.070032; Backpropagation: 0.2927 sec; Batch: 2.0787 sec
0.1188 0.1138 0.0911 0.0810 0.0719 0.0671 0.0631 0.0607 0.0592 0.0582 0.0574 0.0566 0.0560 0.0555 0.0552 0.0550 

[TRAIN] Epoch[1](11565/114412); Loss: 0.086714; Backpropagation: 0.2956 sec; Batch: 2.0828 sec
0.1571 0.1449 0.1059 0.0959 0.0864 0.0821 0.0779 0.0764 0.0737 0.0723 0.0710 0.0700 0.0693 0.0686 0.0681 0.0677 

[TRAIN] Epoch[1](11566/114412); Loss: 0.083899; Backpropagation: 0.2928 sec; Batch: 2.1474 sec
0.1535 0.1388 0.1012 0.0918 0.0838 0.0794 0.0759 0.0730 0.0709 0.0696 0.0688 0.0678 0.0673 0.0671 0.0669 0.0665 

[TRAIN] Epoch[1](11567/114412); Loss: 0.064720; Backpropagation: 0.2929 sec; Batch: 2.1179 sec
0.1276 0.1157 0.0939 0.0787 0.0674 0.0596 0.0556 0.0531 0.0512 0.0498 0.0489 0.0479 0.0471 0.0466 0.0463 0.0459 

[TRAIN] Epoch[1](11568/114412); Loss: 0.093649; Backpropagation: 0.2912 sec; Batch: 2.1194 sec
0.1814 0.1657 0.1097 0.0996 0.0936 0.0882 0.0830 0.0802 0.0780 0.0767 0.0755 0.0747 0.0737 0.0731 0.0729 0.0726 

[TRAIN] Epoch[1](11569/114412); Loss: 0.062615; Backpropagation: 0.2906 sec; Batch: 2.1126 sec
0.1509 0.1485 0.0793 0.0637 0.0584 0.0556 0.0509 0.0481 0.0464 0.0449 0.0437 0.0431 0.0425 0.0422 0.0419 0.0418 

[TRAIN] Epoch[1](11570/114412); Loss: 0.079568; Backpropagation: 0.2910 sec; Batch: 2.1179 sec
0.1581 0.1361 0.1024 0.0870 0.0810 0.0771 0.0710 0.0684 0.0656 0.0640 0.0625 0.0616 0.0605 0.0598 0.0593 0.0588 

[TRAIN] Epoch[1](11571/114412); Loss: 0.090147; Backpropagation: 0.2909 sec; Batch: 2.1146 sec
0.1580 0.1475 0.1061 0.0977 0.0896 0.0848 0.0818 0.0797 0.0776 0.0764 0.0754 0.0746 0.0739 0.0735 0.0730 0.0727 

[TRAIN] Epoch[1](11572/114412); Loss: 0.063391; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1088 0.1067 0.0826 0.0734 0.0642 0.0619 0.0577 0.0557 0.0535 0.0522 0.0510 0.0503 0.0496 0.0493 0.0489 0.0487 

[TRAIN] Epoch[1](11573/114412); Loss: 0.122910; Backpropagation: 0.2910 sec; Batch: 2.1223 sec
0.1754 0.1726 0.1305 0.1243 0.1202 0.1181 0.1161 0.1147 0.1137 0.1128 0.1123 0.1118 0.1115 0.1112 0.1107 0.1106 

[TRAIN] Epoch[1](11574/114412); Loss: 0.075035; Backpropagation: 0.2911 sec; Batch: 2.1206 sec
0.1430 0.1353 0.0968 0.0858 0.0788 0.0734 0.0674 0.0635 0.0610 0.0593 0.0581 0.0571 0.0561 0.0555 0.0549 0.0545 

[TRAIN] Epoch[1](11575/114412); Loss: 0.087668; Backpropagation: 0.2928 sec; Batch: 2.1161 sec
0.1626 0.1474 0.1141 0.1068 0.0935 0.0836 0.0793 0.0742 0.0717 0.0705 0.0688 0.0677 0.0667 0.0656 0.0655 0.0649 

[TRAIN] Epoch[1](11576/114412); Loss: 0.076328; Backpropagation: 0.2924 sec; Batch: 2.1173 sec
0.1357 0.1340 0.1022 0.0959 0.0810 0.0764 0.0704 0.0661 0.0639 0.0608 0.0597 0.0574 0.0563 0.0546 0.0536 0.0532 

[TRAIN] Epoch[1](11577/114412); Loss: 0.060884; Backpropagation: 0.2954 sec; Batch: 2.1210 sec
0.1263 0.1100 0.0874 0.0735 0.0641 0.0578 0.0520 0.0500 0.0472 0.0459 0.0446 0.0438 0.0433 0.0429 0.0429 0.0426 

[TRAIN] Epoch[1](11578/114412); Loss: 0.076212; Backpropagation: 0.2927 sec; Batch: 2.1177 sec
0.1457 0.1375 0.0996 0.0874 0.0762 0.0723 0.0668 0.0653 0.0625 0.0608 0.0594 0.0585 0.0577 0.0571 0.0565 0.0561 

[TRAIN] Epoch[1](11579/114412); Loss: 0.072432; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1138 0.1108 0.0930 0.0795 0.0739 0.0714 0.0684 0.0652 0.0631 0.0621 0.0610 0.0604 0.0596 0.0593 0.0589 0.0587 

[TRAIN] Epoch[1](11580/114412); Loss: 0.057372; Backpropagation: 0.2907 sec; Batch: 2.1258 sec
0.1320 0.1244 0.0777 0.0669 0.0568 0.0510 0.0477 0.0450 0.0432 0.0416 0.0403 0.0393 0.0386 0.0381 0.0378 0.0375 

[TRAIN] Epoch[1](11581/114412); Loss: 0.088135; Backpropagation: 0.2908 sec; Batch: 2.1132 sec
0.1499 0.1412 0.1076 0.0985 0.0896 0.0849 0.0812 0.0788 0.0763 0.0747 0.0732 0.0723 0.0714 0.0707 0.0701 0.0699 

[TRAIN] Epoch[1](11582/114412); Loss: 0.047877; Backpropagation: 0.2953 sec; Batch: 2.0810 sec
0.1093 0.0933 0.0664 0.0524 0.0467 0.0440 0.0420 0.0397 0.0376 0.0356 0.0348 0.0337 0.0332 0.0328 0.0324 0.0322 

[TRAIN] Epoch[1](11583/114412); Loss: 0.088972; Backpropagation: 0.2912 sec; Batch: 2.1148 sec
0.1593 0.1457 0.1105 0.1006 0.0919 0.0874 0.0817 0.0790 0.0762 0.0738 0.0721 0.0706 0.0699 0.0688 0.0683 0.0678 

[TRAIN] Epoch[1](11584/114412); Loss: 0.084912; Backpropagation: 0.2910 sec; Batch: 2.0775 sec
0.1490 0.1418 0.1107 0.1020 0.0886 0.0821 0.0769 0.0739 0.0710 0.0694 0.0678 0.0666 0.0657 0.0649 0.0643 0.0639 

[TRAIN] Epoch[1](11585/114412); Loss: 0.060785; Backpropagation: 0.2913 sec; Batch: 2.0780 sec
0.1190 0.1034 0.0696 0.0686 0.0659 0.0628 0.0559 0.0534 0.0494 0.0484 0.0470 0.0466 0.0460 0.0457 0.0456 0.0452 

[TRAIN] Epoch[1](11586/114412); Loss: 0.092427; Backpropagation: 0.2913 sec; Batch: 2.1235 sec
0.1443 0.1370 0.1101 0.0985 0.0989 0.0926 0.0888 0.0850 0.0827 0.0804 0.0790 0.0777 0.0770 0.0761 0.0756 0.0750 

[TRAIN] Epoch[1](11587/114412); Loss: 0.103667; Backpropagation: 0.2912 sec; Batch: 2.1199 sec
0.1707 0.1630 0.1249 0.1101 0.1034 0.0983 0.0950 0.0927 0.0912 0.0899 0.0884 0.0875 0.0868 0.0861 0.0856 0.0852 

[TRAIN] Epoch[1](11588/114412); Loss: 0.071472; Backpropagation: 0.2901 sec; Batch: 2.0752 sec
0.1384 0.1273 0.0946 0.0853 0.0740 0.0675 0.0629 0.0600 0.0579 0.0561 0.0550 0.0540 0.0532 0.0529 0.0523 0.0520 

[TRAIN] Epoch[1](11589/114412); Loss: 0.104129; Backpropagation: 0.2905 sec; Batch: 2.1131 sec
0.1757 0.1622 0.1346 0.1187 0.1072 0.0992 0.0951 0.0934 0.0900 0.0883 0.0863 0.0856 0.0837 0.0833 0.0818 0.0810 

[TRAIN] Epoch[1](11590/114412); Loss: 0.070101; Backpropagation: 0.2908 sec; Batch: 2.0821 sec
0.1406 0.1342 0.0896 0.0773 0.0703 0.0665 0.0611 0.0586 0.0567 0.0549 0.0539 0.0528 0.0520 0.0513 0.0510 0.0507 

[TRAIN] Epoch[1](11591/114412); Loss: 0.095087; Backpropagation: 0.2911 sec; Batch: 2.1222 sec
0.1681 0.1651 0.1220 0.1115 0.0938 0.0875 0.0846 0.0821 0.0792 0.0778 0.0765 0.0758 0.0750 0.0745 0.0741 0.0738 

[TRAIN] Epoch[1](11592/114412); Loss: 0.069904; Backpropagation: 0.2906 sec; Batch: 2.0753 sec
0.1345 0.1228 0.0954 0.0851 0.0717 0.0668 0.0612 0.0588 0.0563 0.0546 0.0533 0.0525 0.0519 0.0517 0.0510 0.0509 

[TRAIN] Epoch[1](11593/114412); Loss: 0.084188; Backpropagation: 0.2904 sec; Batch: 2.0770 sec
0.1658 0.1591 0.1264 0.1106 0.0941 0.0793 0.0757 0.0727 0.0696 0.0632 0.0604 0.0562 0.0549 0.0542 0.0528 0.0520 

[TRAIN] Epoch[1](11594/114412); Loss: 0.092526; Backpropagation: 0.2912 sec; Batch: 2.1174 sec
0.1905 0.1767 0.1290 0.1114 0.0936 0.0857 0.0799 0.0767 0.0728 0.0701 0.0685 0.0669 0.0658 0.0650 0.0642 0.0636 

[TRAIN] Epoch[1](11595/114412); Loss: 0.080553; Backpropagation: 0.2930 sec; Batch: 2.1200 sec
0.1493 0.1329 0.0985 0.0911 0.0839 0.0782 0.0738 0.0699 0.0674 0.0657 0.0647 0.0637 0.0632 0.0627 0.0620 0.0618 

[TRAIN] Epoch[1](11596/114412); Loss: 0.088489; Backpropagation: 0.2911 sec; Batch: 2.1143 sec
0.1530 0.1426 0.1060 0.0975 0.0907 0.0869 0.0819 0.0791 0.0764 0.0747 0.0734 0.0721 0.0714 0.0706 0.0700 0.0697 

[TRAIN] Epoch[1](11597/114412); Loss: 0.063286; Backpropagation: 0.2950 sec; Batch: 2.1187 sec
0.1037 0.0933 0.0864 0.0751 0.0657 0.0621 0.0578 0.0559 0.0542 0.0528 0.0520 0.0512 0.0509 0.0506 0.0505 0.0505 

[TRAIN] Epoch[1](11598/114412); Loss: 0.076212; Backpropagation: 0.2953 sec; Batch: 2.1232 sec
0.1465 0.1379 0.1069 0.0926 0.0812 0.0743 0.0682 0.0646 0.0608 0.0589 0.0568 0.0555 0.0546 0.0540 0.0536 0.0532 

[TRAIN] Epoch[1](11599/114412); Loss: 0.099087; Backpropagation: 0.2929 sec; Batch: 2.1164 sec
0.2267 0.2123 0.1497 0.1274 0.0951 0.0826 0.0766 0.0732 0.0713 0.0697 0.0687 0.0677 0.0669 0.0663 0.0656 0.0654 

[TRAIN] Epoch[1](11600/114412); Loss: 0.073659; Backpropagation: 0.2927 sec; Batch: 2.1212 sec
0.1109 0.1039 0.0926 0.0870 0.0792 0.0741 0.0702 0.0671 0.0654 0.0635 0.0625 0.0615 0.0610 0.0602 0.0598 0.0595 

[TRAIN] Epoch[1](11601/114412); Loss: 0.108922; Backpropagation: 0.2907 sec; Batch: 2.1121 sec
0.1652 0.1547 0.1273 0.1192 0.1100 0.1075 0.1031 0.1006 0.0978 0.0965 0.0951 0.0942 0.0935 0.0931 0.0927 0.0923 

[TRAIN] Epoch[1](11602/114412); Loss: 0.074987; Backpropagation: 0.2944 sec; Batch: 2.1186 sec
0.1306 0.1206 0.0925 0.0834 0.0762 0.0720 0.0676 0.0661 0.0637 0.0627 0.0618 0.0612 0.0608 0.0604 0.0603 0.0600 

[TRAIN] Epoch[1](11603/114412); Loss: 0.090800; Backpropagation: 0.2925 sec; Batch: 2.1244 sec
0.1541 0.1451 0.1147 0.1072 0.0962 0.0885 0.0835 0.0806 0.0779 0.0758 0.0738 0.0726 0.0717 0.0710 0.0702 0.0697 

[TRAIN] Epoch[1](11604/114412); Loss: 0.054796; Backpropagation: 0.2910 sec; Batch: 2.1166 sec
0.1141 0.1065 0.0664 0.0584 0.0557 0.0496 0.0469 0.0460 0.0443 0.0433 0.0422 0.0414 0.0407 0.0405 0.0405 0.0405 

[TRAIN] Epoch[1](11605/114412); Loss: 0.076525; Backpropagation: 0.2909 sec; Batch: 2.1143 sec
0.1592 0.1445 0.1049 0.0857 0.0743 0.0708 0.0678 0.0648 0.0625 0.0596 0.0577 0.0562 0.0551 0.0543 0.0537 0.0533 

[TRAIN] Epoch[1](11606/114412); Loss: 0.081895; Backpropagation: 0.2909 sec; Batch: 2.1177 sec
0.1689 0.1504 0.1069 0.0904 0.0848 0.0764 0.0740 0.0691 0.0663 0.0640 0.0620 0.0610 0.0600 0.0593 0.0587 0.0582 

[TRAIN] Epoch[1](11607/114412); Loss: 0.074992; Backpropagation: 0.2905 sec; Batch: 2.0930 sec
0.1246 0.1152 0.0885 0.0847 0.0795 0.0749 0.0698 0.0676 0.0651 0.0638 0.0627 0.0618 0.0611 0.0606 0.0602 0.0600 

[TRAIN] Epoch[1](11608/114412); Loss: 0.076575; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.1419 0.1381 0.1019 0.0878 0.0730 0.0697 0.0717 0.0682 0.0661 0.0629 0.0616 0.0589 0.0578 0.0557 0.0555 0.0543 

[TRAIN] Epoch[1](11609/114412); Loss: 0.075885; Backpropagation: 0.2904 sec; Batch: 2.0764 sec
0.1616 0.1458 0.1057 0.0907 0.0742 0.0702 0.0651 0.0615 0.0600 0.0574 0.0566 0.0548 0.0539 0.0529 0.0520 0.0519 

[TRAIN] Epoch[1](11610/114412); Loss: 0.088772; Backpropagation: 0.2910 sec; Batch: 2.1156 sec
0.1766 0.1547 0.1239 0.1040 0.0930 0.0853 0.0796 0.0768 0.0727 0.0702 0.0675 0.0659 0.0640 0.0629 0.0620 0.0612 

[TRAIN] Epoch[1](11611/114412); Loss: 0.087959; Backpropagation: 0.2929 sec; Batch: 2.1190 sec
0.1140 0.1145 0.1061 0.1007 0.0915 0.0873 0.0845 0.0819 0.0804 0.0795 0.0790 0.0782 0.0778 0.0774 0.0773 0.0772 

[TRAIN] Epoch[1](11612/114412); Loss: 0.060546; Backpropagation: 0.2917 sec; Batch: 2.1176 sec
0.1417 0.1319 0.0782 0.0657 0.0602 0.0545 0.0508 0.0475 0.0456 0.0439 0.0429 0.0420 0.0415 0.0411 0.0407 0.0405 

[TRAIN] Epoch[1](11613/114412); Loss: 0.090870; Backpropagation: 0.2910 sec; Batch: 2.1205 sec
0.1444 0.1323 0.1129 0.1022 0.0938 0.0903 0.0857 0.0821 0.0799 0.0787 0.0773 0.0764 0.0754 0.0748 0.0741 0.0737 

[TRAIN] Epoch[1](11614/114412); Loss: 0.085228; Backpropagation: 0.2950 sec; Batch: 2.0827 sec
0.1633 0.1522 0.1174 0.1026 0.0899 0.0797 0.0754 0.0719 0.0692 0.0669 0.0655 0.0637 0.0626 0.0617 0.0613 0.0605 

[TRAIN] Epoch[1](11615/114412); Loss: 0.081648; Backpropagation: 0.2928 sec; Batch: 2.1181 sec
0.1658 0.1481 0.1017 0.0926 0.0829 0.0771 0.0725 0.0690 0.0664 0.0645 0.0630 0.0617 0.0611 0.0606 0.0600 0.0595 

[TRAIN] Epoch[1](11616/114412); Loss: 0.068442; Backpropagation: 0.2931 sec; Batch: 2.0794 sec
0.1416 0.1305 0.0930 0.0815 0.0710 0.0644 0.0599 0.0563 0.0537 0.0520 0.0507 0.0494 0.0485 0.0478 0.0475 0.0473 

[TRAIN] Epoch[1](11617/114412); Loss: 0.067667; Backpropagation: 0.2929 sec; Batch: 2.1196 sec
0.1330 0.1319 0.0977 0.0883 0.0718 0.0626 0.0588 0.0555 0.0533 0.0500 0.0493 0.0476 0.0466 0.0458 0.0454 0.0451 

[TRAIN] Epoch[1](11618/114412); Loss: 0.062497; Backpropagation: 0.2951 sec; Batch: 2.1235 sec
0.1121 0.1025 0.0904 0.0722 0.0647 0.0595 0.0568 0.0537 0.0523 0.0508 0.0495 0.0486 0.0475 0.0469 0.0465 0.0461 

[TRAIN] Epoch[1](11619/114412); Loss: 0.066921; Backpropagation: 0.2947 sec; Batch: 2.1214 sec
0.1347 0.1267 0.0795 0.0753 0.0651 0.0617 0.0583 0.0558 0.0548 0.0542 0.0525 0.0518 0.0506 0.0502 0.0499 0.0497 

[TRAIN] Epoch[1](11620/114412); Loss: 0.070829; Backpropagation: 0.2929 sec; Batch: 2.1085 sec
0.1366 0.1234 0.0935 0.0850 0.0729 0.0671 0.0613 0.0593 0.0576 0.0563 0.0552 0.0540 0.0533 0.0529 0.0526 0.0522 

[TRAIN] Epoch[1](11621/114412); Loss: 0.066287; Backpropagation: 0.2927 sec; Batch: 2.0790 sec
0.1236 0.1140 0.0889 0.0781 0.0682 0.0645 0.0604 0.0568 0.0545 0.0530 0.0517 0.0507 0.0500 0.0492 0.0487 0.0483 

[TRAIN] Epoch[1](11622/114412); Loss: 0.090006; Backpropagation: 0.2903 sec; Batch: 2.1120 sec
0.1368 0.1326 0.1078 0.1010 0.0939 0.0895 0.0855 0.0823 0.0804 0.0786 0.0774 0.0764 0.0754 0.0747 0.0741 0.0738 

[TRAIN] Epoch[1](11623/114412); Loss: 0.068857; Backpropagation: 0.2906 sec; Batch: 2.0769 sec
0.1168 0.1045 0.0839 0.0793 0.0706 0.0678 0.0645 0.0623 0.0604 0.0583 0.0573 0.0561 0.0555 0.0552 0.0547 0.0544 

[TRAIN] Epoch[1](11624/114412); Loss: 0.103271; Backpropagation: 0.2941 sec; Batch: 2.1193 sec
0.1709 0.1581 0.1271 0.1183 0.1074 0.1021 0.0963 0.0928 0.0897 0.0879 0.0860 0.0848 0.0837 0.0830 0.0824 0.0818 

[TRAIN] Epoch[1](11625/114412); Loss: 0.064922; Backpropagation: 0.2931 sec; Batch: 2.0966 sec
0.1074 0.1015 0.0849 0.0719 0.0665 0.0632 0.0603 0.0580 0.0564 0.0548 0.0540 0.0532 0.0522 0.0517 0.0516 0.0513 

[TRAIN] Epoch[1](11626/114412); Loss: 0.061169; Backpropagation: 0.2910 sec; Batch: 2.0847 sec
0.1398 0.1266 0.0931 0.0799 0.0637 0.0558 0.0502 0.0470 0.0445 0.0429 0.0413 0.0403 0.0393 0.0387 0.0380 0.0377 

[TRAIN] Epoch[1](11627/114412); Loss: 0.089133; Backpropagation: 0.2912 sec; Batch: 2.1167 sec
0.1869 0.1722 0.1236 0.1127 0.0908 0.0800 0.0736 0.0711 0.0683 0.0665 0.0657 0.0645 0.0636 0.0628 0.0621 0.0617 

[TRAIN] Epoch[1](11628/114412); Loss: 0.105841; Backpropagation: 0.2895 sec; Batch: 2.1109 sec
0.1711 0.1605 0.1252 0.1179 0.1045 0.1014 0.0974 0.0949 0.0935 0.0921 0.0908 0.0902 0.0893 0.0888 0.0881 0.0878 

[TRAIN] Epoch[1](11629/114412); Loss: 0.059540; Backpropagation: 0.2903 sec; Batch: 2.1019 sec
0.1268 0.1071 0.0779 0.0711 0.0619 0.0551 0.0519 0.0490 0.0474 0.0459 0.0449 0.0437 0.0431 0.0424 0.0421 0.0421 

[TRAIN] Epoch[1](11630/114412); Loss: 0.067414; Backpropagation: 0.2905 sec; Batch: 2.1276 sec
0.1236 0.1114 0.0897 0.0807 0.0738 0.0677 0.0619 0.0584 0.0555 0.0539 0.0524 0.0513 0.0503 0.0498 0.0493 0.0488 

[TRAIN] Epoch[1](11631/114412); Loss: 0.078699; Backpropagation: 0.2954 sec; Batch: 2.0830 sec
0.1417 0.1254 0.0997 0.0927 0.0835 0.0776 0.0720 0.0687 0.0663 0.0647 0.0632 0.0622 0.0613 0.0606 0.0600 0.0595 

[TRAIN] Epoch[1](11632/114412); Loss: 0.085525; Backpropagation: 0.2923 sec; Batch: 2.0799 sec
0.1790 0.1695 0.1326 0.1110 0.0891 0.0777 0.0719 0.0667 0.0640 0.0614 0.0600 0.0585 0.0577 0.0568 0.0564 0.0560 

[TRAIN] Epoch[1](11633/114412); Loss: 0.061348; Backpropagation: 0.2911 sec; Batch: 2.1107 sec
0.1390 0.1202 0.0942 0.0745 0.0664 0.0592 0.0535 0.0484 0.0460 0.0431 0.0422 0.0404 0.0399 0.0388 0.0382 0.0377 

[TRAIN] Epoch[1](11634/114412); Loss: 0.096826; Backpropagation: 0.2911 sec; Batch: 2.0788 sec
0.1665 0.1557 0.1189 0.1138 0.1005 0.0931 0.0887 0.0853 0.0831 0.0811 0.0795 0.0782 0.0772 0.0764 0.0758 0.0753 

[TRAIN] Epoch[1](11635/114412); Loss: 0.061317; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1111 0.0999 0.0790 0.0750 0.0667 0.0613 0.0566 0.0531 0.0508 0.0495 0.0483 0.0474 0.0466 0.0458 0.0452 0.0449 

[TRAIN] Epoch[1](11636/114412); Loss: 0.062837; Backpropagation: 0.2912 sec; Batch: 2.1215 sec
0.1395 0.1324 0.0857 0.0711 0.0611 0.0562 0.0524 0.0498 0.0482 0.0466 0.0454 0.0448 0.0437 0.0431 0.0429 0.0425 

[TRAIN] Epoch[1](11637/114412); Loss: 0.093034; Backpropagation: 0.2905 sec; Batch: 2.1200 sec
0.1902 0.1774 0.1371 0.1151 0.0972 0.0851 0.0802 0.0761 0.0730 0.0703 0.0679 0.0664 0.0649 0.0635 0.0624 0.0619 

[TRAIN] Epoch[1](11638/114412); Loss: 0.086962; Backpropagation: 0.2912 sec; Batch: 2.0778 sec
0.1447 0.1333 0.1113 0.1011 0.0900 0.0845 0.0800 0.0777 0.0755 0.0734 0.0722 0.0710 0.0702 0.0694 0.0687 0.0683 

[TRAIN] Epoch[1](11639/114412); Loss: 0.074189; Backpropagation: 0.2932 sec; Batch: 2.1232 sec
0.1429 0.1271 0.1074 0.0921 0.0811 0.0730 0.0667 0.0609 0.0579 0.0565 0.0555 0.0544 0.0535 0.0530 0.0526 0.0524 

[TRAIN] Epoch[1](11640/114412); Loss: 0.055712; Backpropagation: 0.2918 sec; Batch: 2.1162 sec
0.1077 0.1020 0.0791 0.0630 0.0574 0.0534 0.0500 0.0467 0.0448 0.0434 0.0419 0.0415 0.0408 0.0405 0.0398 0.0395 

[TRAIN] Epoch[1](11641/114412); Loss: 0.047480; Backpropagation: 0.2954 sec; Batch: 2.1213 sec
0.1029 0.0813 0.0635 0.0561 0.0480 0.0439 0.0415 0.0391 0.0377 0.0366 0.0357 0.0354 0.0348 0.0345 0.0345 0.0343 

[TRAIN] Epoch[1](11642/114412); Loss: 0.081705; Backpropagation: 0.2950 sec; Batch: 2.1005 sec
0.1228 0.1133 0.1026 0.0939 0.0852 0.0797 0.0766 0.0744 0.0730 0.0715 0.0707 0.0698 0.0693 0.0686 0.0681 0.0679 

[TRAIN] Epoch[1](11643/114412); Loss: 0.085746; Backpropagation: 0.2902 sec; Batch: 2.1159 sec
0.1550 0.1430 0.1150 0.1010 0.0900 0.0836 0.0780 0.0748 0.0717 0.0692 0.0676 0.0662 0.0653 0.0646 0.0637 0.0633 

[TRAIN] Epoch[1](11644/114412); Loss: 0.072682; Backpropagation: 0.2914 sec; Batch: 2.1157 sec
0.1535 0.1453 0.0980 0.0731 0.0718 0.0658 0.0677 0.0619 0.0587 0.0550 0.0537 0.0524 0.0522 0.0517 0.0512 0.0509 

[TRAIN] Epoch[1](11645/114412); Loss: 0.079334; Backpropagation: 0.2943 sec; Batch: 2.1180 sec
0.1371 0.1276 0.1033 0.0908 0.0833 0.0753 0.0711 0.0694 0.0675 0.0660 0.0646 0.0639 0.0630 0.0626 0.0620 0.0619 

[TRAIN] Epoch[1](11646/114412); Loss: 0.071664; Backpropagation: 0.2952 sec; Batch: 2.1246 sec
0.1284 0.1205 0.0882 0.0780 0.0716 0.0675 0.0651 0.0630 0.0613 0.0595 0.0587 0.0578 0.0574 0.0568 0.0564 0.0563 

[TRAIN] Epoch[1](11647/114412); Loss: 0.068320; Backpropagation: 0.2937 sec; Batch: 2.1195 sec
0.1213 0.1152 0.0901 0.0759 0.0695 0.0652 0.0614 0.0594 0.0576 0.0560 0.0551 0.0544 0.0536 0.0532 0.0528 0.0525 

[TRAIN] Epoch[1](11648/114412); Loss: 0.060237; Backpropagation: 0.2905 sec; Batch: 2.1007 sec
0.1254 0.1164 0.0838 0.0710 0.0580 0.0555 0.0542 0.0503 0.0483 0.0455 0.0446 0.0434 0.0428 0.0420 0.0416 0.0411 

[TRAIN] Epoch[1](11649/114412); Loss: 0.087763; Backpropagation: 0.2909 sec; Batch: 2.1203 sec
0.1618 0.1517 0.1134 0.1015 0.0907 0.0826 0.0781 0.0748 0.0730 0.0711 0.0700 0.0686 0.0678 0.0669 0.0664 0.0657 

[TRAIN] Epoch[1](11650/114412); Loss: 0.073637; Backpropagation: 0.2905 sec; Batch: 2.0754 sec
0.1123 0.1085 0.0895 0.0799 0.0751 0.0723 0.0689 0.0676 0.0655 0.0643 0.0634 0.0630 0.0625 0.0621 0.0618 0.0615 

[TRAIN] Epoch[1](11651/114412); Loss: 0.063130; Backpropagation: 0.2910 sec; Batch: 2.0811 sec
0.1094 0.1062 0.0825 0.0721 0.0675 0.0623 0.0590 0.0554 0.0534 0.0514 0.0504 0.0493 0.0486 0.0480 0.0475 0.0470 

[TRAIN] Epoch[1](11652/114412); Loss: 0.066245; Backpropagation: 0.2905 sec; Batch: 2.0767 sec
0.1255 0.1194 0.0795 0.0710 0.0686 0.0645 0.0614 0.0581 0.0556 0.0537 0.0522 0.0511 0.0502 0.0499 0.0497 0.0496 

[TRAIN] Epoch[1](11653/114412); Loss: 0.060585; Backpropagation: 0.2914 sec; Batch: 2.0938 sec
0.1089 0.1012 0.0770 0.0679 0.0618 0.0578 0.0549 0.0525 0.0510 0.0497 0.0490 0.0486 0.0480 0.0475 0.0471 0.0466 

[TRAIN] Epoch[1](11654/114412); Loss: 0.053513; Backpropagation: 0.2994 sec; Batch: 2.1343 sec
0.0964 0.0941 0.0785 0.0646 0.0569 0.0506 0.0470 0.0433 0.0423 0.0417 0.0410 0.0407 0.0401 0.0398 0.0397 0.0396 

[TRAIN] Epoch[1](11655/114412); Loss: 0.073896; Backpropagation: 0.2908 sec; Batch: 2.0782 sec
0.1242 0.1180 0.0938 0.0828 0.0757 0.0715 0.0672 0.0653 0.0635 0.0623 0.0613 0.0604 0.0598 0.0593 0.0588 0.0585 

[TRAIN] Epoch[1](11656/114412); Loss: 0.070862; Backpropagation: 0.2908 sec; Batch: 2.1226 sec
0.1514 0.1364 0.0998 0.0830 0.0731 0.0657 0.0615 0.0571 0.0547 0.0529 0.0517 0.0507 0.0499 0.0491 0.0487 0.0482 

[TRAIN] Epoch[1](11657/114412); Loss: 0.078737; Backpropagation: 0.2929 sec; Batch: 2.1176 sec
0.1409 0.1297 0.1056 0.0947 0.0808 0.0741 0.0694 0.0671 0.0658 0.0637 0.0629 0.0619 0.0612 0.0610 0.0605 0.0604 

[TRAIN] Epoch[1](11658/114412); Loss: 0.092725; Backpropagation: 0.2966 sec; Batch: 2.1245 sec
0.1733 0.1639 0.1167 0.0987 0.0915 0.0862 0.0822 0.0791 0.0775 0.0757 0.0749 0.0738 0.0734 0.0727 0.0722 0.0717 

[TRAIN] Epoch[1](11659/114412); Loss: 0.071387; Backpropagation: 0.2905 sec; Batch: 2.1126 sec
0.1410 0.1314 0.1004 0.0796 0.0751 0.0679 0.0644 0.0596 0.0573 0.0550 0.0537 0.0528 0.0516 0.0513 0.0506 0.0505 

[TRAIN] Epoch[1](11660/114412); Loss: 0.064522; Backpropagation: 0.2952 sec; Batch: 2.1207 sec
0.1500 0.1387 0.0978 0.0824 0.0624 0.0542 0.0521 0.0491 0.0473 0.0454 0.0441 0.0429 0.0422 0.0417 0.0412 0.0410 

[TRAIN] Epoch[1](11661/114412); Loss: 0.069465; Backpropagation: 0.2953 sec; Batch: 2.1247 sec
0.1347 0.1255 0.0920 0.0823 0.0743 0.0686 0.0633 0.0599 0.0565 0.0542 0.0523 0.0511 0.0502 0.0495 0.0488 0.0481 

[TRAIN] Epoch[1](11662/114412); Loss: 0.066582; Backpropagation: 0.2913 sec; Batch: 2.0774 sec
0.1303 0.1195 0.0831 0.0723 0.0696 0.0645 0.0601 0.0569 0.0544 0.0531 0.0517 0.0508 0.0501 0.0498 0.0496 0.0494 

[TRAIN] Epoch[1](11663/114412); Loss: 0.099497; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.1743 0.1610 0.1287 0.1183 0.1064 0.0992 0.0922 0.0878 0.0845 0.0815 0.0793 0.0778 0.0768 0.0757 0.0746 0.0738 

[TRAIN] Epoch[1](11664/114412); Loss: 0.073980; Backpropagation: 0.2911 sec; Batch: 2.1185 sec
0.1635 0.1433 0.1091 0.0894 0.0768 0.0675 0.0627 0.0592 0.0566 0.0543 0.0527 0.0514 0.0502 0.0493 0.0491 0.0486 

[TRAIN] Epoch[1](11665/114412); Loss: 0.067785; Backpropagation: 0.2922 sec; Batch: 2.1224 sec
0.1452 0.1297 0.0974 0.0852 0.0707 0.0637 0.0573 0.0536 0.0510 0.0494 0.0484 0.0478 0.0469 0.0466 0.0460 0.0456 

[TRAIN] Epoch[1](11666/114412); Loss: 0.072148; Backpropagation: 0.2913 sec; Batch: 2.0767 sec
0.1335 0.1168 0.0920 0.0799 0.0715 0.0684 0.0653 0.0627 0.0606 0.0593 0.0587 0.0579 0.0572 0.0570 0.0569 0.0567 

[TRAIN] Epoch[1](11667/114412); Loss: 0.096650; Backpropagation: 0.2911 sec; Batch: 2.1172 sec
0.1815 0.1748 0.1277 0.1139 0.0936 0.0875 0.0839 0.0809 0.0794 0.0774 0.0758 0.0749 0.0743 0.0742 0.0734 0.0732 

[TRAIN] Epoch[1](11668/114412); Loss: 0.084176; Backpropagation: 0.2914 sec; Batch: 2.0791 sec
0.1288 0.1213 0.1011 0.0938 0.0886 0.0835 0.0798 0.0771 0.0749 0.0733 0.0722 0.0715 0.0710 0.0705 0.0699 0.0695 

[TRAIN] Epoch[1](11669/114412); Loss: 0.065800; Backpropagation: 0.2910 sec; Batch: 2.0774 sec
0.1279 0.1187 0.0884 0.0756 0.0674 0.0627 0.0592 0.0558 0.0535 0.0517 0.0504 0.0494 0.0489 0.0481 0.0477 0.0474 

[TRAIN] Epoch[1](11670/114412); Loss: 0.067257; Backpropagation: 0.2931 sec; Batch: 2.1235 sec
0.1290 0.1154 0.0870 0.0777 0.0706 0.0644 0.0601 0.0570 0.0550 0.0535 0.0526 0.0518 0.0512 0.0506 0.0504 0.0499 

[TRAIN] Epoch[1](11671/114412); Loss: 0.076776; Backpropagation: 0.2910 sec; Batch: 2.1303 sec
0.1361 0.1248 0.0911 0.0833 0.0772 0.0739 0.0694 0.0671 0.0655 0.0644 0.0636 0.0630 0.0625 0.0623 0.0622 0.0622 

[TRAIN] Epoch[1](11672/114412); Loss: 0.087743; Backpropagation: 0.2925 sec; Batch: 2.1155 sec
0.1436 0.1373 0.1086 0.0985 0.0897 0.0844 0.0814 0.0778 0.0760 0.0744 0.0737 0.0729 0.0720 0.0716 0.0712 0.0709 

[TRAIN] Epoch[1](11673/114412); Loss: 0.061360; Backpropagation: 0.2912 sec; Batch: 2.1190 sec
0.1439 0.1328 0.0841 0.0764 0.0602 0.0535 0.0501 0.0470 0.0450 0.0434 0.0422 0.0415 0.0410 0.0405 0.0401 0.0399 

[TRAIN] Epoch[1](11674/114412); Loss: 0.083241; Backpropagation: 0.2911 sec; Batch: 2.1151 sec
0.1587 0.1495 0.1130 0.1014 0.0883 0.0812 0.0749 0.0710 0.0675 0.0654 0.0629 0.0615 0.0603 0.0594 0.0585 0.0580 

[TRAIN] Epoch[1](11675/114412); Loss: 0.052621; Backpropagation: 0.2909 sec; Batch: 2.1188 sec
0.1277 0.1132 0.0733 0.0609 0.0518 0.0466 0.0428 0.0406 0.0386 0.0372 0.0362 0.0355 0.0349 0.0344 0.0342 0.0341 

[TRAIN] Epoch[1](11676/114412); Loss: 0.074358; Backpropagation: 0.2908 sec; Batch: 2.1244 sec
0.1294 0.1227 0.0985 0.0871 0.0758 0.0710 0.0666 0.0639 0.0619 0.0609 0.0599 0.0595 0.0588 0.0583 0.0579 0.0576 

[TRAIN] Epoch[1](11677/114412); Loss: 0.091820; Backpropagation: 0.2911 sec; Batch: 2.1141 sec
0.1517 0.1436 0.1176 0.1087 0.0962 0.0900 0.0849 0.0814 0.0788 0.0770 0.0756 0.0743 0.0733 0.0725 0.0719 0.0716 

[TRAIN] Epoch[1](11678/114412); Loss: 0.077964; Backpropagation: 0.2907 sec; Batch: 2.0774 sec
0.1658 0.1499 0.1005 0.0875 0.0771 0.0723 0.0685 0.0653 0.0621 0.0597 0.0583 0.0573 0.0565 0.0559 0.0556 0.0551 

[TRAIN] Epoch[1](11679/114412); Loss: 0.068290; Backpropagation: 0.2913 sec; Batch: 2.1133 sec
0.1223 0.1142 0.0846 0.0732 0.0717 0.0673 0.0645 0.0601 0.0595 0.0567 0.0553 0.0539 0.0530 0.0526 0.0520 0.0518 

[TRAIN] Epoch[1](11680/114412); Loss: 0.070162; Backpropagation: 0.2927 sec; Batch: 2.1170 sec
0.1386 0.1285 0.0809 0.0749 0.0665 0.0646 0.0614 0.0590 0.0581 0.0571 0.0566 0.0563 0.0554 0.0552 0.0549 0.0546 

[TRAIN] Epoch[1](11681/114412); Loss: 0.123799; Backpropagation: 0.2928 sec; Batch: 2.1172 sec
0.1945 0.1924 0.1601 0.1423 0.1364 0.1314 0.1232 0.1191 0.1114 0.1089 0.1011 0.1000 0.0938 0.0902 0.0888 0.0873 

[TRAIN] Epoch[1](11682/114412); Loss: 0.060898; Backpropagation: 0.2907 sec; Batch: 2.1167 sec
0.1350 0.1274 0.0797 0.0667 0.0639 0.0556 0.0535 0.0497 0.0467 0.0448 0.0434 0.0435 0.0421 0.0413 0.0406 0.0402 

[TRAIN] Epoch[1](11683/114412); Loss: 0.076444; Backpropagation: 0.2909 sec; Batch: 2.1049 sec
0.1509 0.1324 0.1039 0.0900 0.0788 0.0746 0.0690 0.0641 0.0609 0.0593 0.0580 0.0572 0.0565 0.0561 0.0558 0.0556 

[TRAIN] Epoch[1](11684/114412); Loss: 0.057858; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1274 0.1192 0.0801 0.0656 0.0587 0.0526 0.0482 0.0450 0.0436 0.0425 0.0417 0.0413 0.0405 0.0401 0.0398 0.0395 

[TRAIN] Epoch[1](11685/114412); Loss: 0.083704; Backpropagation: 0.2908 sec; Batch: 2.0770 sec
0.1434 0.1345 0.1105 0.0947 0.0888 0.0813 0.0778 0.0737 0.0706 0.0692 0.0679 0.0669 0.0659 0.0653 0.0646 0.0643 

[TRAIN] Epoch[1](11686/114412); Loss: 0.081536; Backpropagation: 0.2904 sec; Batch: 2.1134 sec
0.1481 0.1385 0.1025 0.0970 0.0875 0.0813 0.0748 0.0708 0.0676 0.0654 0.0637 0.0626 0.0620 0.0614 0.0608 0.0605 

[TRAIN] Epoch[1](11687/114412); Loss: 0.085495; Backpropagation: 0.2907 sec; Batch: 2.0774 sec
0.1726 0.1685 0.1342 0.1167 0.0981 0.0861 0.0808 0.0683 0.0647 0.0578 0.0555 0.0540 0.0538 0.0528 0.0525 0.0516 

[TRAIN] Epoch[1](11688/114412); Loss: 0.086927; Backpropagation: 0.2910 sec; Batch: 2.0833 sec
0.1395 0.1295 0.1071 0.0968 0.0877 0.0838 0.0816 0.0785 0.0770 0.0751 0.0741 0.0733 0.0724 0.0719 0.0714 0.0711 

[TRAIN] Epoch[1](11689/114412); Loss: 0.052314; Backpropagation: 0.2908 sec; Batch: 2.0969 sec
0.0897 0.0842 0.0725 0.0618 0.0544 0.0516 0.0476 0.0455 0.0435 0.0426 0.0420 0.0410 0.0405 0.0402 0.0399 0.0399 

[TRAIN] Epoch[1](11690/114412); Loss: 0.062314; Backpropagation: 0.2911 sec; Batch: 2.0781 sec
0.1468 0.1352 0.0827 0.0678 0.0624 0.0565 0.0514 0.0485 0.0467 0.0448 0.0442 0.0432 0.0424 0.0419 0.0414 0.0410 

[TRAIN] Epoch[1](11691/114412); Loss: 0.067452; Backpropagation: 0.2907 sec; Batch: 2.0904 sec
0.1223 0.1108 0.0857 0.0774 0.0693 0.0635 0.0600 0.0580 0.0566 0.0551 0.0546 0.0538 0.0534 0.0532 0.0528 0.0528 

[TRAIN] Epoch[1](11692/114412); Loss: 0.074217; Backpropagation: 0.2952 sec; Batch: 2.1253 sec
0.1352 0.1167 0.0888 0.0809 0.0766 0.0733 0.0695 0.0663 0.0636 0.0618 0.0606 0.0598 0.0591 0.0588 0.0585 0.0580 

[TRAIN] Epoch[1](11693/114412); Loss: 0.067215; Backpropagation: 0.2929 sec; Batch: 2.1241 sec
0.1286 0.1171 0.0871 0.0745 0.0673 0.0643 0.0597 0.0573 0.0556 0.0539 0.0529 0.0521 0.0519 0.0513 0.0511 0.0507 

[TRAIN] Epoch[1](11694/114412); Loss: 0.079101; Backpropagation: 0.2910 sec; Batch: 2.1147 sec
0.1348 0.1225 0.0970 0.0871 0.0811 0.0749 0.0726 0.0702 0.0684 0.0673 0.0665 0.0656 0.0651 0.0646 0.0642 0.0638 

[TRAIN] Epoch[1](11695/114412); Loss: 0.093667; Backpropagation: 0.2910 sec; Batch: 2.1198 sec
0.1418 0.1333 0.1112 0.1046 0.0989 0.0947 0.0901 0.0865 0.0843 0.0823 0.0808 0.0797 0.0785 0.0779 0.0772 0.0768 

[TRAIN] Epoch[1](11696/114412); Loss: 0.077423; Backpropagation: 0.2951 sec; Batch: 2.1220 sec
0.1370 0.1268 0.1051 0.0909 0.0779 0.0718 0.0686 0.0666 0.0644 0.0631 0.0626 0.0615 0.0612 0.0608 0.0603 0.0601 

[TRAIN] Epoch[1](11697/114412); Loss: 0.057083; Backpropagation: 0.2918 sec; Batch: 2.1201 sec
0.1159 0.1060 0.0740 0.0642 0.0591 0.0542 0.0511 0.0485 0.0465 0.0446 0.0433 0.0422 0.0414 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](11698/114412); Loss: 0.070379; Backpropagation: 0.2915 sec; Batch: 2.1145 sec
0.1302 0.1241 0.0906 0.0824 0.0711 0.0663 0.0628 0.0600 0.0580 0.0565 0.0556 0.0548 0.0543 0.0537 0.0531 0.0525 

[TRAIN] Epoch[1](11699/114412); Loss: 0.111216; Backpropagation: 0.2953 sec; Batch: 2.1283 sec
0.1703 0.1596 0.1317 0.1218 0.1147 0.1099 0.1059 0.1032 0.1007 0.0988 0.0967 0.0956 0.0939 0.0929 0.0923 0.0915 

[TRAIN] Epoch[1](11700/114412); Loss: 0.077742; Backpropagation: 0.2925 sec; Batch: 2.1169 sec
0.1420 0.1320 0.1027 0.0926 0.0817 0.0763 0.0702 0.0668 0.0639 0.0622 0.0608 0.0598 0.0591 0.0583 0.0579 0.0575 

[TRAIN] Epoch[1](11701/114412); Loss: 0.072860; Backpropagation: 0.2926 sec; Batch: 2.1157 sec
0.1439 0.1337 0.0920 0.0806 0.0769 0.0712 0.0662 0.0616 0.0592 0.0571 0.0558 0.0547 0.0539 0.0533 0.0529 0.0526 

[TRAIN] Epoch[1](11702/114412); Loss: 0.082415; Backpropagation: 0.2951 sec; Batch: 2.1116 sec
0.1513 0.1404 0.1078 0.1007 0.0894 0.0813 0.0750 0.0707 0.0679 0.0656 0.0640 0.0627 0.0616 0.0608 0.0600 0.0595 

[TRAIN] Epoch[1](11703/114412); Loss: 0.083040; Backpropagation: 0.2926 sec; Batch: 2.1139 sec
0.1448 0.1395 0.1026 0.0956 0.0854 0.0808 0.0765 0.0726 0.0705 0.0686 0.0673 0.0663 0.0654 0.0648 0.0642 0.0639 

[TRAIN] Epoch[1](11704/114412); Loss: 0.104163; Backpropagation: 0.2929 sec; Batch: 2.1185 sec
0.1854 0.1711 0.1421 0.1270 0.1123 0.1039 0.0958 0.0906 0.0884 0.0837 0.0816 0.0800 0.0780 0.0767 0.0757 0.0744 

[TRAIN] Epoch[1](11705/114412); Loss: 0.077876; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1364 0.1253 0.0961 0.0857 0.0806 0.0749 0.0714 0.0691 0.0676 0.0659 0.0644 0.0632 0.0624 0.0615 0.0610 0.0606 

[TRAIN] Epoch[1](11706/114412); Loss: 0.077637; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1379 0.1245 0.0957 0.0854 0.0798 0.0740 0.0704 0.0680 0.0663 0.0649 0.0641 0.0631 0.0627 0.0621 0.0619 0.0616 

[TRAIN] Epoch[1](11707/114412); Loss: 0.094407; Backpropagation: 0.2922 sec; Batch: 2.1149 sec
0.1600 0.1467 0.1117 0.1009 0.0959 0.0886 0.0863 0.0832 0.0818 0.0808 0.0801 0.0795 0.0792 0.0789 0.0786 0.0784 

[TRAIN] Epoch[1](11708/114412); Loss: 0.068724; Backpropagation: 0.2925 sec; Batch: 2.0977 sec
0.1325 0.1237 0.0849 0.0768 0.0656 0.0656 0.0608 0.0588 0.0563 0.0553 0.0548 0.0539 0.0531 0.0527 0.0523 0.0523 

[TRAIN] Epoch[1](11709/114412); Loss: 0.079924; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.1749 0.1636 0.1100 0.0978 0.0846 0.0765 0.0688 0.0637 0.0600 0.0575 0.0559 0.0545 0.0536 0.0530 0.0523 0.0521 

[TRAIN] Epoch[1](11710/114412); Loss: 0.103375; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1640 0.1544 0.1321 0.1192 0.1082 0.1008 0.0965 0.0937 0.0911 0.0887 0.0870 0.0857 0.0846 0.0836 0.0825 0.0818 

[TRAIN] Epoch[1](11711/114412); Loss: 0.072451; Backpropagation: 0.2913 sec; Batch: 2.1214 sec
0.1560 0.1360 0.0982 0.0872 0.0752 0.0675 0.0626 0.0599 0.0571 0.0548 0.0533 0.0519 0.0510 0.0501 0.0494 0.0488 

[TRAIN] Epoch[1](11712/114412); Loss: 0.066051; Backpropagation: 0.2914 sec; Batch: 2.1136 sec
0.1270 0.1173 0.0847 0.0750 0.0683 0.0619 0.0590 0.0564 0.0545 0.0529 0.0516 0.0506 0.0501 0.0495 0.0492 0.0489 

[TRAIN] Epoch[1](11713/114412); Loss: 0.116047; Backpropagation: 0.2911 sec; Batch: 2.1171 sec
0.1457 0.1426 0.1320 0.1276 0.1195 0.1166 0.1125 0.1107 0.1090 0.1081 0.1068 0.1062 0.1056 0.1050 0.1046 0.1043 

[TRAIN] Epoch[1](11714/114412); Loss: 0.071940; Backpropagation: 0.2912 sec; Batch: 2.1216 sec
0.1314 0.1187 0.0982 0.0847 0.0751 0.0686 0.0642 0.0615 0.0592 0.0579 0.0568 0.0558 0.0555 0.0549 0.0544 0.0540 

[TRAIN] Epoch[1](11715/114412); Loss: 0.089096; Backpropagation: 0.2926 sec; Batch: 2.0833 sec
0.1410 0.1347 0.1132 0.1065 0.0972 0.0904 0.0863 0.0823 0.0785 0.0755 0.0740 0.0718 0.0704 0.0691 0.0677 0.0670 

[TRAIN] Epoch[1](11716/114412); Loss: 0.095391; Backpropagation: 0.2927 sec; Batch: 2.0798 sec
0.1652 0.1541 0.1254 0.1148 0.1015 0.0936 0.0874 0.0836 0.0796 0.0780 0.0763 0.0751 0.0738 0.0732 0.0726 0.0720 

[TRAIN] Epoch[1](11717/114412); Loss: 0.089328; Backpropagation: 0.2942 sec; Batch: 2.0847 sec
0.1523 0.1429 0.1095 0.0996 0.0924 0.0864 0.0827 0.0795 0.0771 0.0751 0.0741 0.0730 0.0720 0.0717 0.0707 0.0704 

[TRAIN] Epoch[1](11718/114412); Loss: 0.078009; Backpropagation: 0.2926 sec; Batch: 2.1288 sec
0.1533 0.1457 0.1019 0.0862 0.0745 0.0702 0.0671 0.0644 0.0631 0.0617 0.0613 0.0605 0.0601 0.0597 0.0593 0.0591 

[TRAIN] Epoch[1](11719/114412); Loss: 0.108879; Backpropagation: 0.2912 sec; Batch: 2.1188 sec
0.1871 0.1791 0.1454 0.1338 0.1210 0.1108 0.1042 0.0981 0.0934 0.0888 0.0852 0.0829 0.0804 0.0789 0.0771 0.0760 

[TRAIN] Epoch[1](11720/114412); Loss: 0.081990; Backpropagation: 0.2910 sec; Batch: 2.1192 sec
0.1812 0.1751 0.1175 0.0954 0.0795 0.0747 0.0692 0.0640 0.0609 0.0591 0.0578 0.0569 0.0561 0.0554 0.0547 0.0544 

[TRAIN] Epoch[1](11721/114412); Loss: 0.071330; Backpropagation: 0.2924 sec; Batch: 2.0831 sec
0.1404 0.1313 0.1058 0.0882 0.0725 0.0647 0.0619 0.0599 0.0568 0.0546 0.0531 0.0520 0.0512 0.0500 0.0496 0.0493 

[TRAIN] Epoch[1](11722/114412); Loss: 0.094746; Backpropagation: 0.2909 sec; Batch: 2.0772 sec
0.1706 0.1589 0.1166 0.1022 0.0928 0.0893 0.0855 0.0825 0.0805 0.0789 0.0780 0.0771 0.0765 0.0758 0.0756 0.0750 

[TRAIN] Epoch[1](11723/114412); Loss: 0.046850; Backpropagation: 0.2909 sec; Batch: 2.0819 sec
0.1155 0.1108 0.0738 0.0505 0.0460 0.0391 0.0369 0.0337 0.0329 0.0313 0.0306 0.0301 0.0299 0.0298 0.0294 0.0294 

[TRAIN] Epoch[1](11724/114412); Loss: 0.057064; Backpropagation: 0.2952 sec; Batch: 2.1248 sec
0.1209 0.1170 0.0761 0.0592 0.0533 0.0513 0.0483 0.0464 0.0445 0.0438 0.0434 0.0424 0.0419 0.0416 0.0415 0.0415 

[TRAIN] Epoch[1](11725/114412); Loss: 0.068320; Backpropagation: 0.2928 sec; Batch: 2.1153 sec
0.1317 0.1234 0.0840 0.0698 0.0665 0.0639 0.0608 0.0582 0.0570 0.0557 0.0549 0.0541 0.0536 0.0534 0.0532 0.0530 

[TRAIN] Epoch[1](11726/114412); Loss: 0.085646; Backpropagation: 0.2953 sec; Batch: 2.1238 sec
0.1670 0.1480 0.1254 0.1046 0.0905 0.0797 0.0734 0.0708 0.0682 0.0667 0.0655 0.0636 0.0626 0.0618 0.0613 0.0610 

[TRAIN] Epoch[1](11727/114412); Loss: 0.068733; Backpropagation: 0.2930 sec; Batch: 2.1184 sec
0.1315 0.1049 0.0847 0.0814 0.0724 0.0651 0.0619 0.0595 0.0579 0.0569 0.0558 0.0547 0.0540 0.0534 0.0530 0.0526 

[TRAIN] Epoch[1](11728/114412); Loss: 0.076141; Backpropagation: 0.2953 sec; Batch: 2.1211 sec
0.1251 0.1183 0.0924 0.0846 0.0793 0.0741 0.0704 0.0683 0.0667 0.0653 0.0640 0.0630 0.0622 0.0618 0.0616 0.0612 

[TRAIN] Epoch[1](11729/114412); Loss: 0.085727; Backpropagation: 0.2934 sec; Batch: 2.1191 sec
0.1635 0.1429 0.1144 0.0988 0.0896 0.0821 0.0781 0.0742 0.0709 0.0689 0.0668 0.0659 0.0650 0.0641 0.0635 0.0628 

[TRAIN] Epoch[1](11730/114412); Loss: 0.057240; Backpropagation: 0.2913 sec; Batch: 2.1145 sec
0.1495 0.1370 0.0913 0.0598 0.0501 0.0455 0.0430 0.0421 0.0404 0.0385 0.0375 0.0370 0.0368 0.0360 0.0356 0.0355 

[TRAIN] Epoch[1](11731/114412); Loss: 0.078150; Backpropagation: 0.2902 sec; Batch: 2.1133 sec
0.1391 0.1328 0.1031 0.0922 0.0800 0.0740 0.0708 0.0677 0.0655 0.0633 0.0620 0.0613 0.0606 0.0600 0.0592 0.0588 

[TRAIN] Epoch[1](11732/114412); Loss: 0.074818; Backpropagation: 0.2908 sec; Batch: 2.1255 sec
0.1361 0.1277 0.0975 0.0841 0.0734 0.0701 0.0669 0.0650 0.0624 0.0610 0.0603 0.0595 0.0589 0.0583 0.0580 0.0579 

[TRAIN] Epoch[1](11733/114412); Loss: 0.077979; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1516 0.1432 0.1006 0.0845 0.0755 0.0723 0.0692 0.0670 0.0644 0.0626 0.0614 0.0604 0.0596 0.0591 0.0582 0.0578 

[TRAIN] Epoch[1](11734/114412); Loss: 0.077438; Backpropagation: 0.2918 sec; Batch: 2.1229 sec
0.1420 0.1283 0.0976 0.0883 0.0795 0.0750 0.0707 0.0676 0.0651 0.0637 0.0622 0.0612 0.0604 0.0597 0.0591 0.0587 

[TRAIN] Epoch[1](11735/114412); Loss: 0.074261; Backpropagation: 0.2908 sec; Batch: 2.0800 sec
0.1365 0.1271 0.1019 0.0861 0.0752 0.0706 0.0662 0.0635 0.0613 0.0597 0.0585 0.0576 0.0569 0.0561 0.0555 0.0553 

[TRAIN] Epoch[1](11736/114412); Loss: 0.054431; Backpropagation: 0.2923 sec; Batch: 2.1446 sec
0.0916 0.0815 0.0668 0.0619 0.0551 0.0540 0.0509 0.0484 0.0471 0.0460 0.0453 0.0448 0.0446 0.0444 0.0444 0.0442 

[TRAIN] Epoch[1](11737/114412); Loss: 0.079964; Backpropagation: 0.2907 sec; Batch: 2.0858 sec
0.1489 0.1393 0.0997 0.0884 0.0798 0.0754 0.0713 0.0690 0.0669 0.0653 0.0640 0.0632 0.0626 0.0622 0.0619 0.0616 

[TRAIN] Epoch[1](11738/114412); Loss: 0.081029; Backpropagation: 0.2907 sec; Batch: 2.0790 sec
0.1436 0.1371 0.1035 0.0925 0.0836 0.0769 0.0736 0.0707 0.0684 0.0665 0.0655 0.0644 0.0634 0.0627 0.0622 0.0618 

[TRAIN] Epoch[1](11739/114412); Loss: 0.055795; Backpropagation: 0.3007 sec; Batch: 2.1289 sec
0.1124 0.1068 0.0748 0.0642 0.0554 0.0512 0.0486 0.0459 0.0443 0.0430 0.0422 0.0415 0.0411 0.0407 0.0404 0.0402 

[TRAIN] Epoch[1](11740/114412); Loss: 0.085999; Backpropagation: 0.2974 sec; Batch: 2.1027 sec
0.1404 0.1312 0.1021 0.0945 0.0888 0.0838 0.0802 0.0778 0.0762 0.0744 0.0735 0.0719 0.0711 0.0706 0.0699 0.0695 

[TRAIN] Epoch[1](11741/114412); Loss: 0.068278; Backpropagation: 0.2958 sec; Batch: 2.1119 sec
0.1512 0.1365 0.0986 0.0774 0.0689 0.0609 0.0574 0.0537 0.0519 0.0497 0.0491 0.0483 0.0477 0.0474 0.0470 0.0468 

[TRAIN] Epoch[1](11742/114412); Loss: 0.086928; Backpropagation: 0.2956 sec; Batch: 2.1176 sec
0.1583 0.1491 0.1087 0.0968 0.0874 0.0826 0.0786 0.0759 0.0731 0.0712 0.0698 0.0690 0.0687 0.0680 0.0673 0.0665 

[TRAIN] Epoch[1](11743/114412); Loss: 0.079323; Backpropagation: 0.2956 sec; Batch: 2.1223 sec
0.1391 0.1312 0.0975 0.0890 0.0819 0.0763 0.0719 0.0686 0.0670 0.0659 0.0647 0.0640 0.0635 0.0632 0.0628 0.0626 

[TRAIN] Epoch[1](11744/114412); Loss: 0.050000; Backpropagation: 0.2955 sec; Batch: 2.1020 sec
0.1221 0.1189 0.0854 0.0661 0.0480 0.0407 0.0373 0.0354 0.0338 0.0324 0.0313 0.0309 0.0300 0.0295 0.0292 0.0291 

[TRAIN] Epoch[1](11745/114412); Loss: 0.086554; Backpropagation: 0.2953 sec; Batch: 2.0825 sec
0.1915 0.1727 0.1220 0.0988 0.0890 0.0785 0.0744 0.0704 0.0672 0.0647 0.0624 0.0613 0.0592 0.0584 0.0576 0.0568 

[TRAIN] Epoch[1](11746/114412); Loss: 0.081639; Backpropagation: 0.3012 sec; Batch: 2.1299 sec
0.1396 0.1254 0.1031 0.0927 0.0841 0.0786 0.0747 0.0723 0.0701 0.0689 0.0678 0.0670 0.0662 0.0657 0.0653 0.0649 

[TRAIN] Epoch[1](11747/114412); Loss: 0.055889; Backpropagation: 0.3006 sec; Batch: 2.1252 sec
0.1061 0.0894 0.0779 0.0641 0.0551 0.0523 0.0497 0.0480 0.0467 0.0458 0.0443 0.0437 0.0430 0.0430 0.0429 0.0422 

[TRAIN] Epoch[1](11748/114412); Loss: 0.079063; Backpropagation: 0.2950 sec; Batch: 2.1222 sec
0.1486 0.1365 0.1006 0.0887 0.0790 0.0738 0.0695 0.0672 0.0653 0.0641 0.0631 0.0626 0.0621 0.0617 0.0614 0.0610 

[TRAIN] Epoch[1](11749/114412); Loss: 0.080360; Backpropagation: 0.2956 sec; Batch: 2.1189 sec
0.1482 0.1340 0.1013 0.0901 0.0807 0.0749 0.0726 0.0705 0.0685 0.0665 0.0650 0.0642 0.0633 0.0625 0.0619 0.0616 

[TRAIN] Epoch[1](11750/114412); Loss: 0.086342; Backpropagation: 0.2951 sec; Batch: 2.1172 sec
0.1557 0.1379 0.1058 0.0952 0.0882 0.0840 0.0798 0.0774 0.0743 0.0725 0.0712 0.0698 0.0685 0.0676 0.0670 0.0666 

[TRAIN] Epoch[1](11751/114412); Loss: 0.079397; Backpropagation: 0.2954 sec; Batch: 2.1162 sec
0.1209 0.1138 0.0947 0.0853 0.0803 0.0774 0.0746 0.0727 0.0715 0.0703 0.0696 0.0688 0.0682 0.0678 0.0673 0.0672 

[TRAIN] Epoch[1](11752/114412); Loss: 0.054840; Backpropagation: 0.2957 sec; Batch: 2.1212 sec
0.1155 0.1042 0.0785 0.0645 0.0551 0.0515 0.0472 0.0441 0.0426 0.0409 0.0402 0.0393 0.0391 0.0385 0.0383 0.0381 

[TRAIN] Epoch[1](11753/114412); Loss: 0.087310; Backpropagation: 0.2978 sec; Batch: 2.1229 sec
0.1604 0.1478 0.1131 0.1005 0.0861 0.0801 0.0763 0.0744 0.0726 0.0713 0.0704 0.0696 0.0691 0.0687 0.0684 0.0682 

[TRAIN] Epoch[1](11754/114412); Loss: 0.068277; Backpropagation: 0.2956 sec; Batch: 2.1205 sec
0.1286 0.1095 0.0954 0.0824 0.0739 0.0663 0.0624 0.0583 0.0558 0.0538 0.0536 0.0522 0.0512 0.0503 0.0496 0.0490 

[TRAIN] Epoch[1](11755/114412); Loss: 0.074086; Backpropagation: 0.2959 sec; Batch: 2.1264 sec
0.1385 0.1159 0.0958 0.0842 0.0747 0.0699 0.0665 0.0645 0.0624 0.0611 0.0601 0.0593 0.0587 0.0583 0.0579 0.0576 

[TRAIN] Epoch[1](11756/114412); Loss: 0.075329; Backpropagation: 0.2952 sec; Batch: 2.1205 sec
0.1170 0.1104 0.0885 0.0817 0.0773 0.0734 0.0709 0.0683 0.0676 0.0660 0.0654 0.0646 0.0641 0.0636 0.0633 0.0630 

[TRAIN] Epoch[1](11757/114412); Loss: 0.065298; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.1179 0.1027 0.0791 0.0701 0.0663 0.0620 0.0594 0.0573 0.0559 0.0548 0.0542 0.0538 0.0532 0.0529 0.0526 0.0525 

[TRAIN] Epoch[1](11758/114412); Loss: 0.095958; Backpropagation: 0.2978 sec; Batch: 2.1279 sec
0.1536 0.1377 0.1145 0.1042 0.1019 0.0950 0.0919 0.0877 0.0850 0.0830 0.0819 0.0811 0.0803 0.0797 0.0791 0.0787 

[TRAIN] Epoch[1](11759/114412); Loss: 0.067071; Backpropagation: 0.2953 sec; Batch: 2.1239 sec
0.1289 0.1165 0.0855 0.0760 0.0698 0.0625 0.0596 0.0573 0.0556 0.0541 0.0529 0.0522 0.0512 0.0508 0.0504 0.0499 

[TRAIN] Epoch[1](11760/114412); Loss: 0.065311; Backpropagation: 0.2948 sec; Batch: 2.0820 sec
0.1435 0.1288 0.0919 0.0780 0.0689 0.0620 0.0561 0.0525 0.0502 0.0479 0.0465 0.0453 0.0445 0.0437 0.0428 0.0422 

[TRAIN] Epoch[1](11761/114412); Loss: 0.081129; Backpropagation: 0.2957 sec; Batch: 2.1268 sec
0.1418 0.1266 0.1009 0.0934 0.0841 0.0797 0.0754 0.0724 0.0705 0.0685 0.0669 0.0654 0.0644 0.0634 0.0626 0.0620 

[TRAIN] Epoch[1](11762/114412); Loss: 0.101295; Backpropagation: 0.2957 sec; Batch: 2.1212 sec
0.1651 0.1525 0.1230 0.1139 0.1059 0.0998 0.0950 0.0908 0.0883 0.0870 0.0858 0.0844 0.0833 0.0825 0.0821 0.0815 

[TRAIN] Epoch[1](11763/114412); Loss: 0.071621; Backpropagation: 0.2955 sec; Batch: 2.1224 sec
0.1300 0.1083 0.0957 0.0816 0.0748 0.0682 0.0661 0.0637 0.0607 0.0590 0.0577 0.0571 0.0565 0.0558 0.0555 0.0551 

[TRAIN] Epoch[1](11764/114412); Loss: 0.086998; Backpropagation: 0.2955 sec; Batch: 2.0828 sec
0.1478 0.1390 0.1138 0.1017 0.0914 0.0847 0.0793 0.0761 0.0734 0.0719 0.0707 0.0697 0.0689 0.0684 0.0678 0.0674 

[TRAIN] Epoch[1](11765/114412); Loss: 0.074412; Backpropagation: 0.2962 sec; Batch: 2.1245 sec
0.1652 0.1472 0.1163 0.0870 0.0742 0.0658 0.0613 0.0583 0.0563 0.0547 0.0528 0.0516 0.0508 0.0503 0.0496 0.0493 

[TRAIN] Epoch[1](11766/114412); Loss: 0.082296; Backpropagation: 0.2956 sec; Batch: 2.1215 sec
0.1553 0.1444 0.1038 0.0921 0.0818 0.0756 0.0727 0.0698 0.0680 0.0667 0.0658 0.0652 0.0645 0.0641 0.0637 0.0633 

[TRAIN] Epoch[1](11767/114412); Loss: 0.108038; Backpropagation: 0.2961 sec; Batch: 2.1228 sec
0.2049 0.1920 0.1500 0.1298 0.1119 0.0994 0.0939 0.0897 0.0870 0.0851 0.0833 0.0821 0.0809 0.0803 0.0795 0.0790 

[TRAIN] Epoch[1](11768/114412); Loss: 0.065872; Backpropagation: 0.2977 sec; Batch: 2.1216 sec
0.1252 0.1139 0.0932 0.0787 0.0731 0.0648 0.0589 0.0552 0.0533 0.0509 0.0496 0.0487 0.0478 0.0472 0.0469 0.0465 

[TRAIN] Epoch[1](11769/114412); Loss: 0.057791; Backpropagation: 0.2982 sec; Batch: 2.1231 sec
0.1052 0.0877 0.0743 0.0641 0.0590 0.0556 0.0531 0.0509 0.0495 0.0483 0.0474 0.0466 0.0462 0.0459 0.0455 0.0453 

[TRAIN] Epoch[1](11770/114412); Loss: 0.097752; Backpropagation: 0.2949 sec; Batch: 2.0823 sec
0.1966 0.1811 0.1353 0.1141 0.0920 0.0905 0.0852 0.0827 0.0784 0.0759 0.0749 0.0734 0.0723 0.0714 0.0704 0.0699 

[TRAIN] Epoch[1](11771/114412); Loss: 0.059174; Backpropagation: 0.2957 sec; Batch: 2.1029 sec
0.1075 0.0975 0.0779 0.0658 0.0591 0.0560 0.0534 0.0513 0.0498 0.0486 0.0477 0.0473 0.0466 0.0462 0.0461 0.0459 

[TRAIN] Epoch[1](11772/114412); Loss: 0.095544; Backpropagation: 0.2953 sec; Batch: 2.1231 sec
0.1638 0.1542 0.1250 0.1096 0.0996 0.0922 0.0873 0.0831 0.0813 0.0792 0.0780 0.0768 0.0758 0.0749 0.0743 0.0738 

[TRAIN] Epoch[1](11773/114412); Loss: 0.068533; Backpropagation: 0.3001 sec; Batch: 2.0884 sec
0.1400 0.1215 0.0932 0.0736 0.0673 0.0635 0.0640 0.0595 0.0553 0.0536 0.0524 0.0517 0.0509 0.0506 0.0498 0.0497 

[TRAIN] Epoch[1](11774/114412); Loss: 0.076535; Backpropagation: 0.2957 sec; Batch: 2.1267 sec
0.1203 0.1103 0.1000 0.0877 0.0809 0.0750 0.0713 0.0684 0.0669 0.0655 0.0643 0.0639 0.0631 0.0625 0.0623 0.0622 

[TRAIN] Epoch[1](11775/114412); Loss: 0.064924; Backpropagation: 0.2953 sec; Batch: 2.0829 sec
0.1306 0.1265 0.0902 0.0735 0.0655 0.0594 0.0566 0.0536 0.0519 0.0503 0.0487 0.0478 0.0467 0.0462 0.0457 0.0455 

[TRAIN] Epoch[1](11776/114412); Loss: 0.068886; Backpropagation: 0.2955 sec; Batch: 2.1119 sec
0.1366 0.1278 0.0913 0.0788 0.0736 0.0663 0.0601 0.0577 0.0549 0.0531 0.0521 0.0512 0.0505 0.0499 0.0494 0.0489 

[TRAIN] Epoch[1](11777/114412); Loss: 0.066406; Backpropagation: 0.2952 sec; Batch: 2.1199 sec
0.1435 0.1293 0.0863 0.0717 0.0661 0.0601 0.0567 0.0544 0.0525 0.0513 0.0501 0.0491 0.0485 0.0481 0.0476 0.0472 

[TRAIN] Epoch[1](11778/114412); Loss: 0.085210; Backpropagation: 0.2949 sec; Batch: 2.1218 sec
0.1565 0.1422 0.1131 0.1002 0.0900 0.0807 0.0764 0.0736 0.0711 0.0688 0.0672 0.0661 0.0651 0.0647 0.0640 0.0636 

[TRAIN] Epoch[1](11779/114412); Loss: 0.085992; Backpropagation: 0.2949 sec; Batch: 2.0903 sec
0.1549 0.1409 0.1109 0.1009 0.0879 0.0827 0.0775 0.0748 0.0722 0.0705 0.0692 0.0681 0.0672 0.0665 0.0660 0.0656 

[TRAIN] Epoch[1](11780/114412); Loss: 0.062030; Backpropagation: 0.2956 sec; Batch: 2.1214 sec
0.1375 0.1248 0.0750 0.0665 0.0641 0.0627 0.0568 0.0531 0.0483 0.0466 0.0446 0.0437 0.0430 0.0425 0.0418 0.0415 

[TRAIN] Epoch[1](11781/114412); Loss: 0.112393; Backpropagation: 0.2955 sec; Batch: 2.1211 sec
0.1800 0.1696 0.1419 0.1291 0.1176 0.1118 0.1059 0.1016 0.0983 0.0960 0.0939 0.0927 0.0915 0.0901 0.0895 0.0887 

[TRAIN] Epoch[1](11782/114412); Loss: 0.077420; Backpropagation: 0.2957 sec; Batch: 2.1185 sec
0.1514 0.1399 0.0932 0.0862 0.0785 0.0732 0.0685 0.0661 0.0637 0.0621 0.0612 0.0603 0.0593 0.0587 0.0584 0.0581 

[TRAIN] Epoch[1](11783/114412); Loss: 0.063290; Backpropagation: 0.2988 sec; Batch: 2.1257 sec
0.1310 0.1240 0.0837 0.0746 0.0625 0.0574 0.0540 0.0514 0.0498 0.0482 0.0474 0.0467 0.0460 0.0457 0.0453 0.0450 

[TRAIN] Epoch[1](11784/114412); Loss: 0.075525; Backpropagation: 0.2988 sec; Batch: 2.1207 sec
0.1351 0.1240 0.0949 0.0879 0.0791 0.0732 0.0695 0.0661 0.0645 0.0624 0.0611 0.0601 0.0591 0.0583 0.0571 0.0560 

[TRAIN] Epoch[1](11785/114412); Loss: 0.053361; Backpropagation: 0.2956 sec; Batch: 2.1181 sec
0.0995 0.0873 0.0709 0.0641 0.0559 0.0515 0.0469 0.0449 0.0438 0.0429 0.0422 0.0412 0.0410 0.0407 0.0404 0.0405 

[TRAIN] Epoch[1](11786/114412); Loss: 0.069799; Backpropagation: 0.2946 sec; Batch: 2.1160 sec
0.1260 0.1155 0.0940 0.0855 0.0789 0.0707 0.0651 0.0604 0.0574 0.0554 0.0539 0.0526 0.0514 0.0507 0.0499 0.0495 

[TRAIN] Epoch[1](11787/114412); Loss: 0.063343; Backpropagation: 0.2956 sec; Batch: 2.1221 sec
0.1210 0.1121 0.0831 0.0709 0.0640 0.0587 0.0547 0.0528 0.0514 0.0502 0.0498 0.0493 0.0490 0.0489 0.0488 0.0489 

[TRAIN] Epoch[1](11788/114412); Loss: 0.059929; Backpropagation: 0.2957 sec; Batch: 2.1208 sec
0.1296 0.1064 0.0768 0.0688 0.0629 0.0583 0.0527 0.0500 0.0476 0.0461 0.0450 0.0441 0.0433 0.0428 0.0424 0.0422 

[TRAIN] Epoch[1](11789/114412); Loss: 0.096927; Backpropagation: 0.2955 sec; Batch: 2.1202 sec
0.1528 0.1380 0.1201 0.1079 0.1026 0.0957 0.0912 0.0879 0.0855 0.0839 0.0827 0.0818 0.0810 0.0804 0.0799 0.0794 

[TRAIN] Epoch[1](11790/114412); Loss: 0.083413; Backpropagation: 0.2982 sec; Batch: 2.1238 sec
0.1384 0.1292 0.1103 0.0968 0.0864 0.0804 0.0770 0.0747 0.0726 0.0704 0.0690 0.0674 0.0665 0.0657 0.0650 0.0647 

[TRAIN] Epoch[1](11791/114412); Loss: 0.073063; Backpropagation: 0.2956 sec; Batch: 2.1158 sec
0.1412 0.1270 0.0941 0.0806 0.0745 0.0688 0.0650 0.0626 0.0606 0.0590 0.0578 0.0570 0.0562 0.0555 0.0549 0.0545 

[TRAIN] Epoch[1](11792/114412); Loss: 0.082137; Backpropagation: 0.2959 sec; Batch: 2.1226 sec
0.1398 0.1247 0.1033 0.0911 0.0833 0.0784 0.0749 0.0727 0.0709 0.0697 0.0688 0.0681 0.0679 0.0673 0.0668 0.0665 

[TRAIN] Epoch[1](11793/114412); Loss: 0.059940; Backpropagation: 0.2956 sec; Batch: 2.0821 sec
0.1224 0.1120 0.0819 0.0712 0.0647 0.0579 0.0545 0.0507 0.0482 0.0461 0.0444 0.0430 0.0418 0.0410 0.0400 0.0394 

[TRAIN] Epoch[1](11794/114412); Loss: 0.078697; Backpropagation: 0.2959 sec; Batch: 2.0859 sec
0.1557 0.1405 0.0950 0.0850 0.0795 0.0739 0.0718 0.0686 0.0665 0.0636 0.0622 0.0610 0.0602 0.0591 0.0585 0.0578 

[TRAIN] Epoch[1](11795/114412); Loss: 0.094582; Backpropagation: 0.2959 sec; Batch: 2.0902 sec
0.1462 0.1349 0.1098 0.1031 0.0955 0.0909 0.0885 0.0862 0.0848 0.0836 0.0830 0.0821 0.0817 0.0813 0.0810 0.0807 

[TRAIN] Epoch[1](11796/114412); Loss: 0.057760; Backpropagation: 0.2958 sec; Batch: 2.1241 sec
0.1189 0.1087 0.0788 0.0663 0.0611 0.0532 0.0499 0.0479 0.0456 0.0440 0.0429 0.0423 0.0417 0.0413 0.0410 0.0408 

[TRAIN] Epoch[1](11797/114412); Loss: 0.064806; Backpropagation: 0.2981 sec; Batch: 2.1204 sec
0.1450 0.1299 0.0816 0.0744 0.0646 0.0600 0.0552 0.0520 0.0501 0.0486 0.0476 0.0470 0.0460 0.0453 0.0450 0.0446 

[TRAIN] Epoch[1](11798/114412); Loss: 0.074035; Backpropagation: 0.2956 sec; Batch: 2.1193 sec
0.1476 0.1433 0.1130 0.0925 0.0760 0.0677 0.0634 0.0599 0.0570 0.0550 0.0536 0.0525 0.0518 0.0510 0.0505 0.0497 

[TRAIN] Epoch[1](11799/114412); Loss: 0.063817; Backpropagation: 0.2981 sec; Batch: 2.1249 sec
0.1212 0.1099 0.0810 0.0742 0.0652 0.0599 0.0563 0.0538 0.0525 0.0513 0.0505 0.0498 0.0494 0.0490 0.0487 0.0485 

[TRAIN] Epoch[1](11800/114412); Loss: 0.070646; Backpropagation: 0.2956 sec; Batch: 2.1200 sec
0.1456 0.1313 0.0895 0.0763 0.0713 0.0658 0.0624 0.0596 0.0575 0.0553 0.0542 0.0534 0.0527 0.0523 0.0516 0.0517 

[TRAIN] Epoch[1](11801/114412); Loss: 0.092338; Backpropagation: 0.2951 sec; Batch: 2.1216 sec
0.1780 0.1638 0.1209 0.1049 0.0931 0.0845 0.0802 0.0778 0.0764 0.0749 0.0730 0.0718 0.0709 0.0696 0.0691 0.0685 

[TRAIN] Epoch[1](11802/114412); Loss: 0.075918; Backpropagation: 0.2950 sec; Batch: 2.1210 sec
0.1656 0.1486 0.1008 0.0859 0.0753 0.0676 0.0646 0.0617 0.0596 0.0577 0.0562 0.0554 0.0546 0.0541 0.0538 0.0534 

[TRAIN] Epoch[1](11803/114412); Loss: 0.087272; Backpropagation: 0.2957 sec; Batch: 2.1234 sec
0.1379 0.1273 0.1046 0.0982 0.0929 0.0863 0.0830 0.0798 0.0776 0.0757 0.0742 0.0731 0.0723 0.0716 0.0711 0.0706 

[TRAIN] Epoch[1](11804/114412); Loss: 0.064829; Backpropagation: 0.2956 sec; Batch: 2.1201 sec
0.1170 0.1036 0.0903 0.0770 0.0719 0.0628 0.0606 0.0570 0.0537 0.0519 0.0509 0.0496 0.0486 0.0478 0.0474 0.0470 

[TRAIN] Epoch[1](11805/114412); Loss: 0.082429; Backpropagation: 0.2953 sec; Batch: 2.1188 sec
0.1330 0.1268 0.0993 0.0923 0.0845 0.0813 0.0765 0.0742 0.0723 0.0708 0.0698 0.0688 0.0679 0.0674 0.0671 0.0667 

[TRAIN] Epoch[1](11806/114412); Loss: 0.081877; Backpropagation: 0.2949 sec; Batch: 2.1214 sec
0.1464 0.1319 0.1048 0.0917 0.0842 0.0778 0.0740 0.0714 0.0696 0.0680 0.0665 0.0657 0.0652 0.0647 0.0642 0.0639 

[TRAIN] Epoch[1](11807/114412); Loss: 0.070886; Backpropagation: 0.2980 sec; Batch: 2.1246 sec
0.1243 0.1135 0.0934 0.0818 0.0744 0.0695 0.0663 0.0616 0.0595 0.0579 0.0570 0.0561 0.0553 0.0551 0.0544 0.0541 

[TRAIN] Epoch[1](11808/114412); Loss: 0.072124; Backpropagation: 0.2973 sec; Batch: 2.1213 sec
0.1239 0.1110 0.0871 0.0798 0.0734 0.0700 0.0665 0.0638 0.0624 0.0610 0.0604 0.0599 0.0593 0.0589 0.0585 0.0582 

[TRAIN] Epoch[1](11809/114412); Loss: 0.082541; Backpropagation: 0.3006 sec; Batch: 2.1244 sec
0.1520 0.1411 0.1071 0.0975 0.0856 0.0803 0.0744 0.0714 0.0689 0.0669 0.0653 0.0637 0.0629 0.0618 0.0611 0.0606 

[TRAIN] Epoch[1](11810/114412); Loss: 0.065968; Backpropagation: 0.2972 sec; Batch: 2.1185 sec
0.1137 0.1097 0.0886 0.0769 0.0703 0.0641 0.0605 0.0574 0.0553 0.0537 0.0524 0.0516 0.0509 0.0506 0.0501 0.0499 

[TRAIN] Epoch[1](11811/114412); Loss: 0.091144; Backpropagation: 0.2956 sec; Batch: 2.1236 sec
0.1435 0.1310 0.1121 0.1032 0.0972 0.0904 0.0868 0.0832 0.0813 0.0791 0.0779 0.0764 0.0755 0.0744 0.0736 0.0728 

[TRAIN] Epoch[1](11812/114412); Loss: 0.066005; Backpropagation: 0.2957 sec; Batch: 2.1241 sec
0.1273 0.1154 0.0856 0.0753 0.0688 0.0637 0.0592 0.0568 0.0545 0.0528 0.0516 0.0503 0.0494 0.0489 0.0483 0.0481 

[TRAIN] Epoch[1](11813/114412); Loss: 0.100221; Backpropagation: 0.2956 sec; Batch: 2.1231 sec
0.1804 0.1688 0.1288 0.1181 0.1032 0.0936 0.0897 0.0866 0.0845 0.0823 0.0812 0.0793 0.0783 0.0770 0.0763 0.0757 

[TRAIN] Epoch[1](11814/114412); Loss: 0.069383; Backpropagation: 0.3009 sec; Batch: 2.1076 sec
0.1400 0.1176 0.0932 0.0810 0.0678 0.0631 0.0606 0.0585 0.0567 0.0557 0.0546 0.0537 0.0528 0.0521 0.0516 0.0512 

[TRAIN] Epoch[1](11815/114412); Loss: 0.057353; Backpropagation: 0.2987 sec; Batch: 2.0857 sec
0.1059 0.0988 0.0728 0.0668 0.0595 0.0555 0.0514 0.0490 0.0473 0.0462 0.0453 0.0447 0.0441 0.0437 0.0434 0.0433 

[TRAIN] Epoch[1](11816/114412); Loss: 0.048683; Backpropagation: 0.3012 sec; Batch: 2.0912 sec
0.1471 0.1348 0.0669 0.0523 0.0472 0.0369 0.0343 0.0322 0.0311 0.0295 0.0288 0.0283 0.0277 0.0274 0.0271 0.0270 

[TRAIN] Epoch[1](11817/114412); Loss: 0.066107; Backpropagation: 0.2965 sec; Batch: 2.0848 sec
0.1414 0.1256 0.0968 0.0797 0.0682 0.0599 0.0559 0.0525 0.0502 0.0490 0.0480 0.0471 0.0466 0.0460 0.0456 0.0452 

[TRAIN] Epoch[1](11818/114412); Loss: 0.081339; Backpropagation: 0.2953 sec; Batch: 2.1199 sec
0.1504 0.1339 0.1003 0.0893 0.0845 0.0780 0.0746 0.0709 0.0693 0.0672 0.0659 0.0653 0.0638 0.0633 0.0626 0.0622 

[TRAIN] Epoch[1](11819/114412); Loss: 0.074790; Backpropagation: 0.2981 sec; Batch: 2.1316 sec
0.1476 0.1243 0.0936 0.0848 0.0797 0.0720 0.0677 0.0643 0.0618 0.0599 0.0586 0.0575 0.0569 0.0564 0.0560 0.0556 

[TRAIN] Epoch[1](11820/114412); Loss: 0.065117; Backpropagation: 0.2985 sec; Batch: 2.1223 sec
0.1125 0.1064 0.0831 0.0718 0.0671 0.0626 0.0596 0.0570 0.0554 0.0541 0.0535 0.0526 0.0521 0.0516 0.0514 0.0510 

[TRAIN] Epoch[1](11821/114412); Loss: 0.077955; Backpropagation: 0.2955 sec; Batch: 2.1190 sec
0.1381 0.1232 0.0962 0.0864 0.0809 0.0759 0.0712 0.0683 0.0663 0.0653 0.0642 0.0633 0.0626 0.0622 0.0617 0.0616 

[TRAIN] Epoch[1](11822/114412); Loss: 0.070140; Backpropagation: 0.2976 sec; Batch: 2.1207 sec
0.1470 0.1380 0.1023 0.0847 0.0731 0.0679 0.0605 0.0570 0.0536 0.0517 0.0503 0.0488 0.0480 0.0472 0.0464 0.0458 

[TRAIN] Epoch[1](11823/114412); Loss: 0.084846; Backpropagation: 0.2979 sec; Batch: 2.1217 sec
0.1612 0.1530 0.1149 0.1005 0.0851 0.0794 0.0746 0.0713 0.0692 0.0667 0.0657 0.0645 0.0636 0.0631 0.0625 0.0621 

[TRAIN] Epoch[1](11824/114412); Loss: 0.103741; Backpropagation: 0.2976 sec; Batch: 2.1214 sec
0.1635 0.1506 0.1211 0.1111 0.1085 0.1015 0.0993 0.0952 0.0931 0.0908 0.0895 0.0884 0.0877 0.0871 0.0866 0.0860 

[TRAIN] Epoch[1](11825/114412); Loss: 0.067122; Backpropagation: 0.2978 sec; Batch: 2.1183 sec
0.1359 0.1229 0.0856 0.0749 0.0668 0.0621 0.0595 0.0563 0.0545 0.0529 0.0520 0.0511 0.0506 0.0500 0.0496 0.0493 

[TRAIN] Epoch[1](11826/114412); Loss: 0.081272; Backpropagation: 0.2979 sec; Batch: 2.1208 sec
0.1546 0.1352 0.1098 0.0957 0.0865 0.0780 0.0727 0.0697 0.0668 0.0652 0.0637 0.0621 0.0610 0.0604 0.0597 0.0593 

[TRAIN] Epoch[1](11827/114412); Loss: 0.070499; Backpropagation: 0.2959 sec; Batch: 2.1205 sec
0.1264 0.1127 0.0912 0.0814 0.0736 0.0674 0.0637 0.0612 0.0592 0.0580 0.0569 0.0562 0.0557 0.0551 0.0547 0.0544 

[TRAIN] Epoch[1](11828/114412); Loss: 0.084500; Backpropagation: 0.2959 sec; Batch: 2.1213 sec
0.1544 0.1360 0.1131 0.0949 0.0842 0.0786 0.0761 0.0733 0.0706 0.0695 0.0685 0.0675 0.0669 0.0664 0.0659 0.0659 

[TRAIN] Epoch[1](11829/114412); Loss: 0.079824; Backpropagation: 0.2955 sec; Batch: 2.1227 sec
0.1233 0.1210 0.1044 0.0967 0.0860 0.0782 0.0743 0.0719 0.0696 0.0676 0.0663 0.0649 0.0642 0.0635 0.0629 0.0625 

[TRAIN] Epoch[1](11830/114412); Loss: 0.091031; Backpropagation: 0.2954 sec; Batch: 2.0816 sec
0.1593 0.1503 0.1220 0.1113 0.0975 0.0909 0.0827 0.0787 0.0748 0.0732 0.0715 0.0703 0.0694 0.0688 0.0682 0.0676 

[TRAIN] Epoch[1](11831/114412); Loss: 0.079943; Backpropagation: 0.2958 sec; Batch: 2.1212 sec
0.1277 0.1186 0.1044 0.0931 0.0840 0.0780 0.0744 0.0716 0.0697 0.0677 0.0667 0.0659 0.0651 0.0645 0.0641 0.0636 

[TRAIN] Epoch[1](11832/114412); Loss: 0.090102; Backpropagation: 0.2958 sec; Batch: 2.1198 sec
0.1575 0.1437 0.1032 0.0975 0.0893 0.0858 0.0826 0.0807 0.0784 0.0773 0.0757 0.0750 0.0744 0.0739 0.0735 0.0731 

[TRAIN] Epoch[1](11833/114412); Loss: 0.066947; Backpropagation: 0.2951 sec; Batch: 2.1194 sec
0.1156 0.1100 0.0840 0.0760 0.0705 0.0644 0.0607 0.0588 0.0565 0.0554 0.0545 0.0538 0.0533 0.0529 0.0525 0.0524 

[TRAIN] Epoch[1](11834/114412); Loss: 0.065113; Backpropagation: 0.2953 sec; Batch: 2.1225 sec
0.1111 0.1021 0.0825 0.0751 0.0695 0.0648 0.0603 0.0578 0.0558 0.0545 0.0531 0.0522 0.0517 0.0509 0.0503 0.0499 

[TRAIN] Epoch[1](11835/114412); Loss: 0.058474; Backpropagation: 0.2962 sec; Batch: 2.0983 sec
0.1087 0.1040 0.0801 0.0672 0.0590 0.0547 0.0517 0.0496 0.0478 0.0467 0.0457 0.0451 0.0445 0.0439 0.0436 0.0433 

[TRAIN] Epoch[1](11836/114412); Loss: 0.057803; Backpropagation: 0.3011 sec; Batch: 2.1267 sec
0.1130 0.0972 0.0812 0.0697 0.0653 0.0580 0.0524 0.0487 0.0464 0.0445 0.0433 0.0423 0.0416 0.0409 0.0404 0.0399 

[TRAIN] Epoch[1](11837/114412); Loss: 0.074569; Backpropagation: 0.2967 sec; Batch: 2.1018 sec
0.1295 0.1129 0.0944 0.0850 0.0790 0.0730 0.0687 0.0655 0.0640 0.0627 0.0617 0.0604 0.0598 0.0593 0.0586 0.0585 

[TRAIN] Epoch[1](11838/114412); Loss: 0.075559; Backpropagation: 0.2950 sec; Batch: 2.1221 sec
0.1426 0.1312 0.0979 0.0840 0.0774 0.0718 0.0681 0.0648 0.0627 0.0611 0.0597 0.0589 0.0579 0.0574 0.0571 0.0563 

[TRAIN] Epoch[1](11839/114412); Loss: 0.127619; Backpropagation: 0.2961 sec; Batch: 2.0837 sec
0.1808 0.1749 0.1469 0.1387 0.1312 0.1262 0.1233 0.1194 0.1175 0.1152 0.1140 0.1128 0.1115 0.1106 0.1098 0.1090 

[TRAIN] Epoch[1](11840/114412); Loss: 0.077756; Backpropagation: 0.2956 sec; Batch: 2.1014 sec
0.1421 0.1335 0.0980 0.0867 0.0792 0.0724 0.0696 0.0671 0.0653 0.0639 0.0626 0.0619 0.0612 0.0606 0.0601 0.0598 

[TRAIN] Epoch[1](11841/114412); Loss: 0.077797; Backpropagation: 0.2980 sec; Batch: 2.1370 sec
0.1294 0.1164 0.1047 0.0893 0.0810 0.0758 0.0713 0.0688 0.0673 0.0657 0.0643 0.0633 0.0627 0.0621 0.0615 0.0611 

[TRAIN] Epoch[1](11842/114412); Loss: 0.082426; Backpropagation: 0.2972 sec; Batch: 2.1297 sec
0.1450 0.1317 0.1133 0.0970 0.0875 0.0799 0.0755 0.0717 0.0692 0.0670 0.0654 0.0645 0.0635 0.0631 0.0626 0.0620 

[TRAIN] Epoch[1](11843/114412); Loss: 0.080917; Backpropagation: 0.3009 sec; Batch: 2.1154 sec
0.1397 0.1285 0.1087 0.0943 0.0844 0.0780 0.0738 0.0708 0.0688 0.0668 0.0655 0.0644 0.0636 0.0630 0.0624 0.0621 

[TRAIN] Epoch[1](11844/114412); Loss: 0.067483; Backpropagation: 0.2956 sec; Batch: 2.1213 sec
0.1256 0.1133 0.0874 0.0784 0.0703 0.0641 0.0603 0.0587 0.0563 0.0543 0.0534 0.0523 0.0519 0.0515 0.0510 0.0508 

[TRAIN] Epoch[1](11845/114412); Loss: 0.057240; Backpropagation: 0.2955 sec; Batch: 2.1228 sec
0.1155 0.1086 0.0760 0.0691 0.0612 0.0546 0.0507 0.0478 0.0460 0.0443 0.0428 0.0417 0.0408 0.0398 0.0389 0.0384 

[TRAIN] Epoch[1](11846/114412); Loss: 0.071575; Backpropagation: 0.2951 sec; Batch: 2.1204 sec
0.1467 0.1256 0.1004 0.0854 0.0739 0.0646 0.0613 0.0587 0.0569 0.0554 0.0543 0.0534 0.0528 0.0523 0.0520 0.0515 

[TRAIN] Epoch[1](11847/114412); Loss: 0.080872; Backpropagation: 0.2953 sec; Batch: 2.0862 sec
0.1936 0.1766 0.1179 0.1004 0.0763 0.0680 0.0633 0.0602 0.0580 0.0566 0.0557 0.0546 0.0538 0.0533 0.0529 0.0526 

[TRAIN] Epoch[1](11848/114412); Loss: 0.067644; Backpropagation: 0.2957 sec; Batch: 2.1006 sec
0.1284 0.1155 0.0859 0.0783 0.0696 0.0649 0.0616 0.0586 0.0565 0.0548 0.0534 0.0525 0.0515 0.0507 0.0503 0.0498 

[TRAIN] Epoch[1](11849/114412); Loss: 0.098344; Backpropagation: 0.2980 sec; Batch: 2.0856 sec
0.1479 0.1337 0.1215 0.1102 0.1037 0.0970 0.0931 0.0903 0.0882 0.0866 0.0856 0.0844 0.0837 0.0830 0.0825 0.0821 

[TRAIN] Epoch[1](11850/114412); Loss: 0.071014; Backpropagation: 0.2978 sec; Batch: 2.1316 sec
0.1320 0.1179 0.0899 0.0822 0.0747 0.0681 0.0640 0.0604 0.0589 0.0576 0.0567 0.0558 0.0552 0.0546 0.0542 0.0540 

[TRAIN] Epoch[1](11851/114412); Loss: 0.079992; Backpropagation: 0.2956 sec; Batch: 2.1200 sec
0.1265 0.1185 0.0988 0.0858 0.0814 0.0775 0.0746 0.0720 0.0706 0.0694 0.0687 0.0679 0.0676 0.0672 0.0669 0.0665 

[TRAIN] Epoch[1](11852/114412); Loss: 0.073831; Backpropagation: 0.2959 sec; Batch: 2.1256 sec
0.1446 0.1284 0.0957 0.0855 0.0765 0.0699 0.0661 0.0628 0.0605 0.0588 0.0573 0.0564 0.0555 0.0550 0.0544 0.0539 

[TRAIN] Epoch[1](11853/114412); Loss: 0.074097; Backpropagation: 0.2958 sec; Batch: 2.1065 sec
0.1582 0.1452 0.1064 0.0882 0.0731 0.0671 0.0633 0.0600 0.0576 0.0552 0.0539 0.0528 0.0520 0.0514 0.0506 0.0502 

[TRAIN] Epoch[1](11854/114412); Loss: 0.067809; Backpropagation: 0.2958 sec; Batch: 2.1240 sec
0.1196 0.1041 0.0856 0.0741 0.0686 0.0651 0.0616 0.0602 0.0587 0.0573 0.0563 0.0557 0.0552 0.0546 0.0544 0.0540 

[TRAIN] Epoch[1](11855/114412); Loss: 0.060103; Backpropagation: 0.2959 sec; Batch: 2.1192 sec
0.1252 0.1188 0.0850 0.0678 0.0606 0.0559 0.0514 0.0483 0.0466 0.0452 0.0442 0.0434 0.0430 0.0424 0.0420 0.0417 

[TRAIN] Epoch[1](11856/114412); Loss: 0.082894; Backpropagation: 0.2953 sec; Batch: 2.1216 sec
0.1463 0.1321 0.0969 0.0912 0.0859 0.0816 0.0767 0.0736 0.0716 0.0701 0.0689 0.0677 0.0669 0.0662 0.0655 0.0649 

[TRAIN] Epoch[1](11857/114412); Loss: 0.066038; Backpropagation: 0.2954 sec; Batch: 2.1064 sec
0.1071 0.0960 0.0842 0.0756 0.0704 0.0650 0.0615 0.0590 0.0574 0.0563 0.0555 0.0547 0.0541 0.0536 0.0532 0.0529 

[TRAIN] Epoch[1](11858/114412); Loss: 0.072369; Backpropagation: 0.2982 sec; Batch: 2.1228 sec
0.1451 0.1290 0.1016 0.0837 0.0744 0.0673 0.0627 0.0597 0.0575 0.0561 0.0550 0.0543 0.0536 0.0530 0.0526 0.0522 

[TRAIN] Epoch[1](11859/114412); Loss: 0.082353; Backpropagation: 0.2960 sec; Batch: 2.1195 sec
0.1553 0.1469 0.1116 0.0947 0.0854 0.0787 0.0737 0.0701 0.0672 0.0652 0.0639 0.0625 0.0616 0.0609 0.0601 0.0596 

[TRAIN] Epoch[1](11860/114412); Loss: 0.072939; Backpropagation: 0.2951 sec; Batch: 2.1180 sec
0.1324 0.1150 0.0943 0.0824 0.0746 0.0694 0.0655 0.0631 0.0617 0.0602 0.0593 0.0587 0.0581 0.0577 0.0575 0.0572 

[TRAIN] Epoch[1](11861/114412); Loss: 0.070405; Backpropagation: 0.2984 sec; Batch: 2.1285 sec
0.1548 0.1417 0.1062 0.0861 0.0681 0.0626 0.0592 0.0548 0.0525 0.0506 0.0498 0.0491 0.0483 0.0479 0.0475 0.0473 

[TRAIN] Epoch[1](11862/114412); Loss: 0.067433; Backpropagation: 0.2958 sec; Batch: 2.1188 sec
0.1219 0.1072 0.0824 0.0738 0.0686 0.0638 0.0614 0.0591 0.0577 0.0565 0.0556 0.0550 0.0545 0.0540 0.0539 0.0537 

[TRAIN] Epoch[1](11863/114412); Loss: 0.065300; Backpropagation: 0.2952 sec; Batch: 2.1219 sec
0.1084 0.1055 0.0835 0.0744 0.0648 0.0622 0.0584 0.0570 0.0561 0.0553 0.0542 0.0535 0.0534 0.0531 0.0525 0.0524 

[TRAIN] Epoch[1](11864/114412); Loss: 0.049504; Backpropagation: 0.2975 sec; Batch: 2.1202 sec
0.1017 0.0877 0.0660 0.0566 0.0513 0.0470 0.0436 0.0414 0.0397 0.0384 0.0376 0.0370 0.0365 0.0361 0.0359 0.0356 

[TRAIN] Epoch[1](11865/114412); Loss: 0.059202; Backpropagation: 0.2957 sec; Batch: 2.1226 sec
0.1264 0.1152 0.0787 0.0681 0.0622 0.0552 0.0513 0.0481 0.0462 0.0445 0.0434 0.0426 0.0419 0.0416 0.0411 0.0408 

[TRAIN] Epoch[1](11866/114412); Loss: 0.067838; Backpropagation: 0.2955 sec; Batch: 2.1186 sec
0.1251 0.1127 0.0948 0.0774 0.0702 0.0642 0.0600 0.0582 0.0562 0.0548 0.0539 0.0527 0.0521 0.0514 0.0510 0.0507 

[TRAIN] Epoch[1](11867/114412); Loss: 0.085196; Backpropagation: 0.2958 sec; Batch: 2.1243 sec
0.1786 0.1587 0.1282 0.1077 0.0897 0.0796 0.0712 0.0677 0.0658 0.0638 0.0611 0.0599 0.0589 0.0580 0.0575 0.0567 

[TRAIN] Epoch[1](11868/114412); Loss: 0.053382; Backpropagation: 0.2961 sec; Batch: 2.1052 sec
0.1210 0.0884 0.0723 0.0621 0.0537 0.0518 0.0463 0.0439 0.0423 0.0411 0.0400 0.0392 0.0385 0.0381 0.0379 0.0376 

[TRAIN] Epoch[1](11869/114412); Loss: 0.067040; Backpropagation: 0.2954 sec; Batch: 2.1205 sec
0.1098 0.1044 0.0871 0.0755 0.0683 0.0650 0.0614 0.0596 0.0578 0.0566 0.0559 0.0553 0.0546 0.0542 0.0537 0.0534 

[TRAIN] Epoch[1](11870/114412); Loss: 0.073837; Backpropagation: 0.2954 sec; Batch: 2.1219 sec
0.1316 0.1209 0.0960 0.0825 0.0756 0.0705 0.0670 0.0644 0.0625 0.0607 0.0601 0.0591 0.0585 0.0578 0.0573 0.0569 

[TRAIN] Epoch[1](11871/114412); Loss: 0.082173; Backpropagation: 0.3012 sec; Batch: 2.1254 sec
0.1383 0.1227 0.1006 0.0932 0.0851 0.0791 0.0761 0.0736 0.0720 0.0703 0.0690 0.0680 0.0674 0.0670 0.0664 0.0661 

[TRAIN] Epoch[1](11872/114412); Loss: 0.062415; Backpropagation: 0.2986 sec; Batch: 2.1231 sec
0.1115 0.1084 0.0798 0.0719 0.0647 0.0598 0.0569 0.0538 0.0521 0.0505 0.0496 0.0487 0.0482 0.0479 0.0474 0.0472 

[TRAIN] Epoch[1](11873/114412); Loss: 0.088440; Backpropagation: 0.3010 sec; Batch: 2.1296 sec
0.1589 0.1480 0.1171 0.0996 0.0907 0.0835 0.0793 0.0768 0.0745 0.0729 0.0715 0.0702 0.0692 0.0685 0.0675 0.0669 

[TRAIN] Epoch[1](11874/114412); Loss: 0.064488; Backpropagation: 0.3004 sec; Batch: 2.1255 sec
0.1165 0.1079 0.0800 0.0717 0.0658 0.0625 0.0585 0.0562 0.0546 0.0531 0.0521 0.0515 0.0508 0.0504 0.0502 0.0498 

[TRAIN] Epoch[1](11875/114412); Loss: 0.074826; Backpropagation: 0.2987 sec; Batch: 2.1239 sec
0.1305 0.1129 0.0915 0.0838 0.0783 0.0728 0.0697 0.0671 0.0647 0.0630 0.0620 0.0610 0.0605 0.0600 0.0596 0.0597 

[TRAIN] Epoch[1](11876/114412); Loss: 0.079528; Backpropagation: 0.3013 sec; Batch: 2.1141 sec
0.1459 0.1405 0.1003 0.0829 0.0788 0.0732 0.0700 0.0680 0.0666 0.0655 0.0649 0.0645 0.0636 0.0631 0.0626 0.0623 

[TRAIN] Epoch[1](11877/114412); Loss: 0.080430; Backpropagation: 0.3006 sec; Batch: 2.1308 sec
0.1621 0.1467 0.1038 0.0866 0.0813 0.0759 0.0733 0.0673 0.0656 0.0641 0.0618 0.0606 0.0603 0.0596 0.0590 0.0588 

[TRAIN] Epoch[1](11878/114412); Loss: 0.130693; Backpropagation: 0.2958 sec; Batch: 2.1247 sec
0.1896 0.1795 0.1557 0.1460 0.1368 0.1295 0.1243 0.1207 0.1179 0.1161 0.1149 0.1137 0.1127 0.1119 0.1112 0.1106 

[TRAIN] Epoch[1](11879/114412); Loss: 0.066252; Backpropagation: 0.2960 sec; Batch: 2.1262 sec
0.1229 0.1076 0.0827 0.0732 0.0688 0.0639 0.0600 0.0576 0.0557 0.0544 0.0535 0.0527 0.0523 0.0518 0.0516 0.0512 

[TRAIN] Epoch[1](11880/114412); Loss: 0.071754; Backpropagation: 0.2957 sec; Batch: 2.1249 sec
0.1196 0.1159 0.0947 0.0845 0.0761 0.0701 0.0673 0.0644 0.0616 0.0596 0.0581 0.0568 0.0559 0.0552 0.0544 0.0537 

[TRAIN] Epoch[1](11881/114412); Loss: 0.078341; Backpropagation: 0.2982 sec; Batch: 2.1247 sec
0.1509 0.1416 0.1125 0.0953 0.0820 0.0722 0.0681 0.0650 0.0628 0.0609 0.0596 0.0584 0.0572 0.0563 0.0556 0.0550 

[TRAIN] Epoch[1](11882/114412); Loss: 0.094080; Backpropagation: 0.2980 sec; Batch: 2.1227 sec
0.1841 0.1690 0.1227 0.1028 0.0942 0.0891 0.0826 0.0804 0.0767 0.0746 0.0733 0.0723 0.0717 0.0712 0.0705 0.0701 

[TRAIN] Epoch[1](11883/114412); Loss: 0.081825; Backpropagation: 0.2959 sec; Batch: 2.1239 sec
0.1344 0.1253 0.1016 0.0912 0.0844 0.0795 0.0753 0.0731 0.0710 0.0696 0.0685 0.0679 0.0675 0.0670 0.0666 0.0663 

[TRAIN] Epoch[1](11884/114412); Loss: 0.078019; Backpropagation: 0.2949 sec; Batch: 2.1220 sec
0.1319 0.1150 0.1023 0.0887 0.0823 0.0757 0.0722 0.0691 0.0671 0.0656 0.0645 0.0638 0.0632 0.0627 0.0622 0.0620 

[TRAIN] Epoch[1](11885/114412); Loss: 0.088517; Backpropagation: 0.3010 sec; Batch: 2.1250 sec
0.1715 0.1630 0.1185 0.0982 0.0839 0.0818 0.0775 0.0748 0.0724 0.0704 0.0694 0.0682 0.0675 0.0670 0.0664 0.0659 

[TRAIN] Epoch[1](11886/114412); Loss: 0.076129; Backpropagation: 0.3007 sec; Batch: 2.1260 sec
0.1384 0.1295 0.0980 0.0864 0.0785 0.0725 0.0693 0.0662 0.0644 0.0626 0.0612 0.0598 0.0590 0.0580 0.0574 0.0568 

[TRAIN] Epoch[1](11887/114412); Loss: 0.107538; Backpropagation: 0.2982 sec; Batch: 2.1025 sec
0.1480 0.1414 0.1203 0.1139 0.1094 0.1057 0.1037 0.1020 0.1003 0.0989 0.0978 0.0971 0.0963 0.0957 0.0955 0.0948 

[TRAIN] Epoch[1](11888/114412); Loss: 0.075505; Backpropagation: 0.2958 sec; Batch: 2.1194 sec
0.1238 0.1122 0.0899 0.0836 0.0777 0.0736 0.0709 0.0679 0.0667 0.0654 0.0643 0.0636 0.0630 0.0624 0.0617 0.0613 

[TRAIN] Epoch[1](11889/114412); Loss: 0.063336; Backpropagation: 0.2953 sec; Batch: 2.1214 sec
0.0993 0.0966 0.0868 0.0787 0.0694 0.0642 0.0593 0.0559 0.0542 0.0531 0.0514 0.0505 0.0495 0.0486 0.0482 0.0477 

[TRAIN] Epoch[1](11890/114412); Loss: 0.071078; Backpropagation: 0.2954 sec; Batch: 2.1221 sec
0.1342 0.1293 0.0987 0.0863 0.0744 0.0673 0.0630 0.0594 0.0573 0.0556 0.0542 0.0530 0.0520 0.0514 0.0509 0.0504 

[TRAIN] Epoch[1](11891/114412); Loss: 0.073359; Backpropagation: 0.2954 sec; Batch: 2.1217 sec
0.1427 0.1301 0.0976 0.0888 0.0769 0.0699 0.0648 0.0613 0.0594 0.0575 0.0562 0.0551 0.0542 0.0535 0.0530 0.0525 

[TRAIN] Epoch[1](11892/114412); Loss: 0.086183; Backpropagation: 0.2957 sec; Batch: 2.1234 sec
0.1484 0.1379 0.1074 0.0955 0.0865 0.0818 0.0787 0.0759 0.0743 0.0729 0.0717 0.0709 0.0701 0.0695 0.0689 0.0685 

[TRAIN] Epoch[1](11893/114412); Loss: 0.108355; Backpropagation: 0.2979 sec; Batch: 2.1273 sec
0.1856 0.1667 0.1393 0.1297 0.1150 0.1054 0.0988 0.0953 0.0927 0.0909 0.0888 0.0873 0.0859 0.0849 0.0839 0.0833 

[TRAIN] Epoch[1](11894/114412); Loss: 0.071420; Backpropagation: 0.2957 sec; Batch: 2.1204 sec
0.1209 0.1093 0.0941 0.0809 0.0743 0.0679 0.0659 0.0630 0.0610 0.0598 0.0587 0.0585 0.0577 0.0572 0.0570 0.0566 

[TRAIN] Epoch[1](11895/114412); Loss: 0.085683; Backpropagation: 0.2960 sec; Batch: 2.1213 sec
0.1373 0.1230 0.1026 0.0963 0.0893 0.0845 0.0807 0.0781 0.0761 0.0745 0.0733 0.0725 0.0716 0.0709 0.0704 0.0699 

[TRAIN] Epoch[1](11896/114412); Loss: 0.076377; Backpropagation: 0.2985 sec; Batch: 2.1239 sec
0.1471 0.1338 0.0973 0.0851 0.0780 0.0714 0.0681 0.0655 0.0637 0.0618 0.0606 0.0593 0.0585 0.0578 0.0573 0.0569 

[TRAIN] Epoch[1](11897/114412); Loss: 0.082492; Backpropagation: 0.3015 sec; Batch: 2.1253 sec
0.1688 0.1546 0.1194 0.1005 0.0899 0.0751 0.0712 0.0669 0.0643 0.0618 0.0605 0.0593 0.0579 0.0572 0.0565 0.0560 

[TRAIN] Epoch[1](11898/114412); Loss: 0.068006; Backpropagation: 0.3014 sec; Batch: 2.0903 sec
0.1094 0.0964 0.0817 0.0771 0.0700 0.0664 0.0636 0.0610 0.0599 0.0590 0.0583 0.0579 0.0572 0.0568 0.0567 0.0566 

[TRAIN] Epoch[1](11899/114412); Loss: 0.073908; Backpropagation: 0.3014 sec; Batch: 2.1239 sec
0.1430 0.1290 0.1004 0.0931 0.0831 0.0771 0.0702 0.0648 0.0602 0.0562 0.0540 0.0520 0.0511 0.0500 0.0494 0.0489 

[TRAIN] Epoch[1](11900/114412); Loss: 0.071375; Backpropagation: 0.3007 sec; Batch: 2.0886 sec
0.1531 0.1413 0.0863 0.0782 0.0750 0.0653 0.0624 0.0590 0.0570 0.0550 0.0537 0.0528 0.0516 0.0508 0.0505 0.0500 

[TRAIN] Epoch[1](11901/114412); Loss: 0.062390; Backpropagation: 0.2985 sec; Batch: 2.1052 sec
0.1188 0.1110 0.0799 0.0731 0.0650 0.0596 0.0555 0.0526 0.0506 0.0494 0.0486 0.0479 0.0471 0.0467 0.0463 0.0460 

[TRAIN] Epoch[1](11902/114412); Loss: 0.101566; Backpropagation: 0.3007 sec; Batch: 2.1069 sec
0.1582 0.1527 0.1182 0.1113 0.1049 0.0997 0.0952 0.0919 0.0894 0.0881 0.0873 0.0866 0.0860 0.0856 0.0851 0.0849 

[TRAIN] Epoch[1](11903/114412); Loss: 0.061874; Backpropagation: 0.3009 sec; Batch: 2.1256 sec
0.1255 0.1155 0.0845 0.0708 0.0616 0.0568 0.0531 0.0504 0.0490 0.0476 0.0467 0.0463 0.0459 0.0458 0.0454 0.0450 

[TRAIN] Epoch[1](11904/114412); Loss: 0.074605; Backpropagation: 0.2979 sec; Batch: 2.1227 sec
0.1337 0.1279 0.0915 0.0828 0.0739 0.0711 0.0678 0.0652 0.0631 0.0618 0.0608 0.0600 0.0592 0.0588 0.0582 0.0580 

[TRAIN] Epoch[1](11905/114412); Loss: 0.061317; Backpropagation: 0.2979 sec; Batch: 2.1225 sec
0.1324 0.1225 0.0863 0.0696 0.0610 0.0543 0.0513 0.0486 0.0472 0.0458 0.0448 0.0443 0.0437 0.0436 0.0430 0.0428 

[TRAIN] Epoch[1](11906/114412); Loss: 0.084148; Backpropagation: 0.2954 sec; Batch: 2.1195 sec
0.1462 0.1393 0.1142 0.0981 0.0861 0.0801 0.0769 0.0736 0.0708 0.0688 0.0675 0.0663 0.0655 0.0649 0.0644 0.0638 

[TRAIN] Epoch[1](11907/114412); Loss: 0.066469; Backpropagation: 0.2953 sec; Batch: 2.1227 sec
0.1148 0.1038 0.0838 0.0780 0.0706 0.0652 0.0617 0.0589 0.0571 0.0553 0.0541 0.0532 0.0525 0.0519 0.0515 0.0511 

[TRAIN] Epoch[1](11908/114412); Loss: 0.060448; Backpropagation: 0.2958 sec; Batch: 2.1214 sec
0.1030 0.0984 0.0837 0.0697 0.0628 0.0575 0.0548 0.0527 0.0510 0.0499 0.0487 0.0480 0.0472 0.0470 0.0465 0.0463 

[TRAIN] Epoch[1](11909/114412); Loss: 0.075687; Backpropagation: 0.2956 sec; Batch: 2.1218 sec
0.1218 0.1087 0.0924 0.0821 0.0779 0.0730 0.0703 0.0683 0.0673 0.0665 0.0654 0.0646 0.0639 0.0634 0.0630 0.0624 

[TRAIN] Epoch[1](11910/114412); Loss: 0.080608; Backpropagation: 0.2979 sec; Batch: 2.1235 sec
0.1383 0.1263 0.1048 0.0938 0.0861 0.0783 0.0735 0.0707 0.0687 0.0670 0.0655 0.0646 0.0638 0.0633 0.0628 0.0624 

[TRAIN] Epoch[1](11911/114412); Loss: 0.067659; Backpropagation: 0.2981 sec; Batch: 2.1214 sec
0.1618 0.1414 0.0834 0.0703 0.0695 0.0600 0.0567 0.0530 0.0517 0.0499 0.0490 0.0482 0.0476 0.0470 0.0467 0.0464 

[TRAIN] Epoch[1](11912/114412); Loss: 0.085781; Backpropagation: 0.2982 sec; Batch: 2.1026 sec
0.1690 0.1537 0.1104 0.0966 0.0854 0.0799 0.0762 0.0733 0.0710 0.0689 0.0671 0.0661 0.0647 0.0639 0.0633 0.0629 

[TRAIN] Epoch[1](11913/114412); Loss: 0.074712; Backpropagation: 0.3009 sec; Batch: 2.1185 sec
0.1413 0.1295 0.0995 0.0860 0.0753 0.0697 0.0666 0.0637 0.0617 0.0598 0.0588 0.0578 0.0570 0.0566 0.0562 0.0559 

[TRAIN] Epoch[1](11914/114412); Loss: 0.095246; Backpropagation: 0.3006 sec; Batch: 2.1264 sec
0.1909 0.1808 0.1389 0.1133 0.0950 0.0857 0.0801 0.0768 0.0746 0.0725 0.0711 0.0702 0.0693 0.0687 0.0683 0.0679 

[TRAIN] Epoch[1](11915/114412); Loss: 0.062669; Backpropagation: 0.2957 sec; Batch: 2.1213 sec
0.1250 0.1193 0.0864 0.0745 0.0668 0.0605 0.0556 0.0525 0.0496 0.0478 0.0460 0.0453 0.0441 0.0435 0.0430 0.0426 

[TRAIN] Epoch[1](11916/114412); Loss: 0.087215; Backpropagation: 0.2954 sec; Batch: 2.1208 sec
0.1255 0.1162 0.1101 0.0998 0.0925 0.0860 0.0833 0.0801 0.0784 0.0771 0.0760 0.0754 0.0746 0.0739 0.0734 0.0728 

[TRAIN] Epoch[1](11917/114412); Loss: 0.087998; Backpropagation: 0.2956 sec; Batch: 2.1259 sec
0.1392 0.1337 0.1109 0.0953 0.0893 0.0847 0.0813 0.0798 0.0773 0.0763 0.0752 0.0740 0.0735 0.0729 0.0723 0.0722 

[TRAIN] Epoch[1](11918/114412); Loss: 0.063766; Backpropagation: 0.2959 sec; Batch: 2.1265 sec
0.1246 0.1186 0.0872 0.0696 0.0621 0.0574 0.0548 0.0535 0.0518 0.0506 0.0493 0.0487 0.0482 0.0481 0.0480 0.0476 

[TRAIN] Epoch[1](11919/114412); Loss: 0.060893; Backpropagation: 0.2948 sec; Batch: 2.1206 sec
0.1199 0.1116 0.0781 0.0719 0.0638 0.0593 0.0539 0.0506 0.0488 0.0474 0.0465 0.0455 0.0450 0.0443 0.0440 0.0438 

[TRAIN] Epoch[1](11920/114412); Loss: 0.075136; Backpropagation: 0.2955 sec; Batch: 2.1026 sec
0.1336 0.1182 0.0963 0.0899 0.0794 0.0734 0.0690 0.0665 0.0637 0.0618 0.0605 0.0593 0.0583 0.0577 0.0574 0.0571 

[TRAIN] Epoch[1](11921/114412); Loss: 0.070394; Backpropagation: 0.2953 sec; Batch: 2.0827 sec
0.1311 0.1244 0.0815 0.0724 0.0712 0.0667 0.0636 0.0607 0.0595 0.0582 0.0572 0.0567 0.0561 0.0560 0.0556 0.0553 

[TRAIN] Epoch[1](11922/114412); Loss: 0.066381; Backpropagation: 0.2958 sec; Batch: 2.1207 sec
0.1352 0.1305 0.0788 0.0657 0.0609 0.0592 0.0575 0.0559 0.0546 0.0537 0.0530 0.0523 0.0517 0.0513 0.0509 0.0508 

[TRAIN] Epoch[1](11923/114412); Loss: 0.083627; Backpropagation: 0.2970 sec; Batch: 2.0847 sec
0.1396 0.1304 0.0987 0.0921 0.0857 0.0815 0.0784 0.0755 0.0731 0.0714 0.0704 0.0694 0.0686 0.0682 0.0676 0.0674 

[TRAIN] Epoch[1](11924/114412); Loss: 0.063433; Backpropagation: 0.2980 sec; Batch: 2.1246 sec
0.1424 0.1364 0.0910 0.0783 0.0663 0.0599 0.0528 0.0487 0.0458 0.0441 0.0430 0.0422 0.0416 0.0410 0.0408 0.0406 

[TRAIN] Epoch[1](11925/114412); Loss: 0.088772; Backpropagation: 0.2954 sec; Batch: 2.1202 sec
0.1481 0.1376 0.1069 0.0985 0.0910 0.0856 0.0821 0.0796 0.0775 0.0757 0.0745 0.0738 0.0731 0.0725 0.0721 0.0719 

[TRAIN] Epoch[1](11926/114412); Loss: 0.063892; Backpropagation: 0.2956 sec; Batch: 2.1214 sec
0.1197 0.1112 0.0799 0.0698 0.0645 0.0604 0.0567 0.0547 0.0529 0.0520 0.0514 0.0509 0.0502 0.0496 0.0494 0.0491 

[TRAIN] Epoch[1](11927/114412); Loss: 0.071075; Backpropagation: 0.2956 sec; Batch: 2.1254 sec
0.1490 0.1461 0.1027 0.0759 0.0656 0.0622 0.0593 0.0570 0.0557 0.0537 0.0528 0.0524 0.0519 0.0514 0.0508 0.0506 

[TRAIN] Epoch[1](11928/114412); Loss: 0.083956; Backpropagation: 0.2948 sec; Batch: 2.1252 sec
0.1556 0.1455 0.1085 0.0979 0.0841 0.0796 0.0748 0.0714 0.0691 0.0675 0.0663 0.0658 0.0651 0.0646 0.0640 0.0636 

[TRAIN] Epoch[1](11929/114412); Loss: 0.065812; Backpropagation: 0.2956 sec; Batch: 2.1187 sec
0.1176 0.1082 0.0835 0.0763 0.0694 0.0650 0.0610 0.0584 0.0558 0.0537 0.0526 0.0516 0.0508 0.0502 0.0496 0.0492 

[TRAIN] Epoch[1](11930/114412); Loss: 0.069510; Backpropagation: 0.2955 sec; Batch: 2.1251 sec
0.1333 0.1246 0.0892 0.0786 0.0728 0.0667 0.0625 0.0592 0.0561 0.0551 0.0539 0.0528 0.0523 0.0519 0.0516 0.0514 

[TRAIN] Epoch[1](11931/114412); Loss: 0.057944; Backpropagation: 0.2954 sec; Batch: 2.1183 sec
0.1303 0.1112 0.0759 0.0666 0.0601 0.0535 0.0486 0.0463 0.0444 0.0433 0.0423 0.0416 0.0413 0.0408 0.0407 0.0404 

[TRAIN] Epoch[1](11932/114412); Loss: 0.059409; Backpropagation: 0.2977 sec; Batch: 2.1229 sec
0.1117 0.1033 0.0766 0.0693 0.0614 0.0567 0.0539 0.0507 0.0487 0.0472 0.0465 0.0462 0.0454 0.0448 0.0443 0.0440 

[TRAIN] Epoch[1](11933/114412); Loss: 0.083283; Backpropagation: 0.2959 sec; Batch: 2.1200 sec
0.1323 0.1223 0.0952 0.0883 0.0834 0.0808 0.0788 0.0759 0.0748 0.0734 0.0726 0.0718 0.0713 0.0710 0.0704 0.0703 

[TRAIN] Epoch[1](11934/114412); Loss: 0.076960; Backpropagation: 0.2977 sec; Batch: 2.1239 sec
0.1348 0.1192 0.0970 0.0827 0.0762 0.0741 0.0696 0.0685 0.0668 0.0652 0.0642 0.0636 0.0631 0.0625 0.0621 0.0619 

[TRAIN] Epoch[1](11935/114412); Loss: 0.075728; Backpropagation: 0.2957 sec; Batch: 2.0845 sec
0.1510 0.1349 0.1042 0.0891 0.0781 0.0721 0.0678 0.0640 0.0615 0.0590 0.0574 0.0560 0.0553 0.0542 0.0536 0.0532 

[TRAIN] Epoch[1](11936/114412); Loss: 0.069691; Backpropagation: 0.2955 sec; Batch: 2.1206 sec
0.1379 0.1298 0.0938 0.0833 0.0698 0.0634 0.0603 0.0572 0.0552 0.0539 0.0532 0.0524 0.0517 0.0514 0.0510 0.0507 

[TRAIN] Epoch[1](11937/114412); Loss: 0.067884; Backpropagation: 0.2948 sec; Batch: 2.0818 sec
0.1140 0.1100 0.0899 0.0762 0.0675 0.0645 0.0614 0.0592 0.0579 0.0566 0.0560 0.0554 0.0548 0.0546 0.0543 0.0539 

[TRAIN] Epoch[1](11938/114412); Loss: 0.079954; Backpropagation: 0.2950 sec; Batch: 2.1217 sec
0.1326 0.1224 0.0999 0.0951 0.0860 0.0798 0.0733 0.0705 0.0680 0.0669 0.0659 0.0647 0.0641 0.0637 0.0635 0.0631 

[TRAIN] Epoch[1](11939/114412); Loss: 0.079418; Backpropagation: 0.2987 sec; Batch: 2.0940 sec
0.1300 0.1213 0.0979 0.0931 0.0850 0.0792 0.0742 0.0709 0.0690 0.0675 0.0659 0.0648 0.0639 0.0633 0.0627 0.0620 

[TRAIN] Epoch[1](11940/114412); Loss: 0.067386; Backpropagation: 0.2955 sec; Batch: 2.0828 sec
0.1466 0.1413 0.0820 0.0725 0.0640 0.0606 0.0558 0.0541 0.0524 0.0516 0.0508 0.0499 0.0494 0.0492 0.0490 0.0489 

[TRAIN] Epoch[1](11941/114412); Loss: 0.069083; Backpropagation: 0.2954 sec; Batch: 2.1257 sec
0.1432 0.1320 0.0922 0.0759 0.0669 0.0635 0.0597 0.0567 0.0547 0.0535 0.0525 0.0518 0.0512 0.0507 0.0505 0.0502 

[TRAIN] Epoch[1](11942/114412); Loss: 0.093948; Backpropagation: 0.2979 sec; Batch: 2.1277 sec
0.1951 0.1776 0.1392 0.1188 0.0991 0.0881 0.0802 0.0749 0.0717 0.0690 0.0671 0.0659 0.0652 0.0643 0.0637 0.0633 

[TRAIN] Epoch[1](11943/114412); Loss: 0.070425; Backpropagation: 0.2955 sec; Batch: 2.1235 sec
0.1463 0.1276 0.0949 0.0840 0.0738 0.0672 0.0613 0.0580 0.0554 0.0539 0.0524 0.0515 0.0507 0.0503 0.0499 0.0496 

[TRAIN] Epoch[1](11944/114412); Loss: 0.064403; Backpropagation: 0.2957 sec; Batch: 2.0857 sec
0.1030 0.0970 0.0857 0.0737 0.0672 0.0630 0.0598 0.0574 0.0559 0.0545 0.0536 0.0528 0.0521 0.0518 0.0515 0.0513 

[TRAIN] Epoch[1](11945/114412); Loss: 0.053081; Backpropagation: 0.2959 sec; Batch: 2.0827 sec
0.1186 0.1113 0.0842 0.0647 0.0510 0.0456 0.0438 0.0412 0.0394 0.0379 0.0367 0.0359 0.0352 0.0350 0.0345 0.0343 

[TRAIN] Epoch[1](11946/114412); Loss: 0.072842; Backpropagation: 0.2957 sec; Batch: 2.1212 sec
0.1569 0.1481 0.1027 0.0849 0.0734 0.0697 0.0638 0.0592 0.0554 0.0536 0.0524 0.0507 0.0496 0.0488 0.0482 0.0479 

[TRAIN] Epoch[1](11947/114412); Loss: 0.077544; Backpropagation: 0.3008 sec; Batch: 2.0886 sec
0.1325 0.1227 0.1012 0.0900 0.0820 0.0772 0.0727 0.0689 0.0659 0.0639 0.0624 0.0618 0.0607 0.0599 0.0597 0.0592 

[TRAIN] Epoch[1](11948/114412); Loss: 0.068727; Backpropagation: 0.2953 sec; Batch: 2.1285 sec
0.1867 0.1745 0.1134 0.0940 0.0733 0.0597 0.0538 0.0478 0.0436 0.0405 0.0383 0.0369 0.0356 0.0346 0.0337 0.0331 

[TRAIN] Epoch[1](11949/114412); Loss: 0.054601; Backpropagation: 0.2955 sec; Batch: 2.1180 sec
0.1097 0.1017 0.0727 0.0645 0.0568 0.0503 0.0465 0.0452 0.0438 0.0421 0.0411 0.0405 0.0400 0.0397 0.0396 0.0394 

[TRAIN] Epoch[1](11950/114412); Loss: 0.093773; Backpropagation: 0.2957 sec; Batch: 2.1240 sec
0.1370 0.1319 0.1169 0.1095 0.1009 0.0959 0.0906 0.0865 0.0835 0.0817 0.0802 0.0789 0.0779 0.0769 0.0762 0.0758 

[TRAIN] Epoch[1](11951/114412); Loss: 0.064928; Backpropagation: 0.2956 sec; Batch: 2.1201 sec
0.1193 0.1107 0.0862 0.0761 0.0678 0.0629 0.0590 0.0562 0.0540 0.0522 0.0509 0.0500 0.0491 0.0486 0.0482 0.0479 

[TRAIN] Epoch[1](11952/114412); Loss: 0.068445; Backpropagation: 0.2957 sec; Batch: 2.1266 sec
0.1417 0.1295 0.0947 0.0765 0.0684 0.0623 0.0598 0.0565 0.0545 0.0520 0.0509 0.0502 0.0497 0.0494 0.0494 0.0495 

[TRAIN] Epoch[1](11953/114412); Loss: 0.045829; Backpropagation: 0.2957 sec; Batch: 2.1215 sec
0.0965 0.0819 0.0604 0.0526 0.0462 0.0415 0.0386 0.0372 0.0364 0.0353 0.0351 0.0347 0.0345 0.0343 0.0340 0.0341 

[TRAIN] Epoch[1](11954/114412); Loss: 0.060579; Backpropagation: 0.2957 sec; Batch: 2.1238 sec
0.1167 0.1128 0.0807 0.0646 0.0617 0.0568 0.0530 0.0502 0.0489 0.0478 0.0473 0.0467 0.0461 0.0457 0.0452 0.0452 

[TRAIN] Epoch[1](11955/114412); Loss: 0.075625; Backpropagation: 0.2956 sec; Batch: 2.1203 sec
0.1279 0.1169 0.0952 0.0858 0.0789 0.0741 0.0708 0.0684 0.0657 0.0639 0.0623 0.0614 0.0605 0.0600 0.0592 0.0590 

[TRAIN] Epoch[1](11956/114412); Loss: 0.081377; Backpropagation: 0.2958 sec; Batch: 2.1258 sec
0.1558 0.1491 0.1101 0.0942 0.0826 0.0762 0.0715 0.0674 0.0651 0.0641 0.0629 0.0618 0.0609 0.0606 0.0600 0.0596 

[TRAIN] Epoch[1](11957/114412); Loss: 0.068932; Backpropagation: 0.2976 sec; Batch: 2.1231 sec
0.1362 0.1247 0.0946 0.0790 0.0719 0.0658 0.0628 0.0588 0.0554 0.0536 0.0522 0.0509 0.0501 0.0494 0.0489 0.0485 

[TRAIN] Epoch[1](11958/114412); Loss: 0.073251; Backpropagation: 0.2978 sec; Batch: 2.1259 sec
0.1360 0.1197 0.0989 0.0880 0.0792 0.0709 0.0667 0.0628 0.0600 0.0584 0.0571 0.0562 0.0554 0.0547 0.0542 0.0537 

[TRAIN] Epoch[1](11959/114412); Loss: 0.066329; Backpropagation: 0.3001 sec; Batch: 2.1285 sec
0.1638 0.1601 0.1054 0.0759 0.0631 0.0548 0.0519 0.0470 0.0451 0.0442 0.0431 0.0426 0.0416 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](11960/114412); Loss: 0.080947; Backpropagation: 0.2957 sec; Batch: 2.1207 sec
0.1610 0.1566 0.1067 0.0922 0.0775 0.0730 0.0678 0.0657 0.0643 0.0633 0.0625 0.0617 0.0612 0.0609 0.0606 0.0602 

[TRAIN] Epoch[1](11961/114412); Loss: 0.096971; Backpropagation: 0.2956 sec; Batch: 2.1224 sec
0.1738 0.1678 0.1281 0.1139 0.1015 0.0947 0.0880 0.0842 0.0808 0.0781 0.0761 0.0749 0.0736 0.0728 0.0720 0.0713 

[TRAIN] Epoch[1](11962/114412); Loss: 0.061958; Backpropagation: 0.2956 sec; Batch: 2.1213 sec
0.1360 0.1246 0.0862 0.0679 0.0583 0.0545 0.0509 0.0494 0.0476 0.0464 0.0456 0.0451 0.0448 0.0447 0.0447 0.0447 

[TRAIN] Epoch[1](11963/114412); Loss: 0.064361; Backpropagation: 0.2956 sec; Batch: 2.1220 sec
0.1367 0.1248 0.0761 0.0682 0.0642 0.0600 0.0559 0.0527 0.0518 0.0503 0.0494 0.0488 0.0484 0.0479 0.0474 0.0472 

[TRAIN] Epoch[1](11964/114412); Loss: 0.075437; Backpropagation: 0.2954 sec; Batch: 2.1230 sec
0.1414 0.1337 0.1004 0.0849 0.0749 0.0702 0.0668 0.0638 0.0620 0.0604 0.0593 0.0587 0.0581 0.0578 0.0575 0.0571 

[TRAIN] Epoch[1](11965/114412); Loss: 0.052705; Backpropagation: 0.2950 sec; Batch: 2.1192 sec
0.1064 0.0940 0.0707 0.0617 0.0552 0.0506 0.0479 0.0450 0.0425 0.0407 0.0398 0.0388 0.0381 0.0376 0.0373 0.0370 

[TRAIN] Epoch[1](11966/114412); Loss: 0.080500; Backpropagation: 0.2982 sec; Batch: 2.1208 sec
0.1410 0.1298 0.1001 0.0900 0.0824 0.0770 0.0735 0.0711 0.0693 0.0672 0.0662 0.0653 0.0646 0.0640 0.0634 0.0630 

[TRAIN] Epoch[1](11967/114412); Loss: 0.079628; Backpropagation: 0.2959 sec; Batch: 2.1199 sec
0.1289 0.1208 0.0989 0.0907 0.0833 0.0784 0.0747 0.0721 0.0698 0.0683 0.0667 0.0656 0.0647 0.0643 0.0637 0.0632 

[TRAIN] Epoch[1](11968/114412); Loss: 0.098745; Backpropagation: 0.2958 sec; Batch: 2.1243 sec
0.1549 0.1476 0.1277 0.1139 0.1031 0.0956 0.0922 0.0893 0.0869 0.0849 0.0832 0.0820 0.0809 0.0799 0.0792 0.0786 

[TRAIN] Epoch[1](11969/114412); Loss: 0.067267; Backpropagation: 0.3008 sec; Batch: 2.1279 sec
0.1254 0.1106 0.0820 0.0730 0.0670 0.0639 0.0606 0.0584 0.0570 0.0560 0.0550 0.0544 0.0537 0.0534 0.0531 0.0528 

[TRAIN] Epoch[1](11970/114412); Loss: 0.057982; Backpropagation: 0.2979 sec; Batch: 2.1225 sec
0.1161 0.1000 0.0715 0.0639 0.0590 0.0558 0.0522 0.0492 0.0475 0.0464 0.0456 0.0449 0.0444 0.0439 0.0438 0.0435 

[TRAIN] Epoch[1](11971/114412); Loss: 0.085007; Backpropagation: 0.2956 sec; Batch: 2.1193 sec
0.1587 0.1443 0.1160 0.1029 0.0903 0.0826 0.0753 0.0716 0.0697 0.0676 0.0658 0.0649 0.0637 0.0628 0.0622 0.0616 

[TRAIN] Epoch[1](11972/114412); Loss: 0.063920; Backpropagation: 0.2954 sec; Batch: 2.1181 sec
0.1303 0.1207 0.0937 0.0779 0.0645 0.0568 0.0551 0.0517 0.0501 0.0482 0.0472 0.0464 0.0457 0.0451 0.0448 0.0445 

[TRAIN] Epoch[1](11973/114412); Loss: 0.068427; Backpropagation: 0.2953 sec; Batch: 2.1181 sec
0.1274 0.1197 0.0847 0.0748 0.0681 0.0641 0.0610 0.0590 0.0573 0.0561 0.0551 0.0546 0.0539 0.0534 0.0529 0.0526 

[TRAIN] Epoch[1](11974/114412); Loss: 0.094121; Backpropagation: 0.2958 sec; Batch: 2.1216 sec
0.2193 0.2114 0.1443 0.1212 0.0922 0.0847 0.0735 0.0689 0.0663 0.0642 0.0627 0.0612 0.0601 0.0594 0.0585 0.0580 

[TRAIN] Epoch[1](11975/114412); Loss: 0.099977; Backpropagation: 0.2955 sec; Batch: 2.1188 sec
0.1624 0.1517 0.1163 0.1086 0.1020 0.0961 0.0929 0.0897 0.0882 0.0869 0.0858 0.0851 0.0843 0.0838 0.0831 0.0828 

[TRAIN] Epoch[1](11976/114412); Loss: 0.076540; Backpropagation: 0.2957 sec; Batch: 2.0834 sec
0.1600 0.1511 0.1051 0.0920 0.0763 0.0707 0.0645 0.0614 0.0592 0.0579 0.0561 0.0551 0.0544 0.0540 0.0536 0.0532 

[TRAIN] Epoch[1](11977/114412); Loss: 0.070146; Backpropagation: 0.2973 sec; Batch: 2.1213 sec
0.1192 0.1097 0.0927 0.0809 0.0708 0.0662 0.0632 0.0613 0.0599 0.0588 0.0578 0.0573 0.0566 0.0564 0.0559 0.0557 

[TRAIN] Epoch[1](11978/114412); Loss: 0.059347; Backpropagation: 0.2981 sec; Batch: 2.1262 sec
0.1052 0.1002 0.0783 0.0713 0.0622 0.0564 0.0535 0.0510 0.0495 0.0482 0.0470 0.0462 0.0457 0.0453 0.0449 0.0447 

[TRAIN] Epoch[1](11979/114412); Loss: 0.065029; Backpropagation: 0.2980 sec; Batch: 2.1220 sec
0.1128 0.1042 0.0817 0.0716 0.0667 0.0635 0.0592 0.0574 0.0555 0.0546 0.0537 0.0529 0.0524 0.0518 0.0514 0.0511 

[TRAIN] Epoch[1](11980/114412); Loss: 0.079013; Backpropagation: 0.2981 sec; Batch: 2.1230 sec
0.1422 0.1325 0.1101 0.0950 0.0837 0.0788 0.0720 0.0688 0.0652 0.0630 0.0613 0.0599 0.0589 0.0582 0.0576 0.0571 

[TRAIN] Epoch[1](11981/114412); Loss: 0.063913; Backpropagation: 0.2953 sec; Batch: 2.0872 sec
0.1449 0.1367 0.0845 0.0650 0.0617 0.0538 0.0518 0.0497 0.0486 0.0475 0.0471 0.0466 0.0464 0.0462 0.0461 0.0460 

[TRAIN] Epoch[1](11982/114412); Loss: 0.081026; Backpropagation: 0.2969 sec; Batch: 2.0841 sec
0.1542 0.1363 0.1053 0.0930 0.0844 0.0784 0.0740 0.0700 0.0672 0.0649 0.0636 0.0625 0.0615 0.0606 0.0603 0.0602 

[TRAIN] Epoch[1](11983/114412); Loss: 0.078134; Backpropagation: 0.2946 sec; Batch: 2.1169 sec
0.1594 0.1476 0.1076 0.0938 0.0822 0.0720 0.0666 0.0630 0.0610 0.0597 0.0582 0.0572 0.0562 0.0557 0.0552 0.0548 

[TRAIN] Epoch[1](11984/114412); Loss: 0.044598; Backpropagation: 0.3011 sec; Batch: 2.1286 sec
0.0866 0.0835 0.0645 0.0506 0.0461 0.0418 0.0391 0.0370 0.0354 0.0345 0.0338 0.0328 0.0322 0.0321 0.0318 0.0316 

[TRAIN] Epoch[1](11985/114412); Loss: 0.049707; Backpropagation: 0.2980 sec; Batch: 2.1259 sec
0.0910 0.0861 0.0658 0.0568 0.0504 0.0473 0.0445 0.0430 0.0419 0.0400 0.0393 0.0387 0.0381 0.0378 0.0375 0.0372 

[TRAIN] Epoch[1](11986/114412); Loss: 0.072322; Backpropagation: 0.2958 sec; Batch: 2.0828 sec
0.1430 0.1352 0.0974 0.0839 0.0716 0.0646 0.0609 0.0593 0.0576 0.0565 0.0557 0.0551 0.0547 0.0542 0.0538 0.0535 

[TRAIN] Epoch[1](11987/114412); Loss: 0.064593; Backpropagation: 0.2957 sec; Batch: 2.0823 sec
0.1229 0.1175 0.0808 0.0694 0.0656 0.0608 0.0571 0.0543 0.0528 0.0521 0.0514 0.0507 0.0501 0.0496 0.0493 0.0492 

[TRAIN] Epoch[1](11988/114412); Loss: 0.082238; Backpropagation: 0.2980 sec; Batch: 2.0852 sec
0.1521 0.1348 0.1036 0.0905 0.0819 0.0768 0.0735 0.0707 0.0692 0.0680 0.0672 0.0664 0.0659 0.0656 0.0651 0.0646 

[TRAIN] Epoch[1](11989/114412); Loss: 0.078740; Backpropagation: 0.3009 sec; Batch: 2.0886 sec
0.1255 0.1143 0.0951 0.0888 0.0812 0.0770 0.0740 0.0720 0.0704 0.0687 0.0675 0.0665 0.0656 0.0650 0.0644 0.0639 

[TRAIN] Epoch[1](11990/114412); Loss: 0.062063; Backpropagation: 0.2982 sec; Batch: 2.1274 sec
0.1258 0.1213 0.0930 0.0718 0.0636 0.0586 0.0547 0.0514 0.0490 0.0470 0.0454 0.0441 0.0429 0.0420 0.0415 0.0411 

[TRAIN] Epoch[1](11991/114412); Loss: 0.057999; Backpropagation: 0.2983 sec; Batch: 2.1010 sec
0.1363 0.1274 0.0819 0.0690 0.0579 0.0521 0.0480 0.0440 0.0427 0.0405 0.0398 0.0388 0.0381 0.0376 0.0371 0.0367 

[TRAIN] Epoch[1](11992/114412); Loss: 0.058573; Backpropagation: 0.2955 sec; Batch: 2.0816 sec
0.1166 0.0962 0.0810 0.0713 0.0615 0.0555 0.0520 0.0493 0.0474 0.0460 0.0450 0.0442 0.0435 0.0429 0.0425 0.0422 

[TRAIN] Epoch[1](11993/114412); Loss: 0.090310; Backpropagation: 0.2950 sec; Batch: 2.0853 sec
0.1357 0.1323 0.1121 0.1034 0.0959 0.0906 0.0860 0.0834 0.0808 0.0791 0.0772 0.0759 0.0746 0.0735 0.0727 0.0718 

[TRAIN] Epoch[1](11994/114412); Loss: 0.074595; Backpropagation: 0.2946 sec; Batch: 2.0816 sec
0.1301 0.1204 0.0929 0.0848 0.0776 0.0727 0.0680 0.0659 0.0635 0.0625 0.0611 0.0603 0.0594 0.0587 0.0581 0.0576 

[TRAIN] Epoch[1](11995/114412); Loss: 0.072847; Backpropagation: 0.2947 sec; Batch: 2.0846 sec
0.1283 0.1249 0.0937 0.0809 0.0743 0.0692 0.0657 0.0638 0.0616 0.0601 0.0592 0.0582 0.0573 0.0566 0.0561 0.0556 

[TRAIN] Epoch[1](11996/114412); Loss: 0.049817; Backpropagation: 0.2955 sec; Batch: 2.1214 sec
0.1271 0.1212 0.0702 0.0611 0.0514 0.0448 0.0395 0.0352 0.0333 0.0324 0.0314 0.0306 0.0301 0.0297 0.0297 0.0295 

[TRAIN] Epoch[1](11997/114412); Loss: 0.084415; Backpropagation: 0.2951 sec; Batch: 2.1016 sec
0.1473 0.1405 0.1195 0.1045 0.0922 0.0838 0.0761 0.0730 0.0701 0.0672 0.0652 0.0638 0.0630 0.0621 0.0615 0.0610 

[TRAIN] Epoch[1](11998/114412); Loss: 0.056572; Backpropagation: 0.2983 sec; Batch: 2.1241 sec
0.1193 0.1113 0.0719 0.0625 0.0576 0.0524 0.0488 0.0463 0.0448 0.0434 0.0426 0.0418 0.0411 0.0407 0.0403 0.0402 

[TRAIN] Epoch[1](11999/114412); Loss: 0.069307; Backpropagation: 0.2951 sec; Batch: 2.0817 sec
0.1292 0.1227 0.0970 0.0843 0.0733 0.0661 0.0613 0.0587 0.0563 0.0544 0.0532 0.0518 0.0512 0.0505 0.0498 0.0492 

[TRAIN] Epoch[1](12000/114412); Loss: 0.075174; Backpropagation: 0.2956 sec; Batch: 2.0835 sec
0.1592 0.1464 0.0989 0.0819 0.0720 0.0687 0.0639 0.0615 0.0593 0.0580 0.0572 0.0562 0.0554 0.0551 0.0547 0.0544 

[TRAIN] Epoch[1](12001/114412); Loss: 0.086199; Backpropagation: 0.2988 sec; Batch: 2.0862 sec
0.1518 0.1420 0.1107 0.0975 0.0878 0.0827 0.0796 0.0758 0.0734 0.0715 0.0698 0.0688 0.0679 0.0671 0.0667 0.0663 

[TRAIN] Epoch[1](12002/114412); Loss: 0.095830; Backpropagation: 0.3027 sec; Batch: 2.1335 sec
0.1697 0.1565 0.1240 0.1120 0.0994 0.0917 0.0876 0.0839 0.0813 0.0789 0.0771 0.0761 0.0751 0.0741 0.0732 0.0726 

[TRAIN] Epoch[1](12003/114412); Loss: 0.073969; Backpropagation: 0.2907 sec; Batch: 2.0781 sec
0.1481 0.1310 0.0935 0.0846 0.0738 0.0674 0.0641 0.0614 0.0598 0.0587 0.0579 0.0574 0.0568 0.0565 0.0562 0.0561 

[TRAIN] Epoch[1](12004/114412); Loss: 0.087311; Backpropagation: 0.2928 sec; Batch: 2.0993 sec
0.1759 0.1718 0.1308 0.1103 0.0881 0.0784 0.0738 0.0702 0.0671 0.0646 0.0631 0.0620 0.0612 0.0604 0.0599 0.0595 

[TRAIN] Epoch[1](12005/114412); Loss: 0.084895; Backpropagation: 0.2913 sec; Batch: 2.1218 sec
0.1947 0.1911 0.1346 0.1060 0.0778 0.0699 0.0672 0.0639 0.0613 0.0593 0.0575 0.0563 0.0555 0.0549 0.0545 0.0539 

[TRAIN] Epoch[1](12006/114412); Loss: 0.066399; Backpropagation: 0.2927 sec; Batch: 2.1188 sec
0.1177 0.1073 0.0862 0.0777 0.0689 0.0637 0.0600 0.0575 0.0558 0.0542 0.0534 0.0527 0.0524 0.0519 0.0517 0.0514 

[TRAIN] Epoch[1](12007/114412); Loss: 0.067541; Backpropagation: 0.2910 sec; Batch: 2.1155 sec
0.1442 0.1353 0.0889 0.0738 0.0673 0.0596 0.0565 0.0549 0.0538 0.0521 0.0508 0.0498 0.0492 0.0486 0.0480 0.0477 

[TRAIN] Epoch[1](12008/114412); Loss: 0.074591; Backpropagation: 0.2959 sec; Batch: 2.0813 sec
0.1440 0.1283 0.1005 0.0878 0.0776 0.0713 0.0671 0.0637 0.0614 0.0592 0.0575 0.0562 0.0555 0.0549 0.0544 0.0541 

[TRAIN] Epoch[1](12009/114412); Loss: 0.072171; Backpropagation: 0.2949 sec; Batch: 2.1218 sec
0.1686 0.1645 0.1190 0.0905 0.0685 0.0595 0.0612 0.0560 0.0536 0.0496 0.0478 0.0452 0.0443 0.0426 0.0422 0.0417 

[TRAIN] Epoch[1](12010/114412); Loss: 0.094705; Backpropagation: 0.2931 sec; Batch: 2.0800 sec
0.1756 0.1711 0.1452 0.1251 0.1084 0.0981 0.0891 0.0794 0.0743 0.0707 0.0680 0.0660 0.0632 0.0618 0.0603 0.0590 

[TRAIN] Epoch[1](12011/114412); Loss: 0.064445; Backpropagation: 0.2926 sec; Batch: 2.1166 sec
0.1134 0.1091 0.0862 0.0732 0.0640 0.0611 0.0583 0.0564 0.0543 0.0528 0.0517 0.0509 0.0507 0.0501 0.0496 0.0493 

[TRAIN] Epoch[1](12012/114412); Loss: 0.080034; Backpropagation: 0.2926 sec; Batch: 2.0827 sec
0.1600 0.1505 0.1172 0.1035 0.0865 0.0776 0.0704 0.0658 0.0613 0.0586 0.0567 0.0558 0.0551 0.0546 0.0539 0.0533 

[TRAIN] Epoch[1](12013/114412); Loss: 0.086586; Backpropagation: 0.2950 sec; Batch: 2.0828 sec
0.1603 0.1549 0.1204 0.1062 0.0906 0.0824 0.0773 0.0740 0.0712 0.0684 0.0666 0.0648 0.0637 0.0624 0.0616 0.0608 

[TRAIN] Epoch[1](12014/114412); Loss: 0.070251; Backpropagation: 0.2904 sec; Batch: 2.0843 sec
0.1372 0.1346 0.1018 0.0817 0.0676 0.0633 0.0605 0.0578 0.0556 0.0533 0.0524 0.0520 0.0518 0.0515 0.0514 0.0513 

[TRAIN] Epoch[1](12015/114412); Loss: 0.050220; Backpropagation: 0.2907 sec; Batch: 2.0978 sec
0.1011 0.0980 0.0711 0.0547 0.0508 0.0468 0.0430 0.0406 0.0396 0.0384 0.0375 0.0370 0.0366 0.0364 0.0362 0.0358 

[TRAIN] Epoch[1](12016/114412); Loss: 0.079214; Backpropagation: 0.2913 sec; Batch: 2.1175 sec
0.1302 0.1264 0.1031 0.0899 0.0784 0.0762 0.0725 0.0701 0.0681 0.0670 0.0657 0.0652 0.0643 0.0639 0.0635 0.0632 

[TRAIN] Epoch[1](12017/114412); Loss: 0.063024; Backpropagation: 0.2954 sec; Batch: 2.1193 sec
0.1395 0.1402 0.0977 0.0751 0.0591 0.0553 0.0507 0.0484 0.0461 0.0445 0.0433 0.0425 0.0421 0.0415 0.0413 0.0411 

[TRAIN] Epoch[1](12018/114412); Loss: 0.068383; Backpropagation: 0.2949 sec; Batch: 2.1206 sec
0.1152 0.1128 0.0874 0.0745 0.0667 0.0637 0.0618 0.0600 0.0586 0.0578 0.0570 0.0565 0.0560 0.0556 0.0554 0.0552 

[TRAIN] Epoch[1](12019/114412); Loss: 0.059008; Backpropagation: 0.2940 sec; Batch: 2.1241 sec
0.1136 0.0964 0.0805 0.0711 0.0625 0.0578 0.0538 0.0503 0.0481 0.0466 0.0455 0.0446 0.0440 0.0434 0.0430 0.0428 

[TRAIN] Epoch[1](12020/114412); Loss: 0.058181; Backpropagation: 0.2908 sec; Batch: 2.1197 sec
0.1342 0.1366 0.0956 0.0714 0.0513 0.0476 0.0464 0.0446 0.0418 0.0399 0.0383 0.0378 0.0370 0.0366 0.0360 0.0359 

[TRAIN] Epoch[1](12021/114412); Loss: 0.095295; Backpropagation: 0.2910 sec; Batch: 2.1146 sec
0.1400 0.1361 0.1158 0.1064 0.0987 0.0938 0.0912 0.0877 0.0855 0.0837 0.0827 0.0816 0.0810 0.0805 0.0801 0.0799 

[TRAIN] Epoch[1](12022/114412); Loss: 0.068937; Backpropagation: 0.2908 sec; Batch: 2.1176 sec
0.1232 0.1207 0.1014 0.0776 0.0670 0.0639 0.0612 0.0593 0.0568 0.0555 0.0542 0.0533 0.0527 0.0524 0.0520 0.0518 

[TRAIN] Epoch[1](12023/114412); Loss: 0.058940; Backpropagation: 0.2930 sec; Batch: 2.1194 sec
0.0948 0.0922 0.0733 0.0640 0.0617 0.0580 0.0552 0.0527 0.0514 0.0504 0.0495 0.0488 0.0483 0.0479 0.0475 0.0473 

[TRAIN] Epoch[1](12024/114412); Loss: 0.080202; Backpropagation: 0.2911 sec; Batch: 2.0770 sec
0.1381 0.1341 0.1127 0.0969 0.0850 0.0769 0.0717 0.0688 0.0665 0.0647 0.0633 0.0624 0.0614 0.0608 0.0602 0.0599 

[TRAIN] Epoch[1](12025/114412); Loss: 0.058109; Backpropagation: 0.2911 sec; Batch: 2.1167 sec
0.1210 0.1153 0.0951 0.0767 0.0620 0.0539 0.0497 0.0460 0.0433 0.0414 0.0398 0.0388 0.0376 0.0367 0.0363 0.0361 

[TRAIN] Epoch[1](12026/114412); Loss: 0.089302; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1350 0.1256 0.1026 0.0952 0.0911 0.0871 0.0853 0.0828 0.0816 0.0798 0.0789 0.0778 0.0772 0.0767 0.0761 0.0758 

[TRAIN] Epoch[1](12027/114412); Loss: 0.074360; Backpropagation: 0.2912 sec; Batch: 2.1145 sec
0.1705 0.1607 0.1122 0.0973 0.0791 0.0657 0.0571 0.0538 0.0519 0.0504 0.0498 0.0492 0.0487 0.0482 0.0477 0.0475 

[TRAIN] Epoch[1](12028/114412); Loss: 0.063938; Backpropagation: 0.2911 sec; Batch: 2.0761 sec
0.1049 0.0964 0.0805 0.0713 0.0657 0.0626 0.0593 0.0574 0.0555 0.0545 0.0537 0.0530 0.0525 0.0522 0.0518 0.0518 

[TRAIN] Epoch[1](12029/114412); Loss: 0.071258; Backpropagation: 0.2909 sec; Batch: 2.1150 sec
0.1112 0.1027 0.0856 0.0800 0.0754 0.0728 0.0687 0.0658 0.0633 0.0615 0.0606 0.0595 0.0590 0.0584 0.0580 0.0577 

[TRAIN] Epoch[1](12030/114412); Loss: 0.092547; Backpropagation: 0.2909 sec; Batch: 2.1141 sec
0.1560 0.1542 0.1238 0.1077 0.0955 0.0894 0.0854 0.0821 0.0789 0.0769 0.0748 0.0734 0.0720 0.0710 0.0702 0.0695 

[TRAIN] Epoch[1](12031/114412); Loss: 0.073869; Backpropagation: 0.2908 sec; Batch: 2.0763 sec
0.1307 0.1225 0.0942 0.0842 0.0757 0.0714 0.0683 0.0647 0.0625 0.0610 0.0598 0.0589 0.0579 0.0573 0.0566 0.0563 

[TRAIN] Epoch[1](12032/114412); Loss: 0.084803; Backpropagation: 0.2909 sec; Batch: 2.1083 sec
0.1457 0.1423 0.1150 0.1043 0.0906 0.0839 0.0767 0.0728 0.0698 0.0680 0.0667 0.0656 0.0647 0.0641 0.0635 0.0631 

[TRAIN] Epoch[1](12033/114412); Loss: 0.072927; Backpropagation: 0.2936 sec; Batch: 2.1188 sec
0.1359 0.1315 0.1077 0.0812 0.0723 0.0686 0.0643 0.0615 0.0590 0.0576 0.0561 0.0553 0.0546 0.0541 0.0538 0.0533 

[TRAIN] Epoch[1](12034/114412); Loss: 0.074088; Backpropagation: 0.2954 sec; Batch: 2.1232 sec
0.1248 0.1206 0.0945 0.0821 0.0719 0.0694 0.0672 0.0652 0.0641 0.0626 0.0618 0.0612 0.0605 0.0602 0.0598 0.0596 

[TRAIN] Epoch[1](12035/114412); Loss: 0.071651; Backpropagation: 0.2929 sec; Batch: 2.0790 sec
0.1143 0.1094 0.0852 0.0790 0.0723 0.0690 0.0669 0.0650 0.0634 0.0620 0.0612 0.0607 0.0600 0.0596 0.0593 0.0592 

[TRAIN] Epoch[1](12036/114412); Loss: 0.055728; Backpropagation: 0.2921 sec; Batch: 2.1166 sec
0.0972 0.0933 0.0716 0.0632 0.0579 0.0549 0.0529 0.0500 0.0480 0.0458 0.0447 0.0438 0.0428 0.0422 0.0419 0.0415 

[TRAIN] Epoch[1](12037/114412); Loss: 0.084543; Backpropagation: 0.2917 sec; Batch: 2.1336 sec
0.1650 0.1575 0.1268 0.1093 0.0897 0.0785 0.0720 0.0686 0.0653 0.0630 0.0618 0.0604 0.0595 0.0589 0.0584 0.0581 

[TRAIN] Epoch[1](12038/114412); Loss: 0.081531; Backpropagation: 0.2910 sec; Batch: 2.0765 sec
0.1345 0.1269 0.1028 0.0922 0.0847 0.0797 0.0765 0.0736 0.0712 0.0696 0.0677 0.0665 0.0655 0.0648 0.0643 0.0638 

[TRAIN] Epoch[1](12039/114412); Loss: 0.052627; Backpropagation: 0.2909 sec; Batch: 2.1228 sec
0.0950 0.0912 0.0724 0.0619 0.0527 0.0498 0.0470 0.0450 0.0434 0.0424 0.0416 0.0407 0.0403 0.0398 0.0395 0.0392 

[TRAIN] Epoch[1](12040/114412); Loss: 0.071723; Backpropagation: 0.2908 sec; Batch: 2.0767 sec
0.1606 0.1594 0.1193 0.0978 0.0758 0.0672 0.0593 0.0536 0.0513 0.0471 0.0454 0.0440 0.0426 0.0420 0.0413 0.0410 

[TRAIN] Epoch[1](12041/114412); Loss: 0.098497; Backpropagation: 0.2910 sec; Batch: 2.1255 sec
0.1469 0.1378 0.1196 0.1106 0.1009 0.0964 0.0928 0.0907 0.0888 0.0871 0.0859 0.0850 0.0843 0.0836 0.0831 0.0826 

[TRAIN] Epoch[1](12042/114412); Loss: 0.071202; Backpropagation: 0.2931 sec; Batch: 2.1158 sec
0.1386 0.1301 0.0958 0.0833 0.0730 0.0653 0.0624 0.0592 0.0576 0.0560 0.0551 0.0539 0.0531 0.0524 0.0519 0.0515 

[TRAIN] Epoch[1](12043/114412); Loss: 0.091866; Backpropagation: 0.2913 sec; Batch: 2.1204 sec
0.1334 0.1248 0.1077 0.1013 0.0949 0.0907 0.0875 0.0852 0.0834 0.0821 0.0812 0.0806 0.0799 0.0793 0.0790 0.0789 

[TRAIN] Epoch[1](12044/114412); Loss: 0.061325; Backpropagation: 0.2928 sec; Batch: 2.1192 sec
0.1012 0.0921 0.0765 0.0703 0.0631 0.0597 0.0573 0.0551 0.0534 0.0521 0.0513 0.0507 0.0502 0.0497 0.0494 0.0491 

[TRAIN] Epoch[1](12045/114412); Loss: 0.082550; Backpropagation: 0.2909 sec; Batch: 2.1190 sec
0.1358 0.1317 0.1108 0.0979 0.0872 0.0798 0.0758 0.0726 0.0703 0.0687 0.0675 0.0663 0.0653 0.0644 0.0636 0.0631 

[TRAIN] Epoch[1](12046/114412); Loss: 0.090882; Backpropagation: 0.2910 sec; Batch: 2.2826 sec
0.1520 0.1442 0.1176 0.1052 0.0936 0.0875 0.0837 0.0803 0.0782 0.0763 0.0749 0.0737 0.0728 0.0720 0.0714 0.0708 

[TRAIN] Epoch[1](12047/114412); Loss: 0.062525; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1116 0.1052 0.0840 0.0756 0.0658 0.0604 0.0558 0.0528 0.0511 0.0502 0.0494 0.0488 0.0481 0.0476 0.0473 0.0469 

[TRAIN] Epoch[1](12048/114412); Loss: 0.054933; Backpropagation: 0.2923 sec; Batch: 2.1000 sec
0.1094 0.0978 0.0714 0.0612 0.0567 0.0511 0.0489 0.0463 0.0449 0.0432 0.0425 0.0418 0.0414 0.0410 0.0407 0.0406 

[TRAIN] Epoch[1](12049/114412); Loss: 0.089494; Backpropagation: 0.2928 sec; Batch: 2.1192 sec
0.1341 0.1213 0.1104 0.1007 0.0941 0.0897 0.0854 0.0827 0.0809 0.0788 0.0778 0.0767 0.0756 0.0750 0.0745 0.0741 

[TRAIN] Epoch[1](12050/114412); Loss: 0.068296; Backpropagation: 0.2957 sec; Batch: 2.1064 sec
0.1275 0.1242 0.0998 0.0863 0.0727 0.0623 0.0590 0.0565 0.0547 0.0532 0.0510 0.0501 0.0496 0.0490 0.0486 0.0482 

[TRAIN] Epoch[1](12051/114412); Loss: 0.070240; Backpropagation: 0.2929 sec; Batch: 2.1188 sec
0.1634 0.1571 0.1058 0.0822 0.0659 0.0608 0.0568 0.0537 0.0510 0.0492 0.0479 0.0471 0.0465 0.0459 0.0454 0.0451 

[TRAIN] Epoch[1](12052/114412); Loss: 0.072888; Backpropagation: 0.2911 sec; Batch: 2.1186 sec
0.1184 0.1143 0.0932 0.0841 0.0750 0.0712 0.0677 0.0649 0.0632 0.0615 0.0605 0.0597 0.0589 0.0584 0.0577 0.0576 

[TRAIN] Epoch[1](12053/114412); Loss: 0.068900; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1668 0.1556 0.1108 0.0902 0.0718 0.0598 0.0529 0.0494 0.0473 0.0452 0.0440 0.0430 0.0422 0.0416 0.0410 0.0407 

[TRAIN] Epoch[1](12054/114412); Loss: 0.080339; Backpropagation: 0.2927 sec; Batch: 2.1183 sec
0.1461 0.1345 0.1056 0.0970 0.0854 0.0777 0.0725 0.0691 0.0669 0.0650 0.0636 0.0621 0.0611 0.0603 0.0596 0.0591 

[TRAIN] Epoch[1](12055/114412); Loss: 0.081725; Backpropagation: 0.2953 sec; Batch: 2.0895 sec
0.1345 0.1293 0.1094 0.0997 0.0901 0.0827 0.0771 0.0733 0.0700 0.0676 0.0657 0.0638 0.0624 0.0615 0.0606 0.0598 

[TRAIN] Epoch[1](12056/114412); Loss: 0.059173; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.1216 0.1101 0.0852 0.0683 0.0588 0.0539 0.0514 0.0493 0.0475 0.0459 0.0447 0.0435 0.0425 0.0419 0.0413 0.0410 

[TRAIN] Epoch[1](12057/114412); Loss: 0.080226; Backpropagation: 0.2908 sec; Batch: 2.1137 sec
0.1504 0.1479 0.1153 0.0939 0.0758 0.0753 0.0702 0.0671 0.0647 0.0631 0.0616 0.0608 0.0601 0.0594 0.0590 0.0587 

[TRAIN] Epoch[1](12058/114412); Loss: 0.072149; Backpropagation: 0.2975 sec; Batch: 2.1367 sec
0.1330 0.1221 0.0943 0.0850 0.0733 0.0688 0.0643 0.0619 0.0596 0.0584 0.0574 0.0566 0.0557 0.0551 0.0547 0.0543 

[TRAIN] Epoch[1](12059/114412); Loss: 0.055038; Backpropagation: 0.2952 sec; Batch: 2.0863 sec
0.1161 0.1051 0.0757 0.0643 0.0555 0.0502 0.0477 0.0449 0.0434 0.0419 0.0407 0.0400 0.0393 0.0388 0.0386 0.0382 

[TRAIN] Epoch[1](12060/114412); Loss: 0.076848; Backpropagation: 0.2918 sec; Batch: 2.0800 sec
0.1334 0.1258 0.0950 0.0848 0.0769 0.0723 0.0702 0.0674 0.0657 0.0643 0.0635 0.0627 0.0622 0.0621 0.0618 0.0615 

[TRAIN] Epoch[1](12061/114412); Loss: 0.083708; Backpropagation: 0.2910 sec; Batch: 2.1192 sec
0.1480 0.1411 0.1113 0.1000 0.0876 0.0810 0.0766 0.0731 0.0705 0.0680 0.0663 0.0651 0.0640 0.0630 0.0621 0.0616 

[TRAIN] Epoch[1](12062/114412); Loss: 0.069573; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1169 0.1105 0.0862 0.0759 0.0718 0.0673 0.0638 0.0617 0.0602 0.0588 0.0580 0.0572 0.0566 0.0563 0.0560 0.0561 

[TRAIN] Epoch[1](12063/114412); Loss: 0.081918; Backpropagation: 0.2912 sec; Batch: 2.1184 sec
0.1743 0.1704 0.1177 0.1035 0.0835 0.0747 0.0678 0.0643 0.0621 0.0599 0.0581 0.0568 0.0557 0.0547 0.0538 0.0533 

[TRAIN] Epoch[1](12064/114412); Loss: 0.085710; Backpropagation: 0.2912 sec; Batch: 2.1179 sec
0.1580 0.1557 0.1197 0.1026 0.0873 0.0794 0.0761 0.0716 0.0695 0.0674 0.0662 0.0650 0.0642 0.0633 0.0628 0.0625 

[TRAIN] Epoch[1](12065/114412); Loss: 0.087589; Backpropagation: 0.2910 sec; Batch: 2.1165 sec
0.2156 0.2021 0.1400 0.1157 0.0917 0.0782 0.0641 0.0594 0.0576 0.0558 0.0548 0.0539 0.0536 0.0531 0.0529 0.0527 

[TRAIN] Epoch[1](12066/114412); Loss: 0.105427; Backpropagation: 0.2910 sec; Batch: 2.1139 sec
0.1849 0.1775 0.1323 0.1142 0.1001 0.0953 0.0926 0.0909 0.0897 0.0886 0.0876 0.0872 0.0867 0.0867 0.0863 0.0862 

[TRAIN] Epoch[1](12067/114412); Loss: 0.111958; Backpropagation: 0.2945 sec; Batch: 2.1217 sec
0.2453 0.2406 0.1902 0.1668 0.1393 0.1129 0.0940 0.0812 0.0732 0.0684 0.0664 0.0650 0.0634 0.0623 0.0615 0.0608 

[TRAIN] Epoch[1](12068/114412); Loss: 0.062668; Backpropagation: 0.2909 sec; Batch: 2.1217 sec
0.1114 0.1048 0.0805 0.0716 0.0640 0.0593 0.0559 0.0540 0.0525 0.0513 0.0507 0.0501 0.0496 0.0493 0.0490 0.0487 

[TRAIN] Epoch[1](12069/114412); Loss: 0.061346; Backpropagation: 0.2910 sec; Batch: 2.1131 sec
0.1215 0.1113 0.0808 0.0700 0.0632 0.0565 0.0536 0.0512 0.0496 0.0481 0.0471 0.0467 0.0460 0.0456 0.0453 0.0451 

[TRAIN] Epoch[1](12070/114412); Loss: 0.067937; Backpropagation: 0.2909 sec; Batch: 2.1132 sec
0.1308 0.1250 0.0916 0.0732 0.0671 0.0642 0.0614 0.0575 0.0556 0.0538 0.0527 0.0518 0.0511 0.0506 0.0504 0.0502 

[TRAIN] Epoch[1](12071/114412); Loss: 0.091022; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1561 0.1472 0.1118 0.1026 0.0926 0.0866 0.0829 0.0800 0.0782 0.0767 0.0756 0.0745 0.0738 0.0731 0.0726 0.0722 

[TRAIN] Epoch[1](12072/114412); Loss: 0.079683; Backpropagation: 0.2950 sec; Batch: 2.1172 sec
0.1235 0.1164 0.1012 0.0914 0.0864 0.0819 0.0770 0.0741 0.0708 0.0685 0.0665 0.0653 0.0641 0.0633 0.0628 0.0618 

[TRAIN] Epoch[1](12073/114412); Loss: 0.083784; Backpropagation: 0.2924 sec; Batch: 2.1153 sec
0.1228 0.1161 0.0954 0.0915 0.0861 0.0828 0.0792 0.0774 0.0759 0.0750 0.0742 0.0735 0.0729 0.0727 0.0726 0.0723 

[TRAIN] Epoch[1](12074/114412); Loss: 0.114321; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.1861 0.1784 0.1479 0.1378 0.1221 0.1120 0.1057 0.1010 0.0982 0.0958 0.0938 0.0925 0.0909 0.0898 0.0891 0.0879 

[TRAIN] Epoch[1](12075/114412); Loss: 0.064923; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.1261 0.1195 0.0878 0.0734 0.0656 0.0604 0.0578 0.0543 0.0525 0.0508 0.0497 0.0491 0.0485 0.0481 0.0478 0.0476 

[TRAIN] Epoch[1](12076/114412); Loss: 0.086768; Backpropagation: 0.2905 sec; Batch: 2.1167 sec
0.1252 0.1188 0.1047 0.0934 0.0880 0.0860 0.0838 0.0806 0.0792 0.0775 0.0767 0.0758 0.0754 0.0749 0.0743 0.0740 

[TRAIN] Epoch[1](12077/114412); Loss: 0.076336; Backpropagation: 0.2925 sec; Batch: 2.1154 sec
0.1353 0.1265 0.0977 0.0851 0.0756 0.0717 0.0684 0.0663 0.0647 0.0633 0.0624 0.0616 0.0611 0.0609 0.0605 0.0602 

[TRAIN] Epoch[1](12078/114412); Loss: 0.076201; Backpropagation: 0.2929 sec; Batch: 2.1222 sec
0.1530 0.1414 0.1062 0.0891 0.0736 0.0690 0.0654 0.0619 0.0601 0.0585 0.0581 0.0576 0.0570 0.0564 0.0560 0.0559 

[TRAIN] Epoch[1](12079/114412); Loss: 0.098025; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.1425 0.1363 0.1163 0.1060 0.0987 0.0950 0.0929 0.0911 0.0894 0.0882 0.0872 0.0863 0.0855 0.0848 0.0844 0.0839 

[TRAIN] Epoch[1](12080/114412); Loss: 0.078493; Backpropagation: 0.2910 sec; Batch: 2.1257 sec
0.1624 0.1644 0.1173 0.0994 0.0829 0.0722 0.0639 0.0596 0.0568 0.0554 0.0546 0.0540 0.0536 0.0533 0.0530 0.0530 

[TRAIN] Epoch[1](12081/114412); Loss: 0.075235; Backpropagation: 0.2906 sec; Batch: 2.1093 sec
0.1096 0.1040 0.0924 0.0834 0.0785 0.0763 0.0730 0.0702 0.0681 0.0666 0.0651 0.0642 0.0636 0.0633 0.0628 0.0626 

[TRAIN] Epoch[1](12082/114412); Loss: 0.084103; Backpropagation: 0.2907 sec; Batch: 2.1134 sec
0.1373 0.1300 0.1050 0.0936 0.0853 0.0800 0.0774 0.0755 0.0737 0.0721 0.0709 0.0700 0.0693 0.0689 0.0685 0.0681 

[TRAIN] Epoch[1](12083/114412); Loss: 0.095503; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1704 0.1627 0.1294 0.1164 0.0987 0.0900 0.0843 0.0810 0.0785 0.0767 0.0751 0.0742 0.0733 0.0727 0.0725 0.0721 

[TRAIN] Epoch[1](12084/114412); Loss: 0.079038; Backpropagation: 0.2913 sec; Batch: 2.1277 sec
0.1598 0.1438 0.1042 0.0914 0.0793 0.0737 0.0706 0.0672 0.0645 0.0623 0.0605 0.0592 0.0583 0.0573 0.0565 0.0559 

[TRAIN] Epoch[1](12085/114412); Loss: 0.079764; Backpropagation: 0.2911 sec; Batch: 2.0961 sec
0.1504 0.1385 0.1055 0.0942 0.0829 0.0762 0.0722 0.0685 0.0660 0.0637 0.0623 0.0610 0.0598 0.0591 0.0583 0.0578 

[TRAIN] Epoch[1](12086/114412); Loss: 0.087498; Backpropagation: 0.2930 sec; Batch: 2.0801 sec
0.2085 0.1893 0.1281 0.1003 0.0823 0.0710 0.0668 0.0646 0.0631 0.0621 0.0614 0.0611 0.0606 0.0604 0.0603 0.0602 

[TRAIN] Epoch[1](12087/114412); Loss: 0.059438; Backpropagation: 0.2925 sec; Batch: 2.1164 sec
0.1216 0.1074 0.0832 0.0746 0.0621 0.0564 0.0512 0.0482 0.0466 0.0453 0.0442 0.0430 0.0423 0.0419 0.0416 0.0414 

[TRAIN] Epoch[1](12088/114412); Loss: 0.079969; Backpropagation: 0.2915 sec; Batch: 2.0765 sec
0.1467 0.1433 0.1092 0.0931 0.0789 0.0716 0.0697 0.0671 0.0657 0.0640 0.0632 0.0622 0.0618 0.0614 0.0610 0.0607 

[TRAIN] Epoch[1](12089/114412); Loss: 0.094059; Backpropagation: 0.2911 sec; Batch: 2.1175 sec
0.1505 0.1428 0.1184 0.1087 0.0989 0.0925 0.0880 0.0851 0.0821 0.0799 0.0784 0.0774 0.0766 0.0758 0.0751 0.0748 

[TRAIN] Epoch[1](12090/114412); Loss: 0.083006; Backpropagation: 0.2905 sec; Batch: 2.0839 sec
0.1738 0.1574 0.1110 0.0958 0.0849 0.0771 0.0723 0.0681 0.0654 0.0635 0.0621 0.0609 0.0598 0.0590 0.0588 0.0583 

[TRAIN] Epoch[1](12091/114412); Loss: 0.092789; Backpropagation: 0.2912 sec; Batch: 2.1149 sec
0.1647 0.1589 0.1228 0.1125 0.0979 0.0893 0.0843 0.0797 0.0767 0.0745 0.0729 0.0716 0.0706 0.0701 0.0692 0.0689 

[TRAIN] Epoch[1](12092/114412); Loss: 0.093573; Backpropagation: 0.2905 sec; Batch: 2.1175 sec
0.1518 0.1442 0.1097 0.1005 0.0958 0.0910 0.0872 0.0846 0.0825 0.0811 0.0800 0.0789 0.0782 0.0777 0.0771 0.0767 

[TRAIN] Epoch[1](12093/114412); Loss: 0.075259; Backpropagation: 0.2910 sec; Batch: 2.1091 sec
0.1270 0.1173 0.0975 0.0867 0.0781 0.0725 0.0681 0.0659 0.0644 0.0629 0.0622 0.0616 0.0606 0.0601 0.0596 0.0596 

[TRAIN] Epoch[1](12094/114412); Loss: 0.093031; Backpropagation: 0.2927 sec; Batch: 2.1197 sec
0.1970 0.1820 0.1397 0.1201 0.0994 0.0838 0.0762 0.0717 0.0689 0.0669 0.0655 0.0646 0.0639 0.0632 0.0629 0.0626 

[TRAIN] Epoch[1](12095/114412); Loss: 0.083561; Backpropagation: 0.2908 sec; Batch: 2.1147 sec
0.1334 0.1233 0.1038 0.0971 0.0874 0.0826 0.0773 0.0750 0.0732 0.0718 0.0706 0.0695 0.0688 0.0682 0.0677 0.0673 

[TRAIN] Epoch[1](12096/114412); Loss: 0.059908; Backpropagation: 0.2911 sec; Batch: 2.0990 sec
0.1129 0.1055 0.0791 0.0697 0.0616 0.0580 0.0544 0.0516 0.0498 0.0477 0.0466 0.0456 0.0448 0.0442 0.0437 0.0434 

[TRAIN] Epoch[1](12097/114412); Loss: 0.106342; Backpropagation: 0.2903 sec; Batch: 2.0768 sec
0.1922 0.1830 0.1380 0.1280 0.1119 0.1027 0.0949 0.0898 0.0868 0.0846 0.0836 0.0822 0.0818 0.0811 0.0806 0.0802 

[TRAIN] Epoch[1](12098/114412); Loss: 0.079072; Backpropagation: 0.2908 sec; Batch: 2.1242 sec
0.1293 0.1134 0.0935 0.0832 0.0797 0.0756 0.0729 0.0712 0.0702 0.0694 0.0686 0.0681 0.0678 0.0674 0.0674 0.0674 

[TRAIN] Epoch[1](12099/114412); Loss: 0.062494; Backpropagation: 0.2908 sec; Batch: 2.1143 sec
0.1381 0.1247 0.0940 0.0800 0.0623 0.0524 0.0524 0.0492 0.0476 0.0454 0.0444 0.0431 0.0425 0.0416 0.0414 0.0409 

[TRAIN] Epoch[1](12100/114412); Loss: 0.057002; Backpropagation: 0.2909 sec; Batch: 2.1138 sec
0.1428 0.1356 0.0943 0.0660 0.0495 0.0460 0.0423 0.0402 0.0395 0.0385 0.0376 0.0366 0.0362 0.0360 0.0356 0.0354 

[TRAIN] Epoch[1](12101/114412); Loss: 0.081147; Backpropagation: 0.2927 sec; Batch: 2.1145 sec
0.1209 0.1153 0.1001 0.0920 0.0849 0.0806 0.0768 0.0743 0.0723 0.0709 0.0699 0.0690 0.0684 0.0679 0.0676 0.0674 

[TRAIN] Epoch[1](12102/114412); Loss: 0.072731; Backpropagation: 0.2926 sec; Batch: 2.1255 sec
0.1225 0.1144 0.0883 0.0762 0.0743 0.0699 0.0681 0.0651 0.0635 0.0623 0.0615 0.0605 0.0599 0.0593 0.0590 0.0588 

[TRAIN] Epoch[1](12103/114412); Loss: 0.083664; Backpropagation: 0.2935 sec; Batch: 2.1209 sec
0.1347 0.1319 0.1052 0.0900 0.0838 0.0799 0.0771 0.0744 0.0731 0.0718 0.0709 0.0701 0.0694 0.0690 0.0688 0.0684 

[TRAIN] Epoch[1](12104/114412); Loss: 0.082976; Backpropagation: 0.2915 sec; Batch: 2.1070 sec
0.1696 0.1619 0.1303 0.1121 0.0937 0.0793 0.0711 0.0647 0.0613 0.0584 0.0568 0.0554 0.0545 0.0535 0.0527 0.0522 

[TRAIN] Epoch[1](12105/114412); Loss: 0.075497; Backpropagation: 0.2929 sec; Batch: 2.1241 sec
0.1569 0.1505 0.1066 0.0868 0.0713 0.0657 0.0618 0.0593 0.0583 0.0575 0.0566 0.0557 0.0555 0.0553 0.0551 0.0549 

[TRAIN] Epoch[1](12106/114412); Loss: 0.088391; Backpropagation: 0.2910 sec; Batch: 2.0787 sec
0.1475 0.1400 0.1155 0.1054 0.0923 0.0855 0.0803 0.0776 0.0753 0.0736 0.0723 0.0713 0.0703 0.0696 0.0690 0.0686 

[TRAIN] Epoch[1](12107/114412); Loss: 0.080211; Backpropagation: 0.2908 sec; Batch: 2.1172 sec
0.1486 0.1394 0.1080 0.0941 0.0831 0.0770 0.0723 0.0695 0.0670 0.0643 0.0627 0.0612 0.0602 0.0593 0.0586 0.0581 

[TRAIN] Epoch[1](12108/114412); Loss: 0.066487; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1398 0.1329 0.0921 0.0748 0.0629 0.0578 0.0555 0.0539 0.0524 0.0509 0.0500 0.0493 0.0485 0.0482 0.0476 0.0473 

[TRAIN] Epoch[1](12109/114412); Loss: 0.086995; Backpropagation: 0.2916 sec; Batch: 2.1162 sec
0.1818 0.1675 0.1218 0.1043 0.0909 0.0805 0.0738 0.0706 0.0675 0.0655 0.0640 0.0624 0.0614 0.0605 0.0599 0.0594 

[TRAIN] Epoch[1](12110/114412); Loss: 0.056162; Backpropagation: 0.2951 sec; Batch: 2.1226 sec
0.1291 0.1172 0.0827 0.0636 0.0560 0.0526 0.0480 0.0435 0.0418 0.0400 0.0390 0.0383 0.0373 0.0369 0.0364 0.0361 

[TRAIN] Epoch[1](12111/114412); Loss: 0.089507; Backpropagation: 0.2926 sec; Batch: 2.1165 sec
0.1849 0.1759 0.1203 0.1049 0.0868 0.0777 0.0738 0.0714 0.0699 0.0684 0.0676 0.0670 0.0662 0.0660 0.0657 0.0657 

[TRAIN] Epoch[1](12112/114412); Loss: 0.097503; Backpropagation: 0.2912 sec; Batch: 2.1192 sec
0.2199 0.2134 0.1465 0.1192 0.0951 0.0820 0.0758 0.0727 0.0715 0.0694 0.0679 0.0668 0.0658 0.0652 0.0647 0.0641 

[TRAIN] Epoch[1](12113/114412); Loss: 0.079554; Backpropagation: 0.2912 sec; Batch: 2.1172 sec
0.1337 0.1303 0.1016 0.0904 0.0807 0.0745 0.0710 0.0694 0.0681 0.0667 0.0659 0.0651 0.0646 0.0641 0.0636 0.0633 

[TRAIN] Epoch[1](12114/114412); Loss: 0.054426; Backpropagation: 0.2912 sec; Batch: 2.1182 sec
0.1130 0.1047 0.0798 0.0642 0.0554 0.0491 0.0459 0.0439 0.0419 0.0410 0.0398 0.0395 0.0385 0.0382 0.0380 0.0379 

[TRAIN] Epoch[1](12115/114412); Loss: 0.096549; Backpropagation: 0.2949 sec; Batch: 2.1244 sec
0.1621 0.1533 0.1241 0.1081 0.0978 0.0915 0.0868 0.0851 0.0834 0.0824 0.0810 0.0798 0.0786 0.0778 0.0768 0.0761 

[TRAIN] Epoch[1](12116/114412); Loss: 0.071464; Backpropagation: 0.2949 sec; Batch: 2.1192 sec
0.1164 0.1161 0.0845 0.0789 0.0711 0.0680 0.0659 0.0636 0.0624 0.0614 0.0607 0.0600 0.0592 0.0588 0.0585 0.0581 

[TRAIN] Epoch[1](12117/114412); Loss: 0.082899; Backpropagation: 0.2950 sec; Batch: 2.1198 sec
0.1556 0.1513 0.1181 0.1012 0.0841 0.0784 0.0731 0.0688 0.0663 0.0643 0.0629 0.0617 0.0613 0.0604 0.0597 0.0592 

[TRAIN] Epoch[1](12118/114412); Loss: 0.057901; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1258 0.1160 0.0800 0.0660 0.0578 0.0532 0.0508 0.0471 0.0452 0.0432 0.0419 0.0409 0.0402 0.0399 0.0395 0.0391 

[TRAIN] Epoch[1](12119/114412); Loss: 0.082166; Backpropagation: 0.2915 sec; Batch: 2.1190 sec
0.1233 0.1204 0.0997 0.0919 0.0832 0.0796 0.0767 0.0751 0.0733 0.0720 0.0711 0.0704 0.0700 0.0696 0.0693 0.0693 

[TRAIN] Epoch[1](12120/114412); Loss: 0.065881; Backpropagation: 0.2950 sec; Batch: 2.0826 sec
0.1094 0.1067 0.0863 0.0757 0.0684 0.0631 0.0597 0.0577 0.0560 0.0548 0.0539 0.0532 0.0528 0.0524 0.0521 0.0518 

[TRAIN] Epoch[1](12121/114412); Loss: 0.072548; Backpropagation: 0.2912 sec; Batch: 2.1157 sec
0.1286 0.1195 0.0934 0.0818 0.0729 0.0692 0.0655 0.0634 0.0613 0.0602 0.0590 0.0583 0.0576 0.0572 0.0566 0.0563 

[TRAIN] Epoch[1](12122/114412); Loss: 0.093800; Backpropagation: 0.2928 sec; Batch: 2.1312 sec
0.1405 0.1347 0.1165 0.1089 0.1001 0.0938 0.0886 0.0861 0.0833 0.0814 0.0801 0.0789 0.0780 0.0772 0.0765 0.0762 

[TRAIN] Epoch[1](12123/114412); Loss: 0.084039; Backpropagation: 0.2909 sec; Batch: 2.1189 sec
0.1431 0.1311 0.1065 0.0953 0.0848 0.0800 0.0765 0.0739 0.0725 0.0710 0.0699 0.0691 0.0683 0.0679 0.0675 0.0672 

[TRAIN] Epoch[1](12124/114412); Loss: 0.063857; Backpropagation: 0.2902 sec; Batch: 2.0926 sec
0.1256 0.1189 0.0905 0.0761 0.0647 0.0586 0.0566 0.0535 0.0511 0.0492 0.0478 0.0468 0.0461 0.0456 0.0454 0.0451 

[TRAIN] Epoch[1](12125/114412); Loss: 0.078280; Backpropagation: 0.2912 sec; Batch: 2.1151 sec
0.1291 0.1225 0.0974 0.0890 0.0806 0.0765 0.0724 0.0696 0.0676 0.0662 0.0653 0.0644 0.0639 0.0633 0.0626 0.0622 

[TRAIN] Epoch[1](12126/114412); Loss: 0.075207; Backpropagation: 0.2908 sec; Batch: 2.1172 sec
0.1259 0.1184 0.0938 0.0851 0.0770 0.0729 0.0696 0.0667 0.0649 0.0634 0.0624 0.0617 0.0611 0.0605 0.0601 0.0597 

[TRAIN] Epoch[1](12127/114412); Loss: 0.076925; Backpropagation: 0.2908 sec; Batch: 2.0804 sec
0.1253 0.1202 0.0958 0.0814 0.0771 0.0731 0.0704 0.0689 0.0677 0.0665 0.0655 0.0647 0.0643 0.0637 0.0633 0.0630 

[TRAIN] Epoch[1](12128/114412); Loss: 0.077718; Backpropagation: 0.2908 sec; Batch: 2.0785 sec
0.1290 0.1302 0.0980 0.0856 0.0801 0.0750 0.0702 0.0680 0.0664 0.0651 0.0640 0.0632 0.0626 0.0624 0.0620 0.0617 

[TRAIN] Epoch[1](12129/114412); Loss: 0.061339; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1214 0.1190 0.0868 0.0720 0.0626 0.0573 0.0529 0.0500 0.0477 0.0468 0.0454 0.0448 0.0442 0.0439 0.0435 0.0431 

[TRAIN] Epoch[1](12130/114412); Loss: 0.088098; Backpropagation: 0.2907 sec; Batch: 2.1178 sec
0.1736 0.1623 0.1176 0.1021 0.0871 0.0790 0.0764 0.0737 0.0714 0.0692 0.0683 0.0671 0.0664 0.0656 0.0652 0.0645 

[TRAIN] Epoch[1](12131/114412); Loss: 0.066460; Backpropagation: 0.2918 sec; Batch: 2.0799 sec
0.1305 0.1235 0.0840 0.0743 0.0685 0.0619 0.0584 0.0558 0.0540 0.0523 0.0514 0.0508 0.0502 0.0496 0.0493 0.0490 

[TRAIN] Epoch[1](12132/114412); Loss: 0.055538; Backpropagation: 0.2928 sec; Batch: 2.1198 sec
0.1012 0.0996 0.0785 0.0676 0.0590 0.0531 0.0481 0.0458 0.0447 0.0435 0.0427 0.0418 0.0411 0.0408 0.0406 0.0405 

[TRAIN] Epoch[1](12133/114412); Loss: 0.073509; Backpropagation: 0.2906 sec; Batch: 2.1123 sec
0.1412 0.1319 0.0950 0.0860 0.0754 0.0685 0.0644 0.0618 0.0599 0.0585 0.0573 0.0563 0.0556 0.0551 0.0548 0.0544 

[TRAIN] Epoch[1](12134/114412); Loss: 0.053885; Backpropagation: 0.2905 sec; Batch: 2.0836 sec
0.1273 0.1174 0.0816 0.0620 0.0513 0.0479 0.0447 0.0423 0.0393 0.0378 0.0365 0.0359 0.0353 0.0348 0.0342 0.0339 

[TRAIN] Epoch[1](12135/114412); Loss: 0.057891; Backpropagation: 0.2913 sec; Batch: 2.1217 sec
0.1236 0.1158 0.0797 0.0683 0.0575 0.0536 0.0498 0.0470 0.0451 0.0435 0.0422 0.0412 0.0406 0.0400 0.0395 0.0389 

[TRAIN] Epoch[1](12136/114412); Loss: 0.071654; Backpropagation: 0.2913 sec; Batch: 2.1158 sec
0.1442 0.1424 0.1026 0.0879 0.0733 0.0651 0.0607 0.0572 0.0548 0.0534 0.0524 0.0515 0.0510 0.0504 0.0500 0.0498 

[TRAIN] Epoch[1](12137/114412); Loss: 0.078631; Backpropagation: 0.2911 sec; Batch: 2.1156 sec
0.1394 0.1356 0.1055 0.0884 0.0772 0.0732 0.0694 0.0672 0.0658 0.0645 0.0635 0.0626 0.0620 0.0618 0.0611 0.0608 

[TRAIN] Epoch[1](12138/114412); Loss: 0.065558; Backpropagation: 0.2946 sec; Batch: 2.0900 sec
0.1470 0.1392 0.1016 0.0822 0.0663 0.0582 0.0544 0.0510 0.0480 0.0461 0.0445 0.0436 0.0426 0.0419 0.0415 0.0411 

[TRAIN] Epoch[1](12139/114412); Loss: 0.072866; Backpropagation: 0.2909 sec; Batch: 2.0798 sec
0.1406 0.1331 0.1001 0.0877 0.0763 0.0692 0.0652 0.0614 0.0586 0.0568 0.0553 0.0540 0.0529 0.0521 0.0515 0.0510 

[TRAIN] Epoch[1](12140/114412); Loss: 0.064511; Backpropagation: 0.2911 sec; Batch: 2.1136 sec
0.1342 0.1199 0.0891 0.0728 0.0637 0.0592 0.0558 0.0525 0.0513 0.0500 0.0488 0.0479 0.0474 0.0470 0.0465 0.0461 

[TRAIN] Epoch[1](12141/114412); Loss: 0.065188; Backpropagation: 0.2914 sec; Batch: 2.1131 sec
0.1217 0.1163 0.0787 0.0715 0.0654 0.0603 0.0575 0.0554 0.0546 0.0535 0.0525 0.0517 0.0514 0.0510 0.0508 0.0505 

[TRAIN] Epoch[1](12142/114412); Loss: 0.081604; Backpropagation: 0.2908 sec; Batch: 2.1021 sec
0.1527 0.1463 0.1073 0.0924 0.0800 0.0750 0.0724 0.0698 0.0678 0.0659 0.0644 0.0634 0.0628 0.0622 0.0618 0.0615 

[TRAIN] Epoch[1](12143/114412); Loss: 0.070205; Backpropagation: 0.2908 sec; Batch: 2.1176 sec
0.1421 0.1349 0.1018 0.0831 0.0676 0.0636 0.0601 0.0571 0.0552 0.0539 0.0529 0.0518 0.0509 0.0500 0.0494 0.0488 

[TRAIN] Epoch[1](12144/114412); Loss: 0.070597; Backpropagation: 0.2914 sec; Batch: 2.1227 sec
0.1453 0.1360 0.0886 0.0806 0.0761 0.0670 0.0638 0.0579 0.0556 0.0538 0.0524 0.0516 0.0510 0.0504 0.0499 0.0496 

[TRAIN] Epoch[1](12145/114412); Loss: 0.070572; Backpropagation: 0.2923 sec; Batch: 2.1393 sec
0.1746 0.1663 0.1119 0.0839 0.0656 0.0578 0.0539 0.0510 0.0490 0.0474 0.0465 0.0455 0.0448 0.0442 0.0435 0.0433 

[TRAIN] Epoch[1](12146/114412); Loss: 0.057056; Backpropagation: 0.2947 sec; Batch: 2.0983 sec
0.1107 0.1058 0.0787 0.0595 0.0566 0.0523 0.0493 0.0470 0.0460 0.0450 0.0445 0.0441 0.0437 0.0434 0.0432 0.0430 

[TRAIN] Epoch[1](12147/114412); Loss: 0.071252; Backpropagation: 0.2953 sec; Batch: 2.0913 sec
0.1292 0.1208 0.0950 0.0800 0.0714 0.0675 0.0638 0.0612 0.0593 0.0582 0.0574 0.0565 0.0556 0.0551 0.0547 0.0544 

[TRAIN] Epoch[1](12148/114412); Loss: 0.073589; Backpropagation: 0.2924 sec; Batch: 2.1228 sec
0.1328 0.1234 0.0987 0.0850 0.0736 0.0706 0.0654 0.0630 0.0610 0.0594 0.0584 0.0579 0.0575 0.0572 0.0569 0.0568 

[TRAIN] Epoch[1](12149/114412); Loss: 0.067703; Backpropagation: 0.2916 sec; Batch: 2.0792 sec
0.1131 0.1108 0.0855 0.0736 0.0678 0.0652 0.0627 0.0602 0.0584 0.0574 0.0564 0.0555 0.0549 0.0544 0.0538 0.0536 

[TRAIN] Epoch[1](12150/114412); Loss: 0.098790; Backpropagation: 0.2912 sec; Batch: 2.0764 sec
0.1855 0.1790 0.1422 0.1224 0.1051 0.0929 0.0876 0.0828 0.0793 0.0765 0.0743 0.0726 0.0714 0.0704 0.0695 0.0691 

[TRAIN] Epoch[1](12151/114412); Loss: 0.064151; Backpropagation: 0.2914 sec; Batch: 2.0779 sec
0.1335 0.1249 0.0774 0.0690 0.0658 0.0608 0.0561 0.0541 0.0529 0.0507 0.0486 0.0475 0.0470 0.0463 0.0459 0.0459 

[TRAIN] Epoch[1](12152/114412); Loss: 0.079146; Backpropagation: 0.2955 sec; Batch: 2.1214 sec
0.1224 0.1178 0.0978 0.0873 0.0801 0.0764 0.0735 0.0714 0.0701 0.0690 0.0681 0.0673 0.0669 0.0665 0.0661 0.0658 

[TRAIN] Epoch[1](12153/114412); Loss: 0.065435; Backpropagation: 0.2930 sec; Batch: 2.1196 sec
0.1203 0.1145 0.0821 0.0728 0.0645 0.0615 0.0585 0.0566 0.0548 0.0535 0.0525 0.0519 0.0515 0.0509 0.0506 0.0504 

[TRAIN] Epoch[1](12154/114412); Loss: 0.083131; Backpropagation: 0.2933 sec; Batch: 2.1493 sec
0.1506 0.1451 0.1102 0.0965 0.0836 0.0793 0.0753 0.0718 0.0692 0.0676 0.0660 0.0645 0.0635 0.0628 0.0623 0.0618 

[TRAIN] Epoch[1](12155/114412); Loss: 0.062691; Backpropagation: 0.2914 sec; Batch: 2.1195 sec
0.1447 0.1412 0.1095 0.0859 0.0651 0.0547 0.0511 0.0459 0.0430 0.0404 0.0390 0.0377 0.0370 0.0364 0.0359 0.0356 

[TRAIN] Epoch[1](12156/114412); Loss: 0.077257; Backpropagation: 0.2912 sec; Batch: 2.1216 sec
0.1390 0.1321 0.1008 0.0894 0.0774 0.0732 0.0697 0.0669 0.0646 0.0628 0.0617 0.0607 0.0602 0.0595 0.0592 0.0588 

[TRAIN] Epoch[1](12157/114412); Loss: 0.067355; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1409 0.1346 0.0994 0.0832 0.0690 0.0611 0.0573 0.0543 0.0518 0.0501 0.0482 0.0470 0.0463 0.0455 0.0448 0.0441 

[TRAIN] Epoch[1](12158/114412); Loss: 0.069041; Backpropagation: 0.2912 sec; Batch: 2.0969 sec
0.1271 0.1176 0.0854 0.0752 0.0687 0.0638 0.0620 0.0600 0.0583 0.0573 0.0562 0.0555 0.0549 0.0545 0.0542 0.0539 

[TRAIN] Epoch[1](12159/114412); Loss: 0.079897; Backpropagation: 0.2914 sec; Batch: 2.1132 sec
0.1254 0.1188 0.1016 0.0886 0.0838 0.0787 0.0753 0.0723 0.0700 0.0686 0.0676 0.0667 0.0662 0.0654 0.0649 0.0644 

[TRAIN] Epoch[1](12160/114412); Loss: 0.060874; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1295 0.1079 0.0771 0.0679 0.0631 0.0564 0.0525 0.0503 0.0495 0.0476 0.0468 0.0460 0.0453 0.0450 0.0447 0.0445 

[TRAIN] Epoch[1](12161/114412); Loss: 0.066859; Backpropagation: 0.2914 sec; Batch: 2.1225 sec
0.1188 0.1149 0.0895 0.0783 0.0701 0.0656 0.0613 0.0580 0.0560 0.0542 0.0525 0.0514 0.0506 0.0499 0.0495 0.0491 

[TRAIN] Epoch[1](12162/114412); Loss: 0.099234; Backpropagation: 0.2910 sec; Batch: 2.1163 sec
0.1823 0.1694 0.1227 0.1090 0.0955 0.0911 0.0879 0.0858 0.0840 0.0825 0.0812 0.0804 0.0799 0.0792 0.0786 0.0782 

[TRAIN] Epoch[1](12163/114412); Loss: 0.074147; Backpropagation: 0.2907 sec; Batch: 2.1130 sec
0.1201 0.1122 0.0939 0.0830 0.0763 0.0722 0.0693 0.0668 0.0653 0.0638 0.0626 0.0617 0.0607 0.0600 0.0594 0.0589 

[TRAIN] Epoch[1](12164/114412); Loss: 0.071258; Backpropagation: 0.2928 sec; Batch: 2.1155 sec
0.1445 0.1368 0.1054 0.0866 0.0699 0.0633 0.0605 0.0582 0.0553 0.0537 0.0526 0.0518 0.0511 0.0505 0.0501 0.0498 

[TRAIN] Epoch[1](12165/114412); Loss: 0.074295; Backpropagation: 0.2907 sec; Batch: 2.1163 sec
0.1416 0.1328 0.0997 0.0859 0.0739 0.0676 0.0647 0.0624 0.0609 0.0593 0.0583 0.0573 0.0566 0.0561 0.0559 0.0555 

[TRAIN] Epoch[1](12166/114412); Loss: 0.078218; Backpropagation: 0.2906 sec; Batch: 2.1173 sec
0.1346 0.1253 0.0996 0.0877 0.0796 0.0752 0.0714 0.0687 0.0670 0.0652 0.0643 0.0638 0.0630 0.0624 0.0619 0.0616 

[TRAIN] Epoch[1](12167/114412); Loss: 0.076167; Backpropagation: 0.2911 sec; Batch: 2.0771 sec
0.1422 0.1281 0.1006 0.0864 0.0766 0.0718 0.0678 0.0658 0.0637 0.0623 0.0608 0.0599 0.0590 0.0583 0.0579 0.0574 

[TRAIN] Epoch[1](12168/114412); Loss: 0.081890; Backpropagation: 0.2915 sec; Batch: 2.1147 sec
0.1528 0.1450 0.1099 0.0968 0.0864 0.0764 0.0712 0.0684 0.0662 0.0645 0.0635 0.0628 0.0622 0.0617 0.0613 0.0611 

[TRAIN] Epoch[1](12169/114412); Loss: 0.067116; Backpropagation: 0.2909 sec; Batch: 2.0778 sec
0.1368 0.1254 0.0971 0.0762 0.0642 0.0611 0.0578 0.0545 0.0525 0.0518 0.0510 0.0501 0.0496 0.0488 0.0486 0.0485 

[TRAIN] Epoch[1](12170/114412); Loss: 0.060326; Backpropagation: 0.2914 sec; Batch: 2.0776 sec
0.1409 0.1272 0.0888 0.0765 0.0611 0.0574 0.0488 0.0460 0.0444 0.0434 0.0413 0.0392 0.0383 0.0376 0.0374 0.0370 

[TRAIN] Epoch[1](12171/114412); Loss: 0.054203; Backpropagation: 0.2914 sec; Batch: 2.1217 sec
0.1252 0.1237 0.0819 0.0620 0.0533 0.0477 0.0432 0.0407 0.0389 0.0377 0.0370 0.0360 0.0355 0.0352 0.0347 0.0345 

[TRAIN] Epoch[1](12172/114412); Loss: 0.084682; Backpropagation: 0.2909 sec; Batch: 2.1174 sec
0.1547 0.1437 0.1068 0.0913 0.0851 0.0799 0.0763 0.0736 0.0719 0.0701 0.0688 0.0678 0.0670 0.0665 0.0659 0.0656 

[TRAIN] Epoch[1](12173/114412); Loss: 0.069525; Backpropagation: 0.2905 sec; Batch: 2.1173 sec
0.1343 0.1164 0.0914 0.0754 0.0693 0.0638 0.0609 0.0585 0.0574 0.0568 0.0559 0.0553 0.0548 0.0545 0.0540 0.0538 

[TRAIN] Epoch[1](12174/114412); Loss: 0.083403; Backpropagation: 0.2931 sec; Batch: 2.1194 sec
0.1471 0.1396 0.1147 0.1008 0.0912 0.0822 0.0765 0.0716 0.0686 0.0664 0.0648 0.0636 0.0627 0.0620 0.0614 0.0612 

[TRAIN] Epoch[1](12175/114412); Loss: 0.060101; Backpropagation: 0.2920 sec; Batch: 2.1049 sec
0.1246 0.1099 0.0875 0.0727 0.0625 0.0576 0.0535 0.0500 0.0471 0.0449 0.0439 0.0426 0.0419 0.0415 0.0409 0.0406 

[TRAIN] Epoch[1](12176/114412); Loss: 0.100353; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1878 0.1755 0.1381 0.1175 0.1041 0.0961 0.0904 0.0852 0.0823 0.0801 0.0776 0.0762 0.0749 0.0740 0.0732 0.0726 

[TRAIN] Epoch[1](12177/114412); Loss: 0.081932; Backpropagation: 0.2930 sec; Batch: 2.1214 sec
0.1338 0.1229 0.1007 0.0934 0.0855 0.0811 0.0782 0.0741 0.0729 0.0705 0.0691 0.0676 0.0664 0.0656 0.0649 0.0642 

[TRAIN] Epoch[1](12178/114412); Loss: 0.082032; Backpropagation: 0.2930 sec; Batch: 2.1239 sec
0.1346 0.1282 0.1067 0.0941 0.0815 0.0747 0.0736 0.0718 0.0708 0.0694 0.0686 0.0683 0.0679 0.0676 0.0675 0.0673 

[TRAIN] Epoch[1](12179/114412); Loss: 0.062198; Backpropagation: 0.2952 sec; Batch: 2.1030 sec
0.1072 0.0982 0.0806 0.0709 0.0660 0.0618 0.0582 0.0557 0.0530 0.0511 0.0498 0.0491 0.0488 0.0484 0.0482 0.0481 

[TRAIN] Epoch[1](12180/114412); Loss: 0.087222; Backpropagation: 0.2928 sec; Batch: 2.1233 sec
0.1561 0.1455 0.1094 0.0959 0.0870 0.0822 0.0795 0.0764 0.0739 0.0726 0.0710 0.0702 0.0696 0.0690 0.0687 0.0684 

[TRAIN] Epoch[1](12181/114412); Loss: 0.078011; Backpropagation: 0.2905 sec; Batch: 2.0791 sec
0.1573 0.1482 0.1050 0.0848 0.0772 0.0688 0.0661 0.0640 0.0620 0.0611 0.0601 0.0594 0.0590 0.0587 0.0584 0.0582 

[TRAIN] Epoch[1](12182/114412); Loss: 0.056899; Backpropagation: 0.2954 sec; Batch: 2.1152 sec
0.1106 0.1062 0.0702 0.0616 0.0554 0.0527 0.0496 0.0477 0.0463 0.0454 0.0448 0.0444 0.0442 0.0440 0.0437 0.0436 

[TRAIN] Epoch[1](12183/114412); Loss: 0.076258; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.1544 0.1439 0.1038 0.0887 0.0768 0.0693 0.0651 0.0626 0.0604 0.0586 0.0575 0.0568 0.0561 0.0558 0.0554 0.0550 

[TRAIN] Epoch[1](12184/114412); Loss: 0.057562; Backpropagation: 0.2909 sec; Batch: 2.1147 sec
0.1104 0.0960 0.0761 0.0660 0.0589 0.0542 0.0513 0.0493 0.0476 0.0463 0.0454 0.0447 0.0443 0.0438 0.0435 0.0433 

[TRAIN] Epoch[1](12185/114412); Loss: 0.066517; Backpropagation: 0.2908 sec; Batch: 2.1139 sec
0.1507 0.1447 0.1056 0.0837 0.0640 0.0565 0.0531 0.0497 0.0481 0.0465 0.0454 0.0445 0.0438 0.0431 0.0426 0.0422 

[TRAIN] Epoch[1](12186/114412); Loss: 0.069130; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1327 0.1303 0.0955 0.0797 0.0708 0.0644 0.0611 0.0576 0.0553 0.0535 0.0524 0.0517 0.0510 0.0504 0.0500 0.0497 

[TRAIN] Epoch[1](12187/114412); Loss: 0.085445; Backpropagation: 0.2911 sec; Batch: 2.1752 sec
0.1899 0.1723 0.1276 0.1111 0.0932 0.0797 0.0697 0.0644 0.0625 0.0595 0.0580 0.0568 0.0563 0.0559 0.0554 0.0548 

[TRAIN] Epoch[1](12188/114412); Loss: 0.076796; Backpropagation: 0.2912 sec; Batch: 2.1191 sec
0.1562 0.1463 0.0978 0.0826 0.0749 0.0698 0.0667 0.0640 0.0621 0.0606 0.0596 0.0587 0.0580 0.0576 0.0571 0.0568 

[TRAIN] Epoch[1](12189/114412); Loss: 0.057522; Backpropagation: 0.2910 sec; Batch: 2.1181 sec
0.1289 0.1204 0.0872 0.0726 0.0584 0.0510 0.0466 0.0444 0.0424 0.0406 0.0396 0.0388 0.0382 0.0375 0.0371 0.0368 

[TRAIN] Epoch[1](12190/114412); Loss: 0.069766; Backpropagation: 0.2906 sec; Batch: 2.0783 sec
0.1297 0.1223 0.0956 0.0820 0.0730 0.0670 0.0628 0.0593 0.0570 0.0552 0.0538 0.0530 0.0524 0.0516 0.0510 0.0505 

[TRAIN] Epoch[1](12191/114412); Loss: 0.085647; Backpropagation: 0.2906 sec; Batch: 2.1208 sec
0.1796 0.1622 0.1117 0.0939 0.0886 0.0793 0.0765 0.0734 0.0700 0.0662 0.0643 0.0628 0.0621 0.0607 0.0598 0.0594 

[TRAIN] Epoch[1](12192/114412); Loss: 0.092779; Backpropagation: 0.2930 sec; Batch: 2.1029 sec
0.1614 0.1593 0.1201 0.1061 0.0912 0.0852 0.0831 0.0809 0.0792 0.0774 0.0760 0.0744 0.0735 0.0726 0.0722 0.0718 

[TRAIN] Epoch[1](12193/114412); Loss: 0.081954; Backpropagation: 0.2933 sec; Batch: 2.0988 sec
0.1507 0.1366 0.1056 0.0957 0.0864 0.0797 0.0743 0.0710 0.0694 0.0670 0.0654 0.0639 0.0628 0.0618 0.0609 0.0601 

[TRAIN] Epoch[1](12194/114412); Loss: 0.064571; Backpropagation: 0.2914 sec; Batch: 2.1159 sec
0.1450 0.1390 0.1020 0.0815 0.0667 0.0580 0.0519 0.0477 0.0458 0.0444 0.0434 0.0425 0.0417 0.0414 0.0412 0.0409 

[TRAIN] Epoch[1](12195/114412); Loss: 0.077806; Backpropagation: 0.2917 sec; Batch: 2.1126 sec
0.1487 0.1362 0.0912 0.0840 0.0776 0.0730 0.0701 0.0678 0.0658 0.0641 0.0632 0.0620 0.0612 0.0605 0.0600 0.0595 

[TRAIN] Epoch[1](12196/114412); Loss: 0.075270; Backpropagation: 0.2955 sec; Batch: 2.1219 sec
0.1265 0.1213 0.0911 0.0820 0.0758 0.0722 0.0692 0.0671 0.0656 0.0639 0.0631 0.0625 0.0616 0.0611 0.0609 0.0605 

[TRAIN] Epoch[1](12197/114412); Loss: 0.056177; Backpropagation: 0.2910 sec; Batch: 2.1170 sec
0.1019 0.0972 0.0709 0.0624 0.0583 0.0546 0.0519 0.0493 0.0472 0.0458 0.0446 0.0438 0.0433 0.0428 0.0425 0.0423 

[TRAIN] Epoch[1](12198/114412); Loss: 0.063719; Backpropagation: 0.2910 sec; Batch: 2.0887 sec
0.1341 0.1323 0.0911 0.0774 0.0625 0.0565 0.0533 0.0503 0.0486 0.0473 0.0457 0.0450 0.0444 0.0439 0.0437 0.0435 

[TRAIN] Epoch[1](12199/114412); Loss: 0.073893; Backpropagation: 0.2909 sec; Batch: 2.1182 sec
0.1407 0.1279 0.0929 0.0835 0.0729 0.0683 0.0654 0.0629 0.0614 0.0601 0.0591 0.0586 0.0578 0.0573 0.0569 0.0565 

[TRAIN] Epoch[1](12200/114412); Loss: 0.080087; Backpropagation: 0.2911 sec; Batch: 2.1162 sec
0.1607 0.1512 0.1095 0.0966 0.0828 0.0743 0.0684 0.0647 0.0631 0.0614 0.0600 0.0590 0.0582 0.0576 0.0572 0.0568 

[TRAIN] Epoch[1](12201/114412); Loss: 0.072363; Backpropagation: 0.2928 sec; Batch: 2.1165 sec
0.1531 0.1414 0.1042 0.0908 0.0758 0.0660 0.0604 0.0575 0.0556 0.0537 0.0522 0.0512 0.0500 0.0492 0.0487 0.0480 

[TRAIN] Epoch[1](12202/114412); Loss: 0.083236; Backpropagation: 0.2914 sec; Batch: 2.1168 sec
0.1342 0.1289 0.1068 0.0967 0.0893 0.0834 0.0790 0.0756 0.0728 0.0702 0.0686 0.0671 0.0659 0.0650 0.0644 0.0637 

[TRAIN] Epoch[1](12203/114412); Loss: 0.059913; Backpropagation: 0.2913 sec; Batch: 2.1221 sec
0.1174 0.1062 0.0745 0.0683 0.0621 0.0572 0.0532 0.0505 0.0486 0.0477 0.0466 0.0459 0.0455 0.0451 0.0449 0.0447 

[TRAIN] Epoch[1](12204/114412); Loss: 0.076622; Backpropagation: 0.2913 sec; Batch: 2.3671 sec
0.1511 0.1403 0.1052 0.0913 0.0818 0.0728 0.0677 0.0639 0.0615 0.0593 0.0575 0.0565 0.0554 0.0547 0.0538 0.0531 

[TRAIN] Epoch[1](12205/114412); Loss: 0.067382; Backpropagation: 0.2917 sec; Batch: 2.0777 sec
0.1757 0.1648 0.1128 0.0812 0.0633 0.0548 0.0503 0.0478 0.0453 0.0434 0.0422 0.0408 0.0399 0.0392 0.0385 0.0381 

[TRAIN] Epoch[1](12206/114412); Loss: 0.089057; Backpropagation: 0.2926 sec; Batch: 2.0837 sec
0.1507 0.1379 0.1111 0.1019 0.0956 0.0886 0.0836 0.0805 0.0763 0.0743 0.0728 0.0719 0.0710 0.0703 0.0696 0.0691 

[TRAIN] Epoch[1](12207/114412); Loss: 0.080088; Backpropagation: 0.2913 sec; Batch: 2.1220 sec
0.1875 0.1756 0.1259 0.0958 0.0770 0.0670 0.0627 0.0595 0.0577 0.0565 0.0546 0.0537 0.0531 0.0522 0.0517 0.0510 

[TRAIN] Epoch[1](12208/114412); Loss: 0.072904; Backpropagation: 0.2915 sec; Batch: 2.1176 sec
0.1426 0.1382 0.1000 0.0848 0.0745 0.0680 0.0637 0.0605 0.0585 0.0568 0.0555 0.0543 0.0533 0.0525 0.0519 0.0514 

[TRAIN] Epoch[1](12209/114412); Loss: 0.095089; Backpropagation: 0.2916 sec; Batch: 2.0796 sec
0.1427 0.1338 0.1106 0.1020 0.0967 0.0929 0.0904 0.0879 0.0859 0.0848 0.0835 0.0826 0.0822 0.0819 0.0816 0.0817 

[TRAIN] Epoch[1](12210/114412); Loss: 0.071897; Backpropagation: 0.2914 sec; Batch: 2.1185 sec
0.1316 0.1264 0.0931 0.0849 0.0753 0.0699 0.0646 0.0617 0.0593 0.0576 0.0561 0.0552 0.0545 0.0538 0.0534 0.0530 

[TRAIN] Epoch[1](12211/114412); Loss: 0.060966; Backpropagation: 0.2906 sec; Batch: 2.0802 sec
0.1170 0.1054 0.0806 0.0699 0.0615 0.0578 0.0535 0.0512 0.0499 0.0487 0.0481 0.0471 0.0467 0.0463 0.0460 0.0458 

[TRAIN] Epoch[1](12212/114412); Loss: 0.070908; Backpropagation: 0.2912 sec; Batch: 2.0836 sec
0.1216 0.1140 0.0878 0.0806 0.0713 0.0675 0.0647 0.0621 0.0605 0.0593 0.0586 0.0581 0.0575 0.0572 0.0569 0.0567 

[TRAIN] Epoch[1](12213/114412); Loss: 0.084427; Backpropagation: 0.2915 sec; Batch: 2.0885 sec
0.1401 0.1231 0.1034 0.0962 0.0880 0.0833 0.0792 0.0763 0.0741 0.0727 0.0715 0.0703 0.0692 0.0685 0.0678 0.0673 

[TRAIN] Epoch[1](12214/114412); Loss: 0.079985; Backpropagation: 0.2912 sec; Batch: 2.1246 sec
0.1428 0.1330 0.1015 0.0903 0.0828 0.0776 0.0727 0.0692 0.0671 0.0656 0.0645 0.0638 0.0629 0.0624 0.0619 0.0617 

[TRAIN] Epoch[1](12215/114412); Loss: 0.073036; Backpropagation: 0.2952 sec; Batch: 2.0821 sec
0.1315 0.1214 0.0956 0.0856 0.0765 0.0712 0.0671 0.0637 0.0613 0.0594 0.0580 0.0567 0.0560 0.0553 0.0549 0.0544 

[TRAIN] Epoch[1](12216/114412); Loss: 0.080932; Backpropagation: 0.2953 sec; Batch: 2.1254 sec
0.1944 0.1849 0.1284 0.0992 0.0765 0.0653 0.0610 0.0589 0.0571 0.0550 0.0540 0.0531 0.0525 0.0519 0.0515 0.0513 

[TRAIN] Epoch[1](12217/114412); Loss: 0.068680; Backpropagation: 0.2931 sec; Batch: 2.1178 sec
0.1283 0.1134 0.0850 0.0718 0.0691 0.0648 0.0617 0.0595 0.0583 0.0572 0.0562 0.0556 0.0551 0.0546 0.0543 0.0541 

[TRAIN] Epoch[1](12218/114412); Loss: 0.057362; Backpropagation: 0.2931 sec; Batch: 2.1196 sec
0.0966 0.0902 0.0737 0.0662 0.0592 0.0553 0.0525 0.0511 0.0493 0.0481 0.0474 0.0465 0.0461 0.0456 0.0451 0.0448 

[TRAIN] Epoch[1](12219/114412); Loss: 0.075596; Backpropagation: 0.2907 sec; Batch: 2.1194 sec
0.1372 0.1263 0.1093 0.0917 0.0773 0.0694 0.0659 0.0632 0.0618 0.0604 0.0593 0.0587 0.0580 0.0575 0.0569 0.0568 

[TRAIN] Epoch[1](12220/114412); Loss: 0.082367; Backpropagation: 0.2910 sec; Batch: 2.1168 sec
0.1488 0.1416 0.1024 0.0901 0.0814 0.0777 0.0741 0.0714 0.0696 0.0683 0.0672 0.0663 0.0656 0.0651 0.0644 0.0639 

[TRAIN] Epoch[1](12221/114412); Loss: 0.072988; Backpropagation: 0.2927 sec; Batch: 2.1201 sec
0.1339 0.1216 0.0984 0.0830 0.0736 0.0687 0.0653 0.0628 0.0609 0.0594 0.0581 0.0573 0.0568 0.0564 0.0559 0.0558 

[TRAIN] Epoch[1](12222/114412); Loss: 0.063668; Backpropagation: 0.2910 sec; Batch: 2.1140 sec
0.1154 0.1022 0.0821 0.0684 0.0644 0.0601 0.0571 0.0557 0.0543 0.0533 0.0525 0.0515 0.0509 0.0505 0.0503 0.0502 

[TRAIN] Epoch[1](12223/114412); Loss: 0.071938; Backpropagation: 0.2952 sec; Batch: 2.1226 sec
0.1390 0.1296 0.1029 0.0872 0.0744 0.0644 0.0607 0.0585 0.0568 0.0554 0.0547 0.0542 0.0539 0.0534 0.0531 0.0528 

[TRAIN] Epoch[1](12224/114412); Loss: 0.060408; Backpropagation: 0.2915 sec; Batch: 2.0976 sec
0.1136 0.1066 0.0833 0.0677 0.0602 0.0571 0.0544 0.0513 0.0501 0.0485 0.0471 0.0463 0.0458 0.0453 0.0448 0.0444 

[TRAIN] Epoch[1](12225/114412); Loss: 0.082516; Backpropagation: 0.2907 sec; Batch: 2.0777 sec
0.1384 0.1306 0.1074 0.0964 0.0877 0.0811 0.0756 0.0719 0.0704 0.0689 0.0673 0.0661 0.0656 0.0648 0.0642 0.0639 

[TRAIN] Epoch[1](12226/114412); Loss: 0.088963; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.1803 0.1717 0.1277 0.1051 0.0878 0.0813 0.0762 0.0729 0.0701 0.0678 0.0661 0.0649 0.0637 0.0630 0.0625 0.0622 

[TRAIN] Epoch[1](12227/114412); Loss: 0.057209; Backpropagation: 0.2905 sec; Batch: 2.1172 sec
0.1340 0.1270 0.0871 0.0656 0.0546 0.0486 0.0461 0.0428 0.0410 0.0400 0.0393 0.0388 0.0381 0.0377 0.0375 0.0371 

[TRAIN] Epoch[1](12228/114412); Loss: 0.090097; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1643 0.1575 0.1299 0.1109 0.0992 0.0881 0.0795 0.0726 0.0709 0.0689 0.0684 0.0676 0.0667 0.0661 0.0656 0.0653 

[TRAIN] Epoch[1](12229/114412); Loss: 0.057765; Backpropagation: 0.2912 sec; Batch: 2.1163 sec
0.1262 0.1243 0.0853 0.0702 0.0588 0.0516 0.0467 0.0445 0.0422 0.0411 0.0400 0.0394 0.0390 0.0385 0.0382 0.0382 

[TRAIN] Epoch[1](12230/114412); Loss: 0.079649; Backpropagation: 0.2911 sec; Batch: 2.1189 sec
0.1360 0.1275 0.1041 0.0903 0.0820 0.0768 0.0726 0.0698 0.0679 0.0667 0.0654 0.0644 0.0636 0.0629 0.0624 0.0620 

[TRAIN] Epoch[1](12231/114412); Loss: 0.107494; Backpropagation: 0.2930 sec; Batch: 2.1193 sec
0.1751 0.1638 0.1350 0.1270 0.1137 0.1055 0.1010 0.0965 0.0940 0.0919 0.0890 0.0879 0.0866 0.0850 0.0843 0.0835 

[TRAIN] Epoch[1](12232/114412); Loss: 0.073894; Backpropagation: 0.2911 sec; Batch: 2.1195 sec
0.1589 0.1501 0.1074 0.0826 0.0755 0.0677 0.0619 0.0590 0.0568 0.0548 0.0532 0.0522 0.0514 0.0507 0.0502 0.0498 

[TRAIN] Epoch[1](12233/114412); Loss: 0.081457; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1388 0.1326 0.1051 0.0961 0.0851 0.0798 0.0751 0.0720 0.0687 0.0669 0.0657 0.0649 0.0640 0.0632 0.0628 0.0626 

[TRAIN] Epoch[1](12234/114412); Loss: 0.095501; Backpropagation: 0.2911 sec; Batch: 2.1261 sec
0.1826 0.1781 0.1391 0.1198 0.1037 0.0912 0.0824 0.0774 0.0735 0.0725 0.0706 0.0693 0.0681 0.0671 0.0666 0.0660 

[TRAIN] Epoch[1](12235/114412); Loss: 0.074310; Backpropagation: 0.2929 sec; Batch: 2.0799 sec
0.1237 0.1170 0.0918 0.0835 0.0752 0.0707 0.0678 0.0659 0.0640 0.0630 0.0622 0.0616 0.0611 0.0608 0.0605 0.0602 

[TRAIN] Epoch[1](12236/114412); Loss: 0.093557; Backpropagation: 0.2908 sec; Batch: 2.1184 sec
0.1516 0.1495 0.1163 0.1022 0.0929 0.0885 0.0862 0.0838 0.0818 0.0803 0.0792 0.0782 0.0773 0.0769 0.0764 0.0760 

[TRAIN] Epoch[1](12237/114412); Loss: 0.072516; Backpropagation: 0.2908 sec; Batch: 2.1178 sec
0.1589 0.1531 0.1088 0.0884 0.0700 0.0654 0.0606 0.0571 0.0543 0.0521 0.0506 0.0494 0.0485 0.0481 0.0477 0.0473 

[TRAIN] Epoch[1](12238/114412); Loss: 0.114486; Backpropagation: 0.2912 sec; Batch: 2.1180 sec
0.1595 0.1515 0.1389 0.1256 0.1194 0.1152 0.1117 0.1081 0.1056 0.1036 0.1017 0.1002 0.0990 0.0981 0.0973 0.0964 

[TRAIN] Epoch[1](12239/114412); Loss: 0.093875; Backpropagation: 0.2914 sec; Batch: 2.0818 sec
0.1562 0.1469 0.1173 0.1028 0.0965 0.0892 0.0858 0.0827 0.0813 0.0802 0.0787 0.0778 0.0772 0.0767 0.0765 0.0761 

[TRAIN] Epoch[1](12240/114412); Loss: 0.072565; Backpropagation: 0.2915 sec; Batch: 2.0893 sec
0.1599 0.1577 0.1104 0.0810 0.0654 0.0591 0.0591 0.0555 0.0541 0.0531 0.0523 0.0517 0.0509 0.0506 0.0502 0.0499 

[TRAIN] Epoch[1](12241/114412); Loss: 0.092709; Backpropagation: 0.2904 sec; Batch: 2.1198 sec
0.1603 0.1538 0.1259 0.1136 0.1008 0.0908 0.0848 0.0792 0.0755 0.0738 0.0726 0.0717 0.0711 0.0705 0.0698 0.0692 

[TRAIN] Epoch[1](12242/114412); Loss: 0.063639; Backpropagation: 0.2913 sec; Batch: 2.1190 sec
0.1469 0.1367 0.0991 0.0773 0.0650 0.0581 0.0527 0.0490 0.0463 0.0444 0.0424 0.0414 0.0409 0.0400 0.0392 0.0388 

[TRAIN] Epoch[1](12243/114412); Loss: 0.054780; Backpropagation: 0.2906 sec; Batch: 2.1203 sec
0.1198 0.1154 0.0785 0.0606 0.0512 0.0493 0.0459 0.0437 0.0420 0.0405 0.0396 0.0389 0.0383 0.0380 0.0374 0.0373 

[TRAIN] Epoch[1](12244/114412); Loss: 0.075796; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1508 0.1407 0.0970 0.0840 0.0760 0.0697 0.0646 0.0625 0.0616 0.0602 0.0588 0.0579 0.0575 0.0573 0.0571 0.0569 

[TRAIN] Epoch[1](12245/114412); Loss: 0.087830; Backpropagation: 0.2911 sec; Batch: 2.1158 sec
0.1586 0.1480 0.1198 0.1051 0.0905 0.0831 0.0784 0.0756 0.0733 0.0710 0.0692 0.0679 0.0672 0.0663 0.0657 0.0654 

[TRAIN] Epoch[1](12246/114412); Loss: 0.092216; Backpropagation: 0.2910 sec; Batch: 2.1151 sec
0.1572 0.1529 0.1197 0.1046 0.0937 0.0895 0.0854 0.0820 0.0794 0.0770 0.0751 0.0737 0.0726 0.0718 0.0708 0.0701 

[TRAIN] Epoch[1](12247/114412); Loss: 0.092897; Backpropagation: 0.2908 sec; Batch: 2.1179 sec
0.1575 0.1454 0.1268 0.1089 0.0991 0.0915 0.0865 0.0825 0.0794 0.0772 0.0751 0.0734 0.0721 0.0712 0.0703 0.0694 

[TRAIN] Epoch[1](12248/114412); Loss: 0.052118; Backpropagation: 0.2933 sec; Batch: 2.1191 sec
0.1363 0.1282 0.0820 0.0574 0.0476 0.0420 0.0403 0.0368 0.0351 0.0341 0.0334 0.0328 0.0324 0.0320 0.0318 0.0317 

[TRAIN] Epoch[1](12249/114412); Loss: 0.061968; Backpropagation: 0.2913 sec; Batch: 2.1184 sec
0.1270 0.1091 0.0817 0.0725 0.0642 0.0587 0.0553 0.0521 0.0500 0.0482 0.0472 0.0464 0.0455 0.0449 0.0446 0.0441 

[TRAIN] Epoch[1](12250/114412); Loss: 0.077488; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1478 0.1444 0.1013 0.0785 0.0739 0.0691 0.0663 0.0654 0.0640 0.0630 0.0623 0.0616 0.0612 0.0607 0.0603 0.0601 

[TRAIN] Epoch[1](12251/114412); Loss: 0.089894; Backpropagation: 0.2909 sec; Batch: 2.1152 sec
0.1606 0.1534 0.1243 0.1085 0.0899 0.0848 0.0797 0.0753 0.0740 0.0726 0.0711 0.0703 0.0693 0.0685 0.0681 0.0679 

[TRAIN] Epoch[1](12252/114412); Loss: 0.083125; Backpropagation: 0.2915 sec; Batch: 2.1180 sec
0.1444 0.1340 0.1087 0.0962 0.0873 0.0795 0.0769 0.0726 0.0708 0.0692 0.0673 0.0661 0.0653 0.0646 0.0638 0.0633 

[TRAIN] Epoch[1](12253/114412); Loss: 0.059159; Backpropagation: 0.2923 sec; Batch: 2.1710 sec
0.1143 0.0994 0.0775 0.0685 0.0613 0.0588 0.0541 0.0514 0.0495 0.0478 0.0462 0.0453 0.0443 0.0435 0.0426 0.0422 

[TRAIN] Epoch[1](12254/114412); Loss: 0.070126; Backpropagation: 0.2912 sec; Batch: 2.0793 sec
0.1339 0.1246 0.1011 0.0884 0.0759 0.0688 0.0628 0.0590 0.0556 0.0535 0.0516 0.0506 0.0499 0.0491 0.0488 0.0484 

[TRAIN] Epoch[1](12255/114412); Loss: 0.084631; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1529 0.1424 0.1151 0.1024 0.0903 0.0830 0.0789 0.0751 0.0714 0.0695 0.0663 0.0648 0.0625 0.0612 0.0599 0.0585 

[TRAIN] Epoch[1](12256/114412); Loss: 0.076098; Backpropagation: 0.2936 sec; Batch: 2.2185 sec
0.1190 0.1122 0.0952 0.0869 0.0809 0.0758 0.0718 0.0685 0.0668 0.0654 0.0644 0.0634 0.0625 0.0620 0.0616 0.0613 

[TRAIN] Epoch[1](12257/114412); Loss: 0.070357; Backpropagation: 0.2928 sec; Batch: 2.1324 sec
0.1293 0.1216 0.0893 0.0802 0.0742 0.0691 0.0646 0.0621 0.0592 0.0569 0.0557 0.0544 0.0531 0.0526 0.0521 0.0515 

[TRAIN] Epoch[1](12258/114412); Loss: 0.058387; Backpropagation: 0.2934 sec; Batch: 2.4612 sec
0.1260 0.1144 0.0760 0.0658 0.0600 0.0526 0.0503 0.0468 0.0455 0.0442 0.0433 0.0426 0.0420 0.0416 0.0415 0.0413 

[TRAIN] Epoch[1](12259/114412); Loss: 0.077930; Backpropagation: 0.2915 sec; Batch: 2.1190 sec
0.1546 0.1482 0.1077 0.0892 0.0744 0.0696 0.0667 0.0653 0.0627 0.0613 0.0597 0.0588 0.0580 0.0574 0.0569 0.0564 

[TRAIN] Epoch[1](12260/114412); Loss: 0.077447; Backpropagation: 0.2906 sec; Batch: 2.1123 sec
0.1342 0.1319 0.1006 0.0817 0.0820 0.0742 0.0692 0.0661 0.0648 0.0642 0.0635 0.0626 0.0617 0.0612 0.0608 0.0605 

[TRAIN] Epoch[1](12261/114412); Loss: 0.061926; Backpropagation: 0.2934 sec; Batch: 2.1896 sec
0.1171 0.1079 0.0838 0.0725 0.0658 0.0594 0.0556 0.0539 0.0509 0.0493 0.0480 0.0468 0.0460 0.0451 0.0447 0.0441 

[TRAIN] Epoch[1](12262/114412); Loss: 0.056317; Backpropagation: 0.2913 sec; Batch: 2.1148 sec
0.1227 0.1165 0.0810 0.0671 0.0573 0.0520 0.0478 0.0445 0.0423 0.0409 0.0396 0.0388 0.0382 0.0377 0.0375 0.0372 

[TRAIN] Epoch[1](12263/114412); Loss: 0.067691; Backpropagation: 0.2906 sec; Batch: 2.1164 sec
0.1240 0.1142 0.0829 0.0743 0.0705 0.0659 0.0616 0.0584 0.0571 0.0556 0.0543 0.0536 0.0531 0.0527 0.0526 0.0523 

[TRAIN] Epoch[1](12264/114412); Loss: 0.067785; Backpropagation: 0.2913 sec; Batch: 2.1247 sec
0.1320 0.1211 0.0902 0.0774 0.0682 0.0628 0.0592 0.0564 0.0555 0.0540 0.0529 0.0521 0.0514 0.0510 0.0504 0.0501 

[TRAIN] Epoch[1](12265/114412); Loss: 0.075994; Backpropagation: 0.2912 sec; Batch: 2.1185 sec
0.1417 0.1296 0.0992 0.0875 0.0787 0.0726 0.0681 0.0647 0.0626 0.0610 0.0601 0.0593 0.0584 0.0579 0.0574 0.0570 

[TRAIN] Epoch[1](12266/114412); Loss: 0.082149; Backpropagation: 0.2913 sec; Batch: 2.1177 sec
0.1486 0.1433 0.1105 0.0961 0.0822 0.0755 0.0716 0.0698 0.0677 0.0663 0.0655 0.0643 0.0638 0.0633 0.0630 0.0628 

[TRAIN] Epoch[1](12267/114412); Loss: 0.072446; Backpropagation: 0.2913 sec; Batch: 2.1523 sec
0.1374 0.1273 0.0952 0.0841 0.0747 0.0692 0.0648 0.0623 0.0593 0.0577 0.0563 0.0554 0.0547 0.0541 0.0536 0.0530 

[TRAIN] Epoch[1](12268/114412); Loss: 0.066361; Backpropagation: 0.2910 sec; Batch: 2.1234 sec
0.1144 0.1118 0.0919 0.0804 0.0719 0.0641 0.0597 0.0564 0.0544 0.0532 0.0523 0.0513 0.0505 0.0501 0.0499 0.0494 

[TRAIN] Epoch[1](12269/114412); Loss: 0.073578; Backpropagation: 0.2908 sec; Batch: 2.1232 sec
0.1433 0.1334 0.1013 0.0867 0.0732 0.0670 0.0640 0.0616 0.0595 0.0582 0.0569 0.0559 0.0550 0.0543 0.0537 0.0533 

[TRAIN] Epoch[1](12270/114412); Loss: 0.071007; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1251 0.1116 0.0895 0.0784 0.0713 0.0674 0.0653 0.0630 0.0615 0.0598 0.0585 0.0578 0.0572 0.0570 0.0566 0.0562 

[TRAIN] Epoch[1](12271/114412); Loss: 0.075850; Backpropagation: 0.2944 sec; Batch: 2.1010 sec
0.1537 0.1423 0.1078 0.0900 0.0756 0.0705 0.0661 0.0620 0.0595 0.0581 0.0568 0.0556 0.0548 0.0541 0.0536 0.0531 

[TRAIN] Epoch[1](12272/114412); Loss: 0.067074; Backpropagation: 0.2954 sec; Batch: 2.1183 sec
0.1206 0.1098 0.0860 0.0771 0.0675 0.0643 0.0607 0.0578 0.0564 0.0552 0.0543 0.0537 0.0531 0.0526 0.0521 0.0520 

[TRAIN] Epoch[1](12273/114412); Loss: 0.078628; Backpropagation: 0.2914 sec; Batch: 2.3378 sec
0.1243 0.1213 0.0982 0.0870 0.0792 0.0760 0.0731 0.0709 0.0690 0.0675 0.0664 0.0657 0.0653 0.0651 0.0647 0.0644 

[TRAIN] Epoch[1](12274/114412); Loss: 0.081831; Backpropagation: 0.2913 sec; Batch: 2.1291 sec
0.1536 0.1444 0.1130 0.0990 0.0880 0.0785 0.0736 0.0698 0.0668 0.0647 0.0627 0.0611 0.0601 0.0588 0.0579 0.0573 

[TRAIN] Epoch[1](12275/114412); Loss: 0.057092; Backpropagation: 0.2914 sec; Batch: 2.1184 sec
0.1297 0.1203 0.0796 0.0644 0.0555 0.0515 0.0478 0.0451 0.0434 0.0417 0.0407 0.0397 0.0392 0.0387 0.0383 0.0379 

[TRAIN] Epoch[1](12276/114412); Loss: 0.093758; Backpropagation: 0.2910 sec; Batch: 2.1161 sec
0.1876 0.1745 0.1396 0.1141 0.0960 0.0842 0.0791 0.0758 0.0738 0.0717 0.0701 0.0685 0.0676 0.0667 0.0657 0.0653 

[TRAIN] Epoch[1](12277/114412); Loss: 0.080790; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.1860 0.1775 0.1407 0.1182 0.0929 0.0705 0.0578 0.0539 0.0531 0.0519 0.0504 0.0489 0.0483 0.0479 0.0476 0.0471 

[TRAIN] Epoch[1](12278/114412); Loss: 0.075424; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.1677 0.1524 0.1023 0.0838 0.0719 0.0682 0.0645 0.0613 0.0587 0.0574 0.0552 0.0541 0.0534 0.0526 0.0520 0.0514 

[TRAIN] Epoch[1](12279/114412); Loss: 0.083838; Backpropagation: 0.2916 sec; Batch: 2.1186 sec
0.1427 0.1305 0.1044 0.0946 0.0841 0.0787 0.0760 0.0740 0.0726 0.0711 0.0701 0.0695 0.0688 0.0684 0.0681 0.0676 

[TRAIN] Epoch[1](12280/114412); Loss: 0.070200; Backpropagation: 0.2916 sec; Batch: 2.1173 sec
0.1363 0.1158 0.0903 0.0792 0.0725 0.0677 0.0646 0.0606 0.0584 0.0565 0.0554 0.0544 0.0536 0.0530 0.0527 0.0522 

[TRAIN] Epoch[1](12281/114412); Loss: 0.073432; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1373 0.1313 0.1084 0.0895 0.0738 0.0632 0.0616 0.0593 0.0586 0.0577 0.0569 0.0564 0.0558 0.0552 0.0551 0.0549 

[TRAIN] Epoch[1](12282/114412); Loss: 0.086187; Backpropagation: 0.2913 sec; Batch: 2.1127 sec
0.1834 0.1700 0.1222 0.1026 0.0870 0.0791 0.0736 0.0686 0.0661 0.0644 0.0628 0.0616 0.0605 0.0597 0.0590 0.0586 

[TRAIN] Epoch[1](12283/114412); Loss: 0.062247; Backpropagation: 0.2914 sec; Batch: 2.1182 sec
0.1351 0.1296 0.0959 0.0739 0.0614 0.0549 0.0512 0.0487 0.0466 0.0452 0.0442 0.0430 0.0423 0.0420 0.0412 0.0409 

[TRAIN] Epoch[1](12284/114412); Loss: 0.075115; Backpropagation: 0.2910 sec; Batch: 2.1209 sec
0.1194 0.1152 0.0959 0.0835 0.0772 0.0726 0.0694 0.0677 0.0659 0.0647 0.0634 0.0626 0.0619 0.0614 0.0608 0.0603 

[TRAIN] Epoch[1](12285/114412); Loss: 0.067917; Backpropagation: 0.2907 sec; Batch: 2.1165 sec
0.1332 0.1273 0.0962 0.0814 0.0688 0.0622 0.0583 0.0559 0.0538 0.0522 0.0513 0.0503 0.0495 0.0489 0.0487 0.0486 

[TRAIN] Epoch[1](12286/114412); Loss: 0.078913; Backpropagation: 0.2909 sec; Batch: 2.1260 sec
0.1573 0.1454 0.1057 0.0863 0.0741 0.0707 0.0677 0.0658 0.0640 0.0627 0.0620 0.0615 0.0606 0.0600 0.0596 0.0592 

[TRAIN] Epoch[1](12287/114412); Loss: 0.085797; Backpropagation: 0.2913 sec; Batch: 2.1190 sec
0.1382 0.1306 0.1055 0.0976 0.0896 0.0820 0.0786 0.0769 0.0751 0.0734 0.0724 0.0716 0.0710 0.0704 0.0701 0.0697 

[TRAIN] Epoch[1](12288/114412); Loss: 0.071510; Backpropagation: 0.2930 sec; Batch: 2.1181 sec
0.1403 0.1294 0.1008 0.0874 0.0776 0.0697 0.0627 0.0587 0.0565 0.0543 0.0529 0.0518 0.0512 0.0507 0.0503 0.0499 

[TRAIN] Epoch[1](12289/114412); Loss: 0.069162; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1276 0.1099 0.0975 0.0812 0.0698 0.0645 0.0617 0.0593 0.0577 0.0563 0.0551 0.0543 0.0535 0.0530 0.0529 0.0525 

[TRAIN] Epoch[1](12290/114412); Loss: 0.084671; Backpropagation: 0.2908 sec; Batch: 2.0775 sec
0.1535 0.1507 0.1128 0.0948 0.0815 0.0782 0.0743 0.0724 0.0706 0.0691 0.0679 0.0671 0.0663 0.0656 0.0651 0.0648 

[TRAIN] Epoch[1](12291/114412); Loss: 0.080701; Backpropagation: 0.2911 sec; Batch: 2.1254 sec
0.1358 0.1294 0.1026 0.0910 0.0831 0.0779 0.0745 0.0715 0.0699 0.0682 0.0670 0.0660 0.0647 0.0639 0.0631 0.0627 

[TRAIN] Epoch[1](12292/114412); Loss: 0.084722; Backpropagation: 0.2927 sec; Batch: 2.1228 sec
0.1530 0.1455 0.1080 0.0927 0.0833 0.0779 0.0758 0.0737 0.0724 0.0707 0.0693 0.0680 0.0672 0.0666 0.0658 0.0657 

[TRAIN] Epoch[1](12293/114412); Loss: 0.063667; Backpropagation: 0.2903 sec; Batch: 2.1192 sec
0.1394 0.1339 0.0988 0.0787 0.0620 0.0551 0.0519 0.0487 0.0469 0.0458 0.0449 0.0439 0.0429 0.0425 0.0418 0.0415 

[TRAIN] Epoch[1](12294/114412); Loss: 0.083215; Backpropagation: 0.2905 sec; Batch: 2.1169 sec
0.1771 0.1638 0.1275 0.1025 0.0794 0.0726 0.0670 0.0653 0.0632 0.0613 0.0603 0.0593 0.0585 0.0583 0.0579 0.0575 

[TRAIN] Epoch[1](12295/114412); Loss: 0.065315; Backpropagation: 0.2932 sec; Batch: 2.1048 sec
0.1310 0.1223 0.0834 0.0696 0.0650 0.0613 0.0578 0.0550 0.0531 0.0517 0.0506 0.0498 0.0492 0.0487 0.0484 0.0483 

[TRAIN] Epoch[1](12296/114412); Loss: 0.109081; Backpropagation: 0.2915 sec; Batch: 2.1294 sec
0.1782 0.1725 0.1283 0.1134 0.1054 0.1014 0.1001 0.0985 0.0966 0.0955 0.0947 0.0934 0.0928 0.0921 0.0915 0.0910 

[TRAIN] Epoch[1](12297/114412); Loss: 0.085246; Backpropagation: 0.2915 sec; Batch: 2.0775 sec
0.1478 0.1421 0.1184 0.1013 0.0862 0.0785 0.0751 0.0723 0.0710 0.0695 0.0685 0.0679 0.0670 0.0664 0.0661 0.0658 

[TRAIN] Epoch[1](12298/114412); Loss: 0.079010; Backpropagation: 0.2955 sec; Batch: 2.1233 sec
0.1371 0.1281 0.1103 0.0967 0.0844 0.0774 0.0718 0.0678 0.0658 0.0643 0.0626 0.0612 0.0601 0.0594 0.0587 0.0583 

[TRAIN] Epoch[1](12299/114412); Loss: 0.070578; Backpropagation: 0.2953 sec; Batch: 2.1241 sec
0.1391 0.1313 0.0979 0.0810 0.0704 0.0646 0.0608 0.0582 0.0560 0.0549 0.0540 0.0530 0.0524 0.0520 0.0518 0.0517 

[TRAIN] Epoch[1](12300/114412); Loss: 0.064292; Backpropagation: 0.2931 sec; Batch: 2.1205 sec
0.1199 0.1106 0.0843 0.0732 0.0647 0.0609 0.0573 0.0546 0.0530 0.0518 0.0509 0.0503 0.0498 0.0495 0.0491 0.0489 

[TRAIN] Epoch[1](12301/114412); Loss: 0.052382; Backpropagation: 0.2930 sec; Batch: 2.1217 sec
0.1021 0.1015 0.0800 0.0637 0.0528 0.0470 0.0431 0.0418 0.0405 0.0395 0.0389 0.0381 0.0377 0.0374 0.0371 0.0367 

[TRAIN] Epoch[1](12302/114412); Loss: 0.070093; Backpropagation: 0.2909 sec; Batch: 2.1191 sec
0.1196 0.1100 0.0930 0.0797 0.0720 0.0679 0.0633 0.0609 0.0593 0.0583 0.0572 0.0568 0.0564 0.0559 0.0557 0.0555 

[TRAIN] Epoch[1](12303/114412); Loss: 0.077974; Backpropagation: 0.2936 sec; Batch: 2.1184 sec
0.1273 0.1206 0.0971 0.0853 0.0783 0.0748 0.0723 0.0700 0.0684 0.0671 0.0661 0.0653 0.0645 0.0640 0.0635 0.0630 

[TRAIN] Epoch[1](12304/114412); Loss: 0.064822; Backpropagation: 0.2930 sec; Batch: 2.0833 sec
0.1220 0.1124 0.0883 0.0744 0.0651 0.0612 0.0577 0.0551 0.0537 0.0523 0.0509 0.0498 0.0491 0.0486 0.0485 0.0481 

[TRAIN] Epoch[1](12305/114412); Loss: 0.063622; Backpropagation: 0.2930 sec; Batch: 2.0816 sec
0.1696 0.1568 0.0932 0.0666 0.0547 0.0520 0.0489 0.0459 0.0436 0.0427 0.0417 0.0414 0.0407 0.0402 0.0401 0.0399 

[TRAIN] Epoch[1](12306/114412); Loss: 0.080504; Backpropagation: 0.2911 sec; Batch: 2.1308 sec
0.1236 0.1193 0.0980 0.0876 0.0801 0.0773 0.0751 0.0728 0.0714 0.0704 0.0697 0.0693 0.0688 0.0685 0.0682 0.0679 

[TRAIN] Epoch[1](12307/114412); Loss: 0.077497; Backpropagation: 0.2916 sec; Batch: 2.0782 sec
0.1246 0.1222 0.1022 0.0890 0.0796 0.0736 0.0702 0.0688 0.0668 0.0654 0.0643 0.0639 0.0632 0.0626 0.0620 0.0617 

[TRAIN] Epoch[1](12308/114412); Loss: 0.076164; Backpropagation: 0.2921 sec; Batch: 2.1187 sec
0.1386 0.1347 0.1095 0.0919 0.0792 0.0716 0.0652 0.0623 0.0604 0.0595 0.0588 0.0582 0.0577 0.0574 0.0570 0.0566 

[TRAIN] Epoch[1](12309/114412); Loss: 0.070533; Backpropagation: 0.2930 sec; Batch: 2.0801 sec
0.1309 0.1238 0.0870 0.0751 0.0707 0.0673 0.0649 0.0620 0.0599 0.0586 0.0566 0.0557 0.0548 0.0542 0.0538 0.0533 

[TRAIN] Epoch[1](12310/114412); Loss: 0.063525; Backpropagation: 0.2953 sec; Batch: 2.1197 sec
0.1091 0.1072 0.0833 0.0738 0.0667 0.0610 0.0571 0.0547 0.0531 0.0518 0.0510 0.0501 0.0498 0.0495 0.0493 0.0491 

[TRAIN] Epoch[1](12311/114412); Loss: 0.062279; Backpropagation: 0.2933 sec; Batch: 2.1169 sec
0.1162 0.1133 0.0820 0.0692 0.0617 0.0568 0.0544 0.0523 0.0510 0.0499 0.0493 0.0486 0.0482 0.0480 0.0479 0.0477 

[TRAIN] Epoch[1](12312/114412); Loss: 0.069004; Backpropagation: 0.2915 sec; Batch: 2.1196 sec
0.1242 0.1121 0.0909 0.0803 0.0734 0.0673 0.0628 0.0595 0.0575 0.0560 0.0549 0.0541 0.0536 0.0530 0.0524 0.0522 

[TRAIN] Epoch[1](12313/114412); Loss: 0.060937; Backpropagation: 0.2913 sec; Batch: 2.1167 sec
0.1074 0.0953 0.0859 0.0700 0.0613 0.0582 0.0550 0.0533 0.0514 0.0502 0.0494 0.0484 0.0478 0.0473 0.0471 0.0469 

[TRAIN] Epoch[1](12314/114412); Loss: 0.103493; Backpropagation: 0.2932 sec; Batch: 2.1197 sec
0.1792 0.1646 0.1314 0.1188 0.1059 0.0988 0.0935 0.0903 0.0881 0.0863 0.0852 0.0839 0.0834 0.0827 0.0822 0.0817 

[TRAIN] Epoch[1](12315/114412); Loss: 0.056889; Backpropagation: 0.2955 sec; Batch: 2.1229 sec
0.1192 0.1105 0.0828 0.0715 0.0637 0.0551 0.0499 0.0442 0.0409 0.0409 0.0399 0.0392 0.0388 0.0383 0.0377 0.0376 

[TRAIN] Epoch[1](12316/114412); Loss: 0.066726; Backpropagation: 0.2930 sec; Batch: 2.1231 sec
0.1345 0.1274 0.1008 0.0833 0.0686 0.0606 0.0562 0.0539 0.0514 0.0498 0.0485 0.0475 0.0469 0.0464 0.0459 0.0458 

[TRAIN] Epoch[1](12317/114412); Loss: 0.086996; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.1487 0.1430 0.1198 0.1031 0.0925 0.0864 0.0830 0.0784 0.0751 0.0730 0.0693 0.0668 0.0658 0.0636 0.0621 0.0613 

[TRAIN] Epoch[1](12318/114412); Loss: 0.068650; Backpropagation: 0.2910 sec; Batch: 2.1042 sec
0.1721 0.1628 0.1165 0.0880 0.0643 0.0572 0.0513 0.0477 0.0450 0.0441 0.0430 0.0422 0.0417 0.0411 0.0409 0.0407 

[TRAIN] Epoch[1](12319/114412); Loss: 0.069172; Backpropagation: 0.2930 sec; Batch: 2.1197 sec
0.1530 0.1427 0.1016 0.0821 0.0699 0.0596 0.0557 0.0533 0.0513 0.0500 0.0492 0.0487 0.0481 0.0474 0.0472 0.0470 

[TRAIN] Epoch[1](12320/114412); Loss: 0.074969; Backpropagation: 0.2911 sec; Batch: 2.1153 sec
0.1404 0.1370 0.1018 0.0872 0.0758 0.0684 0.0651 0.0631 0.0609 0.0593 0.0584 0.0576 0.0568 0.0563 0.0558 0.0557 

[TRAIN] Epoch[1](12321/114412); Loss: 0.077594; Backpropagation: 0.2915 sec; Batch: 2.1188 sec
0.1244 0.1148 0.0966 0.0884 0.0830 0.0760 0.0727 0.0698 0.0676 0.0664 0.0652 0.0644 0.0635 0.0630 0.0629 0.0626 

[TRAIN] Epoch[1](12322/114412); Loss: 0.117486; Backpropagation: 0.2912 sec; Batch: 2.1290 sec
0.1913 0.1886 0.1611 0.1459 0.1275 0.1146 0.1073 0.1024 0.0989 0.0961 0.0942 0.0926 0.0914 0.0902 0.0892 0.0886 

[TRAIN] Epoch[1](12323/114412); Loss: 0.060977; Backpropagation: 0.2914 sec; Batch: 2.1213 sec
0.1201 0.1140 0.0934 0.0713 0.0625 0.0569 0.0531 0.0490 0.0475 0.0460 0.0450 0.0444 0.0436 0.0432 0.0431 0.0426 

[TRAIN] Epoch[1](12324/114412); Loss: 0.070931; Backpropagation: 0.2928 sec; Batch: 2.0799 sec
0.1184 0.1137 0.0954 0.0852 0.0762 0.0700 0.0645 0.0614 0.0597 0.0585 0.0570 0.0563 0.0554 0.0548 0.0544 0.0539 

[TRAIN] Epoch[1](12325/114412); Loss: 0.072898; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1352 0.1222 0.1058 0.0895 0.0768 0.0680 0.0641 0.0616 0.0590 0.0571 0.0560 0.0553 0.0546 0.0541 0.0536 0.0533 

[TRAIN] Epoch[1](12326/114412); Loss: 0.074919; Backpropagation: 0.2908 sec; Batch: 2.1167 sec
0.1492 0.1335 0.1030 0.0848 0.0718 0.0653 0.0657 0.0629 0.0612 0.0594 0.0585 0.0577 0.0570 0.0565 0.0563 0.0560 

[TRAIN] Epoch[1](12327/114412); Loss: 0.068385; Backpropagation: 0.2914 sec; Batch: 2.1125 sec
0.1143 0.1049 0.0895 0.0764 0.0692 0.0654 0.0619 0.0600 0.0589 0.0578 0.0571 0.0566 0.0561 0.0557 0.0553 0.0549 

[TRAIN] Epoch[1](12328/114412); Loss: 0.049187; Backpropagation: 0.2933 sec; Batch: 2.1210 sec
0.1184 0.0930 0.0536 0.0499 0.0497 0.0461 0.0437 0.0411 0.0392 0.0381 0.0370 0.0361 0.0358 0.0353 0.0352 0.0347 

[TRAIN] Epoch[1](12329/114412); Loss: 0.081184; Backpropagation: 0.2913 sec; Batch: 2.0790 sec
0.1515 0.1429 0.1117 0.0987 0.0842 0.0745 0.0701 0.0677 0.0658 0.0641 0.0633 0.0624 0.0614 0.0607 0.0602 0.0598 

[TRAIN] Epoch[1](12330/114412); Loss: 0.090706; Backpropagation: 0.2923 sec; Batch: 2.0813 sec
0.1557 0.1370 0.1019 0.0942 0.0922 0.0864 0.0838 0.0812 0.0798 0.0787 0.0778 0.0772 0.0766 0.0765 0.0762 0.0759 

[TRAIN] Epoch[1](12331/114412); Loss: 0.078429; Backpropagation: 0.2946 sec; Batch: 2.1363 sec
0.1501 0.1378 0.1050 0.0932 0.0846 0.0765 0.0708 0.0673 0.0646 0.0621 0.0599 0.0582 0.0573 0.0564 0.0558 0.0552 

[TRAIN] Epoch[1](12332/114412); Loss: 0.064311; Backpropagation: 0.2909 sec; Batch: 2.1186 sec
0.1260 0.1197 0.0996 0.0783 0.0660 0.0594 0.0563 0.0525 0.0505 0.0484 0.0471 0.0461 0.0453 0.0449 0.0445 0.0444 

[TRAIN] Epoch[1](12333/114412); Loss: 0.061537; Backpropagation: 0.2911 sec; Batch: 2.0846 sec
0.1242 0.1145 0.0787 0.0711 0.0606 0.0571 0.0536 0.0512 0.0497 0.0483 0.0474 0.0467 0.0459 0.0454 0.0452 0.0449 

[TRAIN] Epoch[1](12334/114412); Loss: 0.078355; Backpropagation: 0.2906 sec; Batch: 2.1182 sec
0.1345 0.1239 0.0998 0.0877 0.0796 0.0751 0.0723 0.0698 0.0677 0.0660 0.0646 0.0637 0.0630 0.0625 0.0618 0.0617 

[TRAIN] Epoch[1](12335/114412); Loss: 0.055903; Backpropagation: 0.2911 sec; Batch: 2.1258 sec
0.1163 0.1078 0.0741 0.0641 0.0592 0.0530 0.0509 0.0462 0.0443 0.0425 0.0413 0.0405 0.0395 0.0389 0.0382 0.0377 

[TRAIN] Epoch[1](12336/114412); Loss: 0.054250; Backpropagation: 0.2911 sec; Batch: 2.1202 sec
0.1116 0.1031 0.0770 0.0644 0.0559 0.0502 0.0464 0.0443 0.0428 0.0411 0.0400 0.0393 0.0385 0.0381 0.0378 0.0376 

[TRAIN] Epoch[1](12337/114412); Loss: 0.056298; Backpropagation: 0.2913 sec; Batch: 2.1153 sec
0.1180 0.1049 0.0755 0.0613 0.0556 0.0511 0.0491 0.0465 0.0450 0.0438 0.0429 0.0421 0.0418 0.0414 0.0410 0.0408 

[TRAIN] Epoch[1](12338/114412); Loss: 0.086326; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1509 0.1417 0.1140 0.1004 0.0896 0.0830 0.0781 0.0749 0.0725 0.0709 0.0693 0.0683 0.0677 0.0671 0.0666 0.0662 

[TRAIN] Epoch[1](12339/114412); Loss: 0.087586; Backpropagation: 0.2920 sec; Batch: 2.1183 sec
0.1562 0.1491 0.1190 0.1001 0.0876 0.0823 0.0799 0.0760 0.0732 0.0715 0.0703 0.0692 0.0679 0.0671 0.0662 0.0659 

[TRAIN] Epoch[1](12340/114412); Loss: 0.083695; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1368 0.1312 0.1102 0.0946 0.0829 0.0778 0.0762 0.0737 0.0726 0.0709 0.0702 0.0694 0.0690 0.0684 0.0677 0.0675 

[TRAIN] Epoch[1](12341/114412); Loss: 0.077795; Backpropagation: 0.2909 sec; Batch: 2.1169 sec
0.1574 0.1529 0.1128 0.0963 0.0769 0.0685 0.0646 0.0622 0.0605 0.0584 0.0574 0.0568 0.0558 0.0553 0.0548 0.0542 

[TRAIN] Epoch[1](12342/114412); Loss: 0.065458; Backpropagation: 0.2953 sec; Batch: 2.1173 sec
0.1320 0.1252 0.0891 0.0746 0.0662 0.0600 0.0561 0.0535 0.0524 0.0508 0.0499 0.0488 0.0481 0.0473 0.0469 0.0465 

[TRAIN] Epoch[1](12343/114412); Loss: 0.065918; Backpropagation: 0.2933 sec; Batch: 2.1305 sec
0.1246 0.1163 0.0889 0.0744 0.0662 0.0624 0.0592 0.0561 0.0546 0.0529 0.0518 0.0507 0.0500 0.0494 0.0488 0.0485 

[TRAIN] Epoch[1](12344/114412); Loss: 0.072067; Backpropagation: 0.2913 sec; Batch: 2.1169 sec
0.1286 0.1209 0.0956 0.0799 0.0725 0.0680 0.0647 0.0623 0.0607 0.0594 0.0581 0.0577 0.0569 0.0563 0.0560 0.0557 

[TRAIN] Epoch[1](12345/114412); Loss: 0.078805; Backpropagation: 0.2910 sec; Batch: 2.1169 sec
0.1347 0.1248 0.1021 0.0897 0.0806 0.0747 0.0723 0.0698 0.0678 0.0665 0.0649 0.0640 0.0632 0.0624 0.0619 0.0615 

[TRAIN] Epoch[1](12346/114412); Loss: 0.077663; Backpropagation: 0.2913 sec; Batch: 2.0793 sec
0.1504 0.1398 0.1077 0.0946 0.0805 0.0700 0.0668 0.0638 0.0621 0.0606 0.0596 0.0586 0.0578 0.0572 0.0567 0.0565 

[TRAIN] Epoch[1](12347/114412); Loss: 0.076612; Backpropagation: 0.2928 sec; Batch: 2.1187 sec
0.1440 0.1325 0.1082 0.0945 0.0841 0.0751 0.0694 0.0657 0.0623 0.0594 0.0574 0.0561 0.0553 0.0545 0.0539 0.0534 

[TRAIN] Epoch[1](12348/114412); Loss: 0.072651; Backpropagation: 0.2931 sec; Batch: 2.1210 sec
0.1291 0.1213 0.0971 0.0862 0.0766 0.0696 0.0667 0.0632 0.0612 0.0594 0.0578 0.0567 0.0557 0.0547 0.0538 0.0533 

[TRAIN] Epoch[1](12349/114412); Loss: 0.055375; Backpropagation: 0.2929 sec; Batch: 2.1205 sec
0.1186 0.1086 0.0816 0.0676 0.0582 0.0497 0.0468 0.0446 0.0424 0.0406 0.0396 0.0388 0.0379 0.0374 0.0370 0.0367 

[TRAIN] Epoch[1](12350/114412); Loss: 0.062523; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1349 0.1268 0.0906 0.0716 0.0593 0.0548 0.0515 0.0497 0.0479 0.0468 0.0457 0.0450 0.0445 0.0441 0.0438 0.0434 

[TRAIN] Epoch[1](12351/114412); Loss: 0.103917; Backpropagation: 0.2929 sec; Batch: 2.1195 sec
0.1605 0.1541 0.1304 0.1176 0.1088 0.1018 0.0974 0.0940 0.0916 0.0900 0.0884 0.0872 0.0863 0.0854 0.0848 0.0844 

[TRAIN] Epoch[1](12352/114412); Loss: 0.070489; Backpropagation: 0.2925 sec; Batch: 2.1174 sec
0.1152 0.1090 0.0900 0.0798 0.0730 0.0686 0.0657 0.0622 0.0609 0.0596 0.0590 0.0580 0.0573 0.0568 0.0565 0.0563 

[TRAIN] Epoch[1](12353/114412); Loss: 0.078693; Backpropagation: 0.2909 sec; Batch: 2.1202 sec
0.1413 0.1212 0.0900 0.0828 0.0825 0.0762 0.0719 0.0693 0.0679 0.0670 0.0664 0.0653 0.0648 0.0645 0.0641 0.0640 

[TRAIN] Epoch[1](12354/114412); Loss: 0.072963; Backpropagation: 0.2913 sec; Batch: 2.0791 sec
0.1832 0.1721 0.1202 0.0923 0.0745 0.0587 0.0552 0.0523 0.0494 0.0475 0.0459 0.0446 0.0438 0.0430 0.0424 0.0422 

[TRAIN] Epoch[1](12355/114412); Loss: 0.062756; Backpropagation: 0.2905 sec; Batch: 2.1180 sec
0.1310 0.1232 0.0929 0.0737 0.0610 0.0565 0.0528 0.0499 0.0483 0.0470 0.0460 0.0454 0.0446 0.0443 0.0439 0.0436 

[TRAIN] Epoch[1](12356/114412); Loss: 0.076703; Backpropagation: 0.2918 sec; Batch: 2.1337 sec
0.1455 0.1385 0.1041 0.0880 0.0797 0.0729 0.0681 0.0641 0.0618 0.0604 0.0593 0.0581 0.0574 0.0569 0.0564 0.0562 

[TRAIN] Epoch[1](12357/114412); Loss: 0.086311; Backpropagation: 0.2913 sec; Batch: 2.1143 sec
0.1530 0.1436 0.1126 0.0963 0.0849 0.0805 0.0772 0.0751 0.0730 0.0718 0.0705 0.0696 0.0689 0.0684 0.0679 0.0675 

[TRAIN] Epoch[1](12358/114412); Loss: 0.088904; Backpropagation: 0.2916 sec; Batch: 2.1170 sec
0.1467 0.1409 0.1118 0.0968 0.0926 0.0870 0.0824 0.0796 0.0773 0.0757 0.0743 0.0731 0.0723 0.0715 0.0706 0.0700 

[TRAIN] Epoch[1](12359/114412); Loss: 0.056729; Backpropagation: 0.2915 sec; Batch: 2.1172 sec
0.1296 0.1246 0.0909 0.0750 0.0564 0.0499 0.0466 0.0432 0.0403 0.0381 0.0372 0.0364 0.0358 0.0352 0.0344 0.0342 

[TRAIN] Epoch[1](12360/114412); Loss: 0.059931; Backpropagation: 0.2911 sec; Batch: 2.1168 sec
0.1291 0.1235 0.0890 0.0679 0.0569 0.0525 0.0492 0.0480 0.0457 0.0445 0.0437 0.0426 0.0422 0.0418 0.0413 0.0410 

[TRAIN] Epoch[1](12361/114412); Loss: 0.064618; Backpropagation: 0.2929 sec; Batch: 2.1184 sec
0.1372 0.1211 0.0855 0.0736 0.0671 0.0611 0.0563 0.0531 0.0511 0.0498 0.0481 0.0471 0.0467 0.0457 0.0454 0.0450 

[TRAIN] Epoch[1](12362/114412); Loss: 0.078900; Backpropagation: 0.2918 sec; Batch: 2.1172 sec
0.1492 0.1409 0.1064 0.0927 0.0793 0.0744 0.0706 0.0671 0.0649 0.0633 0.0616 0.0604 0.0592 0.0581 0.0575 0.0569 

[TRAIN] Epoch[1](12363/114412); Loss: 0.076689; Backpropagation: 0.2930 sec; Batch: 2.0805 sec
0.1508 0.1474 0.1038 0.0867 0.0759 0.0675 0.0658 0.0631 0.0613 0.0602 0.0590 0.0582 0.0574 0.0570 0.0568 0.0562 

[TRAIN] Epoch[1](12364/114412); Loss: 0.075511; Backpropagation: 0.2931 sec; Batch: 2.1203 sec
0.1607 0.1591 0.1154 0.0910 0.0732 0.0690 0.0621 0.0583 0.0564 0.0548 0.0536 0.0519 0.0515 0.0507 0.0503 0.0501 

[TRAIN] Epoch[1](12365/114412); Loss: 0.068554; Backpropagation: 0.2930 sec; Batch: 2.1222 sec
0.1216 0.1176 0.0894 0.0757 0.0685 0.0646 0.0610 0.0589 0.0575 0.0564 0.0559 0.0550 0.0543 0.0539 0.0535 0.0531 

[TRAIN] Epoch[1](12366/114412); Loss: 0.063688; Backpropagation: 0.2928 sec; Batch: 2.1203 sec
0.1162 0.1082 0.0798 0.0712 0.0657 0.0609 0.0581 0.0554 0.0537 0.0524 0.0512 0.0504 0.0498 0.0491 0.0487 0.0483 

[TRAIN] Epoch[1](12367/114412); Loss: 0.065411; Backpropagation: 0.2909 sec; Batch: 2.1146 sec
0.1280 0.1221 0.0847 0.0714 0.0651 0.0608 0.0581 0.0555 0.0533 0.0516 0.0506 0.0499 0.0493 0.0488 0.0487 0.0486 

[TRAIN] Epoch[1](12368/114412); Loss: 0.075547; Backpropagation: 0.2931 sec; Batch: 2.1208 sec
0.1187 0.1087 0.0962 0.0839 0.0770 0.0738 0.0706 0.0681 0.0664 0.0655 0.0646 0.0640 0.0633 0.0628 0.0626 0.0624 

[TRAIN] Epoch[1](12369/114412); Loss: 0.068378; Backpropagation: 0.2912 sec; Batch: 2.1160 sec
0.1270 0.1234 0.1045 0.0817 0.0693 0.0629 0.0596 0.0565 0.0549 0.0534 0.0518 0.0509 0.0501 0.0496 0.0492 0.0492 

[TRAIN] Epoch[1](12370/114412); Loss: 0.075933; Backpropagation: 0.2914 sec; Batch: 2.0783 sec
0.1257 0.1156 0.0994 0.0886 0.0805 0.0748 0.0708 0.0683 0.0655 0.0636 0.0623 0.0614 0.0604 0.0598 0.0593 0.0589 

[TRAIN] Epoch[1](12371/114412); Loss: 0.067235; Backpropagation: 0.2930 sec; Batch: 2.1061 sec
0.1320 0.1275 0.1125 0.0869 0.0741 0.0656 0.0561 0.0515 0.0498 0.0478 0.0464 0.0460 0.0455 0.0449 0.0447 0.0445 

[TRAIN] Epoch[1](12372/114412); Loss: 0.084264; Backpropagation: 0.2911 sec; Batch: 2.1183 sec
0.1567 0.1503 0.1188 0.0997 0.0851 0.0753 0.0728 0.0704 0.0683 0.0673 0.0658 0.0648 0.0640 0.0633 0.0629 0.0627 

[TRAIN] Epoch[1](12373/114412); Loss: 0.061669; Backpropagation: 0.2913 sec; Batch: 2.1297 sec
0.1256 0.1131 0.0859 0.0696 0.0609 0.0572 0.0535 0.0505 0.0492 0.0472 0.0464 0.0458 0.0455 0.0455 0.0454 0.0454 

[TRAIN] Epoch[1](12374/114412); Loss: 0.096148; Backpropagation: 0.2906 sec; Batch: 2.1196 sec
0.1606 0.1492 0.1220 0.1076 0.0986 0.0914 0.0881 0.0849 0.0829 0.0816 0.0803 0.0794 0.0788 0.0781 0.0776 0.0773 

[TRAIN] Epoch[1](12375/114412); Loss: 0.076644; Backpropagation: 0.2910 sec; Batch: 2.1113 sec
0.1536 0.1429 0.1026 0.0852 0.0749 0.0667 0.0654 0.0637 0.0619 0.0607 0.0593 0.0586 0.0584 0.0578 0.0573 0.0572 

[TRAIN] Epoch[1](12376/114412); Loss: 0.061156; Backpropagation: 0.2914 sec; Batch: 2.1817 sec
0.1536 0.1418 0.0904 0.0653 0.0539 0.0488 0.0470 0.0464 0.0448 0.0433 0.0427 0.0412 0.0407 0.0401 0.0395 0.0392 

[TRAIN] Epoch[1](12377/114412); Loss: 0.070047; Backpropagation: 0.2907 sec; Batch: 2.1169 sec
0.1464 0.1393 0.0979 0.0779 0.0646 0.0633 0.0603 0.0566 0.0543 0.0531 0.0527 0.0516 0.0511 0.0511 0.0505 0.0501 

[TRAIN] Epoch[1](12378/114412); Loss: 0.078785; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1337 0.1282 0.1013 0.0891 0.0801 0.0755 0.0720 0.0695 0.0678 0.0661 0.0649 0.0637 0.0630 0.0623 0.0619 0.0615 

[TRAIN] Epoch[1](12379/114412); Loss: 0.077433; Backpropagation: 0.2914 sec; Batch: 2.1212 sec
0.1462 0.1413 0.1100 0.0903 0.0769 0.0703 0.0670 0.0643 0.0631 0.0616 0.0601 0.0592 0.0578 0.0571 0.0569 0.0567 

[TRAIN] Epoch[1](12380/114412); Loss: 0.070884; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1300 0.1222 0.0965 0.0833 0.0726 0.0658 0.0613 0.0600 0.0585 0.0565 0.0560 0.0553 0.0545 0.0541 0.0539 0.0538 

[TRAIN] Epoch[1](12381/114412); Loss: 0.081201; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1539 0.1415 0.1040 0.0901 0.0827 0.0756 0.0723 0.0698 0.0675 0.0658 0.0644 0.0636 0.0627 0.0621 0.0617 0.0615 

[TRAIN] Epoch[1](12382/114412); Loss: 0.096459; Backpropagation: 0.2911 sec; Batch: 2.1224 sec
0.1839 0.1801 0.1391 0.1143 0.0986 0.0977 0.0894 0.0819 0.0781 0.0731 0.0713 0.0706 0.0685 0.0672 0.0653 0.0643 

[TRAIN] Epoch[1](12383/114412); Loss: 0.080126; Backpropagation: 0.2908 sec; Batch: 2.0768 sec
0.1411 0.1331 0.1044 0.0904 0.0823 0.0773 0.0751 0.0707 0.0682 0.0668 0.0644 0.0635 0.0626 0.0613 0.0606 0.0602 

[TRAIN] Epoch[1](12384/114412); Loss: 0.063395; Backpropagation: 0.2908 sec; Batch: 2.1218 sec
0.1425 0.1375 0.1086 0.0843 0.0639 0.0498 0.0485 0.0467 0.0453 0.0434 0.0422 0.0413 0.0408 0.0402 0.0398 0.0396 

[TRAIN] Epoch[1](12385/114412); Loss: 0.071966; Backpropagation: 0.2908 sec; Batch: 2.0768 sec
0.1439 0.1404 0.1031 0.0817 0.0699 0.0636 0.0610 0.0590 0.0569 0.0560 0.0546 0.0539 0.0530 0.0517 0.0516 0.0511 

[TRAIN] Epoch[1](12386/114412); Loss: 0.070694; Backpropagation: 0.2911 sec; Batch: 2.0771 sec
0.1281 0.1185 0.0837 0.0794 0.0736 0.0688 0.0650 0.0618 0.0598 0.0586 0.0572 0.0563 0.0555 0.0553 0.0549 0.0546 

[TRAIN] Epoch[1](12387/114412); Loss: 0.070803; Backpropagation: 0.2911 sec; Batch: 2.1169 sec
0.1331 0.1250 0.0978 0.0835 0.0739 0.0653 0.0619 0.0586 0.0566 0.0556 0.0549 0.0541 0.0537 0.0533 0.0530 0.0525 

[TRAIN] Epoch[1](12388/114412); Loss: 0.077026; Backpropagation: 0.2932 sec; Batch: 2.1221 sec
0.1168 0.1127 0.0872 0.0799 0.0762 0.0743 0.0730 0.0711 0.0698 0.0691 0.0682 0.0675 0.0670 0.0665 0.0666 0.0664 

[TRAIN] Epoch[1](12389/114412); Loss: 0.055978; Backpropagation: 0.2912 sec; Batch: 2.0782 sec
0.1254 0.1085 0.0797 0.0650 0.0543 0.0501 0.0474 0.0451 0.0427 0.0415 0.0404 0.0397 0.0393 0.0391 0.0389 0.0387 

[TRAIN] Epoch[1](12390/114412); Loss: 0.074558; Backpropagation: 0.2953 sec; Batch: 2.1205 sec
0.1264 0.1216 0.0950 0.0836 0.0746 0.0703 0.0679 0.0658 0.0641 0.0631 0.0618 0.0608 0.0600 0.0595 0.0593 0.0590 

[TRAIN] Epoch[1](12391/114412); Loss: 0.084142; Backpropagation: 0.2950 sec; Batch: 2.1221 sec
0.1359 0.1246 0.1007 0.0925 0.0873 0.0840 0.0800 0.0769 0.0745 0.0729 0.0716 0.0705 0.0695 0.0688 0.0684 0.0680 

[TRAIN] Epoch[1](12392/114412); Loss: 0.061707; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.1317 0.1281 0.0874 0.0678 0.0573 0.0542 0.0518 0.0497 0.0486 0.0469 0.0458 0.0449 0.0440 0.0433 0.0429 0.0429 

[TRAIN] Epoch[1](12393/114412); Loss: 0.074379; Backpropagation: 0.2955 sec; Batch: 2.1212 sec
0.1232 0.1165 0.0932 0.0836 0.0764 0.0727 0.0689 0.0664 0.0647 0.0633 0.0619 0.0610 0.0602 0.0596 0.0594 0.0591 

[TRAIN] Epoch[1](12394/114412); Loss: 0.083892; Backpropagation: 0.2927 sec; Batch: 2.0796 sec
0.1312 0.1245 0.1029 0.0897 0.0838 0.0820 0.0788 0.0769 0.0749 0.0733 0.0719 0.0712 0.0708 0.0704 0.0702 0.0699 

[TRAIN] Epoch[1](12395/114412); Loss: 0.079154; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1163 0.1148 0.0963 0.0888 0.0794 0.0766 0.0752 0.0726 0.0715 0.0695 0.0688 0.0684 0.0677 0.0674 0.0669 0.0666 

[TRAIN] Epoch[1](12396/114412); Loss: 0.076525; Backpropagation: 0.2912 sec; Batch: 2.1197 sec
0.1202 0.1168 0.0921 0.0830 0.0791 0.0750 0.0715 0.0692 0.0675 0.0662 0.0653 0.0644 0.0639 0.0636 0.0635 0.0632 

[TRAIN] Epoch[1](12397/114412); Loss: 0.069306; Backpropagation: 0.2915 sec; Batch: 2.1166 sec
0.1165 0.1118 0.0881 0.0800 0.0726 0.0670 0.0639 0.0613 0.0595 0.0580 0.0572 0.0561 0.0549 0.0544 0.0539 0.0536 

[TRAIN] Epoch[1](12398/114412); Loss: 0.077130; Backpropagation: 0.2913 sec; Batch: 2.1220 sec
0.1532 0.1486 0.1193 0.1046 0.0918 0.0772 0.0648 0.0599 0.0569 0.0561 0.0533 0.0516 0.0504 0.0493 0.0486 0.0486 

[TRAIN] Epoch[1](12399/114412); Loss: 0.073711; Backpropagation: 0.2912 sec; Batch: 2.1112 sec
0.1398 0.1345 0.1021 0.0885 0.0792 0.0724 0.0667 0.0632 0.0598 0.0571 0.0554 0.0541 0.0528 0.0517 0.0511 0.0510 

[TRAIN] Epoch[1](12400/114412); Loss: 0.139140; Backpropagation: 0.2909 sec; Batch: 2.1306 sec
0.2419 0.2387 0.2014 0.1853 0.1670 0.1452 0.1341 0.1218 0.1128 0.1066 0.1020 0.0994 0.0982 0.0946 0.0903 0.0868 

[TRAIN] Epoch[1](12401/114412); Loss: 0.066539; Backpropagation: 0.2915 sec; Batch: 2.0860 sec
0.1305 0.1215 0.0879 0.0808 0.0691 0.0630 0.0596 0.0565 0.0529 0.0515 0.0503 0.0492 0.0486 0.0480 0.0477 0.0475 

[TRAIN] Epoch[1](12402/114412); Loss: 0.109900; Backpropagation: 0.2905 sec; Batch: 2.0846 sec
0.1693 0.1677 0.1454 0.1337 0.1227 0.1119 0.1064 0.1002 0.0950 0.0916 0.0889 0.0870 0.0862 0.0852 0.0840 0.0831 

[TRAIN] Epoch[1](12403/114412); Loss: 0.088957; Backpropagation: 0.2905 sec; Batch: 2.0861 sec
0.1292 0.1252 0.1097 0.1007 0.0918 0.0854 0.0832 0.0806 0.0787 0.0777 0.0776 0.0767 0.0767 0.0766 0.0767 0.0768 

[TRAIN] Epoch[1](12404/114412); Loss: 0.081324; Backpropagation: 0.2913 sec; Batch: 2.1020 sec
0.1267 0.1230 0.1000 0.0906 0.0854 0.0798 0.0769 0.0739 0.0708 0.0701 0.0685 0.0675 0.0674 0.0672 0.0669 0.0665 

[TRAIN] Epoch[1](12405/114412); Loss: 0.080257; Backpropagation: 0.2915 sec; Batch: 2.1187 sec
0.1458 0.1409 0.1039 0.0961 0.0870 0.0786 0.0755 0.0704 0.0674 0.0641 0.0619 0.0602 0.0591 0.0582 0.0577 0.0572 

[TRAIN] Epoch[1](12406/114412); Loss: 0.081628; Backpropagation: 0.2918 sec; Batch: 2.1209 sec
0.1504 0.1428 0.1016 0.0905 0.0811 0.0753 0.0714 0.0691 0.0683 0.0681 0.0673 0.0664 0.0646 0.0633 0.0634 0.0624 

[TRAIN] Epoch[1](12407/114412); Loss: 0.075462; Backpropagation: 0.2932 sec; Batch: 2.1129 sec
0.1319 0.1275 0.0923 0.0821 0.0753 0.0710 0.0692 0.0672 0.0657 0.0642 0.0626 0.0614 0.0603 0.0596 0.0591 0.0582 

[TRAIN] Epoch[1](12408/114412); Loss: 0.088133; Backpropagation: 0.2906 sec; Batch: 2.1130 sec
0.1295 0.1251 0.1062 0.0991 0.0943 0.0890 0.0846 0.0821 0.0799 0.0781 0.0760 0.0748 0.0736 0.0731 0.0727 0.0721 

[TRAIN] Epoch[1](12409/114412); Loss: 0.078925; Backpropagation: 0.2908 sec; Batch: 2.0772 sec
0.1373 0.1335 0.0983 0.0884 0.0805 0.0775 0.0737 0.0693 0.0672 0.0659 0.0646 0.0632 0.0618 0.0611 0.0605 0.0600 

[TRAIN] Epoch[1](12410/114412); Loss: 0.083551; Backpropagation: 0.2905 sec; Batch: 2.1130 sec
0.1568 0.1508 0.1173 0.0982 0.0846 0.0810 0.0749 0.0709 0.0685 0.0666 0.0644 0.0631 0.0615 0.0602 0.0594 0.0587 

[TRAIN] Epoch[1](12411/114412); Loss: 0.090249; Backpropagation: 0.2910 sec; Batch: 2.1175 sec
0.1622 0.1591 0.1265 0.1066 0.0865 0.0828 0.0809 0.0784 0.0766 0.0749 0.0724 0.0705 0.0685 0.0671 0.0658 0.0651 

[TRAIN] Epoch[1](12412/114412); Loss: 0.091304; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1376 0.1344 0.1121 0.0970 0.0925 0.0889 0.0857 0.0834 0.0820 0.0805 0.0794 0.0786 0.0777 0.0772 0.0769 0.0768 

[TRAIN] Epoch[1](12413/114412); Loss: 0.091278; Backpropagation: 0.2955 sec; Batch: 2.1227 sec
0.1391 0.1393 0.1185 0.1055 0.0961 0.0883 0.0851 0.0822 0.0794 0.0778 0.0766 0.0758 0.0749 0.0744 0.0740 0.0737 

[TRAIN] Epoch[1](12414/114412); Loss: 0.097169; Backpropagation: 0.2931 sec; Batch: 2.1150 sec
0.1957 0.1839 0.1420 0.1258 0.1075 0.0941 0.0843 0.0788 0.0750 0.0725 0.0703 0.0687 0.0667 0.0648 0.0628 0.0618 

[TRAIN] Epoch[1](12415/114412); Loss: 0.086545; Backpropagation: 0.2950 sec; Batch: 2.1226 sec
0.1600 0.1519 0.1243 0.1068 0.0896 0.0837 0.0794 0.0758 0.0728 0.0687 0.0659 0.0637 0.0622 0.0610 0.0598 0.0590 

[TRAIN] Epoch[1](12416/114412); Loss: 0.079210; Backpropagation: 0.2913 sec; Batch: 2.1140 sec
0.1432 0.1398 0.1055 0.0920 0.0846 0.0772 0.0724 0.0690 0.0666 0.0650 0.0637 0.0614 0.0583 0.0571 0.0561 0.0555 

[TRAIN] Epoch[1](12417/114412); Loss: 0.104173; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.1960 0.1949 0.1521 0.1330 0.1126 0.1007 0.0952 0.0896 0.0854 0.0812 0.0776 0.0741 0.0716 0.0693 0.0673 0.0664 

[TRAIN] Epoch[1](12418/114412); Loss: 0.116723; Backpropagation: 0.2906 sec; Batch: 2.1131 sec
0.1780 0.1714 0.1446 0.1336 0.1250 0.1165 0.1111 0.1067 0.1039 0.1010 0.0994 0.0977 0.0964 0.0947 0.0941 0.0934 

[TRAIN] Epoch[1](12419/114412); Loss: 0.086900; Backpropagation: 0.2913 sec; Batch: 2.1240 sec
0.1414 0.1414 0.1102 0.0995 0.0903 0.0850 0.0805 0.0764 0.0745 0.0734 0.0721 0.0710 0.0700 0.0691 0.0681 0.0676 

[TRAIN] Epoch[1](12420/114412); Loss: 0.079064; Backpropagation: 0.2918 sec; Batch: 2.1165 sec
0.1393 0.1382 0.1051 0.0863 0.0751 0.0704 0.0688 0.0693 0.0680 0.0667 0.0656 0.0644 0.0634 0.0625 0.0613 0.0608 

[TRAIN] Epoch[1](12421/114412); Loss: 0.093798; Backpropagation: 0.2918 sec; Batch: 2.1229 sec
0.1460 0.1404 0.1189 0.1113 0.1051 0.0996 0.0919 0.0863 0.0824 0.0789 0.0768 0.0747 0.0734 0.0724 0.0717 0.0710 

[TRAIN] Epoch[1](12422/114412); Loss: 0.098017; Backpropagation: 0.2915 sec; Batch: 2.1190 sec
0.1557 0.1508 0.1255 0.1119 0.1013 0.0963 0.0917 0.0889 0.0870 0.0842 0.0821 0.0815 0.0799 0.0785 0.0770 0.0758 

[TRAIN] Epoch[1](12423/114412); Loss: 0.120871; Backpropagation: 0.2932 sec; Batch: 2.1121 sec
0.1913 0.1933 0.1606 0.1461 0.1333 0.1214 0.1175 0.1118 0.1084 0.1061 0.1015 0.0954 0.0911 0.0877 0.0850 0.0835 

[TRAIN] Epoch[1](12424/114412); Loss: 0.076092; Backpropagation: 0.2913 sec; Batch: 2.1190 sec
0.1265 0.1152 0.0968 0.0844 0.0799 0.0763 0.0730 0.0696 0.0671 0.0651 0.0630 0.0617 0.0606 0.0599 0.0595 0.0590 

[TRAIN] Epoch[1](12425/114412); Loss: 0.093464; Backpropagation: 0.2916 sec; Batch: 2.1136 sec
0.1555 0.1387 0.1154 0.1032 0.0961 0.0926 0.0888 0.0852 0.0827 0.0806 0.0787 0.0770 0.0762 0.0754 0.0749 0.0745 

[TRAIN] Epoch[1](12426/114412); Loss: 0.097195; Backpropagation: 0.2911 sec; Batch: 2.0973 sec
0.1484 0.1417 0.1161 0.1114 0.1059 0.1008 0.0974 0.0929 0.0892 0.0858 0.0834 0.0807 0.0778 0.0760 0.0745 0.0732 

[TRAIN] Epoch[1](12427/114412); Loss: 0.108348; Backpropagation: 0.2953 sec; Batch: 2.1299 sec
0.1836 0.1794 0.1514 0.1370 0.1202 0.1091 0.1009 0.0943 0.0905 0.0876 0.0848 0.0824 0.0802 0.0786 0.0772 0.0761 

[TRAIN] Epoch[1](12428/114412); Loss: 0.078478; Backpropagation: 0.2922 sec; Batch: 2.1182 sec
0.1280 0.1276 0.1009 0.0881 0.0823 0.0781 0.0740 0.0712 0.0688 0.0669 0.0650 0.0636 0.0620 0.0608 0.0597 0.0585 

[TRAIN] Epoch[1](12429/114412); Loss: 0.067295; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1218 0.1115 0.0833 0.0738 0.0677 0.0641 0.0618 0.0596 0.0576 0.0564 0.0554 0.0544 0.0532 0.0525 0.0520 0.0515 

[TRAIN] Epoch[1](12430/114412); Loss: 0.106985; Backpropagation: 0.2906 sec; Batch: 2.1008 sec
0.1696 0.1686 0.1429 0.1324 0.1178 0.1061 0.0999 0.0950 0.0918 0.0894 0.0871 0.0845 0.0835 0.0820 0.0810 0.0803 

[TRAIN] Epoch[1](12431/114412); Loss: 0.112114; Backpropagation: 0.2907 sec; Batch: 2.0914 sec
0.1660 0.1629 0.1352 0.1278 0.1202 0.1141 0.1102 0.1069 0.1039 0.1002 0.0971 0.0944 0.0920 0.0900 0.0874 0.0856 

[TRAIN] Epoch[1](12432/114412); Loss: 0.150207; Backpropagation: 0.2910 sec; Batch: 2.1159 sec
0.2489 0.2552 0.2152 0.2065 0.1847 0.1643 0.1554 0.1392 0.1276 0.1177 0.1114 0.1058 0.1009 0.0951 0.0901 0.0853 

[TRAIN] Epoch[1](12433/114412); Loss: 0.088775; Backpropagation: 0.2913 sec; Batch: 2.1185 sec
0.1370 0.1323 0.1058 0.0978 0.0926 0.0882 0.0862 0.0826 0.0806 0.0786 0.0761 0.0748 0.0736 0.0720 0.0713 0.0709 

[TRAIN] Epoch[1](12434/114412); Loss: 0.068600; Backpropagation: 0.2914 sec; Batch: 2.0892 sec
0.1060 0.1063 0.0832 0.0753 0.0727 0.0681 0.0669 0.0640 0.0616 0.0599 0.0579 0.0567 0.0556 0.0549 0.0545 0.0543 

[TRAIN] Epoch[1](12435/114412); Loss: 0.083133; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1589 0.1572 0.1200 0.0983 0.0796 0.0704 0.0749 0.0726 0.0689 0.0663 0.0640 0.0625 0.0617 0.0599 0.0582 0.0568 

[TRAIN] Epoch[1](12436/114412); Loss: 0.078618; Backpropagation: 0.2911 sec; Batch: 2.1182 sec
0.1626 0.1581 0.1171 0.0926 0.0794 0.0744 0.0675 0.0636 0.0615 0.0580 0.0569 0.0554 0.0532 0.0528 0.0526 0.0521 

[TRAIN] Epoch[1](12437/114412); Loss: 0.062964; Backpropagation: 0.2913 sec; Batch: 2.1174 sec
0.1106 0.1090 0.0789 0.0684 0.0618 0.0593 0.0581 0.0563 0.0548 0.0535 0.0520 0.0510 0.0501 0.0488 0.0478 0.0470 

[TRAIN] Epoch[1](12438/114412); Loss: 0.113008; Backpropagation: 0.2913 sec; Batch: 2.1367 sec
0.1714 0.1631 0.1395 0.1309 0.1235 0.1166 0.1125 0.1082 0.1041 0.1010 0.0971 0.0932 0.0900 0.0876 0.0856 0.0841 

[TRAIN] Epoch[1](12439/114412); Loss: 0.073499; Backpropagation: 0.2919 sec; Batch: 2.1191 sec
0.1239 0.1238 0.0944 0.0860 0.0789 0.0725 0.0686 0.0646 0.0621 0.0604 0.0592 0.0582 0.0569 0.0562 0.0555 0.0547 

[TRAIN] Epoch[1](12440/114412); Loss: 0.102993; Backpropagation: 0.3009 sec; Batch: 2.1279 sec
0.1948 0.1918 0.1534 0.1359 0.1102 0.0924 0.0846 0.0839 0.0815 0.0781 0.0763 0.0748 0.0737 0.0730 0.0722 0.0715 

[TRAIN] Epoch[1](12441/114412); Loss: 0.072586; Backpropagation: 0.2956 sec; Batch: 2.1247 sec
0.1304 0.1283 0.0966 0.0822 0.0722 0.0713 0.0676 0.0644 0.0617 0.0597 0.0579 0.0568 0.0552 0.0538 0.0522 0.0510 

[TRAIN] Epoch[1](12442/114412); Loss: 0.093570; Backpropagation: 0.2979 sec; Batch: 2.0904 sec
0.1315 0.1305 0.1062 0.1010 0.0984 0.0964 0.0939 0.0895 0.0863 0.0845 0.0828 0.0813 0.0804 0.0792 0.0780 0.0770 

[TRAIN] Epoch[1](12443/114412); Loss: 0.086894; Backpropagation: 0.2962 sec; Batch: 2.1187 sec
0.1554 0.1529 0.1207 0.1090 0.0973 0.0886 0.0814 0.0743 0.0700 0.0674 0.0650 0.0639 0.0626 0.0615 0.0606 0.0598 

[TRAIN] Epoch[1](12444/114412); Loss: 0.102140; Backpropagation: 0.2982 sec; Batch: 2.1442 sec
0.1834 0.1807 0.1481 0.1354 0.1233 0.1103 0.1011 0.0905 0.0824 0.0768 0.0730 0.0710 0.0682 0.0657 0.0631 0.0612 

[TRAIN] Epoch[1](12445/114412); Loss: 0.086496; Backpropagation: 0.2954 sec; Batch: 2.1246 sec
0.1389 0.1332 0.1096 0.1002 0.0924 0.0858 0.0821 0.0774 0.0754 0.0736 0.0716 0.0707 0.0696 0.0686 0.0677 0.0672 

[TRAIN] Epoch[1](12446/114412); Loss: 0.081289; Backpropagation: 0.2950 sec; Batch: 2.1195 sec
0.1258 0.1235 0.1048 0.0965 0.0877 0.0823 0.0793 0.0770 0.0741 0.0710 0.0683 0.0656 0.0633 0.0615 0.0601 0.0597 

[TRAIN] Epoch[1](12447/114412); Loss: 0.093252; Backpropagation: 0.3011 sec; Batch: 2.1260 sec
0.1707 0.1641 0.1291 0.1106 0.0940 0.0893 0.0857 0.0809 0.0780 0.0754 0.0737 0.0714 0.0695 0.0679 0.0664 0.0652 

[TRAIN] Epoch[1](12448/114412); Loss: 0.113571; Backpropagation: 0.2982 sec; Batch: 2.0856 sec
0.1779 0.1756 0.1439 0.1318 0.1253 0.1186 0.1115 0.1043 0.0998 0.0961 0.0940 0.0915 0.0895 0.0874 0.0857 0.0841 

[TRAIN] Epoch[1](12449/114412); Loss: 0.057506; Backpropagation: 0.2954 sec; Batch: 2.1230 sec
0.1090 0.1109 0.0710 0.0616 0.0613 0.0595 0.0554 0.0516 0.0485 0.0458 0.0438 0.0424 0.0413 0.0400 0.0393 0.0387 

[TRAIN] Epoch[1](12450/114412); Loss: 0.098343; Backpropagation: 0.2977 sec; Batch: 2.0886 sec
0.1734 0.1725 0.1368 0.1275 0.1119 0.0993 0.0931 0.0864 0.0811 0.0761 0.0736 0.0716 0.0701 0.0682 0.0668 0.0653 

[TRAIN] Epoch[1](12451/114412); Loss: 0.092992; Backpropagation: 0.2958 sec; Batch: 2.0837 sec
0.1396 0.1388 0.1101 0.1033 0.0982 0.0935 0.0903 0.0873 0.0841 0.0822 0.0800 0.0785 0.0771 0.0758 0.0749 0.0742 

[TRAIN] Epoch[1](12452/114412); Loss: 0.089481; Backpropagation: 0.2975 sec; Batch: 2.0889 sec
0.1374 0.1349 0.1187 0.1106 0.1025 0.0957 0.0902 0.0841 0.0791 0.0759 0.0730 0.0700 0.0675 0.0655 0.0640 0.0626 

[TRAIN] Epoch[1](12453/114412); Loss: 0.104200; Backpropagation: 0.2972 sec; Batch: 2.0869 sec
0.1587 0.1555 0.1288 0.1221 0.1146 0.1083 0.1037 0.0977 0.0935 0.0900 0.0875 0.0849 0.0828 0.0811 0.0796 0.0784 

[TRAIN] Epoch[1](12454/114412); Loss: 0.077989; Backpropagation: 0.2982 sec; Batch: 2.1297 sec
0.1241 0.1207 0.0968 0.0876 0.0823 0.0790 0.0756 0.0718 0.0695 0.0675 0.0655 0.0637 0.0625 0.0614 0.0604 0.0597 

[TRAIN] Epoch[1](12455/114412); Loss: 0.108670; Backpropagation: 0.2970 sec; Batch: 2.0864 sec
0.1563 0.1566 0.1326 0.1247 0.1187 0.1115 0.1059 0.1009 0.0970 0.0947 0.0928 0.0914 0.0901 0.0894 0.0885 0.0877 

[TRAIN] Epoch[1](12456/114412); Loss: 0.093774; Backpropagation: 0.2956 sec; Batch: 2.1228 sec
0.1560 0.1549 0.1275 0.1166 0.1045 0.0956 0.0888 0.0828 0.0796 0.0774 0.0748 0.0721 0.0697 0.0678 0.0665 0.0657 

[TRAIN] Epoch[1](12457/114412); Loss: 0.084574; Backpropagation: 0.2955 sec; Batch: 2.1243 sec
0.1619 0.1574 0.1137 0.0979 0.0836 0.0773 0.0752 0.0717 0.0691 0.0677 0.0658 0.0648 0.0635 0.0624 0.0611 0.0602 

[TRAIN] Epoch[1](12458/114412); Loss: 0.116780; Backpropagation: 0.2954 sec; Batch: 2.1215 sec
0.1876 0.1813 0.1503 0.1401 0.1301 0.1221 0.1148 0.1101 0.1053 0.1012 0.0975 0.0928 0.0886 0.0847 0.0819 0.0801 

[TRAIN] Epoch[1](12459/114412); Loss: 0.079723; Backpropagation: 0.2957 sec; Batch: 2.1189 sec
0.1171 0.1192 0.1025 0.0951 0.0889 0.0850 0.0804 0.0762 0.0722 0.0687 0.0658 0.0635 0.0618 0.0606 0.0597 0.0590 

[TRAIN] Epoch[1](12460/114412); Loss: 0.091741; Backpropagation: 0.2954 sec; Batch: 2.1336 sec
0.1617 0.1613 0.1259 0.1079 0.0972 0.0902 0.0857 0.0807 0.0770 0.0737 0.0721 0.0711 0.0691 0.0673 0.0645 0.0622 

[TRAIN] Epoch[1](12461/114412); Loss: 0.126657; Backpropagation: 0.2954 sec; Batch: 2.0860 sec
0.1749 0.1693 0.1529 0.1454 0.1385 0.1308 0.1255 0.1215 0.1167 0.1133 0.1114 0.1081 0.1068 0.1054 0.1037 0.1024 

[TRAIN] Epoch[1](12462/114412); Loss: 0.096092; Backpropagation: 0.2982 sec; Batch: 2.1107 sec
0.1667 0.1618 0.1397 0.1261 0.1124 0.0989 0.0908 0.0831 0.0775 0.0744 0.0726 0.0696 0.0677 0.0667 0.0652 0.0643 

[TRAIN] Epoch[1](12463/114412); Loss: 0.126141; Backpropagation: 0.2957 sec; Batch: 2.1227 sec
0.1813 0.1791 0.1525 0.1434 0.1331 0.1258 0.1224 0.1169 0.1145 0.1119 0.1096 0.1080 0.1063 0.1053 0.1044 0.1036 

[TRAIN] Epoch[1](12464/114412); Loss: 0.110711; Backpropagation: 0.2958 sec; Batch: 2.1217 sec
0.1644 0.1693 0.1460 0.1359 0.1262 0.1204 0.1123 0.1046 0.0983 0.0925 0.0885 0.0864 0.0850 0.0829 0.0805 0.0782 

[TRAIN] Epoch[1](12465/114412); Loss: 0.099295; Backpropagation: 0.2959 sec; Batch: 2.1225 sec
0.1555 0.1494 0.1258 0.1171 0.1079 0.1020 0.0970 0.0918 0.0882 0.0849 0.0825 0.0804 0.0788 0.0772 0.0754 0.0748 

[TRAIN] Epoch[1](12466/114412); Loss: 0.105919; Backpropagation: 0.2947 sec; Batch: 2.1198 sec
0.1620 0.1591 0.1364 0.1280 0.1171 0.1082 0.1032 0.0976 0.0946 0.0920 0.0897 0.0868 0.0836 0.0815 0.0785 0.0762 

[TRAIN] Epoch[1](12467/114412); Loss: 0.085649; Backpropagation: 0.2961 sec; Batch: 2.1380 sec
0.1458 0.1358 0.1158 0.1018 0.0923 0.0860 0.0809 0.0753 0.0721 0.0702 0.0687 0.0667 0.0657 0.0650 0.0644 0.0639 

[TRAIN] Epoch[1](12468/114412); Loss: 0.092380; Backpropagation: 0.2960 sec; Batch: 2.1218 sec
0.1447 0.1447 0.1226 0.1171 0.1091 0.0999 0.0939 0.0864 0.0808 0.0767 0.0729 0.0700 0.0678 0.0654 0.0639 0.0620 

[TRAIN] Epoch[1](12469/114412); Loss: 0.090922; Backpropagation: 0.3032 sec; Batch: 2.0937 sec
0.1344 0.1312 0.1100 0.1017 0.0950 0.0902 0.0869 0.0847 0.0829 0.0808 0.0790 0.0774 0.0762 0.0754 0.0749 0.0742 

[TRAIN] Epoch[1](12470/114412); Loss: 0.100877; Backpropagation: 0.2980 sec; Batch: 2.1275 sec
0.1678 0.1588 0.1285 0.1129 0.1031 0.0965 0.0922 0.0899 0.0875 0.0853 0.0841 0.0828 0.0822 0.0815 0.0807 0.0801 

[TRAIN] Epoch[1](12471/114412); Loss: 0.093050; Backpropagation: 0.2952 sec; Batch: 2.0818 sec
0.1843 0.1883 0.1432 0.1255 0.1051 0.0884 0.0845 0.0752 0.0703 0.0668 0.0638 0.0611 0.0596 0.0582 0.0575 0.0571 

[TRAIN] Epoch[1](12472/114412); Loss: 0.070076; Backpropagation: 0.2952 sec; Batch: 2.1223 sec
0.1131 0.1111 0.0854 0.0799 0.0768 0.0729 0.0685 0.0664 0.0636 0.0609 0.0589 0.0561 0.0538 0.0525 0.0509 0.0505 

[TRAIN] Epoch[1](12473/114412); Loss: 0.086500; Backpropagation: 0.2958 sec; Batch: 2.1218 sec
0.1604 0.1575 0.1179 0.0920 0.0837 0.0805 0.0774 0.0747 0.0727 0.0705 0.0694 0.0679 0.0667 0.0655 0.0643 0.0629 

[TRAIN] Epoch[1](12474/114412); Loss: 0.088643; Backpropagation: 0.2955 sec; Batch: 2.1213 sec
0.1459 0.1408 0.1154 0.1060 0.0943 0.0893 0.0844 0.0803 0.0770 0.0738 0.0719 0.0704 0.0690 0.0677 0.0665 0.0654 

[TRAIN] Epoch[1](12475/114412); Loss: 0.067792; Backpropagation: 0.2957 sec; Batch: 2.1258 sec
0.1273 0.1229 0.0906 0.0815 0.0715 0.0640 0.0607 0.0570 0.0552 0.0539 0.0523 0.0510 0.0502 0.0492 0.0489 0.0485 

[TRAIN] Epoch[1](12476/114412); Loss: 0.095215; Backpropagation: 0.2957 sec; Batch: 2.1219 sec
0.1840 0.1851 0.1380 0.1217 0.1055 0.0914 0.0845 0.0800 0.0762 0.0726 0.0690 0.0659 0.0641 0.0629 0.0617 0.0606 

[TRAIN] Epoch[1](12477/114412); Loss: 0.080061; Backpropagation: 0.2960 sec; Batch: 2.0835 sec
0.1327 0.1320 0.1069 0.0920 0.0809 0.0773 0.0744 0.0720 0.0697 0.0676 0.0659 0.0640 0.0625 0.0616 0.0609 0.0602 

[TRAIN] Epoch[1](12478/114412); Loss: 0.100126; Backpropagation: 0.2958 sec; Batch: 2.0993 sec
0.1833 0.1677 0.1302 0.1101 0.1015 0.1010 0.0939 0.0911 0.0864 0.0836 0.0813 0.0786 0.0760 0.0741 0.0723 0.0709 

[TRAIN] Epoch[1](12479/114412); Loss: 0.103235; Backpropagation: 0.2992 sec; Batch: 2.0864 sec
0.1655 0.1721 0.1392 0.1298 0.1158 0.1065 0.1035 0.0962 0.0903 0.0845 0.0813 0.0770 0.0745 0.0732 0.0719 0.0704 

[TRAIN] Epoch[1](12480/114412); Loss: 0.117310; Backpropagation: 0.2957 sec; Batch: 2.0834 sec
0.1796 0.1775 0.1494 0.1323 0.1239 0.1206 0.1154 0.1095 0.1063 0.1021 0.0988 0.0964 0.0941 0.0922 0.0904 0.0886 

[TRAIN] Epoch[1](12481/114412); Loss: 0.097676; Backpropagation: 0.2984 sec; Batch: 2.1073 sec
0.1580 0.1541 0.1204 0.1152 0.1093 0.1020 0.0957 0.0890 0.0851 0.0820 0.0794 0.0772 0.0754 0.0744 0.0735 0.0724 

[TRAIN] Epoch[1](12482/114412); Loss: 0.076052; Backpropagation: 0.2961 sec; Batch: 2.1244 sec
0.1240 0.1225 0.0905 0.0853 0.0801 0.0772 0.0737 0.0701 0.0671 0.0647 0.0630 0.0618 0.0606 0.0595 0.0585 0.0581 

[TRAIN] Epoch[1](12483/114412); Loss: 0.085527; Backpropagation: 0.2955 sec; Batch: 2.1192 sec
0.1378 0.1363 0.1080 0.0974 0.0915 0.0869 0.0821 0.0782 0.0754 0.0728 0.0707 0.0689 0.0675 0.0662 0.0648 0.0641 

[TRAIN] Epoch[1](12484/114412); Loss: 0.079693; Backpropagation: 0.2963 sec; Batch: 2.1225 sec
0.1301 0.1311 0.1066 0.1011 0.0918 0.0837 0.0790 0.0729 0.0682 0.0648 0.0622 0.0598 0.0582 0.0563 0.0551 0.0541 

[TRAIN] Epoch[1](12485/114412); Loss: 0.089418; Backpropagation: 0.2959 sec; Batch: 2.1004 sec
0.1571 0.1571 0.1266 0.1167 0.0988 0.0874 0.0803 0.0764 0.0735 0.0709 0.0685 0.0668 0.0646 0.0634 0.0619 0.0609 

[TRAIN] Epoch[1](12486/114412); Loss: 0.119567; Backpropagation: 0.2957 sec; Batch: 2.0855 sec
0.1743 0.1692 0.1466 0.1359 0.1235 0.1176 0.1147 0.1114 0.1092 0.1067 0.1041 0.1023 0.1010 0.0996 0.0988 0.0980 

[TRAIN] Epoch[1](12487/114412); Loss: 0.069328; Backpropagation: 0.2941 sec; Batch: 2.0812 sec
0.1363 0.1326 0.1036 0.0895 0.0776 0.0659 0.0595 0.0552 0.0531 0.0514 0.0497 0.0487 0.0476 0.0467 0.0460 0.0457 

[TRAIN] Epoch[1](12488/114412); Loss: 0.056616; Backpropagation: 0.2948 sec; Batch: 2.1216 sec
0.0898 0.0899 0.0678 0.0640 0.0584 0.0557 0.0531 0.0509 0.0497 0.0485 0.0473 0.0467 0.0464 0.0460 0.0459 0.0456 

[TRAIN] Epoch[1](12489/114412); Loss: 0.088180; Backpropagation: 0.2978 sec; Batch: 2.1243 sec
0.1511 0.1504 0.1159 0.0977 0.0846 0.0864 0.0838 0.0800 0.0774 0.0746 0.0713 0.0694 0.0685 0.0675 0.0663 0.0660 

[TRAIN] Epoch[1](12490/114412); Loss: 0.092100; Backpropagation: 0.2961 sec; Batch: 2.1231 sec
0.1848 0.1811 0.1353 0.1127 0.0959 0.0854 0.0774 0.0737 0.0712 0.0691 0.0671 0.0656 0.0645 0.0635 0.0632 0.0630 

[TRAIN] Epoch[1](12491/114412); Loss: 0.099001; Backpropagation: 0.2953 sec; Batch: 2.1203 sec
0.1522 0.1505 0.1268 0.1194 0.1096 0.1002 0.0943 0.0894 0.0867 0.0848 0.0815 0.0800 0.0789 0.0774 0.0766 0.0756 

[TRAIN] Epoch[1](12492/114412); Loss: 0.090107; Backpropagation: 0.2947 sec; Batch: 2.0820 sec
0.1196 0.1196 0.1088 0.1015 0.0944 0.0903 0.0885 0.0861 0.0839 0.0817 0.0802 0.0793 0.0782 0.0775 0.0765 0.0758 

[TRAIN] Epoch[1](12493/114412); Loss: 0.081766; Backpropagation: 0.2978 sec; Batch: 2.0862 sec
0.1532 0.1484 0.1114 0.0993 0.0893 0.0822 0.0768 0.0714 0.0669 0.0637 0.0605 0.0592 0.0577 0.0568 0.0559 0.0554 

[TRAIN] Epoch[1](12494/114412); Loss: 0.075734; Backpropagation: 0.2982 sec; Batch: 2.1279 sec
0.1532 0.1476 0.1089 0.0888 0.0811 0.0741 0.0684 0.0634 0.0596 0.0566 0.0550 0.0531 0.0518 0.0509 0.0499 0.0493 

[TRAIN] Epoch[1](12495/114412); Loss: 0.101203; Backpropagation: 0.2979 sec; Batch: 2.1329 sec
0.1954 0.1930 0.1572 0.1385 0.1150 0.0993 0.0923 0.0824 0.0747 0.0718 0.0708 0.0687 0.0675 0.0655 0.0641 0.0632 

[TRAIN] Epoch[1](12496/114412); Loss: 0.105626; Backpropagation: 0.2948 sec; Batch: 2.0819 sec
0.1758 0.1711 0.1431 0.1300 0.1173 0.1088 0.1022 0.0959 0.0918 0.0885 0.0840 0.0812 0.0783 0.0755 0.0738 0.0727 

[TRAIN] Epoch[1](12497/114412); Loss: 0.063626; Backpropagation: 0.2948 sec; Batch: 2.1230 sec
0.1288 0.1280 0.0874 0.0694 0.0661 0.0628 0.0584 0.0545 0.0520 0.0501 0.0466 0.0449 0.0435 0.0425 0.0418 0.0413 

[TRAIN] Epoch[1](12498/114412); Loss: 0.068018; Backpropagation: 0.2970 sec; Batch: 2.0847 sec
0.1256 0.1193 0.0878 0.0749 0.0716 0.0671 0.0628 0.0598 0.0570 0.0554 0.0536 0.0520 0.0514 0.0505 0.0499 0.0496 

[TRAIN] Epoch[1](12499/114412); Loss: 0.072888; Backpropagation: 0.2952 sec; Batch: 2.1269 sec
0.1546 0.1535 0.1115 0.0900 0.0702 0.0672 0.0629 0.0585 0.0550 0.0526 0.0509 0.0496 0.0484 0.0480 0.0471 0.0462 

[TRAIN] Epoch[1](12500/114412); Loss: 0.090798; Backpropagation: 0.2951 sec; Batch: 2.1205 sec
0.1474 0.1422 0.1196 0.1082 0.0982 0.0915 0.0861 0.0813 0.0780 0.0752 0.0736 0.0720 0.0711 0.0706 0.0693 0.0685 

[TRAIN] Epoch[1](12501/114412); Loss: 0.069514; Backpropagation: 0.2956 sec; Batch: 2.1267 sec
0.1385 0.1377 0.0958 0.0778 0.0661 0.0649 0.0614 0.0585 0.0564 0.0540 0.0522 0.0511 0.0502 0.0497 0.0492 0.0488 

[TRAIN] Epoch[1](12502/114412); Loss: 0.131377; Backpropagation: 0.2954 sec; Batch: 2.1240 sec
0.2263 0.2249 0.1896 0.1686 0.1455 0.1302 0.1243 0.1167 0.1109 0.1060 0.1011 0.0969 0.0938 0.0914 0.0888 0.0871 

[TRAIN] Epoch[1](12503/114412); Loss: 0.074099; Backpropagation: 0.2958 sec; Batch: 2.0825 sec
0.1528 0.1376 0.1075 0.0909 0.0756 0.0704 0.0648 0.0607 0.0578 0.0551 0.0540 0.0532 0.0520 0.0514 0.0512 0.0506 

[TRAIN] Epoch[1](12504/114412); Loss: 0.091005; Backpropagation: 0.2952 sec; Batch: 2.1243 sec
0.1566 0.1461 0.1139 0.1053 0.0941 0.0885 0.0858 0.0823 0.0794 0.0763 0.0743 0.0728 0.0715 0.0705 0.0696 0.0689 

[TRAIN] Epoch[1](12505/114412); Loss: 0.089603; Backpropagation: 0.2950 sec; Batch: 2.0829 sec
0.1588 0.1569 0.1218 0.1058 0.0911 0.0823 0.0790 0.0766 0.0750 0.0733 0.0715 0.0704 0.0690 0.0681 0.0674 0.0667 

[TRAIN] Epoch[1](12506/114412); Loss: 0.075800; Backpropagation: 0.2987 sec; Batch: 2.1280 sec
0.1443 0.1426 0.1088 0.0959 0.0822 0.0757 0.0697 0.0656 0.0617 0.0578 0.0552 0.0531 0.0516 0.0502 0.0495 0.0487 

[TRAIN] Epoch[1](12507/114412); Loss: 0.075012; Backpropagation: 0.2967 sec; Batch: 2.1265 sec
0.1351 0.1341 0.1048 0.0905 0.0833 0.0773 0.0711 0.0660 0.0615 0.0582 0.0560 0.0544 0.0528 0.0522 0.0516 0.0511 

[TRAIN] Epoch[1](12508/114412); Loss: 0.077226; Backpropagation: 0.2981 sec; Batch: 2.1271 sec
0.1640 0.1544 0.1079 0.0937 0.0786 0.0705 0.0661 0.0625 0.0602 0.0575 0.0559 0.0544 0.0535 0.0527 0.0521 0.0515 

[TRAIN] Epoch[1](12509/114412); Loss: 0.082201; Backpropagation: 0.2980 sec; Batch: 2.0854 sec
0.1515 0.1475 0.1127 0.0980 0.0848 0.0776 0.0735 0.0696 0.0673 0.0653 0.0634 0.0624 0.0614 0.0606 0.0600 0.0595 

[TRAIN] Epoch[1](12510/114412); Loss: 0.070202; Backpropagation: 0.2979 sec; Batch: 2.1253 sec
0.1364 0.1351 0.1014 0.0860 0.0746 0.0675 0.0631 0.0578 0.0552 0.0534 0.0520 0.0505 0.0491 0.0479 0.0471 0.0461 

[TRAIN] Epoch[1](12511/114412); Loss: 0.076635; Backpropagation: 0.2984 sec; Batch: 2.1219 sec
0.1806 0.1714 0.1237 0.1002 0.0794 0.0674 0.0601 0.0561 0.0542 0.0524 0.0502 0.0484 0.0470 0.0460 0.0449 0.0442 

[TRAIN] Epoch[1](12512/114412); Loss: 0.104185; Backpropagation: 0.2956 sec; Batch: 2.0828 sec
0.1666 0.1640 0.1323 0.1227 0.1096 0.1013 0.0960 0.0927 0.0906 0.0886 0.0864 0.0851 0.0842 0.0831 0.0823 0.0815 

[TRAIN] Epoch[1](12513/114412); Loss: 0.074363; Backpropagation: 0.2951 sec; Batch: 2.1250 sec
0.1566 0.1550 0.1178 0.0968 0.0744 0.0626 0.0642 0.0600 0.0569 0.0546 0.0521 0.0504 0.0490 0.0474 0.0464 0.0456 

[TRAIN] Epoch[1](12514/114412); Loss: 0.083906; Backpropagation: 0.2957 sec; Batch: 2.1220 sec
0.1437 0.1401 0.1119 0.1010 0.0911 0.0838 0.0786 0.0745 0.0709 0.0684 0.0662 0.0645 0.0634 0.0623 0.0614 0.0607 

[TRAIN] Epoch[1](12515/114412); Loss: 0.091785; Backpropagation: 0.2955 sec; Batch: 2.0828 sec
0.1567 0.1528 0.1225 0.1042 0.0955 0.0903 0.0854 0.0818 0.0786 0.0757 0.0737 0.0724 0.0713 0.0701 0.0691 0.0686 

[TRAIN] Epoch[1](12516/114412); Loss: 0.103406; Backpropagation: 0.2984 sec; Batch: 2.1223 sec
0.1798 0.1713 0.1340 0.1216 0.1084 0.1005 0.0956 0.0912 0.0874 0.0848 0.0830 0.0815 0.0803 0.0792 0.0783 0.0777 

[TRAIN] Epoch[1](12517/114412); Loss: 0.136349; Backpropagation: 0.2980 sec; Batch: 2.1354 sec
0.2117 0.2108 0.1760 0.1556 0.1498 0.1490 0.1358 0.1326 0.1238 0.1239 0.1151 0.1058 0.1055 0.0995 0.0951 0.0916 

[TRAIN] Epoch[1](12518/114412); Loss: 0.070897; Backpropagation: 0.2985 sec; Batch: 2.1282 sec
0.1456 0.1313 0.0915 0.0806 0.0738 0.0684 0.0638 0.0591 0.0566 0.0549 0.0531 0.0522 0.0516 0.0510 0.0506 0.0502 

[TRAIN] Epoch[1](12519/114412); Loss: 0.082482; Backpropagation: 0.2979 sec; Batch: 2.1235 sec
0.1513 0.1473 0.1186 0.1087 0.0923 0.0831 0.0752 0.0683 0.0640 0.0620 0.0606 0.0594 0.0585 0.0577 0.0568 0.0559 

[TRAIN] Epoch[1](12520/114412); Loss: 0.046136; Backpropagation: 0.2950 sec; Batch: 2.1191 sec
0.0832 0.0773 0.0556 0.0497 0.0487 0.0472 0.0435 0.0407 0.0392 0.0382 0.0372 0.0361 0.0358 0.0355 0.0352 0.0352 

[TRAIN] Epoch[1](12521/114412); Loss: 0.087232; Backpropagation: 0.2971 sec; Batch: 2.1235 sec
0.1454 0.1417 0.1151 0.1057 0.0931 0.0847 0.0801 0.0772 0.0747 0.0725 0.0706 0.0692 0.0680 0.0669 0.0657 0.0650 

[TRAIN] Epoch[1](12522/114412); Loss: 0.082006; Backpropagation: 0.2981 sec; Batch: 2.1227 sec
0.1466 0.1424 0.1139 0.1018 0.0881 0.0791 0.0750 0.0704 0.0676 0.0649 0.0631 0.0619 0.0609 0.0598 0.0588 0.0579 

[TRAIN] Epoch[1](12523/114412); Loss: 0.087565; Backpropagation: 0.2960 sec; Batch: 2.1236 sec
0.1529 0.1493 0.1249 0.1088 0.0936 0.0843 0.0779 0.0734 0.0708 0.0695 0.0690 0.0679 0.0664 0.0649 0.0642 0.0633 

[TRAIN] Epoch[1](12524/114412); Loss: 0.074238; Backpropagation: 0.2955 sec; Batch: 2.1246 sec
0.1332 0.1308 0.1097 0.0974 0.0823 0.0733 0.0662 0.0618 0.0588 0.0571 0.0556 0.0542 0.0531 0.0522 0.0513 0.0508 

[TRAIN] Epoch[1](12525/114412); Loss: 0.083065; Backpropagation: 0.2958 sec; Batch: 2.1223 sec
0.1323 0.1310 0.1071 0.0986 0.0893 0.0828 0.0783 0.0747 0.0720 0.0700 0.0682 0.0667 0.0657 0.0648 0.0642 0.0634 

[TRAIN] Epoch[1](12526/114412); Loss: 0.058390; Backpropagation: 0.2976 sec; Batch: 2.1235 sec
0.1331 0.1226 0.0809 0.0636 0.0520 0.0521 0.0498 0.0473 0.0454 0.0439 0.0428 0.0420 0.0406 0.0401 0.0393 0.0387 

[TRAIN] Epoch[1](12527/114412); Loss: 0.063708; Backpropagation: 0.3005 sec; Batch: 2.1277 sec
0.1263 0.1151 0.0909 0.0800 0.0665 0.0607 0.0583 0.0540 0.0514 0.0491 0.0467 0.0457 0.0446 0.0437 0.0433 0.0431 

[TRAIN] Epoch[1](12528/114412); Loss: 0.096319; Backpropagation: 0.2985 sec; Batch: 2.1270 sec
0.1803 0.1742 0.1350 0.1202 0.0998 0.0843 0.0819 0.0783 0.0773 0.0760 0.0744 0.0731 0.0723 0.0716 0.0713 0.0711 

[TRAIN] Epoch[1](12529/114412); Loss: 0.068861; Backpropagation: 0.2983 sec; Batch: 2.1213 sec
0.1278 0.1219 0.0991 0.0860 0.0746 0.0651 0.0615 0.0577 0.0551 0.0538 0.0522 0.0511 0.0504 0.0495 0.0484 0.0476 

[TRAIN] Epoch[1](12530/114412); Loss: 0.078569; Backpropagation: 0.3012 sec; Batch: 2.1046 sec
0.1520 0.1443 0.1004 0.0894 0.0814 0.0741 0.0704 0.0674 0.0646 0.0623 0.0609 0.0595 0.0586 0.0577 0.0572 0.0567 

[TRAIN] Epoch[1](12531/114412); Loss: 0.073789; Backpropagation: 0.2978 sec; Batch: 2.1259 sec
0.1377 0.1368 0.1021 0.0886 0.0750 0.0682 0.0680 0.0644 0.0615 0.0585 0.0566 0.0549 0.0535 0.0525 0.0516 0.0508 

[TRAIN] Epoch[1](12532/114412); Loss: 0.084212; Backpropagation: 0.2980 sec; Batch: 2.1219 sec
0.1685 0.1675 0.1317 0.1148 0.0890 0.0740 0.0708 0.0673 0.0643 0.0622 0.0590 0.0580 0.0573 0.0550 0.0543 0.0537 

[TRAIN] Epoch[1](12533/114412); Loss: 0.094121; Backpropagation: 0.3011 sec; Batch: 2.1291 sec
0.1565 0.1495 0.1186 0.1068 0.0974 0.0917 0.0884 0.0845 0.0824 0.0796 0.0775 0.0766 0.0756 0.0741 0.0737 0.0730 

[TRAIN] Epoch[1](12534/114412); Loss: 0.132696; Backpropagation: 0.2982 sec; Batch: 2.1342 sec
0.2174 0.2110 0.1876 0.1707 0.1551 0.1449 0.1304 0.1206 0.1153 0.1069 0.1015 0.0985 0.0947 0.0912 0.0899 0.0874 

[TRAIN] Epoch[1](12535/114412); Loss: 0.085887; Backpropagation: 0.2983 sec; Batch: 2.0852 sec
0.1453 0.1413 0.1136 0.1029 0.0917 0.0843 0.0810 0.0771 0.0736 0.0716 0.0689 0.0670 0.0658 0.0642 0.0633 0.0626 

[TRAIN] Epoch[1](12536/114412); Loss: 0.101637; Backpropagation: 0.2956 sec; Batch: 2.0821 sec
0.1723 0.1645 0.1373 0.1252 0.1115 0.1015 0.0955 0.0899 0.0863 0.0828 0.0808 0.0784 0.0767 0.0755 0.0742 0.0736 

[TRAIN] Epoch[1](12537/114412); Loss: 0.097068; Backpropagation: 0.2954 sec; Batch: 2.1216 sec
0.1558 0.1496 0.1256 0.1152 0.1053 0.0977 0.0920 0.0881 0.0843 0.0819 0.0796 0.0775 0.0766 0.0754 0.0747 0.0738 

[TRAIN] Epoch[1](12538/114412); Loss: 0.071132; Backpropagation: 0.2982 sec; Batch: 2.1304 sec
0.1482 0.1361 0.0981 0.0829 0.0712 0.0658 0.0626 0.0593 0.0565 0.0545 0.0527 0.0516 0.0505 0.0500 0.0494 0.0488 

[TRAIN] Epoch[1](12539/114412); Loss: 0.080817; Backpropagation: 0.2957 sec; Batch: 2.1204 sec
0.1395 0.1379 0.1046 0.0915 0.0807 0.0779 0.0746 0.0718 0.0695 0.0673 0.0652 0.0643 0.0633 0.0624 0.0616 0.0610 

[TRAIN] Epoch[1](12540/114412); Loss: 0.080455; Backpropagation: 0.2947 sec; Batch: 2.1197 sec
0.1487 0.1435 0.1103 0.0979 0.0876 0.0816 0.0760 0.0713 0.0673 0.0635 0.0604 0.0582 0.0566 0.0555 0.0548 0.0541 

[TRAIN] Epoch[1](12541/114412); Loss: 0.101520; Backpropagation: 0.2954 sec; Batch: 2.1193 sec
0.1853 0.1815 0.1416 0.1159 0.0984 0.0908 0.0901 0.0861 0.0841 0.0821 0.0800 0.0793 0.0787 0.0776 0.0766 0.0762 

[TRAIN] Epoch[1](12542/114412); Loss: 0.065589; Backpropagation: 0.2979 sec; Batch: 2.1250 sec
0.1079 0.1065 0.0857 0.0768 0.0694 0.0648 0.0611 0.0580 0.0557 0.0543 0.0530 0.0523 0.0517 0.0513 0.0506 0.0504 

[TRAIN] Epoch[1](12543/114412); Loss: 0.089820; Backpropagation: 0.2984 sec; Batch: 2.1322 sec
0.1555 0.1505 0.1238 0.1125 0.0984 0.0899 0.0838 0.0791 0.0748 0.0716 0.0693 0.0674 0.0663 0.0654 0.0648 0.0640 

[TRAIN] Epoch[1](12544/114412); Loss: 0.064490; Backpropagation: 0.2928 sec; Batch: 2.1245 sec
0.1150 0.1135 0.0870 0.0757 0.0666 0.0623 0.0580 0.0554 0.0531 0.0515 0.0505 0.0497 0.0491 0.0485 0.0481 0.0479 

[TRAIN] Epoch[1](12545/114412); Loss: 0.079731; Backpropagation: 0.2954 sec; Batch: 2.0983 sec
0.1579 0.1560 0.1209 0.0987 0.0794 0.0739 0.0693 0.0653 0.0625 0.0598 0.0580 0.0569 0.0557 0.0546 0.0539 0.0531 

[TRAIN] Epoch[1](12546/114412); Loss: 0.085760; Backpropagation: 0.2931 sec; Batch: 2.1164 sec
0.1355 0.1283 0.1089 0.1001 0.0924 0.0864 0.0824 0.0778 0.0752 0.0729 0.0711 0.0700 0.0688 0.0682 0.0674 0.0667 

[TRAIN] Epoch[1](12547/114412); Loss: 0.071711; Backpropagation: 0.2914 sec; Batch: 2.0769 sec
0.1206 0.1170 0.0933 0.0840 0.0751 0.0699 0.0656 0.0632 0.0612 0.0600 0.0584 0.0579 0.0567 0.0556 0.0547 0.0542 

[TRAIN] Epoch[1](12548/114412); Loss: 0.087949; Backpropagation: 0.2918 sec; Batch: 2.1206 sec
0.1635 0.1585 0.1221 0.1042 0.0894 0.0838 0.0782 0.0738 0.0709 0.0687 0.0677 0.0667 0.0658 0.0651 0.0645 0.0641 

[TRAIN] Epoch[1](12549/114412); Loss: 0.096905; Backpropagation: 0.2910 sec; Batch: 2.1212 sec
0.1573 0.1530 0.1269 0.1170 0.1039 0.0965 0.0895 0.0853 0.0825 0.0805 0.0790 0.0778 0.0766 0.0756 0.0748 0.0742 

[TRAIN] Epoch[1](12550/114412); Loss: 0.075420; Backpropagation: 0.2907 sec; Batch: 2.1163 sec
0.1346 0.1224 0.1034 0.0913 0.0785 0.0728 0.0693 0.0664 0.0637 0.0622 0.0603 0.0588 0.0572 0.0561 0.0553 0.0545 

[TRAIN] Epoch[1](12551/114412); Loss: 0.091350; Backpropagation: 0.2904 sec; Batch: 2.1175 sec
0.1661 0.1623 0.1236 0.1069 0.0966 0.0912 0.0840 0.0789 0.0759 0.0729 0.0712 0.0690 0.0669 0.0659 0.0653 0.0647 

[TRAIN] Epoch[1](12552/114412); Loss: 0.070133; Backpropagation: 0.2904 sec; Batch: 2.1165 sec
0.1385 0.1294 0.0993 0.0854 0.0724 0.0663 0.0616 0.0585 0.0564 0.0545 0.0527 0.0516 0.0502 0.0493 0.0484 0.0477 

[TRAIN] Epoch[1](12553/114412); Loss: 0.081504; Backpropagation: 0.2920 sec; Batch: 2.0779 sec
0.1486 0.1474 0.1183 0.1044 0.0891 0.0774 0.0712 0.0678 0.0657 0.0633 0.0610 0.0594 0.0585 0.0578 0.0572 0.0568 

[TRAIN] Epoch[1](12554/114412); Loss: 0.096966; Backpropagation: 0.2917 sec; Batch: 2.1311 sec
0.1798 0.1702 0.1383 0.1232 0.1059 0.0919 0.0839 0.0795 0.0773 0.0757 0.0742 0.0723 0.0712 0.0700 0.0693 0.0687 

[TRAIN] Epoch[1](12555/114412); Loss: 0.093525; Backpropagation: 0.2905 sec; Batch: 2.1121 sec
0.1639 0.1589 0.1290 0.1140 0.1006 0.0924 0.0862 0.0821 0.0784 0.0755 0.0731 0.0712 0.0695 0.0685 0.0671 0.0661 

[TRAIN] Epoch[1](12556/114412); Loss: 0.092025; Backpropagation: 0.2910 sec; Batch: 2.1138 sec
0.2088 0.2041 0.1536 0.1356 0.1025 0.0818 0.0693 0.0649 0.0627 0.0609 0.0587 0.0566 0.0547 0.0535 0.0528 0.0519 

[TRAIN] Epoch[1](12557/114412); Loss: 0.100061; Backpropagation: 0.2928 sec; Batch: 2.1156 sec
0.1828 0.1785 0.1437 0.1268 0.1087 0.0976 0.0901 0.0837 0.0800 0.0778 0.0752 0.0731 0.0722 0.0712 0.0702 0.0695 

[TRAIN] Epoch[1](12558/114412); Loss: 0.119243; Backpropagation: 0.2933 sec; Batch: 2.1273 sec
0.1815 0.1763 0.1524 0.1427 0.1290 0.1202 0.1131 0.1081 0.1041 0.1015 0.0996 0.0981 0.0968 0.0957 0.0946 0.0941 

[TRAIN] Epoch[1](12559/114412); Loss: 0.072707; Backpropagation: 0.2913 sec; Batch: 2.0868 sec
0.1353 0.1290 0.0961 0.0819 0.0734 0.0689 0.0656 0.0628 0.0603 0.0590 0.0574 0.0564 0.0554 0.0543 0.0541 0.0534 

[TRAIN] Epoch[1](12560/114412); Loss: 0.073979; Backpropagation: 0.2936 sec; Batch: 2.1187 sec
0.1652 0.1618 0.1210 0.0954 0.0735 0.0649 0.0617 0.0574 0.0546 0.0503 0.0479 0.0474 0.0466 0.0457 0.0456 0.0449 

[TRAIN] Epoch[1](12561/114412); Loss: 0.046976; Backpropagation: 0.2916 sec; Batch: 2.1196 sec
0.0894 0.0873 0.0612 0.0534 0.0501 0.0452 0.0420 0.0389 0.0376 0.0374 0.0362 0.0354 0.0348 0.0344 0.0342 0.0342 

[TRAIN] Epoch[1](12562/114412); Loss: 0.064076; Backpropagation: 0.2915 sec; Batch: 2.1140 sec
0.1399 0.1373 0.0984 0.0798 0.0655 0.0585 0.0518 0.0488 0.0468 0.0452 0.0441 0.0432 0.0421 0.0416 0.0412 0.0409 

[TRAIN] Epoch[1](12563/114412); Loss: 0.078126; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1315 0.1295 0.1037 0.0918 0.0782 0.0726 0.0703 0.0673 0.0659 0.0648 0.0637 0.0631 0.0625 0.0619 0.0616 0.0615 

[TRAIN] Epoch[1](12564/114412); Loss: 0.099354; Backpropagation: 0.2910 sec; Batch: 2.1293 sec
0.1607 0.1540 0.1284 0.1161 0.1043 0.0973 0.0926 0.0891 0.0865 0.0841 0.0823 0.0809 0.0798 0.0788 0.0777 0.0770 

[TRAIN] Epoch[1](12565/114412); Loss: 0.067430; Backpropagation: 0.2912 sec; Batch: 2.1169 sec
0.1454 0.1358 0.1000 0.0835 0.0659 0.0580 0.0565 0.0536 0.0517 0.0502 0.0486 0.0478 0.0465 0.0458 0.0450 0.0446 

[TRAIN] Epoch[1](12566/114412); Loss: 0.078400; Backpropagation: 0.2909 sec; Batch: 2.1011 sec
0.1541 0.1481 0.1179 0.1036 0.0871 0.0767 0.0693 0.0642 0.0611 0.0580 0.0562 0.0545 0.0525 0.0511 0.0504 0.0497 

[TRAIN] Epoch[1](12567/114412); Loss: 0.068772; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.1189 0.1148 0.0954 0.0872 0.0788 0.0710 0.0660 0.0604 0.0568 0.0543 0.0528 0.0509 0.0498 0.0485 0.0477 0.0470 

[TRAIN] Epoch[1](12568/114412); Loss: 0.071983; Backpropagation: 0.2907 sec; Batch: 2.1132 sec
0.1093 0.1041 0.0973 0.0841 0.0727 0.0692 0.0676 0.0650 0.0633 0.0620 0.0609 0.0601 0.0597 0.0592 0.0589 0.0584 

[TRAIN] Epoch[1](12569/114412); Loss: 0.101406; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.1899 0.1827 0.1506 0.1348 0.1140 0.0988 0.0893 0.0835 0.0789 0.0756 0.0742 0.0725 0.0712 0.0701 0.0687 0.0678 

[TRAIN] Epoch[1](12570/114412); Loss: 0.102610; Backpropagation: 0.2912 sec; Batch: 2.1170 sec
0.1723 0.1693 0.1551 0.1426 0.1283 0.1109 0.1027 0.0910 0.0821 0.0771 0.0726 0.0701 0.0687 0.0675 0.0663 0.0650 

[TRAIN] Epoch[1](12571/114412); Loss: 0.086763; Backpropagation: 0.2916 sec; Batch: 2.1249 sec
0.1356 0.1342 0.1116 0.1031 0.0946 0.0876 0.0824 0.0782 0.0758 0.0736 0.0717 0.0702 0.0687 0.0680 0.0668 0.0660 

[TRAIN] Epoch[1](12572/114412); Loss: 0.086605; Backpropagation: 0.2957 sec; Batch: 2.1229 sec
0.1646 0.1581 0.1177 0.1000 0.0871 0.0790 0.0749 0.0718 0.0709 0.0689 0.0676 0.0664 0.0657 0.0650 0.0641 0.0636 

[TRAIN] Epoch[1](12573/114412); Loss: 0.094696; Backpropagation: 0.2940 sec; Batch: 2.1184 sec
0.1482 0.1459 0.1207 0.1107 0.0989 0.0915 0.0879 0.0852 0.0834 0.0811 0.0791 0.0780 0.0770 0.0764 0.0758 0.0753 

[TRAIN] Epoch[1](12574/114412); Loss: 0.069925; Backpropagation: 0.2905 sec; Batch: 2.1155 sec
0.1353 0.1243 0.0918 0.0848 0.0758 0.0711 0.0631 0.0593 0.0565 0.0545 0.0521 0.0516 0.0508 0.0498 0.0492 0.0486 

[TRAIN] Epoch[1](12575/114412); Loss: 0.079382; Backpropagation: 0.2915 sec; Batch: 2.1145 sec
0.1390 0.1308 0.1073 0.0941 0.0853 0.0790 0.0721 0.0686 0.0666 0.0648 0.0628 0.0613 0.0606 0.0598 0.0591 0.0588 

[TRAIN] Epoch[1](12576/114412); Loss: 0.066993; Backpropagation: 0.2917 sec; Batch: 2.1143 sec
0.1247 0.1176 0.0936 0.0815 0.0690 0.0645 0.0599 0.0568 0.0553 0.0536 0.0520 0.0505 0.0493 0.0486 0.0478 0.0473 

[TRAIN] Epoch[1](12577/114412); Loss: 0.078329; Backpropagation: 0.2915 sec; Batch: 2.1193 sec
0.1540 0.1493 0.1085 0.0911 0.0781 0.0711 0.0676 0.0651 0.0630 0.0614 0.0600 0.0587 0.0577 0.0566 0.0560 0.0551 

[TRAIN] Epoch[1](12578/114412); Loss: 0.073016; Backpropagation: 0.2913 sec; Batch: 2.1295 sec
0.1388 0.1348 0.1031 0.0883 0.0727 0.0675 0.0645 0.0615 0.0594 0.0570 0.0555 0.0543 0.0535 0.0528 0.0525 0.0520 

[TRAIN] Epoch[1](12579/114412); Loss: 0.086678; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1484 0.1436 0.1209 0.1016 0.0908 0.0829 0.0794 0.0759 0.0731 0.0707 0.0689 0.0679 0.0669 0.0659 0.0652 0.0647 

[TRAIN] Epoch[1](12580/114412); Loss: 0.069242; Backpropagation: 0.2930 sec; Batch: 2.1197 sec
0.1278 0.1268 0.1018 0.0876 0.0738 0.0684 0.0654 0.0598 0.0553 0.0530 0.0510 0.0491 0.0482 0.0475 0.0464 0.0458 

[TRAIN] Epoch[1](12581/114412); Loss: 0.072606; Backpropagation: 0.2929 sec; Batch: 2.0817 sec
0.1474 0.1400 0.1081 0.0942 0.0791 0.0705 0.0646 0.0586 0.0554 0.0535 0.0511 0.0500 0.0487 0.0474 0.0469 0.0462 

[TRAIN] Epoch[1](12582/114412); Loss: 0.060847; Backpropagation: 0.2953 sec; Batch: 2.1228 sec
0.1460 0.1453 0.1026 0.0700 0.0533 0.0519 0.0478 0.0456 0.0440 0.0408 0.0396 0.0391 0.0375 0.0371 0.0368 0.0362 

[TRAIN] Epoch[1](12583/114412); Loss: 0.085251; Backpropagation: 0.2931 sec; Batch: 2.1160 sec
0.1745 0.1744 0.1294 0.1125 0.0931 0.0817 0.0724 0.0665 0.0628 0.0611 0.0593 0.0577 0.0565 0.0550 0.0538 0.0531 

[TRAIN] Epoch[1](12584/114412); Loss: 0.052150; Backpropagation: 0.2932 sec; Batch: 2.1212 sec
0.1051 0.1011 0.0718 0.0652 0.0530 0.0481 0.0462 0.0433 0.0417 0.0393 0.0376 0.0374 0.0373 0.0362 0.0359 0.0352 

[TRAIN] Epoch[1](12585/114412); Loss: 0.064789; Backpropagation: 0.2918 sec; Batch: 2.0812 sec
0.1212 0.1193 0.0897 0.0771 0.0677 0.0611 0.0571 0.0549 0.0530 0.0507 0.0496 0.0482 0.0475 0.0470 0.0465 0.0461 

[TRAIN] Epoch[1](12586/114412); Loss: 0.071727; Backpropagation: 0.2910 sec; Batch: 2.0803 sec
0.1254 0.1201 0.0953 0.0854 0.0754 0.0710 0.0670 0.0625 0.0602 0.0582 0.0571 0.0557 0.0545 0.0540 0.0530 0.0527 

[TRAIN] Epoch[1](12587/114412); Loss: 0.066642; Backpropagation: 0.2930 sec; Batch: 2.0790 sec
0.1316 0.1120 0.0869 0.0781 0.0679 0.0644 0.0616 0.0582 0.0552 0.0535 0.0518 0.0504 0.0498 0.0487 0.0483 0.0478 

[TRAIN] Epoch[1](12588/114412); Loss: 0.073600; Backpropagation: 0.2912 sec; Batch: 2.1428 sec
0.1709 0.1625 0.1184 0.0940 0.0706 0.0594 0.0575 0.0550 0.0532 0.0512 0.0500 0.0486 0.0477 0.0467 0.0462 0.0457 

[TRAIN] Epoch[1](12589/114412); Loss: 0.079962; Backpropagation: 0.2907 sec; Batch: 2.1213 sec
0.1537 0.1445 0.1116 0.1003 0.0897 0.0798 0.0735 0.0664 0.0636 0.0610 0.0596 0.0576 0.0558 0.0549 0.0541 0.0533 

[TRAIN] Epoch[1](12590/114412); Loss: 0.123286; Backpropagation: 0.2906 sec; Batch: 2.1184 sec
0.1923 0.1861 0.1625 0.1496 0.1377 0.1281 0.1198 0.1124 0.1064 0.1032 0.1010 0.0970 0.0960 0.0952 0.0932 0.0922 

[TRAIN] Epoch[1](12591/114412); Loss: 0.067097; Backpropagation: 0.2903 sec; Batch: 2.0968 sec
0.1268 0.1258 0.1024 0.0921 0.0742 0.0644 0.0594 0.0557 0.0520 0.0494 0.0474 0.0461 0.0454 0.0446 0.0440 0.0440 

[TRAIN] Epoch[1](12592/114412); Loss: 0.096330; Backpropagation: 0.2920 sec; Batch: 2.0784 sec
0.1706 0.1630 0.1329 0.1227 0.1092 0.0991 0.0910 0.0838 0.0786 0.0750 0.0723 0.0705 0.0693 0.0684 0.0677 0.0671 

[TRAIN] Epoch[1](12593/114412); Loss: 0.076918; Backpropagation: 0.2894 sec; Batch: 2.1181 sec
0.1369 0.1325 0.1004 0.0880 0.0784 0.0735 0.0706 0.0674 0.0647 0.0627 0.0613 0.0604 0.0594 0.0587 0.0582 0.0576 

[TRAIN] Epoch[1](12594/114412); Loss: 0.072406; Backpropagation: 0.2929 sec; Batch: 2.1175 sec
0.1611 0.1571 0.1210 0.0898 0.0666 0.0634 0.0579 0.0569 0.0537 0.0515 0.0495 0.0480 0.0466 0.0459 0.0452 0.0443 

[TRAIN] Epoch[1](12595/114412); Loss: 0.060557; Backpropagation: 0.2944 sec; Batch: 2.0828 sec
0.1134 0.1103 0.0850 0.0719 0.0611 0.0569 0.0532 0.0511 0.0493 0.0477 0.0467 0.0455 0.0448 0.0444 0.0441 0.0436 

[TRAIN] Epoch[1](12596/114412); Loss: 0.093084; Backpropagation: 0.2930 sec; Batch: 2.1198 sec
0.1772 0.1714 0.1330 0.1113 0.0952 0.0902 0.0829 0.0774 0.0744 0.0722 0.0704 0.0695 0.0675 0.0663 0.0655 0.0648 

[TRAIN] Epoch[1](12597/114412); Loss: 0.075348; Backpropagation: 0.2908 sec; Batch: 2.1155 sec
0.1353 0.1271 0.0951 0.0844 0.0758 0.0714 0.0685 0.0660 0.0637 0.0621 0.0611 0.0601 0.0596 0.0589 0.0583 0.0581 

[TRAIN] Epoch[1](12598/114412); Loss: 0.099755; Backpropagation: 0.2950 sec; Batch: 2.1183 sec
0.1647 0.1594 0.1324 0.1172 0.1058 0.0968 0.0918 0.0878 0.0849 0.0828 0.0814 0.0802 0.0793 0.0780 0.0772 0.0764 

[TRAIN] Epoch[1](12599/114412); Loss: 0.089834; Backpropagation: 0.2952 sec; Batch: 2.1162 sec
0.1945 0.1947 0.1533 0.1321 0.1024 0.0833 0.0707 0.0631 0.0611 0.0592 0.0570 0.0552 0.0539 0.0528 0.0521 0.0518 

[TRAIN] Epoch[1](12600/114412); Loss: 0.056709; Backpropagation: 0.2950 sec; Batch: 2.1224 sec
0.1154 0.1087 0.0749 0.0637 0.0566 0.0526 0.0496 0.0469 0.0453 0.0440 0.0429 0.0424 0.0418 0.0412 0.0408 0.0407 

[TRAIN] Epoch[1](12601/114412); Loss: 0.073720; Backpropagation: 0.2950 sec; Batch: 2.1209 sec
0.1100 0.1040 0.0929 0.0864 0.0795 0.0747 0.0704 0.0673 0.0654 0.0638 0.0627 0.0621 0.0609 0.0603 0.0598 0.0592 

[TRAIN] Epoch[1](12602/114412); Loss: 0.072301; Backpropagation: 0.2933 sec; Batch: 2.1164 sec
0.1234 0.1150 0.0905 0.0828 0.0751 0.0702 0.0677 0.0641 0.0625 0.0610 0.0596 0.0585 0.0577 0.0568 0.0561 0.0557 

[TRAIN] Epoch[1](12603/114412); Loss: 0.066544; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1191 0.1150 0.0891 0.0785 0.0697 0.0642 0.0608 0.0587 0.0570 0.0549 0.0533 0.0515 0.0501 0.0486 0.0475 0.0469 

[TRAIN] Epoch[1](12604/114412); Loss: 0.067858; Backpropagation: 0.2952 sec; Batch: 2.1171 sec
0.1551 0.1522 0.1102 0.0822 0.0589 0.0572 0.0546 0.0521 0.0503 0.0478 0.0471 0.0463 0.0442 0.0435 0.0423 0.0418 

[TRAIN] Epoch[1](12605/114412); Loss: 0.067912; Backpropagation: 0.2928 sec; Batch: 2.1163 sec
0.1271 0.1182 0.0934 0.0796 0.0714 0.0675 0.0625 0.0593 0.0568 0.0544 0.0524 0.0507 0.0494 0.0486 0.0480 0.0473 

[TRAIN] Epoch[1](12606/114412); Loss: 0.092553; Backpropagation: 0.2950 sec; Batch: 2.1151 sec
0.1397 0.1382 0.1164 0.1100 0.1004 0.0927 0.0888 0.0847 0.0817 0.0795 0.0771 0.0755 0.0748 0.0744 0.0738 0.0733 

[TRAIN] Epoch[1](12607/114412); Loss: 0.069347; Backpropagation: 0.2938 sec; Batch: 2.1207 sec
0.1247 0.1193 0.0982 0.0862 0.0726 0.0681 0.0640 0.0599 0.0568 0.0548 0.0534 0.0521 0.0510 0.0499 0.0495 0.0489 

[TRAIN] Epoch[1](12608/114412); Loss: 0.068006; Backpropagation: 0.2953 sec; Batch: 2.1206 sec
0.1265 0.1185 0.0942 0.0808 0.0697 0.0644 0.0605 0.0577 0.0560 0.0542 0.0528 0.0517 0.0511 0.0504 0.0499 0.0496 

[TRAIN] Epoch[1](12609/114412); Loss: 0.071548; Backpropagation: 0.2929 sec; Batch: 2.1287 sec
0.1320 0.1222 0.0973 0.0894 0.0733 0.0662 0.0632 0.0619 0.0594 0.0571 0.0558 0.0550 0.0542 0.0534 0.0525 0.0520 

[TRAIN] Epoch[1](12610/114412); Loss: 0.047815; Backpropagation: 0.2929 sec; Batch: 2.1180 sec
0.0956 0.1026 0.0683 0.0592 0.0518 0.0460 0.0418 0.0376 0.0358 0.0346 0.0337 0.0330 0.0321 0.0314 0.0310 0.0306 

[TRAIN] Epoch[1](12611/114412); Loss: 0.081582; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.1597 0.1449 0.1131 0.0986 0.0866 0.0797 0.0739 0.0694 0.0650 0.0631 0.0611 0.0595 0.0587 0.0578 0.0573 0.0569 

[TRAIN] Epoch[1](12612/114412); Loss: 0.073699; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1193 0.1145 0.0966 0.0857 0.0775 0.0716 0.0680 0.0650 0.0635 0.0616 0.0608 0.0601 0.0595 0.0589 0.0586 0.0581 

[TRAIN] Epoch[1](12613/114412); Loss: 0.083232; Backpropagation: 0.2912 sec; Batch: 2.1145 sec
0.1519 0.1474 0.1105 0.0913 0.0804 0.0774 0.0748 0.0725 0.0703 0.0684 0.0667 0.0654 0.0644 0.0639 0.0635 0.0629 

[TRAIN] Epoch[1](12614/114412); Loss: 0.087291; Backpropagation: 0.2915 sec; Batch: 2.1141 sec
0.1579 0.1540 0.1199 0.1123 0.0958 0.0853 0.0791 0.0735 0.0703 0.0679 0.0659 0.0646 0.0638 0.0627 0.0621 0.0614 

[TRAIN] Epoch[1](12615/114412); Loss: 0.107090; Backpropagation: 0.2913 sec; Batch: 2.1168 sec
0.1685 0.1676 0.1349 0.1237 0.1151 0.1074 0.1020 0.0960 0.0925 0.0908 0.0885 0.0874 0.0861 0.0848 0.0845 0.0835 

[TRAIN] Epoch[1](12616/114412); Loss: 0.066044; Backpropagation: 0.2954 sec; Batch: 2.1179 sec
0.1333 0.1297 0.0908 0.0760 0.0656 0.0619 0.0574 0.0548 0.0532 0.0512 0.0492 0.0479 0.0471 0.0465 0.0461 0.0458 

[TRAIN] Epoch[1](12617/114412); Loss: 0.066893; Backpropagation: 0.2914 sec; Batch: 2.1179 sec
0.1346 0.1295 0.0947 0.0815 0.0676 0.0639 0.0597 0.0560 0.0531 0.0510 0.0494 0.0480 0.0467 0.0457 0.0449 0.0440 

[TRAIN] Epoch[1](12618/114412); Loss: 0.085782; Backpropagation: 0.2907 sec; Batch: 2.1121 sec
0.1356 0.1278 0.1122 0.1051 0.0916 0.0868 0.0831 0.0785 0.0760 0.0724 0.0710 0.0689 0.0674 0.0665 0.0653 0.0644 

[TRAIN] Epoch[1](12619/114412); Loss: 0.078480; Backpropagation: 0.2911 sec; Batch: 2.1147 sec
0.1350 0.1293 0.1022 0.0934 0.0832 0.0759 0.0707 0.0675 0.0658 0.0644 0.0633 0.0624 0.0616 0.0607 0.0605 0.0599 

[TRAIN] Epoch[1](12620/114412); Loss: 0.055621; Backpropagation: 0.2909 sec; Batch: 2.1223 sec
0.0988 0.1024 0.0768 0.0659 0.0571 0.0529 0.0501 0.0473 0.0458 0.0445 0.0430 0.0424 0.0414 0.0409 0.0404 0.0401 

[TRAIN] Epoch[1](12621/114412); Loss: 0.088127; Backpropagation: 0.2908 sec; Batch: 2.1201 sec
0.1508 0.1471 0.1131 0.0990 0.0892 0.0834 0.0800 0.0775 0.0750 0.0734 0.0723 0.0710 0.0704 0.0698 0.0692 0.0688 

[TRAIN] Epoch[1](12622/114412); Loss: 0.109185; Backpropagation: 0.2905 sec; Batch: 2.0769 sec
0.1778 0.1724 0.1363 0.1250 0.1174 0.1083 0.1017 0.0977 0.0945 0.0924 0.0903 0.0888 0.0879 0.0865 0.0856 0.0843 

[TRAIN] Epoch[1](12623/114412); Loss: 0.098184; Backpropagation: 0.2911 sec; Batch: 2.1180 sec
0.1897 0.1823 0.1410 0.1251 0.1011 0.0907 0.0845 0.0809 0.0785 0.0755 0.0741 0.0717 0.0704 0.0693 0.0685 0.0675 

[TRAIN] Epoch[1](12624/114412); Loss: 0.078976; Backpropagation: 0.2912 sec; Batch: 2.1137 sec
0.1414 0.1371 0.0993 0.0881 0.0809 0.0746 0.0702 0.0682 0.0666 0.0649 0.0637 0.0628 0.0620 0.0618 0.0612 0.0607 

[TRAIN] Epoch[1](12625/114412); Loss: 0.058294; Backpropagation: 0.2903 sec; Batch: 2.1161 sec
0.1166 0.1086 0.0799 0.0714 0.0625 0.0563 0.0516 0.0487 0.0464 0.0444 0.0426 0.0418 0.0410 0.0408 0.0401 0.0399 

[TRAIN] Epoch[1](12626/114412); Loss: 0.082033; Backpropagation: 0.2910 sec; Batch: 2.1146 sec
0.1349 0.1256 0.1048 0.0954 0.0872 0.0814 0.0761 0.0726 0.0709 0.0694 0.0679 0.0669 0.0658 0.0653 0.0645 0.0639 

[TRAIN] Epoch[1](12627/114412); Loss: 0.069649; Backpropagation: 0.2913 sec; Batch: 2.1121 sec
0.1302 0.1237 0.0955 0.0839 0.0741 0.0688 0.0629 0.0593 0.0568 0.0547 0.0532 0.0518 0.0509 0.0500 0.0495 0.0490 

[TRAIN] Epoch[1](12628/114412); Loss: 0.075538; Backpropagation: 0.2915 sec; Batch: 2.1210 sec
0.1504 0.1431 0.1082 0.0980 0.0822 0.0722 0.0653 0.0613 0.0583 0.0562 0.0545 0.0535 0.0524 0.0516 0.0509 0.0505 

[TRAIN] Epoch[1](12629/114412); Loss: 0.046950; Backpropagation: 0.2911 sec; Batch: 2.1202 sec
0.0949 0.0911 0.0655 0.0546 0.0462 0.0432 0.0405 0.0385 0.0372 0.0361 0.0350 0.0342 0.0340 0.0336 0.0335 0.0333 

[TRAIN] Epoch[1](12630/114412); Loss: 0.071050; Backpropagation: 0.2903 sec; Batch: 2.1169 sec
0.1250 0.1204 0.0939 0.0836 0.0754 0.0694 0.0650 0.0619 0.0594 0.0582 0.0569 0.0552 0.0541 0.0533 0.0528 0.0522 

[TRAIN] Epoch[1](12631/114412); Loss: 0.054484; Backpropagation: 0.2911 sec; Batch: 2.1535 sec
0.1242 0.1157 0.0790 0.0644 0.0547 0.0487 0.0448 0.0417 0.0403 0.0393 0.0381 0.0373 0.0363 0.0360 0.0357 0.0354 

[TRAIN] Epoch[1](12632/114412); Loss: 0.073205; Backpropagation: 0.2912 sec; Batch: 2.1306 sec
0.1439 0.1422 0.1018 0.0812 0.0751 0.0662 0.0635 0.0606 0.0590 0.0578 0.0559 0.0545 0.0537 0.0525 0.0517 0.0515 

[TRAIN] Epoch[1](12633/114412); Loss: 0.076903; Backpropagation: 0.2929 sec; Batch: 2.1217 sec
0.1332 0.1292 0.1024 0.0909 0.0826 0.0765 0.0729 0.0694 0.0660 0.0632 0.0611 0.0595 0.0577 0.0566 0.0550 0.0542 

[TRAIN] Epoch[1](12634/114412); Loss: 0.064535; Backpropagation: 0.2922 sec; Batch: 2.1181 sec
0.1296 0.1175 0.0841 0.0730 0.0660 0.0616 0.0578 0.0556 0.0535 0.0514 0.0494 0.0481 0.0470 0.0465 0.0459 0.0456 

[TRAIN] Epoch[1](12635/114412); Loss: 0.088649; Backpropagation: 0.2910 sec; Batch: 2.1083 sec
0.1788 0.1708 0.1354 0.1172 0.0949 0.0806 0.0713 0.0683 0.0657 0.0641 0.0636 0.0627 0.0618 0.0614 0.0611 0.0605 

[TRAIN] Epoch[1](12636/114412); Loss: 0.068778; Backpropagation: 0.2915 sec; Batch: 2.1172 sec
0.1326 0.1257 0.0986 0.0828 0.0712 0.0653 0.0611 0.0575 0.0552 0.0534 0.0516 0.0506 0.0495 0.0488 0.0486 0.0480 

[TRAIN] Epoch[1](12637/114412); Loss: 0.065739; Backpropagation: 0.2911 sec; Batch: 2.1280 sec
0.1184 0.1153 0.0877 0.0817 0.0725 0.0667 0.0623 0.0574 0.0538 0.0517 0.0497 0.0484 0.0475 0.0467 0.0460 0.0459 

[TRAIN] Epoch[1](12638/114412); Loss: 0.098987; Backpropagation: 0.2910 sec; Batch: 2.1188 sec
0.1529 0.1495 0.1259 0.1159 0.1071 0.1015 0.0963 0.0913 0.0874 0.0834 0.0815 0.0803 0.0789 0.0780 0.0772 0.0764 

[TRAIN] Epoch[1](12639/114412); Loss: 0.068414; Backpropagation: 0.2906 sec; Batch: 2.1138 sec
0.1405 0.1348 0.0995 0.0803 0.0673 0.0631 0.0596 0.0566 0.0539 0.0521 0.0507 0.0489 0.0479 0.0471 0.0464 0.0458 

[TRAIN] Epoch[1](12640/114412); Loss: 0.090872; Backpropagation: 0.2913 sec; Batch: 2.0916 sec
0.1275 0.1260 0.1080 0.1015 0.0955 0.0905 0.0875 0.0846 0.0828 0.0814 0.0798 0.0790 0.0783 0.0774 0.0772 0.0770 

[TRAIN] Epoch[1](12641/114412); Loss: 0.082301; Backpropagation: 0.2928 sec; Batch: 2.1182 sec
0.1438 0.1414 0.1055 0.0995 0.0892 0.0820 0.0780 0.0724 0.0689 0.0657 0.0638 0.0631 0.0623 0.0613 0.0603 0.0595 

[TRAIN] Epoch[1](12642/114412); Loss: 0.098849; Backpropagation: 0.2912 sec; Batch: 2.1198 sec
0.1649 0.1580 0.1279 0.1111 0.0982 0.0938 0.0905 0.0874 0.0848 0.0835 0.0828 0.0814 0.0804 0.0795 0.0788 0.0784 

[TRAIN] Epoch[1](12643/114412); Loss: 0.063939; Backpropagation: 0.2911 sec; Batch: 2.1184 sec
0.1315 0.1214 0.0897 0.0738 0.0627 0.0567 0.0555 0.0527 0.0510 0.0500 0.0481 0.0471 0.0463 0.0456 0.0456 0.0452 

[TRAIN] Epoch[1](12644/114412); Loss: 0.078812; Backpropagation: 0.2910 sec; Batch: 2.1161 sec
0.1583 0.1464 0.1016 0.0838 0.0799 0.0739 0.0716 0.0673 0.0634 0.0613 0.0611 0.0603 0.0595 0.0582 0.0574 0.0571 

[TRAIN] Epoch[1](12645/114412); Loss: 0.081830; Backpropagation: 0.2928 sec; Batch: 2.0997 sec
0.1530 0.1383 0.1048 0.0915 0.0828 0.0771 0.0741 0.0722 0.0695 0.0673 0.0653 0.0639 0.0633 0.0626 0.0620 0.0615 

[TRAIN] Epoch[1](12646/114412); Loss: 0.066455; Backpropagation: 0.2912 sec; Batch: 2.1205 sec
0.1347 0.1240 0.0919 0.0831 0.0736 0.0645 0.0584 0.0550 0.0522 0.0501 0.0481 0.0470 0.0461 0.0454 0.0447 0.0443 

[TRAIN] Epoch[1](12647/114412); Loss: 0.056968; Backpropagation: 0.2951 sec; Batch: 2.1226 sec
0.0852 0.0807 0.0722 0.0666 0.0622 0.0585 0.0555 0.0526 0.0509 0.0490 0.0477 0.0472 0.0464 0.0461 0.0456 0.0452 

[TRAIN] Epoch[1](12648/114412); Loss: 0.103140; Backpropagation: 0.2931 sec; Batch: 2.1204 sec
0.1868 0.1722 0.1382 0.1186 0.1075 0.1002 0.0939 0.0903 0.0863 0.0843 0.0820 0.0804 0.0793 0.0779 0.0767 0.0758 

[TRAIN] Epoch[1](12649/114412); Loss: 0.075492; Backpropagation: 0.2913 sec; Batch: 2.1161 sec
0.1564 0.1484 0.1092 0.0906 0.0771 0.0703 0.0660 0.0620 0.0582 0.0556 0.0545 0.0537 0.0525 0.0518 0.0511 0.0505 

[TRAIN] Epoch[1](12650/114412); Loss: 0.078360; Backpropagation: 0.2928 sec; Batch: 2.1151 sec
0.1390 0.1293 0.1045 0.0942 0.0817 0.0750 0.0706 0.0677 0.0656 0.0640 0.0627 0.0615 0.0606 0.0597 0.0591 0.0585 

[TRAIN] Epoch[1](12651/114412); Loss: 0.066187; Backpropagation: 0.2954 sec; Batch: 2.1177 sec
0.1163 0.1133 0.0875 0.0805 0.0723 0.0663 0.0622 0.0578 0.0555 0.0536 0.0519 0.0504 0.0491 0.0482 0.0473 0.0468 

[TRAIN] Epoch[1](12652/114412); Loss: 0.086854; Backpropagation: 0.2938 sec; Batch: 2.1233 sec
0.1654 0.1574 0.1212 0.1063 0.0847 0.0746 0.0731 0.0717 0.0702 0.0690 0.0674 0.0668 0.0661 0.0655 0.0654 0.0649 

[TRAIN] Epoch[1](12653/114412); Loss: 0.059932; Backpropagation: 0.2911 sec; Batch: 2.1129 sec
0.1165 0.1023 0.0793 0.0680 0.0585 0.0558 0.0536 0.0509 0.0495 0.0481 0.0474 0.0466 0.0460 0.0456 0.0455 0.0454 

[TRAIN] Epoch[1](12654/114412); Loss: 0.057221; Backpropagation: 0.2911 sec; Batch: 2.1181 sec
0.1067 0.1019 0.0751 0.0667 0.0587 0.0550 0.0521 0.0491 0.0479 0.0456 0.0447 0.0437 0.0428 0.0423 0.0418 0.0415 

[TRAIN] Epoch[1](12655/114412); Loss: 0.074789; Backpropagation: 0.2910 sec; Batch: 2.1129 sec
0.1306 0.1192 0.0976 0.0892 0.0815 0.0753 0.0700 0.0663 0.0640 0.0613 0.0594 0.0581 0.0570 0.0563 0.0557 0.0552 

[TRAIN] Epoch[1](12656/114412); Loss: 0.081719; Backpropagation: 0.2909 sec; Batch: 2.1142 sec
0.1506 0.1451 0.1145 0.0993 0.0926 0.0837 0.0758 0.0702 0.0661 0.0624 0.0611 0.0590 0.0579 0.0569 0.0565 0.0558 

[TRAIN] Epoch[1](12657/114412); Loss: 0.075681; Backpropagation: 0.2911 sec; Batch: 2.1178 sec
0.1484 0.1382 0.1007 0.0870 0.0778 0.0709 0.0665 0.0639 0.0611 0.0589 0.0580 0.0575 0.0565 0.0558 0.0552 0.0547 

[TRAIN] Epoch[1](12658/114412); Loss: 0.081358; Backpropagation: 0.2927 sec; Batch: 2.1197 sec
0.1545 0.1489 0.1008 0.0863 0.0787 0.0747 0.0723 0.0702 0.0682 0.0666 0.0650 0.0642 0.0635 0.0631 0.0626 0.0622 

[TRAIN] Epoch[1](12659/114412); Loss: 0.076230; Backpropagation: 0.2916 sec; Batch: 2.1195 sec
0.1269 0.1233 0.0964 0.0820 0.0753 0.0713 0.0684 0.0666 0.0655 0.0646 0.0640 0.0636 0.0634 0.0631 0.0628 0.0626 

[TRAIN] Epoch[1](12660/114412); Loss: 0.085198; Backpropagation: 0.2935 sec; Batch: 2.1158 sec
0.1405 0.1365 0.1084 0.0980 0.0887 0.0826 0.0782 0.0750 0.0736 0.0715 0.0703 0.0692 0.0685 0.0678 0.0674 0.0670 

[TRAIN] Epoch[1](12661/114412); Loss: 0.114291; Backpropagation: 0.2924 sec; Batch: 2.1224 sec
0.1878 0.1835 0.1548 0.1420 0.1302 0.1182 0.1093 0.1009 0.0961 0.0932 0.0900 0.0873 0.0856 0.0843 0.0831 0.0824 

[TRAIN] Epoch[1](12662/114412); Loss: 0.100006; Backpropagation: 0.2950 sec; Batch: 2.1275 sec
0.1959 0.1880 0.1542 0.1400 0.1221 0.1059 0.0969 0.0867 0.0767 0.0708 0.0654 0.0618 0.0604 0.0596 0.0582 0.0575 

[TRAIN] Epoch[1](12663/114412); Loss: 0.070566; Backpropagation: 0.2954 sec; Batch: 2.1225 sec
0.1375 0.1258 0.0945 0.0805 0.0676 0.0667 0.0632 0.0604 0.0578 0.0562 0.0553 0.0541 0.0531 0.0525 0.0521 0.0517 

[TRAIN] Epoch[1](12664/114412); Loss: 0.067606; Backpropagation: 0.2925 sec; Batch: 2.1246 sec
0.1264 0.1155 0.0905 0.0800 0.0694 0.0633 0.0599 0.0568 0.0556 0.0542 0.0533 0.0525 0.0518 0.0514 0.0508 0.0505 

[TRAIN] Epoch[1](12665/114412); Loss: 0.083939; Backpropagation: 0.2912 sec; Batch: 2.1129 sec
0.1250 0.1164 0.1049 0.0970 0.0901 0.0841 0.0799 0.0769 0.0755 0.0736 0.0719 0.0708 0.0701 0.0694 0.0690 0.0684 

[TRAIN] Epoch[1](12666/114412); Loss: 0.084599; Backpropagation: 0.2912 sec; Batch: 2.1132 sec
0.1610 0.1611 0.1279 0.1115 0.0947 0.0823 0.0725 0.0665 0.0649 0.0628 0.0604 0.0597 0.0582 0.0572 0.0567 0.0562 

[TRAIN] Epoch[1](12667/114412); Loss: 0.079918; Backpropagation: 0.2926 sec; Batch: 2.1153 sec
0.1971 0.1928 0.1394 0.1111 0.0757 0.0693 0.0599 0.0547 0.0516 0.0497 0.0480 0.0470 0.0467 0.0459 0.0453 0.0447 

[TRAIN] Epoch[1](12668/114412); Loss: 0.084594; Backpropagation: 0.2927 sec; Batch: 2.1342 sec
0.1597 0.1478 0.1108 0.0937 0.0871 0.0797 0.0760 0.0725 0.0699 0.0686 0.0669 0.0654 0.0649 0.0640 0.0633 0.0631 

[TRAIN] Epoch[1](12669/114412); Loss: 0.104347; Backpropagation: 0.2927 sec; Batch: 2.1218 sec
0.1434 0.1354 0.1185 0.1124 0.1077 0.1039 0.1011 0.0987 0.0972 0.0952 0.0943 0.0936 0.0926 0.0924 0.0918 0.0913 

[TRAIN] Epoch[1](12670/114412); Loss: 0.082693; Backpropagation: 0.2954 sec; Batch: 2.1232 sec
0.1517 0.1376 0.0994 0.0920 0.0881 0.0822 0.0781 0.0745 0.0707 0.0683 0.0661 0.0649 0.0635 0.0626 0.0620 0.0613 

[TRAIN] Epoch[1](12671/114412); Loss: 0.084305; Backpropagation: 0.2909 sec; Batch: 2.1157 sec
0.1452 0.1416 0.1096 0.0998 0.0880 0.0809 0.0769 0.0737 0.0711 0.0694 0.0677 0.0669 0.0657 0.0648 0.0641 0.0637 

[TRAIN] Epoch[1](12672/114412); Loss: 0.077116; Backpropagation: 0.2928 sec; Batch: 2.0792 sec
0.1389 0.1310 0.1031 0.0921 0.0814 0.0742 0.0696 0.0662 0.0635 0.0619 0.0606 0.0596 0.0588 0.0582 0.0576 0.0571 

[TRAIN] Epoch[1](12673/114412); Loss: 0.088935; Backpropagation: 0.2948 sec; Batch: 2.1061 sec
0.1449 0.1402 0.1045 0.0970 0.0914 0.0873 0.0840 0.0803 0.0782 0.0774 0.0757 0.0742 0.0730 0.0721 0.0716 0.0711 

[TRAIN] Epoch[1](12674/114412); Loss: 0.078354; Backpropagation: 0.2953 sec; Batch: 2.0903 sec
0.1613 0.1499 0.1195 0.0990 0.0831 0.0757 0.0693 0.0642 0.0608 0.0583 0.0564 0.0537 0.0521 0.0509 0.0500 0.0495 

[TRAIN] Epoch[1](12675/114412); Loss: 0.071603; Backpropagation: 0.2953 sec; Batch: 2.1206 sec
0.1338 0.1314 0.0984 0.0829 0.0719 0.0659 0.0630 0.0601 0.0585 0.0575 0.0558 0.0548 0.0539 0.0530 0.0526 0.0522 

[TRAIN] Epoch[1](12676/114412); Loss: 0.064290; Backpropagation: 0.2954 sec; Batch: 2.1018 sec
0.1251 0.1144 0.0838 0.0728 0.0672 0.0614 0.0586 0.0550 0.0531 0.0515 0.0499 0.0489 0.0477 0.0470 0.0465 0.0458 

[TRAIN] Epoch[1](12677/114412); Loss: 0.075898; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1578 0.1515 0.1114 0.0922 0.0791 0.0724 0.0678 0.0620 0.0588 0.0552 0.0537 0.0520 0.0515 0.0505 0.0496 0.0490 

[TRAIN] Epoch[1](12678/114412); Loss: 0.097383; Backpropagation: 0.2911 sec; Batch: 2.1121 sec
0.1582 0.1507 0.1222 0.1084 0.1027 0.0964 0.0925 0.0889 0.0861 0.0837 0.0813 0.0792 0.0784 0.0773 0.0765 0.0757 

[TRAIN] Epoch[1](12679/114412); Loss: 0.065511; Backpropagation: 0.2914 sec; Batch: 2.1136 sec
0.1352 0.1305 0.0844 0.0660 0.0669 0.0615 0.0582 0.0548 0.0528 0.0512 0.0503 0.0488 0.0476 0.0475 0.0465 0.0461 

[TRAIN] Epoch[1](12680/114412); Loss: 0.094652; Backpropagation: 0.2929 sec; Batch: 2.1149 sec
0.1488 0.1367 0.1185 0.1079 0.1004 0.0956 0.0908 0.0874 0.0847 0.0822 0.0801 0.0788 0.0774 0.0761 0.0749 0.0742 

[TRAIN] Epoch[1](12681/114412); Loss: 0.111272; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1945 0.1889 0.1486 0.1252 0.1170 0.1092 0.1025 0.0972 0.0944 0.0919 0.0899 0.0868 0.0853 0.0839 0.0828 0.0821 

[TRAIN] Epoch[1](12682/114412); Loss: 0.098440; Backpropagation: 0.2927 sec; Batch: 2.0874 sec
0.1977 0.1930 0.1523 0.1347 0.1141 0.1004 0.0882 0.0788 0.0714 0.0674 0.0653 0.0647 0.0632 0.0623 0.0612 0.0605 

[TRAIN] Epoch[1](12683/114412); Loss: 0.070807; Backpropagation: 0.2927 sec; Batch: 2.1191 sec
0.1416 0.1295 0.0924 0.0811 0.0711 0.0663 0.0629 0.0592 0.0571 0.0555 0.0542 0.0536 0.0529 0.0523 0.0519 0.0514 

[TRAIN] Epoch[1](12684/114412); Loss: 0.080443; Backpropagation: 0.2929 sec; Batch: 2.0792 sec
0.1560 0.1507 0.1149 0.0958 0.0833 0.0755 0.0730 0.0684 0.0651 0.0626 0.0602 0.0587 0.0573 0.0560 0.0552 0.0543 

[TRAIN] Epoch[1](12685/114412); Loss: 0.078880; Backpropagation: 0.2951 sec; Batch: 2.1196 sec
0.1489 0.1380 0.1075 0.0910 0.0802 0.0738 0.0701 0.0674 0.0649 0.0631 0.0614 0.0608 0.0595 0.0590 0.0584 0.0579 

[TRAIN] Epoch[1](12686/114412); Loss: 0.069202; Backpropagation: 0.2934 sec; Batch: 2.1198 sec
0.1264 0.1190 0.0975 0.0851 0.0713 0.0636 0.0605 0.0580 0.0564 0.0551 0.0536 0.0528 0.0523 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](12687/114412); Loss: 0.095226; Backpropagation: 0.2954 sec; Batch: 2.1241 sec
0.2236 0.2161 0.1661 0.1462 0.1188 0.0997 0.0806 0.0649 0.0584 0.0550 0.0525 0.0508 0.0496 0.0482 0.0472 0.0459 

[TRAIN] Epoch[1](12688/114412); Loss: 0.072259; Backpropagation: 0.2949 sec; Batch: 2.1252 sec
0.1546 0.1504 0.1019 0.0890 0.0740 0.0651 0.0603 0.0571 0.0555 0.0533 0.0515 0.0506 0.0493 0.0484 0.0479 0.0472 

[TRAIN] Epoch[1](12689/114412); Loss: 0.090842; Backpropagation: 0.2944 sec; Batch: 2.1204 sec
0.1288 0.1281 0.1003 0.0965 0.0961 0.0919 0.0893 0.0855 0.0842 0.0814 0.0804 0.0793 0.0784 0.0781 0.0777 0.0775 

[TRAIN] Epoch[1](12690/114412); Loss: 0.079438; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1438 0.1434 0.1068 0.1028 0.0920 0.0819 0.0744 0.0671 0.0642 0.0611 0.0590 0.0573 0.0556 0.0547 0.0537 0.0530 

[TRAIN] Epoch[1](12691/114412); Loss: 0.089498; Backpropagation: 0.3467 sec; Batch: 2.1871 sec
0.1736 0.1606 0.1244 0.1060 0.0885 0.0818 0.0789 0.0756 0.0732 0.0713 0.0692 0.0676 0.0666 0.0658 0.0648 0.0642 

[TRAIN] Epoch[1](12692/114412); Loss: 0.098159; Backpropagation: 0.2925 sec; Batch: 2.4893 sec
0.1667 0.1594 0.1252 0.1087 0.0974 0.0929 0.0891 0.0864 0.0843 0.0827 0.0817 0.0809 0.0798 0.0790 0.0785 0.0779 

[TRAIN] Epoch[1](12693/114412); Loss: 0.082050; Backpropagation: 0.2913 sec; Batch: 2.1173 sec
0.1424 0.1359 0.1047 0.0961 0.0858 0.0801 0.0762 0.0731 0.0703 0.0680 0.0662 0.0648 0.0635 0.0626 0.0619 0.0612 

[TRAIN] Epoch[1](12694/114412); Loss: 0.080805; Backpropagation: 0.2941 sec; Batch: 2.1222 sec
0.1587 0.1576 0.1199 0.1057 0.0918 0.0834 0.0754 0.0679 0.0610 0.0561 0.0545 0.0537 0.0527 0.0520 0.0515 0.0509 

[TRAIN] Epoch[1](12695/114412); Loss: 0.065237; Backpropagation: 0.2921 sec; Batch: 2.1239 sec
0.1452 0.1397 0.0904 0.0804 0.0688 0.0624 0.0578 0.0523 0.0492 0.0472 0.0446 0.0430 0.0418 0.0410 0.0403 0.0397 

[TRAIN] Epoch[1](12696/114412); Loss: 0.077953; Backpropagation: 0.2914 sec; Batch: 2.1210 sec
0.1329 0.1256 0.1011 0.0914 0.0793 0.0749 0.0715 0.0682 0.0665 0.0650 0.0636 0.0629 0.0621 0.0612 0.0607 0.0603 

[TRAIN] Epoch[1](12697/114412); Loss: 0.087505; Backpropagation: 0.2911 sec; Batch: 2.1157 sec
0.1287 0.1260 0.1047 0.0970 0.0902 0.0856 0.0824 0.0810 0.0792 0.0780 0.0768 0.0755 0.0747 0.0740 0.0735 0.0729 

[TRAIN] Epoch[1](12698/114412); Loss: 0.092793; Backpropagation: 0.3001 sec; Batch: 2.0887 sec
0.1529 0.1490 0.1180 0.1066 0.0933 0.0881 0.0843 0.0821 0.0804 0.0785 0.0774 0.0761 0.0755 0.0745 0.0742 0.0737 

[TRAIN] Epoch[1](12699/114412); Loss: 0.118244; Backpropagation: 0.2933 sec; Batch: 2.1210 sec
0.1723 0.1671 0.1446 0.1373 0.1259 0.1186 0.1130 0.1104 0.1068 0.1044 0.1020 0.1003 0.0990 0.0975 0.0970 0.0958 

[TRAIN] Epoch[1](12700/114412); Loss: 0.062181; Backpropagation: 0.2910 sec; Batch: 2.0777 sec
0.1364 0.1349 0.0977 0.0768 0.0634 0.0552 0.0505 0.0473 0.0459 0.0444 0.0426 0.0415 0.0407 0.0397 0.0391 0.0389 

[TRAIN] Epoch[1](12701/114412); Loss: 0.082173; Backpropagation: 0.2932 sec; Batch: 2.1208 sec
0.1412 0.1388 0.1055 0.0958 0.0872 0.0809 0.0776 0.0725 0.0705 0.0674 0.0657 0.0641 0.0632 0.0624 0.0612 0.0607 

[TRAIN] Epoch[1](12702/114412); Loss: 0.134340; Backpropagation: 0.2952 sec; Batch: 2.0822 sec
0.2098 0.2054 0.1766 0.1651 0.1496 0.1384 0.1272 0.1186 0.1142 0.1126 0.1095 0.1070 0.1059 0.1045 0.1032 0.1020 

[TRAIN] Epoch[1](12703/114412); Loss: 0.075076; Backpropagation: 0.2949 sec; Batch: 2.1215 sec
0.1502 0.1315 0.1002 0.0860 0.0767 0.0706 0.0673 0.0640 0.0615 0.0594 0.0580 0.0567 0.0557 0.0549 0.0545 0.0540 

[TRAIN] Epoch[1](12704/114412); Loss: 0.063406; Backpropagation: 0.2906 sec; Batch: 2.1122 sec
0.1372 0.1355 0.0969 0.0809 0.0628 0.0571 0.0525 0.0492 0.0471 0.0450 0.0441 0.0428 0.0417 0.0412 0.0405 0.0400 

[TRAIN] Epoch[1](12705/114412); Loss: 0.073721; Backpropagation: 0.2951 sec; Batch: 2.1240 sec
0.1333 0.1267 0.0981 0.0893 0.0780 0.0723 0.0680 0.0637 0.0614 0.0593 0.0572 0.0560 0.0551 0.0544 0.0536 0.0531 

[TRAIN] Epoch[1](12706/114412); Loss: 0.065203; Backpropagation: 0.2933 sec; Batch: 2.1155 sec
0.1279 0.1233 0.0928 0.0825 0.0652 0.0592 0.0568 0.0536 0.0519 0.0501 0.0485 0.0477 0.0468 0.0461 0.0457 0.0453 

[TRAIN] Epoch[1](12707/114412); Loss: 0.071528; Backpropagation: 0.2911 sec; Batch: 2.1145 sec
0.1322 0.1288 0.0973 0.0857 0.0775 0.0724 0.0639 0.0608 0.0585 0.0568 0.0548 0.0534 0.0516 0.0507 0.0505 0.0495 

[TRAIN] Epoch[1](12708/114412); Loss: 0.074129; Backpropagation: 0.2911 sec; Batch: 2.0784 sec
0.1580 0.1522 0.0940 0.0814 0.0796 0.0724 0.0672 0.0604 0.0569 0.0553 0.0532 0.0527 0.0516 0.0509 0.0502 0.0498 

[TRAIN] Epoch[1](12709/114412); Loss: 0.074862; Backpropagation: 0.2914 sec; Batch: 2.1137 sec
0.1307 0.1302 0.1053 0.0935 0.0816 0.0734 0.0655 0.0629 0.0612 0.0591 0.0580 0.0573 0.0559 0.0550 0.0544 0.0538 

[TRAIN] Epoch[1](12710/114412); Loss: 0.071919; Backpropagation: 0.2910 sec; Batch: 2.1216 sec
0.1572 0.1525 0.1150 0.0902 0.0700 0.0634 0.0580 0.0550 0.0529 0.0519 0.0504 0.0492 0.0476 0.0465 0.0459 0.0450 

[TRAIN] Epoch[1](12711/114412); Loss: 0.103240; Backpropagation: 0.2914 sec; Batch: 2.0771 sec
0.1966 0.1905 0.1514 0.1378 0.1185 0.1066 0.0964 0.0869 0.0806 0.0768 0.0733 0.0706 0.0683 0.0670 0.0658 0.0647 

[TRAIN] Epoch[1](12712/114412); Loss: 0.065259; Backpropagation: 0.2928 sec; Batch: 2.1061 sec
0.1202 0.1150 0.0869 0.0710 0.0647 0.0601 0.0576 0.0561 0.0543 0.0533 0.0525 0.0517 0.0509 0.0502 0.0499 0.0498 

[TRAIN] Epoch[1](12713/114412); Loss: 0.060072; Backpropagation: 0.2911 sec; Batch: 2.1559 sec
0.1146 0.1113 0.0841 0.0691 0.0584 0.0551 0.0517 0.0500 0.0487 0.0471 0.0469 0.0457 0.0451 0.0447 0.0444 0.0443 

[TRAIN] Epoch[1](12714/114412); Loss: 0.069226; Backpropagation: 0.2912 sec; Batch: 2.1195 sec
0.1258 0.1117 0.0927 0.0794 0.0705 0.0662 0.0640 0.0608 0.0588 0.0570 0.0555 0.0549 0.0535 0.0529 0.0524 0.0516 

[TRAIN] Epoch[1](12715/114412); Loss: 0.076040; Backpropagation: 0.2931 sec; Batch: 2.0839 sec
0.1479 0.1436 0.1073 0.0924 0.0784 0.0726 0.0697 0.0655 0.0613 0.0579 0.0552 0.0540 0.0534 0.0529 0.0525 0.0520 

[TRAIN] Epoch[1](12716/114412); Loss: 0.092341; Backpropagation: 0.2921 sec; Batch: 2.1224 sec
0.1522 0.1373 0.1109 0.1002 0.0963 0.0911 0.0881 0.0848 0.0818 0.0804 0.0786 0.0772 0.0763 0.0749 0.0740 0.0734 

[TRAIN] Epoch[1](12717/114412); Loss: 0.068247; Backpropagation: 0.2951 sec; Batch: 2.1244 sec
0.1541 0.1536 0.1079 0.0905 0.0660 0.0571 0.0522 0.0497 0.0487 0.0470 0.0463 0.0452 0.0444 0.0435 0.0430 0.0427 

[TRAIN] Epoch[1](12718/114412); Loss: 0.074303; Backpropagation: 0.2952 sec; Batch: 2.1203 sec
0.1222 0.1133 0.0935 0.0864 0.0763 0.0713 0.0701 0.0660 0.0650 0.0633 0.0616 0.0612 0.0601 0.0599 0.0597 0.0589 

[TRAIN] Epoch[1](12719/114412); Loss: 0.068926; Backpropagation: 0.2953 sec; Batch: 2.1208 sec
0.1578 0.1515 0.1031 0.0817 0.0638 0.0573 0.0553 0.0533 0.0511 0.0492 0.0482 0.0474 0.0467 0.0459 0.0454 0.0450 

[TRAIN] Epoch[1](12720/114412); Loss: 0.060508; Backpropagation: 0.2934 sec; Batch: 2.1160 sec
0.1380 0.1320 0.0904 0.0660 0.0564 0.0522 0.0484 0.0462 0.0447 0.0436 0.0434 0.0422 0.0416 0.0409 0.0412 0.0408 

[TRAIN] Epoch[1](12721/114412); Loss: 0.089227; Backpropagation: 0.2931 sec; Batch: 2.1175 sec
0.1418 0.1366 0.1150 0.1049 0.0966 0.0898 0.0851 0.0804 0.0770 0.0750 0.0734 0.0718 0.0710 0.0702 0.0697 0.0693 

[TRAIN] Epoch[1](12722/114412); Loss: 0.097678; Backpropagation: 0.2954 sec; Batch: 2.1219 sec
0.1955 0.1864 0.1468 0.1321 0.1100 0.0963 0.0858 0.0777 0.0730 0.0694 0.0675 0.0664 0.0651 0.0642 0.0635 0.0630 

[TRAIN] Epoch[1](12723/114412); Loss: 0.070346; Backpropagation: 0.2930 sec; Batch: 2.1206 sec
0.1298 0.1259 0.0973 0.0804 0.0678 0.0668 0.0630 0.0593 0.0580 0.0565 0.0552 0.0544 0.0533 0.0528 0.0525 0.0524 

[TRAIN] Epoch[1](12724/114412); Loss: 0.075634; Backpropagation: 0.2915 sec; Batch: 2.1210 sec
0.1265 0.1215 0.0950 0.0840 0.0781 0.0743 0.0704 0.0680 0.0659 0.0640 0.0626 0.0616 0.0606 0.0597 0.0592 0.0588 

[TRAIN] Epoch[1](12725/114412); Loss: 0.081524; Backpropagation: 0.2915 sec; Batch: 2.1177 sec
0.1177 0.1159 0.1014 0.0938 0.0861 0.0807 0.0763 0.0737 0.0722 0.0711 0.0704 0.0698 0.0693 0.0690 0.0686 0.0684 

[TRAIN] Epoch[1](12726/114412); Loss: 0.079939; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.1389 0.1318 0.1081 0.0981 0.0858 0.0800 0.0738 0.0702 0.0669 0.0651 0.0630 0.0615 0.0602 0.0593 0.0585 0.0577 

[TRAIN] Epoch[1](12727/114412); Loss: 0.079325; Backpropagation: 0.2932 sec; Batch: 2.1191 sec
0.1745 0.1691 0.1230 0.0929 0.0783 0.0726 0.0676 0.0627 0.0578 0.0560 0.0548 0.0538 0.0525 0.0518 0.0512 0.0507 

[TRAIN] Epoch[1](12728/114412); Loss: 0.064562; Backpropagation: 0.2935 sec; Batch: 2.1294 sec
0.1363 0.1252 0.0911 0.0765 0.0663 0.0597 0.0553 0.0524 0.0500 0.0484 0.0471 0.0463 0.0454 0.0447 0.0444 0.0440 

[TRAIN] Epoch[1](12729/114412); Loss: 0.077136; Backpropagation: 0.2953 sec; Batch: 2.1163 sec
0.1209 0.1170 0.0947 0.0887 0.0806 0.0759 0.0721 0.0694 0.0675 0.0663 0.0653 0.0644 0.0637 0.0631 0.0625 0.0622 

[TRAIN] Epoch[1](12730/114412); Loss: 0.081306; Backpropagation: 0.2949 sec; Batch: 2.1174 sec
0.1486 0.1305 0.1086 0.0919 0.0809 0.0779 0.0751 0.0718 0.0692 0.0672 0.0657 0.0644 0.0634 0.0625 0.0618 0.0613 

[TRAIN] Epoch[1](12731/114412); Loss: 0.068969; Backpropagation: 0.2908 sec; Batch: 2.1135 sec
0.1614 0.1519 0.1145 0.0879 0.0653 0.0551 0.0537 0.0517 0.0492 0.0473 0.0460 0.0453 0.0442 0.0436 0.0433 0.0430 

[TRAIN] Epoch[1](12732/114412); Loss: 0.071836; Backpropagation: 0.2933 sec; Batch: 2.1200 sec
0.1520 0.1410 0.1034 0.0866 0.0750 0.0649 0.0606 0.0579 0.0554 0.0536 0.0520 0.0507 0.0500 0.0492 0.0487 0.0483 

[TRAIN] Epoch[1](12733/114412); Loss: 0.072147; Backpropagation: 0.2931 sec; Batch: 2.1178 sec
0.1324 0.1231 0.0986 0.0880 0.0767 0.0700 0.0662 0.0629 0.0590 0.0568 0.0553 0.0542 0.0535 0.0530 0.0524 0.0522 

[TRAIN] Epoch[1](12734/114412); Loss: 0.075961; Backpropagation: 0.2906 sec; Batch: 2.1157 sec
0.1417 0.1128 0.1035 0.0869 0.0785 0.0737 0.0703 0.0664 0.0642 0.0622 0.0611 0.0599 0.0593 0.0586 0.0584 0.0580 

[TRAIN] Epoch[1](12735/114412); Loss: 0.084089; Backpropagation: 0.2914 sec; Batch: 2.1172 sec
0.1345 0.1257 0.1096 0.0974 0.0888 0.0845 0.0795 0.0767 0.0738 0.0717 0.0700 0.0685 0.0674 0.0664 0.0657 0.0652 

[TRAIN] Epoch[1](12736/114412); Loss: 0.116841; Backpropagation: 0.2908 sec; Batch: 2.0756 sec
0.1979 0.1913 0.1587 0.1380 0.1221 0.1140 0.1045 0.1014 0.0974 0.0954 0.0940 0.0927 0.0916 0.0907 0.0901 0.0898 

[TRAIN] Epoch[1](12737/114412); Loss: 0.098993; Backpropagation: 0.2903 sec; Batch: 2.1145 sec
0.2116 0.1936 0.1566 0.1327 0.1090 0.0900 0.0779 0.0745 0.0733 0.0716 0.0690 0.0669 0.0656 0.0648 0.0638 0.0630 

[TRAIN] Epoch[1](12738/114412); Loss: 0.093988; Backpropagation: 0.2910 sec; Batch: 2.1154 sec
0.1687 0.1660 0.1355 0.1221 0.1057 0.0956 0.0865 0.0797 0.0754 0.0723 0.0697 0.0676 0.0661 0.0651 0.0643 0.0634 

[TRAIN] Epoch[1](12739/114412); Loss: 0.096798; Backpropagation: 0.2915 sec; Batch: 2.1171 sec
0.1821 0.1768 0.1411 0.1296 0.1119 0.0987 0.0880 0.0791 0.0737 0.0711 0.0695 0.0681 0.0664 0.0653 0.0643 0.0632 

[TRAIN] Epoch[1](12740/114412); Loss: 0.102276; Backpropagation: 0.2916 sec; Batch: 2.1151 sec
0.1700 0.1677 0.1341 0.1182 0.1079 0.1018 0.0953 0.0906 0.0872 0.0849 0.0827 0.0813 0.0805 0.0791 0.0780 0.0770 

[TRAIN] Epoch[1](12741/114412); Loss: 0.084131; Backpropagation: 0.2909 sec; Batch: 2.1164 sec
0.1385 0.1275 0.1116 0.1026 0.0939 0.0881 0.0823 0.0774 0.0731 0.0694 0.0669 0.0652 0.0639 0.0629 0.0618 0.0610 

[TRAIN] Epoch[1](12742/114412); Loss: 0.053596; Backpropagation: 0.2953 sec; Batch: 2.1180 sec
0.1103 0.1065 0.0682 0.0545 0.0529 0.0489 0.0463 0.0448 0.0436 0.0427 0.0413 0.0406 0.0400 0.0393 0.0390 0.0388 

[TRAIN] Epoch[1](12743/114412); Loss: 0.084850; Backpropagation: 0.2951 sec; Batch: 2.1176 sec
0.1670 0.1504 0.1149 0.1001 0.0901 0.0837 0.0782 0.0746 0.0705 0.0668 0.0638 0.0619 0.0603 0.0592 0.0585 0.0577 

[TRAIN] Epoch[1](12744/114412); Loss: 0.087718; Backpropagation: 0.2913 sec; Batch: 2.1296 sec
0.1597 0.1470 0.1183 0.1053 0.0910 0.0823 0.0797 0.0774 0.0737 0.0710 0.0693 0.0676 0.0664 0.0656 0.0649 0.0643 

[TRAIN] Epoch[1](12745/114412); Loss: 0.075682; Backpropagation: 0.2908 sec; Batch: 2.1135 sec
0.1705 0.1656 0.1245 0.1002 0.0781 0.0659 0.0591 0.0549 0.0533 0.0518 0.0507 0.0491 0.0477 0.0471 0.0464 0.0461 

[TRAIN] Epoch[1](12746/114412); Loss: 0.084713; Backpropagation: 0.2914 sec; Batch: 2.1167 sec
0.1511 0.1465 0.1192 0.1030 0.0894 0.0768 0.0726 0.0707 0.0688 0.0676 0.0666 0.0660 0.0653 0.0646 0.0639 0.0634 

[TRAIN] Epoch[1](12747/114412); Loss: 0.069598; Backpropagation: 0.2919 sec; Batch: 2.1163 sec
0.1256 0.1212 0.0904 0.0819 0.0739 0.0668 0.0627 0.0600 0.0579 0.0559 0.0545 0.0537 0.0530 0.0524 0.0519 0.0517 

[TRAIN] Epoch[1](12748/114412); Loss: 0.111162; Backpropagation: 0.2909 sec; Batch: 2.1160 sec
0.1562 0.1541 0.1360 0.1296 0.1221 0.1141 0.1093 0.1055 0.1022 0.0984 0.0958 0.0939 0.0919 0.0906 0.0899 0.0889 

[TRAIN] Epoch[1](12749/114412); Loss: 0.109393; Backpropagation: 0.2907 sec; Batch: 2.0766 sec
0.1740 0.1666 0.1428 0.1293 0.1175 0.1085 0.1039 0.1002 0.0964 0.0935 0.0908 0.0885 0.0865 0.0850 0.0838 0.0829 

[TRAIN] Epoch[1](12750/114412); Loss: 0.092911; Backpropagation: 0.2912 sec; Batch: 2.0779 sec
0.1536 0.1435 0.1182 0.1065 0.0971 0.0915 0.0878 0.0848 0.0818 0.0789 0.0771 0.0753 0.0741 0.0732 0.0720 0.0714 

[TRAIN] Epoch[1](12751/114412); Loss: 0.062177; Backpropagation: 0.2909 sec; Batch: 2.1175 sec
0.1389 0.1336 0.1015 0.0836 0.0654 0.0518 0.0496 0.0469 0.0446 0.0430 0.0412 0.0402 0.0397 0.0387 0.0381 0.0380 

[TRAIN] Epoch[1](12752/114412); Loss: 0.090598; Backpropagation: 0.2912 sec; Batch: 2.1147 sec
0.1514 0.1384 0.1135 0.1016 0.0925 0.0871 0.0835 0.0801 0.0785 0.0772 0.0761 0.0754 0.0745 0.0737 0.0731 0.0729 

[TRAIN] Epoch[1](12753/114412); Loss: 0.083828; Backpropagation: 0.2926 sec; Batch: 2.0836 sec
0.1443 0.1415 0.1099 0.0981 0.0862 0.0831 0.0791 0.0742 0.0710 0.0688 0.0670 0.0654 0.0643 0.0635 0.0627 0.0623 

[TRAIN] Epoch[1](12754/114412); Loss: 0.102904; Backpropagation: 0.2954 sec; Batch: 2.1230 sec
0.1970 0.1916 0.1552 0.1397 0.1224 0.1123 0.1011 0.0912 0.0825 0.0759 0.0695 0.0653 0.0636 0.0614 0.0598 0.0581 

[TRAIN] Epoch[1](12755/114412); Loss: 0.069765; Backpropagation: 0.2954 sec; Batch: 2.0822 sec
0.1367 0.1301 0.1035 0.0847 0.0697 0.0647 0.0605 0.0570 0.0549 0.0534 0.0522 0.0513 0.0506 0.0497 0.0491 0.0484 

[TRAIN] Epoch[1](12756/114412); Loss: 0.057460; Backpropagation: 0.2948 sec; Batch: 2.1203 sec
0.1282 0.1206 0.0834 0.0673 0.0581 0.0518 0.0489 0.0463 0.0434 0.0418 0.0405 0.0390 0.0383 0.0378 0.0371 0.0369 

[TRAIN] Epoch[1](12757/114412); Loss: 0.085974; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1586 0.1555 0.1211 0.1060 0.0883 0.0803 0.0746 0.0708 0.0698 0.0683 0.0665 0.0648 0.0637 0.0628 0.0623 0.0620 

[TRAIN] Epoch[1](12758/114412); Loss: 0.073837; Backpropagation: 0.2913 sec; Batch: 2.1005 sec
0.1175 0.1125 0.0908 0.0818 0.0769 0.0720 0.0689 0.0668 0.0653 0.0639 0.0625 0.0617 0.0611 0.0604 0.0598 0.0594 

[TRAIN] Epoch[1](12759/114412); Loss: 0.061042; Backpropagation: 0.2906 sec; Batch: 2.1168 sec
0.1091 0.0991 0.0765 0.0686 0.0643 0.0595 0.0567 0.0536 0.0518 0.0504 0.0494 0.0484 0.0481 0.0475 0.0470 0.0467 

[TRAIN] Epoch[1](12760/114412); Loss: 0.106480; Backpropagation: 0.2913 sec; Batch: 2.1160 sec
0.1801 0.1709 0.1440 0.1306 0.1151 0.1049 0.0975 0.0925 0.0888 0.0864 0.0843 0.0831 0.0821 0.0815 0.0812 0.0806 

[TRAIN] Epoch[1](12761/114412); Loss: 0.098705; Backpropagation: 0.2930 sec; Batch: 2.1196 sec
0.1612 0.1534 0.1251 0.1109 0.1010 0.0949 0.0908 0.0885 0.0862 0.0842 0.0825 0.0812 0.0807 0.0802 0.0796 0.0791 

[TRAIN] Epoch[1](12762/114412); Loss: 0.080789; Backpropagation: 0.2932 sec; Batch: 2.1186 sec
0.1557 0.1447 0.1137 0.1013 0.0812 0.0737 0.0715 0.0673 0.0648 0.0624 0.0614 0.0604 0.0596 0.0588 0.0583 0.0576 

[TRAIN] Epoch[1](12763/114412); Loss: 0.093587; Backpropagation: 0.2913 sec; Batch: 2.1157 sec
0.1796 0.1753 0.1368 0.1263 0.1113 0.1001 0.0879 0.0779 0.0697 0.0652 0.0641 0.0632 0.0618 0.0608 0.0593 0.0581 

[TRAIN] Epoch[1](12764/114412); Loss: 0.079482; Backpropagation: 0.2912 sec; Batch: 2.1164 sec
0.1670 0.1430 0.1094 0.0922 0.0819 0.0750 0.0706 0.0669 0.0639 0.0610 0.0592 0.0578 0.0569 0.0563 0.0556 0.0549 

[TRAIN] Epoch[1](12765/114412); Loss: 0.072177; Backpropagation: 0.2912 sec; Batch: 2.1218 sec
0.1321 0.1088 0.0910 0.0835 0.0767 0.0711 0.0682 0.0645 0.0616 0.0596 0.0584 0.0574 0.0566 0.0558 0.0550 0.0547 

[TRAIN] Epoch[1](12766/114412); Loss: 0.092198; Backpropagation: 0.2954 sec; Batch: 2.1198 sec
0.1865 0.1730 0.1372 0.1148 0.0929 0.0854 0.0816 0.0769 0.0731 0.0696 0.0670 0.0657 0.0641 0.0633 0.0624 0.0617 

[TRAIN] Epoch[1](12767/114412); Loss: 0.064275; Backpropagation: 0.2955 sec; Batch: 2.1201 sec
0.1028 0.0920 0.0802 0.0735 0.0688 0.0648 0.0618 0.0587 0.0572 0.0554 0.0539 0.0529 0.0524 0.0518 0.0512 0.0509 

[TRAIN] Epoch[1](12768/114412); Loss: 0.079166; Backpropagation: 0.2913 sec; Batch: 2.1165 sec
0.1533 0.1436 0.1230 0.1023 0.0841 0.0752 0.0692 0.0657 0.0626 0.0601 0.0580 0.0561 0.0548 0.0536 0.0528 0.0522 

[TRAIN] Epoch[1](12769/114412); Loss: 0.091892; Backpropagation: 0.2905 sec; Batch: 2.1142 sec
0.2101 0.1914 0.1536 0.1262 0.0935 0.0772 0.0712 0.0693 0.0670 0.0633 0.0615 0.0593 0.0578 0.0569 0.0563 0.0558 

[TRAIN] Epoch[1](12770/114412); Loss: 0.089558; Backpropagation: 0.2911 sec; Batch: 2.1179 sec
0.1707 0.1530 0.1209 0.1065 0.0889 0.0823 0.0794 0.0769 0.0745 0.0724 0.0704 0.0692 0.0678 0.0672 0.0666 0.0662 

[TRAIN] Epoch[1](12771/114412); Loss: 0.081879; Backpropagation: 0.2930 sec; Batch: 2.1151 sec
0.1654 0.1506 0.1149 0.1022 0.0860 0.0774 0.0715 0.0672 0.0648 0.0626 0.0607 0.0594 0.0580 0.0573 0.0564 0.0557 

[TRAIN] Epoch[1](12772/114412); Loss: 0.067078; Backpropagation: 0.2930 sec; Batch: 2.1192 sec
0.1612 0.1532 0.1070 0.0850 0.0679 0.0572 0.0530 0.0498 0.0470 0.0443 0.0436 0.0422 0.0411 0.0406 0.0403 0.0401 

[TRAIN] Epoch[1](12773/114412); Loss: 0.084760; Backpropagation: 0.2908 sec; Batch: 2.1193 sec
0.1682 0.1533 0.1177 0.1029 0.0899 0.0817 0.0760 0.0704 0.0670 0.0652 0.0635 0.0621 0.0607 0.0596 0.0593 0.0585 

[TRAIN] Epoch[1](12774/114412); Loss: 0.055768; Backpropagation: 0.2916 sec; Batch: 2.1144 sec
0.1235 0.1049 0.0783 0.0685 0.0581 0.0513 0.0477 0.0450 0.0432 0.0417 0.0401 0.0389 0.0384 0.0379 0.0375 0.0372 

[TRAIN] Epoch[1](12775/114412); Loss: 0.071042; Backpropagation: 0.2932 sec; Batch: 2.1190 sec
0.1426 0.1310 0.0991 0.0801 0.0708 0.0638 0.0616 0.0593 0.0576 0.0562 0.0544 0.0532 0.0526 0.0520 0.0514 0.0511 

[TRAIN] Epoch[1](12776/114412); Loss: 0.069498; Backpropagation: 0.2932 sec; Batch: 2.1168 sec
0.1355 0.1165 0.0901 0.0785 0.0733 0.0677 0.0639 0.0599 0.0581 0.0564 0.0544 0.0529 0.0520 0.0516 0.0507 0.0503 

[TRAIN] Epoch[1](12777/114412); Loss: 0.098857; Backpropagation: 0.2930 sec; Batch: 2.1184 sec
0.2000 0.1749 0.1425 0.1198 0.1026 0.0923 0.0861 0.0811 0.0779 0.0755 0.0742 0.0727 0.0716 0.0709 0.0700 0.0694 

[TRAIN] Epoch[1](12778/114412); Loss: 0.108003; Backpropagation: 0.2914 sec; Batch: 2.1161 sec
0.1758 0.1624 0.1352 0.1263 0.1133 0.1063 0.1004 0.0966 0.0945 0.0922 0.0903 0.0888 0.0878 0.0869 0.0858 0.0853 

[TRAIN] Epoch[1](12779/114412); Loss: 0.103374; Backpropagation: 0.2907 sec; Batch: 2.1122 sec
0.1923 0.1788 0.1442 0.1299 0.1150 0.1038 0.0966 0.0892 0.0842 0.0804 0.0775 0.0754 0.0740 0.0722 0.0707 0.0697 

[TRAIN] Epoch[1](12780/114412); Loss: 0.109325; Backpropagation: 0.2927 sec; Batch: 2.1152 sec
0.1816 0.1660 0.1416 0.1267 0.1134 0.1059 0.1005 0.0968 0.0941 0.0928 0.0910 0.0894 0.0885 0.0877 0.0869 0.0862 

[TRAIN] Epoch[1](12781/114412); Loss: 0.066634; Backpropagation: 0.2959 sec; Batch: 2.1179 sec
0.1511 0.1313 0.1034 0.0826 0.0684 0.0603 0.0567 0.0532 0.0503 0.0476 0.0456 0.0442 0.0436 0.0429 0.0426 0.0423 

[TRAIN] Epoch[1](12782/114412); Loss: 0.081669; Backpropagation: 0.2953 sec; Batch: 2.1226 sec
0.1475 0.1335 0.1073 0.0951 0.0850 0.0780 0.0733 0.0705 0.0685 0.0669 0.0656 0.0646 0.0635 0.0629 0.0623 0.0620 

[TRAIN] Epoch[1](12783/114412); Loss: 0.074701; Backpropagation: 0.2910 sec; Batch: 2.1172 sec
0.1755 0.1497 0.1131 0.0958 0.0791 0.0667 0.0599 0.0567 0.0543 0.0533 0.0511 0.0497 0.0488 0.0478 0.0471 0.0466 

[TRAIN] Epoch[1](12784/114412); Loss: 0.097799; Backpropagation: 0.2913 sec; Batch: 2.1189 sec
0.1899 0.1727 0.1339 0.1146 0.1002 0.0906 0.0869 0.0841 0.0808 0.0780 0.0758 0.0740 0.0723 0.0713 0.0702 0.0695 

[TRAIN] Epoch[1](12785/114412); Loss: 0.074089; Backpropagation: 0.2913 sec; Batch: 2.4877 sec
0.1484 0.1273 0.0987 0.0866 0.0776 0.0708 0.0666 0.0635 0.0600 0.0583 0.0566 0.0558 0.0547 0.0539 0.0535 0.0530 

[TRAIN] Epoch[1](12786/114412); Loss: 0.069267; Backpropagation: 0.2939 sec; Batch: 2.3908 sec
0.1507 0.1251 0.1029 0.0794 0.0689 0.0635 0.0581 0.0556 0.0546 0.0533 0.0518 0.0506 0.0495 0.0487 0.0481 0.0475 

[TRAIN] Epoch[1](12787/114412); Loss: 0.083026; Backpropagation: 0.2937 sec; Batch: 2.0992 sec
0.1922 0.1542 0.1196 0.0919 0.0782 0.0744 0.0697 0.0664 0.0638 0.0625 0.0610 0.0601 0.0597 0.0587 0.0582 0.0578 

[TRAIN] Epoch[1](12788/114412); Loss: 0.097603; Backpropagation: 0.2912 sec; Batch: 2.1186 sec
0.2038 0.1912 0.1520 0.1308 0.1072 0.0921 0.0841 0.0792 0.0749 0.0700 0.0664 0.0639 0.0625 0.0618 0.0611 0.0607 

[TRAIN] Epoch[1](12789/114412); Loss: 0.085701; Backpropagation: 0.2943 sec; Batch: 2.1194 sec
0.1570 0.1383 0.1131 0.1011 0.0887 0.0821 0.0780 0.0743 0.0723 0.0701 0.0683 0.0674 0.0663 0.0652 0.0648 0.0643 

[TRAIN] Epoch[1](12790/114412); Loss: 0.091514; Backpropagation: 0.2950 sec; Batch: 2.1291 sec
0.1812 0.1682 0.1413 0.1197 0.1008 0.0887 0.0802 0.0743 0.0704 0.0673 0.0655 0.0637 0.0620 0.0610 0.0602 0.0596 

[TRAIN] Epoch[1](12791/114412); Loss: 0.090267; Backpropagation: 0.2934 sec; Batch: 2.1158 sec
0.1900 0.1612 0.1346 0.1124 0.0967 0.0857 0.0787 0.0746 0.0713 0.0676 0.0657 0.0637 0.0623 0.0609 0.0598 0.0591 

[TRAIN] Epoch[1](12792/114412); Loss: 0.098746; Backpropagation: 0.2931 sec; Batch: 2.1169 sec
0.1995 0.1777 0.1546 0.1304 0.1107 0.0980 0.0924 0.0845 0.0747 0.0689 0.0661 0.0663 0.0666 0.0647 0.0632 0.0618 

[TRAIN] Epoch[1](12793/114412); Loss: 0.086903; Backpropagation: 0.2932 sec; Batch: 2.1185 sec
0.1774 0.1617 0.1215 0.1054 0.0915 0.0826 0.0772 0.0724 0.0686 0.0658 0.0641 0.0627 0.0618 0.0606 0.0593 0.0580 

[TRAIN] Epoch[1](12794/114412); Loss: 0.077830; Backpropagation: 0.2909 sec; Batch: 2.1143 sec
0.1756 0.1620 0.1269 0.1036 0.0807 0.0697 0.0638 0.0587 0.0548 0.0531 0.0517 0.0511 0.0494 0.0484 0.0481 0.0476 

[TRAIN] Epoch[1](12795/114412); Loss: 0.071463; Backpropagation: 0.2905 sec; Batch: 2.1133 sec
0.1532 0.1339 0.1088 0.0889 0.0767 0.0674 0.0603 0.0571 0.0535 0.0516 0.0504 0.0495 0.0491 0.0481 0.0476 0.0472 

[TRAIN] Epoch[1](12796/114412); Loss: 0.077165; Backpropagation: 0.2922 sec; Batch: 2.1152 sec
0.1552 0.1393 0.1117 0.0912 0.0756 0.0691 0.0670 0.0645 0.0622 0.0603 0.0587 0.0572 0.0564 0.0558 0.0552 0.0551 

[TRAIN] Epoch[1](12797/114412); Loss: 0.088917; Backpropagation: 0.2910 sec; Batch: 2.1131 sec
0.1663 0.1505 0.1182 0.1086 0.0962 0.0875 0.0804 0.0748 0.0721 0.0703 0.0692 0.0676 0.0663 0.0654 0.0650 0.0642 

[TRAIN] Epoch[1](12798/114412); Loss: 0.094561; Backpropagation: 0.2909 sec; Batch: 2.1165 sec
0.1772 0.1602 0.1329 0.1158 0.1013 0.0938 0.0881 0.0824 0.0785 0.0750 0.0725 0.0701 0.0680 0.0669 0.0655 0.0647 

[TRAIN] Epoch[1](12799/114412); Loss: 0.095868; Backpropagation: 0.2910 sec; Batch: 2.1141 sec
0.1659 0.1511 0.1286 0.1183 0.1051 0.0968 0.0906 0.0849 0.0814 0.0785 0.0756 0.0738 0.0723 0.0713 0.0703 0.0694 

[TRAIN] Epoch[1](12800/114412); Loss: 0.077757; Backpropagation: 0.2904 sec; Batch: 2.1183 sec
0.1559 0.1466 0.1050 0.0828 0.0835 0.0742 0.0697 0.0658 0.0630 0.0615 0.0591 0.0567 0.0562 0.0557 0.0543 0.0541 

[TRAIN] Epoch[1](12801/114412); Loss: 0.078685; Backpropagation: 0.2955 sec; Batch: 2.1213 sec
0.1698 0.1425 0.1153 0.0961 0.0834 0.0759 0.0703 0.0653 0.0620 0.0594 0.0567 0.0546 0.0533 0.0522 0.0513 0.0506 

[TRAIN] Epoch[1](12802/114412); Loss: 0.087625; Backpropagation: 0.2910 sec; Batch: 2.1130 sec
0.1454 0.1398 0.1161 0.1007 0.0920 0.0864 0.0826 0.0787 0.0759 0.0736 0.0719 0.0700 0.0686 0.0678 0.0667 0.0659 

[TRAIN] Epoch[1](12803/114412); Loss: 0.072340; Backpropagation: 0.2910 sec; Batch: 2.1136 sec
0.1549 0.1191 0.0939 0.0825 0.0720 0.0677 0.0645 0.0617 0.0593 0.0576 0.0562 0.0551 0.0541 0.0534 0.0529 0.0526 

[TRAIN] Epoch[1](12804/114412); Loss: 0.086252; Backpropagation: 0.2909 sec; Batch: 2.1135 sec
0.1639 0.1432 0.1173 0.1042 0.0926 0.0834 0.0780 0.0739 0.0706 0.0681 0.0667 0.0654 0.0645 0.0633 0.0627 0.0622 

[TRAIN] Epoch[1](12805/114412); Loss: 0.076259; Backpropagation: 0.2914 sec; Batch: 2.1173 sec
0.2029 0.1854 0.1333 0.1056 0.0815 0.0735 0.0621 0.0524 0.0449 0.0422 0.0413 0.0404 0.0397 0.0386 0.0382 0.0381 

[TRAIN] Epoch[1](12806/114412); Loss: 0.088965; Backpropagation: 0.2909 sec; Batch: 2.1183 sec
0.1569 0.1472 0.1178 0.1087 0.0960 0.0876 0.0820 0.0770 0.0739 0.0712 0.0700 0.0689 0.0677 0.0666 0.0661 0.0657 

[TRAIN] Epoch[1](12807/114412); Loss: 0.097501; Backpropagation: 0.2913 sec; Batch: 2.1164 sec
0.1917 0.1643 0.1414 0.1196 0.1050 0.0947 0.0870 0.0820 0.0774 0.0753 0.0737 0.0719 0.0707 0.0693 0.0685 0.0676 

[TRAIN] Epoch[1](12808/114412); Loss: 0.076690; Backpropagation: 0.2910 sec; Batch: 2.1145 sec
0.1944 0.1716 0.1409 0.1113 0.0829 0.0652 0.0571 0.0537 0.0496 0.0466 0.0448 0.0436 0.0425 0.0414 0.0407 0.0405 

[TRAIN] Epoch[1](12809/114412); Loss: 0.070808; Backpropagation: 0.2913 sec; Batch: 2.1176 sec
0.1620 0.1403 0.1055 0.0905 0.0762 0.0659 0.0587 0.0555 0.0522 0.0497 0.0487 0.0472 0.0461 0.0454 0.0448 0.0444 

[TRAIN] Epoch[1](12810/114412); Loss: 0.107437; Backpropagation: 0.2913 sec; Batch: 2.1131 sec
0.1953 0.1837 0.1484 0.1195 0.1028 0.0983 0.0953 0.0919 0.0892 0.0874 0.0864 0.0851 0.0847 0.0840 0.0836 0.0833 

[TRAIN] Epoch[1](12811/114412); Loss: 0.059348; Backpropagation: 0.2954 sec; Batch: 2.1069 sec
0.1157 0.1024 0.0808 0.0675 0.0599 0.0544 0.0525 0.0503 0.0489 0.0477 0.0464 0.0455 0.0450 0.0446 0.0443 0.0439 

[TRAIN] Epoch[1](12812/114412); Loss: 0.091185; Backpropagation: 0.2930 sec; Batch: 2.1148 sec
0.1694 0.1485 0.1248 0.1114 0.1024 0.0930 0.0862 0.0792 0.0756 0.0720 0.0693 0.0675 0.0663 0.0654 0.0643 0.0637 

[TRAIN] Epoch[1](12813/114412); Loss: 0.073015; Backpropagation: 0.2917 sec; Batch: 2.1170 sec
0.1523 0.1384 0.1063 0.0895 0.0744 0.0676 0.0641 0.0599 0.0570 0.0546 0.0530 0.0515 0.0508 0.0501 0.0497 0.0492 

[TRAIN] Epoch[1](12814/114412); Loss: 0.066451; Backpropagation: 0.2913 sec; Batch: 2.1132 sec
0.1516 0.1287 0.1017 0.0827 0.0730 0.0636 0.0570 0.0524 0.0491 0.0463 0.0448 0.0441 0.0430 0.0425 0.0416 0.0413 

[TRAIN] Epoch[1](12815/114412); Loss: 0.063855; Backpropagation: 0.2915 sec; Batch: 2.1174 sec
0.1173 0.1081 0.0833 0.0730 0.0664 0.0611 0.0577 0.0555 0.0533 0.0519 0.0506 0.0498 0.0492 0.0486 0.0482 0.0478 

[TRAIN] Epoch[1](12816/114412); Loss: 0.102032; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1772 0.1644 0.1372 0.1226 0.1094 0.1000 0.0939 0.0894 0.0867 0.0835 0.0816 0.0800 0.0782 0.0771 0.0761 0.0752 

[TRAIN] Epoch[1](12817/114412); Loss: 0.088210; Backpropagation: 0.2930 sec; Batch: 2.1186 sec
0.1585 0.1407 0.1183 0.1075 0.0972 0.0898 0.0823 0.0779 0.0742 0.0717 0.0690 0.0671 0.0657 0.0645 0.0637 0.0631 

[TRAIN] Epoch[1](12818/114412); Loss: 0.064231; Backpropagation: 0.2914 sec; Batch: 2.1197 sec
0.1501 0.1389 0.0936 0.0703 0.0582 0.0565 0.0539 0.0501 0.0486 0.0471 0.0457 0.0445 0.0435 0.0428 0.0422 0.0416 

[TRAIN] Epoch[1](12819/114412); Loss: 0.069891; Backpropagation: 0.2902 sec; Batch: 2.1125 sec
0.1512 0.1230 0.0958 0.0779 0.0693 0.0631 0.0598 0.0571 0.0556 0.0542 0.0531 0.0527 0.0521 0.0514 0.0511 0.0509 

[TRAIN] Epoch[1](12820/114412); Loss: 0.109562; Backpropagation: 0.2905 sec; Batch: 2.1188 sec
0.2392 0.2124 0.1688 0.1390 0.1147 0.1049 0.0953 0.0852 0.0820 0.0796 0.0758 0.0741 0.0724 0.0711 0.0698 0.0689 

[TRAIN] Epoch[1](12821/114412); Loss: 0.083725; Backpropagation: 0.2914 sec; Batch: 2.1142 sec
0.1642 0.1468 0.1198 0.1045 0.0897 0.0813 0.0724 0.0691 0.0672 0.0654 0.0635 0.0604 0.0598 0.0591 0.0584 0.0579 

[TRAIN] Epoch[1](12822/114412); Loss: 0.079053; Backpropagation: 0.2913 sec; Batch: 2.1124 sec
0.1977 0.1727 0.1329 0.1088 0.0842 0.0644 0.0592 0.0558 0.0536 0.0522 0.0499 0.0484 0.0473 0.0466 0.0459 0.0453 

[TRAIN] Epoch[1](12823/114412); Loss: 0.080600; Backpropagation: 0.2913 sec; Batch: 2.1143 sec
0.1518 0.1448 0.1132 0.0990 0.0862 0.0775 0.0718 0.0671 0.0643 0.0620 0.0605 0.0596 0.0587 0.0582 0.0577 0.0571 

[TRAIN] Epoch[1](12824/114412); Loss: 0.074760; Backpropagation: 0.2910 sec; Batch: 2.1185 sec
0.1255 0.1149 0.0978 0.0882 0.0809 0.0746 0.0703 0.0667 0.0646 0.0626 0.0609 0.0595 0.0584 0.0578 0.0570 0.0564 

[TRAIN] Epoch[1](12825/114412); Loss: 0.072920; Backpropagation: 0.2912 sec; Batch: 2.0816 sec
0.1528 0.1449 0.1171 0.0937 0.0756 0.0691 0.0633 0.0580 0.0546 0.0523 0.0504 0.0488 0.0480 0.0469 0.0459 0.0455 

[TRAIN] Epoch[1](12826/114412); Loss: 0.093139; Backpropagation: 0.2915 sec; Batch: 2.1139 sec
0.1976 0.1871 0.1402 0.1224 0.1031 0.0871 0.0775 0.0705 0.0680 0.0665 0.0652 0.0632 0.0620 0.0609 0.0596 0.0593 

[TRAIN] Epoch[1](12827/114412); Loss: 0.084472; Backpropagation: 0.2910 sec; Batch: 2.0775 sec
0.2111 0.1840 0.1511 0.1126 0.0882 0.0682 0.0614 0.0602 0.0569 0.0547 0.0530 0.0522 0.0508 0.0495 0.0492 0.0485 

[TRAIN] Epoch[1](12828/114412); Loss: 0.086032; Backpropagation: 0.2910 sec; Batch: 2.1134 sec
0.1855 0.1711 0.1392 0.1174 0.0983 0.0836 0.0731 0.0662 0.0616 0.0587 0.0563 0.0549 0.0538 0.0529 0.0522 0.0518 

[TRAIN] Epoch[1](12829/114412); Loss: 0.089065; Backpropagation: 0.2907 sec; Batch: 2.1202 sec
0.1690 0.1644 0.1319 0.1150 0.0984 0.0865 0.0788 0.0721 0.0686 0.0664 0.0646 0.0636 0.0626 0.0617 0.0610 0.0606 

[TRAIN] Epoch[1](12830/114412); Loss: 0.070558; Backpropagation: 0.2909 sec; Batch: 2.0778 sec
0.1315 0.1188 0.0917 0.0817 0.0742 0.0686 0.0660 0.0624 0.0594 0.0575 0.0555 0.0541 0.0529 0.0521 0.0514 0.0510 

[TRAIN] Epoch[1](12831/114412); Loss: 0.090616; Backpropagation: 0.2911 sec; Batch: 2.1149 sec
0.1606 0.1520 0.1203 0.1043 0.0900 0.0855 0.0821 0.0783 0.0759 0.0743 0.0731 0.0724 0.0714 0.0705 0.0700 0.0691 

[TRAIN] Epoch[1](12832/114412); Loss: 0.065822; Backpropagation: 0.2916 sec; Batch: 2.0769 sec
0.1169 0.1106 0.0927 0.0791 0.0727 0.0663 0.0610 0.0564 0.0539 0.0518 0.0502 0.0496 0.0487 0.0483 0.0476 0.0473 

[TRAIN] Epoch[1](12833/114412); Loss: 0.074188; Backpropagation: 0.2952 sec; Batch: 2.1488 sec
0.1415 0.1245 0.1117 0.0930 0.0837 0.0753 0.0680 0.0612 0.0580 0.0564 0.0548 0.0532 0.0523 0.0517 0.0511 0.0505 

[TRAIN] Epoch[1](12834/114412); Loss: 0.089093; Backpropagation: 0.2952 sec; Batch: 2.0832 sec
0.1697 0.1512 0.1253 0.1031 0.0906 0.0822 0.0783 0.0744 0.0723 0.0710 0.0700 0.0689 0.0678 0.0673 0.0669 0.0665 

[TRAIN] Epoch[1](12835/114412); Loss: 0.108700; Backpropagation: 0.2913 sec; Batch: 2.1131 sec
0.1741 0.1623 0.1390 0.1252 0.1140 0.1071 0.1013 0.0972 0.0944 0.0925 0.0912 0.0899 0.0890 0.0881 0.0873 0.0866 

[TRAIN] Epoch[1](12836/114412); Loss: 0.064106; Backpropagation: 0.2909 sec; Batch: 2.0772 sec
0.1591 0.1506 0.1025 0.0781 0.0592 0.0516 0.0499 0.0470 0.0445 0.0433 0.0423 0.0413 0.0400 0.0391 0.0388 0.0384 

[TRAIN] Epoch[1](12837/114412); Loss: 0.066523; Backpropagation: 0.2910 sec; Batch: 2.1214 sec
0.1704 0.1479 0.1250 0.0933 0.0764 0.0631 0.0495 0.0449 0.0412 0.0396 0.0377 0.0366 0.0359 0.0348 0.0343 0.0338 

[TRAIN] Epoch[1](12838/114412); Loss: 0.085982; Backpropagation: 0.2912 sec; Batch: 2.1139 sec
0.1603 0.1341 0.1131 0.1026 0.0928 0.0844 0.0779 0.0745 0.0718 0.0700 0.0683 0.0665 0.0659 0.0652 0.0644 0.0639 

[TRAIN] Epoch[1](12839/114412); Loss: 0.060419; Backpropagation: 0.2914 sec; Batch: 2.1155 sec
0.1551 0.1299 0.0944 0.0699 0.0574 0.0520 0.0504 0.0460 0.0434 0.0413 0.0397 0.0386 0.0380 0.0374 0.0369 0.0366 

[TRAIN] Epoch[1](12840/114412); Loss: 0.073025; Backpropagation: 0.2929 sec; Batch: 2.1214 sec
0.1469 0.1312 0.1002 0.0854 0.0752 0.0688 0.0652 0.0618 0.0588 0.0570 0.0557 0.0538 0.0530 0.0524 0.0517 0.0513 

[TRAIN] Epoch[1](12841/114412); Loss: 0.077612; Backpropagation: 0.2928 sec; Batch: 2.0791 sec
0.1755 0.1593 0.1249 0.0983 0.0792 0.0699 0.0652 0.0593 0.0568 0.0545 0.0527 0.0509 0.0500 0.0492 0.0484 0.0477 

[TRAIN] Epoch[1](12842/114412); Loss: 0.084736; Backpropagation: 0.2913 sec; Batch: 2.1190 sec
0.1918 0.1719 0.1352 0.1119 0.0875 0.0702 0.0688 0.0628 0.0604 0.0592 0.0582 0.0571 0.0562 0.0554 0.0547 0.0544 

[TRAIN] Epoch[1](12843/114412); Loss: 0.079889; Backpropagation: 0.2921 sec; Batch: 2.1184 sec
0.1700 0.1592 0.1220 0.0990 0.0814 0.0722 0.0673 0.0638 0.0612 0.0582 0.0566 0.0556 0.0539 0.0530 0.0526 0.0522 

[TRAIN] Epoch[1](12844/114412); Loss: 0.059711; Backpropagation: 0.2910 sec; Batch: 2.1057 sec
0.1139 0.0994 0.0799 0.0690 0.0589 0.0560 0.0530 0.0498 0.0487 0.0483 0.0474 0.0467 0.0463 0.0460 0.0460 0.0460 

[TRAIN] Epoch[1](12845/114412); Loss: 0.064465; Backpropagation: 0.2953 sec; Batch: 2.1203 sec
0.1425 0.1161 0.0863 0.0689 0.0643 0.0596 0.0581 0.0549 0.0526 0.0501 0.0489 0.0478 0.0465 0.0456 0.0449 0.0444 

[TRAIN] Epoch[1](12846/114412); Loss: 0.083974; Backpropagation: 0.2927 sec; Batch: 2.1133 sec
0.1708 0.1585 0.1250 0.1045 0.0899 0.0790 0.0726 0.0682 0.0637 0.0620 0.0615 0.0593 0.0582 0.0575 0.0566 0.0561 

[TRAIN] Epoch[1](12847/114412); Loss: 0.057284; Backpropagation: 0.2932 sec; Batch: 2.1160 sec
0.1348 0.1277 0.0848 0.0685 0.0574 0.0523 0.0483 0.0440 0.0419 0.0399 0.0386 0.0371 0.0361 0.0355 0.0350 0.0347 

[TRAIN] Epoch[1](12848/114412); Loss: 0.079208; Backpropagation: 0.2927 sec; Batch: 2.1201 sec
0.1398 0.1296 0.1058 0.0930 0.0829 0.0766 0.0726 0.0692 0.0665 0.0646 0.0634 0.0623 0.0613 0.0605 0.0599 0.0593 

[TRAIN] Epoch[1](12849/114412); Loss: 0.087107; Backpropagation: 0.2953 sec; Batch: 2.1327 sec
0.1463 0.1313 0.1156 0.1051 0.0936 0.0882 0.0829 0.0789 0.0753 0.0727 0.0708 0.0688 0.0674 0.0665 0.0656 0.0648 

[TRAIN] Epoch[1](12850/114412); Loss: 0.071587; Backpropagation: 0.2914 sec; Batch: 2.0849 sec
0.1378 0.1231 0.0945 0.0813 0.0743 0.0690 0.0653 0.0619 0.0591 0.0577 0.0563 0.0548 0.0539 0.0529 0.0521 0.0514 

[TRAIN] Epoch[1](12851/114412); Loss: 0.074534; Backpropagation: 0.2911 sec; Batch: 2.1018 sec
0.1452 0.1358 0.1036 0.0873 0.0746 0.0709 0.0669 0.0629 0.0610 0.0597 0.0575 0.0557 0.0540 0.0531 0.0527 0.0517 

[TRAIN] Epoch[1](12852/114412); Loss: 0.100180; Backpropagation: 0.2925 sec; Batch: 2.0953 sec
0.1842 0.1687 0.1464 0.1196 0.1050 0.0930 0.0873 0.0833 0.0812 0.0795 0.0779 0.0773 0.0761 0.0751 0.0744 0.0739 

[TRAIN] Epoch[1](12853/114412); Loss: 0.073226; Backpropagation: 0.2928 sec; Batch: 2.0784 sec
0.1323 0.1183 0.1011 0.0873 0.0770 0.0693 0.0655 0.0623 0.0607 0.0592 0.0581 0.0572 0.0566 0.0561 0.0555 0.0551 

[TRAIN] Epoch[1](12854/114412); Loss: 0.063090; Backpropagation: 0.2951 sec; Batch: 2.1193 sec
0.1194 0.1021 0.0873 0.0766 0.0678 0.0615 0.0561 0.0541 0.0518 0.0501 0.0489 0.0479 0.0472 0.0465 0.0461 0.0460 

[TRAIN] Epoch[1](12855/114412); Loss: 0.089023; Backpropagation: 0.2913 sec; Batch: 2.1145 sec
0.1693 0.1592 0.1286 0.1107 0.0948 0.0841 0.0768 0.0738 0.0706 0.0689 0.0670 0.0658 0.0648 0.0638 0.0632 0.0629 

[TRAIN] Epoch[1](12856/114412); Loss: 0.074977; Backpropagation: 0.2913 sec; Batch: 2.1168 sec
0.1574 0.1402 0.1057 0.0853 0.0756 0.0712 0.0655 0.0617 0.0594 0.0578 0.0563 0.0545 0.0535 0.0527 0.0518 0.0511 

[TRAIN] Epoch[1](12857/114412); Loss: 0.073185; Backpropagation: 0.2906 sec; Batch: 2.1132 sec
0.1294 0.1281 0.0986 0.0915 0.0788 0.0697 0.0668 0.0640 0.0625 0.0588 0.0563 0.0551 0.0542 0.0530 0.0522 0.0519 

[TRAIN] Epoch[1](12858/114412); Loss: 0.091414; Backpropagation: 0.2906 sec; Batch: 2.1129 sec
0.1679 0.1570 0.1212 0.1029 0.0951 0.0869 0.0834 0.0797 0.0771 0.0749 0.0724 0.0706 0.0697 0.0688 0.0678 0.0673 

[TRAIN] Epoch[1](12859/114412); Loss: 0.064596; Backpropagation: 0.2911 sec; Batch: 2.1151 sec
0.1562 0.1228 0.0858 0.0702 0.0594 0.0557 0.0539 0.0520 0.0505 0.0490 0.0482 0.0472 0.0466 0.0459 0.0453 0.0450 

[TRAIN] Epoch[1](12860/114412); Loss: 0.077872; Backpropagation: 0.2911 sec; Batch: 2.1147 sec
0.1719 0.1599 0.1258 0.0995 0.0802 0.0699 0.0633 0.0599 0.0577 0.0551 0.0530 0.0518 0.0505 0.0497 0.0492 0.0486 

[TRAIN] Epoch[1](12861/114412); Loss: 0.083775; Backpropagation: 0.2913 sec; Batch: 2.1167 sec
0.1623 0.1530 0.1204 0.1064 0.0926 0.0827 0.0744 0.0682 0.0646 0.0628 0.0614 0.0603 0.0588 0.0581 0.0576 0.0567 

[TRAIN] Epoch[1](12862/114412); Loss: 0.070986; Backpropagation: 0.2913 sec; Batch: 2.0854 sec
0.1429 0.1219 0.0991 0.0857 0.0753 0.0667 0.0619 0.0595 0.0578 0.0552 0.0536 0.0524 0.0517 0.0511 0.0506 0.0503 

[TRAIN] Epoch[1](12863/114412); Loss: 0.078969; Backpropagation: 0.2909 sec; Batch: 2.1285 sec
0.1449 0.1314 0.1059 0.0912 0.0803 0.0743 0.0697 0.0671 0.0651 0.0640 0.0634 0.0623 0.0617 0.0612 0.0606 0.0603 

[TRAIN] Epoch[1](12864/114412); Loss: 0.092079; Backpropagation: 0.2911 sec; Batch: 2.1256 sec
0.1735 0.1537 0.1278 0.1119 0.1013 0.0916 0.0833 0.0784 0.0754 0.0726 0.0701 0.0682 0.0675 0.0665 0.0659 0.0655 

[TRAIN] Epoch[1](12865/114412); Loss: 0.090465; Backpropagation: 0.2914 sec; Batch: 2.1150 sec
0.1871 0.1761 0.1347 0.1144 0.0950 0.0836 0.0760 0.0709 0.0683 0.0662 0.0648 0.0636 0.0624 0.0618 0.0615 0.0610 

[TRAIN] Epoch[1](12866/114412); Loss: 0.065519; Backpropagation: 0.2906 sec; Batch: 2.1231 sec
0.1304 0.1188 0.0907 0.0775 0.0688 0.0636 0.0590 0.0565 0.0532 0.0511 0.0492 0.0480 0.0467 0.0455 0.0448 0.0444 

[TRAIN] Epoch[1](12867/114412); Loss: 0.083651; Backpropagation: 0.2931 sec; Batch: 2.1218 sec
0.1514 0.1463 0.1196 0.1036 0.0931 0.0833 0.0779 0.0716 0.0675 0.0647 0.0623 0.0614 0.0603 0.0591 0.0583 0.0581 

[TRAIN] Epoch[1](12868/114412); Loss: 0.100266; Backpropagation: 0.2928 sec; Batch: 2.1162 sec
0.1619 0.1582 0.1316 0.1184 0.1068 0.0987 0.0929 0.0885 0.0857 0.0841 0.0821 0.0808 0.0800 0.0790 0.0782 0.0775 

[TRAIN] Epoch[1](12869/114412); Loss: 0.098563; Backpropagation: 0.2909 sec; Batch: 2.0781 sec
0.1752 0.1650 0.1335 0.1176 0.1056 0.0962 0.0900 0.0853 0.0824 0.0794 0.0778 0.0762 0.0747 0.0737 0.0724 0.0719 

[TRAIN] Epoch[1](12870/114412); Loss: 0.071444; Backpropagation: 0.2911 sec; Batch: 2.1231 sec
0.1264 0.1134 0.0882 0.0783 0.0744 0.0699 0.0670 0.0640 0.0618 0.0598 0.0586 0.0576 0.0568 0.0562 0.0557 0.0552 

[TRAIN] Epoch[1](12871/114412); Loss: 0.094713; Backpropagation: 0.2905 sec; Batch: 2.0776 sec
0.1752 0.1741 0.1366 0.1240 0.1079 0.0955 0.0872 0.0779 0.0738 0.0716 0.0685 0.0664 0.0653 0.0646 0.0638 0.0631 

[TRAIN] Epoch[1](12872/114412); Loss: 0.071407; Backpropagation: 0.2932 sec; Batch: 2.1200 sec
0.1245 0.1116 0.0953 0.0818 0.0735 0.0687 0.0652 0.0626 0.0609 0.0595 0.0581 0.0573 0.0567 0.0561 0.0556 0.0553 

[TRAIN] Epoch[1](12873/114412); Loss: 0.097720; Backpropagation: 0.2913 sec; Batch: 2.1161 sec
0.1707 0.1581 0.1427 0.1180 0.1059 0.0936 0.0882 0.0855 0.0799 0.0769 0.0760 0.0751 0.0741 0.0735 0.0728 0.0724 

[TRAIN] Epoch[1](12874/114412); Loss: 0.089774; Backpropagation: 0.2907 sec; Batch: 2.1167 sec
0.2189 0.1993 0.1619 0.1256 0.1008 0.0796 0.0675 0.0625 0.0585 0.0561 0.0536 0.0524 0.0512 0.0503 0.0495 0.0488 

[TRAIN] Epoch[1](12875/114412); Loss: 0.090191; Backpropagation: 0.2912 sec; Batch: 2.0776 sec
0.1901 0.1772 0.1354 0.1176 0.0978 0.0834 0.0751 0.0722 0.0726 0.0666 0.0643 0.0613 0.0592 0.0577 0.0567 0.0561 

[TRAIN] Epoch[1](12876/114412); Loss: 0.073226; Backpropagation: 0.2928 sec; Batch: 2.1201 sec
0.1600 0.1524 0.1120 0.0967 0.0823 0.0725 0.0627 0.0561 0.0525 0.0504 0.0481 0.0471 0.0460 0.0449 0.0441 0.0435 

[TRAIN] Epoch[1](12877/114412); Loss: 0.087451; Backpropagation: 0.2909 sec; Batch: 2.1112 sec
0.1333 0.1358 0.1124 0.1029 0.0934 0.0861 0.0809 0.0774 0.0755 0.0738 0.0727 0.0720 0.0713 0.0710 0.0707 0.0700 

[TRAIN] Epoch[1](12878/114412); Loss: 0.071565; Backpropagation: 0.2907 sec; Batch: 2.0777 sec
0.1465 0.1377 0.1004 0.0824 0.0736 0.0652 0.0601 0.0582 0.0569 0.0552 0.0533 0.0521 0.0517 0.0511 0.0505 0.0501 

[TRAIN] Epoch[1](12879/114412); Loss: 0.083626; Backpropagation: 0.2913 sec; Batch: 2.1215 sec
0.1405 0.1285 0.1112 0.0985 0.0889 0.0833 0.0782 0.0737 0.0712 0.0694 0.0680 0.0668 0.0659 0.0651 0.0645 0.0642 

[TRAIN] Epoch[1](12880/114412); Loss: 0.072316; Backpropagation: 0.2911 sec; Batch: 2.0779 sec
0.1268 0.1189 0.0917 0.0842 0.0777 0.0720 0.0677 0.0643 0.0617 0.0600 0.0582 0.0568 0.0556 0.0546 0.0538 0.0530 

[TRAIN] Epoch[1](12881/114412); Loss: 0.073419; Backpropagation: 0.2905 sec; Batch: 2.1133 sec
0.1495 0.1439 0.1099 0.0855 0.0690 0.0697 0.0642 0.0587 0.0564 0.0553 0.0542 0.0529 0.0519 0.0517 0.0512 0.0506 

[TRAIN] Epoch[1](12882/114412); Loss: 0.080530; Backpropagation: 0.2910 sec; Batch: 2.1171 sec
0.1463 0.1333 0.1171 0.0987 0.0867 0.0791 0.0733 0.0691 0.0658 0.0633 0.0616 0.0603 0.0596 0.0586 0.0580 0.0576 

[TRAIN] Epoch[1](12883/114412); Loss: 0.063613; Backpropagation: 0.2919 sec; Batch: 2.0788 sec
0.1308 0.1147 0.0909 0.0782 0.0658 0.0592 0.0544 0.0515 0.0499 0.0482 0.0470 0.0465 0.0457 0.0454 0.0451 0.0445 

[TRAIN] Epoch[1](12884/114412); Loss: 0.095054; Backpropagation: 0.2903 sec; Batch: 2.1111 sec
0.1934 0.1853 0.1455 0.1182 0.1001 0.0876 0.0795 0.0756 0.0724 0.0700 0.0683 0.0667 0.0656 0.0648 0.0641 0.0637 

[TRAIN] Epoch[1](12885/114412); Loss: 0.076440; Backpropagation: 0.2901 sec; Batch: 2.0769 sec
0.1315 0.1184 0.1048 0.0899 0.0815 0.0756 0.0716 0.0678 0.0654 0.0630 0.0615 0.0603 0.0592 0.0581 0.0575 0.0570 

[TRAIN] Epoch[1](12886/114412); Loss: 0.070058; Backpropagation: 0.2912 sec; Batch: 2.0777 sec
0.1373 0.1293 0.0995 0.0801 0.0673 0.0611 0.0592 0.0573 0.0564 0.0554 0.0546 0.0537 0.0528 0.0526 0.0523 0.0521 

[TRAIN] Epoch[1](12887/114412); Loss: 0.061910; Backpropagation: 0.2913 sec; Batch: 2.1161 sec
0.1150 0.1074 0.0834 0.0693 0.0611 0.0585 0.0558 0.0531 0.0517 0.0502 0.0494 0.0484 0.0475 0.0469 0.0466 0.0463 

[TRAIN] Epoch[1](12888/114412); Loss: 0.078247; Backpropagation: 0.2908 sec; Batch: 2.0771 sec
0.1325 0.1261 0.1036 0.0885 0.0813 0.0756 0.0721 0.0695 0.0670 0.0655 0.0641 0.0627 0.0617 0.0612 0.0606 0.0602 

[TRAIN] Epoch[1](12889/114412); Loss: 0.075753; Backpropagation: 0.2908 sec; Batch: 2.1146 sec
0.1287 0.1228 0.0996 0.0875 0.0802 0.0747 0.0708 0.0677 0.0644 0.0626 0.0611 0.0600 0.0590 0.0582 0.0578 0.0571 

[TRAIN] Epoch[1](12890/114412); Loss: 0.074655; Backpropagation: 0.2913 sec; Batch: 2.1135 sec
0.1521 0.1360 0.1055 0.0853 0.0729 0.0673 0.0638 0.0615 0.0595 0.0584 0.0573 0.0562 0.0553 0.0549 0.0545 0.0540 

[TRAIN] Epoch[1](12891/114412); Loss: 0.103260; Backpropagation: 0.2951 sec; Batch: 2.1176 sec
0.1653 0.1589 0.1347 0.1217 0.1108 0.1040 0.0973 0.0937 0.0910 0.0876 0.0853 0.0833 0.0814 0.0802 0.0789 0.0779 

[TRAIN] Epoch[1](12892/114412); Loss: 0.072604; Backpropagation: 0.2927 sec; Batch: 2.1222 sec
0.1735 0.1706 0.1235 0.0943 0.0691 0.0565 0.0534 0.0507 0.0487 0.0483 0.0468 0.0458 0.0456 0.0451 0.0450 0.0448 

[TRAIN] Epoch[1](12893/114412); Loss: 0.089016; Backpropagation: 0.2912 sec; Batch: 2.1279 sec
0.1639 0.1508 0.1230 0.1088 0.0956 0.0853 0.0808 0.0765 0.0736 0.0710 0.0689 0.0670 0.0659 0.0650 0.0643 0.0639 

[TRAIN] Epoch[1](12894/114412); Loss: 0.072795; Backpropagation: 0.2909 sec; Batch: 2.1135 sec
0.1558 0.1468 0.1065 0.0831 0.0731 0.0664 0.0612 0.0588 0.0567 0.0551 0.0526 0.0508 0.0506 0.0496 0.0492 0.0486 

[TRAIN] Epoch[1](12895/114412); Loss: 0.129767; Backpropagation: 0.2909 sec; Batch: 2.1158 sec
0.2133 0.2087 0.1787 0.1624 0.1483 0.1348 0.1260 0.1156 0.1104 0.1067 0.1006 0.0985 0.0961 0.0930 0.0921 0.0910 

[TRAIN] Epoch[1](12896/114412); Loss: 0.078111; Backpropagation: 0.2953 sec; Batch: 2.1195 sec
0.1576 0.1377 0.1140 0.1011 0.0845 0.0748 0.0693 0.0653 0.0620 0.0592 0.0574 0.0556 0.0543 0.0530 0.0523 0.0516 

[TRAIN] Epoch[1](12897/114412); Loss: 0.084254; Backpropagation: 0.2933 sec; Batch: 2.1199 sec
0.1387 0.1353 0.1093 0.0970 0.0883 0.0820 0.0783 0.0749 0.0724 0.0706 0.0691 0.0680 0.0672 0.0664 0.0656 0.0650 

[TRAIN] Epoch[1](12898/114412); Loss: 0.090369; Backpropagation: 0.2911 sec; Batch: 2.1143 sec
0.1611 0.1543 0.1241 0.1092 0.1004 0.0928 0.0844 0.0791 0.0754 0.0721 0.0693 0.0670 0.0659 0.0646 0.0634 0.0628 

[TRAIN] Epoch[1](12899/114412); Loss: 0.085895; Backpropagation: 0.2926 sec; Batch: 2.1160 sec
0.1569 0.1441 0.1243 0.1071 0.0927 0.0843 0.0775 0.0732 0.0693 0.0678 0.0663 0.0642 0.0629 0.0619 0.0612 0.0606 

[TRAIN] Epoch[1](12900/114412); Loss: 0.066631; Backpropagation: 0.2917 sec; Batch: 2.0785 sec
0.1107 0.1029 0.0845 0.0773 0.0704 0.0642 0.0618 0.0599 0.0580 0.0566 0.0552 0.0544 0.0535 0.0526 0.0522 0.0519 

[TRAIN] Epoch[1](12901/114412); Loss: 0.083108; Backpropagation: 0.2909 sec; Batch: 2.1062 sec
0.1425 0.1329 0.1099 0.0986 0.0874 0.0802 0.0762 0.0727 0.0704 0.0688 0.0672 0.0660 0.0652 0.0643 0.0639 0.0634 

[TRAIN] Epoch[1](12902/114412); Loss: 0.085376; Backpropagation: 0.2913 sec; Batch: 2.0775 sec
0.1421 0.1344 0.1094 0.0962 0.0888 0.0831 0.0790 0.0764 0.0741 0.0725 0.0711 0.0693 0.0684 0.0678 0.0671 0.0664 

[TRAIN] Epoch[1](12903/114412); Loss: 0.061218; Backpropagation: 0.2910 sec; Batch: 2.1176 sec
0.1417 0.1206 0.0913 0.0701 0.0621 0.0549 0.0502 0.0481 0.0468 0.0446 0.0426 0.0424 0.0418 0.0411 0.0407 0.0405 

[TRAIN] Epoch[1](12904/114412); Loss: 0.078382; Backpropagation: 0.2927 sec; Batch: 2.1201 sec
0.1391 0.1332 0.1051 0.0948 0.0875 0.0795 0.0723 0.0684 0.0659 0.0635 0.0611 0.0592 0.0577 0.0563 0.0556 0.0549 

[TRAIN] Epoch[1](12905/114412); Loss: 0.072039; Backpropagation: 0.2913 sec; Batch: 2.0798 sec
0.1355 0.1301 0.1028 0.0835 0.0716 0.0665 0.0635 0.0610 0.0593 0.0576 0.0562 0.0551 0.0538 0.0526 0.0521 0.0512 

[TRAIN] Epoch[1](12906/114412); Loss: 0.062622; Backpropagation: 0.2953 sec; Batch: 2.0825 sec
0.1513 0.1398 0.1036 0.0842 0.0680 0.0540 0.0474 0.0452 0.0426 0.0410 0.0393 0.0383 0.0378 0.0368 0.0363 0.0362 

[TRAIN] Epoch[1](12907/114412); Loss: 0.073753; Backpropagation: 0.2929 sec; Batch: 2.0869 sec
0.1287 0.1210 0.0934 0.0836 0.0778 0.0715 0.0677 0.0660 0.0633 0.0615 0.0598 0.0583 0.0579 0.0572 0.0564 0.0561 

[TRAIN] Epoch[1](12908/114412); Loss: 0.079438; Backpropagation: 0.2905 sec; Batch: 2.0783 sec
0.1508 0.1347 0.1042 0.0967 0.0831 0.0757 0.0727 0.0685 0.0656 0.0640 0.0618 0.0606 0.0595 0.0586 0.0576 0.0567 

[TRAIN] Epoch[1](12909/114412); Loss: 0.093360; Backpropagation: 0.2905 sec; Batch: 2.1094 sec
0.1529 0.1430 0.1158 0.1043 0.0961 0.0908 0.0872 0.0840 0.0820 0.0801 0.0787 0.0773 0.0764 0.0756 0.0749 0.0747 

[TRAIN] Epoch[1](12910/114412); Loss: 0.097474; Backpropagation: 0.2907 sec; Batch: 2.1139 sec
0.1525 0.1498 0.1270 0.1121 0.1046 0.0984 0.0952 0.0879 0.0844 0.0821 0.0797 0.0785 0.0775 0.0772 0.0766 0.0760 

[TRAIN] Epoch[1](12911/114412); Loss: 0.079777; Backpropagation: 0.2913 sec; Batch: 2.1179 sec
0.1286 0.1168 0.1014 0.0929 0.0858 0.0796 0.0749 0.0715 0.0697 0.0681 0.0666 0.0653 0.0648 0.0641 0.0633 0.0629 

[TRAIN] Epoch[1](12912/114412); Loss: 0.090402; Backpropagation: 0.2910 sec; Batch: 2.1129 sec
0.1709 0.1610 0.1297 0.1096 0.0945 0.0848 0.0798 0.0761 0.0729 0.0709 0.0694 0.0676 0.0661 0.0651 0.0644 0.0637 

[TRAIN] Epoch[1](12913/114412); Loss: 0.060571; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1064 0.1038 0.0839 0.0739 0.0659 0.0613 0.0572 0.0538 0.0511 0.0483 0.0467 0.0454 0.0442 0.0430 0.0423 0.0419 

[TRAIN] Epoch[1](12914/114412); Loss: 0.104083; Backpropagation: 0.2913 sec; Batch: 2.1172 sec
0.1767 0.1649 0.1433 0.1280 0.1141 0.1029 0.0956 0.0902 0.0869 0.0849 0.0830 0.0812 0.0800 0.0788 0.0779 0.0768 

[TRAIN] Epoch[1](12915/114412); Loss: 0.077596; Backpropagation: 0.2909 sec; Batch: 2.1179 sec
0.1402 0.1354 0.1028 0.0877 0.0821 0.0757 0.0697 0.0671 0.0645 0.0631 0.0617 0.0601 0.0591 0.0582 0.0574 0.0567 

[TRAIN] Epoch[1](12916/114412); Loss: 0.072463; Backpropagation: 0.2905 sec; Batch: 2.1170 sec
0.1484 0.1409 0.1034 0.0899 0.0796 0.0719 0.0642 0.0587 0.0560 0.0530 0.0513 0.0499 0.0488 0.0482 0.0478 0.0474 

[TRAIN] Epoch[1](12917/114412); Loss: 0.077407; Backpropagation: 0.2910 sec; Batch: 2.1131 sec
0.1674 0.1487 0.1208 0.0958 0.0804 0.0703 0.0651 0.0628 0.0585 0.0565 0.0546 0.0534 0.0524 0.0515 0.0505 0.0499 

[TRAIN] Epoch[1](12918/114412); Loss: 0.070757; Backpropagation: 0.2914 sec; Batch: 2.1180 sec
0.1600 0.1566 0.1179 0.0933 0.0728 0.0586 0.0539 0.0509 0.0492 0.0476 0.0466 0.0459 0.0454 0.0449 0.0445 0.0441 

[TRAIN] Epoch[1](12919/114412); Loss: 0.063836; Backpropagation: 0.2912 sec; Batch: 2.1223 sec
0.1267 0.1226 0.0909 0.0743 0.0645 0.0594 0.0553 0.0525 0.0504 0.0488 0.0478 0.0469 0.0461 0.0456 0.0450 0.0446 

[TRAIN] Epoch[1](12920/114412); Loss: 0.081864; Backpropagation: 0.2929 sec; Batch: 2.0791 sec
0.1269 0.1182 0.0998 0.0925 0.0865 0.0808 0.0772 0.0749 0.0726 0.0716 0.0701 0.0693 0.0684 0.0675 0.0671 0.0667 

[TRAIN] Epoch[1](12921/114412); Loss: 0.096406; Backpropagation: 0.2915 sec; Batch: 2.0805 sec
0.2086 0.1919 0.1541 0.1259 0.1053 0.0918 0.0801 0.0758 0.0743 0.0675 0.0661 0.0632 0.0607 0.0598 0.0594 0.0579 

[TRAIN] Epoch[1](12922/114412); Loss: 0.086877; Backpropagation: 0.2913 sec; Batch: 2.1155 sec
0.1961 0.1742 0.1347 0.1008 0.0850 0.0783 0.0729 0.0684 0.0659 0.0632 0.0613 0.0595 0.0586 0.0576 0.0570 0.0565 

[TRAIN] Epoch[1](12923/114412); Loss: 0.084032; Backpropagation: 0.2907 sec; Batch: 2.1177 sec
0.1588 0.1506 0.1146 0.0965 0.0870 0.0796 0.0741 0.0714 0.0684 0.0668 0.0652 0.0640 0.0630 0.0623 0.0614 0.0608 

[TRAIN] Epoch[1](12924/114412); Loss: 0.083864; Backpropagation: 0.2905 sec; Batch: 2.1162 sec
0.1601 0.1534 0.1223 0.1034 0.0870 0.0775 0.0720 0.0693 0.0670 0.0641 0.0634 0.0619 0.0608 0.0604 0.0598 0.0594 

[TRAIN] Epoch[1](12925/114412); Loss: 0.083180; Backpropagation: 0.2912 sec; Batch: 2.1183 sec
0.1777 0.1720 0.1302 0.1021 0.0890 0.0776 0.0703 0.0657 0.0618 0.0596 0.0577 0.0559 0.0541 0.0531 0.0524 0.0517 

[TRAIN] Epoch[1](12926/114412); Loss: 0.089109; Backpropagation: 0.2923 sec; Batch: 2.1153 sec
0.1560 0.1512 0.1157 0.1045 0.0943 0.0846 0.0806 0.0778 0.0750 0.0729 0.0714 0.0703 0.0689 0.0682 0.0676 0.0667 

[TRAIN] Epoch[1](12927/114412); Loss: 0.078241; Backpropagation: 0.2954 sec; Batch: 2.1214 sec
0.1469 0.1305 0.1114 0.0931 0.0840 0.0750 0.0694 0.0662 0.0647 0.0622 0.0605 0.0593 0.0584 0.0572 0.0567 0.0563 

[TRAIN] Epoch[1](12928/114412); Loss: 0.115883; Backpropagation: 0.2909 sec; Batch: 2.1186 sec
0.1687 0.1651 0.1440 0.1319 0.1229 0.1168 0.1119 0.1074 0.1038 0.1012 0.0995 0.0982 0.0971 0.0961 0.0951 0.0943 

[TRAIN] Epoch[1](12929/114412); Loss: 0.077007; Backpropagation: 0.2915 sec; Batch: 2.1154 sec
0.1529 0.1360 0.1041 0.0891 0.0781 0.0708 0.0672 0.0652 0.0630 0.0610 0.0594 0.0586 0.0577 0.0570 0.0563 0.0557 

[TRAIN] Epoch[1](12930/114412); Loss: 0.065385; Backpropagation: 0.2937 sec; Batch: 2.1184 sec
0.1134 0.1121 0.0940 0.0770 0.0691 0.0618 0.0586 0.0557 0.0537 0.0524 0.0511 0.0506 0.0497 0.0493 0.0490 0.0487 

[TRAIN] Epoch[1](12931/114412); Loss: 0.075669; Backpropagation: 0.2923 sec; Batch: 2.1139 sec
0.1490 0.1412 0.1071 0.0872 0.0753 0.0686 0.0656 0.0625 0.0604 0.0590 0.0581 0.0569 0.0560 0.0552 0.0546 0.0541 

[TRAIN] Epoch[1](12932/114412); Loss: 0.081210; Backpropagation: 0.2908 sec; Batch: 2.1193 sec
0.1598 0.1509 0.1136 0.0910 0.0817 0.0786 0.0727 0.0691 0.0656 0.0636 0.0619 0.0609 0.0590 0.0580 0.0571 0.0560 

[TRAIN] Epoch[1](12933/114412); Loss: 0.121895; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.2647 0.2592 0.2128 0.1730 0.1411 0.1109 0.0971 0.0864 0.0823 0.0803 0.0778 0.0753 0.0737 0.0729 0.0719 0.0712 

[TRAIN] Epoch[1](12934/114412); Loss: 0.070474; Backpropagation: 0.2904 sec; Batch: 2.1171 sec
0.1758 0.1611 0.1295 0.1011 0.0836 0.0652 0.0515 0.0469 0.0446 0.0422 0.0403 0.0392 0.0376 0.0367 0.0365 0.0359 

[TRAIN] Epoch[1](12935/114412); Loss: 0.068222; Backpropagation: 0.2927 sec; Batch: 2.1194 sec
0.1275 0.1139 0.0936 0.0791 0.0707 0.0659 0.0621 0.0592 0.0566 0.0546 0.0536 0.0525 0.0515 0.0507 0.0501 0.0499 

[TRAIN] Epoch[1](12936/114412); Loss: 0.087622; Backpropagation: 0.2914 sec; Batch: 2.1193 sec
0.1537 0.1492 0.1244 0.1076 0.0947 0.0862 0.0814 0.0770 0.0739 0.0706 0.0677 0.0653 0.0641 0.0631 0.0619 0.0613 

[TRAIN] Epoch[1](12937/114412); Loss: 0.098686; Backpropagation: 0.2910 sec; Batch: 2.1155 sec
0.1637 0.1591 0.1371 0.1225 0.1114 0.1011 0.0927 0.0864 0.0836 0.0793 0.0774 0.0751 0.0742 0.0731 0.0716 0.0709 

[TRAIN] Epoch[1](12938/114412); Loss: 0.065971; Backpropagation: 0.2910 sec; Batch: 2.1053 sec
0.1334 0.1284 0.0991 0.0786 0.0664 0.0595 0.0553 0.0525 0.0509 0.0494 0.0489 0.0479 0.0471 0.0465 0.0461 0.0457 

[TRAIN] Epoch[1](12939/114412); Loss: 0.079891; Backpropagation: 0.2913 sec; Batch: 2.0767 sec
0.1262 0.1213 0.1021 0.0935 0.0851 0.0793 0.0747 0.0718 0.0693 0.0677 0.0666 0.0655 0.0648 0.0640 0.0634 0.0630 

[TRAIN] Epoch[1](12940/114412); Loss: 0.090665; Backpropagation: 0.2906 sec; Batch: 2.1171 sec
0.1857 0.1777 0.1386 0.1134 0.0941 0.0813 0.0791 0.0725 0.0694 0.0674 0.0652 0.0637 0.0623 0.0609 0.0602 0.0594 

[TRAIN] Epoch[1](12941/114412); Loss: 0.074925; Backpropagation: 0.2909 sec; Batch: 2.1197 sec
0.1137 0.1095 0.0885 0.0806 0.0766 0.0737 0.0710 0.0689 0.0669 0.0660 0.0654 0.0647 0.0641 0.0634 0.0631 0.0628 

[TRAIN] Epoch[1](12942/114412); Loss: 0.076635; Backpropagation: 0.2910 sec; Batch: 2.1066 sec
0.1481 0.1366 0.1049 0.0831 0.0754 0.0695 0.0669 0.0646 0.0628 0.0613 0.0601 0.0596 0.0589 0.0584 0.0582 0.0578 

[TRAIN] Epoch[1](12943/114412); Loss: 0.054129; Backpropagation: 0.2933 sec; Batch: 2.1206 sec
0.1116 0.1004 0.0748 0.0624 0.0556 0.0496 0.0465 0.0452 0.0431 0.0420 0.0408 0.0398 0.0394 0.0387 0.0382 0.0380 

[TRAIN] Epoch[1](12944/114412); Loss: 0.080717; Backpropagation: 0.2910 sec; Batch: 2.1164 sec
0.1615 0.1521 0.1175 0.0990 0.0854 0.0771 0.0685 0.0639 0.0625 0.0613 0.0600 0.0582 0.0567 0.0564 0.0558 0.0554 

[TRAIN] Epoch[1](12945/114412); Loss: 0.097850; Backpropagation: 0.2909 sec; Batch: 2.1223 sec
0.1536 0.1489 0.1288 0.1157 0.1028 0.0930 0.0889 0.0861 0.0846 0.0834 0.0825 0.0806 0.0799 0.0793 0.0790 0.0787 

[TRAIN] Epoch[1](12946/114412); Loss: 0.093197; Backpropagation: 0.2908 sec; Batch: 2.0778 sec
0.1923 0.1849 0.1505 0.1253 0.1055 0.0877 0.0757 0.0713 0.0673 0.0650 0.0634 0.0624 0.0612 0.0602 0.0595 0.0590 

[TRAIN] Epoch[1](12947/114412); Loss: 0.071498; Backpropagation: 0.2951 sec; Batch: 2.1240 sec
0.1194 0.1147 0.0940 0.0810 0.0731 0.0707 0.0665 0.0639 0.0608 0.0596 0.0586 0.0577 0.0576 0.0561 0.0553 0.0551 

[TRAIN] Epoch[1](12948/114412); Loss: 0.103964; Backpropagation: 0.2928 sec; Batch: 2.1279 sec
0.1892 0.1805 0.1547 0.1339 0.1160 0.1059 0.0997 0.0898 0.0860 0.0829 0.0764 0.0741 0.0725 0.0685 0.0672 0.0662 

[TRAIN] Epoch[1](12949/114412); Loss: 0.067973; Backpropagation: 0.2932 sec; Batch: 2.1172 sec
0.1457 0.1399 0.1003 0.0822 0.0685 0.0648 0.0605 0.0556 0.0529 0.0495 0.0479 0.0462 0.0448 0.0437 0.0427 0.0424 

[TRAIN] Epoch[1](12950/114412); Loss: 0.080680; Backpropagation: 0.2913 sec; Batch: 2.1193 sec
0.1471 0.1400 0.1087 0.0891 0.0816 0.0736 0.0716 0.0693 0.0669 0.0654 0.0645 0.0636 0.0630 0.0625 0.0621 0.0618 

[TRAIN] Epoch[1](12951/114412); Loss: 0.076174; Backpropagation: 0.2909 sec; Batch: 2.1204 sec
0.1377 0.1289 0.1024 0.0908 0.0818 0.0732 0.0688 0.0656 0.0633 0.0614 0.0598 0.0585 0.0577 0.0570 0.0563 0.0557 

[TRAIN] Epoch[1](12952/114412); Loss: 0.074470; Backpropagation: 0.2914 sec; Batch: 2.1102 sec
0.1605 0.1463 0.0999 0.0742 0.0697 0.0671 0.0642 0.0615 0.0592 0.0583 0.0569 0.0563 0.0551 0.0546 0.0539 0.0536 

[TRAIN] Epoch[1](12953/114412); Loss: 0.056117; Backpropagation: 0.2918 sec; Batch: 2.1086 sec
0.1039 0.1043 0.0829 0.0722 0.0590 0.0529 0.0504 0.0471 0.0443 0.0424 0.0414 0.0408 0.0398 0.0391 0.0389 0.0385 

[TRAIN] Epoch[1](12954/114412); Loss: 0.082555; Backpropagation: 0.2911 sec; Batch: 2.1150 sec
0.1520 0.1390 0.1116 0.0966 0.0886 0.0808 0.0754 0.0716 0.0683 0.0662 0.0649 0.0634 0.0621 0.0608 0.0600 0.0594 

[TRAIN] Epoch[1](12955/114412); Loss: 0.087425; Backpropagation: 0.2952 sec; Batch: 2.0827 sec
0.1346 0.1260 0.1075 0.0948 0.0889 0.0851 0.0828 0.0806 0.0788 0.0773 0.0756 0.0745 0.0740 0.0734 0.0727 0.0722 

[TRAIN] Epoch[1](12956/114412); Loss: 0.091536; Backpropagation: 0.2928 sec; Batch: 2.1172 sec
0.1463 0.1360 0.1130 0.1040 0.0939 0.0883 0.0856 0.0826 0.0807 0.0793 0.0781 0.0769 0.0762 0.0752 0.0745 0.0739 

[TRAIN] Epoch[1](12957/114412); Loss: 0.086859; Backpropagation: 0.2954 sec; Batch: 2.1235 sec
0.1583 0.1501 0.1208 0.1024 0.0921 0.0855 0.0789 0.0756 0.0727 0.0692 0.0678 0.0659 0.0642 0.0629 0.0621 0.0613 

[TRAIN] Epoch[1](12958/114412); Loss: 0.085213; Backpropagation: 0.2950 sec; Batch: 2.1213 sec
0.1508 0.1474 0.1177 0.0995 0.0891 0.0831 0.0779 0.0749 0.0716 0.0690 0.0668 0.0653 0.0640 0.0630 0.0620 0.0612 

[TRAIN] Epoch[1](12959/114412); Loss: 0.079807; Backpropagation: 0.2913 sec; Batch: 2.1131 sec
0.1525 0.1385 0.1132 0.0941 0.0837 0.0744 0.0714 0.0672 0.0649 0.0632 0.0617 0.0603 0.0591 0.0583 0.0575 0.0570 

[TRAIN] Epoch[1](12960/114412); Loss: 0.102415; Backpropagation: 0.2910 sec; Batch: 2.1135 sec
0.1683 0.1601 0.1344 0.1144 0.1031 0.0994 0.0939 0.0905 0.0876 0.0863 0.0854 0.0840 0.0833 0.0829 0.0826 0.0823 

[TRAIN] Epoch[1](12961/114412); Loss: 0.074109; Backpropagation: 0.2912 sec; Batch: 2.1133 sec
0.1350 0.1247 0.0981 0.0857 0.0776 0.0719 0.0667 0.0641 0.0619 0.0596 0.0584 0.0573 0.0567 0.0563 0.0560 0.0557 

[TRAIN] Epoch[1](12962/114412); Loss: 0.079586; Backpropagation: 0.2912 sec; Batch: 2.1140 sec
0.1350 0.1312 0.0993 0.0913 0.0860 0.0793 0.0740 0.0710 0.0670 0.0654 0.0642 0.0635 0.0627 0.0618 0.0611 0.0608 

[TRAIN] Epoch[1](12963/114412); Loss: 0.081394; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.1769 0.1659 0.1148 0.0918 0.0773 0.0697 0.0711 0.0668 0.0634 0.0619 0.0601 0.0584 0.0575 0.0561 0.0558 0.0548 

[TRAIN] Epoch[1](12964/114412); Loss: 0.094535; Backpropagation: 0.2928 sec; Batch: 2.0814 sec
0.1822 0.1705 0.1409 0.1182 0.1068 0.0921 0.0824 0.0775 0.0740 0.0710 0.0689 0.0671 0.0665 0.0657 0.0647 0.0639 

[TRAIN] Epoch[1](12965/114412); Loss: 0.068098; Backpropagation: 0.2913 sec; Batch: 2.1201 sec
0.1186 0.1149 0.0877 0.0783 0.0681 0.0639 0.0610 0.0596 0.0581 0.0570 0.0558 0.0547 0.0539 0.0532 0.0526 0.0522 

[TRAIN] Epoch[1](12966/114412); Loss: 0.076484; Backpropagation: 0.2909 sec; Batch: 2.1056 sec
0.1960 0.1808 0.1465 0.1134 0.0879 0.0695 0.0581 0.0524 0.0484 0.0436 0.0410 0.0392 0.0379 0.0368 0.0362 0.0359 

[TRAIN] Epoch[1](12967/114412); Loss: 0.099506; Backpropagation: 0.2928 sec; Batch: 2.1192 sec
0.1518 0.1440 0.1185 0.1089 0.1027 0.0965 0.0937 0.0910 0.0891 0.0877 0.0865 0.0857 0.0849 0.0842 0.0836 0.0833 

[TRAIN] Epoch[1](12968/114412); Loss: 0.081115; Backpropagation: 0.2912 sec; Batch: 2.1155 sec
0.1618 0.1583 0.1164 0.0975 0.0852 0.0770 0.0726 0.0688 0.0653 0.0623 0.0592 0.0572 0.0555 0.0543 0.0536 0.0530 

[TRAIN] Epoch[1](12969/114412); Loss: 0.074406; Backpropagation: 0.2909 sec; Batch: 2.0772 sec
0.1531 0.1435 0.1075 0.0891 0.0781 0.0685 0.0655 0.0613 0.0575 0.0558 0.0542 0.0530 0.0521 0.0510 0.0503 0.0499 

[TRAIN] Epoch[1](12970/114412); Loss: 0.096254; Backpropagation: 0.2927 sec; Batch: 2.1242 sec
0.1633 0.1517 0.1236 0.1072 0.0987 0.0938 0.0885 0.0851 0.0823 0.0806 0.0796 0.0784 0.0779 0.0772 0.0764 0.0759 

[TRAIN] Epoch[1](12971/114412); Loss: 0.064667; Backpropagation: 0.2933 sec; Batch: 2.1219 sec
0.1166 0.1158 0.0870 0.0735 0.0665 0.0626 0.0587 0.0562 0.0543 0.0523 0.0510 0.0497 0.0482 0.0480 0.0473 0.0468 

[TRAIN] Epoch[1](12972/114412); Loss: 0.067670; Backpropagation: 0.2912 sec; Batch: 2.1626 sec
0.1135 0.1049 0.0832 0.0747 0.0699 0.0655 0.0630 0.0609 0.0592 0.0581 0.0570 0.0559 0.0551 0.0544 0.0539 0.0536 

[TRAIN] Epoch[1](12973/114412); Loss: 0.094668; Backpropagation: 0.2912 sec; Batch: 2.1187 sec
0.1659 0.1539 0.1340 0.1150 0.1040 0.0930 0.0847 0.0811 0.0767 0.0748 0.0735 0.0727 0.0723 0.0715 0.0710 0.0705 

[TRAIN] Epoch[1](12974/114412); Loss: 0.067622; Backpropagation: 0.2928 sec; Batch: 2.0798 sec
0.1289 0.1225 0.0967 0.0802 0.0687 0.0647 0.0615 0.0577 0.0549 0.0533 0.0517 0.0503 0.0488 0.0481 0.0472 0.0466 

[TRAIN] Epoch[1](12975/114412); Loss: 0.092531; Backpropagation: 0.2911 sec; Batch: 2.0777 sec
0.2056 0.1911 0.1466 0.1092 0.0936 0.0815 0.0742 0.0697 0.0675 0.0654 0.0641 0.0634 0.0628 0.0623 0.0620 0.0613 

[TRAIN] Epoch[1](12976/114412); Loss: 0.073808; Backpropagation: 0.2905 sec; Batch: 2.1135 sec
0.1673 0.1609 0.1200 0.0956 0.0751 0.0625 0.0596 0.0560 0.0526 0.0511 0.0495 0.0486 0.0470 0.0455 0.0448 0.0449 

[TRAIN] Epoch[1](12977/114412); Loss: 0.102044; Backpropagation: 0.2909 sec; Batch: 2.1148 sec
0.1829 0.1713 0.1400 0.1147 0.1071 0.0995 0.0933 0.0896 0.0860 0.0825 0.0805 0.0784 0.0775 0.0766 0.0764 0.0765 

[TRAIN] Epoch[1](12978/114412); Loss: 0.092835; Backpropagation: 0.2908 sec; Batch: 2.1174 sec
0.2565 0.2441 0.1923 0.1375 0.1061 0.0822 0.0610 0.0539 0.0497 0.0462 0.0451 0.0438 0.0428 0.0420 0.0412 0.0409 

[TRAIN] Epoch[1](12979/114412); Loss: 0.079552; Backpropagation: 0.2904 sec; Batch: 2.1136 sec
0.1330 0.1244 0.1064 0.0959 0.0858 0.0784 0.0743 0.0712 0.0675 0.0654 0.0640 0.0629 0.0620 0.0612 0.0605 0.0599 

[TRAIN] Epoch[1](12980/114412); Loss: 0.097472; Backpropagation: 0.2909 sec; Batch: 2.1144 sec
0.1798 0.1633 0.1331 0.1156 0.1041 0.0940 0.0966 0.0927 0.0875 0.0818 0.0762 0.0729 0.0698 0.0658 0.0636 0.0626 

[TRAIN] Epoch[1](12981/114412); Loss: 0.067307; Backpropagation: 0.2911 sec; Batch: 2.1133 sec
0.1206 0.1131 0.0973 0.0862 0.0760 0.0689 0.0626 0.0571 0.0546 0.0529 0.0506 0.0492 0.0480 0.0472 0.0465 0.0462 

[TRAIN] Epoch[1](12982/114412); Loss: 0.074366; Backpropagation: 0.2914 sec; Batch: 2.1185 sec
0.1751 0.1525 0.1122 0.0829 0.0722 0.0663 0.0609 0.0578 0.0559 0.0539 0.0527 0.0511 0.0500 0.0494 0.0487 0.0481 

[TRAIN] Epoch[1](12983/114412); Loss: 0.100669; Backpropagation: 0.2911 sec; Batch: 2.1213 sec
0.2071 0.1842 0.1524 0.1233 0.1071 0.0923 0.0837 0.0814 0.0772 0.0754 0.0740 0.0724 0.0711 0.0706 0.0695 0.0688 

[TRAIN] Epoch[1](12984/114412); Loss: 0.101241; Backpropagation: 0.2930 sec; Batch: 2.1260 sec
0.2268 0.2081 0.1635 0.1266 0.1048 0.0946 0.0839 0.0760 0.0734 0.0714 0.0690 0.0663 0.0650 0.0642 0.0635 0.0628 

[TRAIN] Epoch[1](12985/114412); Loss: 0.090506; Backpropagation: 0.2933 sec; Batch: 2.1225 sec
0.1878 0.1701 0.1358 0.1068 0.0953 0.0856 0.0782 0.0745 0.0705 0.0682 0.0659 0.0642 0.0628 0.0615 0.0608 0.0601 

[TRAIN] Epoch[1](12986/114412); Loss: 0.060469; Backpropagation: 0.2954 sec; Batch: 2.1200 sec
0.1270 0.1247 0.0961 0.0758 0.0632 0.0551 0.0497 0.0463 0.0444 0.0434 0.0423 0.0412 0.0403 0.0397 0.0393 0.0391 

[TRAIN] Epoch[1](12987/114412); Loss: 0.076085; Backpropagation: 0.2914 sec; Batch: 2.1142 sec
0.1167 0.1140 0.0933 0.0842 0.0801 0.0752 0.0721 0.0697 0.0679 0.0659 0.0647 0.0640 0.0631 0.0626 0.0621 0.0616 

[TRAIN] Epoch[1](12988/114412); Loss: 0.092557; Backpropagation: 0.2912 sec; Batch: 2.1156 sec
0.1940 0.1812 0.1502 0.1248 0.1030 0.0862 0.0770 0.0736 0.0701 0.0665 0.0634 0.0614 0.0592 0.0580 0.0567 0.0559 

[TRAIN] Epoch[1](12989/114412); Loss: 0.126255; Backpropagation: 0.2931 sec; Batch: 2.1186 sec
0.2347 0.2227 0.1839 0.1477 0.1297 0.1132 0.1103 0.1081 0.1018 0.0990 0.0976 0.0963 0.0948 0.0941 0.0935 0.0926 

[TRAIN] Epoch[1](12990/114412); Loss: 0.097234; Backpropagation: 0.2932 sec; Batch: 2.1160 sec
0.1876 0.1827 0.1493 0.1250 0.1108 0.1012 0.0869 0.0809 0.0765 0.0713 0.0675 0.0655 0.0639 0.0626 0.0622 0.0616 

[TRAIN] Epoch[1](12991/114412); Loss: 0.120455; Backpropagation: 0.2906 sec; Batch: 2.1197 sec
0.2031 0.1945 0.1580 0.1368 0.1225 0.1142 0.1110 0.1074 0.1038 0.1014 0.0994 0.0977 0.0960 0.0946 0.0938 0.0930 

[TRAIN] Epoch[1](12992/114412); Loss: 0.070799; Backpropagation: 0.2928 sec; Batch: 2.0787 sec
0.1275 0.1229 0.0996 0.0838 0.0702 0.0676 0.0631 0.0605 0.0594 0.0571 0.0560 0.0545 0.0535 0.0530 0.0522 0.0517 

[TRAIN] Epoch[1](12993/114412); Loss: 0.064846; Backpropagation: 0.2912 sec; Batch: 2.1275 sec
0.1160 0.1047 0.0832 0.0716 0.0658 0.0611 0.0590 0.0571 0.0552 0.0541 0.0532 0.0523 0.0516 0.0512 0.0507 0.0506 

[TRAIN] Epoch[1](12994/114412); Loss: 0.074275; Backpropagation: 0.2905 sec; Batch: 2.1127 sec
0.1758 0.1719 0.1308 0.1046 0.0879 0.0694 0.0598 0.0565 0.0486 0.0454 0.0428 0.0410 0.0401 0.0389 0.0380 0.0371 

[TRAIN] Epoch[1](12995/114412); Loss: 0.083100; Backpropagation: 0.2905 sec; Batch: 2.1164 sec
0.1785 0.1676 0.1324 0.1086 0.0879 0.0745 0.0667 0.0656 0.0619 0.0593 0.0576 0.0562 0.0550 0.0532 0.0525 0.0519 

[TRAIN] Epoch[1](12996/114412); Loss: 0.093356; Backpropagation: 0.2912 sec; Batch: 2.1119 sec
0.1782 0.1654 0.1389 0.1151 0.0950 0.0884 0.0845 0.0809 0.0766 0.0727 0.0707 0.0681 0.0663 0.0653 0.0642 0.0633 

[TRAIN] Epoch[1](12997/114412); Loss: 0.067539; Backpropagation: 0.2930 sec; Batch: 2.1163 sec
0.1074 0.1008 0.0850 0.0772 0.0707 0.0665 0.0635 0.0609 0.0591 0.0578 0.0572 0.0560 0.0552 0.0547 0.0545 0.0542 

[TRAIN] Epoch[1](12998/114412); Loss: 0.081202; Backpropagation: 0.2912 sec; Batch: 2.1141 sec
0.1380 0.1317 0.1139 0.1011 0.0886 0.0823 0.0775 0.0721 0.0689 0.0658 0.0629 0.0617 0.0601 0.0589 0.0582 0.0575 

[TRAIN] Epoch[1](12999/114412); Loss: 0.063573; Backpropagation: 0.2932 sec; Batch: 2.1237 sec
0.1404 0.1388 0.1044 0.0838 0.0654 0.0549 0.0516 0.0482 0.0454 0.0436 0.0421 0.0412 0.0404 0.0396 0.0390 0.0385 

[TRAIN] Epoch[1](13000/114412); Loss: 0.122043; Backpropagation: 0.2953 sec; Batch: 2.1209 sec
0.2306 0.2213 0.1890 0.1612 0.1393 0.1185 0.1076 0.0998 0.0956 0.0902 0.0872 0.0851 0.0841 0.0825 0.0809 0.0797 

[TRAIN] Epoch[1](13001/114412); Loss: 0.068232; Backpropagation: 0.2928 sec; Batch: 2.0974 sec
0.1107 0.1022 0.0856 0.0792 0.0720 0.0690 0.0647 0.0625 0.0600 0.0582 0.0567 0.0559 0.0547 0.0539 0.0534 0.0530 

[TRAIN] Epoch[1](13002/114412); Loss: 0.091891; Backpropagation: 0.3047 sec; Batch: 2.1325 sec
0.1272 0.1232 0.1071 0.0995 0.0950 0.0913 0.0884 0.0861 0.0844 0.0833 0.0822 0.0812 0.0809 0.0805 0.0801 0.0799 

[TRAIN] Epoch[1](13003/114412); Loss: 0.089379; Backpropagation: 0.2904 sec; Batch: 2.1168 sec
0.1607 0.1533 0.1326 0.1182 0.1017 0.0884 0.0813 0.0764 0.0711 0.0685 0.0670 0.0648 0.0632 0.0620 0.0607 0.0600 

[TRAIN] Epoch[1](13004/114412); Loss: 0.079866; Backpropagation: 0.2913 sec; Batch: 2.1198 sec
0.1465 0.1370 0.1101 0.0971 0.0848 0.0753 0.0723 0.0687 0.0655 0.0635 0.0619 0.0607 0.0599 0.0587 0.0580 0.0578 

[TRAIN] Epoch[1](13005/114412); Loss: 0.073198; Backpropagation: 0.2912 sec; Batch: 2.1292 sec
0.1346 0.1263 0.1038 0.0912 0.0771 0.0684 0.0650 0.0618 0.0593 0.0576 0.0563 0.0551 0.0543 0.0539 0.0534 0.0531 

[TRAIN] Epoch[1](13006/114412); Loss: 0.087214; Backpropagation: 0.2909 sec; Batch: 2.1142 sec
0.1512 0.1460 0.1194 0.1037 0.0938 0.0861 0.0801 0.0763 0.0738 0.0710 0.0690 0.0670 0.0656 0.0649 0.0641 0.0635 

[TRAIN] Epoch[1](13007/114412); Loss: 0.110263; Backpropagation: 0.2908 sec; Batch: 2.1164 sec
0.1959 0.1881 0.1548 0.1328 0.1163 0.1055 0.1000 0.0961 0.0923 0.0883 0.0858 0.0842 0.0828 0.0816 0.0804 0.0794 

[TRAIN] Epoch[1](13008/114412); Loss: 0.065969; Backpropagation: 0.2927 sec; Batch: 2.1195 sec
0.1276 0.1111 0.0886 0.0741 0.0670 0.0617 0.0597 0.0567 0.0547 0.0535 0.0520 0.0509 0.0504 0.0497 0.0491 0.0488 

[TRAIN] Epoch[1](13009/114412); Loss: 0.063369; Backpropagation: 0.2930 sec; Batch: 2.1173 sec
0.1186 0.1103 0.0826 0.0724 0.0649 0.0599 0.0567 0.0541 0.0524 0.0509 0.0501 0.0492 0.0486 0.0481 0.0477 0.0475 

[TRAIN] Epoch[1](13010/114412); Loss: 0.068355; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1112 0.1064 0.0882 0.0798 0.0747 0.0700 0.0639 0.0609 0.0586 0.0576 0.0558 0.0544 0.0539 0.0531 0.0528 0.0524 

[TRAIN] Epoch[1](13011/114412); Loss: 0.074960; Backpropagation: 0.2910 sec; Batch: 2.1200 sec
0.1454 0.1435 0.1099 0.0933 0.0817 0.0718 0.0651 0.0621 0.0589 0.0565 0.0544 0.0531 0.0519 0.0511 0.0505 0.0501 

[TRAIN] Epoch[1](13012/114412); Loss: 0.088864; Backpropagation: 0.2909 sec; Batch: 2.1173 sec
0.1695 0.1599 0.1212 0.0990 0.0875 0.0823 0.0789 0.0766 0.0741 0.0721 0.0697 0.0684 0.0668 0.0661 0.0653 0.0644 

[TRAIN] Epoch[1](13013/114412); Loss: 0.086762; Backpropagation: 0.2911 sec; Batch: 2.1082 sec
0.1509 0.1440 0.1186 0.1004 0.0908 0.0836 0.0789 0.0761 0.0734 0.0714 0.0701 0.0683 0.0666 0.0655 0.0650 0.0644 

[TRAIN] Epoch[1](13014/114412); Loss: 0.090157; Backpropagation: 0.2910 sec; Batch: 2.0795 sec
0.1525 0.1436 0.1208 0.1047 0.0917 0.0825 0.0802 0.0790 0.0770 0.0753 0.0744 0.0733 0.0726 0.0723 0.0716 0.0711 

[TRAIN] Epoch[1](13015/114412); Loss: 0.084014; Backpropagation: 0.2910 sec; Batch: 2.0767 sec
0.1871 0.1761 0.1351 0.1069 0.0839 0.0731 0.0692 0.0632 0.0605 0.0588 0.0574 0.0561 0.0553 0.0545 0.0539 0.0532 

[TRAIN] Epoch[1](13016/114412); Loss: 0.091523; Backpropagation: 0.2907 sec; Batch: 2.1177 sec
0.1840 0.1597 0.1295 0.1095 0.0940 0.0851 0.0793 0.0753 0.0736 0.0714 0.0701 0.0685 0.0670 0.0669 0.0656 0.0649 

[TRAIN] Epoch[1](13017/114412); Loss: 0.081842; Backpropagation: 0.2909 sec; Batch: 2.1136 sec
0.1541 0.1358 0.1113 0.0948 0.0849 0.0770 0.0734 0.0698 0.0678 0.0656 0.0644 0.0636 0.0625 0.0620 0.0614 0.0610 

[TRAIN] Epoch[1](13018/114412); Loss: 0.072600; Backpropagation: 0.2914 sec; Batch: 2.1139 sec
0.1398 0.1357 0.1018 0.0845 0.0758 0.0707 0.0663 0.0620 0.0593 0.0564 0.0549 0.0530 0.0518 0.0507 0.0498 0.0492 

[TRAIN] Epoch[1](13019/114412); Loss: 0.084994; Backpropagation: 0.2938 sec; Batch: 2.1197 sec
0.1551 0.1457 0.1142 0.0971 0.0880 0.0810 0.0770 0.0736 0.0715 0.0697 0.0673 0.0660 0.0647 0.0638 0.0628 0.0624 

[TRAIN] Epoch[1](13020/114412); Loss: 0.078744; Backpropagation: 0.2948 sec; Batch: 2.0813 sec
0.1729 0.1568 0.1187 0.0945 0.0804 0.0725 0.0683 0.0635 0.0598 0.0575 0.0558 0.0543 0.0528 0.0516 0.0507 0.0498 

[TRAIN] Epoch[1](13021/114412); Loss: 0.084210; Backpropagation: 0.2952 sec; Batch: 2.1207 sec
0.1725 0.1577 0.1261 0.0999 0.0846 0.0794 0.0737 0.0691 0.0648 0.0630 0.0616 0.0606 0.0598 0.0588 0.0582 0.0577 

[TRAIN] Epoch[1](13022/114412); Loss: 0.078560; Backpropagation: 0.2931 sec; Batch: 2.1199 sec
0.1297 0.1240 0.1062 0.0877 0.0816 0.0763 0.0726 0.0693 0.0673 0.0658 0.0649 0.0638 0.0633 0.0623 0.0614 0.0607 

[TRAIN] Epoch[1](13023/114412); Loss: 0.101152; Backpropagation: 0.2929 sec; Batch: 2.1169 sec
0.1617 0.1524 0.1324 0.1197 0.1095 0.1017 0.0942 0.0888 0.0864 0.0852 0.0834 0.0821 0.0813 0.0806 0.0798 0.0791 

[TRAIN] Epoch[1](13024/114412); Loss: 0.075552; Backpropagation: 0.2926 sec; Batch: 2.1016 sec
0.1384 0.1280 0.1028 0.0864 0.0780 0.0731 0.0690 0.0661 0.0634 0.0614 0.0601 0.0585 0.0571 0.0562 0.0554 0.0549 

[TRAIN] Epoch[1](13025/114412); Loss: 0.082433; Backpropagation: 0.2907 sec; Batch: 2.1158 sec
0.1917 0.1739 0.1295 0.0934 0.0685 0.0722 0.0652 0.0626 0.0606 0.0597 0.0595 0.0574 0.0566 0.0565 0.0561 0.0557 

[TRAIN] Epoch[1](13026/114412); Loss: 0.080855; Backpropagation: 0.2954 sec; Batch: 2.1014 sec
0.1316 0.1233 0.1032 0.0924 0.0861 0.0810 0.0776 0.0741 0.0712 0.0690 0.0671 0.0658 0.0643 0.0633 0.0622 0.0615 

[TRAIN] Epoch[1](13027/114412); Loss: 0.088634; Backpropagation: 0.2952 sec; Batch: 2.1176 sec
0.1526 0.1421 0.1158 0.1045 0.0963 0.0883 0.0824 0.0787 0.0754 0.0730 0.0713 0.0697 0.0683 0.0673 0.0666 0.0659 

[TRAIN] Epoch[1](13028/114412); Loss: 0.085119; Backpropagation: 0.2925 sec; Batch: 2.0995 sec
0.1336 0.1206 0.1074 0.1030 0.0927 0.0876 0.0828 0.0778 0.0756 0.0735 0.0711 0.0699 0.0685 0.0671 0.0659 0.0647 

[TRAIN] Epoch[1](13029/114412); Loss: 0.072301; Backpropagation: 0.2912 sec; Batch: 2.1143 sec
0.1485 0.1424 0.1099 0.0891 0.0722 0.0647 0.0621 0.0586 0.0555 0.0540 0.0526 0.0510 0.0501 0.0493 0.0487 0.0482 

[TRAIN] Epoch[1](13030/114412); Loss: 0.077460; Backpropagation: 0.2906 sec; Batch: 2.0789 sec
0.1604 0.1526 0.1181 0.0984 0.0818 0.0722 0.0650 0.0625 0.0595 0.0567 0.0549 0.0535 0.0525 0.0513 0.0504 0.0496 

[TRAIN] Epoch[1](13031/114412); Loss: 0.085538; Backpropagation: 0.2915 sec; Batch: 2.1162 sec
0.1380 0.1251 0.1062 0.0958 0.0894 0.0844 0.0807 0.0776 0.0756 0.0739 0.0727 0.0716 0.0704 0.0697 0.0692 0.0686 

[TRAIN] Epoch[1](13032/114412); Loss: 0.089138; Backpropagation: 0.2912 sec; Batch: 2.1162 sec
0.1861 0.1708 0.1286 0.1026 0.0829 0.0785 0.0759 0.0728 0.0705 0.0692 0.0673 0.0657 0.0645 0.0639 0.0636 0.0631 

[TRAIN] Epoch[1](13033/114412); Loss: 0.075486; Backpropagation: 0.2908 sec; Batch: 2.1191 sec
0.1159 0.1089 0.0926 0.0850 0.0804 0.0752 0.0714 0.0688 0.0671 0.0658 0.0645 0.0637 0.0629 0.0621 0.0618 0.0615 

[TRAIN] Epoch[1](13034/114412); Loss: 0.100946; Backpropagation: 0.2915 sec; Batch: 2.1197 sec
0.1619 0.1549 0.1254 0.1125 0.1020 0.0973 0.0942 0.0909 0.0886 0.0870 0.0856 0.0847 0.0835 0.0827 0.0823 0.0818 

[TRAIN] Epoch[1](13035/114412); Loss: 0.059081; Backpropagation: 0.2913 sec; Batch: 2.1139 sec
0.1303 0.1168 0.0887 0.0708 0.0600 0.0552 0.0506 0.0487 0.0452 0.0428 0.0418 0.0405 0.0395 0.0388 0.0381 0.0376 

[TRAIN] Epoch[1](13036/114412); Loss: 0.062956; Backpropagation: 0.2913 sec; Batch: 2.1178 sec
0.1219 0.1097 0.0858 0.0746 0.0660 0.0601 0.0568 0.0536 0.0516 0.0496 0.0484 0.0476 0.0465 0.0457 0.0450 0.0443 

[TRAIN] Epoch[1](13037/114412); Loss: 0.079506; Backpropagation: 0.2912 sec; Batch: 2.1173 sec
0.1586 0.1540 0.1166 0.0978 0.0802 0.0714 0.0684 0.0656 0.0632 0.0613 0.0594 0.0575 0.0558 0.0548 0.0541 0.0533 

[TRAIN] Epoch[1](13038/114412); Loss: 0.089574; Backpropagation: 0.2931 sec; Batch: 2.1184 sec
0.1889 0.1773 0.1422 0.1158 0.0926 0.0849 0.0744 0.0699 0.0683 0.0648 0.0625 0.0610 0.0591 0.0579 0.0571 0.0565 

[TRAIN] Epoch[1](13039/114412); Loss: 0.074874; Backpropagation: 0.2930 sec; Batch: 2.1186 sec
0.1557 0.1444 0.1175 0.0958 0.0833 0.0709 0.0647 0.0607 0.0552 0.0537 0.0523 0.0509 0.0497 0.0486 0.0478 0.0469 

[TRAIN] Epoch[1](13040/114412); Loss: 0.086182; Backpropagation: 0.2928 sec; Batch: 2.1217 sec
0.1485 0.1381 0.1093 0.0978 0.0895 0.0828 0.0792 0.0761 0.0744 0.0734 0.0712 0.0697 0.0684 0.0675 0.0668 0.0661 

[TRAIN] Epoch[1](13041/114412); Loss: 0.069073; Backpropagation: 0.2919 sec; Batch: 2.1201 sec
0.0991 0.0946 0.0883 0.0824 0.0780 0.0717 0.0671 0.0644 0.0625 0.0602 0.0586 0.0576 0.0566 0.0553 0.0545 0.0542 

[TRAIN] Epoch[1](13042/114412); Loss: 0.082832; Backpropagation: 0.2910 sec; Batch: 2.1203 sec
0.1662 0.1595 0.1139 0.0917 0.0754 0.0753 0.0728 0.0684 0.0671 0.0655 0.0643 0.0625 0.0616 0.0607 0.0601 0.0601 

[TRAIN] Epoch[1](13043/114412); Loss: 0.082864; Backpropagation: 0.2906 sec; Batch: 2.1130 sec
0.1565 0.1476 0.1196 0.1002 0.0877 0.0776 0.0729 0.0692 0.0668 0.0646 0.0630 0.0619 0.0607 0.0598 0.0591 0.0586 

[TRAIN] Epoch[1](13044/114412); Loss: 0.087125; Backpropagation: 0.2915 sec; Batch: 2.1142 sec
0.1481 0.1371 0.1123 0.1000 0.0916 0.0850 0.0806 0.0773 0.0746 0.0725 0.0714 0.0700 0.0692 0.0685 0.0681 0.0677 

[TRAIN] Epoch[1](13045/114412); Loss: 0.064138; Backpropagation: 0.2916 sec; Batch: 2.0789 sec
0.1146 0.1062 0.0834 0.0703 0.0660 0.0619 0.0597 0.0571 0.0549 0.0533 0.0519 0.0510 0.0499 0.0493 0.0486 0.0482 

[TRAIN] Epoch[1](13046/114412); Loss: 0.081804; Backpropagation: 0.2913 sec; Batch: 2.1140 sec
0.1500 0.1409 0.1115 0.0932 0.0842 0.0786 0.0754 0.0716 0.0684 0.0660 0.0643 0.0628 0.0617 0.0607 0.0600 0.0595 

[TRAIN] Epoch[1](13047/114412); Loss: 0.102379; Backpropagation: 0.2906 sec; Batch: 2.1145 sec
0.1577 0.1511 0.1266 0.1177 0.1065 0.0998 0.0960 0.0927 0.0909 0.0890 0.0878 0.0868 0.0852 0.0843 0.0833 0.0828 

[TRAIN] Epoch[1](13048/114412); Loss: 0.076231; Backpropagation: 0.2927 sec; Batch: 2.0789 sec
0.1378 0.1265 0.1028 0.0881 0.0794 0.0738 0.0698 0.0662 0.0643 0.0629 0.0607 0.0593 0.0584 0.0573 0.0564 0.0559 

[TRAIN] Epoch[1](13049/114412); Loss: 0.079245; Backpropagation: 0.2930 sec; Batch: 2.1154 sec
0.1559 0.1439 0.1158 0.0939 0.0822 0.0732 0.0684 0.0657 0.0637 0.0613 0.0600 0.0584 0.0574 0.0565 0.0561 0.0556 

[TRAIN] Epoch[1](13050/114412); Loss: 0.092675; Backpropagation: 0.2930 sec; Batch: 2.0784 sec
0.1835 0.1673 0.1312 0.1074 0.0934 0.0880 0.0830 0.0782 0.0744 0.0719 0.0706 0.0689 0.0680 0.0666 0.0656 0.0650 

[TRAIN] Epoch[1](13051/114412); Loss: 0.070955; Backpropagation: 0.2916 sec; Batch: 2.1191 sec
0.1563 0.1400 0.1041 0.0782 0.0672 0.0632 0.0615 0.0581 0.0558 0.0540 0.0524 0.0505 0.0494 0.0485 0.0481 0.0480 

[TRAIN] Epoch[1](13052/114412); Loss: 0.083939; Backpropagation: 0.2952 sec; Batch: 2.0913 sec
0.1667 0.1517 0.1136 0.0930 0.0829 0.0771 0.0739 0.0713 0.0691 0.0667 0.0651 0.0641 0.0634 0.0622 0.0614 0.0610 

[TRAIN] Epoch[1](13053/114412); Loss: 0.085240; Backpropagation: 0.2955 sec; Batch: 2.1165 sec
0.1728 0.1618 0.1242 0.1009 0.0866 0.0805 0.0763 0.0714 0.0686 0.0658 0.0630 0.0608 0.0593 0.0581 0.0573 0.0564 

[TRAIN] Epoch[1](13054/114412); Loss: 0.093247; Backpropagation: 0.2952 sec; Batch: 2.1224 sec
0.1913 0.1798 0.1311 0.1095 0.0965 0.0872 0.0801 0.0759 0.0729 0.0706 0.0686 0.0676 0.0663 0.0655 0.0649 0.0642 

[TRAIN] Epoch[1](13055/114412); Loss: 0.111362; Backpropagation: 0.2931 sec; Batch: 2.1313 sec
0.2062 0.1909 0.1580 0.1354 0.1175 0.1060 0.0983 0.0931 0.0895 0.0873 0.0856 0.0845 0.0834 0.0830 0.0821 0.0811 

[TRAIN] Epoch[1](13056/114412); Loss: 0.079371; Backpropagation: 0.2930 sec; Batch: 2.1183 sec
0.1391 0.1267 0.1056 0.0895 0.0807 0.0750 0.0729 0.0710 0.0680 0.0657 0.0644 0.0634 0.0628 0.0622 0.0615 0.0614 

[TRAIN] Epoch[1](13057/114412); Loss: 0.053758; Backpropagation: 0.2914 sec; Batch: 2.1154 sec
0.1033 0.0870 0.0687 0.0643 0.0566 0.0522 0.0493 0.0473 0.0464 0.0425 0.0417 0.0409 0.0404 0.0402 0.0398 0.0396 

[TRAIN] Epoch[1](13058/114412); Loss: 0.081825; Backpropagation: 0.2928 sec; Batch: 2.1177 sec
0.1766 0.1587 0.1071 0.0835 0.0802 0.0729 0.0673 0.0665 0.0660 0.0645 0.0632 0.0621 0.0611 0.0604 0.0599 0.0593 

[TRAIN] Epoch[1](13059/114412); Loss: 0.083069; Backpropagation: 0.2930 sec; Batch: 2.1338 sec
0.1583 0.1410 0.1141 0.0933 0.0826 0.0788 0.0738 0.0704 0.0679 0.0668 0.0659 0.0648 0.0640 0.0631 0.0624 0.0619 

[TRAIN] Epoch[1](13060/114412); Loss: 0.087232; Backpropagation: 0.2932 sec; Batch: 2.1225 sec
0.1694 0.1542 0.1169 0.1036 0.0946 0.0880 0.0841 0.0771 0.0717 0.0681 0.0651 0.0627 0.0612 0.0606 0.0595 0.0590 

[TRAIN] Epoch[1](13061/114412); Loss: 0.103041; Backpropagation: 0.2915 sec; Batch: 2.0810 sec
0.2088 0.1924 0.1500 0.1204 0.1067 0.0998 0.0924 0.0865 0.0812 0.0779 0.0757 0.0737 0.0721 0.0712 0.0703 0.0696 

[TRAIN] Epoch[1](13062/114412); Loss: 0.075944; Backpropagation: 0.2911 sec; Batch: 2.0786 sec
0.1540 0.1285 0.1039 0.0844 0.0759 0.0698 0.0655 0.0642 0.0623 0.0602 0.0594 0.0585 0.0579 0.0573 0.0568 0.0564 

[TRAIN] Epoch[1](13063/114412); Loss: 0.093390; Backpropagation: 0.2914 sec; Batch: 2.1206 sec
0.1730 0.1584 0.1275 0.1101 0.0967 0.0891 0.0844 0.0813 0.0777 0.0744 0.0727 0.0716 0.0708 0.0695 0.0688 0.0683 

[TRAIN] Epoch[1](13064/114412); Loss: 0.082673; Backpropagation: 0.2953 sec; Batch: 2.0827 sec
0.1643 0.1544 0.1116 0.0915 0.0854 0.0768 0.0708 0.0695 0.0668 0.0653 0.0636 0.0620 0.0611 0.0604 0.0599 0.0593 

[TRAIN] Epoch[1](13065/114412); Loss: 0.074260; Backpropagation: 0.2930 sec; Batch: 2.0965 sec
0.1400 0.1346 0.0935 0.0811 0.0733 0.0689 0.0658 0.0635 0.0616 0.0602 0.0593 0.0582 0.0578 0.0571 0.0566 0.0566 

[TRAIN] Epoch[1](13066/114412); Loss: 0.092798; Backpropagation: 0.2930 sec; Batch: 2.0786 sec
0.1419 0.1330 0.1120 0.1015 0.0952 0.0899 0.0888 0.0862 0.0842 0.0828 0.0809 0.0794 0.0784 0.0774 0.0770 0.0761 

[TRAIN] Epoch[1](13067/114412); Loss: 0.088772; Backpropagation: 0.2931 sec; Batch: 2.1210 sec
0.1812 0.1684 0.1238 0.1001 0.0901 0.0827 0.0763 0.0731 0.0705 0.0683 0.0666 0.0657 0.0646 0.0636 0.0630 0.0623 

[TRAIN] Epoch[1](13068/114412); Loss: 0.092992; Backpropagation: 0.2928 sec; Batch: 2.1173 sec
0.1689 0.1531 0.1220 0.1051 0.0958 0.0886 0.0844 0.0806 0.0788 0.0764 0.0750 0.0738 0.0726 0.0717 0.0709 0.0703 

[TRAIN] Epoch[1](13069/114412); Loss: 0.106485; Backpropagation: 0.2914 sec; Batch: 2.1170 sec
0.2029 0.1823 0.1477 0.1220 0.1096 0.1024 0.0970 0.0919 0.0873 0.0843 0.0824 0.0809 0.0799 0.0785 0.0778 0.0768 

[TRAIN] Epoch[1](13070/114412); Loss: 0.068206; Backpropagation: 0.2910 sec; Batch: 2.1154 sec
0.1503 0.1310 0.0989 0.0812 0.0688 0.0650 0.0600 0.0570 0.0537 0.0514 0.0487 0.0475 0.0457 0.0447 0.0441 0.0434 

[TRAIN] Epoch[1](13071/114412); Loss: 0.078354; Backpropagation: 0.2915 sec; Batch: 2.1158 sec
0.1412 0.1285 0.1113 0.0928 0.0842 0.0768 0.0725 0.0687 0.0654 0.0629 0.0609 0.0595 0.0583 0.0573 0.0569 0.0563 

[TRAIN] Epoch[1](13072/114412); Loss: 0.095937; Backpropagation: 0.2913 sec; Batch: 2.1166 sec
0.2520 0.2251 0.1512 0.1101 0.0802 0.0793 0.0714 0.0652 0.0645 0.0641 0.0638 0.0627 0.0619 0.0616 0.0610 0.0607 

[TRAIN] Epoch[1](13073/114412); Loss: 0.074086; Backpropagation: 0.2912 sec; Batch: 2.1134 sec
0.1404 0.1266 0.1000 0.0863 0.0760 0.0709 0.0659 0.0631 0.0616 0.0594 0.0579 0.0567 0.0560 0.0553 0.0548 0.0544 

[TRAIN] Epoch[1](13074/114412); Loss: 0.086500; Backpropagation: 0.2911 sec; Batch: 2.1177 sec
0.1506 0.1472 0.1020 0.0920 0.0840 0.0807 0.0790 0.0768 0.0754 0.0731 0.0716 0.0713 0.0702 0.0702 0.0702 0.0697 

[TRAIN] Epoch[1](13075/114412); Loss: 0.065968; Backpropagation: 0.2913 sec; Batch: 2.1133 sec
0.1537 0.1368 0.0959 0.0705 0.0618 0.0577 0.0553 0.0530 0.0506 0.0487 0.0473 0.0459 0.0452 0.0445 0.0443 0.0443 

[TRAIN] Epoch[1](13076/114412); Loss: 0.090510; Backpropagation: 0.2911 sec; Batch: 2.1137 sec
0.1761 0.1661 0.1421 0.1226 0.1070 0.0893 0.0797 0.0718 0.0668 0.0637 0.0630 0.0621 0.0606 0.0597 0.0590 0.0584 

[TRAIN] Epoch[1](13077/114412); Loss: 0.070814; Backpropagation: 0.2914 sec; Batch: 2.1186 sec
0.1539 0.1277 0.0890 0.0773 0.0712 0.0639 0.0587 0.0587 0.0587 0.0571 0.0554 0.0530 0.0527 0.0524 0.0518 0.0515 

[TRAIN] Epoch[1](13078/114412); Loss: 0.084989; Backpropagation: 0.2913 sec; Batch: 2.1129 sec
0.1493 0.1330 0.1100 0.0946 0.0867 0.0829 0.0789 0.0768 0.0737 0.0715 0.0694 0.0680 0.0672 0.0663 0.0660 0.0656 

[TRAIN] Epoch[1](13079/114412); Loss: 0.104226; Backpropagation: 0.2913 sec; Batch: 2.1149 sec
0.2048 0.1849 0.1526 0.1223 0.1081 0.0948 0.0912 0.0883 0.0844 0.0811 0.0790 0.0775 0.0761 0.0750 0.0741 0.0733 

[TRAIN] Epoch[1](13080/114412); Loss: 0.094037; Backpropagation: 0.2950 sec; Batch: 2.1242 sec
0.1847 0.1602 0.1271 0.1065 0.0942 0.0873 0.0838 0.0806 0.0781 0.0759 0.0740 0.0727 0.0713 0.0702 0.0692 0.0688 

[TRAIN] Epoch[1](13081/114412); Loss: 0.078052; Backpropagation: 0.2931 sec; Batch: 2.1160 sec
0.1548 0.1392 0.1162 0.0956 0.0856 0.0737 0.0659 0.0643 0.0614 0.0583 0.0581 0.0566 0.0558 0.0548 0.0542 0.0541 

[TRAIN] Epoch[1](13082/114412); Loss: 0.098887; Backpropagation: 0.2907 sec; Batch: 2.1012 sec
0.1934 0.1739 0.1478 0.1171 0.1018 0.0892 0.0855 0.0823 0.0795 0.0774 0.0757 0.0740 0.0726 0.0714 0.0705 0.0700 

[TRAIN] Epoch[1](13083/114412); Loss: 0.067364; Backpropagation: 0.2908 sec; Batch: 2.0760 sec
0.1525 0.1338 0.0924 0.0756 0.0679 0.0615 0.0585 0.0553 0.0526 0.0499 0.0485 0.0472 0.0465 0.0459 0.0452 0.0446 

[TRAIN] Epoch[1](13084/114412); Loss: 0.086831; Backpropagation: 0.2929 sec; Batch: 2.1186 sec
0.1922 0.1645 0.1342 0.1060 0.0910 0.0802 0.0748 0.0709 0.0677 0.0646 0.0618 0.0595 0.0573 0.0560 0.0547 0.0537 

[TRAIN] Epoch[1](13085/114412); Loss: 0.088291; Backpropagation: 0.2928 sec; Batch: 2.1186 sec
0.1383 0.1174 0.1070 0.0960 0.0896 0.0874 0.0845 0.0823 0.0793 0.0783 0.0773 0.0766 0.0756 0.0750 0.0743 0.0739 

[TRAIN] Epoch[1](13086/114412); Loss: 0.078767; Backpropagation: 0.2913 sec; Batch: 2.1156 sec
0.1364 0.1171 0.1044 0.0903 0.0819 0.0777 0.0744 0.0711 0.0684 0.0661 0.0646 0.0636 0.0622 0.0613 0.0606 0.0601 

[TRAIN] Epoch[1](13087/114412); Loss: 0.090681; Backpropagation: 0.2914 sec; Batch: 2.1177 sec
0.1811 0.1602 0.1400 0.1099 0.0937 0.0828 0.0770 0.0755 0.0726 0.0700 0.0678 0.0661 0.0648 0.0641 0.0631 0.0623 

[TRAIN] Epoch[1](13088/114412); Loss: 0.097974; Backpropagation: 0.2928 sec; Batch: 2.1313 sec
0.2108 0.1890 0.1506 0.1180 0.1006 0.0865 0.0809 0.0787 0.0765 0.0744 0.0718 0.0691 0.0675 0.0654 0.0643 0.0635 

[TRAIN] Epoch[1](13089/114412); Loss: 0.079155; Backpropagation: 0.2908 sec; Batch: 2.1144 sec
0.1698 0.1542 0.1245 0.0989 0.0790 0.0678 0.0625 0.0613 0.0591 0.0582 0.0571 0.0565 0.0556 0.0549 0.0538 0.0532 

[TRAIN] Epoch[1](13090/114412); Loss: 0.104086; Backpropagation: 0.2912 sec; Batch: 2.1150 sec
0.1935 0.1735 0.1483 0.1211 0.1057 0.0972 0.0927 0.0896 0.0875 0.0849 0.0826 0.0799 0.0787 0.0776 0.0768 0.0760 

[TRAIN] Epoch[1](13091/114412); Loss: 0.085503; Backpropagation: 0.2912 sec; Batch: 2.1168 sec
0.1486 0.1399 0.1106 0.0969 0.0886 0.0832 0.0776 0.0759 0.0732 0.0711 0.0698 0.0682 0.0672 0.0666 0.0658 0.0651 

[TRAIN] Epoch[1](13092/114412); Loss: 0.103715; Backpropagation: 0.2915 sec; Batch: 2.0773 sec
0.1852 0.1705 0.1473 0.1253 0.1099 0.1012 0.0951 0.0910 0.0870 0.0839 0.0816 0.0795 0.0777 0.0760 0.0747 0.0737 

[TRAIN] Epoch[1](13093/114412); Loss: 0.105318; Backpropagation: 0.2913 sec; Batch: 2.1768 sec
0.1765 0.1558 0.1412 0.1234 0.1112 0.1038 0.0955 0.0925 0.0907 0.0890 0.0876 0.0862 0.0847 0.0834 0.0821 0.0814 

[TRAIN] Epoch[1](13094/114412); Loss: 0.064801; Backpropagation: 0.2909 sec; Batch: 2.1154 sec
0.1263 0.1113 0.0897 0.0729 0.0647 0.0604 0.0588 0.0555 0.0533 0.0515 0.0502 0.0493 0.0489 0.0483 0.0482 0.0475 

[TRAIN] Epoch[1](13095/114412); Loss: 0.086273; Backpropagation: 0.2914 sec; Batch: 2.1142 sec
0.1368 0.1264 0.1063 0.0977 0.0912 0.0873 0.0839 0.0814 0.0776 0.0746 0.0726 0.0713 0.0700 0.0687 0.0677 0.0669 

[TRAIN] Epoch[1](13096/114412); Loss: 0.079953; Backpropagation: 0.2915 sec; Batch: 2.1162 sec
0.1669 0.1396 0.1192 0.0974 0.0816 0.0736 0.0697 0.0671 0.0635 0.0613 0.0591 0.0577 0.0567 0.0559 0.0553 0.0547 

[TRAIN] Epoch[1](13097/114412); Loss: 0.057915; Backpropagation: 0.2926 sec; Batch: 2.1159 sec
0.1151 0.0927 0.0846 0.0715 0.0600 0.0552 0.0511 0.0485 0.0465 0.0450 0.0441 0.0434 0.0430 0.0423 0.0420 0.0418 

[TRAIN] Epoch[1](13098/114412); Loss: 0.110755; Backpropagation: 0.2927 sec; Batch: 2.1168 sec
0.2497 0.2185 0.1808 0.1422 0.1225 0.0999 0.0909 0.0848 0.0795 0.0775 0.0753 0.0740 0.0716 0.0698 0.0680 0.0670 

[TRAIN] Epoch[1](13099/114412); Loss: 0.102804; Backpropagation: 0.2913 sec; Batch: 2.1170 sec
0.2439 0.2191 0.1865 0.1387 0.1105 0.0869 0.0749 0.0719 0.0709 0.0694 0.0669 0.0647 0.0622 0.0604 0.0594 0.0586 

[TRAIN] Epoch[1](13100/114412); Loss: 0.098451; Backpropagation: 0.2910 sec; Batch: 2.1130 sec
0.1744 0.1547 0.1312 0.1147 0.1059 0.0986 0.0895 0.0847 0.0820 0.0801 0.0785 0.0774 0.0765 0.0763 0.0757 0.0752 

[TRAIN] Epoch[1](13101/114412); Loss: 0.070412; Backpropagation: 0.2934 sec; Batch: 2.1315 sec
0.1676 0.1456 0.1048 0.0801 0.0685 0.0642 0.0573 0.0547 0.0538 0.0502 0.0483 0.0478 0.0467 0.0463 0.0458 0.0449 

[TRAIN] Epoch[1](13102/114412); Loss: 0.078499; Backpropagation: 0.2909 sec; Batch: 2.1163 sec
0.1406 0.1252 0.1086 0.0881 0.0810 0.0743 0.0706 0.0681 0.0659 0.0645 0.0632 0.0623 0.0615 0.0611 0.0607 0.0603 

[TRAIN] Epoch[1](13103/114412); Loss: 0.095532; Backpropagation: 0.2906 sec; Batch: 2.1161 sec
0.1789 0.1617 0.1290 0.1079 0.0960 0.0878 0.0844 0.0824 0.0805 0.0785 0.0765 0.0749 0.0739 0.0730 0.0719 0.0712 

[TRAIN] Epoch[1](13104/114412); Loss: 0.103161; Backpropagation: 0.2915 sec; Batch: 2.1186 sec
0.2216 0.2063 0.1686 0.1333 0.1082 0.0937 0.0827 0.0794 0.0772 0.0746 0.0725 0.0697 0.0681 0.0658 0.0649 0.0640 

[TRAIN] Epoch[1](13105/114412); Loss: 0.074701; Backpropagation: 0.2929 sec; Batch: 2.1287 sec
0.1419 0.1293 0.1137 0.0906 0.0787 0.0731 0.0672 0.0639 0.0604 0.0589 0.0566 0.0545 0.0530 0.0519 0.0510 0.0506 

[TRAIN] Epoch[1](13106/114412); Loss: 0.089801; Backpropagation: 0.2912 sec; Batch: 2.1152 sec
0.1757 0.1602 0.1231 0.1019 0.0909 0.0814 0.0789 0.0768 0.0745 0.0717 0.0698 0.0686 0.0671 0.0662 0.0654 0.0648 

[TRAIN] Epoch[1](13107/114412); Loss: 0.098492; Backpropagation: 0.2912 sec; Batch: 2.1176 sec
0.1561 0.1385 0.1275 0.1093 0.1001 0.0945 0.0917 0.0897 0.0881 0.0862 0.0849 0.0834 0.0827 0.0817 0.0811 0.0806 

[TRAIN] Epoch[1](13108/114412); Loss: 0.081532; Backpropagation: 0.2914 sec; Batch: 2.1181 sec
0.1313 0.1176 0.1169 0.1018 0.0883 0.0812 0.0753 0.0732 0.0708 0.0691 0.0675 0.0655 0.0635 0.0618 0.0607 0.0601 

[TRAIN] Epoch[1](13109/114412); Loss: 0.067052; Backpropagation: 0.2911 sec; Batch: 2.0790 sec
0.1173 0.1013 0.0887 0.0780 0.0716 0.0672 0.0624 0.0600 0.0581 0.0562 0.0546 0.0531 0.0522 0.0510 0.0507 0.0504 

[TRAIN] Epoch[1](13110/114412); Loss: 0.104954; Backpropagation: 0.2916 sec; Batch: 2.1211 sec
0.2250 0.2000 0.1821 0.1398 0.1197 0.1018 0.0856 0.0773 0.0754 0.0728 0.0719 0.0694 0.0675 0.0653 0.0637 0.0622 

[TRAIN] Epoch[1](13111/114412); Loss: 0.086474; Backpropagation: 0.2951 sec; Batch: 2.1247 sec
0.1811 0.1573 0.1311 0.1011 0.0892 0.0824 0.0758 0.0706 0.0671 0.0647 0.0635 0.0625 0.0603 0.0595 0.0590 0.0585 

[TRAIN] Epoch[1](13112/114412); Loss: 0.087861; Backpropagation: 0.2933 sec; Batch: 2.1192 sec
0.2015 0.1877 0.1451 0.1008 0.0790 0.0771 0.0695 0.0673 0.0655 0.0631 0.0609 0.0591 0.0579 0.0575 0.0570 0.0567 

