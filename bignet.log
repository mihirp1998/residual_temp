vid count  100
total images: 1500; total batches: 1500
hypernet  1170076544
encoder  0
decoder  0
binarizer  0
Loaded
[TRAIN] Epoch[1](1/1500); Loss: 0.137498; Backpropagation: 0.1834 sec; Batch: 0.6565 sec
0.1752 0.1747 0.1707 0.1507 0.1420 0.1378 0.1293 0.1254 0.1302 0.1244 0.1226 0.1267 0.1223 0.1222 0.1241 0.1217 

[TRAIN] Epoch[1](2/1500); Loss: 0.068881; Backpropagation: 0.0984 sec; Batch: 0.4527 sec
0.1027 0.0865 0.0716 0.0672 0.0635 0.0651 0.0605 0.0601 0.0624 0.0607 0.0625 0.0687 0.0642 0.0656 0.0695 0.0712 

[TRAIN] Epoch[1](3/1500); Loss: 0.084751; Backpropagation: 0.0983 sec; Batch: 0.4482 sec
0.1413 0.1189 0.0823 0.0877 0.0836 0.0771 0.0733 0.0764 0.0749 0.0728 0.0745 0.0774 0.0762 0.0777 0.0815 0.0807 

[TRAIN] Epoch[1](4/1500); Loss: 0.141216; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1732 0.1685 0.1583 0.1438 0.1401 0.1379 0.1347 0.1334 0.1345 0.1325 0.1329 0.1337 0.1333 0.1346 0.1338 0.1344 

[TRAIN] Epoch[1](5/1500); Loss: 0.070275; Backpropagation: 0.0985 sec; Batch: 0.4357 sec
0.0855 0.0723 0.0806 0.0648 0.0654 0.0632 0.0650 0.0645 0.0667 0.0681 0.0669 0.0700 0.0716 0.0705 0.0734 0.0759 

[TRAIN] Epoch[1](6/1500); Loss: 0.191377; Backpropagation: 0.0990 sec; Batch: 0.4333 sec
0.2246 0.2104 0.1961 0.1964 0.1955 0.1879 0.1886 0.1884 0.1856 0.1859 0.1849 0.1849 0.1838 0.1832 0.1826 0.1832 

[TRAIN] Epoch[1](7/1500); Loss: 0.063879; Backpropagation: 0.0984 sec; Batch: 0.4509 sec
0.0875 0.0752 0.0729 0.0704 0.0718 0.0613 0.0589 0.0613 0.0589 0.0558 0.0551 0.0596 0.0577 0.0562 0.0558 0.0637 

[TRAIN] Epoch[1](8/1500); Loss: 0.087053; Backpropagation: 0.0984 sec; Batch: 0.4377 sec
0.2072 0.1637 0.1192 0.0823 0.0666 0.0719 0.0699 0.0668 0.0650 0.0667 0.0651 0.0693 0.0677 0.0691 0.0683 0.0741 

[TRAIN] Epoch[1](9/1500); Loss: 0.089332; Backpropagation: 0.0994 sec; Batch: 0.4346 sec
0.1626 0.1282 0.1066 0.0886 0.0816 0.0786 0.0777 0.0774 0.0762 0.0760 0.0772 0.0783 0.0787 0.0789 0.0806 0.0824 

[TRAIN] Epoch[1](10/1500); Loss: 0.128289; Backpropagation: 0.0990 sec; Batch: 0.4343 sec
0.1795 0.1678 0.1360 0.1290 0.1289 0.1247 0.1214 0.1194 0.1188 0.1183 0.1180 0.1176 0.1178 0.1178 0.1186 0.1191 

[TRAIN] Epoch[1](11/1500); Loss: 0.068800; Backpropagation: 0.0991 sec; Batch: 0.4405 sec
0.2195 0.1589 0.0936 0.0374 0.0529 0.0673 0.0609 0.0443 0.0380 0.0420 0.0507 0.0485 0.0440 0.0451 0.0477 0.0501 

[TRAIN] Epoch[1](12/1500); Loss: 0.113292; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1432 0.1294 0.1272 0.1192 0.1131 0.1114 0.1106 0.1090 0.1080 0.1077 0.1070 0.1062 0.1055 0.1053 0.1049 0.1051 

[TRAIN] Epoch[1](13/1500); Loss: 0.044132; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1818 0.1098 0.0365 0.0552 0.0271 0.0206 0.0204 0.0298 0.0261 0.0256 0.0253 0.0258 0.0280 0.0290 0.0299 0.0352 

[TRAIN] Epoch[1](14/1500); Loss: 0.130575; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1541 0.1429 0.1340 0.1314 0.1293 0.1267 0.1260 0.1263 0.1256 0.1255 0.1262 0.1271 0.1277 0.1280 0.1286 0.1297 

[TRAIN] Epoch[1](15/1500); Loss: 0.077245; Backpropagation: 0.1003 sec; Batch: 0.4359 sec
0.1214 0.1134 0.0861 0.0778 0.0775 0.0740 0.0714 0.0709 0.0688 0.0677 0.0672 0.0678 0.0675 0.0677 0.0679 0.0688 

[TRAIN] Epoch[1](16/1500); Loss: 0.095473; Backpropagation: 0.0997 sec; Batch: 0.4345 sec
0.1489 0.1413 0.1073 0.0918 0.0907 0.0882 0.0864 0.0858 0.0863 0.0856 0.0851 0.0848 0.0857 0.0861 0.0867 0.0868 

[TRAIN] Epoch[1](17/1500); Loss: 0.084943; Backpropagation: 0.1009 sec; Batch: 0.4362 sec
0.1415 0.1221 0.0973 0.0874 0.0851 0.0829 0.0792 0.0765 0.0746 0.0741 0.0737 0.0727 0.0728 0.0726 0.0730 0.0734 

[TRAIN] Epoch[1](18/1500); Loss: 0.117229; Backpropagation: 0.0989 sec; Batch: 0.4354 sec
0.1455 0.1351 0.1183 0.1176 0.1156 0.1139 0.1127 0.1122 0.1125 0.1129 0.1134 0.1137 0.1131 0.1131 0.1130 0.1131 

[TRAIN] Epoch[1](19/1500); Loss: 0.128436; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.2240 0.1842 0.1471 0.1325 0.1278 0.1235 0.1190 0.1164 0.1142 0.1124 0.1108 0.1097 0.1089 0.1084 0.1080 0.1080 

[TRAIN] Epoch[1](20/1500); Loss: 0.128089; Backpropagation: 0.0985 sec; Batch: 0.4482 sec
0.1754 0.1554 0.1458 0.1332 0.1289 0.1251 0.1217 0.1195 0.1182 0.1173 0.1174 0.1176 0.1179 0.1180 0.1187 0.1192 

[TRAIN] Epoch[1](21/1500); Loss: 0.077528; Backpropagation: 0.1008 sec; Batch: 0.4361 sec
0.1382 0.1215 0.0916 0.0805 0.0737 0.0715 0.0693 0.0680 0.0678 0.0664 0.0651 0.0644 0.0648 0.0654 0.0659 0.0663 

[TRAIN] Epoch[1](22/1500); Loss: 0.114398; Backpropagation: 0.0994 sec; Batch: 0.4346 sec
0.1984 0.1527 0.1231 0.1168 0.1120 0.1089 0.1053 0.1037 0.1031 0.1018 0.1006 0.1002 0.1005 0.1006 0.1012 0.1014 

[TRAIN] Epoch[1](23/1500); Loss: 0.120297; Backpropagation: 0.0993 sec; Batch: 0.4344 sec
0.1769 0.1504 0.1333 0.1253 0.1210 0.1177 0.1152 0.1129 0.1115 0.1103 0.1091 0.1087 0.1084 0.1082 0.1083 0.1076 

[TRAIN] Epoch[1](24/1500); Loss: 0.122707; Backpropagation: 0.0991 sec; Batch: 0.4343 sec
0.2661 0.2530 0.2329 0.2080 0.1651 0.1281 0.0954 0.0734 0.0661 0.0722 0.0719 0.0679 0.0651 0.0662 0.0662 0.0658 

[TRAIN] Epoch[1](25/1500); Loss: 0.042458; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.1130 0.0679 0.0503 0.0390 0.0422 0.0386 0.0337 0.0315 0.0290 0.0328 0.0331 0.0308 0.0319 0.0344 0.0354 0.0356 

[TRAIN] Epoch[1](26/1500); Loss: 0.108643; Backpropagation: 0.0992 sec; Batch: 0.4373 sec
0.1593 0.1495 0.1194 0.1081 0.1041 0.1041 0.1045 0.1029 0.1004 0.0988 0.0979 0.0973 0.0978 0.0982 0.0982 0.0981 

[TRAIN] Epoch[1](27/1500); Loss: 0.113353; Backpropagation: 0.0998 sec; Batch: 0.4342 sec
0.2320 0.2112 0.1806 0.1503 0.1083 0.0895 0.0886 0.0897 0.0866 0.0836 0.0820 0.0818 0.0821 0.0826 0.0823 0.0824 

[TRAIN] Epoch[1](28/1500); Loss: 0.095212; Backpropagation: 0.0994 sec; Batch: 0.4347 sec
0.1551 0.1398 0.0951 0.0862 0.0863 0.0891 0.0898 0.0886 0.0874 0.0868 0.0863 0.0858 0.0862 0.0866 0.0868 0.0874 

[TRAIN] Epoch[1](29/1500); Loss: 0.053835; Backpropagation: 0.0993 sec; Batch: 0.4391 sec
0.1063 0.0908 0.0611 0.0598 0.0512 0.0483 0.0485 0.0472 0.0451 0.0435 0.0428 0.0424 0.0427 0.0430 0.0437 0.0448 

[TRAIN] Epoch[1](30/1500); Loss: 0.055761; Backpropagation: 0.0992 sec; Batch: 0.4345 sec
0.0632 0.0561 0.0531 0.0584 0.0543 0.0517 0.0558 0.0575 0.0549 0.0533 0.0532 0.0536 0.0545 0.0556 0.0579 0.0590 

[TRAIN] Epoch[1](31/1500); Loss: 0.044449; Backpropagation: 0.0992 sec; Batch: 0.4357 sec
0.0476 0.0519 0.0520 0.0392 0.0378 0.0554 0.0568 0.0482 0.0423 0.0392 0.0375 0.0372 0.0376 0.0404 0.0440 0.0441 

[TRAIN] Epoch[1](32/1500); Loss: 0.081176; Backpropagation: 0.0994 sec; Batch: 0.4340 sec
0.1398 0.1156 0.0925 0.0859 0.0831 0.0789 0.0752 0.0725 0.0703 0.0694 0.0692 0.0693 0.0693 0.0693 0.0692 0.0693 

[TRAIN] Epoch[1](33/1500); Loss: 0.063051; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.0979 0.0939 0.0711 0.0613 0.0579 0.0557 0.0546 0.0544 0.0551 0.0559 0.0566 0.0575 0.0585 0.0593 0.0593 0.0597 

[TRAIN] Epoch[1](34/1500); Loss: 0.074052; Backpropagation: 0.0990 sec; Batch: 0.4334 sec
0.0943 0.0790 0.1034 0.0856 0.0719 0.0672 0.0655 0.0654 0.0659 0.0667 0.0679 0.0691 0.0698 0.0699 0.0709 0.0723 

[TRAIN] Epoch[1](35/1500); Loss: 0.101303; Backpropagation: 0.1006 sec; Batch: 0.4354 sec
0.1149 0.1280 0.1240 0.1035 0.0987 0.0944 0.0938 0.0936 0.0943 0.0946 0.0951 0.0958 0.0966 0.0972 0.0978 0.0986 

[TRAIN] Epoch[1](36/1500); Loss: 0.082407; Backpropagation: 0.0993 sec; Batch: 0.4337 sec
0.1035 0.0958 0.0864 0.0863 0.0856 0.0831 0.0817 0.0806 0.0794 0.0783 0.0773 0.0766 0.0760 0.0757 0.0758 0.0762 

[TRAIN] Epoch[1](37/1500); Loss: 0.063354; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.1117 0.0974 0.0732 0.0693 0.0624 0.0565 0.0543 0.0532 0.0530 0.0529 0.0541 0.0542 0.0546 0.0554 0.0556 0.0558 

[TRAIN] Epoch[1](38/1500); Loss: 0.202160; Backpropagation: 0.1031 sec; Batch: 0.4382 sec
0.2594 0.2715 0.2556 0.2301 0.2085 0.1905 0.1839 0.1837 0.1843 0.1816 0.1809 0.1818 0.1820 0.1808 0.1801 0.1799 

[TRAIN] Epoch[1](39/1500); Loss: 0.042488; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.0378 0.0673 0.0570 0.0491 0.0570 0.0398 0.0354 0.0375 0.0381 0.0364 0.0363 0.0368 0.0370 0.0373 0.0384 0.0385 

[TRAIN] Epoch[1](40/1500); Loss: 0.099293; Backpropagation: 0.0994 sec; Batch: 0.4349 sec
0.1544 0.1311 0.1106 0.1020 0.0978 0.0951 0.0936 0.0918 0.0906 0.0902 0.0892 0.0887 0.0885 0.0887 0.0878 0.0885 

[TRAIN] Epoch[1](41/1500); Loss: 0.154510; Backpropagation: 0.0992 sec; Batch: 0.4345 sec
0.2136 0.2071 0.1915 0.1772 0.1635 0.1522 0.1436 0.1385 0.1373 0.1367 0.1365 0.1356 0.1348 0.1348 0.1347 0.1347 

[TRAIN] Epoch[1](42/1500); Loss: 0.111974; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1794 0.1466 0.1211 0.1102 0.1075 0.1056 0.1042 0.1030 0.1023 0.1020 0.1014 0.1012 0.1012 0.1013 0.1022 0.1023 

[TRAIN] Epoch[1](43/1500); Loss: 0.091413; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.1261 0.1383 0.1145 0.0964 0.0887 0.0838 0.0818 0.0806 0.0800 0.0801 0.0798 0.0806 0.0815 0.0823 0.0835 0.0846 

[TRAIN] Epoch[1](44/1500); Loss: 0.079311; Backpropagation: 0.1026 sec; Batch: 0.4374 sec
0.1265 0.1085 0.0844 0.0809 0.0768 0.0750 0.0736 0.0730 0.0721 0.0716 0.0712 0.0710 0.0707 0.0708 0.0713 0.0716 

[TRAIN] Epoch[1](45/1500); Loss: 0.163989; Backpropagation: 0.1029 sec; Batch: 0.4379 sec
0.4020 0.4180 0.3647 0.3104 0.2464 0.1851 0.1293 0.0770 0.0540 0.0730 0.0628 0.0598 0.0603 0.0611 0.0602 0.0597 

[TRAIN] Epoch[1](46/1500); Loss: 0.116062; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.1501 0.1390 0.1284 0.1222 0.1191 0.1167 0.1144 0.1122 0.1105 0.1091 0.1078 0.1068 0.1058 0.1053 0.1049 0.1046 

[TRAIN] Epoch[1](47/1500); Loss: 0.165432; Backpropagation: 0.0993 sec; Batch: 0.4343 sec
0.2563 0.2350 0.2071 0.1902 0.1813 0.1722 0.1639 0.1577 0.1521 0.1469 0.1423 0.1376 0.1330 0.1284 0.1238 0.1193 

[TRAIN] Epoch[1](48/1500); Loss: 0.145098; Backpropagation: 0.1017 sec; Batch: 0.4430 sec
0.2224 0.2104 0.1888 0.1700 0.1500 0.1347 0.1285 0.1272 0.1258 0.1246 0.1238 0.1233 0.1230 0.1232 0.1230 0.1228 

[TRAIN] Epoch[1](49/1500); Loss: 0.107038; Backpropagation: 0.0993 sec; Batch: 0.4342 sec
0.1481 0.1305 0.1157 0.1096 0.1065 0.1046 0.1031 0.1018 0.1010 0.1002 0.0995 0.0989 0.0986 0.0982 0.0981 0.0982 

[TRAIN] Epoch[1](50/1500); Loss: 0.065798; Backpropagation: 0.0990 sec; Batch: 0.4347 sec
0.1542 0.1328 0.0869 0.0536 0.0634 0.0518 0.0494 0.0474 0.0533 0.0516 0.0497 0.0500 0.0506 0.0515 0.0528 0.0535 

[TRAIN] Epoch[1](51/1500); Loss: 0.122584; Backpropagation: 0.0985 sec; Batch: 0.4371 sec
0.1718 0.1539 0.1369 0.1264 0.1221 0.1195 0.1168 0.1148 0.1140 0.1131 0.1129 0.1124 0.1118 0.1117 0.1116 0.1117 

[TRAIN] Epoch[1](52/1500); Loss: 0.106560; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.1794 0.1567 0.1249 0.1016 0.0966 0.0943 0.0945 0.0944 0.0947 0.0943 0.0957 0.0964 0.0948 0.0946 0.0950 0.0971 

[TRAIN] Epoch[1](53/1500); Loss: 0.095878; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1325 0.1204 0.1045 0.0984 0.0963 0.0948 0.0932 0.0914 0.0901 0.0887 0.0874 0.0874 0.0870 0.0869 0.0869 0.0881 

[TRAIN] Epoch[1](54/1500); Loss: 0.086342; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1643 0.1422 0.1178 0.0908 0.0733 0.0758 0.0726 0.0715 0.0719 0.0736 0.0716 0.0702 0.0709 0.0706 0.0714 0.0728 

[TRAIN] Epoch[1](55/1500); Loss: 0.038913; Backpropagation: 0.0993 sec; Batch: 0.4349 sec
0.0618 0.0505 0.0489 0.0378 0.0373 0.0339 0.0369 0.0340 0.0341 0.0331 0.0335 0.0337 0.0358 0.0357 0.0368 0.0389 

[TRAIN] Epoch[1](56/1500); Loss: 0.085059; Backpropagation: 0.0992 sec; Batch: 0.4411 sec
0.1747 0.1449 0.1162 0.0938 0.0812 0.0742 0.0711 0.0685 0.0670 0.0663 0.0678 0.0658 0.0672 0.0668 0.0678 0.0676 

[TRAIN] Epoch[1](57/1500); Loss: 0.140284; Backpropagation: 0.0985 sec; Batch: 0.4381 sec
0.1998 0.1741 0.1518 0.1450 0.1488 0.1476 0.1407 0.1342 0.1288 0.1263 0.1247 0.1241 0.1227 0.1249 0.1244 0.1267 

[TRAIN] Epoch[1](58/1500); Loss: 0.073930; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.0947 0.1065 0.0858 0.0761 0.0690 0.0650 0.0667 0.0666 0.0650 0.0661 0.0668 0.0699 0.0689 0.0700 0.0731 0.0728 

[TRAIN] Epoch[1](59/1500); Loss: 0.096061; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1346 0.1166 0.1087 0.0946 0.0897 0.0888 0.0898 0.0866 0.0883 0.0889 0.0912 0.0903 0.0918 0.0921 0.0924 0.0924 

[TRAIN] Epoch[1](60/1500); Loss: 0.111147; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.1212 0.1161 0.1152 0.1167 0.1167 0.1145 0.1154 0.1137 0.1104 0.1078 0.1070 0.1052 0.1040 0.1041 0.1038 0.1065 

[TRAIN] Epoch[1](61/1500); Loss: 0.132861; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.2050 0.1799 0.1582 0.1522 0.1441 0.1308 0.1226 0.1195 0.1138 0.1146 0.1144 0.1137 0.1151 0.1132 0.1140 0.1146 

[TRAIN] Epoch[1](62/1500); Loss: 0.107699; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.1053 0.1161 0.1367 0.1424 0.1295 0.1158 0.1091 0.1019 0.0972 0.0961 0.0951 0.0946 0.0948 0.0951 0.0954 0.0980 

[TRAIN] Epoch[1](63/1500); Loss: 0.176545; Backpropagation: 0.0991 sec; Batch: 0.4339 sec
0.1980 0.1916 0.1855 0.1879 0.1926 0.1945 0.1901 0.1861 0.1803 0.1717 0.1647 0.1630 0.1574 0.1537 0.1542 0.1534 

[TRAIN] Epoch[1](64/1500); Loss: 0.173225; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1977 0.1876 0.1783 0.1729 0.1726 0.1762 0.1844 0.1902 0.1910 0.1840 0.1752 0.1664 0.1599 0.1517 0.1452 0.1384 

[TRAIN] Epoch[1](65/1500); Loss: 0.178892; Backpropagation: 0.0998 sec; Batch: 0.4348 sec
0.2020 0.2034 0.2040 0.2093 0.2117 0.2096 0.2011 0.1875 0.1795 0.1673 0.1580 0.1550 0.1486 0.1430 0.1430 0.1391 

[TRAIN] Epoch[1](66/1500); Loss: 0.089973; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1870 0.1559 0.1185 0.1127 0.0980 0.0771 0.0669 0.0766 0.0714 0.0627 0.0693 0.0665 0.0647 0.0706 0.0713 0.0703 

[TRAIN] Epoch[1](67/1500); Loss: 0.165393; Backpropagation: 0.1027 sec; Batch: 0.4388 sec
0.1983 0.1847 0.1678 0.1598 0.1721 0.1988 0.2064 0.1921 0.1737 0.1605 0.1502 0.1428 0.1381 0.1370 0.1328 0.1312 

[TRAIN] Epoch[1](68/1500); Loss: 0.083579; Backpropagation: 0.0995 sec; Batch: 0.4347 sec
0.1349 0.1117 0.0913 0.0996 0.0904 0.0777 0.0713 0.0733 0.0727 0.0703 0.0733 0.0727 0.0719 0.0753 0.0764 0.0745 

[TRAIN] Epoch[1](69/1500); Loss: 0.187654; Backpropagation: 0.0991 sec; Batch: 0.4343 sec
0.3154 0.2860 0.2599 0.2659 0.2467 0.2232 0.2058 0.1829 0.1632 0.1457 0.1357 0.1243 0.1159 0.1121 0.1099 0.1098 

[TRAIN] Epoch[1](70/1500); Loss: 0.162068; Backpropagation: 0.0987 sec; Batch: 0.4332 sec
0.2384 0.2200 0.1963 0.1987 0.1883 0.1689 0.1576 0.1510 0.1416 0.1388 0.1366 0.1321 0.1306 0.1327 0.1313 0.1302 

[TRAIN] Epoch[1](71/1500); Loss: 0.095614; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1238 0.1205 0.1183 0.1118 0.1038 0.0980 0.0930 0.0933 0.0884 0.0839 0.0831 0.0824 0.0813 0.0832 0.0826 0.0825 

[TRAIN] Epoch[1](72/1500); Loss: 0.161451; Backpropagation: 0.0996 sec; Batch: 0.4351 sec
0.3892 0.3599 0.3003 0.2338 0.1747 0.1151 0.0760 0.0896 0.1232 0.1302 0.1112 0.0980 0.0947 0.0975 0.0925 0.0974 

[TRAIN] Epoch[1](73/1500); Loss: 0.220663; Backpropagation: 0.1006 sec; Batch: 0.4354 sec
0.4393 0.3677 0.3517 0.3469 0.3090 0.2680 0.2325 0.1994 0.1702 0.1419 0.1208 0.1126 0.1144 0.1209 0.1167 0.1187 

[TRAIN] Epoch[1](74/1500); Loss: 0.223775; Backpropagation: 0.0993 sec; Batch: 0.4343 sec
0.3963 0.3341 0.3129 0.3116 0.2784 0.2431 0.2163 0.1902 0.1715 0.1608 0.1585 0.1600 0.1596 0.1618 0.1628 0.1624 

[TRAIN] Epoch[1](75/1500); Loss: 0.104387; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1997 0.1795 0.1527 0.1294 0.1083 0.0898 0.0829 0.0856 0.0911 0.0875 0.0806 0.0771 0.0757 0.0759 0.0765 0.0779 

[TRAIN] Epoch[1](76/1500); Loss: 0.151357; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2272 0.2123 0.2001 0.1913 0.1762 0.1599 0.1472 0.1378 0.1263 0.1228 0.1206 0.1224 0.1183 0.1200 0.1193 0.1199 

[TRAIN] Epoch[1](77/1500); Loss: 0.097945; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1405 0.1170 0.1038 0.0983 0.0953 0.0947 0.0916 0.0901 0.0902 0.0907 0.0909 0.0913 0.0922 0.0927 0.0938 0.0942 

[TRAIN] Epoch[1](78/1500); Loss: 0.094025; Backpropagation: 0.0984 sec; Batch: 0.4348 sec
0.1458 0.1215 0.1081 0.0991 0.0895 0.0854 0.0852 0.0835 0.0857 0.0857 0.0847 0.0850 0.0858 0.0859 0.0864 0.0871 

[TRAIN] Epoch[1](79/1500); Loss: 0.109144; Backpropagation: 0.0993 sec; Batch: 0.4348 sec
0.1872 0.1600 0.1430 0.1306 0.1095 0.0977 0.0950 0.0921 0.0935 0.0911 0.0897 0.0912 0.0898 0.0921 0.0909 0.0930 

[TRAIN] Epoch[1](80/1500); Loss: 0.081333; Backpropagation: 0.0987 sec; Batch: 0.4339 sec
0.0981 0.0941 0.0859 0.0847 0.0832 0.0793 0.0787 0.0760 0.0757 0.0753 0.0766 0.0760 0.0778 0.0781 0.0805 0.0812 

[TRAIN] Epoch[1](81/1500); Loss: 0.078693; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1205 0.1083 0.0945 0.0829 0.0775 0.0745 0.0718 0.0714 0.0700 0.0686 0.0682 0.0686 0.0691 0.0701 0.0712 0.0718 

[TRAIN] Epoch[1](82/1500); Loss: 0.119440; Backpropagation: 0.1005 sec; Batch: 0.4349 sec
0.2916 0.2349 0.1904 0.1412 0.0892 0.0701 0.0782 0.0776 0.0914 0.0949 0.0889 0.0873 0.0930 0.0946 0.0953 0.0925 

[TRAIN] Epoch[1](83/1500); Loss: 0.112248; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.2653 0.2223 0.1907 0.1581 0.1257 0.0966 0.0807 0.0757 0.0736 0.0739 0.0727 0.0721 0.0720 0.0728 0.0717 0.0721 

[TRAIN] Epoch[1](84/1500); Loss: 0.065787; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.1320 0.1174 0.0935 0.0684 0.0608 0.0590 0.0528 0.0556 0.0514 0.0504 0.0507 0.0507 0.0508 0.0524 0.0524 0.0543 

[TRAIN] Epoch[1](85/1500); Loss: 0.132574; Backpropagation: 0.0996 sec; Batch: 0.4343 sec
0.1929 0.1808 0.1632 0.1475 0.1381 0.1295 0.1232 0.1210 0.1183 0.1172 0.1161 0.1155 0.1148 0.1141 0.1140 0.1148 

[TRAIN] Epoch[1](86/1500); Loss: 0.157528; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.1999 0.1879 0.1721 0.1625 0.1579 0.1541 0.1525 0.1520 0.1493 0.1480 0.1474 0.1473 0.1474 0.1472 0.1471 0.1478 

[TRAIN] Epoch[1](87/1500); Loss: 0.119216; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.1668 0.1576 0.1402 0.1297 0.1222 0.1165 0.1122 0.1094 0.1076 0.1074 0.1061 0.1057 0.1060 0.1062 0.1066 0.1072 

[TRAIN] Epoch[1](88/1500); Loss: 0.078139; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1639 0.1458 0.1136 0.0904 0.0807 0.0723 0.0614 0.0628 0.0593 0.0573 0.0563 0.0567 0.0570 0.0559 0.0578 0.0587 

[TRAIN] Epoch[1](89/1500); Loss: 0.107484; Backpropagation: 0.0989 sec; Batch: 0.4341 sec
0.1938 0.1813 0.1564 0.1343 0.1128 0.1014 0.0956 0.0923 0.0845 0.0835 0.0819 0.0805 0.0805 0.0799 0.0800 0.0810 

[TRAIN] Epoch[1](90/1500); Loss: 0.116998; Backpropagation: 0.0988 sec; Batch: 0.4334 sec
0.1768 0.1528 0.1300 0.1203 0.1134 0.1137 0.1089 0.1080 0.1052 0.1080 0.1047 0.1061 0.1052 0.1063 0.1056 0.1068 

[TRAIN] Epoch[1](91/1500); Loss: 0.123853; Backpropagation: 0.0996 sec; Batch: 0.4344 sec
0.2808 0.2624 0.2179 0.1757 0.1439 0.1157 0.0917 0.0797 0.0792 0.0747 0.0785 0.0758 0.0757 0.0763 0.0761 0.0774 

[TRAIN] Epoch[1](92/1500); Loss: 0.118334; Backpropagation: 0.0990 sec; Batch: 0.4339 sec
0.1683 0.1543 0.1361 0.1250 0.1160 0.1120 0.1089 0.1059 0.1051 0.1058 0.1058 0.1065 0.1083 0.1095 0.1113 0.1146 

[TRAIN] Epoch[1](93/1500); Loss: 0.076184; Backpropagation: 0.0989 sec; Batch: 0.4337 sec
0.1493 0.1279 0.1005 0.0819 0.0680 0.0629 0.0593 0.0616 0.0617 0.0606 0.0602 0.0633 0.0626 0.0652 0.0664 0.0676 

[TRAIN] Epoch[1](94/1500); Loss: 0.064533; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.0871 0.0935 0.0757 0.0705 0.0674 0.0670 0.0592 0.0579 0.0570 0.0557 0.0562 0.0569 0.0559 0.0562 0.0578 0.0583 

[TRAIN] Epoch[1](95/1500); Loss: 0.106370; Backpropagation: 0.0989 sec; Batch: 0.4337 sec
0.1718 0.1551 0.1292 0.1187 0.1102 0.1049 0.1006 0.0974 0.0947 0.0923 0.0901 0.0882 0.0875 0.0866 0.0865 0.0881 

[TRAIN] Epoch[1](96/1500); Loss: 0.136826; Backpropagation: 0.0994 sec; Batch: 0.4347 sec
0.2329 0.2163 0.1842 0.1648 0.1470 0.1308 0.1217 0.1164 0.1130 0.1087 0.1069 0.1067 0.1073 0.1088 0.1107 0.1131 

[TRAIN] Epoch[1](97/1500); Loss: 0.126050; Backpropagation: 0.0993 sec; Batch: 0.4347 sec
0.1546 0.1519 0.1306 0.1298 0.1227 0.1225 0.1219 0.1207 0.1191 0.1186 0.1186 0.1187 0.1206 0.1210 0.1221 0.1233 

[TRAIN] Epoch[1](98/1500); Loss: 0.110497; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1725 0.1313 0.1409 0.1217 0.1158 0.1125 0.1032 0.1016 0.0958 0.0934 0.0936 0.0924 0.0949 0.0952 0.0991 0.1040 

[TRAIN] Epoch[1](99/1500); Loss: 0.126622; Backpropagation: 0.0994 sec; Batch: 0.4677 sec
0.2673 0.2493 0.2050 0.1702 0.1445 0.1237 0.1096 0.0991 0.0886 0.0807 0.0803 0.0797 0.0819 0.0818 0.0814 0.0828 

[TRAIN] Epoch[1](100/1500); Loss: 0.128903; Backpropagation: 0.0991 sec; Batch: 0.4565 sec
0.2057 0.1906 0.1628 0.1488 0.1336 0.1230 0.1169 0.1153 0.1094 0.1085 0.1071 0.1084 0.1072 0.1065 0.1090 0.1095 

[TRAIN] Epoch[1](101/1500); Loss: 0.107357; Backpropagation: 0.0991 sec; Batch: 0.4464 sec
0.1594 0.1271 0.1173 0.1097 0.1044 0.1020 0.1000 0.0988 0.0982 0.0969 0.0977 0.0981 0.0992 0.1015 0.1028 0.1046 

[TRAIN] Epoch[1](102/1500); Loss: 0.152228; Backpropagation: 0.0989 sec; Batch: 0.4500 sec
0.1799 0.1628 0.1542 0.1491 0.1493 0.1478 0.1470 0.1471 0.1468 0.1466 0.1470 0.1485 0.1491 0.1511 0.1542 0.1550 

[TRAIN] Epoch[1](103/1500); Loss: 0.184605; Backpropagation: 0.0993 sec; Batch: 0.4561 sec
0.2663 0.2668 0.2397 0.2116 0.1894 0.1747 0.1712 0.1686 0.1648 0.1619 0.1595 0.1577 0.1569 0.1551 0.1550 0.1545 

[TRAIN] Epoch[1](104/1500); Loss: 0.051596; Backpropagation: 0.0991 sec; Batch: 0.4613 sec
0.0989 0.0777 0.0580 0.0534 0.0494 0.0487 0.0445 0.0444 0.0418 0.0428 0.0419 0.0421 0.0441 0.0441 0.0464 0.0474 

[TRAIN] Epoch[1](105/1500); Loss: 0.081288; Backpropagation: 0.0994 sec; Batch: 0.4349 sec
0.1168 0.1069 0.0950 0.0879 0.0849 0.0805 0.0783 0.0752 0.0740 0.0729 0.0725 0.0713 0.0715 0.0709 0.0712 0.0708 

[TRAIN] Epoch[1](106/1500); Loss: 0.129143; Backpropagation: 0.0993 sec; Batch: 0.4347 sec
0.1727 0.1564 0.1456 0.1390 0.1339 0.1291 0.1257 0.1247 0.1216 0.1199 0.1182 0.1172 0.1160 0.1160 0.1150 0.1153 

[TRAIN] Epoch[1](107/1500); Loss: 0.178689; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.2161 0.2045 0.1938 0.1874 0.1830 0.1796 0.1772 0.1741 0.1720 0.1702 0.1687 0.1678 0.1671 0.1662 0.1660 0.1655 

[TRAIN] Epoch[1](108/1500); Loss: 0.231733; Backpropagation: 0.0989 sec; Batch: 0.4344 sec
0.2771 0.2676 0.2550 0.2432 0.2369 0.2313 0.2292 0.2258 0.2229 0.2211 0.2191 0.2179 0.2169 0.2154 0.2145 0.2138 

[TRAIN] Epoch[1](109/1500); Loss: 0.207306; Backpropagation: 0.0989 sec; Batch: 0.4352 sec
0.2506 0.2307 0.2254 0.2236 0.2194 0.2156 0.2111 0.2075 0.2036 0.1996 0.1961 0.1928 0.1895 0.1865 0.1837 0.1811 

[TRAIN] Epoch[1](110/1500); Loss: 0.240014; Backpropagation: 0.0992 sec; Batch: 0.4351 sec
0.2799 0.2698 0.2605 0.2539 0.2504 0.2455 0.2423 0.2387 0.2347 0.2323 0.2287 0.2259 0.2229 0.2208 0.2178 0.2161 

[TRAIN] Epoch[1](111/1500); Loss: 0.276541; Backpropagation: 0.0986 sec; Batch: 0.4328 sec
0.3530 0.3638 0.3417 0.3198 0.3016 0.2827 0.2713 0.2625 0.2594 0.2521 0.2478 0.2425 0.2382 0.2335 0.2294 0.2252 

[TRAIN] Epoch[1](112/1500); Loss: 0.185189; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2163 0.2224 0.2116 0.1987 0.1918 0.1839 0.1794 0.1768 0.1761 0.1741 0.1734 0.1729 0.1718 0.1719 0.1709 0.1711 

[TRAIN] Epoch[1](113/1500); Loss: 0.242499; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.3271 0.3224 0.2983 0.2957 0.2801 0.2703 0.2585 0.2468 0.2355 0.2241 0.2128 0.2019 0.1913 0.1811 0.1715 0.1626 

[TRAIN] Epoch[1](114/1500); Loss: 0.183561; Backpropagation: 0.0989 sec; Batch: 0.4337 sec
0.2231 0.2202 0.2086 0.2048 0.1974 0.1924 0.1870 0.1819 0.1769 0.1728 0.1687 0.1656 0.1624 0.1604 0.1579 0.1569 

[TRAIN] Epoch[1](115/1500); Loss: 0.255012; Backpropagation: 0.0992 sec; Batch: 0.4475 sec
0.3154 0.3165 0.2966 0.2950 0.2822 0.2749 0.2656 0.2573 0.2488 0.2408 0.2326 0.2252 0.2176 0.2106 0.2037 0.1975 

[TRAIN] Epoch[1](116/1500); Loss: 0.187670; Backpropagation: 0.0984 sec; Batch: 0.4726 sec
0.2453 0.2446 0.2233 0.2190 0.2063 0.1988 0.1892 0.1821 0.1748 0.1696 0.1639 0.1610 0.1575 0.1568 0.1548 0.1558 

[TRAIN] Epoch[1](117/1500); Loss: 0.120043; Backpropagation: 0.0993 sec; Batch: 0.4350 sec
0.1632 0.1635 0.1455 0.1440 0.1324 0.1261 0.1189 0.1131 0.1081 0.1042 0.1014 0.0997 0.0989 0.0991 0.1003 0.1021 

[TRAIN] Epoch[1](118/1500); Loss: 0.151541; Backpropagation: 0.0995 sec; Batch: 0.4348 sec
0.1905 0.1984 0.1833 0.1686 0.1576 0.1486 0.1447 0.1405 0.1399 0.1373 0.1359 0.1356 0.1347 0.1359 0.1356 0.1374 

[TRAIN] Epoch[1](119/1500); Loss: 0.177415; Backpropagation: 0.1018 sec; Batch: 0.4415 sec
0.2387 0.2587 0.2333 0.2096 0.1933 0.1761 0.1748 0.1646 0.1649 0.1558 0.1549 0.1474 0.1473 0.1417 0.1405 0.1370 

[TRAIN] Epoch[1](120/1500); Loss: 0.186110; Backpropagation: 0.0994 sec; Batch: 0.4360 sec
0.2894 0.3303 0.2861 0.2335 0.1982 0.1681 0.1527 0.1487 0.1487 0.1461 0.1446 0.1451 0.1453 0.1457 0.1473 0.1479 

[TRAIN] Epoch[1](121/1500); Loss: 0.120638; Backpropagation: 0.0986 sec; Batch: 0.4330 sec
0.1630 0.1681 0.1555 0.1509 0.1419 0.1348 0.1274 0.1205 0.1139 0.1076 0.1018 0.0965 0.0920 0.0881 0.0851 0.0830 

[TRAIN] Epoch[1](122/1500); Loss: 0.110358; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1223 0.1242 0.1127 0.1118 0.1057 0.1043 0.1024 0.1033 0.1038 0.1068 0.1071 0.1112 0.1095 0.1146 0.1100 0.1158 

[TRAIN] Epoch[1](123/1500); Loss: 0.158533; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.2080 0.1895 0.1786 0.1751 0.1674 0.1625 0.1544 0.1507 0.1443 0.1431 0.1401 0.1400 0.1405 0.1427 0.1481 0.1515 

[TRAIN] Epoch[1](124/1500); Loss: 0.133484; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.1906 0.1955 0.1804 0.1747 0.1632 0.1539 0.1442 0.1347 0.1256 0.1169 0.1087 0.1011 0.0943 0.0883 0.0836 0.0802 

[TRAIN] Epoch[1](125/1500); Loss: 0.205546; Backpropagation: 0.0996 sec; Batch: 0.4341 sec
0.2945 0.2977 0.2686 0.2577 0.2396 0.2260 0.2134 0.1999 0.1904 0.1790 0.1718 0.1619 0.1571 0.1484 0.1448 0.1380 

[TRAIN] Epoch[1](126/1500); Loss: 0.156045; Backpropagation: 0.1027 sec; Batch: 0.4385 sec
0.1752 0.1676 0.1599 0.1579 0.1531 0.1520 0.1498 0.1505 0.1495 0.1524 0.1505 0.1551 0.1518 0.1573 0.1543 0.1597 

[TRAIN] Epoch[1](127/1500); Loss: 0.137200; Backpropagation: 0.1024 sec; Batch: 0.4441 sec
0.1799 0.1854 0.1718 0.1674 0.1576 0.1506 0.1423 0.1357 0.1285 0.1226 0.1165 0.1126 0.1083 0.1062 0.1044 0.1054 

[TRAIN] Epoch[1](128/1500); Loss: 0.136311; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.1806 0.1805 0.1621 0.1555 0.1433 0.1352 0.1279 0.1230 0.1201 0.1191 0.1197 0.1200 0.1219 0.1225 0.1229 0.1267 

[TRAIN] Epoch[1](129/1500); Loss: 0.198295; Backpropagation: 0.0991 sec; Batch: 0.4344 sec
0.3232 0.3482 0.3171 0.2740 0.2461 0.2105 0.1803 0.1547 0.1615 0.1434 0.1503 0.1347 0.1413 0.1282 0.1347 0.1246 

[TRAIN] Epoch[1](130/1500); Loss: 0.103171; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1326 0.1437 0.1225 0.1105 0.0967 0.0933 0.0848 0.0879 0.0848 0.0930 0.0914 0.1012 0.0970 0.1050 0.0983 0.1080 

[TRAIN] Epoch[1](131/1500); Loss: 0.155115; Backpropagation: 0.1034 sec; Batch: 0.4397 sec
0.2367 0.2497 0.2250 0.2079 0.1885 0.1716 0.1557 0.1427 0.1355 0.1253 0.1188 0.1109 0.1065 0.1023 0.1018 0.1028 

[TRAIN] Epoch[1](132/1500); Loss: 0.104206; Backpropagation: 0.1027 sec; Batch: 0.4376 sec
0.1621 0.1630 0.1445 0.1339 0.1199 0.1081 0.0972 0.0881 0.0809 0.0761 0.0741 0.0751 0.0791 0.0848 0.0896 0.0909 

[TRAIN] Epoch[1](133/1500); Loss: 0.095662; Backpropagation: 0.0990 sec; Batch: 0.4344 sec
0.1863 0.1854 0.1538 0.1373 0.1125 0.0922 0.0721 0.0566 0.0482 0.0484 0.0559 0.0678 0.0774 0.0777 0.0829 0.0760 

[TRAIN] Epoch[1](134/1500); Loss: 0.159056; Backpropagation: 0.0984 sec; Batch: 0.4336 sec
0.2321 0.2522 0.2282 0.1945 0.1766 0.1558 0.1424 0.1292 0.1336 0.1269 0.1320 0.1268 0.1316 0.1271 0.1299 0.1261 

[TRAIN] Epoch[1](135/1500); Loss: 0.076461; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1006 0.0830 0.0771 0.0741 0.0716 0.0724 0.0708 0.0736 0.0714 0.0764 0.0723 0.0781 0.0734 0.0779 0.0733 0.0772 

[TRAIN] Epoch[1](136/1500); Loss: 0.153409; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2111 0.2011 0.1826 0.1745 0.1635 0.1564 0.1470 0.1428 0.1344 0.1351 0.1302 0.1352 0.1331 0.1386 0.1295 0.1396 

[TRAIN] Epoch[1](137/1500); Loss: 0.142416; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.2327 0.2337 0.2055 0.1872 0.1676 0.1507 0.1347 0.1228 0.1128 0.1074 0.1040 0.1037 0.1029 0.1043 0.1047 0.1038 

[TRAIN] Epoch[1](138/1500); Loss: 0.134017; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.2038 0.2240 0.1927 0.1620 0.1471 0.1291 0.1286 0.1173 0.1158 0.1078 0.1074 0.1026 0.1024 0.1005 0.1018 0.1014 

[TRAIN] Epoch[1](139/1500); Loss: 0.082780; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1203 0.1391 0.1119 0.0806 0.0755 0.0703 0.0703 0.0703 0.0706 0.0734 0.0717 0.0745 0.0718 0.0754 0.0730 0.0757 

[TRAIN] Epoch[1](140/1500); Loss: 0.114937; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.1933 0.1732 0.1508 0.1334 0.1180 0.1062 0.0976 0.0946 0.0929 0.0967 0.0954 0.0958 0.0937 0.0981 0.0976 0.1015 

[TRAIN] Epoch[1](141/1500); Loss: 0.129704; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1576 0.1515 0.1406 0.1336 0.1292 0.1271 0.1230 0.1234 0.1211 0.1234 0.1221 0.1251 0.1234 0.1245 0.1238 0.1258 

[TRAIN] Epoch[1](142/1500); Loss: 0.177487; Backpropagation: 0.0985 sec; Batch: 0.4337 sec
0.3557 0.3464 0.3037 0.2730 0.2395 0.2084 0.1785 0.1504 0.1251 0.1049 0.0933 0.0903 0.0906 0.0917 0.0915 0.0966 

[TRAIN] Epoch[1](143/1500); Loss: 0.213667; Backpropagation: 0.0995 sec; Batch: 0.4351 sec
0.4276 0.4178 0.3743 0.3421 0.3068 0.2734 0.2399 0.2067 0.1738 0.1413 0.1119 0.0886 0.0769 0.0748 0.0791 0.0836 

[TRAIN] Epoch[1](144/1500); Loss: 0.161843; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.3749 0.4219 0.3694 0.2822 0.2263 0.1538 0.0914 0.0692 0.0761 0.0662 0.0707 0.0731 0.0726 0.0790 0.0762 0.0866 

[TRAIN] Epoch[1](145/1500); Loss: 0.140678; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.2164 0.2210 0.1957 0.1687 0.1521 0.1382 0.1282 0.1221 0.1164 0.1136 0.1111 0.1114 0.1125 0.1139 0.1138 0.1161 

[TRAIN] Epoch[1](146/1500); Loss: 0.165771; Backpropagation: 0.1003 sec; Batch: 0.4352 sec
0.2063 0.2050 0.1872 0.1698 0.1630 0.1611 0.1571 0.1562 0.1540 0.1556 0.1542 0.1567 0.1549 0.1574 0.1563 0.1577 

[TRAIN] Epoch[1](147/1500); Loss: 0.138341; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.2666 0.2585 0.2216 0.1934 0.1659 0.1425 0.1216 0.1060 0.0979 0.0951 0.0927 0.0919 0.0909 0.0904 0.0894 0.0892 

[TRAIN] Epoch[1](148/1500); Loss: 0.060075; Backpropagation: 0.0982 sec; Batch: 0.4337 sec
0.0890 0.1350 0.0800 0.0490 0.0526 0.0446 0.0456 0.0480 0.0437 0.0541 0.0451 0.0620 0.0488 0.0625 0.0503 0.0509 

[TRAIN] Epoch[1](149/1500); Loss: 0.161284; Backpropagation: 0.0996 sec; Batch: 0.4344 sec
0.3345 0.3587 0.3165 0.2504 0.2056 0.1520 0.1082 0.1033 0.0937 0.0938 0.0896 0.0982 0.0901 0.0967 0.0916 0.0974 

[TRAIN] Epoch[1](150/1500); Loss: 0.153663; Backpropagation: 0.0987 sec; Batch: 0.4341 sec
0.3611 0.3992 0.3474 0.2621 0.2053 0.1369 0.0822 0.0875 0.0717 0.0772 0.0675 0.0780 0.0675 0.0706 0.0725 0.0718 

[TRAIN] Epoch[1](151/1500); Loss: 0.078144; Backpropagation: 0.0988 sec; Batch: 0.4333 sec
0.1027 0.1043 0.0909 0.0833 0.0792 0.0790 0.0718 0.0740 0.0701 0.0719 0.0689 0.0710 0.0703 0.0705 0.0707 0.0716 

[TRAIN] Epoch[1](152/1500); Loss: 0.056474; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.0799 0.0915 0.0725 0.0527 0.0547 0.0496 0.0502 0.0479 0.0485 0.0483 0.0485 0.0499 0.0506 0.0522 0.0524 0.0543 

[TRAIN] Epoch[1](153/1500); Loss: 0.151866; Backpropagation: 0.0990 sec; Batch: 0.4343 sec
0.2811 0.2762 0.2414 0.2127 0.1888 0.1652 0.1456 0.1285 0.1165 0.1088 0.1032 0.0968 0.0923 0.0915 0.0904 0.0908 

[TRAIN] Epoch[1](154/1500); Loss: 0.053844; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.0605 0.0677 0.0577 0.0520 0.0528 0.0496 0.0520 0.0489 0.0507 0.0493 0.0510 0.0517 0.0526 0.0538 0.0554 0.0559 

[TRAIN] Epoch[1](155/1500); Loss: 0.114940; Backpropagation: 0.0993 sec; Batch: 0.4344 sec
0.1788 0.1753 0.1633 0.1374 0.1355 0.1148 0.1103 0.0962 0.0927 0.0880 0.0930 0.0902 0.0903 0.0908 0.0909 0.0916 

[TRAIN] Epoch[1](156/1500); Loss: 0.155568; Backpropagation: 0.0991 sec; Batch: 0.4341 sec
0.2198 0.2246 0.2048 0.1718 0.1528 0.1396 0.1398 0.1391 0.1378 0.1387 0.1364 0.1384 0.1357 0.1379 0.1352 0.1365 

[TRAIN] Epoch[1](157/1500); Loss: 0.137693; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.2092 0.1974 0.1717 0.1556 0.1433 0.1336 0.1267 0.1220 0.1202 0.1207 0.1151 0.1178 0.1160 0.1173 0.1176 0.1189 

[TRAIN] Epoch[1](158/1500); Loss: 0.050324; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.0837 0.1309 0.0719 0.0423 0.0474 0.0383 0.0373 0.0446 0.0353 0.0417 0.0370 0.0353 0.0394 0.0381 0.0390 0.0429 

[TRAIN] Epoch[1](159/1500); Loss: 0.138260; Backpropagation: 0.0985 sec; Batch: 0.4453 sec
0.3591 0.3989 0.3412 0.2503 0.1960 0.1239 0.0643 0.0617 0.0567 0.0534 0.0505 0.0520 0.0526 0.0493 0.0520 0.0502 

[TRAIN] Epoch[1](160/1500); Loss: 0.126478; Backpropagation: 0.0988 sec; Batch: 0.4385 sec
0.1623 0.1670 0.1480 0.1345 0.1299 0.1236 0.1199 0.1167 0.1158 0.1150 0.1145 0.1148 0.1143 0.1155 0.1150 0.1169 

[TRAIN] Epoch[1](161/1500); Loss: 0.239863; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.3074 0.2703 0.2640 0.2516 0.2458 0.2404 0.2358 0.2329 0.2304 0.2286 0.2256 0.2246 0.2224 0.2212 0.2191 0.2178 

[TRAIN] Epoch[1](162/1500); Loss: 0.099799; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1413 0.1369 0.1196 0.1080 0.1017 0.0972 0.0935 0.0900 0.0898 0.0887 0.0893 0.0870 0.0883 0.0877 0.0887 0.0890 

[TRAIN] Epoch[1](163/1500); Loss: 0.118544; Backpropagation: 0.0986 sec; Batch: 0.4504 sec
0.2246 0.2166 0.1715 0.1393 0.1181 0.1053 0.0961 0.0929 0.0945 0.0911 0.0900 0.0902 0.0902 0.0905 0.0926 0.0932 

[TRAIN] Epoch[1](164/1500); Loss: 0.124613; Backpropagation: 0.0983 sec; Batch: 0.4479 sec
0.2114 0.2054 0.1785 0.1590 0.1433 0.1261 0.1155 0.1037 0.0982 0.0930 0.0916 0.0927 0.0923 0.0938 0.0941 0.0954 

[TRAIN] Epoch[1](165/1500); Loss: 0.149296; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.2177 0.2102 0.1918 0.1713 0.1596 0.1476 0.1427 0.1361 0.1315 0.1291 0.1252 0.1255 0.1235 0.1252 0.1246 0.1271 

[TRAIN] Epoch[1](166/1500); Loss: 0.084567; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.1105 0.1056 0.0959 0.0869 0.0833 0.0821 0.0806 0.0789 0.0789 0.0779 0.0781 0.0779 0.0782 0.0787 0.0801 0.0796 

[TRAIN] Epoch[1](167/1500); Loss: 0.124880; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1753 0.1717 0.1558 0.1370 0.1294 0.1244 0.1190 0.1170 0.1136 0.1117 0.1080 0.1078 0.1061 0.1071 0.1069 0.1073 

[TRAIN] Epoch[1](168/1500); Loss: 0.128124; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.1861 0.1647 0.1519 0.1448 0.1405 0.1333 0.1284 0.1225 0.1191 0.1144 0.1118 0.1095 0.1069 0.1067 0.1044 0.1051 

[TRAIN] Epoch[1](169/1500); Loss: 0.060086; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.0989 0.1063 0.0746 0.0546 0.0521 0.0527 0.0511 0.0498 0.0507 0.0507 0.0512 0.0525 0.0527 0.0540 0.0538 0.0556 

[TRAIN] Epoch[1](170/1500); Loss: 0.127836; Backpropagation: 0.0989 sec; Batch: 0.4343 sec
0.1807 0.1559 0.1406 0.1379 0.1273 0.1271 0.1194 0.1171 0.1118 0.1111 0.1125 0.1131 0.1172 0.1195 0.1258 0.1283 

[TRAIN] Epoch[1](171/1500); Loss: 0.156185; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.2084 0.2087 0.1819 0.1562 0.1473 0.1435 0.1410 0.1397 0.1390 0.1396 0.1424 0.1449 0.1492 0.1502 0.1532 0.1538 

[TRAIN] Epoch[1](172/1500); Loss: 0.142678; Backpropagation: 0.0995 sec; Batch: 0.4349 sec
0.1595 0.1627 0.1517 0.1432 0.1421 0.1405 0.1399 0.1375 0.1372 0.1369 0.1368 0.1380 0.1379 0.1373 0.1398 0.1420 

[TRAIN] Epoch[1](173/1500); Loss: 0.062523; Backpropagation: 0.1003 sec; Batch: 0.4354 sec
0.0907 0.1023 0.0764 0.0663 0.0566 0.0595 0.0545 0.0538 0.0547 0.0524 0.0554 0.0531 0.0556 0.0555 0.0566 0.0570 

[TRAIN] Epoch[1](174/1500); Loss: 0.126261; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.1675 0.1760 0.1503 0.1297 0.1214 0.1209 0.1190 0.1192 0.1162 0.1151 0.1145 0.1139 0.1142 0.1137 0.1142 0.1142 

[TRAIN] Epoch[1](175/1500); Loss: 0.093611; Backpropagation: 0.0984 sec; Batch: 0.4338 sec
0.1535 0.1470 0.1293 0.1164 0.1073 0.0966 0.0901 0.0815 0.0791 0.0731 0.0745 0.0710 0.0741 0.0675 0.0715 0.0653 

[TRAIN] Epoch[1](176/1500); Loss: 0.114310; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1644 0.1458 0.1296 0.1204 0.1152 0.1104 0.1090 0.1062 0.1065 0.1050 0.1053 0.1038 0.1034 0.1017 0.1016 0.1006 

[TRAIN] Epoch[1](177/1500); Loss: 0.072521; Backpropagation: 0.0987 sec; Batch: 0.4341 sec
0.1111 0.1227 0.0935 0.0734 0.0647 0.0659 0.0620 0.0630 0.0633 0.0623 0.0622 0.0618 0.0615 0.0627 0.0641 0.0660 

[TRAIN] Epoch[1](178/1500); Loss: 0.142774; Backpropagation: 0.0987 sec; Batch: 0.4342 sec
0.2824 0.2716 0.2336 0.2101 0.1858 0.1633 0.1427 0.1237 0.1067 0.0923 0.0830 0.0800 0.0799 0.0775 0.0768 0.0749 

[TRAIN] Epoch[1](179/1500); Loss: 0.125544; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.2532 0.2723 0.2280 0.1774 0.1460 0.1168 0.0957 0.0924 0.0817 0.0772 0.0768 0.0801 0.0804 0.0781 0.0761 0.0766 

[TRAIN] Epoch[1](180/1500); Loss: 0.138138; Backpropagation: 0.0984 sec; Batch: 0.4339 sec
0.2447 0.2339 0.2030 0.1832 0.1641 0.1468 0.1323 0.1184 0.1083 0.1005 0.0954 0.0955 0.0984 0.0960 0.0963 0.0934 

[TRAIN] Epoch[1](181/1500); Loss: 0.142123; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.1814 0.1716 0.1594 0.1516 0.1479 0.1413 0.1384 0.1334 0.1316 0.1289 0.1290 0.1291 0.1313 0.1313 0.1333 0.1346 

[TRAIN] Epoch[1](182/1500); Loss: 0.069089; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.0962 0.1075 0.0703 0.0738 0.0623 0.0627 0.0592 0.0583 0.0588 0.0590 0.0609 0.0622 0.0640 0.0673 0.0700 0.0733 

[TRAIN] Epoch[1](183/1500); Loss: 0.071459; Backpropagation: 0.0987 sec; Batch: 0.4338 sec
0.1301 0.0991 0.0803 0.0728 0.0709 0.0665 0.0672 0.0633 0.0638 0.0612 0.0621 0.0610 0.0608 0.0611 0.0614 0.0618 

[TRAIN] Epoch[1](184/1500); Loss: 0.087689; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1009 0.0932 0.0795 0.1008 0.0843 0.0815 0.0806 0.0804 0.0820 0.0828 0.0838 0.0861 0.0887 0.0888 0.0929 0.0967 

[TRAIN] Epoch[1](185/1500); Loss: 0.082920; Backpropagation: 0.0983 sec; Batch: 0.4338 sec
0.1820 0.1682 0.1289 0.1045 0.0840 0.0724 0.0677 0.0654 0.0637 0.0599 0.0568 0.0544 0.0551 0.0545 0.0547 0.0544 

[TRAIN] Epoch[1](186/1500); Loss: 0.131013; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.2068 0.2167 0.1844 0.1433 0.1210 0.1150 0.1207 0.1195 0.1143 0.1095 0.1086 0.1085 0.1084 0.1065 0.1065 0.1066 

[TRAIN] Epoch[1](187/1500); Loss: 0.148872; Backpropagation: 0.0986 sec; Batch: 0.4341 sec
0.2198 0.2262 0.2047 0.1845 0.1662 0.1479 0.1343 0.1248 0.1229 0.1263 0.1226 0.1216 0.1200 0.1201 0.1202 0.1197 

[TRAIN] Epoch[1](188/1500); Loss: 0.092427; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1708 0.1613 0.1347 0.1222 0.1064 0.0927 0.0824 0.0737 0.0684 0.0662 0.0656 0.0671 0.0672 0.0667 0.0671 0.0662 

[TRAIN] Epoch[1](189/1500); Loss: 0.124835; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.2843 0.2642 0.2153 0.1847 0.1527 0.1250 0.1014 0.0830 0.0738 0.0742 0.0755 0.0728 0.0719 0.0725 0.0732 0.0730 

[TRAIN] Epoch[1](190/1500); Loss: 0.108092; Backpropagation: 0.1012 sec; Batch: 0.4358 sec
0.2517 0.2367 0.1964 0.1690 0.1415 0.1164 0.0929 0.0736 0.0597 0.0576 0.0598 0.0562 0.0552 0.0535 0.0542 0.0549 

[TRAIN] Epoch[1](191/1500); Loss: 0.072115; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1020 0.1000 0.0869 0.0801 0.0785 0.0720 0.0699 0.0659 0.0653 0.0639 0.0633 0.0620 0.0614 0.0604 0.0608 0.0614 

[TRAIN] Epoch[1](192/1500); Loss: 0.160722; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.2321 0.2385 0.2142 0.1858 0.1682 0.1548 0.1475 0.1467 0.1443 0.1404 0.1364 0.1348 0.1333 0.1321 0.1316 0.1308 

[TRAIN] Epoch[1](193/1500); Loss: 0.167528; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.2299 0.2331 0.2110 0.1932 0.1774 0.1650 0.1555 0.1559 0.1512 0.1465 0.1440 0.1439 0.1432 0.1432 0.1436 0.1436 

[TRAIN] Epoch[1](194/1500); Loss: 0.099479; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1335 0.1202 0.0980 0.0919 0.0894 0.0886 0.0901 0.0904 0.0938 0.0939 0.0984 0.0978 0.1011 0.0990 0.1034 0.1020 

[TRAIN] Epoch[1](195/1500); Loss: 0.108622; Backpropagation: 0.0996 sec; Batch: 0.4350 sec
0.1433 0.1386 0.1281 0.1178 0.1127 0.1084 0.1063 0.1021 0.1020 0.0986 0.0985 0.0970 0.0975 0.0964 0.0959 0.0946 

[TRAIN] Epoch[1](196/1500); Loss: 0.103792; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1324 0.1388 0.1200 0.1062 0.1032 0.1021 0.0990 0.0971 0.0959 0.0949 0.0954 0.0944 0.0948 0.0949 0.0955 0.0961 

[TRAIN] Epoch[1](197/1500); Loss: 0.119984; Backpropagation: 0.0994 sec; Batch: 0.4353 sec
0.2348 0.2181 0.1837 0.1571 0.1348 0.1148 0.0981 0.0853 0.0828 0.0855 0.0887 0.0910 0.0907 0.0867 0.0843 0.0833 

[TRAIN] Epoch[1](198/1500); Loss: 0.102070; Backpropagation: 0.0990 sec; Batch: 0.4346 sec
0.2049 0.1929 0.1557 0.1276 0.1159 0.1039 0.0921 0.0809 0.0752 0.0739 0.0696 0.0698 0.0673 0.0681 0.0672 0.0682 

[TRAIN] Epoch[1](199/1500); Loss: 0.128921; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1789 0.1672 0.1475 0.1319 0.1255 0.1241 0.1246 0.1232 0.1211 0.1190 0.1177 0.1168 0.1166 0.1165 0.1158 0.1164 

[TRAIN] Epoch[1](200/1500); Loss: 0.090726; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1931 0.2036 0.1610 0.1106 0.0872 0.0626 0.0620 0.0693 0.0659 0.0662 0.0611 0.0613 0.0599 0.0623 0.0609 0.0647 

[TRAIN] Epoch[1](201/1500); Loss: 0.116897; Backpropagation: 0.0988 sec; Batch: 0.4344 sec
0.1574 0.1516 0.1350 0.1223 0.1182 0.1153 0.1139 0.1119 0.1100 0.1077 0.1061 0.1045 0.1041 0.1036 0.1041 0.1048 

[TRAIN] Epoch[1](202/1500); Loss: 0.137392; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1906 0.1653 0.1573 0.1456 0.1459 0.1378 0.1379 0.1304 0.1324 0.1254 0.1273 0.1214 0.1236 0.1186 0.1211 0.1178 

[TRAIN] Epoch[1](203/1500); Loss: 0.122994; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.2000 0.1866 0.1584 0.1421 0.1340 0.1242 0.1162 0.1084 0.1049 0.1020 0.1001 0.0973 0.0979 0.0970 0.0988 0.1000 

[TRAIN] Epoch[1](204/1500); Loss: 0.151335; Backpropagation: 0.0984 sec; Batch: 0.4339 sec
0.1936 0.2027 0.1812 0.1665 0.1633 0.1561 0.1518 0.1470 0.1427 0.1391 0.1355 0.1329 0.1302 0.1278 0.1258 0.1252 

[TRAIN] Epoch[1](205/1500); Loss: 0.075853; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.1648 0.1340 0.0914 0.0673 0.0668 0.0699 0.0746 0.0728 0.0682 0.0612 0.0584 0.0554 0.0551 0.0560 0.0585 0.0592 

[TRAIN] Epoch[1](206/1500); Loss: 0.090830; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1366 0.1168 0.0942 0.0852 0.0912 0.0944 0.0960 0.0920 0.0896 0.0839 0.0804 0.0777 0.0775 0.0774 0.0794 0.0810 

[TRAIN] Epoch[1](207/1500); Loss: 0.156154; Backpropagation: 0.0996 sec; Batch: 0.4386 sec
0.1886 0.1995 0.1777 0.1671 0.1653 0.1573 0.1538 0.1488 0.1457 0.1430 0.1422 0.1404 0.1414 0.1411 0.1434 0.1430 

[TRAIN] Epoch[1](208/1500); Loss: 0.085422; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.1158 0.1046 0.1086 0.0939 0.0959 0.0831 0.0820 0.0772 0.0784 0.0740 0.0759 0.0735 0.0756 0.0746 0.0774 0.0763 

[TRAIN] Epoch[1](209/1500); Loss: 0.084707; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.0908 0.0857 0.1024 0.0919 0.0929 0.0862 0.0833 0.0798 0.0784 0.0778 0.0778 0.0788 0.0803 0.0814 0.0833 0.0845 

[TRAIN] Epoch[1](210/1500); Loss: 0.084475; Backpropagation: 0.0991 sec; Batch: 0.4348 sec
0.1009 0.0945 0.0904 0.0872 0.0877 0.0840 0.0812 0.0782 0.0778 0.0793 0.0786 0.0800 0.0805 0.0829 0.0833 0.0851 

[TRAIN] Epoch[1](211/1500); Loss: 0.132649; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1512 0.1594 0.1397 0.1324 0.1312 0.1259 0.1252 0.1248 0.1263 0.1257 0.1279 0.1275 0.1298 0.1299 0.1329 0.1326 

[TRAIN] Epoch[1](212/1500); Loss: 0.091276; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.1004 0.0969 0.0997 0.0939 0.0932 0.0895 0.0897 0.0881 0.0879 0.0868 0.0875 0.0875 0.0884 0.0893 0.0901 0.0917 

[TRAIN] Epoch[1](213/1500); Loss: 0.150468; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.2093 0.1760 0.1605 0.1522 0.1481 0.1459 0.1447 0.1434 0.1427 0.1411 0.1408 0.1404 0.1400 0.1403 0.1406 0.1414 

[TRAIN] Epoch[1](214/1500); Loss: 0.121916; Backpropagation: 0.0986 sec; Batch: 0.4339 sec
0.1709 0.1599 0.1482 0.1313 0.1205 0.1116 0.1116 0.1092 0.1106 0.1085 0.1093 0.1092 0.1104 0.1115 0.1133 0.1145 

[TRAIN] Epoch[1](215/1500); Loss: 0.094944; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1345 0.1615 0.1319 0.1157 0.1165 0.1054 0.1002 0.0904 0.0861 0.0777 0.0735 0.0688 0.0663 0.0639 0.0634 0.0634 

[TRAIN] Epoch[1](216/1500); Loss: 0.071251; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1087 0.1011 0.0780 0.0674 0.0706 0.0650 0.0649 0.0620 0.0624 0.0637 0.0641 0.0645 0.0666 0.0653 0.0664 0.0695 

[TRAIN] Epoch[1](217/1500); Loss: 0.069955; Backpropagation: 0.0999 sec; Batch: 0.4348 sec
0.1132 0.0896 0.0803 0.0706 0.0761 0.0672 0.0658 0.0617 0.0615 0.0600 0.0618 0.0601 0.0628 0.0613 0.0637 0.0635 

[TRAIN] Epoch[1](218/1500); Loss: 0.113922; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.1497 0.1410 0.1306 0.1211 0.1190 0.1113 0.1110 0.1064 0.1070 0.1045 0.1043 0.1035 0.1030 0.1032 0.1030 0.1039 

[TRAIN] Epoch[1](219/1500); Loss: 0.112089; Backpropagation: 0.0992 sec; Batch: 0.4366 sec
0.1805 0.1651 0.1461 0.1252 0.1162 0.1043 0.0985 0.0962 0.0948 0.0946 0.0946 0.0944 0.0945 0.0950 0.0969 0.0965 

[TRAIN] Epoch[1](220/1500); Loss: 0.063890; Backpropagation: 0.0990 sec; Batch: 0.4385 sec
0.1335 0.1103 0.0802 0.0710 0.0614 0.0547 0.0514 0.0500 0.0507 0.0514 0.0509 0.0513 0.0505 0.0516 0.0506 0.0527 

[TRAIN] Epoch[1](221/1500); Loss: 0.158075; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.2119 0.2277 0.1997 0.1806 0.1791 0.1715 0.1644 0.1566 0.1499 0.1437 0.1373 0.1314 0.1254 0.1211 0.1164 0.1125 

[TRAIN] Epoch[1](222/1500); Loss: 0.149598; Backpropagation: 0.0995 sec; Batch: 0.4348 sec
0.1647 0.1569 0.1524 0.1497 0.1490 0.1479 0.1481 0.1479 0.1471 0.1469 0.1468 0.1467 0.1466 0.1471 0.1482 0.1474 

[TRAIN] Epoch[1](223/1500); Loss: 0.153543; Backpropagation: 0.0984 sec; Batch: 0.4365 sec
0.1928 0.1900 0.1768 0.1641 0.1585 0.1507 0.1478 0.1449 0.1439 0.1426 0.1417 0.1418 0.1411 0.1398 0.1398 0.1402 

[TRAIN] Epoch[1](224/1500); Loss: 0.163243; Backpropagation: 0.0989 sec; Batch: 0.4351 sec
0.1978 0.2056 0.1886 0.1792 0.1796 0.1722 0.1676 0.1624 0.1581 0.1544 0.1495 0.1463 0.1426 0.1394 0.1355 0.1330 

[TRAIN] Epoch[1](225/1500); Loss: 0.095726; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1267 0.1463 0.1173 0.1000 0.0965 0.0876 0.0854 0.0847 0.0849 0.0841 0.0868 0.0839 0.0878 0.0847 0.0891 0.0858 

[TRAIN] Epoch[1](226/1500); Loss: 0.072172; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.1147 0.0894 0.0851 0.0757 0.0775 0.0687 0.0673 0.0634 0.0629 0.0610 0.0645 0.0611 0.0660 0.0629 0.0684 0.0662 

[TRAIN] Epoch[1](227/1500); Loss: 0.076067; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.1370 0.1295 0.1155 0.0960 0.0823 0.0695 0.0646 0.0597 0.0598 0.0563 0.0572 0.0564 0.0587 0.0572 0.0591 0.0583 

[TRAIN] Epoch[1](228/1500); Loss: 0.098039; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1847 0.1701 0.1270 0.1032 0.1014 0.0915 0.0928 0.0859 0.0825 0.0800 0.0791 0.0756 0.0761 0.0726 0.0719 0.0740 

[TRAIN] Epoch[1](229/1500); Loss: 0.096115; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1424 0.1290 0.1113 0.0994 0.0988 0.0933 0.0922 0.0892 0.0872 0.0862 0.0851 0.0850 0.0850 0.0844 0.0843 0.0850 

[TRAIN] Epoch[1](230/1500); Loss: 0.138903; Backpropagation: 0.1027 sec; Batch: 0.4373 sec
0.1643 0.1607 0.1496 0.1422 0.1406 0.1380 0.1361 0.1355 0.1334 0.1334 0.1320 0.1322 0.1310 0.1314 0.1307 0.1314 

[TRAIN] Epoch[1](231/1500); Loss: 0.112247; Backpropagation: 0.1002 sec; Batch: 0.4363 sec
0.1638 0.1882 0.1691 0.1448 0.1478 0.1327 0.1222 0.1116 0.1007 0.0909 0.0817 0.0743 0.0681 0.0661 0.0658 0.0682 

[TRAIN] Epoch[1](232/1500); Loss: 0.094400; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1197 0.1313 0.1235 0.1069 0.1049 0.0969 0.0923 0.0891 0.0860 0.0821 0.0821 0.0781 0.0799 0.0780 0.0797 0.0798 

[TRAIN] Epoch[1](233/1500); Loss: 0.106591; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1406 0.1381 0.1216 0.1138 0.1134 0.1078 0.1037 0.1006 0.0981 0.0967 0.0953 0.0956 0.0950 0.0952 0.0950 0.0949 

[TRAIN] Epoch[1](234/1500); Loss: 0.110720; Backpropagation: 0.1004 sec; Batch: 0.4357 sec
0.1313 0.1262 0.1187 0.1123 0.1132 0.1094 0.1082 0.1068 0.1062 0.1064 0.1055 0.1051 0.1061 0.1049 0.1061 0.1050 

[TRAIN] Epoch[1](235/1500); Loss: 0.155963; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1664 0.1720 0.1650 0.1596 0.1583 0.1548 0.1555 0.1535 0.1543 0.1516 0.1525 0.1505 0.1513 0.1493 0.1517 0.1492 

[TRAIN] Epoch[1](236/1500); Loss: 0.104792; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.1428 0.1264 0.1215 0.1112 0.1038 0.0996 0.0971 0.0971 0.0956 0.0968 0.0953 0.0961 0.0967 0.0974 0.0989 0.1003 

[TRAIN] Epoch[1](237/1500); Loss: 0.073002; Backpropagation: 0.0993 sec; Batch: 0.4342 sec
0.0928 0.1056 0.0788 0.0676 0.0654 0.0674 0.0652 0.0639 0.0669 0.0652 0.0687 0.0671 0.0718 0.0713 0.0743 0.0760 

[TRAIN] Epoch[1](238/1500); Loss: 0.072577; Backpropagation: 0.0992 sec; Batch: 0.4343 sec
0.1048 0.1062 0.0891 0.0760 0.0727 0.0678 0.0670 0.0643 0.0633 0.0627 0.0635 0.0627 0.0651 0.0642 0.0660 0.0659 

[TRAIN] Epoch[1](239/1500); Loss: 0.074669; Backpropagation: 0.0991 sec; Batch: 0.4342 sec
0.1340 0.1250 0.0975 0.0782 0.0671 0.0618 0.0604 0.0611 0.0598 0.0610 0.0629 0.0626 0.0638 0.0647 0.0668 0.0679 

[TRAIN] Epoch[1](240/1500); Loss: 0.106361; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.2210 0.2093 0.1714 0.1481 0.1248 0.1003 0.0813 0.0708 0.0683 0.0696 0.0713 0.0703 0.0728 0.0718 0.0758 0.0749 

[TRAIN] Epoch[1](241/1500); Loss: 0.081221; Backpropagation: 0.0989 sec; Batch: 0.4349 sec
0.1193 0.1256 0.1065 0.0891 0.0838 0.0754 0.0719 0.0700 0.0688 0.0689 0.0678 0.0687 0.0693 0.0708 0.0705 0.0731 

[TRAIN] Epoch[1](242/1500); Loss: 0.109251; Backpropagation: 0.1033 sec; Batch: 0.4392 sec
0.1391 0.1268 0.1088 0.1100 0.1018 0.1041 0.0994 0.1037 0.1003 0.1044 0.1021 0.1066 0.1052 0.1100 0.1108 0.1152 

[TRAIN] Epoch[1](243/1500); Loss: 0.103756; Backpropagation: 0.1028 sec; Batch: 0.4376 sec
0.1416 0.1171 0.1083 0.1090 0.1018 0.1032 0.0990 0.0988 0.0954 0.0964 0.0961 0.0969 0.0960 0.0998 0.0980 0.1028 

[TRAIN] Epoch[1](244/1500); Loss: 0.085350; Backpropagation: 0.0989 sec; Batch: 0.4336 sec
0.1069 0.1036 0.0960 0.0861 0.0841 0.0816 0.0806 0.0811 0.0798 0.0804 0.0802 0.0798 0.0804 0.0808 0.0816 0.0826 

[TRAIN] Epoch[1](245/1500); Loss: 0.155002; Backpropagation: 0.0986 sec; Batch: 0.4341 sec
0.2180 0.2071 0.1885 0.1749 0.1644 0.1530 0.1453 0.1410 0.1382 0.1368 0.1348 0.1346 0.1349 0.1356 0.1360 0.1371 

[TRAIN] Epoch[1](246/1500); Loss: 0.086410; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1015 0.0951 0.0891 0.0859 0.0849 0.0827 0.0805 0.0818 0.0814 0.0826 0.0836 0.0843 0.0856 0.0857 0.0885 0.0894 

[TRAIN] Epoch[1](247/1500); Loss: 0.118218; Backpropagation: 0.1013 sec; Batch: 0.4365 sec
0.1976 0.1794 0.1535 0.1311 0.1161 0.1039 0.0989 0.0972 0.0970 0.0979 0.0999 0.1001 0.1021 0.1046 0.1046 0.1075 

[TRAIN] Epoch[1](248/1500); Loss: 0.109713; Backpropagation: 0.1029 sec; Batch: 0.4383 sec
0.1315 0.1321 0.1160 0.1071 0.1034 0.1028 0.1015 0.1033 0.1022 0.1023 0.1047 0.1063 0.1066 0.1092 0.1119 0.1143 

[TRAIN] Epoch[1](249/1500); Loss: 0.133374; Backpropagation: 0.0993 sec; Batch: 0.4349 sec
0.1593 0.1476 0.1369 0.1340 0.1302 0.1304 0.1284 0.1274 0.1270 0.1279 0.1279 0.1284 0.1296 0.1312 0.1328 0.1349 

[TRAIN] Epoch[1](250/1500); Loss: 0.118610; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1231 0.1227 0.1177 0.1176 0.1177 0.1168 0.1165 0.1173 0.1170 0.1162 0.1177 0.1186 0.1185 0.1193 0.1202 0.1209 

[TRAIN] Epoch[1](251/1500); Loss: 0.098184; Backpropagation: 0.0986 sec; Batch: 0.4430 sec
0.1886 0.2243 0.1898 0.1429 0.1375 0.1062 0.0872 0.0693 0.0601 0.0560 0.0552 0.0518 0.0518 0.0509 0.0492 0.0502 

[TRAIN] Epoch[1](252/1500); Loss: 0.176848; Backpropagation: 0.0985 sec; Batch: 0.4341 sec
0.2455 0.2615 0.2415 0.2175 0.2141 0.1964 0.1849 0.1712 0.1596 0.1482 0.1376 0.1317 0.1284 0.1295 0.1310 0.1310 

[TRAIN] Epoch[1](253/1500); Loss: 0.090278; Backpropagation: 0.1083 sec; Batch: 0.4444 sec
0.1082 0.0994 0.0935 0.0867 0.0905 0.0859 0.0842 0.0837 0.0865 0.0860 0.0866 0.0885 0.0902 0.0903 0.0910 0.0931 

[TRAIN] Epoch[1](254/1500); Loss: 0.112195; Backpropagation: 0.1073 sec; Batch: 0.4420 sec
0.1378 0.1338 0.1243 0.1165 0.1122 0.1091 0.1085 0.1085 0.1088 0.1064 0.1055 0.1048 0.1039 0.1050 0.1045 0.1056 

[TRAIN] Epoch[1](255/1500); Loss: 0.106306; Backpropagation: 0.0989 sec; Batch: 0.4340 sec
0.1230 0.1226 0.1147 0.1111 0.1084 0.1061 0.1044 0.1017 0.1000 0.1010 0.1001 0.1009 0.1001 0.1011 0.1032 0.1023 

[TRAIN] Epoch[1](256/1500); Loss: 0.116909; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1710 0.1680 0.1504 0.1366 0.1317 0.1223 0.1165 0.1108 0.1064 0.1012 0.0980 0.0952 0.0930 0.0903 0.0895 0.0896 

[TRAIN] Epoch[1](257/1500); Loss: 0.102842; Backpropagation: 0.0994 sec; Batch: 0.4342 sec
0.1344 0.1423 0.1258 0.1088 0.1065 0.0978 0.0977 0.0935 0.0908 0.0922 0.0917 0.0908 0.0904 0.0952 0.0929 0.0947 

[TRAIN] Epoch[1](258/1500); Loss: 0.123503; Backpropagation: 0.0989 sec; Batch: 0.4347 sec
0.1858 0.2109 0.1789 0.1488 0.1453 0.1256 0.1166 0.1048 0.1000 0.0937 0.0931 0.0920 0.0952 0.0930 0.0958 0.0963 

[TRAIN] Epoch[1](259/1500); Loss: 0.122825; Backpropagation: 0.0990 sec; Batch: 0.4341 sec
0.1660 0.1547 0.1421 0.1343 0.1270 0.1273 0.1236 0.1171 0.1119 0.1131 0.1085 0.1083 0.1073 0.1079 0.1076 0.1085 

[TRAIN] Epoch[1](260/1500); Loss: 0.084164; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1068 0.1068 0.0930 0.0851 0.0819 0.0812 0.0795 0.0818 0.0800 0.0791 0.0768 0.0800 0.0771 0.0792 0.0807 0.0775 

[TRAIN] Epoch[1](261/1500); Loss: 0.132877; Backpropagation: 0.1005 sec; Batch: 0.4363 sec
0.3350 0.3039 0.2579 0.2104 0.1698 0.1251 0.0847 0.0651 0.0716 0.0695 0.0711 0.0707 0.0737 0.0712 0.0734 0.0728 

[TRAIN] Epoch[1](262/1500); Loss: 0.112464; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.3186 0.2868 0.2377 0.1871 0.1438 0.0964 0.0562 0.0432 0.0598 0.0515 0.0520 0.0534 0.0570 0.0506 0.0541 0.0511 

[TRAIN] Epoch[1](263/1500); Loss: 0.107919; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.2235 0.2014 0.1685 0.1394 0.1173 0.0975 0.0829 0.0777 0.0811 0.0812 0.0748 0.0757 0.0756 0.0768 0.0765 0.0770 

[TRAIN] Epoch[1](264/1500); Loss: 0.102420; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.2939 0.2616 0.2139 0.1647 0.1248 0.0857 0.0580 0.0486 0.0536 0.0462 0.0469 0.0461 0.0475 0.0483 0.0476 0.0514 

[TRAIN] Epoch[1](265/1500); Loss: 0.102548; Backpropagation: 0.0998 sec; Batch: 0.4351 sec
0.1245 0.1233 0.1109 0.1069 0.1009 0.1005 0.0975 0.0977 0.0970 0.0959 0.0957 0.0960 0.0968 0.0977 0.0985 0.1008 

[TRAIN] Epoch[1](266/1500); Loss: 0.101241; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.1926 0.1739 0.1468 0.1204 0.1056 0.0961 0.0890 0.0813 0.0787 0.0786 0.0788 0.0754 0.0760 0.0751 0.0770 0.0748 

[TRAIN] Epoch[1](267/1500); Loss: 0.159680; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1740 0.1776 0.1698 0.1669 0.1619 0.1613 0.1586 0.1577 0.1545 0.1550 0.1535 0.1539 0.1527 0.1531 0.1520 0.1524 

[TRAIN] Epoch[1](268/1500); Loss: 0.131225; Backpropagation: 0.0990 sec; Batch: 0.4351 sec
0.1651 0.1838 0.1534 0.1378 0.1343 0.1262 0.1233 0.1188 0.1222 0.1184 0.1186 0.1201 0.1190 0.1188 0.1166 0.1231 

[TRAIN] Epoch[1](269/1500); Loss: 0.127801; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.2031 0.2201 0.1973 0.1681 0.1628 0.1427 0.1281 0.1139 0.1008 0.0935 0.0867 0.0867 0.0818 0.0858 0.0863 0.0872 

[TRAIN] Epoch[1](270/1500); Loss: 0.128645; Backpropagation: 0.0988 sec; Batch: 0.4341 sec
0.1692 0.1665 0.1461 0.1281 0.1321 0.1189 0.1223 0.1174 0.1199 0.1175 0.1187 0.1179 0.1204 0.1192 0.1231 0.1211 

[TRAIN] Epoch[1](271/1500); Loss: 0.109963; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1742 0.2037 0.1675 0.1225 0.1249 0.0962 0.0925 0.0816 0.0833 0.0829 0.0850 0.0856 0.0861 0.0894 0.0893 0.0948 

[TRAIN] Epoch[1](272/1500); Loss: 0.116105; Backpropagation: 0.0988 sec; Batch: 0.4340 sec
0.1989 0.1904 0.1648 0.1466 0.1321 0.1177 0.1050 0.0933 0.0924 0.0897 0.0890 0.0879 0.0872 0.0880 0.0865 0.0882 

[TRAIN] Epoch[1](273/1500); Loss: 0.144352; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.2223 0.2188 0.1960 0.1754 0.1612 0.1458 0.1339 0.1240 0.1207 0.1163 0.1154 0.1144 0.1153 0.1160 0.1170 0.1171 

[TRAIN] Epoch[1](274/1500); Loss: 0.158671; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.2532 0.2761 0.2463 0.2048 0.1998 0.1746 0.1551 0.1361 0.1211 0.1117 0.1075 0.1084 0.1097 0.1097 0.1110 0.1136 

[TRAIN] Epoch[1](275/1500); Loss: 0.115830; Backpropagation: 0.0989 sec; Batch: 0.4350 sec
0.1356 0.1303 0.1238 0.1199 0.1179 0.1151 0.1130 0.1113 0.1109 0.1093 0.1099 0.1105 0.1103 0.1109 0.1119 0.1126 

[TRAIN] Epoch[1](276/1500); Loss: 0.119164; Backpropagation: 0.0987 sec; Batch: 0.4338 sec
0.1419 0.1371 0.1290 0.1226 0.1200 0.1170 0.1155 0.1137 0.1136 0.1139 0.1136 0.1135 0.1141 0.1140 0.1138 0.1134 

[TRAIN] Epoch[1](277/1500); Loss: 0.148038; Backpropagation: 0.0990 sec; Batch: 0.4336 sec
0.2156 0.2037 0.1782 0.1579 0.1495 0.1387 0.1372 0.1363 0.1326 0.1298 0.1317 0.1306 0.1309 0.1314 0.1322 0.1323 

[TRAIN] Epoch[1](278/1500); Loss: 0.099138; Backpropagation: 0.1010 sec; Batch: 0.4366 sec
0.1617 0.1418 0.1213 0.1024 0.0924 0.0893 0.0848 0.0851 0.0866 0.0854 0.0882 0.0873 0.0885 0.0897 0.0904 0.0913 

[TRAIN] Epoch[1](279/1500); Loss: 0.090455; Backpropagation: 0.0985 sec; Batch: 0.4368 sec
0.1114 0.1062 0.0917 0.0874 0.0885 0.0859 0.0854 0.0854 0.0851 0.0859 0.0862 0.0870 0.0886 0.0880 0.0920 0.0925 

[TRAIN] Epoch[1](280/1500); Loss: 0.151228; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.2696 0.2557 0.2247 0.1896 0.1667 0.1383 0.1171 0.1222 0.1142 0.1186 0.1147 0.1165 0.1150 0.1213 0.1169 0.1186 

[TRAIN] Epoch[1](281/1500); Loss: 0.090532; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1044 0.0954 0.0897 0.0933 0.0889 0.0872 0.0885 0.0862 0.0880 0.0849 0.0890 0.0877 0.0896 0.0901 0.0917 0.0938 

[TRAIN] Epoch[1](282/1500); Loss: 0.100592; Backpropagation: 0.0992 sec; Batch: 0.4344 sec
0.1764 0.1664 0.1429 0.1203 0.1039 0.0922 0.0883 0.0892 0.0822 0.0819 0.0779 0.0801 0.0756 0.0786 0.0757 0.0778 

[TRAIN] Epoch[1](283/1500); Loss: 0.151076; Backpropagation: 0.0992 sec; Batch: 0.4344 sec
0.3443 0.3899 0.3371 0.2509 0.2424 0.1912 0.1393 0.0950 0.0500 0.0417 0.0630 0.0479 0.0569 0.0536 0.0536 0.0603 

[TRAIN] Epoch[1](284/1500); Loss: 0.084435; Backpropagation: 0.0991 sec; Batch: 0.4340 sec
0.0899 0.0855 0.0785 0.0792 0.0801 0.0781 0.0779 0.0810 0.0797 0.0847 0.0825 0.0889 0.0853 0.0917 0.0892 0.0985 

[TRAIN] Epoch[1](285/1500); Loss: 0.148193; Backpropagation: 0.0994 sec; Batch: 0.4412 sec
0.1763 0.1825 0.1698 0.1564 0.1532 0.1468 0.1423 0.1395 0.1382 0.1374 0.1377 0.1382 0.1383 0.1376 0.1385 0.1383 

[TRAIN] Epoch[1](286/1500); Loss: 0.071503; Backpropagation: 0.0991 sec; Batch: 0.4351 sec
0.0802 0.0725 0.0676 0.0676 0.0715 0.0647 0.0692 0.0670 0.0707 0.0690 0.0724 0.0715 0.0746 0.0739 0.0756 0.0759 

[TRAIN] Epoch[1](287/1500); Loss: 0.120714; Backpropagation: 0.0994 sec; Batch: 0.4354 sec
0.1547 0.1549 0.1445 0.1341 0.1294 0.1240 0.1170 0.1145 0.1100 0.1082 0.1054 0.1062 0.1056 0.1074 0.1071 0.1084 

[TRAIN] Epoch[1](288/1500); Loss: 0.140076; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1794 0.1773 0.1565 0.1438 0.1380 0.1339 0.1309 0.1316 0.1292 0.1307 0.1298 0.1313 0.1304 0.1320 0.1322 0.1342 

[TRAIN] Epoch[1](289/1500); Loss: 0.081083; Backpropagation: 0.0989 sec; Batch: 0.4354 sec
0.1420 0.1304 0.1066 0.0894 0.0773 0.0749 0.0696 0.0708 0.0663 0.0686 0.0645 0.0671 0.0657 0.0673 0.0676 0.0694 

[TRAIN] Epoch[1](290/1500); Loss: 0.104143; Backpropagation: 0.0993 sec; Batch: 0.4354 sec
0.1321 0.1336 0.1196 0.1059 0.1052 0.0999 0.0973 0.0961 0.0952 0.0946 0.0947 0.0961 0.0964 0.0992 0.0985 0.1020 

[TRAIN] Epoch[1](291/1500); Loss: 0.101326; Backpropagation: 0.0997 sec; Batch: 0.4359 sec
0.2224 0.2554 0.2049 0.1291 0.1197 0.0781 0.0545 0.0540 0.0601 0.0592 0.0600 0.0617 0.0637 0.0643 0.0664 0.0677 

[TRAIN] Epoch[1](292/1500); Loss: 0.103417; Backpropagation: 0.0993 sec; Batch: 0.4351 sec
0.1280 0.1090 0.1031 0.1023 0.1024 0.1005 0.1028 0.0994 0.1024 0.0977 0.1009 0.0989 0.1005 0.1007 0.1028 0.1032 

[TRAIN] Epoch[1](293/1500); Loss: 0.074298; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1284 0.1426 0.1155 0.0775 0.0734 0.0629 0.0598 0.0594 0.0559 0.0574 0.0563 0.0579 0.0573 0.0608 0.0596 0.0638 

[TRAIN] Epoch[1](294/1500); Loss: 0.132198; Backpropagation: 0.0996 sec; Batch: 0.4353 sec
0.1846 0.1833 0.1625 0.1433 0.1354 0.1302 0.1259 0.1249 0.1209 0.1189 0.1160 0.1154 0.1141 0.1143 0.1122 0.1134 

[TRAIN] Epoch[1](295/1500); Loss: 0.069777; Backpropagation: 0.0995 sec; Batch: 0.4355 sec
0.1346 0.1138 0.0886 0.0804 0.0698 0.0616 0.0584 0.0578 0.0543 0.0576 0.0545 0.0572 0.0541 0.0587 0.0553 0.0597 

[TRAIN] Epoch[1](296/1500); Loss: 0.077858; Backpropagation: 0.0991 sec; Batch: 0.4350 sec
0.1005 0.1024 0.0881 0.0777 0.0789 0.0722 0.0732 0.0691 0.0722 0.0700 0.0730 0.0712 0.0739 0.0728 0.0761 0.0745 

[TRAIN] Epoch[1](297/1500); Loss: 0.132653; Backpropagation: 0.0993 sec; Batch: 0.4354 sec
0.1508 0.1512 0.1416 0.1355 0.1340 0.1327 0.1293 0.1286 0.1266 0.1268 0.1260 0.1270 0.1266 0.1281 0.1274 0.1301 

[TRAIN] Epoch[1](298/1500); Loss: 0.100434; Backpropagation: 0.0993 sec; Batch: 0.4348 sec
0.1755 0.1635 0.1352 0.1049 0.0933 0.0856 0.0837 0.0845 0.0832 0.0838 0.0844 0.0846 0.0850 0.0859 0.0862 0.0876 

[TRAIN] Epoch[1](299/1500); Loss: 0.083828; Backpropagation: 0.0995 sec; Batch: 0.4356 sec
0.2471 0.2113 0.1587 0.1021 0.0670 0.0452 0.0464 0.0453 0.0461 0.0486 0.0496 0.0501 0.0532 0.0537 0.0578 0.0588 

[TRAIN] Epoch[1](300/1500); Loss: 0.062755; Backpropagation: 0.0997 sec; Batch: 0.4351 sec
0.1092 0.1357 0.1044 0.0561 0.0601 0.0443 0.0478 0.0500 0.0460 0.0474 0.0483 0.0492 0.0499 0.0509 0.0513 0.0534 

[TRAIN] Epoch[1](301/1500); Loss: 0.101525; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.1595 0.1549 0.1409 0.1255 0.1183 0.1099 0.1003 0.0936 0.0834 0.0785 0.0741 0.0773 0.0745 0.0779 0.0765 0.0793 

[TRAIN] Epoch[1](302/1500); Loss: 0.082916; Backpropagation: 0.0987 sec; Batch: 0.4339 sec
0.1453 0.1623 0.1366 0.0962 0.0887 0.0732 0.0654 0.0654 0.0616 0.0622 0.0589 0.0619 0.0586 0.0636 0.0608 0.0662 

[TRAIN] Epoch[1](303/1500); Loss: 0.124208; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1896 0.1800 0.1595 0.1455 0.1345 0.1274 0.1185 0.1125 0.1044 0.1037 0.1014 0.1029 0.1017 0.1017 0.1019 0.1020 

[TRAIN] Epoch[1](304/1500); Loss: 0.115806; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1581 0.1596 0.1404 0.1236 0.1187 0.1149 0.1045 0.1048 0.1006 0.1049 0.1007 0.1054 0.1013 0.1064 0.1019 0.1069 

[TRAIN] Epoch[1](305/1500); Loss: 0.070331; Backpropagation: 0.1007 sec; Batch: 0.4359 sec
0.1427 0.1708 0.1367 0.0827 0.0758 0.0511 0.0391 0.0388 0.0386 0.0437 0.0438 0.0483 0.0482 0.0533 0.0533 0.0583 

[TRAIN] Epoch[1](306/1500); Loss: 0.140193; Backpropagation: 0.0995 sec; Batch: 0.4353 sec
0.1792 0.1450 0.1491 0.1629 0.1508 0.1575 0.1465 0.1474 0.1373 0.1362 0.1293 0.1271 0.1206 0.1213 0.1149 0.1180 

[TRAIN] Epoch[1](307/1500); Loss: 0.134201; Backpropagation: 0.0993 sec; Batch: 0.4351 sec
0.1985 0.1816 0.1636 0.1500 0.1335 0.1238 0.1173 0.1221 0.1166 0.1211 0.1169 0.1211 0.1174 0.1216 0.1185 0.1236 

[TRAIN] Epoch[1](308/1500); Loss: 0.120188; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.2869 0.2532 0.2054 0.1499 0.1107 0.0815 0.0785 0.0799 0.0787 0.0843 0.0804 0.0852 0.0829 0.0883 0.0862 0.0910 

[TRAIN] Epoch[1](309/1500); Loss: 0.094900; Backpropagation: 0.0988 sec; Batch: 0.4351 sec
0.1048 0.1023 0.0975 0.0981 0.0953 0.0959 0.0931 0.0943 0.0921 0.0932 0.0916 0.0927 0.0913 0.0925 0.0914 0.0924 

[TRAIN] Epoch[1](310/1500); Loss: 0.098350; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1778 0.2035 0.1601 0.1062 0.0994 0.0805 0.0686 0.0725 0.0717 0.0737 0.0729 0.0755 0.0754 0.0776 0.0783 0.0799 

[TRAIN] Epoch[1](311/1500); Loss: 0.102500; Backpropagation: 0.1003 sec; Batch: 0.4358 sec
0.1658 0.1899 0.1509 0.1057 0.1024 0.0891 0.0787 0.0820 0.0811 0.0830 0.0809 0.0852 0.0835 0.0866 0.0863 0.0890 

[TRAIN] Epoch[1](312/1500); Loss: 0.155250; Backpropagation: 0.0997 sec; Batch: 0.4350 sec
0.1974 0.1782 0.1733 0.1703 0.1617 0.1611 0.1523 0.1530 0.1459 0.1471 0.1408 0.1423 0.1391 0.1407 0.1399 0.1408 

[TRAIN] Epoch[1](313/1500); Loss: 0.079042; Backpropagation: 0.0999 sec; Batch: 0.4361 sec
0.1233 0.1069 0.0874 0.0787 0.0718 0.0753 0.0711 0.0737 0.0703 0.0734 0.0713 0.0727 0.0720 0.0720 0.0730 0.0717 

[TRAIN] Epoch[1](314/1500); Loss: 0.068778; Backpropagation: 0.0992 sec; Batch: 0.4347 sec
0.1039 0.1237 0.0970 0.0728 0.0708 0.0594 0.0578 0.0559 0.0571 0.0558 0.0573 0.0560 0.0584 0.0570 0.0595 0.0580 

[TRAIN] Epoch[1](315/1500); Loss: 0.107752; Backpropagation: 0.0993 sec; Batch: 0.4350 sec
0.1920 0.1950 0.1702 0.1411 0.1323 0.1195 0.1010 0.0927 0.0746 0.0735 0.0698 0.0738 0.0699 0.0735 0.0710 0.0741 

[TRAIN] Epoch[1](316/1500); Loss: 0.066057; Backpropagation: 0.0990 sec; Batch: 0.4343 sec
0.1057 0.1120 0.0886 0.0675 0.0676 0.0615 0.0598 0.0551 0.0554 0.0534 0.0558 0.0537 0.0560 0.0535 0.0568 0.0545 

[TRAIN] Epoch[1](317/1500); Loss: 0.052917; Backpropagation: 0.1027 sec; Batch: 0.4385 sec
0.0779 0.0746 0.0515 0.0503 0.0474 0.0481 0.0478 0.0486 0.0479 0.0493 0.0492 0.0501 0.0498 0.0510 0.0507 0.0526 

[TRAIN] Epoch[1](318/1500); Loss: 0.137934; Backpropagation: 0.1027 sec; Batch: 0.4384 sec
0.2291 0.2110 0.1829 0.1572 0.1357 0.1171 0.1191 0.1135 0.1145 0.1165 0.1148 0.1174 0.1170 0.1197 0.1197 0.1217 

[TRAIN] Epoch[1](319/1500); Loss: 0.139721; Backpropagation: 0.0993 sec; Batch: 0.4356 sec
0.1666 0.1646 0.1518 0.1417 0.1388 0.1367 0.1335 0.1340 0.1327 0.1342 0.1326 0.1337 0.1328 0.1340 0.1333 0.1343 

[TRAIN] Epoch[1](320/1500); Loss: 0.093918; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1201 0.1136 0.1019 0.0945 0.0926 0.0909 0.0903 0.0897 0.0896 0.0891 0.0887 0.0883 0.0886 0.0879 0.0887 0.0882 

[TRAIN] Epoch[1](321/1500); Loss: 0.081000; Backpropagation: 0.0989 sec; Batch: 0.4336 sec
0.1185 0.1131 0.0940 0.0860 0.0796 0.0763 0.0718 0.0744 0.0710 0.0733 0.0707 0.0740 0.0714 0.0742 0.0721 0.0756 

[TRAIN] Epoch[1](322/1500); Loss: 0.133909; Backpropagation: 0.1009 sec; Batch: 0.4420 sec
0.1613 0.1523 0.1407 0.1325 0.1298 0.1280 0.1281 0.1281 0.1291 0.1277 0.1300 0.1288 0.1314 0.1300 0.1331 0.1316 

[TRAIN] Epoch[1](323/1500); Loss: 0.122271; Backpropagation: 0.1000 sec; Batch: 0.4347 sec
0.1387 0.1445 0.1328 0.1260 0.1232 0.1202 0.1186 0.1181 0.1173 0.1167 0.1166 0.1162 0.1165 0.1165 0.1173 0.1171 

[TRAIN] Epoch[1](324/1500); Loss: 0.090235; Backpropagation: 0.0996 sec; Batch: 0.4341 sec
0.1396 0.1268 0.1092 0.0972 0.0926 0.0855 0.0826 0.0798 0.0798 0.0789 0.0792 0.0783 0.0787 0.0780 0.0790 0.0788 

[TRAIN] Epoch[1](325/1500); Loss: 0.067966; Backpropagation: 0.0991 sec; Batch: 0.4348 sec
0.1472 0.1198 0.0902 0.0670 0.0571 0.0577 0.0540 0.0570 0.0525 0.0557 0.0527 0.0558 0.0529 0.0565 0.0542 0.0570 

[TRAIN] Epoch[1](326/1500); Loss: 0.069876; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1147 0.0857 0.0776 0.0753 0.0719 0.0696 0.0673 0.0658 0.0638 0.0624 0.0618 0.0606 0.0607 0.0596 0.0612 0.0598 

[TRAIN] Epoch[1](327/1500); Loss: 0.115722; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1595 0.1561 0.1416 0.1281 0.1211 0.1137 0.1091 0.1045 0.1039 0.1032 0.1026 0.1021 0.1019 0.1013 0.1013 0.1015 

[TRAIN] Epoch[1](328/1500); Loss: 0.095993; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.1442 0.1340 0.1128 0.0998 0.0942 0.0897 0.0864 0.0863 0.0857 0.0858 0.0859 0.0858 0.0859 0.0862 0.0864 0.0869 

[TRAIN] Epoch[1](329/1500); Loss: 0.080082; Backpropagation: 0.0995 sec; Batch: 0.4360 sec
0.1220 0.1203 0.0988 0.0867 0.0789 0.0730 0.0732 0.0698 0.0721 0.0693 0.0704 0.0676 0.0709 0.0682 0.0707 0.0692 

[TRAIN] Epoch[1](330/1500); Loss: 0.209399; Backpropagation: 0.1023 sec; Batch: 0.4374 sec
0.2743 0.2853 0.2645 0.2314 0.2263 0.2072 0.1924 0.1884 0.1862 0.1852 0.1849 0.1843 0.1848 0.1850 0.1851 0.1851 

[TRAIN] Epoch[1](331/1500); Loss: 0.113395; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.1652 0.1531 0.1313 0.1164 0.1111 0.1072 0.1033 0.1041 0.1018 0.1029 0.1014 0.1031 0.1023 0.1035 0.1027 0.1049 

[TRAIN] Epoch[1](332/1500); Loss: 0.121973; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.2255 0.2192 0.1848 0.1468 0.1306 0.1129 0.1050 0.0972 0.0932 0.0918 0.0925 0.0901 0.0905 0.0902 0.0909 0.0902 

[TRAIN] Epoch[1](333/1500); Loss: 0.072441; Backpropagation: 0.0990 sec; Batch: 0.4340 sec
0.0899 0.0889 0.0777 0.0700 0.0692 0.0679 0.0678 0.0691 0.0686 0.0689 0.0697 0.0698 0.0706 0.0702 0.0713 0.0697 

[TRAIN] Epoch[1](334/1500); Loss: 0.164603; Backpropagation: 0.1004 sec; Batch: 0.4364 sec
0.2137 0.2078 0.1912 0.1721 0.1674 0.1606 0.1558 0.1524 0.1522 0.1503 0.1510 0.1509 0.1515 0.1521 0.1521 0.1525 

[TRAIN] Epoch[1](335/1500); Loss: 0.101200; Backpropagation: 0.1073 sec; Batch: 0.4431 sec
0.1289 0.1183 0.1071 0.1013 0.1003 0.0987 0.0983 0.0977 0.0970 0.0969 0.0963 0.0957 0.0953 0.0956 0.0957 0.0960 

[TRAIN] Epoch[1](336/1500); Loss: 0.077268; Backpropagation: 0.1044 sec; Batch: 0.4402 sec
0.1387 0.1142 0.0927 0.0759 0.0712 0.0648 0.0657 0.0627 0.0658 0.0635 0.0670 0.0660 0.0696 0.0699 0.0739 0.0747 

[TRAIN] Epoch[1](337/1500); Loss: 0.076955; Backpropagation: 0.0996 sec; Batch: 0.4345 sec
0.1535 0.1316 0.1058 0.0887 0.0738 0.0653 0.0616 0.0622 0.0624 0.0609 0.0613 0.0607 0.0610 0.0609 0.0610 0.0606 

[TRAIN] Epoch[1](338/1500); Loss: 0.120985; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.1734 0.1646 0.1446 0.1254 0.1186 0.1135 0.1111 0.1109 0.1094 0.1092 0.1086 0.1088 0.1092 0.1092 0.1096 0.1098 

[TRAIN] Epoch[1](339/1500); Loss: 0.134713; Backpropagation: 0.0999 sec; Batch: 0.4347 sec
0.1941 0.1603 0.1549 0.1454 0.1362 0.1327 0.1282 0.1261 0.1225 0.1217 0.1201 0.1206 0.1203 0.1221 0.1233 0.1271 

[TRAIN] Epoch[1](340/1500); Loss: 0.094535; Backpropagation: 0.0994 sec; Batch: 0.4374 sec
0.1203 0.1117 0.0992 0.0933 0.0920 0.0902 0.0905 0.0890 0.0895 0.0890 0.0898 0.0901 0.0905 0.0924 0.0914 0.0936 

[TRAIN] Epoch[1](341/1500); Loss: 0.104492; Backpropagation: 0.0991 sec; Batch: 0.4344 sec
0.1383 0.1363 0.1183 0.1066 0.1038 0.1015 0.0984 0.0982 0.0962 0.0970 0.0968 0.0958 0.0967 0.0953 0.0964 0.0963 

[TRAIN] Epoch[1](342/1500); Loss: 0.125085; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1647 0.1529 0.1387 0.1289 0.1216 0.1214 0.1180 0.1203 0.1170 0.1190 0.1157 0.1177 0.1153 0.1181 0.1145 0.1176 

[TRAIN] Epoch[1](343/1500); Loss: 0.095229; Backpropagation: 0.0987 sec; Batch: 0.4344 sec
0.2174 0.1897 0.1526 0.1132 0.0878 0.0724 0.0718 0.0666 0.0693 0.0679 0.0686 0.0684 0.0685 0.0693 0.0695 0.0706 

[TRAIN] Epoch[1](344/1500); Loss: 0.136421; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2213 0.2053 0.1755 0.1477 0.1369 0.1280 0.1202 0.1166 0.1142 0.1142 0.1144 0.1162 0.1155 0.1185 0.1180 0.1202 

[TRAIN] Epoch[1](345/1500); Loss: 0.059172; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1248 0.1127 0.0903 0.0691 0.0571 0.0492 0.0488 0.0456 0.0452 0.0435 0.0429 0.0433 0.0420 0.0444 0.0429 0.0451 

[TRAIN] Epoch[1](346/1500); Loss: 0.123179; Backpropagation: 0.0989 sec; Batch: 0.4344 sec
0.1894 0.1912 0.1713 0.1455 0.1372 0.1247 0.1144 0.1064 0.1000 0.0986 0.0992 0.0981 0.0991 0.0974 0.0996 0.0987 

[TRAIN] Epoch[1](347/1500); Loss: 0.237861; Backpropagation: 0.0990 sec; Batch: 0.4347 sec
0.2800 0.3013 0.2757 0.2400 0.2402 0.2251 0.2184 0.2161 0.2152 0.2152 0.2215 0.2236 0.2274 0.2304 0.2356 0.2401 

[TRAIN] Epoch[1](348/1500); Loss: 0.073719; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.0916 0.0636 0.0753 0.0654 0.0660 0.0642 0.0688 0.0656 0.0715 0.0690 0.0758 0.0736 0.0801 0.0789 0.0849 0.0853 

[TRAIN] Epoch[1](349/1500); Loss: 0.132132; Backpropagation: 0.0988 sec; Batch: 0.4348 sec
0.1987 0.1838 0.1641 0.1449 0.1318 0.1239 0.1197 0.1176 0.1170 0.1161 0.1159 0.1160 0.1160 0.1160 0.1154 0.1171 

[TRAIN] Epoch[1](350/1500); Loss: 0.070825; Backpropagation: 0.0995 sec; Batch: 0.4353 sec
0.0985 0.0864 0.0765 0.0668 0.0673 0.0669 0.0659 0.0660 0.0661 0.0661 0.0663 0.0671 0.0678 0.0680 0.0685 0.0691 

[TRAIN] Epoch[1](351/1500); Loss: 0.058381; Backpropagation: 0.0994 sec; Batch: 0.4352 sec
0.1485 0.1200 0.0839 0.0494 0.0429 0.0508 0.0458 0.0412 0.0437 0.0420 0.0450 0.0420 0.0443 0.0431 0.0473 0.0441 

[TRAIN] Epoch[1](352/1500); Loss: 0.124727; Backpropagation: 0.0991 sec; Batch: 0.4344 sec
0.1591 0.1532 0.1398 0.1306 0.1247 0.1227 0.1179 0.1186 0.1151 0.1166 0.1154 0.1168 0.1152 0.1167 0.1162 0.1169 

[TRAIN] Epoch[1](353/1500); Loss: 0.069917; Backpropagation: 0.0989 sec; Batch: 0.4351 sec
0.0925 0.0940 0.0704 0.0856 0.0654 0.0683 0.0623 0.0643 0.0662 0.0625 0.0645 0.0637 0.0648 0.0642 0.0650 0.0650 

[TRAIN] Epoch[1](354/1500); Loss: 0.090779; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1835 0.1513 0.1179 0.0948 0.0892 0.0906 0.0806 0.0732 0.0723 0.0723 0.0698 0.0714 0.0701 0.0719 0.0704 0.0733 

[TRAIN] Epoch[1](355/1500); Loss: 0.066449; Backpropagation: 0.0987 sec; Batch: 0.4347 sec
0.1489 0.1084 0.0702 0.0656 0.0739 0.0590 0.0516 0.0504 0.0521 0.0519 0.0530 0.0554 0.0531 0.0563 0.0565 0.0568 

[TRAIN] Epoch[1](356/1500); Loss: 0.080490; Backpropagation: 0.0984 sec; Batch: 0.4336 sec
0.1002 0.0966 0.1009 0.0994 0.0854 0.0770 0.0728 0.0713 0.0727 0.0722 0.0714 0.0725 0.0723 0.0734 0.0745 0.0752 

[TRAIN] Epoch[1](357/1500); Loss: 0.158350; Backpropagation: 0.0987 sec; Batch: 0.4344 sec
0.1838 0.1862 0.1800 0.1681 0.1600 0.1558 0.1526 0.1517 0.1505 0.1498 0.1498 0.1482 0.1485 0.1484 0.1498 0.1504 

[TRAIN] Epoch[1](358/1500); Loss: 0.129098; Backpropagation: 0.0995 sec; Batch: 0.4352 sec
0.1837 0.1752 0.1645 0.1541 0.1418 0.1330 0.1232 0.1151 0.1093 0.1102 0.1093 0.1078 0.1085 0.1089 0.1100 0.1110 

[TRAIN] Epoch[1](359/1500); Loss: 0.145677; Backpropagation: 0.1002 sec; Batch: 0.4357 sec
0.2009 0.2175 0.1820 0.1459 0.1411 0.1289 0.1261 0.1312 0.1285 0.1287 0.1314 0.1314 0.1313 0.1343 0.1350 0.1365 

[TRAIN] Epoch[1](360/1500); Loss: 0.095795; Backpropagation: 0.0990 sec; Batch: 0.4379 sec
0.1486 0.1322 0.1140 0.1075 0.0978 0.0980 0.0919 0.0815 0.0778 0.0814 0.0793 0.0817 0.0823 0.0853 0.0862 0.0873 

[TRAIN] Epoch[1](361/1500); Loss: 0.145145; Backpropagation: 0.0984 sec; Batch: 0.4351 sec
0.1489 0.1570 0.1636 0.1490 0.1432 0.1455 0.1476 0.1394 0.1398 0.1394 0.1418 0.1411 0.1403 0.1404 0.1430 0.1424 

[TRAIN] Epoch[1](362/1500); Loss: 0.153949; Backpropagation: 0.0984 sec; Batch: 0.4336 sec
0.1998 0.2018 0.1857 0.1617 0.1502 0.1443 0.1405 0.1365 0.1370 0.1404 0.1398 0.1407 0.1421 0.1448 0.1483 0.1493 

[TRAIN] Epoch[1](363/1500); Loss: 0.105276; Backpropagation: 0.0992 sec; Batch: 0.4357 sec
0.2101 0.2583 0.2030 0.1193 0.1007 0.0751 0.0710 0.0674 0.0749 0.0714 0.0699 0.0693 0.0719 0.0727 0.0720 0.0775 

[TRAIN] Epoch[1](364/1500); Loss: 0.137041; Backpropagation: 0.0988 sec; Batch: 0.4345 sec
0.1520 0.1449 0.1499 0.1519 0.1365 0.1326 0.1316 0.1312 0.1285 0.1299 0.1300 0.1317 0.1322 0.1340 0.1362 0.1395 

[TRAIN] Epoch[1](365/1500); Loss: 0.187399; Backpropagation: 0.0986 sec; Batch: 0.4340 sec
0.2990 0.3301 0.2807 0.2001 0.1745 0.1533 0.1601 0.1522 0.1650 0.1607 0.1530 0.1550 0.1511 0.1545 0.1531 0.1559 

[TRAIN] Epoch[1](366/1500); Loss: 0.167960; Backpropagation: 0.0984 sec; Batch: 0.4336 sec
0.2736 0.2372 0.1952 0.1454 0.1200 0.1552 0.1915 0.2008 0.1878 0.1616 0.1429 0.1345 0.1336 0.1341 0.1343 0.1397 

[TRAIN] Epoch[1](367/1500); Loss: 0.066008; Backpropagation: 0.0987 sec; Batch: 0.4349 sec
0.1084 0.0721 0.0446 0.0839 0.1036 0.0840 0.0562 0.0477 0.0550 0.0487 0.0553 0.0569 0.0553 0.0607 0.0599 0.0639 

[TRAIN] Epoch[1](368/1500); Loss: 0.060891; Backpropagation: 0.0988 sec; Batch: 0.4343 sec
0.0729 0.0743 0.0742 0.0887 0.0654 0.0490 0.0566 0.0510 0.0588 0.0557 0.0494 0.0569 0.0521 0.0562 0.0568 0.0565 

[TRAIN] Epoch[1](369/1500); Loss: 0.095005; Backpropagation: 0.0986 sec; Batch: 0.4382 sec
0.1257 0.1112 0.0950 0.1146 0.1181 0.1074 0.0957 0.0875 0.0826 0.0828 0.0821 0.0829 0.0816 0.0825 0.0841 0.0862 

[TRAIN] Epoch[1](370/1500); Loss: 0.092944; Backpropagation: 0.0996 sec; Batch: 0.4351 sec
0.1092 0.1176 0.1341 0.1183 0.1041 0.0928 0.0867 0.0818 0.0772 0.0811 0.0778 0.0781 0.0778 0.0841 0.0841 0.0822 

[TRAIN] Epoch[1](371/1500); Loss: 0.148805; Backpropagation: 0.0993 sec; Batch: 0.4345 sec
0.1691 0.1618 0.1759 0.1662 0.1533 0.1442 0.1509 0.1449 0.1437 0.1410 0.1401 0.1380 0.1373 0.1386 0.1377 0.1382 

[TRAIN] Epoch[1](372/1500); Loss: 0.137770; Backpropagation: 0.0992 sec; Batch: 0.4335 sec
0.1612 0.1695 0.1619 0.1541 0.1467 0.1393 0.1307 0.1284 0.1260 0.1253 0.1258 0.1245 0.1269 0.1288 0.1276 0.1279 

[TRAIN] Epoch[1](373/1500); Loss: 0.139439; Backpropagation: 0.1009 sec; Batch: 0.4363 sec
0.1440 0.1449 0.1409 0.1578 0.1479 0.1384 0.1341 0.1321 0.1331 0.1333 0.1349 0.1364 0.1375 0.1378 0.1377 0.1403 

[TRAIN] Epoch[1](374/1500); Loss: 0.098471; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.1526 0.1253 0.1066 0.1013 0.1156 0.1279 0.1137 0.0932 0.0815 0.0823 0.0827 0.0796 0.0804 0.0776 0.0773 0.0779 

[TRAIN] Epoch[1](375/1500); Loss: 0.135202; Backpropagation: 0.0991 sec; Batch: 0.4347 sec
0.1958 0.2036 0.1661 0.1367 0.1340 0.1329 0.1309 0.1223 0.1187 0.1183 0.1197 0.1149 0.1154 0.1187 0.1184 0.1168 

[TRAIN] Epoch[1](376/1500); Loss: 0.131714; Backpropagation: 0.0984 sec; Batch: 0.4366 sec
0.1622 0.1670 0.1550 0.1475 0.1372 0.1314 0.1281 0.1241 0.1196 0.1184 0.1181 0.1185 0.1195 0.1201 0.1206 0.1200 

[TRAIN] Epoch[1](377/1500); Loss: 0.155171; Backpropagation: 0.0988 sec; Batch: 0.4345 sec
0.1850 0.1708 0.1636 0.1741 0.1652 0.1522 0.1466 0.1502 0.1502 0.1489 0.1470 0.1479 0.1495 0.1437 0.1437 0.1442 

[TRAIN] Epoch[1](378/1500); Loss: 0.113216; Backpropagation: 0.0985 sec; Batch: 0.4360 sec
0.2420 0.1969 0.1514 0.1032 0.0875 0.1155 0.1095 0.0920 0.0878 0.0876 0.0880 0.0865 0.0910 0.0891 0.0907 0.0926 

[TRAIN] Epoch[1](379/1500); Loss: 0.113544; Backpropagation: 0.0994 sec; Batch: 0.4349 sec
0.1667 0.1664 0.1555 0.1188 0.0971 0.0989 0.1050 0.0988 0.0980 0.1004 0.1007 0.1021 0.1004 0.1016 0.1033 0.1030 

[TRAIN] Epoch[1](380/1500); Loss: 0.110396; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1410 0.1216 0.1302 0.1300 0.1129 0.1085 0.1019 0.1063 0.1009 0.0975 0.1022 0.1012 0.1024 0.1019 0.1032 0.1047 

[TRAIN] Epoch[1](381/1500); Loss: 0.134514; Backpropagation: 0.0996 sec; Batch: 0.4351 sec
0.1651 0.1642 0.1474 0.1521 0.1404 0.1316 0.1290 0.1241 0.1248 0.1242 0.1255 0.1240 0.1231 0.1249 0.1260 0.1257 

[TRAIN] Epoch[1](382/1500); Loss: 0.063768; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.1178 0.0822 0.0564 0.0626 0.0548 0.0625 0.0518 0.0612 0.0536 0.0567 0.0580 0.0580 0.0576 0.0621 0.0601 0.0648 

[TRAIN] Epoch[1](383/1500); Loss: 0.075392; Backpropagation: 0.0989 sec; Batch: 0.4343 sec
0.1255 0.0841 0.0773 0.0602 0.0634 0.0707 0.0689 0.0678 0.0675 0.0734 0.0704 0.0716 0.0748 0.0754 0.0741 0.0813 

[TRAIN] Epoch[1](384/1500); Loss: 0.169836; Backpropagation: 0.0989 sec; Batch: 0.4344 sec
0.1987 0.1973 0.1774 0.1933 0.1916 0.1701 0.1631 0.1580 0.1639 0.1545 0.1529 0.1553 0.1606 0.1592 0.1595 0.1621 

[TRAIN] Epoch[1](385/1500); Loss: 0.166098; Backpropagation: 0.0987 sec; Batch: 0.4338 sec
0.1946 0.1756 0.1661 0.1837 0.1824 0.1734 0.1596 0.1570 0.1570 0.1554 0.1562 0.1573 0.1557 0.1583 0.1611 0.1641 

[TRAIN] Epoch[1](386/1500); Loss: 0.094390; Backpropagation: 0.0982 sec; Batch: 0.4333 sec
0.1108 0.1005 0.0876 0.1350 0.1157 0.0952 0.0812 0.0795 0.0885 0.0887 0.0815 0.0860 0.0927 0.0913 0.0862 0.0898 

[TRAIN] Epoch[1](387/1500); Loss: 0.084479; Backpropagation: 0.1008 sec; Batch: 0.4367 sec
0.1311 0.1372 0.1032 0.0862 0.0727 0.0872 0.0815 0.0692 0.0740 0.0739 0.0708 0.0732 0.0711 0.0714 0.0741 0.0748 

[TRAIN] Epoch[1](388/1500); Loss: 0.096423; Backpropagation: 0.0994 sec; Batch: 0.4346 sec
0.1232 0.1723 0.1716 0.1438 0.1089 0.0806 0.0777 0.0824 0.0723 0.0722 0.0745 0.0726 0.0720 0.0725 0.0730 0.0730 

[TRAIN] Epoch[1](389/1500); Loss: 0.125926; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.2213 0.1708 0.1246 0.1223 0.1176 0.1168 0.1253 0.1112 0.1095 0.1130 0.1122 0.1101 0.1112 0.1148 0.1146 0.1194 

[TRAIN] Epoch[1](390/1500); Loss: 0.102441; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1442 0.1220 0.1195 0.1236 0.1165 0.1004 0.0953 0.0935 0.0919 0.0906 0.0885 0.0879 0.0930 0.0889 0.0896 0.0936 

[TRAIN] Epoch[1](391/1500); Loss: 0.133806; Backpropagation: 0.0986 sec; Batch: 0.4343 sec
0.1778 0.1403 0.1329 0.1579 0.1538 0.1380 0.1290 0.1256 0.1247 0.1233 0.1215 0.1207 0.1254 0.1231 0.1219 0.1250 

[TRAIN] Epoch[1](392/1500); Loss: 0.155238; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.2127 0.1738 0.1560 0.1864 0.1798 0.1595 0.1455 0.1428 0.1436 0.1423 0.1376 0.1384 0.1406 0.1388 0.1403 0.1457 

[TRAIN] Epoch[1](393/1500); Loss: 0.145086; Backpropagation: 0.0990 sec; Batch: 0.4338 sec
0.1631 0.1608 0.1703 0.1864 0.1841 0.1616 0.1416 0.1330 0.1304 0.1306 0.1270 0.1233 0.1254 0.1289 0.1276 0.1273 

[TRAIN] Epoch[1](394/1500); Loss: 0.091651; Backpropagation: 0.0994 sec; Batch: 0.4348 sec
0.1024 0.1054 0.1086 0.1155 0.1075 0.0874 0.0797 0.0787 0.0815 0.0808 0.0797 0.0860 0.0861 0.0841 0.0932 0.0898 

[TRAIN] Epoch[1](395/1500); Loss: 0.093984; Backpropagation: 0.0992 sec; Batch: 0.4725 sec
0.0912 0.1026 0.1575 0.1339 0.1002 0.0789 0.0797 0.0875 0.0833 0.0807 0.0864 0.0807 0.0807 0.0925 0.0857 0.0822 

[TRAIN] Epoch[1](396/1500); Loss: 0.126784; Backpropagation: 0.0991 sec; Batch: 0.4637 sec
0.1476 0.1390 0.1260 0.1389 0.1384 0.1249 0.1161 0.1150 0.1199 0.1153 0.1174 0.1240 0.1201 0.1242 0.1343 0.1274 

[TRAIN] Epoch[1](397/1500); Loss: 0.100977; Backpropagation: 0.0991 sec; Batch: 0.4479 sec
0.1067 0.1213 0.1721 0.1416 0.1117 0.0920 0.0931 0.0851 0.0836 0.0888 0.0869 0.0818 0.0877 0.0866 0.0842 0.0924 

[TRAIN] Epoch[1](398/1500); Loss: 0.147474; Backpropagation: 0.0989 sec; Batch: 0.4721 sec
0.1711 0.1863 0.2010 0.1792 0.1619 0.1513 0.1423 0.1348 0.1294 0.1313 0.1298 0.1290 0.1260 0.1303 0.1272 0.1288 

[TRAIN] Epoch[1](399/1500); Loss: 0.115199; Backpropagation: 0.0990 sec; Batch: 0.4337 sec
0.1182 0.1423 0.1220 0.1212 0.1032 0.1040 0.1003 0.0999 0.1117 0.1064 0.1079 0.1156 0.1146 0.1167 0.1327 0.1265 

[TRAIN] Epoch[1](400/1500); Loss: 0.170207; Backpropagation: 0.0976 sec; Batch: 0.4324 sec
0.1896 0.1920 0.2064 0.1825 0.1697 0.1676 0.1653 0.1601 0.1651 0.1583 0.1614 0.1593 0.1630 0.1578 0.1626 0.1627 

[TRAIN] Epoch[1](401/1500); Loss: 0.099868; Backpropagation: 0.0985 sec; Batch: 0.4460 sec
0.0897 0.1227 0.1660 0.1290 0.1002 0.0847 0.0943 0.0850 0.0813 0.0920 0.0892 0.0787 0.1011 0.0916 0.0845 0.1080 

[TRAIN] Epoch[1](402/1500); Loss: 0.164306; Backpropagation: 0.0983 sec; Batch: 0.4339 sec
0.1861 0.1866 0.1724 0.1654 0.1576 0.1548 0.1535 0.1558 0.1562 0.1582 0.1591 0.1595 0.1627 0.1648 0.1659 0.1701 

[TRAIN] Epoch[1](403/1500); Loss: 0.082479; Backpropagation: 0.0983 sec; Batch: 0.4338 sec
0.1288 0.0693 0.1027 0.0665 0.0728 0.0851 0.0708 0.0760 0.0676 0.0825 0.0669 0.0899 0.0675 0.0987 0.0743 0.1002 

[TRAIN] Epoch[1](404/1500); Loss: 0.068204; Backpropagation: 0.0991 sec; Batch: 0.4351 sec
0.1841 0.0776 0.0530 0.0419 0.0552 0.0380 0.0629 0.0379 0.0697 0.0430 0.0767 0.0505 0.0837 0.0589 0.0906 0.0677 

[TRAIN] Epoch[1](405/1500); Loss: 0.079570; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.0834 0.0913 0.0671 0.0711 0.0650 0.0722 0.0690 0.0754 0.0732 0.0794 0.0788 0.0846 0.0845 0.0906 0.0907 0.0968 

[TRAIN] Epoch[1](406/1500); Loss: 0.150643; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.2094 0.2256 0.1743 0.1320 0.1336 0.1356 0.1345 0.1369 0.1344 0.1400 0.1368 0.1428 0.1385 0.1460 0.1419 0.1480 

[TRAIN] Epoch[1](407/1500); Loss: 0.135307; Backpropagation: 0.0991 sec; Batch: 0.4339 sec
0.1667 0.1753 0.1549 0.1290 0.1368 0.1254 0.1281 0.1217 0.1263 0.1244 0.1268 0.1274 0.1284 0.1305 0.1308 0.1323 

[TRAIN] Epoch[1](408/1500); Loss: 0.134379; Backpropagation: 0.0995 sec; Batch: 0.4353 sec
0.1738 0.1663 0.1471 0.1287 0.1235 0.1211 0.1217 0.1229 0.1251 0.1257 0.1280 0.1297 0.1322 0.1332 0.1338 0.1373 

[TRAIN] Epoch[1](409/1500); Loss: 0.167226; Backpropagation: 0.0995 sec; Batch: 0.4357 sec
0.2179 0.2026 0.1957 0.1753 0.1639 0.1584 0.1544 0.1529 0.1532 0.1528 0.1551 0.1532 0.1622 0.1561 0.1620 0.1600 

[TRAIN] Epoch[1](410/1500); Loss: 0.123620; Backpropagation: 0.0995 sec; Batch: 0.4382 sec
0.1704 0.1755 0.1420 0.1181 0.1178 0.1074 0.1121 0.1047 0.1121 0.1076 0.1133 0.1123 0.1169 0.1198 0.1227 0.1254 

[TRAIN] Epoch[1](411/1500); Loss: 0.189118; Backpropagation: 0.1008 sec; Batch: 0.4452 sec
0.2265 0.2158 0.2096 0.1954 0.1847 0.1812 0.1831 0.1780 0.1791 0.1773 0.1816 0.1789 0.1820 0.1815 0.1868 0.1844 

[TRAIN] Epoch[1](412/1500); Loss: 0.188417; Backpropagation: 0.0985 sec; Batch: 0.4878 sec
0.2200 0.1850 0.2035 0.1809 0.1774 0.1752 0.1744 0.1756 0.1791 0.1806 0.1830 0.1853 0.1924 0.1941 0.2015 0.2066 

[TRAIN] Epoch[1](413/1500); Loss: 0.155088; Backpropagation: 0.0992 sec; Batch: 0.4424 sec
0.1766 0.1681 0.1719 0.1583 0.1519 0.1508 0.1448 0.1468 0.1422 0.1459 0.1451 0.1485 0.1538 0.1559 0.1580 0.1628 

[TRAIN] Epoch[1](414/1500); Loss: 0.218685; Backpropagation: 0.0983 sec; Batch: 0.4439 sec
0.2539 0.2098 0.2435 0.2177 0.2130 0.2099 0.2083 0.2079 0.2078 0.2093 0.2094 0.2151 0.2170 0.2213 0.2233 0.2317 

[TRAIN] Epoch[1](415/1500); Loss: 0.124447; Backpropagation: 0.0988 sec; Batch: 0.4455 sec
0.1655 0.1811 0.1415 0.1269 0.1107 0.1130 0.1029 0.1074 0.1058 0.1071 0.1125 0.1126 0.1208 0.1221 0.1301 0.1311 

[TRAIN] Epoch[1](416/1500); Loss: 0.115636; Backpropagation: 0.0993 sec; Batch: 0.4390 sec
0.1351 0.1469 0.1220 0.1184 0.1075 0.1106 0.1015 0.1085 0.1061 0.1129 0.1081 0.1131 0.1121 0.1147 0.1150 0.1176 

[TRAIN] Epoch[1](417/1500); Loss: 0.155052; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.1934 0.2443 0.1634 0.1668 0.1396 0.1472 0.1358 0.1363 0.1339 0.1332 0.1365 0.1372 0.1449 0.1494 0.1556 0.1636 

[TRAIN] Epoch[1](418/1500); Loss: 0.124123; Backpropagation: 0.0994 sec; Batch: 0.4352 sec
0.1425 0.1335 0.1299 0.1288 0.1202 0.1250 0.1196 0.1274 0.1171 0.1237 0.1123 0.1212 0.1156 0.1210 0.1199 0.1284 

[TRAIN] Epoch[1](419/1500); Loss: 0.130491; Backpropagation: 0.0991 sec; Batch: 0.4741 sec
0.1641 0.1493 0.1491 0.1305 0.1227 0.1161 0.1142 0.1168 0.1183 0.1243 0.1220 0.1282 0.1288 0.1346 0.1324 0.1365 

[TRAIN] Epoch[1](420/1500); Loss: 0.085552; Backpropagation: 0.0991 sec; Batch: 0.4347 sec
0.1245 0.1508 0.0921 0.1032 0.0744 0.0864 0.0658 0.0739 0.0644 0.0692 0.0678 0.0716 0.0742 0.0812 0.0805 0.0889 

[TRAIN] Epoch[1](421/1500); Loss: 0.075079; Backpropagation: 0.0996 sec; Batch: 0.4370 sec
0.0941 0.1251 0.0695 0.0832 0.0648 0.0718 0.0655 0.0660 0.0644 0.0657 0.0660 0.0679 0.0682 0.0766 0.0736 0.0788 

[TRAIN] Epoch[1](422/1500); Loss: 0.100384; Backpropagation: 0.0987 sec; Batch: 0.4344 sec
0.1490 0.1273 0.1285 0.1077 0.0958 0.0947 0.0868 0.0920 0.0835 0.0907 0.0845 0.0928 0.0877 0.0957 0.0911 0.0983 

[TRAIN] Epoch[1](423/1500); Loss: 0.131573; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1699 0.1409 0.1467 0.1463 0.1365 0.1367 0.1292 0.1263 0.1256 0.1217 0.1229 0.1208 0.1209 0.1203 0.1200 0.1203 

[TRAIN] Epoch[1](424/1500); Loss: 0.159129; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.2009 0.1917 0.1893 0.1753 0.1678 0.1614 0.1545 0.1521 0.1478 0.1470 0.1446 0.1447 0.1414 0.1427 0.1421 0.1428 

[TRAIN] Epoch[1](425/1500); Loss: 0.176798; Backpropagation: 0.0987 sec; Batch: 0.4339 sec
0.2441 0.2183 0.2288 0.2013 0.1824 0.1713 0.1628 0.1575 0.1536 0.1534 0.1527 0.1566 0.1577 0.1604 0.1617 0.1662 

[TRAIN] Epoch[1](426/1500); Loss: 0.252781; Backpropagation: 0.0988 sec; Batch: 0.4332 sec
0.3380 0.3074 0.3226 0.2942 0.2771 0.2629 0.2516 0.2408 0.2326 0.2249 0.2208 0.2172 0.2140 0.2129 0.2139 0.2135 

[TRAIN] Epoch[1](427/1500); Loss: 0.218803; Backpropagation: 0.0985 sec; Batch: 0.4413 sec
0.2939 0.2648 0.2771 0.2598 0.2410 0.2344 0.2179 0.2132 0.2019 0.1979 0.1901 0.1869 0.1825 0.1815 0.1790 0.1791 

[TRAIN] Epoch[1](428/1500); Loss: 0.261077; Backpropagation: 0.0988 sec; Batch: 0.4624 sec
0.4544 0.3839 0.3947 0.3506 0.3233 0.2987 0.2745 0.2473 0.2271 0.2037 0.1875 0.1750 0.1659 0.1631 0.1628 0.1649 

[TRAIN] Epoch[1](429/1500); Loss: 0.131886; Backpropagation: 0.0992 sec; Batch: 0.4758 sec
0.1717 0.1376 0.1293 0.1181 0.1137 0.1156 0.1186 0.1265 0.1268 0.1324 0.1340 0.1356 0.1355 0.1379 0.1374 0.1395 

[TRAIN] Epoch[1](430/1500); Loss: 0.125330; Backpropagation: 0.0991 sec; Batch: 0.4478 sec
0.1913 0.1478 0.1244 0.1130 0.1090 0.1099 0.1112 0.1212 0.1167 0.1259 0.1150 0.1257 0.1170 0.1264 0.1196 0.1310 

[TRAIN] Epoch[1](431/1500); Loss: 0.177337; Backpropagation: 0.0991 sec; Batch: 0.4504 sec
0.4223 0.3626 0.2976 0.2301 0.1701 0.1155 0.0978 0.1085 0.1122 0.1331 0.1208 0.1391 0.1198 0.1392 0.1241 0.1446 

[TRAIN] Epoch[1](432/1500); Loss: 0.161364; Backpropagation: 0.0991 sec; Batch: 0.4350 sec
0.2451 0.2087 0.1827 0.1663 0.1533 0.1524 0.1486 0.1591 0.1461 0.1571 0.1412 0.1533 0.1371 0.1488 0.1354 0.1466 

[TRAIN] Epoch[1](433/1500); Loss: 0.150443; Backpropagation: 0.0985 sec; Batch: 0.4490 sec
0.2218 0.1882 0.1569 0.1496 0.1370 0.1383 0.1373 0.1417 0.1381 0.1465 0.1385 0.1453 0.1365 0.1456 0.1389 0.1469 

[TRAIN] Epoch[1](434/1500); Loss: 0.103694; Backpropagation: 0.0990 sec; Batch: 0.4485 sec
0.1226 0.1019 0.0904 0.0978 0.0864 0.1007 0.0908 0.1057 0.0910 0.1068 0.0961 0.1112 0.1010 0.1170 0.1111 0.1284 

[TRAIN] Epoch[1](435/1500); Loss: 0.124598; Backpropagation: 0.0993 sec; Batch: 0.4505 sec
0.2051 0.1688 0.1277 0.1395 0.1149 0.1049 0.0992 0.1095 0.1006 0.1121 0.1077 0.1169 0.1143 0.1234 0.1178 0.1311 

[TRAIN] Epoch[1](436/1500); Loss: 0.151792; Backpropagation: 0.0990 sec; Batch: 0.4495 sec
0.2302 0.1934 0.1757 0.1691 0.1493 0.1383 0.1355 0.1361 0.1389 0.1385 0.1374 0.1384 0.1370 0.1368 0.1367 0.1373 

[TRAIN] Epoch[1](437/1500); Loss: 0.176654; Backpropagation: 0.0991 sec; Batch: 0.4473 sec
0.2745 0.2360 0.2035 0.1977 0.1758 0.1664 0.1639 0.1680 0.1591 0.1643 0.1514 0.1588 0.1482 0.1560 0.1478 0.1552 

[TRAIN] Epoch[1](438/1500); Loss: 0.151491; Backpropagation: 0.1010 sec; Batch: 0.4763 sec
0.2355 0.1996 0.1764 0.1784 0.1537 0.1407 0.1329 0.1339 0.1302 0.1374 0.1312 0.1359 0.1313 0.1371 0.1316 0.1381 

[TRAIN] Epoch[1](439/1500); Loss: 0.135699; Backpropagation: 0.0993 sec; Batch: 0.4529 sec
0.1894 0.1604 0.1351 0.1456 0.1279 0.1295 0.1222 0.1299 0.1239 0.1309 0.1243 0.1305 0.1273 0.1338 0.1280 0.1326 

[TRAIN] Epoch[1](440/1500); Loss: 0.125192; Backpropagation: 0.0991 sec; Batch: 0.4479 sec
0.2351 0.1751 0.1686 0.1419 0.1150 0.1079 0.1016 0.1008 0.1048 0.1035 0.1056 0.1053 0.1080 0.1070 0.1115 0.1114 

[TRAIN] Epoch[1](441/1500); Loss: 0.159530; Backpropagation: 0.0985 sec; Batch: 0.4505 sec
0.2495 0.2086 0.1933 0.1824 0.1593 0.1519 0.1437 0.1403 0.1394 0.1382 0.1391 0.1394 0.1401 0.1411 0.1422 0.1440 

[TRAIN] Epoch[1](442/1500); Loss: 0.158442; Backpropagation: 0.0991 sec; Batch: 0.4497 sec
0.2174 0.1858 0.1694 0.1706 0.1578 0.1532 0.1491 0.1515 0.1466 0.1481 0.1455 0.1474 0.1457 0.1486 0.1472 0.1512 

[TRAIN] Epoch[1](443/1500); Loss: 0.136760; Backpropagation: 0.0992 sec; Batch: 0.4502 sec
0.1466 0.1467 0.1357 0.1445 0.1364 0.1365 0.1345 0.1339 0.1327 0.1323 0.1323 0.1331 0.1338 0.1357 0.1349 0.1386 

[TRAIN] Epoch[1](444/1500); Loss: 0.103560; Backpropagation: 0.0995 sec; Batch: 0.4345 sec
0.1954 0.1465 0.1086 0.1109 0.0934 0.0961 0.0875 0.0922 0.0879 0.0907 0.0887 0.0913 0.0892 0.0908 0.0942 0.0938 

[TRAIN] Epoch[1](445/1500); Loss: 0.158585; Backpropagation: 0.0995 sec; Batch: 0.4350 sec
0.3161 0.2492 0.2075 0.1741 0.1443 0.1363 0.1372 0.1308 0.1311 0.1300 0.1307 0.1290 0.1301 0.1299 0.1308 0.1304 

[TRAIN] Epoch[1](446/1500); Loss: 0.115967; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.1925 0.1442 0.1222 0.1079 0.1119 0.1053 0.1091 0.1049 0.1073 0.1053 0.1066 0.1055 0.1071 0.1082 0.1078 0.1096 

[TRAIN] Epoch[1](447/1500); Loss: 0.156911; Backpropagation: 0.0994 sec; Batch: 0.4353 sec
0.2237 0.1920 0.1693 0.1556 0.1520 0.1491 0.1503 0.1472 0.1475 0.1461 0.1468 0.1453 0.1466 0.1455 0.1470 0.1464 

[TRAIN] Epoch[1](448/1500); Loss: 0.194745; Backpropagation: 0.0990 sec; Batch: 0.4472 sec
0.2249 0.2455 0.2111 0.1806 0.1932 0.1815 0.1880 0.1817 0.1863 0.1832 0.1865 0.1862 0.1899 0.1907 0.1919 0.1948 

[TRAIN] Epoch[1](449/1500); Loss: 0.137827; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.2111 0.1869 0.1548 0.1328 0.1276 0.1251 0.1278 0.1239 0.1287 0.1241 0.1288 0.1232 0.1302 0.1233 0.1317 0.1252 

[TRAIN] Epoch[1](450/1500); Loss: 0.127648; Backpropagation: 0.1002 sec; Batch: 0.4355 sec
0.1790 0.1535 0.1345 0.1286 0.1178 0.1253 0.1170 0.1229 0.1166 0.1220 0.1173 0.1219 0.1189 0.1224 0.1206 0.1240 

[TRAIN] Epoch[1](451/1500); Loss: 0.131884; Backpropagation: 0.0996 sec; Batch: 0.4345 sec
0.2288 0.1743 0.1397 0.1257 0.1221 0.1207 0.1212 0.1195 0.1196 0.1188 0.1189 0.1193 0.1192 0.1206 0.1201 0.1218 

[TRAIN] Epoch[1](452/1500); Loss: 0.140655; Backpropagation: 0.0985 sec; Batch: 0.4475 sec
0.2522 0.1882 0.1530 0.1397 0.1356 0.1325 0.1296 0.1284 0.1265 0.1247 0.1238 0.1234 0.1227 0.1233 0.1226 0.1244 

[TRAIN] Epoch[1](453/1500); Loss: 0.140802; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.2148 0.1768 0.1514 0.1417 0.1285 0.1371 0.1270 0.1347 0.1257 0.1340 0.1255 0.1340 0.1263 0.1340 0.1267 0.1347 

[TRAIN] Epoch[1](454/1500); Loss: 0.127534; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.1924 0.1486 0.1318 0.1243 0.1230 0.1213 0.1216 0.1196 0.1201 0.1188 0.1196 0.1191 0.1198 0.1197 0.1197 0.1209 

[TRAIN] Epoch[1](455/1500); Loss: 0.104749; Backpropagation: 0.0995 sec; Batch: 0.4481 sec
0.2535 0.1822 0.1295 0.0956 0.0876 0.0813 0.0905 0.0775 0.0867 0.0770 0.0859 0.0792 0.0868 0.0831 0.0901 0.0894 

[TRAIN] Epoch[1](456/1500); Loss: 0.209984; Backpropagation: 0.0997 sec; Batch: 0.4346 sec
0.2471 0.2242 0.2126 0.2001 0.2015 0.2001 0.2003 0.2007 0.2008 0.2032 0.2043 0.2077 0.2086 0.2131 0.2144 0.2209 

[TRAIN] Epoch[1](457/1500); Loss: 0.142280; Backpropagation: 0.0995 sec; Batch: 0.4348 sec
0.1998 0.1602 0.1469 0.1406 0.1401 0.1372 0.1366 0.1343 0.1341 0.1340 0.1342 0.1345 0.1356 0.1353 0.1359 0.1371 

[TRAIN] Epoch[1](458/1500); Loss: 0.071171; Backpropagation: 0.0990 sec; Batch: 0.4339 sec
0.1357 0.0641 0.0672 0.0746 0.0631 0.0735 0.0621 0.0714 0.0624 0.0673 0.0612 0.0666 0.0646 0.0664 0.0685 0.0700 

[TRAIN] Epoch[1](459/1500); Loss: 0.090970; Backpropagation: 0.0989 sec; Batch: 0.4340 sec
0.1399 0.0986 0.0841 0.0820 0.0836 0.0849 0.0810 0.0868 0.0816 0.0897 0.0827 0.0932 0.0843 0.0966 0.0861 0.1003 

[TRAIN] Epoch[1](460/1500); Loss: 0.131031; Backpropagation: 0.0984 sec; Batch: 0.4512 sec
0.2465 0.1649 0.1343 0.1146 0.1204 0.1107 0.1152 0.1132 0.1148 0.1182 0.1166 0.1234 0.1211 0.1292 0.1255 0.1279 

[TRAIN] Epoch[1](461/1500); Loss: 0.164813; Backpropagation: 0.0987 sec; Batch: 0.4471 sec
0.2479 0.1773 0.1658 0.1634 0.1513 0.1542 0.1493 0.1532 0.1498 0.1538 0.1550 0.1560 0.1607 0.1640 0.1645 0.1708 

[TRAIN] Epoch[1](462/1500); Loss: 0.151237; Backpropagation: 0.0990 sec; Batch: 0.4390 sec
0.2561 0.1874 0.1748 0.1451 0.1352 0.1256 0.1293 0.1278 0.1334 0.1311 0.1380 0.1402 0.1444 0.1475 0.1514 0.1525 

[TRAIN] Epoch[1](463/1500); Loss: 0.095962; Backpropagation: 0.0986 sec; Batch: 0.4344 sec
0.1326 0.0603 0.0791 0.0736 0.0810 0.0712 0.0897 0.0820 0.0981 0.0882 0.1038 0.0947 0.1140 0.1064 0.1247 0.1358 

[TRAIN] Epoch[1](464/1500); Loss: 0.675877; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.3427 0.2599 0.2958 0.4008 0.4327 0.4927 0.5739 0.6299 0.6947 0.7634 0.8254 0.8898 0.9564 1.0207 1.0846 1.1506 

[TRAIN] Epoch[1](465/1500); Loss: 0.492143; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.2240 0.2002 0.2107 0.2598 0.2792 0.3228 0.3848 0.4324 0.4896 0.5496 0.6053 0.6653 0.7247 0.7822 0.8416 0.9020 

[TRAIN] Epoch[1](466/1500); Loss: 0.484818; Backpropagation: 0.0987 sec; Batch: 0.4338 sec
0.2035 0.1644 0.1946 0.2655 0.2845 0.3321 0.3940 0.4395 0.4935 0.5489 0.6010 0.6585 0.7116 0.7658 0.8226 0.8771 

[TRAIN] Epoch[1](467/1500); Loss: 0.348093; Backpropagation: 0.1028 sec; Batch: 0.4392 sec
0.2089 0.2574 0.2221 0.1782 0.1751 0.1742 0.1988 0.2326 0.2807 0.3375 0.3939 0.4571 0.5183 0.5813 0.6448 0.7085 

[TRAIN] Epoch[1](468/1500); Loss: 0.305722; Backpropagation: 0.0996 sec; Batch: 0.4345 sec
0.3083 0.3899 0.3429 0.2570 0.2420 0.2039 0.1743 0.1770 0.1958 0.2300 0.2690 0.3158 0.3651 0.4179 0.4737 0.5291 

[TRAIN] Epoch[1](469/1500); Loss: 0.587666; Backpropagation: 0.0989 sec; Batch: 0.4343 sec
0.3387 0.2576 0.3187 0.4043 0.4155 0.4662 0.5220 0.5578 0.6062 0.6527 0.6960 0.7438 0.7880 0.8328 0.8782 0.9241 

[TRAIN] Epoch[1](470/1500); Loss: 0.449754; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.2717 0.2194 0.2628 0.3194 0.3330 0.3619 0.4007 0.4288 0.4603 0.4939 0.5256 0.5582 0.5905 0.6241 0.6563 0.6893 

[TRAIN] Epoch[1](471/1500); Loss: 0.437796; Backpropagation: 0.0986 sec; Batch: 0.4341 sec
0.3403 0.3233 0.3353 0.3490 0.3499 0.3626 0.3797 0.3940 0.4200 0.4469 0.4734 0.5041 0.5341 0.5658 0.5965 0.6299 

[TRAIN] Epoch[1](472/1500); Loss: 0.574605; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.4553 0.3839 0.4201 0.4624 0.4622 0.4956 0.5267 0.5463 0.5786 0.6068 0.6347 0.6652 0.6954 0.7231 0.7538 0.7836 

[TRAIN] Epoch[1](473/1500); Loss: 0.435784; Backpropagation: 0.0991 sec; Batch: 0.4350 sec
0.3385 0.2777 0.3170 0.3469 0.3467 0.3753 0.3994 0.4149 0.4399 0.4623 0.4841 0.5074 0.5307 0.5534 0.5777 0.6007 

[TRAIN] Epoch[1](474/1500); Loss: 0.236471; Backpropagation: 0.0991 sec; Batch: 0.4335 sec
0.2111 0.2016 0.1913 0.1854 0.1838 0.1910 0.1996 0.2088 0.2219 0.2363 0.2512 0.2664 0.2835 0.2998 0.3169 0.3349 

[TRAIN] Epoch[1](475/1500); Loss: 0.192280; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1576 0.1556 0.1570 0.1595 0.1621 0.1689 0.1755 0.1819 0.1896 0.1976 0.2058 0.2147 0.2236 0.2328 0.2424 0.2520 

[TRAIN] Epoch[1](476/1500); Loss: 0.263037; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.2471 0.2343 0.2377 0.2388 0.2426 0.2465 0.2498 0.2544 0.2597 0.2652 0.2715 0.2779 0.2847 0.2920 0.2994 0.3072 

[TRAIN] Epoch[1](477/1500); Loss: 0.394174; Backpropagation: 0.0987 sec; Batch: 0.4338 sec
0.4029 0.3768 0.4013 0.3960 0.3888 0.3917 0.3924 0.3909 0.3912 0.3921 0.3929 0.3940 0.3955 0.3976 0.4000 0.4026 

[TRAIN] Epoch[1](478/1500); Loss: 0.205793; Backpropagation: 0.0991 sec; Batch: 0.4345 sec
0.1740 0.1816 0.1827 0.1849 0.1892 0.1914 0.1952 0.1996 0.2043 0.2091 0.2144 0.2203 0.2265 0.2329 0.2396 0.2468 

[TRAIN] Epoch[1](479/1500); Loss: 0.211867; Backpropagation: 0.0999 sec; Batch: 0.4358 sec
0.1996 0.1936 0.1975 0.1962 0.1969 0.1977 0.2000 0.2030 0.2066 0.2108 0.2160 0.2215 0.2275 0.2340 0.2409 0.2481 

[TRAIN] Epoch[1](480/1500); Loss: 0.244861; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.2394 0.2230 0.2303 0.2261 0.2260 0.2282 0.2315 0.2349 0.2391 0.2437 0.2493 0.2553 0.2618 0.2689 0.2762 0.2840 

[TRAIN] Epoch[1](481/1500); Loss: 0.157144; Backpropagation: 0.0992 sec; Batch: 0.4341 sec
0.1542 0.1422 0.1525 0.1473 0.1439 0.1433 0.1445 0.1464 0.1493 0.1529 0.1577 0.1631 0.1691 0.1754 0.1825 0.1900 

[TRAIN] Epoch[1](482/1500); Loss: 0.182746; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1490 0.1546 0.1497 0.1536 0.1608 0.1642 0.1687 0.1748 0.1809 0.1873 0.1943 0.2016 0.2091 0.2169 0.2250 0.2334 

[TRAIN] Epoch[1](483/1500); Loss: 0.154362; Backpropagation: 0.0986 sec; Batch: 0.4500 sec
0.1651 0.1493 0.1572 0.1521 0.1477 0.1467 0.1464 0.1460 0.1467 0.1485 0.1510 0.1541 0.1578 0.1621 0.1669 0.1722 

[TRAIN] Epoch[1](484/1500); Loss: 0.131468; Backpropagation: 0.0987 sec; Batch: 0.4348 sec
0.1382 0.1159 0.1159 0.1120 0.1134 0.1131 0.1144 0.1180 0.1222 0.1272 0.1334 0.1403 0.1475 0.1556 0.1639 0.1726 

[TRAIN] Epoch[1](485/1500); Loss: 0.221202; Backpropagation: 0.1082 sec; Batch: 0.4446 sec
0.2121 0.2144 0.2089 0.2090 0.2115 0.2126 0.2138 0.2161 0.2186 0.2212 0.2242 0.2275 0.2312 0.2352 0.2393 0.2437 

[TRAIN] Epoch[1](486/1500); Loss: 0.250321; Backpropagation: 0.1031 sec; Batch: 0.4457 sec
0.2289 0.2422 0.2344 0.2370 0.2411 0.2422 0.2440 0.2467 0.2495 0.2523 0.2555 0.2588 0.2624 0.2661 0.2700 0.2740 

[TRAIN] Epoch[1](487/1500); Loss: 0.171882; Backpropagation: 0.0990 sec; Batch: 0.4333 sec
0.1767 0.1709 0.1766 0.1739 0.1714 0.1709 0.1703 0.1695 0.1693 0.1693 0.1696 0.1701 0.1709 0.1721 0.1735 0.1751 

[TRAIN] Epoch[1](488/1500); Loss: 0.212622; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.2020 0.2103 0.2010 0.2026 0.2055 0.2060 0.2069 0.2088 0.2107 0.2127 0.2151 0.2178 0.2207 0.2239 0.2272 0.2308 

[TRAIN] Epoch[1](489/1500); Loss: 0.338460; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.3514 0.3435 0.3591 0.3563 0.3487 0.3462 0.3439 0.3406 0.3372 0.3346 0.3317 0.3291 0.3268 0.3243 0.3221 0.3200 

[TRAIN] Epoch[1](490/1500); Loss: 0.199464; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.1941 0.1898 0.1948 0.1953 0.1946 0.1955 0.1966 0.1974 0.1986 0.1999 0.2013 0.2029 0.2046 0.2065 0.2086 0.2108 

[TRAIN] Epoch[1](491/1500); Loss: 0.281978; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.2681 0.2882 0.2796 0.2800 0.2809 0.2810 0.2812 0.2816 0.2820 0.2824 0.2829 0.2834 0.2840 0.2847 0.2854 0.2863 

[TRAIN] Epoch[1](492/1500); Loss: 0.210630; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.2085 0.2104 0.2074 0.2070 0.2074 0.2075 0.2077 0.2083 0.2089 0.2097 0.2107 0.2119 0.2134 0.2151 0.2170 0.2191 

[TRAIN] Epoch[1](493/1500); Loss: 0.191101; Backpropagation: 0.0988 sec; Batch: 0.4344 sec
0.2020 0.1936 0.2020 0.2000 0.1948 0.1929 0.1915 0.1893 0.1877 0.1865 0.1857 0.1852 0.1852 0.1858 0.1869 0.1884 

[TRAIN] Epoch[1](494/1500); Loss: 0.230861; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.2084 0.2280 0.2069 0.2089 0.2169 0.2199 0.2223 0.2266 0.2305 0.2342 0.2382 0.2422 0.2464 0.2505 0.2548 0.2591 

[TRAIN] Epoch[1](495/1500); Loss: 0.303020; Backpropagation: 0.0986 sec; Batch: 0.4341 sec
0.2834 0.3149 0.2954 0.2965 0.2994 0.2996 0.3007 0.3019 0.3027 0.3039 0.3051 0.3062 0.3075 0.3089 0.3103 0.3119 

[TRAIN] Epoch[1](496/1500); Loss: 0.178665; Backpropagation: 0.0994 sec; Batch: 0.4347 sec
0.1737 0.1854 0.1781 0.1780 0.1769 0.1760 0.1757 0.1757 0.1757 0.1762 0.1771 0.1783 0.1798 0.1818 0.1839 0.1864 

[TRAIN] Epoch[1](497/1500); Loss: 0.145152; Backpropagation: 0.0989 sec; Batch: 0.4342 sec
0.1550 0.1461 0.1534 0.1530 0.1485 0.1469 0.1457 0.1440 0.1427 0.1418 0.1411 0.1406 0.1405 0.1406 0.1410 0.1418 

[TRAIN] Epoch[1](498/1500); Loss: 0.223528; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2293 0.2545 0.2254 0.2227 0.2246 0.2228 0.2219 0.2216 0.2209 0.2202 0.2197 0.2192 0.2188 0.2185 0.2182 0.2180 

[TRAIN] Epoch[1](499/1500); Loss: 0.126360; Backpropagation: 0.0987 sec; Batch: 0.4343 sec
0.1315 0.1410 0.1234 0.1226 0.1229 0.1217 0.1213 0.1213 0.1215 0.1222 0.1234 0.1250 0.1269 0.1294 0.1322 0.1354 

[TRAIN] Epoch[1](500/1500); Loss: 0.200860; Backpropagation: 0.0988 sec; Batch: 0.4340 sec
0.2126 0.2055 0.2028 0.2028 0.2008 0.1995 0.1991 0.1985 0.1980 0.1977 0.1978 0.1980 0.1986 0.1995 0.2005 0.2018 

[TRAIN] Epoch[1](501/1500); Loss: 0.153218; Backpropagation: 0.0987 sec; Batch: 0.4342 sec
0.1605 0.1658 0.1578 0.1566 0.1556 0.1538 0.1520 0.1508 0.1499 0.1492 0.1489 0.1490 0.1492 0.1499 0.1507 0.1518 

[TRAIN] Epoch[1](502/1500); Loss: 0.217039; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.2179 0.2351 0.2138 0.2136 0.2148 0.2139 0.2140 0.2144 0.2146 0.2150 0.2155 0.2163 0.2169 0.2179 0.2189 0.2200 

[TRAIN] Epoch[1](503/1500); Loss: 0.264171; Backpropagation: 0.0986 sec; Batch: 0.4341 sec
0.2848 0.2732 0.2681 0.2682 0.2663 0.2642 0.2640 0.2628 0.2619 0.2612 0.2603 0.2596 0.2588 0.2583 0.2575 0.2574 

[TRAIN] Epoch[1](504/1500); Loss: 0.186583; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.1985 0.1932 0.1901 0.1894 0.1880 0.1869 0.1863 0.1855 0.1846 0.1842 0.1837 0.1833 0.1831 0.1828 0.1828 0.1829 

[TRAIN] Epoch[1](505/1500); Loss: 0.142921; Backpropagation: 0.0986 sec; Batch: 0.4339 sec
0.1609 0.1480 0.1431 0.1440 0.1417 0.1405 0.1401 0.1396 0.1395 0.1395 0.1396 0.1402 0.1409 0.1418 0.1431 0.1443 

[TRAIN] Epoch[1](506/1500); Loss: 0.121533; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1494 0.1792 0.1316 0.1282 0.1290 0.1234 0.1194 0.1167 0.1137 0.1110 0.1092 0.1077 0.1067 0.1063 0.1063 0.1067 

[TRAIN] Epoch[1](507/1500); Loss: 0.085184; Backpropagation: 0.0988 sec; Batch: 0.4342 sec
0.0807 0.0990 0.0884 0.0883 0.0877 0.0866 0.0846 0.0837 0.0830 0.0825 0.0821 0.0822 0.0824 0.0830 0.0839 0.0849 

[TRAIN] Epoch[1](508/1500); Loss: 0.167430; Backpropagation: 0.1025 sec; Batch: 0.4377 sec
0.1945 0.2008 0.1922 0.1888 0.1821 0.1767 0.1703 0.1653 0.1606 0.1564 0.1529 0.1502 0.1482 0.1469 0.1465 0.1465 

[TRAIN] Epoch[1](509/1500); Loss: 0.166137; Backpropagation: 0.0996 sec; Batch: 0.4349 sec
0.1801 0.1929 0.1735 0.1720 0.1699 0.1664 0.1634 0.1614 0.1596 0.1585 0.1580 0.1581 0.1589 0.1601 0.1616 0.1639 

[TRAIN] Epoch[1](510/1500); Loss: 0.247078; Backpropagation: 0.0997 sec; Batch: 0.4470 sec
0.2883 0.3092 0.2727 0.2690 0.2660 0.2577 0.2525 0.2468 0.2410 0.2354 0.2303 0.2251 0.2204 0.2162 0.2127 0.2098 

[TRAIN] Epoch[1](511/1500); Loss: 0.144819; Backpropagation: 0.0984 sec; Batch: 0.4782 sec
0.1656 0.1867 0.1497 0.1474 0.1455 0.1397 0.1375 0.1356 0.1345 0.1342 0.1348 0.1359 0.1381 0.1406 0.1438 0.1476 

[TRAIN] Epoch[1](512/1500); Loss: 0.131714; Backpropagation: 0.0983 sec; Batch: 0.4479 sec
0.1408 0.1375 0.1293 0.1271 0.1241 0.1223 0.1217 0.1219 0.1233 0.1253 0.1288 0.1325 0.1364 0.1409 0.1456 0.1499 

[TRAIN] Epoch[1](513/1500); Loss: 0.145381; Backpropagation: 0.0991 sec; Batch: 0.4470 sec
0.1880 0.2110 0.1674 0.1616 0.1580 0.1460 0.1394 0.1336 0.1282 0.1244 0.1227 0.1228 0.1247 0.1279 0.1325 0.1378 

[TRAIN] Epoch[1](514/1500); Loss: 0.086882; Backpropagation: 0.1073 sec; Batch: 0.4576 sec
0.1024 0.1168 0.0925 0.0889 0.0819 0.0770 0.0738 0.0729 0.0735 0.0758 0.0788 0.0822 0.0869 0.0910 0.0955 0.1003 

[TRAIN] Epoch[1](515/1500); Loss: 0.194510; Backpropagation: 0.1023 sec; Batch: 0.4508 sec
0.1928 0.1859 0.1843 0.1857 0.1853 0.1876 0.1893 0.1906 0.1925 0.1946 0.1967 0.1995 0.2022 0.2050 0.2084 0.2117 

[TRAIN] Epoch[1](516/1500); Loss: 0.104300; Backpropagation: 0.0983 sec; Batch: 0.4463 sec
0.1385 0.1109 0.1038 0.1026 0.0979 0.0950 0.0936 0.0928 0.0936 0.0955 0.0979 0.1018 0.1057 0.1095 0.1130 0.1166 

[TRAIN] Epoch[1](517/1500); Loss: 0.104036; Backpropagation: 0.0986 sec; Batch: 0.4482 sec
0.1105 0.1167 0.1084 0.1061 0.1044 0.1029 0.1014 0.1005 0.1000 0.0999 0.1001 0.1006 0.1013 0.1024 0.1038 0.1055 

[TRAIN] Epoch[1](518/1500); Loss: 0.132118; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.2038 0.2134 0.1615 0.1551 0.1516 0.1385 0.1315 0.1249 0.1185 0.1128 0.1080 0.1039 0.1006 0.0980 0.0964 0.0955 

[TRAIN] Epoch[1](519/1500); Loss: 0.100608; Backpropagation: 0.0986 sec; Batch: 0.4473 sec
0.1027 0.1055 0.0970 0.0964 0.0964 0.0970 0.0976 0.0978 0.0982 0.0992 0.1002 0.1015 0.1027 0.1041 0.1057 0.1075 

[TRAIN] Epoch[1](520/1500); Loss: 0.184574; Backpropagation: 0.0990 sec; Batch: 0.4581 sec
0.2023 0.2049 0.1960 0.1936 0.1885 0.1851 0.1816 0.1794 0.1775 0.1763 0.1758 0.1759 0.1767 0.1778 0.1797 0.1820 

[TRAIN] Epoch[1](521/1500); Loss: 0.141688; Backpropagation: 0.0985 sec; Batch: 0.4506 sec
0.1567 0.1560 0.1481 0.1465 0.1436 0.1411 0.1392 0.1377 0.1363 0.1358 0.1357 0.1360 0.1367 0.1377 0.1391 0.1409 

[TRAIN] Epoch[1](522/1500); Loss: 0.109888; Backpropagation: 0.0990 sec; Batch: 0.4462 sec
0.1303 0.1399 0.1227 0.1206 0.1159 0.1115 0.1066 0.1046 0.1021 0.1003 0.0996 0.0996 0.0999 0.1003 0.1014 0.1027 

[TRAIN] Epoch[1](523/1500); Loss: 0.133364; Backpropagation: 0.0992 sec; Batch: 0.4393 sec
0.1484 0.1510 0.1395 0.1386 0.1366 0.1339 0.1317 0.1307 0.1294 0.1287 0.1279 0.1275 0.1273 0.1275 0.1276 0.1275 

[TRAIN] Epoch[1](524/1500); Loss: 0.126721; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.1499 0.1494 0.1323 0.1313 0.1291 0.1259 0.1236 0.1221 0.1211 0.1203 0.1198 0.1198 0.1200 0.1202 0.1209 0.1217 

[TRAIN] Epoch[1](525/1500); Loss: 0.089560; Backpropagation: 0.0996 sec; Batch: 0.4342 sec
0.0953 0.0960 0.0866 0.0854 0.0843 0.0844 0.0845 0.0854 0.0863 0.0874 0.0892 0.0904 0.0920 0.0937 0.0952 0.0969 

[TRAIN] Epoch[1](526/1500); Loss: 0.106698; Backpropagation: 0.0990 sec; Batch: 0.4492 sec
0.1238 0.1214 0.1149 0.1136 0.1098 0.1079 0.1065 0.1042 0.1029 0.1018 0.1009 0.1003 0.0997 0.0996 0.0996 0.1001 

[TRAIN] Epoch[1](527/1500); Loss: 0.187240; Backpropagation: 0.0994 sec; Batch: 0.4347 sec
0.1934 0.1882 0.1917 0.1917 0.1885 0.1877 0.1870 0.1860 0.1854 0.1849 0.1848 0.1845 0.1846 0.1853 0.1857 0.1866 

[TRAIN] Epoch[1](528/1500); Loss: 0.120703; Backpropagation: 0.0993 sec; Batch: 0.4351 sec
0.1320 0.1266 0.1240 0.1234 0.1209 0.1194 0.1189 0.1183 0.1178 0.1177 0.1176 0.1178 0.1184 0.1188 0.1191 0.1203 

[TRAIN] Epoch[1](529/1500); Loss: 0.155724; Backpropagation: 0.0988 sec; Batch: 0.4349 sec
0.1763 0.1687 0.1611 0.1594 0.1559 0.1532 0.1521 0.1504 0.1496 0.1496 0.1497 0.1504 0.1517 0.1529 0.1542 0.1563 

[TRAIN] Epoch[1](530/1500); Loss: 0.156119; Backpropagation: 0.0992 sec; Batch: 0.4354 sec
0.2023 0.1906 0.1637 0.1580 0.1537 0.1502 0.1511 0.1523 0.1511 0.1497 0.1493 0.1477 0.1467 0.1452 0.1438 0.1424 

[TRAIN] Epoch[1](531/1500); Loss: 0.137773; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.1629 0.1593 0.1506 0.1476 0.1439 0.1403 0.1376 0.1359 0.1344 0.1323 0.1301 0.1281 0.1269 0.1257 0.1248 0.1241 

[TRAIN] Epoch[1](532/1500); Loss: 0.121721; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.1402 0.1376 0.1243 0.1228 0.1218 0.1197 0.1186 0.1184 0.1180 0.1174 0.1175 0.1177 0.1177 0.1181 0.1187 0.1193 

[TRAIN] Epoch[1](533/1500); Loss: 0.088834; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1042 0.0982 0.0904 0.0890 0.0876 0.0858 0.0852 0.0852 0.0855 0.0858 0.0862 0.0864 0.0869 0.0877 0.0883 0.0891 

[TRAIN] Epoch[1](534/1500); Loss: 0.129501; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1470 0.1526 0.1355 0.1333 0.1318 0.1277 0.1262 0.1248 0.1238 0.1230 0.1231 0.1233 0.1237 0.1246 0.1252 0.1262 

[TRAIN] Epoch[1](535/1500); Loss: 0.110382; Backpropagation: 0.0987 sec; Batch: 0.4363 sec
0.1446 0.1358 0.1181 0.1144 0.1128 0.1101 0.1073 0.1059 0.1054 0.1037 0.1024 0.1014 0.1005 0.1005 0.1011 0.1021 

[TRAIN] Epoch[1](536/1500); Loss: 0.110231; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1269 0.1161 0.1152 0.1132 0.1089 0.1076 0.1067 0.1060 0.1059 0.1062 0.1066 0.1070 0.1077 0.1088 0.1099 0.1111 

[TRAIN] Epoch[1](537/1500); Loss: 0.122788; Backpropagation: 0.0987 sec; Batch: 0.4540 sec
0.1400 0.1416 0.1223 0.1187 0.1173 0.1160 0.1165 0.1176 0.1181 0.1191 0.1205 0.1215 0.1223 0.1234 0.1243 0.1253 

[TRAIN] Epoch[1](538/1500); Loss: 0.170935; Backpropagation: 0.0993 sec; Batch: 0.4343 sec
0.2006 0.1876 0.1785 0.1769 0.1719 0.1695 0.1683 0.1673 0.1660 0.1652 0.1648 0.1642 0.1639 0.1636 0.1633 0.1633 

[TRAIN] Epoch[1](539/1500); Loss: 0.103428; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.1238 0.1137 0.1114 0.1100 0.1059 0.1033 0.1017 0.1000 0.0986 0.0979 0.0974 0.0972 0.0975 0.0980 0.0991 0.0995 

[TRAIN] Epoch[1](540/1500); Loss: 0.116525; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.1477 0.1487 0.1217 0.1191 0.1182 0.1134 0.1118 0.1110 0.1096 0.1092 0.1087 0.1081 0.1084 0.1090 0.1094 0.1104 

[TRAIN] Epoch[1](541/1500); Loss: 0.091129; Backpropagation: 0.0995 sec; Batch: 0.4357 sec
0.1328 0.1210 0.1013 0.0995 0.0958 0.0912 0.0880 0.0854 0.0830 0.0815 0.0806 0.0800 0.0795 0.0794 0.0794 0.0798 

[TRAIN] Epoch[1](542/1500); Loss: 0.094558; Backpropagation: 0.0993 sec; Batch: 0.4352 sec
0.1672 0.1283 0.1037 0.0922 0.0833 0.0844 0.0855 0.0856 0.0856 0.0851 0.0842 0.0848 0.0843 0.0847 0.0866 0.0874 

[TRAIN] Epoch[1](543/1500); Loss: 0.146412; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.2085 0.2233 0.1707 0.1630 0.1592 0.1447 0.1396 0.1342 0.1303 0.1271 0.1249 0.1235 0.1226 0.1229 0.1237 0.1243 

[TRAIN] Epoch[1](544/1500); Loss: 0.096121; Backpropagation: 0.0989 sec; Batch: 0.4371 sec
0.1530 0.1237 0.1039 0.0991 0.0903 0.0863 0.0846 0.0859 0.0883 0.0886 0.0880 0.0885 0.0885 0.0890 0.0896 0.0904 

[TRAIN] Epoch[1](545/1500); Loss: 0.109163; Backpropagation: 0.0993 sec; Batch: 0.4344 sec
0.1300 0.1224 0.1216 0.1190 0.1113 0.1087 0.1072 0.1048 0.1030 0.1027 0.1023 0.1020 0.1019 0.1025 0.1032 0.1040 

[TRAIN] Epoch[1](546/1500); Loss: 0.148179; Backpropagation: 0.0993 sec; Batch: 0.4345 sec
0.1620 0.1561 0.1562 0.1548 0.1497 0.1481 0.1477 0.1460 0.1448 0.1443 0.1440 0.1434 0.1432 0.1434 0.1434 0.1437 

[TRAIN] Epoch[1](547/1500); Loss: 0.113907; Backpropagation: 0.0992 sec; Batch: 0.4348 sec
0.1369 0.1271 0.1203 0.1185 0.1144 0.1124 0.1109 0.1100 0.1093 0.1088 0.1085 0.1086 0.1087 0.1091 0.1094 0.1095 

[TRAIN] Epoch[1](548/1500); Loss: 0.113363; Backpropagation: 0.0986 sec; Batch: 0.4342 sec
0.1325 0.1242 0.1216 0.1154 0.1086 0.1078 0.1067 0.1073 0.1079 0.1085 0.1105 0.1107 0.1112 0.1128 0.1133 0.1148 

[TRAIN] Epoch[1](549/1500); Loss: 0.101502; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1196 0.1148 0.1106 0.1041 0.0958 0.0946 0.0935 0.0926 0.0930 0.0932 0.0968 0.0979 0.0993 0.1037 0.1063 0.1084 

[TRAIN] Epoch[1](550/1500); Loss: 0.074735; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.0976 0.0893 0.0806 0.0768 0.0745 0.0727 0.0707 0.0705 0.0694 0.0690 0.0699 0.0698 0.0700 0.0707 0.0714 0.0728 

[TRAIN] Epoch[1](551/1500); Loss: 0.122844; Backpropagation: 0.0994 sec; Batch: 0.4350 sec
0.1276 0.1301 0.1202 0.1198 0.1207 0.1206 0.1203 0.1209 0.1216 0.1213 0.1214 0.1228 0.1236 0.1242 0.1249 0.1257 

[TRAIN] Epoch[1](552/1500); Loss: 0.182275; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.2008 0.1923 0.1920 0.1883 0.1864 0.1855 0.1835 0.1817 0.1803 0.1787 0.1778 0.1763 0.1748 0.1737 0.1724 0.1718 

[TRAIN] Epoch[1](553/1500); Loss: 0.116886; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.1849 0.1858 0.1330 0.1255 0.1203 0.1105 0.1073 0.1045 0.1026 0.1012 0.1000 0.0990 0.0989 0.0988 0.0988 0.0993 

[TRAIN] Epoch[1](554/1500); Loss: 0.129432; Backpropagation: 0.0995 sec; Batch: 0.4357 sec
0.1848 0.1654 0.1452 0.1440 0.1380 0.1321 0.1282 0.1240 0.1203 0.1170 0.1147 0.1133 0.1118 0.1110 0.1109 0.1101 

[TRAIN] Epoch[1](555/1500); Loss: 0.090757; Backpropagation: 0.0991 sec; Batch: 0.4745 sec
0.1472 0.1155 0.1003 0.0960 0.0908 0.0882 0.0849 0.0839 0.0823 0.0809 0.0807 0.0807 0.0803 0.0803 0.0799 0.0801 

[TRAIN] Epoch[1](556/1500); Loss: 0.093056; Backpropagation: 0.0991 sec; Batch: 0.4529 sec
0.1079 0.0997 0.0964 0.0922 0.0905 0.0891 0.0895 0.0895 0.0893 0.0894 0.0901 0.0910 0.0915 0.0931 0.0942 0.0955 

[TRAIN] Epoch[1](557/1500); Loss: 0.151761; Backpropagation: 0.0991 sec; Batch: 0.4492 sec
0.1957 0.1941 0.1760 0.1709 0.1650 0.1569 0.1529 0.1479 0.1436 0.1397 0.1362 0.1330 0.1307 0.1292 0.1282 0.1281 

[TRAIN] Epoch[1](558/1500); Loss: 0.130491; Backpropagation: 0.0991 sec; Batch: 0.4490 sec
0.1727 0.1500 0.1349 0.1296 0.1275 0.1258 0.1231 0.1213 0.1220 0.1214 0.1226 0.1239 0.1247 0.1282 0.1294 0.1307 

[TRAIN] Epoch[1](559/1500); Loss: 0.141270; Backpropagation: 0.0992 sec; Batch: 0.4488 sec
0.1798 0.1768 0.1614 0.1553 0.1490 0.1424 0.1392 0.1352 0.1320 0.1293 0.1276 0.1264 0.1260 0.1261 0.1266 0.1272 

[TRAIN] Epoch[1](560/1500); Loss: 0.147317; Backpropagation: 0.0995 sec; Batch: 0.4368 sec
0.1646 0.1598 0.1525 0.1483 0.1447 0.1430 0.1427 0.1422 0.1429 0.1431 0.1436 0.1444 0.1452 0.1457 0.1468 0.1477 

[TRAIN] Epoch[1](561/1500); Loss: 0.084415; Backpropagation: 0.0992 sec; Batch: 0.4345 sec
0.1018 0.0959 0.0860 0.0821 0.0789 0.0781 0.0764 0.0767 0.0772 0.0784 0.0809 0.0822 0.0846 0.0878 0.0903 0.0933 

[TRAIN] Epoch[1](562/1500); Loss: 0.108444; Backpropagation: 0.0986 sec; Batch: 0.4327 sec
0.1325 0.1192 0.1116 0.1091 0.1066 0.1051 0.1043 0.1040 0.1034 0.1039 0.1043 0.1044 0.1055 0.1060 0.1068 0.1085 

[TRAIN] Epoch[1](563/1500); Loss: 0.099417; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.1893 0.1561 0.1302 0.1125 0.0981 0.0906 0.0872 0.0857 0.0826 0.0805 0.0799 0.0794 0.0787 0.0789 0.0804 0.0807 

[TRAIN] Epoch[1](564/1500); Loss: 0.063625; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.0926 0.0873 0.0664 0.0633 0.0597 0.0570 0.0567 0.0564 0.0564 0.0570 0.0579 0.0588 0.0599 0.0612 0.0629 0.0645 

[TRAIN] Epoch[1](565/1500); Loss: 0.063322; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.0993 0.0846 0.0717 0.0656 0.0595 0.0584 0.0574 0.0573 0.0566 0.0559 0.0566 0.0563 0.0569 0.0586 0.0587 0.0597 

[TRAIN] Epoch[1](566/1500); Loss: 0.139707; Backpropagation: 0.0991 sec; Batch: 0.4517 sec
0.1889 0.1710 0.1524 0.1454 0.1395 0.1367 0.1348 0.1322 0.1303 0.1294 0.1288 0.1286 0.1286 0.1290 0.1294 0.1304 

[TRAIN] Epoch[1](567/1500); Loss: 0.084923; Backpropagation: 0.0998 sec; Batch: 0.4354 sec
0.1032 0.0990 0.0958 0.0914 0.0857 0.0831 0.0818 0.0803 0.0798 0.0790 0.0789 0.0791 0.0792 0.0798 0.0810 0.0816 

[TRAIN] Epoch[1](568/1500); Loss: 0.100173; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1713 0.1687 0.1133 0.1045 0.0940 0.0875 0.0847 0.0842 0.0840 0.0842 0.0852 0.0860 0.0870 0.0882 0.0893 0.0907 

[TRAIN] Epoch[1](569/1500); Loss: 0.097632; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1155 0.1038 0.1020 0.0986 0.0960 0.0946 0.0939 0.0939 0.0940 0.0941 0.0945 0.0952 0.0957 0.0961 0.0967 0.0975 

[TRAIN] Epoch[1](570/1500); Loss: 0.055924; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1133 0.1060 0.0737 0.0631 0.0512 0.0477 0.0456 0.0441 0.0435 0.0428 0.0429 0.0432 0.0433 0.0443 0.0448 0.0452 

[TRAIN] Epoch[1](571/1500); Loss: 0.166709; Backpropagation: 0.1002 sec; Batch: 0.4491 sec
0.3240 0.3255 0.2500 0.2377 0.2030 0.1790 0.1585 0.1313 0.1149 0.1057 0.1082 0.1064 0.1052 0.1055 0.1061 0.1065 

[TRAIN] Epoch[1](572/1500); Loss: 0.123824; Backpropagation: 0.0991 sec; Batch: 0.4745 sec
0.1418 0.1309 0.1330 0.1247 0.1207 0.1205 0.1202 0.1199 0.1201 0.1199 0.1201 0.1206 0.1212 0.1217 0.1226 0.1235 

[TRAIN] Epoch[1](573/1500); Loss: 0.118243; Backpropagation: 0.0992 sec; Batch: 0.4466 sec
0.1421 0.1254 0.1277 0.1208 0.1181 0.1168 0.1157 0.1147 0.1140 0.1135 0.1130 0.1133 0.1133 0.1141 0.1147 0.1148 

[TRAIN] Epoch[1](574/1500); Loss: 0.106908; Backpropagation: 0.0989 sec; Batch: 0.4704 sec
0.1144 0.1075 0.1128 0.1087 0.1091 0.1078 0.1064 0.1060 0.1049 0.1045 0.1044 0.1041 0.1045 0.1051 0.1050 0.1055 

[TRAIN] Epoch[1](575/1500); Loss: 0.070874; Backpropagation: 0.0987 sec; Batch: 0.4332 sec
0.1054 0.0847 0.0820 0.0739 0.0704 0.0686 0.0672 0.0659 0.0649 0.0642 0.0639 0.0637 0.0639 0.0646 0.0650 0.0655 

[TRAIN] Epoch[1](576/1500); Loss: 0.060619; Backpropagation: 0.0991 sec; Batch: 0.4370 sec
0.0836 0.0780 0.0855 0.0760 0.0619 0.0541 0.0519 0.0509 0.0510 0.0511 0.0516 0.0528 0.0535 0.0550 0.0559 0.0569 

[TRAIN] Epoch[1](577/1500); Loss: 0.121821; Backpropagation: 0.1000 sec; Batch: 0.4348 sec
0.1761 0.1531 0.1442 0.1314 0.1211 0.1165 0.1132 0.1113 0.1099 0.1095 0.1100 0.1100 0.1103 0.1105 0.1108 0.1114 

[TRAIN] Epoch[1](578/1500); Loss: 0.068310; Backpropagation: 0.0992 sec; Batch: 0.4341 sec
0.0819 0.0750 0.0700 0.0677 0.0672 0.0660 0.0664 0.0661 0.0655 0.0668 0.0658 0.0656 0.0671 0.0663 0.0663 0.0693 

[TRAIN] Epoch[1](579/1500); Loss: 0.138497; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1577 0.1531 0.1442 0.1427 0.1397 0.1381 0.1369 0.1359 0.1351 0.1343 0.1337 0.1335 0.1329 0.1325 0.1328 0.1328 

[TRAIN] Epoch[1](580/1500); Loss: 0.138647; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1551 0.1468 0.1432 0.1390 0.1370 0.1370 0.1366 0.1362 0.1362 0.1358 0.1357 0.1354 0.1361 0.1363 0.1358 0.1361 

[TRAIN] Epoch[1](581/1500); Loss: 0.120038; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1262 0.1208 0.1182 0.1169 0.1185 0.1180 0.1183 0.1192 0.1192 0.1191 0.1202 0.1207 0.1203 0.1210 0.1220 0.1221 

[TRAIN] Epoch[1](582/1500); Loss: 0.157895; Backpropagation: 0.0990 sec; Batch: 0.4343 sec
0.1700 0.1606 0.1587 0.1574 0.1584 0.1584 0.1580 0.1576 0.1575 0.1566 0.1564 0.1558 0.1554 0.1555 0.1551 0.1551 

[TRAIN] Epoch[1](583/1500); Loss: 0.123157; Backpropagation: 0.0996 sec; Batch: 0.4348 sec
0.1660 0.1542 0.1374 0.1326 0.1278 0.1235 0.1208 0.1178 0.1149 0.1134 0.1122 0.1108 0.1103 0.1095 0.1095 0.1098 

[TRAIN] Epoch[1](584/1500); Loss: 0.106179; Backpropagation: 0.0987 sec; Batch: 0.4329 sec
0.1365 0.1181 0.1158 0.1094 0.1028 0.1015 0.1012 0.1008 0.1006 0.1005 0.1007 0.1012 0.1015 0.1021 0.1029 0.1033 

[TRAIN] Epoch[1](585/1500); Loss: 0.130633; Backpropagation: 0.0991 sec; Batch: 0.4343 sec
0.1455 0.1391 0.1335 0.1316 0.1316 0.1296 0.1284 0.1276 0.1273 0.1268 0.1273 0.1274 0.1279 0.1282 0.1288 0.1297 

[TRAIN] Epoch[1](586/1500); Loss: 0.083449; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1192 0.1101 0.0846 0.0821 0.0805 0.0789 0.0786 0.0775 0.0769 0.0767 0.0767 0.0768 0.0777 0.0784 0.0795 0.0808 

[TRAIN] Epoch[1](587/1500); Loss: 0.077285; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1228 0.1144 0.0737 0.0707 0.0699 0.0697 0.0700 0.0694 0.0699 0.0703 0.0706 0.0713 0.0721 0.0729 0.0739 0.0748 

[TRAIN] Epoch[1](588/1500); Loss: 0.159924; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.1757 0.1690 0.1611 0.1591 0.1588 0.1583 0.1583 0.1581 0.1580 0.1576 0.1574 0.1573 0.1574 0.1573 0.1576 0.1577 

[TRAIN] Epoch[1](589/1500); Loss: 0.067226; Backpropagation: 0.0990 sec; Batch: 0.4340 sec
0.1061 0.0908 0.0785 0.0680 0.0669 0.0631 0.0619 0.0622 0.0604 0.0595 0.0601 0.0592 0.0594 0.0596 0.0596 0.0604 

[TRAIN] Epoch[1](590/1500); Loss: 0.112248; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1730 0.1648 0.1238 0.1224 0.1138 0.1087 0.1060 0.1022 0.0994 0.0978 0.0966 0.0962 0.0965 0.0971 0.0981 0.0994 

[TRAIN] Epoch[1](591/1500); Loss: 0.073421; Backpropagation: 0.0994 sec; Batch: 0.4349 sec
0.1009 0.0903 0.0797 0.0745 0.0717 0.0706 0.0696 0.0691 0.0687 0.0685 0.0683 0.0684 0.0683 0.0685 0.0689 0.0687 

[TRAIN] Epoch[1](592/1500); Loss: 0.119035; Backpropagation: 0.0987 sec; Batch: 0.4339 sec
0.1543 0.1387 0.1300 0.1241 0.1204 0.1182 0.1161 0.1143 0.1132 0.1123 0.1113 0.1108 0.1104 0.1102 0.1101 0.1100 

[TRAIN] Epoch[1](593/1500); Loss: 0.104303; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1977 0.1882 0.1184 0.1169 0.1005 0.0899 0.0868 0.0843 0.0838 0.0836 0.0843 0.0850 0.0860 0.0869 0.0878 0.0888 

[TRAIN] Epoch[1](594/1500); Loss: 0.084701; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.1150 0.1042 0.0955 0.0870 0.0824 0.0809 0.0799 0.0790 0.0791 0.0785 0.0784 0.0786 0.0788 0.0789 0.0792 0.0798 

[TRAIN] Epoch[1](595/1500); Loss: 0.118704; Backpropagation: 0.0991 sec; Batch: 0.5297 sec
0.1663 0.1384 0.1286 0.1207 0.1168 0.1160 0.1147 0.1128 0.1132 0.1120 0.1118 0.1102 0.1103 0.1092 0.1095 0.1089 

[TRAIN] Epoch[1](596/1500); Loss: 0.153519; Backpropagation: 0.0984 sec; Batch: 0.4473 sec
0.2322 0.2175 0.1831 0.1763 0.1641 0.1555 0.1505 0.1421 0.1377 0.1327 0.1295 0.1276 0.1271 0.1270 0.1267 0.1269 

[TRAIN] Epoch[1](597/1500); Loss: 0.093035; Backpropagation: 0.0994 sec; Batch: 0.4373 sec
0.1348 0.1182 0.1040 0.0946 0.0889 0.0872 0.0863 0.0860 0.0855 0.0850 0.0853 0.0853 0.0857 0.0865 0.0873 0.0880 

[TRAIN] Epoch[1](598/1500); Loss: 0.120654; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1505 0.1360 0.1247 0.1208 0.1190 0.1179 0.1173 0.1177 0.1173 0.1161 0.1164 0.1149 0.1154 0.1155 0.1153 0.1156 

[TRAIN] Epoch[1](599/1500); Loss: 0.121075; Backpropagation: 0.0986 sec; Batch: 0.4341 sec
0.1340 0.1348 0.1239 0.1214 0.1199 0.1194 0.1188 0.1181 0.1178 0.1175 0.1177 0.1180 0.1182 0.1187 0.1191 0.1197 

[TRAIN] Epoch[1](600/1500); Loss: 0.091593; Backpropagation: 0.1083 sec; Batch: 0.4610 sec
0.1663 0.1536 0.1232 0.1154 0.1034 0.0929 0.0863 0.0781 0.0724 0.0686 0.0675 0.0676 0.0671 0.0681 0.0673 0.0676 

[TRAIN] Epoch[1](601/1500); Loss: 0.071838; Backpropagation: 0.1027 sec; Batch: 0.4386 sec
0.1062 0.1064 0.0810 0.0744 0.0698 0.0663 0.0651 0.0640 0.0632 0.0632 0.0639 0.0638 0.0640 0.0660 0.0657 0.0664 

[TRAIN] Epoch[1](602/1500); Loss: 0.115998; Backpropagation: 0.0994 sec; Batch: 0.4356 sec
0.1391 0.1327 0.1249 0.1191 0.1156 0.1123 0.1104 0.1100 0.1101 0.1105 0.1108 0.1109 0.1113 0.1124 0.1127 0.1134 

[TRAIN] Epoch[1](603/1500); Loss: 0.135064; Backpropagation: 0.0986 sec; Batch: 0.4343 sec
0.1982 0.1782 0.1561 0.1390 0.1280 0.1253 0.1239 0.1231 0.1227 0.1228 0.1228 0.1232 0.1238 0.1242 0.1246 0.1252 

[TRAIN] Epoch[1](604/1500); Loss: 0.081436; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.1403 0.1124 0.0975 0.0930 0.0853 0.0814 0.0763 0.0724 0.0699 0.0680 0.0670 0.0672 0.0674 0.0678 0.0681 0.0689 

[TRAIN] Epoch[1](605/1500); Loss: 0.113357; Backpropagation: 0.0992 sec; Batch: 0.4344 sec
0.1356 0.1202 0.1157 0.1125 0.1118 0.1119 0.1113 0.1113 0.1113 0.1103 0.1108 0.1101 0.1100 0.1103 0.1103 0.1105 

[TRAIN] Epoch[1](606/1500); Loss: 0.056971; Backpropagation: 0.1027 sec; Batch: 0.4386 sec
0.0922 0.0894 0.0656 0.0598 0.0512 0.0481 0.0476 0.0475 0.0478 0.0484 0.0490 0.0509 0.0512 0.0528 0.0547 0.0554 

[TRAIN] Epoch[1](607/1500); Loss: 0.135320; Backpropagation: 0.1028 sec; Batch: 0.4383 sec
0.1735 0.1596 0.1473 0.1408 0.1350 0.1332 0.1315 0.1302 0.1291 0.1281 0.1274 0.1268 0.1260 0.1255 0.1254 0.1257 

[TRAIN] Epoch[1](608/1500); Loss: 0.096742; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.1560 0.1499 0.1147 0.1005 0.0887 0.0887 0.0855 0.0844 0.0834 0.0838 0.0839 0.0843 0.0851 0.0851 0.0864 0.0875 

[TRAIN] Epoch[1](609/1500); Loss: 0.080001; Backpropagation: 0.0985 sec; Batch: 0.4340 sec
0.1642 0.1144 0.1150 0.0885 0.0691 0.0649 0.0630 0.0618 0.0628 0.0636 0.0642 0.0660 0.0678 0.0698 0.0713 0.0735 

[TRAIN] Epoch[1](610/1500); Loss: 0.099951; Backpropagation: 0.0993 sec; Batch: 0.4343 sec
0.2142 0.1662 0.1634 0.1296 0.0968 0.0850 0.0780 0.0736 0.0727 0.0722 0.0724 0.0726 0.0739 0.0752 0.0764 0.0771 

[TRAIN] Epoch[1](611/1500); Loss: 0.092776; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.1088 0.1005 0.1128 0.0970 0.0942 0.0911 0.0884 0.0880 0.0867 0.0863 0.0883 0.0872 0.0868 0.0897 0.0890 0.0895 

[TRAIN] Epoch[1](612/1500); Loss: 0.102729; Backpropagation: 0.1031 sec; Batch: 0.4524 sec
0.1658 0.1384 0.1343 0.1138 0.0975 0.0941 0.0928 0.0920 0.0905 0.0896 0.0903 0.0887 0.0884 0.0891 0.0886 0.0899 

[TRAIN] Epoch[1](613/1500); Loss: 0.061790; Backpropagation: 0.1025 sec; Batch: 0.4974 sec
0.0785 0.0667 0.0681 0.0621 0.0630 0.0590 0.0574 0.0579 0.0571 0.0571 0.0590 0.0584 0.0591 0.0615 0.0613 0.0624 

[TRAIN] Epoch[1](614/1500); Loss: 0.068625; Backpropagation: 0.0984 sec; Batch: 0.4454 sec
0.1859 0.1715 0.0786 0.0672 0.0476 0.0407 0.0408 0.0429 0.0435 0.0468 0.0480 0.0502 0.0554 0.0561 0.0588 0.0641 

[TRAIN] Epoch[1](615/1500); Loss: 0.124672; Backpropagation: 0.0991 sec; Batch: 0.4431 sec
0.1757 0.1659 0.1325 0.1281 0.1215 0.1154 0.1130 0.1088 0.1081 0.1078 0.1096 0.1130 0.1171 0.1217 0.1259 0.1306 

[TRAIN] Epoch[1](616/1500); Loss: 0.105103; Backpropagation: 0.0984 sec; Batch: 0.4715 sec
0.2113 0.1259 0.0797 0.0603 0.0732 0.0743 0.0806 0.0847 0.0901 0.0962 0.1017 0.1085 0.1139 0.1207 0.1268 0.1338 

[TRAIN] Epoch[1](617/1500); Loss: 0.112254; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.1529 0.1780 0.1374 0.1230 0.1010 0.0949 0.0893 0.0886 0.0902 0.0942 0.0984 0.1026 0.1060 0.1095 0.1134 0.1170 

[TRAIN] Epoch[1](618/1500); Loss: 0.154789; Backpropagation: 0.0990 sec; Batch: 0.4478 sec
0.1690 0.1723 0.1603 0.1535 0.1490 0.1479 0.1461 0.1464 0.1466 0.1479 0.1498 0.1522 0.1550 0.1576 0.1602 0.1628 

[TRAIN] Epoch[1](619/1500); Loss: 0.129198; Backpropagation: 0.0994 sec; Batch: 0.4360 sec
0.1303 0.1350 0.1311 0.1271 0.1247 0.1240 0.1235 0.1238 0.1247 0.1260 0.1278 0.1295 0.1315 0.1338 0.1361 0.1382 

[TRAIN] Epoch[1](620/1500); Loss: 0.111450; Backpropagation: 0.0989 sec; Batch: 0.4342 sec
0.1370 0.1299 0.1306 0.1190 0.1132 0.1112 0.1078 0.1061 0.1048 0.1038 0.1032 0.1029 0.1029 0.1031 0.1035 0.1042 

[TRAIN] Epoch[1](621/1500); Loss: 0.163895; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1966 0.1998 0.1800 0.1723 0.1664 0.1628 0.1598 0.1576 0.1557 0.1545 0.1536 0.1529 0.1524 0.1524 0.1526 0.1529 

[TRAIN] Epoch[1](622/1500); Loss: 0.131783; Backpropagation: 0.0990 sec; Batch: 0.4357 sec
0.2112 0.2184 0.1658 0.1550 0.1420 0.1285 0.1231 0.1149 0.1109 0.1074 0.1053 0.1043 0.1042 0.1047 0.1057 0.1071 

[TRAIN] Epoch[1](623/1500); Loss: 0.101621; Backpropagation: 0.0998 sec; Batch: 0.4362 sec
0.1859 0.1853 0.1138 0.1053 0.0951 0.0854 0.0832 0.0822 0.0825 0.0833 0.0841 0.0853 0.0864 0.0879 0.0892 0.0910 

[TRAIN] Epoch[1](624/1500); Loss: 0.113756; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.1471 0.1750 0.1487 0.1361 0.1166 0.1136 0.1055 0.1029 0.0992 0.0973 0.0956 0.0947 0.0948 0.0958 0.0975 0.0996 

[TRAIN] Epoch[1](625/1500); Loss: 0.206211; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1876 0.1718 0.1758 0.1812 0.1868 0.1959 0.1993 0.2046 0.2089 0.2135 0.2179 0.2223 0.2267 0.2312 0.2357 0.2401 

[TRAIN] Epoch[1](626/1500); Loss: 0.105870; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1125 0.1099 0.1084 0.1004 0.1013 0.1015 0.1013 0.1017 0.1023 0.1032 0.1043 0.1057 0.1073 0.1091 0.1113 0.1137 

[TRAIN] Epoch[1](627/1500); Loss: 0.148375; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.2696 0.1911 0.1433 0.1496 0.1523 0.1469 0.1423 0.1390 0.1363 0.1341 0.1319 0.1302 0.1286 0.1273 0.1262 0.1253 

[TRAIN] Epoch[1](628/1500); Loss: 0.107167; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1191 0.1268 0.1204 0.1125 0.1072 0.1068 0.1050 0.1039 0.1032 0.1023 0.1016 0.1012 0.1011 0.1009 0.1013 0.1013 

[TRAIN] Epoch[1](629/1500); Loss: 0.186261; Backpropagation: 0.1061 sec; Batch: 0.4415 sec
0.1898 0.1911 0.1900 0.1864 0.1832 0.1835 0.1831 0.1832 0.1832 0.1836 0.1844 0.1850 0.1861 0.1873 0.1891 0.1912 

[TRAIN] Epoch[1](630/1500); Loss: 0.134643; Backpropagation: 0.1024 sec; Batch: 0.4495 sec
0.1164 0.1637 0.1469 0.1421 0.1289 0.1300 0.1295 0.1297 0.1300 0.1306 0.1313 0.1323 0.1334 0.1348 0.1365 0.1382 

[TRAIN] Epoch[1](631/1500); Loss: 0.124386; Backpropagation: 0.0991 sec; Batch: 0.4649 sec
0.1208 0.1287 0.1209 0.1198 0.1186 0.1191 0.1198 0.1209 0.1219 0.1229 0.1251 0.1263 0.1278 0.1304 0.1326 0.1347 

[TRAIN] Epoch[1](632/1500); Loss: 0.131972; Backpropagation: 0.0990 sec; Batch: 0.4473 sec
0.1546 0.1638 0.1392 0.1368 0.1303 0.1285 0.1269 0.1259 0.1252 0.1250 0.1246 0.1250 0.1252 0.1259 0.1268 0.1280 

[TRAIN] Epoch[1](633/1500); Loss: 0.140490; Backpropagation: 0.0991 sec; Batch: 0.4491 sec
0.1651 0.1621 0.1476 0.1460 0.1425 0.1408 0.1392 0.1379 0.1368 0.1355 0.1345 0.1335 0.1325 0.1318 0.1313 0.1307 

[TRAIN] Epoch[1](634/1500); Loss: 0.151075; Backpropagation: 0.0990 sec; Batch: 0.4490 sec
0.1805 0.1681 0.1650 0.1539 0.1529 0.1514 0.1492 0.1474 0.1464 0.1453 0.1444 0.1436 0.1430 0.1425 0.1419 0.1417 

[TRAIN] Epoch[1](635/1500); Loss: 0.160418; Backpropagation: 0.0994 sec; Batch: 0.4472 sec
0.1642 0.1644 0.1690 0.1634 0.1684 0.1655 0.1627 0.1609 0.1594 0.1580 0.1568 0.1560 0.1551 0.1545 0.1543 0.1540 

[TRAIN] Epoch[1](636/1500); Loss: 0.060619; Backpropagation: 0.0997 sec; Batch: 0.4355 sec
0.1053 0.0976 0.0732 0.0658 0.0575 0.0557 0.0527 0.0511 0.0500 0.0497 0.0499 0.0501 0.0512 0.0520 0.0535 0.0547 

[TRAIN] Epoch[1](637/1500); Loss: 0.226478; Backpropagation: 0.0993 sec; Batch: 0.4350 sec
0.2922 0.2895 0.2533 0.2492 0.2404 0.2293 0.2241 0.2160 0.2128 0.2080 0.2054 0.2028 0.2016 0.2002 0.1998 0.1990 

[TRAIN] Epoch[1](638/1500); Loss: 0.065706; Backpropagation: 0.0983 sec; Batch: 0.4341 sec
0.1233 0.1274 0.0761 0.0709 0.0630 0.0605 0.0589 0.0568 0.0562 0.0535 0.0533 0.0510 0.0514 0.0494 0.0505 0.0491 

[TRAIN] Epoch[1](639/1500); Loss: 0.162989; Backpropagation: 0.0987 sec; Batch: 0.4370 sec
0.1821 0.1717 0.1680 0.1641 0.1654 0.1641 0.1625 0.1614 0.1603 0.1595 0.1589 0.1584 0.1580 0.1578 0.1578 0.1578 

[TRAIN] Epoch[1](640/1500); Loss: 0.134277; Backpropagation: 0.0994 sec; Batch: 0.4354 sec
0.2016 0.1662 0.1576 0.1395 0.1423 0.1372 0.1303 0.1263 0.1230 0.1203 0.1184 0.1174 0.1169 0.1167 0.1172 0.1175 

[TRAIN] Epoch[1](641/1500); Loss: 0.146885; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.1765 0.1674 0.1476 0.1477 0.1468 0.1454 0.1444 0.1435 0.1428 0.1422 0.1418 0.1412 0.1411 0.1408 0.1406 0.1405 

[TRAIN] Epoch[1](642/1500); Loss: 0.111052; Backpropagation: 0.0992 sec; Batch: 0.4336 sec
0.1572 0.1191 0.1082 0.1063 0.1117 0.1069 0.1056 0.1050 0.1051 0.1054 0.1058 0.1062 0.1074 0.1079 0.1090 0.1100 

[TRAIN] Epoch[1](643/1500); Loss: 0.158327; Backpropagation: 0.0989 sec; Batch: 0.4342 sec
0.1778 0.1756 0.1623 0.1614 0.1580 0.1562 0.1545 0.1538 0.1534 0.1531 0.1533 0.1533 0.1539 0.1546 0.1556 0.1565 

[TRAIN] Epoch[1](644/1500); Loss: 0.141811; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1885 0.1758 0.1504 0.1440 0.1433 0.1390 0.1366 0.1346 0.1335 0.1326 0.1321 0.1314 0.1316 0.1316 0.1318 0.1321 

[TRAIN] Epoch[1](645/1500); Loss: 0.115154; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1433 0.1373 0.1149 0.1149 0.1134 0.1114 0.1112 0.1099 0.1100 0.1098 0.1101 0.1101 0.1108 0.1109 0.1118 0.1126 

[TRAIN] Epoch[1](646/1500); Loss: 0.119252; Backpropagation: 0.1006 sec; Batch: 0.4466 sec
0.1461 0.1432 0.1267 0.1235 0.1185 0.1168 0.1148 0.1140 0.1132 0.1127 0.1125 0.1125 0.1127 0.1130 0.1135 0.1141 

[TRAIN] Epoch[1](647/1500); Loss: 0.104235; Backpropagation: 0.0996 sec; Batch: 0.4346 sec
0.1295 0.1203 0.1082 0.1039 0.1032 0.1012 0.0995 0.0998 0.0991 0.0989 0.0993 0.0994 0.1001 0.1010 0.1018 0.1026 

[TRAIN] Epoch[1](648/1500); Loss: 0.109458; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1358 0.1249 0.1109 0.1098 0.1078 0.1068 0.1057 0.1049 0.1047 0.1046 0.1046 0.1049 0.1054 0.1060 0.1068 0.1076 

[TRAIN] Epoch[1](649/1500); Loss: 0.150679; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.1948 0.1870 0.1613 0.1585 0.1539 0.1483 0.1456 0.1433 0.1422 0.1409 0.1400 0.1394 0.1389 0.1391 0.1388 0.1389 

[TRAIN] Epoch[1](650/1500); Loss: 0.126365; Backpropagation: 0.0992 sec; Batch: 0.4704 sec
0.1680 0.1391 0.1290 0.1289 0.1268 0.1244 0.1228 0.1217 0.1206 0.1206 0.1202 0.1200 0.1198 0.1201 0.1197 0.1202 

[TRAIN] Epoch[1](651/1500); Loss: 0.144440; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1555 0.1550 0.1475 0.1467 0.1466 0.1446 0.1434 0.1420 0.1412 0.1408 0.1403 0.1405 0.1407 0.1414 0.1419 0.1429 

[TRAIN] Epoch[1](652/1500); Loss: 0.123212; Backpropagation: 0.0989 sec; Batch: 0.4338 sec
0.1504 0.1371 0.1315 0.1269 0.1246 0.1244 0.1218 0.1203 0.1188 0.1178 0.1170 0.1164 0.1160 0.1160 0.1159 0.1164 

[TRAIN] Epoch[1](653/1500); Loss: 0.080913; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1156 0.1084 0.0924 0.0909 0.0857 0.0822 0.0794 0.0765 0.0744 0.0724 0.0712 0.0698 0.0690 0.0687 0.0687 0.0691 

[TRAIN] Epoch[1](654/1500); Loss: 0.151804; Backpropagation: 0.0985 sec; Batch: 0.4373 sec
0.1865 0.1773 0.1621 0.1592 0.1546 0.1512 0.1494 0.1473 0.1459 0.1446 0.1433 0.1425 0.1419 0.1412 0.1410 0.1408 

[TRAIN] Epoch[1](655/1500); Loss: 0.120489; Backpropagation: 0.0985 sec; Batch: 0.4348 sec
0.1688 0.1463 0.1250 0.1182 0.1197 0.1165 0.1146 0.1140 0.1134 0.1129 0.1131 0.1128 0.1130 0.1128 0.1133 0.1134 

[TRAIN] Epoch[1](656/1500); Loss: 0.083262; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1425 0.1447 0.0877 0.0766 0.0723 0.0711 0.0708 0.0710 0.0710 0.0725 0.0722 0.0737 0.0748 0.0760 0.0770 0.0784 

[TRAIN] Epoch[1](657/1500); Loss: 0.145011; Backpropagation: 0.0987 sec; Batch: 0.4342 sec
0.1914 0.1686 0.1474 0.1397 0.1394 0.1365 0.1366 0.1368 0.1374 0.1380 0.1386 0.1396 0.1406 0.1418 0.1432 0.1445 

[TRAIN] Epoch[1](658/1500); Loss: 0.074478; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.0905 0.0922 0.0849 0.0778 0.0753 0.0735 0.0723 0.0714 0.0705 0.0699 0.0694 0.0690 0.0687 0.0685 0.0686 0.0690 

[TRAIN] Epoch[1](659/1500); Loss: 0.071626; Backpropagation: 0.0993 sec; Batch: 0.4381 sec
0.1130 0.1121 0.0700 0.0658 0.0663 0.0654 0.0651 0.0642 0.0648 0.0640 0.0652 0.0644 0.0660 0.0656 0.0671 0.0669 

[TRAIN] Epoch[1](660/1500); Loss: 0.137773; Backpropagation: 0.0988 sec; Batch: 0.4341 sec
0.1760 0.1660 0.1466 0.1438 0.1407 0.1361 0.1341 0.1320 0.1306 0.1298 0.1288 0.1285 0.1278 0.1277 0.1279 0.1282 

[TRAIN] Epoch[1](661/1500); Loss: 0.131562; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.2127 0.2146 0.1542 0.1446 0.1278 0.1161 0.1131 0.1105 0.1104 0.1111 0.1121 0.1127 0.1146 0.1153 0.1168 0.1182 

[TRAIN] Epoch[1](662/1500); Loss: 0.104489; Backpropagation: 0.0985 sec; Batch: 0.4340 sec
0.1425 0.1392 0.1136 0.1076 0.1055 0.1019 0.1000 0.0982 0.0972 0.0962 0.0958 0.0950 0.0950 0.0947 0.0947 0.0947 

[TRAIN] Epoch[1](663/1500); Loss: 0.089571; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.1510 0.1171 0.0934 0.0874 0.0862 0.0830 0.0818 0.0810 0.0808 0.0811 0.0811 0.0814 0.0814 0.0817 0.0821 0.0826 

[TRAIN] Epoch[1](664/1500); Loss: 0.107796; Backpropagation: 0.0996 sec; Batch: 0.4355 sec
0.1337 0.1156 0.1153 0.1094 0.1062 0.1049 0.1041 0.1033 0.1031 0.1032 0.1034 0.1035 0.1038 0.1044 0.1050 0.1057 

[TRAIN] Epoch[1](665/1500); Loss: 0.089960; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.1141 0.1098 0.1065 0.0919 0.0902 0.0886 0.0866 0.0853 0.0844 0.0845 0.0833 0.0832 0.0827 0.0827 0.0828 0.0828 

[TRAIN] Epoch[1](666/1500); Loss: 0.123931; Backpropagation: 0.0984 sec; Batch: 0.4385 sec
0.1874 0.1800 0.1448 0.1372 0.1289 0.1185 0.1151 0.1093 0.1077 0.1073 0.1072 0.1073 0.1075 0.1079 0.1082 0.1085 

[TRAIN] Epoch[1](667/1500); Loss: 0.102244; Backpropagation: 0.0987 sec; Batch: 0.4360 sec
0.1141 0.1107 0.1133 0.1031 0.1092 0.1035 0.0993 0.1002 0.0985 0.0978 0.0977 0.0976 0.0975 0.0978 0.0977 0.0979 

[TRAIN] Epoch[1](668/1500); Loss: 0.112862; Backpropagation: 0.0986 sec; Batch: 0.4341 sec
0.2018 0.1963 0.1475 0.1341 0.1203 0.1065 0.1000 0.0926 0.0896 0.0883 0.0875 0.0880 0.0877 0.0881 0.0883 0.0893 

[TRAIN] Epoch[1](669/1500); Loss: 0.193092; Backpropagation: 0.0988 sec; Batch: 0.4340 sec
0.2186 0.2155 0.2052 0.2001 0.2001 0.1961 0.1936 0.1914 0.1894 0.1874 0.1857 0.1834 0.1825 0.1812 0.1802 0.1790 

[TRAIN] Epoch[1](670/1500); Loss: 0.141382; Backpropagation: 0.1056 sec; Batch: 0.4413 sec
0.1680 0.1605 0.1461 0.1429 0.1412 0.1396 0.1383 0.1376 0.1369 0.1365 0.1361 0.1357 0.1354 0.1356 0.1356 0.1361 

[TRAIN] Epoch[1](671/1500); Loss: 0.045054; Backpropagation: 0.1027 sec; Batch: 0.4385 sec
0.0869 0.0819 0.0484 0.0367 0.0407 0.0372 0.0369 0.0365 0.0369 0.0369 0.0381 0.0384 0.0398 0.0406 0.0421 0.0429 

[TRAIN] Epoch[1](672/1500); Loss: 0.092868; Backpropagation: 0.0993 sec; Batch: 0.4349 sec
0.1238 0.1127 0.0982 0.0929 0.0905 0.0884 0.0876 0.0874 0.0871 0.0872 0.0875 0.0876 0.0878 0.0885 0.0890 0.0896 

[TRAIN] Epoch[1](673/1500); Loss: 0.078411; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1260 0.1175 0.0852 0.0781 0.0757 0.0744 0.0717 0.0708 0.0699 0.0694 0.0688 0.0686 0.0686 0.0693 0.0700 0.0705 

[TRAIN] Epoch[1](674/1500); Loss: 0.146210; Backpropagation: 0.0988 sec; Batch: 0.4347 sec
0.1810 0.1686 0.1559 0.1521 0.1500 0.1473 0.1454 0.1434 0.1416 0.1400 0.1383 0.1369 0.1358 0.1350 0.1342 0.1337 

[TRAIN] Epoch[1](675/1500); Loss: 0.141209; Backpropagation: 0.0994 sec; Batch: 0.4353 sec
0.1866 0.1600 0.1461 0.1388 0.1390 0.1372 0.1361 0.1359 0.1356 0.1350 0.1352 0.1345 0.1354 0.1344 0.1349 0.1347 

[TRAIN] Epoch[1](676/1500); Loss: 0.059857; Backpropagation: 0.0985 sec; Batch: 0.4342 sec
0.0787 0.0815 0.0707 0.0621 0.0599 0.0584 0.0570 0.0558 0.0548 0.0541 0.0537 0.0537 0.0537 0.0539 0.0545 0.0553 

[TRAIN] Epoch[1](677/1500); Loss: 0.114200; Backpropagation: 0.0940 sec; Batch: 0.4401 sec
0.1923 0.1874 0.1274 0.1157 0.1037 0.1029 0.1004 0.1012 0.1000 0.1003 0.0992 0.0999 0.0990 0.0997 0.0988 0.0993 

[TRAIN] Epoch[1](678/1500); Loss: 0.082282; Backpropagation: 0.0939 sec; Batch: 0.4430 sec
0.1460 0.1264 0.0898 0.0836 0.0762 0.0736 0.0735 0.0725 0.0718 0.0724 0.0717 0.0720 0.0713 0.0717 0.0716 0.0725 

[TRAIN] Epoch[1](679/1500); Loss: 0.113237; Backpropagation: 0.0939 sec; Batch: 0.4686 sec
0.1572 0.1358 0.1197 0.1180 0.1136 0.1101 0.1084 0.1072 0.1065 0.1061 0.1055 0.1052 0.1049 0.1049 0.1045 0.1043 

[TRAIN] Epoch[1](680/1500); Loss: 0.141081; Backpropagation: 0.0939 sec; Batch: 0.4589 sec
0.1997 0.1874 0.1646 0.1527 0.1382 0.1352 0.1305 0.1300 0.1281 0.1276 0.1272 0.1273 0.1268 0.1274 0.1271 0.1275 

[TRAIN] Epoch[1](681/1500); Loss: 0.225758; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2975 0.2937 0.2571 0.2453 0.2299 0.2174 0.2114 0.2065 0.2063 0.2044 0.2045 0.2053 0.2054 0.2072 0.2092 0.2110 

[TRAIN] Epoch[1](682/1500); Loss: 0.081742; Backpropagation: 0.0939 sec; Batch: 0.4540 sec
0.1012 0.0909 0.0841 0.0837 0.0812 0.0800 0.0793 0.0789 0.0786 0.0784 0.0783 0.0782 0.0785 0.0786 0.0789 0.0791 

[TRAIN] Epoch[1](683/1500); Loss: 0.128888; Backpropagation: 0.0934 sec; Batch: 0.4422 sec
0.1910 0.1755 0.1394 0.1313 0.1262 0.1225 0.1199 0.1191 0.1180 0.1174 0.1168 0.1169 0.1167 0.1169 0.1170 0.1176 

[TRAIN] Epoch[1](684/1500); Loss: 0.119084; Backpropagation: 0.0939 sec; Batch: 0.4301 sec
0.1375 0.1275 0.1312 0.1216 0.1183 0.1156 0.1152 0.1145 0.1140 0.1141 0.1143 0.1146 0.1154 0.1161 0.1172 0.1184 

[TRAIN] Epoch[1](685/1500); Loss: 0.121635; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1495 0.1350 0.1287 0.1246 0.1233 0.1204 0.1193 0.1177 0.1176 0.1164 0.1165 0.1156 0.1157 0.1152 0.1156 0.1151 

[TRAIN] Epoch[1](686/1500); Loss: 0.109374; Backpropagation: 0.0939 sec; Batch: 0.4426 sec
0.1410 0.1274 0.1222 0.1177 0.1141 0.1125 0.1087 0.1062 0.1036 0.1018 0.1003 0.0993 0.0988 0.0986 0.0986 0.0993 

[TRAIN] Epoch[1](687/1500); Loss: 0.121653; Backpropagation: 0.0949 sec; Batch: 0.4302 sec
0.1696 0.1614 0.1382 0.1268 0.1194 0.1155 0.1132 0.1122 0.1115 0.1109 0.1107 0.1109 0.1110 0.1115 0.1115 0.1121 

[TRAIN] Epoch[1](688/1500); Loss: 0.079550; Backpropagation: 0.0940 sec; Batch: 0.4296 sec
0.1190 0.1078 0.1032 0.0884 0.0814 0.0778 0.0741 0.0722 0.0702 0.0691 0.0681 0.0676 0.0673 0.0679 0.0687 0.0699 

[TRAIN] Epoch[1](689/1500); Loss: 0.107065; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1607 0.1296 0.1054 0.1004 0.1001 0.0977 0.0991 0.0991 0.0997 0.1005 0.1013 0.1023 0.1027 0.1037 0.1048 0.1060 

[TRAIN] Epoch[1](690/1500); Loss: 0.088935; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1492 0.1258 0.0920 0.0863 0.0830 0.0818 0.0809 0.0802 0.0798 0.0799 0.0799 0.0800 0.0803 0.0808 0.0813 0.0818 

[TRAIN] Epoch[1](691/1500); Loss: 0.066887; Backpropagation: 0.0943 sec; Batch: 0.4294 sec
0.1112 0.0953 0.0688 0.0640 0.0636 0.0610 0.0620 0.0609 0.0605 0.0598 0.0601 0.0598 0.0604 0.0605 0.0613 0.0611 

[TRAIN] Epoch[1](692/1500); Loss: 0.149639; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1853 0.1799 0.1616 0.1554 0.1500 0.1464 0.1447 0.1433 0.1425 0.1419 0.1413 0.1410 0.1405 0.1404 0.1399 0.1401 

[TRAIN] Epoch[1](693/1500); Loss: 0.086565; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.1191 0.1135 0.1018 0.0918 0.0871 0.0843 0.0808 0.0801 0.0793 0.0789 0.0783 0.0782 0.0779 0.0778 0.0780 0.0783 

[TRAIN] Epoch[1](694/1500); Loss: 0.114309; Backpropagation: 0.0944 sec; Batch: 0.4396 sec
0.1322 0.1319 0.1241 0.1158 0.1178 0.1137 0.1101 0.1095 0.1088 0.1089 0.1086 0.1089 0.1090 0.1095 0.1098 0.1104 

[TRAIN] Epoch[1](695/1500); Loss: 0.075167; Backpropagation: 0.0939 sec; Batch: 0.4665 sec
0.0994 0.0926 0.0814 0.0770 0.0723 0.0726 0.0713 0.0711 0.0707 0.0703 0.0700 0.0702 0.0703 0.0709 0.0709 0.0718 

[TRAIN] Epoch[1](696/1500); Loss: 0.095207; Backpropagation: 0.0938 sec; Batch: 0.4350 sec
0.1291 0.1202 0.1063 0.0999 0.0955 0.0911 0.0899 0.0889 0.0884 0.0881 0.0880 0.0875 0.0875 0.0875 0.0875 0.0877 

[TRAIN] Epoch[1](697/1500); Loss: 0.135277; Backpropagation: 0.0942 sec; Batch: 0.4311 sec
0.1589 0.1557 0.1435 0.1399 0.1373 0.1331 0.1318 0.1310 0.1296 0.1296 0.1289 0.1290 0.1289 0.1292 0.1289 0.1292 

[TRAIN] Epoch[1](698/1500); Loss: 0.097170; Backpropagation: 0.0943 sec; Batch: 0.4296 sec
0.1155 0.1056 0.0961 0.0970 0.0933 0.0942 0.0934 0.0935 0.0939 0.0942 0.0940 0.0949 0.0956 0.0967 0.0977 0.0992 

[TRAIN] Epoch[1](699/1500); Loss: 0.086463; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1661 0.1351 0.1069 0.0931 0.0860 0.0797 0.0747 0.0731 0.0716 0.0719 0.0709 0.0712 0.0704 0.0709 0.0705 0.0713 

[TRAIN] Epoch[1](700/1500); Loss: 0.158229; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.2122 0.1913 0.1670 0.1645 0.1578 0.1540 0.1526 0.1506 0.1502 0.1494 0.1480 0.1476 0.1467 0.1467 0.1464 0.1468 

[TRAIN] Epoch[1](701/1500); Loss: 0.118367; Backpropagation: 0.0936 sec; Batch: 0.4292 sec
0.1528 0.1400 0.1250 0.1201 0.1181 0.1172 0.1155 0.1142 0.1129 0.1123 0.1114 0.1110 0.1109 0.1108 0.1108 0.1109 

[TRAIN] Epoch[1](702/1500); Loss: 0.126038; Backpropagation: 0.0935 sec; Batch: 0.4287 sec
0.1643 0.1455 0.1321 0.1277 0.1250 0.1247 0.1218 0.1209 0.1199 0.1192 0.1187 0.1188 0.1187 0.1193 0.1197 0.1204 

[TRAIN] Epoch[1](703/1500); Loss: 0.057182; Backpropagation: 0.0942 sec; Batch: 0.4293 sec
0.1709 0.0891 0.0426 0.0625 0.0407 0.0482 0.0416 0.0449 0.0420 0.0460 0.0435 0.0472 0.0457 0.0492 0.0489 0.0519 

[TRAIN] Epoch[1](704/1500); Loss: 0.087899; Backpropagation: 0.0942 sec; Batch: 0.4296 sec
0.0920 0.0824 0.0887 0.0830 0.0856 0.0897 0.0869 0.0861 0.0862 0.0855 0.0859 0.0874 0.0886 0.0901 0.0928 0.0952 

[TRAIN] Epoch[1](705/1500); Loss: 0.139983; Backpropagation: 0.0941 sec; Batch: 0.4311 sec
0.1727 0.1504 0.1431 0.1407 0.1392 0.1365 0.1356 0.1355 0.1349 0.1350 0.1346 0.1353 0.1356 0.1362 0.1368 0.1377 

[TRAIN] Epoch[1](706/1500); Loss: 0.125733; Backpropagation: 0.0940 sec; Batch: 0.4294 sec
0.1854 0.1867 0.1530 0.1437 0.1315 0.1271 0.1203 0.1171 0.1128 0.1104 0.1075 0.1056 0.1039 0.1029 0.1020 0.1020 

[TRAIN] Epoch[1](707/1500); Loss: 0.118369; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.1620 0.1441 0.1235 0.1208 0.1159 0.1135 0.1121 0.1112 0.1103 0.1099 0.1100 0.1104 0.1112 0.1117 0.1131 0.1141 

[TRAIN] Epoch[1](708/1500); Loss: 0.121849; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.2247 0.2150 0.1545 0.1425 0.1291 0.1207 0.1141 0.1077 0.1022 0.0969 0.0939 0.0909 0.0906 0.0891 0.0889 0.0888 

[TRAIN] Epoch[1](709/1500); Loss: 0.184357; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.2036 0.1971 0.1911 0.1864 0.1872 0.1855 0.1820 0.1812 0.1803 0.1799 0.1793 0.1795 0.1793 0.1791 0.1792 0.1789 

[TRAIN] Epoch[1](710/1500); Loss: 0.106113; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1890 0.1792 0.1378 0.1251 0.1150 0.1024 0.0942 0.0865 0.0850 0.0833 0.0828 0.0834 0.0830 0.0833 0.0837 0.0842 

[TRAIN] Epoch[1](711/1500); Loss: 0.165821; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1697 0.1669 0.1733 0.1673 0.1699 0.1701 0.1683 0.1673 0.1658 0.1645 0.1633 0.1623 0.1615 0.1613 0.1607 0.1609 

[TRAIN] Epoch[1](712/1500); Loss: 0.112281; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1378 0.1214 0.1127 0.1159 0.1171 0.1118 0.1094 0.1073 0.1058 0.1055 0.1061 0.1066 0.1078 0.1092 0.1106 0.1116 

[TRAIN] Epoch[1](713/1500); Loss: 0.213981; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2413 0.2327 0.2230 0.2229 0.2203 0.2168 0.2146 0.2124 0.2099 0.2080 0.2064 0.2052 0.2039 0.2032 0.2019 0.2012 

[TRAIN] Epoch[1](714/1500); Loss: 0.147962; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1685 0.1619 0.1576 0.1528 0.1499 0.1488 0.1466 0.1449 0.1435 0.1428 0.1422 0.1418 0.1414 0.1416 0.1416 0.1416 

[TRAIN] Epoch[1](715/1500); Loss: 0.113724; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1570 0.1465 0.1225 0.1159 0.1105 0.1082 0.1062 0.1055 0.1055 0.1052 0.1053 0.1056 0.1056 0.1061 0.1066 0.1071 

[TRAIN] Epoch[1](716/1500); Loss: 0.084771; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1139 0.1052 0.0929 0.0859 0.0837 0.0801 0.0790 0.0799 0.0784 0.0789 0.0792 0.0791 0.0799 0.0798 0.0800 0.0804 

[TRAIN] Epoch[1](717/1500); Loss: 0.070205; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1710 0.1494 0.0860 0.0703 0.0567 0.0540 0.0511 0.0523 0.0526 0.0524 0.0534 0.0532 0.0543 0.0548 0.0558 0.0561 

[TRAIN] Epoch[1](718/1500); Loss: 0.085041; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1352 0.1175 0.0886 0.0809 0.0776 0.0772 0.0782 0.0770 0.0767 0.0769 0.0764 0.0785 0.0771 0.0800 0.0791 0.0837 

[TRAIN] Epoch[1](719/1500); Loss: 0.072768; Backpropagation: 0.0937 sec; Batch: 0.4290 sec
0.1141 0.1245 0.0842 0.0755 0.0687 0.0639 0.0623 0.0622 0.0632 0.0624 0.0638 0.0628 0.0643 0.0631 0.0651 0.0641 

[TRAIN] Epoch[1](720/1500); Loss: 0.082469; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.1674 0.1517 0.1004 0.0895 0.0762 0.0677 0.0698 0.0659 0.0652 0.0666 0.0655 0.0662 0.0664 0.0670 0.0670 0.0672 

[TRAIN] Epoch[1](721/1500); Loss: 0.096631; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1743 0.1578 0.0949 0.0857 0.0838 0.0854 0.0848 0.0853 0.0850 0.0853 0.0864 0.0866 0.0870 0.0873 0.0878 0.0887 

[TRAIN] Epoch[1](722/1500); Loss: 0.139980; Backpropagation: 0.0944 sec; Batch: 0.4300 sec
0.1925 0.1947 0.1561 0.1457 0.1360 0.1319 0.1328 0.1297 0.1300 0.1295 0.1284 0.1273 0.1271 0.1258 0.1265 0.1259 

[TRAIN] Epoch[1](723/1500); Loss: 0.135976; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2077 0.1931 0.1542 0.1445 0.1330 0.1264 0.1254 0.1234 0.1224 0.1222 0.1215 0.1212 0.1204 0.1205 0.1198 0.1201 

[TRAIN] Epoch[1](724/1500); Loss: 0.100384; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1284 0.1248 0.1058 0.1045 0.0986 0.0959 0.0951 0.0946 0.0941 0.0947 0.0940 0.0943 0.0944 0.0953 0.0957 0.0961 

[TRAIN] Epoch[1](725/1500); Loss: 0.088060; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1437 0.1231 0.0949 0.0885 0.0831 0.0803 0.0801 0.0798 0.0789 0.0792 0.0791 0.0797 0.0792 0.0798 0.0794 0.0802 

[TRAIN] Epoch[1](726/1500); Loss: 0.110987; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1470 0.1458 0.1257 0.1220 0.1138 0.1069 0.1043 0.1025 0.1012 0.1008 0.1008 0.1009 0.1008 0.1011 0.1011 0.1012 

[TRAIN] Epoch[1](727/1500); Loss: 0.107833; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1246 0.1227 0.1169 0.1104 0.1083 0.1055 0.1047 0.1040 0.1039 0.1037 0.1037 0.1035 0.1037 0.1031 0.1034 0.1033 

[TRAIN] Epoch[1](728/1500); Loss: 0.125748; Backpropagation: 0.0943 sec; Batch: 0.4293 sec
0.1668 0.1484 0.1315 0.1267 0.1235 0.1215 0.1207 0.1203 0.1193 0.1197 0.1191 0.1191 0.1188 0.1189 0.1188 0.1188 

[TRAIN] Epoch[1](729/1500); Loss: 0.132478; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1543 0.1519 0.1368 0.1340 0.1302 0.1292 0.1284 0.1282 0.1278 0.1274 0.1277 0.1280 0.1275 0.1286 0.1291 0.1305 

[TRAIN] Epoch[1](730/1500); Loss: 0.091006; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1120 0.1087 0.0950 0.0927 0.0893 0.0880 0.0876 0.0871 0.0870 0.0870 0.0870 0.0866 0.0871 0.0867 0.0874 0.0870 

[TRAIN] Epoch[1](731/1500); Loss: 0.090563; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.1309 0.1223 0.0959 0.0912 0.0871 0.0855 0.0847 0.0840 0.0834 0.0834 0.0832 0.0832 0.0832 0.0834 0.0836 0.0840 

[TRAIN] Epoch[1](732/1500); Loss: 0.066054; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1145 0.0828 0.0712 0.0669 0.0619 0.0632 0.0590 0.0600 0.0584 0.0596 0.0585 0.0599 0.0591 0.0602 0.0602 0.0615 

[TRAIN] Epoch[1](733/1500); Loss: 0.126117; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1746 0.1745 0.1318 0.1227 0.1244 0.1174 0.1177 0.1170 0.1170 0.1168 0.1178 0.1167 0.1177 0.1169 0.1179 0.1172 

[TRAIN] Epoch[1](734/1500); Loss: 0.140965; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.1701 0.1594 0.1481 0.1440 0.1405 0.1385 0.1374 0.1370 0.1360 0.1358 0.1353 0.1350 0.1346 0.1345 0.1347 0.1346 

[TRAIN] Epoch[1](735/1500); Loss: 0.165184; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.2249 0.2165 0.1857 0.1749 0.1644 0.1558 0.1531 0.1525 0.1517 0.1520 0.1520 0.1522 0.1521 0.1522 0.1515 0.1515 

[TRAIN] Epoch[1](736/1500); Loss: 0.079610; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.0928 0.0869 0.0821 0.0788 0.0793 0.0784 0.0775 0.0775 0.0772 0.0773 0.0770 0.0774 0.0773 0.0778 0.0782 0.0785 

[TRAIN] Epoch[1](737/1500); Loss: 0.142733; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1739 0.1729 0.1505 0.1461 0.1412 0.1398 0.1382 0.1372 0.1365 0.1359 0.1358 0.1351 0.1353 0.1348 0.1355 0.1350 

[TRAIN] Epoch[1](738/1500); Loss: 0.065562; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1058 0.1112 0.0867 0.0685 0.0617 0.0584 0.0557 0.0547 0.0544 0.0541 0.0543 0.0544 0.0557 0.0565 0.0580 0.0590 

[TRAIN] Epoch[1](739/1500); Loss: 0.151016; Backpropagation: 0.0942 sec; Batch: 0.4296 sec
0.1737 0.1696 0.1549 0.1517 0.1490 0.1484 0.1477 0.1474 0.1471 0.1467 0.1466 0.1465 0.1464 0.1467 0.1467 0.1471 

[TRAIN] Epoch[1](740/1500); Loss: 0.154701; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.1608 0.1621 0.1543 0.1527 0.1525 0.1522 0.1519 0.1528 0.1529 0.1533 0.1536 0.1545 0.1545 0.1551 0.1557 0.1564 

[TRAIN] Epoch[1](741/1500); Loss: 0.093252; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.1628 0.1565 0.1184 0.1040 0.0880 0.0816 0.0774 0.0771 0.0770 0.0773 0.0776 0.0783 0.0781 0.0790 0.0791 0.0798 

[TRAIN] Epoch[1](742/1500); Loss: 0.127683; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.1882 0.1684 0.1451 0.1490 0.1375 0.1351 0.1302 0.1244 0.1205 0.1168 0.1126 0.1097 0.1055 0.1031 0.0996 0.0972 

[TRAIN] Epoch[1](743/1500); Loss: 0.134856; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1562 0.1513 0.1418 0.1366 0.1342 0.1328 0.1321 0.1318 0.1310 0.1306 0.1304 0.1299 0.1302 0.1296 0.1296 0.1296 

[TRAIN] Epoch[1](744/1500); Loss: 0.084908; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.1542 0.1445 0.1073 0.0941 0.0828 0.0772 0.0732 0.0717 0.0712 0.0703 0.0699 0.0691 0.0687 0.0682 0.0682 0.0678 

[TRAIN] Epoch[1](745/1500); Loss: 0.088650; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1126 0.1060 0.0957 0.0963 0.0875 0.0872 0.0851 0.0845 0.0839 0.0832 0.0830 0.0823 0.0824 0.0826 0.0828 0.0834 

[TRAIN] Epoch[1](746/1500); Loss: 0.059413; Backpropagation: 0.0942 sec; Batch: 0.4295 sec
0.0644 0.0646 0.0659 0.0598 0.0647 0.0595 0.0568 0.0562 0.0562 0.0563 0.0566 0.0570 0.0574 0.0578 0.0585 0.0590 

[TRAIN] Epoch[1](747/1500); Loss: 0.055043; Backpropagation: 0.0937 sec; Batch: 0.4688 sec
0.1189 0.0691 0.0630 0.0519 0.0506 0.0473 0.0469 0.0458 0.0464 0.0461 0.0470 0.0475 0.0486 0.0494 0.0504 0.0518 

[TRAIN] Epoch[1](748/1500); Loss: 0.069854; Backpropagation: 0.0940 sec; Batch: 0.4461 sec
0.1241 0.1117 0.0777 0.0701 0.0654 0.0621 0.0607 0.0595 0.0599 0.0593 0.0600 0.0596 0.0607 0.0610 0.0625 0.0633 

[TRAIN] Epoch[1](749/1500); Loss: 0.123364; Backpropagation: 0.0936 sec; Batch: 0.4432 sec
0.1520 0.1367 0.1302 0.1268 0.1237 0.1218 0.1201 0.1190 0.1181 0.1176 0.1173 0.1175 0.1173 0.1179 0.1184 0.1193 

[TRAIN] Epoch[1](750/1500); Loss: 0.110719; Backpropagation: 0.0940 sec; Batch: 0.4441 sec
0.1331 0.1275 0.1186 0.1136 0.1118 0.1104 0.1086 0.1077 0.1068 0.1061 0.1055 0.1050 0.1046 0.1044 0.1041 0.1037 

[TRAIN] Epoch[1](751/1500); Loss: 0.111886; Backpropagation: 0.0959 sec; Batch: 0.4474 sec
0.1576 0.1322 0.1234 0.1128 0.1113 0.1090 0.1074 0.1063 0.1055 0.1047 0.1042 0.1036 0.1032 0.1030 0.1029 0.1029 

[TRAIN] Epoch[1](752/1500); Loss: 0.087589; Backpropagation: 0.0940 sec; Batch: 0.4417 sec
0.1531 0.1365 0.0993 0.0882 0.0824 0.0802 0.0788 0.0777 0.0769 0.0762 0.0757 0.0754 0.0751 0.0751 0.0753 0.0756 

[TRAIN] Epoch[1](753/1500); Loss: 0.090540; Backpropagation: 0.0941 sec; Batch: 0.4428 sec
0.1205 0.1092 0.0975 0.0919 0.0881 0.0871 0.0856 0.0850 0.0846 0.0842 0.0846 0.0847 0.0854 0.0858 0.0869 0.0877 

[TRAIN] Epoch[1](754/1500); Loss: 0.097905; Backpropagation: 0.0939 sec; Batch: 0.4598 sec
0.1826 0.1636 0.1158 0.0989 0.0918 0.0885 0.0864 0.0849 0.0837 0.0826 0.0818 0.0813 0.0812 0.0810 0.0810 0.0811 

[TRAIN] Epoch[1](755/1500); Loss: 0.069156; Backpropagation: 0.0940 sec; Batch: 0.4423 sec
0.0764 0.0770 0.0737 0.0733 0.0692 0.0674 0.0672 0.0669 0.0667 0.0665 0.0668 0.0665 0.0670 0.0669 0.0675 0.0675 

[TRAIN] Epoch[1](756/1500); Loss: 0.105142; Backpropagation: 0.0945 sec; Batch: 0.4439 sec
0.1282 0.1141 0.1073 0.1086 0.1034 0.1033 0.1021 0.1009 0.1014 0.1011 0.1014 0.1011 0.1020 0.1019 0.1024 0.1029 

[TRAIN] Epoch[1](757/1500); Loss: 0.057338; Backpropagation: 0.0945 sec; Batch: 0.4670 sec
0.1252 0.0770 0.0681 0.0537 0.0512 0.0485 0.0481 0.0480 0.0477 0.0485 0.0480 0.0488 0.0494 0.0508 0.0514 0.0528 

[TRAIN] Epoch[1](758/1500); Loss: 0.147817; Backpropagation: 0.0943 sec; Batch: 0.4543 sec
0.1918 0.1738 0.1466 0.1422 0.1346 0.1322 0.1354 0.1363 0.1376 0.1396 0.1425 0.1449 0.1472 0.1503 0.1536 0.1564 

[TRAIN] Epoch[1](759/1500); Loss: 0.043851; Backpropagation: 0.1016 sec; Batch: 0.4369 sec
0.0746 0.0580 0.0589 0.0447 0.0407 0.0383 0.0390 0.0372 0.0386 0.0375 0.0380 0.0379 0.0388 0.0390 0.0401 0.0403 

[TRAIN] Epoch[1](760/1500); Loss: 0.079687; Backpropagation: 0.0984 sec; Batch: 0.4465 sec
0.1193 0.1082 0.0841 0.0792 0.0739 0.0737 0.0720 0.0719 0.0715 0.0721 0.0721 0.0734 0.0739 0.0752 0.0763 0.0781 

[TRAIN] Epoch[1](761/1500); Loss: 0.181998; Backpropagation: 0.0984 sec; Batch: 0.4485 sec
0.2928 0.2759 0.2171 0.1760 0.1616 0.1609 0.1573 0.1612 0.1615 0.1601 0.1632 0.1631 0.1632 0.1654 0.1660 0.1667 

[TRAIN] Epoch[1](762/1500); Loss: 0.064005; Backpropagation: 0.0990 sec; Batch: 0.4361 sec
0.1266 0.0982 0.0711 0.0646 0.0592 0.0589 0.0559 0.0554 0.0544 0.0546 0.0535 0.0543 0.0535 0.0544 0.0542 0.0554 

[TRAIN] Epoch[1](763/1500); Loss: 0.061157; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.1535 0.1227 0.0646 0.0509 0.0542 0.0475 0.0479 0.0472 0.0470 0.0476 0.0475 0.0485 0.0484 0.0499 0.0499 0.0514 

[TRAIN] Epoch[1](764/1500); Loss: 0.082538; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1519 0.1164 0.1025 0.0880 0.0811 0.0775 0.0750 0.0727 0.0718 0.0702 0.0701 0.0690 0.0691 0.0683 0.0686 0.0683 

[TRAIN] Epoch[1](765/1500); Loss: 0.109773; Backpropagation: 0.0988 sec; Batch: 0.4340 sec
0.1310 0.1253 0.1152 0.1125 0.1098 0.1089 0.1077 0.1072 0.1064 0.1061 0.1051 0.1049 0.1043 0.1041 0.1039 0.1039 

[TRAIN] Epoch[1](766/1500); Loss: 0.155155; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1693 0.1664 0.1606 0.1566 0.1543 0.1521 0.1513 0.1513 0.1512 0.1516 0.1518 0.1522 0.1526 0.1530 0.1537 0.1545 

[TRAIN] Epoch[1](767/1500); Loss: 0.099844; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.1740 0.1608 0.1146 0.0998 0.0925 0.0900 0.0874 0.0871 0.0867 0.0859 0.0860 0.0860 0.0863 0.0866 0.0867 0.0870 

[TRAIN] Epoch[1](768/1500); Loss: 0.088438; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1284 0.1140 0.0963 0.0862 0.0837 0.0824 0.0818 0.0814 0.0815 0.0820 0.0817 0.0823 0.0824 0.0831 0.0832 0.0845 

[TRAIN] Epoch[1](769/1500); Loss: 0.065264; Backpropagation: 0.0989 sec; Batch: 0.4347 sec
0.1131 0.1010 0.0730 0.0683 0.0607 0.0596 0.0574 0.0575 0.0565 0.0569 0.0564 0.0566 0.0566 0.0568 0.0568 0.0569 

[TRAIN] Epoch[1](770/1500); Loss: 0.074492; Backpropagation: 0.0995 sec; Batch: 0.4350 sec
0.1213 0.1049 0.0806 0.0730 0.0692 0.0673 0.0667 0.0664 0.0664 0.0669 0.0669 0.0675 0.0679 0.0684 0.0688 0.0696 

[TRAIN] Epoch[1](771/1500); Loss: 0.138254; Backpropagation: 0.0991 sec; Batch: 0.4337 sec
0.1831 0.1590 0.1478 0.1381 0.1355 0.1338 0.1328 0.1320 0.1313 0.1312 0.1309 0.1311 0.1311 0.1311 0.1314 0.1318 

[TRAIN] Epoch[1](772/1500); Loss: 0.057812; Backpropagation: 0.0990 sec; Batch: 0.4378 sec
0.0972 0.0772 0.0707 0.0583 0.0565 0.0534 0.0528 0.0516 0.0510 0.0515 0.0506 0.0504 0.0506 0.0507 0.0511 0.0514 

[TRAIN] Epoch[1](773/1500); Loss: 0.081990; Backpropagation: 0.1054 sec; Batch: 0.4406 sec
0.1252 0.1052 0.1032 0.0915 0.0810 0.0829 0.0801 0.0754 0.0754 0.0736 0.0717 0.0717 0.0701 0.0687 0.0689 0.0671 

[TRAIN] Epoch[1](774/1500); Loss: 0.160345; Backpropagation: 0.0993 sec; Batch: 0.4429 sec
0.2139 0.1969 0.1816 0.1642 0.1587 0.1553 0.1533 0.1522 0.1512 0.1499 0.1495 0.1489 0.1484 0.1476 0.1470 0.1467 

[TRAIN] Epoch[1](775/1500); Loss: 0.112983; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.1416 0.1318 0.1192 0.1156 0.1125 0.1116 0.1104 0.1096 0.1086 0.1080 0.1073 0.1070 0.1064 0.1062 0.1059 0.1061 

[TRAIN] Epoch[1](776/1500); Loss: 0.117526; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1489 0.1416 0.1245 0.1214 0.1161 0.1159 0.1137 0.1127 0.1120 0.1114 0.1109 0.1106 0.1102 0.1102 0.1100 0.1102 

[TRAIN] Epoch[1](777/1500); Loss: 0.088996; Backpropagation: 0.0989 sec; Batch: 0.4342 sec
0.1185 0.1105 0.0952 0.0861 0.0840 0.0828 0.0820 0.0817 0.0819 0.0824 0.0831 0.0843 0.0854 0.0870 0.0887 0.0905 

[TRAIN] Epoch[1](778/1500); Loss: 0.126695; Backpropagation: 0.0983 sec; Batch: 0.4335 sec
0.1614 0.1464 0.1297 0.1231 0.1243 0.1221 0.1215 0.1218 0.1216 0.1214 0.1215 0.1221 0.1221 0.1224 0.1228 0.1231 

[TRAIN] Epoch[1](779/1500); Loss: 0.135564; Backpropagation: 0.0985 sec; Batch: 0.4345 sec
0.1624 0.1551 0.1418 0.1368 0.1337 0.1326 0.1314 0.1310 0.1305 0.1303 0.1302 0.1303 0.1303 0.1306 0.1309 0.1311 

[TRAIN] Epoch[1](780/1500); Loss: 0.104777; Backpropagation: 0.0990 sec; Batch: 0.4461 sec
0.1272 0.1165 0.1100 0.1074 0.1062 0.1038 0.1038 0.1021 0.1021 0.1007 0.1009 0.0995 0.0999 0.0987 0.0991 0.0981 

[TRAIN] Epoch[1](781/1500); Loss: 0.091230; Backpropagation: 0.0989 sec; Batch: 0.4348 sec
0.1604 0.1401 0.0960 0.0832 0.0839 0.0819 0.0809 0.0811 0.0808 0.0805 0.0807 0.0812 0.0816 0.0819 0.0827 0.0830 

[TRAIN] Epoch[1](782/1500); Loss: 0.044258; Backpropagation: 0.0992 sec; Batch: 0.4341 sec
0.1779 0.0859 0.0457 0.0348 0.0297 0.0286 0.0269 0.0276 0.0266 0.0294 0.0283 0.0321 0.0308 0.0340 0.0333 0.0366 

[TRAIN] Epoch[1](783/1500); Loss: 0.101523; Backpropagation: 0.0986 sec; Batch: 0.4347 sec
0.1147 0.1064 0.1062 0.1010 0.1015 0.1002 0.0998 0.0993 0.0994 0.0991 0.0994 0.0990 0.0993 0.0993 0.0999 0.0997 

[TRAIN] Epoch[1](784/1500); Loss: 0.092038; Backpropagation: 0.0989 sec; Batch: 0.4374 sec
0.1372 0.1219 0.1002 0.0933 0.0893 0.0870 0.0856 0.0846 0.0841 0.0842 0.0840 0.0838 0.0840 0.0841 0.0845 0.0848 

[TRAIN] Epoch[1](785/1500); Loss: 0.095892; Backpropagation: 0.0991 sec; Batch: 0.4348 sec
0.1301 0.1188 0.1018 0.0971 0.0942 0.0930 0.0921 0.0914 0.0906 0.0900 0.0894 0.0891 0.0891 0.0891 0.0891 0.0892 

[TRAIN] Epoch[1](786/1500); Loss: 0.101525; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.1415 0.1300 0.1093 0.1037 0.0993 0.0973 0.0956 0.0952 0.0945 0.0942 0.0941 0.0941 0.0937 0.0938 0.0939 0.0941 

[TRAIN] Epoch[1](787/1500); Loss: 0.074055; Backpropagation: 0.0995 sec; Batch: 0.4349 sec
0.1406 0.1289 0.0951 0.0830 0.0750 0.0682 0.0647 0.0622 0.0616 0.0598 0.0594 0.0581 0.0579 0.0572 0.0569 0.0564 

[TRAIN] Epoch[1](788/1500); Loss: 0.119677; Backpropagation: 0.0994 sec; Batch: 0.4340 sec
0.1410 0.1392 0.1230 0.1185 0.1203 0.1172 0.1168 0.1161 0.1156 0.1153 0.1154 0.1151 0.1152 0.1152 0.1155 0.1157 

[TRAIN] Epoch[1](789/1500); Loss: 0.109405; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1511 0.1245 0.1106 0.1080 0.1068 0.1055 0.1051 0.1047 0.1048 0.1038 0.1040 0.1041 0.1041 0.1042 0.1046 0.1046 

[TRAIN] Epoch[1](790/1500); Loss: 0.110990; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.1404 0.1246 0.1168 0.1107 0.1081 0.1079 0.1072 0.1069 0.1064 0.1061 0.1067 0.1067 0.1068 0.1064 0.1069 0.1072 

[TRAIN] Epoch[1](791/1500); Loss: 0.114662; Backpropagation: 0.0993 sec; Batch: 0.4350 sec
0.1560 0.1479 0.1224 0.1144 0.1119 0.1108 0.1088 0.1082 0.1075 0.1071 0.1068 0.1061 0.1064 0.1065 0.1066 0.1071 

[TRAIN] Epoch[1](792/1500); Loss: 0.062813; Backpropagation: 0.0995 sec; Batch: 0.4347 sec
0.1017 0.0950 0.0839 0.0663 0.0635 0.0614 0.0591 0.0572 0.0556 0.0540 0.0530 0.0519 0.0512 0.0507 0.0503 0.0502 

[TRAIN] Epoch[1](793/1500); Loss: 0.110547; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.1449 0.1318 0.1144 0.1093 0.1076 0.1063 0.1063 0.1052 0.1052 0.1049 0.1050 0.1049 0.1052 0.1054 0.1061 0.1062 

[TRAIN] Epoch[1](794/1500); Loss: 0.127997; Backpropagation: 0.0987 sec; Batch: 0.4344 sec
0.1740 0.1457 0.1335 0.1261 0.1239 0.1228 0.1223 0.1220 0.1217 0.1218 0.1219 0.1222 0.1220 0.1226 0.1225 0.1229 

[TRAIN] Epoch[1](795/1500); Loss: 0.113662; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1877 0.1435 0.1170 0.1130 0.1074 0.1067 0.1052 0.1049 0.1041 0.1045 0.1038 0.1043 0.1037 0.1043 0.1038 0.1048 

[TRAIN] Epoch[1](796/1500); Loss: 0.118829; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.1489 0.1364 0.1227 0.1186 0.1170 0.1156 0.1149 0.1143 0.1141 0.1142 0.1144 0.1141 0.1142 0.1140 0.1139 0.1140 

[TRAIN] Epoch[1](797/1500); Loss: 0.037275; Backpropagation: 0.0990 sec; Batch: 0.4341 sec
0.0973 0.0760 0.0492 0.0359 0.0336 0.0293 0.0279 0.0275 0.0268 0.0265 0.0265 0.0268 0.0274 0.0278 0.0287 0.0293 

[TRAIN] Epoch[1](798/1500); Loss: 0.103765; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.1399 0.1252 0.1128 0.1039 0.1021 0.1001 0.0991 0.0983 0.0977 0.0973 0.0969 0.0972 0.0972 0.0973 0.0974 0.0978 

[TRAIN] Epoch[1](799/1500); Loss: 0.112945; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.1424 0.1262 0.1154 0.1124 0.1100 0.1095 0.1085 0.1086 0.1084 0.1087 0.1083 0.1088 0.1093 0.1097 0.1101 0.1107 

[TRAIN] Epoch[1](800/1500); Loss: 0.176471; Backpropagation: 0.0989 sec; Batch: 0.4335 sec
0.2035 0.1997 0.1762 0.1807 0.1738 0.1719 0.1718 0.1710 0.1712 0.1713 0.1713 0.1722 0.1723 0.1722 0.1721 0.1724 

[TRAIN] Epoch[1](801/1500); Loss: 0.071866; Backpropagation: 0.0989 sec; Batch: 0.4343 sec
0.1362 0.1098 0.0786 0.0706 0.0644 0.0625 0.0614 0.0612 0.0615 0.0615 0.0621 0.0625 0.0632 0.0641 0.0648 0.0655 

[TRAIN] Epoch[1](802/1500); Loss: 0.057284; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.0635 0.0601 0.0654 0.0557 0.0580 0.0546 0.0553 0.0544 0.0548 0.0548 0.0553 0.0553 0.0564 0.0566 0.0582 0.0581 

[TRAIN] Epoch[1](803/1500); Loss: 0.068838; Backpropagation: 0.0996 sec; Batch: 0.4349 sec
0.1222 0.0967 0.0676 0.0641 0.0615 0.0612 0.0603 0.0605 0.0611 0.0614 0.0618 0.0627 0.0634 0.0644 0.0656 0.0669 

[TRAIN] Epoch[1](804/1500); Loss: 0.049501; Backpropagation: 0.0998 sec; Batch: 0.4345 sec
0.1240 0.0760 0.0489 0.0494 0.0428 0.0389 0.0393 0.0377 0.0401 0.0389 0.0399 0.0412 0.0419 0.0426 0.0450 0.0453 

[TRAIN] Epoch[1](805/1500); Loss: 0.106194; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.1290 0.1233 0.1205 0.1099 0.1081 0.1044 0.1025 0.1018 0.1010 0.1002 0.1001 0.0998 0.0995 0.0994 0.0997 0.1002 

[TRAIN] Epoch[1](806/1500); Loss: 0.118544; Backpropagation: 0.0994 sec; Batch: 0.4342 sec
0.1497 0.1758 0.1467 0.1310 0.1210 0.1156 0.1116 0.1088 0.1067 0.1054 0.1044 0.1044 0.1043 0.1039 0.1037 0.1037 

[TRAIN] Epoch[1](807/1500); Loss: 0.146293; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.2059 0.2334 0.2255 0.1979 0.1707 0.1533 0.1365 0.1276 0.1188 0.1142 0.1109 0.1093 0.1086 0.1091 0.1094 0.1098 

[TRAIN] Epoch[1](808/1500); Loss: 0.262813; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.3225 0.3650 0.3859 0.3579 0.3311 0.3043 0.2777 0.2565 0.2349 0.2205 0.2068 0.1979 0.1909 0.1867 0.1837 0.1826 

[TRAIN] Epoch[1](809/1500); Loss: 0.150590; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.1299 0.1698 0.1760 0.1449 0.1257 0.1212 0.1268 0.1314 0.1397 0.1431 0.1505 0.1563 0.1644 0.1702 0.1768 0.1826 

[TRAIN] Epoch[1](810/1500); Loss: 0.139332; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.2017 0.2849 0.2700 0.2222 0.1622 0.1322 0.0960 0.0843 0.0845 0.0862 0.0914 0.0939 0.0985 0.1024 0.1071 0.1118 

[TRAIN] Epoch[1](811/1500); Loss: 0.102529; Backpropagation: 0.0993 sec; Batch: 0.4407 sec
0.0846 0.0759 0.1611 0.0994 0.0726 0.0729 0.0821 0.0888 0.0902 0.0962 0.1015 0.1090 0.1156 0.1229 0.1299 0.1378 

[TRAIN] Epoch[1](812/1500); Loss: 0.169970; Backpropagation: 0.0989 sec; Batch: 0.4336 sec
0.1293 0.0988 0.0915 0.1114 0.1386 0.1497 0.1578 0.1637 0.1731 0.1827 0.1944 0.2049 0.2153 0.2253 0.2368 0.2462 

[TRAIN] Epoch[1](813/1500); Loss: 0.166430; Backpropagation: 0.0995 sec; Batch: 0.4347 sec
0.1891 0.2034 0.1672 0.1600 0.1494 0.1454 0.1505 0.1578 0.1581 0.1595 0.1621 0.1652 0.1686 0.1719 0.1753 0.1795 

[TRAIN] Epoch[1](814/1500); Loss: 0.126817; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1715 0.1876 0.1489 0.1383 0.1205 0.1143 0.1136 0.1110 0.1092 0.1105 0.1118 0.1133 0.1156 0.1179 0.1211 0.1240 

[TRAIN] Epoch[1](815/1500); Loss: 0.150360; Backpropagation: 0.1028 sec; Batch: 0.4383 sec
0.1980 0.2021 0.1742 0.1713 0.1575 0.1484 0.1394 0.1343 0.1315 0.1309 0.1320 0.1334 0.1348 0.1365 0.1390 0.1424 

[TRAIN] Epoch[1](816/1500); Loss: 0.153411; Backpropagation: 0.0994 sec; Batch: 0.4340 sec
0.1764 0.1874 0.1571 0.1498 0.1461 0.1447 0.1430 0.1426 0.1429 0.1437 0.1456 0.1478 0.1511 0.1546 0.1588 0.1630 

[TRAIN] Epoch[1](817/1500); Loss: 0.144167; Backpropagation: 0.0990 sec; Batch: 0.4332 sec
0.1708 0.1653 0.1439 0.1475 0.1400 0.1358 0.1349 0.1345 0.1349 0.1364 0.1375 0.1392 0.1419 0.1445 0.1482 0.1513 

[TRAIN] Epoch[1](818/1500); Loss: 0.238160; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.2467 0.2691 0.2132 0.2145 0.2134 0.2242 0.2253 0.2288 0.2312 0.2357 0.2387 0.2435 0.2480 0.2539 0.2592 0.2652 

[TRAIN] Epoch[1](819/1500); Loss: 0.087901; Backpropagation: 0.0991 sec; Batch: 0.4339 sec
0.0861 0.0845 0.0785 0.0817 0.0793 0.0783 0.0802 0.0808 0.0847 0.0869 0.0888 0.0927 0.0962 0.0993 0.1024 0.1060 

[TRAIN] Epoch[1](820/1500); Loss: 0.116015; Backpropagation: 0.0991 sec; Batch: 0.4336 sec
0.1324 0.1293 0.1163 0.1190 0.1145 0.1084 0.1087 0.1081 0.1097 0.1107 0.1118 0.1130 0.1151 0.1171 0.1197 0.1224 

[TRAIN] Epoch[1](821/1500); Loss: 0.155100; Backpropagation: 0.0990 sec; Batch: 0.4335 sec
0.1814 0.1788 0.1627 0.1673 0.1604 0.1517 0.1486 0.1473 0.1471 0.1469 0.1468 0.1468 0.1476 0.1484 0.1494 0.1504 

[TRAIN] Epoch[1](822/1500); Loss: 0.180690; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2714 0.2608 0.2248 0.1812 0.1527 0.1566 0.1560 0.1581 0.1603 0.1605 0.1625 0.1654 0.1661 0.1699 0.1718 0.1732 

[TRAIN] Epoch[1](823/1500); Loss: 0.147040; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1306 0.1286 0.1700 0.1698 0.1596 0.1473 0.1441 0.1418 0.1416 0.1414 0.1417 0.1429 0.1454 0.1465 0.1495 0.1521 

[TRAIN] Epoch[1](824/1500); Loss: 0.207694; Backpropagation: 0.0986 sec; Batch: 0.4330 sec
0.2352 0.2360 0.2153 0.2167 0.2164 0.2110 0.2062 0.2039 0.2019 0.2002 0.1986 0.1972 0.1965 0.1960 0.1960 0.1961 

[TRAIN] Epoch[1](825/1500); Loss: 0.152940; Backpropagation: 0.0988 sec; Batch: 0.4340 sec
0.1874 0.1830 0.1684 0.1594 0.1525 0.1468 0.1452 0.1451 0.1442 0.1434 0.1438 0.1439 0.1450 0.1456 0.1460 0.1472 

[TRAIN] Epoch[1](826/1500); Loss: 0.134508; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1471 0.1463 0.1404 0.1344 0.1362 0.1318 0.1306 0.1304 0.1293 0.1296 0.1305 0.1308 0.1315 0.1328 0.1341 0.1362 

[TRAIN] Epoch[1](827/1500); Loss: 0.103227; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1559 0.1476 0.1131 0.1032 0.1023 0.0974 0.0946 0.0931 0.0912 0.0913 0.0912 0.0917 0.0925 0.0944 0.0952 0.0967 

[TRAIN] Epoch[1](828/1500); Loss: 0.080620; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.0662 0.0747 0.0934 0.0828 0.0791 0.0760 0.0768 0.0769 0.0764 0.0793 0.0806 0.0810 0.0833 0.0854 0.0877 0.0903 

[TRAIN] Epoch[1](829/1500); Loss: 0.086487; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1172 0.1055 0.0884 0.0820 0.0786 0.0782 0.0778 0.0777 0.0783 0.0794 0.0808 0.0827 0.0851 0.0877 0.0905 0.0938 

[TRAIN] Epoch[1](830/1500); Loss: 0.131133; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1316 0.1347 0.1374 0.1301 0.1298 0.1267 0.1261 0.1265 0.1272 0.1280 0.1300 0.1305 0.1318 0.1335 0.1363 0.1379 

[TRAIN] Epoch[1](831/1500); Loss: 0.113879; Backpropagation: 0.0989 sec; Batch: 0.4340 sec
0.1637 0.1616 0.1099 0.1059 0.1057 0.1061 0.1032 0.1035 0.1028 0.1045 0.1050 0.1060 0.1078 0.1098 0.1123 0.1143 

[TRAIN] Epoch[1](832/1500); Loss: 0.175840; Backpropagation: 0.0998 sec; Batch: 0.4352 sec
0.3148 0.3318 0.2353 0.2221 0.1962 0.1915 0.1745 0.1633 0.1486 0.1384 0.1280 0.1207 0.1152 0.1121 0.1111 0.1098 

[TRAIN] Epoch[1](833/1500); Loss: 0.134374; Backpropagation: 0.0992 sec; Batch: 0.4358 sec
0.2016 0.1891 0.1646 0.1497 0.1322 0.1272 0.1200 0.1177 0.1163 0.1159 0.1160 0.1168 0.1181 0.1200 0.1214 0.1234 

[TRAIN] Epoch[1](834/1500); Loss: 0.108593; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1910 0.1852 0.1280 0.1141 0.0993 0.0919 0.0885 0.0875 0.0884 0.0894 0.0916 0.0923 0.0939 0.0974 0.0987 0.1004 

[TRAIN] Epoch[1](835/1500); Loss: 0.077298; Backpropagation: 0.0997 sec; Batch: 0.4354 sec
0.0656 0.0355 0.0536 0.0542 0.0691 0.0684 0.0713 0.0745 0.0747 0.0817 0.0866 0.0856 0.0985 0.1022 0.1022 0.1130 

[TRAIN] Epoch[1](836/1500); Loss: 0.135113; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1712 0.1674 0.1564 0.1384 0.1330 0.1300 0.1268 0.1262 0.1258 0.1254 0.1256 0.1257 0.1263 0.1269 0.1277 0.1288 

[TRAIN] Epoch[1](837/1500); Loss: 0.192518; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2388 0.2354 0.1967 0.1958 0.1924 0.1898 0.1877 0.1868 0.1852 0.1835 0.1827 0.1817 0.1813 0.1809 0.1807 0.1807 

[TRAIN] Epoch[1](838/1500); Loss: 0.132840; Backpropagation: 0.0998 sec; Batch: 0.4346 sec
0.1811 0.1766 0.1029 0.1138 0.1217 0.1216 0.1203 0.1210 0.1224 0.1244 0.1270 0.1303 0.1342 0.1382 0.1427 0.1473 

[TRAIN] Epoch[1](839/1500); Loss: 0.109725; Backpropagation: 0.0996 sec; Batch: 0.4346 sec
0.1945 0.1842 0.1140 0.1082 0.1046 0.1000 0.0970 0.0957 0.0938 0.0940 0.0939 0.0937 0.0946 0.0949 0.0956 0.0970 

[TRAIN] Epoch[1](840/1500); Loss: 0.141280; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.1829 0.1728 0.1464 0.1409 0.1362 0.1342 0.1332 0.1330 0.1334 0.1330 0.1338 0.1346 0.1348 0.1359 0.1374 0.1379 

[TRAIN] Epoch[1](841/1500); Loss: 0.108348; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1554 0.1497 0.1245 0.1103 0.1126 0.1010 0.0971 0.0964 0.0962 0.0963 0.0967 0.0969 0.0984 0.0997 0.1006 0.1019 

[TRAIN] Epoch[1](842/1500); Loss: 0.129495; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.1905 0.1717 0.1245 0.1220 0.1268 0.1242 0.1207 0.1200 0.1190 0.1197 0.1201 0.1206 0.1214 0.1222 0.1233 0.1252 

[TRAIN] Epoch[1](843/1500); Loss: 0.146228; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1970 0.1920 0.1545 0.1516 0.1477 0.1422 0.1381 0.1369 0.1363 0.1354 0.1348 0.1345 0.1344 0.1346 0.1347 0.1349 

[TRAIN] Epoch[1](844/1500); Loss: 0.109226; Backpropagation: 0.0989 sec; Batch: 0.4332 sec
0.1665 0.1568 0.1157 0.1121 0.1065 0.1024 0.1001 0.0989 0.0982 0.0977 0.0975 0.0977 0.0983 0.0989 0.0997 0.1008 

[TRAIN] Epoch[1](845/1500); Loss: 0.150156; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1826 0.1705 0.1653 0.1541 0.1474 0.1457 0.1442 0.1438 0.1436 0.1434 0.1434 0.1436 0.1435 0.1435 0.1437 0.1444 

[TRAIN] Epoch[1](846/1500); Loss: 0.055752; Backpropagation: 0.0995 sec; Batch: 0.4348 sec
0.0835 0.0759 0.0684 0.0551 0.0487 0.0490 0.0473 0.0478 0.0506 0.0483 0.0489 0.0531 0.0515 0.0524 0.0559 0.0555 

[TRAIN] Epoch[1](847/1500); Loss: 0.077556; Backpropagation: 0.0993 sec; Batch: 0.4344 sec
0.1728 0.1661 0.0980 0.0635 0.0529 0.0537 0.0526 0.0529 0.0643 0.0602 0.0583 0.0684 0.0655 0.0649 0.0744 0.0724 

[TRAIN] Epoch[1](848/1500); Loss: 0.093591; Backpropagation: 0.0992 sec; Batch: 0.4337 sec
0.1399 0.1248 0.1085 0.0960 0.0898 0.0876 0.0859 0.0853 0.0850 0.0848 0.0850 0.0844 0.0846 0.0847 0.0856 0.0856 

[TRAIN] Epoch[1](849/1500); Loss: 0.102485; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.1157 0.1090 0.1303 0.1117 0.1007 0.0976 0.0970 0.0968 0.0972 0.0962 0.0965 0.0969 0.0976 0.0982 0.0987 0.0997 

[TRAIN] Epoch[1](850/1500); Loss: 0.061875; Backpropagation: 0.0989 sec; Batch: 0.4332 sec
0.1096 0.0966 0.0828 0.0627 0.0521 0.0534 0.0500 0.0503 0.0528 0.0508 0.0522 0.0545 0.0535 0.0550 0.0572 0.0565 

[TRAIN] Epoch[1](851/1500); Loss: 0.135000; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1690 0.1615 0.1400 0.1331 0.1311 0.1313 0.1304 0.1288 0.1287 0.1284 0.1291 0.1291 0.1294 0.1296 0.1303 0.1303 

[TRAIN] Epoch[1](852/1500); Loss: 0.113044; Backpropagation: 0.0986 sec; Batch: 0.4328 sec
0.1357 0.1510 0.1636 0.1321 0.1143 0.1090 0.1056 0.1026 0.1003 0.0993 0.0987 0.0987 0.0989 0.0990 0.0996 0.1003 

[TRAIN] Epoch[1](853/1500); Loss: 0.128166; Backpropagation: 0.0987 sec; Batch: 0.4339 sec
0.1503 0.1518 0.1447 0.1297 0.1266 0.1252 0.1242 0.1236 0.1227 0.1224 0.1216 0.1214 0.1215 0.1214 0.1217 0.1219 

[TRAIN] Epoch[1](854/1500); Loss: 0.073297; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.0880 0.0872 0.1088 0.0802 0.0700 0.0664 0.0659 0.0654 0.0648 0.0653 0.0661 0.0665 0.0677 0.0690 0.0695 0.0718 

[TRAIN] Epoch[1](855/1500); Loss: 0.151338; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1763 0.1676 0.1603 0.1521 0.1483 0.1478 0.1469 0.1459 0.1451 0.1458 0.1456 0.1464 0.1468 0.1478 0.1488 0.1499 

[TRAIN] Epoch[1](856/1500); Loss: 0.136529; Backpropagation: 0.0997 sec; Batch: 0.4344 sec
0.1800 0.1612 0.1385 0.1387 0.1334 0.1323 0.1314 0.1308 0.1294 0.1295 0.1297 0.1290 0.1299 0.1297 0.1299 0.1311 

[TRAIN] Epoch[1](857/1500); Loss: 0.110887; Backpropagation: 0.0993 sec; Batch: 0.4342 sec
0.1321 0.1218 0.1184 0.1156 0.1165 0.1141 0.1094 0.1070 0.1059 0.1050 0.1044 0.1042 0.1042 0.1047 0.1052 0.1056 

[TRAIN] Epoch[1](858/1500); Loss: 0.190406; Backpropagation: 0.0989 sec; Batch: 0.4338 sec
0.2118 0.2002 0.1672 0.1900 0.1951 0.1950 0.1930 0.1922 0.1906 0.1896 0.1886 0.1876 0.1870 0.1866 0.1861 0.1858 

[TRAIN] Epoch[1](859/1500); Loss: 0.142360; Backpropagation: 0.0986 sec; Batch: 0.4339 sec
0.1933 0.1801 0.1462 0.1525 0.1393 0.1364 0.1354 0.1335 0.1322 0.1321 0.1317 0.1320 0.1322 0.1329 0.1335 0.1345 

[TRAIN] Epoch[1](860/1500); Loss: 0.125377; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1318 0.1248 0.1474 0.1385 0.1261 0.1194 0.1201 0.1192 0.1189 0.1198 0.1205 0.1210 0.1228 0.1241 0.1251 0.1265 

[TRAIN] Epoch[1](861/1500); Loss: 0.132599; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1925 0.1842 0.1350 0.1293 0.1265 0.1240 0.1234 0.1232 0.1222 0.1220 0.1226 0.1221 0.1227 0.1236 0.1237 0.1246 

[TRAIN] Epoch[1](862/1500); Loss: 0.179793; Backpropagation: 0.0991 sec; Batch: 0.4417 sec
0.2487 0.2419 0.2026 0.2026 0.1833 0.1768 0.1707 0.1680 0.1649 0.1632 0.1617 0.1598 0.1588 0.1583 0.1580 0.1575 

[TRAIN] Epoch[1](863/1500); Loss: 0.139008; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.1884 0.1788 0.1481 0.1449 0.1332 0.1309 0.1306 0.1302 0.1293 0.1295 0.1293 0.1291 0.1296 0.1303 0.1305 0.1313 

[TRAIN] Epoch[1](864/1500); Loss: 0.096428; Backpropagation: 0.0992 sec; Batch: 0.4343 sec
0.1790 0.1708 0.1128 0.0930 0.0808 0.0796 0.0796 0.0787 0.0799 0.0803 0.0811 0.0826 0.0837 0.0853 0.0872 0.0884 

[TRAIN] Epoch[1](865/1500); Loss: 0.099453; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1575 0.1473 0.1070 0.1051 0.0935 0.0895 0.0876 0.0879 0.0875 0.0878 0.0886 0.0890 0.0894 0.0903 0.0912 0.0921 

[TRAIN] Epoch[1](866/1500); Loss: 0.135023; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1919 0.1829 0.1396 0.1405 0.1301 0.1264 0.1231 0.1226 0.1221 0.1227 0.1238 0.1245 0.1260 0.1269 0.1279 0.1293 

[TRAIN] Epoch[1](867/1500); Loss: 0.096811; Backpropagation: 0.0989 sec; Batch: 0.4337 sec
0.1396 0.1283 0.1132 0.1076 0.0977 0.0939 0.0887 0.0878 0.0866 0.0868 0.0861 0.0860 0.0860 0.0861 0.0867 0.0879 

[TRAIN] Epoch[1](868/1500); Loss: 0.072225; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.0830 0.0771 0.1001 0.0768 0.0690 0.0711 0.0690 0.0664 0.0662 0.0663 0.0663 0.0670 0.0677 0.0686 0.0697 0.0713 

[TRAIN] Epoch[1](869/1500); Loss: 0.112707; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1511 0.1448 0.1184 0.1103 0.1067 0.1063 0.1056 0.1056 0.1059 0.1058 0.1062 0.1063 0.1071 0.1070 0.1079 0.1084 

[TRAIN] Epoch[1](870/1500); Loss: 0.110434; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1071 0.1060 0.1483 0.1172 0.1211 0.1036 0.1001 0.1030 0.1022 0.1043 0.1053 0.1079 0.1075 0.1092 0.1119 0.1122 

[TRAIN] Epoch[1](871/1500); Loss: 0.075832; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1238 0.1091 0.0821 0.0726 0.0706 0.0699 0.0676 0.0662 0.0680 0.0663 0.0667 0.0669 0.0682 0.0701 0.0713 0.0738 

[TRAIN] Epoch[1](872/1500); Loss: 0.088989; Backpropagation: 0.0987 sec; Batch: 0.4332 sec
0.1620 0.1607 0.1082 0.0979 0.0844 0.0815 0.0782 0.0758 0.0739 0.0729 0.0716 0.0714 0.0709 0.0708 0.0714 0.0724 

[TRAIN] Epoch[1](873/1500); Loss: 0.109195; Backpropagation: 0.0997 sec; Batch: 0.4345 sec
0.1208 0.1345 0.1444 0.1173 0.1077 0.0993 0.0961 0.1014 0.0998 0.0989 0.1023 0.1023 0.1020 0.1059 0.1072 0.1074 

[TRAIN] Epoch[1](874/1500); Loss: 0.091040; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.1003 0.0975 0.1270 0.1037 0.0867 0.0855 0.0842 0.0831 0.0840 0.0841 0.0848 0.0851 0.0861 0.0870 0.0883 0.0891 

[TRAIN] Epoch[1](875/1500); Loss: 0.066195; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1097 0.1140 0.0853 0.0659 0.0579 0.0585 0.0578 0.0557 0.0557 0.0555 0.0560 0.0557 0.0569 0.0573 0.0582 0.0588 

[TRAIN] Epoch[1](876/1500); Loss: 0.140914; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.2401 0.2345 0.1499 0.1590 0.1389 0.1324 0.1254 0.1220 0.1197 0.1184 0.1182 0.1182 0.1185 0.1192 0.1199 0.1204 

[TRAIN] Epoch[1](877/1500); Loss: 0.100399; Backpropagation: 0.0988 sec; Batch: 0.4340 sec
0.1148 0.1215 0.1164 0.1025 0.0967 0.0978 0.0961 0.0953 0.0952 0.0947 0.0947 0.0951 0.0956 0.0960 0.0966 0.0974 

[TRAIN] Epoch[1](878/1500); Loss: 0.125392; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1458 0.1405 0.1276 0.1220 0.1221 0.1216 0.1211 0.1213 0.1216 0.1221 0.1222 0.1228 0.1230 0.1235 0.1242 0.1250 

[TRAIN] Epoch[1](879/1500); Loss: 0.082799; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.1170 0.0878 0.1157 0.0926 0.0771 0.0739 0.0736 0.0730 0.0732 0.0741 0.0745 0.0755 0.0770 0.0784 0.0800 0.0817 

[TRAIN] Epoch[1](880/1500); Loss: 0.171540; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.2224 0.2247 0.1743 0.1782 0.1700 0.1665 0.1631 0.1625 0.1615 0.1604 0.1602 0.1601 0.1599 0.1598 0.1604 0.1607 

[TRAIN] Epoch[1](881/1500); Loss: 0.120543; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.1834 0.1903 0.1417 0.1383 0.1235 0.1164 0.1102 0.1068 0.1044 0.1030 0.1015 0.1016 0.1012 0.1018 0.1019 0.1028 

[TRAIN] Epoch[1](882/1500); Loss: 0.174653; Backpropagation: 0.0990 sec; Batch: 0.4380 sec
0.2505 0.2854 0.2033 0.2099 0.1793 0.1692 0.1589 0.1539 0.1499 0.1488 0.1470 0.1468 0.1473 0.1472 0.1480 0.1492 

[TRAIN] Epoch[1](883/1500); Loss: 0.155794; Backpropagation: 0.0990 sec; Batch: 0.4339 sec
0.2774 0.3376 0.2088 0.2266 0.1720 0.1504 0.1273 0.1211 0.1130 0.1097 0.1077 0.1070 0.1070 0.1080 0.1087 0.1103 

[TRAIN] Epoch[1](884/1500); Loss: 0.096113; Backpropagation: 0.0991 sec; Batch: 0.4432 sec
0.1821 0.2607 0.1305 0.1400 0.0952 0.0799 0.0689 0.0655 0.0647 0.0642 0.0632 0.0631 0.0636 0.0640 0.0654 0.0667 

[TRAIN] Epoch[1](885/1500); Loss: 0.167493; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.2114 0.2289 0.1725 0.1743 0.1661 0.1626 0.1599 0.1585 0.1573 0.1561 0.1555 0.1551 0.1556 0.1550 0.1554 0.1558 

[TRAIN] Epoch[1](886/1500); Loss: 0.134304; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.1955 0.2261 0.1551 0.1482 0.1340 0.1352 0.1272 0.1257 0.1231 0.1166 0.1166 0.1122 0.1114 0.1089 0.1072 0.1059 

[TRAIN] Epoch[1](887/1500); Loss: 0.079468; Backpropagation: 0.0992 sec; Batch: 0.4417 sec
0.0839 0.1520 0.0810 0.0696 0.0791 0.0748 0.0723 0.0686 0.0709 0.0714 0.0701 0.0738 0.0738 0.0740 0.0774 0.0789 

[TRAIN] Epoch[1](888/1500); Loss: 0.155889; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.2408 0.3177 0.1990 0.1868 0.1541 0.1439 0.1383 0.1339 0.1291 0.1263 0.1252 0.1215 0.1198 0.1201 0.1181 0.1197 

[TRAIN] Epoch[1](889/1500); Loss: 0.128712; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.1693 0.1589 0.1315 0.1211 0.1282 0.1159 0.1237 0.1229 0.1185 0.1196 0.1232 0.1203 0.1260 0.1250 0.1259 0.1293 

[TRAIN] Epoch[1](890/1500); Loss: 0.180444; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.2375 0.2834 0.1877 0.1848 0.1715 0.1704 0.1721 0.1706 0.1657 0.1667 0.1654 0.1627 0.1625 0.1628 0.1616 0.1617 

[TRAIN] Epoch[1](891/1500); Loss: 0.088411; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1244 0.2268 0.0960 0.0764 0.0844 0.0733 0.0708 0.0650 0.0697 0.0689 0.0691 0.0719 0.0768 0.0771 0.0807 0.0833 

[TRAIN] Epoch[1](892/1500); Loss: 0.078585; Backpropagation: 0.0990 sec; Batch: 0.4333 sec
0.0870 0.1455 0.0969 0.0734 0.0860 0.0744 0.0679 0.0688 0.0716 0.0669 0.0678 0.0695 0.0672 0.0707 0.0722 0.0715 

[TRAIN] Epoch[1](893/1500); Loss: 0.119380; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.2240 0.2230 0.1521 0.1310 0.1090 0.0962 0.0994 0.0966 0.0965 0.0958 0.0965 0.0967 0.0970 0.0976 0.0987 0.0999 

[TRAIN] Epoch[1](894/1500); Loss: 0.136438; Backpropagation: 0.0987 sec; Batch: 0.4338 sec
0.1846 0.1833 0.1368 0.1303 0.1281 0.1296 0.1303 0.1251 0.1280 0.1288 0.1267 0.1292 0.1298 0.1297 0.1310 0.1317 

[TRAIN] Epoch[1](895/1500); Loss: 0.104920; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1809 0.1953 0.1291 0.1228 0.0965 0.0848 0.0839 0.0807 0.0842 0.0839 0.0847 0.0869 0.0879 0.0905 0.0925 0.0942 

[TRAIN] Epoch[1](896/1500); Loss: 0.118663; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.1588 0.1614 0.1426 0.1225 0.1129 0.1075 0.1156 0.1063 0.1101 0.1109 0.1050 0.1085 0.1100 0.1061 0.1092 0.1110 

[TRAIN] Epoch[1](897/1500); Loss: 0.137892; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.1501 0.1665 0.1500 0.1372 0.1313 0.1314 0.1393 0.1295 0.1327 0.1342 0.1300 0.1332 0.1349 0.1329 0.1354 0.1374 

[TRAIN] Epoch[1](898/1500); Loss: 0.130925; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.2266 0.2256 0.1337 0.1336 0.1267 0.1225 0.1137 0.1139 0.1136 0.1124 0.1122 0.1118 0.1118 0.1126 0.1121 0.1121 

[TRAIN] Epoch[1](899/1500); Loss: 0.088898; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1329 0.1333 0.1186 0.1012 0.0856 0.0803 0.0860 0.0777 0.0742 0.0751 0.0747 0.0744 0.0762 0.0767 0.0768 0.0788 

[TRAIN] Epoch[1](900/1500); Loss: 0.092254; Backpropagation: 0.0985 sec; Batch: 0.4349 sec
0.1426 0.1403 0.0895 0.0827 0.0959 0.0855 0.0858 0.0813 0.0816 0.0826 0.0825 0.0834 0.0839 0.0859 0.0861 0.0865 

[TRAIN] Epoch[1](901/1500); Loss: 0.120177; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1773 0.1724 0.1252 0.1222 0.1153 0.1125 0.1109 0.1102 0.1104 0.1094 0.1092 0.1094 0.1093 0.1096 0.1098 0.1098 

[TRAIN] Epoch[1](902/1500); Loss: 0.140837; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.2414 0.2361 0.1467 0.1399 0.1294 0.1280 0.1246 0.1233 0.1231 0.1229 0.1229 0.1227 0.1227 0.1229 0.1232 0.1235 

[TRAIN] Epoch[1](903/1500); Loss: 0.137167; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.2597 0.2664 0.1338 0.1288 0.1258 0.1220 0.1178 0.1161 0.1148 0.1155 0.1153 0.1147 0.1159 0.1155 0.1152 0.1175 

[TRAIN] Epoch[1](904/1500); Loss: 0.123104; Backpropagation: 0.0996 sec; Batch: 0.4378 sec
0.1647 0.1618 0.1232 0.1183 0.1281 0.1179 0.1153 0.1161 0.1157 0.1153 0.1154 0.1153 0.1153 0.1156 0.1158 0.1158 

[TRAIN] Epoch[1](905/1500); Loss: 0.104306; Backpropagation: 0.0985 sec; Batch: 0.5321 sec
0.2211 0.2114 0.0999 0.1061 0.1086 0.0931 0.0846 0.0849 0.0846 0.0823 0.0813 0.0811 0.0812 0.0817 0.0826 0.0843 

[TRAIN] Epoch[1](906/1500); Loss: 0.123117; Backpropagation: 0.0984 sec; Batch: 0.4434 sec
0.1389 0.1333 0.1589 0.1473 0.1189 0.1260 0.1298 0.1210 0.1172 0.1150 0.1130 0.1116 0.1114 0.1102 0.1090 0.1083 

[TRAIN] Epoch[1](907/1500); Loss: 0.131470; Backpropagation: 0.0983 sec; Batch: 0.4484 sec
0.1934 0.1873 0.1515 0.1402 0.1237 0.1234 0.1236 0.1214 0.1195 0.1186 0.1176 0.1172 0.1168 0.1165 0.1164 0.1164 

[TRAIN] Epoch[1](908/1500); Loss: 0.104847; Backpropagation: 0.0996 sec; Batch: 0.4343 sec
0.1950 0.1777 0.1240 0.1189 0.1111 0.1036 0.0999 0.0951 0.0902 0.0870 0.0837 0.0812 0.0793 0.0777 0.0768 0.0764 

[TRAIN] Epoch[1](909/1500); Loss: 0.128426; Backpropagation: 0.0994 sec; Batch: 0.4342 sec
0.2020 0.1946 0.1486 0.1400 0.1240 0.1207 0.1194 0.1173 0.1153 0.1133 0.1118 0.1108 0.1099 0.1093 0.1089 0.1090 

[TRAIN] Epoch[1](910/1500); Loss: 0.101310; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.1631 0.1472 0.1035 0.0981 0.0938 0.0929 0.0925 0.0921 0.0919 0.0919 0.0920 0.0919 0.0921 0.0923 0.0926 0.0931 

[TRAIN] Epoch[1](911/1500); Loss: 0.157437; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.2129 0.2061 0.1725 0.1607 0.1516 0.1497 0.1487 0.1479 0.1471 0.1465 0.1461 0.1459 0.1459 0.1460 0.1457 0.1458 

[TRAIN] Epoch[1](912/1500); Loss: 0.102330; Backpropagation: 0.0993 sec; Batch: 0.4342 sec
0.2043 0.1884 0.1144 0.1073 0.0917 0.0904 0.0886 0.0864 0.0853 0.0843 0.0839 0.0831 0.0829 0.0823 0.0820 0.0820 

[TRAIN] Epoch[1](913/1500); Loss: 0.089979; Backpropagation: 0.0996 sec; Batch: 0.4344 sec
0.1808 0.1638 0.1129 0.0922 0.0754 0.0708 0.0710 0.0720 0.0720 0.0727 0.0733 0.0739 0.0753 0.0765 0.0780 0.0791 

[TRAIN] Epoch[1](914/1500); Loss: 0.114096; Backpropagation: 0.0994 sec; Batch: 0.4353 sec
0.1308 0.1246 0.1148 0.1122 0.1129 0.1107 0.1102 0.1106 0.1112 0.1109 0.1114 0.1125 0.1124 0.1129 0.1135 0.1139 

[TRAIN] Epoch[1](915/1500); Loss: 0.101596; Backpropagation: 0.0998 sec; Batch: 0.4345 sec
0.1783 0.1622 0.1129 0.1074 0.0946 0.0899 0.0890 0.0882 0.0878 0.0883 0.0876 0.0870 0.0871 0.0881 0.0885 0.0884 

[TRAIN] Epoch[1](916/1500); Loss: 0.093490; Backpropagation: 0.0995 sec; Batch: 0.4341 sec
0.1589 0.1464 0.0919 0.0923 0.0847 0.0824 0.0832 0.0834 0.0832 0.0832 0.0833 0.0836 0.0841 0.0846 0.0852 0.0854 

[TRAIN] Epoch[1](917/1500); Loss: 0.089023; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.2001 0.1855 0.0937 0.0849 0.0720 0.0690 0.0694 0.0700 0.0703 0.0704 0.0713 0.0718 0.0726 0.0731 0.0745 0.0757 

[TRAIN] Epoch[1](918/1500); Loss: 0.164718; Backpropagation: 0.0987 sec; Batch: 0.4339 sec
0.2472 0.2315 0.1906 0.1821 0.1567 0.1533 0.1513 0.1498 0.1487 0.1476 0.1462 0.1460 0.1461 0.1460 0.1461 0.1463 

[TRAIN] Epoch[1](919/1500); Loss: 0.111863; Backpropagation: 0.0997 sec; Batch: 0.4342 sec
0.1770 0.1613 0.1202 0.1145 0.1084 0.1033 0.0995 0.0987 0.0984 0.0982 0.0990 0.0999 0.1007 0.1020 0.1035 0.1051 

[TRAIN] Epoch[1](920/1500); Loss: 0.112937; Backpropagation: 0.0994 sec; Batch: 0.4338 sec
0.1608 0.1493 0.1151 0.1133 0.1079 0.1073 0.1064 0.1056 0.1051 0.1050 0.1048 0.1046 0.1049 0.1051 0.1056 0.1062 

[TRAIN] Epoch[1](921/1500); Loss: 0.105057; Backpropagation: 0.0992 sec; Batch: 0.4342 sec
0.1427 0.1304 0.1282 0.1204 0.1045 0.0999 0.0989 0.0974 0.0962 0.0956 0.0951 0.0945 0.0943 0.0943 0.0943 0.0941 

[TRAIN] Epoch[1](922/1500); Loss: 0.101482; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1752 0.1623 0.1454 0.1313 0.0998 0.0896 0.0868 0.0847 0.0831 0.0818 0.0811 0.0805 0.0805 0.0805 0.0805 0.0808 

[TRAIN] Epoch[1](923/1500); Loss: 0.089959; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1295 0.1229 0.0992 0.0877 0.0864 0.0847 0.0838 0.0831 0.0827 0.0826 0.0825 0.0824 0.0826 0.0829 0.0831 0.0834 

[TRAIN] Epoch[1](924/1500); Loss: 0.144475; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.2588 0.2389 0.1648 0.1519 0.1354 0.1275 0.1238 0.1231 0.1232 0.1221 0.1217 0.1218 0.1224 0.1236 0.1253 0.1272 

[TRAIN] Epoch[1](925/1500); Loss: 0.132346; Backpropagation: 0.0998 sec; Batch: 0.4350 sec
0.2295 0.2185 0.1372 0.1323 0.1184 0.1168 0.1156 0.1142 0.1141 0.1144 0.1148 0.1156 0.1170 0.1180 0.1195 0.1216 

[TRAIN] Epoch[1](926/1500); Loss: 0.146879; Backpropagation: 0.0991 sec; Batch: 0.4424 sec
0.2859 0.2674 0.1507 0.1438 0.1297 0.1289 0.1263 0.1248 0.1239 0.1238 0.1235 0.1235 0.1240 0.1241 0.1245 0.1252 

[TRAIN] Epoch[1](927/1500); Loss: 0.115613; Backpropagation: 0.0989 sec; Batch: 0.4337 sec
0.1096 0.1064 0.1950 0.1768 0.1189 0.1035 0.1056 0.1049 0.1023 0.1026 0.1030 0.1029 0.1035 0.1043 0.1048 0.1056 

[TRAIN] Epoch[1](928/1500); Loss: 0.081621; Backpropagation: 0.0998 sec; Batch: 0.4469 sec
0.1527 0.1288 0.1109 0.0985 0.0734 0.0696 0.0701 0.0679 0.0664 0.0665 0.0668 0.0666 0.0667 0.0668 0.0670 0.0674 

[TRAIN] Epoch[1](929/1500); Loss: 0.106061; Backpropagation: 0.0991 sec; Batch: 0.4711 sec
0.1130 0.1153 0.1389 0.1293 0.1093 0.1034 0.1025 0.1004 0.0988 0.0977 0.0972 0.0970 0.0976 0.0983 0.0990 0.0992 

[TRAIN] Epoch[1](930/1500); Loss: 0.127038; Backpropagation: 0.0991 sec; Batch: 0.4504 sec
0.2511 0.2345 0.1280 0.1213 0.1190 0.1131 0.1097 0.1081 0.1069 0.1060 0.1056 0.1052 0.1052 0.1056 0.1062 0.1071 

[TRAIN] Epoch[1](931/1500); Loss: 0.138454; Backpropagation: 0.0984 sec; Batch: 0.4496 sec
0.1756 0.1660 0.1412 0.1370 0.1390 0.1357 0.1332 0.1331 0.1323 0.1316 0.1316 0.1317 0.1317 0.1319 0.1318 0.1319 

[TRAIN] Epoch[1](932/1500); Loss: 0.083736; Backpropagation: 0.0984 sec; Batch: 0.4463 sec
0.1712 0.1467 0.0683 0.0783 0.0747 0.0739 0.0712 0.0705 0.0704 0.0709 0.0729 0.0726 0.0730 0.0747 0.0747 0.0757 

[TRAIN] Epoch[1](933/1500); Loss: 0.101343; Backpropagation: 0.0985 sec; Batch: 0.4472 sec
0.2084 0.1873 0.0987 0.0909 0.0923 0.0862 0.0844 0.0848 0.0840 0.0844 0.0859 0.0855 0.0872 0.0868 0.0866 0.0881 

[TRAIN] Epoch[1](934/1500); Loss: 0.059873; Backpropagation: 0.0984 sec; Batch: 0.4691 sec
0.1184 0.1117 0.0534 0.0547 0.0495 0.0469 0.0479 0.0491 0.0495 0.0506 0.0513 0.0530 0.0538 0.0547 0.0562 0.0572 

[TRAIN] Epoch[1](935/1500); Loss: 0.085812; Backpropagation: 0.0995 sec; Batch: 0.4349 sec
0.1440 0.1257 0.1179 0.1015 0.0822 0.0789 0.0767 0.0742 0.0730 0.0721 0.0722 0.0714 0.0709 0.0715 0.0706 0.0702 

[TRAIN] Epoch[1](936/1500); Loss: 0.085816; Backpropagation: 0.0990 sec; Batch: 0.4468 sec
0.1179 0.1136 0.1689 0.1430 0.0831 0.0739 0.0715 0.0692 0.0676 0.0664 0.0658 0.0665 0.0660 0.0659 0.0670 0.0667 

[TRAIN] Epoch[1](937/1500); Loss: 0.062022; Backpropagation: 0.0996 sec; Batch: 0.4338 sec
0.0661 0.0616 0.0691 0.0630 0.0638 0.0598 0.0600 0.0600 0.0595 0.0601 0.0602 0.0607 0.0612 0.0617 0.0623 0.0633 

[TRAIN] Epoch[1](938/1500); Loss: 0.099280; Backpropagation: 0.0993 sec; Batch: 0.4499 sec
0.1300 0.1180 0.1280 0.1136 0.0980 0.0944 0.0925 0.0905 0.0906 0.0900 0.0899 0.0898 0.0896 0.0904 0.0915 0.0916 

[TRAIN] Epoch[1](939/1500); Loss: 0.114447; Backpropagation: 0.0993 sec; Batch: 0.4349 sec
0.1948 0.1736 0.1386 0.1256 0.1046 0.1020 0.1015 0.0996 0.0991 0.0993 0.0987 0.0986 0.0989 0.0987 0.0988 0.0990 

[TRAIN] Epoch[1](940/1500); Loss: 0.113097; Backpropagation: 0.0992 sec; Batch: 0.4355 sec
0.1873 0.1713 0.1125 0.1094 0.1044 0.1025 0.1022 0.1022 0.1019 0.1016 0.1019 0.1021 0.1021 0.1024 0.1027 0.1030 

[TRAIN] Epoch[1](941/1500); Loss: 0.155091; Backpropagation: 0.0999 sec; Batch: 0.4345 sec
0.2099 0.1972 0.1660 0.1581 0.1502 0.1480 0.1474 0.1461 0.1454 0.1449 0.1446 0.1446 0.1446 0.1447 0.1447 0.1450 

[TRAIN] Epoch[1](942/1500); Loss: 0.223992; Backpropagation: 0.1010 sec; Batch: 0.4361 sec
0.2679 0.2538 0.2329 0.2237 0.2241 0.2241 0.2211 0.2202 0.2189 0.2175 0.2165 0.2151 0.2137 0.2125 0.2114 0.2102 

[TRAIN] Epoch[1](943/1500); Loss: 0.100493; Backpropagation: 0.1027 sec; Batch: 0.4405 sec
0.1540 0.1471 0.1100 0.1025 0.0948 0.0928 0.0926 0.0912 0.0907 0.0904 0.0906 0.0901 0.0902 0.0901 0.0903 0.0906 

[TRAIN] Epoch[1](944/1500); Loss: 0.128970; Backpropagation: 0.1027 sec; Batch: 0.4375 sec
0.2542 0.2312 0.1461 0.1360 0.1170 0.1119 0.1112 0.1088 0.1078 0.1073 0.1059 0.1058 0.1053 0.1046 0.1050 0.1052 

[TRAIN] Epoch[1](945/1500); Loss: 0.145806; Backpropagation: 0.0994 sec; Batch: 0.4624 sec
0.2106 0.1896 0.1569 0.1601 0.1473 0.1392 0.1381 0.1361 0.1345 0.1335 0.1326 0.1317 0.1317 0.1305 0.1303 0.1301 

[TRAIN] Epoch[1](946/1500); Loss: 0.095824; Backpropagation: 0.0990 sec; Batch: 0.4747 sec
0.1923 0.1676 0.1102 0.0952 0.0837 0.0818 0.0808 0.0802 0.0799 0.0798 0.0800 0.0796 0.0799 0.0808 0.0806 0.0810 

[TRAIN] Epoch[1](947/1500); Loss: 0.132599; Backpropagation: 0.0991 sec; Batch: 0.4470 sec
0.1635 0.1575 0.1433 0.1363 0.1314 0.1299 0.1287 0.1279 0.1269 0.1261 0.1257 0.1255 0.1250 0.1248 0.1247 0.1245 

[TRAIN] Epoch[1](948/1500); Loss: 0.072516; Backpropagation: 0.0991 sec; Batch: 0.4493 sec
0.1106 0.1053 0.1379 0.0831 0.0858 0.0627 0.0639 0.0562 0.0542 0.0540 0.0571 0.0543 0.0562 0.0589 0.0586 0.0614 

[TRAIN] Epoch[1](949/1500); Loss: 0.079666; Backpropagation: 0.0991 sec; Batch: 0.4482 sec
0.1121 0.1013 0.0821 0.0781 0.0787 0.0758 0.0750 0.0749 0.0747 0.0750 0.0742 0.0743 0.0747 0.0744 0.0746 0.0746 

[TRAIN] Epoch[1](950/1500); Loss: 0.145548; Backpropagation: 0.0984 sec; Batch: 0.4427 sec
0.2683 0.2476 0.1505 0.1408 0.1311 0.1318 0.1299 0.1290 0.1277 0.1266 0.1258 0.1250 0.1243 0.1237 0.1234 0.1232 

[TRAIN] Epoch[1](951/1500); Loss: 0.074903; Backpropagation: 0.0985 sec; Batch: 0.4457 sec
0.1166 0.1000 0.0751 0.0704 0.0689 0.0682 0.0670 0.0664 0.0688 0.0670 0.0675 0.0714 0.0698 0.0713 0.0753 0.0747 

[TRAIN] Epoch[1](952/1500); Loss: 0.133069; Backpropagation: 0.0985 sec; Batch: 0.4492 sec
0.1905 0.1760 0.1436 0.1343 0.1280 0.1236 0.1222 0.1217 0.1217 0.1220 0.1225 0.1231 0.1239 0.1247 0.1253 0.1261 

[TRAIN] Epoch[1](953/1500); Loss: 0.125980; Backpropagation: 0.0991 sec; Batch: 0.4697 sec
0.1678 0.1601 0.1579 0.1340 0.1190 0.1183 0.1204 0.1169 0.1152 0.1153 0.1148 0.1145 0.1150 0.1149 0.1155 0.1162 

[TRAIN] Epoch[1](954/1500); Loss: 0.067346; Backpropagation: 0.0983 sec; Batch: 0.4500 sec
0.0827 0.0784 0.0712 0.0698 0.0687 0.0654 0.0647 0.0642 0.0637 0.0634 0.0637 0.0637 0.0640 0.0642 0.0647 0.0650 

[TRAIN] Epoch[1](955/1500); Loss: 0.131055; Backpropagation: 0.0985 sec; Batch: 0.5769 sec
0.2036 0.1814 0.1385 0.1298 0.1261 0.1219 0.1210 0.1201 0.1197 0.1195 0.1194 0.1192 0.1189 0.1190 0.1193 0.1194 

[TRAIN] Epoch[1](956/1500); Loss: 0.107310; Backpropagation: 0.0990 sec; Batch: 0.4401 sec
0.1848 0.1589 0.1152 0.1071 0.0998 0.0968 0.0965 0.0956 0.0950 0.0947 0.0947 0.0947 0.0952 0.0955 0.0959 0.0966 

[TRAIN] Epoch[1](957/1500); Loss: 0.176158; Backpropagation: 0.0992 sec; Batch: 0.4679 sec
0.2822 0.2646 0.2051 0.1793 0.1594 0.1589 0.1570 0.1564 0.1565 0.1562 0.1561 0.1562 0.1568 0.1574 0.1581 0.1583 

[TRAIN] Epoch[1](958/1500); Loss: 0.058680; Backpropagation: 0.0990 sec; Batch: 0.4409 sec
0.1229 0.1035 0.0844 0.0674 0.0560 0.0498 0.0472 0.0453 0.0447 0.0444 0.0443 0.0446 0.0456 0.0457 0.0461 0.0469 

[TRAIN] Epoch[1](959/1500); Loss: 0.083040; Backpropagation: 0.0996 sec; Batch: 0.4366 sec
0.1040 0.1087 0.1424 0.0754 0.0879 0.0724 0.0748 0.0686 0.0729 0.0716 0.0716 0.0733 0.0742 0.0752 0.0771 0.0784 

[TRAIN] Epoch[1](960/1500); Loss: 0.058502; Backpropagation: 0.0990 sec; Batch: 0.4593 sec
0.0911 0.0836 0.0649 0.0544 0.0567 0.0521 0.0532 0.0515 0.0515 0.0524 0.0523 0.0529 0.0540 0.0543 0.0551 0.0561 

[TRAIN] Epoch[1](961/1500); Loss: 0.074641; Backpropagation: 0.0996 sec; Batch: 0.4346 sec
0.1276 0.1098 0.0897 0.0748 0.0720 0.0675 0.0665 0.0652 0.0647 0.0645 0.0645 0.0648 0.0650 0.0654 0.0659 0.0664 

[TRAIN] Epoch[1](962/1500); Loss: 0.073858; Backpropagation: 0.0985 sec; Batch: 0.4356 sec
0.0719 0.0653 0.1614 0.1054 0.0785 0.0673 0.0708 0.0634 0.0623 0.0618 0.0617 0.0614 0.0616 0.0621 0.0631 0.0636 

[TRAIN] Epoch[1](963/1500); Loss: 0.089712; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.1818 0.1697 0.1231 0.1019 0.0795 0.0751 0.0733 0.0715 0.0711 0.0705 0.0700 0.0698 0.0697 0.0696 0.0694 0.0695 

[TRAIN] Epoch[1](964/1500); Loss: 0.096796; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.1514 0.1482 0.1232 0.1079 0.0918 0.0877 0.0869 0.0860 0.0852 0.0841 0.0838 0.0832 0.0829 0.0824 0.0822 0.0819 

[TRAIN] Epoch[1](965/1500); Loss: 0.079735; Backpropagation: 0.0994 sec; Batch: 0.4346 sec
0.1845 0.1617 0.0831 0.0744 0.0690 0.0663 0.0657 0.0646 0.0639 0.0633 0.0633 0.0630 0.0631 0.0631 0.0635 0.0634 

[TRAIN] Epoch[1](966/1500); Loss: 0.124976; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1566 0.1496 0.1421 0.1322 0.1227 0.1198 0.1190 0.1189 0.1184 0.1181 0.1176 0.1176 0.1170 0.1167 0.1167 0.1166 

[TRAIN] Epoch[1](967/1500); Loss: 0.087054; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1225 0.1183 0.1027 0.0912 0.0851 0.0828 0.0822 0.0810 0.0795 0.0786 0.0784 0.0780 0.0782 0.0779 0.0781 0.0785 

[TRAIN] Epoch[1](968/1500); Loss: 0.043576; Backpropagation: 0.0984 sec; Batch: 0.4426 sec
0.0915 0.0641 0.0657 0.0519 0.0460 0.0358 0.0333 0.0334 0.0342 0.0331 0.0337 0.0347 0.0341 0.0349 0.0353 0.0353 

[TRAIN] Epoch[1](969/1500); Loss: 0.124395; Backpropagation: 0.0985 sec; Batch: 0.4337 sec
0.1609 0.1585 0.1411 0.1270 0.1208 0.1186 0.1177 0.1171 0.1164 0.1161 0.1160 0.1159 0.1160 0.1160 0.1161 0.1161 

[TRAIN] Epoch[1](970/1500); Loss: 0.062550; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1485 0.1208 0.0657 0.0515 0.0795 0.0624 0.0503 0.0469 0.0467 0.0462 0.0465 0.0467 0.0468 0.0470 0.0476 0.0477 

[TRAIN] Epoch[1](971/1500); Loss: 0.112630; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.2613 0.2329 0.1594 0.1278 0.0907 0.0866 0.0846 0.0871 0.0849 0.0835 0.0836 0.0838 0.0837 0.0838 0.0841 0.0843 

[TRAIN] Epoch[1](972/1500); Loss: 0.135602; Backpropagation: 0.1001 sec; Batch: 0.4354 sec
0.2122 0.1905 0.1385 0.1327 0.1296 0.1272 0.1259 0.1249 0.1244 0.1239 0.1233 0.1231 0.1231 0.1232 0.1234 0.1237 

[TRAIN] Epoch[1](973/1500); Loss: 0.089116; Backpropagation: 0.0991 sec; Batch: 0.4757 sec
0.1890 0.1586 0.0853 0.0806 0.0777 0.0748 0.0739 0.0736 0.0740 0.0746 0.0750 0.0756 0.0766 0.0776 0.0788 0.0800 

[TRAIN] Epoch[1](974/1500); Loss: 0.091855; Backpropagation: 0.0991 sec; Batch: 0.4474 sec
0.1713 0.1534 0.1003 0.0930 0.0841 0.0812 0.0799 0.0792 0.0789 0.0786 0.0784 0.0783 0.0782 0.0783 0.0781 0.0784 

[TRAIN] Epoch[1](975/1500); Loss: 0.171945; Backpropagation: 0.0991 sec; Batch: 0.4473 sec
0.1983 0.1934 0.1827 0.1788 0.1700 0.1667 0.1660 0.1659 0.1658 0.1657 0.1658 0.1660 0.1662 0.1663 0.1666 0.1671 

[TRAIN] Epoch[1](976/1500); Loss: 0.130913; Backpropagation: 0.0992 sec; Batch: 0.4518 sec
0.1706 0.1508 0.1302 0.1338 0.1308 0.1260 0.1232 0.1235 0.1236 0.1238 0.1242 0.1250 0.1256 0.1266 0.1278 0.1292 

[TRAIN] Epoch[1](977/1500); Loss: 0.090061; Backpropagation: 0.0991 sec; Batch: 0.4475 sec
0.2221 0.1901 0.1118 0.0958 0.0738 0.0701 0.0685 0.0685 0.0678 0.0675 0.0670 0.0673 0.0671 0.0675 0.0677 0.0683 

[TRAIN] Epoch[1](978/1500); Loss: 0.175535; Backpropagation: 0.0985 sec; Batch: 0.4470 sec
0.2313 0.2306 0.2127 0.1856 0.1696 0.1657 0.1647 0.1630 0.1620 0.1613 0.1606 0.1604 0.1602 0.1602 0.1603 0.1605 

[TRAIN] Epoch[1](979/1500); Loss: 0.175925; Backpropagation: 0.0984 sec; Batch: 0.4465 sec
0.2387 0.2351 0.2094 0.1843 0.1711 0.1661 0.1640 0.1627 0.1618 0.1612 0.1607 0.1603 0.1600 0.1599 0.1598 0.1596 

[TRAIN] Epoch[1](980/1500); Loss: 0.127061; Backpropagation: 0.0984 sec; Batch: 0.4461 sec
0.1922 0.1829 0.1465 0.1330 0.1199 0.1159 0.1159 0.1154 0.1147 0.1141 0.1140 0.1136 0.1136 0.1137 0.1138 0.1139 

[TRAIN] Epoch[1](981/1500); Loss: 0.109379; Backpropagation: 0.0985 sec; Batch: 0.4457 sec
0.2050 0.1776 0.1168 0.1067 0.1023 0.1000 0.0972 0.0960 0.0951 0.0945 0.0939 0.0936 0.0933 0.0930 0.0927 0.0925 

[TRAIN] Epoch[1](982/1500); Loss: 0.048995; Backpropagation: 0.0991 sec; Batch: 0.4493 sec
0.1030 0.1032 0.0662 0.0493 0.0403 0.0395 0.0389 0.0378 0.0375 0.0374 0.0375 0.0376 0.0379 0.0387 0.0392 0.0399 

[TRAIN] Epoch[1](983/1500); Loss: 0.087072; Backpropagation: 0.0984 sec; Batch: 0.4428 sec
0.2136 0.1793 0.1018 0.0900 0.0701 0.0688 0.0686 0.0669 0.0665 0.0667 0.0663 0.0662 0.0665 0.0669 0.0673 0.0676 

[TRAIN] Epoch[1](984/1500); Loss: 0.095785; Backpropagation: 0.0983 sec; Batch: 0.4468 sec
0.2154 0.1853 0.1033 0.0940 0.0818 0.0794 0.0786 0.0779 0.0770 0.0767 0.0768 0.0769 0.0771 0.0771 0.0775 0.0779 

[TRAIN] Epoch[1](985/1500); Loss: 0.132645; Backpropagation: 0.0984 sec; Batch: 0.4471 sec
0.2124 0.1884 0.1337 0.1288 0.1261 0.1241 0.1228 0.1222 0.1213 0.1208 0.1204 0.1202 0.1200 0.1201 0.1203 0.1207 

[TRAIN] Epoch[1](986/1500); Loss: 0.075704; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.1889 0.1621 0.0803 0.0675 0.0774 0.0658 0.0602 0.0593 0.0580 0.0567 0.0561 0.0571 0.0554 0.0552 0.0561 0.0552 

[TRAIN] Epoch[1](987/1500); Loss: 0.101748; Backpropagation: 0.0984 sec; Batch: 0.4689 sec
0.1400 0.1311 0.1417 0.1253 0.0985 0.0940 0.0924 0.0914 0.0905 0.0898 0.0891 0.0890 0.0889 0.0888 0.0887 0.0887 

[TRAIN] Epoch[1](988/1500); Loss: 0.083351; Backpropagation: 0.0996 sec; Batch: 0.4340 sec
0.1926 0.1691 0.0940 0.0819 0.0750 0.0709 0.0691 0.0667 0.0650 0.0640 0.0634 0.0634 0.0635 0.0640 0.0649 0.0659 

[TRAIN] Epoch[1](989/1500); Loss: 0.074595; Backpropagation: 0.1016 sec; Batch: 0.4373 sec
0.1337 0.1152 0.1112 0.0984 0.0702 0.0664 0.0633 0.0622 0.0604 0.0597 0.0590 0.0587 0.0587 0.0587 0.0588 0.0590 

[TRAIN] Epoch[1](990/1500); Loss: 0.077531; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.1095 0.1096 0.1012 0.0918 0.0771 0.0701 0.0683 0.0681 0.0683 0.0679 0.0680 0.0679 0.0677 0.0677 0.0683 0.0690 

[TRAIN] Epoch[1](991/1500); Loss: 0.122825; Backpropagation: 0.0993 sec; Batch: 0.4345 sec
0.1200 0.1297 0.2366 0.2096 0.1325 0.1104 0.1061 0.1073 0.1021 0.1011 0.1009 0.1008 0.1013 0.1017 0.1021 0.1033 

[TRAIN] Epoch[1](992/1500); Loss: 0.118421; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1527 0.1523 0.1726 0.1528 0.1213 0.1084 0.1062 0.1059 0.1049 0.1039 0.1030 0.1025 0.1024 0.1022 0.1018 0.1019 

[TRAIN] Epoch[1](993/1500); Loss: 0.068804; Backpropagation: 0.0986 sec; Batch: 0.4481 sec
0.1664 0.1409 0.0721 0.0584 0.0577 0.0559 0.0525 0.0528 0.0544 0.0552 0.0552 0.0551 0.0556 0.0558 0.0562 0.0566 

[TRAIN] Epoch[1](994/1500); Loss: 0.165076; Backpropagation: 0.0994 sec; Batch: 0.4344 sec
0.1974 0.1909 0.1893 0.1782 0.1661 0.1581 0.1566 0.1564 0.1562 0.1560 0.1558 0.1556 0.1557 0.1559 0.1562 0.1568 

[TRAIN] Epoch[1](995/1500); Loss: 0.076669; Backpropagation: 0.0985 sec; Batch: 0.4353 sec
0.1334 0.1165 0.0960 0.0858 0.0764 0.0691 0.0663 0.0654 0.0649 0.0648 0.0645 0.0647 0.0646 0.0647 0.0648 0.0648 

[TRAIN] Epoch[1](996/1500); Loss: 0.075119; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1693 0.1248 0.0778 0.0714 0.0666 0.0634 0.0608 0.0611 0.0624 0.0625 0.0623 0.0631 0.0631 0.0635 0.0644 0.0651 

[TRAIN] Epoch[1](997/1500); Loss: 0.149227; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.2037 0.1933 0.1746 0.1609 0.1498 0.1427 0.1399 0.1385 0.1376 0.1368 0.1361 0.1357 0.1350 0.1345 0.1344 0.1342 

[TRAIN] Epoch[1](998/1500); Loss: 0.104946; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1474 0.1166 0.1166 0.1124 0.1014 0.1004 0.0989 0.0980 0.0979 0.0980 0.0980 0.0981 0.0984 0.0986 0.0989 0.0995 

[TRAIN] Epoch[1](999/1500); Loss: 0.083445; Backpropagation: 0.0992 sec; Batch: 0.4342 sec
0.1175 0.1051 0.0723 0.1094 0.0908 0.0732 0.0711 0.0733 0.0731 0.0744 0.0760 0.0767 0.0782 0.0799 0.0814 0.0827 

[TRAIN] Epoch[1](1000/1500); Loss: 0.117269; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.1861 0.1771 0.1422 0.1243 0.1124 0.1067 0.1047 0.1037 0.1030 0.1026 0.1025 0.1025 0.1023 0.1022 0.1019 0.1021 

[TRAIN] Epoch[1](1001/1500); Loss: 0.044242; Backpropagation: 0.0993 sec; Batch: 0.4342 sec
0.0501 0.0418 0.0558 0.0592 0.0473 0.0407 0.0420 0.0407 0.0403 0.0412 0.0411 0.0410 0.0409 0.0415 0.0419 0.0423 

[TRAIN] Epoch[1](1002/1500); Loss: 0.082026; Backpropagation: 0.1059 sec; Batch: 0.4477 sec
0.1302 0.1047 0.0907 0.0987 0.0864 0.0779 0.0724 0.0708 0.0712 0.0718 0.0717 0.0723 0.0729 0.0732 0.0736 0.0741 

[TRAIN] Epoch[1](1003/1500); Loss: 0.065953; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.2343 0.1792 0.0642 0.0620 0.0500 0.0479 0.0453 0.0442 0.0433 0.0421 0.0414 0.0409 0.0406 0.0400 0.0400 0.0399 

[TRAIN] Epoch[1](1004/1500); Loss: 0.065204; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.0952 0.0836 0.0760 0.0847 0.0688 0.0607 0.0603 0.0600 0.0584 0.0578 0.0570 0.0569 0.0564 0.0559 0.0558 0.0558 

[TRAIN] Epoch[1](1005/1500); Loss: 0.100295; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1751 0.1679 0.1597 0.1173 0.0967 0.0895 0.0852 0.0815 0.0814 0.0803 0.0791 0.0783 0.0784 0.0783 0.0778 0.0780 

[TRAIN] Epoch[1](1006/1500); Loss: 0.111892; Backpropagation: 0.1126 sec; Batch: 0.4518 sec
0.1708 0.1375 0.1149 0.1170 0.1119 0.1077 0.1044 0.1029 0.1027 0.1025 0.1026 0.1027 0.1027 0.1031 0.1033 0.1037 

[TRAIN] Epoch[1](1007/1500); Loss: 0.081763; Backpropagation: 0.0997 sec; Batch: 0.4348 sec
0.2068 0.1697 0.0978 0.0795 0.0681 0.0687 0.0640 0.0623 0.0622 0.0619 0.0612 0.0612 0.0609 0.0616 0.0609 0.0615 

[TRAIN] Epoch[1](1008/1500); Loss: 0.135810; Backpropagation: 0.0988 sec; Batch: 0.4332 sec
0.1809 0.1685 0.1487 0.1404 0.1383 0.1332 0.1290 0.1272 0.1270 0.1272 0.1266 0.1254 0.1248 0.1245 0.1253 0.1260 

[TRAIN] Epoch[1](1009/1500); Loss: 0.099185; Backpropagation: 0.0989 sec; Batch: 0.4336 sec
0.1971 0.1788 0.1420 0.1125 0.0818 0.0879 0.0804 0.0770 0.0776 0.0776 0.0775 0.0781 0.0784 0.0790 0.0799 0.0813 

[TRAIN] Epoch[1](1010/1500); Loss: 0.137398; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.2024 0.1823 0.1507 0.1431 0.1324 0.1293 0.1271 0.1257 0.1254 0.1253 0.1252 0.1253 0.1254 0.1258 0.1263 0.1267 

[TRAIN] Epoch[1](1011/1500); Loss: 0.096978; Backpropagation: 0.0996 sec; Batch: 0.4348 sec
0.1490 0.1231 0.0982 0.1006 0.0935 0.0911 0.0899 0.0893 0.0893 0.0892 0.0894 0.0894 0.0896 0.0899 0.0899 0.0902 

[TRAIN] Epoch[1](1012/1500); Loss: 0.124765; Backpropagation: 0.0939 sec; Batch: 0.4313 sec
0.2096 0.1747 0.1299 0.1259 0.1208 0.1179 0.1152 0.1141 0.1137 0.1128 0.1118 0.1111 0.1105 0.1098 0.1094 0.1091 

[TRAIN] Epoch[1](1013/1500); Loss: 0.122137; Backpropagation: 0.0940 sec; Batch: 0.4389 sec
0.1613 0.1425 0.1535 0.1515 0.1203 0.1173 0.1139 0.1115 0.1102 0.1100 0.1098 0.1100 0.1102 0.1105 0.1106 0.1111 

[TRAIN] Epoch[1](1014/1500); Loss: 0.120158; Backpropagation: 0.0938 sec; Batch: 0.4462 sec
0.1640 0.1434 0.1289 0.1262 0.1198 0.1150 0.1136 0.1132 0.1129 0.1126 0.1121 0.1120 0.1120 0.1122 0.1123 0.1124 

[TRAIN] Epoch[1](1015/1500); Loss: 0.169135; Backpropagation: 0.0939 sec; Batch: 0.4372 sec
0.2569 0.2372 0.1819 0.1584 0.1603 0.1600 0.1568 0.1562 0.1558 0.1556 0.1553 0.1550 0.1544 0.1542 0.1541 0.1542 

[TRAIN] Epoch[1](1016/1500); Loss: 0.162992; Backpropagation: 0.0938 sec; Batch: 0.4433 sec
0.2022 0.1935 0.1729 0.1629 0.1599 0.1577 0.1571 0.1567 0.1561 0.1556 0.1553 0.1554 0.1554 0.1553 0.1557 0.1561 

[TRAIN] Epoch[1](1017/1500); Loss: 0.127597; Backpropagation: 0.0942 sec; Batch: 0.4319 sec
0.2029 0.1707 0.1338 0.1280 0.1233 0.1222 0.1205 0.1193 0.1178 0.1169 0.1160 0.1154 0.1147 0.1140 0.1133 0.1128 

[TRAIN] Epoch[1](1018/1500); Loss: 0.104577; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1664 0.1519 0.1252 0.1122 0.1003 0.0957 0.0941 0.0934 0.0925 0.0918 0.0914 0.0914 0.0916 0.0918 0.0917 0.0919 

[TRAIN] Epoch[1](1019/1500); Loss: 0.077503; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1995 0.1657 0.0866 0.0717 0.0607 0.0586 0.0561 0.0555 0.0556 0.0564 0.0577 0.0591 0.0607 0.0630 0.0653 0.0679 

[TRAIN] Epoch[1](1020/1500); Loss: 0.175917; Backpropagation: 0.0939 sec; Batch: 0.4298 sec
0.2015 0.1950 0.1875 0.1821 0.1751 0.1718 0.1709 0.1707 0.1703 0.1700 0.1698 0.1697 0.1698 0.1700 0.1701 0.1703 

[TRAIN] Epoch[1](1021/1500); Loss: 0.067939; Backpropagation: 0.0939 sec; Batch: 0.4307 sec
0.2027 0.1545 0.0705 0.0626 0.0534 0.0515 0.0501 0.0495 0.0489 0.0486 0.0483 0.0484 0.0486 0.0492 0.0497 0.0505 

[TRAIN] Epoch[1](1022/1500); Loss: 0.114098; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2029 0.1699 0.1295 0.1272 0.1144 0.1089 0.1065 0.1041 0.1012 0.0987 0.0966 0.0953 0.0935 0.0927 0.0920 0.0921 

[TRAIN] Epoch[1](1023/1500); Loss: 0.073611; Backpropagation: 0.0936 sec; Batch: 0.4288 sec
0.0866 0.0911 0.0866 0.0758 0.0725 0.0732 0.0706 0.0690 0.0689 0.0689 0.0686 0.0689 0.0690 0.0690 0.0694 0.0697 

[TRAIN] Epoch[1](1024/1500); Loss: 0.080689; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.0975 0.0882 0.1589 0.0865 0.0968 0.0698 0.0729 0.0677 0.0698 0.0662 0.0672 0.0692 0.0686 0.0694 0.0709 0.0715 

[TRAIN] Epoch[1](1025/1500); Loss: 0.061770; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1396 0.1147 0.0572 0.0692 0.0519 0.0574 0.0499 0.0500 0.0490 0.0483 0.0486 0.0499 0.0498 0.0504 0.0509 0.0516 

[TRAIN] Epoch[1](1026/1500); Loss: 0.060966; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2309 0.1798 0.0679 0.0375 0.0349 0.0356 0.0338 0.0339 0.0345 0.0358 0.0373 0.0389 0.0409 0.0426 0.0445 0.0467 

[TRAIN] Epoch[1](1027/1500); Loss: 0.107287; Backpropagation: 0.0935 sec; Batch: 0.4293 sec
0.1505 0.1257 0.1454 0.1281 0.1027 0.0985 0.0975 0.0969 0.0963 0.0962 0.0962 0.0964 0.0964 0.0965 0.0965 0.0967 

[TRAIN] Epoch[1](1028/1500); Loss: 0.069632; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.0975 0.0998 0.1000 0.0682 0.0661 0.0675 0.0644 0.0619 0.0612 0.0609 0.0608 0.0609 0.0610 0.0611 0.0613 0.0615 

[TRAIN] Epoch[1](1029/1500); Loss: 0.131187; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1866 0.1783 0.1523 0.1346 0.1254 0.1232 0.1224 0.1212 0.1204 0.1200 0.1196 0.1193 0.1191 0.1189 0.1188 0.1188 

[TRAIN] Epoch[1](1030/1500); Loss: 0.054582; Backpropagation: 0.0936 sec; Batch: 0.4291 sec
0.0684 0.0558 0.1474 0.0697 0.0722 0.0443 0.0476 0.0399 0.0408 0.0392 0.0401 0.0404 0.0407 0.0413 0.0423 0.0432 

[TRAIN] Epoch[1](1031/1500); Loss: 0.112752; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1565 0.1309 0.1197 0.1130 0.1075 0.1047 0.1050 0.1049 0.1049 0.1053 0.1061 0.1069 0.1078 0.1090 0.1102 0.1116 

[TRAIN] Epoch[1](1032/1500); Loss: 0.045145; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1020 0.1050 0.0564 0.0365 0.0338 0.0325 0.0326 0.0329 0.0334 0.0338 0.0347 0.0356 0.0365 0.0377 0.0388 0.0402 

[TRAIN] Epoch[1](1033/1500); Loss: 0.059746; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.0935 0.0897 0.0615 0.0565 0.0584 0.0515 0.0521 0.0512 0.0520 0.0524 0.0528 0.0542 0.0551 0.0567 0.0583 0.0600 

[TRAIN] Epoch[1](1034/1500); Loss: 0.072034; Backpropagation: 0.0938 sec; Batch: 0.4299 sec
0.1188 0.0955 0.0764 0.0742 0.0708 0.0662 0.0654 0.0649 0.0648 0.0646 0.0645 0.0648 0.0650 0.0651 0.0656 0.0661 

[TRAIN] Epoch[1](1035/1500); Loss: 0.065485; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1193 0.0968 0.0878 0.0699 0.0674 0.0569 0.0563 0.0551 0.0546 0.0545 0.0543 0.0547 0.0546 0.0547 0.0550 0.0557 

[TRAIN] Epoch[1](1036/1500); Loss: 0.045760; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1114 0.0695 0.0734 0.0552 0.0471 0.0387 0.0381 0.0354 0.0340 0.0332 0.0326 0.0322 0.0325 0.0325 0.0328 0.0333 

[TRAIN] Epoch[1](1037/1500); Loss: 0.065005; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.0840 0.0834 0.0759 0.0663 0.0646 0.0634 0.0626 0.0612 0.0606 0.0603 0.0597 0.0598 0.0597 0.0596 0.0594 0.0595 

[TRAIN] Epoch[1](1038/1500); Loss: 0.077866; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1082 0.0991 0.0831 0.0792 0.0750 0.0747 0.0734 0.0724 0.0721 0.0721 0.0720 0.0722 0.0725 0.0729 0.0733 0.0738 

[TRAIN] Epoch[1](1039/1500); Loss: 0.156811; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1802 0.1742 0.1630 0.1603 0.1563 0.1529 0.1520 0.1522 0.1521 0.1522 0.1520 0.1519 0.1520 0.1523 0.1525 0.1528 

[TRAIN] Epoch[1](1040/1500); Loss: 0.094949; Backpropagation: 0.0937 sec; Batch: 0.4410 sec
0.1966 0.1741 0.1170 0.0925 0.0822 0.0821 0.0816 0.0784 0.0775 0.0772 0.0768 0.0766 0.0769 0.0766 0.0764 0.0767 

[TRAIN] Epoch[1](1041/1500); Loss: 0.057713; Backpropagation: 0.0939 sec; Batch: 0.4297 sec
0.0867 0.0671 0.0947 0.0675 0.0629 0.0557 0.0501 0.0493 0.0485 0.0481 0.0483 0.0484 0.0481 0.0488 0.0491 0.0499 

[TRAIN] Epoch[1](1042/1500); Loss: 0.057383; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1172 0.0965 0.0677 0.0537 0.0511 0.0505 0.0489 0.0483 0.0483 0.0479 0.0479 0.0480 0.0481 0.0480 0.0482 0.0481 

[TRAIN] Epoch[1](1043/1500); Loss: 0.130402; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2056 0.1858 0.1460 0.1293 0.1232 0.1210 0.1195 0.1186 0.1181 0.1176 0.1173 0.1170 0.1168 0.1168 0.1170 0.1169 

[TRAIN] Epoch[1](1044/1500); Loss: 0.066227; Backpropagation: 0.0933 sec; Batch: 0.4287 sec
0.1272 0.0970 0.0827 0.0746 0.0690 0.0600 0.0573 0.0552 0.0547 0.0546 0.0542 0.0544 0.0543 0.0546 0.0548 0.0550 

[TRAIN] Epoch[1](1045/1500); Loss: 0.073375; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.0981 0.0901 0.0827 0.0794 0.0709 0.0688 0.0675 0.0667 0.0665 0.0669 0.0672 0.0679 0.0688 0.0697 0.0708 0.0720 

[TRAIN] Epoch[1](1046/1500); Loss: 0.092380; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1873 0.1659 0.0933 0.0806 0.0966 0.0823 0.0770 0.0771 0.0770 0.0768 0.0767 0.0769 0.0769 0.0773 0.0780 0.0782 

[TRAIN] Epoch[1](1047/1500); Loss: 0.084333; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1373 0.1192 0.1035 0.0932 0.0837 0.0793 0.0772 0.0752 0.0740 0.0735 0.0729 0.0726 0.0722 0.0719 0.0718 0.0717 

[TRAIN] Epoch[1](1048/1500); Loss: 0.054812; Backpropagation: 0.0935 sec; Batch: 0.4292 sec
0.0828 0.0530 0.0547 0.0509 0.0666 0.0647 0.0528 0.0484 0.0483 0.0489 0.0491 0.0495 0.0503 0.0515 0.0520 0.0534 

[TRAIN] Epoch[1](1049/1500); Loss: 0.102179; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1111 0.1064 0.1066 0.1057 0.1020 0.1004 0.1003 0.1003 0.1004 0.1004 0.1004 0.1003 0.1001 0.1002 0.1001 0.1001 

[TRAIN] Epoch[1](1050/1500); Loss: 0.093175; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1773 0.1488 0.1196 0.0875 0.0868 0.0876 0.0818 0.0781 0.0780 0.0778 0.0776 0.0776 0.0778 0.0779 0.0782 0.0785 

[TRAIN] Epoch[1](1051/1500); Loss: 0.078907; Backpropagation: 0.0937 sec; Batch: 0.4294 sec
0.1272 0.1098 0.0957 0.0857 0.0771 0.0738 0.0721 0.0706 0.0698 0.0691 0.0687 0.0687 0.0684 0.0684 0.0686 0.0688 

[TRAIN] Epoch[1](1052/1500); Loss: 0.047642; Backpropagation: 0.0952 sec; Batch: 0.4313 sec
0.0586 0.0507 0.0678 0.0523 0.0546 0.0506 0.0455 0.0437 0.0420 0.0427 0.0418 0.0421 0.0421 0.0423 0.0422 0.0434 

[TRAIN] Epoch[1](1053/1500); Loss: 0.128911; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1796 0.1598 0.1484 0.1380 0.1323 0.1283 0.1247 0.1221 0.1198 0.1181 0.1166 0.1160 0.1153 0.1149 0.1146 0.1141 

[TRAIN] Epoch[1](1054/1500); Loss: 0.065348; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1496 0.1236 0.0879 0.0628 0.0636 0.0589 0.0525 0.0505 0.0500 0.0486 0.0489 0.0495 0.0494 0.0497 0.0500 0.0499 

[TRAIN] Epoch[1](1055/1500); Loss: 0.116710; Backpropagation: 0.0936 sec; Batch: 0.4296 sec
0.1791 0.1560 0.1404 0.1182 0.1179 0.1152 0.1106 0.1081 0.1063 0.1046 0.1036 0.1029 0.1014 0.1014 0.1008 0.1007 

[TRAIN] Epoch[1](1056/1500); Loss: 0.118743; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2445 0.1975 0.1531 0.1277 0.1185 0.1134 0.1042 0.0998 0.0961 0.0944 0.0933 0.0926 0.0917 0.0911 0.0911 0.0909 

[TRAIN] Epoch[1](1057/1500); Loss: 0.096830; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.2013 0.1728 0.1375 0.1149 0.1023 0.0920 0.0822 0.0774 0.0752 0.0736 0.0710 0.0702 0.0700 0.0694 0.0697 0.0698 

[TRAIN] Epoch[1](1058/1500); Loss: 0.134275; Backpropagation: 0.0940 sec; Batch: 0.4298 sec
0.2546 0.2077 0.1614 0.1362 0.1282 0.1256 0.1203 0.1175 0.1160 0.1144 0.1133 0.1123 0.1113 0.1104 0.1098 0.1094 

[TRAIN] Epoch[1](1059/1500); Loss: 0.080093; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1445 0.1211 0.0943 0.0819 0.0782 0.0720 0.0678 0.0671 0.0671 0.0674 0.0676 0.0686 0.0693 0.0704 0.0715 0.0726 

[TRAIN] Epoch[1](1060/1500); Loss: 0.094616; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2158 0.1623 0.1074 0.0875 0.0830 0.0806 0.0784 0.0777 0.0782 0.0771 0.0773 0.0775 0.0773 0.0775 0.0780 0.0783 

[TRAIN] Epoch[1](1061/1500); Loss: 0.094576; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.3118 0.2577 0.1677 0.1089 0.0804 0.0626 0.0553 0.0542 0.0540 0.0524 0.0521 0.0517 0.0514 0.0512 0.0510 0.0509 

[TRAIN] Epoch[1](1062/1500); Loss: 0.114502; Backpropagation: 0.0940 sec; Batch: 0.4297 sec
0.1512 0.1372 0.1282 0.1189 0.1151 0.1124 0.1103 0.1091 0.1081 0.1072 0.1066 0.1062 0.1059 0.1055 0.1052 0.1050 

[TRAIN] Epoch[1](1063/1500); Loss: 0.086892; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1493 0.1214 0.1014 0.0914 0.0917 0.0828 0.0790 0.0773 0.0761 0.0748 0.0743 0.0739 0.0741 0.0739 0.0741 0.0746 

[TRAIN] Epoch[1](1064/1500); Loss: 0.115014; Backpropagation: 0.0958 sec; Batch: 0.4305 sec
0.2227 0.1846 0.1413 0.1176 0.1036 0.1001 0.0983 0.0974 0.0971 0.0968 0.0966 0.0964 0.0967 0.0969 0.0970 0.0973 

[TRAIN] Epoch[1](1065/1500); Loss: 0.082483; Backpropagation: 0.0955 sec; Batch: 0.4313 sec
0.1958 0.1540 0.1016 0.0812 0.0736 0.0743 0.0690 0.0664 0.0648 0.0639 0.0632 0.0628 0.0625 0.0624 0.0621 0.0622 

[TRAIN] Epoch[1](1066/1500); Loss: 0.161758; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2098 0.1803 0.1662 0.1657 0.1601 0.1577 0.1568 0.1562 0.1556 0.1553 0.1547 0.1542 0.1540 0.1538 0.1539 0.1538 

[TRAIN] Epoch[1](1067/1500); Loss: 0.077628; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2162 0.1824 0.1024 0.0777 0.0603 0.0596 0.0554 0.0555 0.0546 0.0543 0.0538 0.0537 0.0539 0.0539 0.0540 0.0543 

[TRAIN] Epoch[1](1068/1500); Loss: 0.144332; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2049 0.1683 0.1514 0.1509 0.1428 0.1370 0.1367 0.1369 0.1363 0.1354 0.1349 0.1347 0.1347 0.1347 0.1349 0.1349 

[TRAIN] Epoch[1](1069/1500); Loss: 0.093367; Backpropagation: 0.0938 sec; Batch: 0.4297 sec
0.1109 0.0981 0.1137 0.1100 0.0967 0.0899 0.0881 0.0883 0.0874 0.0871 0.0867 0.0867 0.0870 0.0872 0.0879 0.0883 

[TRAIN] Epoch[1](1070/1500); Loss: 0.087878; Backpropagation: 0.0935 sec; Batch: 0.4291 sec
0.1797 0.1367 0.1087 0.0979 0.0837 0.0774 0.0757 0.0732 0.0722 0.0716 0.0711 0.0710 0.0713 0.0717 0.0718 0.0723 

[TRAIN] Epoch[1](1071/1500); Loss: 0.065329; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.1424 0.0827 0.0651 0.0621 0.0594 0.0570 0.0578 0.0560 0.0555 0.0561 0.0566 0.0573 0.0581 0.0588 0.0596 0.0609 

[TRAIN] Epoch[1](1072/1500); Loss: 0.107582; Backpropagation: 0.0936 sec; Batch: 0.4328 sec
0.1688 0.1489 0.1277 0.1090 0.1027 0.1013 0.0987 0.0970 0.0962 0.0955 0.0956 0.0959 0.0958 0.0959 0.0960 0.0963 

[TRAIN] Epoch[1](1073/1500); Loss: 0.159251; Backpropagation: 0.0933 sec; Batch: 0.4650 sec
0.1890 0.1792 0.1696 0.1606 0.1586 0.1574 0.1563 0.1550 0.1540 0.1533 0.1529 0.1528 0.1526 0.1524 0.1523 0.1521 

[TRAIN] Epoch[1](1074/1500); Loss: 0.098022; Backpropagation: 0.0938 sec; Batch: 0.4415 sec
0.1196 0.1235 0.1157 0.0974 0.0939 0.0956 0.0935 0.0918 0.0915 0.0917 0.0918 0.0917 0.0920 0.0924 0.0929 0.0934 

[TRAIN] Epoch[1](1075/1500); Loss: 0.073257; Backpropagation: 0.0939 sec; Batch: 0.4421 sec
0.1469 0.0985 0.0886 0.0743 0.0714 0.0677 0.0662 0.0622 0.0610 0.0610 0.0616 0.0615 0.0619 0.0626 0.0629 0.0639 

[TRAIN] Epoch[1](1076/1500); Loss: 0.093792; Backpropagation: 0.0938 sec; Batch: 0.4437 sec
0.1238 0.1158 0.1133 0.0943 0.0943 0.0930 0.0894 0.0862 0.0856 0.0853 0.0856 0.0859 0.0862 0.0865 0.0875 0.0880 

[TRAIN] Epoch[1](1077/1500); Loss: 0.104261; Backpropagation: 0.0939 sec; Batch: 0.4426 sec
0.1390 0.1272 0.1156 0.1032 0.1020 0.0997 0.0995 0.0987 0.0980 0.0977 0.0976 0.0974 0.0975 0.0980 0.0984 0.0988 

[TRAIN] Epoch[1](1078/1500); Loss: 0.131775; Backpropagation: 0.0938 sec; Batch: 0.4424 sec
0.1602 0.1610 0.1574 0.1335 0.1278 0.1255 0.1274 0.1260 0.1240 0.1235 0.1233 0.1233 0.1235 0.1238 0.1239 0.1244 

[TRAIN] Epoch[1](1079/1500); Loss: 0.122965; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.1602 0.1428 0.1349 0.1281 0.1219 0.1189 0.1178 0.1179 0.1172 0.1164 0.1159 0.1154 0.1151 0.1151 0.1151 0.1148 

[TRAIN] Epoch[1](1080/1500); Loss: 0.147489; Backpropagation: 0.0933 sec; Batch: 0.4413 sec
0.1839 0.1699 0.1539 0.1550 0.1488 0.1438 0.1426 0.1423 0.1412 0.1406 0.1402 0.1398 0.1395 0.1393 0.1393 0.1397 

[TRAIN] Epoch[1](1081/1500); Loss: 0.103182; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.2180 0.1694 0.1262 0.1031 0.1060 0.0991 0.0905 0.0880 0.0862 0.0834 0.0823 0.0807 0.0803 0.0792 0.0794 0.0789 

[TRAIN] Epoch[1](1082/1500); Loss: 0.157919; Backpropagation: 0.0936 sec; Batch: 0.4454 sec
0.2151 0.2078 0.1771 0.1628 0.1555 0.1516 0.1486 0.1471 0.1466 0.1461 0.1456 0.1451 0.1449 0.1446 0.1443 0.1439 

[TRAIN] Epoch[1](1083/1500); Loss: 0.118247; Backpropagation: 0.0941 sec; Batch: 0.4314 sec
0.1715 0.1476 0.1237 0.1196 0.1151 0.1105 0.1092 0.1100 0.1095 0.1098 0.1095 0.1102 0.1106 0.1108 0.1118 0.1124 

[TRAIN] Epoch[1](1084/1500); Loss: 0.107383; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1273 0.1135 0.1094 0.1149 0.1131 0.1054 0.1020 0.1023 0.1027 0.1032 0.1031 0.1032 0.1035 0.1041 0.1049 0.1056 

[TRAIN] Epoch[1](1085/1500); Loss: 0.076314; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1222 0.1315 0.1363 0.0784 0.0764 0.0635 0.0604 0.0634 0.0618 0.0610 0.0612 0.0609 0.0608 0.0606 0.0610 0.0618 

[TRAIN] Epoch[1](1086/1500); Loss: 0.097860; Backpropagation: 0.0938 sec; Batch: 0.4325 sec
0.1452 0.1237 0.1043 0.0923 0.0911 0.0921 0.0912 0.0905 0.0902 0.0909 0.0916 0.0916 0.0919 0.0924 0.0931 0.0936 

[TRAIN] Epoch[1](1087/1500); Loss: 0.085438; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1404 0.1515 0.1428 0.0755 0.0984 0.0760 0.0678 0.0734 0.0693 0.0692 0.0674 0.0676 0.0661 0.0666 0.0673 0.0678 

[TRAIN] Epoch[1](1088/1500); Loss: 0.072775; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1595 0.1287 0.0821 0.0631 0.0606 0.0646 0.0621 0.0601 0.0600 0.0596 0.0596 0.0598 0.0599 0.0611 0.0616 0.0620 

[TRAIN] Epoch[1](1089/1500); Loss: 0.058651; Backpropagation: 0.0934 sec; Batch: 0.4288 sec
0.1027 0.0608 0.0556 0.0687 0.0626 0.0557 0.0539 0.0526 0.0523 0.0522 0.0529 0.0525 0.0531 0.0536 0.0545 0.0546 

[TRAIN] Epoch[1](1090/1500); Loss: 0.110321; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1725 0.1403 0.1122 0.1060 0.1053 0.1058 0.1031 0.1018 0.1020 0.1020 0.1019 0.1018 0.1020 0.1026 0.1029 0.1030 

[TRAIN] Epoch[1](1091/1500); Loss: 0.126668; Backpropagation: 0.0933 sec; Batch: 0.4437 sec
0.1456 0.1501 0.1523 0.1363 0.1356 0.1274 0.1224 0.1210 0.1199 0.1186 0.1172 0.1166 0.1161 0.1161 0.1158 0.1156 

[TRAIN] Epoch[1](1092/1500); Loss: 0.161458; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.2026 0.1855 0.1724 0.1635 0.1657 0.1600 0.1550 0.1536 0.1531 0.1530 0.1529 0.1527 0.1527 0.1531 0.1535 0.1541 

[TRAIN] Epoch[1](1093/1500); Loss: 0.066772; Backpropagation: 0.0942 sec; Batch: 0.4298 sec
0.1220 0.0847 0.0703 0.0653 0.0636 0.0623 0.0608 0.0605 0.0600 0.0597 0.0595 0.0596 0.0598 0.0599 0.0600 0.0602 

[TRAIN] Epoch[1](1094/1500); Loss: 0.093658; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1531 0.1191 0.0981 0.0888 0.0883 0.0870 0.0863 0.0862 0.0861 0.0863 0.0862 0.0864 0.0863 0.0867 0.0867 0.0869 

[TRAIN] Epoch[1](1095/1500); Loss: 0.082624; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1841 0.1340 0.0914 0.0739 0.0715 0.0697 0.0686 0.0668 0.0675 0.0682 0.0690 0.0695 0.0705 0.0713 0.0724 0.0735 

[TRAIN] Epoch[1](1096/1500); Loss: 0.036936; Backpropagation: 0.0935 sec; Batch: 0.4293 sec
0.0812 0.0705 0.0506 0.0429 0.0336 0.0305 0.0295 0.0286 0.0280 0.0276 0.0276 0.0275 0.0276 0.0280 0.0283 0.0290 

[TRAIN] Epoch[1](1097/1500); Loss: 0.104006; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1850 0.1454 0.1132 0.1007 0.0996 0.0958 0.0945 0.0934 0.0930 0.0926 0.0922 0.0920 0.0918 0.0917 0.0917 0.0916 

[TRAIN] Epoch[1](1098/1500); Loss: 0.078673; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1142 0.1067 0.0872 0.0774 0.0768 0.0753 0.0735 0.0725 0.0717 0.0715 0.0716 0.0717 0.0718 0.0719 0.0722 0.0727 

[TRAIN] Epoch[1](1099/1500); Loss: 0.146955; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1892 0.1796 0.1626 0.1488 0.1441 0.1425 0.1403 0.1396 0.1391 0.1386 0.1382 0.1379 0.1377 0.1377 0.1377 0.1376 

[TRAIN] Epoch[1](1100/1500); Loss: 0.079704; Backpropagation: 0.0940 sec; Batch: 0.4297 sec
0.1152 0.1137 0.1054 0.0779 0.0778 0.0749 0.0725 0.0715 0.0710 0.0707 0.0707 0.0706 0.0707 0.0707 0.0709 0.0711 

[TRAIN] Epoch[1](1101/1500); Loss: 0.121806; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2155 0.1718 0.1420 0.1274 0.1154 0.1127 0.1136 0.1101 0.1071 0.1059 0.1053 0.1044 0.1040 0.1044 0.1043 0.1049 

[TRAIN] Epoch[1](1102/1500); Loss: 0.146562; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1819 0.1548 0.1526 0.1483 0.1485 0.1435 0.1417 0.1418 0.1414 0.1413 0.1414 0.1414 0.1414 0.1415 0.1416 0.1418 

[TRAIN] Epoch[1](1103/1500); Loss: 0.074295; Backpropagation: 0.0942 sec; Batch: 0.4299 sec
0.1963 0.1345 0.0860 0.0631 0.0693 0.0684 0.0606 0.0581 0.0585 0.0567 0.0565 0.0566 0.0565 0.0560 0.0558 0.0559 

[TRAIN] Epoch[1](1104/1500); Loss: 0.069926; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.1101 0.0927 0.0765 0.0672 0.0663 0.0652 0.0643 0.0638 0.0637 0.0637 0.0639 0.0640 0.0640 0.0642 0.0644 0.0648 

[TRAIN] Epoch[1](1105/1500); Loss: 0.078510; Backpropagation: 0.0959 sec; Batch: 0.4308 sec
0.1220 0.1143 0.0812 0.0740 0.0724 0.0717 0.0716 0.0715 0.0715 0.0716 0.0719 0.0721 0.0723 0.0725 0.0728 0.0728 

[TRAIN] Epoch[1](1106/1500); Loss: 0.125482; Backpropagation: 0.0941 sec; Batch: 0.4308 sec
0.1750 0.1518 0.1387 0.1232 0.1232 0.1200 0.1196 0.1181 0.1172 0.1170 0.1170 0.1170 0.1172 0.1175 0.1176 0.1177 

[TRAIN] Epoch[1](1107/1500); Loss: 0.098008; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1361 0.1283 0.0980 0.0941 0.0940 0.0933 0.0928 0.0927 0.0926 0.0925 0.0923 0.0922 0.0923 0.0923 0.0922 0.0923 

[TRAIN] Epoch[1](1108/1500); Loss: 0.102490; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.1331 0.1445 0.1307 0.0994 0.0958 0.0947 0.0946 0.0941 0.0941 0.0940 0.0938 0.0939 0.0939 0.0941 0.0946 0.0947 

[TRAIN] Epoch[1](1109/1500); Loss: 0.076583; Backpropagation: 0.0943 sec; Batch: 0.4290 sec
0.1267 0.1068 0.0772 0.0755 0.0741 0.0702 0.0702 0.0699 0.0692 0.0689 0.0691 0.0691 0.0694 0.0693 0.0697 0.0700 

[TRAIN] Epoch[1](1110/1500); Loss: 0.053494; Backpropagation: 0.0942 sec; Batch: 0.4400 sec
0.0930 0.0790 0.0782 0.0535 0.0608 0.0494 0.0463 0.0458 0.0445 0.0437 0.0435 0.0436 0.0433 0.0435 0.0437 0.0441 

[TRAIN] Epoch[1](1111/1500); Loss: 0.106919; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1513 0.1395 0.1264 0.1090 0.1039 0.1009 0.0998 0.0990 0.0985 0.0980 0.0977 0.0975 0.0974 0.0973 0.0973 0.0973 

[TRAIN] Epoch[1](1112/1500); Loss: 0.117500; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1820 0.1664 0.1470 0.1213 0.1109 0.1092 0.1072 0.1061 0.1052 0.1045 0.1037 0.1034 0.1033 0.1033 0.1032 0.1034 

[TRAIN] Epoch[1](1113/1500); Loss: 0.058048; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1496 0.1070 0.0644 0.0498 0.0486 0.0467 0.0458 0.0457 0.0457 0.0457 0.0459 0.0461 0.0465 0.0468 0.0471 0.0475 

[TRAIN] Epoch[1](1114/1500); Loss: 0.082134; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1379 0.1221 0.1080 0.0827 0.0756 0.0742 0.0729 0.0718 0.0711 0.0708 0.0708 0.0708 0.0709 0.0712 0.0715 0.0718 

[TRAIN] Epoch[1](1115/1500); Loss: 0.081952; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1120 0.1028 0.1071 0.0826 0.0779 0.0773 0.0765 0.0758 0.0754 0.0749 0.0746 0.0745 0.0745 0.0748 0.0750 0.0754 

[TRAIN] Epoch[1](1116/1500); Loss: 0.055510; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1133 0.0709 0.0806 0.0637 0.0527 0.0509 0.0494 0.0466 0.0459 0.0447 0.0449 0.0444 0.0449 0.0446 0.0452 0.0453 

[TRAIN] Epoch[1](1117/1500); Loss: 0.118148; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1437 0.1282 0.1252 0.1222 0.1153 0.1135 0.1129 0.1126 0.1127 0.1131 0.1136 0.1142 0.1148 0.1154 0.1161 0.1168 

[TRAIN] Epoch[1](1118/1500); Loss: 0.114790; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1461 0.1364 0.1285 0.1222 0.1167 0.1150 0.1133 0.1116 0.1101 0.1087 0.1078 0.1062 0.1053 0.1040 0.1029 0.1020 

[TRAIN] Epoch[1](1119/1500); Loss: 0.096217; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1602 0.1484 0.1479 0.1107 0.0915 0.0873 0.0842 0.0817 0.0801 0.0788 0.0783 0.0778 0.0776 0.0780 0.0783 0.0787 

[TRAIN] Epoch[1](1120/1500); Loss: 0.112574; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1472 0.1246 0.1159 0.1123 0.1103 0.1093 0.1087 0.1083 0.1081 0.1080 0.1079 0.1079 0.1079 0.1081 0.1083 0.1084 

[TRAIN] Epoch[1](1121/1500); Loss: 0.124841; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1655 0.1545 0.1400 0.1257 0.1219 0.1210 0.1202 0.1191 0.1180 0.1169 0.1164 0.1157 0.1159 0.1152 0.1156 0.1158 

[TRAIN] Epoch[1](1122/1500); Loss: 0.161183; Backpropagation: 0.0981 sec; Batch: 0.4327 sec
0.1924 0.1826 0.1645 0.1593 0.1584 0.1580 0.1574 0.1571 0.1568 0.1566 0.1561 0.1558 0.1558 0.1559 0.1560 0.1561 

[TRAIN] Epoch[1](1123/1500); Loss: 0.104348; Backpropagation: 0.0959 sec; Batch: 0.4305 sec
0.1640 0.1392 0.1134 0.1013 0.0987 0.0973 0.0965 0.0961 0.0958 0.0955 0.0953 0.0953 0.0953 0.0953 0.0952 0.0953 

[TRAIN] Epoch[1](1124/1500); Loss: 0.088312; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1330 0.1103 0.1004 0.0900 0.0848 0.0841 0.0834 0.0828 0.0817 0.0808 0.0804 0.0803 0.0802 0.0802 0.0802 0.0805 

[TRAIN] Epoch[1](1125/1500); Loss: 0.076491; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1454 0.0985 0.0787 0.0735 0.0715 0.0695 0.0687 0.0683 0.0681 0.0681 0.0683 0.0683 0.0687 0.0690 0.0695 0.0698 

[TRAIN] Epoch[1](1126/1500); Loss: 0.115344; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1309 0.1281 0.1163 0.1142 0.1127 0.1120 0.1114 0.1113 0.1115 0.1118 0.1122 0.1129 0.1136 0.1146 0.1155 0.1166 

[TRAIN] Epoch[1](1127/1500); Loss: 0.099604; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1541 0.1337 0.1114 0.0989 0.0931 0.0924 0.0919 0.0916 0.0910 0.0906 0.0905 0.0904 0.0906 0.0909 0.0912 0.0914 

[TRAIN] Epoch[1](1128/1500); Loss: 0.081606; Backpropagation: 0.0936 sec; Batch: 0.4288 sec
0.0861 0.0735 0.0615 0.0992 0.0944 0.0915 0.0897 0.0874 0.0832 0.0796 0.0772 0.0760 0.0761 0.0761 0.0768 0.0773 

[TRAIN] Epoch[1](1129/1500); Loss: 0.104948; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1697 0.1327 0.1110 0.1021 0.0998 0.0986 0.0979 0.0972 0.0965 0.0963 0.0959 0.0959 0.0961 0.0962 0.0965 0.0969 

[TRAIN] Epoch[1](1130/1500); Loss: 0.113183; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1488 0.1256 0.1204 0.1136 0.1099 0.1091 0.1084 0.1077 0.1078 0.1076 0.1080 0.1079 0.1084 0.1088 0.1093 0.1097 

[TRAIN] Epoch[1](1131/1500); Loss: 0.085681; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1914 0.1424 0.0977 0.0786 0.0719 0.0705 0.0702 0.0697 0.0701 0.0703 0.0710 0.0715 0.0726 0.0734 0.0744 0.0752 

[TRAIN] Epoch[1](1132/1500); Loss: 0.097558; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1085 0.1029 0.1016 0.0987 0.0963 0.0957 0.0953 0.0951 0.0950 0.0952 0.0954 0.0955 0.0960 0.0964 0.0965 0.0969 

[TRAIN] Epoch[1](1133/1500); Loss: 0.083145; Backpropagation: 0.0938 sec; Batch: 0.4295 sec
0.1289 0.1012 0.0935 0.0858 0.0810 0.0805 0.0786 0.0774 0.0767 0.0761 0.0758 0.0752 0.0752 0.0750 0.0747 0.0748 

[TRAIN] Epoch[1](1134/1500); Loss: 0.088956; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.2515 0.1887 0.1220 0.0867 0.0708 0.0679 0.0657 0.0645 0.0636 0.0630 0.0626 0.0625 0.0627 0.0630 0.0637 0.0645 

[TRAIN] Epoch[1](1135/1500); Loss: 0.079169; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1458 0.1151 0.1027 0.0785 0.0719 0.0702 0.0688 0.0682 0.0677 0.0677 0.0675 0.0679 0.0679 0.0685 0.0687 0.0696 

[TRAIN] Epoch[1](1136/1500); Loss: 0.060876; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1310 0.0905 0.0681 0.0574 0.0539 0.0524 0.0518 0.0515 0.0515 0.0514 0.0517 0.0519 0.0521 0.0525 0.0529 0.0534 

[TRAIN] Epoch[1](1137/1500); Loss: 0.083488; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1283 0.1195 0.1100 0.0819 0.0830 0.0823 0.0766 0.0739 0.0729 0.0725 0.0722 0.0721 0.0722 0.0725 0.0727 0.0731 

[TRAIN] Epoch[1](1138/1500); Loss: 0.077080; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1510 0.1045 0.0793 0.0729 0.0739 0.0722 0.0700 0.0690 0.0685 0.0680 0.0677 0.0676 0.0672 0.0670 0.0672 0.0675 

[TRAIN] Epoch[1](1139/1500); Loss: 0.074074; Backpropagation: 0.0942 sec; Batch: 0.4301 sec
0.1040 0.1064 0.0944 0.0702 0.0774 0.0766 0.0707 0.0669 0.0653 0.0648 0.0648 0.0646 0.0647 0.0646 0.0647 0.0650 

[TRAIN] Epoch[1](1140/1500); Loss: 0.197440; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.2578 0.2411 0.1973 0.1884 0.1936 0.1911 0.1909 0.1903 0.1910 0.1892 0.1895 0.1881 0.1886 0.1875 0.1878 0.1869 

[TRAIN] Epoch[1](1141/1500); Loss: 0.077977; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1516 0.1105 0.0903 0.0759 0.0709 0.0696 0.0685 0.0680 0.0679 0.0676 0.0678 0.0676 0.0678 0.0677 0.0678 0.0680 

[TRAIN] Epoch[1](1142/1500); Loss: 0.086317; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1171 0.1218 0.1287 0.0977 0.0902 0.0869 0.0818 0.0779 0.0752 0.0733 0.0724 0.0719 0.0718 0.0714 0.0715 0.0714 

[TRAIN] Epoch[1](1143/1500); Loss: 0.075372; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1291 0.1107 0.0805 0.0714 0.0705 0.0696 0.0683 0.0682 0.0675 0.0677 0.0673 0.0673 0.0669 0.0670 0.0668 0.0673 

[TRAIN] Epoch[1](1144/1500); Loss: 0.078519; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.0936 0.0932 0.1106 0.0807 0.0733 0.0726 0.0726 0.0716 0.0721 0.0718 0.0724 0.0728 0.0737 0.0743 0.0754 0.0755 

[TRAIN] Epoch[1](1145/1500); Loss: 0.174188; Backpropagation: 0.0943 sec; Batch: 0.4304 sec
0.2189 0.1931 0.1871 0.1799 0.1759 0.1743 0.1720 0.1699 0.1686 0.1671 0.1658 0.1646 0.1637 0.1627 0.1620 0.1614 

[TRAIN] Epoch[1](1146/1500); Loss: 0.078323; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1073 0.0927 0.0832 0.0780 0.0767 0.0756 0.0749 0.0743 0.0739 0.0736 0.0739 0.0737 0.0737 0.0738 0.0739 0.0740 

[TRAIN] Epoch[1](1147/1500); Loss: 0.087820; Backpropagation: 0.0939 sec; Batch: 0.4418 sec
0.1261 0.1181 0.1012 0.0915 0.0876 0.0853 0.0836 0.0824 0.0811 0.0803 0.0793 0.0786 0.0779 0.0778 0.0772 0.0771 

[TRAIN] Epoch[1](1148/1500); Loss: 0.082809; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1463 0.1157 0.0942 0.0809 0.0742 0.0729 0.0727 0.0727 0.0731 0.0732 0.0735 0.0739 0.0745 0.0750 0.0756 0.0764 

[TRAIN] Epoch[1](1149/1500); Loss: 0.133212; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.2169 0.1693 0.1395 0.1300 0.1258 0.1242 0.1233 0.1226 0.1225 0.1220 0.1222 0.1223 0.1224 0.1223 0.1229 0.1230 

[TRAIN] Epoch[1](1150/1500); Loss: 0.129016; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1725 0.1512 0.1402 0.1238 0.1213 0.1197 0.1187 0.1187 0.1195 0.1208 0.1224 0.1241 0.1252 0.1275 0.1288 0.1299 

[TRAIN] Epoch[1](1151/1500); Loss: 0.053353; Backpropagation: 0.0964 sec; Batch: 0.4321 sec
0.0836 0.0805 0.0616 0.0541 0.0522 0.0500 0.0488 0.0479 0.0474 0.0469 0.0467 0.0466 0.0466 0.0468 0.0469 0.0471 

[TRAIN] Epoch[1](1152/1500); Loss: 0.083715; Backpropagation: 0.0958 sec; Batch: 0.4389 sec
0.1265 0.1190 0.1196 0.0891 0.0783 0.0767 0.0754 0.0747 0.0739 0.0734 0.0728 0.0728 0.0720 0.0721 0.0716 0.0717 

[TRAIN] Epoch[1](1153/1500); Loss: 0.105316; Backpropagation: 0.0943 sec; Batch: 0.4287 sec
0.1342 0.1308 0.1193 0.1080 0.1039 0.1021 0.1009 0.0998 0.0991 0.0986 0.0983 0.0981 0.0980 0.0980 0.0979 0.0979 

[TRAIN] Epoch[1](1154/1500); Loss: 0.092718; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1364 0.1183 0.0973 0.0924 0.0908 0.0890 0.0878 0.0867 0.0862 0.0859 0.0856 0.0853 0.0853 0.0853 0.0855 0.0856 

[TRAIN] Epoch[1](1155/1500); Loss: 0.102148; Backpropagation: 0.0942 sec; Batch: 0.4299 sec
0.1311 0.1245 0.1277 0.1041 0.0994 0.0979 0.0956 0.0947 0.0946 0.0943 0.0942 0.0945 0.0949 0.0952 0.0956 0.0961 

[TRAIN] Epoch[1](1156/1500); Loss: 0.092380; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1202 0.1133 0.1151 0.0963 0.0900 0.0885 0.0871 0.0858 0.0853 0.0848 0.0845 0.0846 0.0850 0.0852 0.0856 0.0866 

[TRAIN] Epoch[1](1157/1500); Loss: 0.160082; Backpropagation: 0.0942 sec; Batch: 0.4294 sec
0.1987 0.1905 0.1694 0.1578 0.1534 0.1526 0.1521 0.1516 0.1520 0.1526 0.1532 0.1539 0.1547 0.1555 0.1562 0.1571 

[TRAIN] Epoch[1](1158/1500); Loss: 0.116374; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1497 0.1267 0.1230 0.1171 0.1134 0.1122 0.1115 0.1112 0.1110 0.1110 0.1113 0.1115 0.1120 0.1127 0.1134 0.1142 

[TRAIN] Epoch[1](1159/1500); Loss: 0.074720; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.1783 0.1176 0.0769 0.0713 0.0664 0.0651 0.0649 0.0632 0.0626 0.0618 0.0617 0.0612 0.0612 0.0609 0.0609 0.0614 

[TRAIN] Epoch[1](1160/1500); Loss: 0.051469; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.0956 0.0864 0.1266 0.0556 0.0281 0.0318 0.0314 0.0344 0.0348 0.0367 0.0378 0.0411 0.0414 0.0458 0.0458 0.0501 

[TRAIN] Epoch[1](1161/1500); Loss: 0.130795; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.1615 0.1457 0.1357 0.1298 0.1283 0.1274 0.1265 0.1262 0.1261 0.1260 0.1258 0.1262 0.1266 0.1269 0.1268 0.1272 

[TRAIN] Epoch[1](1162/1500); Loss: 0.078543; Backpropagation: 0.0933 sec; Batch: 0.4359 sec
0.1556 0.1284 0.0912 0.0846 0.0677 0.0657 0.0671 0.0657 0.0638 0.0637 0.0647 0.0652 0.0660 0.0681 0.0687 0.0703 

[TRAIN] Epoch[1](1163/1500); Loss: 0.122783; Backpropagation: 0.0982 sec; Batch: 0.4330 sec
0.2211 0.2017 0.1472 0.1345 0.1153 0.1110 0.1064 0.1039 0.1021 0.1013 0.1010 0.1015 0.1023 0.1040 0.1050 0.1063 

[TRAIN] Epoch[1](1164/1500); Loss: 0.115886; Backpropagation: 0.0961 sec; Batch: 0.4330 sec
0.1255 0.1204 0.1284 0.1361 0.1303 0.1232 0.1180 0.1131 0.1103 0.1085 0.1078 0.1072 0.1065 0.1059 0.1062 0.1068 

[TRAIN] Epoch[1](1165/1500); Loss: 0.117095; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1030 0.1005 0.0981 0.1351 0.1299 0.1254 0.1210 0.1193 0.1181 0.1172 0.1171 0.1169 0.1171 0.1178 0.1182 0.1188 

[TRAIN] Epoch[1](1166/1500); Loss: 0.094721; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.1106 0.1198 0.1126 0.1173 0.1005 0.0942 0.0876 0.0861 0.0849 0.0856 0.0854 0.0851 0.0851 0.0858 0.0868 0.0882 

[TRAIN] Epoch[1](1167/1500); Loss: 0.148510; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.0991 0.0995 0.1105 0.1707 0.1606 0.1560 0.1522 0.1526 0.1530 0.1543 0.1555 0.1572 0.1599 0.1630 0.1651 0.1670 

[TRAIN] Epoch[1](1168/1500); Loss: 0.102481; Backpropagation: 0.0938 sec; Batch: 0.4288 sec
0.1251 0.1156 0.1054 0.1005 0.0972 0.0966 0.0970 0.0977 0.0983 0.0987 0.0993 0.0999 0.1006 0.1018 0.1025 0.1036 

[TRAIN] Epoch[1](1169/1500); Loss: 0.086020; Backpropagation: 0.0944 sec; Batch: 0.4295 sec
0.1058 0.1126 0.1020 0.0897 0.0824 0.0792 0.0748 0.0751 0.0770 0.0781 0.0791 0.0808 0.0823 0.0839 0.0857 0.0879 

[TRAIN] Epoch[1](1170/1500); Loss: 0.126580; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.1403 0.1387 0.1315 0.1256 0.1246 0.1213 0.1210 0.1208 0.1218 0.1223 0.1237 0.1253 0.1262 0.1264 0.1273 0.1286 

[TRAIN] Epoch[1](1171/1500); Loss: 0.130450; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1510 0.1451 0.1293 0.1304 0.1290 0.1267 0.1279 0.1271 0.1272 0.1269 0.1266 0.1269 0.1271 0.1279 0.1285 0.1296 

[TRAIN] Epoch[1](1172/1500); Loss: 0.135505; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1879 0.1688 0.1483 0.1373 0.1309 0.1308 0.1297 0.1284 0.1274 0.1266 0.1259 0.1250 0.1248 0.1253 0.1254 0.1257 

[TRAIN] Epoch[1](1173/1500); Loss: 0.113603; Backpropagation: 0.0937 sec; Batch: 0.4287 sec
0.1622 0.1450 0.1256 0.1153 0.1157 0.1090 0.1046 0.1038 0.1037 0.1035 0.1033 0.1034 0.1043 0.1049 0.1063 0.1069 

[TRAIN] Epoch[1](1174/1500); Loss: 0.100251; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1178 0.1223 0.1237 0.1136 0.1101 0.1047 0.0995 0.0969 0.0942 0.0920 0.0900 0.0886 0.0878 0.0876 0.0875 0.0878 

[TRAIN] Epoch[1](1175/1500); Loss: 0.065941; Backpropagation: 0.0941 sec; Batch: 0.4336 sec
0.0993 0.0478 0.0710 0.0496 0.0586 0.0557 0.0550 0.0585 0.0619 0.0630 0.0662 0.0693 0.0720 0.0737 0.0755 0.0778 

[TRAIN] Epoch[1](1176/1500); Loss: 0.154974; Backpropagation: 0.0941 sec; Batch: 0.4310 sec
0.1907 0.1850 0.1621 0.1605 0.1565 0.1535 0.1517 0.1506 0.1491 0.1475 0.1464 0.1458 0.1455 0.1452 0.1447 0.1447 

[TRAIN] Epoch[1](1177/1500); Loss: 0.102455; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1337 0.1435 0.1419 0.1305 0.1207 0.1141 0.1046 0.0992 0.0931 0.0882 0.0837 0.0805 0.0781 0.0764 0.0757 0.0752 

[TRAIN] Epoch[1](1178/1500); Loss: 0.108650; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1247 0.1322 0.1254 0.1225 0.1139 0.1098 0.1056 0.1035 0.1019 0.1007 0.0999 0.0994 0.0993 0.0994 0.0998 0.1004 

[TRAIN] Epoch[1](1179/1500); Loss: 0.171682; Backpropagation: 0.0935 sec; Batch: 0.4294 sec
0.2065 0.1940 0.1759 0.1741 0.1723 0.1711 0.1696 0.1683 0.1662 0.1652 0.1641 0.1638 0.1638 0.1639 0.1640 0.1640 

[TRAIN] Epoch[1](1180/1500); Loss: 0.072334; Backpropagation: 0.0981 sec; Batch: 0.4342 sec
0.0873 0.0840 0.0800 0.0768 0.0732 0.0703 0.0682 0.0668 0.0665 0.0662 0.0668 0.0676 0.0689 0.0700 0.0715 0.0733 

[TRAIN] Epoch[1](1181/1500); Loss: 0.126099; Backpropagation: 0.0962 sec; Batch: 0.4309 sec
0.1495 0.1493 0.1400 0.1365 0.1281 0.1239 0.1210 0.1197 0.1188 0.1179 0.1178 0.1180 0.1181 0.1188 0.1195 0.1207 

[TRAIN] Epoch[1](1182/1500); Loss: 0.092928; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1373 0.1382 0.0929 0.0871 0.0826 0.0806 0.0826 0.0831 0.0837 0.0843 0.0850 0.0872 0.0881 0.0897 0.0913 0.0931 

[TRAIN] Epoch[1](1183/1500); Loss: 0.166786; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.1805 0.1702 0.1628 0.1627 0.1632 0.1635 0.1636 0.1639 0.1645 0.1652 0.1662 0.1667 0.1674 0.1684 0.1694 0.1704 

[TRAIN] Epoch[1](1184/1500); Loss: 0.156500; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2377 0.2014 0.1662 0.1526 0.1485 0.1481 0.1471 0.1452 0.1435 0.1432 0.1436 0.1445 0.1451 0.1453 0.1457 0.1464 

[TRAIN] Epoch[1](1185/1500); Loss: 0.095631; Backpropagation: 0.0942 sec; Batch: 0.4289 sec
0.1911 0.1247 0.0883 0.0827 0.0867 0.0863 0.0848 0.0848 0.0849 0.0854 0.0859 0.0866 0.0875 0.0888 0.0900 0.0913 

[TRAIN] Epoch[1](1186/1500); Loss: 0.104118; Backpropagation: 0.0942 sec; Batch: 0.4282 sec
0.1370 0.1261 0.1075 0.1021 0.0999 0.0987 0.0980 0.0977 0.0977 0.0980 0.0985 0.0992 0.1000 0.1008 0.1018 0.1030 

[TRAIN] Epoch[1](1187/1500); Loss: 0.136397; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1925 0.1856 0.1470 0.1364 0.1321 0.1293 0.1279 0.1279 0.1264 0.1257 0.1252 0.1254 0.1249 0.1249 0.1253 0.1257 

[TRAIN] Epoch[1](1188/1500); Loss: 0.136613; Backpropagation: 0.0940 sec; Batch: 0.4305 sec
0.2125 0.1990 0.1511 0.1376 0.1285 0.1283 0.1267 0.1256 0.1242 0.1231 0.1221 0.1214 0.1212 0.1212 0.1216 0.1219 

[TRAIN] Epoch[1](1189/1500); Loss: 0.082569; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1177 0.1143 0.1020 0.0909 0.0837 0.0798 0.0770 0.0749 0.0737 0.0728 0.0725 0.0723 0.0721 0.0721 0.0724 0.0729 

[TRAIN] Epoch[1](1190/1500); Loss: 0.066602; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1476 0.1111 0.0754 0.0698 0.0611 0.0584 0.0563 0.0546 0.0539 0.0537 0.0534 0.0533 0.0538 0.0538 0.0545 0.0550 

[TRAIN] Epoch[1](1191/1500); Loss: 0.086228; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1233 0.1086 0.0987 0.0914 0.0846 0.0815 0.0799 0.0788 0.0781 0.0783 0.0783 0.0786 0.0791 0.0796 0.0800 0.0807 

[TRAIN] Epoch[1](1192/1500); Loss: 0.125182; Backpropagation: 0.0962 sec; Batch: 0.4317 sec
0.1788 0.1628 0.1406 0.1301 0.1251 0.1219 0.1182 0.1166 0.1156 0.1146 0.1140 0.1137 0.1132 0.1129 0.1126 0.1124 

[TRAIN] Epoch[1](1193/1500); Loss: 0.117683; Backpropagation: 0.0962 sec; Batch: 0.4322 sec
0.1339 0.1265 0.1221 0.1233 0.1205 0.1173 0.1168 0.1157 0.1153 0.1143 0.1138 0.1130 0.1132 0.1128 0.1125 0.1121 

[TRAIN] Epoch[1](1194/1500); Loss: 0.207081; Backpropagation: 0.0940 sec; Batch: 0.4316 sec
0.2471 0.2310 0.2140 0.2100 0.2072 0.2051 0.2041 0.2030 0.2020 0.2009 0.2001 0.1992 0.1985 0.1977 0.1971 0.1963 

[TRAIN] Epoch[1](1195/1500); Loss: 0.121030; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1716 0.1543 0.1390 0.1266 0.1217 0.1182 0.1158 0.1133 0.1116 0.1101 0.1096 0.1093 0.1090 0.1087 0.1088 0.1087 

[TRAIN] Epoch[1](1196/1500); Loss: 0.082639; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1170 0.1016 0.0928 0.0873 0.0826 0.0774 0.0754 0.0749 0.0756 0.0757 0.0756 0.0763 0.0769 0.0772 0.0777 0.0784 

[TRAIN] Epoch[1](1197/1500); Loss: 0.103186; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1506 0.1335 0.1133 0.1061 0.1025 0.0999 0.0980 0.0965 0.0954 0.0947 0.0939 0.0935 0.0934 0.0933 0.0931 0.0933 

[TRAIN] Epoch[1](1198/1500); Loss: 0.103975; Backpropagation: 0.0937 sec; Batch: 0.4288 sec
0.1415 0.1372 0.1133 0.1048 0.1032 0.1019 0.0999 0.0972 0.0957 0.0951 0.0948 0.0952 0.0957 0.0956 0.0959 0.0965 

[TRAIN] Epoch[1](1199/1500); Loss: 0.191027; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1492 0.1694 0.1895 0.2101 0.1917 0.1872 0.1876 0.1892 0.1908 0.1927 0.1945 0.1965 0.1986 0.2008 0.2031 0.2057 

[TRAIN] Epoch[1](1200/1500); Loss: 0.119024; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.0728 0.0760 0.1004 0.1167 0.1177 0.1180 0.1202 0.1227 0.1250 0.1271 0.1293 0.1315 0.1336 0.1357 0.1378 0.1398 

[TRAIN] Epoch[1](1201/1500); Loss: 0.199824; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1513 0.1626 0.1960 0.2100 0.2070 0.2053 0.2052 0.2053 0.2055 0.2058 0.2061 0.2065 0.2069 0.2074 0.2078 0.2084 

[TRAIN] Epoch[1](1202/1500); Loss: 0.140736; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1526 0.1388 0.1427 0.1454 0.1439 0.1420 0.1411 0.1404 0.1398 0.1391 0.1386 0.1382 0.1378 0.1374 0.1371 0.1369 

[TRAIN] Epoch[1](1203/1500); Loss: 0.140820; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1248 0.1318 0.1520 0.1525 0.1490 0.1467 0.1450 0.1433 0.1418 0.1406 0.1394 0.1385 0.1377 0.1371 0.1366 0.1362 

[TRAIN] Epoch[1](1204/1500); Loss: 0.154703; Backpropagation: 0.0942 sec; Batch: 0.4292 sec
0.1826 0.1646 0.1652 0.1545 0.1511 0.1495 0.1530 0.1536 0.1525 0.1513 0.1504 0.1498 0.1495 0.1493 0.1492 0.1492 

[TRAIN] Epoch[1](1205/1500); Loss: 0.141197; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1554 0.1457 0.1512 0.1489 0.1457 0.1429 0.1413 0.1396 0.1383 0.1373 0.1363 0.1356 0.1352 0.1350 0.1350 0.1357 

[TRAIN] Epoch[1](1206/1500); Loss: 0.153111; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1775 0.1627 0.1555 0.1548 0.1528 0.1515 0.1509 0.1503 0.1499 0.1495 0.1491 0.1490 0.1490 0.1491 0.1491 0.1491 

[TRAIN] Epoch[1](1207/1500); Loss: 0.090733; Backpropagation: 0.0941 sec; Batch: 0.4293 sec
0.1161 0.1002 0.0900 0.0865 0.0850 0.0844 0.0849 0.0853 0.0857 0.0866 0.0879 0.0891 0.0903 0.0917 0.0933 0.0949 

[TRAIN] Epoch[1](1208/1500); Loss: 0.194455; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2142 0.2033 0.1948 0.1911 0.1917 0.1902 0.1893 0.1892 0.1898 0.1904 0.1911 0.1922 0.1935 0.1952 0.1968 0.1986 

[TRAIN] Epoch[1](1209/1500); Loss: 0.120775; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1634 0.1453 0.1246 0.1229 0.1214 0.1194 0.1170 0.1147 0.1130 0.1121 0.1119 0.1122 0.1126 0.1131 0.1139 0.1149 

[TRAIN] Epoch[1](1210/1500); Loss: 0.085296; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1008 0.0922 0.0894 0.0890 0.0829 0.0818 0.0809 0.0807 0.0806 0.0811 0.0816 0.0825 0.0835 0.0847 0.0859 0.0874 

[TRAIN] Epoch[1](1211/1500); Loss: 0.086357; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.0980 0.0890 0.0878 0.0863 0.0834 0.0831 0.0830 0.0832 0.0838 0.0843 0.0846 0.0852 0.0861 0.0870 0.0878 0.0890 

[TRAIN] Epoch[1](1212/1500); Loss: 0.134285; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1666 0.1498 0.1318 0.1369 0.1310 0.1322 0.1309 0.1292 0.1285 0.1286 0.1287 0.1292 0.1297 0.1306 0.1318 0.1329 

[TRAIN] Epoch[1](1213/1500); Loss: 0.144236; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1626 0.1558 0.1449 0.1422 0.1426 0.1417 0.1397 0.1395 0.1396 0.1398 0.1405 0.1416 0.1426 0.1437 0.1450 0.1461 

[TRAIN] Epoch[1](1214/1500); Loss: 0.115477; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1281 0.1211 0.1193 0.1178 0.1166 0.1156 0.1143 0.1137 0.1133 0.1129 0.1126 0.1126 0.1124 0.1123 0.1124 0.1128 

[TRAIN] Epoch[1](1215/1500); Loss: 0.103461; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1759 0.1413 0.1188 0.0980 0.1011 0.1012 0.0944 0.0920 0.0915 0.0913 0.0909 0.0909 0.0912 0.0918 0.0921 0.0928 

[TRAIN] Epoch[1](1216/1500); Loss: 0.099242; Backpropagation: 0.0960 sec; Batch: 0.4304 sec
0.1063 0.0961 0.1051 0.0981 0.1050 0.1065 0.1037 0.1005 0.0985 0.0968 0.0958 0.0952 0.0949 0.0950 0.0950 0.0954 

[TRAIN] Epoch[1](1217/1500); Loss: 0.103777; Backpropagation: 0.0973 sec; Batch: 0.4333 sec
0.1768 0.1485 0.1207 0.1057 0.1022 0.1011 0.0972 0.0947 0.0924 0.0906 0.0894 0.0887 0.0883 0.0881 0.0879 0.0882 

[TRAIN] Epoch[1](1218/1500); Loss: 0.049684; Backpropagation: 0.0939 sec; Batch: 0.4383 sec
0.1356 0.1100 0.0611 0.0487 0.0374 0.0363 0.0359 0.0352 0.0350 0.0353 0.0356 0.0363 0.0369 0.0377 0.0385 0.0396 

[TRAIN] Epoch[1](1219/1500); Loss: 0.125428; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1928 0.1692 0.1441 0.1276 0.1260 0.1240 0.1183 0.1152 0.1134 0.1123 0.1115 0.1110 0.1107 0.1105 0.1102 0.1101 

[TRAIN] Epoch[1](1220/1500); Loss: 0.068406; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1426 0.1254 0.0824 0.0696 0.0595 0.0578 0.0562 0.0553 0.0554 0.0554 0.0552 0.0553 0.0556 0.0558 0.0562 0.0568 

[TRAIN] Epoch[1](1221/1500); Loss: 0.087196; Backpropagation: 0.0943 sec; Batch: 0.4290 sec
0.1316 0.1344 0.1040 0.0950 0.0864 0.0837 0.0793 0.0771 0.0756 0.0748 0.0747 0.0747 0.0750 0.0754 0.0760 0.0775 

[TRAIN] Epoch[1](1222/1500); Loss: 0.121639; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.1787 0.1735 0.1442 0.1321 0.1233 0.1209 0.1140 0.1102 0.1076 0.1062 0.1058 0.1058 0.1060 0.1058 0.1060 0.1061 

[TRAIN] Epoch[1](1223/1500); Loss: 0.089719; Backpropagation: 0.0944 sec; Batch: 0.4291 sec
0.1303 0.1571 0.0961 0.0899 0.0869 0.0869 0.0841 0.0814 0.0798 0.0782 0.0776 0.0772 0.0772 0.0773 0.0776 0.0778 

[TRAIN] Epoch[1](1224/1500); Loss: 0.074960; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1155 0.0784 0.0748 0.0668 0.0727 0.0684 0.0698 0.0684 0.0760 0.0756 0.0736 0.0717 0.0710 0.0716 0.0719 0.0731 

[TRAIN] Epoch[1](1225/1500); Loss: 0.082477; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1190 0.1175 0.0936 0.0883 0.0813 0.0790 0.0774 0.0758 0.0748 0.0741 0.0734 0.0729 0.0729 0.0728 0.0734 0.0736 

[TRAIN] Epoch[1](1226/1500); Loss: 0.108830; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1536 0.1408 0.1103 0.1072 0.1056 0.1046 0.1059 0.1050 0.1027 0.1008 0.1001 0.1000 0.1008 0.1009 0.1013 0.1016 

[TRAIN] Epoch[1](1227/1500); Loss: 0.112943; Backpropagation: 0.0943 sec; Batch: 0.4302 sec
0.1357 0.1399 0.1208 0.1161 0.1109 0.1092 0.1085 0.1079 0.1076 0.1075 0.1074 0.1069 0.1069 0.1068 0.1072 0.1076 

[TRAIN] Epoch[1](1228/1500); Loss: 0.092847; Backpropagation: 0.0938 sec; Batch: 0.4307 sec
0.1285 0.1226 0.0993 0.0950 0.0893 0.0875 0.0864 0.0859 0.0856 0.0855 0.0857 0.0858 0.0862 0.0867 0.0874 0.0882 

[TRAIN] Epoch[1](1229/1500); Loss: 0.105750; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1246 0.1217 0.1089 0.1064 0.1058 0.1047 0.1034 0.1027 0.1024 0.1020 0.1016 0.1015 0.1016 0.1014 0.1016 0.1017 

[TRAIN] Epoch[1](1230/1500); Loss: 0.113929; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1280 0.1246 0.1218 0.1195 0.1160 0.1134 0.1118 0.1105 0.1098 0.1094 0.1092 0.1093 0.1095 0.1097 0.1100 0.1103 

[TRAIN] Epoch[1](1231/1500); Loss: 0.080300; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.0965 0.0965 0.0893 0.0850 0.0807 0.0791 0.0773 0.0761 0.0752 0.0748 0.0749 0.0750 0.0757 0.0758 0.0764 0.0767 

[TRAIN] Epoch[1](1232/1500); Loss: 0.144973; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1791 0.1817 0.1572 0.1491 0.1410 0.1399 0.1388 0.1378 0.1370 0.1366 0.1367 0.1368 0.1371 0.1369 0.1369 0.1369 

[TRAIN] Epoch[1](1233/1500); Loss: 0.090523; Backpropagation: 0.0955 sec; Batch: 0.4299 sec
0.1315 0.1301 0.1042 0.0975 0.0903 0.0898 0.0857 0.0832 0.0811 0.0801 0.0793 0.0791 0.0788 0.0791 0.0789 0.0796 

[TRAIN] Epoch[1](1234/1500); Loss: 0.091617; Backpropagation: 0.0950 sec; Batch: 0.4304 sec
0.1395 0.1754 0.1307 0.1161 0.0990 0.0889 0.0822 0.0786 0.0749 0.0713 0.0695 0.0683 0.0675 0.0680 0.0676 0.0682 

[TRAIN] Epoch[1](1235/1500); Loss: 0.101083; Backpropagation: 0.0953 sec; Batch: 0.4303 sec
0.2027 0.2228 0.1580 0.1500 0.1089 0.0964 0.0773 0.0724 0.0676 0.0653 0.0648 0.0647 0.0650 0.0661 0.0669 0.0684 

[TRAIN] Epoch[1](1236/1500); Loss: 0.113336; Backpropagation: 0.0947 sec; Batch: 0.4293 sec
0.1335 0.1293 0.1244 0.1209 0.1221 0.1184 0.1123 0.1095 0.1079 0.1068 0.1059 0.1055 0.1050 0.1045 0.1039 0.1036 

[TRAIN] Epoch[1](1237/1500); Loss: 0.082971; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.0857 0.0657 0.1147 0.1292 0.1191 0.1007 0.0908 0.0789 0.0716 0.0667 0.0651 0.0655 0.0666 0.0684 0.0687 0.0701 

[TRAIN] Epoch[1](1238/1500); Loss: 0.111543; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1974 0.1903 0.1376 0.1291 0.1064 0.1017 0.0970 0.0953 0.0935 0.0924 0.0915 0.0907 0.0905 0.0903 0.0904 0.0905 

[TRAIN] Epoch[1](1239/1500); Loss: 0.116417; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.2254 0.2702 0.1985 0.2042 0.1401 0.1192 0.0864 0.0814 0.0712 0.0687 0.0672 0.0667 0.0659 0.0658 0.0662 0.0656 

[TRAIN] Epoch[1](1240/1500); Loss: 0.108309; Backpropagation: 0.0954 sec; Batch: 0.4300 sec
0.1336 0.1348 0.1127 0.1126 0.1084 0.1059 0.1047 0.1036 0.1025 0.1018 0.1019 0.1021 0.1019 0.1020 0.1021 0.1023 

[TRAIN] Epoch[1](1241/1500); Loss: 0.111122; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.1261 0.1105 0.1190 0.1054 0.1215 0.1248 0.1211 0.1142 0.1090 0.1050 0.1038 0.1036 0.1037 0.1035 0.1032 0.1035 

[TRAIN] Epoch[1](1242/1500); Loss: 0.076936; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1272 0.1870 0.1298 0.1424 0.0674 0.0559 0.0614 0.0533 0.0510 0.0505 0.0505 0.0501 0.0497 0.0504 0.0513 0.0529 

[TRAIN] Epoch[1](1243/1500); Loss: 0.070099; Backpropagation: 0.0938 sec; Batch: 0.4288 sec
0.1049 0.1423 0.0729 0.0715 0.0718 0.0675 0.0640 0.0637 0.0607 0.0583 0.0580 0.0579 0.0568 0.0568 0.0574 0.0571 

[TRAIN] Epoch[1](1244/1500); Loss: 0.140931; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1897 0.1773 0.1547 0.1469 0.1397 0.1369 0.1328 0.1315 0.1311 0.1309 0.1307 0.1302 0.1302 0.1306 0.1308 0.1308 

[TRAIN] Epoch[1](1245/1500); Loss: 0.122751; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.2320 0.2586 0.1879 0.1913 0.1377 0.1151 0.0897 0.0869 0.0844 0.0833 0.0833 0.0828 0.0821 0.0826 0.0832 0.0830 

[TRAIN] Epoch[1](1246/1500); Loss: 0.101865; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1199 0.1269 0.1127 0.1052 0.1124 0.1081 0.0977 0.0961 0.0950 0.0951 0.0943 0.0939 0.0935 0.0933 0.0928 0.0927 

[TRAIN] Epoch[1](1247/1500); Loss: 0.046910; Backpropagation: 0.0964 sec; Batch: 0.4312 sec
0.1099 0.0649 0.0471 0.0408 0.0520 0.0501 0.0414 0.0389 0.0371 0.0369 0.0375 0.0369 0.0371 0.0393 0.0403 0.0402 

[TRAIN] Epoch[1](1248/1500); Loss: 0.071158; Backpropagation: 0.0933 sec; Batch: 0.4304 sec
0.1001 0.1374 0.0702 0.0672 0.0746 0.0664 0.0690 0.0683 0.0638 0.0598 0.0604 0.0600 0.0598 0.0600 0.0605 0.0609 

[TRAIN] Epoch[1](1249/1500); Loss: 0.109868; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.1598 0.1850 0.1364 0.1355 0.1074 0.1039 0.0979 0.0935 0.0922 0.0916 0.0920 0.0916 0.0920 0.0926 0.0927 0.0937 

[TRAIN] Epoch[1](1250/1500); Loss: 0.067155; Backpropagation: 0.0932 sec; Batch: 0.4283 sec
0.0762 0.1037 0.0702 0.0652 0.0770 0.0693 0.0665 0.0667 0.0640 0.0609 0.0598 0.0589 0.0586 0.0588 0.0592 0.0595 

[TRAIN] Epoch[1](1251/1500); Loss: 0.105836; Backpropagation: 0.0942 sec; Batch: 0.4294 sec
0.1385 0.1508 0.1118 0.1094 0.1087 0.1038 0.1002 0.0992 0.0974 0.0971 0.0956 0.0957 0.0960 0.0958 0.0964 0.0969 

[TRAIN] Epoch[1](1252/1500); Loss: 0.110217; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.1677 0.1554 0.1264 0.1231 0.1108 0.1103 0.1060 0.1000 0.0969 0.0957 0.0950 0.0946 0.0947 0.0948 0.0956 0.0964 

[TRAIN] Epoch[1](1253/1500); Loss: 0.071869; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1115 0.1069 0.0852 0.0809 0.0734 0.0702 0.0648 0.0638 0.0622 0.0614 0.0612 0.0614 0.0615 0.0617 0.0620 0.0621 

[TRAIN] Epoch[1](1254/1500); Loss: 0.081154; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.0984 0.1303 0.0956 0.0902 0.0920 0.0857 0.0748 0.0727 0.0715 0.0708 0.0700 0.0693 0.0690 0.0693 0.0695 0.0694 

[TRAIN] Epoch[1](1255/1500); Loss: 0.113418; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.2510 0.2880 0.1911 0.1810 0.1184 0.1008 0.0724 0.0696 0.0697 0.0678 0.0673 0.0672 0.0672 0.0673 0.0677 0.0681 

[TRAIN] Epoch[1](1256/1500); Loss: 0.094071; Backpropagation: 0.0935 sec; Batch: 0.4292 sec
0.2036 0.1662 0.1018 0.0980 0.0838 0.0827 0.0795 0.0771 0.0764 0.0776 0.0762 0.0758 0.0758 0.0765 0.0767 0.0775 

[TRAIN] Epoch[1](1257/1500); Loss: 0.059596; Backpropagation: 0.0940 sec; Batch: 0.4297 sec
0.0811 0.0962 0.0657 0.0608 0.0688 0.0648 0.0528 0.0502 0.0505 0.0509 0.0510 0.0509 0.0512 0.0521 0.0531 0.0534 

[TRAIN] Epoch[1](1258/1500); Loss: 0.104059; Backpropagation: 0.0944 sec; Batch: 0.4296 sec
0.1173 0.1204 0.1239 0.1145 0.1084 0.1042 0.1008 0.0999 0.0986 0.0979 0.0972 0.0961 0.0962 0.0966 0.0965 0.0964 

[TRAIN] Epoch[1](1259/1500); Loss: 0.109892; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1589 0.1708 0.1321 0.1285 0.1158 0.1097 0.0995 0.0971 0.0946 0.0940 0.0937 0.0934 0.0927 0.0924 0.0924 0.0926 

[TRAIN] Epoch[1](1260/1500); Loss: 0.070588; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.0882 0.0914 0.0882 0.0863 0.0779 0.0706 0.0651 0.0641 0.0638 0.0627 0.0617 0.0611 0.0615 0.0619 0.0621 0.0626 

[TRAIN] Epoch[1](1261/1500); Loss: 0.110441; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1842 0.2106 0.1421 0.1375 0.1125 0.1047 0.0988 0.0917 0.0875 0.0861 0.0858 0.0851 0.0848 0.0849 0.0852 0.0855 

[TRAIN] Epoch[1](1262/1500); Loss: 0.086270; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1075 0.1067 0.0973 0.0882 0.0842 0.0829 0.0813 0.0811 0.0806 0.0805 0.0804 0.0805 0.0814 0.0820 0.0824 0.0832 

[TRAIN] Epoch[1](1263/1500); Loss: 0.092335; Backpropagation: 0.0941 sec; Batch: 0.4302 sec
0.1513 0.1482 0.0984 0.0981 0.0874 0.0847 0.0832 0.0821 0.0813 0.0807 0.0803 0.0800 0.0803 0.0804 0.0803 0.0805 

[TRAIN] Epoch[1](1264/1500); Loss: 0.132378; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1512 0.1530 0.1463 0.1415 0.1323 0.1291 0.1277 0.1267 0.1267 0.1264 0.1257 0.1258 0.1260 0.1264 0.1265 0.1268 

[TRAIN] Epoch[1](1265/1500); Loss: 0.063776; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1166 0.0932 0.0709 0.0640 0.0577 0.0568 0.0554 0.0544 0.0549 0.0551 0.0553 0.0558 0.0565 0.0572 0.0581 0.0587 

[TRAIN] Epoch[1](1266/1500); Loss: 0.131697; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1532 0.1568 0.1389 0.1354 0.1273 0.1261 0.1256 0.1255 0.1257 0.1259 0.1262 0.1268 0.1274 0.1281 0.1287 0.1294 

[TRAIN] Epoch[1](1267/1500); Loss: 0.111449; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1515 0.1585 0.1323 0.1296 0.1138 0.1071 0.1018 0.0995 0.0981 0.0977 0.0978 0.0980 0.0984 0.0992 0.0997 0.1003 

[TRAIN] Epoch[1](1268/1500); Loss: 0.083567; Backpropagation: 0.0957 sec; Batch: 0.4313 sec
0.1578 0.1864 0.1043 0.0996 0.0833 0.0773 0.0651 0.0635 0.0628 0.0622 0.0617 0.0619 0.0622 0.0625 0.0630 0.0634 

[TRAIN] Epoch[1](1269/1500); Loss: 0.073306; Backpropagation: 0.0943 sec; Batch: 0.4295 sec
0.1596 0.1987 0.0897 0.0842 0.0648 0.0618 0.0519 0.0511 0.0509 0.0503 0.0502 0.0503 0.0520 0.0522 0.0522 0.0531 

[TRAIN] Epoch[1](1270/1500); Loss: 0.061805; Backpropagation: 0.0939 sec; Batch: 0.4292 sec
0.1028 0.1339 0.0635 0.0594 0.0646 0.0594 0.0527 0.0509 0.0503 0.0499 0.0496 0.0494 0.0500 0.0505 0.0507 0.0511 

[TRAIN] Epoch[1](1271/1500); Loss: 0.073835; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1020 0.0987 0.0971 0.0870 0.0708 0.0666 0.0664 0.0660 0.0652 0.0651 0.0651 0.0654 0.0658 0.0662 0.0667 0.0672 

[TRAIN] Epoch[1](1272/1500); Loss: 0.099453; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1300 0.1292 0.1107 0.1049 0.1079 0.1043 0.0958 0.0932 0.0912 0.0901 0.0892 0.0887 0.0887 0.0887 0.0889 0.0895 

[TRAIN] Epoch[1](1273/1500); Loss: 0.125763; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.1647 0.1558 0.1358 0.1274 0.1229 0.1222 0.1210 0.1192 0.1187 0.1182 0.1180 0.1173 0.1174 0.1176 0.1179 0.1182 

[TRAIN] Epoch[1](1274/1500); Loss: 0.124910; Backpropagation: 0.0957 sec; Batch: 0.4313 sec
0.2164 0.1975 0.1613 0.1458 0.1220 0.1161 0.1088 0.1075 0.1056 0.1045 0.1034 0.1026 0.1020 0.1017 0.1016 0.1016 

[TRAIN] Epoch[1](1275/1500); Loss: 0.109126; Backpropagation: 0.0947 sec; Batch: 0.4304 sec
0.1222 0.1202 0.1106 0.1090 0.1085 0.1076 0.1066 0.1066 0.1064 0.1062 0.1062 0.1064 0.1067 0.1072 0.1076 0.1081 

[TRAIN] Epoch[1](1276/1500); Loss: 0.129899; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1413 0.1469 0.1400 0.1346 0.1322 0.1280 0.1262 0.1260 0.1255 0.1251 0.1253 0.1252 0.1250 0.1254 0.1259 0.1258 

[TRAIN] Epoch[1](1277/1500); Loss: 0.116901; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1641 0.1464 0.1210 0.1163 0.1160 0.1142 0.1113 0.1104 0.1094 0.1088 0.1086 0.1088 0.1089 0.1087 0.1087 0.1089 

[TRAIN] Epoch[1](1278/1500); Loss: 0.079525; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1456 0.1170 0.1027 0.1254 0.0820 0.0802 0.0719 0.0687 0.0627 0.0590 0.0585 0.0586 0.0587 0.0601 0.0605 0.0609 

[TRAIN] Epoch[1](1279/1500); Loss: 0.086856; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1029 0.0900 0.1049 0.0921 0.0879 0.0876 0.0852 0.0831 0.0825 0.0822 0.0818 0.0821 0.0818 0.0816 0.0819 0.0820 

[TRAIN] Epoch[1](1280/1500); Loss: 0.101715; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1524 0.1616 0.1169 0.1108 0.0986 0.0946 0.0899 0.0883 0.0881 0.0880 0.0883 0.0883 0.0890 0.0901 0.0907 0.0918 

[TRAIN] Epoch[1](1281/1500); Loss: 0.122527; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1389 0.1335 0.1210 0.1198 0.1189 0.1185 0.1187 0.1186 0.1187 0.1194 0.1201 0.1209 0.1217 0.1228 0.1240 0.1250 

[TRAIN] Epoch[1](1282/1500); Loss: 0.115450; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1282 0.1387 0.1166 0.1114 0.1095 0.1097 0.1098 0.1103 0.1108 0.1116 0.1124 0.1133 0.1144 0.1155 0.1168 0.1181 

[TRAIN] Epoch[1](1283/1500); Loss: 0.137489; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1271 0.1526 0.1315 0.1311 0.1321 0.1323 0.1334 0.1344 0.1355 0.1368 0.1382 0.1396 0.1412 0.1428 0.1446 0.1465 

[TRAIN] Epoch[1](1284/1500); Loss: 0.143300; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1633 0.1967 0.1475 0.1419 0.1338 0.1320 0.1312 0.1325 0.1340 0.1356 0.1369 0.1383 0.1399 0.1415 0.1429 0.1446 

[TRAIN] Epoch[1](1285/1500); Loss: 0.095236; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.0850 0.1294 0.0959 0.0873 0.0874 0.0878 0.0887 0.0903 0.0917 0.0929 0.0941 0.0954 0.0970 0.0987 0.1003 0.1019 

[TRAIN] Epoch[1](1286/1500); Loss: 0.151476; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1649 0.1659 0.1445 0.1449 0.1464 0.1473 0.1477 0.1480 0.1486 0.1493 0.1501 0.1509 0.1519 0.1531 0.1543 0.1556 

[TRAIN] Epoch[1](1287/1500); Loss: 0.108340; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.0959 0.1347 0.1082 0.1011 0.1022 0.1029 0.1036 0.1046 0.1057 0.1068 0.1079 0.1091 0.1105 0.1119 0.1134 0.1150 

[TRAIN] Epoch[1](1288/1500); Loss: 0.128034; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1342 0.1404 0.1275 0.1248 0.1246 0.1244 0.1244 0.1246 0.1251 0.1257 0.1265 0.1273 0.1282 0.1292 0.1302 0.1314 

[TRAIN] Epoch[1](1289/1500); Loss: 0.127976; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1606 0.1552 0.1312 0.1244 0.1186 0.1192 0.1193 0.1193 0.1199 0.1210 0.1224 0.1238 0.1254 0.1271 0.1290 0.1310 

[TRAIN] Epoch[1](1290/1500); Loss: 0.202975; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1917 0.2222 0.2020 0.1989 0.1998 0.2000 0.2003 0.2007 0.2013 0.2019 0.2026 0.2033 0.2042 0.2052 0.2062 0.2071 

[TRAIN] Epoch[1](1291/1500); Loss: 0.143769; Backpropagation: 0.0938 sec; Batch: 0.4293 sec
0.1763 0.1830 0.1538 0.1425 0.1406 0.1400 0.1392 0.1383 0.1375 0.1367 0.1362 0.1357 0.1353 0.1352 0.1351 0.1351 

[TRAIN] Epoch[1](1292/1500); Loss: 0.132778; Backpropagation: 0.0956 sec; Batch: 0.4303 sec
0.1397 0.1536 0.1362 0.1306 0.1297 0.1296 0.1297 0.1297 0.1298 0.1299 0.1302 0.1304 0.1307 0.1311 0.1316 0.1320 

[TRAIN] Epoch[1](1293/1500); Loss: 0.086250; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.1942 0.2267 0.1264 0.1006 0.0781 0.0702 0.0657 0.0626 0.0599 0.0578 0.0564 0.0558 0.0556 0.0559 0.0565 0.0575 

[TRAIN] Epoch[1](1294/1500); Loss: 0.102038; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1206 0.1366 0.1094 0.1030 0.0999 0.0994 0.0988 0.0981 0.0975 0.0968 0.0963 0.0957 0.0953 0.0951 0.0950 0.0950 

[TRAIN] Epoch[1](1295/1500); Loss: 0.087352; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.1415 0.1365 0.1039 0.0942 0.0828 0.0828 0.0793 0.0772 0.0756 0.0748 0.0744 0.0744 0.0744 0.0747 0.0752 0.0759 

[TRAIN] Epoch[1](1296/1500); Loss: 0.131546; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.1489 0.1440 0.1345 0.1324 0.1306 0.1302 0.1296 0.1292 0.1288 0.1286 0.1283 0.1281 0.1280 0.1278 0.1278 0.1279 

[TRAIN] Epoch[1](1297/1500); Loss: 0.078664; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1410 0.1494 0.0799 0.0678 0.0699 0.0696 0.0689 0.0683 0.0678 0.0676 0.0675 0.0677 0.0678 0.0681 0.0684 0.0688 

[TRAIN] Epoch[1](1298/1500); Loss: 0.091861; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1042 0.1151 0.0942 0.0903 0.0895 0.0892 0.0890 0.0888 0.0886 0.0886 0.0885 0.0885 0.0885 0.0887 0.0889 0.0892 

[TRAIN] Epoch[1](1299/1500); Loss: 0.124598; Backpropagation: 0.0936 sec; Batch: 0.4409 sec
0.1482 0.1513 0.1293 0.1232 0.1208 0.1209 0.1205 0.1201 0.1199 0.1197 0.1197 0.1197 0.1198 0.1199 0.1201 0.1203 

[TRAIN] Epoch[1](1300/1500); Loss: 0.127150; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1646 0.1472 0.1323 0.1247 0.1238 0.1236 0.1231 0.1226 0.1222 0.1219 0.1217 0.1215 0.1214 0.1213 0.1213 0.1213 

[TRAIN] Epoch[1](1301/1500); Loss: 0.154707; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1879 0.1656 0.1556 0.1545 0.1543 0.1535 0.1525 0.1517 0.1510 0.1505 0.1501 0.1498 0.1497 0.1496 0.1495 0.1496 

[TRAIN] Epoch[1](1302/1500); Loss: 0.116861; Backpropagation: 0.0933 sec; Batch: 0.4286 sec
0.1823 0.1523 0.1318 0.1164 0.1100 0.1094 0.1083 0.1074 0.1068 0.1065 0.1063 0.1062 0.1062 0.1064 0.1066 0.1069 

[TRAIN] Epoch[1](1303/1500); Loss: 0.138827; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1771 0.1759 0.1401 0.1335 0.1316 0.1323 0.1320 0.1319 0.1319 0.1320 0.1323 0.1328 0.1333 0.1340 0.1348 0.1356 

[TRAIN] Epoch[1](1304/1500); Loss: 0.072175; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1192 0.1073 0.0763 0.0714 0.0650 0.0666 0.0657 0.0648 0.0645 0.0645 0.0645 0.0646 0.0648 0.0650 0.0652 0.0653 

[TRAIN] Epoch[1](1305/1500); Loss: 0.077917; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1114 0.1225 0.0910 0.0845 0.0732 0.0714 0.0706 0.0700 0.0696 0.0692 0.0689 0.0688 0.0688 0.0688 0.0688 0.0690 

[TRAIN] Epoch[1](1306/1500); Loss: 0.147071; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1752 0.1594 0.1519 0.1465 0.1461 0.1456 0.1448 0.1442 0.1436 0.1431 0.1427 0.1424 0.1422 0.1420 0.1418 0.1417 

[TRAIN] Epoch[1](1307/1500); Loss: 0.045383; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.0716 0.0860 0.0605 0.0397 0.0386 0.0383 0.0382 0.0382 0.0383 0.0384 0.0387 0.0391 0.0394 0.0399 0.0404 0.0409 

[TRAIN] Epoch[1](1308/1500); Loss: 0.109761; Backpropagation: 0.0938 sec; Batch: 0.4295 sec
0.1268 0.1470 0.1143 0.1060 0.1064 0.1057 0.1049 0.1044 0.1043 0.1043 0.1045 0.1048 0.1051 0.1055 0.1059 0.1063 

[TRAIN] Epoch[1](1309/1500); Loss: 0.081471; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.1134 0.0915 0.0847 0.0801 0.0791 0.0786 0.0781 0.0778 0.0776 0.0774 0.0774 0.0774 0.0774 0.0775 0.0777 0.0778 

[TRAIN] Epoch[1](1310/1500); Loss: 0.066318; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.0867 0.1072 0.0762 0.0708 0.0632 0.0615 0.0606 0.0599 0.0595 0.0593 0.0592 0.0593 0.0593 0.0594 0.0595 0.0595 

[TRAIN] Epoch[1](1311/1500); Loss: 0.122915; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1704 0.1377 0.1235 0.1206 0.1183 0.1193 0.1187 0.1181 0.1177 0.1175 0.1174 0.1174 0.1174 0.1174 0.1175 0.1176 

[TRAIN] Epoch[1](1312/1500); Loss: 0.095298; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.1156 0.1080 0.1085 0.1060 0.0978 0.0960 0.0941 0.0926 0.0913 0.0902 0.0892 0.0884 0.0876 0.0870 0.0865 0.0861 

[TRAIN] Epoch[1](1313/1500); Loss: 0.057354; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.0785 0.0976 0.0634 0.0551 0.0542 0.0531 0.0520 0.0515 0.0513 0.0513 0.0513 0.0513 0.0514 0.0516 0.0518 0.0521 

[TRAIN] Epoch[1](1314/1500); Loss: 0.212663; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.2986 0.2411 0.2112 0.1951 0.1966 0.2000 0.2016 0.2022 0.2030 0.2041 0.2051 0.2063 0.2075 0.2087 0.2100 0.2115 

[TRAIN] Epoch[1](1315/1500); Loss: 0.081003; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1219 0.1103 0.0831 0.0775 0.0766 0.0759 0.0753 0.0748 0.0747 0.0748 0.0749 0.0749 0.0750 0.0753 0.0755 0.0757 

[TRAIN] Epoch[1](1316/1500); Loss: 0.151651; Backpropagation: 0.0945 sec; Batch: 0.4299 sec
0.1794 0.1825 0.1613 0.1534 0.1494 0.1490 0.1481 0.1470 0.1462 0.1455 0.1449 0.1444 0.1441 0.1439 0.1437 0.1436 

[TRAIN] Epoch[1](1317/1500); Loss: 0.140420; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.2114 0.1828 0.1557 0.1403 0.1343 0.1330 0.1320 0.1311 0.1303 0.1295 0.1289 0.1284 0.1279 0.1274 0.1271 0.1267 

[TRAIN] Epoch[1](1318/1500); Loss: 0.059764; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.0745 0.0693 0.0638 0.0665 0.0582 0.0604 0.0578 0.0564 0.0559 0.0559 0.0560 0.0560 0.0560 0.0561 0.0565 0.0569 

[TRAIN] Epoch[1](1319/1500); Loss: 0.073554; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1117 0.0938 0.0819 0.0848 0.0744 0.0759 0.0702 0.0675 0.0660 0.0653 0.0647 0.0643 0.0641 0.0639 0.0640 0.0642 

[TRAIN] Epoch[1](1320/1500); Loss: 0.130573; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.1681 0.1458 0.1332 0.1393 0.1299 0.1263 0.1249 0.1244 0.1244 0.1244 0.1242 0.1242 0.1244 0.1249 0.1252 0.1255 

[TRAIN] Epoch[1](1321/1500); Loss: 0.098139; Backpropagation: 0.0940 sec; Batch: 0.4293 sec
0.1092 0.1008 0.1030 0.1050 0.0975 0.1044 0.0976 0.0952 0.0941 0.0940 0.0942 0.0943 0.0945 0.0949 0.0954 0.0962 

[TRAIN] Epoch[1](1322/1500); Loss: 0.058073; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1037 0.1070 0.0619 0.0548 0.0518 0.0518 0.0506 0.0499 0.0498 0.0496 0.0494 0.0494 0.0494 0.0497 0.0501 0.0504 

[TRAIN] Epoch[1](1323/1500); Loss: 0.117309; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1624 0.1312 0.1203 0.1167 0.1157 0.1160 0.1148 0.1135 0.1124 0.1116 0.1110 0.1106 0.1103 0.1102 0.1101 0.1102 

[TRAIN] Epoch[1](1324/1500); Loss: 0.051608; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.0765 0.0496 0.0591 0.0675 0.0521 0.0619 0.0472 0.0442 0.0446 0.0451 0.0454 0.0455 0.0458 0.0463 0.0471 0.0478 

[TRAIN] Epoch[1](1325/1500); Loss: 0.067754; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1199 0.1395 0.0684 0.0611 0.0610 0.0608 0.0596 0.0583 0.0575 0.0571 0.0569 0.0568 0.0568 0.0568 0.0568 0.0569 

[TRAIN] Epoch[1](1326/1500); Loss: 0.073983; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.0982 0.1035 0.0772 0.0768 0.0733 0.0715 0.0699 0.0691 0.0686 0.0683 0.0680 0.0677 0.0678 0.0678 0.0679 0.0679 

[TRAIN] Epoch[1](1327/1500); Loss: 0.101767; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1160 0.1324 0.1012 0.1034 0.1031 0.1020 0.0997 0.0982 0.0974 0.0968 0.0964 0.0962 0.0962 0.0962 0.0963 0.0967 

[TRAIN] Epoch[1](1328/1500); Loss: 0.073077; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1875 0.1029 0.0682 0.0659 0.0635 0.0627 0.0618 0.0613 0.0614 0.0616 0.0618 0.0618 0.0618 0.0620 0.0624 0.0628 

[TRAIN] Epoch[1](1329/1500); Loss: 0.098844; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1496 0.1122 0.1012 0.0968 0.0963 0.0959 0.0951 0.0944 0.0937 0.0932 0.0927 0.0924 0.0922 0.0921 0.0919 0.0918 

[TRAIN] Epoch[1](1330/1500); Loss: 0.105752; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1324 0.1267 0.1101 0.1074 0.1037 0.1028 0.1020 0.1014 0.1011 0.1008 0.1005 0.1005 0.1005 0.1006 0.1007 0.1008 

[TRAIN] Epoch[1](1331/1500); Loss: 0.074905; Backpropagation: 0.0931 sec; Batch: 0.4277 sec
0.1035 0.0910 0.0755 0.0748 0.0741 0.0731 0.0720 0.0713 0.0708 0.0705 0.0703 0.0702 0.0701 0.0702 0.0705 0.0707 

[TRAIN] Epoch[1](1332/1500); Loss: 0.047231; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.0697 0.0504 0.0523 0.0511 0.0471 0.0508 0.0431 0.0421 0.0423 0.0423 0.0426 0.0431 0.0436 0.0443 0.0451 0.0459 

[TRAIN] Epoch[1](1333/1500); Loss: 0.111624; Backpropagation: 0.0936 sec; Batch: 0.4293 sec
0.1898 0.1334 0.1129 0.1067 0.1058 0.1055 0.1049 0.1042 0.1038 0.1035 0.1032 0.1029 0.1026 0.1024 0.1023 0.1021 

[TRAIN] Epoch[1](1334/1500); Loss: 0.080322; Backpropagation: 0.0931 sec; Batch: 0.4276 sec
0.1596 0.1660 0.0894 0.0775 0.0705 0.0680 0.0667 0.0655 0.0650 0.0647 0.0647 0.0648 0.0650 0.0654 0.0659 0.0666 

[TRAIN] Epoch[1](1335/1500); Loss: 0.074097; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.0975 0.0965 0.0756 0.0730 0.0714 0.0711 0.0708 0.0703 0.0700 0.0698 0.0698 0.0697 0.0698 0.0699 0.0701 0.0703 

[TRAIN] Epoch[1](1336/1500); Loss: 0.074906; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1043 0.1018 0.0780 0.0750 0.0720 0.0712 0.0705 0.0700 0.0697 0.0694 0.0692 0.0692 0.0693 0.0694 0.0696 0.0698 

[TRAIN] Epoch[1](1337/1500); Loss: 0.066705; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1250 0.1380 0.0733 0.0666 0.0586 0.0569 0.0561 0.0556 0.0552 0.0549 0.0546 0.0545 0.0545 0.0544 0.0545 0.0545 

[TRAIN] Epoch[1](1338/1500); Loss: 0.120203; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1767 0.1771 0.1312 0.1207 0.1177 0.1146 0.1120 0.1099 0.1089 0.1083 0.1079 0.1077 0.1075 0.1076 0.1077 0.1079 

[TRAIN] Epoch[1](1339/1500); Loss: 0.087304; Backpropagation: 0.0942 sec; Batch: 0.4292 sec
0.1121 0.1040 0.0896 0.0876 0.0863 0.0852 0.0841 0.0836 0.0833 0.0831 0.0831 0.0830 0.0829 0.0829 0.0829 0.0831 

[TRAIN] Epoch[1](1340/1500); Loss: 0.093566; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.1206 0.1076 0.0968 0.0960 0.0926 0.0910 0.0899 0.0894 0.0892 0.0891 0.0891 0.0891 0.0891 0.0892 0.0892 0.0893 

[TRAIN] Epoch[1](1341/1500); Loss: 0.133729; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.1888 0.1517 0.1265 0.1344 0.1359 0.1332 0.1296 0.1275 0.1266 0.1261 0.1259 0.1260 0.1263 0.1267 0.1270 0.1274 

[TRAIN] Epoch[1](1342/1500); Loss: 0.121174; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1687 0.1647 0.1338 0.1197 0.1156 0.1149 0.1137 0.1127 0.1122 0.1120 0.1118 0.1117 0.1116 0.1117 0.1118 0.1120 

[TRAIN] Epoch[1](1343/1500); Loss: 0.091736; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.2042 0.1385 0.1095 0.0880 0.0818 0.0794 0.0784 0.0777 0.0772 0.0768 0.0765 0.0762 0.0760 0.0759 0.0759 0.0759 

[TRAIN] Epoch[1](1344/1500); Loss: 0.106107; Backpropagation: 0.0956 sec; Batch: 0.4322 sec
0.1671 0.1315 0.1103 0.1041 0.1017 0.1006 0.0996 0.0988 0.0984 0.0981 0.0979 0.0977 0.0977 0.0978 0.0981 0.0982 

[TRAIN] Epoch[1](1345/1500); Loss: 0.107505; Backpropagation: 0.0957 sec; Batch: 0.4317 sec
0.1230 0.1229 0.1144 0.1083 0.1047 0.1042 0.1040 0.1040 0.1041 0.1042 0.1042 0.1043 0.1043 0.1044 0.1045 0.1045 

[TRAIN] Epoch[1](1346/1500); Loss: 0.083546; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1223 0.1132 0.0865 0.0846 0.0816 0.0802 0.0789 0.0778 0.0772 0.0767 0.0765 0.0764 0.0763 0.0763 0.0762 0.0762 

[TRAIN] Epoch[1](1347/1500); Loss: 0.067522; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.0978 0.1022 0.0686 0.0682 0.0637 0.0632 0.0622 0.0613 0.0610 0.0610 0.0611 0.0614 0.0616 0.0619 0.0623 0.0627 

[TRAIN] Epoch[1](1348/1500); Loss: 0.097653; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1286 0.1477 0.1027 0.1009 0.0976 0.0942 0.0914 0.0902 0.0896 0.0891 0.0887 0.0886 0.0884 0.0883 0.0882 0.0883 

[TRAIN] Epoch[1](1349/1500); Loss: 0.075247; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1027 0.1259 0.0833 0.0754 0.0713 0.0696 0.0683 0.0677 0.0675 0.0674 0.0673 0.0672 0.0673 0.0675 0.0676 0.0679 

[TRAIN] Epoch[1](1350/1500); Loss: 0.120420; Backpropagation: 0.0958 sec; Batch: 0.4317 sec
0.1493 0.1575 0.1213 0.1158 0.1145 0.1145 0.1141 0.1136 0.1137 0.1140 0.1145 0.1152 0.1160 0.1167 0.1175 0.1185 

[TRAIN] Epoch[1](1351/1500); Loss: 0.067465; Backpropagation: 0.0958 sec; Batch: 0.4306 sec
0.0969 0.1205 0.0759 0.0682 0.0636 0.0620 0.0604 0.0594 0.0590 0.0588 0.0587 0.0588 0.0592 0.0593 0.0593 0.0596 

[TRAIN] Epoch[1](1352/1500); Loss: 0.052593; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.0793 0.1328 0.0575 0.0493 0.0482 0.0460 0.0443 0.0435 0.0430 0.0427 0.0425 0.0424 0.0424 0.0425 0.0425 0.0426 

[TRAIN] Epoch[1](1353/1500); Loss: 0.057295; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1376 0.0584 0.0596 0.0607 0.0565 0.0522 0.0500 0.0491 0.0487 0.0486 0.0486 0.0488 0.0490 0.0493 0.0496 0.0500 

[TRAIN] Epoch[1](1354/1500); Loss: 0.162775; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1729 0.1705 0.1633 0.1622 0.1613 0.1607 0.1605 0.1605 0.1606 0.1608 0.1610 0.1613 0.1616 0.1619 0.1623 0.1628 

[TRAIN] Epoch[1](1355/1500); Loss: 0.102077; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1516 0.1341 0.1091 0.0994 0.0975 0.0968 0.0956 0.0947 0.0943 0.0941 0.0940 0.0940 0.0942 0.0943 0.0945 0.0948 

[TRAIN] Epoch[1](1356/1500); Loss: 0.112663; Backpropagation: 0.0956 sec; Batch: 0.4314 sec
0.1777 0.1405 0.1182 0.1175 0.1095 0.1066 0.1052 0.1045 0.1039 0.1035 0.1032 0.1029 0.1026 0.1024 0.1022 0.1022 

[TRAIN] Epoch[1](1357/1500); Loss: 0.097893; Backpropagation: 0.0950 sec; Batch: 0.4301 sec
0.1128 0.1103 0.1032 0.0969 0.0968 0.0964 0.0952 0.0945 0.0945 0.0947 0.0948 0.0950 0.0952 0.0952 0.0953 0.0955 

[TRAIN] Epoch[1](1358/1500); Loss: 0.075100; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1111 0.1229 0.0824 0.0756 0.0737 0.0717 0.0699 0.0682 0.0671 0.0664 0.0659 0.0655 0.0652 0.0652 0.0653 0.0654 

[TRAIN] Epoch[1](1359/1500); Loss: 0.094630; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.1346 0.1383 0.1045 0.0972 0.0915 0.0897 0.0884 0.0872 0.0864 0.0858 0.0854 0.0852 0.0850 0.0850 0.0850 0.0849 

[TRAIN] Epoch[1](1360/1500); Loss: 0.045222; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1090 0.0660 0.0477 0.0553 0.0370 0.0382 0.0367 0.0364 0.0359 0.0359 0.0364 0.0367 0.0372 0.0377 0.0384 0.0390 

[TRAIN] Epoch[1](1361/1500); Loss: 0.129168; Backpropagation: 0.0936 sec; Batch: 0.4288 sec
0.1507 0.1393 0.1344 0.1306 0.1284 0.1277 0.1271 0.1266 0.1263 0.1259 0.1255 0.1252 0.1250 0.1249 0.1246 0.1245 

[TRAIN] Epoch[1](1362/1500); Loss: 0.114069; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.2643 0.1819 0.1344 0.0966 0.0983 0.0964 0.0963 0.0963 0.0960 0.0955 0.0952 0.0949 0.0948 0.0948 0.0947 0.0946 

[TRAIN] Epoch[1](1363/1500); Loss: 0.053960; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.0579 0.0561 0.0745 0.0630 0.0518 0.0507 0.0505 0.0505 0.0506 0.0507 0.0508 0.0509 0.0510 0.0512 0.0514 0.0517 

[TRAIN] Epoch[1](1364/1500); Loss: 0.130182; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1688 0.1500 0.1336 0.1301 0.1289 0.1274 0.1264 0.1256 0.1249 0.1245 0.1241 0.1239 0.1238 0.1237 0.1236 0.1235 

[TRAIN] Epoch[1](1365/1500); Loss: 0.081325; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.1435 0.1078 0.0889 0.0842 0.0783 0.0766 0.0750 0.0741 0.0734 0.0728 0.0721 0.0715 0.0711 0.0708 0.0706 0.0704 

[TRAIN] Epoch[1](1366/1500); Loss: 0.099231; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1334 0.1133 0.1001 0.0977 0.0967 0.0960 0.0955 0.0953 0.0952 0.0951 0.0949 0.0948 0.0947 0.0949 0.0950 0.0951 

[TRAIN] Epoch[1](1367/1500); Loss: 0.063173; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1060 0.0975 0.0685 0.0623 0.0587 0.0576 0.0567 0.0563 0.0561 0.0559 0.0557 0.0556 0.0558 0.0558 0.0560 0.0563 

[TRAIN] Epoch[1](1368/1500); Loss: 0.078015; Backpropagation: 0.0959 sec; Batch: 0.4321 sec
0.1549 0.1043 0.0825 0.0780 0.0716 0.0703 0.0694 0.0691 0.0689 0.0686 0.0684 0.0684 0.0684 0.0684 0.0684 0.0686 

[TRAIN] Epoch[1](1369/1500); Loss: 0.072765; Backpropagation: 0.0958 sec; Batch: 0.4314 sec
0.1068 0.0969 0.0754 0.0709 0.0694 0.0688 0.0682 0.0677 0.0674 0.0673 0.0673 0.0673 0.0674 0.0676 0.0678 0.0680 

[TRAIN] Epoch[1](1370/1500); Loss: 0.093168; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1198 0.1203 0.0977 0.0942 0.0924 0.0907 0.0896 0.0888 0.0881 0.0876 0.0873 0.0871 0.0868 0.0866 0.0867 0.0870 

[TRAIN] Epoch[1](1371/1500); Loss: 0.045673; Backpropagation: 0.0936 sec; Batch: 0.4288 sec
0.0583 0.1178 0.0553 0.0441 0.0421 0.0405 0.0393 0.0386 0.0379 0.0373 0.0371 0.0368 0.0367 0.0365 0.0363 0.0363 

[TRAIN] Epoch[1](1372/1500); Loss: 0.104067; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1478 0.1433 0.1141 0.1050 0.0997 0.0981 0.0973 0.0968 0.0964 0.0960 0.0955 0.0952 0.0951 0.0949 0.0949 0.0948 

[TRAIN] Epoch[1](1373/1500); Loss: 0.079818; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1646 0.1046 0.0824 0.0783 0.0742 0.0735 0.0717 0.0707 0.0704 0.0699 0.0695 0.0693 0.0692 0.0693 0.0694 0.0698 

[TRAIN] Epoch[1](1374/1500); Loss: 0.072787; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.0956 0.1006 0.0773 0.0730 0.0711 0.0705 0.0693 0.0683 0.0678 0.0675 0.0673 0.0671 0.0671 0.0672 0.0674 0.0676 

[TRAIN] Epoch[1](1375/1500); Loss: 0.058672; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1280 0.1452 0.0655 0.0539 0.0516 0.0512 0.0482 0.0456 0.0444 0.0440 0.0438 0.0435 0.0434 0.0434 0.0434 0.0435 

[TRAIN] Epoch[1](1376/1500); Loss: 0.101081; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1759 0.1346 0.1056 0.1027 0.0970 0.0950 0.0931 0.0916 0.0908 0.0903 0.0901 0.0900 0.0900 0.0902 0.0901 0.0903 

[TRAIN] Epoch[1](1377/1500); Loss: 0.079339; Backpropagation: 0.0941 sec; Batch: 0.4293 sec
0.1303 0.0899 0.0847 0.0892 0.0755 0.0783 0.0732 0.0712 0.0711 0.0712 0.0715 0.0720 0.0723 0.0724 0.0729 0.0737 

[TRAIN] Epoch[1](1378/1500); Loss: 0.094573; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1377 0.1353 0.1091 0.1015 0.0973 0.0933 0.0902 0.0881 0.0864 0.0848 0.0833 0.0822 0.0814 0.0810 0.0808 0.0808 

[TRAIN] Epoch[1](1379/1500); Loss: 0.059904; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.0809 0.0815 0.0682 0.0614 0.0571 0.0572 0.0561 0.0551 0.0547 0.0548 0.0548 0.0549 0.0551 0.0553 0.0556 0.0558 

[TRAIN] Epoch[1](1380/1500); Loss: 0.133628; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1819 0.1661 0.1396 0.1328 0.1307 0.1292 0.1280 0.1270 0.1263 0.1259 0.1256 0.1254 0.1251 0.1249 0.1248 0.1247 

[TRAIN] Epoch[1](1381/1500); Loss: 0.119683; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.1640 0.1514 0.1294 0.1209 0.1183 0.1165 0.1149 0.1135 0.1126 0.1117 0.1110 0.1105 0.1102 0.1100 0.1100 0.1100 

[TRAIN] Epoch[1](1382/1500); Loss: 0.147749; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2232 0.2297 0.1579 0.1445 0.1274 0.1227 0.1275 0.1301 0.1320 0.1331 0.1343 0.1360 0.1384 0.1405 0.1424 0.1443 

[TRAIN] Epoch[1](1383/1500); Loss: 0.096556; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1402 0.1222 0.0986 0.0962 0.0931 0.0940 0.0920 0.0909 0.0903 0.0898 0.0896 0.0896 0.0896 0.0896 0.0896 0.0896 

[TRAIN] Epoch[1](1384/1500); Loss: 0.150131; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1720 0.1593 0.1599 0.1540 0.1491 0.1479 0.1473 0.1472 0.1468 0.1462 0.1457 0.1457 0.1456 0.1453 0.1451 0.1452 

[TRAIN] Epoch[1](1385/1500); Loss: 0.056875; Backpropagation: 0.0938 sec; Batch: 0.4290 sec
0.1647 0.0838 0.0538 0.0581 0.0497 0.0649 0.0521 0.0438 0.0415 0.0413 0.0411 0.0413 0.0423 0.0430 0.0439 0.0446 

[TRAIN] Epoch[1](1386/1500); Loss: 0.084034; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.1193 0.1009 0.0896 0.0867 0.0851 0.0838 0.0811 0.0801 0.0791 0.0784 0.0776 0.0771 0.0767 0.0764 0.0763 0.0763 

[TRAIN] Epoch[1](1387/1500); Loss: 0.069908; Backpropagation: 0.0940 sec; Batch: 0.4293 sec
0.1654 0.0941 0.0769 0.0681 0.0662 0.0645 0.0629 0.0615 0.0605 0.0596 0.0587 0.0576 0.0568 0.0560 0.0553 0.0545 

[TRAIN] Epoch[1](1388/1500); Loss: 0.059732; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.0875 0.0827 0.0699 0.0633 0.0558 0.0553 0.0543 0.0541 0.0539 0.0539 0.0539 0.0540 0.0539 0.0542 0.0544 0.0545 

[TRAIN] Epoch[1](1389/1500); Loss: 0.188899; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.2039 0.1941 0.1974 0.1929 0.1895 0.1884 0.1878 0.1877 0.1874 0.1870 0.1862 0.1854 0.1846 0.1839 0.1834 0.1830 

[TRAIN] Epoch[1](1390/1500); Loss: 0.052075; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.0956 0.0946 0.0614 0.0541 0.0470 0.0459 0.0448 0.0440 0.0435 0.0433 0.0432 0.0430 0.0429 0.0431 0.0433 0.0435 

[TRAIN] Epoch[1](1391/1500); Loss: 0.110275; Backpropagation: 0.0942 sec; Batch: 0.4345 sec
0.1439 0.1434 0.1175 0.1126 0.1072 0.1060 0.1050 0.1045 0.1041 0.1037 0.1033 0.1030 0.1027 0.1026 0.1025 0.1023 

[TRAIN] Epoch[1](1392/1500); Loss: 0.099795; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1858 0.1448 0.0999 0.1025 0.0985 0.0933 0.0892 0.0879 0.0870 0.0867 0.0869 0.0868 0.0866 0.0868 0.0869 0.0872 

[TRAIN] Epoch[1](1393/1500); Loss: 0.118788; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1698 0.1449 0.1231 0.1199 0.1170 0.1151 0.1139 0.1127 0.1118 0.1112 0.1107 0.1103 0.1101 0.1100 0.1100 0.1100 

[TRAIN] Epoch[1](1394/1500); Loss: 0.086349; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1390 0.1015 0.0865 0.0861 0.0852 0.0823 0.0803 0.0803 0.0802 0.0799 0.0797 0.0798 0.0799 0.0801 0.0803 0.0806 

[TRAIN] Epoch[1](1395/1500); Loss: 0.046898; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1555 0.0432 0.0723 0.0858 0.0567 0.0313 0.0316 0.0303 0.0304 0.0300 0.0301 0.0301 0.0302 0.0304 0.0310 0.0316 

[TRAIN] Epoch[1](1396/1500); Loss: 0.131005; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.1705 0.1809 0.1396 0.1299 0.1264 0.1251 0.1236 0.1225 0.1221 0.1219 0.1215 0.1217 0.1221 0.1223 0.1228 0.1231 

[TRAIN] Epoch[1](1397/1500); Loss: 0.096451; Backpropagation: 0.0956 sec; Batch: 0.4762 sec
0.1087 0.1233 0.0978 0.1004 0.0988 0.0961 0.0939 0.0926 0.0918 0.0915 0.0913 0.0912 0.0912 0.0913 0.0914 0.0917 

[TRAIN] Epoch[1](1398/1500); Loss: 0.057163; Backpropagation: 0.0957 sec; Batch: 0.4306 sec
0.0854 0.0947 0.0691 0.0642 0.0564 0.0543 0.0524 0.0506 0.0495 0.0487 0.0482 0.0478 0.0479 0.0481 0.0484 0.0488 

[TRAIN] Epoch[1](1399/1500); Loss: 0.132299; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1885 0.2270 0.1609 0.1467 0.1350 0.1284 0.1245 0.1211 0.1183 0.1155 0.1131 0.1109 0.1090 0.1073 0.1058 0.1046 

[TRAIN] Epoch[1](1400/1500); Loss: 0.128402; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1606 0.1561 0.1330 0.1301 0.1280 0.1265 0.1252 0.1240 0.1230 0.1222 0.1216 0.1212 0.1209 0.1207 0.1206 0.1206 

[TRAIN] Epoch[1](1401/1500); Loss: 0.123310; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1843 0.2408 0.1571 0.1381 0.1218 0.1135 0.1097 0.1063 0.1038 0.1019 0.1005 0.0997 0.0992 0.0989 0.0986 0.0987 

[TRAIN] Epoch[1](1402/1500); Loss: 0.142680; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1612 0.2122 0.1484 0.1409 0.1383 0.1368 0.1356 0.1348 0.1343 0.1340 0.1338 0.1340 0.1341 0.1344 0.1348 0.1352 

[TRAIN] Epoch[1](1403/1500); Loss: 0.092333; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1371 0.1949 0.1112 0.0988 0.0874 0.0820 0.0792 0.0775 0.0767 0.0763 0.0763 0.0763 0.0761 0.0759 0.0759 0.0758 

[TRAIN] Epoch[1](1404/1500); Loss: 0.095260; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1462 0.1832 0.1139 0.0991 0.0906 0.0868 0.0847 0.0832 0.0819 0.0809 0.0802 0.0794 0.0790 0.0786 0.0783 0.0781 

[TRAIN] Epoch[1](1405/1500); Loss: 0.204996; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.2265 0.2481 0.2110 0.2059 0.2058 0.2045 0.2031 0.2018 0.2006 0.1994 0.1982 0.1971 0.1961 0.1950 0.1938 0.1928 

[TRAIN] Epoch[1](1406/1500); Loss: 0.094613; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1993 0.2643 0.1447 0.1103 0.0830 0.0737 0.0700 0.0672 0.0653 0.0642 0.0631 0.0624 0.0618 0.0614 0.0614 0.0617 

[TRAIN] Epoch[1](1407/1500); Loss: 0.086688; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1172 0.1608 0.1058 0.0983 0.0811 0.0788 0.0774 0.0767 0.0755 0.0751 0.0741 0.0741 0.0731 0.0729 0.0731 0.0729 

[TRAIN] Epoch[1](1408/1500); Loss: 0.107566; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1509 0.1902 0.1191 0.1058 0.1039 0.0987 0.0963 0.0961 0.0958 0.0957 0.0954 0.0950 0.0947 0.0946 0.0944 0.0945 

[TRAIN] Epoch[1](1409/1500); Loss: 0.084227; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1448 0.1782 0.1010 0.0912 0.0784 0.0744 0.0721 0.0708 0.0697 0.0684 0.0675 0.0666 0.0663 0.0662 0.0658 0.0661 

[TRAIN] Epoch[1](1410/1500); Loss: 0.115854; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1358 0.1841 0.1292 0.1294 0.1108 0.1079 0.1070 0.1065 0.1063 0.1056 0.1055 0.1053 0.1051 0.1051 0.1049 0.1051 

[TRAIN] Epoch[1](1411/1500); Loss: 0.101636; Backpropagation: 0.0938 sec; Batch: 0.4290 sec
0.1431 0.1834 0.1232 0.1051 0.0941 0.0913 0.0893 0.0886 0.0883 0.0879 0.0877 0.0878 0.0882 0.0888 0.0893 0.0900 

[TRAIN] Epoch[1](1412/1500); Loss: 0.064263; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1194 0.0631 0.0683 0.0645 0.0595 0.0570 0.0565 0.0569 0.0574 0.0579 0.0589 0.0596 0.0608 0.0618 0.0625 0.0640 

[TRAIN] Epoch[1](1413/1500); Loss: 0.151552; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1667 0.1901 0.1567 0.1568 0.1486 0.1487 0.1483 0.1476 0.1465 0.1457 0.1454 0.1453 0.1447 0.1446 0.1447 0.1445 

[TRAIN] Epoch[1](1414/1500); Loss: 0.099446; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1313 0.1800 0.1116 0.1132 0.0913 0.0892 0.0882 0.0875 0.0873 0.0869 0.0869 0.0870 0.0872 0.0875 0.0880 0.0882 

[TRAIN] Epoch[1](1415/1500); Loss: 0.101215; Backpropagation: 0.0948 sec; Batch: 0.4297 sec
0.1118 0.1434 0.1090 0.1052 0.0968 0.0956 0.0953 0.0950 0.0949 0.0952 0.0955 0.0956 0.0959 0.0961 0.0968 0.0974 

[TRAIN] Epoch[1](1416/1500); Loss: 0.139892; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1518 0.1629 0.1504 0.1447 0.1366 0.1364 0.1363 0.1362 0.1358 0.1357 0.1352 0.1350 0.1351 0.1352 0.1354 0.1354 

[TRAIN] Epoch[1](1417/1500); Loss: 0.120029; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1486 0.1774 0.1194 0.1208 0.1166 0.1164 0.1148 0.1130 0.1118 0.1111 0.1108 0.1105 0.1111 0.1118 0.1125 0.1138 

[TRAIN] Epoch[1](1418/1500); Loss: 0.078106; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.0991 0.1247 0.0776 0.0749 0.0736 0.0729 0.0725 0.0722 0.0720 0.0720 0.0722 0.0724 0.0727 0.0731 0.0736 0.0742 

[TRAIN] Epoch[1](1419/1500); Loss: 0.051318; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.0601 0.1244 0.0500 0.0503 0.0465 0.0432 0.0424 0.0424 0.0427 0.0431 0.0435 0.0442 0.0454 0.0465 0.0476 0.0489 

[TRAIN] Epoch[1](1420/1500); Loss: 0.099297; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1621 0.1833 0.1169 0.1055 0.0919 0.0889 0.0872 0.0861 0.0850 0.0842 0.0835 0.0830 0.0828 0.0826 0.0828 0.0830 

[TRAIN] Epoch[1](1421/1500); Loss: 0.099215; Backpropagation: 0.0958 sec; Batch: 0.4303 sec
0.1645 0.1799 0.1124 0.0977 0.0872 0.0872 0.0863 0.0859 0.0858 0.0856 0.0855 0.0856 0.0857 0.0859 0.0860 0.0863 

[TRAIN] Epoch[1](1422/1500); Loss: 0.122930; Backpropagation: 0.0957 sec; Batch: 0.4306 sec
0.1449 0.1638 0.1269 0.1219 0.1214 0.1203 0.1191 0.1180 0.1171 0.1167 0.1165 0.1161 0.1158 0.1159 0.1161 0.1162 

[TRAIN] Epoch[1](1423/1500); Loss: 0.066085; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.0844 0.1095 0.0682 0.0685 0.0664 0.0637 0.0619 0.0611 0.0604 0.0596 0.0594 0.0592 0.0587 0.0589 0.0589 0.0587 

[TRAIN] Epoch[1](1424/1500); Loss: 0.067894; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1062 0.1200 0.0721 0.0651 0.0629 0.0615 0.0608 0.0605 0.0600 0.0597 0.0594 0.0594 0.0595 0.0595 0.0598 0.0600 

[TRAIN] Epoch[1](1425/1500); Loss: 0.115447; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1302 0.1611 0.1225 0.1137 0.1125 0.1114 0.1104 0.1098 0.1094 0.1091 0.1091 0.1091 0.1092 0.1096 0.1099 0.1102 

[TRAIN] Epoch[1](1426/1500); Loss: 0.119715; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1745 0.1950 0.1445 0.1275 0.1101 0.1079 0.1067 0.1058 0.1049 0.1046 0.1047 0.1050 0.1055 0.1058 0.1062 0.1067 

[TRAIN] Epoch[1](1427/1500); Loss: 0.122750; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.1594 0.1638 0.1333 0.1219 0.1198 0.1187 0.1171 0.1159 0.1150 0.1144 0.1141 0.1140 0.1139 0.1139 0.1142 0.1145 

[TRAIN] Epoch[1](1428/1500); Loss: 0.118610; Backpropagation: 0.0955 sec; Batch: 0.4309 sec
0.1713 0.1865 0.1360 0.1256 0.1120 0.1096 0.1085 0.1073 0.1064 0.1056 0.1053 0.1049 0.1050 0.1049 0.1046 0.1043 

[TRAIN] Epoch[1](1429/1500); Loss: 0.096227; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1142 0.1494 0.1207 0.1011 0.0945 0.0931 0.0907 0.0880 0.0867 0.0861 0.0859 0.0860 0.0859 0.0857 0.0859 0.0860 

[TRAIN] Epoch[1](1430/1500); Loss: 0.180070; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.2509 0.1913 0.1833 0.1801 0.1791 0.1762 0.1745 0.1737 0.1733 0.1725 0.1720 0.1717 0.1714 0.1706 0.1704 0.1700 

[TRAIN] Epoch[1](1431/1500); Loss: 0.071412; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.0832 0.1342 0.0737 0.0677 0.0674 0.0665 0.0661 0.0657 0.0652 0.0651 0.0648 0.0649 0.0647 0.0646 0.0643 0.0645 

[TRAIN] Epoch[1](1432/1500); Loss: 0.127743; Backpropagation: 0.0938 sec; Batch: 0.4299 sec
0.1660 0.1723 0.1352 0.1279 0.1242 0.1234 0.1223 0.1212 0.1202 0.1198 0.1194 0.1189 0.1186 0.1183 0.1182 0.1181 

[TRAIN] Epoch[1](1433/1500); Loss: 0.080886; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.1309 0.1395 0.0844 0.0768 0.0735 0.0719 0.0711 0.0707 0.0707 0.0709 0.0711 0.0715 0.0718 0.0724 0.0732 0.0739 

[TRAIN] Epoch[1](1434/1500); Loss: 0.078726; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1246 0.1487 0.0853 0.0755 0.0709 0.0699 0.0687 0.0680 0.0675 0.0674 0.0677 0.0679 0.0683 0.0691 0.0695 0.0704 

[TRAIN] Epoch[1](1435/1500); Loss: 0.078787; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1300 0.1334 0.0906 0.0770 0.0703 0.0697 0.0697 0.0690 0.0685 0.0686 0.0685 0.0685 0.0690 0.0691 0.0692 0.0695 

[TRAIN] Epoch[1](1436/1500); Loss: 0.076967; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1637 0.1695 0.0891 0.0728 0.0696 0.0681 0.0653 0.0619 0.0601 0.0589 0.0585 0.0585 0.0585 0.0587 0.0591 0.0594 

[TRAIN] Epoch[1](1437/1500); Loss: 0.085562; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.3340 0.1902 0.1207 0.0592 0.0599 0.0599 0.0574 0.0539 0.0537 0.0536 0.0530 0.0542 0.0544 0.0542 0.0552 0.0554 

[TRAIN] Epoch[1](1438/1500); Loss: 0.104880; Backpropagation: 0.0980 sec; Batch: 0.4339 sec
0.2157 0.1671 0.1232 0.0956 0.0951 0.0942 0.0919 0.0898 0.0888 0.0883 0.0880 0.0882 0.0880 0.0878 0.0881 0.0885 

[TRAIN] Epoch[1](1439/1500); Loss: 0.074783; Backpropagation: 0.0958 sec; Batch: 0.4315 sec
0.1197 0.1234 0.0851 0.0740 0.0705 0.0691 0.0676 0.0666 0.0659 0.0654 0.0650 0.0646 0.0646 0.0646 0.0649 0.0654 

[TRAIN] Epoch[1](1440/1500); Loss: 0.105164; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.1172 0.1416 0.1212 0.1111 0.0998 0.0984 0.0986 0.0992 0.0987 0.0986 0.0991 0.0993 0.0993 0.0997 0.1004 0.1004 

[TRAIN] Epoch[1](1441/1500); Loss: 0.114020; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1434 0.1558 0.1188 0.1138 0.1117 0.1104 0.1093 0.1081 0.1076 0.1072 0.1067 0.1063 0.1062 0.1063 0.1062 0.1065 

[TRAIN] Epoch[1](1442/1500); Loss: 0.109002; Backpropagation: 0.0931 sec; Batch: 0.4274 sec
0.1253 0.1423 0.1121 0.1086 0.1065 0.1052 0.1044 0.1041 0.1040 0.1038 0.1039 0.1040 0.1043 0.1047 0.1053 0.1055 

[TRAIN] Epoch[1](1443/1500); Loss: 0.095309; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1448 0.1608 0.0997 0.0921 0.0868 0.0865 0.0861 0.0856 0.0852 0.0851 0.0852 0.0851 0.0851 0.0853 0.0856 0.0859 

[TRAIN] Epoch[1](1444/1500); Loss: 0.103577; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1232 0.1305 0.1178 0.1076 0.1004 0.0990 0.0984 0.0979 0.0977 0.0975 0.0976 0.0978 0.0977 0.0975 0.0979 0.0985 

[TRAIN] Epoch[1](1445/1500); Loss: 0.116344; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1514 0.1473 0.1267 0.1211 0.1171 0.1136 0.1113 0.1100 0.1091 0.1083 0.1079 0.1077 0.1075 0.1074 0.1075 0.1077 

[TRAIN] Epoch[1](1446/1500); Loss: 0.100758; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.1526 0.1670 0.1220 0.1072 0.0962 0.0929 0.0910 0.0898 0.0887 0.0877 0.0871 0.0867 0.0863 0.0859 0.0856 0.0856 

[TRAIN] Epoch[1](1447/1500); Loss: 0.142745; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.1853 0.1912 0.1537 0.1452 0.1392 0.1376 0.1363 0.1352 0.1341 0.1333 0.1329 0.1325 0.1321 0.1319 0.1317 0.1317 

[TRAIN] Epoch[1](1448/1500); Loss: 0.101763; Backpropagation: 0.0931 sec; Batch: 0.4274 sec
0.1214 0.1333 0.1023 0.0994 0.0993 0.0975 0.0968 0.0962 0.0961 0.0962 0.0966 0.0971 0.0979 0.0985 0.0992 0.1002 

[TRAIN] Epoch[1](1449/1500); Loss: 0.143708; Backpropagation: 0.0933 sec; Batch: 0.4286 sec
0.1792 0.1747 0.1482 0.1444 0.1423 0.1409 0.1398 0.1388 0.1379 0.1373 0.1367 0.1363 0.1359 0.1357 0.1356 0.1356 

[TRAIN] Epoch[1](1450/1500); Loss: 0.063424; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.1006 0.0746 0.0632 0.0615 0.0598 0.0585 0.0586 0.0585 0.0586 0.0589 0.0593 0.0596 0.0600 0.0605 0.0610 0.0615 

[TRAIN] Epoch[1](1451/1500); Loss: 0.085585; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1267 0.1174 0.0938 0.0862 0.0827 0.0808 0.0799 0.0791 0.0785 0.0780 0.0777 0.0776 0.0776 0.0775 0.0778 0.0780 

[TRAIN] Epoch[1](1452/1500); Loss: 0.128307; Backpropagation: 0.0932 sec; Batch: 0.4280 sec
0.1849 0.1968 0.1545 0.1442 0.1288 0.1217 0.1179 0.1150 0.1132 0.1120 0.1112 0.1106 0.1104 0.1104 0.1106 0.1108 

[TRAIN] Epoch[1](1453/1500); Loss: 0.055628; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.0861 0.0772 0.0691 0.0634 0.0583 0.0536 0.0510 0.0494 0.0484 0.0479 0.0477 0.0475 0.0474 0.0475 0.0477 0.0480 

[TRAIN] Epoch[1](1454/1500); Loss: 0.055420; Backpropagation: 0.0930 sec; Batch: 0.4274 sec
0.0863 0.0862 0.0699 0.0632 0.0573 0.0526 0.0498 0.0482 0.0472 0.0471 0.0467 0.0463 0.0465 0.0466 0.0463 0.0464 

[TRAIN] Epoch[1](1455/1500); Loss: 0.158988; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1989 0.2051 0.1749 0.1699 0.1612 0.1569 0.1539 0.1515 0.1498 0.1485 0.1475 0.1465 0.1457 0.1450 0.1445 0.1442 

[TRAIN] Epoch[1](1456/1500); Loss: 0.152038; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1683 0.1636 0.1554 0.1522 0.1511 0.1501 0.1497 0.1493 0.1491 0.1490 0.1489 0.1489 0.1490 0.1492 0.1494 0.1494 

[TRAIN] Epoch[1](1457/1500); Loss: 0.083927; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1160 0.1234 0.0942 0.0850 0.0812 0.0792 0.0774 0.0764 0.0760 0.0756 0.0755 0.0757 0.0761 0.0766 0.0771 0.0775 

[TRAIN] Epoch[1](1458/1500); Loss: 0.069243; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1087 0.1260 0.0769 0.0671 0.0629 0.0624 0.0613 0.0606 0.0602 0.0601 0.0599 0.0599 0.0602 0.0604 0.0605 0.0608 

[TRAIN] Epoch[1](1459/1500); Loss: 0.082686; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1496 0.1603 0.1127 0.0959 0.0801 0.0740 0.0706 0.0687 0.0668 0.0654 0.0644 0.0638 0.0633 0.0627 0.0624 0.0622 

[TRAIN] Epoch[1](1460/1500); Loss: 0.123470; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1611 0.1586 0.1330 0.1257 0.1218 0.1195 0.1177 0.1167 0.1161 0.1154 0.1149 0.1147 0.1148 0.1150 0.1151 0.1153 

[TRAIN] Epoch[1](1461/1500); Loss: 0.144163; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1815 0.1870 0.1586 0.1511 0.1435 0.1405 0.1379 0.1365 0.1353 0.1345 0.1340 0.1336 0.1331 0.1331 0.1332 0.1331 

[TRAIN] Epoch[1](1462/1500); Loss: 0.056355; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.0814 0.1338 0.0660 0.0534 0.0479 0.0455 0.0444 0.0438 0.0433 0.0471 0.0478 0.0474 0.0475 0.0499 0.0507 0.0517 

[TRAIN] Epoch[1](1463/1500); Loss: 0.084051; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1332 0.1514 0.1036 0.0866 0.0785 0.0758 0.0744 0.0728 0.0718 0.0711 0.0709 0.0707 0.0707 0.0707 0.0712 0.0714 

[TRAIN] Epoch[1](1464/1500); Loss: 0.112872; Backpropagation: 0.0931 sec; Batch: 0.4276 sec
0.1713 0.1715 0.1325 0.1162 0.1039 0.1022 0.1015 0.1008 0.1002 0.1000 0.1001 0.1005 0.1008 0.1011 0.1015 0.1019 

[TRAIN] Epoch[1](1465/1500); Loss: 0.083457; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1699 0.1727 0.1172 0.0925 0.0741 0.0684 0.0657 0.0648 0.0640 0.0634 0.0632 0.0632 0.0633 0.0641 0.0644 0.0646 

[TRAIN] Epoch[1](1466/1500); Loss: 0.069683; Backpropagation: 0.0929 sec; Batch: 0.4284 sec
0.1103 0.1224 0.0776 0.0678 0.0640 0.0629 0.0620 0.0613 0.0608 0.0605 0.0606 0.0605 0.0606 0.0610 0.0613 0.0615 

[TRAIN] Epoch[1](1467/1500); Loss: 0.107602; Backpropagation: 0.0934 sec; Batch: 0.4358 sec
0.1019 0.1102 0.1743 0.1482 0.1064 0.1013 0.0997 0.0987 0.0979 0.0976 0.0980 0.0978 0.0972 0.0970 0.0976 0.0979 

[TRAIN] Epoch[1](1468/1500); Loss: 0.060468; Backpropagation: 0.0932 sec; Batch: 0.4284 sec
0.1268 0.1217 0.0677 0.0575 0.0534 0.0513 0.0501 0.0490 0.0484 0.0483 0.0485 0.0485 0.0486 0.0490 0.0492 0.0495 

[TRAIN] Epoch[1](1469/1500); Loss: 0.091058; Backpropagation: 0.0933 sec; Batch: 0.4286 sec
0.1653 0.1728 0.0893 0.0855 0.0820 0.0797 0.0787 0.0782 0.0780 0.0776 0.0778 0.0776 0.0781 0.0784 0.0787 0.0792 

[TRAIN] Epoch[1](1470/1500); Loss: 0.089677; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1199 0.1310 0.1019 0.0915 0.0860 0.0853 0.0838 0.0830 0.0821 0.0817 0.0816 0.0815 0.0813 0.0814 0.0816 0.0814 

[TRAIN] Epoch[1](1471/1500); Loss: 0.069522; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1905 0.1713 0.0690 0.0566 0.0527 0.0515 0.0517 0.0509 0.0511 0.0514 0.0514 0.0517 0.0524 0.0529 0.0533 0.0540 

[TRAIN] Epoch[1](1472/1500); Loss: 0.119530; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.1695 0.1718 0.1237 0.1165 0.1161 0.1142 0.1133 0.1121 0.1111 0.1105 0.1098 0.1096 0.1092 0.1086 0.1084 0.1081 

[TRAIN] Epoch[1](1473/1500); Loss: 0.108602; Backpropagation: 0.0948 sec; Batch: 0.4306 sec
0.1169 0.1320 0.1234 0.1139 0.1103 0.1088 0.1074 0.1060 0.1048 0.1039 0.1030 0.1021 0.1015 0.1014 0.1012 0.1009 

[TRAIN] Epoch[1](1474/1500); Loss: 0.091803; Backpropagation: 0.0938 sec; Batch: 0.4296 sec
0.0736 0.1111 0.0979 0.0943 0.0934 0.0935 0.0930 0.0922 0.0916 0.0911 0.0907 0.0904 0.0899 0.0893 0.0886 0.0882 

[TRAIN] Epoch[1](1475/1500); Loss: 0.198821; Backpropagation: 0.0938 sec; Batch: 0.4290 sec
0.2414 0.2006 0.1906 0.1776 0.1783 0.1993 0.2057 0.2085 0.2064 0.2050 0.2029 0.2000 0.1964 0.1928 0.1894 0.1863 

[TRAIN] Epoch[1](1476/1500); Loss: 0.455837; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1815 0.2025 0.2544 0.3199 0.3911 0.4477 0.4636 0.4943 0.5089 0.5324 0.5478 0.5639 0.5767 0.5903 0.6031 0.6153 

[TRAIN] Epoch[1](1477/1500); Loss: 0.130102; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.1167 0.1186 0.1581 0.1769 0.1682 0.1564 0.1467 0.1372 0.1291 0.1222 0.1165 0.1119 0.1083 0.1060 0.1046 0.1043 

[TRAIN] Epoch[1](1478/1500); Loss: 0.130417; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1611 0.1546 0.1422 0.1516 0.1449 0.1351 0.1280 0.1226 0.1196 0.1180 0.1175 0.1176 0.1179 0.1183 0.1187 0.1192 

[TRAIN] Epoch[1](1479/1500); Loss: 0.113399; Backpropagation: 0.0957 sec; Batch: 0.4304 sec
0.1782 0.1628 0.1304 0.1179 0.1107 0.1044 0.1012 0.0998 0.0989 0.0991 0.1002 0.1009 0.1013 0.1021 0.1026 0.1039 

[TRAIN] Epoch[1](1480/1500); Loss: 0.117485; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.2295 0.2149 0.1249 0.1054 0.1034 0.1008 0.0956 0.0958 0.0967 0.0980 0.0994 0.1004 0.1014 0.1029 0.1044 0.1061 

[TRAIN] Epoch[1](1481/1500); Loss: 0.089221; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.1537 0.1419 0.0899 0.0833 0.0742 0.0726 0.0743 0.0759 0.0775 0.0787 0.0797 0.0815 0.0827 0.0845 0.0876 0.0895 

[TRAIN] Epoch[1](1482/1500); Loss: 0.104324; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.1878 0.1781 0.1183 0.1031 0.0885 0.0860 0.0856 0.0860 0.0865 0.0878 0.0891 0.0908 0.0922 0.0947 0.0964 0.0983 

[TRAIN] Epoch[1](1483/1500); Loss: 0.225301; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.3086 0.2869 0.2525 0.2375 0.2281 0.2229 0.2182 0.2139 0.2100 0.2073 0.2048 0.2031 0.2024 0.2023 0.2028 0.2036 

[TRAIN] Epoch[1](1484/1500); Loss: 0.144680; Backpropagation: 0.0932 sec; Batch: 0.4283 sec
0.1683 0.1522 0.1314 0.1287 0.1305 0.1331 0.1362 0.1395 0.1422 0.1447 0.1467 0.1483 0.1499 0.1523 0.1545 0.1564 

[TRAIN] Epoch[1](1485/1500); Loss: 0.125931; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1864 0.1613 0.1354 0.1367 0.1245 0.1170 0.1139 0.1134 0.1135 0.1134 0.1139 0.1146 0.1156 0.1169 0.1183 0.1200 

[TRAIN] Epoch[1](1486/1500); Loss: 0.177198; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.2378 0.2243 0.1959 0.1794 0.1720 0.1696 0.1678 0.1662 0.1651 0.1647 0.1648 0.1648 0.1651 0.1657 0.1658 0.1660 

[TRAIN] Epoch[1](1487/1500); Loss: 0.234412; Backpropagation: 0.0940 sec; Batch: 0.4295 sec
0.4738 0.3874 0.3346 0.2888 0.2684 0.2529 0.2382 0.2207 0.2042 0.1882 0.1740 0.1613 0.1507 0.1418 0.1352 0.1305 

[TRAIN] Epoch[1](1488/1500); Loss: 0.154173; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.2386 0.2237 0.1667 0.1504 0.1472 0.1461 0.1452 0.1442 0.1427 0.1419 0.1401 0.1389 0.1371 0.1360 0.1345 0.1334 

[TRAIN] Epoch[1](1489/1500); Loss: 0.106929; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1993 0.1483 0.1069 0.0940 0.0932 0.0934 0.0954 0.0955 0.0962 0.0961 0.0970 0.0976 0.0987 0.0992 0.0992 0.1006 

[TRAIN] Epoch[1](1490/1500); Loss: 0.147310; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1837 0.1587 0.1514 0.1456 0.1431 0.1431 0.1437 0.1441 0.1442 0.1441 0.1436 0.1432 0.1426 0.1419 0.1419 0.1420 

[TRAIN] Epoch[1](1491/1500); Loss: 0.090072; Backpropagation: 0.0942 sec; Batch: 0.4300 sec
0.1148 0.1039 0.1024 0.0944 0.0848 0.0836 0.0838 0.0842 0.0844 0.0852 0.0861 0.0866 0.0863 0.0867 0.0867 0.0873 

[TRAIN] Epoch[1](1492/1500); Loss: 0.107724; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.2194 0.1856 0.1139 0.0984 0.0994 0.0958 0.0936 0.0924 0.0910 0.0907 0.0904 0.0903 0.0903 0.0905 0.0908 0.0912 

[TRAIN] Epoch[1](1493/1500); Loss: 0.171611; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2174 0.2011 0.1780 0.1718 0.1677 0.1660 0.1652 0.1653 0.1650 0.1643 0.1641 0.1642 0.1640 0.1638 0.1637 0.1641 

[TRAIN] Epoch[1](1494/1500); Loss: 0.178453; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.2012 0.2047 0.1882 0.1925 0.1917 0.1852 0.1782 0.1737 0.1710 0.1693 0.1682 0.1674 0.1668 0.1662 0.1656 0.1653 

[TRAIN] Epoch[1](1495/1500); Loss: 0.081561; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.0642 0.0650 0.1422 0.1568 0.1204 0.0871 0.0741 0.0683 0.0663 0.0658 0.0652 0.0657 0.0651 0.0660 0.0655 0.0672 

[TRAIN] Epoch[1](1496/1500); Loss: 0.114445; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1327 0.1308 0.1361 0.1266 0.1143 0.1105 0.1095 0.1085 0.1080 0.1081 0.1078 0.1079 0.1077 0.1076 0.1073 0.1077 

[TRAIN] Epoch[1](1497/1500); Loss: 0.077574; Backpropagation: 0.0940 sec; Batch: 0.4515 sec
0.1399 0.1160 0.0926 0.0801 0.0748 0.0712 0.0702 0.0688 0.0677 0.0670 0.0667 0.0660 0.0655 0.0649 0.0651 0.0646 

[TRAIN] Epoch[1](1498/1500); Loss: 0.098282; Backpropagation: 0.0937 sec; Batch: 0.4303 sec
0.1703 0.1521 0.1147 0.1078 0.1009 0.0935 0.0884 0.0850 0.0831 0.0821 0.0826 0.0820 0.0823 0.0822 0.0826 0.0828 

[TRAIN] Epoch[1](1499/1500); Loss: 0.110519; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1224 0.1220 0.1323 0.1228 0.1117 0.1072 0.1055 0.1048 0.1043 0.1044 0.1045 0.1050 0.1050 0.1053 0.1054 0.1059 

[TRAIN] Epoch[1](1500/1500); Loss: 0.082704; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1783 0.1681 0.1162 0.0879 0.0683 0.0658 0.0639 0.0635 0.0636 0.0631 0.0633 0.0632 0.0636 0.0638 0.0653 0.0653 

[TRAIN] Epoch[2](1/1500); Loss: 0.070932; Backpropagation: 0.0980 sec; Batch: 0.4715 sec
0.0550 0.0510 0.1541 0.1639 0.1142 0.0726 0.0571 0.0516 0.0497 0.0513 0.0506 0.0510 0.0521 0.0522 0.0535 0.0550 

[TRAIN] Epoch[2](2/1500); Loss: 0.075685; Backpropagation: 0.0933 sec; Batch: 0.4324 sec
0.1694 0.1393 0.0814 0.0746 0.0674 0.0636 0.0621 0.0612 0.0627 0.0602 0.0596 0.0622 0.0605 0.0607 0.0635 0.0623 

[TRAIN] Epoch[2](3/1500); Loss: 0.083952; Backpropagation: 0.0932 sec; Batch: 0.4330 sec
0.0936 0.0976 0.1074 0.1003 0.0894 0.0832 0.0791 0.0766 0.0756 0.0756 0.0761 0.0765 0.0772 0.0779 0.0786 0.0786 

[TRAIN] Epoch[2](4/1500); Loss: 0.107303; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1280 0.1214 0.1237 0.1211 0.1128 0.1070 0.1040 0.1018 0.1008 0.1003 0.0998 0.0992 0.0990 0.0990 0.0992 0.0997 

[TRAIN] Epoch[2](5/1500); Loss: 0.093673; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1035 0.1145 0.1127 0.1054 0.0989 0.0950 0.0920 0.0897 0.0880 0.0867 0.0858 0.0855 0.0851 0.0849 0.0854 0.0859 

[TRAIN] Epoch[2](6/1500); Loss: 0.135096; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.0973 0.1067 0.1653 0.1731 0.1670 0.1580 0.1518 0.1457 0.1397 0.1341 0.1291 0.1249 0.1211 0.1180 0.1157 0.1140 

[TRAIN] Epoch[2](7/1500); Loss: 0.173435; Backpropagation: 0.0936 sec; Batch: 0.4288 sec
0.1726 0.1680 0.1890 0.1967 0.1932 0.1867 0.1822 0.1779 0.1739 0.1703 0.1669 0.1640 0.1614 0.1591 0.1573 0.1558 

[TRAIN] Epoch[2](8/1500); Loss: 0.122636; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1157 0.1320 0.1487 0.1450 0.1383 0.1334 0.1289 0.1247 0.1210 0.1176 0.1146 0.1119 0.1096 0.1079 0.1068 0.1060 

[TRAIN] Epoch[2](9/1500); Loss: 0.164912; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1748 0.1662 0.1724 0.1808 0.1777 0.1728 0.1696 0.1666 0.1637 0.1613 0.1591 0.1572 0.1557 0.1545 0.1535 0.1528 

[TRAIN] Epoch[2](10/1500); Loss: 0.143433; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1676 0.1547 0.1550 0.1485 0.1439 0.1409 0.1390 0.1378 0.1371 0.1370 0.1372 0.1376 0.1383 0.1391 0.1402 0.1411 

[TRAIN] Epoch[2](11/1500); Loss: 0.085097; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1407 0.1228 0.0920 0.0849 0.0791 0.0765 0.0747 0.0737 0.0734 0.0738 0.0748 0.0757 0.0775 0.0789 0.0805 0.0826 

[TRAIN] Epoch[2](12/1500); Loss: 0.100624; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1104 0.1079 0.1192 0.1139 0.1071 0.1016 0.0978 0.0950 0.0932 0.0926 0.0927 0.0935 0.0944 0.0956 0.0968 0.0983 

[TRAIN] Epoch[2](13/1500); Loss: 0.123219; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1481 0.1422 0.1228 0.1189 0.1171 0.1168 0.1171 0.1178 0.1186 0.1193 0.1204 0.1218 0.1228 0.1220 0.1223 0.1235 

[TRAIN] Epoch[2](14/1500); Loss: 0.053351; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.1209 0.0702 0.0488 0.0401 0.0395 0.0404 0.0426 0.0447 0.0456 0.0469 0.0491 0.0500 0.0512 0.0530 0.0545 0.0561 

[TRAIN] Epoch[2](15/1500); Loss: 0.138815; Backpropagation: 0.0931 sec; Batch: 0.4279 sec
0.1736 0.1524 0.1427 0.1384 0.1376 0.1363 0.1353 0.1348 0.1342 0.1335 0.1332 0.1329 0.1335 0.1339 0.1343 0.1345 

[TRAIN] Epoch[2](16/1500); Loss: 0.121783; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1467 0.1331 0.1270 0.1240 0.1213 0.1193 0.1180 0.1172 0.1168 0.1169 0.1170 0.1168 0.1173 0.1185 0.1192 0.1194 

[TRAIN] Epoch[2](17/1500); Loss: 0.107556; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.1343 0.1109 0.1033 0.1017 0.1035 0.1057 0.1066 0.1061 0.1058 0.1059 0.1060 0.1057 0.1060 0.1062 0.1065 0.1067 

[TRAIN] Epoch[2](18/1500); Loss: 0.047580; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.0816 0.0590 0.0451 0.0424 0.0427 0.0432 0.0435 0.0431 0.0429 0.0442 0.0440 0.0439 0.0455 0.0462 0.0470 0.0469 

[TRAIN] Epoch[2](19/1500); Loss: 0.189397; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2755 0.2350 0.2064 0.1767 0.1732 0.1744 0.1762 0.1775 0.1788 0.1799 0.1801 0.1799 0.1795 0.1788 0.1788 0.1796 

[TRAIN] Epoch[2](20/1500); Loss: 0.127058; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1386 0.1308 0.1302 0.1303 0.1269 0.1241 0.1226 0.1221 0.1222 0.1228 0.1237 0.1250 0.1264 0.1279 0.1291 0.1301 

[TRAIN] Epoch[2](21/1500); Loss: 0.100693; Backpropagation: 0.0931 sec; Batch: 0.4304 sec
0.1206 0.1088 0.1005 0.0995 0.0996 0.0993 0.0988 0.0990 0.0982 0.0977 0.0977 0.0973 0.0974 0.0988 0.0989 0.0990 

[TRAIN] Epoch[2](22/1500); Loss: 0.085133; Backpropagation: 0.0956 sec; Batch: 0.4298 sec
0.1137 0.1122 0.0886 0.0825 0.0810 0.0814 0.0805 0.0800 0.0799 0.0796 0.0796 0.0799 0.0802 0.0806 0.0806 0.0817 

[TRAIN] Epoch[2](23/1500); Loss: 0.134697; Backpropagation: 0.0956 sec; Batch: 0.4308 sec
0.1447 0.1379 0.1321 0.1305 0.1307 0.1313 0.1320 0.1324 0.1330 0.1338 0.1341 0.1342 0.1352 0.1365 0.1378 0.1387 

[TRAIN] Epoch[2](24/1500); Loss: 0.144070; Backpropagation: 0.0938 sec; Batch: 0.4291 sec
0.1696 0.1571 0.1478 0.1433 0.1419 0.1421 0.1424 0.1417 0.1403 0.1394 0.1395 0.1398 0.1395 0.1397 0.1403 0.1407 

[TRAIN] Epoch[2](25/1500); Loss: 0.130233; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1684 0.1521 0.1318 0.1276 0.1263 0.1263 0.1263 0.1261 0.1261 0.1259 0.1248 0.1238 0.1242 0.1246 0.1248 0.1248 

[TRAIN] Epoch[2](26/1500); Loss: 0.116140; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1455 0.1246 0.1176 0.1158 0.1153 0.1138 0.1122 0.1114 0.1118 0.1113 0.1113 0.1122 0.1128 0.1134 0.1145 0.1148 

[TRAIN] Epoch[2](27/1500); Loss: 0.096245; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1162 0.1100 0.0999 0.0951 0.0939 0.0936 0.0932 0.0927 0.0918 0.0918 0.0925 0.0925 0.0930 0.0939 0.0945 0.0952 

[TRAIN] Epoch[2](28/1500); Loss: 0.084784; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1171 0.1113 0.0963 0.0926 0.0875 0.0839 0.0815 0.0791 0.0773 0.0762 0.0752 0.0749 0.0750 0.0753 0.0762 0.0770 

[TRAIN] Epoch[2](29/1500); Loss: 0.091814; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1181 0.1199 0.1001 0.0935 0.0909 0.0896 0.0880 0.0865 0.0858 0.0852 0.0852 0.0846 0.0850 0.0854 0.0853 0.0859 

[TRAIN] Epoch[2](30/1500); Loss: 0.173420; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.2065 0.1856 0.1765 0.1742 0.1738 0.1732 0.1721 0.1700 0.1691 0.1691 0.1687 0.1680 0.1674 0.1671 0.1668 0.1668 

[TRAIN] Epoch[2](31/1500); Loss: 0.103034; Backpropagation: 0.0937 sec; Batch: 0.4297 sec
0.1630 0.1428 0.1191 0.1019 0.0962 0.0945 0.0934 0.0920 0.0916 0.0920 0.0923 0.0925 0.0931 0.0940 0.0949 0.0951 

[TRAIN] Epoch[2](32/1500); Loss: 0.064834; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.0829 0.0850 0.0782 0.0697 0.0662 0.0656 0.0638 0.0611 0.0599 0.0594 0.0583 0.0576 0.0575 0.0574 0.0573 0.0575 

[TRAIN] Epoch[2](33/1500); Loss: 0.135374; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1640 0.1494 0.1439 0.1378 0.1356 0.1341 0.1334 0.1324 0.1311 0.1305 0.1297 0.1292 0.1287 0.1286 0.1287 0.1288 

[TRAIN] Epoch[2](34/1500); Loss: 0.101073; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1393 0.1179 0.1071 0.1035 0.1015 0.0994 0.0969 0.0962 0.0958 0.0946 0.0940 0.0940 0.0946 0.0943 0.0939 0.0943 

[TRAIN] Epoch[2](35/1500); Loss: 0.133078; Backpropagation: 0.0935 sec; Batch: 0.4288 sec
0.1407 0.1334 0.1403 0.1349 0.1307 0.1304 0.1308 0.1305 0.1303 0.1305 0.1310 0.1317 0.1324 0.1330 0.1338 0.1348 

[TRAIN] Epoch[2](36/1500); Loss: 0.105185; Backpropagation: 0.0931 sec; Batch: 0.4277 sec
0.1235 0.1139 0.1076 0.1045 0.1046 0.1038 0.1027 0.1026 0.1031 0.1022 0.1019 0.1024 0.1029 0.1024 0.1022 0.1027 

[TRAIN] Epoch[2](37/1500); Loss: 0.096293; Backpropagation: 0.0931 sec; Batch: 0.4339 sec
0.1294 0.1148 0.1027 0.0968 0.0953 0.0937 0.0923 0.0913 0.0906 0.0905 0.0906 0.0903 0.0902 0.0907 0.0906 0.0909 

[TRAIN] Epoch[2](38/1500); Loss: 0.121897; Backpropagation: 0.0944 sec; Batch: 0.4299 sec
0.1386 0.1346 0.1279 0.1239 0.1213 0.1198 0.1188 0.1182 0.1180 0.1180 0.1179 0.1182 0.1188 0.1189 0.1185 0.1188 

[TRAIN] Epoch[2](39/1500); Loss: 0.083213; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.0980 0.1033 0.0905 0.0842 0.0821 0.0809 0.0794 0.0787 0.0788 0.0785 0.0779 0.0793 0.0795 0.0795 0.0798 0.0810 

[TRAIN] Epoch[2](40/1500); Loss: 0.070959; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.0905 0.0835 0.0759 0.0741 0.0701 0.0692 0.0684 0.0676 0.0677 0.0672 0.0670 0.0668 0.0664 0.0666 0.0672 0.0670 

[TRAIN] Epoch[2](41/1500); Loss: 0.096382; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1157 0.1233 0.1088 0.0993 0.0948 0.0928 0.0924 0.0915 0.0904 0.0900 0.0901 0.0902 0.0903 0.0904 0.0908 0.0911 

[TRAIN] Epoch[2](42/1500); Loss: 0.076028; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1147 0.0854 0.0864 0.0769 0.0728 0.0721 0.0716 0.0702 0.0697 0.0699 0.0694 0.0700 0.0707 0.0709 0.0721 0.0736 

[TRAIN] Epoch[2](43/1500); Loss: 0.075130; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.0986 0.0973 0.0827 0.0771 0.0751 0.0737 0.0717 0.0708 0.0700 0.0693 0.0695 0.0690 0.0690 0.0694 0.0693 0.0695 

[TRAIN] Epoch[2](44/1500); Loss: 0.094468; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1273 0.1125 0.0994 0.0939 0.0926 0.0910 0.0905 0.0893 0.0888 0.0886 0.0882 0.0884 0.0889 0.0896 0.0907 0.0918 

[TRAIN] Epoch[2](45/1500); Loss: 0.080653; Backpropagation: 0.0958 sec; Batch: 0.4316 sec
0.1081 0.0892 0.0812 0.0792 0.0780 0.0776 0.0773 0.0770 0.0769 0.0772 0.0772 0.0775 0.0779 0.0782 0.0786 0.0793 

[TRAIN] Epoch[2](46/1500); Loss: 0.141326; Backpropagation: 0.0957 sec; Batch: 0.4296 sec
0.2137 0.1731 0.1523 0.1448 0.1404 0.1369 0.1347 0.1331 0.1315 0.1304 0.1296 0.1290 0.1284 0.1278 0.1276 0.1279 

[TRAIN] Epoch[2](47/1500); Loss: 0.080023; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1270 0.0937 0.0905 0.0830 0.0809 0.0779 0.0766 0.0748 0.0733 0.0721 0.0716 0.0718 0.0709 0.0714 0.0724 0.0724 

[TRAIN] Epoch[2](48/1500); Loss: 0.126242; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1525 0.1407 0.1396 0.1321 0.1281 0.1268 0.1251 0.1229 0.1219 0.1206 0.1200 0.1193 0.1179 0.1178 0.1177 0.1168 

[TRAIN] Epoch[2](49/1500); Loss: 0.128750; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1980 0.1565 0.1364 0.1264 0.1247 0.1242 0.1234 0.1215 0.1202 0.1194 0.1192 0.1186 0.1180 0.1183 0.1181 0.1172 

[TRAIN] Epoch[2](50/1500); Loss: 0.125299; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1737 0.1408 0.1389 0.1255 0.1192 0.1194 0.1194 0.1186 0.1187 0.1183 0.1183 0.1189 0.1185 0.1184 0.1189 0.1191 

[TRAIN] Epoch[2](51/1500); Loss: 0.138278; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1645 0.1628 0.1480 0.1413 0.1370 0.1359 0.1350 0.1336 0.1325 0.1317 0.1317 0.1318 0.1315 0.1314 0.1320 0.1317 

[TRAIN] Epoch[2](52/1500); Loss: 0.148160; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1777 0.1873 0.1655 0.1541 0.1473 0.1453 0.1436 0.1420 0.1402 0.1390 0.1380 0.1376 0.1378 0.1383 0.1385 0.1385 

[TRAIN] Epoch[2](53/1500); Loss: 0.160786; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1837 0.1828 0.1741 0.1666 0.1616 0.1596 0.1585 0.1571 0.1557 0.1548 0.1543 0.1536 0.1530 0.1525 0.1523 0.1522 

[TRAIN] Epoch[2](54/1500); Loss: 0.105837; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1358 0.1385 0.1164 0.1088 0.1065 0.1045 0.1009 0.0996 0.0980 0.0976 0.0977 0.0973 0.0975 0.0978 0.0981 0.0984 

[TRAIN] Epoch[2](55/1500); Loss: 0.105764; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1480 0.1533 0.1326 0.1169 0.1039 0.1001 0.0973 0.0949 0.0949 0.0944 0.0928 0.0927 0.0926 0.0924 0.0927 0.0929 

[TRAIN] Epoch[2](56/1500); Loss: 0.112127; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1412 0.1246 0.1182 0.1150 0.1126 0.1104 0.1086 0.1076 0.1071 0.1069 0.1069 0.1067 0.1067 0.1070 0.1071 0.1073 

[TRAIN] Epoch[2](57/1500); Loss: 0.084377; Backpropagation: 0.0980 sec; Batch: 0.4324 sec
0.1212 0.1347 0.1187 0.1024 0.0836 0.0768 0.0734 0.0717 0.0710 0.0707 0.0706 0.0706 0.0706 0.0712 0.0714 0.0715 

[TRAIN] Epoch[2](58/1500); Loss: 0.132197; Backpropagation: 0.0957 sec; Batch: 0.4299 sec
0.2383 0.1973 0.1647 0.1378 0.1245 0.1212 0.1189 0.1161 0.1139 0.1123 0.1123 0.1120 0.1116 0.1116 0.1114 0.1112 

[TRAIN] Epoch[2](59/1500); Loss: 0.140547; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1913 0.1834 0.1628 0.1534 0.1441 0.1387 0.1353 0.1321 0.1289 0.1272 0.1261 0.1255 0.1254 0.1249 0.1247 0.1248 

[TRAIN] Epoch[2](60/1500); Loss: 0.086144; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1175 0.1121 0.1085 0.0996 0.0879 0.0842 0.0823 0.0793 0.0781 0.0774 0.0756 0.0752 0.0750 0.0750 0.0752 0.0754 

[TRAIN] Epoch[2](61/1500); Loss: 0.073182; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1084 0.1288 0.1105 0.0957 0.0771 0.0686 0.0634 0.0601 0.0586 0.0577 0.0576 0.0568 0.0568 0.0569 0.0568 0.0571 

[TRAIN] Epoch[2](62/1500); Loss: 0.102462; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1447 0.1448 0.1267 0.1164 0.1042 0.0989 0.0948 0.0920 0.0909 0.0902 0.0899 0.0895 0.0894 0.0891 0.0888 0.0890 

[TRAIN] Epoch[2](63/1500); Loss: 0.134637; Backpropagation: 0.0942 sec; Batch: 0.4292 sec
0.1649 0.1585 0.1514 0.1442 0.1351 0.1325 0.1306 0.1288 0.1277 0.1268 0.1263 0.1256 0.1254 0.1254 0.1255 0.1255 

[TRAIN] Epoch[2](64/1500); Loss: 0.078589; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1067 0.1104 0.1054 0.0953 0.0801 0.0766 0.0738 0.0702 0.0686 0.0673 0.0668 0.0667 0.0668 0.0674 0.0675 0.0679 

[TRAIN] Epoch[2](65/1500); Loss: 0.099242; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1384 0.1379 0.1309 0.1221 0.1060 0.0997 0.0952 0.0912 0.0874 0.0849 0.0834 0.0826 0.0821 0.0819 0.0819 0.0825 

[TRAIN] Epoch[2](66/1500); Loss: 0.080704; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1984 0.1439 0.1020 0.0765 0.0682 0.0666 0.0647 0.0640 0.0636 0.0630 0.0634 0.0633 0.0630 0.0633 0.0636 0.0639 

[TRAIN] Epoch[2](67/1500); Loss: 0.146509; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2066 0.1744 0.1542 0.1457 0.1403 0.1391 0.1390 0.1392 0.1393 0.1390 0.1386 0.1382 0.1380 0.1376 0.1375 0.1374 

[TRAIN] Epoch[2](68/1500); Loss: 0.075856; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1105 0.0865 0.0806 0.0797 0.0780 0.0766 0.0749 0.0725 0.0718 0.0708 0.0695 0.0690 0.0686 0.0681 0.0682 0.0683 

[TRAIN] Epoch[2](69/1500); Loss: 0.155343; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1791 0.1736 0.1659 0.1621 0.1572 0.1540 0.1520 0.1506 0.1497 0.1492 0.1491 0.1488 0.1485 0.1485 0.1485 0.1487 

[TRAIN] Epoch[2](70/1500); Loss: 0.100845; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1503 0.1261 0.1172 0.1095 0.1036 0.0980 0.0932 0.0899 0.0878 0.0876 0.0885 0.0898 0.0911 0.0925 0.0938 0.0947 

[TRAIN] Epoch[2](71/1500); Loss: 0.122043; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1792 0.1507 0.1300 0.1192 0.1171 0.1160 0.1148 0.1143 0.1141 0.1139 0.1140 0.1138 0.1137 0.1137 0.1139 0.1142 

[TRAIN] Epoch[2](72/1500); Loss: 0.098645; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1466 0.1307 0.1049 0.0984 0.0935 0.0934 0.0910 0.0911 0.0908 0.0901 0.0903 0.0903 0.0906 0.0922 0.0923 0.0922 

[TRAIN] Epoch[2](73/1500); Loss: 0.099586; Backpropagation: 0.0935 sec; Batch: 0.4289 sec
0.1154 0.1151 0.1056 0.1020 0.0994 0.0976 0.0969 0.0962 0.0957 0.0955 0.0955 0.0955 0.0955 0.0957 0.0958 0.0960 

[TRAIN] Epoch[2](74/1500); Loss: 0.064317; Backpropagation: 0.0944 sec; Batch: 0.4284 sec
0.1004 0.0822 0.0700 0.0661 0.0639 0.0625 0.0610 0.0600 0.0594 0.0587 0.0578 0.0577 0.0574 0.0570 0.0574 0.0576 

[TRAIN] Epoch[2](75/1500); Loss: 0.065473; Backpropagation: 0.0979 sec; Batch: 0.4322 sec
0.0867 0.0753 0.0676 0.0662 0.0646 0.0631 0.0626 0.0620 0.0618 0.0622 0.0619 0.0619 0.0624 0.0627 0.0631 0.0637 

[TRAIN] Epoch[2](76/1500); Loss: 0.105930; Backpropagation: 0.0955 sec; Batch: 0.4475 sec
0.1206 0.1111 0.1038 0.1031 0.1039 0.1043 0.1041 0.1040 0.1040 0.1043 0.1044 0.1046 0.1048 0.1053 0.1060 0.1065 

[TRAIN] Epoch[2](77/1500); Loss: 0.062210; Backpropagation: 0.0940 sec; Batch: 0.4348 sec
0.0859 0.0819 0.0727 0.0682 0.0660 0.0635 0.0611 0.0593 0.0580 0.0567 0.0554 0.0546 0.0537 0.0532 0.0528 0.0522 

[TRAIN] Epoch[2](78/1500); Loss: 0.111887; Backpropagation: 0.0938 sec; Batch: 0.4299 sec
0.1820 0.1548 0.1362 0.1253 0.1139 0.1034 0.0997 0.0986 0.0978 0.0975 0.0970 0.0968 0.0971 0.0972 0.0966 0.0963 

[TRAIN] Epoch[2](79/1500); Loss: 0.115728; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1446 0.1237 0.1173 0.1152 0.1160 0.1154 0.1134 0.1123 0.1114 0.1110 0.1113 0.1113 0.1113 0.1119 0.1126 0.1129 

[TRAIN] Epoch[2](80/1500); Loss: 0.082148; Backpropagation: 0.0940 sec; Batch: 0.4297 sec
0.1200 0.0950 0.0830 0.0799 0.0794 0.0787 0.0781 0.0777 0.0777 0.0776 0.0775 0.0778 0.0778 0.0777 0.0782 0.0785 

[TRAIN] Epoch[2](81/1500); Loss: 0.133095; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.1701 0.1494 0.1371 0.1337 0.1325 0.1312 0.1294 0.1287 0.1283 0.1279 0.1274 0.1270 0.1266 0.1266 0.1267 0.1268 

[TRAIN] Epoch[2](82/1500); Loss: 0.071973; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1348 0.0888 0.0720 0.0685 0.0661 0.0658 0.0659 0.0652 0.0648 0.0654 0.0651 0.0653 0.0660 0.0656 0.0657 0.0666 

[TRAIN] Epoch[2](83/1500); Loss: 0.050555; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.0757 0.0645 0.0529 0.0501 0.0467 0.0458 0.0453 0.0448 0.0455 0.0457 0.0461 0.0475 0.0481 0.0489 0.0498 0.0514 

[TRAIN] Epoch[2](84/1500); Loss: 0.135651; Backpropagation: 0.0938 sec; Batch: 0.4275 sec
0.1688 0.1606 0.1512 0.1472 0.1413 0.1381 0.1355 0.1332 0.1309 0.1287 0.1264 0.1245 0.1230 0.1217 0.1203 0.1191 

[TRAIN] Epoch[2](85/1500); Loss: 0.064418; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1056 0.0881 0.0742 0.0665 0.0638 0.0618 0.0598 0.0583 0.0573 0.0566 0.0565 0.0562 0.0564 0.0563 0.0564 0.0567 

[TRAIN] Epoch[2](86/1500); Loss: 0.099748; Backpropagation: 0.0956 sec; Batch: 0.4292 sec
0.1561 0.1255 0.1084 0.1045 0.0999 0.0963 0.0937 0.0920 0.0904 0.0900 0.0896 0.0892 0.0898 0.0902 0.0900 0.0903 

[TRAIN] Epoch[2](87/1500); Loss: 0.062549; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1033 0.0836 0.0666 0.0617 0.0596 0.0583 0.0571 0.0565 0.0561 0.0561 0.0560 0.0563 0.0567 0.0571 0.0577 0.0581 

[TRAIN] Epoch[2](88/1500); Loss: 0.066506; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.0783 0.0784 0.0719 0.0689 0.0667 0.0657 0.0644 0.0640 0.0637 0.0631 0.0629 0.0630 0.0632 0.0632 0.0634 0.0634 

[TRAIN] Epoch[2](89/1500); Loss: 0.097654; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1262 0.1129 0.1048 0.1018 0.0997 0.0982 0.0960 0.0945 0.0931 0.0918 0.0914 0.0909 0.0904 0.0902 0.0903 0.0904 

[TRAIN] Epoch[2](90/1500); Loss: 0.139424; Backpropagation: 0.0937 sec; Batch: 0.4294 sec
0.2059 0.1784 0.1507 0.1424 0.1404 0.1373 0.1339 0.1314 0.1292 0.1274 0.1263 0.1257 0.1254 0.1254 0.1253 0.1255 

[TRAIN] Epoch[2](91/1500); Loss: 0.133211; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1733 0.1516 0.1400 0.1349 0.1319 0.1305 0.1298 0.1289 0.1277 0.1270 0.1265 0.1258 0.1256 0.1258 0.1259 0.1261 

[TRAIN] Epoch[2](92/1500); Loss: 0.063650; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1347 0.1094 0.0765 0.0620 0.0583 0.0553 0.0532 0.0522 0.0515 0.0513 0.0513 0.0519 0.0522 0.0523 0.0529 0.0534 

[TRAIN] Epoch[2](93/1500); Loss: 0.100280; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.2464 0.1980 0.1400 0.1145 0.1100 0.1024 0.0929 0.0850 0.0779 0.0717 0.0665 0.0626 0.0601 0.0591 0.0586 0.0589 

[TRAIN] Epoch[2](94/1500); Loss: 0.157599; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.2464 0.2086 0.1827 0.1691 0.1538 0.1469 0.1446 0.1437 0.1425 0.1417 0.1413 0.1406 0.1400 0.1399 0.1398 0.1400 

[TRAIN] Epoch[2](95/1500); Loss: 0.199598; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.2800 0.2481 0.2219 0.2040 0.1902 0.1906 0.1901 0.1894 0.1873 0.1864 0.1865 0.1851 0.1838 0.1845 0.1833 0.1823 

[TRAIN] Epoch[2](96/1500); Loss: 0.076581; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.1447 0.1101 0.0874 0.0823 0.0785 0.0740 0.0713 0.0689 0.0667 0.0650 0.0637 0.0630 0.0626 0.0621 0.0624 0.0628 

[TRAIN] Epoch[2](97/1500); Loss: 0.118126; Backpropagation: 0.0942 sec; Batch: 0.4296 sec
0.1553 0.1394 0.1282 0.1244 0.1209 0.1183 0.1156 0.1137 0.1118 0.1107 0.1098 0.1093 0.1085 0.1082 0.1082 0.1078 

[TRAIN] Epoch[2](98/1500); Loss: 0.113135; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2247 0.1889 0.1476 0.1121 0.1046 0.1017 0.0964 0.0940 0.0926 0.0919 0.0915 0.0920 0.0925 0.0928 0.0929 0.0939 

[TRAIN] Epoch[2](99/1500); Loss: 0.118283; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.2006 0.1650 0.1320 0.1186 0.1104 0.1087 0.1073 0.1059 0.1055 0.1054 0.1048 0.1045 0.1054 0.1059 0.1058 0.1065 

[TRAIN] Epoch[2](100/1500); Loss: 0.076891; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1140 0.0962 0.0851 0.0801 0.0744 0.0724 0.0725 0.0711 0.0699 0.0702 0.0698 0.0698 0.0703 0.0708 0.0717 0.0721 

[TRAIN] Epoch[2](101/1500); Loss: 0.127903; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1703 0.1506 0.1349 0.1316 0.1267 0.1242 0.1230 0.1217 0.1208 0.1203 0.1195 0.1194 0.1206 0.1205 0.1205 0.1218 

[TRAIN] Epoch[2](102/1500); Loss: 0.111778; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1520 0.1466 0.1353 0.1194 0.1113 0.1082 0.1064 0.1040 0.1026 0.1018 0.1012 0.1003 0.0999 0.1000 0.0997 0.0997 

[TRAIN] Epoch[2](103/1500); Loss: 0.103572; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1135 0.1084 0.1085 0.1053 0.1011 0.1008 0.1013 0.1008 0.1006 0.1010 0.1014 0.1019 0.1022 0.1028 0.1034 0.1042 

[TRAIN] Epoch[2](104/1500); Loss: 0.088457; Backpropagation: 0.0946 sec; Batch: 0.4292 sec
0.1443 0.1258 0.1038 0.0975 0.0892 0.0863 0.0824 0.0803 0.0769 0.0761 0.0753 0.0749 0.0752 0.0750 0.0753 0.0770 

[TRAIN] Epoch[2](105/1500); Loss: 0.090176; Backpropagation: 0.0938 sec; Batch: 0.4685 sec
0.1841 0.1557 0.1102 0.0848 0.0777 0.0748 0.0768 0.0759 0.0730 0.0736 0.0740 0.0732 0.0758 0.0768 0.0774 0.0790 

[TRAIN] Epoch[2](106/1500); Loss: 0.127227; Backpropagation: 0.0935 sec; Batch: 0.4268 sec
0.1500 0.1368 0.1307 0.1287 0.1232 0.1228 0.1234 0.1230 0.1228 0.1233 0.1239 0.1243 0.1249 0.1255 0.1258 0.1266 

[TRAIN] Epoch[2](107/1500); Loss: 0.069998; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.0959 0.0727 0.0726 0.0733 0.0688 0.0661 0.0670 0.0666 0.0660 0.0667 0.0662 0.0661 0.0669 0.0677 0.0684 0.0689 

[TRAIN] Epoch[2](108/1500); Loss: 0.069896; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.0984 0.0829 0.0834 0.0762 0.0667 0.0656 0.0653 0.0637 0.0622 0.0637 0.0629 0.0627 0.0649 0.0655 0.0658 0.0685 

[TRAIN] Epoch[2](109/1500); Loss: 0.142754; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2224 0.1935 0.1705 0.1602 0.1399 0.1308 0.1286 0.1280 0.1262 0.1257 0.1255 0.1265 0.1263 0.1260 0.1265 0.1276 

[TRAIN] Epoch[2](110/1500); Loss: 0.100665; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1282 0.1147 0.1070 0.1035 0.0993 0.0977 0.0955 0.0950 0.0938 0.0938 0.0940 0.0951 0.0963 0.0970 0.0989 0.1010 

[TRAIN] Epoch[2](111/1500); Loss: 0.108616; Backpropagation: 0.0948 sec; Batch: 0.4292 sec
0.1609 0.1261 0.1277 0.1203 0.1032 0.1022 0.0987 0.0981 0.0993 0.0987 0.0984 0.0995 0.0998 0.0998 0.1010 0.1042 

[TRAIN] Epoch[2](112/1500); Loss: 0.076309; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1848 0.1380 0.0914 0.0872 0.0689 0.0601 0.0589 0.0581 0.0571 0.0566 0.0569 0.0579 0.0592 0.0606 0.0624 0.0628 

[TRAIN] Epoch[2](113/1500); Loss: 0.109980; Backpropagation: 0.0932 sec; Batch: 0.4291 sec
0.1614 0.1343 0.1170 0.1142 0.1082 0.1058 0.1030 0.1025 0.1015 0.1010 0.1011 0.1013 0.1012 0.1018 0.1022 0.1028 

[TRAIN] Epoch[2](114/1500); Loss: 0.149471; Backpropagation: 0.0931 sec; Batch: 0.4285 sec
0.1691 0.1601 0.1568 0.1530 0.1488 0.1487 0.1467 0.1453 0.1453 0.1456 0.1446 0.1444 0.1457 0.1456 0.1454 0.1464 

[TRAIN] Epoch[2](115/1500); Loss: 0.114942; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1645 0.1384 0.1217 0.1215 0.1124 0.1113 0.1083 0.1069 0.1077 0.1064 0.1055 0.1063 0.1066 0.1063 0.1070 0.1084 

[TRAIN] Epoch[2](116/1500); Loss: 0.147499; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2004 0.1847 0.1657 0.1519 0.1456 0.1417 0.1400 0.1384 0.1373 0.1365 0.1364 0.1362 0.1359 0.1358 0.1364 0.1370 

[TRAIN] Epoch[2](117/1500); Loss: 0.067125; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.0939 0.0751 0.0726 0.0682 0.0655 0.0633 0.0625 0.0621 0.0624 0.0627 0.0625 0.0629 0.0633 0.0642 0.0663 0.0664 

[TRAIN] Epoch[2](118/1500); Loss: 0.103904; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1118 0.1117 0.1119 0.1053 0.1028 0.1017 0.1009 0.1008 0.1013 0.1012 0.1012 0.1016 0.1021 0.1021 0.1025 0.1036 

[TRAIN] Epoch[2](119/1500); Loss: 0.087733; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1310 0.1101 0.0999 0.0934 0.0861 0.0849 0.0815 0.0805 0.0800 0.0792 0.0790 0.0791 0.0792 0.0794 0.0802 0.0805 

[TRAIN] Epoch[2](120/1500); Loss: 0.071191; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.0843 0.0785 0.0833 0.0754 0.0684 0.0668 0.0675 0.0664 0.0656 0.0676 0.0680 0.0673 0.0691 0.0696 0.0699 0.0713 

[TRAIN] Epoch[2](121/1500); Loss: 0.091847; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1117 0.1070 0.1177 0.1013 0.0917 0.0885 0.0862 0.0853 0.0845 0.0848 0.0849 0.0845 0.0847 0.0852 0.0853 0.0863 

[TRAIN] Epoch[2](122/1500); Loss: 0.052916; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.0919 0.0688 0.0680 0.0530 0.0488 0.0480 0.0467 0.0466 0.0464 0.0463 0.0462 0.0465 0.0469 0.0469 0.0477 0.0478 

[TRAIN] Epoch[2](123/1500); Loss: 0.077952; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.0971 0.0881 0.0830 0.0811 0.0773 0.0758 0.0745 0.0744 0.0742 0.0735 0.0737 0.0746 0.0747 0.0750 0.0751 0.0752 

[TRAIN] Epoch[2](124/1500); Loss: 0.044116; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1287 0.0783 0.0451 0.0422 0.0319 0.0308 0.0297 0.0306 0.0312 0.0306 0.0323 0.0360 0.0372 0.0391 0.0407 0.0414 

[TRAIN] Epoch[2](125/1500); Loss: 0.165783; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1867 0.1759 0.1733 0.1696 0.1673 0.1683 0.1646 0.1630 0.1622 0.1619 0.1609 0.1598 0.1601 0.1600 0.1597 0.1595 

[TRAIN] Epoch[2](126/1500); Loss: 0.080428; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1955 0.1530 0.1286 0.1121 0.0820 0.0689 0.0581 0.0553 0.0550 0.0535 0.0535 0.0537 0.0525 0.0537 0.0547 0.0566 

[TRAIN] Epoch[2](127/1500); Loss: 0.095728; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1943 0.1632 0.1087 0.1028 0.0834 0.0785 0.0809 0.0788 0.0780 0.0790 0.0778 0.0789 0.0811 0.0804 0.0816 0.0843 

[TRAIN] Epoch[2](128/1500); Loss: 0.122906; Backpropagation: 0.0948 sec; Batch: 0.4652 sec
0.1425 0.1334 0.1202 0.1197 0.1217 0.1202 0.1192 0.1210 0.1199 0.1201 0.1217 0.1212 0.1207 0.1217 0.1218 0.1214 

[TRAIN] Epoch[2](129/1500); Loss: 0.120529; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1603 0.1405 0.1292 0.1229 0.1193 0.1193 0.1150 0.1143 0.1137 0.1132 0.1133 0.1129 0.1130 0.1134 0.1138 0.1145 

[TRAIN] Epoch[2](130/1500); Loss: 0.064925; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.1046 0.0824 0.0744 0.0694 0.0676 0.0642 0.0588 0.0572 0.0564 0.0558 0.0553 0.0569 0.0570 0.0578 0.0599 0.0611 

[TRAIN] Epoch[2](131/1500); Loss: 0.105220; Backpropagation: 0.0939 sec; Batch: 0.4299 sec
0.1501 0.1298 0.1248 0.1138 0.1025 0.1006 0.0984 0.0967 0.0962 0.0959 0.0955 0.0955 0.0959 0.0957 0.0951 0.0969 

[TRAIN] Epoch[2](132/1500); Loss: 0.088596; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.1333 0.1125 0.0946 0.0888 0.0920 0.0856 0.0816 0.0812 0.0821 0.0810 0.0801 0.0804 0.0804 0.0810 0.0815 0.0815 

[TRAIN] Epoch[2](133/1500); Loss: 0.129434; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1699 0.1551 0.1470 0.1389 0.1328 0.1292 0.1249 0.1221 0.1203 0.1192 0.1190 0.1182 0.1185 0.1187 0.1183 0.1187 

[TRAIN] Epoch[2](134/1500); Loss: 0.058700; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1108 0.0835 0.0681 0.0602 0.0538 0.0537 0.0512 0.0506 0.0506 0.0504 0.0500 0.0507 0.0508 0.0506 0.0517 0.0524 

[TRAIN] Epoch[2](135/1500); Loss: 0.096976; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.1319 0.1121 0.1079 0.0992 0.0974 0.0966 0.0920 0.0920 0.0907 0.0902 0.0902 0.0898 0.0899 0.0907 0.0905 0.0907 

[TRAIN] Epoch[2](136/1500); Loss: 0.061331; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1072 0.0840 0.0688 0.0636 0.0581 0.0577 0.0544 0.0534 0.0528 0.0543 0.0535 0.0535 0.0548 0.0546 0.0550 0.0558 

[TRAIN] Epoch[2](137/1500); Loss: 0.114779; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1530 0.1395 0.1309 0.1256 0.1165 0.1130 0.1098 0.1087 0.1074 0.1058 0.1056 0.1044 0.1040 0.1043 0.1047 0.1033 

[TRAIN] Epoch[2](138/1500); Loss: 0.096942; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.2043 0.1515 0.1148 0.0962 0.0943 0.0962 0.0819 0.0793 0.0789 0.0786 0.0782 0.0784 0.0789 0.0794 0.0800 0.0803 

[TRAIN] Epoch[2](139/1500); Loss: 0.047098; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1025 0.0470 0.0623 0.0497 0.0369 0.0350 0.0432 0.0406 0.0372 0.0370 0.0439 0.0437 0.0412 0.0433 0.0451 0.0450 

[TRAIN] Epoch[2](140/1500); Loss: 0.128713; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1667 0.1428 0.1379 0.1320 0.1275 0.1267 0.1246 0.1237 0.1232 0.1224 0.1222 0.1218 0.1218 0.1220 0.1220 0.1220 

[TRAIN] Epoch[2](141/1500); Loss: 0.091882; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1850 0.1265 0.1031 0.0892 0.0863 0.0837 0.0802 0.0791 0.0783 0.0800 0.0799 0.0784 0.0788 0.0797 0.0810 0.0809 

[TRAIN] Epoch[2](142/1500); Loss: 0.123566; Backpropagation: 0.0930 sec; Batch: 0.4273 sec
0.1681 0.1437 0.1259 0.1245 0.1261 0.1214 0.1164 0.1155 0.1172 0.1165 0.1158 0.1160 0.1169 0.1175 0.1177 0.1180 

[TRAIN] Epoch[2](143/1500); Loss: 0.085534; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1415 0.1065 0.0869 0.0802 0.0886 0.0822 0.0775 0.0767 0.0793 0.0779 0.0779 0.0776 0.0785 0.0784 0.0789 0.0798 

[TRAIN] Epoch[2](144/1500); Loss: 0.076047; Backpropagation: 0.0931 sec; Batch: 0.4282 sec
0.2531 0.1570 0.0930 0.0598 0.0701 0.0629 0.0527 0.0499 0.0505 0.0497 0.0497 0.0524 0.0537 0.0533 0.0533 0.0557 

[TRAIN] Epoch[2](145/1500); Loss: 0.091395; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1416 0.1147 0.1096 0.0961 0.0920 0.0880 0.0830 0.0810 0.0826 0.0816 0.0816 0.0815 0.0812 0.0818 0.0828 0.0834 

[TRAIN] Epoch[2](146/1500); Loss: 0.057728; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1095 0.0786 0.0573 0.0538 0.0531 0.0527 0.0514 0.0498 0.0487 0.0495 0.0500 0.0508 0.0521 0.0536 0.0550 0.0578 

[TRAIN] Epoch[2](147/1500); Loss: 0.079427; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1484 0.1153 0.1017 0.0959 0.0774 0.0722 0.0675 0.0657 0.0652 0.0650 0.0645 0.0653 0.0654 0.0663 0.0670 0.0681 

[TRAIN] Epoch[2](148/1500); Loss: 0.092793; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1241 0.1019 0.0984 0.0934 0.0903 0.0894 0.0882 0.0879 0.0879 0.0884 0.0879 0.0883 0.0886 0.0889 0.0900 0.0911 

[TRAIN] Epoch[2](149/1500); Loss: 0.131122; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1652 0.1501 0.1439 0.1417 0.1344 0.1313 0.1279 0.1257 0.1238 0.1228 0.1221 0.1220 0.1218 0.1218 0.1218 0.1217 

[TRAIN] Epoch[2](150/1500); Loss: 0.176209; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.2226 0.2045 0.1989 0.1966 0.1848 0.1801 0.1750 0.1720 0.1683 0.1660 0.1632 0.1608 0.1583 0.1568 0.1559 0.1554 

[TRAIN] Epoch[2](151/1500); Loss: 0.100472; Backpropagation: 0.0956 sec; Batch: 0.4301 sec
0.1658 0.1404 0.1189 0.1191 0.1019 0.0966 0.0909 0.0882 0.0866 0.0857 0.0852 0.0850 0.0852 0.0852 0.0860 0.0869 

[TRAIN] Epoch[2](152/1500); Loss: 0.066214; Backpropagation: 0.0956 sec; Batch: 0.4297 sec
0.0916 0.0870 0.0692 0.0620 0.0562 0.0578 0.0582 0.0577 0.0584 0.0595 0.0615 0.0633 0.0652 0.0676 0.0708 0.0736 

[TRAIN] Epoch[2](153/1500); Loss: 0.063742; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.0776 0.0749 0.0667 0.0646 0.0619 0.0604 0.0595 0.0592 0.0595 0.0599 0.0603 0.0609 0.0619 0.0630 0.0641 0.0653 

[TRAIN] Epoch[2](154/1500); Loss: 0.164720; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1964 0.1810 0.1759 0.1740 0.1666 0.1636 0.1594 0.1574 0.1555 0.1550 0.1552 0.1561 0.1576 0.1593 0.1610 0.1616 

[TRAIN] Epoch[2](155/1500); Loss: 0.160181; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1861 0.1741 0.1639 0.1638 0.1603 0.1591 0.1575 0.1567 0.1560 0.1555 0.1552 0.1550 0.1548 0.1550 0.1549 0.1550 

[TRAIN] Epoch[2](156/1500); Loss: 0.197965; Backpropagation: 0.0938 sec; Batch: 0.4328 sec
0.2600 0.2347 0.2314 0.2293 0.2165 0.2121 0.2030 0.1975 0.1902 0.1847 0.1788 0.1739 0.1692 0.1653 0.1618 0.1592 

[TRAIN] Epoch[2](157/1500); Loss: 0.170362; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2060 0.1904 0.1865 0.1855 0.1785 0.1759 0.1717 0.1691 0.1659 0.1632 0.1604 0.1581 0.1560 0.1543 0.1528 0.1516 

[TRAIN] Epoch[2](158/1500); Loss: 0.095227; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.1198 0.1071 0.1003 0.1003 0.0969 0.0953 0.0939 0.0927 0.0915 0.0906 0.0898 0.0895 0.0891 0.0889 0.0889 0.0890 

[TRAIN] Epoch[2](159/1500); Loss: 0.114819; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1454 0.1312 0.1237 0.1219 0.1166 0.1137 0.1110 0.1092 0.1080 0.1073 0.1073 0.1076 0.1079 0.1085 0.1088 0.1089 

[TRAIN] Epoch[2](160/1500); Loss: 0.166272; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1896 0.1782 0.1758 0.1750 0.1707 0.1689 0.1662 0.1645 0.1627 0.1614 0.1600 0.1589 0.1579 0.1572 0.1568 0.1564 

[TRAIN] Epoch[2](161/1500); Loss: 0.119638; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1427 0.1314 0.1234 0.1227 0.1202 0.1194 0.1182 0.1175 0.1169 0.1162 0.1154 0.1148 0.1145 0.1140 0.1137 0.1133 

[TRAIN] Epoch[2](162/1500); Loss: 0.169601; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2209 0.1984 0.1832 0.1843 0.1760 0.1730 0.1679 0.1647 0.1616 0.1592 0.1571 0.1557 0.1543 0.1533 0.1525 0.1516 

[TRAIN] Epoch[2](163/1500); Loss: 0.113191; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1442 0.1277 0.1220 0.1201 0.1150 0.1133 0.1109 0.1097 0.1082 0.1071 0.1060 0.1055 0.1054 0.1053 0.1053 0.1053 

[TRAIN] Epoch[2](164/1500); Loss: 0.132527; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1379 0.1319 0.1306 0.1305 0.1317 0.1320 0.1328 0.1327 0.1326 0.1322 0.1320 0.1319 0.1321 0.1325 0.1331 0.1339 

[TRAIN] Epoch[2](165/1500); Loss: 0.180370; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2175 0.2011 0.1963 0.1936 0.1867 0.1842 0.1798 0.1773 0.1739 0.1717 0.1696 0.1683 0.1673 0.1666 0.1662 0.1658 

[TRAIN] Epoch[2](166/1500); Loss: 0.099718; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1297 0.1105 0.1060 0.1044 0.0991 0.0976 0.0958 0.0951 0.0943 0.0937 0.0937 0.0942 0.0947 0.0951 0.0955 0.0960 

[TRAIN] Epoch[2](167/1500); Loss: 0.103255; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1144 0.1074 0.1032 0.1027 0.1027 0.1027 0.1027 0.1026 0.1025 0.1023 0.1020 0.1016 0.1014 0.1011 0.1012 0.1016 

[TRAIN] Epoch[2](168/1500); Loss: 0.194098; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2928 0.2542 0.2462 0.2442 0.2243 0.2179 0.2031 0.1951 0.1834 0.1743 0.1643 0.1557 0.1473 0.1401 0.1338 0.1288 

[TRAIN] Epoch[2](169/1500); Loss: 0.112821; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.1554 0.1311 0.1256 0.1247 0.1187 0.1163 0.1122 0.1094 0.1065 0.1045 0.1026 0.1013 0.1001 0.0993 0.0988 0.0986 

[TRAIN] Epoch[2](170/1500); Loss: 0.121156; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1494 0.1370 0.1240 0.1251 0.1211 0.1197 0.1182 0.1174 0.1167 0.1161 0.1155 0.1152 0.1151 0.1155 0.1160 0.1165 

[TRAIN] Epoch[2](171/1500); Loss: 0.155606; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.2059 0.1798 0.1739 0.1713 0.1619 0.1584 0.1535 0.1514 0.1487 0.1463 0.1434 0.1412 0.1395 0.1386 0.1380 0.1378 

[TRAIN] Epoch[2](172/1500); Loss: 0.102760; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1564 0.1285 0.1158 0.1116 0.1038 0.1006 0.0972 0.0952 0.0936 0.0928 0.0923 0.0920 0.0916 0.0913 0.0909 0.0906 

[TRAIN] Epoch[2](173/1500); Loss: 0.073961; Backpropagation: 0.0931 sec; Batch: 0.4277 sec
0.0794 0.0755 0.0750 0.0738 0.0724 0.0717 0.0716 0.0717 0.0718 0.0724 0.0727 0.0734 0.0742 0.0753 0.0759 0.0766 

[TRAIN] Epoch[2](174/1500); Loss: 0.096650; Backpropagation: 0.0957 sec; Batch: 0.4300 sec
0.1252 0.1095 0.1002 0.0997 0.0953 0.0944 0.0935 0.0927 0.0920 0.0916 0.0916 0.0917 0.0918 0.0920 0.0924 0.0928 

[TRAIN] Epoch[2](175/1500); Loss: 0.092236; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1523 0.1275 0.1048 0.1023 0.0923 0.0890 0.0854 0.0836 0.0818 0.0807 0.0799 0.0795 0.0794 0.0792 0.0790 0.0790 

[TRAIN] Epoch[2](176/1500); Loss: 0.089499; Backpropagation: 0.0939 sec; Batch: 0.4298 sec
0.1377 0.1197 0.1061 0.1057 0.0961 0.0923 0.0863 0.0827 0.0794 0.0773 0.0759 0.0748 0.0742 0.0741 0.0745 0.0751 

[TRAIN] Epoch[2](177/1500); Loss: 0.207090; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.2530 0.2347 0.2251 0.2209 0.2105 0.2061 0.2015 0.1993 0.1983 0.1975 0.1966 0.1956 0.1950 0.1942 0.1931 0.1921 

[TRAIN] Epoch[2](178/1500); Loss: 0.089846; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1438 0.1157 0.0951 0.0883 0.0846 0.0828 0.0821 0.0816 0.0816 0.0817 0.0818 0.0822 0.0828 0.0835 0.0845 0.0855 

[TRAIN] Epoch[2](179/1500); Loss: 0.122526; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1712 0.1556 0.1437 0.1397 0.1327 0.1309 0.1262 0.1236 0.1172 0.1114 0.1071 0.1042 0.1020 0.1001 0.0982 0.0967 

[TRAIN] Epoch[2](180/1500); Loss: 0.070466; Backpropagation: 0.0935 sec; Batch: 0.4289 sec
0.1250 0.0848 0.0710 0.0694 0.0682 0.0695 0.0663 0.0638 0.0632 0.0631 0.0630 0.0630 0.0634 0.0640 0.0645 0.0651 

[TRAIN] Epoch[2](181/1500); Loss: 0.092808; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1396 0.1084 0.1029 0.1010 0.0945 0.0904 0.0883 0.0870 0.0858 0.0850 0.0842 0.0836 0.0833 0.0834 0.0837 0.0840 

[TRAIN] Epoch[2](182/1500); Loss: 0.122910; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1995 0.1686 0.1448 0.1418 0.1278 0.1217 0.1150 0.1102 0.1070 0.1053 0.1044 0.1042 0.1041 0.1040 0.1041 0.1041 

[TRAIN] Epoch[2](183/1500); Loss: 0.043782; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0807 0.0666 0.0496 0.0475 0.0396 0.0400 0.0385 0.0376 0.0368 0.0364 0.0366 0.0371 0.0373 0.0380 0.0389 0.0393 

[TRAIN] Epoch[2](184/1500); Loss: 0.087191; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1009 0.0950 0.0893 0.0885 0.0843 0.0833 0.0822 0.0820 0.0830 0.0836 0.0843 0.0851 0.0864 0.0879 0.0890 0.0902 

[TRAIN] Epoch[2](185/1500); Loss: 0.106013; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1859 0.1527 0.1358 0.1322 0.1178 0.1093 0.1019 0.0947 0.0890 0.0849 0.0823 0.0813 0.0813 0.0818 0.0823 0.0829 

[TRAIN] Epoch[2](186/1500); Loss: 0.088333; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1331 0.1063 0.0977 0.0964 0.0895 0.0869 0.0848 0.0832 0.0820 0.0811 0.0802 0.0794 0.0787 0.0782 0.0779 0.0780 

[TRAIN] Epoch[2](187/1500); Loss: 0.063756; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.1188 0.0876 0.0690 0.0680 0.0633 0.0597 0.0575 0.0560 0.0552 0.0548 0.0547 0.0547 0.0549 0.0549 0.0552 0.0558 

[TRAIN] Epoch[2](188/1500); Loss: 0.104151; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1666 0.1346 0.1170 0.1153 0.1073 0.1035 0.0993 0.0953 0.0929 0.0915 0.0912 0.0910 0.0906 0.0902 0.0900 0.0900 

[TRAIN] Epoch[2](189/1500); Loss: 0.046703; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1054 0.0380 0.0716 0.0749 0.0691 0.0416 0.0320 0.0324 0.0334 0.0325 0.0331 0.0341 0.0355 0.0361 0.0377 0.0399 

[TRAIN] Epoch[2](190/1500); Loss: 0.134133; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1617 0.1420 0.1366 0.1343 0.1304 0.1295 0.1291 0.1286 0.1285 0.1288 0.1297 0.1309 0.1321 0.1333 0.1346 0.1360 

[TRAIN] Epoch[2](191/1500); Loss: 0.076079; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1405 0.1089 0.0789 0.0747 0.0695 0.0673 0.0662 0.0659 0.0659 0.0661 0.0666 0.0672 0.0680 0.0691 0.0705 0.0720 

[TRAIN] Epoch[2](192/1500); Loss: 0.087452; Backpropagation: 0.0939 sec; Batch: 0.4293 sec
0.1395 0.1140 0.0998 0.0979 0.0861 0.0822 0.0793 0.0780 0.0778 0.0776 0.0777 0.0776 0.0775 0.0778 0.0781 0.0783 

[TRAIN] Epoch[2](193/1500); Loss: 0.095566; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1400 0.1216 0.1069 0.1023 0.0944 0.0923 0.0908 0.0899 0.0889 0.0880 0.0869 0.0862 0.0857 0.0853 0.0852 0.0847 

[TRAIN] Epoch[2](194/1500); Loss: 0.134779; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.2082 0.1737 0.1590 0.1567 0.1462 0.1386 0.1322 0.1230 0.1179 0.1141 0.1140 0.1144 0.1143 0.1146 0.1147 0.1148 

[TRAIN] Epoch[2](195/1500); Loss: 0.133885; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2101 0.1786 0.1610 0.1583 0.1436 0.1343 0.1272 0.1200 0.1165 0.1144 0.1139 0.1137 0.1131 0.1126 0.1124 0.1125 

[TRAIN] Epoch[2](196/1500); Loss: 0.067024; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1403 0.1178 0.0840 0.0827 0.0614 0.0579 0.0545 0.0543 0.0531 0.0521 0.0516 0.0517 0.0521 0.0525 0.0529 0.0535 

[TRAIN] Epoch[2](197/1500); Loss: 0.081529; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1236 0.0892 0.0855 0.0825 0.0786 0.0784 0.0779 0.0772 0.0768 0.0765 0.0764 0.0764 0.0764 0.0763 0.0763 0.0763 

[TRAIN] Epoch[2](198/1500); Loss: 0.131016; Backpropagation: 0.0938 sec; Batch: 0.4434 sec
0.1804 0.1586 0.1487 0.1464 0.1384 0.1329 0.1281 0.1223 0.1194 0.1175 0.1172 0.1171 0.1172 0.1173 0.1174 0.1174 

[TRAIN] Epoch[2](199/1500); Loss: 0.092808; Backpropagation: 0.0937 sec; Batch: 0.4332 sec
0.1652 0.1310 0.1096 0.1039 0.0951 0.0900 0.0845 0.0798 0.0785 0.0787 0.0787 0.0784 0.0781 0.0778 0.0778 0.0777 

[TRAIN] Epoch[2](200/1500); Loss: 0.109531; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1670 0.1336 0.1253 0.1207 0.1095 0.1035 0.0999 0.0993 0.0998 0.0994 0.0989 0.0987 0.0990 0.0993 0.0993 0.0994 

[TRAIN] Epoch[2](201/1500); Loss: 0.067696; Backpropagation: 0.0943 sec; Batch: 0.4286 sec
0.1310 0.0908 0.0696 0.0692 0.0663 0.0608 0.0597 0.0592 0.0593 0.0593 0.0595 0.0593 0.0595 0.0598 0.0599 0.0601 

[TRAIN] Epoch[2](202/1500); Loss: 0.082965; Backpropagation: 0.0931 sec; Batch: 0.4684 sec
0.1286 0.0971 0.0877 0.0867 0.0844 0.0798 0.0786 0.0774 0.0767 0.0762 0.0760 0.0757 0.0757 0.0755 0.0755 0.0758 

[TRAIN] Epoch[2](203/1500); Loss: 0.093714; Backpropagation: 0.0973 sec; Batch: 0.4329 sec
0.1169 0.1029 0.0972 0.0961 0.0927 0.0913 0.0904 0.0902 0.0902 0.0900 0.0899 0.0899 0.0901 0.0903 0.0905 0.0907 

[TRAIN] Epoch[2](204/1500); Loss: 0.112852; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1508 0.1315 0.1214 0.1166 0.1118 0.1096 0.1076 0.1059 0.1051 0.1047 0.1048 0.1052 0.1059 0.1070 0.1083 0.1095 

[TRAIN] Epoch[2](205/1500); Loss: 0.089720; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1136 0.1058 0.0981 0.0943 0.0907 0.0889 0.0869 0.0855 0.0847 0.0842 0.0839 0.0837 0.0835 0.0836 0.0839 0.0843 

[TRAIN] Epoch[2](206/1500); Loss: 0.092835; Backpropagation: 0.0931 sec; Batch: 0.4276 sec
0.1705 0.1373 0.0985 0.0848 0.0836 0.0831 0.0822 0.0817 0.0818 0.0821 0.0823 0.0825 0.0829 0.0834 0.0840 0.0847 

[TRAIN] Epoch[2](207/1500); Loss: 0.097226; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1488 0.1200 0.1044 0.1006 0.0950 0.0927 0.0912 0.0902 0.0894 0.0890 0.0887 0.0885 0.0886 0.0889 0.0893 0.0902 

[TRAIN] Epoch[2](208/1500); Loss: 0.067054; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1412 0.1103 0.0755 0.0630 0.0600 0.0588 0.0572 0.0563 0.0559 0.0558 0.0558 0.0559 0.0562 0.0566 0.0569 0.0574 

[TRAIN] Epoch[2](209/1500); Loss: 0.051294; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.0987 0.0702 0.0644 0.0565 0.0517 0.0503 0.0471 0.0447 0.0432 0.0425 0.0420 0.0417 0.0416 0.0418 0.0420 0.0422 

[TRAIN] Epoch[2](210/1500); Loss: 0.059942; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.0694 0.0633 0.0641 0.0619 0.0577 0.0576 0.0573 0.0575 0.0574 0.0576 0.0580 0.0584 0.0588 0.0594 0.0599 0.0609 

[TRAIN] Epoch[2](211/1500); Loss: 0.043944; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1618 0.1061 0.0329 0.0317 0.0309 0.0314 0.0312 0.0290 0.0299 0.0310 0.0306 0.0298 0.0309 0.0316 0.0318 0.0326 

[TRAIN] Epoch[2](212/1500); Loss: 0.084204; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1413 0.1115 0.0874 0.0849 0.0785 0.0812 0.0792 0.0769 0.0760 0.0757 0.0755 0.0755 0.0757 0.0758 0.0759 0.0762 

[TRAIN] Epoch[2](213/1500); Loss: 0.222160; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.2557 0.2420 0.2322 0.2275 0.2231 0.2229 0.2213 0.2195 0.2180 0.2165 0.2152 0.2140 0.2131 0.2122 0.2112 0.2101 

[TRAIN] Epoch[2](214/1500); Loss: 0.144139; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1755 0.1594 0.1486 0.1429 0.1417 0.1413 0.1408 0.1401 0.1395 0.1393 0.1393 0.1393 0.1394 0.1396 0.1397 0.1399 

[TRAIN] Epoch[2](215/1500); Loss: 0.124147; Backpropagation: 0.0981 sec; Batch: 0.4338 sec
0.1488 0.1339 0.1240 0.1229 0.1224 0.1233 0.1231 0.1221 0.1213 0.1207 0.1203 0.1202 0.1203 0.1206 0.1210 0.1214 

[TRAIN] Epoch[2](216/1500); Loss: 0.122446; Backpropagation: 0.0957 sec; Batch: 0.4309 sec
0.1335 0.1272 0.1273 0.1237 0.1219 0.1219 0.1215 0.1208 0.1202 0.1200 0.1198 0.1198 0.1199 0.1201 0.1205 0.1210 

[TRAIN] Epoch[2](217/1500); Loss: 0.114370; Backpropagation: 0.0941 sec; Batch: 0.4277 sec
0.1573 0.1232 0.0934 0.0952 0.0972 0.1014 0.1060 0.1091 0.1111 0.1130 0.1149 0.1170 0.1192 0.1215 0.1239 0.1264 

[TRAIN] Epoch[2](218/1500); Loss: 0.153457; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1762 0.1577 0.1474 0.1436 0.1475 0.1516 0.1531 0.1531 0.1530 0.1529 0.1529 0.1529 0.1530 0.1532 0.1534 0.1538 

[TRAIN] Epoch[2](219/1500); Loss: 0.209808; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.3690 0.2958 0.2548 0.2474 0.2071 0.1838 0.1665 0.1586 0.1633 0.1739 0.1798 0.1851 0.1885 0.1917 0.1945 0.1973 

[TRAIN] Epoch[2](220/1500); Loss: 0.171324; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1897 0.1648 0.1449 0.1467 0.1512 0.1565 0.1623 0.1664 0.1698 0.1732 0.1768 0.1803 0.1839 0.1876 0.1915 0.1954 

[TRAIN] Epoch[2](221/1500); Loss: 0.112981; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1512 0.1265 0.1080 0.1049 0.1024 0.1028 0.1054 0.1076 0.1088 0.1098 0.1107 0.1117 0.1127 0.1138 0.1150 0.1163 

[TRAIN] Epoch[2](222/1500); Loss: 0.119038; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1417 0.1269 0.1194 0.1176 0.1143 0.1145 0.1153 0.1158 0.1160 0.1163 0.1166 0.1170 0.1175 0.1180 0.1186 0.1192 

[TRAIN] Epoch[2](223/1500); Loss: 0.160027; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1686 0.1598 0.1586 0.1556 0.1544 0.1555 0.1564 0.1574 0.1583 0.1594 0.1603 0.1612 0.1622 0.1632 0.1643 0.1654 

[TRAIN] Epoch[2](224/1500); Loss: 0.094467; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1523 0.1208 0.0897 0.0840 0.0829 0.0834 0.0846 0.0860 0.0870 0.0880 0.0890 0.0901 0.0913 0.0926 0.0940 0.0955 

[TRAIN] Epoch[2](225/1500); Loss: 0.073012; Backpropagation: 0.0931 sec; Batch: 0.4277 sec
0.0955 0.0808 0.0729 0.0703 0.0680 0.0674 0.0673 0.0677 0.0684 0.0694 0.0704 0.0715 0.0725 0.0738 0.0753 0.0769 

[TRAIN] Epoch[2](226/1500); Loss: 0.139883; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1759 0.1583 0.1494 0.1466 0.1397 0.1369 0.1350 0.1335 0.1321 0.1319 0.1321 0.1324 0.1328 0.1333 0.1338 0.1344 

[TRAIN] Epoch[2](227/1500); Loss: 0.098402; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1277 0.1158 0.1066 0.1001 0.0946 0.0928 0.0925 0.0922 0.0921 0.0923 0.0926 0.0931 0.0939 0.0948 0.0960 0.0973 

[TRAIN] Epoch[2](228/1500); Loss: 0.067596; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.0706 0.0607 0.0666 0.0677 0.0632 0.0622 0.0627 0.0635 0.0647 0.0661 0.0678 0.0697 0.0714 0.0731 0.0747 0.0766 

[TRAIN] Epoch[2](229/1500); Loss: 0.115744; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2264 0.1747 0.1430 0.1373 0.1141 0.1008 0.0947 0.0942 0.0952 0.0954 0.0952 0.0953 0.0956 0.0960 0.0966 0.0973 

[TRAIN] Epoch[2](230/1500); Loss: 0.066844; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.0840 0.0722 0.0752 0.0741 0.0666 0.0640 0.0628 0.0626 0.0624 0.0626 0.0629 0.0633 0.0635 0.0637 0.0645 0.0652 

[TRAIN] Epoch[2](231/1500); Loss: 0.117095; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1961 0.1453 0.1265 0.1243 0.1124 0.1085 0.1072 0.1068 0.1059 0.1056 0.1055 0.1055 0.1056 0.1058 0.1061 0.1065 

[TRAIN] Epoch[2](232/1500); Loss: 0.094057; Backpropagation: 0.0937 sec; Batch: 0.4297 sec
0.1399 0.1159 0.0992 0.0989 0.0929 0.0901 0.0885 0.0875 0.0867 0.0864 0.0862 0.0862 0.0862 0.0864 0.0867 0.0871 

[TRAIN] Epoch[2](233/1500); Loss: 0.098716; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1281 0.1128 0.1054 0.1000 0.0964 0.0946 0.0939 0.0937 0.0936 0.0936 0.0938 0.0940 0.0942 0.0946 0.0952 0.0957 

[TRAIN] Epoch[2](234/1500); Loss: 0.091983; Backpropagation: 0.0931 sec; Batch: 0.4281 sec
0.2004 0.1470 0.1242 0.1176 0.0936 0.0815 0.0741 0.0719 0.0718 0.0715 0.0707 0.0699 0.0695 0.0693 0.0693 0.0693 

[TRAIN] Epoch[2](235/1500); Loss: 0.063693; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1051 0.0815 0.0749 0.0701 0.0625 0.0599 0.0586 0.0572 0.0562 0.0558 0.0556 0.0556 0.0558 0.0562 0.0567 0.0573 

[TRAIN] Epoch[2](236/1500); Loss: 0.097867; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1601 0.1258 0.1096 0.1058 0.0961 0.0925 0.0908 0.0896 0.0881 0.0874 0.0869 0.0866 0.0865 0.0865 0.0867 0.0869 

[TRAIN] Epoch[2](237/1500); Loss: 0.148225; Backpropagation: 0.0935 sec; Batch: 0.4295 sec
0.1853 0.1588 0.1500 0.1460 0.1437 0.1431 0.1437 0.1437 0.1439 0.1440 0.1442 0.1444 0.1446 0.1449 0.1454 0.1459 

[TRAIN] Epoch[2](238/1500); Loss: 0.115083; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1979 0.1541 0.1342 0.1278 0.1157 0.1102 0.1072 0.1044 0.1012 0.0989 0.0978 0.0975 0.0977 0.0983 0.0989 0.0996 

[TRAIN] Epoch[2](239/1500); Loss: 0.131036; Backpropagation: 0.0937 sec; Batch: 0.4387 sec
0.1782 0.1536 0.1378 0.1346 0.1280 0.1262 0.1256 0.1252 0.1246 0.1242 0.1237 0.1234 0.1231 0.1229 0.1228 0.1226 

[TRAIN] Epoch[2](240/1500); Loss: 0.117741; Backpropagation: 0.0932 sec; Batch: 0.4285 sec
0.2036 0.1760 0.1496 0.1426 0.1271 0.1148 0.1081 0.1037 0.0975 0.0945 0.0938 0.0939 0.0946 0.0946 0.0946 0.0947 

[TRAIN] Epoch[2](241/1500); Loss: 0.092452; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1325 0.1132 0.1005 0.0957 0.0898 0.0881 0.0872 0.0865 0.0861 0.0858 0.0855 0.0855 0.0855 0.0856 0.0858 0.0861 

[TRAIN] Epoch[2](242/1500); Loss: 0.133389; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1825 0.1625 0.1465 0.1369 0.1302 0.1276 0.1265 0.1254 0.1249 0.1245 0.1244 0.1243 0.1242 0.1243 0.1246 0.1249 

[TRAIN] Epoch[2](243/1500); Loss: 0.086383; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.0944 0.0923 0.0908 0.0942 0.0882 0.0855 0.0843 0.0836 0.0831 0.0828 0.0827 0.0828 0.0833 0.0841 0.0847 0.0853 

[TRAIN] Epoch[2](244/1500); Loss: 0.119858; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2540 0.2014 0.1731 0.1672 0.1346 0.1178 0.1096 0.1019 0.0883 0.0824 0.0813 0.0815 0.0813 0.0810 0.0810 0.0812 

[TRAIN] Epoch[2](245/1500); Loss: 0.117913; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1739 0.1464 0.1246 0.1219 0.1165 0.1140 0.1126 0.1111 0.1099 0.1089 0.1083 0.1080 0.1076 0.1076 0.1077 0.1077 

[TRAIN] Epoch[2](246/1500); Loss: 0.051634; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.1066 0.0791 0.0688 0.0583 0.0481 0.0463 0.0448 0.0434 0.0423 0.0418 0.0413 0.0410 0.0408 0.0409 0.0412 0.0414 

[TRAIN] Epoch[2](247/1500); Loss: 0.060579; Backpropagation: 0.0935 sec; Batch: 0.4290 sec
0.0835 0.0798 0.0758 0.0650 0.0601 0.0576 0.0565 0.0555 0.0550 0.0546 0.0544 0.0542 0.0542 0.0543 0.0543 0.0545 

[TRAIN] Epoch[2](248/1500); Loss: 0.111539; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1910 0.1573 0.1362 0.1263 0.1133 0.1074 0.1040 0.1006 0.0967 0.0944 0.0931 0.0926 0.0927 0.0929 0.0930 0.0932 

[TRAIN] Epoch[2](249/1500); Loss: 0.104374; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1725 0.1408 0.1160 0.1114 0.1000 0.0961 0.0954 0.0945 0.0936 0.0932 0.0929 0.0928 0.0926 0.0925 0.0926 0.0929 

[TRAIN] Epoch[2](250/1500); Loss: 0.127322; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1954 0.1738 0.1559 0.1463 0.1285 0.1221 0.1186 0.1158 0.1110 0.1106 0.1103 0.1100 0.1098 0.1097 0.1096 0.1098 

[TRAIN] Epoch[2](251/1500); Loss: 0.065091; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.0858 0.0801 0.0718 0.0655 0.0628 0.0620 0.0613 0.0611 0.0613 0.0612 0.0611 0.0611 0.0613 0.0615 0.0616 0.0619 

[TRAIN] Epoch[2](252/1500); Loss: 0.119975; Backpropagation: 0.0931 sec; Batch: 0.4274 sec
0.1760 0.1533 0.1290 0.1218 0.1189 0.1167 0.1154 0.1145 0.1131 0.1119 0.1107 0.1098 0.1086 0.1076 0.1066 0.1057 

[TRAIN] Epoch[2](253/1500); Loss: 0.151093; Backpropagation: 0.0934 sec; Batch: 0.4297 sec
0.2095 0.1767 0.1646 0.1521 0.1446 0.1454 0.1444 0.1434 0.1429 0.1424 0.1421 0.1419 0.1418 0.1418 0.1419 0.1419 

[TRAIN] Epoch[2](254/1500); Loss: 0.098294; Backpropagation: 0.0962 sec; Batch: 0.4341 sec
0.1151 0.1099 0.1075 0.0990 0.0968 0.0960 0.0956 0.0952 0.0950 0.0949 0.0947 0.0944 0.0945 0.0946 0.0946 0.0949 

[TRAIN] Epoch[2](255/1500); Loss: 0.095933; Backpropagation: 0.0964 sec; Batch: 0.4330 sec
0.1078 0.1094 0.1055 0.0973 0.0940 0.0936 0.0933 0.0928 0.0925 0.0923 0.0923 0.0924 0.0925 0.0928 0.0931 0.0933 

[TRAIN] Epoch[2](256/1500); Loss: 0.059276; Backpropagation: 0.0964 sec; Batch: 0.4324 sec
0.0924 0.0841 0.0708 0.0635 0.0586 0.0567 0.0549 0.0537 0.0531 0.0525 0.0521 0.0517 0.0513 0.0512 0.0510 0.0507 

[TRAIN] Epoch[2](257/1500); Loss: 0.055342; Backpropagation: 0.0948 sec; Batch: 0.4308 sec
0.0820 0.0685 0.0594 0.0534 0.0527 0.0524 0.0517 0.0512 0.0510 0.0515 0.0517 0.0517 0.0518 0.0520 0.0521 0.0525 

[TRAIN] Epoch[2](258/1500); Loss: 0.063684; Backpropagation: 0.0938 sec; Batch: 0.4301 sec
0.0932 0.0805 0.0701 0.0655 0.0615 0.0604 0.0598 0.0593 0.0589 0.0585 0.0584 0.0584 0.0586 0.0586 0.0586 0.0588 

[TRAIN] Epoch[2](259/1500); Loss: 0.097928; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1440 0.1270 0.1164 0.1038 0.0979 0.0955 0.0921 0.0900 0.0886 0.0875 0.0869 0.0866 0.0866 0.0871 0.0878 0.0891 

[TRAIN] Epoch[2](260/1500); Loss: 0.127031; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1686 0.1440 0.1348 0.1302 0.1239 0.1227 0.1218 0.1212 0.1208 0.1205 0.1202 0.1202 0.1204 0.1208 0.1211 0.1215 

[TRAIN] Epoch[2](261/1500); Loss: 0.081778; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.0944 0.0942 0.0876 0.0846 0.0820 0.0812 0.0802 0.0792 0.0784 0.0778 0.0778 0.0780 0.0780 0.0781 0.0782 0.0787 

[TRAIN] Epoch[2](262/1500); Loss: 0.114764; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1597 0.1201 0.1242 0.1146 0.1117 0.1103 0.1098 0.1096 0.1094 0.1092 0.1091 0.1093 0.1096 0.1097 0.1098 0.1102 

[TRAIN] Epoch[2](263/1500); Loss: 0.092997; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2595 0.1736 0.1275 0.1109 0.0782 0.0810 0.0756 0.0700 0.0667 0.0651 0.0642 0.0638 0.0633 0.0630 0.0628 0.0628 

[TRAIN] Epoch[2](264/1500); Loss: 0.130033; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.2614 0.1975 0.1602 0.1498 0.1202 0.1165 0.1134 0.1108 0.1090 0.1076 0.1068 0.1060 0.1055 0.1054 0.1053 0.1052 

[TRAIN] Epoch[2](265/1500); Loss: 0.055262; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.0793 0.0747 0.0608 0.0572 0.0545 0.0530 0.0517 0.0509 0.0506 0.0502 0.0502 0.0500 0.0502 0.0501 0.0503 0.0506 

[TRAIN] Epoch[2](266/1500); Loss: 0.046714; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.0897 0.0679 0.0518 0.0467 0.0419 0.0416 0.0410 0.0402 0.0399 0.0397 0.0399 0.0402 0.0407 0.0413 0.0420 0.0429 

[TRAIN] Epoch[2](267/1500); Loss: 0.143614; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1561 0.1540 0.1453 0.1435 0.1419 0.1415 0.1410 0.1406 0.1405 0.1406 0.1410 0.1414 0.1418 0.1424 0.1429 0.1434 

[TRAIN] Epoch[2](268/1500); Loss: 0.054111; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1208 0.0638 0.0704 0.0528 0.0512 0.0475 0.0460 0.0458 0.0451 0.0450 0.0449 0.0449 0.0457 0.0462 0.0472 0.0483 

[TRAIN] Epoch[2](269/1500); Loss: 0.088474; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1460 0.1078 0.0948 0.0891 0.0833 0.0827 0.0822 0.0817 0.0813 0.0810 0.0808 0.0806 0.0808 0.0809 0.0811 0.0814 

[TRAIN] Epoch[2](270/1500); Loss: 0.075243; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1224 0.0994 0.0888 0.0793 0.0741 0.0707 0.0692 0.0682 0.0676 0.0671 0.0663 0.0660 0.0659 0.0659 0.0662 0.0666 

[TRAIN] Epoch[2](271/1500); Loss: 0.090374; Backpropagation: 0.0938 sec; Batch: 0.4288 sec
0.1466 0.1105 0.0954 0.0898 0.0840 0.0835 0.0831 0.0829 0.0827 0.0828 0.0830 0.0833 0.0837 0.0842 0.0849 0.0857 

[TRAIN] Epoch[2](272/1500); Loss: 0.127395; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.2074 0.1635 0.1282 0.1281 0.1219 0.1198 0.1194 0.1181 0.1171 0.1164 0.1161 0.1162 0.1163 0.1165 0.1166 0.1169 

[TRAIN] Epoch[2](273/1500); Loss: 0.098007; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1629 0.1105 0.0983 0.0953 0.0941 0.0931 0.0918 0.0913 0.0910 0.0910 0.0909 0.0911 0.0914 0.0917 0.0918 0.0920 

[TRAIN] Epoch[2](274/1500); Loss: 0.071551; Backpropagation: 0.0944 sec; Batch: 0.4300 sec
0.1044 0.0911 0.0756 0.0710 0.0674 0.0666 0.0667 0.0663 0.0663 0.0665 0.0664 0.0666 0.0670 0.0674 0.0677 0.0680 

[TRAIN] Epoch[2](275/1500); Loss: 0.083324; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1691 0.1156 0.0758 0.0776 0.0743 0.0761 0.0766 0.0753 0.0742 0.0736 0.0734 0.0735 0.0737 0.0739 0.0750 0.0754 

[TRAIN] Epoch[2](276/1500); Loss: 0.116535; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1646 0.1457 0.1254 0.1183 0.1144 0.1131 0.1118 0.1105 0.1093 0.1086 0.1080 0.1077 0.1072 0.1068 0.1066 0.1066 

[TRAIN] Epoch[2](277/1500); Loss: 0.082599; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1546 0.1173 0.0933 0.0888 0.0770 0.0726 0.0721 0.0723 0.0721 0.0714 0.0715 0.0713 0.0717 0.0719 0.0719 0.0720 

[TRAIN] Epoch[2](278/1500); Loss: 0.194602; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.2841 0.2495 0.2226 0.2158 0.1978 0.1877 0.1832 0.1795 0.1768 0.1746 0.1727 0.1727 0.1733 0.1740 0.1745 0.1750 

[TRAIN] Epoch[2](279/1500); Loss: 0.081893; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.0978 0.0879 0.0849 0.0831 0.0804 0.0800 0.0794 0.0792 0.0791 0.0791 0.0793 0.0794 0.0797 0.0801 0.0803 0.0806 

[TRAIN] Epoch[2](280/1500); Loss: 0.121506; Backpropagation: 0.0982 sec; Batch: 0.4330 sec
0.1439 0.1306 0.1249 0.1235 0.1202 0.1193 0.1184 0.1182 0.1179 0.1178 0.1179 0.1179 0.1180 0.1183 0.1186 0.1189 

[TRAIN] Epoch[2](281/1500); Loss: 0.094842; Backpropagation: 0.0983 sec; Batch: 0.4338 sec
0.1034 0.0971 0.0951 0.0993 0.0959 0.0941 0.0934 0.0930 0.0928 0.0928 0.0928 0.0933 0.0933 0.0934 0.0938 0.0940 

[TRAIN] Epoch[2](282/1500); Loss: 0.124423; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1798 0.1465 0.1368 0.1341 0.1246 0.1196 0.1171 0.1152 0.1146 0.1147 0.1145 0.1144 0.1145 0.1147 0.1148 0.1149 

[TRAIN] Epoch[2](283/1500); Loss: 0.110229; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1359 0.1201 0.1129 0.1128 0.1098 0.1083 0.1074 0.1066 0.1063 0.1062 0.1062 0.1062 0.1062 0.1061 0.1062 0.1065 

[TRAIN] Epoch[2](284/1500); Loss: 0.045184; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.0605 0.0524 0.0463 0.0492 0.0445 0.0429 0.0423 0.0424 0.0420 0.0418 0.0420 0.0425 0.0426 0.0433 0.0438 0.0443 

[TRAIN] Epoch[2](285/1500); Loss: 0.077174; Backpropagation: 0.0942 sec; Batch: 0.4297 sec
0.0982 0.0885 0.0795 0.0819 0.0774 0.0749 0.0739 0.0736 0.0735 0.0732 0.0730 0.0732 0.0734 0.0733 0.0735 0.0738 

[TRAIN] Epoch[2](286/1500); Loss: 0.112722; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1470 0.1261 0.1168 0.1157 0.1114 0.1102 0.1092 0.1087 0.1081 0.1075 0.1072 0.1070 0.1070 0.1070 0.1072 0.1074 

[TRAIN] Epoch[2](287/1500); Loss: 0.076881; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.1315 0.0939 0.0876 0.0788 0.0731 0.0715 0.0708 0.0701 0.0696 0.0693 0.0691 0.0688 0.0689 0.0690 0.0691 0.0692 

[TRAIN] Epoch[2](288/1500); Loss: 0.056804; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1531 0.0991 0.0592 0.0504 0.0479 0.0438 0.0432 0.0434 0.0441 0.0446 0.0450 0.0453 0.0464 0.0470 0.0477 0.0487 

[TRAIN] Epoch[2](289/1500); Loss: 0.104395; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1504 0.1242 0.1092 0.1064 0.1029 0.1013 0.1003 0.0992 0.0985 0.0979 0.0974 0.0969 0.0966 0.0965 0.0963 0.0963 

[TRAIN] Epoch[2](290/1500); Loss: 0.123904; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1557 0.1391 0.1281 0.1224 0.1209 0.1208 0.1200 0.1195 0.1194 0.1193 0.1192 0.1192 0.1194 0.1196 0.1196 0.1201 

[TRAIN] Epoch[2](291/1500); Loss: 0.052541; Backpropagation: 0.0939 sec; Batch: 0.4297 sec
0.0667 0.0764 0.0728 0.0550 0.0492 0.0480 0.0480 0.0471 0.0467 0.0468 0.0467 0.0468 0.0472 0.0474 0.0477 0.0484 

[TRAIN] Epoch[2](292/1500); Loss: 0.131178; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1563 0.1461 0.1319 0.1292 0.1279 0.1275 0.1270 0.1267 0.1269 0.1272 0.1276 0.1280 0.1283 0.1287 0.1294 0.1301 

[TRAIN] Epoch[2](293/1500); Loss: 0.121152; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1670 0.1415 0.1301 0.1265 0.1210 0.1190 0.1171 0.1156 0.1146 0.1136 0.1130 0.1125 0.1121 0.1118 0.1116 0.1114 

[TRAIN] Epoch[2](294/1500); Loss: 0.132699; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2151 0.1742 0.1439 0.1283 0.1254 0.1247 0.1243 0.1231 0.1219 0.1211 0.1207 0.1205 0.1203 0.1200 0.1198 0.1198 

[TRAIN] Epoch[2](295/1500); Loss: 0.118929; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1420 0.1329 0.1269 0.1223 0.1193 0.1176 0.1164 0.1153 0.1146 0.1142 0.1137 0.1136 0.1135 0.1134 0.1136 0.1136 

[TRAIN] Epoch[2](296/1500); Loss: 0.112086; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1471 0.1285 0.1236 0.1155 0.1099 0.1086 0.1077 0.1068 0.1062 0.1058 0.1054 0.1053 0.1054 0.1056 0.1059 0.1061 

[TRAIN] Epoch[2](297/1500); Loss: 0.066299; Backpropagation: 0.0943 sec; Batch: 0.4298 sec
0.0935 0.0922 0.0875 0.0705 0.0644 0.0626 0.0615 0.0606 0.0602 0.0596 0.0589 0.0585 0.0582 0.0577 0.0576 0.0573 

[TRAIN] Epoch[2](298/1500); Loss: 0.052866; Backpropagation: 0.0947 sec; Batch: 0.4298 sec
0.0825 0.0687 0.0572 0.0542 0.0529 0.0533 0.0497 0.0482 0.0479 0.0477 0.0471 0.0471 0.0473 0.0469 0.0473 0.0479 

[TRAIN] Epoch[2](299/1500); Loss: 0.107752; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1893 0.1604 0.1337 0.1094 0.0993 0.0959 0.0968 0.0959 0.0947 0.0939 0.0933 0.0929 0.0925 0.0921 0.0920 0.0919 

[TRAIN] Epoch[2](300/1500); Loss: 0.135467; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.2018 0.1736 0.1412 0.1415 0.1330 0.1269 0.1265 0.1258 0.1253 0.1248 0.1245 0.1245 0.1244 0.1245 0.1246 0.1246 

[TRAIN] Epoch[2](301/1500); Loss: 0.093597; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1425 0.1148 0.0955 0.0916 0.0893 0.0904 0.0896 0.0882 0.0872 0.0870 0.0869 0.0869 0.0869 0.0869 0.0870 0.0871 

[TRAIN] Epoch[2](302/1500); Loss: 0.104726; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1273 0.1173 0.1095 0.1061 0.1035 0.1028 0.1022 0.1017 0.1013 0.1010 0.1008 0.1007 0.1005 0.1005 0.1003 0.1003 

[TRAIN] Epoch[2](303/1500); Loss: 0.150091; Backpropagation: 0.0942 sec; Batch: 0.4300 sec
0.3488 0.2678 0.2289 0.2163 0.1621 0.1382 0.1187 0.1034 0.0945 0.1041 0.1060 0.1042 0.1029 0.1022 0.1018 0.1017 

[TRAIN] Epoch[2](304/1500); Loss: 0.076772; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1497 0.1110 0.0887 0.0818 0.0681 0.0690 0.0684 0.0667 0.0659 0.0657 0.0655 0.0655 0.0656 0.0656 0.0655 0.0655 

[TRAIN] Epoch[2](305/1500); Loss: 0.081252; Backpropagation: 0.0940 sec; Batch: 0.4618 sec
0.1230 0.1049 0.0927 0.0831 0.0779 0.0764 0.0759 0.0753 0.0747 0.0742 0.0739 0.0738 0.0736 0.0735 0.0734 0.0736 

[TRAIN] Epoch[2](306/1500); Loss: 0.128457; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2005 0.1548 0.1391 0.1352 0.1254 0.1228 0.1209 0.1196 0.1186 0.1179 0.1173 0.1169 0.1169 0.1167 0.1164 0.1163 

[TRAIN] Epoch[2](307/1500); Loss: 0.085662; Backpropagation: 0.0934 sec; Batch: 0.4288 sec
0.1198 0.1042 0.0912 0.0844 0.0814 0.0805 0.0797 0.0796 0.0798 0.0802 0.0805 0.0809 0.0812 0.0817 0.0824 0.0831 

[TRAIN] Epoch[2](308/1500); Loss: 0.084148; Backpropagation: 0.0932 sec; Batch: 0.4284 sec
0.2128 0.1253 0.0875 0.0778 0.0733 0.0811 0.0758 0.0723 0.0698 0.0683 0.0674 0.0670 0.0669 0.0668 0.0670 0.0674 

[TRAIN] Epoch[2](309/1500); Loss: 0.080667; Backpropagation: 0.0937 sec; Batch: 0.4292 sec
0.1343 0.0972 0.0842 0.0814 0.0775 0.0767 0.0753 0.0745 0.0742 0.0738 0.0735 0.0736 0.0736 0.0735 0.0736 0.0738 

[TRAIN] Epoch[2](310/1500); Loss: 0.048871; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1930 0.0947 0.0505 0.0390 0.0463 0.0501 0.0386 0.0326 0.0306 0.0295 0.0293 0.0294 0.0293 0.0294 0.0296 0.0299 

[TRAIN] Epoch[2](311/1500); Loss: 0.095865; Backpropagation: 0.0933 sec; Batch: 0.4285 sec
0.1471 0.1206 0.1024 0.1065 0.0968 0.0917 0.0895 0.0882 0.0875 0.0868 0.0863 0.0862 0.0862 0.0862 0.0860 0.0860 

[TRAIN] Epoch[2](312/1500); Loss: 0.055313; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.0672 0.0626 0.0557 0.0573 0.0548 0.0533 0.0529 0.0529 0.0529 0.0528 0.0530 0.0533 0.0538 0.0539 0.0541 0.0545 

[TRAIN] Epoch[2](313/1500); Loss: 0.090705; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.2910 0.1991 0.1495 0.1321 0.0784 0.0589 0.0560 0.0566 0.0553 0.0544 0.0540 0.0537 0.0535 0.0533 0.0531 0.0527 

[TRAIN] Epoch[2](314/1500); Loss: 0.031620; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.0608 0.0461 0.0322 0.0334 0.0284 0.0266 0.0267 0.0266 0.0266 0.0270 0.0272 0.0273 0.0282 0.0287 0.0294 0.0307 

[TRAIN] Epoch[2](315/1500); Loss: 0.059504; Backpropagation: 0.0982 sec; Batch: 0.4335 sec
0.0641 0.0660 0.0643 0.0601 0.0588 0.0579 0.0577 0.0575 0.0577 0.0575 0.0576 0.0580 0.0582 0.0585 0.0589 0.0593 

[TRAIN] Epoch[2](316/1500); Loss: 0.145416; Backpropagation: 0.0963 sec; Batch: 0.4315 sec
0.1863 0.1728 0.1585 0.1485 0.1429 0.1411 0.1400 0.1391 0.1384 0.1376 0.1371 0.1369 0.1368 0.1367 0.1369 0.1370 

[TRAIN] Epoch[2](317/1500); Loss: 0.074994; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1018 0.0926 0.0834 0.0761 0.0735 0.0719 0.0712 0.0706 0.0700 0.0696 0.0695 0.0695 0.0699 0.0698 0.0701 0.0704 

[TRAIN] Epoch[2](318/1500); Loss: 0.108440; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1364 0.1252 0.1169 0.1122 0.1076 0.1062 0.1050 0.1040 0.1030 0.1023 0.1021 0.1022 0.1023 0.1027 0.1032 0.1039 

[TRAIN] Epoch[2](319/1500); Loss: 0.077831; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1212 0.1018 0.0913 0.0820 0.0753 0.0726 0.0711 0.0703 0.0699 0.0699 0.0697 0.0698 0.0698 0.0699 0.0703 0.0705 

[TRAIN] Epoch[2](320/1500); Loss: 0.075839; Backpropagation: 0.0938 sec; Batch: 0.4365 sec
0.1350 0.1018 0.0748 0.0729 0.0711 0.0722 0.0714 0.0699 0.0689 0.0683 0.0679 0.0678 0.0677 0.0678 0.0679 0.0681 

[TRAIN] Epoch[2](321/1500); Loss: 0.099157; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1458 0.1254 0.1068 0.0984 0.0951 0.0945 0.0937 0.0929 0.0924 0.0919 0.0916 0.0916 0.0914 0.0914 0.0916 0.0919 

[TRAIN] Epoch[2](322/1500); Loss: 0.079208; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1165 0.0959 0.0844 0.0794 0.0771 0.0775 0.0757 0.0744 0.0737 0.0734 0.0734 0.0733 0.0730 0.0732 0.0731 0.0732 

[TRAIN] Epoch[2](323/1500); Loss: 0.048696; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.0901 0.0702 0.0684 0.0532 0.0456 0.0433 0.0420 0.0414 0.0412 0.0406 0.0404 0.0404 0.0404 0.0405 0.0407 0.0409 

[TRAIN] Epoch[2](324/1500); Loss: 0.091261; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1467 0.1126 0.0984 0.0927 0.0869 0.0843 0.0834 0.0831 0.0831 0.0832 0.0836 0.0836 0.0841 0.0846 0.0849 0.0852 

[TRAIN] Epoch[2](325/1500); Loss: 0.103573; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1398 0.1154 0.1046 0.1016 0.1012 0.1012 0.1007 0.1002 0.0998 0.0994 0.0993 0.0990 0.0988 0.0988 0.0988 0.0987 

[TRAIN] Epoch[2](326/1500); Loss: 0.108903; Backpropagation: 0.0936 sec; Batch: 0.4291 sec
0.1892 0.1475 0.1274 0.1161 0.1065 0.1019 0.0992 0.0977 0.0965 0.0957 0.0950 0.0945 0.0942 0.0939 0.0937 0.0935 

[TRAIN] Epoch[2](327/1500); Loss: 0.092492; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1711 0.1269 0.1021 0.0971 0.0845 0.0832 0.0824 0.0818 0.0809 0.0808 0.0809 0.0811 0.0813 0.0815 0.0819 0.0823 

[TRAIN] Epoch[2](328/1500); Loss: 0.073567; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1132 0.0963 0.0877 0.0809 0.0736 0.0710 0.0680 0.0667 0.0659 0.0655 0.0653 0.0649 0.0647 0.0646 0.0644 0.0644 

[TRAIN] Epoch[2](329/1500); Loss: 0.100191; Backpropagation: 0.0933 sec; Batch: 0.4288 sec
0.3072 0.1884 0.1319 0.1140 0.0805 0.0869 0.0781 0.0738 0.0707 0.0690 0.0679 0.0673 0.0670 0.0667 0.0667 0.0669 

[TRAIN] Epoch[2](330/1500); Loss: 0.066290; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1078 0.0933 0.0764 0.0699 0.0647 0.0637 0.0620 0.0608 0.0598 0.0588 0.0580 0.0574 0.0571 0.0569 0.0569 0.0574 

[TRAIN] Epoch[2](331/1500); Loss: 0.113106; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1535 0.1362 0.1171 0.1144 0.1110 0.1097 0.1082 0.1075 0.1073 0.1070 0.1068 0.1066 0.1064 0.1061 0.1059 0.1061 

[TRAIN] Epoch[2](332/1500); Loss: 0.139873; Backpropagation: 0.0982 sec; Batch: 0.4338 sec
0.2201 0.1794 0.1564 0.1493 0.1369 0.1322 0.1280 0.1275 0.1269 0.1261 0.1258 0.1258 0.1257 0.1258 0.1259 0.1260 

[TRAIN] Epoch[2](333/1500); Loss: 0.067395; Backpropagation: 0.0963 sec; Batch: 0.4320 sec
0.1279 0.0899 0.0687 0.0724 0.0636 0.0609 0.0603 0.0598 0.0596 0.0593 0.0591 0.0591 0.0592 0.0593 0.0596 0.0598 

[TRAIN] Epoch[2](334/1500); Loss: 0.068909; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.1549 0.0998 0.0717 0.0654 0.0649 0.0626 0.0595 0.0583 0.0582 0.0581 0.0580 0.0580 0.0581 0.0582 0.0583 0.0585 

[TRAIN] Epoch[2](335/1500); Loss: 0.116324; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1554 0.1374 0.1241 0.1181 0.1139 0.1130 0.1119 0.1113 0.1106 0.1101 0.1097 0.1094 0.1091 0.1091 0.1090 0.1091 

[TRAIN] Epoch[2](336/1500); Loss: 0.086275; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1987 0.1320 0.0948 0.0899 0.0769 0.0750 0.0733 0.0722 0.0715 0.0709 0.0707 0.0708 0.0709 0.0707 0.0708 0.0712 

[TRAIN] Epoch[2](337/1500); Loss: 0.155025; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1732 0.1634 0.1584 0.1567 0.1543 0.1536 0.1529 0.1524 0.1524 0.1522 0.1518 0.1515 0.1515 0.1518 0.1521 0.1524 

[TRAIN] Epoch[2](338/1500); Loss: 0.097029; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.2848 0.2035 0.1531 0.1351 0.0857 0.0684 0.0664 0.0672 0.0632 0.0611 0.0609 0.0608 0.0604 0.0605 0.0606 0.0608 

[TRAIN] Epoch[2](339/1500); Loss: 0.117859; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1596 0.1326 0.1204 0.1168 0.1154 0.1152 0.1142 0.1138 0.1132 0.1129 0.1124 0.1122 0.1120 0.1120 0.1116 0.1115 

[TRAIN] Epoch[2](340/1500); Loss: 0.101708; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1515 0.1316 0.1163 0.1095 0.1006 0.0975 0.0938 0.0924 0.0922 0.0918 0.0918 0.0916 0.0915 0.0916 0.0918 0.0918 

[TRAIN] Epoch[2](341/1500); Loss: 0.102132; Backpropagation: 0.0934 sec; Batch: 0.4287 sec
0.1965 0.1427 0.1162 0.1092 0.0928 0.0922 0.0904 0.0888 0.0885 0.0881 0.0877 0.0878 0.0876 0.0883 0.0887 0.0885 

[TRAIN] Epoch[2](342/1500); Loss: 0.058362; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.0919 0.0766 0.0769 0.0637 0.0567 0.0548 0.0548 0.0534 0.0521 0.0514 0.0507 0.0502 0.0501 0.0501 0.0500 0.0503 

[TRAIN] Epoch[2](343/1500); Loss: 0.149306; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1600 0.1514 0.1511 0.1514 0.1486 0.1474 0.1469 0.1468 0.1471 0.1472 0.1474 0.1478 0.1483 0.1488 0.1490 0.1496 

[TRAIN] Epoch[2](344/1500); Loss: 0.108543; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1485 0.1327 0.1221 0.1085 0.1053 0.1046 0.1038 0.1025 0.1018 0.1019 0.1012 0.1007 0.1010 0.1007 0.1007 0.1006 

[TRAIN] Epoch[2](345/1500); Loss: 0.110879; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.1341 0.1248 0.1156 0.1163 0.1105 0.1087 0.1075 0.1068 0.1069 0.1065 0.1064 0.1063 0.1058 0.1058 0.1061 0.1058 

[TRAIN] Epoch[2](346/1500); Loss: 0.071809; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.0958 0.0750 0.0787 0.0739 0.0710 0.0698 0.0684 0.0685 0.0683 0.0678 0.0679 0.0685 0.0685 0.0687 0.0689 0.0692 

[TRAIN] Epoch[2](347/1500); Loss: 0.101291; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1533 0.1223 0.1137 0.1054 0.0966 0.0959 0.0947 0.0937 0.0933 0.0930 0.0928 0.0928 0.0929 0.0931 0.0934 0.0937 

[TRAIN] Epoch[2](348/1500); Loss: 0.093905; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1356 0.1223 0.1078 0.0981 0.0913 0.0890 0.0875 0.0865 0.0856 0.0853 0.0854 0.0855 0.0854 0.0855 0.0857 0.0859 

[TRAIN] Epoch[2](349/1500); Loss: 0.097326; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1482 0.1094 0.1043 0.0968 0.0950 0.0936 0.0921 0.0915 0.0911 0.0906 0.0906 0.0906 0.0909 0.0908 0.0907 0.0910 

[TRAIN] Epoch[2](350/1500); Loss: 0.069581; Backpropagation: 0.1012 sec; Batch: 0.4366 sec
0.1521 0.1223 0.0809 0.0746 0.0606 0.0589 0.0570 0.0566 0.0566 0.0561 0.0560 0.0559 0.0561 0.0563 0.0566 0.0567 

[TRAIN] Epoch[2](351/1500); Loss: 0.050758; Backpropagation: 0.0957 sec; Batch: 0.4312 sec
0.0563 0.0598 0.0537 0.0580 0.0554 0.0512 0.0476 0.0465 0.0466 0.0468 0.0469 0.0474 0.0479 0.0485 0.0492 0.0502 

[TRAIN] Epoch[2](352/1500); Loss: 0.087215; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.2361 0.1349 0.0826 0.0708 0.0722 0.0753 0.0728 0.0719 0.0712 0.0711 0.0716 0.0723 0.0721 0.0729 0.0741 0.0736 

[TRAIN] Epoch[2](353/1500); Loss: 0.048504; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.0749 0.0875 0.0828 0.0552 0.0468 0.0422 0.0396 0.0389 0.0387 0.0384 0.0383 0.0383 0.0384 0.0385 0.0386 0.0390 

[TRAIN] Epoch[2](354/1500); Loss: 0.065804; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1132 0.0856 0.0776 0.0738 0.0661 0.0631 0.0610 0.0593 0.0585 0.0576 0.0570 0.0566 0.0563 0.0558 0.0559 0.0556 

[TRAIN] Epoch[2](355/1500); Loss: 0.054779; Backpropagation: 0.0935 sec; Batch: 0.4292 sec
0.1748 0.1236 0.0451 0.0447 0.0451 0.0492 0.0453 0.0399 0.0393 0.0385 0.0375 0.0386 0.0383 0.0376 0.0396 0.0395 

[TRAIN] Epoch[2](356/1500); Loss: 0.085642; Backpropagation: 0.0942 sec; Batch: 0.4293 sec
0.1620 0.1424 0.1074 0.0970 0.0822 0.0790 0.0756 0.0729 0.0714 0.0700 0.0689 0.0685 0.0685 0.0679 0.0680 0.0686 

[TRAIN] Epoch[2](357/1500); Loss: 0.104000; Backpropagation: 0.0937 sec; Batch: 0.4601 sec
0.1954 0.1644 0.1246 0.1093 0.1010 0.0999 0.0951 0.0912 0.0884 0.0868 0.0861 0.0852 0.0844 0.0841 0.0842 0.0839 

[TRAIN] Epoch[2](358/1500); Loss: 0.124048; Backpropagation: 0.0939 sec; Batch: 0.4318 sec
0.1822 0.1515 0.1363 0.1274 0.1243 0.1230 0.1181 0.1153 0.1142 0.1138 0.1135 0.1132 0.1130 0.1130 0.1129 0.1130 

[TRAIN] Epoch[2](359/1500); Loss: 0.094238; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1038 0.1038 0.1077 0.0968 0.0939 0.0925 0.0918 0.0911 0.0904 0.0904 0.0902 0.0903 0.0904 0.0909 0.0916 0.0922 

[TRAIN] Epoch[2](360/1500); Loss: 0.090021; Backpropagation: 0.0934 sec; Batch: 0.4287 sec
0.1562 0.1384 0.1135 0.0980 0.0846 0.0839 0.0818 0.0788 0.0773 0.0765 0.0759 0.0756 0.0752 0.0752 0.0748 0.0746 

[TRAIN] Epoch[2](361/1500); Loss: 0.121937; Backpropagation: 0.0942 sec; Batch: 0.4301 sec
0.1983 0.1473 0.1256 0.1186 0.1302 0.1300 0.1214 0.1158 0.1126 0.1099 0.1082 0.1071 0.1065 0.1068 0.1065 0.1064 

[TRAIN] Epoch[2](362/1500); Loss: 0.125867; Backpropagation: 0.0939 sec; Batch: 0.4308 sec
0.1814 0.1640 0.1473 0.1335 0.1250 0.1226 0.1198 0.1176 0.1160 0.1147 0.1136 0.1127 0.1118 0.1114 0.1112 0.1111 

[TRAIN] Epoch[2](363/1500); Loss: 0.075100; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.1026 0.0952 0.0907 0.0805 0.0762 0.0795 0.0750 0.0708 0.0685 0.0676 0.0667 0.0661 0.0659 0.0655 0.0654 0.0654 

[TRAIN] Epoch[2](364/1500); Loss: 0.137144; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1780 0.1523 0.1436 0.1366 0.1369 0.1362 0.1341 0.1325 0.1316 0.1310 0.1306 0.1302 0.1301 0.1301 0.1300 0.1302 

[TRAIN] Epoch[2](365/1500); Loss: 0.093918; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1464 0.1199 0.1123 0.0970 0.0943 0.0924 0.0885 0.0860 0.0844 0.0835 0.0829 0.0828 0.0830 0.0829 0.0830 0.0835 

[TRAIN] Epoch[2](366/1500); Loss: 0.066347; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1226 0.0969 0.0879 0.0727 0.0707 0.0667 0.0606 0.0562 0.0539 0.0529 0.0525 0.0527 0.0530 0.0534 0.0541 0.0547 

[TRAIN] Epoch[2](367/1500); Loss: 0.135222; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1577 0.1493 0.1446 0.1372 0.1355 0.1354 0.1335 0.1315 0.1304 0.1299 0.1297 0.1296 0.1295 0.1296 0.1299 0.1302 

[TRAIN] Epoch[2](368/1500); Loss: 0.070352; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1610 0.1384 0.1039 0.0860 0.0591 0.0588 0.0580 0.0544 0.0526 0.0515 0.0508 0.0502 0.0500 0.0499 0.0504 0.0506 

[TRAIN] Epoch[2](369/1500); Loss: 0.105658; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1582 0.1439 0.1242 0.1037 0.0997 0.1027 0.1000 0.0974 0.0961 0.0954 0.0948 0.0945 0.0944 0.0947 0.0953 0.0956 

[TRAIN] Epoch[2](370/1500); Loss: 0.104517; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1370 0.1354 0.1237 0.1086 0.1014 0.0990 0.0975 0.0966 0.0964 0.0964 0.0961 0.0964 0.0965 0.0969 0.0971 0.0973 

[TRAIN] Epoch[2](371/1500); Loss: 0.117232; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1778 0.1541 0.1402 0.1201 0.1141 0.1137 0.1098 0.1075 0.1065 0.1055 0.1047 0.1042 0.1041 0.1044 0.1044 0.1046 

[TRAIN] Epoch[2](372/1500); Loss: 0.059377; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1293 0.0966 0.0699 0.0584 0.0535 0.0526 0.0496 0.0484 0.0485 0.0482 0.0479 0.0486 0.0489 0.0489 0.0499 0.0507 

[TRAIN] Epoch[2](373/1500); Loss: 0.070747; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1876 0.1215 0.0853 0.0717 0.0617 0.0596 0.0558 0.0547 0.0538 0.0536 0.0543 0.0539 0.0540 0.0546 0.0548 0.0553 

[TRAIN] Epoch[2](374/1500); Loss: 0.147696; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1633 0.1665 0.1587 0.1487 0.1458 0.1452 0.1444 0.1439 0.1436 0.1434 0.1432 0.1433 0.1432 0.1433 0.1433 0.1434 

[TRAIN] Epoch[2](375/1500); Loss: 0.093138; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.2388 0.1795 0.1305 0.1094 0.0762 0.0733 0.0723 0.0716 0.0688 0.0674 0.0670 0.0663 0.0669 0.0671 0.0674 0.0678 

[TRAIN] Epoch[2](376/1500); Loss: 0.100203; Backpropagation: 0.0935 sec; Batch: 0.4288 sec
0.1339 0.1242 0.1126 0.1018 0.0985 0.0973 0.0956 0.0946 0.0937 0.0931 0.0928 0.0930 0.0930 0.0930 0.0930 0.0931 

[TRAIN] Epoch[2](377/1500); Loss: 0.114143; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1259 0.1205 0.1122 0.1116 0.1108 0.1109 0.1111 0.1113 0.1116 0.1120 0.1124 0.1130 0.1143 0.1149 0.1165 0.1174 

[TRAIN] Epoch[2](378/1500); Loss: 0.051946; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.0959 0.0744 0.0726 0.0485 0.0466 0.0464 0.0440 0.0442 0.0435 0.0437 0.0440 0.0440 0.0454 0.0451 0.0458 0.0468 

[TRAIN] Epoch[2](379/1500); Loss: 0.086711; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1103 0.1097 0.0984 0.0856 0.0865 0.0873 0.0834 0.0815 0.0807 0.0808 0.0803 0.0800 0.0803 0.0806 0.0808 0.0812 

[TRAIN] Epoch[2](380/1500); Loss: 0.097825; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1385 0.1051 0.1045 0.0961 0.0963 0.0958 0.0948 0.0943 0.0931 0.0927 0.0925 0.0923 0.0925 0.0921 0.0924 0.0922 

[TRAIN] Epoch[2](381/1500); Loss: 0.081493; Backpropagation: 0.0934 sec; Batch: 0.4287 sec
0.1242 0.1103 0.0931 0.0873 0.0792 0.0765 0.0760 0.0743 0.0738 0.0732 0.0734 0.0729 0.0727 0.0722 0.0725 0.0724 

[TRAIN] Epoch[2](382/1500); Loss: 0.079573; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1271 0.1069 0.0828 0.0768 0.0730 0.0731 0.0724 0.0718 0.0720 0.0722 0.0727 0.0735 0.0738 0.0742 0.0751 0.0757 

[TRAIN] Epoch[2](383/1500); Loss: 0.079149; Backpropagation: 0.0935 sec; Batch: 0.4295 sec
0.1166 0.1058 0.0884 0.0792 0.0735 0.0735 0.0724 0.0720 0.0718 0.0722 0.0722 0.0726 0.0731 0.0736 0.0745 0.0747 

[TRAIN] Epoch[2](384/1500); Loss: 0.077067; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1048 0.1030 0.0967 0.0798 0.0723 0.0712 0.0703 0.0700 0.0695 0.0696 0.0694 0.0701 0.0702 0.0710 0.0724 0.0729 

[TRAIN] Epoch[2](385/1500); Loss: 0.103742; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1257 0.1232 0.1155 0.1038 0.1022 0.1023 0.1001 0.0989 0.0986 0.0986 0.0983 0.0981 0.0983 0.0986 0.0987 0.0990 

[TRAIN] Epoch[2](386/1500); Loss: 0.080038; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1493 0.1216 0.1042 0.0756 0.0728 0.0705 0.0702 0.0686 0.0682 0.0682 0.0682 0.0683 0.0683 0.0685 0.0689 0.0690 

[TRAIN] Epoch[2](387/1500); Loss: 0.099178; Backpropagation: 0.0941 sec; Batch: 0.4278 sec
0.1493 0.1354 0.1187 0.1064 0.0963 0.0937 0.0914 0.0903 0.0895 0.0888 0.0882 0.0879 0.0878 0.0875 0.0877 0.0879 

[TRAIN] Epoch[2](388/1500); Loss: 0.048478; Backpropagation: 0.0932 sec; Batch: 0.4281 sec
0.1052 0.1157 0.0755 0.0265 0.0420 0.0434 0.0382 0.0354 0.0344 0.0348 0.0355 0.0361 0.0372 0.0377 0.0390 0.0392 

[TRAIN] Epoch[2](389/1500); Loss: 0.120616; Backpropagation: 0.0936 sec; Batch: 0.4293 sec
0.1635 0.1478 0.1310 0.1232 0.1174 0.1161 0.1141 0.1130 0.1126 0.1124 0.1124 0.1126 0.1130 0.1133 0.1137 0.1139 

[TRAIN] Epoch[2](390/1500); Loss: 0.065590; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1686 0.1366 0.0950 0.0844 0.0586 0.0510 0.0473 0.0464 0.0460 0.0450 0.0454 0.0448 0.0450 0.0451 0.0448 0.0453 

[TRAIN] Epoch[2](391/1500); Loss: 0.065020; Backpropagation: 0.0941 sec; Batch: 0.4276 sec
0.1081 0.0935 0.0728 0.0658 0.0609 0.0607 0.0594 0.0588 0.0580 0.0576 0.0573 0.0571 0.0571 0.0575 0.0576 0.0581 

[TRAIN] Epoch[2](392/1500); Loss: 0.111764; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1761 0.1515 0.1332 0.1201 0.1087 0.1050 0.1012 0.0997 0.0996 0.0991 0.0993 0.0991 0.0988 0.0987 0.0989 0.0992 

[TRAIN] Epoch[2](393/1500); Loss: 0.046806; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1027 0.0635 0.0548 0.0433 0.0424 0.0394 0.0399 0.0388 0.0386 0.0390 0.0401 0.0402 0.0401 0.0415 0.0421 0.0426 

[TRAIN] Epoch[2](394/1500); Loss: 0.057857; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1074 0.1191 0.0814 0.0512 0.0513 0.0529 0.0462 0.0452 0.0458 0.0454 0.0452 0.0453 0.0474 0.0471 0.0468 0.0482 

[TRAIN] Epoch[2](395/1500); Loss: 0.049137; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1213 0.0494 0.0602 0.0438 0.0452 0.0432 0.0414 0.0410 0.0416 0.0408 0.0417 0.0421 0.0418 0.0433 0.0449 0.0446 

[TRAIN] Epoch[2](396/1500); Loss: 0.051512; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.0916 0.0516 0.0893 0.0573 0.0462 0.0437 0.0473 0.0449 0.0434 0.0432 0.0430 0.0441 0.0441 0.0439 0.0452 0.0455 

[TRAIN] Epoch[2](397/1500); Loss: 0.069963; Backpropagation: 0.0942 sec; Batch: 0.4293 sec
0.0918 0.0975 0.0877 0.0703 0.0685 0.0669 0.0638 0.0637 0.0634 0.0633 0.0629 0.0632 0.0639 0.0638 0.0641 0.0646 

[TRAIN] Epoch[2](398/1500); Loss: 0.094294; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1163 0.1102 0.1036 0.0970 0.0919 0.0908 0.0908 0.0897 0.0894 0.0896 0.0896 0.0896 0.0899 0.0901 0.0900 0.0902 

[TRAIN] Epoch[2](399/1500); Loss: 0.058790; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.0851 0.0660 0.0849 0.0706 0.0579 0.0529 0.0522 0.0516 0.0515 0.0516 0.0518 0.0525 0.0525 0.0525 0.0537 0.0533 

[TRAIN] Epoch[2](400/1500); Loss: 0.085035; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1638 0.1381 0.1118 0.0882 0.0759 0.0734 0.0717 0.0712 0.0707 0.0703 0.0710 0.0705 0.0704 0.0712 0.0709 0.0715 

[TRAIN] Epoch[2](401/1500); Loss: 0.110717; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.4049 0.2992 0.2093 0.1730 0.0957 0.0745 0.0466 0.0571 0.0570 0.0500 0.0491 0.0504 0.0498 0.0508 0.0526 0.0514 

[TRAIN] Epoch[2](402/1500); Loss: 0.113280; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1594 0.1321 0.1200 0.1124 0.1100 0.1083 0.1073 0.1068 0.1066 0.1065 0.1064 0.1067 0.1070 0.1071 0.1076 0.1082 

[TRAIN] Epoch[2](403/1500); Loss: 0.081814; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1075 0.1029 0.0961 0.0885 0.0830 0.0790 0.0776 0.0759 0.0751 0.0748 0.0749 0.0745 0.0744 0.0748 0.0750 0.0752 

[TRAIN] Epoch[2](404/1500); Loss: 0.050108; Backpropagation: 0.0934 sec; Batch: 0.4287 sec
0.0834 0.0728 0.0612 0.0520 0.0481 0.0467 0.0450 0.0445 0.0435 0.0435 0.0432 0.0430 0.0434 0.0434 0.0437 0.0443 

[TRAIN] Epoch[2](405/1500); Loss: 0.079986; Backpropagation: 0.0933 sec; Batch: 0.4290 sec
0.2475 0.1687 0.0944 0.0672 0.0731 0.0782 0.0660 0.0574 0.0539 0.0527 0.0529 0.0530 0.0529 0.0533 0.0543 0.0544 

[TRAIN] Epoch[2](406/1500); Loss: 0.075680; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.1055 0.0954 0.0814 0.0753 0.0719 0.0713 0.0713 0.0712 0.0707 0.0704 0.0708 0.0706 0.0707 0.0711 0.0716 0.0718 

[TRAIN] Epoch[2](407/1500); Loss: 0.066778; Backpropagation: 0.0936 sec; Batch: 0.4292 sec
0.1027 0.0874 0.0894 0.0773 0.0684 0.0629 0.0605 0.0590 0.0580 0.0577 0.0572 0.0571 0.0574 0.0573 0.0577 0.0584 

[TRAIN] Epoch[2](408/1500); Loss: 0.083887; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1941 0.1304 0.0935 0.0792 0.0792 0.0783 0.0733 0.0704 0.0690 0.0680 0.0679 0.0677 0.0675 0.0678 0.0680 0.0678 

[TRAIN] Epoch[2](409/1500); Loss: 0.107688; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2004 0.1496 0.1292 0.1072 0.1026 0.0998 0.0962 0.0948 0.0940 0.0930 0.0928 0.0927 0.0925 0.0926 0.0928 0.0930 

[TRAIN] Epoch[2](410/1500); Loss: 0.102816; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1508 0.1299 0.1292 0.1144 0.1033 0.0985 0.0957 0.0938 0.0926 0.0917 0.0912 0.0909 0.0907 0.0907 0.0909 0.0908 

[TRAIN] Epoch[2](411/1500); Loss: 0.113160; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.1393 0.1335 0.1204 0.1141 0.1110 0.1096 0.1089 0.1090 0.1085 0.1084 0.1080 0.1077 0.1081 0.1079 0.1078 0.1082 

[TRAIN] Epoch[2](412/1500); Loss: 0.119959; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1661 0.1408 0.1273 0.1217 0.1184 0.1164 0.1150 0.1140 0.1132 0.1127 0.1125 0.1121 0.1120 0.1122 0.1122 0.1126 

[TRAIN] Epoch[2](413/1500); Loss: 0.116149; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1688 0.1547 0.1331 0.1234 0.1125 0.1092 0.1069 0.1058 0.1057 0.1055 0.1053 0.1053 0.1053 0.1054 0.1056 0.1059 

[TRAIN] Epoch[2](414/1500); Loss: 0.069889; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1817 0.1891 0.1412 0.0695 0.0488 0.0403 0.0487 0.0470 0.0428 0.0426 0.0427 0.0442 0.0438 0.0440 0.0462 0.0457 

[TRAIN] Epoch[2](415/1500); Loss: 0.102102; Backpropagation: 0.0934 sec; Batch: 0.4292 sec
0.1742 0.1464 0.1095 0.0989 0.0954 0.0953 0.0926 0.0916 0.0913 0.0911 0.0910 0.0910 0.0910 0.0911 0.0914 0.0917 

[TRAIN] Epoch[2](416/1500); Loss: 0.114260; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1532 0.1417 0.1212 0.1148 0.1102 0.1094 0.1089 0.1081 0.1078 0.1081 0.1075 0.1073 0.1073 0.1074 0.1075 0.1077 

[TRAIN] Epoch[2](417/1500); Loss: 0.092273; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.1753 0.1485 0.1134 0.0897 0.0868 0.0858 0.0819 0.0793 0.0781 0.0775 0.0769 0.0767 0.0766 0.0765 0.0766 0.0769 

[TRAIN] Epoch[2](418/1500); Loss: 0.114386; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1441 0.1466 0.1263 0.1199 0.1145 0.1101 0.1091 0.1079 0.1069 0.1065 0.1063 0.1060 0.1061 0.1064 0.1064 0.1068 

[TRAIN] Epoch[2](419/1500); Loss: 0.091448; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1630 0.1429 0.1133 0.0902 0.0856 0.0831 0.0807 0.0790 0.0783 0.0783 0.0780 0.0780 0.0779 0.0781 0.0784 0.0786 

[TRAIN] Epoch[2](420/1500); Loss: 0.079222; Backpropagation: 0.0982 sec; Batch: 0.4344 sec
0.1015 0.0975 0.0868 0.0803 0.0764 0.0753 0.0748 0.0748 0.0742 0.0743 0.0745 0.0749 0.0747 0.0755 0.0758 0.0763 

[TRAIN] Epoch[2](421/1500); Loss: 0.043670; Backpropagation: 0.0961 sec; Batch: 0.4307 sec
0.1077 0.1142 0.0489 0.0606 0.0553 0.0250 0.0284 0.0279 0.0270 0.0266 0.0289 0.0280 0.0289 0.0294 0.0299 0.0318 

[TRAIN] Epoch[2](422/1500); Loss: 0.053425; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1273 0.0874 0.0631 0.0524 0.0483 0.0448 0.0435 0.0441 0.0427 0.0425 0.0438 0.0425 0.0423 0.0437 0.0432 0.0432 

[TRAIN] Epoch[2](423/1500); Loss: 0.039776; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.0916 0.0476 0.0667 0.0465 0.0382 0.0360 0.0330 0.0311 0.0304 0.0303 0.0301 0.0304 0.0303 0.0312 0.0314 0.0317 

[TRAIN] Epoch[2](424/1500); Loss: 0.082137; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1043 0.1194 0.0930 0.0899 0.0842 0.0774 0.0760 0.0752 0.0751 0.0742 0.0741 0.0740 0.0742 0.0745 0.0741 0.0746 

[TRAIN] Epoch[2](425/1500); Loss: 0.121935; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.3122 0.2299 0.1569 0.1318 0.0918 0.1048 0.1050 0.0986 0.0939 0.0912 0.0899 0.0891 0.0890 0.0889 0.0889 0.0891 

[TRAIN] Epoch[2](426/1500); Loss: 0.084677; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1631 0.1552 0.1114 0.0793 0.0763 0.0770 0.0752 0.0698 0.0678 0.0682 0.0680 0.0681 0.0685 0.0685 0.0688 0.0697 

[TRAIN] Epoch[2](427/1500); Loss: 0.110610; Backpropagation: 0.0937 sec; Batch: 0.4295 sec
0.1640 0.1454 0.1279 0.1149 0.1069 0.1047 0.1032 0.1019 0.1015 0.1007 0.1003 0.1000 0.0999 0.0995 0.0996 0.0993 

[TRAIN] Epoch[2](428/1500); Loss: 0.129824; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1603 0.1592 0.1410 0.1289 0.1253 0.1245 0.1239 0.1237 0.1235 0.1236 0.1236 0.1238 0.1238 0.1238 0.1240 0.1242 

[TRAIN] Epoch[2](429/1500); Loss: 0.076532; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1286 0.1060 0.0843 0.0754 0.0731 0.0720 0.0700 0.0689 0.0682 0.0683 0.0676 0.0684 0.0683 0.0684 0.0681 0.0689 

[TRAIN] Epoch[2](430/1500); Loss: 0.097451; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1403 0.1312 0.1098 0.0964 0.0946 0.0930 0.0916 0.0904 0.0899 0.0896 0.0895 0.0889 0.0887 0.0886 0.0884 0.0885 

[TRAIN] Epoch[2](431/1500); Loss: 0.116020; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1504 0.1332 0.1167 0.1142 0.1127 0.1121 0.1117 0.1115 0.1115 0.1113 0.1113 0.1114 0.1115 0.1120 0.1121 0.1126 

[TRAIN] Epoch[2](432/1500); Loss: 0.149960; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2430 0.2044 0.1716 0.1621 0.1422 0.1370 0.1355 0.1350 0.1345 0.1337 0.1338 0.1337 0.1334 0.1333 0.1332 0.1331 

[TRAIN] Epoch[2](433/1500); Loss: 0.192962; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.3015 0.2488 0.1968 0.1895 0.1762 0.1792 0.1813 0.1813 0.1809 0.1796 0.1794 0.1791 0.1787 0.1788 0.1782 0.1780 

[TRAIN] Epoch[2](434/1500); Loss: 0.134319; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1665 0.1578 0.1422 0.1375 0.1325 0.1310 0.1300 0.1292 0.1286 0.1284 0.1281 0.1278 0.1276 0.1274 0.1274 0.1272 

[TRAIN] Epoch[2](435/1500); Loss: 0.142747; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2172 0.1858 0.1586 0.1475 0.1346 0.1326 0.1324 0.1319 0.1315 0.1310 0.1304 0.1304 0.1303 0.1302 0.1299 0.1296 

[TRAIN] Epoch[2](436/1500); Loss: 0.069896; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0904 0.0858 0.0697 0.0683 0.0658 0.0650 0.0647 0.0648 0.0653 0.0656 0.0664 0.0671 0.0681 0.0691 0.0704 0.0716 

[TRAIN] Epoch[2](437/1500); Loss: 0.075834; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1220 0.1053 0.0834 0.0769 0.0723 0.0704 0.0698 0.0691 0.0686 0.0683 0.0682 0.0679 0.0676 0.0678 0.0679 0.0679 

[TRAIN] Epoch[2](438/1500); Loss: 0.123547; Backpropagation: 0.0943 sec; Batch: 0.4285 sec
0.1377 0.1266 0.1342 0.1273 0.1230 0.1213 0.1206 0.1201 0.1202 0.1205 0.1205 0.1205 0.1207 0.1209 0.1210 0.1215 

[TRAIN] Epoch[2](439/1500); Loss: 0.096739; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1281 0.1138 0.1066 0.0974 0.0934 0.0918 0.0907 0.0904 0.0904 0.0907 0.0908 0.0914 0.0922 0.0928 0.0934 0.0940 

[TRAIN] Epoch[2](440/1500); Loss: 0.124671; Backpropagation: 0.0944 sec; Batch: 0.4303 sec
0.1658 0.1438 0.1393 0.1322 0.1245 0.1217 0.1194 0.1175 0.1167 0.1165 0.1163 0.1162 0.1161 0.1161 0.1163 0.1164 

[TRAIN] Epoch[2](441/1500); Loss: 0.119671; Backpropagation: 0.0937 sec; Batch: 0.4289 sec
0.1571 0.1597 0.1371 0.1218 0.1151 0.1134 0.1127 0.1118 0.1114 0.1111 0.1108 0.1107 0.1105 0.1104 0.1105 0.1106 

[TRAIN] Epoch[2](442/1500); Loss: 0.135426; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1770 0.1708 0.1490 0.1373 0.1310 0.1300 0.1290 0.1281 0.1277 0.1272 0.1270 0.1267 0.1265 0.1266 0.1265 0.1266 

[TRAIN] Epoch[2](443/1500); Loss: 0.089764; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1534 0.1413 0.1066 0.0984 0.0850 0.0799 0.0780 0.0776 0.0771 0.0771 0.0770 0.0767 0.0769 0.0769 0.0770 0.0773 

[TRAIN] Epoch[2](444/1500); Loss: 0.060595; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.0941 0.0759 0.0659 0.0620 0.0579 0.0560 0.0553 0.0550 0.0549 0.0550 0.0553 0.0555 0.0559 0.0564 0.0569 0.0575 

[TRAIN] Epoch[2](445/1500); Loss: 0.138560; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1558 0.1533 0.1471 0.1397 0.1372 0.1363 0.1358 0.1355 0.1352 0.1350 0.1348 0.1345 0.1344 0.1342 0.1340 0.1339 

[TRAIN] Epoch[2](446/1500); Loss: 0.047800; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1402 0.1324 0.0694 0.0429 0.0495 0.0322 0.0317 0.0301 0.0283 0.0284 0.0289 0.0291 0.0299 0.0301 0.0307 0.0311 

[TRAIN] Epoch[2](447/1500); Loss: 0.080205; Backpropagation: 0.0934 sec; Batch: 0.4450 sec
0.1614 0.1530 0.1072 0.0675 0.0758 0.0716 0.0713 0.0677 0.0647 0.0635 0.0633 0.0632 0.0632 0.0632 0.0632 0.0634 

[TRAIN] Epoch[2](448/1500); Loss: 0.067105; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.1817 0.0972 0.0711 0.0645 0.0620 0.0579 0.0557 0.0550 0.0545 0.0539 0.0535 0.0531 0.0530 0.0533 0.0535 0.0537 

[TRAIN] Epoch[2](449/1500); Loss: 0.121838; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1525 0.1364 0.1238 0.1239 0.1210 0.1194 0.1187 0.1181 0.1179 0.1175 0.1172 0.1168 0.1167 0.1165 0.1165 0.1166 

[TRAIN] Epoch[2](450/1500); Loss: 0.128210; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1555 0.1435 0.1305 0.1294 0.1272 0.1263 0.1255 0.1251 0.1246 0.1243 0.1239 0.1235 0.1231 0.1231 0.1230 0.1229 

[TRAIN] Epoch[2](451/1500); Loss: 0.085265; Backpropagation: 0.0940 sec; Batch: 0.4295 sec
0.1219 0.0984 0.0966 0.0897 0.0834 0.0806 0.0798 0.0794 0.0792 0.0791 0.0788 0.0792 0.0790 0.0793 0.0796 0.0803 

[TRAIN] Epoch[2](452/1500); Loss: 0.071208; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.0987 0.0780 0.0859 0.0745 0.0685 0.0675 0.0670 0.0664 0.0662 0.0662 0.0664 0.0665 0.0666 0.0667 0.0671 0.0672 

[TRAIN] Epoch[2](453/1500); Loss: 0.137013; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1580 0.1473 0.1423 0.1392 0.1362 0.1352 0.1343 0.1339 0.1336 0.1332 0.1330 0.1331 0.1332 0.1332 0.1331 0.1334 

[TRAIN] Epoch[2](454/1500); Loss: 0.125983; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1680 0.1542 0.1376 0.1314 0.1245 0.1219 0.1201 0.1187 0.1182 0.1178 0.1175 0.1174 0.1173 0.1170 0.1170 0.1170 

[TRAIN] Epoch[2](455/1500); Loss: 0.153187; Backpropagation: 0.0982 sec; Batch: 0.4340 sec
0.1680 0.1595 0.1574 0.1541 0.1524 0.1520 0.1515 0.1512 0.1510 0.1508 0.1507 0.1506 0.1504 0.1505 0.1505 0.1505 

[TRAIN] Epoch[2](456/1500); Loss: 0.111445; Backpropagation: 0.0982 sec; Batch: 0.4333 sec
0.1708 0.1638 0.1358 0.1119 0.1018 0.1003 0.1007 0.1001 0.0997 0.0992 0.0994 0.0995 0.0998 0.0998 0.1001 0.1005 

[TRAIN] Epoch[2](457/1500); Loss: 0.079115; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1236 0.1021 0.0841 0.0782 0.0735 0.0735 0.0720 0.0720 0.0722 0.0724 0.0726 0.0730 0.0735 0.0739 0.0743 0.0749 

[TRAIN] Epoch[2](458/1500); Loss: 0.078428; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1148 0.0942 0.0824 0.0769 0.0747 0.0743 0.0738 0.0736 0.0735 0.0736 0.0736 0.0737 0.0739 0.0739 0.0739 0.0741 

[TRAIN] Epoch[2](459/1500); Loss: 0.126520; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1551 0.1422 0.1340 0.1283 0.1263 0.1248 0.1235 0.1226 0.1220 0.1215 0.1210 0.1208 0.1205 0.1205 0.1205 0.1207 

[TRAIN] Epoch[2](460/1500); Loss: 0.090245; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1055 0.1078 0.0922 0.0923 0.0898 0.0881 0.0875 0.0870 0.0867 0.0866 0.0866 0.0866 0.0868 0.0869 0.0867 0.0868 

[TRAIN] Epoch[2](461/1500); Loss: 0.136583; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.1946 0.1627 0.1454 0.1373 0.1320 0.1316 0.1301 0.1292 0.1286 0.1284 0.1282 0.1277 0.1275 0.1273 0.1273 0.1274 

[TRAIN] Epoch[2](462/1500); Loss: 0.059727; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.0989 0.0929 0.0737 0.0610 0.0568 0.0538 0.0527 0.0518 0.0517 0.0516 0.0517 0.0514 0.0518 0.0520 0.0517 0.0520 

[TRAIN] Epoch[2](463/1500); Loss: 0.118257; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1299 0.1294 0.1249 0.1204 0.1177 0.1170 0.1165 0.1158 0.1154 0.1151 0.1150 0.1148 0.1149 0.1149 0.1150 0.1153 

[TRAIN] Epoch[2](464/1500); Loss: 0.034555; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.0938 0.0618 0.0485 0.0369 0.0303 0.0280 0.0263 0.0261 0.0251 0.0249 0.0250 0.0247 0.0250 0.0251 0.0253 0.0260 

[TRAIN] Epoch[2](465/1500); Loss: 0.100989; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1380 0.1237 0.1071 0.1031 0.0997 0.0979 0.0965 0.0956 0.0951 0.0946 0.0943 0.0943 0.0941 0.0940 0.0938 0.0939 

[TRAIN] Epoch[2](466/1500); Loss: 0.093994; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1228 0.1078 0.0932 0.0924 0.0911 0.0904 0.0903 0.0904 0.0904 0.0904 0.0905 0.0905 0.0906 0.0909 0.0910 0.0913 

[TRAIN] Epoch[2](467/1500); Loss: 0.058404; Backpropagation: 0.0983 sec; Batch: 0.4336 sec
0.1074 0.1037 0.0685 0.0598 0.0575 0.0523 0.0510 0.0501 0.0488 0.0482 0.0486 0.0476 0.0474 0.0481 0.0477 0.0476 

[TRAIN] Epoch[2](468/1500); Loss: 0.076077; Backpropagation: 0.0959 sec; Batch: 0.4307 sec
0.1470 0.1139 0.0841 0.0741 0.0685 0.0677 0.0664 0.0659 0.0658 0.0660 0.0659 0.0659 0.0662 0.0665 0.0666 0.0668 

[TRAIN] Epoch[2](469/1500); Loss: 0.114523; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1671 0.1454 0.1292 0.1175 0.1092 0.1071 0.1069 0.1061 0.1059 0.1057 0.1055 0.1052 0.1053 0.1052 0.1055 0.1055 

[TRAIN] Epoch[2](470/1500); Loss: 0.080985; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1124 0.1062 0.0890 0.0858 0.0807 0.0781 0.0765 0.0753 0.0746 0.0742 0.0738 0.0736 0.0737 0.0739 0.0739 0.0741 

[TRAIN] Epoch[2](471/1500); Loss: 0.039144; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.0892 0.0911 0.0496 0.0397 0.0375 0.0303 0.0297 0.0291 0.0285 0.0280 0.0290 0.0285 0.0282 0.0295 0.0293 0.0292 

[TRAIN] Epoch[2](472/1500); Loss: 0.053028; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.0716 0.0766 0.0578 0.0564 0.0537 0.0512 0.0498 0.0493 0.0488 0.0481 0.0479 0.0476 0.0474 0.0474 0.0475 0.0473 

[TRAIN] Epoch[2](473/1500); Loss: 0.081857; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1107 0.0910 0.0951 0.0863 0.0801 0.0778 0.0767 0.0765 0.0766 0.0763 0.0767 0.0769 0.0770 0.0773 0.0775 0.0773 

[TRAIN] Epoch[2](474/1500); Loss: 0.074610; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1311 0.0996 0.0807 0.0768 0.0717 0.0696 0.0682 0.0676 0.0669 0.0667 0.0661 0.0659 0.0658 0.0657 0.0657 0.0656 

[TRAIN] Epoch[2](475/1500); Loss: 0.156588; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1917 0.1686 0.1557 0.1542 0.1534 0.1532 0.1532 0.1531 0.1529 0.1526 0.1525 0.1525 0.1526 0.1529 0.1530 0.1532 

[TRAIN] Epoch[2](476/1500); Loss: 0.115010; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1664 0.1337 0.1212 0.1142 0.1119 0.1112 0.1098 0.1086 0.1081 0.1080 0.1077 0.1075 0.1078 0.1078 0.1079 0.1084 

[TRAIN] Epoch[2](477/1500); Loss: 0.141082; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1974 0.1744 0.1622 0.1558 0.1457 0.1408 0.1357 0.1304 0.1283 0.1276 0.1271 0.1268 0.1266 0.1264 0.1262 0.1261 

[TRAIN] Epoch[2](478/1500); Loss: 0.134090; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.3477 0.2801 0.2220 0.1978 0.1415 0.1121 0.0877 0.0859 0.0864 0.0846 0.0834 0.0830 0.0833 0.0832 0.0832 0.0836 

[TRAIN] Epoch[2](479/1500); Loss: 0.095337; Backpropagation: 0.0943 sec; Batch: 0.4289 sec
0.1454 0.1089 0.1097 0.0954 0.0921 0.0916 0.0902 0.0897 0.0889 0.0882 0.0879 0.0878 0.0876 0.0876 0.0874 0.0872 

[TRAIN] Epoch[2](480/1500); Loss: 0.090588; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1340 0.1051 0.1026 0.0919 0.0870 0.0865 0.0857 0.0856 0.0850 0.0843 0.0842 0.0837 0.0835 0.0830 0.0837 0.0837 

[TRAIN] Epoch[2](481/1500); Loss: 0.132617; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1869 0.1563 0.1480 0.1434 0.1352 0.1320 0.1290 0.1256 0.1233 0.1210 0.1202 0.1202 0.1199 0.1199 0.1203 0.1206 

[TRAIN] Epoch[2](482/1500); Loss: 0.071113; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2272 0.1823 0.1307 0.1101 0.0668 0.0488 0.0385 0.0387 0.0378 0.0366 0.0364 0.0365 0.0365 0.0366 0.0370 0.0374 

[TRAIN] Epoch[2](483/1500); Loss: 0.135806; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2252 0.1774 0.1619 0.1481 0.1341 0.1288 0.1258 0.1237 0.1221 0.1206 0.1195 0.1185 0.1176 0.1172 0.1164 0.1162 

[TRAIN] Epoch[2](484/1500); Loss: 0.133283; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2031 0.1506 0.1417 0.1345 0.1298 0.1278 0.1260 0.1253 0.1248 0.1246 0.1244 0.1240 0.1239 0.1240 0.1239 0.1240 

[TRAIN] Epoch[2](485/1500); Loss: 0.108155; Backpropagation: 0.0942 sec; Batch: 0.4301 sec
0.3630 0.2174 0.1408 0.0881 0.0781 0.0798 0.0788 0.0769 0.0756 0.0749 0.0751 0.0749 0.0750 0.0772 0.0775 0.0776 

[TRAIN] Epoch[2](486/1500); Loss: 0.092781; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2581 0.2078 0.1483 0.0964 0.0719 0.0699 0.0674 0.0630 0.0639 0.0633 0.0613 0.0627 0.0625 0.0619 0.0632 0.0628 

[TRAIN] Epoch[2](487/1500); Loss: 0.048037; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.0655 0.0629 0.0512 0.0513 0.0468 0.0440 0.0434 0.0435 0.0438 0.0442 0.0446 0.0447 0.0450 0.0454 0.0459 0.0465 

[TRAIN] Epoch[2](488/1500); Loss: 0.082439; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1221 0.1036 0.0839 0.0927 0.0940 0.0861 0.0801 0.0762 0.0747 0.0733 0.0727 0.0719 0.0719 0.0721 0.0719 0.0718 

[TRAIN] Epoch[2](489/1500); Loss: 0.078192; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.0982 0.0926 0.0844 0.0823 0.0786 0.0759 0.0755 0.0742 0.0733 0.0735 0.0732 0.0733 0.0737 0.0739 0.0740 0.0744 

[TRAIN] Epoch[2](490/1500); Loss: 0.093678; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2256 0.2096 0.1367 0.0780 0.0785 0.0801 0.0754 0.0729 0.0707 0.0682 0.0676 0.0671 0.0666 0.0673 0.0673 0.0672 

[TRAIN] Epoch[2](491/1500); Loss: 0.120745; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.2017 0.1869 0.1429 0.1275 0.1143 0.1117 0.1080 0.1054 0.1047 0.1043 0.1040 0.1038 0.1039 0.1041 0.1042 0.1045 

[TRAIN] Epoch[2](492/1500); Loss: 0.097251; Backpropagation: 0.0947 sec; Batch: 0.4297 sec
0.1055 0.0984 0.1067 0.1048 0.0990 0.0963 0.0952 0.0946 0.0948 0.0947 0.0944 0.0944 0.0943 0.0941 0.0943 0.0946 

[TRAIN] Epoch[2](493/1500); Loss: 0.053690; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1413 0.1114 0.0664 0.0550 0.0492 0.0479 0.0421 0.0389 0.0380 0.0378 0.0380 0.0382 0.0385 0.0386 0.0388 0.0391 

[TRAIN] Epoch[2](494/1500); Loss: 0.102493; Backpropagation: 0.0940 sec; Batch: 0.4276 sec
0.1454 0.1382 0.1201 0.1082 0.0984 0.0971 0.0960 0.0943 0.0934 0.0929 0.0928 0.0926 0.0925 0.0924 0.0926 0.0929 

[TRAIN] Epoch[2](495/1500); Loss: 0.048672; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.0961 0.0734 0.0561 0.0515 0.0487 0.0448 0.0417 0.0406 0.0406 0.0403 0.0404 0.0405 0.0407 0.0408 0.0412 0.0414 

[TRAIN] Epoch[2](496/1500); Loss: 0.164193; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1904 0.1819 0.1715 0.1651 0.1651 0.1625 0.1605 0.1600 0.1593 0.1591 0.1589 0.1590 0.1587 0.1585 0.1583 0.1584 

[TRAIN] Epoch[2](497/1500); Loss: 0.061515; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.0858 0.0772 0.0795 0.0806 0.0667 0.0580 0.0545 0.0531 0.0526 0.0527 0.0529 0.0530 0.0536 0.0540 0.0545 0.0554 

[TRAIN] Epoch[2](498/1500); Loss: 0.061111; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.0926 0.0863 0.0669 0.0611 0.0581 0.0572 0.0553 0.0546 0.0547 0.0545 0.0548 0.0556 0.0557 0.0563 0.0568 0.0573 

[TRAIN] Epoch[2](499/1500); Loss: 0.075597; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1423 0.1067 0.0718 0.0761 0.0792 0.0721 0.0678 0.0665 0.0661 0.0658 0.0656 0.0657 0.0657 0.0658 0.0661 0.0663 

[TRAIN] Epoch[2](500/1500); Loss: 0.097146; Backpropagation: 0.0932 sec; Batch: 0.4337 sec
0.1176 0.1107 0.0999 0.1093 0.1086 0.1025 0.0970 0.0936 0.0913 0.0898 0.0892 0.0889 0.0890 0.0889 0.0890 0.0891 

[TRAIN] Epoch[2](501/1500); Loss: 0.067071; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1076 0.1040 0.0795 0.0684 0.0640 0.0615 0.0602 0.0592 0.0590 0.0587 0.0584 0.0584 0.0585 0.0584 0.0585 0.0587 

[TRAIN] Epoch[2](502/1500); Loss: 0.141174; Backpropagation: 0.1000 sec; Batch: 0.4412 sec
0.1971 0.1875 0.1572 0.1490 0.1381 0.1347 0.1312 0.1302 0.1298 0.1295 0.1294 0.1293 0.1291 0.1289 0.1288 0.1288 

[TRAIN] Epoch[2](503/1500); Loss: 0.099592; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.1188 0.1129 0.1054 0.1004 0.0977 0.0969 0.0966 0.0963 0.0959 0.0959 0.0961 0.0960 0.0959 0.0960 0.0962 0.0963 

[TRAIN] Epoch[2](504/1500); Loss: 0.076222; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1069 0.0915 0.0825 0.0776 0.0741 0.0730 0.0724 0.0720 0.0715 0.0714 0.0714 0.0711 0.0710 0.0710 0.0711 0.0712 

[TRAIN] Epoch[2](505/1500); Loss: 0.162887; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1882 0.1784 0.1667 0.1647 0.1658 0.1645 0.1625 0.1606 0.1593 0.1583 0.1575 0.1567 0.1562 0.1558 0.1556 0.1552 

[TRAIN] Epoch[2](506/1500); Loss: 0.115229; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.2804 0.2428 0.1924 0.1685 0.1208 0.1045 0.0821 0.0702 0.0735 0.0730 0.0726 0.0723 0.0723 0.0729 0.0726 0.0727 

[TRAIN] Epoch[2](507/1500); Loss: 0.079236; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1276 0.1151 0.0886 0.0748 0.0738 0.0725 0.0714 0.0706 0.0705 0.0706 0.0708 0.0712 0.0716 0.0723 0.0729 0.0737 

[TRAIN] Epoch[2](508/1500); Loss: 0.125511; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1564 0.1460 0.1307 0.1275 0.1249 0.1227 0.1217 0.1211 0.1206 0.1201 0.1197 0.1197 0.1195 0.1193 0.1190 0.1191 

[TRAIN] Epoch[2](509/1500); Loss: 0.103164; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1276 0.1227 0.1052 0.1029 0.1028 0.1017 0.1003 0.0995 0.0992 0.0990 0.0987 0.0984 0.0982 0.0983 0.0981 0.0981 

[TRAIN] Epoch[2](510/1500); Loss: 0.080328; Backpropagation: 0.0944 sec; Batch: 0.4298 sec
0.1304 0.1096 0.0881 0.0813 0.0752 0.0750 0.0743 0.0740 0.0733 0.0723 0.0722 0.0720 0.0718 0.0716 0.0718 0.0723 

[TRAIN] Epoch[2](511/1500); Loss: 0.120432; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1525 0.1475 0.1323 0.1216 0.1199 0.1191 0.1170 0.1154 0.1144 0.1137 0.1130 0.1125 0.1122 0.1120 0.1120 0.1119 

[TRAIN] Epoch[2](512/1500); Loss: 0.097162; Backpropagation: 0.0933 sec; Batch: 0.4364 sec
0.1506 0.1441 0.1287 0.1161 0.1011 0.0943 0.0866 0.0818 0.0805 0.0811 0.0812 0.0814 0.0817 0.0816 0.0816 0.0820 

[TRAIN] Epoch[2](513/1500); Loss: 0.119294; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1487 0.1458 0.1323 0.1226 0.1192 0.1174 0.1156 0.1144 0.1136 0.1127 0.1122 0.1117 0.1113 0.1108 0.1103 0.1102 

[TRAIN] Epoch[2](514/1500); Loss: 0.140600; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2269 0.2002 0.1759 0.1644 0.1439 0.1354 0.1261 0.1220 0.1212 0.1202 0.1198 0.1193 0.1191 0.1187 0.1183 0.1182 

[TRAIN] Epoch[2](515/1500); Loss: 0.072313; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1256 0.1032 0.0798 0.0760 0.0721 0.0684 0.0659 0.0647 0.0640 0.0633 0.0628 0.0625 0.0623 0.0621 0.0621 0.0623 

[TRAIN] Epoch[2](516/1500); Loss: 0.085443; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1330 0.1103 0.0836 0.0852 0.0867 0.0826 0.0799 0.0792 0.0790 0.0786 0.0784 0.0782 0.0782 0.0781 0.0780 0.0781 

[TRAIN] Epoch[2](517/1500); Loss: 0.146089; Backpropagation: 0.0941 sec; Batch: 0.4278 sec
0.1722 0.1668 0.1553 0.1481 0.1443 0.1427 0.1421 0.1415 0.1412 0.1410 0.1408 0.1406 0.1404 0.1403 0.1401 0.1400 

[TRAIN] Epoch[2](518/1500); Loss: 0.063104; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1252 0.0923 0.0690 0.0658 0.0654 0.0591 0.0558 0.0546 0.0537 0.0534 0.0526 0.0522 0.0525 0.0525 0.0524 0.0531 

[TRAIN] Epoch[2](519/1500); Loss: 0.099862; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1321 0.1245 0.1045 0.1010 0.0992 0.0974 0.0953 0.0938 0.0934 0.0932 0.0932 0.0934 0.0935 0.0943 0.0943 0.0946 

[TRAIN] Epoch[2](520/1500); Loss: 0.072768; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1146 0.0960 0.0866 0.0803 0.0723 0.0685 0.0663 0.0655 0.0648 0.0642 0.0640 0.0638 0.0639 0.0642 0.0645 0.0648 

[TRAIN] Epoch[2](521/1500); Loss: 0.105459; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1769 0.1589 0.1194 0.1121 0.0994 0.0964 0.0940 0.0930 0.0920 0.0920 0.0921 0.0921 0.0922 0.0920 0.0921 0.0926 

[TRAIN] Epoch[2](522/1500); Loss: 0.104442; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1501 0.1348 0.1138 0.1052 0.0993 0.0984 0.0979 0.0972 0.0971 0.0966 0.0965 0.0966 0.0968 0.0967 0.0969 0.0972 

[TRAIN] Epoch[2](523/1500); Loss: 0.143664; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1735 0.1648 0.1538 0.1479 0.1443 0.1394 0.1386 0.1378 0.1371 0.1369 0.1367 0.1370 0.1372 0.1376 0.1380 0.1383 

[TRAIN] Epoch[2](524/1500); Loss: 0.049867; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.0839 0.0715 0.0640 0.0586 0.0499 0.0462 0.0446 0.0432 0.0421 0.0421 0.0416 0.0416 0.0420 0.0422 0.0419 0.0422 

[TRAIN] Epoch[2](525/1500); Loss: 0.119688; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2305 0.2016 0.1537 0.1400 0.1105 0.1038 0.0998 0.0992 0.0978 0.0969 0.0966 0.0964 0.0965 0.0968 0.0972 0.0975 

[TRAIN] Epoch[2](526/1500); Loss: 0.042990; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.0784 0.0722 0.0482 0.0541 0.0472 0.0392 0.0365 0.0350 0.0340 0.0341 0.0340 0.0340 0.0344 0.0349 0.0356 0.0361 

[TRAIN] Epoch[2](527/1500); Loss: 0.116924; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.4089 0.3418 0.2345 0.1991 0.1002 0.0693 0.0560 0.0580 0.0503 0.0495 0.0503 0.0500 0.0500 0.0503 0.0509 0.0517 

[TRAIN] Epoch[2](528/1500); Loss: 0.054067; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1086 0.0907 0.0564 0.0556 0.0495 0.0472 0.0466 0.0457 0.0457 0.0454 0.0453 0.0457 0.0454 0.0455 0.0457 0.0461 

[TRAIN] Epoch[2](529/1500); Loss: 0.091811; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1255 0.1099 0.0969 0.0908 0.0895 0.0884 0.0875 0.0869 0.0868 0.0863 0.0862 0.0864 0.0866 0.0868 0.0871 0.0873 

[TRAIN] Epoch[2](530/1500); Loss: 0.158459; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.2023 0.1844 0.1681 0.1640 0.1546 0.1524 0.1518 0.1517 0.1516 0.1511 0.1511 0.1507 0.1505 0.1505 0.1503 0.1503 

[TRAIN] Epoch[2](531/1500); Loss: 0.079621; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1620 0.1501 0.1079 0.0705 0.0643 0.0636 0.0646 0.0642 0.0638 0.0642 0.0648 0.0656 0.0659 0.0668 0.0673 0.0685 

[TRAIN] Epoch[2](532/1500); Loss: 0.114107; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1970 0.1580 0.1249 0.1182 0.1100 0.1078 0.1043 0.1024 0.1012 0.1005 0.0999 0.0997 0.0998 0.1004 0.1007 0.1008 

[TRAIN] Epoch[2](533/1500); Loss: 0.134394; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1784 0.1569 0.1378 0.1390 0.1356 0.1330 0.1308 0.1295 0.1283 0.1274 0.1267 0.1261 0.1256 0.1254 0.1250 0.1248 

[TRAIN] Epoch[2](534/1500); Loss: 0.139197; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1983 0.1775 0.1574 0.1508 0.1341 0.1309 0.1301 0.1297 0.1288 0.1283 0.1278 0.1275 0.1267 0.1265 0.1266 0.1262 

[TRAIN] Epoch[2](535/1500); Loss: 0.060832; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1609 0.1281 0.0598 0.0877 0.0735 0.0429 0.0400 0.0397 0.0404 0.0410 0.0414 0.0426 0.0430 0.0431 0.0443 0.0449 

[TRAIN] Epoch[2](536/1500); Loss: 0.127743; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1838 0.1508 0.1309 0.1253 0.1244 0.1245 0.1229 0.1216 0.1209 0.1204 0.1201 0.1199 0.1197 0.1196 0.1196 0.1197 

[TRAIN] Epoch[2](537/1500); Loss: 0.063267; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1189 0.0956 0.0665 0.0673 0.0614 0.0570 0.0556 0.0551 0.0546 0.0547 0.0543 0.0541 0.0542 0.0542 0.0542 0.0547 

[TRAIN] Epoch[2](538/1500); Loss: 0.109132; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2060 0.1808 0.1422 0.1332 0.1093 0.1007 0.0925 0.0878 0.0885 0.0875 0.0867 0.0865 0.0863 0.0862 0.0860 0.0861 

[TRAIN] Epoch[2](539/1500); Loss: 0.147256; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2500 0.2173 0.1815 0.1692 0.1463 0.1387 0.1309 0.1261 0.1270 0.1252 0.1251 0.1241 0.1239 0.1237 0.1235 0.1235 

[TRAIN] Epoch[2](540/1500); Loss: 0.125625; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1715 0.1449 0.1303 0.1286 0.1252 0.1228 0.1216 0.1208 0.1202 0.1194 0.1187 0.1182 0.1175 0.1170 0.1167 0.1164 

[TRAIN] Epoch[2](541/1500); Loss: 0.135057; Backpropagation: 0.0938 sec; Batch: 0.4293 sec
0.2108 0.1730 0.1489 0.1385 0.1316 0.1288 0.1261 0.1238 0.1228 0.1223 0.1223 0.1222 0.1222 0.1223 0.1225 0.1229 

[TRAIN] Epoch[2](542/1500); Loss: 0.130274; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1940 0.1583 0.1356 0.1298 0.1250 0.1239 0.1231 0.1222 0.1217 0.1216 0.1213 0.1213 0.1213 0.1213 0.1216 0.1222 

[TRAIN] Epoch[2](543/1500); Loss: 0.098116; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1240 0.1069 0.1008 0.0977 0.0975 0.0967 0.0962 0.0954 0.0949 0.0945 0.0943 0.0940 0.0942 0.0944 0.0943 0.0943 

[TRAIN] Epoch[2](544/1500); Loss: 0.116349; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1420 0.1260 0.1244 0.1215 0.1158 0.1134 0.1128 0.1123 0.1118 0.1117 0.1118 0.1116 0.1115 0.1115 0.1117 0.1118 

[TRAIN] Epoch[2](545/1500); Loss: 0.040993; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.0990 0.0681 0.0418 0.0559 0.0481 0.0359 0.0301 0.0304 0.0304 0.0296 0.0300 0.0305 0.0308 0.0312 0.0315 0.0327 

[TRAIN] Epoch[2](546/1500); Loss: 0.112002; Backpropagation: 0.0933 sec; Batch: 0.4285 sec
0.1569 0.1386 0.1186 0.1120 0.1081 0.1060 0.1053 0.1050 0.1049 0.1050 0.1050 0.1049 0.1051 0.1053 0.1054 0.1058 

[TRAIN] Epoch[2](547/1500); Loss: 0.040286; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1207 0.0847 0.0324 0.0483 0.0461 0.0327 0.0275 0.0264 0.0262 0.0266 0.0268 0.0276 0.0284 0.0288 0.0299 0.0312 

[TRAIN] Epoch[2](548/1500); Loss: 0.077068; Backpropagation: 0.0944 sec; Batch: 0.4310 sec
0.1105 0.0887 0.0886 0.0823 0.0768 0.0744 0.0731 0.0722 0.0714 0.0710 0.0709 0.0706 0.0704 0.0706 0.0707 0.0710 

[TRAIN] Epoch[2](549/1500); Loss: 0.101881; Backpropagation: 0.0938 sec; Batch: 0.4660 sec
0.1406 0.1163 0.1065 0.1012 0.0984 0.0973 0.0968 0.0969 0.0970 0.0971 0.0970 0.0972 0.0969 0.0967 0.0971 0.0971 

[TRAIN] Epoch[2](550/1500); Loss: 0.066757; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.1102 0.0914 0.0773 0.0681 0.0628 0.0613 0.0610 0.0599 0.0593 0.0599 0.0590 0.0593 0.0596 0.0595 0.0596 0.0600 

[TRAIN] Epoch[2](551/1500); Loss: 0.130278; Backpropagation: 0.0942 sec; Batch: 0.4306 sec
0.1664 0.1460 0.1351 0.1311 0.1276 0.1266 0.1257 0.1253 0.1247 0.1250 0.1249 0.1250 0.1251 0.1254 0.1253 0.1254 

[TRAIN] Epoch[2](552/1500); Loss: 0.060598; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1182 0.0981 0.0645 0.0602 0.0555 0.0535 0.0529 0.0526 0.0520 0.0517 0.0517 0.0519 0.0517 0.0515 0.0519 0.0518 

[TRAIN] Epoch[2](553/1500); Loss: 0.099719; Backpropagation: 0.0949 sec; Batch: 0.4295 sec
0.1483 0.1261 0.1031 0.1018 0.0964 0.0942 0.0926 0.0924 0.0922 0.0927 0.0921 0.0923 0.0926 0.0929 0.0928 0.0930 

[TRAIN] Epoch[2](554/1500); Loss: 0.118870; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1560 0.1406 0.1310 0.1251 0.1166 0.1144 0.1128 0.1121 0.1120 0.1118 0.1117 0.1117 0.1118 0.1114 0.1113 0.1116 

[TRAIN] Epoch[2](555/1500); Loss: 0.103375; Backpropagation: 0.0940 sec; Batch: 0.4376 sec
0.1366 0.1251 0.1110 0.1056 0.1015 0.1003 0.0992 0.0985 0.0978 0.0972 0.0971 0.0968 0.0968 0.0970 0.0967 0.0969 

[TRAIN] Epoch[2](556/1500); Loss: 0.098556; Backpropagation: 0.0933 sec; Batch: 0.4658 sec
0.1581 0.1193 0.1115 0.1135 0.1094 0.1031 0.0973 0.0936 0.0909 0.0886 0.0863 0.0845 0.0823 0.0807 0.0793 0.0786 

[TRAIN] Epoch[2](557/1500); Loss: 0.038093; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.0794 0.0554 0.0545 0.0431 0.0346 0.0330 0.0320 0.0313 0.0309 0.0308 0.0307 0.0306 0.0305 0.0308 0.0309 0.0309 

[TRAIN] Epoch[2](558/1500); Loss: 0.107072; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1512 0.1345 0.1147 0.1096 0.1039 0.1023 0.1010 0.1004 0.0999 0.0996 0.0995 0.0995 0.0995 0.0992 0.0991 0.0990 

[TRAIN] Epoch[2](559/1500); Loss: 0.079492; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1025 0.0999 0.0817 0.0817 0.0785 0.0764 0.0750 0.0751 0.0750 0.0750 0.0748 0.0748 0.0749 0.0751 0.0756 0.0758 

[TRAIN] Epoch[2](560/1500); Loss: 0.070021; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1098 0.0863 0.0766 0.0712 0.0664 0.0655 0.0653 0.0648 0.0644 0.0643 0.0641 0.0641 0.0645 0.0643 0.0643 0.0645 

[TRAIN] Epoch[2](561/1500); Loss: 0.055991; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.0892 0.0691 0.0652 0.0583 0.0540 0.0517 0.0507 0.0509 0.0504 0.0507 0.0507 0.0508 0.0507 0.0513 0.0512 0.0511 

[TRAIN] Epoch[2](562/1500); Loss: 0.067762; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.0947 0.0868 0.0724 0.0708 0.0666 0.0640 0.0629 0.0629 0.0627 0.0628 0.0626 0.0625 0.0629 0.0631 0.0631 0.0634 

[TRAIN] Epoch[2](563/1500); Loss: 0.185663; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.3037 0.2787 0.2251 0.2085 0.1766 0.1688 0.1619 0.1617 0.1613 0.1613 0.1609 0.1608 0.1605 0.1605 0.1602 0.1603 

[TRAIN] Epoch[2](564/1500); Loss: 0.130905; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2166 0.1847 0.1519 0.1383 0.1255 0.1215 0.1179 0.1160 0.1159 0.1157 0.1152 0.1146 0.1152 0.1152 0.1152 0.1154 

[TRAIN] Epoch[2](565/1500); Loss: 0.085678; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1524 0.1234 0.0926 0.0833 0.0797 0.0788 0.0781 0.0774 0.0766 0.0763 0.0760 0.0754 0.0753 0.0753 0.0752 0.0751 

[TRAIN] Epoch[2](566/1500); Loss: 0.090987; Backpropagation: 0.0933 sec; Batch: 0.4285 sec
0.1377 0.1304 0.1050 0.0946 0.0888 0.0854 0.0834 0.0826 0.0816 0.0806 0.0803 0.0805 0.0808 0.0809 0.0814 0.0820 

[TRAIN] Epoch[2](567/1500); Loss: 0.057631; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.0666 0.0631 0.0606 0.0608 0.0583 0.0567 0.0554 0.0553 0.0555 0.0556 0.0554 0.0557 0.0556 0.0556 0.0560 0.0560 

[TRAIN] Epoch[2](568/1500); Loss: 0.148930; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1756 0.1573 0.1491 0.1508 0.1481 0.1463 0.1455 0.1452 0.1454 0.1456 0.1456 0.1456 0.1459 0.1458 0.1456 0.1455 

[TRAIN] Epoch[2](569/1500); Loss: 0.159018; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1977 0.1900 0.1708 0.1626 0.1578 0.1554 0.1533 0.1524 0.1517 0.1511 0.1506 0.1504 0.1503 0.1500 0.1500 0.1501 

[TRAIN] Epoch[2](570/1500); Loss: 0.064747; Backpropagation: 0.0941 sec; Batch: 0.4293 sec
0.1068 0.0998 0.0779 0.0684 0.0647 0.0615 0.0597 0.0582 0.0573 0.0563 0.0552 0.0546 0.0541 0.0539 0.0539 0.0537 

[TRAIN] Epoch[2](571/1500); Loss: 0.115603; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1222 0.1183 0.1134 0.1161 0.1142 0.1131 0.1134 0.1134 0.1135 0.1140 0.1149 0.1153 0.1158 0.1164 0.1173 0.1183 

[TRAIN] Epoch[2](572/1500); Loss: 0.064417; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0986 0.0928 0.0726 0.0647 0.0614 0.0600 0.0591 0.0583 0.0580 0.0575 0.0575 0.0575 0.0579 0.0579 0.0582 0.0586 

[TRAIN] Epoch[2](573/1500); Loss: 0.067372; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1043 0.0964 0.0753 0.0691 0.0669 0.0640 0.0622 0.0619 0.0609 0.0604 0.0600 0.0596 0.0592 0.0592 0.0593 0.0593 

[TRAIN] Epoch[2](574/1500); Loss: 0.074574; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1315 0.0982 0.0811 0.0741 0.0701 0.0675 0.0652 0.0647 0.0641 0.0642 0.0648 0.0661 0.0674 0.0690 0.0713 0.0738 

[TRAIN] Epoch[2](575/1500); Loss: 0.094185; Backpropagation: 0.0938 sec; Batch: 0.4370 sec
0.1605 0.1454 0.1066 0.1098 0.0992 0.0893 0.0845 0.0803 0.0797 0.0791 0.0791 0.0787 0.0789 0.0785 0.0788 0.0787 

[TRAIN] Epoch[2](576/1500); Loss: 0.107229; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2153 0.1759 0.1314 0.1166 0.0981 0.0941 0.0912 0.0892 0.0888 0.0887 0.0885 0.0878 0.0877 0.0876 0.0874 0.0874 

[TRAIN] Epoch[2](577/1500); Loss: 0.068323; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1125 0.0984 0.0735 0.0703 0.0630 0.0617 0.0610 0.0603 0.0602 0.0607 0.0608 0.0611 0.0619 0.0620 0.0626 0.0632 

[TRAIN] Epoch[2](578/1500); Loss: 0.107540; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1423 0.1328 0.1166 0.1107 0.1064 0.1050 0.1035 0.1021 0.1014 0.1008 0.1004 0.1001 0.1000 0.0996 0.0995 0.0995 

[TRAIN] Epoch[2](579/1500); Loss: 0.095507; Backpropagation: 0.0939 sec; Batch: 0.4300 sec
0.1238 0.1301 0.1064 0.0957 0.0931 0.0900 0.0890 0.0885 0.0880 0.0880 0.0883 0.0887 0.0891 0.0894 0.0896 0.0904 

[TRAIN] Epoch[2](580/1500); Loss: 0.154885; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2354 0.1937 0.1644 0.1541 0.1503 0.1476 0.1457 0.1448 0.1440 0.1436 0.1430 0.1427 0.1425 0.1422 0.1420 0.1420 

[TRAIN] Epoch[2](581/1500); Loss: 0.119534; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.3504 0.2897 0.2064 0.1778 0.1125 0.0929 0.0694 0.0715 0.0703 0.0667 0.0657 0.0682 0.0677 0.0675 0.0675 0.0683 

[TRAIN] Epoch[2](582/1500); Loss: 0.071240; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1031 0.0933 0.0765 0.0702 0.0681 0.0674 0.0665 0.0658 0.0654 0.0653 0.0651 0.0654 0.0658 0.0665 0.0672 0.0682 

[TRAIN] Epoch[2](583/1500); Loss: 0.063075; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.0954 0.0773 0.0643 0.0685 0.0657 0.0617 0.0592 0.0582 0.0575 0.0572 0.0573 0.0570 0.0572 0.0573 0.0576 0.0577 

[TRAIN] Epoch[2](584/1500); Loss: 0.044340; Backpropagation: 0.0931 sec; Batch: 0.4279 sec
0.0809 0.0698 0.0566 0.0466 0.0420 0.0405 0.0389 0.0385 0.0380 0.0373 0.0371 0.0367 0.0366 0.0366 0.0366 0.0367 

[TRAIN] Epoch[2](585/1500); Loss: 0.123304; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1646 0.1529 0.1356 0.1238 0.1217 0.1190 0.1172 0.1164 0.1159 0.1154 0.1152 0.1152 0.1151 0.1149 0.1149 0.1150 

[TRAIN] Epoch[2](586/1500); Loss: 0.176962; Backpropagation: 0.0966 sec; Batch: 0.4319 sec
0.1991 0.2052 0.1844 0.1765 0.1754 0.1752 0.1745 0.1732 0.1724 0.1717 0.1712 0.1709 0.1708 0.1707 0.1701 0.1699 

[TRAIN] Epoch[2](587/1500); Loss: 0.036971; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.0938 0.0499 0.0647 0.0432 0.0314 0.0279 0.0291 0.0281 0.0271 0.0272 0.0272 0.0278 0.0279 0.0284 0.0287 0.0290 

[TRAIN] Epoch[2](588/1500); Loss: 0.099831; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1223 0.1065 0.1038 0.1001 0.0993 0.0985 0.0974 0.0970 0.0965 0.0965 0.0965 0.0964 0.0963 0.0966 0.0967 0.0969 

[TRAIN] Epoch[2](589/1500); Loss: 0.105314; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1513 0.1376 0.1102 0.1104 0.1050 0.1008 0.0984 0.0973 0.0971 0.0968 0.0965 0.0966 0.0966 0.0967 0.0968 0.0970 

[TRAIN] Epoch[2](590/1500); Loss: 0.084746; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1037 0.1004 0.0865 0.0867 0.0846 0.0829 0.0820 0.0816 0.0811 0.0808 0.0808 0.0809 0.0808 0.0810 0.0810 0.0811 

[TRAIN] Epoch[2](591/1500); Loss: 0.092769; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1235 0.1175 0.0982 0.0961 0.0931 0.0888 0.0873 0.0868 0.0862 0.0861 0.0863 0.0862 0.0865 0.0868 0.0871 0.0877 

[TRAIN] Epoch[2](592/1500); Loss: 0.073661; Backpropagation: 0.0936 sec; Batch: 0.4289 sec
0.1458 0.1165 0.0872 0.0802 0.0709 0.0671 0.0634 0.0621 0.0614 0.0608 0.0608 0.0605 0.0604 0.0605 0.0604 0.0604 

[TRAIN] Epoch[2](593/1500); Loss: 0.121541; Backpropagation: 0.0942 sec; Batch: 0.4628 sec
0.1707 0.1588 0.1399 0.1253 0.1173 0.1152 0.1134 0.1120 0.1117 0.1116 0.1114 0.1114 0.1114 0.1115 0.1115 0.1115 

[TRAIN] Epoch[2](594/1500); Loss: 0.085314; Backpropagation: 0.0938 sec; Batch: 0.4658 sec
0.1103 0.0993 0.0896 0.0876 0.0829 0.0819 0.0810 0.0808 0.0808 0.0809 0.0813 0.0814 0.0814 0.0817 0.0819 0.0822 

[TRAIN] Epoch[2](595/1500); Loss: 0.090336; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1310 0.1188 0.1073 0.1008 0.0888 0.0853 0.0827 0.0817 0.0814 0.0810 0.0809 0.0809 0.0811 0.0811 0.0812 0.0814 

[TRAIN] Epoch[2](596/1500); Loss: 0.064212; Backpropagation: 0.0938 sec; Batch: 0.4297 sec
0.1198 0.1012 0.0714 0.0660 0.0628 0.0616 0.0566 0.0554 0.0547 0.0544 0.0541 0.0539 0.0539 0.0536 0.0540 0.0540 

[TRAIN] Epoch[2](597/1500); Loss: 0.075547; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1186 0.1011 0.0834 0.0812 0.0745 0.0723 0.0699 0.0686 0.0681 0.0676 0.0674 0.0673 0.0672 0.0671 0.0672 0.0674 

[TRAIN] Epoch[2](598/1500); Loss: 0.067145; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.1016 0.0843 0.0697 0.0692 0.0663 0.0644 0.0635 0.0629 0.0622 0.0618 0.0616 0.0614 0.0612 0.0613 0.0613 0.0614 

[TRAIN] Epoch[2](599/1500); Loss: 0.136989; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2112 0.1779 0.1513 0.1392 0.1351 0.1311 0.1281 0.1262 0.1254 0.1247 0.1245 0.1239 0.1236 0.1233 0.1232 0.1233 

[TRAIN] Epoch[2](600/1500); Loss: 0.072722; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.1020 0.0820 0.0781 0.0764 0.0715 0.0698 0.0686 0.0680 0.0677 0.0680 0.0678 0.0681 0.0683 0.0687 0.0690 0.0694 

[TRAIN] Epoch[2](601/1500); Loss: 0.098441; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2121 0.1669 0.1158 0.0949 0.0893 0.0865 0.0828 0.0814 0.0811 0.0810 0.0804 0.0806 0.0805 0.0805 0.0807 0.0808 

[TRAIN] Epoch[2](602/1500); Loss: 0.111701; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1551 0.1337 0.1187 0.1153 0.1104 0.1081 0.1060 0.1054 0.1049 0.1047 0.1044 0.1043 0.1040 0.1040 0.1040 0.1041 

[TRAIN] Epoch[2](603/1500); Loss: 0.121975; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1712 0.1488 0.1314 0.1243 0.1183 0.1172 0.1160 0.1152 0.1147 0.1142 0.1138 0.1138 0.1135 0.1133 0.1131 0.1128 

[TRAIN] Epoch[2](604/1500); Loss: 0.093301; Backpropagation: 0.0940 sec; Batch: 0.4309 sec
0.1354 0.1004 0.1063 0.0993 0.0918 0.0893 0.0895 0.0882 0.0874 0.0869 0.0867 0.0864 0.0861 0.0864 0.0863 0.0866 

[TRAIN] Epoch[2](605/1500); Loss: 0.083591; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1304 0.1290 0.1026 0.0850 0.0784 0.0763 0.0748 0.0737 0.0730 0.0729 0.0731 0.0733 0.0732 0.0735 0.0738 0.0744 

[TRAIN] Epoch[2](606/1500); Loss: 0.114434; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1430 0.1286 0.1235 0.1173 0.1133 0.1119 0.1105 0.1099 0.1094 0.1092 0.1092 0.1090 0.1091 0.1090 0.1090 0.1091 

[TRAIN] Epoch[2](607/1500); Loss: 0.044036; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.0821 0.0575 0.0593 0.0535 0.0447 0.0409 0.0388 0.0379 0.0372 0.0366 0.0363 0.0361 0.0359 0.0359 0.0359 0.0360 

[TRAIN] Epoch[2](608/1500); Loss: 0.085001; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1263 0.1191 0.1031 0.0896 0.0815 0.0793 0.0783 0.0775 0.0770 0.0764 0.0759 0.0756 0.0753 0.0751 0.0751 0.0750 

[TRAIN] Epoch[2](609/1500); Loss: 0.093520; Backpropagation: 0.0947 sec; Batch: 0.4288 sec
0.1716 0.1475 0.1301 0.1092 0.0912 0.0857 0.0807 0.0778 0.0768 0.0760 0.0755 0.0751 0.0748 0.0747 0.0747 0.0749 

[TRAIN] Epoch[2](610/1500); Loss: 0.112592; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1394 0.1290 0.1213 0.1179 0.1129 0.1108 0.1090 0.1080 0.1074 0.1069 0.1066 0.1066 0.1064 0.1064 0.1065 0.1065 

[TRAIN] Epoch[2](611/1500); Loss: 0.064963; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1328 0.1137 0.0796 0.0746 0.0724 0.0648 0.0571 0.0519 0.0498 0.0490 0.0485 0.0486 0.0488 0.0490 0.0493 0.0496 

[TRAIN] Epoch[2](612/1500); Loss: 0.075404; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1231 0.1060 0.0867 0.0796 0.0748 0.0711 0.0686 0.0673 0.0667 0.0664 0.0660 0.0660 0.0658 0.0660 0.0661 0.0662 

[TRAIN] Epoch[2](613/1500); Loss: 0.077140; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1936 0.1252 0.0724 0.0699 0.0698 0.0655 0.0633 0.0628 0.0626 0.0633 0.0635 0.0647 0.0639 0.0643 0.0650 0.0644 

[TRAIN] Epoch[2](614/1500); Loss: 0.106682; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1353 0.1201 0.1114 0.1097 0.1057 0.1034 0.1031 0.1028 0.1023 0.1021 0.1020 0.1017 0.1018 0.1018 0.1019 0.1018 

[TRAIN] Epoch[2](615/1500); Loss: 0.192729; Backpropagation: 0.0958 sec; Batch: 0.4304 sec
0.2477 0.2122 0.2045 0.2007 0.1942 0.1914 0.1895 0.1877 0.1860 0.1847 0.1833 0.1820 0.1810 0.1802 0.1795 0.1789 

[TRAIN] Epoch[2](616/1500); Loss: 0.080852; Backpropagation: 0.0956 sec; Batch: 0.4299 sec
0.1045 0.0972 0.0890 0.0849 0.0799 0.0785 0.0775 0.0769 0.0765 0.0762 0.0758 0.0754 0.0753 0.0753 0.0753 0.0755 

[TRAIN] Epoch[2](617/1500); Loss: 0.068531; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1321 0.1155 0.0540 0.0925 0.1053 0.0839 0.0657 0.0484 0.0496 0.0492 0.0477 0.0493 0.0502 0.0499 0.0513 0.0519 

[TRAIN] Epoch[2](618/1500); Loss: 0.125500; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1689 0.1496 0.1410 0.1326 0.1242 0.1212 0.1193 0.1179 0.1173 0.1170 0.1169 0.1165 0.1165 0.1164 0.1162 0.1164 

[TRAIN] Epoch[2](619/1500); Loss: 0.096627; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1473 0.1276 0.1130 0.1038 0.0965 0.0929 0.0907 0.0892 0.0878 0.0867 0.0858 0.0851 0.0846 0.0848 0.0850 0.0852 

[TRAIN] Epoch[2](620/1500); Loss: 0.045396; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1191 0.0998 0.0347 0.0742 0.0844 0.0606 0.0403 0.0219 0.0271 0.0259 0.0219 0.0225 0.0228 0.0234 0.0237 0.0242 

[TRAIN] Epoch[2](621/1500); Loss: 0.168895; Backpropagation: 0.0959 sec; Batch: 0.4309 sec
0.3073 0.2563 0.2048 0.1869 0.1490 0.1445 0.1437 0.1487 0.1482 0.1450 0.1444 0.1449 0.1444 0.1446 0.1447 0.1450 

[TRAIN] Epoch[2](622/1500); Loss: 0.116211; Backpropagation: 0.0957 sec; Batch: 0.4300 sec
0.1400 0.1262 0.1238 0.1184 0.1149 0.1137 0.1129 0.1127 0.1122 0.1121 0.1123 0.1122 0.1120 0.1117 0.1118 0.1122 

[TRAIN] Epoch[2](623/1500); Loss: 0.111629; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1324 0.1288 0.1124 0.1138 0.1134 0.1106 0.1085 0.1075 0.1068 0.1070 0.1072 0.1078 0.1074 0.1072 0.1075 0.1078 

[TRAIN] Epoch[2](624/1500); Loss: 0.146203; Backpropagation: 0.0938 sec; Batch: 0.4294 sec
0.1922 0.1672 0.1602 0.1573 0.1533 0.1479 0.1434 0.1406 0.1384 0.1366 0.1354 0.1347 0.1340 0.1333 0.1326 0.1322 

[TRAIN] Epoch[2](625/1500); Loss: 0.181635; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2093 0.1924 0.1891 0.1853 0.1835 0.1821 0.1803 0.1787 0.1780 0.1770 0.1764 0.1756 0.1752 0.1745 0.1745 0.1743 

[TRAIN] Epoch[2](626/1500); Loss: 0.100736; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1214 0.1214 0.1371 0.1161 0.1005 0.0966 0.0948 0.0933 0.0925 0.0918 0.0913 0.0914 0.0911 0.0909 0.0910 0.0908 

[TRAIN] Epoch[2](627/1500); Loss: 0.058008; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.0921 0.0662 0.0861 0.0737 0.0603 0.0536 0.0503 0.0492 0.0491 0.0492 0.0493 0.0493 0.0495 0.0497 0.0500 0.0505 

[TRAIN] Epoch[2](628/1500); Loss: 0.114158; Backpropagation: 0.0940 sec; Batch: 0.4296 sec
0.1833 0.1601 0.1380 0.1295 0.1149 0.1098 0.1053 0.1018 0.1009 0.1001 0.0986 0.0976 0.0971 0.0967 0.0964 0.0962 

[TRAIN] Epoch[2](629/1500); Loss: 0.087590; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1465 0.1235 0.1104 0.1032 0.0935 0.0874 0.0816 0.0772 0.0750 0.0739 0.0727 0.0714 0.0710 0.0712 0.0713 0.0715 

[TRAIN] Epoch[2](630/1500); Loss: 0.107359; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1608 0.1347 0.1171 0.1141 0.1125 0.1085 0.1029 0.0998 0.0981 0.0974 0.0966 0.0958 0.0954 0.0951 0.0946 0.0943 

[TRAIN] Epoch[2](631/1500); Loss: 0.121728; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1615 0.1465 0.1365 0.1348 0.1311 0.1250 0.1197 0.1161 0.1139 0.1123 0.1110 0.1097 0.1086 0.1076 0.1070 0.1064 

[TRAIN] Epoch[2](632/1500); Loss: 0.112950; Backpropagation: 0.0932 sec; Batch: 0.4664 sec
0.4117 0.3161 0.2279 0.1938 0.1148 0.0890 0.0547 0.0406 0.0581 0.0523 0.0412 0.0406 0.0411 0.0416 0.0418 0.0419 

[TRAIN] Epoch[2](633/1500); Loss: 0.096287; Backpropagation: 0.0939 sec; Batch: 0.4756 sec
0.1302 0.1188 0.1064 0.1016 0.0972 0.0951 0.0931 0.0918 0.0907 0.0898 0.0891 0.0884 0.0878 0.0873 0.0870 0.0865 

[TRAIN] Epoch[2](634/1500); Loss: 0.053674; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1022 0.1003 0.0666 0.0625 0.0542 0.0486 0.0452 0.0448 0.0435 0.0420 0.0416 0.0411 0.0410 0.0413 0.0416 0.0423 

[TRAIN] Epoch[2](635/1500); Loss: 0.069984; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.0997 0.0912 0.0785 0.0735 0.0690 0.0677 0.0652 0.0638 0.0639 0.0635 0.0636 0.0634 0.0638 0.0641 0.0643 0.0645 

[TRAIN] Epoch[2](636/1500); Loss: 0.143106; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2019 0.1779 0.1601 0.1491 0.1398 0.1381 0.1357 0.1341 0.1331 0.1324 0.1319 0.1316 0.1312 0.1310 0.1309 0.1307 

[TRAIN] Epoch[2](637/1500); Loss: 0.128424; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1664 0.1503 0.1396 0.1339 0.1306 0.1285 0.1253 0.1237 0.1224 0.1213 0.1203 0.1197 0.1190 0.1184 0.1177 0.1174 

[TRAIN] Epoch[2](638/1500); Loss: 0.088026; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1202 0.1068 0.0950 0.0912 0.0862 0.0846 0.0843 0.0833 0.0826 0.0823 0.0822 0.0820 0.0820 0.0819 0.0819 0.0819 

[TRAIN] Epoch[2](639/1500); Loss: 0.093720; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1280 0.1150 0.1038 0.0997 0.0943 0.0924 0.0899 0.0884 0.0873 0.0864 0.0859 0.0856 0.0854 0.0857 0.0859 0.0859 

[TRAIN] Epoch[2](640/1500); Loss: 0.081431; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1229 0.1078 0.0939 0.0861 0.0785 0.0770 0.0755 0.0740 0.0735 0.0734 0.0735 0.0732 0.0732 0.0735 0.0733 0.0737 

[TRAIN] Epoch[2](641/1500); Loss: 0.101538; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1264 0.1104 0.1060 0.1026 0.1009 0.0996 0.0986 0.0983 0.0981 0.0978 0.0977 0.0975 0.0975 0.0976 0.0977 0.0979 

[TRAIN] Epoch[2](642/1500); Loss: 0.076325; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1081 0.0965 0.0813 0.0782 0.0743 0.0729 0.0718 0.0710 0.0708 0.0708 0.0706 0.0706 0.0708 0.0709 0.0712 0.0714 

[TRAIN] Epoch[2](643/1500); Loss: 0.066785; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1107 0.1035 0.0782 0.0630 0.0618 0.0594 0.0581 0.0577 0.0577 0.0583 0.0586 0.0592 0.0598 0.0602 0.0608 0.0614 

[TRAIN] Epoch[2](644/1500); Loss: 0.105401; Backpropagation: 0.0965 sec; Batch: 0.4316 sec
0.1431 0.1278 0.1207 0.1125 0.1042 0.1020 0.0997 0.0987 0.0982 0.0978 0.0974 0.0970 0.0970 0.0969 0.0967 0.0968 

[TRAIN] Epoch[2](645/1500); Loss: 0.053971; Backpropagation: 0.0959 sec; Batch: 0.4311 sec
0.0883 0.0625 0.0703 0.0591 0.0501 0.0492 0.0483 0.0479 0.0478 0.0480 0.0480 0.0479 0.0483 0.0490 0.0493 0.0497 

[TRAIN] Epoch[2](646/1500); Loss: 0.075061; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1083 0.0958 0.0821 0.0760 0.0723 0.0713 0.0702 0.0698 0.0695 0.0691 0.0688 0.0689 0.0691 0.0694 0.0699 0.0705 

[TRAIN] Epoch[2](647/1500); Loss: 0.083434; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1221 0.1189 0.0930 0.0914 0.0860 0.0809 0.0777 0.0757 0.0747 0.0743 0.0737 0.0735 0.0735 0.0731 0.0731 0.0735 

[TRAIN] Epoch[2](648/1500); Loss: 0.082147; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1285 0.1197 0.1020 0.0874 0.0777 0.0749 0.0735 0.0728 0.0723 0.0722 0.0720 0.0719 0.0721 0.0724 0.0723 0.0726 

[TRAIN] Epoch[2](649/1500); Loss: 0.104853; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1402 0.1330 0.1192 0.1083 0.1015 0.0997 0.0987 0.0981 0.0977 0.0974 0.0971 0.0971 0.0972 0.0973 0.0975 0.0976 

[TRAIN] Epoch[2](650/1500); Loss: 0.096374; Backpropagation: 0.0937 sec; Batch: 0.4293 sec
0.1392 0.1272 0.1160 0.1041 0.0936 0.0911 0.0889 0.0873 0.0870 0.0868 0.0866 0.0866 0.0867 0.0868 0.0869 0.0872 

[TRAIN] Epoch[2](651/1500); Loss: 0.119140; Backpropagation: 0.0940 sec; Batch: 0.4293 sec
0.1659 0.1430 0.1349 0.1220 0.1147 0.1131 0.1116 0.1116 0.1113 0.1112 0.1111 0.1111 0.1110 0.1111 0.1112 0.1113 

[TRAIN] Epoch[2](652/1500); Loss: 0.160226; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2347 0.1976 0.1754 0.1649 0.1527 0.1509 0.1493 0.1484 0.1483 0.1481 0.1483 0.1485 0.1488 0.1490 0.1492 0.1494 

[TRAIN] Epoch[2](653/1500); Loss: 0.056274; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.0967 0.0782 0.0643 0.0592 0.0528 0.0518 0.0509 0.0506 0.0499 0.0496 0.0494 0.0493 0.0493 0.0494 0.0495 0.0497 

[TRAIN] Epoch[2](654/1500); Loss: 0.112959; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1411 0.1250 0.1189 0.1130 0.1104 0.1088 0.1080 0.1079 0.1082 0.1084 0.1086 0.1090 0.1094 0.1098 0.1102 0.1107 

[TRAIN] Epoch[2](655/1500); Loss: 0.091704; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1283 0.1117 0.1005 0.0937 0.0882 0.0877 0.0866 0.0861 0.0858 0.0856 0.0856 0.0855 0.0855 0.0855 0.0855 0.0856 

[TRAIN] Epoch[2](656/1500); Loss: 0.090170; Backpropagation: 0.0940 sec; Batch: 0.4298 sec
0.1524 0.1390 0.1067 0.0915 0.0857 0.0820 0.0805 0.0790 0.0786 0.0782 0.0779 0.0780 0.0781 0.0781 0.0786 0.0785 

[TRAIN] Epoch[2](657/1500); Loss: 0.109452; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1535 0.1340 0.1174 0.1121 0.1067 0.1061 0.1042 0.1032 0.1027 0.1024 0.1020 0.1016 0.1013 0.1012 0.1013 0.1013 

[TRAIN] Epoch[2](658/1500); Loss: 0.056270; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1028 0.0870 0.0697 0.0606 0.0495 0.0490 0.0481 0.0479 0.0478 0.0479 0.0480 0.0481 0.0482 0.0484 0.0486 0.0488 

[TRAIN] Epoch[2](659/1500); Loss: 0.127083; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1855 0.1685 0.1445 0.1312 0.1199 0.1177 0.1168 0.1166 0.1169 0.1164 0.1160 0.1161 0.1161 0.1166 0.1169 0.1175 

[TRAIN] Epoch[2](660/1500); Loss: 0.137793; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1670 0.1554 0.1496 0.1427 0.1373 0.1360 0.1349 0.1339 0.1328 0.1320 0.1311 0.1306 0.1303 0.1302 0.1305 0.1306 

[TRAIN] Epoch[2](661/1500); Loss: 0.048244; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1167 0.1004 0.0605 0.0473 0.0471 0.0389 0.0376 0.0359 0.0355 0.0358 0.0352 0.0357 0.0358 0.0360 0.0365 0.0370 

[TRAIN] Epoch[2](662/1500); Loss: 0.055216; Backpropagation: 0.0961 sec; Batch: 0.4307 sec
0.0784 0.0793 0.0725 0.0581 0.0508 0.0504 0.0493 0.0488 0.0485 0.0485 0.0489 0.0492 0.0497 0.0502 0.0505 0.0506 

[TRAIN] Epoch[2](663/1500); Loss: 0.075363; Backpropagation: 0.0982 sec; Batch: 0.4342 sec
0.1967 0.1488 0.1128 0.0931 0.0658 0.0593 0.0545 0.0549 0.0540 0.0522 0.0524 0.0522 0.0521 0.0520 0.0526 0.0524 

[TRAIN] Epoch[2](664/1500); Loss: 0.142665; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.2452 0.2029 0.1688 0.1521 0.1359 0.1375 0.1305 0.1263 0.1252 0.1244 0.1241 0.1232 0.1222 0.1218 0.1214 0.1211 

[TRAIN] Epoch[2](665/1500); Loss: 0.100774; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1489 0.1367 0.1248 0.1107 0.1036 0.1009 0.0966 0.0933 0.0912 0.0895 0.0884 0.0872 0.0861 0.0855 0.0847 0.0842 

[TRAIN] Epoch[2](666/1500); Loss: 0.160302; Backpropagation: 0.0935 sec; Batch: 0.4290 sec
0.2014 0.1854 0.1835 0.1713 0.1632 0.1602 0.1572 0.1547 0.1527 0.1506 0.1493 0.1480 0.1475 0.1469 0.1466 0.1463 

[TRAIN] Epoch[2](667/1500); Loss: 0.144587; Backpropagation: 0.0942 sec; Batch: 0.4297 sec
0.2137 0.1931 0.1777 0.1656 0.1509 0.1457 0.1391 0.1318 0.1290 0.1284 0.1265 0.1242 0.1229 0.1223 0.1216 0.1208 

[TRAIN] Epoch[2](668/1500); Loss: 0.123737; Backpropagation: 0.0958 sec; Batch: 0.4299 sec
0.1357 0.1272 0.1321 0.1300 0.1268 0.1245 0.1225 0.1208 0.1202 0.1201 0.1200 0.1201 0.1201 0.1195 0.1199 0.1202 

[TRAIN] Epoch[2](669/1500); Loss: 0.150142; Backpropagation: 0.0961 sec; Batch: 0.4320 sec
0.2118 0.1889 0.1714 0.1628 0.1520 0.1481 0.1430 0.1389 0.1401 0.1386 0.1363 0.1351 0.1346 0.1340 0.1335 0.1332 

[TRAIN] Epoch[2](670/1500); Loss: 0.161472; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2060 0.1873 0.1872 0.1755 0.1715 0.1673 0.1621 0.1572 0.1533 0.1498 0.1473 0.1456 0.1445 0.1435 0.1430 0.1425 

[TRAIN] Epoch[2](671/1500); Loss: 0.115792; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1225 0.1283 0.1228 0.1174 0.1146 0.1135 0.1121 0.1118 0.1120 0.1123 0.1125 0.1131 0.1139 0.1144 0.1151 0.1163 

[TRAIN] Epoch[2](672/1500); Loss: 0.055326; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.0663 0.0650 0.0751 0.0640 0.0561 0.0532 0.0512 0.0510 0.0506 0.0502 0.0504 0.0501 0.0505 0.0504 0.0505 0.0507 

[TRAIN] Epoch[2](673/1500); Loss: 0.100559; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1624 0.1587 0.1269 0.1012 0.0945 0.0938 0.0912 0.0879 0.0862 0.0859 0.0863 0.0867 0.0866 0.0867 0.0869 0.0870 

[TRAIN] Epoch[2](674/1500); Loss: 0.098281; Backpropagation: 0.0980 sec; Batch: 0.4333 sec
0.1331 0.1019 0.1007 0.1064 0.1159 0.1101 0.1019 0.0960 0.0920 0.0898 0.0889 0.0880 0.0872 0.0868 0.0870 0.0868 

[TRAIN] Epoch[2](675/1500); Loss: 0.137332; Backpropagation: 0.0960 sec; Batch: 0.4311 sec
0.1947 0.1603 0.1542 0.1455 0.1401 0.1365 0.1343 0.1308 0.1280 0.1257 0.1246 0.1241 0.1240 0.1241 0.1249 0.1255 

[TRAIN] Epoch[2](676/1500); Loss: 0.127531; Backpropagation: 0.0947 sec; Batch: 0.4320 sec
0.1497 0.1444 0.1512 0.1420 0.1389 0.1353 0.1297 0.1250 0.1214 0.1189 0.1171 0.1155 0.1141 0.1130 0.1125 0.1119 

[TRAIN] Epoch[2](677/1500); Loss: 0.068893; Backpropagation: 0.0939 sec; Batch: 0.4890 sec
0.1028 0.0941 0.1027 0.0942 0.0882 0.0812 0.0729 0.0657 0.0597 0.0549 0.0510 0.0486 0.0472 0.0463 0.0464 0.0462 

[TRAIN] Epoch[2](678/1500); Loss: 0.093355; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.1757 0.1726 0.1377 0.1032 0.0850 0.0806 0.0765 0.0745 0.0742 0.0737 0.0736 0.0736 0.0734 0.0732 0.0732 0.0730 

[TRAIN] Epoch[2](679/1500); Loss: 0.122297; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1936 0.1723 0.1506 0.1312 0.1193 0.1158 0.1112 0.1087 0.1076 0.1068 0.1066 0.1069 0.1066 0.1065 0.1067 0.1065 

[TRAIN] Epoch[2](680/1500); Loss: 0.110721; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1372 0.1265 0.1300 0.1220 0.1152 0.1120 0.1085 0.1060 0.1044 0.1031 0.1022 0.1016 0.1012 0.1008 0.1004 0.1003 

[TRAIN] Epoch[2](681/1500); Loss: 0.091604; Backpropagation: 0.0939 sec; Batch: 0.4299 sec
0.1027 0.1132 0.1172 0.1039 0.0942 0.0908 0.0880 0.0859 0.0846 0.0839 0.0839 0.0837 0.0833 0.0833 0.0833 0.0836 

[TRAIN] Epoch[2](682/1500); Loss: 0.133411; Backpropagation: 0.0935 sec; Batch: 0.4300 sec
0.1941 0.1777 0.1718 0.1559 0.1373 0.1311 0.1246 0.1185 0.1171 0.1166 0.1156 0.1152 0.1149 0.1147 0.1147 0.1149 

[TRAIN] Epoch[2](683/1500); Loss: 0.146959; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.3042 0.2508 0.2115 0.1922 0.1581 0.1470 0.1335 0.1158 0.1076 0.1072 0.1060 0.1041 0.1040 0.1033 0.1031 0.1030 

[TRAIN] Epoch[2](684/1500); Loss: 0.121767; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1966 0.1576 0.1368 0.1274 0.1207 0.1169 0.1137 0.1120 0.1108 0.1097 0.1088 0.1082 0.1076 0.1073 0.1071 0.1068 

[TRAIN] Epoch[2](685/1500); Loss: 0.098166; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1807 0.1520 0.1278 0.1131 0.0979 0.0927 0.0874 0.0822 0.0816 0.0808 0.0797 0.0794 0.0793 0.0789 0.0786 0.0785 

[TRAIN] Epoch[2](686/1500); Loss: 0.152603; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1678 0.1607 0.1638 0.1606 0.1558 0.1527 0.1507 0.1493 0.1485 0.1481 0.1478 0.1475 0.1472 0.1471 0.1470 0.1469 

[TRAIN] Epoch[2](687/1500); Loss: 0.099855; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1297 0.1177 0.1248 0.1157 0.1040 0.0997 0.0961 0.0941 0.0924 0.0911 0.0903 0.0895 0.0886 0.0883 0.0881 0.0878 

[TRAIN] Epoch[2](688/1500); Loss: 0.127811; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1639 0.1502 0.1370 0.1301 0.1251 0.1240 0.1224 0.1214 0.1212 0.1212 0.1211 0.1210 0.1214 0.1215 0.1216 0.1218 

[TRAIN] Epoch[2](689/1500); Loss: 0.118895; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1510 0.1409 0.1444 0.1344 0.1253 0.1199 0.1149 0.1122 0.1104 0.1091 0.1080 0.1072 0.1065 0.1060 0.1061 0.1059 

[TRAIN] Epoch[2](690/1500); Loss: 0.046276; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.0858 0.0535 0.0606 0.0572 0.0464 0.0411 0.0401 0.0391 0.0384 0.0394 0.0390 0.0393 0.0395 0.0394 0.0407 0.0410 

[TRAIN] Epoch[2](691/1500); Loss: 0.140467; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1568 0.1476 0.1570 0.1484 0.1414 0.1393 0.1379 0.1374 0.1361 0.1355 0.1352 0.1350 0.1350 0.1351 0.1349 0.1349 

[TRAIN] Epoch[2](692/1500); Loss: 0.054316; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0844 0.0807 0.0772 0.0629 0.0512 0.0503 0.0477 0.0463 0.0464 0.0461 0.0459 0.0459 0.0460 0.0458 0.0461 0.0462 

[TRAIN] Epoch[2](693/1500); Loss: 0.063871; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1892 0.1196 0.0826 0.0689 0.0704 0.0644 0.0513 0.0452 0.0426 0.0418 0.0411 0.0409 0.0407 0.0409 0.0411 0.0412 

[TRAIN] Epoch[2](694/1500); Loss: 0.095459; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1389 0.1260 0.1123 0.1005 0.0929 0.0911 0.0890 0.0877 0.0874 0.0866 0.0864 0.0860 0.0860 0.0857 0.0856 0.0854 

[TRAIN] Epoch[2](695/1500); Loss: 0.079037; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1217 0.0987 0.0926 0.0845 0.0806 0.0775 0.0738 0.0720 0.0709 0.0703 0.0700 0.0698 0.0700 0.0704 0.0707 0.0711 

[TRAIN] Epoch[2](696/1500); Loss: 0.092009; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.1440 0.1234 0.1134 0.0998 0.0895 0.0882 0.0847 0.0833 0.0824 0.0817 0.0814 0.0807 0.0805 0.0800 0.0796 0.0795 

[TRAIN] Epoch[2](697/1500); Loss: 0.113591; Backpropagation: 0.0942 sec; Batch: 0.4298 sec
0.2052 0.1714 0.1461 0.1320 0.1133 0.1073 0.1011 0.0945 0.0930 0.0927 0.0927 0.0928 0.0931 0.0935 0.0941 0.0946 

[TRAIN] Epoch[2](698/1500); Loss: 0.146234; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.1777 0.1598 0.1538 0.1480 0.1442 0.1431 0.1425 0.1420 0.1417 0.1415 0.1411 0.1409 0.1408 0.1408 0.1409 0.1410 

[TRAIN] Epoch[2](699/1500); Loss: 0.041156; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.0715 0.0498 0.0478 0.0438 0.0380 0.0374 0.0370 0.0369 0.0364 0.0364 0.0365 0.0366 0.0368 0.0373 0.0379 0.0385 

[TRAIN] Epoch[2](700/1500); Loss: 0.064307; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.0802 0.0873 0.0846 0.0725 0.0625 0.0607 0.0592 0.0589 0.0588 0.0583 0.0580 0.0579 0.0577 0.0576 0.0577 0.0572 

[TRAIN] Epoch[2](701/1500); Loss: 0.095879; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1098 0.1192 0.1301 0.1105 0.0940 0.0904 0.0892 0.0892 0.0887 0.0880 0.0878 0.0879 0.0873 0.0870 0.0875 0.0875 

[TRAIN] Epoch[2](702/1500); Loss: 0.149510; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2071 0.1838 0.1643 0.1535 0.1438 0.1422 0.1407 0.1397 0.1399 0.1397 0.1395 0.1397 0.1397 0.1395 0.1395 0.1397 

[TRAIN] Epoch[2](703/1500); Loss: 0.103968; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.3824 0.2820 0.1955 0.1628 0.0839 0.0628 0.0394 0.0641 0.0627 0.0480 0.0453 0.0456 0.0461 0.0472 0.0476 0.0481 

[TRAIN] Epoch[2](704/1500); Loss: 0.087403; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1808 0.1242 0.1049 0.0922 0.0807 0.0774 0.0754 0.0744 0.0741 0.0737 0.0734 0.0736 0.0736 0.0735 0.0732 0.0733 

[TRAIN] Epoch[2](705/1500); Loss: 0.104351; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1247 0.1164 0.1153 0.1074 0.1014 0.1001 0.1001 0.0999 0.1000 0.0998 0.1003 0.1007 0.1007 0.1007 0.1009 0.1011 

[TRAIN] Epoch[2](706/1500); Loss: 0.071219; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1050 0.0968 0.0838 0.0765 0.0684 0.0663 0.0667 0.0657 0.0649 0.0645 0.0642 0.0635 0.0635 0.0635 0.0634 0.0630 

[TRAIN] Epoch[2](707/1500); Loss: 0.055401; Backpropagation: 0.0938 sec; Batch: 0.4288 sec
0.0713 0.0661 0.0592 0.0566 0.0540 0.0530 0.0524 0.0526 0.0526 0.0526 0.0523 0.0522 0.0524 0.0529 0.0531 0.0531 

[TRAIN] Epoch[2](708/1500); Loss: 0.046881; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1498 0.0946 0.0743 0.0568 0.0370 0.0331 0.0299 0.0287 0.0287 0.0294 0.0296 0.0300 0.0310 0.0317 0.0322 0.0330 

[TRAIN] Epoch[2](709/1500); Loss: 0.056110; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.0836 0.0649 0.0894 0.0716 0.0547 0.0505 0.0490 0.0484 0.0484 0.0482 0.0481 0.0480 0.0480 0.0481 0.0483 0.0485 

[TRAIN] Epoch[2](710/1500); Loss: 0.078997; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1315 0.1160 0.0963 0.0763 0.0707 0.0694 0.0688 0.0691 0.0691 0.0695 0.0694 0.0701 0.0706 0.0715 0.0723 0.0732 

[TRAIN] Epoch[2](711/1500); Loss: 0.091749; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1405 0.1017 0.1203 0.0998 0.0876 0.0853 0.0841 0.0838 0.0828 0.0825 0.0831 0.0830 0.0832 0.0837 0.0834 0.0835 

[TRAIN] Epoch[2](712/1500); Loss: 0.097878; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1805 0.1532 0.1267 0.1141 0.0990 0.0933 0.0883 0.0819 0.0792 0.0787 0.0786 0.0786 0.0786 0.0786 0.0785 0.0783 

[TRAIN] Epoch[2](713/1500); Loss: 0.091349; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1790 0.1279 0.1032 0.0951 0.0855 0.0815 0.0797 0.0788 0.0784 0.0787 0.0785 0.0786 0.0788 0.0790 0.0794 0.0794 

[TRAIN] Epoch[2](714/1500); Loss: 0.070258; Backpropagation: 0.0932 sec; Batch: 0.4282 sec
0.1020 0.0829 0.0810 0.0753 0.0697 0.0683 0.0671 0.0660 0.0655 0.0647 0.0641 0.0639 0.0636 0.0634 0.0633 0.0633 

[TRAIN] Epoch[2](715/1500); Loss: 0.117811; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1420 0.1284 0.1225 0.1181 0.1164 0.1155 0.1145 0.1140 0.1138 0.1138 0.1137 0.1138 0.1141 0.1144 0.1147 0.1151 

[TRAIN] Epoch[2](716/1500); Loss: 0.090182; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1306 0.1283 0.1041 0.0931 0.0924 0.0885 0.0861 0.0834 0.0810 0.0797 0.0794 0.0790 0.0792 0.0792 0.0795 0.0794 

[TRAIN] Epoch[2](717/1500); Loss: 0.173568; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.3165 0.2583 0.2068 0.1925 0.1559 0.1497 0.1478 0.1498 0.1502 0.1497 0.1499 0.1500 0.1502 0.1500 0.1499 0.1499 

[TRAIN] Epoch[2](718/1500); Loss: 0.090652; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1993 0.1358 0.0983 0.0911 0.0803 0.0791 0.0778 0.0773 0.0765 0.0766 0.0761 0.0760 0.0758 0.0766 0.0767 0.0770 

[TRAIN] Epoch[2](719/1500); Loss: 0.063777; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1050 0.0925 0.0786 0.0698 0.0602 0.0576 0.0563 0.0553 0.0547 0.0547 0.0548 0.0552 0.0560 0.0561 0.0565 0.0572 

[TRAIN] Epoch[2](720/1500); Loss: 0.097158; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1283 0.1112 0.1082 0.0980 0.0935 0.0927 0.0921 0.0923 0.0922 0.0921 0.0921 0.0921 0.0921 0.0924 0.0925 0.0928 

[TRAIN] Epoch[2](721/1500); Loss: 0.085419; Backpropagation: 0.0944 sec; Batch: 0.4291 sec
0.1816 0.1206 0.0979 0.0854 0.0747 0.0738 0.0733 0.0726 0.0727 0.0728 0.0735 0.0731 0.0733 0.0736 0.0737 0.0742 

[TRAIN] Epoch[2](722/1500); Loss: 0.140746; Backpropagation: 0.0938 sec; Batch: 0.4692 sec
0.1938 0.1759 0.1587 0.1510 0.1418 0.1383 0.1356 0.1327 0.1304 0.1287 0.1282 0.1278 0.1275 0.1275 0.1272 0.1270 

[TRAIN] Epoch[2](723/1500); Loss: 0.124721; Backpropagation: 0.0934 sec; Batch: 0.4309 sec
0.1760 0.1568 0.1343 0.1289 0.1236 0.1220 0.1200 0.1185 0.1173 0.1164 0.1151 0.1144 0.1141 0.1130 0.1127 0.1124 

[TRAIN] Epoch[2](724/1500); Loss: 0.098392; Backpropagation: 0.0938 sec; Batch: 0.4311 sec
0.1480 0.1258 0.1051 0.1012 0.0972 0.0943 0.0924 0.0911 0.0903 0.0900 0.0898 0.0898 0.0897 0.0898 0.0898 0.0899 

[TRAIN] Epoch[2](725/1500); Loss: 0.054391; Backpropagation: 0.0925 sec; Batch: 0.4278 sec
0.0946 0.0667 0.0585 0.0535 0.0519 0.0510 0.0494 0.0491 0.0494 0.0491 0.0489 0.0491 0.0495 0.0496 0.0497 0.0504 

[TRAIN] Epoch[2](726/1500); Loss: 0.072956; Backpropagation: 0.0948 sec; Batch: 0.4294 sec
0.1478 0.1096 0.0874 0.0732 0.0654 0.0634 0.0626 0.0620 0.0616 0.0615 0.0618 0.0618 0.0621 0.0620 0.0624 0.0627 

[TRAIN] Epoch[2](727/1500); Loss: 0.105318; Backpropagation: 0.0925 sec; Batch: 0.4267 sec
0.1665 0.1453 0.1191 0.1129 0.1044 0.1009 0.0986 0.0959 0.0942 0.0928 0.0922 0.0923 0.0920 0.0924 0.0927 0.0928 

[TRAIN] Epoch[2](728/1500); Loss: 0.122749; Backpropagation: 0.0925 sec; Batch: 0.4267 sec
0.2091 0.1760 0.1542 0.1409 0.1234 0.1182 0.1126 0.1057 0.1029 0.1030 0.1030 0.1030 0.1028 0.1030 0.1032 0.1030 

[TRAIN] Epoch[2](729/1500); Loss: 0.122033; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1700 0.1444 0.1345 0.1266 0.1209 0.1188 0.1170 0.1155 0.1143 0.1139 0.1134 0.1130 0.1126 0.1125 0.1125 0.1125 

[TRAIN] Epoch[2](730/1500); Loss: 0.094804; Backpropagation: 0.0923 sec; Batch: 0.4263 sec
0.1448 0.1079 0.1258 0.1060 0.0911 0.0874 0.0857 0.0855 0.0851 0.0856 0.0852 0.0850 0.0854 0.0853 0.0855 0.0856 

[TRAIN] Epoch[2](731/1500); Loss: 0.153842; Backpropagation: 0.0925 sec; Batch: 0.4266 sec
0.1666 0.1612 0.1697 0.1609 0.1533 0.1507 0.1502 0.1502 0.1501 0.1496 0.1497 0.1498 0.1497 0.1499 0.1500 0.1499 

[TRAIN] Epoch[2](732/1500); Loss: 0.085746; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.1470 0.1258 0.1109 0.0989 0.0824 0.0775 0.0748 0.0739 0.0735 0.0727 0.0726 0.0725 0.0723 0.0724 0.0725 0.0724 

[TRAIN] Epoch[2](733/1500); Loss: 0.086131; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.0998 0.0963 0.0935 0.0880 0.0852 0.0846 0.0842 0.0839 0.0832 0.0828 0.0827 0.0828 0.0827 0.0826 0.0828 0.0829 

[TRAIN] Epoch[2](734/1500); Loss: 0.132364; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.2064 0.1695 0.1421 0.1322 0.1232 0.1226 0.1221 0.1219 0.1218 0.1217 0.1221 0.1220 0.1222 0.1225 0.1226 0.1230 

[TRAIN] Epoch[2](735/1500); Loss: 0.076946; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.1108 0.1013 0.0974 0.0856 0.0750 0.0722 0.0705 0.0697 0.0692 0.0688 0.0688 0.0685 0.0682 0.0683 0.0685 0.0684 

[TRAIN] Epoch[2](736/1500); Loss: 0.065838; Backpropagation: 0.0924 sec; Batch: 0.4265 sec
0.1633 0.1053 0.0819 0.0705 0.0657 0.0592 0.0544 0.0530 0.0515 0.0510 0.0504 0.0496 0.0498 0.0494 0.0495 0.0490 

[TRAIN] Epoch[2](737/1500); Loss: 0.096849; Backpropagation: 0.0926 sec; Batch: 0.4269 sec
0.1470 0.1305 0.1137 0.1067 0.0943 0.0914 0.0891 0.0862 0.0856 0.0863 0.0862 0.0867 0.0866 0.0863 0.0866 0.0864 

[TRAIN] Epoch[2](738/1500); Loss: 0.109135; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1669 0.1333 0.1254 0.1152 0.1064 0.1038 0.1024 0.1007 0.0999 0.0994 0.0992 0.0989 0.0986 0.0987 0.0986 0.0987 

[TRAIN] Epoch[2](739/1500); Loss: 0.082790; Backpropagation: 0.0935 sec; Batch: 0.4292 sec
0.1003 0.1029 0.0951 0.0873 0.0832 0.0813 0.0800 0.0790 0.0781 0.0774 0.0770 0.0767 0.0766 0.0765 0.0766 0.0766 

[TRAIN] Epoch[2](740/1500); Loss: 0.111350; Backpropagation: 0.0926 sec; Batch: 0.4270 sec
0.1443 0.1339 0.1225 0.1132 0.1093 0.1069 0.1059 0.1055 0.1050 0.1050 0.1051 0.1049 0.1048 0.1049 0.1051 0.1053 

[TRAIN] Epoch[2](741/1500); Loss: 0.081409; Backpropagation: 0.0923 sec; Batch: 0.4264 sec
0.1043 0.1054 0.1201 0.0990 0.0803 0.0753 0.0734 0.0724 0.0719 0.0716 0.0716 0.0714 0.0713 0.0713 0.0715 0.0717 

[TRAIN] Epoch[2](742/1500); Loss: 0.100080; Backpropagation: 0.0925 sec; Batch: 0.4268 sec
0.1308 0.1212 0.1098 0.1037 0.0978 0.0963 0.0955 0.0949 0.0946 0.0940 0.0940 0.0937 0.0937 0.0936 0.0939 0.0938 

[TRAIN] Epoch[2](743/1500); Loss: 0.088216; Backpropagation: 0.0923 sec; Batch: 0.4266 sec
0.1394 0.1214 0.1067 0.0941 0.0857 0.0829 0.0805 0.0790 0.0781 0.0780 0.0778 0.0776 0.0775 0.0774 0.0776 0.0777 

[TRAIN] Epoch[2](744/1500); Loss: 0.134657; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1659 0.1511 0.1445 0.1392 0.1342 0.1328 0.1317 0.1308 0.1301 0.1294 0.1286 0.1279 0.1275 0.1271 0.1268 0.1267 

[TRAIN] Epoch[2](745/1500); Loss: 0.075527; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1277 0.1064 0.0973 0.0827 0.0691 0.0672 0.0661 0.0655 0.0650 0.0649 0.0652 0.0656 0.0659 0.0662 0.0665 0.0672 

[TRAIN] Epoch[2](746/1500); Loss: 0.057279; Backpropagation: 0.0929 sec; Batch: 0.4270 sec
0.1303 0.1214 0.0637 0.0618 0.0658 0.0518 0.0477 0.0402 0.0398 0.0403 0.0404 0.0406 0.0432 0.0424 0.0427 0.0444 

[TRAIN] Epoch[2](747/1500); Loss: 0.118442; Backpropagation: 0.0923 sec; Batch: 0.4266 sec
0.1717 0.1358 0.1369 0.1240 0.1155 0.1133 0.1115 0.1108 0.1105 0.1101 0.1097 0.1093 0.1094 0.1092 0.1087 0.1087 

[TRAIN] Epoch[2](748/1500); Loss: 0.045712; Backpropagation: 0.0926 sec; Batch: 0.4264 sec
0.1116 0.1065 0.0725 0.0391 0.0354 0.0340 0.0335 0.0332 0.0332 0.0327 0.0334 0.0329 0.0329 0.0335 0.0334 0.0335 

[TRAIN] Epoch[2](749/1500); Loss: 0.151487; Backpropagation: 0.0923 sec; Batch: 0.4280 sec
0.1895 0.1697 0.1629 0.1547 0.1494 0.1481 0.1471 0.1460 0.1454 0.1450 0.1447 0.1444 0.1443 0.1442 0.1442 0.1441 

[TRAIN] Epoch[2](750/1500); Loss: 0.110336; Backpropagation: 0.0950 sec; Batch: 0.4302 sec
0.1507 0.1340 0.1235 0.1137 0.1073 0.1056 0.1046 0.1039 0.1036 0.1033 0.1025 0.1025 0.1025 0.1024 0.1028 0.1026 

[TRAIN] Epoch[2](751/1500); Loss: 0.112916; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1933 0.1440 0.1199 0.1089 0.1084 0.1050 0.1025 0.1020 0.1019 0.1020 0.1023 0.1024 0.1027 0.1036 0.1038 0.1042 

[TRAIN] Epoch[2](752/1500); Loss: 0.100478; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1377 0.1187 0.1099 0.1042 0.0983 0.0968 0.0953 0.0948 0.0947 0.0942 0.0942 0.0939 0.0939 0.0938 0.0936 0.0936 

[TRAIN] Epoch[2](753/1500); Loss: 0.121741; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1399 0.1284 0.1276 0.1227 0.1201 0.1197 0.1192 0.1187 0.1188 0.1186 0.1188 0.1187 0.1191 0.1192 0.1191 0.1192 

[TRAIN] Epoch[2](754/1500); Loss: 0.108314; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1237 0.1173 0.1154 0.1088 0.1068 0.1063 0.1054 0.1050 0.1050 0.1050 0.1051 0.1053 0.1055 0.1060 0.1061 0.1064 

[TRAIN] Epoch[2](755/1500); Loss: 0.080613; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1770 0.1391 0.1021 0.0868 0.0685 0.0671 0.0661 0.0653 0.0644 0.0645 0.0646 0.0644 0.0646 0.0649 0.0653 0.0651 

[TRAIN] Epoch[2](756/1500); Loss: 0.091798; Backpropagation: 0.0959 sec; Batch: 0.4307 sec
0.1064 0.1017 0.1020 0.0917 0.0887 0.0896 0.0895 0.0883 0.0884 0.0884 0.0884 0.0884 0.0889 0.0892 0.0895 0.0900 

[TRAIN] Epoch[2](757/1500); Loss: 0.169068; Backpropagation: 0.0958 sec; Batch: 0.4302 sec
0.1920 0.1772 0.1754 0.1706 0.1673 0.1660 0.1654 0.1651 0.1652 0.1651 0.1651 0.1654 0.1656 0.1661 0.1668 0.1671 

[TRAIN] Epoch[2](758/1500); Loss: 0.134664; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2470 0.1984 0.1605 0.1383 0.1251 0.1197 0.1161 0.1163 0.1161 0.1155 0.1157 0.1165 0.1166 0.1169 0.1177 0.1182 

[TRAIN] Epoch[2](759/1500); Loss: 0.112229; Backpropagation: 0.0930 sec; Batch: 0.4272 sec
0.1528 0.1323 0.1209 0.1135 0.1076 0.1085 0.1068 0.1058 0.1055 0.1065 0.1059 0.1057 0.1058 0.1058 0.1060 0.1061 

[TRAIN] Epoch[2](760/1500); Loss: 0.064639; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1389 0.1171 0.0862 0.0635 0.0599 0.0551 0.0526 0.0517 0.0511 0.0508 0.0510 0.0511 0.0512 0.0514 0.0511 0.0518 

[TRAIN] Epoch[2](761/1500); Loss: 0.075109; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1089 0.0994 0.0844 0.0835 0.0757 0.0724 0.0704 0.0693 0.0683 0.0677 0.0676 0.0671 0.0670 0.0667 0.0666 0.0667 

[TRAIN] Epoch[2](762/1500); Loss: 0.111002; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2025 0.1626 0.1335 0.1111 0.1056 0.1036 0.0971 0.0947 0.0946 0.0946 0.0944 0.0959 0.0955 0.0964 0.0961 0.0977 

[TRAIN] Epoch[2](763/1500); Loss: 0.114650; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1985 0.1694 0.1433 0.1328 0.1139 0.1081 0.1015 0.0986 0.0987 0.0970 0.0961 0.0955 0.0958 0.0950 0.0952 0.0950 

[TRAIN] Epoch[2](764/1500); Loss: 0.144333; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1946 0.1677 0.1545 0.1446 0.1427 0.1416 0.1397 0.1389 0.1379 0.1368 0.1360 0.1354 0.1352 0.1349 0.1344 0.1343 

[TRAIN] Epoch[2](765/1500); Loss: 0.132619; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1595 0.1472 0.1418 0.1342 0.1317 0.1308 0.1295 0.1287 0.1286 0.1282 0.1273 0.1271 0.1272 0.1268 0.1268 0.1266 

[TRAIN] Epoch[2](766/1500); Loss: 0.142611; Backpropagation: 0.0933 sec; Batch: 0.4287 sec
0.1981 0.1711 0.1586 0.1428 0.1388 0.1373 0.1355 0.1345 0.1338 0.1336 0.1332 0.1330 0.1330 0.1327 0.1327 0.1330 

[TRAIN] Epoch[2](767/1500); Loss: 0.194679; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2714 0.2423 0.2181 0.2060 0.1952 0.1926 0.1874 0.1830 0.1800 0.1779 0.1772 0.1772 0.1771 0.1767 0.1764 0.1764 

[TRAIN] Epoch[2](768/1500); Loss: 0.107357; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.2199 0.1723 0.1342 0.1198 0.0989 0.0948 0.0904 0.0881 0.0884 0.0874 0.0871 0.0871 0.0870 0.0873 0.0876 0.0877 

[TRAIN] Epoch[2](769/1500); Loss: 0.055291; Backpropagation: 0.0939 sec; Batch: 0.4314 sec
0.0742 0.0698 0.0662 0.0555 0.0524 0.0525 0.0524 0.0517 0.0514 0.0512 0.0509 0.0508 0.0510 0.0514 0.0515 0.0517 

[TRAIN] Epoch[2](770/1500); Loss: 0.075013; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1075 0.0912 0.0953 0.0813 0.0774 0.0738 0.0703 0.0679 0.0671 0.0670 0.0669 0.0668 0.0668 0.0669 0.0670 0.0670 

[TRAIN] Epoch[2](771/1500); Loss: 0.188828; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2412 0.2133 0.1993 0.1921 0.1884 0.1867 0.1846 0.1831 0.1819 0.1806 0.1799 0.1793 0.1785 0.1780 0.1774 0.1769 

[TRAIN] Epoch[2](772/1500); Loss: 0.121383; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1543 0.1396 0.1321 0.1269 0.1222 0.1202 0.1182 0.1159 0.1147 0.1141 0.1139 0.1139 0.1139 0.1139 0.1140 0.1143 

[TRAIN] Epoch[2](773/1500); Loss: 0.101031; Backpropagation: 0.0943 sec; Batch: 0.4297 sec
0.1289 0.1134 0.1051 0.1032 0.0999 0.0988 0.0977 0.0973 0.0969 0.0966 0.0966 0.0965 0.0962 0.0963 0.0966 0.0967 

[TRAIN] Epoch[2](774/1500); Loss: 0.100812; Backpropagation: 0.0941 sec; Batch: 0.4297 sec
0.1966 0.1474 0.1283 0.1130 0.0934 0.0898 0.0863 0.0845 0.0840 0.0838 0.0838 0.0841 0.0842 0.0845 0.0846 0.0848 

[TRAIN] Epoch[2](775/1500); Loss: 0.098480; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1282 0.1115 0.1073 0.1002 0.0950 0.0941 0.0936 0.0934 0.0933 0.0933 0.0936 0.0939 0.0941 0.0944 0.0948 0.0950 

[TRAIN] Epoch[2](776/1500); Loss: 0.091036; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1218 0.1172 0.1089 0.0964 0.0885 0.0875 0.0861 0.0851 0.0844 0.0839 0.0835 0.0832 0.0829 0.0826 0.0823 0.0823 

[TRAIN] Epoch[2](777/1500); Loss: 0.112611; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1437 0.1255 0.1181 0.1155 0.1110 0.1093 0.1080 0.1079 0.1079 0.1075 0.1076 0.1079 0.1078 0.1079 0.1079 0.1080 

[TRAIN] Epoch[2](778/1500); Loss: 0.105576; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1315 0.1206 0.1220 0.1113 0.1041 0.1024 0.1011 0.1004 0.1002 0.0998 0.0995 0.0995 0.0994 0.0991 0.0991 0.0992 

[TRAIN] Epoch[2](779/1500); Loss: 0.093251; Backpropagation: 0.0945 sec; Batch: 0.4292 sec
0.1306 0.1201 0.0999 0.1019 0.0949 0.0908 0.0880 0.0862 0.0854 0.0849 0.0848 0.0847 0.0849 0.0850 0.0850 0.0850 

[TRAIN] Epoch[2](780/1500); Loss: 0.125415; Backpropagation: 0.0942 sec; Batch: 0.4449 sec
0.2349 0.1911 0.1662 0.1461 0.1261 0.1198 0.1114 0.1056 0.1028 0.1018 0.1012 0.1003 0.0999 0.0998 0.0998 0.0997 

[TRAIN] Epoch[2](781/1500); Loss: 0.097283; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1718 0.1351 0.1088 0.1003 0.0898 0.0878 0.0865 0.0858 0.0859 0.0860 0.0862 0.0862 0.0862 0.0864 0.0868 0.0870 

[TRAIN] Epoch[2](782/1500); Loss: 0.087312; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1290 0.1153 0.0889 0.0982 0.0942 0.0886 0.0847 0.0798 0.0777 0.0769 0.0768 0.0770 0.0772 0.0773 0.0774 0.0780 

[TRAIN] Epoch[2](783/1500); Loss: 0.101509; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2059 0.1468 0.1060 0.0935 0.1002 0.0957 0.0896 0.0878 0.0874 0.0874 0.0871 0.0872 0.0875 0.0873 0.0871 0.0875 

[TRAIN] Epoch[2](784/1500); Loss: 0.121763; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1811 0.1417 0.1303 0.1228 0.1172 0.1166 0.1151 0.1143 0.1140 0.1137 0.1136 0.1135 0.1135 0.1136 0.1136 0.1137 

[TRAIN] Epoch[2](785/1500); Loss: 0.110087; Backpropagation: 0.0943 sec; Batch: 0.4298 sec
0.1446 0.1265 0.1155 0.1128 0.1133 0.1120 0.1073 0.1058 0.1047 0.1040 0.1036 0.1035 0.1028 0.1021 0.1016 0.1013 

[TRAIN] Epoch[2](786/1500); Loss: 0.077735; Backpropagation: 0.0939 sec; Batch: 0.4293 sec
0.1256 0.1195 0.1026 0.0917 0.0748 0.0710 0.0678 0.0663 0.0659 0.0655 0.0654 0.0654 0.0653 0.0655 0.0657 0.0658 

[TRAIN] Epoch[2](787/1500); Loss: 0.094451; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.1027 0.1017 0.0951 0.0955 0.0923 0.0914 0.0912 0.0915 0.0919 0.0922 0.0927 0.0933 0.0939 0.0946 0.0952 0.0959 

[TRAIN] Epoch[2](788/1500); Loss: 0.071910; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0920 0.0894 0.0860 0.0761 0.0699 0.0689 0.0677 0.0677 0.0678 0.0674 0.0667 0.0666 0.0664 0.0663 0.0660 0.0657 

[TRAIN] Epoch[2](789/1500); Loss: 0.044628; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1221 0.0930 0.0666 0.0579 0.0375 0.0336 0.0326 0.0316 0.0306 0.0304 0.0300 0.0298 0.0296 0.0294 0.0295 0.0297 

[TRAIN] Epoch[2](790/1500); Loss: 0.042763; Backpropagation: 0.0931 sec; Batch: 0.4275 sec
0.0838 0.0703 0.0376 0.0671 0.0619 0.0512 0.0441 0.0336 0.0304 0.0288 0.0283 0.0286 0.0290 0.0294 0.0299 0.0301 

[TRAIN] Epoch[2](791/1500); Loss: 0.106597; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.2034 0.1656 0.1369 0.1063 0.0981 0.0951 0.0930 0.0917 0.0908 0.0904 0.0897 0.0893 0.0890 0.0888 0.0887 0.0888 

[TRAIN] Epoch[2](792/1500); Loss: 0.070420; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1002 0.0888 0.0841 0.0741 0.0693 0.0677 0.0662 0.0654 0.0647 0.0642 0.0640 0.0638 0.0637 0.0635 0.0635 0.0635 

[TRAIN] Epoch[2](793/1500); Loss: 0.084939; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1111 0.1051 0.1022 0.0920 0.0860 0.0838 0.0824 0.0810 0.0797 0.0787 0.0778 0.0769 0.0763 0.0757 0.0753 0.0751 

[TRAIN] Epoch[2](794/1500); Loss: 0.079513; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.1430 0.1187 0.0920 0.0856 0.0736 0.0722 0.0697 0.0692 0.0689 0.0685 0.0684 0.0684 0.0684 0.0684 0.0685 0.0686 

[TRAIN] Epoch[2](795/1500); Loss: 0.092585; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1177 0.1067 0.1045 0.0952 0.0923 0.0904 0.0889 0.0884 0.0877 0.0874 0.0873 0.0870 0.0870 0.0870 0.0869 0.0870 

[TRAIN] Epoch[2](796/1500); Loss: 0.095685; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1999 0.1555 0.0974 0.1199 0.1124 0.0998 0.0915 0.0782 0.0739 0.0720 0.0715 0.0715 0.0717 0.0715 0.0720 0.0723 

[TRAIN] Epoch[2](797/1500); Loss: 0.050039; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.0617 0.0554 0.0538 0.0538 0.0477 0.0463 0.0461 0.0464 0.0467 0.0472 0.0477 0.0482 0.0488 0.0496 0.0503 0.0509 

[TRAIN] Epoch[2](798/1500); Loss: 0.050948; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1173 0.0933 0.0283 0.0917 0.0970 0.0793 0.0671 0.0425 0.0286 0.0245 0.0242 0.0240 0.0236 0.0245 0.0248 0.0245 

[TRAIN] Epoch[2](799/1500); Loss: 0.055746; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2059 0.1203 0.0616 0.0427 0.0488 0.0435 0.0382 0.0372 0.0367 0.0362 0.0366 0.0365 0.0368 0.0368 0.0370 0.0371 

[TRAIN] Epoch[2](800/1500); Loss: 0.081060; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1827 0.1312 0.1075 0.0908 0.0747 0.0697 0.0656 0.0648 0.0650 0.0642 0.0637 0.0635 0.0634 0.0634 0.0634 0.0634 

[TRAIN] Epoch[2](801/1500); Loss: 0.103371; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1807 0.1439 0.1217 0.1038 0.0956 0.0932 0.0927 0.0917 0.0913 0.0913 0.0913 0.0913 0.0914 0.0913 0.0914 0.0914 

[TRAIN] Epoch[2](802/1500); Loss: 0.092838; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.1269 0.1160 0.1027 0.0957 0.0906 0.0897 0.0881 0.0874 0.0869 0.0866 0.0863 0.0859 0.0859 0.0857 0.0855 0.0854 

[TRAIN] Epoch[2](803/1500); Loss: 0.066238; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.0949 0.0935 0.0878 0.0702 0.0623 0.0613 0.0601 0.0595 0.0590 0.0588 0.0585 0.0582 0.0586 0.0588 0.0589 0.0592 

[TRAIN] Epoch[2](804/1500); Loss: 0.051561; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.1029 0.0844 0.0729 0.0573 0.0478 0.0453 0.0428 0.0417 0.0414 0.0412 0.0411 0.0412 0.0412 0.0411 0.0412 0.0415 

[TRAIN] Epoch[2](805/1500); Loss: 0.105846; Backpropagation: 0.0935 sec; Batch: 0.4293 sec
0.1393 0.1246 0.1144 0.1096 0.1049 0.1026 0.1008 0.1000 0.0998 0.0997 0.0998 0.0996 0.0994 0.0995 0.0997 0.0997 

[TRAIN] Epoch[2](806/1500); Loss: 0.082411; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1466 0.1210 0.1055 0.0833 0.0759 0.0734 0.0727 0.0719 0.0715 0.0712 0.0711 0.0709 0.0708 0.0709 0.0709 0.0709 

[TRAIN] Epoch[2](807/1500); Loss: 0.202519; Backpropagation: 0.0931 sec; Batch: 0.4275 sec
0.3425 0.2881 0.2529 0.2341 0.2070 0.1983 0.1822 0.1728 0.1690 0.1697 0.1701 0.1698 0.1702 0.1710 0.1712 0.1714 

[TRAIN] Epoch[2](808/1500); Loss: 0.118823; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1627 0.1429 0.1300 0.1187 0.1147 0.1139 0.1130 0.1125 0.1121 0.1118 0.1117 0.1115 0.1114 0.1114 0.1115 0.1116 

[TRAIN] Epoch[2](809/1500); Loss: 0.135425; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1939 0.1737 0.1549 0.1443 0.1348 0.1325 0.1286 0.1262 0.1248 0.1235 0.1225 0.1217 0.1215 0.1213 0.1212 0.1213 

[TRAIN] Epoch[2](810/1500); Loss: 0.105984; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1676 0.1441 0.1181 0.1117 0.1027 0.1004 0.0983 0.0969 0.0960 0.0952 0.0948 0.0945 0.0941 0.0938 0.0938 0.0937 

[TRAIN] Epoch[2](811/1500); Loss: 0.119941; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1476 0.1378 0.1278 0.1255 0.1192 0.1175 0.1162 0.1153 0.1145 0.1142 0.1139 0.1137 0.1138 0.1140 0.1139 0.1140 

[TRAIN] Epoch[2](812/1500); Loss: 0.090288; Backpropagation: 0.0931 sec; Batch: 0.4301 sec
0.2373 0.1653 0.1202 0.1004 0.0768 0.0736 0.0695 0.0676 0.0668 0.0663 0.0663 0.0664 0.0667 0.0669 0.0671 0.0673 

[TRAIN] Epoch[2](813/1500); Loss: 0.132999; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1713 0.1549 0.1462 0.1383 0.1327 0.1311 0.1291 0.1274 0.1265 0.1259 0.1254 0.1246 0.1241 0.1238 0.1235 0.1233 

[TRAIN] Epoch[2](814/1500); Loss: 0.094761; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1702 0.1439 0.1119 0.1034 0.0947 0.0932 0.0857 0.0840 0.0829 0.0817 0.0803 0.0790 0.0778 0.0768 0.0758 0.0750 

[TRAIN] Epoch[2](815/1500); Loss: 0.095838; Backpropagation: 0.0939 sec; Batch: 0.4343 sec
0.1714 0.1396 0.1101 0.0990 0.0926 0.0893 0.0861 0.0846 0.0834 0.0833 0.0829 0.0826 0.0824 0.0820 0.0821 0.0821 

[TRAIN] Epoch[2](816/1500); Loss: 0.082151; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1412 0.0895 0.0840 0.0830 0.0803 0.0768 0.0758 0.0755 0.0756 0.0757 0.0758 0.0760 0.0760 0.0762 0.0764 0.0767 

[TRAIN] Epoch[2](817/1500); Loss: 0.095624; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1244 0.1086 0.0976 0.0954 0.0942 0.0934 0.0919 0.0917 0.0915 0.0915 0.0915 0.0914 0.0915 0.0917 0.0919 0.0920 

[TRAIN] Epoch[2](818/1500); Loss: 0.117129; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1492 0.1307 0.1191 0.1167 0.1156 0.1155 0.1144 0.1137 0.1133 0.1128 0.1126 0.1124 0.1122 0.1119 0.1120 0.1120 

[TRAIN] Epoch[2](819/1500); Loss: 0.055918; Backpropagation: 0.0934 sec; Batch: 0.4492 sec
0.1025 0.0888 0.0641 0.0641 0.0527 0.0501 0.0485 0.0476 0.0470 0.0467 0.0468 0.0470 0.0470 0.0473 0.0471 0.0473 

[TRAIN] Epoch[2](820/1500); Loss: 0.063113; Backpropagation: 0.0940 sec; Batch: 0.4277 sec
0.0888 0.0756 0.0644 0.0628 0.0601 0.0593 0.0584 0.0582 0.0585 0.0590 0.0592 0.0597 0.0604 0.0610 0.0618 0.0627 

[TRAIN] Epoch[2](821/1500); Loss: 0.092981; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1461 0.1184 0.1141 0.0992 0.0919 0.0894 0.0865 0.0844 0.0831 0.0826 0.0824 0.0819 0.0817 0.0817 0.0821 0.0821 

[TRAIN] Epoch[2](822/1500); Loss: 0.086689; Backpropagation: 0.0931 sec; Batch: 0.4689 sec
0.1521 0.1208 0.1013 0.0929 0.0834 0.0807 0.0776 0.0760 0.0757 0.0754 0.0751 0.0751 0.0751 0.0751 0.0752 0.0754 

[TRAIN] Epoch[2](823/1500); Loss: 0.104025; Backpropagation: 0.0924 sec; Batch: 0.4263 sec
0.1344 0.1173 0.1110 0.1078 0.1053 0.1036 0.1020 0.1008 0.0997 0.0988 0.0982 0.0978 0.0975 0.0970 0.0967 0.0964 

[TRAIN] Epoch[2](824/1500); Loss: 0.117984; Backpropagation: 0.0922 sec; Batch: 0.4260 sec
0.1436 0.1263 0.1240 0.1201 0.1173 0.1162 0.1151 0.1146 0.1140 0.1136 0.1139 0.1138 0.1137 0.1139 0.1139 0.1138 

[TRAIN] Epoch[2](825/1500); Loss: 0.115398; Backpropagation: 0.0937 sec; Batch: 0.4290 sec
0.1974 0.1570 0.1381 0.1286 0.1169 0.1131 0.1064 0.1015 0.0987 0.0995 0.0989 0.0981 0.0980 0.0981 0.0980 0.0980 

[TRAIN] Epoch[2](826/1500); Loss: 0.085523; Backpropagation: 0.0939 sec; Batch: 0.4295 sec
0.0945 0.0969 0.1056 0.0920 0.0844 0.0832 0.0823 0.0817 0.0813 0.0812 0.0810 0.0807 0.0807 0.0808 0.0809 0.0812 

[TRAIN] Epoch[2](827/1500); Loss: 0.071985; Backpropagation: 0.0932 sec; Batch: 0.4288 sec
0.1368 0.0965 0.0796 0.0740 0.0697 0.0658 0.0640 0.0634 0.0630 0.0628 0.0628 0.0628 0.0627 0.0626 0.0627 0.0627 

[TRAIN] Epoch[2](828/1500); Loss: 0.101649; Backpropagation: 0.0924 sec; Batch: 0.4265 sec
0.1679 0.1491 0.1201 0.0986 0.0945 0.0938 0.0913 0.0910 0.0903 0.0898 0.0899 0.0898 0.0898 0.0899 0.0901 0.0905 

[TRAIN] Epoch[2](829/1500); Loss: 0.063120; Backpropagation: 0.0923 sec; Batch: 0.4264 sec
0.0988 0.0823 0.0672 0.0666 0.0615 0.0602 0.0580 0.0571 0.0569 0.0565 0.0564 0.0568 0.0572 0.0576 0.0581 0.0587 

[TRAIN] Epoch[2](830/1500); Loss: 0.093849; Backpropagation: 0.0925 sec; Batch: 0.4263 sec
0.1232 0.1116 0.0968 0.0938 0.0910 0.0907 0.0894 0.0892 0.0891 0.0888 0.0889 0.0892 0.0897 0.0899 0.0901 0.0902 

[TRAIN] Epoch[2](831/1500); Loss: 0.101017; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1356 0.1212 0.1055 0.1043 0.0991 0.0977 0.0965 0.0959 0.0958 0.0954 0.0950 0.0951 0.0951 0.0948 0.0947 0.0947 

[TRAIN] Epoch[2](832/1500); Loss: 0.099515; Backpropagation: 0.0946 sec; Batch: 0.4295 sec
0.1340 0.1187 0.1071 0.1028 0.0973 0.0963 0.0946 0.0943 0.0940 0.0938 0.0936 0.0933 0.0931 0.0932 0.0932 0.0931 

[TRAIN] Epoch[2](833/1500); Loss: 0.081542; Backpropagation: 0.0938 sec; Batch: 0.4651 sec
0.2131 0.1361 0.0901 0.0679 0.0772 0.0735 0.0633 0.0634 0.0626 0.0631 0.0646 0.0652 0.0654 0.0659 0.0663 0.0670 

[TRAIN] Epoch[2](834/1500); Loss: 0.106476; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1327 0.1163 0.1141 0.1104 0.1068 0.1051 0.1035 0.1029 0.1023 0.1020 0.1017 0.1014 0.1012 0.1013 0.1009 0.1009 

[TRAIN] Epoch[2](835/1500); Loss: 0.107610; Backpropagation: 0.0945 sec; Batch: 0.4288 sec
0.1502 0.1247 0.1121 0.1088 0.1076 0.1063 0.1042 0.1034 0.1025 0.1017 0.1009 0.1004 0.1003 0.0999 0.0995 0.0994 

[TRAIN] Epoch[2](836/1500); Loss: 0.057702; Backpropagation: 0.0923 sec; Batch: 0.4267 sec
0.1043 0.0759 0.0587 0.0573 0.0556 0.0539 0.0524 0.0519 0.0516 0.0516 0.0514 0.0515 0.0516 0.0517 0.0519 0.0518 

[TRAIN] Epoch[2](837/1500); Loss: 0.111084; Backpropagation: 0.0937 sec; Batch: 0.4521 sec
0.1640 0.1421 0.1276 0.1168 0.1097 0.1076 0.1053 0.1029 0.1013 0.1009 0.1006 0.1001 0.0999 0.0997 0.0994 0.0994 

[TRAIN] Epoch[2](838/1500); Loss: 0.058726; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.0985 0.0672 0.0615 0.0592 0.0564 0.0544 0.0545 0.0544 0.0544 0.0543 0.0542 0.0543 0.0542 0.0538 0.0543 0.0541 

[TRAIN] Epoch[2](839/1500); Loss: 0.060952; Backpropagation: 0.0954 sec; Batch: 0.4307 sec
0.1544 0.1206 0.0733 0.0639 0.0519 0.0552 0.0467 0.0448 0.0442 0.0443 0.0449 0.0450 0.0454 0.0464 0.0468 0.0476 

[TRAIN] Epoch[2](840/1500); Loss: 0.084126; Backpropagation: 0.0946 sec; Batch: 0.4289 sec
0.1281 0.1063 0.0877 0.0845 0.0820 0.0809 0.0786 0.0780 0.0778 0.0774 0.0775 0.0774 0.0775 0.0775 0.0774 0.0776 

[TRAIN] Epoch[2](841/1500); Loss: 0.039457; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.0615 0.0596 0.0807 0.0550 0.0353 0.0334 0.0322 0.0303 0.0295 0.0296 0.0299 0.0300 0.0305 0.0308 0.0312 0.0319 

[TRAIN] Epoch[2](842/1500); Loss: 0.070688; Backpropagation: 0.0931 sec; Batch: 0.4296 sec
0.1058 0.0819 0.0788 0.0728 0.0704 0.0686 0.0668 0.0660 0.0657 0.0653 0.0650 0.0649 0.0648 0.0647 0.0647 0.0646 

[TRAIN] Epoch[2](843/1500); Loss: 0.077642; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1317 0.0983 0.0886 0.0802 0.0739 0.0723 0.0713 0.0707 0.0698 0.0692 0.0696 0.0690 0.0690 0.0696 0.0695 0.0694 

[TRAIN] Epoch[2](844/1500); Loss: 0.083970; Backpropagation: 0.0946 sec; Batch: 0.4297 sec
0.1157 0.0953 0.0895 0.0845 0.0824 0.0820 0.0804 0.0795 0.0794 0.0793 0.0794 0.0793 0.0791 0.0791 0.0793 0.0792 

[TRAIN] Epoch[2](845/1500); Loss: 0.128273; Backpropagation: 0.0957 sec; Batch: 0.4325 sec
0.1724 0.1448 0.1360 0.1297 0.1254 0.1240 0.1231 0.1222 0.1218 0.1214 0.1214 0.1214 0.1218 0.1220 0.1223 0.1228 

[TRAIN] Epoch[2](846/1500); Loss: 0.139930; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1769 0.1510 0.1449 0.1397 0.1375 0.1368 0.1360 0.1357 0.1355 0.1351 0.1352 0.1350 0.1349 0.1349 0.1349 0.1349 

[TRAIN] Epoch[2](847/1500); Loss: 0.103231; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1785 0.1248 0.1058 0.0987 0.0993 0.0978 0.0958 0.0951 0.0950 0.0947 0.0945 0.0944 0.0944 0.0942 0.0943 0.0943 

[TRAIN] Epoch[2](848/1500); Loss: 0.059549; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1061 0.0695 0.0806 0.0626 0.0567 0.0542 0.0537 0.0527 0.0523 0.0520 0.0521 0.0519 0.0521 0.0524 0.0520 0.0520 

[TRAIN] Epoch[2](849/1500); Loss: 0.108190; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1627 0.1208 0.1180 0.1091 0.1041 0.1032 0.1024 0.1017 0.1014 0.1012 0.1012 0.1010 0.1010 0.1011 0.1010 0.1010 

[TRAIN] Epoch[2](850/1500); Loss: 0.126468; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.3030 0.2132 0.1699 0.1315 0.1124 0.1062 0.1032 0.1008 0.0994 0.0986 0.0982 0.0977 0.0975 0.0972 0.0973 0.0973 

[TRAIN] Epoch[2](851/1500); Loss: 0.177994; Backpropagation: 0.0937 sec; Batch: 0.4727 sec
0.2561 0.2207 0.2096 0.1933 0.1869 0.1839 0.1812 0.1776 0.1724 0.1665 0.1618 0.1574 0.1515 0.1472 0.1433 0.1385 

[TRAIN] Epoch[2](852/1500); Loss: 0.121779; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.3659 0.2456 0.1885 0.1358 0.1089 0.0976 0.0900 0.0844 0.0814 0.0797 0.0790 0.0785 0.0782 0.0781 0.0782 0.0785 

[TRAIN] Epoch[2](853/1500); Loss: 0.118409; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.2297 0.1817 0.1496 0.1252 0.1133 0.1073 0.1031 0.1005 0.0990 0.0980 0.0977 0.0977 0.0976 0.0977 0.0980 0.0985 

[TRAIN] Epoch[2](854/1500); Loss: 0.133028; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2095 0.1701 0.1550 0.1442 0.1325 0.1279 0.1234 0.1204 0.1195 0.1188 0.1182 0.1179 0.1178 0.1179 0.1177 0.1176 

[TRAIN] Epoch[2](855/1500); Loss: 0.071224; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1447 0.0892 0.0718 0.0685 0.0640 0.0627 0.0622 0.0618 0.0624 0.0626 0.0631 0.0636 0.0640 0.0654 0.0663 0.0671 

[TRAIN] Epoch[2](856/1500); Loss: 0.144121; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2033 0.1572 0.1445 0.1440 0.1394 0.1377 0.1375 0.1379 0.1379 0.1378 0.1378 0.1379 0.1379 0.1382 0.1383 0.1386 

[TRAIN] Epoch[2](857/1500); Loss: 0.071491; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1644 0.0985 0.0765 0.0659 0.0634 0.0619 0.0611 0.0611 0.0607 0.0614 0.0611 0.0610 0.0615 0.0614 0.0616 0.0621 

[TRAIN] Epoch[2](858/1500); Loss: 0.102890; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1695 0.1198 0.1079 0.1028 0.0984 0.0972 0.0963 0.0958 0.0953 0.0953 0.0951 0.0951 0.0947 0.0944 0.0944 0.0944 

[TRAIN] Epoch[2](859/1500); Loss: 0.135705; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1688 0.1501 0.1380 0.1357 0.1331 0.1315 0.1311 0.1311 0.1314 0.1315 0.1310 0.1310 0.1315 0.1317 0.1318 0.1320 

[TRAIN] Epoch[2](860/1500); Loss: 0.109085; Backpropagation: 0.0933 sec; Batch: 0.4289 sec
0.2334 0.1829 0.1449 0.1293 0.1027 0.0944 0.0883 0.0854 0.0849 0.0850 0.0853 0.0854 0.0856 0.0857 0.0859 0.0865 

[TRAIN] Epoch[2](861/1500); Loss: 0.080194; Backpropagation: 0.0940 sec; Batch: 0.4293 sec
0.1973 0.1324 0.0887 0.0773 0.0707 0.0679 0.0673 0.0666 0.0656 0.0647 0.0641 0.0640 0.0641 0.0641 0.0643 0.0641 

[TRAIN] Epoch[2](862/1500); Loss: 0.109269; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.1527 0.1390 0.1153 0.1082 0.1046 0.1040 0.1036 0.1032 0.1028 0.1028 0.1024 0.1019 0.1021 0.1019 0.1019 0.1017 

[TRAIN] Epoch[2](863/1500); Loss: 0.104996; Backpropagation: 0.0943 sec; Batch: 0.4293 sec
0.1381 0.1208 0.1113 0.1062 0.1024 0.1008 0.1005 0.1000 0.0998 0.1000 0.0996 0.0999 0.1001 0.1002 0.1000 0.1002 

[TRAIN] Epoch[2](864/1500); Loss: 0.105142; Backpropagation: 0.0936 sec; Batch: 0.4703 sec
0.1717 0.1312 0.1102 0.1007 0.0977 0.0973 0.0967 0.0965 0.0968 0.0970 0.0969 0.0971 0.0972 0.0978 0.0985 0.0990 

[TRAIN] Epoch[2](865/1500); Loss: 0.124139; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.2463 0.1827 0.1408 0.1172 0.1118 0.1095 0.1080 0.1081 0.1083 0.1083 0.1076 0.1075 0.1075 0.1072 0.1073 0.1078 

[TRAIN] Epoch[2](866/1500); Loss: 0.103234; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1420 0.1149 0.1077 0.1027 0.0991 0.0978 0.0973 0.0979 0.0978 0.0980 0.0988 0.0987 0.0989 0.0997 0.1001 0.1003 

[TRAIN] Epoch[2](867/1500); Loss: 0.117479; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1364 0.1332 0.1218 0.1167 0.1156 0.1141 0.1139 0.1145 0.1136 0.1141 0.1144 0.1143 0.1142 0.1141 0.1145 0.1144 

[TRAIN] Epoch[2](868/1500); Loss: 0.102620; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1734 0.1556 0.1206 0.1023 0.0961 0.0919 0.0899 0.0890 0.0893 0.0897 0.0900 0.0900 0.0908 0.0909 0.0913 0.0910 

[TRAIN] Epoch[2](869/1500); Loss: 0.147492; Backpropagation: 0.0931 sec; Batch: 0.4680 sec
0.2237 0.1968 0.1658 0.1558 0.1428 0.1388 0.1358 0.1342 0.1336 0.1332 0.1333 0.1332 0.1331 0.1332 0.1333 0.1332 

[TRAIN] Epoch[2](870/1500); Loss: 0.073750; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1479 0.0906 0.0792 0.0738 0.0707 0.0685 0.0665 0.0660 0.0654 0.0649 0.0645 0.0645 0.0645 0.0641 0.0641 0.0646 

[TRAIN] Epoch[2](871/1500); Loss: 0.199041; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.3395 0.2960 0.2477 0.2310 0.1914 0.1806 0.1729 0.1702 0.1692 0.1686 0.1687 0.1690 0.1696 0.1699 0.1698 0.1705 

[TRAIN] Epoch[2](872/1500); Loss: 0.074255; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1058 0.0897 0.0750 0.0758 0.0715 0.0698 0.0693 0.0697 0.0695 0.0697 0.0700 0.0700 0.0701 0.0705 0.0707 0.0710 

[TRAIN] Epoch[2](873/1500); Loss: 0.089674; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1244 0.1075 0.0891 0.0834 0.0824 0.0815 0.0816 0.0829 0.0836 0.0844 0.0858 0.0868 0.0880 0.0896 0.0911 0.0928 

[TRAIN] Epoch[2](874/1500); Loss: 0.059545; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1742 0.1295 0.0663 0.0653 0.0584 0.0383 0.0371 0.0379 0.0384 0.0404 0.0411 0.0417 0.0436 0.0452 0.0463 0.0488 

[TRAIN] Epoch[2](875/1500); Loss: 0.134119; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1998 0.1637 0.1499 0.1382 0.1271 0.1251 0.1249 0.1247 0.1240 0.1242 0.1240 0.1237 0.1242 0.1240 0.1240 0.1243 

[TRAIN] Epoch[2](876/1500); Loss: 0.057000; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.0683 0.0751 0.0626 0.0571 0.0572 0.0558 0.0541 0.0544 0.0534 0.0530 0.0533 0.0532 0.0535 0.0537 0.0538 0.0535 

[TRAIN] Epoch[2](877/1500); Loss: 0.132054; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1564 0.1392 0.1324 0.1287 0.1279 0.1275 0.1277 0.1286 0.1289 0.1289 0.1293 0.1299 0.1307 0.1314 0.1322 0.1333 

[TRAIN] Epoch[2](878/1500); Loss: 0.136517; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1897 0.1584 0.1415 0.1354 0.1332 0.1313 0.1304 0.1301 0.1299 0.1298 0.1295 0.1294 0.1290 0.1290 0.1288 0.1289 

[TRAIN] Epoch[2](879/1500); Loss: 0.061607; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.0896 0.0806 0.0747 0.0684 0.0619 0.0588 0.0575 0.0567 0.0558 0.0552 0.0549 0.0544 0.0544 0.0544 0.0543 0.0543 

[TRAIN] Epoch[2](880/1500); Loss: 0.088043; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1360 0.1109 0.1017 0.0927 0.0827 0.0802 0.0800 0.0799 0.0796 0.0800 0.0802 0.0804 0.0806 0.0810 0.0812 0.0816 

[TRAIN] Epoch[2](881/1500); Loss: 0.087546; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1196 0.1010 0.0971 0.0910 0.0856 0.0844 0.0836 0.0829 0.0825 0.0821 0.0819 0.0818 0.0818 0.0817 0.0816 0.0819 

[TRAIN] Epoch[2](882/1500); Loss: 0.145379; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1565 0.1528 0.1614 0.1544 0.1441 0.1431 0.1427 0.1416 0.1417 0.1416 0.1407 0.1416 0.1411 0.1405 0.1413 0.1410 

[TRAIN] Epoch[2](883/1500); Loss: 0.080934; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2194 0.1494 0.0992 0.0925 0.0719 0.0661 0.0615 0.0598 0.0591 0.0590 0.0591 0.0590 0.0594 0.0595 0.0598 0.0601 

[TRAIN] Epoch[2](884/1500); Loss: 0.090810; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1205 0.1006 0.0939 0.0939 0.0903 0.0878 0.0871 0.0872 0.0867 0.0867 0.0867 0.0862 0.0865 0.0865 0.0860 0.0863 

[TRAIN] Epoch[2](885/1500); Loss: 0.106985; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1916 0.1527 0.1235 0.1086 0.0995 0.0987 0.0951 0.0939 0.0933 0.0932 0.0931 0.0935 0.0936 0.0939 0.0936 0.0939 

[TRAIN] Epoch[2](886/1500); Loss: 0.139467; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.2078 0.1767 0.1554 0.1423 0.1347 0.1329 0.1302 0.1286 0.1280 0.1280 0.1278 0.1277 0.1276 0.1278 0.1279 0.1282 

[TRAIN] Epoch[2](887/1500); Loss: 0.071829; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1797 0.1475 0.0866 0.0564 0.0450 0.0693 0.0632 0.0520 0.0528 0.0529 0.0547 0.0556 0.0560 0.0581 0.0595 0.0601 

[TRAIN] Epoch[2](888/1500); Loss: 0.079227; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2085 0.1629 0.1160 0.0794 0.0623 0.0595 0.0612 0.0574 0.0566 0.0570 0.0570 0.0573 0.0574 0.0576 0.0587 0.0589 

[TRAIN] Epoch[2](889/1500); Loss: 0.096669; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1353 0.1217 0.1170 0.1256 0.1214 0.1079 0.0980 0.0957 0.0918 0.0869 0.0831 0.0796 0.0757 0.0725 0.0689 0.0657 

[TRAIN] Epoch[2](890/1500); Loss: 0.040536; Backpropagation: 0.0938 sec; Batch: 0.4291 sec
0.0945 0.0564 0.0554 0.0435 0.0347 0.0331 0.0329 0.0317 0.0318 0.0323 0.0325 0.0328 0.0337 0.0338 0.0342 0.0354 

[TRAIN] Epoch[2](891/1500); Loss: 0.106182; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1709 0.1355 0.1212 0.1058 0.1002 0.1005 0.0987 0.0973 0.0964 0.0963 0.0964 0.0960 0.0958 0.0960 0.0960 0.0959 

[TRAIN] Epoch[2](892/1500); Loss: 0.112368; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1488 0.1243 0.1253 0.1172 0.1106 0.1088 0.1077 0.1071 0.1065 0.1061 0.1061 0.1062 0.1059 0.1060 0.1058 0.1056 

[TRAIN] Epoch[2](893/1500); Loss: 0.056796; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.0670 0.0711 0.0673 0.0591 0.0538 0.0539 0.0528 0.0530 0.0532 0.0531 0.0529 0.0540 0.0539 0.0541 0.0544 0.0550 

[TRAIN] Epoch[2](894/1500); Loss: 0.141510; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.2048 0.1718 0.1500 0.1424 0.1414 0.1385 0.1345 0.1333 0.1323 0.1316 0.1315 0.1310 0.1306 0.1302 0.1300 0.1301 

[TRAIN] Epoch[2](895/1500); Loss: 0.130626; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1635 0.1444 0.1432 0.1368 0.1299 0.1281 0.1263 0.1247 0.1243 0.1241 0.1242 0.1241 0.1240 0.1241 0.1238 0.1243 

[TRAIN] Epoch[2](896/1500); Loss: 0.117017; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1549 0.1423 0.1254 0.1193 0.1125 0.1127 0.1113 0.1106 0.1104 0.1105 0.1105 0.1102 0.1102 0.1104 0.1104 0.1106 

[TRAIN] Epoch[2](897/1500); Loss: 0.097866; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1273 0.1103 0.1015 0.0993 0.0949 0.0941 0.0937 0.0936 0.0935 0.0936 0.0936 0.0939 0.0940 0.0940 0.0943 0.0942 

[TRAIN] Epoch[2](898/1500); Loss: 0.060911; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1114 0.0889 0.0661 0.0625 0.0571 0.0561 0.0529 0.0526 0.0529 0.0532 0.0533 0.0531 0.0534 0.0535 0.0534 0.0542 

[TRAIN] Epoch[2](899/1500); Loss: 0.096355; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1606 0.1209 0.1260 0.1063 0.0920 0.0897 0.0873 0.0855 0.0851 0.0847 0.0843 0.0840 0.0841 0.0839 0.0837 0.0837 

[TRAIN] Epoch[2](900/1500); Loss: 0.106257; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1447 0.1271 0.1159 0.1061 0.1048 0.1033 0.1013 0.1000 0.0999 0.0998 0.0991 0.0996 0.0995 0.0997 0.0999 0.0996 

[TRAIN] Epoch[2](901/1500); Loss: 0.144108; Backpropagation: 0.0932 sec; Batch: 0.4281 sec
0.1689 0.1553 0.1526 0.1478 0.1445 0.1424 0.1409 0.1402 0.1397 0.1395 0.1394 0.1392 0.1391 0.1389 0.1386 0.1387 

[TRAIN] Epoch[2](902/1500); Loss: 0.127298; Backpropagation: 0.0944 sec; Batch: 0.4299 sec
0.2365 0.1898 0.1492 0.1297 0.1193 0.1173 0.1137 0.1118 0.1106 0.1094 0.1087 0.1089 0.1084 0.1079 0.1080 0.1076 

[TRAIN] Epoch[2](903/1500); Loss: 0.053093; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.0985 0.0763 0.0755 0.0618 0.0518 0.0477 0.0460 0.0441 0.0439 0.0435 0.0431 0.0437 0.0431 0.0431 0.0435 0.0440 

[TRAIN] Epoch[2](904/1500); Loss: 0.134279; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1533 0.1467 0.1479 0.1392 0.1339 0.1328 0.1314 0.1307 0.1301 0.1296 0.1292 0.1288 0.1288 0.1288 0.1287 0.1287 

[TRAIN] Epoch[2](905/1500); Loss: 0.137876; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2472 0.2020 0.1734 0.1580 0.1316 0.1255 0.1177 0.1209 0.1196 0.1166 0.1158 0.1154 0.1156 0.1154 0.1156 0.1157 

[TRAIN] Epoch[2](906/1500); Loss: 0.130839; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2177 0.1848 0.1610 0.1411 0.1237 0.1203 0.1159 0.1141 0.1148 0.1145 0.1141 0.1141 0.1141 0.1143 0.1143 0.1145 

[TRAIN] Epoch[2](907/1500); Loss: 0.108905; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1826 0.1654 0.1275 0.1133 0.1044 0.1034 0.0997 0.0954 0.0944 0.0941 0.0940 0.0935 0.0935 0.0943 0.0934 0.0936 

[TRAIN] Epoch[2](908/1500); Loss: 0.049266; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1503 0.0881 0.0567 0.0474 0.0477 0.0408 0.0359 0.0360 0.0354 0.0351 0.0352 0.0352 0.0358 0.0359 0.0363 0.0366 

[TRAIN] Epoch[2](909/1500); Loss: 0.082571; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1254 0.1167 0.0931 0.0841 0.0799 0.0795 0.0763 0.0744 0.0745 0.0741 0.0737 0.0739 0.0739 0.0739 0.0738 0.0739 

[TRAIN] Epoch[2](910/1500); Loss: 0.064205; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1007 0.0864 0.0815 0.0678 0.0622 0.0588 0.0564 0.0562 0.0562 0.0561 0.0565 0.0570 0.0571 0.0577 0.0582 0.0585 

[TRAIN] Epoch[2](911/1500); Loss: 0.080783; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1474 0.1346 0.1014 0.0747 0.0741 0.0764 0.0719 0.0685 0.0685 0.0682 0.0675 0.0678 0.0678 0.0676 0.0679 0.0682 

[TRAIN] Epoch[2](912/1500); Loss: 0.041849; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1193 0.0789 0.0608 0.0518 0.0424 0.0332 0.0303 0.0288 0.0286 0.0280 0.0278 0.0280 0.0282 0.0280 0.0277 0.0280 

[TRAIN] Epoch[2](913/1500); Loss: 0.067764; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.0859 0.0905 0.0915 0.0738 0.0656 0.0643 0.0631 0.0622 0.0617 0.0614 0.0608 0.0608 0.0607 0.0606 0.0606 0.0606 

[TRAIN] Epoch[2](914/1500); Loss: 0.057633; Backpropagation: 0.0938 sec; Batch: 0.4312 sec
0.1235 0.1133 0.0768 0.0489 0.0487 0.0539 0.0499 0.0456 0.0453 0.0445 0.0452 0.0449 0.0451 0.0453 0.0454 0.0457 

[TRAIN] Epoch[2](915/1500); Loss: 0.092904; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1255 0.1080 0.1116 0.0968 0.0893 0.0880 0.0874 0.0871 0.0867 0.0865 0.0864 0.0865 0.0867 0.0866 0.0866 0.0869 

[TRAIN] Epoch[2](916/1500); Loss: 0.106942; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1351 0.1191 0.1313 0.1201 0.1102 0.1050 0.1027 0.1012 0.1002 0.0993 0.0986 0.0984 0.0978 0.0975 0.0973 0.0971 

[TRAIN] Epoch[2](917/1500); Loss: 0.037301; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1165 0.1043 0.0570 0.0303 0.0272 0.0326 0.0274 0.0218 0.0214 0.0212 0.0222 0.0224 0.0221 0.0235 0.0232 0.0239 

[TRAIN] Epoch[2](918/1500); Loss: 0.093096; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1176 0.1124 0.1031 0.0945 0.0910 0.0902 0.0892 0.0884 0.0881 0.0881 0.0878 0.0877 0.0879 0.0878 0.0879 0.0879 

[TRAIN] Epoch[2](919/1500); Loss: 0.146880; Backpropagation: 0.0933 sec; Batch: 0.4286 sec
0.2836 0.2385 0.2067 0.1904 0.1622 0.1515 0.1367 0.1213 0.1116 0.1068 0.1082 0.1076 0.1067 0.1064 0.1060 0.1058 

[TRAIN] Epoch[2](920/1500); Loss: 0.134457; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1853 0.1633 0.1437 0.1366 0.1360 0.1345 0.1310 0.1277 0.1263 0.1251 0.1246 0.1239 0.1236 0.1236 0.1233 0.1229 

[TRAIN] Epoch[2](921/1500); Loss: 0.152182; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2817 0.2301 0.1967 0.1803 0.1512 0.1422 0.1308 0.1257 0.1270 0.1256 0.1244 0.1240 0.1239 0.1240 0.1240 0.1236 

[TRAIN] Epoch[2](922/1500); Loss: 0.114833; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.1442 0.1279 0.1266 0.1226 0.1179 0.1144 0.1121 0.1105 0.1092 0.1083 0.1081 0.1077 0.1073 0.1070 0.1069 0.1065 

[TRAIN] Epoch[2](923/1500); Loss: 0.069130; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1516 0.1152 0.0883 0.0811 0.0697 0.0665 0.0600 0.0556 0.0538 0.0532 0.0525 0.0522 0.0519 0.0517 0.0516 0.0513 

[TRAIN] Epoch[2](924/1500); Loss: 0.068029; Backpropagation: 0.0930 sec; Batch: 0.4273 sec
0.1198 0.1043 0.0762 0.0718 0.0668 0.0660 0.0616 0.0598 0.0590 0.0581 0.0577 0.0576 0.0574 0.0574 0.0574 0.0574 

[TRAIN] Epoch[2](925/1500); Loss: 0.108643; Backpropagation: 0.0947 sec; Batch: 0.4300 sec
0.1740 0.1423 0.1218 0.1154 0.1084 0.1055 0.1014 0.0997 0.0986 0.0973 0.0966 0.0963 0.0958 0.0954 0.0950 0.0949 

[TRAIN] Epoch[2](926/1500); Loss: 0.127198; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1715 0.1476 0.1301 0.1292 0.1348 0.1338 0.1278 0.1227 0.1197 0.1179 0.1172 0.1169 0.1165 0.1165 0.1164 0.1167 

[TRAIN] Epoch[2](927/1500); Loss: 0.095637; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1390 0.1219 0.1078 0.0996 0.0950 0.0943 0.0910 0.0881 0.0869 0.0868 0.0868 0.0866 0.0864 0.0868 0.0867 0.0864 

[TRAIN] Epoch[2](928/1500); Loss: 0.077478; Backpropagation: 0.0932 sec; Batch: 0.4282 sec
0.1382 0.1075 0.0917 0.0829 0.0749 0.0760 0.0714 0.0681 0.0663 0.0657 0.0656 0.0656 0.0660 0.0664 0.0664 0.0669 

[TRAIN] Epoch[2](929/1500); Loss: 0.093578; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1273 0.1177 0.1031 0.0963 0.0973 0.0944 0.0899 0.0874 0.0862 0.0858 0.0856 0.0854 0.0853 0.0852 0.0851 0.0851 

[TRAIN] Epoch[2](930/1500); Loss: 0.060536; Backpropagation: 0.0931 sec; Batch: 0.4274 sec
0.1195 0.0798 0.0601 0.0618 0.0642 0.0584 0.0544 0.0527 0.0521 0.0522 0.0522 0.0522 0.0524 0.0521 0.0522 0.0523 

[TRAIN] Epoch[2](931/1500); Loss: 0.126432; Backpropagation: 0.0958 sec; Batch: 0.4313 sec
0.1983 0.1912 0.1431 0.1205 0.1032 0.1035 0.1097 0.1108 0.1112 0.1113 0.1122 0.1145 0.1176 0.1211 0.1251 0.1295 

[TRAIN] Epoch[2](932/1500); Loss: 0.041460; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.0652 0.0537 0.0418 0.0415 0.0405 0.0376 0.0367 0.0368 0.0369 0.0373 0.0378 0.0382 0.0387 0.0395 0.0403 0.0409 

[TRAIN] Epoch[2](933/1500); Loss: 0.042526; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.0987 0.0841 0.0437 0.0646 0.0565 0.0366 0.0297 0.0279 0.0294 0.0289 0.0287 0.0300 0.0293 0.0297 0.0316 0.0310 

[TRAIN] Epoch[2](934/1500); Loss: 0.057110; Backpropagation: 0.0936 sec; Batch: 0.4562 sec
0.1096 0.1136 0.0754 0.0557 0.0506 0.0508 0.0484 0.0461 0.0458 0.0453 0.0452 0.0454 0.0452 0.0453 0.0455 0.0456 

[TRAIN] Epoch[2](935/1500); Loss: 0.099612; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2255 0.1756 0.1394 0.1277 0.1042 0.0943 0.0827 0.0733 0.0720 0.0717 0.0714 0.0713 0.0708 0.0711 0.0716 0.0712 

[TRAIN] Epoch[2](936/1500); Loss: 0.092418; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1340 0.1133 0.1024 0.0966 0.0946 0.0920 0.0880 0.0858 0.0849 0.0844 0.0840 0.0840 0.0839 0.0837 0.0836 0.0836 

[TRAIN] Epoch[2](937/1500); Loss: 0.107818; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1757 0.1585 0.1369 0.1258 0.1118 0.1087 0.1030 0.0972 0.0936 0.0910 0.0895 0.0884 0.0872 0.0865 0.0860 0.0855 

[TRAIN] Epoch[2](938/1500); Loss: 0.086450; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1722 0.1369 0.1007 0.0851 0.0773 0.0824 0.0808 0.0747 0.0722 0.0715 0.0715 0.0715 0.0715 0.0715 0.0716 0.0715 

[TRAIN] Epoch[2](939/1500); Loss: 0.131204; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1573 0.1456 0.1389 0.1339 0.1321 0.1297 0.1280 0.1271 0.1266 0.1261 0.1260 0.1259 0.1257 0.1257 0.1254 0.1253 

[TRAIN] Epoch[2](940/1500); Loss: 0.069134; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1872 0.1321 0.0980 0.0802 0.0629 0.0585 0.0563 0.0517 0.0486 0.0476 0.0474 0.0478 0.0472 0.0468 0.0468 0.0471 

[TRAIN] Epoch[2](941/1500); Loss: 0.081399; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1271 0.0974 0.1036 0.0980 0.0908 0.0854 0.0780 0.0732 0.0707 0.0693 0.0689 0.0685 0.0683 0.0678 0.0678 0.0675 

[TRAIN] Epoch[2](942/1500); Loss: 0.104353; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.1877 0.1383 0.1115 0.1011 0.1105 0.1071 0.0991 0.0934 0.0910 0.0904 0.0902 0.0899 0.0898 0.0897 0.0901 0.0899 

[TRAIN] Epoch[2](943/1500); Loss: 0.064144; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1036 0.0900 0.0842 0.0774 0.0735 0.0691 0.0629 0.0576 0.0545 0.0523 0.0509 0.0504 0.0504 0.0501 0.0497 0.0498 

[TRAIN] Epoch[2](944/1500); Loss: 0.117552; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.1560 0.1449 0.1323 0.1246 0.1219 0.1202 0.1148 0.1113 0.1097 0.1083 0.1072 0.1067 0.1060 0.1058 0.1057 0.1054 

[TRAIN] Epoch[2](945/1500); Loss: 0.041140; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.0814 0.0823 0.0427 0.0593 0.0522 0.0364 0.0342 0.0317 0.0298 0.0295 0.0296 0.0296 0.0293 0.0294 0.0304 0.0304 

[TRAIN] Epoch[2](946/1500); Loss: 0.100941; Backpropagation: 0.0930 sec; Batch: 0.4270 sec
0.1245 0.1152 0.1134 0.1079 0.1045 0.1012 0.0972 0.0955 0.0948 0.0944 0.0940 0.0944 0.0944 0.0945 0.0945 0.0947 

[TRAIN] Epoch[2](947/1500); Loss: 0.126156; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1504 0.1436 0.1433 0.1387 0.1363 0.1318 0.1264 0.1228 0.1201 0.1183 0.1167 0.1157 0.1148 0.1138 0.1132 0.1126 

[TRAIN] Epoch[2](948/1500); Loss: 0.089293; Backpropagation: 0.0931 sec; Batch: 0.4266 sec
0.1103 0.1254 0.1073 0.0938 0.0911 0.0925 0.0893 0.0844 0.0823 0.0799 0.0798 0.0794 0.0782 0.0783 0.0787 0.0781 

[TRAIN] Epoch[2](949/1500); Loss: 0.087838; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1289 0.1172 0.1032 0.0919 0.0874 0.0871 0.0843 0.0817 0.0799 0.0792 0.0787 0.0784 0.0776 0.0770 0.0765 0.0764 

[TRAIN] Epoch[2](950/1500); Loss: 0.114847; Backpropagation: 0.0930 sec; Batch: 0.4267 sec
0.2208 0.1740 0.1404 0.1246 0.1129 0.1100 0.1048 0.1009 0.0971 0.0951 0.0944 0.0938 0.0929 0.0922 0.0919 0.0918 

[TRAIN] Epoch[2](951/1500); Loss: 0.099660; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1197 0.1158 0.1239 0.1146 0.1068 0.1004 0.0958 0.0937 0.0930 0.0918 0.0911 0.0907 0.0901 0.0896 0.0890 0.0887 

[TRAIN] Epoch[2](952/1500); Loss: 0.073316; Backpropagation: 0.0930 sec; Batch: 0.4268 sec
0.2227 0.1510 0.1047 0.0894 0.0696 0.0607 0.0512 0.0489 0.0486 0.0472 0.0459 0.0460 0.0464 0.0466 0.0470 0.0472 

[TRAIN] Epoch[2](953/1500); Loss: 0.064337; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1195 0.0775 0.0680 0.0717 0.0668 0.0584 0.0572 0.0569 0.0569 0.0566 0.0563 0.0561 0.0569 0.0564 0.0570 0.0573 

[TRAIN] Epoch[2](954/1500); Loss: 0.092188; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1618 0.1285 0.1014 0.0917 0.0942 0.0894 0.0836 0.0816 0.0809 0.0806 0.0802 0.0800 0.0802 0.0802 0.0802 0.0806 

[TRAIN] Epoch[2](955/1500); Loss: 0.134507; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1967 0.1661 0.1500 0.1411 0.1387 0.1359 0.1306 0.1264 0.1243 0.1229 0.1215 0.1208 0.1202 0.1192 0.1189 0.1188 

[TRAIN] Epoch[2](956/1500); Loss: 0.084596; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1169 0.1060 0.1024 0.0898 0.0821 0.0793 0.0782 0.0776 0.0773 0.0773 0.0772 0.0773 0.0776 0.0778 0.0782 0.0784 

[TRAIN] Epoch[2](957/1500); Loss: 0.039154; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.0858 0.0956 0.0414 0.0623 0.0472 0.0217 0.0237 0.0221 0.0268 0.0230 0.0287 0.0277 0.0282 0.0287 0.0312 0.0321 

[TRAIN] Epoch[2](958/1500); Loss: 0.113652; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1379 0.1348 0.1369 0.1255 0.1154 0.1121 0.1092 0.1075 0.1063 0.1055 0.1050 0.1048 0.1044 0.1044 0.1043 0.1044 

[TRAIN] Epoch[2](959/1500); Loss: 0.064121; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.0914 0.0845 0.0859 0.0704 0.0619 0.0597 0.0585 0.0576 0.0569 0.0566 0.0566 0.0563 0.0568 0.0572 0.0577 0.0579 

[TRAIN] Epoch[2](960/1500); Loss: 0.094400; Backpropagation: 0.0937 sec; Batch: 0.4293 sec
0.1443 0.1278 0.1091 0.1004 0.0943 0.0911 0.0887 0.0868 0.0857 0.0848 0.0841 0.0835 0.0831 0.0827 0.0821 0.0818 

[TRAIN] Epoch[2](961/1500); Loss: 0.110190; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1502 0.1309 0.1188 0.1125 0.1079 0.1064 0.1053 0.1046 0.1039 0.1036 0.1033 0.1032 0.1031 0.1029 0.1032 0.1032 

[TRAIN] Epoch[2](962/1500); Loss: 0.145590; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2247 0.1833 0.1604 0.1502 0.1360 0.1345 0.1341 0.1339 0.1340 0.1337 0.1338 0.1339 0.1340 0.1341 0.1344 0.1343 

[TRAIN] Epoch[2](963/1500); Loss: 0.093635; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1302 0.1147 0.1116 0.0985 0.0913 0.0897 0.0880 0.0869 0.0863 0.0859 0.0859 0.0859 0.0860 0.0856 0.0856 0.0862 

[TRAIN] Epoch[2](964/1500); Loss: 0.078214; Backpropagation: 0.0938 sec; Batch: 0.4286 sec
0.1352 0.1119 0.0895 0.0803 0.0726 0.0707 0.0695 0.0687 0.0685 0.0685 0.0686 0.0688 0.0691 0.0695 0.0699 0.0701 

[TRAIN] Epoch[2](965/1500); Loss: 0.068073; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1715 0.1301 0.0893 0.0688 0.0539 0.0555 0.0536 0.0541 0.0514 0.0507 0.0516 0.0519 0.0508 0.0525 0.0522 0.0512 

[TRAIN] Epoch[2](966/1500); Loss: 0.078211; Backpropagation: 0.0931 sec; Batch: 0.4266 sec
0.1188 0.1024 0.0963 0.0843 0.0757 0.0734 0.0721 0.0710 0.0703 0.0697 0.0696 0.0694 0.0694 0.0695 0.0697 0.0697 

[TRAIN] Epoch[2](967/1500); Loss: 0.081847; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1616 0.1286 0.0943 0.0854 0.0745 0.0721 0.0709 0.0699 0.0692 0.0692 0.0693 0.0689 0.0689 0.0688 0.0690 0.0691 

[TRAIN] Epoch[2](968/1500); Loss: 0.098842; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1360 0.1143 0.0997 0.0968 0.0944 0.0940 0.0951 0.0950 0.0947 0.0939 0.0942 0.0943 0.0941 0.0944 0.0951 0.0955 

[TRAIN] Epoch[2](969/1500); Loss: 0.171979; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2235 0.2103 0.1907 0.1821 0.1755 0.1726 0.1690 0.1653 0.1623 0.1600 0.1584 0.1573 0.1566 0.1564 0.1561 0.1557 

[TRAIN] Epoch[2](970/1500); Loss: 0.126269; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1957 0.1724 0.1494 0.1386 0.1269 0.1216 0.1166 0.1136 0.1114 0.1101 0.1107 0.1108 0.1108 0.1105 0.1104 0.1108 

[TRAIN] Epoch[2](971/1500); Loss: 0.129348; Backpropagation: 0.0937 sec; Batch: 0.4499 sec
0.1467 0.1498 0.1382 0.1346 0.1318 0.1288 0.1267 0.1254 0.1245 0.1243 0.1236 0.1233 0.1232 0.1230 0.1229 0.1229 

[TRAIN] Epoch[2](972/1500); Loss: 0.077090; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.0990 0.0938 0.0804 0.0827 0.0807 0.0775 0.0750 0.0736 0.0721 0.0718 0.0713 0.0711 0.0709 0.0711 0.0711 0.0714 

[TRAIN] Epoch[2](973/1500); Loss: 0.079866; Backpropagation: 0.0938 sec; Batch: 0.4346 sec
0.1450 0.1209 0.0996 0.0936 0.0849 0.0786 0.0736 0.0692 0.0667 0.0653 0.0643 0.0638 0.0631 0.0629 0.0629 0.0633 

[TRAIN] Epoch[2](974/1500); Loss: 0.107973; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1412 0.1486 0.1089 0.1284 0.1256 0.1141 0.1088 0.1027 0.0986 0.0961 0.0942 0.0935 0.0924 0.0917 0.0916 0.0912 

[TRAIN] Epoch[2](975/1500); Loss: 0.144167; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1667 0.1719 0.1545 0.1469 0.1446 0.1404 0.1378 0.1357 0.1350 0.1350 0.1352 0.1372 0.1389 0.1407 0.1421 0.1439 

[TRAIN] Epoch[2](976/1500); Loss: 0.094649; Backpropagation: 0.0931 sec; Batch: 0.4283 sec
0.1483 0.1163 0.1026 0.1034 0.0969 0.0919 0.0894 0.0872 0.0858 0.0848 0.0840 0.0841 0.0852 0.0850 0.0848 0.0847 

[TRAIN] Epoch[2](977/1500); Loss: 0.104359; Backpropagation: 0.0936 sec; Batch: 0.4752 sec
0.1583 0.1729 0.1356 0.1183 0.1111 0.1004 0.0943 0.0893 0.0875 0.0870 0.0859 0.0850 0.0846 0.0852 0.0866 0.0877 

[TRAIN] Epoch[2](978/1500); Loss: 0.134754; Backpropagation: 0.0935 sec; Batch: 0.4677 sec
0.2107 0.1851 0.1652 0.1594 0.1448 0.1379 0.1307 0.1241 0.1190 0.1145 0.1119 0.1105 0.1100 0.1108 0.1108 0.1106 

[TRAIN] Epoch[2](979/1500); Loss: 0.138498; Backpropagation: 0.0936 sec; Batch: 0.4704 sec
0.1598 0.1514 0.1445 0.1405 0.1371 0.1351 0.1343 0.1336 0.1335 0.1338 0.1345 0.1346 0.1353 0.1359 0.1359 0.1361 

[TRAIN] Epoch[2](980/1500); Loss: 0.083816; Backpropagation: 0.0936 sec; Batch: 0.4698 sec
0.1247 0.1229 0.1015 0.0936 0.0849 0.0804 0.0769 0.0747 0.0730 0.0725 0.0722 0.0721 0.0724 0.0728 0.0732 0.0734 

[TRAIN] Epoch[2](981/1500); Loss: 0.114639; Backpropagation: 0.0938 sec; Batch: 0.4557 sec
0.1318 0.1209 0.1163 0.1132 0.1125 0.1116 0.1115 0.1114 0.1118 0.1122 0.1127 0.1129 0.1131 0.1135 0.1141 0.1146 

[TRAIN] Epoch[2](982/1500); Loss: 0.119765; Backpropagation: 0.0936 sec; Batch: 0.4695 sec
0.1594 0.1333 0.1238 0.1193 0.1164 0.1157 0.1152 0.1148 0.1146 0.1145 0.1142 0.1146 0.1148 0.1150 0.1151 0.1156 

[TRAIN] Epoch[2](983/1500); Loss: 0.074521; Backpropagation: 0.0937 sec; Batch: 0.4665 sec
0.1149 0.0799 0.0865 0.0717 0.0704 0.0692 0.0678 0.0680 0.0687 0.0688 0.0687 0.0698 0.0709 0.0713 0.0723 0.0734 

[TRAIN] Epoch[2](984/1500); Loss: 0.099252; Backpropagation: 0.0935 sec; Batch: 0.4662 sec
0.1851 0.1367 0.1230 0.0980 0.0909 0.0880 0.0854 0.0848 0.0850 0.0853 0.0860 0.0862 0.0866 0.0881 0.0890 0.0898 

[TRAIN] Epoch[2](985/1500); Loss: 0.157817; Backpropagation: 0.0939 sec; Batch: 0.4713 sec
0.1894 0.1645 0.1625 0.1579 0.1542 0.1538 0.1541 0.1530 0.1533 0.1538 0.1538 0.1543 0.1549 0.1552 0.1553 0.1550 

[TRAIN] Epoch[2](986/1500); Loss: 0.123369; Backpropagation: 0.0937 sec; Batch: 0.4364 sec
0.2272 0.1725 0.1388 0.1261 0.1210 0.1150 0.1129 0.1112 0.1099 0.1078 0.1073 0.1054 0.1047 0.1046 0.1046 0.1050 

[TRAIN] Epoch[2](987/1500); Loss: 0.093813; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.2859 0.1612 0.0969 0.0817 0.0833 0.0762 0.0737 0.0725 0.0705 0.0705 0.0701 0.0704 0.0710 0.0715 0.0723 0.0731 

[TRAIN] Epoch[2](988/1500); Loss: 0.120143; Backpropagation: 0.0937 sec; Batch: 0.4708 sec
0.1859 0.1447 0.1296 0.1191 0.1168 0.1146 0.1130 0.1115 0.1115 0.1110 0.1102 0.1102 0.1107 0.1105 0.1112 0.1118 

[TRAIN] Epoch[2](989/1500); Loss: 0.160919; Backpropagation: 0.0965 sec; Batch: 0.4308 sec
0.2980 0.2533 0.2186 0.1841 0.1731 0.1678 0.1581 0.1504 0.1457 0.1383 0.1312 0.1250 0.1165 0.1102 0.1032 0.1013 

[TRAIN] Epoch[2](990/1500); Loss: 0.135773; Backpropagation: 0.0980 sec; Batch: 0.4730 sec
0.2248 0.1897 0.1720 0.1471 0.1373 0.1312 0.1267 0.1220 0.1192 0.1166 0.1149 0.1137 0.1142 0.1139 0.1142 0.1148 

[TRAIN] Epoch[2](991/1500); Loss: 0.159838; Backpropagation: 0.0966 sec; Batch: 0.4695 sec
0.3286 0.2519 0.2064 0.1695 0.1518 0.1439 0.1367 0.1326 0.1307 0.1300 0.1295 0.1288 0.1288 0.1290 0.1293 0.1299 

[TRAIN] Epoch[2](992/1500); Loss: 0.105393; Backpropagation: 0.0936 sec; Batch: 0.5029 sec
0.2125 0.1624 0.1304 0.1094 0.1019 0.0974 0.0931 0.0894 0.0875 0.0863 0.0861 0.0858 0.0855 0.0856 0.0862 0.0867 

[TRAIN] Epoch[2](993/1500); Loss: 0.168243; Backpropagation: 0.0936 sec; Batch: 0.4669 sec
0.4008 0.2860 0.2320 0.1743 0.1492 0.1389 0.1330 0.1301 0.1290 0.1290 0.1290 0.1299 0.1307 0.1318 0.1334 0.1347 

[TRAIN] Epoch[2](994/1500); Loss: 0.117918; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.2595 0.2016 0.1634 0.1240 0.1053 0.0980 0.0940 0.0929 0.0927 0.0925 0.0925 0.0928 0.0932 0.0941 0.0947 0.0954 

[TRAIN] Epoch[2](995/1500); Loss: 0.120203; Backpropagation: 0.0956 sec; Batch: 0.4692 sec
0.2428 0.1986 0.1703 0.1445 0.1307 0.1193 0.1081 0.0998 0.0940 0.0910 0.0893 0.0874 0.0866 0.0868 0.0869 0.0870 

[TRAIN] Epoch[2](996/1500); Loss: 0.097392; Backpropagation: 0.0936 sec; Batch: 0.4875 sec
0.1720 0.1372 0.1157 0.1036 0.0973 0.0929 0.0892 0.0866 0.0843 0.0829 0.0821 0.0824 0.0827 0.0828 0.0830 0.0836 

[TRAIN] Epoch[2](997/1500); Loss: 0.131748; Backpropagation: 0.0942 sec; Batch: 0.5275 sec
0.3094 0.2289 0.1801 0.1405 0.1208 0.1121 0.1066 0.1049 0.1035 0.1015 0.1000 0.0992 0.0995 0.0998 0.1004 0.1009 

[TRAIN] Epoch[2](998/1500); Loss: 0.132892; Backpropagation: 0.0936 sec; Batch: 0.4700 sec
0.2563 0.1842 0.1559 0.1343 0.1252 0.1210 0.1182 0.1164 0.1152 0.1140 0.1138 0.1135 0.1138 0.1143 0.1148 0.1154 

[TRAIN] Epoch[2](999/1500); Loss: 0.098218; Backpropagation: 0.0937 sec; Batch: 0.4670 sec
0.2115 0.1365 0.1068 0.0926 0.0866 0.0839 0.0847 0.0841 0.0841 0.0847 0.0847 0.0845 0.0848 0.0864 0.0871 0.0885 

[TRAIN] Epoch[2](1000/1500); Loss: 0.089205; Backpropagation: 0.0937 sec; Batch: 0.4297 sec
0.2032 0.1440 0.1046 0.0914 0.0741 0.0728 0.0709 0.0719 0.0721 0.0718 0.0724 0.0731 0.0745 0.0755 0.0767 0.0782 

[TRAIN] Epoch[2](1001/1500); Loss: 0.154765; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.3217 0.2490 0.2129 0.1793 0.1606 0.1459 0.1339 0.1248 0.1200 0.1191 0.1191 0.1186 0.1179 0.1176 0.1177 0.1180 

[TRAIN] Epoch[2](1002/1500); Loss: 0.140492; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.4298 0.3164 0.2608 0.1869 0.1395 0.1076 0.0868 0.0751 0.0734 0.0785 0.0793 0.0784 0.0807 0.0838 0.0856 0.0852 

[TRAIN] Epoch[2](1003/1500); Loss: 0.084642; Backpropagation: 0.0937 sec; Batch: 0.4652 sec
0.1541 0.1019 0.0834 0.0813 0.0803 0.0781 0.0765 0.0768 0.0765 0.0763 0.0772 0.0776 0.0778 0.0780 0.0788 0.0797 

[TRAIN] Epoch[2](1004/1500); Loss: 0.175791; Backpropagation: 0.0937 sec; Batch: 0.4716 sec
0.3398 0.2473 0.2093 0.1737 0.1606 0.1557 0.1541 0.1535 0.1532 0.1525 0.1518 0.1520 0.1523 0.1523 0.1523 0.1523 

[TRAIN] Epoch[2](1005/1500); Loss: 0.169871; Backpropagation: 0.0937 sec; Batch: 0.4656 sec
0.4240 0.3193 0.2591 0.1920 0.1562 0.1336 0.1222 0.1224 0.1229 0.1229 0.1229 0.1234 0.1235 0.1243 0.1246 0.1244 

[TRAIN] Epoch[2](1006/1500); Loss: 0.078161; Backpropagation: 0.0933 sec; Batch: 0.4289 sec
0.1761 0.1036 0.0816 0.0779 0.0739 0.0699 0.0687 0.0676 0.0666 0.0658 0.0655 0.0659 0.0661 0.0665 0.0671 0.0678 

[TRAIN] Epoch[2](1007/1500); Loss: 0.181194; Backpropagation: 0.0940 sec; Batch: 0.4786 sec
0.2840 0.2413 0.2034 0.1901 0.1755 0.1717 0.1670 0.1643 0.1626 0.1620 0.1617 0.1620 0.1621 0.1627 0.1638 0.1647 

[TRAIN] Epoch[2](1008/1500); Loss: 0.089883; Backpropagation: 0.0938 sec; Batch: 0.4736 sec
0.2305 0.1399 0.1061 0.0826 0.0733 0.0729 0.0751 0.0766 0.0770 0.0772 0.0756 0.0737 0.0718 0.0702 0.0686 0.0671 

[TRAIN] Epoch[2](1009/1500); Loss: 0.177069; Backpropagation: 0.0942 sec; Batch: 0.4304 sec
0.3289 0.2502 0.2156 0.1831 0.1664 0.1593 0.1568 0.1562 0.1552 0.1546 0.1536 0.1531 0.1520 0.1507 0.1494 0.1480 

[TRAIN] Epoch[2](1010/1500); Loss: 0.083817; Backpropagation: 0.0938 sec; Batch: 0.4652 sec
0.1331 0.0831 0.0722 0.0868 0.0876 0.0851 0.0842 0.0827 0.0809 0.0792 0.0785 0.0780 0.0777 0.0774 0.0771 0.0774 

[TRAIN] Epoch[2](1011/1500); Loss: 0.147710; Backpropagation: 0.0939 sec; Batch: 0.4475 sec
0.3213 0.2179 0.1789 0.1446 0.1312 0.1256 0.1246 0.1256 0.1265 0.1261 0.1253 0.1246 0.1237 0.1232 0.1224 0.1218 

[TRAIN] Epoch[2](1012/1500); Loss: 0.117307; Backpropagation: 0.0933 sec; Batch: 0.4649 sec
0.1602 0.1031 0.1038 0.1205 0.1182 0.1140 0.1137 0.1143 0.1162 0.1164 0.1162 0.1156 0.1160 0.1156 0.1163 0.1168 

[TRAIN] Epoch[2](1013/1500); Loss: 0.125238; Backpropagation: 0.0940 sec; Batch: 0.4675 sec
0.1532 0.1110 0.1156 0.1330 0.1335 0.1302 0.1278 0.1258 0.1247 0.1231 0.1224 0.1214 0.1207 0.1206 0.1205 0.1204 

[TRAIN] Epoch[2](1014/1500); Loss: 0.105731; Backpropagation: 0.0939 sec; Batch: 0.5102 sec
0.1709 0.1127 0.1045 0.1092 0.1074 0.1029 0.1014 0.1007 0.1000 0.0986 0.0978 0.0971 0.0966 0.0964 0.0971 0.0983 

[TRAIN] Epoch[2](1015/1500); Loss: 0.153014; Backpropagation: 0.0939 sec; Batch: 0.4667 sec
0.2266 0.1802 0.1666 0.1549 0.1487 0.1463 0.1451 0.1442 0.1443 0.1437 0.1426 0.1418 0.1415 0.1410 0.1407 0.1403 

[TRAIN] Epoch[2](1016/1500); Loss: 0.117913; Backpropagation: 0.0933 sec; Batch: 0.4662 sec
0.1643 0.1205 0.1137 0.1221 0.1200 0.1168 0.1154 0.1145 0.1134 0.1131 0.1127 0.1126 0.1121 0.1118 0.1117 0.1119 

[TRAIN] Epoch[2](1017/1500); Loss: 0.123771; Backpropagation: 0.0959 sec; Batch: 0.4693 sec
0.2001 0.1669 0.1552 0.1343 0.1238 0.1185 0.1147 0.1124 0.1103 0.1082 0.1070 0.1064 0.1060 0.1053 0.1055 0.1057 

[TRAIN] Epoch[2](1018/1500); Loss: 0.192859; Backpropagation: 0.0956 sec; Batch: 0.4650 sec
0.2774 0.2236 0.2023 0.1950 0.1913 0.1873 0.1846 0.1838 0.1828 0.1817 0.1807 0.1800 0.1792 0.1789 0.1786 0.1785 

[TRAIN] Epoch[2](1019/1500); Loss: 0.069612; Backpropagation: 0.0939 sec; Batch: 0.4687 sec
0.1255 0.0919 0.0748 0.0752 0.0711 0.0662 0.0635 0.0620 0.0611 0.0603 0.0598 0.0602 0.0600 0.0607 0.0606 0.0609 

[TRAIN] Epoch[2](1020/1500); Loss: 0.100329; Backpropagation: 0.0934 sec; Batch: 0.4537 sec
0.1403 0.1106 0.1051 0.1036 0.0994 0.0972 0.0955 0.0956 0.0950 0.0945 0.0942 0.0945 0.0944 0.0947 0.0951 0.0955 

[TRAIN] Epoch[2](1021/1500); Loss: 0.110383; Backpropagation: 0.0934 sec; Batch: 0.4665 sec
0.1716 0.1241 0.1131 0.1124 0.1082 0.1049 0.1047 0.1035 0.1032 0.1022 0.1025 0.1021 0.1035 0.1031 0.1035 0.1036 

[TRAIN] Epoch[2](1022/1500); Loss: 0.101851; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.1583 0.1151 0.1044 0.1012 0.0981 0.0970 0.0965 0.0961 0.0957 0.0951 0.0947 0.0946 0.0951 0.0952 0.0962 0.0964 

[TRAIN] Epoch[2](1023/1500); Loss: 0.143835; Backpropagation: 0.0940 sec; Batch: 0.4708 sec
0.1988 0.1671 0.1500 0.1449 0.1414 0.1386 0.1386 0.1375 0.1366 0.1354 0.1353 0.1351 0.1355 0.1356 0.1352 0.1358 

[TRAIN] Epoch[2](1024/1500); Loss: 0.147605; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.2346 0.1874 0.1580 0.1475 0.1417 0.1378 0.1358 0.1350 0.1352 0.1349 0.1349 0.1347 0.1359 0.1358 0.1361 0.1363 

[TRAIN] Epoch[2](1025/1500); Loss: 0.144623; Backpropagation: 0.0939 sec; Batch: 0.4660 sec
0.2219 0.1810 0.1572 0.1488 0.1441 0.1404 0.1372 0.1355 0.1337 0.1325 0.1313 0.1301 0.1305 0.1301 0.1300 0.1298 

[TRAIN] Epoch[2](1026/1500); Loss: 0.119855; Backpropagation: 0.0939 sec; Batch: 0.4698 sec
0.1796 0.1405 0.1255 0.1201 0.1157 0.1134 0.1136 0.1121 0.1125 0.1116 0.1123 0.1118 0.1121 0.1118 0.1127 0.1124 

[TRAIN] Epoch[2](1027/1500); Loss: 0.132549; Backpropagation: 0.0940 sec; Batch: 0.4585 sec
0.1859 0.1455 0.1310 0.1331 0.1299 0.1267 0.1263 0.1260 0.1263 0.1263 0.1269 0.1268 0.1272 0.1271 0.1277 0.1281 

[TRAIN] Epoch[2](1028/1500); Loss: 0.130678; Backpropagation: 0.0940 sec; Batch: 0.4308 sec
0.1835 0.1544 0.1381 0.1311 0.1287 0.1273 0.1261 0.1245 0.1233 0.1226 0.1219 0.1217 0.1214 0.1217 0.1221 0.1225 

[TRAIN] Epoch[2](1029/1500); Loss: 0.127168; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1650 0.1445 0.1344 0.1288 0.1268 0.1252 0.1248 0.1231 0.1218 0.1207 0.1205 0.1199 0.1198 0.1196 0.1197 0.1199 

[TRAIN] Epoch[2](1030/1500); Loss: 0.093970; Backpropagation: 0.0940 sec; Batch: 0.4680 sec
0.2057 0.1887 0.1531 0.1067 0.0734 0.0690 0.0688 0.0708 0.0699 0.0696 0.0695 0.0704 0.0713 0.0714 0.0717 0.0736 

[TRAIN] Epoch[2](1031/1500); Loss: 0.081783; Backpropagation: 0.0950 sec; Batch: 0.4295 sec
0.1193 0.0973 0.0868 0.0806 0.0789 0.0783 0.0776 0.0773 0.0767 0.0767 0.0762 0.0761 0.0762 0.0764 0.0770 0.0771 

[TRAIN] Epoch[2](1032/1500); Loss: 0.080327; Backpropagation: 0.0932 sec; Batch: 0.5026 sec
0.1391 0.1080 0.0933 0.0837 0.0767 0.0735 0.0718 0.0703 0.0704 0.0699 0.0712 0.0706 0.0712 0.0713 0.0720 0.0723 

[TRAIN] Epoch[2](1033/1500); Loss: 0.163364; Backpropagation: 0.0946 sec; Batch: 0.4559 sec
0.2055 0.1798 0.1692 0.1642 0.1622 0.1610 0.1598 0.1590 0.1582 0.1575 0.1569 0.1564 0.1561 0.1559 0.1561 0.1561 

[TRAIN] Epoch[2](1034/1500); Loss: 0.135501; Backpropagation: 0.0945 sec; Batch: 0.4671 sec
0.1837 0.1608 0.1448 0.1345 0.1310 0.1302 0.1292 0.1287 0.1281 0.1279 0.1281 0.1281 0.1279 0.1284 0.1283 0.1284 

[TRAIN] Epoch[2](1035/1500); Loss: 0.175200; Backpropagation: 0.0946 sec; Batch: 0.4285 sec
0.2649 0.2092 0.1779 0.1778 0.1729 0.1684 0.1649 0.1642 0.1629 0.1632 0.1623 0.1629 0.1621 0.1634 0.1630 0.1634 

[TRAIN] Epoch[2](1036/1500); Loss: 0.094112; Backpropagation: 0.0932 sec; Batch: 0.4555 sec
0.1437 0.1291 0.1014 0.1049 0.0959 0.0886 0.0871 0.0847 0.0848 0.0831 0.0839 0.0829 0.0836 0.0831 0.0848 0.0842 

[TRAIN] Epoch[2](1037/1500); Loss: 0.087794; Backpropagation: 0.0940 sec; Batch: 0.4867 sec
0.1431 0.1150 0.0982 0.0915 0.0862 0.0828 0.0808 0.0793 0.0782 0.0781 0.0779 0.0779 0.0783 0.0789 0.0788 0.0795 

[TRAIN] Epoch[2](1038/1500); Loss: 0.104036; Backpropagation: 0.0939 sec; Batch: 0.4673 sec
0.1557 0.1510 0.1334 0.1134 0.1120 0.1092 0.1032 0.1005 0.0965 0.0937 0.0887 0.0866 0.0835 0.0816 0.0783 0.0771 

[TRAIN] Epoch[2](1039/1500); Loss: 0.119873; Backpropagation: 0.0939 sec; Batch: 0.4700 sec
0.1537 0.1425 0.1292 0.1193 0.1168 0.1164 0.1150 0.1144 0.1137 0.1141 0.1139 0.1139 0.1138 0.1138 0.1137 0.1139 

[TRAIN] Epoch[2](1040/1500); Loss: 0.084529; Backpropagation: 0.0933 sec; Batch: 0.4657 sec
0.1312 0.0941 0.0899 0.0859 0.0831 0.0817 0.0798 0.0804 0.0787 0.0784 0.0776 0.0784 0.0779 0.0783 0.0775 0.0795 

[TRAIN] Epoch[2](1041/1500); Loss: 0.049308; Backpropagation: 0.0939 sec; Batch: 0.4703 sec
0.1081 0.1070 0.0697 0.0428 0.0390 0.0401 0.0372 0.0359 0.0387 0.0372 0.0374 0.0369 0.0406 0.0393 0.0395 0.0396 

[TRAIN] Epoch[2](1042/1500); Loss: 0.073200; Backpropagation: 0.0937 sec; Batch: 0.4704 sec
0.1499 0.0988 0.0739 0.0710 0.0670 0.0654 0.0651 0.0641 0.0637 0.0636 0.0641 0.0638 0.0645 0.0659 0.0651 0.0652 

[TRAIN] Epoch[2](1043/1500); Loss: 0.100309; Backpropagation: 0.0940 sec; Batch: 0.4664 sec
0.1161 0.1189 0.1053 0.1005 0.0990 0.0991 0.0983 0.0981 0.0970 0.0970 0.0963 0.0965 0.0957 0.0959 0.0956 0.0957 

[TRAIN] Epoch[2](1044/1500); Loss: 0.090414; Backpropagation: 0.0939 sec; Batch: 0.4666 sec
0.1773 0.1409 0.1070 0.0899 0.0818 0.0786 0.0771 0.0776 0.0763 0.0768 0.0760 0.0771 0.0769 0.0772 0.0775 0.0787 

[TRAIN] Epoch[2](1045/1500); Loss: 0.115359; Backpropagation: 0.0939 sec; Batch: 0.4705 sec
0.2107 0.1564 0.1316 0.1252 0.1166 0.1117 0.1063 0.1022 0.0996 0.0987 0.0980 0.0977 0.0976 0.0977 0.0976 0.0981 

[TRAIN] Epoch[2](1046/1500); Loss: 0.082658; Backpropagation: 0.0938 sec; Batch: 0.4722 sec
0.1519 0.1154 0.0987 0.0886 0.0790 0.0742 0.0725 0.0708 0.0709 0.0710 0.0712 0.0714 0.0713 0.0719 0.0712 0.0723 

[TRAIN] Epoch[2](1047/1500); Loss: 0.072912; Backpropagation: 0.0940 sec; Batch: 0.5248 sec
0.1229 0.0962 0.0815 0.0759 0.0730 0.0711 0.0693 0.0673 0.0660 0.0653 0.0642 0.0639 0.0628 0.0627 0.0623 0.0622 

[TRAIN] Epoch[2](1048/1500); Loss: 0.085760; Backpropagation: 0.0935 sec; Batch: 0.4297 sec
0.1224 0.0970 0.0890 0.0853 0.0827 0.0825 0.0820 0.0816 0.0813 0.0810 0.0810 0.0809 0.0812 0.0811 0.0815 0.0815 

[TRAIN] Epoch[2](1049/1500); Loss: 0.080979; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.1022 0.1084 0.0851 0.0841 0.0815 0.0771 0.0761 0.0755 0.0756 0.0755 0.0754 0.0753 0.0755 0.0759 0.0761 0.0765 

[TRAIN] Epoch[2](1050/1500); Loss: 0.075881; Backpropagation: 0.0938 sec; Batch: 0.4694 sec
0.1332 0.0958 0.0836 0.0761 0.0720 0.0701 0.0688 0.0677 0.0674 0.0675 0.0675 0.0680 0.0685 0.0689 0.0690 0.0701 

[TRAIN] Epoch[2](1051/1500); Loss: 0.125328; Backpropagation: 0.0957 sec; Batch: 0.4681 sec
0.1950 0.1547 0.1327 0.1276 0.1236 0.1216 0.1195 0.1180 0.1167 0.1157 0.1145 0.1138 0.1135 0.1133 0.1127 0.1122 

[TRAIN] Epoch[2](1052/1500); Loss: 0.118894; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1888 0.1369 0.1195 0.1137 0.1118 0.1110 0.1105 0.1096 0.1098 0.1103 0.1109 0.1117 0.1127 0.1138 0.1149 0.1165 

[TRAIN] Epoch[2](1053/1500); Loss: 0.138835; Backpropagation: 0.0939 sec; Batch: 0.4713 sec
0.2212 0.1762 0.1561 0.1439 0.1370 0.1331 0.1300 0.1275 0.1258 0.1253 0.1246 0.1240 0.1240 0.1239 0.1241 0.1247 

[TRAIN] Epoch[2](1054/1500); Loss: 0.145082; Backpropagation: 0.0933 sec; Batch: 0.4696 sec
0.2293 0.1888 0.1694 0.1515 0.1440 0.1406 0.1370 0.1333 0.1309 0.1293 0.1285 0.1275 0.1276 0.1275 0.1277 0.1286 

[TRAIN] Epoch[2](1055/1500); Loss: 0.102951; Backpropagation: 0.0933 sec; Batch: 0.4706 sec
0.1737 0.1374 0.1197 0.1063 0.1019 0.0991 0.0961 0.0937 0.0920 0.0907 0.0908 0.0898 0.0889 0.0897 0.0889 0.0884 

[TRAIN] Epoch[2](1056/1500); Loss: 0.163478; Backpropagation: 0.0957 sec; Batch: 0.4657 sec
0.2202 0.2130 0.1905 0.1686 0.1636 0.1606 0.1577 0.1556 0.1531 0.1512 0.1491 0.1478 0.1474 0.1462 0.1457 0.1452 

[TRAIN] Epoch[2](1057/1500); Loss: 0.126842; Backpropagation: 0.0938 sec; Batch: 0.4678 sec
0.1887 0.1493 0.1315 0.1215 0.1191 0.1184 0.1173 0.1175 0.1172 0.1182 0.1191 0.1198 0.1210 0.1225 0.1235 0.1250 

[TRAIN] Epoch[2](1058/1500); Loss: 0.046773; Backpropagation: 0.0939 sec; Batch: 0.4695 sec
0.0603 0.0587 0.0566 0.0491 0.0453 0.0440 0.0430 0.0435 0.0428 0.0422 0.0433 0.0430 0.0429 0.0454 0.0443 0.0440 

[TRAIN] Epoch[2](1059/1500); Loss: 0.073274; Backpropagation: 0.0945 sec; Batch: 0.4716 sec
0.1477 0.1000 0.0778 0.0728 0.0705 0.0688 0.0673 0.0661 0.0651 0.0641 0.0633 0.0627 0.0623 0.0616 0.0611 0.0611 

[TRAIN] Epoch[2](1060/1500); Loss: 0.067091; Backpropagation: 0.0937 sec; Batch: 0.4696 sec
0.2340 0.1261 0.0844 0.0581 0.0512 0.0502 0.0467 0.0458 0.0460 0.0461 0.0465 0.0466 0.0474 0.0479 0.0481 0.0486 

[TRAIN] Epoch[2](1061/1500); Loss: 0.103628; Backpropagation: 0.0938 sec; Batch: 0.4712 sec
0.1559 0.1502 0.1331 0.1122 0.1016 0.0972 0.0949 0.0927 0.0911 0.0899 0.0898 0.0898 0.0896 0.0896 0.0899 0.0905 

[TRAIN] Epoch[2](1062/1500); Loss: 0.087464; Backpropagation: 0.0981 sec; Batch: 0.4739 sec
0.2546 0.1624 0.1208 0.0916 0.0783 0.0739 0.0693 0.0657 0.0635 0.0623 0.0607 0.0597 0.0593 0.0593 0.0591 0.0590 

[TRAIN] Epoch[2](1063/1500); Loss: 0.122273; Backpropagation: 0.0957 sec; Batch: 0.4683 sec
0.2627 0.2111 0.1692 0.1311 0.1152 0.1104 0.1058 0.1002 0.0977 0.0960 0.0947 0.0933 0.0925 0.0923 0.0921 0.0921 

[TRAIN] Epoch[2](1064/1500); Loss: 0.079733; Backpropagation: 0.0938 sec; Batch: 0.4688 sec
0.1537 0.1030 0.0914 0.0809 0.0810 0.0791 0.0732 0.0703 0.0701 0.0690 0.0678 0.0686 0.0677 0.0667 0.0666 0.0666 

[TRAIN] Epoch[2](1065/1500); Loss: 0.121414; Backpropagation: 0.0940 sec; Batch: 0.4705 sec
0.2318 0.1920 0.1702 0.1411 0.1244 0.1159 0.1084 0.1022 0.0978 0.0958 0.0948 0.0944 0.0941 0.0937 0.0933 0.0928 

[TRAIN] Epoch[2](1066/1500); Loss: 0.049250; Backpropagation: 0.0939 sec; Batch: 0.4709 sec
0.0604 0.0926 0.0849 0.0439 0.0466 0.0450 0.0351 0.0337 0.0402 0.0392 0.0380 0.0429 0.0432 0.0431 0.0493 0.0498 

[TRAIN] Epoch[2](1067/1500); Loss: 0.138758; Backpropagation: 0.0982 sec; Batch: 0.4713 sec
0.2247 0.2037 0.1831 0.1545 0.1411 0.1336 0.1273 0.1232 0.1221 0.1196 0.1164 0.1152 0.1152 0.1140 0.1131 0.1134 

[TRAIN] Epoch[2](1068/1500); Loss: 0.087857; Backpropagation: 0.0981 sec; Batch: 0.4696 sec
0.1286 0.1026 0.0910 0.0874 0.0880 0.0841 0.0810 0.0799 0.0803 0.0801 0.0807 0.0834 0.0836 0.0832 0.0850 0.0868 

[TRAIN] Epoch[2](1069/1500); Loss: 0.108681; Backpropagation: 0.0939 sec; Batch: 0.4663 sec
0.1970 0.1537 0.1358 0.1138 0.1037 0.1007 0.0984 0.0962 0.0946 0.0936 0.0928 0.0922 0.0920 0.0917 0.0914 0.0915 

[TRAIN] Epoch[2](1070/1500); Loss: 0.077821; Backpropagation: 0.0937 sec; Batch: 0.4656 sec
0.1853 0.1335 0.1045 0.0845 0.0718 0.0675 0.0645 0.0618 0.0600 0.0598 0.0592 0.0584 0.0587 0.0585 0.0582 0.0589 

[TRAIN] Epoch[2](1071/1500); Loss: 0.096070; Backpropagation: 0.0939 sec; Batch: 0.4670 sec
0.2051 0.1372 0.1135 0.0967 0.0906 0.0881 0.0854 0.0824 0.0807 0.0799 0.0797 0.0796 0.0796 0.0796 0.0794 0.0794 

[TRAIN] Epoch[2](1072/1500); Loss: 0.074197; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.1907 0.1021 0.0805 0.0704 0.0675 0.0654 0.0629 0.0613 0.0602 0.0597 0.0599 0.0599 0.0603 0.0614 0.0621 0.0630 

[TRAIN] Epoch[2](1073/1500); Loss: 0.108173; Backpropagation: 0.0957 sec; Batch: 0.4728 sec
0.2445 0.1769 0.1460 0.1218 0.1082 0.0999 0.0942 0.0904 0.0871 0.0839 0.0820 0.0811 0.0800 0.0789 0.0784 0.0775 

[TRAIN] Epoch[2](1074/1500); Loss: 0.120263; Backpropagation: 0.0937 sec; Batch: 0.4673 sec
0.1928 0.1483 0.1277 0.1181 0.1136 0.1109 0.1106 0.1106 0.1103 0.1101 0.1104 0.1109 0.1114 0.1119 0.1128 0.1137 

[TRAIN] Epoch[2](1075/1500); Loss: 0.085498; Backpropagation: 0.0938 sec; Batch: 0.4727 sec
0.1391 0.1016 0.0819 0.0906 0.0851 0.0806 0.0791 0.0793 0.0787 0.0782 0.0788 0.0787 0.0787 0.0791 0.0790 0.0792 

[TRAIN] Epoch[2](1076/1500); Loss: 0.125946; Backpropagation: 0.0939 sec; Batch: 0.4701 sec
0.2270 0.1604 0.1270 0.1165 0.1171 0.1171 0.1156 0.1159 0.1158 0.1152 0.1146 0.1144 0.1143 0.1147 0.1147 0.1150 

[TRAIN] Epoch[2](1077/1500); Loss: 0.117258; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.2082 0.1553 0.1333 0.1195 0.1138 0.1111 0.1070 0.1049 0.1041 0.1032 0.1025 0.1035 0.1029 0.1021 0.1023 0.1023 

[TRAIN] Epoch[2](1078/1500); Loss: 0.138592; Backpropagation: 0.0939 sec; Batch: 0.4765 sec
0.2064 0.1758 0.1556 0.1398 0.1350 0.1329 0.1306 0.1290 0.1278 0.1266 0.1260 0.1259 0.1263 0.1267 0.1265 0.1266 

[TRAIN] Epoch[2](1079/1500); Loss: 0.134190; Backpropagation: 0.0939 sec; Batch: 0.5019 sec
0.2168 0.1618 0.1367 0.1256 0.1219 0.1214 0.1206 0.1219 0.1225 0.1241 0.1256 0.1265 0.1279 0.1297 0.1312 0.1329 

[TRAIN] Epoch[2](1080/1500); Loss: 0.123018; Backpropagation: 0.0937 sec; Batch: 0.4435 sec
0.2524 0.1986 0.1649 0.1380 0.1234 0.1142 0.1074 0.1017 0.0982 0.0966 0.0959 0.0958 0.0953 0.0951 0.0950 0.0959 

[TRAIN] Epoch[2](1081/1500); Loss: 0.136039; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1970 0.1494 0.1442 0.1418 0.1373 0.1341 0.1324 0.1306 0.1290 0.1277 0.1269 0.1261 0.1256 0.1252 0.1249 0.1244 

[TRAIN] Epoch[2](1082/1500); Loss: 0.100697; Backpropagation: 0.0938 sec; Batch: 0.4763 sec
0.2049 0.1489 0.1251 0.1060 0.0953 0.0913 0.0881 0.0860 0.0847 0.0839 0.0834 0.0828 0.0829 0.0827 0.0827 0.0827 

[TRAIN] Epoch[2](1083/1500); Loss: 0.124343; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1713 0.1378 0.1295 0.1259 0.1234 0.1219 0.1205 0.1195 0.1187 0.1179 0.1175 0.1172 0.1169 0.1170 0.1171 0.1171 

[TRAIN] Epoch[2](1084/1500); Loss: 0.108844; Backpropagation: 0.0957 sec; Batch: 0.4705 sec
0.1670 0.1254 0.1262 0.1153 0.1078 0.1046 0.1016 0.1005 0.0998 0.0993 0.0989 0.0990 0.0989 0.0991 0.0991 0.0991 

[TRAIN] Epoch[2](1085/1500); Loss: 0.058691; Backpropagation: 0.0943 sec; Batch: 0.4286 sec
0.1199 0.0598 0.0688 0.0566 0.0673 0.0660 0.0559 0.0488 0.0478 0.0498 0.0486 0.0485 0.0510 0.0495 0.0485 0.0523 

[TRAIN] Epoch[2](1086/1500); Loss: 0.108733; Backpropagation: 0.0933 sec; Batch: 0.4701 sec
0.1880 0.1487 0.1278 0.1141 0.1097 0.1047 0.1004 0.0983 0.0970 0.0951 0.0939 0.0933 0.0924 0.0922 0.0923 0.0920 

[TRAIN] Epoch[2](1087/1500); Loss: 0.075354; Backpropagation: 0.0934 sec; Batch: 0.4325 sec
0.1018 0.0889 0.0795 0.0745 0.0795 0.0774 0.0730 0.0711 0.0704 0.0700 0.0695 0.0696 0.0697 0.0700 0.0702 0.0705 

[TRAIN] Epoch[2](1088/1500); Loss: 0.068893; Backpropagation: 0.0934 sec; Batch: 0.4288 sec
0.0910 0.0901 0.0867 0.0775 0.0728 0.0701 0.0654 0.0624 0.0617 0.0607 0.0604 0.0608 0.0605 0.0606 0.0610 0.0606 

[TRAIN] Epoch[2](1089/1500); Loss: 0.084767; Backpropagation: 0.0935 sec; Batch: 0.4711 sec
0.1890 0.1215 0.0924 0.0812 0.0768 0.0744 0.0720 0.0721 0.0719 0.0717 0.0724 0.0723 0.0719 0.0721 0.0723 0.0725 

[TRAIN] Epoch[2](1090/1500); Loss: 0.110860; Backpropagation: 0.0956 sec; Batch: 0.4736 sec
0.1596 0.1254 0.1291 0.1244 0.1178 0.1121 0.1081 0.1049 0.1031 0.1015 0.0999 0.0992 0.0983 0.0977 0.0968 0.0959 

[TRAIN] Epoch[2](1091/1500); Loss: 0.076141; Backpropagation: 0.0938 sec; Batch: 0.4680 sec
0.1333 0.1008 0.0917 0.0817 0.0740 0.0699 0.0681 0.0676 0.0669 0.0664 0.0664 0.0663 0.0663 0.0664 0.0662 0.0661 

[TRAIN] Epoch[2](1092/1500); Loss: 0.108014; Backpropagation: 0.0939 sec; Batch: 0.4714 sec
0.3187 0.2204 0.1583 0.1334 0.0886 0.0733 0.0663 0.0707 0.0716 0.0753 0.0750 0.0741 0.0736 0.0750 0.0758 0.0780 

[TRAIN] Epoch[2](1093/1500); Loss: 0.127681; Backpropagation: 0.0940 sec; Batch: 0.4309 sec
0.1941 0.1568 0.1420 0.1336 0.1254 0.1217 0.1191 0.1177 0.1168 0.1166 0.1168 0.1166 0.1164 0.1163 0.1162 0.1168 

[TRAIN] Epoch[2](1094/1500); Loss: 0.139795; Backpropagation: 0.0937 sec; Batch: 0.4694 sec
0.2055 0.1602 0.1453 0.1440 0.1376 0.1351 0.1342 0.1329 0.1316 0.1308 0.1306 0.1306 0.1297 0.1293 0.1294 0.1300 

[TRAIN] Epoch[2](1095/1500); Loss: 0.128167; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1658 0.1454 0.1358 0.1313 0.1286 0.1278 0.1250 0.1234 0.1230 0.1227 0.1213 0.1206 0.1204 0.1203 0.1196 0.1197 

[TRAIN] Epoch[2](1096/1500); Loss: 0.104651; Backpropagation: 0.0938 sec; Batch: 0.4640 sec
0.1718 0.1261 0.1129 0.1061 0.1029 0.1005 0.0977 0.0962 0.0949 0.0952 0.0942 0.0941 0.0943 0.0955 0.0956 0.0964 

[TRAIN] Epoch[2](1097/1500); Loss: 0.125957; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.1657 0.1461 0.1369 0.1301 0.1277 0.1254 0.1229 0.1206 0.1190 0.1179 0.1170 0.1172 0.1172 0.1164 0.1171 0.1181 

[TRAIN] Epoch[2](1098/1500); Loss: 0.090166; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1575 0.1239 0.0883 0.0887 0.0841 0.0806 0.0806 0.0799 0.0807 0.0819 0.0813 0.0810 0.0816 0.0824 0.0845 0.0858 

[TRAIN] Epoch[2](1099/1500); Loss: 0.087389; Backpropagation: 0.0947 sec; Batch: 0.4314 sec
0.1698 0.1143 0.0914 0.0861 0.0804 0.0785 0.0780 0.0780 0.0767 0.0767 0.0770 0.0780 0.0776 0.0784 0.0782 0.0791 

[TRAIN] Epoch[2](1100/1500); Loss: 0.123943; Backpropagation: 0.0933 sec; Batch: 0.4682 sec
0.1626 0.1404 0.1347 0.1262 0.1269 0.1242 0.1204 0.1181 0.1169 0.1165 0.1162 0.1160 0.1154 0.1161 0.1161 0.1164 

[TRAIN] Epoch[2](1101/1500); Loss: 0.068453; Backpropagation: 0.0943 sec; Batch: 0.4285 sec
0.1159 0.0845 0.0758 0.0701 0.0673 0.0645 0.0625 0.0620 0.0611 0.0609 0.0612 0.0619 0.0613 0.0619 0.0621 0.0623 

[TRAIN] Epoch[2](1102/1500); Loss: 0.100706; Backpropagation: 0.0933 sec; Batch: 0.4531 sec
0.1556 0.1169 0.1160 0.0973 0.0984 0.0964 0.0915 0.0907 0.0928 0.0934 0.0920 0.0922 0.0944 0.0944 0.0943 0.0948 

[TRAIN] Epoch[2](1103/1500); Loss: 0.099570; Backpropagation: 0.0939 sec; Batch: 0.4671 sec
0.1502 0.1203 0.1123 0.1079 0.0964 0.0921 0.0927 0.0914 0.0907 0.0903 0.0919 0.0912 0.0903 0.0899 0.0930 0.0926 

[TRAIN] Epoch[2](1104/1500); Loss: 0.120669; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1667 0.1476 0.1345 0.1298 0.1205 0.1169 0.1163 0.1149 0.1125 0.1115 0.1115 0.1105 0.1095 0.1100 0.1096 0.1084 

[TRAIN] Epoch[2](1105/1500); Loss: 0.080173; Backpropagation: 0.0942 sec; Batch: 0.4497 sec
0.1281 0.0971 0.0866 0.0845 0.0805 0.0758 0.0744 0.0737 0.0722 0.0712 0.0722 0.0721 0.0728 0.0731 0.0744 0.0742 

[TRAIN] Epoch[2](1106/1500); Loss: 0.099422; Backpropagation: 0.0934 sec; Batch: 0.4580 sec
0.1402 0.1184 0.1107 0.0987 0.0959 0.0951 0.0945 0.0939 0.0923 0.0926 0.0927 0.0922 0.0924 0.0934 0.0934 0.0942 

[TRAIN] Epoch[2](1107/1500); Loss: 0.141304; Backpropagation: 0.0983 sec; Batch: 0.4440 sec
0.1846 0.1580 0.1507 0.1466 0.1406 0.1385 0.1368 0.1358 0.1348 0.1334 0.1333 0.1337 0.1338 0.1332 0.1332 0.1340 

[TRAIN] Epoch[2](1108/1500); Loss: 0.106478; Backpropagation: 0.0957 sec; Batch: 0.4552 sec
0.2139 0.1650 0.1259 0.1012 0.1073 0.1025 0.0922 0.0906 0.0884 0.0891 0.0880 0.0872 0.0877 0.0883 0.0876 0.0887 

[TRAIN] Epoch[2](1109/1500); Loss: 0.083855; Backpropagation: 0.0942 sec; Batch: 0.4294 sec
0.1486 0.1106 0.0986 0.0862 0.0809 0.0782 0.0750 0.0743 0.0731 0.0736 0.0734 0.0725 0.0730 0.0741 0.0745 0.0749 

[TRAIN] Epoch[2](1110/1500); Loss: 0.184031; Backpropagation: 0.0939 sec; Batch: 0.4662 sec
0.2645 0.2108 0.1754 0.1756 0.1822 0.1844 0.1783 0.1757 0.1725 0.1729 0.1741 0.1755 0.1744 0.1754 0.1763 0.1764 

[TRAIN] Epoch[2](1111/1500); Loss: 0.066550; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1196 0.0994 0.0795 0.0638 0.0793 0.0718 0.0603 0.0563 0.0556 0.0543 0.0540 0.0540 0.0537 0.0537 0.0543 0.0551 

[TRAIN] Epoch[2](1112/1500); Loss: 0.078661; Backpropagation: 0.0950 sec; Batch: 0.4821 sec
0.0901 0.0901 0.0871 0.0796 0.0747 0.0739 0.0768 0.0765 0.0749 0.0757 0.0765 0.0753 0.0747 0.0774 0.0782 0.0771 

[TRAIN] Epoch[2](1113/1500); Loss: 0.112538; Backpropagation: 0.0957 sec; Batch: 0.4670 sec
0.2038 0.1665 0.1355 0.1266 0.1136 0.1053 0.1008 0.0971 0.0963 0.0958 0.0943 0.0927 0.0929 0.0928 0.0932 0.0935 

[TRAIN] Epoch[2](1114/1500); Loss: 0.084573; Backpropagation: 0.0957 sec; Batch: 0.4294 sec
0.1205 0.0936 0.0915 0.0879 0.0905 0.0869 0.0818 0.0804 0.0807 0.0789 0.0773 0.0775 0.0770 0.0753 0.0758 0.0777 

[TRAIN] Epoch[2](1115/1500); Loss: 0.063665; Backpropagation: 0.0935 sec; Batch: 0.4558 sec
0.0853 0.0603 0.0698 0.0641 0.0587 0.0577 0.0634 0.0624 0.0592 0.0585 0.0619 0.0630 0.0620 0.0639 0.0643 0.0640 

[TRAIN] Epoch[2](1116/1500); Loss: 0.139207; Backpropagation: 0.0938 sec; Batch: 0.4710 sec
0.1446 0.1455 0.1450 0.1508 0.1498 0.1425 0.1379 0.1348 0.1341 0.1336 0.1337 0.1343 0.1355 0.1349 0.1348 0.1355 

[TRAIN] Epoch[2](1117/1500); Loss: 0.133969; Backpropagation: 0.0938 sec; Batch: 0.4694 sec
0.1720 0.1559 0.1463 0.1407 0.1407 0.1350 0.1312 0.1286 0.1265 0.1251 0.1241 0.1240 0.1238 0.1234 0.1234 0.1228 

[TRAIN] Epoch[2](1118/1500); Loss: 0.045605; Backpropagation: 0.0938 sec; Batch: 0.4698 sec
0.0689 0.0628 0.0604 0.0525 0.0466 0.0418 0.0393 0.0387 0.0389 0.0390 0.0391 0.0390 0.0397 0.0408 0.0412 0.0412 

[TRAIN] Epoch[2](1119/1500); Loss: 0.062787; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.1058 0.0818 0.0834 0.0744 0.0641 0.0589 0.0549 0.0538 0.0544 0.0534 0.0531 0.0527 0.0532 0.0530 0.0531 0.0546 

[TRAIN] Epoch[2](1120/1500); Loss: 0.168934; Backpropagation: 0.0938 sec; Batch: 0.5276 sec
0.1654 0.1677 0.1757 0.1824 0.1789 0.1742 0.1708 0.1679 0.1665 0.1657 0.1648 0.1652 0.1652 0.1643 0.1638 0.1645 

[TRAIN] Epoch[2](1121/1500); Loss: 0.110749; Backpropagation: 0.0938 sec; Batch: 0.4658 sec
0.1687 0.1481 0.1365 0.1262 0.1185 0.1121 0.1053 0.1014 0.0983 0.0968 0.0947 0.0928 0.0926 0.0930 0.0931 0.0939 

[TRAIN] Epoch[2](1122/1500); Loss: 0.105216; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.1349 0.1249 0.1123 0.1076 0.1175 0.1158 0.1092 0.1055 0.1007 0.0977 0.0951 0.0932 0.0925 0.0921 0.0921 0.0924 

[TRAIN] Epoch[2](1123/1500); Loss: 0.058670; Backpropagation: 0.0939 sec; Batch: 0.4666 sec
0.0669 0.0630 0.0700 0.0707 0.0660 0.0608 0.0563 0.0540 0.0538 0.0536 0.0535 0.0530 0.0532 0.0545 0.0548 0.0547 

[TRAIN] Epoch[2](1124/1500); Loss: 0.124173; Backpropagation: 0.0935 sec; Batch: 0.4301 sec
0.1608 0.1592 0.1485 0.1404 0.1334 0.1279 0.1217 0.1176 0.1144 0.1118 0.1101 0.1089 0.1085 0.1081 0.1076 0.1079 

[TRAIN] Epoch[2](1125/1500); Loss: 0.110832; Backpropagation: 0.0940 sec; Batch: 0.4718 sec
0.1815 0.1683 0.1609 0.1393 0.1151 0.0982 0.0957 0.0940 0.0919 0.0905 0.0896 0.0892 0.0893 0.0896 0.0899 0.0902 

[TRAIN] Epoch[2](1126/1500); Loss: 0.174102; Backpropagation: 0.0932 sec; Batch: 0.4927 sec
0.1913 0.1905 0.1915 0.1884 0.1796 0.1765 0.1732 0.1715 0.1700 0.1690 0.1675 0.1656 0.1639 0.1630 0.1623 0.1618 

[TRAIN] Epoch[2](1127/1500); Loss: 0.150106; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1684 0.1680 0.1657 0.1617 0.1565 0.1534 0.1502 0.1477 0.1456 0.1437 0.1420 0.1410 0.1402 0.1396 0.1391 0.1390 

[TRAIN] Epoch[2](1128/1500); Loss: 0.105630; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.1153 0.1084 0.1078 0.1092 0.1075 0.1062 0.1055 0.1040 0.1029 0.1028 0.1031 0.1035 0.1035 0.1033 0.1033 0.1037 

[TRAIN] Epoch[2](1129/1500); Loss: 0.135842; Backpropagation: 0.0939 sec; Batch: 0.4545 sec
0.2142 0.1934 0.1775 0.1750 0.1497 0.1394 0.1300 0.1228 0.1156 0.1112 0.1082 0.1071 0.1071 0.1073 0.1074 0.1076 

[TRAIN] Epoch[2](1130/1500); Loss: 0.114692; Backpropagation: 0.0938 sec; Batch: 0.4674 sec
0.2072 0.1936 0.1560 0.1087 0.1120 0.1121 0.1018 0.0992 0.0954 0.0947 0.0936 0.0929 0.0922 0.0918 0.0919 0.0918 

[TRAIN] Epoch[2](1131/1500); Loss: 0.099184; Backpropagation: 0.0940 sec; Batch: 0.4322 sec
0.1422 0.1262 0.1189 0.1092 0.1013 0.0981 0.0948 0.0927 0.0906 0.0893 0.0883 0.0877 0.0874 0.0870 0.0867 0.0865 

[TRAIN] Epoch[2](1132/1500); Loss: 0.129432; Backpropagation: 0.0953 sec; Batch: 0.4303 sec
0.1936 0.1774 0.1568 0.1308 0.1308 0.1287 0.1211 0.1186 0.1156 0.1149 0.1143 0.1133 0.1130 0.1134 0.1140 0.1147 

[TRAIN] Epoch[2](1133/1500); Loss: 0.120574; Backpropagation: 0.0940 sec; Batch: 0.4653 sec
0.1960 0.1872 0.1549 0.1180 0.1173 0.1150 0.1079 0.1062 0.1045 0.1037 0.1029 0.1026 0.1028 0.1030 0.1035 0.1037 

[TRAIN] Epoch[2](1134/1500); Loss: 0.145410; Backpropagation: 0.0938 sec; Batch: 0.4397 sec
0.1888 0.1638 0.1546 0.1512 0.1466 0.1443 0.1428 0.1414 0.1394 0.1384 0.1373 0.1368 0.1363 0.1354 0.1348 0.1347 

[TRAIN] Epoch[2](1135/1500); Loss: 0.098242; Backpropagation: 0.0943 sec; Batch: 0.4296 sec
0.1965 0.1822 0.1484 0.1045 0.0814 0.0812 0.0778 0.0755 0.0766 0.0769 0.0766 0.0784 0.0785 0.0781 0.0793 0.0799 

[TRAIN] Epoch[2](1136/1500); Loss: 0.092249; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1429 0.1407 0.1246 0.1111 0.0959 0.0903 0.0851 0.0800 0.0781 0.0760 0.0745 0.0739 0.0742 0.0750 0.0762 0.0774 

[TRAIN] Epoch[2](1137/1500); Loss: 0.103195; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1691 0.1537 0.1320 0.1213 0.1075 0.1008 0.0959 0.0911 0.0879 0.0862 0.0850 0.0841 0.0836 0.0839 0.0842 0.0848 

[TRAIN] Epoch[2](1138/1500); Loss: 0.071584; Backpropagation: 0.0934 sec; Batch: 0.4296 sec
0.1390 0.1163 0.0967 0.0761 0.0675 0.0640 0.0617 0.0598 0.0583 0.0579 0.0575 0.0574 0.0577 0.0580 0.0582 0.0590 

[TRAIN] Epoch[2](1139/1500); Loss: 0.114950; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1529 0.1301 0.1224 0.1184 0.1148 0.1127 0.1112 0.1101 0.1095 0.1087 0.1079 0.1080 0.1078 0.1079 0.1083 0.1083 

[TRAIN] Epoch[2](1140/1500); Loss: 0.080895; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1418 0.1166 0.0966 0.0902 0.0845 0.0774 0.0731 0.0708 0.0685 0.0678 0.0670 0.0670 0.0675 0.0682 0.0689 0.0684 

[TRAIN] Epoch[2](1141/1500); Loss: 0.127474; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1898 0.1671 0.1530 0.1461 0.1290 0.1229 0.1181 0.1153 0.1128 0.1118 0.1111 0.1115 0.1118 0.1126 0.1133 0.1133 

[TRAIN] Epoch[2](1142/1500); Loss: 0.069686; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.0818 0.0842 0.0759 0.0732 0.0708 0.0692 0.0683 0.0674 0.0667 0.0662 0.0656 0.0652 0.0651 0.0651 0.0651 0.0651 

[TRAIN] Epoch[2](1143/1500); Loss: 0.064012; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1163 0.0883 0.0686 0.0678 0.0605 0.0590 0.0625 0.0627 0.0588 0.0568 0.0548 0.0541 0.0540 0.0538 0.0531 0.0529 

[TRAIN] Epoch[2](1144/1500); Loss: 0.108913; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1375 0.1163 0.1111 0.1094 0.1117 0.1085 0.1062 0.1050 0.1039 0.1041 0.1042 0.1046 0.1047 0.1046 0.1052 0.1054 

[TRAIN] Epoch[2](1145/1500); Loss: 0.084848; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.1377 0.1197 0.1076 0.1037 0.0869 0.0805 0.0771 0.0738 0.0726 0.0712 0.0716 0.0715 0.0711 0.0705 0.0709 0.0710 

[TRAIN] Epoch[2](1146/1500); Loss: 0.089085; Backpropagation: 0.0941 sec; Batch: 0.4317 sec
0.1043 0.0917 0.0917 0.0901 0.0875 0.0868 0.0859 0.0861 0.0866 0.0867 0.0872 0.0878 0.0879 0.0880 0.0882 0.0889 

[TRAIN] Epoch[2](1147/1500); Loss: 0.058944; Backpropagation: 0.0982 sec; Batch: 0.4336 sec
0.0864 0.0716 0.0638 0.0597 0.0568 0.0545 0.0554 0.0555 0.0543 0.0540 0.0542 0.0546 0.0545 0.0553 0.0559 0.0566 

[TRAIN] Epoch[2](1148/1500); Loss: 0.083028; Backpropagation: 0.0982 sec; Batch: 0.4334 sec
0.2014 0.1704 0.1415 0.1310 0.0906 0.0739 0.0611 0.0514 0.0493 0.0498 0.0503 0.0514 0.0509 0.0512 0.0518 0.0525 

[TRAIN] Epoch[2](1149/1500); Loss: 0.140508; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1985 0.1772 0.1541 0.1417 0.1370 0.1319 0.1298 0.1301 0.1307 0.1303 0.1308 0.1309 0.1306 0.1309 0.1316 0.1321 

[TRAIN] Epoch[2](1150/1500); Loss: 0.093402; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1257 0.1177 0.0983 0.0986 0.0961 0.0884 0.0865 0.0858 0.0857 0.0857 0.0866 0.0875 0.0874 0.0877 0.0882 0.0888 

[TRAIN] Epoch[2](1151/1500); Loss: 0.098532; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1464 0.1189 0.1099 0.1020 0.0975 0.0960 0.0941 0.0926 0.0908 0.0898 0.0893 0.0892 0.0891 0.0903 0.0904 0.0903 

[TRAIN] Epoch[2](1152/1500); Loss: 0.098953; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1279 0.1080 0.1028 0.1014 0.0971 0.0959 0.0950 0.0951 0.0949 0.0948 0.0947 0.0945 0.0947 0.0950 0.0956 0.0960 

[TRAIN] Epoch[2](1153/1500); Loss: 0.101795; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1884 0.1561 0.1344 0.1292 0.1109 0.1026 0.0957 0.0913 0.0860 0.0822 0.0784 0.0761 0.0745 0.0742 0.0741 0.0746 

[TRAIN] Epoch[2](1154/1500); Loss: 0.075466; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2271 0.2064 0.1422 0.0419 0.0820 0.0827 0.0517 0.0489 0.0382 0.0350 0.0343 0.0434 0.0483 0.0446 0.0416 0.0392 

[TRAIN] Epoch[2](1155/1500); Loss: 0.078869; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1167 0.0872 0.0775 0.0772 0.0749 0.0762 0.0798 0.0775 0.0754 0.0744 0.0741 0.0746 0.0745 0.0736 0.0733 0.0750 

[TRAIN] Epoch[2](1156/1500); Loss: 0.073616; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1422 0.0991 0.0810 0.0737 0.0701 0.0683 0.0658 0.0650 0.0646 0.0635 0.0628 0.0624 0.0636 0.0650 0.0652 0.0655 

[TRAIN] Epoch[2](1157/1500); Loss: 0.107971; Backpropagation: 0.0942 sec; Batch: 0.4311 sec
0.1611 0.1418 0.1240 0.1074 0.1033 0.1015 0.1000 0.0994 0.0988 0.0984 0.0983 0.0982 0.0985 0.0987 0.0989 0.0992 

[TRAIN] Epoch[2](1158/1500); Loss: 0.070850; Backpropagation: 0.0942 sec; Batch: 0.4281 sec
0.1488 0.1342 0.0925 0.0647 0.0839 0.0781 0.0649 0.0603 0.0538 0.0507 0.0486 0.0477 0.0483 0.0514 0.0531 0.0526 

[TRAIN] Epoch[2](1159/1500); Loss: 0.061127; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.0929 0.0792 0.0727 0.0664 0.0637 0.0613 0.0591 0.0574 0.0561 0.0550 0.0539 0.0532 0.0525 0.0519 0.0514 0.0511 

[TRAIN] Epoch[2](1160/1500); Loss: 0.108445; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1361 0.1253 0.1197 0.1116 0.1085 0.1065 0.1057 0.1047 0.1036 0.1028 0.1022 0.1016 0.1013 0.1013 0.1019 0.1023 

[TRAIN] Epoch[2](1161/1500); Loss: 0.107106; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1462 0.1352 0.1275 0.1233 0.1146 0.1104 0.1068 0.1029 0.0999 0.0974 0.0954 0.0934 0.0915 0.0903 0.0898 0.0892 

[TRAIN] Epoch[2](1162/1500); Loss: 0.097086; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1292 0.1197 0.1138 0.1069 0.1005 0.0979 0.0959 0.0935 0.0916 0.0890 0.0874 0.0859 0.0857 0.0857 0.0855 0.0852 

[TRAIN] Epoch[2](1163/1500); Loss: 0.107301; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1218 0.1142 0.1140 0.1101 0.1053 0.1050 0.1048 0.1046 0.1047 0.1049 0.1049 0.1047 0.1044 0.1044 0.1045 0.1045 

[TRAIN] Epoch[2](1164/1500); Loss: 0.128736; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.2301 0.2107 0.1949 0.1868 0.1543 0.1412 0.1282 0.1147 0.1015 0.0912 0.0839 0.0813 0.0818 0.0839 0.0868 0.0885 

[TRAIN] Epoch[2](1165/1500); Loss: 0.054146; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.0780 0.0692 0.0574 0.0686 0.0594 0.0540 0.0518 0.0489 0.0484 0.0472 0.0463 0.0463 0.0467 0.0478 0.0479 0.0485 

[TRAIN] Epoch[2](1166/1500); Loss: 0.090503; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.0988 0.0977 0.0963 0.0903 0.0896 0.0885 0.0883 0.0881 0.0883 0.0886 0.0884 0.0885 0.0888 0.0887 0.0893 0.0899 

[TRAIN] Epoch[2](1167/1500); Loss: 0.097525; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.3027 0.2338 0.1712 0.1114 0.0719 0.0636 0.0650 0.0605 0.0588 0.0582 0.0587 0.0589 0.0606 0.0618 0.0616 0.0617 

[TRAIN] Epoch[2](1168/1500); Loss: 0.072773; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1384 0.0838 0.0699 0.0695 0.0672 0.0661 0.0663 0.0665 0.0672 0.0663 0.0668 0.0663 0.0666 0.0673 0.0678 0.0685 

[TRAIN] Epoch[2](1169/1500); Loss: 0.115980; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.2165 0.1474 0.1156 0.1061 0.1103 0.1087 0.1052 0.1053 0.1053 0.1053 0.1052 0.1052 0.1042 0.1051 0.1047 0.1056 

[TRAIN] Epoch[2](1170/1500); Loss: 0.160777; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2081 0.1832 0.1728 0.1700 0.1617 0.1587 0.1554 0.1536 0.1529 0.1526 0.1510 0.1505 0.1501 0.1506 0.1504 0.1508 

[TRAIN] Epoch[2](1171/1500); Loss: 0.078526; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1343 0.0975 0.0836 0.0789 0.0744 0.0751 0.0735 0.0716 0.0714 0.0713 0.0710 0.0710 0.0708 0.0704 0.0710 0.0705 

[TRAIN] Epoch[2](1172/1500); Loss: 0.145151; Backpropagation: 0.0946 sec; Batch: 0.4291 sec
0.2100 0.1715 0.1609 0.1600 0.1510 0.1448 0.1410 0.1378 0.1346 0.1317 0.1306 0.1302 0.1294 0.1296 0.1296 0.1297 

[TRAIN] Epoch[2](1173/1500); Loss: 0.143361; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1880 0.1759 0.1663 0.1615 0.1493 0.1443 0.1394 0.1354 0.1329 0.1302 0.1285 0.1285 0.1287 0.1283 0.1281 0.1286 

[TRAIN] Epoch[2](1174/1500); Loss: 0.074666; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1147 0.0929 0.0821 0.0745 0.0726 0.0704 0.0696 0.0684 0.0675 0.0678 0.0688 0.0684 0.0687 0.0692 0.0692 0.0699 

[TRAIN] Epoch[2](1175/1500); Loss: 0.079287; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2602 0.1563 0.0906 0.0675 0.0618 0.0611 0.0581 0.0560 0.0565 0.0567 0.0569 0.0569 0.0569 0.0571 0.0579 0.0581 

[TRAIN] Epoch[2](1176/1500); Loss: 0.098531; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1226 0.1154 0.1084 0.1056 0.0996 0.0977 0.0966 0.0948 0.0938 0.0929 0.0923 0.0919 0.0919 0.0915 0.0910 0.0908 

[TRAIN] Epoch[2](1177/1500); Loss: 0.153782; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2229 0.1909 0.1779 0.1704 0.1557 0.1494 0.1458 0.1424 0.1395 0.1383 0.1381 0.1384 0.1377 0.1374 0.1376 0.1381 

[TRAIN] Epoch[2](1178/1500); Loss: 0.068093; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1443 0.1191 0.1043 0.0983 0.0684 0.0578 0.0527 0.0510 0.0500 0.0479 0.0487 0.0489 0.0487 0.0492 0.0500 0.0500 

[TRAIN] Epoch[2](1179/1500); Loss: 0.092290; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1035 0.1039 0.0970 0.0926 0.0925 0.0920 0.0908 0.0901 0.0897 0.0896 0.0889 0.0889 0.0894 0.0891 0.0892 0.0895 

[TRAIN] Epoch[2](1180/1500); Loss: 0.096721; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2214 0.1431 0.1043 0.0890 0.0880 0.0867 0.0854 0.0837 0.0820 0.0812 0.0804 0.0802 0.0806 0.0802 0.0805 0.0810 

[TRAIN] Epoch[2](1181/1500); Loss: 0.097470; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1688 0.1473 0.1335 0.1307 0.1011 0.0900 0.0827 0.0780 0.0801 0.0784 0.0781 0.0782 0.0776 0.0780 0.0783 0.0789 

[TRAIN] Epoch[2](1182/1500); Loss: 0.080851; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1330 0.1013 0.0892 0.0857 0.0772 0.0772 0.0732 0.0730 0.0724 0.0724 0.0725 0.0725 0.0727 0.0736 0.0737 0.0741 

[TRAIN] Epoch[2](1183/1500); Loss: 0.119911; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2195 0.1627 0.1357 0.1265 0.1172 0.1144 0.1095 0.1073 0.1060 0.1042 0.1036 0.1030 0.1025 0.1022 0.1020 0.1021 

[TRAIN] Epoch[2](1184/1500); Loss: 0.067828; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1837 0.1437 0.1168 0.1047 0.0518 0.0449 0.0412 0.0415 0.0422 0.0444 0.0452 0.0440 0.0443 0.0450 0.0446 0.0473 

[TRAIN] Epoch[2](1185/1500); Loss: 0.092665; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2629 0.1585 0.1011 0.0753 0.0743 0.0760 0.0736 0.0724 0.0724 0.0729 0.0734 0.0727 0.0741 0.0742 0.0737 0.0752 

[TRAIN] Epoch[2](1186/1500); Loss: 0.114519; Backpropagation: 0.0935 sec; Batch: 0.4287 sec
0.2530 0.1939 0.1581 0.1340 0.1087 0.0973 0.0942 0.0908 0.0892 0.0897 0.0877 0.0870 0.0874 0.0868 0.0874 0.0873 

[TRAIN] Epoch[2](1187/1500); Loss: 0.127679; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2449 0.1903 0.1731 0.1694 0.1450 0.1330 0.1256 0.1166 0.1055 0.0993 0.0930 0.0903 0.0915 0.0884 0.0884 0.0887 

[TRAIN] Epoch[2](1188/1500); Loss: 0.131247; Backpropagation: 0.0978 sec; Batch: 0.4322 sec
0.1883 0.1575 0.1405 0.1359 0.1272 0.1276 0.1238 0.1232 0.1219 0.1221 0.1215 0.1214 0.1219 0.1220 0.1220 0.1232 

[TRAIN] Epoch[2](1189/1500); Loss: 0.100231; Backpropagation: 0.0960 sec; Batch: 0.4305 sec
0.2188 0.1391 0.1101 0.1061 0.1016 0.0948 0.0903 0.0866 0.0848 0.0822 0.0815 0.0822 0.0816 0.0813 0.0811 0.0818 

[TRAIN] Epoch[2](1190/1500); Loss: 0.076695; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2034 0.1292 0.0912 0.0784 0.0706 0.0647 0.0612 0.0606 0.0579 0.0586 0.0580 0.0585 0.0580 0.0587 0.0589 0.0592 

[TRAIN] Epoch[2](1191/1500); Loss: 0.062970; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1079 0.0667 0.0649 0.0646 0.0593 0.0596 0.0580 0.0577 0.0576 0.0577 0.0578 0.0583 0.0583 0.0591 0.0601 0.0600 

[TRAIN] Epoch[2](1192/1500); Loss: 0.124951; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2029 0.1555 0.1388 0.1346 0.1279 0.1214 0.1176 0.1155 0.1138 0.1127 0.1109 0.1100 0.1093 0.1100 0.1094 0.1090 

[TRAIN] Epoch[2](1193/1500); Loss: 0.159502; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.2237 0.1974 0.1854 0.1826 0.1651 0.1598 0.1533 0.1487 0.1440 0.1419 0.1419 0.1413 0.1415 0.1417 0.1417 0.1421 

[TRAIN] Epoch[2](1194/1500); Loss: 0.095768; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1784 0.1322 0.1091 0.1003 0.0944 0.0894 0.0859 0.0838 0.0827 0.0823 0.0820 0.0818 0.0823 0.0821 0.0827 0.0829 

[TRAIN] Epoch[2](1195/1500); Loss: 0.110426; Backpropagation: 0.0942 sec; Batch: 0.4282 sec
0.1880 0.1420 0.1268 0.1202 0.1114 0.1070 0.1043 0.1021 0.1001 0.0978 0.0958 0.0948 0.0945 0.0943 0.0939 0.0939 

[TRAIN] Epoch[2](1196/1500); Loss: 0.120454; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.1773 0.1334 0.1280 0.1217 0.1193 0.1175 0.1158 0.1144 0.1131 0.1124 0.1124 0.1123 0.1121 0.1125 0.1126 0.1127 

[TRAIN] Epoch[2](1197/1500); Loss: 0.086294; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1695 0.1514 0.1336 0.1247 0.1013 0.0931 0.0840 0.0758 0.0674 0.0606 0.0556 0.0536 0.0539 0.0514 0.0526 0.0521 

[TRAIN] Epoch[2](1198/1500); Loss: 0.100204; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1974 0.1433 0.1178 0.1013 0.0975 0.0933 0.0904 0.0882 0.0867 0.0856 0.0849 0.0841 0.0835 0.0839 0.0829 0.0823 

[TRAIN] Epoch[2](1199/1500); Loss: 0.053566; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1231 0.0874 0.0636 0.0575 0.0579 0.0582 0.0412 0.0399 0.0408 0.0404 0.0409 0.0395 0.0415 0.0410 0.0420 0.0423 

[TRAIN] Epoch[2](1200/1500); Loss: 0.107685; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1651 0.1330 0.1207 0.1163 0.1088 0.1059 0.1029 0.1003 0.0988 0.0976 0.0965 0.0961 0.0957 0.0950 0.0950 0.0953 

[TRAIN] Epoch[2](1201/1500); Loss: 0.104391; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2471 0.1555 0.1107 0.0900 0.0871 0.0875 0.0879 0.0870 0.0877 0.0885 0.0885 0.0894 0.0897 0.0906 0.0912 0.0918 

[TRAIN] Epoch[2](1202/1500); Loss: 0.036400; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.0657 0.0472 0.0413 0.0367 0.0396 0.0372 0.0332 0.0317 0.0312 0.0318 0.0305 0.0310 0.0310 0.0313 0.0312 0.0320 

[TRAIN] Epoch[2](1203/1500); Loss: 0.088000; Backpropagation: 0.0937 sec; Batch: 0.4289 sec
0.3363 0.2178 0.1195 0.0527 0.0613 0.0614 0.0578 0.0602 0.0558 0.0529 0.0539 0.0547 0.0557 0.0553 0.0557 0.0572 

[TRAIN] Epoch[2](1204/1500); Loss: 0.058835; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1534 0.0866 0.0738 0.0598 0.0568 0.0470 0.0464 0.0427 0.0406 0.0394 0.0427 0.0428 0.0444 0.0519 0.0554 0.0578 

[TRAIN] Epoch[2](1205/1500); Loss: 0.069955; Backpropagation: 0.0959 sec; Batch: 0.4302 sec
0.1831 0.0960 0.0697 0.0660 0.0614 0.0589 0.0603 0.0587 0.0569 0.0570 0.0570 0.0577 0.0580 0.0589 0.0591 0.0605 

[TRAIN] Epoch[2](1206/1500); Loss: 0.191428; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.2483 0.2067 0.2008 0.1968 0.1944 0.1923 0.1890 0.1863 0.1842 0.1828 0.1823 0.1812 0.1798 0.1796 0.1794 0.1789 

[TRAIN] Epoch[2](1207/1500); Loss: 0.033333; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.0372 0.0546 0.0316 0.0273 0.0259 0.0278 0.0258 0.0264 0.0285 0.0304 0.0309 0.0331 0.0354 0.0373 0.0391 0.0420 

[TRAIN] Epoch[2](1208/1500); Loss: 0.218614; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.3428 0.3177 0.3013 0.2899 0.2380 0.2189 0.1989 0.1827 0.1718 0.1724 0.1769 0.1757 0.1765 0.1774 0.1782 0.1787 

[TRAIN] Epoch[2](1209/1500); Loss: 0.084245; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2005 0.1158 0.0887 0.0834 0.0774 0.0753 0.0740 0.0722 0.0710 0.0698 0.0696 0.0696 0.0697 0.0699 0.0705 0.0704 

[TRAIN] Epoch[2](1210/1500); Loss: 0.125149; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1547 0.1496 0.1399 0.1303 0.1235 0.1239 0.1221 0.1191 0.1180 0.1193 0.1177 0.1169 0.1175 0.1166 0.1160 0.1173 

[TRAIN] Epoch[2](1211/1500); Loss: 0.138537; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.3612 0.3058 0.2680 0.2514 0.1588 0.1255 0.0905 0.0686 0.0733 0.0667 0.0821 0.0776 0.0693 0.0704 0.0740 0.0735 

[TRAIN] Epoch[2](1212/1500); Loss: 0.132543; Backpropagation: 0.0959 sec; Batch: 0.4301 sec
0.3662 0.3024 0.2623 0.2459 0.1490 0.1142 0.0790 0.0589 0.0716 0.0642 0.0740 0.0693 0.0638 0.0662 0.0663 0.0673 

[TRAIN] Epoch[2](1213/1500); Loss: 0.076215; Backpropagation: 0.0948 sec; Batch: 0.4295 sec
0.1214 0.0987 0.0881 0.0769 0.0754 0.0754 0.0734 0.0698 0.0685 0.0682 0.0673 0.0676 0.0672 0.0670 0.0675 0.0671 

[TRAIN] Epoch[2](1214/1500); Loss: 0.081500; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2358 0.1511 0.0961 0.0920 0.0750 0.0666 0.0621 0.0637 0.0618 0.0588 0.0574 0.0568 0.0569 0.0566 0.0564 0.0568 

[TRAIN] Epoch[2](1215/1500); Loss: 0.201802; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.3351 0.3012 0.2785 0.2675 0.2095 0.1887 0.1710 0.1599 0.1619 0.1639 0.1643 0.1645 0.1653 0.1654 0.1656 0.1666 

[TRAIN] Epoch[2](1216/1500); Loss: 0.149456; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.2428 0.2013 0.1795 0.1699 0.1540 0.1486 0.1424 0.1377 0.1329 0.1291 0.1257 0.1256 0.1249 0.1263 0.1255 0.1251 

[TRAIN] Epoch[2](1217/1500); Loss: 0.046001; Backpropagation: 0.0942 sec; Batch: 0.4288 sec
0.0516 0.0492 0.0421 0.0446 0.0436 0.0442 0.0432 0.0428 0.0439 0.0459 0.0442 0.0465 0.0473 0.0469 0.0482 0.0519 

[TRAIN] Epoch[2](1218/1500); Loss: 0.071144; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1190 0.0908 0.0789 0.0734 0.0710 0.0686 0.0653 0.0646 0.0636 0.0625 0.0629 0.0629 0.0628 0.0635 0.0643 0.0642 

[TRAIN] Epoch[2](1219/1500); Loss: 0.115220; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.2128 0.1471 0.1243 0.1158 0.1098 0.1072 0.1053 0.1048 0.1034 0.1027 0.1017 0.1019 0.1022 0.1014 0.1014 0.1017 

[TRAIN] Epoch[2](1220/1500); Loss: 0.070740; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1277 0.0899 0.0797 0.0740 0.0743 0.0700 0.0631 0.0620 0.0613 0.0608 0.0602 0.0609 0.0607 0.0620 0.0619 0.0635 

[TRAIN] Epoch[2](1221/1500); Loss: 0.071645; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1913 0.1131 0.0729 0.0663 0.0613 0.0585 0.0591 0.0588 0.0571 0.0568 0.0582 0.0574 0.0574 0.0596 0.0586 0.0598 

[TRAIN] Epoch[2](1222/1500); Loss: 0.106993; Backpropagation: 0.0935 sec; Batch: 0.4270 sec
0.2251 0.1605 0.1237 0.1109 0.0979 0.0984 0.0917 0.0928 0.0910 0.0892 0.0881 0.0882 0.0887 0.0880 0.0888 0.0889 

[TRAIN] Epoch[2](1223/1500); Loss: 0.100753; Backpropagation: 0.0982 sec; Batch: 0.4326 sec
0.1939 0.1455 0.1452 0.1335 0.1081 0.0989 0.0943 0.0877 0.0794 0.0755 0.0750 0.0747 0.0760 0.0747 0.0744 0.0750 

[TRAIN] Epoch[2](1224/1500); Loss: 0.068285; Backpropagation: 0.0959 sec; Batch: 0.4305 sec
0.1835 0.1046 0.0731 0.0642 0.0600 0.0570 0.0558 0.0554 0.0549 0.0547 0.0555 0.0546 0.0540 0.0565 0.0546 0.0543 

[TRAIN] Epoch[2](1225/1500); Loss: 0.130342; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1651 0.1556 0.1435 0.1369 0.1277 0.1261 0.1237 0.1226 0.1221 0.1240 0.1231 0.1226 0.1228 0.1229 0.1232 0.1236 

[TRAIN] Epoch[2](1226/1500); Loss: 0.073900; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1750 0.0908 0.0863 0.0798 0.0677 0.0653 0.0613 0.0640 0.0624 0.0604 0.0607 0.0602 0.0610 0.0622 0.0623 0.0632 

[TRAIN] Epoch[2](1227/1500); Loss: 0.108257; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1996 0.1481 0.1269 0.1208 0.1067 0.1025 0.0954 0.0928 0.0916 0.0925 0.0914 0.0911 0.0921 0.0929 0.0932 0.0944 

[TRAIN] Epoch[2](1228/1500); Loss: 0.113025; Backpropagation: 0.0940 sec; Batch: 0.4276 sec
0.1549 0.1314 0.1172 0.1111 0.1113 0.1123 0.1099 0.1071 0.1072 0.1079 0.1067 0.1062 0.1065 0.1061 0.1060 0.1065 

[TRAIN] Epoch[2](1229/1500); Loss: 0.086269; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1932 0.1416 0.1284 0.1187 0.0916 0.0832 0.0762 0.0707 0.0639 0.0604 0.0603 0.0596 0.0586 0.0582 0.0581 0.0576 

[TRAIN] Epoch[2](1230/1500); Loss: 0.090655; Backpropagation: 0.0943 sec; Batch: 0.4284 sec
0.1473 0.1127 0.0998 0.0900 0.0886 0.0888 0.0838 0.0816 0.0816 0.0820 0.0819 0.0815 0.0823 0.0826 0.0825 0.0836 

[TRAIN] Epoch[2](1231/1500); Loss: 0.077669; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1336 0.0912 0.0871 0.0765 0.0745 0.0730 0.0720 0.0708 0.0705 0.0701 0.0706 0.0701 0.0707 0.0703 0.0707 0.0711 

[TRAIN] Epoch[2](1232/1500); Loss: 0.109743; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1517 0.1315 0.1191 0.1140 0.1106 0.1087 0.1044 0.1024 0.1024 0.1015 0.1014 0.1016 0.1018 0.1016 0.1011 0.1020 

[TRAIN] Epoch[2](1233/1500); Loss: 0.112704; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.3731 0.3023 0.2485 0.2284 0.1189 0.0782 0.0425 0.0406 0.0393 0.0573 0.0468 0.0426 0.0450 0.0453 0.0465 0.0481 

[TRAIN] Epoch[2](1234/1500); Loss: 0.074257; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1686 0.0905 0.0901 0.0812 0.0710 0.0688 0.0639 0.0621 0.0611 0.0610 0.0614 0.0607 0.0613 0.0622 0.0618 0.0625 

[TRAIN] Epoch[2](1235/1500); Loss: 0.116075; Backpropagation: 0.0957 sec; Batch: 0.4300 sec
0.1528 0.1329 0.1290 0.1201 0.1175 0.1160 0.1141 0.1120 0.1103 0.1093 0.1085 0.1080 0.1073 0.1067 0.1066 0.1062 

[TRAIN] Epoch[2](1236/1500); Loss: 0.138180; Backpropagation: 0.0958 sec; Batch: 0.4299 sec
0.1702 0.1537 0.1471 0.1421 0.1375 0.1357 0.1343 0.1336 0.1327 0.1323 0.1321 0.1317 0.1317 0.1319 0.1322 0.1320 

[TRAIN] Epoch[2](1237/1500); Loss: 0.127576; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.1788 0.1495 0.1384 0.1290 0.1238 0.1208 0.1199 0.1194 0.1187 0.1184 0.1191 0.1195 0.1202 0.1214 0.1219 0.1225 

[TRAIN] Epoch[2](1238/1500); Loss: 0.156097; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2095 0.1829 0.1723 0.1596 0.1573 0.1553 0.1519 0.1487 0.1471 0.1462 0.1454 0.1448 0.1444 0.1444 0.1441 0.1437 

[TRAIN] Epoch[2](1239/1500); Loss: 0.117637; Backpropagation: 0.0935 sec; Batch: 0.4270 sec
0.1701 0.1439 0.1290 0.1236 0.1161 0.1131 0.1103 0.1094 0.1089 0.1086 0.1082 0.1084 0.1080 0.1083 0.1081 0.1081 

[TRAIN] Epoch[2](1240/1500); Loss: 0.042966; Backpropagation: 0.0957 sec; Batch: 0.4296 sec
0.0513 0.0682 0.0474 0.0455 0.0429 0.0403 0.0388 0.0395 0.0389 0.0387 0.0386 0.0388 0.0393 0.0395 0.0396 0.0400 

[TRAIN] Epoch[2](1241/1500); Loss: 0.093227; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2297 0.1428 0.1032 0.0947 0.0874 0.0839 0.0740 0.0740 0.0737 0.0738 0.0738 0.0743 0.0750 0.0765 0.0765 0.0782 

[TRAIN] Epoch[2](1242/1500); Loss: 0.108652; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2017 0.1523 0.1231 0.1141 0.1041 0.1023 0.0982 0.0948 0.0940 0.0935 0.0931 0.0931 0.0927 0.0941 0.0935 0.0938 

[TRAIN] Epoch[2](1243/1500); Loss: 0.132478; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1844 0.1477 0.1403 0.1335 0.1332 0.1308 0.1267 0.1263 0.1262 0.1248 0.1242 0.1241 0.1243 0.1244 0.1241 0.1247 

[TRAIN] Epoch[2](1244/1500); Loss: 0.053286; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1259 0.0876 0.0629 0.0498 0.0504 0.0498 0.0434 0.0418 0.0417 0.0421 0.0410 0.0425 0.0426 0.0426 0.0439 0.0446 

[TRAIN] Epoch[2](1245/1500); Loss: 0.087768; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1339 0.1065 0.0958 0.0886 0.0848 0.0820 0.0816 0.0814 0.0804 0.0801 0.0808 0.0808 0.0810 0.0823 0.0819 0.0824 

[TRAIN] Epoch[2](1246/1500); Loss: 0.085596; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1328 0.1035 0.0948 0.0876 0.0828 0.0803 0.0790 0.0787 0.0789 0.0788 0.0782 0.0784 0.0786 0.0787 0.0790 0.0795 

[TRAIN] Epoch[2](1247/1500); Loss: 0.078527; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1178 0.1041 0.0886 0.0785 0.0765 0.0749 0.0728 0.0717 0.0717 0.0720 0.0709 0.0710 0.0720 0.0711 0.0710 0.0719 

[TRAIN] Epoch[2](1248/1500); Loss: 0.074432; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1507 0.1265 0.0990 0.0818 0.0713 0.0667 0.0610 0.0593 0.0599 0.0582 0.0582 0.0601 0.0586 0.0591 0.0606 0.0598 

[TRAIN] Epoch[2](1249/1500); Loss: 0.066033; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1798 0.0897 0.0762 0.0573 0.0564 0.0551 0.0567 0.0538 0.0527 0.0542 0.0535 0.0530 0.0548 0.0540 0.0544 0.0548 

[TRAIN] Epoch[2](1250/1500); Loss: 0.088904; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1334 0.1054 0.0963 0.0877 0.0852 0.0846 0.0815 0.0818 0.0829 0.0825 0.0822 0.0828 0.0835 0.0833 0.0842 0.0852 

[TRAIN] Epoch[2](1251/1500); Loss: 0.131760; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.2213 0.1834 0.1634 0.1566 0.1369 0.1292 0.1217 0.1171 0.1129 0.1108 0.1098 0.1095 0.1089 0.1087 0.1088 0.1091 

[TRAIN] Epoch[2](1252/1500); Loss: 0.141636; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.2171 0.1855 0.1715 0.1646 0.1445 0.1384 0.1324 0.1277 0.1246 0.1235 0.1228 0.1224 0.1230 0.1224 0.1224 0.1234 

[TRAIN] Epoch[2](1253/1500); Loss: 0.089972; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2324 0.1828 0.1475 0.1336 0.0774 0.0637 0.0613 0.0600 0.0634 0.0589 0.0588 0.0600 0.0594 0.0585 0.0621 0.0597 

[TRAIN] Epoch[2](1254/1500); Loss: 0.091423; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1616 0.1161 0.0916 0.0932 0.0833 0.0838 0.0827 0.0828 0.0817 0.0831 0.0829 0.0829 0.0837 0.0843 0.0841 0.0849 

[TRAIN] Epoch[2](1255/1500); Loss: 0.108179; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1563 0.1241 0.1075 0.1065 0.1065 0.1035 0.1032 0.1025 0.1034 0.1019 0.1021 0.1023 0.1025 0.1029 0.1030 0.1027 

[TRAIN] Epoch[2](1256/1500); Loss: 0.082823; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.3298 0.2107 0.1026 0.0460 0.0510 0.0495 0.0663 0.0555 0.0485 0.0498 0.0498 0.0509 0.0520 0.0525 0.0544 0.0560 

[TRAIN] Epoch[2](1257/1500); Loss: 0.122623; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1764 0.1537 0.1411 0.1333 0.1237 0.1195 0.1164 0.1131 0.1111 0.1106 0.1099 0.1098 0.1099 0.1108 0.1111 0.1115 

[TRAIN] Epoch[2](1258/1500); Loss: 0.097808; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1427 0.1253 0.1098 0.0976 0.0940 0.0906 0.0891 0.0882 0.0896 0.0895 0.0899 0.0903 0.0911 0.0924 0.0920 0.0929 

[TRAIN] Epoch[2](1259/1500); Loss: 0.067824; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1247 0.0778 0.0761 0.0669 0.0625 0.0620 0.0611 0.0605 0.0610 0.0606 0.0609 0.0612 0.0619 0.0624 0.0623 0.0632 

[TRAIN] Epoch[2](1260/1500); Loss: 0.157350; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.2209 0.1914 0.1772 0.1647 0.1578 0.1534 0.1504 0.1481 0.1462 0.1446 0.1439 0.1439 0.1436 0.1435 0.1440 0.1441 

[TRAIN] Epoch[2](1261/1500); Loss: 0.084413; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1751 0.1381 0.1060 0.0867 0.0767 0.0741 0.0718 0.0713 0.0710 0.0696 0.0688 0.0693 0.0681 0.0678 0.0683 0.0678 

[TRAIN] Epoch[2](1262/1500); Loss: 0.138519; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.3844 0.3399 0.2927 0.2684 0.1829 0.1503 0.1057 0.0727 0.0468 0.0601 0.0507 0.0549 0.0515 0.0527 0.0505 0.0521 

[TRAIN] Epoch[2](1263/1500); Loss: 0.070112; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1074 0.0917 0.0790 0.0727 0.0670 0.0658 0.0643 0.0629 0.0632 0.0634 0.0637 0.0636 0.0638 0.0641 0.0646 0.0646 

[TRAIN] Epoch[2](1264/1500); Loss: 0.104437; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1525 0.1215 0.1114 0.1043 0.1010 0.0994 0.0990 0.0985 0.0981 0.0979 0.0979 0.0977 0.0979 0.0981 0.0979 0.0979 

[TRAIN] Epoch[2](1265/1500); Loss: 0.092097; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1581 0.1183 0.1029 0.0942 0.0901 0.0867 0.0856 0.0846 0.0834 0.0827 0.0819 0.0816 0.0813 0.0808 0.0808 0.0806 

[TRAIN] Epoch[2](1266/1500); Loss: 0.156998; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2281 0.2095 0.1960 0.1859 0.1671 0.1611 0.1528 0.1467 0.1412 0.1361 0.1321 0.1308 0.1304 0.1319 0.1311 0.1310 

[TRAIN] Epoch[2](1267/1500); Loss: 0.132162; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1877 0.1771 0.1573 0.1458 0.1322 0.1274 0.1238 0.1210 0.1193 0.1182 0.1179 0.1175 0.1169 0.1174 0.1175 0.1175 

[TRAIN] Epoch[2](1268/1500); Loss: 0.115325; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2204 0.1697 0.1417 0.1233 0.1143 0.1080 0.1033 0.1002 0.0980 0.0969 0.0962 0.0956 0.0945 0.0944 0.0946 0.0940 

[TRAIN] Epoch[2](1269/1500); Loss: 0.135321; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.3744 0.2806 0.2076 0.1532 0.1211 0.1021 0.0915 0.0906 0.0924 0.0921 0.0918 0.0925 0.0935 0.0940 0.0936 0.0942 

[TRAIN] Epoch[2](1270/1500); Loss: 0.097553; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1430 0.1251 0.1139 0.1077 0.1030 0.0992 0.0962 0.0936 0.0907 0.0886 0.0872 0.0852 0.0836 0.0824 0.0810 0.0804 

[TRAIN] Epoch[2](1271/1500); Loss: 0.153124; Backpropagation: 0.0945 sec; Batch: 0.4291 sec
0.2657 0.2157 0.1864 0.1693 0.1608 0.1536 0.1462 0.1394 0.1343 0.1300 0.1275 0.1261 0.1253 0.1243 0.1229 0.1224 

[TRAIN] Epoch[2](1272/1500); Loss: 0.076384; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2088 0.1423 0.0958 0.0750 0.0669 0.0628 0.0601 0.0575 0.0564 0.0559 0.0559 0.0558 0.0567 0.0579 0.0570 0.0572 

[TRAIN] Epoch[2](1273/1500); Loss: 0.112392; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1934 0.1497 0.1288 0.1192 0.1148 0.1108 0.1080 0.1035 0.0998 0.0988 0.0969 0.0955 0.0956 0.0947 0.0941 0.0947 

[TRAIN] Epoch[2](1274/1500); Loss: 0.124492; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2190 0.1726 0.1469 0.1327 0.1267 0.1215 0.1169 0.1131 0.1107 0.1083 0.1065 0.1050 0.1039 0.1035 0.1026 0.1022 

[TRAIN] Epoch[2](1275/1500); Loss: 0.147506; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.2012 0.1750 0.1618 0.1541 0.1499 0.1457 0.1426 0.1405 0.1392 0.1382 0.1368 0.1357 0.1348 0.1349 0.1349 0.1349 

[TRAIN] Epoch[2](1276/1500); Loss: 0.083175; Backpropagation: 0.0980 sec; Batch: 0.4323 sec
0.1387 0.1221 0.1026 0.0907 0.0797 0.0783 0.0740 0.0719 0.0713 0.0717 0.0716 0.0716 0.0720 0.0712 0.0714 0.0720 

[TRAIN] Epoch[2](1277/1500); Loss: 0.072714; Backpropagation: 0.0959 sec; Batch: 0.4303 sec
0.2076 0.1303 0.0837 0.0650 0.0616 0.0603 0.0584 0.0566 0.0564 0.0558 0.0552 0.0550 0.0547 0.0539 0.0543 0.0547 

[TRAIN] Epoch[2](1278/1500); Loss: 0.136709; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2106 0.1705 0.1531 0.1424 0.1374 0.1338 0.1324 0.1295 0.1261 0.1240 0.1226 0.1216 0.1212 0.1214 0.1206 0.1200 

[TRAIN] Epoch[2](1279/1500); Loss: 0.114770; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1786 0.1376 0.1217 0.1155 0.1138 0.1106 0.1084 0.1081 0.1070 0.1063 0.1053 0.1053 0.1050 0.1048 0.1044 0.1039 

[TRAIN] Epoch[2](1280/1500); Loss: 0.095173; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1775 0.1482 0.1283 0.1169 0.0998 0.0897 0.0813 0.0763 0.0751 0.0756 0.0756 0.0758 0.0753 0.0759 0.0757 0.0756 

[TRAIN] Epoch[2](1281/1500); Loss: 0.067969; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.1291 0.0910 0.0789 0.0761 0.0700 0.0659 0.0643 0.0621 0.0602 0.0587 0.0571 0.0564 0.0550 0.0544 0.0544 0.0539 

[TRAIN] Epoch[2](1282/1500); Loss: 0.066258; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1687 0.1086 0.0803 0.0635 0.0609 0.0575 0.0561 0.0541 0.0525 0.0517 0.0513 0.0509 0.0506 0.0504 0.0515 0.0515 

[TRAIN] Epoch[2](1283/1500); Loss: 0.105505; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2132 0.1632 0.1288 0.1123 0.1045 0.0982 0.0936 0.0907 0.0886 0.0865 0.0857 0.0855 0.0843 0.0843 0.0843 0.0843 

[TRAIN] Epoch[2](1284/1500); Loss: 0.119365; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.1572 0.1338 0.1264 0.1238 0.1211 0.1185 0.1170 0.1156 0.1145 0.1137 0.1129 0.1122 0.1116 0.1110 0.1104 0.1102 

[TRAIN] Epoch[2](1285/1500); Loss: 0.133317; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2006 0.1708 0.1531 0.1437 0.1336 0.1283 0.1249 0.1224 0.1208 0.1205 0.1198 0.1192 0.1190 0.1189 0.1190 0.1188 

[TRAIN] Epoch[2](1286/1500); Loss: 0.138257; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2688 0.2336 0.2064 0.1864 0.1443 0.1306 0.1156 0.1048 0.1004 0.1013 0.1012 0.1020 0.1021 0.1034 0.1045 0.1065 

[TRAIN] Epoch[2](1287/1500); Loss: 0.079705; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.2325 0.1649 0.1133 0.0861 0.0712 0.0649 0.0609 0.0568 0.0543 0.0547 0.0538 0.0525 0.0526 0.0521 0.0523 0.0525 

[TRAIN] Epoch[2](1288/1500); Loss: 0.126456; Backpropagation: 0.0957 sec; Batch: 0.4300 sec
0.4551 0.3527 0.2632 0.1862 0.1293 0.0823 0.0550 0.0597 0.0536 0.0532 0.0578 0.0554 0.0543 0.0564 0.0549 0.0543 

[TRAIN] Epoch[2](1289/1500); Loss: 0.156171; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2528 0.2259 0.2053 0.1926 0.1728 0.1637 0.1532 0.1438 0.1350 0.1274 0.1235 0.1221 0.1211 0.1202 0.1198 0.1197 

[TRAIN] Epoch[2](1290/1500); Loss: 0.213311; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.3126 0.2848 0.2640 0.2518 0.2297 0.2184 0.2042 0.1952 0.1884 0.1834 0.1806 0.1797 0.1798 0.1805 0.1799 0.1800 

[TRAIN] Epoch[2](1291/1500); Loss: 0.099584; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2234 0.1898 0.1567 0.1413 0.1047 0.0894 0.0769 0.0730 0.0694 0.0675 0.0666 0.0679 0.0669 0.0663 0.0668 0.0667 

[TRAIN] Epoch[2](1292/1500); Loss: 0.074186; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.1372 0.1184 0.0997 0.0899 0.0763 0.0708 0.0654 0.0626 0.0616 0.0597 0.0582 0.0578 0.0576 0.0572 0.0573 0.0571 

[TRAIN] Epoch[2](1293/1500); Loss: 0.135139; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1757 0.1529 0.1448 0.1431 0.1405 0.1364 0.1338 0.1322 0.1301 0.1281 0.1263 0.1248 0.1242 0.1236 0.1230 0.1229 

[TRAIN] Epoch[2](1294/1500); Loss: 0.110364; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2624 0.2253 0.1888 0.1659 0.1243 0.1028 0.0820 0.0790 0.0726 0.0673 0.0664 0.0666 0.0652 0.0653 0.0653 0.0666 

[TRAIN] Epoch[2](1295/1500); Loss: 0.120302; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.2554 0.2184 0.1901 0.1688 0.1444 0.1291 0.1131 0.0995 0.0874 0.0779 0.0746 0.0743 0.0731 0.0729 0.0731 0.0728 

[TRAIN] Epoch[2](1296/1500); Loss: 0.103123; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2779 0.2370 0.1901 0.1675 0.1014 0.0803 0.0651 0.0640 0.0638 0.0578 0.0584 0.0587 0.0560 0.0567 0.0580 0.0574 

[TRAIN] Epoch[2](1297/1500); Loss: 0.117298; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1589 0.1360 0.1300 0.1210 0.1158 0.1132 0.1117 0.1104 0.1103 0.1096 0.1093 0.1095 0.1093 0.1099 0.1109 0.1110 

[TRAIN] Epoch[2](1298/1500); Loss: 0.106471; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1506 0.1401 0.1253 0.1158 0.1051 0.1012 0.0982 0.0963 0.0955 0.0952 0.0953 0.0956 0.0963 0.0969 0.0977 0.0984 

[TRAIN] Epoch[2](1299/1500); Loss: 0.073171; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.1512 0.1172 0.0982 0.0866 0.0748 0.0681 0.0619 0.0589 0.0588 0.0573 0.0564 0.0561 0.0570 0.0556 0.0556 0.0569 

[TRAIN] Epoch[2](1300/1500); Loss: 0.138497; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2118 0.1795 0.1556 0.1360 0.1338 0.1330 0.1307 0.1289 0.1294 0.1270 0.1259 0.1258 0.1250 0.1248 0.1242 0.1247 

[TRAIN] Epoch[2](1301/1500); Loss: 0.117248; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2667 0.2212 0.1838 0.1568 0.1231 0.1028 0.0865 0.0842 0.0828 0.0827 0.0805 0.0799 0.0814 0.0811 0.0806 0.0819 

[TRAIN] Epoch[2](1302/1500); Loss: 0.093085; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1594 0.1178 0.0993 0.0865 0.0863 0.0862 0.0845 0.0840 0.0850 0.0846 0.0848 0.0862 0.0857 0.0858 0.0859 0.0875 

[TRAIN] Epoch[2](1303/1500); Loss: 0.102130; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.4113 0.3043 0.2108 0.1252 0.0623 0.0466 0.0518 0.0441 0.0470 0.0479 0.0477 0.0441 0.0485 0.0495 0.0468 0.0462 

[TRAIN] Epoch[2](1304/1500); Loss: 0.113741; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.4450 0.3393 0.2446 0.1530 0.0726 0.0462 0.0496 0.0503 0.0624 0.0505 0.0491 0.0498 0.0547 0.0502 0.0492 0.0533 

[TRAIN] Epoch[2](1305/1500); Loss: 0.114815; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2382 0.1999 0.1674 0.1458 0.1190 0.1055 0.0956 0.0905 0.0868 0.0850 0.0850 0.0840 0.0833 0.0836 0.0842 0.0833 

[TRAIN] Epoch[2](1306/1500); Loss: 0.107801; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.3299 0.2486 0.1852 0.1368 0.1056 0.0826 0.0670 0.0619 0.0621 0.0624 0.0623 0.0640 0.0634 0.0632 0.0649 0.0651 

[TRAIN] Epoch[2](1307/1500); Loss: 0.079883; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1766 0.1239 0.0888 0.0710 0.0703 0.0685 0.0683 0.0686 0.0666 0.0666 0.0696 0.0674 0.0667 0.0692 0.0678 0.0681 

[TRAIN] Epoch[2](1308/1500); Loss: 0.081367; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2297 0.1577 0.1048 0.0679 0.0567 0.0621 0.0574 0.0584 0.0591 0.0634 0.0617 0.0619 0.0635 0.0661 0.0648 0.0669 

[TRAIN] Epoch[2](1309/1500); Loss: 0.049835; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.0794 0.0630 0.0542 0.0494 0.0478 0.0458 0.0449 0.0451 0.0447 0.0461 0.0448 0.0454 0.0467 0.0461 0.0465 0.0476 

[TRAIN] Epoch[2](1310/1500); Loss: 0.121977; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1816 0.1557 0.1401 0.1250 0.1221 0.1213 0.1174 0.1157 0.1154 0.1118 0.1107 0.1089 0.1081 0.1065 0.1063 0.1051 

[TRAIN] Epoch[2](1311/1500); Loss: 0.105359; Backpropagation: 0.0960 sec; Batch: 0.4300 sec
0.1953 0.1517 0.1191 0.1043 0.1014 0.0952 0.0927 0.0932 0.0938 0.0914 0.0908 0.0924 0.0909 0.0905 0.0917 0.0914 

[TRAIN] Epoch[2](1312/1500); Loss: 0.122883; Backpropagation: 0.0945 sec; Batch: 0.4288 sec
0.2372 0.1943 0.1684 0.1450 0.1305 0.1150 0.1048 0.0988 0.0970 0.0967 0.0965 0.0970 0.0967 0.0959 0.0958 0.0963 

[TRAIN] Epoch[2](1313/1500); Loss: 0.066378; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1209 0.0906 0.0777 0.0664 0.0629 0.0608 0.0611 0.0592 0.0589 0.0586 0.0577 0.0578 0.0575 0.0573 0.0572 0.0574 

[TRAIN] Epoch[2](1314/1500); Loss: 0.096775; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2219 0.1930 0.1566 0.1389 0.0913 0.0780 0.0684 0.0682 0.0672 0.0655 0.0658 0.0670 0.0671 0.0662 0.0666 0.0668 

[TRAIN] Epoch[2](1315/1500); Loss: 0.080176; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1256 0.0918 0.0798 0.0766 0.0766 0.0754 0.0758 0.0748 0.0746 0.0755 0.0754 0.0751 0.0758 0.0767 0.0767 0.0767 

[TRAIN] Epoch[2](1316/1500); Loss: 0.070499; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.2452 0.1557 0.0881 0.0575 0.0541 0.0492 0.0485 0.0499 0.0479 0.0468 0.0483 0.0477 0.0466 0.0475 0.0478 0.0471 

[TRAIN] Epoch[2](1317/1500); Loss: 0.094719; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1528 0.1249 0.1111 0.1038 0.0953 0.0906 0.0868 0.0851 0.0840 0.0834 0.0830 0.0830 0.0829 0.0827 0.0828 0.0833 

[TRAIN] Epoch[2](1318/1500); Loss: 0.101167; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.2195 0.1592 0.1233 0.1011 0.0928 0.0864 0.0826 0.0809 0.0813 0.0825 0.0812 0.0819 0.0858 0.0849 0.0856 0.0898 

[TRAIN] Epoch[2](1319/1500); Loss: 0.107188; Backpropagation: 0.0935 sec; Batch: 0.4336 sec
0.2034 0.1646 0.1409 0.1255 0.1151 0.1066 0.0988 0.0920 0.0873 0.0845 0.0829 0.0826 0.0821 0.0826 0.0833 0.0828 

[TRAIN] Epoch[2](1320/1500); Loss: 0.102174; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1809 0.1257 0.1291 0.1150 0.1081 0.1047 0.1031 0.0977 0.0945 0.0929 0.0882 0.0846 0.0825 0.0786 0.0760 0.0733 

[TRAIN] Epoch[2](1321/1500); Loss: 0.092578; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1635 0.1350 0.1171 0.1124 0.1100 0.1029 0.0889 0.0818 0.0787 0.0764 0.0701 0.0694 0.0686 0.0673 0.0688 0.0703 

[TRAIN] Epoch[2](1322/1500); Loss: 0.108594; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2223 0.1888 0.1587 0.1472 0.1031 0.0906 0.0852 0.0850 0.0829 0.0813 0.0826 0.0825 0.0812 0.0820 0.0822 0.0819 

[TRAIN] Epoch[2](1323/1500); Loss: 0.072996; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1422 0.1047 0.0872 0.0821 0.0760 0.0694 0.0656 0.0641 0.0627 0.0610 0.0605 0.0594 0.0589 0.0581 0.0581 0.0581 

[TRAIN] Epoch[2](1324/1500); Loss: 0.104158; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1575 0.1300 0.1186 0.1110 0.1046 0.1010 0.0979 0.0962 0.0955 0.0947 0.0942 0.0936 0.0931 0.0928 0.0928 0.0930 

[TRAIN] Epoch[2](1325/1500); Loss: 0.126477; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.3086 0.2388 0.1857 0.1519 0.1295 0.1130 0.1005 0.0923 0.0888 0.0880 0.0880 0.0877 0.0877 0.0879 0.0877 0.0876 

[TRAIN] Epoch[2](1326/1500); Loss: 0.097244; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.2588 0.1922 0.1424 0.1086 0.0901 0.0788 0.0736 0.0708 0.0698 0.0682 0.0676 0.0671 0.0671 0.0669 0.0668 0.0671 

[TRAIN] Epoch[2](1327/1500); Loss: 0.113603; Backpropagation: 0.0938 sec; Batch: 0.4286 sec
0.2396 0.1962 0.1635 0.1436 0.1166 0.1060 0.0949 0.0897 0.0878 0.0851 0.0835 0.0831 0.0824 0.0825 0.0814 0.0816 

[TRAIN] Epoch[2](1328/1500); Loss: 0.127946; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2101 0.1755 0.1533 0.1351 0.1249 0.1191 0.1166 0.1146 0.1140 0.1132 0.1124 0.1121 0.1117 0.1116 0.1115 0.1113 

[TRAIN] Epoch[2](1329/1500); Loss: 0.120195; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.3706 0.2767 0.1982 0.1360 0.0864 0.0812 0.0769 0.0769 0.0773 0.0767 0.0760 0.0788 0.0784 0.0763 0.0777 0.0791 

[TRAIN] Epoch[2](1330/1500); Loss: 0.088278; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2348 0.1601 0.1150 0.0907 0.0767 0.0735 0.0701 0.0692 0.0675 0.0656 0.0655 0.0655 0.0643 0.0647 0.0645 0.0647 

[TRAIN] Epoch[2](1331/1500); Loss: 0.113475; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2116 0.1762 0.1524 0.1365 0.1214 0.1101 0.0977 0.0914 0.0900 0.0898 0.0882 0.0894 0.0910 0.0897 0.0895 0.0907 

[TRAIN] Epoch[2](1332/1500); Loss: 0.067375; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1136 0.1001 0.0818 0.0743 0.0657 0.0629 0.0601 0.0583 0.0576 0.0575 0.0572 0.0570 0.0575 0.0579 0.0580 0.0586 

[TRAIN] Epoch[2](1333/1500); Loss: 0.110933; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2271 0.1808 0.1469 0.1180 0.1003 0.0909 0.0908 0.0910 0.0903 0.0900 0.0894 0.0910 0.0919 0.0911 0.0923 0.0931 

[TRAIN] Epoch[2](1334/1500); Loss: 0.093524; Backpropagation: 0.0942 sec; Batch: 0.4282 sec
0.1828 0.1555 0.1330 0.1220 0.0976 0.0886 0.0788 0.0738 0.0717 0.0715 0.0707 0.0699 0.0694 0.0715 0.0697 0.0699 

[TRAIN] Epoch[2](1335/1500); Loss: 0.066854; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.0809 0.0704 0.0663 0.0687 0.0649 0.0628 0.0631 0.0622 0.0620 0.0639 0.0637 0.0649 0.0665 0.0683 0.0697 0.0713 

[TRAIN] Epoch[2](1336/1500); Loss: 0.076173; Backpropagation: 0.0983 sec; Batch: 0.4323 sec
0.1186 0.0957 0.0885 0.0798 0.0748 0.0716 0.0707 0.0690 0.0686 0.0696 0.0686 0.0680 0.0691 0.0681 0.0684 0.0696 

[TRAIN] Epoch[2](1337/1500); Loss: 0.089199; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.2941 0.2082 0.1456 0.1057 0.0835 0.0626 0.0549 0.0535 0.0523 0.0499 0.0537 0.0524 0.0514 0.0516 0.0547 0.0532 

[TRAIN] Epoch[2](1338/1500); Loss: 0.102941; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2615 0.1931 0.1510 0.1206 0.0989 0.0850 0.0762 0.0735 0.0727 0.0743 0.0744 0.0725 0.0727 0.0744 0.0728 0.0734 

[TRAIN] Epoch[2](1339/1500); Loss: 0.175553; Backpropagation: 0.0944 sec; Batch: 0.4295 sec
0.2567 0.2081 0.1911 0.1819 0.1769 0.1729 0.1692 0.1667 0.1647 0.1629 0.1613 0.1605 0.1595 0.1592 0.1589 0.1582 

[TRAIN] Epoch[2](1340/1500); Loss: 0.095491; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.2785 0.2039 0.1521 0.1125 0.0892 0.0746 0.0660 0.0636 0.0620 0.0607 0.0607 0.0599 0.0599 0.0604 0.0620 0.0618 

[TRAIN] Epoch[2](1341/1500); Loss: 0.062792; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1075 0.0877 0.0704 0.0647 0.0595 0.0594 0.0571 0.0557 0.0553 0.0559 0.0547 0.0548 0.0553 0.0550 0.0553 0.0563 

[TRAIN] Epoch[2](1342/1500); Loss: 0.127134; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2143 0.1784 0.1549 0.1418 0.1253 0.1202 0.1151 0.1109 0.1098 0.1110 0.1091 0.1080 0.1090 0.1089 0.1082 0.1092 

[TRAIN] Epoch[2](1343/1500); Loss: 0.049026; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1319 0.1084 0.0837 0.0749 0.0449 0.0377 0.0292 0.0286 0.0298 0.0307 0.0291 0.0311 0.0307 0.0310 0.0313 0.0315 

[TRAIN] Epoch[2](1344/1500); Loss: 0.108067; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1892 0.1553 0.1295 0.1140 0.1046 0.1007 0.0957 0.0934 0.0927 0.0932 0.0924 0.0931 0.0939 0.0934 0.0935 0.0944 

[TRAIN] Epoch[2](1345/1500); Loss: 0.107878; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.3194 0.2181 0.1448 0.1041 0.0912 0.0856 0.0818 0.0793 0.0784 0.0768 0.0747 0.0749 0.0744 0.0736 0.0741 0.0750 

[TRAIN] Epoch[2](1346/1500); Loss: 0.051382; Backpropagation: 0.0940 sec; Batch: 0.4277 sec
0.1127 0.0713 0.0583 0.0514 0.0501 0.0455 0.0444 0.0425 0.0414 0.0414 0.0421 0.0421 0.0430 0.0443 0.0451 0.0464 

[TRAIN] Epoch[2](1347/1500); Loss: 0.098096; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1532 0.1284 0.1107 0.1030 0.0958 0.0923 0.0891 0.0873 0.0872 0.0860 0.0864 0.0875 0.0883 0.0900 0.0915 0.0927 

[TRAIN] Epoch[2](1348/1500); Loss: 0.166630; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2738 0.2276 0.1980 0.1796 0.1701 0.1622 0.1538 0.1500 0.1474 0.1444 0.1436 0.1437 0.1436 0.1428 0.1428 0.1426 

[TRAIN] Epoch[2](1349/1500); Loss: 0.096980; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1394 0.1154 0.1061 0.1008 0.0983 0.0953 0.0930 0.0913 0.0901 0.0893 0.0888 0.0887 0.0885 0.0887 0.0889 0.0890 

[TRAIN] Epoch[2](1350/1500); Loss: 0.125201; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.2145 0.1626 0.1386 0.1261 0.1202 0.1145 0.1114 0.1098 0.1086 0.1089 0.1098 0.1113 0.1128 0.1154 0.1180 0.1208 

[TRAIN] Epoch[2](1351/1500); Loss: 0.056652; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.0833 0.0669 0.0610 0.0550 0.0500 0.0487 0.0529 0.0489 0.0470 0.0494 0.0502 0.0521 0.0562 0.0580 0.0608 0.0662 

[TRAIN] Epoch[2](1352/1500); Loss: 0.068832; Backpropagation: 0.0941 sec; Batch: 0.4276 sec
0.1803 0.1156 0.0864 0.0730 0.0672 0.0613 0.0568 0.0536 0.0518 0.0504 0.0495 0.0494 0.0496 0.0507 0.0519 0.0537 

[TRAIN] Epoch[2](1353/1500); Loss: 0.092333; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.1983 0.1608 0.1262 0.1137 0.0863 0.0822 0.0745 0.0720 0.0718 0.0706 0.0700 0.0702 0.0703 0.0700 0.0697 0.0708 

[TRAIN] Epoch[2](1354/1500); Loss: 0.067837; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2289 0.1663 0.1247 0.0881 0.0644 0.0465 0.0398 0.0377 0.0361 0.0372 0.0358 0.0362 0.0356 0.0353 0.0363 0.0366 

[TRAIN] Epoch[2](1355/1500); Loss: 0.077122; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2239 0.1444 0.0979 0.0747 0.0660 0.0612 0.0585 0.0570 0.0564 0.0555 0.0552 0.0562 0.0560 0.0561 0.0575 0.0575 

[TRAIN] Epoch[2](1356/1500); Loss: 0.079637; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1503 0.1056 0.0837 0.0782 0.0719 0.0688 0.0671 0.0669 0.0687 0.0682 0.0692 0.0720 0.0728 0.0746 0.0774 0.0790 

[TRAIN] Epoch[2](1357/1500); Loss: 0.127877; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.2829 0.2310 0.1922 0.1693 0.1481 0.1339 0.1187 0.1045 0.0926 0.0857 0.0846 0.0818 0.0801 0.0801 0.0803 0.0802 

[TRAIN] Epoch[2](1358/1500); Loss: 0.100715; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1233 0.1081 0.1025 0.1027 0.0999 0.0993 0.0986 0.0979 0.0981 0.0975 0.0974 0.0972 0.0975 0.0972 0.0971 0.0973 

[TRAIN] Epoch[2](1359/1500); Loss: 0.123783; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1855 0.1585 0.1383 0.1323 0.1227 0.1193 0.1151 0.1133 0.1132 0.1123 0.1111 0.1120 0.1116 0.1116 0.1118 0.1119 

[TRAIN] Epoch[2](1360/1500); Loss: 0.093089; Backpropagation: 0.0940 sec; Batch: 0.4397 sec
0.1474 0.1187 0.1044 0.0996 0.0937 0.0902 0.0875 0.0854 0.0837 0.0822 0.0817 0.0822 0.0823 0.0830 0.0834 0.0841 

[TRAIN] Epoch[2](1361/1500); Loss: 0.096568; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1465 0.1196 0.0987 0.0913 0.1060 0.0977 0.0863 0.0876 0.0894 0.0861 0.0866 0.0908 0.0889 0.0871 0.0905 0.0921 

[TRAIN] Epoch[2](1362/1500); Loss: 0.049115; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.0556 0.0622 0.0488 0.0487 0.0470 0.0510 0.0458 0.0457 0.0496 0.0468 0.0463 0.0489 0.0468 0.0473 0.0479 0.0472 

[TRAIN] Epoch[2](1363/1500); Loss: 0.100983; Backpropagation: 0.0936 sec; Batch: 0.4271 sec
0.1393 0.1164 0.1038 0.0985 0.0984 0.0968 0.0956 0.0958 0.0958 0.0955 0.0958 0.0960 0.0966 0.0967 0.0972 0.0974 

[TRAIN] Epoch[2](1364/1500); Loss: 0.122494; Backpropagation: 0.0957 sec; Batch: 0.4295 sec
0.1612 0.1378 0.1301 0.1255 0.1240 0.1199 0.1175 0.1169 0.1163 0.1157 0.1152 0.1155 0.1153 0.1157 0.1166 0.1168 

[TRAIN] Epoch[2](1365/1500); Loss: 0.083786; Backpropagation: 0.0954 sec; Batch: 0.4293 sec
0.1620 0.1196 0.1007 0.0954 0.0883 0.0816 0.0777 0.0738 0.0708 0.0687 0.0680 0.0674 0.0668 0.0666 0.0667 0.0667 

[TRAIN] Epoch[2](1366/1500); Loss: 0.116330; Backpropagation: 0.0948 sec; Batch: 0.4289 sec
0.1740 0.1454 0.1248 0.1139 0.1090 0.1089 0.1079 0.1072 0.1073 0.1080 0.1077 0.1079 0.1089 0.1094 0.1101 0.1110 

[TRAIN] Epoch[2](1367/1500); Loss: 0.057857; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.0675 0.0665 0.0571 0.0544 0.0575 0.0584 0.0551 0.0561 0.0572 0.0558 0.0564 0.0568 0.0560 0.0571 0.0566 0.0572 

[TRAIN] Epoch[2](1368/1500); Loss: 0.093754; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2578 0.2150 0.1710 0.1555 0.0856 0.0728 0.0587 0.0541 0.0551 0.0533 0.0525 0.0530 0.0536 0.0539 0.0535 0.0548 

[TRAIN] Epoch[2](1369/1500); Loss: 0.128400; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2619 0.2164 0.1807 0.1610 0.1325 0.1209 0.1076 0.1014 0.0992 0.0981 0.0973 0.0966 0.0955 0.0957 0.0946 0.0949 

[TRAIN] Epoch[2](1370/1500); Loss: 0.044147; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1250 0.0983 0.0699 0.0604 0.0420 0.0386 0.0283 0.0272 0.0265 0.0265 0.0256 0.0267 0.0268 0.0273 0.0279 0.0294 

[TRAIN] Epoch[2](1371/1500); Loss: 0.046552; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1171 0.0796 0.0423 0.0319 0.0803 0.0614 0.0318 0.0347 0.0315 0.0333 0.0311 0.0322 0.0332 0.0341 0.0348 0.0357 

[TRAIN] Epoch[2](1372/1500); Loss: 0.072137; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1057 0.0984 0.0827 0.0815 0.0693 0.0669 0.0654 0.0649 0.0647 0.0645 0.0645 0.0648 0.0647 0.0651 0.0652 0.0659 

[TRAIN] Epoch[2](1373/1500); Loss: 0.146596; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2256 0.1987 0.1796 0.1743 0.1513 0.1450 0.1380 0.1334 0.1276 0.1261 0.1255 0.1246 0.1239 0.1238 0.1240 0.1242 

[TRAIN] Epoch[2](1374/1500); Loss: 0.127753; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2166 0.1931 0.1739 0.1657 0.1427 0.1329 0.1218 0.1149 0.1055 0.1003 0.0971 0.0963 0.0961 0.0956 0.0957 0.0958 

[TRAIN] Epoch[2](1375/1500); Loss: 0.105185; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1453 0.1241 0.1095 0.1082 0.1045 0.1011 0.0997 0.0998 0.0990 0.0983 0.0985 0.0992 0.0989 0.0988 0.0990 0.0991 

[TRAIN] Epoch[2](1376/1500); Loss: 0.125094; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.2590 0.1889 0.1472 0.1273 0.1202 0.1135 0.1094 0.1073 0.1060 0.1051 0.1044 0.1036 0.1029 0.1027 0.1022 0.1017 

[TRAIN] Epoch[2](1377/1500); Loss: 0.075009; Backpropagation: 0.0991 sec; Batch: 0.4332 sec
0.1556 0.1210 0.1004 0.0922 0.0767 0.0703 0.0650 0.0621 0.0595 0.0586 0.0572 0.0568 0.0565 0.0561 0.0561 0.0560 

[TRAIN] Epoch[2](1378/1500); Loss: 0.082297; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2144 0.1834 0.1521 0.1429 0.0828 0.0702 0.0546 0.0523 0.0485 0.0476 0.0461 0.0452 0.0445 0.0441 0.0441 0.0438 

[TRAIN] Epoch[2](1379/1500); Loss: 0.062334; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1127 0.0883 0.0710 0.0722 0.0617 0.0570 0.0565 0.0549 0.0527 0.0545 0.0532 0.0523 0.0525 0.0526 0.0520 0.0533 

[TRAIN] Epoch[2](1380/1500); Loss: 0.148762; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.3691 0.3276 0.2933 0.2782 0.1882 0.1599 0.1210 0.1018 0.0627 0.0766 0.0637 0.0734 0.0655 0.0663 0.0647 0.0682 

[TRAIN] Epoch[2](1381/1500); Loss: 0.047862; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1276 0.0995 0.0751 0.0593 0.0401 0.0428 0.0305 0.0324 0.0323 0.0308 0.0319 0.0307 0.0323 0.0328 0.0335 0.0343 

[TRAIN] Epoch[2](1382/1500); Loss: 0.108880; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.2235 0.1983 0.1805 0.1672 0.1159 0.0997 0.0824 0.0770 0.0741 0.0738 0.0736 0.0744 0.0744 0.0751 0.0756 0.0766 

[TRAIN] Epoch[2](1383/1500); Loss: 0.089918; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.1533 0.1361 0.1249 0.1201 0.1005 0.0951 0.0887 0.0838 0.0783 0.0729 0.0687 0.0644 0.0626 0.0625 0.0633 0.0635 

[TRAIN] Epoch[2](1384/1500); Loss: 0.071040; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1045 0.0908 0.0838 0.0789 0.0704 0.0676 0.0645 0.0636 0.0637 0.0633 0.0636 0.0640 0.0642 0.0644 0.0645 0.0648 

[TRAIN] Epoch[2](1385/1500); Loss: 0.055895; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1881 0.0921 0.0453 0.0531 0.0424 0.0418 0.0442 0.0445 0.0401 0.0408 0.0455 0.0425 0.0432 0.0437 0.0421 0.0451 

[TRAIN] Epoch[2](1386/1500); Loss: 0.070280; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1286 0.0925 0.0832 0.0762 0.0681 0.0661 0.0634 0.0623 0.0619 0.0610 0.0604 0.0604 0.0602 0.0600 0.0599 0.0604 

[TRAIN] Epoch[2](1387/1500); Loss: 0.074456; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.1144 0.0971 0.0870 0.0842 0.0747 0.0726 0.0697 0.0688 0.0672 0.0662 0.0658 0.0648 0.0643 0.0646 0.0646 0.0652 

[TRAIN] Epoch[2](1388/1500); Loss: 0.108920; Backpropagation: 0.0944 sec; Batch: 0.4287 sec
0.1769 0.1423 0.1248 0.1159 0.1059 0.1020 0.0988 0.0987 0.0979 0.0974 0.0970 0.0967 0.0970 0.0971 0.0970 0.0973 

[TRAIN] Epoch[2](1389/1500); Loss: 0.084761; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1334 0.1077 0.0920 0.0847 0.0837 0.0812 0.0775 0.0774 0.0770 0.0766 0.0768 0.0771 0.0767 0.0771 0.0781 0.0792 

[TRAIN] Epoch[2](1390/1500); Loss: 0.063331; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1027 0.0777 0.0707 0.0652 0.0642 0.0595 0.0637 0.0597 0.0560 0.0555 0.0554 0.0558 0.0558 0.0569 0.0571 0.0575 

[TRAIN] Epoch[2](1391/1500); Loss: 0.083117; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.4101 0.2895 0.1800 0.0862 0.0252 0.0577 0.0276 0.0263 0.0277 0.0278 0.0263 0.0298 0.0285 0.0287 0.0290 0.0294 

[TRAIN] Epoch[2](1392/1500); Loss: 0.237445; Backpropagation: 0.0935 sec; Batch: 0.4268 sec
0.3460 0.3174 0.3065 0.2953 0.2738 0.2624 0.2446 0.2335 0.2173 0.2047 0.1940 0.1876 0.1821 0.1790 0.1775 0.1773 

[TRAIN] Epoch[2](1393/1500); Loss: 0.117330; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.1994 0.1598 0.1379 0.1232 0.1152 0.1110 0.1080 0.1059 0.1041 0.1031 0.1027 0.1017 0.1012 0.1012 0.1014 0.1014 

[TRAIN] Epoch[2](1394/1500); Loss: 0.174654; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2438 0.2309 0.2246 0.2148 0.1915 0.1835 0.1745 0.1689 0.1585 0.1522 0.1468 0.1439 0.1404 0.1398 0.1401 0.1402 

[TRAIN] Epoch[2](1395/1500); Loss: 0.166995; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2469 0.1948 0.1745 0.1668 0.1643 0.1635 0.1615 0.1597 0.1583 0.1572 0.1560 0.1548 0.1542 0.1536 0.1530 0.1530 

[TRAIN] Epoch[2](1396/1500); Loss: 0.060500; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1529 0.1342 0.1229 0.1037 0.0518 0.0366 0.0336 0.0326 0.0419 0.0395 0.0351 0.0346 0.0358 0.0365 0.0375 0.0391 

[TRAIN] Epoch[2](1397/1500); Loss: 0.142305; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2395 0.2023 0.1820 0.1685 0.1501 0.1446 0.1397 0.1351 0.1289 0.1242 0.1195 0.1153 0.1110 0.1077 0.1048 0.1035 

[TRAIN] Epoch[2](1398/1500); Loss: 0.125387; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1466 0.1397 0.1403 0.1313 0.1243 0.1221 0.1214 0.1199 0.1192 0.1195 0.1200 0.1201 0.1202 0.1204 0.1205 0.1207 

[TRAIN] Epoch[2](1399/1500); Loss: 0.235462; Backpropagation: 0.0941 sec; Batch: 0.4306 sec
0.3561 0.3322 0.3203 0.3012 0.2745 0.2616 0.2414 0.2292 0.2108 0.1967 0.1844 0.1774 0.1726 0.1699 0.1691 0.1702 

[TRAIN] Epoch[2](1400/1500); Loss: 0.072613; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.0986 0.1020 0.0950 0.0812 0.0726 0.0694 0.0676 0.0657 0.0641 0.0641 0.0635 0.0634 0.0633 0.0635 0.0637 0.0642 

[TRAIN] Epoch[2](1401/1500); Loss: 0.075118; Backpropagation: 0.0941 sec; Batch: 0.4404 sec
0.2710 0.1463 0.1025 0.0796 0.0622 0.0533 0.0496 0.0475 0.0505 0.0490 0.0472 0.0472 0.0479 0.0490 0.0493 0.0498 

[TRAIN] Epoch[2](1402/1500); Loss: 0.115858; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1723 0.1584 0.1481 0.1362 0.1135 0.1065 0.1020 0.1012 0.1016 0.1023 0.1016 0.1017 0.1015 0.1019 0.1022 0.1027 

[TRAIN] Epoch[2](1403/1500); Loss: 0.078976; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.1638 0.1409 0.1266 0.1182 0.0902 0.0797 0.0673 0.0623 0.0551 0.0525 0.0514 0.0505 0.0506 0.0511 0.0516 0.0518 

[TRAIN] Epoch[2](1404/1500); Loss: 0.109250; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2328 0.1978 0.1709 0.1458 0.1192 0.1006 0.0885 0.0797 0.0776 0.0773 0.0761 0.0762 0.0763 0.0765 0.0764 0.0763 

[TRAIN] Epoch[2](1405/1500); Loss: 0.105080; Backpropagation: 0.0934 sec; Batch: 0.4359 sec
0.2653 0.2017 0.1493 0.1144 0.1010 0.0946 0.0869 0.0851 0.0792 0.0750 0.0721 0.0712 0.0708 0.0715 0.0715 0.0715 

[TRAIN] Epoch[2](1406/1500); Loss: 0.141896; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2389 0.2000 0.1776 0.1591 0.1392 0.1282 0.1253 0.1237 0.1227 0.1218 0.1220 0.1221 0.1219 0.1225 0.1227 0.1227 

[TRAIN] Epoch[2](1407/1500); Loss: 0.060705; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1119 0.0841 0.0717 0.0653 0.0604 0.0579 0.0546 0.0538 0.0533 0.0511 0.0512 0.0514 0.0510 0.0510 0.0511 0.0516 

[TRAIN] Epoch[2](1408/1500); Loss: 0.140000; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2426 0.2016 0.1772 0.1632 0.1411 0.1334 0.1263 0.1223 0.1179 0.1163 0.1169 0.1167 0.1159 0.1163 0.1163 0.1162 

[TRAIN] Epoch[2](1409/1500); Loss: 0.066652; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1149 0.0939 0.0770 0.0697 0.0658 0.0621 0.0598 0.0587 0.0585 0.0578 0.0579 0.0584 0.0577 0.0578 0.0579 0.0584 

[TRAIN] Epoch[2](1410/1500); Loss: 0.128042; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2258 0.1998 0.1832 0.1711 0.1413 0.1316 0.1167 0.1077 0.0991 0.0976 0.0957 0.0961 0.0954 0.0956 0.0959 0.0960 

[TRAIN] Epoch[2](1411/1500); Loss: 0.089619; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1282 0.1117 0.0981 0.0909 0.0869 0.0879 0.0860 0.0847 0.0846 0.0837 0.0826 0.0823 0.0826 0.0817 0.0810 0.0811 

[TRAIN] Epoch[2](1412/1500); Loss: 0.084646; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1575 0.1135 0.0881 0.0805 0.0835 0.0814 0.0768 0.0764 0.0763 0.0746 0.0756 0.0740 0.0741 0.0740 0.0741 0.0738 

[TRAIN] Epoch[2](1413/1500); Loss: 0.146581; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2048 0.1782 0.1654 0.1596 0.1467 0.1380 0.1361 0.1366 0.1344 0.1348 0.1361 0.1352 0.1347 0.1346 0.1352 0.1347 

[TRAIN] Epoch[2](1414/1500); Loss: 0.086323; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1612 0.1142 0.1021 0.0919 0.0817 0.0809 0.0795 0.0775 0.0747 0.0740 0.0741 0.0733 0.0736 0.0741 0.0740 0.0743 

[TRAIN] Epoch[2](1415/1500); Loss: 0.111663; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2695 0.2065 0.1584 0.1232 0.1051 0.0915 0.0874 0.0831 0.0828 0.0831 0.0820 0.0819 0.0820 0.0826 0.0833 0.0842 

[TRAIN] Epoch[2](1416/1500); Loss: 0.105406; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1645 0.1268 0.1110 0.1065 0.1040 0.0996 0.0976 0.0980 0.0966 0.0961 0.0965 0.0965 0.0971 0.0972 0.0986 0.1000 

[TRAIN] Epoch[2](1417/1500); Loss: 0.093976; Backpropagation: 0.0943 sec; Batch: 0.4281 sec
0.2703 0.1925 0.1259 0.0839 0.0767 0.0741 0.0724 0.0704 0.0675 0.0676 0.0670 0.0672 0.0667 0.0667 0.0673 0.0674 

[TRAIN] Epoch[2](1418/1500); Loss: 0.077152; Backpropagation: 0.0989 sec; Batch: 0.4328 sec
0.1389 0.0942 0.0888 0.0803 0.0740 0.0710 0.0742 0.0695 0.0679 0.0681 0.0678 0.0669 0.0687 0.0681 0.0673 0.0685 

[TRAIN] Epoch[2](1419/1500); Loss: 0.064642; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1799 0.1505 0.1262 0.1156 0.0681 0.0545 0.0372 0.0330 0.0328 0.0367 0.0318 0.0310 0.0331 0.0343 0.0339 0.0357 

[TRAIN] Epoch[2](1420/1500); Loss: 0.124048; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2196 0.1927 0.1761 0.1674 0.1330 0.1174 0.1019 0.0985 0.0981 0.0971 0.0963 0.0974 0.0980 0.0969 0.0966 0.0976 

[TRAIN] Epoch[2](1421/1500); Loss: 0.059046; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1168 0.0676 0.0674 0.0573 0.0542 0.0518 0.0577 0.0520 0.0517 0.0524 0.0516 0.0519 0.0537 0.0523 0.0525 0.0538 

[TRAIN] Epoch[2](1422/1500); Loss: 0.155189; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1909 0.1693 0.1617 0.1588 0.1575 0.1537 0.1512 0.1499 0.1488 0.1486 0.1485 0.1483 0.1485 0.1487 0.1490 0.1498 

[TRAIN] Epoch[2](1423/1500); Loss: 0.082329; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1328 0.1070 0.0921 0.0833 0.0800 0.0776 0.0753 0.0744 0.0746 0.0738 0.0742 0.0741 0.0743 0.0741 0.0746 0.0750 

[TRAIN] Epoch[2](1424/1500); Loss: 0.132779; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2259 0.1954 0.1785 0.1709 0.1464 0.1375 0.1269 0.1202 0.1108 0.1045 0.1023 0.1012 0.1011 0.1010 0.1008 0.1008 

[TRAIN] Epoch[2](1425/1500); Loss: 0.050413; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.0739 0.0596 0.0517 0.0523 0.0521 0.0459 0.0444 0.0449 0.0460 0.0458 0.0452 0.0474 0.0480 0.0487 0.0502 0.0504 

[TRAIN] Epoch[2](1426/1500); Loss: 0.065567; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2063 0.1159 0.0594 0.0703 0.0515 0.0539 0.0488 0.0561 0.0477 0.0480 0.0470 0.0493 0.0470 0.0499 0.0482 0.0497 

[TRAIN] Epoch[2](1427/1500); Loss: 0.080769; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1807 0.1408 0.1123 0.0973 0.0862 0.0776 0.0690 0.0633 0.0614 0.0587 0.0580 0.0583 0.0577 0.0576 0.0564 0.0570 

[TRAIN] Epoch[2](1428/1500); Loss: 0.091175; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1526 0.1298 0.1149 0.1062 0.0948 0.0880 0.0827 0.0791 0.0761 0.0751 0.0752 0.0758 0.0762 0.0775 0.0771 0.0778 

[TRAIN] Epoch[2](1429/1500); Loss: 0.076658; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2043 0.1314 0.0853 0.0690 0.0620 0.0644 0.0627 0.0620 0.0598 0.0614 0.0613 0.0613 0.0596 0.0608 0.0612 0.0601 

[TRAIN] Epoch[2](1430/1500); Loss: 0.152537; Backpropagation: 0.0949 sec; Batch: 0.4297 sec
0.1965 0.1799 0.1700 0.1699 0.1575 0.1509 0.1468 0.1456 0.1419 0.1402 0.1410 0.1405 0.1394 0.1402 0.1400 0.1402 

[TRAIN] Epoch[2](1431/1500); Loss: 0.131037; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2322 0.1890 0.1579 0.1360 0.1228 0.1193 0.1166 0.1142 0.1140 0.1137 0.1130 0.1133 0.1140 0.1132 0.1132 0.1141 

[TRAIN] Epoch[2](1432/1500); Loss: 0.128081; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2207 0.1724 0.1427 0.1250 0.1177 0.1177 0.1163 0.1150 0.1145 0.1147 0.1158 0.1151 0.1154 0.1150 0.1149 0.1164 

[TRAIN] Epoch[2](1433/1500); Loss: 0.103507; Backpropagation: 0.0940 sec; Batch: 0.4650 sec
0.3582 0.2706 0.1917 0.1240 0.0883 0.0535 0.0680 0.0538 0.0581 0.0525 0.0611 0.0538 0.0547 0.0533 0.0592 0.0553 

[TRAIN] Epoch[2](1434/1500); Loss: 0.151188; Backpropagation: 0.0940 sec; Batch: 0.4274 sec
0.2357 0.2115 0.1874 0.1727 0.1530 0.1477 0.1413 0.1386 0.1333 0.1305 0.1289 0.1282 0.1286 0.1275 0.1274 0.1265 

[TRAIN] Epoch[2](1435/1500); Loss: 0.118292; Backpropagation: 0.0970 sec; Batch: 0.4694 sec
0.1797 0.1497 0.1282 0.1213 0.1171 0.1103 0.1096 0.1114 0.1087 0.1076 0.1075 0.1089 0.1072 0.1081 0.1080 0.1093 

[TRAIN] Epoch[2](1436/1500); Loss: 0.134345; Backpropagation: 0.0938 sec; Batch: 0.4684 sec
0.2170 0.1734 0.1544 0.1457 0.1362 0.1297 0.1252 0.1236 0.1206 0.1182 0.1182 0.1174 0.1174 0.1176 0.1177 0.1171 

[TRAIN] Epoch[2](1437/1500); Loss: 0.072818; Backpropagation: 0.0934 sec; Batch: 0.4655 sec
0.2614 0.1842 0.1161 0.0568 0.0551 0.0426 0.0520 0.0426 0.0461 0.0414 0.0455 0.0430 0.0430 0.0443 0.0451 0.0459 

[TRAIN] Epoch[2](1438/1500); Loss: 0.144167; Backpropagation: 0.0937 sec; Batch: 0.4671 sec
0.1802 0.1493 0.1458 0.1483 0.1460 0.1394 0.1414 0.1417 0.1379 0.1393 0.1399 0.1387 0.1401 0.1401 0.1394 0.1391 

[TRAIN] Epoch[2](1439/1500); Loss: 0.041352; Backpropagation: 0.0940 sec; Batch: 0.4677 sec
0.0727 0.0588 0.0492 0.0427 0.0499 0.0406 0.0365 0.0353 0.0370 0.0335 0.0332 0.0356 0.0333 0.0339 0.0353 0.0342 

[TRAIN] Epoch[2](1440/1500); Loss: 0.087390; Backpropagation: 0.0938 sec; Batch: 0.4692 sec
0.1281 0.1071 0.0964 0.0950 0.0897 0.0865 0.0829 0.0829 0.0802 0.0795 0.0786 0.0794 0.0781 0.0772 0.0784 0.0784 

[TRAIN] Epoch[2](1441/1500); Loss: 0.120796; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.1824 0.1600 0.1495 0.1436 0.1266 0.1195 0.1105 0.1082 0.1066 0.1046 0.1037 0.1041 0.1036 0.1028 0.1031 0.1038 

[TRAIN] Epoch[2](1442/1500); Loss: 0.095841; Backpropagation: 0.0938 sec; Batch: 0.4664 sec
0.1420 0.1317 0.1237 0.1173 0.1090 0.1003 0.0890 0.0847 0.0826 0.0799 0.0792 0.0791 0.0791 0.0784 0.0784 0.0790 

[TRAIN] Epoch[2](1443/1500); Loss: 0.082233; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1271 0.1055 0.0965 0.0938 0.0872 0.0797 0.0767 0.0768 0.0753 0.0715 0.0729 0.0718 0.0715 0.0707 0.0702 0.0687 

[TRAIN] Epoch[2](1444/1500); Loss: 0.065807; Backpropagation: 0.0933 sec; Batch: 0.4323 sec
0.1677 0.1139 0.0813 0.0626 0.0580 0.0544 0.0547 0.0513 0.0513 0.0513 0.0515 0.0508 0.0510 0.0512 0.0506 0.0513 

[TRAIN] Epoch[2](1445/1500); Loss: 0.106140; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1831 0.1482 0.1281 0.1166 0.1015 0.0981 0.0951 0.0936 0.0916 0.0909 0.0918 0.0915 0.0915 0.0921 0.0921 0.0924 

[TRAIN] Epoch[2](1446/1500); Loss: 0.123856; Backpropagation: 0.0932 sec; Batch: 0.4697 sec
0.1766 0.1582 0.1461 0.1437 0.1281 0.1214 0.1174 0.1155 0.1118 0.1111 0.1096 0.1090 0.1087 0.1084 0.1082 0.1079 

[TRAIN] Epoch[2](1447/1500); Loss: 0.097987; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.3212 0.2373 0.1637 0.1096 0.0771 0.0619 0.0598 0.0617 0.0591 0.0586 0.0591 0.0593 0.0594 0.0596 0.0600 0.0605 

[TRAIN] Epoch[2](1448/1500); Loss: 0.121225; Backpropagation: 0.0931 sec; Batch: 0.4659 sec
0.1867 0.1650 0.1471 0.1393 0.1273 0.1164 0.1112 0.1103 0.1078 0.1065 0.1052 0.1036 0.1040 0.1034 0.1030 0.1028 

[TRAIN] Epoch[2](1449/1500); Loss: 0.146694; Backpropagation: 0.0939 sec; Batch: 0.4677 sec
0.2364 0.1896 0.1661 0.1593 0.1516 0.1442 0.1375 0.1349 0.1318 0.1297 0.1284 0.1274 0.1282 0.1266 0.1270 0.1283 

[TRAIN] Epoch[2](1450/1500); Loss: 0.126756; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.1931 0.1569 0.1348 0.1339 0.1294 0.1222 0.1186 0.1168 0.1166 0.1152 0.1157 0.1155 0.1153 0.1152 0.1145 0.1145 

[TRAIN] Epoch[2](1451/1500); Loss: 0.117348; Backpropagation: 0.0958 sec; Batch: 0.4671 sec
0.1831 0.1507 0.1334 0.1269 0.1196 0.1133 0.1092 0.1076 0.1056 0.1048 0.1042 0.1039 0.1038 0.1039 0.1038 0.1038 

[TRAIN] Epoch[2](1452/1500); Loss: 0.097887; Backpropagation: 0.0957 sec; Batch: 0.4668 sec
0.1655 0.1302 0.1131 0.1103 0.1003 0.0930 0.0904 0.0878 0.0860 0.0858 0.0851 0.0836 0.0849 0.0837 0.0833 0.0833 

[TRAIN] Epoch[2](1453/1500); Loss: 0.106966; Backpropagation: 0.0939 sec; Batch: 0.4689 sec
0.1633 0.1295 0.1130 0.1082 0.1051 0.1020 0.1005 0.1005 0.0993 0.0985 0.0986 0.0988 0.0983 0.0987 0.0988 0.0985 

[TRAIN] Epoch[2](1454/1500); Loss: 0.106773; Backpropagation: 0.0932 sec; Batch: 0.4706 sec
0.1477 0.1190 0.1088 0.1072 0.1090 0.1044 0.1003 0.1005 0.1006 0.1016 0.1012 0.1012 0.1012 0.1021 0.1017 0.1020 

[TRAIN] Epoch[2](1455/1500); Loss: 0.132334; Backpropagation: 0.0941 sec; Batch: 0.4715 sec
0.3033 0.2486 0.2026 0.1692 0.1306 0.1094 0.0933 0.0990 0.0946 0.0963 0.0948 0.0946 0.0947 0.0953 0.0951 0.0958 

[TRAIN] Epoch[2](1456/1500); Loss: 0.085445; Backpropagation: 0.0938 sec; Batch: 0.4622 sec
0.3459 0.2417 0.1421 0.0796 0.0547 0.0438 0.0427 0.0432 0.0447 0.0442 0.0435 0.0457 0.0473 0.0468 0.0481 0.0531 

[TRAIN] Epoch[2](1457/1500); Loss: 0.128604; Backpropagation: 0.0939 sec; Batch: 0.4701 sec
0.2912 0.2173 0.1559 0.1287 0.1198 0.1084 0.1049 0.1054 0.1043 0.1024 0.1031 0.1026 0.1030 0.1039 0.1031 0.1038 

[TRAIN] Epoch[2](1458/1500); Loss: 0.074131; Backpropagation: 0.0939 sec; Batch: 0.4709 sec
0.1724 0.1134 0.0790 0.0714 0.0722 0.0656 0.0617 0.0612 0.0605 0.0605 0.0604 0.0602 0.0613 0.0613 0.0620 0.0629 

[TRAIN] Epoch[2](1459/1500); Loss: 0.086784; Backpropagation: 0.0939 sec; Batch: 0.4658 sec
0.1112 0.0938 0.0882 0.0938 0.0906 0.0857 0.0851 0.0841 0.0828 0.0825 0.0816 0.0816 0.0817 0.0815 0.0821 0.0823 

[TRAIN] Epoch[2](1460/1500); Loss: 0.111692; Backpropagation: 0.0940 sec; Batch: 0.4306 sec
0.2489 0.1937 0.1506 0.1343 0.1164 0.1039 0.0924 0.0867 0.0839 0.0827 0.0821 0.0825 0.0817 0.0815 0.0829 0.0829 

[TRAIN] Epoch[2](1461/1500); Loss: 0.126529; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.2284 0.1797 0.1486 0.1409 0.1376 0.1286 0.1194 0.1121 0.1069 0.1036 0.1025 0.1024 0.1027 0.1031 0.1039 0.1041 

[TRAIN] Epoch[2](1462/1500); Loss: 0.084958; Backpropagation: 0.0938 sec; Batch: 0.4658 sec
0.1793 0.1471 0.1114 0.1043 0.0951 0.0858 0.0750 0.0695 0.0644 0.0620 0.0615 0.0612 0.0605 0.0611 0.0606 0.0603 

[TRAIN] Epoch[2](1463/1500); Loss: 0.056145; Backpropagation: 0.0939 sec; Batch: 0.4657 sec
0.1859 0.0948 0.0587 0.0550 0.0560 0.0435 0.0424 0.0405 0.0391 0.0399 0.0391 0.0386 0.0410 0.0407 0.0399 0.0433 

[TRAIN] Epoch[2](1464/1500); Loss: 0.119257; Backpropagation: 0.0938 sec; Batch: 0.4684 sec
0.2230 0.1845 0.1647 0.1558 0.1138 0.1006 0.0991 0.0991 0.0953 0.0951 0.0962 0.0960 0.0952 0.0957 0.0969 0.0970 

[TRAIN] Epoch[2](1465/1500); Loss: 0.085107; Backpropagation: 0.0939 sec; Batch: 0.4705 sec
0.1972 0.1309 0.0920 0.0806 0.0793 0.0689 0.0615 0.0586 0.0593 0.0619 0.0650 0.0699 0.0755 0.0806 0.0869 0.0933 

[TRAIN] Epoch[2](1466/1500); Loss: 0.071937; Backpropagation: 0.0937 sec; Batch: 0.4659 sec
0.1214 0.0918 0.0779 0.0719 0.0736 0.0715 0.0672 0.0653 0.0652 0.0640 0.0637 0.0640 0.0629 0.0632 0.0633 0.0640 

[TRAIN] Epoch[2](1467/1500); Loss: 0.067616; Backpropagation: 0.0939 sec; Batch: 0.4708 sec
0.2318 0.1427 0.0865 0.0695 0.0684 0.0571 0.0491 0.0443 0.0415 0.0408 0.0406 0.0406 0.0417 0.0419 0.0416 0.0439 

[TRAIN] Epoch[2](1468/1500); Loss: 0.106607; Backpropagation: 0.0939 sec; Batch: 0.4706 sec
0.1482 0.1315 0.1189 0.1170 0.1113 0.1077 0.1048 0.1025 0.1012 0.0991 0.0973 0.0961 0.0947 0.0931 0.0919 0.0906 

[TRAIN] Epoch[2](1469/1500); Loss: 0.100919; Backpropagation: 0.0939 sec; Batch: 0.4662 sec
0.1462 0.1241 0.1124 0.1086 0.1060 0.1008 0.0962 0.0942 0.0927 0.0914 0.0910 0.0906 0.0902 0.0903 0.0902 0.0898 

[TRAIN] Epoch[2](1470/1500); Loss: 0.122409; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.3636 0.2780 0.1927 0.1524 0.1408 0.1218 0.0951 0.0764 0.0685 0.0666 0.0672 0.0666 0.0663 0.0668 0.0677 0.0682 

[TRAIN] Epoch[2](1471/1500); Loss: 0.114253; Backpropagation: 0.0948 sec; Batch: 0.4710 sec
0.1751 0.1480 0.1338 0.1257 0.1256 0.1201 0.1089 0.1039 0.1018 0.0996 0.0986 0.0979 0.0974 0.0972 0.0973 0.0972 

[TRAIN] Epoch[2](1472/1500); Loss: 0.065432; Backpropagation: 0.0949 sec; Batch: 0.4290 sec
0.1879 0.1198 0.0757 0.0646 0.0609 0.0555 0.0516 0.0494 0.0485 0.0475 0.0475 0.0481 0.0475 0.0474 0.0475 0.0474 

[TRAIN] Epoch[2](1473/1500); Loss: 0.130012; Backpropagation: 0.0936 sec; Batch: 0.4296 sec
0.2340 0.1911 0.1651 0.1524 0.1338 0.1224 0.1154 0.1141 0.1106 0.1085 0.1072 0.1059 0.1051 0.1054 0.1045 0.1047 

[TRAIN] Epoch[2](1474/1500); Loss: 0.083520; Backpropagation: 0.0932 sec; Batch: 0.4299 sec
0.1295 0.1030 0.0900 0.0897 0.0865 0.0817 0.0790 0.0772 0.0764 0.0754 0.0748 0.0747 0.0746 0.0746 0.0746 0.0747 

[TRAIN] Epoch[2](1475/1500); Loss: 0.069558; Backpropagation: 0.0939 sec; Batch: 0.4441 sec
0.1671 0.1180 0.0803 0.0705 0.0671 0.0612 0.0577 0.0562 0.0546 0.0546 0.0541 0.0542 0.0546 0.0541 0.0537 0.0550 

[TRAIN] Epoch[2](1476/1500); Loss: 0.063122; Backpropagation: 0.0937 sec; Batch: 0.4595 sec
0.0908 0.0797 0.0677 0.0700 0.0684 0.0618 0.0599 0.0593 0.0576 0.0570 0.0564 0.0565 0.0563 0.0562 0.0562 0.0562 

[TRAIN] Epoch[2](1477/1500); Loss: 0.115285; Backpropagation: 0.0940 sec; Batch: 0.5270 sec
0.1797 0.1466 0.1295 0.1263 0.1219 0.1138 0.1089 0.1066 0.1040 0.1019 0.1013 0.1007 0.1006 0.1005 0.1008 0.1015 

[TRAIN] Epoch[2](1478/1500); Loss: 0.121847; Backpropagation: 0.0938 sec; Batch: 0.4694 sec
0.1720 0.1462 0.1340 0.1330 0.1209 0.1174 0.1164 0.1143 0.1125 0.1125 0.1126 0.1118 0.1113 0.1112 0.1115 0.1118 

[TRAIN] Epoch[2](1479/1500); Loss: 0.128084; Backpropagation: 0.0939 sec; Batch: 0.4504 sec
0.2440 0.1914 0.1474 0.1385 0.1320 0.1268 0.1174 0.1126 0.1094 0.1065 0.1050 0.1047 0.1038 0.1038 0.1031 0.1029 

[TRAIN] Epoch[2](1480/1500); Loss: 0.150244; Backpropagation: 0.0932 sec; Batch: 0.4376 sec
0.2280 0.1996 0.1830 0.1757 0.1551 0.1489 0.1391 0.1347 0.1328 0.1311 0.1303 0.1300 0.1293 0.1294 0.1288 0.1283 

[TRAIN] Epoch[2](1481/1500); Loss: 0.113555; Backpropagation: 0.0940 sec; Batch: 0.4487 sec
0.2256 0.1735 0.1319 0.1167 0.1132 0.1052 0.0996 0.0985 0.0960 0.0947 0.0949 0.0941 0.0932 0.0932 0.0932 0.0933 

[TRAIN] Epoch[2](1482/1500); Loss: 0.107406; Backpropagation: 0.0932 sec; Batch: 0.4610 sec
0.1569 0.1278 0.1153 0.1145 0.1118 0.1049 0.1015 0.1006 0.0996 0.0984 0.0983 0.0981 0.0979 0.0974 0.0974 0.0980 

[TRAIN] Epoch[2](1483/1500); Loss: 0.118050; Backpropagation: 0.0940 sec; Batch: 0.4718 sec
0.1875 0.1448 0.1232 0.1154 0.1164 0.1117 0.1093 0.1088 0.1088 0.1083 0.1082 0.1087 0.1086 0.1090 0.1096 0.1104 

[TRAIN] Epoch[2](1484/1500); Loss: 0.099760; Backpropagation: 0.0965 sec; Batch: 0.4301 sec
0.1479 0.1227 0.1122 0.1066 0.1014 0.1005 0.0933 0.0911 0.0907 0.0907 0.0893 0.0891 0.0898 0.0900 0.0902 0.0908 

[TRAIN] Epoch[2](1485/1500); Loss: 0.114701; Backpropagation: 0.0937 sec; Batch: 0.4709 sec
0.1791 0.1487 0.1226 0.1129 0.1099 0.1068 0.1061 0.1053 0.1045 0.1047 0.1047 0.1051 0.1057 0.1059 0.1063 0.1068 

[TRAIN] Epoch[2](1486/1500); Loss: 0.090725; Backpropagation: 0.0937 sec; Batch: 0.4676 sec
0.1304 0.0958 0.0871 0.0926 0.0912 0.0850 0.0857 0.0859 0.0860 0.0860 0.0866 0.0867 0.0876 0.0882 0.0886 0.0883 

[TRAIN] Epoch[2](1487/1500); Loss: 0.082304; Backpropagation: 0.0934 sec; Batch: 0.4383 sec
0.1149 0.0988 0.0842 0.0847 0.0863 0.0796 0.0775 0.0777 0.0772 0.0764 0.0759 0.0763 0.0763 0.0763 0.0765 0.0782 

[TRAIN] Epoch[2](1488/1500); Loss: 0.087025; Backpropagation: 0.0933 sec; Batch: 0.4663 sec
0.2870 0.1946 0.1256 0.0843 0.0703 0.0593 0.0578 0.0580 0.0568 0.0563 0.0564 0.0566 0.0571 0.0572 0.0574 0.0577 

[TRAIN] Epoch[2](1489/1500); Loss: 0.088850; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.2737 0.1698 0.0915 0.0714 0.0744 0.0711 0.0671 0.0671 0.0670 0.0658 0.0662 0.0669 0.0663 0.0667 0.0687 0.0679 

[TRAIN] Epoch[2](1490/1500); Loss: 0.099237; Backpropagation: 0.0940 sec; Batch: 0.4302 sec
0.1860 0.1445 0.1199 0.1044 0.0890 0.0880 0.0863 0.0854 0.0845 0.0857 0.0851 0.0853 0.0857 0.0852 0.0859 0.0870 

[TRAIN] Epoch[2](1491/1500); Loss: 0.096070; Backpropagation: 0.0939 sec; Batch: 0.4713 sec
0.1160 0.1051 0.0988 0.0981 0.0967 0.0938 0.0928 0.0930 0.0921 0.0923 0.0921 0.0926 0.0928 0.0936 0.0933 0.0939 

[TRAIN] Epoch[2](1492/1500); Loss: 0.161566; Backpropagation: 0.0938 sec; Batch: 0.4657 sec
0.2607 0.2142 0.1919 0.1822 0.1628 0.1533 0.1462 0.1442 0.1427 0.1422 0.1409 0.1412 0.1407 0.1406 0.1403 0.1410 

[TRAIN] Epoch[2](1493/1500); Loss: 0.066811; Backpropagation: 0.0938 sec; Batch: 0.4662 sec
0.2944 0.1865 0.0605 0.0468 0.0534 0.0507 0.0352 0.0330 0.0357 0.0356 0.0331 0.0380 0.0392 0.0384 0.0434 0.0452 

[TRAIN] Epoch[2](1494/1500); Loss: 0.112074; Backpropagation: 0.0939 sec; Batch: 0.4707 sec
0.1529 0.1208 0.1113 0.1120 0.1082 0.1040 0.1037 0.1035 0.1040 0.1049 0.1061 0.1079 0.1100 0.1123 0.1145 0.1170 

[TRAIN] Epoch[2](1495/1500); Loss: 0.111762; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.1785 0.1423 0.1188 0.1192 0.1171 0.1084 0.1067 0.1027 0.1008 0.0994 0.0989 0.0976 0.0987 0.0984 0.0999 0.1007 

[TRAIN] Epoch[2](1496/1500); Loss: 0.054396; Backpropagation: 0.0981 sec; Batch: 0.4709 sec
0.0746 0.0682 0.0532 0.0551 0.0482 0.0455 0.0480 0.0478 0.0467 0.0503 0.0501 0.0520 0.0548 0.0562 0.0591 0.0607 

[TRAIN] Epoch[2](1497/1500); Loss: 0.087552; Backpropagation: 0.0956 sec; Batch: 0.4725 sec
0.2649 0.2057 0.0883 0.0609 0.0684 0.0706 0.0546 0.0581 0.0631 0.0631 0.0614 0.0641 0.0650 0.0690 0.0708 0.0729 

[TRAIN] Epoch[2](1498/1500); Loss: 0.109934; Backpropagation: 0.0938 sec; Batch: 0.4648 sec
0.2979 0.2282 0.2060 0.1798 0.0881 0.0712 0.0630 0.0658 0.0645 0.0705 0.0713 0.0661 0.0706 0.0697 0.0734 0.0728 

[TRAIN] Epoch[2](1499/1500); Loss: 0.100255; Backpropagation: 0.0937 sec; Batch: 0.4271 sec
0.1136 0.0910 0.0799 0.0923 0.0990 0.0992 0.0956 0.0995 0.0991 0.1014 0.1011 0.1044 0.1042 0.1063 0.1076 0.1099 

[TRAIN] Epoch[2](1500/1500); Loss: 0.127327; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1674 0.1360 0.1154 0.1292 0.1363 0.1285 0.1228 0.1222 0.1199 0.1203 0.1223 0.1190 0.1256 0.1219 0.1259 0.1247 

[TRAIN] Epoch[3](1/1500); Loss: 0.196509; Backpropagation: 0.0986 sec; Batch: 0.5025 sec
0.3298 0.2830 0.2499 0.2334 0.2048 0.1894 0.1760 0.1679 0.1655 0.1655 0.1635 0.1639 0.1620 0.1623 0.1647 0.1627 

[TRAIN] Epoch[3](2/1500); Loss: 0.122695; Backpropagation: 0.0937 sec; Batch: 0.4360 sec
0.1517 0.1186 0.1060 0.1185 0.1238 0.1180 0.1159 0.1146 0.1186 0.1190 0.1213 0.1235 0.1249 0.1269 0.1296 0.1324 

[TRAIN] Epoch[3](3/1500); Loss: 0.146363; Backpropagation: 0.0937 sec; Batch: 0.4289 sec
0.2578 0.1981 0.1343 0.1435 0.1573 0.1454 0.1260 0.1364 0.1318 0.1279 0.1272 0.1269 0.1311 0.1290 0.1349 0.1339 

[TRAIN] Epoch[3](4/1500); Loss: 0.147733; Backpropagation: 0.0936 sec; Batch: 0.4686 sec
0.1544 0.1417 0.1223 0.1356 0.1452 0.1479 0.1500 0.1506 0.1532 0.1504 0.1527 0.1511 0.1510 0.1498 0.1547 0.1530 

[TRAIN] Epoch[3](5/1500); Loss: 0.168077; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2586 0.2104 0.1803 0.1686 0.1434 0.1522 0.1456 0.1588 0.1598 0.1656 0.1621 0.1600 0.1542 0.1565 0.1571 0.1561 

[TRAIN] Epoch[3](6/1500); Loss: 0.137245; Backpropagation: 0.0933 sec; Batch: 0.4304 sec
0.2918 0.2252 0.1301 0.1223 0.1362 0.1265 0.1099 0.1198 0.1166 0.1123 0.1128 0.1128 0.1157 0.1193 0.1214 0.1234 

[TRAIN] Epoch[3](7/1500); Loss: 0.150264; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.2034 0.1563 0.1320 0.1451 0.1511 0.1505 0.1438 0.1497 0.1485 0.1459 0.1449 0.1457 0.1456 0.1458 0.1472 0.1486 

[TRAIN] Epoch[3](8/1500); Loss: 0.130335; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1528 0.1353 0.1202 0.1252 0.1367 0.1326 0.1316 0.1286 0.1286 0.1258 0.1267 0.1253 0.1269 0.1274 0.1303 0.1312 

[TRAIN] Epoch[3](9/1500); Loss: 0.172957; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.2310 0.1942 0.1695 0.1662 0.1961 0.1846 0.1691 0.1714 0.1638 0.1624 0.1611 0.1591 0.1594 0.1592 0.1611 0.1591 

[TRAIN] Epoch[3](10/1500); Loss: 0.111561; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.1215 0.1410 0.1050 0.1134 0.1179 0.1078 0.1078 0.1020 0.1063 0.1038 0.1069 0.1024 0.1130 0.1116 0.1132 0.1115 

[TRAIN] Epoch[3](11/1500); Loss: 0.155894; Backpropagation: 0.0940 sec; Batch: 0.4442 sec
0.1938 0.1659 0.1477 0.1678 0.1668 0.1626 0.1563 0.1539 0.1496 0.1494 0.1449 0.1478 0.1453 0.1474 0.1457 0.1494 

[TRAIN] Epoch[3](12/1500); Loss: 0.132233; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1892 0.1633 0.1449 0.1349 0.1433 0.1320 0.1191 0.1251 0.1215 0.1201 0.1158 0.1202 0.1199 0.1208 0.1202 0.1254 

[TRAIN] Epoch[3](13/1500); Loss: 0.187946; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.2324 0.2191 0.1957 0.1992 0.2000 0.1935 0.1866 0.1828 0.1788 0.1761 0.1747 0.1741 0.1733 0.1742 0.1730 0.1736 

[TRAIN] Epoch[3](14/1500); Loss: 0.149248; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2191 0.1943 0.1564 0.1445 0.1527 0.1473 0.1401 0.1363 0.1367 0.1365 0.1352 0.1368 0.1375 0.1381 0.1381 0.1384 

[TRAIN] Epoch[3](15/1500); Loss: 0.075880; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.0769 0.1164 0.0766 0.0886 0.0754 0.0771 0.0688 0.0705 0.0656 0.0689 0.0665 0.0695 0.0698 0.0725 0.0741 0.0768 

[TRAIN] Epoch[3](16/1500); Loss: 0.158257; Backpropagation: 0.0982 sec; Batch: 0.4355 sec
0.1823 0.1975 0.1632 0.1701 0.1708 0.1638 0.1582 0.1541 0.1506 0.1472 0.1463 0.1444 0.1468 0.1451 0.1464 0.1453 

[TRAIN] Epoch[3](17/1500); Loss: 0.136732; Backpropagation: 0.0959 sec; Batch: 0.4311 sec
0.2045 0.2212 0.1554 0.1308 0.1464 0.1341 0.1251 0.1209 0.1199 0.1173 0.1178 0.1171 0.1177 0.1188 0.1200 0.1207 

[TRAIN] Epoch[3](18/1500); Loss: 0.086779; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.0668 0.1498 0.1042 0.0655 0.0934 0.0925 0.0776 0.0746 0.0792 0.0786 0.0807 0.0809 0.0838 0.0848 0.0872 0.0889 

[TRAIN] Epoch[3](19/1500); Loss: 0.108785; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1850 0.1585 0.1315 0.1290 0.1143 0.1027 0.0949 0.0911 0.0911 0.0900 0.0905 0.0902 0.0915 0.0920 0.0933 0.0948 

[TRAIN] Epoch[3](20/1500); Loss: 0.125813; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1640 0.1693 0.1451 0.1292 0.1300 0.1229 0.1153 0.1158 0.1132 0.1144 0.1126 0.1153 0.1137 0.1168 0.1160 0.1196 

[TRAIN] Epoch[3](21/1500); Loss: 0.107113; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1724 0.2005 0.1153 0.0907 0.1123 0.0979 0.0905 0.0882 0.0919 0.0905 0.0907 0.0911 0.0938 0.0941 0.0966 0.0972 

[TRAIN] Epoch[3](22/1500); Loss: 0.138448; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1913 0.1717 0.1470 0.1443 0.1412 0.1360 0.1307 0.1282 0.1263 0.1265 0.1260 0.1271 0.1275 0.1292 0.1303 0.1318 

[TRAIN] Epoch[3](23/1500); Loss: 0.118458; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1564 0.1469 0.1239 0.1202 0.1182 0.1145 0.1100 0.1098 0.1089 0.1098 0.1100 0.1113 0.1120 0.1133 0.1143 0.1158 

[TRAIN] Epoch[3](24/1500); Loss: 0.084361; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.0791 0.1485 0.1031 0.0750 0.0875 0.0848 0.0731 0.0766 0.0744 0.0756 0.0755 0.0765 0.0786 0.0783 0.0823 0.0809 

[TRAIN] Epoch[3](25/1500); Loss: 0.101209; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1658 0.1410 0.1185 0.1090 0.1043 0.0970 0.0904 0.0883 0.0870 0.0872 0.0867 0.0875 0.0876 0.0889 0.0891 0.0911 

[TRAIN] Epoch[3](26/1500); Loss: 0.163380; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1793 0.1825 0.1619 0.1690 0.1612 0.1645 0.1584 0.1612 0.1574 0.1601 0.1578 0.1598 0.1588 0.1604 0.1602 0.1614 

[TRAIN] Epoch[3](27/1500); Loss: 0.101632; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1313 0.1730 0.1135 0.1040 0.1014 0.0957 0.0893 0.0898 0.0872 0.0895 0.0881 0.0907 0.0900 0.0931 0.0932 0.0962 

[TRAIN] Epoch[3](28/1500); Loss: 0.109719; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1325 0.1781 0.1162 0.1214 0.1033 0.1123 0.1003 0.1033 0.0953 0.0995 0.0958 0.0987 0.0968 0.0995 0.0998 0.1025 

[TRAIN] Epoch[3](29/1500); Loss: 0.214499; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2802 0.2559 0.2423 0.2409 0.2205 0.2165 0.2053 0.2031 0.1976 0.1985 0.1955 0.1958 0.1942 0.1956 0.1944 0.1956 

[TRAIN] Epoch[3](30/1500); Loss: 0.101843; Backpropagation: 0.0942 sec; Batch: 0.4280 sec
0.1918 0.2338 0.1422 0.0919 0.0973 0.0831 0.0834 0.0748 0.0787 0.0738 0.0780 0.0757 0.0793 0.0792 0.0822 0.0844 

[TRAIN] Epoch[3](31/1500); Loss: 0.093027; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.0956 0.1006 0.0867 0.0927 0.0875 0.0920 0.0886 0.0906 0.0895 0.0913 0.0919 0.0932 0.0946 0.0960 0.0982 0.0994 

[TRAIN] Epoch[3](32/1500); Loss: 0.101441; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1342 0.1274 0.1089 0.1123 0.1015 0.1020 0.0949 0.0953 0.0913 0.0929 0.0915 0.0930 0.0925 0.0943 0.0947 0.0962 

[TRAIN] Epoch[3](33/1500); Loss: 0.161017; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2236 0.2015 0.1867 0.1805 0.1649 0.1600 0.1522 0.1486 0.1462 0.1456 0.1443 0.1444 0.1441 0.1443 0.1447 0.1448 

[TRAIN] Epoch[3](34/1500); Loss: 0.116359; Backpropagation: 0.0962 sec; Batch: 0.4302 sec
0.1611 0.2008 0.1377 0.1290 0.1211 0.1128 0.1023 0.1005 0.0984 0.0980 0.0978 0.0976 0.0991 0.0997 0.1027 0.1032 

[TRAIN] Epoch[3](35/1500); Loss: 0.118579; Backpropagation: 0.0958 sec; Batch: 0.4298 sec
0.1302 0.1769 0.1353 0.1346 0.1190 0.1197 0.1095 0.1119 0.1059 0.1087 0.1056 0.1076 0.1067 0.1083 0.1079 0.1094 

[TRAIN] Epoch[3](36/1500); Loss: 0.146050; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1933 0.1973 0.1567 0.1623 0.1469 0.1449 0.1344 0.1380 0.1313 0.1344 0.1306 0.1327 0.1309 0.1339 0.1335 0.1357 

[TRAIN] Epoch[3](37/1500); Loss: 0.116240; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2097 0.1918 0.1629 0.1444 0.1204 0.1074 0.1005 0.0928 0.0923 0.0895 0.0908 0.0899 0.0908 0.0912 0.0920 0.0936 

[TRAIN] Epoch[3](38/1500); Loss: 0.061192; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1444 0.0762 0.0828 0.0472 0.0472 0.0431 0.0448 0.0464 0.0461 0.0519 0.0497 0.0560 0.0542 0.0622 0.0600 0.0669 

[TRAIN] Epoch[3](39/1500); Loss: 0.133435; Backpropagation: 0.0950 sec; Batch: 0.4302 sec
0.2119 0.2345 0.1752 0.1415 0.1341 0.1248 0.1173 0.1141 0.1096 0.1103 0.1089 0.1095 0.1099 0.1104 0.1113 0.1118 

[TRAIN] Epoch[3](40/1500); Loss: 0.068212; Backpropagation: 0.0957 sec; Batch: 0.4305 sec
0.0592 0.1447 0.0786 0.0756 0.0634 0.0682 0.0573 0.0618 0.0562 0.0596 0.0572 0.0597 0.0601 0.0614 0.0638 0.0645 

[TRAIN] Epoch[3](41/1500); Loss: 0.112250; Backpropagation: 0.0960 sec; Batch: 0.4314 sec
0.2226 0.2576 0.1789 0.1287 0.1224 0.1027 0.0885 0.0803 0.0759 0.0751 0.0740 0.0757 0.0758 0.0783 0.0789 0.0805 

[TRAIN] Epoch[3](42/1500); Loss: 0.098678; Backpropagation: 0.0941 sec; Batch: 0.4335 sec
0.2431 0.2260 0.1320 0.0815 0.0989 0.0762 0.0748 0.0647 0.0706 0.0663 0.0703 0.0699 0.0721 0.0756 0.0760 0.0811 

[TRAIN] Epoch[3](43/1500); Loss: 0.164775; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.2311 0.2242 0.1933 0.1846 0.1629 0.1592 0.1506 0.1503 0.1466 0.1473 0.1462 0.1468 0.1470 0.1480 0.1488 0.1496 

[TRAIN] Epoch[3](44/1500); Loss: 0.146840; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1897 0.1638 0.1603 0.1540 0.1445 0.1413 0.1400 0.1381 0.1388 0.1380 0.1391 0.1386 0.1400 0.1399 0.1413 0.1418 

[TRAIN] Epoch[3](45/1500); Loss: 0.125159; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1608 0.1718 0.1379 0.1381 0.1261 0.1234 0.1162 0.1167 0.1131 0.1137 0.1126 0.1131 0.1137 0.1142 0.1152 0.1159 

[TRAIN] Epoch[3](46/1500); Loss: 0.099327; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1353 0.1236 0.1025 0.1030 0.0962 0.0954 0.0919 0.0917 0.0913 0.0909 0.0924 0.0922 0.0943 0.0945 0.0966 0.0974 

[TRAIN] Epoch[3](47/1500); Loss: 0.132575; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2056 0.1971 0.1559 0.1371 0.1295 0.1248 0.1191 0.1164 0.1153 0.1155 0.1159 0.1163 0.1171 0.1176 0.1186 0.1195 

[TRAIN] Epoch[3](48/1500); Loss: 0.125497; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2395 0.2011 0.1546 0.1462 0.1238 0.1169 0.1054 0.1031 0.1005 0.1005 0.1011 0.1012 0.1028 0.1024 0.1045 0.1043 

[TRAIN] Epoch[3](49/1500); Loss: 0.113859; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1566 0.1490 0.1231 0.1234 0.1148 0.1130 0.1071 0.1066 0.1029 0.1029 0.1020 0.1026 0.1033 0.1038 0.1049 0.1055 

[TRAIN] Epoch[3](50/1500); Loss: 0.112010; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1676 0.1795 0.1209 0.1208 0.1088 0.1065 0.0987 0.0997 0.0967 0.0976 0.0971 0.0978 0.0987 0.0996 0.1005 0.1017 

[TRAIN] Epoch[3](51/1500); Loss: 0.112144; Backpropagation: 0.0942 sec; Batch: 0.4289 sec
0.1418 0.1541 0.1259 0.1207 0.1097 0.1073 0.1027 0.1015 0.1018 0.1010 0.1031 0.1024 0.1046 0.1044 0.1066 0.1065 

[TRAIN] Epoch[3](52/1500); Loss: 0.111274; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1507 0.1239 0.1288 0.1145 0.1083 0.1076 0.1042 0.1038 0.1024 0.1029 0.1026 0.1042 0.1045 0.1062 0.1070 0.1087 

[TRAIN] Epoch[3](53/1500); Loss: 0.137506; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1840 0.1795 0.1456 0.1449 0.1354 0.1324 0.1289 0.1285 0.1274 0.1271 0.1269 0.1275 0.1274 0.1277 0.1282 0.1289 

[TRAIN] Epoch[3](54/1500); Loss: 0.122295; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2060 0.1716 0.1198 0.1284 0.1164 0.1137 0.1076 0.1074 0.1066 0.1073 0.1092 0.1097 0.1118 0.1118 0.1146 0.1150 

[TRAIN] Epoch[3](55/1500); Loss: 0.142107; Backpropagation: 0.0936 sec; Batch: 0.4273 sec
0.2366 0.1982 0.1675 0.1485 0.1423 0.1321 0.1274 0.1239 0.1234 0.1227 0.1232 0.1235 0.1247 0.1257 0.1265 0.1273 

[TRAIN] Epoch[3](56/1500); Loss: 0.075667; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.0988 0.1288 0.0818 0.0780 0.0646 0.0650 0.0641 0.0627 0.0673 0.0653 0.0709 0.0689 0.0734 0.0719 0.0752 0.0739 

[TRAIN] Epoch[3](57/1500); Loss: 0.166712; Backpropagation: 0.0959 sec; Batch: 0.4303 sec
0.2045 0.1868 0.1712 0.1706 0.1651 0.1639 0.1614 0.1607 0.1595 0.1600 0.1596 0.1602 0.1601 0.1607 0.1611 0.1619 

[TRAIN] Epoch[3](58/1500); Loss: 0.096303; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1650 0.1337 0.1072 0.0998 0.0909 0.0883 0.0844 0.0842 0.0837 0.0835 0.0848 0.0844 0.0865 0.0864 0.0889 0.0891 

[TRAIN] Epoch[3](59/1500); Loss: 0.139860; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2403 0.1849 0.1519 0.1441 0.1354 0.1316 0.1263 0.1256 0.1236 0.1231 0.1241 0.1239 0.1250 0.1251 0.1261 0.1266 

[TRAIN] Epoch[3](60/1500); Loss: 0.128313; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1692 0.1665 0.1324 0.1328 0.1223 0.1231 0.1203 0.1196 0.1200 0.1190 0.1210 0.1198 0.1215 0.1207 0.1225 0.1224 

[TRAIN] Epoch[3](61/1500); Loss: 0.111615; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1725 0.1421 0.1322 0.1165 0.1132 0.1089 0.1051 0.1024 0.1005 0.0994 0.0979 0.0985 0.0972 0.0994 0.0987 0.1015 

[TRAIN] Epoch[3](62/1500); Loss: 0.100761; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.1315 0.1153 0.1111 0.1019 0.0961 0.0948 0.0934 0.0931 0.0930 0.0938 0.0942 0.0958 0.0971 0.0987 0.1001 0.1021 

[TRAIN] Epoch[3](63/1500); Loss: 0.105229; Backpropagation: 0.0951 sec; Batch: 0.4290 sec
0.1731 0.1439 0.1118 0.1114 0.1033 0.0992 0.0944 0.0917 0.0923 0.0907 0.0937 0.0925 0.0958 0.0950 0.0978 0.0971 

[TRAIN] Epoch[3](64/1500); Loss: 0.107083; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1853 0.1577 0.1256 0.1115 0.1044 0.0997 0.0968 0.0943 0.0936 0.0927 0.0918 0.0916 0.0914 0.0920 0.0920 0.0928 

[TRAIN] Epoch[3](65/1500); Loss: 0.092766; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1647 0.1542 0.1078 0.0913 0.0829 0.0779 0.0760 0.0760 0.0767 0.0781 0.0807 0.0806 0.0836 0.0830 0.0855 0.0852 

[TRAIN] Epoch[3](66/1500); Loss: 0.154258; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2653 0.2248 0.2246 0.2087 0.1755 0.1639 0.1484 0.1361 0.1250 0.1163 0.1127 0.1121 0.1123 0.1136 0.1138 0.1150 

[TRAIN] Epoch[3](67/1500); Loss: 0.089151; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1357 0.1145 0.0926 0.0902 0.0825 0.0809 0.0803 0.0806 0.0815 0.0826 0.0828 0.0834 0.0833 0.0845 0.0845 0.0865 

[TRAIN] Epoch[3](68/1500); Loss: 0.094283; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2077 0.1409 0.0918 0.0990 0.0856 0.0846 0.0782 0.0788 0.0784 0.0778 0.0807 0.0791 0.0812 0.0802 0.0824 0.0821 

[TRAIN] Epoch[3](69/1500); Loss: 0.121111; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.2099 0.1728 0.1553 0.1380 0.1285 0.1204 0.1127 0.1067 0.1012 0.0995 0.0987 0.0984 0.0982 0.0985 0.0991 0.1001 

[TRAIN] Epoch[3](70/1500); Loss: 0.155818; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.2547 0.2082 0.1953 0.1785 0.1583 0.1519 0.1444 0.1390 0.1349 0.1340 0.1330 0.1325 0.1319 0.1320 0.1321 0.1324 

[TRAIN] Epoch[3](71/1500); Loss: 0.081254; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1284 0.1168 0.0891 0.0848 0.0766 0.0750 0.0726 0.0724 0.0717 0.0720 0.0721 0.0725 0.0731 0.0735 0.0746 0.0750 

[TRAIN] Epoch[3](72/1500); Loss: 0.107894; Backpropagation: 0.0938 sec; Batch: 0.4334 sec
0.1701 0.1394 0.1211 0.1134 0.1047 0.1018 0.0982 0.0975 0.0972 0.0967 0.0972 0.0970 0.0973 0.0976 0.0983 0.0988 

[TRAIN] Epoch[3](73/1500); Loss: 0.087335; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1612 0.1197 0.1037 0.0959 0.0827 0.0781 0.0756 0.0755 0.0732 0.0757 0.0733 0.0756 0.0746 0.0773 0.0770 0.0782 

[TRAIN] Epoch[3](74/1500); Loss: 0.105206; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.1806 0.1367 0.1196 0.1096 0.0961 0.0968 0.0937 0.0943 0.0939 0.0942 0.0941 0.0946 0.0940 0.0945 0.0951 0.0956 

[TRAIN] Epoch[3](75/1500); Loss: 0.089055; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1509 0.1180 0.0954 0.1031 0.0864 0.0877 0.0794 0.0793 0.0777 0.0774 0.0773 0.0774 0.0777 0.0783 0.0791 0.0800 

[TRAIN] Epoch[3](76/1500); Loss: 0.112794; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1576 0.1312 0.1196 0.1125 0.1085 0.1073 0.1061 0.1059 0.1057 0.1061 0.1064 0.1066 0.1072 0.1074 0.1079 0.1086 

[TRAIN] Epoch[3](77/1500); Loss: 0.105515; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1316 0.1232 0.1127 0.1152 0.1023 0.1032 0.0998 0.1008 0.0991 0.0998 0.0987 0.1000 0.0994 0.1005 0.1003 0.1016 

[TRAIN] Epoch[3](78/1500); Loss: 0.105540; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1585 0.1217 0.1182 0.1100 0.1045 0.1023 0.0999 0.0987 0.0972 0.0967 0.0965 0.0963 0.0966 0.0968 0.0972 0.0975 

[TRAIN] Epoch[3](79/1500); Loss: 0.164038; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2525 0.2153 0.1929 0.1758 0.1644 0.1590 0.1521 0.1488 0.1463 0.1452 0.1448 0.1450 0.1449 0.1455 0.1456 0.1467 

[TRAIN] Epoch[3](80/1500); Loss: 0.104476; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1520 0.1176 0.1223 0.1057 0.0999 0.0984 0.0965 0.0956 0.0958 0.0965 0.0963 0.0972 0.0977 0.0992 0.0998 0.1010 

[TRAIN] Epoch[3](81/1500); Loss: 0.096415; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2190 0.1625 0.1371 0.1161 0.0763 0.0741 0.0720 0.0729 0.0732 0.0737 0.0750 0.0755 0.0766 0.0777 0.0797 0.0811 

[TRAIN] Epoch[3](82/1500); Loss: 0.188521; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2824 0.2406 0.2152 0.1968 0.1898 0.1836 0.1780 0.1750 0.1719 0.1699 0.1694 0.1685 0.1692 0.1684 0.1689 0.1687 

[TRAIN] Epoch[3](83/1500); Loss: 0.137269; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2830 0.2149 0.1502 0.1195 0.1328 0.1176 0.1170 0.1152 0.1147 0.1182 0.1174 0.1179 0.1174 0.1197 0.1194 0.1213 

[TRAIN] Epoch[3](84/1500); Loss: 0.101627; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1422 0.1262 0.1170 0.0972 0.0966 0.0946 0.0946 0.0933 0.0940 0.0935 0.0950 0.0947 0.0962 0.0962 0.0970 0.0978 

[TRAIN] Epoch[3](85/1500); Loss: 0.159335; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2154 0.1772 0.1682 0.1576 0.1548 0.1535 0.1527 0.1519 0.1518 0.1516 0.1514 0.1516 0.1522 0.1525 0.1533 0.1538 

[TRAIN] Epoch[3](86/1500); Loss: 0.145305; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2448 0.2027 0.1932 0.1786 0.1485 0.1377 0.1286 0.1218 0.1209 0.1211 0.1207 0.1206 0.1208 0.1210 0.1217 0.1221 

[TRAIN] Epoch[3](87/1500); Loss: 0.123726; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2771 0.2221 0.1768 0.1476 0.1183 0.1058 0.0981 0.0944 0.0931 0.0922 0.0925 0.0918 0.0927 0.0921 0.0925 0.0925 

[TRAIN] Epoch[3](88/1500); Loss: 0.110748; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1643 0.1294 0.1205 0.1082 0.1046 0.1023 0.1012 0.1005 0.1012 0.1014 0.1026 0.1034 0.1049 0.1063 0.1093 0.1116 

[TRAIN] Epoch[3](89/1500); Loss: 0.099362; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2014 0.1536 0.1124 0.1020 0.0927 0.0875 0.0835 0.0823 0.0823 0.0828 0.0838 0.0839 0.0849 0.0845 0.0865 0.0856 

[TRAIN] Epoch[3](90/1500); Loss: 0.118851; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2216 0.1852 0.1479 0.1302 0.1164 0.1095 0.1046 0.1008 0.1000 0.0983 0.0977 0.0975 0.0980 0.0978 0.0982 0.0979 

[TRAIN] Epoch[3](91/1500); Loss: 0.067229; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.0673 0.1131 0.0716 0.0774 0.0602 0.0601 0.0564 0.0553 0.0610 0.0583 0.0664 0.0629 0.0683 0.0643 0.0684 0.0648 

[TRAIN] Epoch[3](92/1500); Loss: 0.116512; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.1398 0.1358 0.1243 0.1162 0.1146 0.1137 0.1141 0.1129 0.1129 0.1112 0.1118 0.1109 0.1115 0.1111 0.1118 0.1116 

[TRAIN] Epoch[3](93/1500); Loss: 0.070306; Backpropagation: 0.0942 sec; Batch: 0.4289 sec
0.1198 0.0804 0.0819 0.0677 0.0647 0.0627 0.0640 0.0615 0.0636 0.0620 0.0655 0.0636 0.0674 0.0653 0.0682 0.0667 

[TRAIN] Epoch[3](94/1500); Loss: 0.108642; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1512 0.1413 0.1204 0.1092 0.1049 0.1028 0.1017 0.1008 0.1009 0.1000 0.1006 0.1002 0.1006 0.1007 0.1016 0.1016 

[TRAIN] Epoch[3](95/1500); Loss: 0.072669; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1184 0.0966 0.0920 0.0776 0.0677 0.0647 0.0645 0.0625 0.0643 0.0630 0.0648 0.0639 0.0650 0.0646 0.0667 0.0663 

[TRAIN] Epoch[3](96/1500); Loss: 0.069321; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1246 0.0886 0.0747 0.0708 0.0637 0.0635 0.0610 0.0632 0.0617 0.0627 0.0617 0.0624 0.0617 0.0628 0.0621 0.0640 

[TRAIN] Epoch[3](97/1500); Loss: 0.121128; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1729 0.1522 0.1383 0.1265 0.1172 0.1138 0.1123 0.1114 0.1107 0.1114 0.1109 0.1118 0.1113 0.1121 0.1121 0.1130 

[TRAIN] Epoch[3](98/1500); Loss: 0.156221; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2579 0.1994 0.1785 0.1653 0.1502 0.1456 0.1422 0.1400 0.1401 0.1390 0.1392 0.1395 0.1397 0.1402 0.1407 0.1419 

[TRAIN] Epoch[3](99/1500); Loss: 0.108991; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1694 0.1383 0.1194 0.1086 0.1039 0.1029 0.1009 0.1012 0.0999 0.1004 0.0998 0.1002 0.0995 0.0998 0.0994 0.1003 

[TRAIN] Epoch[3](100/1500); Loss: 0.063381; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.0890 0.0828 0.0689 0.0647 0.0579 0.0595 0.0564 0.0622 0.0598 0.0598 0.0574 0.0588 0.0573 0.0606 0.0588 0.0601 

[TRAIN] Epoch[3](101/1500); Loss: 0.194103; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2460 0.2086 0.2012 0.1993 0.1923 0.1909 0.1883 0.1881 0.1874 0.1876 0.1867 0.1867 0.1860 0.1861 0.1857 0.1848 

[TRAIN] Epoch[3](102/1500); Loss: 0.127579; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2085 0.1622 0.1344 0.1346 0.1238 0.1210 0.1161 0.1153 0.1141 0.1141 0.1143 0.1149 0.1158 0.1165 0.1173 0.1183 

[TRAIN] Epoch[3](103/1500); Loss: 0.114515; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2290 0.1746 0.1355 0.1341 0.1058 0.1014 0.0956 0.0949 0.0945 0.0942 0.0944 0.0952 0.0951 0.0955 0.0958 0.0967 

[TRAIN] Epoch[3](104/1500); Loss: 0.081679; Backpropagation: 0.0982 sec; Batch: 0.4330 sec
0.1644 0.1339 0.1018 0.0925 0.0780 0.0721 0.0723 0.0676 0.0690 0.0652 0.0663 0.0636 0.0648 0.0638 0.0663 0.0655 

[TRAIN] Epoch[3](105/1500); Loss: 0.102774; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.1560 0.1184 0.1168 0.1038 0.0994 0.0974 0.0956 0.0954 0.0945 0.0950 0.0944 0.0951 0.0950 0.0956 0.0955 0.0965 

[TRAIN] Epoch[3](106/1500); Loss: 0.106184; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1960 0.1397 0.1017 0.0975 0.0946 0.0927 0.0921 0.0923 0.0943 0.0946 0.0972 0.0975 0.0998 0.1009 0.1035 0.1046 

[TRAIN] Epoch[3](107/1500); Loss: 0.105402; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1327 0.1230 0.1101 0.1085 0.1046 0.1034 0.1022 0.1009 0.1010 0.1000 0.1004 0.0995 0.1000 0.0994 0.1005 0.1002 

[TRAIN] Epoch[3](108/1500); Loss: 0.130902; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1845 0.1539 0.1430 0.1298 0.1280 0.1256 0.1240 0.1236 0.1227 0.1230 0.1225 0.1226 0.1226 0.1231 0.1229 0.1227 

[TRAIN] Epoch[3](109/1500); Loss: 0.119484; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1955 0.1539 0.1351 0.1271 0.1100 0.1104 0.1082 0.1081 0.1068 0.1077 0.1068 0.1079 0.1077 0.1084 0.1087 0.1095 

[TRAIN] Epoch[3](110/1500); Loss: 0.073042; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1185 0.0886 0.0782 0.0718 0.0691 0.0683 0.0676 0.0683 0.0686 0.0669 0.0671 0.0661 0.0675 0.0667 0.0679 0.0673 

[TRAIN] Epoch[3](111/1500); Loss: 0.087101; Backpropagation: 0.0939 sec; Batch: 0.4677 sec
0.1429 0.1137 0.1028 0.0883 0.0856 0.0808 0.0797 0.0776 0.0773 0.0767 0.0768 0.0770 0.0779 0.0780 0.0790 0.0795 

[TRAIN] Epoch[3](112/1500); Loss: 0.081810; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.2811 0.2039 0.0948 0.0569 0.0718 0.0530 0.0508 0.0537 0.0508 0.0572 0.0547 0.0536 0.0528 0.0581 0.0570 0.0588 

[TRAIN] Epoch[3](113/1500); Loss: 0.123201; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1790 0.1551 0.1302 0.1271 0.1208 0.1188 0.1179 0.1153 0.1151 0.1136 0.1136 0.1129 0.1128 0.1127 0.1132 0.1131 

[TRAIN] Epoch[3](114/1500); Loss: 0.067406; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1112 0.0791 0.0782 0.0653 0.0621 0.0617 0.0612 0.0609 0.0609 0.0610 0.0614 0.0613 0.0624 0.0629 0.0640 0.0649 

[TRAIN] Epoch[3](115/1500); Loss: 0.097612; Backpropagation: 0.0937 sec; Batch: 0.4460 sec
0.1506 0.1261 0.1113 0.1042 0.0940 0.0929 0.0902 0.0897 0.0885 0.0884 0.0880 0.0876 0.0872 0.0877 0.0875 0.0879 

[TRAIN] Epoch[3](116/1500); Loss: 0.080973; Backpropagation: 0.0931 sec; Batch: 0.4651 sec
0.0989 0.1046 0.1073 0.0782 0.0735 0.0724 0.0716 0.0732 0.0729 0.0749 0.0750 0.0765 0.0771 0.0787 0.0791 0.0816 

[TRAIN] Epoch[3](117/1500); Loss: 0.081764; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1607 0.1227 0.0972 0.0841 0.0749 0.0719 0.0709 0.0697 0.0683 0.0691 0.0680 0.0696 0.0686 0.0707 0.0699 0.0722 

[TRAIN] Epoch[3](118/1500); Loss: 0.156903; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1853 0.1677 0.1622 0.1597 0.1556 0.1559 0.1550 0.1539 0.1533 0.1528 0.1528 0.1522 0.1513 0.1511 0.1508 0.1509 

[TRAIN] Epoch[3](119/1500); Loss: 0.102460; Backpropagation: 0.0933 sec; Batch: 0.4266 sec
0.1843 0.1553 0.1144 0.0947 0.0976 0.0917 0.0921 0.0905 0.0902 0.0899 0.0894 0.0898 0.0893 0.0896 0.0899 0.0906 

[TRAIN] Epoch[3](120/1500); Loss: 0.099140; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.1555 0.1432 0.1181 0.0993 0.0968 0.0921 0.0913 0.0893 0.0885 0.0880 0.0876 0.0871 0.0874 0.0871 0.0875 0.0875 

[TRAIN] Epoch[3](121/1500); Loss: 0.124064; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1563 0.1466 0.1333 0.1265 0.1223 0.1207 0.1194 0.1187 0.1183 0.1178 0.1175 0.1174 0.1174 0.1175 0.1175 0.1180 

[TRAIN] Epoch[3](122/1500); Loss: 0.129717; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2103 0.1575 0.1417 0.1340 0.1257 0.1221 0.1183 0.1178 0.1175 0.1180 0.1173 0.1186 0.1179 0.1190 0.1194 0.1201 

[TRAIN] Epoch[3](123/1500); Loss: 0.137748; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.2193 0.1817 0.1646 0.1500 0.1396 0.1340 0.1289 0.1255 0.1236 0.1215 0.1199 0.1195 0.1191 0.1188 0.1188 0.1193 

[TRAIN] Epoch[3](124/1500); Loss: 0.084681; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1815 0.1207 0.0874 0.0861 0.0775 0.0746 0.0711 0.0710 0.0710 0.0708 0.0722 0.0719 0.0740 0.0737 0.0756 0.0758 

[TRAIN] Epoch[3](125/1500); Loss: 0.098299; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1435 0.1430 0.1104 0.0999 0.0951 0.0909 0.0894 0.0877 0.0894 0.0879 0.0894 0.0885 0.0898 0.0889 0.0899 0.0890 

[TRAIN] Epoch[3](126/1500); Loss: 0.103157; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1632 0.1369 0.1223 0.1062 0.1010 0.0975 0.0964 0.0948 0.0935 0.0934 0.0918 0.0915 0.0901 0.0910 0.0901 0.0907 

[TRAIN] Epoch[3](127/1500); Loss: 0.155889; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.2091 0.1838 0.1760 0.1645 0.1525 0.1520 0.1496 0.1497 0.1473 0.1463 0.1451 0.1444 0.1439 0.1433 0.1433 0.1433 

[TRAIN] Epoch[3](128/1500); Loss: 0.075665; Backpropagation: 0.0940 sec; Batch: 0.4276 sec
0.1411 0.0968 0.0868 0.0758 0.0724 0.0678 0.0674 0.0665 0.0667 0.0663 0.0667 0.0669 0.0667 0.0667 0.0678 0.0683 

[TRAIN] Epoch[3](129/1500); Loss: 0.077372; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1841 0.1058 0.0728 0.0661 0.0634 0.0625 0.0632 0.0644 0.0664 0.0668 0.0693 0.0681 0.0700 0.0696 0.0725 0.0729 

[TRAIN] Epoch[3](130/1500); Loss: 0.134931; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.2012 0.1590 0.1430 0.1334 0.1316 0.1290 0.1276 0.1278 0.1267 0.1268 0.1261 0.1262 0.1252 0.1256 0.1249 0.1249 

[TRAIN] Epoch[3](131/1500); Loss: 0.118713; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1564 0.1333 0.1305 0.1237 0.1164 0.1147 0.1133 0.1129 0.1127 0.1125 0.1121 0.1122 0.1116 0.1122 0.1121 0.1128 

[TRAIN] Epoch[3](132/1500); Loss: 0.093440; Backpropagation: 0.0933 sec; Batch: 0.4332 sec
0.1227 0.1107 0.1156 0.0987 0.0826 0.0864 0.0834 0.0884 0.0861 0.0890 0.0873 0.0885 0.0873 0.0891 0.0885 0.0907 

[TRAIN] Epoch[3](133/1500); Loss: 0.150208; Backpropagation: 0.0936 sec; Batch: 0.4301 sec
0.1914 0.1810 0.1741 0.1642 0.1529 0.1507 0.1466 0.1448 0.1414 0.1405 0.1380 0.1378 0.1359 0.1351 0.1341 0.1349 

[TRAIN] Epoch[3](134/1500); Loss: 0.195575; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2545 0.2165 0.2174 0.2058 0.1990 0.1932 0.1900 0.1866 0.1853 0.1832 0.1834 0.1823 0.1825 0.1829 0.1833 0.1835 

[TRAIN] Epoch[3](135/1500); Loss: 0.120634; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1363 0.1495 0.1374 0.1275 0.1174 0.1171 0.1162 0.1154 0.1155 0.1145 0.1142 0.1135 0.1134 0.1133 0.1146 0.1143 

[TRAIN] Epoch[3](136/1500); Loss: 0.102452; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1195 0.1316 0.1163 0.1164 0.0980 0.1005 0.0967 0.0992 0.0964 0.0974 0.0952 0.0952 0.0937 0.0945 0.0940 0.0947 

[TRAIN] Epoch[3](137/1500); Loss: 0.181337; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2519 0.1985 0.1914 0.1829 0.1788 0.1768 0.1752 0.1739 0.1728 0.1720 0.1716 0.1715 0.1711 0.1710 0.1711 0.1710 

[TRAIN] Epoch[3](138/1500); Loss: 0.139393; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.3059 0.2175 0.1769 0.1371 0.1226 0.1190 0.1167 0.1179 0.1159 0.1175 0.1155 0.1149 0.1135 0.1140 0.1125 0.1128 

[TRAIN] Epoch[3](139/1500); Loss: 0.139537; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.1848 0.1681 0.1682 0.1566 0.1407 0.1383 0.1329 0.1310 0.1282 0.1283 0.1259 0.1275 0.1253 0.1258 0.1248 0.1260 

[TRAIN] Epoch[3](140/1500); Loss: 0.140867; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1870 0.1972 0.1896 0.1645 0.1354 0.1319 0.1264 0.1261 0.1235 0.1249 0.1230 0.1245 0.1233 0.1256 0.1247 0.1262 

[TRAIN] Epoch[3](141/1500); Loss: 0.106525; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2845 0.1782 0.1325 0.0950 0.0839 0.0822 0.0811 0.0837 0.0840 0.0861 0.0855 0.0862 0.0851 0.0852 0.0849 0.0863 

[TRAIN] Epoch[3](142/1500); Loss: 0.181157; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2489 0.2238 0.2130 0.1958 0.1815 0.1777 0.1730 0.1705 0.1668 0.1657 0.1642 0.1644 0.1635 0.1634 0.1631 0.1634 

[TRAIN] Epoch[3](143/1500); Loss: 0.129623; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1679 0.1596 0.1481 0.1362 0.1258 0.1245 0.1214 0.1228 0.1203 0.1213 0.1195 0.1207 0.1197 0.1216 0.1213 0.1232 

[TRAIN] Epoch[3](144/1500); Loss: 0.147438; Backpropagation: 0.0934 sec; Batch: 0.4267 sec
0.1700 0.1646 0.1557 0.1511 0.1453 0.1438 0.1429 0.1431 0.1429 0.1432 0.1427 0.1427 0.1424 0.1424 0.1429 0.1434 

[TRAIN] Epoch[3](145/1500); Loss: 0.140423; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2044 0.1614 0.1494 0.1404 0.1361 0.1338 0.1317 0.1332 0.1314 0.1335 0.1317 0.1335 0.1319 0.1321 0.1310 0.1313 

[TRAIN] Epoch[3](146/1500); Loss: 0.065455; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0773 0.1037 0.0755 0.0723 0.0615 0.0594 0.0591 0.0595 0.0590 0.0596 0.0590 0.0597 0.0589 0.0603 0.0608 0.0616 

[TRAIN] Epoch[3](147/1500); Loss: 0.073135; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1104 0.1019 0.0787 0.0853 0.0668 0.0722 0.0658 0.0685 0.0636 0.0670 0.0627 0.0671 0.0631 0.0667 0.0637 0.0667 

[TRAIN] Epoch[3](148/1500); Loss: 0.161081; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.2156 0.1891 0.1794 0.1628 0.1588 0.1551 0.1534 0.1528 0.1518 0.1517 0.1510 0.1511 0.1511 0.1511 0.1510 0.1515 

[TRAIN] Epoch[3](149/1500); Loss: 0.082656; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1260 0.1257 0.1077 0.0976 0.0787 0.0784 0.0728 0.0735 0.0692 0.0706 0.0677 0.0712 0.0689 0.0717 0.0704 0.0724 

[TRAIN] Epoch[3](150/1500); Loss: 0.069482; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1039 0.1100 0.0712 0.0832 0.0653 0.0662 0.0588 0.0639 0.0580 0.0635 0.0589 0.0620 0.0590 0.0631 0.0607 0.0640 

[TRAIN] Epoch[3](151/1500); Loss: 0.081315; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.0790 0.1084 0.0799 0.0896 0.0769 0.0808 0.0768 0.0794 0.0767 0.0787 0.0764 0.0790 0.0774 0.0809 0.0796 0.0814 

[TRAIN] Epoch[3](152/1500); Loss: 0.056808; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.0894 0.0793 0.0544 0.0608 0.0502 0.0530 0.0488 0.0526 0.0495 0.0531 0.0510 0.0532 0.0517 0.0540 0.0528 0.0552 

[TRAIN] Epoch[3](153/1500); Loss: 0.084451; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2242 0.0961 0.0613 0.0621 0.0604 0.0615 0.0636 0.0666 0.0693 0.0731 0.0760 0.0798 0.0835 0.0878 0.0910 0.0950 

[TRAIN] Epoch[3](154/1500); Loss: 0.102239; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2783 0.1446 0.1066 0.0878 0.0903 0.0838 0.0851 0.0819 0.0837 0.0820 0.0838 0.0832 0.0851 0.0851 0.0870 0.0874 

[TRAIN] Epoch[3](155/1500); Loss: 0.077218; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2454 0.1064 0.0821 0.0629 0.0612 0.0579 0.0585 0.0572 0.0602 0.0590 0.0621 0.0615 0.0637 0.0637 0.0662 0.0675 

[TRAIN] Epoch[3](156/1500); Loss: 0.135243; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.2385 0.1809 0.1616 0.1458 0.1316 0.1251 0.1215 0.1189 0.1185 0.1174 0.1171 0.1167 0.1176 0.1173 0.1177 0.1177 

[TRAIN] Epoch[3](157/1500); Loss: 0.121111; Backpropagation: 0.0961 sec; Batch: 0.4314 sec
0.1715 0.1543 0.1357 0.1243 0.1167 0.1150 0.1119 0.1117 0.1109 0.1109 0.1109 0.1112 0.1119 0.1125 0.1139 0.1145 

[TRAIN] Epoch[3](158/1500); Loss: 0.109911; Backpropagation: 0.0958 sec; Batch: 0.4304 sec
0.1300 0.1319 0.1215 0.1113 0.1070 0.1052 0.1045 0.1048 0.1047 0.1052 0.1047 0.1050 0.1049 0.1054 0.1058 0.1068 

[TRAIN] Epoch[3](159/1500); Loss: 0.122285; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1949 0.1650 0.1431 0.1208 0.1181 0.1126 0.1113 0.1102 0.1096 0.1094 0.1096 0.1099 0.1098 0.1103 0.1106 0.1113 

[TRAIN] Epoch[3](160/1500); Loss: 0.213251; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.2908 0.2514 0.2521 0.2349 0.2182 0.2112 0.2053 0.1993 0.1964 0.1939 0.1942 0.1927 0.1932 0.1923 0.1932 0.1928 

[TRAIN] Epoch[3](161/1500); Loss: 0.073021; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1101 0.1058 0.0898 0.0834 0.0711 0.0703 0.0643 0.0679 0.0621 0.0655 0.0612 0.0647 0.0609 0.0643 0.0614 0.0653 

[TRAIN] Epoch[3](162/1500); Loss: 0.077716; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1240 0.1108 0.0957 0.0833 0.0711 0.0692 0.0677 0.0676 0.0672 0.0678 0.0674 0.0692 0.0690 0.0705 0.0711 0.0718 

[TRAIN] Epoch[3](163/1500); Loss: 0.079662; Backpropagation: 0.0958 sec; Batch: 0.4300 sec
0.1227 0.1090 0.0872 0.0744 0.0748 0.0704 0.0717 0.0706 0.0719 0.0717 0.0729 0.0734 0.0749 0.0750 0.0769 0.0770 

[TRAIN] Epoch[3](164/1500); Loss: 0.081562; Backpropagation: 0.0957 sec; Batch: 0.4303 sec
0.1730 0.0881 0.0805 0.0741 0.0690 0.0702 0.0688 0.0678 0.0699 0.0702 0.0731 0.0740 0.0779 0.0793 0.0836 0.0855 

[TRAIN] Epoch[3](165/1500); Loss: 0.099711; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1921 0.1401 0.1177 0.1021 0.0891 0.0850 0.0851 0.0833 0.0847 0.0839 0.0856 0.0865 0.0883 0.0884 0.0914 0.0921 

[TRAIN] Epoch[3](166/1500); Loss: 0.136748; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.3433 0.2979 0.2672 0.2433 0.1606 0.1346 0.1067 0.0748 0.0691 0.0694 0.0682 0.0690 0.0693 0.0705 0.0714 0.0726 

[TRAIN] Epoch[3](167/1500); Loss: 0.092089; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.3332 0.1854 0.1206 0.0687 0.0708 0.0614 0.0621 0.0612 0.0607 0.0641 0.0617 0.0649 0.0625 0.0653 0.0641 0.0666 

[TRAIN] Epoch[3](168/1500); Loss: 0.100244; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1660 0.1130 0.1094 0.1020 0.0978 0.0943 0.0925 0.0939 0.0916 0.0933 0.0915 0.0923 0.0911 0.0917 0.0914 0.0921 

[TRAIN] Epoch[3](169/1500); Loss: 0.096394; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2281 0.1737 0.1351 0.1019 0.0819 0.0748 0.0747 0.0709 0.0746 0.0709 0.0752 0.0724 0.0768 0.0749 0.0785 0.0778 

[TRAIN] Epoch[3](170/1500); Loss: 0.115408; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1819 0.1526 0.1382 0.1168 0.1092 0.1077 0.1049 0.1050 0.1033 0.1050 0.1028 0.1043 0.1025 0.1045 0.1029 0.1049 

[TRAIN] Epoch[3](171/1500); Loss: 0.065803; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1022 0.1057 0.0817 0.0701 0.0642 0.0602 0.0592 0.0570 0.0565 0.0559 0.0559 0.0562 0.0560 0.0569 0.0569 0.0580 

[TRAIN] Epoch[3](172/1500); Loss: 0.095381; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1355 0.1309 0.1051 0.0954 0.0914 0.0915 0.0883 0.0884 0.0866 0.0873 0.0859 0.0877 0.0869 0.0885 0.0879 0.0888 

[TRAIN] Epoch[3](173/1500); Loss: 0.102212; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1896 0.1323 0.1128 0.0994 0.0954 0.0932 0.0924 0.0914 0.0918 0.0906 0.0915 0.0904 0.0916 0.0904 0.0919 0.0906 

[TRAIN] Epoch[3](174/1500); Loss: 0.137087; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.1745 0.1543 0.1488 0.1412 0.1362 0.1348 0.1328 0.1327 0.1311 0.1317 0.1300 0.1301 0.1289 0.1292 0.1283 0.1288 

[TRAIN] Epoch[3](175/1500); Loss: 0.119512; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2651 0.2326 0.2035 0.1863 0.1215 0.1037 0.0813 0.0786 0.0787 0.0788 0.0794 0.0793 0.0798 0.0803 0.0815 0.0818 

[TRAIN] Epoch[3](176/1500); Loss: 0.068795; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1791 0.0696 0.0812 0.0643 0.0599 0.0573 0.0561 0.0579 0.0555 0.0599 0.0565 0.0616 0.0577 0.0621 0.0587 0.0634 

[TRAIN] Epoch[3](177/1500); Loss: 0.091973; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1392 0.1288 0.1131 0.0991 0.0893 0.0872 0.0841 0.0829 0.0808 0.0814 0.0803 0.0814 0.0804 0.0813 0.0806 0.0815 

[TRAIN] Epoch[3](178/1500); Loss: 0.076090; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1478 0.1094 0.0879 0.0734 0.0694 0.0674 0.0665 0.0666 0.0656 0.0668 0.0656 0.0669 0.0653 0.0665 0.0655 0.0669 

[TRAIN] Epoch[3](179/1500); Loss: 0.092835; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2517 0.1971 0.1666 0.1430 0.0649 0.0585 0.0605 0.0583 0.0584 0.0591 0.0588 0.0601 0.0602 0.0619 0.0622 0.0641 

[TRAIN] Epoch[3](180/1500); Loss: 0.083831; Backpropagation: 0.0981 sec; Batch: 0.4329 sec
0.2246 0.1529 0.1187 0.0936 0.0626 0.0607 0.0614 0.0603 0.0618 0.0615 0.0618 0.0629 0.0624 0.0649 0.0639 0.0673 

[TRAIN] Epoch[3](181/1500); Loss: 0.121873; Backpropagation: 0.0968 sec; Batch: 0.4320 sec
0.2231 0.1542 0.1293 0.1149 0.1108 0.1098 0.1087 0.1099 0.1089 0.1105 0.1096 0.1113 0.1109 0.1119 0.1127 0.1136 

[TRAIN] Epoch[3](182/1500); Loss: 0.095292; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1711 0.1169 0.1008 0.0918 0.0911 0.0885 0.0878 0.0860 0.0874 0.0858 0.0869 0.0855 0.0867 0.0855 0.0870 0.0861 

[TRAIN] Epoch[3](183/1500); Loss: 0.130502; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1906 0.1491 0.1433 0.1313 0.1279 0.1252 0.1242 0.1236 0.1226 0.1224 0.1218 0.1213 0.1211 0.1211 0.1210 0.1214 

[TRAIN] Epoch[3](184/1500); Loss: 0.086950; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1482 0.1045 0.0957 0.0857 0.0811 0.0801 0.0785 0.0791 0.0781 0.0792 0.0785 0.0797 0.0793 0.0806 0.0807 0.0822 

[TRAIN] Epoch[3](185/1500); Loss: 0.095999; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1244 0.1163 0.1022 0.1020 0.0940 0.0938 0.0905 0.0910 0.0890 0.0903 0.0888 0.0902 0.0897 0.0910 0.0906 0.0919 

[TRAIN] Epoch[3](186/1500); Loss: 0.066173; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.0965 0.0874 0.0684 0.0640 0.0625 0.0619 0.0614 0.0608 0.0608 0.0603 0.0613 0.0608 0.0628 0.0620 0.0644 0.0636 

[TRAIN] Epoch[3](187/1500); Loss: 0.066984; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.1693 0.1081 0.0663 0.0577 0.0658 0.0574 0.0563 0.0523 0.0532 0.0505 0.0534 0.0511 0.0560 0.0548 0.0599 0.0597 

[TRAIN] Epoch[3](188/1500); Loss: 0.092764; Backpropagation: 0.0941 sec; Batch: 0.4390 sec
0.1946 0.1359 0.0978 0.0817 0.0920 0.0808 0.0772 0.0761 0.0783 0.0770 0.0793 0.0785 0.0827 0.0812 0.0867 0.0845 

[TRAIN] Epoch[3](189/1500); Loss: 0.112061; Backpropagation: 0.0938 sec; Batch: 0.4698 sec
0.1649 0.1173 0.1141 0.1040 0.1136 0.1059 0.1096 0.1044 0.1081 0.1037 0.1081 0.1043 0.1096 0.1060 0.1113 0.1082 

[TRAIN] Epoch[3](190/1500); Loss: 0.052120; Backpropagation: 0.0938 sec; Batch: 0.4308 sec
0.0966 0.0750 0.0577 0.0574 0.0504 0.0494 0.0459 0.0454 0.0441 0.0440 0.0438 0.0440 0.0442 0.0448 0.0449 0.0462 

[TRAIN] Epoch[3](191/1500); Loss: 0.067617; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.0693 0.0975 0.0680 0.0742 0.0649 0.0674 0.0625 0.0643 0.0618 0.0636 0.0626 0.0641 0.0638 0.0653 0.0655 0.0671 

[TRAIN] Epoch[3](192/1500); Loss: 0.092572; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2059 0.1261 0.0921 0.0792 0.0788 0.0771 0.0768 0.0777 0.0790 0.0797 0.0818 0.0824 0.0846 0.0849 0.0875 0.0875 

[TRAIN] Epoch[3](193/1500); Loss: 0.064078; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1234 0.0782 0.0696 0.0636 0.0603 0.0552 0.0581 0.0539 0.0582 0.0545 0.0581 0.0554 0.0596 0.0572 0.0611 0.0590 

[TRAIN] Epoch[3](194/1500); Loss: 0.065734; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.0867 0.1140 0.0825 0.0597 0.0596 0.0579 0.0556 0.0580 0.0560 0.0594 0.0568 0.0607 0.0585 0.0622 0.0602 0.0639 

[TRAIN] Epoch[3](195/1500); Loss: 0.116314; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1798 0.1421 0.1304 0.1152 0.1149 0.1101 0.1086 0.1077 0.1067 0.1069 0.1058 0.1065 0.1061 0.1065 0.1064 0.1073 

[TRAIN] Epoch[3](196/1500); Loss: 0.124316; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2079 0.1433 0.1341 0.1258 0.1187 0.1170 0.1164 0.1149 0.1144 0.1139 0.1138 0.1135 0.1135 0.1136 0.1138 0.1143 

[TRAIN] Epoch[3](197/1500); Loss: 0.115653; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2015 0.1542 0.1379 0.1233 0.1106 0.1066 0.1041 0.1030 0.1015 0.1019 0.1008 0.1012 0.1004 0.1011 0.1006 0.1016 

[TRAIN] Epoch[3](198/1500); Loss: 0.087772; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1755 0.1013 0.0981 0.0869 0.0836 0.0791 0.0788 0.0780 0.0777 0.0777 0.0775 0.0779 0.0778 0.0780 0.0779 0.0785 

[TRAIN] Epoch[3](199/1500); Loss: 0.072233; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.2301 0.0952 0.0630 0.0695 0.0587 0.0619 0.0567 0.0583 0.0556 0.0575 0.0556 0.0581 0.0570 0.0592 0.0584 0.0609 

[TRAIN] Epoch[3](200/1500); Loss: 0.100596; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.2771 0.1723 0.1181 0.0861 0.0896 0.0804 0.0793 0.0774 0.0776 0.0769 0.0777 0.0777 0.0789 0.0791 0.0802 0.0810 

[TRAIN] Epoch[3](201/1500); Loss: 0.120605; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.3161 0.2048 0.1588 0.1244 0.1155 0.1007 0.0942 0.0902 0.0900 0.0886 0.0896 0.0892 0.0909 0.0907 0.0929 0.0931 

[TRAIN] Epoch[3](202/1500); Loss: 0.084038; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1579 0.1146 0.0989 0.0846 0.0828 0.0776 0.0753 0.0741 0.0725 0.0733 0.0715 0.0728 0.0714 0.0728 0.0716 0.0728 

[TRAIN] Epoch[3](203/1500); Loss: 0.107679; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1624 0.1204 0.1204 0.1118 0.1058 0.1032 0.1018 0.1009 0.0998 0.0998 0.0991 0.0994 0.0989 0.0997 0.0994 0.1001 

[TRAIN] Epoch[3](204/1500); Loss: 0.044287; Backpropagation: 0.0940 sec; Batch: 0.4275 sec
0.0543 0.0623 0.0466 0.0456 0.0430 0.0408 0.0411 0.0394 0.0403 0.0394 0.0408 0.0406 0.0423 0.0425 0.0445 0.0451 

[TRAIN] Epoch[3](205/1500); Loss: 0.105794; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1928 0.1362 0.1233 0.1111 0.0959 0.0947 0.0931 0.0931 0.0929 0.0937 0.0933 0.0937 0.0940 0.0945 0.0952 0.0952 

[TRAIN] Epoch[3](206/1500); Loss: 0.119350; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1459 0.1360 0.1234 0.1217 0.1158 0.1155 0.1143 0.1151 0.1140 0.1154 0.1142 0.1153 0.1147 0.1160 0.1155 0.1170 

[TRAIN] Epoch[3](207/1500); Loss: 0.083593; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1819 0.0995 0.0865 0.0796 0.0779 0.0743 0.0743 0.0717 0.0754 0.0714 0.0754 0.0715 0.0760 0.0724 0.0764 0.0734 

[TRAIN] Epoch[3](208/1500); Loss: 0.179842; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.2642 0.2034 0.1896 0.1774 0.1796 0.1737 0.1711 0.1696 0.1694 0.1689 0.1689 0.1683 0.1685 0.1683 0.1683 0.1683 

[TRAIN] Epoch[3](209/1500); Loss: 0.127240; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1988 0.1496 0.1400 0.1280 0.1245 0.1190 0.1181 0.1168 0.1171 0.1167 0.1170 0.1175 0.1176 0.1180 0.1183 0.1189 

[TRAIN] Epoch[3](210/1500); Loss: 0.056548; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1518 0.0792 0.0405 0.0500 0.0560 0.0418 0.0509 0.0417 0.0487 0.0427 0.0496 0.0449 0.0518 0.0483 0.0547 0.0520 

[TRAIN] Epoch[3](211/1500); Loss: 0.070514; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.1120 0.0791 0.0787 0.0697 0.0684 0.0647 0.0649 0.0642 0.0639 0.0648 0.0642 0.0657 0.0653 0.0673 0.0671 0.0683 

[TRAIN] Epoch[3](212/1500); Loss: 0.137057; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2323 0.1600 0.1556 0.1367 0.1321 0.1290 0.1280 0.1271 0.1255 0.1252 0.1242 0.1239 0.1233 0.1234 0.1232 0.1235 

[TRAIN] Epoch[3](213/1500); Loss: 0.064134; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1205 0.0840 0.0702 0.0653 0.0599 0.0581 0.0562 0.0569 0.0546 0.0574 0.0548 0.0583 0.0554 0.0589 0.0562 0.0593 

[TRAIN] Epoch[3](214/1500); Loss: 0.182533; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2865 0.2153 0.2059 0.1863 0.1748 0.1733 0.1711 0.1691 0.1686 0.1677 0.1673 0.1667 0.1671 0.1665 0.1672 0.1671 

[TRAIN] Epoch[3](215/1500); Loss: 0.135555; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1844 0.1421 0.1454 0.1360 0.1348 0.1315 0.1311 0.1297 0.1296 0.1292 0.1290 0.1289 0.1290 0.1292 0.1293 0.1296 

[TRAIN] Epoch[3](216/1500); Loss: 0.078149; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2048 0.1053 0.0834 0.0721 0.0680 0.0650 0.0629 0.0641 0.0629 0.0641 0.0639 0.0652 0.0649 0.0672 0.0674 0.0694 

[TRAIN] Epoch[3](217/1500); Loss: 0.093178; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.1523 0.1423 0.1134 0.1041 0.0914 0.0865 0.0813 0.0807 0.0786 0.0792 0.0787 0.0797 0.0799 0.0805 0.0808 0.0814 

[TRAIN] Epoch[3](218/1500); Loss: 0.058032; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.0714 0.0696 0.0573 0.0584 0.0542 0.0546 0.0534 0.0554 0.0537 0.0567 0.0548 0.0579 0.0560 0.0586 0.0569 0.0595 

[TRAIN] Epoch[3](219/1500); Loss: 0.143021; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.2454 0.1850 0.1695 0.1457 0.1367 0.1310 0.1293 0.1279 0.1276 0.1269 0.1274 0.1265 0.1274 0.1267 0.1279 0.1274 

[TRAIN] Epoch[3](220/1500); Loss: 0.104567; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1343 0.1112 0.1078 0.1029 0.1045 0.1020 0.1022 0.1008 0.1010 0.1007 0.1008 0.1006 0.1008 0.1009 0.1013 0.1014 

[TRAIN] Epoch[3](221/1500); Loss: 0.109234; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1708 0.1276 0.1149 0.1082 0.1037 0.1022 0.1013 0.1008 0.1010 0.1009 0.1010 0.1017 0.1022 0.1033 0.1034 0.1047 

[TRAIN] Epoch[3](222/1500); Loss: 0.099748; Backpropagation: 0.0939 sec; Batch: 0.4271 sec
0.1346 0.1109 0.1070 0.1033 0.0990 0.0967 0.0955 0.0959 0.0937 0.0948 0.0931 0.0947 0.0932 0.0948 0.0936 0.0953 

[TRAIN] Epoch[3](223/1500); Loss: 0.093788; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.3204 0.1976 0.1334 0.0794 0.0665 0.0621 0.0609 0.0612 0.0615 0.0637 0.0633 0.0658 0.0645 0.0669 0.0656 0.0678 

[TRAIN] Epoch[3](224/1500); Loss: 0.109318; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.3753 0.2602 0.1931 0.1297 0.0880 0.0694 0.0641 0.0616 0.0616 0.0612 0.0643 0.0629 0.0656 0.0637 0.0650 0.0634 

[TRAIN] Epoch[3](225/1500); Loss: 0.098182; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1473 0.1167 0.1047 0.0988 0.0986 0.0950 0.0928 0.0927 0.0902 0.0915 0.0891 0.0912 0.0891 0.0914 0.0898 0.0922 

[TRAIN] Epoch[3](226/1500); Loss: 0.091148; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1673 0.1278 0.1145 0.0953 0.0882 0.0847 0.0826 0.0829 0.0789 0.0799 0.0767 0.0782 0.0752 0.0765 0.0744 0.0753 

[TRAIN] Epoch[3](227/1500); Loss: 0.090838; Backpropagation: 0.0942 sec; Batch: 0.4295 sec
0.2273 0.1362 0.0972 0.0795 0.0831 0.0772 0.0742 0.0737 0.0731 0.0748 0.0741 0.0754 0.0753 0.0765 0.0774 0.0784 

[TRAIN] Epoch[3](228/1500); Loss: 0.099751; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2000 0.1295 0.1076 0.0942 0.0936 0.0906 0.0893 0.0892 0.0884 0.0885 0.0879 0.0879 0.0871 0.0875 0.0870 0.0876 

[TRAIN] Epoch[3](229/1500); Loss: 0.165595; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2164 0.1758 0.1729 0.1667 0.1644 0.1626 0.1611 0.1604 0.1596 0.1591 0.1584 0.1586 0.1583 0.1583 0.1584 0.1586 

[TRAIN] Epoch[3](230/1500); Loss: 0.130687; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2359 0.1650 0.1473 0.1272 0.1273 0.1220 0.1199 0.1177 0.1171 0.1165 0.1161 0.1159 0.1157 0.1156 0.1159 0.1159 

[TRAIN] Epoch[3](231/1500); Loss: 0.082875; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1877 0.1200 0.0937 0.0792 0.0769 0.0727 0.0720 0.0709 0.0702 0.0698 0.0692 0.0692 0.0686 0.0687 0.0686 0.0687 

[TRAIN] Epoch[3](232/1500); Loss: 0.077712; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1535 0.0995 0.0878 0.0730 0.0735 0.0693 0.0698 0.0682 0.0682 0.0682 0.0680 0.0681 0.0682 0.0688 0.0694 0.0698 

[TRAIN] Epoch[3](233/1500); Loss: 0.115962; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.2658 0.1572 0.1227 0.1112 0.1073 0.1038 0.1010 0.0995 0.0992 0.0983 0.0983 0.0981 0.0983 0.0980 0.0984 0.0982 

[TRAIN] Epoch[3](234/1500); Loss: 0.069947; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1620 0.0974 0.0750 0.0668 0.0631 0.0607 0.0596 0.0589 0.0589 0.0583 0.0586 0.0585 0.0596 0.0597 0.0608 0.0613 

[TRAIN] Epoch[3](235/1500); Loss: 0.127767; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1515 0.1430 0.1340 0.1330 0.1269 0.1264 0.1249 0.1251 0.1234 0.1239 0.1228 0.1230 0.1212 0.1221 0.1209 0.1222 

[TRAIN] Epoch[3](236/1500); Loss: 0.071645; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1136 0.0793 0.0759 0.0706 0.0697 0.0671 0.0671 0.0665 0.0664 0.0667 0.0664 0.0670 0.0670 0.0673 0.0677 0.0681 

[TRAIN] Epoch[3](237/1500); Loss: 0.105470; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1544 0.1135 0.1033 0.1019 0.1008 0.1005 0.1004 0.1001 0.1005 0.1002 0.1010 0.1008 0.1020 0.1017 0.1032 0.1031 

[TRAIN] Epoch[3](238/1500); Loss: 0.101175; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.4042 0.2371 0.1294 0.0604 0.0765 0.0635 0.0632 0.0615 0.0652 0.0618 0.0646 0.0636 0.0665 0.0657 0.0677 0.0681 

[TRAIN] Epoch[3](239/1500); Loss: 0.075326; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1644 0.1113 0.0882 0.0757 0.0710 0.0662 0.0638 0.0637 0.0619 0.0630 0.0616 0.0626 0.0619 0.0632 0.0627 0.0638 

[TRAIN] Epoch[3](240/1500); Loss: 0.046267; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1035 0.0629 0.0549 0.0434 0.0451 0.0401 0.0408 0.0388 0.0389 0.0382 0.0383 0.0380 0.0389 0.0387 0.0399 0.0399 

[TRAIN] Epoch[3](241/1500); Loss: 0.117528; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.2805 0.1975 0.1452 0.1130 0.1048 0.0980 0.0954 0.0952 0.0934 0.0951 0.0928 0.0945 0.0925 0.0945 0.0931 0.0949 

[TRAIN] Epoch[3](242/1500); Loss: 0.119637; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1593 0.1424 0.1291 0.1215 0.1172 0.1156 0.1148 0.1139 0.1133 0.1128 0.1124 0.1123 0.1122 0.1122 0.1125 0.1128 

[TRAIN] Epoch[3](243/1500); Loss: 0.131934; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2522 0.1880 0.1504 0.1243 0.1290 0.1198 0.1155 0.1131 0.1135 0.1135 0.1140 0.1144 0.1147 0.1156 0.1161 0.1169 

[TRAIN] Epoch[3](244/1500); Loss: 0.101526; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.2662 0.1793 0.1444 0.1309 0.0783 0.0819 0.0740 0.0755 0.0738 0.0756 0.0733 0.0748 0.0729 0.0747 0.0734 0.0753 

[TRAIN] Epoch[3](245/1500); Loss: 0.104684; Backpropagation: 0.0941 sec; Batch: 0.4277 sec
0.2864 0.1747 0.1368 0.1125 0.0966 0.0875 0.0817 0.0789 0.0781 0.0768 0.0772 0.0766 0.0775 0.0772 0.0781 0.0784 

[TRAIN] Epoch[3](246/1500); Loss: 0.104874; Backpropagation: 0.0957 sec; Batch: 0.4297 sec
0.2405 0.1520 0.1202 0.0976 0.0954 0.0911 0.0892 0.0886 0.0877 0.0881 0.0874 0.0876 0.0877 0.0879 0.0883 0.0887 

[TRAIN] Epoch[3](247/1500); Loss: 0.059838; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1553 0.0879 0.0671 0.0600 0.0534 0.0497 0.0489 0.0485 0.0482 0.0476 0.0484 0.0476 0.0486 0.0479 0.0495 0.0488 

[TRAIN] Epoch[3](248/1500); Loss: 0.124011; Backpropagation: 0.0938 sec; Batch: 0.4274 sec
0.2024 0.1663 0.1350 0.1278 0.1238 0.1214 0.1175 0.1166 0.1146 0.1130 0.1110 0.1096 0.1078 0.1069 0.1054 0.1051 

[TRAIN] Epoch[3](249/1500); Loss: 0.059809; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.0952 0.0828 0.0668 0.0586 0.0558 0.0561 0.0543 0.0548 0.0531 0.0544 0.0531 0.0543 0.0533 0.0548 0.0541 0.0554 

[TRAIN] Epoch[3](250/1500); Loss: 0.169105; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2317 0.1817 0.1687 0.1627 0.1643 0.1632 0.1631 0.1629 0.1627 0.1628 0.1630 0.1632 0.1632 0.1636 0.1642 0.1646 

[TRAIN] Epoch[3](251/1500); Loss: 0.088631; Backpropagation: 0.0943 sec; Batch: 0.4289 sec
0.3054 0.1862 0.1306 0.0821 0.0618 0.0598 0.0577 0.0581 0.0581 0.0588 0.0588 0.0599 0.0600 0.0599 0.0599 0.0611 

[TRAIN] Epoch[3](252/1500); Loss: 0.119593; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2968 0.1967 0.1516 0.1160 0.1052 0.0970 0.0946 0.0935 0.0938 0.0943 0.0955 0.0947 0.0955 0.0956 0.0966 0.0962 

[TRAIN] Epoch[3](253/1500); Loss: 0.189057; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2782 0.2337 0.2064 0.1959 0.1755 0.1756 0.1744 0.1760 0.1750 0.1761 0.1753 0.1769 0.1758 0.1770 0.1758 0.1772 

[TRAIN] Epoch[3](254/1500); Loss: 0.069741; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1505 0.1030 0.0789 0.0634 0.0639 0.0610 0.0599 0.0593 0.0589 0.0591 0.0590 0.0593 0.0593 0.0597 0.0600 0.0605 

[TRAIN] Epoch[3](255/1500); Loss: 0.076859; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2483 0.1161 0.0733 0.0569 0.0563 0.0554 0.0564 0.0575 0.0583 0.0591 0.0606 0.0623 0.0638 0.0663 0.0681 0.0710 

[TRAIN] Epoch[3](256/1500); Loss: 0.108945; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2149 0.1348 0.1185 0.1066 0.1037 0.1001 0.0991 0.0974 0.0971 0.0965 0.0962 0.0960 0.0956 0.0956 0.0954 0.0955 

[TRAIN] Epoch[3](257/1500); Loss: 0.092239; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2150 0.1366 0.1135 0.0953 0.0871 0.0802 0.0764 0.0750 0.0743 0.0749 0.0740 0.0744 0.0740 0.0748 0.0744 0.0758 

[TRAIN] Epoch[3](258/1500); Loss: 0.094750; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1690 0.1108 0.1015 0.0950 0.0901 0.0884 0.0873 0.0862 0.0860 0.0857 0.0856 0.0856 0.0856 0.0860 0.0864 0.0869 

[TRAIN] Epoch[3](259/1500); Loss: 0.174087; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2542 0.1888 0.1826 0.1717 0.1710 0.1689 0.1675 0.1662 0.1654 0.1645 0.1644 0.1643 0.1640 0.1642 0.1637 0.1639 

[TRAIN] Epoch[3](260/1500); Loss: 0.106739; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2155 0.1556 0.1326 0.1123 0.1039 0.0980 0.0950 0.0919 0.0903 0.0887 0.0880 0.0873 0.0872 0.0869 0.0873 0.0873 

[TRAIN] Epoch[3](261/1500); Loss: 0.068462; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2920 0.1198 0.0755 0.0605 0.0499 0.0460 0.0450 0.0441 0.0449 0.0442 0.0454 0.0445 0.0456 0.0450 0.0464 0.0465 

[TRAIN] Epoch[3](262/1500); Loss: 0.074670; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1599 0.1077 0.0953 0.0800 0.0714 0.0669 0.0627 0.0626 0.0602 0.0620 0.0597 0.0621 0.0598 0.0618 0.0603 0.0624 

[TRAIN] Epoch[3](263/1500); Loss: 0.105635; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1744 0.1226 0.1136 0.1052 0.1033 0.1008 0.0993 0.0986 0.0971 0.0972 0.0964 0.0967 0.0961 0.0965 0.0959 0.0964 

[TRAIN] Epoch[3](264/1500); Loss: 0.073559; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.2018 0.1057 0.0838 0.0714 0.0674 0.0639 0.0614 0.0600 0.0589 0.0582 0.0576 0.0573 0.0573 0.0574 0.0573 0.0576 

[TRAIN] Epoch[3](265/1500); Loss: 0.183663; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.2991 0.2384 0.2201 0.1971 0.1684 0.1686 0.1651 0.1645 0.1650 0.1643 0.1643 0.1644 0.1643 0.1646 0.1645 0.1659 

[TRAIN] Epoch[3](266/1500); Loss: 0.112218; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1949 0.1379 0.1212 0.1113 0.1068 0.1053 0.1038 0.1034 0.1026 0.1020 0.1016 0.1014 0.1009 0.1007 0.1006 0.1009 

[TRAIN] Epoch[3](267/1500); Loss: 0.046475; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.0637 0.0853 0.0484 0.0525 0.0416 0.0419 0.0400 0.0414 0.0396 0.0408 0.0399 0.0410 0.0407 0.0419 0.0419 0.0430 

[TRAIN] Epoch[3](268/1500); Loss: 0.105765; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1876 0.1291 0.1161 0.1042 0.1001 0.0981 0.0964 0.0967 0.0954 0.0959 0.0952 0.0956 0.0950 0.0955 0.0954 0.0961 

[TRAIN] Epoch[3](269/1500); Loss: 0.127460; Backpropagation: 0.0941 sec; Batch: 0.4276 sec
0.2748 0.1913 0.1510 0.1216 0.1149 0.1102 0.1077 0.1078 0.1075 0.1074 0.1073 0.1080 0.1073 0.1077 0.1071 0.1075 

[TRAIN] Epoch[3](270/1500); Loss: 0.091142; Backpropagation: 0.0938 sec; Batch: 0.4275 sec
0.1866 0.1220 0.1027 0.0891 0.0871 0.0827 0.0797 0.0789 0.0787 0.0782 0.0787 0.0783 0.0786 0.0785 0.0790 0.0793 

[TRAIN] Epoch[3](271/1500); Loss: 0.134615; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1820 0.1571 0.1417 0.1359 0.1319 0.1297 0.1289 0.1283 0.1277 0.1275 0.1271 0.1273 0.1272 0.1272 0.1271 0.1271 

[TRAIN] Epoch[3](272/1500); Loss: 0.045624; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.0604 0.0738 0.0451 0.0490 0.0410 0.0413 0.0403 0.0420 0.0405 0.0413 0.0411 0.0419 0.0420 0.0428 0.0431 0.0444 

[TRAIN] Epoch[3](273/1500); Loss: 0.094705; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.3374 0.2027 0.1449 0.1015 0.0783 0.0663 0.0620 0.0602 0.0592 0.0585 0.0578 0.0580 0.0573 0.0576 0.0566 0.0572 

[TRAIN] Epoch[3](274/1500); Loss: 0.115790; Backpropagation: 0.0941 sec; Batch: 0.4276 sec
0.2102 0.1530 0.1376 0.1217 0.1151 0.1096 0.1055 0.1028 0.1008 0.0998 0.0996 0.0996 0.0993 0.0993 0.0992 0.0994 

[TRAIN] Epoch[3](275/1500); Loss: 0.115119; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.3970 0.2493 0.1705 0.1121 0.0868 0.0778 0.0744 0.0738 0.0757 0.0729 0.0761 0.0733 0.0768 0.0743 0.0761 0.0750 

[TRAIN] Epoch[3](276/1500); Loss: 0.071656; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2334 0.1484 0.0902 0.0587 0.0815 0.0654 0.0485 0.0445 0.0470 0.0443 0.0452 0.0454 0.0473 0.0474 0.0499 0.0494 

[TRAIN] Epoch[3](277/1500); Loss: 0.118999; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1961 0.1565 0.1324 0.1195 0.1154 0.1119 0.1098 0.1087 0.1076 0.1072 0.1068 0.1065 0.1064 0.1063 0.1064 0.1066 

[TRAIN] Epoch[3](278/1500); Loss: 0.146199; Backpropagation: 0.0936 sec; Batch: 0.4350 sec
0.1988 0.1619 0.1588 0.1517 0.1454 0.1431 0.1416 0.1399 0.1389 0.1379 0.1370 0.1371 0.1368 0.1367 0.1368 0.1367 

[TRAIN] Epoch[3](279/1500); Loss: 0.135405; Backpropagation: 0.0938 sec; Batch: 0.4706 sec
0.2451 0.1711 0.1459 0.1336 0.1289 0.1257 0.1239 0.1230 0.1222 0.1209 0.1206 0.1205 0.1209 0.1209 0.1216 0.1217 

[TRAIN] Epoch[3](280/1500); Loss: 0.107216; Backpropagation: 0.0933 sec; Batch: 0.4302 sec
0.2190 0.1450 0.1223 0.1010 0.0979 0.0957 0.0943 0.0941 0.0932 0.0936 0.0932 0.0934 0.0930 0.0932 0.0931 0.0935 

[TRAIN] Epoch[3](281/1500); Loss: 0.047096; Backpropagation: 0.0938 sec; Batch: 0.4514 sec
0.0700 0.1139 0.0720 0.0384 0.0400 0.0366 0.0372 0.0371 0.0370 0.0368 0.0371 0.0382 0.0384 0.0394 0.0400 0.0413 

[TRAIN] Epoch[3](282/1500); Loss: 0.124916; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.3925 0.2794 0.2195 0.1693 0.1399 0.1200 0.0993 0.0806 0.0665 0.0607 0.0601 0.0612 0.0611 0.0628 0.0625 0.0632 

[TRAIN] Epoch[3](283/1500); Loss: 0.057381; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1574 0.0661 0.0589 0.0535 0.0499 0.0482 0.0477 0.0471 0.0487 0.0473 0.0481 0.0471 0.0488 0.0486 0.0503 0.0501 

[TRAIN] Epoch[3](284/1500); Loss: 0.121224; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1812 0.1377 0.1293 0.1218 0.1191 0.1154 0.1145 0.1136 0.1132 0.1133 0.1131 0.1133 0.1129 0.1135 0.1135 0.1141 

[TRAIN] Epoch[3](285/1500); Loss: 0.102643; Backpropagation: 0.0934 sec; Batch: 0.4289 sec
0.2519 0.1557 0.1176 0.0930 0.0902 0.0876 0.0848 0.0846 0.0840 0.0848 0.0842 0.0848 0.0843 0.0849 0.0846 0.0853 

[TRAIN] Epoch[3](286/1500); Loss: 0.083011; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1649 0.1087 0.0952 0.0849 0.0784 0.0763 0.0740 0.0743 0.0723 0.0728 0.0710 0.0718 0.0705 0.0713 0.0704 0.0714 

[TRAIN] Epoch[3](287/1500); Loss: 0.092444; Backpropagation: 0.0939 sec; Batch: 0.4458 sec
0.2028 0.1337 0.0981 0.0831 0.1048 0.0918 0.0784 0.0746 0.0754 0.0752 0.0758 0.0756 0.0768 0.0766 0.0782 0.0782 

[TRAIN] Epoch[3](288/1500); Loss: 0.145598; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1776 0.1600 0.1514 0.1452 0.1434 0.1428 0.1421 0.1418 0.1415 0.1408 0.1405 0.1403 0.1402 0.1404 0.1405 0.1413 

[TRAIN] Epoch[3](289/1500); Loss: 0.068070; Backpropagation: 0.0927 sec; Batch: 0.4267 sec
0.2230 0.1300 0.0944 0.0637 0.0519 0.0467 0.0469 0.0458 0.0473 0.0462 0.0480 0.0473 0.0491 0.0482 0.0506 0.0496 

[TRAIN] Epoch[3](290/1500); Loss: 0.129475; Backpropagation: 0.0932 sec; Batch: 0.4636 sec
0.1557 0.1523 0.1359 0.1364 0.1264 0.1268 0.1257 0.1265 0.1239 0.1247 0.1232 0.1241 0.1225 0.1231 0.1215 0.1227 

[TRAIN] Epoch[3](291/1500); Loss: 0.144052; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.2296 0.1760 0.1579 0.1452 0.1400 0.1367 0.1330 0.1323 0.1312 0.1319 0.1311 0.1321 0.1314 0.1324 0.1315 0.1324 

[TRAIN] Epoch[3](292/1500); Loss: 0.152301; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.2580 0.2093 0.1842 0.1626 0.1438 0.1412 0.1378 0.1366 0.1348 0.1342 0.1335 0.1330 0.1326 0.1320 0.1320 0.1315 

[TRAIN] Epoch[3](293/1500); Loss: 0.112509; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2248 0.1535 0.1267 0.1083 0.1021 0.1000 0.0995 0.0999 0.0990 0.0990 0.0981 0.0982 0.0978 0.0979 0.0976 0.0977 

[TRAIN] Epoch[3](294/1500); Loss: 0.192966; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2834 0.2217 0.2115 0.1943 0.1880 0.1863 0.1840 0.1823 0.1813 0.1806 0.1803 0.1796 0.1791 0.1787 0.1784 0.1779 

[TRAIN] Epoch[3](295/1500); Loss: 0.059808; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1291 0.0859 0.0714 0.0603 0.0572 0.0535 0.0520 0.0506 0.0498 0.0493 0.0497 0.0490 0.0498 0.0493 0.0501 0.0501 

[TRAIN] Epoch[3](296/1500); Loss: 0.118903; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2195 0.1566 0.1310 0.1157 0.1124 0.1097 0.1082 0.1067 0.1060 0.1054 0.1055 0.1050 0.1053 0.1048 0.1056 0.1051 

[TRAIN] Epoch[3](297/1500); Loss: 0.059133; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.1747 0.1061 0.0572 0.0530 0.0839 0.0674 0.0456 0.0406 0.0414 0.0398 0.0385 0.0386 0.0387 0.0395 0.0404 0.0406 

[TRAIN] Epoch[3](298/1500); Loss: 0.123060; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.2320 0.1719 0.1454 0.1226 0.1224 0.1145 0.1091 0.1070 0.1062 0.1055 0.1051 0.1050 0.1051 0.1054 0.1057 0.1062 

[TRAIN] Epoch[3](299/1500); Loss: 0.085810; Backpropagation: 0.0942 sec; Batch: 0.4288 sec
0.1751 0.1132 0.1006 0.0874 0.0808 0.0778 0.0763 0.0754 0.0743 0.0739 0.0734 0.0732 0.0730 0.0728 0.0729 0.0728 

[TRAIN] Epoch[3](300/1500); Loss: 0.147996; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2170 0.1731 0.1538 0.1411 0.1481 0.1415 0.1386 0.1380 0.1381 0.1383 0.1387 0.1393 0.1398 0.1401 0.1410 0.1414 

[TRAIN] Epoch[3](301/1500); Loss: 0.127347; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1948 0.1459 0.1340 0.1282 0.1236 0.1211 0.1202 0.1194 0.1190 0.1187 0.1186 0.1186 0.1188 0.1187 0.1190 0.1190 

[TRAIN] Epoch[3](302/1500); Loss: 0.081091; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1791 0.1003 0.0952 0.0821 0.0749 0.0718 0.0705 0.0698 0.0693 0.0692 0.0692 0.0689 0.0693 0.0688 0.0697 0.0692 

[TRAIN] Epoch[3](303/1500); Loss: 0.064898; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.1094 0.0720 0.0818 0.0650 0.0658 0.0611 0.0623 0.0588 0.0605 0.0576 0.0589 0.0566 0.0580 0.0562 0.0578 0.0565 

[TRAIN] Epoch[3](304/1500); Loss: 0.073208; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1994 0.1041 0.0765 0.0678 0.0628 0.0628 0.0613 0.0610 0.0594 0.0595 0.0592 0.0596 0.0593 0.0596 0.0596 0.0597 

[TRAIN] Epoch[3](305/1500); Loss: 0.102929; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1820 0.1308 0.1171 0.1045 0.0996 0.0983 0.0961 0.0957 0.0936 0.0930 0.0908 0.0907 0.0890 0.0893 0.0880 0.0884 

[TRAIN] Epoch[3](306/1500); Loss: 0.098633; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2125 0.1249 0.1091 0.0956 0.0926 0.0880 0.0875 0.0862 0.0861 0.0854 0.0850 0.0845 0.0848 0.0850 0.0855 0.0854 

[TRAIN] Epoch[3](307/1500); Loss: 0.092524; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1500 0.1077 0.1005 0.0934 0.0887 0.0869 0.0854 0.0862 0.0847 0.0853 0.0841 0.0855 0.0845 0.0857 0.0854 0.0863 

[TRAIN] Epoch[3](308/1500); Loss: 0.099492; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.1795 0.1253 0.1145 0.0988 0.0939 0.0932 0.0915 0.0910 0.0896 0.0890 0.0879 0.0879 0.0873 0.0874 0.0873 0.0879 

[TRAIN] Epoch[3](309/1500); Loss: 0.072349; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1037 0.0873 0.0771 0.0724 0.0713 0.0691 0.0686 0.0682 0.0675 0.0678 0.0671 0.0675 0.0671 0.0675 0.0675 0.0678 

[TRAIN] Epoch[3](310/1500); Loss: 0.041898; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1701 0.0974 0.0409 0.0255 0.0451 0.0323 0.0283 0.0230 0.0239 0.0241 0.0246 0.0242 0.0263 0.0267 0.0289 0.0290 

[TRAIN] Epoch[3](311/1500); Loss: 0.143373; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2292 0.1725 0.1547 0.1417 0.1380 0.1356 0.1345 0.1334 0.1333 0.1322 0.1320 0.1315 0.1316 0.1313 0.1313 0.1312 

[TRAIN] Epoch[3](312/1500); Loss: 0.049947; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1324 0.0739 0.0507 0.0433 0.0542 0.0434 0.0432 0.0390 0.0403 0.0389 0.0393 0.0387 0.0400 0.0396 0.0412 0.0410 

[TRAIN] Epoch[3](313/1500); Loss: 0.070866; Backpropagation: 0.0949 sec; Batch: 0.4290 sec
0.1927 0.1209 0.0872 0.0660 0.0583 0.0566 0.0557 0.0563 0.0553 0.0557 0.0542 0.0553 0.0544 0.0552 0.0545 0.0555 

[TRAIN] Epoch[3](314/1500); Loss: 0.064691; Backpropagation: 0.0948 sec; Batch: 0.4284 sec
0.0921 0.0865 0.0719 0.0623 0.0616 0.0603 0.0604 0.0599 0.0598 0.0597 0.0598 0.0598 0.0600 0.0602 0.0601 0.0606 

[TRAIN] Epoch[3](315/1500); Loss: 0.106283; Backpropagation: 0.0956 sec; Batch: 0.4295 sec
0.1872 0.1608 0.1258 0.1143 0.1004 0.0968 0.0940 0.0937 0.0920 0.0918 0.0908 0.0914 0.0905 0.0906 0.0900 0.0903 

[TRAIN] Epoch[3](316/1500); Loss: 0.116916; Backpropagation: 0.0952 sec; Batch: 0.4302 sec
0.2723 0.1810 0.1372 0.1052 0.1001 0.0983 0.0972 0.0970 0.0973 0.0972 0.0980 0.0978 0.0982 0.0978 0.0983 0.0976 

[TRAIN] Epoch[3](317/1500); Loss: 0.111763; Backpropagation: 0.0949 sec; Batch: 0.4294 sec
0.1775 0.1354 0.1212 0.1128 0.1050 0.1036 0.1026 0.1035 0.1027 0.1035 0.1027 0.1037 0.1031 0.1035 0.1033 0.1041 

[TRAIN] Epoch[3](318/1500); Loss: 0.081459; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1042 0.0906 0.0840 0.0830 0.0786 0.0786 0.0777 0.0784 0.0776 0.0782 0.0778 0.0785 0.0783 0.0792 0.0791 0.0799 

[TRAIN] Epoch[3](319/1500); Loss: 0.131787; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2246 0.1618 0.1465 0.1349 0.1261 0.1234 0.1215 0.1208 0.1196 0.1198 0.1187 0.1189 0.1179 0.1183 0.1177 0.1181 

[TRAIN] Epoch[3](320/1500); Loss: 0.133737; Backpropagation: 0.0942 sec; Batch: 0.4282 sec
0.2553 0.1874 0.1553 0.1318 0.1214 0.1211 0.1191 0.1183 0.1167 0.1176 0.1161 0.1167 0.1157 0.1162 0.1151 0.1159 

[TRAIN] Epoch[3](321/1500); Loss: 0.102805; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.3612 0.2310 0.1560 0.0915 0.0651 0.0687 0.0624 0.0670 0.0635 0.0729 0.0677 0.0685 0.0641 0.0691 0.0652 0.0710 

[TRAIN] Epoch[3](322/1500); Loss: 0.099717; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1786 0.1250 0.0957 0.0949 0.0912 0.0901 0.0902 0.0912 0.0903 0.0916 0.0905 0.0930 0.0919 0.0938 0.0930 0.0945 

[TRAIN] Epoch[3](323/1500); Loss: 0.071762; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.0996 0.0855 0.0940 0.0728 0.0692 0.0671 0.0657 0.0661 0.0660 0.0654 0.0656 0.0660 0.0653 0.0667 0.0657 0.0676 

[TRAIN] Epoch[3](324/1500); Loss: 0.076290; Backpropagation: 0.0935 sec; Batch: 0.4298 sec
0.1743 0.0966 0.0776 0.0714 0.0721 0.0704 0.0716 0.0703 0.0689 0.0669 0.0657 0.0643 0.0633 0.0624 0.0625 0.0623 

[TRAIN] Epoch[3](325/1500); Loss: 0.098670; Backpropagation: 0.0948 sec; Batch: 0.4284 sec
0.2383 0.1380 0.1006 0.0922 0.0879 0.0857 0.0837 0.0867 0.0840 0.0839 0.0816 0.0846 0.0824 0.0830 0.0815 0.0847 

[TRAIN] Epoch[3](326/1500); Loss: 0.127901; Backpropagation: 0.0936 sec; Batch: 0.4273 sec
0.2093 0.1474 0.1304 0.1236 0.1252 0.1208 0.1204 0.1202 0.1188 0.1191 0.1184 0.1183 0.1186 0.1184 0.1186 0.1190 

[TRAIN] Epoch[3](327/1500); Loss: 0.107107; Backpropagation: 0.0943 sec; Batch: 0.4284 sec
0.1393 0.1129 0.1114 0.1085 0.1047 0.1065 0.1046 0.1051 0.1032 0.1028 0.1011 0.1027 0.1018 0.1032 0.1023 0.1036 

[TRAIN] Epoch[3](328/1500); Loss: 0.127029; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1658 0.1394 0.1332 0.1275 0.1227 0.1232 0.1221 0.1230 0.1221 0.1225 0.1219 0.1220 0.1217 0.1217 0.1216 0.1220 

[TRAIN] Epoch[3](329/1500); Loss: 0.091265; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1618 0.1270 0.1069 0.0858 0.0830 0.0818 0.0808 0.0821 0.0803 0.0818 0.0803 0.0817 0.0810 0.0818 0.0813 0.0828 

[TRAIN] Epoch[3](330/1500); Loss: 0.107885; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1818 0.1200 0.1097 0.1053 0.1077 0.1016 0.1028 0.1010 0.1004 0.0984 0.1003 0.0989 0.0995 0.0985 0.1004 0.0998 

[TRAIN] Epoch[3](331/1500); Loss: 0.125832; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1895 0.1371 0.1269 0.1209 0.1193 0.1210 0.1199 0.1210 0.1197 0.1199 0.1189 0.1198 0.1192 0.1201 0.1198 0.1202 

[TRAIN] Epoch[3](332/1500); Loss: 0.063831; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.0876 0.0719 0.0607 0.0654 0.0581 0.0631 0.0617 0.0626 0.0602 0.0623 0.0605 0.0614 0.0601 0.0620 0.0611 0.0628 

[TRAIN] Epoch[3](333/1500); Loss: 0.132058; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2395 0.1673 0.1409 0.1309 0.1221 0.1213 0.1195 0.1206 0.1193 0.1193 0.1180 0.1191 0.1181 0.1194 0.1187 0.1191 

[TRAIN] Epoch[3](334/1500); Loss: 0.071958; Backpropagation: 0.0948 sec; Batch: 0.4291 sec
0.1971 0.1234 0.0784 0.0666 0.0590 0.0587 0.0558 0.0593 0.0565 0.0580 0.0553 0.0568 0.0544 0.0582 0.0562 0.0578 

[TRAIN] Epoch[3](335/1500); Loss: 0.115895; Backpropagation: 0.0947 sec; Batch: 0.4287 sec
0.1615 0.1447 0.1264 0.1172 0.1136 0.1105 0.1100 0.1085 0.1091 0.1073 0.1078 0.1070 0.1076 0.1071 0.1084 0.1079 

[TRAIN] Epoch[3](336/1500); Loss: 0.079449; Backpropagation: 0.0948 sec; Batch: 0.4284 sec
0.1203 0.0978 0.0827 0.0816 0.0761 0.0768 0.0753 0.0748 0.0732 0.0739 0.0726 0.0733 0.0726 0.0735 0.0731 0.0736 

[TRAIN] Epoch[3](337/1500); Loss: 0.091059; Backpropagation: 0.0949 sec; Batch: 0.4292 sec
0.1291 0.1062 0.0957 0.0922 0.0868 0.0880 0.0860 0.0871 0.0851 0.0865 0.0851 0.0864 0.0850 0.0861 0.0853 0.0864 

[TRAIN] Epoch[3](338/1500); Loss: 0.072156; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1104 0.1021 0.0798 0.0718 0.0695 0.0661 0.0663 0.0649 0.0654 0.0647 0.0651 0.0646 0.0656 0.0652 0.0665 0.0664 

[TRAIN] Epoch[3](339/1500); Loss: 0.104483; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.2397 0.1504 0.1129 0.0972 0.0947 0.0904 0.0914 0.0896 0.0896 0.0882 0.0881 0.0872 0.0883 0.0875 0.0888 0.0878 

[TRAIN] Epoch[3](340/1500); Loss: 0.065431; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1175 0.0811 0.0669 0.0687 0.0602 0.0613 0.0582 0.0607 0.0582 0.0598 0.0573 0.0599 0.0576 0.0602 0.0585 0.0606 

[TRAIN] Epoch[3](341/1500); Loss: 0.150448; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2646 0.2220 0.2015 0.1814 0.1479 0.1372 0.1297 0.1271 0.1256 0.1254 0.1241 0.1244 0.1236 0.1245 0.1238 0.1243 

[TRAIN] Epoch[3](342/1500); Loss: 0.073934; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.1763 0.1109 0.0775 0.0671 0.0615 0.0627 0.0607 0.0643 0.0617 0.0639 0.0616 0.0628 0.0611 0.0636 0.0623 0.0649 

[TRAIN] Epoch[3](343/1500); Loss: 0.097641; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2889 0.1784 0.1294 0.0958 0.0836 0.0749 0.0713 0.0711 0.0693 0.0707 0.0696 0.0707 0.0705 0.0721 0.0722 0.0737 

[TRAIN] Epoch[3](344/1500); Loss: 0.087611; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.2787 0.1710 0.1251 0.0935 0.0732 0.0646 0.0599 0.0598 0.0596 0.0594 0.0593 0.0593 0.0593 0.0593 0.0597 0.0600 

[TRAIN] Epoch[3](345/1500); Loss: 0.099603; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1648 0.1268 0.1137 0.0969 0.0886 0.0885 0.0888 0.0895 0.0900 0.0902 0.0908 0.0917 0.0918 0.0932 0.0936 0.0946 

[TRAIN] Epoch[3](346/1500); Loss: 0.052273; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1345 0.0550 0.0560 0.0465 0.0477 0.0487 0.0446 0.0445 0.0439 0.0450 0.0436 0.0445 0.0445 0.0455 0.0448 0.0471 

[TRAIN] Epoch[3](347/1500); Loss: 0.105195; Backpropagation: 0.0952 sec; Batch: 0.4296 sec
0.1675 0.1303 0.1125 0.1095 0.1021 0.1014 0.0988 0.0978 0.0958 0.0963 0.0949 0.0955 0.0950 0.0954 0.0948 0.0954 

[TRAIN] Epoch[3](348/1500); Loss: 0.068176; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.2659 0.1097 0.0731 0.0516 0.0559 0.0489 0.0456 0.0483 0.0452 0.0514 0.0479 0.0482 0.0463 0.0516 0.0489 0.0522 

[TRAIN] Epoch[3](349/1500); Loss: 0.105558; Backpropagation: 0.0949 sec; Batch: 0.4290 sec
0.2166 0.1490 0.1171 0.0967 0.0960 0.0934 0.0936 0.0930 0.0920 0.0919 0.0911 0.0916 0.0915 0.0917 0.0917 0.0920 

[TRAIN] Epoch[3](350/1500); Loss: 0.072252; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.2007 0.1256 0.0769 0.0579 0.0593 0.0563 0.0567 0.0564 0.0574 0.0577 0.0576 0.0574 0.0580 0.0589 0.0588 0.0604 

[TRAIN] Epoch[3](351/1500); Loss: 0.066410; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1269 0.0853 0.0715 0.0678 0.0621 0.0616 0.0597 0.0604 0.0586 0.0586 0.0575 0.0592 0.0580 0.0585 0.0580 0.0587 

[TRAIN] Epoch[3](352/1500); Loss: 0.147422; Backpropagation: 0.0938 sec; Batch: 0.4275 sec
0.2208 0.1672 0.1538 0.1462 0.1414 0.1415 0.1403 0.1402 0.1394 0.1390 0.1385 0.1384 0.1383 0.1380 0.1378 0.1382 

[TRAIN] Epoch[3](353/1500); Loss: 0.096544; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1976 0.1316 0.0980 0.0930 0.0884 0.0856 0.0836 0.0850 0.0832 0.0844 0.0835 0.0853 0.0848 0.0859 0.0868 0.0880 

[TRAIN] Epoch[3](354/1500); Loss: 0.096402; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.4232 0.2444 0.1317 0.0488 0.0749 0.0486 0.0620 0.0565 0.0549 0.0505 0.0597 0.0547 0.0581 0.0546 0.0619 0.0579 

[TRAIN] Epoch[3](355/1500); Loss: 0.100624; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1741 0.1325 0.1082 0.0987 0.0958 0.0929 0.0922 0.0906 0.0909 0.0898 0.0913 0.0901 0.0913 0.0901 0.0911 0.0903 

[TRAIN] Epoch[3](356/1500); Loss: 0.051591; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1146 0.0729 0.0602 0.0551 0.0483 0.0457 0.0426 0.0430 0.0404 0.0426 0.0406 0.0436 0.0421 0.0442 0.0440 0.0457 

[TRAIN] Epoch[3](357/1500); Loss: 0.108241; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2765 0.1576 0.1116 0.0964 0.0940 0.0934 0.0911 0.0926 0.0908 0.0910 0.0888 0.0909 0.0893 0.0896 0.0881 0.0901 

[TRAIN] Epoch[3](358/1500); Loss: 0.076481; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1193 0.1018 0.0834 0.0744 0.0758 0.0719 0.0712 0.0693 0.0701 0.0689 0.0701 0.0689 0.0701 0.0691 0.0699 0.0695 

[TRAIN] Epoch[3](359/1500); Loss: 0.063838; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1360 0.0830 0.0645 0.0656 0.0591 0.0591 0.0573 0.0576 0.0554 0.0554 0.0544 0.0545 0.0545 0.0547 0.0548 0.0556 

[TRAIN] Epoch[3](360/1500); Loss: 0.125735; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.1687 0.1490 0.1370 0.1313 0.1248 0.1229 0.1213 0.1192 0.1184 0.1176 0.1173 0.1170 0.1168 0.1167 0.1168 0.1169 

[TRAIN] Epoch[3](361/1500); Loss: 0.111209; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1829 0.1309 0.1115 0.1083 0.1052 0.1041 0.1037 0.1035 0.1034 0.1032 0.1035 0.1035 0.1037 0.1039 0.1040 0.1042 

[TRAIN] Epoch[3](362/1500); Loss: 0.082255; Backpropagation: 0.0956 sec; Batch: 0.4300 sec
0.1697 0.0929 0.0853 0.0775 0.0770 0.0763 0.0744 0.0735 0.0731 0.0731 0.0739 0.0733 0.0744 0.0734 0.0742 0.0741 

[TRAIN] Epoch[3](363/1500); Loss: 0.056853; Backpropagation: 0.0954 sec; Batch: 0.4299 sec
0.1864 0.1102 0.0584 0.0416 0.0519 0.0432 0.0429 0.0413 0.0411 0.0420 0.0407 0.0423 0.0402 0.0424 0.0411 0.0439 

[TRAIN] Epoch[3](364/1500); Loss: 0.145855; Backpropagation: 0.0949 sec; Batch: 0.4284 sec
0.1718 0.1592 0.1511 0.1450 0.1435 0.1430 0.1425 0.1421 0.1416 0.1413 0.1418 0.1420 0.1420 0.1420 0.1421 0.1425 

[TRAIN] Epoch[3](365/1500); Loss: 0.077954; Backpropagation: 0.0950 sec; Batch: 0.4294 sec
0.2091 0.1478 0.1102 0.0873 0.0637 0.0609 0.0589 0.0593 0.0572 0.0565 0.0554 0.0560 0.0553 0.0560 0.0562 0.0575 

[TRAIN] Epoch[3](366/1500); Loss: 0.158946; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2537 0.2055 0.1815 0.1608 0.1506 0.1490 0.1474 0.1463 0.1458 0.1448 0.1439 0.1435 0.1431 0.1427 0.1423 0.1423 

[TRAIN] Epoch[3](367/1500); Loss: 0.101023; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.3334 0.1779 0.1043 0.0811 0.0797 0.0778 0.0769 0.0775 0.0766 0.0753 0.0762 0.0757 0.0758 0.0756 0.0762 0.0765 

[TRAIN] Epoch[3](368/1500); Loss: 0.121880; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2726 0.1930 0.1553 0.1266 0.1065 0.1022 0.1005 0.1006 0.0995 0.0990 0.0984 0.0992 0.0989 0.0993 0.0992 0.0994 

[TRAIN] Epoch[3](369/1500); Loss: 0.083097; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1188 0.1007 0.0873 0.0860 0.0823 0.0803 0.0786 0.0781 0.0771 0.0771 0.0767 0.0771 0.0772 0.0776 0.0772 0.0776 

[TRAIN] Epoch[3](370/1500); Loss: 0.051561; Backpropagation: 0.0933 sec; Batch: 0.4266 sec
0.0826 0.0813 0.0599 0.0531 0.0481 0.0468 0.0453 0.0449 0.0443 0.0448 0.0449 0.0451 0.0449 0.0461 0.0462 0.0467 

[TRAIN] Epoch[3](371/1500); Loss: 0.104761; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1776 0.1402 0.1121 0.1025 0.0997 0.0970 0.0957 0.0950 0.0944 0.0936 0.0947 0.0940 0.0951 0.0944 0.0955 0.0947 

[TRAIN] Epoch[3](372/1500); Loss: 0.133486; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2935 0.2034 0.1623 0.1322 0.1217 0.1146 0.1119 0.1104 0.1101 0.1098 0.1101 0.1104 0.1108 0.1113 0.1112 0.1119 

[TRAIN] Epoch[3](373/1500); Loss: 0.113718; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2222 0.1617 0.1307 0.1114 0.1086 0.0994 0.0996 0.0998 0.0985 0.0987 0.0981 0.0980 0.0977 0.0982 0.0983 0.0987 

[TRAIN] Epoch[3](374/1500); Loss: 0.051902; Backpropagation: 0.0943 sec; Batch: 0.4279 sec
0.1496 0.0565 0.0554 0.0533 0.0446 0.0488 0.0443 0.0435 0.0406 0.0432 0.0404 0.0438 0.0416 0.0416 0.0404 0.0427 

[TRAIN] Epoch[3](375/1500); Loss: 0.085312; Backpropagation: 0.0942 sec; Batch: 0.4347 sec
0.1335 0.1170 0.0890 0.0841 0.0822 0.0806 0.0798 0.0784 0.0787 0.0780 0.0776 0.0772 0.0772 0.0771 0.0776 0.0772 

[TRAIN] Epoch[3](376/1500); Loss: 0.114259; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1481 0.1323 0.1216 0.1186 0.1126 0.1114 0.1097 0.1085 0.1080 0.1079 0.1078 0.1080 0.1081 0.1083 0.1085 0.1087 

[TRAIN] Epoch[3](377/1500); Loss: 0.059522; Backpropagation: 0.0936 sec; Batch: 0.4273 sec
0.0790 0.0782 0.0637 0.0610 0.0560 0.0568 0.0554 0.0554 0.0549 0.0551 0.0550 0.0558 0.0559 0.0564 0.0565 0.0573 

[TRAIN] Epoch[3](378/1500); Loss: 0.084483; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1711 0.1026 0.0876 0.0824 0.0785 0.0773 0.0766 0.0766 0.0757 0.0752 0.0744 0.0752 0.0745 0.0747 0.0745 0.0749 

[TRAIN] Epoch[3](379/1500); Loss: 0.097514; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2757 0.1717 0.1269 0.0908 0.0823 0.0784 0.0767 0.0756 0.0740 0.0726 0.0726 0.0720 0.0727 0.0722 0.0730 0.0731 

[TRAIN] Epoch[3](380/1500); Loss: 0.082424; Backpropagation: 0.0936 sec; Batch: 0.4273 sec
0.2175 0.1370 0.0990 0.0728 0.0673 0.0659 0.0648 0.0643 0.0656 0.0659 0.0654 0.0657 0.0661 0.0672 0.0665 0.0676 

[TRAIN] Epoch[3](381/1500); Loss: 0.164901; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2550 0.1872 0.1735 0.1600 0.1580 0.1570 0.1565 0.1562 0.1557 0.1550 0.1548 0.1546 0.1539 0.1542 0.1533 0.1536 

[TRAIN] Epoch[3](382/1500); Loss: 0.096375; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.2093 0.1498 0.1169 0.0926 0.0860 0.0831 0.0830 0.0819 0.0803 0.0794 0.0800 0.0796 0.0798 0.0793 0.0806 0.0804 

[TRAIN] Epoch[3](383/1500); Loss: 0.070577; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1234 0.0948 0.0756 0.0709 0.0668 0.0649 0.0639 0.0632 0.0631 0.0627 0.0630 0.0632 0.0632 0.0634 0.0633 0.0637 

[TRAIN] Epoch[3](384/1500); Loss: 0.149093; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.3050 0.2323 0.1875 0.1587 0.1276 0.1218 0.1224 0.1264 0.1248 0.1250 0.1240 0.1252 0.1247 0.1267 0.1262 0.1272 

[TRAIN] Epoch[3](385/1500); Loss: 0.101514; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.2165 0.1382 0.1084 0.0951 0.0923 0.0907 0.0899 0.0890 0.0886 0.0880 0.0881 0.0880 0.0880 0.0879 0.0878 0.0879 

[TRAIN] Epoch[3](386/1500); Loss: 0.086882; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.2418 0.1528 0.1086 0.0797 0.0719 0.0696 0.0688 0.0689 0.0676 0.0674 0.0659 0.0661 0.0649 0.0660 0.0648 0.0654 

[TRAIN] Epoch[3](387/1500); Loss: 0.071921; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.0852 0.0767 0.0836 0.0722 0.0712 0.0702 0.0699 0.0696 0.0692 0.0691 0.0690 0.0691 0.0689 0.0689 0.0689 0.0691 

[TRAIN] Epoch[3](388/1500); Loss: 0.143272; Backpropagation: 0.0934 sec; Batch: 0.4264 sec
0.1880 0.1595 0.1544 0.1480 0.1422 0.1404 0.1385 0.1368 0.1361 0.1357 0.1355 0.1354 0.1352 0.1353 0.1356 0.1357 

[TRAIN] Epoch[3](389/1500); Loss: 0.079227; Backpropagation: 0.0946 sec; Batch: 0.4319 sec
0.1213 0.0908 0.0821 0.0806 0.0766 0.0757 0.0747 0.0742 0.0739 0.0739 0.0738 0.0737 0.0738 0.0739 0.0743 0.0743 

[TRAIN] Epoch[3](390/1500); Loss: 0.074267; Backpropagation: 0.0938 sec; Batch: 0.4351 sec
0.2292 0.1174 0.0788 0.0649 0.0607 0.0597 0.0586 0.0590 0.0577 0.0573 0.0576 0.0577 0.0569 0.0574 0.0572 0.0582 

[TRAIN] Epoch[3](391/1500); Loss: 0.139279; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.2382 0.1850 0.1636 0.1495 0.1336 0.1283 0.1259 0.1248 0.1238 0.1230 0.1225 0.1223 0.1222 0.1221 0.1217 0.1220 

[TRAIN] Epoch[3](392/1500); Loss: 0.079492; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1892 0.1138 0.0846 0.0750 0.0721 0.0681 0.0672 0.0677 0.0668 0.0670 0.0662 0.0665 0.0665 0.0670 0.0669 0.0672 

[TRAIN] Epoch[3](393/1500); Loss: 0.073274; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1066 0.0959 0.0724 0.0743 0.0715 0.0686 0.0678 0.0683 0.0669 0.0681 0.0673 0.0686 0.0681 0.0693 0.0687 0.0700 

[TRAIN] Epoch[3](394/1500); Loss: 0.090030; Backpropagation: 0.0934 sec; Batch: 0.4291 sec
0.1896 0.1137 0.0982 0.0851 0.0810 0.0802 0.0795 0.0790 0.0788 0.0786 0.0791 0.0790 0.0792 0.0792 0.0799 0.0802 

[TRAIN] Epoch[3](395/1500); Loss: 0.046839; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.0906 0.0612 0.0486 0.0444 0.0419 0.0428 0.0414 0.0417 0.0407 0.0412 0.0410 0.0419 0.0420 0.0428 0.0431 0.0441 

[TRAIN] Epoch[3](396/1500); Loss: 0.124600; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2285 0.1539 0.1337 0.1258 0.1178 0.1150 0.1136 0.1126 0.1121 0.1118 0.1116 0.1116 0.1116 0.1114 0.1113 0.1113 

[TRAIN] Epoch[3](397/1500); Loss: 0.082456; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1051 0.0891 0.0843 0.0821 0.0812 0.0800 0.0799 0.0796 0.0797 0.0796 0.0796 0.0795 0.0798 0.0797 0.0800 0.0800 

[TRAIN] Epoch[3](398/1500); Loss: 0.163312; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2658 0.1929 0.1744 0.1607 0.1561 0.1551 0.1531 0.1521 0.1514 0.1507 0.1502 0.1499 0.1505 0.1499 0.1500 0.1502 

[TRAIN] Epoch[3](399/1500); Loss: 0.119708; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2197 0.1480 0.1280 0.1206 0.1127 0.1112 0.1094 0.1083 0.1075 0.1075 0.1068 0.1074 0.1071 0.1071 0.1070 0.1070 

[TRAIN] Epoch[3](400/1500); Loss: 0.082990; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1626 0.1052 0.0891 0.0838 0.0791 0.0768 0.0755 0.0746 0.0738 0.0730 0.0724 0.0723 0.0724 0.0724 0.0724 0.0724 

[TRAIN] Epoch[3](401/1500); Loss: 0.078832; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.3257 0.2188 0.1448 0.0863 0.0797 0.0374 0.0420 0.0308 0.0356 0.0324 0.0403 0.0362 0.0361 0.0358 0.0404 0.0390 

[TRAIN] Epoch[3](402/1500); Loss: 0.060022; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.0985 0.0853 0.0653 0.0644 0.0589 0.0571 0.0557 0.0540 0.0537 0.0526 0.0539 0.0524 0.0531 0.0515 0.0525 0.0513 

[TRAIN] Epoch[3](403/1500); Loss: 0.079830; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.2382 0.1435 0.1009 0.0797 0.0637 0.0605 0.0607 0.0596 0.0587 0.0587 0.0584 0.0585 0.0586 0.0590 0.0592 0.0593 

[TRAIN] Epoch[3](404/1500); Loss: 0.056078; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1288 0.0721 0.0686 0.0588 0.0550 0.0546 0.0511 0.0496 0.0472 0.0460 0.0453 0.0450 0.0441 0.0441 0.0434 0.0437 

[TRAIN] Epoch[3](405/1500); Loss: 0.124247; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2287 0.1602 0.1391 0.1228 0.1153 0.1142 0.1126 0.1120 0.1111 0.1107 0.1104 0.1102 0.1100 0.1101 0.1100 0.1105 

[TRAIN] Epoch[3](406/1500); Loss: 0.108012; Backpropagation: 0.0931 sec; Batch: 0.4263 sec
0.1764 0.1304 0.1182 0.1047 0.1031 0.1010 0.1000 0.0994 0.0993 0.0993 0.0995 0.0993 0.0993 0.0992 0.0996 0.0996 

[TRAIN] Epoch[3](407/1500); Loss: 0.126313; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2216 0.1571 0.1315 0.1242 0.1218 0.1182 0.1175 0.1165 0.1158 0.1147 0.1147 0.1143 0.1141 0.1133 0.1129 0.1128 

[TRAIN] Epoch[3](408/1500); Loss: 0.158149; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2378 0.1888 0.1682 0.1547 0.1498 0.1481 0.1477 0.1478 0.1478 0.1478 0.1480 0.1483 0.1483 0.1487 0.1491 0.1493 

[TRAIN] Epoch[3](409/1500); Loss: 0.092003; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1675 0.1183 0.1035 0.0908 0.0866 0.0829 0.0828 0.0830 0.0826 0.0823 0.0821 0.0817 0.0818 0.0817 0.0824 0.0820 

[TRAIN] Epoch[3](410/1500); Loss: 0.078948; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1160 0.1076 0.0849 0.0812 0.0753 0.0746 0.0734 0.0728 0.0724 0.0726 0.0715 0.0720 0.0716 0.0726 0.0718 0.0730 

[TRAIN] Epoch[3](411/1500); Loss: 0.105198; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.2170 0.1284 0.1045 0.0961 0.0982 0.0959 0.0951 0.0949 0.0944 0.0941 0.0939 0.0943 0.0940 0.0942 0.0942 0.0941 

[TRAIN] Epoch[3](412/1500); Loss: 0.058276; Backpropagation: 0.0938 sec; Batch: 0.4270 sec
0.1605 0.0780 0.0663 0.0578 0.0558 0.0519 0.0498 0.0490 0.0471 0.0463 0.0455 0.0451 0.0447 0.0448 0.0448 0.0451 

[TRAIN] Epoch[3](413/1500); Loss: 0.103407; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1769 0.1205 0.1071 0.0984 0.0948 0.0940 0.0936 0.0936 0.0941 0.0945 0.0953 0.0962 0.0971 0.0983 0.0995 0.1007 

[TRAIN] Epoch[3](414/1500); Loss: 0.100509; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.2995 0.2034 0.1331 0.0827 0.1211 0.0976 0.0671 0.0710 0.0629 0.0645 0.0637 0.0668 0.0662 0.0683 0.0689 0.0713 

[TRAIN] Epoch[3](415/1500); Loss: 0.102912; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1374 0.1177 0.1062 0.1025 0.1003 0.0992 0.0989 0.0991 0.0987 0.0985 0.0984 0.0979 0.0982 0.0979 0.0980 0.0977 

[TRAIN] Epoch[3](416/1500); Loss: 0.182282; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2603 0.2145 0.1987 0.1805 0.1782 0.1751 0.1731 0.1722 0.1715 0.1712 0.1708 0.1701 0.1703 0.1704 0.1697 0.1697 

[TRAIN] Epoch[3](417/1500); Loss: 0.049309; Backpropagation: 0.0934 sec; Batch: 0.4342 sec
0.1228 0.0660 0.0579 0.0462 0.0482 0.0434 0.0424 0.0406 0.0402 0.0394 0.0401 0.0393 0.0400 0.0400 0.0413 0.0412 

[TRAIN] Epoch[3](418/1500); Loss: 0.074643; Backpropagation: 0.0931 sec; Batch: 0.4266 sec
0.3726 0.1881 0.0852 0.0479 0.0494 0.0396 0.0421 0.0401 0.0416 0.0382 0.0427 0.0392 0.0422 0.0398 0.0439 0.0416 

[TRAIN] Epoch[3](419/1500); Loss: 0.072364; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1660 0.0852 0.0791 0.0696 0.0651 0.0645 0.0633 0.0635 0.0628 0.0629 0.0622 0.0627 0.0623 0.0629 0.0625 0.0632 

[TRAIN] Epoch[3](420/1500); Loss: 0.075798; Backpropagation: 0.0938 sec; Batch: 0.4407 sec
0.4158 0.2313 0.1120 0.0306 0.0543 0.0302 0.0360 0.0324 0.0329 0.0296 0.0351 0.0317 0.0347 0.0324 0.0378 0.0359 

[TRAIN] Epoch[3](421/1500); Loss: 0.105704; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1341 0.1266 0.1127 0.1051 0.1045 0.1024 0.1017 0.1011 0.1007 0.1005 0.1002 0.1000 0.1002 0.1002 0.1006 0.1007 

[TRAIN] Epoch[3](422/1500); Loss: 0.193004; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2368 0.2102 0.2039 0.1928 0.1921 0.1898 0.1889 0.1880 0.1874 0.1868 0.1863 0.1858 0.1854 0.1851 0.1848 0.1840 

[TRAIN] Epoch[3](423/1500); Loss: 0.139339; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1867 0.1572 0.1456 0.1363 0.1346 0.1336 0.1335 0.1331 0.1332 0.1331 0.1333 0.1331 0.1334 0.1337 0.1342 0.1346 

[TRAIN] Epoch[3](424/1500); Loss: 0.093780; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2482 0.1451 0.0970 0.0928 0.0796 0.0807 0.0765 0.0770 0.0747 0.0763 0.0745 0.0758 0.0745 0.0765 0.0750 0.0762 

[TRAIN] Epoch[3](425/1500); Loss: 0.072199; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1520 0.1019 0.0774 0.0694 0.0667 0.0648 0.0625 0.0634 0.0613 0.0629 0.0612 0.0624 0.0612 0.0629 0.0618 0.0632 

[TRAIN] Epoch[3](426/1500); Loss: 0.111290; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.2052 0.1366 0.1109 0.1090 0.1018 0.1036 0.1014 0.1011 0.1003 0.1007 0.1006 0.1012 0.1013 0.1022 0.1022 0.1027 

[TRAIN] Epoch[3](427/1500); Loss: 0.113832; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2446 0.1612 0.1234 0.1144 0.1032 0.1024 0.0986 0.0979 0.0967 0.0973 0.0962 0.0971 0.0963 0.0970 0.0970 0.0979 

[TRAIN] Epoch[3](428/1500); Loss: 0.114055; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1650 0.1528 0.1322 0.1096 0.1099 0.1069 0.1058 0.1048 0.1047 0.1043 0.1045 0.1043 0.1046 0.1047 0.1053 0.1055 

[TRAIN] Epoch[3](429/1500); Loss: 0.117295; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1512 0.1394 0.1195 0.1147 0.1147 0.1128 0.1132 0.1122 0.1122 0.1115 0.1124 0.1122 0.1125 0.1122 0.1131 0.1130 

[TRAIN] Epoch[3](430/1500); Loss: 0.090911; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1561 0.1088 0.0953 0.0943 0.0866 0.0855 0.0843 0.0840 0.0831 0.0829 0.0823 0.0826 0.0821 0.0826 0.0820 0.0822 

[TRAIN] Epoch[3](431/1500); Loss: 0.047466; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.0655 0.0601 0.0540 0.0464 0.0465 0.0433 0.0438 0.0429 0.0438 0.0433 0.0445 0.0439 0.0451 0.0448 0.0458 0.0457 

[TRAIN] Epoch[3](432/1500); Loss: 0.098631; Backpropagation: 0.0940 sec; Batch: 0.4293 sec
0.1909 0.1250 0.0986 0.0968 0.0906 0.0902 0.0884 0.0882 0.0878 0.0882 0.0878 0.0884 0.0883 0.0893 0.0892 0.0903 

[TRAIN] Epoch[3](433/1500); Loss: 0.152616; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.2352 0.1863 0.1639 0.1464 0.1465 0.1425 0.1419 0.1413 0.1413 0.1414 0.1417 0.1417 0.1420 0.1426 0.1432 0.1438 

[TRAIN] Epoch[3](434/1500); Loss: 0.074550; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1751 0.0830 0.0705 0.0617 0.0653 0.0615 0.0619 0.0614 0.0630 0.0633 0.0661 0.0668 0.0703 0.0713 0.0751 0.0765 

[TRAIN] Epoch[3](435/1500); Loss: 0.085608; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1087 0.1138 0.0932 0.0859 0.0823 0.0793 0.0790 0.0785 0.0808 0.0789 0.0816 0.0799 0.0815 0.0806 0.0834 0.0823 

[TRAIN] Epoch[3](436/1500); Loss: 0.081005; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2080 0.1224 0.0904 0.0787 0.0717 0.0687 0.0671 0.0657 0.0660 0.0647 0.0654 0.0647 0.0660 0.0652 0.0660 0.0656 

[TRAIN] Epoch[3](437/1500); Loss: 0.090459; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2009 0.1140 0.0926 0.0904 0.0828 0.0814 0.0794 0.0782 0.0777 0.0788 0.0774 0.0780 0.0784 0.0790 0.0788 0.0795 

[TRAIN] Epoch[3](438/1500); Loss: 0.127052; Backpropagation: 0.0944 sec; Batch: 0.4285 sec
0.1668 0.1312 0.1440 0.1291 0.1235 0.1235 0.1216 0.1217 0.1204 0.1214 0.1206 0.1216 0.1209 0.1222 0.1217 0.1229 

[TRAIN] Epoch[3](439/1500); Loss: 0.047884; Backpropagation: 0.0942 sec; Batch: 0.4315 sec
0.0525 0.0661 0.0702 0.0451 0.0523 0.0419 0.0440 0.0410 0.0446 0.0413 0.0447 0.0420 0.0454 0.0433 0.0468 0.0448 

[TRAIN] Epoch[3](440/1500); Loss: 0.095389; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1207 0.1080 0.0989 0.0967 0.0940 0.0929 0.0923 0.0918 0.0917 0.0916 0.0913 0.0914 0.0912 0.0912 0.0912 0.0914 

[TRAIN] Epoch[3](441/1500); Loss: 0.077193; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.3082 0.1976 0.1088 0.0470 0.0728 0.0539 0.0427 0.0436 0.0428 0.0426 0.0430 0.0448 0.0450 0.0465 0.0460 0.0497 

[TRAIN] Epoch[3](442/1500); Loss: 0.128176; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2156 0.1542 0.1365 0.1243 0.1218 0.1187 0.1190 0.1178 0.1182 0.1174 0.1180 0.1174 0.1180 0.1175 0.1184 0.1180 

[TRAIN] Epoch[3](443/1500); Loss: 0.116897; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1811 0.1419 0.1222 0.1146 0.1115 0.1103 0.1098 0.1089 0.1087 0.1087 0.1081 0.1084 0.1084 0.1090 0.1090 0.1095 

[TRAIN] Epoch[3](444/1500); Loss: 0.073945; Backpropagation: 0.0934 sec; Batch: 0.4267 sec
0.1150 0.0776 0.0818 0.0755 0.0716 0.0700 0.0693 0.0689 0.0688 0.0686 0.0689 0.0686 0.0692 0.0693 0.0702 0.0700 

[TRAIN] Epoch[3](445/1500); Loss: 0.090425; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1774 0.1093 0.0979 0.0937 0.0844 0.0850 0.0824 0.0812 0.0793 0.0800 0.0788 0.0794 0.0787 0.0799 0.0791 0.0803 

[TRAIN] Epoch[3](446/1500); Loss: 0.141341; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.1977 0.1703 0.1597 0.1394 0.1383 0.1349 0.1348 0.1336 0.1329 0.1315 0.1316 0.1315 0.1316 0.1311 0.1316 0.1311 

[TRAIN] Epoch[3](447/1500); Loss: 0.046863; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.0790 0.0669 0.0483 0.0482 0.0421 0.0433 0.0407 0.0415 0.0402 0.0416 0.0408 0.0428 0.0422 0.0436 0.0435 0.0452 

[TRAIN] Epoch[3](448/1500); Loss: 0.070148; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1497 0.0963 0.0763 0.0777 0.0661 0.0631 0.0620 0.0601 0.0602 0.0589 0.0594 0.0587 0.0586 0.0581 0.0587 0.0584 

[TRAIN] Epoch[3](449/1500); Loss: 0.107084; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2422 0.1471 0.1069 0.1036 0.0971 0.0936 0.0938 0.0924 0.0931 0.0915 0.0926 0.0914 0.0920 0.0915 0.0927 0.0918 

[TRAIN] Epoch[3](450/1500); Loss: 0.126459; Backpropagation: 0.0981 sec; Batch: 0.4331 sec
0.1782 0.1439 0.1337 0.1246 0.1226 0.1215 0.1207 0.1200 0.1196 0.1193 0.1194 0.1195 0.1195 0.1198 0.1203 0.1209 

[TRAIN] Epoch[3](451/1500); Loss: 0.133345; Backpropagation: 0.0959 sec; Batch: 0.4305 sec
0.1821 0.1529 0.1498 0.1342 0.1306 0.1280 0.1264 0.1255 0.1253 0.1253 0.1250 0.1250 0.1252 0.1255 0.1259 0.1266 

[TRAIN] Epoch[3](452/1500); Loss: 0.106399; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1909 0.1268 0.1211 0.1211 0.1042 0.0971 0.0967 0.0948 0.0955 0.0933 0.0935 0.0926 0.0931 0.0936 0.0936 0.0942 

[TRAIN] Epoch[3](453/1500); Loss: 0.125499; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2453 0.1518 0.1295 0.1392 0.1190 0.1154 0.1139 0.1118 0.1117 0.1109 0.1103 0.1103 0.1099 0.1099 0.1094 0.1095 

[TRAIN] Epoch[3](454/1500); Loss: 0.181151; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2907 0.2216 0.2019 0.1757 0.1686 0.1677 0.1676 0.1666 0.1678 0.1670 0.1678 0.1665 0.1668 0.1670 0.1677 0.1674 

[TRAIN] Epoch[3](455/1500); Loss: 0.130797; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.3638 0.1964 0.1258 0.1343 0.1218 0.1143 0.1144 0.1074 0.1040 0.1028 0.1015 0.1011 0.1009 0.1012 0.1016 0.1013 

[TRAIN] Epoch[3](456/1500); Loss: 0.115108; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1745 0.1358 0.1322 0.1174 0.1105 0.1091 0.1077 0.1076 0.1061 0.1061 0.1054 0.1056 0.1051 0.1060 0.1059 0.1068 

[TRAIN] Epoch[3](457/1500); Loss: 0.088650; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.3951 0.1774 0.0770 0.0984 0.0797 0.0676 0.0680 0.0566 0.0517 0.0499 0.0493 0.0500 0.0493 0.0495 0.0486 0.0503 

[TRAIN] Epoch[3](458/1500); Loss: 0.098866; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1226 0.1003 0.1047 0.0950 0.0958 0.0946 0.0953 0.0951 0.0954 0.0957 0.0963 0.0967 0.0975 0.0981 0.0990 0.0997 

[TRAIN] Epoch[3](459/1500); Loss: 0.145077; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1822 0.1595 0.1668 0.1529 0.1437 0.1402 0.1390 0.1382 0.1380 0.1373 0.1370 0.1366 0.1373 0.1371 0.1375 0.1380 

[TRAIN] Epoch[3](460/1500); Loss: 0.080588; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.1152 0.1040 0.0941 0.0790 0.0789 0.0756 0.0752 0.0739 0.0741 0.0738 0.0742 0.0736 0.0742 0.0738 0.0750 0.0748 

[TRAIN] Epoch[3](461/1500); Loss: 0.112981; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.2177 0.1432 0.1307 0.1241 0.1138 0.1080 0.1049 0.1012 0.0996 0.0980 0.0968 0.0953 0.0945 0.0938 0.0932 0.0929 

[TRAIN] Epoch[3](462/1500); Loss: 0.134531; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1982 0.1410 0.1552 0.1629 0.1422 0.1331 0.1293 0.1241 0.1229 0.1211 0.1201 0.1197 0.1202 0.1205 0.1207 0.1213 

[TRAIN] Epoch[3](463/1500); Loss: 0.105357; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2835 0.1617 0.1064 0.1087 0.1027 0.0912 0.0880 0.0838 0.0834 0.0822 0.0823 0.0816 0.0825 0.0822 0.0828 0.0829 

[TRAIN] Epoch[3](464/1500); Loss: 0.108005; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1601 0.1125 0.1279 0.1123 0.1034 0.1032 0.1026 0.1023 0.1020 0.1009 0.1005 0.1003 0.1001 0.0996 0.1000 0.1002 

[TRAIN] Epoch[3](465/1500); Loss: 0.060027; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1673 0.0825 0.0653 0.0602 0.0522 0.0511 0.0495 0.0480 0.0473 0.0471 0.0473 0.0476 0.0480 0.0483 0.0490 0.0498 

[TRAIN] Epoch[3](466/1500); Loss: 0.121629; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.2389 0.1448 0.1333 0.1392 0.1196 0.1125 0.1093 0.1069 0.1067 0.1055 0.1054 0.1048 0.1049 0.1045 0.1050 0.1047 

[TRAIN] Epoch[3](467/1500); Loss: 0.160700; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2594 0.1964 0.1755 0.1617 0.1561 0.1535 0.1525 0.1501 0.1486 0.1468 0.1462 0.1454 0.1454 0.1446 0.1446 0.1445 

[TRAIN] Epoch[3](468/1500); Loss: 0.107872; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.1756 0.1239 0.1170 0.1135 0.1060 0.1039 0.1015 0.1003 0.0989 0.0981 0.0973 0.0975 0.0978 0.0981 0.0981 0.0986 

[TRAIN] Epoch[3](469/1500); Loss: 0.090377; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1356 0.1072 0.1036 0.0902 0.0868 0.0856 0.0844 0.0835 0.0833 0.0830 0.0830 0.0831 0.0834 0.0839 0.0843 0.0850 

[TRAIN] Epoch[3](470/1500); Loss: 0.039022; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.0871 0.0536 0.0411 0.0417 0.0353 0.0347 0.0325 0.0341 0.0315 0.0331 0.0313 0.0333 0.0320 0.0338 0.0336 0.0357 

[TRAIN] Epoch[3](471/1500); Loss: 0.084201; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1512 0.0905 0.0873 0.0822 0.0796 0.0786 0.0778 0.0767 0.0768 0.0767 0.0770 0.0772 0.0774 0.0784 0.0795 0.0802 

[TRAIN] Epoch[3](472/1500); Loss: 0.110059; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2623 0.1579 0.1142 0.1100 0.1024 0.0981 0.0959 0.0931 0.0926 0.0911 0.0910 0.0902 0.0902 0.0901 0.0909 0.0909 

[TRAIN] Epoch[3](473/1500); Loss: 0.084503; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2252 0.1251 0.0976 0.0721 0.0736 0.0695 0.0689 0.0679 0.0676 0.0677 0.0680 0.0686 0.0690 0.0693 0.0704 0.0714 

[TRAIN] Epoch[3](474/1500); Loss: 0.116869; Backpropagation: 0.0958 sec; Batch: 0.4294 sec
0.1708 0.1310 0.1205 0.1139 0.1130 0.1116 0.1107 0.1106 0.1102 0.1102 0.1101 0.1104 0.1110 0.1114 0.1120 0.1124 

[TRAIN] Epoch[3](475/1500); Loss: 0.099417; Backpropagation: 0.0959 sec; Batch: 0.4301 sec
0.1895 0.1114 0.1007 0.0995 0.0914 0.0910 0.0909 0.0902 0.0900 0.0901 0.0903 0.0904 0.0906 0.0910 0.0915 0.0921 

[TRAIN] Epoch[3](476/1500); Loss: 0.128061; Backpropagation: 0.0951 sec; Batch: 0.4298 sec
0.1915 0.1453 0.1315 0.1266 0.1239 0.1221 0.1214 0.1207 0.1201 0.1200 0.1202 0.1203 0.1207 0.1211 0.1216 0.1219 

[TRAIN] Epoch[3](477/1500); Loss: 0.081465; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1830 0.1283 0.1010 0.0814 0.0696 0.0688 0.0680 0.0675 0.0667 0.0665 0.0661 0.0667 0.0667 0.0673 0.0677 0.0683 

[TRAIN] Epoch[3](478/1500); Loss: 0.134632; Backpropagation: 0.0938 sec; Batch: 0.4271 sec
0.2541 0.1622 0.1416 0.1363 0.1252 0.1237 0.1233 0.1214 0.1204 0.1199 0.1199 0.1205 0.1209 0.1212 0.1215 0.1218 

[TRAIN] Epoch[3](479/1500); Loss: 0.069390; Backpropagation: 0.0952 sec; Batch: 0.4294 sec
0.1423 0.0870 0.0749 0.0676 0.0657 0.0632 0.0625 0.0613 0.0613 0.0607 0.0610 0.0604 0.0605 0.0603 0.0607 0.0609 

[TRAIN] Epoch[3](480/1500); Loss: 0.073498; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1212 0.0850 0.0797 0.0715 0.0695 0.0682 0.0685 0.0679 0.0684 0.0671 0.0682 0.0675 0.0683 0.0676 0.0688 0.0685 

[TRAIN] Epoch[3](481/1500); Loss: 0.132730; Backpropagation: 0.0954 sec; Batch: 0.4294 sec
0.2706 0.1603 0.1397 0.1327 0.1214 0.1199 0.1189 0.1185 0.1179 0.1175 0.1178 0.1176 0.1179 0.1179 0.1177 0.1174 

[TRAIN] Epoch[3](482/1500); Loss: 0.082575; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.4279 0.2122 0.0740 0.0824 0.0686 0.0445 0.0482 0.0436 0.0390 0.0364 0.0395 0.0381 0.0396 0.0398 0.0440 0.0433 

[TRAIN] Epoch[3](483/1500); Loss: 0.105414; Backpropagation: 0.0936 sec; Batch: 0.4312 sec
0.2706 0.1860 0.1412 0.0947 0.0907 0.0851 0.0823 0.0825 0.0816 0.0818 0.0806 0.0815 0.0810 0.0820 0.0817 0.0834 

[TRAIN] Epoch[3](484/1500); Loss: 0.045593; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.0456 0.0788 0.0570 0.0470 0.0439 0.0414 0.0421 0.0403 0.0427 0.0400 0.0425 0.0402 0.0427 0.0409 0.0427 0.0416 

[TRAIN] Epoch[3](485/1500); Loss: 0.094556; Backpropagation: 0.0944 sec; Batch: 0.4319 sec
0.1856 0.1195 0.1144 0.0970 0.0901 0.0876 0.0849 0.0833 0.0823 0.0813 0.0811 0.0804 0.0808 0.0808 0.0816 0.0821 

[TRAIN] Epoch[3](486/1500); Loss: 0.098153; Backpropagation: 0.0943 sec; Batch: 0.4283 sec
0.3282 0.1498 0.0873 0.1215 0.0918 0.0751 0.0743 0.0719 0.0724 0.0707 0.0714 0.0702 0.0713 0.0706 0.0721 0.0718 

[TRAIN] Epoch[3](487/1500); Loss: 0.107793; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1916 0.1410 0.1162 0.1047 0.1000 0.0992 0.0983 0.0979 0.0968 0.0968 0.0965 0.0970 0.0968 0.0972 0.0971 0.0974 

[TRAIN] Epoch[3](488/1500); Loss: 0.106895; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1556 0.1166 0.1104 0.1047 0.1033 0.1022 0.1019 0.1015 0.1014 0.1014 0.1017 0.1014 0.1017 0.1018 0.1022 0.1023 

[TRAIN] Epoch[3](489/1500); Loss: 0.054979; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.1091 0.1061 0.0709 0.0490 0.0514 0.0455 0.0449 0.0439 0.0449 0.0439 0.0444 0.0438 0.0449 0.0448 0.0460 0.0462 

[TRAIN] Epoch[3](490/1500); Loss: 0.101670; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2254 0.1531 0.1266 0.0926 0.0920 0.0903 0.0867 0.0866 0.0851 0.0845 0.0841 0.0840 0.0839 0.0838 0.0840 0.0840 

[TRAIN] Epoch[3](491/1500); Loss: 0.044648; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.0894 0.0590 0.0459 0.0420 0.0381 0.0396 0.0384 0.0384 0.0384 0.0387 0.0393 0.0397 0.0406 0.0415 0.0423 0.0430 

[TRAIN] Epoch[3](492/1500); Loss: 0.106686; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1591 0.1196 0.1179 0.1075 0.1037 0.1013 0.1006 0.1000 0.0999 0.0995 0.0998 0.0993 0.0996 0.0993 0.0999 0.0998 

[TRAIN] Epoch[3](493/1500); Loss: 0.090961; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1699 0.1263 0.1135 0.0998 0.0909 0.0882 0.0855 0.0825 0.0800 0.0778 0.0759 0.0745 0.0735 0.0724 0.0724 0.0723 

[TRAIN] Epoch[3](494/1500); Loss: 0.099822; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.4259 0.2637 0.1638 0.0864 0.0553 0.0552 0.0571 0.0580 0.0576 0.0547 0.0527 0.0523 0.0528 0.0534 0.0538 0.0543 

[TRAIN] Epoch[3](495/1500); Loss: 0.095840; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.3125 0.2063 0.1455 0.0851 0.0912 0.0750 0.0735 0.0668 0.0636 0.0596 0.0595 0.0588 0.0593 0.0591 0.0587 0.0591 

[TRAIN] Epoch[3](496/1500); Loss: 0.099808; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.1623 0.1051 0.1072 0.1000 0.0952 0.0952 0.0944 0.0939 0.0933 0.0927 0.0927 0.0928 0.0929 0.0930 0.0931 0.0931 

[TRAIN] Epoch[3](497/1500); Loss: 0.113976; Backpropagation: 0.0956 sec; Batch: 0.4298 sec
0.2446 0.1640 0.1170 0.1117 0.1051 0.1020 0.0999 0.0987 0.0982 0.0973 0.0979 0.0975 0.0974 0.0973 0.0976 0.0974 

[TRAIN] Epoch[3](498/1500); Loss: 0.118318; Backpropagation: 0.0948 sec; Batch: 0.4293 sec
0.2009 0.1356 0.1314 0.1285 0.1128 0.1113 0.1081 0.1072 0.1068 0.1070 0.1066 0.1066 0.1068 0.1074 0.1077 0.1085 

[TRAIN] Epoch[3](499/1500); Loss: 0.068935; Backpropagation: 0.0948 sec; Batch: 0.4290 sec
0.1250 0.0918 0.0932 0.0732 0.0638 0.0622 0.0604 0.0596 0.0595 0.0588 0.0586 0.0587 0.0594 0.0592 0.0597 0.0599 

[TRAIN] Epoch[3](500/1500); Loss: 0.062873; Backpropagation: 0.0950 sec; Batch: 0.4296 sec
0.0940 0.0755 0.0660 0.0621 0.0598 0.0598 0.0597 0.0594 0.0593 0.0590 0.0583 0.0584 0.0582 0.0590 0.0586 0.0591 

[TRAIN] Epoch[3](501/1500); Loss: 0.124754; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.2216 0.1461 0.1374 0.1288 0.1229 0.1205 0.1164 0.1156 0.1135 0.1130 0.1113 0.1107 0.1098 0.1097 0.1092 0.1096 

[TRAIN] Epoch[3](502/1500); Loss: 0.085529; Backpropagation: 0.0946 sec; Batch: 0.4287 sec
0.1876 0.1215 0.0893 0.0827 0.0811 0.0789 0.0764 0.0755 0.0730 0.0733 0.0717 0.0723 0.0709 0.0719 0.0710 0.0715 

[TRAIN] Epoch[3](503/1500); Loss: 0.144017; Backpropagation: 0.0944 sec; Batch: 0.4286 sec
0.2350 0.1728 0.1609 0.1546 0.1463 0.1414 0.1376 0.1344 0.1323 0.1296 0.1281 0.1270 0.1267 0.1261 0.1261 0.1254 

[TRAIN] Epoch[3](504/1500); Loss: 0.104161; Backpropagation: 0.0947 sec; Batch: 0.4285 sec
0.1811 0.1428 0.1440 0.1095 0.0980 0.0905 0.0919 0.0910 0.0920 0.0913 0.0915 0.0898 0.0892 0.0877 0.0881 0.0879 

[TRAIN] Epoch[3](505/1500); Loss: 0.132390; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.1827 0.1524 0.1583 0.1499 0.1354 0.1322 0.1266 0.1246 0.1224 0.1212 0.1196 0.1191 0.1183 0.1185 0.1184 0.1184 

[TRAIN] Epoch[3](506/1500); Loss: 0.125324; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1675 0.1346 0.1478 0.1314 0.1250 0.1242 0.1221 0.1212 0.1194 0.1183 0.1173 0.1165 0.1155 0.1152 0.1145 0.1146 

[TRAIN] Epoch[3](507/1500); Loss: 0.141689; Backpropagation: 0.0948 sec; Batch: 0.4294 sec
0.2376 0.1508 0.1549 0.1681 0.1480 0.1414 0.1349 0.1301 0.1275 0.1252 0.1251 0.1247 0.1243 0.1246 0.1246 0.1253 

[TRAIN] Epoch[3](508/1500); Loss: 0.131493; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2242 0.1683 0.1680 0.1454 0.1260 0.1259 0.1221 0.1201 0.1177 0.1163 0.1134 0.1131 0.1121 0.1116 0.1098 0.1100 

[TRAIN] Epoch[3](509/1500); Loss: 0.108662; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1647 0.1303 0.1410 0.1234 0.1076 0.1029 0.0993 0.0970 0.0968 0.0958 0.0966 0.0961 0.0972 0.0964 0.0969 0.0965 

[TRAIN] Epoch[3](510/1500); Loss: 0.125834; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1677 0.1560 0.1551 0.1343 0.1298 0.1230 0.1207 0.1173 0.1168 0.1145 0.1143 0.1130 0.1131 0.1123 0.1133 0.1122 

[TRAIN] Epoch[3](511/1500); Loss: 0.076161; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.2756 0.1486 0.1050 0.0853 0.0702 0.0643 0.0571 0.0521 0.0476 0.0457 0.0442 0.0439 0.0440 0.0442 0.0448 0.0459 

[TRAIN] Epoch[3](512/1500); Loss: 0.071989; Backpropagation: 0.0948 sec; Batch: 0.4287 sec
0.2345 0.0941 0.0944 0.0844 0.0694 0.0637 0.0562 0.0547 0.0502 0.0499 0.0482 0.0502 0.0492 0.0508 0.0500 0.0519 

[TRAIN] Epoch[3](513/1500); Loss: 0.105621; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1931 0.1268 0.1146 0.1132 0.0981 0.0973 0.0945 0.0947 0.0939 0.0944 0.0941 0.0946 0.0942 0.0955 0.0951 0.0959 

[TRAIN] Epoch[3](514/1500); Loss: 0.081446; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1779 0.1079 0.0845 0.0760 0.0717 0.0703 0.0689 0.0701 0.0691 0.0710 0.0702 0.0718 0.0719 0.0732 0.0739 0.0747 

[TRAIN] Epoch[3](515/1500); Loss: 0.083033; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1648 0.1209 0.1065 0.0849 0.0780 0.0744 0.0735 0.0710 0.0706 0.0687 0.0693 0.0686 0.0692 0.0688 0.0698 0.0695 

[TRAIN] Epoch[3](516/1500); Loss: 0.113039; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.2388 0.1531 0.1165 0.1129 0.1026 0.1006 0.0993 0.0995 0.0987 0.0982 0.0981 0.0980 0.0977 0.0980 0.0982 0.0985 

[TRAIN] Epoch[3](517/1500); Loss: 0.080973; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.3313 0.1520 0.0768 0.0990 0.0715 0.0612 0.0568 0.0512 0.0512 0.0476 0.0509 0.0477 0.0506 0.0480 0.0509 0.0488 

[TRAIN] Epoch[3](518/1500); Loss: 0.123975; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.2181 0.1592 0.1334 0.1244 0.1191 0.1175 0.1155 0.1138 0.1114 0.1111 0.1106 0.1101 0.1099 0.1099 0.1097 0.1099 

[TRAIN] Epoch[3](519/1500); Loss: 0.111667; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1705 0.1314 0.1306 0.1171 0.1099 0.1093 0.1050 0.1033 0.1022 0.1015 0.1011 0.1013 0.1009 0.1006 0.1009 0.1011 

[TRAIN] Epoch[3](520/1500); Loss: 0.070715; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.1606 0.1020 0.0678 0.0653 0.0616 0.0605 0.0597 0.0606 0.0596 0.0604 0.0601 0.0611 0.0615 0.0626 0.0636 0.0643 

[TRAIN] Epoch[3](521/1500); Loss: 0.139617; Backpropagation: 0.0961 sec; Batch: 0.4314 sec
0.2231 0.1740 0.1555 0.1366 0.1330 0.1307 0.1291 0.1284 0.1279 0.1277 0.1272 0.1277 0.1276 0.1280 0.1285 0.1290 

[TRAIN] Epoch[3](522/1500); Loss: 0.122248; Backpropagation: 0.0954 sec; Batch: 0.4303 sec
0.2048 0.1625 0.1523 0.1246 0.1187 0.1128 0.1099 0.1083 0.1082 0.1077 0.1075 0.1072 0.1076 0.1077 0.1081 0.1081 

[TRAIN] Epoch[3](523/1500); Loss: 0.132263; Backpropagation: 0.0948 sec; Batch: 0.4286 sec
0.1720 0.1552 0.1482 0.1322 0.1278 0.1251 0.1244 0.1252 0.1244 0.1241 0.1240 0.1249 0.1258 0.1269 0.1274 0.1285 

[TRAIN] Epoch[3](524/1500); Loss: 0.119763; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.2036 0.1568 0.1364 0.1158 0.1143 0.1109 0.1098 0.1089 0.1081 0.1083 0.1080 0.1073 0.1074 0.1070 0.1067 0.1067 

[TRAIN] Epoch[3](525/1500); Loss: 0.090160; Backpropagation: 0.0947 sec; Batch: 0.4291 sec
0.2945 0.1612 0.1057 0.0744 0.0695 0.0681 0.0674 0.0668 0.0667 0.0664 0.0665 0.0667 0.0671 0.0671 0.0671 0.0672 

[TRAIN] Epoch[3](526/1500); Loss: 0.083238; Backpropagation: 0.0939 sec; Batch: 0.4274 sec
0.2551 0.1759 0.1280 0.0627 0.0710 0.0621 0.0578 0.0577 0.0567 0.0577 0.0570 0.0577 0.0574 0.0586 0.0579 0.0587 

[TRAIN] Epoch[3](527/1500); Loss: 0.126899; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1781 0.1435 0.1375 0.1287 0.1250 0.1231 0.1214 0.1204 0.1197 0.1195 0.1190 0.1188 0.1188 0.1191 0.1189 0.1190 

[TRAIN] Epoch[3](528/1500); Loss: 0.104367; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1646 0.1287 0.1106 0.1016 0.1007 0.0975 0.0976 0.0964 0.0968 0.0957 0.0963 0.0961 0.0968 0.0966 0.0970 0.0968 

[TRAIN] Epoch[3](529/1500); Loss: 0.121988; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1807 0.1437 0.1332 0.1215 0.1177 0.1166 0.1151 0.1146 0.1141 0.1138 0.1136 0.1135 0.1134 0.1133 0.1134 0.1138 

[TRAIN] Epoch[3](530/1500); Loss: 0.060758; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1488 0.0584 0.0776 0.0562 0.0562 0.0529 0.0521 0.0517 0.0515 0.0515 0.0518 0.0520 0.0525 0.0523 0.0531 0.0534 

[TRAIN] Epoch[3](531/1500); Loss: 0.073929; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.2071 0.1254 0.0764 0.0636 0.0623 0.0595 0.0599 0.0598 0.0583 0.0584 0.0581 0.0580 0.0584 0.0587 0.0593 0.0596 

[TRAIN] Epoch[3](532/1500); Loss: 0.131718; Backpropagation: 0.0978 sec; Batch: 0.4324 sec
0.2397 0.1678 0.1405 0.1330 0.1218 0.1197 0.1190 0.1190 0.1185 0.1186 0.1182 0.1185 0.1184 0.1182 0.1182 0.1185 

[TRAIN] Epoch[3](533/1500); Loss: 0.089058; Backpropagation: 0.0977 sec; Batch: 0.4323 sec
0.1823 0.1064 0.0914 0.0868 0.0840 0.0815 0.0806 0.0790 0.0786 0.0779 0.0785 0.0784 0.0790 0.0794 0.0801 0.0811 

[TRAIN] Epoch[3](534/1500); Loss: 0.164195; Backpropagation: 0.0954 sec; Batch: 0.4375 sec
0.2610 0.2052 0.1796 0.1622 0.1581 0.1558 0.1549 0.1525 0.1508 0.1499 0.1493 0.1493 0.1494 0.1495 0.1497 0.1499 

[TRAIN] Epoch[3](535/1500); Loss: 0.066739; Backpropagation: 0.0933 sec; Batch: 0.4686 sec
0.1228 0.0847 0.0734 0.0650 0.0616 0.0619 0.0606 0.0598 0.0590 0.0592 0.0591 0.0596 0.0593 0.0602 0.0603 0.0613 

[TRAIN] Epoch[3](536/1500); Loss: 0.150784; Backpropagation: 0.0933 sec; Batch: 0.4355 sec
0.2489 0.1704 0.1567 0.1490 0.1426 0.1424 0.1414 0.1411 0.1404 0.1402 0.1400 0.1399 0.1397 0.1401 0.1397 0.1400 

[TRAIN] Epoch[3](537/1500); Loss: 0.109032; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1826 0.1204 0.1162 0.1135 0.1059 0.1043 0.1028 0.1016 0.1013 0.0999 0.0998 0.0992 0.0994 0.0989 0.0993 0.0992 

[TRAIN] Epoch[3](538/1500); Loss: 0.110511; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.1911 0.1493 0.1200 0.1099 0.1035 0.1011 0.1004 0.0996 0.0993 0.0987 0.0991 0.0987 0.0992 0.0990 0.0997 0.0997 

[TRAIN] Epoch[3](539/1500); Loss: 0.121859; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.2109 0.1420 0.1226 0.1279 0.1182 0.1158 0.1144 0.1127 0.1118 0.1112 0.1108 0.1107 0.1104 0.1102 0.1101 0.1099 

[TRAIN] Epoch[3](540/1500); Loss: 0.115584; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1919 0.1245 0.1144 0.1099 0.1086 0.1083 0.1077 0.1077 0.1077 0.1086 0.1087 0.1092 0.1097 0.1105 0.1107 0.1110 

[TRAIN] Epoch[3](541/1500); Loss: 0.113185; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1956 0.1423 0.1276 0.1136 0.1103 0.1063 0.1041 0.1024 0.1019 0.1011 0.1011 0.1010 0.1011 0.1009 0.1009 0.1008 

[TRAIN] Epoch[3](542/1500); Loss: 0.089839; Backpropagation: 0.0933 sec; Batch: 0.4286 sec
0.1893 0.1208 0.0987 0.0871 0.0826 0.0817 0.0800 0.0796 0.0784 0.0775 0.0772 0.0767 0.0767 0.0766 0.0771 0.0774 

[TRAIN] Epoch[3](543/1500); Loss: 0.055269; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1012 0.0765 0.0587 0.0545 0.0515 0.0499 0.0489 0.0488 0.0485 0.0485 0.0487 0.0490 0.0491 0.0498 0.0501 0.0507 

[TRAIN] Epoch[3](544/1500); Loss: 0.115017; Backpropagation: 0.0942 sec; Batch: 0.4296 sec
0.2125 0.1460 0.1166 0.1132 0.1064 0.1053 0.1045 0.1049 0.1036 0.1038 0.1033 0.1037 0.1035 0.1043 0.1040 0.1045 

[TRAIN] Epoch[3](545/1500); Loss: 0.119496; Backpropagation: 0.0944 sec; Batch: 0.4297 sec
0.1793 0.1332 0.1222 0.1175 0.1158 0.1134 0.1130 0.1125 0.1126 0.1127 0.1130 0.1129 0.1135 0.1132 0.1135 0.1137 

[TRAIN] Epoch[3](546/1500); Loss: 0.092773; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1544 0.1106 0.1025 0.0932 0.0888 0.0869 0.0858 0.0853 0.0848 0.0848 0.0846 0.0847 0.0844 0.0844 0.0845 0.0848 

[TRAIN] Epoch[3](547/1500); Loss: 0.097327; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.3685 0.1834 0.0906 0.1056 0.0784 0.0697 0.0688 0.0651 0.0662 0.0645 0.0662 0.0645 0.0664 0.0653 0.0676 0.0663 

[TRAIN] Epoch[3](548/1500); Loss: 0.064511; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.2544 0.0713 0.0951 0.0694 0.0449 0.0473 0.0444 0.0452 0.0429 0.0447 0.0429 0.0448 0.0439 0.0468 0.0459 0.0483 

[TRAIN] Epoch[3](549/1500); Loss: 0.093280; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.3292 0.2126 0.1280 0.0685 0.0778 0.0643 0.0641 0.0606 0.0613 0.0595 0.0606 0.0599 0.0611 0.0606 0.0622 0.0622 

[TRAIN] Epoch[3](550/1500); Loss: 0.061014; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1313 0.0824 0.0644 0.0615 0.0551 0.0533 0.0525 0.0516 0.0514 0.0515 0.0519 0.0524 0.0529 0.0539 0.0546 0.0556 

[TRAIN] Epoch[3](551/1500); Loss: 0.106614; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.1911 0.1483 0.1157 0.0993 0.0982 0.0979 0.0967 0.0960 0.0956 0.0951 0.0952 0.0952 0.0951 0.0952 0.0954 0.0958 

[TRAIN] Epoch[3](552/1500); Loss: 0.061206; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1560 0.0861 0.0658 0.0541 0.0552 0.0518 0.0515 0.0507 0.0508 0.0507 0.0505 0.0507 0.0509 0.0512 0.0515 0.0517 

[TRAIN] Epoch[3](553/1500); Loss: 0.057712; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1102 0.0568 0.0584 0.0505 0.0518 0.0515 0.0525 0.0520 0.0537 0.0529 0.0543 0.0539 0.0557 0.0554 0.0570 0.0569 

[TRAIN] Epoch[3](554/1500); Loss: 0.100602; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2497 0.1435 0.1051 0.0959 0.0860 0.0856 0.0838 0.0841 0.0832 0.0841 0.0833 0.0842 0.0841 0.0855 0.0850 0.0864 

[TRAIN] Epoch[3](555/1500); Loss: 0.060617; Backpropagation: 0.0951 sec; Batch: 0.4300 sec
0.1589 0.0782 0.0686 0.0606 0.0591 0.0540 0.0531 0.0507 0.0493 0.0482 0.0480 0.0477 0.0478 0.0480 0.0487 0.0491 

[TRAIN] Epoch[3](556/1500); Loss: 0.082243; Backpropagation: 0.0959 sec; Batch: 0.4316 sec
0.1637 0.1085 0.0893 0.0787 0.0757 0.0740 0.0728 0.0720 0.0721 0.0718 0.0721 0.0725 0.0727 0.0731 0.0733 0.0736 

[TRAIN] Epoch[3](557/1500); Loss: 0.094868; Backpropagation: 0.0960 sec; Batch: 0.4309 sec
0.1686 0.1181 0.1058 0.0948 0.0902 0.0883 0.0868 0.0862 0.0855 0.0850 0.0846 0.0845 0.0845 0.0847 0.0849 0.0855 

[TRAIN] Epoch[3](558/1500); Loss: 0.133025; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1637 0.1497 0.1380 0.1343 0.1320 0.1307 0.1299 0.1291 0.1285 0.1282 0.1279 0.1276 0.1273 0.1273 0.1271 0.1271 

[TRAIN] Epoch[3](559/1500); Loss: 0.060872; Backpropagation: 0.0935 sec; Batch: 0.4287 sec
0.0809 0.0957 0.0652 0.0570 0.0562 0.0552 0.0549 0.0551 0.0552 0.0555 0.0558 0.0564 0.0566 0.0575 0.0580 0.0586 

[TRAIN] Epoch[3](560/1500); Loss: 0.097345; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2440 0.1555 0.1072 0.0922 0.0843 0.0822 0.0801 0.0793 0.0788 0.0784 0.0789 0.0787 0.0797 0.0791 0.0796 0.0797 

[TRAIN] Epoch[3](561/1500); Loss: 0.093919; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.2008 0.1352 0.1055 0.0866 0.0833 0.0822 0.0805 0.0807 0.0802 0.0804 0.0804 0.0810 0.0806 0.0812 0.0815 0.0824 

[TRAIN] Epoch[3](562/1500); Loss: 0.049387; Backpropagation: 0.0937 sec; Batch: 0.4289 sec
0.1182 0.0772 0.0563 0.0469 0.0450 0.0427 0.0415 0.0404 0.0406 0.0397 0.0403 0.0396 0.0405 0.0398 0.0409 0.0406 

[TRAIN] Epoch[3](563/1500); Loss: 0.039208; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1057 0.0768 0.0473 0.0344 0.0341 0.0311 0.0301 0.0288 0.0292 0.0286 0.0293 0.0289 0.0300 0.0298 0.0315 0.0317 

[TRAIN] Epoch[3](564/1500); Loss: 0.067200; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1737 0.0737 0.0828 0.0618 0.0628 0.0590 0.0582 0.0568 0.0569 0.0558 0.0559 0.0553 0.0558 0.0552 0.0560 0.0555 

[TRAIN] Epoch[3](565/1500); Loss: 0.115361; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1687 0.1293 0.1195 0.1157 0.1122 0.1111 0.1098 0.1093 0.1084 0.1087 0.1085 0.1085 0.1084 0.1091 0.1090 0.1096 

[TRAIN] Epoch[3](566/1500); Loss: 0.127150; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1747 0.1457 0.1376 0.1288 0.1234 0.1210 0.1208 0.1204 0.1199 0.1197 0.1199 0.1201 0.1203 0.1204 0.1207 0.1209 

[TRAIN] Epoch[3](567/1500); Loss: 0.077756; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1427 0.1002 0.0860 0.0780 0.0732 0.0717 0.0703 0.0694 0.0688 0.0687 0.0687 0.0688 0.0688 0.0693 0.0695 0.0699 

[TRAIN] Epoch[3](568/1500); Loss: 0.115411; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.3693 0.2485 0.1755 0.1124 0.0825 0.0807 0.0783 0.0775 0.0773 0.0766 0.0766 0.0777 0.0776 0.0785 0.0784 0.0792 

[TRAIN] Epoch[3](569/1500); Loss: 0.126392; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2202 0.1577 0.1376 0.1234 0.1180 0.1166 0.1157 0.1154 0.1150 0.1149 0.1147 0.1148 0.1146 0.1145 0.1146 0.1145 

[TRAIN] Epoch[3](570/1500); Loss: 0.066516; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1238 0.0882 0.0697 0.0604 0.0630 0.0610 0.0606 0.0594 0.0598 0.0592 0.0596 0.0593 0.0597 0.0595 0.0606 0.0604 

[TRAIN] Epoch[3](571/1500); Loss: 0.035306; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.0813 0.0471 0.0431 0.0346 0.0345 0.0312 0.0302 0.0288 0.0287 0.0284 0.0287 0.0287 0.0296 0.0293 0.0305 0.0303 

[TRAIN] Epoch[3](572/1500); Loss: 0.068005; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.3182 0.1689 0.0926 0.0488 0.0465 0.0427 0.0407 0.0384 0.0376 0.0362 0.0363 0.0359 0.0364 0.0359 0.0365 0.0365 

[TRAIN] Epoch[3](573/1500); Loss: 0.128599; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.2235 0.1494 0.1335 0.1241 0.1210 0.1204 0.1195 0.1188 0.1185 0.1183 0.1183 0.1182 0.1183 0.1185 0.1187 0.1186 

[TRAIN] Epoch[3](574/1500); Loss: 0.118616; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.3423 0.2082 0.1278 0.1241 0.1063 0.0947 0.0932 0.0907 0.0906 0.0892 0.0888 0.0884 0.0886 0.0884 0.0884 0.0883 

[TRAIN] Epoch[3](575/1500); Loss: 0.094244; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.2855 0.1472 0.0934 0.0899 0.0784 0.0743 0.0736 0.0729 0.0726 0.0730 0.0733 0.0736 0.0740 0.0750 0.0752 0.0761 

[TRAIN] Epoch[3](576/1500); Loss: 0.057810; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.0986 0.0764 0.0644 0.0583 0.0545 0.0539 0.0528 0.0523 0.0523 0.0517 0.0516 0.0515 0.0514 0.0516 0.0517 0.0521 

[TRAIN] Epoch[3](577/1500); Loss: 0.105104; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1763 0.1209 0.1131 0.1054 0.1013 0.0998 0.0977 0.0968 0.0961 0.0961 0.0958 0.0963 0.0962 0.0964 0.0965 0.0968 

[TRAIN] Epoch[3](578/1500); Loss: 0.051329; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1147 0.0837 0.0645 0.0532 0.0456 0.0426 0.0414 0.0413 0.0407 0.0411 0.0410 0.0415 0.0416 0.0422 0.0427 0.0434 

[TRAIN] Epoch[3](579/1500); Loss: 0.076434; Backpropagation: 0.0949 sec; Batch: 0.4292 sec
0.1470 0.1037 0.0761 0.0734 0.0708 0.0693 0.0692 0.0683 0.0688 0.0679 0.0684 0.0677 0.0683 0.0678 0.0683 0.0680 

[TRAIN] Epoch[3](580/1500); Loss: 0.088488; Backpropagation: 0.0938 sec; Batch: 0.5284 sec
0.1390 0.1038 0.0919 0.0843 0.0838 0.0826 0.0824 0.0822 0.0822 0.0822 0.0828 0.0830 0.0835 0.0835 0.0841 0.0844 

[TRAIN] Epoch[3](581/1500); Loss: 0.170647; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2845 0.2589 0.1914 0.1525 0.1558 0.1529 0.1531 0.1527 0.1535 0.1532 0.1535 0.1531 0.1537 0.1535 0.1541 0.1540 

[TRAIN] Epoch[3](582/1500); Loss: 0.119005; Backpropagation: 0.0939 sec; Batch: 0.4273 sec
0.2293 0.1534 0.1314 0.1143 0.1114 0.1094 0.1076 0.1060 0.1056 0.1051 0.1050 0.1049 0.1050 0.1050 0.1054 0.1054 

[TRAIN] Epoch[3](583/1500); Loss: 0.069434; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1115 0.0842 0.0729 0.0681 0.0663 0.0652 0.0648 0.0644 0.0640 0.0641 0.0639 0.0640 0.0642 0.0642 0.0644 0.0646 

[TRAIN] Epoch[3](584/1500); Loss: 0.068710; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2506 0.0958 0.0700 0.0561 0.0565 0.0530 0.0527 0.0518 0.0520 0.0510 0.0511 0.0509 0.0515 0.0515 0.0523 0.0524 

[TRAIN] Epoch[3](585/1500); Loss: 0.065261; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1216 0.0771 0.0721 0.0626 0.0627 0.0603 0.0595 0.0588 0.0587 0.0585 0.0585 0.0585 0.0587 0.0587 0.0590 0.0590 

[TRAIN] Epoch[3](586/1500); Loss: 0.100863; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.3111 0.1750 0.1103 0.0880 0.0842 0.0799 0.0780 0.0778 0.0767 0.0765 0.0761 0.0760 0.0758 0.0760 0.0760 0.0763 

[TRAIN] Epoch[3](587/1500); Loss: 0.087343; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1591 0.1134 0.0919 0.0843 0.0831 0.0806 0.0801 0.0796 0.0788 0.0785 0.0784 0.0781 0.0780 0.0779 0.0779 0.0779 

[TRAIN] Epoch[3](588/1500); Loss: 0.146354; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2323 0.1853 0.1600 0.1430 0.1388 0.1371 0.1356 0.1353 0.1346 0.1346 0.1342 0.1342 0.1340 0.1340 0.1342 0.1344 

[TRAIN] Epoch[3](589/1500); Loss: 0.081371; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1604 0.1120 0.0923 0.0767 0.0748 0.0724 0.0723 0.0716 0.0716 0.0712 0.0711 0.0709 0.0711 0.0709 0.0713 0.0713 

[TRAIN] Epoch[3](590/1500); Loss: 0.115906; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.2347 0.1536 0.1226 0.1055 0.1083 0.1051 0.1036 0.1024 0.1026 0.1020 0.1026 0.1021 0.1028 0.1021 0.1025 0.1020 

[TRAIN] Epoch[3](591/1500); Loss: 0.069769; Backpropagation: 0.0960 sec; Batch: 0.4302 sec
0.1804 0.0964 0.0742 0.0651 0.0605 0.0589 0.0585 0.0579 0.0579 0.0575 0.0582 0.0579 0.0581 0.0579 0.0584 0.0584 

[TRAIN] Epoch[3](592/1500); Loss: 0.145208; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2524 0.1952 0.1651 0.1401 0.1357 0.1334 0.1323 0.1313 0.1308 0.1301 0.1297 0.1295 0.1295 0.1294 0.1292 0.1294 

[TRAIN] Epoch[3](593/1500); Loss: 0.073760; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.2110 0.1427 0.0758 0.0646 0.0592 0.0580 0.0572 0.0569 0.0566 0.0569 0.0566 0.0567 0.0568 0.0569 0.0570 0.0572 

[TRAIN] Epoch[3](594/1500); Loss: 0.115626; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2645 0.1849 0.1365 0.1099 0.0991 0.0990 0.0977 0.0964 0.0957 0.0949 0.0949 0.0949 0.0952 0.0952 0.0956 0.0957 

[TRAIN] Epoch[3](595/1500); Loss: 0.105105; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1771 0.1147 0.1097 0.1028 0.1008 0.1003 0.0994 0.0986 0.0980 0.0976 0.0976 0.0974 0.0971 0.0970 0.0968 0.0969 

[TRAIN] Epoch[3](596/1500); Loss: 0.120931; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2072 0.1607 0.1316 0.1162 0.1147 0.1130 0.1113 0.1102 0.1095 0.1089 0.1088 0.1087 0.1086 0.1085 0.1084 0.1084 

[TRAIN] Epoch[3](597/1500); Loss: 0.075950; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2731 0.1365 0.0839 0.0640 0.0586 0.0571 0.0556 0.0548 0.0544 0.0541 0.0542 0.0539 0.0537 0.0537 0.0535 0.0539 

[TRAIN] Epoch[3](598/1500); Loss: 0.057313; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1504 0.0697 0.0592 0.0497 0.0502 0.0484 0.0482 0.0479 0.0480 0.0484 0.0484 0.0489 0.0491 0.0498 0.0501 0.0507 

[TRAIN] Epoch[3](599/1500); Loss: 0.093673; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1647 0.1234 0.1044 0.0926 0.0872 0.0857 0.0847 0.0842 0.0842 0.0838 0.0839 0.0838 0.0839 0.0838 0.0841 0.0844 

[TRAIN] Epoch[3](600/1500); Loss: 0.112647; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2167 0.1427 0.1192 0.1087 0.1042 0.1020 0.1010 0.1008 0.1007 0.1008 0.1004 0.1008 0.1008 0.1012 0.1011 0.1013 

[TRAIN] Epoch[3](601/1500); Loss: 0.068647; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2956 0.1130 0.0729 0.0758 0.0499 0.0475 0.0464 0.0443 0.0443 0.0436 0.0438 0.0436 0.0439 0.0441 0.0447 0.0451 

[TRAIN] Epoch[3](602/1500); Loss: 0.083512; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.2463 0.1492 0.0991 0.0769 0.0655 0.0641 0.0636 0.0635 0.0638 0.0638 0.0640 0.0635 0.0633 0.0631 0.0633 0.0634 

[TRAIN] Epoch[3](603/1500); Loss: 0.114036; Backpropagation: 0.0938 sec; Batch: 0.4292 sec
0.2265 0.1490 0.1205 0.1101 0.1059 0.1040 0.1025 0.1017 0.1012 0.1009 0.1007 0.1006 0.1003 0.1002 0.1002 0.1003 

[TRAIN] Epoch[3](604/1500); Loss: 0.128668; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1600 0.1411 0.1261 0.1241 0.1242 0.1237 0.1240 0.1242 0.1249 0.1250 0.1257 0.1260 0.1265 0.1270 0.1278 0.1285 

[TRAIN] Epoch[3](605/1500); Loss: 0.106326; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1823 0.1528 0.1197 0.1030 0.0994 0.0973 0.0959 0.0950 0.0947 0.0945 0.0944 0.0943 0.0943 0.0946 0.0945 0.0945 

[TRAIN] Epoch[3](606/1500); Loss: 0.135288; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.3053 0.2007 0.1567 0.1298 0.1212 0.1168 0.1152 0.1132 0.1128 0.1123 0.1125 0.1124 0.1135 0.1135 0.1143 0.1144 

[TRAIN] Epoch[3](607/1500); Loss: 0.119990; Backpropagation: 0.1014 sec; Batch: 0.4429 sec
0.1950 0.1445 0.1255 0.1151 0.1142 0.1129 0.1123 0.1119 0.1113 0.1108 0.1108 0.1107 0.1106 0.1113 0.1115 0.1116 

[TRAIN] Epoch[3](608/1500); Loss: 0.093082; Backpropagation: 0.0987 sec; Batch: 0.4344 sec
0.1297 0.1063 0.0957 0.0903 0.0897 0.0894 0.0892 0.0893 0.0888 0.0890 0.0884 0.0888 0.0884 0.0888 0.0887 0.0888 

[TRAIN] Epoch[3](609/1500); Loss: 0.061226; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.1484 0.0859 0.0701 0.0584 0.0552 0.0537 0.0519 0.0515 0.0506 0.0507 0.0504 0.0504 0.0502 0.0504 0.0506 0.0510 

[TRAIN] Epoch[3](610/1500); Loss: 0.102402; Backpropagation: 0.0998 sec; Batch: 0.4342 sec
0.1636 0.1165 0.1083 0.1003 0.0987 0.0975 0.0960 0.0953 0.0949 0.0950 0.0951 0.0954 0.0952 0.0954 0.0955 0.0959 

[TRAIN] Epoch[3](611/1500); Loss: 0.066058; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1017 0.0702 0.0751 0.0643 0.0652 0.0635 0.0624 0.0620 0.0618 0.0615 0.0615 0.0614 0.0615 0.0615 0.0616 0.0618 

[TRAIN] Epoch[3](612/1500); Loss: 0.072782; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1981 0.1126 0.0770 0.0644 0.0649 0.0612 0.0607 0.0595 0.0589 0.0586 0.0584 0.0583 0.0581 0.0581 0.0578 0.0581 

[TRAIN] Epoch[3](613/1500); Loss: 0.086964; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.2792 0.2310 0.1187 0.0751 0.0615 0.0588 0.0574 0.0578 0.0562 0.0558 0.0562 0.0564 0.0564 0.0565 0.0568 0.0576 

[TRAIN] Epoch[3](614/1500); Loss: 0.088453; Backpropagation: 0.0997 sec; Batch: 0.4351 sec
0.1583 0.1091 0.0933 0.0846 0.0851 0.0822 0.0811 0.0802 0.0801 0.0799 0.0799 0.0800 0.0800 0.0801 0.0804 0.0810 

[TRAIN] Epoch[3](615/1500); Loss: 0.109983; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.2128 0.1641 0.1292 0.1066 0.0986 0.0968 0.0958 0.0957 0.0952 0.0951 0.0949 0.0950 0.0949 0.0950 0.0948 0.0952 

[TRAIN] Epoch[3](616/1500); Loss: 0.095564; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1631 0.1049 0.0966 0.0940 0.0920 0.0910 0.0892 0.0889 0.0886 0.0887 0.0883 0.0885 0.0884 0.0886 0.0887 0.0894 

[TRAIN] Epoch[3](617/1500); Loss: 0.109305; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2509 0.1706 0.1413 0.1127 0.0981 0.0940 0.0918 0.0906 0.0901 0.0886 0.0880 0.0869 0.0868 0.0864 0.0862 0.0859 

[TRAIN] Epoch[3](618/1500); Loss: 0.082887; Backpropagation: 0.0992 sec; Batch: 0.4342 sec
0.1222 0.1239 0.0912 0.0757 0.0793 0.0754 0.0757 0.0742 0.0755 0.0746 0.0757 0.0754 0.0767 0.0762 0.0773 0.0771 

[TRAIN] Epoch[3](619/1500); Loss: 0.108779; Backpropagation: 0.0990 sec; Batch: 0.4344 sec
0.3482 0.2091 0.1214 0.1125 0.0879 0.0846 0.0822 0.0802 0.0790 0.0777 0.0770 0.0762 0.0761 0.0757 0.0763 0.0764 

[TRAIN] Epoch[3](620/1500); Loss: 0.075709; Backpropagation: 0.1022 sec; Batch: 0.4452 sec
0.1689 0.1164 0.0910 0.0761 0.0667 0.0648 0.0633 0.0624 0.0621 0.0621 0.0624 0.0626 0.0630 0.0631 0.0632 0.0634 

[TRAIN] Epoch[3](621/1500); Loss: 0.055330; Backpropagation: 0.1028 sec; Batch: 0.4379 sec
0.1140 0.0745 0.0587 0.0555 0.0521 0.0508 0.0493 0.0489 0.0482 0.0478 0.0477 0.0475 0.0473 0.0473 0.0477 0.0481 

[TRAIN] Epoch[3](622/1500); Loss: 0.084982; Backpropagation: 0.0986 sec; Batch: 0.4377 sec
0.1655 0.1255 0.0978 0.0801 0.0797 0.0773 0.0752 0.0739 0.0734 0.0731 0.0730 0.0728 0.0729 0.0730 0.0732 0.0732 

[TRAIN] Epoch[3](623/1500); Loss: 0.105335; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1810 0.1299 0.1117 0.1047 0.1018 0.0991 0.0976 0.0964 0.0959 0.0956 0.0955 0.0954 0.0954 0.0951 0.0950 0.0951 

[TRAIN] Epoch[3](624/1500); Loss: 0.192942; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.2520 0.2318 0.1969 0.1904 0.1862 0.1861 0.1852 0.1865 0.1847 0.1855 0.1836 0.1847 0.1831 0.1843 0.1827 0.1835 

[TRAIN] Epoch[3](625/1500); Loss: 0.103535; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.2096 0.1366 0.1119 0.1003 0.0984 0.0954 0.0939 0.0934 0.0914 0.0911 0.0898 0.0894 0.0890 0.0888 0.0887 0.0888 

[TRAIN] Epoch[3](626/1500); Loss: 0.134232; Backpropagation: 0.0989 sec; Batch: 0.4334 sec
0.2089 0.1540 0.1376 0.1325 0.1307 0.1290 0.1276 0.1267 0.1262 0.1256 0.1253 0.1249 0.1248 0.1248 0.1246 0.1246 

[TRAIN] Epoch[3](627/1500); Loss: 0.100987; Backpropagation: 0.0988 sec; Batch: 0.4344 sec
0.1627 0.1198 0.1099 0.0994 0.0982 0.0963 0.0948 0.0938 0.0933 0.0929 0.0928 0.0926 0.0925 0.0922 0.0922 0.0923 

[TRAIN] Epoch[3](628/1500); Loss: 0.138759; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1861 0.1513 0.1436 0.1386 0.1365 0.1355 0.1346 0.1340 0.1335 0.1329 0.1327 0.1325 0.1322 0.1320 0.1319 0.1319 

[TRAIN] Epoch[3](629/1500); Loss: 0.090564; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1734 0.1087 0.0909 0.0861 0.0831 0.0836 0.0829 0.0827 0.0818 0.0823 0.0818 0.0824 0.0817 0.0826 0.0821 0.0829 

[TRAIN] Epoch[3](630/1500); Loss: 0.127769; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2329 0.1742 0.1296 0.1233 0.1186 0.1170 0.1153 0.1148 0.1141 0.1144 0.1142 0.1146 0.1147 0.1151 0.1156 0.1159 

[TRAIN] Epoch[3](631/1500); Loss: 0.044278; Backpropagation: 0.0986 sec; Batch: 0.4342 sec
0.1213 0.0974 0.0517 0.0371 0.0360 0.0341 0.0333 0.0326 0.0329 0.0325 0.0328 0.0326 0.0331 0.0332 0.0339 0.0339 

[TRAIN] Epoch[3](632/1500); Loss: 0.078141; Backpropagation: 0.0990 sec; Batch: 0.4338 sec
0.1468 0.1093 0.0934 0.0804 0.0758 0.0723 0.0704 0.0693 0.0678 0.0673 0.0667 0.0666 0.0661 0.0662 0.0658 0.0661 

[TRAIN] Epoch[3](633/1500); Loss: 0.056990; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1276 0.0800 0.0628 0.0524 0.0541 0.0513 0.0493 0.0483 0.0484 0.0480 0.0482 0.0477 0.0483 0.0481 0.0486 0.0490 

[TRAIN] Epoch[3](634/1500); Loss: 0.104448; Backpropagation: 0.0989 sec; Batch: 0.4441 sec
0.3998 0.2367 0.1369 0.0693 0.0934 0.0696 0.0662 0.0662 0.0656 0.0664 0.0655 0.0660 0.0661 0.0671 0.0680 0.0684 

[TRAIN] Epoch[3](635/1500); Loss: 0.102899; Backpropagation: 0.0985 sec; Batch: 0.4782 sec
0.1655 0.1294 0.1083 0.1019 0.0982 0.0970 0.0963 0.0955 0.0950 0.0946 0.0945 0.0941 0.0943 0.0940 0.0939 0.0938 

[TRAIN] Epoch[3](636/1500); Loss: 0.125736; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2189 0.1494 0.1270 0.1199 0.1177 0.1172 0.1168 0.1170 0.1163 0.1159 0.1160 0.1158 0.1155 0.1159 0.1160 0.1164 

[TRAIN] Epoch[3](637/1500); Loss: 0.066250; Backpropagation: 0.0988 sec; Batch: 0.4333 sec
0.2416 0.0805 0.0679 0.0554 0.0552 0.0522 0.0517 0.0510 0.0506 0.0500 0.0501 0.0499 0.0506 0.0507 0.0510 0.0515 

[TRAIN] Epoch[3](638/1500); Loss: 0.077274; Backpropagation: 0.0974 sec; Batch: 0.4312 sec
0.1955 0.1198 0.0923 0.0740 0.0671 0.0653 0.0639 0.0632 0.0624 0.0619 0.0618 0.0618 0.0617 0.0619 0.0618 0.0619 

[TRAIN] Epoch[3](639/1500); Loss: 0.113336; Backpropagation: 0.0975 sec; Batch: 0.4318 sec
0.2016 0.1379 0.1201 0.1104 0.1063 0.1048 0.1039 0.1038 0.1031 0.1032 0.1028 0.1029 0.1029 0.1031 0.1032 0.1034 

[TRAIN] Epoch[3](640/1500); Loss: 0.142277; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.2339 0.1869 0.1586 0.1394 0.1345 0.1331 0.1315 0.1306 0.1300 0.1295 0.1290 0.1285 0.1282 0.1279 0.1276 0.1273 

[TRAIN] Epoch[3](641/1500); Loss: 0.046394; Backpropagation: 0.0984 sec; Batch: 0.4787 sec
0.0783 0.0677 0.0501 0.0466 0.0451 0.0433 0.0418 0.0406 0.0410 0.0404 0.0410 0.0406 0.0413 0.0411 0.0417 0.0418 

[TRAIN] Epoch[3](642/1500); Loss: 0.066965; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1057 0.0791 0.0743 0.0681 0.0670 0.0644 0.0629 0.0616 0.0612 0.0608 0.0610 0.0608 0.0610 0.0610 0.0613 0.0612 

[TRAIN] Epoch[3](643/1500); Loss: 0.093061; Backpropagation: 0.0988 sec; Batch: 0.4709 sec
0.2732 0.2233 0.1237 0.0825 0.0715 0.0671 0.0660 0.0652 0.0646 0.0639 0.0641 0.0641 0.0645 0.0644 0.0653 0.0657 

[TRAIN] Epoch[3](644/1500); Loss: 0.096341; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1586 0.1113 0.0960 0.0886 0.0907 0.0887 0.0886 0.0883 0.0887 0.0892 0.0900 0.0908 0.0913 0.0926 0.0936 0.0945 

[TRAIN] Epoch[3](645/1500); Loss: 0.099076; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1597 0.1107 0.1080 0.0977 0.0946 0.0938 0.0930 0.0926 0.0923 0.0920 0.0920 0.0916 0.0921 0.0915 0.0919 0.0917 

[TRAIN] Epoch[3](646/1500); Loss: 0.099229; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2928 0.1696 0.1156 0.0909 0.0855 0.0774 0.0762 0.0747 0.0746 0.0745 0.0750 0.0751 0.0758 0.0760 0.0770 0.0772 

[TRAIN] Epoch[3](647/1500); Loss: 0.064854; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.1154 0.0848 0.0665 0.0619 0.0610 0.0592 0.0591 0.0586 0.0587 0.0583 0.0586 0.0584 0.0590 0.0589 0.0596 0.0596 

[TRAIN] Epoch[3](648/1500); Loss: 0.087616; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.1424 0.1010 0.0928 0.0874 0.0841 0.0829 0.0821 0.0816 0.0814 0.0812 0.0810 0.0807 0.0808 0.0808 0.0808 0.0808 

[TRAIN] Epoch[3](649/1500); Loss: 0.097312; Backpropagation: 0.1025 sec; Batch: 0.4376 sec
0.1729 0.1132 0.1002 0.0934 0.0916 0.0900 0.0893 0.0888 0.0890 0.0889 0.0891 0.0895 0.0899 0.0902 0.0904 0.0905 

[TRAIN] Epoch[3](650/1500); Loss: 0.113771; Backpropagation: 0.0994 sec; Batch: 0.4337 sec
0.2389 0.1855 0.1418 0.1048 0.1032 0.0976 0.0969 0.0955 0.0953 0.0944 0.0946 0.0944 0.0945 0.0942 0.0945 0.0944 

[TRAIN] Epoch[3](651/1500); Loss: 0.053554; Backpropagation: 0.0999 sec; Batch: 0.4343 sec
0.1033 0.0642 0.0578 0.0527 0.0508 0.0492 0.0478 0.0485 0.0474 0.0477 0.0474 0.0477 0.0475 0.0480 0.0481 0.0489 

[TRAIN] Epoch[3](652/1500); Loss: 0.096949; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.1930 0.1343 0.1074 0.0930 0.0922 0.0890 0.0868 0.0856 0.0845 0.0844 0.0834 0.0838 0.0833 0.0835 0.0833 0.0836 

[TRAIN] Epoch[3](653/1500); Loss: 0.069588; Backpropagation: 0.0992 sec; Batch: 0.4343 sec
0.1307 0.0887 0.0742 0.0632 0.0639 0.0621 0.0606 0.0614 0.0626 0.0627 0.0636 0.0633 0.0641 0.0635 0.0645 0.0644 

[TRAIN] Epoch[3](654/1500); Loss: 0.089585; Backpropagation: 0.0992 sec; Batch: 0.4348 sec
0.1292 0.1109 0.0948 0.0896 0.0872 0.0860 0.0849 0.0845 0.0840 0.0839 0.0833 0.0833 0.0830 0.0831 0.0827 0.0829 

[TRAIN] Epoch[3](655/1500); Loss: 0.081877; Backpropagation: 0.0998 sec; Batch: 0.4356 sec
0.1133 0.0898 0.0846 0.0806 0.0809 0.0796 0.0791 0.0783 0.0782 0.0781 0.0779 0.0778 0.0780 0.0778 0.0780 0.0781 

[TRAIN] Epoch[3](656/1500); Loss: 0.067599; Backpropagation: 0.1024 sec; Batch: 0.4377 sec
0.1149 0.0846 0.0695 0.0664 0.0656 0.0640 0.0627 0.0624 0.0616 0.0615 0.0609 0.0616 0.0613 0.0615 0.0614 0.0618 

[TRAIN] Epoch[3](657/1500); Loss: 0.115348; Backpropagation: 0.0996 sec; Batch: 0.4350 sec
0.1407 0.1224 0.1168 0.1160 0.1141 0.1134 0.1128 0.1127 0.1122 0.1120 0.1119 0.1119 0.1119 0.1121 0.1123 0.1124 

[TRAIN] Epoch[3](658/1500); Loss: 0.116533; Backpropagation: 0.0988 sec; Batch: 0.4344 sec
0.1828 0.1538 0.1240 0.1155 0.1106 0.1095 0.1086 0.1074 0.1070 0.1067 0.1066 0.1064 0.1065 0.1064 0.1064 0.1063 

[TRAIN] Epoch[3](659/1500); Loss: 0.069608; Backpropagation: 0.0993 sec; Batch: 0.4350 sec
0.1343 0.0823 0.0687 0.0678 0.0636 0.0632 0.0628 0.0629 0.0629 0.0628 0.0635 0.0633 0.0637 0.0636 0.0640 0.0643 

[TRAIN] Epoch[3](660/1500); Loss: 0.125902; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.3515 0.2169 0.1356 0.1092 0.1157 0.1006 0.1002 0.0985 0.0976 0.0978 0.0974 0.0978 0.0983 0.0987 0.0990 0.0996 

[TRAIN] Epoch[3](661/1500); Loss: 0.078148; Backpropagation: 0.0989 sec; Batch: 0.4333 sec
0.2029 0.1214 0.0873 0.0735 0.0673 0.0655 0.0642 0.0638 0.0633 0.0631 0.0628 0.0629 0.0627 0.0632 0.0632 0.0633 

[TRAIN] Epoch[3](662/1500); Loss: 0.109334; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.1905 0.1416 0.1223 0.1038 0.1013 0.0997 0.0987 0.0987 0.0986 0.0988 0.0988 0.0990 0.0991 0.0994 0.0994 0.0997 

[TRAIN] Epoch[3](663/1500); Loss: 0.118889; Backpropagation: 0.0988 sec; Batch: 0.4334 sec
0.1645 0.1341 0.1197 0.1188 0.1160 0.1149 0.1141 0.1139 0.1135 0.1135 0.1134 0.1134 0.1130 0.1132 0.1130 0.1132 

[TRAIN] Epoch[3](664/1500); Loss: 0.125538; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.2109 0.1537 0.1262 0.1226 0.1188 0.1183 0.1174 0.1164 0.1159 0.1160 0.1157 0.1155 0.1154 0.1154 0.1152 0.1152 

[TRAIN] Epoch[3](665/1500); Loss: 0.126561; Backpropagation: 0.0987 sec; Batch: 0.4344 sec
0.2469 0.1671 0.1372 0.1186 0.1158 0.1147 0.1138 0.1129 0.1127 0.1125 0.1122 0.1122 0.1120 0.1121 0.1122 0.1121 

[TRAIN] Epoch[3](666/1500); Loss: 0.086024; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.1993 0.1233 0.0947 0.0800 0.0775 0.0759 0.0744 0.0738 0.0728 0.0723 0.0720 0.0720 0.0721 0.0721 0.0721 0.0720 

[TRAIN] Epoch[3](667/1500); Loss: 0.090029; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1833 0.1116 0.0937 0.0866 0.0839 0.0824 0.0812 0.0805 0.0802 0.0798 0.0799 0.0798 0.0794 0.0793 0.0795 0.0796 

[TRAIN] Epoch[3](668/1500); Loss: 0.125004; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1970 0.1530 0.1314 0.1219 0.1199 0.1184 0.1178 0.1169 0.1163 0.1159 0.1156 0.1152 0.1153 0.1150 0.1153 0.1152 

[TRAIN] Epoch[3](669/1500); Loss: 0.096819; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.2907 0.1717 0.1130 0.0863 0.0852 0.0782 0.0750 0.0737 0.0725 0.0722 0.0718 0.0716 0.0717 0.0717 0.0717 0.0719 

[TRAIN] Epoch[3](670/1500); Loss: 0.033563; Backpropagation: 0.0984 sec; Batch: 0.4339 sec
0.0799 0.0462 0.0438 0.0367 0.0327 0.0299 0.0276 0.0260 0.0262 0.0259 0.0259 0.0265 0.0267 0.0273 0.0272 0.0286 

[TRAIN] Epoch[3](671/1500); Loss: 0.069437; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.1306 0.0816 0.0731 0.0704 0.0634 0.0647 0.0632 0.0626 0.0620 0.0621 0.0621 0.0622 0.0624 0.0633 0.0636 0.0637 

[TRAIN] Epoch[3](672/1500); Loss: 0.090701; Backpropagation: 0.0996 sec; Batch: 0.4345 sec
0.2391 0.1309 0.0970 0.0839 0.0800 0.0771 0.0758 0.0754 0.0744 0.0740 0.0737 0.0737 0.0741 0.0740 0.0741 0.0741 

[TRAIN] Epoch[3](673/1500); Loss: 0.089527; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1701 0.1228 0.1129 0.0911 0.0821 0.0815 0.0798 0.0785 0.0775 0.0768 0.0768 0.0764 0.0766 0.0765 0.0765 0.0766 

[TRAIN] Epoch[3](674/1500); Loss: 0.115819; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.2292 0.1698 0.1241 0.1121 0.1065 0.1035 0.1016 0.1014 0.1005 0.1003 0.1001 0.1003 0.1007 0.1008 0.1010 0.1012 

[TRAIN] Epoch[3](675/1500); Loss: 0.167574; Backpropagation: 0.0990 sec; Batch: 0.4347 sec
0.2499 0.2191 0.1610 0.1596 0.1606 0.1573 0.1571 0.1571 0.1579 0.1574 0.1577 0.1567 0.1573 0.1575 0.1578 0.1571 

[TRAIN] Epoch[3](676/1500); Loss: 0.051350; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1666 0.0593 0.0624 0.0457 0.0445 0.0404 0.0396 0.0395 0.0397 0.0395 0.0395 0.0401 0.0403 0.0412 0.0414 0.0420 

[TRAIN] Epoch[3](677/1500); Loss: 0.128363; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.1900 0.1620 0.1354 0.1238 0.1241 0.1215 0.1215 0.1206 0.1206 0.1196 0.1196 0.1191 0.1191 0.1190 0.1192 0.1189 

[TRAIN] Epoch[3](678/1500); Loss: 0.089981; Backpropagation: 0.0996 sec; Batch: 0.4343 sec
0.1819 0.1087 0.0882 0.0854 0.0832 0.0816 0.0812 0.0808 0.0808 0.0806 0.0809 0.0810 0.0815 0.0813 0.0813 0.0814 

[TRAIN] Epoch[3](679/1500); Loss: 0.110909; Backpropagation: 0.0996 sec; Batch: 0.4351 sec
0.2785 0.1808 0.1310 0.1022 0.0956 0.0941 0.0920 0.0913 0.0896 0.0897 0.0887 0.0887 0.0882 0.0883 0.0879 0.0879 

[TRAIN] Epoch[3](680/1500); Loss: 0.097837; Backpropagation: 0.0995 sec; Batch: 0.4349 sec
0.1764 0.1192 0.0989 0.0921 0.0919 0.0900 0.0895 0.0894 0.0896 0.0895 0.0898 0.0899 0.0897 0.0895 0.0900 0.0901 

[TRAIN] Epoch[3](681/1500); Loss: 0.101518; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.1546 0.1321 0.1050 0.0997 0.0978 0.0961 0.0948 0.0943 0.0943 0.0940 0.0938 0.0935 0.0936 0.0934 0.0936 0.0937 

[TRAIN] Epoch[3](682/1500); Loss: 0.138786; Backpropagation: 0.0991 sec; Batch: 0.4397 sec
0.2621 0.1777 0.1510 0.1318 0.1282 0.1265 0.1258 0.1253 0.1249 0.1244 0.1241 0.1240 0.1237 0.1237 0.1237 0.1238 

[TRAIN] Epoch[3](683/1500); Loss: 0.058934; Backpropagation: 0.0985 sec; Batch: 0.4881 sec
0.1629 0.0791 0.0678 0.0592 0.0584 0.0517 0.0518 0.0489 0.0486 0.0458 0.0459 0.0445 0.0450 0.0442 0.0450 0.0442 

[TRAIN] Epoch[3](684/1500); Loss: 0.109463; Backpropagation: 0.0996 sec; Batch: 0.4344 sec
0.1613 0.1247 0.1126 0.1083 0.1064 0.1047 0.1039 0.1031 0.1031 0.1027 0.1030 0.1029 0.1033 0.1034 0.1038 0.1041 

[TRAIN] Epoch[3](685/1500); Loss: 0.073218; Backpropagation: 0.0994 sec; Batch: 0.4335 sec
0.1866 0.0938 0.0733 0.0676 0.0639 0.0629 0.0621 0.0618 0.0618 0.0621 0.0619 0.0627 0.0623 0.0628 0.0627 0.0633 

[TRAIN] Epoch[3](686/1500); Loss: 0.095993; Backpropagation: 0.0986 sec; Batch: 0.4339 sec
0.2299 0.1536 0.1007 0.0868 0.0833 0.0817 0.0813 0.0806 0.0798 0.0797 0.0798 0.0799 0.0800 0.0795 0.0798 0.0795 

[TRAIN] Epoch[3](687/1500); Loss: 0.092818; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.2299 0.1318 0.1045 0.0888 0.0819 0.0806 0.0786 0.0772 0.0766 0.0763 0.0763 0.0762 0.0763 0.0765 0.0767 0.0769 

[TRAIN] Epoch[3](688/1500); Loss: 0.089576; Backpropagation: 0.0984 sec; Batch: 0.4583 sec
0.2038 0.1177 0.0956 0.0843 0.0804 0.0798 0.0789 0.0781 0.0776 0.0771 0.0767 0.0766 0.0766 0.0766 0.0766 0.0768 

[TRAIN] Epoch[3](689/1500); Loss: 0.120615; Backpropagation: 0.1020 sec; Batch: 0.4377 sec
0.2112 0.1619 0.1185 0.1135 0.1126 0.1111 0.1101 0.1100 0.1099 0.1099 0.1097 0.1101 0.1099 0.1104 0.1104 0.1107 

[TRAIN] Epoch[3](690/1500); Loss: 0.041658; Backpropagation: 0.1026 sec; Batch: 0.4377 sec
0.0473 0.0661 0.0548 0.0437 0.0476 0.0438 0.0386 0.0366 0.0369 0.0362 0.0362 0.0354 0.0368 0.0357 0.0357 0.0354 

[TRAIN] Epoch[3](691/1500); Loss: 0.081804; Backpropagation: 0.1025 sec; Batch: 0.4378 sec
0.2630 0.1348 0.0833 0.0711 0.0730 0.0649 0.0626 0.0615 0.0612 0.0610 0.0616 0.0614 0.0620 0.0617 0.0629 0.0628 

[TRAIN] Epoch[3](692/1500); Loss: 0.106351; Backpropagation: 0.0975 sec; Batch: 0.4321 sec
0.1476 0.1153 0.1080 0.1032 0.1043 0.1029 0.1021 0.1018 0.1017 0.1017 0.1018 0.1021 0.1022 0.1023 0.1024 0.1023 

[TRAIN] Epoch[3](693/1500); Loss: 0.078653; Backpropagation: 0.0975 sec; Batch: 0.4327 sec
0.3324 0.1800 0.1115 0.0574 0.0513 0.0524 0.0490 0.0475 0.0472 0.0469 0.0471 0.0470 0.0471 0.0469 0.0473 0.0473 

[TRAIN] Epoch[3](694/1500); Loss: 0.048447; Backpropagation: 0.0981 sec; Batch: 0.4331 sec
0.0727 0.1164 0.0614 0.0426 0.0441 0.0412 0.0397 0.0392 0.0398 0.0392 0.0389 0.0396 0.0394 0.0400 0.0403 0.0407 

[TRAIN] Epoch[3](695/1500); Loss: 0.062025; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.0912 0.0738 0.0745 0.0644 0.0612 0.0591 0.0577 0.0573 0.0569 0.0566 0.0567 0.0564 0.0567 0.0566 0.0567 0.0566 

[TRAIN] Epoch[3](696/1500); Loss: 0.109594; Backpropagation: 0.0984 sec; Batch: 0.4725 sec
0.1906 0.1336 0.1151 0.1078 0.1047 0.1037 0.1023 0.1017 0.1003 0.0997 0.0992 0.0989 0.0988 0.0990 0.0991 0.0991 

[TRAIN] Epoch[3](697/1500); Loss: 0.101632; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.2068 0.1213 0.1029 0.0982 0.0944 0.0925 0.0917 0.0912 0.0908 0.0905 0.0904 0.0906 0.0908 0.0915 0.0911 0.0914 

[TRAIN] Epoch[3](698/1500); Loss: 0.056959; Backpropagation: 0.0986 sec; Batch: 0.4328 sec
0.1091 0.0843 0.0668 0.0564 0.0537 0.0513 0.0504 0.0496 0.0490 0.0488 0.0487 0.0487 0.0488 0.0486 0.0487 0.0486 

[TRAIN] Epoch[3](699/1500); Loss: 0.067655; Backpropagation: 0.1006 sec; Batch: 0.4353 sec
0.1046 0.0880 0.0811 0.0698 0.0642 0.0635 0.0622 0.0620 0.0611 0.0616 0.0609 0.0609 0.0605 0.0608 0.0604 0.0607 

[TRAIN] Epoch[3](700/1500); Loss: 0.079088; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.1091 0.0930 0.0834 0.0778 0.0756 0.0746 0.0740 0.0738 0.0741 0.0742 0.0746 0.0750 0.0756 0.0762 0.0769 0.0776 

[TRAIN] Epoch[3](701/1500); Loss: 0.136543; Backpropagation: 0.0995 sec; Batch: 0.4339 sec
0.2065 0.1582 0.1398 0.1327 0.1318 0.1302 0.1299 0.1292 0.1287 0.1284 0.1283 0.1283 0.1281 0.1282 0.1281 0.1284 

[TRAIN] Epoch[3](702/1500); Loss: 0.132979; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.2197 0.1634 0.1392 0.1302 0.1266 0.1254 0.1239 0.1234 0.1226 0.1223 0.1219 0.1219 0.1218 0.1217 0.1217 0.1219 

[TRAIN] Epoch[3](703/1500); Loss: 0.096801; Backpropagation: 0.0989 sec; Batch: 0.4342 sec
0.3003 0.1841 0.1177 0.0815 0.0835 0.0753 0.0729 0.0724 0.0710 0.0708 0.0698 0.0699 0.0697 0.0698 0.0700 0.0702 

[TRAIN] Epoch[3](704/1500); Loss: 0.113094; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.3793 0.2011 0.1187 0.0867 0.0945 0.0857 0.0832 0.0833 0.0836 0.0839 0.0842 0.0845 0.0847 0.0854 0.0851 0.0858 

[TRAIN] Epoch[3](705/1500); Loss: 0.125269; Backpropagation: 0.0987 sec; Batch: 0.4330 sec
0.1922 0.1459 0.1299 0.1239 0.1219 0.1202 0.1193 0.1186 0.1181 0.1176 0.1170 0.1166 0.1162 0.1159 0.1156 0.1154 

[TRAIN] Epoch[3](706/1500); Loss: 0.080600; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1462 0.1027 0.0936 0.0823 0.0760 0.0736 0.0725 0.0719 0.0713 0.0714 0.0711 0.0710 0.0709 0.0715 0.0717 0.0719 

[TRAIN] Epoch[3](707/1500); Loss: 0.069439; Backpropagation: 0.0988 sec; Batch: 0.4341 sec
0.1795 0.0809 0.0717 0.0648 0.0624 0.0609 0.0604 0.0597 0.0591 0.0587 0.0585 0.0585 0.0589 0.0587 0.0591 0.0593 

[TRAIN] Epoch[3](708/1500); Loss: 0.075501; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1755 0.0963 0.0787 0.0670 0.0672 0.0654 0.0649 0.0650 0.0647 0.0650 0.0651 0.0657 0.0659 0.0665 0.0672 0.0680 

[TRAIN] Epoch[3](709/1500); Loss: 0.075029; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1026 0.0864 0.0777 0.0753 0.0726 0.0717 0.0707 0.0706 0.0707 0.0710 0.0711 0.0715 0.0717 0.0720 0.0722 0.0727 

[TRAIN] Epoch[3](710/1500); Loss: 0.102436; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.2038 0.1233 0.1065 0.0976 0.0949 0.0944 0.0937 0.0934 0.0928 0.0925 0.0917 0.0916 0.0911 0.0909 0.0903 0.0904 

[TRAIN] Epoch[3](711/1500); Loss: 0.107743; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.2850 0.1760 0.1335 0.0970 0.0934 0.0887 0.0879 0.0868 0.0860 0.0851 0.0846 0.0838 0.0841 0.0840 0.0840 0.0839 

[TRAIN] Epoch[3](712/1500); Loss: 0.128694; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.2212 0.1733 0.1464 0.1259 0.1197 0.1177 0.1169 0.1160 0.1159 0.1155 0.1154 0.1151 0.1151 0.1151 0.1151 0.1149 

[TRAIN] Epoch[3](713/1500); Loss: 0.073353; Backpropagation: 0.1079 sec; Batch: 0.4426 sec
0.2332 0.1053 0.0784 0.0648 0.0621 0.0591 0.0576 0.0566 0.0566 0.0565 0.0564 0.0569 0.0568 0.0576 0.0576 0.0581 

[TRAIN] Epoch[3](714/1500); Loss: 0.093817; Backpropagation: 0.1027 sec; Batch: 0.4372 sec
0.1745 0.1211 0.1065 0.0946 0.0910 0.0880 0.0870 0.0856 0.0848 0.0832 0.0824 0.0815 0.0810 0.0803 0.0801 0.0795 

[TRAIN] Epoch[3](715/1500); Loss: 0.044324; Backpropagation: 0.0987 sec; Batch: 0.4330 sec
0.0697 0.0545 0.0542 0.0451 0.0447 0.0423 0.0404 0.0397 0.0398 0.0397 0.0397 0.0396 0.0398 0.0397 0.0402 0.0402 

[TRAIN] Epoch[3](716/1500); Loss: 0.088290; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.2842 0.2337 0.1088 0.0909 0.0612 0.0618 0.0596 0.0573 0.0570 0.0572 0.0569 0.0563 0.0565 0.0569 0.0569 0.0573 

[TRAIN] Epoch[3](717/1500); Loss: 0.160327; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2844 0.2497 0.1648 0.1486 0.1434 0.1433 0.1430 0.1416 0.1423 0.1423 0.1425 0.1430 0.1435 0.1438 0.1441 0.1446 

[TRAIN] Epoch[3](718/1500); Loss: 0.124105; Backpropagation: 0.0994 sec; Batch: 0.4335 sec
0.1609 0.1440 0.1340 0.1273 0.1218 0.1203 0.1196 0.1190 0.1186 0.1183 0.1178 0.1172 0.1171 0.1168 0.1166 0.1165 

[TRAIN] Epoch[3](719/1500); Loss: 0.114867; Backpropagation: 0.0995 sec; Batch: 0.4336 sec
0.2630 0.1806 0.1326 0.1065 0.0987 0.0982 0.0969 0.0964 0.0957 0.0959 0.0953 0.0954 0.0954 0.0959 0.0957 0.0958 

[TRAIN] Epoch[3](720/1500); Loss: 0.079707; Backpropagation: 0.0990 sec; Batch: 0.4343 sec
0.2461 0.1388 0.0974 0.0702 0.0654 0.0617 0.0607 0.0599 0.0599 0.0591 0.0594 0.0589 0.0594 0.0591 0.0596 0.0596 

[TRAIN] Epoch[3](721/1500); Loss: 0.095961; Backpropagation: 0.0989 sec; Batch: 0.4345 sec
0.1918 0.1075 0.0958 0.0930 0.0886 0.0884 0.0879 0.0875 0.0872 0.0869 0.0868 0.0867 0.0867 0.0868 0.0868 0.0868 

[TRAIN] Epoch[3](722/1500); Loss: 0.058526; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.0825 0.0848 0.0598 0.0567 0.0537 0.0538 0.0528 0.0530 0.0533 0.0540 0.0543 0.0547 0.0551 0.0556 0.0559 0.0564 

[TRAIN] Epoch[3](723/1500); Loss: 0.098671; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1383 0.1148 0.1031 0.0973 0.0969 0.0953 0.0948 0.0942 0.0938 0.0936 0.0933 0.0930 0.0927 0.0926 0.0926 0.0925 

[TRAIN] Epoch[3](724/1500); Loss: 0.073350; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.2888 0.1416 0.0872 0.0555 0.0544 0.0496 0.0492 0.0496 0.0491 0.0494 0.0497 0.0498 0.0493 0.0502 0.0497 0.0504 

[TRAIN] Epoch[3](725/1500); Loss: 0.115195; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1789 0.1291 0.1224 0.1191 0.1131 0.1102 0.1087 0.1081 0.1073 0.1073 0.1068 0.1067 0.1065 0.1063 0.1061 0.1065 

[TRAIN] Epoch[3](726/1500); Loss: 0.122562; Backpropagation: 0.0995 sec; Batch: 0.4361 sec
0.2333 0.1829 0.1466 0.1220 0.1137 0.1113 0.1098 0.1080 0.1067 0.1059 0.1049 0.1044 0.1036 0.1029 0.1028 0.1022 

[TRAIN] Epoch[3](727/1500); Loss: 0.159259; Backpropagation: 0.0987 sec; Batch: 0.4346 sec
0.2506 0.1958 0.1768 0.1622 0.1538 0.1507 0.1489 0.1477 0.1468 0.1461 0.1459 0.1453 0.1448 0.1446 0.1442 0.1438 

[TRAIN] Epoch[3](728/1500); Loss: 0.063450; Backpropagation: 0.0993 sec; Batch: 0.4349 sec
0.1450 0.1006 0.0757 0.0705 0.0586 0.0547 0.0534 0.0521 0.0517 0.0512 0.0508 0.0503 0.0501 0.0501 0.0502 0.0503 

[TRAIN] Epoch[3](729/1500); Loss: 0.124936; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.2479 0.1671 0.1369 0.1163 0.1161 0.1128 0.1117 0.1110 0.1105 0.1103 0.1098 0.1098 0.1096 0.1098 0.1096 0.1097 

[TRAIN] Epoch[3](730/1500); Loss: 0.121947; Backpropagation: 0.1009 sec; Batch: 0.4362 sec
0.2314 0.1797 0.1458 0.1185 0.1135 0.1097 0.1082 0.1070 0.1062 0.1057 0.1050 0.1046 0.1042 0.1041 0.1038 0.1038 

[TRAIN] Epoch[3](731/1500); Loss: 0.098746; Backpropagation: 0.0994 sec; Batch: 0.4342 sec
0.2618 0.1408 0.1034 0.0944 0.0896 0.0855 0.0830 0.0823 0.0812 0.0809 0.0801 0.0800 0.0795 0.0793 0.0790 0.0792 

[TRAIN] Epoch[3](732/1500); Loss: 0.110072; Backpropagation: 0.0992 sec; Batch: 0.4338 sec
0.1916 0.1360 0.1190 0.1078 0.1052 0.1034 0.1017 0.1008 0.1002 0.1000 0.1000 0.0997 0.0992 0.0992 0.0989 0.0986 

[TRAIN] Epoch[3](733/1500); Loss: 0.084044; Backpropagation: 0.0995 sec; Batch: 0.4351 sec
0.4404 0.2442 0.1281 0.0405 0.0584 0.0444 0.0404 0.0396 0.0384 0.0382 0.0378 0.0380 0.0390 0.0388 0.0390 0.0394 

[TRAIN] Epoch[3](734/1500); Loss: 0.095327; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1588 0.1062 0.0968 0.0913 0.0907 0.0889 0.0886 0.0883 0.0882 0.0882 0.0884 0.0890 0.0895 0.0901 0.0907 0.0915 

[TRAIN] Epoch[3](735/1500); Loss: 0.056553; Backpropagation: 0.0990 sec; Batch: 0.4333 sec
0.0991 0.0759 0.0675 0.0649 0.0558 0.0522 0.0505 0.0499 0.0489 0.0490 0.0487 0.0486 0.0484 0.0484 0.0484 0.0487 

[TRAIN] Epoch[3](736/1500); Loss: 0.090635; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.1526 0.1096 0.0941 0.0878 0.0860 0.0852 0.0843 0.0834 0.0835 0.0833 0.0835 0.0831 0.0835 0.0834 0.0835 0.0832 

[TRAIN] Epoch[3](737/1500); Loss: 0.104416; Backpropagation: 0.0984 sec; Batch: 0.4338 sec
0.1629 0.1176 0.1071 0.1022 0.1013 0.1003 0.0990 0.0983 0.0979 0.0976 0.0976 0.0977 0.0977 0.0977 0.0978 0.0979 

[TRAIN] Epoch[3](738/1500); Loss: 0.110481; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.2181 0.1700 0.1368 0.1224 0.1085 0.0990 0.0925 0.0905 0.0897 0.0900 0.0899 0.0908 0.0910 0.0922 0.0923 0.0939 

[TRAIN] Epoch[3](739/1500); Loss: 0.133500; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1881 0.1392 0.1344 0.1310 0.1296 0.1291 0.1286 0.1285 0.1285 0.1284 0.1284 0.1283 0.1283 0.1285 0.1285 0.1287 

[TRAIN] Epoch[3](740/1500); Loss: 0.096483; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1899 0.1114 0.0982 0.0931 0.0905 0.0893 0.0882 0.0875 0.0870 0.0873 0.0870 0.0868 0.0868 0.0869 0.0869 0.0867 

[TRAIN] Epoch[3](741/1500); Loss: 0.147596; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.2307 0.1646 0.1571 0.1469 0.1427 0.1417 0.1407 0.1396 0.1387 0.1381 0.1377 0.1372 0.1369 0.1365 0.1363 0.1361 

[TRAIN] Epoch[3](742/1500); Loss: 0.102363; Backpropagation: 0.1004 sec; Batch: 0.4349 sec
0.3607 0.2459 0.1783 0.1156 0.0693 0.0662 0.0598 0.0601 0.0604 0.0595 0.0600 0.0599 0.0602 0.0601 0.0607 0.0611 

[TRAIN] Epoch[3](743/1500); Loss: 0.096811; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.1529 0.1087 0.1015 0.0945 0.0940 0.0925 0.0910 0.0900 0.0899 0.0900 0.0902 0.0904 0.0906 0.0907 0.0910 0.0910 

[TRAIN] Epoch[3](744/1500); Loss: 0.079260; Backpropagation: 0.0993 sec; Batch: 0.4337 sec
0.3485 0.1875 0.1145 0.0702 0.0543 0.0507 0.0476 0.0451 0.0447 0.0437 0.0436 0.0435 0.0435 0.0432 0.0435 0.0440 

[TRAIN] Epoch[3](745/1500); Loss: 0.029490; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.0650 0.0419 0.0490 0.0377 0.0327 0.0264 0.0232 0.0218 0.0217 0.0212 0.0212 0.0210 0.0220 0.0219 0.0224 0.0227 

[TRAIN] Epoch[3](746/1500); Loss: 0.062542; Backpropagation: 0.0985 sec; Batch: 0.4326 sec
0.1277 0.0823 0.0681 0.0600 0.0576 0.0567 0.0556 0.0555 0.0551 0.0552 0.0544 0.0545 0.0543 0.0544 0.0544 0.0548 

[TRAIN] Epoch[3](747/1500); Loss: 0.121417; Backpropagation: 0.1000 sec; Batch: 0.4356 sec
0.1990 0.1547 0.1351 0.1214 0.1142 0.1128 0.1119 0.1113 0.1111 0.1107 0.1106 0.1104 0.1103 0.1100 0.1097 0.1095 

[TRAIN] Epoch[3](748/1500); Loss: 0.119608; Backpropagation: 0.1080 sec; Batch: 0.4435 sec
0.1614 0.1377 0.1230 0.1201 0.1174 0.1165 0.1158 0.1154 0.1150 0.1144 0.1136 0.1133 0.1130 0.1126 0.1124 0.1122 

[TRAIN] Epoch[3](749/1500); Loss: 0.087824; Backpropagation: 0.1080 sec; Batch: 0.4436 sec
0.3783 0.1847 0.0915 0.0768 0.0652 0.0591 0.0561 0.0566 0.0545 0.0549 0.0539 0.0543 0.0542 0.0548 0.0548 0.0553 

[TRAIN] Epoch[3](750/1500); Loss: 0.166460; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.2212 0.1728 0.1687 0.1652 0.1643 0.1630 0.1624 0.1620 0.1614 0.1610 0.1606 0.1605 0.1602 0.1602 0.1599 0.1599 

[TRAIN] Epoch[3](751/1500); Loss: 0.121109; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2199 0.1444 0.1254 0.1175 0.1162 0.1135 0.1122 0.1112 0.1105 0.1100 0.1099 0.1097 0.1095 0.1093 0.1092 0.1093 

[TRAIN] Epoch[3](752/1500); Loss: 0.085264; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.2217 0.1391 0.1061 0.0734 0.0738 0.0689 0.0688 0.0686 0.0683 0.0679 0.0679 0.0681 0.0680 0.0679 0.0679 0.0680 

[TRAIN] Epoch[3](753/1500); Loss: 0.084028; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.1204 0.0913 0.0844 0.0829 0.0815 0.0810 0.0807 0.0805 0.0804 0.0804 0.0802 0.0800 0.0801 0.0802 0.0802 0.0803 

[TRAIN] Epoch[3](754/1500); Loss: 0.035572; Backpropagation: 0.0993 sec; Batch: 0.4344 sec
0.0527 0.0533 0.0468 0.0393 0.0357 0.0335 0.0322 0.0314 0.0310 0.0305 0.0304 0.0303 0.0305 0.0303 0.0307 0.0306 

[TRAIN] Epoch[3](755/1500); Loss: 0.061601; Backpropagation: 0.0983 sec; Batch: 0.4453 sec
0.0961 0.0656 0.0588 0.0576 0.0564 0.0563 0.0574 0.0588 0.0581 0.0586 0.0595 0.0596 0.0602 0.0601 0.0609 0.0617 

[TRAIN] Epoch[3](756/1500); Loss: 0.077831; Backpropagation: 0.0983 sec; Batch: 0.4382 sec
0.1531 0.1139 0.0807 0.0750 0.0717 0.0704 0.0691 0.0684 0.0679 0.0680 0.0678 0.0678 0.0676 0.0678 0.0679 0.0681 

[TRAIN] Epoch[3](757/1500); Loss: 0.154538; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1932 0.1631 0.1580 0.1537 0.1553 0.1539 0.1517 0.1503 0.1498 0.1493 0.1494 0.1493 0.1493 0.1489 0.1486 0.1487 

[TRAIN] Epoch[3](758/1500); Loss: 0.101944; Backpropagation: 0.0982 sec; Batch: 0.4324 sec
0.2043 0.1717 0.1262 0.1000 0.0910 0.0887 0.0876 0.0863 0.0856 0.0850 0.0846 0.0842 0.0839 0.0840 0.0839 0.0841 

[TRAIN] Epoch[3](759/1500); Loss: 0.079789; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.1671 0.1026 0.0802 0.0812 0.0734 0.0721 0.0708 0.0707 0.0698 0.0696 0.0700 0.0696 0.0697 0.0702 0.0698 0.0698 

[TRAIN] Epoch[3](760/1500); Loss: 0.098345; Backpropagation: 0.0993 sec; Batch: 0.4344 sec
0.2056 0.1272 0.1020 0.1019 0.0927 0.0894 0.0874 0.0862 0.0857 0.0853 0.0850 0.0848 0.0848 0.0850 0.0852 0.0854 

[TRAIN] Epoch[3](761/1500); Loss: 0.115924; Backpropagation: 0.0991 sec; Batch: 0.4342 sec
0.1710 0.1254 0.1186 0.1170 0.1130 0.1119 0.1111 0.1106 0.1100 0.1097 0.1094 0.1094 0.1094 0.1094 0.1094 0.1093 

[TRAIN] Epoch[3](762/1500); Loss: 0.077469; Backpropagation: 0.0992 sec; Batch: 0.4336 sec
0.1852 0.1038 0.0924 0.0754 0.0777 0.0717 0.0682 0.0671 0.0652 0.0640 0.0628 0.0624 0.0619 0.0613 0.0603 0.0602 

[TRAIN] Epoch[3](763/1500); Loss: 0.135559; Backpropagation: 0.0986 sec; Batch: 0.4328 sec
0.1793 0.1479 0.1373 0.1342 0.1324 0.1317 0.1314 0.1312 0.1309 0.1306 0.1305 0.1304 0.1303 0.1303 0.1302 0.1302 

[TRAIN] Epoch[3](764/1500); Loss: 0.095542; Backpropagation: 0.0994 sec; Batch: 0.4340 sec
0.2382 0.1489 0.1121 0.0888 0.0854 0.0820 0.0806 0.0794 0.0785 0.0777 0.0771 0.0767 0.0761 0.0759 0.0757 0.0757 

[TRAIN] Epoch[3](765/1500); Loss: 0.055295; Backpropagation: 0.0994 sec; Batch: 0.4343 sec
0.1088 0.0744 0.0606 0.0521 0.0513 0.0499 0.0489 0.0487 0.0486 0.0484 0.0484 0.0487 0.0486 0.0489 0.0491 0.0493 

[TRAIN] Epoch[3](766/1500); Loss: 0.174282; Backpropagation: 0.0991 sec; Batch: 0.4334 sec
0.2532 0.2095 0.1636 0.1716 0.1674 0.1687 0.1671 0.1670 0.1663 0.1665 0.1656 0.1655 0.1645 0.1641 0.1637 0.1640 

[TRAIN] Epoch[3](767/1500); Loss: 0.100602; Backpropagation: 0.0988 sec; Batch: 0.4344 sec
0.2283 0.1362 0.1075 0.0910 0.0949 0.0899 0.0878 0.0863 0.0858 0.0854 0.0856 0.0856 0.0859 0.0861 0.0866 0.0868 

[TRAIN] Epoch[3](768/1500); Loss: 0.150859; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1888 0.1599 0.1531 0.1511 0.1484 0.1476 0.1471 0.1468 0.1464 0.1462 0.1463 0.1464 0.1463 0.1463 0.1465 0.1466 

[TRAIN] Epoch[3](769/1500); Loss: 0.072358; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.3536 0.1604 0.0921 0.0447 0.0521 0.0437 0.0411 0.0422 0.0404 0.0412 0.0399 0.0405 0.0410 0.0410 0.0419 0.0418 

[TRAIN] Epoch[3](770/1500); Loss: 0.090526; Backpropagation: 0.0981 sec; Batch: 0.4325 sec
0.1842 0.1219 0.0948 0.0859 0.0845 0.0812 0.0807 0.0798 0.0798 0.0795 0.0796 0.0793 0.0794 0.0791 0.0794 0.0795 

[TRAIN] Epoch[3](771/1500); Loss: 0.084420; Backpropagation: 0.0992 sec; Batch: 0.4345 sec
0.1805 0.1381 0.1050 0.0872 0.0774 0.0739 0.0720 0.0709 0.0695 0.0690 0.0682 0.0679 0.0677 0.0678 0.0677 0.0680 

[TRAIN] Epoch[3](772/1500); Loss: 0.081909; Backpropagation: 0.0992 sec; Batch: 0.4344 sec
0.2573 0.1318 0.0951 0.0734 0.0761 0.0657 0.0635 0.0614 0.0612 0.0604 0.0604 0.0602 0.0605 0.0607 0.0612 0.0615 

[TRAIN] Epoch[3](773/1500); Loss: 0.166003; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.2672 0.2085 0.1846 0.1686 0.1605 0.1574 0.1552 0.1538 0.1525 0.1513 0.1504 0.1501 0.1496 0.1492 0.1488 0.1484 

[TRAIN] Epoch[3](774/1500); Loss: 0.121259; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.2854 0.1887 0.1361 0.1104 0.1078 0.1035 0.1029 0.1022 0.1010 0.1005 0.1004 0.1004 0.1001 0.1000 0.1004 0.1004 

[TRAIN] Epoch[3](775/1500); Loss: 0.097544; Backpropagation: 0.0986 sec; Batch: 0.4330 sec
0.1761 0.1238 0.1030 0.0950 0.0914 0.0902 0.0894 0.0885 0.0879 0.0877 0.0878 0.0879 0.0879 0.0878 0.0881 0.0882 

[TRAIN] Epoch[3](776/1500); Loss: 0.088529; Backpropagation: 0.0990 sec; Batch: 0.4331 sec
0.2011 0.1221 0.1039 0.0867 0.0793 0.0768 0.0756 0.0755 0.0747 0.0745 0.0741 0.0743 0.0742 0.0743 0.0746 0.0749 

[TRAIN] Epoch[3](777/1500); Loss: 0.040649; Backpropagation: 0.1026 sec; Batch: 0.4439 sec
0.0764 0.0491 0.0523 0.0450 0.0404 0.0379 0.0363 0.0355 0.0351 0.0349 0.0345 0.0345 0.0345 0.0346 0.0347 0.0348 

[TRAIN] Epoch[3](778/1500); Loss: 0.124905; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1673 0.1424 0.1300 0.1230 0.1202 0.1197 0.1193 0.1193 0.1191 0.1192 0.1191 0.1194 0.1195 0.1200 0.1204 0.1206 

[TRAIN] Epoch[3](779/1500); Loss: 0.081430; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.4622 0.2586 0.1265 0.0334 0.0532 0.0352 0.0361 0.0347 0.0325 0.0321 0.0325 0.0329 0.0328 0.0329 0.0333 0.0340 

[TRAIN] Epoch[3](780/1500); Loss: 0.078734; Backpropagation: 0.0985 sec; Batch: 0.4326 sec
0.2350 0.1339 0.0915 0.0657 0.0678 0.0614 0.0609 0.0604 0.0606 0.0604 0.0600 0.0599 0.0600 0.0604 0.0608 0.0611 

[TRAIN] Epoch[3](781/1500); Loss: 0.070406; Backpropagation: 0.0989 sec; Batch: 0.4340 sec
0.1476 0.0901 0.0782 0.0662 0.0650 0.0632 0.0623 0.0615 0.0612 0.0610 0.0609 0.0612 0.0614 0.0616 0.0623 0.0627 

[TRAIN] Epoch[3](782/1500); Loss: 0.127548; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.2278 0.1594 0.1313 0.1260 0.1206 0.1186 0.1176 0.1167 0.1158 0.1158 0.1155 0.1150 0.1151 0.1151 0.1152 0.1152 

[TRAIN] Epoch[3](783/1500); Loss: 0.137728; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.2287 0.1650 0.1466 0.1410 0.1329 0.1298 0.1279 0.1264 0.1261 0.1258 0.1255 0.1256 0.1255 0.1255 0.1257 0.1257 

[TRAIN] Epoch[3](784/1500); Loss: 0.091940; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.2456 0.1540 0.1212 0.0936 0.0794 0.0747 0.0735 0.0728 0.0713 0.0702 0.0696 0.0693 0.0688 0.0689 0.0689 0.0691 

[TRAIN] Epoch[3](785/1500); Loss: 0.099481; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.2483 0.1401 0.1122 0.1001 0.0869 0.0844 0.0832 0.0831 0.0822 0.0816 0.0808 0.0811 0.0813 0.0818 0.0821 0.0826 

[TRAIN] Epoch[3](786/1500); Loss: 0.110326; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.2801 0.1544 0.1093 0.1225 0.0961 0.0955 0.0934 0.0918 0.0911 0.0905 0.0903 0.0900 0.0901 0.0899 0.0901 0.0901 

[TRAIN] Epoch[3](787/1500); Loss: 0.124801; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.1704 0.1383 0.1338 0.1206 0.1194 0.1188 0.1186 0.1185 0.1186 0.1190 0.1193 0.1194 0.1199 0.1205 0.1209 0.1210 

[TRAIN] Epoch[3](788/1500); Loss: 0.079104; Backpropagation: 0.1025 sec; Batch: 0.4384 sec
0.3805 0.1832 0.1112 0.0558 0.0644 0.0517 0.0476 0.0439 0.0416 0.0414 0.0402 0.0406 0.0401 0.0408 0.0408 0.0419 

[TRAIN] Epoch[3](789/1500); Loss: 0.097791; Backpropagation: 0.0995 sec; Batch: 0.4352 sec
0.2589 0.1515 0.1191 0.1085 0.0846 0.0819 0.0806 0.0794 0.0776 0.0764 0.0752 0.0748 0.0746 0.0739 0.0738 0.0740 

[TRAIN] Epoch[3](790/1500); Loss: 0.111812; Backpropagation: 0.0992 sec; Batch: 0.4338 sec
0.2611 0.1747 0.1325 0.1057 0.1013 0.0961 0.0946 0.0932 0.0926 0.0921 0.0915 0.0909 0.0907 0.0907 0.0907 0.0906 

[TRAIN] Epoch[3](791/1500); Loss: 0.151999; Backpropagation: 0.0993 sec; Batch: 0.4343 sec
0.2564 0.2059 0.1802 0.1581 0.1447 0.1431 0.1401 0.1389 0.1366 0.1347 0.1336 0.1325 0.1321 0.1319 0.1317 0.1314 

[TRAIN] Epoch[3](792/1500); Loss: 0.081884; Backpropagation: 0.0993 sec; Batch: 0.4337 sec
0.1668 0.1006 0.0997 0.0855 0.0745 0.0736 0.0721 0.0719 0.0712 0.0710 0.0705 0.0705 0.0705 0.0704 0.0705 0.0707 

[TRAIN] Epoch[3](793/1500); Loss: 0.108473; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.1758 0.1487 0.1166 0.1140 0.1073 0.1039 0.1006 0.0987 0.0974 0.0966 0.0959 0.0959 0.0958 0.0960 0.0960 0.0963 

[TRAIN] Epoch[3](794/1500); Loss: 0.102419; Backpropagation: 0.0993 sec; Batch: 0.4348 sec
0.1954 0.1185 0.1082 0.1013 0.0952 0.0942 0.0936 0.0932 0.0928 0.0925 0.0924 0.0923 0.0923 0.0921 0.0922 0.0925 

[TRAIN] Epoch[3](795/1500); Loss: 0.104502; Backpropagation: 0.0990 sec; Batch: 0.4338 sec
0.2552 0.1443 0.1175 0.1073 0.0932 0.0913 0.0898 0.0881 0.0868 0.0864 0.0862 0.0856 0.0852 0.0851 0.0849 0.0850 

[TRAIN] Epoch[3](796/1500); Loss: 0.119029; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1449 0.1345 0.1272 0.1195 0.1178 0.1170 0.1163 0.1156 0.1146 0.1144 0.1140 0.1140 0.1137 0.1138 0.1136 0.1136 

[TRAIN] Epoch[3](797/1500); Loss: 0.155515; Backpropagation: 0.0983 sec; Batch: 0.4323 sec
0.2453 0.1952 0.1708 0.1573 0.1492 0.1473 0.1459 0.1443 0.1432 0.1424 0.1420 0.1418 0.1416 0.1410 0.1405 0.1404 

[TRAIN] Epoch[3](798/1500); Loss: 0.146349; Backpropagation: 0.0985 sec; Batch: 0.4340 sec
0.2021 0.1569 0.1511 0.1478 0.1438 0.1433 0.1420 0.1409 0.1400 0.1395 0.1393 0.1393 0.1391 0.1388 0.1388 0.1389 

[TRAIN] Epoch[3](799/1500); Loss: 0.069877; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1662 0.1228 0.0763 0.0697 0.0652 0.0629 0.0604 0.0575 0.0552 0.0545 0.0543 0.0543 0.0544 0.0545 0.0548 0.0551 

[TRAIN] Epoch[3](800/1500); Loss: 0.122045; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.2284 0.1466 0.1374 0.1258 0.1147 0.1137 0.1118 0.1109 0.1103 0.1093 0.1084 0.1077 0.1073 0.1070 0.1067 0.1069 

[TRAIN] Epoch[3](801/1500); Loss: 0.130853; Backpropagation: 0.0996 sec; Batch: 0.4352 sec
0.2726 0.1882 0.1312 0.1368 0.1270 0.1209 0.1161 0.1132 0.1114 0.1106 0.1106 0.1107 0.1108 0.1109 0.1112 0.1117 

[TRAIN] Epoch[3](802/1500); Loss: 0.091396; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1709 0.1162 0.1006 0.0884 0.0868 0.0849 0.0836 0.0828 0.0819 0.0813 0.0810 0.0808 0.0806 0.0806 0.0808 0.0811 

[TRAIN] Epoch[3](803/1500); Loss: 0.141823; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2837 0.2086 0.1685 0.1387 0.1297 0.1266 0.1251 0.1236 0.1226 0.1220 0.1210 0.1202 0.1200 0.1197 0.1197 0.1196 

[TRAIN] Epoch[3](804/1500); Loss: 0.117974; Backpropagation: 0.0989 sec; Batch: 0.4337 sec
0.2507 0.1764 0.1137 0.1399 0.1201 0.1094 0.1027 0.0997 0.0980 0.0968 0.0965 0.0962 0.0964 0.0969 0.0971 0.0971 

[TRAIN] Epoch[3](805/1500); Loss: 0.093051; Backpropagation: 0.0985 sec; Batch: 0.4344 sec
0.2277 0.1405 0.1081 0.0945 0.0864 0.0816 0.0786 0.0772 0.0759 0.0750 0.0743 0.0738 0.0738 0.0739 0.0738 0.0737 

[TRAIN] Epoch[3](806/1500); Loss: 0.114596; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.2627 0.1807 0.1487 0.1143 0.1008 0.0977 0.0964 0.0950 0.0938 0.0927 0.0923 0.0920 0.0916 0.0915 0.0915 0.0918 

[TRAIN] Epoch[3](807/1500); Loss: 0.067897; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.0934 0.0911 0.0746 0.0690 0.0664 0.0644 0.0634 0.0628 0.0627 0.0624 0.0623 0.0623 0.0625 0.0627 0.0630 0.0634 

[TRAIN] Epoch[3](808/1500); Loss: 0.075132; Backpropagation: 0.0993 sec; Batch: 0.4343 sec
0.1182 0.1210 0.0838 0.0726 0.0694 0.0672 0.0668 0.0662 0.0661 0.0663 0.0664 0.0668 0.0671 0.0677 0.0681 0.0684 

[TRAIN] Epoch[3](809/1500); Loss: 0.100824; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1967 0.1285 0.1234 0.0972 0.0919 0.0918 0.0894 0.0886 0.0883 0.0882 0.0882 0.0880 0.0880 0.0881 0.0884 0.0886 

[TRAIN] Epoch[3](810/1500); Loss: 0.154218; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2185 0.1900 0.1660 0.1562 0.1523 0.1502 0.1480 0.1462 0.1450 0.1438 0.1428 0.1422 0.1419 0.1416 0.1414 0.1413 

[TRAIN] Epoch[3](811/1500); Loss: 0.085800; Backpropagation: 0.0986 sec; Batch: 0.4340 sec
0.1436 0.0950 0.0881 0.0829 0.0817 0.0805 0.0797 0.0795 0.0796 0.0796 0.0798 0.0802 0.0804 0.0806 0.0807 0.0808 

[TRAIN] Epoch[3](812/1500); Loss: 0.101874; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1682 0.1388 0.1123 0.1031 0.0983 0.0951 0.0930 0.0914 0.0906 0.0902 0.0902 0.0907 0.0911 0.0918 0.0923 0.0928 

[TRAIN] Epoch[3](813/1500); Loss: 0.119617; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.2807 0.1769 0.1301 0.1076 0.1035 0.1025 0.1015 0.1006 0.1003 0.1011 0.1013 0.1017 0.1017 0.1014 0.1015 0.1015 

[TRAIN] Epoch[3](814/1500); Loss: 0.099967; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2207 0.1302 0.1097 0.0969 0.0897 0.0889 0.0878 0.0868 0.0866 0.0859 0.0858 0.0855 0.0856 0.0858 0.0864 0.0872 

[TRAIN] Epoch[3](815/1500); Loss: 0.101219; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.2270 0.1504 0.1101 0.1030 0.0951 0.0910 0.0893 0.0869 0.0859 0.0843 0.0835 0.0829 0.0826 0.0826 0.0826 0.0825 

[TRAIN] Epoch[3](816/1500); Loss: 0.098335; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1720 0.1519 0.1083 0.0962 0.0916 0.0894 0.0873 0.0859 0.0853 0.0855 0.0858 0.0860 0.0864 0.0869 0.0872 0.0877 

[TRAIN] Epoch[3](817/1500); Loss: 0.095166; Backpropagation: 0.0994 sec; Batch: 0.4342 sec
0.1140 0.1021 0.0969 0.0951 0.0940 0.0928 0.0923 0.0922 0.0925 0.0926 0.0927 0.0926 0.0928 0.0931 0.0933 0.0935 

[TRAIN] Epoch[3](818/1500); Loss: 0.119356; Backpropagation: 0.0992 sec; Batch: 0.4349 sec
0.1637 0.1439 0.1252 0.1224 0.1183 0.1160 0.1142 0.1132 0.1127 0.1121 0.1116 0.1114 0.1112 0.1111 0.1112 0.1114 

[TRAIN] Epoch[3](819/1500); Loss: 0.077604; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.1064 0.0815 0.0771 0.0813 0.0772 0.0756 0.0757 0.0753 0.0748 0.0739 0.0741 0.0739 0.0738 0.0738 0.0738 0.0735 

[TRAIN] Epoch[3](820/1500); Loss: 0.116926; Backpropagation: 0.0993 sec; Batch: 0.4336 sec
0.3260 0.2174 0.1590 0.1145 0.0989 0.0908 0.0880 0.0862 0.0850 0.0851 0.0854 0.0859 0.0864 0.0868 0.0873 0.0881 

[TRAIN] Epoch[3](821/1500); Loss: 0.145838; Backpropagation: 0.0987 sec; Batch: 0.4470 sec
0.1966 0.1642 0.1544 0.1461 0.1422 0.1409 0.1397 0.1393 0.1392 0.1390 0.1388 0.1389 0.1386 0.1384 0.1384 0.1387 

[TRAIN] Epoch[3](822/1500); Loss: 0.108107; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1873 0.1283 0.1195 0.1117 0.1024 0.1009 0.0996 0.0984 0.0971 0.0971 0.0971 0.0976 0.0977 0.0980 0.0983 0.0988 

[TRAIN] Epoch[3](823/1500); Loss: 0.075040; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.1432 0.1416 0.0913 0.0739 0.0684 0.0655 0.0636 0.0626 0.0621 0.0616 0.0613 0.0611 0.0610 0.0610 0.0613 0.0612 

[TRAIN] Epoch[3](824/1500); Loss: 0.081181; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.1512 0.1032 0.0920 0.0817 0.0761 0.0743 0.0727 0.0721 0.0717 0.0716 0.0717 0.0717 0.0718 0.0721 0.0725 0.0726 

[TRAIN] Epoch[3](825/1500); Loss: 0.149710; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.2397 0.1758 0.1546 0.1493 0.1438 0.1422 0.1413 0.1400 0.1394 0.1389 0.1387 0.1387 0.1384 0.1381 0.1381 0.1382 

[TRAIN] Epoch[3](826/1500); Loss: 0.068030; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1682 0.0987 0.0796 0.0618 0.0602 0.0585 0.0566 0.0559 0.0557 0.0561 0.0562 0.0559 0.0558 0.0562 0.0563 0.0568 

[TRAIN] Epoch[3](827/1500); Loss: 0.091832; Backpropagation: 0.0990 sec; Batch: 0.4338 sec
0.2644 0.1583 0.1154 0.0837 0.0745 0.0729 0.0715 0.0711 0.0703 0.0694 0.0694 0.0694 0.0693 0.0693 0.0702 0.0702 

[TRAIN] Epoch[3](828/1500); Loss: 0.102526; Backpropagation: 0.0987 sec; Batch: 0.4339 sec
0.1166 0.1093 0.1038 0.1026 0.1013 0.1003 0.0999 0.0998 0.0999 0.1002 0.1006 0.1008 0.1008 0.1011 0.1014 0.1017 

[TRAIN] Epoch[3](829/1500); Loss: 0.065613; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.1047 0.0812 0.0755 0.0672 0.0649 0.0623 0.0605 0.0597 0.0594 0.0593 0.0591 0.0591 0.0590 0.0591 0.0593 0.0596 

[TRAIN] Epoch[3](830/1500); Loss: 0.079114; Backpropagation: 0.0992 sec; Batch: 0.4343 sec
0.1586 0.1029 0.0883 0.0825 0.0744 0.0721 0.0704 0.0695 0.0687 0.0682 0.0680 0.0680 0.0682 0.0683 0.0686 0.0692 

[TRAIN] Epoch[3](831/1500); Loss: 0.131664; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.1850 0.1618 0.1421 0.1436 0.1323 0.1277 0.1250 0.1240 0.1228 0.1218 0.1212 0.1205 0.1201 0.1198 0.1196 0.1192 

[TRAIN] Epoch[3](832/1500); Loss: 0.061328; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.1021 0.0900 0.0773 0.0622 0.0561 0.0549 0.0546 0.0542 0.0537 0.0533 0.0533 0.0536 0.0535 0.0540 0.0541 0.0544 

[TRAIN] Epoch[3](833/1500); Loss: 0.133077; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1910 0.1514 0.1414 0.1305 0.1289 0.1277 0.1266 0.1260 0.1256 0.1253 0.1251 0.1251 0.1256 0.1259 0.1264 0.1269 

[TRAIN] Epoch[3](834/1500); Loss: 0.088894; Backpropagation: 0.0983 sec; Batch: 0.4325 sec
0.2013 0.1308 0.1049 0.0863 0.0787 0.0771 0.0758 0.0750 0.0743 0.0742 0.0740 0.0738 0.0738 0.0740 0.0740 0.0743 

[TRAIN] Epoch[3](835/1500); Loss: 0.101815; Backpropagation: 0.0996 sec; Batch: 0.4353 sec
0.2328 0.1493 0.1096 0.1041 0.0931 0.0901 0.0887 0.0868 0.0857 0.0845 0.0839 0.0838 0.0841 0.0841 0.0842 0.0843 

[TRAIN] Epoch[3](836/1500); Loss: 0.089446; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.2619 0.1899 0.1049 0.0978 0.0889 0.0802 0.0687 0.0627 0.0599 0.0593 0.0595 0.0593 0.0594 0.0594 0.0596 0.0596 

[TRAIN] Epoch[3](837/1500); Loss: 0.064891; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1047 0.0960 0.0801 0.0670 0.0620 0.0606 0.0587 0.0578 0.0575 0.0567 0.0564 0.0561 0.0562 0.0561 0.0562 0.0562 

[TRAIN] Epoch[3](838/1500); Loss: 0.058062; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1161 0.0974 0.0645 0.0550 0.0532 0.0519 0.0506 0.0500 0.0493 0.0492 0.0489 0.0487 0.0485 0.0486 0.0486 0.0486 

[TRAIN] Epoch[3](839/1500); Loss: 0.087322; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1586 0.1210 0.1019 0.0884 0.0824 0.0792 0.0776 0.0769 0.0766 0.0763 0.0761 0.0763 0.0762 0.0762 0.0767 0.0768 

[TRAIN] Epoch[3](840/1500); Loss: 0.115024; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.1894 0.1267 0.1164 0.1116 0.1108 0.1097 0.1081 0.1077 0.1077 0.1074 0.1071 0.1072 0.1074 0.1075 0.1078 0.1078 

[TRAIN] Epoch[3](841/1500); Loss: 0.047554; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.0754 0.0685 0.0517 0.0473 0.0453 0.0443 0.0430 0.0427 0.0426 0.0426 0.0426 0.0428 0.0429 0.0428 0.0431 0.0432 

[TRAIN] Epoch[3](842/1500); Loss: 0.088834; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.2222 0.1226 0.0899 0.0861 0.0788 0.0776 0.0761 0.0750 0.0744 0.0743 0.0744 0.0741 0.0739 0.0738 0.0740 0.0742 

[TRAIN] Epoch[3](843/1500); Loss: 0.121313; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1864 0.1371 0.1255 0.1184 0.1168 0.1163 0.1158 0.1151 0.1145 0.1140 0.1137 0.1135 0.1135 0.1135 0.1134 0.1135 

[TRAIN] Epoch[3](844/1500); Loss: 0.057362; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1624 0.0714 0.0844 0.0510 0.0481 0.0466 0.0468 0.0457 0.0452 0.0446 0.0446 0.0448 0.0450 0.0454 0.0458 0.0461 

[TRAIN] Epoch[3](845/1500); Loss: 0.100217; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.3722 0.2485 0.1810 0.1153 0.0734 0.0593 0.0577 0.0563 0.0559 0.0561 0.0547 0.0547 0.0545 0.0547 0.0546 0.0546 

[TRAIN] Epoch[3](846/1500); Loss: 0.135473; Backpropagation: 0.1002 sec; Batch: 0.4359 sec
0.1630 0.1535 0.1372 0.1279 0.1271 0.1282 0.1290 0.1295 0.1299 0.1308 0.1320 0.1327 0.1339 0.1356 0.1377 0.1394 

[TRAIN] Epoch[3](847/1500); Loss: 0.080046; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.1712 0.1212 0.0929 0.0753 0.0721 0.0699 0.0684 0.0677 0.0675 0.0671 0.0673 0.0674 0.0680 0.0681 0.0683 0.0684 

[TRAIN] Epoch[3](848/1500); Loss: 0.108868; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.2485 0.1741 0.1024 0.1198 0.0993 0.0929 0.0909 0.0906 0.0905 0.0902 0.0903 0.0902 0.0905 0.0904 0.0904 0.0908 

[TRAIN] Epoch[3](849/1500); Loss: 0.070368; Backpropagation: 0.0997 sec; Batch: 0.4347 sec
0.1145 0.0991 0.0820 0.0706 0.0681 0.0655 0.0641 0.0632 0.0629 0.0626 0.0623 0.0622 0.0622 0.0621 0.0621 0.0623 

[TRAIN] Epoch[3](850/1500); Loss: 0.145544; Backpropagation: 0.0982 sec; Batch: 0.4325 sec
0.2162 0.1505 0.1506 0.1419 0.1413 0.1403 0.1399 0.1393 0.1390 0.1385 0.1384 0.1386 0.1386 0.1383 0.1387 0.1387 

[TRAIN] Epoch[3](851/1500); Loss: 0.125440; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2957 0.1720 0.1322 0.1155 0.1148 0.1124 0.1107 0.1085 0.1072 0.1062 0.1061 0.1057 0.1052 0.1048 0.1051 0.1049 

[TRAIN] Epoch[3](852/1500); Loss: 0.091580; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.2156 0.1178 0.0924 0.0911 0.0820 0.0812 0.0801 0.0795 0.0787 0.0787 0.0783 0.0782 0.0780 0.0777 0.0781 0.0780 

[TRAIN] Epoch[3](853/1500); Loss: 0.130186; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.2226 0.1565 0.1466 0.1271 0.1221 0.1210 0.1199 0.1195 0.1193 0.1189 0.1187 0.1185 0.1183 0.1182 0.1180 0.1179 

[TRAIN] Epoch[3](854/1500); Loss: 0.043709; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1890 0.0521 0.0599 0.0338 0.0338 0.0324 0.0302 0.0298 0.0297 0.0297 0.0291 0.0293 0.0297 0.0298 0.0303 0.0307 

[TRAIN] Epoch[3](855/1500); Loss: 0.081657; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1560 0.1077 0.0940 0.0807 0.0756 0.0741 0.0734 0.0729 0.0722 0.0718 0.0715 0.0713 0.0713 0.0712 0.0714 0.0715 

[TRAIN] Epoch[3](856/1500); Loss: 0.069114; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.3630 0.1875 0.0848 0.0523 0.0407 0.0365 0.0355 0.0347 0.0340 0.0338 0.0335 0.0333 0.0336 0.0340 0.0341 0.0347 

[TRAIN] Epoch[3](857/1500); Loss: 0.135630; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1852 0.1521 0.1396 0.1346 0.1319 0.1307 0.1300 0.1300 0.1299 0.1297 0.1295 0.1295 0.1294 0.1294 0.1293 0.1292 

[TRAIN] Epoch[3](858/1500); Loss: 0.086371; Backpropagation: 0.0994 sec; Batch: 0.4336 sec
0.2467 0.1673 0.1030 0.0814 0.0742 0.0690 0.0655 0.0642 0.0637 0.0637 0.0636 0.0637 0.0640 0.0639 0.0639 0.0639 

[TRAIN] Epoch[3](859/1500); Loss: 0.097795; Backpropagation: 0.0985 sec; Batch: 0.4337 sec
0.1897 0.1688 0.1233 0.0953 0.0897 0.0850 0.0836 0.0829 0.0818 0.0810 0.0808 0.0811 0.0808 0.0805 0.0802 0.0800 

[TRAIN] Epoch[3](860/1500); Loss: 0.119196; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1628 0.1443 0.1307 0.1210 0.1173 0.1154 0.1136 0.1123 0.1117 0.1113 0.1110 0.1110 0.1110 0.1111 0.1112 0.1115 

[TRAIN] Epoch[3](861/1500); Loss: 0.062135; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.1155 0.0673 0.0739 0.0858 0.0685 0.0569 0.0530 0.0522 0.0521 0.0523 0.0523 0.0523 0.0527 0.0528 0.0531 0.0534 

[TRAIN] Epoch[3](862/1500); Loss: 0.084497; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.2025 0.0969 0.0962 0.0813 0.0753 0.0751 0.0732 0.0726 0.0725 0.0724 0.0725 0.0723 0.0722 0.0721 0.0724 0.0725 

[TRAIN] Epoch[3](863/1500); Loss: 0.094345; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1307 0.1239 0.1054 0.0951 0.0918 0.0899 0.0893 0.0888 0.0876 0.0871 0.0866 0.0866 0.0865 0.0867 0.0866 0.0869 

[TRAIN] Epoch[3](864/1500); Loss: 0.098346; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.1840 0.1257 0.1150 0.0985 0.0927 0.0903 0.0886 0.0878 0.0874 0.0868 0.0864 0.0862 0.0864 0.0859 0.0860 0.0859 

[TRAIN] Epoch[3](865/1500); Loss: 0.117043; Backpropagation: 0.1004 sec; Batch: 0.4345 sec
0.1431 0.1318 0.1223 0.1179 0.1163 0.1150 0.1139 0.1133 0.1128 0.1126 0.1125 0.1122 0.1122 0.1122 0.1123 0.1124 

[TRAIN] Epoch[3](866/1500); Loss: 0.108560; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.2185 0.1448 0.1110 0.1139 0.1033 0.1006 0.0974 0.0960 0.0951 0.0944 0.0940 0.0938 0.0938 0.0934 0.0933 0.0935 

[TRAIN] Epoch[3](867/1500); Loss: 0.148081; Backpropagation: 0.0983 sec; Batch: 0.4348 sec
0.2218 0.1862 0.1593 0.1432 0.1448 0.1412 0.1386 0.1368 0.1368 0.1365 0.1372 0.1370 0.1373 0.1376 0.1375 0.1376 

[TRAIN] Epoch[3](868/1500); Loss: 0.099982; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1642 0.1246 0.1047 0.1003 0.0950 0.0934 0.0926 0.0920 0.0918 0.0915 0.0913 0.0913 0.0916 0.0918 0.0919 0.0920 

[TRAIN] Epoch[3](869/1500); Loss: 0.074760; Backpropagation: 0.0992 sec; Batch: 0.4353 sec
0.2376 0.1314 0.0766 0.0767 0.0606 0.0574 0.0554 0.0557 0.0555 0.0552 0.0551 0.0553 0.0555 0.0558 0.0562 0.0562 

[TRAIN] Epoch[3](870/1500); Loss: 0.052361; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.1257 0.0943 0.0529 0.0678 0.0530 0.0458 0.0418 0.0401 0.0396 0.0393 0.0392 0.0394 0.0395 0.0395 0.0399 0.0398 

[TRAIN] Epoch[3](871/1500); Loss: 0.046693; Backpropagation: 0.0991 sec; Batch: 0.4336 sec
0.0717 0.0501 0.0607 0.0550 0.0448 0.0440 0.0432 0.0420 0.0421 0.0414 0.0416 0.0414 0.0417 0.0418 0.0427 0.0430 

[TRAIN] Epoch[3](872/1500); Loss: 0.129561; Backpropagation: 0.0992 sec; Batch: 0.4341 sec
0.1505 0.1357 0.1333 0.1313 0.1293 0.1278 0.1273 0.1267 0.1267 0.1266 0.1265 0.1265 0.1266 0.1265 0.1260 0.1259 

[TRAIN] Epoch[3](873/1500); Loss: 0.088204; Backpropagation: 0.0992 sec; Batch: 0.4347 sec
0.2302 0.1598 0.0964 0.1001 0.0898 0.0800 0.0683 0.0653 0.0653 0.0645 0.0648 0.0650 0.0651 0.0652 0.0654 0.0659 

[TRAIN] Epoch[3](874/1500); Loss: 0.085229; Backpropagation: 0.0994 sec; Batch: 0.4343 sec
0.2704 0.1567 0.0760 0.0793 0.0732 0.0671 0.0650 0.0647 0.0637 0.0636 0.0633 0.0633 0.0635 0.0638 0.0647 0.0652 

[TRAIN] Epoch[3](875/1500); Loss: 0.060366; Backpropagation: 0.0991 sec; Batch: 0.4350 sec
0.1363 0.1239 0.0538 0.0608 0.0527 0.0490 0.0487 0.0478 0.0477 0.0481 0.0483 0.0488 0.0490 0.0495 0.0502 0.0512 

[TRAIN] Epoch[3](876/1500); Loss: 0.087174; Backpropagation: 0.1029 sec; Batch: 0.4387 sec
0.2041 0.1282 0.0956 0.0791 0.0761 0.0757 0.0746 0.0736 0.0732 0.0729 0.0731 0.0731 0.0734 0.0737 0.0741 0.0740 

[TRAIN] Epoch[3](877/1500); Loss: 0.096129; Backpropagation: 0.0995 sec; Batch: 0.4347 sec
0.1657 0.1064 0.1036 0.0955 0.0939 0.0918 0.0892 0.0886 0.0880 0.0880 0.0878 0.0875 0.0876 0.0876 0.0880 0.0887 

[TRAIN] Epoch[3](878/1500); Loss: 0.068742; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1476 0.0903 0.0696 0.0750 0.0676 0.0623 0.0585 0.0585 0.0580 0.0578 0.0579 0.0585 0.0587 0.0594 0.0599 0.0604 

[TRAIN] Epoch[3](879/1500); Loss: 0.070244; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.1145 0.0887 0.0920 0.1051 0.0827 0.0672 0.0596 0.0579 0.0571 0.0566 0.0563 0.0562 0.0569 0.0573 0.0577 0.0581 

[TRAIN] Epoch[3](880/1500); Loss: 0.108821; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.1880 0.1494 0.1221 0.1038 0.1040 0.1006 0.0988 0.0984 0.0974 0.0968 0.0970 0.0969 0.0968 0.0968 0.0970 0.0974 

[TRAIN] Epoch[3](881/1500); Loss: 0.081028; Backpropagation: 0.0973 sec; Batch: 0.4354 sec
0.1572 0.1149 0.0867 0.0835 0.0794 0.0747 0.0728 0.0716 0.0705 0.0700 0.0695 0.0692 0.0691 0.0690 0.0692 0.0693 

[TRAIN] Epoch[3](882/1500); Loss: 0.068476; Backpropagation: 0.0940 sec; Batch: 0.4386 sec
0.1021 0.1115 0.0821 0.0719 0.0654 0.0629 0.0613 0.0604 0.0596 0.0593 0.0594 0.0596 0.0598 0.0600 0.0600 0.0602 

[TRAIN] Epoch[3](883/1500); Loss: 0.051694; Backpropagation: 0.0934 sec; Batch: 0.4392 sec
0.0928 0.0739 0.0534 0.0709 0.0597 0.0528 0.0464 0.0432 0.0419 0.0417 0.0414 0.0416 0.0415 0.0415 0.0420 0.0425 

[TRAIN] Epoch[3](884/1500); Loss: 0.061265; Backpropagation: 0.0931 sec; Batch: 0.4672 sec
0.1473 0.1153 0.0858 0.0625 0.0566 0.0514 0.0482 0.0458 0.0451 0.0451 0.0453 0.0458 0.0460 0.0463 0.0465 0.0472 

[TRAIN] Epoch[3](885/1500); Loss: 0.074113; Backpropagation: 0.0934 sec; Batch: 0.4426 sec
0.3006 0.1554 0.0434 0.0846 0.0531 0.0495 0.0505 0.0501 0.0479 0.0479 0.0482 0.0489 0.0497 0.0509 0.0520 0.0531 

[TRAIN] Epoch[3](886/1500); Loss: 0.065560; Backpropagation: 0.0934 sec; Batch: 0.5272 sec
0.1153 0.0707 0.0694 0.0672 0.0625 0.0613 0.0600 0.0602 0.0593 0.0593 0.0593 0.0597 0.0603 0.0609 0.0615 0.0623 

[TRAIN] Epoch[3](887/1500); Loss: 0.117589; Backpropagation: 0.0982 sec; Batch: 0.4754 sec
0.2085 0.1768 0.1291 0.1130 0.1081 0.1044 0.1029 0.1028 0.1031 0.1035 0.1036 0.1036 0.1044 0.1051 0.1061 0.1065 

[TRAIN] Epoch[3](888/1500); Loss: 0.051719; Backpropagation: 0.0957 sec; Batch: 0.4728 sec
0.1235 0.0715 0.0579 0.0635 0.0537 0.0453 0.0428 0.0418 0.0408 0.0404 0.0406 0.0406 0.0406 0.0410 0.0414 0.0421 

[TRAIN] Epoch[3](889/1500); Loss: 0.112747; Backpropagation: 0.0956 sec; Batch: 0.4995 sec
0.1585 0.1382 0.1255 0.1171 0.1118 0.1083 0.1068 0.1055 0.1045 0.1041 0.1041 0.1039 0.1037 0.1037 0.1038 0.1043 

[TRAIN] Epoch[3](890/1500); Loss: 0.089784; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.1565 0.1465 0.1094 0.0941 0.0870 0.0829 0.0805 0.0785 0.0767 0.0756 0.0751 0.0748 0.0747 0.0747 0.0747 0.0748 

[TRAIN] Epoch[3](891/1500); Loss: 0.129134; Backpropagation: 0.0939 sec; Batch: 0.4666 sec
0.2154 0.1929 0.1489 0.1355 0.1257 0.1186 0.1154 0.1141 0.1133 0.1124 0.1122 0.1121 0.1121 0.1123 0.1126 0.1128 

[TRAIN] Epoch[3](892/1500); Loss: 0.120515; Backpropagation: 0.0958 sec; Batch: 0.4690 sec
0.2250 0.1461 0.1449 0.1229 0.1225 0.1169 0.1097 0.1071 0.1055 0.1043 0.1036 0.1031 0.1030 0.1038 0.1048 0.1051 

[TRAIN] Epoch[3](893/1500); Loss: 0.127270; Backpropagation: 0.0957 sec; Batch: 0.4500 sec
0.1788 0.1679 0.1415 0.1277 0.1251 0.1221 0.1206 0.1194 0.1186 0.1177 0.1170 0.1165 0.1161 0.1160 0.1159 0.1156 

[TRAIN] Epoch[3](894/1500); Loss: 0.081332; Backpropagation: 0.0938 sec; Batch: 0.5267 sec
0.1349 0.0882 0.0884 0.1044 0.0869 0.0766 0.0718 0.0717 0.0719 0.0716 0.0716 0.0718 0.0721 0.0724 0.0733 0.0736 

[TRAIN] Epoch[3](895/1500); Loss: 0.082666; Backpropagation: 0.0940 sec; Batch: 0.5283 sec
0.1292 0.1094 0.0945 0.0921 0.0849 0.0778 0.0748 0.0733 0.0729 0.0728 0.0727 0.0729 0.0732 0.0737 0.0743 0.0741 

[TRAIN] Epoch[3](896/1500); Loss: 0.070760; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1353 0.1231 0.0972 0.0729 0.0646 0.0612 0.0586 0.0576 0.0572 0.0573 0.0575 0.0574 0.0578 0.0580 0.0581 0.0583 

[TRAIN] Epoch[3](897/1500); Loss: 0.063537; Backpropagation: 0.0939 sec; Batch: 0.4547 sec
0.1103 0.1067 0.0738 0.0680 0.0650 0.0614 0.0561 0.0539 0.0531 0.0526 0.0519 0.0517 0.0522 0.0529 0.0533 0.0536 

[TRAIN] Epoch[3](898/1500); Loss: 0.089405; Backpropagation: 0.0939 sec; Batch: 0.4510 sec
0.1458 0.1291 0.1054 0.0931 0.0886 0.0856 0.0821 0.0801 0.0789 0.0779 0.0773 0.0772 0.0773 0.0771 0.0773 0.0776 

[TRAIN] Epoch[3](899/1500); Loss: 0.083435; Backpropagation: 0.0939 sec; Batch: 0.4696 sec
0.1203 0.0991 0.0883 0.0945 0.0889 0.0809 0.0779 0.0767 0.0763 0.0763 0.0759 0.0759 0.0759 0.0760 0.0761 0.0761 

[TRAIN] Epoch[3](900/1500); Loss: 0.110690; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.2241 0.1396 0.1088 0.1083 0.1055 0.1020 0.0997 0.0985 0.0979 0.0978 0.0977 0.0975 0.0980 0.0980 0.0987 0.0989 

[TRAIN] Epoch[3](901/1500); Loss: 0.112281; Backpropagation: 0.0944 sec; Batch: 0.4831 sec
0.1930 0.1451 0.1202 0.1146 0.1112 0.1078 0.1043 0.1024 0.1012 0.1004 0.1001 0.0998 0.0994 0.0993 0.0991 0.0986 

[TRAIN] Epoch[3](902/1500); Loss: 0.127675; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.1740 0.1559 0.1422 0.1293 0.1265 0.1241 0.1212 0.1202 0.1193 0.1184 0.1180 0.1183 0.1185 0.1188 0.1189 0.1193 

[TRAIN] Epoch[3](903/1500); Loss: 0.115762; Backpropagation: 0.0957 sec; Batch: 0.4682 sec
0.1958 0.1744 0.1251 0.1253 0.1160 0.1095 0.1047 0.1020 0.1006 0.0997 0.0996 0.0994 0.0996 0.0997 0.1002 0.1006 

[TRAIN] Epoch[3](904/1500); Loss: 0.079464; Backpropagation: 0.0937 sec; Batch: 0.5267 sec
0.1342 0.1390 0.1019 0.0772 0.0704 0.0693 0.0684 0.0676 0.0673 0.0673 0.0674 0.0674 0.0678 0.0682 0.0688 0.0693 

[TRAIN] Epoch[3](905/1500); Loss: 0.125915; Backpropagation: 0.0939 sec; Batch: 0.4680 sec
0.2178 0.1764 0.1485 0.1206 0.1201 0.1178 0.1139 0.1122 0.1114 0.1111 0.1106 0.1105 0.1106 0.1107 0.1111 0.1113 

[TRAIN] Epoch[3](906/1500); Loss: 0.108576; Backpropagation: 0.0938 sec; Batch: 0.4695 sec
0.1523 0.1372 0.1165 0.1182 0.1089 0.1048 0.1022 0.1008 0.1000 0.0998 0.0997 0.0997 0.0994 0.0993 0.0991 0.0995 

[TRAIN] Epoch[3](907/1500); Loss: 0.082789; Backpropagation: 0.0939 sec; Batch: 0.4707 sec
0.1238 0.0999 0.0995 0.1037 0.0878 0.0778 0.0743 0.0736 0.0731 0.0725 0.0722 0.0724 0.0727 0.0733 0.0737 0.0743 

[TRAIN] Epoch[3](908/1500); Loss: 0.139756; Backpropagation: 0.0939 sec; Batch: 0.4707 sec
0.1986 0.1763 0.1541 0.1397 0.1339 0.1341 0.1325 0.1318 0.1307 0.1299 0.1293 0.1291 0.1295 0.1290 0.1287 0.1288 

[TRAIN] Epoch[3](909/1500); Loss: 0.129732; Backpropagation: 0.0982 sec; Batch: 0.4734 sec
0.1586 0.1446 0.1341 0.1314 0.1296 0.1285 0.1274 0.1264 0.1258 0.1253 0.1248 0.1242 0.1240 0.1239 0.1235 0.1234 

[TRAIN] Epoch[3](910/1500); Loss: 0.074262; Backpropagation: 0.0957 sec; Batch: 0.4696 sec
0.1011 0.0946 0.0792 0.0760 0.0742 0.0713 0.0700 0.0696 0.0688 0.0684 0.0684 0.0684 0.0686 0.0694 0.0700 0.0702 

[TRAIN] Epoch[3](911/1500); Loss: 0.060216; Backpropagation: 0.0940 sec; Batch: 0.4689 sec
0.1376 0.1273 0.0878 0.0622 0.0524 0.0487 0.0464 0.0450 0.0437 0.0436 0.0436 0.0439 0.0441 0.0450 0.0457 0.0466 

[TRAIN] Epoch[3](912/1500); Loss: 0.139317; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.2040 0.1889 0.1562 0.1406 0.1345 0.1319 0.1304 0.1293 0.1283 0.1275 0.1269 0.1264 0.1263 0.1260 0.1259 0.1259 

[TRAIN] Epoch[3](913/1500); Loss: 0.093383; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.2004 0.1219 0.1310 0.0865 0.0907 0.0886 0.0807 0.0791 0.0787 0.0779 0.0769 0.0765 0.0766 0.0764 0.0761 0.0761 

[TRAIN] Epoch[3](914/1500); Loss: 0.062162; Backpropagation: 0.0995 sec; Batch: 0.4783 sec
0.1332 0.1241 0.0909 0.0662 0.0574 0.0536 0.0505 0.0486 0.0469 0.0457 0.0456 0.0455 0.0457 0.0462 0.0469 0.0476 

[TRAIN] Epoch[3](915/1500); Loss: 0.068300; Backpropagation: 0.0946 sec; Batch: 0.4295 sec
0.2711 0.1105 0.0858 0.0602 0.0596 0.0452 0.0427 0.0493 0.0495 0.0451 0.0444 0.0446 0.0449 0.0456 0.0465 0.0478 

[TRAIN] Epoch[3](916/1500); Loss: 0.121110; Backpropagation: 0.0946 sec; Batch: 0.4707 sec
0.1882 0.1283 0.1365 0.1184 0.1176 0.1158 0.1134 0.1127 0.1124 0.1126 0.1127 0.1130 0.1132 0.1138 0.1143 0.1149 

[TRAIN] Epoch[3](917/1500); Loss: 0.110451; Backpropagation: 0.0987 sec; Batch: 0.4719 sec
0.1477 0.1341 0.1142 0.1161 0.1088 0.1064 0.1047 0.1044 0.1039 0.1036 0.1035 0.1036 0.1036 0.1040 0.1041 0.1045 

[TRAIN] Epoch[3](918/1500); Loss: 0.077420; Backpropagation: 0.0985 sec; Batch: 0.4344 sec
0.1205 0.1393 0.0854 0.0785 0.0716 0.0701 0.0693 0.0685 0.0679 0.0674 0.0671 0.0669 0.0667 0.0665 0.0665 0.0667 

[TRAIN] Epoch[3](919/1500); Loss: 0.084188; Backpropagation: 0.0990 sec; Batch: 0.4824 sec
0.1178 0.1036 0.0945 0.0866 0.0832 0.0809 0.0798 0.0787 0.0783 0.0781 0.0776 0.0772 0.0774 0.0776 0.0778 0.0780 

[TRAIN] Epoch[3](920/1500); Loss: 0.077571; Backpropagation: 0.0990 sec; Batch: 0.4742 sec
0.2271 0.1135 0.0882 0.0690 0.0741 0.0643 0.0635 0.0623 0.0596 0.0601 0.0608 0.0588 0.0595 0.0599 0.0600 0.0606 

[TRAIN] Epoch[3](921/1500); Loss: 0.142866; Backpropagation: 0.0992 sec; Batch: 0.4754 sec
0.1555 0.1491 0.1446 0.1439 0.1417 0.1409 0.1408 0.1405 0.1406 0.1406 0.1407 0.1410 0.1410 0.1411 0.1416 0.1421 

[TRAIN] Epoch[3](922/1500); Loss: 0.099079; Backpropagation: 0.0990 sec; Batch: 0.4718 sec
0.1414 0.1410 0.1195 0.1008 0.0940 0.0922 0.0913 0.0900 0.0897 0.0890 0.0889 0.0887 0.0890 0.0896 0.0900 0.0902 

[TRAIN] Epoch[3](923/1500); Loss: 0.139230; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.2243 0.1689 0.1528 0.1418 0.1357 0.1330 0.1306 0.1293 0.1284 0.1272 0.1267 0.1264 0.1259 0.1258 0.1255 0.1255 

[TRAIN] Epoch[3](924/1500); Loss: 0.125712; Backpropagation: 0.0991 sec; Batch: 0.4760 sec
0.2025 0.1585 0.1399 0.1338 0.1202 0.1171 0.1161 0.1158 0.1145 0.1142 0.1135 0.1135 0.1133 0.1134 0.1127 0.1124 

[TRAIN] Epoch[3](925/1500); Loss: 0.085587; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.2616 0.1578 0.0934 0.0815 0.0688 0.0672 0.0645 0.0643 0.0638 0.0635 0.0635 0.0636 0.0637 0.0637 0.0640 0.0644 

[TRAIN] Epoch[3](926/1500); Loss: 0.103515; Backpropagation: 0.0989 sec; Batch: 0.4737 sec
0.1594 0.1506 0.1314 0.1006 0.0987 0.0958 0.0951 0.0934 0.0925 0.0923 0.0916 0.0911 0.0910 0.0910 0.0909 0.0907 

[TRAIN] Epoch[3](927/1500); Loss: 0.102014; Backpropagation: 0.0991 sec; Batch: 0.4709 sec
0.1639 0.1610 0.1282 0.1004 0.0955 0.0938 0.0923 0.0912 0.0906 0.0893 0.0890 0.0884 0.0875 0.0872 0.0870 0.0869 

[TRAIN] Epoch[3](928/1500); Loss: 0.094096; Backpropagation: 0.0990 sec; Batch: 0.4707 sec
0.1178 0.1148 0.1044 0.0965 0.0932 0.0911 0.0895 0.0886 0.0882 0.0878 0.0879 0.0883 0.0886 0.0888 0.0896 0.0905 

[TRAIN] Epoch[3](929/1500); Loss: 0.106635; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.1382 0.1362 0.1181 0.1066 0.1026 0.1018 0.1008 0.1008 0.1004 0.1003 0.0999 0.0997 0.0998 0.1001 0.1002 0.1008 

[TRAIN] Epoch[3](930/1500); Loss: 0.126926; Backpropagation: 0.0982 sec; Batch: 0.4708 sec
0.1749 0.1502 0.1296 0.1278 0.1232 0.1218 0.1209 0.1205 0.1203 0.1204 0.1203 0.1202 0.1200 0.1201 0.1202 0.1204 

[TRAIN] Epoch[3](931/1500); Loss: 0.101769; Backpropagation: 0.0985 sec; Batch: 0.4714 sec
0.1229 0.1245 0.1101 0.1049 0.0999 0.0989 0.0980 0.0972 0.0967 0.0964 0.0962 0.0963 0.0964 0.0964 0.0966 0.0968 

[TRAIN] Epoch[3](932/1500); Loss: 0.070638; Backpropagation: 0.1005 sec; Batch: 0.4354 sec
0.1209 0.0954 0.0867 0.0708 0.0682 0.0657 0.0643 0.0632 0.0630 0.0621 0.0623 0.0616 0.0614 0.0613 0.0618 0.0615 

[TRAIN] Epoch[3](933/1500); Loss: 0.089633; Backpropagation: 0.0990 sec; Batch: 0.4739 sec
0.1569 0.1420 0.1018 0.0888 0.0846 0.0813 0.0797 0.0790 0.0781 0.0778 0.0775 0.0775 0.0773 0.0771 0.0774 0.0772 

[TRAIN] Epoch[3](934/1500); Loss: 0.079919; Backpropagation: 0.0991 sec; Batch: 0.5218 sec
0.1258 0.1008 0.0874 0.0804 0.0767 0.0753 0.0740 0.0729 0.0724 0.0724 0.0726 0.0729 0.0729 0.0735 0.0741 0.0747 

[TRAIN] Epoch[3](935/1500); Loss: 0.109193; Backpropagation: 0.0991 sec; Batch: 0.4714 sec
0.1806 0.1318 0.1130 0.1134 0.1045 0.1022 0.1014 0.1006 0.0998 0.0992 0.0995 0.0995 0.1000 0.1004 0.1006 0.1007 

[TRAIN] Epoch[3](936/1500); Loss: 0.071556; Backpropagation: 0.0989 sec; Batch: 0.4705 sec
0.1052 0.1007 0.0795 0.0689 0.0680 0.0675 0.0666 0.0655 0.0654 0.0651 0.0649 0.0651 0.0652 0.0654 0.0656 0.0663 

[TRAIN] Epoch[3](937/1500); Loss: 0.092351; Backpropagation: 0.0991 sec; Batch: 0.4750 sec
0.1324 0.1143 0.1011 0.0917 0.0886 0.0873 0.0865 0.0857 0.0854 0.0854 0.0855 0.0856 0.0862 0.0867 0.0872 0.0879 

[TRAIN] Epoch[3](938/1500); Loss: 0.110068; Backpropagation: 0.0989 sec; Batch: 0.5209 sec
0.1306 0.1314 0.1197 0.1123 0.1090 0.1072 0.1061 0.1055 0.1054 0.1051 0.1052 0.1051 0.1048 0.1046 0.1045 0.1046 

[TRAIN] Epoch[3](939/1500); Loss: 0.090567; Backpropagation: 0.0990 sec; Batch: 0.4750 sec
0.1236 0.1164 0.0968 0.0915 0.0897 0.0882 0.0868 0.0857 0.0849 0.0843 0.0840 0.0837 0.0836 0.0832 0.0833 0.0834 

[TRAIN] Epoch[3](940/1500); Loss: 0.105838; Backpropagation: 0.0992 sec; Batch: 0.4534 sec
0.1383 0.1276 0.1105 0.1047 0.1051 0.1030 0.1019 0.1008 0.1002 0.1003 0.1000 0.1000 0.0999 0.1003 0.1003 0.1005 

[TRAIN] Epoch[3](941/1500); Loss: 0.089192; Backpropagation: 0.0991 sec; Batch: 0.4674 sec
0.1216 0.1079 0.0959 0.0876 0.0852 0.0847 0.0841 0.0837 0.0838 0.0839 0.0842 0.0844 0.0846 0.0848 0.0850 0.0857 

[TRAIN] Epoch[3](942/1500); Loss: 0.070848; Backpropagation: 0.0989 sec; Batch: 0.4705 sec
0.1282 0.0911 0.0889 0.0710 0.0683 0.0661 0.0641 0.0633 0.0626 0.0618 0.0614 0.0614 0.0613 0.0613 0.0611 0.0617 

[TRAIN] Epoch[3](943/1500); Loss: 0.115136; Backpropagation: 0.0989 sec; Batch: 0.4748 sec
0.2087 0.2048 0.1611 0.1131 0.1047 0.1025 0.0994 0.0974 0.0959 0.0950 0.0944 0.0937 0.0931 0.0928 0.0926 0.0929 

[TRAIN] Epoch[3](944/1500); Loss: 0.121845; Backpropagation: 0.0991 sec; Batch: 0.4704 sec
0.1914 0.1720 0.1285 0.1227 0.1179 0.1136 0.1107 0.1096 0.1099 0.1098 0.1100 0.1100 0.1101 0.1105 0.1111 0.1117 

[TRAIN] Epoch[3](945/1500); Loss: 0.116512; Backpropagation: 0.0990 sec; Batch: 0.4750 sec
0.1378 0.1344 0.1213 0.1160 0.1149 0.1136 0.1125 0.1124 0.1124 0.1126 0.1124 0.1125 0.1126 0.1126 0.1130 0.1132 

[TRAIN] Epoch[3](946/1500); Loss: 0.090888; Backpropagation: 0.0989 sec; Batch: 0.4696 sec
0.1627 0.1118 0.0976 0.0924 0.0883 0.0840 0.0822 0.0819 0.0815 0.0811 0.0813 0.0811 0.0813 0.0822 0.0825 0.0825 

[TRAIN] Epoch[3](947/1500); Loss: 0.102067; Backpropagation: 0.1016 sec; Batch: 0.4787 sec
0.1496 0.1215 0.1074 0.1011 0.0979 0.0966 0.0961 0.0959 0.0959 0.0956 0.0956 0.0957 0.0957 0.0957 0.0962 0.0964 

[TRAIN] Epoch[3](948/1500); Loss: 0.092144; Backpropagation: 0.1081 sec; Batch: 0.4619 sec
0.1324 0.1382 0.1131 0.0915 0.0871 0.0860 0.0848 0.0837 0.0829 0.0825 0.0823 0.0822 0.0818 0.0818 0.0819 0.0821 

[TRAIN] Epoch[3](949/1500); Loss: 0.103137; Backpropagation: 0.1080 sec; Batch: 0.4442 sec
0.1633 0.1230 0.1103 0.1046 0.1003 0.0981 0.0966 0.0964 0.0957 0.0950 0.0949 0.0945 0.0941 0.0942 0.0945 0.0948 

[TRAIN] Epoch[3](950/1500); Loss: 0.077965; Backpropagation: 0.0983 sec; Batch: 0.4809 sec
0.2137 0.1080 0.1020 0.0711 0.0718 0.0642 0.0621 0.0614 0.0612 0.0608 0.0610 0.0614 0.0616 0.0621 0.0622 0.0627 

[TRAIN] Epoch[3](951/1500); Loss: 0.126072; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1466 0.1447 0.1310 0.1256 0.1240 0.1230 0.1226 0.1225 0.1226 0.1222 0.1220 0.1219 0.1219 0.1221 0.1223 0.1224 

[TRAIN] Epoch[3](952/1500); Loss: 0.072373; Backpropagation: 0.0982 sec; Batch: 0.4764 sec
0.1077 0.0977 0.0772 0.0741 0.0710 0.0689 0.0682 0.0676 0.0665 0.0660 0.0659 0.0655 0.0655 0.0657 0.0653 0.0652 

[TRAIN] Epoch[3](953/1500); Loss: 0.081644; Backpropagation: 0.0995 sec; Batch: 0.4354 sec
0.1505 0.1242 0.0953 0.0779 0.0749 0.0733 0.0719 0.0712 0.0708 0.0710 0.0705 0.0704 0.0706 0.0710 0.0713 0.0715 

[TRAIN] Epoch[3](954/1500); Loss: 0.034466; Backpropagation: 0.1021 sec; Batch: 0.4849 sec
0.0740 0.0505 0.0377 0.0481 0.0339 0.0273 0.0258 0.0258 0.0261 0.0265 0.0270 0.0278 0.0287 0.0297 0.0309 0.0316 

[TRAIN] Epoch[3](955/1500); Loss: 0.097155; Backpropagation: 0.0990 sec; Batch: 0.4752 sec
0.1277 0.1216 0.1044 0.0970 0.0943 0.0927 0.0920 0.0917 0.0915 0.0914 0.0915 0.0914 0.0913 0.0917 0.0919 0.0924 

[TRAIN] Epoch[3](956/1500); Loss: 0.060829; Backpropagation: 0.0998 sec; Batch: 0.4721 sec
0.0997 0.0734 0.0671 0.0677 0.0613 0.0583 0.0572 0.0558 0.0552 0.0547 0.0542 0.0542 0.0537 0.0536 0.0535 0.0538 

[TRAIN] Epoch[3](957/1500); Loss: 0.148390; Backpropagation: 0.0990 sec; Batch: 0.4778 sec
0.2119 0.1713 0.1501 0.1526 0.1440 0.1429 0.1418 0.1409 0.1404 0.1401 0.1397 0.1397 0.1394 0.1397 0.1399 0.1399 

[TRAIN] Epoch[3](958/1500); Loss: 0.106961; Backpropagation: 0.0989 sec; Batch: 0.4977 sec
0.1693 0.1264 0.1142 0.1043 0.1029 0.1009 0.1003 0.0998 0.0998 0.0993 0.0991 0.0991 0.0990 0.0989 0.0991 0.0990 

[TRAIN] Epoch[3](959/1500); Loss: 0.068924; Backpropagation: 0.0990 sec; Batch: 0.4706 sec
0.1039 0.0952 0.0765 0.0705 0.0667 0.0653 0.0643 0.0634 0.0626 0.0619 0.0616 0.0618 0.0619 0.0621 0.0623 0.0628 

[TRAIN] Epoch[3](960/1500); Loss: 0.089924; Backpropagation: 0.0990 sec; Batch: 0.4752 sec
0.1239 0.0959 0.0946 0.0941 0.0892 0.0867 0.0858 0.0855 0.0851 0.0850 0.0847 0.0850 0.0851 0.0856 0.0862 0.0863 

[TRAIN] Epoch[3](961/1500); Loss: 0.075590; Backpropagation: 0.0990 sec; Batch: 0.4821 sec
0.1383 0.1411 0.1060 0.0762 0.0661 0.0679 0.0652 0.0628 0.0612 0.0606 0.0605 0.0605 0.0605 0.0607 0.0608 0.0609 

[TRAIN] Epoch[3](962/1500); Loss: 0.061368; Backpropagation: 0.0989 sec; Batch: 0.4699 sec
0.1121 0.0752 0.0650 0.0604 0.0580 0.0561 0.0555 0.0555 0.0552 0.0551 0.0550 0.0554 0.0556 0.0557 0.0558 0.0562 

[TRAIN] Epoch[3](963/1500); Loss: 0.067256; Backpropagation: 0.0991 sec; Batch: 0.4732 sec
0.1112 0.0831 0.0852 0.0832 0.0701 0.0601 0.0581 0.0581 0.0577 0.0578 0.0576 0.0582 0.0582 0.0590 0.0589 0.0595 

[TRAIN] Epoch[3](964/1500); Loss: 0.130540; Backpropagation: 0.0989 sec; Batch: 0.4452 sec
0.2025 0.1547 0.1319 0.1307 0.1243 0.1242 0.1233 0.1228 0.1220 0.1219 0.1218 0.1216 0.1215 0.1214 0.1220 0.1220 

[TRAIN] Epoch[3](965/1500); Loss: 0.127924; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1653 0.1522 0.1356 0.1306 0.1265 0.1248 0.1233 0.1221 0.1216 0.1211 0.1207 0.1207 0.1206 0.1208 0.1205 0.1206 

[TRAIN] Epoch[3](966/1500); Loss: 0.058742; Backpropagation: 0.0983 sec; Batch: 0.4754 sec
0.0674 0.0835 0.0692 0.0610 0.0598 0.0577 0.0559 0.0543 0.0537 0.0538 0.0538 0.0538 0.0533 0.0537 0.0542 0.0546 

[TRAIN] Epoch[3](967/1500); Loss: 0.073553; Backpropagation: 0.0970 sec; Batch: 0.4375 sec
0.1417 0.0883 0.0794 0.0723 0.0693 0.0684 0.0672 0.0664 0.0656 0.0655 0.0650 0.0654 0.0652 0.0654 0.0656 0.0662 

[TRAIN] Epoch[3](968/1500); Loss: 0.076513; Backpropagation: 0.0982 sec; Batch: 0.4420 sec
0.1151 0.1112 0.0926 0.0770 0.0722 0.0711 0.0694 0.0689 0.0683 0.0682 0.0680 0.0681 0.0681 0.0685 0.0687 0.0690 

[TRAIN] Epoch[3](969/1500); Loss: 0.110396; Backpropagation: 0.1000 sec; Batch: 0.4773 sec
0.1457 0.1308 0.1146 0.1143 0.1088 0.1066 0.1059 0.1052 0.1049 0.1047 0.1043 0.1043 0.1042 0.1040 0.1039 0.1042 

[TRAIN] Epoch[3](970/1500); Loss: 0.155671; Backpropagation: 0.0990 sec; Batch: 0.4860 sec
0.1867 0.1874 0.1625 0.1542 0.1534 0.1525 0.1517 0.1506 0.1499 0.1494 0.1492 0.1491 0.1491 0.1485 0.1484 0.1482 

[TRAIN] Epoch[3](971/1500); Loss: 0.059777; Backpropagation: 0.0992 sec; Batch: 0.4346 sec
0.1308 0.0860 0.0785 0.0609 0.0599 0.0516 0.0495 0.0488 0.0484 0.0483 0.0481 0.0485 0.0486 0.0490 0.0491 0.0505 

[TRAIN] Epoch[3](972/1500); Loss: 0.153071; Backpropagation: 0.0985 sec; Batch: 0.4734 sec
0.1800 0.1730 0.1599 0.1526 0.1504 0.1493 0.1486 0.1481 0.1479 0.1478 0.1481 0.1482 0.1483 0.1486 0.1491 0.1492 

[TRAIN] Epoch[3](973/1500); Loss: 0.125234; Backpropagation: 0.0989 sec; Batch: 0.4351 sec
0.1663 0.1587 0.1353 0.1242 0.1228 0.1210 0.1199 0.1186 0.1180 0.1172 0.1167 0.1167 0.1167 0.1169 0.1174 0.1173 

[TRAIN] Epoch[3](974/1500); Loss: 0.166209; Backpropagation: 0.0989 sec; Batch: 0.4752 sec
0.2328 0.1877 0.1699 0.1692 0.1633 0.1633 0.1622 0.1615 0.1602 0.1591 0.1571 0.1565 0.1553 0.1548 0.1535 0.1530 

[TRAIN] Epoch[3](975/1500); Loss: 0.076427; Backpropagation: 0.0991 sec; Batch: 0.4384 sec
0.1342 0.1330 0.0819 0.0731 0.0704 0.0679 0.0672 0.0665 0.0662 0.0660 0.0659 0.0659 0.0664 0.0661 0.0661 0.0662 

[TRAIN] Epoch[3](976/1500); Loss: 0.099821; Backpropagation: 0.0996 sec; Batch: 0.4342 sec
0.1165 0.1121 0.1037 0.0995 0.0981 0.0980 0.0971 0.0970 0.0966 0.0966 0.0966 0.0966 0.0970 0.0972 0.0970 0.0977 

[TRAIN] Epoch[3](977/1500); Loss: 0.135278; Backpropagation: 0.0992 sec; Batch: 0.4406 sec
0.1627 0.1564 0.1425 0.1366 0.1346 0.1332 0.1317 0.1305 0.1299 0.1297 0.1297 0.1296 0.1294 0.1293 0.1294 0.1292 

[TRAIN] Epoch[3](978/1500); Loss: 0.129070; Backpropagation: 0.0989 sec; Batch: 0.4733 sec
0.2021 0.1600 0.1417 0.1348 0.1275 0.1198 0.1182 0.1176 0.1177 0.1173 0.1176 0.1174 0.1180 0.1184 0.1183 0.1186 

[TRAIN] Epoch[3](979/1500); Loss: 0.058068; Backpropagation: 0.0993 sec; Batch: 0.4712 sec
0.1139 0.0750 0.0664 0.0571 0.0555 0.0532 0.0523 0.0517 0.0511 0.0513 0.0509 0.0503 0.0501 0.0500 0.0502 0.0500 

[TRAIN] Epoch[3](980/1500); Loss: 0.100424; Backpropagation: 0.0990 sec; Batch: 0.4700 sec
0.1362 0.1319 0.1064 0.1025 0.0955 0.0949 0.0940 0.0939 0.0937 0.0935 0.0936 0.0937 0.0939 0.0940 0.0944 0.0947 

[TRAIN] Epoch[3](981/1500); Loss: 0.129589; Backpropagation: 0.0990 sec; Batch: 0.4695 sec
0.1377 0.1397 0.1482 0.1300 0.1286 0.1267 0.1261 0.1256 0.1258 0.1258 0.1258 0.1262 0.1265 0.1265 0.1269 0.1273 

[TRAIN] Epoch[3](982/1500); Loss: 0.075190; Backpropagation: 0.1022 sec; Batch: 0.4434 sec
0.1490 0.1066 0.0869 0.0760 0.0696 0.0672 0.0658 0.0650 0.0644 0.0644 0.0645 0.0647 0.0643 0.0647 0.0647 0.0652 

[TRAIN] Epoch[3](983/1500); Loss: 0.073586; Backpropagation: 0.0984 sec; Batch: 0.4752 sec
0.1973 0.0990 0.0944 0.0716 0.0678 0.0612 0.0595 0.0589 0.0585 0.0588 0.0584 0.0582 0.0579 0.0582 0.0586 0.0591 

[TRAIN] Epoch[3](984/1500); Loss: 0.062881; Backpropagation: 0.0990 sec; Batch: 0.4985 sec
0.0984 0.0899 0.0659 0.0669 0.0610 0.0583 0.0571 0.0570 0.0563 0.0566 0.0562 0.0565 0.0562 0.0565 0.0564 0.0570 

[TRAIN] Epoch[3](985/1500); Loss: 0.146671; Backpropagation: 0.0989 sec; Batch: 0.4711 sec
0.1929 0.1659 0.1504 0.1488 0.1449 0.1435 0.1426 0.1418 0.1408 0.1402 0.1395 0.1393 0.1392 0.1389 0.1389 0.1392 

[TRAIN] Epoch[3](986/1500); Loss: 0.091313; Backpropagation: 0.0990 sec; Batch: 0.4543 sec
0.1518 0.1619 0.1129 0.0914 0.0856 0.0829 0.0812 0.0796 0.0787 0.0776 0.0771 0.0766 0.0762 0.0760 0.0760 0.0755 

[TRAIN] Epoch[3](987/1500); Loss: 0.102028; Backpropagation: 0.1081 sec; Batch: 0.4830 sec
0.1241 0.1234 0.1070 0.1028 0.1003 0.0994 0.0987 0.0982 0.0976 0.0974 0.0970 0.0973 0.0969 0.0973 0.0972 0.0977 

[TRAIN] Epoch[3](988/1500); Loss: 0.112696; Backpropagation: 0.1080 sec; Batch: 0.4789 sec
0.1468 0.1205 0.1191 0.1138 0.1122 0.1108 0.1097 0.1087 0.1084 0.1081 0.1076 0.1074 0.1073 0.1074 0.1077 0.1078 

[TRAIN] Epoch[3](989/1500); Loss: 0.130067; Backpropagation: 0.0992 sec; Batch: 0.4813 sec
0.1533 0.1456 0.1319 0.1320 0.1285 0.1272 0.1266 0.1263 0.1260 0.1258 0.1261 0.1263 0.1262 0.1263 0.1265 0.1267 

[TRAIN] Epoch[3](990/1500); Loss: 0.116210; Backpropagation: 0.0992 sec; Batch: 0.4344 sec
0.1733 0.1314 0.1245 0.1162 0.1150 0.1115 0.1112 0.1096 0.1098 0.1087 0.1087 0.1079 0.1085 0.1076 0.1080 0.1074 

[TRAIN] Epoch[3](991/1500); Loss: 0.084201; Backpropagation: 0.0990 sec; Batch: 0.4758 sec
0.1556 0.1483 0.0989 0.0766 0.0791 0.0746 0.0732 0.0719 0.0715 0.0710 0.0710 0.0710 0.0711 0.0708 0.0711 0.0714 

[TRAIN] Epoch[3](992/1500); Loss: 0.061164; Backpropagation: 0.1084 sec; Batch: 0.4804 sec
0.0976 0.0744 0.0732 0.0681 0.0601 0.0578 0.0566 0.0558 0.0552 0.0546 0.0541 0.0543 0.0541 0.0542 0.0542 0.0543 

[TRAIN] Epoch[3](993/1500); Loss: 0.112007; Backpropagation: 0.1022 sec; Batch: 0.4795 sec
0.1521 0.1190 0.1136 0.1116 0.1080 0.1078 0.1079 0.1073 0.1075 0.1074 0.1077 0.1081 0.1082 0.1083 0.1086 0.1088 

[TRAIN] Epoch[3](994/1500); Loss: 0.052991; Backpropagation: 0.0989 sec; Batch: 0.4700 sec
0.0592 0.0920 0.0588 0.0580 0.0532 0.0510 0.0491 0.0489 0.0470 0.0474 0.0468 0.0471 0.0470 0.0475 0.0473 0.0477 

[TRAIN] Epoch[3](995/1500); Loss: 0.136367; Backpropagation: 0.0990 sec; Batch: 0.4864 sec
0.1713 0.1597 0.1442 0.1379 0.1349 0.1325 0.1319 0.1310 0.1305 0.1301 0.1298 0.1296 0.1296 0.1297 0.1296 0.1296 

[TRAIN] Epoch[3](996/1500); Loss: 0.061602; Backpropagation: 0.0990 sec; Batch: 0.4708 sec
0.1437 0.0773 0.0855 0.0630 0.0623 0.0531 0.0514 0.0505 0.0499 0.0495 0.0496 0.0496 0.0495 0.0497 0.0503 0.0507 

[TRAIN] Epoch[3](997/1500); Loss: 0.090409; Backpropagation: 0.0990 sec; Batch: 0.4753 sec
0.1165 0.1106 0.0946 0.0886 0.0874 0.0868 0.0864 0.0866 0.0863 0.0860 0.0858 0.0860 0.0859 0.0861 0.0863 0.0868 

[TRAIN] Epoch[3](998/1500); Loss: 0.122529; Backpropagation: 0.0989 sec; Batch: 0.4701 sec
0.1758 0.1501 0.1392 0.1251 0.1205 0.1174 0.1162 0.1149 0.1143 0.1135 0.1132 0.1125 0.1123 0.1118 0.1119 0.1119 

[TRAIN] Epoch[3](999/1500); Loss: 0.103790; Backpropagation: 0.0991 sec; Batch: 0.4719 sec
0.1400 0.1328 0.1129 0.1036 0.1012 0.0995 0.0982 0.0977 0.0971 0.0970 0.0967 0.0969 0.0967 0.0970 0.0967 0.0967 

[TRAIN] Epoch[3](1000/1500); Loss: 0.122267; Backpropagation: 0.0990 sec; Batch: 0.4702 sec
0.1706 0.1542 0.1329 0.1214 0.1188 0.1167 0.1155 0.1148 0.1145 0.1143 0.1143 0.1141 0.1138 0.1135 0.1135 0.1136 

[TRAIN] Epoch[3](1001/1500); Loss: 0.112062; Backpropagation: 0.0990 sec; Batch: 0.4708 sec
0.1708 0.1490 0.1270 0.1149 0.1094 0.1054 0.1038 0.1033 0.1025 0.1021 0.1018 0.1009 0.1007 0.1007 0.1005 0.1002 

[TRAIN] Epoch[3](1002/1500); Loss: 0.060765; Backpropagation: 0.1078 sec; Batch: 0.4745 sec
0.0786 0.0743 0.0684 0.0616 0.0600 0.0585 0.0580 0.0577 0.0571 0.0568 0.0567 0.0568 0.0568 0.0569 0.0569 0.0570 

[TRAIN] Epoch[3](1003/1500); Loss: 0.063916; Backpropagation: 0.0991 sec; Batch: 0.4749 sec
0.0718 0.0980 0.0704 0.0773 0.0633 0.0634 0.0610 0.0601 0.0579 0.0579 0.0569 0.0571 0.0566 0.0570 0.0568 0.0571 

[TRAIN] Epoch[3](1004/1500); Loss: 0.146545; Backpropagation: 0.0943 sec; Batch: 0.7311 sec
0.1763 0.1578 0.1556 0.1487 0.1460 0.1451 0.1441 0.1432 0.1425 0.1418 0.1411 0.1408 0.1405 0.1405 0.1403 0.1404 

[TRAIN] Epoch[3](1005/1500); Loss: 0.075913; Backpropagation: 0.0938 sec; Batch: 0.5097 sec
0.1099 0.0990 0.0853 0.0744 0.0728 0.0716 0.0708 0.0706 0.0701 0.0700 0.0699 0.0698 0.0698 0.0699 0.0702 0.0704 

[TRAIN] Epoch[3](1006/1500); Loss: 0.148209; Backpropagation: 0.0937 sec; Batch: 0.4651 sec
0.1728 0.1701 0.1588 0.1507 0.1481 0.1465 0.1455 0.1447 0.1441 0.1435 0.1429 0.1420 0.1413 0.1407 0.1401 0.1396 

[TRAIN] Epoch[3](1007/1500); Loss: 0.076937; Backpropagation: 0.0939 sec; Batch: 0.4686 sec
0.1375 0.1148 0.0948 0.0853 0.0759 0.0670 0.0656 0.0654 0.0654 0.0651 0.0651 0.0652 0.0656 0.0657 0.0662 0.0664 

[TRAIN] Epoch[3](1008/1500); Loss: 0.157383; Backpropagation: 0.0937 sec; Batch: 0.4690 sec
0.1733 0.1792 0.1656 0.1611 0.1576 0.1559 0.1553 0.1544 0.1536 0.1532 0.1522 0.1517 0.1512 0.1512 0.1511 0.1512 

[TRAIN] Epoch[3](1009/1500); Loss: 0.086749; Backpropagation: 0.0937 sec; Batch: 0.4669 sec
0.1280 0.1055 0.0989 0.0879 0.0858 0.0839 0.0823 0.0812 0.0805 0.0798 0.0795 0.0793 0.0791 0.0789 0.0787 0.0786 

[TRAIN] Epoch[3](1010/1500); Loss: 0.096599; Backpropagation: 0.0936 sec; Batch: 0.4700 sec
0.1680 0.1331 0.1040 0.0966 0.0921 0.0899 0.0884 0.0876 0.0870 0.0859 0.0856 0.0853 0.0854 0.0855 0.0856 0.0855 

[TRAIN] Epoch[3](1011/1500); Loss: 0.168059; Backpropagation: 0.0941 sec; Batch: 0.5333 sec
0.1995 0.1865 0.1737 0.1679 0.1669 0.1657 0.1644 0.1636 0.1632 0.1628 0.1626 0.1626 0.1624 0.1624 0.1623 0.1625 

[TRAIN] Epoch[3](1012/1500); Loss: 0.201507; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.2464 0.2338 0.2151 0.2060 0.2013 0.1988 0.1968 0.1951 0.1936 0.1929 0.1923 0.1918 0.1911 0.1904 0.1897 0.1890 

[TRAIN] Epoch[3](1013/1500); Loss: 0.118490; Backpropagation: 0.0932 sec; Batch: 0.4696 sec
0.1831 0.1504 0.1297 0.1171 0.1126 0.1112 0.1104 0.1096 0.1095 0.1090 0.1088 0.1087 0.1087 0.1089 0.1091 0.1092 

[TRAIN] Epoch[3](1014/1500); Loss: 0.149024; Backpropagation: 0.0938 sec; Batch: 0.4565 sec
0.1799 0.1734 0.1591 0.1513 0.1480 0.1465 0.1452 0.1443 0.1434 0.1429 0.1423 0.1420 0.1418 0.1414 0.1414 0.1415 

[TRAIN] Epoch[3](1015/1500); Loss: 0.112448; Backpropagation: 0.0957 sec; Batch: 0.4876 sec
0.1737 0.1330 0.1149 0.1126 0.1076 0.1067 0.1063 0.1061 0.1055 0.1051 0.1049 0.1047 0.1047 0.1044 0.1043 0.1048 

[TRAIN] Epoch[3](1016/1500); Loss: 0.070717; Backpropagation: 0.0954 sec; Batch: 0.4700 sec
0.0919 0.0919 0.0950 0.0706 0.0679 0.0671 0.0659 0.0656 0.0656 0.0647 0.0644 0.0645 0.0639 0.0638 0.0642 0.0642 

[TRAIN] Epoch[3](1017/1500); Loss: 0.160533; Backpropagation: 0.0939 sec; Batch: 0.4527 sec
0.2105 0.2087 0.1749 0.1603 0.1551 0.1542 0.1528 0.1513 0.1505 0.1504 0.1504 0.1501 0.1498 0.1497 0.1497 0.1501 

[TRAIN] Epoch[3](1018/1500); Loss: 0.110015; Backpropagation: 0.0938 sec; Batch: 0.4704 sec
0.2090 0.1902 0.1357 0.1019 0.0985 0.0948 0.0941 0.0930 0.0926 0.0924 0.0926 0.0928 0.0928 0.0929 0.0932 0.0937 

[TRAIN] Epoch[3](1019/1500); Loss: 0.057885; Backpropagation: 0.0938 sec; Batch: 0.4674 sec
0.0790 0.0849 0.0610 0.0605 0.0555 0.0535 0.0529 0.0525 0.0526 0.0524 0.0525 0.0528 0.0533 0.0537 0.0541 0.0547 

[TRAIN] Epoch[3](1020/1500); Loss: 0.082951; Backpropagation: 0.0936 sec; Batch: 0.4703 sec
0.1255 0.1178 0.0971 0.0838 0.0788 0.0768 0.0754 0.0745 0.0743 0.0741 0.0743 0.0742 0.0745 0.0750 0.0754 0.0757 

[TRAIN] Epoch[3](1021/1500); Loss: 0.129139; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1754 0.1487 0.1403 0.1323 0.1265 0.1250 0.1241 0.1228 0.1217 0.1215 0.1211 0.1212 0.1210 0.1213 0.1217 0.1217 

[TRAIN] Epoch[3](1022/1500); Loss: 0.071889; Backpropagation: 0.0937 sec; Batch: 0.5205 sec
0.2645 0.1491 0.0619 0.0892 0.0498 0.0517 0.0503 0.0478 0.0471 0.0483 0.0473 0.0474 0.0486 0.0486 0.0492 0.0496 

[TRAIN] Epoch[3](1023/1500); Loss: 0.079709; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1623 0.1686 0.0899 0.0725 0.0674 0.0655 0.0652 0.0645 0.0640 0.0640 0.0642 0.0646 0.0650 0.0654 0.0658 0.0665 

[TRAIN] Epoch[3](1024/1500); Loss: 0.058338; Backpropagation: 0.0938 sec; Batch: 0.4680 sec
0.1072 0.0801 0.0578 0.0603 0.0543 0.0534 0.0523 0.0518 0.0518 0.0515 0.0516 0.0515 0.0520 0.0522 0.0527 0.0529 

[TRAIN] Epoch[3](1025/1500); Loss: 0.165018; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2039 0.1751 0.1685 0.1692 0.1639 0.1613 0.1608 0.1606 0.1601 0.1597 0.1597 0.1593 0.1596 0.1596 0.1596 0.1593 

[TRAIN] Epoch[3](1026/1500); Loss: 0.110365; Backpropagation: 0.0937 sec; Batch: 0.4701 sec
0.1799 0.1373 0.1158 0.1090 0.1057 0.1038 0.1025 0.1018 0.1012 0.1013 0.1008 0.1008 0.1009 0.1009 0.1017 0.1023 

[TRAIN] Epoch[3](1027/1500); Loss: 0.079448; Backpropagation: 0.0939 sec; Batch: 0.4727 sec
0.1184 0.0911 0.0867 0.0794 0.0767 0.0757 0.0751 0.0746 0.0743 0.0740 0.0736 0.0739 0.0741 0.0742 0.0745 0.0750 

[TRAIN] Epoch[3](1028/1500); Loss: 0.070774; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1110 0.0937 0.0781 0.0731 0.0708 0.0682 0.0666 0.0654 0.0646 0.0640 0.0636 0.0630 0.0628 0.0623 0.0625 0.0624 

[TRAIN] Epoch[3](1029/1500); Loss: 0.091087; Backpropagation: 0.0938 sec; Batch: 0.4346 sec
0.1195 0.1115 0.0947 0.0894 0.0888 0.0877 0.0869 0.0863 0.0863 0.0864 0.0860 0.0862 0.0864 0.0864 0.0876 0.0873 

[TRAIN] Epoch[3](1030/1500); Loss: 0.066388; Backpropagation: 0.0932 sec; Batch: 0.4307 sec
0.0670 0.0670 0.0898 0.0649 0.0644 0.0644 0.0641 0.0640 0.0639 0.0642 0.0633 0.0638 0.0644 0.0654 0.0656 0.0660 

[TRAIN] Epoch[3](1031/1500); Loss: 0.079480; Backpropagation: 0.0938 sec; Batch: 0.4722 sec
0.1344 0.1276 0.0916 0.0765 0.0739 0.0721 0.0706 0.0698 0.0694 0.0691 0.0694 0.0691 0.0693 0.0694 0.0695 0.0698 

[TRAIN] Epoch[3](1032/1500); Loss: 0.116065; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1780 0.1607 0.1291 0.1120 0.1092 0.1086 0.1070 0.1066 0.1057 0.1053 0.1054 0.1054 0.1054 0.1059 0.1062 0.1064 

[TRAIN] Epoch[3](1033/1500); Loss: 0.129376; Backpropagation: 0.0938 sec; Batch: 0.4470 sec
0.2479 0.1613 0.1324 0.1229 0.1236 0.1179 0.1169 0.1163 0.1158 0.1160 0.1161 0.1161 0.1164 0.1165 0.1166 0.1172 

[TRAIN] Epoch[3](1034/1500); Loss: 0.098841; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1615 0.1619 0.1197 0.0896 0.0895 0.0880 0.0872 0.0871 0.0869 0.0867 0.0868 0.0869 0.0873 0.0873 0.0874 0.0878 

[TRAIN] Epoch[3](1035/1500); Loss: 0.110650; Backpropagation: 0.0939 sec; Batch: 0.4709 sec
0.1635 0.1235 0.1166 0.1097 0.1081 0.1061 0.1060 0.1049 0.1047 0.1037 0.1040 0.1037 0.1038 0.1036 0.1043 0.1043 

[TRAIN] Epoch[3](1036/1500); Loss: 0.148874; Backpropagation: 0.0937 sec; Batch: 0.4660 sec
0.2033 0.1821 0.1562 0.1464 0.1433 0.1423 0.1416 0.1411 0.1407 0.1407 0.1407 0.1407 0.1408 0.1407 0.1407 0.1408 

[TRAIN] Epoch[3](1037/1500); Loss: 0.107344; Backpropagation: 0.0956 sec; Batch: 0.4301 sec
0.1574 0.1372 0.1126 0.1077 0.1042 0.1019 0.1010 0.1000 0.0995 0.0996 0.0994 0.0993 0.0993 0.0993 0.0994 0.0998 

[TRAIN] Epoch[3](1038/1500); Loss: 0.077566; Backpropagation: 0.0937 sec; Batch: 0.4360 sec
0.1467 0.0989 0.0895 0.0796 0.0751 0.0702 0.0688 0.0682 0.0680 0.0677 0.0676 0.0676 0.0679 0.0680 0.0684 0.0687 

[TRAIN] Epoch[3](1039/1500); Loss: 0.137187; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2344 0.1883 0.1456 0.1354 0.1293 0.1264 0.1248 0.1243 0.1239 0.1234 0.1230 0.1231 0.1232 0.1232 0.1231 0.1235 

[TRAIN] Epoch[3](1040/1500); Loss: 0.119964; Backpropagation: 0.0938 sec; Batch: 0.4726 sec
0.1816 0.1674 0.1327 0.1166 0.1138 0.1126 0.1120 0.1109 0.1103 0.1095 0.1092 0.1089 0.1088 0.1085 0.1084 0.1082 

[TRAIN] Epoch[3](1041/1500); Loss: 0.048709; Backpropagation: 0.0933 sec; Batch: 0.4662 sec
0.0887 0.0777 0.0544 0.0509 0.0463 0.0445 0.0435 0.0429 0.0425 0.0420 0.0415 0.0413 0.0407 0.0409 0.0406 0.0409 

[TRAIN] Epoch[3](1042/1500); Loss: 0.110076; Backpropagation: 0.0937 sec; Batch: 0.4703 sec
0.1467 0.1291 0.1174 0.1089 0.1078 0.1071 0.1061 0.1052 0.1046 0.1041 0.1042 0.1040 0.1039 0.1039 0.1040 0.1041 

[TRAIN] Epoch[3](1043/1500); Loss: 0.155567; Backpropagation: 0.0956 sec; Batch: 0.4734 sec
0.2350 0.2181 0.1706 0.1524 0.1494 0.1474 0.1459 0.1446 0.1434 0.1424 0.1415 0.1410 0.1402 0.1396 0.1390 0.1386 

[TRAIN] Epoch[3](1044/1500); Loss: 0.078808; Backpropagation: 0.0937 sec; Batch: 0.4696 sec
0.1278 0.1286 0.0897 0.0792 0.0748 0.0731 0.0718 0.0705 0.0693 0.0685 0.0680 0.0677 0.0677 0.0678 0.0680 0.0683 

[TRAIN] Epoch[3](1045/1500); Loss: 0.110162; Backpropagation: 0.0938 sec; Batch: 0.4693 sec
0.1578 0.1465 0.1248 0.1088 0.1065 0.1055 0.1040 0.1023 0.1020 0.1016 0.1012 0.1007 0.1005 0.1002 0.1001 0.1002 

[TRAIN] Epoch[3](1046/1500); Loss: 0.104731; Backpropagation: 0.0938 sec; Batch: 0.4673 sec
0.1501 0.1247 0.1100 0.1043 0.1027 0.1008 0.1001 0.0993 0.0990 0.0984 0.0983 0.0980 0.0976 0.0977 0.0973 0.0973 

[TRAIN] Epoch[3](1047/1500); Loss: 0.128664; Backpropagation: 0.0939 sec; Batch: 0.4459 sec
0.1745 0.1563 0.1334 0.1282 0.1248 0.1238 0.1233 0.1228 0.1222 0.1219 0.1218 0.1215 0.1214 0.1211 0.1210 0.1207 

[TRAIN] Epoch[3](1048/1500); Loss: 0.076570; Backpropagation: 0.0933 sec; Batch: 0.4696 sec
0.1187 0.1209 0.0825 0.0702 0.0732 0.0711 0.0696 0.0688 0.0686 0.0683 0.0685 0.0686 0.0689 0.0689 0.0691 0.0693 

[TRAIN] Epoch[3](1049/1500); Loss: 0.150279; Backpropagation: 0.0981 sec; Batch: 0.4680 sec
0.2083 0.1719 0.1561 0.1569 0.1484 0.1422 0.1429 0.1425 0.1413 0.1419 0.1416 0.1413 0.1421 0.1421 0.1422 0.1428 

[TRAIN] Epoch[3](1050/1500); Loss: 0.087123; Backpropagation: 0.0937 sec; Batch: 0.4697 sec
0.1432 0.1228 0.1015 0.0899 0.0830 0.0793 0.0785 0.0778 0.0773 0.0772 0.0771 0.0771 0.0771 0.0774 0.0774 0.0775 

[TRAIN] Epoch[3](1051/1500); Loss: 0.135514; Backpropagation: 0.0933 sec; Batch: 0.4664 sec
0.2021 0.1589 0.1364 0.1378 0.1334 0.1314 0.1302 0.1291 0.1283 0.1274 0.1263 0.1263 0.1255 0.1253 0.1253 0.1247 

[TRAIN] Epoch[3](1052/1500); Loss: 0.136072; Backpropagation: 0.0938 sec; Batch: 0.4312 sec
0.2191 0.1884 0.1445 0.1284 0.1308 0.1280 0.1260 0.1247 0.1244 0.1240 0.1237 0.1235 0.1233 0.1228 0.1228 0.1226 

[TRAIN] Epoch[3](1053/1500); Loss: 0.136977; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.2160 0.1705 0.1458 0.1374 0.1335 0.1305 0.1289 0.1273 0.1269 0.1258 0.1252 0.1249 0.1247 0.1245 0.1247 0.1250 

[TRAIN] Epoch[3](1054/1500); Loss: 0.118489; Backpropagation: 0.0938 sec; Batch: 0.4376 sec
0.1662 0.1395 0.1220 0.1189 0.1163 0.1143 0.1134 0.1127 0.1121 0.1118 0.1115 0.1113 0.1112 0.1113 0.1113 0.1117 

[TRAIN] Epoch[3](1055/1500); Loss: 0.145790; Backpropagation: 0.0935 sec; Batch: 0.4302 sec
0.2179 0.1756 0.1649 0.1465 0.1417 0.1390 0.1373 0.1361 0.1351 0.1345 0.1339 0.1339 0.1337 0.1340 0.1340 0.1342 

[TRAIN] Epoch[3](1056/1500); Loss: 0.075679; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.1676 0.0833 0.0894 0.0749 0.0754 0.0694 0.0673 0.0659 0.0654 0.0649 0.0646 0.0641 0.0646 0.0647 0.0647 0.0647 

[TRAIN] Epoch[3](1057/1500); Loss: 0.104363; Backpropagation: 0.0932 sec; Batch: 0.4656 sec
0.2342 0.1382 0.1227 0.0998 0.0989 0.0917 0.0897 0.0888 0.0884 0.0885 0.0882 0.0881 0.0878 0.0886 0.0880 0.0880 

[TRAIN] Epoch[3](1058/1500); Loss: 0.124437; Backpropagation: 0.0936 sec; Batch: 0.4701 sec
0.2101 0.2051 0.1426 0.1166 0.1152 0.1122 0.1107 0.1098 0.1091 0.1087 0.1085 0.1085 0.1085 0.1084 0.1086 0.1085 

[TRAIN] Epoch[3](1059/1500); Loss: 0.110372; Backpropagation: 0.0937 sec; Batch: 0.4672 sec
0.1761 0.1522 0.1190 0.1086 0.1066 0.1038 0.1026 0.1014 0.1006 0.1003 0.0997 0.0996 0.0990 0.0990 0.0986 0.0987 

[TRAIN] Epoch[3](1060/1500); Loss: 0.110483; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1848 0.1273 0.1197 0.1116 0.1056 0.1049 0.1031 0.1027 0.1017 0.1020 0.1009 0.1011 0.1005 0.1008 0.1003 0.1007 

[TRAIN] Epoch[3](1061/1500); Loss: 0.057566; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.0748 0.0949 0.0625 0.0590 0.0577 0.0542 0.0527 0.0517 0.0520 0.0517 0.0512 0.0515 0.0514 0.0516 0.0523 0.0520 

[TRAIN] Epoch[3](1062/1500); Loss: 0.097967; Backpropagation: 0.0937 sec; Batch: 0.4661 sec
0.1363 0.1188 0.1052 0.0979 0.0959 0.0942 0.0933 0.0927 0.0922 0.0919 0.0918 0.0915 0.0914 0.0916 0.0916 0.0913 

[TRAIN] Epoch[3](1063/1500); Loss: 0.114747; Backpropagation: 0.0941 sec; Batch: 0.4676 sec
0.1733 0.1516 0.1259 0.1152 0.1106 0.1081 0.1070 0.1061 0.1057 0.1053 0.1051 0.1050 0.1048 0.1043 0.1040 0.1039 

[TRAIN] Epoch[3](1064/1500); Loss: 0.106893; Backpropagation: 0.0937 sec; Batch: 0.4641 sec
0.1334 0.1270 0.1192 0.1090 0.1086 0.1035 0.1025 0.1014 0.1009 0.1005 0.1007 0.1008 0.1007 0.1006 0.1008 0.1010 

[TRAIN] Epoch[3](1065/1500); Loss: 0.070930; Backpropagation: 0.0938 sec; Batch: 0.4669 sec
0.1539 0.1123 0.0787 0.0694 0.0658 0.0621 0.0607 0.0597 0.0593 0.0592 0.0594 0.0589 0.0587 0.0587 0.0592 0.0589 

[TRAIN] Epoch[3](1066/1500); Loss: 0.080729; Backpropagation: 0.0936 sec; Batch: 0.4663 sec
0.0879 0.1154 0.0804 0.0885 0.0769 0.0772 0.0776 0.0783 0.0768 0.0768 0.0758 0.0767 0.0751 0.0756 0.0756 0.0772 

[TRAIN] Epoch[3](1067/1500); Loss: 0.137380; Backpropagation: 0.0939 sec; Batch: 0.4717 sec
0.1935 0.1695 0.1456 0.1361 0.1335 0.1325 0.1316 0.1304 0.1299 0.1290 0.1285 0.1282 0.1279 0.1274 0.1273 0.1271 

[TRAIN] Epoch[3](1068/1500); Loss: 0.095198; Backpropagation: 0.0937 sec; Batch: 0.4651 sec
0.2603 0.1559 0.0947 0.0892 0.0822 0.0780 0.0769 0.0765 0.0760 0.0767 0.0763 0.0762 0.0758 0.0759 0.0760 0.0766 

[TRAIN] Epoch[3](1069/1500); Loss: 0.078882; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1683 0.1418 0.1026 0.0772 0.0663 0.0675 0.0658 0.0647 0.0635 0.0635 0.0631 0.0635 0.0633 0.0636 0.0634 0.0639 

[TRAIN] Epoch[3](1070/1500); Loss: 0.102459; Backpropagation: 0.0949 sec; Batch: 0.4296 sec
0.1683 0.1587 0.1159 0.0975 0.0932 0.0944 0.0930 0.0927 0.0918 0.0914 0.0907 0.0908 0.0904 0.0903 0.0899 0.0903 

[TRAIN] Epoch[3](1071/1500); Loss: 0.182998; Backpropagation: 0.0938 sec; Batch: 0.5037 sec
0.2230 0.1981 0.1996 0.1880 0.1833 0.1782 0.1779 0.1772 0.1777 0.1758 0.1758 0.1748 0.1751 0.1745 0.1751 0.1738 

[TRAIN] Epoch[3](1072/1500); Loss: 0.111759; Backpropagation: 0.0937 sec; Batch: 0.4661 sec
0.1763 0.1526 0.1255 0.1110 0.1055 0.1028 0.1020 0.1015 0.1015 0.1014 0.1012 0.1012 0.1016 0.1013 0.1013 0.1013 

[TRAIN] Epoch[3](1073/1500); Loss: 0.089320; Backpropagation: 0.0934 sec; Batch: 0.4318 sec
0.1943 0.1470 0.0857 0.1140 0.1001 0.0872 0.0762 0.0712 0.0698 0.0696 0.0691 0.0693 0.0691 0.0689 0.0689 0.0689 

[TRAIN] Epoch[3](1074/1500); Loss: 0.121991; Backpropagation: 0.0937 sec; Batch: 0.4343 sec
0.2071 0.1744 0.1333 0.1216 0.1162 0.1130 0.1114 0.1101 0.1092 0.1085 0.1082 0.1079 0.1081 0.1077 0.1075 0.1075 

[TRAIN] Epoch[3](1075/1500); Loss: 0.066423; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.2006 0.0850 0.0837 0.0580 0.0572 0.0530 0.0524 0.0517 0.0521 0.0517 0.0521 0.0521 0.0526 0.0530 0.0536 0.0541 

[TRAIN] Epoch[3](1076/1500); Loss: 0.089931; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1433 0.1093 0.0917 0.0900 0.0859 0.0852 0.0839 0.0837 0.0837 0.0833 0.0832 0.0829 0.0834 0.0832 0.0830 0.0831 

[TRAIN] Epoch[3](1077/1500); Loss: 0.130018; Backpropagation: 0.0938 sec; Batch: 0.4694 sec
0.1636 0.1441 0.1345 0.1309 0.1274 0.1266 0.1263 0.1256 0.1253 0.1252 0.1252 0.1252 0.1252 0.1252 0.1251 0.1250 

[TRAIN] Epoch[3](1078/1500); Loss: 0.145684; Backpropagation: 0.0936 sec; Batch: 0.4699 sec
0.1907 0.1586 0.1521 0.1432 0.1421 0.1411 0.1407 0.1407 0.1404 0.1405 0.1403 0.1401 0.1400 0.1402 0.1401 0.1402 

[TRAIN] Epoch[3](1079/1500); Loss: 0.153255; Backpropagation: 0.0938 sec; Batch: 0.4343 sec
0.2046 0.1803 0.1646 0.1536 0.1502 0.1481 0.1469 0.1458 0.1454 0.1449 0.1447 0.1446 0.1447 0.1445 0.1445 0.1445 

[TRAIN] Epoch[3](1080/1500); Loss: 0.066231; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1109 0.0916 0.0822 0.0683 0.0638 0.0606 0.0600 0.0593 0.0591 0.0584 0.0583 0.0577 0.0576 0.0573 0.0573 0.0573 

[TRAIN] Epoch[3](1081/1500); Loss: 0.130298; Backpropagation: 0.0938 sec; Batch: 0.4690 sec
0.2003 0.1682 0.1527 0.1306 0.1275 0.1217 0.1205 0.1185 0.1182 0.1178 0.1179 0.1175 0.1180 0.1180 0.1186 0.1188 

[TRAIN] Epoch[3](1082/1500); Loss: 0.158901; Backpropagation: 0.0956 sec; Batch: 0.4678 sec
0.2483 0.2081 0.1774 0.1650 0.1501 0.1492 0.1469 0.1457 0.1450 0.1446 0.1443 0.1443 0.1438 0.1434 0.1433 0.1433 

[TRAIN] Epoch[3](1083/1500); Loss: 0.118741; Backpropagation: 0.0957 sec; Batch: 0.4672 sec
0.2856 0.1751 0.1163 0.1193 0.1050 0.1031 0.1022 0.1002 0.0999 0.0990 0.0991 0.0986 0.0989 0.0987 0.0994 0.0995 

[TRAIN] Epoch[3](1084/1500); Loss: 0.073358; Backpropagation: 0.0937 sec; Batch: 0.4755 sec
0.3004 0.1345 0.0602 0.0669 0.0637 0.0522 0.0518 0.0500 0.0502 0.0484 0.0488 0.0484 0.0494 0.0490 0.0500 0.0500 

[TRAIN] Epoch[3](1085/1500); Loss: 0.109849; Backpropagation: 0.0939 sec; Batch: 0.4313 sec
0.1588 0.1304 0.1187 0.1114 0.1084 0.1067 0.1053 0.1044 0.1035 0.1027 0.1020 0.1016 0.1012 0.1011 0.1008 0.1006 

[TRAIN] Epoch[3](1086/1500); Loss: 0.053632; Backpropagation: 0.0941 sec; Batch: 0.4293 sec
0.1261 0.1384 0.0816 0.0531 0.0442 0.0404 0.0394 0.0380 0.0372 0.0369 0.0366 0.0369 0.0367 0.0374 0.0374 0.0379 

[TRAIN] Epoch[3](1087/1500); Loss: 0.074497; Backpropagation: 0.0938 sec; Batch: 0.4735 sec
0.1699 0.1367 0.0974 0.0692 0.0631 0.0610 0.0595 0.0583 0.0579 0.0579 0.0583 0.0588 0.0596 0.0605 0.0614 0.0625 

[TRAIN] Epoch[3](1088/1500); Loss: 0.075061; Backpropagation: 0.0958 sec; Batch: 0.4306 sec
0.1675 0.1762 0.1103 0.0660 0.0587 0.0574 0.0560 0.0562 0.0558 0.0553 0.0558 0.0564 0.0567 0.0570 0.0575 0.0581 

[TRAIN] Epoch[3](1089/1500); Loss: 0.112889; Backpropagation: 0.0937 sec; Batch: 0.4713 sec
0.1669 0.1770 0.1291 0.1088 0.1072 0.1025 0.1016 0.1018 0.1011 0.1011 0.1009 0.1011 0.1015 0.1015 0.1019 0.1022 

[TRAIN] Epoch[3](1090/1500); Loss: 0.073096; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1895 0.1219 0.0823 0.0690 0.0670 0.0616 0.0597 0.0584 0.0583 0.0576 0.0570 0.0569 0.0572 0.0577 0.0576 0.0578 

[TRAIN] Epoch[3](1091/1500); Loss: 0.044643; Backpropagation: 0.0938 sec; Batch: 0.4437 sec
0.1035 0.1129 0.0770 0.0538 0.0352 0.0310 0.0309 0.0299 0.0294 0.0291 0.0305 0.0297 0.0297 0.0300 0.0308 0.0309 

[TRAIN] Epoch[3](1092/1500); Loss: 0.102133; Backpropagation: 0.0937 sec; Batch: 0.4331 sec
0.2960 0.2120 0.1347 0.0804 0.0884 0.0757 0.0785 0.0756 0.0753 0.0744 0.0742 0.0740 0.0740 0.0737 0.0737 0.0736 

[TRAIN] Epoch[3](1093/1500); Loss: 0.097130; Backpropagation: 0.0938 sec; Batch: 0.4343 sec
0.1984 0.1416 0.1129 0.0979 0.0881 0.0874 0.0855 0.0843 0.0837 0.0829 0.0827 0.0821 0.0819 0.0816 0.0815 0.0813 

[TRAIN] Epoch[3](1094/1500); Loss: 0.052012; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.0884 0.0907 0.0622 0.0540 0.0482 0.0447 0.0436 0.0434 0.0433 0.0434 0.0437 0.0444 0.0445 0.0453 0.0458 0.0466 

[TRAIN] Epoch[3](1095/1500); Loss: 0.131301; Backpropagation: 0.0932 sec; Batch: 0.4702 sec
0.2126 0.1624 0.1514 0.1266 0.1270 0.1223 0.1210 0.1196 0.1197 0.1193 0.1198 0.1195 0.1199 0.1197 0.1201 0.1200 

[TRAIN] Epoch[3](1096/1500); Loss: 0.065485; Backpropagation: 0.0937 sec; Batch: 0.4362 sec
0.1723 0.0614 0.0913 0.0586 0.0654 0.0566 0.0558 0.0550 0.0541 0.0536 0.0539 0.0543 0.0539 0.0537 0.0538 0.0541 

[TRAIN] Epoch[3](1097/1500); Loss: 0.154958; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2215 0.1729 0.1667 0.1554 0.1541 0.1498 0.1488 0.1472 0.1465 0.1461 0.1455 0.1451 0.1450 0.1448 0.1448 0.1451 

[TRAIN] Epoch[3](1098/1500); Loss: 0.122218; Backpropagation: 0.0936 sec; Batch: 0.4645 sec
0.2052 0.1949 0.1313 0.1242 0.1123 0.1095 0.1089 0.1085 0.1079 0.1080 0.1077 0.1074 0.1073 0.1075 0.1075 0.1074 

[TRAIN] Epoch[3](1099/1500); Loss: 0.114748; Backpropagation: 0.0938 sec; Batch: 0.4358 sec
0.2307 0.1634 0.1238 0.1106 0.1047 0.1024 0.1010 0.1008 0.1001 0.1000 0.0996 0.0997 0.1000 0.1001 0.0996 0.0996 

[TRAIN] Epoch[3](1100/1500); Loss: 0.151104; Backpropagation: 0.0940 sec; Batch: 0.4315 sec
0.1932 0.1712 0.1566 0.1536 0.1499 0.1488 0.1476 0.1466 0.1458 0.1452 0.1446 0.1439 0.1434 0.1430 0.1422 0.1419 

[TRAIN] Epoch[3](1101/1500); Loss: 0.113817; Backpropagation: 0.0937 sec; Batch: 0.4692 sec
0.2077 0.1899 0.1363 0.1101 0.1037 0.1018 0.1004 0.0990 0.0976 0.0970 0.0965 0.0963 0.0960 0.0966 0.0960 0.0962 

[TRAIN] Epoch[3](1102/1500); Loss: 0.116642; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1641 0.1509 0.1338 0.1229 0.1169 0.1114 0.1095 0.1083 0.1079 0.1067 0.1063 0.1057 0.1057 0.1055 0.1055 0.1052 

[TRAIN] Epoch[3](1103/1500); Loss: 0.093549; Backpropagation: 0.0933 sec; Batch: 0.4665 sec
0.1428 0.1374 0.1074 0.0926 0.0883 0.0864 0.0856 0.0852 0.0848 0.0842 0.0837 0.0836 0.0836 0.0836 0.0837 0.0838 

[TRAIN] Epoch[3](1104/1500); Loss: 0.091495; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.2194 0.1449 0.0983 0.0889 0.0801 0.0773 0.0758 0.0756 0.0754 0.0754 0.0753 0.0753 0.0754 0.0755 0.0759 0.0756 

[TRAIN] Epoch[3](1105/1500); Loss: 0.074391; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.2627 0.1385 0.0663 0.0836 0.0591 0.0575 0.0542 0.0528 0.0526 0.0519 0.0520 0.0515 0.0514 0.0521 0.0522 0.0519 

[TRAIN] Epoch[3](1106/1500); Loss: 0.116731; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2094 0.1684 0.1269 0.1157 0.1090 0.1070 0.1047 0.1040 0.1034 0.1035 0.1029 0.1027 0.1026 0.1027 0.1023 0.1026 

[TRAIN] Epoch[3](1107/1500); Loss: 0.070007; Backpropagation: 0.0933 sec; Batch: 0.4349 sec
0.0700 0.0749 0.1009 0.0671 0.0682 0.0673 0.0655 0.0652 0.0677 0.0655 0.0668 0.0682 0.0673 0.0681 0.0693 0.0680 

[TRAIN] Epoch[3](1108/1500); Loss: 0.083599; Backpropagation: 0.0936 sec; Batch: 0.4683 sec
0.1957 0.1909 0.1047 0.0761 0.0742 0.0667 0.0649 0.0641 0.0636 0.0628 0.0625 0.0626 0.0621 0.0620 0.0620 0.0626 

[TRAIN] Epoch[3](1109/1500); Loss: 0.076515; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.1064 0.1101 0.0803 0.0761 0.0741 0.0723 0.0716 0.0713 0.0707 0.0706 0.0704 0.0703 0.0701 0.0699 0.0699 0.0702 

[TRAIN] Epoch[3](1110/1500); Loss: 0.097606; Backpropagation: 0.0938 sec; Batch: 0.4700 sec
0.1770 0.1272 0.1015 0.0936 0.0935 0.0904 0.0893 0.0886 0.0880 0.0877 0.0876 0.0875 0.0875 0.0873 0.0875 0.0875 

[TRAIN] Epoch[3](1111/1500); Loss: 0.124005; Backpropagation: 0.0937 sec; Batch: 0.4699 sec
0.2060 0.1652 0.1303 0.1225 0.1153 0.1157 0.1143 0.1139 0.1133 0.1132 0.1128 0.1124 0.1123 0.1124 0.1122 0.1122 

[TRAIN] Epoch[3](1112/1500); Loss: 0.157246; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.2212 0.1674 0.1767 0.1687 0.1563 0.1493 0.1481 0.1477 0.1470 0.1475 0.1473 0.1468 0.1481 0.1480 0.1475 0.1483 

[TRAIN] Epoch[3](1113/1500); Loss: 0.112815; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.1574 0.1389 0.1195 0.1136 0.1100 0.1081 0.1071 0.1063 0.1057 0.1057 0.1056 0.1053 0.1055 0.1053 0.1055 0.1054 

[TRAIN] Epoch[3](1114/1500); Loss: 0.109382; Backpropagation: 0.0937 sec; Batch: 0.4698 sec
0.2430 0.1689 0.1324 0.0991 0.1063 0.0948 0.0922 0.0918 0.0910 0.0900 0.0902 0.0899 0.0905 0.0901 0.0902 0.0897 

[TRAIN] Epoch[3](1115/1500); Loss: 0.157134; Backpropagation: 0.0937 sec; Batch: 0.4676 sec
0.2630 0.2124 0.1740 0.1546 0.1487 0.1450 0.1438 0.1428 0.1421 0.1416 0.1413 0.1412 0.1409 0.1409 0.1408 0.1409 

[TRAIN] Epoch[3](1116/1500); Loss: 0.073331; Backpropagation: 0.0939 sec; Batch: 0.4680 sec
0.1955 0.1029 0.0883 0.0708 0.0656 0.0634 0.0616 0.0607 0.0596 0.0591 0.0582 0.0583 0.0578 0.0575 0.0569 0.0570 

[TRAIN] Epoch[3](1117/1500); Loss: 0.067090; Backpropagation: 0.0937 sec; Batch: 0.4653 sec
0.1725 0.0682 0.0790 0.0626 0.0623 0.0592 0.0581 0.0574 0.0566 0.0569 0.0562 0.0567 0.0562 0.0571 0.0567 0.0577 

[TRAIN] Epoch[3](1118/1500); Loss: 0.064472; Backpropagation: 0.0937 sec; Batch: 0.4661 sec
0.1662 0.0653 0.0763 0.0607 0.0598 0.0569 0.0558 0.0554 0.0543 0.0545 0.0539 0.0544 0.0542 0.0547 0.0542 0.0549 

[TRAIN] Epoch[3](1119/1500); Loss: 0.114772; Backpropagation: 0.0943 sec; Batch: 0.4645 sec
0.1755 0.1518 0.1349 0.1179 0.1146 0.1102 0.1081 0.1061 0.1053 0.1039 0.1027 0.1018 0.1016 0.1009 0.1008 0.1003 

[TRAIN] Epoch[3](1120/1500); Loss: 0.098122; Backpropagation: 0.0938 sec; Batch: 0.4766 sec
0.1850 0.1951 0.1305 0.0914 0.0881 0.0835 0.0815 0.0800 0.0796 0.0793 0.0792 0.0798 0.0795 0.0789 0.0792 0.0793 

[TRAIN] Epoch[3](1121/1500); Loss: 0.063910; Backpropagation: 0.0938 sec; Batch: 0.4671 sec
0.1266 0.0851 0.0747 0.0631 0.0585 0.0575 0.0563 0.0557 0.0557 0.0556 0.0553 0.0555 0.0557 0.0559 0.0560 0.0555 

[TRAIN] Epoch[3](1122/1500); Loss: 0.084812; Backpropagation: 0.0936 sec; Batch: 0.5028 sec
0.1692 0.0911 0.1031 0.0802 0.0801 0.0770 0.0761 0.0755 0.0757 0.0754 0.0750 0.0750 0.0760 0.0757 0.0755 0.0763 

[TRAIN] Epoch[3](1123/1500); Loss: 0.063525; Backpropagation: 0.0939 sec; Batch: 0.4675 sec
0.2510 0.1040 0.0737 0.0587 0.0503 0.0495 0.0450 0.0428 0.0428 0.0423 0.0421 0.0426 0.0428 0.0427 0.0427 0.0432 

[TRAIN] Epoch[3](1124/1500); Loss: 0.079022; Backpropagation: 0.0937 sec; Batch: 0.4499 sec
0.1277 0.1250 0.0997 0.0854 0.0749 0.0715 0.0712 0.0693 0.0683 0.0676 0.0678 0.0674 0.0669 0.0672 0.0674 0.0670 

[TRAIN] Epoch[3](1125/1500); Loss: 0.133430; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.2102 0.1790 0.1460 0.1384 0.1289 0.1274 0.1248 0.1222 0.1214 0.1215 0.1205 0.1194 0.1192 0.1189 0.1185 0.1184 

[TRAIN] Epoch[3](1126/1500); Loss: 0.104811; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.1692 0.1323 0.1167 0.1061 0.0984 0.0988 0.0979 0.0962 0.0954 0.0955 0.0950 0.0949 0.0942 0.0961 0.0955 0.0949 

[TRAIN] Epoch[3](1127/1500); Loss: 0.087750; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1025 0.1444 0.1373 0.1202 0.1011 0.0920 0.0845 0.0783 0.0733 0.0704 0.0677 0.0668 0.0664 0.0665 0.0663 0.0662 

[TRAIN] Epoch[3](1128/1500); Loss: 0.124380; Backpropagation: 0.0937 sec; Batch: 0.4644 sec
0.2112 0.1871 0.1624 0.1451 0.1283 0.1202 0.1153 0.1115 0.1087 0.1062 0.1038 0.1014 0.0996 0.0979 0.0965 0.0950 

[TRAIN] Epoch[3](1129/1500); Loss: 0.111435; Backpropagation: 0.0934 sec; Batch: 0.4459 sec
0.1746 0.1342 0.1508 0.1549 0.1321 0.1180 0.1045 0.0979 0.0919 0.0900 0.0875 0.0909 0.0896 0.0882 0.0875 0.0903 

[TRAIN] Epoch[3](1130/1500); Loss: 0.125424; Backpropagation: 0.0931 sec; Batch: 0.4308 sec
0.1887 0.1989 0.1923 0.1756 0.1519 0.1354 0.1235 0.1135 0.1062 0.1000 0.0950 0.0908 0.0873 0.0838 0.0823 0.0815 

[TRAIN] Epoch[3](1131/1500); Loss: 0.121281; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1735 0.2069 0.2293 0.2023 0.1636 0.1308 0.1053 0.0909 0.0874 0.0824 0.0798 0.0778 0.0787 0.0782 0.0776 0.0759 

[TRAIN] Epoch[3](1132/1500); Loss: 0.101414; Backpropagation: 0.0930 sec; Batch: 0.4691 sec
0.1589 0.1606 0.1207 0.1093 0.0996 0.0941 0.0907 0.0883 0.0889 0.0879 0.0872 0.0880 0.0866 0.0873 0.0880 0.0866 

[TRAIN] Epoch[3](1133/1500); Loss: 0.101148; Backpropagation: 0.0938 sec; Batch: 0.4680 sec
0.1560 0.1314 0.1241 0.1051 0.1002 0.0985 0.0963 0.0926 0.0915 0.0896 0.0897 0.0884 0.0886 0.0892 0.0894 0.0879 

[TRAIN] Epoch[3](1134/1500); Loss: 0.108527; Backpropagation: 0.0937 sec; Batch: 0.4699 sec
0.2127 0.1910 0.1768 0.1534 0.1245 0.1078 0.0939 0.0863 0.0805 0.0760 0.0739 0.0724 0.0718 0.0719 0.0718 0.0717 

[TRAIN] Epoch[3](1135/1500); Loss: 0.129769; Backpropagation: 0.0937 sec; Batch: 0.4673 sec
0.2001 0.1904 0.1833 0.1759 0.1555 0.1449 0.1325 0.1211 0.1146 0.1068 0.1020 0.0965 0.0940 0.0892 0.0861 0.0835 

[TRAIN] Epoch[3](1136/1500); Loss: 0.113927; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.1070 0.1966 0.2437 0.2250 0.1834 0.1472 0.1161 0.0904 0.0719 0.0640 0.0662 0.0644 0.0621 0.0608 0.0627 0.0614 

[TRAIN] Epoch[3](1137/1500); Loss: 0.100105; Backpropagation: 0.0939 sec; Batch: 0.4702 sec
0.1713 0.1161 0.1207 0.1068 0.1017 0.0929 0.0958 0.0929 0.0895 0.0860 0.0891 0.0883 0.0872 0.0862 0.0889 0.0883 

[TRAIN] Epoch[3](1138/1500); Loss: 0.152612; Backpropagation: 0.0937 sec; Batch: 0.4703 sec
0.2148 0.2177 0.2150 0.1938 0.1688 0.1514 0.1432 0.1357 0.1309 0.1270 0.1267 0.1252 0.1240 0.1231 0.1223 0.1222 

[TRAIN] Epoch[3](1139/1500); Loss: 0.115396; Backpropagation: 0.0933 sec; Batch: 0.4628 sec
0.1914 0.1552 0.1538 0.1387 0.1228 0.1160 0.1090 0.1028 0.0976 0.0952 0.0942 0.0940 0.0939 0.0936 0.0940 0.0940 

[TRAIN] Epoch[3](1140/1500); Loss: 0.105562; Backpropagation: 0.0932 sec; Batch: 0.4657 sec
0.1249 0.1643 0.2018 0.1883 0.1523 0.1228 0.0990 0.0825 0.0744 0.0767 0.0728 0.0673 0.0646 0.0674 0.0665 0.0635 

[TRAIN] Epoch[3](1141/1500); Loss: 0.133960; Backpropagation: 0.0937 sec; Batch: 0.4682 sec
0.2205 0.2139 0.1933 0.1758 0.1507 0.1328 0.1194 0.1104 0.1059 0.1043 0.1034 0.1028 0.1023 0.1019 0.1029 0.1029 

[TRAIN] Epoch[3](1142/1500); Loss: 0.162285; Backpropagation: 0.0938 sec; Batch: 0.4320 sec
0.2187 0.2180 0.2203 0.2033 0.1791 0.1619 0.1506 0.1451 0.1409 0.1385 0.1367 0.1370 0.1370 0.1367 0.1365 0.1361 

[TRAIN] Epoch[3](1143/1500); Loss: 0.186391; Backpropagation: 0.0939 sec; Batch: 0.4292 sec
0.2537 0.2608 0.2590 0.2347 0.2021 0.1828 0.1723 0.1663 0.1620 0.1592 0.1575 0.1570 0.1556 0.1542 0.1529 0.1522 

[TRAIN] Epoch[3](1144/1500); Loss: 0.138778; Backpropagation: 0.0948 sec; Batch: 0.4722 sec
0.1967 0.1957 0.1922 0.1777 0.1547 0.1397 0.1305 0.1267 0.1216 0.1172 0.1151 0.1130 0.1120 0.1106 0.1090 0.1081 

[TRAIN] Epoch[3](1145/1500); Loss: 0.160833; Backpropagation: 0.0939 sec; Batch: 0.4656 sec
0.3118 0.2376 0.1796 0.1839 0.1562 0.1462 0.1460 0.1413 0.1367 0.1352 0.1346 0.1340 0.1331 0.1323 0.1325 0.1322 

[TRAIN] Epoch[3](1146/1500); Loss: 0.085163; Backpropagation: 0.0939 sec; Batch: 0.4361 sec
0.1518 0.1128 0.1065 0.0858 0.0883 0.0805 0.0775 0.0732 0.0739 0.0728 0.0727 0.0733 0.0726 0.0732 0.0737 0.0739 

[TRAIN] Epoch[3](1147/1500); Loss: 0.070879; Backpropagation: 0.0939 sec; Batch: 0.5016 sec
0.3021 0.1188 0.0607 0.0751 0.0453 0.0529 0.0509 0.0454 0.0450 0.0472 0.0461 0.0470 0.0474 0.0476 0.0513 0.0512 

[TRAIN] Epoch[3](1148/1500); Loss: 0.064021; Backpropagation: 0.0937 sec; Batch: 0.4695 sec
0.1180 0.1290 0.1122 0.0906 0.0728 0.0599 0.0509 0.0451 0.0428 0.0421 0.0423 0.0423 0.0430 0.0436 0.0444 0.0454 

[TRAIN] Epoch[3](1149/1500); Loss: 0.136797; Backpropagation: 0.0939 sec; Batch: 0.4712 sec
0.2138 0.2059 0.1906 0.1579 0.1380 0.1243 0.1198 0.1177 0.1157 0.1154 0.1146 0.1149 0.1146 0.1151 0.1149 0.1155 

[TRAIN] Epoch[3](1150/1500); Loss: 0.140331; Backpropagation: 0.0980 sec; Batch: 0.4713 sec
0.2068 0.2036 0.1767 0.1536 0.1400 0.1315 0.1282 0.1253 0.1242 0.1233 0.1230 0.1220 0.1221 0.1211 0.1220 0.1220 

[TRAIN] Epoch[3](1151/1500); Loss: 0.179311; Backpropagation: 0.0957 sec; Batch: 0.4681 sec
0.2657 0.2926 0.2623 0.2257 0.1850 0.1626 0.1533 0.1505 0.1479 0.1465 0.1470 0.1470 0.1464 0.1458 0.1454 0.1454 

[TRAIN] Epoch[3](1152/1500); Loss: 0.073847; Backpropagation: 0.0936 sec; Batch: 0.4922 sec
0.3652 0.1601 0.0441 0.0967 0.0334 0.0504 0.0420 0.0426 0.0398 0.0400 0.0409 0.0393 0.0465 0.0466 0.0443 0.0497 

[TRAIN] Epoch[3](1153/1500); Loss: 0.071417; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.3201 0.1648 0.0656 0.0666 0.0478 0.0452 0.0442 0.0422 0.0407 0.0416 0.0421 0.0425 0.0428 0.0449 0.0450 0.0465 

[TRAIN] Epoch[3](1154/1500); Loss: 0.172147; Backpropagation: 0.0937 sec; Batch: 0.4663 sec
0.2822 0.2350 0.1841 0.1674 0.1613 0.1603 0.1577 0.1571 0.1569 0.1565 0.1560 0.1562 0.1564 0.1557 0.1558 0.1556 

[TRAIN] Epoch[3](1155/1500); Loss: 0.102442; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.3369 0.2321 0.1411 0.0839 0.0824 0.0712 0.0725 0.0683 0.0671 0.0687 0.0678 0.0683 0.0682 0.0694 0.0699 0.0713 

[TRAIN] Epoch[3](1156/1500); Loss: 0.155690; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.2383 0.2647 0.2187 0.1713 0.1446 0.1350 0.1350 0.1334 0.1330 0.1323 0.1318 0.1314 0.1310 0.1304 0.1302 0.1298 

[TRAIN] Epoch[3](1157/1500); Loss: 0.143645; Backpropagation: 0.0940 sec; Batch: 0.4302 sec
0.2254 0.1708 0.1522 0.1383 0.1381 0.1349 0.1341 0.1328 0.1331 0.1328 0.1337 0.1336 0.1343 0.1343 0.1348 0.1351 

[TRAIN] Epoch[3](1158/1500); Loss: 0.118129; Backpropagation: 0.0937 sec; Batch: 0.4653 sec
0.2575 0.1747 0.1367 0.1168 0.1110 0.1054 0.1023 0.1003 0.0987 0.0975 0.0975 0.0977 0.0977 0.0985 0.0989 0.0991 

[TRAIN] Epoch[3](1159/1500); Loss: 0.076301; Backpropagation: 0.0939 sec; Batch: 0.4674 sec
0.2533 0.1165 0.0681 0.0660 0.0709 0.0587 0.0618 0.0566 0.0568 0.0564 0.0577 0.0575 0.0590 0.0593 0.0609 0.0614 

[TRAIN] Epoch[3](1160/1500); Loss: 0.049643; Backpropagation: 0.0936 sec; Batch: 0.4821 sec
0.1244 0.0647 0.0510 0.0541 0.0462 0.0437 0.0414 0.0399 0.0400 0.0397 0.0398 0.0406 0.0409 0.0418 0.0425 0.0437 

[TRAIN] Epoch[3](1161/1500); Loss: 0.122614; Backpropagation: 0.0937 sec; Batch: 0.4700 sec
0.1643 0.1414 0.1256 0.1198 0.1194 0.1170 0.1175 0.1169 0.1168 0.1169 0.1172 0.1173 0.1175 0.1177 0.1180 0.1185 

[TRAIN] Epoch[3](1162/1500); Loss: 0.149908; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.2878 0.1872 0.1491 0.1443 0.1460 0.1408 0.1351 0.1330 0.1328 0.1334 0.1337 0.1340 0.1342 0.1349 0.1356 0.1368 

[TRAIN] Epoch[3](1163/1500); Loss: 0.073210; Backpropagation: 0.0938 sec; Batch: 0.4705 sec
0.3382 0.1089 0.0911 0.0608 0.0486 0.0521 0.0493 0.0436 0.0441 0.0435 0.0448 0.0450 0.0475 0.0485 0.0523 0.0533 

[TRAIN] Epoch[3](1164/1500); Loss: 0.104152; Backpropagation: 0.0931 sec; Batch: 0.4670 sec
0.2658 0.1402 0.1131 0.0965 0.1101 0.0906 0.0881 0.0853 0.0847 0.0843 0.0839 0.0835 0.0842 0.0844 0.0857 0.0860 

[TRAIN] Epoch[3](1165/1500); Loss: 0.082914; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1320 0.1319 0.0973 0.0827 0.0784 0.0761 0.0753 0.0745 0.0732 0.0729 0.0725 0.0722 0.0719 0.0718 0.0719 0.0720 

[TRAIN] Epoch[3](1166/1500); Loss: 0.115242; Backpropagation: 0.0946 sec; Batch: 0.4291 sec
0.2384 0.1795 0.1312 0.1151 0.1076 0.1062 0.1016 0.0982 0.0969 0.0961 0.0955 0.0952 0.0951 0.0954 0.0957 0.0961 

[TRAIN] Epoch[3](1167/1500); Loss: 0.079652; Backpropagation: 0.0937 sec; Batch: 0.4702 sec
0.2091 0.0931 0.0848 0.0744 0.0747 0.0684 0.0671 0.0660 0.0659 0.0662 0.0664 0.0667 0.0670 0.0677 0.0682 0.0688 

[TRAIN] Epoch[3](1168/1500); Loss: 0.115126; Backpropagation: 0.0937 sec; Batch: 0.4629 sec
0.1907 0.1218 0.1156 0.1224 0.1121 0.1106 0.1081 0.1073 0.1071 0.1068 0.1066 0.1065 0.1065 0.1066 0.1065 0.1066 

[TRAIN] Epoch[3](1169/1500); Loss: 0.053934; Backpropagation: 0.0939 sec; Batch: 0.4676 sec
0.0906 0.0987 0.0587 0.0493 0.0481 0.0475 0.0459 0.0456 0.0458 0.0460 0.0463 0.0472 0.0475 0.0479 0.0486 0.0494 

[TRAIN] Epoch[3](1170/1500); Loss: 0.125630; Backpropagation: 0.0931 sec; Batch: 0.4969 sec
0.1731 0.1430 0.1266 0.1226 0.1231 0.1215 0.1211 0.1207 0.1202 0.1199 0.1199 0.1199 0.1198 0.1196 0.1196 0.1196 

[TRAIN] Epoch[3](1171/1500); Loss: 0.093853; Backpropagation: 0.0932 sec; Batch: 0.4709 sec
0.2376 0.1539 0.0962 0.0886 0.0776 0.0886 0.0785 0.0762 0.0758 0.0746 0.0750 0.0749 0.0756 0.0757 0.0763 0.0767 

[TRAIN] Epoch[3](1172/1500); Loss: 0.140368; Backpropagation: 0.0935 sec; Batch: 0.4628 sec
0.1857 0.1612 0.1433 0.1390 0.1362 0.1344 0.1341 0.1339 0.1339 0.1338 0.1339 0.1343 0.1347 0.1352 0.1357 0.1363 

[TRAIN] Epoch[3](1173/1500); Loss: 0.072335; Backpropagation: 0.0939 sec; Batch: 0.4702 sec
0.1110 0.1194 0.0801 0.0686 0.0656 0.0640 0.0647 0.0637 0.0638 0.0637 0.0642 0.0645 0.0652 0.0655 0.0663 0.0671 

[TRAIN] Epoch[3](1174/1500); Loss: 0.113447; Backpropagation: 0.0936 sec; Batch: 0.4670 sec
0.2751 0.1527 0.1126 0.1031 0.1234 0.1057 0.1036 0.0964 0.0941 0.0928 0.0923 0.0921 0.0923 0.0928 0.0929 0.0933 

[TRAIN] Epoch[3](1175/1500); Loss: 0.084043; Backpropagation: 0.0940 sec; Batch: 0.4714 sec
0.1666 0.1542 0.0830 0.0843 0.0800 0.0758 0.0724 0.0707 0.0697 0.0696 0.0692 0.0695 0.0694 0.0696 0.0701 0.0706 

[TRAIN] Epoch[3](1176/1500); Loss: 0.088084; Backpropagation: 0.0937 sec; Batch: 0.4657 sec
0.1535 0.1171 0.0892 0.0874 0.0823 0.0840 0.0812 0.0806 0.0794 0.0789 0.0788 0.0790 0.0792 0.0794 0.0795 0.0798 

[TRAIN] Epoch[3](1177/1500); Loss: 0.131685; Backpropagation: 0.0937 sec; Batch: 0.4671 sec
0.2009 0.1489 0.1414 0.1297 0.1358 0.1264 0.1235 0.1218 0.1220 0.1218 0.1218 0.1221 0.1224 0.1226 0.1228 0.1230 

[TRAIN] Epoch[3](1178/1500); Loss: 0.076839; Backpropagation: 0.0980 sec; Batch: 0.4723 sec
0.2059 0.0979 0.1214 0.1036 0.0599 0.0588 0.0598 0.0571 0.0584 0.0565 0.0574 0.0563 0.0580 0.0587 0.0598 0.0599 

[TRAIN] Epoch[3](1179/1500); Loss: 0.062726; Backpropagation: 0.0957 sec; Batch: 0.4679 sec
0.1047 0.0926 0.0713 0.0601 0.0606 0.0584 0.0574 0.0549 0.0543 0.0538 0.0550 0.0548 0.0557 0.0560 0.0565 0.0575 

[TRAIN] Epoch[3](1180/1500); Loss: 0.108934; Backpropagation: 0.0937 sec; Batch: 0.4639 sec
0.1656 0.1512 0.1154 0.1155 0.1055 0.1044 0.1018 0.0999 0.0983 0.0974 0.0974 0.0977 0.0979 0.0979 0.0984 0.0986 

[TRAIN] Epoch[3](1181/1500); Loss: 0.075571; Backpropagation: 0.0931 sec; Batch: 0.4703 sec
0.1856 0.0843 0.0922 0.0735 0.0876 0.0707 0.0674 0.0630 0.0621 0.0606 0.0609 0.0600 0.0605 0.0602 0.0604 0.0601 

[TRAIN] Epoch[3](1182/1500); Loss: 0.089365; Backpropagation: 0.0932 sec; Batch: 0.4665 sec
0.1532 0.1121 0.1022 0.1041 0.1004 0.0856 0.0797 0.0774 0.0757 0.0759 0.0763 0.0766 0.0765 0.0774 0.0781 0.0786 

[TRAIN] Epoch[3](1183/1500); Loss: 0.111890; Backpropagation: 0.0937 sec; Batch: 0.4670 sec
0.1804 0.1345 0.1162 0.1113 0.1100 0.1066 0.1055 0.1039 0.1033 0.1026 0.1025 0.1023 0.1025 0.1026 0.1030 0.1031 

[TRAIN] Epoch[3](1184/1500); Loss: 0.073855; Backpropagation: 0.0956 sec; Batch: 0.4685 sec
0.2070 0.0980 0.1094 0.0907 0.0604 0.0559 0.0569 0.0538 0.0566 0.0541 0.0568 0.0546 0.0565 0.0554 0.0583 0.0573 

[TRAIN] Epoch[3](1185/1500); Loss: 0.095210; Backpropagation: 0.0956 sec; Batch: 0.4610 sec
0.3284 0.1703 0.0890 0.0838 0.0785 0.0956 0.0816 0.0760 0.0692 0.0661 0.0642 0.0641 0.0639 0.0640 0.0641 0.0647 

[TRAIN] Epoch[3](1186/1500); Loss: 0.047265; Backpropagation: 0.0938 sec; Batch: 0.4698 sec
0.0865 0.0390 0.0632 0.0450 0.0498 0.0475 0.0455 0.0421 0.0417 0.0418 0.0416 0.0419 0.0420 0.0427 0.0428 0.0432 

[TRAIN] Epoch[3](1187/1500); Loss: 0.128761; Backpropagation: 0.0937 sec; Batch: 0.4709 sec
0.1736 0.1575 0.1352 0.1265 0.1263 0.1234 0.1228 0.1221 0.1218 0.1214 0.1213 0.1213 0.1217 0.1215 0.1217 0.1220 

[TRAIN] Epoch[3](1188/1500); Loss: 0.127208; Backpropagation: 0.0936 sec; Batch: 0.4662 sec
0.2290 0.1490 0.1360 0.1253 0.1311 0.1201 0.1171 0.1153 0.1146 0.1142 0.1140 0.1137 0.1139 0.1138 0.1141 0.1141 

[TRAIN] Epoch[3](1189/1500); Loss: 0.114498; Backpropagation: 0.0957 sec; Batch: 0.4694 sec
0.1687 0.1303 0.1137 0.1146 0.1100 0.1077 0.1072 0.1071 0.1077 0.1078 0.1085 0.1089 0.1094 0.1098 0.1101 0.1106 

[TRAIN] Epoch[3](1190/1500); Loss: 0.117540; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1620 0.1553 0.1377 0.1244 0.1262 0.1130 0.1109 0.1077 0.1065 0.1056 0.1054 0.1052 0.1050 0.1047 0.1053 0.1057 

[TRAIN] Epoch[3](1191/1500); Loss: 0.147805; Backpropagation: 0.0931 sec; Batch: 0.4658 sec
0.2045 0.1610 0.1592 0.1602 0.1525 0.1463 0.1421 0.1395 0.1386 0.1377 0.1376 0.1373 0.1372 0.1370 0.1370 0.1371 

[TRAIN] Epoch[3](1192/1500); Loss: 0.109173; Backpropagation: 0.0937 sec; Batch: 0.4728 sec
0.1734 0.1240 0.1069 0.1125 0.1067 0.1047 0.1028 0.1018 0.1015 0.1013 0.1012 0.1013 0.1018 0.1019 0.1024 0.1027 

[TRAIN] Epoch[3](1193/1500); Loss: 0.098807; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.1920 0.1527 0.1080 0.1116 0.0922 0.0978 0.0888 0.0837 0.0823 0.0820 0.0821 0.0815 0.0816 0.0813 0.0816 0.0817 

[TRAIN] Epoch[3](1194/1500); Loss: 0.142127; Backpropagation: 0.0937 sec; Batch: 0.4659 sec
0.1780 0.1678 0.1671 0.1609 0.1469 0.1371 0.1335 0.1321 0.1311 0.1300 0.1309 0.1313 0.1310 0.1317 0.1318 0.1327 

[TRAIN] Epoch[3](1195/1500); Loss: 0.080337; Backpropagation: 0.0938 sec; Batch: 0.4657 sec
0.1611 0.1191 0.0877 0.0762 0.0797 0.0759 0.0728 0.0703 0.0683 0.0677 0.0675 0.0673 0.0677 0.0678 0.0679 0.0684 

[TRAIN] Epoch[3](1196/1500); Loss: 0.093936; Backpropagation: 0.0937 sec; Batch: 0.4700 sec
0.1229 0.1038 0.0953 0.0905 0.0904 0.0891 0.0882 0.0886 0.0890 0.0895 0.0903 0.0912 0.0921 0.0931 0.0941 0.0949 

[TRAIN] Epoch[3](1197/1500); Loss: 0.087402; Backpropagation: 0.0937 sec; Batch: 0.5205 sec
0.3022 0.1020 0.0945 0.0652 0.1410 0.1087 0.0847 0.0651 0.0563 0.0548 0.0535 0.0534 0.0539 0.0541 0.0540 0.0550 

[TRAIN] Epoch[3](1198/1500); Loss: 0.132125; Backpropagation: 0.0940 sec; Batch: 0.4671 sec
0.1810 0.1777 0.1521 0.1388 0.1306 0.1274 0.1241 0.1233 0.1219 0.1213 0.1206 0.1199 0.1193 0.1191 0.1185 0.1183 

[TRAIN] Epoch[3](1199/1500); Loss: 0.120233; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.1587 0.1442 0.1274 0.1204 0.1166 0.1151 0.1144 0.1140 0.1138 0.1135 0.1137 0.1139 0.1141 0.1144 0.1146 0.1149 

[TRAIN] Epoch[3](1200/1500); Loss: 0.094441; Backpropagation: 0.0936 sec; Batch: 0.4977 sec
0.2503 0.1458 0.0907 0.0926 0.0813 0.0846 0.0800 0.0768 0.0753 0.0751 0.0751 0.0757 0.0759 0.0767 0.0772 0.0778 

[TRAIN] Epoch[3](1201/1500); Loss: 0.131734; Backpropagation: 0.0937 sec; Batch: 0.4660 sec
0.1777 0.1521 0.1394 0.1370 0.1336 0.1302 0.1272 0.1258 0.1249 0.1242 0.1235 0.1226 0.1226 0.1223 0.1225 0.1222 

[TRAIN] Epoch[3](1202/1500); Loss: 0.131106; Backpropagation: 0.0931 sec; Batch: 0.4467 sec
0.1891 0.1564 0.1373 0.1537 0.1365 0.1279 0.1230 0.1209 0.1201 0.1194 0.1190 0.1189 0.1187 0.1188 0.1190 0.1191 

[TRAIN] Epoch[3](1203/1500); Loss: 0.079632; Backpropagation: 0.0938 sec; Batch: 0.4706 sec
0.1501 0.0992 0.0813 0.0832 0.0791 0.0756 0.0733 0.0714 0.0707 0.0702 0.0701 0.0701 0.0698 0.0699 0.0698 0.0702 

[TRAIN] Epoch[3](1204/1500); Loss: 0.090947; Backpropagation: 0.0936 sec; Batch: 0.4668 sec
0.1191 0.1398 0.1081 0.0936 0.0882 0.0883 0.0845 0.0827 0.0819 0.0810 0.0810 0.0810 0.0811 0.0814 0.0817 0.0819 

[TRAIN] Epoch[3](1205/1500); Loss: 0.081659; Backpropagation: 0.0939 sec; Batch: 0.4712 sec
0.1743 0.1147 0.0871 0.0821 0.0828 0.0758 0.0721 0.0699 0.0685 0.0682 0.0683 0.0683 0.0683 0.0686 0.0686 0.0690 

[TRAIN] Epoch[3](1206/1500); Loss: 0.097388; Backpropagation: 0.0936 sec; Batch: 0.4653 sec
0.3560 0.1322 0.0874 0.0616 0.1609 0.1180 0.0879 0.0697 0.0596 0.0601 0.0592 0.0604 0.0593 0.0613 0.0611 0.0636 

[TRAIN] Epoch[3](1207/1500); Loss: 0.086339; Backpropagation: 0.0938 sec; Batch: 0.4712 sec
0.3525 0.1377 0.0695 0.0487 0.1334 0.0947 0.0722 0.0578 0.0525 0.0525 0.0509 0.0514 0.0509 0.0519 0.0518 0.0531 

[TRAIN] Epoch[3](1208/1500); Loss: 0.094410; Backpropagation: 0.0938 sec; Batch: 0.4708 sec
0.1297 0.1143 0.1013 0.1051 0.0948 0.0916 0.0892 0.0881 0.0875 0.0870 0.0869 0.0868 0.0870 0.0870 0.0870 0.0873 

[TRAIN] Epoch[3](1209/1500); Loss: 0.105800; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.3212 0.1332 0.0946 0.0781 0.1377 0.1072 0.0893 0.0835 0.0804 0.0808 0.0803 0.0806 0.0805 0.0812 0.0816 0.0825 

[TRAIN] Epoch[3](1210/1500); Loss: 0.102698; Backpropagation: 0.0937 sec; Batch: 0.4703 sec
0.1788 0.1374 0.1272 0.1075 0.1001 0.0910 0.0912 0.0876 0.0878 0.0868 0.0880 0.0886 0.0902 0.0916 0.0936 0.0958 

[TRAIN] Epoch[3](1211/1500); Loss: 0.097635; Backpropagation: 0.0956 sec; Batch: 0.4688 sec
0.2025 0.1227 0.1051 0.0973 0.0998 0.0928 0.0888 0.0858 0.0847 0.0839 0.0837 0.0833 0.0831 0.0828 0.0830 0.0829 

[TRAIN] Epoch[3](1212/1500); Loss: 0.142729; Backpropagation: 0.0981 sec; Batch: 0.4734 sec
0.1833 0.1676 0.1545 0.1431 0.1457 0.1402 0.1385 0.1365 0.1359 0.1351 0.1348 0.1341 0.1340 0.1337 0.1335 0.1332 

[TRAIN] Epoch[3](1213/1500); Loss: 0.048714; Backpropagation: 0.0937 sec; Batch: 0.4668 sec
0.0871 0.0648 0.0709 0.0543 0.0483 0.0432 0.0422 0.0400 0.0410 0.0399 0.0410 0.0402 0.0410 0.0406 0.0426 0.0423 

[TRAIN] Epoch[3](1214/1500); Loss: 0.081881; Backpropagation: 0.0938 sec; Batch: 0.4307 sec
0.3317 0.1673 0.0694 0.1040 0.0817 0.0644 0.0568 0.0492 0.0497 0.0477 0.0482 0.0471 0.0479 0.0475 0.0487 0.0489 

[TRAIN] Epoch[3](1215/1500); Loss: 0.113670; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1875 0.1529 0.1182 0.1167 0.1093 0.1054 0.1045 0.1038 0.1030 0.1026 0.1024 0.1023 0.1023 0.1025 0.1025 0.1026 

[TRAIN] Epoch[3](1216/1500); Loss: 0.127426; Backpropagation: 0.0932 sec; Batch: 0.4318 sec
0.2526 0.1715 0.1247 0.1330 0.1448 0.1237 0.1163 0.1112 0.1086 0.1077 0.1073 0.1069 0.1071 0.1073 0.1077 0.1084 

[TRAIN] Epoch[3](1217/1500); Loss: 0.070947; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1262 0.1275 0.0685 0.0633 0.0731 0.0648 0.0632 0.0604 0.0605 0.0602 0.0606 0.0604 0.0612 0.0614 0.0618 0.0622 

[TRAIN] Epoch[3](1218/1500); Loss: 0.119734; Backpropagation: 0.0940 sec; Batch: 0.4651 sec
0.1698 0.1334 0.1220 0.1257 0.1182 0.1179 0.1149 0.1141 0.1133 0.1129 0.1128 0.1126 0.1127 0.1121 0.1120 0.1116 

[TRAIN] Epoch[3](1219/1500); Loss: 0.108394; Backpropagation: 0.0937 sec; Batch: 0.4744 sec
0.1581 0.1284 0.1123 0.1076 0.1065 0.1033 0.1032 0.1024 0.1022 0.1018 0.1021 0.1018 0.1014 0.1010 0.1012 0.1011 

[TRAIN] Epoch[3](1220/1500); Loss: 0.072956; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.1321 0.0885 0.0783 0.0750 0.0693 0.0695 0.0663 0.0655 0.0649 0.0650 0.0650 0.0650 0.0652 0.0655 0.0659 0.0663 

[TRAIN] Epoch[3](1221/1500); Loss: 0.120519; Backpropagation: 0.0932 sec; Batch: 0.4656 sec
0.1724 0.1371 0.1260 0.1215 0.1187 0.1162 0.1153 0.1143 0.1137 0.1134 0.1134 0.1132 0.1132 0.1133 0.1133 0.1133 

[TRAIN] Epoch[3](1222/1500); Loss: 0.121338; Backpropagation: 0.0938 sec; Batch: 0.4669 sec
0.1580 0.1509 0.1318 0.1243 0.1220 0.1176 0.1153 0.1143 0.1137 0.1134 0.1132 0.1131 0.1132 0.1133 0.1136 0.1138 

[TRAIN] Epoch[3](1223/1500); Loss: 0.085533; Backpropagation: 0.0932 sec; Batch: 0.4699 sec
0.3144 0.1599 0.0917 0.0655 0.0781 0.0763 0.0641 0.0613 0.0585 0.0570 0.0570 0.0569 0.0570 0.0567 0.0571 0.0569 

[TRAIN] Epoch[3](1224/1500); Loss: 0.155959; Backpropagation: 0.0937 sec; Batch: 0.4707 sec
0.2300 0.1656 0.1659 0.1563 0.1508 0.1516 0.1500 0.1483 0.1475 0.1471 0.1467 0.1467 0.1468 0.1471 0.1474 0.1474 

[TRAIN] Epoch[3](1225/1500); Loss: 0.092262; Backpropagation: 0.0939 sec; Batch: 0.4675 sec
0.1285 0.1085 0.0965 0.0887 0.0887 0.0869 0.0864 0.0864 0.0865 0.0868 0.0873 0.0878 0.0885 0.0889 0.0895 0.0901 

[TRAIN] Epoch[3](1226/1500); Loss: 0.068229; Backpropagation: 0.0937 sec; Batch: 0.4658 sec
0.1095 0.0887 0.0784 0.0706 0.0664 0.0644 0.0631 0.0615 0.0610 0.0610 0.0609 0.0610 0.0610 0.0613 0.0612 0.0617 

[TRAIN] Epoch[3](1227/1500); Loss: 0.075729; Backpropagation: 0.0937 sec; Batch: 0.4709 sec
0.0965 0.1108 0.0908 0.0763 0.0749 0.0731 0.0717 0.0707 0.0700 0.0693 0.0689 0.0684 0.0680 0.0677 0.0674 0.0672 

[TRAIN] Epoch[3](1228/1500); Loss: 0.065909; Backpropagation: 0.0939 sec; Batch: 0.4690 sec
0.1764 0.0810 0.0579 0.0859 0.0665 0.0577 0.0544 0.0530 0.0528 0.0524 0.0524 0.0524 0.0525 0.0528 0.0530 0.0533 

[TRAIN] Epoch[3](1229/1500); Loss: 0.101981; Backpropagation: 0.0938 sec; Batch: 0.4759 sec
0.1899 0.1171 0.1050 0.1025 0.1001 0.0958 0.0947 0.0935 0.0926 0.0918 0.0918 0.0915 0.0915 0.0914 0.0913 0.0912 

[TRAIN] Epoch[3](1230/1500); Loss: 0.066863; Backpropagation: 0.0936 sec; Batch: 0.4667 sec
0.1724 0.0775 0.0740 0.0687 0.0657 0.0583 0.0563 0.0556 0.0553 0.0552 0.0551 0.0549 0.0550 0.0551 0.0553 0.0554 

[TRAIN] Epoch[3](1231/1500); Loss: 0.077945; Backpropagation: 0.0937 sec; Batch: 0.4826 sec
0.3459 0.1239 0.0648 0.0485 0.1202 0.0881 0.0718 0.0548 0.0424 0.0416 0.0398 0.0409 0.0400 0.0411 0.0409 0.0424 

[TRAIN] Epoch[3](1232/1500); Loss: 0.069034; Backpropagation: 0.0932 sec; Batch: 0.4658 sec
0.1225 0.0845 0.0914 0.0776 0.0665 0.0649 0.0629 0.0598 0.0596 0.0592 0.0590 0.0588 0.0593 0.0594 0.0594 0.0597 

[TRAIN] Epoch[3](1233/1500); Loss: 0.088749; Backpropagation: 0.0938 sec; Batch: 0.4730 sec
0.2053 0.1114 0.1230 0.1201 0.0748 0.0750 0.0721 0.0711 0.0698 0.0700 0.0699 0.0706 0.0707 0.0715 0.0719 0.0727 

[TRAIN] Epoch[3](1234/1500); Loss: 0.100950; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.1768 0.1365 0.1213 0.1069 0.0988 0.0927 0.0909 0.0893 0.0886 0.0874 0.0872 0.0868 0.0872 0.0872 0.0884 0.0892 

[TRAIN] Epoch[3](1235/1500); Loss: 0.102331; Backpropagation: 0.0939 sec; Batch: 0.4518 sec
0.2550 0.1402 0.0966 0.0886 0.1181 0.1015 0.0974 0.0894 0.0835 0.0816 0.0809 0.0808 0.0808 0.0808 0.0809 0.0811 

[TRAIN] Epoch[3](1236/1500); Loss: 0.127191; Backpropagation: 0.0937 sec; Batch: 0.4649 sec
0.2003 0.1361 0.1369 0.1300 0.1282 0.1222 0.1200 0.1188 0.1183 0.1179 0.1178 0.1177 0.1177 0.1178 0.1176 0.1176 

[TRAIN] Epoch[3](1237/1500); Loss: 0.088801; Backpropagation: 0.0939 sec; Batch: 0.4340 sec
0.1259 0.1134 0.0982 0.1024 0.0901 0.0849 0.0828 0.0817 0.0809 0.0802 0.0801 0.0800 0.0801 0.0799 0.0799 0.0802 

[TRAIN] Epoch[3](1238/1500); Loss: 0.131145; Backpropagation: 0.0933 sec; Batch: 0.4360 sec
0.2524 0.1586 0.1297 0.1251 0.1383 0.1308 0.1264 0.1212 0.1176 0.1154 0.1143 0.1140 0.1138 0.1136 0.1135 0.1136 

[TRAIN] Epoch[3](1239/1500); Loss: 0.078684; Backpropagation: 0.0937 sec; Batch: 0.4669 sec
0.1598 0.0959 0.0845 0.0769 0.0814 0.0759 0.0730 0.0699 0.0686 0.0679 0.0678 0.0676 0.0675 0.0675 0.0673 0.0674 

[TRAIN] Epoch[3](1240/1500); Loss: 0.103997; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1855 0.1190 0.1038 0.1067 0.1011 0.0978 0.0958 0.0950 0.0948 0.0948 0.0948 0.0946 0.0946 0.0950 0.0951 0.0952 

[TRAIN] Epoch[3](1241/1500); Loss: 0.073388; Backpropagation: 0.0946 sec; Batch: 0.4298 sec
0.2223 0.1026 0.0708 0.0775 0.0748 0.0682 0.0628 0.0581 0.0560 0.0548 0.0546 0.0545 0.0544 0.0542 0.0543 0.0544 

[TRAIN] Epoch[3](1242/1500); Loss: 0.077512; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1330 0.0801 0.1003 0.0890 0.0745 0.0716 0.0706 0.0691 0.0690 0.0688 0.0692 0.0689 0.0690 0.0687 0.0693 0.0693 

[TRAIN] Epoch[3](1243/1500); Loss: 0.104964; Backpropagation: 0.0933 sec; Batch: 0.4294 sec
0.1772 0.1282 0.1084 0.1043 0.1049 0.1011 0.0987 0.0971 0.0961 0.0956 0.0951 0.0949 0.0946 0.0945 0.0944 0.0943 

[TRAIN] Epoch[3](1244/1500); Loss: 0.112030; Backpropagation: 0.0931 sec; Batch: 0.4323 sec
0.1870 0.1473 0.1159 0.1172 0.1108 0.1068 0.1038 0.1024 0.1014 0.1010 0.1004 0.1000 0.0998 0.0996 0.0996 0.0995 

[TRAIN] Epoch[3](1245/1500); Loss: 0.075263; Backpropagation: 0.0939 sec; Batch: 0.4687 sec
0.3159 0.1507 0.0634 0.0791 0.0597 0.0740 0.0647 0.0572 0.0489 0.0447 0.0421 0.0412 0.0406 0.0405 0.0405 0.0409 

[TRAIN] Epoch[3](1246/1500); Loss: 0.081085; Backpropagation: 0.0936 sec; Batch: 0.4694 sec
0.1256 0.1212 0.0964 0.0815 0.0780 0.0742 0.0734 0.0724 0.0719 0.0717 0.0717 0.0716 0.0718 0.0718 0.0720 0.0721 

[TRAIN] Epoch[3](1247/1500); Loss: 0.083934; Backpropagation: 0.0937 sec; Batch: 0.4661 sec
0.3762 0.1537 0.0405 0.0321 0.1086 0.0999 0.0929 0.0781 0.0630 0.0512 0.0445 0.0414 0.0403 0.0401 0.0403 0.0403 

[TRAIN] Epoch[3](1248/1500); Loss: 0.059683; Backpropagation: 0.0936 sec; Batch: 0.4865 sec
0.0920 0.0822 0.0727 0.0674 0.0678 0.0622 0.0569 0.0527 0.0515 0.0505 0.0504 0.0498 0.0501 0.0496 0.0496 0.0495 

[TRAIN] Epoch[3](1249/1500); Loss: 0.068599; Backpropagation: 0.0937 sec; Batch: 0.4669 sec
0.1371 0.0901 0.0767 0.0702 0.0663 0.0640 0.0618 0.0603 0.0595 0.0590 0.0589 0.0588 0.0586 0.0586 0.0587 0.0588 

[TRAIN] Epoch[3](1250/1500); Loss: 0.077065; Backpropagation: 0.0936 sec; Batch: 0.4663 sec
0.0966 0.1020 0.0843 0.0834 0.0764 0.0737 0.0726 0.0720 0.0719 0.0716 0.0715 0.0714 0.0713 0.0713 0.0714 0.0715 

[TRAIN] Epoch[3](1251/1500); Loss: 0.072908; Backpropagation: 0.0981 sec; Batch: 0.4717 sec
0.1531 0.1331 0.0944 0.0867 0.0758 0.0667 0.0624 0.0590 0.0574 0.0557 0.0546 0.0539 0.0539 0.0534 0.0532 0.0531 

[TRAIN] Epoch[3](1252/1500); Loss: 0.074090; Backpropagation: 0.0956 sec; Batch: 0.4603 sec
0.1957 0.0932 0.0808 0.0700 0.0798 0.0703 0.0664 0.0624 0.0602 0.0592 0.0584 0.0580 0.0578 0.0577 0.0577 0.0579 

[TRAIN] Epoch[3](1253/1500); Loss: 0.104282; Backpropagation: 0.0938 sec; Batch: 0.4685 sec
0.1662 0.1391 0.1093 0.1054 0.1001 0.0977 0.0965 0.0957 0.0952 0.0949 0.0950 0.0949 0.0947 0.0947 0.0947 0.0944 

[TRAIN] Epoch[3](1254/1500); Loss: 0.136025; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1775 0.1606 0.1439 0.1380 0.1348 0.1318 0.1305 0.1297 0.1291 0.1288 0.1287 0.1285 0.1284 0.1285 0.1286 0.1288 

[TRAIN] Epoch[3](1255/1500); Loss: 0.125274; Backpropagation: 0.0922 sec; Batch: 0.4635 sec
0.1657 0.1318 0.1248 0.1243 0.1225 0.1214 0.1209 0.1210 0.1216 0.1222 0.1220 0.1218 0.1212 0.1211 0.1210 0.1210 

[TRAIN] Epoch[3](1256/1500); Loss: 0.132341; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.1900 0.1605 0.1380 0.1435 0.1334 0.1294 0.1262 0.1240 0.1229 0.1223 0.1218 0.1214 0.1212 0.1210 0.1210 0.1208 

[TRAIN] Epoch[3](1257/1500); Loss: 0.126994; Backpropagation: 0.0938 sec; Batch: 0.4696 sec
0.1719 0.1460 0.1286 0.1259 0.1243 0.1235 0.1226 0.1219 0.1216 0.1212 0.1209 0.1206 0.1206 0.1206 0.1208 0.1208 

[TRAIN] Epoch[3](1258/1500); Loss: 0.078383; Backpropagation: 0.0942 sec; Batch: 0.4597 sec
0.3131 0.1148 0.0712 0.0550 0.1049 0.0824 0.0737 0.0608 0.0524 0.0478 0.0467 0.0460 0.0464 0.0460 0.0464 0.0465 

[TRAIN] Epoch[3](1259/1500); Loss: 0.093658; Backpropagation: 0.0939 sec; Batch: 0.4695 sec
0.1429 0.1235 0.1067 0.0986 0.0923 0.0887 0.0874 0.0866 0.0859 0.0852 0.0846 0.0840 0.0835 0.0831 0.0829 0.0826 

[TRAIN] Epoch[3](1260/1500); Loss: 0.069799; Backpropagation: 0.0936 sec; Batch: 0.4659 sec
0.0984 0.0928 0.0754 0.0791 0.0710 0.0677 0.0653 0.0641 0.0634 0.0632 0.0630 0.0627 0.0627 0.0626 0.0627 0.0628 

[TRAIN] Epoch[3](1261/1500); Loss: 0.093924; Backpropagation: 0.0938 sec; Batch: 0.4710 sec
0.3757 0.1542 0.0629 0.0500 0.1296 0.1086 0.0990 0.0810 0.0648 0.0556 0.0535 0.0529 0.0531 0.0533 0.0541 0.0545 

[TRAIN] Epoch[3](1262/1500); Loss: 0.120669; Backpropagation: 0.0931 sec; Batch: 0.4696 sec
0.1953 0.1606 0.1346 0.1202 0.1143 0.1122 0.1108 0.1101 0.1097 0.1095 0.1093 0.1091 0.1089 0.1088 0.1086 0.1087 

[TRAIN] Epoch[3](1263/1500); Loss: 0.149675; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.2275 0.1942 0.1585 0.1470 0.1433 0.1463 0.1423 0.1394 0.1380 0.1377 0.1377 0.1372 0.1367 0.1364 0.1364 0.1364 

[TRAIN] Epoch[3](1264/1500); Loss: 0.097754; Backpropagation: 0.0936 sec; Batch: 0.4667 sec
0.2113 0.1404 0.1055 0.0948 0.0921 0.0877 0.0861 0.0850 0.0840 0.0835 0.0829 0.0825 0.0821 0.0821 0.0820 0.0821 

[TRAIN] Epoch[3](1265/1500); Loss: 0.058066; Backpropagation: 0.0939 sec; Batch: 0.4671 sec
0.0964 0.1112 0.0722 0.0566 0.0524 0.0510 0.0495 0.0489 0.0487 0.0487 0.0487 0.0487 0.0487 0.0489 0.0493 0.0492 

[TRAIN] Epoch[3](1266/1500); Loss: 0.103877; Backpropagation: 0.0937 sec; Batch: 0.4593 sec
0.1933 0.1280 0.1062 0.1006 0.0990 0.0959 0.0948 0.0942 0.0942 0.0941 0.0940 0.0937 0.0936 0.0934 0.0935 0.0935 

[TRAIN] Epoch[3](1267/1500); Loss: 0.102835; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.1817 0.1185 0.1048 0.1022 0.1009 0.0975 0.0961 0.0951 0.0944 0.0941 0.0940 0.0938 0.0933 0.0932 0.0930 0.0929 

[TRAIN] Epoch[3](1268/1500); Loss: 0.104082; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.1704 0.1308 0.1131 0.1045 0.1006 0.0980 0.0970 0.0961 0.0953 0.0947 0.0944 0.0942 0.0941 0.0940 0.0941 0.0940 

[TRAIN] Epoch[3](1269/1500); Loss: 0.079148; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.1553 0.0996 0.0857 0.0751 0.0824 0.0750 0.0723 0.0699 0.0691 0.0689 0.0687 0.0687 0.0689 0.0689 0.0690 0.0689 

[TRAIN] Epoch[3](1270/1500); Loss: 0.119704; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1579 0.1342 0.1267 0.1196 0.1208 0.1174 0.1157 0.1145 0.1139 0.1135 0.1134 0.1133 0.1133 0.1134 0.1137 0.1139 

[TRAIN] Epoch[3](1271/1500); Loss: 0.045827; Backpropagation: 0.0938 sec; Batch: 0.4803 sec
0.0504 0.0673 0.0855 0.0597 0.0444 0.0423 0.0415 0.0392 0.0385 0.0372 0.0377 0.0373 0.0376 0.0374 0.0386 0.0386 

[TRAIN] Epoch[3](1272/1500); Loss: 0.111976; Backpropagation: 0.0937 sec; Batch: 0.4585 sec
0.1557 0.1309 0.1208 0.1100 0.1049 0.1017 0.1016 0.1013 0.1020 0.1035 0.1051 0.1067 0.1086 0.1106 0.1128 0.1154 

[TRAIN] Epoch[3](1273/1500); Loss: 0.052384; Backpropagation: 0.0957 sec; Batch: 0.4725 sec
0.1225 0.1255 0.0559 0.0486 0.0418 0.0419 0.0396 0.0391 0.0389 0.0393 0.0395 0.0401 0.0405 0.0411 0.0416 0.0423 

[TRAIN] Epoch[3](1274/1500); Loss: 0.120886; Backpropagation: 0.0936 sec; Batch: 0.4735 sec
0.1794 0.1440 0.1281 0.1234 0.1199 0.1167 0.1143 0.1133 0.1127 0.1123 0.1122 0.1120 0.1118 0.1115 0.1113 0.1111 

[TRAIN] Epoch[3](1275/1500); Loss: 0.062343; Backpropagation: 0.0938 sec; Batch: 0.4683 sec
0.1900 0.0831 0.0653 0.0617 0.0589 0.0537 0.0513 0.0495 0.0488 0.0483 0.0480 0.0477 0.0475 0.0476 0.0478 0.0483 

[TRAIN] Epoch[3](1276/1500); Loss: 0.122829; Backpropagation: 0.0937 sec; Batch: 0.5036 sec
0.2391 0.1604 0.1304 0.1174 0.1183 0.1147 0.1126 0.1108 0.1095 0.1086 0.1081 0.1078 0.1073 0.1071 0.1067 0.1064 

[TRAIN] Epoch[3](1277/1500); Loss: 0.108422; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.1878 0.1566 0.1185 0.1107 0.1048 0.1003 0.0977 0.0962 0.0959 0.0954 0.0953 0.0952 0.0952 0.0951 0.0951 0.0949 

[TRAIN] Epoch[3](1278/1500); Loss: 0.086306; Backpropagation: 0.0938 sec; Batch: 0.4678 sec
0.3733 0.1512 0.0619 0.0515 0.1188 0.0937 0.0817 0.0633 0.0501 0.0481 0.0470 0.0470 0.0471 0.0483 0.0484 0.0494 

[TRAIN] Epoch[3](1279/1500); Loss: 0.118982; Backpropagation: 0.0939 sec; Batch: 0.4384 sec
0.2210 0.1435 0.1158 0.1105 0.1149 0.1110 0.1096 0.1089 0.1087 0.1088 0.1087 0.1085 0.1085 0.1082 0.1084 0.1086 

[TRAIN] Epoch[3](1280/1500); Loss: 0.089118; Backpropagation: 0.0937 sec; Batch: 0.4695 sec
0.3453 0.2019 0.1092 0.0600 0.0605 0.0777 0.0659 0.0638 0.0590 0.0562 0.0556 0.0554 0.0546 0.0540 0.0533 0.0534 

[TRAIN] Epoch[3](1281/1500); Loss: 0.106289; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.1756 0.1362 0.1189 0.1066 0.1044 0.1003 0.0989 0.0971 0.0967 0.0961 0.0960 0.0952 0.0949 0.0946 0.0946 0.0946 

[TRAIN] Epoch[3](1282/1500); Loss: 0.055130; Backpropagation: 0.0931 sec; Batch: 0.4298 sec
0.1386 0.0694 0.0533 0.0740 0.0568 0.0518 0.0466 0.0451 0.0442 0.0437 0.0436 0.0432 0.0431 0.0428 0.0429 0.0429 

[TRAIN] Epoch[3](1283/1500); Loss: 0.090472; Backpropagation: 0.0932 sec; Batch: 0.4302 sec
0.1128 0.0986 0.0915 0.0906 0.0892 0.0884 0.0878 0.0875 0.0875 0.0873 0.0874 0.0874 0.0875 0.0878 0.0880 0.0882 

[TRAIN] Epoch[3](1284/1500); Loss: 0.107394; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1377 0.1294 0.1118 0.1073 0.1049 0.1039 0.1029 0.1023 0.1019 0.1019 0.1021 0.1020 0.1021 0.1022 0.1028 0.1031 

[TRAIN] Epoch[3](1285/1500); Loss: 0.103929; Backpropagation: 0.0939 sec; Batch: 0.4660 sec
0.1660 0.1387 0.1166 0.1057 0.1016 0.0980 0.0959 0.0949 0.0941 0.0937 0.0933 0.0933 0.0930 0.0927 0.0926 0.0927 

[TRAIN] Epoch[3](1286/1500); Loss: 0.100225; Backpropagation: 0.0931 sec; Batch: 0.4532 sec
0.2639 0.1293 0.0946 0.0863 0.1033 0.0894 0.0864 0.0843 0.0833 0.0832 0.0829 0.0831 0.0831 0.0833 0.0835 0.0839 

[TRAIN] Epoch[3](1287/1500); Loss: 0.107318; Backpropagation: 0.0939 sec; Batch: 0.4713 sec
0.1413 0.1155 0.1083 0.1129 0.1076 0.1052 0.1030 0.1020 0.1015 0.1015 0.1017 0.1021 0.1023 0.1035 0.1041 0.1046 

[TRAIN] Epoch[3](1288/1500); Loss: 0.113792; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.1851 0.1352 0.1132 0.1115 0.1101 0.1088 0.1078 0.1069 0.1062 0.1055 0.1052 0.1051 0.1052 0.1050 0.1050 0.1048 

[TRAIN] Epoch[3](1289/1500); Loss: 0.180069; Backpropagation: 0.0937 sec; Batch: 0.4663 sec
0.2204 0.1821 0.1808 0.1825 0.1833 0.1809 0.1784 0.1766 0.1758 0.1754 0.1749 0.1743 0.1741 0.1740 0.1739 0.1738 

[TRAIN] Epoch[3](1290/1500); Loss: 0.134352; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1943 0.1603 0.1407 0.1387 0.1333 0.1298 0.1279 0.1265 0.1260 0.1255 0.1251 0.1246 0.1244 0.1243 0.1242 0.1240 

[TRAIN] Epoch[3](1291/1500); Loss: 0.064735; Backpropagation: 0.0944 sec; Batch: 0.4901 sec
0.1793 0.0853 0.0583 0.0787 0.0663 0.0596 0.0541 0.0516 0.0508 0.0507 0.0503 0.0502 0.0501 0.0503 0.0501 0.0503 

[TRAIN] Epoch[3](1292/1500); Loss: 0.110700; Backpropagation: 0.0937 sec; Batch: 0.4686 sec
0.2088 0.1479 0.1133 0.1047 0.1103 0.1019 0.1010 0.0987 0.0982 0.0978 0.0977 0.0975 0.0979 0.0980 0.0987 0.0986 

[TRAIN] Epoch[3](1293/1500); Loss: 0.138455; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.1904 0.1604 0.1559 0.1422 0.1380 0.1330 0.1314 0.1302 0.1296 0.1293 0.1295 0.1292 0.1292 0.1290 0.1293 0.1288 

[TRAIN] Epoch[3](1294/1500); Loss: 0.114733; Backpropagation: 0.0936 sec; Batch: 0.4663 sec
0.1819 0.1378 0.1226 0.1176 0.1128 0.1101 0.1085 0.1073 0.1064 0.1056 0.1050 0.1046 0.1043 0.1041 0.1036 0.1034 

[TRAIN] Epoch[3](1295/1500); Loss: 0.091082; Backpropagation: 0.0947 sec; Batch: 0.4689 sec
0.2152 0.1109 0.0959 0.0848 0.0878 0.0818 0.0795 0.0780 0.0775 0.0776 0.0774 0.0778 0.0778 0.0781 0.0783 0.0788 

[TRAIN] Epoch[3](1296/1500); Loss: 0.144733; Backpropagation: 0.0956 sec; Batch: 0.4830 sec
0.2234 0.1783 0.1465 0.1411 0.1367 0.1361 0.1354 0.1352 0.1351 0.1352 0.1352 0.1353 0.1354 0.1353 0.1355 0.1357 

[TRAIN] Epoch[3](1297/1500); Loss: 0.087511; Backpropagation: 0.0955 sec; Batch: 0.4705 sec
0.1309 0.1034 0.0937 0.0991 0.0884 0.0850 0.0826 0.0813 0.0808 0.0803 0.0798 0.0795 0.0792 0.0790 0.0787 0.0786 

[TRAIN] Epoch[3](1298/1500); Loss: 0.106674; Backpropagation: 0.0939 sec; Batch: 0.4699 sec
0.1632 0.1281 0.1151 0.1055 0.1045 0.1007 0.0998 0.0989 0.0989 0.0988 0.0986 0.0987 0.0988 0.0990 0.0990 0.0993 

[TRAIN] Epoch[3](1299/1500); Loss: 0.091424; Backpropagation: 0.0938 sec; Batch: 0.4697 sec
0.1122 0.0967 0.0928 0.0897 0.0896 0.0895 0.0893 0.0891 0.0891 0.0891 0.0891 0.0891 0.0891 0.0891 0.0895 0.0898 

[TRAIN] Epoch[3](1300/1500); Loss: 0.150742; Backpropagation: 0.0937 sec; Batch: 0.4793 sec
0.2082 0.1719 0.1597 0.1513 0.1479 0.1466 0.1450 0.1442 0.1435 0.1432 0.1427 0.1423 0.1417 0.1414 0.1412 0.1411 

[TRAIN] Epoch[3](1301/1500); Loss: 0.106406; Backpropagation: 0.0938 sec; Batch: 0.5267 sec
0.1311 0.1283 0.1189 0.1034 0.1011 0.1007 0.1000 0.1004 0.1005 0.1007 0.1012 0.1018 0.1024 0.1032 0.1040 0.1050 

[TRAIN] Epoch[3](1302/1500); Loss: 0.103271; Backpropagation: 0.0938 sec; Batch: 0.4653 sec
0.1393 0.1254 0.1069 0.1092 0.1016 0.1009 0.0975 0.0972 0.0970 0.0968 0.0968 0.0968 0.0967 0.0968 0.0967 0.0968 

[TRAIN] Epoch[3](1303/1500); Loss: 0.132573; Backpropagation: 0.0937 sec; Batch: 0.4703 sec
0.1479 0.1383 0.1311 0.1308 0.1299 0.1297 0.1296 0.1299 0.1301 0.1303 0.1309 0.1316 0.1321 0.1325 0.1330 0.1336 

[TRAIN] Epoch[3](1304/1500); Loss: 0.115439; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2953 0.1536 0.1038 0.1014 0.1197 0.1036 0.1038 0.0987 0.0971 0.0960 0.0956 0.0954 0.0957 0.0956 0.0958 0.0958 

[TRAIN] Epoch[3](1305/1500); Loss: 0.141707; Backpropagation: 0.0922 sec; Batch: 0.4682 sec
0.2235 0.1626 0.1386 0.1472 0.1406 0.1363 0.1342 0.1331 0.1327 0.1324 0.1320 0.1315 0.1313 0.1308 0.1305 0.1301 

[TRAIN] Epoch[3](1306/1500); Loss: 0.062651; Backpropagation: 0.0943 sec; Batch: 0.4688 sec
0.1225 0.1082 0.0730 0.0666 0.0591 0.0564 0.0541 0.0531 0.0522 0.0519 0.0513 0.0515 0.0510 0.0507 0.0504 0.0506 

[TRAIN] Epoch[3](1307/1500); Loss: 0.110422; Backpropagation: 0.0981 sec; Batch: 0.4754 sec
0.1541 0.1287 0.1202 0.1093 0.1079 0.1053 0.1042 0.1038 0.1038 0.1037 0.1039 0.1040 0.1041 0.1042 0.1046 0.1049 

[TRAIN] Epoch[3](1308/1500); Loss: 0.133245; Backpropagation: 0.0981 sec; Batch: 0.4745 sec
0.1781 0.1514 0.1376 0.1348 0.1303 0.1287 0.1283 0.1277 0.1275 0.1274 0.1273 0.1268 0.1266 0.1266 0.1265 0.1265 

[TRAIN] Epoch[3](1309/1500); Loss: 0.062423; Backpropagation: 0.0939 sec; Batch: 0.4689 sec
0.1624 0.0623 0.0589 0.0823 0.0617 0.0601 0.0541 0.0518 0.0516 0.0511 0.0507 0.0505 0.0504 0.0503 0.0502 0.0504 

[TRAIN] Epoch[3](1310/1500); Loss: 0.090689; Backpropagation: 0.0936 sec; Batch: 0.4703 sec
0.2499 0.1348 0.0906 0.0811 0.0893 0.0828 0.0779 0.0744 0.0727 0.0718 0.0713 0.0709 0.0709 0.0708 0.0709 0.0709 

[TRAIN] Epoch[3](1311/1500); Loss: 0.092281; Backpropagation: 0.0940 sec; Batch: 0.4319 sec
0.1288 0.1121 0.1039 0.0949 0.0930 0.0899 0.0880 0.0870 0.0859 0.0853 0.0848 0.0847 0.0846 0.0845 0.0846 0.0847 

[TRAIN] Epoch[3](1312/1500); Loss: 0.046239; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.0659 0.0723 0.0487 0.0460 0.0440 0.0429 0.0424 0.0419 0.0418 0.0417 0.0418 0.0419 0.0419 0.0419 0.0423 0.0423 

[TRAIN] Epoch[3](1313/1500); Loss: 0.092435; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1327 0.1063 0.1000 0.0937 0.0915 0.0896 0.0887 0.0879 0.0872 0.0868 0.0865 0.0859 0.0858 0.0854 0.0856 0.0854 

[TRAIN] Epoch[3](1314/1500); Loss: 0.045247; Backpropagation: 0.0938 sec; Batch: 0.4305 sec
0.0640 0.0671 0.0576 0.0469 0.0417 0.0420 0.0404 0.0401 0.0399 0.0399 0.0402 0.0407 0.0406 0.0409 0.0408 0.0410 

[TRAIN] Epoch[3](1315/1500); Loss: 0.072593; Backpropagation: 0.0932 sec; Batch: 0.4386 sec
0.2554 0.1206 0.0636 0.0702 0.0629 0.0587 0.0552 0.0538 0.0526 0.0526 0.0524 0.0526 0.0527 0.0529 0.0526 0.0527 

[TRAIN] Epoch[3](1316/1500); Loss: 0.059166; Backpropagation: 0.0931 sec; Batch: 0.4661 sec
0.1031 0.0803 0.0699 0.0632 0.0599 0.0554 0.0539 0.0525 0.0516 0.0513 0.0509 0.0508 0.0507 0.0510 0.0511 0.0510 

[TRAIN] Epoch[3](1317/1500); Loss: 0.067590; Backpropagation: 0.0932 sec; Batch: 0.4672 sec
0.1260 0.1023 0.0682 0.0834 0.0670 0.0649 0.0584 0.0571 0.0565 0.0564 0.0566 0.0566 0.0566 0.0568 0.0573 0.0574 

[TRAIN] Epoch[3](1318/1500); Loss: 0.087219; Backpropagation: 0.0938 sec; Batch: 0.4712 sec
0.1504 0.1126 0.0978 0.0887 0.0832 0.0799 0.0789 0.0783 0.0781 0.0778 0.0778 0.0778 0.0779 0.0783 0.0788 0.0792 

[TRAIN] Epoch[3](1319/1500); Loss: 0.049314; Backpropagation: 0.0939 sec; Batch: 0.4292 sec
0.1222 0.0899 0.0564 0.0476 0.0444 0.0413 0.0398 0.0391 0.0385 0.0386 0.0385 0.0381 0.0384 0.0387 0.0387 0.0386 

[TRAIN] Epoch[3](1320/1500); Loss: 0.056421; Backpropagation: 0.0937 sec; Batch: 0.4721 sec
0.1618 0.0915 0.0585 0.0503 0.0565 0.0489 0.0463 0.0443 0.0436 0.0433 0.0431 0.0430 0.0430 0.0427 0.0430 0.0430 

[TRAIN] Epoch[3](1321/1500); Loss: 0.070139; Backpropagation: 0.0955 sec; Batch: 0.4299 sec
0.2066 0.0737 0.0746 0.0725 0.0677 0.0612 0.0587 0.0574 0.0571 0.0562 0.0564 0.0560 0.0559 0.0559 0.0562 0.0562 

[TRAIN] Epoch[3](1322/1500); Loss: 0.079126; Backpropagation: 0.0937 sec; Batch: 0.4347 sec
0.1980 0.1256 0.0858 0.0860 0.0791 0.0712 0.0662 0.0631 0.0622 0.0617 0.0614 0.0612 0.0613 0.0610 0.0612 0.0611 

[TRAIN] Epoch[3](1323/1500); Loss: 0.088337; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1229 0.1145 0.0937 0.0890 0.0854 0.0838 0.0829 0.0825 0.0822 0.0823 0.0823 0.0825 0.0819 0.0823 0.0826 0.0826 

[TRAIN] Epoch[3](1324/1500); Loss: 0.123442; Backpropagation: 0.0932 sec; Batch: 0.4690 sec
0.2245 0.1536 0.1258 0.1197 0.1187 0.1148 0.1140 0.1128 0.1121 0.1117 0.1114 0.1112 0.1112 0.1111 0.1112 0.1112 

[TRAIN] Epoch[3](1325/1500); Loss: 0.072041; Backpropagation: 0.0932 sec; Batch: 0.4586 sec
0.1242 0.1143 0.0803 0.0704 0.0675 0.0651 0.0640 0.0633 0.0629 0.0629 0.0627 0.0627 0.0629 0.0628 0.0631 0.0636 

[TRAIN] Epoch[3](1326/1500); Loss: 0.095451; Backpropagation: 0.0937 sec; Batch: 0.4676 sec
0.3239 0.2028 0.1204 0.0679 0.0715 0.0840 0.0722 0.0724 0.0682 0.0659 0.0644 0.0637 0.0631 0.0625 0.0622 0.0619 

[TRAIN] Epoch[3](1327/1500); Loss: 0.136864; Backpropagation: 0.0939 sec; Batch: 0.4664 sec
0.2695 0.1651 0.1336 0.1296 0.1344 0.1267 0.1253 0.1236 0.1231 0.1230 0.1226 0.1226 0.1226 0.1225 0.1226 0.1229 

[TRAIN] Epoch[3](1328/1500); Loss: 0.094330; Backpropagation: 0.0937 sec; Batch: 0.4675 sec
0.1825 0.1295 0.1018 0.0925 0.0876 0.0856 0.0843 0.0836 0.0834 0.0830 0.0829 0.0826 0.0827 0.0822 0.0825 0.0827 

[TRAIN] Epoch[3](1329/1500); Loss: 0.102179; Backpropagation: 0.0937 sec; Batch: 0.4699 sec
0.1859 0.1368 0.1177 0.1033 0.0993 0.0947 0.0922 0.0907 0.0903 0.0897 0.0895 0.0889 0.0890 0.0891 0.0890 0.0890 

[TRAIN] Epoch[3](1330/1500); Loss: 0.111793; Backpropagation: 0.0937 sec; Batch: 0.4659 sec
0.2039 0.1542 0.1237 0.1127 0.1102 0.1039 0.1004 0.0986 0.0980 0.0980 0.0975 0.0974 0.0971 0.0975 0.0976 0.0979 

[TRAIN] Epoch[3](1331/1500); Loss: 0.136043; Backpropagation: 0.0939 sec; Batch: 0.4678 sec
0.1992 0.1549 0.1419 0.1336 0.1334 0.1297 0.1288 0.1281 0.1280 0.1280 0.1281 0.1281 0.1283 0.1285 0.1288 0.1291 

[TRAIN] Epoch[3](1332/1500); Loss: 0.106777; Backpropagation: 0.0938 sec; Batch: 0.4654 sec
0.1713 0.1537 0.1290 0.1105 0.1082 0.1007 0.0984 0.0963 0.0953 0.0941 0.0936 0.0922 0.0919 0.0911 0.0913 0.0907 

[TRAIN] Epoch[3](1333/1500); Loss: 0.081102; Backpropagation: 0.0938 sec; Batch: 0.4670 sec
0.1882 0.1174 0.0824 0.0822 0.0738 0.0731 0.0705 0.0690 0.0681 0.0676 0.0678 0.0677 0.0676 0.0676 0.0675 0.0671 

[TRAIN] Epoch[3](1334/1500); Loss: 0.090593; Backpropagation: 0.0937 sec; Batch: 0.4869 sec
0.1599 0.1159 0.0943 0.0870 0.0862 0.0850 0.0835 0.0828 0.0823 0.0822 0.0820 0.0819 0.0817 0.0815 0.0816 0.0818 

[TRAIN] Epoch[3](1335/1500); Loss: 0.120359; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.2344 0.1646 0.1301 0.1130 0.1111 0.1088 0.1073 0.1070 0.1064 0.1062 0.1060 0.1059 0.1060 0.1060 0.1063 0.1065 

[TRAIN] Epoch[3](1336/1500); Loss: 0.109182; Backpropagation: 0.0936 sec; Batch: 0.4659 sec
0.1611 0.1347 0.1164 0.1089 0.1048 0.1031 0.1022 0.1019 0.1016 0.1015 0.1012 0.1013 0.1015 0.1020 0.1022 0.1026 

[TRAIN] Epoch[3](1337/1500); Loss: 0.139617; Backpropagation: 0.0937 sec; Batch: 0.4740 sec
0.2704 0.1670 0.1361 0.1297 0.1356 0.1287 0.1305 0.1281 0.1272 0.1264 0.1261 0.1258 0.1256 0.1255 0.1255 0.1256 

[TRAIN] Epoch[3](1338/1500); Loss: 0.076136; Backpropagation: 0.0938 sec; Batch: 0.4684 sec
0.2419 0.1292 0.0815 0.0755 0.0742 0.0646 0.0608 0.0576 0.0556 0.0544 0.0541 0.0537 0.0539 0.0536 0.0538 0.0537 

[TRAIN] Epoch[3](1339/1500); Loss: 0.129856; Backpropagation: 0.0938 sec; Batch: 0.4381 sec
0.2020 0.1627 0.1424 0.1358 0.1278 0.1236 0.1210 0.1194 0.1187 0.1178 0.1176 0.1175 0.1176 0.1177 0.1180 0.1183 

[TRAIN] Epoch[3](1340/1500); Loss: 0.113537; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1512 0.1362 0.1252 0.1160 0.1132 0.1098 0.1087 0.1077 0.1071 0.1066 0.1062 0.1060 0.1059 0.1057 0.1056 0.1055 

[TRAIN] Epoch[3](1341/1500); Loss: 0.103123; Backpropagation: 0.0939 sec; Batch: 0.4697 sec
0.1497 0.1481 0.1196 0.1054 0.0991 0.1017 0.0948 0.0932 0.0927 0.0925 0.0920 0.0921 0.0921 0.0923 0.0922 0.0926 

[TRAIN] Epoch[3](1342/1500); Loss: 0.051090; Backpropagation: 0.0936 sec; Batch: 0.4701 sec
0.0893 0.0723 0.0662 0.0534 0.0500 0.0464 0.0455 0.0442 0.0438 0.0435 0.0435 0.0435 0.0437 0.0437 0.0441 0.0445 

[TRAIN] Epoch[3](1343/1500); Loss: 0.082417; Backpropagation: 0.0938 sec; Batch: 0.4706 sec
0.2656 0.1379 0.0834 0.0739 0.0925 0.0728 0.0684 0.0622 0.0592 0.0580 0.0575 0.0576 0.0572 0.0574 0.0575 0.0577 

[TRAIN] Epoch[3](1344/1500); Loss: 0.078099; Backpropagation: 0.0933 sec; Batch: 0.4579 sec
0.0860 0.1159 0.0936 0.0794 0.0763 0.0730 0.0739 0.0728 0.0731 0.0723 0.0724 0.0717 0.0727 0.0721 0.0724 0.0719 

[TRAIN] Epoch[3](1345/1500); Loss: 0.041174; Backpropagation: 0.0938 sec; Batch: 0.4629 sec
0.0602 0.0436 0.0532 0.0507 0.0460 0.0409 0.0355 0.0362 0.0360 0.0360 0.0359 0.0360 0.0367 0.0370 0.0372 0.0378 

[TRAIN] Epoch[3](1346/1500); Loss: 0.050755; Backpropagation: 0.0980 sec; Batch: 0.4325 sec
0.1417 0.0803 0.0517 0.0556 0.0443 0.0426 0.0406 0.0401 0.0401 0.0394 0.0391 0.0392 0.0392 0.0394 0.0395 0.0393 

[TRAIN] Epoch[3](1347/1500); Loss: 0.069597; Backpropagation: 0.0944 sec; Batch: 0.4681 sec
0.1290 0.0869 0.0707 0.0777 0.0675 0.0645 0.0629 0.0618 0.0615 0.0614 0.0614 0.0615 0.0610 0.0614 0.0620 0.0625 

[TRAIN] Epoch[3](1348/1500); Loss: 0.072420; Backpropagation: 0.0945 sec; Batch: 0.4445 sec
0.1576 0.1140 0.0814 0.0661 0.0613 0.0611 0.0596 0.0595 0.0595 0.0599 0.0604 0.0613 0.0624 0.0636 0.0648 0.0662 

[TRAIN] Epoch[3](1349/1500); Loss: 0.095429; Backpropagation: 0.0943 sec; Batch: 0.4756 sec
0.1286 0.1133 0.0980 0.0939 0.0936 0.0923 0.0914 0.0910 0.0906 0.0903 0.0903 0.0904 0.0905 0.0907 0.0908 0.0911 

[TRAIN] Epoch[3](1350/1500); Loss: 0.088072; Backpropagation: 0.0938 sec; Batch: 0.4679 sec
0.1999 0.1253 0.0915 0.0828 0.0793 0.0775 0.0763 0.0758 0.0754 0.0751 0.0751 0.0751 0.0748 0.0750 0.0750 0.0752 

[TRAIN] Epoch[3](1351/1500); Loss: 0.095726; Backpropagation: 0.0954 sec; Batch: 0.4652 sec
0.1994 0.1321 0.1046 0.0915 0.0894 0.0865 0.0851 0.0844 0.0836 0.0831 0.0825 0.0823 0.0821 0.0818 0.0816 0.0817 

[TRAIN] Epoch[3](1352/1500); Loss: 0.113857; Backpropagation: 0.0957 sec; Batch: 0.5007 sec
0.1993 0.1696 0.1251 0.1120 0.1060 0.1031 0.1025 0.1012 0.1006 0.1005 0.1004 0.1003 0.1003 0.1002 0.1002 0.1003 

[TRAIN] Epoch[3](1353/1500); Loss: 0.100941; Backpropagation: 0.0958 sec; Batch: 0.4331 sec
0.1712 0.1287 0.1101 0.0999 0.0973 0.0954 0.0926 0.0918 0.0913 0.0911 0.0909 0.0911 0.0909 0.0910 0.0908 0.0909 

[TRAIN] Epoch[3](1354/1500); Loss: 0.140515; Backpropagation: 0.0939 sec; Batch: 0.4396 sec
0.1963 0.1586 0.1471 0.1396 0.1367 0.1352 0.1341 0.1337 0.1334 0.1333 0.1335 0.1331 0.1331 0.1333 0.1335 0.1336 

[TRAIN] Epoch[3](1355/1500); Loss: 0.081264; Backpropagation: 0.0939 sec; Batch: 0.4679 sec
0.1752 0.1024 0.0836 0.0765 0.0743 0.0716 0.0709 0.0712 0.0711 0.0713 0.0715 0.0716 0.0718 0.0719 0.0724 0.0727 

[TRAIN] Epoch[3](1356/1500); Loss: 0.090426; Backpropagation: 0.0938 sec; Batch: 0.4333 sec
0.1343 0.1197 0.1005 0.0897 0.0868 0.0853 0.0845 0.0841 0.0837 0.0833 0.0829 0.0827 0.0827 0.0823 0.0822 0.0820 

[TRAIN] Epoch[3](1357/1500); Loss: 0.120071; Backpropagation: 0.0938 sec; Batch: 0.4682 sec
0.1652 0.1318 0.1254 0.1168 0.1157 0.1148 0.1155 0.1158 0.1154 0.1154 0.1148 0.1148 0.1147 0.1148 0.1149 0.1152 

[TRAIN] Epoch[3](1358/1500); Loss: 0.090260; Backpropagation: 0.0939 sec; Batch: 0.4442 sec
0.1403 0.1345 0.1090 0.0955 0.0862 0.0830 0.0809 0.0800 0.0796 0.0794 0.0793 0.0791 0.0789 0.0792 0.0794 0.0798 

[TRAIN] Epoch[3](1359/1500); Loss: 0.123195; Backpropagation: 0.0938 sec; Batch: 0.4687 sec
0.1816 0.1548 0.1346 0.1227 0.1203 0.1187 0.1175 0.1162 0.1150 0.1143 0.1139 0.1133 0.1127 0.1122 0.1119 0.1115 

[TRAIN] Epoch[3](1360/1500); Loss: 0.106542; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.1467 0.1381 0.1126 0.1059 0.1036 0.1018 0.1007 0.1000 0.0996 0.0995 0.0993 0.0994 0.0993 0.0994 0.0994 0.0996 

[TRAIN] Epoch[3](1361/1500); Loss: 0.155722; Backpropagation: 0.0940 sec; Batch: 0.4662 sec
0.1973 0.1678 0.1596 0.1555 0.1541 0.1530 0.1524 0.1516 0.1511 0.1508 0.1505 0.1502 0.1499 0.1495 0.1492 0.1491 

[TRAIN] Epoch[3](1362/1500); Loss: 0.081257; Backpropagation: 0.0967 sec; Batch: 0.4743 sec
0.2559 0.1356 0.0832 0.0716 0.0759 0.0676 0.0652 0.0626 0.0615 0.0608 0.0603 0.0600 0.0600 0.0600 0.0600 0.0599 

[TRAIN] Epoch[3](1363/1500); Loss: 0.172769; Backpropagation: 0.0982 sec; Batch: 0.4336 sec
0.2559 0.1920 0.1771 0.1684 0.1683 0.1672 0.1657 0.1647 0.1643 0.1640 0.1636 0.1632 0.1627 0.1626 0.1623 0.1623 

[TRAIN] Epoch[3](1364/1500); Loss: 0.088930; Backpropagation: 0.0963 sec; Batch: 0.4438 sec
0.2327 0.1333 0.0894 0.0877 0.0774 0.0762 0.0738 0.0728 0.0722 0.0723 0.0720 0.0720 0.0721 0.0726 0.0729 0.0735 

[TRAIN] Epoch[3](1365/1500); Loss: 0.112516; Backpropagation: 0.0934 sec; Batch: 0.4617 sec
0.2126 0.1299 0.1198 0.1080 0.1042 0.1025 0.1024 0.1022 0.1023 0.1024 0.1025 0.1023 0.1021 0.1022 0.1023 0.1026 

[TRAIN] Epoch[3](1366/1500); Loss: 0.082443; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1366 0.1150 0.0886 0.0766 0.0759 0.0781 0.0759 0.0757 0.0746 0.0751 0.0746 0.0749 0.0745 0.0746 0.0740 0.0745 

[TRAIN] Epoch[3](1367/1500); Loss: 0.073719; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.2808 0.1498 0.0754 0.0592 0.0567 0.0557 0.0521 0.0506 0.0505 0.0505 0.0498 0.0497 0.0500 0.0495 0.0494 0.0498 

[TRAIN] Epoch[3](1368/1500); Loss: 0.091391; Backpropagation: 0.0939 sec; Batch: 0.4655 sec
0.1420 0.1109 0.0915 0.0902 0.0872 0.0870 0.0860 0.0858 0.0854 0.0854 0.0853 0.0853 0.0851 0.0851 0.0851 0.0851 

[TRAIN] Epoch[3](1369/1500); Loss: 0.126797; Backpropagation: 0.0939 sec; Batch: 0.4673 sec
0.1753 0.1460 0.1318 0.1239 0.1211 0.1205 0.1203 0.1203 0.1203 0.1205 0.1206 0.1209 0.1211 0.1215 0.1220 0.1226 

[TRAIN] Epoch[3](1370/1500); Loss: 0.061742; Backpropagation: 0.0938 sec; Batch: 0.4700 sec
0.1905 0.0940 0.0693 0.0581 0.0522 0.0497 0.0482 0.0471 0.0467 0.0468 0.0469 0.0468 0.0474 0.0475 0.0480 0.0486 

[TRAIN] Epoch[3](1371/1500); Loss: 0.060015; Backpropagation: 0.0958 sec; Batch: 0.4738 sec
0.1077 0.0759 0.0783 0.0660 0.0562 0.0540 0.0527 0.0523 0.0526 0.0526 0.0520 0.0519 0.0524 0.0518 0.0520 0.0520 

[TRAIN] Epoch[3](1372/1500); Loss: 0.102471; Backpropagation: 0.0937 sec; Batch: 0.4671 sec
0.2763 0.1690 0.1165 0.0887 0.0895 0.0856 0.0835 0.0827 0.0819 0.0815 0.0814 0.0807 0.0806 0.0805 0.0806 0.0805 

[TRAIN] Epoch[3](1373/1500); Loss: 0.098203; Backpropagation: 0.0939 sec; Batch: 0.4685 sec
0.1321 0.1067 0.0979 0.0958 0.0942 0.0947 0.0946 0.0950 0.0947 0.0948 0.0947 0.0952 0.0953 0.0952 0.0951 0.0951 

[TRAIN] Epoch[3](1374/1500); Loss: 0.067234; Backpropagation: 0.0959 sec; Batch: 0.4305 sec
0.1123 0.1077 0.0838 0.0673 0.0618 0.0604 0.0595 0.0591 0.0584 0.0581 0.0580 0.0582 0.0577 0.0578 0.0576 0.0580 

[TRAIN] Epoch[3](1375/1500); Loss: 0.068875; Backpropagation: 0.0957 sec; Batch: 0.4489 sec
0.1090 0.0936 0.0742 0.0664 0.0646 0.0651 0.0640 0.0637 0.0633 0.0632 0.0631 0.0629 0.0628 0.0621 0.0621 0.0619 

[TRAIN] Epoch[3](1376/1500); Loss: 0.063834; Backpropagation: 0.0938 sec; Batch: 0.4685 sec
0.1307 0.0980 0.0712 0.0615 0.0600 0.0570 0.0556 0.0549 0.0546 0.0543 0.0541 0.0541 0.0539 0.0539 0.0537 0.0538 

[TRAIN] Epoch[3](1377/1500); Loss: 0.085241; Backpropagation: 0.0937 sec; Batch: 0.4700 sec
0.3182 0.1806 0.1007 0.0672 0.0644 0.0632 0.0598 0.0587 0.0574 0.0571 0.0567 0.0562 0.0559 0.0559 0.0559 0.0560 

[TRAIN] Epoch[3](1378/1500); Loss: 0.105050; Backpropagation: 0.0938 sec; Batch: 0.4674 sec
0.1629 0.1269 0.1152 0.1059 0.1023 0.1005 0.0986 0.0978 0.0972 0.0966 0.0964 0.0962 0.0962 0.0959 0.0961 0.0962 

[TRAIN] Epoch[3](1379/1500); Loss: 0.096616; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.1642 0.1185 0.1022 0.0987 0.0927 0.0904 0.0889 0.0883 0.0878 0.0878 0.0876 0.0876 0.0876 0.0878 0.0878 0.0881 

[TRAIN] Epoch[3](1380/1500); Loss: 0.096467; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.2556 0.1269 0.0901 0.0874 0.0948 0.0843 0.0821 0.0809 0.0805 0.0802 0.0801 0.0799 0.0800 0.0800 0.0803 0.0804 

[TRAIN] Epoch[3](1381/1500); Loss: 0.066555; Backpropagation: 0.0933 sec; Batch: 0.4768 sec
0.1889 0.0982 0.0673 0.0607 0.0616 0.0560 0.0546 0.0538 0.0532 0.0533 0.0531 0.0528 0.0527 0.0529 0.0528 0.0531 

[TRAIN] Epoch[3](1382/1500); Loss: 0.114365; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.2156 0.1468 0.1203 0.1106 0.1082 0.1058 0.1047 0.1037 0.1028 0.1024 0.1022 0.1019 0.1016 0.1013 0.1011 0.1010 

[TRAIN] Epoch[3](1383/1500); Loss: 0.094154; Backpropagation: 0.0933 sec; Batch: 0.4722 sec
0.1279 0.1050 0.0998 0.0955 0.0910 0.0895 0.0888 0.0886 0.0885 0.0887 0.0891 0.0895 0.0902 0.0908 0.0914 0.0922 

[TRAIN] Epoch[3](1384/1500); Loss: 0.094535; Backpropagation: 0.0936 sec; Batch: 0.4292 sec
0.1167 0.1196 0.1017 0.0937 0.0912 0.0910 0.0900 0.0896 0.0895 0.0897 0.0895 0.0897 0.0899 0.0901 0.0903 0.0904 

[TRAIN] Epoch[3](1385/1500); Loss: 0.080114; Backpropagation: 0.0941 sec; Batch: 0.4321 sec
0.3721 0.1504 0.0532 0.0463 0.1064 0.0795 0.0631 0.0479 0.0461 0.0440 0.0441 0.0442 0.0452 0.0457 0.0465 0.0470 

[TRAIN] Epoch[3](1386/1500); Loss: 0.084622; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1605 0.1043 0.0990 0.0877 0.0795 0.0772 0.0765 0.0757 0.0751 0.0747 0.0745 0.0742 0.0739 0.0738 0.0737 0.0737 

[TRAIN] Epoch[3](1387/1500); Loss: 0.077844; Backpropagation: 0.0932 sec; Batch: 0.4681 sec
0.1379 0.0929 0.0869 0.0861 0.0748 0.0724 0.0703 0.0697 0.0696 0.0694 0.0693 0.0693 0.0692 0.0693 0.0692 0.0693 

[TRAIN] Epoch[3](1388/1500); Loss: 0.095673; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1472 0.1308 0.1076 0.0953 0.0925 0.0906 0.0895 0.0887 0.0881 0.0874 0.0868 0.0861 0.0856 0.0851 0.0848 0.0846 

[TRAIN] Epoch[3](1389/1500); Loss: 0.073453; Backpropagation: 0.0932 sec; Batch: 0.4696 sec
0.2457 0.0985 0.0836 0.0630 0.0860 0.0668 0.0588 0.0542 0.0529 0.0522 0.0523 0.0520 0.0524 0.0521 0.0523 0.0521 

[TRAIN] Epoch[3](1390/1500); Loss: 0.127120; Backpropagation: 0.0928 sec; Batch: 0.4290 sec
0.1801 0.1416 0.1305 0.1243 0.1232 0.1224 0.1216 0.1213 0.1212 0.1212 0.1212 0.1209 0.1210 0.1212 0.1210 0.1212 

[TRAIN] Epoch[3](1391/1500); Loss: 0.114644; Backpropagation: 0.0939 sec; Batch: 0.4538 sec
0.2054 0.1437 0.1245 0.1145 0.1086 0.1071 0.1050 0.1043 0.1036 0.1033 0.1029 0.1027 0.1023 0.1022 0.1021 0.1020 

[TRAIN] Epoch[3](1392/1500); Loss: 0.121975; Backpropagation: 0.0938 sec; Batch: 0.4685 sec
0.1582 0.1323 0.1222 0.1191 0.1190 0.1192 0.1186 0.1180 0.1181 0.1179 0.1180 0.1177 0.1180 0.1184 0.1185 0.1186 

[TRAIN] Epoch[3](1393/1500); Loss: 0.065348; Backpropagation: 0.0939 sec; Batch: 0.4680 sec
0.1658 0.1054 0.0812 0.0680 0.0606 0.0566 0.0544 0.0528 0.0517 0.0509 0.0502 0.0497 0.0495 0.0495 0.0496 0.0497 

[TRAIN] Epoch[3](1394/1500); Loss: 0.100585; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1481 0.1293 0.1111 0.1003 0.0980 0.0963 0.0954 0.0944 0.0934 0.0928 0.0923 0.0921 0.0920 0.0915 0.0913 0.0911 

[TRAIN] Epoch[3](1395/1500); Loss: 0.081708; Backpropagation: 0.0939 sec; Batch: 0.4700 sec
0.2575 0.1148 0.0835 0.0801 0.0869 0.0723 0.0661 0.0620 0.0610 0.0609 0.0604 0.0604 0.0601 0.0602 0.0603 0.0608 

[TRAIN] Epoch[3](1396/1500); Loss: 0.112623; Backpropagation: 0.0936 sec; Batch: 0.4656 sec
0.2200 0.1314 0.1178 0.1090 0.1059 0.1042 0.1038 0.1031 0.1025 0.1019 0.1015 0.1010 0.1007 0.1001 0.0998 0.0994 

[TRAIN] Epoch[3](1397/1500); Loss: 0.111066; Backpropagation: 0.0938 sec; Batch: 0.5040 sec
0.2241 0.1181 0.1134 0.1042 0.1030 0.1005 0.1003 0.1005 0.1005 0.1006 0.1009 0.1013 0.1018 0.1022 0.1027 0.1031 

[TRAIN] Epoch[3](1398/1500); Loss: 0.129464; Backpropagation: 0.0938 sec; Batch: 0.4849 sec
0.1855 0.1428 0.1291 0.1259 0.1234 0.1226 0.1223 0.1223 0.1228 0.1234 0.1238 0.1243 0.1248 0.1254 0.1261 0.1269 

[TRAIN] Epoch[3](1399/1500); Loss: 0.123235; Backpropagation: 0.0939 sec; Batch: 0.4718 sec
0.1783 0.1387 0.1265 0.1216 0.1192 0.1175 0.1167 0.1164 0.1165 0.1166 0.1166 0.1168 0.1171 0.1174 0.1177 0.1181 

[TRAIN] Epoch[3](1400/1500); Loss: 0.092113; Backpropagation: 0.0938 sec; Batch: 0.4657 sec
0.2569 0.1779 0.1036 0.0859 0.0783 0.0720 0.0712 0.0696 0.0697 0.0695 0.0695 0.0698 0.0698 0.0698 0.0699 0.0702 

[TRAIN] Epoch[3](1401/1500); Loss: 0.066205; Backpropagation: 0.0939 sec; Batch: 0.4671 sec
0.1210 0.0898 0.0750 0.0706 0.0651 0.0624 0.0601 0.0588 0.0578 0.0575 0.0572 0.0572 0.0568 0.0567 0.0567 0.0566 

[TRAIN] Epoch[3](1402/1500); Loss: 0.070983; Backpropagation: 0.0957 sec; Batch: 0.4799 sec
0.1173 0.0885 0.0774 0.0706 0.0680 0.0664 0.0654 0.0653 0.0651 0.0648 0.0648 0.0647 0.0647 0.0642 0.0643 0.0643 

[TRAIN] Epoch[3](1403/1500); Loss: 0.090436; Backpropagation: 0.0948 sec; Batch: 0.4700 sec
0.1270 0.1092 0.0986 0.0939 0.0893 0.0874 0.0858 0.0849 0.0845 0.0841 0.0839 0.0837 0.0835 0.0836 0.0839 0.0839 

[TRAIN] Epoch[3](1404/1500); Loss: 0.074255; Backpropagation: 0.0940 sec; Batch: 0.6377 sec
0.1324 0.1121 0.0835 0.0744 0.0711 0.0679 0.0662 0.0654 0.0647 0.0643 0.0641 0.0640 0.0643 0.0645 0.0645 0.0649 

[TRAIN] Epoch[3](1405/1500); Loss: 0.079332; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.1817 0.1027 0.0786 0.0760 0.0744 0.0703 0.0694 0.0686 0.0685 0.0683 0.0683 0.0684 0.0685 0.0685 0.0685 0.0686 

[TRAIN] Epoch[3](1406/1500); Loss: 0.101286; Backpropagation: 0.0940 sec; Batch: 0.4312 sec
0.1998 0.1514 0.1085 0.0967 0.0917 0.0898 0.0889 0.0885 0.0883 0.0880 0.0879 0.0879 0.0882 0.0883 0.0882 0.0884 

[TRAIN] Epoch[3](1407/1500); Loss: 0.082667; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2732 0.1705 0.0746 0.0910 0.0706 0.0625 0.0602 0.0588 0.0584 0.0577 0.0575 0.0574 0.0576 0.0574 0.0577 0.0577 

[TRAIN] Epoch[3](1408/1500); Loss: 0.091759; Backpropagation: 0.0932 sec; Batch: 0.5265 sec
0.1392 0.1022 0.0936 0.0906 0.0875 0.0870 0.0866 0.0862 0.0862 0.0863 0.0864 0.0866 0.0868 0.0872 0.0877 0.0882 

[TRAIN] Epoch[3](1409/1500); Loss: 0.088948; Backpropagation: 0.0933 sec; Batch: 0.4346 sec
0.2140 0.1151 0.0877 0.0830 0.0822 0.0801 0.0777 0.0765 0.0761 0.0756 0.0757 0.0757 0.0757 0.0759 0.0762 0.0761 

[TRAIN] Epoch[3](1410/1500); Loss: 0.102962; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.1203 0.1226 0.1051 0.1017 0.1016 0.1022 0.1001 0.1000 0.0998 0.0998 0.0995 0.0992 0.0988 0.0989 0.0989 0.0990 

[TRAIN] Epoch[3](1411/1500); Loss: 0.057791; Backpropagation: 0.0939 sec; Batch: 0.4680 sec
0.0702 0.0716 0.0695 0.0615 0.0571 0.0552 0.0536 0.0534 0.0534 0.0534 0.0536 0.0540 0.0540 0.0543 0.0548 0.0551 

[TRAIN] Epoch[3](1412/1500); Loss: 0.134366; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1940 0.1470 0.1394 0.1327 0.1298 0.1290 0.1285 0.1279 0.1276 0.1277 0.1276 0.1276 0.1277 0.1277 0.1277 0.1278 

[TRAIN] Epoch[3](1413/1500); Loss: 0.085406; Backpropagation: 0.0957 sec; Batch: 0.4664 sec
0.1332 0.1147 0.0989 0.0844 0.0809 0.0787 0.0780 0.0776 0.0775 0.0772 0.0775 0.0774 0.0776 0.0776 0.0777 0.0777 

[TRAIN] Epoch[3](1414/1500); Loss: 0.087203; Backpropagation: 0.0942 sec; Batch: 0.4654 sec
0.1251 0.1100 0.0948 0.0868 0.0844 0.0830 0.0822 0.0814 0.0810 0.0809 0.0810 0.0809 0.0810 0.0808 0.0810 0.0810 

[TRAIN] Epoch[3](1415/1500); Loss: 0.099996; Backpropagation: 0.0938 sec; Batch: 0.4705 sec
0.1689 0.1283 0.1096 0.0999 0.0953 0.0925 0.0914 0.0908 0.0905 0.0905 0.0902 0.0904 0.0903 0.0903 0.0904 0.0905 

[TRAIN] Epoch[3](1416/1500); Loss: 0.105733; Backpropagation: 0.0937 sec; Batch: 0.4739 sec
0.1800 0.1204 0.1086 0.1036 0.1028 0.1006 0.0994 0.0986 0.0981 0.0978 0.0973 0.0971 0.0968 0.0969 0.0968 0.0968 

[TRAIN] Epoch[3](1417/1500); Loss: 0.033399; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.0420 0.0473 0.0334 0.0316 0.0306 0.0295 0.0295 0.0297 0.0303 0.0307 0.0312 0.0321 0.0329 0.0335 0.0345 0.0356 

[TRAIN] Epoch[3](1418/1500); Loss: 0.120936; Backpropagation: 0.0957 sec; Batch: 0.4692 sec
0.1589 0.1429 0.1295 0.1224 0.1188 0.1169 0.1158 0.1152 0.1145 0.1143 0.1142 0.1142 0.1142 0.1143 0.1143 0.1145 

[TRAIN] Epoch[3](1419/1500); Loss: 0.075820; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.0858 0.1024 0.0877 0.0751 0.0766 0.0720 0.0718 0.0715 0.0720 0.0715 0.0712 0.0710 0.0711 0.0710 0.0711 0.0712 

[TRAIN] Epoch[3](1420/1500); Loss: 0.095779; Backpropagation: 0.0932 sec; Batch: 0.4766 sec
0.2748 0.1679 0.1124 0.0790 0.0829 0.0791 0.0750 0.0741 0.0742 0.0738 0.0737 0.0732 0.0732 0.0730 0.0729 0.0732 

[TRAIN] Epoch[3](1421/1500); Loss: 0.100441; Backpropagation: 0.0935 sec; Batch: 0.4688 sec
0.1432 0.1004 0.0980 0.1046 0.0991 0.0978 0.0963 0.0956 0.0951 0.0954 0.0959 0.0968 0.0968 0.0971 0.0972 0.0978 

[TRAIN] Epoch[3](1422/1500); Loss: 0.071138; Backpropagation: 0.0921 sec; Batch: 0.5237 sec
0.1515 0.1007 0.0715 0.0666 0.0686 0.0638 0.0626 0.0616 0.0613 0.0612 0.0612 0.0614 0.0614 0.0615 0.0616 0.0618 

[TRAIN] Epoch[3](1423/1500); Loss: 0.071499; Backpropagation: 0.0934 sec; Batch: 0.4606 sec
0.1792 0.1133 0.0689 0.0833 0.0699 0.0607 0.0585 0.0568 0.0565 0.0564 0.0563 0.0564 0.0566 0.0569 0.0571 0.0572 

[TRAIN] Epoch[3](1424/1500); Loss: 0.112857; Backpropagation: 0.0939 sec; Batch: 0.4708 sec
0.2251 0.1330 0.1148 0.1084 0.1052 0.1042 0.1032 0.1027 0.1023 0.1022 0.1016 0.1011 0.1008 0.1006 0.1004 0.1002 

[TRAIN] Epoch[3](1425/1500); Loss: 0.066919; Backpropagation: 0.0939 sec; Batch: 0.4665 sec
0.0813 0.0812 0.0757 0.0672 0.0664 0.0649 0.0640 0.0636 0.0634 0.0636 0.0633 0.0631 0.0631 0.0633 0.0632 0.0632 

[TRAIN] Epoch[3](1426/1500); Loss: 0.101891; Backpropagation: 0.0937 sec; Batch: 0.4703 sec
0.1517 0.1226 0.1140 0.1009 0.0976 0.0960 0.0955 0.0951 0.0947 0.0946 0.0944 0.0944 0.0946 0.0947 0.0946 0.0947 

[TRAIN] Epoch[3](1427/1500); Loss: 0.066403; Backpropagation: 0.0939 sec; Batch: 0.4592 sec
0.1203 0.0960 0.0693 0.0687 0.0613 0.0598 0.0593 0.0589 0.0587 0.0584 0.0585 0.0583 0.0583 0.0587 0.0588 0.0590 

[TRAIN] Epoch[3](1428/1500); Loss: 0.065831; Backpropagation: 0.0938 sec; Batch: 0.4701 sec
0.3569 0.1338 0.0482 0.0349 0.0968 0.0624 0.0456 0.0334 0.0311 0.0298 0.0295 0.0298 0.0298 0.0300 0.0304 0.0309 

[TRAIN] Epoch[3](1429/1500); Loss: 0.072499; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.0952 0.0944 0.0836 0.0714 0.0698 0.0683 0.0675 0.0673 0.0672 0.0672 0.0672 0.0674 0.0676 0.0682 0.0686 0.0690 

[TRAIN] Epoch[3](1430/1500); Loss: 0.066493; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.1833 0.0894 0.0692 0.0958 0.0679 0.0590 0.0537 0.0519 0.0507 0.0498 0.0495 0.0491 0.0491 0.0485 0.0486 0.0483 

[TRAIN] Epoch[3](1431/1500); Loss: 0.091303; Backpropagation: 0.0940 sec; Batch: 0.4675 sec
0.1660 0.1120 0.0984 0.0871 0.0897 0.0863 0.0835 0.0820 0.0820 0.0819 0.0818 0.0819 0.0819 0.0820 0.0821 0.0822 

[TRAIN] Epoch[3](1432/1500); Loss: 0.087858; Backpropagation: 0.0932 sec; Batch: 0.4693 sec
0.1162 0.1099 0.0977 0.0864 0.0878 0.0837 0.0828 0.0825 0.0825 0.0822 0.0821 0.0821 0.0822 0.0823 0.0826 0.0828 

[TRAIN] Epoch[3](1433/1500); Loss: 0.083388; Backpropagation: 0.0932 sec; Batch: 0.4976 sec
0.1637 0.1022 0.0863 0.0801 0.0819 0.0775 0.0758 0.0745 0.0742 0.0741 0.0740 0.0738 0.0739 0.0739 0.0740 0.0743 

[TRAIN] Epoch[3](1434/1500); Loss: 0.099966; Backpropagation: 0.0938 sec; Batch: 0.4648 sec
0.2466 0.1658 0.0964 0.0917 0.0945 0.0914 0.0871 0.0825 0.0816 0.0806 0.0803 0.0799 0.0801 0.0801 0.0803 0.0806 

[TRAIN] Epoch[3](1435/1500); Loss: 0.046741; Backpropagation: 0.0939 sec; Batch: 0.4706 sec
0.0847 0.0683 0.0748 0.0566 0.0487 0.0392 0.0375 0.0370 0.0367 0.0366 0.0369 0.0370 0.0378 0.0381 0.0388 0.0393 

[TRAIN] Epoch[3](1436/1500); Loss: 0.051916; Backpropagation: 0.0938 sec; Batch: 0.4699 sec
0.1131 0.0962 0.0681 0.0556 0.0453 0.0426 0.0417 0.0413 0.0409 0.0406 0.0406 0.0407 0.0407 0.0410 0.0410 0.0412 

[TRAIN] Epoch[3](1437/1500); Loss: 0.091604; Backpropagation: 0.0939 sec; Batch: 0.4397 sec
0.2186 0.1151 0.1047 0.0880 0.1005 0.0873 0.0823 0.0779 0.0756 0.0742 0.0741 0.0735 0.0735 0.0734 0.0735 0.0735 

[TRAIN] Epoch[3](1438/1500); Loss: 0.083195; Backpropagation: 0.0932 sec; Batch: 0.4697 sec
0.0931 0.0903 0.0894 0.0850 0.0838 0.0828 0.0818 0.0811 0.0807 0.0806 0.0805 0.0804 0.0804 0.0803 0.0804 0.0805 

[TRAIN] Epoch[3](1439/1500); Loss: 0.126296; Backpropagation: 0.0939 sec; Batch: 0.4597 sec
0.1545 0.1411 0.1316 0.1282 0.1251 0.1234 0.1227 0.1220 0.1217 0.1214 0.1213 0.1212 0.1214 0.1216 0.1217 0.1220 

[TRAIN] Epoch[3](1440/1500); Loss: 0.067455; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1225 0.1050 0.0782 0.0691 0.0650 0.0610 0.0594 0.0582 0.0579 0.0576 0.0576 0.0575 0.0575 0.0573 0.0576 0.0578 

[TRAIN] Epoch[3](1441/1500); Loss: 0.080344; Backpropagation: 0.0937 sec; Batch: 0.4700 sec
0.0899 0.1075 0.1025 0.0914 0.0836 0.0766 0.0751 0.0742 0.0739 0.0734 0.0732 0.0730 0.0729 0.0727 0.0727 0.0727 

[TRAIN] Epoch[3](1442/1500); Loss: 0.162833; Backpropagation: 0.0938 sec; Batch: 0.4659 sec
0.1877 0.1837 0.1683 0.1628 0.1604 0.1597 0.1590 0.1586 0.1582 0.1583 0.1583 0.1580 0.1580 0.1582 0.1581 0.1580 

[TRAIN] Epoch[3](1443/1500); Loss: 0.051183; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.0862 0.0865 0.0575 0.0506 0.0492 0.0462 0.0453 0.0444 0.0440 0.0440 0.0438 0.0439 0.0441 0.0443 0.0444 0.0446 

[TRAIN] Epoch[3](1444/1500); Loss: 0.094014; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1413 0.1162 0.1019 0.0975 0.0961 0.0916 0.0892 0.0875 0.0865 0.0859 0.0854 0.0850 0.0849 0.0850 0.0850 0.0852 

[TRAIN] Epoch[3](1445/1500); Loss: 0.073334; Backpropagation: 0.0939 sec; Batch: 0.4330 sec
0.1205 0.0795 0.0974 0.0859 0.0808 0.0720 0.0670 0.0648 0.0641 0.0638 0.0634 0.0629 0.0627 0.0629 0.0627 0.0629 

[TRAIN] Epoch[3](1446/1500); Loss: 0.141618; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.2230 0.1717 0.1440 0.1381 0.1362 0.1349 0.1338 0.1328 0.1322 0.1318 0.1315 0.1313 0.1311 0.1311 0.1311 0.1312 

[TRAIN] Epoch[3](1447/1500); Loss: 0.102755; Backpropagation: 0.0935 sec; Batch: 0.4694 sec
0.1214 0.1296 0.1109 0.1050 0.1012 0.0987 0.0981 0.0979 0.0977 0.0976 0.0975 0.0975 0.0976 0.0976 0.0978 0.0979 

[TRAIN] Epoch[3](1448/1500); Loss: 0.175663; Backpropagation: 0.0932 sec; Batch: 0.4706 sec
0.2456 0.1970 0.1697 0.1700 0.1729 0.1724 0.1710 0.1696 0.1691 0.1685 0.1681 0.1676 0.1676 0.1673 0.1672 0.1669 

[TRAIN] Epoch[3](1449/1500); Loss: 0.063911; Backpropagation: 0.0939 sec; Batch: 0.4711 sec
0.1206 0.0965 0.0707 0.0637 0.0603 0.0586 0.0565 0.0554 0.0549 0.0547 0.0545 0.0545 0.0549 0.0552 0.0556 0.0560 

[TRAIN] Epoch[3](1450/1500); Loss: 0.119659; Backpropagation: 0.0936 sec; Batch: 0.4661 sec
0.1880 0.1419 0.1208 0.1200 0.1167 0.1150 0.1134 0.1122 0.1115 0.1112 0.1109 0.1107 0.1106 0.1104 0.1105 0.1107 

[TRAIN] Epoch[3](1451/1500); Loss: 0.142845; Backpropagation: 0.0939 sec; Batch: 0.4678 sec
0.2049 0.1577 0.1453 0.1433 0.1435 0.1398 0.1379 0.1361 0.1355 0.1351 0.1349 0.1346 0.1343 0.1342 0.1342 0.1342 

[TRAIN] Epoch[3](1452/1500); Loss: 0.081033; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.2214 0.0810 0.1017 0.0984 0.1018 0.0905 0.0809 0.0711 0.0643 0.0593 0.0567 0.0546 0.0538 0.0536 0.0537 0.0537 

[TRAIN] Epoch[3](1453/1500); Loss: 0.094844; Backpropagation: 0.0938 sec; Batch: 0.4664 sec
0.2562 0.1234 0.0875 0.0782 0.1027 0.0961 0.0910 0.0839 0.0782 0.0750 0.0742 0.0741 0.0742 0.0742 0.0743 0.0745 

[TRAIN] Epoch[3](1454/1500); Loss: 0.065705; Backpropagation: 0.0940 sec; Batch: 0.4430 sec
0.0929 0.0816 0.0740 0.0701 0.0672 0.0638 0.0615 0.0605 0.0600 0.0598 0.0598 0.0597 0.0598 0.0600 0.0602 0.0604 

[TRAIN] Epoch[3](1455/1500); Loss: 0.093061; Backpropagation: 0.0940 sec; Batch: 0.4308 sec
0.1207 0.0996 0.0993 0.0926 0.0914 0.0905 0.0899 0.0896 0.0894 0.0893 0.0893 0.0894 0.0894 0.0893 0.0895 0.0897 

[TRAIN] Epoch[3](1456/1500); Loss: 0.059733; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1466 0.0678 0.0526 0.0771 0.0641 0.0582 0.0520 0.0495 0.0485 0.0484 0.0482 0.0482 0.0485 0.0485 0.0488 0.0487 

[TRAIN] Epoch[3](1457/1500); Loss: 0.070518; Backpropagation: 0.0939 sec; Batch: 0.5016 sec
0.1904 0.1183 0.0762 0.0608 0.0635 0.0605 0.0586 0.0565 0.0556 0.0547 0.0546 0.0547 0.0552 0.0557 0.0562 0.0567 

[TRAIN] Epoch[3](1458/1500); Loss: 0.049839; Backpropagation: 0.0932 sec; Batch: 0.4701 sec
0.0651 0.0571 0.0509 0.0474 0.0469 0.0465 0.0464 0.0465 0.0468 0.0473 0.0477 0.0483 0.0489 0.0498 0.0505 0.0512 

[TRAIN] Epoch[3](1459/1500); Loss: 0.071553; Backpropagation: 0.0939 sec; Batch: 0.4671 sec
0.0693 0.0791 0.0816 0.0737 0.0719 0.0693 0.0685 0.0687 0.0689 0.0691 0.0697 0.0700 0.0704 0.0710 0.0715 0.0720 

[TRAIN] Epoch[3](1460/1500); Loss: 0.144881; Backpropagation: 0.0938 sec; Batch: 0.4545 sec
0.2306 0.1842 0.1523 0.1472 0.1417 0.1387 0.1364 0.1343 0.1330 0.1321 0.1317 0.1314 0.1312 0.1311 0.1310 0.1311 

[TRAIN] Epoch[3](1461/1500); Loss: 0.090386; Backpropagation: 0.0939 sec; Batch: 0.4676 sec
0.1240 0.1236 0.0953 0.1088 0.0975 0.0892 0.0842 0.0816 0.0807 0.0801 0.0799 0.0799 0.0801 0.0803 0.0805 0.0806 

[TRAIN] Epoch[3](1462/1500); Loss: 0.113591; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.1768 0.1269 0.1135 0.1117 0.1088 0.1078 0.1074 0.1073 0.1073 0.1071 0.1070 0.1071 0.1071 0.1071 0.1071 0.1073 

[TRAIN] Epoch[3](1463/1500); Loss: 0.115480; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.2374 0.1553 0.1253 0.1061 0.1041 0.1059 0.1044 0.1033 0.1022 0.1011 0.1005 0.1004 0.1003 0.1004 0.1004 0.1005 

[TRAIN] Epoch[3](1464/1500); Loss: 0.142797; Backpropagation: 0.0938 sec; Batch: 0.4671 sec
0.2167 0.1686 0.1437 0.1377 0.1366 0.1356 0.1348 0.1345 0.1346 0.1346 0.1345 0.1344 0.1344 0.1346 0.1347 0.1347 

[TRAIN] Epoch[3](1465/1500); Loss: 0.088717; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1705 0.0974 0.0998 0.0866 0.0856 0.0829 0.0810 0.0799 0.0794 0.0792 0.0791 0.0793 0.0794 0.0796 0.0798 0.0799 

[TRAIN] Epoch[3](1466/1500); Loss: 0.068119; Backpropagation: 0.0938 sec; Batch: 0.4643 sec
0.2568 0.1279 0.0712 0.0534 0.0588 0.0558 0.0520 0.0484 0.0464 0.0455 0.0453 0.0454 0.0454 0.0455 0.0457 0.0462 

[TRAIN] Epoch[3](1467/1500); Loss: 0.137827; Backpropagation: 0.0940 sec; Batch: 0.6650 sec
0.1711 0.1573 0.1456 0.1406 0.1381 0.1363 0.1346 0.1335 0.1328 0.1321 0.1313 0.1310 0.1307 0.1304 0.1301 0.1298 

[TRAIN] Epoch[3](1468/1500); Loss: 0.056267; Backpropagation: 0.0950 sec; Batch: 0.4703 sec
0.0871 0.0776 0.0673 0.0569 0.0527 0.0515 0.0511 0.0511 0.0510 0.0508 0.0505 0.0507 0.0505 0.0506 0.0504 0.0505 

[TRAIN] Epoch[3](1469/1500); Loss: 0.075553; Backpropagation: 0.0956 sec; Batch: 0.4664 sec
0.1012 0.0992 0.0909 0.0794 0.0755 0.0732 0.0721 0.0711 0.0704 0.0695 0.0688 0.0684 0.0679 0.0675 0.0670 0.0667 

[TRAIN] Epoch[3](1470/1500); Loss: 0.062669; Backpropagation: 0.0956 sec; Batch: 0.4665 sec
0.0848 0.0850 0.0738 0.0649 0.0627 0.0596 0.0588 0.0578 0.0576 0.0573 0.0573 0.0569 0.0566 0.0565 0.0564 0.0566 

[TRAIN] Epoch[3](1471/1500); Loss: 0.090302; Backpropagation: 0.0939 sec; Batch: 0.4696 sec
0.2170 0.1275 0.0995 0.0845 0.0903 0.0802 0.0775 0.0753 0.0743 0.0739 0.0739 0.0738 0.0741 0.0742 0.0743 0.0744 

[TRAIN] Epoch[3](1472/1500); Loss: 0.069272; Backpropagation: 0.0934 sec; Batch: 0.4320 sec
0.0894 0.0932 0.0765 0.0703 0.0671 0.0656 0.0649 0.0647 0.0646 0.0645 0.0645 0.0644 0.0644 0.0646 0.0647 0.0648 

[TRAIN] Epoch[3](1473/1500); Loss: 0.047778; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.0544 0.0653 0.0499 0.0476 0.0459 0.0451 0.0447 0.0444 0.0446 0.0449 0.0451 0.0454 0.0459 0.0465 0.0471 0.0476 

[TRAIN] Epoch[3](1474/1500); Loss: 0.084445; Backpropagation: 0.0957 sec; Batch: 0.4710 sec
0.3383 0.1307 0.0837 0.0588 0.1030 0.0822 0.0712 0.0591 0.0530 0.0517 0.0517 0.0522 0.0527 0.0534 0.0543 0.0552 

[TRAIN] Epoch[3](1475/1500); Loss: 0.120910; Backpropagation: 0.0938 sec; Batch: 0.4759 sec
0.2126 0.1611 0.1311 0.1170 0.1126 0.1125 0.1105 0.1098 0.1092 0.1087 0.1085 0.1083 0.1082 0.1081 0.1081 0.1082 

[TRAIN] Epoch[3](1476/1500); Loss: 0.063239; Backpropagation: 0.0938 sec; Batch: 0.4671 sec
0.1403 0.0910 0.0748 0.0670 0.0606 0.0574 0.0553 0.0540 0.0531 0.0523 0.0518 0.0514 0.0509 0.0506 0.0506 0.0509 

[TRAIN] Epoch[3](1477/1500); Loss: 0.070584; Backpropagation: 0.0940 sec; Batch: 0.4680 sec
0.0904 0.0797 0.0802 0.0705 0.0693 0.0677 0.0671 0.0669 0.0670 0.0671 0.0670 0.0671 0.0671 0.0672 0.0676 0.0675 

[TRAIN] Epoch[3](1478/1500); Loss: 0.109855; Backpropagation: 0.0938 sec; Batch: 0.5260 sec
0.1803 0.1322 0.1164 0.1092 0.1060 0.1038 0.1028 0.1022 0.1017 0.1013 0.1010 0.1008 0.1002 0.1000 0.0999 0.0999 

[TRAIN] Epoch[3](1479/1500); Loss: 0.065061; Backpropagation: 0.0939 sec; Batch: 0.4670 sec
0.1164 0.0994 0.0741 0.0648 0.0603 0.0578 0.0572 0.0570 0.0568 0.0566 0.0565 0.0565 0.0567 0.0569 0.0570 0.0571 

[TRAIN] Epoch[3](1480/1500); Loss: 0.156022; Backpropagation: 0.0958 sec; Batch: 0.4679 sec
0.2682 0.2042 0.1512 0.1432 0.1454 0.1452 0.1446 0.1441 0.1438 0.1435 0.1435 0.1435 0.1436 0.1438 0.1440 0.1445 

[TRAIN] Epoch[3](1481/1500); Loss: 0.119173; Backpropagation: 0.0939 sec; Batch: 0.5095 sec
0.1834 0.1529 0.1404 0.1271 0.1186 0.1124 0.1104 0.1087 0.1078 0.1072 0.1068 0.1065 0.1061 0.1062 0.1061 0.1062 

[TRAIN] Epoch[3](1482/1500); Loss: 0.155848; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.2571 0.2019 0.1637 0.1476 0.1440 0.1433 0.1432 0.1431 0.1430 0.1432 0.1433 0.1436 0.1437 0.1439 0.1443 0.1447 

[TRAIN] Epoch[3](1483/1500); Loss: 0.153550; Backpropagation: 0.0932 sec; Batch: 0.4658 sec
0.1897 0.1643 0.1698 0.1598 0.1553 0.1508 0.1485 0.1475 0.1469 0.1466 0.1464 0.1464 0.1462 0.1461 0.1462 0.1462 

[TRAIN] Epoch[3](1484/1500); Loss: 0.148033; Backpropagation: 0.0939 sec; Batch: 0.4676 sec
0.2004 0.1755 0.1509 0.1469 0.1432 0.1428 0.1421 0.1418 0.1412 0.1410 0.1409 0.1405 0.1404 0.1403 0.1404 0.1403 

[TRAIN] Epoch[3](1485/1500); Loss: 0.114741; Backpropagation: 0.0957 sec; Batch: 0.4721 sec
0.2148 0.1455 0.1161 0.1094 0.1092 0.1069 0.1058 0.1048 0.1040 0.1035 0.1030 0.1027 0.1025 0.1025 0.1025 0.1026 

[TRAIN] Epoch[3](1486/1500); Loss: 0.108998; Backpropagation: 0.0956 sec; Batch: 0.4783 sec
0.1554 0.1316 0.1228 0.1138 0.1075 0.1041 0.1021 0.1014 0.1011 0.1007 0.1006 0.1006 0.1006 0.1005 0.1005 0.1005 

[TRAIN] Epoch[3](1487/1500); Loss: 0.093816; Backpropagation: 0.0940 sec; Batch: 0.4704 sec
0.1434 0.0994 0.0993 0.0948 0.0906 0.0890 0.0879 0.0876 0.0877 0.0878 0.0880 0.0884 0.0888 0.0892 0.0893 0.0898 

[TRAIN] Epoch[3](1488/1500); Loss: 0.078863; Backpropagation: 0.0939 sec; Batch: 0.4698 sec
0.3451 0.1337 0.0692 0.0462 0.1023 0.0808 0.0671 0.0512 0.0460 0.0450 0.0449 0.0452 0.0455 0.0459 0.0466 0.0472 

[TRAIN] Epoch[3](1489/1500); Loss: 0.035587; Backpropagation: 0.0938 sec; Batch: 0.4704 sec
0.0437 0.0526 0.0475 0.0389 0.0364 0.0322 0.0315 0.0311 0.0309 0.0313 0.0315 0.0317 0.0319 0.0323 0.0327 0.0334 

[TRAIN] Epoch[3](1490/1500); Loss: 0.128911; Backpropagation: 0.0942 sec; Batch: 0.4720 sec
0.1831 0.1413 0.1312 0.1262 0.1241 0.1232 0.1229 0.1227 0.1226 0.1227 0.1231 0.1233 0.1235 0.1238 0.1242 0.1247 

[TRAIN] Epoch[3](1491/1500); Loss: 0.133531; Backpropagation: 0.0957 sec; Batch: 0.4677 sec
0.1888 0.1493 0.1341 0.1292 0.1286 0.1276 0.1272 0.1271 0.1272 0.1274 0.1278 0.1281 0.1283 0.1284 0.1286 0.1288 

[TRAIN] Epoch[3](1492/1500); Loss: 0.132534; Backpropagation: 0.0938 sec; Batch: 0.4677 sec
0.1878 0.1489 0.1436 0.1363 0.1311 0.1274 0.1259 0.1248 0.1240 0.1240 0.1240 0.1239 0.1241 0.1246 0.1248 0.1253 

[TRAIN] Epoch[3](1493/1500); Loss: 0.121714; Backpropagation: 0.0940 sec; Batch: 0.4644 sec
0.2017 0.1429 0.1232 0.1168 0.1155 0.1146 0.1139 0.1134 0.1130 0.1130 0.1130 0.1131 0.1132 0.1131 0.1133 0.1137 

[TRAIN] Epoch[3](1494/1500); Loss: 0.091317; Backpropagation: 0.0939 sec; Batch: 0.4980 sec
0.2049 0.1362 0.0962 0.0834 0.0819 0.0801 0.0790 0.0782 0.0779 0.0777 0.0775 0.0775 0.0775 0.0776 0.0778 0.0776 

[TRAIN] Epoch[3](1495/1500); Loss: 0.130739; Backpropagation: 0.0939 sec; Batch: 0.4661 sec
0.1761 0.1462 0.1353 0.1304 0.1281 0.1266 0.1255 0.1250 0.1248 0.1246 0.1244 0.1244 0.1247 0.1249 0.1252 0.1255 

[TRAIN] Epoch[3](1496/1500); Loss: 0.127234; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.1587 0.1452 0.1345 0.1283 0.1252 0.1234 0.1226 0.1220 0.1218 0.1217 0.1217 0.1218 0.1219 0.1221 0.1223 0.1225 

[TRAIN] Epoch[3](1497/1500); Loss: 0.066368; Backpropagation: 0.0940 sec; Batch: 0.4678 sec
0.2457 0.0947 0.0824 0.0592 0.0691 0.0572 0.0499 0.0461 0.0448 0.0444 0.0444 0.0443 0.0444 0.0449 0.0450 0.0452 

[TRAIN] Epoch[3](1498/1500); Loss: 0.156200; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.2091 0.1767 0.1666 0.1550 0.1526 0.1512 0.1505 0.1499 0.1494 0.1491 0.1487 0.1484 0.1482 0.1480 0.1479 0.1479 

[TRAIN] Epoch[3](1499/1500); Loss: 0.067101; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1049 0.0885 0.0779 0.0678 0.0639 0.0627 0.0615 0.0608 0.0605 0.0603 0.0602 0.0603 0.0606 0.0609 0.0612 0.0614 

[TRAIN] Epoch[3](1500/1500); Loss: 0.072025; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1229 0.1017 0.0802 0.0733 0.0677 0.0658 0.0651 0.0644 0.0637 0.0634 0.0638 0.0639 0.0640 0.0640 0.0642 0.0643 

[TRAIN] Epoch[4](1/1500); Loss: 0.111821; Backpropagation: 0.1030 sec; Batch: 0.4742 sec
0.1799 0.1476 0.1214 0.1094 0.1061 0.1042 0.1034 0.1029 0.1025 0.1022 0.1022 0.1019 0.1017 0.1014 0.1013 0.1012 

[TRAIN] Epoch[4](2/1500); Loss: 0.123089; Backpropagation: 0.0935 sec; Batch: 0.4314 sec
0.1563 0.1451 0.1279 0.1207 0.1197 0.1200 0.1194 0.1189 0.1186 0.1182 0.1178 0.1176 0.1176 0.1174 0.1171 0.1171 

[TRAIN] Epoch[4](3/1500); Loss: 0.100603; Backpropagation: 0.0938 sec; Batch: 0.4301 sec
0.1645 0.1336 0.1084 0.1006 0.0961 0.0939 0.0928 0.0923 0.0920 0.0916 0.0907 0.0905 0.0905 0.0905 0.0908 0.0909 

[TRAIN] Epoch[4](4/1500); Loss: 0.119019; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1889 0.1366 0.1243 0.1159 0.1137 0.1126 0.1122 0.1118 0.1112 0.1111 0.1111 0.1111 0.1110 0.1111 0.1110 0.1107 

[TRAIN] Epoch[4](5/1500); Loss: 0.133696; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2042 0.1691 0.1352 0.1271 0.1266 0.1261 0.1254 0.1249 0.1249 0.1250 0.1249 0.1249 0.1249 0.1251 0.1253 0.1254 

[TRAIN] Epoch[4](6/1500); Loss: 0.066414; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1057 0.0896 0.0717 0.0655 0.0631 0.0618 0.0614 0.0610 0.0606 0.0603 0.0602 0.0601 0.0602 0.0603 0.0605 0.0606 

[TRAIN] Epoch[4](7/1500); Loss: 0.089310; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1888 0.1132 0.0875 0.0828 0.0823 0.0811 0.0802 0.0796 0.0792 0.0790 0.0789 0.0793 0.0792 0.0790 0.0792 0.0794 

[TRAIN] Epoch[4](8/1500); Loss: 0.088252; Backpropagation: 0.0938 sec; Batch: 0.4303 sec
0.1277 0.1262 0.0964 0.0871 0.0842 0.0830 0.0820 0.0814 0.0812 0.0809 0.0805 0.0804 0.0803 0.0801 0.0802 0.0804 

[TRAIN] Epoch[4](9/1500); Loss: 0.045305; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.0713 0.0681 0.0558 0.0463 0.0425 0.0412 0.0402 0.0398 0.0395 0.0393 0.0395 0.0398 0.0400 0.0402 0.0405 0.0410 

[TRAIN] Epoch[4](10/1500); Loss: 0.120629; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1794 0.1539 0.1452 0.1286 0.1205 0.1151 0.1127 0.1111 0.1101 0.1093 0.1085 0.1079 0.1074 0.1070 0.1067 0.1067 

[TRAIN] Epoch[4](11/1500); Loss: 0.058723; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.0950 0.0713 0.0754 0.0576 0.0570 0.0553 0.0533 0.0527 0.0526 0.0527 0.0525 0.0524 0.0526 0.0530 0.0529 0.0531 

[TRAIN] Epoch[4](12/1500); Loss: 0.065703; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1285 0.0896 0.0743 0.0644 0.0612 0.0595 0.0587 0.0579 0.0575 0.0571 0.0571 0.0570 0.0570 0.0569 0.0571 0.0575 

[TRAIN] Epoch[4](13/1500); Loss: 0.069999; Backpropagation: 0.0933 sec; Batch: 0.4300 sec
0.1880 0.1093 0.0769 0.0655 0.0614 0.0589 0.0575 0.0566 0.0561 0.0559 0.0558 0.0557 0.0556 0.0556 0.0556 0.0557 

[TRAIN] Epoch[4](14/1500); Loss: 0.055537; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1106 0.0703 0.0636 0.0646 0.0576 0.0546 0.0510 0.0488 0.0478 0.0471 0.0466 0.0461 0.0455 0.0452 0.0448 0.0446 

[TRAIN] Epoch[4](15/1500); Loss: 0.087028; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.3088 0.1968 0.1094 0.0727 0.0632 0.0619 0.0597 0.0591 0.0581 0.0577 0.0575 0.0572 0.0574 0.0574 0.0576 0.0579 

[TRAIN] Epoch[4](16/1500); Loss: 0.088936; Backpropagation: 0.0934 sec; Batch: 0.4329 sec
0.1340 0.1097 0.0974 0.0891 0.0865 0.0852 0.0840 0.0831 0.0826 0.0823 0.0820 0.0816 0.0814 0.0814 0.0813 0.0814 

[TRAIN] Epoch[4](17/1500); Loss: 0.080169; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1458 0.0892 0.0978 0.0778 0.0772 0.0748 0.0723 0.0716 0.0717 0.0717 0.0717 0.0718 0.0719 0.0722 0.0725 0.0725 

[TRAIN] Epoch[4](18/1500); Loss: 0.079125; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1171 0.0907 0.0879 0.0789 0.0767 0.0751 0.0744 0.0744 0.0740 0.0737 0.0735 0.0736 0.0738 0.0740 0.0740 0.0741 

[TRAIN] Epoch[4](19/1500); Loss: 0.078329; Backpropagation: 0.0936 sec; Batch: 0.4463 sec
0.1953 0.1001 0.0995 0.0800 0.0760 0.0689 0.0654 0.0639 0.0634 0.0631 0.0628 0.0629 0.0630 0.0630 0.0630 0.0631 

[TRAIN] Epoch[4](20/1500); Loss: 0.175202; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2545 0.1964 0.1794 0.1712 0.1691 0.1680 0.1674 0.1670 0.1669 0.1666 0.1663 0.1661 0.1662 0.1662 0.1660 0.1659 

[TRAIN] Epoch[4](21/1500); Loss: 0.133155; Backpropagation: 0.0941 sec; Batch: 0.4368 sec
0.1933 0.1654 0.1392 0.1323 0.1290 0.1276 0.1265 0.1256 0.1250 0.1246 0.1243 0.1240 0.1237 0.1234 0.1232 0.1233 

[TRAIN] Epoch[4](22/1500); Loss: 0.120158; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.2192 0.1458 0.1201 0.1162 0.1131 0.1122 0.1114 0.1111 0.1108 0.1103 0.1098 0.1092 0.1086 0.1084 0.1082 0.1080 

[TRAIN] Epoch[4](23/1500); Loss: 0.049474; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1091 0.0761 0.0529 0.0450 0.0471 0.0451 0.0426 0.0412 0.0409 0.0409 0.0411 0.0413 0.0416 0.0418 0.0423 0.0426 

[TRAIN] Epoch[4](24/1500); Loss: 0.049031; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.0851 0.0752 0.0554 0.0500 0.0479 0.0457 0.0439 0.0433 0.0431 0.0427 0.0424 0.0422 0.0420 0.0418 0.0420 0.0421 

[TRAIN] Epoch[4](25/1500); Loss: 0.114937; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1463 0.1342 0.1229 0.1158 0.1127 0.1115 0.1107 0.1103 0.1099 0.1095 0.1094 0.1094 0.1093 0.1091 0.1090 0.1091 

[TRAIN] Epoch[4](26/1500); Loss: 0.063452; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2630 0.1572 0.0548 0.0495 0.0567 0.0530 0.0423 0.0373 0.0372 0.0371 0.0374 0.0375 0.0376 0.0379 0.0381 0.0385 

[TRAIN] Epoch[4](27/1500); Loss: 0.040752; Backpropagation: 0.0959 sec; Batch: 0.4301 sec
0.0820 0.0586 0.0485 0.0375 0.0368 0.0352 0.0350 0.0349 0.0350 0.0349 0.0349 0.0352 0.0353 0.0357 0.0360 0.0365 

[TRAIN] Epoch[4](28/1500); Loss: 0.063146; Backpropagation: 0.0958 sec; Batch: 0.4303 sec
0.1075 0.0979 0.0774 0.0622 0.0589 0.0564 0.0558 0.0552 0.0549 0.0546 0.0543 0.0543 0.0547 0.0550 0.0554 0.0559 

[TRAIN] Epoch[4](29/1500); Loss: 0.126787; Backpropagation: 0.0942 sec; Batch: 0.4288 sec
0.1729 0.1368 0.1273 0.1251 0.1237 0.1231 0.1228 0.1227 0.1224 0.1222 0.1220 0.1217 0.1215 0.1214 0.1214 0.1214 

[TRAIN] Epoch[4](30/1500); Loss: 0.127564; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1859 0.1510 0.1316 0.1246 0.1229 0.1220 0.1213 0.1207 0.1206 0.1206 0.1204 0.1202 0.1200 0.1198 0.1197 0.1198 

[TRAIN] Epoch[4](31/1500); Loss: 0.066291; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1791 0.0693 0.0674 0.0649 0.0593 0.0580 0.0575 0.0571 0.0567 0.0563 0.0560 0.0559 0.0557 0.0557 0.0558 0.0559 

[TRAIN] Epoch[4](32/1500); Loss: 0.131783; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2381 0.1533 0.1354 0.1287 0.1247 0.1230 0.1220 0.1214 0.1209 0.1205 0.1203 0.1202 0.1201 0.1200 0.1200 0.1201 

[TRAIN] Epoch[4](33/1500); Loss: 0.045689; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.0965 0.0499 0.0708 0.0432 0.0409 0.0396 0.0386 0.0383 0.0384 0.0390 0.0391 0.0390 0.0391 0.0393 0.0395 0.0397 

[TRAIN] Epoch[4](34/1500); Loss: 0.119564; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.1929 0.1376 0.1202 0.1170 0.1149 0.1141 0.1133 0.1129 0.1121 0.1117 0.1113 0.1112 0.1110 0.1109 0.1109 0.1109 

[TRAIN] Epoch[4](35/1500); Loss: 0.111513; Backpropagation: 0.0944 sec; Batch: 0.4415 sec
0.1790 0.1453 0.1155 0.1086 0.1062 0.1052 0.1044 0.1034 0.1029 0.1026 0.1025 0.1022 0.1019 0.1017 0.1014 0.1014 

[TRAIN] Epoch[4](36/1500); Loss: 0.152892; Backpropagation: 0.0932 sec; Batch: 0.4652 sec
0.1904 0.1656 0.1599 0.1578 0.1543 0.1510 0.1495 0.1486 0.1478 0.1472 0.1467 0.1463 0.1458 0.1454 0.1450 0.1450 

[TRAIN] Epoch[4](37/1500); Loss: 0.129191; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2034 0.1442 0.1292 0.1258 0.1237 0.1231 0.1227 0.1223 0.1222 0.1219 0.1217 0.1215 0.1213 0.1213 0.1214 0.1212 

[TRAIN] Epoch[4](38/1500); Loss: 0.084222; Backpropagation: 0.0939 sec; Batch: 0.4273 sec
0.1282 0.1061 0.0885 0.0838 0.0806 0.0795 0.0791 0.0786 0.0783 0.0780 0.0779 0.0778 0.0780 0.0777 0.0777 0.0778 

[TRAIN] Epoch[4](39/1500); Loss: 0.087845; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.3070 0.1721 0.0946 0.0679 0.0668 0.0644 0.0644 0.0637 0.0633 0.0629 0.0629 0.0630 0.0631 0.0631 0.0632 0.0633 

[TRAIN] Epoch[4](40/1500); Loss: 0.098568; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2216 0.1266 0.0979 0.0905 0.0941 0.0898 0.0876 0.0859 0.0856 0.0854 0.0853 0.0852 0.0852 0.0853 0.0854 0.0854 

[TRAIN] Epoch[4](41/1500); Loss: 0.145347; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2066 0.1641 0.1544 0.1463 0.1422 0.1407 0.1397 0.1387 0.1382 0.1376 0.1370 0.1365 0.1363 0.1361 0.1356 0.1355 

[TRAIN] Epoch[4](42/1500); Loss: 0.129641; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1929 0.1481 0.1401 0.1298 0.1265 0.1236 0.1224 0.1217 0.1215 0.1215 0.1215 0.1214 0.1211 0.1208 0.1207 0.1207 

[TRAIN] Epoch[4](43/1500); Loss: 0.067931; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1426 0.0843 0.0768 0.0686 0.0636 0.0610 0.0599 0.0595 0.0592 0.0589 0.0587 0.0587 0.0586 0.0588 0.0587 0.0589 

[TRAIN] Epoch[4](44/1500); Loss: 0.152070; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2661 0.2006 0.1468 0.1388 0.1400 0.1400 0.1395 0.1390 0.1390 0.1393 0.1397 0.1401 0.1405 0.1409 0.1412 0.1416 

[TRAIN] Epoch[4](45/1500); Loss: 0.087381; Backpropagation: 0.0943 sec; Batch: 0.4295 sec
0.1161 0.1108 0.0997 0.0909 0.0867 0.0841 0.0829 0.0823 0.0819 0.0814 0.0809 0.0805 0.0802 0.0800 0.0798 0.0798 

[TRAIN] Epoch[4](46/1500); Loss: 0.065629; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.0891 0.0792 0.0728 0.0698 0.0669 0.0639 0.0619 0.0612 0.0610 0.0608 0.0606 0.0605 0.0605 0.0605 0.0606 0.0606 

[TRAIN] Epoch[4](47/1500); Loss: 0.089804; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1418 0.1339 0.1071 0.0987 0.0918 0.0819 0.0791 0.0781 0.0782 0.0781 0.0780 0.0778 0.0778 0.0782 0.0782 0.0782 

[TRAIN] Epoch[4](48/1500); Loss: 0.160326; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2368 0.1823 0.1695 0.1603 0.1593 0.1569 0.1550 0.1529 0.1517 0.1507 0.1498 0.1491 0.1484 0.1479 0.1475 0.1470 

[TRAIN] Epoch[4](49/1500); Loss: 0.056838; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.0968 0.0858 0.0678 0.0733 0.0647 0.0549 0.0497 0.0475 0.0464 0.0459 0.0458 0.0459 0.0459 0.0460 0.0463 0.0466 

[TRAIN] Epoch[4](50/1500); Loss: 0.118566; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1609 0.1294 0.1244 0.1187 0.1169 0.1155 0.1145 0.1139 0.1134 0.1131 0.1129 0.1128 0.1126 0.1126 0.1126 0.1128 

[TRAIN] Epoch[4](51/1500); Loss: 0.063376; Backpropagation: 0.0943 sec; Batch: 0.4289 sec
0.1527 0.0728 0.0684 0.0635 0.0610 0.0574 0.0549 0.0539 0.0535 0.0535 0.0535 0.0535 0.0536 0.0537 0.0540 0.0541 

[TRAIN] Epoch[4](52/1500); Loss: 0.130174; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1764 0.1438 0.1353 0.1316 0.1289 0.1269 0.1259 0.1252 0.1246 0.1241 0.1237 0.1235 0.1233 0.1232 0.1233 0.1232 

[TRAIN] Epoch[4](53/1500); Loss: 0.105816; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1518 0.1260 0.1194 0.1132 0.1091 0.1041 0.1007 0.0986 0.0974 0.0969 0.0966 0.0962 0.0959 0.0958 0.0957 0.0956 

[TRAIN] Epoch[4](54/1500); Loss: 0.067082; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1138 0.0840 0.0739 0.0715 0.0697 0.0655 0.0624 0.0607 0.0598 0.0593 0.0590 0.0588 0.0587 0.0587 0.0588 0.0589 

[TRAIN] Epoch[4](55/1500); Loss: 0.045644; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.0828 0.0690 0.0563 0.0505 0.0463 0.0424 0.0400 0.0385 0.0379 0.0377 0.0377 0.0378 0.0379 0.0382 0.0385 0.0387 

[TRAIN] Epoch[4](56/1500); Loss: 0.151849; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1827 0.1635 0.1596 0.1555 0.1524 0.1501 0.1488 0.1480 0.1474 0.1469 0.1466 0.1462 0.1459 0.1456 0.1453 0.1452 

[TRAIN] Epoch[4](57/1500); Loss: 0.128753; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.2013 0.1553 0.1375 0.1336 0.1301 0.1255 0.1227 0.1204 0.1189 0.1177 0.1168 0.1164 0.1161 0.1160 0.1158 0.1158 

[TRAIN] Epoch[4](58/1500); Loss: 0.128661; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1917 0.1539 0.1336 0.1268 0.1242 0.1223 0.1214 0.1208 0.1205 0.1204 0.1204 0.1204 0.1204 0.1205 0.1206 0.1208 

[TRAIN] Epoch[4](59/1500); Loss: 0.031650; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.0546 0.0463 0.0350 0.0308 0.0285 0.0270 0.0265 0.0265 0.0267 0.0271 0.0278 0.0284 0.0291 0.0298 0.0307 0.0317 

[TRAIN] Epoch[4](60/1500); Loss: 0.100107; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1473 0.1268 0.1099 0.1054 0.1005 0.0966 0.0944 0.0928 0.0919 0.0915 0.0912 0.0910 0.0908 0.0907 0.0906 0.0906 

[TRAIN] Epoch[4](61/1500); Loss: 0.048862; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1031 0.0652 0.0643 0.0513 0.0481 0.0438 0.0416 0.0406 0.0404 0.0402 0.0403 0.0403 0.0404 0.0405 0.0407 0.0410 

[TRAIN] Epoch[4](62/1500); Loss: 0.088023; Backpropagation: 0.0957 sec; Batch: 0.4313 sec
0.1738 0.1085 0.1009 0.0963 0.0938 0.0886 0.0839 0.0798 0.0766 0.0743 0.0729 0.0722 0.0718 0.0717 0.0715 0.0717 

[TRAIN] Epoch[4](63/1500); Loss: 0.072549; Backpropagation: 0.0943 sec; Batch: 0.4290 sec
0.2350 0.1126 0.0706 0.0634 0.0599 0.0579 0.0565 0.0554 0.0551 0.0550 0.0550 0.0554 0.0560 0.0566 0.0577 0.0588 

[TRAIN] Epoch[4](64/1500); Loss: 0.069479; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1709 0.0853 0.0748 0.0712 0.0675 0.0635 0.0606 0.0588 0.0577 0.0573 0.0570 0.0571 0.0571 0.0573 0.0575 0.0579 

[TRAIN] Epoch[4](65/1500); Loss: 0.108182; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1562 0.1186 0.1129 0.1109 0.1099 0.1060 0.1032 0.1020 0.1014 0.1013 0.1010 0.1011 0.1012 0.1015 0.1017 0.1020 

[TRAIN] Epoch[4](66/1500); Loss: 0.097234; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1618 0.1153 0.1146 0.1070 0.1036 0.0978 0.0929 0.0895 0.0871 0.0856 0.0846 0.0839 0.0835 0.0831 0.0828 0.0827 

[TRAIN] Epoch[4](67/1500); Loss: 0.136928; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2580 0.1607 0.1404 0.1349 0.1358 0.1317 0.1281 0.1253 0.1236 0.1228 0.1222 0.1217 0.1216 0.1214 0.1213 0.1214 

[TRAIN] Epoch[4](68/1500); Loss: 0.067423; Backpropagation: 0.0959 sec; Batch: 0.4315 sec
0.3484 0.1422 0.0408 0.0314 0.0762 0.0680 0.0606 0.0499 0.0418 0.0360 0.0325 0.0305 0.0299 0.0296 0.0305 0.0305 

[TRAIN] Epoch[4](69/1500); Loss: 0.118775; Backpropagation: 0.0942 sec; Batch: 0.4292 sec
0.2022 0.1524 0.1188 0.1093 0.1078 0.1073 0.1076 0.1079 0.1084 0.1091 0.1099 0.1106 0.1112 0.1120 0.1127 0.1132 

[TRAIN] Epoch[4](70/1500); Loss: 0.125294; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1669 0.1394 0.1314 0.1268 0.1236 0.1215 0.1206 0.1198 0.1193 0.1193 0.1192 0.1191 0.1192 0.1193 0.1194 0.1196 

[TRAIN] Epoch[4](71/1500); Loss: 0.059800; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.0844 0.0793 0.0619 0.0590 0.0567 0.0556 0.0552 0.0551 0.0550 0.0552 0.0556 0.0560 0.0563 0.0567 0.0571 0.0576 

[TRAIN] Epoch[4](72/1500); Loss: 0.079696; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.3508 0.1441 0.0632 0.0523 0.0868 0.0759 0.0671 0.0568 0.0508 0.0471 0.0461 0.0460 0.0465 0.0466 0.0472 0.0477 

[TRAIN] Epoch[4](73/1500); Loss: 0.070477; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2795 0.1280 0.0649 0.0569 0.0636 0.0603 0.0565 0.0523 0.0488 0.0465 0.0453 0.0448 0.0448 0.0449 0.0451 0.0454 

[TRAIN] Epoch[4](74/1500); Loss: 0.077188; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.1563 0.0913 0.0814 0.0788 0.0745 0.0717 0.0701 0.0690 0.0682 0.0677 0.0675 0.0675 0.0675 0.0676 0.0678 0.0681 

[TRAIN] Epoch[4](75/1500); Loss: 0.093704; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1491 0.1010 0.0920 0.0999 0.0954 0.0925 0.0898 0.0882 0.0873 0.0868 0.0865 0.0862 0.0862 0.0861 0.0861 0.0862 

[TRAIN] Epoch[4](76/1500); Loss: 0.067991; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1589 0.0846 0.0709 0.0681 0.0639 0.0612 0.0595 0.0585 0.0581 0.0578 0.0579 0.0577 0.0577 0.0576 0.0577 0.0578 

[TRAIN] Epoch[4](77/1500); Loss: 0.069668; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.2839 0.1799 0.0731 0.0474 0.0442 0.0439 0.0438 0.0433 0.0432 0.0433 0.0437 0.0439 0.0444 0.0449 0.0456 0.0462 

[TRAIN] Epoch[4](78/1500); Loss: 0.075351; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1070 0.0878 0.0932 0.0883 0.0823 0.0748 0.0703 0.0676 0.0665 0.0662 0.0662 0.0662 0.0666 0.0670 0.0674 0.0682 

[TRAIN] Epoch[4](79/1500); Loss: 0.132518; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1660 0.1457 0.1424 0.1372 0.1338 0.1306 0.1291 0.1281 0.1273 0.1267 0.1263 0.1260 0.1256 0.1254 0.1251 0.1250 

[TRAIN] Epoch[4](80/1500); Loss: 0.113235; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2214 0.1497 0.1166 0.1058 0.1042 0.1033 0.1024 0.1017 0.1011 0.1009 0.1008 0.1008 0.1007 0.1008 0.1007 0.1007 

[TRAIN] Epoch[4](81/1500); Loss: 0.075163; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.1606 0.1099 0.0807 0.0716 0.0698 0.0673 0.0653 0.0647 0.0642 0.0641 0.0642 0.0641 0.0639 0.0640 0.0641 0.0641 

[TRAIN] Epoch[4](82/1500); Loss: 0.055717; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.0698 0.0666 0.0644 0.0579 0.0554 0.0534 0.0526 0.0522 0.0521 0.0521 0.0521 0.0522 0.0522 0.0525 0.0529 0.0531 

[TRAIN] Epoch[4](83/1500); Loss: 0.056752; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2728 0.1663 0.0555 0.0353 0.0334 0.0321 0.0312 0.0308 0.0305 0.0306 0.0308 0.0309 0.0312 0.0317 0.0323 0.0328 

[TRAIN] Epoch[4](84/1500); Loss: 0.071622; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1876 0.1189 0.0783 0.0666 0.0636 0.0607 0.0591 0.0580 0.0573 0.0568 0.0567 0.0565 0.0564 0.0564 0.0565 0.0565 

[TRAIN] Epoch[4](85/1500); Loss: 0.061584; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.0903 0.0845 0.0718 0.0651 0.0614 0.0579 0.0566 0.0560 0.0554 0.0551 0.0550 0.0548 0.0549 0.0551 0.0555 0.0557 

[TRAIN] Epoch[4](86/1500); Loss: 0.078248; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1334 0.1078 0.0897 0.0789 0.0749 0.0722 0.0707 0.0699 0.0695 0.0694 0.0693 0.0693 0.0692 0.0691 0.0692 0.0693 

[TRAIN] Epoch[4](87/1500); Loss: 0.086192; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1159 0.1032 0.0929 0.0886 0.0858 0.0830 0.0818 0.0813 0.0811 0.0809 0.0808 0.0807 0.0807 0.0807 0.0808 0.0809 

[TRAIN] Epoch[4](88/1500); Loss: 0.058251; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1580 0.0638 0.0540 0.0591 0.0534 0.0511 0.0499 0.0494 0.0495 0.0491 0.0492 0.0490 0.0492 0.0491 0.0492 0.0490 

[TRAIN] Epoch[4](89/1500); Loss: 0.110821; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1281 0.1209 0.1135 0.1115 0.1105 0.1095 0.1088 0.1084 0.1080 0.1079 0.1077 0.1076 0.1076 0.1076 0.1077 0.1078 

[TRAIN] Epoch[4](90/1500); Loss: 0.081485; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.0992 0.0888 0.0862 0.0819 0.0806 0.0796 0.0791 0.0791 0.0789 0.0789 0.0787 0.0786 0.0786 0.0785 0.0785 0.0786 

[TRAIN] Epoch[4](91/1500); Loss: 0.091624; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1295 0.1125 0.1043 0.0951 0.0902 0.0869 0.0858 0.0851 0.0847 0.0843 0.0843 0.0844 0.0844 0.0845 0.0848 0.0852 

[TRAIN] Epoch[4](92/1500); Loss: 0.057933; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1998 0.0711 0.0568 0.0499 0.0490 0.0465 0.0454 0.0450 0.0449 0.0450 0.0450 0.0452 0.0453 0.0456 0.0460 0.0464 

[TRAIN] Epoch[4](93/1500); Loss: 0.060510; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.1028 0.0813 0.0703 0.0633 0.0608 0.0584 0.0559 0.0547 0.0540 0.0535 0.0530 0.0527 0.0522 0.0519 0.0518 0.0515 

[TRAIN] Epoch[4](94/1500); Loss: 0.097674; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1350 0.1118 0.1015 0.0980 0.0960 0.0945 0.0936 0.0932 0.0929 0.0927 0.0925 0.0924 0.0923 0.0922 0.0922 0.0921 

[TRAIN] Epoch[4](95/1500); Loss: 0.104911; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2600 0.1611 0.1099 0.0919 0.0898 0.0887 0.0878 0.0873 0.0871 0.0874 0.0875 0.0876 0.0877 0.0880 0.0882 0.0885 

[TRAIN] Epoch[4](96/1500); Loss: 0.140169; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1741 0.1454 0.1460 0.1424 0.1409 0.1383 0.1366 0.1358 0.1353 0.1354 0.1353 0.1353 0.1354 0.1353 0.1355 0.1355 

[TRAIN] Epoch[4](97/1500); Loss: 0.078745; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2095 0.1241 0.0795 0.0698 0.0702 0.0686 0.0670 0.0653 0.0645 0.0639 0.0635 0.0631 0.0629 0.0627 0.0626 0.0626 

[TRAIN] Epoch[4](98/1500); Loss: 0.123564; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1722 0.1372 0.1261 0.1218 0.1201 0.1193 0.1189 0.1186 0.1185 0.1184 0.1182 0.1180 0.1177 0.1176 0.1173 0.1172 

[TRAIN] Epoch[4](99/1500); Loss: 0.090267; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1982 0.1437 0.0879 0.0820 0.0802 0.0791 0.0783 0.0778 0.0775 0.0772 0.0770 0.0769 0.0771 0.0770 0.0771 0.0773 

[TRAIN] Epoch[4](100/1500); Loss: 0.067895; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1210 0.1025 0.0791 0.0707 0.0659 0.0614 0.0601 0.0594 0.0590 0.0588 0.0585 0.0583 0.0579 0.0579 0.0579 0.0580 

[TRAIN] Epoch[4](101/1500); Loss: 0.070758; Backpropagation: 0.0938 sec; Batch: 0.4694 sec
0.2360 0.1222 0.0647 0.0614 0.0585 0.0564 0.0550 0.0538 0.0534 0.0532 0.0529 0.0530 0.0529 0.0529 0.0529 0.0530 

[TRAIN] Epoch[4](102/1500); Loss: 0.065775; Backpropagation: 0.0932 sec; Batch: 0.4696 sec
0.0931 0.0840 0.0704 0.0672 0.0647 0.0631 0.0623 0.0617 0.0613 0.0611 0.0608 0.0607 0.0606 0.0606 0.0605 0.0604 

[TRAIN] Epoch[4](103/1500); Loss: 0.116466; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1959 0.1404 0.1184 0.1114 0.1098 0.1091 0.1086 0.1084 0.1083 0.1079 0.1077 0.1076 0.1075 0.1074 0.1075 0.1075 

[TRAIN] Epoch[4](104/1500); Loss: 0.069403; Backpropagation: 0.0934 sec; Batch: 0.4289 sec
0.0982 0.0888 0.0786 0.0719 0.0678 0.0651 0.0645 0.0642 0.0640 0.0639 0.0639 0.0639 0.0639 0.0639 0.0639 0.0641 

[TRAIN] Epoch[4](105/1500); Loss: 0.079351; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1094 0.1014 0.0866 0.0808 0.0771 0.0751 0.0744 0.0741 0.0739 0.0737 0.0738 0.0739 0.0738 0.0738 0.0739 0.0740 

[TRAIN] Epoch[4](106/1500); Loss: 0.062452; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2119 0.0902 0.0844 0.0680 0.0610 0.0512 0.0472 0.0446 0.0436 0.0429 0.0427 0.0422 0.0422 0.0422 0.0424 0.0426 

[TRAIN] Epoch[4](107/1500); Loss: 0.064258; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2843 0.1203 0.0585 0.0479 0.0584 0.0494 0.0451 0.0410 0.0407 0.0401 0.0401 0.0399 0.0403 0.0404 0.0407 0.0409 

[TRAIN] Epoch[4](108/1500); Loss: 0.096705; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1571 0.1148 0.1016 0.0940 0.0925 0.0914 0.0905 0.0900 0.0897 0.0895 0.0893 0.0893 0.0892 0.0893 0.0894 0.0896 

[TRAIN] Epoch[4](109/1500); Loss: 0.084215; Backpropagation: 0.0943 sec; Batch: 0.4281 sec
0.2461 0.1386 0.0756 0.0758 0.0766 0.0720 0.0699 0.0680 0.0667 0.0662 0.0657 0.0655 0.0653 0.0651 0.0651 0.0652 

[TRAIN] Epoch[4](110/1500); Loss: 0.076651; Backpropagation: 0.0939 sec; Batch: 0.4274 sec
0.1416 0.1055 0.0808 0.0761 0.0732 0.0709 0.0693 0.0685 0.0680 0.0678 0.0676 0.0674 0.0674 0.0673 0.0675 0.0675 

[TRAIN] Epoch[4](111/1500); Loss: 0.084529; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1717 0.1135 0.0873 0.0803 0.0778 0.0764 0.0754 0.0750 0.0747 0.0745 0.0743 0.0741 0.0742 0.0743 0.0744 0.0746 

[TRAIN] Epoch[4](112/1500); Loss: 0.113256; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1845 0.1341 0.1156 0.1101 0.1087 0.1070 0.1060 0.1055 0.1053 0.1052 0.1049 0.1049 0.1050 0.1050 0.1051 0.1052 

[TRAIN] Epoch[4](113/1500); Loss: 0.062655; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1522 0.0920 0.0679 0.0591 0.0556 0.0541 0.0533 0.0527 0.0522 0.0521 0.0519 0.0520 0.0520 0.0519 0.0518 0.0517 

[TRAIN] Epoch[4](114/1500); Loss: 0.106364; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1833 0.1273 0.1137 0.1057 0.1025 0.1008 0.0995 0.0984 0.0976 0.0971 0.0966 0.0963 0.0960 0.0958 0.0957 0.0956 

[TRAIN] Epoch[4](115/1500); Loss: 0.054763; Backpropagation: 0.0939 sec; Batch: 0.4421 sec
0.1352 0.0792 0.0542 0.0639 0.0555 0.0514 0.0476 0.0451 0.0439 0.0434 0.0430 0.0428 0.0428 0.0427 0.0427 0.0428 

[TRAIN] Epoch[4](116/1500); Loss: 0.055871; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1942 0.1008 0.0561 0.0478 0.0448 0.0430 0.0420 0.0413 0.0410 0.0408 0.0408 0.0407 0.0402 0.0401 0.0401 0.0402 

[TRAIN] Epoch[4](117/1500); Loss: 0.124174; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2641 0.1701 0.1337 0.1192 0.1182 0.1152 0.1125 0.1101 0.1083 0.1071 0.1062 0.1056 0.1050 0.1041 0.1038 0.1037 

[TRAIN] Epoch[4](118/1500); Loss: 0.030024; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.0617 0.0539 0.0395 0.0320 0.0291 0.0260 0.0241 0.0236 0.0231 0.0230 0.0232 0.0236 0.0241 0.0241 0.0243 0.0250 

[TRAIN] Epoch[4](119/1500); Loss: 0.092436; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2138 0.1257 0.0906 0.0852 0.0840 0.0820 0.0811 0.0804 0.0800 0.0798 0.0797 0.0796 0.0794 0.0793 0.0792 0.0793 

[TRAIN] Epoch[4](120/1500); Loss: 0.068039; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1240 0.0978 0.0752 0.0673 0.0642 0.0631 0.0620 0.0612 0.0606 0.0602 0.0598 0.0595 0.0590 0.0586 0.0582 0.0579 

[TRAIN] Epoch[4](121/1500); Loss: 0.078234; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1608 0.0996 0.0845 0.0812 0.0751 0.0716 0.0701 0.0692 0.0686 0.0681 0.0677 0.0673 0.0670 0.0670 0.0670 0.0669 

[TRAIN] Epoch[4](122/1500); Loss: 0.100638; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1790 0.1247 0.1094 0.0986 0.0959 0.0940 0.0926 0.0917 0.0913 0.0909 0.0908 0.0905 0.0903 0.0902 0.0902 0.0903 

[TRAIN] Epoch[4](123/1500); Loss: 0.100173; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.1818 0.1163 0.1009 0.0967 0.0950 0.0943 0.0938 0.0932 0.0928 0.0924 0.0919 0.0915 0.0912 0.0906 0.0903 0.0900 

[TRAIN] Epoch[4](124/1500); Loss: 0.119268; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2504 0.2051 0.1536 0.1302 0.1077 0.0986 0.0973 0.0966 0.0963 0.0960 0.0960 0.0960 0.0959 0.0961 0.0963 0.0963 

[TRAIN] Epoch[4](125/1500); Loss: 0.101393; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1268 0.1158 0.1080 0.1024 0.1005 0.0982 0.0974 0.0970 0.0969 0.0970 0.0970 0.0969 0.0970 0.0971 0.0972 0.0972 

[TRAIN] Epoch[4](126/1500); Loss: 0.113406; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1987 0.1555 0.1167 0.1113 0.1086 0.1066 0.1049 0.1036 0.1027 0.1018 0.1012 0.1008 0.1006 0.1004 0.1004 0.1005 

[TRAIN] Epoch[4](127/1500); Loss: 0.067520; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1339 0.0799 0.0763 0.0681 0.0655 0.0620 0.0602 0.0596 0.0592 0.0592 0.0592 0.0593 0.0592 0.0593 0.0596 0.0600 

[TRAIN] Epoch[4](128/1500); Loss: 0.058750; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.0900 0.0691 0.0687 0.0610 0.0587 0.0568 0.0556 0.0549 0.0543 0.0537 0.0533 0.0531 0.0529 0.0528 0.0526 0.0524 

[TRAIN] Epoch[4](129/1500); Loss: 0.093458; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1784 0.1044 0.0943 0.0899 0.0882 0.0870 0.0861 0.0856 0.0853 0.0851 0.0851 0.0850 0.0851 0.0851 0.0853 0.0854 

[TRAIN] Epoch[4](130/1500); Loss: 0.120671; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1817 0.1539 0.1238 0.1192 0.1166 0.1149 0.1136 0.1129 0.1124 0.1121 0.1119 0.1118 0.1116 0.1115 0.1115 0.1113 

[TRAIN] Epoch[4](131/1500); Loss: 0.083110; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1160 0.1050 0.0906 0.0872 0.0839 0.0818 0.0801 0.0787 0.0778 0.0770 0.0764 0.0758 0.0753 0.0750 0.0747 0.0745 

[TRAIN] Epoch[4](132/1500); Loss: 0.104479; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1845 0.1224 0.1077 0.0995 0.0993 0.0978 0.0971 0.0968 0.0966 0.0963 0.0958 0.0959 0.0957 0.0955 0.0953 0.0954 

[TRAIN] Epoch[4](133/1500); Loss: 0.131434; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1814 0.1417 0.1331 0.1293 0.1286 0.1278 0.1270 0.1265 0.1261 0.1259 0.1258 0.1257 0.1258 0.1259 0.1260 0.1262 

[TRAIN] Epoch[4](134/1500); Loss: 0.101644; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2302 0.1457 0.1058 0.1006 0.0938 0.0915 0.0888 0.0867 0.0863 0.0859 0.0856 0.0853 0.0851 0.0850 0.0850 0.0850 

[TRAIN] Epoch[4](135/1500); Loss: 0.083402; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1565 0.1107 0.0876 0.0811 0.0785 0.0768 0.0757 0.0750 0.0746 0.0744 0.0741 0.0740 0.0740 0.0739 0.0737 0.0737 

[TRAIN] Epoch[4](136/1500); Loss: 0.118423; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1759 0.1345 0.1242 0.1160 0.1147 0.1132 0.1125 0.1121 0.1119 0.1116 0.1113 0.1112 0.1113 0.1113 0.1115 0.1116 

[TRAIN] Epoch[4](137/1500); Loss: 0.046199; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.0651 0.0646 0.0499 0.0467 0.0448 0.0433 0.0424 0.0423 0.0422 0.0422 0.0421 0.0424 0.0425 0.0428 0.0429 0.0432 

[TRAIN] Epoch[4](138/1500); Loss: 0.058923; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1070 0.0999 0.0687 0.0637 0.0595 0.0524 0.0512 0.0503 0.0500 0.0494 0.0490 0.0487 0.0485 0.0484 0.0481 0.0481 

[TRAIN] Epoch[4](139/1500); Loss: 0.067011; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.0766 0.0793 0.0708 0.0667 0.0652 0.0640 0.0637 0.0636 0.0636 0.0640 0.0644 0.0649 0.0654 0.0660 0.0667 0.0673 

[TRAIN] Epoch[4](140/1500); Loss: 0.084902; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1722 0.1077 0.0916 0.0815 0.0781 0.0768 0.0759 0.0756 0.0753 0.0750 0.0748 0.0747 0.0748 0.0748 0.0747 0.0748 

[TRAIN] Epoch[4](141/1500); Loss: 0.088009; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1663 0.1046 0.0933 0.0883 0.0841 0.0818 0.0808 0.0802 0.0799 0.0793 0.0788 0.0785 0.0785 0.0781 0.0778 0.0777 

[TRAIN] Epoch[4](142/1500); Loss: 0.125014; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2052 0.1466 0.1225 0.1204 0.1191 0.1183 0.1178 0.1175 0.1171 0.1167 0.1165 0.1164 0.1165 0.1164 0.1164 0.1166 

[TRAIN] Epoch[4](143/1500); Loss: 0.051946; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1375 0.0904 0.0555 0.0597 0.0479 0.0438 0.0424 0.0413 0.0404 0.0398 0.0393 0.0391 0.0388 0.0386 0.0384 0.0384 

[TRAIN] Epoch[4](144/1500); Loss: 0.081304; Backpropagation: 0.0938 sec; Batch: 0.4288 sec
0.1636 0.1145 0.0910 0.0798 0.0764 0.0737 0.0724 0.0714 0.0709 0.0704 0.0701 0.0696 0.0695 0.0694 0.0691 0.0688 

[TRAIN] Epoch[4](145/1500); Loss: 0.033121; Backpropagation: 0.0941 sec; Batch: 0.4278 sec
0.1031 0.0688 0.0330 0.0264 0.0253 0.0243 0.0242 0.0241 0.0244 0.0243 0.0244 0.0247 0.0250 0.0254 0.0260 0.0266 

[TRAIN] Epoch[4](146/1500); Loss: 0.077302; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1319 0.1134 0.0842 0.0827 0.0753 0.0713 0.0696 0.0688 0.0681 0.0679 0.0677 0.0674 0.0672 0.0672 0.0671 0.0670 

[TRAIN] Epoch[4](147/1500); Loss: 0.064743; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2626 0.1566 0.0548 0.0453 0.0471 0.0451 0.0435 0.0420 0.0420 0.0414 0.0417 0.0420 0.0424 0.0427 0.0431 0.0436 

[TRAIN] Epoch[4](148/1500); Loss: 0.107581; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1614 0.1289 0.1101 0.1050 0.1036 0.1022 0.1018 0.1017 0.1014 0.1011 0.1010 0.1007 0.1005 0.1005 0.1007 0.1007 

[TRAIN] Epoch[4](149/1500); Loss: 0.155975; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2239 0.1707 0.1585 0.1538 0.1529 0.1520 0.1511 0.1500 0.1492 0.1487 0.1481 0.1478 0.1476 0.1472 0.1471 0.1469 

[TRAIN] Epoch[4](150/1500); Loss: 0.054124; Backpropagation: 0.0959 sec; Batch: 0.4315 sec
0.2535 0.1383 0.0552 0.0328 0.0352 0.0335 0.0335 0.0324 0.0307 0.0309 0.0307 0.0309 0.0313 0.0317 0.0323 0.0330 

[TRAIN] Epoch[4](151/1500); Loss: 0.092038; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1622 0.0932 0.0927 0.0891 0.0873 0.0867 0.0865 0.0865 0.0864 0.0859 0.0856 0.0858 0.0860 0.0861 0.0861 0.0863 

[TRAIN] Epoch[4](152/1500); Loss: 0.048422; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1754 0.0785 0.0449 0.0547 0.0410 0.0375 0.0358 0.0350 0.0343 0.0338 0.0337 0.0337 0.0337 0.0340 0.0341 0.0345 

[TRAIN] Epoch[4](153/1500); Loss: 0.069568; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1251 0.0989 0.0777 0.0703 0.0666 0.0642 0.0628 0.0619 0.0614 0.0609 0.0605 0.0605 0.0604 0.0605 0.0606 0.0609 

[TRAIN] Epoch[4](154/1500); Loss: 0.084503; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2292 0.1349 0.0899 0.0826 0.0753 0.0716 0.0690 0.0675 0.0669 0.0665 0.0664 0.0663 0.0665 0.0663 0.0665 0.0667 

[TRAIN] Epoch[4](155/1500); Loss: 0.092864; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1936 0.1284 0.0982 0.0878 0.0852 0.0835 0.0820 0.0814 0.0809 0.0807 0.0806 0.0804 0.0803 0.0806 0.0810 0.0812 

[TRAIN] Epoch[4](156/1500); Loss: 0.086304; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1757 0.1118 0.0922 0.0898 0.0828 0.0791 0.0775 0.0765 0.0757 0.0750 0.0745 0.0742 0.0742 0.0739 0.0739 0.0739 

[TRAIN] Epoch[4](157/1500); Loss: 0.084224; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1869 0.1312 0.0930 0.0794 0.0788 0.0765 0.0742 0.0733 0.0721 0.0713 0.0701 0.0693 0.0684 0.0682 0.0675 0.0674 

[TRAIN] Epoch[4](158/1500); Loss: 0.116735; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1336 0.1252 0.1281 0.1216 0.1187 0.1156 0.1141 0.1132 0.1126 0.1120 0.1118 0.1119 0.1121 0.1124 0.1123 0.1124 

[TRAIN] Epoch[4](159/1500); Loss: 0.116071; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2013 0.1440 0.1321 0.1152 0.1127 0.1100 0.1078 0.1066 0.1056 0.1047 0.1040 0.1034 0.1030 0.1024 0.1023 0.1020 

[TRAIN] Epoch[4](160/1500); Loss: 0.065406; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1302 0.0866 0.1000 0.0702 0.0570 0.0558 0.0552 0.0547 0.0543 0.0542 0.0542 0.0542 0.0545 0.0548 0.0550 0.0554 

[TRAIN] Epoch[4](161/1500); Loss: 0.125579; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2074 0.1428 0.1354 0.1209 0.1176 0.1170 0.1166 0.1167 0.1165 0.1166 0.1166 0.1168 0.1167 0.1171 0.1172 0.1173 

[TRAIN] Epoch[4](162/1500); Loss: 0.061250; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.1090 0.0978 0.0738 0.0604 0.0572 0.0553 0.0540 0.0533 0.0525 0.0521 0.0521 0.0519 0.0522 0.0524 0.0527 0.0533 

[TRAIN] Epoch[4](163/1500); Loss: 0.063081; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.0942 0.0847 0.0749 0.0653 0.0614 0.0594 0.0582 0.0573 0.0571 0.0566 0.0567 0.0566 0.0567 0.0566 0.0567 0.0569 

[TRAIN] Epoch[4](164/1500); Loss: 0.086859; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2139 0.1250 0.0913 0.0797 0.0766 0.0745 0.0735 0.0731 0.0727 0.0728 0.0724 0.0727 0.0725 0.0731 0.0727 0.0732 

[TRAIN] Epoch[4](165/1500); Loss: 0.067913; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2262 0.1089 0.0628 0.0592 0.0578 0.0551 0.0538 0.0527 0.0518 0.0519 0.0515 0.0507 0.0509 0.0509 0.0510 0.0513 

[TRAIN] Epoch[4](166/1500); Loss: 0.100506; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1391 0.1129 0.1050 0.0992 0.0984 0.0967 0.0960 0.0956 0.0954 0.0953 0.0952 0.0954 0.0955 0.0958 0.0962 0.0963 

[TRAIN] Epoch[4](167/1500); Loss: 0.097394; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1356 0.1134 0.1019 0.0974 0.0951 0.0939 0.0929 0.0926 0.0922 0.0921 0.0917 0.0917 0.0915 0.0918 0.0921 0.0924 

[TRAIN] Epoch[4](168/1500); Loss: 0.148659; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2121 0.1804 0.1508 0.1461 0.1428 0.1427 0.1414 0.1412 0.1407 0.1408 0.1402 0.1403 0.1397 0.1397 0.1400 0.1398 

[TRAIN] Epoch[4](169/1500); Loss: 0.067908; Backpropagation: 0.0940 sec; Batch: 0.4276 sec
0.0991 0.0816 0.0861 0.0701 0.0656 0.0623 0.0625 0.0622 0.0622 0.0620 0.0620 0.0620 0.0619 0.0624 0.0621 0.0623 

[TRAIN] Epoch[4](170/1500); Loss: 0.080003; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1121 0.1061 0.0908 0.0841 0.0767 0.0752 0.0739 0.0737 0.0733 0.0735 0.0732 0.0734 0.0732 0.0735 0.0735 0.0739 

[TRAIN] Epoch[4](171/1500); Loss: 0.053681; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.0914 0.0787 0.0573 0.0510 0.0498 0.0493 0.0479 0.0476 0.0476 0.0478 0.0479 0.0484 0.0481 0.0484 0.0487 0.0490 

[TRAIN] Epoch[4](172/1500); Loss: 0.107807; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1462 0.1193 0.1202 0.1083 0.1051 0.1037 0.1031 0.1026 0.1022 0.1015 0.1018 0.1018 0.1018 0.1020 0.1025 0.1029 

[TRAIN] Epoch[4](173/1500); Loss: 0.098441; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1247 0.1042 0.1047 0.0981 0.0973 0.0957 0.0948 0.0947 0.0947 0.0948 0.0948 0.0948 0.0949 0.0953 0.0956 0.0958 

[TRAIN] Epoch[4](174/1500); Loss: 0.135682; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1787 0.1515 0.1380 0.1343 0.1333 0.1324 0.1318 0.1316 0.1310 0.1306 0.1301 0.1300 0.1299 0.1294 0.1293 0.1291 

[TRAIN] Epoch[4](175/1500); Loss: 0.150233; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1733 0.1601 0.1509 0.1491 0.1481 0.1479 0.1472 0.1473 0.1470 0.1472 0.1471 0.1473 0.1475 0.1478 0.1478 0.1481 

[TRAIN] Epoch[4](176/1500); Loss: 0.088995; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.0973 0.0917 0.0944 0.0870 0.0869 0.0867 0.0871 0.0873 0.0874 0.0875 0.0880 0.0880 0.0882 0.0884 0.0888 0.0891 

[TRAIN] Epoch[4](177/1500); Loss: 0.043017; Backpropagation: 0.0938 sec; Batch: 0.4291 sec
0.0651 0.0492 0.0565 0.0419 0.0405 0.0388 0.0384 0.0382 0.0386 0.0389 0.0393 0.0395 0.0400 0.0407 0.0411 0.0416 

[TRAIN] Epoch[4](178/1500); Loss: 0.075742; Backpropagation: 0.0938 sec; Batch: 0.4292 sec
0.1170 0.0957 0.0931 0.0764 0.0732 0.0694 0.0689 0.0687 0.0685 0.0687 0.0687 0.0685 0.0685 0.0685 0.0688 0.0693 

[TRAIN] Epoch[4](179/1500); Loss: 0.078269; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1905 0.1045 0.0980 0.0836 0.0759 0.0681 0.0649 0.0630 0.0623 0.0622 0.0623 0.0625 0.0628 0.0633 0.0639 0.0645 

[TRAIN] Epoch[4](180/1500); Loss: 0.115749; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1452 0.1283 0.1211 0.1159 0.1141 0.1130 0.1123 0.1119 0.1114 0.1112 0.1113 0.1112 0.1113 0.1113 0.1113 0.1113 

[TRAIN] Epoch[4](181/1500); Loss: 0.041442; Backpropagation: 0.0935 sec; Batch: 0.4288 sec
0.0642 0.0569 0.0702 0.0475 0.0399 0.0365 0.0350 0.0346 0.0342 0.0343 0.0342 0.0344 0.0348 0.0351 0.0355 0.0359 

[TRAIN] Epoch[4](182/1500); Loss: 0.098468; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1441 0.1053 0.0980 0.0988 0.0957 0.0946 0.0942 0.0942 0.0943 0.0944 0.0940 0.0935 0.0935 0.0937 0.0936 0.0935 

[TRAIN] Epoch[4](183/1500); Loss: 0.081984; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1226 0.1000 0.1095 0.0861 0.0763 0.0765 0.0750 0.0749 0.0744 0.0741 0.0737 0.0739 0.0737 0.0737 0.0737 0.0736 

[TRAIN] Epoch[4](184/1500); Loss: 0.066460; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1706 0.0846 0.0788 0.0857 0.0669 0.0582 0.0536 0.0514 0.0504 0.0505 0.0508 0.0511 0.0516 0.0523 0.0531 0.0538 

[TRAIN] Epoch[4](185/1500); Loss: 0.065381; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1127 0.0926 0.0799 0.0681 0.0626 0.0582 0.0572 0.0568 0.0565 0.0566 0.0567 0.0570 0.0572 0.0574 0.0580 0.0587 

[TRAIN] Epoch[4](186/1500); Loss: 0.116327; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1719 0.1341 0.1187 0.1144 0.1128 0.1120 0.1110 0.1105 0.1102 0.1101 0.1099 0.1097 0.1093 0.1093 0.1089 0.1085 

[TRAIN] Epoch[4](187/1500); Loss: 0.091583; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1383 0.1209 0.0950 0.0898 0.0873 0.0860 0.0851 0.0847 0.0844 0.0843 0.0843 0.0846 0.0849 0.0848 0.0851 0.0856 

[TRAIN] Epoch[4](188/1500); Loss: 0.057083; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.0917 0.0840 0.0670 0.0626 0.0548 0.0516 0.0501 0.0497 0.0496 0.0495 0.0495 0.0498 0.0501 0.0505 0.0510 0.0518 

[TRAIN] Epoch[4](189/1500); Loss: 0.123946; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1701 0.1319 0.1264 0.1250 0.1217 0.1204 0.1197 0.1191 0.1188 0.1185 0.1186 0.1188 0.1184 0.1186 0.1185 0.1188 

[TRAIN] Epoch[4](190/1500); Loss: 0.070941; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.2418 0.1329 0.1179 0.0597 0.0562 0.0530 0.0500 0.0484 0.0471 0.0462 0.0462 0.0463 0.0465 0.0473 0.0476 0.0480 

[TRAIN] Epoch[4](191/1500); Loss: 0.100277; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1520 0.1189 0.1117 0.1078 0.1006 0.0962 0.0942 0.0929 0.0924 0.0920 0.0914 0.0910 0.0907 0.0907 0.0910 0.0911 

[TRAIN] Epoch[4](192/1500); Loss: 0.075802; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1036 0.0945 0.0862 0.0776 0.0757 0.0727 0.0715 0.0711 0.0704 0.0700 0.0698 0.0696 0.0698 0.0699 0.0701 0.0703 

[TRAIN] Epoch[4](193/1500); Loss: 0.099831; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1431 0.1106 0.1244 0.1053 0.0973 0.0950 0.0935 0.0930 0.0924 0.0921 0.0919 0.0918 0.0917 0.0915 0.0916 0.0919 

[TRAIN] Epoch[4](194/1500); Loss: 0.065778; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1181 0.0904 0.0718 0.0671 0.0641 0.0604 0.0590 0.0583 0.0580 0.0576 0.0577 0.0576 0.0578 0.0579 0.0583 0.0584 

[TRAIN] Epoch[4](195/1500); Loss: 0.071502; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2753 0.1296 0.0772 0.0622 0.0577 0.0529 0.0495 0.0483 0.0482 0.0485 0.0486 0.0487 0.0487 0.0491 0.0495 0.0500 

[TRAIN] Epoch[4](196/1500); Loss: 0.084164; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.2461 0.1685 0.0788 0.0792 0.0695 0.0658 0.0644 0.0642 0.0634 0.0633 0.0632 0.0636 0.0636 0.0641 0.0642 0.0647 

[TRAIN] Epoch[4](197/1500); Loss: 0.110402; Backpropagation: 0.0960 sec; Batch: 0.4312 sec
0.1605 0.1257 0.1159 0.1088 0.1061 0.1045 0.1041 0.1034 0.1036 0.1039 0.1044 0.1043 0.1047 0.1049 0.1057 0.1057 

[TRAIN] Epoch[4](198/1500); Loss: 0.064468; Backpropagation: 0.0961 sec; Batch: 0.4312 sec
0.1011 0.0841 0.0745 0.0703 0.0633 0.0602 0.0586 0.0581 0.0579 0.0578 0.0575 0.0574 0.0573 0.0575 0.0577 0.0580 

[TRAIN] Epoch[4](199/1500); Loss: 0.072282; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1070 0.1018 0.0850 0.0770 0.0715 0.0680 0.0659 0.0645 0.0638 0.0633 0.0633 0.0637 0.0641 0.0651 0.0658 0.0668 

[TRAIN] Epoch[4](200/1500); Loss: 0.038833; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.0694 0.0404 0.0832 0.0500 0.0347 0.0325 0.0309 0.0307 0.0306 0.0307 0.0310 0.0311 0.0312 0.0312 0.0317 0.0320 

[TRAIN] Epoch[4](201/1500); Loss: 0.073476; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1542 0.0864 0.0767 0.0800 0.0693 0.0661 0.0645 0.0643 0.0638 0.0639 0.0638 0.0639 0.0641 0.0646 0.0648 0.0652 

[TRAIN] Epoch[4](202/1500); Loss: 0.058197; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.0843 0.0698 0.0677 0.0599 0.0573 0.0556 0.0542 0.0540 0.0534 0.0535 0.0533 0.0534 0.0535 0.0537 0.0537 0.0539 

[TRAIN] Epoch[4](203/1500); Loss: 0.083664; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1396 0.1115 0.0979 0.0891 0.0864 0.0804 0.0772 0.0757 0.0747 0.0740 0.0734 0.0728 0.0721 0.0718 0.0715 0.0707 

[TRAIN] Epoch[4](204/1500); Loss: 0.083698; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.2067 0.1045 0.0903 0.0850 0.0759 0.0721 0.0700 0.0696 0.0698 0.0697 0.0700 0.0701 0.0706 0.0713 0.0715 0.0720 

[TRAIN] Epoch[4](205/1500); Loss: 0.061387; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1053 0.0772 0.0704 0.0643 0.0590 0.0577 0.0557 0.0553 0.0547 0.0548 0.0543 0.0544 0.0546 0.0548 0.0548 0.0551 

[TRAIN] Epoch[4](206/1500); Loss: 0.105111; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1374 0.1141 0.1103 0.1045 0.1030 0.1027 0.1014 0.1009 0.1002 0.1005 0.1007 0.1008 0.1014 0.1010 0.1012 0.1015 

[TRAIN] Epoch[4](207/1500); Loss: 0.088879; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1848 0.0901 0.0889 0.0921 0.0841 0.0820 0.0800 0.0791 0.0792 0.0795 0.0799 0.0798 0.0799 0.0804 0.0812 0.0811 

[TRAIN] Epoch[4](208/1500); Loss: 0.075599; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.0985 0.0817 0.0807 0.0762 0.0751 0.0740 0.0729 0.0729 0.0724 0.0724 0.0717 0.0722 0.0724 0.0725 0.0722 0.0719 

[TRAIN] Epoch[4](209/1500); Loss: 0.137379; Backpropagation: 0.0942 sec; Batch: 0.4289 sec
0.2066 0.1428 0.1476 0.1441 0.1399 0.1354 0.1310 0.1302 0.1284 0.1278 0.1277 0.1273 0.1273 0.1271 0.1273 0.1275 

[TRAIN] Epoch[4](210/1500); Loss: 0.061649; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.0881 0.0914 0.0683 0.0651 0.0627 0.0612 0.0595 0.0579 0.0570 0.0560 0.0548 0.0541 0.0536 0.0527 0.0521 0.0520 

[TRAIN] Epoch[4](211/1500); Loss: 0.071861; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1153 0.1004 0.1037 0.0836 0.0655 0.0620 0.0605 0.0605 0.0596 0.0607 0.0612 0.0620 0.0625 0.0638 0.0639 0.0647 

[TRAIN] Epoch[4](212/1500); Loss: 0.087640; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1526 0.1045 0.1720 0.1222 0.0790 0.0720 0.0703 0.0693 0.0686 0.0690 0.0700 0.0693 0.0697 0.0712 0.0709 0.0718 

[TRAIN] Epoch[4](213/1500); Loss: 0.074217; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1502 0.0834 0.1136 0.0880 0.0662 0.0626 0.0613 0.0616 0.0613 0.0614 0.0617 0.0619 0.0631 0.0630 0.0641 0.0642 

[TRAIN] Epoch[4](214/1500); Loss: 0.129670; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.1496 0.1565 0.1368 0.1318 0.1301 0.1276 0.1252 0.1245 0.1244 0.1247 0.1244 0.1248 0.1235 0.1236 0.1239 0.1235 

[TRAIN] Epoch[4](215/1500); Loss: 0.085756; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2369 0.0794 0.1518 0.1348 0.1089 0.0714 0.0658 0.0645 0.0582 0.0572 0.0581 0.0558 0.0567 0.0574 0.0572 0.0579 

[TRAIN] Epoch[4](216/1500); Loss: 0.114929; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1443 0.1500 0.1243 0.1183 0.1135 0.1117 0.1104 0.1088 0.1084 0.1083 0.1073 0.1065 0.1069 0.1073 0.1068 0.1062 

[TRAIN] Epoch[4](217/1500); Loss: 0.071043; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1069 0.1091 0.1209 0.0909 0.0661 0.0604 0.0586 0.0572 0.0579 0.0585 0.0576 0.0592 0.0596 0.0574 0.0577 0.0585 

[TRAIN] Epoch[4](218/1500); Loss: 0.073467; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1195 0.0951 0.0732 0.0686 0.0702 0.0649 0.0644 0.0647 0.0650 0.0646 0.0668 0.0686 0.0695 0.0713 0.0738 0.0754 

[TRAIN] Epoch[4](219/1500); Loss: 0.127349; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1844 0.1525 0.1556 0.1314 0.1214 0.1196 0.1174 0.1180 0.1180 0.1174 0.1160 0.1166 0.1168 0.1175 0.1178 0.1173 

[TRAIN] Epoch[4](220/1500); Loss: 0.087559; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1019 0.1053 0.1248 0.1027 0.0843 0.0834 0.0824 0.0816 0.0804 0.0797 0.0794 0.0795 0.0793 0.0785 0.0786 0.0793 

[TRAIN] Epoch[4](221/1500); Loss: 0.101559; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.1357 0.1558 0.1639 0.1237 0.0923 0.0909 0.0905 0.0874 0.0858 0.0863 0.0850 0.0864 0.0846 0.0849 0.0862 0.0856 

[TRAIN] Epoch[4](222/1500); Loss: 0.118344; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1439 0.1461 0.1287 0.1241 0.1174 0.1146 0.1137 0.1131 0.1117 0.1115 0.1114 0.1112 0.1118 0.1125 0.1110 0.1109 

[TRAIN] Epoch[4](223/1500); Loss: 0.051515; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.0802 0.0935 0.0534 0.0508 0.0499 0.0436 0.0442 0.0456 0.0435 0.0447 0.0450 0.0443 0.0452 0.0467 0.0462 0.0474 

[TRAIN] Epoch[4](224/1500); Loss: 0.137255; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1693 0.1479 0.1439 0.1437 0.1392 0.1366 0.1335 0.1323 0.1313 0.1317 0.1307 0.1304 0.1311 0.1318 0.1311 0.1314 

[TRAIN] Epoch[4](225/1500); Loss: 0.071768; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.0774 0.1123 0.1592 0.1378 0.1093 0.0853 0.0647 0.0520 0.0472 0.0446 0.0448 0.0437 0.0432 0.0426 0.0419 0.0423 

[TRAIN] Epoch[4](226/1500); Loss: 0.139961; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1522 0.1739 0.2309 0.1829 0.1391 0.1328 0.1291 0.1265 0.1246 0.1231 0.1226 0.1210 0.1206 0.1203 0.1199 0.1200 

[TRAIN] Epoch[4](227/1500); Loss: 0.073122; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.0926 0.1065 0.1459 0.1149 0.0840 0.0688 0.0622 0.0586 0.0550 0.0545 0.0554 0.0543 0.0531 0.0537 0.0546 0.0559 

[TRAIN] Epoch[4](228/1500); Loss: 0.108924; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1580 0.1319 0.1169 0.1107 0.1082 0.1045 0.1022 0.0997 0.1016 0.1006 0.1012 0.1010 0.1005 0.1023 0.1008 0.1026 

[TRAIN] Epoch[4](229/1500); Loss: 0.058610; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1267 0.0881 0.0910 0.0861 0.0666 0.0516 0.0467 0.0434 0.0407 0.0400 0.0412 0.0411 0.0418 0.0433 0.0442 0.0452 

[TRAIN] Epoch[4](230/1500); Loss: 0.102462; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2422 0.1523 0.1162 0.0981 0.1000 0.0880 0.0866 0.0870 0.0838 0.0844 0.0844 0.0829 0.0836 0.0833 0.0829 0.0837 

[TRAIN] Epoch[4](231/1500); Loss: 0.139632; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2169 0.1941 0.1798 0.1553 0.1418 0.1350 0.1273 0.1252 0.1230 0.1215 0.1214 0.1192 0.1192 0.1185 0.1179 0.1179 

[TRAIN] Epoch[4](232/1500); Loss: 0.112286; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1540 0.1294 0.1170 0.1136 0.1165 0.1118 0.1089 0.1084 0.1081 0.1066 0.1051 0.1041 0.1043 0.1032 0.1028 0.1028 

[TRAIN] Epoch[4](233/1500); Loss: 0.077721; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.0995 0.0948 0.0992 0.0925 0.0765 0.0725 0.0704 0.0702 0.0695 0.0684 0.0694 0.0717 0.0713 0.0713 0.0723 0.0739 

[TRAIN] Epoch[4](234/1500); Loss: 0.124497; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1866 0.1573 0.1207 0.1230 0.1210 0.1201 0.1176 0.1170 0.1164 0.1161 0.1156 0.1159 0.1164 0.1160 0.1157 0.1167 

[TRAIN] Epoch[4](235/1500); Loss: 0.147887; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1926 0.1814 0.2006 0.1752 0.1524 0.1449 0.1411 0.1370 0.1344 0.1318 0.1308 0.1291 0.1289 0.1289 0.1287 0.1284 

[TRAIN] Epoch[4](236/1500); Loss: 0.114345; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1287 0.1496 0.1287 0.1236 0.1170 0.1129 0.1120 0.1082 0.1077 0.1076 0.1066 0.1055 0.1064 0.1059 0.1051 0.1039 

[TRAIN] Epoch[4](237/1500); Loss: 0.070479; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1112 0.0927 0.1188 0.1078 0.0812 0.0704 0.0593 0.0568 0.0554 0.0533 0.0513 0.0535 0.0539 0.0530 0.0536 0.0554 

[TRAIN] Epoch[4](238/1500); Loss: 0.138287; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1804 0.1854 0.1815 0.1624 0.1459 0.1371 0.1303 0.1254 0.1244 0.1231 0.1217 0.1204 0.1198 0.1188 0.1182 0.1178 

[TRAIN] Epoch[4](239/1500); Loss: 0.133665; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1628 0.1746 0.2201 0.1903 0.1631 0.1454 0.1299 0.1215 0.1127 0.1074 0.1046 0.1045 0.1016 0.0995 0.1005 0.1000 

[TRAIN] Epoch[4](240/1500); Loss: 0.123164; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.2451 0.1392 0.1341 0.1357 0.1339 0.1218 0.1168 0.1128 0.1099 0.1076 0.1054 0.1032 0.1030 0.1009 0.1011 0.1001 

[TRAIN] Epoch[4](241/1500); Loss: 0.154675; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1354 0.1866 0.2532 0.2204 0.1991 0.1843 0.1701 0.1523 0.1403 0.1304 0.1261 0.1220 0.1184 0.1138 0.1119 0.1104 

[TRAIN] Epoch[4](242/1500); Loss: 0.103713; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2063 0.1612 0.1016 0.1131 0.1080 0.0967 0.0925 0.0916 0.0880 0.0864 0.0869 0.0856 0.0861 0.0848 0.0845 0.0861 

[TRAIN] Epoch[4](243/1500); Loss: 0.129804; Backpropagation: 0.0956 sec; Batch: 0.4299 sec
0.2161 0.1984 0.1617 0.1434 0.1199 0.1199 0.1179 0.1143 0.1142 0.1120 0.1105 0.1101 0.1096 0.1094 0.1099 0.1096 

[TRAIN] Epoch[4](244/1500); Loss: 0.128097; Backpropagation: 0.0941 sec; Batch: 0.4320 sec
0.2055 0.1836 0.1568 0.1419 0.1268 0.1214 0.1164 0.1136 0.1131 0.1100 0.1104 0.1095 0.1103 0.1100 0.1096 0.1107 

[TRAIN] Epoch[4](245/1500); Loss: 0.155911; Backpropagation: 0.0935 sec; Batch: 0.4287 sec
0.3704 0.2614 0.1778 0.1566 0.1525 0.1429 0.1360 0.1296 0.1250 0.1239 0.1221 0.1209 0.1201 0.1194 0.1178 0.1180 

[TRAIN] Epoch[4](246/1500); Loss: 0.114746; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2171 0.1598 0.1304 0.1218 0.1143 0.1064 0.1045 0.1017 0.0995 0.0984 0.0979 0.0975 0.0970 0.0964 0.0965 0.0968 

[TRAIN] Epoch[4](247/1500); Loss: 0.092217; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1200 0.1615 0.1863 0.1425 0.0886 0.0720 0.0712 0.0709 0.0692 0.0693 0.0698 0.0695 0.0703 0.0720 0.0699 0.0726 

[TRAIN] Epoch[4](248/1500); Loss: 0.177944; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.2209 0.2252 0.2356 0.2065 0.1880 0.1790 0.1735 0.1686 0.1643 0.1602 0.1579 0.1561 0.1549 0.1527 0.1519 0.1518 

[TRAIN] Epoch[4](249/1500); Loss: 0.167741; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.2545 0.1888 0.2252 0.1859 0.1586 0.1617 0.1599 0.1506 0.1515 0.1520 0.1478 0.1489 0.1509 0.1486 0.1493 0.1495 

[TRAIN] Epoch[4](250/1500); Loss: 0.099837; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1654 0.1684 0.1715 0.1300 0.0965 0.0826 0.0814 0.0790 0.0754 0.0765 0.0759 0.0775 0.0775 0.0784 0.0798 0.0817 

[TRAIN] Epoch[4](251/1500); Loss: 0.099567; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.3536 0.2098 0.1257 0.0887 0.0829 0.0741 0.0687 0.0671 0.0655 0.0656 0.0643 0.0650 0.0660 0.0651 0.0654 0.0656 

[TRAIN] Epoch[4](252/1500); Loss: 0.113686; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1961 0.2080 0.1542 0.1203 0.1062 0.1006 0.0947 0.0932 0.0930 0.0925 0.0931 0.0926 0.0927 0.0936 0.0936 0.0945 

[TRAIN] Epoch[4](253/1500); Loss: 0.105712; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1533 0.1493 0.1297 0.1130 0.1017 0.0978 0.0956 0.0939 0.0935 0.0930 0.0935 0.0939 0.0946 0.0953 0.0962 0.0972 

[TRAIN] Epoch[4](254/1500); Loss: 0.133905; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2629 0.2185 0.1847 0.1463 0.1299 0.1177 0.1138 0.1107 0.1094 0.1076 0.1075 0.1072 0.1064 0.1065 0.1067 0.1069 

[TRAIN] Epoch[4](255/1500); Loss: 0.143637; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2567 0.2328 0.2363 0.1925 0.1578 0.1388 0.1291 0.1216 0.1131 0.1091 0.1059 0.1030 0.1018 0.1007 0.0999 0.0992 

[TRAIN] Epoch[4](256/1500); Loss: 0.244774; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.4527 0.4237 0.3771 0.3228 0.2864 0.2550 0.2327 0.2135 0.1970 0.1825 0.1754 0.1689 0.1634 0.1590 0.1551 0.1513 

[TRAIN] Epoch[4](257/1500); Loss: 0.143490; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.3725 0.3535 0.2632 0.1968 0.1558 0.1287 0.1135 0.0977 0.0880 0.0799 0.0765 0.0740 0.0734 0.0735 0.0744 0.0742 

[TRAIN] Epoch[4](258/1500); Loss: 0.117231; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.2673 0.2025 0.1266 0.1086 0.1048 0.1022 0.0996 0.0974 0.0959 0.0953 0.0952 0.0961 0.0955 0.0956 0.0964 0.0966 

[TRAIN] Epoch[4](259/1500); Loss: 0.108524; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2729 0.2130 0.1162 0.1007 0.0936 0.0909 0.0901 0.0857 0.0843 0.0835 0.0828 0.0833 0.0839 0.0843 0.0850 0.0861 

[TRAIN] Epoch[4](260/1500); Loss: 0.137759; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1764 0.2003 0.2247 0.1898 0.1628 0.1420 0.1286 0.1178 0.1123 0.1102 0.1086 0.1071 0.1061 0.1056 0.1059 0.1058 

[TRAIN] Epoch[4](261/1500); Loss: 0.238688; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.4183 0.4518 0.4332 0.3621 0.3041 0.2643 0.2307 0.2058 0.1821 0.1626 0.1487 0.1400 0.1336 0.1296 0.1270 0.1250 

[TRAIN] Epoch[4](262/1500); Loss: 0.090078; Backpropagation: 0.0935 sec; Batch: 0.4296 sec
0.1264 0.1344 0.1640 0.1328 0.1079 0.0923 0.0818 0.0730 0.0680 0.0659 0.0650 0.0649 0.0653 0.0658 0.0665 0.0673 

[TRAIN] Epoch[4](263/1500); Loss: 0.162451; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2414 0.2564 0.2660 0.2176 0.1826 0.1591 0.1473 0.1367 0.1308 0.1258 0.1237 0.1220 0.1224 0.1220 0.1229 0.1225 

[TRAIN] Epoch[4](264/1500); Loss: 0.139334; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2491 0.1789 0.2567 0.1890 0.1423 0.1303 0.1251 0.1163 0.1089 0.1056 0.1025 0.1032 0.1038 0.1049 0.1060 0.1066 

[TRAIN] Epoch[4](265/1500); Loss: 0.127086; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1935 0.2021 0.2478 0.1886 0.1416 0.1125 0.1033 0.0984 0.0954 0.0940 0.0933 0.0917 0.0918 0.0925 0.0933 0.0936 

[TRAIN] Epoch[4](266/1500); Loss: 0.196855; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2377 0.2083 0.2838 0.2306 0.1961 0.1899 0.1896 0.1858 0.1833 0.1826 0.1799 0.1784 0.1775 0.1765 0.1750 0.1747 

[TRAIN] Epoch[4](267/1500); Loss: 0.184413; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.3070 0.2926 0.2766 0.2213 0.1915 0.1740 0.1650 0.1594 0.1548 0.1497 0.1478 0.1447 0.1430 0.1418 0.1414 0.1400 

[TRAIN] Epoch[4](268/1500); Loss: 0.105497; Backpropagation: 0.0937 sec; Batch: 0.4288 sec
0.2807 0.2402 0.1627 0.1085 0.0935 0.0837 0.0751 0.0724 0.0709 0.0703 0.0699 0.0707 0.0712 0.0717 0.0728 0.0737 

[TRAIN] Epoch[4](269/1500); Loss: 0.150406; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.3199 0.2702 0.2133 0.1672 0.1490 0.1391 0.1287 0.1207 0.1179 0.1140 0.1124 0.1112 0.1105 0.1109 0.1110 0.1108 

[TRAIN] Epoch[4](270/1500); Loss: 0.110529; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2687 0.2365 0.1831 0.1359 0.1097 0.0982 0.0876 0.0801 0.0754 0.0720 0.0709 0.0697 0.0696 0.0701 0.0702 0.0708 

[TRAIN] Epoch[4](271/1500); Loss: 0.156484; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.3310 0.3367 0.2769 0.2079 0.1598 0.1336 0.1211 0.1137 0.1082 0.1061 0.1033 0.1008 0.1021 0.1016 0.1006 0.1003 

[TRAIN] Epoch[4](272/1500); Loss: 0.158548; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.2011 0.2155 0.2641 0.2221 0.1834 0.1610 0.1474 0.1373 0.1315 0.1281 0.1263 0.1251 0.1237 0.1236 0.1232 0.1232 

[TRAIN] Epoch[4](273/1500); Loss: 0.133619; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1689 0.1813 0.1928 0.1577 0.1337 0.1243 0.1210 0.1183 0.1173 0.1175 0.1176 0.1177 0.1175 0.1172 0.1178 0.1174 

[TRAIN] Epoch[4](274/1500); Loss: 0.125300; Backpropagation: 0.0981 sec; Batch: 0.4325 sec
0.1608 0.1981 0.2385 0.1920 0.1473 0.1189 0.1054 0.0999 0.0956 0.0948 0.0932 0.0932 0.0920 0.0920 0.0916 0.0916 

[TRAIN] Epoch[4](275/1500); Loss: 0.166131; Backpropagation: 0.0960 sec; Batch: 0.4308 sec
0.2621 0.2517 0.2338 0.1919 0.1686 0.1552 0.1461 0.1417 0.1400 0.1385 0.1380 0.1381 0.1376 0.1377 0.1382 0.1387 

[TRAIN] Epoch[4](276/1500); Loss: 0.142262; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1929 0.1723 0.1489 0.1408 0.1376 0.1366 0.1350 0.1343 0.1344 0.1345 0.1343 0.1339 0.1345 0.1347 0.1358 0.1357 

[TRAIN] Epoch[4](277/1500); Loss: 0.141773; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.2293 0.2069 0.1655 0.1463 0.1395 0.1331 0.1292 0.1268 0.1249 0.1243 0.1235 0.1239 0.1240 0.1239 0.1238 0.1235 

[TRAIN] Epoch[4](278/1500); Loss: 0.112115; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1921 0.1832 0.1878 0.1367 0.1041 0.0954 0.0931 0.0905 0.0897 0.0889 0.0883 0.0879 0.0881 0.0891 0.0889 0.0900 

[TRAIN] Epoch[4](279/1500); Loss: 0.161282; Backpropagation: 0.0933 sec; Batch: 0.4701 sec
0.3056 0.2492 0.1973 0.1607 0.1499 0.1457 0.1418 0.1386 0.1376 0.1369 0.1366 0.1358 0.1356 0.1359 0.1366 0.1369 

[TRAIN] Epoch[4](280/1500); Loss: 0.083684; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.3007 0.1447 0.0888 0.0726 0.0695 0.0617 0.0610 0.0599 0.0593 0.0586 0.0590 0.0594 0.0594 0.0608 0.0612 0.0623 

[TRAIN] Epoch[4](281/1500); Loss: 0.114262; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.2402 0.1700 0.1233 0.1090 0.1039 0.1013 0.0988 0.0971 0.0971 0.0970 0.0972 0.0977 0.0985 0.0986 0.0990 0.0995 

[TRAIN] Epoch[4](282/1500); Loss: 0.074372; Backpropagation: 0.0933 sec; Batch: 0.4295 sec
0.1164 0.1036 0.0764 0.0696 0.0684 0.0675 0.0672 0.0672 0.0680 0.0677 0.0685 0.0688 0.0691 0.0699 0.0706 0.0711 

[TRAIN] Epoch[4](283/1500); Loss: 0.115511; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2080 0.1643 0.1259 0.1094 0.1053 0.1040 0.1029 0.1031 0.1029 0.1029 0.1024 0.1021 0.1030 0.1034 0.1039 0.1047 

[TRAIN] Epoch[4](284/1500); Loss: 0.070257; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2328 0.0949 0.0667 0.0599 0.0603 0.0569 0.0550 0.0549 0.0539 0.0549 0.0541 0.0554 0.0550 0.0562 0.0558 0.0573 

[TRAIN] Epoch[4](285/1500); Loss: 0.070439; Backpropagation: 0.0943 sec; Batch: 0.4302 sec
0.1307 0.0959 0.0714 0.0674 0.0676 0.0642 0.0625 0.0620 0.0616 0.0623 0.0618 0.0626 0.0629 0.0641 0.0640 0.0658 

[TRAIN] Epoch[4](286/1500); Loss: 0.077524; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1791 0.1016 0.0783 0.0755 0.0750 0.0687 0.0659 0.0657 0.0651 0.0647 0.0660 0.0655 0.0668 0.0664 0.0674 0.0687 

[TRAIN] Epoch[4](287/1500); Loss: 0.121307; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2626 0.1806 0.1376 0.1200 0.1120 0.1087 0.1064 0.1046 0.1031 0.1025 0.1015 0.1014 0.1003 0.0997 0.1000 0.0999 

[TRAIN] Epoch[4](288/1500); Loss: 0.073291; Backpropagation: 0.0938 sec; Batch: 0.4273 sec
0.2370 0.1013 0.0690 0.0671 0.0602 0.0585 0.0576 0.0572 0.0566 0.0570 0.0575 0.0578 0.0581 0.0593 0.0591 0.0594 

[TRAIN] Epoch[4](289/1500); Loss: 0.128659; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.2874 0.1658 0.1249 0.1191 0.1155 0.1142 0.1129 0.1127 0.1121 0.1125 0.1124 0.1126 0.1131 0.1138 0.1145 0.1149 

[TRAIN] Epoch[4](290/1500); Loss: 0.093356; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2338 0.1131 0.0926 0.0859 0.0823 0.0808 0.0798 0.0796 0.0796 0.0797 0.0798 0.0800 0.0807 0.0815 0.0821 0.0825 

[TRAIN] Epoch[4](291/1500); Loss: 0.048111; Backpropagation: 0.0958 sec; Batch: 0.4309 sec
0.1086 0.0791 0.0518 0.0423 0.0449 0.0435 0.0419 0.0400 0.0394 0.0388 0.0385 0.0388 0.0394 0.0402 0.0410 0.0417 

[TRAIN] Epoch[4](292/1500); Loss: 0.122602; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2530 0.1724 0.1218 0.1110 0.1052 0.1050 0.1049 0.1062 0.1071 0.1081 0.1089 0.1098 0.1108 0.1116 0.1124 0.1132 

[TRAIN] Epoch[4](293/1500); Loss: 0.108192; Backpropagation: 0.0936 sec; Batch: 0.4272 sec
0.2038 0.1356 0.1072 0.0964 0.0913 0.0901 0.0918 0.0941 0.0960 0.0978 0.0997 0.1017 0.1037 0.1054 0.1072 0.1092 

[TRAIN] Epoch[4](294/1500); Loss: 0.104333; Backpropagation: 0.0932 sec; Batch: 0.4263 sec
0.2618 0.1434 0.0863 0.0833 0.0797 0.0806 0.0830 0.0858 0.0885 0.0907 0.0928 0.0945 0.0966 0.0987 0.1008 0.1028 

[TRAIN] Epoch[4](295/1500); Loss: 0.088045; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1520 0.0878 0.0701 0.0671 0.0702 0.0724 0.0751 0.0782 0.0816 0.0849 0.0878 0.0909 0.0936 0.0962 0.0989 0.1019 

[TRAIN] Epoch[4](296/1500); Loss: 0.193284; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2699 0.2120 0.1768 0.1737 0.1723 0.1736 0.1763 0.1796 0.1830 0.1862 0.1896 0.1933 0.1965 0.1999 0.2032 0.2066 

[TRAIN] Epoch[4](297/1500); Loss: 0.121571; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1138 0.0986 0.1043 0.1075 0.1127 0.1146 0.1171 0.1196 0.1222 0.1247 0.1276 0.1305 0.1335 0.1364 0.1395 0.1425 

[TRAIN] Epoch[4](298/1500); Loss: 0.141252; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2113 0.1486 0.1226 0.1226 0.1249 0.1264 0.1286 0.1315 0.1342 0.1366 0.1391 0.1417 0.1441 0.1467 0.1493 0.1518 

[TRAIN] Epoch[4](299/1500); Loss: 0.169154; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.4069 0.2193 0.1391 0.1186 0.1276 0.1298 0.1349 0.1399 0.1450 0.1500 0.1546 0.1594 0.1638 0.1680 0.1722 0.1772 

[TRAIN] Epoch[4](300/1500); Loss: 0.149849; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1376 0.1325 0.1333 0.1358 0.1401 0.1419 0.1441 0.1467 0.1494 0.1522 0.1553 0.1586 0.1621 0.1658 0.1693 0.1727 

[TRAIN] Epoch[4](301/1500); Loss: 0.100248; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1258 0.1053 0.0798 0.0785 0.0824 0.0849 0.0881 0.0917 0.0957 0.0995 0.1030 0.1067 0.1102 0.1138 0.1176 0.1210 

[TRAIN] Epoch[4](302/1500); Loss: 0.107079; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2229 0.1228 0.0888 0.0801 0.0828 0.0854 0.0886 0.0922 0.0953 0.0985 0.1016 0.1046 0.1078 0.1109 0.1139 0.1170 

[TRAIN] Epoch[4](303/1500); Loss: 0.149295; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.3529 0.2173 0.1489 0.1247 0.1231 0.1231 0.1236 0.1249 0.1263 0.1278 0.1293 0.1305 0.1319 0.1334 0.1349 0.1362 

[TRAIN] Epoch[4](304/1500); Loss: 0.148621; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2169 0.1552 0.1377 0.1366 0.1375 0.1383 0.1395 0.1412 0.1427 0.1440 0.1451 0.1463 0.1474 0.1485 0.1498 0.1511 

[TRAIN] Epoch[4](305/1500); Loss: 0.125535; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2349 0.1570 0.1300 0.1146 0.1074 0.1056 0.1058 0.1076 0.1101 0.1129 0.1154 0.1175 0.1195 0.1214 0.1235 0.1253 

[TRAIN] Epoch[4](306/1500); Loss: 0.131706; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.4596 0.2805 0.1642 0.0852 0.0786 0.0801 0.0848 0.0883 0.0916 0.0940 0.0961 0.0979 0.0994 0.1009 0.1023 0.1037 

[TRAIN] Epoch[4](307/1500); Loss: 0.072785; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1017 0.0869 0.0723 0.0590 0.0654 0.0663 0.0675 0.0686 0.0696 0.0703 0.0710 0.0717 0.0724 0.0731 0.0740 0.0748 

[TRAIN] Epoch[4](308/1500); Loss: 0.147289; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.3033 0.1911 0.1449 0.1291 0.1280 0.1282 0.1290 0.1301 0.1312 0.1321 0.1330 0.1338 0.1347 0.1354 0.1360 0.1367 

[TRAIN] Epoch[4](309/1500); Loss: 0.138040; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.4751 0.2543 0.1374 0.0903 0.0929 0.0946 0.0966 0.0996 0.1025 0.1050 0.1065 0.1080 0.1094 0.1108 0.1121 0.1135 

[TRAIN] Epoch[4](310/1500); Loss: 0.112009; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1685 0.1312 0.1012 0.1020 0.1038 0.1043 0.1050 0.1058 0.1064 0.1071 0.1077 0.1084 0.1091 0.1098 0.1106 0.1114 

[TRAIN] Epoch[4](311/1500); Loss: 0.084965; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1788 0.1105 0.0796 0.0720 0.0725 0.0727 0.0735 0.0743 0.0752 0.0760 0.0769 0.0777 0.0786 0.0795 0.0804 0.0812 

[TRAIN] Epoch[4](312/1500); Loss: 0.117995; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.2362 0.1306 0.0973 0.0979 0.1039 0.1044 0.1059 0.1073 0.1087 0.1099 0.1113 0.1124 0.1136 0.1148 0.1161 0.1174 

[TRAIN] Epoch[4](313/1500); Loss: 0.125100; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.3531 0.1928 0.1343 0.1024 0.1001 0.0996 0.0995 0.1000 0.1006 0.1012 0.1018 0.1023 0.1027 0.1032 0.1037 0.1043 

[TRAIN] Epoch[4](314/1500); Loss: 0.124532; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.3504 0.2059 0.1500 0.0997 0.0980 0.0968 0.0973 0.0979 0.0984 0.0987 0.0991 0.0993 0.0996 0.1000 0.1004 0.1009 

[TRAIN] Epoch[4](315/1500); Loss: 0.128468; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2729 0.1633 0.1121 0.1101 0.1101 0.1104 0.1111 0.1122 0.1137 0.1152 0.1166 0.1182 0.1198 0.1215 0.1232 0.1249 

[TRAIN] Epoch[4](316/1500); Loss: 0.169632; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.3135 0.2376 0.1849 0.1614 0.1549 0.1527 0.1512 0.1507 0.1504 0.1505 0.1505 0.1506 0.1508 0.1511 0.1515 0.1518 

[TRAIN] Epoch[4](317/1500); Loss: 0.109637; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2745 0.1819 0.1273 0.1005 0.0950 0.0909 0.0887 0.0876 0.0871 0.0874 0.0877 0.0881 0.0885 0.0891 0.0897 0.0902 

[TRAIN] Epoch[4](318/1500); Loss: 0.085604; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1796 0.1402 0.0978 0.0805 0.0736 0.0717 0.0711 0.0712 0.0713 0.0717 0.0721 0.0726 0.0731 0.0737 0.0743 0.0751 

[TRAIN] Epoch[4](319/1500); Loss: 0.116314; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2407 0.1755 0.1316 0.1113 0.1047 0.1017 0.1002 0.0995 0.0992 0.0991 0.0991 0.0992 0.0994 0.0996 0.0999 0.1002 

[TRAIN] Epoch[4](320/1500); Loss: 0.133157; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1951 0.1607 0.1392 0.1316 0.1290 0.1276 0.1266 0.1257 0.1251 0.1247 0.1244 0.1243 0.1241 0.1241 0.1241 0.1243 

[TRAIN] Epoch[4](321/1500); Loss: 0.055486; Backpropagation: 0.0958 sec; Batch: 0.4302 sec
0.0840 0.0444 0.1019 0.0555 0.0472 0.0473 0.0479 0.0483 0.0487 0.0493 0.0499 0.0507 0.0516 0.0526 0.0537 0.0547 

[TRAIN] Epoch[4](322/1500); Loss: 0.077121; Backpropagation: 0.0941 sec; Batch: 0.4278 sec
0.2198 0.1122 0.0738 0.0643 0.0614 0.0607 0.0606 0.0608 0.0613 0.0619 0.0629 0.0640 0.0653 0.0667 0.0683 0.0699 

[TRAIN] Epoch[4](323/1500); Loss: 0.135011; Backpropagation: 0.0937 sec; Batch: 0.4300 sec
0.2461 0.1948 0.1414 0.1327 0.1273 0.1246 0.1226 0.1208 0.1194 0.1189 0.1185 0.1185 0.1184 0.1185 0.1187 0.1189 

[TRAIN] Epoch[4](324/1500); Loss: 0.051017; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.0476 0.0670 0.0652 0.0486 0.0514 0.0506 0.0497 0.0488 0.0481 0.0479 0.0478 0.0479 0.0481 0.0486 0.0491 0.0498 

[TRAIN] Epoch[4](325/1500); Loss: 0.090824; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2709 0.1436 0.1148 0.0812 0.0738 0.0713 0.0698 0.0688 0.0688 0.0688 0.0691 0.0694 0.0699 0.0704 0.0710 0.0716 

[TRAIN] Epoch[4](326/1500); Loss: 0.147409; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2009 0.1867 0.1491 0.1419 0.1406 0.1399 0.1397 0.1395 0.1396 0.1396 0.1397 0.1399 0.1401 0.1403 0.1404 0.1406 

[TRAIN] Epoch[4](327/1500); Loss: 0.097658; Backpropagation: 0.0942 sec; Batch: 0.4279 sec
0.1346 0.1196 0.1067 0.0958 0.0934 0.0927 0.0923 0.0920 0.0918 0.0918 0.0917 0.0918 0.0918 0.0920 0.0921 0.0924 

[TRAIN] Epoch[4](328/1500); Loss: 0.075312; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1425 0.1069 0.0940 0.0746 0.0701 0.0687 0.0674 0.0663 0.0655 0.0649 0.0644 0.0641 0.0639 0.0638 0.0639 0.0640 

[TRAIN] Epoch[4](329/1500); Loss: 0.080691; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1676 0.1154 0.1103 0.0753 0.0696 0.0690 0.0686 0.0684 0.0682 0.0680 0.0680 0.0681 0.0683 0.0684 0.0687 0.0691 

[TRAIN] Epoch[4](330/1500); Loss: 0.064446; Backpropagation: 0.0937 sec; Batch: 0.4427 sec
0.1344 0.0959 0.0786 0.0633 0.0600 0.0586 0.0571 0.0558 0.0547 0.0539 0.0534 0.0531 0.0530 0.0530 0.0532 0.0534 

[TRAIN] Epoch[4](331/1500); Loss: 0.140884; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.1646 0.1530 0.1449 0.1400 0.1401 0.1395 0.1387 0.1381 0.1375 0.1371 0.1368 0.1367 0.1366 0.1367 0.1368 0.1370 

[TRAIN] Epoch[4](332/1500); Loss: 0.156494; Backpropagation: 0.0940 sec; Batch: 0.4302 sec
0.2685 0.2208 0.1685 0.1547 0.1464 0.1441 0.1427 0.1418 0.1411 0.1406 0.1400 0.1396 0.1392 0.1389 0.1387 0.1385 

[TRAIN] Epoch[4](333/1500); Loss: 0.145547; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2817 0.1844 0.1389 0.1315 0.1319 0.1313 0.1314 0.1315 0.1317 0.1320 0.1324 0.1329 0.1334 0.1339 0.1346 0.1352 

[TRAIN] Epoch[4](334/1500); Loss: 0.097858; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2790 0.1345 0.1111 0.0859 0.0816 0.0793 0.0784 0.0779 0.0780 0.0783 0.0786 0.0791 0.0798 0.0805 0.0814 0.0823 

[TRAIN] Epoch[4](335/1500); Loss: 0.145843; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1783 0.1328 0.1345 0.1383 0.1382 0.1388 0.1397 0.1410 0.1425 0.1441 0.1458 0.1477 0.1496 0.1517 0.1541 0.1564 

[TRAIN] Epoch[4](336/1500); Loss: 0.126287; Backpropagation: 0.0933 sec; Batch: 0.4321 sec
0.2779 0.1878 0.1466 0.1232 0.1129 0.1096 0.1082 0.1073 0.1067 0.1062 0.1059 0.1057 0.1056 0.1056 0.1057 0.1058 

[TRAIN] Epoch[4](337/1500); Loss: 0.104504; Backpropagation: 0.0939 sec; Batch: 0.4639 sec
0.2968 0.1791 0.1361 0.0952 0.0842 0.0805 0.0798 0.0796 0.0795 0.0796 0.0797 0.0799 0.0801 0.0803 0.0806 0.0809 

[TRAIN] Epoch[4](338/1500); Loss: 0.119577; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.3918 0.2296 0.1526 0.1014 0.0945 0.0895 0.0884 0.0868 0.0860 0.0855 0.0851 0.0848 0.0845 0.0843 0.0842 0.0842 

[TRAIN] Epoch[4](339/1500); Loss: 0.095683; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2154 0.1434 0.1179 0.0981 0.0885 0.0848 0.0825 0.0799 0.0789 0.0782 0.0777 0.0773 0.0771 0.0770 0.0770 0.0770 

[TRAIN] Epoch[4](340/1500); Loss: 0.095391; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.3337 0.1584 0.0858 0.0628 0.0632 0.0644 0.0656 0.0677 0.0699 0.0722 0.0744 0.0767 0.0791 0.0816 0.0841 0.0867 

[TRAIN] Epoch[4](341/1500); Loss: 0.050076; Backpropagation: 0.0939 sec; Batch: 0.4294 sec
0.0707 0.0780 0.0607 0.0491 0.0478 0.0468 0.0462 0.0455 0.0450 0.0446 0.0443 0.0442 0.0443 0.0444 0.0446 0.0450 

[TRAIN] Epoch[4](342/1500); Loss: 0.130866; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2074 0.1676 0.1378 0.1251 0.1227 0.1221 0.1217 0.1213 0.1211 0.1209 0.1209 0.1209 0.1209 0.1211 0.1212 0.1214 

[TRAIN] Epoch[4](343/1500); Loss: 0.095832; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2754 0.1173 0.0937 0.0865 0.0830 0.0811 0.0804 0.0799 0.0795 0.0792 0.0790 0.0790 0.0792 0.0795 0.0800 0.0807 

[TRAIN] Epoch[4](344/1500); Loss: 0.161143; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2837 0.2258 0.1813 0.1595 0.1518 0.1488 0.1470 0.1449 0.1439 0.1432 0.1425 0.1420 0.1414 0.1411 0.1408 0.1406 

[TRAIN] Epoch[4](345/1500); Loss: 0.136597; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.3400 0.2460 0.1939 0.1412 0.1196 0.1087 0.1055 0.1040 0.1034 0.1032 0.1031 0.1031 0.1032 0.1033 0.1035 0.1037 

[TRAIN] Epoch[4](346/1500); Loss: 0.081480; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1901 0.1111 0.0829 0.0734 0.0723 0.0717 0.0710 0.0705 0.0702 0.0700 0.0699 0.0699 0.0699 0.0700 0.0702 0.0705 

[TRAIN] Epoch[4](347/1500); Loss: 0.083335; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1308 0.1022 0.0818 0.0790 0.0783 0.0782 0.0780 0.0779 0.0779 0.0780 0.0780 0.0782 0.0784 0.0786 0.0789 0.0792 

[TRAIN] Epoch[4](348/1500); Loss: 0.080069; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1570 0.1017 0.0811 0.0744 0.0731 0.0727 0.0721 0.0718 0.0718 0.0718 0.0718 0.0719 0.0721 0.0723 0.0725 0.0728 

[TRAIN] Epoch[4](349/1500); Loss: 0.129661; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.3108 0.2084 0.1600 0.1288 0.1120 0.1064 0.1058 0.1056 0.1054 0.1053 0.1050 0.1046 0.1044 0.1042 0.1040 0.1038 

[TRAIN] Epoch[4](350/1500); Loss: 0.090213; Backpropagation: 0.0957 sec; Batch: 0.4298 sec
0.3594 0.1774 0.1101 0.0631 0.0603 0.0589 0.0590 0.0591 0.0595 0.0601 0.0607 0.0615 0.0623 0.0631 0.0640 0.0650 

[TRAIN] Epoch[4](351/1500); Loss: 0.073607; Backpropagation: 0.0959 sec; Batch: 0.4307 sec
0.1612 0.0947 0.0731 0.0672 0.0659 0.0652 0.0649 0.0647 0.0646 0.0646 0.0646 0.0648 0.0651 0.0654 0.0657 0.0662 

[TRAIN] Epoch[4](352/1500); Loss: 0.119661; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.4661 0.2993 0.2008 0.1109 0.0769 0.0706 0.0701 0.0694 0.0694 0.0692 0.0690 0.0688 0.0686 0.0685 0.0685 0.0686 

[TRAIN] Epoch[4](353/1500); Loss: 0.088299; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1471 0.1397 0.1074 0.0952 0.0906 0.0859 0.0828 0.0791 0.0756 0.0738 0.0729 0.0726 0.0725 0.0725 0.0725 0.0725 

[TRAIN] Epoch[4](354/1500); Loss: 0.046102; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.0704 0.0607 0.0446 0.0429 0.0425 0.0422 0.0421 0.0421 0.0422 0.0424 0.0428 0.0432 0.0438 0.0444 0.0452 0.0461 

[TRAIN] Epoch[4](355/1500); Loss: 0.094754; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1717 0.1081 0.0963 0.0899 0.0890 0.0886 0.0882 0.0878 0.0875 0.0872 0.0870 0.0869 0.0869 0.0869 0.0870 0.0872 

[TRAIN] Epoch[4](356/1500); Loss: 0.147068; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.3171 0.1995 0.1535 0.1358 0.1339 0.1313 0.1303 0.1291 0.1285 0.1281 0.1280 0.1277 0.1276 0.1276 0.1276 0.1275 

[TRAIN] Epoch[4](357/1500); Loss: 0.140673; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2420 0.1662 0.1409 0.1356 0.1336 0.1330 0.1321 0.1314 0.1308 0.1304 0.1300 0.1295 0.1292 0.1290 0.1287 0.1285 

[TRAIN] Epoch[4](358/1500); Loss: 0.133829; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.5480 0.2987 0.1604 0.0924 0.0843 0.0900 0.0873 0.0884 0.0884 0.0879 0.0871 0.0864 0.0858 0.0855 0.0852 0.0852 

[TRAIN] Epoch[4](359/1500); Loss: 0.099068; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2726 0.1670 0.1064 0.0827 0.0818 0.0805 0.0801 0.0798 0.0797 0.0795 0.0793 0.0792 0.0791 0.0791 0.0791 0.0792 

[TRAIN] Epoch[4](360/1500); Loss: 0.124380; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2408 0.1449 0.1326 0.1167 0.1142 0.1135 0.1131 0.1129 0.1127 0.1126 0.1125 0.1126 0.1126 0.1127 0.1128 0.1129 

[TRAIN] Epoch[4](361/1500); Loss: 0.113021; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.2508 0.1513 0.1140 0.1036 0.1011 0.1006 0.1000 0.0995 0.0991 0.0988 0.0985 0.0984 0.0982 0.0981 0.0981 0.0982 

[TRAIN] Epoch[4](362/1500); Loss: 0.106657; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2672 0.1622 0.1301 0.1041 0.0945 0.0905 0.0884 0.0873 0.0865 0.0859 0.0856 0.0853 0.0850 0.0848 0.0846 0.0845 

[TRAIN] Epoch[4](363/1500); Loss: 0.070664; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1244 0.0778 0.0894 0.0691 0.0655 0.0649 0.0645 0.0641 0.0639 0.0637 0.0637 0.0637 0.0637 0.0639 0.0640 0.0643 

[TRAIN] Epoch[4](364/1500); Loss: 0.102333; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2998 0.1575 0.1136 0.0902 0.0862 0.0842 0.0833 0.0824 0.0815 0.0808 0.0803 0.0799 0.0797 0.0795 0.0793 0.0793 

[TRAIN] Epoch[4](365/1500); Loss: 0.062317; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1130 0.0818 0.0654 0.0597 0.0575 0.0571 0.0567 0.0564 0.0563 0.0562 0.0561 0.0560 0.0560 0.0561 0.0563 0.0564 

[TRAIN] Epoch[4](366/1500); Loss: 0.119587; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.3790 0.2373 0.1754 0.1089 0.0917 0.0860 0.0864 0.0853 0.0847 0.0841 0.0836 0.0831 0.0825 0.0821 0.0818 0.0815 

[TRAIN] Epoch[4](367/1500); Loss: 0.072552; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.2743 0.1056 0.0751 0.0620 0.0562 0.0551 0.0544 0.0538 0.0534 0.0531 0.0528 0.0528 0.0529 0.0530 0.0531 0.0533 

[TRAIN] Epoch[4](368/1500); Loss: 0.181501; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2784 0.2343 0.1876 0.1818 0.1773 0.1754 0.1732 0.1715 0.1701 0.1687 0.1674 0.1661 0.1648 0.1637 0.1625 0.1613 

[TRAIN] Epoch[4](369/1500); Loss: 0.094457; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2526 0.1235 0.1014 0.0857 0.0812 0.0802 0.0796 0.0791 0.0788 0.0786 0.0784 0.0783 0.0783 0.0783 0.0785 0.0787 

[TRAIN] Epoch[4](370/1500); Loss: 0.098206; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1660 0.1186 0.1008 0.1009 0.0952 0.0941 0.0928 0.0916 0.0907 0.0900 0.0893 0.0888 0.0884 0.0882 0.0880 0.0880 

[TRAIN] Epoch[4](371/1500); Loss: 0.068898; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1045 0.0886 0.0852 0.0686 0.0669 0.0656 0.0645 0.0636 0.0629 0.0623 0.0619 0.0616 0.0615 0.0615 0.0615 0.0615 

[TRAIN] Epoch[4](372/1500); Loss: 0.074291; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1098 0.0936 0.0721 0.0732 0.0709 0.0703 0.0698 0.0696 0.0694 0.0693 0.0693 0.0695 0.0698 0.0702 0.0707 0.0713 

[TRAIN] Epoch[4](373/1500); Loss: 0.101118; Backpropagation: 0.0959 sec; Batch: 0.4308 sec
0.2066 0.1315 0.1132 0.0960 0.0915 0.0899 0.0894 0.0889 0.0887 0.0886 0.0886 0.0886 0.0888 0.0889 0.0892 0.0896 

[TRAIN] Epoch[4](374/1500); Loss: 0.055176; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1209 0.0873 0.0768 0.0558 0.0513 0.0493 0.0478 0.0466 0.0454 0.0446 0.0438 0.0433 0.0429 0.0426 0.0423 0.0422 

[TRAIN] Epoch[4](375/1500); Loss: 0.134700; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.2170 0.1459 0.1390 0.1341 0.1311 0.1301 0.1287 0.1276 0.1268 0.1261 0.1255 0.1251 0.1247 0.1246 0.1244 0.1245 

[TRAIN] Epoch[4](376/1500); Loss: 0.127544; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.4151 0.2570 0.1782 0.1093 0.0954 0.0916 0.0907 0.0903 0.0900 0.0897 0.0894 0.0891 0.0888 0.0887 0.0887 0.0887 

[TRAIN] Epoch[4](377/1500); Loss: 0.119015; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.3440 0.1990 0.1231 0.1018 0.0968 0.0960 0.0954 0.0949 0.0945 0.0943 0.0941 0.0940 0.0939 0.0939 0.0942 0.0944 

[TRAIN] Epoch[4](378/1500); Loss: 0.133662; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1894 0.1587 0.1391 0.1290 0.1281 0.1275 0.1273 0.1271 0.1269 0.1268 0.1267 0.1266 0.1265 0.1265 0.1263 0.1262 

[TRAIN] Epoch[4](379/1500); Loss: 0.106009; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1648 0.1180 0.1067 0.1028 0.1007 0.0996 0.0995 0.0995 0.0996 0.0997 0.1000 0.1003 0.1007 0.1010 0.1014 0.1017 

[TRAIN] Epoch[4](380/1500); Loss: 0.102847; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2348 0.1550 0.1234 0.0982 0.0905 0.0879 0.0871 0.0865 0.0860 0.0856 0.0854 0.0850 0.0849 0.0849 0.0850 0.0851 

[TRAIN] Epoch[4](381/1500); Loss: 0.050977; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.0918 0.0816 0.0645 0.0483 0.0474 0.0462 0.0452 0.0444 0.0438 0.0434 0.0431 0.0430 0.0431 0.0431 0.0432 0.0435 

[TRAIN] Epoch[4](382/1500); Loss: 0.092435; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1870 0.1106 0.0908 0.0860 0.0848 0.0838 0.0834 0.0831 0.0830 0.0829 0.0830 0.0832 0.0836 0.0840 0.0845 0.0851 

[TRAIN] Epoch[4](383/1500); Loss: 0.082932; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.3829 0.1424 0.0793 0.0740 0.0596 0.0589 0.0569 0.0557 0.0544 0.0533 0.0523 0.0517 0.0515 0.0514 0.0513 0.0512 

[TRAIN] Epoch[4](384/1500); Loss: 0.122093; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2025 0.1580 0.1282 0.1180 0.1149 0.1136 0.1129 0.1125 0.1122 0.1120 0.1118 0.1116 0.1114 0.1113 0.1113 0.1113 

[TRAIN] Epoch[4](385/1500); Loss: 0.102712; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1614 0.1222 0.1060 0.1022 0.0989 0.0982 0.0974 0.0966 0.0961 0.0957 0.0953 0.0949 0.0948 0.0947 0.0946 0.0946 

[TRAIN] Epoch[4](386/1500); Loss: 0.102109; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1729 0.1276 0.1051 0.0999 0.0970 0.0959 0.0952 0.0946 0.0942 0.0938 0.0935 0.0932 0.0930 0.0927 0.0926 0.0926 

[TRAIN] Epoch[4](387/1500); Loss: 0.074923; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1627 0.0891 0.0774 0.0706 0.0686 0.0679 0.0674 0.0669 0.0666 0.0662 0.0661 0.0660 0.0660 0.0658 0.0657 0.0657 

[TRAIN] Epoch[4](388/1500); Loss: 0.110224; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.5027 0.2359 0.1047 0.1001 0.0763 0.0786 0.0743 0.0721 0.0697 0.0676 0.0658 0.0645 0.0635 0.0630 0.0625 0.0623 

[TRAIN] Epoch[4](389/1500); Loss: 0.081781; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.2056 0.1006 0.0811 0.0779 0.0718 0.0713 0.0706 0.0702 0.0699 0.0698 0.0697 0.0697 0.0698 0.0699 0.0701 0.0702 

[TRAIN] Epoch[4](390/1500); Loss: 0.065078; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.0848 0.0995 0.0706 0.0628 0.0629 0.0617 0.0609 0.0603 0.0599 0.0597 0.0596 0.0595 0.0596 0.0597 0.0598 0.0600 

[TRAIN] Epoch[4](391/1500); Loss: 0.173820; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2809 0.2281 0.1648 0.1682 0.1636 0.1628 0.1616 0.1610 0.1608 0.1606 0.1606 0.1608 0.1613 0.1617 0.1620 0.1623 

[TRAIN] Epoch[4](392/1500); Loss: 0.081070; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1501 0.0902 0.0816 0.0770 0.0755 0.0750 0.0747 0.0745 0.0743 0.0742 0.0743 0.0745 0.0748 0.0751 0.0755 0.0759 

[TRAIN] Epoch[4](393/1500); Loss: 0.108367; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1554 0.1241 0.1191 0.1077 0.1053 0.1043 0.1035 0.1025 0.1021 0.1018 0.1016 0.1014 0.1013 0.1012 0.1013 0.1014 

[TRAIN] Epoch[4](394/1500); Loss: 0.186550; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.3052 0.2337 0.2059 0.1822 0.1770 0.1744 0.1733 0.1721 0.1716 0.1708 0.1704 0.1701 0.1699 0.1696 0.1694 0.1692 

[TRAIN] Epoch[4](395/1500); Loss: 0.062616; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1408 0.0806 0.0642 0.0594 0.0574 0.0559 0.0552 0.0545 0.0541 0.0540 0.0539 0.0540 0.0541 0.0543 0.0545 0.0547 

[TRAIN] Epoch[4](396/1500); Loss: 0.076714; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2841 0.1171 0.0858 0.0614 0.0592 0.0568 0.0568 0.0567 0.0566 0.0563 0.0561 0.0560 0.0561 0.0562 0.0563 0.0561 

[TRAIN] Epoch[4](397/1500); Loss: 0.106185; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1843 0.1247 0.1161 0.1027 0.1002 0.0994 0.0988 0.0981 0.0976 0.0974 0.0971 0.0967 0.0965 0.0964 0.0964 0.0965 

[TRAIN] Epoch[4](398/1500); Loss: 0.112558; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.4941 0.2390 0.1196 0.0965 0.0799 0.0778 0.0749 0.0730 0.0713 0.0698 0.0686 0.0678 0.0673 0.0671 0.0671 0.0672 

[TRAIN] Epoch[4](399/1500); Loss: 0.145281; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2258 0.1893 0.1489 0.1457 0.1422 0.1406 0.1388 0.1371 0.1356 0.1342 0.1331 0.1320 0.1312 0.1305 0.1300 0.1296 

[TRAIN] Epoch[4](400/1500); Loss: 0.105497; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.3018 0.1985 0.1140 0.0998 0.0921 0.0890 0.0865 0.0839 0.0818 0.0799 0.0785 0.0775 0.0768 0.0763 0.0760 0.0756 

[TRAIN] Epoch[4](401/1500); Loss: 0.142940; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.2163 0.1708 0.1494 0.1393 0.1364 0.1351 0.1345 0.1340 0.1338 0.1337 0.1336 0.1337 0.1339 0.1340 0.1341 0.1345 

[TRAIN] Epoch[4](402/1500); Loss: 0.078759; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2281 0.0937 0.0889 0.0710 0.0688 0.0664 0.0657 0.0652 0.0647 0.0643 0.0640 0.0639 0.0638 0.0638 0.0638 0.0639 

[TRAIN] Epoch[4](403/1500); Loss: 0.126311; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.2826 0.1803 0.1471 0.1169 0.1113 0.1102 0.1093 0.1086 0.1079 0.1076 0.1072 0.1069 0.1066 0.1064 0.1061 0.1059 

[TRAIN] Epoch[4](404/1500); Loss: 0.116579; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1894 0.1237 0.1257 0.1135 0.1117 0.1105 0.1101 0.1096 0.1093 0.1090 0.1089 0.1087 0.1087 0.1088 0.1088 0.1089 

[TRAIN] Epoch[4](405/1500); Loss: 0.095651; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1877 0.1273 0.1079 0.0971 0.0913 0.0895 0.0878 0.0860 0.0845 0.0833 0.0824 0.0818 0.0814 0.0809 0.0807 0.0806 

[TRAIN] Epoch[4](406/1500); Loss: 0.075501; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.1660 0.0954 0.0833 0.0720 0.0692 0.0680 0.0668 0.0660 0.0656 0.0653 0.0651 0.0649 0.0649 0.0650 0.0651 0.0653 

[TRAIN] Epoch[4](407/1500); Loss: 0.080825; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2063 0.1159 0.0840 0.0761 0.0726 0.0705 0.0693 0.0681 0.0674 0.0667 0.0663 0.0662 0.0660 0.0659 0.0660 0.0659 

[TRAIN] Epoch[4](408/1500); Loss: 0.103442; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2456 0.1357 0.1084 0.0981 0.0943 0.0928 0.0912 0.0902 0.0893 0.0885 0.0878 0.0873 0.0868 0.0865 0.0863 0.0863 

[TRAIN] Epoch[4](409/1500); Loss: 0.127910; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1999 0.1623 0.1393 0.1242 0.1212 0.1202 0.1194 0.1189 0.1185 0.1182 0.1178 0.1176 0.1174 0.1173 0.1173 0.1173 

[TRAIN] Epoch[4](410/1500); Loss: 0.079738; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.3735 0.1372 0.0692 0.0720 0.0581 0.0562 0.0541 0.0527 0.0514 0.0507 0.0502 0.0500 0.0501 0.0501 0.0502 0.0502 

[TRAIN] Epoch[4](411/1500); Loss: 0.187723; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2737 0.2010 0.1896 0.1805 0.1802 0.1800 0.1802 0.1801 0.1802 0.1801 0.1800 0.1798 0.1797 0.1795 0.1795 0.1795 

[TRAIN] Epoch[4](412/1500); Loss: 0.116574; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.4162 0.2128 0.1222 0.1037 0.0893 0.0885 0.0863 0.0851 0.0842 0.0834 0.0828 0.0824 0.0821 0.0821 0.0821 0.0821 

[TRAIN] Epoch[4](413/1500); Loss: 0.135880; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2848 0.1678 0.1437 0.1279 0.1232 0.1223 0.1216 0.1212 0.1209 0.1205 0.1203 0.1202 0.1200 0.1200 0.1199 0.1198 

[TRAIN] Epoch[4](414/1500); Loss: 0.038813; Backpropagation: 0.0958 sec; Batch: 0.4311 sec
0.0704 0.0417 0.0778 0.0447 0.0366 0.0346 0.0330 0.0321 0.0314 0.0311 0.0309 0.0309 0.0310 0.0313 0.0315 0.0317 

[TRAIN] Epoch[4](415/1500); Loss: 0.111969; Backpropagation: 0.0957 sec; Batch: 0.4301 sec
0.2321 0.1504 0.1235 0.1059 0.1013 0.0994 0.0984 0.0978 0.0975 0.0974 0.0975 0.0977 0.0979 0.0980 0.0982 0.0984 

[TRAIN] Epoch[4](416/1500); Loss: 0.044589; Backpropagation: 0.0940 sec; Batch: 0.4277 sec
0.1164 0.0880 0.0499 0.0404 0.0367 0.0359 0.0352 0.0346 0.0343 0.0342 0.0342 0.0343 0.0345 0.0347 0.0349 0.0352 

[TRAIN] Epoch[4](417/1500); Loss: 0.072180; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1451 0.0899 0.0748 0.0702 0.0677 0.0664 0.0655 0.0648 0.0643 0.0639 0.0637 0.0637 0.0637 0.0637 0.0638 0.0639 

[TRAIN] Epoch[4](418/1500); Loss: 0.084265; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1411 0.1079 0.0874 0.0842 0.0805 0.0791 0.0781 0.0776 0.0772 0.0770 0.0768 0.0765 0.0764 0.0762 0.0761 0.0762 

[TRAIN] Epoch[4](419/1500); Loss: 0.077614; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1568 0.1031 0.0815 0.0745 0.0714 0.0706 0.0698 0.0693 0.0690 0.0686 0.0683 0.0679 0.0678 0.0676 0.0678 0.0679 

[TRAIN] Epoch[4](420/1500); Loss: 0.127661; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2004 0.1546 0.1434 0.1303 0.1239 0.1216 0.1200 0.1188 0.1178 0.1171 0.1165 0.1161 0.1158 0.1156 0.1155 0.1152 

[TRAIN] Epoch[4](421/1500); Loss: 0.115867; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.2018 0.1389 0.1245 0.1150 0.1124 0.1100 0.1083 0.1071 0.1063 0.1055 0.1048 0.1043 0.1040 0.1039 0.1035 0.1034 

[TRAIN] Epoch[4](422/1500); Loss: 0.072455; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.2359 0.0861 0.0676 0.0649 0.0613 0.0598 0.0592 0.0587 0.0585 0.0583 0.0582 0.0580 0.0580 0.0582 0.0583 0.0583 

[TRAIN] Epoch[4](423/1500); Loss: 0.125661; Backpropagation: 0.0939 sec; Batch: 0.4274 sec
0.2043 0.1268 0.1305 0.1212 0.1205 0.1197 0.1194 0.1190 0.1188 0.1187 0.1186 0.1186 0.1186 0.1187 0.1187 0.1187 

[TRAIN] Epoch[4](424/1500); Loss: 0.088345; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.4514 0.1827 0.0752 0.0747 0.0612 0.0583 0.0553 0.0538 0.0524 0.0512 0.0502 0.0496 0.0494 0.0492 0.0493 0.0495 

[TRAIN] Epoch[4](425/1500); Loss: 0.134315; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2646 0.1687 0.1464 0.1282 0.1247 0.1230 0.1214 0.1205 0.1197 0.1192 0.1190 0.1188 0.1186 0.1186 0.1187 0.1189 

[TRAIN] Epoch[4](426/1500); Loss: 0.098186; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2473 0.1381 0.1074 0.0887 0.0858 0.0841 0.0834 0.0827 0.0822 0.0818 0.0815 0.0814 0.0815 0.0816 0.0817 0.0818 

[TRAIN] Epoch[4](427/1500); Loss: 0.072212; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.2457 0.0978 0.0737 0.0616 0.0595 0.0579 0.0571 0.0562 0.0560 0.0559 0.0557 0.0556 0.0556 0.0556 0.0558 0.0559 

[TRAIN] Epoch[4](428/1500); Loss: 0.040328; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1041 0.0814 0.0603 0.0372 0.0327 0.0317 0.0309 0.0303 0.0298 0.0296 0.0294 0.0294 0.0294 0.0294 0.0297 0.0299 

[TRAIN] Epoch[4](429/1500); Loss: 0.082198; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1434 0.0987 0.0826 0.0804 0.0773 0.0767 0.0761 0.0756 0.0753 0.0752 0.0751 0.0752 0.0754 0.0757 0.0760 0.0764 

[TRAIN] Epoch[4](430/1500); Loss: 0.146215; Backpropagation: 0.0938 sec; Batch: 0.4274 sec
0.2581 0.1640 0.1459 0.1386 0.1377 0.1373 0.1370 0.1363 0.1360 0.1358 0.1356 0.1355 0.1354 0.1353 0.1353 0.1356 

[TRAIN] Epoch[4](431/1500); Loss: 0.043564; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.0644 0.0658 0.0627 0.0433 0.0407 0.0395 0.0388 0.0382 0.0379 0.0376 0.0376 0.0377 0.0379 0.0381 0.0384 0.0385 

[TRAIN] Epoch[4](432/1500); Loss: 0.093706; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1439 0.1239 0.0950 0.0888 0.0881 0.0878 0.0875 0.0873 0.0872 0.0871 0.0872 0.0871 0.0871 0.0871 0.0872 0.0873 

[TRAIN] Epoch[4](433/1500); Loss: 0.065037; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1442 0.0958 0.0690 0.0639 0.0592 0.0565 0.0552 0.0545 0.0543 0.0544 0.0546 0.0547 0.0553 0.0558 0.0562 0.0569 

[TRAIN] Epoch[4](434/1500); Loss: 0.075683; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1781 0.0973 0.0832 0.0701 0.0667 0.0655 0.0649 0.0644 0.0643 0.0644 0.0646 0.0649 0.0652 0.0654 0.0658 0.0662 

[TRAIN] Epoch[4](435/1500); Loss: 0.055450; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.0990 0.0767 0.0630 0.0540 0.0533 0.0518 0.0507 0.0499 0.0492 0.0487 0.0485 0.0483 0.0483 0.0484 0.0486 0.0488 

[TRAIN] Epoch[4](436/1500); Loss: 0.111310; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.1910 0.1266 0.1211 0.1090 0.1060 0.1044 0.1035 0.1028 0.1024 0.1022 0.1021 0.1019 0.1019 0.1019 0.1020 0.1020 

[TRAIN] Epoch[4](437/1500); Loss: 0.077478; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1662 0.1010 0.0906 0.0737 0.0699 0.0688 0.0681 0.0675 0.0670 0.0668 0.0666 0.0666 0.0665 0.0666 0.0668 0.0670 

[TRAIN] Epoch[4](438/1500); Loss: 0.063911; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1950 0.0819 0.0725 0.0604 0.0551 0.0534 0.0527 0.0519 0.0512 0.0505 0.0501 0.0498 0.0497 0.0495 0.0494 0.0494 

[TRAIN] Epoch[4](439/1500); Loss: 0.136716; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1899 0.1588 0.1415 0.1334 0.1323 0.1317 0.1313 0.1310 0.1306 0.1302 0.1299 0.1296 0.1295 0.1293 0.1292 0.1292 

[TRAIN] Epoch[4](440/1500); Loss: 0.178729; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.2800 0.2286 0.1819 0.1695 0.1671 0.1669 0.1665 0.1662 0.1663 0.1664 0.1664 0.1665 0.1666 0.1667 0.1669 0.1671 

[TRAIN] Epoch[4](441/1500); Loss: 0.098528; Backpropagation: 0.0940 sec; Batch: 0.4277 sec
0.1558 0.1145 0.0999 0.0944 0.0939 0.0933 0.0929 0.0926 0.0925 0.0925 0.0924 0.0924 0.0923 0.0923 0.0924 0.0925 

[TRAIN] Epoch[4](442/1500); Loss: 0.112790; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2229 0.1217 0.1174 0.1077 0.1058 0.1043 0.1040 0.1033 0.1030 0.1027 0.1025 0.1022 0.1020 0.1018 0.1017 0.1016 

[TRAIN] Epoch[4](443/1500); Loss: 0.165309; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2696 0.2265 0.1832 0.1707 0.1638 0.1599 0.1567 0.1537 0.1513 0.1491 0.1470 0.1452 0.1437 0.1425 0.1414 0.1406 

[TRAIN] Epoch[4](444/1500); Loss: 0.097649; Backpropagation: 0.0958 sec; Batch: 0.4299 sec
0.1833 0.1160 0.1022 0.0925 0.0909 0.0903 0.0895 0.0890 0.0886 0.0884 0.0884 0.0884 0.0885 0.0886 0.0888 0.0890 

[TRAIN] Epoch[4](445/1500); Loss: 0.084455; Backpropagation: 0.0959 sec; Batch: 0.4303 sec
0.1137 0.1087 0.0944 0.0887 0.0853 0.0829 0.0812 0.0796 0.0784 0.0776 0.0771 0.0768 0.0767 0.0767 0.0767 0.0768 

[TRAIN] Epoch[4](446/1500); Loss: 0.084807; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1136 0.1105 0.1018 0.0899 0.0838 0.0819 0.0805 0.0793 0.0784 0.0778 0.0771 0.0767 0.0765 0.0763 0.0763 0.0763 

[TRAIN] Epoch[4](447/1500); Loss: 0.134662; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2466 0.1792 0.1332 0.1267 0.1246 0.1235 0.1228 0.1224 0.1222 0.1219 0.1219 0.1218 0.1219 0.1218 0.1220 0.1222 

[TRAIN] Epoch[4](448/1500); Loss: 0.086332; Backpropagation: 0.0936 sec; Batch: 0.4470 sec
0.1413 0.1079 0.0895 0.0838 0.0822 0.0810 0.0803 0.0799 0.0795 0.0794 0.0793 0.0793 0.0793 0.0793 0.0795 0.0797 

[TRAIN] Epoch[4](449/1500); Loss: 0.090670; Backpropagation: 0.0937 sec; Batch: 0.4672 sec
0.1597 0.1024 0.0952 0.0874 0.0855 0.0850 0.0846 0.0842 0.0838 0.0835 0.0833 0.0833 0.0832 0.0832 0.0832 0.0832 

[TRAIN] Epoch[4](450/1500); Loss: 0.050438; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1670 0.1007 0.0616 0.0373 0.0361 0.0363 0.0361 0.0358 0.0358 0.0362 0.0364 0.0366 0.0370 0.0375 0.0380 0.0384 

[TRAIN] Epoch[4](451/1500); Loss: 0.103120; Backpropagation: 0.0938 sec; Batch: 0.4299 sec
0.3641 0.1478 0.0976 0.0819 0.0841 0.0807 0.0802 0.0799 0.0795 0.0791 0.0789 0.0789 0.0789 0.0792 0.0794 0.0798 

[TRAIN] Epoch[4](452/1500); Loss: 0.069454; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2437 0.0986 0.0750 0.0666 0.0593 0.0560 0.0546 0.0532 0.0524 0.0514 0.0509 0.0504 0.0500 0.0498 0.0497 0.0496 

[TRAIN] Epoch[4](453/1500); Loss: 0.142725; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2232 0.1680 0.1478 0.1400 0.1378 0.1365 0.1356 0.1348 0.1341 0.1335 0.1330 0.1326 0.1322 0.1318 0.1315 0.1312 

[TRAIN] Epoch[4](454/1500); Loss: 0.111256; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2423 0.1220 0.1192 0.1035 0.1033 0.1007 0.1004 0.0998 0.0993 0.0990 0.0988 0.0985 0.0985 0.0983 0.0983 0.0983 

[TRAIN] Epoch[4](455/1500); Loss: 0.108679; Backpropagation: 0.0957 sec; Batch: 0.4424 sec
0.1903 0.1258 0.1159 0.1060 0.1037 0.1026 0.1016 0.1007 0.1000 0.0995 0.0991 0.0989 0.0988 0.0987 0.0987 0.0987 

[TRAIN] Epoch[4](456/1500); Loss: 0.132439; Backpropagation: 0.0957 sec; Batch: 0.4297 sec
0.2338 0.1550 0.1376 0.1274 0.1250 0.1241 0.1235 0.1229 0.1224 0.1219 0.1215 0.1212 0.1210 0.1206 0.1205 0.1205 

[TRAIN] Epoch[4](457/1500); Loss: 0.155550; Backpropagation: 0.0939 sec; Batch: 0.4292 sec
0.2462 0.1700 0.1555 0.1517 0.1494 0.1485 0.1479 0.1473 0.1469 0.1466 0.1465 0.1464 0.1465 0.1464 0.1464 0.1465 

[TRAIN] Epoch[4](458/1500); Loss: 0.109443; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.2971 0.1590 0.1120 0.0942 0.0916 0.0912 0.0906 0.0904 0.0903 0.0903 0.0903 0.0905 0.0907 0.0908 0.0909 0.0912 

[TRAIN] Epoch[4](459/1500); Loss: 0.154947; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2418 0.2013 0.1589 0.1520 0.1486 0.1469 0.1456 0.1444 0.1435 0.1430 0.1427 0.1423 0.1421 0.1420 0.1420 0.1420 

[TRAIN] Epoch[4](460/1500); Loss: 0.066549; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.1226 0.0821 0.0756 0.0643 0.0636 0.0618 0.0606 0.0599 0.0596 0.0593 0.0592 0.0592 0.0591 0.0592 0.0593 0.0595 

[TRAIN] Epoch[4](461/1500); Loss: 0.138330; Backpropagation: 0.0957 sec; Batch: 0.4309 sec
0.2846 0.1766 0.1380 0.1304 0.1261 0.1255 0.1247 0.1239 0.1234 0.1230 0.1228 0.1227 0.1227 0.1228 0.1229 0.1229 

[TRAIN] Epoch[4](462/1500); Loss: 0.101499; Backpropagation: 0.0940 sec; Batch: 0.4275 sec
0.1532 0.1410 0.1074 0.0998 0.0965 0.0958 0.0949 0.0943 0.0936 0.0932 0.0928 0.0926 0.0924 0.0922 0.0921 0.0921 

[TRAIN] Epoch[4](463/1500); Loss: 0.093397; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2098 0.1343 0.1055 0.0935 0.0873 0.0841 0.0820 0.0804 0.0792 0.0782 0.0776 0.0771 0.0768 0.0764 0.0762 0.0760 

[TRAIN] Epoch[4](464/1500); Loss: 0.154255; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.2525 0.1904 0.1610 0.1488 0.1466 0.1456 0.1447 0.1439 0.1431 0.1426 0.1422 0.1418 0.1415 0.1413 0.1411 0.1410 

[TRAIN] Epoch[4](465/1500); Loss: 0.121038; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1669 0.1454 0.1352 0.1196 0.1174 0.1157 0.1149 0.1142 0.1139 0.1138 0.1135 0.1133 0.1132 0.1132 0.1132 0.1134 

[TRAIN] Epoch[4](466/1500); Loss: 0.091798; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.1638 0.1157 0.1044 0.0919 0.0886 0.0867 0.0855 0.0841 0.0831 0.0823 0.0816 0.0809 0.0804 0.0802 0.0799 0.0798 

[TRAIN] Epoch[4](467/1500); Loss: 0.090978; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.3658 0.1088 0.0997 0.0788 0.0728 0.0692 0.0673 0.0660 0.0653 0.0649 0.0651 0.0653 0.0659 0.0662 0.0669 0.0676 

[TRAIN] Epoch[4](468/1500); Loss: 0.084589; Backpropagation: 0.0957 sec; Batch: 0.4308 sec
0.2228 0.1094 0.0845 0.0765 0.0736 0.0722 0.0719 0.0717 0.0714 0.0713 0.0713 0.0714 0.0714 0.0714 0.0714 0.0715 

[TRAIN] Epoch[4](469/1500); Loss: 0.117574; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.2238 0.1506 0.1165 0.1138 0.1106 0.1096 0.1083 0.1074 0.1066 0.1059 0.1054 0.1050 0.1048 0.1045 0.1043 0.1041 

[TRAIN] Epoch[4](470/1500); Loss: 0.091064; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.3893 0.2006 0.1017 0.0853 0.0659 0.0628 0.0595 0.0577 0.0563 0.0549 0.0541 0.0539 0.0538 0.0538 0.0538 0.0536 

[TRAIN] Epoch[4](471/1500); Loss: 0.079476; Backpropagation: 0.0938 sec; Batch: 0.4286 sec
0.1418 0.1025 0.0821 0.0770 0.0750 0.0739 0.0729 0.0722 0.0718 0.0716 0.0714 0.0715 0.0717 0.0718 0.0720 0.0723 

[TRAIN] Epoch[4](472/1500); Loss: 0.140245; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2415 0.1902 0.1465 0.1351 0.1325 0.1302 0.1292 0.1285 0.1278 0.1271 0.1266 0.1263 0.1259 0.1257 0.1254 0.1253 

[TRAIN] Epoch[4](473/1500); Loss: 0.141275; Backpropagation: 0.0982 sec; Batch: 0.4333 sec
0.1799 0.1702 0.1442 0.1427 0.1388 0.1371 0.1363 0.1355 0.1351 0.1348 0.1345 0.1343 0.1343 0.1344 0.1343 0.1342 

[TRAIN] Epoch[4](474/1500); Loss: 0.128767; Backpropagation: 0.0959 sec; Batch: 0.4303 sec
0.1791 0.1349 0.1316 0.1268 0.1255 0.1244 0.1239 0.1235 0.1232 0.1232 0.1232 0.1235 0.1237 0.1242 0.1246 0.1250 

[TRAIN] Epoch[4](475/1500); Loss: 0.096515; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.2950 0.1065 0.0994 0.0866 0.0816 0.0797 0.0796 0.0793 0.0794 0.0794 0.0796 0.0794 0.0796 0.0797 0.0798 0.0798 

[TRAIN] Epoch[4](476/1500); Loss: 0.108501; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2105 0.1328 0.1162 0.1091 0.1044 0.1018 0.0998 0.0983 0.0975 0.0967 0.0957 0.0952 0.0948 0.0946 0.0943 0.0942 

[TRAIN] Epoch[4](477/1500); Loss: 0.126518; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1750 0.1417 0.1359 0.1266 0.1235 0.1227 0.1218 0.1211 0.1205 0.1201 0.1197 0.1195 0.1193 0.1191 0.1190 0.1188 

[TRAIN] Epoch[4](478/1500); Loss: 0.059078; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.0836 0.0639 0.0861 0.0609 0.0563 0.0555 0.0550 0.0544 0.0541 0.0538 0.0536 0.0535 0.0535 0.0535 0.0536 0.0538 

[TRAIN] Epoch[4](479/1500); Loss: 0.086165; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.2470 0.1171 0.0913 0.0790 0.0755 0.0723 0.0710 0.0701 0.0698 0.0697 0.0696 0.0692 0.0694 0.0692 0.0692 0.0692 

[TRAIN] Epoch[4](480/1500); Loss: 0.097549; Backpropagation: 0.0956 sec; Batch: 0.4295 sec
0.2312 0.1266 0.1037 0.0929 0.0888 0.0867 0.0854 0.0841 0.0837 0.0833 0.0830 0.0827 0.0825 0.0821 0.0821 0.0820 

[TRAIN] Epoch[4](481/1500); Loss: 0.102286; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.2115 0.1359 0.1123 0.0981 0.0951 0.0927 0.0917 0.0905 0.0898 0.0892 0.0888 0.0885 0.0884 0.0882 0.0879 0.0879 

[TRAIN] Epoch[4](482/1500); Loss: 0.066683; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1848 0.1034 0.0852 0.0580 0.0583 0.0559 0.0543 0.0525 0.0515 0.0513 0.0515 0.0517 0.0518 0.0520 0.0522 0.0525 

[TRAIN] Epoch[4](483/1500); Loss: 0.089239; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2135 0.1094 0.1006 0.0873 0.0827 0.0803 0.0787 0.0775 0.0764 0.0755 0.0748 0.0744 0.0743 0.0743 0.0741 0.0742 

[TRAIN] Epoch[4](484/1500); Loss: 0.067929; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.2356 0.0872 0.0745 0.0595 0.0556 0.0532 0.0525 0.0528 0.0523 0.0518 0.0515 0.0517 0.0518 0.0520 0.0522 0.0526 

[TRAIN] Epoch[4](485/1500); Loss: 0.068759; Backpropagation: 0.0958 sec; Batch: 0.4313 sec
0.1019 0.1117 0.0770 0.0729 0.0676 0.0648 0.0634 0.0621 0.0612 0.0604 0.0600 0.0597 0.0596 0.0594 0.0593 0.0592 

[TRAIN] Epoch[4](486/1500); Loss: 0.081786; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.1514 0.1006 0.0856 0.0793 0.0771 0.0762 0.0755 0.0747 0.0743 0.0740 0.0737 0.0735 0.0733 0.0732 0.0731 0.0731 

[TRAIN] Epoch[4](487/1500); Loss: 0.134691; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2534 0.1890 0.1418 0.1272 0.1256 0.1230 0.1218 0.1205 0.1198 0.1194 0.1192 0.1191 0.1191 0.1189 0.1188 0.1186 

[TRAIN] Epoch[4](488/1500); Loss: 0.133203; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.2719 0.1534 0.1375 0.1248 0.1231 0.1213 0.1210 0.1203 0.1202 0.1199 0.1200 0.1196 0.1196 0.1194 0.1195 0.1196 

[TRAIN] Epoch[4](489/1500); Loss: 0.144645; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.2418 0.1900 0.1524 0.1425 0.1377 0.1359 0.1346 0.1335 0.1324 0.1317 0.1312 0.1307 0.1304 0.1300 0.1298 0.1297 

[TRAIN] Epoch[4](490/1500); Loss: 0.104744; Backpropagation: 0.0939 sec; Batch: 0.4321 sec
0.1372 0.1249 0.1054 0.1019 0.1007 0.1001 0.1002 0.1005 0.1008 0.1009 0.1008 0.1007 0.1005 0.1005 0.1004 0.1003 

[TRAIN] Epoch[4](491/1500); Loss: 0.072848; Backpropagation: 0.0944 sec; Batch: 0.4288 sec
0.1132 0.0911 0.0800 0.0720 0.0709 0.0697 0.0687 0.0679 0.0673 0.0669 0.0666 0.0664 0.0663 0.0662 0.0661 0.0661 

[TRAIN] Epoch[4](492/1500); Loss: 0.095119; Backpropagation: 0.0946 sec; Batch: 0.4296 sec
0.1681 0.1257 0.1034 0.0930 0.0893 0.0876 0.0869 0.0863 0.0860 0.0856 0.0855 0.0852 0.0851 0.0849 0.0848 0.0846 

[TRAIN] Epoch[4](493/1500); Loss: 0.097106; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.2066 0.1241 0.1031 0.0945 0.0893 0.0875 0.0864 0.0857 0.0852 0.0849 0.0846 0.0845 0.0844 0.0844 0.0843 0.0843 

[TRAIN] Epoch[4](494/1500); Loss: 0.032420; Backpropagation: 0.0938 sec; Batch: 0.4290 sec
0.0783 0.0652 0.0554 0.0351 0.0309 0.0277 0.0253 0.0234 0.0223 0.0218 0.0216 0.0217 0.0218 0.0221 0.0227 0.0233 

[TRAIN] Epoch[4](495/1500); Loss: 0.118628; Backpropagation: 0.0937 sec; Batch: 0.4272 sec
0.2476 0.1308 0.1250 0.1100 0.1105 0.1086 0.1085 0.1073 0.1070 0.1067 0.1067 0.1062 0.1060 0.1058 0.1058 0.1056 

[TRAIN] Epoch[4](496/1500); Loss: 0.095715; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1401 0.1120 0.1001 0.0963 0.0937 0.0922 0.0914 0.0906 0.0899 0.0896 0.0892 0.0891 0.0891 0.0892 0.0893 0.0896 

[TRAIN] Epoch[4](497/1500); Loss: 0.090329; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1746 0.1172 0.0978 0.0900 0.0841 0.0815 0.0804 0.0797 0.0794 0.0792 0.0794 0.0796 0.0799 0.0804 0.0807 0.0814 

[TRAIN] Epoch[4](498/1500); Loss: 0.107217; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1631 0.1231 0.1132 0.1066 0.1049 0.1034 0.1021 0.1011 0.1004 0.1000 0.0997 0.0996 0.0997 0.0995 0.0994 0.0996 

[TRAIN] Epoch[4](499/1500); Loss: 0.038345; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.0649 0.0666 0.0450 0.0379 0.0366 0.0353 0.0341 0.0332 0.0326 0.0322 0.0322 0.0322 0.0324 0.0326 0.0328 0.0329 

[TRAIN] Epoch[4](500/1500); Loss: 0.096979; Backpropagation: 0.0931 sec; Batch: 0.4275 sec
0.1750 0.1182 0.1073 0.0976 0.0936 0.0913 0.0899 0.0886 0.0877 0.0871 0.0865 0.0861 0.0858 0.0857 0.0857 0.0856 

[TRAIN] Epoch[4](501/1500); Loss: 0.100256; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2818 0.1697 0.1058 0.0984 0.0874 0.0844 0.0823 0.0807 0.0793 0.0777 0.0768 0.0762 0.0759 0.0758 0.0759 0.0761 

[TRAIN] Epoch[4](502/1500); Loss: 0.093062; Backpropagation: 0.1004 sec; Batch: 0.4427 sec
0.1921 0.1495 0.1118 0.0868 0.0824 0.0806 0.0799 0.0791 0.0786 0.0784 0.0783 0.0782 0.0781 0.0782 0.0784 0.0786 

[TRAIN] Epoch[4](503/1500); Loss: 0.083690; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1784 0.1192 0.1073 0.0824 0.0750 0.0738 0.0727 0.0718 0.0709 0.0704 0.0700 0.0698 0.0696 0.0693 0.0692 0.0691 

[TRAIN] Epoch[4](504/1500); Loss: 0.119198; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2572 0.1630 0.1266 0.1109 0.1068 0.1059 0.1049 0.1041 0.1037 0.1034 0.1032 0.1033 0.1034 0.1034 0.1035 0.1037 

[TRAIN] Epoch[4](505/1500); Loss: 0.059572; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1621 0.0830 0.0589 0.0522 0.0502 0.0490 0.0481 0.0477 0.0478 0.0481 0.0486 0.0491 0.0501 0.0516 0.0527 0.0540 

[TRAIN] Epoch[4](506/1500); Loss: 0.133793; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2256 0.1718 0.1424 0.1286 0.1271 0.1249 0.1240 0.1228 0.1225 0.1222 0.1219 0.1216 0.1214 0.1212 0.1212 0.1213 

[TRAIN] Epoch[4](507/1500); Loss: 0.114241; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2158 0.1204 0.1177 0.1088 0.1066 0.1056 0.1052 0.1049 0.1048 0.1049 0.1050 0.1052 0.1054 0.1056 0.1059 0.1062 

[TRAIN] Epoch[4](508/1500); Loss: 0.144262; Backpropagation: 0.0937 sec; Batch: 0.4546 sec
0.2223 0.1609 0.1514 0.1432 0.1406 0.1391 0.1381 0.1370 0.1363 0.1353 0.1349 0.1344 0.1341 0.1335 0.1336 0.1334 

[TRAIN] Epoch[4](509/1500); Loss: 0.165558; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.2091 0.1773 0.1716 0.1637 0.1634 0.1628 0.1621 0.1615 0.1611 0.1606 0.1601 0.1597 0.1594 0.1591 0.1588 0.1585 

[TRAIN] Epoch[4](510/1500); Loss: 0.163140; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.2479 0.1740 0.1609 0.1599 0.1574 0.1569 0.1564 0.1561 0.1560 0.1557 0.1553 0.1551 0.1549 0.1549 0.1545 0.1543 

[TRAIN] Epoch[4](511/1500); Loss: 0.127058; Backpropagation: 0.0935 sec; Batch: 0.4269 sec
0.1944 0.1507 0.1291 0.1239 0.1221 0.1214 0.1207 0.1200 0.1195 0.1192 0.1188 0.1187 0.1186 0.1186 0.1186 0.1187 

[TRAIN] Epoch[4](512/1500); Loss: 0.104957; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.1599 0.1350 0.1140 0.1059 0.1027 0.1005 0.0991 0.0980 0.0973 0.0965 0.0959 0.0954 0.0951 0.0948 0.0947 0.0946 

[TRAIN] Epoch[4](513/1500); Loss: 0.127779; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1537 0.1650 0.1374 0.1330 0.1276 0.1242 0.1226 0.1212 0.1207 0.1205 0.1201 0.1198 0.1196 0.1197 0.1196 0.1196 

[TRAIN] Epoch[4](514/1500); Loss: 0.112344; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2425 0.1308 0.1142 0.1072 0.1040 0.1022 0.1014 0.1005 0.1001 0.0998 0.0996 0.0994 0.0993 0.0991 0.0988 0.0989 

[TRAIN] Epoch[4](515/1500); Loss: 0.143201; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1920 0.1813 0.1520 0.1456 0.1416 0.1394 0.1379 0.1364 0.1351 0.1341 0.1335 0.1330 0.1328 0.1324 0.1321 0.1319 

[TRAIN] Epoch[4](516/1500); Loss: 0.115749; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1336 0.1283 0.1177 0.1136 0.1138 0.1136 0.1134 0.1132 0.1131 0.1131 0.1130 0.1131 0.1130 0.1130 0.1131 0.1133 

[TRAIN] Epoch[4](517/1500); Loss: 0.095607; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1843 0.1262 0.1064 0.0979 0.0921 0.0880 0.0856 0.0840 0.0831 0.0826 0.0825 0.0826 0.0829 0.0835 0.0839 0.0843 

[TRAIN] Epoch[4](518/1500); Loss: 0.096554; Backpropagation: 0.0931 sec; Batch: 0.4265 sec
0.1853 0.1073 0.1058 0.0923 0.0909 0.0895 0.0887 0.0883 0.0877 0.0874 0.0870 0.0868 0.0868 0.0870 0.0870 0.0871 

[TRAIN] Epoch[4](519/1500); Loss: 0.068663; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.0911 0.0972 0.0711 0.0670 0.0665 0.0654 0.0648 0.0642 0.0639 0.0637 0.0638 0.0638 0.0638 0.0639 0.0641 0.0643 

[TRAIN] Epoch[4](520/1500); Loss: 0.155883; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.2120 0.1700 0.1647 0.1553 0.1538 0.1523 0.1512 0.1503 0.1496 0.1489 0.1486 0.1482 0.1477 0.1474 0.1472 0.1470 

[TRAIN] Epoch[4](521/1500); Loss: 0.073298; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.0939 0.0880 0.0738 0.0742 0.0721 0.0713 0.0707 0.0702 0.0700 0.0698 0.0698 0.0697 0.0696 0.0697 0.0699 0.0700 

[TRAIN] Epoch[4](522/1500); Loss: 0.119121; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1780 0.1363 0.1416 0.1250 0.1216 0.1156 0.1125 0.1104 0.1092 0.1086 0.1082 0.1079 0.1077 0.1076 0.1078 0.1079 

[TRAIN] Epoch[4](523/1500); Loss: 0.049586; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1319 0.0951 0.0594 0.0424 0.0398 0.0387 0.0385 0.0383 0.0383 0.0382 0.0382 0.0383 0.0387 0.0389 0.0392 0.0395 

[TRAIN] Epoch[4](524/1500); Loss: 0.094516; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1876 0.1263 0.1206 0.0918 0.0872 0.0850 0.0836 0.0821 0.0815 0.0811 0.0808 0.0809 0.0809 0.0808 0.0810 0.0811 

[TRAIN] Epoch[4](525/1500); Loss: 0.086789; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2245 0.1251 0.0888 0.0775 0.0744 0.0733 0.0728 0.0725 0.0722 0.0721 0.0721 0.0723 0.0723 0.0726 0.0729 0.0730 

[TRAIN] Epoch[4](526/1500); Loss: 0.089643; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1207 0.1114 0.0951 0.0885 0.0860 0.0846 0.0841 0.0839 0.0841 0.0842 0.0844 0.0846 0.0850 0.0855 0.0859 0.0861 

[TRAIN] Epoch[4](527/1500); Loss: 0.079787; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1065 0.1053 0.0885 0.0814 0.0794 0.0770 0.0759 0.0750 0.0743 0.0739 0.0736 0.0733 0.0732 0.0731 0.0731 0.0730 

[TRAIN] Epoch[4](528/1500); Loss: 0.084041; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1794 0.1113 0.0957 0.0842 0.0788 0.0753 0.0739 0.0727 0.0721 0.0717 0.0716 0.0715 0.0715 0.0715 0.0715 0.0717 

[TRAIN] Epoch[4](529/1500); Loss: 0.086842; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1851 0.1373 0.0942 0.0761 0.0765 0.0751 0.0749 0.0744 0.0748 0.0745 0.0745 0.0741 0.0743 0.0744 0.0747 0.0745 

[TRAIN] Epoch[4](530/1500); Loss: 0.136050; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1699 0.1369 0.1480 0.1394 0.1370 0.1344 0.1327 0.1316 0.1307 0.1310 0.1306 0.1304 0.1305 0.1308 0.1313 0.1316 

[TRAIN] Epoch[4](531/1500); Loss: 0.065073; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1453 0.0819 0.0587 0.0600 0.0606 0.0597 0.0583 0.0574 0.0570 0.0568 0.0569 0.0571 0.0575 0.0576 0.0580 0.0584 

[TRAIN] Epoch[4](532/1500); Loss: 0.105633; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1980 0.1158 0.1099 0.1038 0.1004 0.0990 0.0980 0.0973 0.0969 0.0965 0.0962 0.0960 0.0958 0.0955 0.0955 0.0956 

[TRAIN] Epoch[4](533/1500); Loss: 0.101419; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1711 0.1297 0.1102 0.1001 0.0973 0.0950 0.0940 0.0930 0.0924 0.0918 0.0915 0.0913 0.0913 0.0912 0.0913 0.0913 

[TRAIN] Epoch[4](534/1500); Loss: 0.079989; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1836 0.1241 0.1004 0.0770 0.0712 0.0681 0.0668 0.0661 0.0655 0.0653 0.0652 0.0652 0.0651 0.0653 0.0654 0.0657 

[TRAIN] Epoch[4](535/1500); Loss: 0.084039; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1668 0.1238 0.0935 0.0812 0.0775 0.0748 0.0743 0.0734 0.0727 0.0724 0.0723 0.0721 0.0723 0.0724 0.0725 0.0724 

[TRAIN] Epoch[4](536/1500); Loss: 0.059388; Backpropagation: 0.0937 sec; Batch: 0.4368 sec
0.1008 0.0965 0.0742 0.0673 0.0599 0.0552 0.0527 0.0508 0.0500 0.0495 0.0490 0.0489 0.0487 0.0487 0.0489 0.0490 

[TRAIN] Epoch[4](537/1500); Loss: 0.114044; Backpropagation: 0.0933 sec; Batch: 0.4697 sec
0.1835 0.1429 0.1262 0.1159 0.1112 0.1079 0.1066 0.1053 0.1044 0.1038 0.1035 0.1030 0.1029 0.1027 0.1026 0.1024 

[TRAIN] Epoch[4](538/1500); Loss: 0.116472; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2028 0.1359 0.1206 0.1113 0.1099 0.1088 0.1084 0.1080 0.1078 0.1074 0.1072 0.1071 0.1071 0.1071 0.1070 0.1072 

[TRAIN] Epoch[4](539/1500); Loss: 0.064950; Backpropagation: 0.0940 sec; Batch: 0.4312 sec
0.1577 0.1020 0.0734 0.0612 0.0573 0.0547 0.0542 0.0534 0.0532 0.0529 0.0533 0.0532 0.0531 0.0530 0.0531 0.0534 

[TRAIN] Epoch[4](540/1500); Loss: 0.100709; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1829 0.1509 0.1134 0.1006 0.0943 0.0901 0.0889 0.0883 0.0882 0.0879 0.0878 0.0877 0.0877 0.0874 0.0874 0.0877 

[TRAIN] Epoch[4](541/1500); Loss: 0.100375; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2446 0.1267 0.0976 0.0916 0.0887 0.0874 0.0873 0.0871 0.0869 0.0868 0.0867 0.0866 0.0867 0.0869 0.0872 0.0873 

[TRAIN] Epoch[4](542/1500); Loss: 0.127462; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1916 0.1437 0.1313 0.1242 0.1225 0.1218 0.1213 0.1210 0.1208 0.1206 0.1203 0.1201 0.1201 0.1200 0.1201 0.1199 

[TRAIN] Epoch[4](543/1500); Loss: 0.097878; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.2416 0.1136 0.1026 0.0984 0.0900 0.0878 0.0862 0.0849 0.0840 0.0834 0.0828 0.0824 0.0822 0.0821 0.0820 0.0820 

[TRAIN] Epoch[4](544/1500); Loss: 0.175820; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.2512 0.1852 0.1777 0.1724 0.1713 0.1706 0.1706 0.1698 0.1695 0.1691 0.1685 0.1685 0.1681 0.1674 0.1669 0.1664 

[TRAIN] Epoch[4](545/1500); Loss: 0.149826; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.2549 0.1791 0.1531 0.1445 0.1426 0.1413 0.1402 0.1396 0.1390 0.1384 0.1378 0.1374 0.1374 0.1373 0.1373 0.1373 

[TRAIN] Epoch[4](546/1500); Loss: 0.100812; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1672 0.1176 0.1082 0.0967 0.0955 0.0946 0.0940 0.0934 0.0934 0.0935 0.0934 0.0931 0.0931 0.0930 0.0930 0.0930 

[TRAIN] Epoch[4](547/1500); Loss: 0.077045; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1857 0.1200 0.1053 0.0703 0.0657 0.0635 0.0625 0.0618 0.0619 0.0619 0.0619 0.0619 0.0622 0.0624 0.0628 0.0629 

[TRAIN] Epoch[4](548/1500); Loss: 0.105931; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1618 0.1299 0.1127 0.1049 0.1035 0.1016 0.1003 0.0993 0.0986 0.0982 0.0979 0.0976 0.0973 0.0972 0.0971 0.0971 

[TRAIN] Epoch[4](549/1500); Loss: 0.076691; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1071 0.0965 0.0832 0.0758 0.0743 0.0729 0.0726 0.0723 0.0721 0.0718 0.0717 0.0715 0.0714 0.0713 0.0713 0.0714 

[TRAIN] Epoch[4](550/1500); Loss: 0.100390; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1618 0.1340 0.1084 0.1029 0.0969 0.0933 0.0923 0.0916 0.0913 0.0910 0.0908 0.0905 0.0904 0.0904 0.0904 0.0904 

[TRAIN] Epoch[4](551/1500); Loss: 0.083472; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1171 0.1094 0.0961 0.0838 0.0810 0.0793 0.0782 0.0775 0.0769 0.0766 0.0766 0.0765 0.0765 0.0766 0.0767 0.0768 

[TRAIN] Epoch[4](552/1500); Loss: 0.100442; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1620 0.1197 0.1079 0.0989 0.0952 0.0937 0.0932 0.0931 0.0930 0.0929 0.0930 0.0931 0.0930 0.0929 0.0928 0.0928 

[TRAIN] Epoch[4](553/1500); Loss: 0.140668; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1849 0.1588 0.1430 0.1396 0.1376 0.1368 0.1362 0.1358 0.1356 0.1353 0.1350 0.1347 0.1345 0.1344 0.1342 0.1342 

[TRAIN] Epoch[4](554/1500); Loss: 0.101389; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1479 0.1205 0.1120 0.1010 0.0974 0.0966 0.0960 0.0953 0.0949 0.0946 0.0944 0.0943 0.0943 0.0942 0.0944 0.0944 

[TRAIN] Epoch[4](555/1500); Loss: 0.178583; Backpropagation: 0.0960 sec; Batch: 0.4310 sec
0.2496 0.2067 0.1973 0.1675 0.1715 0.1723 0.1720 0.1710 0.1703 0.1698 0.1693 0.1685 0.1679 0.1679 0.1680 0.1677 

[TRAIN] Epoch[4](556/1500); Loss: 0.113238; Backpropagation: 0.0957 sec; Batch: 0.4294 sec
0.1696 0.1212 0.1141 0.1085 0.1093 0.1080 0.1079 0.1078 0.1080 0.1076 0.1078 0.1082 0.1083 0.1082 0.1085 0.1087 

[TRAIN] Epoch[4](557/1500); Loss: 0.045640; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.0928 0.0856 0.0541 0.0462 0.0417 0.0397 0.0387 0.0384 0.0379 0.0373 0.0367 0.0367 0.0361 0.0361 0.0361 0.0361 

[TRAIN] Epoch[4](558/1500); Loss: 0.120940; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2531 0.1488 0.1233 0.1154 0.1118 0.1099 0.1091 0.1081 0.1075 0.1071 0.1069 0.1068 0.1066 0.1067 0.1069 0.1070 

[TRAIN] Epoch[4](559/1500); Loss: 0.106541; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1930 0.1327 0.1190 0.1085 0.1035 0.1003 0.0983 0.0967 0.0956 0.0950 0.0945 0.0941 0.0936 0.0935 0.0932 0.0934 

[TRAIN] Epoch[4](560/1500); Loss: 0.084455; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1373 0.1039 0.0867 0.0829 0.0798 0.0790 0.0785 0.0784 0.0784 0.0785 0.0784 0.0780 0.0778 0.0778 0.0781 0.0780 

[TRAIN] Epoch[4](561/1500); Loss: 0.044670; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.0937 0.0718 0.0588 0.0433 0.0422 0.0392 0.0377 0.0367 0.0366 0.0364 0.0362 0.0362 0.0362 0.0363 0.0365 0.0368 

[TRAIN] Epoch[4](562/1500); Loss: 0.071294; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1308 0.0957 0.0806 0.0730 0.0689 0.0658 0.0646 0.0637 0.0631 0.0627 0.0624 0.0621 0.0619 0.0618 0.0618 0.0618 

[TRAIN] Epoch[4](563/1500); Loss: 0.078385; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1155 0.1070 0.0898 0.0797 0.0770 0.0747 0.0732 0.0719 0.0711 0.0707 0.0704 0.0704 0.0704 0.0706 0.0708 0.0710 

[TRAIN] Epoch[4](564/1500); Loss: 0.102358; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1435 0.1198 0.1063 0.1010 0.0996 0.0985 0.0979 0.0974 0.0971 0.0969 0.0967 0.0966 0.0965 0.0965 0.0966 0.0967 

[TRAIN] Epoch[4](565/1500); Loss: 0.116256; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1669 0.1495 0.1274 0.1176 0.1140 0.1112 0.1102 0.1088 0.1082 0.1076 0.1072 0.1068 0.1065 0.1062 0.1060 0.1058 

[TRAIN] Epoch[4](566/1500); Loss: 0.078443; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1422 0.1054 0.0839 0.0802 0.0747 0.0727 0.0712 0.0706 0.0698 0.0693 0.0690 0.0689 0.0689 0.0691 0.0693 0.0697 

[TRAIN] Epoch[4](567/1500); Loss: 0.118114; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.2308 0.1566 0.1220 0.1149 0.1107 0.1088 0.1071 0.1060 0.1054 0.1049 0.1044 0.1040 0.1037 0.1036 0.1036 0.1034 

[TRAIN] Epoch[4](568/1500); Loss: 0.093822; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2086 0.1116 0.0953 0.0948 0.0871 0.0854 0.0841 0.0830 0.0825 0.0820 0.0817 0.0814 0.0809 0.0807 0.0810 0.0811 

[TRAIN] Epoch[4](569/1500); Loss: 0.086221; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1704 0.0993 0.0936 0.0845 0.0808 0.0794 0.0786 0.0778 0.0773 0.0772 0.0770 0.0769 0.0768 0.0767 0.0766 0.0765 

[TRAIN] Epoch[4](570/1500); Loss: 0.058808; Backpropagation: 0.0931 sec; Batch: 0.4324 sec
0.1295 0.0809 0.0698 0.0574 0.0544 0.0525 0.0517 0.0509 0.0502 0.0498 0.0494 0.0492 0.0490 0.0488 0.0487 0.0488 

[TRAIN] Epoch[4](571/1500); Loss: 0.084903; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.2023 0.1093 0.0925 0.0817 0.0768 0.0749 0.0737 0.0726 0.0721 0.0719 0.0717 0.0715 0.0716 0.0717 0.0719 0.0722 

[TRAIN] Epoch[4](572/1500); Loss: 0.063495; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.1943 0.0715 0.0684 0.0612 0.0549 0.0532 0.0523 0.0518 0.0512 0.0510 0.0510 0.0508 0.0509 0.0509 0.0512 0.0514 

[TRAIN] Epoch[4](573/1500); Loss: 0.139119; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.2086 0.1557 0.1417 0.1361 0.1338 0.1331 0.1325 0.1324 0.1321 0.1319 0.1316 0.1315 0.1313 0.1314 0.1312 0.1311 

[TRAIN] Epoch[4](574/1500); Loss: 0.105353; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.1545 0.1313 0.1111 0.1037 0.1010 0.1000 0.0996 0.0992 0.0989 0.0986 0.0983 0.0981 0.0981 0.0979 0.0977 0.0976 

[TRAIN] Epoch[4](575/1500); Loss: 0.130998; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1804 0.1394 0.1327 0.1292 0.1272 0.1264 0.1259 0.1255 0.1254 0.1254 0.1255 0.1258 0.1261 0.1265 0.1270 0.1275 

[TRAIN] Epoch[4](576/1500); Loss: 0.045456; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.0711 0.0722 0.0555 0.0454 0.0426 0.0414 0.0407 0.0401 0.0397 0.0395 0.0396 0.0396 0.0397 0.0399 0.0400 0.0403 

[TRAIN] Epoch[4](577/1500); Loss: 0.116359; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1497 0.1449 0.1272 0.1198 0.1149 0.1126 0.1115 0.1108 0.1101 0.1096 0.1092 0.1088 0.1085 0.1082 0.1080 0.1078 

[TRAIN] Epoch[4](578/1500); Loss: 0.117523; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1879 0.1560 0.1381 0.1196 0.1114 0.1090 0.1075 0.1066 0.1063 0.1062 0.1058 0.1053 0.1052 0.1052 0.1051 0.1050 

[TRAIN] Epoch[4](579/1500); Loss: 0.117471; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2180 0.1270 0.1116 0.1127 0.1092 0.1085 0.1085 0.1088 0.1088 0.1087 0.1089 0.1091 0.1093 0.1097 0.1100 0.1106 

[TRAIN] Epoch[4](580/1500); Loss: 0.095671; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1377 0.1166 0.0999 0.0915 0.0902 0.0896 0.0895 0.0894 0.0896 0.0899 0.0901 0.0905 0.0909 0.0914 0.0918 0.0922 

[TRAIN] Epoch[4](581/1500); Loss: 0.056936; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2373 0.0638 0.0785 0.0611 0.0479 0.0420 0.0392 0.0382 0.0378 0.0379 0.0377 0.0375 0.0376 0.0381 0.0382 0.0382 

[TRAIN] Epoch[4](582/1500); Loss: 0.105140; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1722 0.1289 0.1359 0.1076 0.1002 0.0976 0.0962 0.0951 0.0945 0.0938 0.0936 0.0934 0.0934 0.0933 0.0932 0.0934 

[TRAIN] Epoch[4](583/1500); Loss: 0.122784; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2087 0.1635 0.1258 0.1178 0.1143 0.1135 0.1126 0.1121 0.1118 0.1118 0.1118 0.1118 0.1118 0.1121 0.1124 0.1126 

[TRAIN] Epoch[4](584/1500); Loss: 0.084173; Backpropagation: 0.0938 sec; Batch: 0.4393 sec
0.2138 0.1093 0.0816 0.0764 0.0753 0.0734 0.0722 0.0716 0.0715 0.0714 0.0713 0.0713 0.0714 0.0716 0.0720 0.0724 

[TRAIN] Epoch[4](585/1500); Loss: 0.067901; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.1033 0.0774 0.0804 0.0685 0.0666 0.0649 0.0638 0.0631 0.0627 0.0624 0.0621 0.0622 0.0624 0.0622 0.0621 0.0621 

[TRAIN] Epoch[4](586/1500); Loss: 0.140750; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1880 0.1614 0.1448 0.1405 0.1386 0.1375 0.1370 0.1361 0.1352 0.1346 0.1339 0.1333 0.1329 0.1329 0.1328 0.1326 

[TRAIN] Epoch[4](587/1500); Loss: 0.131588; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2168 0.1618 0.1397 0.1287 0.1254 0.1236 0.1226 0.1219 0.1213 0.1208 0.1207 0.1205 0.1203 0.1203 0.1205 0.1205 

[TRAIN] Epoch[4](588/1500); Loss: 0.120685; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2344 0.1550 0.1352 0.1152 0.1104 0.1090 0.1081 0.1076 0.1073 0.1070 0.1068 0.1067 0.1069 0.1070 0.1072 0.1073 

[TRAIN] Epoch[4](589/1500); Loss: 0.057673; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1665 0.0815 0.0694 0.0544 0.0502 0.0480 0.0472 0.0464 0.0458 0.0452 0.0450 0.0447 0.0445 0.0444 0.0447 0.0450 

[TRAIN] Epoch[4](590/1500); Loss: 0.110204; Backpropagation: 0.0938 sec; Batch: 0.4290 sec
0.1570 0.1297 0.1167 0.1118 0.1084 0.1068 0.1058 0.1048 0.1042 0.1036 0.1032 0.1028 0.1026 0.1023 0.1019 0.1016 

[TRAIN] Epoch[4](591/1500); Loss: 0.070048; Backpropagation: 0.0936 sec; Batch: 0.4291 sec
0.0973 0.1044 0.0704 0.0685 0.0671 0.0660 0.0653 0.0647 0.0643 0.0644 0.0642 0.0642 0.0645 0.0648 0.0651 0.0657 

[TRAIN] Epoch[4](592/1500); Loss: 0.105440; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.3174 0.1397 0.1137 0.0938 0.0895 0.0877 0.0859 0.0849 0.0844 0.0841 0.0841 0.0841 0.0841 0.0843 0.0845 0.0847 

[TRAIN] Epoch[4](593/1500); Loss: 0.155396; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2034 0.1729 0.1566 0.1515 0.1512 0.1513 0.1510 0.1507 0.1503 0.1499 0.1499 0.1498 0.1496 0.1495 0.1494 0.1493 

[TRAIN] Epoch[4](594/1500); Loss: 0.145676; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2516 0.1845 0.1503 0.1408 0.1380 0.1366 0.1354 0.1345 0.1339 0.1333 0.1326 0.1322 0.1320 0.1318 0.1317 0.1316 

[TRAIN] Epoch[4](595/1500); Loss: 0.076503; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1286 0.1118 0.0852 0.0750 0.0707 0.0690 0.0684 0.0680 0.0676 0.0677 0.0680 0.0683 0.0684 0.0686 0.0692 0.0696 

[TRAIN] Epoch[4](596/1500); Loss: 0.092400; Backpropagation: 0.0940 sec; Batch: 0.4295 sec
0.2703 0.1308 0.1127 0.0855 0.0769 0.0755 0.0742 0.0738 0.0733 0.0730 0.0728 0.0724 0.0720 0.0719 0.0717 0.0716 

[TRAIN] Epoch[4](597/1500); Loss: 0.100292; Backpropagation: 0.0943 sec; Batch: 0.4295 sec
0.2298 0.1413 0.0981 0.0925 0.0892 0.0883 0.0875 0.0870 0.0865 0.0863 0.0862 0.0861 0.0862 0.0865 0.0866 0.0866 

[TRAIN] Epoch[4](598/1500); Loss: 0.122677; Backpropagation: 0.0939 sec; Batch: 0.4294 sec
0.1793 0.1356 0.1320 0.1229 0.1177 0.1169 0.1163 0.1161 0.1160 0.1158 0.1157 0.1157 0.1156 0.1158 0.1158 0.1156 

[TRAIN] Epoch[4](599/1500); Loss: 0.101046; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1536 0.1432 0.1146 0.1006 0.0960 0.0938 0.0924 0.0918 0.0915 0.0913 0.0912 0.0912 0.0911 0.0913 0.0915 0.0917 

[TRAIN] Epoch[4](600/1500); Loss: 0.098807; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1460 0.1199 0.1043 0.0997 0.0963 0.0948 0.0940 0.0933 0.0927 0.0922 0.0918 0.0914 0.0912 0.0911 0.0911 0.0911 

[TRAIN] Epoch[4](601/1500); Loss: 0.084018; Backpropagation: 0.0943 sec; Batch: 0.4285 sec
0.1294 0.1098 0.0906 0.0870 0.0815 0.0794 0.0784 0.0774 0.0769 0.0766 0.0762 0.0761 0.0763 0.0763 0.0762 0.0762 

[TRAIN] Epoch[4](602/1500); Loss: 0.066462; Backpropagation: 0.0981 sec; Batch: 0.4338 sec
0.1018 0.1272 0.0834 0.0711 0.0628 0.0578 0.0559 0.0556 0.0554 0.0553 0.0554 0.0556 0.0559 0.0563 0.0567 0.0573 

[TRAIN] Epoch[4](603/1500); Loss: 0.127101; Backpropagation: 0.0982 sec; Batch: 0.4338 sec
0.1768 0.1438 0.1338 0.1268 0.1248 0.1237 0.1228 0.1218 0.1212 0.1207 0.1202 0.1198 0.1196 0.1194 0.1193 0.1191 

[TRAIN] Epoch[4](604/1500); Loss: 0.153555; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.2472 0.1743 0.1561 0.1489 0.1471 0.1459 0.1450 0.1444 0.1442 0.1439 0.1437 0.1437 0.1436 0.1432 0.1430 0.1426 

[TRAIN] Epoch[4](605/1500); Loss: 0.124621; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.2051 0.1402 0.1299 0.1246 0.1203 0.1170 0.1162 0.1156 0.1151 0.1149 0.1151 0.1152 0.1153 0.1159 0.1165 0.1169 

[TRAIN] Epoch[4](606/1500); Loss: 0.062180; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.3301 0.0851 0.1231 0.0649 0.0501 0.0397 0.0323 0.0301 0.0295 0.0293 0.0292 0.0296 0.0298 0.0302 0.0305 0.0312 

[TRAIN] Epoch[4](607/1500); Loss: 0.081132; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1261 0.0964 0.0879 0.0806 0.0785 0.0771 0.0764 0.0759 0.0754 0.0751 0.0749 0.0748 0.0748 0.0747 0.0747 0.0746 

[TRAIN] Epoch[4](608/1500); Loss: 0.054981; Backpropagation: 0.0933 sec; Batch: 0.4287 sec
0.1024 0.0825 0.0623 0.0538 0.0518 0.0498 0.0488 0.0481 0.0478 0.0476 0.0474 0.0472 0.0473 0.0476 0.0476 0.0476 

[TRAIN] Epoch[4](609/1500); Loss: 0.095347; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.1499 0.1011 0.0963 0.0940 0.0911 0.0909 0.0904 0.0901 0.0897 0.0897 0.0898 0.0899 0.0901 0.0904 0.0908 0.0913 

[TRAIN] Epoch[4](610/1500); Loss: 0.076566; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1543 0.1113 0.0998 0.0735 0.0698 0.0677 0.0665 0.0657 0.0652 0.0647 0.0646 0.0645 0.0644 0.0644 0.0643 0.0643 

[TRAIN] Epoch[4](611/1500); Loss: 0.113409; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2032 0.1558 0.1200 0.1142 0.1081 0.1052 0.1032 0.1018 0.1011 0.1007 0.1005 0.1003 0.1002 0.1001 0.1001 0.1002 

[TRAIN] Epoch[4](612/1500); Loss: 0.110973; Backpropagation: 0.0939 sec; Batch: 0.4363 sec
0.1673 0.1273 0.1151 0.1095 0.1069 0.1059 0.1053 0.1047 0.1044 0.1042 0.1042 0.1041 0.1041 0.1042 0.1041 0.1041 

[TRAIN] Epoch[4](613/1500); Loss: 0.094037; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2139 0.1329 0.0886 0.0867 0.0847 0.0830 0.0821 0.0818 0.0816 0.0816 0.0815 0.0813 0.0814 0.0812 0.0812 0.0811 

[TRAIN] Epoch[4](614/1500); Loss: 0.073520; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.2156 0.0990 0.0790 0.0672 0.0632 0.0616 0.0605 0.0597 0.0592 0.0588 0.0586 0.0585 0.0585 0.0586 0.0590 0.0593 

[TRAIN] Epoch[4](615/1500); Loss: 0.074264; Backpropagation: 0.0940 sec; Batch: 0.4295 sec
0.1318 0.0966 0.0790 0.0715 0.0696 0.0684 0.0680 0.0676 0.0673 0.0672 0.0670 0.0669 0.0668 0.0669 0.0668 0.0669 

[TRAIN] Epoch[4](616/1500); Loss: 0.069062; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.1429 0.1101 0.0830 0.0721 0.0656 0.0623 0.0606 0.0593 0.0579 0.0571 0.0564 0.0561 0.0557 0.0554 0.0552 0.0553 

[TRAIN] Epoch[4](617/1500); Loss: 0.031020; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.0727 0.0532 0.0620 0.0354 0.0287 0.0254 0.0236 0.0222 0.0216 0.0211 0.0210 0.0212 0.0215 0.0219 0.0222 0.0227 

[TRAIN] Epoch[4](618/1500); Loss: 0.146039; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2085 0.1716 0.1446 0.1423 0.1412 0.1409 0.1402 0.1397 0.1396 0.1392 0.1388 0.1385 0.1385 0.1378 0.1375 0.1376 

[TRAIN] Epoch[4](619/1500); Loss: 0.098036; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.2188 0.1355 0.1005 0.0916 0.0896 0.0874 0.0862 0.0856 0.0851 0.0847 0.0844 0.0843 0.0840 0.0838 0.0837 0.0836 

[TRAIN] Epoch[4](620/1500); Loss: 0.131187; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1897 0.1421 0.1372 0.1303 0.1279 0.1266 0.1259 0.1252 0.1247 0.1243 0.1243 0.1242 0.1242 0.1242 0.1241 0.1241 

[TRAIN] Epoch[4](621/1500); Loss: 0.092881; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2186 0.1646 0.0926 0.0838 0.0795 0.0792 0.0785 0.0776 0.0771 0.0768 0.0766 0.0765 0.0763 0.0762 0.0761 0.0762 

[TRAIN] Epoch[4](622/1500); Loss: 0.084494; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1413 0.1036 0.0958 0.0828 0.0801 0.0784 0.0779 0.0776 0.0773 0.0769 0.0767 0.0767 0.0768 0.0767 0.0767 0.0767 

[TRAIN] Epoch[4](623/1500); Loss: 0.082656; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1170 0.0954 0.0908 0.0835 0.0813 0.0802 0.0794 0.0787 0.0781 0.0776 0.0774 0.0770 0.0768 0.0765 0.0764 0.0763 

[TRAIN] Epoch[4](624/1500); Loss: 0.098375; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1854 0.1109 0.0999 0.0928 0.0913 0.0909 0.0907 0.0906 0.0904 0.0903 0.0902 0.0903 0.0902 0.0900 0.0899 0.0900 

[TRAIN] Epoch[4](625/1500); Loss: 0.112866; Backpropagation: 0.0941 sec; Batch: 0.4368 sec
0.2100 0.1206 0.1207 0.1086 0.1090 0.1058 0.1054 0.1044 0.1042 0.1032 0.1031 0.1027 0.1029 0.1019 0.1018 0.1016 

[TRAIN] Epoch[4](626/1500); Loss: 0.111652; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1956 0.1218 0.1163 0.1118 0.1082 0.1068 0.1058 0.1048 0.1036 0.1029 0.1023 0.1018 0.1016 0.1014 0.1010 0.1008 

[TRAIN] Epoch[4](627/1500); Loss: 0.066343; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1373 0.0990 0.0723 0.0664 0.0632 0.0596 0.0586 0.0575 0.0571 0.0562 0.0560 0.0558 0.0559 0.0555 0.0556 0.0555 

[TRAIN] Epoch[4](628/1500); Loss: 0.102786; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1638 0.1303 0.1095 0.1077 0.1001 0.0975 0.0957 0.0946 0.0938 0.0933 0.0932 0.0931 0.0930 0.0930 0.0930 0.0929 

[TRAIN] Epoch[4](629/1500); Loss: 0.122876; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1604 0.1348 0.1279 0.1217 0.1207 0.1197 0.1192 0.1186 0.1183 0.1183 0.1182 0.1178 0.1176 0.1175 0.1175 0.1176 

[TRAIN] Epoch[4](630/1500); Loss: 0.109296; Backpropagation: 0.0931 sec; Batch: 0.4275 sec
0.1910 0.1448 0.1152 0.1072 0.1034 0.1018 0.1004 0.0997 0.0991 0.0986 0.0983 0.0981 0.0980 0.0979 0.0977 0.0975 

[TRAIN] Epoch[4](631/1500); Loss: 0.145362; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2010 0.1502 0.1523 0.1452 0.1428 0.1413 0.1401 0.1396 0.1394 0.1394 0.1391 0.1391 0.1392 0.1390 0.1389 0.1390 

[TRAIN] Epoch[4](632/1500); Loss: 0.045671; Backpropagation: 0.0935 sec; Batch: 0.4293 sec
0.0894 0.0454 0.0758 0.0490 0.0445 0.0410 0.0399 0.0389 0.0387 0.0388 0.0385 0.0379 0.0384 0.0382 0.0381 0.0382 

[TRAIN] Epoch[4](633/1500); Loss: 0.137302; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.1954 0.1543 0.1442 0.1356 0.1344 0.1332 0.1321 0.1311 0.1307 0.1303 0.1298 0.1296 0.1294 0.1292 0.1288 0.1286 

[TRAIN] Epoch[4](634/1500); Loss: 0.109525; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.1647 0.1241 0.1192 0.1112 0.1078 0.1053 0.1034 0.1026 0.1021 0.1019 0.1017 0.1015 0.1015 0.1016 0.1018 0.1020 

[TRAIN] Epoch[4](635/1500); Loss: 0.057067; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1722 0.0656 0.0575 0.0508 0.0486 0.0469 0.0466 0.0468 0.0470 0.0471 0.0471 0.0469 0.0472 0.0472 0.0475 0.0481 

[TRAIN] Epoch[4](636/1500); Loss: 0.135558; Backpropagation: 0.0935 sec; Batch: 0.4291 sec
0.1763 0.1715 0.1437 0.1359 0.1323 0.1300 0.1293 0.1286 0.1283 0.1282 0.1279 0.1276 0.1274 0.1273 0.1273 0.1274 

[TRAIN] Epoch[4](637/1500); Loss: 0.073547; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.1455 0.1018 0.0821 0.0696 0.0678 0.0661 0.0660 0.0650 0.0647 0.0644 0.0643 0.0639 0.0640 0.0641 0.0637 0.0639 

[TRAIN] Epoch[4](638/1500); Loss: 0.063594; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.0913 0.0930 0.0746 0.0646 0.0614 0.0596 0.0587 0.0580 0.0576 0.0574 0.0571 0.0570 0.0569 0.0568 0.0567 0.0568 

[TRAIN] Epoch[4](639/1500); Loss: 0.074764; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.0854 0.0978 0.0827 0.0764 0.0727 0.0715 0.0710 0.0709 0.0709 0.0708 0.0708 0.0708 0.0707 0.0709 0.0713 0.0715 

[TRAIN] Epoch[4](640/1500); Loss: 0.066496; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1438 0.0830 0.0720 0.0640 0.0610 0.0593 0.0588 0.0582 0.0581 0.0578 0.0578 0.0578 0.0579 0.0581 0.0581 0.0581 

[TRAIN] Epoch[4](641/1500); Loss: 0.131156; Backpropagation: 0.0933 sec; Batch: 0.4287 sec
0.1863 0.1499 0.1323 0.1265 0.1249 0.1244 0.1241 0.1248 0.1248 0.1249 0.1252 0.1256 0.1257 0.1260 0.1264 0.1267 

[TRAIN] Epoch[4](642/1500); Loss: 0.140965; Backpropagation: 0.0940 sec; Batch: 0.4294 sec
0.2035 0.1500 0.1534 0.1396 0.1359 0.1351 0.1346 0.1344 0.1340 0.1335 0.1334 0.1335 0.1336 0.1336 0.1336 0.1338 

[TRAIN] Epoch[4](643/1500); Loss: 0.079635; Backpropagation: 0.0938 sec; Batch: 0.4293 sec
0.1192 0.1055 0.0941 0.0835 0.0780 0.0751 0.0734 0.0725 0.0722 0.0718 0.0716 0.0716 0.0714 0.0715 0.0714 0.0713 

[TRAIN] Epoch[4](644/1500); Loss: 0.097065; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1924 0.1099 0.1037 0.0945 0.0909 0.0895 0.0886 0.0879 0.0875 0.0871 0.0870 0.0871 0.0869 0.0868 0.0866 0.0867 

[TRAIN] Epoch[4](645/1500); Loss: 0.130790; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.2090 0.1417 0.1411 0.1270 0.1263 0.1246 0.1244 0.1232 0.1230 0.1219 0.1218 0.1216 0.1217 0.1219 0.1220 0.1214 

[TRAIN] Epoch[4](646/1500); Loss: 0.108573; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.1643 0.1328 0.1139 0.1060 0.1043 0.1031 0.1026 0.1019 0.1015 0.1012 0.1009 0.1010 0.1008 0.1009 0.1010 0.1007 

[TRAIN] Epoch[4](647/1500); Loss: 0.085748; Backpropagation: 0.0938 sec; Batch: 0.4291 sec
0.2177 0.1329 0.0985 0.0815 0.0737 0.0717 0.0701 0.0700 0.0695 0.0692 0.0691 0.0694 0.0694 0.0695 0.0698 0.0699 

[TRAIN] Epoch[4](648/1500); Loss: 0.061839; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1002 0.0947 0.0687 0.0596 0.0575 0.0559 0.0552 0.0552 0.0549 0.0552 0.0552 0.0553 0.0550 0.0553 0.0555 0.0560 

[TRAIN] Epoch[4](649/1500); Loss: 0.102979; Backpropagation: 0.0943 sec; Batch: 0.4300 sec
0.2840 0.1091 0.1437 0.1047 0.0937 0.0868 0.0830 0.0820 0.0822 0.0820 0.0822 0.0827 0.0828 0.0829 0.0829 0.0832 

[TRAIN] Epoch[4](650/1500); Loss: 0.137829; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.2249 0.1668 0.1472 0.1344 0.1314 0.1293 0.1286 0.1281 0.1276 0.1275 0.1272 0.1267 0.1265 0.1265 0.1264 0.1262 

[TRAIN] Epoch[4](651/1500); Loss: 0.060889; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1278 0.1051 0.0697 0.0579 0.0542 0.0516 0.0510 0.0507 0.0507 0.0507 0.0505 0.0507 0.0507 0.0506 0.0510 0.0511 

[TRAIN] Epoch[4](652/1500); Loss: 0.122578; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2102 0.1418 0.1268 0.1210 0.1177 0.1160 0.1151 0.1143 0.1136 0.1130 0.1125 0.1121 0.1119 0.1117 0.1116 0.1118 

[TRAIN] Epoch[4](653/1500); Loss: 0.077199; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1309 0.0995 0.0844 0.0749 0.0722 0.0709 0.0706 0.0704 0.0701 0.0699 0.0699 0.0700 0.0701 0.0703 0.0704 0.0706 

[TRAIN] Epoch[4](654/1500); Loss: 0.097161; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2095 0.1376 0.1141 0.0926 0.0870 0.0848 0.0835 0.0826 0.0823 0.0824 0.0825 0.0828 0.0829 0.0830 0.0832 0.0837 

[TRAIN] Epoch[4](655/1500); Loss: 0.082377; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1922 0.1026 0.0846 0.0761 0.0733 0.0728 0.0719 0.0716 0.0715 0.0715 0.0714 0.0715 0.0716 0.0716 0.0718 0.0720 

[TRAIN] Epoch[4](656/1500); Loss: 0.174861; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2643 0.2068 0.1745 0.1672 0.1663 0.1660 0.1657 0.1657 0.1664 0.1663 0.1658 0.1653 0.1651 0.1646 0.1642 0.1635 

[TRAIN] Epoch[4](657/1500); Loss: 0.119367; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2217 0.1435 0.1214 0.1143 0.1117 0.1105 0.1099 0.1092 0.1090 0.1087 0.1085 0.1084 0.1084 0.1084 0.1082 0.1082 

[TRAIN] Epoch[4](658/1500); Loss: 0.073948; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2180 0.1158 0.0713 0.0640 0.0611 0.0602 0.0600 0.0596 0.0594 0.0592 0.0590 0.0590 0.0590 0.0589 0.0591 0.0595 

[TRAIN] Epoch[4](659/1500); Loss: 0.103009; Backpropagation: 0.0937 sec; Batch: 0.4293 sec
0.2132 0.1534 0.1100 0.0988 0.0948 0.0930 0.0913 0.0901 0.0894 0.0886 0.0883 0.0879 0.0876 0.0874 0.0872 0.0870 

[TRAIN] Epoch[4](660/1500); Loss: 0.133905; Backpropagation: 0.0933 sec; Batch: 0.4285 sec
0.1865 0.1532 0.1424 0.1338 0.1325 0.1306 0.1298 0.1285 0.1276 0.1267 0.1259 0.1254 0.1251 0.1249 0.1248 0.1249 

[TRAIN] Epoch[4](661/1500); Loss: 0.087310; Backpropagation: 0.0942 sec; Batch: 0.4288 sec
0.1339 0.1085 0.0917 0.0870 0.0843 0.0830 0.0822 0.0814 0.0811 0.0807 0.0805 0.0804 0.0805 0.0804 0.0805 0.0806 

[TRAIN] Epoch[4](662/1500); Loss: 0.095052; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.2349 0.1177 0.1032 0.0933 0.0877 0.0856 0.0835 0.0818 0.0807 0.0800 0.0793 0.0790 0.0786 0.0785 0.0784 0.0786 

[TRAIN] Epoch[4](663/1500); Loss: 0.106281; Backpropagation: 0.0936 sec; Batch: 0.4283 sec
0.1464 0.1133 0.1082 0.1034 0.1022 0.1019 0.1016 0.1015 0.1016 0.1018 0.1020 0.1023 0.1028 0.1032 0.1038 0.1044 

[TRAIN] Epoch[4](664/1500); Loss: 0.093764; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2083 0.1288 0.1035 0.0906 0.0853 0.0834 0.0821 0.0811 0.0806 0.0803 0.0799 0.0797 0.0793 0.0791 0.0791 0.0791 

[TRAIN] Epoch[4](665/1500); Loss: 0.140717; Backpropagation: 0.0932 sec; Batch: 0.4280 sec
0.2106 0.1786 0.1500 0.1410 0.1358 0.1339 0.1325 0.1317 0.1310 0.1303 0.1300 0.1295 0.1293 0.1290 0.1291 0.1292 

[TRAIN] Epoch[4](666/1500); Loss: 0.083534; Backpropagation: 0.0937 sec; Batch: 0.4459 sec
0.1344 0.0955 0.0904 0.0820 0.0800 0.0793 0.0788 0.0783 0.0778 0.0774 0.0772 0.0770 0.0769 0.0769 0.0771 0.0773 

[TRAIN] Epoch[4](667/1500); Loss: 0.071656; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.1320 0.1054 0.0819 0.0756 0.0697 0.0664 0.0644 0.0631 0.0620 0.0615 0.0612 0.0609 0.0606 0.0606 0.0605 0.0608 

[TRAIN] Epoch[4](668/1500); Loss: 0.102681; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2112 0.1272 0.1144 0.1040 0.0993 0.0967 0.0946 0.0931 0.0915 0.0903 0.0891 0.0881 0.0872 0.0863 0.0853 0.0847 

[TRAIN] Epoch[4](669/1500); Loss: 0.107241; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1317 0.1178 0.1108 0.1074 0.1062 0.1053 0.1047 0.1043 0.1040 0.1038 0.1037 0.1034 0.1034 0.1032 0.1031 0.1029 

[TRAIN] Epoch[4](670/1500); Loss: 0.081443; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1237 0.0997 0.0906 0.0807 0.0792 0.0778 0.0769 0.0761 0.0757 0.0754 0.0749 0.0748 0.0746 0.0745 0.0743 0.0742 

[TRAIN] Epoch[4](671/1500); Loss: 0.119345; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.2380 0.1688 0.1427 0.1278 0.1209 0.1155 0.1119 0.1084 0.1050 0.1020 0.0994 0.0972 0.0950 0.0934 0.0922 0.0913 

[TRAIN] Epoch[4](672/1500); Loss: 0.080381; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2240 0.1066 0.0884 0.0777 0.0730 0.0707 0.0687 0.0677 0.0665 0.0656 0.0648 0.0641 0.0631 0.0623 0.0617 0.0612 

[TRAIN] Epoch[4](673/1500); Loss: 0.104142; Backpropagation: 0.0950 sec; Batch: 0.4703 sec
0.2180 0.1140 0.1122 0.1019 0.0980 0.0959 0.0949 0.0942 0.0935 0.0927 0.0922 0.0919 0.0918 0.0917 0.0917 0.0917 

[TRAIN] Epoch[4](674/1500); Loss: 0.061907; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.0910 0.0875 0.0700 0.0654 0.0617 0.0596 0.0582 0.0569 0.0560 0.0554 0.0551 0.0549 0.0548 0.0546 0.0546 0.0548 

[TRAIN] Epoch[4](675/1500); Loss: 0.070037; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1602 0.0914 0.0778 0.0677 0.0644 0.0625 0.0618 0.0606 0.0599 0.0596 0.0595 0.0591 0.0591 0.0589 0.0590 0.0591 

[TRAIN] Epoch[4](676/1500); Loss: 0.102076; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1559 0.1252 0.1098 0.1045 0.1013 0.0991 0.0974 0.0959 0.0948 0.0939 0.0933 0.0928 0.0923 0.0922 0.0923 0.0925 

[TRAIN] Epoch[4](677/1500); Loss: 0.137977; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2459 0.1883 0.1513 0.1327 0.1262 0.1251 0.1235 0.1230 0.1231 0.1235 0.1238 0.1241 0.1240 0.1243 0.1244 0.1245 

[TRAIN] Epoch[4](678/1500); Loss: 0.111526; Backpropagation: 0.0940 sec; Batch: 0.4294 sec
0.1518 0.1335 0.1177 0.1111 0.1087 0.1075 0.1065 0.1062 0.1058 0.1055 0.1050 0.1049 0.1049 0.1050 0.1050 0.1052 

[TRAIN] Epoch[4](679/1500); Loss: 0.118464; Backpropagation: 0.0958 sec; Batch: 0.4311 sec
0.1586 0.1551 0.1386 0.1319 0.1271 0.1229 0.1192 0.1157 0.1125 0.1094 0.1066 0.1038 0.1015 0.0994 0.0974 0.0956 

[TRAIN] Epoch[4](680/1500); Loss: 0.117825; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.1614 0.1344 0.1229 0.1164 0.1148 0.1139 0.1135 0.1130 0.1126 0.1124 0.1122 0.1119 0.1117 0.1116 0.1114 0.1112 

[TRAIN] Epoch[4](681/1500); Loss: 0.099990; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1644 0.1248 0.1111 0.1025 0.0993 0.0969 0.0952 0.0934 0.0920 0.0909 0.0899 0.0890 0.0884 0.0878 0.0873 0.0869 

[TRAIN] Epoch[4](682/1500); Loss: 0.052445; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.0901 0.0712 0.0582 0.0533 0.0505 0.0490 0.0481 0.0476 0.0471 0.0467 0.0466 0.0464 0.0460 0.0461 0.0461 0.0461 

[TRAIN] Epoch[4](683/1500); Loss: 0.078454; Backpropagation: 0.0940 sec; Batch: 0.4474 sec
0.1433 0.0944 0.0836 0.0765 0.0733 0.0720 0.0714 0.0713 0.0712 0.0710 0.0711 0.0710 0.0710 0.0712 0.0714 0.0716 

[TRAIN] Epoch[4](684/1500); Loss: 0.102199; Backpropagation: 0.0959 sec; Batch: 0.4312 sec
0.1522 0.1167 0.1070 0.1002 0.0986 0.0974 0.0966 0.0963 0.0960 0.0958 0.0960 0.0964 0.0965 0.0964 0.0963 0.0966 

[TRAIN] Epoch[4](685/1500); Loss: 0.096920; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.2290 0.1193 0.1190 0.1003 0.0899 0.0856 0.0831 0.0826 0.0814 0.0808 0.0806 0.0801 0.0798 0.0797 0.0796 0.0798 

[TRAIN] Epoch[4](686/1500); Loss: 0.075332; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2023 0.0994 0.0849 0.0684 0.0663 0.0642 0.0639 0.0631 0.0626 0.0622 0.0619 0.0614 0.0615 0.0611 0.0612 0.0611 

[TRAIN] Epoch[4](687/1500); Loss: 0.217559; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2646 0.2392 0.2251 0.2201 0.2177 0.2162 0.2144 0.2131 0.2121 0.2114 0.2100 0.2092 0.2081 0.2073 0.2065 0.2059 

[TRAIN] Epoch[4](688/1500); Loss: 0.064206; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1452 0.0907 0.0660 0.0596 0.0583 0.0566 0.0557 0.0557 0.0550 0.0553 0.0550 0.0549 0.0547 0.0550 0.0545 0.0551 

[TRAIN] Epoch[4](689/1500); Loss: 0.137570; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.2027 0.1479 0.1449 0.1341 0.1336 0.1322 0.1317 0.1310 0.1309 0.1307 0.1303 0.1301 0.1304 0.1303 0.1301 0.1303 

[TRAIN] Epoch[4](690/1500); Loss: 0.087633; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2143 0.1121 0.0947 0.0839 0.0793 0.0774 0.0759 0.0751 0.0746 0.0741 0.0733 0.0733 0.0732 0.0734 0.0736 0.0739 

[TRAIN] Epoch[4](691/1500); Loss: 0.121480; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.2751 0.1864 0.1649 0.1315 0.1209 0.1121 0.1058 0.1009 0.0973 0.0949 0.0936 0.0924 0.0921 0.0921 0.0916 0.0920 

[TRAIN] Epoch[4](692/1500); Loss: 0.061605; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.3038 0.0676 0.1377 0.0755 0.0509 0.0334 0.0285 0.0301 0.0285 0.0291 0.0302 0.0305 0.0316 0.0353 0.0360 0.0369 

[TRAIN] Epoch[4](693/1500); Loss: 0.144736; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2069 0.1677 0.1525 0.1428 0.1409 0.1391 0.1387 0.1380 0.1373 0.1369 0.1366 0.1362 0.1359 0.1355 0.1354 0.1354 

[TRAIN] Epoch[4](694/1500); Loss: 0.038936; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.0443 0.0534 0.0421 0.0397 0.0377 0.0368 0.0363 0.0362 0.0361 0.0361 0.0363 0.0366 0.0369 0.0377 0.0382 0.0386 

[TRAIN] Epoch[4](695/1500); Loss: 0.124216; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1949 0.1605 0.1343 0.1223 0.1196 0.1174 0.1163 0.1148 0.1141 0.1135 0.1132 0.1132 0.1129 0.1133 0.1135 0.1136 

[TRAIN] Epoch[4](696/1500); Loss: 0.085421; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1339 0.1083 0.0955 0.0871 0.0838 0.0816 0.0801 0.0788 0.0784 0.0778 0.0774 0.0770 0.0768 0.0768 0.0768 0.0766 

[TRAIN] Epoch[4](697/1500); Loss: 0.109790; Backpropagation: 0.0940 sec; Batch: 0.4296 sec
0.2750 0.1561 0.1416 0.1127 0.1027 0.0976 0.0940 0.0906 0.0886 0.0869 0.0857 0.0853 0.0850 0.0851 0.0848 0.0849 

[TRAIN] Epoch[4](698/1500); Loss: 0.113283; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1542 0.1280 0.1188 0.1124 0.1114 0.1100 0.1095 0.1083 0.1079 0.1075 0.1075 0.1076 0.1073 0.1074 0.1072 0.1075 

[TRAIN] Epoch[4](699/1500); Loss: 0.070949; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1829 0.0937 0.0778 0.0672 0.0628 0.0613 0.0603 0.0596 0.0590 0.0587 0.0589 0.0585 0.0586 0.0585 0.0588 0.0586 

[TRAIN] Epoch[4](700/1500); Loss: 0.129358; Backpropagation: 0.0943 sec; Batch: 0.4298 sec
0.1998 0.1538 0.1425 0.1296 0.1258 0.1230 0.1213 0.1202 0.1197 0.1195 0.1193 0.1192 0.1190 0.1189 0.1190 0.1192 

[TRAIN] Epoch[4](701/1500); Loss: 0.083199; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.2121 0.1055 0.0922 0.0778 0.0742 0.0723 0.0712 0.0704 0.0699 0.0698 0.0693 0.0691 0.0692 0.0694 0.0693 0.0695 

[TRAIN] Epoch[4](702/1500); Loss: 0.129205; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.2497 0.1962 0.1567 0.1318 0.1212 0.1161 0.1128 0.1118 0.1104 0.1091 0.1089 0.1087 0.1085 0.1083 0.1085 0.1084 

[TRAIN] Epoch[4](703/1500); Loss: 0.053209; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1437 0.0667 0.0613 0.0472 0.0465 0.0450 0.0441 0.0439 0.0439 0.0442 0.0443 0.0441 0.0438 0.0440 0.0441 0.0444 

[TRAIN] Epoch[4](704/1500); Loss: 0.070274; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.1006 0.0973 0.0786 0.0698 0.0679 0.0664 0.0657 0.0648 0.0646 0.0643 0.0638 0.0640 0.0642 0.0638 0.0643 0.0643 

[TRAIN] Epoch[4](705/1500); Loss: 0.119020; Backpropagation: 0.0942 sec; Batch: 0.4289 sec
0.1415 0.1309 0.1228 0.1228 0.1207 0.1185 0.1176 0.1167 0.1157 0.1149 0.1146 0.1142 0.1139 0.1134 0.1132 0.1130 

[TRAIN] Epoch[4](706/1500); Loss: 0.064860; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2002 0.1248 0.0740 0.0563 0.0544 0.0497 0.0474 0.0483 0.0470 0.0474 0.0480 0.0479 0.0477 0.0478 0.0482 0.0486 

[TRAIN] Epoch[4](707/1500); Loss: 0.138401; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.2137 0.1763 0.1571 0.1411 0.1368 0.1334 0.1302 0.1281 0.1266 0.1256 0.1248 0.1245 0.1242 0.1242 0.1239 0.1241 

[TRAIN] Epoch[4](708/1500); Loss: 0.063386; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1943 0.0731 0.0722 0.0577 0.0566 0.0534 0.0521 0.0509 0.0505 0.0500 0.0502 0.0503 0.0504 0.0508 0.0507 0.0510 

[TRAIN] Epoch[4](709/1500); Loss: 0.104421; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.3024 0.1761 0.1232 0.0900 0.0891 0.0847 0.0816 0.0803 0.0803 0.0804 0.0805 0.0802 0.0803 0.0803 0.0809 0.0805 

[TRAIN] Epoch[4](710/1500); Loss: 0.105162; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2019 0.1342 0.1127 0.1048 0.0966 0.0953 0.0941 0.0942 0.0935 0.0932 0.0932 0.0936 0.0933 0.0937 0.0939 0.0945 

[TRAIN] Epoch[4](711/1500); Loss: 0.074326; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.3753 0.1401 0.0579 0.0541 0.0526 0.0526 0.0492 0.0473 0.0475 0.0460 0.0457 0.0441 0.0442 0.0442 0.0442 0.0441 

[TRAIN] Epoch[4](712/1500); Loss: 0.071610; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.3398 0.1131 0.0672 0.0551 0.0550 0.0516 0.0487 0.0479 0.0470 0.0463 0.0458 0.0455 0.0453 0.0456 0.0459 0.0458 

[TRAIN] Epoch[4](713/1500); Loss: 0.075120; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1188 0.0988 0.0831 0.0762 0.0731 0.0702 0.0689 0.0681 0.0676 0.0675 0.0678 0.0679 0.0681 0.0684 0.0685 0.0689 

[TRAIN] Epoch[4](714/1500); Loss: 0.128682; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2531 0.1714 0.1444 0.1224 0.1190 0.1192 0.1156 0.1139 0.1134 0.1129 0.1125 0.1124 0.1124 0.1120 0.1121 0.1122 

[TRAIN] Epoch[4](715/1500); Loss: 0.137981; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1919 0.1542 0.1457 0.1394 0.1356 0.1336 0.1324 0.1315 0.1311 0.1307 0.1307 0.1307 0.1305 0.1302 0.1300 0.1296 

[TRAIN] Epoch[4](716/1500); Loss: 0.093347; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1323 0.1131 0.1055 0.0961 0.0924 0.0901 0.0884 0.0874 0.0868 0.0863 0.0860 0.0858 0.0857 0.0858 0.0859 0.0860 

[TRAIN] Epoch[4](717/1500); Loss: 0.074990; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.2005 0.0843 0.0841 0.0711 0.0684 0.0653 0.0633 0.0630 0.0622 0.0623 0.0619 0.0621 0.0626 0.0626 0.0628 0.0634 

[TRAIN] Epoch[4](718/1500); Loss: 0.084302; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2058 0.1366 0.1042 0.0819 0.0739 0.0721 0.0700 0.0686 0.0676 0.0674 0.0672 0.0667 0.0667 0.0668 0.0666 0.0669 

[TRAIN] Epoch[4](719/1500); Loss: 0.104737; Backpropagation: 0.0945 sec; Batch: 0.4295 sec
0.1560 0.1237 0.1109 0.1050 0.1035 0.1021 0.0999 0.0977 0.0974 0.0973 0.0971 0.0968 0.0970 0.0970 0.0971 0.0971 

[TRAIN] Epoch[4](720/1500); Loss: 0.111311; Backpropagation: 0.0982 sec; Batch: 0.4333 sec
0.1949 0.1395 0.1238 0.1118 0.1092 0.1077 0.1037 0.1018 0.1004 0.0993 0.0982 0.0978 0.0977 0.0981 0.0983 0.0988 

[TRAIN] Epoch[4](721/1500); Loss: 0.132634; Backpropagation: 0.0961 sec; Batch: 0.4317 sec
0.2630 0.1629 0.1413 0.1244 0.1233 0.1224 0.1198 0.1185 0.1181 0.1179 0.1178 0.1180 0.1182 0.1185 0.1189 0.1191 

[TRAIN] Epoch[4](722/1500); Loss: 0.082848; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2285 0.1533 0.1135 0.0779 0.0738 0.0650 0.0630 0.0605 0.0607 0.0604 0.0608 0.0606 0.0614 0.0616 0.0619 0.0626 

[TRAIN] Epoch[4](723/1500); Loss: 0.144591; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.3090 0.1994 0.1557 0.1392 0.1312 0.1279 0.1270 0.1257 0.1253 0.1252 0.1248 0.1245 0.1242 0.1248 0.1247 0.1248 

[TRAIN] Epoch[4](724/1500); Loss: 0.084121; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.2208 0.1148 0.0840 0.0764 0.0719 0.0715 0.0701 0.0697 0.0697 0.0702 0.0702 0.0703 0.0707 0.0713 0.0719 0.0724 

[TRAIN] Epoch[4](725/1500); Loss: 0.146746; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.2869 0.1780 0.1490 0.1398 0.1373 0.1345 0.1333 0.1328 0.1328 0.1324 0.1322 0.1321 0.1319 0.1315 0.1316 0.1318 

[TRAIN] Epoch[4](726/1500); Loss: 0.121026; Backpropagation: 0.0958 sec; Batch: 0.4328 sec
0.1931 0.1574 0.1285 0.1142 0.1149 0.1132 0.1126 0.1113 0.1111 0.1110 0.1113 0.1110 0.1112 0.1117 0.1119 0.1120 

[TRAIN] Epoch[4](727/1500); Loss: 0.133146; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1703 0.1412 0.1363 0.1323 0.1309 0.1300 0.1295 0.1293 0.1291 0.1290 0.1291 0.1289 0.1288 0.1286 0.1285 0.1285 

[TRAIN] Epoch[4](728/1500); Loss: 0.095449; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1212 0.1206 0.1038 0.0983 0.0943 0.0913 0.0893 0.0893 0.0891 0.0883 0.0889 0.0902 0.0897 0.0902 0.0911 0.0916 

[TRAIN] Epoch[4](729/1500); Loss: 0.133873; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2664 0.1736 0.1370 0.1221 0.1211 0.1206 0.1194 0.1191 0.1189 0.1194 0.1197 0.1202 0.1205 0.1208 0.1213 0.1219 

[TRAIN] Epoch[4](730/1500); Loss: 0.064522; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1594 0.0957 0.0672 0.0580 0.0585 0.0572 0.0541 0.0534 0.0537 0.0537 0.0536 0.0533 0.0535 0.0538 0.0535 0.0538 

[TRAIN] Epoch[4](731/1500); Loss: 0.081398; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.2344 0.1469 0.1068 0.0772 0.0679 0.0679 0.0632 0.0622 0.0609 0.0602 0.0596 0.0593 0.0588 0.0590 0.0590 0.0590 

[TRAIN] Epoch[4](732/1500); Loss: 0.084877; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1891 0.1001 0.0892 0.0795 0.0776 0.0757 0.0748 0.0745 0.0748 0.0745 0.0744 0.0747 0.0741 0.0748 0.0752 0.0751 

[TRAIN] Epoch[4](733/1500); Loss: 0.143858; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1771 0.1582 0.1488 0.1444 0.1423 0.1413 0.1404 0.1397 0.1391 0.1388 0.1387 0.1385 0.1387 0.1387 0.1386 0.1386 

[TRAIN] Epoch[4](734/1500); Loss: 0.112600; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.2037 0.1338 0.1137 0.1098 0.1083 0.1059 0.1040 0.1030 0.1027 0.1027 0.1024 0.1022 0.1021 0.1023 0.1023 0.1027 

[TRAIN] Epoch[4](735/1500); Loss: 0.062450; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.0898 0.0917 0.0688 0.0627 0.0595 0.0578 0.0570 0.0566 0.0564 0.0566 0.0565 0.0566 0.0566 0.0570 0.0577 0.0580 

[TRAIN] Epoch[4](736/1500); Loss: 0.089925; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1275 0.1177 0.0991 0.0910 0.0882 0.0861 0.0848 0.0839 0.0838 0.0834 0.0828 0.0823 0.0823 0.0821 0.0818 0.0819 

[TRAIN] Epoch[4](737/1500); Loss: 0.087828; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1581 0.0974 0.0907 0.0857 0.0825 0.0821 0.0817 0.0814 0.0812 0.0811 0.0806 0.0802 0.0808 0.0806 0.0806 0.0806 

[TRAIN] Epoch[4](738/1500); Loss: 0.076131; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.1242 0.1047 0.0861 0.0769 0.0719 0.0695 0.0698 0.0688 0.0680 0.0682 0.0684 0.0683 0.0681 0.0682 0.0686 0.0684 

[TRAIN] Epoch[4](739/1500); Loss: 0.117466; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1776 0.1414 0.1268 0.1148 0.1127 0.1113 0.1105 0.1102 0.1101 0.1097 0.1097 0.1091 0.1088 0.1089 0.1089 0.1090 

[TRAIN] Epoch[4](740/1500); Loss: 0.077313; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1973 0.1199 0.0850 0.0730 0.0652 0.0654 0.0648 0.0638 0.0628 0.0626 0.0621 0.0627 0.0626 0.0628 0.0629 0.0640 

[TRAIN] Epoch[4](741/1500); Loss: 0.082253; Backpropagation: 0.0945 sec; Batch: 0.4286 sec
0.1235 0.0924 0.0858 0.0853 0.0800 0.0795 0.0785 0.0775 0.0772 0.0769 0.0766 0.0762 0.0763 0.0767 0.0768 0.0768 

[TRAIN] Epoch[4](742/1500); Loss: 0.089703; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1752 0.1202 0.0978 0.0864 0.0836 0.0815 0.0811 0.0802 0.0802 0.0786 0.0784 0.0784 0.0790 0.0783 0.0782 0.0782 

[TRAIN] Epoch[4](743/1500); Loss: 0.073552; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.0762 0.0961 0.0786 0.0725 0.0717 0.0707 0.0701 0.0698 0.0705 0.0709 0.0708 0.0708 0.0716 0.0721 0.0720 0.0724 

[TRAIN] Epoch[4](744/1500); Loss: 0.093656; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1908 0.1333 0.0993 0.0877 0.0850 0.0850 0.0836 0.0832 0.0823 0.0816 0.0812 0.0812 0.0812 0.0810 0.0810 0.0810 

[TRAIN] Epoch[4](745/1500); Loss: 0.134270; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.2280 0.1605 0.1407 0.1315 0.1282 0.1259 0.1252 0.1243 0.1240 0.1233 0.1228 0.1225 0.1227 0.1227 0.1230 0.1229 

[TRAIN] Epoch[4](746/1500); Loss: 0.089063; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1715 0.1177 0.0989 0.0917 0.0825 0.0813 0.0795 0.0784 0.0773 0.0778 0.0771 0.0773 0.0774 0.0784 0.0787 0.0795 

[TRAIN] Epoch[4](747/1500); Loss: 0.064182; Backpropagation: 0.0942 sec; Batch: 0.4282 sec
0.1349 0.0872 0.0697 0.0621 0.0637 0.0576 0.0555 0.0543 0.0557 0.0547 0.0542 0.0542 0.0551 0.0552 0.0562 0.0567 

[TRAIN] Epoch[4](748/1500); Loss: 0.121131; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1405 0.1466 0.1250 0.1275 0.1195 0.1193 0.1176 0.1168 0.1158 0.1156 0.1152 0.1157 0.1153 0.1156 0.1156 0.1163 

[TRAIN] Epoch[4](749/1500); Loss: 0.101230; Backpropagation: 0.0982 sec; Batch: 0.4332 sec
0.1498 0.1213 0.1077 0.1075 0.0975 0.0954 0.0930 0.0933 0.0934 0.0934 0.0932 0.0937 0.0942 0.0952 0.0953 0.0960 

[TRAIN] Epoch[4](750/1500); Loss: 0.086271; Backpropagation: 0.0983 sec; Batch: 0.4323 sec
0.1852 0.1043 0.0821 0.0867 0.0833 0.0793 0.0763 0.0749 0.0740 0.0746 0.0750 0.0759 0.0760 0.0771 0.0777 0.0780 

[TRAIN] Epoch[4](751/1500); Loss: 0.123247; Backpropagation: 0.0942 sec; Batch: 0.4280 sec
0.2102 0.1491 0.1237 0.1186 0.1146 0.1161 0.1142 0.1133 0.1128 0.1130 0.1132 0.1138 0.1141 0.1147 0.1150 0.1155 

[TRAIN] Epoch[4](752/1500); Loss: 0.092914; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1210 0.0977 0.0932 0.0916 0.0896 0.0898 0.0892 0.0893 0.0893 0.0894 0.0897 0.0906 0.0910 0.0913 0.0917 0.0923 

[TRAIN] Epoch[4](753/1500); Loss: 0.101016; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1458 0.1125 0.0996 0.1031 0.0982 0.0967 0.0951 0.0958 0.0955 0.0955 0.0955 0.0959 0.0958 0.0967 0.0968 0.0977 

[TRAIN] Epoch[4](754/1500); Loss: 0.164257; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1936 0.1698 0.1656 0.1667 0.1633 0.1627 0.1614 0.1611 0.1605 0.1601 0.1600 0.1603 0.1602 0.1607 0.1610 0.1610 

[TRAIN] Epoch[4](755/1500); Loss: 0.117770; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1924 0.1283 0.1138 0.1142 0.1088 0.1114 0.1096 0.1101 0.1098 0.1102 0.1105 0.1116 0.1121 0.1130 0.1138 0.1149 

[TRAIN] Epoch[4](756/1500); Loss: 0.067573; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.0747 0.0844 0.0706 0.0662 0.0647 0.0643 0.0648 0.0642 0.0640 0.0641 0.0647 0.0650 0.0659 0.0670 0.0679 0.0686 

[TRAIN] Epoch[4](757/1500); Loss: 0.146110; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1791 0.1619 0.1503 0.1483 0.1439 0.1434 0.1418 0.1409 0.1402 0.1404 0.1403 0.1406 0.1409 0.1414 0.1420 0.1426 

[TRAIN] Epoch[4](758/1500); Loss: 0.133377; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1587 0.1458 0.1388 0.1404 0.1339 0.1326 0.1307 0.1297 0.1288 0.1286 0.1280 0.1277 0.1274 0.1274 0.1275 0.1281 

[TRAIN] Epoch[4](759/1500); Loss: 0.068429; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2136 0.0794 0.0598 0.0781 0.0559 0.0714 0.0579 0.0530 0.0480 0.0507 0.0513 0.0527 0.0528 0.0551 0.0562 0.0590 

[TRAIN] Epoch[4](760/1500); Loss: 0.093311; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1302 0.1120 0.1012 0.1004 0.0943 0.0918 0.0894 0.0883 0.0870 0.0865 0.0855 0.0854 0.0850 0.0850 0.0851 0.0859 

[TRAIN] Epoch[4](761/1500); Loss: 0.052250; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.0727 0.0550 0.0730 0.0491 0.0510 0.0446 0.0460 0.0454 0.0469 0.0467 0.0478 0.0483 0.0515 0.0517 0.0527 0.0536 

[TRAIN] Epoch[4](762/1500); Loss: 0.182960; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.2443 0.1965 0.1856 0.1754 0.1773 0.1775 0.1782 0.1777 0.1776 0.1768 0.1770 0.1767 0.1767 0.1767 0.1768 0.1768 

[TRAIN] Epoch[4](763/1500); Loss: 0.122152; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1465 0.1362 0.1215 0.1310 0.1208 0.1197 0.1175 0.1173 0.1169 0.1173 0.1171 0.1176 0.1178 0.1187 0.1190 0.1197 

[TRAIN] Epoch[4](764/1500); Loss: 0.072503; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1703 0.1187 0.0859 0.0783 0.0686 0.0650 0.0620 0.0603 0.0579 0.0576 0.0564 0.0558 0.0550 0.0562 0.0559 0.0562 

[TRAIN] Epoch[4](765/1500); Loss: 0.104506; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1762 0.1303 0.1097 0.1105 0.1008 0.1007 0.0971 0.0964 0.0949 0.0942 0.0934 0.0933 0.0933 0.0938 0.0935 0.0940 

[TRAIN] Epoch[4](766/1500); Loss: 0.092349; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1717 0.1248 0.0960 0.0893 0.0862 0.0844 0.0831 0.0832 0.0828 0.0825 0.0819 0.0820 0.0820 0.0825 0.0826 0.0828 

[TRAIN] Epoch[4](767/1500); Loss: 0.096727; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1593 0.0997 0.0944 0.0912 0.0925 0.0923 0.0911 0.0910 0.0901 0.0907 0.0910 0.0917 0.0918 0.0929 0.0934 0.0945 

[TRAIN] Epoch[4](768/1500); Loss: 0.117134; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1768 0.1356 0.1209 0.1163 0.1131 0.1101 0.1100 0.1096 0.1097 0.1095 0.1098 0.1097 0.1102 0.1105 0.1109 0.1114 

[TRAIN] Epoch[4](769/1500); Loss: 0.069262; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1141 0.0867 0.0697 0.0801 0.0677 0.0671 0.0629 0.0623 0.0604 0.0617 0.0611 0.0619 0.0617 0.0632 0.0633 0.0643 

[TRAIN] Epoch[4](770/1500); Loss: 0.102398; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1507 0.1131 0.1005 0.1092 0.0992 0.1012 0.0977 0.0964 0.0951 0.0953 0.0951 0.0963 0.0964 0.0969 0.0972 0.0980 

[TRAIN] Epoch[4](771/1500); Loss: 0.120973; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2856 0.1748 0.1255 0.1078 0.1107 0.1095 0.1059 0.1046 0.1028 0.1017 0.1010 0.1005 0.1005 0.1010 0.1015 0.1023 

[TRAIN] Epoch[4](772/1500); Loss: 0.065294; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.0885 0.0654 0.0615 0.0674 0.0694 0.0632 0.0601 0.0592 0.0601 0.0608 0.0628 0.0627 0.0637 0.0650 0.0671 0.0678 

[TRAIN] Epoch[4](773/1500); Loss: 0.086340; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1122 0.0981 0.0859 0.0922 0.0848 0.0839 0.0819 0.0821 0.0817 0.0821 0.0818 0.0820 0.0821 0.0832 0.0833 0.0840 

[TRAIN] Epoch[4](774/1500); Loss: 0.089142; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1336 0.1023 0.0917 0.1001 0.0876 0.0911 0.0861 0.0842 0.0817 0.0812 0.0804 0.0810 0.0804 0.0815 0.0813 0.0820 

[TRAIN] Epoch[4](775/1500); Loss: 0.067971; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2449 0.0812 0.0728 0.0525 0.0863 0.0651 0.0515 0.0444 0.0478 0.0456 0.0457 0.0468 0.0494 0.0498 0.0512 0.0526 

[TRAIN] Epoch[4](776/1500); Loss: 0.054000; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1200 0.0766 0.0634 0.0498 0.0447 0.0456 0.0439 0.0453 0.0449 0.0460 0.0458 0.0463 0.0466 0.0477 0.0483 0.0490 

[TRAIN] Epoch[4](777/1500); Loss: 0.058847; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1096 0.0800 0.0631 0.0541 0.0541 0.0524 0.0520 0.0513 0.0523 0.0520 0.0522 0.0524 0.0534 0.0537 0.0543 0.0547 

[TRAIN] Epoch[4](778/1500); Loss: 0.149777; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1908 0.1620 0.1651 0.1505 0.1486 0.1441 0.1441 0.1432 0.1436 0.1431 0.1434 0.1431 0.1438 0.1433 0.1439 0.1439 

[TRAIN] Epoch[4](779/1500); Loss: 0.091650; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1929 0.1422 0.0968 0.0768 0.0827 0.0777 0.0771 0.0773 0.0786 0.0784 0.0788 0.0798 0.0814 0.0813 0.0816 0.0830 

[TRAIN] Epoch[4](780/1500); Loss: 0.083973; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1797 0.1066 0.0835 0.0822 0.0771 0.0763 0.0745 0.0747 0.0739 0.0735 0.0732 0.0735 0.0733 0.0738 0.0737 0.0739 

[TRAIN] Epoch[4](781/1500); Loss: 0.131722; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1587 0.1375 0.1319 0.1326 0.1291 0.1291 0.1281 0.1283 0.1280 0.1280 0.1281 0.1285 0.1290 0.1294 0.1303 0.1309 

[TRAIN] Epoch[4](782/1500); Loss: 0.085994; Backpropagation: 0.0945 sec; Batch: 0.4290 sec
0.1746 0.1115 0.0849 0.0882 0.0899 0.0808 0.0815 0.0771 0.0752 0.0734 0.0737 0.0730 0.0726 0.0726 0.0734 0.0736 

[TRAIN] Epoch[4](783/1500); Loss: 0.082829; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.2009 0.1369 0.0862 0.0710 0.0690 0.0670 0.0663 0.0671 0.0679 0.0680 0.0687 0.0697 0.0705 0.0711 0.0719 0.0730 

[TRAIN] Epoch[4](784/1500); Loss: 0.037026; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.0763 0.0528 0.0436 0.0352 0.0339 0.0321 0.0312 0.0303 0.0302 0.0306 0.0309 0.0314 0.0323 0.0329 0.0340 0.0348 

[TRAIN] Epoch[4](785/1500); Loss: 0.090756; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1360 0.1046 0.0924 0.0964 0.0880 0.0898 0.0874 0.0867 0.0852 0.0847 0.0837 0.0835 0.0831 0.0834 0.0834 0.0838 

[TRAIN] Epoch[4](786/1500); Loss: 0.133187; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.2206 0.1826 0.1518 0.1372 0.1256 0.1221 0.1196 0.1194 0.1188 0.1186 0.1184 0.1185 0.1189 0.1192 0.1196 0.1200 

[TRAIN] Epoch[4](787/1500); Loss: 0.073875; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1883 0.1225 0.0763 0.0652 0.0615 0.0603 0.0593 0.0596 0.0590 0.0598 0.0597 0.0612 0.0612 0.0620 0.0624 0.0638 

[TRAIN] Epoch[4](788/1500); Loss: 0.051602; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.0614 0.0673 0.0554 0.0508 0.0532 0.0501 0.0488 0.0486 0.0487 0.0482 0.0483 0.0482 0.0486 0.0488 0.0495 0.0497 

[TRAIN] Epoch[4](789/1500); Loss: 0.101564; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2042 0.1313 0.1037 0.0979 0.0913 0.0947 0.0914 0.0916 0.0903 0.0897 0.0892 0.0895 0.0895 0.0900 0.0902 0.0907 

[TRAIN] Epoch[4](790/1500); Loss: 0.153684; Backpropagation: 0.0958 sec; Batch: 0.4305 sec
0.1942 0.1733 0.1572 0.1533 0.1502 0.1494 0.1483 0.1483 0.1481 0.1480 0.1480 0.1479 0.1482 0.1483 0.1483 0.1481 

[TRAIN] Epoch[4](791/1500); Loss: 0.085051; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.2361 0.1278 0.0747 0.0769 0.0731 0.0697 0.0725 0.0701 0.0692 0.0682 0.0696 0.0691 0.0703 0.0699 0.0720 0.0714 

[TRAIN] Epoch[4](792/1500); Loss: 0.146317; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.2164 0.1773 0.1517 0.1488 0.1426 0.1398 0.1383 0.1372 0.1365 0.1364 0.1359 0.1362 0.1359 0.1360 0.1359 0.1362 

[TRAIN] Epoch[4](793/1500); Loss: 0.127750; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2282 0.1585 0.1292 0.1316 0.1254 0.1223 0.1192 0.1180 0.1162 0.1151 0.1140 0.1139 0.1131 0.1134 0.1129 0.1130 

[TRAIN] Epoch[4](794/1500); Loss: 0.078949; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1321 0.1303 0.0915 0.0991 0.0776 0.0741 0.0675 0.0685 0.0652 0.0661 0.0637 0.0655 0.0639 0.0663 0.0651 0.0666 

[TRAIN] Epoch[4](795/1500); Loss: 0.052918; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.0671 0.0651 0.0584 0.0558 0.0545 0.0522 0.0513 0.0497 0.0496 0.0489 0.0486 0.0483 0.0490 0.0489 0.0495 0.0497 

[TRAIN] Epoch[4](796/1500); Loss: 0.050689; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.0867 0.0726 0.0485 0.0737 0.0460 0.0562 0.0464 0.0441 0.0411 0.0415 0.0405 0.0424 0.0419 0.0426 0.0425 0.0443 

[TRAIN] Epoch[4](797/1500); Loss: 0.155554; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2119 0.1712 0.1606 0.1588 0.1548 0.1528 0.1509 0.1500 0.1492 0.1482 0.1476 0.1471 0.1468 0.1466 0.1464 0.1461 

[TRAIN] Epoch[4](798/1500); Loss: 0.081542; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1806 0.1090 0.0763 0.0810 0.0742 0.0724 0.0744 0.0723 0.0710 0.0703 0.0701 0.0704 0.0704 0.0706 0.0707 0.0710 

[TRAIN] Epoch[4](799/1500); Loss: 0.122977; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1501 0.1359 0.1257 0.1276 0.1224 0.1211 0.1199 0.1191 0.1188 0.1188 0.1184 0.1183 0.1183 0.1179 0.1177 0.1176 

[TRAIN] Epoch[4](800/1500); Loss: 0.093546; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1502 0.0992 0.1016 0.0969 0.0897 0.0953 0.0907 0.0885 0.0865 0.0860 0.0856 0.0857 0.0853 0.0852 0.0851 0.0852 

[TRAIN] Epoch[4](801/1500); Loss: 0.055383; Backpropagation: 0.0936 sec; Batch: 0.4289 sec
0.0758 0.0622 0.0703 0.0568 0.0558 0.0520 0.0519 0.0508 0.0512 0.0507 0.0508 0.0506 0.0516 0.0516 0.0519 0.0523 

[TRAIN] Epoch[4](802/1500); Loss: 0.051141; Backpropagation: 0.0982 sec; Batch: 0.4335 sec
0.0838 0.0709 0.0528 0.0556 0.0488 0.0477 0.0463 0.0457 0.0452 0.0453 0.0452 0.0458 0.0459 0.0461 0.0464 0.0468 

[TRAIN] Epoch[4](803/1500); Loss: 0.045765; Backpropagation: 0.0944 sec; Batch: 0.4293 sec
0.0879 0.0690 0.0526 0.0439 0.0416 0.0409 0.0404 0.0400 0.0394 0.0395 0.0391 0.0392 0.0394 0.0396 0.0396 0.0401 

[TRAIN] Epoch[4](804/1500); Loss: 0.055281; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.0858 0.0796 0.0725 0.0573 0.0541 0.0504 0.0492 0.0481 0.0483 0.0482 0.0483 0.0479 0.0483 0.0488 0.0486 0.0491 

[TRAIN] Epoch[4](805/1500); Loss: 0.063644; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2833 0.1296 0.0444 0.0585 0.0531 0.0446 0.0460 0.0420 0.0419 0.0400 0.0389 0.0382 0.0396 0.0391 0.0397 0.0393 

[TRAIN] Epoch[4](806/1500); Loss: 0.147721; Backpropagation: 0.0941 sec; Batch: 0.4413 sec
0.2206 0.1818 0.1532 0.1536 0.1462 0.1444 0.1408 0.1393 0.1376 0.1363 0.1357 0.1354 0.1350 0.1345 0.1345 0.1345 

[TRAIN] Epoch[4](807/1500); Loss: 0.078354; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1097 0.0960 0.0797 0.0838 0.0766 0.0750 0.0742 0.0740 0.0734 0.0731 0.0729 0.0731 0.0728 0.0731 0.0730 0.0732 

[TRAIN] Epoch[4](808/1500); Loss: 0.146356; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1791 0.1504 0.1491 0.1441 0.1441 0.1431 0.1430 0.1426 0.1429 0.1429 0.1432 0.1431 0.1433 0.1434 0.1436 0.1439 

[TRAIN] Epoch[4](809/1500); Loss: 0.070667; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.2469 0.1338 0.0652 0.0745 0.0593 0.0555 0.0582 0.0522 0.0495 0.0471 0.0471 0.0471 0.0484 0.0479 0.0489 0.0490 

[TRAIN] Epoch[4](810/1500); Loss: 0.086421; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1450 0.1021 0.0877 0.0835 0.0823 0.0803 0.0793 0.0790 0.0789 0.0792 0.0795 0.0802 0.0804 0.0811 0.0817 0.0825 

[TRAIN] Epoch[4](811/1500); Loss: 0.101928; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1750 0.1146 0.1034 0.1021 0.0974 0.0962 0.0947 0.0944 0.0941 0.0937 0.0938 0.0940 0.0942 0.0944 0.0944 0.0944 

[TRAIN] Epoch[4](812/1500); Loss: 0.140446; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.2742 0.1711 0.1339 0.1329 0.1378 0.1289 0.1331 0.1284 0.1263 0.1258 0.1259 0.1254 0.1257 0.1258 0.1260 0.1259 

[TRAIN] Epoch[4](813/1500); Loss: 0.140413; Backpropagation: 0.0984 sec; Batch: 0.4346 sec
0.2019 0.1604 0.1481 0.1409 0.1402 0.1368 0.1358 0.1343 0.1337 0.1326 0.1317 0.1310 0.1303 0.1301 0.1296 0.1294 

[TRAIN] Epoch[4](814/1500); Loss: 0.108630; Backpropagation: 0.0961 sec; Batch: 0.4310 sec
0.1727 0.1265 0.1118 0.1151 0.1053 0.1056 0.1026 0.1015 0.1005 0.0999 0.0994 0.0995 0.0994 0.0996 0.0993 0.0996 

[TRAIN] Epoch[4](815/1500); Loss: 0.084901; Backpropagation: 0.0941 sec; Batch: 0.4324 sec
0.2751 0.1176 0.0783 0.0756 0.0860 0.0692 0.0720 0.0673 0.0654 0.0643 0.0646 0.0642 0.0647 0.0644 0.0647 0.0650 

[TRAIN] Epoch[4](816/1500); Loss: 0.090754; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1147 0.0939 0.0928 0.0926 0.0895 0.0885 0.0882 0.0875 0.0877 0.0875 0.0877 0.0876 0.0881 0.0882 0.0887 0.0888 

[TRAIN] Epoch[4](817/1500); Loss: 0.099808; Backpropagation: 0.0943 sec; Batch: 0.4290 sec
0.1287 0.1075 0.1018 0.1007 0.0978 0.0973 0.0968 0.0961 0.0962 0.0959 0.0961 0.0960 0.0964 0.0964 0.0966 0.0967 

[TRAIN] Epoch[4](818/1500); Loss: 0.121620; Backpropagation: 0.0941 sec; Batch: 0.4323 sec
0.1782 0.1392 0.1269 0.1210 0.1180 0.1170 0.1160 0.1154 0.1148 0.1142 0.1140 0.1141 0.1141 0.1142 0.1142 0.1147 

[TRAIN] Epoch[4](819/1500); Loss: 0.143042; Backpropagation: 0.0983 sec; Batch: 0.4339 sec
0.2253 0.1730 0.1476 0.1441 0.1372 0.1365 0.1336 0.1329 0.1325 0.1325 0.1323 0.1322 0.1322 0.1322 0.1323 0.1324 

[TRAIN] Epoch[4](820/1500); Loss: 0.067419; Backpropagation: 0.0945 sec; Batch: 0.4294 sec
0.1016 0.0969 0.0753 0.0683 0.0644 0.0631 0.0622 0.0613 0.0606 0.0606 0.0607 0.0604 0.0604 0.0608 0.0609 0.0611 

[TRAIN] Epoch[4](821/1500); Loss: 0.100594; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1864 0.1307 0.1012 0.1047 0.0935 0.0979 0.0932 0.0918 0.0902 0.0894 0.0889 0.0886 0.0884 0.0883 0.0881 0.0883 

[TRAIN] Epoch[4](822/1500); Loss: 0.070054; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.0945 0.0859 0.0741 0.0741 0.0682 0.0674 0.0663 0.0661 0.0657 0.0656 0.0655 0.0656 0.0654 0.0653 0.0654 0.0657 

[TRAIN] Epoch[4](823/1500); Loss: 0.152303; Backpropagation: 0.0950 sec; Batch: 0.4296 sec
0.2277 0.1787 0.1576 0.1500 0.1467 0.1466 0.1449 0.1440 0.1434 0.1431 0.1430 0.1425 0.1424 0.1422 0.1419 0.1418 

[TRAIN] Epoch[4](824/1500); Loss: 0.121080; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1544 0.1263 0.1265 0.1212 0.1198 0.1184 0.1181 0.1170 0.1171 0.1166 0.1171 0.1171 0.1170 0.1167 0.1170 0.1169 

[TRAIN] Epoch[4](825/1500); Loss: 0.146746; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2536 0.1989 0.1573 0.1387 0.1382 0.1341 0.1337 0.1330 0.1330 0.1328 0.1326 0.1324 0.1323 0.1323 0.1325 0.1325 

[TRAIN] Epoch[4](826/1500); Loss: 0.071622; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1540 0.0910 0.0824 0.0751 0.0682 0.0650 0.0625 0.0618 0.0604 0.0602 0.0597 0.0605 0.0604 0.0612 0.0612 0.0623 

[TRAIN] Epoch[4](827/1500); Loss: 0.089140; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.2392 0.1187 0.0769 0.0823 0.0781 0.0799 0.0764 0.0754 0.0741 0.0744 0.0745 0.0746 0.0749 0.0753 0.0756 0.0759 

[TRAIN] Epoch[4](828/1500); Loss: 0.122859; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1553 0.1343 0.1252 0.1247 0.1211 0.1203 0.1191 0.1187 0.1180 0.1183 0.1180 0.1183 0.1183 0.1186 0.1187 0.1191 

[TRAIN] Epoch[4](829/1500); Loss: 0.099219; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2562 0.1444 0.1161 0.0878 0.1006 0.0876 0.0843 0.0804 0.0799 0.0791 0.0789 0.0783 0.0783 0.0785 0.0786 0.0784 

[TRAIN] Epoch[4](830/1500); Loss: 0.065756; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.2652 0.0923 0.0648 0.0540 0.0767 0.0523 0.0512 0.0443 0.0431 0.0422 0.0441 0.0432 0.0440 0.0438 0.0454 0.0454 

[TRAIN] Epoch[4](831/1500); Loss: 0.036296; Backpropagation: 0.0961 sec; Batch: 0.4307 sec
0.0732 0.0386 0.0533 0.0327 0.0320 0.0318 0.0307 0.0308 0.0311 0.0310 0.0308 0.0313 0.0330 0.0329 0.0333 0.0341 

[TRAIN] Epoch[4](832/1500); Loss: 0.087562; Backpropagation: 0.0959 sec; Batch: 0.4302 sec
0.2262 0.1326 0.0849 0.0870 0.0799 0.0810 0.0750 0.0726 0.0709 0.0706 0.0704 0.0701 0.0698 0.0700 0.0699 0.0701 

[TRAIN] Epoch[4](833/1500); Loss: 0.139468; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2321 0.1604 0.1408 0.1337 0.1322 0.1304 0.1302 0.1301 0.1296 0.1296 0.1299 0.1299 0.1301 0.1304 0.1308 0.1312 

[TRAIN] Epoch[4](834/1500); Loss: 0.092780; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.3072 0.1963 0.1217 0.0646 0.0778 0.0691 0.0637 0.0732 0.0676 0.0665 0.0630 0.0626 0.0621 0.0634 0.0625 0.0632 

[TRAIN] Epoch[4](835/1500); Loss: 0.091069; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1929 0.1129 0.0974 0.0863 0.0932 0.0848 0.0833 0.0803 0.0790 0.0781 0.0784 0.0780 0.0781 0.0779 0.0783 0.0782 

[TRAIN] Epoch[4](836/1500); Loss: 0.040768; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.0557 0.0629 0.0400 0.0455 0.0383 0.0374 0.0373 0.0370 0.0367 0.0368 0.0369 0.0369 0.0372 0.0377 0.0379 0.0381 

[TRAIN] Epoch[4](837/1500); Loss: 0.045906; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.0517 0.0626 0.0502 0.0466 0.0447 0.0438 0.0435 0.0431 0.0430 0.0430 0.0431 0.0434 0.0436 0.0438 0.0441 0.0445 

[TRAIN] Epoch[4](838/1500); Loss: 0.070516; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.3221 0.1262 0.0556 0.0435 0.0950 0.0540 0.0414 0.0392 0.0444 0.0411 0.0402 0.0423 0.0448 0.0456 0.0454 0.0475 

[TRAIN] Epoch[4](839/1500); Loss: 0.102717; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1736 0.1153 0.1095 0.1054 0.0998 0.0986 0.0968 0.0954 0.0942 0.0940 0.0934 0.0936 0.0931 0.0937 0.0931 0.0937 

[TRAIN] Epoch[4](840/1500); Loss: 0.114772; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1938 0.1493 0.1218 0.1147 0.1086 0.1088 0.1056 0.1046 0.1039 0.1035 0.1033 0.1039 0.1037 0.1037 0.1035 0.1037 

[TRAIN] Epoch[4](841/1500); Loss: 0.065232; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1168 0.0956 0.0704 0.0662 0.0620 0.0614 0.0596 0.0584 0.0572 0.0570 0.0565 0.0564 0.0563 0.0566 0.0565 0.0568 

[TRAIN] Epoch[4](842/1500); Loss: 0.112586; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1917 0.1355 0.1217 0.1099 0.1066 0.1052 0.1044 0.1037 0.1035 0.1032 0.1029 0.1026 0.1025 0.1027 0.1027 0.1026 

[TRAIN] Epoch[4](843/1500); Loss: 0.105645; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.1663 0.1326 0.1167 0.1081 0.1010 0.1001 0.0982 0.0973 0.0964 0.0961 0.0958 0.0961 0.0961 0.0964 0.0964 0.0966 

[TRAIN] Epoch[4](844/1500); Loss: 0.063312; Backpropagation: 0.0959 sec; Batch: 0.4303 sec
0.0896 0.0705 0.0628 0.0621 0.0608 0.0606 0.0605 0.0605 0.0604 0.0604 0.0604 0.0604 0.0607 0.0609 0.0612 0.0613 

[TRAIN] Epoch[4](845/1500); Loss: 0.076340; Backpropagation: 0.0944 sec; Batch: 0.4287 sec
0.1515 0.0989 0.0822 0.0787 0.0728 0.0716 0.0694 0.0679 0.0670 0.0664 0.0662 0.0660 0.0659 0.0658 0.0656 0.0655 

[TRAIN] Epoch[4](846/1500); Loss: 0.114744; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2488 0.1501 0.1274 0.1086 0.1118 0.1032 0.1008 0.0986 0.0984 0.0981 0.0981 0.0981 0.0983 0.0983 0.0985 0.0987 

[TRAIN] Epoch[4](847/1500); Loss: 0.127725; Backpropagation: 0.0943 sec; Batch: 0.4292 sec
0.1945 0.1533 0.1400 0.1283 0.1228 0.1202 0.1194 0.1188 0.1188 0.1185 0.1185 0.1182 0.1181 0.1179 0.1182 0.1180 

[TRAIN] Epoch[4](848/1500); Loss: 0.144563; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2308 0.1857 0.1536 0.1396 0.1372 0.1350 0.1339 0.1333 0.1332 0.1328 0.1329 0.1329 0.1330 0.1330 0.1330 0.1330 

[TRAIN] Epoch[4](849/1500); Loss: 0.066145; Backpropagation: 0.0943 sec; Batch: 0.4289 sec
0.1298 0.0932 0.0783 0.0691 0.0636 0.0605 0.0594 0.0580 0.0573 0.0565 0.0559 0.0556 0.0553 0.0553 0.0551 0.0555 

[TRAIN] Epoch[4](850/1500); Loss: 0.049702; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1756 0.1187 0.0648 0.0388 0.0331 0.0334 0.0322 0.0323 0.0325 0.0325 0.0331 0.0330 0.0333 0.0336 0.0341 0.0341 

[TRAIN] Epoch[4](851/1500); Loss: 0.098580; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1840 0.1227 0.1020 0.0972 0.0932 0.0928 0.0908 0.0896 0.0889 0.0883 0.0881 0.0881 0.0881 0.0879 0.0879 0.0877 

[TRAIN] Epoch[4](852/1500); Loss: 0.099817; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1819 0.1399 0.1083 0.0934 0.0884 0.0871 0.0868 0.0877 0.0881 0.0889 0.0893 0.0902 0.0907 0.0915 0.0919 0.0929 

[TRAIN] Epoch[4](853/1500); Loss: 0.087589; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1157 0.1040 0.0946 0.0915 0.0869 0.0861 0.0845 0.0834 0.0825 0.0821 0.0818 0.0817 0.0816 0.0816 0.0817 0.0818 

[TRAIN] Epoch[4](854/1500); Loss: 0.060470; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.1167 0.0715 0.0665 0.0574 0.0563 0.0557 0.0548 0.0548 0.0544 0.0546 0.0542 0.0543 0.0538 0.0542 0.0539 0.0542 

[TRAIN] Epoch[4](855/1500); Loss: 0.152445; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2489 0.2104 0.1720 0.1486 0.1423 0.1410 0.1393 0.1382 0.1376 0.1374 0.1371 0.1371 0.1371 0.1373 0.1373 0.1375 

[TRAIN] Epoch[4](856/1500); Loss: 0.074612; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1194 0.0993 0.0817 0.0792 0.0738 0.0713 0.0693 0.0686 0.0676 0.0671 0.0666 0.0662 0.0662 0.0659 0.0658 0.0658 

[TRAIN] Epoch[4](857/1500); Loss: 0.097365; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2182 0.1475 0.1054 0.0939 0.0868 0.0864 0.0835 0.0829 0.0821 0.0819 0.0814 0.0815 0.0814 0.0815 0.0815 0.0818 

[TRAIN] Epoch[4](858/1500); Loss: 0.113438; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1711 0.1438 0.1233 0.1133 0.1091 0.1070 0.1063 0.1054 0.1053 0.1049 0.1046 0.1043 0.1043 0.1041 0.1040 0.1042 

[TRAIN] Epoch[4](859/1500); Loss: 0.087952; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2673 0.1560 0.0987 0.0717 0.0769 0.0727 0.0669 0.0688 0.0669 0.0664 0.0656 0.0654 0.0656 0.0659 0.0659 0.0665 

[TRAIN] Epoch[4](860/1500); Loss: 0.067473; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.0972 0.0865 0.0707 0.0700 0.0652 0.0643 0.0635 0.0633 0.0628 0.0627 0.0622 0.0621 0.0620 0.0624 0.0622 0.0625 

[TRAIN] Epoch[4](861/1500); Loss: 0.175193; Backpropagation: 0.0943 sec; Batch: 0.4294 sec
0.2595 0.2138 0.1743 0.1730 0.1682 0.1686 0.1665 0.1669 0.1650 0.1656 0.1640 0.1642 0.1631 0.1639 0.1629 0.1637 

[TRAIN] Epoch[4](862/1500); Loss: 0.064493; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1062 0.0756 0.0708 0.0628 0.0619 0.0608 0.0598 0.0593 0.0591 0.0590 0.0590 0.0591 0.0594 0.0594 0.0598 0.0601 

[TRAIN] Epoch[4](863/1500); Loss: 0.082436; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.3069 0.1921 0.1020 0.0624 0.0572 0.0729 0.0546 0.0580 0.0530 0.0514 0.0504 0.0518 0.0506 0.0512 0.0511 0.0535 

[TRAIN] Epoch[4](864/1500); Loss: 0.086836; Backpropagation: 0.0943 sec; Batch: 0.4289 sec
0.2301 0.1164 0.1031 0.0779 0.0912 0.0788 0.0740 0.0706 0.0696 0.0686 0.0685 0.0679 0.0680 0.0680 0.0683 0.0683 

[TRAIN] Epoch[4](865/1500); Loss: 0.092244; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1862 0.1202 0.0979 0.0929 0.0876 0.0852 0.0832 0.0825 0.0816 0.0809 0.0801 0.0801 0.0797 0.0796 0.0792 0.0793 

[TRAIN] Epoch[4](866/1500); Loss: 0.036405; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.0629 0.0565 0.0437 0.0375 0.0333 0.0324 0.0323 0.0315 0.0314 0.0309 0.0310 0.0310 0.0316 0.0317 0.0322 0.0324 

[TRAIN] Epoch[4](867/1500); Loss: 0.105462; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1797 0.1219 0.1139 0.1048 0.1009 0.0985 0.0981 0.0976 0.0971 0.0968 0.0964 0.0964 0.0963 0.0963 0.0964 0.0964 

[TRAIN] Epoch[4](868/1500); Loss: 0.081670; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1080 0.0999 0.0850 0.0825 0.0808 0.0793 0.0789 0.0782 0.0779 0.0774 0.0771 0.0767 0.0766 0.0764 0.0761 0.0761 

[TRAIN] Epoch[4](869/1500); Loss: 0.080558; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2215 0.1059 0.0858 0.0741 0.0875 0.0715 0.0672 0.0650 0.0645 0.0640 0.0639 0.0635 0.0636 0.0635 0.0637 0.0639 

[TRAIN] Epoch[4](870/1500); Loss: 0.108213; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2100 0.1623 0.1312 0.1084 0.1012 0.0988 0.0953 0.0940 0.0927 0.0920 0.0913 0.0914 0.0909 0.0907 0.0905 0.0906 

[TRAIN] Epoch[4](871/1500); Loss: 0.048309; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.0981 0.0630 0.0634 0.0461 0.0490 0.0427 0.0423 0.0411 0.0417 0.0407 0.0405 0.0403 0.0409 0.0407 0.0412 0.0412 

[TRAIN] Epoch[4](872/1500); Loss: 0.092723; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1467 0.1089 0.1041 0.0961 0.0946 0.0888 0.0868 0.0852 0.0846 0.0841 0.0840 0.0839 0.0839 0.0839 0.0841 0.0839 

[TRAIN] Epoch[4](873/1500); Loss: 0.121752; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1666 0.1308 0.1303 0.1201 0.1204 0.1174 0.1168 0.1167 0.1166 0.1161 0.1162 0.1161 0.1161 0.1160 0.1160 0.1160 

[TRAIN] Epoch[4](874/1500); Loss: 0.079862; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1476 0.1081 0.0833 0.0795 0.0749 0.0748 0.0719 0.0714 0.0710 0.0708 0.0707 0.0707 0.0707 0.0706 0.0708 0.0710 

[TRAIN] Epoch[4](875/1500); Loss: 0.189614; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.2870 0.2359 0.2036 0.1857 0.1789 0.1774 0.1766 0.1772 0.1764 0.1767 0.1766 0.1764 0.1764 0.1761 0.1767 0.1764 

[TRAIN] Epoch[4](876/1500); Loss: 0.117695; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2031 0.1367 0.1211 0.1203 0.1136 0.1109 0.1099 0.1089 0.1085 0.1077 0.1077 0.1072 0.1072 0.1069 0.1069 0.1067 

[TRAIN] Epoch[4](877/1500); Loss: 0.079661; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1062 0.0989 0.0847 0.0811 0.0784 0.0770 0.0761 0.0753 0.0750 0.0745 0.0744 0.0743 0.0746 0.0746 0.0746 0.0748 

[TRAIN] Epoch[4](878/1500); Loss: 0.048477; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.0876 0.0693 0.0526 0.0492 0.0458 0.0445 0.0432 0.0427 0.0421 0.0422 0.0419 0.0424 0.0423 0.0429 0.0431 0.0438 

[TRAIN] Epoch[4](879/1500); Loss: 0.088282; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.1397 0.1061 0.0932 0.0878 0.0855 0.0841 0.0831 0.0823 0.0817 0.0814 0.0812 0.0811 0.0813 0.0813 0.0813 0.0814 

[TRAIN] Epoch[4](880/1500); Loss: 0.066814; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1210 0.0841 0.0747 0.0665 0.0631 0.0618 0.0606 0.0601 0.0597 0.0596 0.0595 0.0596 0.0596 0.0596 0.0597 0.0600 

[TRAIN] Epoch[4](881/1500); Loss: 0.070077; Backpropagation: 0.0945 sec; Batch: 0.4289 sec
0.1025 0.0784 0.0813 0.0717 0.0670 0.0667 0.0662 0.0653 0.0651 0.0649 0.0652 0.0649 0.0654 0.0653 0.0656 0.0657 

[TRAIN] Epoch[4](882/1500); Loss: 0.075369; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1271 0.1010 0.0735 0.0742 0.0705 0.0710 0.0697 0.0692 0.0686 0.0684 0.0684 0.0687 0.0687 0.0689 0.0689 0.0692 

[TRAIN] Epoch[4](883/1500); Loss: 0.097643; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1467 0.1171 0.1015 0.0974 0.0945 0.0932 0.0925 0.0921 0.0917 0.0913 0.0910 0.0907 0.0906 0.0906 0.0906 0.0907 

[TRAIN] Epoch[4](884/1500); Loss: 0.113303; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1603 0.1280 0.1156 0.1124 0.1104 0.1095 0.1088 0.1083 0.1078 0.1074 0.1073 0.1073 0.1074 0.1073 0.1075 0.1075 

[TRAIN] Epoch[4](885/1500); Loss: 0.073189; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.0831 0.0811 0.0796 0.0732 0.0718 0.0716 0.0713 0.0710 0.0711 0.0710 0.0710 0.0710 0.0709 0.0710 0.0712 0.0712 

[TRAIN] Epoch[4](886/1500); Loss: 0.107505; Backpropagation: 0.0933 sec; Batch: 0.4342 sec
0.2034 0.1277 0.1126 0.1023 0.1054 0.0997 0.0983 0.0980 0.0973 0.0969 0.0965 0.0966 0.0968 0.0964 0.0961 0.0961 

[TRAIN] Epoch[4](887/1500); Loss: 0.102234; Backpropagation: 0.0934 sec; Batch: 0.4296 sec
0.1851 0.1459 0.1077 0.1011 0.0957 0.0944 0.0921 0.0919 0.0908 0.0909 0.0901 0.0902 0.0898 0.0902 0.0898 0.0902 

[TRAIN] Epoch[4](888/1500); Loss: 0.145361; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1735 0.1506 0.1498 0.1479 0.1439 0.1434 0.1423 0.1424 0.1420 0.1417 0.1414 0.1414 0.1414 0.1413 0.1412 0.1414 

[TRAIN] Epoch[4](889/1500); Loss: 0.127422; Backpropagation: 0.0951 sec; Batch: 0.4304 sec
0.2029 0.1509 0.1318 0.1220 0.1215 0.1198 0.1193 0.1191 0.1193 0.1188 0.1188 0.1187 0.1191 0.1189 0.1189 0.1188 

[TRAIN] Epoch[4](890/1500); Loss: 0.101299; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.1903 0.1250 0.1025 0.0956 0.0926 0.0924 0.0914 0.0917 0.0917 0.0917 0.0919 0.0924 0.0925 0.0926 0.0930 0.0936 

[TRAIN] Epoch[4](891/1500); Loss: 0.082402; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1736 0.1033 0.0840 0.0774 0.0796 0.0743 0.0733 0.0731 0.0728 0.0725 0.0723 0.0723 0.0722 0.0724 0.0725 0.0726 

[TRAIN] Epoch[4](892/1500); Loss: 0.108131; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1573 0.1304 0.1133 0.1050 0.1052 0.1029 0.1029 0.1019 0.1018 0.1014 0.1015 0.1011 0.1014 0.1013 0.1015 0.1012 

[TRAIN] Epoch[4](893/1500); Loss: 0.111647; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1434 0.1268 0.1156 0.1131 0.1094 0.1084 0.1075 0.1071 0.1068 0.1065 0.1065 0.1068 0.1071 0.1071 0.1071 0.1072 

[TRAIN] Epoch[4](894/1500); Loss: 0.110241; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2131 0.1534 0.1254 0.1119 0.1021 0.1011 0.0978 0.0968 0.0963 0.0956 0.0952 0.0950 0.0948 0.0951 0.0951 0.0952 

[TRAIN] Epoch[4](895/1500); Loss: 0.058994; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.0997 0.0679 0.0708 0.0598 0.0576 0.0556 0.0556 0.0539 0.0534 0.0528 0.0532 0.0525 0.0527 0.0526 0.0529 0.0530 

[TRAIN] Epoch[4](896/1500); Loss: 0.071899; Backpropagation: 0.0943 sec; Batch: 0.4287 sec
0.1275 0.0922 0.0753 0.0703 0.0685 0.0670 0.0656 0.0651 0.0647 0.0647 0.0646 0.0648 0.0647 0.0649 0.0651 0.0655 

[TRAIN] Epoch[4](897/1500); Loss: 0.106635; Backpropagation: 0.0945 sec; Batch: 0.4291 sec
0.1590 0.1246 0.1124 0.1092 0.1041 0.1031 0.1017 0.1012 0.1000 0.0997 0.0990 0.0990 0.0984 0.0984 0.0981 0.0983 

[TRAIN] Epoch[4](898/1500); Loss: 0.059010; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1443 0.1005 0.0648 0.0636 0.0532 0.0515 0.0480 0.0473 0.0467 0.0464 0.0462 0.0463 0.0461 0.0463 0.0463 0.0466 

[TRAIN] Epoch[4](899/1500); Loss: 0.091206; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.2826 0.1370 0.0854 0.0691 0.1082 0.0767 0.0701 0.0689 0.0678 0.0691 0.0684 0.0701 0.0702 0.0713 0.0715 0.0730 

[TRAIN] Epoch[4](900/1500); Loss: 0.105597; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1790 0.1416 0.1114 0.1036 0.0972 0.0995 0.0966 0.0964 0.0956 0.0954 0.0952 0.0955 0.0954 0.0959 0.0953 0.0960 

[TRAIN] Epoch[4](901/1500); Loss: 0.087668; Backpropagation: 0.0961 sec; Batch: 0.4307 sec
0.2089 0.0996 0.1078 0.0792 0.0805 0.0757 0.0761 0.0749 0.0760 0.0742 0.0749 0.0742 0.0753 0.0748 0.0757 0.0749 

[TRAIN] Epoch[4](902/1500); Loss: 0.091319; Backpropagation: 0.0957 sec; Batch: 0.4301 sec
0.1467 0.1108 0.0943 0.0920 0.0879 0.0863 0.0854 0.0846 0.0843 0.0838 0.0840 0.0839 0.0842 0.0842 0.0845 0.0843 

[TRAIN] Epoch[4](903/1500); Loss: 0.097041; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1303 0.1064 0.0993 0.0963 0.0947 0.0936 0.0931 0.0927 0.0927 0.0928 0.0929 0.0929 0.0930 0.0935 0.0940 0.0943 

[TRAIN] Epoch[4](904/1500); Loss: 0.080343; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.2011 0.1193 0.0832 0.0768 0.0722 0.0720 0.0687 0.0674 0.0665 0.0659 0.0655 0.0655 0.0654 0.0653 0.0652 0.0655 

[TRAIN] Epoch[4](905/1500); Loss: 0.057238; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1084 0.0867 0.0635 0.0769 0.0553 0.0542 0.0485 0.0474 0.0462 0.0465 0.0460 0.0468 0.0466 0.0473 0.0472 0.0483 

[TRAIN] Epoch[4](906/1500); Loss: 0.081719; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1548 0.0977 0.0850 0.0852 0.0769 0.0742 0.0738 0.0730 0.0726 0.0732 0.0728 0.0729 0.0733 0.0736 0.0740 0.0745 

[TRAIN] Epoch[4](907/1500); Loss: 0.125336; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2036 0.1645 0.1415 0.1250 0.1157 0.1145 0.1140 0.1136 0.1133 0.1142 0.1145 0.1145 0.1143 0.1141 0.1141 0.1140 

[TRAIN] Epoch[4](908/1500); Loss: 0.059011; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1771 0.0870 0.0627 0.0593 0.0682 0.0500 0.0449 0.0425 0.0433 0.0428 0.0425 0.0431 0.0444 0.0446 0.0455 0.0462 

[TRAIN] Epoch[4](909/1500); Loss: 0.045033; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.0544 0.0657 0.0501 0.0457 0.0425 0.0424 0.0420 0.0415 0.0415 0.0420 0.0418 0.0418 0.0419 0.0422 0.0425 0.0426 

[TRAIN] Epoch[4](910/1500); Loss: 0.034450; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.0646 0.0424 0.0501 0.0319 0.0301 0.0310 0.0299 0.0295 0.0286 0.0292 0.0304 0.0296 0.0297 0.0302 0.0325 0.0317 

[TRAIN] Epoch[4](911/1500); Loss: 0.075645; Backpropagation: 0.0944 sec; Batch: 0.4284 sec
0.2836 0.1248 0.0712 0.0471 0.1035 0.0606 0.0503 0.0518 0.0504 0.0500 0.0486 0.0530 0.0521 0.0537 0.0527 0.0569 

[TRAIN] Epoch[4](912/1500); Loss: 0.073725; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1297 0.0876 0.0856 0.0757 0.0754 0.0701 0.0685 0.0672 0.0663 0.0655 0.0652 0.0647 0.0647 0.0645 0.0646 0.0642 

[TRAIN] Epoch[4](913/1500); Loss: 0.070360; Backpropagation: 0.0960 sec; Batch: 0.4310 sec
0.2403 0.1277 0.0782 0.0522 0.0724 0.0553 0.0522 0.0500 0.0498 0.0494 0.0492 0.0492 0.0500 0.0495 0.0501 0.0502 

[TRAIN] Epoch[4](914/1500); Loss: 0.104572; Backpropagation: 0.0956 sec; Batch: 0.4305 sec
0.1879 0.1441 0.1152 0.1044 0.0988 0.0962 0.0947 0.0945 0.0933 0.0929 0.0924 0.0921 0.0920 0.0916 0.0915 0.0914 

[TRAIN] Epoch[4](915/1500); Loss: 0.086665; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.1165 0.1055 0.0926 0.0875 0.0859 0.0837 0.0824 0.0815 0.0815 0.0813 0.0810 0.0810 0.0812 0.0816 0.0817 0.0818 

[TRAIN] Epoch[4](916/1500); Loss: 0.081875; Backpropagation: 0.0939 sec; Batch: 0.4292 sec
0.1580 0.0973 0.0971 0.0773 0.0796 0.0730 0.0728 0.0718 0.0730 0.0721 0.0724 0.0722 0.0735 0.0728 0.0736 0.0734 

[TRAIN] Epoch[4](917/1500); Loss: 0.079266; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1147 0.1123 0.0836 0.0782 0.0769 0.0747 0.0736 0.0730 0.0729 0.0725 0.0727 0.0725 0.0724 0.0725 0.0727 0.0732 

[TRAIN] Epoch[4](918/1500); Loss: 0.114271; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.2045 0.1339 0.1161 0.1081 0.1085 0.1064 0.1054 0.1055 0.1052 0.1050 0.1048 0.1049 0.1048 0.1051 0.1050 0.1050 

[TRAIN] Epoch[4](919/1500); Loss: 0.121054; Backpropagation: 0.0943 sec; Batch: 0.4285 sec
0.2372 0.1398 0.1236 0.1091 0.1182 0.1088 0.1094 0.1075 0.1089 0.1084 0.1096 0.1095 0.1109 0.1110 0.1125 0.1126 

[TRAIN] Epoch[4](920/1500); Loss: 0.091184; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.2304 0.1166 0.1018 0.0772 0.0986 0.0787 0.0766 0.0753 0.0750 0.0745 0.0748 0.0744 0.0761 0.0756 0.0769 0.0763 

[TRAIN] Epoch[4](921/1500); Loss: 0.085717; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1454 0.0927 0.0902 0.0832 0.0825 0.0816 0.0801 0.0802 0.0791 0.0798 0.0790 0.0795 0.0789 0.0794 0.0794 0.0804 

[TRAIN] Epoch[4](922/1500); Loss: 0.173950; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.2427 0.2159 0.1902 0.1781 0.1706 0.1674 0.1647 0.1640 0.1631 0.1628 0.1616 0.1615 0.1606 0.1604 0.1596 0.1600 

[TRAIN] Epoch[4](923/1500); Loss: 0.089533; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1146 0.1104 0.0918 0.0882 0.0882 0.0858 0.0857 0.0848 0.0851 0.0846 0.0853 0.0850 0.0854 0.0855 0.0861 0.0861 

[TRAIN] Epoch[4](924/1500); Loss: 0.099068; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.1884 0.1328 0.1051 0.0938 0.0927 0.0891 0.0890 0.0875 0.0872 0.0868 0.0873 0.0874 0.0887 0.0889 0.0903 0.0901 

[TRAIN] Epoch[4](925/1500); Loss: 0.119500; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1841 0.1435 0.1217 0.1208 0.1141 0.1139 0.1122 0.1118 0.1114 0.1118 0.1114 0.1113 0.1110 0.1111 0.1108 0.1111 

[TRAIN] Epoch[4](926/1500); Loss: 0.083943; Backpropagation: 0.0959 sec; Batch: 0.4308 sec
0.1569 0.1130 0.1003 0.0777 0.0821 0.0744 0.0754 0.0739 0.0743 0.0730 0.0735 0.0730 0.0737 0.0732 0.0746 0.0742 

[TRAIN] Epoch[4](927/1500); Loss: 0.104090; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1618 0.1298 0.1148 0.0996 0.1041 0.0975 0.0979 0.0946 0.0961 0.0945 0.0959 0.0947 0.0958 0.0957 0.0965 0.0962 

[TRAIN] Epoch[4](928/1500); Loss: 0.119322; Backpropagation: 0.0942 sec; Batch: 0.4281 sec
0.1612 0.1619 0.1228 0.1146 0.1139 0.1118 0.1127 0.1120 0.1118 0.1117 0.1121 0.1122 0.1124 0.1126 0.1127 0.1127 

[TRAIN] Epoch[4](929/1500); Loss: 0.089858; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2200 0.1468 0.0924 0.0849 0.0746 0.0849 0.0737 0.0768 0.0721 0.0742 0.0712 0.0739 0.0715 0.0741 0.0720 0.0746 

[TRAIN] Epoch[4](930/1500); Loss: 0.080532; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2841 0.1667 0.0802 0.0683 0.0551 0.0727 0.0548 0.0622 0.0557 0.0548 0.0535 0.0556 0.0540 0.0568 0.0556 0.0585 

[TRAIN] Epoch[4](931/1500); Loss: 0.077323; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.2174 0.1211 0.0739 0.0711 0.0734 0.0651 0.0649 0.0606 0.0604 0.0595 0.0608 0.0602 0.0614 0.0614 0.0630 0.0631 

[TRAIN] Epoch[4](932/1500); Loss: 0.072006; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1104 0.0938 0.0792 0.0715 0.0701 0.0682 0.0674 0.0660 0.0656 0.0653 0.0654 0.0654 0.0658 0.0657 0.0663 0.0659 

[TRAIN] Epoch[4](933/1500); Loss: 0.095627; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.2050 0.2108 0.1176 0.0830 0.0780 0.0790 0.0756 0.0759 0.0746 0.0759 0.0750 0.0761 0.0752 0.0764 0.0752 0.0766 

[TRAIN] Epoch[4](934/1500); Loss: 0.042180; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.0652 0.0712 0.0474 0.0592 0.0402 0.0380 0.0364 0.0343 0.0335 0.0342 0.0339 0.0351 0.0353 0.0360 0.0368 0.0380 

[TRAIN] Epoch[4](935/1500); Loss: 0.122784; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1993 0.1691 0.1322 0.1274 0.1169 0.1151 0.1126 0.1122 0.1112 0.1106 0.1097 0.1098 0.1097 0.1095 0.1098 0.1095 

[TRAIN] Epoch[4](936/1500); Loss: 0.124106; Backpropagation: 0.0959 sec; Batch: 0.4309 sec
0.1846 0.1851 0.1353 0.1232 0.1175 0.1166 0.1153 0.1144 0.1130 0.1126 0.1120 0.1118 0.1113 0.1113 0.1106 0.1110 

[TRAIN] Epoch[4](937/1500); Loss: 0.129350; Backpropagation: 0.0958 sec; Batch: 0.4309 sec
0.1848 0.1949 0.1425 0.1417 0.1284 0.1227 0.1193 0.1185 0.1168 0.1159 0.1148 0.1146 0.1140 0.1140 0.1128 0.1137 

[TRAIN] Epoch[4](938/1500); Loss: 0.155263; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.2369 0.2025 0.1655 0.1625 0.1569 0.1473 0.1425 0.1406 0.1415 0.1401 0.1399 0.1406 0.1414 0.1414 0.1419 0.1429 

[TRAIN] Epoch[4](939/1500); Loss: 0.062281; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.1187 0.0926 0.0640 0.0777 0.0567 0.0594 0.0512 0.0519 0.0498 0.0523 0.0507 0.0530 0.0524 0.0545 0.0548 0.0568 

[TRAIN] Epoch[4](940/1500); Loss: 0.080042; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1203 0.1355 0.0955 0.0773 0.0779 0.0716 0.0725 0.0700 0.0726 0.0705 0.0700 0.0685 0.0701 0.0691 0.0701 0.0692 

[TRAIN] Epoch[4](941/1500); Loss: 0.103702; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1748 0.1660 0.1228 0.1001 0.0978 0.0946 0.0944 0.0921 0.0921 0.0904 0.0905 0.0892 0.0892 0.0883 0.0888 0.0879 

[TRAIN] Epoch[4](942/1500); Loss: 0.106389; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1745 0.1490 0.1156 0.1058 0.1015 0.0987 0.0966 0.0957 0.0954 0.0955 0.0955 0.0952 0.0954 0.0958 0.0961 0.0960 

[TRAIN] Epoch[4](943/1500); Loss: 0.125029; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.2361 0.1965 0.1365 0.1240 0.1164 0.1104 0.1128 0.1096 0.1084 0.1074 0.1078 0.1068 0.1070 0.1066 0.1072 0.1070 

[TRAIN] Epoch[4](944/1500); Loss: 0.043657; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1059 0.1321 0.0634 0.0390 0.0341 0.0293 0.0297 0.0282 0.0293 0.0290 0.0289 0.0288 0.0301 0.0298 0.0302 0.0307 

[TRAIN] Epoch[4](945/1500); Loss: 0.131733; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2219 0.1733 0.1453 0.1268 0.1264 0.1216 0.1217 0.1198 0.1198 0.1186 0.1193 0.1185 0.1192 0.1181 0.1189 0.1183 

[TRAIN] Epoch[4](946/1500); Loss: 0.137244; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.1851 0.1669 0.1476 0.1455 0.1364 0.1323 0.1302 0.1291 0.1290 0.1282 0.1279 0.1275 0.1280 0.1276 0.1274 0.1273 

[TRAIN] Epoch[4](947/1500); Loss: 0.069477; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1381 0.1022 0.0746 0.0878 0.0642 0.0688 0.0603 0.0591 0.0553 0.0562 0.0552 0.0575 0.0566 0.0579 0.0582 0.0600 

[TRAIN] Epoch[4](948/1500); Loss: 0.114391; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2407 0.2469 0.1504 0.1006 0.0960 0.0919 0.0925 0.0912 0.0905 0.0896 0.0899 0.0899 0.0899 0.0896 0.0901 0.0907 

[TRAIN] Epoch[4](949/1500); Loss: 0.093322; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1467 0.1334 0.1035 0.0947 0.0891 0.0862 0.0847 0.0839 0.0835 0.0835 0.0838 0.0836 0.0834 0.0838 0.0844 0.0850 

[TRAIN] Epoch[4](950/1500); Loss: 0.134328; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1999 0.2016 0.1504 0.1332 0.1268 0.1241 0.1246 0.1238 0.1226 0.1217 0.1210 0.1208 0.1203 0.1198 0.1196 0.1192 

[TRAIN] Epoch[4](951/1500); Loss: 0.098332; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1507 0.1430 0.1166 0.1089 0.0967 0.0928 0.0897 0.0886 0.0874 0.0869 0.0864 0.0855 0.0850 0.0849 0.0851 0.0850 

[TRAIN] Epoch[4](952/1500); Loss: 0.091445; Backpropagation: 0.0932 sec; Batch: 0.4447 sec
0.1828 0.1756 0.1303 0.0927 0.0774 0.0748 0.0740 0.0727 0.0719 0.0721 0.0723 0.0725 0.0730 0.0735 0.0736 0.0740 

[TRAIN] Epoch[4](953/1500); Loss: 0.119193; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2060 0.1671 0.1304 0.1190 0.1104 0.1063 0.1085 0.1061 0.1055 0.1053 0.1060 0.1058 0.1070 0.1072 0.1083 0.1082 

[TRAIN] Epoch[4](954/1500); Loss: 0.082906; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1576 0.1576 0.1102 0.0856 0.0749 0.0702 0.0686 0.0672 0.0669 0.0665 0.0667 0.0665 0.0671 0.0669 0.0670 0.0671 

[TRAIN] Epoch[4](955/1500); Loss: 0.082811; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.1515 0.1169 0.0916 0.0854 0.0761 0.0750 0.0740 0.0733 0.0725 0.0724 0.0725 0.0722 0.0725 0.0724 0.0735 0.0732 

[TRAIN] Epoch[4](956/1500); Loss: 0.114266; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2601 0.1792 0.1298 0.1089 0.0991 0.0997 0.0952 0.0955 0.0944 0.0943 0.0942 0.0948 0.0952 0.0953 0.0960 0.0965 

[TRAIN] Epoch[4](957/1500); Loss: 0.109864; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2290 0.1628 0.1163 0.1134 0.0996 0.0992 0.0947 0.0940 0.0934 0.0935 0.0932 0.0938 0.0937 0.0939 0.0935 0.0938 

[TRAIN] Epoch[4](958/1500); Loss: 0.084647; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1203 0.1050 0.0932 0.0839 0.0878 0.0809 0.0797 0.0793 0.0791 0.0783 0.0781 0.0780 0.0776 0.0776 0.0778 0.0778 

[TRAIN] Epoch[4](959/1500); Loss: 0.076741; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1303 0.1088 0.0843 0.0780 0.0729 0.0709 0.0692 0.0685 0.0682 0.0681 0.0679 0.0679 0.0680 0.0681 0.0682 0.0685 

[TRAIN] Epoch[4](960/1500); Loss: 0.097122; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.1622 0.1699 0.1272 0.1011 0.0971 0.0862 0.0837 0.0833 0.0816 0.0810 0.0796 0.0801 0.0791 0.0802 0.0798 0.0819 

[TRAIN] Epoch[4](961/1500); Loss: 0.087319; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1627 0.1270 0.0945 0.0910 0.0838 0.0791 0.0767 0.0760 0.0756 0.0756 0.0754 0.0756 0.0758 0.0759 0.0759 0.0763 

[TRAIN] Epoch[4](962/1500); Loss: 0.109130; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1485 0.1786 0.1343 0.1176 0.1085 0.1020 0.0996 0.0971 0.0959 0.0946 0.0948 0.0942 0.0946 0.0945 0.0955 0.0955 

[TRAIN] Epoch[4](963/1500); Loss: 0.103735; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1425 0.1354 0.1182 0.1088 0.1018 0.0982 0.0963 0.0954 0.0951 0.0950 0.0951 0.0952 0.0954 0.0956 0.0957 0.0960 

[TRAIN] Epoch[4](964/1500); Loss: 0.042699; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.0909 0.1035 0.0620 0.0438 0.0340 0.0313 0.0300 0.0299 0.0305 0.0307 0.0307 0.0317 0.0318 0.0335 0.0335 0.0354 

[TRAIN] Epoch[4](965/1500); Loss: 0.086516; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1626 0.1497 0.1060 0.0976 0.0817 0.0758 0.0730 0.0721 0.0713 0.0712 0.0707 0.0704 0.0705 0.0704 0.0707 0.0706 

[TRAIN] Epoch[4](966/1500); Loss: 0.102307; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.1192 0.1876 0.1091 0.0960 0.0974 0.0931 0.0927 0.0925 0.0928 0.0926 0.0931 0.0933 0.0940 0.0941 0.0944 0.0950 

[TRAIN] Epoch[4](967/1500); Loss: 0.114450; Backpropagation: 0.0958 sec; Batch: 0.4304 sec
0.2351 0.2262 0.1491 0.1186 0.1168 0.1061 0.1037 0.0970 0.0949 0.0897 0.0880 0.0844 0.0834 0.0805 0.0802 0.0775 

[TRAIN] Epoch[4](968/1500); Loss: 0.065294; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1291 0.1682 0.1047 0.0792 0.0559 0.0470 0.0455 0.0454 0.0454 0.0465 0.0464 0.0458 0.0458 0.0461 0.0465 0.0472 

[TRAIN] Epoch[4](969/1500); Loss: 0.083219; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1303 0.1158 0.0988 0.0866 0.0790 0.0782 0.0753 0.0745 0.0735 0.0735 0.0731 0.0737 0.0736 0.0746 0.0748 0.0761 

[TRAIN] Epoch[4](970/1500); Loss: 0.110117; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1676 0.1875 0.1340 0.1198 0.1058 0.1005 0.0979 0.0960 0.0952 0.0944 0.0945 0.0940 0.0940 0.0933 0.0936 0.0935 

[TRAIN] Epoch[4](971/1500); Loss: 0.091718; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1358 0.1557 0.1159 0.1012 0.0895 0.0854 0.0821 0.0800 0.0794 0.0779 0.0780 0.0776 0.0776 0.0771 0.0772 0.0771 

[TRAIN] Epoch[4](972/1500); Loss: 0.075172; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1585 0.2088 0.1229 0.0870 0.0587 0.0533 0.0514 0.0510 0.0505 0.0513 0.0508 0.0512 0.0514 0.0516 0.0519 0.0525 

[TRAIN] Epoch[4](973/1500); Loss: 0.132059; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1845 0.1463 0.1351 0.1260 0.1243 0.1258 0.1242 0.1258 0.1251 0.1271 0.1263 0.1276 0.1273 0.1287 0.1284 0.1305 

[TRAIN] Epoch[4](974/1500); Loss: 0.085714; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2157 0.1047 0.1003 0.0796 0.0965 0.0735 0.0713 0.0713 0.0685 0.0688 0.0686 0.0697 0.0695 0.0708 0.0707 0.0719 

[TRAIN] Epoch[4](975/1500); Loss: 0.133553; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.3041 0.1906 0.1667 0.1276 0.1549 0.1232 0.1129 0.1102 0.1058 0.1052 0.1052 0.1052 0.1056 0.1055 0.1065 0.1075 

[TRAIN] Epoch[4](976/1500); Loss: 0.143114; Backpropagation: 0.0935 sec; Batch: 0.4354 sec
0.2393 0.2057 0.1685 0.1485 0.1383 0.1320 0.1294 0.1277 0.1268 0.1262 0.1258 0.1252 0.1245 0.1241 0.1240 0.1238 

[TRAIN] Epoch[4](977/1500); Loss: 0.146816; Backpropagation: 0.0938 sec; Batch: 0.4469 sec
0.2017 0.2444 0.1816 0.1543 0.1381 0.1332 0.1317 0.1301 0.1297 0.1288 0.1289 0.1287 0.1291 0.1292 0.1297 0.1298 

[TRAIN] Epoch[4](978/1500); Loss: 0.159412; Backpropagation: 0.0981 sec; Batch: 0.4361 sec
0.2525 0.2780 0.2124 0.1822 0.1575 0.1444 0.1389 0.1360 0.1336 0.1322 0.1311 0.1306 0.1304 0.1305 0.1301 0.1301 

[TRAIN] Epoch[4](979/1500); Loss: 0.068048; Backpropagation: 0.0980 sec; Batch: 0.4333 sec
0.1097 0.0904 0.0726 0.0662 0.0662 0.0635 0.0629 0.0620 0.0618 0.0617 0.0616 0.0617 0.0619 0.0617 0.0623 0.0627 

[TRAIN] Epoch[4](980/1500); Loss: 0.138678; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2489 0.1922 0.1675 0.1442 0.1387 0.1302 0.1270 0.1235 0.1215 0.1199 0.1189 0.1183 0.1176 0.1174 0.1167 0.1165 

[TRAIN] Epoch[4](981/1500); Loss: 0.087517; Backpropagation: 0.0934 sec; Batch: 0.4292 sec
0.1734 0.2793 0.1644 0.1063 0.0727 0.0622 0.0564 0.0551 0.0539 0.0540 0.0535 0.0537 0.0536 0.0538 0.0539 0.0542 

[TRAIN] Epoch[4](982/1500); Loss: 0.061803; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1076 0.0801 0.0705 0.0668 0.0603 0.0560 0.0562 0.0534 0.0539 0.0535 0.0540 0.0540 0.0549 0.0551 0.0562 0.0565 

[TRAIN] Epoch[4](983/1500); Loss: 0.136040; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.2437 0.2641 0.1975 0.1571 0.1291 0.1170 0.1134 0.1099 0.1089 0.1070 0.1064 0.1051 0.1047 0.1039 0.1048 0.1040 

[TRAIN] Epoch[4](984/1500); Loss: 0.089865; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.2073 0.1084 0.1048 0.0911 0.0872 0.0823 0.0806 0.0780 0.0764 0.0758 0.0749 0.0744 0.0743 0.0739 0.0742 0.0742 

[TRAIN] Epoch[4](985/1500); Loss: 0.069799; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1347 0.2421 0.1300 0.0776 0.0483 0.0507 0.0468 0.0428 0.0432 0.0427 0.0430 0.0421 0.0428 0.0427 0.0437 0.0436 

[TRAIN] Epoch[4](986/1500); Loss: 0.092993; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1041 0.1306 0.0968 0.0956 0.0898 0.0888 0.0879 0.0874 0.0872 0.0873 0.0875 0.0880 0.0884 0.0890 0.0895 0.0900 

[TRAIN] Epoch[4](987/1500); Loss: 0.163150; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2738 0.2953 0.2163 0.1801 0.1546 0.1432 0.1382 0.1364 0.1352 0.1340 0.1342 0.1338 0.1336 0.1336 0.1343 0.1338 

[TRAIN] Epoch[4](988/1500); Loss: 0.169034; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2639 0.2987 0.2200 0.1964 0.1687 0.1569 0.1485 0.1439 0.1417 0.1404 0.1393 0.1385 0.1379 0.1370 0.1368 0.1361 

[TRAIN] Epoch[4](989/1500); Loss: 0.129695; Backpropagation: 0.0958 sec; Batch: 0.4298 sec
0.1900 0.1836 0.1591 0.1391 0.1329 0.1239 0.1195 0.1156 0.1163 0.1143 0.1133 0.1142 0.1136 0.1133 0.1127 0.1137 

[TRAIN] Epoch[4](990/1500); Loss: 0.172949; Backpropagation: 0.0940 sec; Batch: 0.4293 sec
0.2426 0.2505 0.2019 0.1854 0.1740 0.1656 0.1610 0.1579 0.1565 0.1550 0.1542 0.1533 0.1527 0.1525 0.1522 0.1519 

[TRAIN] Epoch[4](991/1500); Loss: 0.118028; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2805 0.2389 0.1519 0.1244 0.1052 0.0995 0.0917 0.0902 0.0892 0.0893 0.0879 0.0878 0.0881 0.0882 0.0876 0.0880 

[TRAIN] Epoch[4](992/1500); Loss: 0.157697; Backpropagation: 0.0937 sec; Batch: 0.4272 sec
0.2402 0.2230 0.1848 0.1679 0.1540 0.1487 0.1435 0.1422 0.1402 0.1400 0.1398 0.1398 0.1394 0.1397 0.1399 0.1400 

[TRAIN] Epoch[4](993/1500); Loss: 0.090016; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1681 0.1353 0.1158 0.0946 0.0904 0.0815 0.0783 0.0759 0.0762 0.0750 0.0748 0.0743 0.0750 0.0749 0.0752 0.0750 

[TRAIN] Epoch[4](994/1500); Loss: 0.103686; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1411 0.1517 0.1216 0.1149 0.1012 0.0981 0.0956 0.0942 0.0930 0.0928 0.0923 0.0923 0.0921 0.0926 0.0927 0.0928 

[TRAIN] Epoch[4](995/1500); Loss: 0.092422; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1449 0.0978 0.0957 0.0888 0.0892 0.0872 0.0873 0.0859 0.0861 0.0861 0.0870 0.0874 0.0878 0.0883 0.0893 0.0898 

[TRAIN] Epoch[4](996/1500); Loss: 0.108338; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2168 0.1826 0.1441 0.1231 0.1046 0.0978 0.0930 0.0890 0.0869 0.0855 0.0847 0.0842 0.0848 0.0851 0.0854 0.0857 

[TRAIN] Epoch[4](997/1500); Loss: 0.086895; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.2886 0.0838 0.1253 0.0598 0.1347 0.0778 0.0589 0.0591 0.0597 0.0590 0.0601 0.0612 0.0633 0.0645 0.0659 0.0685 

[TRAIN] Epoch[4](998/1500); Loss: 0.093525; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1541 0.1304 0.1180 0.1010 0.0907 0.0849 0.0832 0.0818 0.0814 0.0813 0.0815 0.0811 0.0812 0.0815 0.0820 0.0823 

[TRAIN] Epoch[4](999/1500); Loss: 0.188377; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.3144 0.2925 0.2488 0.2178 0.1979 0.1823 0.1752 0.1685 0.1625 0.1587 0.1556 0.1520 0.1500 0.1478 0.1459 0.1443 

[TRAIN] Epoch[4](1000/1500); Loss: 0.068252; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1927 0.1030 0.0694 0.0852 0.0764 0.0514 0.0484 0.0486 0.0486 0.0487 0.0499 0.0512 0.0528 0.0532 0.0556 0.0569 

[TRAIN] Epoch[4](1001/1500); Loss: 0.085373; Backpropagation: 0.0959 sec; Batch: 0.4309 sec
0.1527 0.1421 0.1196 0.1052 0.0895 0.0808 0.0753 0.0712 0.0695 0.0679 0.0670 0.0661 0.0656 0.0648 0.0644 0.0642 

[TRAIN] Epoch[4](1002/1500); Loss: 0.122699; Backpropagation: 0.0957 sec; Batch: 0.4301 sec
0.1970 0.2641 0.2085 0.1798 0.1424 0.1197 0.1039 0.0931 0.0866 0.0839 0.0819 0.0812 0.0807 0.0803 0.0799 0.0800 

[TRAIN] Epoch[4](1003/1500); Loss: 0.143270; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2400 0.2365 0.1856 0.1594 0.1387 0.1274 0.1228 0.1207 0.1198 0.1193 0.1195 0.1197 0.1201 0.1203 0.1209 0.1217 

[TRAIN] Epoch[4](1004/1500); Loss: 0.145566; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2445 0.1760 0.1674 0.1464 0.1409 0.1359 0.1351 0.1336 0.1331 0.1325 0.1318 0.1308 0.1304 0.1303 0.1303 0.1301 

[TRAIN] Epoch[4](1005/1500); Loss: 0.177226; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2544 0.2834 0.2289 0.1955 0.1717 0.1610 0.1574 0.1560 0.1552 0.1548 0.1540 0.1534 0.1528 0.1523 0.1523 0.1523 

[TRAIN] Epoch[4](1006/1500); Loss: 0.128821; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1759 0.2519 0.2187 0.1777 0.1319 0.1091 0.1038 0.1017 0.1007 0.0996 0.0991 0.0983 0.0983 0.0981 0.0983 0.0981 

[TRAIN] Epoch[4](1007/1500); Loss: 0.143618; Backpropagation: 0.0957 sec; Batch: 0.4303 sec
0.2559 0.2132 0.1816 0.1588 0.1416 0.1323 0.1265 0.1234 0.1221 0.1211 0.1208 0.1202 0.1203 0.1201 0.1200 0.1199 

[TRAIN] Epoch[4](1008/1500); Loss: 0.119593; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.1865 0.1755 0.1428 0.1268 0.1163 0.1099 0.1073 0.1055 0.1050 0.1047 0.1050 0.1050 0.1051 0.1055 0.1060 0.1065 

[TRAIN] Epoch[4](1009/1500); Loss: 0.121924; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2330 0.3131 0.2478 0.1902 0.1232 0.0853 0.0763 0.0755 0.0752 0.0751 0.0751 0.0751 0.0754 0.0761 0.0766 0.0778 

[TRAIN] Epoch[4](1010/1500); Loss: 0.145759; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1705 0.2254 0.2313 0.2008 0.1592 0.1379 0.1281 0.1253 0.1229 0.1225 0.1206 0.1194 0.1180 0.1172 0.1168 0.1165 

[TRAIN] Epoch[4](1011/1500); Loss: 0.167391; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2563 0.2281 0.2013 0.1828 0.1648 0.1593 0.1539 0.1519 0.1498 0.1486 0.1479 0.1474 0.1471 0.1467 0.1461 0.1460 

[TRAIN] Epoch[4](1012/1500); Loss: 0.094893; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1839 0.2249 0.1773 0.1472 0.1058 0.0793 0.0658 0.0613 0.0594 0.0583 0.0582 0.0584 0.0588 0.0594 0.0597 0.0607 

[TRAIN] Epoch[4](1013/1500); Loss: 0.059556; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.0753 0.0929 0.0577 0.0802 0.0598 0.0555 0.0538 0.0530 0.0524 0.0532 0.0522 0.0530 0.0527 0.0535 0.0534 0.0543 

[TRAIN] Epoch[4](1014/1500); Loss: 0.190262; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.2712 0.3397 0.2832 0.2381 0.1932 0.1699 0.1616 0.1586 0.1567 0.1551 0.1539 0.1532 0.1530 0.1525 0.1523 0.1522 

[TRAIN] Epoch[4](1015/1500); Loss: 0.076158; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1685 0.0820 0.0965 0.0715 0.0771 0.0683 0.0681 0.0660 0.0652 0.0651 0.0647 0.0648 0.0647 0.0652 0.0652 0.0656 

[TRAIN] Epoch[4](1016/1500); Loss: 0.087254; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.2700 0.0995 0.1092 0.0692 0.0956 0.0744 0.0692 0.0676 0.0672 0.0666 0.0669 0.0669 0.0680 0.0678 0.0685 0.0695 

[TRAIN] Epoch[4](1017/1500); Loss: 0.130051; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1976 0.2229 0.1831 0.1474 0.1213 0.1146 0.1121 0.1111 0.1100 0.1096 0.1089 0.1087 0.1083 0.1085 0.1083 0.1085 

[TRAIN] Epoch[4](1018/1500); Loss: 0.123270; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1582 0.1783 0.1471 0.1342 0.1198 0.1161 0.1141 0.1135 0.1124 0.1117 0.1113 0.1112 0.1111 0.1112 0.1111 0.1111 

[TRAIN] Epoch[4](1019/1500); Loss: 0.115016; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1925 0.1572 0.1263 0.1179 0.1089 0.1061 0.1047 0.1041 0.1038 0.1031 0.1028 0.1025 0.1025 0.1025 0.1026 0.1028 

[TRAIN] Epoch[4](1020/1500); Loss: 0.130250; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1954 0.1954 0.1559 0.1356 0.1236 0.1196 0.1184 0.1180 0.1173 0.1165 0.1156 0.1149 0.1150 0.1144 0.1144 0.1140 

[TRAIN] Epoch[4](1021/1500); Loss: 0.118035; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1730 0.1988 0.1657 0.1328 0.1108 0.1042 0.1034 0.1022 0.1009 0.1003 0.0998 0.0994 0.0993 0.0991 0.0994 0.0996 

[TRAIN] Epoch[4](1022/1500); Loss: 0.086904; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1712 0.1276 0.1075 0.0975 0.0861 0.0770 0.0754 0.0735 0.0725 0.0722 0.0714 0.0716 0.0713 0.0718 0.0717 0.0721 

[TRAIN] Epoch[4](1023/1500); Loss: 0.200805; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2510 0.2617 0.2227 0.2074 0.1952 0.1944 0.1916 0.1913 0.1896 0.1888 0.1879 0.1878 0.1868 0.1862 0.1853 0.1852 

[TRAIN] Epoch[4](1024/1500); Loss: 0.067306; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1466 0.0945 0.0664 0.0788 0.0628 0.0587 0.0574 0.0559 0.0566 0.0558 0.0565 0.0563 0.0570 0.0570 0.0581 0.0583 

[TRAIN] Epoch[4](1025/1500); Loss: 0.145457; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2313 0.1724 0.1517 0.1470 0.1407 0.1364 0.1363 0.1362 0.1359 0.1354 0.1350 0.1344 0.1337 0.1336 0.1336 0.1338 

[TRAIN] Epoch[4](1026/1500); Loss: 0.127690; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2067 0.1746 0.1472 0.1309 0.1227 0.1190 0.1174 0.1153 0.1147 0.1136 0.1136 0.1131 0.1132 0.1135 0.1137 0.1140 

[TRAIN] Epoch[4](1027/1500); Loss: 0.144966; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2278 0.2244 0.2005 0.1653 0.1439 0.1323 0.1273 0.1248 0.1236 0.1221 0.1216 0.1210 0.1214 0.1211 0.1212 0.1213 

[TRAIN] Epoch[4](1028/1500); Loss: 0.151792; Backpropagation: 0.0930 sec; Batch: 0.4269 sec
0.1967 0.1898 0.1626 0.1528 0.1490 0.1457 0.1451 0.1437 0.1433 0.1430 0.1432 0.1431 0.1430 0.1426 0.1425 0.1426 

[TRAIN] Epoch[4](1029/1500); Loss: 0.138426; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2143 0.2112 0.1668 0.1441 0.1348 0.1312 0.1276 0.1261 0.1238 0.1221 0.1206 0.1198 0.1190 0.1184 0.1179 0.1174 

[TRAIN] Epoch[4](1030/1500); Loss: 0.084236; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1780 0.1086 0.0917 0.0812 0.0788 0.0747 0.0739 0.0727 0.0726 0.0723 0.0727 0.0729 0.0736 0.0741 0.0747 0.0752 

[TRAIN] Epoch[4](1031/1500); Loss: 0.108767; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1865 0.1527 0.1281 0.1129 0.1096 0.1029 0.1005 0.0978 0.0964 0.0950 0.0942 0.0933 0.0929 0.0925 0.0926 0.0923 

[TRAIN] Epoch[4](1032/1500); Loss: 0.111564; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1839 0.1392 0.1366 0.1094 0.1074 0.1002 0.1009 0.1001 0.1003 0.1004 0.1007 0.1008 0.1009 0.1009 0.1015 0.1019 

[TRAIN] Epoch[4](1033/1500); Loss: 0.073511; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1163 0.2440 0.1580 0.0673 0.0582 0.0448 0.0517 0.0474 0.0476 0.0463 0.0488 0.0470 0.0491 0.0485 0.0511 0.0500 

[TRAIN] Epoch[4](1034/1500); Loss: 0.103028; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1853 0.1656 0.1431 0.1137 0.0970 0.0914 0.0886 0.0872 0.0860 0.0850 0.0845 0.0843 0.0842 0.0841 0.0841 0.0844 

[TRAIN] Epoch[4](1035/1500); Loss: 0.096271; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2061 0.1379 0.1182 0.0976 0.0950 0.0846 0.0831 0.0812 0.0808 0.0802 0.0796 0.0792 0.0793 0.0791 0.0792 0.0793 

[TRAIN] Epoch[4](1036/1500); Loss: 0.091952; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1634 0.2348 0.1535 0.0848 0.0740 0.0663 0.0697 0.0677 0.0682 0.0675 0.0695 0.0686 0.0698 0.0698 0.0718 0.0717 

[TRAIN] Epoch[4](1037/1500); Loss: 0.111913; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1560 0.1446 0.1239 0.1133 0.1124 0.1065 0.1060 0.1037 0.1043 0.1028 0.1036 0.1023 0.1031 0.1025 0.1032 0.1024 

[TRAIN] Epoch[4](1038/1500); Loss: 0.101363; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.2636 0.1675 0.1094 0.0954 0.0856 0.0868 0.0827 0.0819 0.0814 0.0808 0.0807 0.0803 0.0807 0.0810 0.0817 0.0822 

[TRAIN] Epoch[4](1039/1500); Loss: 0.110018; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1520 0.1755 0.1251 0.1058 0.1014 0.1008 0.1006 0.1001 0.1000 0.0998 0.0997 0.0997 0.0999 0.0998 0.1000 0.1002 

[TRAIN] Epoch[4](1040/1500); Loss: 0.107403; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1397 0.1573 0.1205 0.1111 0.1043 0.1014 0.1010 0.0998 0.0987 0.0978 0.0979 0.0977 0.0978 0.0978 0.0979 0.0977 

[TRAIN] Epoch[4](1041/1500); Loss: 0.112543; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1344 0.1262 0.1169 0.1131 0.1113 0.1102 0.1105 0.1089 0.1089 0.1085 0.1086 0.1084 0.1084 0.1090 0.1088 0.1086 

[TRAIN] Epoch[4](1042/1500); Loss: 0.083700; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1597 0.1206 0.0884 0.0833 0.0820 0.0766 0.0747 0.0733 0.0735 0.0727 0.0724 0.0721 0.0724 0.0723 0.0726 0.0727 

[TRAIN] Epoch[4](1043/1500); Loss: 0.099344; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2677 0.1793 0.1330 0.0864 0.0926 0.0789 0.0798 0.0757 0.0759 0.0743 0.0742 0.0733 0.0750 0.0739 0.0748 0.0748 

[TRAIN] Epoch[4](1044/1500); Loss: 0.081150; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.2801 0.0720 0.1612 0.0862 0.0511 0.0774 0.0628 0.0534 0.0552 0.0552 0.0545 0.0557 0.0575 0.0578 0.0581 0.0602 

[TRAIN] Epoch[4](1045/1500); Loss: 0.066258; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2517 0.0847 0.0832 0.0418 0.0871 0.0521 0.0468 0.0425 0.0450 0.0437 0.0453 0.0446 0.0472 0.0468 0.0489 0.0487 

[TRAIN] Epoch[4](1046/1500); Loss: 0.103337; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.2161 0.1344 0.1129 0.1009 0.0957 0.0937 0.0909 0.0908 0.0901 0.0901 0.0892 0.0893 0.0893 0.0897 0.0899 0.0903 

[TRAIN] Epoch[4](1047/1500); Loss: 0.105338; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1907 0.1387 0.1096 0.1119 0.1000 0.0979 0.0953 0.0948 0.0940 0.0940 0.0935 0.0935 0.0932 0.0928 0.0928 0.0926 

[TRAIN] Epoch[4](1048/1500); Loss: 0.121171; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.2020 0.2468 0.2057 0.1403 0.0988 0.1005 0.0953 0.0969 0.0954 0.0940 0.0941 0.0935 0.0938 0.0937 0.0943 0.0939 

[TRAIN] Epoch[4](1049/1500); Loss: 0.068252; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.1238 0.1180 0.0842 0.0673 0.0611 0.0583 0.0575 0.0566 0.0572 0.0567 0.0570 0.0573 0.0582 0.0587 0.0597 0.0604 

[TRAIN] Epoch[4](1050/1500); Loss: 0.147893; Backpropagation: 0.0937 sec; Batch: 0.4631 sec
0.2059 0.2103 0.1659 0.1513 0.1425 0.1402 0.1381 0.1364 0.1355 0.1349 0.1344 0.1339 0.1342 0.1341 0.1343 0.1342 

[TRAIN] Epoch[4](1051/1500); Loss: 0.108354; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1522 0.1580 0.1140 0.1101 0.1033 0.1025 0.1006 0.1005 0.0991 0.0988 0.0988 0.0988 0.0987 0.0993 0.0994 0.0995 

[TRAIN] Epoch[4](1052/1500); Loss: 0.100833; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1606 0.1827 0.1375 0.1070 0.0934 0.0880 0.0871 0.0856 0.0850 0.0843 0.0840 0.0832 0.0835 0.0834 0.0840 0.0841 

[TRAIN] Epoch[4](1053/1500); Loss: 0.112839; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1505 0.1259 0.1164 0.1138 0.1108 0.1098 0.1093 0.1086 0.1077 0.1074 0.1075 0.1075 0.1075 0.1075 0.1075 0.1076 

[TRAIN] Epoch[4](1054/1500); Loss: 0.105628; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1521 0.1264 0.1071 0.1047 0.1017 0.1009 0.1005 0.1000 0.0995 0.0993 0.0992 0.0992 0.0994 0.0997 0.1000 0.1004 

[TRAIN] Epoch[4](1055/1500); Loss: 0.078326; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1518 0.1275 0.0918 0.0812 0.0759 0.0701 0.0687 0.0672 0.0667 0.0655 0.0652 0.0645 0.0646 0.0642 0.0643 0.0640 

[TRAIN] Epoch[4](1056/1500); Loss: 0.136664; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2079 0.1813 0.1582 0.1438 0.1318 0.1283 0.1266 0.1259 0.1248 0.1240 0.1231 0.1227 0.1222 0.1222 0.1219 0.1219 

[TRAIN] Epoch[4](1057/1500); Loss: 0.080862; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1232 0.1405 0.1011 0.0863 0.0758 0.0711 0.0700 0.0697 0.0692 0.0691 0.0691 0.0691 0.0695 0.0698 0.0700 0.0705 

[TRAIN] Epoch[4](1058/1500); Loss: 0.127108; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2128 0.1969 0.1508 0.1224 0.1151 0.1123 0.1123 0.1119 0.1113 0.1114 0.1115 0.1118 0.1122 0.1131 0.1134 0.1148 

[TRAIN] Epoch[4](1059/1500); Loss: 0.115575; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1865 0.1612 0.1480 0.1303 0.1081 0.1051 0.1039 0.1029 0.1020 0.1012 0.1004 0.1004 0.1001 0.0998 0.0996 0.0998 

[TRAIN] Epoch[4](1060/1500); Loss: 0.183160; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2523 0.2412 0.2236 0.1953 0.1788 0.1706 0.1688 0.1674 0.1670 0.1669 0.1665 0.1661 0.1662 0.1663 0.1666 0.1668 

[TRAIN] Epoch[4](1061/1500); Loss: 0.186822; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.2508 0.2153 0.2094 0.1963 0.1854 0.1811 0.1784 0.1770 0.1759 0.1751 0.1745 0.1743 0.1741 0.1739 0.1736 0.1739 

[TRAIN] Epoch[4](1062/1500); Loss: 0.076196; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1012 0.1310 0.1135 0.0962 0.0745 0.0671 0.0660 0.0647 0.0636 0.0628 0.0628 0.0628 0.0628 0.0630 0.0633 0.0637 

[TRAIN] Epoch[4](1063/1500); Loss: 0.077149; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1179 0.1286 0.1267 0.1065 0.0787 0.0646 0.0621 0.0619 0.0613 0.0607 0.0604 0.0609 0.0609 0.0609 0.0611 0.0612 

[TRAIN] Epoch[4](1064/1500); Loss: 0.109502; Backpropagation: 0.0930 sec; Batch: 0.4272 sec
0.1865 0.1671 0.1193 0.1092 0.1059 0.1033 0.1017 0.0990 0.0977 0.0966 0.0955 0.0948 0.0943 0.0938 0.0935 0.0937 

[TRAIN] Epoch[4](1065/1500); Loss: 0.106568; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.2431 0.1531 0.1109 0.1033 0.0958 0.0938 0.0916 0.0911 0.0907 0.0904 0.0903 0.0901 0.0900 0.0903 0.0903 0.0905 

[TRAIN] Epoch[4](1066/1500); Loss: 0.090535; Backpropagation: 0.0979 sec; Batch: 0.4323 sec
0.1812 0.1190 0.0944 0.0864 0.0845 0.0813 0.0809 0.0805 0.0801 0.0800 0.0801 0.0801 0.0799 0.0799 0.0800 0.0802 

[TRAIN] Epoch[4](1067/1500); Loss: 0.068997; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.1634 0.1108 0.0741 0.0661 0.0611 0.0594 0.0581 0.0577 0.0567 0.0570 0.0562 0.0563 0.0567 0.0564 0.0566 0.0571 

[TRAIN] Epoch[4](1068/1500); Loss: 0.115821; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1845 0.1480 0.1544 0.1408 0.1258 0.1135 0.1082 0.1041 0.1011 0.0989 0.0974 0.0963 0.0955 0.0949 0.0949 0.0948 

[TRAIN] Epoch[4](1069/1500); Loss: 0.132876; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1670 0.1542 0.1493 0.1397 0.1328 0.1292 0.1282 0.1269 0.1261 0.1260 0.1256 0.1249 0.1242 0.1243 0.1240 0.1236 

[TRAIN] Epoch[4](1070/1500); Loss: 0.163697; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2119 0.2112 0.2073 0.1883 0.1674 0.1569 0.1532 0.1510 0.1491 0.1479 0.1468 0.1463 0.1459 0.1455 0.1454 0.1451 

[TRAIN] Epoch[4](1071/1500); Loss: 0.083015; Backpropagation: 0.0943 sec; Batch: 0.4295 sec
0.1900 0.0954 0.1080 0.1039 0.0903 0.0736 0.0685 0.0668 0.0662 0.0657 0.0663 0.0665 0.0664 0.0666 0.0669 0.0672 

[TRAIN] Epoch[4](1072/1500); Loss: 0.160869; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2393 0.1877 0.1732 0.1670 0.1554 0.1540 0.1520 0.1513 0.1506 0.1504 0.1493 0.1488 0.1489 0.1489 0.1486 0.1485 

[TRAIN] Epoch[4](1073/1500); Loss: 0.129673; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1624 0.1614 0.1374 0.1325 0.1297 0.1270 0.1254 0.1240 0.1232 0.1226 0.1223 0.1219 0.1216 0.1212 0.1210 0.1210 

[TRAIN] Epoch[4](1074/1500); Loss: 0.082381; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2624 0.0928 0.1003 0.0658 0.0699 0.0688 0.0665 0.0654 0.0645 0.0651 0.0653 0.0655 0.0659 0.0664 0.0665 0.0671 

[TRAIN] Epoch[4](1075/1500); Loss: 0.074955; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1226 0.1129 0.0791 0.0752 0.0710 0.0691 0.0679 0.0673 0.0669 0.0666 0.0665 0.0667 0.0667 0.0667 0.0670 0.0670 

[TRAIN] Epoch[4](1076/1500); Loss: 0.065416; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.3139 0.1044 0.0896 0.0349 0.0521 0.0487 0.0407 0.0395 0.0392 0.0389 0.0386 0.0395 0.0403 0.0414 0.0422 0.0428 

[TRAIN] Epoch[4](1077/1500); Loss: 0.083627; Backpropagation: 0.0960 sec; Batch: 0.4317 sec
0.2034 0.1098 0.0824 0.0810 0.0757 0.0757 0.0735 0.0727 0.0713 0.0714 0.0707 0.0708 0.0701 0.0703 0.0695 0.0698 

[TRAIN] Epoch[4](1078/1500); Loss: 0.054892; Backpropagation: 0.0957 sec; Batch: 0.4308 sec
0.0807 0.0967 0.0608 0.0608 0.0527 0.0514 0.0494 0.0486 0.0477 0.0477 0.0472 0.0470 0.0471 0.0469 0.0467 0.0469 

[TRAIN] Epoch[4](1079/1500); Loss: 0.114917; Backpropagation: 0.0957 sec; Batch: 0.4292 sec
0.2027 0.1678 0.1282 0.1132 0.1088 0.1048 0.1031 0.1021 0.1014 0.1010 0.1009 0.1008 0.1009 0.1009 0.1010 0.1011 

[TRAIN] Epoch[4](1080/1500); Loss: 0.158070; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2094 0.2062 0.1810 0.1656 0.1549 0.1506 0.1486 0.1474 0.1470 0.1466 0.1462 0.1457 0.1454 0.1450 0.1448 0.1447 

[TRAIN] Epoch[4](1081/1500); Loss: 0.112815; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.1581 0.1718 0.1350 0.1211 0.1087 0.1045 0.1027 0.1018 0.1010 0.1007 0.1003 0.1000 0.0998 0.0999 0.0998 0.1000 

[TRAIN] Epoch[4](1082/1500); Loss: 0.128264; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2084 0.1563 0.1458 0.1384 0.1314 0.1227 0.1190 0.1168 0.1154 0.1148 0.1143 0.1140 0.1138 0.1138 0.1137 0.1136 

[TRAIN] Epoch[4](1083/1500); Loss: 0.102952; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.2951 0.1491 0.1269 0.0919 0.0940 0.0860 0.0826 0.0813 0.0813 0.0798 0.0799 0.0797 0.0796 0.0798 0.0800 0.0804 

[TRAIN] Epoch[4](1084/1500); Loss: 0.161696; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2320 0.2279 0.1835 0.1654 0.1570 0.1530 0.1507 0.1490 0.1478 0.1470 0.1464 0.1459 0.1457 0.1456 0.1452 0.1451 

[TRAIN] Epoch[4](1085/1500); Loss: 0.129759; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2045 0.1752 0.1480 0.1308 0.1251 0.1217 0.1206 0.1196 0.1183 0.1177 0.1170 0.1164 0.1161 0.1154 0.1150 0.1146 

[TRAIN] Epoch[4](1086/1500); Loss: 0.068318; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.0885 0.1428 0.1006 0.0803 0.0637 0.0588 0.0580 0.0570 0.0570 0.0563 0.0558 0.0557 0.0553 0.0549 0.0545 0.0540 

[TRAIN] Epoch[4](1087/1500); Loss: 0.119251; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1523 0.1394 0.1311 0.1238 0.1182 0.1150 0.1142 0.1131 0.1129 0.1126 0.1126 0.1125 0.1127 0.1126 0.1126 0.1126 

[TRAIN] Epoch[4](1088/1500); Loss: 0.076386; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1976 0.1268 0.0882 0.0706 0.0668 0.0642 0.0627 0.0617 0.0611 0.0603 0.0602 0.0602 0.0601 0.0603 0.0604 0.0608 

[TRAIN] Epoch[4](1089/1500); Loss: 0.158301; Backpropagation: 0.0981 sec; Batch: 0.4333 sec
0.2142 0.1445 0.2154 0.1978 0.1692 0.1506 0.1443 0.1438 0.1444 0.1437 0.1447 0.1438 0.1439 0.1442 0.1444 0.1439 

[TRAIN] Epoch[4](1090/1500); Loss: 0.069229; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.1521 0.0853 0.0850 0.0629 0.0653 0.0597 0.0584 0.0576 0.0579 0.0583 0.0587 0.0591 0.0602 0.0612 0.0624 0.0635 

[TRAIN] Epoch[4](1091/1500); Loss: 0.071102; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.0784 0.1016 0.0706 0.0675 0.0675 0.0676 0.0674 0.0674 0.0679 0.0682 0.0680 0.0683 0.0689 0.0691 0.0695 0.0698 

[TRAIN] Epoch[4](1092/1500); Loss: 0.150412; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1539 0.1273 0.1269 0.1393 0.1394 0.1409 0.1445 0.1489 0.1507 0.1530 0.1561 0.1590 0.1617 0.1649 0.1684 0.1716 

[TRAIN] Epoch[4](1093/1500); Loss: 0.095546; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2213 0.1499 0.1087 0.1109 0.0963 0.0883 0.0815 0.0781 0.0761 0.0748 0.0741 0.0739 0.0735 0.0736 0.0737 0.0740 

[TRAIN] Epoch[4](1094/1500); Loss: 0.045220; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.0954 0.0786 0.0501 0.0521 0.0450 0.0407 0.0386 0.0370 0.0365 0.0356 0.0354 0.0359 0.0353 0.0356 0.0354 0.0362 

[TRAIN] Epoch[4](1095/1500); Loss: 0.115449; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.2447 0.1404 0.1185 0.1133 0.1087 0.1061 0.1035 0.1024 0.1014 0.1012 0.1013 0.1011 0.1009 0.1013 0.1012 0.1012 

[TRAIN] Epoch[4](1096/1500); Loss: 0.057403; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.0910 0.1353 0.1042 0.0786 0.0530 0.0450 0.0427 0.0417 0.0408 0.0408 0.0404 0.0407 0.0407 0.0412 0.0411 0.0414 

[TRAIN] Epoch[4](1097/1500); Loss: 0.101330; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2439 0.1537 0.1114 0.0998 0.0871 0.0856 0.0836 0.0835 0.0831 0.0833 0.0835 0.0839 0.0840 0.0845 0.0849 0.0854 

[TRAIN] Epoch[4](1098/1500); Loss: 0.062353; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.3274 0.1055 0.0783 0.0361 0.0652 0.0390 0.0335 0.0328 0.0349 0.0321 0.0333 0.0338 0.0352 0.0357 0.0370 0.0380 

[TRAIN] Epoch[4](1099/1500); Loss: 0.167784; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2245 0.2359 0.2018 0.1808 0.1621 0.1545 0.1547 0.1537 0.1528 0.1525 0.1520 0.1522 0.1519 0.1519 0.1515 0.1515 

[TRAIN] Epoch[4](1100/1500); Loss: 0.115371; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.2083 0.1852 0.1322 0.1152 0.1076 0.1041 0.1027 0.1010 0.0993 0.0984 0.0981 0.0982 0.0983 0.0988 0.0991 0.0995 

[TRAIN] Epoch[4](1101/1500); Loss: 0.045841; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.0603 0.0585 0.1039 0.0966 0.0580 0.0370 0.0326 0.0318 0.0313 0.0315 0.0314 0.0315 0.0318 0.0322 0.0323 0.0328 

[TRAIN] Epoch[4](1102/1500); Loss: 0.095475; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1851 0.1122 0.1043 0.0947 0.0907 0.0877 0.0860 0.0856 0.0850 0.0850 0.0848 0.0848 0.0850 0.0853 0.0856 0.0858 

[TRAIN] Epoch[4](1103/1500); Loss: 0.099764; Backpropagation: 0.0951 sec; Batch: 0.4294 sec
0.1787 0.1400 0.1193 0.1065 0.0980 0.0926 0.0897 0.0877 0.0868 0.0859 0.0855 0.0850 0.0849 0.0850 0.0852 0.0854 

[TRAIN] Epoch[4](1104/1500); Loss: 0.103592; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1533 0.1251 0.1131 0.1046 0.1011 0.0993 0.0978 0.0968 0.0963 0.0958 0.0956 0.0956 0.0956 0.0957 0.0958 0.0959 

[TRAIN] Epoch[4](1105/1500); Loss: 0.076536; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1456 0.1150 0.0932 0.0771 0.0737 0.0696 0.0675 0.0660 0.0651 0.0647 0.0642 0.0642 0.0642 0.0646 0.0646 0.0652 

[TRAIN] Epoch[4](1106/1500); Loss: 0.065909; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1349 0.1732 0.1127 0.0781 0.0532 0.0465 0.0449 0.0444 0.0443 0.0449 0.0450 0.0456 0.0460 0.0465 0.0469 0.0474 

[TRAIN] Epoch[4](1107/1500); Loss: 0.078285; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2304 0.1175 0.0819 0.0786 0.0672 0.0653 0.0617 0.0619 0.0610 0.0607 0.0605 0.0608 0.0611 0.0611 0.0613 0.0616 

[TRAIN] Epoch[4](1108/1500); Loss: 0.072811; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.0985 0.1166 0.1064 0.0971 0.0759 0.0651 0.0615 0.0604 0.0603 0.0603 0.0602 0.0603 0.0604 0.0604 0.0606 0.0610 

[TRAIN] Epoch[4](1109/1500); Loss: 0.078786; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1792 0.0881 0.0940 0.0775 0.0748 0.0698 0.0685 0.0679 0.0675 0.0673 0.0670 0.0674 0.0674 0.0679 0.0679 0.0685 

[TRAIN] Epoch[4](1110/1500); Loss: 0.101441; Backpropagation: 0.0930 sec; Batch: 0.4271 sec
0.2194 0.1173 0.1094 0.0973 0.0963 0.0928 0.0916 0.0906 0.0899 0.0893 0.0888 0.0884 0.0882 0.0882 0.0878 0.0878 

[TRAIN] Epoch[4](1111/1500); Loss: 0.051276; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1204 0.0721 0.0564 0.0543 0.0492 0.0460 0.0440 0.0425 0.0423 0.0418 0.0414 0.0414 0.0417 0.0419 0.0423 0.0427 

[TRAIN] Epoch[4](1112/1500); Loss: 0.072596; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1262 0.2049 0.1522 0.1164 0.0699 0.0496 0.0468 0.0454 0.0445 0.0438 0.0435 0.0432 0.0437 0.0434 0.0437 0.0441 

[TRAIN] Epoch[4](1113/1500); Loss: 0.118291; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1654 0.1561 0.1427 0.1317 0.1163 0.1099 0.1075 0.1065 0.1064 0.1065 0.1067 0.1070 0.1071 0.1073 0.1075 0.1080 

[TRAIN] Epoch[4](1114/1500); Loss: 0.123029; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1658 0.2055 0.1654 0.1410 0.1189 0.1127 0.1102 0.1086 0.1077 0.1068 0.1058 0.1047 0.1042 0.1039 0.1037 0.1036 

[TRAIN] Epoch[4](1115/1500); Loss: 0.080878; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1416 0.1123 0.1144 0.1096 0.0918 0.0761 0.0683 0.0659 0.0649 0.0644 0.0641 0.0640 0.0641 0.0641 0.0641 0.0643 

[TRAIN] Epoch[4](1116/1500); Loss: 0.122215; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1572 0.1652 0.1538 0.1411 0.1235 0.1170 0.1143 0.1125 0.1113 0.1108 0.1098 0.1086 0.1080 0.1077 0.1075 0.1071 

[TRAIN] Epoch[4](1117/1500); Loss: 0.111225; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1682 0.1457 0.1197 0.1146 0.1077 0.1055 0.1040 0.1035 0.1031 0.1019 0.1015 0.1014 0.1012 0.1008 0.1004 0.1004 

[TRAIN] Epoch[4](1118/1500); Loss: 0.099585; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1589 0.1388 0.1129 0.1023 0.0966 0.0937 0.0923 0.0911 0.0901 0.0891 0.0889 0.0883 0.0881 0.0876 0.0875 0.0872 

[TRAIN] Epoch[4](1119/1500); Loss: 0.132376; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1846 0.1550 0.1502 0.1348 0.1298 0.1260 0.1259 0.1251 0.1242 0.1238 0.1236 0.1234 0.1230 0.1227 0.1229 0.1229 

[TRAIN] Epoch[4](1120/1500); Loss: 0.131089; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2743 0.1858 0.1369 0.1241 0.1216 0.1179 0.1167 0.1149 0.1139 0.1137 0.1133 0.1129 0.1128 0.1129 0.1128 0.1130 

[TRAIN] Epoch[4](1121/1500); Loss: 0.124704; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.2218 0.1839 0.1428 0.1309 0.1196 0.1135 0.1114 0.1101 0.1097 0.1091 0.1084 0.1077 0.1072 0.1068 0.1064 0.1060 

[TRAIN] Epoch[4](1122/1500); Loss: 0.114436; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1452 0.1799 0.1521 0.1331 0.1135 0.1063 0.1041 0.1030 0.1014 0.1006 0.0998 0.0991 0.0988 0.0983 0.0980 0.0978 

[TRAIN] Epoch[4](1123/1500); Loss: 0.112577; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1871 0.1523 0.1267 0.1119 0.1088 0.1043 0.1028 0.1021 0.1017 0.1010 0.1007 0.1003 0.1005 0.1004 0.1005 0.1004 

[TRAIN] Epoch[4](1124/1500); Loss: 0.060744; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.1408 0.0872 0.0617 0.0667 0.0548 0.0524 0.0515 0.0513 0.0510 0.0508 0.0505 0.0505 0.0505 0.0507 0.0507 0.0509 

[TRAIN] Epoch[4](1125/1500); Loss: 0.094639; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2008 0.1098 0.1048 0.0964 0.0874 0.0861 0.0840 0.0836 0.0830 0.0826 0.0826 0.0827 0.0826 0.0826 0.0826 0.0828 

[TRAIN] Epoch[4](1126/1500); Loss: 0.067572; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1755 0.0858 0.0710 0.0660 0.0617 0.0589 0.0577 0.0568 0.0564 0.0561 0.0558 0.0557 0.0558 0.0560 0.0559 0.0562 

[TRAIN] Epoch[4](1127/1500); Loss: 0.083386; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.3312 0.1459 0.0741 0.0746 0.0747 0.0640 0.0580 0.0582 0.0578 0.0567 0.0561 0.0565 0.0564 0.0564 0.0562 0.0575 

[TRAIN] Epoch[4](1128/1500); Loss: 0.094240; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2373 0.1414 0.0951 0.0902 0.0855 0.0829 0.0795 0.0789 0.0784 0.0780 0.0774 0.0770 0.0766 0.0767 0.0764 0.0764 

[TRAIN] Epoch[4](1129/1500); Loss: 0.113604; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1572 0.1440 0.1256 0.1198 0.1135 0.1094 0.1075 0.1064 0.1056 0.1052 0.1046 0.1044 0.1039 0.1037 0.1035 0.1035 

[TRAIN] Epoch[4](1130/1500); Loss: 0.125232; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1638 0.1513 0.1401 0.1345 0.1244 0.1199 0.1187 0.1179 0.1174 0.1170 0.1165 0.1163 0.1163 0.1164 0.1165 0.1169 

[TRAIN] Epoch[4](1131/1500); Loss: 0.151527; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.2014 0.2289 0.1798 0.1572 0.1449 0.1422 0.1406 0.1394 0.1386 0.1374 0.1364 0.1362 0.1359 0.1355 0.1351 0.1350 

[TRAIN] Epoch[4](1132/1500); Loss: 0.142446; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2241 0.2176 0.1766 0.1507 0.1366 0.1303 0.1283 0.1269 0.1258 0.1246 0.1237 0.1232 0.1231 0.1230 0.1226 0.1220 

[TRAIN] Epoch[4](1133/1500); Loss: 0.150301; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2211 0.1393 0.1877 0.1718 0.1551 0.1452 0.1394 0.1378 0.1387 0.1379 0.1381 0.1384 0.1385 0.1383 0.1385 0.1391 

[TRAIN] Epoch[4](1134/1500); Loss: 0.120060; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.1922 0.1510 0.1384 0.1257 0.1181 0.1144 0.1122 0.1106 0.1090 0.1084 0.1076 0.1069 0.1066 0.1065 0.1067 0.1067 

[TRAIN] Epoch[4](1135/1500); Loss: 0.116400; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1628 0.1423 0.1292 0.1193 0.1143 0.1106 0.1097 0.1093 0.1088 0.1084 0.1077 0.1079 0.1077 0.1077 0.1081 0.1085 

[TRAIN] Epoch[4](1136/1500); Loss: 0.129316; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1555 0.1775 0.1499 0.1365 0.1251 0.1217 0.1208 0.1207 0.1205 0.1204 0.1201 0.1199 0.1199 0.1201 0.1202 0.1203 

[TRAIN] Epoch[4](1137/1500); Loss: 0.069136; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1043 0.1819 0.1404 0.1174 0.0806 0.0587 0.0482 0.0447 0.0429 0.0423 0.0414 0.0410 0.0405 0.0406 0.0405 0.0408 

[TRAIN] Epoch[4](1138/1500); Loss: 0.070565; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1074 0.1067 0.0796 0.0749 0.0672 0.0649 0.0640 0.0632 0.0623 0.0622 0.0622 0.0623 0.0624 0.0628 0.0633 0.0635 

[TRAIN] Epoch[4](1139/1500); Loss: 0.090635; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1622 0.1125 0.1049 0.0900 0.0860 0.0833 0.0820 0.0813 0.0809 0.0807 0.0807 0.0808 0.0808 0.0810 0.0813 0.0818 

[TRAIN] Epoch[4](1140/1500); Loss: 0.061500; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1028 0.0810 0.0735 0.0630 0.0602 0.0580 0.0568 0.0561 0.0551 0.0546 0.0542 0.0539 0.0538 0.0535 0.0536 0.0540 

[TRAIN] Epoch[4](1141/1500); Loss: 0.078978; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1461 0.1019 0.0829 0.0767 0.0744 0.0732 0.0729 0.0723 0.0716 0.0709 0.0706 0.0703 0.0701 0.0700 0.0699 0.0699 

[TRAIN] Epoch[4](1142/1500); Loss: 0.152619; Backpropagation: 0.0957 sec; Batch: 0.4298 sec
0.2159 0.2127 0.1666 0.1556 0.1446 0.1421 0.1415 0.1410 0.1408 0.1403 0.1402 0.1403 0.1402 0.1400 0.1400 0.1400 

[TRAIN] Epoch[4](1143/1500); Loss: 0.091853; Backpropagation: 0.0959 sec; Batch: 0.4306 sec
0.1346 0.1667 0.1175 0.0986 0.0842 0.0819 0.0803 0.0794 0.0788 0.0787 0.0781 0.0781 0.0777 0.0781 0.0783 0.0786 

[TRAIN] Epoch[4](1144/1500); Loss: 0.137707; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1754 0.1712 0.1462 0.1402 0.1359 0.1339 0.1326 0.1319 0.1313 0.1307 0.1302 0.1295 0.1289 0.1286 0.1284 0.1284 

[TRAIN] Epoch[4](1145/1500); Loss: 0.139403; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1914 0.1597 0.1480 0.1413 0.1370 0.1349 0.1339 0.1332 0.1322 0.1318 0.1315 0.1313 0.1313 0.1311 0.1308 0.1309 

[TRAIN] Epoch[4](1146/1500); Loss: 0.097145; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.2024 0.1102 0.1148 0.0989 0.0956 0.0881 0.0864 0.0852 0.0849 0.0840 0.0838 0.0834 0.0840 0.0838 0.0844 0.0845 

[TRAIN] Epoch[4](1147/1500); Loss: 0.075482; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.0996 0.1213 0.0806 0.0792 0.0703 0.0698 0.0690 0.0704 0.0685 0.0688 0.0680 0.0688 0.0679 0.0687 0.0678 0.0690 

[TRAIN] Epoch[4](1148/1500); Loss: 0.070284; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1012 0.1198 0.0902 0.0894 0.0738 0.0677 0.0631 0.0609 0.0587 0.0577 0.0571 0.0573 0.0567 0.0569 0.0570 0.0571 

[TRAIN] Epoch[4](1149/1500); Loss: 0.077581; Backpropagation: 0.0946 sec; Batch: 0.4285 sec
0.2466 0.1190 0.0734 0.0769 0.0654 0.0662 0.0611 0.0602 0.0599 0.0587 0.0589 0.0588 0.0592 0.0589 0.0594 0.0587 

[TRAIN] Epoch[4](1150/1500); Loss: 0.099004; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1392 0.1608 0.1267 0.1087 0.0974 0.0905 0.0878 0.0864 0.0861 0.0859 0.0858 0.0855 0.0855 0.0857 0.0859 0.0859 

[TRAIN] Epoch[4](1151/1500); Loss: 0.065563; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.0948 0.0807 0.0735 0.0728 0.0645 0.0624 0.0612 0.0617 0.0604 0.0601 0.0595 0.0595 0.0593 0.0597 0.0593 0.0595 

[TRAIN] Epoch[4](1152/1500); Loss: 0.115504; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1631 0.1581 0.1324 0.1187 0.1118 0.1087 0.1074 0.1068 0.1058 0.1053 0.1053 0.1050 0.1050 0.1048 0.1048 0.1050 

[TRAIN] Epoch[4](1153/1500); Loss: 0.109516; Backpropagation: 0.0944 sec; Batch: 0.4289 sec
0.1601 0.1325 0.1750 0.1575 0.1307 0.1062 0.0930 0.0898 0.0890 0.0886 0.0878 0.0882 0.0881 0.0884 0.0885 0.0891 

[TRAIN] Epoch[4](1154/1500); Loss: 0.091370; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.1208 0.0798 0.1307 0.1228 0.0918 0.0807 0.0804 0.0818 0.0823 0.0829 0.0844 0.0846 0.0848 0.0846 0.0848 0.0849 

[TRAIN] Epoch[4](1155/1500); Loss: 0.086969; Backpropagation: 0.0956 sec; Batch: 0.4299 sec
0.2119 0.1290 0.1065 0.0991 0.0838 0.0785 0.0732 0.0711 0.0696 0.0684 0.0672 0.0669 0.0668 0.0666 0.0663 0.0664 

[TRAIN] Epoch[4](1156/1500); Loss: 0.160188; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2409 0.2308 0.1742 0.1583 0.1554 0.1498 0.1484 0.1471 0.1464 0.1455 0.1449 0.1444 0.1444 0.1442 0.1443 0.1441 

[TRAIN] Epoch[4](1157/1500); Loss: 0.116249; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2335 0.1682 0.1250 0.1171 0.1111 0.1078 0.1032 0.1016 0.1003 0.1002 0.0990 0.0989 0.0985 0.0988 0.0984 0.0985 

[TRAIN] Epoch[4](1158/1500); Loss: 0.077403; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.3656 0.1633 0.0542 0.0749 0.0543 0.0606 0.0501 0.0498 0.0470 0.0465 0.0459 0.0452 0.0452 0.0450 0.0455 0.0453 

[TRAIN] Epoch[4](1159/1500); Loss: 0.056249; Backpropagation: 0.0938 sec; Batch: 0.4273 sec
0.0584 0.1269 0.1017 0.0844 0.0599 0.0471 0.0433 0.0420 0.0421 0.0413 0.0413 0.0420 0.0417 0.0422 0.0426 0.0430 

[TRAIN] Epoch[4](1160/1500); Loss: 0.105071; Backpropagation: 0.0958 sec; Batch: 0.4308 sec
0.2069 0.1382 0.1106 0.1102 0.0983 0.0968 0.0938 0.0934 0.0921 0.0919 0.0916 0.0917 0.0914 0.0913 0.0913 0.0916 

[TRAIN] Epoch[4](1161/1500); Loss: 0.058961; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1364 0.0699 0.0743 0.0562 0.0546 0.0507 0.0491 0.0499 0.0494 0.0499 0.0499 0.0500 0.0500 0.0509 0.0509 0.0511 

[TRAIN] Epoch[4](1162/1500); Loss: 0.053649; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1458 0.0640 0.0649 0.0513 0.0528 0.0467 0.0448 0.0451 0.0435 0.0433 0.0428 0.0428 0.0425 0.0427 0.0428 0.0427 

[TRAIN] Epoch[4](1163/1500); Loss: 0.129765; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1914 0.1736 0.1406 0.1298 0.1263 0.1233 0.1223 0.1212 0.1205 0.1195 0.1188 0.1185 0.1180 0.1176 0.1175 0.1173 

[TRAIN] Epoch[4](1164/1500); Loss: 0.119070; Backpropagation: 0.0933 sec; Batch: 0.4293 sec
0.1751 0.1611 0.1516 0.1398 0.1221 0.1114 0.1085 0.1068 0.1052 0.1045 0.1038 0.1034 0.1031 0.1030 0.1029 0.1029 

[TRAIN] Epoch[4](1165/1500); Loss: 0.120753; Backpropagation: 0.0932 sec; Batch: 0.4280 sec
0.2039 0.1757 0.1374 0.1170 0.1171 0.1131 0.1118 0.1099 0.1091 0.1081 0.1063 0.1055 0.1046 0.1044 0.1037 0.1043 

[TRAIN] Epoch[4](1166/1500); Loss: 0.080973; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1206 0.1000 0.0845 0.0834 0.0777 0.0782 0.0768 0.0768 0.0756 0.0751 0.0747 0.0748 0.0747 0.0746 0.0742 0.0738 

[TRAIN] Epoch[4](1167/1500); Loss: 0.117896; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.2219 0.1565 0.1402 0.1327 0.1145 0.1086 0.1043 0.1030 0.1018 0.1010 0.1007 0.1004 0.1003 0.1002 0.1001 0.1002 

[TRAIN] Epoch[4](1168/1500); Loss: 0.119451; Backpropagation: 0.0931 sec; Batch: 0.4275 sec
0.2359 0.2192 0.1454 0.1319 0.1079 0.1033 0.0994 0.0981 0.0974 0.0968 0.0963 0.0963 0.0960 0.0958 0.0956 0.0958 

[TRAIN] Epoch[4](1169/1500); Loss: 0.106016; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1927 0.1479 0.1148 0.1082 0.0997 0.0976 0.0959 0.0953 0.0942 0.0934 0.0929 0.0927 0.0926 0.0927 0.0928 0.0927 

[TRAIN] Epoch[4](1170/1500); Loss: 0.047305; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1139 0.1020 0.0767 0.0618 0.0470 0.0355 0.0324 0.0318 0.0327 0.0318 0.0312 0.0311 0.0323 0.0317 0.0321 0.0330 

[TRAIN] Epoch[4](1171/1500); Loss: 0.091766; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1416 0.1193 0.1002 0.0934 0.0889 0.0867 0.0859 0.0854 0.0843 0.0839 0.0833 0.0833 0.0828 0.0831 0.0829 0.0833 

[TRAIN] Epoch[4](1172/1500); Loss: 0.111686; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.2194 0.1762 0.1338 0.1055 0.1009 0.0973 0.0975 0.0966 0.0963 0.0954 0.0949 0.0947 0.0947 0.0945 0.0946 0.0948 

[TRAIN] Epoch[4](1173/1500); Loss: 0.069198; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.1281 0.1527 0.1019 0.0725 0.0637 0.0551 0.0544 0.0541 0.0542 0.0529 0.0528 0.0533 0.0526 0.0529 0.0528 0.0533 

[TRAIN] Epoch[4](1174/1500); Loss: 0.107716; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1837 0.1250 0.1173 0.1048 0.1026 0.1012 0.0998 0.0997 0.0991 0.0989 0.0986 0.0985 0.0983 0.0985 0.0988 0.0989 

[TRAIN] Epoch[4](1175/1500); Loss: 0.155058; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2113 0.1702 0.1593 0.1534 0.1512 0.1499 0.1494 0.1489 0.1489 0.1488 0.1484 0.1482 0.1480 0.1482 0.1484 0.1483 

[TRAIN] Epoch[4](1176/1500); Loss: 0.084281; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1147 0.1210 0.0926 0.0837 0.0805 0.0791 0.0785 0.0784 0.0782 0.0777 0.0776 0.0773 0.0774 0.0773 0.0773 0.0773 

[TRAIN] Epoch[4](1177/1500); Loss: 0.058683; Backpropagation: 0.0959 sec; Batch: 0.4314 sec
0.1049 0.0897 0.0634 0.0612 0.0575 0.0545 0.0535 0.0530 0.0517 0.0510 0.0504 0.0503 0.0497 0.0495 0.0494 0.0493 

[TRAIN] Epoch[4](1178/1500); Loss: 0.089671; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1262 0.0781 0.1191 0.1050 0.0828 0.0802 0.0813 0.0830 0.0836 0.0838 0.0840 0.0859 0.0848 0.0847 0.0854 0.0868 

[TRAIN] Epoch[4](1179/1500); Loss: 0.120019; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2310 0.1812 0.1329 0.1157 0.1116 0.1087 0.1070 0.1060 0.1052 0.1044 0.1038 0.1033 0.1027 0.1023 0.1024 0.1020 

[TRAIN] Epoch[4](1180/1500); Loss: 0.075498; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1225 0.0729 0.1419 0.1215 0.0871 0.0661 0.0582 0.0592 0.0592 0.0597 0.0590 0.0594 0.0600 0.0601 0.0604 0.0608 

[TRAIN] Epoch[4](1181/1500); Loss: 0.129686; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1899 0.1821 0.1480 0.1324 0.1258 0.1220 0.1205 0.1194 0.1184 0.1174 0.1169 0.1168 0.1165 0.1163 0.1163 0.1162 

[TRAIN] Epoch[4](1182/1500); Loss: 0.079200; Backpropagation: 0.0931 sec; Batch: 0.4274 sec
0.2844 0.1588 0.0672 0.0711 0.0581 0.0627 0.0552 0.0566 0.0559 0.0564 0.0557 0.0566 0.0564 0.0573 0.0570 0.0578 

[TRAIN] Epoch[4](1183/1500); Loss: 0.044158; Backpropagation: 0.0981 sec; Batch: 0.4336 sec
0.0785 0.0521 0.0706 0.0626 0.0407 0.0370 0.0363 0.0357 0.0356 0.0359 0.0359 0.0363 0.0365 0.0371 0.0377 0.0382 

[TRAIN] Epoch[4](1184/1500); Loss: 0.061144; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.1357 0.1047 0.0782 0.0701 0.0590 0.0534 0.0502 0.0491 0.0480 0.0477 0.0472 0.0472 0.0469 0.0470 0.0469 0.0471 

[TRAIN] Epoch[4](1185/1500); Loss: 0.175911; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.2550 0.2506 0.2100 0.1866 0.1704 0.1652 0.1615 0.1599 0.1584 0.1580 0.1573 0.1567 0.1564 0.1563 0.1562 0.1561 

[TRAIN] Epoch[4](1186/1500); Loss: 0.114694; Backpropagation: 0.0937 sec; Batch: 0.4270 sec
0.2324 0.1533 0.1242 0.1142 0.1080 0.1031 0.1016 0.1013 0.1011 0.1002 0.0998 0.0995 0.0993 0.0991 0.0989 0.0992 

[TRAIN] Epoch[4](1187/1500); Loss: 0.065206; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.0896 0.1014 0.0731 0.0664 0.0621 0.0602 0.0596 0.0589 0.0589 0.0588 0.0587 0.0588 0.0589 0.0591 0.0593 0.0595 

[TRAIN] Epoch[4](1188/1500); Loss: 0.204139; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2379 0.1958 0.2410 0.2227 0.2080 0.2015 0.1989 0.1982 0.1984 0.1972 0.1966 0.1959 0.1954 0.1938 0.1929 0.1921 

[TRAIN] Epoch[4](1189/1500); Loss: 0.089871; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.2048 0.1399 0.0951 0.0851 0.0793 0.0786 0.0772 0.0763 0.0758 0.0755 0.0752 0.0748 0.0751 0.0751 0.0751 0.0751 

[TRAIN] Epoch[4](1190/1500); Loss: 0.081519; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.3236 0.1553 0.0699 0.0775 0.0594 0.0647 0.0593 0.0576 0.0560 0.0551 0.0546 0.0542 0.0546 0.0542 0.0541 0.0542 

[TRAIN] Epoch[4](1191/1500); Loss: 0.090292; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1730 0.1505 0.1086 0.0904 0.0820 0.0789 0.0780 0.0774 0.0767 0.0760 0.0758 0.0753 0.0753 0.0754 0.0756 0.0757 

[TRAIN] Epoch[4](1192/1500); Loss: 0.175553; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.2425 0.1664 0.2257 0.2101 0.2018 0.1890 0.1761 0.1652 0.1576 0.1539 0.1533 0.1528 0.1530 0.1533 0.1539 0.1541 

[TRAIN] Epoch[4](1193/1500); Loss: 0.111252; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2992 0.1914 0.1162 0.1041 0.1002 0.0951 0.0926 0.0903 0.0888 0.0878 0.0868 0.0862 0.0857 0.0855 0.0852 0.0849 

[TRAIN] Epoch[4](1194/1500); Loss: 0.092978; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1447 0.1263 0.0990 0.0961 0.0887 0.0864 0.0858 0.0853 0.0850 0.0847 0.0845 0.0843 0.0841 0.0842 0.0842 0.0843 

[TRAIN] Epoch[4](1195/1500); Loss: 0.100275; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.1254 0.1220 0.1034 0.1015 0.0991 0.0984 0.0979 0.0974 0.0964 0.0959 0.0953 0.0951 0.0945 0.0942 0.0939 0.0939 

[TRAIN] Epoch[4](1196/1500); Loss: 0.088284; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2235 0.1680 0.1033 0.0820 0.0752 0.0719 0.0706 0.0699 0.0694 0.0689 0.0687 0.0683 0.0681 0.0682 0.0682 0.0683 

[TRAIN] Epoch[4](1197/1500); Loss: 0.070908; Backpropagation: 0.0936 sec; Batch: 0.4299 sec
0.2023 0.1016 0.0712 0.0696 0.0624 0.0614 0.0594 0.0585 0.0577 0.0564 0.0561 0.0559 0.0556 0.0557 0.0553 0.0554 

[TRAIN] Epoch[4](1198/1500); Loss: 0.156870; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2535 0.2129 0.1894 0.1752 0.1573 0.1475 0.1429 0.1404 0.1389 0.1375 0.1369 0.1363 0.1359 0.1354 0.1352 0.1348 

[TRAIN] Epoch[4](1199/1500); Loss: 0.125074; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1438 0.1515 0.1319 0.1278 0.1230 0.1226 0.1217 0.1219 0.1209 0.1207 0.1199 0.1197 0.1191 0.1192 0.1187 0.1189 

[TRAIN] Epoch[4](1200/1500); Loss: 0.099099; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1321 0.1228 0.1133 0.1064 0.0982 0.0950 0.0938 0.0930 0.0923 0.0918 0.0919 0.0917 0.0912 0.0909 0.0906 0.0906 

[TRAIN] Epoch[4](1201/1500); Loss: 0.130971; Backpropagation: 0.0940 sec; Batch: 0.4293 sec
0.1688 0.1564 0.1350 0.1306 0.1277 0.1270 0.1264 0.1261 0.1257 0.1254 0.1249 0.1246 0.1245 0.1244 0.1242 0.1241 

[TRAIN] Epoch[4](1202/1500); Loss: 0.058049; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.0897 0.1244 0.0855 0.0716 0.0553 0.0485 0.0462 0.0456 0.0453 0.0451 0.0451 0.0451 0.0451 0.0453 0.0455 0.0456 

[TRAIN] Epoch[4](1203/1500); Loss: 0.097052; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1518 0.1262 0.1097 0.1029 0.0950 0.0906 0.0884 0.0880 0.0873 0.0870 0.0873 0.0875 0.0878 0.0877 0.0878 0.0879 

[TRAIN] Epoch[4](1204/1500); Loss: 0.144621; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1585 0.1610 0.1627 0.1570 0.1469 0.1425 0.1410 0.1409 0.1405 0.1400 0.1396 0.1387 0.1373 0.1363 0.1357 0.1355 

[TRAIN] Epoch[4](1205/1500); Loss: 0.087527; Backpropagation: 0.0932 sec; Batch: 0.4292 sec
0.1352 0.1419 0.1147 0.1019 0.0878 0.0807 0.0778 0.0766 0.0756 0.0743 0.0734 0.0729 0.0724 0.0719 0.0718 0.0716 

[TRAIN] Epoch[4](1206/1500); Loss: 0.109210; Backpropagation: 0.0942 sec; Batch: 0.4295 sec
0.1386 0.1708 0.1495 0.1352 0.1149 0.1030 0.0984 0.0966 0.0953 0.0942 0.0932 0.0924 0.0916 0.0914 0.0913 0.0908 

[TRAIN] Epoch[4](1207/1500); Loss: 0.120720; Backpropagation: 0.0952 sec; Batch: 0.4295 sec
0.2015 0.1518 0.1325 0.1164 0.1154 0.1116 0.1106 0.1104 0.1103 0.1103 0.1101 0.1100 0.1102 0.1102 0.1102 0.1101 

[TRAIN] Epoch[4](1208/1500); Loss: 0.085055; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2474 0.1206 0.0822 0.0797 0.0753 0.0737 0.0705 0.0691 0.0690 0.0678 0.0678 0.0677 0.0678 0.0673 0.0675 0.0675 

[TRAIN] Epoch[4](1209/1500); Loss: 0.124685; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2236 0.1688 0.1314 0.1224 0.1166 0.1136 0.1133 0.1128 0.1123 0.1120 0.1118 0.1115 0.1112 0.1112 0.1112 0.1112 

[TRAIN] Epoch[4](1210/1500); Loss: 0.127050; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2101 0.1600 0.1313 0.1287 0.1234 0.1205 0.1188 0.1176 0.1166 0.1157 0.1154 0.1152 0.1149 0.1148 0.1148 0.1149 

[TRAIN] Epoch[4](1211/1500); Loss: 0.056362; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1183 0.1445 0.0970 0.0747 0.0527 0.0432 0.0403 0.0388 0.0373 0.0367 0.0362 0.0362 0.0363 0.0361 0.0365 0.0369 

[TRAIN] Epoch[4](1212/1500); Loss: 0.098049; Backpropagation: 0.0957 sec; Batch: 0.4306 sec
0.1639 0.1502 0.1082 0.0948 0.0890 0.0883 0.0886 0.0878 0.0872 0.0877 0.0881 0.0871 0.0872 0.0875 0.0867 0.0864 

[TRAIN] Epoch[4](1213/1500); Loss: 0.134190; Backpropagation: 0.0957 sec; Batch: 0.4299 sec
0.1919 0.1755 0.1660 0.1534 0.1371 0.1287 0.1239 0.1232 0.1230 0.1217 0.1198 0.1184 0.1175 0.1166 0.1156 0.1148 

[TRAIN] Epoch[4](1214/1500); Loss: 0.147484; Backpropagation: 0.0943 sec; Batch: 0.4293 sec
0.2006 0.2082 0.1832 0.1654 0.1493 0.1408 0.1372 0.1349 0.1332 0.1314 0.1306 0.1297 0.1294 0.1289 0.1287 0.1285 

[TRAIN] Epoch[4](1215/1500); Loss: 0.118899; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2640 0.2275 0.1562 0.1257 0.1090 0.1019 0.0957 0.0934 0.0922 0.0917 0.0906 0.0912 0.0910 0.0904 0.0911 0.0907 

[TRAIN] Epoch[4](1216/1500); Loss: 0.072553; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.3817 0.1842 0.0492 0.0805 0.0435 0.0429 0.0393 0.0394 0.0375 0.0371 0.0374 0.0369 0.0376 0.0373 0.0381 0.0380 

[TRAIN] Epoch[4](1217/1500); Loss: 0.118914; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2123 0.1580 0.1289 0.1165 0.1121 0.1089 0.1083 0.1074 0.1072 0.1066 0.1062 0.1060 0.1060 0.1060 0.1061 0.1062 

[TRAIN] Epoch[4](1218/1500); Loss: 0.069533; Backpropagation: 0.0958 sec; Batch: 0.4315 sec
0.1936 0.1367 0.0862 0.0631 0.0606 0.0551 0.0536 0.0531 0.0524 0.0517 0.0514 0.0512 0.0511 0.0509 0.0510 0.0508 

[TRAIN] Epoch[4](1219/1500); Loss: 0.116637; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.2179 0.2052 0.1565 0.1321 0.1151 0.1027 0.0968 0.0963 0.0946 0.0940 0.0932 0.0930 0.0923 0.0923 0.0921 0.0920 

[TRAIN] Epoch[4](1220/1500); Loss: 0.067920; Backpropagation: 0.0940 sec; Batch: 0.4277 sec
0.0905 0.1034 0.0743 0.0654 0.0636 0.0627 0.0621 0.0621 0.0622 0.0625 0.0627 0.0623 0.0627 0.0632 0.0634 0.0636 

[TRAIN] Epoch[4](1221/1500); Loss: 0.101253; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1562 0.1420 0.1376 0.1243 0.1070 0.0987 0.0918 0.0884 0.0867 0.0859 0.0852 0.0844 0.0834 0.0827 0.0829 0.0828 

[TRAIN] Epoch[4](1222/1500); Loss: 0.139242; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1989 0.1809 0.1599 0.1456 0.1369 0.1321 0.1308 0.1298 0.1295 0.1286 0.1276 0.1264 0.1258 0.1254 0.1251 0.1245 

[TRAIN] Epoch[4](1223/1500); Loss: 0.102283; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2684 0.1905 0.1381 0.1129 0.0885 0.0813 0.0782 0.0780 0.0773 0.0766 0.0760 0.0748 0.0748 0.0743 0.0737 0.0731 

[TRAIN] Epoch[4](1224/1500); Loss: 0.170158; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2254 0.1904 0.1769 0.1693 0.1673 0.1658 0.1653 0.1643 0.1637 0.1630 0.1627 0.1623 0.1620 0.1617 0.1613 0.1611 

[TRAIN] Epoch[4](1225/1500); Loss: 0.095283; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1461 0.1441 0.1157 0.1034 0.0930 0.0881 0.0870 0.0857 0.0847 0.0838 0.0830 0.0828 0.0825 0.0819 0.0816 0.0814 

[TRAIN] Epoch[4](1226/1500); Loss: 0.099709; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1883 0.1127 0.1394 0.1260 0.1153 0.1048 0.0927 0.0849 0.0807 0.0794 0.0798 0.0788 0.0786 0.0780 0.0782 0.0777 

[TRAIN] Epoch[4](1227/1500); Loss: 0.118827; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2216 0.1227 0.1759 0.1653 0.1561 0.1394 0.1202 0.1018 0.0904 0.0858 0.0864 0.0875 0.0872 0.0866 0.0871 0.0874 

[TRAIN] Epoch[4](1228/1500); Loss: 0.103822; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1655 0.1389 0.1148 0.1050 0.0997 0.0972 0.0955 0.0950 0.0944 0.0938 0.0936 0.0936 0.0936 0.0934 0.0935 0.0937 

[TRAIN] Epoch[4](1229/1500); Loss: 0.091038; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2208 0.1757 0.1240 0.0985 0.0804 0.0745 0.0714 0.0707 0.0692 0.0686 0.0676 0.0670 0.0669 0.0670 0.0671 0.0673 

[TRAIN] Epoch[4](1230/1500); Loss: 0.112080; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.2725 0.2057 0.1551 0.1168 0.0984 0.0897 0.0876 0.0861 0.0859 0.0852 0.0852 0.0850 0.0851 0.0850 0.0850 0.0852 

[TRAIN] Epoch[4](1231/1500); Loss: 0.079502; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1721 0.1501 0.1004 0.0779 0.0683 0.0635 0.0630 0.0624 0.0625 0.0625 0.0631 0.0636 0.0644 0.0652 0.0661 0.0671 

[TRAIN] Epoch[4](1232/1500); Loss: 0.104736; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.2248 0.1570 0.1235 0.0994 0.0958 0.0911 0.0917 0.0900 0.0895 0.0889 0.0885 0.0878 0.0875 0.0871 0.0870 0.0862 

[TRAIN] Epoch[4](1233/1500); Loss: 0.091320; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2368 0.1473 0.1017 0.0777 0.0743 0.0721 0.0728 0.0728 0.0733 0.0735 0.0739 0.0745 0.0755 0.0770 0.0782 0.0796 

[TRAIN] Epoch[4](1234/1500); Loss: 0.090641; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.1367 0.1138 0.0934 0.0882 0.0887 0.0866 0.0859 0.0851 0.0848 0.0842 0.0840 0.0837 0.0837 0.0837 0.0839 0.0839 

[TRAIN] Epoch[4](1235/1500); Loss: 0.060909; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1177 0.1188 0.0803 0.0628 0.0566 0.0516 0.0510 0.0494 0.0489 0.0483 0.0481 0.0480 0.0481 0.0482 0.0484 0.0483 

[TRAIN] Epoch[4](1236/1500); Loss: 0.089533; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1568 0.1312 0.1024 0.0901 0.0826 0.0805 0.0801 0.0797 0.0789 0.0784 0.0781 0.0784 0.0785 0.0787 0.0788 0.0793 

[TRAIN] Epoch[4](1237/1500); Loss: 0.047449; Backpropagation: 0.0957 sec; Batch: 0.4298 sec
0.1192 0.0778 0.0553 0.0526 0.0454 0.0403 0.0381 0.0367 0.0361 0.0362 0.0362 0.0366 0.0367 0.0368 0.0372 0.0378 

[TRAIN] Epoch[4](1238/1500); Loss: 0.111569; Backpropagation: 0.0939 sec; Batch: 0.4423 sec
0.1432 0.1366 0.1221 0.1155 0.1112 0.1082 0.1074 0.1067 0.1056 0.1046 0.1042 0.1041 0.1039 0.1039 0.1039 0.1041 

[TRAIN] Epoch[4](1239/1500); Loss: 0.087563; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.2079 0.1618 0.1206 0.0961 0.0781 0.0757 0.0704 0.0701 0.0683 0.0666 0.0655 0.0650 0.0642 0.0638 0.0635 0.0636 

[TRAIN] Epoch[4](1240/1500); Loss: 0.143350; Backpropagation: 0.0930 sec; Batch: 0.4271 sec
0.2022 0.1660 0.1440 0.1369 0.1361 0.1366 0.1367 0.1370 0.1371 0.1374 0.1373 0.1374 0.1373 0.1371 0.1372 0.1372 

[TRAIN] Epoch[4](1241/1500); Loss: 0.099163; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1785 0.1461 0.1153 0.1039 0.0958 0.0912 0.0886 0.0875 0.0864 0.0853 0.0852 0.0853 0.0848 0.0840 0.0842 0.0845 

[TRAIN] Epoch[4](1242/1500); Loss: 0.074201; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1458 0.1118 0.0848 0.0732 0.0671 0.0654 0.0655 0.0650 0.0649 0.0642 0.0639 0.0635 0.0632 0.0631 0.0630 0.0629 

[TRAIN] Epoch[4](1243/1500); Loss: 0.068050; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1690 0.1299 0.0878 0.0673 0.0580 0.0554 0.0538 0.0534 0.0526 0.0518 0.0515 0.0515 0.0514 0.0516 0.0518 0.0519 

[TRAIN] Epoch[4](1244/1500); Loss: 0.088335; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1614 0.1257 0.1009 0.0909 0.0845 0.0822 0.0811 0.0801 0.0788 0.0775 0.0763 0.0755 0.0750 0.0748 0.0744 0.0742 

[TRAIN] Epoch[4](1245/1500); Loss: 0.116241; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2352 0.1323 0.1689 0.1501 0.1423 0.1251 0.1059 0.0927 0.0887 0.0888 0.0897 0.0883 0.0879 0.0880 0.0882 0.0877 

[TRAIN] Epoch[4](1246/1500); Loss: 0.104470; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1802 0.1542 0.1089 0.1100 0.0980 0.0961 0.0941 0.0943 0.0929 0.0927 0.0923 0.0918 0.0914 0.0914 0.0916 0.0917 

[TRAIN] Epoch[4](1247/1500); Loss: 0.081846; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.1501 0.1651 0.0989 0.0760 0.0722 0.0676 0.0676 0.0669 0.0676 0.0672 0.0676 0.0676 0.0681 0.0684 0.0690 0.0696 

[TRAIN] Epoch[4](1248/1500); Loss: 0.135457; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.2213 0.1817 0.1516 0.1380 0.1278 0.1261 0.1243 0.1237 0.1233 0.1229 0.1222 0.1219 0.1209 0.1206 0.1205 0.1204 

[TRAIN] Epoch[4](1249/1500); Loss: 0.084127; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1408 0.1059 0.0907 0.0853 0.0804 0.0769 0.0762 0.0764 0.0761 0.0758 0.0756 0.0758 0.0763 0.0770 0.0778 0.0788 

[TRAIN] Epoch[4](1250/1500); Loss: 0.153806; Backpropagation: 0.0938 sec; Batch: 0.4274 sec
0.2511 0.2198 0.1818 0.1627 0.1509 0.1430 0.1403 0.1380 0.1366 0.1351 0.1346 0.1339 0.1337 0.1332 0.1331 0.1331 

[TRAIN] Epoch[4](1251/1500); Loss: 0.099844; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2075 0.1302 0.1093 0.1150 0.0965 0.0926 0.0905 0.0908 0.0875 0.0872 0.0841 0.0842 0.0819 0.0821 0.0792 0.0789 

[TRAIN] Epoch[4](1252/1500); Loss: 0.061318; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1251 0.1501 0.0883 0.0643 0.0503 0.0470 0.0446 0.0444 0.0448 0.0448 0.0449 0.0451 0.0461 0.0466 0.0472 0.0476 

[TRAIN] Epoch[4](1253/1500); Loss: 0.118225; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.2900 0.2037 0.1609 0.1153 0.1010 0.0954 0.0952 0.0931 0.0935 0.0928 0.0923 0.0918 0.0921 0.0917 0.0915 0.0912 

[TRAIN] Epoch[4](1254/1500); Loss: 0.073481; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1620 0.1495 0.1166 0.0943 0.0816 0.0675 0.0582 0.0516 0.0497 0.0500 0.0493 0.0491 0.0490 0.0487 0.0490 0.0495 

[TRAIN] Epoch[4](1255/1500); Loss: 0.081845; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2881 0.1959 0.1355 0.0770 0.0573 0.0523 0.0508 0.0504 0.0504 0.0502 0.0497 0.0497 0.0500 0.0504 0.0507 0.0511 

[TRAIN] Epoch[4](1256/1500); Loss: 0.129414; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1723 0.1448 0.1334 0.1284 0.1265 0.1260 0.1253 0.1250 0.1245 0.1243 0.1239 0.1237 0.1234 0.1232 0.1230 0.1229 

[TRAIN] Epoch[4](1257/1500); Loss: 0.117323; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2044 0.1651 0.1291 0.1158 0.1155 0.1093 0.1065 0.1053 0.1046 0.1039 0.1034 0.1031 0.1027 0.1027 0.1029 0.1028 

[TRAIN] Epoch[4](1258/1500); Loss: 0.142226; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.3998 0.2975 0.2411 0.1661 0.1064 0.1043 0.0968 0.1003 0.0966 0.0978 0.0958 0.0957 0.0945 0.0947 0.0940 0.0943 

[TRAIN] Epoch[4](1259/1500); Loss: 0.119432; Backpropagation: 0.0942 sec; Batch: 0.4296 sec
0.3200 0.2450 0.1940 0.1411 0.1042 0.0888 0.0865 0.0842 0.0829 0.0819 0.0814 0.0807 0.0804 0.0801 0.0799 0.0799 

[TRAIN] Epoch[4](1260/1500); Loss: 0.068396; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.2021 0.1090 0.0713 0.0651 0.0561 0.0592 0.0544 0.0541 0.0533 0.0535 0.0530 0.0528 0.0527 0.0526 0.0524 0.0524 

[TRAIN] Epoch[4](1261/1500); Loss: 0.120188; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.2334 0.1922 0.1704 0.1399 0.1166 0.1053 0.1013 0.0990 0.0979 0.0970 0.0959 0.0952 0.0947 0.0946 0.0947 0.0949 

[TRAIN] Epoch[4](1262/1500); Loss: 0.157274; Backpropagation: 0.0939 sec; Batch: 0.4294 sec
0.2523 0.1901 0.1715 0.1566 0.1495 0.1476 0.1471 0.1461 0.1453 0.1450 0.1447 0.1445 0.1441 0.1439 0.1440 0.1440 

[TRAIN] Epoch[4](1263/1500); Loss: 0.088165; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1311 0.1309 0.1001 0.0940 0.0849 0.0823 0.0810 0.0804 0.0794 0.0785 0.0781 0.0779 0.0779 0.0779 0.0780 0.0781 

[TRAIN] Epoch[4](1264/1500); Loss: 0.040941; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.0667 0.1150 0.0425 0.0448 0.0346 0.0324 0.0321 0.0339 0.0315 0.0310 0.0313 0.0314 0.0312 0.0319 0.0320 0.0328 

[TRAIN] Epoch[4](1265/1500); Loss: 0.098219; Backpropagation: 0.0958 sec; Batch: 0.4300 sec
0.1238 0.1113 0.1029 0.0978 0.0958 0.0962 0.0966 0.0964 0.0953 0.0940 0.0933 0.0932 0.0935 0.0936 0.0938 0.0940 

[TRAIN] Epoch[4](1266/1500); Loss: 0.144126; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.2151 0.2197 0.1717 0.1491 0.1352 0.1350 0.1322 0.1314 0.1302 0.1290 0.1280 0.1273 0.1265 0.1258 0.1254 0.1244 

[TRAIN] Epoch[4](1267/1500); Loss: 0.126630; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.4166 0.3269 0.2660 0.1908 0.1299 0.0910 0.0645 0.0665 0.0601 0.0604 0.0593 0.0598 0.0587 0.0585 0.0586 0.0586 

[TRAIN] Epoch[4](1268/1500); Loss: 0.143083; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.2367 0.2086 0.1831 0.1677 0.1561 0.1427 0.1320 0.1245 0.1207 0.1184 0.1172 0.1169 0.1168 0.1162 0.1160 0.1159 

[TRAIN] Epoch[4](1269/1500); Loss: 0.058913; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.0945 0.1327 0.0778 0.0676 0.0575 0.0497 0.0476 0.0470 0.0467 0.0462 0.0459 0.0459 0.0456 0.0457 0.0462 0.0460 

[TRAIN] Epoch[4](1270/1500); Loss: 0.056671; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1006 0.0507 0.0665 0.0557 0.0543 0.0507 0.0521 0.0533 0.0537 0.0523 0.0522 0.0529 0.0526 0.0525 0.0530 0.0536 

[TRAIN] Epoch[4](1271/1500); Loss: 0.109699; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2362 0.1559 0.1261 0.1059 0.0993 0.0993 0.0972 0.0965 0.0957 0.0945 0.0933 0.0921 0.0912 0.0909 0.0908 0.0903 

[TRAIN] Epoch[4](1272/1500); Loss: 0.170889; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2215 0.2137 0.1811 0.1690 0.1661 0.1649 0.1643 0.1626 0.1625 0.1620 0.1617 0.1613 0.1611 0.1609 0.1609 0.1606 

[TRAIN] Epoch[4](1273/1500); Loss: 0.065510; Backpropagation: 0.0932 sec; Batch: 0.4281 sec
0.1318 0.1047 0.0763 0.0651 0.0623 0.0576 0.0571 0.0568 0.0559 0.0549 0.0545 0.0544 0.0542 0.0539 0.0541 0.0545 

[TRAIN] Epoch[4](1274/1500); Loss: 0.077794; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1899 0.1257 0.1018 0.0798 0.0690 0.0651 0.0626 0.0623 0.0617 0.0614 0.0608 0.0607 0.0611 0.0610 0.0608 0.0609 

[TRAIN] Epoch[4](1275/1500); Loss: 0.150015; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1843 0.1704 0.1540 0.1513 0.1502 0.1483 0.1462 0.1452 0.1448 0.1446 0.1440 0.1435 0.1434 0.1432 0.1432 0.1435 

[TRAIN] Epoch[4](1276/1500); Loss: 0.077981; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1260 0.1197 0.0861 0.0813 0.0747 0.0707 0.0690 0.0692 0.0685 0.0683 0.0683 0.0686 0.0688 0.0692 0.0696 0.0697 

[TRAIN] Epoch[4](1277/1500); Loss: 0.106035; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.2110 0.1585 0.1104 0.1020 0.0952 0.0968 0.0941 0.0928 0.0927 0.0923 0.0920 0.0915 0.0914 0.0918 0.0919 0.0922 

[TRAIN] Epoch[4](1278/1500); Loss: 0.114936; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1787 0.1306 0.1174 0.1136 0.1106 0.1099 0.1086 0.1076 0.1069 0.1067 0.1068 0.1074 0.1080 0.1084 0.1086 0.1090 

[TRAIN] Epoch[4](1279/1500); Loss: 0.071922; Backpropagation: 0.0934 sec; Batch: 0.4373 sec
0.1229 0.0909 0.0787 0.0742 0.0704 0.0673 0.0665 0.0661 0.0653 0.0647 0.0644 0.0641 0.0637 0.0639 0.0639 0.0639 

[TRAIN] Epoch[4](1280/1500); Loss: 0.098061; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1566 0.1279 0.1123 0.1102 0.0953 0.0928 0.0892 0.0889 0.0882 0.0879 0.0869 0.0867 0.0864 0.0865 0.0865 0.0868 

[TRAIN] Epoch[4](1281/1500); Loss: 0.116480; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.3180 0.2239 0.1675 0.1099 0.0927 0.0903 0.0912 0.0876 0.0861 0.0850 0.0851 0.0848 0.0849 0.0850 0.0855 0.0860 

[TRAIN] Epoch[4](1282/1500); Loss: 0.133615; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1845 0.1560 0.1379 0.1461 0.1327 0.1317 0.1281 0.1277 0.1258 0.1252 0.1244 0.1238 0.1232 0.1233 0.1237 0.1238 

[TRAIN] Epoch[4](1283/1500); Loss: 0.070173; Backpropagation: 0.0960 sec; Batch: 0.4307 sec
0.2061 0.1208 0.0744 0.0649 0.0568 0.0586 0.0539 0.0537 0.0537 0.0539 0.0536 0.0537 0.0543 0.0544 0.0549 0.0551 

[TRAIN] Epoch[4](1284/1500); Loss: 0.119667; Backpropagation: 0.0956 sec; Batch: 0.4298 sec
0.1762 0.1509 0.1323 0.1262 0.1196 0.1159 0.1131 0.1117 0.1102 0.1095 0.1087 0.1082 0.1076 0.1079 0.1083 0.1083 

[TRAIN] Epoch[4](1285/1500); Loss: 0.092042; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1381 0.1395 0.1040 0.0896 0.0874 0.0829 0.0847 0.0838 0.0833 0.0827 0.0824 0.0822 0.0828 0.0831 0.0831 0.0830 

[TRAIN] Epoch[4](1286/1500); Loss: 0.082582; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1947 0.1262 0.0957 0.0844 0.0755 0.0718 0.0694 0.0690 0.0677 0.0668 0.0664 0.0664 0.0665 0.0666 0.0668 0.0675 

[TRAIN] Epoch[4](1287/1500); Loss: 0.085302; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1942 0.1658 0.1086 0.0929 0.0827 0.0745 0.0709 0.0672 0.0659 0.0636 0.0630 0.0625 0.0626 0.0624 0.0632 0.0648 

[TRAIN] Epoch[4](1288/1500); Loss: 0.071205; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1085 0.0904 0.0765 0.0745 0.0705 0.0680 0.0666 0.0661 0.0653 0.0647 0.0642 0.0643 0.0646 0.0648 0.0650 0.0651 

[TRAIN] Epoch[4](1289/1500); Loss: 0.077688; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2386 0.1277 0.1206 0.0846 0.0509 0.0713 0.0523 0.0495 0.0490 0.0595 0.0551 0.0539 0.0541 0.0595 0.0581 0.0584 

[TRAIN] Epoch[4](1290/1500); Loss: 0.129787; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.3985 0.2868 0.2179 0.1373 0.0859 0.0970 0.0882 0.0892 0.0853 0.0851 0.0837 0.0848 0.0839 0.0844 0.0838 0.0850 

[TRAIN] Epoch[4](1291/1500); Loss: 0.080389; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2395 0.1300 0.1178 0.0856 0.0601 0.0684 0.0559 0.0536 0.0542 0.0608 0.0583 0.0579 0.0578 0.0624 0.0616 0.0622 

[TRAIN] Epoch[4](1292/1500); Loss: 0.104119; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2268 0.1649 0.1113 0.1057 0.0934 0.0891 0.0884 0.0884 0.0877 0.0870 0.0871 0.0872 0.0868 0.0869 0.0874 0.0878 

[TRAIN] Epoch[4](1293/1500); Loss: 0.077358; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1542 0.1259 0.0864 0.0702 0.0674 0.0630 0.0631 0.0646 0.0646 0.0646 0.0653 0.0668 0.0681 0.0695 0.0707 0.0733 

[TRAIN] Epoch[4](1294/1500); Loss: 0.081795; Backpropagation: 0.0976 sec; Batch: 0.4327 sec
0.1396 0.1121 0.0935 0.0854 0.0795 0.0759 0.0746 0.0739 0.0728 0.0720 0.0715 0.0715 0.0715 0.0714 0.0717 0.0721 

[TRAIN] Epoch[4](1295/1500); Loss: 0.103534; Backpropagation: 0.0981 sec; Batch: 0.4326 sec
0.1323 0.1234 0.1050 0.1032 0.1084 0.1019 0.0987 0.0980 0.0992 0.0988 0.0979 0.0973 0.0980 0.0981 0.0982 0.0982 

[TRAIN] Epoch[4](1296/1500); Loss: 0.113302; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1763 0.1603 0.1244 0.1162 0.1126 0.1074 0.1040 0.1023 0.1021 0.1014 0.1010 0.1011 0.1010 0.1008 0.1009 0.1009 

[TRAIN] Epoch[4](1297/1500); Loss: 0.146946; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.3207 0.2270 0.1862 0.1463 0.1279 0.1277 0.1234 0.1224 0.1222 0.1220 0.1214 0.1209 0.1209 0.1208 0.1206 0.1207 

[TRAIN] Epoch[4](1298/1500); Loss: 0.095062; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1460 0.1338 0.1055 0.0970 0.0947 0.0902 0.0881 0.0870 0.0863 0.0856 0.0851 0.0847 0.0844 0.0842 0.0842 0.0841 

[TRAIN] Epoch[4](1299/1500); Loss: 0.128050; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1880 0.1752 0.1475 0.1376 0.1290 0.1214 0.1182 0.1167 0.1160 0.1150 0.1142 0.1139 0.1141 0.1144 0.1140 0.1137 

[TRAIN] Epoch[4](1300/1500); Loss: 0.081496; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1067 0.1004 0.0840 0.0833 0.0806 0.0781 0.0770 0.0766 0.0764 0.0764 0.0766 0.0769 0.0773 0.0777 0.0779 0.0782 

[TRAIN] Epoch[4](1301/1500); Loss: 0.137304; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2239 0.1814 0.1581 0.1415 0.1339 0.1291 0.1269 0.1250 0.1239 0.1231 0.1227 0.1222 0.1216 0.1213 0.1211 0.1211 

[TRAIN] Epoch[4](1302/1500); Loss: 0.058667; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1070 0.0900 0.0643 0.0581 0.0543 0.0525 0.0518 0.0520 0.0509 0.0505 0.0504 0.0510 0.0511 0.0513 0.0513 0.0523 

[TRAIN] Epoch[4](1303/1500); Loss: 0.099574; Backpropagation: 0.0938 sec; Batch: 0.4298 sec
0.1468 0.1349 0.1109 0.1050 0.0999 0.0958 0.0945 0.0933 0.0917 0.0900 0.0895 0.0888 0.0885 0.0881 0.0877 0.0878 

[TRAIN] Epoch[4](1304/1500); Loss: 0.105085; Backpropagation: 0.0937 sec; Batch: 0.4674 sec
0.1670 0.1361 0.1106 0.1037 0.1026 0.0999 0.0988 0.0975 0.0969 0.0964 0.0960 0.0952 0.0950 0.0952 0.0953 0.0953 

[TRAIN] Epoch[4](1305/1500); Loss: 0.138226; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.2810 0.2144 0.1762 0.1479 0.1319 0.1226 0.1184 0.1157 0.1142 0.1137 0.1132 0.1124 0.1123 0.1125 0.1125 0.1128 

[TRAIN] Epoch[4](1306/1500); Loss: 0.106971; Backpropagation: 0.0956 sec; Batch: 0.4685 sec
0.3145 0.2286 0.1807 0.1275 0.0861 0.0822 0.0746 0.0713 0.0688 0.0690 0.0683 0.0680 0.0677 0.0678 0.0680 0.0684 

[TRAIN] Epoch[4](1307/1500); Loss: 0.119755; Backpropagation: 0.0938 sec; Batch: 0.4734 sec
0.2647 0.1932 0.1609 0.1230 0.1073 0.1039 0.1007 0.0986 0.0973 0.0961 0.0955 0.0951 0.0952 0.0950 0.0948 0.0948 

[TRAIN] Epoch[4](1308/1500); Loss: 0.110915; Backpropagation: 0.0936 sec; Batch: 0.4656 sec
0.2385 0.1739 0.1347 0.1066 0.1002 0.0952 0.0945 0.0945 0.0936 0.0923 0.0923 0.0919 0.0916 0.0918 0.0917 0.0914 

[TRAIN] Epoch[4](1309/1500); Loss: 0.086254; Backpropagation: 0.0937 sec; Batch: 0.4675 sec
0.2368 0.1761 0.1389 0.1022 0.0778 0.0666 0.0617 0.0596 0.0581 0.0575 0.0571 0.0572 0.0573 0.0575 0.0578 0.0578 

[TRAIN] Epoch[4](1310/1500); Loss: 0.067614; Backpropagation: 0.0938 sec; Batch: 0.4710 sec
0.1035 0.1043 0.0779 0.0666 0.0692 0.0637 0.0614 0.0603 0.0598 0.0594 0.0592 0.0592 0.0592 0.0591 0.0594 0.0598 

[TRAIN] Epoch[4](1311/1500); Loss: 0.082752; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1226 0.1147 0.0821 0.0873 0.0792 0.0752 0.0742 0.0753 0.0758 0.0752 0.0758 0.0758 0.0769 0.0770 0.0779 0.0790 

[TRAIN] Epoch[4](1312/1500); Loss: 0.107328; Backpropagation: 0.0980 sec; Batch: 0.4729 sec
0.1468 0.1277 0.1155 0.1095 0.1029 0.1018 0.1019 0.1015 0.1002 0.1002 0.1008 0.1012 0.1013 0.1014 0.1020 0.1026 

[TRAIN] Epoch[4](1313/1500); Loss: 0.101674; Backpropagation: 0.0965 sec; Batch: 0.4742 sec
0.2336 0.1679 0.1370 0.1114 0.0937 0.0861 0.0832 0.0828 0.0807 0.0795 0.0788 0.0785 0.0784 0.0783 0.0782 0.0786 

[TRAIN] Epoch[4](1314/1500); Loss: 0.136111; Backpropagation: 0.0937 sec; Batch: 0.4674 sec
0.2029 0.1848 0.1599 0.1503 0.1397 0.1307 0.1247 0.1222 0.1234 0.1227 0.1216 0.1206 0.1197 0.1188 0.1181 0.1179 

[TRAIN] Epoch[4](1315/1500); Loss: 0.109932; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.1771 0.1720 0.1275 0.1137 0.1113 0.1013 0.0986 0.0972 0.0963 0.0948 0.0946 0.0949 0.0947 0.0947 0.0948 0.0955 

[TRAIN] Epoch[4](1316/1500); Loss: 0.100035; Backpropagation: 0.0937 sec; Batch: 0.4670 sec
0.1223 0.1207 0.1051 0.1001 0.0992 0.0969 0.0958 0.0949 0.0947 0.0947 0.0953 0.0955 0.0955 0.0959 0.0966 0.0972 

[TRAIN] Epoch[4](1317/1500); Loss: 0.134261; Backpropagation: 0.0982 sec; Batch: 0.4718 sec
0.2582 0.2018 0.1657 0.1375 0.1265 0.1212 0.1179 0.1161 0.1147 0.1136 0.1130 0.1125 0.1124 0.1122 0.1123 0.1124 

[TRAIN] Epoch[4](1318/1500); Loss: 0.053637; Backpropagation: 0.0956 sec; Batch: 0.4703 sec
0.0970 0.1055 0.0588 0.0460 0.0490 0.0453 0.0442 0.0451 0.0451 0.0448 0.0447 0.0455 0.0461 0.0464 0.0468 0.0476 

[TRAIN] Epoch[4](1319/1500); Loss: 0.128741; Backpropagation: 0.0938 sec; Batch: 0.5009 sec
0.2013 0.1790 0.1524 0.1401 0.1307 0.1221 0.1185 0.1159 0.1146 0.1136 0.1133 0.1126 0.1121 0.1114 0.1112 0.1112 

[TRAIN] Epoch[4](1320/1500); Loss: 0.055059; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1166 0.0807 0.0670 0.0611 0.0527 0.0487 0.0469 0.0458 0.0449 0.0446 0.0449 0.0448 0.0446 0.0451 0.0460 0.0466 

[TRAIN] Epoch[4](1321/1500); Loss: 0.134424; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.3207 0.2305 0.1844 0.1352 0.1146 0.1099 0.1061 0.1051 0.1052 0.1052 0.1049 0.1050 0.1055 0.1056 0.1062 0.1067 

[TRAIN] Epoch[4](1322/1500); Loss: 0.074940; Backpropagation: 0.0931 sec; Batch: 0.4357 sec
0.1527 0.1304 0.0871 0.0774 0.0694 0.0644 0.0642 0.0629 0.0622 0.0618 0.0610 0.0611 0.0609 0.0610 0.0611 0.0614 

[TRAIN] Epoch[4](1323/1500); Loss: 0.117187; Backpropagation: 0.0942 sec; Batch: 0.4427 sec
0.1577 0.1446 0.1190 0.1149 0.1111 0.1096 0.1095 0.1103 0.1105 0.1108 0.1113 0.1122 0.1126 0.1130 0.1136 0.1143 

[TRAIN] Epoch[4](1324/1500); Loss: 0.130079; Backpropagation: 0.0938 sec; Batch: 0.4870 sec
0.2473 0.1860 0.1498 0.1270 0.1202 0.1172 0.1148 0.1138 0.1136 0.1131 0.1126 0.1127 0.1130 0.1133 0.1134 0.1135 

[TRAIN] Epoch[4](1325/1500); Loss: 0.078118; Backpropagation: 0.0937 sec; Batch: 0.4673 sec
0.1389 0.1058 0.0879 0.0793 0.0753 0.0723 0.0713 0.0699 0.0688 0.0685 0.0684 0.0684 0.0685 0.0685 0.0689 0.0691 

[TRAIN] Epoch[4](1326/1500); Loss: 0.098542; Backpropagation: 0.0937 sec; Batch: 0.4709 sec
0.1286 0.1180 0.1045 0.1029 0.1020 0.0956 0.0930 0.0940 0.0941 0.0926 0.0917 0.0919 0.0921 0.0916 0.0920 0.0921 

[TRAIN] Epoch[4](1327/1500); Loss: 0.075045; Backpropagation: 0.0939 sec; Batch: 0.4709 sec
0.0945 0.0854 0.0780 0.0764 0.0761 0.0732 0.0723 0.0723 0.0721 0.0715 0.0713 0.0712 0.0714 0.0715 0.0716 0.0719 

[TRAIN] Epoch[4](1328/1500); Loss: 0.047300; Backpropagation: 0.0957 sec; Batch: 0.4318 sec
0.1221 0.0719 0.0741 0.0538 0.0377 0.0372 0.0351 0.0357 0.0350 0.0366 0.0358 0.0354 0.0360 0.0366 0.0369 0.0369 

[TRAIN] Epoch[4](1329/1500); Loss: 0.097663; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.2492 0.1668 0.1235 0.0974 0.0862 0.0821 0.0806 0.0784 0.0779 0.0762 0.0756 0.0742 0.0740 0.0734 0.0738 0.0733 

[TRAIN] Epoch[4](1330/1500); Loss: 0.089464; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1786 0.1354 0.1161 0.0931 0.0847 0.0819 0.0783 0.0767 0.0757 0.0746 0.0735 0.0730 0.0727 0.0724 0.0724 0.0723 

[TRAIN] Epoch[4](1331/1500); Loss: 0.070520; Backpropagation: 0.0938 sec; Batch: 0.4748 sec
0.1760 0.1187 0.0862 0.0693 0.0631 0.0596 0.0573 0.0565 0.0558 0.0557 0.0553 0.0553 0.0549 0.0548 0.0548 0.0549 

[TRAIN] Epoch[4](1332/1500); Loss: 0.116169; Backpropagation: 0.0936 sec; Batch: 0.4664 sec
0.1502 0.1306 0.1166 0.1144 0.1151 0.1138 0.1129 0.1117 0.1114 0.1113 0.1116 0.1117 0.1118 0.1118 0.1117 0.1119 

[TRAIN] Epoch[4](1333/1500); Loss: 0.098396; Backpropagation: 0.0941 sec; Batch: 0.4728 sec
0.2403 0.1593 0.1192 0.0997 0.0887 0.0852 0.0814 0.0816 0.0795 0.0780 0.0774 0.0770 0.0767 0.0772 0.0765 0.0765 

[TRAIN] Epoch[4](1334/1500); Loss: 0.117728; Backpropagation: 0.0937 sec; Batch: 0.4650 sec
0.1811 0.1615 0.1315 0.1247 0.1151 0.1102 0.1093 0.1080 0.1072 0.1058 0.1053 0.1050 0.1048 0.1047 0.1047 0.1046 

[TRAIN] Epoch[4](1335/1500); Loss: 0.060553; Backpropagation: 0.0939 sec; Batch: 0.4348 sec
0.0932 0.0795 0.0656 0.0639 0.0601 0.0571 0.0562 0.0557 0.0552 0.0548 0.0543 0.0544 0.0544 0.0548 0.0546 0.0550 

[TRAIN] Epoch[4](1336/1500); Loss: 0.108864; Backpropagation: 0.0936 sec; Batch: 0.4552 sec
0.2277 0.1710 0.1517 0.1280 0.1067 0.0969 0.0921 0.0910 0.0877 0.0861 0.0845 0.0840 0.0838 0.0834 0.0834 0.0838 

[TRAIN] Epoch[4](1337/1500); Loss: 0.125707; Backpropagation: 0.0938 sec; Batch: 0.4715 sec
0.2756 0.1852 0.1473 0.1217 0.1138 0.1110 0.1089 0.1076 0.1064 0.1059 0.1054 0.1052 0.1047 0.1045 0.1041 0.1040 

[TRAIN] Epoch[4](1338/1500); Loss: 0.133009; Backpropagation: 0.0937 sec; Batch: 0.4651 sec
0.2556 0.1819 0.1469 0.1259 0.1209 0.1182 0.1186 0.1183 0.1184 0.1176 0.1173 0.1174 0.1176 0.1177 0.1178 0.1181 

[TRAIN] Epoch[4](1339/1500); Loss: 0.161339; Backpropagation: 0.0939 sec; Batch: 0.4397 sec
0.2628 0.1999 0.1601 0.1548 0.1520 0.1486 0.1493 0.1493 0.1481 0.1488 0.1506 0.1502 0.1503 0.1515 0.1524 0.1527 

[TRAIN] Epoch[4](1340/1500); Loss: 0.126456; Backpropagation: 0.0937 sec; Batch: 0.4498 sec
0.1582 0.1467 0.1359 0.1299 0.1280 0.1241 0.1227 0.1214 0.1208 0.1200 0.1197 0.1197 0.1196 0.1191 0.1189 0.1186 

[TRAIN] Epoch[4](1341/1500); Loss: 0.103464; Backpropagation: 0.0937 sec; Batch: 0.4953 sec
0.1712 0.1300 0.1124 0.1033 0.0995 0.0968 0.0957 0.0951 0.0946 0.0942 0.0941 0.0939 0.0937 0.0937 0.0936 0.0937 

[TRAIN] Epoch[4](1342/1500); Loss: 0.060959; Backpropagation: 0.0939 sec; Batch: 0.4670 sec
0.0876 0.0697 0.0694 0.0626 0.0596 0.0577 0.0573 0.0573 0.0570 0.0566 0.0567 0.0565 0.0567 0.0566 0.0569 0.0571 

[TRAIN] Epoch[4](1343/1500); Loss: 0.060366; Backpropagation: 0.0939 sec; Batch: 0.4791 sec
0.1299 0.0710 0.0643 0.0595 0.0548 0.0547 0.0538 0.0534 0.0532 0.0531 0.0529 0.0528 0.0528 0.0529 0.0532 0.0534 

[TRAIN] Epoch[4](1344/1500); Loss: 0.106763; Backpropagation: 0.0931 sec; Batch: 0.4711 sec
0.1840 0.1366 0.1167 0.1119 0.1023 0.1002 0.0994 0.0982 0.0967 0.0960 0.0952 0.0950 0.0943 0.0942 0.0939 0.0935 

[TRAIN] Epoch[4](1345/1500); Loss: 0.092943; Backpropagation: 0.0981 sec; Batch: 0.4710 sec
0.2568 0.1752 0.1360 0.0946 0.0735 0.0701 0.0675 0.0676 0.0672 0.0666 0.0670 0.0678 0.0682 0.0690 0.0694 0.0705 

[TRAIN] Epoch[4](1346/1500); Loss: 0.109133; Backpropagation: 0.0955 sec; Batch: 0.4682 sec
0.2419 0.1628 0.1303 0.1067 0.0970 0.0948 0.0926 0.0915 0.0913 0.0910 0.0905 0.0908 0.0910 0.0913 0.0911 0.0915 

[TRAIN] Epoch[4](1347/1500); Loss: 0.125347; Backpropagation: 0.0932 sec; Batch: 0.4681 sec
0.2228 0.1890 0.1566 0.1303 0.1184 0.1132 0.1103 0.1102 0.1088 0.1079 0.1071 0.1064 0.1063 0.1063 0.1060 0.1060 

[TRAIN] Epoch[4](1348/1500); Loss: 0.123178; Backpropagation: 0.0931 sec; Batch: 0.4586 sec
0.1627 0.1423 0.1278 0.1232 0.1218 0.1195 0.1188 0.1183 0.1177 0.1173 0.1169 0.1168 0.1165 0.1167 0.1172 0.1174 

[TRAIN] Epoch[4](1349/1500); Loss: 0.057931; Backpropagation: 0.0938 sec; Batch: 0.4680 sec
0.1154 0.0969 0.0629 0.0587 0.0536 0.0510 0.0503 0.0498 0.0490 0.0485 0.0484 0.0484 0.0483 0.0482 0.0485 0.0490 

[TRAIN] Epoch[4](1350/1500); Loss: 0.039918; Backpropagation: 0.0938 sec; Batch: 0.4871 sec
0.0694 0.0745 0.0564 0.0323 0.0393 0.0339 0.0338 0.0319 0.0324 0.0331 0.0319 0.0330 0.0333 0.0347 0.0339 0.0348 

[TRAIN] Epoch[4](1351/1500); Loss: 0.080351; Backpropagation: 0.0938 sec; Batch: 0.4669 sec
0.1748 0.1012 0.0819 0.0798 0.0758 0.0724 0.0722 0.0712 0.0712 0.0700 0.0700 0.0693 0.0691 0.0687 0.0691 0.0687 

[TRAIN] Epoch[4](1352/1500); Loss: 0.136108; Backpropagation: 0.0938 sec; Batch: 0.4664 sec
0.3254 0.2196 0.1715 0.1263 0.1171 0.1139 0.1138 0.1115 0.1103 0.1098 0.1099 0.1099 0.1096 0.1098 0.1098 0.1096 

[TRAIN] Epoch[4](1353/1500); Loss: 0.079489; Backpropagation: 0.0933 sec; Batch: 0.4703 sec
0.1948 0.1480 0.1087 0.0845 0.0711 0.0667 0.0642 0.0627 0.0614 0.0604 0.0593 0.0587 0.0581 0.0579 0.0577 0.0576 

[TRAIN] Epoch[4](1354/1500); Loss: 0.093662; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1577 0.1152 0.1005 0.0911 0.0896 0.0874 0.0861 0.0857 0.0854 0.0852 0.0849 0.0852 0.0856 0.0859 0.0862 0.0868 

[TRAIN] Epoch[4](1355/1500); Loss: 0.109205; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1666 0.1366 0.1160 0.1089 0.1055 0.1028 0.1015 0.1010 0.1007 0.1010 0.1004 0.1005 0.1006 0.1012 0.1016 0.1022 

[TRAIN] Epoch[4](1356/1500); Loss: 0.125295; Backpropagation: 0.0940 sec; Batch: 0.4641 sec
0.1885 0.1593 0.1333 0.1220 0.1214 0.1187 0.1186 0.1177 0.1173 0.1166 0.1161 0.1158 0.1152 0.1148 0.1146 0.1147 

[TRAIN] Epoch[4](1357/1500); Loss: 0.081320; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1592 0.1130 0.0927 0.0822 0.0766 0.0742 0.0724 0.0710 0.0704 0.0704 0.0700 0.0697 0.0699 0.0697 0.0697 0.0700 

[TRAIN] Epoch[4](1358/1500); Loss: 0.033673; Backpropagation: 0.0937 sec; Batch: 0.4714 sec
0.0510 0.0548 0.0356 0.0329 0.0297 0.0293 0.0285 0.0295 0.0289 0.0292 0.0300 0.0302 0.0307 0.0320 0.0331 0.0335 

[TRAIN] Epoch[4](1359/1500); Loss: 0.136852; Backpropagation: 0.0937 sec; Batch: 0.4699 sec
0.2742 0.1948 0.1551 0.1353 0.1245 0.1226 0.1196 0.1185 0.1177 0.1171 0.1174 0.1177 0.1183 0.1188 0.1191 0.1190 

[TRAIN] Epoch[4](1360/1500); Loss: 0.069140; Backpropagation: 0.0938 sec; Batch: 0.4711 sec
0.1177 0.0835 0.0764 0.0719 0.0686 0.0655 0.0643 0.0640 0.0636 0.0625 0.0621 0.0618 0.0615 0.0611 0.0609 0.0607 

[TRAIN] Epoch[4](1361/1500); Loss: 0.054256; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.0987 0.0803 0.0585 0.0541 0.0505 0.0482 0.0473 0.0474 0.0472 0.0473 0.0472 0.0477 0.0477 0.0483 0.0485 0.0492 

[TRAIN] Epoch[4](1362/1500); Loss: 0.070721; Backpropagation: 0.0937 sec; Batch: 0.4657 sec
0.2836 0.1367 0.0768 0.0668 0.0526 0.0559 0.0484 0.0485 0.0462 0.0459 0.0451 0.0453 0.0446 0.0451 0.0448 0.0451 

[TRAIN] Epoch[4](1363/1500); Loss: 0.066997; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.2092 0.0927 0.0615 0.0607 0.0590 0.0555 0.0540 0.0542 0.0538 0.0532 0.0530 0.0532 0.0531 0.0529 0.0526 0.0532 

[TRAIN] Epoch[4](1364/1500); Loss: 0.088464; Backpropagation: 0.0937 sec; Batch: 0.4543 sec
0.1254 0.1158 0.0951 0.0901 0.0848 0.0835 0.0825 0.0821 0.0820 0.0820 0.0818 0.0817 0.0820 0.0820 0.0821 0.0824 

[TRAIN] Epoch[4](1365/1500); Loss: 0.117821; Backpropagation: 0.0938 sec; Batch: 0.4711 sec
0.2609 0.1700 0.1341 0.1137 0.1089 0.1043 0.1027 0.1013 0.1002 0.0997 0.0992 0.0987 0.0984 0.0978 0.0978 0.0974 

[TRAIN] Epoch[4](1366/1500); Loss: 0.101199; Backpropagation: 0.0941 sec; Batch: 0.4400 sec
0.1495 0.1215 0.1067 0.1012 0.0984 0.0966 0.0954 0.0947 0.0944 0.0943 0.0942 0.0942 0.0944 0.0945 0.0945 0.0947 

[TRAIN] Epoch[4](1367/1500); Loss: 0.111585; Backpropagation: 0.0934 sec; Batch: 0.4681 sec
0.1846 0.1451 0.1228 0.1117 0.1072 0.1043 0.1027 0.1022 0.1016 0.1011 0.1005 0.1005 0.1004 0.1003 0.1001 0.1002 

[TRAIN] Epoch[4](1368/1500); Loss: 0.081712; Backpropagation: 0.0931 sec; Batch: 0.4697 sec
0.1440 0.1122 0.0975 0.0856 0.0791 0.0761 0.0743 0.0728 0.0719 0.0711 0.0707 0.0706 0.0705 0.0703 0.0702 0.0703 

[TRAIN] Epoch[4](1369/1500); Loss: 0.089464; Backpropagation: 0.0932 sec; Batch: 0.4678 sec
0.1695 0.1177 0.1004 0.0876 0.0877 0.0817 0.0803 0.0793 0.0788 0.0783 0.0784 0.0782 0.0781 0.0784 0.0784 0.0786 

[TRAIN] Epoch[4](1370/1500); Loss: 0.101419; Backpropagation: 0.0938 sec; Batch: 0.4675 sec
0.1490 0.1231 0.1097 0.1047 0.0968 0.0968 0.0958 0.0950 0.0940 0.0940 0.0938 0.0939 0.0938 0.0940 0.0941 0.0942 

[TRAIN] Epoch[4](1371/1500); Loss: 0.134664; Backpropagation: 0.0937 sec; Batch: 0.4656 sec
0.1802 0.1458 0.1382 0.1338 0.1325 0.1306 0.1297 0.1298 0.1294 0.1291 0.1291 0.1292 0.1290 0.1291 0.1293 0.1299 

[TRAIN] Epoch[4](1372/1500); Loss: 0.075867; Backpropagation: 0.0937 sec; Batch: 0.4659 sec
0.2382 0.1432 0.0980 0.0600 0.0610 0.0540 0.0529 0.0530 0.0545 0.0546 0.0549 0.0563 0.0569 0.0580 0.0585 0.0599 

[TRAIN] Epoch[4](1373/1500); Loss: 0.151247; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.1948 0.1654 0.1581 0.1556 0.1511 0.1485 0.1468 0.1464 0.1458 0.1453 0.1447 0.1442 0.1437 0.1433 0.1432 0.1431 

[TRAIN] Epoch[4](1374/1500); Loss: 0.122609; Backpropagation: 0.0937 sec; Batch: 0.4698 sec
0.3438 0.2516 0.2098 0.1471 0.1015 0.0890 0.0854 0.0825 0.0814 0.0814 0.0811 0.0810 0.0813 0.0813 0.0815 0.0821 

[TRAIN] Epoch[4](1375/1500); Loss: 0.140950; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.1958 0.1546 0.1416 0.1362 0.1352 0.1351 0.1350 0.1346 0.1349 0.1356 0.1358 0.1356 0.1359 0.1363 0.1363 0.1366 

[TRAIN] Epoch[4](1376/1500); Loss: 0.096053; Backpropagation: 0.0938 sec; Batch: 0.5081 sec
0.1314 0.1243 0.1018 0.1006 0.0955 0.0936 0.0931 0.0918 0.0908 0.0899 0.0891 0.0883 0.0879 0.0871 0.0861 0.0858 

[TRAIN] Epoch[4](1377/1500); Loss: 0.157102; Backpropagation: 0.0938 sec; Batch: 0.4660 sec
0.2029 0.1743 0.1651 0.1591 0.1541 0.1521 0.1509 0.1507 0.1505 0.1502 0.1502 0.1503 0.1505 0.1506 0.1509 0.1511 

[TRAIN] Epoch[4](1378/1500); Loss: 0.111220; Backpropagation: 0.0937 sec; Batch: 0.4663 sec
0.2912 0.2023 0.1668 0.1155 0.0904 0.0927 0.0829 0.0824 0.0819 0.0819 0.0817 0.0815 0.0820 0.0820 0.0820 0.0823 

[TRAIN] Epoch[4](1379/1500); Loss: 0.117246; Backpropagation: 0.0939 sec; Batch: 0.4625 sec
0.3471 0.2326 0.1891 0.1181 0.0887 0.0880 0.0844 0.0836 0.0824 0.0818 0.0809 0.0808 0.0799 0.0795 0.0794 0.0797 

[TRAIN] Epoch[4](1380/1500); Loss: 0.134939; Backpropagation: 0.0937 sec; Batch: 0.4665 sec
0.1805 0.1532 0.1386 0.1355 0.1307 0.1298 0.1297 0.1294 0.1287 0.1287 0.1287 0.1287 0.1288 0.1290 0.1293 0.1297 

[TRAIN] Epoch[4](1381/1500); Loss: 0.100660; Backpropagation: 0.0938 sec; Batch: 0.4337 sec
0.2681 0.1926 0.1636 0.1258 0.0922 0.0840 0.0801 0.0744 0.0708 0.0685 0.0667 0.0655 0.0649 0.0644 0.0645 0.0646 

[TRAIN] Epoch[4](1382/1500); Loss: 0.130048; Backpropagation: 0.0936 sec; Batch: 0.4717 sec
0.1802 0.1577 0.1489 0.1442 0.1359 0.1281 0.1244 0.1223 0.1205 0.1192 0.1186 0.1173 0.1166 0.1159 0.1157 0.1152 

[TRAIN] Epoch[4](1383/1500); Loss: 0.115569; Backpropagation: 0.0938 sec; Batch: 0.4351 sec
0.2370 0.1791 0.1522 0.1256 0.1079 0.1024 0.0980 0.0971 0.0954 0.0943 0.0939 0.0933 0.0933 0.0933 0.0934 0.0929 

[TRAIN] Epoch[4](1384/1500); Loss: 0.112960; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.2203 0.1680 0.1410 0.1228 0.1060 0.1034 0.0994 0.0978 0.0961 0.0946 0.0937 0.0932 0.0932 0.0929 0.0927 0.0924 

[TRAIN] Epoch[4](1385/1500); Loss: 0.095737; Backpropagation: 0.0937 sec; Batch: 0.4689 sec
0.1944 0.1339 0.1221 0.1000 0.0944 0.0850 0.0844 0.0818 0.0808 0.0796 0.0798 0.0793 0.0789 0.0790 0.0792 0.0792 

[TRAIN] Epoch[4](1386/1500); Loss: 0.072793; Backpropagation: 0.0939 sec; Batch: 0.4674 sec
0.1466 0.0914 0.0818 0.0776 0.0712 0.0672 0.0648 0.0642 0.0635 0.0627 0.0624 0.0622 0.0621 0.0622 0.0624 0.0622 

[TRAIN] Epoch[4](1387/1500); Loss: 0.124152; Backpropagation: 0.0938 sec; Batch: 0.4700 sec
0.3706 0.2906 0.2548 0.1973 0.1409 0.0899 0.0674 0.0640 0.0654 0.0627 0.0627 0.0633 0.0633 0.0637 0.0644 0.0653 

[TRAIN] Epoch[4](1388/1500); Loss: 0.115776; Backpropagation: 0.0937 sec; Batch: 0.4657 sec
0.2633 0.1974 0.1643 0.1251 0.1083 0.1019 0.0991 0.0944 0.0911 0.0888 0.0879 0.0868 0.0862 0.0859 0.0858 0.0860 

[TRAIN] Epoch[4](1389/1500); Loss: 0.106654; Backpropagation: 0.0940 sec; Batch: 0.4673 sec
0.1274 0.1119 0.1109 0.1061 0.1053 0.1044 0.1042 0.1038 0.1038 0.1036 0.1039 0.1039 0.1040 0.1041 0.1044 0.1045 

[TRAIN] Epoch[4](1390/1500); Loss: 0.100046; Backpropagation: 0.0956 sec; Batch: 0.4720 sec
0.1589 0.1224 0.1078 0.1029 0.0978 0.0948 0.0930 0.0921 0.0914 0.0913 0.0909 0.0908 0.0918 0.0916 0.0914 0.0920 

[TRAIN] Epoch[4](1391/1500); Loss: 0.066895; Backpropagation: 0.0939 sec; Batch: 0.4448 sec
0.1483 0.0834 0.0713 0.0705 0.0630 0.0611 0.0583 0.0578 0.0567 0.0569 0.0573 0.0572 0.0573 0.0570 0.0569 0.0573 

[TRAIN] Epoch[4](1392/1500); Loss: 0.109888; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1909 0.1469 0.1306 0.1249 0.1124 0.1016 0.0975 0.0960 0.0963 0.0953 0.0947 0.0946 0.0943 0.0940 0.0943 0.0937 

[TRAIN] Epoch[4](1393/1500); Loss: 0.113588; Backpropagation: 0.0939 sec; Batch: 0.4749 sec
0.1984 0.1562 0.1255 0.1129 0.1094 0.1050 0.1033 0.1024 0.1011 0.1005 0.1003 0.1007 0.1005 0.1003 0.1003 0.1006 

[TRAIN] Epoch[4](1394/1500); Loss: 0.143861; Backpropagation: 0.0937 sec; Batch: 0.4746 sec
0.1777 0.1592 0.1537 0.1468 0.1438 0.1398 0.1391 0.1388 0.1394 0.1385 0.1379 0.1377 0.1376 0.1373 0.1375 0.1372 

[TRAIN] Epoch[4](1395/1500); Loss: 0.081813; Backpropagation: 0.0938 sec; Batch: 0.4677 sec
0.1967 0.1182 0.0934 0.0864 0.0767 0.0711 0.0691 0.0689 0.0672 0.0663 0.0665 0.0659 0.0654 0.0658 0.0655 0.0658 

[TRAIN] Epoch[4](1396/1500); Loss: 0.081187; Backpropagation: 0.0938 sec; Batch: 0.4591 sec
0.1682 0.1087 0.0919 0.0799 0.0737 0.0719 0.0708 0.0707 0.0699 0.0700 0.0702 0.0701 0.0703 0.0705 0.0708 0.0711 

[TRAIN] Epoch[4](1397/1500); Loss: 0.101503; Backpropagation: 0.0932 sec; Batch: 0.4648 sec
0.1284 0.1148 0.1081 0.1039 0.1014 0.0991 0.0982 0.0978 0.0970 0.0965 0.0963 0.0964 0.0963 0.0963 0.0965 0.0970 

[TRAIN] Epoch[4](1398/1500); Loss: 0.123764; Backpropagation: 0.0937 sec; Batch: 0.4637 sec
0.1747 0.1481 0.1330 0.1265 0.1240 0.1187 0.1169 0.1160 0.1155 0.1150 0.1148 0.1151 0.1150 0.1154 0.1155 0.1160 

[TRAIN] Epoch[4](1399/1500); Loss: 0.084596; Backpropagation: 0.0939 sec; Batch: 0.4685 sec
0.1337 0.1072 0.0975 0.0907 0.0833 0.0804 0.0783 0.0773 0.0765 0.0761 0.0761 0.0756 0.0753 0.0752 0.0751 0.0752 

[TRAIN] Epoch[4](1400/1500); Loss: 0.104192; Backpropagation: 0.0931 sec; Batch: 0.4642 sec
0.1854 0.1393 0.1280 0.1141 0.1003 0.0971 0.0938 0.0925 0.0913 0.0904 0.0896 0.0894 0.0893 0.0890 0.0889 0.0889 

[TRAIN] Epoch[4](1401/1500); Loss: 0.084301; Backpropagation: 0.0938 sec; Batch: 0.4704 sec
0.1686 0.1119 0.0977 0.0885 0.0852 0.0802 0.0747 0.0725 0.0713 0.0712 0.0710 0.0707 0.0708 0.0713 0.0714 0.0717 

[TRAIN] Epoch[4](1402/1500); Loss: 0.062557; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1706 0.1251 0.0981 0.0645 0.0487 0.0542 0.0508 0.0484 0.0454 0.0432 0.0419 0.0415 0.0416 0.0419 0.0423 0.0428 

[TRAIN] Epoch[4](1403/1500); Loss: 0.174104; Backpropagation: 0.0939 sec; Batch: 0.4706 sec
0.2290 0.1949 0.1849 0.1772 0.1752 0.1707 0.1684 0.1661 0.1663 0.1655 0.1654 0.1647 0.1646 0.1644 0.1642 0.1642 

[TRAIN] Epoch[4](1404/1500); Loss: 0.136809; Backpropagation: 0.0936 sec; Batch: 0.4305 sec
0.3249 0.2473 0.2163 0.1521 0.1126 0.1103 0.1110 0.1076 0.1044 0.1027 0.1013 0.1001 0.0997 0.0996 0.0995 0.0995 

[TRAIN] Epoch[4](1405/1500); Loss: 0.134697; Backpropagation: 0.0939 sec; Batch: 0.4308 sec
0.1937 0.1698 0.1562 0.1465 0.1375 0.1298 0.1297 0.1266 0.1238 0.1217 0.1208 0.1201 0.1199 0.1202 0.1197 0.1191 

[TRAIN] Epoch[4](1406/1500); Loss: 0.100051; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.1778 0.1334 0.1132 0.0857 0.0857 0.0974 0.1002 0.0999 0.0970 0.0937 0.0908 0.0881 0.0859 0.0846 0.0838 0.0835 

[TRAIN] Epoch[4](1407/1500); Loss: 0.135475; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.3577 0.2671 0.2346 0.1554 0.1052 0.0960 0.1125 0.1091 0.1024 0.0967 0.0925 0.0898 0.0882 0.0873 0.0867 0.0864 

[TRAIN] Epoch[4](1408/1500); Loss: 0.157315; Backpropagation: 0.0936 sec; Batch: 0.4387 sec
0.1969 0.1693 0.1645 0.1631 0.1659 0.1630 0.1582 0.1542 0.1513 0.1493 0.1477 0.1472 0.1471 0.1468 0.1463 0.1462 

[TRAIN] Epoch[4](1409/1500); Loss: 0.108152; Backpropagation: 0.0940 sec; Batch: 0.4676 sec
0.1648 0.1360 0.1067 0.1223 0.1193 0.1101 0.1031 0.0994 0.0976 0.0974 0.0964 0.0955 0.0957 0.0953 0.0953 0.0955 

[TRAIN] Epoch[4](1410/1500); Loss: 0.093819; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1428 0.1027 0.0985 0.0947 0.1018 0.0967 0.0920 0.0877 0.0866 0.0860 0.0856 0.0850 0.0849 0.0850 0.0854 0.0857 

[TRAIN] Epoch[4](1411/1500); Loss: 0.161830; Backpropagation: 0.0940 sec; Batch: 0.4341 sec
0.1221 0.1549 0.1449 0.1506 0.1528 0.1566 0.1587 0.1612 0.1628 0.1655 0.1687 0.1717 0.1748 0.1774 0.1816 0.1851 

[TRAIN] Epoch[4](1412/1500); Loss: 0.105989; Backpropagation: 0.0948 sec; Batch: 0.4715 sec
0.1581 0.1321 0.1172 0.1119 0.1073 0.1050 0.1022 0.0996 0.0977 0.0962 0.0951 0.0946 0.0943 0.0945 0.0949 0.0950 

[TRAIN] Epoch[4](1413/1500); Loss: 0.114787; Backpropagation: 0.0957 sec; Batch: 0.4670 sec
0.2335 0.1675 0.1069 0.1375 0.1147 0.1107 0.1074 0.1008 0.0952 0.0940 0.0935 0.0936 0.0935 0.0953 0.0961 0.0965 

[TRAIN] Epoch[4](1414/1500); Loss: 0.161965; Backpropagation: 0.0937 sec; Batch: 0.4685 sec
0.2173 0.1822 0.1764 0.1675 0.1671 0.1692 0.1653 0.1612 0.1566 0.1528 0.1500 0.1480 0.1463 0.1449 0.1438 0.1429 

[TRAIN] Epoch[4](1415/1500); Loss: 0.042243; Backpropagation: 0.0939 sec; Batch: 0.4670 sec
0.0580 0.0545 0.0462 0.0515 0.0496 0.0444 0.0402 0.0380 0.0375 0.0366 0.0360 0.0359 0.0364 0.0366 0.0368 0.0378 

[TRAIN] Epoch[4](1416/1500); Loss: 0.106374; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.1484 0.1416 0.1099 0.1189 0.1254 0.1179 0.1091 0.1011 0.0954 0.0923 0.0912 0.0906 0.0900 0.0898 0.0901 0.0903 

[TRAIN] Epoch[4](1417/1500); Loss: 0.098860; Backpropagation: 0.0938 sec; Batch: 0.4747 sec
0.1645 0.1255 0.1094 0.0845 0.0882 0.1044 0.1046 0.1024 0.0983 0.0936 0.0895 0.0863 0.0840 0.0825 0.0820 0.0820 

[TRAIN] Epoch[4](1418/1500); Loss: 0.089042; Backpropagation: 0.0937 sec; Batch: 0.4699 sec
0.1231 0.1036 0.1007 0.0998 0.0939 0.0890 0.0869 0.0869 0.0858 0.0837 0.0813 0.0796 0.0784 0.0777 0.0772 0.0769 

[TRAIN] Epoch[4](1419/1500); Loss: 0.101956; Backpropagation: 0.0938 sec; Batch: 0.5060 sec
0.1750 0.1414 0.1280 0.1078 0.0990 0.0941 0.0953 0.0945 0.0928 0.0912 0.0888 0.0867 0.0853 0.0844 0.0839 0.0831 

[TRAIN] Epoch[4](1420/1500); Loss: 0.101813; Backpropagation: 0.0937 sec; Batch: 0.4634 sec
0.1631 0.1181 0.1139 0.1102 0.1128 0.1126 0.1045 0.0979 0.0926 0.0902 0.0889 0.0869 0.0851 0.0844 0.0842 0.0836 

[TRAIN] Epoch[4](1421/1500); Loss: 0.124409; Backpropagation: 0.0938 sec; Batch: 0.4671 sec
0.2790 0.2019 0.1775 0.1288 0.1109 0.1096 0.1075 0.1035 0.1000 0.0979 0.0967 0.0959 0.0953 0.0953 0.0953 0.0954 

[TRAIN] Epoch[4](1422/1500); Loss: 0.145768; Backpropagation: 0.0936 sec; Batch: 0.4722 sec
0.4748 0.3592 0.3185 0.1897 0.0958 0.0790 0.1008 0.0956 0.0882 0.0816 0.0781 0.0756 0.0736 0.0736 0.0733 0.0748 

[TRAIN] Epoch[4](1423/1500); Loss: 0.119642; Backpropagation: 0.0939 sec; Batch: 0.4711 sec
0.1809 0.1398 0.1311 0.1272 0.1249 0.1245 0.1198 0.1158 0.1123 0.1095 0.1076 0.1061 0.1049 0.1040 0.1033 0.1027 

[TRAIN] Epoch[4](1424/1500); Loss: 0.071497; Backpropagation: 0.0937 sec; Batch: 0.4692 sec
0.1658 0.0992 0.0843 0.0730 0.0797 0.0759 0.0659 0.0600 0.0574 0.0568 0.0555 0.0542 0.0541 0.0541 0.0540 0.0541 

[TRAIN] Epoch[4](1425/1500); Loss: 0.138759; Backpropagation: 0.0938 sec; Batch: 0.4345 sec
0.3238 0.2574 0.2309 0.1700 0.1310 0.1111 0.1091 0.1096 0.1107 0.1059 0.1001 0.0957 0.0925 0.0911 0.0908 0.0905 

[TRAIN] Epoch[4](1426/1500); Loss: 0.162099; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.3832 0.2947 0.2685 0.1898 0.1392 0.1270 0.1289 0.1246 0.1206 0.1181 0.1164 0.1161 0.1160 0.1163 0.1166 0.1175 

[TRAIN] Epoch[4](1427/1500); Loss: 0.123097; Backpropagation: 0.0932 sec; Batch: 0.4694 sec
0.1684 0.1469 0.1362 0.1273 0.1243 0.1213 0.1203 0.1183 0.1162 0.1145 0.1134 0.1128 0.1124 0.1123 0.1124 0.1126 

[TRAIN] Epoch[4](1428/1500); Loss: 0.094019; Backpropagation: 0.0937 sec; Batch: 0.4682 sec
0.1726 0.1187 0.1056 0.0992 0.1000 0.0970 0.0879 0.0832 0.0814 0.0810 0.0802 0.0795 0.0795 0.0794 0.0795 0.0797 

[TRAIN] Epoch[4](1429/1500); Loss: 0.117609; Backpropagation: 0.0939 sec; Batch: 0.4812 sec
0.1492 0.1297 0.1246 0.1246 0.1203 0.1165 0.1143 0.1129 0.1127 0.1121 0.1116 0.1109 0.1104 0.1104 0.1108 0.1108 

[TRAIN] Epoch[4](1430/1500); Loss: 0.145820; Backpropagation: 0.0937 sec; Batch: 0.4688 sec
0.3642 0.2947 0.2776 0.2096 0.1607 0.1208 0.0944 0.1011 0.0996 0.0946 0.0894 0.0868 0.0859 0.0847 0.0844 0.0848 

[TRAIN] Epoch[4](1431/1500); Loss: 0.090404; Backpropagation: 0.0937 sec; Batch: 0.4692 sec
0.1315 0.1113 0.0991 0.0908 0.0928 0.0877 0.0849 0.0832 0.0828 0.0828 0.0827 0.0827 0.0831 0.0832 0.0839 0.0841 

[TRAIN] Epoch[4](1432/1500); Loss: 0.147719; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.2381 0.1969 0.1836 0.1604 0.1447 0.1385 0.1407 0.1384 0.1344 0.1315 0.1294 0.1277 0.1264 0.1250 0.1243 0.1237 

[TRAIN] Epoch[4](1433/1500); Loss: 0.094265; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.1767 0.1160 0.1013 0.0824 0.0929 0.0894 0.0858 0.0841 0.0836 0.0831 0.0836 0.0845 0.0851 0.0854 0.0870 0.0874 

[TRAIN] Epoch[4](1434/1500); Loss: 0.133666; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.4742 0.3579 0.3148 0.1878 0.0904 0.0761 0.0725 0.0669 0.0630 0.0628 0.0615 0.0611 0.0614 0.0621 0.0626 0.0636 

[TRAIN] Epoch[4](1435/1500); Loss: 0.094124; Backpropagation: 0.0981 sec; Batch: 0.4709 sec
0.1626 0.1298 0.1157 0.0981 0.0930 0.0894 0.0885 0.0857 0.0841 0.0824 0.0805 0.0796 0.0794 0.0794 0.0787 0.0789 

[TRAIN] Epoch[4](1436/1500); Loss: 0.076046; Backpropagation: 0.0982 sec; Batch: 0.4747 sec
0.1714 0.1218 0.1015 0.0801 0.0760 0.0751 0.0675 0.0619 0.0582 0.0578 0.0571 0.0572 0.0573 0.0580 0.0578 0.0581 

[TRAIN] Epoch[4](1437/1500); Loss: 0.122946; Backpropagation: 0.0940 sec; Batch: 0.4341 sec
0.1614 0.1505 0.1363 0.1262 0.1263 0.1193 0.1163 0.1141 0.1136 0.1132 0.1132 0.1137 0.1147 0.1151 0.1161 0.1171 

[TRAIN] Epoch[4](1438/1500); Loss: 0.111288; Backpropagation: 0.0936 sec; Batch: 0.4660 sec
0.1593 0.1335 0.1224 0.1152 0.1130 0.1100 0.1073 0.1052 0.1037 0.1024 0.1015 0.1013 0.1011 0.1012 0.1015 0.1021 

[TRAIN] Epoch[4](1439/1500); Loss: 0.039996; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.0648 0.0546 0.0390 0.0413 0.0390 0.0363 0.0350 0.0345 0.0342 0.0345 0.0358 0.0368 0.0371 0.0379 0.0386 0.0405 

[TRAIN] Epoch[4](1440/1500); Loss: 0.139367; Backpropagation: 0.0943 sec; Batch: 0.4660 sec
0.1771 0.1509 0.1488 0.1577 0.1529 0.1457 0.1380 0.1341 0.1320 0.1306 0.1288 0.1278 0.1270 0.1267 0.1260 0.1257 

[TRAIN] Epoch[4](1441/1500); Loss: 0.110188; Backpropagation: 0.0939 sec; Batch: 0.4662 sec
0.2362 0.1922 0.1402 0.0981 0.0987 0.0975 0.0962 0.0928 0.0895 0.0884 0.0885 0.0890 0.0886 0.0888 0.0892 0.0893 

[TRAIN] Epoch[4](1442/1500); Loss: 0.058543; Backpropagation: 0.0954 sec; Batch: 0.4402 sec
0.0860 0.0864 0.0587 0.0666 0.0677 0.0601 0.0543 0.0516 0.0504 0.0507 0.0508 0.0500 0.0503 0.0507 0.0509 0.0513 

[TRAIN] Epoch[4](1443/1500); Loss: 0.098845; Backpropagation: 0.0939 sec; Batch: 0.4655 sec
0.1753 0.1378 0.1222 0.1092 0.1027 0.0982 0.0927 0.0890 0.0861 0.0838 0.0820 0.0807 0.0806 0.0807 0.0804 0.0803 

[TRAIN] Epoch[4](1444/1500); Loss: 0.108485; Backpropagation: 0.0952 sec; Batch: 0.4294 sec
0.1849 0.1465 0.1313 0.1164 0.1092 0.1076 0.1032 0.0985 0.0949 0.0931 0.0922 0.0917 0.0914 0.0912 0.0917 0.0918 

[TRAIN] Epoch[4](1445/1500); Loss: 0.149378; Backpropagation: 0.0938 sec; Batch: 0.4718 sec
0.2777 0.2292 0.2105 0.1740 0.1539 0.1360 0.1296 0.1244 0.1210 0.1196 0.1194 0.1193 0.1188 0.1187 0.1191 0.1189 

[TRAIN] Epoch[4](1446/1500); Loss: 0.130902; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2203 0.1723 0.1600 0.1392 0.1282 0.1200 0.1155 0.1139 0.1130 0.1136 0.1141 0.1147 0.1155 0.1167 0.1179 0.1194 

[TRAIN] Epoch[4](1447/1500); Loss: 0.114523; Backpropagation: 0.0935 sec; Batch: 0.4291 sec
0.2205 0.1795 0.1682 0.1381 0.1191 0.1065 0.1009 0.0973 0.0942 0.0906 0.0879 0.0868 0.0862 0.0858 0.0855 0.0852 

[TRAIN] Epoch[4](1448/1500); Loss: 0.130549; Backpropagation: 0.0937 sec; Batch: 0.4744 sec
0.1982 0.1583 0.1526 0.1403 0.1385 0.1326 0.1268 0.1230 0.1198 0.1174 0.1156 0.1142 0.1136 0.1131 0.1126 0.1121 

[TRAIN] Epoch[4](1449/1500); Loss: 0.126070; Backpropagation: 0.0940 sec; Batch: 0.4475 sec
0.1757 0.1475 0.1302 0.1333 0.1307 0.1256 0.1213 0.1190 0.1178 0.1173 0.1168 0.1164 0.1165 0.1163 0.1163 0.1164 

[TRAIN] Epoch[4](1450/1500); Loss: 0.181570; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.2604 0.2070 0.1939 0.1845 0.1791 0.1757 0.1728 0.1714 0.1705 0.1704 0.1703 0.1702 0.1698 0.1696 0.1697 0.1698 

[TRAIN] Epoch[4](1451/1500); Loss: 0.110252; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1416 0.1231 0.1151 0.1148 0.1176 0.1132 0.1085 0.1056 0.1043 0.1037 0.1034 0.1028 0.1025 0.1025 0.1026 0.1026 

[TRAIN] Epoch[4](1452/1500); Loss: 0.080984; Backpropagation: 0.0936 sec; Batch: 0.4675 sec
0.1561 0.1107 0.0921 0.0812 0.0790 0.0744 0.0711 0.0701 0.0701 0.0692 0.0692 0.0692 0.0696 0.0702 0.0715 0.0720 

[TRAIN] Epoch[4](1453/1500); Loss: 0.075291; Backpropagation: 0.0938 sec; Batch: 0.4991 sec
0.1831 0.1151 0.0966 0.0734 0.0790 0.0732 0.0652 0.0601 0.0578 0.0584 0.0581 0.0569 0.0567 0.0569 0.0569 0.0571 

[TRAIN] Epoch[4](1454/1500); Loss: 0.131041; Backpropagation: 0.0938 sec; Batch: 0.4677 sec
0.1988 0.1661 0.1581 0.1469 0.1345 0.1269 0.1240 0.1210 0.1181 0.1162 0.1151 0.1144 0.1143 0.1140 0.1140 0.1142 

[TRAIN] Epoch[4](1455/1500); Loss: 0.086052; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.1166 0.1016 0.0913 0.0902 0.0897 0.0862 0.0832 0.0817 0.0807 0.0798 0.0792 0.0790 0.0791 0.0792 0.0794 0.0800 

[TRAIN] Epoch[4](1456/1500); Loss: 0.150699; Backpropagation: 0.0937 sec; Batch: 0.4473 sec
0.2393 0.2111 0.1944 0.1719 0.1552 0.1422 0.1343 0.1323 0.1313 0.1298 0.1292 0.1287 0.1283 0.1279 0.1277 0.1276 

[TRAIN] Epoch[4](1457/1500); Loss: 0.071764; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.0942 0.0951 0.0744 0.0755 0.0751 0.0702 0.0682 0.0674 0.0673 0.0666 0.0660 0.0657 0.0657 0.0659 0.0656 0.0655 

[TRAIN] Epoch[4](1458/1500); Loss: 0.172858; Backpropagation: 0.0936 sec; Batch: 0.4656 sec
0.2260 0.1931 0.1914 0.1779 0.1740 0.1673 0.1663 0.1651 0.1646 0.1632 0.1639 0.1635 0.1620 0.1625 0.1629 0.1621 

[TRAIN] Epoch[4](1459/1500); Loss: 0.113948; Backpropagation: 0.0938 sec; Batch: 0.4710 sec
0.2593 0.2051 0.1771 0.1345 0.1044 0.0926 0.0991 0.0927 0.0864 0.0826 0.0818 0.0810 0.0814 0.0813 0.0818 0.0822 

[TRAIN] Epoch[4](1460/1500); Loss: 0.090840; Backpropagation: 0.0938 sec; Batch: 0.5266 sec
0.1215 0.1164 0.0915 0.0972 0.0953 0.0898 0.0861 0.0847 0.0841 0.0838 0.0835 0.0835 0.0840 0.0841 0.0839 0.0840 

[TRAIN] Epoch[4](1461/1500); Loss: 0.092811; Backpropagation: 0.0938 sec; Batch: 0.4343 sec
0.1438 0.1173 0.1007 0.0930 0.0936 0.0891 0.0861 0.0845 0.0846 0.0841 0.0839 0.0840 0.0844 0.0849 0.0853 0.0857 

[TRAIN] Epoch[4](1462/1500); Loss: 0.140736; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2235 0.1867 0.1661 0.1452 0.1368 0.1355 0.1341 0.1315 0.1285 0.1261 0.1244 0.1235 0.1230 0.1225 0.1222 0.1222 

[TRAIN] Epoch[4](1463/1500); Loss: 0.095073; Backpropagation: 0.0938 sec; Batch: 0.4785 sec
0.1416 0.1039 0.0987 0.1059 0.0991 0.0959 0.0914 0.0891 0.0877 0.0874 0.0868 0.0864 0.0865 0.0866 0.0869 0.0872 

[TRAIN] Epoch[4](1464/1500); Loss: 0.081647; Backpropagation: 0.0931 sec; Batch: 0.4685 sec
0.1530 0.1208 0.0963 0.0832 0.0793 0.0761 0.0729 0.0706 0.0694 0.0685 0.0684 0.0689 0.0692 0.0691 0.0699 0.0707 

[TRAIN] Epoch[4](1465/1500); Loss: 0.082882; Backpropagation: 0.0937 sec; Batch: 0.4556 sec
0.1608 0.1180 0.0989 0.0964 0.0900 0.0816 0.0737 0.0703 0.0690 0.0677 0.0667 0.0663 0.0666 0.0664 0.0668 0.0669 

[TRAIN] Epoch[4](1466/1500); Loss: 0.063304; Backpropagation: 0.0937 sec; Batch: 0.4718 sec
0.1089 0.0969 0.0637 0.0597 0.0609 0.0580 0.0565 0.0564 0.0564 0.0557 0.0557 0.0560 0.0567 0.0567 0.0572 0.0576 

[TRAIN] Epoch[4](1467/1500); Loss: 0.071339; Backpropagation: 0.0956 sec; Batch: 0.4685 sec
0.2124 0.1198 0.0905 0.0622 0.0683 0.0626 0.0562 0.0534 0.0523 0.0525 0.0520 0.0515 0.0518 0.0516 0.0519 0.0525 

[TRAIN] Epoch[4](1468/1500); Loss: 0.146622; Backpropagation: 0.0937 sec; Batch: 0.4642 sec
0.1919 0.1782 0.1626 0.1540 0.1482 0.1441 0.1418 0.1406 0.1387 0.1371 0.1363 0.1355 0.1348 0.1343 0.1341 0.1337 

[TRAIN] Epoch[4](1469/1500); Loss: 0.092922; Backpropagation: 0.0932 sec; Batch: 0.4674 sec
0.2778 0.1853 0.1510 0.0837 0.0811 0.0802 0.0716 0.0666 0.0640 0.0627 0.0612 0.0607 0.0602 0.0600 0.0602 0.0603 

[TRAIN] Epoch[4](1470/1500); Loss: 0.137826; Backpropagation: 0.0930 sec; Batch: 0.4657 sec
0.2810 0.2242 0.2049 0.1701 0.1429 0.1221 0.1125 0.1135 0.1097 0.1060 0.1040 0.1030 0.1028 0.1026 0.1031 0.1030 

[TRAIN] Epoch[4](1471/1500); Loss: 0.092392; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2474 0.1856 0.1547 0.1168 0.0924 0.0765 0.0700 0.0641 0.0601 0.0587 0.0584 0.0580 0.0585 0.0588 0.0588 0.0594 

[TRAIN] Epoch[4](1472/1500); Loss: 0.092920; Backpropagation: 0.0936 sec; Batch: 0.5124 sec
0.2251 0.1404 0.1270 0.0856 0.0960 0.0813 0.0743 0.0711 0.0711 0.0713 0.0715 0.0719 0.0725 0.0755 0.0756 0.0766 

[TRAIN] Epoch[4](1473/1500); Loss: 0.097161; Backpropagation: 0.0938 sec; Batch: 0.4643 sec
0.2300 0.1745 0.1184 0.0815 0.0902 0.0854 0.0838 0.0798 0.0770 0.0757 0.0756 0.0762 0.0763 0.0761 0.0766 0.0776 

[TRAIN] Epoch[4](1474/1500); Loss: 0.107187; Backpropagation: 0.0936 sec; Batch: 0.4666 sec
0.2271 0.1729 0.1185 0.1065 0.0998 0.1010 0.0946 0.0907 0.0891 0.0884 0.0882 0.0875 0.0874 0.0874 0.0876 0.0883 

[TRAIN] Epoch[4](1475/1500); Loss: 0.049450; Backpropagation: 0.0937 sec; Batch: 0.4675 sec
0.0812 0.0480 0.0791 0.0555 0.0486 0.0421 0.0410 0.0404 0.0429 0.0425 0.0424 0.0434 0.0441 0.0458 0.0469 0.0471 

[TRAIN] Epoch[4](1476/1500); Loss: 0.081040; Backpropagation: 0.0937 sec; Batch: 0.4657 sec
0.1449 0.0958 0.0997 0.0884 0.0809 0.0759 0.0727 0.0708 0.0719 0.0714 0.0706 0.0701 0.0704 0.0707 0.0713 0.0711 

[TRAIN] Epoch[4](1477/1500); Loss: 0.101712; Backpropagation: 0.0940 sec; Batch: 0.4294 sec
0.2693 0.1963 0.1702 0.1124 0.0899 0.0922 0.0817 0.0759 0.0715 0.0692 0.0679 0.0671 0.0665 0.0661 0.0657 0.0656 

[TRAIN] Epoch[4](1478/1500); Loss: 0.126709; Backpropagation: 0.0937 sec; Batch: 0.4656 sec
0.1824 0.1548 0.1399 0.1341 0.1285 0.1236 0.1197 0.1177 0.1166 0.1158 0.1156 0.1158 0.1156 0.1158 0.1158 0.1158 

[TRAIN] Epoch[4](1479/1500); Loss: 0.056869; Backpropagation: 0.0939 sec; Batch: 0.4676 sec
0.0992 0.0899 0.0600 0.0605 0.0561 0.0524 0.0506 0.0502 0.0498 0.0490 0.0487 0.0487 0.0483 0.0482 0.0490 0.0492 

[TRAIN] Epoch[4](1480/1500); Loss: 0.122239; Backpropagation: 0.0937 sec; Batch: 0.4648 sec
0.1790 0.1495 0.1410 0.1348 0.1258 0.1195 0.1155 0.1138 0.1128 0.1114 0.1104 0.1095 0.1087 0.1082 0.1081 0.1078 

[TRAIN] Epoch[4](1481/1500); Loss: 0.077374; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1251 0.1068 0.0842 0.0822 0.0761 0.0724 0.0702 0.0695 0.0692 0.0686 0.0685 0.0687 0.0689 0.0689 0.0691 0.0695 

[TRAIN] Epoch[4](1482/1500); Loss: 0.128416; Backpropagation: 0.0932 sec; Batch: 0.4538 sec
0.2129 0.1760 0.1470 0.1438 0.1309 0.1226 0.1189 0.1176 0.1164 0.1138 0.1112 0.1107 0.1098 0.1081 0.1075 0.1073 

[TRAIN] Epoch[4](1483/1500); Loss: 0.087878; Backpropagation: 0.0937 sec; Batch: 0.4767 sec
0.1143 0.1051 0.0939 0.0900 0.0901 0.0867 0.0844 0.0832 0.0831 0.0826 0.0822 0.0818 0.0820 0.0821 0.0822 0.0825 

[TRAIN] Epoch[4](1484/1500); Loss: 0.107534; Backpropagation: 0.0936 sec; Batch: 0.4649 sec
0.2143 0.1688 0.1375 0.1129 0.1006 0.0978 0.0941 0.0914 0.0895 0.0886 0.0879 0.0878 0.0875 0.0874 0.0872 0.0870 

[TRAIN] Epoch[4](1485/1500); Loss: 0.126922; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.2260 0.1837 0.1582 0.1323 0.1228 0.1178 0.1152 0.1130 0.1105 0.1088 0.1079 0.1075 0.1070 0.1067 0.1067 0.1067 

[TRAIN] Epoch[4](1486/1500); Loss: 0.101208; Backpropagation: 0.0937 sec; Batch: 0.4697 sec
0.1522 0.1226 0.1041 0.1045 0.0993 0.0962 0.0949 0.0942 0.0939 0.0936 0.0934 0.0937 0.0939 0.0941 0.0941 0.0946 

[TRAIN] Epoch[4](1487/1500); Loss: 0.109634; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.2259 0.1812 0.1410 0.1158 0.0995 0.0981 0.0922 0.0897 0.0886 0.0883 0.0886 0.0883 0.0886 0.0889 0.0895 0.0899 

[TRAIN] Epoch[4](1488/1500); Loss: 0.107703; Backpropagation: 0.0937 sec; Batch: 0.4708 sec
0.1632 0.1243 0.1202 0.1081 0.1105 0.1044 0.1006 0.0978 0.0982 0.0986 0.0989 0.0989 0.0991 0.0995 0.1002 0.1009 

[TRAIN] Epoch[4](1489/1500); Loss: 0.081998; Backpropagation: 0.0933 sec; Batch: 0.4660 sec
0.1041 0.1100 0.0834 0.0823 0.0829 0.0790 0.0768 0.0766 0.0767 0.0771 0.0766 0.0765 0.0774 0.0770 0.0777 0.0778 

[TRAIN] Epoch[4](1490/1500); Loss: 0.187501; Backpropagation: 0.0937 sec; Batch: 0.4636 sec
0.2341 0.2153 0.2026 0.1909 0.1886 0.1844 0.1829 0.1814 0.1802 0.1790 0.1783 0.1772 0.1767 0.1764 0.1761 0.1759 

[TRAIN] Epoch[4](1491/1500); Loss: 0.110140; Backpropagation: 0.0938 sec; Batch: 0.4700 sec
0.3821 0.2984 0.2499 0.1607 0.0875 0.0547 0.0674 0.0602 0.0526 0.0488 0.0491 0.0495 0.0489 0.0499 0.0513 0.0513 

[TRAIN] Epoch[4](1492/1500); Loss: 0.070030; Backpropagation: 0.0938 sec; Batch: 0.4687 sec
0.1602 0.1012 0.0906 0.0982 0.0748 0.0645 0.0560 0.0562 0.0555 0.0532 0.0518 0.0519 0.0520 0.0513 0.0512 0.0519 

[TRAIN] Epoch[4](1493/1500); Loss: 0.059975; Backpropagation: 0.0931 sec; Batch: 0.4691 sec
0.1366 0.1144 0.0766 0.0572 0.0578 0.0516 0.0480 0.0468 0.0455 0.0444 0.0449 0.0458 0.0462 0.0464 0.0482 0.0492 

[TRAIN] Epoch[4](1494/1500); Loss: 0.125622; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.2881 0.2243 0.2127 0.1545 0.1161 0.0963 0.0969 0.0927 0.0911 0.0912 0.0907 0.0902 0.0903 0.0914 0.0916 0.0918 

[TRAIN] Epoch[4](1495/1500); Loss: 0.085776; Backpropagation: 0.0939 sec; Batch: 0.4670 sec
0.1323 0.1233 0.0918 0.0876 0.0851 0.0808 0.0788 0.0777 0.0770 0.0767 0.0766 0.0769 0.0764 0.0768 0.0772 0.0774 

[TRAIN] Epoch[4](1496/1500); Loss: 0.096913; Backpropagation: 0.0956 sec; Batch: 0.4734 sec
0.1506 0.1220 0.1065 0.0970 0.0951 0.0916 0.0899 0.0891 0.0889 0.0885 0.0884 0.0884 0.0881 0.0884 0.0890 0.0893 

[TRAIN] Epoch[4](1497/1500); Loss: 0.121830; Backpropagation: 0.0959 sec; Batch: 0.4455 sec
0.2190 0.1763 0.1508 0.1332 0.1234 0.1141 0.1087 0.1065 0.1050 0.1033 0.1026 0.1020 0.1019 0.1012 0.1007 0.1008 

[TRAIN] Epoch[4](1498/1500); Loss: 0.122787; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1636 0.1419 0.1218 0.1167 0.1161 0.1143 0.1149 0.1150 0.1160 0.1174 0.1181 0.1192 0.1203 0.1219 0.1230 0.1243 

[TRAIN] Epoch[4](1499/1500); Loss: 0.135123; Backpropagation: 0.0939 sec; Batch: 0.4361 sec
0.3696 0.2909 0.2554 0.1804 0.1268 0.0984 0.0944 0.0879 0.0833 0.0819 0.0821 0.0813 0.0816 0.0821 0.0828 0.0829 

[TRAIN] Epoch[4](1500/1500); Loss: 0.067788; Backpropagation: 0.0938 sec; Batch: 0.4274 sec
0.0933 0.1024 0.0679 0.0698 0.0695 0.0638 0.0625 0.0613 0.0621 0.0615 0.0612 0.0610 0.0616 0.0618 0.0624 0.0625 

[TRAIN] Epoch[5](1/1500); Loss: 0.111590; Backpropagation: 0.1004 sec; Batch: 0.4649 sec
0.2600 0.1903 0.1626 0.1234 0.1047 0.1016 0.0926 0.0875 0.0848 0.0840 0.0831 0.0823 0.0816 0.0821 0.0822 0.0826 

[TRAIN] Epoch[5](2/1500); Loss: 0.053031; Backpropagation: 0.0958 sec; Batch: 0.4410 sec
0.0878 0.0598 0.0818 0.0625 0.0496 0.0452 0.0459 0.0443 0.0467 0.0453 0.0449 0.0465 0.0454 0.0468 0.0476 0.0484 

[TRAIN] Epoch[5](3/1500); Loss: 0.122678; Backpropagation: 0.0942 sec; Batch: 0.4313 sec
0.3431 0.2759 0.2401 0.1767 0.1221 0.0787 0.0823 0.0743 0.0701 0.0700 0.0698 0.0711 0.0713 0.0716 0.0727 0.0731 

[TRAIN] Epoch[5](4/1500); Loss: 0.071870; Backpropagation: 0.0940 sec; Batch: 0.4298 sec
0.1749 0.1087 0.0857 0.0825 0.0698 0.0656 0.0603 0.0592 0.0578 0.0567 0.0562 0.0553 0.0548 0.0544 0.0541 0.0537 

[TRAIN] Epoch[5](5/1500); Loss: 0.111604; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.3376 0.2677 0.2252 0.1443 0.0860 0.0721 0.0671 0.0663 0.0642 0.0668 0.0648 0.0642 0.0642 0.0642 0.0648 0.0661 

[TRAIN] Epoch[5](6/1500); Loss: 0.064334; Backpropagation: 0.0940 sec; Batch: 0.4298 sec
0.1112 0.0955 0.0704 0.0680 0.0631 0.0604 0.0591 0.0576 0.0568 0.0561 0.0558 0.0553 0.0552 0.0550 0.0548 0.0547 

[TRAIN] Epoch[5](7/1500); Loss: 0.086826; Backpropagation: 0.0945 sec; Batch: 0.4331 sec
0.1671 0.1176 0.1119 0.0959 0.0883 0.0820 0.0757 0.0744 0.0729 0.0720 0.0720 0.0720 0.0720 0.0717 0.0720 0.0716 

[TRAIN] Epoch[5](8/1500); Loss: 0.085175; Backpropagation: 0.0938 sec; Batch: 0.5170 sec
0.1590 0.1363 0.0944 0.0968 0.0909 0.0801 0.0749 0.0722 0.0712 0.0703 0.0698 0.0694 0.0694 0.0692 0.0696 0.0694 

[TRAIN] Epoch[5](9/1500); Loss: 0.111325; Backpropagation: 0.0942 sec; Batch: 0.4341 sec
0.1852 0.1494 0.1260 0.1143 0.1101 0.1058 0.1026 0.1009 0.0993 0.0986 0.0986 0.0986 0.0982 0.0977 0.0977 0.0982 

[TRAIN] Epoch[5](10/1500); Loss: 0.038094; Backpropagation: 0.0934 sec; Batch: 0.4648 sec
0.0476 0.0650 0.0352 0.0368 0.0372 0.0359 0.0340 0.0343 0.0350 0.0346 0.0341 0.0351 0.0357 0.0358 0.0355 0.0376 

[TRAIN] Epoch[5](11/1500); Loss: 0.075168; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1031 0.0850 0.0769 0.0810 0.0770 0.0740 0.0716 0.0707 0.0707 0.0707 0.0698 0.0697 0.0701 0.0708 0.0707 0.0707 

[TRAIN] Epoch[5](12/1500); Loss: 0.083339; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1255 0.1070 0.0927 0.0918 0.0867 0.0820 0.0789 0.0770 0.0756 0.0747 0.0738 0.0736 0.0734 0.0734 0.0736 0.0737 

[TRAIN] Epoch[5](13/1500); Loss: 0.140887; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2818 0.2201 0.1963 0.1573 0.1481 0.1349 0.1266 0.1215 0.1162 0.1122 0.1100 0.1082 0.1065 0.1051 0.1048 0.1045 

[TRAIN] Epoch[5](14/1500); Loss: 0.153420; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2037 0.1961 0.1598 0.1511 0.1488 0.1468 0.1459 0.1463 0.1463 0.1447 0.1437 0.1437 0.1447 0.1450 0.1446 0.1435 

[TRAIN] Epoch[5](15/1500); Loss: 0.157660; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2127 0.1836 0.1735 0.1630 0.1572 0.1543 0.1514 0.1494 0.1483 0.1475 0.1471 0.1469 0.1470 0.1470 0.1468 0.1470 

[TRAIN] Epoch[5](16/1500); Loss: 0.100191; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1914 0.1499 0.1307 0.1058 0.0983 0.0966 0.0919 0.0874 0.0839 0.0827 0.0820 0.0812 0.0807 0.0803 0.0802 0.0801 

[TRAIN] Epoch[5](17/1500); Loss: 0.115952; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.4591 0.3446 0.2941 0.1684 0.0726 0.0637 0.0551 0.0507 0.0479 0.0453 0.0422 0.0411 0.0433 0.0425 0.0419 0.0426 

[TRAIN] Epoch[5](18/1500); Loss: 0.068456; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1200 0.0962 0.0698 0.0823 0.0747 0.0678 0.0632 0.0610 0.0604 0.0589 0.0577 0.0574 0.0571 0.0564 0.0564 0.0562 

[TRAIN] Epoch[5](19/1500); Loss: 0.119507; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1646 0.1564 0.1290 0.1230 0.1227 0.1165 0.1129 0.1111 0.1105 0.1100 0.1094 0.1091 0.1091 0.1094 0.1092 0.1093 

[TRAIN] Epoch[5](20/1500); Loss: 0.129842; Backpropagation: 0.0981 sec; Batch: 0.4331 sec
0.1776 0.1576 0.1405 0.1374 0.1353 0.1302 0.1260 0.1234 0.1214 0.1201 0.1196 0.1191 0.1182 0.1175 0.1170 0.1166 

[TRAIN] Epoch[5](21/1500); Loss: 0.039973; Backpropagation: 0.0959 sec; Batch: 0.4307 sec
0.0761 0.0473 0.0472 0.0416 0.0434 0.0388 0.0348 0.0348 0.0340 0.0334 0.0339 0.0337 0.0347 0.0350 0.0348 0.0362 

[TRAIN] Epoch[5](22/1500); Loss: 0.105865; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1918 0.1512 0.1363 0.1172 0.1038 0.1023 0.0981 0.0941 0.0910 0.0893 0.0876 0.0866 0.0861 0.0863 0.0861 0.0861 

[TRAIN] Epoch[5](23/1500); Loss: 0.083401; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.2894 0.1708 0.1259 0.0826 0.0815 0.0765 0.0601 0.0537 0.0519 0.0510 0.0489 0.0483 0.0487 0.0484 0.0481 0.0484 

[TRAIN] Epoch[5](24/1500); Loss: 0.088605; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1754 0.1377 0.1231 0.0968 0.0851 0.0825 0.0798 0.0772 0.0742 0.0725 0.0712 0.0690 0.0685 0.0678 0.0684 0.0684 

[TRAIN] Epoch[5](25/1500); Loss: 0.126024; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1544 0.1397 0.1332 0.1355 0.1300 0.1253 0.1228 0.1218 0.1209 0.1198 0.1191 0.1193 0.1192 0.1186 0.1182 0.1185 

[TRAIN] Epoch[5](26/1500); Loss: 0.084742; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1414 0.1035 0.0922 0.0927 0.0873 0.0811 0.0778 0.0760 0.0762 0.0754 0.0744 0.0744 0.0752 0.0757 0.0762 0.0762 

[TRAIN] Epoch[5](27/1500); Loss: 0.076153; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.1072 0.0973 0.0796 0.0831 0.0816 0.0769 0.0728 0.0708 0.0698 0.0694 0.0692 0.0685 0.0681 0.0679 0.0681 0.0681 

[TRAIN] Epoch[5](28/1500); Loss: 0.082897; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2466 0.1690 0.1323 0.0805 0.0750 0.0736 0.0645 0.0576 0.0548 0.0540 0.0535 0.0524 0.0527 0.0528 0.0535 0.0535 

[TRAIN] Epoch[5](29/1500); Loss: 0.130278; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.4026 0.2964 0.2531 0.1534 0.0966 0.0899 0.0843 0.0800 0.0786 0.0785 0.0781 0.0775 0.0785 0.0785 0.0785 0.0801 

[TRAIN] Epoch[5](30/1500); Loss: 0.119954; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.3211 0.2413 0.2087 0.1353 0.0952 0.0978 0.0944 0.0882 0.0825 0.0805 0.0799 0.0793 0.0789 0.0786 0.0786 0.0791 

[TRAIN] Epoch[5](31/1500); Loss: 0.102508; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1485 0.1216 0.1079 0.1076 0.1064 0.1023 0.0979 0.0949 0.0940 0.0937 0.0940 0.0940 0.0937 0.0942 0.0944 0.0952 

[TRAIN] Epoch[5](32/1500); Loss: 0.112496; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.2112 0.1587 0.1426 0.1241 0.1129 0.1130 0.1052 0.1005 0.0967 0.0938 0.0916 0.0902 0.0903 0.0902 0.0896 0.0893 

[TRAIN] Epoch[5](33/1500); Loss: 0.102316; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2607 0.1886 0.1546 0.1087 0.1028 0.0953 0.0882 0.0845 0.0783 0.0735 0.0701 0.0682 0.0669 0.0660 0.0656 0.0652 

[TRAIN] Epoch[5](34/1500); Loss: 0.105759; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1642 0.1378 0.1248 0.1181 0.1088 0.1013 0.0976 0.0955 0.0948 0.0938 0.0931 0.0930 0.0929 0.0926 0.0920 0.0920 

[TRAIN] Epoch[5](35/1500); Loss: 0.125101; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.2288 0.1817 0.1656 0.1484 0.1269 0.1146 0.1122 0.1099 0.1069 0.1046 0.1021 0.1006 0.1000 0.1004 0.0998 0.0989 

[TRAIN] Epoch[5](36/1500); Loss: 0.100419; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2024 0.1588 0.1210 0.1043 0.0979 0.0958 0.0908 0.0868 0.0842 0.0823 0.0816 0.0807 0.0801 0.0798 0.0799 0.0804 

[TRAIN] Epoch[5](37/1500); Loss: 0.120681; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1947 0.1512 0.1381 0.1360 0.1233 0.1164 0.1116 0.1093 0.1079 0.1070 0.1064 0.1059 0.1056 0.1056 0.1057 0.1060 

[TRAIN] Epoch[5](38/1500); Loss: 0.137995; Backpropagation: 0.0957 sec; Batch: 0.4293 sec
0.2126 0.1744 0.1495 0.1400 0.1392 0.1364 0.1321 0.1289 0.1270 0.1259 0.1250 0.1244 0.1236 0.1232 0.1230 0.1229 

[TRAIN] Epoch[5](39/1500); Loss: 0.073974; Backpropagation: 0.0943 sec; Batch: 0.4282 sec
0.1503 0.1027 0.0849 0.0846 0.0749 0.0694 0.0657 0.0642 0.0628 0.0616 0.0606 0.0604 0.0601 0.0605 0.0603 0.0606 

[TRAIN] Epoch[5](40/1500); Loss: 0.095995; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.2365 0.1784 0.1062 0.0903 0.0842 0.0812 0.0776 0.0763 0.0749 0.0770 0.0767 0.0750 0.0750 0.0752 0.0758 0.0756 

[TRAIN] Epoch[5](41/1500); Loss: 0.065198; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1034 0.0869 0.0767 0.0755 0.0673 0.0622 0.0601 0.0585 0.0575 0.0569 0.0567 0.0564 0.0562 0.0563 0.0561 0.0565 

[TRAIN] Epoch[5](42/1500); Loss: 0.134673; Backpropagation: 0.0932 sec; Batch: 0.4280 sec
0.2782 0.2070 0.1803 0.1405 0.1258 0.1211 0.1159 0.1127 0.1107 0.1095 0.1090 0.1088 0.1088 0.1089 0.1088 0.1088 

[TRAIN] Epoch[5](43/1500); Loss: 0.101137; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1683 0.1337 0.1157 0.1101 0.1027 0.0985 0.0931 0.0904 0.0888 0.0885 0.0881 0.0879 0.0884 0.0875 0.0875 0.0890 

[TRAIN] Epoch[5](44/1500); Loss: 0.108619; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1790 0.1363 0.1209 0.1134 0.1059 0.1021 0.1000 0.0992 0.0982 0.0974 0.0972 0.0973 0.0973 0.0977 0.0979 0.0982 

[TRAIN] Epoch[5](45/1500); Loss: 0.109480; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2174 0.1674 0.1077 0.1104 0.1053 0.1028 0.0977 0.0941 0.0942 0.0935 0.0933 0.0932 0.0935 0.0940 0.0936 0.0936 

[TRAIN] Epoch[5](46/1500); Loss: 0.058825; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.0915 0.0942 0.0578 0.0604 0.0636 0.0582 0.0540 0.0516 0.0516 0.0515 0.0505 0.0506 0.0513 0.0516 0.0514 0.0514 

[TRAIN] Epoch[5](47/1500); Loss: 0.087749; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1562 0.1138 0.1022 0.1004 0.0960 0.0874 0.0802 0.0768 0.0755 0.0747 0.0741 0.0736 0.0735 0.0733 0.0732 0.0729 

[TRAIN] Epoch[5](48/1500); Loss: 0.063558; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.0930 0.0944 0.0674 0.0654 0.0642 0.0604 0.0585 0.0580 0.0572 0.0569 0.0564 0.0572 0.0566 0.0564 0.0567 0.0583 

[TRAIN] Epoch[5](49/1500); Loss: 0.102815; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2867 0.2172 0.1872 0.1278 0.0877 0.0787 0.0845 0.0778 0.0689 0.0635 0.0621 0.0611 0.0606 0.0602 0.0606 0.0604 

[TRAIN] Epoch[5](50/1500); Loss: 0.069008; Backpropagation: 0.0980 sec; Batch: 0.4323 sec
0.1068 0.0856 0.0718 0.0731 0.0690 0.0657 0.0633 0.0627 0.0627 0.0626 0.0624 0.0628 0.0632 0.0635 0.0640 0.0650 

[TRAIN] Epoch[5](51/1500); Loss: 0.150500; Backpropagation: 0.0959 sec; Batch: 0.4301 sec
0.1771 0.1625 0.1559 0.1538 0.1514 0.1490 0.1474 0.1465 0.1457 0.1452 0.1452 0.1454 0.1455 0.1455 0.1456 0.1464 

[TRAIN] Epoch[5](52/1500); Loss: 0.126847; Backpropagation: 0.0943 sec; Batch: 0.4283 sec
0.3246 0.2446 0.2116 0.1423 0.1059 0.1007 0.0989 0.0937 0.0900 0.0889 0.0882 0.0877 0.0881 0.0882 0.0879 0.0883 

[TRAIN] Epoch[5](53/1500); Loss: 0.052386; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.0921 0.0818 0.0559 0.0577 0.0508 0.0463 0.0447 0.0453 0.0452 0.0443 0.0451 0.0448 0.0454 0.0457 0.0464 0.0467 

[TRAIN] Epoch[5](54/1500); Loss: 0.047785; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1644 0.0814 0.0531 0.0618 0.0442 0.0374 0.0340 0.0356 0.0339 0.0314 0.0310 0.0316 0.0306 0.0309 0.0313 0.0320 

[TRAIN] Epoch[5](55/1500); Loss: 0.071755; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1385 0.1089 0.0901 0.0782 0.0749 0.0711 0.0656 0.0619 0.0602 0.0587 0.0579 0.0571 0.0565 0.0564 0.0559 0.0561 

[TRAIN] Epoch[5](56/1500); Loss: 0.121215; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1946 0.1643 0.1530 0.1379 0.1264 0.1152 0.1087 0.1081 0.1070 0.1055 0.1040 0.1032 0.1033 0.1032 0.1027 0.1022 

[TRAIN] Epoch[5](57/1500); Loss: 0.125579; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.2068 0.1607 0.1464 0.1268 0.1185 0.1200 0.1185 0.1161 0.1145 0.1129 0.1123 0.1118 0.1110 0.1108 0.1108 0.1114 

[TRAIN] Epoch[5](58/1500); Loss: 0.073864; Backpropagation: 0.0932 sec; Batch: 0.4286 sec
0.1262 0.0979 0.0808 0.0851 0.0758 0.0703 0.0672 0.0656 0.0645 0.0636 0.0636 0.0636 0.0639 0.0642 0.0643 0.0653 

[TRAIN] Epoch[5](59/1500); Loss: 0.045003; Backpropagation: 0.0935 sec; Batch: 0.4420 sec
0.0867 0.0851 0.0465 0.0405 0.0382 0.0372 0.0369 0.0359 0.0363 0.0368 0.0376 0.0377 0.0393 0.0406 0.0414 0.0432 

[TRAIN] Epoch[5](60/1500); Loss: 0.123818; Backpropagation: 0.0938 sec; Batch: 0.4382 sec
0.1808 0.1518 0.1412 0.1322 0.1256 0.1210 0.1182 0.1158 0.1138 0.1128 0.1122 0.1117 0.1113 0.1109 0.1109 0.1109 

[TRAIN] Epoch[5](61/1500); Loss: 0.074730; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1045 0.1164 0.0727 0.0789 0.0821 0.0736 0.0689 0.0667 0.0671 0.0671 0.0662 0.0659 0.0664 0.0664 0.0664 0.0665 

[TRAIN] Epoch[5](62/1500); Loss: 0.133792; Backpropagation: 0.0933 sec; Batch: 0.4292 sec
0.2671 0.2189 0.2003 0.1698 0.1417 0.1218 0.1096 0.1071 0.1038 0.1014 0.1004 0.1000 0.0996 0.0996 0.0998 0.0999 

[TRAIN] Epoch[5](63/1500); Loss: 0.109711; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2132 0.1619 0.1405 0.1157 0.1060 0.1005 0.0963 0.0939 0.0928 0.0917 0.0911 0.0910 0.0905 0.0903 0.0900 0.0902 

[TRAIN] Epoch[5](64/1500); Loss: 0.162837; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2560 0.2237 0.2033 0.1786 0.1640 0.1550 0.1496 0.1466 0.1445 0.1429 0.1415 0.1409 0.1404 0.1403 0.1394 0.1388 

[TRAIN] Epoch[5](65/1500); Loss: 0.047714; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.0814 0.0913 0.0471 0.0529 0.0526 0.0444 0.0407 0.0391 0.0383 0.0387 0.0384 0.0397 0.0390 0.0396 0.0401 0.0402 

[TRAIN] Epoch[5](66/1500); Loss: 0.095144; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2205 0.1484 0.1161 0.0773 0.0914 0.0849 0.0780 0.0761 0.0757 0.0774 0.0779 0.0779 0.0788 0.0796 0.0808 0.0817 

[TRAIN] Epoch[5](67/1500); Loss: 0.039767; Backpropagation: 0.0982 sec; Batch: 0.4338 sec
0.0538 0.0645 0.0394 0.0392 0.0384 0.0380 0.0360 0.0353 0.0357 0.0361 0.0357 0.0357 0.0365 0.0371 0.0371 0.0379 

[TRAIN] Epoch[5](68/1500); Loss: 0.047290; Backpropagation: 0.0957 sec; Batch: 0.4298 sec
0.1017 0.0732 0.0676 0.0530 0.0487 0.0448 0.0396 0.0375 0.0363 0.0368 0.0358 0.0348 0.0367 0.0357 0.0370 0.0375 

[TRAIN] Epoch[5](69/1500); Loss: 0.088094; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1563 0.1342 0.1095 0.0991 0.0906 0.0838 0.0801 0.0770 0.0757 0.0745 0.0730 0.0720 0.0713 0.0713 0.0707 0.0704 

[TRAIN] Epoch[5](70/1500); Loss: 0.077371; Backpropagation: 0.0938 sec; Batch: 0.4459 sec
0.1425 0.1042 0.0888 0.0894 0.0785 0.0727 0.0693 0.0685 0.0674 0.0664 0.0656 0.0652 0.0649 0.0649 0.0649 0.0648 

[TRAIN] Epoch[5](71/1500); Loss: 0.167377; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.2299 0.2024 0.1773 0.1673 0.1618 0.1598 0.1594 0.1601 0.1590 0.1569 0.1563 0.1574 0.1585 0.1581 0.1570 0.1569 

[TRAIN] Epoch[5](72/1500); Loss: 0.063929; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1595 0.1336 0.0881 0.0633 0.0651 0.0589 0.0523 0.0485 0.0458 0.0449 0.0436 0.0430 0.0441 0.0435 0.0442 0.0444 

[TRAIN] Epoch[5](73/1500); Loss: 0.061253; Backpropagation: 0.0959 sec; Batch: 0.4357 sec
0.1915 0.1146 0.0865 0.0728 0.0660 0.0586 0.0483 0.0433 0.0409 0.0388 0.0371 0.0367 0.0368 0.0360 0.0358 0.0365 

[TRAIN] Epoch[5](74/1500); Loss: 0.085706; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1287 0.1106 0.0895 0.0902 0.0863 0.0825 0.0806 0.0798 0.0786 0.0779 0.0779 0.0778 0.0777 0.0777 0.0779 0.0775 

[TRAIN] Epoch[5](75/1500); Loss: 0.103760; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1679 0.1267 0.1297 0.1078 0.1004 0.0982 0.0958 0.0940 0.0931 0.0929 0.0924 0.0920 0.0922 0.0920 0.0923 0.0927 

[TRAIN] Epoch[5](76/1500); Loss: 0.105123; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1579 0.1282 0.1143 0.1088 0.1027 0.1002 0.0986 0.0977 0.0970 0.0965 0.0969 0.0964 0.0964 0.0965 0.0970 0.0970 

[TRAIN] Epoch[5](77/1500); Loss: 0.138083; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2526 0.1937 0.1710 0.1389 0.1302 0.1278 0.1239 0.1216 0.1203 0.1202 0.1191 0.1184 0.1179 0.1182 0.1177 0.1179 

[TRAIN] Epoch[5](78/1500); Loss: 0.108356; Backpropagation: 0.0930 sec; Batch: 0.4268 sec
0.1532 0.1261 0.1187 0.1180 0.1098 0.1038 0.1029 0.1026 0.1012 0.1007 0.1003 0.0999 0.0998 0.0987 0.0990 0.0990 

[TRAIN] Epoch[5](79/1500); Loss: 0.071541; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1249 0.1050 0.0790 0.0731 0.0681 0.0650 0.0637 0.0634 0.0631 0.0627 0.0625 0.0626 0.0626 0.0629 0.0628 0.0633 

[TRAIN] Epoch[5](80/1500); Loss: 0.126170; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2399 0.1959 0.1725 0.1391 0.1164 0.1087 0.1065 0.1052 0.1052 0.1046 0.1042 0.1042 0.1041 0.1040 0.1040 0.1043 

[TRAIN] Epoch[5](81/1500); Loss: 0.111470; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2054 0.1637 0.1406 0.1258 0.1061 0.0979 0.0963 0.0950 0.0946 0.0944 0.0938 0.0935 0.0940 0.0941 0.0940 0.0944 

[TRAIN] Epoch[5](82/1500); Loss: 0.166006; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2566 0.2004 0.1835 0.1687 0.1617 0.1595 0.1572 0.1546 0.1535 0.1526 0.1519 0.1515 0.1513 0.1510 0.1509 0.1510 

[TRAIN] Epoch[5](83/1500); Loss: 0.082770; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1463 0.1218 0.1041 0.0906 0.0842 0.0782 0.0749 0.0732 0.0712 0.0701 0.0693 0.0682 0.0679 0.0681 0.0680 0.0683 

[TRAIN] Epoch[5](84/1500); Loss: 0.089108; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1555 0.1278 0.0992 0.0888 0.0844 0.0815 0.0805 0.0792 0.0786 0.0785 0.0787 0.0784 0.0783 0.0786 0.0789 0.0788 

[TRAIN] Epoch[5](85/1500); Loss: 0.123307; Backpropagation: 0.0980 sec; Batch: 0.4325 sec
0.3542 0.2836 0.2496 0.1817 0.1243 0.0813 0.0751 0.0682 0.0692 0.0687 0.0689 0.0673 0.0703 0.0702 0.0705 0.0699 

[TRAIN] Epoch[5](86/1500); Loss: 0.137406; Backpropagation: 0.0981 sec; Batch: 0.4321 sec
0.2558 0.1954 0.1674 0.1338 0.1249 0.1225 0.1207 0.1195 0.1199 0.1196 0.1191 0.1192 0.1196 0.1200 0.1202 0.1208 

[TRAIN] Epoch[5](87/1500); Loss: 0.066643; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.0815 0.0739 0.0670 0.0663 0.0652 0.0647 0.0630 0.0639 0.0639 0.0641 0.0633 0.0652 0.0651 0.0662 0.0658 0.0672 

[TRAIN] Epoch[5](88/1500); Loss: 0.071942; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1516 0.1304 0.1011 0.0830 0.0715 0.0624 0.0568 0.0559 0.0549 0.0547 0.0539 0.0542 0.0546 0.0551 0.0551 0.0559 

[TRAIN] Epoch[5](89/1500); Loss: 0.103172; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2357 0.1994 0.1411 0.1163 0.0962 0.0848 0.0823 0.0803 0.0780 0.0775 0.0777 0.0771 0.0763 0.0761 0.0761 0.0758 

[TRAIN] Epoch[5](90/1500); Loss: 0.087120; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.2294 0.1490 0.1198 0.0864 0.0721 0.0681 0.0668 0.0658 0.0653 0.0653 0.0658 0.0663 0.0670 0.0681 0.0689 0.0699 

[TRAIN] Epoch[5](91/1500); Loss: 0.063499; Backpropagation: 0.0943 sec; Batch: 0.4289 sec
0.0959 0.0877 0.0682 0.0655 0.0615 0.0596 0.0584 0.0581 0.0575 0.0573 0.0577 0.0575 0.0577 0.0575 0.0578 0.0580 

[TRAIN] Epoch[5](92/1500); Loss: 0.147197; Backpropagation: 0.0936 sec; Batch: 0.4674 sec
0.2216 0.1846 0.1635 0.1504 0.1426 0.1388 0.1368 0.1359 0.1360 0.1358 0.1353 0.1353 0.1352 0.1347 0.1343 0.1345 

[TRAIN] Epoch[5](93/1500); Loss: 0.105045; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1699 0.1262 0.1190 0.1051 0.1015 0.0995 0.0984 0.0976 0.0964 0.0964 0.0958 0.0954 0.0952 0.0949 0.0947 0.0947 

[TRAIN] Epoch[5](94/1500); Loss: 0.073613; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1666 0.1030 0.0839 0.0801 0.0678 0.0650 0.0626 0.0624 0.0610 0.0606 0.0606 0.0605 0.0606 0.0609 0.0609 0.0613 

[TRAIN] Epoch[5](95/1500); Loss: 0.154606; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2357 0.1981 0.1816 0.1618 0.1502 0.1452 0.1447 0.1425 0.1417 0.1410 0.1400 0.1392 0.1388 0.1381 0.1376 0.1375 

[TRAIN] Epoch[5](96/1500); Loss: 0.107068; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1960 0.1440 0.1238 0.1205 0.1065 0.1015 0.0981 0.0966 0.0945 0.0927 0.0922 0.0910 0.0898 0.0891 0.0885 0.0882 

[TRAIN] Epoch[5](97/1500); Loss: 0.137393; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2903 0.2139 0.1815 0.1380 0.1212 0.1177 0.1148 0.1142 0.1135 0.1135 0.1134 0.1128 0.1128 0.1130 0.1139 0.1138 

[TRAIN] Epoch[5](98/1500); Loss: 0.099475; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1322 0.1082 0.1022 0.0988 0.0978 0.0992 0.0977 0.0948 0.0948 0.0962 0.0953 0.0948 0.0953 0.0951 0.0946 0.0945 

[TRAIN] Epoch[5](99/1500); Loss: 0.068936; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0901 0.0919 0.0734 0.0703 0.0676 0.0637 0.0647 0.0635 0.0633 0.0631 0.0635 0.0647 0.0643 0.0649 0.0660 0.0680 

[TRAIN] Epoch[5](100/1500); Loss: 0.104331; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1586 0.1312 0.1112 0.1037 0.0988 0.0969 0.0970 0.0963 0.0964 0.0963 0.0968 0.0969 0.0966 0.0970 0.0977 0.0980 

[TRAIN] Epoch[5](101/1500); Loss: 0.102806; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2335 0.1652 0.1399 0.0995 0.0948 0.0889 0.0857 0.0841 0.0825 0.0810 0.0812 0.0815 0.0812 0.0814 0.0824 0.0820 

[TRAIN] Epoch[5](102/1500); Loss: 0.121397; Backpropagation: 0.0980 sec; Batch: 0.4332 sec
0.1879 0.1497 0.1355 0.1247 0.1180 0.1147 0.1148 0.1141 0.1130 0.1110 0.1104 0.1103 0.1095 0.1094 0.1096 0.1097 

[TRAIN] Epoch[5](103/1500); Loss: 0.116006; Backpropagation: 0.0958 sec; Batch: 0.4298 sec
0.3679 0.2557 0.1860 0.0844 0.1128 0.0916 0.0770 0.0742 0.0731 0.0727 0.0745 0.0763 0.0762 0.0769 0.0778 0.0790 

[TRAIN] Epoch[5](104/1500); Loss: 0.141266; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.2924 0.2247 0.1844 0.1449 0.1261 0.1262 0.1221 0.1187 0.1164 0.1159 0.1154 0.1148 0.1148 0.1146 0.1143 0.1145 

[TRAIN] Epoch[5](105/1500); Loss: 0.097274; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.2101 0.1435 0.1080 0.0973 0.0885 0.0849 0.0835 0.0819 0.0811 0.0813 0.0812 0.0822 0.0821 0.0829 0.0837 0.0841 

[TRAIN] Epoch[5](106/1500); Loss: 0.084252; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2236 0.1440 0.1000 0.0856 0.0814 0.0732 0.0669 0.0652 0.0632 0.0628 0.0621 0.0630 0.0634 0.0637 0.0640 0.0659 

[TRAIN] Epoch[5](107/1500); Loss: 0.131382; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2315 0.1903 0.1515 0.1294 0.1190 0.1177 0.1155 0.1151 0.1154 0.1158 0.1153 0.1166 0.1166 0.1168 0.1176 0.1180 

[TRAIN] Epoch[5](108/1500); Loss: 0.108294; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1749 0.1457 0.1199 0.1061 0.1033 0.1002 0.0987 0.0983 0.0981 0.0976 0.0973 0.0977 0.0984 0.0987 0.0991 0.0989 

[TRAIN] Epoch[5](109/1500); Loss: 0.098902; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2378 0.1543 0.1002 0.1052 0.0957 0.0894 0.0822 0.0791 0.0792 0.0780 0.0790 0.0793 0.0804 0.0811 0.0809 0.0808 

[TRAIN] Epoch[5](110/1500); Loss: 0.108005; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1793 0.1478 0.1228 0.1205 0.1129 0.1058 0.0997 0.0968 0.0954 0.0935 0.0924 0.0921 0.0926 0.0925 0.0918 0.0921 

[TRAIN] Epoch[5](111/1500); Loss: 0.075056; Backpropagation: 0.0937 sec; Batch: 0.4395 sec
0.1846 0.1174 0.0867 0.0753 0.0706 0.0657 0.0620 0.0616 0.0606 0.0596 0.0593 0.0594 0.0594 0.0591 0.0598 0.0598 

[TRAIN] Epoch[5](112/1500); Loss: 0.106938; Backpropagation: 0.0937 sec; Batch: 0.4701 sec
0.1838 0.1551 0.1290 0.1107 0.0998 0.0968 0.0953 0.0938 0.0933 0.0927 0.0931 0.0934 0.0929 0.0932 0.0940 0.0942 

[TRAIN] Epoch[5](113/1500); Loss: 0.134444; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1626 0.1441 0.1354 0.1353 0.1328 0.1317 0.1315 0.1301 0.1296 0.1296 0.1301 0.1313 0.1315 0.1314 0.1316 0.1327 

[TRAIN] Epoch[5](114/1500); Loss: 0.144891; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2201 0.1897 0.1598 0.1443 0.1444 0.1415 0.1373 0.1344 0.1324 0.1317 0.1307 0.1305 0.1310 0.1304 0.1301 0.1300 

[TRAIN] Epoch[5](115/1500); Loss: 0.141613; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.2531 0.1968 0.1623 0.1344 0.1335 0.1307 0.1281 0.1271 0.1263 0.1254 0.1248 0.1251 0.1251 0.1248 0.1245 0.1237 

[TRAIN] Epoch[5](116/1500); Loss: 0.113647; Backpropagation: 0.0936 sec; Batch: 0.4292 sec
0.2521 0.1742 0.1368 0.1139 0.1159 0.1053 0.0946 0.0911 0.0932 0.0915 0.0905 0.0902 0.0915 0.0919 0.0925 0.0932 

[TRAIN] Epoch[5](117/1500); Loss: 0.058685; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.0662 0.0660 0.0640 0.0583 0.0564 0.0555 0.0552 0.0542 0.0565 0.0563 0.0555 0.0566 0.0579 0.0602 0.0604 0.0598 

[TRAIN] Epoch[5](118/1500); Loss: 0.106665; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.3930 0.2573 0.1458 0.0602 0.0576 0.0611 0.0653 0.0655 0.0682 0.0702 0.0718 0.0748 0.0768 0.0783 0.0795 0.0812 

[TRAIN] Epoch[5](119/1500); Loss: 0.076334; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2880 0.1554 0.0796 0.0923 0.0709 0.0572 0.0486 0.0480 0.0465 0.0457 0.0476 0.0468 0.0471 0.0485 0.0499 0.0494 

[TRAIN] Epoch[5](120/1500); Loss: 0.113031; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1333 0.1381 0.1179 0.1186 0.1155 0.1109 0.1086 0.1089 0.1082 0.1073 0.1067 0.1070 0.1073 0.1069 0.1066 0.1067 

[TRAIN] Epoch[5](121/1500); Loss: 0.079376; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.2273 0.1441 0.0939 0.0757 0.0750 0.0678 0.0613 0.0586 0.0586 0.0576 0.0570 0.0572 0.0587 0.0588 0.0592 0.0592 

[TRAIN] Epoch[5](122/1500); Loss: 0.077163; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1667 0.1077 0.0857 0.0877 0.0762 0.0697 0.0688 0.0674 0.0644 0.0633 0.0629 0.0625 0.0621 0.0626 0.0632 0.0637 

[TRAIN] Epoch[5](123/1500); Loss: 0.077838; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2219 0.1498 0.1007 0.0849 0.0762 0.0696 0.0587 0.0554 0.0548 0.0525 0.0530 0.0533 0.0531 0.0535 0.0536 0.0544 

[TRAIN] Epoch[5](124/1500); Loss: 0.094042; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1467 0.1117 0.0989 0.0955 0.0910 0.0896 0.0895 0.0882 0.0875 0.0865 0.0861 0.0867 0.0861 0.0862 0.0870 0.0874 

[TRAIN] Epoch[5](125/1500); Loss: 0.041443; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1479 0.0664 0.0438 0.0262 0.0320 0.0314 0.0295 0.0287 0.0295 0.0296 0.0314 0.0311 0.0319 0.0335 0.0343 0.0356 

[TRAIN] Epoch[5](126/1500); Loss: 0.049378; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.0782 0.0553 0.0687 0.0482 0.0449 0.0460 0.0439 0.0436 0.0419 0.0435 0.0458 0.0446 0.0449 0.0462 0.0473 0.0472 

[TRAIN] Epoch[5](127/1500); Loss: 0.098649; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.3879 0.2502 0.1362 0.0618 0.0557 0.0552 0.0584 0.0592 0.0612 0.0615 0.0624 0.0634 0.0657 0.0659 0.0665 0.0673 

[TRAIN] Epoch[5](128/1500); Loss: 0.114478; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1924 0.1584 0.1225 0.1168 0.1129 0.1083 0.1058 0.1050 0.1047 0.1030 0.1013 0.1003 0.1006 0.1008 0.1000 0.0991 

[TRAIN] Epoch[5](129/1500); Loss: 0.068550; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1159 0.0841 0.0751 0.0731 0.0674 0.0656 0.0640 0.0621 0.0610 0.0609 0.0601 0.0599 0.0611 0.0622 0.0618 0.0626 

[TRAIN] Epoch[5](130/1500); Loss: 0.114080; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1593 0.1403 0.1231 0.1209 0.1145 0.1109 0.1079 0.1070 0.1065 0.1062 0.1060 0.1045 0.1042 0.1043 0.1048 0.1049 

[TRAIN] Epoch[5](131/1500); Loss: 0.119080; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1624 0.1355 0.1227 0.1303 0.1241 0.1195 0.1153 0.1132 0.1122 0.1110 0.1100 0.1099 0.1103 0.1103 0.1096 0.1090 

[TRAIN] Epoch[5](132/1500); Loss: 0.132185; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.2354 0.1783 0.1401 0.1307 0.1273 0.1226 0.1195 0.1183 0.1183 0.1178 0.1172 0.1175 0.1183 0.1184 0.1177 0.1175 

[TRAIN] Epoch[5](133/1500); Loss: 0.126112; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1887 0.1644 0.1408 0.1264 0.1220 0.1193 0.1173 0.1169 0.1171 0.1165 0.1154 0.1143 0.1143 0.1146 0.1148 0.1148 

[TRAIN] Epoch[5](134/1500); Loss: 0.120309; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1632 0.1467 0.1360 0.1236 0.1174 0.1137 0.1123 0.1118 0.1124 0.1122 0.1123 0.1125 0.1121 0.1123 0.1128 0.1136 

[TRAIN] Epoch[5](135/1500); Loss: 0.090250; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1373 0.1298 0.0963 0.0930 0.0894 0.0843 0.0828 0.0824 0.0816 0.0808 0.0808 0.0813 0.0812 0.0806 0.0809 0.0816 

[TRAIN] Epoch[5](136/1500); Loss: 0.139689; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2035 0.1750 0.1504 0.1404 0.1366 0.1351 0.1331 0.1312 0.1298 0.1289 0.1286 0.1288 0.1288 0.1285 0.1281 0.1282 

[TRAIN] Epoch[5](137/1500); Loss: 0.045572; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.0809 0.0743 0.0645 0.0497 0.0434 0.0405 0.0386 0.0382 0.0384 0.0376 0.0361 0.0361 0.0368 0.0378 0.0382 0.0379 

[TRAIN] Epoch[5](138/1500); Loss: 0.071103; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1643 0.0991 0.0767 0.0796 0.0690 0.0628 0.0612 0.0607 0.0585 0.0576 0.0574 0.0573 0.0578 0.0582 0.0588 0.0585 

[TRAIN] Epoch[5](139/1500); Loss: 0.082824; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1620 0.1106 0.0824 0.0959 0.0867 0.0806 0.0750 0.0722 0.0697 0.0691 0.0696 0.0705 0.0698 0.0697 0.0701 0.0714 

[TRAIN] Epoch[5](140/1500); Loss: 0.067038; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.0795 0.0799 0.0731 0.0690 0.0665 0.0641 0.0622 0.0623 0.0636 0.0636 0.0623 0.0633 0.0639 0.0654 0.0674 0.0666 

[TRAIN] Epoch[5](141/1500); Loss: 0.134717; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.2248 0.1848 0.1510 0.1304 0.1287 0.1257 0.1232 0.1229 0.1230 0.1216 0.1204 0.1200 0.1202 0.1202 0.1191 0.1194 

[TRAIN] Epoch[5](142/1500); Loss: 0.102408; Backpropagation: 0.0938 sec; Batch: 0.4360 sec
0.1491 0.1242 0.1047 0.1169 0.1105 0.1038 0.0979 0.0945 0.0937 0.0931 0.0920 0.0916 0.0915 0.0914 0.0917 0.0919 

[TRAIN] Epoch[5](143/1500); Loss: 0.060162; Backpropagation: 0.0939 sec; Batch: 0.4712 sec
0.0975 0.0735 0.0641 0.0602 0.0568 0.0551 0.0552 0.0556 0.0548 0.0545 0.0547 0.0548 0.0558 0.0559 0.0567 0.0575 

[TRAIN] Epoch[5](144/1500); Loss: 0.069538; Backpropagation: 0.0937 sec; Batch: 0.4658 sec
0.1230 0.1136 0.0746 0.0712 0.0651 0.0633 0.0616 0.0610 0.0604 0.0600 0.0600 0.0600 0.0595 0.0595 0.0598 0.0600 

[TRAIN] Epoch[5](145/1500); Loss: 0.094612; Backpropagation: 0.0937 sec; Batch: 0.4295 sec
0.1297 0.1131 0.1028 0.0949 0.0939 0.0924 0.0913 0.0901 0.0887 0.0882 0.0877 0.0878 0.0883 0.0882 0.0882 0.0886 

[TRAIN] Epoch[5](146/1500); Loss: 0.101162; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2517 0.1682 0.1241 0.1036 0.0970 0.0941 0.0881 0.0830 0.0796 0.0778 0.0764 0.0757 0.0750 0.0750 0.0746 0.0745 

[TRAIN] Epoch[5](147/1500); Loss: 0.098365; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1957 0.1357 0.1246 0.1186 0.1064 0.0992 0.0914 0.0854 0.0812 0.0785 0.0773 0.0769 0.0762 0.0757 0.0755 0.0756 

[TRAIN] Epoch[5](148/1500); Loss: 0.040640; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.0637 0.0652 0.0579 0.0418 0.0430 0.0411 0.0380 0.0357 0.0343 0.0336 0.0332 0.0323 0.0318 0.0327 0.0328 0.0330 

[TRAIN] Epoch[5](149/1500); Loss: 0.166847; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.2616 0.1995 0.1633 0.1653 0.1605 0.1648 0.1601 0.1567 0.1540 0.1535 0.1549 0.1550 0.1543 0.1547 0.1555 0.1556 

[TRAIN] Epoch[5](150/1500); Loss: 0.129266; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1543 0.1503 0.1375 0.1332 0.1310 0.1303 0.1279 0.1248 0.1237 0.1234 0.1236 0.1227 0.1213 0.1209 0.1217 0.1216 

[TRAIN] Epoch[5](151/1500); Loss: 0.133654; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2065 0.1575 0.1343 0.1344 0.1306 0.1282 0.1278 0.1277 0.1263 0.1248 0.1242 0.1235 0.1234 0.1232 0.1233 0.1228 

[TRAIN] Epoch[5](152/1500); Loss: 0.114223; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1491 0.1288 0.1230 0.1157 0.1161 0.1132 0.1107 0.1094 0.1083 0.1081 0.1080 0.1078 0.1077 0.1074 0.1072 0.1071 

[TRAIN] Epoch[5](153/1500); Loss: 0.113899; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2393 0.1547 0.1144 0.1296 0.1194 0.1121 0.1031 0.0974 0.0955 0.0944 0.0937 0.0939 0.0936 0.0937 0.0937 0.0939 

[TRAIN] Epoch[5](154/1500); Loss: 0.144698; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1811 0.1568 0.1478 0.1468 0.1428 0.1409 0.1406 0.1408 0.1405 0.1399 0.1393 0.1392 0.1393 0.1394 0.1397 0.1401 

[TRAIN] Epoch[5](155/1500); Loss: 0.097978; Backpropagation: 0.0942 sec; Batch: 0.4282 sec
0.2392 0.1652 0.1128 0.0943 0.0909 0.0842 0.0790 0.0794 0.0774 0.0777 0.0776 0.0774 0.0776 0.0775 0.0782 0.0791 

[TRAIN] Epoch[5](156/1500); Loss: 0.092780; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.2220 0.1449 0.0919 0.1108 0.1004 0.0926 0.0820 0.0750 0.0722 0.0719 0.0707 0.0701 0.0705 0.0699 0.0698 0.0698 

[TRAIN] Epoch[5](157/1500); Loss: 0.084865; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.1672 0.1261 0.0895 0.0921 0.0870 0.0820 0.0772 0.0740 0.0722 0.0711 0.0710 0.0704 0.0696 0.0693 0.0694 0.0699 

[TRAIN] Epoch[5](158/1500); Loss: 0.154352; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.2354 0.1916 0.1689 0.1558 0.1508 0.1478 0.1451 0.1436 0.1435 0.1433 0.1421 0.1407 0.1404 0.1407 0.1404 0.1395 

[TRAIN] Epoch[5](159/1500); Loss: 0.049542; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.0529 0.0950 0.0602 0.0482 0.0497 0.0469 0.0452 0.0446 0.0444 0.0434 0.0432 0.0435 0.0439 0.0434 0.0438 0.0443 

[TRAIN] Epoch[5](160/1500); Loss: 0.058132; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.0750 0.1195 0.0738 0.0552 0.0587 0.0548 0.0519 0.0501 0.0486 0.0484 0.0484 0.0487 0.0493 0.0494 0.0492 0.0492 

[TRAIN] Epoch[5](161/1500); Loss: 0.125534; Backpropagation: 0.0983 sec; Batch: 0.4338 sec
0.2059 0.1594 0.1352 0.1292 0.1271 0.1237 0.1191 0.1154 0.1131 0.1119 0.1115 0.1115 0.1117 0.1116 0.1111 0.1112 

[TRAIN] Epoch[5](162/1500); Loss: 0.073603; Backpropagation: 0.0981 sec; Batch: 0.4333 sec
0.0863 0.0978 0.0801 0.0759 0.0751 0.0722 0.0699 0.0693 0.0695 0.0689 0.0682 0.0676 0.0677 0.0686 0.0700 0.0705 

[TRAIN] Epoch[5](163/1500); Loss: 0.123795; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.2303 0.1835 0.1480 0.1210 0.1224 0.1180 0.1123 0.1073 0.1043 0.1038 0.1049 0.1049 0.1046 0.1047 0.1052 0.1056 

[TRAIN] Epoch[5](164/1500); Loss: 0.097579; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.2743 0.1769 0.1147 0.0884 0.0949 0.0913 0.0840 0.0773 0.0728 0.0706 0.0701 0.0703 0.0692 0.0688 0.0687 0.0687 

[TRAIN] Epoch[5](165/1500); Loss: 0.122719; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2108 0.1522 0.1346 0.1299 0.1241 0.1177 0.1149 0.1125 0.1111 0.1091 0.1078 0.1081 0.1083 0.1082 0.1070 0.1072 

[TRAIN] Epoch[5](166/1500); Loss: 0.093837; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1287 0.1198 0.1082 0.1057 0.1006 0.0949 0.0908 0.0883 0.0862 0.0838 0.0830 0.0826 0.0827 0.0823 0.0820 0.0818 

[TRAIN] Epoch[5](167/1500); Loss: 0.103238; Backpropagation: 0.0943 sec; Batch: 0.4289 sec
0.1959 0.1302 0.1072 0.1111 0.1022 0.0966 0.0923 0.0910 0.0913 0.0911 0.0905 0.0901 0.0902 0.0909 0.0907 0.0906 

[TRAIN] Epoch[5](168/1500); Loss: 0.086597; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.2015 0.1215 0.0759 0.0962 0.0874 0.0825 0.0779 0.0736 0.0716 0.0710 0.0710 0.0713 0.0709 0.0709 0.0709 0.0713 

[TRAIN] Epoch[5](169/1500); Loss: 0.102672; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1395 0.1196 0.1097 0.1097 0.1027 0.0999 0.0982 0.0971 0.0965 0.0965 0.0966 0.0959 0.0954 0.0952 0.0951 0.0952 

[TRAIN] Epoch[5](170/1500); Loss: 0.122308; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1692 0.1512 0.1318 0.1200 0.1210 0.1165 0.1151 0.1142 0.1137 0.1139 0.1138 0.1145 0.1149 0.1150 0.1156 0.1164 

[TRAIN] Epoch[5](171/1500); Loss: 0.104828; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1292 0.1260 0.1100 0.1080 0.1048 0.1028 0.1012 0.0999 0.0998 0.1000 0.0998 0.0992 0.0991 0.0992 0.0991 0.0992 

[TRAIN] Epoch[5](172/1500); Loss: 0.081132; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1692 0.1833 0.1186 0.0806 0.0669 0.0657 0.0634 0.0620 0.0614 0.0607 0.0603 0.0611 0.0612 0.0613 0.0610 0.0614 

[TRAIN] Epoch[5](173/1500); Loss: 0.085524; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1848 0.1146 0.0965 0.0942 0.0821 0.0813 0.0776 0.0741 0.0721 0.0709 0.0705 0.0700 0.0697 0.0701 0.0699 0.0701 

[TRAIN] Epoch[5](174/1500); Loss: 0.110226; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1541 0.1384 0.1194 0.1219 0.1149 0.1108 0.1067 0.1038 0.1017 0.1008 0.0996 0.0989 0.0985 0.0981 0.0983 0.0977 

[TRAIN] Epoch[5](175/1500); Loss: 0.069877; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.0928 0.0820 0.0769 0.0743 0.0697 0.0676 0.0669 0.0661 0.0653 0.0653 0.0650 0.0650 0.0653 0.0656 0.0652 0.0651 

[TRAIN] Epoch[5](176/1500); Loss: 0.098204; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.2025 0.1228 0.1014 0.1188 0.1050 0.0971 0.0890 0.0853 0.0837 0.0822 0.0809 0.0804 0.0809 0.0806 0.0803 0.0802 

[TRAIN] Epoch[5](177/1500); Loss: 0.119072; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1536 0.1430 0.1290 0.1268 0.1203 0.1172 0.1149 0.1137 0.1126 0.1116 0.1110 0.1105 0.1104 0.1102 0.1102 0.1102 

[TRAIN] Epoch[5](178/1500); Loss: 0.050080; Backpropagation: 0.0956 sec; Batch: 0.4329 sec
0.0644 0.0669 0.0603 0.0507 0.0475 0.0441 0.0450 0.0465 0.0460 0.0448 0.0445 0.0476 0.0487 0.0483 0.0478 0.0482 

[TRAIN] Epoch[5](179/1500); Loss: 0.078017; Backpropagation: 0.0958 sec; Batch: 0.4309 sec
0.2233 0.1452 0.0903 0.0852 0.0766 0.0703 0.0637 0.0598 0.0580 0.0553 0.0540 0.0537 0.0535 0.0533 0.0531 0.0528 

[TRAIN] Epoch[5](180/1500); Loss: 0.139604; Backpropagation: 0.0946 sec; Batch: 0.4287 sec
0.2358 0.2016 0.1708 0.1416 0.1309 0.1284 0.1256 0.1236 0.1229 0.1226 0.1226 0.1223 0.1216 0.1211 0.1211 0.1212 

[TRAIN] Epoch[5](181/1500); Loss: 0.138684; Backpropagation: 0.0938 sec; Batch: 0.4534 sec
0.1800 0.1567 0.1575 0.1418 0.1341 0.1323 0.1303 0.1298 0.1307 0.1316 0.1319 0.1325 0.1322 0.1323 0.1326 0.1324 

[TRAIN] Epoch[5](182/1500); Loss: 0.111982; Backpropagation: 0.0932 sec; Batch: 0.4265 sec
0.2121 0.1520 0.1117 0.1196 0.1122 0.1075 0.1019 0.0981 0.0966 0.0967 0.0973 0.0978 0.0976 0.0972 0.0970 0.0965 

[TRAIN] Epoch[5](183/1500); Loss: 0.124153; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2197 0.1547 0.1239 0.1158 0.1132 0.1119 0.1128 0.1147 0.1161 0.1162 0.1148 0.1147 0.1150 0.1146 0.1146 0.1137 

[TRAIN] Epoch[5](184/1500); Loss: 0.073465; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.0909 0.0929 0.0918 0.0810 0.0713 0.0692 0.0679 0.0673 0.0671 0.0671 0.0673 0.0682 0.0683 0.0682 0.0684 0.0686 

[TRAIN] Epoch[5](185/1500); Loss: 0.089136; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1906 0.1284 0.0961 0.0848 0.0860 0.0846 0.0806 0.0782 0.0768 0.0748 0.0742 0.0741 0.0743 0.0739 0.0748 0.0740 

[TRAIN] Epoch[5](186/1500); Loss: 0.221602; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2747 0.2414 0.2266 0.2186 0.2157 0.2164 0.2168 0.2170 0.2170 0.2170 0.2163 0.2150 0.2140 0.2131 0.2132 0.2128 

[TRAIN] Epoch[5](187/1500); Loss: 0.099428; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1948 0.1224 0.0948 0.1146 0.1120 0.0975 0.0859 0.0834 0.0838 0.0852 0.0865 0.0869 0.0864 0.0860 0.0854 0.0850 

[TRAIN] Epoch[5](188/1500); Loss: 0.095953; Backpropagation: 0.0936 sec; Batch: 0.4272 sec
0.1427 0.1126 0.1021 0.0971 0.0930 0.0909 0.0894 0.0886 0.0889 0.0896 0.0903 0.0904 0.0898 0.0897 0.0898 0.0904 

[TRAIN] Epoch[5](189/1500); Loss: 0.113088; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1638 0.1202 0.1097 0.1164 0.1154 0.1116 0.1090 0.1070 0.1063 0.1069 0.1078 0.1088 0.1077 0.1065 0.1062 0.1060 

[TRAIN] Epoch[5](190/1500); Loss: 0.111057; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2091 0.1547 0.1223 0.1068 0.0998 0.0996 0.0983 0.0971 0.0964 0.0964 0.0967 0.0978 0.0989 0.1002 0.1013 0.1016 

[TRAIN] Epoch[5](191/1500); Loss: 0.075718; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1523 0.1026 0.0802 0.0729 0.0741 0.0759 0.0747 0.0716 0.0692 0.0658 0.0626 0.0614 0.0611 0.0616 0.0627 0.0629 

[TRAIN] Epoch[5](192/1500); Loss: 0.123632; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1595 0.1360 0.1293 0.1262 0.1247 0.1233 0.1216 0.1201 0.1189 0.1182 0.1177 0.1175 0.1171 0.1167 0.1164 0.1150 

[TRAIN] Epoch[5](193/1500); Loss: 0.099864; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2116 0.1451 0.1054 0.0947 0.0912 0.0892 0.0865 0.0843 0.0832 0.0829 0.0836 0.0849 0.0867 0.0885 0.0898 0.0903 

[TRAIN] Epoch[5](194/1500); Loss: 0.208511; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.3435 0.2855 0.2525 0.2240 0.1988 0.1895 0.1836 0.1821 0.1827 0.1845 0.1862 0.1872 0.1868 0.1851 0.1828 0.1814 

[TRAIN] Epoch[5](195/1500); Loss: 0.101899; Backpropagation: 0.0961 sec; Batch: 0.4303 sec
0.1268 0.1055 0.0995 0.0987 0.0978 0.0975 0.0976 0.0985 0.0995 0.1002 0.1009 0.1014 0.1020 0.1022 0.1015 0.1009 

[TRAIN] Epoch[5](196/1500); Loss: 0.068730; Backpropagation: 0.0940 sec; Batch: 0.4366 sec
0.1447 0.0719 0.0722 0.0771 0.0709 0.0672 0.0638 0.0609 0.0583 0.0567 0.0565 0.0572 0.0587 0.0606 0.0616 0.0613 

[TRAIN] Epoch[5](197/1500); Loss: 0.141507; Backpropagation: 0.0938 sec; Batch: 0.4301 sec
0.2322 0.1881 0.1530 0.1304 0.1281 0.1284 0.1283 0.1285 0.1287 0.1292 0.1298 0.1304 0.1313 0.1320 0.1328 0.1330 

[TRAIN] Epoch[5](198/1500); Loss: 0.136048; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1909 0.1531 0.1446 0.1465 0.1489 0.1435 0.1348 0.1263 0.1219 0.1212 0.1217 0.1231 0.1242 0.1248 0.1251 0.1261 

[TRAIN] Epoch[5](199/1500); Loss: 0.109871; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1905 0.1489 0.1235 0.1062 0.1023 0.1011 0.1003 0.0995 0.0990 0.0994 0.0986 0.0978 0.0974 0.0975 0.0975 0.0983 

[TRAIN] Epoch[5](200/1500); Loss: 0.126985; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1993 0.1614 0.1368 0.1303 0.1244 0.1221 0.1206 0.1199 0.1194 0.1184 0.1168 0.1150 0.1137 0.1126 0.1113 0.1098 

[TRAIN] Epoch[5](201/1500); Loss: 0.108024; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1952 0.1420 0.1171 0.1068 0.0994 0.0974 0.0967 0.0968 0.0975 0.0991 0.1002 0.0994 0.0973 0.0949 0.0943 0.0945 

[TRAIN] Epoch[5](202/1500); Loss: 0.139584; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2794 0.1950 0.1429 0.1201 0.1192 0.1183 0.1195 0.1213 0.1226 0.1237 0.1252 0.1268 0.1281 0.1293 0.1304 0.1315 

[TRAIN] Epoch[5](203/1500); Loss: 0.101690; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1390 0.1126 0.1044 0.1032 0.1007 0.0986 0.0978 0.0978 0.0978 0.0974 0.0967 0.0964 0.0961 0.0961 0.0962 0.0963 

[TRAIN] Epoch[5](204/1500); Loss: 0.063670; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1291 0.0923 0.0790 0.0713 0.0681 0.0646 0.0589 0.0535 0.0507 0.0492 0.0484 0.0487 0.0498 0.0510 0.0518 0.0523 

[TRAIN] Epoch[5](205/1500); Loss: 0.108325; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2565 0.1949 0.1559 0.1242 0.1024 0.0929 0.0868 0.0842 0.0825 0.0814 0.0804 0.0801 0.0800 0.0787 0.0768 0.0753 

[TRAIN] Epoch[5](206/1500); Loss: 0.173707; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2297 0.1986 0.1779 0.1708 0.1716 0.1735 0.1753 0.1737 0.1679 0.1635 0.1616 0.1621 0.1631 0.1637 0.1638 0.1625 

[TRAIN] Epoch[5](207/1500); Loss: 0.075542; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1652 0.1024 0.0790 0.0759 0.0726 0.0695 0.0668 0.0648 0.0635 0.0630 0.0633 0.0639 0.0643 0.0646 0.0649 0.0650 

[TRAIN] Epoch[5](208/1500); Loss: 0.144221; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1858 0.1599 0.1524 0.1470 0.1435 0.1420 0.1410 0.1404 0.1400 0.1395 0.1391 0.1383 0.1371 0.1356 0.1337 0.1323 

[TRAIN] Epoch[5](209/1500); Loss: 0.076093; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1949 0.1042 0.0764 0.0763 0.0709 0.0675 0.0643 0.0622 0.0610 0.0608 0.0612 0.0620 0.0633 0.0644 0.0649 0.0631 

[TRAIN] Epoch[5](210/1500); Loss: 0.057690; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.1152 0.0485 0.0631 0.0703 0.0634 0.0592 0.0556 0.0531 0.0511 0.0491 0.0475 0.0472 0.0477 0.0491 0.0510 0.0521 

[TRAIN] Epoch[5](211/1500); Loss: 0.139495; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2068 0.1701 0.1500 0.1415 0.1383 0.1358 0.1334 0.1316 0.1301 0.1290 0.1281 0.1275 0.1273 0.1273 0.1274 0.1277 

[TRAIN] Epoch[5](212/1500); Loss: 0.120122; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.2431 0.1878 0.1480 0.1170 0.1087 0.1057 0.1039 0.1035 0.1032 0.1024 0.1017 0.1021 0.1019 0.1009 0.0977 0.0943 

[TRAIN] Epoch[5](213/1500); Loss: 0.112603; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2594 0.1943 0.1485 0.0970 0.1127 0.1094 0.1067 0.0992 0.0908 0.0851 0.0833 0.0824 0.0825 0.0830 0.0837 0.0837 

[TRAIN] Epoch[5](214/1500); Loss: 0.153977; Backpropagation: 0.0940 sec; Batch: 0.4277 sec
0.2713 0.2148 0.1920 0.1797 0.1676 0.1595 0.1514 0.1444 0.1380 0.1324 0.1276 0.1235 0.1200 0.1167 0.1136 0.1111 

[TRAIN] Epoch[5](215/1500); Loss: 0.125810; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.2086 0.1706 0.1437 0.1260 0.1183 0.1145 0.1127 0.1123 0.1132 0.1148 0.1155 0.1150 0.1141 0.1123 0.1108 0.1106 

[TRAIN] Epoch[5](216/1500); Loss: 0.108224; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1655 0.1301 0.1104 0.1024 0.0997 0.0991 0.0995 0.1006 0.1014 0.1021 0.1028 0.1032 0.1036 0.1035 0.1038 0.1038 

[TRAIN] Epoch[5](217/1500); Loss: 0.183462; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2737 0.2441 0.2257 0.2066 0.1947 0.1852 0.1760 0.1696 0.1644 0.1608 0.1585 0.1567 0.1555 0.1552 0.1546 0.1542 

[TRAIN] Epoch[5](218/1500); Loss: 0.095850; Backpropagation: 0.0931 sec; Batch: 0.4280 sec
0.3481 0.2354 0.1369 0.0621 0.0617 0.0600 0.0621 0.0630 0.0625 0.0621 0.0610 0.0612 0.0625 0.0642 0.0655 0.0651 

[TRAIN] Epoch[5](219/1500); Loss: 0.077892; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1817 0.1289 0.0918 0.0737 0.0699 0.0680 0.0649 0.0621 0.0618 0.0622 0.0630 0.0636 0.0638 0.0639 0.0638 0.0633 

[TRAIN] Epoch[5](220/1500); Loss: 0.073545; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1687 0.1179 0.0922 0.0744 0.0705 0.0705 0.0714 0.0701 0.0672 0.0634 0.0597 0.0558 0.0512 0.0478 0.0477 0.0484 

[TRAIN] Epoch[5](221/1500); Loss: 0.104311; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1688 0.1373 0.1237 0.1142 0.1057 0.0979 0.0938 0.0921 0.0911 0.0908 0.0910 0.0913 0.0920 0.0925 0.0931 0.0934 

[TRAIN] Epoch[5](222/1500); Loss: 0.126989; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2434 0.1703 0.1305 0.1187 0.1154 0.1138 0.1123 0.1118 0.1119 0.1130 0.1146 0.1159 0.1157 0.1147 0.1146 0.1152 

[TRAIN] Epoch[5](223/1500); Loss: 0.129003; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1644 0.1388 0.1347 0.1335 0.1307 0.1271 0.1254 0.1248 0.1248 0.1243 0.1235 0.1231 0.1226 0.1223 0.1223 0.1219 

[TRAIN] Epoch[5](224/1500); Loss: 0.112736; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.2143 0.1604 0.1283 0.1106 0.1012 0.0986 0.0985 0.1001 0.1021 0.1023 0.1012 0.0991 0.0971 0.0963 0.0966 0.0969 

[TRAIN] Epoch[5](225/1500); Loss: 0.109553; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2786 0.1917 0.1337 0.0961 0.0947 0.0922 0.0891 0.0867 0.0852 0.0849 0.0855 0.0863 0.0870 0.0876 0.0873 0.0862 

[TRAIN] Epoch[5](226/1500); Loss: 0.066587; Backpropagation: 0.0934 sec; Batch: 0.4265 sec
0.1602 0.0952 0.0860 0.0738 0.0679 0.0640 0.0600 0.0568 0.0542 0.0522 0.0508 0.0499 0.0496 0.0490 0.0481 0.0477 

[TRAIN] Epoch[5](227/1500); Loss: 0.087800; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1963 0.1147 0.0784 0.0909 0.0875 0.0851 0.0821 0.0791 0.0754 0.0723 0.0713 0.0719 0.0731 0.0747 0.0756 0.0763 

[TRAIN] Epoch[5](228/1500); Loss: 0.090954; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1485 0.1093 0.0908 0.0917 0.0908 0.0896 0.0883 0.0868 0.0858 0.0846 0.0833 0.0821 0.0814 0.0809 0.0807 0.0809 

[TRAIN] Epoch[5](229/1500); Loss: 0.099202; Backpropagation: 0.0934 sec; Batch: 0.4289 sec
0.1469 0.1150 0.1007 0.0951 0.0962 0.0973 0.0964 0.0935 0.0925 0.0932 0.0935 0.0937 0.0934 0.0933 0.0933 0.0933 

[TRAIN] Epoch[5](230/1500); Loss: 0.144521; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1777 0.1586 0.1528 0.1514 0.1492 0.1467 0.1437 0.1411 0.1385 0.1368 0.1363 0.1360 0.1357 0.1357 0.1359 0.1362 

[TRAIN] Epoch[5](231/1500); Loss: 0.059122; Backpropagation: 0.0987 sec; Batch: 0.4345 sec
0.1029 0.0644 0.0587 0.0690 0.0819 0.0807 0.0634 0.0499 0.0498 0.0485 0.0471 0.0466 0.0467 0.0460 0.0453 0.0449 

[TRAIN] Epoch[5](232/1500); Loss: 0.072725; Backpropagation: 0.0981 sec; Batch: 0.4325 sec
0.1488 0.1018 0.0795 0.0701 0.0720 0.0749 0.0740 0.0661 0.0603 0.0592 0.0595 0.0594 0.0591 0.0592 0.0598 0.0599 

[TRAIN] Epoch[5](233/1500); Loss: 0.098478; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2948 0.1994 0.1206 0.0733 0.0773 0.0755 0.0745 0.0738 0.0734 0.0728 0.0726 0.0727 0.0728 0.0733 0.0741 0.0748 

[TRAIN] Epoch[5](234/1500); Loss: 0.074557; Backpropagation: 0.0981 sec; Batch: 0.4356 sec
0.1411 0.0935 0.0710 0.0782 0.0767 0.0748 0.0728 0.0709 0.0690 0.0672 0.0655 0.0641 0.0630 0.0622 0.0616 0.0612 

[TRAIN] Epoch[5](235/1500); Loss: 0.112416; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.1777 0.1322 0.1120 0.1126 0.1126 0.1092 0.1057 0.1037 0.1031 0.1029 0.1033 0.1038 0.1044 0.1050 0.1054 0.1052 

[TRAIN] Epoch[5](236/1500); Loss: 0.109313; Backpropagation: 0.0931 sec; Batch: 0.4275 sec
0.1717 0.1268 0.1126 0.1114 0.1101 0.1078 0.1052 0.1035 0.1026 0.1017 0.1010 0.1000 0.0991 0.0987 0.0984 0.0985 

[TRAIN] Epoch[5](237/1500); Loss: 0.075224; Backpropagation: 0.0958 sec; Batch: 0.4311 sec
0.1899 0.1107 0.0757 0.0730 0.0690 0.0657 0.0633 0.0621 0.0618 0.0620 0.0621 0.0621 0.0617 0.0618 0.0617 0.0610 

[TRAIN] Epoch[5](238/1500); Loss: 0.112427; Backpropagation: 0.0942 sec; Batch: 0.4297 sec
0.1510 0.1284 0.1195 0.1149 0.1124 0.1106 0.1090 0.1080 0.1073 0.1067 0.1062 0.1058 0.1055 0.1050 0.1045 0.1040 

[TRAIN] Epoch[5](239/1500); Loss: 0.096184; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1065 0.1055 0.1097 0.1044 0.0979 0.0955 0.0943 0.0932 0.0925 0.0919 0.0918 0.0915 0.0912 0.0910 0.0910 0.0911 

[TRAIN] Epoch[5](240/1500); Loss: 0.098158; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.2192 0.1585 0.1226 0.1139 0.1026 0.0956 0.0881 0.0822 0.0781 0.0753 0.0736 0.0727 0.0724 0.0720 0.0720 0.0716 

[TRAIN] Epoch[5](241/1500); Loss: 0.121331; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1664 0.1345 0.1208 0.1236 0.1227 0.1200 0.1169 0.1156 0.1151 0.1148 0.1151 0.1155 0.1157 0.1153 0.1145 0.1147 

[TRAIN] Epoch[5](242/1500); Loss: 0.093120; Backpropagation: 0.0932 sec; Batch: 0.4283 sec
0.2130 0.1416 0.1068 0.0933 0.0857 0.0820 0.0793 0.0782 0.0780 0.0778 0.0769 0.0762 0.0758 0.0751 0.0750 0.0751 

[TRAIN] Epoch[5](243/1500); Loss: 0.072426; Backpropagation: 0.0959 sec; Batch: 0.4306 sec
0.1772 0.1214 0.0828 0.0688 0.0663 0.0641 0.0611 0.0589 0.0576 0.0572 0.0571 0.0574 0.0575 0.0572 0.0572 0.0571 

[TRAIN] Epoch[5](244/1500); Loss: 0.078892; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.3657 0.2359 0.1168 0.0493 0.0449 0.0421 0.0407 0.0402 0.0416 0.0418 0.0404 0.0398 0.0398 0.0402 0.0415 0.0416 

[TRAIN] Epoch[5](245/1500); Loss: 0.097517; Backpropagation: 0.0936 sec; Batch: 0.4291 sec
0.2035 0.1519 0.1156 0.0852 0.0940 0.0917 0.0877 0.0838 0.0816 0.0805 0.0803 0.0807 0.0812 0.0816 0.0807 0.0803 

[TRAIN] Epoch[5](246/1500); Loss: 0.099929; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1589 0.1362 0.1194 0.1042 0.0996 0.0966 0.0942 0.0918 0.0897 0.0884 0.0875 0.0868 0.0865 0.0862 0.0862 0.0864 

[TRAIN] Epoch[5](247/1500); Loss: 0.079745; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1234 0.0987 0.0930 0.0913 0.0848 0.0800 0.0773 0.0753 0.0739 0.0723 0.0702 0.0685 0.0676 0.0668 0.0664 0.0664 

[TRAIN] Epoch[5](248/1500); Loss: 0.191118; Backpropagation: 0.0933 sec; Batch: 0.4290 sec
0.2658 0.2217 0.2032 0.1931 0.1879 0.1851 0.1825 0.1806 0.1794 0.1789 0.1787 0.1789 0.1795 0.1801 0.1811 0.1816 

[TRAIN] Epoch[5](249/1500); Loss: 0.071078; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1946 0.1125 0.0736 0.0768 0.0679 0.0619 0.0571 0.0550 0.0548 0.0551 0.0551 0.0544 0.0535 0.0540 0.0550 0.0560 

[TRAIN] Epoch[5](250/1500); Loss: 0.069926; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1723 0.1032 0.0665 0.0522 0.0664 0.0785 0.0832 0.0720 0.0569 0.0538 0.0523 0.0519 0.0523 0.0527 0.0525 0.0521 

[TRAIN] Epoch[5](251/1500); Loss: 0.107386; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1388 0.1193 0.1135 0.1091 0.1075 0.1064 0.1053 0.1043 0.1034 0.1027 0.1022 0.1019 0.1016 0.1012 0.1007 0.1002 

[TRAIN] Epoch[5](252/1500); Loss: 0.125448; Backpropagation: 0.0940 sec; Batch: 0.4296 sec
0.1759 0.1586 0.1506 0.1368 0.1263 0.1226 0.1200 0.1179 0.1164 0.1152 0.1141 0.1129 0.1114 0.1101 0.1094 0.1089 

[TRAIN] Epoch[5](253/1500); Loss: 0.108424; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1871 0.1315 0.1138 0.1158 0.1112 0.1063 0.1019 0.0985 0.0970 0.0962 0.0957 0.0956 0.0957 0.0958 0.0962 0.0964 

[TRAIN] Epoch[5](254/1500); Loss: 0.137062; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2401 0.1739 0.1428 0.1350 0.1305 0.1282 0.1263 0.1253 0.1250 0.1249 0.1245 0.1238 0.1234 0.1233 0.1232 0.1228 

[TRAIN] Epoch[5](255/1500); Loss: 0.100743; Backpropagation: 0.0938 sec; Batch: 0.4286 sec
0.1399 0.1155 0.1052 0.1026 0.1007 0.0989 0.0979 0.0974 0.0968 0.0952 0.0939 0.0933 0.0935 0.0937 0.0939 0.0936 

[TRAIN] Epoch[5](256/1500); Loss: 0.112464; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.2535 0.1953 0.1606 0.1313 0.1120 0.1019 0.0935 0.0880 0.0847 0.0835 0.0832 0.0830 0.0828 0.0821 0.0819 0.0819 

[TRAIN] Epoch[5](257/1500); Loss: 0.073336; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.1647 0.1096 0.0779 0.0709 0.0688 0.0668 0.0637 0.0623 0.0620 0.0618 0.0614 0.0610 0.0606 0.0604 0.0605 0.0609 

[TRAIN] Epoch[5](258/1500); Loss: 0.093011; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1250 0.1085 0.0992 0.0943 0.0919 0.0900 0.0885 0.0876 0.0874 0.0877 0.0882 0.0882 0.0878 0.0877 0.0879 0.0882 

[TRAIN] Epoch[5](259/1500); Loss: 0.101876; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1233 0.1051 0.1024 0.1014 0.1008 0.1004 0.0999 0.1001 0.0999 0.0996 0.0996 0.0997 0.0996 0.0996 0.0995 0.0993 

[TRAIN] Epoch[5](260/1500); Loss: 0.063545; Backpropagation: 0.0943 sec; Batch: 0.4293 sec
0.1086 0.0779 0.0709 0.0677 0.0624 0.0594 0.0582 0.0577 0.0576 0.0573 0.0568 0.0566 0.0568 0.0565 0.0563 0.0561 

[TRAIN] Epoch[5](261/1500); Loss: 0.135801; Backpropagation: 0.0982 sec; Batch: 0.4332 sec
0.2410 0.1962 0.1631 0.1373 0.1313 0.1271 0.1232 0.1202 0.1181 0.1169 0.1164 0.1164 0.1167 0.1165 0.1163 0.1162 

[TRAIN] Epoch[5](262/1500); Loss: 0.156088; Backpropagation: 0.0959 sec; Batch: 0.4311 sec
0.2829 0.2256 0.1915 0.1680 0.1500 0.1420 0.1358 0.1324 0.1316 0.1318 0.1331 0.1344 0.1352 0.1353 0.1342 0.1334 

[TRAIN] Epoch[5](263/1500); Loss: 0.136235; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.2461 0.1973 0.1691 0.1417 0.1255 0.1239 0.1217 0.1201 0.1188 0.1180 0.1174 0.1169 0.1166 0.1161 0.1154 0.1153 

[TRAIN] Epoch[5](264/1500); Loss: 0.129514; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2515 0.1952 0.1795 0.1594 0.1461 0.1357 0.1260 0.1178 0.1105 0.1041 0.0988 0.0946 0.0913 0.0888 0.0870 0.0860 

[TRAIN] Epoch[5](265/1500); Loss: 0.110403; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.2901 0.2257 0.1892 0.1531 0.1296 0.1143 0.0993 0.0873 0.0769 0.0690 0.0636 0.0598 0.0567 0.0536 0.0506 0.0478 

[TRAIN] Epoch[5](266/1500); Loss: 0.088526; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1328 0.1130 0.0982 0.0909 0.0864 0.0851 0.0840 0.0829 0.0824 0.0820 0.0814 0.0803 0.0798 0.0796 0.0791 0.0786 

[TRAIN] Epoch[5](267/1500); Loss: 0.153125; Backpropagation: 0.0958 sec; Batch: 0.4305 sec
0.2035 0.1725 0.1612 0.1568 0.1585 0.1573 0.1519 0.1461 0.1437 0.1435 0.1433 0.1427 0.1423 0.1421 0.1422 0.1423 

[TRAIN] Epoch[5](268/1500); Loss: 0.036948; Backpropagation: 0.0957 sec; Batch: 0.4303 sec
0.0464 0.0394 0.0405 0.0390 0.0372 0.0357 0.0343 0.0338 0.0340 0.0345 0.0351 0.0356 0.0360 0.0362 0.0364 0.0371 

[TRAIN] Epoch[5](269/1500); Loss: 0.131624; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1866 0.1514 0.1399 0.1339 0.1313 0.1302 0.1287 0.1260 0.1244 0.1234 0.1223 0.1216 0.1214 0.1214 0.1217 0.1217 

[TRAIN] Epoch[5](270/1500); Loss: 0.127456; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2424 0.1934 0.1562 0.1290 0.1224 0.1175 0.1130 0.1096 0.1075 0.1071 0.1080 0.1090 0.1083 0.1063 0.1049 0.1047 

[TRAIN] Epoch[5](271/1500); Loss: 0.100683; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1670 0.1253 0.1100 0.1085 0.1024 0.0950 0.0926 0.0923 0.0921 0.0908 0.0895 0.0894 0.0896 0.0893 0.0887 0.0884 

[TRAIN] Epoch[5](272/1500); Loss: 0.067424; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.1285 0.0770 0.0748 0.0688 0.0662 0.0642 0.0624 0.0601 0.0594 0.0595 0.0596 0.0599 0.0601 0.0599 0.0591 0.0592 

[TRAIN] Epoch[5](273/1500); Loss: 0.109246; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2311 0.1575 0.1119 0.1100 0.1054 0.1032 0.0987 0.0943 0.0924 0.0922 0.0926 0.0930 0.0928 0.0919 0.0906 0.0902 

[TRAIN] Epoch[5](274/1500); Loss: 0.097055; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.2012 0.1338 0.0966 0.0871 0.0850 0.0841 0.0846 0.0850 0.0853 0.0859 0.0865 0.0871 0.0876 0.0877 0.0877 0.0878 

[TRAIN] Epoch[5](275/1500); Loss: 0.096588; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1755 0.1302 0.1036 0.0916 0.0885 0.0880 0.0880 0.0877 0.0874 0.0873 0.0872 0.0871 0.0866 0.0857 0.0854 0.0855 

[TRAIN] Epoch[5](276/1500); Loss: 0.098593; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1392 0.1050 0.1061 0.1015 0.0986 0.0960 0.0944 0.0937 0.0936 0.0944 0.0945 0.0930 0.0920 0.0916 0.0918 0.0920 

[TRAIN] Epoch[5](277/1500); Loss: 0.086716; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1279 0.0989 0.0963 0.1003 0.0982 0.0917 0.0851 0.0794 0.0773 0.0770 0.0775 0.0772 0.0763 0.0751 0.0748 0.0745 

[TRAIN] Epoch[5](278/1500); Loss: 0.068571; Backpropagation: 0.0981 sec; Batch: 0.4328 sec
0.1096 0.0727 0.0742 0.0934 0.0952 0.0781 0.0627 0.0574 0.0575 0.0580 0.0580 0.0572 0.0558 0.0552 0.0555 0.0567 

[TRAIN] Epoch[5](279/1500); Loss: 0.112671; Backpropagation: 0.0971 sec; Batch: 0.4324 sec
0.1977 0.1531 0.1292 0.1244 0.1163 0.1102 0.1054 0.1016 0.0990 0.0977 0.0976 0.0980 0.0962 0.0936 0.0917 0.0909 

[TRAIN] Epoch[5](280/1500); Loss: 0.146866; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.2052 0.1711 0.1522 0.1441 0.1430 0.1420 0.1413 0.1408 0.1404 0.1399 0.1394 0.1387 0.1382 0.1378 0.1377 0.1380 

[TRAIN] Epoch[5](281/1500); Loss: 0.104692; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1938 0.1375 0.1101 0.0965 0.0986 0.1055 0.1058 0.0967 0.0924 0.0918 0.0911 0.0909 0.0911 0.0910 0.0910 0.0912 

[TRAIN] Epoch[5](282/1500); Loss: 0.105329; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2477 0.1701 0.1259 0.1006 0.0970 0.0954 0.0935 0.0941 0.0910 0.0849 0.0815 0.0808 0.0808 0.0807 0.0805 0.0806 

[TRAIN] Epoch[5](283/1500); Loss: 0.064629; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1582 0.0849 0.0745 0.0717 0.0651 0.0594 0.0569 0.0549 0.0535 0.0516 0.0502 0.0500 0.0501 0.0503 0.0511 0.0516 

[TRAIN] Epoch[5](284/1500); Loss: 0.129433; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1881 0.1642 0.1492 0.1370 0.1280 0.1236 0.1220 0.1201 0.1182 0.1178 0.1174 0.1173 0.1173 0.1172 0.1169 0.1165 

[TRAIN] Epoch[5](285/1500); Loss: 0.090781; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1834 0.1367 0.1055 0.0839 0.0818 0.0823 0.0808 0.0788 0.0786 0.0786 0.0784 0.0775 0.0767 0.0764 0.0763 0.0767 

[TRAIN] Epoch[5](286/1500); Loss: 0.092843; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1590 0.1158 0.0962 0.0886 0.0881 0.0881 0.0880 0.0872 0.0856 0.0847 0.0842 0.0841 0.0842 0.0839 0.0839 0.0839 

[TRAIN] Epoch[5](287/1500); Loss: 0.166289; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2966 0.2371 0.2030 0.1778 0.1567 0.1457 0.1401 0.1409 0.1449 0.1491 0.1481 0.1443 0.1436 0.1435 0.1444 0.1448 

[TRAIN] Epoch[5](288/1500); Loss: 0.067855; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1166 0.0976 0.0803 0.0657 0.0634 0.0622 0.0617 0.0618 0.0613 0.0599 0.0594 0.0593 0.0594 0.0593 0.0590 0.0587 

[TRAIN] Epoch[5](289/1500); Loss: 0.106792; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1714 0.1369 0.1188 0.1079 0.1039 0.1012 0.0990 0.0979 0.0978 0.0977 0.0971 0.0964 0.0962 0.0960 0.0958 0.0949 

[TRAIN] Epoch[5](290/1500); Loss: 0.093200; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2519 0.1661 0.1177 0.0864 0.0875 0.0863 0.0794 0.0727 0.0709 0.0682 0.0685 0.0683 0.0666 0.0665 0.0669 0.0673 

[TRAIN] Epoch[5](291/1500); Loss: 0.108979; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1360 0.1152 0.1086 0.1085 0.1095 0.1091 0.1072 0.1060 0.1058 0.1058 0.1055 0.1051 0.1052 0.1052 0.1053 0.1055 

[TRAIN] Epoch[5](292/1500); Loss: 0.073287; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1713 0.1081 0.0775 0.0682 0.0656 0.0646 0.0642 0.0637 0.0626 0.0610 0.0608 0.0608 0.0609 0.0613 0.0612 0.0607 

[TRAIN] Epoch[5](293/1500); Loss: 0.092621; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.2135 0.1515 0.1139 0.0918 0.0811 0.0791 0.0776 0.0764 0.0760 0.0757 0.0750 0.0746 0.0743 0.0739 0.0738 0.0739 

[TRAIN] Epoch[5](294/1500); Loss: 0.071931; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.0958 0.0883 0.0852 0.0720 0.0668 0.0663 0.0671 0.0670 0.0664 0.0666 0.0671 0.0678 0.0683 0.0685 0.0688 0.0691 

[TRAIN] Epoch[5](295/1500); Loss: 0.075783; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.3778 0.2406 0.1210 0.0397 0.0341 0.0329 0.0342 0.0430 0.0429 0.0399 0.0357 0.0334 0.0332 0.0345 0.0352 0.0345 

[TRAIN] Epoch[5](296/1500); Loss: 0.067039; Backpropagation: 0.0957 sec; Batch: 0.4299 sec
0.1759 0.1225 0.0989 0.0750 0.0585 0.0543 0.0550 0.0547 0.0490 0.0479 0.0479 0.0474 0.0467 0.0463 0.0462 0.0463 

[TRAIN] Epoch[5](297/1500); Loss: 0.089882; Backpropagation: 0.0959 sec; Batch: 0.4305 sec
0.2034 0.1378 0.0959 0.0849 0.0805 0.0789 0.0780 0.0766 0.0757 0.0754 0.0753 0.0753 0.0752 0.0750 0.0750 0.0751 

[TRAIN] Epoch[5](298/1500); Loss: 0.118416; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1391 0.1332 0.1254 0.1206 0.1179 0.1161 0.1151 0.1148 0.1146 0.1144 0.1139 0.1137 0.1137 0.1139 0.1141 0.1142 

[TRAIN] Epoch[5](299/1500); Loss: 0.086108; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2060 0.1329 0.1063 0.0869 0.0792 0.0755 0.0729 0.0712 0.0695 0.0685 0.0681 0.0680 0.0680 0.0680 0.0684 0.0683 

[TRAIN] Epoch[5](300/1500); Loss: 0.067401; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2835 0.1516 0.0658 0.0727 0.0534 0.0481 0.0425 0.0407 0.0404 0.0399 0.0395 0.0392 0.0395 0.0401 0.0407 0.0407 

[TRAIN] Epoch[5](301/1500); Loss: 0.123534; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2033 0.1653 0.1392 0.1224 0.1160 0.1144 0.1146 0.1139 0.1120 0.1111 0.1111 0.1112 0.1112 0.1106 0.1101 0.1102 

[TRAIN] Epoch[5](302/1500); Loss: 0.108355; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1711 0.1347 0.1201 0.1114 0.1071 0.1045 0.1021 0.0993 0.0985 0.0980 0.0977 0.0978 0.0978 0.0979 0.0979 0.0979 

[TRAIN] Epoch[5](303/1500); Loss: 0.102890; Backpropagation: 0.0938 sec; Batch: 0.4275 sec
0.1868 0.1306 0.1078 0.0991 0.0970 0.0966 0.0946 0.0938 0.0932 0.0926 0.0918 0.0919 0.0923 0.0928 0.0928 0.0927 

[TRAIN] Epoch[5](304/1500); Loss: 0.184682; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.3494 0.2787 0.2397 0.2096 0.1821 0.1664 0.1546 0.1502 0.1514 0.1530 0.1548 0.1545 0.1528 0.1527 0.1525 0.1525 

[TRAIN] Epoch[5](305/1500); Loss: 0.134051; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2088 0.1686 0.1503 0.1399 0.1348 0.1316 0.1291 0.1267 0.1241 0.1221 0.1204 0.1188 0.1180 0.1175 0.1172 0.1170 

[TRAIN] Epoch[5](306/1500); Loss: 0.081657; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1871 0.1133 0.0943 0.0800 0.0748 0.0723 0.0711 0.0702 0.0690 0.0685 0.0679 0.0675 0.0677 0.0677 0.0675 0.0675 

[TRAIN] Epoch[5](307/1500); Loss: 0.129842; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.2127 0.1787 0.1546 0.1345 0.1261 0.1223 0.1196 0.1178 0.1160 0.1143 0.1136 0.1135 0.1134 0.1135 0.1134 0.1132 

[TRAIN] Epoch[5](308/1500); Loss: 0.134903; Backpropagation: 0.0939 sec; Batch: 0.4307 sec
0.3549 0.2662 0.2073 0.1512 0.1134 0.0950 0.0970 0.1084 0.1020 0.0982 0.0960 0.0944 0.0937 0.0936 0.0937 0.0936 

[TRAIN] Epoch[5](309/1500); Loss: 0.217286; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.3214 0.2764 0.2488 0.2316 0.2206 0.2141 0.2077 0.2026 0.1988 0.1960 0.1942 0.1931 0.1927 0.1927 0.1927 0.1930 

[TRAIN] Epoch[5](310/1500); Loss: 0.113056; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1659 0.1332 0.1196 0.1123 0.1093 0.1081 0.1072 0.1064 0.1059 0.1057 0.1056 0.1054 0.1054 0.1058 0.1063 0.1068 

[TRAIN] Epoch[5](311/1500); Loss: 0.159247; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2181 0.1812 0.1646 0.1594 0.1561 0.1551 0.1545 0.1537 0.1528 0.1519 0.1514 0.1508 0.1502 0.1497 0.1495 0.1491 

[TRAIN] Epoch[5](312/1500); Loss: 0.125659; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1590 0.1389 0.1319 0.1265 0.1247 0.1232 0.1220 0.1214 0.1210 0.1207 0.1204 0.1204 0.1202 0.1201 0.1201 0.1200 

[TRAIN] Epoch[5](313/1500); Loss: 0.160099; Backpropagation: 0.0944 sec; Batch: 0.4289 sec
0.2525 0.2184 0.1909 0.1672 0.1627 0.1570 0.1527 0.1488 0.1453 0.1426 0.1404 0.1389 0.1374 0.1363 0.1356 0.1348 

[TRAIN] Epoch[5](314/1500); Loss: 0.137995; Backpropagation: 0.0958 sec; Batch: 0.4313 sec
0.2542 0.2034 0.1781 0.1539 0.1390 0.1320 0.1271 0.1220 0.1176 0.1145 0.1123 0.1113 0.1109 0.1110 0.1106 0.1099 

[TRAIN] Epoch[5](315/1500); Loss: 0.110858; Backpropagation: 0.0944 sec; Batch: 0.4292 sec
0.3152 0.2152 0.1436 0.0907 0.0877 0.0861 0.0850 0.0869 0.0859 0.0844 0.0829 0.0825 0.0822 0.0819 0.0819 0.0815 

[TRAIN] Epoch[5](316/1500); Loss: 0.109728; Backpropagation: 0.0938 sec; Batch: 0.4288 sec
0.1905 0.1392 0.1187 0.1111 0.1067 0.1040 0.1023 0.1009 0.0997 0.0987 0.0981 0.0974 0.0971 0.0970 0.0970 0.0972 

[TRAIN] Epoch[5](317/1500); Loss: 0.086442; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.0992 0.0979 0.0997 0.0904 0.0877 0.0864 0.0847 0.0832 0.0823 0.0819 0.0818 0.0817 0.0816 0.0815 0.0815 0.0816 

[TRAIN] Epoch[5](318/1500); Loss: 0.039121; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.0984 0.0663 0.0626 0.0507 0.0382 0.0336 0.0317 0.0292 0.0267 0.0265 0.0269 0.0269 0.0265 0.0267 0.0271 0.0281 

[TRAIN] Epoch[5](319/1500); Loss: 0.098900; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1342 0.1156 0.1048 0.0971 0.0964 0.0958 0.0952 0.0947 0.0943 0.0941 0.0939 0.0936 0.0934 0.0932 0.0931 0.0930 

[TRAIN] Epoch[5](320/1500); Loss: 0.115792; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2175 0.1514 0.1149 0.1081 0.1068 0.1063 0.1061 0.1056 0.1053 0.1047 0.1044 0.1045 0.1046 0.1044 0.1042 0.1041 

[TRAIN] Epoch[5](321/1500); Loss: 0.087848; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1814 0.1335 0.1038 0.0859 0.0786 0.0773 0.0762 0.0757 0.0754 0.0749 0.0742 0.0738 0.0736 0.0735 0.0738 0.0739 

[TRAIN] Epoch[5](322/1500); Loss: 0.071492; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2196 0.1261 0.0758 0.0667 0.0619 0.0587 0.0555 0.0539 0.0532 0.0526 0.0528 0.0529 0.0528 0.0530 0.0537 0.0547 

[TRAIN] Epoch[5](323/1500); Loss: 0.070626; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1238 0.0930 0.0739 0.0701 0.0672 0.0657 0.0645 0.0638 0.0634 0.0633 0.0633 0.0633 0.0635 0.0635 0.0636 0.0639 

[TRAIN] Epoch[5](324/1500); Loss: 0.095968; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2275 0.1676 0.1334 0.1091 0.0981 0.0874 0.0755 0.0713 0.0712 0.0721 0.0719 0.0708 0.0702 0.0697 0.0698 0.0698 

[TRAIN] Epoch[5](325/1500); Loss: 0.095520; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1413 0.1095 0.1012 0.0967 0.0943 0.0926 0.0914 0.0903 0.0894 0.0890 0.0888 0.0884 0.0884 0.0886 0.0889 0.0895 

[TRAIN] Epoch[5](326/1500); Loss: 0.107700; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1283 0.1232 0.1159 0.1085 0.1067 0.1059 0.1049 0.1041 0.1037 0.1034 0.1033 0.1032 0.1031 0.1031 0.1030 0.1029 

[TRAIN] Epoch[5](327/1500); Loss: 0.139451; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2471 0.2029 0.1725 0.1513 0.1393 0.1321 0.1263 0.1220 0.1189 0.1172 0.1170 0.1174 0.1179 0.1171 0.1162 0.1158 

[TRAIN] Epoch[5](328/1500); Loss: 0.110216; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2107 0.1645 0.1292 0.1115 0.1070 0.1026 0.0987 0.0961 0.0947 0.0941 0.0940 0.0935 0.0921 0.0918 0.0916 0.0915 

[TRAIN] Epoch[5](329/1500); Loss: 0.114797; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2143 0.1632 0.1345 0.1155 0.1079 0.1024 0.1007 0.0999 0.0996 0.0997 0.0996 0.0998 0.0999 0.0999 0.0998 0.0999 

[TRAIN] Epoch[5](330/1500); Loss: 0.148173; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2791 0.2288 0.1948 0.1643 0.1556 0.1467 0.1385 0.1311 0.1247 0.1199 0.1166 0.1149 0.1141 0.1140 0.1138 0.1139 

[TRAIN] Epoch[5](331/1500); Loss: 0.100044; Backpropagation: 0.0943 sec; Batch: 0.4286 sec
0.1946 0.1457 0.1165 0.0990 0.0911 0.0890 0.0881 0.0872 0.0866 0.0862 0.0861 0.0860 0.0859 0.0859 0.0862 0.0866 

[TRAIN] Epoch[5](332/1500); Loss: 0.109124; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.3345 0.2338 0.1576 0.0843 0.0945 0.0880 0.0863 0.0818 0.0779 0.0746 0.0725 0.0719 0.0717 0.0720 0.0721 0.0724 

[TRAIN] Epoch[5](333/1500); Loss: 0.097396; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1542 0.1283 0.1200 0.1043 0.0963 0.0933 0.0905 0.0889 0.0877 0.0864 0.0857 0.0851 0.0845 0.0844 0.0844 0.0845 

[TRAIN] Epoch[5](334/1500); Loss: 0.089037; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.3333 0.2421 0.1690 0.0845 0.0606 0.0534 0.0504 0.0485 0.0482 0.0476 0.0478 0.0476 0.0472 0.0482 0.0482 0.0482 

[TRAIN] Epoch[5](335/1500); Loss: 0.116708; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2495 0.1949 0.1627 0.1371 0.1175 0.1079 0.1000 0.0945 0.0913 0.0893 0.0880 0.0873 0.0867 0.0868 0.0869 0.0867 

[TRAIN] Epoch[5](336/1500); Loss: 0.112861; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1643 0.1320 0.1228 0.1177 0.1125 0.1096 0.1069 0.1055 0.1050 0.1049 0.1050 0.1044 0.1041 0.1038 0.1035 0.1036 

[TRAIN] Epoch[5](337/1500); Loss: 0.045592; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.0859 0.0496 0.0512 0.0557 0.0530 0.0429 0.0397 0.0389 0.0386 0.0388 0.0384 0.0385 0.0389 0.0392 0.0397 0.0404 

[TRAIN] Epoch[5](338/1500); Loss: 0.182746; Backpropagation: 0.0942 sec; Batch: 0.4288 sec
0.2051 0.1952 0.1890 0.1854 0.1832 0.1816 0.1804 0.1796 0.1790 0.1787 0.1783 0.1781 0.1778 0.1776 0.1775 0.1775 

[TRAIN] Epoch[5](339/1500); Loss: 0.111661; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.2556 0.1946 0.1501 0.1216 0.1081 0.0996 0.0927 0.0884 0.0861 0.0848 0.0841 0.0843 0.0844 0.0841 0.0839 0.0842 

[TRAIN] Epoch[5](340/1500); Loss: 0.127489; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2110 0.1520 0.1259 0.1237 0.1205 0.1197 0.1189 0.1185 0.1182 0.1180 0.1182 0.1184 0.1187 0.1190 0.1194 0.1199 

[TRAIN] Epoch[5](341/1500); Loss: 0.139983; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1913 0.1767 0.1598 0.1467 0.1418 0.1384 0.1358 0.1337 0.1317 0.1297 0.1282 0.1268 0.1257 0.1249 0.1243 0.1242 

[TRAIN] Epoch[5](342/1500); Loss: 0.078872; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1347 0.0960 0.0945 0.0899 0.0821 0.0746 0.0714 0.0695 0.0687 0.0683 0.0682 0.0683 0.0687 0.0689 0.0690 0.0693 

[TRAIN] Epoch[5](343/1500); Loss: 0.080475; Backpropagation: 0.0982 sec; Batch: 0.4326 sec
0.1802 0.1260 0.0969 0.0781 0.0715 0.0684 0.0671 0.0664 0.0660 0.0656 0.0658 0.0659 0.0663 0.0669 0.0679 0.0684 

[TRAIN] Epoch[5](344/1500); Loss: 0.075238; Backpropagation: 0.0970 sec; Batch: 0.4315 sec
0.1403 0.1016 0.0851 0.0743 0.0704 0.0689 0.0677 0.0673 0.0668 0.0659 0.0656 0.0656 0.0658 0.0660 0.0662 0.0664 

[TRAIN] Epoch[5](345/1500); Loss: 0.103982; Backpropagation: 0.0942 sec; Batch: 0.4344 sec
0.2066 0.1331 0.1042 0.1006 0.0958 0.0942 0.0931 0.0929 0.0926 0.0923 0.0923 0.0924 0.0928 0.0933 0.0937 0.0939 

[TRAIN] Epoch[5](346/1500); Loss: 0.121905; Backpropagation: 0.0932 sec; Batch: 0.4658 sec
0.1759 0.1526 0.1400 0.1321 0.1244 0.1196 0.1163 0.1134 0.1113 0.1102 0.1098 0.1094 0.1089 0.1088 0.1088 0.1089 

[TRAIN] Epoch[5](347/1500); Loss: 0.079163; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2517 0.1795 0.1432 0.1079 0.0856 0.0730 0.0619 0.0545 0.0499 0.0448 0.0406 0.0377 0.0355 0.0342 0.0334 0.0332 

[TRAIN] Epoch[5](348/1500); Loss: 0.084563; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.3012 0.2008 0.1433 0.0872 0.0564 0.0548 0.0623 0.0618 0.0546 0.0480 0.0463 0.0469 0.0477 0.0473 0.0472 0.0471 

[TRAIN] Epoch[5](349/1500); Loss: 0.088627; Backpropagation: 0.0959 sec; Batch: 0.4318 sec
0.0951 0.0952 0.1009 0.0954 0.0906 0.0881 0.0868 0.0861 0.0858 0.0854 0.0849 0.0847 0.0847 0.0847 0.0848 0.0848 

[TRAIN] Epoch[5](350/1500); Loss: 0.147386; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2337 0.1925 0.1728 0.1576 0.1480 0.1425 0.1378 0.1341 0.1325 0.1325 0.1322 0.1304 0.1288 0.1280 0.1275 0.1272 

[TRAIN] Epoch[5](351/1500); Loss: 0.112748; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.2001 0.1553 0.1324 0.1197 0.1099 0.1038 0.1008 0.0988 0.0982 0.0979 0.0978 0.0980 0.0979 0.0978 0.0977 0.0978 

[TRAIN] Epoch[5](352/1500); Loss: 0.084086; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1463 0.0966 0.0809 0.0833 0.0854 0.0827 0.0795 0.0782 0.0772 0.0766 0.0764 0.0759 0.0764 0.0767 0.0766 0.0768 

[TRAIN] Epoch[5](353/1500); Loss: 0.126403; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1953 0.1602 0.1426 0.1285 0.1217 0.1203 0.1200 0.1189 0.1165 0.1158 0.1148 0.1141 0.1138 0.1136 0.1134 0.1131 

[TRAIN] Epoch[5](354/1500); Loss: 0.108295; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2263 0.1666 0.1277 0.1034 0.1019 0.0966 0.0948 0.0934 0.0923 0.0912 0.0906 0.0901 0.0898 0.0897 0.0893 0.0890 

[TRAIN] Epoch[5](355/1500); Loss: 0.118918; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1591 0.1345 0.1243 0.1198 0.1173 0.1165 0.1151 0.1146 0.1137 0.1130 0.1128 0.1126 0.1126 0.1123 0.1122 0.1123 

[TRAIN] Epoch[5](356/1500); Loss: 0.055423; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1542 0.0801 0.0755 0.0609 0.0547 0.0487 0.0442 0.0421 0.0416 0.0413 0.0405 0.0405 0.0404 0.0403 0.0407 0.0411 

[TRAIN] Epoch[5](357/1500); Loss: 0.105806; Backpropagation: 0.0941 sec; Batch: 0.4278 sec
0.1871 0.1407 0.1161 0.1068 0.1032 0.1001 0.0980 0.0960 0.0949 0.0944 0.0939 0.0931 0.0925 0.0921 0.0921 0.0919 

[TRAIN] Epoch[5](358/1500); Loss: 0.127666; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2040 0.1693 0.1465 0.1289 0.1222 0.1187 0.1170 0.1163 0.1158 0.1157 0.1154 0.1149 0.1148 0.1146 0.1143 0.1143 

[TRAIN] Epoch[5](359/1500); Loss: 0.091928; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1766 0.1291 0.1001 0.0879 0.0854 0.0853 0.0845 0.0832 0.0821 0.0815 0.0810 0.0802 0.0795 0.0786 0.0781 0.0776 

[TRAIN] Epoch[5](360/1500); Loss: 0.143099; Backpropagation: 0.0941 sec; Batch: 0.4278 sec
0.2109 0.1894 0.1683 0.1455 0.1355 0.1327 0.1310 0.1307 0.1313 0.1318 0.1314 0.1307 0.1300 0.1299 0.1301 0.1305 

[TRAIN] Epoch[5](361/1500); Loss: 0.149416; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2400 0.2018 0.1766 0.1555 0.1500 0.1445 0.1405 0.1373 0.1352 0.1338 0.1324 0.1303 0.1290 0.1284 0.1280 0.1276 

[TRAIN] Epoch[5](362/1500); Loss: 0.119173; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1751 0.1431 0.1278 0.1204 0.1181 0.1155 0.1137 0.1123 0.1113 0.1109 0.1108 0.1105 0.1098 0.1093 0.1091 0.1090 

[TRAIN] Epoch[5](363/1500); Loss: 0.087829; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1348 0.1089 0.1065 0.1048 0.0898 0.0831 0.0807 0.0794 0.0791 0.0784 0.0772 0.0761 0.0761 0.0764 0.0768 0.0771 

[TRAIN] Epoch[5](364/1500); Loss: 0.131537; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1949 0.1689 0.1488 0.1369 0.1314 0.1289 0.1263 0.1231 0.1211 0.1197 0.1188 0.1184 0.1179 0.1173 0.1164 0.1159 

[TRAIN] Epoch[5](365/1500); Loss: 0.063072; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1180 0.0895 0.0700 0.0582 0.0573 0.0560 0.0555 0.0552 0.0554 0.0553 0.0554 0.0557 0.0560 0.0568 0.0573 0.0575 

[TRAIN] Epoch[5](366/1500); Loss: 0.102804; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.2118 0.1570 0.1311 0.1173 0.1022 0.0909 0.0868 0.0863 0.0859 0.0842 0.0830 0.0826 0.0819 0.0816 0.0811 0.0812 

[TRAIN] Epoch[5](367/1500); Loss: 0.121731; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1969 0.1645 0.1464 0.1335 0.1259 0.1195 0.1144 0.1107 0.1081 0.1057 0.1042 0.1034 0.1036 0.1039 0.1037 0.1032 

[TRAIN] Epoch[5](368/1500); Loss: 0.092450; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1800 0.1177 0.0903 0.0935 0.0946 0.0861 0.0839 0.0831 0.0822 0.0818 0.0811 0.0807 0.0807 0.0808 0.0813 0.0813 

[TRAIN] Epoch[5](369/1500); Loss: 0.072335; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1238 0.0947 0.0830 0.0717 0.0720 0.0755 0.0694 0.0652 0.0640 0.0633 0.0633 0.0630 0.0625 0.0620 0.0620 0.0618 

[TRAIN] Epoch[5](370/1500); Loss: 0.075922; Backpropagation: 0.0935 sec; Batch: 0.4270 sec
0.1090 0.0967 0.0922 0.0840 0.0785 0.0735 0.0710 0.0707 0.0693 0.0685 0.0676 0.0667 0.0666 0.0667 0.0669 0.0669 

[TRAIN] Epoch[5](371/1500); Loss: 0.103343; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2475 0.1884 0.1490 0.1125 0.0897 0.0852 0.0859 0.0840 0.0812 0.0770 0.0760 0.0757 0.0759 0.0755 0.0748 0.0752 

[TRAIN] Epoch[5](372/1500); Loss: 0.137633; Backpropagation: 0.0941 sec; Batch: 0.4276 sec
0.2033 0.1706 0.1487 0.1377 0.1348 0.1327 0.1314 0.1301 0.1292 0.1282 0.1269 0.1261 0.1258 0.1256 0.1255 0.1252 

[TRAIN] Epoch[5](373/1500); Loss: 0.062320; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1628 0.0866 0.0669 0.0642 0.0577 0.0537 0.0523 0.0519 0.0500 0.0498 0.0501 0.0498 0.0502 0.0501 0.0503 0.0506 

[TRAIN] Epoch[5](374/1500); Loss: 0.130777; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2089 0.1690 0.1511 0.1351 0.1288 0.1275 0.1214 0.1190 0.1181 0.1165 0.1164 0.1160 0.1164 0.1162 0.1159 0.1161 

[TRAIN] Epoch[5](375/1500); Loss: 0.103917; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1662 0.1175 0.1113 0.1111 0.1062 0.1003 0.0982 0.0966 0.0960 0.0949 0.0945 0.0941 0.0940 0.0939 0.0939 0.0940 

[TRAIN] Epoch[5](376/1500); Loss: 0.063994; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.1236 0.0808 0.0637 0.0715 0.0752 0.0615 0.0571 0.0555 0.0553 0.0560 0.0545 0.0540 0.0539 0.0540 0.0539 0.0535 

[TRAIN] Epoch[5](377/1500); Loss: 0.124946; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2114 0.1714 0.1435 0.1234 0.1170 0.1158 0.1144 0.1132 0.1123 0.1116 0.1112 0.1110 0.1110 0.1109 0.1106 0.1105 

[TRAIN] Epoch[5](378/1500); Loss: 0.112684; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1984 0.1391 0.1176 0.1090 0.1067 0.1051 0.1046 0.1048 0.1046 0.1039 0.1030 0.1021 0.1011 0.1008 0.1010 0.1012 

[TRAIN] Epoch[5](379/1500); Loss: 0.067579; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.0958 0.0838 0.0777 0.0719 0.0692 0.0676 0.0654 0.0643 0.0632 0.0621 0.0614 0.0607 0.0602 0.0596 0.0594 0.0590 

[TRAIN] Epoch[5](380/1500); Loss: 0.096603; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1970 0.1477 0.1158 0.0985 0.0908 0.0868 0.0844 0.0827 0.0817 0.0811 0.0808 0.0802 0.0799 0.0795 0.0793 0.0793 

[TRAIN] Epoch[5](381/1500); Loss: 0.104070; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2431 0.1764 0.1310 0.0979 0.0897 0.0872 0.0859 0.0851 0.0845 0.0844 0.0841 0.0837 0.0832 0.0829 0.0830 0.0831 

[TRAIN] Epoch[5](382/1500); Loss: 0.137460; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.2063 0.1643 0.1487 0.1375 0.1342 0.1322 0.1307 0.1294 0.1285 0.1278 0.1272 0.1267 0.1265 0.1265 0.1265 0.1263 

[TRAIN] Epoch[5](383/1500); Loss: 0.100722; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2717 0.1750 0.1237 0.1035 0.0891 0.0831 0.0788 0.0782 0.0788 0.0780 0.0762 0.0752 0.0748 0.0750 0.0752 0.0751 

[TRAIN] Epoch[5](384/1500); Loss: 0.091816; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.3114 0.1982 0.1159 0.0738 0.0739 0.0706 0.0672 0.0643 0.0621 0.0620 0.0623 0.0617 0.0613 0.0614 0.0614 0.0616 

[TRAIN] Epoch[5](385/1500); Loss: 0.090757; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1388 0.1094 0.0969 0.0913 0.0880 0.0875 0.0864 0.0846 0.0838 0.0836 0.0837 0.0838 0.0839 0.0834 0.0834 0.0836 

[TRAIN] Epoch[5](386/1500); Loss: 0.077130; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1457 0.0962 0.0885 0.0832 0.0780 0.0711 0.0687 0.0675 0.0668 0.0666 0.0673 0.0674 0.0665 0.0668 0.0669 0.0670 

[TRAIN] Epoch[5](387/1500); Loss: 0.103855; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2283 0.1615 0.1304 0.1044 0.0941 0.0911 0.0894 0.0881 0.0864 0.0852 0.0846 0.0844 0.0841 0.0837 0.0831 0.0828 

[TRAIN] Epoch[5](388/1500); Loss: 0.200442; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.3013 0.2541 0.2273 0.2093 0.1908 0.1836 0.1859 0.1901 0.1879 0.1850 0.1839 0.1827 0.1815 0.1812 0.1811 0.1814 

[TRAIN] Epoch[5](389/1500); Loss: 0.122013; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.3698 0.2629 0.1923 0.1242 0.0827 0.0808 0.0989 0.0899 0.0868 0.0815 0.0790 0.0797 0.0808 0.0808 0.0811 0.0812 

[TRAIN] Epoch[5](390/1500); Loss: 0.125054; Backpropagation: 0.0934 sec; Batch: 0.4445 sec
0.1652 0.1427 0.1289 0.1236 0.1220 0.1203 0.1193 0.1194 0.1195 0.1195 0.1196 0.1197 0.1201 0.1203 0.1202 0.1205 

[TRAIN] Epoch[5](391/1500); Loss: 0.145897; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.2376 0.1949 0.1683 0.1516 0.1441 0.1403 0.1373 0.1347 0.1326 0.1308 0.1292 0.1280 0.1269 0.1265 0.1261 0.1254 

[TRAIN] Epoch[5](392/1500); Loss: 0.087962; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2535 0.1675 0.1129 0.0794 0.0916 0.0745 0.0670 0.0636 0.0632 0.0632 0.0626 0.0616 0.0614 0.0617 0.0617 0.0621 

[TRAIN] Epoch[5](393/1500); Loss: 0.103526; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1533 0.1251 0.1078 0.1024 0.1011 0.1006 0.0998 0.0985 0.0975 0.0967 0.0962 0.0960 0.0956 0.0954 0.0952 0.0952 

[TRAIN] Epoch[5](394/1500); Loss: 0.137088; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2816 0.2237 0.1813 0.1370 0.1146 0.1142 0.1245 0.1149 0.1172 0.1131 0.1116 0.1113 0.1120 0.1117 0.1124 0.1124 

[TRAIN] Epoch[5](395/1500); Loss: 0.116319; Backpropagation: 0.0952 sec; Batch: 0.4303 sec
0.1775 0.1469 0.1308 0.1186 0.1114 0.1088 0.1074 0.1069 0.1069 0.1065 0.1063 0.1063 0.1065 0.1066 0.1067 0.1068 

[TRAIN] Epoch[5](396/1500); Loss: 0.090120; Backpropagation: 0.0982 sec; Batch: 0.4411 sec
0.1418 0.1144 0.0978 0.0922 0.0892 0.0861 0.0839 0.0828 0.0819 0.0817 0.0815 0.0815 0.0815 0.0817 0.0818 0.0821 

[TRAIN] Epoch[5](397/1500); Loss: 0.094072; Backpropagation: 0.0943 sec; Batch: 0.4296 sec
0.2701 0.1655 0.1027 0.0945 0.0819 0.0781 0.0745 0.0741 0.0726 0.0714 0.0702 0.0694 0.0693 0.0700 0.0705 0.0705 

[TRAIN] Epoch[5](398/1500); Loss: 0.097977; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.3270 0.2475 0.1796 0.1087 0.0624 0.0685 0.0623 0.0601 0.0576 0.0569 0.0564 0.0560 0.0562 0.0559 0.0558 0.0566 

[TRAIN] Epoch[5](399/1500); Loss: 0.124117; Backpropagation: 0.0939 sec; Batch: 0.4721 sec
0.2068 0.1629 0.1461 0.1412 0.1306 0.1171 0.1138 0.1125 0.1094 0.1083 0.1075 0.1069 0.1063 0.1057 0.1055 0.1053 

[TRAIN] Epoch[5](400/1500); Loss: 0.096999; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.3509 0.2594 0.1826 0.1074 0.0570 0.0675 0.0591 0.0562 0.0523 0.0509 0.0509 0.0514 0.0526 0.0518 0.0508 0.0511 

[TRAIN] Epoch[5](401/1500); Loss: 0.104772; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.1576 0.1283 0.1275 0.1072 0.1019 0.0993 0.0973 0.0971 0.0962 0.0945 0.0937 0.0942 0.0949 0.0951 0.0953 0.0963 

[TRAIN] Epoch[5](402/1500); Loss: 0.099484; Backpropagation: 0.0941 sec; Batch: 0.4290 sec
0.1758 0.1276 0.1037 0.0984 0.0949 0.0930 0.0917 0.0911 0.0907 0.0903 0.0899 0.0895 0.0888 0.0886 0.0888 0.0889 

[TRAIN] Epoch[5](403/1500); Loss: 0.089084; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.2446 0.1675 0.1211 0.0855 0.0829 0.0902 0.0802 0.0665 0.0616 0.0611 0.0611 0.0611 0.0602 0.0602 0.0603 0.0612 

[TRAIN] Epoch[5](404/1500); Loss: 0.109697; Backpropagation: 0.0940 sec; Batch: 0.4295 sec
0.2700 0.1742 0.1165 0.0973 0.0969 0.0957 0.0947 0.0925 0.0914 0.0907 0.0899 0.0898 0.0893 0.0887 0.0888 0.0886 

[TRAIN] Epoch[5](405/1500); Loss: 0.105628; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2322 0.1733 0.1271 0.0958 0.0954 0.0926 0.0898 0.0900 0.0883 0.0871 0.0871 0.0870 0.0865 0.0860 0.0856 0.0862 

[TRAIN] Epoch[5](406/1500); Loss: 0.060882; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2591 0.1352 0.0788 0.0515 0.0444 0.0422 0.0391 0.0390 0.0361 0.0350 0.0349 0.0353 0.0351 0.0354 0.0362 0.0369 

[TRAIN] Epoch[5](407/1500); Loss: 0.059566; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1076 0.0847 0.0737 0.0718 0.0653 0.0543 0.0528 0.0516 0.0514 0.0505 0.0491 0.0483 0.0478 0.0484 0.0481 0.0477 

[TRAIN] Epoch[5](408/1500); Loss: 0.060374; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.0844 0.0703 0.0619 0.0584 0.0578 0.0578 0.0576 0.0568 0.0565 0.0569 0.0571 0.0573 0.0575 0.0579 0.0586 0.0594 

[TRAIN] Epoch[5](409/1500); Loss: 0.100519; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2451 0.1686 0.1143 0.0872 0.0860 0.0844 0.0841 0.0840 0.0835 0.0823 0.0816 0.0816 0.0819 0.0814 0.0812 0.0811 

[TRAIN] Epoch[5](410/1500); Loss: 0.129991; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2557 0.1968 0.1558 0.1301 0.1250 0.1219 0.1156 0.1118 0.1107 0.1101 0.1092 0.1083 0.1077 0.1074 0.1071 0.1067 

[TRAIN] Epoch[5](411/1500); Loss: 0.058616; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.0769 0.0707 0.0773 0.0728 0.0609 0.0555 0.0539 0.0528 0.0523 0.0523 0.0518 0.0517 0.0521 0.0525 0.0522 0.0523 

[TRAIN] Epoch[5](412/1500); Loss: 0.094464; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1309 0.1091 0.0989 0.0943 0.0923 0.0924 0.0917 0.0899 0.0891 0.0888 0.0886 0.0888 0.0891 0.0892 0.0893 0.0891 

[TRAIN] Epoch[5](413/1500); Loss: 0.067165; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.1717 0.1253 0.0893 0.0668 0.0604 0.0554 0.0532 0.0514 0.0505 0.0503 0.0497 0.0496 0.0498 0.0502 0.0504 0.0507 

[TRAIN] Epoch[5](414/1500); Loss: 0.066034; Backpropagation: 0.0939 sec; Batch: 0.4271 sec
0.1847 0.0930 0.0726 0.0610 0.0584 0.0563 0.0551 0.0534 0.0530 0.0529 0.0527 0.0529 0.0525 0.0524 0.0526 0.0528 

[TRAIN] Epoch[5](415/1500); Loss: 0.143320; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2507 0.2124 0.1938 0.1618 0.1357 0.1219 0.1237 0.1332 0.1240 0.1215 0.1191 0.1188 0.1189 0.1191 0.1194 0.1192 

[TRAIN] Epoch[5](416/1500); Loss: 0.048220; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.0742 0.0748 0.0634 0.0505 0.0455 0.0440 0.0428 0.0420 0.0415 0.0412 0.0407 0.0412 0.0418 0.0420 0.0424 0.0433 

[TRAIN] Epoch[5](417/1500); Loss: 0.119633; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2643 0.2014 0.1504 0.1188 0.1067 0.1006 0.0993 0.0981 0.0975 0.0973 0.0970 0.0966 0.0964 0.0965 0.0966 0.0967 

[TRAIN] Epoch[5](418/1500); Loss: 0.073528; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2226 0.1403 0.0885 0.0613 0.0592 0.0578 0.0563 0.0562 0.0555 0.0548 0.0543 0.0538 0.0537 0.0536 0.0542 0.0543 

[TRAIN] Epoch[5](419/1500); Loss: 0.083412; Backpropagation: 0.0944 sec; Batch: 0.4285 sec
0.1176 0.1031 0.0938 0.0878 0.0864 0.0827 0.0795 0.0777 0.0770 0.0765 0.0761 0.0755 0.0751 0.0751 0.0752 0.0753 

[TRAIN] Epoch[5](420/1500); Loss: 0.134335; Backpropagation: 0.0957 sec; Batch: 0.4298 sec
0.2181 0.1819 0.1561 0.1346 0.1296 0.1254 0.1232 0.1218 0.1209 0.1204 0.1199 0.1195 0.1193 0.1195 0.1196 0.1197 

[TRAIN] Epoch[5](421/1500); Loss: 0.141361; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1884 0.1702 0.1601 0.1505 0.1440 0.1398 0.1367 0.1336 0.1318 0.1307 0.1300 0.1295 0.1292 0.1290 0.1292 0.1293 

[TRAIN] Epoch[5](422/1500); Loss: 0.070190; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.0854 0.0759 0.0749 0.0728 0.0702 0.0689 0.0682 0.0675 0.0671 0.0669 0.0670 0.0670 0.0672 0.0675 0.0680 0.0685 

[TRAIN] Epoch[5](423/1500); Loss: 0.095452; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1383 0.1193 0.1137 0.0967 0.0918 0.0888 0.0872 0.0863 0.0855 0.0859 0.0865 0.0874 0.0880 0.0893 0.0906 0.0919 

[TRAIN] Epoch[5](424/1500); Loss: 0.105034; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.3319 0.2276 0.1557 0.0894 0.0877 0.0895 0.0783 0.0700 0.0707 0.0691 0.0682 0.0675 0.0685 0.0684 0.0692 0.0688 

[TRAIN] Epoch[5](425/1500); Loss: 0.127369; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.1914 0.1562 0.1378 0.1286 0.1240 0.1217 0.1200 0.1191 0.1185 0.1179 0.1174 0.1173 0.1171 0.1170 0.1169 0.1171 

[TRAIN] Epoch[5](426/1500); Loss: 0.202874; Backpropagation: 0.0935 sec; Batch: 0.4270 sec
0.2803 0.2507 0.2312 0.2114 0.1957 0.1922 0.1901 0.1881 0.1877 0.1875 0.1876 0.1878 0.1884 0.1887 0.1891 0.1895 

[TRAIN] Epoch[5](427/1500); Loss: 0.038168; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.0848 0.0524 0.0407 0.0419 0.0436 0.0326 0.0327 0.0321 0.0316 0.0312 0.0309 0.0306 0.0308 0.0312 0.0316 0.0320 

[TRAIN] Epoch[5](428/1500); Loss: 0.112605; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1481 0.1300 0.1202 0.1167 0.1137 0.1114 0.1093 0.1081 0.1071 0.1063 0.1058 0.1053 0.1051 0.1049 0.1048 0.1050 

[TRAIN] Epoch[5](429/1500); Loss: 0.044738; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.0923 0.0592 0.0503 0.0482 0.0467 0.0400 0.0392 0.0385 0.0379 0.0375 0.0375 0.0374 0.0374 0.0376 0.0380 0.0381 

[TRAIN] Epoch[5](430/1500); Loss: 0.174055; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2593 0.2115 0.1871 0.1739 0.1682 0.1669 0.1650 0.1633 0.1627 0.1622 0.1620 0.1613 0.1606 0.1603 0.1603 0.1604 

[TRAIN] Epoch[5](431/1500); Loss: 0.156562; Backpropagation: 0.0943 sec; Batch: 0.4281 sec
0.2450 0.2066 0.1804 0.1630 0.1541 0.1502 0.1473 0.1447 0.1428 0.1411 0.1398 0.1388 0.1383 0.1379 0.1375 0.1373 

[TRAIN] Epoch[5](432/1500); Loss: 0.146387; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1757 0.1601 0.1524 0.1475 0.1453 0.1439 0.1427 0.1420 0.1416 0.1414 0.1414 0.1415 0.1414 0.1415 0.1418 0.1422 

[TRAIN] Epoch[5](433/1500); Loss: 0.090850; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.2875 0.1924 0.1335 0.0742 0.0719 0.0931 0.0765 0.0605 0.0578 0.0572 0.0575 0.0584 0.0587 0.0581 0.0578 0.0584 

[TRAIN] Epoch[5](434/1500); Loss: 0.062627; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1134 0.0827 0.0730 0.0660 0.0626 0.0600 0.0581 0.0564 0.0553 0.0545 0.0539 0.0535 0.0531 0.0530 0.0531 0.0533 

[TRAIN] Epoch[5](435/1500); Loss: 0.124937; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.2186 0.1760 0.1528 0.1274 0.1126 0.1153 0.1141 0.1104 0.1097 0.1096 0.1094 0.1092 0.1090 0.1086 0.1083 0.1082 

[TRAIN] Epoch[5](436/1500); Loss: 0.133515; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1976 0.1601 0.1455 0.1345 0.1296 0.1274 0.1266 0.1257 0.1245 0.1240 0.1236 0.1235 0.1235 0.1234 0.1233 0.1233 

[TRAIN] Epoch[5](437/1500); Loss: 0.130736; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2747 0.1963 0.1530 0.1204 0.1218 0.1179 0.1151 0.1130 0.1116 0.1103 0.1103 0.1098 0.1091 0.1091 0.1093 0.1099 

[TRAIN] Epoch[5](438/1500); Loss: 0.093179; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1474 0.1139 0.1097 0.1007 0.0932 0.0894 0.0869 0.0851 0.0839 0.0832 0.0831 0.0828 0.0825 0.0827 0.0831 0.0835 

[TRAIN] Epoch[5](439/1500); Loss: 0.102461; Backpropagation: 0.0934 sec; Batch: 0.4606 sec
0.1856 0.1319 0.1046 0.0974 0.0960 0.0950 0.0939 0.0932 0.0927 0.0923 0.0927 0.0929 0.0928 0.0925 0.0929 0.0930 

[TRAIN] Epoch[5](440/1500); Loss: 0.068494; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1651 0.1109 0.0837 0.0711 0.0672 0.0569 0.0544 0.0533 0.0538 0.0536 0.0527 0.0528 0.0538 0.0549 0.0554 0.0562 

[TRAIN] Epoch[5](441/1500); Loss: 0.093648; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.2378 0.1554 0.1110 0.0924 0.1054 0.0944 0.0768 0.0714 0.0706 0.0698 0.0690 0.0692 0.0691 0.0686 0.0685 0.0689 

[TRAIN] Epoch[5](442/1500); Loss: 0.087515; Backpropagation: 0.0982 sec; Batch: 0.4358 sec
0.1481 0.1181 0.1000 0.0906 0.0821 0.0802 0.0793 0.0792 0.0786 0.0778 0.0775 0.0776 0.0780 0.0777 0.0776 0.0778 

[TRAIN] Epoch[5](443/1500); Loss: 0.120602; Backpropagation: 0.0944 sec; Batch: 0.4286 sec
0.2125 0.1648 0.1441 0.1167 0.1112 0.1095 0.1090 0.1085 0.1075 0.1067 0.1066 0.1065 0.1064 0.1061 0.1066 0.1068 

[TRAIN] Epoch[5](444/1500); Loss: 0.059361; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1178 0.0906 0.0701 0.0587 0.0562 0.0554 0.0534 0.0517 0.0511 0.0509 0.0499 0.0494 0.0489 0.0487 0.0485 0.0483 

[TRAIN] Epoch[5](445/1500); Loss: 0.073392; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.0874 0.0858 0.0797 0.0754 0.0740 0.0704 0.0694 0.0692 0.0691 0.0693 0.0695 0.0700 0.0703 0.0711 0.0715 0.0720 

[TRAIN] Epoch[5](446/1500); Loss: 0.096145; Backpropagation: 0.0938 sec; Batch: 0.4442 sec
0.1509 0.1099 0.1025 0.0946 0.0919 0.0903 0.0924 0.0906 0.0900 0.0889 0.0886 0.0895 0.0895 0.0895 0.0893 0.0900 

[TRAIN] Epoch[5](447/1500); Loss: 0.155549; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1774 0.1829 0.1729 0.1594 0.1524 0.1515 0.1523 0.1526 0.1507 0.1486 0.1481 0.1483 0.1490 0.1486 0.1473 0.1469 

[TRAIN] Epoch[5](448/1500); Loss: 0.076300; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1314 0.0894 0.0803 0.1001 0.0923 0.0729 0.0704 0.0684 0.0674 0.0656 0.0654 0.0642 0.0631 0.0631 0.0640 0.0629 

[TRAIN] Epoch[5](449/1500); Loss: 0.078748; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1307 0.0977 0.0839 0.0782 0.0770 0.0751 0.0734 0.0721 0.0710 0.0706 0.0709 0.0707 0.0710 0.0714 0.0725 0.0736 

[TRAIN] Epoch[5](450/1500); Loss: 0.105500; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.1857 0.1326 0.1135 0.1078 0.1045 0.1005 0.0983 0.0966 0.0954 0.0948 0.0940 0.0934 0.0931 0.0928 0.0923 0.0925 

[TRAIN] Epoch[5](451/1500); Loss: 0.064661; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1628 0.1158 0.0833 0.0545 0.0583 0.0552 0.0560 0.0521 0.0504 0.0492 0.0496 0.0501 0.0499 0.0490 0.0491 0.0492 

[TRAIN] Epoch[5](452/1500); Loss: 0.097418; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1473 0.1162 0.1017 0.0961 0.0979 0.0990 0.0912 0.0894 0.0895 0.0898 0.0899 0.0899 0.0896 0.0899 0.0903 0.0909 

[TRAIN] Epoch[5](453/1500); Loss: 0.089678; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.1164 0.1010 0.0949 0.0888 0.0869 0.0862 0.0858 0.0856 0.0858 0.0859 0.0859 0.0860 0.0858 0.0862 0.0868 0.0869 

[TRAIN] Epoch[5](454/1500); Loss: 0.084744; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2718 0.1816 0.1242 0.0818 0.0608 0.0597 0.0586 0.0577 0.0566 0.0566 0.0569 0.0576 0.0577 0.0578 0.0580 0.0587 

[TRAIN] Epoch[5](455/1500); Loss: 0.070778; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1957 0.1253 0.0872 0.0604 0.0570 0.0566 0.0550 0.0548 0.0545 0.0546 0.0546 0.0547 0.0550 0.0552 0.0556 0.0562 

[TRAIN] Epoch[5](456/1500); Loss: 0.124018; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.2547 0.2018 0.1585 0.1275 0.1225 0.1152 0.1070 0.1019 0.1009 0.1007 0.1002 0.0996 0.0988 0.0982 0.0985 0.0985 

[TRAIN] Epoch[5](457/1500); Loss: 0.075559; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.2502 0.1710 0.1191 0.0572 0.0527 0.0860 0.0692 0.0480 0.0447 0.0438 0.0449 0.0442 0.0442 0.0441 0.0446 0.0452 

[TRAIN] Epoch[5](458/1500); Loss: 0.131942; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.3528 0.2514 0.1628 0.0932 0.1663 0.1598 0.1119 0.0973 0.0932 0.0920 0.0898 0.0880 0.0875 0.0887 0.0882 0.0882 

[TRAIN] Epoch[5](459/1500); Loss: 0.103697; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1132 0.1171 0.1049 0.0994 0.0993 0.0998 0.0997 0.0996 0.0999 0.1008 0.1020 0.1027 0.1037 0.1045 0.1057 0.1067 

[TRAIN] Epoch[5](460/1500); Loss: 0.089099; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1568 0.1231 0.1066 0.0974 0.0878 0.0820 0.0779 0.0776 0.0777 0.0771 0.0762 0.0763 0.0767 0.0772 0.0773 0.0778 

[TRAIN] Epoch[5](461/1500); Loss: 0.128167; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2000 0.1693 0.1450 0.1280 0.1224 0.1192 0.1178 0.1171 0.1166 0.1165 0.1165 0.1162 0.1160 0.1162 0.1167 0.1171 

[TRAIN] Epoch[5](462/1500); Loss: 0.104931; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2631 0.1855 0.1399 0.0984 0.0875 0.0844 0.0832 0.0829 0.0824 0.0819 0.0816 0.0814 0.0814 0.0816 0.0818 0.0819 

[TRAIN] Epoch[5](463/1500); Loss: 0.161004; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.2955 0.2516 0.2251 0.2043 0.1730 0.1566 0.1450 0.1335 0.1276 0.1249 0.1230 0.1236 0.1243 0.1231 0.1226 0.1225 

[TRAIN] Epoch[5](464/1500); Loss: 0.091506; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2464 0.1759 0.1431 0.1089 0.0616 0.0603 0.0630 0.0680 0.0669 0.0652 0.0654 0.0661 0.0674 0.0682 0.0686 0.0691 

[TRAIN] Epoch[5](465/1500); Loss: 0.146255; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.2296 0.1998 0.1787 0.1586 0.1436 0.1371 0.1327 0.1301 0.1293 0.1287 0.1285 0.1285 0.1284 0.1285 0.1287 0.1290 

[TRAIN] Epoch[5](466/1500); Loss: 0.139095; Backpropagation: 0.0980 sec; Batch: 0.4325 sec
0.2916 0.2310 0.1982 0.1829 0.1540 0.1375 0.1268 0.1145 0.1062 0.1035 0.1021 0.1004 0.0975 0.0950 0.0929 0.0915 

[TRAIN] Epoch[5](467/1500); Loss: 0.080804; Backpropagation: 0.0959 sec; Batch: 0.4307 sec
0.1240 0.0998 0.0863 0.0794 0.0774 0.0766 0.0758 0.0756 0.0753 0.0750 0.0749 0.0747 0.0746 0.0746 0.0745 0.0744 

[TRAIN] Epoch[5](468/1500); Loss: 0.107927; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1876 0.1386 0.1220 0.1095 0.1030 0.1012 0.0990 0.0973 0.0960 0.0952 0.0949 0.0949 0.0953 0.0962 0.0973 0.0988 

[TRAIN] Epoch[5](469/1500); Loss: 0.138401; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2191 0.1967 0.1742 0.1572 0.1431 0.1342 0.1284 0.1241 0.1210 0.1188 0.1172 0.1162 0.1160 0.1161 0.1161 0.1161 

[TRAIN] Epoch[5](470/1500); Loss: 0.108950; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1405 0.1260 0.1144 0.1104 0.1078 0.1066 0.1052 0.1039 0.1035 0.1034 0.1033 0.1032 0.1033 0.1036 0.1039 0.1043 

[TRAIN] Epoch[5](471/1500); Loss: 0.104045; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1624 0.1473 0.1271 0.1161 0.1068 0.0992 0.0955 0.0930 0.0911 0.0901 0.0898 0.0897 0.0896 0.0893 0.0890 0.0889 

[TRAIN] Epoch[5](472/1500); Loss: 0.152792; Backpropagation: 0.0935 sec; Batch: 0.4270 sec
0.2404 0.1960 0.1763 0.1612 0.1479 0.1437 0.1418 0.1392 0.1376 0.1371 0.1367 0.1367 0.1368 0.1372 0.1378 0.1384 

[TRAIN] Epoch[5](473/1500); Loss: 0.124071; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.3299 0.2479 0.1944 0.1434 0.1130 0.0983 0.0923 0.0889 0.0869 0.0859 0.0849 0.0840 0.0837 0.0837 0.0840 0.0841 

[TRAIN] Epoch[5](474/1500); Loss: 0.104301; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1544 0.1335 0.1177 0.1092 0.1031 0.0987 0.0967 0.0958 0.0955 0.0953 0.0951 0.0950 0.0949 0.0947 0.0946 0.0946 

[TRAIN] Epoch[5](475/1500); Loss: 0.070265; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2195 0.1538 0.1171 0.0821 0.0580 0.0495 0.0465 0.0456 0.0453 0.0445 0.0438 0.0434 0.0438 0.0437 0.0437 0.0437 

[TRAIN] Epoch[5](476/1500); Loss: 0.168985; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2526 0.2277 0.2131 0.2009 0.1797 0.1686 0.1609 0.1544 0.1488 0.1455 0.1432 0.1421 0.1417 0.1415 0.1416 0.1414 

[TRAIN] Epoch[5](477/1500); Loss: 0.088832; Backpropagation: 0.0946 sec; Batch: 0.4297 sec
0.1260 0.1014 0.0912 0.0876 0.0857 0.0848 0.0843 0.0840 0.0841 0.0842 0.0842 0.0843 0.0844 0.0846 0.0850 0.0854 

[TRAIN] Epoch[5](478/1500); Loss: 0.113860; Backpropagation: 0.0957 sec; Batch: 0.4307 sec
0.2042 0.1655 0.1375 0.1166 0.1059 0.1024 0.1002 0.0992 0.0988 0.0988 0.0987 0.0988 0.0988 0.0988 0.0988 0.0989 

[TRAIN] Epoch[5](479/1500); Loss: 0.115784; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.2581 0.2139 0.1878 0.1654 0.1383 0.1169 0.0995 0.0859 0.0776 0.0750 0.0731 0.0724 0.0723 0.0722 0.0722 0.0721 

[TRAIN] Epoch[5](480/1500); Loss: 0.152395; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.3763 0.2941 0.2479 0.1933 0.1501 0.1215 0.1114 0.1068 0.1042 0.1034 0.1036 0.1043 0.1043 0.1048 0.1056 0.1065 

[TRAIN] Epoch[5](481/1500); Loss: 0.150293; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2277 0.1948 0.1740 0.1559 0.1462 0.1429 0.1403 0.1384 0.1370 0.1358 0.1351 0.1349 0.1350 0.1352 0.1354 0.1358 

[TRAIN] Epoch[5](482/1500); Loss: 0.118019; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.1705 0.1378 0.1250 0.1187 0.1153 0.1133 0.1114 0.1104 0.1103 0.1102 0.1103 0.1106 0.1107 0.1110 0.1113 0.1117 

[TRAIN] Epoch[5](483/1500); Loss: 0.115948; Backpropagation: 0.0960 sec; Batch: 0.4309 sec
0.1648 0.1369 0.1235 0.1164 0.1133 0.1115 0.1102 0.1095 0.1091 0.1088 0.1086 0.1086 0.1085 0.1084 0.1085 0.1086 

[TRAIN] Epoch[5](484/1500); Loss: 0.065565; Backpropagation: 0.0943 sec; Batch: 0.4287 sec
0.1165 0.0893 0.0764 0.0687 0.0603 0.0589 0.0588 0.0584 0.0575 0.0570 0.0569 0.0572 0.0576 0.0581 0.0584 0.0589 

[TRAIN] Epoch[5](485/1500); Loss: 0.124037; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.2872 0.2303 0.2074 0.1928 0.1498 0.1220 0.1054 0.0906 0.0810 0.0765 0.0747 0.0742 0.0736 0.0733 0.0728 0.0729 

[TRAIN] Epoch[5](486/1500); Loss: 0.132859; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2423 0.1925 0.1660 0.1441 0.1301 0.1216 0.1163 0.1148 0.1138 0.1132 0.1125 0.1122 0.1119 0.1117 0.1115 0.1113 

[TRAIN] Epoch[5](487/1500); Loss: 0.114417; Backpropagation: 0.0938 sec; Batch: 0.4300 sec
0.4443 0.3296 0.2563 0.1601 0.0811 0.0554 0.0503 0.0492 0.0480 0.0501 0.0506 0.0507 0.0507 0.0507 0.0514 0.0520 

[TRAIN] Epoch[5](488/1500); Loss: 0.094875; Backpropagation: 0.0938 sec; Batch: 0.4704 sec
0.2031 0.1404 0.1134 0.0919 0.0799 0.0830 0.0827 0.0805 0.0797 0.0797 0.0799 0.0802 0.0804 0.0805 0.0811 0.0817 

[TRAIN] Epoch[5](489/1500); Loss: 0.184540; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.3110 0.2624 0.2391 0.2273 0.1950 0.1801 0.1682 0.1604 0.1553 0.1524 0.1507 0.1496 0.1493 0.1495 0.1503 0.1520 

[TRAIN] Epoch[5](490/1500); Loss: 0.095691; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1318 0.1074 0.1016 0.0966 0.0934 0.0907 0.0902 0.0902 0.0903 0.0903 0.0904 0.0909 0.0912 0.0915 0.0919 0.0927 

[TRAIN] Epoch[5](491/1500); Loss: 0.114171; Backpropagation: 0.0941 sec; Batch: 0.4295 sec
0.4445 0.3263 0.2514 0.1521 0.0744 0.0622 0.0558 0.0538 0.0507 0.0499 0.0498 0.0503 0.0509 0.0513 0.0515 0.0518 

[TRAIN] Epoch[5](492/1500); Loss: 0.089727; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1287 0.1065 0.0962 0.0896 0.0869 0.0867 0.0858 0.0855 0.0848 0.0843 0.0840 0.0836 0.0834 0.0833 0.0832 0.0831 

[TRAIN] Epoch[5](493/1500); Loss: 0.073064; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2451 0.1601 0.1038 0.0632 0.0504 0.0491 0.0485 0.0483 0.0485 0.0488 0.0492 0.0497 0.0501 0.0506 0.0514 0.0521 

[TRAIN] Epoch[5](494/1500); Loss: 0.114139; Backpropagation: 0.0934 sec; Batch: 0.4288 sec
0.1644 0.1331 0.1193 0.1135 0.1095 0.1090 0.1082 0.1077 0.1077 0.1076 0.1075 0.1075 0.1075 0.1077 0.1078 0.1082 

[TRAIN] Epoch[5](495/1500); Loss: 0.069002; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.2169 0.1322 0.0963 0.0628 0.0529 0.0524 0.0493 0.0476 0.0468 0.0477 0.0475 0.0474 0.0482 0.0498 0.0519 0.0545 

[TRAIN] Epoch[5](496/1500); Loss: 0.103151; Backpropagation: 0.0937 sec; Batch: 0.4295 sec
0.2241 0.1682 0.1432 0.1267 0.1062 0.0973 0.0915 0.0869 0.0830 0.0797 0.0771 0.0754 0.0742 0.0731 0.0722 0.0717 

[TRAIN] Epoch[5](497/1500); Loss: 0.073438; Backpropagation: 0.0935 sec; Batch: 0.4287 sec
0.1225 0.0941 0.0804 0.0718 0.0686 0.0676 0.0670 0.0669 0.0670 0.0668 0.0667 0.0667 0.0668 0.0671 0.0673 0.0676 

[TRAIN] Epoch[5](498/1500); Loss: 0.068896; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1571 0.1069 0.0783 0.0723 0.0670 0.0651 0.0611 0.0570 0.0546 0.0537 0.0536 0.0541 0.0547 0.0551 0.0555 0.0561 

[TRAIN] Epoch[5](499/1500); Loss: 0.053402; Backpropagation: 0.0941 sec; Batch: 0.4293 sec
0.1702 0.0913 0.0682 0.0583 0.0403 0.0527 0.0521 0.0413 0.0354 0.0350 0.0343 0.0340 0.0344 0.0353 0.0357 0.0359 

[TRAIN] Epoch[5](500/1500); Loss: 0.073433; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.1077 0.0872 0.0815 0.0783 0.0728 0.0709 0.0692 0.0680 0.0677 0.0676 0.0674 0.0675 0.0672 0.0673 0.0672 0.0673 

[TRAIN] Epoch[5](501/1500); Loss: 0.062291; Backpropagation: 0.0961 sec; Batch: 0.4316 sec
0.1395 0.0822 0.0615 0.0577 0.0561 0.0561 0.0551 0.0543 0.0539 0.0539 0.0545 0.0544 0.0543 0.0543 0.0544 0.0547 

[TRAIN] Epoch[5](502/1500); Loss: 0.046591; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1050 0.0699 0.0618 0.0575 0.0483 0.0451 0.0406 0.0376 0.0359 0.0348 0.0346 0.0347 0.0349 0.0347 0.0348 0.0351 

[TRAIN] Epoch[5](503/1500); Loss: 0.156559; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.2794 0.2304 0.2102 0.1946 0.1688 0.1561 0.1469 0.1395 0.1316 0.1267 0.1234 0.1211 0.1207 0.1198 0.1186 0.1171 

[TRAIN] Epoch[5](504/1500); Loss: 0.135993; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1997 0.1719 0.1511 0.1393 0.1314 0.1284 0.1270 0.1262 0.1254 0.1250 0.1249 0.1249 0.1250 0.1252 0.1252 0.1253 

[TRAIN] Epoch[5](505/1500); Loss: 0.068395; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1231 0.0931 0.0740 0.0672 0.0644 0.0630 0.0619 0.0605 0.0603 0.0603 0.0604 0.0607 0.0610 0.0612 0.0614 0.0617 

[TRAIN] Epoch[5](506/1500); Loss: 0.147730; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2797 0.2333 0.2188 0.2063 0.1730 0.1485 0.1329 0.1210 0.1120 0.1090 0.1084 0.1072 0.1050 0.1034 0.1027 0.1023 

[TRAIN] Epoch[5](507/1500); Loss: 0.127934; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.2074 0.1702 0.1580 0.1515 0.1309 0.1199 0.1147 0.1116 0.1087 0.1085 0.1090 0.1097 0.1108 0.1115 0.1119 0.1127 

[TRAIN] Epoch[5](508/1500); Loss: 0.046548; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1044 0.0736 0.0662 0.0609 0.0488 0.0424 0.0388 0.0365 0.0344 0.0337 0.0339 0.0338 0.0340 0.0343 0.0344 0.0345 

[TRAIN] Epoch[5](509/1500); Loss: 0.133721; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.2868 0.2399 0.1885 0.1451 0.1172 0.1100 0.1066 0.1058 0.1053 0.1051 0.1051 0.1052 0.1050 0.1050 0.1047 0.1045 

[TRAIN] Epoch[5](510/1500); Loss: 0.119583; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2534 0.2073 0.1613 0.1251 0.1072 0.0996 0.0967 0.0959 0.0956 0.0956 0.0958 0.0958 0.0959 0.0959 0.0960 0.0962 

[TRAIN] Epoch[5](511/1500); Loss: 0.111907; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2348 0.1856 0.1647 0.1501 0.1163 0.0976 0.0902 0.0843 0.0825 0.0839 0.0835 0.0831 0.0831 0.0834 0.0837 0.0837 

[TRAIN] Epoch[5](512/1500); Loss: 0.131143; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.2559 0.2130 0.1663 0.1360 0.1193 0.1135 0.1123 0.1117 0.1109 0.1101 0.1092 0.1088 0.1083 0.1080 0.1076 0.1074 

[TRAIN] Epoch[5](513/1500); Loss: 0.117833; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2244 0.2024 0.1634 0.1374 0.1190 0.1091 0.1028 0.0983 0.0953 0.0940 0.0923 0.0909 0.0898 0.0890 0.0887 0.0886 

[TRAIN] Epoch[5](514/1500); Loss: 0.113118; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1493 0.1363 0.1264 0.1180 0.1127 0.1101 0.1086 0.1077 0.1072 0.1067 0.1059 0.1050 0.1043 0.1039 0.1038 0.1039 

[TRAIN] Epoch[5](515/1500); Loss: 0.073711; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1242 0.1012 0.0849 0.0748 0.0704 0.0688 0.0674 0.0665 0.0658 0.0654 0.0653 0.0652 0.0649 0.0647 0.0648 0.0650 

[TRAIN] Epoch[5](516/1500); Loss: 0.103429; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.2892 0.2216 0.1592 0.1084 0.0794 0.0760 0.0730 0.0725 0.0716 0.0710 0.0712 0.0720 0.0724 0.0724 0.0724 0.0725 

[TRAIN] Epoch[5](517/1500); Loss: 0.104661; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.4408 0.3444 0.2571 0.1570 0.0714 0.0438 0.0378 0.0361 0.0350 0.0355 0.0357 0.0356 0.0358 0.0359 0.0362 0.0365 

[TRAIN] Epoch[5](518/1500); Loss: 0.067995; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1863 0.1405 0.0953 0.0680 0.0571 0.0528 0.0516 0.0511 0.0501 0.0491 0.0484 0.0481 0.0478 0.0475 0.0472 0.0470 

[TRAIN] Epoch[5](519/1500); Loss: 0.072419; Backpropagation: 0.0940 sec; Batch: 0.4289 sec
0.1688 0.1367 0.1000 0.0756 0.0649 0.0621 0.0596 0.0579 0.0564 0.0553 0.0543 0.0538 0.0536 0.0533 0.0532 0.0532 

[TRAIN] Epoch[5](520/1500); Loss: 0.098574; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1830 0.1515 0.1276 0.1102 0.0928 0.0873 0.0852 0.0837 0.0835 0.0831 0.0820 0.0816 0.0816 0.0817 0.0814 0.0810 

[TRAIN] Epoch[5](521/1500); Loss: 0.090214; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1971 0.1532 0.1114 0.0885 0.0792 0.0759 0.0751 0.0748 0.0748 0.0744 0.0736 0.0732 0.0731 0.0731 0.0731 0.0729 

[TRAIN] Epoch[5](522/1500); Loss: 0.101614; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.4213 0.3281 0.2368 0.1429 0.0637 0.0475 0.0408 0.0393 0.0382 0.0385 0.0385 0.0382 0.0380 0.0379 0.0381 0.0380 

[TRAIN] Epoch[5](523/1500); Loss: 0.118687; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1605 0.1488 0.1373 0.1282 0.1183 0.1142 0.1120 0.1109 0.1096 0.1091 0.1088 0.1087 0.1084 0.1084 0.1081 0.1077 

[TRAIN] Epoch[5](524/1500); Loss: 0.113640; Backpropagation: 0.0977 sec; Batch: 0.4328 sec
0.4129 0.3236 0.2411 0.1531 0.0814 0.0623 0.0566 0.0550 0.0544 0.0542 0.0541 0.0540 0.0541 0.0541 0.0538 0.0535 

[TRAIN] Epoch[5](525/1500); Loss: 0.104824; Backpropagation: 0.0998 sec; Batch: 0.4341 sec
0.3125 0.2642 0.2096 0.1552 0.1008 0.0664 0.0614 0.0580 0.0570 0.0563 0.0566 0.0562 0.0557 0.0556 0.0558 0.0558 

[TRAIN] Epoch[5](526/1500); Loss: 0.094343; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1485 0.1192 0.1059 0.1046 0.0962 0.0980 0.0983 0.0933 0.0864 0.0817 0.0808 0.0801 0.0794 0.0789 0.0790 0.0791 

[TRAIN] Epoch[5](527/1500); Loss: 0.162851; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.2109 0.1989 0.1840 0.1746 0.1667 0.1622 0.1572 0.1549 0.1530 0.1515 0.1503 0.1495 0.1487 0.1481 0.1477 0.1474 

[TRAIN] Epoch[5](528/1500); Loss: 0.070715; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1597 0.1252 0.1088 0.0954 0.0727 0.0623 0.0569 0.0551 0.0526 0.0502 0.0490 0.0485 0.0485 0.0485 0.0488 0.0493 

[TRAIN] Epoch[5](529/1500); Loss: 0.110582; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1506 0.1262 0.1139 0.1091 0.1073 0.1063 0.1058 0.1052 0.1048 0.1047 0.1047 0.1050 0.1055 0.1060 0.1068 0.1075 

[TRAIN] Epoch[5](530/1500); Loss: 0.138686; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.2112 0.1802 0.1595 0.1505 0.1435 0.1378 0.1323 0.1283 0.1245 0.1234 0.1234 0.1226 0.1215 0.1207 0.1201 0.1197 

[TRAIN] Epoch[5](531/1500); Loss: 0.137601; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.2172 0.1783 0.1626 0.1538 0.1366 0.1296 0.1274 0.1275 0.1271 0.1252 0.1233 0.1215 0.1201 0.1186 0.1168 0.1160 

[TRAIN] Epoch[5](532/1500); Loss: 0.072385; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.1721 0.1141 0.0915 0.0754 0.0695 0.0644 0.0618 0.0605 0.0587 0.0584 0.0575 0.0558 0.0546 0.0542 0.0546 0.0549 

[TRAIN] Epoch[5](533/1500); Loss: 0.085115; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1164 0.1142 0.1166 0.1124 0.1062 0.0955 0.0865 0.0790 0.0734 0.0700 0.0677 0.0661 0.0650 0.0639 0.0641 0.0649 

[TRAIN] Epoch[5](534/1500); Loss: 0.074792; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1249 0.0831 0.0711 0.0740 0.0840 0.0859 0.0795 0.0722 0.0673 0.0646 0.0642 0.0642 0.0643 0.0651 0.0659 0.0665 

[TRAIN] Epoch[5](535/1500); Loss: 0.047553; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1002 0.0769 0.0550 0.0508 0.0478 0.0450 0.0419 0.0407 0.0399 0.0391 0.0380 0.0373 0.0373 0.0371 0.0369 0.0370 

[TRAIN] Epoch[5](536/1500); Loss: 0.098665; Backpropagation: 0.0950 sec; Batch: 0.4301 sec
0.3108 0.2317 0.1680 0.1127 0.0769 0.0661 0.0642 0.0628 0.0620 0.0608 0.0604 0.0606 0.0605 0.0601 0.0603 0.0607 

[TRAIN] Epoch[5](537/1500); Loss: 0.144011; Backpropagation: 0.0939 sec; Batch: 0.4300 sec
0.3014 0.2423 0.1877 0.1531 0.1341 0.1284 0.1228 0.1196 0.1172 0.1157 0.1150 0.1146 0.1139 0.1133 0.1127 0.1123 

[TRAIN] Epoch[5](538/1500); Loss: 0.143720; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.2194 0.1961 0.1703 0.1551 0.1452 0.1387 0.1337 0.1304 0.1284 0.1271 0.1263 0.1258 0.1256 0.1256 0.1257 0.1260 

[TRAIN] Epoch[5](539/1500); Loss: 0.166901; Backpropagation: 0.0944 sec; Batch: 0.4291 sec
0.3736 0.3146 0.2837 0.2606 0.2119 0.1791 0.1569 0.1380 0.1158 0.1029 0.0965 0.0905 0.0885 0.0864 0.0861 0.0853 

[TRAIN] Epoch[5](540/1500); Loss: 0.112204; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1614 0.1486 0.1357 0.1297 0.1185 0.1118 0.1073 0.1033 0.0994 0.0971 0.0961 0.0962 0.0969 0.0975 0.0977 0.0980 

[TRAIN] Epoch[5](541/1500); Loss: 0.118259; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1882 0.1543 0.1340 0.1241 0.1151 0.1146 0.1124 0.1101 0.1074 0.1057 0.1047 0.1042 0.1041 0.1042 0.1045 0.1045 

[TRAIN] Epoch[5](542/1500); Loss: 0.102046; Backpropagation: 0.0932 sec; Batch: 0.4687 sec
0.2479 0.1845 0.1420 0.1149 0.1001 0.0907 0.0856 0.0820 0.0766 0.0732 0.0720 0.0724 0.0735 0.0733 0.0726 0.0716 

[TRAIN] Epoch[5](543/1500); Loss: 0.112251; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.2016 0.1770 0.1409 0.1219 0.1136 0.1087 0.1053 0.1019 0.0992 0.0965 0.0943 0.0917 0.0892 0.0867 0.0843 0.0830 

[TRAIN] Epoch[5](544/1500); Loss: 0.169740; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2203 0.2086 0.1914 0.1838 0.1772 0.1736 0.1703 0.1677 0.1643 0.1603 0.1564 0.1535 0.1504 0.1479 0.1457 0.1443 

[TRAIN] Epoch[5](545/1500); Loss: 0.056781; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1447 0.1046 0.0812 0.0634 0.0484 0.0456 0.0452 0.0437 0.0430 0.0427 0.0419 0.0410 0.0406 0.0406 0.0409 0.0409 

[TRAIN] Epoch[5](546/1500); Loss: 0.202358; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2519 0.2435 0.2237 0.2170 0.2116 0.2065 0.2026 0.1984 0.1948 0.1912 0.1882 0.1856 0.1832 0.1815 0.1797 0.1784 

[TRAIN] Epoch[5](547/1500); Loss: 0.072958; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1437 0.1195 0.1029 0.0890 0.0727 0.0630 0.0605 0.0594 0.0579 0.0569 0.0565 0.0569 0.0571 0.0571 0.0570 0.0571 

[TRAIN] Epoch[5](548/1500); Loss: 0.094538; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.1408 0.1263 0.1092 0.1020 0.0949 0.0921 0.0894 0.0875 0.0853 0.0839 0.0828 0.0827 0.0828 0.0835 0.0843 0.0853 

[TRAIN] Epoch[5](549/1500); Loss: 0.118105; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.2008 0.1598 0.1376 0.1246 0.1202 0.1140 0.1066 0.1051 0.1042 0.1031 0.1026 0.1025 0.1026 0.1024 0.1019 0.1016 

[TRAIN] Epoch[5](550/1500); Loss: 0.138150; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2410 0.2005 0.1687 0.1462 0.1308 0.1240 0.1212 0.1207 0.1211 0.1203 0.1193 0.1192 0.1192 0.1193 0.1194 0.1195 

[TRAIN] Epoch[5](551/1500); Loss: 0.104593; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.1283 0.1169 0.1089 0.1070 0.1065 0.1045 0.1023 0.1014 0.1008 0.1003 0.0999 0.0997 0.0994 0.0990 0.0991 0.0994 

[TRAIN] Epoch[5](552/1500); Loss: 0.084172; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1522 0.1254 0.1105 0.0967 0.0854 0.0791 0.0745 0.0721 0.0705 0.0696 0.0691 0.0689 0.0683 0.0682 0.0681 0.0681 

[TRAIN] Epoch[5](553/1500); Loss: 0.134959; Backpropagation: 0.0936 sec; Batch: 0.4286 sec
0.2655 0.2105 0.1726 0.1397 0.1215 0.1173 0.1167 0.1157 0.1138 0.1129 0.1123 0.1121 0.1121 0.1124 0.1122 0.1120 

[TRAIN] Epoch[5](554/1500); Loss: 0.149494; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.4625 0.3437 0.3034 0.2698 0.1731 0.1053 0.0787 0.0671 0.0824 0.0848 0.0780 0.0689 0.0684 0.0689 0.0686 0.0683 

[TRAIN] Epoch[5](555/1500); Loss: 0.137611; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.1824 0.1668 0.1508 0.1444 0.1397 0.1354 0.1320 0.1303 0.1287 0.1280 0.1278 0.1277 0.1272 0.1268 0.1268 0.1269 

[TRAIN] Epoch[5](556/1500); Loss: 0.066750; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1139 0.0979 0.0799 0.0683 0.0630 0.0608 0.0584 0.0573 0.0566 0.0566 0.0569 0.0577 0.0586 0.0594 0.0606 0.0622 

[TRAIN] Epoch[5](557/1500); Loss: 0.051172; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.0667 0.0600 0.0576 0.0510 0.0501 0.0485 0.0481 0.0482 0.0484 0.0483 0.0481 0.0480 0.0484 0.0486 0.0492 0.0494 

[TRAIN] Epoch[5](558/1500); Loss: 0.119279; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1696 0.1404 0.1245 0.1164 0.1142 0.1129 0.1129 0.1130 0.1129 0.1126 0.1126 0.1128 0.1131 0.1133 0.1135 0.1137 

[TRAIN] Epoch[5](559/1500); Loss: 0.068693; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1472 0.0851 0.0738 0.0650 0.0608 0.0603 0.0604 0.0606 0.0603 0.0600 0.0601 0.0604 0.0606 0.0609 0.0615 0.0620 

[TRAIN] Epoch[5](560/1500); Loss: 0.058651; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1719 0.0781 0.0494 0.0468 0.0462 0.0464 0.0526 0.0519 0.0504 0.0487 0.0476 0.0478 0.0491 0.0506 0.0505 0.0506 

[TRAIN] Epoch[5](561/1500); Loss: 0.093312; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2316 0.1673 0.1380 0.1127 0.0853 0.0750 0.0709 0.0697 0.0685 0.0680 0.0670 0.0669 0.0675 0.0681 0.0681 0.0684 

[TRAIN] Epoch[5](562/1500); Loss: 0.101011; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2013 0.1576 0.1282 0.1050 0.0944 0.0915 0.0889 0.0873 0.0857 0.0844 0.0832 0.0825 0.0822 0.0817 0.0813 0.0811 

[TRAIN] Epoch[5](563/1500); Loss: 0.068014; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.2019 0.1398 0.1042 0.0761 0.0581 0.0532 0.0490 0.0471 0.0456 0.0457 0.0451 0.0447 0.0444 0.0442 0.0445 0.0445 

[TRAIN] Epoch[5](564/1500); Loss: 0.047572; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1220 0.0757 0.0515 0.0482 0.0452 0.0420 0.0404 0.0410 0.0398 0.0384 0.0372 0.0368 0.0366 0.0360 0.0355 0.0351 

[TRAIN] Epoch[5](565/1500); Loss: 0.088179; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1296 0.1096 0.0972 0.0903 0.0846 0.0830 0.0830 0.0823 0.0817 0.0812 0.0809 0.0808 0.0813 0.0816 0.0817 0.0820 

[TRAIN] Epoch[5](566/1500); Loss: 0.095513; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.2652 0.1964 0.1730 0.1532 0.0975 0.0722 0.0608 0.0527 0.0580 0.0564 0.0557 0.0560 0.0565 0.0574 0.0582 0.0588 

[TRAIN] Epoch[5](567/1500); Loss: 0.127443; Backpropagation: 0.0944 sec; Batch: 0.4287 sec
0.1814 0.1598 0.1469 0.1363 0.1265 0.1225 0.1198 0.1187 0.1178 0.1170 0.1163 0.1158 0.1155 0.1151 0.1148 0.1147 

[TRAIN] Epoch[5](568/1500); Loss: 0.096162; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1855 0.1432 0.1266 0.1165 0.0969 0.0895 0.0849 0.0815 0.0804 0.0791 0.0776 0.0763 0.0757 0.0751 0.0750 0.0747 

[TRAIN] Epoch[5](569/1500); Loss: 0.102390; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1873 0.1456 0.1199 0.1051 0.0964 0.0928 0.0913 0.0904 0.0897 0.0894 0.0890 0.0884 0.0881 0.0880 0.0880 0.0889 

[TRAIN] Epoch[5](570/1500); Loss: 0.098327; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2250 0.1650 0.1256 0.0971 0.0865 0.0827 0.0810 0.0799 0.0798 0.0792 0.0794 0.0790 0.0785 0.0780 0.0782 0.0783 

[TRAIN] Epoch[5](571/1500); Loss: 0.085509; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.2079 0.1357 0.1041 0.0914 0.0789 0.0733 0.0701 0.0694 0.0681 0.0666 0.0665 0.0672 0.0673 0.0668 0.0669 0.0680 

[TRAIN] Epoch[5](572/1500); Loss: 0.167675; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2614 0.2232 0.1936 0.1779 0.1673 0.1604 0.1561 0.1535 0.1513 0.1499 0.1493 0.1492 0.1483 0.1475 0.1470 0.1471 

[TRAIN] Epoch[5](573/1500); Loss: 0.101670; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1456 0.1181 0.1047 0.0997 0.0992 0.0991 0.0972 0.0965 0.0959 0.0955 0.0954 0.0956 0.0957 0.0958 0.0960 0.0965 

[TRAIN] Epoch[5](574/1500); Loss: 0.090553; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.4177 0.3016 0.2146 0.1192 0.0431 0.0327 0.0297 0.0312 0.0304 0.0333 0.0314 0.0310 0.0310 0.0339 0.0340 0.0340 

[TRAIN] Epoch[5](575/1500); Loss: 0.146315; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.4507 0.3345 0.2953 0.2612 0.1731 0.1177 0.0866 0.0714 0.0731 0.0733 0.0705 0.0664 0.0663 0.0665 0.0668 0.0674 

[TRAIN] Epoch[5](576/1500); Loss: 0.130858; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2138 0.1708 0.1556 0.1462 0.1322 0.1278 0.1220 0.1183 0.1156 0.1142 0.1135 0.1129 0.1127 0.1127 0.1126 0.1126 

[TRAIN] Epoch[5](577/1500); Loss: 0.098099; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1702 0.1335 0.1170 0.1024 0.0986 0.0921 0.0890 0.0876 0.0868 0.0860 0.0853 0.0846 0.0844 0.0842 0.0839 0.0840 

[TRAIN] Epoch[5](578/1500); Loss: 0.147483; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2088 0.1825 0.1685 0.1571 0.1481 0.1461 0.1424 0.1397 0.1373 0.1359 0.1343 0.1333 0.1324 0.1317 0.1312 0.1305 

[TRAIN] Epoch[5](579/1500); Loss: 0.078009; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2254 0.1583 0.1318 0.1098 0.0683 0.0576 0.0502 0.0512 0.0521 0.0492 0.0482 0.0486 0.0488 0.0490 0.0494 0.0503 

[TRAIN] Epoch[5](580/1500); Loss: 0.104359; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2992 0.2247 0.1672 0.1236 0.0962 0.0785 0.0694 0.0694 0.0687 0.0679 0.0675 0.0672 0.0671 0.0671 0.0676 0.0685 

[TRAIN] Epoch[5](581/1500); Loss: 0.121468; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1731 0.1536 0.1394 0.1309 0.1230 0.1177 0.1134 0.1113 0.1102 0.1100 0.1098 0.1100 0.1098 0.1101 0.1105 0.1108 

[TRAIN] Epoch[5](582/1500); Loss: 0.038586; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.0891 0.0595 0.0488 0.0385 0.0356 0.0406 0.0322 0.0302 0.0304 0.0302 0.0297 0.0299 0.0304 0.0307 0.0305 0.0310 

[TRAIN] Epoch[5](583/1500); Loss: 0.117209; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.2129 0.1660 0.1406 0.1236 0.1138 0.1110 0.1073 0.1034 0.1017 0.1009 0.0997 0.0991 0.0986 0.0989 0.0990 0.0990 

[TRAIN] Epoch[5](584/1500); Loss: 0.051563; Backpropagation: 0.0941 sec; Batch: 0.4415 sec
0.0523 0.0574 0.0627 0.0480 0.0498 0.0460 0.0458 0.0461 0.0491 0.0509 0.0501 0.0501 0.0514 0.0552 0.0551 0.0549 

[TRAIN] Epoch[5](585/1500); Loss: 0.091641; Backpropagation: 0.0937 sec; Batch: 0.4306 sec
0.2510 0.1805 0.1334 0.0916 0.0721 0.0684 0.0685 0.0677 0.0684 0.0668 0.0667 0.0664 0.0668 0.0663 0.0659 0.0657 

[TRAIN] Epoch[5](586/1500); Loss: 0.163803; Backpropagation: 0.0938 sec; Batch: 0.4275 sec
0.2292 0.2030 0.1884 0.1752 0.1648 0.1580 0.1518 0.1497 0.1493 0.1495 0.1495 0.1495 0.1499 0.1506 0.1509 0.1514 

[TRAIN] Epoch[5](587/1500); Loss: 0.109271; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.3145 0.2208 0.1866 0.1606 0.1007 0.0806 0.0754 0.0780 0.0738 0.0681 0.0635 0.0642 0.0642 0.0640 0.0651 0.0682 

[TRAIN] Epoch[5](588/1500); Loss: 0.109193; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1881 0.1381 0.1158 0.1038 0.1043 0.1081 0.1028 0.0997 0.0980 0.0975 0.0980 0.0987 0.0982 0.0980 0.0989 0.0991 

[TRAIN] Epoch[5](589/1500); Loss: 0.201643; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.3949 0.3216 0.2893 0.2651 0.1988 0.1649 0.1566 0.1630 0.1657 0.1621 0.1581 0.1566 0.1564 0.1569 0.1577 0.1586 

[TRAIN] Epoch[5](590/1500); Loss: 0.108422; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2616 0.1860 0.1521 0.1281 0.0935 0.1027 0.0958 0.0857 0.0798 0.0784 0.0782 0.0783 0.0787 0.0784 0.0788 0.0789 

[TRAIN] Epoch[5](591/1500); Loss: 0.101679; Backpropagation: 0.0939 sec; Batch: 0.4300 sec
0.1769 0.1347 0.1133 0.1006 0.0953 0.0934 0.0926 0.0910 0.0906 0.0918 0.0915 0.0907 0.0906 0.0910 0.0915 0.0912 

[TRAIN] Epoch[5](592/1500); Loss: 0.073817; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.1220 0.0918 0.0853 0.0751 0.0737 0.0749 0.0701 0.0670 0.0656 0.0649 0.0648 0.0649 0.0647 0.0654 0.0656 0.0652 

[TRAIN] Epoch[5](593/1500); Loss: 0.135035; Backpropagation: 0.0939 sec; Batch: 0.4310 sec
0.2353 0.1921 0.1642 0.1438 0.1301 0.1233 0.1183 0.1175 0.1168 0.1165 0.1166 0.1168 0.1170 0.1173 0.1174 0.1175 

[TRAIN] Epoch[5](594/1500); Loss: 0.135505; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2002 0.1724 0.1566 0.1415 0.1329 0.1282 0.1253 0.1247 0.1242 0.1235 0.1231 0.1231 0.1227 0.1230 0.1231 0.1236 

[TRAIN] Epoch[5](595/1500); Loss: 0.093676; Backpropagation: 0.0981 sec; Batch: 0.4325 sec
0.1677 0.1346 0.1158 0.1002 0.0935 0.0913 0.0844 0.0794 0.0771 0.0768 0.0773 0.0780 0.0791 0.0802 0.0811 0.0823 

[TRAIN] Epoch[5](596/1500); Loss: 0.110350; Backpropagation: 0.0956 sec; Batch: 0.4299 sec
0.1524 0.1529 0.1427 0.1230 0.1106 0.1067 0.1032 0.0999 0.0986 0.0977 0.0968 0.0957 0.0961 0.0968 0.0964 0.0959 

[TRAIN] Epoch[5](597/1500); Loss: 0.096585; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2706 0.2024 0.1626 0.1306 0.0785 0.0638 0.0713 0.0711 0.0627 0.0609 0.0614 0.0611 0.0611 0.0626 0.0623 0.0624 

[TRAIN] Epoch[5](598/1500); Loss: 0.083802; Backpropagation: 0.0931 sec; Batch: 0.4279 sec
0.1322 0.1159 0.0980 0.0860 0.0786 0.0763 0.0749 0.0754 0.0754 0.0751 0.0747 0.0752 0.0754 0.0758 0.0756 0.0762 

[TRAIN] Epoch[5](599/1500); Loss: 0.099924; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1835 0.1547 0.1418 0.1171 0.0991 0.0875 0.0837 0.0826 0.0820 0.0818 0.0821 0.0810 0.0804 0.0807 0.0806 0.0802 

[TRAIN] Epoch[5](600/1500); Loss: 0.076774; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1745 0.0961 0.0643 0.0531 0.0897 0.1076 0.0892 0.0805 0.0697 0.0627 0.0586 0.0566 0.0549 0.0562 0.0571 0.0576 

[TRAIN] Epoch[5](601/1500); Loss: 0.090597; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1965 0.1489 0.1182 0.0934 0.0840 0.0780 0.0749 0.0727 0.0721 0.0716 0.0722 0.0722 0.0725 0.0731 0.0741 0.0751 

[TRAIN] Epoch[5](602/1500); Loss: 0.060453; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1171 0.0922 0.0817 0.0706 0.0604 0.0582 0.0526 0.0509 0.0493 0.0485 0.0477 0.0474 0.0475 0.0477 0.0476 0.0477 

[TRAIN] Epoch[5](603/1500); Loss: 0.112267; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.1735 0.1501 0.1288 0.1162 0.1106 0.1088 0.1065 0.1043 0.1021 0.1003 0.0999 0.0988 0.0985 0.0989 0.0993 0.0997 

[TRAIN] Epoch[5](604/1500); Loss: 0.130573; Backpropagation: 0.0931 sec; Batch: 0.4264 sec
0.2555 0.1975 0.1706 0.1511 0.1166 0.1299 0.1292 0.1204 0.1099 0.1046 0.1024 0.1012 0.1013 0.1004 0.0996 0.0991 

[TRAIN] Epoch[5](605/1500); Loss: 0.091631; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1914 0.1471 0.1202 0.0956 0.0812 0.0786 0.0776 0.0766 0.0755 0.0746 0.0745 0.0744 0.0743 0.0748 0.0750 0.0749 

[TRAIN] Epoch[5](606/1500); Loss: 0.084899; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1468 0.1124 0.1077 0.0952 0.0864 0.0793 0.0770 0.0743 0.0722 0.0725 0.0719 0.0714 0.0721 0.0727 0.0736 0.0730 

[TRAIN] Epoch[5](607/1500); Loss: 0.094316; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.2018 0.1536 0.1225 0.1002 0.0896 0.0847 0.0806 0.0774 0.0761 0.0756 0.0750 0.0747 0.0744 0.0743 0.0742 0.0742 

[TRAIN] Epoch[5](608/1500); Loss: 0.140073; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2986 0.2359 0.2006 0.1697 0.1347 0.1201 0.1134 0.1115 0.1127 0.1099 0.1079 0.1067 0.1055 0.1050 0.1046 0.1045 

[TRAIN] Epoch[5](609/1500); Loss: 0.135308; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.2520 0.2038 0.1756 0.1546 0.1392 0.1266 0.1171 0.1123 0.1116 0.1107 0.1103 0.1105 0.1104 0.1102 0.1101 0.1102 

[TRAIN] Epoch[5](610/1500); Loss: 0.122150; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2530 0.1918 0.1591 0.1305 0.1069 0.1120 0.1108 0.1073 0.1001 0.0968 0.0974 0.0975 0.0974 0.0973 0.0980 0.0985 

[TRAIN] Epoch[5](611/1500); Loss: 0.118264; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.2251 0.1796 0.1600 0.1477 0.1183 0.1071 0.0999 0.0980 0.0983 0.0976 0.0944 0.0931 0.0932 0.0935 0.0935 0.0932 

[TRAIN] Epoch[5](612/1500); Loss: 0.095139; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.1067 0.1099 0.1065 0.0969 0.0941 0.0929 0.0923 0.0920 0.0916 0.0913 0.0914 0.0914 0.0913 0.0912 0.0913 0.0915 

[TRAIN] Epoch[5](613/1500); Loss: 0.100600; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1529 0.1292 0.1276 0.1163 0.1016 0.0953 0.0921 0.0907 0.0892 0.0886 0.0880 0.0885 0.0879 0.0873 0.0870 0.0874 

[TRAIN] Epoch[5](614/1500); Loss: 0.141504; Backpropagation: 0.0931 sec; Batch: 0.4263 sec
0.1769 0.1676 0.1581 0.1472 0.1415 0.1391 0.1370 0.1356 0.1344 0.1337 0.1331 0.1327 0.1323 0.1320 0.1316 0.1314 

[TRAIN] Epoch[5](615/1500); Loss: 0.148587; Backpropagation: 0.0930 sec; Batch: 0.4273 sec
0.2102 0.1724 0.1562 0.1513 0.1567 0.1504 0.1410 0.1388 0.1384 0.1379 0.1374 0.1373 0.1375 0.1375 0.1372 0.1372 

[TRAIN] Epoch[5](616/1500); Loss: 0.055759; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1185 0.0784 0.0636 0.0643 0.0581 0.0542 0.0506 0.0482 0.0465 0.0457 0.0450 0.0443 0.0440 0.0437 0.0435 0.0437 

[TRAIN] Epoch[5](617/1500); Loss: 0.107200; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.2226 0.1691 0.1375 0.1093 0.0963 0.0916 0.0898 0.0895 0.0896 0.0884 0.0880 0.0881 0.0889 0.0887 0.0889 0.0890 

[TRAIN] Epoch[5](618/1500); Loss: 0.131953; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.2192 0.1845 0.1650 0.1404 0.1278 0.1211 0.1175 0.1165 0.1161 0.1157 0.1151 0.1144 0.1145 0.1146 0.1144 0.1143 

[TRAIN] Epoch[5](619/1500); Loss: 0.041632; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.0929 0.0575 0.0477 0.0447 0.0424 0.0388 0.0365 0.0363 0.0352 0.0345 0.0334 0.0337 0.0331 0.0331 0.0328 0.0336 

[TRAIN] Epoch[5](620/1500); Loss: 0.098722; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1895 0.1374 0.1083 0.1012 0.0929 0.0895 0.0882 0.0869 0.0862 0.0863 0.0859 0.0853 0.0855 0.0857 0.0854 0.0852 

[TRAIN] Epoch[5](621/1500); Loss: 0.105091; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.4053 0.2956 0.2164 0.1241 0.0691 0.0509 0.0537 0.0508 0.0512 0.0506 0.0509 0.0515 0.0517 0.0517 0.0532 0.0547 

[TRAIN] Epoch[5](622/1500); Loss: 0.104430; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1311 0.1200 0.1105 0.1076 0.1053 0.1035 0.1023 0.1012 0.1005 0.0998 0.0989 0.0983 0.0981 0.0981 0.0979 0.0977 

[TRAIN] Epoch[5](623/1500); Loss: 0.087838; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.2175 0.1523 0.1145 0.0868 0.0754 0.0715 0.0714 0.0696 0.0691 0.0680 0.0675 0.0683 0.0682 0.0683 0.0682 0.0688 

[TRAIN] Epoch[5](624/1500); Loss: 0.080420; Backpropagation: 0.0939 sec; Batch: 0.4274 sec
0.3542 0.2323 0.1392 0.0595 0.0508 0.0348 0.0353 0.0381 0.0452 0.0410 0.0407 0.0399 0.0406 0.0441 0.0448 0.0463 

[TRAIN] Epoch[5](625/1500); Loss: 0.147192; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2784 0.2145 0.1842 0.1643 0.1289 0.1221 0.1208 0.1218 0.1221 0.1233 0.1244 0.1259 0.1280 0.1295 0.1327 0.1341 

[TRAIN] Epoch[5](626/1500); Loss: 0.115531; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1988 0.1558 0.1260 0.1105 0.1095 0.1071 0.1058 0.1048 0.1046 0.1042 0.1037 0.1033 0.1033 0.1037 0.1036 0.1038 

[TRAIN] Epoch[5](627/1500); Loss: 0.065803; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1281 0.0874 0.0704 0.0634 0.0615 0.0599 0.0592 0.0593 0.0588 0.0587 0.0582 0.0578 0.0576 0.0578 0.0573 0.0573 

[TRAIN] Epoch[5](628/1500); Loss: 0.098037; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2662 0.1753 0.1281 0.0981 0.0861 0.0816 0.0771 0.0739 0.0755 0.0742 0.0727 0.0717 0.0714 0.0713 0.0725 0.0731 

[TRAIN] Epoch[5](629/1500); Loss: 0.120950; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.1528 0.1351 0.1275 0.1240 0.1217 0.1194 0.1183 0.1177 0.1165 0.1153 0.1147 0.1144 0.1142 0.1144 0.1146 0.1147 

[TRAIN] Epoch[5](630/1500); Loss: 0.151048; Backpropagation: 0.0981 sec; Batch: 0.4334 sec
0.1547 0.1614 0.1562 0.1524 0.1511 0.1508 0.1504 0.1487 0.1484 0.1487 0.1490 0.1491 0.1491 0.1488 0.1488 0.1491 

[TRAIN] Epoch[5](631/1500); Loss: 0.128371; Backpropagation: 0.0957 sec; Batch: 0.4307 sec
0.2168 0.1815 0.1665 0.1560 0.1354 0.1224 0.1139 0.1089 0.1067 0.1073 0.1070 0.1067 0.1060 0.1058 0.1062 0.1068 

[TRAIN] Epoch[5](632/1500); Loss: 0.074212; Backpropagation: 0.0933 sec; Batch: 0.4265 sec
0.0898 0.0822 0.0773 0.0726 0.0713 0.0707 0.0714 0.0714 0.0711 0.0709 0.0721 0.0722 0.0726 0.0730 0.0742 0.0748 

[TRAIN] Epoch[5](633/1500); Loss: 0.085957; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1279 0.0981 0.0902 0.0871 0.0822 0.0814 0.0805 0.0802 0.0802 0.0799 0.0798 0.0806 0.0811 0.0817 0.0820 0.0824 

[TRAIN] Epoch[5](634/1500); Loss: 0.140026; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.4733 0.3436 0.2787 0.2395 0.1186 0.0702 0.0782 0.0625 0.0862 0.0751 0.0703 0.0682 0.0674 0.0697 0.0703 0.0686 

[TRAIN] Epoch[5](635/1500); Loss: 0.097000; Backpropagation: 0.0930 sec; Batch: 0.4265 sec
0.1809 0.1273 0.1078 0.0952 0.0953 0.0923 0.0886 0.0876 0.0861 0.0852 0.0844 0.0838 0.0842 0.0846 0.0844 0.0843 

[TRAIN] Epoch[5](636/1500); Loss: 0.084480; Backpropagation: 0.0980 sec; Batch: 0.4325 sec
0.2461 0.1690 0.1117 0.0607 0.0821 0.0704 0.0668 0.0614 0.0583 0.0577 0.0619 0.0620 0.0607 0.0603 0.0609 0.0616 

[TRAIN] Epoch[5](637/1500); Loss: 0.069737; Backpropagation: 0.0957 sec; Batch: 0.4297 sec
0.2424 0.1532 0.0817 0.0461 0.0492 0.0474 0.0499 0.0510 0.0492 0.0481 0.0475 0.0497 0.0499 0.0499 0.0502 0.0505 

[TRAIN] Epoch[5](638/1500); Loss: 0.154827; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2473 0.1886 0.1527 0.1408 0.1332 0.1228 0.1219 0.1248 0.1319 0.1386 0.1447 0.1515 0.1588 0.1662 0.1732 0.1802 

[TRAIN] Epoch[5](639/1500); Loss: 0.109831; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1475 0.0952 0.0872 0.0791 0.0822 0.0826 0.0865 0.0929 0.1006 0.1076 0.1144 0.1214 0.1280 0.1361 0.1442 0.1519 

[TRAIN] Epoch[5](640/1500); Loss: 0.151003; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1854 0.1253 0.1106 0.1140 0.1208 0.1292 0.1370 0.1455 0.1527 0.1576 0.1616 0.1659 0.1706 0.1757 0.1800 0.1840 

[TRAIN] Epoch[5](641/1500); Loss: 0.183381; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.2311 0.1793 0.1573 0.1615 0.1576 0.1565 0.1611 0.1690 0.1770 0.1828 0.1883 0.1937 0.1987 0.2028 0.2070 0.2106 

[TRAIN] Epoch[5](642/1500); Loss: 0.118281; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.1415 0.1168 0.1083 0.1033 0.1014 0.1009 0.1016 0.1038 0.1083 0.1133 0.1184 0.1242 0.1297 0.1347 0.1402 0.1460 

[TRAIN] Epoch[5](643/1500); Loss: 0.164752; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1271 0.1159 0.1176 0.1198 0.1249 0.1302 0.1384 0.1484 0.1596 0.1716 0.1835 0.1951 0.2072 0.2194 0.2324 0.2449 

[TRAIN] Epoch[5](644/1500); Loss: 0.182037; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2135 0.1873 0.1881 0.1864 0.1784 0.1738 0.1742 0.1747 0.1752 0.1762 0.1775 0.1788 0.1802 0.1815 0.1828 0.1840 

[TRAIN] Epoch[5](645/1500); Loss: 0.097867; Backpropagation: 0.0931 sec; Batch: 0.4276 sec
0.1214 0.1013 0.1017 0.1003 0.0959 0.0925 0.0915 0.0920 0.0925 0.0930 0.0940 0.0947 0.0965 0.0985 0.0994 0.1007 

[TRAIN] Epoch[5](646/1500); Loss: 0.097843; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2195 0.1453 0.0895 0.1040 0.0917 0.0889 0.0844 0.0818 0.0817 0.0812 0.0804 0.0836 0.0839 0.0832 0.0832 0.0832 

[TRAIN] Epoch[5](647/1500); Loss: 0.070855; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1105 0.0741 0.0694 0.0712 0.0677 0.0758 0.0737 0.0710 0.0680 0.0659 0.0649 0.0641 0.0641 0.0641 0.0643 0.0647 

[TRAIN] Epoch[5](648/1500); Loss: 0.068602; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1115 0.0852 0.0676 0.0673 0.0644 0.0648 0.0640 0.0628 0.0627 0.0627 0.0629 0.0641 0.0641 0.0639 0.0646 0.0651 

[TRAIN] Epoch[5](649/1500); Loss: 0.158254; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.2144 0.1841 0.1724 0.1693 0.1632 0.1583 0.1542 0.1518 0.1499 0.1479 0.1464 0.1451 0.1441 0.1436 0.1437 0.1436 

[TRAIN] Epoch[5](650/1500); Loss: 0.064023; Backpropagation: 0.0939 sec; Batch: 0.4321 sec
0.1324 0.0649 0.0695 0.0590 0.0624 0.0593 0.0569 0.0569 0.0565 0.0577 0.0574 0.0578 0.0578 0.0578 0.0580 0.0600 

[TRAIN] Epoch[5](651/1500); Loss: 0.159728; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.2572 0.2065 0.1926 0.1780 0.1516 0.1496 0.1500 0.1454 0.1427 0.1421 0.1410 0.1403 0.1391 0.1393 0.1402 0.1398 

[TRAIN] Epoch[5](652/1500); Loss: 0.098493; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2608 0.1852 0.1208 0.1118 0.0974 0.0847 0.0820 0.0789 0.0725 0.0690 0.0678 0.0662 0.0689 0.0695 0.0699 0.0703 

[TRAIN] Epoch[5](653/1500); Loss: 0.110836; Backpropagation: 0.0955 sec; Batch: 0.4307 sec
0.2095 0.1603 0.1214 0.1097 0.1070 0.1057 0.1031 0.0984 0.0968 0.0943 0.0954 0.0955 0.0956 0.0943 0.0935 0.0929 

[TRAIN] Epoch[5](654/1500); Loss: 0.142896; Backpropagation: 0.0958 sec; Batch: 0.4313 sec
0.1841 0.1617 0.1609 0.1541 0.1456 0.1388 0.1371 0.1348 0.1358 0.1349 0.1344 0.1333 0.1329 0.1326 0.1327 0.1327 

[TRAIN] Epoch[5](655/1500); Loss: 0.088357; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1800 0.1318 0.0989 0.0756 0.0819 0.0777 0.0767 0.0752 0.0733 0.0768 0.0765 0.0769 0.0774 0.0778 0.0777 0.0797 

[TRAIN] Epoch[5](656/1500); Loss: 0.175784; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2761 0.2323 0.2243 0.2030 0.1940 0.1785 0.1671 0.1600 0.1555 0.1493 0.1463 0.1458 0.1452 0.1448 0.1449 0.1455 

[TRAIN] Epoch[5](657/1500); Loss: 0.123729; Backpropagation: 0.0933 sec; Batch: 0.4347 sec
0.1809 0.1510 0.1516 0.1428 0.1363 0.1240 0.1158 0.1126 0.1094 0.1083 0.1078 0.1077 0.1078 0.1076 0.1077 0.1083 

[TRAIN] Epoch[5](658/1500); Loss: 0.128238; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1518 0.1442 0.1360 0.1337 0.1302 0.1284 0.1264 0.1243 0.1237 0.1219 0.1208 0.1206 0.1216 0.1223 0.1229 0.1228 

[TRAIN] Epoch[5](659/1500); Loss: 0.142876; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2448 0.1979 0.1775 0.1609 0.1551 0.1400 0.1306 0.1249 0.1227 0.1206 0.1191 0.1178 0.1178 0.1172 0.1194 0.1197 

[TRAIN] Epoch[5](660/1500); Loss: 0.111911; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1739 0.1418 0.1364 0.1255 0.1210 0.1133 0.1070 0.1028 0.0994 0.0986 0.0982 0.0968 0.0951 0.0942 0.0935 0.0931 

[TRAIN] Epoch[5](661/1500); Loss: 0.071613; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1680 0.1076 0.0748 0.0704 0.0654 0.0631 0.0630 0.0611 0.0594 0.0578 0.0576 0.0595 0.0611 0.0600 0.0587 0.0583 

[TRAIN] Epoch[5](662/1500); Loss: 0.192421; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2948 0.2501 0.2497 0.2313 0.2219 0.2026 0.1883 0.1764 0.1710 0.1657 0.1613 0.1578 0.1549 0.1521 0.1508 0.1502 

[TRAIN] Epoch[5](663/1500); Loss: 0.178829; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.2677 0.2302 0.2275 0.2101 0.2028 0.1930 0.1796 0.1696 0.1641 0.1546 0.1487 0.1457 0.1433 0.1416 0.1414 0.1413 

[TRAIN] Epoch[5](664/1500); Loss: 0.150770; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2135 0.1772 0.1714 0.1597 0.1561 0.1497 0.1445 0.1407 0.1403 0.1392 0.1379 0.1372 0.1370 0.1365 0.1358 0.1355 

[TRAIN] Epoch[5](665/1500); Loss: 0.079785; Backpropagation: 0.0940 sec; Batch: 0.4334 sec
0.1666 0.1142 0.0836 0.0801 0.0795 0.0745 0.0720 0.0696 0.0669 0.0652 0.0662 0.0673 0.0675 0.0680 0.0677 0.0677 

[TRAIN] Epoch[5](666/1500); Loss: 0.063684; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1556 0.0864 0.0617 0.0569 0.0520 0.0584 0.0589 0.0552 0.0569 0.0544 0.0538 0.0528 0.0532 0.0538 0.0538 0.0552 

[TRAIN] Epoch[5](667/1500); Loss: 0.098958; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2120 0.1666 0.1634 0.1436 0.1310 0.1101 0.0916 0.0805 0.0724 0.0628 0.0577 0.0583 0.0584 0.0578 0.0581 0.0590 

[TRAIN] Epoch[5](668/1500); Loss: 0.121800; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2281 0.1876 0.1838 0.1715 0.1555 0.1341 0.1180 0.1069 0.0988 0.0889 0.0838 0.0801 0.0793 0.0773 0.0769 0.0780 

[TRAIN] Epoch[5](669/1500); Loss: 0.154912; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.3031 0.2518 0.2346 0.2054 0.1971 0.1783 0.1587 0.1442 0.1330 0.1149 0.1010 0.0941 0.0911 0.0893 0.0911 0.0909 

[TRAIN] Epoch[5](670/1500); Loss: 0.161775; Backpropagation: 0.0940 sec; Batch: 0.4276 sec
0.2616 0.2224 0.2059 0.1841 0.1752 0.1613 0.1532 0.1452 0.1410 0.1360 0.1340 0.1333 0.1339 0.1334 0.1331 0.1348 

[TRAIN] Epoch[5](671/1500); Loss: 0.142425; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.2099 0.1820 0.1796 0.1649 0.1572 0.1427 0.1330 0.1295 0.1274 0.1240 0.1218 0.1207 0.1211 0.1212 0.1210 0.1228 

[TRAIN] Epoch[5](672/1500); Loss: 0.252942; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.5424 0.4598 0.4474 0.3868 0.3609 0.2982 0.2616 0.2173 0.1879 0.1337 0.1144 0.1186 0.1303 0.1306 0.1292 0.1280 

[TRAIN] Epoch[5](673/1500); Loss: 0.196858; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.3596 0.3052 0.2852 0.2495 0.2348 0.2066 0.1887 0.1727 0.1635 0.1485 0.1412 0.1379 0.1367 0.1370 0.1390 0.1435 

[TRAIN] Epoch[5](674/1500); Loss: 0.160797; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1871 0.1754 0.1720 0.1649 0.1618 0.1581 0.1575 0.1568 0.1563 0.1563 0.1556 0.1546 0.1543 0.1542 0.1537 0.1541 

[TRAIN] Epoch[5](675/1500); Loss: 0.150107; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1945 0.1749 0.1758 0.1658 0.1624 0.1542 0.1481 0.1458 0.1441 0.1397 0.1356 0.1335 0.1322 0.1316 0.1320 0.1316 

[TRAIN] Epoch[5](676/1500); Loss: 0.132363; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2158 0.1737 0.1481 0.1336 0.1293 0.1263 0.1234 0.1223 0.1204 0.1200 0.1186 0.1174 0.1171 0.1169 0.1181 0.1170 

[TRAIN] Epoch[5](677/1500); Loss: 0.110538; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1636 0.1322 0.1147 0.1138 0.1093 0.1059 0.1042 0.1023 0.1023 0.1014 0.1029 0.1033 0.1029 0.1031 0.1031 0.1037 

[TRAIN] Epoch[5](678/1500); Loss: 0.128381; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1884 0.1600 0.1558 0.1449 0.1381 0.1282 0.1218 0.1161 0.1138 0.1123 0.1120 0.1125 0.1120 0.1124 0.1128 0.1129 

[TRAIN] Epoch[5](679/1500); Loss: 0.135731; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1818 0.1574 0.1480 0.1368 0.1358 0.1315 0.1297 0.1296 0.1282 0.1275 0.1268 0.1273 0.1274 0.1272 0.1280 0.1289 

[TRAIN] Epoch[5](680/1500); Loss: 0.052516; Backpropagation: 0.0931 sec; Batch: 0.4266 sec
0.1048 0.0716 0.0598 0.0523 0.0501 0.0467 0.0453 0.0445 0.0459 0.0459 0.0448 0.0443 0.0459 0.0456 0.0460 0.0468 

[TRAIN] Epoch[5](681/1500); Loss: 0.127146; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.2737 0.2206 0.2173 0.1852 0.1726 0.1393 0.1191 0.0970 0.0836 0.0675 0.0721 0.0798 0.0791 0.0774 0.0755 0.0745 

[TRAIN] Epoch[5](682/1500); Loss: 0.071734; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1033 0.0892 0.0822 0.0770 0.0727 0.0702 0.0679 0.0656 0.0642 0.0635 0.0637 0.0642 0.0650 0.0655 0.0663 0.0673 

[TRAIN] Epoch[5](683/1500); Loss: 0.071990; Backpropagation: 0.0960 sec; Batch: 0.4305 sec
0.1419 0.1067 0.1041 0.0870 0.0793 0.0682 0.0633 0.0595 0.0570 0.0538 0.0539 0.0536 0.0543 0.0556 0.0564 0.0575 

[TRAIN] Epoch[5](684/1500); Loss: 0.062215; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.0830 0.0666 0.0654 0.0588 0.0575 0.0570 0.0570 0.0579 0.0588 0.0585 0.0593 0.0611 0.0624 0.0629 0.0640 0.0653 

[TRAIN] Epoch[5](685/1500); Loss: 0.122545; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.2849 0.2315 0.1928 0.1495 0.1115 0.0981 0.0910 0.0922 0.0894 0.0875 0.0862 0.0901 0.0881 0.0884 0.0895 0.0901 

[TRAIN] Epoch[5](686/1500); Loss: 0.160120; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2063 0.1855 0.1798 0.1688 0.1640 0.1575 0.1552 0.1511 0.1506 0.1488 0.1488 0.1480 0.1487 0.1491 0.1499 0.1497 

[TRAIN] Epoch[5](687/1500); Loss: 0.124796; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.2453 0.1940 0.1485 0.1178 0.1124 0.1071 0.1073 0.1069 0.1070 0.1062 0.1064 0.1076 0.1069 0.1072 0.1076 0.1085 

[TRAIN] Epoch[5](688/1500); Loss: 0.068392; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.0928 0.0710 0.0669 0.0718 0.0662 0.0654 0.0639 0.0636 0.0630 0.0639 0.0649 0.0660 0.0669 0.0679 0.0693 0.0707 

[TRAIN] Epoch[5](689/1500); Loss: 0.091544; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1880 0.1401 0.1167 0.0932 0.0879 0.0813 0.0769 0.0779 0.0744 0.0746 0.0744 0.0752 0.0764 0.0758 0.0755 0.0763 

[TRAIN] Epoch[5](690/1500); Loss: 0.156417; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2632 0.2262 0.2166 0.1939 0.1830 0.1630 0.1518 0.1364 0.1311 0.1205 0.1192 0.1203 0.1197 0.1194 0.1187 0.1197 

[TRAIN] Epoch[5](691/1500); Loss: 0.104962; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1322 0.1223 0.1139 0.1042 0.1030 0.0996 0.0985 0.0980 0.0980 0.0993 0.0995 0.1006 0.1007 0.1022 0.1031 0.1043 

[TRAIN] Epoch[5](692/1500); Loss: 0.077217; Backpropagation: 0.0932 sec; Batch: 0.4278 sec
0.1764 0.1252 0.1196 0.0923 0.0829 0.0641 0.0587 0.0545 0.0592 0.0554 0.0555 0.0566 0.0577 0.0578 0.0590 0.0605 

[TRAIN] Epoch[5](693/1500); Loss: 0.115356; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.2084 0.1599 0.1399 0.1212 0.1172 0.1042 0.1006 0.0990 0.0991 0.0993 0.0997 0.0985 0.0984 0.0990 0.0997 0.1015 

[TRAIN] Epoch[5](694/1500); Loss: 0.071794; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1319 0.1040 0.0780 0.0691 0.0676 0.0652 0.0610 0.0622 0.0619 0.0621 0.0632 0.0628 0.0646 0.0644 0.0648 0.0659 

[TRAIN] Epoch[5](695/1500); Loss: 0.220948; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.5326 0.4523 0.4317 0.3618 0.3234 0.2394 0.1931 0.1329 0.1083 0.1073 0.1175 0.1060 0.1062 0.1065 0.1077 0.1085 

[TRAIN] Epoch[5](696/1500); Loss: 0.148486; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2226 0.1973 0.1900 0.1679 0.1620 0.1474 0.1382 0.1332 0.1292 0.1267 0.1290 0.1247 0.1271 0.1262 0.1265 0.1279 

[TRAIN] Epoch[5](697/1500); Loss: 0.164434; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2276 0.2041 0.1940 0.1773 0.1713 0.1614 0.1536 0.1532 0.1463 0.1495 0.1492 0.1472 0.1480 0.1494 0.1489 0.1500 

[TRAIN] Epoch[5](698/1500); Loss: 0.067166; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1382 0.1085 0.0822 0.0626 0.0599 0.0555 0.0552 0.0554 0.0557 0.0563 0.0560 0.0557 0.0568 0.0577 0.0595 0.0593 

[TRAIN] Epoch[5](699/1500); Loss: 0.135100; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2235 0.1797 0.1680 0.1430 0.1361 0.1249 0.1204 0.1175 0.1173 0.1170 0.1182 0.1188 0.1175 0.1186 0.1196 0.1212 

[TRAIN] Epoch[5](700/1500); Loss: 0.099824; Backpropagation: 0.0958 sec; Batch: 0.4312 sec
0.2095 0.1540 0.1279 0.1044 0.0990 0.0871 0.0793 0.0782 0.0816 0.0813 0.0825 0.0821 0.0824 0.0823 0.0827 0.0828 

[TRAIN] Epoch[5](701/1500); Loss: 0.057171; Backpropagation: 0.0957 sec; Batch: 0.4302 sec
0.1430 0.0975 0.0699 0.0467 0.0449 0.0468 0.0439 0.0455 0.0450 0.0446 0.0449 0.0446 0.0465 0.0486 0.0508 0.0516 

[TRAIN] Epoch[5](702/1500); Loss: 0.125734; Backpropagation: 0.0942 sec; Batch: 0.4433 sec
0.2415 0.1965 0.1792 0.1522 0.1435 0.1203 0.1094 0.0998 0.0972 0.0972 0.0992 0.0956 0.0942 0.0957 0.0950 0.0952 

[TRAIN] Epoch[5](703/1500); Loss: 0.077501; Backpropagation: 0.0938 sec; Batch: 0.4377 sec
0.1212 0.0951 0.0845 0.0736 0.0709 0.0753 0.0723 0.0681 0.0687 0.0693 0.0703 0.0710 0.0727 0.0741 0.0756 0.0774 

[TRAIN] Epoch[5](704/1500); Loss: 0.158640; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.2208 0.1985 0.1924 0.1778 0.1705 0.1621 0.1518 0.1394 0.1399 0.1405 0.1404 0.1407 0.1410 0.1401 0.1414 0.1408 

[TRAIN] Epoch[5](705/1500); Loss: 0.165906; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.3048 0.2592 0.2468 0.2087 0.1922 0.1586 0.1393 0.1294 0.1250 0.1315 0.1270 0.1274 0.1267 0.1260 0.1262 0.1257 

[TRAIN] Epoch[5](706/1500); Loss: 0.135088; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.2336 0.1963 0.1855 0.1498 0.1314 0.1173 0.1209 0.1186 0.1153 0.1147 0.1129 0.1121 0.1131 0.1128 0.1128 0.1143 

[TRAIN] Epoch[5](707/1500); Loss: 0.127415; Backpropagation: 0.0939 sec; Batch: 0.4604 sec
0.1756 0.1408 0.1327 0.1194 0.1170 0.1204 0.1181 0.1177 0.1189 0.1209 0.1210 0.1223 0.1244 0.1270 0.1300 0.1322 

[TRAIN] Epoch[5](708/1500); Loss: 0.070756; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1290 0.0972 0.0841 0.0761 0.0622 0.0604 0.0584 0.0605 0.0592 0.0606 0.0608 0.0618 0.0629 0.0645 0.0667 0.0675 

[TRAIN] Epoch[5](709/1500); Loss: 0.077069; Backpropagation: 0.0923 sec; Batch: 0.4269 sec
0.1082 0.0736 0.0703 0.0728 0.0733 0.0748 0.0768 0.0731 0.0741 0.0749 0.0741 0.0762 0.0757 0.0769 0.0789 0.0794 

[TRAIN] Epoch[5](710/1500); Loss: 0.101252; Backpropagation: 0.0925 sec; Batch: 0.4258 sec
0.1889 0.1405 0.1248 0.1077 0.0945 0.0887 0.0874 0.0868 0.0863 0.0858 0.0865 0.0867 0.0877 0.0878 0.0892 0.0905 

[TRAIN] Epoch[5](711/1500); Loss: 0.106414; Backpropagation: 0.0924 sec; Batch: 0.4263 sec
0.1652 0.1353 0.1254 0.1080 0.1028 0.0973 0.1002 0.0970 0.0936 0.0957 0.0956 0.0958 0.0966 0.0976 0.0976 0.0991 

[TRAIN] Epoch[5](712/1500); Loss: 0.144091; Backpropagation: 0.0981 sec; Batch: 0.4332 sec
0.2710 0.2145 0.1918 0.1530 0.1433 0.1269 0.1220 0.1191 0.1173 0.1175 0.1189 0.1203 0.1210 0.1219 0.1233 0.1238 

[TRAIN] Epoch[5](713/1500); Loss: 0.108717; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.1718 0.1413 0.1331 0.1132 0.1050 0.1035 0.1024 0.0954 0.0959 0.0947 0.0971 0.0964 0.0973 0.0971 0.0973 0.0981 

[TRAIN] Epoch[5](714/1500); Loss: 0.153506; Backpropagation: 0.0927 sec; Batch: 0.4267 sec
0.2942 0.2429 0.2365 0.2057 0.1946 0.1581 0.1328 0.1150 0.1083 0.1108 0.1102 0.1085 0.1092 0.1097 0.1099 0.1098 

[TRAIN] Epoch[5](715/1500); Loss: 0.160161; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1971 0.1718 0.1648 0.1611 0.1612 0.1622 0.1558 0.1550 0.1538 0.1548 0.1532 0.1532 0.1537 0.1545 0.1548 0.1557 

[TRAIN] Epoch[5](716/1500); Loss: 0.160296; Backpropagation: 0.0932 sec; Batch: 0.4634 sec
0.2516 0.2081 0.2023 0.1873 0.1808 0.1654 0.1549 0.1457 0.1397 0.1372 0.1369 0.1322 0.1310 0.1298 0.1306 0.1313 

[TRAIN] Epoch[5](717/1500); Loss: 0.159663; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2662 0.2215 0.2114 0.1866 0.1784 0.1595 0.1504 0.1386 0.1313 0.1281 0.1314 0.1305 0.1293 0.1298 0.1310 0.1306 

[TRAIN] Epoch[5](718/1500); Loss: 0.100625; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1792 0.1214 0.1049 0.0925 0.0890 0.0907 0.0885 0.0883 0.0880 0.0900 0.0916 0.0938 0.0963 0.0973 0.0985 0.1002 

[TRAIN] Epoch[5](719/1500); Loss: 0.128288; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2648 0.2043 0.1779 0.1399 0.1256 0.1120 0.1066 0.1038 0.1013 0.1012 0.1018 0.1015 0.1011 0.1028 0.1033 0.1049 

[TRAIN] Epoch[5](720/1500); Loss: 0.120334; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1818 0.1603 0.1605 0.1457 0.1406 0.1235 0.1130 0.1054 0.0985 0.0988 0.1006 0.0997 0.0987 0.0985 0.0993 0.1004 

[TRAIN] Epoch[5](721/1500); Loss: 0.145979; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2284 0.1853 0.1639 0.1368 0.1392 0.1317 0.1331 0.1313 0.1310 0.1316 0.1366 0.1354 0.1373 0.1376 0.1375 0.1390 

[TRAIN] Epoch[5](722/1500); Loss: 0.070707; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.2167 0.1316 0.1025 0.0575 0.0610 0.0478 0.0482 0.0472 0.0462 0.0543 0.0509 0.0516 0.0516 0.0527 0.0546 0.0569 

[TRAIN] Epoch[5](723/1500); Loss: 0.127614; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1804 0.1587 0.1565 0.1424 0.1365 0.1254 0.1198 0.1179 0.1152 0.1119 0.1139 0.1115 0.1115 0.1121 0.1134 0.1147 

[TRAIN] Epoch[5](724/1500); Loss: 0.106587; Backpropagation: 0.0981 sec; Batch: 0.4327 sec
0.1953 0.1568 0.1469 0.1168 0.1037 0.0953 0.0899 0.0886 0.0896 0.0873 0.0895 0.0879 0.0886 0.0887 0.0895 0.0909 

[TRAIN] Epoch[5](725/1500); Loss: 0.130005; Backpropagation: 0.0982 sec; Batch: 0.4325 sec
0.2129 0.1741 0.1741 0.1520 0.1479 0.1315 0.1216 0.1143 0.1103 0.1068 0.1065 0.1043 0.1055 0.1057 0.1060 0.1063 

[TRAIN] Epoch[5](726/1500); Loss: 0.109965; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.2126 0.1613 0.1336 0.1071 0.0928 0.0864 0.0863 0.0886 0.0918 0.0942 0.0986 0.0986 0.1000 0.1011 0.1021 0.1045 

[TRAIN] Epoch[5](727/1500); Loss: 0.197995; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2268 0.2146 0.2065 0.2003 0.1989 0.1960 0.1962 0.1953 0.1954 0.1937 0.1927 0.1897 0.1909 0.1899 0.1902 0.1911 

[TRAIN] Epoch[5](728/1500); Loss: 0.145759; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2042 0.1833 0.1908 0.1735 0.1687 0.1498 0.1409 0.1328 0.1320 0.1281 0.1263 0.1228 0.1196 0.1191 0.1198 0.1204 

[TRAIN] Epoch[5](729/1500); Loss: 0.092362; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1719 0.1121 0.0968 0.0936 0.0873 0.0858 0.0829 0.0817 0.0819 0.0829 0.0835 0.0833 0.0845 0.0840 0.0826 0.0829 

[TRAIN] Epoch[5](730/1500); Loss: 0.202845; Backpropagation: 0.0934 sec; Batch: 0.4284 sec
0.3165 0.2847 0.2967 0.2675 0.2609 0.2237 0.2029 0.1761 0.1586 0.1517 0.1588 0.1540 0.1505 0.1485 0.1474 0.1472 

[TRAIN] Epoch[5](731/1500); Loss: 0.137040; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2152 0.1791 0.1944 0.1709 0.1681 0.1512 0.1437 0.1298 0.1222 0.1105 0.1046 0.0985 0.0980 0.1000 0.1026 0.1038 

[TRAIN] Epoch[5](732/1500); Loss: 0.105211; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1418 0.1103 0.1169 0.1017 0.0985 0.0987 0.1026 0.1011 0.0988 0.0989 0.0997 0.1007 0.1016 0.1024 0.1038 0.1059 

[TRAIN] Epoch[5](733/1500); Loss: 0.179204; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.2516 0.2205 0.2261 0.2014 0.1971 0.1753 0.1683 0.1627 0.1644 0.1659 0.1624 0.1576 0.1541 0.1537 0.1528 0.1533 

[TRAIN] Epoch[5](734/1500); Loss: 0.215316; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.3346 0.3026 0.3120 0.2835 0.2762 0.2416 0.2234 0.1993 0.1808 0.1612 0.1536 0.1575 0.1585 0.1538 0.1533 0.1533 

[TRAIN] Epoch[5](735/1500); Loss: 0.142911; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.2083 0.1825 0.1894 0.1705 0.1662 0.1443 0.1323 0.1207 0.1203 0.1280 0.1266 0.1201 0.1193 0.1189 0.1193 0.1200 

[TRAIN] Epoch[5](736/1500); Loss: 0.187548; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.2665 0.2367 0.2433 0.2222 0.2171 0.1913 0.1812 0.1666 0.1627 0.1585 0.1605 0.1587 0.1586 0.1582 0.1588 0.1598 

[TRAIN] Epoch[5](737/1500); Loss: 0.118276; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1967 0.1463 0.1470 0.1235 0.1199 0.1103 0.1064 0.1025 0.1027 0.1043 0.1035 0.1035 0.1037 0.1051 0.1072 0.1098 

[TRAIN] Epoch[5](738/1500); Loss: 0.175621; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2266 0.2108 0.2201 0.2041 0.1996 0.1820 0.1750 0.1635 0.1600 0.1546 0.1528 0.1508 0.1488 0.1490 0.1536 0.1587 

[TRAIN] Epoch[5](739/1500); Loss: 0.177759; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2134 0.1987 0.2007 0.1887 0.1851 0.1739 0.1676 0.1670 0.1716 0.1714 0.1687 0.1681 0.1667 0.1673 0.1674 0.1679 

[TRAIN] Epoch[5](740/1500); Loss: 0.120419; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1832 0.1545 0.1598 0.1367 0.1322 0.1146 0.1099 0.1091 0.1059 0.1033 0.1023 0.1023 0.1026 0.1028 0.1034 0.1043 

[TRAIN] Epoch[5](741/1500); Loss: 0.070875; Backpropagation: 0.0983 sec; Batch: 0.4336 sec
0.1297 0.0800 0.0829 0.0668 0.0664 0.0681 0.0633 0.0643 0.0633 0.0631 0.0629 0.0642 0.0641 0.0635 0.0648 0.0665 

[TRAIN] Epoch[5](742/1500); Loss: 0.109150; Backpropagation: 0.0957 sec; Batch: 0.4300 sec
0.1694 0.1452 0.1511 0.1298 0.1245 0.1056 0.0993 0.0935 0.0950 0.0898 0.0878 0.0887 0.0893 0.0908 0.0923 0.0944 

[TRAIN] Epoch[5](743/1500); Loss: 0.220259; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.3715 0.3192 0.3251 0.2855 0.2763 0.2413 0.2233 0.1957 0.1777 0.1616 0.1576 0.1586 0.1588 0.1594 0.1570 0.1557 

[TRAIN] Epoch[5](744/1500); Loss: 0.083782; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1108 0.0734 0.0761 0.0759 0.0760 0.0767 0.0786 0.0812 0.0833 0.0825 0.0842 0.0859 0.0866 0.0881 0.0898 0.0913 

[TRAIN] Epoch[5](745/1500); Loss: 0.122394; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1664 0.1443 0.1491 0.1321 0.1291 0.1292 0.1281 0.1151 0.1108 0.1080 0.1082 0.1071 0.1077 0.1069 0.1075 0.1087 

[TRAIN] Epoch[5](746/1500); Loss: 0.115453; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2142 0.1577 0.1648 0.1315 0.1245 0.1115 0.1068 0.0991 0.0985 0.0955 0.0966 0.0898 0.0888 0.0888 0.0894 0.0898 

[TRAIN] Epoch[5](747/1500); Loss: 0.056021; Backpropagation: 0.0982 sec; Batch: 0.4335 sec
0.0641 0.0549 0.0525 0.0497 0.0501 0.0520 0.0535 0.0540 0.0559 0.0562 0.0556 0.0568 0.0584 0.0594 0.0610 0.0625 

[TRAIN] Epoch[5](748/1500); Loss: 0.160312; Backpropagation: 0.0960 sec; Batch: 0.4305 sec
0.2048 0.1917 0.1933 0.1824 0.1792 0.1682 0.1613 0.1531 0.1468 0.1430 0.1432 0.1411 0.1387 0.1393 0.1396 0.1393 

[TRAIN] Epoch[5](749/1500); Loss: 0.134678; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.2240 0.1947 0.2010 0.1804 0.1747 0.1527 0.1397 0.1200 0.1085 0.0979 0.0957 0.0926 0.0935 0.0927 0.0929 0.0937 

[TRAIN] Epoch[5](750/1500); Loss: 0.133080; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1905 0.1457 0.1538 0.1325 0.1327 0.1248 0.1248 0.1243 0.1241 0.1267 0.1265 0.1240 0.1237 0.1246 0.1251 0.1257 

[TRAIN] Epoch[5](751/1500); Loss: 0.107567; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1264 0.1175 0.1149 0.1145 0.1113 0.1128 0.1076 0.1065 0.1043 0.1024 0.1019 0.0993 0.0999 0.1007 0.1003 0.1008 

[TRAIN] Epoch[5](752/1500); Loss: 0.128168; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1941 0.1558 0.1646 0.1393 0.1372 0.1203 0.1151 0.1100 0.1120 0.1154 0.1124 0.1126 0.1142 0.1156 0.1155 0.1166 

[TRAIN] Epoch[5](753/1500); Loss: 0.140707; Backpropagation: 0.0939 sec; Batch: 0.4399 sec
0.2139 0.1900 0.1975 0.1803 0.1735 0.1519 0.1374 0.1208 0.1115 0.1062 0.1073 0.1106 0.1121 0.1131 0.1133 0.1120 

[TRAIN] Epoch[5](754/1500); Loss: 0.106718; Backpropagation: 0.0942 sec; Batch: 0.4281 sec
0.1398 0.1186 0.1180 0.1067 0.1015 0.0981 0.0984 0.1010 0.1017 0.0997 0.1016 0.1014 0.1032 0.1048 0.1063 0.1068 

[TRAIN] Epoch[5](755/1500); Loss: 0.104811; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1881 0.1246 0.1265 0.1009 0.0983 0.0947 0.0966 0.0926 0.0913 0.0913 0.0922 0.0926 0.0941 0.0961 0.0978 0.0994 

[TRAIN] Epoch[5](756/1500); Loss: 0.168920; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2406 0.2107 0.2076 0.1836 0.1782 0.1655 0.1650 0.1572 0.1581 0.1534 0.1486 0.1451 0.1439 0.1453 0.1488 0.1511 

[TRAIN] Epoch[5](757/1500); Loss: 0.093159; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1547 0.1164 0.1179 0.0987 0.0938 0.0804 0.0814 0.0840 0.0807 0.0824 0.0865 0.0838 0.0807 0.0826 0.0832 0.0833 

[TRAIN] Epoch[5](758/1500); Loss: 0.200314; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.3063 0.2709 0.2682 0.2332 0.2220 0.2016 0.1866 0.1802 0.1803 0.1726 0.1651 0.1641 0.1631 0.1635 0.1635 0.1638 

[TRAIN] Epoch[5](759/1500); Loss: 0.139109; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2442 0.1923 0.1908 0.1590 0.1520 0.1467 0.1396 0.1246 0.1153 0.1100 0.1147 0.1086 0.1071 0.1071 0.1066 0.1073 

[TRAIN] Epoch[5](760/1500); Loss: 0.091030; Backpropagation: 0.0938 sec; Batch: 0.4281 sec
0.1466 0.1096 0.1078 0.0945 0.0902 0.0840 0.0827 0.0801 0.0810 0.0817 0.0817 0.0805 0.0816 0.0831 0.0846 0.0867 

[TRAIN] Epoch[5](761/1500); Loss: 0.156571; Backpropagation: 0.0939 sec; Batch: 0.4628 sec
0.2197 0.1924 0.1834 0.1683 0.1661 0.1602 0.1549 0.1474 0.1454 0.1408 0.1408 0.1391 0.1362 0.1363 0.1374 0.1368 

[TRAIN] Epoch[5](762/1500); Loss: 0.146242; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2502 0.1884 0.1867 0.1643 0.1545 0.1453 0.1382 0.1307 0.1295 0.1320 0.1346 0.1252 0.1183 0.1157 0.1134 0.1127 

[TRAIN] Epoch[5](763/1500); Loss: 0.181349; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.3418 0.2860 0.2812 0.2204 0.2066 0.1642 0.1524 0.1556 0.1537 0.1379 0.1357 0.1346 0.1342 0.1324 0.1325 0.1325 

[TRAIN] Epoch[5](764/1500); Loss: 0.103731; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2718 0.2174 0.2094 0.1388 0.1252 0.0679 0.0655 0.0793 0.0635 0.0643 0.0589 0.0589 0.0601 0.0589 0.0596 0.0601 

[TRAIN] Epoch[5](765/1500); Loss: 0.137846; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2034 0.1656 0.1686 0.1493 0.1446 0.1324 0.1287 0.1245 0.1258 0.1286 0.1250 0.1222 0.1223 0.1216 0.1218 0.1211 

[TRAIN] Epoch[5](766/1500); Loss: 0.137825; Backpropagation: 0.0932 sec; Batch: 0.4669 sec
0.2007 0.1638 0.1595 0.1353 0.1329 0.1344 0.1326 0.1257 0.1277 0.1266 0.1244 0.1250 0.1270 0.1290 0.1290 0.1316 

[TRAIN] Epoch[5](767/1500); Loss: 0.118733; Backpropagation: 0.0938 sec; Batch: 0.4717 sec
0.1562 0.1222 0.1235 0.1173 0.1202 0.1183 0.1187 0.1162 0.1143 0.1131 0.1140 0.1140 0.1121 0.1124 0.1135 0.1139 

[TRAIN] Epoch[5](768/1500); Loss: 0.117176; Backpropagation: 0.0937 sec; Batch: 0.4678 sec
0.2962 0.2095 0.2052 0.1453 0.1153 0.0898 0.0864 0.0852 0.0828 0.0803 0.0806 0.0809 0.0792 0.0790 0.0794 0.0796 

[TRAIN] Epoch[5](769/1500); Loss: 0.158216; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.1686 0.1637 0.1608 0.1686 0.1637 0.1596 0.1588 0.1548 0.1559 0.1537 0.1544 0.1530 0.1548 0.1533 0.1540 0.1540 

[TRAIN] Epoch[5](770/1500); Loss: 0.127111; Backpropagation: 0.0956 sec; Batch: 0.4682 sec
0.2944 0.2532 0.2472 0.1879 0.1712 0.1166 0.0895 0.0686 0.0846 0.0934 0.0771 0.0712 0.0712 0.0705 0.0686 0.0686 

[TRAIN] Epoch[5](771/1500); Loss: 0.085965; Backpropagation: 0.0943 sec; Batch: 0.6811 sec
0.1441 0.0888 0.0966 0.0824 0.0822 0.0789 0.0778 0.0776 0.0776 0.0779 0.0781 0.0796 0.0812 0.0824 0.0839 0.0863 

[TRAIN] Epoch[5](772/1500); Loss: 0.092401; Backpropagation: 0.0938 sec; Batch: 0.4462 sec
0.1323 0.1137 0.1066 0.1001 0.0921 0.0914 0.0909 0.0852 0.0826 0.0839 0.0841 0.0826 0.0838 0.0830 0.0824 0.0836 

[TRAIN] Epoch[5](773/1500); Loss: 0.154574; Backpropagation: 0.0935 sec; Batch: 0.4303 sec
0.1952 0.1819 0.1781 0.1647 0.1596 0.1510 0.1434 0.1457 0.1478 0.1449 0.1396 0.1410 0.1434 0.1433 0.1455 0.1480 

[TRAIN] Epoch[5](774/1500); Loss: 0.119221; Backpropagation: 0.0931 sec; Batch: 0.4698 sec
0.2347 0.1552 0.1596 0.1174 0.1109 0.1059 0.1051 0.1030 0.1054 0.1088 0.1014 0.0979 0.0991 0.1004 0.1011 0.1017 

[TRAIN] Epoch[5](775/1500); Loss: 0.079527; Backpropagation: 0.0923 sec; Batch: 0.4271 sec
0.1331 0.1045 0.1012 0.0922 0.0876 0.0874 0.0758 0.0731 0.0683 0.0674 0.0631 0.0631 0.0637 0.0648 0.0626 0.0645 

[TRAIN] Epoch[5](776/1500); Loss: 0.155307; Backpropagation: 0.0937 sec; Batch: 0.5239 sec
0.2142 0.1916 0.1849 0.1696 0.1627 0.1518 0.1506 0.1513 0.1487 0.1382 0.1382 0.1381 0.1373 0.1359 0.1359 0.1357 

[TRAIN] Epoch[5](777/1500); Loss: 0.134423; Backpropagation: 0.0939 sec; Batch: 0.4666 sec
0.1885 0.1305 0.1423 0.1282 0.1322 0.1275 0.1278 0.1265 0.1277 0.1287 0.1303 0.1312 0.1311 0.1316 0.1327 0.1340 

[TRAIN] Epoch[5](778/1500); Loss: 0.131456; Backpropagation: 0.0938 sec; Batch: 0.4671 sec
0.2766 0.2300 0.2280 0.1671 0.1536 0.1096 0.0986 0.0960 0.1108 0.0975 0.0902 0.0901 0.0896 0.0886 0.0885 0.0884 

[TRAIN] Epoch[5](779/1500); Loss: 0.075059; Backpropagation: 0.0939 sec; Batch: 0.4663 sec
0.1465 0.0922 0.0934 0.0765 0.0740 0.0703 0.0675 0.0678 0.0654 0.0658 0.0644 0.0623 0.0631 0.0644 0.0636 0.0638 

[TRAIN] Epoch[5](780/1500); Loss: 0.088376; Backpropagation: 0.0937 sec; Batch: 0.4712 sec
0.2162 0.1566 0.1553 0.1085 0.1033 0.0805 0.0690 0.0650 0.0688 0.0571 0.0556 0.0559 0.0566 0.0542 0.0552 0.0562 

[TRAIN] Epoch[5](781/1500); Loss: 0.153850; Backpropagation: 0.0941 sec; Batch: 0.4601 sec
0.2228 0.1981 0.1932 0.1702 0.1637 0.1459 0.1409 0.1490 0.1560 0.1398 0.1345 0.1299 0.1317 0.1289 0.1289 0.1282 

[TRAIN] Epoch[5](782/1500); Loss: 0.190982; Backpropagation: 0.0937 sec; Batch: 0.4691 sec
0.3092 0.2683 0.2561 0.2246 0.2157 0.1857 0.1742 0.1608 0.1636 0.1674 0.1569 0.1546 0.1550 0.1557 0.1541 0.1537 

[TRAIN] Epoch[5](783/1500); Loss: 0.147048; Backpropagation: 0.0938 sec; Batch: 0.4708 sec
0.2241 0.2011 0.1971 0.1717 0.1659 0.1458 0.1394 0.1338 0.1337 0.1242 0.1225 0.1228 0.1192 0.1173 0.1176 0.1165 

[TRAIN] Epoch[5](784/1500); Loss: 0.056856; Backpropagation: 0.0937 sec; Batch: 0.4715 sec
0.1021 0.0548 0.0636 0.0567 0.0564 0.0542 0.0540 0.0521 0.0517 0.0512 0.0515 0.0513 0.0514 0.0525 0.0530 0.0532 

[TRAIN] Epoch[5](785/1500); Loss: 0.098376; Backpropagation: 0.0939 sec; Batch: 0.4714 sec
0.1487 0.1389 0.1172 0.1140 0.1080 0.0943 0.0886 0.0885 0.0848 0.0819 0.0827 0.0842 0.0844 0.0835 0.0863 0.0882 

[TRAIN] Epoch[5](786/1500); Loss: 0.065389; Backpropagation: 0.0937 sec; Batch: 0.4658 sec
0.0899 0.0767 0.0708 0.0688 0.0680 0.0654 0.0653 0.0580 0.0596 0.0587 0.0588 0.0593 0.0600 0.0611 0.0623 0.0636 

[TRAIN] Epoch[5](787/1500); Loss: 0.125819; Backpropagation: 0.0939 sec; Batch: 0.4667 sec
0.2161 0.1815 0.1749 0.1423 0.1370 0.1233 0.1226 0.1207 0.1075 0.1023 0.1007 0.0971 0.0972 0.0964 0.0965 0.0970 

[TRAIN] Epoch[5](788/1500); Loss: 0.163917; Backpropagation: 0.0938 sec; Batch: 0.4678 sec
0.3018 0.2577 0.2479 0.2036 0.1969 0.1660 0.1530 0.1339 0.1272 0.1220 0.1228 0.1263 0.1202 0.1131 0.1150 0.1152 

[TRAIN] Epoch[5](789/1500); Loss: 0.156405; Backpropagation: 0.0939 sec; Batch: 0.4745 sec
0.3286 0.2838 0.2713 0.2155 0.2032 0.1669 0.1513 0.1242 0.1097 0.0977 0.1014 0.0985 0.0881 0.0881 0.0875 0.0866 

[TRAIN] Epoch[5](790/1500); Loss: 0.175068; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.2436 0.2298 0.2120 0.1898 0.1833 0.1720 0.1641 0.1617 0.1580 0.1604 0.1591 0.1529 0.1537 0.1533 0.1532 0.1541 

[TRAIN] Epoch[5](791/1500); Loss: 0.141593; Backpropagation: 0.0939 sec; Batch: 0.4664 sec
0.2576 0.2220 0.2148 0.1776 0.1716 0.1364 0.1256 0.1090 0.1071 0.1141 0.1072 0.1057 0.1044 0.1043 0.1040 0.1042 

[TRAIN] Epoch[5](792/1500); Loss: 0.081627; Backpropagation: 0.0938 sec; Batch: 0.4704 sec
0.1136 0.1081 0.0957 0.0879 0.0808 0.0783 0.0771 0.0763 0.0765 0.0740 0.0727 0.0724 0.0723 0.0728 0.0732 0.0743 

[TRAIN] Epoch[5](793/1500); Loss: 0.128979; Backpropagation: 0.0938 sec; Batch: 0.4715 sec
0.2153 0.1899 0.1761 0.1482 0.1415 0.1231 0.1164 0.1055 0.1064 0.1127 0.1116 0.1019 0.1029 0.1036 0.1052 0.1032 

[TRAIN] Epoch[5](794/1500); Loss: 0.090930; Backpropagation: 0.0938 sec; Batch: 0.4912 sec
0.1638 0.1698 0.1187 0.0958 0.0838 0.0737 0.0676 0.0707 0.0713 0.0734 0.0726 0.0745 0.0770 0.0784 0.0812 0.0826 

[TRAIN] Epoch[5](795/1500); Loss: 0.140806; Backpropagation: 0.0939 sec; Batch: 0.4662 sec
0.2172 0.2157 0.1703 0.1454 0.1375 0.1294 0.1247 0.1239 0.1227 0.1221 0.1227 0.1233 0.1238 0.1241 0.1248 0.1252 

[TRAIN] Epoch[5](796/1500); Loss: 0.101973; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.1746 0.1833 0.1454 0.1270 0.1152 0.0993 0.0904 0.0830 0.0794 0.0758 0.0754 0.0756 0.0760 0.0757 0.0771 0.0784 

[TRAIN] Epoch[5](797/1500); Loss: 0.123079; Backpropagation: 0.0939 sec; Batch: 0.4684 sec
0.1894 0.1701 0.1602 0.1368 0.1306 0.1164 0.1130 0.1145 0.1173 0.1097 0.1046 0.1021 0.1026 0.1018 0.1002 0.1000 

[TRAIN] Epoch[5](798/1500); Loss: 0.088398; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.1829 0.1490 0.1416 0.1051 0.0976 0.0702 0.0671 0.0704 0.0654 0.0633 0.0637 0.0646 0.0660 0.0676 0.0689 0.0708 

[TRAIN] Epoch[5](799/1500); Loss: 0.143888; Backpropagation: 0.0939 sec; Batch: 0.4699 sec
0.2143 0.1995 0.1747 0.1484 0.1427 0.1341 0.1323 0.1317 0.1317 0.1309 0.1260 0.1270 0.1269 0.1271 0.1271 0.1279 

[TRAIN] Epoch[5](800/1500); Loss: 0.122134; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.2314 0.2074 0.1907 0.1551 0.1435 0.1227 0.1083 0.0972 0.0915 0.0897 0.0940 0.0842 0.0854 0.0846 0.0841 0.0843 

[TRAIN] Epoch[5](801/1500); Loss: 0.209364; Backpropagation: 0.0940 sec; Batch: 0.4699 sec
0.2683 0.2609 0.2465 0.2385 0.2314 0.2221 0.2106 0.2016 0.1956 0.1885 0.1839 0.1813 0.1805 0.1807 0.1800 0.1793 

[TRAIN] Epoch[5](802/1500); Loss: 0.129160; Backpropagation: 0.0938 sec; Batch: 0.4672 sec
0.1946 0.1756 0.1617 0.1390 0.1332 0.1216 0.1169 0.1183 0.1161 0.1155 0.1128 0.1122 0.1129 0.1117 0.1119 0.1123 

[TRAIN] Epoch[5](803/1500); Loss: 0.074784; Backpropagation: 0.0951 sec; Batch: 0.4681 sec
0.1100 0.1009 0.0876 0.0831 0.0762 0.0789 0.0706 0.0672 0.0662 0.0643 0.0641 0.0641 0.0649 0.0648 0.0665 0.0672 

[TRAIN] Epoch[5](804/1500); Loss: 0.199731; Backpropagation: 0.0957 sec; Batch: 0.4671 sec
0.3546 0.3156 0.3137 0.2704 0.2608 0.2216 0.2038 0.1711 0.1571 0.1433 0.1350 0.1391 0.1294 0.1278 0.1268 0.1255 

[TRAIN] Epoch[5](805/1500); Loss: 0.106150; Backpropagation: 0.0957 sec; Batch: 0.4828 sec
0.1333 0.1335 0.1145 0.1074 0.1033 0.1057 0.1015 0.0998 0.0989 0.0985 0.0974 0.0996 0.1005 0.1005 0.1014 0.1027 

[TRAIN] Epoch[5](806/1500); Loss: 0.061336; Backpropagation: 0.0938 sec; Batch: 0.4647 sec
0.1058 0.0993 0.0722 0.0572 0.0514 0.0522 0.0491 0.0511 0.0528 0.0522 0.0520 0.0541 0.0561 0.0568 0.0588 0.0603 

[TRAIN] Epoch[5](807/1500); Loss: 0.192405; Backpropagation: 0.0941 sec; Batch: 0.4676 sec
0.2848 0.2590 0.2556 0.2243 0.2147 0.1967 0.1841 0.1725 0.1721 0.1670 0.1612 0.1591 0.1578 0.1570 0.1565 0.1561 

[TRAIN] Epoch[5](808/1500); Loss: 0.129255; Backpropagation: 0.0937 sec; Batch: 0.4695 sec
0.2102 0.1730 0.1725 0.1376 0.1321 0.1209 0.1215 0.1214 0.1134 0.1116 0.1093 0.1083 0.1083 0.1089 0.1092 0.1098 

[TRAIN] Epoch[5](809/1500); Loss: 0.101577; Backpropagation: 0.0982 sec; Batch: 0.4526 sec
0.2247 0.2743 0.1987 0.1399 0.1124 0.0822 0.0637 0.0576 0.0563 0.0558 0.0564 0.0580 0.0591 0.0601 0.0621 0.0640 

[TRAIN] Epoch[5](810/1500); Loss: 0.132832; Backpropagation: 0.0981 sec; Batch: 0.4740 sec
0.3471 0.2873 0.2874 0.2145 0.2027 0.1196 0.0955 0.0592 0.0614 0.0740 0.0606 0.0605 0.0621 0.0630 0.0643 0.0661 

[TRAIN] Epoch[5](811/1500); Loss: 0.071090; Backpropagation: 0.0939 sec; Batch: 0.4684 sec
0.1355 0.1077 0.1061 0.0778 0.0694 0.0614 0.0629 0.0624 0.0547 0.0553 0.0559 0.0562 0.0562 0.0577 0.0585 0.0596 

[TRAIN] Epoch[5](812/1500); Loss: 0.161041; Backpropagation: 0.0938 sec; Batch: 0.4677 sec
0.2308 0.2250 0.2053 0.1781 0.1648 0.1549 0.1496 0.1451 0.1412 0.1411 0.1412 0.1389 0.1393 0.1396 0.1411 0.1407 

[TRAIN] Epoch[5](813/1500); Loss: 0.184724; Backpropagation: 0.0933 sec; Batch: 0.4707 sec
0.3053 0.2707 0.2697 0.2321 0.2259 0.1895 0.1791 0.1581 0.1495 0.1436 0.1404 0.1396 0.1380 0.1379 0.1379 0.1384 

[TRAIN] Epoch[5](814/1500); Loss: 0.134547; Backpropagation: 0.0938 sec; Batch: 0.4683 sec
0.2349 0.2462 0.2031 0.1664 0.1375 0.1155 0.1042 0.1043 0.1058 0.1062 0.1051 0.1043 0.1047 0.1046 0.1046 0.1053 

[TRAIN] Epoch[5](815/1500); Loss: 0.153626; Backpropagation: 0.0939 sec; Batch: 0.4664 sec
0.2260 0.2116 0.2034 0.1828 0.1748 0.1540 0.1459 0.1386 0.1360 0.1310 0.1284 0.1271 0.1251 0.1244 0.1241 0.1249 

[TRAIN] Epoch[5](816/1500); Loss: 0.131671; Backpropagation: 0.0939 sec; Batch: 0.4354 sec
0.2013 0.1943 0.1712 0.1443 0.1358 0.1280 0.1254 0.1153 0.1138 0.1097 0.1102 0.1098 0.1103 0.1120 0.1125 0.1129 

[TRAIN] Epoch[5](817/1500); Loss: 0.094447; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.1553 0.1697 0.1226 0.0951 0.0787 0.0784 0.0769 0.0779 0.0766 0.0784 0.0808 0.0808 0.0827 0.0840 0.0861 0.0872 

[TRAIN] Epoch[5](818/1500); Loss: 0.177350; Backpropagation: 0.0938 sec; Batch: 0.4684 sec
0.2594 0.2368 0.2327 0.2121 0.2056 0.1852 0.1737 0.1603 0.1547 0.1478 0.1508 0.1439 0.1441 0.1432 0.1430 0.1443 

[TRAIN] Epoch[5](819/1500); Loss: 0.092826; Backpropagation: 0.0939 sec; Batch: 0.4800 sec
0.1525 0.1185 0.1187 0.0886 0.0853 0.0931 0.0885 0.0834 0.0794 0.0795 0.0802 0.0813 0.0824 0.0839 0.0845 0.0854 

[TRAIN] Epoch[5](820/1500); Loss: 0.165339; Backpropagation: 0.0937 sec; Batch: 0.4683 sec
0.3050 0.2661 0.2513 0.1855 0.1690 0.1410 0.1335 0.1259 0.1254 0.1327 0.1305 0.1342 0.1350 0.1354 0.1366 0.1385 

[TRAIN] Epoch[5](821/1500); Loss: 0.153080; Backpropagation: 0.0939 sec; Batch: 0.4677 sec
0.2729 0.2439 0.2342 0.1853 0.1748 0.1349 0.1261 0.1221 0.1203 0.1198 0.1170 0.1188 0.1190 0.1200 0.1198 0.1204 

[TRAIN] Epoch[5](822/1500); Loss: 0.143674; Backpropagation: 0.0933 sec; Batch: 0.4659 sec
0.1716 0.1665 0.1550 0.1477 0.1449 0.1408 0.1383 0.1367 0.1350 0.1352 0.1356 0.1366 0.1378 0.1380 0.1394 0.1397 

[TRAIN] Epoch[5](823/1500); Loss: 0.174886; Backpropagation: 0.0933 sec; Batch: 0.4706 sec
0.2952 0.2757 0.2623 0.2190 0.2088 0.1818 0.1699 0.1475 0.1354 0.1263 0.1334 0.1273 0.1271 0.1281 0.1295 0.1308 

[TRAIN] Epoch[5](824/1500); Loss: 0.129359; Backpropagation: 0.0936 sec; Batch: 0.4675 sec
0.1629 0.1574 0.1437 0.1285 0.1241 0.1210 0.1222 0.1249 0.1230 0.1228 0.1235 0.1219 0.1228 0.1231 0.1237 0.1245 

[TRAIN] Epoch[5](825/1500); Loss: 0.112012; Backpropagation: 0.0940 sec; Batch: 0.4345 sec
0.2869 0.2372 0.2416 0.1763 0.1608 0.1054 0.0865 0.0567 0.0578 0.0598 0.0511 0.0516 0.0525 0.0540 0.0559 0.0580 

[TRAIN] Epoch[5](826/1500); Loss: 0.128920; Backpropagation: 0.0938 sec; Batch: 0.4394 sec
0.2593 0.2443 0.2164 0.1606 0.1429 0.1187 0.1098 0.0952 0.0908 0.0873 0.0915 0.0872 0.0878 0.0889 0.0904 0.0917 

[TRAIN] Epoch[5](827/1500); Loss: 0.126451; Backpropagation: 0.0952 sec; Batch: 0.4368 sec
0.1371 0.1349 0.1202 0.1189 0.1158 0.1223 0.1189 0.1216 0.1230 0.1248 0.1258 0.1278 0.1296 0.1317 0.1342 0.1367 

[TRAIN] Epoch[5](828/1500); Loss: 0.136955; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.3018 0.2576 0.2586 0.1996 0.1856 0.1218 0.0999 0.0875 0.0886 0.0873 0.0813 0.0813 0.0826 0.0842 0.0860 0.0876 

[TRAIN] Epoch[5](829/1500); Loss: 0.057489; Backpropagation: 0.0934 sec; Batch: 0.4303 sec
0.1053 0.0748 0.0785 0.0529 0.0472 0.0394 0.0474 0.0524 0.0493 0.0501 0.0506 0.0513 0.0527 0.0541 0.0558 0.0580 

[TRAIN] Epoch[5](830/1500); Loss: 0.086745; Backpropagation: 0.0937 sec; Batch: 0.4675 sec
0.1040 0.1033 0.0878 0.0839 0.0791 0.0824 0.0795 0.0822 0.0827 0.0831 0.0848 0.0845 0.0848 0.0868 0.0885 0.0904 

[TRAIN] Epoch[5](831/1500); Loss: 0.104062; Backpropagation: 0.0934 sec; Batch: 0.4663 sec
0.1838 0.1629 0.1495 0.1160 0.1025 0.0927 0.0867 0.0844 0.0845 0.0839 0.0851 0.0849 0.0858 0.0860 0.0873 0.0889 

[TRAIN] Epoch[5](832/1500); Loss: 0.114214; Backpropagation: 0.0938 sec; Batch: 0.4669 sec
0.2784 0.2292 0.2291 0.1628 0.1502 0.0955 0.0811 0.0729 0.0698 0.0646 0.0632 0.0634 0.0645 0.0659 0.0676 0.0692 

[TRAIN] Epoch[5](833/1500); Loss: 0.214852; Backpropagation: 0.0939 sec; Batch: 0.4638 sec
0.2557 0.2472 0.2332 0.2171 0.2194 0.2079 0.2059 0.1991 0.1990 0.2014 0.2019 0.2045 0.2074 0.2095 0.2124 0.2162 

[TRAIN] Epoch[5](834/1500); Loss: 0.149060; Backpropagation: 0.0932 sec; Batch: 0.4299 sec
0.1841 0.1857 0.1675 0.1517 0.1459 0.1453 0.1410 0.1412 0.1376 0.1381 0.1383 0.1399 0.1400 0.1415 0.1427 0.1443 

[TRAIN] Epoch[5](835/1500); Loss: 0.095018; Backpropagation: 0.0938 sec; Batch: 0.4675 sec
0.1169 0.1152 0.1033 0.0912 0.0885 0.0918 0.0907 0.0899 0.0901 0.0889 0.0895 0.0899 0.0909 0.0931 0.0948 0.0956 

[TRAIN] Epoch[5](836/1500); Loss: 0.081934; Backpropagation: 0.0931 sec; Batch: 0.4658 sec
0.1312 0.1427 0.1004 0.0779 0.0643 0.0688 0.0664 0.0672 0.0682 0.0696 0.0710 0.0723 0.0743 0.0768 0.0789 0.0809 

[TRAIN] Epoch[5](837/1500); Loss: 0.099518; Backpropagation: 0.0978 sec; Batch: 0.4754 sec
0.1840 0.1596 0.1527 0.1238 0.1169 0.0992 0.0891 0.0773 0.0769 0.0723 0.0737 0.0719 0.0729 0.0730 0.0735 0.0755 

[TRAIN] Epoch[5](838/1500); Loss: 0.119636; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.2961 0.2960 0.2134 0.0976 0.0602 0.0669 0.0713 0.0850 0.0844 0.0845 0.0861 0.0882 0.0900 0.0943 0.0980 0.1023 

[TRAIN] Epoch[5](839/1500); Loss: 0.140524; Backpropagation: 0.0938 sec; Batch: 0.4705 sec
0.2364 0.2349 0.2003 0.1573 0.1351 0.1188 0.1177 0.1137 0.1133 0.1153 0.1158 0.1155 0.1172 0.1176 0.1190 0.1205 

[TRAIN] Epoch[5](840/1500); Loss: 0.115272; Backpropagation: 0.0939 sec; Batch: 0.4591 sec
0.2358 0.2443 0.1891 0.1248 0.0959 0.0822 0.0823 0.0840 0.0854 0.0849 0.0863 0.0869 0.0878 0.0898 0.0919 0.0931 

[TRAIN] Epoch[5](841/1500); Loss: 0.140036; Backpropagation: 0.0939 sec; Batch: 0.4429 sec
0.2445 0.2127 0.2076 0.1668 0.1613 0.1310 0.1260 0.1133 0.1093 0.1078 0.1072 0.1082 0.1097 0.1107 0.1116 0.1130 

[TRAIN] Epoch[5](842/1500); Loss: 0.126905; Backpropagation: 0.0938 sec; Batch: 0.4704 sec
0.2060 0.1860 0.1755 0.1446 0.1389 0.1284 0.1214 0.1133 0.1049 0.1006 0.1015 0.1045 0.1011 0.1013 0.1011 0.1014 

[TRAIN] Epoch[5](843/1500); Loss: 0.073922; Backpropagation: 0.0956 sec; Batch: 0.4650 sec
0.1182 0.1112 0.0879 0.0644 0.0600 0.0662 0.0617 0.0628 0.0630 0.0646 0.0661 0.0675 0.0695 0.0711 0.0731 0.0754 

[TRAIN] Epoch[5](844/1500); Loss: 0.132369; Backpropagation: 0.0939 sec; Batch: 0.4780 sec
0.2280 0.1891 0.1879 0.1434 0.1380 0.1165 0.1160 0.1102 0.1061 0.1072 0.1077 0.1091 0.1103 0.1140 0.1157 0.1186 

[TRAIN] Epoch[5](845/1500); Loss: 0.089657; Backpropagation: 0.0939 sec; Batch: 0.4706 sec
0.1577 0.1429 0.1294 0.0960 0.0808 0.0842 0.0736 0.0725 0.0728 0.0734 0.0729 0.0740 0.0749 0.0759 0.0764 0.0773 

[TRAIN] Epoch[5](846/1500); Loss: 0.099618; Backpropagation: 0.0937 sec; Batch: 0.4657 sec
0.1555 0.1323 0.1257 0.1083 0.1018 0.0937 0.0882 0.0868 0.0869 0.0858 0.0856 0.0874 0.0874 0.0881 0.0893 0.0912 

[TRAIN] Epoch[5](847/1500); Loss: 0.127723; Backpropagation: 0.0942 sec; Batch: 0.4642 sec
0.1950 0.1768 0.1611 0.1250 0.1133 0.1123 0.1116 0.1128 0.1126 0.1134 0.1145 0.1164 0.1184 0.1186 0.1200 0.1217 

[TRAIN] Epoch[5](848/1500); Loss: 0.129986; Backpropagation: 0.0937 sec; Batch: 0.4697 sec
0.1953 0.1907 0.1621 0.1336 0.1265 0.1155 0.1140 0.1149 0.1118 0.1137 0.1151 0.1159 0.1160 0.1167 0.1180 0.1199 

[TRAIN] Epoch[5](849/1500); Loss: 0.091566; Backpropagation: 0.0957 sec; Batch: 0.4731 sec
0.1612 0.1310 0.1272 0.0988 0.0935 0.0821 0.0831 0.0805 0.0747 0.0745 0.0739 0.0747 0.0756 0.0766 0.0781 0.0796 

[TRAIN] Epoch[5](850/1500); Loss: 0.157159; Backpropagation: 0.0944 sec; Batch: 0.4687 sec
0.2648 0.2506 0.2271 0.1822 0.1716 0.1567 0.1518 0.1339 0.1300 0.1233 0.1234 0.1201 0.1196 0.1201 0.1194 0.1199 

[TRAIN] Epoch[5](851/1500); Loss: 0.126566; Backpropagation: 0.0939 sec; Batch: 0.4661 sec
0.1635 0.1589 0.1403 0.1260 0.1171 0.1227 0.1179 0.1178 0.1171 0.1183 0.1173 0.1186 0.1205 0.1216 0.1229 0.1246 

[TRAIN] Epoch[5](852/1500); Loss: 0.123003; Backpropagation: 0.0937 sec; Batch: 0.4662 sec
0.2167 0.2227 0.1702 0.1149 0.0955 0.0974 0.0997 0.0998 0.1012 0.1032 0.1036 0.1061 0.1067 0.1081 0.1101 0.1122 

[TRAIN] Epoch[5](853/1500); Loss: 0.147902; Backpropagation: 0.0938 sec; Batch: 0.4670 sec
0.2038 0.1950 0.1801 0.1594 0.1445 0.1394 0.1382 0.1368 0.1335 0.1325 0.1329 0.1334 0.1340 0.1330 0.1342 0.1359 

[TRAIN] Epoch[5](854/1500); Loss: 0.103539; Backpropagation: 0.0957 sec; Batch: 0.4695 sec
0.1860 0.1611 0.1587 0.1294 0.1213 0.1006 0.0891 0.0820 0.0799 0.0829 0.0800 0.0758 0.0761 0.0766 0.0781 0.0789 

[TRAIN] Epoch[5](855/1500); Loss: 0.104345; Backpropagation: 0.0957 sec; Batch: 0.4673 sec
0.1720 0.1555 0.1433 0.1155 0.1059 0.0930 0.0898 0.0902 0.0871 0.0853 0.0859 0.0865 0.0876 0.0892 0.0904 0.0923 

[TRAIN] Epoch[5](856/1500); Loss: 0.089201; Backpropagation: 0.0937 sec; Batch: 0.4714 sec
0.1209 0.1121 0.0919 0.0861 0.0800 0.0805 0.0787 0.0810 0.0825 0.0834 0.0837 0.0851 0.0873 0.0892 0.0913 0.0934 

[TRAIN] Epoch[5](857/1500); Loss: 0.128257; Backpropagation: 0.0940 sec; Batch: 0.4674 sec
0.2722 0.2511 0.2225 0.1686 0.1547 0.1186 0.0964 0.0762 0.0885 0.0840 0.0825 0.0832 0.0840 0.0865 0.0901 0.0929 

[TRAIN] Epoch[5](858/1500); Loss: 0.068573; Backpropagation: 0.0938 sec; Batch: 0.4697 sec
0.1161 0.1013 0.0818 0.0651 0.0583 0.0690 0.0583 0.0597 0.0574 0.0582 0.0587 0.0592 0.0613 0.0624 0.0641 0.0661 

[TRAIN] Epoch[5](859/1500); Loss: 0.099008; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1582 0.1369 0.1249 0.1077 0.1027 0.0978 0.0936 0.0851 0.0847 0.0838 0.0839 0.0825 0.0836 0.0850 0.0862 0.0875 

[TRAIN] Epoch[5](860/1500); Loss: 0.128630; Backpropagation: 0.0937 sec; Batch: 0.4673 sec
0.2033 0.1989 0.1758 0.1509 0.1373 0.1231 0.1166 0.1083 0.1069 0.1048 0.1026 0.1035 0.1046 0.1060 0.1074 0.1079 

[TRAIN] Epoch[5](861/1500); Loss: 0.070275; Backpropagation: 0.0938 sec; Batch: 0.4712 sec
0.1085 0.1008 0.0699 0.0624 0.0606 0.0626 0.0607 0.0610 0.0618 0.0625 0.0649 0.0665 0.0679 0.0696 0.0717 0.0731 

[TRAIN] Epoch[5](862/1500); Loss: 0.097058; Backpropagation: 0.0936 sec; Batch: 0.5271 sec
0.1481 0.1496 0.1166 0.1046 0.0930 0.0893 0.0870 0.0840 0.0830 0.0824 0.0826 0.0837 0.0851 0.0867 0.0879 0.0893 

[TRAIN] Epoch[5](863/1500); Loss: 0.151297; Backpropagation: 0.0938 sec; Batch: 0.4695 sec
0.2874 0.2478 0.2473 0.2016 0.1900 0.1501 0.1341 0.1146 0.1088 0.1082 0.1080 0.1055 0.1032 0.1034 0.1045 0.1064 

[TRAIN] Epoch[5](864/1500); Loss: 0.117833; Backpropagation: 0.0939 sec; Batch: 0.4714 sec
0.2201 0.2032 0.1646 0.1205 0.1108 0.1008 0.0999 0.0981 0.0969 0.0975 0.0961 0.0943 0.0939 0.0949 0.0961 0.0976 

[TRAIN] Epoch[5](865/1500); Loss: 0.158247; Backpropagation: 0.0983 sec; Batch: 0.4353 sec
0.2198 0.2037 0.1909 0.1687 0.1609 0.1481 0.1455 0.1459 0.1454 0.1423 0.1421 0.1425 0.1424 0.1432 0.1445 0.1460 

[TRAIN] Epoch[5](866/1500); Loss: 0.193528; Backpropagation: 0.0956 sec; Batch: 0.4673 sec
0.3307 0.2973 0.2963 0.2563 0.2467 0.2107 0.1936 0.1658 0.1560 0.1427 0.1391 0.1337 0.1295 0.1326 0.1328 0.1327 

[TRAIN] Epoch[5](867/1500); Loss: 0.072287; Backpropagation: 0.0933 sec; Batch: 0.4692 sec
0.1553 0.1237 0.1101 0.0806 0.0688 0.0563 0.0622 0.0595 0.0511 0.0507 0.0524 0.0536 0.0542 0.0568 0.0598 0.0615 

[TRAIN] Epoch[5](868/1500); Loss: 0.129472; Backpropagation: 0.0932 sec; Batch: 0.4667 sec
0.1868 0.1754 0.1675 0.1490 0.1412 0.1225 0.1149 0.1132 0.1142 0.1114 0.1106 0.1103 0.1113 0.1130 0.1144 0.1157 

[TRAIN] Epoch[5](869/1500); Loss: 0.098089; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1315 0.1199 0.1091 0.1009 0.0973 0.0918 0.0916 0.0897 0.0886 0.0883 0.0888 0.0898 0.0917 0.0940 0.0967 0.0997 

[TRAIN] Epoch[5](870/1500); Loss: 0.187967; Backpropagation: 0.0940 sec; Batch: 0.5676 sec
0.3221 0.2828 0.2874 0.2507 0.2415 0.2107 0.1921 0.1643 0.1494 0.1397 0.1360 0.1313 0.1285 0.1258 0.1237 0.1215 

[TRAIN] Epoch[5](871/1500); Loss: 0.070055; Backpropagation: 0.0938 sec; Batch: 0.5267 sec
0.1224 0.1034 0.0715 0.0632 0.0607 0.0609 0.0605 0.0609 0.0620 0.0623 0.0630 0.0637 0.0647 0.0659 0.0673 0.0685 

[TRAIN] Epoch[5](872/1500); Loss: 0.126506; Backpropagation: 0.0938 sec; Batch: 0.4645 sec
0.1874 0.1857 0.1616 0.1475 0.1391 0.1245 0.1193 0.1130 0.1105 0.1077 0.1061 0.1026 0.1031 0.1040 0.1055 0.1066 

[TRAIN] Epoch[5](873/1500); Loss: 0.058347; Backpropagation: 0.0937 sec; Batch: 0.4681 sec
0.0645 0.0689 0.0578 0.0548 0.0519 0.0513 0.0509 0.0519 0.0540 0.0553 0.0573 0.0586 0.0610 0.0627 0.0650 0.0678 

[TRAIN] Epoch[5](874/1500); Loss: 0.107807; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.1388 0.1284 0.1206 0.1120 0.1074 0.1010 0.1019 0.1008 0.1009 0.0992 0.0999 0.1007 0.1011 0.1021 0.1038 0.1062 

[TRAIN] Epoch[5](875/1500); Loss: 0.098846; Backpropagation: 0.0933 sec; Batch: 0.4714 sec
0.1654 0.1429 0.1395 0.1175 0.1111 0.0937 0.0893 0.0855 0.0835 0.0811 0.0791 0.0774 0.0776 0.0781 0.0791 0.0807 

[TRAIN] Epoch[5](876/1500); Loss: 0.150686; Backpropagation: 0.0934 sec; Batch: 0.4308 sec
0.2088 0.1963 0.1660 0.1541 0.1530 0.1493 0.1472 0.1431 0.1416 0.1383 0.1362 0.1344 0.1344 0.1350 0.1363 0.1369 

[TRAIN] Epoch[5](877/1500); Loss: 0.162727; Backpropagation: 0.0940 sec; Batch: 0.4296 sec
0.3099 0.2652 0.2623 0.2128 0.2031 0.1598 0.1464 0.1270 0.1217 0.1156 0.1163 0.1114 0.1118 0.1130 0.1131 0.1143 

[TRAIN] Epoch[5](878/1500); Loss: 0.088213; Backpropagation: 0.0932 sec; Batch: 0.4309 sec
0.2868 0.2202 0.1239 0.0498 0.0514 0.0621 0.0602 0.0595 0.0593 0.0593 0.0600 0.0611 0.0623 0.0634 0.0650 0.0669 

[TRAIN] Epoch[5](879/1500); Loss: 0.101280; Backpropagation: 0.0938 sec; Batch: 0.4319 sec
0.1266 0.1252 0.1044 0.1026 0.0978 0.0969 0.0957 0.0963 0.0955 0.0956 0.0960 0.0961 0.0965 0.0976 0.0983 0.0994 

[TRAIN] Epoch[5](880/1500); Loss: 0.132736; Backpropagation: 0.0938 sec; Batch: 0.4494 sec
0.2538 0.2267 0.1904 0.1470 0.1304 0.1134 0.1045 0.1040 0.1139 0.1083 0.1029 0.1020 0.1034 0.1053 0.1076 0.1102 

[TRAIN] Epoch[5](881/1500); Loss: 0.066201; Backpropagation: 0.0939 sec; Batch: 0.4707 sec
0.1241 0.1100 0.0745 0.0582 0.0542 0.0527 0.0533 0.0523 0.0542 0.0566 0.0583 0.0602 0.0602 0.0617 0.0639 0.0648 

[TRAIN] Epoch[5](882/1500); Loss: 0.181593; Backpropagation: 0.0957 sec; Batch: 0.4686 sec
0.2088 0.1998 0.1941 0.1867 0.1845 0.1792 0.1770 0.1747 0.1740 0.1729 0.1721 0.1730 0.1745 0.1764 0.1783 0.1795 

[TRAIN] Epoch[5](883/1500); Loss: 0.075037; Backpropagation: 0.0945 sec; Batch: 0.4539 sec
0.1363 0.1074 0.1018 0.0771 0.0719 0.0609 0.0593 0.0554 0.0581 0.0630 0.0640 0.0642 0.0663 0.0689 0.0715 0.0745 

[TRAIN] Epoch[5](884/1500); Loss: 0.107581; Backpropagation: 0.0939 sec; Batch: 0.4739 sec
0.1738 0.1515 0.1421 0.1187 0.1079 0.0994 0.0978 0.0941 0.0951 0.0922 0.0911 0.0910 0.0912 0.0913 0.0918 0.0923 

[TRAIN] Epoch[5](885/1500); Loss: 0.201447; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.2983 0.2699 0.2662 0.2342 0.2286 0.2017 0.1918 0.1798 0.1767 0.1693 0.1676 0.1672 0.1666 0.1677 0.1682 0.1693 

[TRAIN] Epoch[5](886/1500); Loss: 0.076816; Backpropagation: 0.0937 sec; Batch: 0.4665 sec
0.1278 0.1100 0.0846 0.0778 0.0733 0.0695 0.0674 0.0668 0.0678 0.0686 0.0671 0.0676 0.0687 0.0694 0.0707 0.0719 

[TRAIN] Epoch[5](887/1500); Loss: 0.118169; Backpropagation: 0.0940 sec; Batch: 0.4726 sec
0.1834 0.1537 0.1485 0.1187 0.1102 0.1042 0.1052 0.1107 0.1090 0.1033 0.1044 0.1055 0.1067 0.1081 0.1095 0.1097 

[TRAIN] Epoch[5](888/1500); Loss: 0.076639; Backpropagation: 0.0937 sec; Batch: 0.4656 sec
0.1238 0.0914 0.0909 0.0698 0.0679 0.0824 0.0760 0.0659 0.0659 0.0662 0.0673 0.0692 0.0712 0.0720 0.0728 0.0735 

[TRAIN] Epoch[5](889/1500); Loss: 0.167337; Backpropagation: 0.0939 sec; Batch: 0.4716 sec
0.2656 0.2364 0.2140 0.1819 0.1764 0.1617 0.1587 0.1503 0.1484 0.1444 0.1431 0.1404 0.1388 0.1383 0.1390 0.1400 

[TRAIN] Epoch[5](890/1500); Loss: 0.070062; Backpropagation: 0.0933 sec; Batch: 0.4657 sec
0.1428 0.1167 0.0877 0.0624 0.0573 0.0574 0.0563 0.0576 0.0588 0.0585 0.0590 0.0601 0.0604 0.0614 0.0618 0.0626 

[TRAIN] Epoch[5](891/1500); Loss: 0.173893; Backpropagation: 0.0933 sec; Batch: 0.4698 sec
0.3798 0.3374 0.3316 0.2736 0.2492 0.1918 0.1527 0.1092 0.1006 0.1013 0.0972 0.0890 0.0903 0.0912 0.0926 0.0947 

[TRAIN] Epoch[5](892/1500); Loss: 0.166029; Backpropagation: 0.0934 sec; Batch: 0.4673 sec
0.3084 0.2769 0.2718 0.2298 0.2157 0.1744 0.1525 0.1277 0.1178 0.1112 0.1136 0.1113 0.1112 0.1120 0.1115 0.1108 

[TRAIN] Epoch[5](893/1500); Loss: 0.157003; Backpropagation: 0.0939 sec; Batch: 0.4720 sec
0.3053 0.2650 0.2450 0.1946 0.1738 0.1528 0.1454 0.1328 0.1266 0.1165 0.1127 0.1093 0.1083 0.1076 0.1081 0.1082 

[TRAIN] Epoch[5](894/1500); Loss: 0.150971; Backpropagation: 0.0938 sec; Batch: 0.4664 sec
0.2636 0.2314 0.2277 0.1944 0.1851 0.1530 0.1467 0.1308 0.1268 0.1173 0.1153 0.1083 0.1067 0.1037 0.1031 0.1015 

[TRAIN] Epoch[5](895/1500); Loss: 0.145119; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2054 0.1859 0.1839 0.1641 0.1550 0.1389 0.1333 0.1330 0.1321 0.1286 0.1267 0.1263 0.1271 0.1275 0.1268 0.1272 

[TRAIN] Epoch[5](896/1500); Loss: 0.107213; Backpropagation: 0.0937 sec; Batch: 0.4653 sec
0.2724 0.2172 0.2172 0.1555 0.1428 0.0896 0.0736 0.0613 0.0628 0.0676 0.0600 0.0573 0.0577 0.0588 0.0599 0.0616 

[TRAIN] Epoch[5](897/1500); Loss: 0.069958; Backpropagation: 0.0934 sec; Batch: 0.4306 sec
0.1893 0.1366 0.0711 0.0637 0.0532 0.0535 0.0522 0.0519 0.0521 0.0524 0.0534 0.0545 0.0559 0.0577 0.0597 0.0621 

[TRAIN] Epoch[5](898/1500); Loss: 0.129384; Backpropagation: 0.0932 sec; Batch: 0.4662 sec
0.2469 0.2061 0.1974 0.1618 0.1531 0.1217 0.1120 0.1019 0.0979 0.0983 0.0965 0.0937 0.0940 0.0951 0.0964 0.0974 

[TRAIN] Epoch[5](899/1500); Loss: 0.073935; Backpropagation: 0.0933 sec; Batch: 0.4729 sec
0.2180 0.1758 0.1045 0.0519 0.0505 0.0505 0.0523 0.0536 0.0528 0.0523 0.0519 0.0523 0.0524 0.0543 0.0550 0.0550 

[TRAIN] Epoch[5](900/1500); Loss: 0.168269; Backpropagation: 0.0933 sec; Batch: 0.4691 sec
0.3101 0.2809 0.2692 0.2169 0.1980 0.1641 0.1512 0.1354 0.1273 0.1197 0.1211 0.1291 0.1233 0.1154 0.1152 0.1153 

[TRAIN] Epoch[5](901/1500); Loss: 0.099933; Backpropagation: 0.0933 sec; Batch: 0.4349 sec
0.1862 0.1477 0.1471 0.1017 0.0960 0.0811 0.0870 0.1027 0.0916 0.0767 0.0789 0.0793 0.0783 0.0797 0.0820 0.0829 

[TRAIN] Epoch[5](902/1500); Loss: 0.124440; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1634 0.1472 0.1379 0.1267 0.1237 0.1200 0.1187 0.1168 0.1165 0.1164 0.1164 0.1163 0.1167 0.1172 0.1180 0.1190 

[TRAIN] Epoch[5](903/1500); Loss: 0.083459; Backpropagation: 0.0934 sec; Batch: 0.4465 sec
0.1388 0.1206 0.1016 0.0830 0.0799 0.0781 0.0799 0.0743 0.0738 0.0706 0.0710 0.0719 0.0719 0.0723 0.0734 0.0743 

[TRAIN] Epoch[5](904/1500); Loss: 0.177400; Backpropagation: 0.0931 sec; Batch: 0.4486 sec
0.3436 0.2945 0.2919 0.2284 0.2150 0.1632 0.1451 0.1314 0.1309 0.1327 0.1279 0.1251 0.1255 0.1266 0.1275 0.1289 

[TRAIN] Epoch[5](905/1500); Loss: 0.139597; Backpropagation: 0.0932 sec; Batch: 0.4642 sec
0.1842 0.1708 0.1560 0.1431 0.1378 0.1319 0.1297 0.1282 0.1280 0.1287 0.1297 0.1299 0.1313 0.1332 0.1349 0.1362 

[TRAIN] Epoch[5](906/1500); Loss: 0.082325; Backpropagation: 0.0931 sec; Batch: 0.4672 sec
0.1342 0.1197 0.1006 0.0813 0.0750 0.0719 0.0722 0.0780 0.0766 0.0719 0.0730 0.0712 0.0713 0.0725 0.0733 0.0746 

[TRAIN] Epoch[5](907/1500); Loss: 0.068558; Backpropagation: 0.0934 sec; Batch: 0.4312 sec
0.1507 0.1290 0.0818 0.0599 0.0586 0.0559 0.0555 0.0544 0.0546 0.0553 0.0557 0.0560 0.0563 0.0571 0.0576 0.0585 

[TRAIN] Epoch[5](908/1500); Loss: 0.181263; Backpropagation: 0.0932 sec; Batch: 0.4657 sec
0.2680 0.2400 0.2267 0.1975 0.1945 0.1775 0.1731 0.1629 0.1601 0.1619 0.1616 0.1556 0.1556 0.1547 0.1550 0.1555 

[TRAIN] Epoch[5](909/1500); Loss: 0.074337; Backpropagation: 0.0943 sec; Batch: 0.4290 sec
0.1546 0.1360 0.0937 0.0716 0.0637 0.0630 0.0627 0.0601 0.0605 0.0591 0.0596 0.0587 0.0598 0.0611 0.0622 0.0629 

[TRAIN] Epoch[5](910/1500); Loss: 0.119419; Backpropagation: 0.0957 sec; Batch: 0.4437 sec
0.1855 0.1625 0.1313 0.1195 0.1146 0.1102 0.1103 0.1075 0.1082 0.1067 0.1075 0.1080 0.1086 0.1092 0.1101 0.1111 

[TRAIN] Epoch[5](911/1500); Loss: 0.174320; Backpropagation: 0.0938 sec; Batch: 0.4705 sec
0.3571 0.3236 0.3127 0.2541 0.2355 0.1864 0.1611 0.1267 0.1146 0.1026 0.1024 0.1091 0.1053 0.0987 0.0996 0.0997 

[TRAIN] Epoch[5](912/1500); Loss: 0.139742; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2610 0.2310 0.2182 0.1755 0.1649 0.1318 0.1199 0.1049 0.1064 0.1081 0.1035 0.1025 0.1015 0.1018 0.1021 0.1027 

[TRAIN] Epoch[5](913/1500); Loss: 0.155426; Backpropagation: 0.0935 sec; Batch: 0.4672 sec
0.3508 0.3078 0.3062 0.2468 0.2281 0.1783 0.1502 0.1019 0.0847 0.0755 0.0746 0.0842 0.0830 0.0712 0.0718 0.0717 

[TRAIN] Epoch[5](914/1500); Loss: 0.119161; Backpropagation: 0.0932 sec; Batch: 0.4696 sec
0.1992 0.1753 0.1665 0.1319 0.1230 0.1110 0.1102 0.1056 0.0993 0.0976 0.0982 0.0973 0.0975 0.0978 0.0980 0.0981 

[TRAIN] Epoch[5](915/1500); Loss: 0.167345; Backpropagation: 0.0942 sec; Batch: 0.4282 sec
0.1877 0.1832 0.1769 0.1732 0.1707 0.1666 0.1653 0.1641 0.1627 0.1616 0.1613 0.1599 0.1605 0.1611 0.1611 0.1618 

[TRAIN] Epoch[5](916/1500); Loss: 0.144240; Backpropagation: 0.0937 sec; Batch: 0.4649 sec
0.3120 0.2614 0.2501 0.1871 0.1719 0.1342 0.1153 0.1105 0.1038 0.0960 0.0964 0.0938 0.0941 0.0930 0.0936 0.0947 

[TRAIN] Epoch[5](917/1500); Loss: 0.139021; Backpropagation: 0.0940 sec; Batch: 0.4675 sec
0.2138 0.1870 0.1749 0.1536 0.1496 0.1418 0.1356 0.1251 0.1202 0.1189 0.1189 0.1171 0.1164 0.1163 0.1171 0.1181 

[TRAIN] Epoch[5](918/1500); Loss: 0.122173; Backpropagation: 0.0938 sec; Batch: 0.4653 sec
0.2337 0.2121 0.1999 0.1594 0.1395 0.1123 0.0992 0.0935 0.0948 0.0877 0.0873 0.0852 0.0861 0.0871 0.0880 0.0887 

[TRAIN] Epoch[5](919/1500); Loss: 0.081408; Backpropagation: 0.0932 sec; Batch: 0.4665 sec
0.0918 0.1000 0.0821 0.0862 0.0826 0.0822 0.0798 0.0777 0.0772 0.0770 0.0768 0.0766 0.0771 0.0776 0.0784 0.0792 

[TRAIN] Epoch[5](920/1500); Loss: 0.083372; Backpropagation: 0.0939 sec; Batch: 0.4680 sec
0.1157 0.1098 0.0949 0.0841 0.0789 0.0830 0.0838 0.0756 0.0759 0.0756 0.0757 0.0761 0.0763 0.0756 0.0759 0.0772 

[TRAIN] Epoch[5](921/1500); Loss: 0.168248; Backpropagation: 0.0932 sec; Batch: 0.4657 sec
0.2635 0.2421 0.2304 0.1971 0.1867 0.1679 0.1572 0.1412 0.1414 0.1394 0.1389 0.1378 0.1370 0.1368 0.1369 0.1376 

[TRAIN] Epoch[5](922/1500); Loss: 0.126303; Backpropagation: 0.0937 sec; Batch: 0.4676 sec
0.2030 0.1817 0.1720 0.1423 0.1319 0.1182 0.1151 0.1151 0.1142 0.1066 0.1057 0.1047 0.1028 0.1017 0.1024 0.1034 

[TRAIN] Epoch[5](923/1500); Loss: 0.097798; Backpropagation: 0.0939 sec; Batch: 0.4674 sec
0.2257 0.1969 0.1808 0.1302 0.1072 0.0825 0.0722 0.0690 0.0718 0.0620 0.0605 0.0606 0.0604 0.0608 0.0616 0.0625 

[TRAIN] Epoch[5](924/1500); Loss: 0.117605; Backpropagation: 0.0938 sec; Batch: 0.4662 sec
0.1943 0.1689 0.1538 0.1245 0.1180 0.1107 0.1120 0.1040 0.1014 0.0993 0.0992 0.0987 0.0986 0.0989 0.0992 0.1003 

[TRAIN] Epoch[5](925/1500); Loss: 0.090113; Backpropagation: 0.0938 sec; Batch: 0.4670 sec
0.2100 0.1686 0.1618 0.1138 0.1059 0.0828 0.0675 0.0631 0.0724 0.0548 0.0564 0.0561 0.0564 0.0570 0.0575 0.0576 

[TRAIN] Epoch[5](926/1500); Loss: 0.067952; Backpropagation: 0.0951 sec; Batch: 0.4687 sec
0.0940 0.0925 0.0715 0.0644 0.0662 0.0657 0.0602 0.0602 0.0613 0.0615 0.0621 0.0628 0.0643 0.0654 0.0669 0.0683 

[TRAIN] Epoch[5](927/1500); Loss: 0.184678; Backpropagation: 0.0958 sec; Batch: 0.4723 sec
0.3181 0.2870 0.2653 0.2234 0.2126 0.1786 0.1661 0.1505 0.1531 0.1503 0.1418 0.1398 0.1407 0.1415 0.1423 0.1437 

[TRAIN] Epoch[5](928/1500); Loss: 0.121899; Backpropagation: 0.0956 sec; Batch: 0.5155 sec
0.1590 0.1381 0.1318 0.1248 0.1250 0.1227 0.1211 0.1211 0.1172 0.1113 0.1118 0.1126 0.1136 0.1131 0.1133 0.1141 

[TRAIN] Epoch[5](929/1500); Loss: 0.098422; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.2892 0.2437 0.1749 0.1038 0.0652 0.0665 0.0629 0.0632 0.0638 0.0635 0.0628 0.0632 0.0635 0.0632 0.0626 0.0628 

[TRAIN] Epoch[5](930/1500); Loss: 0.098701; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.2356 0.1849 0.1809 0.1156 0.1045 0.0739 0.0737 0.0795 0.0692 0.0662 0.0655 0.0659 0.0654 0.0655 0.0659 0.0670 

[TRAIN] Epoch[5](931/1500); Loss: 0.066369; Backpropagation: 0.0938 sec; Batch: 0.4686 sec
0.1286 0.0905 0.0629 0.0647 0.0599 0.0599 0.0586 0.0582 0.0586 0.0591 0.0588 0.0594 0.0599 0.0601 0.0610 0.0618 

[TRAIN] Epoch[5](932/1500); Loss: 0.155330; Backpropagation: 0.0938 sec; Batch: 0.4698 sec
0.3946 0.3364 0.3337 0.2323 0.2002 0.1284 0.0958 0.1055 0.1161 0.0783 0.0794 0.0751 0.0754 0.0765 0.0780 0.0795 

[TRAIN] Epoch[5](933/1500); Loss: 0.094270; Backpropagation: 0.0943 sec; Batch: 0.6037 sec
0.1152 0.1070 0.0918 0.0948 0.0942 0.0933 0.0925 0.0926 0.0908 0.0894 0.0896 0.0907 0.0910 0.0912 0.0918 0.0924 

[TRAIN] Epoch[5](934/1500); Loss: 0.130277; Backpropagation: 0.0938 sec; Batch: 0.5092 sec
0.2301 0.2061 0.1725 0.1366 0.1303 0.1161 0.1126 0.1145 0.1137 0.1089 0.1075 0.1069 0.1071 0.1067 0.1072 0.1077 

[TRAIN] Epoch[5](935/1500); Loss: 0.092268; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.1925 0.1536 0.1504 0.1094 0.0981 0.0715 0.0704 0.0761 0.0689 0.0693 0.0676 0.0682 0.0687 0.0693 0.0705 0.0718 

[TRAIN] Epoch[5](936/1500); Loss: 0.145115; Backpropagation: 0.0936 sec; Batch: 0.4701 sec
0.2307 0.2078 0.1907 0.1632 0.1553 0.1394 0.1320 0.1305 0.1278 0.1214 0.1205 0.1193 0.1198 0.1208 0.1214 0.1212 

[TRAIN] Epoch[5](937/1500); Loss: 0.130589; Backpropagation: 0.0957 sec; Batch: 0.4701 sec
0.1912 0.1827 0.1612 0.1469 0.1414 0.1292 0.1234 0.1184 0.1159 0.1126 0.1116 0.1110 0.1108 0.1111 0.1110 0.1111 

[TRAIN] Epoch[5](938/1500); Loss: 0.110239; Backpropagation: 0.0939 sec; Batch: 0.4762 sec
0.1679 0.1503 0.1392 0.1200 0.1094 0.1002 0.0976 0.0944 0.0942 0.0949 0.0965 0.0983 0.0993 0.0998 0.1003 0.1015 

[TRAIN] Epoch[5](939/1500); Loss: 0.104058; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1576 0.1311 0.1239 0.1111 0.1116 0.1061 0.0973 0.0932 0.0926 0.0923 0.0910 0.0910 0.0917 0.0913 0.0912 0.0921 

[TRAIN] Epoch[5](940/1500); Loss: 0.119839; Backpropagation: 0.0939 sec; Batch: 0.4335 sec
0.1994 0.1715 0.1476 0.1215 0.1121 0.1101 0.1085 0.1053 0.1055 0.1060 0.1062 0.1056 0.1051 0.1045 0.1042 0.1043 

[TRAIN] Epoch[5](941/1500); Loss: 0.090751; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1839 0.1597 0.1339 0.1104 0.0996 0.0889 0.0803 0.0689 0.0655 0.0640 0.0648 0.0653 0.0659 0.0662 0.0667 0.0679 

[TRAIN] Epoch[5](942/1500); Loss: 0.102671; Backpropagation: 0.0945 sec; Batch: 0.4380 sec
0.1728 0.1451 0.1404 0.1122 0.1048 0.0948 0.0918 0.0892 0.0865 0.0870 0.0849 0.0850 0.0856 0.0865 0.0876 0.0885 

[TRAIN] Epoch[5](943/1500); Loss: 0.134056; Backpropagation: 0.0942 sec; Batch: 0.5315 sec
0.2191 0.1971 0.1670 0.1399 0.1289 0.1216 0.1176 0.1159 0.1150 0.1159 0.1164 0.1179 0.1184 0.1176 0.1181 0.1184 

[TRAIN] Epoch[5](944/1500); Loss: 0.128751; Backpropagation: 0.0937 sec; Batch: 0.4651 sec
0.2097 0.1775 0.1758 0.1406 0.1326 0.1176 0.1155 0.1178 0.1141 0.1083 0.1078 0.1083 0.1088 0.1085 0.1088 0.1084 

[TRAIN] Epoch[5](945/1500); Loss: 0.121044; Backpropagation: 0.0939 sec; Batch: 0.5034 sec
0.1989 0.1689 0.1601 0.1269 0.1196 0.1110 0.1111 0.1066 0.1046 0.1029 0.1031 0.1040 0.1041 0.1048 0.1052 0.1051 

[TRAIN] Epoch[5](946/1500); Loss: 0.124708; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1863 0.1696 0.1429 0.1290 0.1256 0.1187 0.1164 0.1142 0.1125 0.1118 0.1112 0.1110 0.1107 0.1111 0.1117 0.1126 

[TRAIN] Epoch[5](947/1500); Loss: 0.129202; Backpropagation: 0.0939 sec; Batch: 0.4678 sec
0.1794 0.1735 0.1538 0.1394 0.1310 0.1281 0.1232 0.1162 0.1148 0.1142 0.1145 0.1159 0.1165 0.1155 0.1157 0.1155 

[TRAIN] Epoch[5](948/1500); Loss: 0.080133; Backpropagation: 0.0938 sec; Batch: 0.4658 sec
0.2041 0.1616 0.1618 0.1037 0.0883 0.0627 0.0565 0.0632 0.0654 0.0460 0.0442 0.0438 0.0440 0.0447 0.0457 0.0465 

[TRAIN] Epoch[5](949/1500); Loss: 0.123168; Backpropagation: 0.0942 sec; Batch: 0.5029 sec
0.2127 0.1796 0.1323 0.1135 0.1137 0.1134 0.1121 0.1114 0.1109 0.1106 0.1101 0.1101 0.1100 0.1099 0.1100 0.1106 

[TRAIN] Epoch[5](950/1500); Loss: 0.063964; Backpropagation: 0.0938 sec; Batch: 0.4673 sec
0.1270 0.0888 0.0615 0.0616 0.0582 0.0574 0.0565 0.0561 0.0561 0.0560 0.0561 0.0564 0.0570 0.0575 0.0582 0.0591 

[TRAIN] Epoch[5](951/1500); Loss: 0.106636; Backpropagation: 0.0938 sec; Batch: 0.4660 sec
0.1456 0.1376 0.1131 0.1095 0.1061 0.1041 0.1006 0.0996 0.0991 0.0978 0.0972 0.0980 0.0987 0.0990 0.0997 0.1006 

[TRAIN] Epoch[5](952/1500); Loss: 0.114685; Backpropagation: 0.0938 sec; Batch: 0.4705 sec
0.1550 0.1436 0.1296 0.1150 0.1083 0.1064 0.1087 0.1086 0.1073 0.1072 0.1075 0.1077 0.1076 0.1074 0.1072 0.1079 

[TRAIN] Epoch[5](953/1500); Loss: 0.112468; Backpropagation: 0.0939 sec; Batch: 0.4714 sec
0.1669 0.1448 0.1196 0.1141 0.1081 0.1060 0.1050 0.1046 0.1041 0.1039 0.1037 0.1038 0.1035 0.1036 0.1037 0.1042 

[TRAIN] Epoch[5](954/1500); Loss: 0.105040; Backpropagation: 0.0981 sec; Batch: 0.4709 sec
0.1673 0.1462 0.1433 0.1254 0.1176 0.0995 0.0920 0.0857 0.0896 0.0901 0.0868 0.0869 0.0872 0.0875 0.0879 0.0875 

[TRAIN] Epoch[5](955/1500); Loss: 0.139136; Backpropagation: 0.0957 sec; Batch: 0.4719 sec
0.3439 0.3011 0.2963 0.2118 0.1839 0.1255 0.0926 0.0804 0.0995 0.0715 0.0672 0.0684 0.0690 0.0698 0.0716 0.0738 

[TRAIN] Epoch[5](956/1500); Loss: 0.100210; Backpropagation: 0.0937 sec; Batch: 0.5126 sec
0.2317 0.1943 0.1418 0.1003 0.0805 0.0787 0.0774 0.0774 0.0766 0.0767 0.0765 0.0769 0.0775 0.0780 0.0790 0.0802 

[TRAIN] Epoch[5](957/1500); Loss: 0.106264; Backpropagation: 0.0939 sec; Batch: 0.5037 sec
0.2168 0.1840 0.1656 0.1149 0.0980 0.0915 0.0821 0.0809 0.0821 0.0812 0.0823 0.0830 0.0832 0.0841 0.0847 0.0856 

[TRAIN] Epoch[5](958/1500); Loss: 0.079923; Backpropagation: 0.0937 sec; Batch: 0.4660 sec
0.1176 0.0902 0.0743 0.0776 0.0765 0.0760 0.0750 0.0744 0.0753 0.0755 0.0756 0.0760 0.0770 0.0781 0.0792 0.0803 

[TRAIN] Epoch[5](959/1500); Loss: 0.118254; Backpropagation: 0.0942 sec; Batch: 0.4296 sec
0.1834 0.1712 0.1526 0.1340 0.1255 0.1134 0.1097 0.1039 0.1024 0.1007 0.0992 0.0992 0.0981 0.0986 0.0995 0.1006 

[TRAIN] Epoch[5](960/1500); Loss: 0.168422; Backpropagation: 0.0938 sec; Batch: 0.4954 sec
0.1950 0.1921 0.1756 0.1774 0.1732 0.1709 0.1679 0.1626 0.1624 0.1605 0.1601 0.1595 0.1591 0.1592 0.1594 0.1598 

[TRAIN] Epoch[5](961/1500); Loss: 0.083914; Backpropagation: 0.0932 sec; Batch: 0.4672 sec
0.1295 0.1033 0.1022 0.0799 0.0784 0.0813 0.0844 0.0783 0.0771 0.0753 0.0750 0.0745 0.0747 0.0752 0.0762 0.0774 

[TRAIN] Epoch[5](962/1500); Loss: 0.118955; Backpropagation: 0.0938 sec; Batch: 0.4588 sec
0.2060 0.1724 0.1640 0.1224 0.1155 0.1088 0.1082 0.1049 0.1020 0.1001 0.0998 0.0994 0.0993 0.0996 0.1000 0.1006 

[TRAIN] Epoch[5](963/1500); Loss: 0.103037; Backpropagation: 0.0939 sec; Batch: 0.4682 sec
0.2048 0.1752 0.1668 0.1264 0.1158 0.0909 0.0832 0.0780 0.0796 0.0759 0.0745 0.0749 0.0750 0.0753 0.0757 0.0766 

[TRAIN] Epoch[5](964/1500); Loss: 0.135471; Backpropagation: 0.0956 sec; Batch: 0.4714 sec
0.2174 0.1990 0.1854 0.1571 0.1478 0.1329 0.1263 0.1200 0.1157 0.1120 0.1097 0.1095 0.1091 0.1088 0.1084 0.1084 

[TRAIN] Epoch[5](965/1500); Loss: 0.137397; Backpropagation: 0.0982 sec; Batch: 0.4794 sec
0.1715 0.1692 0.1610 0.1542 0.1482 0.1379 0.1335 0.1302 0.1276 0.1243 0.1235 0.1239 0.1248 0.1234 0.1226 0.1226 

[TRAIN] Epoch[5](966/1500); Loss: 0.097489; Backpropagation: 0.0967 sec; Batch: 0.4670 sec
0.1494 0.1362 0.1201 0.1029 0.0980 0.0912 0.0903 0.0893 0.0894 0.0846 0.0845 0.0851 0.0840 0.0842 0.0848 0.0859 

[TRAIN] Epoch[5](967/1500); Loss: 0.095664; Backpropagation: 0.0939 sec; Batch: 0.4678 sec
0.1362 0.1218 0.1170 0.1090 0.1068 0.0907 0.0880 0.0852 0.0839 0.0829 0.0833 0.0840 0.0842 0.0847 0.0857 0.0872 

[TRAIN] Epoch[5](968/1500); Loss: 0.127941; Backpropagation: 0.0931 sec; Batch: 0.4660 sec
0.2139 0.1949 0.1781 0.1480 0.1418 0.1206 0.1139 0.1051 0.1054 0.1069 0.1046 0.1035 0.1025 0.1023 0.1026 0.1028 

[TRAIN] Epoch[5](969/1500); Loss: 0.123395; Backpropagation: 0.0939 sec; Batch: 0.4294 sec
0.1882 0.1702 0.1380 0.1225 0.1202 0.1162 0.1143 0.1133 0.1126 0.1111 0.1102 0.1107 0.1115 0.1120 0.1118 0.1116 

[TRAIN] Epoch[5](970/1500); Loss: 0.131192; Backpropagation: 0.0979 sec; Batch: 0.4499 sec
0.2414 0.2151 0.1997 0.1680 0.1504 0.1273 0.1180 0.1033 0.0982 0.0958 0.0978 0.0969 0.0963 0.0963 0.0969 0.0977 

[TRAIN] Epoch[5](971/1500); Loss: 0.121292; Backpropagation: 0.0981 sec; Batch: 0.4710 sec
0.2526 0.2145 0.2130 0.1579 0.1426 0.1101 0.0965 0.0879 0.0893 0.0834 0.0814 0.0814 0.0817 0.0819 0.0828 0.0837 

[TRAIN] Epoch[5](972/1500); Loss: 0.112944; Backpropagation: 0.0982 sec; Batch: 0.4748 sec
0.1779 0.1507 0.1247 0.1158 0.1137 0.1085 0.1057 0.1048 0.1041 0.1015 0.1007 0.1002 0.0998 0.0995 0.0997 0.0998 

[TRAIN] Epoch[5](973/1500); Loss: 0.125068; Backpropagation: 0.0939 sec; Batch: 0.4819 sec
0.3562 0.3017 0.2961 0.1962 0.1713 0.0971 0.0636 0.0743 0.0789 0.0555 0.0528 0.0515 0.0515 0.0510 0.0513 0.0519 

[TRAIN] Epoch[5](974/1500); Loss: 0.104602; Backpropagation: 0.0938 sec; Batch: 0.4701 sec
0.2922 0.2503 0.1884 0.1177 0.0745 0.0783 0.0723 0.0695 0.0691 0.0670 0.0656 0.0651 0.0652 0.0659 0.0661 0.0665 

[TRAIN] Epoch[5](975/1500); Loss: 0.094276; Backpropagation: 0.0939 sec; Batch: 0.4671 sec
0.1497 0.1271 0.1192 0.1001 0.0972 0.0938 0.0899 0.0855 0.0833 0.0820 0.0811 0.0805 0.0802 0.0797 0.0795 0.0795 

[TRAIN] Epoch[5](976/1500); Loss: 0.131292; Backpropagation: 0.0939 sec; Batch: 0.4661 sec
0.2861 0.2565 0.2386 0.1877 0.1724 0.1367 0.1156 0.0815 0.0762 0.0838 0.0768 0.0782 0.0775 0.0772 0.0776 0.0783 

[TRAIN] Epoch[5](977/1500); Loss: 0.099592; Backpropagation: 0.0938 sec; Batch: 0.4470 sec
0.1755 0.1595 0.1086 0.0997 0.0934 0.0907 0.0894 0.0872 0.0865 0.0872 0.0857 0.0853 0.0853 0.0860 0.0865 0.0869 

[TRAIN] Epoch[5](978/1500); Loss: 0.099038; Backpropagation: 0.0939 sec; Batch: 0.4312 sec
0.2890 0.2077 0.1163 0.0650 0.0565 0.0653 0.0803 0.0858 0.0811 0.0805 0.0795 0.0776 0.0764 0.0752 0.0744 0.0739 

[TRAIN] Epoch[5](979/1500); Loss: 0.117146; Backpropagation: 0.0942 sec; Batch: 0.4440 sec
0.1874 0.1734 0.1504 0.1269 0.1164 0.1089 0.1047 0.1022 0.1009 0.0998 0.0998 0.0998 0.1003 0.1008 0.1014 0.1014 

[TRAIN] Epoch[5](980/1500); Loss: 0.124372; Backpropagation: 0.0933 sec; Batch: 0.4692 sec
0.1773 0.1598 0.1327 0.1198 0.1183 0.1186 0.1168 0.1156 0.1157 0.1162 0.1165 0.1166 0.1162 0.1163 0.1165 0.1169 

[TRAIN] Epoch[5](981/1500); Loss: 0.145801; Backpropagation: 0.0934 sec; Batch: 0.4673 sec
0.2398 0.2116 0.1927 0.1608 0.1535 0.1392 0.1321 0.1260 0.1256 0.1217 0.1215 0.1210 0.1216 0.1218 0.1218 0.1222 

[TRAIN] Epoch[5](982/1500); Loss: 0.101938; Backpropagation: 0.0934 sec; Batch: 0.4345 sec
0.2040 0.1743 0.1685 0.1274 0.1142 0.0902 0.0803 0.0758 0.0791 0.0732 0.0726 0.0729 0.0735 0.0744 0.0750 0.0756 

[TRAIN] Epoch[5](983/1500); Loss: 0.136267; Backpropagation: 0.0935 sec; Batch: 0.4309 sec
0.1895 0.1704 0.1532 0.1519 0.1416 0.1328 0.1297 0.1266 0.1259 0.1251 0.1226 0.1224 0.1222 0.1221 0.1221 0.1224 

[TRAIN] Epoch[5](984/1500); Loss: 0.120190; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1428 0.1370 0.1279 0.1302 0.1257 0.1181 0.1174 0.1144 0.1131 0.1119 0.1120 0.1120 0.1130 0.1147 0.1159 0.1169 

[TRAIN] Epoch[5](985/1500); Loss: 0.086451; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.1674 0.1358 0.1258 0.0989 0.0929 0.0801 0.0778 0.0748 0.0712 0.0665 0.0661 0.0664 0.0652 0.0644 0.0647 0.0653 

[TRAIN] Epoch[5](986/1500); Loss: 0.197148; Backpropagation: 0.0933 sec; Batch: 0.4638 sec
0.4727 0.4160 0.3921 0.2855 0.2635 0.1924 0.1518 0.1076 0.1168 0.1127 0.1063 0.1067 0.1060 0.1057 0.1072 0.1113 

[TRAIN] Epoch[5](987/1500); Loss: 0.126921; Backpropagation: 0.0956 sec; Batch: 0.4656 sec
0.1601 0.1434 0.1394 0.1403 0.1360 0.1243 0.1223 0.1204 0.1199 0.1186 0.1190 0.1193 0.1174 0.1167 0.1169 0.1168 

[TRAIN] Epoch[5](988/1500); Loss: 0.113338; Backpropagation: 0.0957 sec; Batch: 0.4663 sec
0.2239 0.1906 0.1727 0.1256 0.1106 0.0973 0.0903 0.0886 0.0869 0.0868 0.0882 0.0894 0.0892 0.0900 0.0912 0.0922 

[TRAIN] Epoch[5](989/1500); Loss: 0.095826; Backpropagation: 0.0942 sec; Batch: 0.4925 sec
0.2135 0.1701 0.1181 0.0946 0.0875 0.0837 0.0817 0.0787 0.0779 0.0771 0.0775 0.0748 0.0748 0.0745 0.0744 0.0743 

[TRAIN] Epoch[5](990/1500); Loss: 0.123660; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.1876 0.1668 0.1525 0.1301 0.1253 0.1200 0.1166 0.1119 0.1102 0.1091 0.1089 0.1081 0.1081 0.1073 0.1079 0.1083 

[TRAIN] Epoch[5](991/1500); Loss: 0.076807; Backpropagation: 0.0938 sec; Batch: 0.4669 sec
0.1459 0.1239 0.1073 0.0819 0.0755 0.0671 0.0662 0.0672 0.0646 0.0597 0.0603 0.0606 0.0610 0.0616 0.0626 0.0635 

[TRAIN] Epoch[5](992/1500); Loss: 0.143291; Backpropagation: 0.0937 sec; Batch: 0.4702 sec
0.1971 0.1781 0.1619 0.1474 0.1439 0.1377 0.1354 0.1324 0.1314 0.1306 0.1306 0.1311 0.1318 0.1332 0.1344 0.1358 

[TRAIN] Epoch[5](993/1500); Loss: 0.127952; Backpropagation: 0.0958 sec; Batch: 0.4735 sec
0.1993 0.1808 0.1605 0.1333 0.1260 0.1195 0.1172 0.1140 0.1132 0.1127 0.1121 0.1118 0.1114 0.1114 0.1117 0.1122 

[TRAIN] Epoch[5](994/1500); Loss: 0.102201; Backpropagation: 0.0957 sec; Batch: 0.5286 sec
0.2072 0.1647 0.1593 0.1023 0.0946 0.0827 0.0850 0.0868 0.0817 0.0805 0.0806 0.0806 0.0809 0.0817 0.0826 0.0840 

[TRAIN] Epoch[5](995/1500); Loss: 0.144139; Backpropagation: 0.0939 sec; Batch: 0.4703 sec
0.1924 0.1834 0.1711 0.1496 0.1450 0.1380 0.1350 0.1345 0.1335 0.1335 0.1340 0.1320 0.1311 0.1309 0.1310 0.1313 

[TRAIN] Epoch[5](996/1500); Loss: 0.176358; Backpropagation: 0.0939 sec; Batch: 0.4672 sec
0.3186 0.2753 0.2625 0.2029 0.1957 0.1621 0.1549 0.1412 0.1383 0.1363 0.1354 0.1377 0.1379 0.1397 0.1409 0.1422 

[TRAIN] Epoch[5](997/1500); Loss: 0.122685; Backpropagation: 0.0939 sec; Batch: 0.4673 sec
0.1893 0.1653 0.1446 0.1223 0.1180 0.1067 0.1062 0.1075 0.1069 0.1084 0.1097 0.1115 0.1131 0.1153 0.1178 0.1203 

[TRAIN] Epoch[5](998/1500); Loss: 0.114987; Backpropagation: 0.0956 sec; Batch: 0.4841 sec
0.1423 0.1356 0.1217 0.1171 0.1114 0.1105 0.1099 0.1100 0.1102 0.1105 0.1105 0.1100 0.1098 0.1099 0.1101 0.1103 

[TRAIN] Epoch[5](999/1500); Loss: 0.159427; Backpropagation: 0.0934 sec; Batch: 0.4321 sec
0.3441 0.2823 0.2796 0.1946 0.1813 0.1469 0.1313 0.1151 0.1108 0.1105 0.1104 0.1096 0.1086 0.1083 0.1084 0.1088 

[TRAIN] Epoch[5](1000/1500); Loss: 0.090902; Backpropagation: 0.0939 sec; Batch: 0.4309 sec
0.1473 0.1199 0.1167 0.0980 0.0923 0.0839 0.0808 0.0799 0.0777 0.0778 0.0784 0.0789 0.0793 0.0803 0.0812 0.0821 

[TRAIN] Epoch[5](1001/1500); Loss: 0.129615; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.3323 0.2714 0.2682 0.1728 0.1580 0.1081 0.0931 0.0747 0.0698 0.0799 0.0744 0.0755 0.0745 0.0740 0.0735 0.0736 

[TRAIN] Epoch[5](1002/1500); Loss: 0.132114; Backpropagation: 0.1002 sec; Batch: 0.4647 sec
0.2842 0.2411 0.2356 0.1606 0.1449 0.1082 0.0976 0.1001 0.0932 0.0946 0.0927 0.0921 0.0923 0.0921 0.0921 0.0924 

[TRAIN] Epoch[5](1003/1500); Loss: 0.099626; Backpropagation: 0.0942 sec; Batch: 0.4366 sec
0.1514 0.1330 0.1234 0.1056 0.1020 0.0947 0.0915 0.0891 0.0882 0.0888 0.0878 0.0876 0.0874 0.0874 0.0878 0.0884 

[TRAIN] Epoch[5](1004/1500); Loss: 0.059977; Backpropagation: 0.0959 sec; Batch: 0.4308 sec
0.0761 0.0707 0.0594 0.0585 0.0577 0.0589 0.0584 0.0580 0.0574 0.0571 0.0569 0.0573 0.0575 0.0580 0.0585 0.0592 

[TRAIN] Epoch[5](1005/1500); Loss: 0.115259; Backpropagation: 0.0941 sec; Batch: 0.4346 sec
0.2109 0.1680 0.1250 0.1056 0.1036 0.1036 0.1021 0.1008 0.1005 0.1010 0.1017 0.1024 0.1029 0.1037 0.1053 0.1070 

[TRAIN] Epoch[5](1006/1500); Loss: 0.043529; Backpropagation: 0.0932 sec; Batch: 0.4344 sec
0.0700 0.0532 0.0426 0.0453 0.0408 0.0405 0.0405 0.0393 0.0388 0.0386 0.0390 0.0398 0.0403 0.0414 0.0426 0.0438 

[TRAIN] Epoch[5](1007/1500); Loss: 0.093241; Backpropagation: 0.0940 sec; Batch: 0.4511 sec
0.1304 0.1248 0.1060 0.0974 0.0889 0.0889 0.0882 0.0870 0.0859 0.0846 0.0846 0.0848 0.0847 0.0849 0.0852 0.0857 

[TRAIN] Epoch[5](1008/1500); Loss: 0.087375; Backpropagation: 0.0942 sec; Batch: 0.4585 sec
0.1531 0.1261 0.1249 0.0925 0.0857 0.0751 0.0745 0.0726 0.0735 0.0732 0.0737 0.0735 0.0739 0.0745 0.0752 0.0761 

[TRAIN] Epoch[5](1009/1500); Loss: 0.096319; Backpropagation: 0.0939 sec; Batch: 0.4707 sec
0.1637 0.1304 0.1014 0.0856 0.0863 0.0862 0.0858 0.0862 0.0862 0.0866 0.0873 0.0882 0.0896 0.0910 0.0925 0.0942 

[TRAIN] Epoch[5](1010/1500); Loss: 0.091610; Backpropagation: 0.0938 sec; Batch: 0.4701 sec
0.1594 0.1257 0.0921 0.0912 0.0863 0.0837 0.0830 0.0826 0.0823 0.0824 0.0822 0.0824 0.0823 0.0830 0.0834 0.0838 

[TRAIN] Epoch[5](1011/1500); Loss: 0.123113; Backpropagation: 0.0938 sec; Batch: 0.4471 sec
0.2751 0.2297 0.2243 0.1431 0.1279 0.0982 0.0976 0.0921 0.0877 0.0859 0.0852 0.0843 0.0844 0.0846 0.0848 0.0850 

[TRAIN] Epoch[5](1012/1500); Loss: 0.109107; Backpropagation: 0.0939 sec; Batch: 0.4725 sec
0.1951 0.1590 0.1420 0.1195 0.1118 0.1029 0.0990 0.0956 0.0943 0.0917 0.0897 0.0887 0.0889 0.0888 0.0891 0.0896 

[TRAIN] Epoch[5](1013/1500); Loss: 0.127728; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.2003 0.1701 0.1521 0.1301 0.1265 0.1223 0.1174 0.1148 0.1132 0.1125 0.1123 0.1128 0.1133 0.1141 0.1152 0.1167 

[TRAIN] Epoch[5](1014/1500); Loss: 0.082395; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.1217 0.1130 0.0937 0.0860 0.0777 0.0763 0.0768 0.0765 0.0751 0.0741 0.0741 0.0743 0.0744 0.0746 0.0749 0.0753 

[TRAIN] Epoch[5](1015/1500); Loss: 0.065349; Backpropagation: 0.0941 sec; Batch: 0.4690 sec
0.1450 0.1129 0.0789 0.0612 0.0582 0.0575 0.0553 0.0544 0.0535 0.0523 0.0520 0.0524 0.0526 0.0529 0.0530 0.0537 

[TRAIN] Epoch[5](1016/1500); Loss: 0.135320; Backpropagation: 0.0939 sec; Batch: 0.4678 sec
0.2120 0.1874 0.1645 0.1385 0.1345 0.1266 0.1242 0.1245 0.1221 0.1200 0.1184 0.1182 0.1183 0.1185 0.1185 0.1189 

[TRAIN] Epoch[5](1017/1500); Loss: 0.270248; Backpropagation: 0.0939 sec; Batch: 0.4649 sec
0.5173 0.4562 0.4496 0.3568 0.3408 0.2827 0.2583 0.2030 0.1942 0.1786 0.1793 0.1810 0.1800 0.1808 0.1820 0.1832 

[TRAIN] Epoch[5](1018/1500); Loss: 0.109958; Backpropagation: 0.0942 sec; Batch: 0.4431 sec
0.1377 0.1336 0.1206 0.1157 0.1100 0.1063 0.1062 0.1072 0.1054 0.1033 0.1029 0.1023 0.1015 0.1019 0.1022 0.1024 

[TRAIN] Epoch[5](1019/1500); Loss: 0.127128; Backpropagation: 0.0940 sec; Batch: 0.4707 sec
0.2474 0.2136 0.1824 0.1453 0.1355 0.1223 0.1140 0.1013 0.0975 0.0972 0.0977 0.0951 0.0954 0.0959 0.0964 0.0970 

[TRAIN] Epoch[5](1020/1500); Loss: 0.090787; Backpropagation: 0.0937 sec; Batch: 0.4581 sec
0.1310 0.1189 0.1034 0.0966 0.0900 0.0858 0.0840 0.0834 0.0829 0.0822 0.0821 0.0819 0.0820 0.0825 0.0828 0.0831 

[TRAIN] Epoch[5](1021/1500); Loss: 0.183333; Backpropagation: 0.0956 sec; Batch: 0.4783 sec
0.2472 0.2315 0.2237 0.2060 0.1984 0.1821 0.1750 0.1669 0.1643 0.1630 0.1621 0.1618 0.1621 0.1628 0.1630 0.1635 

[TRAIN] Epoch[5](1022/1500); Loss: 0.138781; Backpropagation: 0.0939 sec; Batch: 0.4474 sec
0.2986 0.2488 0.2454 0.1672 0.1519 0.1214 0.1083 0.1009 0.0985 0.1003 0.0971 0.0952 0.0957 0.0964 0.0971 0.0975 

[TRAIN] Epoch[5](1023/1500); Loss: 0.120830; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.1532 0.1456 0.1352 0.1358 0.1291 0.1207 0.1175 0.1138 0.1120 0.1105 0.1102 0.1098 0.1097 0.1099 0.1101 0.1102 

[TRAIN] Epoch[5](1024/1500); Loss: 0.133813; Backpropagation: 0.0938 sec; Batch: 0.4659 sec
0.1698 0.1548 0.1513 0.1518 0.1456 0.1337 0.1317 0.1287 0.1271 0.1235 0.1219 0.1208 0.1203 0.1198 0.1200 0.1203 

[TRAIN] Epoch[5](1025/1500); Loss: 0.163250; Backpropagation: 0.0934 sec; Batch: 0.4675 sec
0.2749 0.2429 0.2350 0.1909 0.1817 0.1561 0.1469 0.1404 0.1337 0.1315 0.1322 0.1295 0.1294 0.1290 0.1288 0.1289 

[TRAIN] Epoch[5](1026/1500); Loss: 0.120401; Backpropagation: 0.0934 sec; Batch: 0.4306 sec
0.1624 0.1458 0.1363 0.1205 0.1180 0.1144 0.1130 0.1128 0.1128 0.1124 0.1124 0.1124 0.1126 0.1130 0.1135 0.1141 

[TRAIN] Epoch[5](1027/1500); Loss: 0.114092; Backpropagation: 0.0939 sec; Batch: 0.4668 sec
0.2801 0.2437 0.2396 0.1796 0.1623 0.1148 0.0921 0.0607 0.0569 0.0593 0.0592 0.0556 0.0555 0.0551 0.0552 0.0558 

[TRAIN] Epoch[5](1028/1500); Loss: 0.109321; Backpropagation: 0.0945 sec; Batch: 0.4288 sec
0.1696 0.1504 0.1242 0.1131 0.1069 0.1031 0.1014 0.0985 0.0972 0.0967 0.0967 0.0969 0.0974 0.0980 0.0990 0.1003 

[TRAIN] Epoch[5](1029/1500); Loss: 0.159258; Backpropagation: 0.0939 sec; Batch: 0.4725 sec
0.2859 0.2523 0.2428 0.1920 0.1824 0.1564 0.1443 0.1255 0.1204 0.1265 0.1218 0.1203 0.1199 0.1197 0.1193 0.1188 

[TRAIN] Epoch[5](1030/1500); Loss: 0.086263; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1618 0.1319 0.1239 0.0974 0.0888 0.0805 0.0759 0.0737 0.0725 0.0700 0.0689 0.0664 0.0665 0.0669 0.0673 0.0677 

[TRAIN] Epoch[5](1031/1500); Loss: 0.257360; Backpropagation: 0.0941 sec; Batch: 0.4302 sec
0.4653 0.4109 0.4038 0.3283 0.3153 0.2685 0.2437 0.1967 0.1911 0.1860 0.1869 0.1832 0.1831 0.1844 0.1848 0.1856 

[TRAIN] Epoch[5](1032/1500); Loss: 0.174045; Backpropagation: 0.0939 sec; Batch: 0.4623 sec
0.2775 0.2490 0.2329 0.1887 0.1805 0.1658 0.1572 0.1502 0.1489 0.1481 0.1478 0.1466 0.1468 0.1479 0.1482 0.1487 

[TRAIN] Epoch[5](1033/1500); Loss: 0.122092; Backpropagation: 0.0938 sec; Batch: 0.4657 sec
0.1297 0.1435 0.1188 0.1219 0.1197 0.1203 0.1198 0.1199 0.1200 0.1200 0.1194 0.1193 0.1195 0.1201 0.1205 0.1210 

[TRAIN] Epoch[5](1034/1500); Loss: 0.098861; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1397 0.1214 0.1108 0.1139 0.1090 0.0964 0.0932 0.0896 0.0883 0.0883 0.0883 0.0883 0.0882 0.0884 0.0888 0.0892 

[TRAIN] Epoch[5](1035/1500); Loss: 0.070517; Backpropagation: 0.0934 sec; Batch: 0.4748 sec
0.0998 0.0819 0.0683 0.0786 0.0715 0.0670 0.0640 0.0642 0.0648 0.0650 0.0671 0.0667 0.0666 0.0669 0.0676 0.0682 

[TRAIN] Epoch[5](1036/1500); Loss: 0.170621; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.3377 0.2939 0.2877 0.2158 0.2021 0.1622 0.1440 0.1324 0.1258 0.1267 0.1215 0.1182 0.1163 0.1152 0.1151 0.1154 

[TRAIN] Epoch[5](1037/1500); Loss: 0.177369; Backpropagation: 0.0939 sec; Batch: 0.4660 sec
0.3419 0.3024 0.2965 0.2266 0.2128 0.1733 0.1521 0.1348 0.1285 0.1280 0.1248 0.1239 0.1235 0.1233 0.1229 0.1227 

[TRAIN] Epoch[5](1038/1500); Loss: 0.084933; Backpropagation: 0.0938 sec; Batch: 0.5118 sec
0.1789 0.1499 0.1386 0.0910 0.0829 0.0761 0.0747 0.0669 0.0636 0.0616 0.0615 0.0618 0.0625 0.0626 0.0630 0.0635 

[TRAIN] Epoch[5](1039/1500); Loss: 0.103568; Backpropagation: 0.0940 sec; Batch: 0.4666 sec
0.3231 0.2602 0.2512 0.1338 0.1135 0.0536 0.0486 0.0751 0.0500 0.0488 0.0478 0.0480 0.0487 0.0504 0.0515 0.0527 

[TRAIN] Epoch[5](1040/1500); Loss: 0.197192; Backpropagation: 0.0937 sec; Batch: 0.4693 sec
0.4709 0.4075 0.3955 0.2873 0.2645 0.1841 0.1507 0.1093 0.1122 0.1177 0.1119 0.1082 0.1082 0.1088 0.1087 0.1095 

[TRAIN] Epoch[5](1041/1500); Loss: 0.076157; Backpropagation: 0.0938 sec; Batch: 0.4675 sec
0.1201 0.1016 0.0916 0.0839 0.0809 0.0718 0.0693 0.0670 0.0662 0.0661 0.0660 0.0663 0.0665 0.0669 0.0670 0.0673 

[TRAIN] Epoch[5](1042/1500); Loss: 0.088520; Backpropagation: 0.0939 sec; Batch: 0.4675 sec
0.1893 0.1582 0.1481 0.1085 0.1003 0.0765 0.0715 0.0676 0.0680 0.0623 0.0623 0.0615 0.0608 0.0604 0.0605 0.0606 

[TRAIN] Epoch[5](1043/1500); Loss: 0.136050; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.2603 0.2304 0.2078 0.1556 0.1454 0.1221 0.1114 0.1080 0.1034 0.1060 0.1050 0.1041 0.1040 0.1043 0.1044 0.1045 

[TRAIN] Epoch[5](1044/1500); Loss: 0.145346; Backpropagation: 0.0932 sec; Batch: 0.4690 sec
0.2346 0.2119 0.2054 0.1653 0.1555 0.1404 0.1373 0.1307 0.1237 0.1198 0.1183 0.1180 0.1174 0.1155 0.1157 0.1160 

[TRAIN] Epoch[5](1045/1500); Loss: 0.131415; Backpropagation: 0.0939 sec; Batch: 0.4766 sec
0.2195 0.1877 0.1653 0.1434 0.1350 0.1229 0.1197 0.1193 0.1164 0.1130 0.1119 0.1110 0.1105 0.1098 0.1090 0.1081 

[TRAIN] Epoch[5](1046/1500); Loss: 0.081592; Backpropagation: 0.0938 sec; Batch: 0.4662 sec
0.1773 0.1534 0.1160 0.0827 0.0713 0.0647 0.0652 0.0637 0.0633 0.0625 0.0626 0.0631 0.0637 0.0646 0.0653 0.0660 

[TRAIN] Epoch[5](1047/1500); Loss: 0.128890; Backpropagation: 0.0933 sec; Batch: 0.4663 sec
0.2034 0.1818 0.1574 0.1336 0.1267 0.1172 0.1171 0.1159 0.1146 0.1142 0.1134 0.1130 0.1132 0.1136 0.1134 0.1138 

[TRAIN] Epoch[5](1048/1500); Loss: 0.127351; Backpropagation: 0.0939 sec; Batch: 0.4679 sec
0.1877 0.1784 0.1635 0.1389 0.1312 0.1215 0.1208 0.1156 0.1129 0.1094 0.1091 0.1096 0.1091 0.1095 0.1102 0.1102 

[TRAIN] Epoch[5](1049/1500); Loss: 0.135786; Backpropagation: 0.0939 sec; Batch: 0.4709 sec
0.2246 0.1899 0.1867 0.1425 0.1363 0.1272 0.1249 0.1206 0.1189 0.1154 0.1143 0.1134 0.1137 0.1144 0.1149 0.1151 

[TRAIN] Epoch[5](1050/1500); Loss: 0.153713; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.1868 0.1753 0.1634 0.1571 0.1539 0.1497 0.1493 0.1488 0.1479 0.1469 0.1464 0.1466 0.1467 0.1467 0.1468 0.1471 

[TRAIN] Epoch[5](1051/1500); Loss: 0.154217; Backpropagation: 0.0941 sec; Batch: 0.4712 sec
0.2553 0.2265 0.2057 0.1707 0.1649 0.1506 0.1442 0.1340 0.1314 0.1281 0.1260 0.1260 0.1261 0.1259 0.1261 0.1260 

[TRAIN] Epoch[5](1052/1500); Loss: 0.155921; Backpropagation: 0.0938 sec; Batch: 0.4706 sec
0.2056 0.1962 0.1842 0.1689 0.1625 0.1549 0.1501 0.1442 0.1416 0.1402 0.1411 0.1415 0.1417 0.1407 0.1405 0.1408 

[TRAIN] Epoch[5](1053/1500); Loss: 0.110981; Backpropagation: 0.0939 sec; Batch: 0.4707 sec
0.1754 0.1526 0.1359 0.1094 0.1073 0.1057 0.1022 0.1018 0.1000 0.0987 0.0978 0.0972 0.0972 0.0978 0.0982 0.0985 

[TRAIN] Epoch[5](1054/1500); Loss: 0.118571; Backpropagation: 0.0936 sec; Batch: 0.4662 sec
0.2102 0.1793 0.1467 0.1177 0.1134 0.1088 0.1059 0.1051 0.1024 0.1015 0.1004 0.1005 0.1009 0.1012 0.1016 0.1016 

[TRAIN] Epoch[5](1055/1500); Loss: 0.079942; Backpropagation: 0.0934 sec; Batch: 0.4668 sec
0.1218 0.1206 0.0914 0.0839 0.0743 0.0764 0.0734 0.0700 0.0685 0.0689 0.0691 0.0698 0.0708 0.0720 0.0732 0.0749 

[TRAIN] Epoch[5](1056/1500); Loss: 0.132462; Backpropagation: 0.0932 sec; Batch: 0.4665 sec
0.2159 0.1780 0.1732 0.1488 0.1427 0.1248 0.1210 0.1154 0.1133 0.1130 0.1118 0.1116 0.1119 0.1122 0.1126 0.1130 

[TRAIN] Epoch[5](1057/1500); Loss: 0.122264; Backpropagation: 0.0939 sec; Batch: 0.4684 sec
0.2690 0.2202 0.2054 0.1311 0.1186 0.1006 0.0985 0.0961 0.0943 0.0923 0.0895 0.0887 0.0879 0.0876 0.0882 0.0884 

[TRAIN] Epoch[5](1058/1500); Loss: 0.104691; Backpropagation: 0.0940 sec; Batch: 0.4510 sec
0.1998 0.1666 0.1273 0.1030 0.0970 0.0955 0.0928 0.0913 0.0905 0.0887 0.0879 0.0871 0.0868 0.0869 0.0869 0.0869 

[TRAIN] Epoch[5](1059/1500); Loss: 0.147628; Backpropagation: 0.0939 sec; Batch: 0.4661 sec
0.2574 0.2251 0.2202 0.1794 0.1677 0.1368 0.1288 0.1223 0.1193 0.1179 0.1165 0.1153 0.1140 0.1137 0.1138 0.1139 

[TRAIN] Epoch[5](1060/1500); Loss: 0.083174; Backpropagation: 0.0939 sec; Batch: 0.4978 sec
0.1222 0.1007 0.0881 0.0893 0.0835 0.0783 0.0767 0.0759 0.0757 0.0760 0.0764 0.0769 0.0771 0.0773 0.0778 0.0789 

[TRAIN] Epoch[5](1061/1500); Loss: 0.119516; Backpropagation: 0.0946 sec; Batch: 0.4440 sec
0.1788 0.1649 0.1395 0.1268 0.1179 0.1134 0.1105 0.1082 0.1076 0.1060 0.1055 0.1053 0.1057 0.1064 0.1072 0.1085 

[TRAIN] Epoch[5](1062/1500); Loss: 0.069620; Backpropagation: 0.0933 sec; Batch: 0.5508 sec
0.1180 0.1036 0.0864 0.0718 0.0664 0.0627 0.0606 0.0603 0.0601 0.0594 0.0593 0.0596 0.0602 0.0610 0.0617 0.0626 

[TRAIN] Epoch[5](1063/1500); Loss: 0.126281; Backpropagation: 0.0933 sec; Batch: 0.4699 sec
0.1589 0.1514 0.1442 0.1329 0.1269 0.1214 0.1201 0.1216 0.1196 0.1181 0.1178 0.1176 0.1175 0.1173 0.1174 0.1177 

[TRAIN] Epoch[5](1064/1500); Loss: 0.154420; Backpropagation: 0.0937 sec; Batch: 0.4672 sec
0.2958 0.2559 0.2491 0.1824 0.1698 0.1454 0.1359 0.1241 0.1164 0.1161 0.1129 0.1132 0.1131 0.1131 0.1135 0.1138 

[TRAIN] Epoch[5](1065/1500); Loss: 0.194812; Backpropagation: 0.0944 sec; Batch: 0.4567 sec
0.3550 0.3209 0.3003 0.2337 0.2216 0.1886 0.1758 0.1599 0.1566 0.1483 0.1443 0.1428 0.1421 0.1428 0.1421 0.1422 

[TRAIN] Epoch[5](1066/1500); Loss: 0.123086; Backpropagation: 0.0982 sec; Batch: 0.4701 sec
0.2792 0.2341 0.2029 0.1424 0.1130 0.1050 0.0984 0.0935 0.0914 0.0892 0.0877 0.0871 0.0868 0.0867 0.0860 0.0862 

[TRAIN] Epoch[5](1067/1500); Loss: 0.145408; Backpropagation: 0.0958 sec; Batch: 0.4679 sec
0.1810 0.1698 0.1630 0.1526 0.1471 0.1427 0.1397 0.1385 0.1365 0.1365 0.1361 0.1362 0.1363 0.1365 0.1366 0.1373 

[TRAIN] Epoch[5](1068/1500); Loss: 0.106065; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1688 0.1573 0.1340 0.1190 0.1054 0.0963 0.0934 0.0917 0.0915 0.0911 0.0911 0.0912 0.0912 0.0913 0.0916 0.0920 

[TRAIN] Epoch[5](1069/1500); Loss: 0.153793; Backpropagation: 0.0938 sec; Batch: 0.4742 sec
0.2914 0.2577 0.2479 0.2024 0.1930 0.1615 0.1454 0.1219 0.1134 0.1047 0.1080 0.1027 0.1024 0.1025 0.1028 0.1031 

[TRAIN] Epoch[5](1070/1500); Loss: 0.089153; Backpropagation: 0.0937 sec; Batch: 0.4666 sec
0.1863 0.1561 0.1484 0.1051 0.0947 0.0727 0.0687 0.0709 0.0679 0.0646 0.0640 0.0641 0.0648 0.0657 0.0667 0.0657 

[TRAIN] Epoch[5](1071/1500); Loss: 0.123664; Backpropagation: 0.0943 sec; Batch: 0.4291 sec
0.1440 0.1526 0.1308 0.1307 0.1216 0.1197 0.1182 0.1177 0.1174 0.1172 0.1176 0.1179 0.1180 0.1182 0.1185 0.1187 

[TRAIN] Epoch[5](1072/1500); Loss: 0.078134; Backpropagation: 0.0932 sec; Batch: 0.4680 sec
0.1216 0.0993 0.0918 0.0914 0.0876 0.0756 0.0723 0.0706 0.0693 0.0686 0.0682 0.0681 0.0678 0.0666 0.0657 0.0657 

[TRAIN] Epoch[5](1073/1500); Loss: 0.081053; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.1367 0.1125 0.0935 0.0824 0.0822 0.0752 0.0748 0.0731 0.0720 0.0711 0.0705 0.0703 0.0706 0.0705 0.0706 0.0709 

[TRAIN] Epoch[5](1074/1500); Loss: 0.059118; Backpropagation: 0.0938 sec; Batch: 0.4659 sec
0.1307 0.0889 0.0842 0.0606 0.0630 0.0497 0.0498 0.0459 0.0453 0.0454 0.0464 0.0463 0.0465 0.0470 0.0479 0.0482 

[TRAIN] Epoch[5](1075/1500); Loss: 0.118099; Backpropagation: 0.0934 sec; Batch: 0.4668 sec
0.1653 0.1480 0.1324 0.1248 0.1194 0.1140 0.1114 0.1099 0.1088 0.1083 0.1084 0.1084 0.1080 0.1076 0.1075 0.1076 

[TRAIN] Epoch[5](1076/1500); Loss: 0.126502; Backpropagation: 0.0933 sec; Batch: 0.4619 sec
0.2161 0.1802 0.1593 0.1287 0.1232 0.1114 0.1080 0.1118 0.1104 0.1109 0.1106 0.1104 0.1103 0.1104 0.1110 0.1115 

[TRAIN] Epoch[5](1077/1500); Loss: 0.097472; Backpropagation: 0.0939 sec; Batch: 0.4510 sec
0.1786 0.1489 0.1217 0.0966 0.0891 0.0877 0.0861 0.0845 0.0840 0.0836 0.0834 0.0832 0.0829 0.0829 0.0832 0.0830 

[TRAIN] Epoch[5](1078/1500); Loss: 0.120034; Backpropagation: 0.0939 sec; Batch: 0.5157 sec
0.1895 0.1637 0.1492 0.1233 0.1125 0.1139 0.1049 0.1062 0.1060 0.1067 0.1067 0.1076 0.1077 0.1075 0.1080 0.1073 

[TRAIN] Epoch[5](1079/1500); Loss: 0.081982; Backpropagation: 0.0939 sec; Batch: 0.4664 sec
0.1671 0.1354 0.1146 0.0852 0.0792 0.0713 0.0690 0.0673 0.0645 0.0643 0.0644 0.0649 0.0655 0.0661 0.0663 0.0667 

[TRAIN] Epoch[5](1080/1500); Loss: 0.124694; Backpropagation: 0.0938 sec; Batch: 0.4706 sec
0.2061 0.1790 0.1680 0.1351 0.1294 0.1162 0.1154 0.1090 0.1066 0.1041 0.1036 0.1040 0.1040 0.1044 0.1049 0.1052 

[TRAIN] Epoch[5](1081/1500); Loss: 0.096774; Backpropagation: 0.0940 sec; Batch: 0.4688 sec
0.2512 0.1881 0.1223 0.0675 0.0718 0.0859 0.0804 0.0771 0.0763 0.0750 0.0743 0.0743 0.0751 0.0756 0.0763 0.0772 

[TRAIN] Epoch[5](1082/1500); Loss: 0.140481; Backpropagation: 0.0939 sec; Batch: 0.4659 sec
0.2920 0.2469 0.2330 0.1517 0.1419 0.1159 0.1104 0.1182 0.1078 0.1042 0.1040 0.1038 0.1041 0.1044 0.1044 0.1050 

[TRAIN] Epoch[5](1083/1500); Loss: 0.130823; Backpropagation: 0.0938 sec; Batch: 0.4620 sec
0.2108 0.1878 0.1598 0.1360 0.1246 0.1189 0.1165 0.1149 0.1152 0.1157 0.1156 0.1155 0.1154 0.1154 0.1154 0.1155 

[TRAIN] Epoch[5](1084/1500); Loss: 0.154659; Backpropagation: 0.0944 sec; Batch: 0.4909 sec
0.2348 0.2057 0.1916 0.1667 0.1617 0.1518 0.1488 0.1435 0.1408 0.1379 0.1358 0.1340 0.1325 0.1312 0.1293 0.1284 

[TRAIN] Epoch[5](1085/1500); Loss: 0.198272; Backpropagation: 0.0995 sec; Batch: 0.4797 sec
0.4915 0.4261 0.4053 0.2819 0.2580 0.1752 0.1404 0.1128 0.1103 0.1154 0.1098 0.1101 0.1098 0.1086 0.1085 0.1087 

[TRAIN] Epoch[5](1086/1500); Loss: 0.082944; Backpropagation: 0.0982 sec; Batch: 0.5527 sec
0.2268 0.1802 0.1680 0.0828 0.0710 0.0599 0.0604 0.0601 0.0544 0.0534 0.0524 0.0514 0.0512 0.0512 0.0518 0.0521 

[TRAIN] Epoch[5](1087/1500); Loss: 0.111665; Backpropagation: 0.0992 sec; Batch: 0.4736 sec
0.1520 0.1449 0.1191 0.1117 0.1057 0.1038 0.1035 0.1037 0.1039 0.1041 0.1047 0.1048 0.1051 0.1057 0.1065 0.1076 

[TRAIN] Epoch[5](1088/1500); Loss: 0.091925; Backpropagation: 0.0989 sec; Batch: 0.4859 sec
0.1415 0.1201 0.1052 0.0940 0.0931 0.0855 0.0842 0.0844 0.0837 0.0838 0.0834 0.0825 0.0823 0.0821 0.0823 0.0827 

[TRAIN] Epoch[5](1089/1500); Loss: 0.077238; Backpropagation: 0.0990 sec; Batch: 0.4957 sec
0.1369 0.1166 0.0968 0.0769 0.0733 0.0750 0.0678 0.0646 0.0645 0.0643 0.0646 0.0653 0.0656 0.0667 0.0677 0.0691 

[TRAIN] Epoch[5](1090/1500); Loss: 0.138969; Backpropagation: 0.0988 sec; Batch: 0.4726 sec
0.2656 0.2338 0.2163 0.1646 0.1484 0.1234 0.1138 0.1085 0.1047 0.1066 0.1057 0.1056 0.1060 0.1063 0.1068 0.1075 

[TRAIN] Epoch[5](1091/1500); Loss: 0.106894; Backpropagation: 0.0993 sec; Batch: 0.4713 sec
0.2550 0.2160 0.1747 0.1201 0.0906 0.0890 0.0825 0.0787 0.0779 0.0763 0.0752 0.0749 0.0748 0.0749 0.0748 0.0748 

[TRAIN] Epoch[5](1092/1500); Loss: 0.070928; Backpropagation: 0.0990 sec; Batch: 0.4983 sec
0.1560 0.1236 0.0938 0.0637 0.0608 0.0595 0.0575 0.0562 0.0565 0.0571 0.0575 0.0579 0.0579 0.0582 0.0590 0.0597 

[TRAIN] Epoch[5](1093/1500); Loss: 0.130047; Backpropagation: 0.0990 sec; Batch: 0.4752 sec
0.2128 0.1812 0.1728 0.1340 0.1306 0.1219 0.1211 0.1201 0.1177 0.1101 0.1093 0.1101 0.1091 0.1090 0.1098 0.1114 

[TRAIN] Epoch[5](1094/1500); Loss: 0.089474; Backpropagation: 0.0991 sec; Batch: 0.4712 sec
0.1610 0.1372 0.1320 0.1006 0.0971 0.0833 0.0776 0.0764 0.0730 0.0706 0.0701 0.0701 0.0699 0.0703 0.0708 0.0716 

[TRAIN] Epoch[5](1095/1500); Loss: 0.142657; Backpropagation: 0.0990 sec; Batch: 0.4821 sec
0.2676 0.2333 0.2176 0.1782 0.1681 0.1387 0.1250 0.1065 0.1049 0.1104 0.1075 0.1052 0.1051 0.1048 0.1047 0.1049 

[TRAIN] Epoch[5](1096/1500); Loss: 0.080738; Backpropagation: 0.0989 sec; Batch: 0.4703 sec
0.1557 0.1214 0.1073 0.0786 0.0805 0.0794 0.0737 0.0706 0.0687 0.0664 0.0651 0.0646 0.0647 0.0647 0.0648 0.0654 

[TRAIN] Epoch[5](1097/1500); Loss: 0.110311; Backpropagation: 0.0991 sec; Batch: 0.4920 sec
0.1474 0.1408 0.1254 0.1159 0.1119 0.1081 0.1072 0.1051 0.1030 0.1011 0.1006 0.1002 0.0998 0.0993 0.0995 0.0997 

[TRAIN] Epoch[5](1098/1500); Loss: 0.096667; Backpropagation: 0.0989 sec; Batch: 0.4736 sec
0.1864 0.1476 0.1233 0.0962 0.0883 0.0868 0.0839 0.0826 0.0814 0.0805 0.0808 0.0816 0.0818 0.0819 0.0818 0.0818 

[TRAIN] Epoch[5](1099/1500); Loss: 0.143086; Backpropagation: 0.0990 sec; Batch: 0.4743 sec
0.2133 0.1919 0.1809 0.1594 0.1548 0.1470 0.1405 0.1338 0.1299 0.1231 0.1215 0.1197 0.1189 0.1183 0.1183 0.1182 

[TRAIN] Epoch[5](1100/1500); Loss: 0.085645; Backpropagation: 0.0991 sec; Batch: 0.4720 sec
0.2934 0.2100 0.1214 0.0489 0.0487 0.0552 0.0630 0.0654 0.0604 0.0597 0.0586 0.0571 0.0565 0.0567 0.0573 0.0580 

[TRAIN] Epoch[5](1101/1500); Loss: 0.115450; Backpropagation: 0.0982 sec; Batch: 0.4702 sec
0.1790 0.1510 0.1407 0.1213 0.1186 0.1109 0.1067 0.1044 0.1032 0.1013 0.1012 0.1020 0.1016 0.1015 0.1017 0.1021 

[TRAIN] Epoch[5](1102/1500); Loss: 0.110271; Backpropagation: 0.0989 sec; Batch: 0.4786 sec
0.2763 0.2188 0.1476 0.0759 0.0782 0.0962 0.0940 0.0913 0.0899 0.0880 0.0866 0.0854 0.0845 0.0839 0.0836 0.0841 

[TRAIN] Epoch[5](1103/1500); Loss: 0.078148; Backpropagation: 0.0989 sec; Batch: 0.4713 sec
0.1136 0.0972 0.0803 0.0870 0.0790 0.0748 0.0729 0.0730 0.0724 0.0719 0.0716 0.0717 0.0715 0.0713 0.0712 0.0710 

[TRAIN] Epoch[5](1104/1500); Loss: 0.190209; Backpropagation: 0.1072 sec; Batch: 0.4836 sec
0.2984 0.2780 0.2587 0.2120 0.2002 0.1805 0.1737 0.1682 0.1659 0.1608 0.1597 0.1581 0.1578 0.1575 0.1570 0.1568 

[TRAIN] Epoch[5](1105/1500); Loss: 0.066258; Backpropagation: 0.1081 sec; Batch: 0.5000 sec
0.1950 0.1515 0.1448 0.0839 0.0755 0.0520 0.0447 0.0387 0.0366 0.0344 0.0327 0.0327 0.0329 0.0343 0.0349 0.0355 

[TRAIN] Epoch[5](1106/1500); Loss: 0.125585; Backpropagation: 0.0989 sec; Batch: 0.4719 sec
0.1902 0.1779 0.1564 0.1331 0.1212 0.1171 0.1143 0.1127 0.1118 0.1108 0.1106 0.1106 0.1104 0.1105 0.1107 0.1111 

[TRAIN] Epoch[5](1107/1500); Loss: 0.094025; Backpropagation: 0.0983 sec; Batch: 0.4704 sec
0.1798 0.1565 0.1389 0.1091 0.1015 0.0864 0.0812 0.0745 0.0727 0.0730 0.0722 0.0712 0.0711 0.0714 0.0720 0.0730 

[TRAIN] Epoch[5](1108/1500); Loss: 0.061600; Backpropagation: 0.0989 sec; Batch: 0.4672 sec
0.1415 0.1004 0.0701 0.0577 0.0545 0.0527 0.0522 0.0514 0.0505 0.0499 0.0502 0.0505 0.0505 0.0507 0.0512 0.0516 

[TRAIN] Epoch[5](1109/1500); Loss: 0.122777; Backpropagation: 0.0992 sec; Batch: 0.4713 sec
0.2556 0.2104 0.1883 0.1335 0.1214 0.1043 0.1005 0.0972 0.0942 0.0934 0.0936 0.0941 0.0939 0.0944 0.0946 0.0951 

[TRAIN] Epoch[5](1110/1500); Loss: 0.101692; Backpropagation: 0.0991 sec; Batch: 0.5158 sec
0.1970 0.1754 0.1318 0.1047 0.0901 0.0854 0.0851 0.0844 0.0839 0.0839 0.0837 0.0836 0.0839 0.0841 0.0848 0.0851 

[TRAIN] Epoch[5](1111/1500); Loss: 0.123482; Backpropagation: 0.0991 sec; Batch: 0.4941 sec
0.2119 0.1770 0.1616 0.1234 0.1194 0.1090 0.1064 0.1067 0.1054 0.1068 0.1064 0.1067 0.1073 0.1082 0.1091 0.1103 

[TRAIN] Epoch[5](1112/1500); Loss: 0.074642; Backpropagation: 0.0982 sec; Batch: 0.4689 sec
0.2299 0.1615 0.0961 0.0549 0.0490 0.0640 0.0586 0.0554 0.0547 0.0533 0.0524 0.0521 0.0521 0.0530 0.0534 0.0540 

[TRAIN] Epoch[5](1113/1500); Loss: 0.106253; Backpropagation: 0.1004 sec; Batch: 0.4454 sec
0.1699 0.1421 0.1326 0.1139 0.1115 0.1027 0.0982 0.0934 0.0924 0.0913 0.0913 0.0916 0.0917 0.0919 0.0925 0.0930 

[TRAIN] Epoch[5](1114/1500); Loss: 0.087220; Backpropagation: 0.0989 sec; Batch: 0.4853 sec
0.1629 0.1274 0.1137 0.0958 0.0889 0.0828 0.0789 0.0752 0.0738 0.0722 0.0713 0.0708 0.0705 0.0703 0.0705 0.0707 

[TRAIN] Epoch[5](1115/1500); Loss: 0.088088; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.2666 0.2190 0.1523 0.0869 0.0602 0.0615 0.0583 0.0574 0.0569 0.0560 0.0551 0.0552 0.0555 0.0559 0.0561 0.0565 

[TRAIN] Epoch[5](1116/1500); Loss: 0.112559; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.2242 0.1939 0.1774 0.1295 0.1225 0.1006 0.0999 0.0978 0.0974 0.0837 0.0812 0.0798 0.0783 0.0781 0.0781 0.0785 

[TRAIN] Epoch[5](1117/1500); Loss: 0.113073; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.2381 0.2106 0.1603 0.1186 0.0971 0.0910 0.0907 0.0901 0.0893 0.0890 0.0887 0.0887 0.0886 0.0891 0.0894 0.0899 

[TRAIN] Epoch[5](1118/1500); Loss: 0.080894; Backpropagation: 0.0996 sec; Batch: 0.4345 sec
0.1138 0.0979 0.0856 0.0846 0.0804 0.0769 0.0758 0.0755 0.0753 0.0749 0.0748 0.0751 0.0755 0.0757 0.0761 0.0766 

[TRAIN] Epoch[5](1119/1500); Loss: 0.086963; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.1653 0.1374 0.1128 0.0861 0.0842 0.0814 0.0781 0.0748 0.0738 0.0721 0.0713 0.0706 0.0706 0.0708 0.0709 0.0712 

[TRAIN] Epoch[5](1120/1500); Loss: 0.114177; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1900 0.1608 0.1531 0.1162 0.1100 0.1018 0.1017 0.1025 0.0998 0.0982 0.0981 0.0983 0.0985 0.0989 0.0993 0.0998 

[TRAIN] Epoch[5](1121/1500); Loss: 0.066804; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.1007 0.0878 0.0715 0.0692 0.0651 0.0631 0.0609 0.0602 0.0602 0.0598 0.0602 0.0602 0.0609 0.0617 0.0629 0.0646 

[TRAIN] Epoch[5](1122/1500); Loss: 0.078509; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.1228 0.1103 0.0921 0.0828 0.0811 0.0761 0.0720 0.0706 0.0690 0.0681 0.0675 0.0674 0.0678 0.0684 0.0693 0.0708 

[TRAIN] Epoch[5](1123/1500); Loss: 0.106891; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.2315 0.2003 0.1948 0.1463 0.1345 0.1056 0.0898 0.0705 0.0687 0.0695 0.0667 0.0665 0.0661 0.0663 0.0665 0.0666 

[TRAIN] Epoch[5](1124/1500); Loss: 0.144670; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.2086 0.1859 0.1699 0.1566 0.1518 0.1437 0.1401 0.1360 0.1335 0.1313 0.1292 0.1280 0.1268 0.1256 0.1243 0.1232 

[TRAIN] Epoch[5](1125/1500); Loss: 0.133129; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.2707 0.2425 0.2156 0.1575 0.1462 0.1203 0.1072 0.1026 0.0987 0.0979 0.0961 0.0956 0.0957 0.0951 0.0944 0.0940 

[TRAIN] Epoch[5](1126/1500); Loss: 0.086233; Backpropagation: 0.0985 sec; Batch: 0.4321 sec
0.1324 0.1164 0.1003 0.0836 0.0839 0.0802 0.0790 0.0777 0.0772 0.0772 0.0775 0.0781 0.0783 0.0787 0.0794 0.0800 

[TRAIN] Epoch[5](1127/1500); Loss: 0.129004; Backpropagation: 0.1084 sec; Batch: 0.4439 sec
0.3260 0.2620 0.2525 0.1557 0.1392 0.1015 0.0913 0.0890 0.0823 0.0816 0.0805 0.0803 0.0805 0.0807 0.0804 0.0808 

[TRAIN] Epoch[5](1128/1500); Loss: 0.165641; Backpropagation: 0.1081 sec; Batch: 0.4429 sec
0.2498 0.2336 0.2201 0.1946 0.1877 0.1723 0.1645 0.1530 0.1466 0.1371 0.1343 0.1333 0.1314 0.1308 0.1307 0.1304 

[TRAIN] Epoch[5](1129/1500); Loss: 0.115195; Backpropagation: 0.0988 sec; Batch: 0.4333 sec
0.2358 0.1980 0.1704 0.1386 0.1287 0.1082 0.0980 0.0853 0.0841 0.0877 0.0855 0.0841 0.0842 0.0844 0.0847 0.0852 

[TRAIN] Epoch[5](1130/1500); Loss: 0.060719; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1703 0.1198 0.1138 0.0513 0.0517 0.0478 0.0466 0.0425 0.0409 0.0405 0.0400 0.0399 0.0408 0.0415 0.0416 0.0423 

[TRAIN] Epoch[5](1131/1500); Loss: 0.094432; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.1574 0.1365 0.1180 0.1013 0.0924 0.0843 0.0824 0.0822 0.0815 0.0813 0.0823 0.0822 0.0821 0.0820 0.0822 0.0828 

[TRAIN] Epoch[5](1132/1500); Loss: 0.086896; Backpropagation: 0.0982 sec; Batch: 0.4330 sec
0.1674 0.1317 0.1247 0.1019 0.0947 0.0696 0.0657 0.0749 0.0694 0.0672 0.0683 0.0689 0.0696 0.0710 0.0721 0.0734 

[TRAIN] Epoch[5](1133/1500); Loss: 0.101517; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1476 0.1355 0.1228 0.1014 0.0966 0.0953 0.0925 0.0918 0.0917 0.0919 0.0922 0.0922 0.0925 0.0929 0.0935 0.0940 

[TRAIN] Epoch[5](1134/1500); Loss: 0.115794; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1469 0.1394 0.1231 0.1228 0.1168 0.1125 0.1112 0.1103 0.1095 0.1090 0.1084 0.1084 0.1087 0.1087 0.1085 0.1086 

[TRAIN] Epoch[5](1135/1500); Loss: 0.142225; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.2265 0.2050 0.1939 0.1612 0.1545 0.1409 0.1329 0.1217 0.1180 0.1172 0.1159 0.1176 0.1174 0.1179 0.1176 0.1173 

[TRAIN] Epoch[5](1136/1500); Loss: 0.068392; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.1356 0.1027 0.0710 0.0732 0.0662 0.0620 0.0604 0.0583 0.0569 0.0579 0.0583 0.0582 0.0580 0.0581 0.0584 0.0592 

[TRAIN] Epoch[5](1137/1500); Loss: 0.062315; Backpropagation: 0.0989 sec; Batch: 0.4338 sec
0.1330 0.0900 0.0844 0.0516 0.0540 0.0592 0.0524 0.0517 0.0510 0.0504 0.0507 0.0517 0.0526 0.0542 0.0545 0.0557 

[TRAIN] Epoch[5](1138/1500); Loss: 0.144345; Backpropagation: 0.0989 sec; Batch: 0.4343 sec
0.2215 0.2050 0.1938 0.1618 0.1530 0.1411 0.1344 0.1247 0.1213 0.1211 0.1205 0.1230 0.1218 0.1221 0.1222 0.1222 

[TRAIN] Epoch[5](1139/1500); Loss: 0.061602; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1253 0.0884 0.0823 0.0552 0.0563 0.0577 0.0531 0.0516 0.0504 0.0505 0.0511 0.0519 0.0523 0.0524 0.0531 0.0538 

[TRAIN] Epoch[5](1140/1500); Loss: 0.098390; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.1793 0.1456 0.1159 0.1022 0.0979 0.0939 0.0910 0.0870 0.0859 0.0855 0.0830 0.0816 0.0815 0.0813 0.0812 0.0814 

[TRAIN] Epoch[5](1141/1500); Loss: 0.086339; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1493 0.1229 0.0933 0.0887 0.0829 0.0801 0.0786 0.0775 0.0769 0.0758 0.0757 0.0754 0.0759 0.0759 0.0760 0.0763 

[TRAIN] Epoch[5](1142/1500); Loss: 0.109078; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.2329 0.2023 0.1854 0.1328 0.1237 0.0950 0.0903 0.0876 0.0828 0.0757 0.0732 0.0718 0.0718 0.0722 0.0732 0.0745 

[TRAIN] Epoch[5](1143/1500); Loss: 0.152359; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2527 0.2306 0.1985 0.1686 0.1625 0.1521 0.1441 0.1338 0.1297 0.1248 0.1238 0.1238 0.1233 0.1231 0.1232 0.1231 

[TRAIN] Epoch[5](1144/1500); Loss: 0.098822; Backpropagation: 0.1011 sec; Batch: 0.4366 sec
0.1581 0.1374 0.1226 0.1070 0.0990 0.0910 0.0885 0.0864 0.0859 0.0857 0.0860 0.0861 0.0862 0.0865 0.0870 0.0878 

[TRAIN] Epoch[5](1145/1500); Loss: 0.091764; Backpropagation: 0.1025 sec; Batch: 0.4450 sec
0.2906 0.2306 0.2200 0.1202 0.1034 0.0503 0.0471 0.0655 0.0451 0.0468 0.0435 0.0419 0.0408 0.0403 0.0402 0.0420 

[TRAIN] Epoch[5](1146/1500); Loss: 0.090513; Backpropagation: 0.0992 sec; Batch: 0.4346 sec
0.1433 0.1228 0.1072 0.0969 0.0901 0.0844 0.0816 0.0811 0.0808 0.0804 0.0803 0.0804 0.0795 0.0797 0.0797 0.0799 

[TRAIN] Epoch[5](1147/1500); Loss: 0.061572; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1413 0.1015 0.0694 0.0578 0.0551 0.0541 0.0511 0.0506 0.0503 0.0499 0.0500 0.0501 0.0501 0.0505 0.0512 0.0520 

[TRAIN] Epoch[5](1148/1500); Loss: 0.089237; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1515 0.1235 0.1175 0.0964 0.0918 0.0841 0.0832 0.0770 0.0771 0.0753 0.0753 0.0750 0.0752 0.0752 0.0748 0.0746 

[TRAIN] Epoch[5](1149/1500); Loss: 0.084842; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1681 0.1322 0.1064 0.0853 0.0782 0.0767 0.0735 0.0731 0.0718 0.0715 0.0712 0.0705 0.0698 0.0694 0.0697 0.0701 

[TRAIN] Epoch[5](1150/1500); Loss: 0.062713; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.1454 0.1102 0.0778 0.0771 0.0706 0.0545 0.0521 0.0496 0.0474 0.0457 0.0451 0.0447 0.0443 0.0451 0.0461 0.0477 

[TRAIN] Epoch[5](1151/1500); Loss: 0.182396; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.2780 0.2404 0.2310 0.2027 0.1947 0.1739 0.1645 0.1629 0.1605 0.1604 0.1589 0.1583 0.1577 0.1576 0.1586 0.1583 

[TRAIN] Epoch[5](1152/1500); Loss: 0.087926; Backpropagation: 0.0990 sec; Batch: 0.4345 sec
0.2081 0.1623 0.1513 0.0933 0.0840 0.0712 0.0696 0.0658 0.0627 0.0629 0.0621 0.0617 0.0638 0.0630 0.0625 0.0624 

[TRAIN] Epoch[5](1153/1500); Loss: 0.133413; Backpropagation: 0.0984 sec; Batch: 0.4338 sec
0.2291 0.1996 0.1810 0.1265 0.1202 0.1294 0.1196 0.1179 0.1147 0.1140 0.1140 0.1137 0.1134 0.1136 0.1139 0.1139 

[TRAIN] Epoch[5](1154/1500); Loss: 0.140787; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.2346 0.2127 0.1989 0.1581 0.1490 0.1350 0.1299 0.1234 0.1201 0.1169 0.1149 0.1126 0.1118 0.1116 0.1115 0.1116 

[TRAIN] Epoch[5](1155/1500); Loss: 0.115867; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1823 0.1562 0.1287 0.1195 0.1152 0.1115 0.1101 0.1072 0.1057 0.1045 0.1034 0.1027 0.1021 0.1019 0.1017 0.1012 

[TRAIN] Epoch[5](1156/1500); Loss: 0.103155; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.1902 0.1605 0.1459 0.1012 0.0950 0.0990 0.0885 0.0877 0.0864 0.0853 0.0847 0.0855 0.0854 0.0851 0.0852 0.0849 

[TRAIN] Epoch[5](1157/1500); Loss: 0.131661; Backpropagation: 0.0983 sec; Batch: 0.4325 sec
0.1911 0.1739 0.1487 0.1359 0.1295 0.1238 0.1226 0.1213 0.1207 0.1204 0.1203 0.1202 0.1197 0.1195 0.1195 0.1194 

[TRAIN] Epoch[5](1158/1500); Loss: 0.108635; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.2295 0.1973 0.1564 0.1127 0.0974 0.0936 0.0910 0.0867 0.0850 0.0835 0.0834 0.0839 0.0840 0.0843 0.0843 0.0852 

[TRAIN] Epoch[5](1159/1500); Loss: 0.073352; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.1477 0.1255 0.1006 0.0804 0.0735 0.0688 0.0647 0.0591 0.0582 0.0580 0.0559 0.0556 0.0558 0.0561 0.0568 0.0570 

[TRAIN] Epoch[5](1160/1500); Loss: 0.082847; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.1332 0.1109 0.0924 0.0850 0.0793 0.0773 0.0752 0.0748 0.0745 0.0743 0.0743 0.0747 0.0747 0.0747 0.0751 0.0753 

[TRAIN] Epoch[5](1161/1500); Loss: 0.105076; Backpropagation: 0.0987 sec; Batch: 0.4332 sec
0.3308 0.2761 0.2708 0.1651 0.1438 0.0934 0.0729 0.0441 0.0394 0.0378 0.0345 0.0340 0.0338 0.0340 0.0350 0.0357 

[TRAIN] Epoch[5](1162/1500); Loss: 0.135402; Backpropagation: 0.0996 sec; Batch: 0.4343 sec
0.3596 0.3125 0.3055 0.2164 0.2001 0.1469 0.1160 0.0592 0.0543 0.0721 0.0543 0.0533 0.0533 0.0540 0.0544 0.0547 

[TRAIN] Epoch[5](1163/1500); Loss: 0.139495; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.3084 0.2758 0.2407 0.1737 0.1499 0.1281 0.1153 0.0969 0.0927 0.0932 0.0914 0.0925 0.0923 0.0928 0.0936 0.0946 

[TRAIN] Epoch[5](1164/1500); Loss: 0.110818; Backpropagation: 0.0992 sec; Batch: 0.4337 sec
0.2804 0.2336 0.2257 0.1355 0.1207 0.0856 0.0782 0.0765 0.0692 0.0692 0.0672 0.0676 0.0665 0.0656 0.0655 0.0660 

[TRAIN] Epoch[5](1165/1500); Loss: 0.105573; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1438 0.1386 0.1162 0.1131 0.1064 0.1015 0.0997 0.0986 0.0973 0.0969 0.0962 0.0961 0.0957 0.0959 0.0963 0.0968 

[TRAIN] Epoch[5](1166/1500); Loss: 0.115069; Backpropagation: 0.0982 sec; Batch: 0.4326 sec
0.1716 0.1500 0.1357 0.1181 0.1129 0.1077 0.1064 0.1076 0.1055 0.1040 0.1036 0.1035 0.1034 0.1034 0.1036 0.1039 

[TRAIN] Epoch[5](1167/1500); Loss: 0.074574; Backpropagation: 0.1000 sec; Batch: 0.4376 sec
0.1219 0.0901 0.0784 0.0903 0.0799 0.0717 0.0674 0.0669 0.0669 0.0656 0.0651 0.0654 0.0654 0.0658 0.0659 0.0663 

[TRAIN] Epoch[5](1168/1500); Loss: 0.123437; Backpropagation: 0.1017 sec; Batch: 0.4375 sec
0.1924 0.1697 0.1598 0.1405 0.1355 0.1218 0.1172 0.1096 0.1072 0.1049 0.1033 0.1029 0.1025 0.1025 0.1025 0.1027 

[TRAIN] Epoch[5](1169/1500); Loss: 0.084257; Backpropagation: 0.0993 sec; Batch: 0.4351 sec
0.1317 0.1117 0.0864 0.0870 0.0790 0.0783 0.0779 0.0773 0.0791 0.0777 0.0773 0.0771 0.0768 0.0767 0.0769 0.0772 

[TRAIN] Epoch[5](1170/1500); Loss: 0.107568; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.2258 0.1981 0.1710 0.1344 0.1183 0.1048 0.0969 0.0829 0.0779 0.0741 0.0741 0.0734 0.0725 0.0720 0.0722 0.0728 

[TRAIN] Epoch[5](1171/1500); Loss: 0.073107; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.1020 0.0785 0.0724 0.0759 0.0706 0.0689 0.0683 0.0681 0.0690 0.0692 0.0694 0.0697 0.0706 0.0714 0.0725 0.0731 

[TRAIN] Epoch[5](1172/1500); Loss: 0.160149; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.3935 0.3408 0.3253 0.2233 0.2108 0.1590 0.1402 0.0940 0.0878 0.0869 0.0840 0.0850 0.0824 0.0825 0.0829 0.0839 

[TRAIN] Epoch[5](1173/1500); Loss: 0.078782; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.1393 0.1096 0.0770 0.0708 0.0688 0.0681 0.0663 0.0674 0.0683 0.0696 0.0711 0.0727 0.0746 0.0766 0.0788 0.0814 

[TRAIN] Epoch[5](1174/1500); Loss: 0.075803; Backpropagation: 0.0982 sec; Batch: 0.4329 sec
0.2228 0.1493 0.0872 0.0641 0.0605 0.0589 0.0596 0.0585 0.0574 0.0568 0.0565 0.0563 0.0560 0.0561 0.0564 0.0566 

[TRAIN] Epoch[5](1175/1500); Loss: 0.093612; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1769 0.1482 0.1310 0.0961 0.0918 0.0849 0.0800 0.0773 0.0767 0.0765 0.0756 0.0758 0.0760 0.0763 0.0769 0.0777 

[TRAIN] Epoch[5](1176/1500); Loss: 0.096273; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.3151 0.2555 0.1907 0.1048 0.0555 0.0525 0.0537 0.0636 0.0647 0.0605 0.0583 0.0557 0.0538 0.0525 0.0518 0.0517 

[TRAIN] Epoch[5](1177/1500); Loss: 0.060619; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.1511 0.1044 0.0989 0.0631 0.0632 0.0517 0.0444 0.0463 0.0431 0.0446 0.0435 0.0430 0.0430 0.0429 0.0431 0.0436 

[TRAIN] Epoch[5](1178/1500); Loss: 0.090708; Backpropagation: 0.0981 sec; Batch: 0.4322 sec
0.1844 0.1559 0.1407 0.1083 0.0999 0.0774 0.0728 0.0773 0.0701 0.0693 0.0674 0.0662 0.0658 0.0658 0.0651 0.0650 

[TRAIN] Epoch[5](1179/1500); Loss: 0.172299; Backpropagation: 0.0996 sec; Batch: 0.4349 sec
0.3783 0.3267 0.3194 0.2309 0.2185 0.1746 0.1557 0.1212 0.1156 0.1069 0.1043 0.1049 0.1013 0.1000 0.0995 0.0991 

[TRAIN] Epoch[5](1180/1500); Loss: 0.147312; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.1945 0.1795 0.1711 0.1541 0.1473 0.1408 0.1387 0.1391 0.1361 0.1361 0.1360 0.1362 0.1363 0.1366 0.1371 0.1375 

[TRAIN] Epoch[5](1181/1500); Loss: 0.157279; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.2601 0.2368 0.2245 0.1909 0.1825 0.1621 0.1539 0.1346 0.1299 0.1237 0.1210 0.1221 0.1190 0.1187 0.1184 0.1183 

[TRAIN] Epoch[5](1182/1500); Loss: 0.119716; Backpropagation: 0.0991 sec; Batch: 0.4342 sec
0.2429 0.2057 0.1749 0.1383 0.1316 0.1183 0.1113 0.0969 0.0923 0.0879 0.0860 0.0880 0.0858 0.0854 0.0850 0.0851 

[TRAIN] Epoch[5](1183/1500); Loss: 0.087778; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1550 0.1229 0.1113 0.0889 0.0870 0.0810 0.0780 0.0765 0.0760 0.0754 0.0744 0.0742 0.0748 0.0756 0.0764 0.0770 

[TRAIN] Epoch[5](1184/1500); Loss: 0.144363; Backpropagation: 0.0983 sec; Batch: 0.4325 sec
0.2338 0.2127 0.1968 0.1596 0.1491 0.1332 0.1292 0.1244 0.1215 0.1203 0.1200 0.1210 0.1216 0.1221 0.1223 0.1221 

[TRAIN] Epoch[5](1185/1500); Loss: 0.104117; Backpropagation: 0.0994 sec; Batch: 0.4340 sec
0.2382 0.2052 0.1818 0.1237 0.1019 0.0794 0.0762 0.0799 0.0749 0.0728 0.0722 0.0718 0.0717 0.0721 0.0724 0.0719 

[TRAIN] Epoch[5](1186/1500); Loss: 0.093080; Backpropagation: 0.0993 sec; Batch: 0.4338 sec
0.1178 0.1082 0.1010 0.0976 0.0927 0.0909 0.0893 0.0882 0.0878 0.0877 0.0876 0.0878 0.0879 0.0880 0.0883 0.0886 

[TRAIN] Epoch[5](1187/1500); Loss: 0.035042; Backpropagation: 0.0991 sec; Batch: 0.4338 sec
0.0603 0.0421 0.0359 0.0349 0.0331 0.0320 0.0293 0.0299 0.0301 0.0306 0.0313 0.0322 0.0330 0.0340 0.0353 0.0367 

[TRAIN] Epoch[5](1188/1500); Loss: 0.110411; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1889 0.1529 0.1403 0.1269 0.1161 0.1049 0.0999 0.0961 0.0941 0.0925 0.0938 0.0938 0.0927 0.0920 0.0911 0.0906 

[TRAIN] Epoch[5](1189/1500); Loss: 0.088130; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.2945 0.2296 0.2177 0.0982 0.0841 0.0405 0.0439 0.0715 0.0471 0.0446 0.0401 0.0388 0.0393 0.0391 0.0405 0.0408 

[TRAIN] Epoch[5](1190/1500); Loss: 0.102001; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1442 0.1306 0.1130 0.1063 0.1014 0.0986 0.0971 0.0958 0.0948 0.0941 0.0930 0.0924 0.0923 0.0927 0.0927 0.0930 

[TRAIN] Epoch[5](1191/1500); Loss: 0.122676; Backpropagation: 0.0996 sec; Batch: 0.4353 sec
0.2315 0.1960 0.1634 0.1252 0.1162 0.1095 0.1067 0.1040 0.1019 0.1015 0.1011 0.1012 0.1009 0.1009 0.1012 0.1016 

[TRAIN] Epoch[5](1192/1500); Loss: 0.046517; Backpropagation: 0.1021 sec; Batch: 0.4377 sec
0.0858 0.0532 0.0479 0.0485 0.0448 0.0425 0.0405 0.0401 0.0419 0.0444 0.0433 0.0424 0.0418 0.0414 0.0428 0.0429 

[TRAIN] Epoch[5](1193/1500); Loss: 0.090147; Backpropagation: 0.0989 sec; Batch: 0.4333 sec
0.2344 0.1895 0.1424 0.0999 0.0680 0.0669 0.0679 0.0691 0.0677 0.0651 0.0639 0.0621 0.0609 0.0607 0.0622 0.0617 

[TRAIN] Epoch[5](1194/1500); Loss: 0.098626; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1777 0.1528 0.1300 0.1099 0.1031 0.0912 0.0889 0.0858 0.0814 0.0804 0.0800 0.0792 0.0791 0.0794 0.0793 0.0799 

[TRAIN] Epoch[5](1195/1500); Loss: 0.175272; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.2870 0.2535 0.2438 0.1941 0.1860 0.1637 0.1577 0.1520 0.1481 0.1479 0.1460 0.1455 0.1445 0.1451 0.1447 0.1447 

[TRAIN] Epoch[5](1196/1500); Loss: 0.091865; Backpropagation: 0.0992 sec; Batch: 0.4344 sec
0.1479 0.1311 0.1117 0.1035 0.0906 0.0877 0.0828 0.0810 0.0801 0.0799 0.0798 0.0791 0.0785 0.0785 0.0785 0.0790 

[TRAIN] Epoch[5](1197/1500); Loss: 0.126960; Backpropagation: 0.0998 sec; Batch: 0.4349 sec
0.2087 0.1879 0.1697 0.1407 0.1358 0.1187 0.1142 0.1096 0.1086 0.1059 0.1058 0.1056 0.1055 0.1047 0.1049 0.1051 

[TRAIN] Epoch[5](1198/1500); Loss: 0.208561; Backpropagation: 0.0992 sec; Batch: 0.4333 sec
0.2969 0.2738 0.2644 0.2366 0.2281 0.2046 0.1974 0.1904 0.1857 0.1837 0.1818 0.1803 0.1793 0.1786 0.1779 0.1772 

[TRAIN] Epoch[5](1199/1500); Loss: 0.108918; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.2635 0.2217 0.2085 0.1400 0.1297 0.1034 0.0912 0.0706 0.0673 0.0671 0.0640 0.0637 0.0632 0.0630 0.0628 0.0631 

[TRAIN] Epoch[5](1200/1500); Loss: 0.076582; Backpropagation: 0.0982 sec; Batch: 0.4329 sec
0.1073 0.0934 0.0786 0.0769 0.0738 0.0719 0.0711 0.0714 0.0716 0.0712 0.0712 0.0716 0.0723 0.0731 0.0743 0.0756 

[TRAIN] Epoch[5](1201/1500); Loss: 0.210660; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.4186 0.3615 0.3464 0.2556 0.2438 0.1995 0.1845 0.1553 0.1530 0.1537 0.1500 0.1496 0.1496 0.1492 0.1498 0.1505 

[TRAIN] Epoch[5](1202/1500); Loss: 0.148129; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1907 0.1704 0.1619 0.1487 0.1443 0.1445 0.1418 0.1397 0.1389 0.1389 0.1391 0.1401 0.1420 0.1426 0.1429 0.1437 

[TRAIN] Epoch[5](1203/1500); Loss: 0.100139; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1518 0.1200 0.1134 0.1145 0.1073 0.0970 0.0927 0.0923 0.0901 0.0890 0.0892 0.0889 0.0884 0.0890 0.0891 0.0894 

[TRAIN] Epoch[5](1204/1500); Loss: 0.116632; Backpropagation: 0.0982 sec; Batch: 0.4323 sec
0.2256 0.1892 0.1649 0.1342 0.1242 0.1081 0.1019 0.0956 0.0941 0.0905 0.0905 0.0902 0.0897 0.0892 0.0891 0.0891 

[TRAIN] Epoch[5](1205/1500); Loss: 0.145201; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.2695 0.2252 0.2185 0.1777 0.1692 0.1443 0.1355 0.1183 0.1137 0.1093 0.1077 0.1078 0.1071 0.1065 0.1065 0.1065 

[TRAIN] Epoch[5](1206/1500); Loss: 0.152578; Backpropagation: 0.0990 sec; Batch: 0.4426 sec
0.1947 0.1818 0.1721 0.1541 0.1500 0.1450 0.1439 0.1433 0.1433 0.1439 0.1439 0.1442 0.1445 0.1449 0.1454 0.1460 

[TRAIN] Epoch[5](1207/1500); Loss: 0.117433; Backpropagation: 0.0992 sec; Batch: 0.4341 sec
0.1665 0.1490 0.1293 0.1211 0.1162 0.1151 0.1128 0.1086 0.1082 0.1075 0.1074 0.1070 0.1066 0.1072 0.1079 0.1085 

[TRAIN] Epoch[5](1208/1500); Loss: 0.169090; Backpropagation: 0.0987 sec; Batch: 0.4330 sec
0.3306 0.2936 0.2830 0.2227 0.2115 0.1786 0.1660 0.1308 0.1200 0.1113 0.1090 0.1123 0.1100 0.1090 0.1085 0.1087 

[TRAIN] Epoch[5](1209/1500); Loss: 0.050916; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.0695 0.0613 0.0559 0.0566 0.0510 0.0497 0.0480 0.0471 0.0463 0.0459 0.0460 0.0464 0.0467 0.0472 0.0481 0.0491 

[TRAIN] Epoch[5](1210/1500); Loss: 0.158057; Backpropagation: 0.0985 sec; Batch: 0.4392 sec
0.3206 0.2727 0.2650 0.1890 0.1776 0.1488 0.1379 0.1228 0.1168 0.1122 0.1113 0.1110 0.1109 0.1109 0.1105 0.1107 

[TRAIN] Epoch[5](1211/1500); Loss: 0.082104; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1474 0.1189 0.0955 0.0990 0.0878 0.0733 0.0717 0.0711 0.0708 0.0701 0.0689 0.0685 0.0683 0.0675 0.0676 0.0671 

[TRAIN] Epoch[5](1212/1500); Loss: 0.064183; Backpropagation: 0.0984 sec; Batch: 0.4323 sec
0.1740 0.1120 0.0634 0.0689 0.0542 0.0514 0.0494 0.0484 0.0486 0.0519 0.0500 0.0499 0.0501 0.0504 0.0516 0.0527 

[TRAIN] Epoch[5](1213/1500); Loss: 0.143611; Backpropagation: 0.0987 sec; Batch: 0.4341 sec
0.2350 0.2131 0.1952 0.1579 0.1467 0.1324 0.1272 0.1238 0.1210 0.1193 0.1199 0.1209 0.1209 0.1213 0.1213 0.1219 

[TRAIN] Epoch[5](1214/1500); Loss: 0.110708; Backpropagation: 0.1081 sec; Batch: 0.4430 sec
0.1635 0.1495 0.1226 0.1123 0.1081 0.1046 0.1028 0.1026 0.1018 0.1010 0.1006 0.1006 0.1004 0.1003 0.1003 0.1003 

[TRAIN] Epoch[5](1215/1500); Loss: 0.101144; Backpropagation: 0.1026 sec; Batch: 0.4374 sec
0.1872 0.1592 0.1371 0.1059 0.0974 0.0896 0.0870 0.0880 0.0850 0.0835 0.0828 0.0829 0.0831 0.0831 0.0831 0.0831 

[TRAIN] Epoch[5](1216/1500); Loss: 0.115634; Backpropagation: 0.1003 sec; Batch: 0.4343 sec
0.3561 0.3015 0.2961 0.1886 0.1675 0.1131 0.0845 0.0484 0.0482 0.0371 0.0341 0.0343 0.0346 0.0345 0.0352 0.0363 

[TRAIN] Epoch[5](1217/1500); Loss: 0.095948; Backpropagation: 0.0990 sec; Batch: 0.4342 sec
0.2192 0.1786 0.1506 0.1170 0.1099 0.0942 0.0868 0.0704 0.0666 0.0643 0.0629 0.0634 0.0621 0.0624 0.0630 0.0638 

[TRAIN] Epoch[5](1218/1500); Loss: 0.152876; Backpropagation: 0.0982 sec; Batch: 0.4329 sec
0.3980 0.3410 0.3279 0.2243 0.2085 0.1468 0.1231 0.0792 0.0799 0.0816 0.0752 0.0745 0.0726 0.0713 0.0709 0.0711 

[TRAIN] Epoch[5](1219/1500); Loss: 0.049361; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.0569 0.0615 0.0479 0.0517 0.0480 0.0481 0.0470 0.0463 0.0463 0.0466 0.0479 0.0478 0.0478 0.0482 0.0486 0.0491 

[TRAIN] Epoch[5](1220/1500); Loss: 0.109371; Backpropagation: 0.1027 sec; Batch: 0.4384 sec
0.1379 0.1229 0.1156 0.1194 0.1145 0.1082 0.1057 0.1036 0.1031 0.1029 0.1028 0.1029 0.1027 0.1025 0.1026 0.1027 

[TRAIN] Epoch[5](1221/1500); Loss: 0.132205; Backpropagation: 0.1024 sec; Batch: 0.4370 sec
0.2228 0.1983 0.1875 0.1519 0.1446 0.1293 0.1238 0.1109 0.1075 0.1047 0.1043 0.1070 0.1060 0.1057 0.1054 0.1055 

[TRAIN] Epoch[5](1222/1500); Loss: 0.125920; Backpropagation: 0.0991 sec; Batch: 0.4337 sec
0.1726 0.1597 0.1362 0.1268 0.1171 0.1169 0.1156 0.1153 0.1154 0.1159 0.1170 0.1183 0.1197 0.1210 0.1227 0.1246 

[TRAIN] Epoch[5](1223/1500); Loss: 0.118666; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2339 0.1914 0.1767 0.1248 0.1171 0.1029 0.1004 0.1005 0.0971 0.0939 0.0930 0.0926 0.0928 0.0935 0.0938 0.0942 

[TRAIN] Epoch[5](1224/1500); Loss: 0.097533; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1370 0.1230 0.1121 0.1165 0.1039 0.0958 0.0928 0.0902 0.0875 0.0863 0.0858 0.0859 0.0857 0.0857 0.0860 0.0863 

[TRAIN] Epoch[5](1225/1500); Loss: 0.177830; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.3449 0.2990 0.2869 0.2335 0.2124 0.1510 0.1379 0.1462 0.1379 0.1289 0.1271 0.1267 0.1276 0.1280 0.1287 0.1286 

[TRAIN] Epoch[5](1226/1500); Loss: 0.107048; Backpropagation: 0.1024 sec; Batch: 0.4369 sec
0.1845 0.1597 0.1326 0.1157 0.1119 0.1010 0.0974 0.0931 0.0915 0.0891 0.0889 0.0892 0.0893 0.0897 0.0894 0.0897 

[TRAIN] Epoch[5](1227/1500); Loss: 0.155076; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.2732 0.2335 0.2236 0.1710 0.1636 0.1343 0.1258 0.1388 0.1273 0.1299 0.1269 0.1267 0.1266 0.1264 0.1266 0.1269 

[TRAIN] Epoch[5](1228/1500); Loss: 0.062008; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1432 0.1137 0.0825 0.0749 0.0638 0.0504 0.0494 0.0476 0.0467 0.0455 0.0455 0.0451 0.0452 0.0456 0.0463 0.0468 

[TRAIN] Epoch[5](1229/1500); Loss: 0.110872; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1708 0.1370 0.1140 0.1113 0.1081 0.1050 0.1043 0.1031 0.1030 0.1028 0.1025 0.1025 0.1023 0.1023 0.1023 0.1027 

[TRAIN] Epoch[5](1230/1500); Loss: 0.100910; Backpropagation: 0.0989 sec; Batch: 0.4433 sec
0.2191 0.1867 0.1447 0.1037 0.0889 0.0786 0.0791 0.0800 0.0781 0.0777 0.0781 0.0788 0.0791 0.0798 0.0806 0.0815 

[TRAIN] Epoch[5](1231/1500); Loss: 0.096449; Backpropagation: 0.0993 sec; Batch: 0.4342 sec
0.1351 0.1287 0.1162 0.1050 0.0954 0.0906 0.0889 0.0871 0.0879 0.0869 0.0866 0.0864 0.0866 0.0868 0.0872 0.0877 

[TRAIN] Epoch[5](1232/1500); Loss: 0.224575; Backpropagation: 0.0994 sec; Batch: 0.4351 sec
0.3819 0.3299 0.3180 0.2515 0.2417 0.2088 0.1989 0.1953 0.1909 0.1865 0.1838 0.1823 0.1826 0.1813 0.1803 0.1797 

[TRAIN] Epoch[5](1233/1500); Loss: 0.105988; Backpropagation: 0.0994 sec; Batch: 0.4347 sec
0.1624 0.1442 0.1189 0.1040 0.1022 0.0986 0.0986 0.0989 0.0980 0.0958 0.0958 0.0958 0.0957 0.0956 0.0956 0.0957 

[TRAIN] Epoch[5](1234/1500); Loss: 0.097127; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1424 0.1173 0.1088 0.1149 0.1058 0.0920 0.0901 0.0884 0.0877 0.0865 0.0864 0.0865 0.0864 0.0864 0.0870 0.0872 

[TRAIN] Epoch[5](1235/1500); Loss: 0.054963; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1094 0.0712 0.0678 0.0658 0.0600 0.0517 0.0464 0.0469 0.0451 0.0440 0.0439 0.0444 0.0447 0.0452 0.0460 0.0470 

[TRAIN] Epoch[5](1236/1500); Loss: 0.144955; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.1927 0.1896 0.1688 0.1572 0.1514 0.1443 0.1417 0.1337 0.1315 0.1297 0.1292 0.1296 0.1296 0.1298 0.1301 0.1303 

[TRAIN] Epoch[5](1237/1500); Loss: 0.127604; Backpropagation: 0.1028 sec; Batch: 0.4391 sec
0.2770 0.2365 0.2200 0.1647 0.1542 0.1282 0.1176 0.0926 0.0880 0.0827 0.0806 0.0798 0.0796 0.0796 0.0799 0.0806 

[TRAIN] Epoch[5](1238/1500); Loss: 0.101475; Backpropagation: 0.0992 sec; Batch: 0.4336 sec
0.1776 0.1415 0.1146 0.1061 0.0976 0.0944 0.0936 0.0925 0.0898 0.0891 0.0887 0.0881 0.0876 0.0876 0.0874 0.0874 

[TRAIN] Epoch[5](1239/1500); Loss: 0.105793; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1824 0.1544 0.1219 0.0983 0.0942 0.0936 0.0951 0.0969 0.0947 0.0942 0.0939 0.0940 0.0941 0.0946 0.0950 0.0953 

[TRAIN] Epoch[5](1240/1500); Loss: 0.088262; Backpropagation: 0.0982 sec; Batch: 0.4323 sec
0.1771 0.1408 0.1217 0.0901 0.0843 0.0760 0.0729 0.0774 0.0730 0.0717 0.0714 0.0709 0.0709 0.0709 0.0713 0.0718 

[TRAIN] Epoch[5](1241/1500); Loss: 0.080802; Backpropagation: 0.0985 sec; Batch: 0.4336 sec
0.1209 0.1089 0.0948 0.0842 0.0819 0.0779 0.0764 0.0734 0.0719 0.0716 0.0710 0.0717 0.0717 0.0719 0.0721 0.0726 

[TRAIN] Epoch[5](1242/1500); Loss: 0.067457; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.1849 0.1436 0.1313 0.0731 0.0664 0.0485 0.0442 0.0532 0.0470 0.0416 0.0411 0.0405 0.0403 0.0406 0.0412 0.0419 

[TRAIN] Epoch[5](1243/1500); Loss: 0.055136; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1159 0.0755 0.0713 0.0574 0.0597 0.0485 0.0454 0.0453 0.0448 0.0446 0.0448 0.0452 0.0450 0.0456 0.0463 0.0469 

[TRAIN] Epoch[5](1244/1500); Loss: 0.057945; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.1393 0.1051 0.0645 0.0598 0.0539 0.0455 0.0444 0.0440 0.0443 0.0462 0.0465 0.0469 0.0466 0.0463 0.0466 0.0472 

[TRAIN] Epoch[5](1245/1500); Loss: 0.104147; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1461 0.1323 0.1171 0.1257 0.1093 0.0970 0.0969 0.0952 0.0944 0.0937 0.0933 0.0929 0.0930 0.0929 0.0930 0.0933 

[TRAIN] Epoch[5](1246/1500); Loss: 0.149517; Backpropagation: 0.0982 sec; Batch: 0.4326 sec
0.3013 0.2645 0.2549 0.1986 0.1889 0.1619 0.1484 0.1090 0.1000 0.0940 0.0934 0.0979 0.0959 0.0943 0.0947 0.0948 

[TRAIN] Epoch[5](1247/1500); Loss: 0.152189; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.2901 0.2448 0.2302 0.1704 0.1620 0.1403 0.1355 0.1242 0.1193 0.1167 0.1165 0.1178 0.1170 0.1166 0.1167 0.1168 

[TRAIN] Epoch[5](1248/1500); Loss: 0.093724; Backpropagation: 0.0983 sec; Batch: 0.4335 sec
0.1297 0.1129 0.1000 0.0938 0.0916 0.0895 0.0884 0.0883 0.0883 0.0883 0.0882 0.0887 0.0884 0.0881 0.0877 0.0878 

[TRAIN] Epoch[5](1249/1500); Loss: 0.068362; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1140 0.1039 0.0854 0.0846 0.0723 0.0631 0.0617 0.0590 0.0573 0.0566 0.0560 0.0554 0.0553 0.0556 0.0563 0.0572 

[TRAIN] Epoch[5](1250/1500); Loss: 0.073641; Backpropagation: 0.0982 sec; Batch: 0.4323 sec
0.2830 0.1978 0.1065 0.0447 0.0379 0.0407 0.0557 0.0610 0.0522 0.0500 0.0467 0.0430 0.0406 0.0401 0.0392 0.0392 

[TRAIN] Epoch[5](1251/1500); Loss: 0.092540; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1314 0.1212 0.1065 0.0993 0.0930 0.0877 0.0847 0.0848 0.0819 0.0817 0.0822 0.0829 0.0839 0.0851 0.0864 0.0879 

[TRAIN] Epoch[5](1252/1500); Loss: 0.146927; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.2366 0.2100 0.1668 0.1477 0.1429 0.1400 0.1383 0.1342 0.1329 0.1314 0.1292 0.1285 0.1285 0.1282 0.1280 0.1278 

[TRAIN] Epoch[5](1253/1500); Loss: 0.099116; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.2274 0.1851 0.1585 0.1222 0.1114 0.0956 0.0893 0.0730 0.0696 0.0652 0.0643 0.0642 0.0647 0.0649 0.0648 0.0657 

[TRAIN] Epoch[5](1254/1500); Loss: 0.228309; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.4623 0.3969 0.3826 0.2749 0.2632 0.2224 0.2092 0.1724 0.1653 0.1632 0.1566 0.1573 0.1572 0.1568 0.1565 0.1563 

[TRAIN] Epoch[5](1255/1500); Loss: 0.092607; Backpropagation: 0.1000 sec; Batch: 0.4349 sec
0.1729 0.1405 0.1328 0.0949 0.0850 0.0766 0.0779 0.0820 0.0783 0.0777 0.0770 0.0766 0.0767 0.0770 0.0774 0.0782 

[TRAIN] Epoch[5](1256/1500); Loss: 0.077526; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.2151 0.1416 0.0861 0.0677 0.0653 0.0643 0.0642 0.0636 0.0617 0.0604 0.0595 0.0586 0.0582 0.0580 0.0579 0.0582 

[TRAIN] Epoch[5](1257/1500); Loss: 0.067611; Backpropagation: 0.0988 sec; Batch: 0.4333 sec
0.2414 0.1505 0.0720 0.0503 0.0418 0.0434 0.0530 0.0535 0.0487 0.0478 0.0464 0.0456 0.0457 0.0469 0.0470 0.0479 

[TRAIN] Epoch[5](1258/1500); Loss: 0.088186; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.1708 0.1280 0.1074 0.0953 0.0909 0.0826 0.0794 0.0769 0.0757 0.0729 0.0721 0.0721 0.0719 0.0719 0.0717 0.0713 

[TRAIN] Epoch[5](1259/1500); Loss: 0.089381; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1995 0.1596 0.1443 0.1016 0.0971 0.0833 0.0756 0.0667 0.0665 0.0627 0.0628 0.0622 0.0621 0.0621 0.0620 0.0621 

[TRAIN] Epoch[5](1260/1500); Loss: 0.063636; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1726 0.1278 0.1213 0.0555 0.0493 0.0433 0.0457 0.0505 0.0462 0.0451 0.0440 0.0433 0.0430 0.0431 0.0436 0.0437 

[TRAIN] Epoch[5](1261/1500); Loss: 0.134795; Backpropagation: 0.0997 sec; Batch: 0.4347 sec
0.2276 0.2038 0.1816 0.1423 0.1327 0.1197 0.1177 0.1175 0.1156 0.1145 0.1143 0.1134 0.1138 0.1139 0.1142 0.1142 

[TRAIN] Epoch[5](1262/1500); Loss: 0.160807; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.2630 0.2329 0.2197 0.1765 0.1698 0.1517 0.1471 0.1414 0.1374 0.1339 0.1329 0.1333 0.1333 0.1331 0.1334 0.1335 

[TRAIN] Epoch[5](1263/1500); Loss: 0.100457; Backpropagation: 0.0991 sec; Batch: 0.4335 sec
0.1573 0.1338 0.1265 0.1178 0.1100 0.1006 0.0973 0.0920 0.0898 0.0869 0.0853 0.0834 0.0823 0.0817 0.0814 0.0811 

[TRAIN] Epoch[5](1264/1500); Loss: 0.084547; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2541 0.1722 0.0966 0.0648 0.0559 0.0591 0.0672 0.0684 0.0652 0.0646 0.0634 0.0630 0.0632 0.0640 0.0650 0.0662 

[TRAIN] Epoch[5](1265/1500); Loss: 0.135342; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.2040 0.1778 0.1584 0.1389 0.1301 0.1276 0.1242 0.1233 0.1212 0.1219 0.1216 0.1222 0.1225 0.1230 0.1238 0.1250 

[TRAIN] Epoch[5](1266/1500); Loss: 0.161356; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1924 0.1857 0.1774 0.1688 0.1632 0.1575 0.1556 0.1547 0.1537 0.1536 0.1530 0.1529 0.1530 0.1532 0.1533 0.1536 

[TRAIN] Epoch[5](1267/1500); Loss: 0.064949; Backpropagation: 0.0986 sec; Batch: 0.4330 sec
0.1318 0.0868 0.0664 0.0628 0.0611 0.0593 0.0574 0.0573 0.0571 0.0570 0.0568 0.0569 0.0569 0.0570 0.0573 0.0573 

[TRAIN] Epoch[5](1268/1500); Loss: 0.067816; Backpropagation: 0.0992 sec; Batch: 0.4470 sec
0.1291 0.1060 0.0814 0.0844 0.0734 0.0630 0.0597 0.0577 0.0558 0.0543 0.0537 0.0535 0.0535 0.0533 0.0532 0.0531 

[TRAIN] Epoch[5](1269/1500); Loss: 0.134622; Backpropagation: 0.0990 sec; Batch: 0.4377 sec
0.2602 0.2179 0.2047 0.1347 0.1276 0.1149 0.1102 0.1162 0.1115 0.1095 0.1090 0.1083 0.1077 0.1073 0.1070 0.1072 

[TRAIN] Epoch[5](1270/1500); Loss: 0.077924; Backpropagation: 0.0990 sec; Batch: 0.4338 sec
0.1442 0.1135 0.1086 0.0962 0.0855 0.0722 0.0685 0.0664 0.0648 0.0618 0.0612 0.0608 0.0608 0.0604 0.0606 0.0612 

[TRAIN] Epoch[5](1271/1500); Loss: 0.089087; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.1332 0.1207 0.1043 0.0947 0.0908 0.0837 0.0805 0.0799 0.0790 0.0782 0.0784 0.0792 0.0794 0.0801 0.0811 0.0823 

[TRAIN] Epoch[5](1272/1500); Loss: 0.107376; Backpropagation: 0.0990 sec; Batch: 0.4414 sec
0.1797 0.1469 0.1243 0.1175 0.1061 0.0993 0.0970 0.0952 0.0948 0.0943 0.0941 0.0939 0.0938 0.0938 0.0935 0.0936 

[TRAIN] Epoch[5](1273/1500); Loss: 0.100126; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1689 0.1369 0.1233 0.1040 0.0992 0.0969 0.0919 0.0910 0.0880 0.0864 0.0857 0.0855 0.0858 0.0858 0.0861 0.0866 

[TRAIN] Epoch[5](1274/1500); Loss: 0.158744; Backpropagation: 0.0992 sec; Batch: 0.4343 sec
0.2333 0.2138 0.1934 0.1663 0.1578 0.1510 0.1485 0.1473 0.1437 0.1408 0.1404 0.1404 0.1404 0.1406 0.1409 0.1414 

[TRAIN] Epoch[5](1275/1500); Loss: 0.068099; Backpropagation: 0.0994 sec; Batch: 0.4352 sec
0.0836 0.0874 0.0682 0.0720 0.0681 0.0677 0.0670 0.0657 0.0650 0.0642 0.0637 0.0634 0.0631 0.0633 0.0634 0.0638 

[TRAIN] Epoch[5](1276/1500); Loss: 0.084188; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.0980 0.0903 0.0829 0.0926 0.0860 0.0822 0.0810 0.0807 0.0807 0.0808 0.0809 0.0812 0.0818 0.0820 0.0826 0.0833 

[TRAIN] Epoch[5](1277/1500); Loss: 0.130811; Backpropagation: 0.0991 sec; Batch: 0.4336 sec
0.2529 0.2174 0.1980 0.1525 0.1462 0.1261 0.1198 0.1078 0.1024 0.0984 0.0961 0.0957 0.0952 0.0950 0.0949 0.0947 

[TRAIN] Epoch[5](1278/1500); Loss: 0.101650; Backpropagation: 0.1025 sec; Batch: 0.4373 sec
0.1496 0.1319 0.1162 0.1016 0.0996 0.0988 0.0961 0.0952 0.0940 0.0928 0.0920 0.0916 0.0918 0.0917 0.0916 0.0920 

[TRAIN] Epoch[5](1279/1500); Loss: 0.145988; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.1877 0.1834 0.1638 0.1597 0.1492 0.1453 0.1411 0.1398 0.1375 0.1354 0.1338 0.1331 0.1322 0.1316 0.1312 0.1310 

[TRAIN] Epoch[5](1280/1500); Loss: 0.106768; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2635 0.2189 0.2099 0.1215 0.1089 0.0820 0.0802 0.0827 0.0759 0.0691 0.0682 0.0667 0.0660 0.0652 0.0648 0.0648 

[TRAIN] Epoch[5](1281/1500); Loss: 0.089608; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1336 0.1233 0.0974 0.0958 0.0915 0.0861 0.0835 0.0808 0.0804 0.0801 0.0800 0.0799 0.0799 0.0800 0.0805 0.0811 

[TRAIN] Epoch[5](1282/1500); Loss: 0.101841; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1334 0.1284 0.1136 0.1096 0.1048 0.0998 0.0975 0.0934 0.0927 0.0925 0.0926 0.0931 0.0939 0.0942 0.0947 0.0953 

[TRAIN] Epoch[5](1283/1500); Loss: 0.073216; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.2183 0.1404 0.0784 0.0627 0.0578 0.0584 0.0580 0.0577 0.0563 0.0554 0.0547 0.0544 0.0546 0.0547 0.0547 0.0550 

[TRAIN] Epoch[5](1284/1500); Loss: 0.107860; Backpropagation: 0.0993 sec; Batch: 0.4337 sec
0.2306 0.1909 0.1834 0.1335 0.1263 0.1013 0.0899 0.0766 0.0812 0.0731 0.0733 0.0732 0.0731 0.0730 0.0731 0.0733 

[TRAIN] Epoch[5](1285/1500); Loss: 0.117795; Backpropagation: 0.0990 sec; Batch: 0.4331 sec
0.1486 0.1353 0.1273 0.1267 0.1216 0.1153 0.1144 0.1132 0.1124 0.1111 0.1105 0.1100 0.1097 0.1096 0.1096 0.1096 

[TRAIN] Epoch[5](1286/1500); Loss: 0.088408; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1283 0.1159 0.1019 0.0931 0.0861 0.0828 0.0818 0.0816 0.0811 0.0806 0.0804 0.0802 0.0800 0.0800 0.0803 0.0805 

[TRAIN] Epoch[5](1287/1500); Loss: 0.068403; Backpropagation: 0.0983 sec; Batch: 0.4333 sec
0.1236 0.0885 0.0828 0.0714 0.0721 0.0663 0.0618 0.0605 0.0598 0.0590 0.0587 0.0582 0.0578 0.0579 0.0581 0.0580 

[TRAIN] Epoch[5](1288/1500); Loss: 0.066134; Backpropagation: 0.0982 sec; Batch: 0.4325 sec
0.1027 0.0927 0.0721 0.0719 0.0655 0.0615 0.0603 0.0594 0.0589 0.0587 0.0586 0.0587 0.0588 0.0591 0.0594 0.0598 

[TRAIN] Epoch[5](1289/1500); Loss: 0.106706; Backpropagation: 0.0989 sec; Batch: 0.4341 sec
0.2416 0.1998 0.1941 0.1233 0.1104 0.0879 0.0807 0.0814 0.0801 0.0729 0.0724 0.0723 0.0724 0.0724 0.0726 0.0728 

[TRAIN] Epoch[5](1290/1500); Loss: 0.107480; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.2822 0.2346 0.1883 0.1220 0.0889 0.0790 0.0767 0.0796 0.0753 0.0717 0.0710 0.0705 0.0701 0.0701 0.0700 0.0698 

[TRAIN] Epoch[5](1291/1500); Loss: 0.066715; Backpropagation: 0.0994 sec; Batch: 0.4337 sec
0.1321 0.1053 0.0850 0.0584 0.0565 0.0563 0.0549 0.0546 0.0547 0.0546 0.0555 0.0567 0.0582 0.0597 0.0615 0.0636 

[TRAIN] Epoch[5](1292/1500); Loss: 0.112290; Backpropagation: 0.0990 sec; Batch: 0.4337 sec
0.1794 0.1462 0.1200 0.1127 0.1087 0.1059 0.1047 0.1037 0.1025 0.1021 0.1017 0.1016 0.1017 0.1018 0.1019 0.1020 

[TRAIN] Epoch[5](1293/1500); Loss: 0.128752; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.2036 0.1686 0.1405 0.1307 0.1285 0.1230 0.1207 0.1168 0.1164 0.1158 0.1151 0.1153 0.1155 0.1155 0.1166 0.1177 

[TRAIN] Epoch[5](1294/1500); Loss: 0.101642; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1459 0.1290 0.1174 0.1043 0.1013 0.0965 0.0947 0.0949 0.0948 0.0930 0.0927 0.0924 0.0923 0.0923 0.0924 0.0925 

[TRAIN] Epoch[5](1295/1500); Loss: 0.165173; Backpropagation: 0.1017 sec; Batch: 0.4366 sec
0.2129 0.1914 0.1890 0.1860 0.1806 0.1590 0.1571 0.1574 0.1533 0.1524 0.1517 0.1511 0.1508 0.1505 0.1501 0.1495 

[TRAIN] Epoch[5](1296/1500); Loss: 0.149228; Backpropagation: 0.0994 sec; Batch: 0.4343 sec
0.2512 0.2298 0.2119 0.1681 0.1582 0.1426 0.1355 0.1266 0.1246 0.1195 0.1194 0.1205 0.1203 0.1196 0.1198 0.1200 

[TRAIN] Epoch[5](1297/1500); Loss: 0.064761; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.0936 0.0813 0.0728 0.0724 0.0677 0.0626 0.0603 0.0595 0.0588 0.0583 0.0577 0.0574 0.0577 0.0581 0.0587 0.0595 

[TRAIN] Epoch[5](1298/1500); Loss: 0.100041; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2249 0.1872 0.1735 0.1060 0.0937 0.0871 0.0750 0.0753 0.0740 0.0725 0.0719 0.0717 0.0716 0.0718 0.0721 0.0724 

[TRAIN] Epoch[5](1299/1500); Loss: 0.065492; Backpropagation: 0.0989 sec; Batch: 0.4338 sec
0.2090 0.1492 0.0862 0.0511 0.0479 0.0470 0.0474 0.0473 0.0460 0.0457 0.0453 0.0448 0.0448 0.0450 0.0455 0.0457 

[TRAIN] Epoch[5](1300/1500); Loss: 0.131924; Backpropagation: 0.0990 sec; Batch: 0.4721 sec
0.3214 0.2609 0.2486 0.1300 0.1146 0.0839 0.0835 0.1130 0.1016 0.0903 0.0921 0.0923 0.0934 0.0946 0.0949 0.0958 

[TRAIN] Epoch[5](1301/1500); Loss: 0.142939; Backpropagation: 0.0995 sec; Batch: 0.4350 sec
0.1871 0.1756 0.1613 0.1464 0.1420 0.1370 0.1355 0.1369 0.1357 0.1332 0.1330 0.1327 0.1327 0.1327 0.1326 0.1327 

[TRAIN] Epoch[5](1302/1500); Loss: 0.099270; Backpropagation: 0.0990 sec; Batch: 0.4341 sec
0.2263 0.1933 0.1877 0.1415 0.1269 0.0937 0.0799 0.0628 0.0700 0.0583 0.0585 0.0583 0.0579 0.0577 0.0577 0.0578 

[TRAIN] Epoch[5](1303/1500); Loss: 0.141317; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.2892 0.2474 0.2154 0.1588 0.1485 0.1294 0.1212 0.1133 0.1097 0.1042 0.1039 0.1040 0.1040 0.1039 0.1039 0.1042 

[TRAIN] Epoch[5](1304/1500); Loss: 0.089827; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.1561 0.1231 0.0926 0.0937 0.0862 0.0823 0.0817 0.0807 0.0801 0.0796 0.0794 0.0794 0.0796 0.0804 0.0809 0.0815 

[TRAIN] Epoch[5](1305/1500); Loss: 0.080513; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1195 0.0994 0.0884 0.0904 0.0808 0.0752 0.0739 0.0741 0.0734 0.0731 0.0731 0.0733 0.0732 0.0732 0.0734 0.0736 

[TRAIN] Epoch[5](1306/1500); Loss: 0.087976; Backpropagation: 0.0984 sec; Batch: 0.4336 sec
0.1899 0.1479 0.1388 0.0844 0.0739 0.0730 0.0710 0.0756 0.0705 0.0700 0.0691 0.0685 0.0684 0.0683 0.0688 0.0696 

[TRAIN] Epoch[5](1307/1500); Loss: 0.063548; Backpropagation: 0.0988 sec; Batch: 0.4334 sec
0.1140 0.0966 0.0825 0.0752 0.0692 0.0584 0.0544 0.0543 0.0516 0.0504 0.0506 0.0507 0.0511 0.0517 0.0526 0.0535 

[TRAIN] Epoch[5](1308/1500); Loss: 0.092470; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.2143 0.1653 0.1579 0.0899 0.0819 0.0731 0.0736 0.0758 0.0715 0.0690 0.0686 0.0680 0.0677 0.0676 0.0677 0.0677 

[TRAIN] Epoch[5](1309/1500); Loss: 0.084262; Backpropagation: 0.0991 sec; Batch: 0.4340 sec
0.2410 0.1871 0.1794 0.0972 0.0814 0.0615 0.0524 0.0669 0.0571 0.0461 0.0466 0.0457 0.0455 0.0459 0.0468 0.0477 

[TRAIN] Epoch[5](1310/1500); Loss: 0.072102; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.1647 0.1302 0.0956 0.0766 0.0703 0.0619 0.0591 0.0573 0.0567 0.0553 0.0547 0.0542 0.0542 0.0543 0.0542 0.0544 

[TRAIN] Epoch[5](1311/1500); Loss: 0.077854; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1175 0.1045 0.0919 0.0890 0.0804 0.0752 0.0734 0.0701 0.0686 0.0679 0.0679 0.0683 0.0677 0.0674 0.0677 0.0681 

[TRAIN] Epoch[5](1312/1500); Loss: 0.196942; Backpropagation: 0.0982 sec; Batch: 0.4319 sec
0.3957 0.3559 0.3457 0.2735 0.2589 0.2163 0.1960 0.1413 0.1268 0.1188 0.1175 0.1230 0.1212 0.1202 0.1202 0.1201 

[TRAIN] Epoch[5](1313/1500); Loss: 0.074266; Backpropagation: 0.0996 sec; Batch: 0.4346 sec
0.1528 0.1157 0.0924 0.0774 0.0759 0.0695 0.0652 0.0620 0.0603 0.0595 0.0592 0.0597 0.0593 0.0593 0.0597 0.0602 

[TRAIN] Epoch[5](1314/1500); Loss: 0.135154; Backpropagation: 0.0991 sec; Batch: 0.4331 sec
0.1780 0.1633 0.1485 0.1408 0.1366 0.1284 0.1269 0.1276 0.1269 0.1267 0.1266 0.1263 0.1263 0.1264 0.1265 0.1267 

[TRAIN] Epoch[5](1315/1500); Loss: 0.072600; Backpropagation: 0.1003 sec; Batch: 0.4346 sec
0.1942 0.1489 0.1007 0.0691 0.0600 0.0596 0.0575 0.0554 0.0538 0.0527 0.0519 0.0517 0.0516 0.0514 0.0514 0.0516 

[TRAIN] Epoch[5](1316/1500); Loss: 0.144462; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.2666 0.2295 0.2082 0.1688 0.1620 0.1366 0.1296 0.1213 0.1153 0.1107 0.1104 0.1109 0.1111 0.1104 0.1100 0.1100 

[TRAIN] Epoch[5](1317/1500); Loss: 0.097329; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1475 0.1351 0.1200 0.1020 0.0999 0.0903 0.0886 0.0881 0.0861 0.0853 0.0854 0.0855 0.0852 0.0855 0.0860 0.0870 

[TRAIN] Epoch[5](1318/1500); Loss: 0.145107; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.4044 0.3511 0.3323 0.2083 0.1845 0.1082 0.0795 0.1065 0.0924 0.0698 0.0664 0.0642 0.0639 0.0636 0.0634 0.0635 

[TRAIN] Epoch[5](1319/1500); Loss: 0.091670; Backpropagation: 0.1025 sec; Batch: 0.4372 sec
0.1331 0.1171 0.1097 0.1011 0.0973 0.0869 0.0837 0.0820 0.0817 0.0809 0.0807 0.0810 0.0816 0.0824 0.0833 0.0842 

[TRAIN] Epoch[5](1320/1500); Loss: 0.096398; Backpropagation: 0.0995 sec; Batch: 0.4346 sec
0.1904 0.1719 0.1441 0.1023 0.0873 0.0813 0.0797 0.0783 0.0783 0.0761 0.0753 0.0752 0.0752 0.0754 0.0756 0.0759 

[TRAIN] Epoch[5](1321/1500); Loss: 0.086436; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.1295 0.1127 0.1020 0.0928 0.0888 0.0829 0.0794 0.0784 0.0777 0.0772 0.0771 0.0769 0.0767 0.0768 0.0770 0.0771 

[TRAIN] Epoch[5](1322/1500); Loss: 0.098314; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1693 0.1368 0.1316 0.1171 0.1076 0.0881 0.0853 0.0858 0.0842 0.0806 0.0806 0.0807 0.0809 0.0811 0.0815 0.0819 

[TRAIN] Epoch[5](1323/1500); Loss: 0.075314; Backpropagation: 0.0990 sec; Batch: 0.4337 sec
0.1698 0.1267 0.1150 0.0800 0.0778 0.0678 0.0648 0.0612 0.0586 0.0570 0.0558 0.0549 0.0544 0.0540 0.0537 0.0535 

[TRAIN] Epoch[5](1324/1500); Loss: 0.175354; Backpropagation: 0.0995 sec; Batch: 0.4345 sec
0.1960 0.1988 0.1863 0.1965 0.1818 0.1719 0.1724 0.1712 0.1698 0.1678 0.1671 0.1662 0.1655 0.1648 0.1647 0.1646 

[TRAIN] Epoch[5](1325/1500); Loss: 0.107634; Backpropagation: 0.1025 sec; Batch: 0.4372 sec
0.1669 0.1549 0.1356 0.1150 0.1072 0.1009 0.0972 0.0968 0.0946 0.0938 0.0933 0.0931 0.0931 0.0931 0.0932 0.0933 

[TRAIN] Epoch[5](1326/1500); Loss: 0.059971; Backpropagation: 0.1024 sec; Batch: 0.4369 sec
0.1270 0.0913 0.0761 0.0757 0.0723 0.0535 0.0478 0.0476 0.0467 0.0464 0.0454 0.0451 0.0454 0.0459 0.0466 0.0468 

[TRAIN] Epoch[5](1327/1500); Loss: 0.149818; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.2379 0.2205 0.2062 0.1733 0.1611 0.1444 0.1382 0.1317 0.1267 0.1233 0.1227 0.1225 0.1225 0.1222 0.1220 0.1220 

[TRAIN] Epoch[5](1328/1500); Loss: 0.112444; Backpropagation: 0.0982 sec; Batch: 0.4325 sec
0.1814 0.1584 0.1449 0.1120 0.1052 0.1000 0.1008 0.1013 0.0999 0.0995 0.0993 0.0988 0.0989 0.0994 0.0996 0.0999 

[TRAIN] Epoch[5](1329/1500); Loss: 0.091643; Backpropagation: 0.0983 sec; Batch: 0.4325 sec
0.2003 0.1650 0.1481 0.0993 0.0927 0.0770 0.0737 0.0714 0.0696 0.0674 0.0672 0.0668 0.0668 0.0669 0.0670 0.0671 

[TRAIN] Epoch[5](1330/1500); Loss: 0.129950; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.2930 0.2639 0.2284 0.1622 0.1379 0.1149 0.1013 0.0876 0.0908 0.0856 0.0850 0.0852 0.0854 0.0856 0.0860 0.0865 

[TRAIN] Epoch[5](1331/1500); Loss: 0.117244; Backpropagation: 0.0993 sec; Batch: 0.4345 sec
0.2418 0.2069 0.1871 0.1240 0.1144 0.1061 0.0979 0.0921 0.0905 0.0882 0.0880 0.0878 0.0877 0.0877 0.0878 0.0880 

[TRAIN] Epoch[5](1332/1500); Loss: 0.072821; Backpropagation: 0.0991 sec; Batch: 0.4335 sec
0.1777 0.1389 0.1301 0.0793 0.0724 0.0540 0.0548 0.0578 0.0521 0.0500 0.0499 0.0496 0.0496 0.0495 0.0496 0.0498 

[TRAIN] Epoch[5](1333/1500); Loss: 0.189453; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.2655 0.2487 0.2381 0.2155 0.2043 0.1769 0.1749 0.1733 0.1708 0.1697 0.1680 0.1667 0.1658 0.1650 0.1644 0.1637 

[TRAIN] Epoch[5](1334/1500); Loss: 0.121287; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.2317 0.1933 0.1700 0.1409 0.1338 0.1191 0.1131 0.0998 0.0964 0.0942 0.0932 0.0933 0.0914 0.0905 0.0902 0.0897 

[TRAIN] Epoch[5](1335/1500); Loss: 0.113909; Backpropagation: 0.0983 sec; Batch: 0.4325 sec
0.1677 0.1427 0.1236 0.1162 0.1129 0.1092 0.1079 0.1068 0.1060 0.1054 0.1047 0.1044 0.1041 0.1038 0.1036 0.1036 

[TRAIN] Epoch[5](1336/1500); Loss: 0.079888; Backpropagation: 0.1024 sec; Batch: 0.4378 sec
0.1505 0.1158 0.0947 0.0807 0.0825 0.0714 0.0705 0.0697 0.0688 0.0683 0.0677 0.0675 0.0674 0.0675 0.0676 0.0677 

[TRAIN] Epoch[5](1337/1500); Loss: 0.076786; Backpropagation: 0.1028 sec; Batch: 0.4379 sec
0.1487 0.1192 0.1008 0.0917 0.0855 0.0629 0.0623 0.0654 0.0618 0.0606 0.0611 0.0613 0.0616 0.0618 0.0619 0.0620 

[TRAIN] Epoch[5](1338/1500); Loss: 0.062522; Backpropagation: 0.0988 sec; Batch: 0.4334 sec
0.1258 0.0950 0.0797 0.0665 0.0645 0.0558 0.0517 0.0514 0.0510 0.0507 0.0506 0.0507 0.0509 0.0514 0.0520 0.0526 

[TRAIN] Epoch[5](1339/1500); Loss: 0.064415; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2346 0.1537 0.0699 0.0569 0.0412 0.0420 0.0456 0.0444 0.0421 0.0418 0.0413 0.0411 0.0415 0.0445 0.0444 0.0457 

[TRAIN] Epoch[5](1340/1500); Loss: 0.136527; Backpropagation: 0.0983 sec; Batch: 0.4323 sec
0.2023 0.1841 0.1633 0.1436 0.1377 0.1294 0.1264 0.1266 0.1243 0.1217 0.1214 0.1208 0.1208 0.1208 0.1206 0.1207 

[TRAIN] Epoch[5](1341/1500); Loss: 0.053954; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.0610 0.0671 0.0553 0.0592 0.0566 0.0522 0.0511 0.0508 0.0506 0.0507 0.0506 0.0509 0.0513 0.0515 0.0520 0.0525 

[TRAIN] Epoch[5](1342/1500); Loss: 0.121458; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.2304 0.2010 0.1856 0.1333 0.1210 0.1060 0.1018 0.1045 0.0976 0.0951 0.0943 0.0942 0.0945 0.0947 0.0947 0.0948 

[TRAIN] Epoch[5](1343/1500); Loss: 0.092665; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.1539 0.1257 0.1190 0.0985 0.0962 0.0867 0.0840 0.0831 0.0811 0.0798 0.0793 0.0791 0.0791 0.0790 0.0791 0.0790 

[TRAIN] Epoch[5](1344/1500); Loss: 0.094172; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.2645 0.2024 0.1227 0.0769 0.0710 0.0713 0.0745 0.0756 0.0711 0.0698 0.0686 0.0675 0.0672 0.0674 0.0682 0.0681 

[TRAIN] Epoch[5](1345/1500); Loss: 0.077420; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1460 0.1229 0.0908 0.0800 0.0759 0.0696 0.0674 0.0669 0.0652 0.0643 0.0645 0.0647 0.0647 0.0650 0.0652 0.0655 

[TRAIN] Epoch[5](1346/1500); Loss: 0.054400; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1497 0.0978 0.0904 0.0477 0.0552 0.0441 0.0418 0.0387 0.0382 0.0380 0.0378 0.0378 0.0380 0.0381 0.0382 0.0390 

[TRAIN] Epoch[5](1347/1500); Loss: 0.144953; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2859 0.2383 0.2246 0.1451 0.1347 0.1191 0.1180 0.1245 0.1190 0.1154 0.1154 0.1152 0.1156 0.1160 0.1161 0.1164 

[TRAIN] Epoch[5](1348/1500); Loss: 0.073109; Backpropagation: 0.1027 sec; Batch: 0.4372 sec
0.0903 0.1058 0.0768 0.0797 0.0759 0.0682 0.0668 0.0669 0.0671 0.0667 0.0666 0.0668 0.0672 0.0677 0.0683 0.0690 

[TRAIN] Epoch[5](1349/1500); Loss: 0.086663; Backpropagation: 0.1023 sec; Batch: 0.4386 sec
0.1655 0.1429 0.1153 0.0999 0.0871 0.0784 0.0732 0.0718 0.0703 0.0698 0.0693 0.0690 0.0688 0.0685 0.0684 0.0685 

[TRAIN] Epoch[5](1350/1500); Loss: 0.083477; Backpropagation: 0.0987 sec; Batch: 0.4332 sec
0.1934 0.1667 0.1472 0.1048 0.0918 0.0682 0.0595 0.0619 0.0620 0.0542 0.0545 0.0540 0.0538 0.0541 0.0546 0.0551 

[TRAIN] Epoch[5](1351/1500); Loss: 0.117753; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.2894 0.2477 0.2371 0.1495 0.1343 0.0879 0.0708 0.1026 0.0864 0.0707 0.0692 0.0681 0.0678 0.0677 0.0674 0.0673 

[TRAIN] Epoch[5](1352/1500); Loss: 0.129306; Backpropagation: 0.0982 sec; Batch: 0.4325 sec
0.2415 0.2062 0.1784 0.1223 0.1181 0.1183 0.1121 0.1100 0.1088 0.1077 0.1074 0.1073 0.1073 0.1076 0.1079 0.1081 

[TRAIN] Epoch[5](1353/1500); Loss: 0.066470; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2699 0.1820 0.0806 0.0558 0.0347 0.0387 0.0379 0.0373 0.0380 0.0382 0.0377 0.0401 0.0456 0.0420 0.0421 0.0430 

[TRAIN] Epoch[5](1354/1500); Loss: 0.085448; Backpropagation: 0.0997 sec; Batch: 0.4350 sec
0.1535 0.1363 0.1183 0.0973 0.0900 0.0797 0.0747 0.0705 0.0680 0.0678 0.0677 0.0679 0.0684 0.0686 0.0690 0.0694 

[TRAIN] Epoch[5](1355/1500); Loss: 0.074674; Backpropagation: 0.0990 sec; Batch: 0.4724 sec
0.1262 0.1077 0.0885 0.0765 0.0747 0.0680 0.0668 0.0655 0.0645 0.0648 0.0653 0.0652 0.0653 0.0654 0.0652 0.0653 

[TRAIN] Epoch[5](1356/1500); Loss: 0.099397; Backpropagation: 0.0991 sec; Batch: 0.4331 sec
0.2250 0.1784 0.1234 0.0906 0.0860 0.0874 0.0834 0.0806 0.0797 0.0792 0.0789 0.0793 0.0795 0.0795 0.0795 0.0799 

[TRAIN] Epoch[5](1357/1500); Loss: 0.124813; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.2885 0.2490 0.2319 0.1494 0.1293 0.0917 0.0859 0.1108 0.0966 0.0790 0.0811 0.0806 0.0806 0.0806 0.0810 0.0811 

[TRAIN] Epoch[5](1358/1500); Loss: 0.062935; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1156 0.1007 0.0713 0.0688 0.0598 0.0557 0.0554 0.0547 0.0536 0.0531 0.0528 0.0530 0.0527 0.0529 0.0533 0.0535 

[TRAIN] Epoch[5](1359/1500); Loss: 0.087505; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.1495 0.1222 0.1136 0.0990 0.0971 0.0848 0.0802 0.0783 0.0767 0.0751 0.0733 0.0717 0.0706 0.0698 0.0693 0.0688 

[TRAIN] Epoch[5](1360/1500); Loss: 0.119528; Backpropagation: 0.0984 sec; Batch: 0.4322 sec
0.1646 0.1541 0.1380 0.1309 0.1253 0.1141 0.1116 0.1095 0.1094 0.1077 0.1074 0.1075 0.1077 0.1080 0.1082 0.1084 

[TRAIN] Epoch[5](1361/1500); Loss: 0.130933; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.1469 0.1497 0.1429 0.1388 0.1347 0.1292 0.1279 0.1257 0.1251 0.1244 0.1243 0.1251 0.1246 0.1246 0.1251 0.1260 

[TRAIN] Epoch[5](1362/1500); Loss: 0.071540; Backpropagation: 0.0970 sec; Batch: 0.4318 sec
0.1199 0.0908 0.0790 0.0889 0.0842 0.0649 0.0635 0.0624 0.0619 0.0619 0.0618 0.0614 0.0612 0.0611 0.0609 0.0608 

[TRAIN] Epoch[5](1363/1500); Loss: 0.150388; Backpropagation: 0.0971 sec; Batch: 0.4315 sec
0.2671 0.2392 0.2311 0.1898 0.1809 0.1517 0.1391 0.1182 0.1157 0.1125 0.1098 0.1103 0.1104 0.1102 0.1100 0.1102 

[TRAIN] Epoch[5](1364/1500); Loss: 0.097688; Backpropagation: 0.0969 sec; Batch: 0.4312 sec
0.1359 0.1214 0.1143 0.1106 0.1077 0.0940 0.0903 0.0873 0.0870 0.0865 0.0863 0.0867 0.0876 0.0883 0.0891 0.0900 

[TRAIN] Epoch[5](1365/1500); Loss: 0.091884; Backpropagation: 0.0997 sec; Batch: 0.4347 sec
0.1576 0.1298 0.1189 0.1126 0.1005 0.0852 0.0821 0.0805 0.0785 0.0770 0.0752 0.0745 0.0743 0.0742 0.0742 0.0748 

[TRAIN] Epoch[5](1366/1500); Loss: 0.074279; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.2440 0.1877 0.1804 0.1007 0.0882 0.0508 0.0383 0.0482 0.0454 0.0302 0.0284 0.0288 0.0283 0.0288 0.0298 0.0304 

[TRAIN] Epoch[5](1367/1500); Loss: 0.127657; Backpropagation: 0.0988 sec; Batch: 0.4328 sec
0.2477 0.2177 0.1991 0.1565 0.1473 0.1213 0.1077 0.1020 0.1048 0.0926 0.0910 0.0910 0.0910 0.0909 0.0911 0.0911 

[TRAIN] Epoch[5](1368/1500); Loss: 0.153667; Backpropagation: 0.0983 sec; Batch: 0.4742 sec
0.2147 0.2023 0.1968 0.1759 0.1686 0.1521 0.1455 0.1365 0.1374 0.1342 0.1331 0.1332 0.1326 0.1320 0.1318 0.1319 

[TRAIN] Epoch[5](1369/1500); Loss: 0.117709; Backpropagation: 0.0994 sec; Batch: 0.4337 sec
0.1837 0.1573 0.1432 0.1329 0.1255 0.1050 0.1036 0.1071 0.1031 0.1023 0.1025 0.1028 0.1032 0.1035 0.1037 0.1039 

[TRAIN] Epoch[5](1370/1500); Loss: 0.153964; Backpropagation: 0.0993 sec; Batch: 0.4359 sec
0.4455 0.3733 0.3563 0.2165 0.1954 0.1252 0.0891 0.0955 0.1042 0.0690 0.0666 0.0656 0.0658 0.0653 0.0651 0.0649 

[TRAIN] Epoch[5](1371/1500); Loss: 0.096451; Backpropagation: 0.1022 sec; Batch: 0.4378 sec
0.2170 0.1584 0.1188 0.1026 0.0954 0.0781 0.0790 0.0797 0.0800 0.0761 0.0758 0.0756 0.0761 0.0764 0.0768 0.0774 

[TRAIN] Epoch[5](1372/1500); Loss: 0.138471; Backpropagation: 0.0994 sec; Batch: 0.4343 sec
0.2789 0.2343 0.2231 0.1537 0.1447 0.1264 0.1127 0.1119 0.1127 0.1037 0.1030 0.1027 0.1023 0.1021 0.1017 0.1016 

[TRAIN] Epoch[5](1373/1500); Loss: 0.075131; Backpropagation: 0.0983 sec; Batch: 0.4335 sec
0.1356 0.1125 0.1058 0.0790 0.0782 0.0675 0.0664 0.0648 0.0635 0.0615 0.0612 0.0612 0.0612 0.0610 0.0610 0.0616 

[TRAIN] Epoch[5](1374/1500); Loss: 0.136910; Backpropagation: 0.0983 sec; Batch: 0.4325 sec
0.2234 0.1983 0.1855 0.1609 0.1538 0.1271 0.1230 0.1192 0.1175 0.1132 0.1120 0.1113 0.1114 0.1116 0.1112 0.1112 

[TRAIN] Epoch[5](1375/1500); Loss: 0.072458; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.1803 0.1355 0.1292 0.0817 0.0746 0.0548 0.0604 0.0503 0.0501 0.0486 0.0485 0.0483 0.0484 0.0489 0.0496 0.0501 

[TRAIN] Epoch[5](1376/1500); Loss: 0.067248; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1869 0.1223 0.0649 0.0604 0.0565 0.0558 0.0537 0.0523 0.0524 0.0524 0.0525 0.0522 0.0525 0.0528 0.0541 0.0544 

[TRAIN] Epoch[5](1377/1500); Loss: 0.112853; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.3499 0.2827 0.2709 0.1385 0.1061 0.0598 0.0603 0.0945 0.0727 0.0495 0.0519 0.0526 0.0521 0.0531 0.0547 0.0565 

[TRAIN] Epoch[5](1378/1500); Loss: 0.152809; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.2638 0.2355 0.2275 0.1929 0.1822 0.1499 0.1407 0.1228 0.1235 0.1178 0.1156 0.1152 0.1150 0.1145 0.1141 0.1139 

[TRAIN] Epoch[5](1379/1500); Loss: 0.108008; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1495 0.1343 0.1252 0.1311 0.1236 0.0992 0.0996 0.0997 0.0978 0.0956 0.0955 0.0959 0.0958 0.0953 0.0952 0.0948 

[TRAIN] Epoch[5](1380/1500); Loss: 0.095067; Backpropagation: 0.0990 sec; Batch: 0.4339 sec
0.1794 0.1359 0.1087 0.1007 0.0948 0.0840 0.0821 0.0824 0.0827 0.0824 0.0817 0.0813 0.0812 0.0805 0.0812 0.0820 

[TRAIN] Epoch[5](1381/1500); Loss: 0.156713; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1992 0.1725 0.1692 0.1746 0.1730 0.1514 0.1519 0.1499 0.1480 0.1462 0.1454 0.1453 0.1452 0.1451 0.1451 0.1453 

[TRAIN] Epoch[5](1382/1500); Loss: 0.097993; Backpropagation: 0.0990 sec; Batch: 0.4339 sec
0.2340 0.1764 0.1310 0.1043 0.0994 0.0869 0.0810 0.0753 0.0770 0.0722 0.0720 0.0718 0.0717 0.0715 0.0716 0.0719 

[TRAIN] Epoch[5](1383/1500); Loss: 0.140956; Backpropagation: 0.0985 sec; Batch: 0.4702 sec
0.2720 0.2312 0.2202 0.1725 0.1624 0.1267 0.1193 0.1140 0.1168 0.1036 0.1040 0.1034 0.1028 0.1024 0.1022 0.1017 

[TRAIN] Epoch[5](1384/1500); Loss: 0.142974; Backpropagation: 0.0992 sec; Batch: 0.4352 sec
0.3267 0.2744 0.2606 0.1793 0.1576 0.0975 0.0959 0.1292 0.1132 0.0929 0.0936 0.0931 0.0929 0.0935 0.0936 0.0936 

[TRAIN] Epoch[5](1385/1500); Loss: 0.149208; Backpropagation: 0.0990 sec; Batch: 0.4348 sec
0.2445 0.2130 0.2008 0.1696 0.1635 0.1451 0.1385 0.1327 0.1286 0.1236 0.1225 0.1220 0.1214 0.1208 0.1204 0.1202 

[TRAIN] Epoch[5](1386/1500); Loss: 0.081092; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1775 0.1366 0.1150 0.0833 0.0785 0.0674 0.0666 0.0688 0.0629 0.0616 0.0622 0.0624 0.0628 0.0634 0.0637 0.0648 

[TRAIN] Epoch[5](1387/1500); Loss: 0.144916; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.2604 0.2208 0.2092 0.1657 0.1588 0.1282 0.1242 0.1291 0.1256 0.1142 0.1143 0.1146 0.1143 0.1139 0.1131 0.1124 

[TRAIN] Epoch[5](1388/1500); Loss: 0.087794; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1794 0.1366 0.1276 0.0807 0.0752 0.0812 0.0734 0.0719 0.0702 0.0701 0.0709 0.0716 0.0724 0.0732 0.0744 0.0760 

[TRAIN] Epoch[5](1389/1500); Loss: 0.158272; Backpropagation: 0.0994 sec; Batch: 0.4351 sec
0.1755 0.1727 0.1672 0.1878 0.1734 0.1493 0.1509 0.1511 0.1511 0.1510 0.1512 0.1510 0.1506 0.1499 0.1499 0.1499 

[TRAIN] Epoch[5](1390/1500); Loss: 0.117171; Backpropagation: 0.0993 sec; Batch: 0.4351 sec
0.2353 0.1876 0.1688 0.1050 0.1057 0.1071 0.1012 0.0981 0.0966 0.0957 0.0957 0.0955 0.0951 0.0954 0.0957 0.0962 

[TRAIN] Epoch[5](1391/1500); Loss: 0.081743; Backpropagation: 0.0994 sec; Batch: 0.4348 sec
0.1634 0.1266 0.1164 0.0986 0.0929 0.0793 0.0731 0.0651 0.0627 0.0616 0.0612 0.0609 0.0610 0.0614 0.0617 0.0620 

[TRAIN] Epoch[5](1392/1500); Loss: 0.157419; Backpropagation: 0.0984 sec; Batch: 0.4343 sec
0.1915 0.1788 0.1746 0.1684 0.1602 0.1520 0.1522 0.1507 0.1495 0.1488 0.1487 0.1489 0.1487 0.1485 0.1486 0.1485 

[TRAIN] Epoch[5](1393/1500); Loss: 0.143091; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.3152 0.2666 0.2531 0.1843 0.1717 0.1169 0.1031 0.1222 0.1165 0.0946 0.0916 0.0912 0.0908 0.0908 0.0904 0.0903 

[TRAIN] Epoch[5](1394/1500); Loss: 0.110965; Backpropagation: 0.1024 sec; Batch: 0.4387 sec
0.2198 0.1836 0.1577 0.1277 0.1211 0.1069 0.1009 0.0894 0.0882 0.0856 0.0827 0.0827 0.0824 0.0821 0.0824 0.0822 

[TRAIN] Epoch[5](1395/1500); Loss: 0.062632; Backpropagation: 0.1013 sec; Batch: 0.4382 sec
0.1269 0.0831 0.0686 0.0645 0.0547 0.0529 0.0583 0.0574 0.0554 0.0549 0.0539 0.0533 0.0526 0.0533 0.0560 0.0565 

[TRAIN] Epoch[5](1396/1500); Loss: 0.108845; Backpropagation: 0.0994 sec; Batch: 0.4349 sec
0.2505 0.2188 0.2036 0.1386 0.1285 0.0855 0.0760 0.0695 0.0730 0.0702 0.0661 0.0674 0.0696 0.0718 0.0746 0.0777 

[TRAIN] Epoch[5](1397/1500); Loss: 0.079713; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2418 0.1403 0.0631 0.0623 0.0679 0.0647 0.0669 0.0639 0.0621 0.0627 0.0631 0.0630 0.0627 0.0623 0.0635 0.0651 

[TRAIN] Epoch[5](1398/1500); Loss: 0.153390; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.2966 0.2537 0.2455 0.1957 0.1858 0.1538 0.1439 0.1193 0.1133 0.1090 0.1061 0.1071 0.1066 0.1059 0.1060 0.1060 

[TRAIN] Epoch[5](1399/1500); Loss: 0.117431; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1551 0.1425 0.1295 0.1236 0.1191 0.1122 0.1112 0.1103 0.1099 0.1085 0.1084 0.1083 0.1088 0.1095 0.1104 0.1116 

[TRAIN] Epoch[5](1400/1500); Loss: 0.115870; Backpropagation: 0.1021 sec; Batch: 0.4368 sec
0.1703 0.1435 0.1296 0.1204 0.1170 0.1098 0.1039 0.1027 0.1026 0.1040 0.1052 0.1061 0.1073 0.1087 0.1104 0.1124 

[TRAIN] Epoch[5](1401/1500); Loss: 0.157987; Backpropagation: 0.1025 sec; Batch: 0.4374 sec
0.1579 0.1466 0.1496 0.1490 0.1488 0.1518 0.1525 0.1584 0.1578 0.1577 0.1603 0.1614 0.1645 0.1675 0.1703 0.1736 

[TRAIN] Epoch[5](1402/1500); Loss: 0.091237; Backpropagation: 0.0936 sec; Batch: 0.4292 sec
0.2841 0.2139 0.1521 0.0861 0.0801 0.0673 0.0593 0.0623 0.0618 0.0568 0.0564 0.0559 0.0559 0.0559 0.0558 0.0561 

[TRAIN] Epoch[5](1403/1500); Loss: 0.123611; Backpropagation: 0.0939 sec; Batch: 0.4418 sec
0.1843 0.1718 0.1462 0.1295 0.1251 0.1188 0.1161 0.1129 0.1111 0.1098 0.1092 0.1089 0.1091 0.1085 0.1082 0.1082 

[TRAIN] Epoch[5](1404/1500); Loss: 0.127621; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1855 0.1572 0.1474 0.1312 0.1276 0.1213 0.1184 0.1175 0.1171 0.1164 0.1159 0.1161 0.1166 0.1172 0.1178 0.1186 

[TRAIN] Epoch[5](1405/1500); Loss: 0.102363; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1558 0.1346 0.1265 0.1077 0.1026 0.0946 0.0921 0.0913 0.0917 0.0915 0.0915 0.0914 0.0915 0.0917 0.0917 0.0918 

[TRAIN] Epoch[5](1406/1500); Loss: 0.077477; Backpropagation: 0.0957 sec; Batch: 0.4578 sec
0.2220 0.1620 0.1496 0.0706 0.0608 0.0609 0.0645 0.0573 0.0502 0.0495 0.0486 0.0481 0.0479 0.0483 0.0497 0.0495 

[TRAIN] Epoch[5](1407/1500); Loss: 0.101991; Backpropagation: 0.0960 sec; Batch: 0.4305 sec
0.1392 0.1387 0.1212 0.1119 0.1094 0.0954 0.0944 0.0950 0.0932 0.0905 0.0906 0.0906 0.0905 0.0905 0.0904 0.0905 

[TRAIN] Epoch[5](1408/1500); Loss: 0.082518; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1043 0.0989 0.0892 0.0860 0.0837 0.0807 0.0783 0.0776 0.0771 0.0769 0.0768 0.0770 0.0774 0.0779 0.0787 0.0797 

[TRAIN] Epoch[5](1409/1500); Loss: 0.219748; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.4558 0.3845 0.3681 0.2634 0.2462 0.1985 0.1799 0.1724 0.1734 0.1561 0.1533 0.1531 0.1527 0.1527 0.1528 0.1531 

[TRAIN] Epoch[5](1410/1500); Loss: 0.121436; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1664 0.1467 0.1319 0.1267 0.1225 0.1180 0.1147 0.1137 0.1132 0.1127 0.1122 0.1125 0.1125 0.1124 0.1132 0.1137 

[TRAIN] Epoch[5](1411/1500); Loss: 0.064513; Backpropagation: 0.0946 sec; Batch: 0.4286 sec
0.0841 0.0971 0.0735 0.0768 0.0715 0.0633 0.0589 0.0571 0.0569 0.0561 0.0564 0.0564 0.0560 0.0555 0.0559 0.0565 

[TRAIN] Epoch[5](1412/1500); Loss: 0.226372; Backpropagation: 0.0959 sec; Batch: 0.4299 sec
0.4387 0.3748 0.3603 0.2681 0.2519 0.2071 0.1895 0.1827 0.1847 0.1675 0.1665 0.1664 0.1662 0.1660 0.1657 0.1660 

[TRAIN] Epoch[5](1413/1500); Loss: 0.123814; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.3010 0.2505 0.2393 0.1483 0.1322 0.1088 0.0927 0.0913 0.0911 0.0772 0.0765 0.0756 0.0748 0.0744 0.0739 0.0735 

[TRAIN] Epoch[5](1414/1500); Loss: 0.066468; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.0946 0.1022 0.0673 0.0692 0.0684 0.0626 0.0611 0.0606 0.0601 0.0599 0.0597 0.0597 0.0595 0.0597 0.0594 0.0595 

[TRAIN] Epoch[5](1415/1500); Loss: 0.160987; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.2925 0.2464 0.2299 0.1640 0.1564 0.1410 0.1355 0.1336 0.1340 0.1340 0.1336 0.1335 0.1341 0.1350 0.1359 0.1365 

[TRAIN] Epoch[5](1416/1500); Loss: 0.094768; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1797 0.1869 0.1260 0.0909 0.0888 0.0838 0.0822 0.0786 0.0772 0.0765 0.0758 0.0747 0.0743 0.0739 0.0736 0.0734 

[TRAIN] Epoch[5](1417/1500); Loss: 0.093771; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1314 0.1158 0.1077 0.0994 0.0982 0.0951 0.0918 0.0893 0.0877 0.0853 0.0833 0.0827 0.0825 0.0828 0.0833 0.0839 

[TRAIN] Epoch[5](1418/1500); Loss: 0.127103; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.2195 0.2215 0.1902 0.1540 0.1407 0.1240 0.1150 0.1008 0.1014 0.0973 0.0954 0.0951 0.0948 0.0948 0.0945 0.0945 

[TRAIN] Epoch[5](1419/1500); Loss: 0.108519; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2129 0.1726 0.1632 0.1182 0.1105 0.0923 0.0898 0.0944 0.0908 0.0865 0.0857 0.0845 0.0842 0.0838 0.0836 0.0833 

[TRAIN] Epoch[5](1420/1500); Loss: 0.086965; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1746 0.1327 0.1243 0.0849 0.0796 0.0793 0.0779 0.0720 0.0703 0.0696 0.0694 0.0698 0.0704 0.0711 0.0722 0.0732 

[TRAIN] Epoch[5](1421/1500); Loss: 0.095792; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2017 0.1551 0.1486 0.1086 0.1011 0.0761 0.0746 0.0897 0.0842 0.0707 0.0710 0.0709 0.0704 0.0701 0.0698 0.0700 

[TRAIN] Epoch[5](1422/1500); Loss: 0.079942; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1455 0.1652 0.1226 0.0862 0.0786 0.0708 0.0673 0.0670 0.0643 0.0613 0.0597 0.0588 0.0580 0.0581 0.0578 0.0578 

[TRAIN] Epoch[5](1423/1500); Loss: 0.129422; Backpropagation: 0.0938 sec; Batch: 0.4290 sec
0.1711 0.1731 0.1501 0.1352 0.1288 0.1239 0.1218 0.1215 0.1205 0.1184 0.1180 0.1179 0.1176 0.1176 0.1176 0.1176 

[TRAIN] Epoch[5](1424/1500); Loss: 0.082862; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1545 0.1139 0.1073 0.0769 0.0778 0.0769 0.0770 0.0747 0.0729 0.0710 0.0703 0.0706 0.0705 0.0704 0.0704 0.0708 

[TRAIN] Epoch[5](1425/1500); Loss: 0.108657; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1764 0.1990 0.1521 0.1214 0.1015 0.0942 0.0931 0.0905 0.0888 0.0884 0.0884 0.0884 0.0887 0.0890 0.0891 0.0895 

[TRAIN] Epoch[5](1426/1500); Loss: 0.137169; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.2361 0.2045 0.1898 0.1378 0.1295 0.1276 0.1228 0.1211 0.1183 0.1163 0.1157 0.1150 0.1148 0.1151 0.1151 0.1151 

[TRAIN] Epoch[5](1427/1500); Loss: 0.099904; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.2093 0.1667 0.1597 0.1073 0.1026 0.0881 0.0790 0.0803 0.0843 0.0751 0.0748 0.0742 0.0741 0.0741 0.0743 0.0746 

[TRAIN] Epoch[5](1428/1500); Loss: 0.124161; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1610 0.1643 0.1464 0.1376 0.1276 0.1194 0.1180 0.1148 0.1128 0.1122 0.1121 0.1121 0.1120 0.1119 0.1121 0.1122 

[TRAIN] Epoch[5](1429/1500); Loss: 0.141475; Backpropagation: 0.0941 sec; Batch: 0.4293 sec
0.2340 0.2073 0.1939 0.1516 0.1437 0.1346 0.1277 0.1213 0.1202 0.1196 0.1192 0.1184 0.1180 0.1179 0.1179 0.1182 

[TRAIN] Epoch[5](1430/1500); Loss: 0.077825; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.1548 0.1931 0.1330 0.0841 0.0689 0.0650 0.0602 0.0559 0.0545 0.0541 0.0540 0.0538 0.0533 0.0532 0.0536 0.0538 

[TRAIN] Epoch[5](1431/1500); Loss: 0.104543; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1917 0.2475 0.1572 0.0932 0.0869 0.0837 0.0820 0.0803 0.0800 0.0801 0.0801 0.0805 0.0813 0.0818 0.0827 0.0837 

[TRAIN] Epoch[5](1432/1500); Loss: 0.062741; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.0600 0.0879 0.0704 0.0735 0.0650 0.0606 0.0596 0.0591 0.0589 0.0585 0.0584 0.0584 0.0581 0.0583 0.0585 0.0587 

[TRAIN] Epoch[5](1433/1500); Loss: 0.086632; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2425 0.1797 0.1687 0.0865 0.0774 0.0617 0.0580 0.0623 0.0597 0.0552 0.0555 0.0556 0.0556 0.0555 0.0560 0.0563 

[TRAIN] Epoch[5](1434/1500); Loss: 0.114359; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1888 0.1908 0.1633 0.1239 0.1142 0.1025 0.0975 0.1021 0.0987 0.0923 0.0924 0.0922 0.0924 0.0927 0.0929 0.0931 

[TRAIN] Epoch[5](1435/1500); Loss: 0.078286; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1276 0.1122 0.1027 0.0862 0.0789 0.0737 0.0702 0.0684 0.0678 0.0673 0.0665 0.0663 0.0662 0.0661 0.0662 0.0664 

[TRAIN] Epoch[5](1436/1500); Loss: 0.173123; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2658 0.2676 0.2372 0.1963 0.1885 0.1756 0.1681 0.1508 0.1449 0.1410 0.1390 0.1393 0.1389 0.1387 0.1387 0.1394 

[TRAIN] Epoch[5](1437/1500); Loss: 0.147821; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2908 0.2437 0.2337 0.1627 0.1509 0.1344 0.1254 0.1210 0.1231 0.1123 0.1116 0.1115 0.1112 0.1110 0.1109 0.1110 

[TRAIN] Epoch[5](1438/1500); Loss: 0.101713; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1229 0.1129 0.1096 0.1126 0.1070 0.0994 0.0985 0.0975 0.0966 0.0962 0.0959 0.0957 0.0956 0.0956 0.0957 0.0957 

[TRAIN] Epoch[5](1439/1500); Loss: 0.067592; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.0890 0.1021 0.0803 0.0776 0.0715 0.0642 0.0622 0.0611 0.0603 0.0595 0.0591 0.0589 0.0588 0.0588 0.0590 0.0593 

[TRAIN] Epoch[5](1440/1500); Loss: 0.102181; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1396 0.1587 0.1243 0.1062 0.1007 0.0951 0.0936 0.0922 0.0910 0.0906 0.0903 0.0904 0.0905 0.0905 0.0905 0.0906 

[TRAIN] Epoch[5](1441/1500); Loss: 0.135919; Backpropagation: 0.0958 sec; Batch: 0.4300 sec
0.2257 0.2306 0.1934 0.1506 0.1401 0.1263 0.1192 0.1149 0.1121 0.1092 0.1089 0.1085 0.1086 0.1087 0.1088 0.1089 

[TRAIN] Epoch[5](1442/1500); Loss: 0.117028; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1765 0.1504 0.1436 0.1190 0.1164 0.1122 0.1099 0.1075 0.1066 0.1060 0.1053 0.1047 0.1041 0.1037 0.1033 0.1031 

[TRAIN] Epoch[5](1443/1500); Loss: 0.082196; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1582 0.1946 0.1391 0.0953 0.0704 0.0656 0.0634 0.0619 0.0601 0.0591 0.0585 0.0582 0.0578 0.0577 0.0577 0.0578 

[TRAIN] Epoch[5](1444/1500); Loss: 0.125149; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.3088 0.2762 0.2570 0.1746 0.1542 0.1148 0.0989 0.0780 0.0836 0.0687 0.0649 0.0649 0.0646 0.0643 0.0644 0.0646 

[TRAIN] Epoch[5](1445/1500); Loss: 0.136031; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2542 0.2198 0.2133 0.1603 0.1485 0.1260 0.1183 0.1096 0.1051 0.1053 0.1034 0.1028 0.1024 0.1023 0.1025 0.1026 

[TRAIN] Epoch[5](1446/1500); Loss: 0.074638; Backpropagation: 0.0931 sec; Batch: 0.4276 sec
0.0934 0.1113 0.0845 0.0866 0.0768 0.0706 0.0696 0.0681 0.0671 0.0663 0.0661 0.0662 0.0664 0.0667 0.0671 0.0676 

[TRAIN] Epoch[5](1447/1500); Loss: 0.076852; Backpropagation: 0.0958 sec; Batch: 0.4404 sec
0.1210 0.1039 0.0970 0.1067 0.0938 0.0740 0.0705 0.0652 0.0635 0.0620 0.0618 0.0616 0.0616 0.0619 0.0622 0.0629 

[TRAIN] Epoch[5](1448/1500); Loss: 0.131856; Backpropagation: 0.0958 sec; Batch: 0.4302 sec
0.2439 0.2162 0.1997 0.1517 0.1404 0.1243 0.1167 0.1061 0.1072 0.1025 0.1010 0.1005 0.1004 0.1000 0.0995 0.0995 

[TRAIN] Epoch[5](1449/1500); Loss: 0.075047; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1031 0.1040 0.0878 0.0770 0.0734 0.0693 0.0685 0.0674 0.0671 0.0672 0.0675 0.0681 0.0687 0.0696 0.0705 0.0715 

[TRAIN] Epoch[5](1450/1500); Loss: 0.114698; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1991 0.1915 0.1666 0.1307 0.1096 0.1024 0.0983 0.0958 0.0939 0.0930 0.0926 0.0924 0.0923 0.0923 0.0922 0.0924 

[TRAIN] Epoch[5](1451/1500); Loss: 0.092208; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1790 0.1574 0.1372 0.0918 0.0867 0.0791 0.0779 0.0762 0.0747 0.0738 0.0735 0.0734 0.0735 0.0736 0.0737 0.0739 

[TRAIN] Epoch[5](1452/1500); Loss: 0.162573; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.2440 0.2288 0.2136 0.1741 0.1650 0.1518 0.1484 0.1486 0.1462 0.1408 0.1399 0.1400 0.1398 0.1400 0.1401 0.1400 

[TRAIN] Epoch[5](1453/1500); Loss: 0.102589; Backpropagation: 0.0943 sec; Batch: 0.4282 sec
0.2346 0.2148 0.1874 0.1174 0.0961 0.0675 0.0638 0.0889 0.0817 0.0685 0.0688 0.0694 0.0697 0.0703 0.0710 0.0717 

[TRAIN] Epoch[5](1454/1500); Loss: 0.198875; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.3099 0.2877 0.2727 0.2246 0.2171 0.1943 0.1866 0.1724 0.1688 0.1663 0.1647 0.1641 0.1635 0.1632 0.1630 0.1630 

[TRAIN] Epoch[5](1455/1500); Loss: 0.098599; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1646 0.1318 0.1255 0.1056 0.1024 0.0939 0.0915 0.0886 0.0861 0.0853 0.0846 0.0840 0.0836 0.0834 0.0833 0.0833 

[TRAIN] Epoch[5](1456/1500); Loss: 0.117900; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1882 0.1614 0.1545 0.1357 0.1304 0.1130 0.1096 0.1029 0.1022 0.0998 0.0989 0.0981 0.0981 0.0980 0.0977 0.0978 

[TRAIN] Epoch[5](1457/1500); Loss: 0.055203; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1618 0.1091 0.1024 0.0425 0.0406 0.0424 0.0420 0.0396 0.0383 0.0380 0.0378 0.0375 0.0374 0.0376 0.0379 0.0384 

[TRAIN] Epoch[5](1458/1500); Loss: 0.059142; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.0940 0.0983 0.0751 0.0620 0.0580 0.0544 0.0514 0.0509 0.0502 0.0499 0.0498 0.0499 0.0500 0.0503 0.0508 0.0512 

[TRAIN] Epoch[5](1459/1500); Loss: 0.130721; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.3641 0.2855 0.2705 0.1593 0.1395 0.0962 0.0852 0.0927 0.0880 0.0754 0.0725 0.0723 0.0724 0.0725 0.0726 0.0728 

[TRAIN] Epoch[5](1460/1500); Loss: 0.103091; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1878 0.1603 0.1517 0.1288 0.1169 0.0997 0.0932 0.0807 0.0815 0.0790 0.0780 0.0780 0.0780 0.0782 0.0786 0.0789 

[TRAIN] Epoch[5](1461/1500); Loss: 0.156846; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2013 0.2080 0.1874 0.1667 0.1570 0.1482 0.1456 0.1453 0.1448 0.1441 0.1436 0.1434 0.1433 0.1437 0.1437 0.1437 

[TRAIN] Epoch[5](1462/1500); Loss: 0.062417; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1368 0.0884 0.0837 0.0623 0.0632 0.0542 0.0516 0.0512 0.0508 0.0505 0.0503 0.0502 0.0505 0.0511 0.0516 0.0522 

[TRAIN] Epoch[5](1463/1500); Loss: 0.155955; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2709 0.2408 0.2284 0.1802 0.1679 0.1423 0.1350 0.1319 0.1350 0.1243 0.1237 0.1231 0.1230 0.1230 0.1229 0.1229 

[TRAIN] Epoch[5](1464/1500); Loss: 0.067635; Backpropagation: 0.0957 sec; Batch: 0.4300 sec
0.1391 0.0958 0.0903 0.0771 0.0700 0.0616 0.0581 0.0568 0.0557 0.0549 0.0545 0.0540 0.0538 0.0536 0.0534 0.0535 

[TRAIN] Epoch[5](1465/1500); Loss: 0.223145; Backpropagation: 0.0959 sec; Batch: 0.4332 sec
0.3796 0.3212 0.3094 0.2379 0.2272 0.2046 0.1966 0.1951 0.1925 0.1887 0.1871 0.1865 0.1862 0.1864 0.1859 0.1853 

[TRAIN] Epoch[5](1466/1500); Loss: 0.130360; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.1739 0.1747 0.1596 0.1429 0.1343 0.1284 0.1259 0.1207 0.1179 0.1162 0.1157 0.1153 0.1154 0.1149 0.1149 0.1151 

[TRAIN] Epoch[5](1467/1500); Loss: 0.168616; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2636 0.2339 0.2277 0.2039 0.1950 0.1703 0.1628 0.1462 0.1408 0.1376 0.1363 0.1370 0.1364 0.1357 0.1354 0.1353 

[TRAIN] Epoch[5](1468/1500); Loss: 0.119514; Backpropagation: 0.0933 sec; Batch: 0.4367 sec
0.1859 0.1746 0.1620 0.1321 0.1249 0.1164 0.1127 0.1052 0.1027 0.1006 0.0995 0.0990 0.0993 0.0991 0.0990 0.0992 

[TRAIN] Epoch[5](1469/1500); Loss: 0.087404; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.3069 0.2387 0.2267 0.1069 0.0801 0.0482 0.0395 0.0544 0.0499 0.0362 0.0357 0.0351 0.0347 0.0347 0.0351 0.0356 

[TRAIN] Epoch[5](1470/1500); Loss: 0.068608; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1640 0.2185 0.1095 0.0496 0.0509 0.0477 0.0473 0.0469 0.0458 0.0450 0.0449 0.0449 0.0449 0.0451 0.0459 0.0467 

[TRAIN] Epoch[5](1471/1500); Loss: 0.158761; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2824 0.2411 0.2335 0.1866 0.1746 0.1484 0.1409 0.1312 0.1300 0.1272 0.1257 0.1250 0.1245 0.1236 0.1230 0.1225 

[TRAIN] Epoch[5](1472/1500); Loss: 0.099377; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1752 0.1409 0.1263 0.1156 0.1093 0.0981 0.0930 0.0895 0.0870 0.0843 0.0818 0.0801 0.0786 0.0775 0.0767 0.0761 

[TRAIN] Epoch[5](1473/1500); Loss: 0.109344; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.3063 0.2432 0.2307 0.1252 0.1036 0.0687 0.0648 0.0888 0.0757 0.0651 0.0637 0.0628 0.0624 0.0629 0.0627 0.0629 

[TRAIN] Epoch[5](1474/1500); Loss: 0.067328; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.0901 0.0807 0.0715 0.0787 0.0705 0.0655 0.0639 0.0630 0.0623 0.0616 0.0615 0.0614 0.0614 0.0616 0.0617 0.0620 

[TRAIN] Epoch[5](1475/1500); Loss: 0.092363; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2188 0.1690 0.1623 0.1124 0.1059 0.0786 0.0693 0.0670 0.0740 0.0624 0.0605 0.0600 0.0597 0.0593 0.0593 0.0592 

[TRAIN] Epoch[5](1476/1500); Loss: 0.062263; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1218 0.0950 0.0821 0.0614 0.0642 0.0541 0.0521 0.0515 0.0513 0.0510 0.0510 0.0513 0.0517 0.0522 0.0526 0.0532 

[TRAIN] Epoch[5](1477/1500); Loss: 0.085023; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1541 0.1567 0.1086 0.0822 0.0802 0.0767 0.0722 0.0708 0.0701 0.0700 0.0698 0.0697 0.0695 0.0696 0.0699 0.0703 

[TRAIN] Epoch[5](1478/1500); Loss: 0.123373; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2190 0.2138 0.1857 0.1480 0.1325 0.1206 0.1142 0.1011 0.0975 0.0943 0.0916 0.0917 0.0918 0.0905 0.0907 0.0909 

[TRAIN] Epoch[5](1479/1500); Loss: 0.144482; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2061 0.1850 0.1728 0.1538 0.1490 0.1378 0.1354 0.1327 0.1312 0.1306 0.1300 0.1292 0.1292 0.1293 0.1294 0.1300 

[TRAIN] Epoch[5](1480/1500); Loss: 0.117892; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1409 0.1359 0.1259 0.1230 0.1198 0.1159 0.1138 0.1132 0.1128 0.1124 0.1119 0.1118 0.1120 0.1121 0.1123 0.1125 

[TRAIN] Epoch[5](1481/1500); Loss: 0.069484; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1206 0.0977 0.0914 0.1047 0.0940 0.0696 0.0609 0.0547 0.0535 0.0535 0.0520 0.0514 0.0514 0.0516 0.0521 0.0526 

[TRAIN] Epoch[5](1482/1500); Loss: 0.119221; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.1710 0.1510 0.1432 0.1285 0.1234 0.1141 0.1108 0.1088 0.1080 0.1076 0.1072 0.1069 0.1067 0.1066 0.1067 0.1069 

[TRAIN] Epoch[5](1483/1500); Loss: 0.159575; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2526 0.2509 0.2249 0.1842 0.1748 0.1583 0.1504 0.1338 0.1335 0.1312 0.1277 0.1268 0.1263 0.1260 0.1260 0.1259 

[TRAIN] Epoch[5](1484/1500); Loss: 0.076561; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1675 0.1290 0.1211 0.0825 0.0809 0.0709 0.0631 0.0581 0.0577 0.0564 0.0561 0.0560 0.0560 0.0563 0.0566 0.0569 

[TRAIN] Epoch[5](1485/1500); Loss: 0.139738; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.2223 0.1909 0.1838 0.1502 0.1438 0.1308 0.1269 0.1260 0.1252 0.1218 0.1201 0.1194 0.1192 0.1188 0.1184 0.1181 

[TRAIN] Epoch[5](1486/1500); Loss: 0.072314; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1790 0.1412 0.1244 0.0687 0.0652 0.0583 0.0586 0.0567 0.0527 0.0509 0.0505 0.0502 0.0499 0.0499 0.0502 0.0506 

[TRAIN] Epoch[5](1487/1500); Loss: 0.142936; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2118 0.1989 0.1854 0.1584 0.1493 0.1310 0.1255 0.1324 0.1318 0.1239 0.1237 0.1234 0.1231 0.1228 0.1228 0.1229 

[TRAIN] Epoch[5](1488/1500); Loss: 0.103262; Backpropagation: 0.0940 sec; Batch: 0.4316 sec
0.1142 0.1269 0.1095 0.1098 0.1046 0.1018 0.1001 0.0986 0.0983 0.0978 0.0980 0.0978 0.0983 0.0985 0.0988 0.0993 

[TRAIN] Epoch[5](1489/1500); Loss: 0.158473; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.2132 0.1951 0.1835 0.1708 0.1605 0.1510 0.1500 0.1494 0.1487 0.1465 0.1454 0.1448 0.1443 0.1441 0.1441 0.1441 

[TRAIN] Epoch[5](1490/1500); Loss: 0.080954; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.0921 0.0940 0.0863 0.0789 0.0759 0.0741 0.0736 0.0739 0.0748 0.0757 0.0772 0.0793 0.0814 0.0837 0.0860 0.0884 

[TRAIN] Epoch[5](1491/1500); Loss: 0.136856; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2389 0.2323 0.2069 0.1546 0.1428 0.1203 0.1133 0.1150 0.1150 0.1088 0.1078 0.1073 0.1070 0.1068 0.1066 0.1064 

[TRAIN] Epoch[5](1492/1500); Loss: 0.194300; Backpropagation: 0.0939 sec; Batch: 0.4290 sec
0.2146 0.2048 0.2000 0.2093 0.2069 0.1983 0.1958 0.1911 0.1895 0.1877 0.1866 0.1860 0.1852 0.1851 0.1845 0.1834 

[TRAIN] Epoch[5](1493/1500); Loss: 0.088753; Backpropagation: 0.0947 sec; Batch: 0.4346 sec
0.1029 0.1084 0.0939 0.0926 0.0893 0.0832 0.0827 0.0824 0.0827 0.0832 0.0839 0.0848 0.0857 0.0868 0.0881 0.0895 

[TRAIN] Epoch[5](1494/1500); Loss: 0.148078; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1966 0.2184 0.1820 0.1511 0.1467 0.1401 0.1385 0.1370 0.1356 0.1337 0.1326 0.1320 0.1315 0.1313 0.1312 0.1311 

[TRAIN] Epoch[5](1495/1500); Loss: 0.128887; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.1915 0.1738 0.1697 0.1478 0.1369 0.1175 0.1144 0.1172 0.1182 0.1113 0.1111 0.1112 0.1108 0.1103 0.1102 0.1103 

[TRAIN] Epoch[5](1496/1500); Loss: 0.082860; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1146 0.0892 0.0882 0.0924 0.0920 0.0796 0.0781 0.0769 0.0766 0.0762 0.0763 0.0764 0.0767 0.0771 0.0775 0.0781 

[TRAIN] Epoch[5](1497/1500); Loss: 0.097977; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1452 0.1661 0.1334 0.1039 0.0946 0.0872 0.0857 0.0847 0.0840 0.0835 0.0833 0.0832 0.0831 0.0830 0.0832 0.0835 

[TRAIN] Epoch[5](1498/1500); Loss: 0.068238; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1361 0.0928 0.0854 0.0680 0.0743 0.0715 0.0627 0.0576 0.0565 0.0553 0.0549 0.0549 0.0550 0.0552 0.0555 0.0561 

[TRAIN] Epoch[5](1499/1500); Loss: 0.091420; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1430 0.1441 0.1234 0.1126 0.1011 0.0828 0.0803 0.0785 0.0762 0.0756 0.0752 0.0747 0.0742 0.0739 0.0738 0.0736 

[TRAIN] Epoch[5](1500/1500); Loss: 0.107729; Backpropagation: 0.0940 sec; Batch: 0.4294 sec
0.2577 0.2384 0.2051 0.1159 0.0960 0.0796 0.0750 0.0852 0.0812 0.0723 0.0704 0.0696 0.0695 0.0691 0.0693 0.0694 

[TRAIN] Epoch[6](1/1500); Loss: 0.102470; Backpropagation: 0.1004 sec; Batch: 0.4647 sec
0.1943 0.1676 0.1513 0.1077 0.0986 0.0914 0.0867 0.0856 0.0841 0.0822 0.0819 0.0815 0.0813 0.0815 0.0818 0.0820 

[TRAIN] Epoch[6](2/1500); Loss: 0.128189; Backpropagation: 0.0938 sec; Batch: 0.4370 sec
0.1915 0.1789 0.1601 0.1331 0.1281 0.1162 0.1156 0.1181 0.1167 0.1140 0.1136 0.1131 0.1129 0.1130 0.1131 0.1132 

[TRAIN] Epoch[6](3/1500); Loss: 0.066179; Backpropagation: 0.0931 sec; Batch: 0.4298 sec
0.0914 0.1077 0.0898 0.0841 0.0718 0.0594 0.0577 0.0573 0.0557 0.0551 0.0552 0.0547 0.0546 0.0548 0.0547 0.0547 

[TRAIN] Epoch[6](4/1500); Loss: 0.045520; Backpropagation: 0.0932 sec; Batch: 0.4287 sec
0.0741 0.0640 0.0561 0.0639 0.0533 0.0410 0.0392 0.0385 0.0377 0.0369 0.0367 0.0368 0.0370 0.0373 0.0377 0.0383 

[TRAIN] Epoch[6](5/1500); Loss: 0.091500; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1987 0.2686 0.1811 0.0679 0.0729 0.0647 0.0623 0.0605 0.0592 0.0594 0.0597 0.0602 0.0609 0.0616 0.0625 0.0639 

[TRAIN] Epoch[6](6/1500); Loss: 0.095928; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1739 0.2199 0.1750 0.1251 0.0918 0.0728 0.0708 0.0687 0.0674 0.0672 0.0671 0.0671 0.0670 0.0669 0.0670 0.0673 

[TRAIN] Epoch[6](7/1500); Loss: 0.106896; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.1772 0.2338 0.2032 0.1720 0.1360 0.0979 0.0783 0.0712 0.0698 0.0684 0.0672 0.0668 0.0667 0.0669 0.0671 0.0679 

[TRAIN] Epoch[6](8/1500); Loss: 0.078696; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.1869 0.1357 0.1280 0.0992 0.0859 0.0680 0.0698 0.0635 0.0564 0.0539 0.0532 0.0523 0.0519 0.0515 0.0514 0.0515 

[TRAIN] Epoch[6](9/1500); Loss: 0.133206; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1566 0.1599 0.1514 0.1497 0.1461 0.1396 0.1347 0.1287 0.1253 0.1223 0.1205 0.1198 0.1193 0.1191 0.1190 0.1193 

[TRAIN] Epoch[6](10/1500); Loss: 0.104581; Backpropagation: 0.0930 sec; Batch: 0.4272 sec
0.1525 0.1463 0.1377 0.1372 0.1306 0.1121 0.1031 0.0942 0.0901 0.0855 0.0829 0.0816 0.0809 0.0801 0.0793 0.0792 

[TRAIN] Epoch[6](11/1500); Loss: 0.053970; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.0776 0.0669 0.0624 0.0588 0.0574 0.0517 0.0493 0.0487 0.0480 0.0476 0.0478 0.0482 0.0487 0.0493 0.0501 0.0510 

[TRAIN] Epoch[6](12/1500); Loss: 0.054482; Backpropagation: 0.0932 sec; Batch: 0.4280 sec
0.1215 0.0666 0.0602 0.0951 0.0988 0.0535 0.0468 0.0391 0.0373 0.0365 0.0357 0.0353 0.0357 0.0361 0.0366 0.0370 

[TRAIN] Epoch[6](13/1500); Loss: 0.171219; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2374 0.2320 0.2271 0.2211 0.2072 0.1803 0.1675 0.1503 0.1463 0.1459 0.1419 0.1391 0.1372 0.1362 0.1354 0.1346 

[TRAIN] Epoch[6](14/1500); Loss: 0.117138; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1042 0.1104 0.1095 0.1626 0.1581 0.1348 0.1256 0.1199 0.1151 0.1111 0.1081 0.1055 0.1039 0.1028 0.1017 0.1008 

[TRAIN] Epoch[6](15/1500); Loss: 0.066137; Backpropagation: 0.0937 sec; Batch: 0.4296 sec
0.1607 0.1157 0.1100 0.0877 0.0754 0.0528 0.0519 0.0514 0.0458 0.0436 0.0435 0.0435 0.0437 0.0438 0.0441 0.0445 

[TRAIN] Epoch[6](16/1500); Loss: 0.117862; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1562 0.1807 0.1739 0.1735 0.1606 0.1374 0.1247 0.1132 0.1035 0.0925 0.0860 0.0811 0.0781 0.0763 0.0745 0.0738 

[TRAIN] Epoch[6](17/1500); Loss: 0.115520; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1152 0.1297 0.1278 0.1513 0.1453 0.1277 0.1221 0.1162 0.1122 0.1079 0.1042 0.1014 0.0990 0.0974 0.0961 0.0948 

[TRAIN] Epoch[6](18/1500); Loss: 0.234982; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.3238 0.3216 0.3154 0.2881 0.2765 0.2442 0.2300 0.2173 0.2208 0.2084 0.1992 0.1931 0.1876 0.1829 0.1778 0.1728 

[TRAIN] Epoch[6](19/1500); Loss: 0.210318; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.2298 0.2541 0.2497 0.2594 0.2531 0.2381 0.2273 0.2182 0.2099 0.1995 0.1892 0.1807 0.1736 0.1668 0.1609 0.1549 

[TRAIN] Epoch[6](20/1500); Loss: 0.274154; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2488 0.3082 0.3058 0.3452 0.3403 0.3158 0.2998 0.2875 0.2768 0.2659 0.2554 0.2453 0.2359 0.2269 0.2183 0.2106 

[TRAIN] Epoch[6](21/1500); Loss: 0.113978; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.1511 0.1659 0.1575 0.1568 0.1482 0.1316 0.1168 0.1058 0.0966 0.0896 0.0855 0.0838 0.0836 0.0837 0.0835 0.0838 

[TRAIN] Epoch[6](22/1500); Loss: 0.077905; Backpropagation: 0.0947 sec; Batch: 0.4294 sec
0.1215 0.1026 0.0993 0.1128 0.1020 0.0766 0.0711 0.0662 0.0632 0.0620 0.0614 0.0612 0.0615 0.0616 0.0617 0.0618 

[TRAIN] Epoch[6](23/1500); Loss: 0.249704; Backpropagation: 0.0931 sec; Batch: 0.4303 sec
0.1856 0.2810 0.2714 0.3083 0.3057 0.2956 0.2807 0.2676 0.2562 0.2442 0.2332 0.2235 0.2169 0.2119 0.2080 0.2057 

[TRAIN] Epoch[6](24/1500); Loss: 0.127205; Backpropagation: 0.0936 sec; Batch: 0.4291 sec
0.1557 0.1893 0.1791 0.2007 0.1839 0.1525 0.1325 0.1163 0.1037 0.0949 0.0899 0.0875 0.0869 0.0869 0.0876 0.0881 

[TRAIN] Epoch[6](25/1500); Loss: 0.118777; Backpropagation: 0.0939 sec; Batch: 0.4295 sec
0.1533 0.2088 0.1884 0.1727 0.1478 0.1197 0.1016 0.0934 0.0893 0.0876 0.0877 0.0884 0.0894 0.0904 0.0908 0.0910 

[TRAIN] Epoch[6](26/1500); Loss: 0.144590; Backpropagation: 0.0938 sec; Batch: 0.4292 sec
0.1981 0.2161 0.2038 0.1910 0.1738 0.1529 0.1390 0.1249 0.1176 0.1143 0.1136 0.1133 0.1134 0.1137 0.1140 0.1140 

[TRAIN] Epoch[6](27/1500); Loss: 0.129555; Backpropagation: 0.0925 sec; Batch: 0.4268 sec
0.1754 0.1864 0.1744 0.1594 0.1487 0.1320 0.1200 0.1123 0.1088 0.1075 0.1069 0.1069 0.1074 0.1080 0.1089 0.1099 

[TRAIN] Epoch[6](28/1500); Loss: 0.177228; Backpropagation: 0.0930 sec; Batch: 0.4264 sec
0.2431 0.2307 0.2209 0.2072 0.1953 0.1778 0.1683 0.1628 0.1580 0.1547 0.1529 0.1522 0.1522 0.1528 0.1533 0.1534 

[TRAIN] Epoch[6](29/1500); Loss: 0.056586; Backpropagation: 0.0925 sec; Batch: 0.4265 sec
0.1124 0.0694 0.0659 0.0646 0.0614 0.0497 0.0482 0.0478 0.0470 0.0473 0.0475 0.0476 0.0481 0.0488 0.0494 0.0501 

[TRAIN] Epoch[6](30/1500); Loss: 0.156109; Backpropagation: 0.0954 sec; Batch: 0.4752 sec
0.1896 0.1943 0.1874 0.1774 0.1676 0.1557 0.1491 0.1438 0.1419 0.1411 0.1413 0.1412 0.1412 0.1418 0.1421 0.1424 

[TRAIN] Epoch[6](31/1500); Loss: 0.153744; Backpropagation: 0.0957 sec; Batch: 0.4309 sec
0.2247 0.2360 0.2203 0.2031 0.1854 0.1672 0.1533 0.1396 0.1272 0.1176 0.1132 0.1124 0.1135 0.1144 0.1156 0.1164 

[TRAIN] Epoch[6](32/1500); Loss: 0.161436; Backpropagation: 0.0931 sec; Batch: 0.4280 sec
0.3433 0.2975 0.2839 0.2146 0.1894 0.1520 0.1361 0.1069 0.1059 0.1040 0.1049 0.1075 0.1081 0.1088 0.1096 0.1102 

[TRAIN] Epoch[6](33/1500); Loss: 0.086464; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1833 0.1449 0.1373 0.0943 0.0833 0.0690 0.0667 0.0650 0.0655 0.0658 0.0664 0.0673 0.0681 0.0683 0.0687 0.0695 

[TRAIN] Epoch[6](34/1500); Loss: 0.073360; Backpropagation: 0.0931 sec; Batch: 0.4278 sec
0.1896 0.1437 0.1340 0.0936 0.0748 0.0528 0.0474 0.0466 0.0479 0.0484 0.0485 0.0482 0.0486 0.0494 0.0500 0.0504 

[TRAIN] Epoch[6](35/1500); Loss: 0.128592; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.2001 0.3003 0.2497 0.2112 0.1586 0.1116 0.0869 0.0775 0.0735 0.0754 0.0789 0.0829 0.0851 0.0871 0.0885 0.0904 

[TRAIN] Epoch[6](36/1500); Loss: 0.081362; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1684 0.1242 0.1161 0.0758 0.0729 0.0673 0.0664 0.0663 0.0662 0.0664 0.0667 0.0672 0.0683 0.0691 0.0697 0.0706 

[TRAIN] Epoch[6](37/1500); Loss: 0.112795; Backpropagation: 0.0938 sec; Batch: 0.4287 sec
0.2249 0.1917 0.1780 0.1405 0.1206 0.1033 0.0960 0.0869 0.0847 0.0828 0.0822 0.0821 0.0823 0.0824 0.0828 0.0836 

[TRAIN] Epoch[6](38/1500); Loss: 0.071527; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1063 0.1332 0.1054 0.0887 0.0712 0.0629 0.0593 0.0578 0.0572 0.0572 0.0570 0.0575 0.0576 0.0576 0.0578 0.0580 

[TRAIN] Epoch[6](39/1500); Loss: 0.148085; Backpropagation: 0.0936 sec; Batch: 0.4288 sec
0.1701 0.2005 0.1782 0.1660 0.1500 0.1412 0.1358 0.1343 0.1338 0.1347 0.1356 0.1369 0.1373 0.1377 0.1383 0.1390 

[TRAIN] Epoch[6](40/1500); Loss: 0.090718; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.2058 0.1675 0.1543 0.0948 0.0784 0.0751 0.0670 0.0682 0.0678 0.0674 0.0673 0.0670 0.0671 0.0674 0.0679 0.0685 

[TRAIN] Epoch[6](41/1500); Loss: 0.142266; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1805 0.1785 0.1715 0.1574 0.1478 0.1395 0.1345 0.1315 0.1304 0.1298 0.1296 0.1294 0.1293 0.1291 0.1289 0.1287 

[TRAIN] Epoch[6](42/1500); Loss: 0.149528; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1976 0.1921 0.1802 0.1563 0.1480 0.1425 0.1396 0.1380 0.1371 0.1368 0.1367 0.1368 0.1372 0.1376 0.1378 0.1381 

[TRAIN] Epoch[6](43/1500); Loss: 0.124629; Backpropagation: 0.0939 sec; Batch: 0.4372 sec
0.2061 0.2848 0.2377 0.2052 0.1585 0.1164 0.0899 0.0774 0.0752 0.0751 0.0762 0.0764 0.0767 0.0778 0.0799 0.0806 

[TRAIN] Epoch[6](44/1500); Loss: 0.148510; Backpropagation: 0.0932 sec; Batch: 0.4291 sec
0.2383 0.2455 0.2249 0.1850 0.1601 0.1371 0.1253 0.1195 0.1181 0.1167 0.1166 0.1166 0.1175 0.1180 0.1183 0.1186 

[TRAIN] Epoch[6](45/1500); Loss: 0.166919; Backpropagation: 0.0944 sec; Batch: 0.4317 sec
0.2310 0.2153 0.2041 0.1811 0.1731 0.1599 0.1558 0.1522 0.1503 0.1497 0.1497 0.1498 0.1498 0.1497 0.1497 0.1494 

[TRAIN] Epoch[6](46/1500); Loss: 0.083542; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.1300 0.1952 0.1501 0.1161 0.0803 0.0647 0.0605 0.0604 0.0594 0.0597 0.0599 0.0600 0.0600 0.0601 0.0600 0.0602 

[TRAIN] Epoch[6](47/1500); Loss: 0.120727; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1904 0.1518 0.1433 0.1376 0.1293 0.1171 0.1130 0.1101 0.1076 0.1050 0.1043 0.1040 0.1041 0.1042 0.1046 0.1052 

[TRAIN] Epoch[6](48/1500); Loss: 0.136084; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.2822 0.2424 0.2314 0.1696 0.1508 0.1229 0.1124 0.0996 0.0969 0.0954 0.0951 0.0951 0.0955 0.0958 0.0959 0.0964 

[TRAIN] Epoch[6](49/1500); Loss: 0.141891; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1755 0.1663 0.1591 0.1504 0.1422 0.1366 0.1353 0.1339 0.1336 0.1333 0.1334 0.1337 0.1340 0.1341 0.1344 0.1345 

[TRAIN] Epoch[6](50/1500); Loss: 0.087995; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1218 0.1181 0.1058 0.0975 0.0893 0.0845 0.0801 0.0784 0.0789 0.0790 0.0791 0.0791 0.0791 0.0791 0.0791 0.0791 

[TRAIN] Epoch[6](51/1500); Loss: 0.073508; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1908 0.1380 0.1234 0.0756 0.0712 0.0623 0.0565 0.0527 0.0516 0.0510 0.0505 0.0502 0.0500 0.0502 0.0508 0.0514 

[TRAIN] Epoch[6](52/1500); Loss: 0.135275; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.2349 0.2382 0.2169 0.1716 0.1437 0.1179 0.1084 0.1053 0.1048 0.1039 0.1034 0.1034 0.1033 0.1032 0.1029 0.1026 

[TRAIN] Epoch[6](53/1500); Loss: 0.088444; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.0980 0.0938 0.0882 0.0874 0.0865 0.0869 0.0869 0.0870 0.0871 0.0871 0.0871 0.0872 0.0874 0.0878 0.0881 0.0885 

[TRAIN] Epoch[6](54/1500); Loss: 0.142348; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1874 0.1793 0.1711 0.1606 0.1497 0.1370 0.1335 0.1306 0.1300 0.1289 0.1285 0.1283 0.1281 0.1280 0.1282 0.1286 

[TRAIN] Epoch[6](55/1500); Loss: 0.128005; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1926 0.1810 0.1691 0.1376 0.1303 0.1219 0.1185 0.1132 0.1108 0.1102 0.1099 0.1100 0.1104 0.1107 0.1109 0.1110 

[TRAIN] Epoch[6](56/1500); Loss: 0.170149; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.2455 0.2194 0.2102 0.1768 0.1676 0.1616 0.1582 0.1547 0.1535 0.1532 0.1530 0.1529 0.1531 0.1535 0.1542 0.1550 

[TRAIN] Epoch[6](57/1500); Loss: 0.077543; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1205 0.1133 0.0995 0.0962 0.0811 0.0695 0.0656 0.0646 0.0640 0.0642 0.0649 0.0658 0.0665 0.0672 0.0682 0.0696 

[TRAIN] Epoch[6](58/1500); Loss: 0.146978; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2303 0.2685 0.2371 0.2011 0.1644 0.1318 0.1163 0.1117 0.1112 0.1116 0.1116 0.1112 0.1110 0.1109 0.1116 0.1116 

[TRAIN] Epoch[6](59/1500); Loss: 0.159637; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.2836 0.3863 0.3327 0.2993 0.2487 0.1876 0.1317 0.0898 0.0777 0.0712 0.0700 0.0718 0.0756 0.0761 0.0758 0.0763 

[TRAIN] Epoch[6](60/1500); Loss: 0.170167; Backpropagation: 0.0957 sec; Batch: 0.4314 sec
0.2161 0.2372 0.2161 0.1923 0.1779 0.1617 0.1518 0.1471 0.1463 0.1482 0.1504 0.1525 0.1541 0.1556 0.1571 0.1580 

[TRAIN] Epoch[6](61/1500); Loss: 0.131273; Backpropagation: 0.0957 sec; Batch: 0.4305 sec
0.3654 0.2886 0.2708 0.1572 0.1302 0.0940 0.0818 0.0906 0.0859 0.0783 0.0770 0.0761 0.0758 0.0760 0.0764 0.0763 

[TRAIN] Epoch[6](62/1500); Loss: 0.125586; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1785 0.1841 0.1639 0.1467 0.1329 0.1182 0.1122 0.1093 0.1084 0.1080 0.1078 0.1078 0.1080 0.1079 0.1079 0.1078 

[TRAIN] Epoch[6](63/1500); Loss: 0.081746; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1303 0.1023 0.0979 0.0880 0.0820 0.0756 0.0749 0.0745 0.0737 0.0732 0.0729 0.0726 0.0726 0.0724 0.0724 0.0725 

[TRAIN] Epoch[6](64/1500); Loss: 0.114591; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1347 0.1269 0.1236 0.1269 0.1168 0.1120 0.1113 0.1107 0.1101 0.1096 0.1091 0.1089 0.1085 0.1083 0.1082 0.1080 

[TRAIN] Epoch[6](65/1500); Loss: 0.127603; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1803 0.1849 0.1665 0.1381 0.1237 0.1180 0.1162 0.1152 0.1145 0.1137 0.1129 0.1123 0.1120 0.1114 0.1110 0.1108 

[TRAIN] Epoch[6](66/1500); Loss: 0.132600; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1767 0.1878 0.1680 0.1549 0.1393 0.1256 0.1205 0.1176 0.1166 0.1167 0.1164 0.1163 0.1163 0.1163 0.1163 0.1163 

[TRAIN] Epoch[6](67/1500); Loss: 0.102285; Backpropagation: 0.0952 sec; Batch: 0.4306 sec
0.1999 0.2210 0.1895 0.1502 0.1174 0.0870 0.0728 0.0682 0.0695 0.0676 0.0667 0.0663 0.0656 0.0650 0.0650 0.0649 

[TRAIN] Epoch[6](68/1500); Loss: 0.093965; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1920 0.1669 0.1554 0.1164 0.1018 0.0827 0.0743 0.0700 0.0696 0.0682 0.0676 0.0675 0.0675 0.0675 0.0678 0.0682 

[TRAIN] Epoch[6](69/1500); Loss: 0.120578; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1798 0.1724 0.1589 0.1372 0.1235 0.1101 0.1069 0.1055 0.1050 0.1046 0.1044 0.1042 0.1041 0.1041 0.1043 0.1043 

[TRAIN] Epoch[6](70/1500); Loss: 0.130636; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1732 0.1809 0.1612 0.1512 0.1381 0.1263 0.1207 0.1183 0.1174 0.1175 0.1164 0.1151 0.1140 0.1135 0.1133 0.1132 

[TRAIN] Epoch[6](71/1500); Loss: 0.092016; Backpropagation: 0.0958 sec; Batch: 0.4337 sec
0.2548 0.1959 0.1845 0.1039 0.0769 0.0675 0.0629 0.0620 0.0606 0.0593 0.0583 0.0570 0.0566 0.0568 0.0574 0.0580 

[TRAIN] Epoch[6](72/1500); Loss: 0.069854; Backpropagation: 0.0955 sec; Batch: 0.4298 sec
0.1063 0.1463 0.1087 0.0872 0.0678 0.0582 0.0551 0.0548 0.0545 0.0543 0.0541 0.0540 0.0538 0.0543 0.0542 0.0541 

[TRAIN] Epoch[6](73/1500); Loss: 0.069484; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1874 0.1392 0.1278 0.0885 0.0703 0.0484 0.0477 0.0460 0.0458 0.0447 0.0444 0.0443 0.0442 0.0441 0.0443 0.0446 

[TRAIN] Epoch[6](74/1500); Loss: 0.168057; Backpropagation: 0.0931 sec; Batch: 0.4274 sec
0.2225 0.2215 0.2068 0.1885 0.1770 0.1664 0.1590 0.1530 0.1502 0.1492 0.1489 0.1490 0.1491 0.1492 0.1493 0.1495 

[TRAIN] Epoch[6](75/1500); Loss: 0.108829; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1692 0.1339 0.1266 0.1169 0.1105 0.1016 0.1005 0.0994 0.0991 0.0986 0.0981 0.0978 0.0975 0.0974 0.0972 0.0971 

[TRAIN] Epoch[6](76/1500); Loss: 0.123214; Backpropagation: 0.0936 sec; Batch: 0.4272 sec
0.2706 0.2215 0.2094 0.1362 0.1190 0.0954 0.0907 0.0921 0.0916 0.0918 0.0914 0.0915 0.0920 0.0926 0.0927 0.0931 

[TRAIN] Epoch[6](77/1500); Loss: 0.132665; Backpropagation: 0.0968 sec; Batch: 0.4325 sec
0.2093 0.2198 0.1972 0.1663 0.1440 0.1261 0.1175 0.1087 0.1094 0.1068 0.1053 0.1042 0.1031 0.1023 0.1017 0.1013 

[TRAIN] Epoch[6](78/1500); Loss: 0.073166; Backpropagation: 0.0981 sec; Batch: 0.4330 sec
0.1371 0.0995 0.0894 0.0704 0.0741 0.0648 0.0630 0.0619 0.0618 0.0619 0.0626 0.0632 0.0638 0.0645 0.0658 0.0668 

[TRAIN] Epoch[6](79/1500); Loss: 0.106220; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.2139 0.1608 0.1531 0.1276 0.1120 0.0916 0.0868 0.0888 0.0864 0.0838 0.0829 0.0823 0.0823 0.0824 0.0825 0.0825 

[TRAIN] Epoch[6](80/1500); Loss: 0.131845; Backpropagation: 0.0955 sec; Batch: 0.4296 sec
0.2786 0.3813 0.3184 0.2670 0.1956 0.1247 0.0675 0.0588 0.0516 0.0514 0.0513 0.0519 0.0518 0.0520 0.0531 0.0544 

[TRAIN] Epoch[6](81/1500); Loss: 0.117201; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2025 0.2464 0.2096 0.1808 0.1386 0.1039 0.0858 0.0809 0.0797 0.0790 0.0786 0.0784 0.0781 0.0777 0.0776 0.0775 

[TRAIN] Epoch[6](82/1500); Loss: 0.097961; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1673 0.1302 0.1255 0.0929 0.0899 0.0883 0.0881 0.0873 0.0873 0.0871 0.0870 0.0870 0.0871 0.0873 0.0875 0.0876 

[TRAIN] Epoch[6](83/1500); Loss: 0.074601; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.1416 0.1220 0.1101 0.0849 0.0794 0.0675 0.0652 0.0620 0.0599 0.0592 0.0578 0.0564 0.0561 0.0565 0.0570 0.0580 

[TRAIN] Epoch[6](84/1500); Loss: 0.125363; Backpropagation: 0.0933 sec; Batch: 0.4282 sec
0.2033 0.2043 0.1783 0.1389 0.1229 0.1106 0.1062 0.1068 0.1058 0.1045 0.1041 0.1040 0.1040 0.1039 0.1040 0.1042 

[TRAIN] Epoch[6](85/1500); Loss: 0.072879; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.2171 0.1427 0.1332 0.0670 0.0583 0.0532 0.0520 0.0513 0.0503 0.0494 0.0488 0.0482 0.0482 0.0485 0.0487 0.0489 

[TRAIN] Epoch[6](86/1500); Loss: 0.141646; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.2451 0.3130 0.2642 0.2227 0.1730 0.1272 0.0977 0.0928 0.0902 0.0892 0.0902 0.0910 0.0913 0.0919 0.0926 0.0941 

[TRAIN] Epoch[6](87/1500); Loss: 0.113606; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2587 0.2151 0.1997 0.1273 0.1011 0.0890 0.0869 0.0835 0.0827 0.0820 0.0819 0.0818 0.0818 0.0820 0.0821 0.0822 

[TRAIN] Epoch[6](88/1500); Loss: 0.164397; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2521 0.2603 0.2360 0.1899 0.1681 0.1476 0.1408 0.1375 0.1364 0.1370 0.1366 0.1369 0.1370 0.1373 0.1381 0.1386 

[TRAIN] Epoch[6](89/1500); Loss: 0.070055; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1077 0.1006 0.0895 0.0837 0.0747 0.0669 0.0625 0.0602 0.0597 0.0594 0.0592 0.0591 0.0593 0.0593 0.0594 0.0597 

[TRAIN] Epoch[6](90/1500); Loss: 0.161569; Backpropagation: 0.0932 sec; Batch: 0.4266 sec
0.3215 0.2616 0.2493 0.1848 0.1745 0.1458 0.1380 0.1260 0.1232 0.1231 0.1221 0.1226 0.1227 0.1230 0.1232 0.1239 

[TRAIN] Epoch[6](91/1500); Loss: 0.112429; Backpropagation: 0.0931 sec; Batch: 0.4277 sec
0.1951 0.1939 0.1710 0.1429 0.1270 0.1108 0.0982 0.0896 0.0873 0.0851 0.0841 0.0832 0.0830 0.0828 0.0825 0.0823 

[TRAIN] Epoch[6](92/1500); Loss: 0.142799; Backpropagation: 0.1607 sec; Batch: 0.5332 sec
0.1786 0.1736 0.1665 0.1688 0.1572 0.1429 0.1364 0.1320 0.1303 0.1295 0.1288 0.1285 0.1282 0.1279 0.1278 0.1277 

[TRAIN] Epoch[6](93/1500); Loss: 0.103241; Backpropagation: 0.1115 sec; Batch: 0.4778 sec
0.2007 0.1785 0.1528 0.1122 0.0988 0.0879 0.0837 0.0828 0.0825 0.0819 0.0817 0.0818 0.0816 0.0816 0.0816 0.0817 

[TRAIN] Epoch[6](94/1500); Loss: 0.078818; Backpropagation: 0.0980 sec; Batch: 0.4363 sec
0.1596 0.1272 0.1195 0.0834 0.0747 0.0660 0.0651 0.0647 0.0641 0.0623 0.0622 0.0621 0.0622 0.0626 0.0627 0.0628 

[TRAIN] Epoch[6](95/1500); Loss: 0.109586; Backpropagation: 0.0959 sec; Batch: 0.4314 sec
0.2418 0.2078 0.1881 0.1242 0.1023 0.0874 0.0829 0.0819 0.0808 0.0800 0.0798 0.0795 0.0794 0.0793 0.0791 0.0789 

[TRAIN] Epoch[6](96/1500); Loss: 0.081877; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1752 0.1240 0.1173 0.0899 0.0824 0.0679 0.0670 0.0676 0.0663 0.0654 0.0647 0.0644 0.0643 0.0644 0.0645 0.0647 

[TRAIN] Epoch[6](97/1500); Loss: 0.137151; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.1887 0.2165 0.1874 0.1613 0.1395 0.1264 0.1218 0.1190 0.1183 0.1175 0.1169 0.1165 0.1163 0.1163 0.1162 0.1158 

[TRAIN] Epoch[6](98/1500); Loss: 0.051916; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1299 0.0831 0.0756 0.0508 0.0537 0.0427 0.0407 0.0395 0.0392 0.0390 0.0391 0.0392 0.0392 0.0394 0.0396 0.0400 

[TRAIN] Epoch[6](99/1500); Loss: 0.136323; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2331 0.2060 0.1897 0.1515 0.1396 0.1255 0.1192 0.1153 0.1150 0.1136 0.1129 0.1125 0.1122 0.1119 0.1117 0.1117 

[TRAIN] Epoch[6](100/1500); Loss: 0.087173; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1916 0.1243 0.1166 0.0966 0.0939 0.0745 0.0716 0.0696 0.0685 0.0691 0.0691 0.0691 0.0695 0.0697 0.0703 0.0707 

[TRAIN] Epoch[6](101/1500); Loss: 0.164792; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.2366 0.2786 0.2425 0.2120 0.1780 0.1538 0.1394 0.1355 0.1338 0.1333 0.1327 0.1325 0.1322 0.1318 0.1318 0.1321 

[TRAIN] Epoch[6](102/1500); Loss: 0.071946; Backpropagation: 0.0932 sec; Batch: 0.4277 sec
0.1590 0.1099 0.1030 0.0816 0.0754 0.0604 0.0596 0.0576 0.0565 0.0559 0.0555 0.0553 0.0554 0.0553 0.0553 0.0555 

[TRAIN] Epoch[6](103/1500); Loss: 0.119028; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1948 0.2111 0.1810 0.1591 0.1301 0.1093 0.0991 0.0957 0.0936 0.0923 0.0914 0.0904 0.0898 0.0892 0.0888 0.0887 

[TRAIN] Epoch[6](104/1500); Loss: 0.079456; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1443 0.1235 0.1113 0.0881 0.0790 0.0726 0.0698 0.0673 0.0660 0.0652 0.0645 0.0642 0.0639 0.0639 0.0639 0.0639 

[TRAIN] Epoch[6](105/1500); Loss: 0.094184; Backpropagation: 0.0933 sec; Batch: 0.4301 sec
0.1630 0.1310 0.1242 0.0924 0.0887 0.0861 0.0852 0.0835 0.0826 0.0821 0.0816 0.0814 0.0813 0.0812 0.0812 0.0813 

[TRAIN] Epoch[6](106/1500); Loss: 0.128615; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1792 0.1649 0.1590 0.1527 0.1406 0.1244 0.1202 0.1144 0.1148 0.1131 0.1124 0.1124 0.1123 0.1124 0.1124 0.1125 

[TRAIN] Epoch[6](107/1500); Loss: 0.156836; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.1735 0.1761 0.1724 0.1791 0.1682 0.1532 0.1510 0.1496 0.1491 0.1485 0.1482 0.1482 0.1482 0.1481 0.1480 0.1479 

[TRAIN] Epoch[6](108/1500); Loss: 0.091806; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1863 0.1714 0.1563 0.1217 0.1004 0.0783 0.0690 0.0684 0.0675 0.0646 0.0644 0.0643 0.0642 0.0640 0.0640 0.0642 

[TRAIN] Epoch[6](109/1500); Loss: 0.117910; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1427 0.1285 0.1271 0.1314 0.1217 0.1156 0.1143 0.1134 0.1125 0.1117 0.1112 0.1112 0.1110 0.1109 0.1115 0.1118 

[TRAIN] Epoch[6](110/1500); Loss: 0.113691; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2716 0.3737 0.3017 0.2299 0.1401 0.0683 0.0552 0.0456 0.0429 0.0408 0.0396 0.0404 0.0409 0.0411 0.0432 0.0440 

[TRAIN] Epoch[6](111/1500); Loss: 0.152134; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1642 0.1594 0.1588 0.1751 0.1651 0.1503 0.1481 0.1473 0.1467 0.1465 0.1460 0.1456 0.1454 0.1453 0.1452 0.1450 

[TRAIN] Epoch[6](112/1500); Loss: 0.115234; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2066 0.2319 0.1980 0.1541 0.1185 0.0986 0.0896 0.0837 0.0835 0.0821 0.0821 0.0826 0.0830 0.0828 0.0828 0.0837 

[TRAIN] Epoch[6](113/1500); Loss: 0.053604; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.0976 0.0643 0.0620 0.0656 0.0538 0.0517 0.0493 0.0478 0.0466 0.0459 0.0454 0.0451 0.0453 0.0457 0.0457 0.0458 

[TRAIN] Epoch[6](114/1500); Loss: 0.077787; Backpropagation: 0.0940 sec; Batch: 0.4303 sec
0.1210 0.1083 0.0983 0.0838 0.0759 0.0718 0.0701 0.0696 0.0689 0.0687 0.0683 0.0680 0.0677 0.0677 0.0682 0.0685 

[TRAIN] Epoch[6](115/1500); Loss: 0.109922; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1947 0.1569 0.1466 0.1154 0.1117 0.1014 0.0981 0.0934 0.0934 0.0928 0.0921 0.0926 0.0925 0.0923 0.0923 0.0925 

[TRAIN] Epoch[6](116/1500); Loss: 0.127747; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2308 0.2286 0.2025 0.1501 0.1282 0.1079 0.1018 0.1030 0.1030 0.0995 0.0987 0.0984 0.0980 0.0977 0.0977 0.0979 

[TRAIN] Epoch[6](117/1500); Loss: 0.212699; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.4191 0.3484 0.3376 0.2535 0.2352 0.1907 0.1710 0.1640 0.1666 0.1597 0.1592 0.1591 0.1592 0.1596 0.1599 0.1602 

[TRAIN] Epoch[6](118/1500); Loss: 0.119158; Backpropagation: 0.0943 sec; Batch: 0.4293 sec
0.1991 0.1732 0.1632 0.1316 0.1223 0.1100 0.1070 0.1052 0.1018 0.0990 0.0988 0.0990 0.0990 0.0990 0.0991 0.0992 

[TRAIN] Epoch[6](119/1500); Loss: 0.119141; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.1548 0.1554 0.1418 0.1239 0.1178 0.1125 0.1106 0.1102 0.1107 0.1104 0.1099 0.1098 0.1096 0.1095 0.1096 0.1097 

[TRAIN] Epoch[6](120/1500); Loss: 0.132872; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1854 0.1662 0.1523 0.1427 0.1318 0.1282 0.1257 0.1237 0.1227 0.1220 0.1216 0.1210 0.1208 0.1205 0.1209 0.1204 

[TRAIN] Epoch[6](121/1500); Loss: 0.141878; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.2832 0.2610 0.2454 0.1842 0.1627 0.1324 0.1178 0.1072 0.1007 0.0981 0.0971 0.0966 0.0963 0.0958 0.0957 0.0957 

[TRAIN] Epoch[6](122/1500); Loss: 0.150243; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.3127 0.2555 0.2457 0.1747 0.1515 0.1231 0.1200 0.1238 0.1196 0.1141 0.1123 0.1114 0.1105 0.1098 0.1095 0.1096 

[TRAIN] Epoch[6](123/1500); Loss: 0.123595; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2472 0.2087 0.1994 0.1567 0.1372 0.1139 0.1039 0.0934 0.0949 0.0897 0.0891 0.0888 0.0889 0.0887 0.0883 0.0886 

[TRAIN] Epoch[6](124/1500); Loss: 0.082959; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1871 0.2736 0.2059 0.1381 0.0692 0.0432 0.0431 0.0399 0.0394 0.0395 0.0401 0.0396 0.0396 0.0423 0.0432 0.0435 

[TRAIN] Epoch[6](125/1500); Loss: 0.114407; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.1423 0.1671 0.1402 0.1210 0.1129 0.1079 0.1063 0.1048 0.1043 0.1037 0.1036 0.1032 0.1031 0.1032 0.1033 0.1036 

[TRAIN] Epoch[6](126/1500); Loss: 0.143684; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1838 0.1905 0.1729 0.1576 0.1436 0.1368 0.1332 0.1322 0.1315 0.1312 0.1309 0.1307 0.1307 0.1308 0.1310 0.1316 

[TRAIN] Epoch[6](127/1500); Loss: 0.145166; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.4928 0.3758 0.3476 0.1842 0.1321 0.0611 0.0795 0.0865 0.0790 0.0702 0.0685 0.0680 0.0680 0.0693 0.0696 0.0705 

[TRAIN] Epoch[6](128/1500); Loss: 0.076580; Backpropagation: 0.0933 sec; Batch: 0.4284 sec
0.1258 0.0941 0.0894 0.0861 0.0811 0.0712 0.0700 0.0691 0.0684 0.0679 0.0673 0.0670 0.0669 0.0669 0.0669 0.0670 

[TRAIN] Epoch[6](129/1500); Loss: 0.061981; Backpropagation: 0.0942 sec; Batch: 0.4291 sec
0.0949 0.0619 0.0612 0.0696 0.0630 0.0614 0.0604 0.0594 0.0587 0.0577 0.0571 0.0567 0.0566 0.0571 0.0576 0.0583 

[TRAIN] Epoch[6](130/1500); Loss: 0.071921; Backpropagation: 0.0958 sec; Batch: 0.4301 sec
0.1223 0.1160 0.0992 0.0828 0.0725 0.0654 0.0637 0.0616 0.0606 0.0592 0.0584 0.0579 0.0577 0.0576 0.0577 0.0580 

[TRAIN] Epoch[6](131/1500); Loss: 0.147605; Backpropagation: 0.0941 sec; Batch: 0.4299 sec
0.1724 0.1667 0.1612 0.1598 0.1530 0.1453 0.1442 0.1425 0.1415 0.1407 0.1401 0.1393 0.1388 0.1387 0.1388 0.1387 

[TRAIN] Epoch[6](132/1500); Loss: 0.080519; Backpropagation: 0.0938 sec; Batch: 0.4420 sec
0.1986 0.1344 0.1245 0.0764 0.0773 0.0655 0.0630 0.0618 0.0609 0.0610 0.0606 0.0606 0.0609 0.0610 0.0609 0.0608 

[TRAIN] Epoch[6](133/1500); Loss: 0.080192; Backpropagation: 0.0934 sec; Batch: 0.4323 sec
0.1347 0.1620 0.1186 0.0882 0.0733 0.0653 0.0642 0.0645 0.0645 0.0640 0.0638 0.0635 0.0639 0.0640 0.0640 0.0646 

[TRAIN] Epoch[6](134/1500); Loss: 0.090271; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1802 0.1275 0.1164 0.1031 0.0983 0.0797 0.0768 0.0750 0.0739 0.0735 0.0732 0.0729 0.0730 0.0737 0.0736 0.0735 

[TRAIN] Epoch[6](135/1500); Loss: 0.110530; Backpropagation: 0.0945 sec; Batch: 0.4298 sec
0.1804 0.2053 0.1745 0.1361 0.1064 0.0956 0.0912 0.0896 0.0885 0.0871 0.0863 0.0861 0.0854 0.0851 0.0853 0.0856 

[TRAIN] Epoch[6](136/1500); Loss: 0.152136; Backpropagation: 0.0958 sec; Batch: 0.4304 sec
0.2284 0.2130 0.1998 0.1796 0.1616 0.1423 0.1364 0.1334 0.1325 0.1306 0.1302 0.1297 0.1295 0.1292 0.1291 0.1291 

[TRAIN] Epoch[6](137/1500); Loss: 0.082269; Backpropagation: 0.0943 sec; Batch: 0.4284 sec
0.1517 0.1051 0.1015 0.0960 0.0866 0.0774 0.0736 0.0709 0.0702 0.0696 0.0691 0.0686 0.0688 0.0689 0.0691 0.0693 

[TRAIN] Epoch[6](138/1500); Loss: 0.116663; Backpropagation: 0.0933 sec; Batch: 0.4291 sec
0.1523 0.1677 0.1469 0.1333 0.1213 0.1099 0.1047 0.1027 0.1027 0.1024 0.1025 0.1028 0.1033 0.1041 0.1047 0.1055 

[TRAIN] Epoch[6](139/1500); Loss: 0.080668; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2080 0.1650 0.1454 0.0819 0.0694 0.0714 0.0606 0.0548 0.0540 0.0535 0.0535 0.0536 0.0540 0.0543 0.0553 0.0561 

[TRAIN] Epoch[6](140/1500); Loss: 0.115357; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2024 0.2289 0.1898 0.1367 0.1103 0.0929 0.0893 0.0944 0.0916 0.0880 0.0871 0.0867 0.0865 0.0864 0.0869 0.0877 

[TRAIN] Epoch[6](141/1500); Loss: 0.098321; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1533 0.2038 0.1589 0.1157 0.0882 0.0802 0.0793 0.0783 0.0779 0.0773 0.0766 0.0764 0.0765 0.0770 0.0768 0.0768 

[TRAIN] Epoch[6](142/1500); Loss: 0.077902; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1311 0.1010 0.0930 0.0991 0.0813 0.0764 0.0705 0.0683 0.0671 0.0662 0.0656 0.0656 0.0655 0.0652 0.0651 0.0654 

[TRAIN] Epoch[6](143/1500); Loss: 0.123547; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1949 0.1558 0.1474 0.1330 0.1252 0.1141 0.1127 0.1111 0.1105 0.1104 0.1103 0.1103 0.1102 0.1103 0.1103 0.1103 

[TRAIN] Epoch[6](144/1500); Loss: 0.061291; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.0989 0.1194 0.0856 0.0721 0.0598 0.0538 0.0506 0.0496 0.0489 0.0483 0.0482 0.0488 0.0488 0.0489 0.0492 0.0496 

[TRAIN] Epoch[6](145/1500); Loss: 0.094135; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.1625 0.1399 0.1275 0.1024 0.0933 0.0842 0.0812 0.0806 0.0794 0.0793 0.0790 0.0789 0.0789 0.0793 0.0798 0.0800 

[TRAIN] Epoch[6](146/1500); Loss: 0.096504; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1170 0.1205 0.1044 0.1063 0.0988 0.0918 0.0911 0.0901 0.0901 0.0902 0.0903 0.0903 0.0903 0.0905 0.0911 0.0914 

[TRAIN] Epoch[6](147/1500); Loss: 0.113700; Backpropagation: 0.0959 sec; Batch: 0.4306 sec
0.1924 0.1774 0.1620 0.1399 0.1161 0.0988 0.0952 0.0970 0.0955 0.0932 0.0928 0.0923 0.0919 0.0918 0.0916 0.0913 

[TRAIN] Epoch[6](148/1500); Loss: 0.114593; Backpropagation: 0.0959 sec; Batch: 0.4305 sec
0.3168 0.2688 0.2497 0.1575 0.1260 0.0847 0.0727 0.0735 0.0732 0.0619 0.0599 0.0582 0.0578 0.0575 0.0576 0.0577 

[TRAIN] Epoch[6](149/1500); Loss: 0.150421; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1955 0.1823 0.1744 0.1651 0.1534 0.1439 0.1410 0.1395 0.1390 0.1389 0.1388 0.1388 0.1389 0.1390 0.1391 0.1391 

[TRAIN] Epoch[6](150/1500); Loss: 0.145670; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.4821 0.3674 0.3441 0.1938 0.1451 0.0663 0.0801 0.0833 0.0754 0.0695 0.0689 0.0692 0.0695 0.0708 0.0721 0.0731 

[TRAIN] Epoch[6](151/1500); Loss: 0.096671; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.2352 0.1835 0.1677 0.1018 0.0942 0.0776 0.0728 0.0728 0.0708 0.0682 0.0675 0.0669 0.0669 0.0670 0.0671 0.0669 

[TRAIN] Epoch[6](152/1500); Loss: 0.131219; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1658 0.1522 0.1487 0.1337 0.1305 0.1262 0.1252 0.1234 0.1230 0.1230 0.1231 0.1234 0.1240 0.1247 0.1257 0.1269 

[TRAIN] Epoch[6](153/1500); Loss: 0.094945; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1905 0.1328 0.1211 0.0994 0.0913 0.0851 0.0823 0.0808 0.0802 0.0799 0.0799 0.0793 0.0793 0.0791 0.0790 0.0793 

[TRAIN] Epoch[6](154/1500); Loss: 0.108635; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2600 0.3518 0.2769 0.2093 0.1183 0.0571 0.0502 0.0463 0.0465 0.0466 0.0457 0.0449 0.0447 0.0458 0.0467 0.0473 

[TRAIN] Epoch[6](155/1500); Loss: 0.121337; Backpropagation: 0.0936 sec; Batch: 0.4290 sec
0.3329 0.2701 0.2504 0.1455 0.1185 0.0849 0.0791 0.0767 0.0761 0.0721 0.0717 0.0718 0.0720 0.0726 0.0729 0.0741 

[TRAIN] Epoch[6](156/1500); Loss: 0.096081; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1390 0.1518 0.1278 0.1111 0.0977 0.0884 0.0838 0.0832 0.0826 0.0823 0.0820 0.0819 0.0816 0.0814 0.0813 0.0814 

[TRAIN] Epoch[6](157/1500); Loss: 0.142386; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1704 0.1819 0.1620 0.1503 0.1412 0.1363 0.1348 0.1345 0.1340 0.1336 0.1336 0.1334 0.1331 0.1332 0.1330 0.1329 

[TRAIN] Epoch[6](158/1500); Loss: 0.115470; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1703 0.1573 0.1428 0.1228 0.1115 0.1063 0.1036 0.1033 0.1032 0.1032 0.1035 0.1037 0.1036 0.1038 0.1043 0.1045 

[TRAIN] Epoch[6](159/1500); Loss: 0.127573; Backpropagation: 0.0959 sec; Batch: 0.4467 sec
0.2739 0.3007 0.2596 0.2104 0.1625 0.1192 0.0809 0.0737 0.0727 0.0716 0.0706 0.0697 0.0693 0.0691 0.0687 0.0688 

[TRAIN] Epoch[6](160/1500); Loss: 0.049299; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.0946 0.0517 0.0503 0.0640 0.0546 0.0460 0.0450 0.0440 0.0431 0.0422 0.0421 0.0420 0.0421 0.0422 0.0423 0.0427 

[TRAIN] Epoch[6](161/1500); Loss: 0.151268; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.2417 0.2300 0.2154 0.1782 0.1642 0.1473 0.1408 0.1324 0.1276 0.1231 0.1207 0.1209 0.1212 0.1192 0.1188 0.1186 

[TRAIN] Epoch[6](162/1500); Loss: 0.052942; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1904 0.1169 0.1080 0.0701 0.0584 0.0309 0.0283 0.0299 0.0287 0.0270 0.0262 0.0261 0.0262 0.0263 0.0267 0.0270 

[TRAIN] Epoch[6](163/1500); Loss: 0.076214; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1337 0.1288 0.1075 0.0990 0.0821 0.0731 0.0669 0.0645 0.0625 0.0602 0.0585 0.0574 0.0569 0.0565 0.0560 0.0558 

[TRAIN] Epoch[6](164/1500); Loss: 0.160354; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1871 0.1783 0.1703 0.1590 0.1561 0.1554 0.1551 0.1548 0.1549 0.1552 0.1557 0.1561 0.1566 0.1567 0.1569 0.1574 

[TRAIN] Epoch[6](165/1500); Loss: 0.076796; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1103 0.1180 0.0935 0.0822 0.0726 0.0713 0.0693 0.0692 0.0688 0.0678 0.0672 0.0675 0.0678 0.0676 0.0676 0.0681 

[TRAIN] Epoch[6](166/1500); Loss: 0.122104; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.1662 0.1786 0.1526 0.1400 0.1269 0.1169 0.1121 0.1096 0.1081 0.1071 0.1069 0.1066 0.1060 0.1054 0.1052 0.1054 

[TRAIN] Epoch[6](167/1500); Loss: 0.080044; Backpropagation: 0.0942 sec; Batch: 0.4293 sec
0.2260 0.1524 0.1439 0.0972 0.0868 0.0566 0.0530 0.0579 0.0543 0.0516 0.0506 0.0499 0.0499 0.0499 0.0503 0.0505 

[TRAIN] Epoch[6](168/1500); Loss: 0.141380; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.3775 0.3326 0.3122 0.2200 0.1891 0.1421 0.1147 0.0668 0.0680 0.0659 0.0647 0.0640 0.0624 0.0613 0.0605 0.0603 

[TRAIN] Epoch[6](169/1500); Loss: 0.162314; Backpropagation: 0.0941 sec; Batch: 0.4297 sec
0.2344 0.2745 0.2349 0.2071 0.1733 0.1496 0.1375 0.1338 0.1338 0.1327 0.1318 0.1311 0.1304 0.1302 0.1309 0.1311 

[TRAIN] Epoch[6](170/1500); Loss: 0.144103; Backpropagation: 0.0953 sec; Batch: 0.4299 sec
0.2564 0.2503 0.2272 0.1810 0.1548 0.1291 0.1185 0.1119 0.1163 0.1097 0.1086 0.1083 0.1082 0.1084 0.1085 0.1085 

[TRAIN] Epoch[6](171/1500); Loss: 0.085190; Backpropagation: 0.0960 sec; Batch: 0.4298 sec
0.1207 0.1274 0.1066 0.0975 0.0854 0.0802 0.0772 0.0759 0.0749 0.0742 0.0739 0.0737 0.0736 0.0736 0.0740 0.0744 

[TRAIN] Epoch[6](172/1500); Loss: 0.109195; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.2545 0.2072 0.1919 0.1218 0.0962 0.0837 0.0856 0.0807 0.0791 0.0780 0.0776 0.0777 0.0779 0.0781 0.0783 0.0790 

[TRAIN] Epoch[6](173/1500); Loss: 0.105410; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1617 0.1823 0.1475 0.1352 0.1118 0.0945 0.0878 0.0862 0.0851 0.0850 0.0853 0.0849 0.0846 0.0846 0.0848 0.0851 

[TRAIN] Epoch[6](174/1500); Loss: 0.070363; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1125 0.0881 0.0823 0.0826 0.0742 0.0673 0.0658 0.0645 0.0635 0.0626 0.0619 0.0611 0.0604 0.0599 0.0597 0.0594 

[TRAIN] Epoch[6](175/1500); Loss: 0.151347; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.5263 0.4001 0.3795 0.2167 0.1822 0.0964 0.0522 0.1028 0.0805 0.0581 0.0542 0.0533 0.0535 0.0544 0.0554 0.0560 

[TRAIN] Epoch[6](176/1500); Loss: 0.054566; Backpropagation: 0.0941 sec; Batch: 0.4289 sec
0.1275 0.0754 0.0713 0.0614 0.0547 0.0469 0.0459 0.0453 0.0441 0.0432 0.0427 0.0426 0.0425 0.0430 0.0431 0.0434 

[TRAIN] Epoch[6](177/1500); Loss: 0.070918; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1088 0.1063 0.0876 0.0819 0.0747 0.0676 0.0657 0.0630 0.0612 0.0610 0.0604 0.0601 0.0596 0.0592 0.0587 0.0587 

[TRAIN] Epoch[6](178/1500); Loss: 0.076890; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1343 0.0948 0.0927 0.0915 0.0821 0.0748 0.0731 0.0706 0.0679 0.0656 0.0644 0.0639 0.0640 0.0639 0.0633 0.0633 

[TRAIN] Epoch[6](179/1500); Loss: 0.098201; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1712 0.2444 0.1814 0.1351 0.0955 0.0720 0.0675 0.0661 0.0662 0.0666 0.0670 0.0670 0.0674 0.0673 0.0678 0.0687 

[TRAIN] Epoch[6](180/1500); Loss: 0.115674; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.3162 0.2403 0.2306 0.1349 0.1130 0.0743 0.0770 0.0758 0.0751 0.0738 0.0725 0.0728 0.0726 0.0728 0.0733 0.0761 

[TRAIN] Epoch[6](181/1500); Loss: 0.079083; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1464 0.1378 0.1176 0.1006 0.0837 0.0734 0.0660 0.0617 0.0605 0.0599 0.0595 0.0594 0.0596 0.0595 0.0597 0.0600 

[TRAIN] Epoch[6](182/1500); Loss: 0.064336; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.0797 0.1138 0.0805 0.0682 0.0627 0.0586 0.0575 0.0579 0.0574 0.0567 0.0561 0.0558 0.0560 0.0561 0.0560 0.0561 

[TRAIN] Epoch[6](183/1500); Loss: 0.121469; Backpropagation: 0.0960 sec; Batch: 0.4314 sec
0.1682 0.2070 0.1660 0.1374 0.1159 0.1089 0.1065 0.1048 0.1045 0.1041 0.1038 0.1035 0.1032 0.1032 0.1033 0.1031 

[TRAIN] Epoch[6](184/1500); Loss: 0.078013; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1263 0.1093 0.1002 0.0933 0.0826 0.0731 0.0709 0.0682 0.0665 0.0652 0.0647 0.0647 0.0651 0.0655 0.0659 0.0666 

[TRAIN] Epoch[6](185/1500); Loss: 0.061146; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.0916 0.0924 0.0749 0.0797 0.0652 0.0554 0.0543 0.0532 0.0524 0.0520 0.0514 0.0512 0.0513 0.0514 0.0511 0.0508 

[TRAIN] Epoch[6](186/1500); Loss: 0.094477; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1766 0.1378 0.1318 0.0924 0.0873 0.0859 0.0842 0.0805 0.0797 0.0796 0.0795 0.0793 0.0792 0.0792 0.0793 0.0794 

[TRAIN] Epoch[6](187/1500); Loss: 0.107975; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1918 0.1885 0.1637 0.1378 0.1156 0.0972 0.0894 0.0864 0.0850 0.0835 0.0826 0.0819 0.0814 0.0811 0.0809 0.0806 

[TRAIN] Epoch[6](188/1500); Loss: 0.109625; Backpropagation: 0.0958 sec; Batch: 0.4306 sec
0.1730 0.1923 0.1625 0.1423 0.1185 0.1003 0.0924 0.0883 0.0872 0.0862 0.0855 0.0851 0.0851 0.0850 0.0851 0.0852 

[TRAIN] Epoch[6](189/1500); Loss: 0.134907; Backpropagation: 0.0961 sec; Batch: 0.4304 sec
0.2460 0.2716 0.2326 0.1838 0.1436 0.1136 0.1046 0.0999 0.0975 0.0962 0.0951 0.0947 0.0943 0.0948 0.0950 0.0953 

[TRAIN] Epoch[6](190/1500); Loss: 0.113438; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1832 0.1946 0.1702 0.1658 0.1337 0.1051 0.0912 0.0883 0.0870 0.0864 0.0858 0.0851 0.0847 0.0847 0.0847 0.0845 

[TRAIN] Epoch[6](191/1500); Loss: 0.119191; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.3602 0.2678 0.2554 0.1532 0.1333 0.0925 0.0738 0.0780 0.0686 0.0627 0.0608 0.0600 0.0597 0.0601 0.0605 0.0606 

[TRAIN] Epoch[6](192/1500); Loss: 0.150422; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.5177 0.3902 0.3675 0.2027 0.1633 0.0774 0.0495 0.1291 0.1050 0.0609 0.0588 0.0568 0.0566 0.0559 0.0574 0.0581 

[TRAIN] Epoch[6](193/1500); Loss: 0.112356; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1574 0.1546 0.1379 0.1211 0.1130 0.1053 0.1023 0.1011 0.1003 0.1006 0.1003 0.1002 0.1007 0.1009 0.1010 0.1010 

[TRAIN] Epoch[6](194/1500); Loss: 0.096179; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.2103 0.2180 0.1818 0.1301 0.0963 0.0702 0.0642 0.0672 0.0650 0.0636 0.0628 0.0620 0.0618 0.0618 0.0618 0.0621 

[TRAIN] Epoch[6](195/1500); Loss: 0.132448; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2695 0.2149 0.2085 0.1548 0.1417 0.1177 0.1103 0.1017 0.0987 0.0983 0.0985 0.0989 0.1001 0.1011 0.1019 0.1028 

[TRAIN] Epoch[6](196/1500); Loss: 0.084015; Backpropagation: 0.0940 sec; Batch: 0.4296 sec
0.1156 0.1356 0.1101 0.0938 0.0870 0.0801 0.0769 0.0728 0.0721 0.0716 0.0717 0.0716 0.0715 0.0714 0.0713 0.0712 

[TRAIN] Epoch[6](197/1500); Loss: 0.118752; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1920 0.1656 0.1596 0.1371 0.1261 0.1110 0.1076 0.1033 0.1025 0.1006 0.0999 0.0996 0.0992 0.0988 0.0985 0.0986 

[TRAIN] Epoch[6](198/1500); Loss: 0.147402; Backpropagation: 0.0941 sec; Batch: 0.4293 sec
0.1897 0.1780 0.1711 0.1751 0.1597 0.1393 0.1398 0.1386 0.1378 0.1357 0.1349 0.1337 0.1332 0.1317 0.1307 0.1295 

[TRAIN] Epoch[6](199/1500); Loss: 0.113586; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.2260 0.2638 0.2209 0.1841 0.1451 0.1145 0.0825 0.0674 0.0654 0.0644 0.0640 0.0641 0.0639 0.0635 0.0637 0.0638 

[TRAIN] Epoch[6](200/1500); Loss: 0.051079; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.0729 0.1197 0.0729 0.0528 0.0485 0.0439 0.0424 0.0412 0.0405 0.0398 0.0401 0.0399 0.0400 0.0404 0.0410 0.0413 

[TRAIN] Epoch[6](201/1500); Loss: 0.159618; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2287 0.1985 0.1934 0.1762 0.1647 0.1511 0.1484 0.1468 0.1452 0.1444 0.1439 0.1431 0.1429 0.1425 0.1419 0.1421 

[TRAIN] Epoch[6](202/1500); Loss: 0.115802; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1706 0.1788 0.1538 0.1294 0.1137 0.1069 0.1036 0.1019 0.1003 0.1000 0.0999 0.0996 0.0992 0.0987 0.0984 0.0981 

[TRAIN] Epoch[6](203/1500); Loss: 0.113984; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.2584 0.2050 0.1872 0.1118 0.0924 0.1047 0.0940 0.0863 0.0852 0.0848 0.0845 0.0849 0.0855 0.0861 0.0863 0.0867 

[TRAIN] Epoch[6](204/1500); Loss: 0.060967; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.0886 0.1309 0.0879 0.0662 0.0567 0.0512 0.0496 0.0488 0.0488 0.0488 0.0489 0.0491 0.0496 0.0497 0.0499 0.0508 

[TRAIN] Epoch[6](205/1500); Loss: 0.132188; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1773 0.1531 0.1476 0.1392 0.1359 0.1274 0.1257 0.1243 0.1240 0.1235 0.1232 0.1227 0.1226 0.1226 0.1227 0.1233 

[TRAIN] Epoch[6](206/1500); Loss: 0.075208; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1899 0.1314 0.1144 0.0831 0.0862 0.0641 0.0566 0.0537 0.0527 0.0532 0.0528 0.0529 0.0528 0.0530 0.0531 0.0534 

[TRAIN] Epoch[6](207/1500); Loss: 0.110881; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2038 0.1448 0.1383 0.1104 0.1101 0.1018 0.0987 0.0975 0.0970 0.0964 0.0961 0.0958 0.0957 0.0958 0.0959 0.0961 

[TRAIN] Epoch[6](208/1500); Loss: 0.131745; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.2298 0.1807 0.1737 0.1323 0.1267 0.1246 0.1185 0.1169 0.1142 0.1132 0.1135 0.1139 0.1133 0.1124 0.1120 0.1124 

[TRAIN] Epoch[6](209/1500); Loss: 0.127578; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2079 0.2599 0.2142 0.1757 0.1309 0.1024 0.0975 0.0951 0.0944 0.0945 0.0942 0.0941 0.0947 0.0950 0.0955 0.0953 

[TRAIN] Epoch[6](210/1500); Loss: 0.071252; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1294 0.1070 0.0912 0.0762 0.0739 0.0641 0.0613 0.0598 0.0594 0.0594 0.0590 0.0587 0.0592 0.0600 0.0604 0.0611 

[TRAIN] Epoch[6](211/1500); Loss: 0.115128; Backpropagation: 0.0951 sec; Batch: 0.4300 sec
0.2265 0.2214 0.1956 0.1397 0.1102 0.0878 0.0896 0.0929 0.0880 0.0851 0.0849 0.0845 0.0842 0.0841 0.0839 0.0838 

[TRAIN] Epoch[6](212/1500); Loss: 0.139845; Backpropagation: 0.0958 sec; Batch: 0.4306 sec
0.2128 0.2561 0.2156 0.1846 0.1520 0.1294 0.1167 0.1109 0.1097 0.1087 0.1077 0.1070 0.1067 0.1065 0.1065 0.1067 

[TRAIN] Epoch[6](213/1500); Loss: 0.067350; Backpropagation: 0.0961 sec; Batch: 0.4309 sec
0.1000 0.0897 0.0842 0.0854 0.0735 0.0642 0.0614 0.0599 0.0591 0.0581 0.0577 0.0575 0.0570 0.0566 0.0567 0.0568 

[TRAIN] Epoch[6](214/1500); Loss: 0.116313; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.3095 0.2299 0.2172 0.1169 0.0919 0.0919 0.0855 0.0856 0.0812 0.0792 0.0774 0.0774 0.0792 0.0797 0.0791 0.0795 

[TRAIN] Epoch[6](215/1500); Loss: 0.108346; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.2205 0.2251 0.1947 0.1471 0.1161 0.0959 0.0836 0.0779 0.0756 0.0730 0.0717 0.0707 0.0704 0.0702 0.0705 0.0704 

[TRAIN] Epoch[6](216/1500); Loss: 0.093873; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1345 0.1840 0.1378 0.1036 0.0843 0.0780 0.0780 0.0773 0.0783 0.0783 0.0782 0.0778 0.0776 0.0777 0.0780 0.0784 

[TRAIN] Epoch[6](217/1500); Loss: 0.055458; Backpropagation: 0.0937 sec; Batch: 0.4285 sec
0.0836 0.0544 0.0530 0.0666 0.0582 0.0540 0.0523 0.0510 0.0507 0.0508 0.0512 0.0513 0.0517 0.0521 0.0529 0.0534 

[TRAIN] Epoch[6](218/1500); Loss: 0.158990; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1761 0.1787 0.1727 0.1709 0.1636 0.1574 0.1557 0.1541 0.1535 0.1527 0.1523 0.1515 0.1513 0.1512 0.1513 0.1509 

[TRAIN] Epoch[6](219/1500); Loss: 0.072186; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1613 0.1123 0.1057 0.0947 0.0838 0.0663 0.0621 0.0563 0.0548 0.0527 0.0525 0.0513 0.0505 0.0501 0.0503 0.0502 

[TRAIN] Epoch[6](220/1500); Loss: 0.102771; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1848 0.1375 0.1306 0.1194 0.1122 0.0937 0.0903 0.0864 0.0863 0.0863 0.0861 0.0861 0.0862 0.0862 0.0861 0.0862 

[TRAIN] Epoch[6](221/1500); Loss: 0.149945; Backpropagation: 0.0932 sec; Batch: 0.4280 sec
0.1970 0.1850 0.1753 0.1611 0.1519 0.1443 0.1403 0.1389 0.1382 0.1380 0.1378 0.1379 0.1380 0.1383 0.1384 0.1387 

[TRAIN] Epoch[6](222/1500); Loss: 0.112574; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.1920 0.2212 0.1825 0.1439 0.1132 0.0957 0.0897 0.0874 0.0862 0.0846 0.0838 0.0838 0.0838 0.0843 0.0846 0.0846 

[TRAIN] Epoch[6](223/1500); Loss: 0.061451; Backpropagation: 0.0941 sec; Batch: 0.4274 sec
0.1688 0.1015 0.0944 0.0773 0.0683 0.0458 0.0448 0.0436 0.0424 0.0421 0.0420 0.0419 0.0421 0.0423 0.0426 0.0432 

[TRAIN] Epoch[6](224/1500); Loss: 0.136008; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1958 0.1809 0.1689 0.1476 0.1391 0.1291 0.1254 0.1236 0.1224 0.1217 0.1211 0.1207 0.1201 0.1199 0.1199 0.1198 

[TRAIN] Epoch[6](225/1500); Loss: 0.098517; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1596 0.1306 0.1215 0.1034 0.0982 0.0926 0.0906 0.0880 0.0872 0.0869 0.0866 0.0864 0.0862 0.0861 0.0862 0.0862 

[TRAIN] Epoch[6](226/1500); Loss: 0.078760; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.2716 0.1820 0.1672 0.0581 0.0491 0.0797 0.0545 0.0466 0.0441 0.0430 0.0421 0.0447 0.0446 0.0442 0.0440 0.0446 

[TRAIN] Epoch[6](227/1500); Loss: 0.079324; Backpropagation: 0.0935 sec; Batch: 0.4285 sec
0.2041 0.1360 0.1280 0.0711 0.0680 0.0683 0.0636 0.0598 0.0592 0.0592 0.0591 0.0588 0.0586 0.0585 0.0584 0.0584 

[TRAIN] Epoch[6](228/1500); Loss: 0.105794; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1310 0.1385 0.1213 0.1070 0.1036 0.1005 0.0991 0.0991 0.0991 0.0990 0.0988 0.0990 0.0992 0.0991 0.0991 0.0992 

[TRAIN] Epoch[6](229/1500); Loss: 0.222181; Backpropagation: 0.0959 sec; Batch: 0.4309 sec
0.3448 0.3083 0.2993 0.2563 0.2414 0.2096 0.2004 0.1926 0.1879 0.1871 0.1857 0.1873 0.1874 0.1881 0.1892 0.1894 

[TRAIN] Epoch[6](230/1500); Loss: 0.127455; Backpropagation: 0.0961 sec; Batch: 0.4304 sec
0.1722 0.1693 0.1489 0.1379 0.1235 0.1182 0.1170 0.1167 0.1165 0.1165 0.1164 0.1166 0.1166 0.1171 0.1177 0.1181 

[TRAIN] Epoch[6](231/1500); Loss: 0.111297; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.2355 0.2159 0.1919 0.1366 0.1207 0.0961 0.0828 0.0814 0.0833 0.0781 0.0770 0.0764 0.0761 0.0761 0.0762 0.0767 

[TRAIN] Epoch[6](232/1500); Loss: 0.119498; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.2710 0.3700 0.2958 0.2335 0.1495 0.0829 0.0594 0.0527 0.0500 0.0483 0.0502 0.0495 0.0492 0.0497 0.0497 0.0506 

[TRAIN] Epoch[6](233/1500); Loss: 0.087164; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1390 0.1097 0.1059 0.1012 0.0918 0.0817 0.0792 0.0783 0.0774 0.0765 0.0761 0.0758 0.0757 0.0756 0.0754 0.0755 

[TRAIN] Epoch[6](234/1500); Loss: 0.115082; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1362 0.1465 0.1287 0.1185 0.1116 0.1103 0.1090 0.1086 0.1084 0.1084 0.1084 0.1087 0.1090 0.1093 0.1097 0.1101 

[TRAIN] Epoch[6](235/1500); Loss: 0.091605; Backpropagation: 0.0949 sec; Batch: 0.4297 sec
0.1257 0.1518 0.1208 0.1038 0.0910 0.0831 0.0812 0.0800 0.0791 0.0789 0.0786 0.0784 0.0783 0.0782 0.0783 0.0784 

[TRAIN] Epoch[6](236/1500); Loss: 0.098871; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1369 0.1430 0.1185 0.1142 0.1013 0.0929 0.0913 0.0895 0.0884 0.0874 0.0868 0.0866 0.0862 0.0862 0.0864 0.0864 

[TRAIN] Epoch[6](237/1500); Loss: 0.089777; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.2373 0.1754 0.1683 0.1375 0.1154 0.0832 0.0723 0.0539 0.0506 0.0513 0.0487 0.0485 0.0481 0.0485 0.0487 0.0489 

[TRAIN] Epoch[6](238/1500); Loss: 0.129321; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1783 0.2063 0.1755 0.1531 0.1328 0.1202 0.1138 0.1125 0.1115 0.1108 0.1101 0.1095 0.1090 0.1087 0.1086 0.1084 

[TRAIN] Epoch[6](239/1500); Loss: 0.160480; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2159 0.2411 0.2110 0.1903 0.1684 0.1517 0.1450 0.1420 0.1402 0.1387 0.1379 0.1370 0.1369 0.1374 0.1375 0.1369 

[TRAIN] Epoch[6](240/1500); Loss: 0.103479; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1574 0.1512 0.1380 0.1291 0.1131 0.1002 0.0935 0.0891 0.0886 0.0868 0.0859 0.0851 0.0846 0.0844 0.0842 0.0844 

[TRAIN] Epoch[6](241/1500); Loss: 0.106262; Backpropagation: 0.0945 sec; Batch: 0.4290 sec
0.2193 0.2225 0.1869 0.1300 0.1066 0.0905 0.0790 0.0748 0.0739 0.0733 0.0731 0.0731 0.0734 0.0740 0.0745 0.0752 

[TRAIN] Epoch[6](242/1500); Loss: 0.131270; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2897 0.2733 0.2460 0.1793 0.1438 0.1045 0.0889 0.0968 0.0924 0.0862 0.0847 0.0836 0.0831 0.0828 0.0827 0.0825 

[TRAIN] Epoch[6](243/1500); Loss: 0.142618; Backpropagation: 0.0942 sec; Batch: 0.4288 sec
0.2471 0.2277 0.2051 0.1765 0.1522 0.1308 0.1177 0.1154 0.1142 0.1144 0.1136 0.1144 0.1137 0.1133 0.1130 0.1129 

[TRAIN] Epoch[6](244/1500); Loss: 0.076890; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1581 0.1161 0.1063 0.0790 0.0804 0.0686 0.0651 0.0637 0.0628 0.0628 0.0619 0.0612 0.0609 0.0608 0.0609 0.0616 

[TRAIN] Epoch[6](245/1500); Loss: 0.097591; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2720 0.2342 0.2111 0.1337 0.1023 0.0716 0.0637 0.0637 0.0590 0.0518 0.0505 0.0501 0.0496 0.0494 0.0493 0.0493 

[TRAIN] Epoch[6](246/1500); Loss: 0.078970; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2376 0.1536 0.1403 0.0908 0.0819 0.0563 0.0564 0.0525 0.0507 0.0498 0.0494 0.0488 0.0487 0.0488 0.0487 0.0492 

[TRAIN] Epoch[6](247/1500); Loss: 0.083715; Backpropagation: 0.0960 sec; Batch: 0.4308 sec
0.2015 0.2712 0.2078 0.1539 0.0902 0.0473 0.0408 0.0364 0.0351 0.0357 0.0366 0.0356 0.0369 0.0368 0.0366 0.0371 

[TRAIN] Epoch[6](248/1500); Loss: 0.115918; Backpropagation: 0.0958 sec; Batch: 0.4305 sec
0.1937 0.2467 0.1974 0.1585 0.1180 0.0949 0.0864 0.0841 0.0842 0.0840 0.0839 0.0841 0.0843 0.0845 0.0849 0.0852 

[TRAIN] Epoch[6](249/1500); Loss: 0.140048; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.2645 0.2002 0.1906 0.1509 0.1396 0.1183 0.1160 0.1183 0.1156 0.1149 0.1160 0.1174 0.1186 0.1190 0.1198 0.1210 

[TRAIN] Epoch[6](250/1500); Loss: 0.154341; Backpropagation: 0.0941 sec; Batch: 0.4296 sec
0.2117 0.1963 0.1801 0.1653 0.1553 0.1438 0.1424 0.1416 0.1414 0.1415 0.1419 0.1417 0.1417 0.1419 0.1415 0.1412 

[TRAIN] Epoch[6](251/1500); Loss: 0.096640; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.1284 0.1731 0.1302 0.1064 0.0901 0.0863 0.0849 0.0847 0.0835 0.0829 0.0829 0.0828 0.0824 0.0822 0.0826 0.0828 

[TRAIN] Epoch[6](252/1500); Loss: 0.105168; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.3501 0.2448 0.2274 0.1183 0.0932 0.0700 0.0718 0.0644 0.0578 0.0555 0.0544 0.0548 0.0545 0.0549 0.0553 0.0554 

[TRAIN] Epoch[6](253/1500); Loss: 0.112946; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1506 0.1318 0.1250 0.1185 0.1131 0.1103 0.1091 0.1083 0.1067 0.1058 0.1050 0.1045 0.1046 0.1047 0.1047 0.1045 

[TRAIN] Epoch[6](254/1500); Loss: 0.076098; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1029 0.1043 0.0926 0.0912 0.0778 0.0716 0.0704 0.0690 0.0679 0.0674 0.0674 0.0670 0.0671 0.0670 0.0671 0.0670 

[TRAIN] Epoch[6](255/1500); Loss: 0.076097; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.1460 0.1226 0.1000 0.0682 0.0690 0.0673 0.0658 0.0644 0.0635 0.0628 0.0641 0.0640 0.0640 0.0641 0.0652 0.0663 

[TRAIN] Epoch[6](256/1500); Loss: 0.107893; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.2651 0.3649 0.2855 0.2136 0.1166 0.0524 0.0524 0.0436 0.0410 0.0396 0.0407 0.0425 0.0418 0.0410 0.0421 0.0433 

[TRAIN] Epoch[6](257/1500); Loss: 0.214991; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.3275 0.3053 0.2913 0.2510 0.2362 0.2047 0.1942 0.1859 0.1824 0.1807 0.1787 0.1794 0.1804 0.1804 0.1805 0.1812 

[TRAIN] Epoch[6](258/1500); Loss: 0.086307; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1431 0.1829 0.1350 0.1020 0.0775 0.0707 0.0684 0.0680 0.0677 0.0666 0.0660 0.0661 0.0666 0.0668 0.0668 0.0666 

[TRAIN] Epoch[6](259/1500); Loss: 0.072072; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1130 0.1311 0.1000 0.0792 0.0677 0.0634 0.0621 0.0619 0.0607 0.0598 0.0595 0.0590 0.0587 0.0588 0.0590 0.0593 

[TRAIN] Epoch[6](260/1500); Loss: 0.111543; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.2001 0.1656 0.1477 0.1058 0.1003 0.0982 0.0977 0.0970 0.0967 0.0964 0.0968 0.0968 0.0961 0.0961 0.0968 0.0966 

[TRAIN] Epoch[6](261/1500); Loss: 0.077670; Backpropagation: 0.0936 sec; Batch: 0.4279 sec
0.1323 0.1785 0.1311 0.0915 0.0695 0.0617 0.0603 0.0589 0.0582 0.0574 0.0570 0.0572 0.0572 0.0572 0.0572 0.0574 

[TRAIN] Epoch[6](262/1500); Loss: 0.152607; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.2227 0.2599 0.2217 0.1900 0.1619 0.1416 0.1287 0.1273 0.1260 0.1249 0.1241 0.1233 0.1225 0.1225 0.1222 0.1224 

[TRAIN] Epoch[6](263/1500); Loss: 0.091854; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1678 0.2121 0.1601 0.1258 0.0928 0.0706 0.0654 0.0634 0.0630 0.0635 0.0634 0.0632 0.0634 0.0640 0.0650 0.0661 

[TRAIN] Epoch[6](264/1500); Loss: 0.127682; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1764 0.1826 0.1604 0.1383 0.1254 0.1195 0.1179 0.1164 0.1152 0.1142 0.1135 0.1130 0.1128 0.1127 0.1124 0.1122 

[TRAIN] Epoch[6](265/1500); Loss: 0.061845; Backpropagation: 0.0935 sec; Batch: 0.4286 sec
0.0775 0.1168 0.0769 0.0652 0.0597 0.0556 0.0544 0.0540 0.0536 0.0532 0.0536 0.0538 0.0537 0.0536 0.0539 0.0542 

[TRAIN] Epoch[6](266/1500); Loss: 0.120605; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1726 0.1895 0.1597 0.1332 0.1124 0.1084 0.1065 0.1056 0.1050 0.1051 0.1053 0.1052 0.1051 0.1051 0.1054 0.1055 

[TRAIN] Epoch[6](267/1500); Loss: 0.056934; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2012 0.1021 0.0903 0.0545 0.0769 0.0414 0.0368 0.0346 0.0353 0.0343 0.0339 0.0328 0.0346 0.0347 0.0338 0.0338 

[TRAIN] Epoch[6](268/1500); Loss: 0.104025; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1925 0.1546 0.1458 0.1112 0.0999 0.0907 0.0921 0.0884 0.0864 0.0860 0.0858 0.0864 0.0865 0.0862 0.0859 0.0859 

[TRAIN] Epoch[6](269/1500); Loss: 0.064593; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1554 0.1153 0.1042 0.0769 0.0675 0.0549 0.0491 0.0469 0.0460 0.0451 0.0446 0.0449 0.0452 0.0454 0.0458 0.0464 

[TRAIN] Epoch[6](270/1500); Loss: 0.092962; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1463 0.1545 0.1288 0.1069 0.0914 0.0871 0.0845 0.0827 0.0812 0.0790 0.0769 0.0751 0.0738 0.0732 0.0728 0.0730 

[TRAIN] Epoch[6](271/1500); Loss: 0.121850; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1742 0.1839 0.1577 0.1360 0.1186 0.1111 0.1094 0.1086 0.1085 0.1078 0.1070 0.1062 0.1055 0.1052 0.1050 0.1049 

[TRAIN] Epoch[6](272/1500); Loss: 0.119505; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1729 0.1679 0.1514 0.1300 0.1215 0.1136 0.1100 0.1083 0.1074 0.1063 0.1051 0.1042 0.1036 0.1034 0.1033 0.1032 

[TRAIN] Epoch[6](273/1500); Loss: 0.086079; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1426 0.1303 0.1164 0.0974 0.0798 0.0752 0.0739 0.0744 0.0743 0.0741 0.0737 0.0733 0.0731 0.0730 0.0728 0.0728 

[TRAIN] Epoch[6](274/1500); Loss: 0.161213; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.3354 0.2816 0.2750 0.1968 0.1790 0.1501 0.1351 0.1213 0.1156 0.1137 0.1130 0.1130 0.1127 0.1127 0.1122 0.1121 

[TRAIN] Epoch[6](275/1500); Loss: 0.115529; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1466 0.1232 0.1202 0.1143 0.1126 0.1132 0.1132 0.1127 0.1122 0.1119 0.1118 0.1115 0.1113 0.1113 0.1113 0.1112 

[TRAIN] Epoch[6](276/1500); Loss: 0.137847; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.3208 0.2727 0.2651 0.1853 0.1659 0.1328 0.1159 0.0970 0.0902 0.0834 0.0816 0.0792 0.0788 0.0786 0.0790 0.0794 

[TRAIN] Epoch[6](277/1500); Loss: 0.059354; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.0791 0.1068 0.0687 0.0543 0.0519 0.0513 0.0522 0.0525 0.0530 0.0534 0.0536 0.0539 0.0542 0.0545 0.0549 0.0554 

[TRAIN] Epoch[6](278/1500); Loss: 0.218959; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.3606 0.3401 0.3243 0.2595 0.2299 0.1995 0.1940 0.1863 0.1838 0.1803 0.1782 0.1765 0.1750 0.1732 0.1717 0.1703 

[TRAIN] Epoch[6](279/1500); Loss: 0.130578; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1998 0.1706 0.1669 0.1413 0.1374 0.1275 0.1243 0.1197 0.1174 0.1152 0.1137 0.1125 0.1115 0.1108 0.1104 0.1102 

[TRAIN] Epoch[6](280/1500); Loss: 0.125425; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1677 0.1442 0.1411 0.1247 0.1226 0.1189 0.1178 0.1171 0.1172 0.1176 0.1180 0.1186 0.1193 0.1200 0.1206 0.1214 

[TRAIN] Epoch[6](281/1500); Loss: 0.096070; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1413 0.1476 0.1222 0.0964 0.0873 0.0860 0.0853 0.0852 0.0856 0.0857 0.0857 0.0856 0.0859 0.0859 0.0858 0.0859 

[TRAIN] Epoch[6](282/1500); Loss: 0.036953; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.0611 0.0398 0.0363 0.0298 0.0285 0.0290 0.0298 0.0311 0.0324 0.0339 0.0356 0.0374 0.0390 0.0407 0.0425 0.0443 

[TRAIN] Epoch[6](283/1500); Loss: 0.120476; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1966 0.2078 0.1775 0.1428 0.1145 0.0982 0.0983 0.0977 0.0976 0.0982 0.0988 0.0992 0.0995 0.1000 0.1003 0.1008 

[TRAIN] Epoch[6](284/1500); Loss: 0.150781; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2014 0.2209 0.1869 0.1519 0.1465 0.1408 0.1392 0.1360 0.1361 0.1358 0.1359 0.1357 0.1360 0.1361 0.1363 0.1368 

[TRAIN] Epoch[6](285/1500); Loss: 0.077358; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1266 0.1015 0.0963 0.0778 0.0721 0.0687 0.0689 0.0690 0.0692 0.0691 0.0692 0.0694 0.0696 0.0699 0.0701 0.0704 

[TRAIN] Epoch[6](286/1500); Loss: 0.146338; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.2754 0.2279 0.2258 0.1753 0.1664 0.1474 0.1399 0.1288 0.1235 0.1163 0.1118 0.1063 0.1030 0.1001 0.0978 0.0957 

[TRAIN] Epoch[6](287/1500); Loss: 0.153179; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.3346 0.2820 0.2822 0.2145 0.1990 0.1701 0.1528 0.1239 0.1109 0.0955 0.0899 0.0817 0.0790 0.0775 0.0776 0.0796 

[TRAIN] Epoch[6](288/1500); Loss: 0.086875; Backpropagation: 0.0964 sec; Batch: 0.4313 sec
0.1353 0.1038 0.1031 0.0912 0.0895 0.0858 0.0841 0.0813 0.0799 0.0785 0.0777 0.0770 0.0763 0.0758 0.0755 0.0753 

[TRAIN] Epoch[6](289/1500); Loss: 0.150350; Backpropagation: 0.0959 sec; Batch: 0.4308 sec
0.1979 0.2213 0.1886 0.1635 0.1513 0.1430 0.1404 0.1377 0.1366 0.1349 0.1339 0.1323 0.1321 0.1312 0.1305 0.1304 

[TRAIN] Epoch[6](290/1500); Loss: 0.104409; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.2383 0.1998 0.1951 0.1341 0.1156 0.0881 0.0743 0.0750 0.0687 0.0693 0.0692 0.0688 0.0684 0.0684 0.0686 0.0690 

[TRAIN] Epoch[6](291/1500); Loss: 0.110703; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2178 0.1758 0.1698 0.1249 0.1186 0.1117 0.1039 0.0962 0.0905 0.0860 0.0832 0.0799 0.0788 0.0786 0.0779 0.0777 

[TRAIN] Epoch[6](292/1500); Loss: 0.130951; Backpropagation: 0.0936 sec; Batch: 0.4280 sec
0.1764 0.1665 0.1579 0.1414 0.1354 0.1283 0.1234 0.1207 0.1193 0.1184 0.1180 0.1180 0.1177 0.1177 0.1179 0.1182 

[TRAIN] Epoch[6](293/1500); Loss: 0.105830; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.1821 0.2138 0.1690 0.1254 0.0965 0.0877 0.0855 0.0845 0.0833 0.0824 0.0813 0.0807 0.0803 0.0801 0.0802 0.0804 

[TRAIN] Epoch[6](294/1500); Loss: 0.076780; Backpropagation: 0.0941 sec; Batch: 0.4294 sec
0.1400 0.1534 0.1235 0.0928 0.0731 0.0652 0.0628 0.0604 0.0587 0.0575 0.0572 0.0570 0.0567 0.0566 0.0566 0.0570 

[TRAIN] Epoch[6](295/1500); Loss: 0.064143; Backpropagation: 0.0943 sec; Batch: 0.4302 sec
0.1014 0.1472 0.0938 0.0667 0.0534 0.0517 0.0513 0.0513 0.0511 0.0511 0.0509 0.0509 0.0510 0.0514 0.0516 0.0515 

[TRAIN] Epoch[6](296/1500); Loss: 0.052536; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.0809 0.0636 0.0607 0.0523 0.0496 0.0479 0.0475 0.0472 0.0474 0.0475 0.0478 0.0483 0.0488 0.0495 0.0503 0.0511 

[TRAIN] Epoch[6](297/1500); Loss: 0.057417; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1201 0.0783 0.0777 0.0498 0.0518 0.0496 0.0490 0.0492 0.0489 0.0487 0.0484 0.0485 0.0488 0.0493 0.0499 0.0508 

[TRAIN] Epoch[6](298/1500); Loss: 0.155661; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.2341 0.2114 0.2030 0.1577 0.1495 0.1434 0.1410 0.1400 0.1387 0.1378 0.1376 0.1378 0.1385 0.1390 0.1401 0.1408 

[TRAIN] Epoch[6](299/1500); Loss: 0.105214; Backpropagation: 0.0936 sec; Batch: 0.4292 sec
0.1839 0.1580 0.1544 0.1248 0.1167 0.1045 0.0973 0.0911 0.0862 0.0835 0.0818 0.0812 0.0808 0.0800 0.0797 0.0795 

[TRAIN] Epoch[6](300/1500); Loss: 0.130836; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.2279 0.2900 0.2260 0.1677 0.1024 0.1012 0.1042 0.1020 0.1008 0.0991 0.0978 0.0969 0.0955 0.0947 0.0938 0.0933 

[TRAIN] Epoch[6](301/1500); Loss: 0.109751; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1336 0.1391 0.1222 0.1088 0.1067 0.1052 0.1040 0.1029 0.1024 0.1025 0.1027 0.1032 0.1039 0.1050 0.1061 0.1075 

[TRAIN] Epoch[6](302/1500); Loss: 0.054373; Backpropagation: 0.0939 sec; Batch: 0.4286 sec
0.0719 0.0861 0.0572 0.0517 0.0501 0.0483 0.0503 0.0501 0.0493 0.0490 0.0492 0.0500 0.0509 0.0513 0.0520 0.0526 

[TRAIN] Epoch[6](303/1500); Loss: 0.057031; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.0779 0.0979 0.0659 0.0574 0.0580 0.0556 0.0541 0.0521 0.0505 0.0494 0.0487 0.0484 0.0486 0.0488 0.0493 0.0500 

[TRAIN] Epoch[6](304/1500); Loss: 0.172453; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.2213 0.2056 0.1964 0.1791 0.1747 0.1706 0.1645 0.1633 0.1619 0.1618 0.1615 0.1610 0.1602 0.1596 0.1591 0.1587 

[TRAIN] Epoch[6](305/1500); Loss: 0.081936; Backpropagation: 0.0937 sec; Batch: 0.4290 sec
0.1623 0.1475 0.1311 0.0909 0.0821 0.0727 0.0682 0.0632 0.0622 0.0610 0.0605 0.0607 0.0611 0.0616 0.0624 0.0633 

[TRAIN] Epoch[6](306/1500); Loss: 0.057204; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.0969 0.0895 0.0716 0.0597 0.0534 0.0475 0.0477 0.0469 0.0471 0.0477 0.0486 0.0497 0.0506 0.0516 0.0529 0.0538 

[TRAIN] Epoch[6](307/1500); Loss: 0.092292; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1932 0.1615 0.1527 0.1024 0.0915 0.0807 0.0746 0.0723 0.0709 0.0694 0.0688 0.0678 0.0675 0.0676 0.0678 0.0680 

[TRAIN] Epoch[6](308/1500); Loss: 0.093552; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1481 0.1280 0.1094 0.1017 0.0968 0.0913 0.0885 0.0859 0.0834 0.0822 0.0811 0.0804 0.0799 0.0797 0.0799 0.0805 

[TRAIN] Epoch[6](309/1500); Loss: 0.095872; Backpropagation: 0.0936 sec; Batch: 0.4287 sec
0.1358 0.1324 0.1141 0.1007 0.0925 0.0886 0.0868 0.0868 0.0864 0.0862 0.0865 0.0867 0.0869 0.0873 0.0878 0.0884 

[TRAIN] Epoch[6](310/1500); Loss: 0.151625; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2545 0.2189 0.2160 0.1670 0.1560 0.1423 0.1347 0.1289 0.1257 0.1248 0.1251 0.1257 0.1262 0.1264 0.1267 0.1270 

[TRAIN] Epoch[6](311/1500); Loss: 0.072163; Backpropagation: 0.0983 sec; Batch: 0.4337 sec
0.1107 0.0834 0.0839 0.0745 0.0717 0.0698 0.0687 0.0674 0.0666 0.0660 0.0656 0.0653 0.0651 0.0650 0.0652 0.0657 

[TRAIN] Epoch[6](312/1500); Loss: 0.095851; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1338 0.1394 0.1232 0.1071 0.0972 0.0908 0.0871 0.0852 0.0842 0.0839 0.0836 0.0834 0.0833 0.0836 0.0838 0.0841 

[TRAIN] Epoch[6](313/1500); Loss: 0.150117; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.2488 0.2724 0.2337 0.1821 0.1523 0.1356 0.1298 0.1222 0.1194 0.1168 0.1151 0.1135 0.1135 0.1143 0.1155 0.1168 

[TRAIN] Epoch[6](314/1500); Loss: 0.178917; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.4423 0.3767 0.3755 0.2549 0.2246 0.1732 0.1354 0.0904 0.1023 0.0953 0.0970 0.0972 0.0974 0.0982 0.1001 0.1022 

[TRAIN] Epoch[6](315/1500); Loss: 0.044142; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.0560 0.0954 0.0484 0.0406 0.0397 0.0387 0.0382 0.0372 0.0373 0.0376 0.0376 0.0378 0.0393 0.0400 0.0406 0.0418 

[TRAIN] Epoch[6](316/1500); Loss: 0.087296; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1580 0.1318 0.1263 0.0951 0.0879 0.0783 0.0751 0.0727 0.0722 0.0710 0.0708 0.0708 0.0713 0.0715 0.0717 0.0720 

[TRAIN] Epoch[6](317/1500); Loss: 0.057087; Backpropagation: 0.0943 sec; Batch: 0.4288 sec
0.1044 0.0629 0.0658 0.0519 0.0513 0.0586 0.0558 0.0546 0.0531 0.0513 0.0501 0.0496 0.0497 0.0509 0.0514 0.0519 

[TRAIN] Epoch[6](318/1500); Loss: 0.127836; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.2003 0.1830 0.1744 0.1444 0.1357 0.1253 0.1201 0.1118 0.1075 0.1058 0.1057 0.1056 0.1056 0.1060 0.1068 0.1073 

[TRAIN] Epoch[6](319/1500); Loss: 0.155261; Backpropagation: 0.0942 sec; Batch: 0.4289 sec
0.2118 0.2000 0.1885 0.1718 0.1629 0.1533 0.1489 0.1447 0.1418 0.1396 0.1385 0.1377 0.1369 0.1362 0.1357 0.1358 

[TRAIN] Epoch[6](320/1500); Loss: 0.096817; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1512 0.1445 0.1278 0.1023 0.0911 0.0866 0.0858 0.0849 0.0845 0.0842 0.0840 0.0840 0.0842 0.0842 0.0847 0.0850 

[TRAIN] Epoch[6](321/1500); Loss: 0.123856; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1819 0.1700 0.1525 0.1311 0.1232 0.1135 0.1117 0.1099 0.1102 0.1098 0.1101 0.1105 0.1108 0.1115 0.1122 0.1127 

[TRAIN] Epoch[6](322/1500); Loss: 0.117837; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.2404 0.3295 0.2420 0.1649 0.0936 0.0643 0.0635 0.0630 0.0661 0.0696 0.0762 0.0791 0.0820 0.0834 0.0839 0.0840 

[TRAIN] Epoch[6](323/1500); Loss: 0.160080; Backpropagation: 0.0984 sec; Batch: 0.4339 sec
0.2384 0.2360 0.2229 0.1883 0.1694 0.1537 0.1440 0.1368 0.1339 0.1322 0.1321 0.1326 0.1336 0.1346 0.1357 0.1371 

[TRAIN] Epoch[6](324/1500); Loss: 0.064568; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.0737 0.0996 0.0710 0.0617 0.0600 0.0594 0.0597 0.0601 0.0602 0.0600 0.0601 0.0601 0.0605 0.0615 0.0624 0.0629 

[TRAIN] Epoch[6](325/1500); Loss: 0.141476; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1485 0.1454 0.1399 0.1353 0.1377 0.1414 0.1402 0.1390 0.1391 0.1390 0.1394 0.1403 0.1414 0.1434 0.1456 0.1480 

[TRAIN] Epoch[6](326/1500); Loss: 0.093684; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1179 0.1152 0.1061 0.0990 0.0918 0.0900 0.0891 0.0888 0.0884 0.0878 0.0875 0.0872 0.0871 0.0874 0.0877 0.0882 

[TRAIN] Epoch[6](327/1500); Loss: 0.133657; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2661 0.3104 0.2581 0.2100 0.1662 0.1292 0.0950 0.0778 0.0757 0.0766 0.0769 0.0779 0.0788 0.0797 0.0800 0.0800 

[TRAIN] Epoch[6](328/1500); Loss: 0.124369; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2190 0.2255 0.1962 0.1466 0.1312 0.1202 0.1156 0.1059 0.0969 0.0919 0.0897 0.0888 0.0899 0.0905 0.0909 0.0911 

[TRAIN] Epoch[6](329/1500); Loss: 0.105103; Backpropagation: 0.0982 sec; Batch: 0.4337 sec
0.2769 0.2288 0.2288 0.1556 0.1370 0.1049 0.0833 0.0582 0.0534 0.0525 0.0505 0.0499 0.0498 0.0502 0.0506 0.0513 

[TRAIN] Epoch[6](330/1500); Loss: 0.142839; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.2470 0.2121 0.2138 0.1742 0.1625 0.1445 0.1327 0.1172 0.1109 0.1093 0.1084 0.1092 0.1100 0.1105 0.1112 0.1121 

[TRAIN] Epoch[6](331/1500); Loss: 0.118128; Backpropagation: 0.0941 sec; Batch: 0.4284 sec
0.1407 0.1337 0.1274 0.1210 0.1190 0.1175 0.1151 0.1136 0.1127 0.1125 0.1124 0.1124 0.1125 0.1127 0.1131 0.1137 

[TRAIN] Epoch[6](332/1500); Loss: 0.097622; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1279 0.1365 0.1149 0.0980 0.0948 0.0914 0.0908 0.0907 0.0902 0.0890 0.0885 0.0884 0.0890 0.0898 0.0907 0.0916 

[TRAIN] Epoch[6](333/1500); Loss: 0.152379; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.2333 0.2205 0.2121 0.1851 0.1684 0.1511 0.1365 0.1258 0.1236 0.1236 0.1240 0.1251 0.1256 0.1268 0.1280 0.1286 

[TRAIN] Epoch[6](334/1500); Loss: 0.081424; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1408 0.1776 0.1286 0.0889 0.0681 0.0629 0.0622 0.0626 0.0631 0.0636 0.0637 0.0638 0.0636 0.0640 0.0643 0.0648 

[TRAIN] Epoch[6](335/1500); Loss: 0.140116; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.2949 0.3357 0.2848 0.2323 0.1839 0.1405 0.0966 0.0745 0.0722 0.0737 0.0735 0.0749 0.0755 0.0758 0.0762 0.0768 

[TRAIN] Epoch[6](336/1500); Loss: 0.073096; Backpropagation: 0.0939 sec; Batch: 0.4415 sec
0.1250 0.1837 0.1170 0.0707 0.0593 0.0560 0.0565 0.0563 0.0566 0.0563 0.0557 0.0555 0.0551 0.0550 0.0551 0.0555 

[TRAIN] Epoch[6](337/1500); Loss: 0.075214; Backpropagation: 0.0940 sec; Batch: 0.4372 sec
0.1511 0.1991 0.1387 0.0868 0.0563 0.0501 0.0509 0.0512 0.0518 0.0525 0.0524 0.0524 0.0523 0.0523 0.0526 0.0529 

[TRAIN] Epoch[6](338/1500); Loss: 0.220835; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.3443 0.3031 0.3049 0.2490 0.2357 0.2157 0.2046 0.1874 0.1865 0.1858 0.1860 0.1858 0.1860 0.1858 0.1862 0.1865 

[TRAIN] Epoch[6](339/1500); Loss: 0.122465; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.1883 0.2306 0.1773 0.1383 0.1140 0.1069 0.1016 0.1001 0.1001 0.1001 0.1003 0.1003 0.1004 0.1002 0.1003 0.1006 

[TRAIN] Epoch[6](340/1500); Loss: 0.143562; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.2102 0.2361 0.2003 0.1580 0.1369 0.1270 0.1223 0.1205 0.1214 0.1224 0.1228 0.1230 0.1236 0.1238 0.1240 0.1246 

[TRAIN] Epoch[6](341/1500); Loss: 0.106891; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1388 0.1472 0.1285 0.1096 0.1047 0.1002 0.0984 0.0979 0.0982 0.0983 0.0983 0.0981 0.0977 0.0979 0.0982 0.0983 

[TRAIN] Epoch[6](342/1500); Loss: 0.093305; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.1281 0.1242 0.1077 0.0967 0.0927 0.0898 0.0879 0.0868 0.0861 0.0854 0.0848 0.0843 0.0843 0.0846 0.0846 0.0848 

[TRAIN] Epoch[6](343/1500); Loss: 0.054572; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.0809 0.0615 0.0609 0.0536 0.0523 0.0523 0.0516 0.0513 0.0509 0.0505 0.0504 0.0508 0.0509 0.0512 0.0516 0.0525 

[TRAIN] Epoch[6](344/1500); Loss: 0.071473; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1069 0.0971 0.0930 0.0821 0.0746 0.0703 0.0646 0.0627 0.0619 0.0613 0.0610 0.0611 0.0612 0.0617 0.0619 0.0621 

[TRAIN] Epoch[6](345/1500); Loss: 0.122302; Backpropagation: 0.0933 sec; Batch: 0.4278 sec
0.2010 0.1991 0.1772 0.1361 0.1238 0.1106 0.1047 0.1019 0.1014 0.1010 0.1006 0.1000 0.0998 0.0997 0.1000 0.0999 

[TRAIN] Epoch[6](346/1500); Loss: 0.086850; Backpropagation: 0.0935 sec; Batch: 0.4281 sec
0.1072 0.1409 0.1021 0.0886 0.0829 0.0806 0.0799 0.0792 0.0784 0.0780 0.0779 0.0783 0.0784 0.0788 0.0790 0.0793 

[TRAIN] Epoch[6](347/1500); Loss: 0.092486; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1203 0.1401 0.1130 0.0941 0.0870 0.0850 0.0849 0.0840 0.0828 0.0820 0.0819 0.0826 0.0836 0.0847 0.0862 0.0874 

[TRAIN] Epoch[6](348/1500); Loss: 0.118943; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1436 0.1553 0.1358 0.1224 0.1166 0.1128 0.1120 0.1118 0.1117 0.1116 0.1116 0.1113 0.1113 0.1118 0.1119 0.1117 

[TRAIN] Epoch[6](349/1500); Loss: 0.097638; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.1521 0.1678 0.1401 0.1063 0.0944 0.0862 0.0828 0.0837 0.0821 0.0812 0.0809 0.0807 0.0808 0.0809 0.0810 0.0812 

[TRAIN] Epoch[6](350/1500); Loss: 0.102002; Backpropagation: 0.0935 sec; Batch: 0.4289 sec
0.1785 0.1428 0.1430 0.1102 0.1031 0.0924 0.0896 0.0869 0.0861 0.0853 0.0852 0.0851 0.0854 0.0856 0.0863 0.0866 

[TRAIN] Epoch[6](351/1500); Loss: 0.123900; Backpropagation: 0.0934 sec; Batch: 0.4277 sec
0.2154 0.2401 0.2056 0.1701 0.1328 0.1059 0.0934 0.0924 0.0924 0.0916 0.0915 0.0911 0.0907 0.0901 0.0897 0.0895 

[TRAIN] Epoch[6](352/1500); Loss: 0.071658; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1170 0.1086 0.0932 0.0756 0.0715 0.0668 0.0652 0.0637 0.0626 0.0615 0.0609 0.0604 0.0601 0.0598 0.0598 0.0599 

[TRAIN] Epoch[6](353/1500); Loss: 0.141211; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.2550 0.2469 0.2277 0.1758 0.1522 0.1327 0.1196 0.1097 0.1090 0.1059 0.1048 0.1045 0.1040 0.1037 0.1038 0.1041 

[TRAIN] Epoch[6](354/1500); Loss: 0.128139; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2206 0.2463 0.2064 0.1538 0.1210 0.1089 0.1055 0.0986 0.0976 0.0989 0.0997 0.0993 0.0991 0.0988 0.0982 0.0978 

[TRAIN] Epoch[6](355/1500); Loss: 0.092670; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1465 0.1939 0.1406 0.1040 0.0919 0.0834 0.0784 0.0761 0.0740 0.0722 0.0707 0.0701 0.0698 0.0703 0.0704 0.0704 

[TRAIN] Epoch[6](356/1500); Loss: 0.111679; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1854 0.2029 0.1690 0.1265 0.1111 0.0994 0.0962 0.0930 0.0901 0.0886 0.0877 0.0874 0.0871 0.0876 0.0872 0.0875 

[TRAIN] Epoch[6](357/1500); Loss: 0.076744; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.1282 0.1694 0.1156 0.0823 0.0695 0.0623 0.0608 0.0601 0.0596 0.0591 0.0597 0.0599 0.0601 0.0602 0.0605 0.0607 

[TRAIN] Epoch[6](358/1500); Loss: 0.084754; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1282 0.1184 0.1094 0.0989 0.0918 0.0817 0.0791 0.0752 0.0731 0.0716 0.0713 0.0716 0.0716 0.0712 0.0714 0.0715 

[TRAIN] Epoch[6](359/1500); Loss: 0.113491; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2019 0.2311 0.1905 0.1467 0.1159 0.0999 0.0917 0.0856 0.0841 0.0837 0.0824 0.0814 0.0810 0.0802 0.0799 0.0797 

[TRAIN] Epoch[6](360/1500); Loss: 0.070864; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1024 0.1153 0.0945 0.0804 0.0698 0.0650 0.0618 0.0609 0.0607 0.0609 0.0606 0.0604 0.0602 0.0601 0.0602 0.0605 

[TRAIN] Epoch[6](361/1500); Loss: 0.093896; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2002 0.2888 0.2013 0.1252 0.0852 0.0606 0.0552 0.0521 0.0534 0.0529 0.0544 0.0539 0.0539 0.0544 0.0551 0.0555 

[TRAIN] Epoch[6](362/1500); Loss: 0.088386; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1739 0.1892 0.1551 0.1144 0.0862 0.0705 0.0646 0.0633 0.0624 0.0617 0.0618 0.0618 0.0619 0.0623 0.0625 0.0627 

[TRAIN] Epoch[6](363/1500); Loss: 0.158078; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.2362 0.2381 0.2172 0.1844 0.1676 0.1491 0.1421 0.1357 0.1339 0.1324 0.1321 0.1319 0.1320 0.1319 0.1322 0.1325 

[TRAIN] Epoch[6](364/1500); Loss: 0.141302; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.2171 0.2122 0.1960 0.1611 0.1492 0.1344 0.1265 0.1217 0.1190 0.1181 0.1177 0.1174 0.1175 0.1176 0.1176 0.1177 

[TRAIN] Epoch[6](365/1500); Loss: 0.076689; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1208 0.1042 0.0959 0.0947 0.0819 0.0733 0.0689 0.0667 0.0657 0.0651 0.0649 0.0647 0.0648 0.0648 0.0651 0.0654 

[TRAIN] Epoch[6](366/1500); Loss: 0.116682; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2153 0.2232 0.1900 0.1420 0.1138 0.1020 0.0951 0.0921 0.0900 0.0876 0.0861 0.0863 0.0858 0.0857 0.0857 0.0863 

[TRAIN] Epoch[6](367/1500); Loss: 0.143844; Backpropagation: 0.0933 sec; Batch: 0.4283 sec
0.2279 0.2209 0.2073 0.1709 0.1584 0.1422 0.1328 0.1227 0.1181 0.1160 0.1151 0.1142 0.1142 0.1140 0.1137 0.1130 

[TRAIN] Epoch[6](368/1500); Loss: 0.069699; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1161 0.1288 0.1046 0.0795 0.0665 0.0598 0.0576 0.0564 0.0560 0.0557 0.0556 0.0555 0.0556 0.0557 0.0558 0.0559 

[TRAIN] Epoch[6](369/1500); Loss: 0.132790; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1886 0.1998 0.1724 0.1498 0.1322 0.1235 0.1189 0.1174 0.1166 0.1159 0.1152 0.1151 0.1149 0.1149 0.1148 0.1145 

[TRAIN] Epoch[6](370/1500); Loss: 0.094293; Backpropagation: 0.0958 sec; Batch: 0.4302 sec
0.1298 0.1145 0.1085 0.1019 0.0965 0.0922 0.0904 0.0890 0.0880 0.0872 0.0867 0.0858 0.0852 0.0846 0.0844 0.0840 

[TRAIN] Epoch[6](371/1500); Loss: 0.167834; Backpropagation: 0.0959 sec; Batch: 0.4302 sec
0.2374 0.2214 0.2111 0.1704 0.1595 0.1547 0.1518 0.1518 0.1532 0.1528 0.1531 0.1530 0.1536 0.1537 0.1540 0.1539 

[TRAIN] Epoch[6](372/1500); Loss: 0.086137; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1931 0.2368 0.1861 0.1347 0.0844 0.0549 0.0517 0.0497 0.0500 0.0493 0.0485 0.0477 0.0476 0.0475 0.0478 0.0482 

[TRAIN] Epoch[6](373/1500); Loss: 0.154091; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2525 0.2716 0.2379 0.1967 0.1628 0.1354 0.1251 0.1225 0.1221 0.1212 0.1210 0.1201 0.1194 0.1191 0.1190 0.1190 

[TRAIN] Epoch[6](374/1500); Loss: 0.085943; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1680 0.1587 0.1456 0.1160 0.0954 0.0768 0.0656 0.0651 0.0632 0.0606 0.0599 0.0597 0.0600 0.0601 0.0601 0.0601 

[TRAIN] Epoch[6](375/1500); Loss: 0.095169; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1500 0.1402 0.1301 0.1113 0.1014 0.0893 0.0822 0.0795 0.0823 0.0798 0.0793 0.0795 0.0792 0.0792 0.0795 0.0800 

[TRAIN] Epoch[6](376/1500); Loss: 0.101878; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.2414 0.2219 0.1995 0.1255 0.0953 0.0771 0.0697 0.0678 0.0693 0.0668 0.0660 0.0656 0.0655 0.0656 0.0659 0.0671 

[TRAIN] Epoch[6](377/1500); Loss: 0.114876; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.2183 0.2579 0.2127 0.1681 0.1205 0.0892 0.0804 0.0782 0.0779 0.0771 0.0766 0.0764 0.0762 0.0761 0.0762 0.0763 

[TRAIN] Epoch[6](378/1500); Loss: 0.112872; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1995 0.2306 0.1856 0.1382 0.1044 0.0926 0.0897 0.0874 0.0859 0.0853 0.0846 0.0844 0.0843 0.0844 0.0844 0.0846 

[TRAIN] Epoch[6](379/1500); Loss: 0.125823; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.2398 0.2875 0.2294 0.1742 0.1225 0.0937 0.0888 0.0867 0.0865 0.0863 0.0863 0.0862 0.0864 0.0862 0.0862 0.0865 

[TRAIN] Epoch[6](380/1500); Loss: 0.094283; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1377 0.1473 0.1265 0.1032 0.0912 0.0860 0.0836 0.0832 0.0827 0.0815 0.0811 0.0810 0.0809 0.0809 0.0808 0.0809 

[TRAIN] Epoch[6](381/1500); Loss: 0.078847; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1600 0.1389 0.1283 0.0840 0.0743 0.0657 0.0637 0.0627 0.0621 0.0610 0.0604 0.0603 0.0600 0.0600 0.0600 0.0601 

[TRAIN] Epoch[6](382/1500); Loss: 0.091976; Backpropagation: 0.0936 sec; Batch: 0.4271 sec
0.2351 0.3042 0.2268 0.1477 0.0794 0.0496 0.0467 0.0433 0.0428 0.0422 0.0419 0.0417 0.0417 0.0422 0.0429 0.0433 

[TRAIN] Epoch[6](383/1500); Loss: 0.077843; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1357 0.1204 0.1138 0.0878 0.0805 0.0692 0.0663 0.0657 0.0648 0.0635 0.0632 0.0629 0.0628 0.0630 0.0630 0.0629 

[TRAIN] Epoch[6](384/1500); Loss: 0.087484; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1171 0.1173 0.1054 0.0952 0.0889 0.0843 0.0812 0.0802 0.0792 0.0785 0.0786 0.0786 0.0787 0.0786 0.0788 0.0792 

[TRAIN] Epoch[6](385/1500); Loss: 0.078151; Backpropagation: 0.0933 sec; Batch: 0.4280 sec
0.1178 0.1346 0.1010 0.0804 0.0738 0.0712 0.0695 0.0683 0.0674 0.0667 0.0666 0.0666 0.0663 0.0664 0.0667 0.0671 

[TRAIN] Epoch[6](386/1500); Loss: 0.134377; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.2735 0.2931 0.2565 0.1981 0.1628 0.1287 0.1020 0.0847 0.0849 0.0816 0.0814 0.0808 0.0806 0.0803 0.0804 0.0804 

[TRAIN] Epoch[6](387/1500); Loss: 0.092378; Backpropagation: 0.0937 sec; Batch: 0.4286 sec
0.1102 0.1082 0.0987 0.0962 0.0909 0.0889 0.0888 0.0887 0.0884 0.0883 0.0880 0.0882 0.0883 0.0884 0.0886 0.0890 

[TRAIN] Epoch[6](388/1500); Loss: 0.131723; Backpropagation: 0.0959 sec; Batch: 0.4310 sec
0.3231 0.2710 0.2690 0.1736 0.1507 0.1059 0.0832 0.0922 0.0810 0.0789 0.0797 0.0788 0.0796 0.0798 0.0807 0.0805 

[TRAIN] Epoch[6](389/1500); Loss: 0.144816; Backpropagation: 0.0960 sec; Batch: 0.4302 sec
0.2539 0.2171 0.2132 0.1595 0.1487 0.1361 0.1270 0.1235 0.1199 0.1186 0.1179 0.1170 0.1161 0.1161 0.1162 0.1161 

[TRAIN] Epoch[6](390/1500); Loss: 0.154906; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.2409 0.2298 0.2179 0.1768 0.1618 0.1448 0.1362 0.1304 0.1304 0.1308 0.1304 0.1302 0.1297 0.1294 0.1292 0.1298 

[TRAIN] Epoch[6](391/1500); Loss: 0.128888; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2810 0.2905 0.2540 0.1949 0.1535 0.1153 0.0854 0.0790 0.0766 0.0758 0.0762 0.0760 0.0761 0.0760 0.0760 0.0759 

[TRAIN] Epoch[6](392/1500); Loss: 0.106881; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1904 0.2240 0.1744 0.1240 0.0962 0.0879 0.0846 0.0833 0.0821 0.0814 0.0808 0.0805 0.0801 0.0801 0.0801 0.0802 

[TRAIN] Epoch[6](393/1500); Loss: 0.069055; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1016 0.0911 0.0845 0.0789 0.0702 0.0672 0.0626 0.0615 0.0609 0.0606 0.0605 0.0608 0.0608 0.0609 0.0613 0.0615 

[TRAIN] Epoch[6](394/1500); Loss: 0.156870; Backpropagation: 0.0958 sec; Batch: 0.4292 sec
0.2271 0.2074 0.1976 0.1583 0.1499 0.1448 0.1427 0.1434 0.1427 0.1420 0.1419 0.1420 0.1424 0.1421 0.1426 0.1429 

[TRAIN] Epoch[6](395/1500); Loss: 0.123246; Backpropagation: 0.0958 sec; Batch: 0.4306 sec
0.2152 0.2308 0.1960 0.1579 0.1279 0.1072 0.1004 0.0977 0.0972 0.0943 0.0934 0.0919 0.0911 0.0904 0.0903 0.0902 

[TRAIN] Epoch[6](396/1500); Loss: 0.164307; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.2716 0.2766 0.2509 0.2016 0.1732 0.1497 0.1399 0.1360 0.1323 0.1302 0.1284 0.1279 0.1276 0.1276 0.1276 0.1278 

[TRAIN] Epoch[6](397/1500); Loss: 0.074589; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1157 0.1192 0.1002 0.0843 0.0753 0.0683 0.0658 0.0636 0.0627 0.0623 0.0623 0.0622 0.0623 0.0627 0.0630 0.0635 

[TRAIN] Epoch[6](398/1500); Loss: 0.133837; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.3239 0.4040 0.3183 0.2269 0.1329 0.0753 0.0651 0.0675 0.0664 0.0656 0.0648 0.0647 0.0652 0.0660 0.0672 0.0677 

[TRAIN] Epoch[6](399/1500); Loss: 0.128132; Backpropagation: 0.0937 sec; Batch: 0.4280 sec
0.1885 0.2116 0.1709 0.1433 0.1289 0.1201 0.1165 0.1133 0.1111 0.1088 0.1078 0.1068 0.1060 0.1055 0.1054 0.1056 

[TRAIN] Epoch[6](400/1500); Loss: 0.141191; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2193 0.2389 0.1999 0.1597 0.1391 0.1268 0.1214 0.1189 0.1182 0.1171 0.1166 0.1166 0.1164 0.1164 0.1169 0.1169 

[TRAIN] Epoch[6](401/1500); Loss: 0.076526; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.1259 0.0888 0.0873 0.0946 0.0777 0.0746 0.0690 0.0672 0.0663 0.0664 0.0668 0.0669 0.0669 0.0675 0.0687 0.0697 

[TRAIN] Epoch[6](402/1500); Loss: 0.091751; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.2454 0.2905 0.2189 0.1480 0.0831 0.0484 0.0452 0.0437 0.0433 0.0428 0.0429 0.0427 0.0426 0.0429 0.0436 0.0440 

[TRAIN] Epoch[6](403/1500); Loss: 0.087205; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1579 0.1921 0.1402 0.0963 0.0772 0.0701 0.0688 0.0678 0.0665 0.0657 0.0652 0.0650 0.0653 0.0654 0.0659 0.0660 

[TRAIN] Epoch[6](404/1500); Loss: 0.090409; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.1317 0.1209 0.1116 0.0948 0.0893 0.0847 0.0835 0.0827 0.0816 0.0810 0.0807 0.0805 0.0806 0.0807 0.0810 0.0812 

[TRAIN] Epoch[6](405/1500); Loss: 0.075371; Backpropagation: 0.0943 sec; Batch: 0.4286 sec
0.1165 0.1288 0.1025 0.0835 0.0774 0.0710 0.0676 0.0643 0.0628 0.0617 0.0615 0.0619 0.0619 0.0615 0.0614 0.0616 

[TRAIN] Epoch[6](406/1500); Loss: 0.102980; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2127 0.2370 0.1903 0.1359 0.1122 0.0898 0.0765 0.0703 0.0681 0.0664 0.0655 0.0648 0.0645 0.0646 0.0645 0.0646 

[TRAIN] Epoch[6](407/1500); Loss: 0.090007; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1702 0.1635 0.1432 0.1104 0.0940 0.0804 0.0752 0.0690 0.0683 0.0664 0.0664 0.0662 0.0663 0.0666 0.0668 0.0672 

[TRAIN] Epoch[6](408/1500); Loss: 0.099450; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.2156 0.2129 0.1835 0.1282 0.1069 0.0886 0.0799 0.0724 0.0677 0.0650 0.0637 0.0623 0.0613 0.0613 0.0612 0.0609 

[TRAIN] Epoch[6](409/1500); Loss: 0.133855; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.1677 0.1694 0.1538 0.1354 0.1277 0.1251 0.1247 0.1245 0.1247 0.1252 0.1257 0.1266 0.1271 0.1275 0.1280 0.1287 

[TRAIN] Epoch[6](410/1500); Loss: 0.137724; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1875 0.1855 0.1659 0.1442 0.1328 0.1290 0.1298 0.1279 0.1268 0.1256 0.1253 0.1249 0.1248 0.1245 0.1246 0.1246 

[TRAIN] Epoch[6](411/1500); Loss: 0.115391; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1696 0.1885 0.1528 0.1282 0.1145 0.1054 0.1012 0.1004 0.0991 0.0984 0.0979 0.0978 0.0979 0.0980 0.0981 0.0983 

[TRAIN] Epoch[6](412/1500); Loss: 0.100920; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.2346 0.2218 0.1983 0.1344 0.1186 0.0960 0.0836 0.0699 0.0643 0.0595 0.0576 0.0561 0.0553 0.0551 0.0548 0.0547 

[TRAIN] Epoch[6](413/1500); Loss: 0.153226; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2036 0.1987 0.1865 0.1647 0.1567 0.1484 0.1436 0.1412 0.1401 0.1394 0.1392 0.1389 0.1384 0.1377 0.1374 0.1372 

[TRAIN] Epoch[6](414/1500); Loss: 0.079475; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2429 0.1987 0.1926 0.1065 0.0835 0.0509 0.0442 0.0472 0.0407 0.0379 0.0378 0.0375 0.0378 0.0376 0.0377 0.0380 

[TRAIN] Epoch[6](415/1500); Loss: 0.150358; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1802 0.1843 0.1686 0.1556 0.1501 0.1467 0.1445 0.1428 0.1419 0.1414 0.1415 0.1416 0.1415 0.1415 0.1416 0.1418 

[TRAIN] Epoch[6](416/1500); Loss: 0.079355; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1342 0.1167 0.1035 0.0781 0.0753 0.0726 0.0705 0.0694 0.0683 0.0678 0.0677 0.0681 0.0685 0.0687 0.0696 0.0706 

[TRAIN] Epoch[6](417/1500); Loss: 0.114468; Backpropagation: 0.0940 sec; Batch: 0.4288 sec
0.1572 0.1633 0.1385 0.1225 0.1139 0.1074 0.1056 0.1045 0.1037 0.1031 0.1024 0.1022 0.1022 0.1017 0.1015 0.1017 

[TRAIN] Epoch[6](418/1500); Loss: 0.060772; Backpropagation: 0.0938 sec; Batch: 0.4272 sec
0.1029 0.0981 0.0723 0.0660 0.0567 0.0519 0.0503 0.0501 0.0500 0.0503 0.0507 0.0516 0.0530 0.0543 0.0560 0.0580 

[TRAIN] Epoch[6](419/1500); Loss: 0.091980; Backpropagation: 0.0938 sec; Batch: 0.4392 sec
0.1424 0.1253 0.1189 0.1015 0.0951 0.0872 0.0849 0.0825 0.0808 0.0798 0.0790 0.0788 0.0787 0.0787 0.0789 0.0791 

[TRAIN] Epoch[6](420/1500); Loss: 0.121141; Backpropagation: 0.0933 sec; Batch: 0.4695 sec
0.2423 0.2676 0.2107 0.1545 0.1150 0.0962 0.0882 0.0867 0.0859 0.0851 0.0848 0.0844 0.0843 0.0842 0.0840 0.0842 

[TRAIN] Epoch[6](421/1500); Loss: 0.165536; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.4007 0.3504 0.3383 0.2213 0.1837 0.1239 0.1011 0.1177 0.1065 0.1022 0.1012 0.1009 0.1001 0.1000 0.1001 0.1004 

[TRAIN] Epoch[6](422/1500); Loss: 0.074439; Backpropagation: 0.0942 sec; Batch: 0.4286 sec
0.1527 0.1309 0.1187 0.0857 0.0721 0.0651 0.0595 0.0580 0.0573 0.0567 0.0557 0.0553 0.0554 0.0555 0.0559 0.0565 

[TRAIN] Epoch[6](423/1500); Loss: 0.101866; Backpropagation: 0.0941 sec; Batch: 0.4347 sec
0.1708 0.1498 0.1420 0.1043 0.0966 0.0898 0.0906 0.0875 0.0873 0.0871 0.0871 0.0871 0.0871 0.0872 0.0875 0.0880 

[TRAIN] Epoch[6](424/1500); Loss: 0.120636; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.1599 0.1677 0.1462 0.1263 0.1190 0.1154 0.1141 0.1119 0.1106 0.1094 0.1088 0.1087 0.1082 0.1080 0.1080 0.1081 

[TRAIN] Epoch[6](425/1500); Loss: 0.118200; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.3116 0.2539 0.2495 0.1562 0.1328 0.0963 0.0747 0.0754 0.0700 0.0694 0.0679 0.0669 0.0666 0.0664 0.0666 0.0669 

[TRAIN] Epoch[6](426/1500); Loss: 0.112410; Backpropagation: 0.0934 sec; Batch: 0.4289 sec
0.1877 0.2100 0.1651 0.1322 0.1109 0.0969 0.0932 0.0912 0.0907 0.0897 0.0890 0.0886 0.0882 0.0883 0.0884 0.0885 

[TRAIN] Epoch[6](427/1500); Loss: 0.096032; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1688 0.1707 0.1447 0.1158 0.1057 0.0942 0.0868 0.0770 0.0730 0.0729 0.0717 0.0717 0.0710 0.0710 0.0705 0.0709 

[TRAIN] Epoch[6](428/1500); Loss: 0.144460; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.3207 0.2845 0.2709 0.1772 0.1511 0.1223 0.1064 0.1053 0.0980 0.0970 0.0960 0.0959 0.0962 0.0963 0.0968 0.0969 

[TRAIN] Epoch[6](429/1500); Loss: 0.083316; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1732 0.1808 0.1416 0.0940 0.0812 0.0699 0.0649 0.0628 0.0605 0.0591 0.0583 0.0578 0.0574 0.0571 0.0571 0.0573 

[TRAIN] Epoch[6](430/1500); Loss: 0.095013; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1519 0.1501 0.1299 0.0969 0.0872 0.0844 0.0839 0.0825 0.0818 0.0813 0.0814 0.0815 0.0815 0.0817 0.0819 0.0823 

[TRAIN] Epoch[6](431/1500); Loss: 0.115642; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1711 0.1626 0.1468 0.1303 0.1203 0.1129 0.1077 0.1045 0.1033 0.1011 0.0990 0.0987 0.0985 0.0981 0.0977 0.0977 

[TRAIN] Epoch[6](432/1500); Loss: 0.096805; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1565 0.1841 0.1308 0.0998 0.0879 0.0844 0.0821 0.0815 0.0805 0.0797 0.0795 0.0795 0.0797 0.0801 0.0810 0.0816 

[TRAIN] Epoch[6](433/1500); Loss: 0.070351; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1152 0.1020 0.0848 0.0683 0.0671 0.0650 0.0621 0.0614 0.0613 0.0611 0.0616 0.0620 0.0623 0.0628 0.0637 0.0649 

[TRAIN] Epoch[6](434/1500); Loss: 0.141400; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.2041 0.2130 0.1826 0.1545 0.1373 0.1290 0.1267 0.1255 0.1248 0.1243 0.1240 0.1236 0.1236 0.1232 0.1232 0.1231 

[TRAIN] Epoch[6](435/1500); Loss: 0.106912; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.1426 0.1285 0.1221 0.1126 0.1082 0.1051 0.1030 0.1017 0.1007 0.0999 0.0990 0.0982 0.0977 0.0973 0.0971 0.0968 

[TRAIN] Epoch[6](436/1500); Loss: 0.102019; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.2149 0.1852 0.1692 0.0999 0.0872 0.0830 0.0806 0.0831 0.0814 0.0789 0.0780 0.0779 0.0780 0.0781 0.0783 0.0786 

[TRAIN] Epoch[6](437/1500); Loss: 0.129759; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.1722 0.1942 0.1603 0.1414 0.1308 0.1244 0.1197 0.1163 0.1151 0.1147 0.1146 0.1145 0.1142 0.1144 0.1145 0.1149 

[TRAIN] Epoch[6](438/1500); Loss: 0.073661; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1195 0.1239 0.0954 0.0754 0.0664 0.0643 0.0640 0.0639 0.0634 0.0634 0.0633 0.0629 0.0631 0.0633 0.0631 0.0632 

[TRAIN] Epoch[6](439/1500); Loss: 0.072000; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1278 0.1095 0.0976 0.0850 0.0743 0.0630 0.0632 0.0606 0.0599 0.0592 0.0587 0.0583 0.0585 0.0588 0.0588 0.0590 

[TRAIN] Epoch[6](440/1500); Loss: 0.108754; Backpropagation: 0.0943 sec; Batch: 0.4297 sec
0.1467 0.1488 0.1251 0.1124 0.1059 0.1025 0.1012 0.1005 0.0997 0.0997 0.0992 0.0992 0.0993 0.0995 0.0998 0.1007 

[TRAIN] Epoch[6](441/1500); Loss: 0.083290; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1660 0.1859 0.1290 0.0898 0.0700 0.0650 0.0643 0.0636 0.0629 0.0627 0.0626 0.0625 0.0623 0.0622 0.0619 0.0620 

[TRAIN] Epoch[6](442/1500); Loss: 0.116088; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1691 0.1887 0.1482 0.1251 0.1135 0.1089 0.1065 0.1039 0.1021 0.1006 0.0998 0.0987 0.0981 0.0978 0.0981 0.0983 

[TRAIN] Epoch[6](443/1500); Loss: 0.083683; Backpropagation: 0.0938 sec; Batch: 0.4286 sec
0.1923 0.2132 0.1449 0.0836 0.0634 0.0634 0.0617 0.0599 0.0585 0.0576 0.0566 0.0564 0.0565 0.0565 0.0567 0.0578 

[TRAIN] Epoch[6](444/1500); Loss: 0.124444; Backpropagation: 0.0940 sec; Batch: 0.4287 sec
0.3054 0.2576 0.2538 0.1649 0.1401 0.1024 0.0860 0.0833 0.0777 0.0761 0.0751 0.0739 0.0732 0.0734 0.0740 0.0742 

[TRAIN] Epoch[6](445/1500); Loss: 0.048090; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.0906 0.0575 0.0585 0.0433 0.0445 0.0453 0.0435 0.0424 0.0420 0.0418 0.0418 0.0422 0.0427 0.0434 0.0445 0.0454 

[TRAIN] Epoch[6](446/1500); Loss: 0.109167; Backpropagation: 0.0933 sec; Batch: 0.4327 sec
0.1273 0.1470 0.1207 0.1089 0.1063 0.1053 0.1045 0.1035 0.1027 0.1024 0.1028 0.1031 0.1029 0.1029 0.1031 0.1033 

[TRAIN] Epoch[6](447/1500); Loss: 0.211296; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.3633 0.3114 0.3097 0.2376 0.2189 0.1917 0.1774 0.1763 0.1765 0.1757 0.1750 0.1738 0.1730 0.1738 0.1733 0.1732 

[TRAIN] Epoch[6](448/1500); Loss: 0.114982; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.2211 0.2392 0.1829 0.1250 0.1035 0.0932 0.0893 0.0875 0.0864 0.0860 0.0863 0.0869 0.0873 0.0875 0.0882 0.0893 

[TRAIN] Epoch[6](449/1500); Loss: 0.143199; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.2351 0.2023 0.1978 0.1507 0.1415 0.1313 0.1270 0.1244 0.1236 0.1231 0.1223 0.1220 0.1222 0.1224 0.1226 0.1230 

[TRAIN] Epoch[6](450/1500); Loss: 0.083359; Backpropagation: 0.0935 sec; Batch: 0.4273 sec
0.2065 0.2445 0.1583 0.0872 0.0590 0.0557 0.0571 0.0547 0.0529 0.0509 0.0501 0.0502 0.0505 0.0513 0.0517 0.0531 

[TRAIN] Epoch[6](451/1500); Loss: 0.149647; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1812 0.1831 0.1662 0.1538 0.1487 0.1455 0.1441 0.1431 0.1425 0.1418 0.1413 0.1409 0.1406 0.1406 0.1405 0.1403 

[TRAIN] Epoch[6](452/1500); Loss: 0.091665; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1222 0.1286 0.1076 0.0960 0.0922 0.0880 0.0866 0.0849 0.0843 0.0836 0.0827 0.0823 0.0818 0.0818 0.0821 0.0820 

[TRAIN] Epoch[6](453/1500); Loss: 0.082109; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.0969 0.0900 0.0840 0.0827 0.0819 0.0810 0.0802 0.0799 0.0798 0.0792 0.0787 0.0790 0.0795 0.0798 0.0803 0.0808 

[TRAIN] Epoch[6](454/1500); Loss: 0.030902; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.0611 0.0358 0.0339 0.0350 0.0322 0.0279 0.0270 0.0266 0.0259 0.0254 0.0256 0.0261 0.0268 0.0274 0.0283 0.0293 

[TRAIN] Epoch[6](455/1500); Loss: 0.124749; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1813 0.1836 0.1506 0.1283 0.1207 0.1170 0.1149 0.1128 0.1119 0.1112 0.1105 0.1103 0.1100 0.1103 0.1109 0.1116 

[TRAIN] Epoch[6](456/1500); Loss: 0.120664; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1746 0.1465 0.1420 0.1239 0.1191 0.1176 0.1151 0.1141 0.1132 0.1113 0.1100 0.1093 0.1090 0.1085 0.1082 0.1082 

[TRAIN] Epoch[6](457/1500); Loss: 0.047875; Backpropagation: 0.0941 sec; Batch: 0.4280 sec
0.1497 0.0962 0.0914 0.0611 0.0568 0.0369 0.0310 0.0284 0.0272 0.0258 0.0254 0.0262 0.0270 0.0272 0.0274 0.0281 

[TRAIN] Epoch[6](458/1500); Loss: 0.099500; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1794 0.1595 0.1488 0.1154 0.1044 0.0914 0.0874 0.0814 0.0786 0.0774 0.0773 0.0774 0.0777 0.0782 0.0786 0.0793 

[TRAIN] Epoch[6](459/1500); Loss: 0.104524; Backpropagation: 0.0940 sec; Batch: 0.4277 sec
0.1890 0.1869 0.1601 0.1189 0.1007 0.0910 0.0860 0.0855 0.0833 0.0827 0.0818 0.0814 0.0811 0.0810 0.0813 0.0814 

[TRAIN] Epoch[6](460/1500); Loss: 0.093095; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.2013 0.1733 0.1672 0.1231 0.1059 0.0800 0.0673 0.0700 0.0653 0.0637 0.0631 0.0623 0.0618 0.0616 0.0618 0.0618 

[TRAIN] Epoch[6](461/1500); Loss: 0.108558; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1550 0.1526 0.1289 0.1092 0.1033 0.0988 0.0989 0.0991 0.0989 0.0985 0.0987 0.0987 0.0989 0.0987 0.0991 0.0996 

[TRAIN] Epoch[6](462/1500); Loss: 0.145014; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1864 0.1691 0.1630 0.1543 0.1487 0.1403 0.1394 0.1372 0.1363 0.1351 0.1353 0.1350 0.1351 0.1351 0.1351 0.1351 

[TRAIN] Epoch[6](463/1500); Loss: 0.122729; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2223 0.2020 0.1806 0.1351 0.1203 0.1099 0.1047 0.1008 0.1016 0.0988 0.0980 0.0982 0.0980 0.0976 0.0976 0.0983 

[TRAIN] Epoch[6](464/1500); Loss: 0.077550; Backpropagation: 0.0960 sec; Batch: 0.4308 sec
0.1970 0.2221 0.1441 0.0833 0.0619 0.0547 0.0522 0.0496 0.0472 0.0461 0.0455 0.0458 0.0467 0.0475 0.0480 0.0490 

[TRAIN] Epoch[6](465/1500); Loss: 0.089104; Backpropagation: 0.0959 sec; Batch: 0.4304 sec
0.1736 0.1668 0.1345 0.0995 0.0844 0.0772 0.0741 0.0722 0.0706 0.0692 0.0681 0.0676 0.0670 0.0667 0.0670 0.0670 

[TRAIN] Epoch[6](466/1500); Loss: 0.092816; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2070 0.2141 0.1610 0.0995 0.0832 0.0736 0.0681 0.0679 0.0650 0.0651 0.0643 0.0636 0.0631 0.0630 0.0632 0.0632 

[TRAIN] Epoch[6](467/1500); Loss: 0.140650; Backpropagation: 0.0923 sec; Batch: 0.4259 sec
0.2358 0.2121 0.2001 0.1712 0.1572 0.1370 0.1265 0.1151 0.1169 0.1117 0.1114 0.1110 0.1107 0.1106 0.1112 0.1118 

[TRAIN] Epoch[6](468/1500); Loss: 0.074985; Backpropagation: 0.0926 sec; Batch: 0.4263 sec
0.1291 0.1072 0.0933 0.0888 0.0808 0.0707 0.0687 0.0664 0.0644 0.0626 0.0618 0.0614 0.0611 0.0610 0.0610 0.0614 

[TRAIN] Epoch[6](469/1500); Loss: 0.166117; Backpropagation: 0.0925 sec; Batch: 0.4271 sec
0.3160 0.2707 0.2658 0.2018 0.1852 0.1580 0.1427 0.1280 0.1246 0.1228 0.1226 0.1226 0.1228 0.1244 0.1250 0.1250 

[TRAIN] Epoch[6](470/1500); Loss: 0.080128; Backpropagation: 0.0956 sec; Batch: 0.4298 sec
0.1153 0.1099 0.0950 0.0869 0.0817 0.0757 0.0744 0.0731 0.0722 0.0716 0.0713 0.0708 0.0708 0.0710 0.0710 0.0714 

[TRAIN] Epoch[6](471/1500); Loss: 0.103035; Backpropagation: 0.0941 sec; Batch: 0.4287 sec
0.2159 0.2273 0.1704 0.1252 0.0961 0.0796 0.0751 0.0745 0.0733 0.0723 0.0724 0.0726 0.0731 0.0729 0.0736 0.0742 

[TRAIN] Epoch[6](472/1500); Loss: 0.098090; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.1480 0.1389 0.1296 0.1065 0.0988 0.0911 0.0876 0.0864 0.0855 0.0850 0.0849 0.0851 0.0853 0.0853 0.0854 0.0859 

[TRAIN] Epoch[6](473/1500); Loss: 0.136124; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1672 0.1592 0.1523 0.1484 0.1430 0.1376 0.1350 0.1319 0.1285 0.1267 0.1258 0.1254 0.1249 0.1243 0.1239 0.1237 

[TRAIN] Epoch[6](474/1500); Loss: 0.124675; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2086 0.2044 0.1708 0.1358 0.1214 0.1128 0.1081 0.1062 0.1047 0.1041 0.1032 0.1029 0.1028 0.1030 0.1030 0.1030 

[TRAIN] Epoch[6](475/1500); Loss: 0.080399; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1381 0.1170 0.1110 0.0856 0.0776 0.0707 0.0700 0.0704 0.0700 0.0689 0.0679 0.0678 0.0680 0.0677 0.0678 0.0678 

[TRAIN] Epoch[6](476/1500); Loss: 0.124864; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.2688 0.2393 0.2245 0.1546 0.1339 0.1072 0.0965 0.0898 0.0886 0.0864 0.0856 0.0851 0.0846 0.0843 0.0842 0.0844 

[TRAIN] Epoch[6](477/1500); Loss: 0.108086; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1754 0.1688 0.1437 0.1194 0.1047 0.0970 0.0950 0.0939 0.0926 0.0922 0.0920 0.0917 0.0909 0.0908 0.0905 0.0907 

[TRAIN] Epoch[6](478/1500); Loss: 0.112291; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.3325 0.2880 0.2727 0.1546 0.1153 0.0654 0.0567 0.0694 0.0582 0.0545 0.0548 0.0549 0.0548 0.0549 0.0549 0.0549 

[TRAIN] Epoch[6](479/1500); Loss: 0.095148; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1796 0.1628 0.1518 0.1193 0.1048 0.0866 0.0784 0.0771 0.0731 0.0710 0.0704 0.0696 0.0694 0.0694 0.0695 0.0694 

[TRAIN] Epoch[6](480/1500); Loss: 0.108790; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.2400 0.2498 0.1904 0.1306 0.0876 0.0787 0.0770 0.0767 0.0761 0.0759 0.0757 0.0756 0.0756 0.0760 0.0770 0.0778 

[TRAIN] Epoch[6](481/1500); Loss: 0.087684; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1438 0.1167 0.1109 0.0881 0.0841 0.0822 0.0794 0.0787 0.0780 0.0775 0.0772 0.0772 0.0771 0.0771 0.0774 0.0775 

[TRAIN] Epoch[6](482/1500); Loss: 0.062183; Backpropagation: 0.0934 sec; Batch: 0.4280 sec
0.1027 0.0876 0.0757 0.0825 0.0673 0.0561 0.0549 0.0539 0.0529 0.0517 0.0510 0.0510 0.0515 0.0519 0.0520 0.0523 

[TRAIN] Epoch[6](483/1500); Loss: 0.099749; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.2009 0.1973 0.1617 0.1116 0.0904 0.0834 0.0814 0.0797 0.0775 0.0757 0.0740 0.0731 0.0724 0.0723 0.0723 0.0722 

[TRAIN] Epoch[6](484/1500); Loss: 0.105288; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1876 0.1757 0.1719 0.1416 0.1322 0.1172 0.1062 0.0923 0.0779 0.0711 0.0693 0.0684 0.0685 0.0684 0.0681 0.0681 

[TRAIN] Epoch[6](485/1500); Loss: 0.048070; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.0873 0.0922 0.0529 0.0461 0.0431 0.0416 0.0399 0.0394 0.0400 0.0406 0.0406 0.0405 0.0403 0.0410 0.0415 0.0420 

[TRAIN] Epoch[6](486/1500); Loss: 0.156163; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2377 0.2304 0.2154 0.1809 0.1630 0.1478 0.1407 0.1365 0.1338 0.1321 0.1312 0.1305 0.1300 0.1296 0.1297 0.1292 

[TRAIN] Epoch[6](487/1500); Loss: 0.142619; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.2487 0.2473 0.2120 0.1610 0.1323 0.1225 0.1196 0.1182 0.1164 0.1152 0.1147 0.1146 0.1144 0.1145 0.1149 0.1155 

[TRAIN] Epoch[6](488/1500); Loss: 0.077117; Backpropagation: 0.0935 sec; Batch: 0.4283 sec
0.2000 0.2193 0.1370 0.0781 0.0577 0.0541 0.0529 0.0496 0.0478 0.0474 0.0473 0.0475 0.0471 0.0486 0.0492 0.0504 

[TRAIN] Epoch[6](489/1500); Loss: 0.124615; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1620 0.1638 0.1459 0.1288 0.1194 0.1180 0.1155 0.1156 0.1154 0.1151 0.1149 0.1151 0.1152 0.1160 0.1163 0.1169 

[TRAIN] Epoch[6](490/1500); Loss: 0.138905; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.2718 0.2545 0.2364 0.1830 0.1663 0.1432 0.1278 0.1111 0.0974 0.0914 0.0917 0.0894 0.0899 0.0897 0.0894 0.0895 

[TRAIN] Epoch[6](491/1500); Loss: 0.181751; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.3026 0.2857 0.2664 0.2051 0.1842 0.1676 0.1613 0.1554 0.1502 0.1483 0.1474 0.1471 0.1467 0.1468 0.1466 0.1466 

[TRAIN] Epoch[6](492/1500); Loss: 0.052730; Backpropagation: 0.0934 sec; Batch: 0.4282 sec
0.1477 0.1037 0.1007 0.0592 0.0517 0.0453 0.0400 0.0380 0.0355 0.0330 0.0316 0.0314 0.0312 0.0315 0.0315 0.0317 

[TRAIN] Epoch[6](493/1500); Loss: 0.097583; Backpropagation: 0.0943 sec; Batch: 0.4285 sec
0.1351 0.1117 0.1095 0.1123 0.1039 0.0945 0.0927 0.0913 0.0904 0.0891 0.0886 0.0884 0.0883 0.0885 0.0885 0.0885 

[TRAIN] Epoch[6](494/1500); Loss: 0.145456; Backpropagation: 0.0939 sec; Batch: 0.4273 sec
0.2871 0.2468 0.2420 0.1759 0.1563 0.1297 0.1196 0.1150 0.1108 0.1090 0.1074 0.1064 0.1059 0.1054 0.1052 0.1049 

[TRAIN] Epoch[6](495/1500); Loss: 0.108708; Backpropagation: 0.0943 sec; Batch: 0.4284 sec
0.3024 0.2404 0.2320 0.1167 0.0918 0.0816 0.0694 0.0719 0.0705 0.0688 0.0674 0.0653 0.0646 0.0653 0.0654 0.0659 

[TRAIN] Epoch[6](496/1500); Loss: 0.092476; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1594 0.1673 0.1231 0.0930 0.0842 0.0806 0.0799 0.0789 0.0781 0.0777 0.0771 0.0765 0.0762 0.0760 0.0760 0.0757 

[TRAIN] Epoch[6](497/1500); Loss: 0.075007; Backpropagation: 0.0934 sec; Batch: 0.4278 sec
0.1378 0.1101 0.1018 0.0886 0.0804 0.0689 0.0667 0.0637 0.0619 0.0604 0.0599 0.0596 0.0595 0.0597 0.0605 0.0606 

[TRAIN] Epoch[6](498/1500); Loss: 0.049420; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.0836 0.1027 0.0568 0.0475 0.0460 0.0440 0.0429 0.0419 0.0410 0.0407 0.0407 0.0405 0.0405 0.0407 0.0406 0.0407 

[TRAIN] Epoch[6](499/1500); Loss: 0.078618; Backpropagation: 0.0938 sec; Batch: 0.4286 sec
0.1866 0.1523 0.1346 0.0811 0.0737 0.0630 0.0600 0.0580 0.0571 0.0560 0.0555 0.0554 0.0557 0.0561 0.0563 0.0565 

[TRAIN] Epoch[6](500/1500); Loss: 0.119737; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.1875 0.1758 0.1628 0.1310 0.1201 0.1118 0.1082 0.1041 0.1033 0.1022 0.1015 0.1014 0.1013 0.1015 0.1015 0.1017 

[TRAIN] Epoch[6](501/1500); Loss: 0.159219; Backpropagation: 0.0941 sec; Batch: 0.4285 sec
0.3266 0.2810 0.2727 0.1928 0.1739 0.1391 0.1235 0.1143 0.1123 0.1132 0.1147 0.1149 0.1157 0.1164 0.1175 0.1187 

[TRAIN] Epoch[6](502/1500); Loss: 0.144858; Backpropagation: 0.0998 sec; Batch: 0.4420 sec
0.2449 0.2359 0.2124 0.1629 0.1488 0.1346 0.1262 0.1211 0.1188 0.1171 0.1168 0.1161 0.1156 0.1153 0.1155 0.1156 

[TRAIN] Epoch[6](503/1500); Loss: 0.125630; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.2361 0.2091 0.1980 0.1427 0.1264 0.1091 0.1032 0.1022 0.1005 0.0987 0.0975 0.0973 0.0974 0.0976 0.0970 0.0973 

[TRAIN] Epoch[6](504/1500); Loss: 0.107665; Backpropagation: 0.0994 sec; Batch: 0.4671 sec
0.2912 0.3201 0.2398 0.1411 0.0695 0.0613 0.0694 0.0660 0.0634 0.0611 0.0579 0.0563 0.0555 0.0563 0.0569 0.0569 

[TRAIN] Epoch[6](505/1500); Loss: 0.152361; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.2098 0.1947 0.1890 0.1674 0.1601 0.1477 0.1416 0.1378 0.1364 0.1370 0.1369 0.1363 0.1357 0.1353 0.1360 0.1362 

[TRAIN] Epoch[6](506/1500); Loss: 0.087719; Backpropagation: 0.0990 sec; Batch: 0.4743 sec
0.1700 0.1388 0.1335 0.0850 0.0791 0.0765 0.0740 0.0724 0.0725 0.0719 0.0713 0.0714 0.0715 0.0717 0.0718 0.0722 

[TRAIN] Epoch[6](507/1500); Loss: 0.140314; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.2121 0.2130 0.1812 0.1427 0.1367 0.1299 0.1272 0.1242 0.1232 0.1222 0.1219 0.1219 0.1221 0.1222 0.1221 0.1225 

[TRAIN] Epoch[6](508/1500); Loss: 0.145841; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.2391 0.2321 0.2057 0.1556 0.1439 0.1319 0.1258 0.1244 0.1233 0.1229 0.1218 0.1214 0.1215 0.1211 0.1216 0.1214 

[TRAIN] Epoch[6](509/1500); Loss: 0.072305; Backpropagation: 0.0990 sec; Batch: 0.4340 sec
0.1030 0.1171 0.0711 0.0717 0.0681 0.0672 0.0661 0.0647 0.0641 0.0650 0.0656 0.0656 0.0656 0.0668 0.0674 0.0677 

[TRAIN] Epoch[6](510/1500); Loss: 0.101756; Backpropagation: 0.0996 sec; Batch: 0.4344 sec
0.1927 0.1982 0.1606 0.1103 0.0982 0.0863 0.0822 0.0811 0.0798 0.0777 0.0773 0.0772 0.0767 0.0769 0.0767 0.0763 

[TRAIN] Epoch[6](511/1500); Loss: 0.124236; Backpropagation: 0.0996 sec; Batch: 0.4349 sec
0.1750 0.1639 0.1529 0.1331 0.1254 0.1183 0.1156 0.1126 0.1108 0.1102 0.1100 0.1106 0.1110 0.1117 0.1127 0.1140 

[TRAIN] Epoch[6](512/1500); Loss: 0.059740; Backpropagation: 0.0988 sec; Batch: 0.4339 sec
0.1982 0.1345 0.1294 0.0445 0.0515 0.0442 0.0386 0.0360 0.0345 0.0355 0.0354 0.0346 0.0341 0.0343 0.0353 0.0351 

[TRAIN] Epoch[6](513/1500); Loss: 0.064655; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1138 0.0723 0.0705 0.0721 0.0654 0.0663 0.0621 0.0605 0.0582 0.0565 0.0557 0.0561 0.0560 0.0559 0.0564 0.0567 

[TRAIN] Epoch[6](514/1500); Loss: 0.104897; Backpropagation: 0.0982 sec; Batch: 0.4325 sec
0.1435 0.1472 0.1256 0.1095 0.1022 0.0980 0.0970 0.0964 0.0955 0.0952 0.0950 0.0945 0.0946 0.0946 0.0947 0.0950 

[TRAIN] Epoch[6](515/1500); Loss: 0.154225; Backpropagation: 0.0990 sec; Batch: 0.4345 sec
0.2479 0.2366 0.2101 0.1627 0.1521 0.1438 0.1381 0.1334 0.1320 0.1306 0.1301 0.1297 0.1299 0.1301 0.1302 0.1303 

[TRAIN] Epoch[6](516/1500); Loss: 0.114314; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1693 0.1749 0.1413 0.1133 0.1076 0.1025 0.1021 0.1016 0.1017 0.1019 0.1024 0.1016 0.1018 0.1017 0.1024 0.1028 

[TRAIN] Epoch[6](517/1500); Loss: 0.065034; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1188 0.1202 0.0790 0.0659 0.0594 0.0558 0.0546 0.0538 0.0541 0.0538 0.0534 0.0534 0.0540 0.0545 0.0547 0.0549 

[TRAIN] Epoch[6](518/1500); Loss: 0.177806; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2287 0.2325 0.2078 0.1914 0.1806 0.1705 0.1680 0.1662 0.1645 0.1633 0.1628 0.1621 0.1616 0.1613 0.1616 0.1618 

[TRAIN] Epoch[6](519/1500); Loss: 0.125250; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.3136 0.2948 0.2575 0.1690 0.1272 0.0887 0.0788 0.0783 0.0739 0.0739 0.0736 0.0739 0.0743 0.0750 0.0754 0.0762 

[TRAIN] Epoch[6](520/1500); Loss: 0.111854; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.2608 0.2417 0.2207 0.1541 0.1340 0.0948 0.0731 0.0715 0.0684 0.0693 0.0682 0.0672 0.0666 0.0659 0.0659 0.0676 

[TRAIN] Epoch[6](521/1500); Loss: 0.112356; Backpropagation: 0.0996 sec; Batch: 0.4347 sec
0.1414 0.1419 0.1262 0.1207 0.1144 0.1114 0.1089 0.1070 0.1059 0.1054 0.1041 0.1033 0.1021 0.1017 0.1016 0.1015 

[TRAIN] Epoch[6](522/1500); Loss: 0.128614; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.1909 0.1962 0.1645 0.1373 0.1238 0.1178 0.1168 0.1152 0.1143 0.1127 0.1121 0.1116 0.1115 0.1110 0.1109 0.1111 

[TRAIN] Epoch[6](523/1500); Loss: 0.068058; Backpropagation: 0.0990 sec; Batch: 0.4339 sec
0.1238 0.1426 0.0907 0.0652 0.0583 0.0566 0.0559 0.0555 0.0556 0.0544 0.0547 0.0549 0.0547 0.0549 0.0555 0.0554 

[TRAIN] Epoch[6](524/1500); Loss: 0.132503; Backpropagation: 0.0984 sec; Batch: 0.4323 sec
0.1758 0.1729 0.1564 0.1378 0.1358 0.1262 0.1236 0.1219 0.1211 0.1205 0.1208 0.1209 0.1217 0.1216 0.1217 0.1213 

[TRAIN] Epoch[6](525/1500); Loss: 0.053405; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.0898 0.1089 0.0634 0.0530 0.0495 0.0461 0.0448 0.0441 0.0435 0.0433 0.0441 0.0442 0.0443 0.0444 0.0450 0.0461 

[TRAIN] Epoch[6](526/1500); Loss: 0.078748; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1098 0.1152 0.0878 0.0846 0.0783 0.0708 0.0708 0.0703 0.0708 0.0707 0.0708 0.0708 0.0715 0.0724 0.0725 0.0730 

[TRAIN] Epoch[6](527/1500); Loss: 0.124122; Backpropagation: 0.0985 sec; Batch: 0.4391 sec
0.2892 0.2872 0.2503 0.1736 0.1334 0.0923 0.0810 0.0781 0.0759 0.0746 0.0747 0.0746 0.0746 0.0747 0.0755 0.0761 

[TRAIN] Epoch[6](528/1500); Loss: 0.063819; Backpropagation: 0.0993 sec; Batch: 0.4357 sec
0.1225 0.1377 0.0849 0.0601 0.0529 0.0514 0.0512 0.0505 0.0506 0.0506 0.0509 0.0515 0.0512 0.0512 0.0513 0.0525 

[TRAIN] Epoch[6](529/1500); Loss: 0.137730; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.2056 0.2234 0.1884 0.1605 0.1397 0.1260 0.1201 0.1173 0.1158 0.1155 0.1152 0.1152 0.1149 0.1149 0.1154 0.1156 

[TRAIN] Epoch[6](530/1500); Loss: 0.172306; Backpropagation: 0.0982 sec; Batch: 0.4325 sec
0.2352 0.2184 0.2079 0.1770 0.1694 0.1610 0.1562 0.1559 0.1564 0.1560 0.1567 0.1585 0.1600 0.1612 0.1625 0.1645 

[TRAIN] Epoch[6](531/1500); Loss: 0.131600; Backpropagation: 0.0984 sec; Batch: 0.4326 sec
0.1858 0.1742 0.1647 0.1394 0.1337 0.1270 0.1224 0.1194 0.1176 0.1183 0.1181 0.1178 0.1171 0.1170 0.1167 0.1166 

[TRAIN] Epoch[6](532/1500); Loss: 0.140263; Backpropagation: 0.0983 sec; Batch: 0.4344 sec
0.1843 0.1751 0.1657 0.1461 0.1377 0.1331 0.1345 0.1324 0.1316 0.1301 0.1298 0.1293 0.1292 0.1290 0.1287 0.1276 

[TRAIN] Epoch[6](533/1500); Loss: 0.099112; Backpropagation: 0.0997 sec; Batch: 0.4346 sec
0.1678 0.1695 0.1336 0.1149 0.0992 0.0894 0.0868 0.0848 0.0836 0.0819 0.0803 0.0803 0.0792 0.0782 0.0781 0.0781 

[TRAIN] Epoch[6](534/1500); Loss: 0.092069; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.1372 0.1251 0.1084 0.1068 0.0967 0.0855 0.0837 0.0823 0.0819 0.0814 0.0807 0.0802 0.0803 0.0808 0.0813 0.0809 

[TRAIN] Epoch[6](535/1500); Loss: 0.106145; Backpropagation: 0.0992 sec; Batch: 0.4378 sec
0.1939 0.2000 0.1471 0.1053 0.0945 0.0893 0.0867 0.0866 0.0866 0.0856 0.0860 0.0863 0.0863 0.0875 0.0883 0.0884 

[TRAIN] Epoch[6](536/1500); Loss: 0.134162; Backpropagation: 0.0991 sec; Batch: 0.4340 sec
0.2045 0.1927 0.1704 0.1427 0.1349 0.1276 0.1224 0.1193 0.1174 0.1170 0.1167 0.1164 0.1162 0.1158 0.1158 0.1167 

[TRAIN] Epoch[6](537/1500); Loss: 0.133597; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.1833 0.1974 0.1620 0.1384 0.1335 0.1265 0.1246 0.1211 0.1188 0.1189 0.1189 0.1177 0.1183 0.1191 0.1195 0.1194 

[TRAIN] Epoch[6](538/1500); Loss: 0.139069; Backpropagation: 0.0988 sec; Batch: 0.4331 sec
0.2497 0.2676 0.2220 0.1518 0.1265 0.1216 0.1222 0.1138 0.1119 0.1080 0.1050 0.1037 0.1043 0.1056 0.1059 0.1055 

[TRAIN] Epoch[6](539/1500); Loss: 0.094013; Backpropagation: 0.0988 sec; Batch: 0.4342 sec
0.1398 0.1843 0.1261 0.0940 0.0850 0.0822 0.0792 0.0788 0.0767 0.0778 0.0755 0.0781 0.0798 0.0805 0.0824 0.0841 

[TRAIN] Epoch[6](540/1500); Loss: 0.142665; Backpropagation: 0.0982 sec; Batch: 0.4329 sec
0.1663 0.1696 0.1454 0.1390 0.1366 0.1420 0.1371 0.1375 0.1390 0.1358 0.1339 0.1357 0.1379 0.1397 0.1422 0.1451 

[TRAIN] Epoch[6](541/1500); Loss: 0.191869; Backpropagation: 0.0986 sec; Batch: 0.4330 sec
0.1145 0.1174 0.1115 0.1579 0.1787 0.2011 0.2063 0.2029 0.2034 0.2038 0.2092 0.2155 0.2238 0.2324 0.2416 0.2499 

[TRAIN] Epoch[6](542/1500); Loss: 0.416653; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.3124 0.4097 0.3505 0.3682 0.3737 0.4020 0.4092 0.4145 0.4181 0.4274 0.4352 0.4459 0.4561 0.4698 0.4805 0.4931 

[TRAIN] Epoch[6](543/1500); Loss: 0.263223; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1446 0.1510 0.1435 0.2085 0.2236 0.2430 0.2523 0.2668 0.2787 0.2926 0.3045 0.3176 0.3294 0.3414 0.3521 0.3621 

[TRAIN] Epoch[6](544/1500); Loss: 0.409422; Backpropagation: 0.0990 sec; Batch: 0.4337 sec
0.2338 0.2646 0.2554 0.2978 0.3132 0.3518 0.3765 0.4041 0.4257 0.4517 0.4746 0.4986 0.5213 0.5426 0.5608 0.5783 

[TRAIN] Epoch[6](545/1500); Loss: 0.433215; Backpropagation: 0.0987 sec; Batch: 0.4332 sec
0.2233 0.2367 0.2292 0.2598 0.2902 0.3508 0.3897 0.4206 0.4543 0.4877 0.5241 0.5512 0.5816 0.6099 0.6462 0.6760 

[TRAIN] Epoch[6](546/1500); Loss: 0.382763; Backpropagation: 0.0986 sec; Batch: 0.4328 sec
0.0899 0.1513 0.1382 0.2350 0.2698 0.3212 0.3626 0.3943 0.4242 0.4525 0.4832 0.5068 0.5365 0.5603 0.5881 0.6105 

[TRAIN] Epoch[6](547/1500); Loss: 0.345037; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1469 0.2047 0.1891 0.2515 0.2722 0.3066 0.3291 0.3511 0.3699 0.3921 0.4105 0.4288 0.4439 0.4594 0.4751 0.4898 

[TRAIN] Epoch[6](548/1500); Loss: 0.280243; Backpropagation: 0.0982 sec; Batch: 0.4330 sec
0.1896 0.1950 0.1897 0.2320 0.2486 0.2682 0.2817 0.2935 0.3016 0.3099 0.3134 0.3196 0.3255 0.3314 0.3385 0.3457 

[TRAIN] Epoch[6](549/1500); Loss: 0.170706; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1725 0.1530 0.1384 0.1228 0.1289 0.1425 0.1519 0.1713 0.1768 0.1829 0.1857 0.1909 0.1953 0.2023 0.2062 0.2098 

[TRAIN] Epoch[6](550/1500); Loss: 0.272606; Backpropagation: 0.1025 sec; Batch: 0.4375 sec
0.2702 0.3341 0.2864 0.2977 0.2994 0.2989 0.2914 0.2829 0.2717 0.2628 0.2537 0.2481 0.2436 0.2411 0.2390 0.2408 

[TRAIN] Epoch[6](551/1500); Loss: 0.228195; Backpropagation: 0.1026 sec; Batch: 0.4374 sec
0.3716 0.3088 0.3024 0.2163 0.1959 0.1748 0.1780 0.1915 0.1963 0.2048 0.2081 0.2134 0.2169 0.2207 0.2240 0.2276 

[TRAIN] Epoch[6](552/1500); Loss: 0.231835; Backpropagation: 0.0993 sec; Batch: 0.4331 sec
0.1975 0.2005 0.1981 0.2369 0.2493 0.2467 0.2399 0.2357 0.2351 0.2361 0.2373 0.2379 0.2375 0.2392 0.2406 0.2412 

[TRAIN] Epoch[6](553/1500); Loss: 0.129211; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1372 0.1093 0.1058 0.1219 0.1318 0.1275 0.1274 0.1272 0.1287 0.1302 0.1318 0.1344 0.1365 0.1383 0.1392 0.1404 

[TRAIN] Epoch[6](554/1500); Loss: 0.106019; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.1168 0.1063 0.0935 0.1055 0.1134 0.1098 0.1089 0.1042 0.1032 0.1031 0.1039 0.1035 0.1042 0.1057 0.1065 0.1079 

[TRAIN] Epoch[6](555/1500); Loss: 0.150033; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.2047 0.1774 0.1703 0.1542 0.1538 0.1445 0.1431 0.1400 0.1391 0.1379 0.1378 0.1376 0.1385 0.1396 0.1408 0.1414 

[TRAIN] Epoch[6](556/1500); Loss: 0.075267; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.1033 0.0620 0.0617 0.0807 0.0871 0.0734 0.0723 0.0692 0.0705 0.0721 0.0719 0.0729 0.0751 0.0762 0.0767 0.0794 

[TRAIN] Epoch[6](557/1500); Loss: 0.177181; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1685 0.1604 0.1601 0.1967 0.1990 0.1820 0.1802 0.1779 0.1761 0.1763 0.1750 0.1755 0.1760 0.1767 0.1769 0.1777 

[TRAIN] Epoch[6](558/1500); Loss: 0.105312; Backpropagation: 0.0985 sec; Batch: 0.4325 sec
0.1105 0.0969 0.0941 0.1169 0.1195 0.1057 0.1060 0.1056 0.1045 0.1030 0.1025 0.1025 0.1029 0.1045 0.1047 0.1053 

[TRAIN] Epoch[6](559/1500); Loss: 0.108227; Backpropagation: 0.1009 sec; Batch: 0.4357 sec
0.1321 0.1115 0.1076 0.1237 0.1181 0.1063 0.1066 0.1055 0.1036 0.1028 0.1024 0.1022 0.1018 0.1022 0.1027 0.1026 

[TRAIN] Epoch[6](560/1500); Loss: 0.156392; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.2161 0.1846 0.1820 0.1550 0.1519 0.1466 0.1462 0.1473 0.1466 0.1469 0.1459 0.1453 0.1456 0.1467 0.1475 0.1482 

[TRAIN] Epoch[6](561/1500); Loss: 0.090269; Backpropagation: 0.0983 sec; Batch: 0.4335 sec
0.0940 0.1614 0.1064 0.0944 0.0861 0.0827 0.0803 0.0787 0.0790 0.0798 0.0810 0.0816 0.0823 0.0842 0.0854 0.0869 

[TRAIN] Epoch[6](562/1500); Loss: 0.095754; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.1239 0.0875 0.0860 0.1020 0.1058 0.0912 0.0934 0.0927 0.0915 0.0921 0.0922 0.0930 0.0938 0.0948 0.0956 0.0966 

[TRAIN] Epoch[6](563/1500); Loss: 0.108368; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.1140 0.1216 0.1116 0.1182 0.1189 0.1106 0.1091 0.1064 0.1030 0.1024 0.1023 0.1026 0.1024 0.1028 0.1035 0.1045 

[TRAIN] Epoch[6](564/1500); Loss: 0.136354; Backpropagation: 0.0991 sec; Batch: 0.4337 sec
0.1702 0.1749 0.1575 0.1494 0.1454 0.1388 0.1333 0.1294 0.1257 0.1230 0.1224 0.1220 0.1220 0.1217 0.1228 0.1232 

[TRAIN] Epoch[6](565/1500); Loss: 0.152033; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1880 0.1774 0.1680 0.1717 0.1630 0.1532 0.1499 0.1473 0.1431 0.1418 0.1394 0.1391 0.1380 0.1382 0.1373 0.1370 

[TRAIN] Epoch[6](566/1500); Loss: 0.183471; Backpropagation: 0.0991 sec; Batch: 0.4337 sec
0.1932 0.2210 0.1961 0.1954 0.1921 0.1861 0.1813 0.1773 0.1751 0.1745 0.1742 0.1746 0.1739 0.1736 0.1735 0.1737 

[TRAIN] Epoch[6](567/1500); Loss: 0.139473; Backpropagation: 0.0985 sec; Batch: 0.4340 sec
0.2599 0.2150 0.2084 0.1703 0.1571 0.1325 0.1249 0.1150 0.1106 0.1059 0.1047 0.1047 0.1043 0.1048 0.1064 0.1071 

[TRAIN] Epoch[6](568/1500); Loss: 0.136753; Backpropagation: 0.0989 sec; Batch: 0.4334 sec
0.1865 0.2084 0.1786 0.1587 0.1490 0.1383 0.1299 0.1224 0.1169 0.1156 0.1147 0.1138 0.1137 0.1136 0.1140 0.1140 

[TRAIN] Epoch[6](569/1500); Loss: 0.188581; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.2618 0.3509 0.2812 0.2526 0.2256 0.1931 0.1618 0.1430 0.1412 0.1417 0.1424 0.1424 0.1436 0.1442 0.1452 0.1467 

[TRAIN] Epoch[6](570/1500); Loss: 0.153964; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.3385 0.2801 0.2766 0.1907 0.1699 0.1403 0.1220 0.1043 0.1032 0.1065 0.1040 0.1040 0.1045 0.1056 0.1063 0.1071 

[TRAIN] Epoch[6](571/1500); Loss: 0.140735; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.1885 0.1659 0.1626 0.1428 0.1414 0.1368 0.1365 0.1369 0.1337 0.1320 0.1293 0.1296 0.1295 0.1291 0.1281 0.1290 

[TRAIN] Epoch[6](572/1500); Loss: 0.110809; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1552 0.1277 0.1242 0.1174 0.1148 0.1085 0.1074 0.1059 0.1042 0.1029 0.1020 0.1007 0.1002 0.1002 0.1005 0.1012 

[TRAIN] Epoch[6](573/1500); Loss: 0.175665; Backpropagation: 0.0987 sec; Batch: 0.4341 sec
0.1896 0.2036 0.1888 0.1893 0.1869 0.1808 0.1757 0.1725 0.1702 0.1674 0.1669 0.1653 0.1643 0.1635 0.1633 0.1626 

[TRAIN] Epoch[6](574/1500); Loss: 0.176668; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.1933 0.1979 0.1861 0.1868 0.1852 0.1798 0.1768 0.1748 0.1724 0.1702 0.1696 0.1684 0.1670 0.1665 0.1661 0.1657 

[TRAIN] Epoch[6](575/1500); Loss: 0.193188; Backpropagation: 0.0993 sec; Batch: 0.4333 sec
0.5355 0.4371 0.4289 0.2682 0.2215 0.1639 0.1215 0.1003 0.0990 0.1019 0.0996 0.1019 0.1006 0.1025 0.1039 0.1048 

[TRAIN] Epoch[6](576/1500); Loss: 0.106597; Backpropagation: 0.0992 sec; Batch: 0.4337 sec
0.1696 0.1274 0.1261 0.1117 0.1127 0.1028 0.1002 0.0981 0.0961 0.0954 0.0952 0.0949 0.0941 0.0942 0.0935 0.0937 

[TRAIN] Epoch[6](577/1500); Loss: 0.112897; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.1589 0.1457 0.1385 0.1189 0.1179 0.1114 0.1090 0.1059 0.1028 0.1013 0.0997 0.0996 0.0995 0.0993 0.0990 0.0988 

[TRAIN] Epoch[6](578/1500); Loss: 0.150996; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2072 0.2628 0.2131 0.1979 0.1808 0.1627 0.1481 0.1373 0.1261 0.1178 0.1123 0.1104 0.1098 0.1100 0.1095 0.1102 

[TRAIN] Epoch[6](579/1500); Loss: 0.121835; Backpropagation: 0.1080 sec; Batch: 0.4440 sec
0.1667 0.1549 0.1426 0.1282 0.1240 0.1161 0.1140 0.1120 0.1116 0.1109 0.1106 0.1110 0.1109 0.1113 0.1119 0.1126 

[TRAIN] Epoch[6](580/1500); Loss: 0.162277; Backpropagation: 0.1029 sec; Batch: 0.4383 sec
0.1871 0.1913 0.1798 0.1725 0.1678 0.1609 0.1575 0.1552 0.1537 0.1529 0.1523 0.1525 0.1526 0.1532 0.1535 0.1537 

[TRAIN] Epoch[6](581/1500); Loss: 0.143871; Backpropagation: 0.0994 sec; Batch: 0.4343 sec
0.3338 0.2748 0.2713 0.1833 0.1612 0.1298 0.1101 0.0936 0.0930 0.0935 0.0928 0.0921 0.0924 0.0930 0.0933 0.0941 

[TRAIN] Epoch[6](582/1500); Loss: 0.112730; Backpropagation: 0.0989 sec; Batch: 0.4337 sec
0.1534 0.2506 0.1685 0.1449 0.1194 0.0989 0.0882 0.0851 0.0828 0.0838 0.0847 0.0853 0.0865 0.0888 0.0906 0.0923 

[TRAIN] Epoch[6](583/1500); Loss: 0.111503; Backpropagation: 0.0986 sec; Batch: 0.4343 sec
0.1420 0.1193 0.1133 0.1231 0.1227 0.1082 0.1079 0.1065 0.1050 0.1045 0.1043 0.1046 0.1050 0.1053 0.1059 0.1068 

[TRAIN] Epoch[6](584/1500); Loss: 0.113426; Backpropagation: 0.0990 sec; Batch: 0.4337 sec
0.1320 0.1452 0.1244 0.1265 0.1218 0.1167 0.1122 0.1085 0.1071 0.1055 0.1034 0.1029 0.1023 0.1017 0.1018 0.1027 

[TRAIN] Epoch[6](585/1500); Loss: 0.155619; Backpropagation: 0.1025 sec; Batch: 0.4379 sec
0.2251 0.2204 0.2034 0.1759 0.1658 0.1527 0.1440 0.1372 0.1342 0.1326 0.1321 0.1331 0.1329 0.1332 0.1335 0.1338 

[TRAIN] Epoch[6](586/1500); Loss: 0.080438; Backpropagation: 0.0994 sec; Batch: 0.4338 sec
0.2051 0.1422 0.1393 0.0818 0.0701 0.0606 0.0579 0.0582 0.0570 0.0570 0.0574 0.0582 0.0588 0.0599 0.0610 0.0625 

[TRAIN] Epoch[6](587/1500); Loss: 0.112311; Backpropagation: 0.0995 sec; Batch: 0.4345 sec
0.1724 0.1358 0.1344 0.1227 0.1226 0.1083 0.1031 0.1011 0.1003 0.0997 0.0994 0.0996 0.0993 0.0993 0.0992 0.0999 

[TRAIN] Epoch[6](588/1500); Loss: 0.144847; Backpropagation: 0.0992 sec; Batch: 0.4337 sec
0.2157 0.1820 0.1780 0.1582 0.1489 0.1358 0.1344 0.1320 0.1299 0.1281 0.1277 0.1282 0.1284 0.1292 0.1298 0.1313 

[TRAIN] Epoch[6](589/1500); Loss: 0.127213; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2002 0.1702 0.1657 0.1332 0.1276 0.1199 0.1167 0.1137 0.1126 0.1114 0.1118 0.1109 0.1105 0.1104 0.1103 0.1102 

[TRAIN] Epoch[6](590/1500); Loss: 0.117647; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1729 0.1602 0.1506 0.1317 0.1240 0.1117 0.1079 0.1056 0.1033 0.1026 0.1021 0.1016 0.1016 0.1017 0.1021 0.1027 

[TRAIN] Epoch[6](591/1500); Loss: 0.091653; Backpropagation: 0.0988 sec; Batch: 0.4334 sec
0.2160 0.1615 0.1582 0.0958 0.0866 0.0727 0.0691 0.0693 0.0682 0.0665 0.0670 0.0669 0.0670 0.0671 0.0673 0.0673 

[TRAIN] Epoch[6](592/1500); Loss: 0.112120; Backpropagation: 0.0982 sec; Batch: 0.4329 sec
0.1721 0.1668 0.1470 0.1259 0.1196 0.1100 0.1044 0.1014 0.0978 0.0939 0.0934 0.0934 0.0925 0.0918 0.0919 0.0921 

[TRAIN] Epoch[6](593/1500); Loss: 0.177601; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.3246 0.2961 0.2781 0.2133 0.1924 0.1623 0.1414 0.1376 0.1342 0.1348 0.1362 0.1357 0.1372 0.1380 0.1391 0.1406 

[TRAIN] Epoch[6](594/1500); Loss: 0.201937; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.3491 0.2977 0.2915 0.2247 0.2079 0.1868 0.1734 0.1673 0.1659 0.1678 0.1675 0.1668 0.1665 0.1659 0.1661 0.1660 

[TRAIN] Epoch[6](595/1500); Loss: 0.115044; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1619 0.1869 0.1592 0.1422 0.1291 0.1154 0.1062 0.0999 0.0973 0.0953 0.0934 0.0922 0.0909 0.0908 0.0902 0.0897 

[TRAIN] Epoch[6](596/1500); Loss: 0.073433; Backpropagation: 0.0983 sec; Batch: 0.4334 sec
0.2285 0.1690 0.1658 0.0936 0.0829 0.0619 0.0491 0.0397 0.0361 0.0342 0.0344 0.0348 0.0356 0.0357 0.0363 0.0372 

[TRAIN] Epoch[6](597/1500); Loss: 0.141991; Backpropagation: 0.0991 sec; Batch: 0.4344 sec
0.1781 0.1866 0.1599 0.1548 0.1467 0.1382 0.1343 0.1324 0.1303 0.1296 0.1296 0.1297 0.1296 0.1301 0.1306 0.1313 

[TRAIN] Epoch[6](598/1500); Loss: 0.103074; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1524 0.1202 0.1157 0.1133 0.1094 0.1006 0.0985 0.0968 0.0949 0.0927 0.0924 0.0925 0.0925 0.0924 0.0923 0.0925 

[TRAIN] Epoch[6](599/1500); Loss: 0.160242; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.2557 0.2259 0.2211 0.1850 0.1757 0.1589 0.1489 0.1387 0.1347 0.1332 0.1330 0.1320 0.1307 0.1304 0.1304 0.1296 

[TRAIN] Epoch[6](600/1500); Loss: 0.109808; Backpropagation: 0.0982 sec; Batch: 0.4332 sec
0.1393 0.1379 0.1243 0.1204 0.1177 0.1085 0.1053 0.1030 0.1010 0.0998 0.0996 0.0993 0.0995 0.1000 0.1003 0.1010 

[TRAIN] Epoch[6](601/1500); Loss: 0.099192; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1569 0.2439 0.1704 0.1352 0.1017 0.0817 0.0733 0.0699 0.0681 0.0677 0.0675 0.0681 0.0688 0.0698 0.0714 0.0726 

[TRAIN] Epoch[6](602/1500); Loss: 0.090787; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1191 0.1101 0.1026 0.0969 0.0958 0.0893 0.0867 0.0849 0.0840 0.0836 0.0833 0.0833 0.0831 0.0831 0.0833 0.0836 

[TRAIN] Epoch[6](603/1500); Loss: 0.095383; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.1605 0.1333 0.1285 0.1048 0.0991 0.0884 0.0841 0.0839 0.0834 0.0803 0.0797 0.0803 0.0804 0.0797 0.0798 0.0800 

[TRAIN] Epoch[6](604/1500); Loss: 0.157723; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.2492 0.2394 0.2224 0.1823 0.1714 0.1588 0.1485 0.1389 0.1331 0.1291 0.1272 0.1264 0.1254 0.1242 0.1239 0.1234 

[TRAIN] Epoch[6](605/1500); Loss: 0.145378; Backpropagation: 0.0994 sec; Batch: 0.4340 sec
0.2015 0.1877 0.1745 0.1561 0.1539 0.1415 0.1387 0.1350 0.1320 0.1299 0.1290 0.1289 0.1290 0.1291 0.1294 0.1297 

[TRAIN] Epoch[6](606/1500); Loss: 0.078627; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1676 0.1230 0.1213 0.0864 0.0823 0.0697 0.0657 0.0637 0.0618 0.0613 0.0604 0.0596 0.0592 0.0588 0.0585 0.0587 

[TRAIN] Epoch[6](607/1500); Loss: 0.074800; Backpropagation: 0.0986 sec; Batch: 0.4339 sec
0.1748 0.1218 0.1208 0.0718 0.0653 0.0629 0.0600 0.0584 0.0573 0.0566 0.0564 0.0565 0.0572 0.0579 0.0588 0.0603 

[TRAIN] Epoch[6](608/1500); Loss: 0.073044; Backpropagation: 0.0988 sec; Batch: 0.4343 sec
0.2422 0.1668 0.1655 0.0617 0.0476 0.0503 0.0442 0.0433 0.0422 0.0417 0.0421 0.0426 0.0431 0.0440 0.0452 0.0462 

[TRAIN] Epoch[6](609/1500); Loss: 0.165002; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.2946 0.2499 0.2443 0.1880 0.1749 0.1602 0.1503 0.1416 0.1369 0.1341 0.1313 0.1291 0.1273 0.1263 0.1257 0.1255 

[TRAIN] Epoch[6](610/1500); Loss: 0.128463; Backpropagation: 0.0987 sec; Batch: 0.4336 sec
0.1887 0.2317 0.1898 0.1736 0.1542 0.1307 0.1144 0.1040 0.0989 0.0968 0.0956 0.0951 0.0949 0.0954 0.0957 0.0957 

[TRAIN] Epoch[6](611/1500); Loss: 0.062376; Backpropagation: 0.0988 sec; Batch: 0.4341 sec
0.1761 0.1203 0.1192 0.0731 0.0687 0.0500 0.0442 0.0396 0.0377 0.0382 0.0387 0.0382 0.0380 0.0386 0.0385 0.0389 

[TRAIN] Epoch[6](612/1500); Loss: 0.058391; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1504 0.0926 0.0917 0.0513 0.0555 0.0460 0.0441 0.0432 0.0422 0.0424 0.0434 0.0436 0.0448 0.0460 0.0474 0.0497 

[TRAIN] Epoch[6](613/1500); Loss: 0.161871; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1872 0.1900 0.1778 0.1684 0.1631 0.1591 0.1571 0.1557 0.1548 0.1542 0.1539 0.1536 0.1533 0.1535 0.1539 0.1544 

[TRAIN] Epoch[6](614/1500); Loss: 0.088861; Backpropagation: 0.1028 sec; Batch: 0.4383 sec
0.1152 0.1499 0.1129 0.1035 0.0915 0.0830 0.0777 0.0752 0.0744 0.0746 0.0748 0.0757 0.0766 0.0777 0.0789 0.0802 

[TRAIN] Epoch[6](615/1500); Loss: 0.155781; Backpropagation: 0.0996 sec; Batch: 0.4346 sec
0.2103 0.1978 0.1861 0.1661 0.1622 0.1526 0.1489 0.1449 0.1422 0.1413 0.1408 0.1403 0.1401 0.1399 0.1394 0.1397 

[TRAIN] Epoch[6](616/1500); Loss: 0.118636; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.2170 0.2079 0.1884 0.1412 0.1240 0.1083 0.1000 0.0942 0.0922 0.0908 0.0900 0.0895 0.0891 0.0887 0.0884 0.0883 

[TRAIN] Epoch[6](617/1500); Loss: 0.103229; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1636 0.1451 0.1326 0.1164 0.1141 0.1013 0.0955 0.0905 0.0876 0.0867 0.0861 0.0860 0.0860 0.0863 0.0868 0.0871 

[TRAIN] Epoch[6](618/1500); Loss: 0.122001; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1441 0.1584 0.1366 0.1288 0.1248 0.1210 0.1189 0.1166 0.1147 0.1133 0.1127 0.1123 0.1123 0.1123 0.1125 0.1128 

[TRAIN] Epoch[6](619/1500); Loss: 0.125094; Backpropagation: 0.0983 sec; Batch: 0.4339 sec
0.1333 0.1572 0.1301 0.1274 0.1245 0.1230 0.1214 0.1207 0.1204 0.1201 0.1201 0.1200 0.1202 0.1205 0.1210 0.1214 

[TRAIN] Epoch[6](620/1500); Loss: 0.168086; Backpropagation: 0.1080 sec; Batch: 0.4432 sec
0.2049 0.2038 0.1913 0.1765 0.1717 0.1669 0.1641 0.1620 0.1599 0.1582 0.1570 0.1560 0.1552 0.1544 0.1539 0.1536 

[TRAIN] Epoch[6](621/1500); Loss: 0.108273; Backpropagation: 0.1086 sec; Batch: 0.4435 sec
0.1468 0.1274 0.1189 0.1130 0.1111 0.1081 0.1058 0.1041 0.1021 0.1010 0.0999 0.0996 0.0987 0.0985 0.0986 0.0988 

[TRAIN] Epoch[6](622/1500); Loss: 0.111269; Backpropagation: 0.0989 sec; Batch: 0.4335 sec
0.1875 0.1593 0.1499 0.1188 0.1166 0.1074 0.1046 0.1008 0.0989 0.0964 0.0946 0.0928 0.0903 0.0890 0.0871 0.0864 

[TRAIN] Epoch[6](623/1500); Loss: 0.122221; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2457 0.3505 0.2619 0.2101 0.1478 0.0911 0.0727 0.0663 0.0614 0.0619 0.0620 0.0631 0.0635 0.0646 0.0654 0.0676 

[TRAIN] Epoch[6](624/1500); Loss: 0.105808; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1739 0.1355 0.1354 0.1142 0.1110 0.1026 0.0985 0.0950 0.0932 0.0918 0.0911 0.0906 0.0903 0.0899 0.0901 0.0898 

[TRAIN] Epoch[6](625/1500); Loss: 0.153676; Backpropagation: 0.0985 sec; Batch: 0.4343 sec
0.1803 0.1838 0.1699 0.1603 0.1554 0.1508 0.1491 0.1477 0.1467 0.1458 0.1452 0.1448 0.1448 0.1448 0.1447 0.1447 

[TRAIN] Epoch[6](626/1500); Loss: 0.181212; Backpropagation: 0.1025 sec; Batch: 0.4370 sec
0.2579 0.2364 0.2281 0.1974 0.1888 0.1752 0.1708 0.1667 0.1647 0.1630 0.1610 0.1595 0.1586 0.1577 0.1568 0.1566 

[TRAIN] Epoch[6](627/1500); Loss: 0.168135; Backpropagation: 0.1023 sec; Batch: 0.4372 sec
0.2607 0.2381 0.2287 0.1916 0.1812 0.1707 0.1627 0.1549 0.1492 0.1442 0.1399 0.1370 0.1350 0.1331 0.1321 0.1311 

[TRAIN] Epoch[6](628/1500); Loss: 0.111948; Backpropagation: 0.0990 sec; Batch: 0.4340 sec
0.1837 0.2224 0.1726 0.1521 0.1289 0.1070 0.0934 0.0881 0.0835 0.0809 0.0794 0.0788 0.0789 0.0795 0.0804 0.0816 

[TRAIN] Epoch[6](629/1500); Loss: 0.153454; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2811 0.2299 0.2274 0.1701 0.1583 0.1479 0.1409 0.1339 0.1296 0.1255 0.1227 0.1208 0.1189 0.1171 0.1159 0.1152 

[TRAIN] Epoch[6](630/1500); Loss: 0.104210; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1908 0.2758 0.1978 0.1517 0.1059 0.0809 0.0705 0.0675 0.0649 0.0645 0.0647 0.0651 0.0655 0.0664 0.0672 0.0681 

[TRAIN] Epoch[6](631/1500); Loss: 0.146353; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.2832 0.2867 0.2565 0.2024 0.1741 0.1467 0.1279 0.1164 0.1089 0.1031 0.0974 0.0928 0.0892 0.0870 0.0852 0.0843 

[TRAIN] Epoch[6](632/1500); Loss: 0.156431; Backpropagation: 0.0987 sec; Batch: 0.4342 sec
0.2136 0.2561 0.2140 0.1908 0.1683 0.1517 0.1440 0.1385 0.1345 0.1318 0.1298 0.1277 0.1267 0.1259 0.1250 0.1244 

[TRAIN] Epoch[6](633/1500); Loss: 0.135165; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.1515 0.1744 0.1484 0.1428 0.1390 0.1340 0.1305 0.1288 0.1276 0.1271 0.1269 0.1266 0.1262 0.1263 0.1264 0.1265 

[TRAIN] Epoch[6](634/1500); Loss: 0.082081; Backpropagation: 0.0984 sec; Batch: 0.4324 sec
0.1139 0.1606 0.1129 0.0938 0.0815 0.0725 0.0696 0.0682 0.0670 0.0669 0.0672 0.0674 0.0675 0.0677 0.0681 0.0684 

[TRAIN] Epoch[6](635/1500); Loss: 0.068063; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.0905 0.0913 0.0784 0.0732 0.0723 0.0689 0.0664 0.0645 0.0634 0.0622 0.0612 0.0604 0.0598 0.0592 0.0587 0.0584 

[TRAIN] Epoch[6](636/1500); Loss: 0.134366; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1920 0.2016 0.1753 0.1496 0.1389 0.1288 0.1216 0.1173 0.1153 0.1152 0.1150 0.1155 0.1153 0.1159 0.1161 0.1165 

[TRAIN] Epoch[6](637/1500); Loss: 0.103070; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1916 0.2931 0.2032 0.1506 0.0995 0.0732 0.0649 0.0630 0.0613 0.0614 0.0618 0.0629 0.0639 0.0648 0.0659 0.0681 

[TRAIN] Epoch[6](638/1500); Loss: 0.107983; Backpropagation: 0.1079 sec; Batch: 0.4426 sec
0.1399 0.1557 0.1273 0.1146 0.1051 0.1007 0.0992 0.0986 0.0981 0.0979 0.0976 0.0978 0.0981 0.0987 0.0990 0.0994 

[TRAIN] Epoch[6](639/1500); Loss: 0.110009; Backpropagation: 0.0997 sec; Batch: 0.4349 sec
0.1601 0.1781 0.1444 0.1310 0.1190 0.1089 0.1013 0.0955 0.0938 0.0920 0.0904 0.0895 0.0891 0.0888 0.0889 0.0892 

[TRAIN] Epoch[6](640/1500); Loss: 0.102967; Backpropagation: 0.0992 sec; Batch: 0.4341 sec
0.1357 0.1126 0.1169 0.1082 0.1064 0.1046 0.1020 0.1001 0.0986 0.0975 0.0964 0.0955 0.0943 0.0933 0.0928 0.0924 

[TRAIN] Epoch[6](641/1500); Loss: 0.083032; Backpropagation: 0.0991 sec; Batch: 0.4336 sec
0.1136 0.1394 0.1064 0.0961 0.0840 0.0748 0.0721 0.0704 0.0700 0.0702 0.0705 0.0708 0.0714 0.0721 0.0730 0.0737 

[TRAIN] Epoch[6](642/1500); Loss: 0.121486; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1968 0.1681 0.1572 0.1275 0.1300 0.1141 0.1117 0.1078 0.1057 0.1043 0.1034 0.1031 0.1033 0.1034 0.1037 0.1038 

[TRAIN] Epoch[6](643/1500); Loss: 0.088545; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.1146 0.1457 0.1096 0.1006 0.0908 0.0847 0.0804 0.0782 0.0769 0.0765 0.0762 0.0762 0.0762 0.0763 0.0768 0.0771 

[TRAIN] Epoch[6](644/1500); Loss: 0.072340; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.1092 0.1068 0.0861 0.0818 0.0779 0.0724 0.0687 0.0659 0.0636 0.0624 0.0616 0.0605 0.0603 0.0600 0.0601 0.0601 

[TRAIN] Epoch[6](645/1500); Loss: 0.148144; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2586 0.2231 0.2173 0.1846 0.1728 0.1509 0.1409 0.1305 0.1229 0.1179 0.1126 0.1094 0.1083 0.1078 0.1071 0.1056 

[TRAIN] Epoch[6](646/1500); Loss: 0.138679; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1708 0.1524 0.1499 0.1442 0.1435 0.1410 0.1378 0.1357 0.1338 0.1327 0.1316 0.1303 0.1295 0.1290 0.1285 0.1282 

[TRAIN] Epoch[6](647/1500); Loss: 0.104205; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1661 0.1408 0.1319 0.1077 0.1029 0.0962 0.0935 0.0924 0.0921 0.0915 0.0914 0.0916 0.0917 0.0920 0.0925 0.0929 

[TRAIN] Epoch[6](648/1500); Loss: 0.096739; Backpropagation: 0.0989 sec; Batch: 0.4331 sec
0.1721 0.2013 0.1588 0.1247 0.1016 0.0870 0.0799 0.0755 0.0726 0.0702 0.0687 0.0675 0.0668 0.0670 0.0671 0.0669 

[TRAIN] Epoch[6](649/1500); Loss: 0.108741; Backpropagation: 0.1027 sec; Batch: 0.4379 sec
0.1350 0.1377 0.1197 0.1207 0.1158 0.1081 0.1049 0.1031 0.1015 0.1008 0.0998 0.0995 0.0985 0.0983 0.0982 0.0983 

[TRAIN] Epoch[6](650/1500); Loss: 0.156207; Backpropagation: 0.1025 sec; Batch: 0.4374 sec
0.2512 0.2210 0.2123 0.1689 0.1618 0.1505 0.1430 0.1368 0.1345 0.1332 0.1329 0.1314 0.1305 0.1304 0.1305 0.1305 

[TRAIN] Epoch[6](651/1500); Loss: 0.073005; Backpropagation: 0.0991 sec; Batch: 0.4340 sec
0.1422 0.1192 0.1071 0.0787 0.0722 0.0648 0.0622 0.0584 0.0582 0.0577 0.0570 0.0573 0.0580 0.0579 0.0582 0.0588 

[TRAIN] Epoch[6](652/1500); Loss: 0.075100; Backpropagation: 0.1011 sec; Batch: 0.4360 sec
0.1149 0.0908 0.0808 0.0786 0.0790 0.0664 0.0659 0.0657 0.0659 0.0672 0.0676 0.0684 0.0698 0.0722 0.0734 0.0750 

[TRAIN] Epoch[6](653/1500); Loss: 0.169127; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.2459 0.2350 0.2192 0.1848 0.1739 0.1607 0.1565 0.1541 0.1516 0.1490 0.1481 0.1468 0.1458 0.1452 0.1449 0.1446 

[TRAIN] Epoch[6](654/1500); Loss: 0.108132; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1489 0.1651 0.1399 0.1248 0.1152 0.1062 0.1011 0.0972 0.0940 0.0928 0.0919 0.0913 0.0910 0.0906 0.0900 0.0900 

[TRAIN] Epoch[6](655/1500); Loss: 0.091801; Backpropagation: 0.1023 sec; Batch: 0.4371 sec
0.1869 0.1518 0.1488 0.1100 0.0991 0.0848 0.0773 0.0736 0.0714 0.0685 0.0675 0.0670 0.0656 0.0658 0.0655 0.0652 

[TRAIN] Epoch[6](656/1500); Loss: 0.079521; Backpropagation: 0.0995 sec; Batch: 0.4348 sec
0.1056 0.1079 0.0959 0.0903 0.0863 0.0782 0.0747 0.0723 0.0713 0.0708 0.0703 0.0699 0.0697 0.0695 0.0696 0.0698 

[TRAIN] Epoch[6](657/1500); Loss: 0.137226; Backpropagation: 0.0993 sec; Batch: 0.4342 sec
0.1796 0.2053 0.1753 0.1580 0.1445 0.1345 0.1277 0.1227 0.1199 0.1190 0.1187 0.1186 0.1184 0.1179 0.1178 0.1179 

[TRAIN] Epoch[6](658/1500); Loss: 0.134634; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.1715 0.1771 0.1599 0.1495 0.1422 0.1335 0.1292 0.1267 0.1245 0.1226 0.1214 0.1204 0.1197 0.1190 0.1187 0.1185 

[TRAIN] Epoch[6](659/1500); Loss: 0.094204; Backpropagation: 0.1000 sec; Batch: 0.4350 sec
0.2429 0.1764 0.1736 0.0915 0.0800 0.0698 0.0697 0.0662 0.0668 0.0663 0.0660 0.0662 0.0668 0.0675 0.0684 0.0692 

[TRAIN] Epoch[6](660/1500); Loss: 0.149148; Backpropagation: 0.0991 sec; Batch: 0.4721 sec
0.2266 0.2038 0.1951 0.1648 0.1572 0.1480 0.1424 0.1377 0.1343 0.1311 0.1286 0.1266 0.1249 0.1232 0.1218 0.1204 

[TRAIN] Epoch[6](661/1500); Loss: 0.208224; Backpropagation: 0.1000 sec; Batch: 0.4343 sec
0.3757 0.3131 0.3102 0.2373 0.2175 0.1953 0.1808 0.1728 0.1704 0.1683 0.1675 0.1659 0.1652 0.1642 0.1640 0.1633 

[TRAIN] Epoch[6](662/1500); Loss: 0.136717; Backpropagation: 0.0993 sec; Batch: 0.4332 sec
0.2284 0.2211 0.2024 0.1590 0.1424 0.1262 0.1173 0.1139 0.1120 0.1104 0.1103 0.1092 0.1089 0.1089 0.1086 0.1085 

[TRAIN] Epoch[6](663/1500); Loss: 0.082774; Backpropagation: 0.0988 sec; Batch: 0.4345 sec
0.2230 0.1666 0.1641 0.0980 0.0875 0.0704 0.0634 0.0549 0.0515 0.0491 0.0487 0.0493 0.0495 0.0494 0.0494 0.0493 

[TRAIN] Epoch[6](664/1500); Loss: 0.164448; Backpropagation: 0.0982 sec; Batch: 0.4330 sec
0.3024 0.2793 0.2635 0.2021 0.1826 0.1601 0.1454 0.1335 0.1277 0.1237 0.1219 0.1209 0.1185 0.1169 0.1166 0.1160 

[TRAIN] Epoch[6](665/1500); Loss: 0.127025; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.2260 0.2276 0.2025 0.1530 0.1327 0.1127 0.1051 0.1029 0.0994 0.0979 0.0965 0.0956 0.0952 0.0951 0.0949 0.0951 

[TRAIN] Epoch[6](666/1500); Loss: 0.077416; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1356 0.1075 0.1011 0.0727 0.0716 0.0695 0.0689 0.0676 0.0675 0.0673 0.0676 0.0678 0.0679 0.0684 0.0687 0.0691 

[TRAIN] Epoch[6](667/1500); Loss: 0.104463; Backpropagation: 0.0988 sec; Batch: 0.4341 sec
0.1763 0.1431 0.1392 0.1196 0.1167 0.1013 0.0970 0.0923 0.0895 0.0873 0.0862 0.0853 0.0846 0.0843 0.0844 0.0844 

[TRAIN] Epoch[6](668/1500); Loss: 0.056904; Backpropagation: 0.0991 sec; Batch: 0.4361 sec
0.0984 0.0777 0.0665 0.0665 0.0635 0.0506 0.0511 0.0504 0.0482 0.0478 0.0479 0.0478 0.0478 0.0481 0.0486 0.0494 

[TRAIN] Epoch[6](669/1500); Loss: 0.146626; Backpropagation: 0.0992 sec; Batch: 0.4342 sec
0.1668 0.1780 0.1600 0.1550 0.1495 0.1429 0.1410 0.1405 0.1397 0.1390 0.1390 0.1388 0.1388 0.1390 0.1390 0.1390 

[TRAIN] Epoch[6](670/1500); Loss: 0.169845; Backpropagation: 0.0985 sec; Batch: 0.4337 sec
0.2104 0.2364 0.2060 0.1926 0.1802 0.1683 0.1618 0.1569 0.1541 0.1520 0.1510 0.1504 0.1502 0.1493 0.1491 0.1489 

[TRAIN] Epoch[6](671/1500); Loss: 0.125044; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.2139 0.1903 0.1746 0.1477 0.1359 0.1192 0.1081 0.1020 0.1016 0.1011 0.1013 0.1009 0.1008 0.1011 0.1012 0.1010 

[TRAIN] Epoch[6](672/1500); Loss: 0.073683; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.1569 0.1200 0.1133 0.0757 0.0695 0.0618 0.0599 0.0572 0.0568 0.0569 0.0572 0.0575 0.0581 0.0588 0.0594 0.0600 

[TRAIN] Epoch[6](673/1500); Loss: 0.082856; Backpropagation: 0.0988 sec; Batch: 0.4340 sec
0.1797 0.1385 0.1347 0.0972 0.0907 0.0710 0.0730 0.0650 0.0633 0.0619 0.0595 0.0584 0.0588 0.0580 0.0579 0.0580 

[TRAIN] Epoch[6](674/1500); Loss: 0.143307; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.2954 0.2883 0.2627 0.1984 0.1707 0.1409 0.1208 0.1071 0.0984 0.0924 0.0886 0.0883 0.0863 0.0853 0.0849 0.0846 

[TRAIN] Epoch[6](675/1500); Loss: 0.097252; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2170 0.1687 0.1615 0.1010 0.0923 0.0808 0.0783 0.0756 0.0749 0.0732 0.0727 0.0727 0.0720 0.0717 0.0717 0.0719 

[TRAIN] Epoch[6](676/1500); Loss: 0.041559; Backpropagation: 0.1010 sec; Batch: 0.4373 sec
0.0748 0.0803 0.0520 0.0439 0.0383 0.0386 0.0361 0.0335 0.0336 0.0335 0.0330 0.0330 0.0334 0.0332 0.0336 0.0340 

[TRAIN] Epoch[6](677/1500); Loss: 0.129806; Backpropagation: 0.0988 sec; Batch: 0.4334 sec
0.1738 0.1930 0.1607 0.1405 0.1288 0.1244 0.1202 0.1175 0.1163 0.1153 0.1145 0.1145 0.1144 0.1141 0.1143 0.1147 

[TRAIN] Epoch[6](678/1500); Loss: 0.065828; Backpropagation: 0.0994 sec; Batch: 0.4369 sec
0.1050 0.1302 0.0828 0.0722 0.0633 0.0580 0.0568 0.0548 0.0544 0.0530 0.0525 0.0526 0.0528 0.0536 0.0548 0.0566 

[TRAIN] Epoch[6](679/1500); Loss: 0.106677; Backpropagation: 0.0991 sec; Batch: 0.4336 sec
0.1668 0.2164 0.1695 0.1456 0.1232 0.1063 0.0945 0.0857 0.0802 0.0768 0.0750 0.0740 0.0734 0.0732 0.0731 0.0732 

[TRAIN] Epoch[6](680/1500); Loss: 0.221583; Backpropagation: 0.0994 sec; Batch: 0.4342 sec
0.4312 0.3711 0.3656 0.2670 0.2390 0.2012 0.1746 0.1654 0.1681 0.1678 0.1633 0.1650 0.1657 0.1660 0.1665 0.1677 

[TRAIN] Epoch[6](681/1500); Loss: 0.110681; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.1467 0.1378 0.1274 0.1177 0.1141 0.1075 0.1045 0.1029 0.1025 0.1017 0.1014 0.1015 0.1014 0.1013 0.1013 0.1013 

[TRAIN] Epoch[6](682/1500); Loss: 0.091672; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1255 0.1173 0.1021 0.0971 0.0944 0.0867 0.0857 0.0851 0.0842 0.0835 0.0833 0.0833 0.0836 0.0841 0.0847 0.0859 

[TRAIN] Epoch[6](683/1500); Loss: 0.066220; Backpropagation: 0.0989 sec; Batch: 0.4341 sec
0.0939 0.1566 0.0979 0.0753 0.0632 0.0552 0.0523 0.0522 0.0516 0.0514 0.0514 0.0515 0.0515 0.0516 0.0520 0.0521 

[TRAIN] Epoch[6](684/1500); Loss: 0.124683; Backpropagation: 0.1081 sec; Batch: 0.4443 sec
0.2021 0.1884 0.1695 0.1276 0.1200 0.1142 0.1096 0.1084 0.1075 0.1069 0.1071 0.1067 0.1064 0.1067 0.1071 0.1069 

[TRAIN] Epoch[6](685/1500); Loss: 0.143451; Backpropagation: 0.1080 sec; Batch: 0.4429 sec
0.1815 0.2154 0.1812 0.1715 0.1606 0.1495 0.1404 0.1318 0.1257 0.1216 0.1201 0.1195 0.1190 0.1190 0.1191 0.1192 

[TRAIN] Epoch[6](686/1500); Loss: 0.101714; Backpropagation: 0.0989 sec; Batch: 0.4336 sec
0.1255 0.1021 0.1015 0.1165 0.1125 0.0993 0.1002 0.0986 0.0972 0.0969 0.0965 0.0964 0.0962 0.0960 0.0960 0.0961 

[TRAIN] Epoch[6](687/1500); Loss: 0.176180; Backpropagation: 0.0993 sec; Batch: 0.4343 sec
0.2980 0.2656 0.2602 0.2117 0.1978 0.1734 0.1570 0.1446 0.1379 0.1377 0.1410 0.1387 0.1392 0.1386 0.1388 0.1385 

[TRAIN] Epoch[6](688/1500); Loss: 0.120953; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.2324 0.2197 0.2002 0.1357 0.1173 0.1009 0.1012 0.0964 0.0931 0.0928 0.0920 0.0911 0.0911 0.0908 0.0903 0.0903 

[TRAIN] Epoch[6](689/1500); Loss: 0.066520; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1003 0.1144 0.0815 0.0778 0.0703 0.0632 0.0604 0.0587 0.0570 0.0557 0.0550 0.0545 0.0539 0.0537 0.0538 0.0542 

[TRAIN] Epoch[6](690/1500); Loss: 0.091141; Backpropagation: 0.0996 sec; Batch: 0.4344 sec
0.1335 0.1392 0.1116 0.0972 0.0935 0.0820 0.0815 0.0814 0.0804 0.0791 0.0793 0.0797 0.0797 0.0798 0.0801 0.0803 

[TRAIN] Epoch[6](691/1500); Loss: 0.126059; Backpropagation: 0.0992 sec; Batch: 0.4335 sec
0.2716 0.2500 0.2318 0.1715 0.1541 0.1300 0.1116 0.0941 0.0814 0.0740 0.0772 0.0746 0.0738 0.0736 0.0738 0.0738 

[TRAIN] Epoch[6](692/1500); Loss: 0.101760; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.2333 0.3295 0.2437 0.1821 0.1115 0.0577 0.0539 0.0501 0.0466 0.0456 0.0456 0.0456 0.0450 0.0455 0.0460 0.0466 

[TRAIN] Epoch[6](693/1500); Loss: 0.164008; Backpropagation: 0.0992 sec; Batch: 0.4340 sec
0.1874 0.1968 0.1761 0.1730 0.1700 0.1663 0.1619 0.1602 0.1583 0.1568 0.1554 0.1544 0.1532 0.1520 0.1514 0.1509 

[TRAIN] Epoch[6](694/1500); Loss: 0.154657; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2450 0.2965 0.2432 0.2037 0.1722 0.1405 0.1278 0.1217 0.1189 0.1181 0.1171 0.1153 0.1143 0.1137 0.1131 0.1134 

[TRAIN] Epoch[6](695/1500); Loss: 0.129380; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.2136 0.1748 0.1724 0.1512 0.1424 0.1244 0.1184 0.1129 0.1101 0.1089 0.1083 0.1075 0.1067 0.1064 0.1061 0.1058 

[TRAIN] Epoch[6](696/1500); Loss: 0.135404; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.1643 0.1485 0.1451 0.1416 0.1404 0.1335 0.1328 0.1314 0.1302 0.1293 0.1289 0.1285 0.1281 0.1280 0.1279 0.1280 

[TRAIN] Epoch[6](697/1500); Loss: 0.057859; Backpropagation: 0.0995 sec; Batch: 0.4344 sec
0.1791 0.1132 0.1078 0.0553 0.0649 0.0373 0.0392 0.0396 0.0360 0.0360 0.0352 0.0359 0.0358 0.0361 0.0363 0.0378 

[TRAIN] Epoch[6](698/1500); Loss: 0.067648; Backpropagation: 0.0995 sec; Batch: 0.4345 sec
0.1077 0.0933 0.0813 0.0778 0.0726 0.0616 0.0614 0.0605 0.0587 0.0581 0.0578 0.0577 0.0579 0.0582 0.0586 0.0591 

[TRAIN] Epoch[6](699/1500); Loss: 0.103511; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1895 0.1579 0.1473 0.1133 0.1076 0.0926 0.0889 0.0882 0.0867 0.0849 0.0840 0.0839 0.0833 0.0831 0.0825 0.0825 

[TRAIN] Epoch[6](700/1500); Loss: 0.070588; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.0887 0.1496 0.0932 0.0756 0.0688 0.0653 0.0623 0.0607 0.0600 0.0584 0.0583 0.0577 0.0579 0.0575 0.0577 0.0578 

[TRAIN] Epoch[6](701/1500); Loss: 0.077331; Backpropagation: 0.0989 sec; Batch: 0.4342 sec
0.1208 0.1245 0.1025 0.0901 0.0831 0.0702 0.0680 0.0660 0.0647 0.0641 0.0640 0.0639 0.0637 0.0638 0.0639 0.0641 

[TRAIN] Epoch[6](702/1500); Loss: 0.115058; Backpropagation: 0.1025 sec; Batch: 0.4368 sec
0.1507 0.1511 0.1370 0.1234 0.1196 0.1140 0.1100 0.1075 0.1061 0.1053 0.1041 0.1032 0.1027 0.1025 0.1020 0.1019 

[TRAIN] Epoch[6](703/1500); Loss: 0.138936; Backpropagation: 0.1025 sec; Batch: 0.4376 sec
0.3204 0.2650 0.2570 0.1648 0.1457 0.1214 0.1095 0.1009 0.0968 0.0950 0.0929 0.0919 0.0912 0.0908 0.0901 0.0896 

[TRAIN] Epoch[6](704/1500); Loss: 0.124256; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.1802 0.1994 0.1688 0.1511 0.1343 0.1187 0.1100 0.1055 0.1034 0.1027 0.1022 0.1021 0.1021 0.1023 0.1024 0.1029 

[TRAIN] Epoch[6](705/1500); Loss: 0.076428; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.1581 0.1385 0.1258 0.0934 0.0850 0.0734 0.0659 0.0600 0.0562 0.0541 0.0536 0.0524 0.0517 0.0516 0.0516 0.0516 

[TRAIN] Epoch[6](706/1500); Loss: 0.132121; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1631 0.1642 0.1505 0.1400 0.1360 0.1300 0.1270 0.1254 0.1243 0.1237 0.1228 0.1219 0.1216 0.1213 0.1211 0.1210 

[TRAIN] Epoch[6](707/1500); Loss: 0.056036; Backpropagation: 0.0991 sec; Batch: 0.6600 sec
0.2069 0.1316 0.1274 0.0330 0.0418 0.0387 0.0335 0.0317 0.0303 0.0311 0.0306 0.0307 0.0305 0.0332 0.0328 0.0329 

[TRAIN] Epoch[6](708/1500); Loss: 0.071755; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.0812 0.1020 0.0748 0.0754 0.0732 0.0690 0.0679 0.0676 0.0670 0.0660 0.0663 0.0667 0.0674 0.0676 0.0678 0.0680 

[TRAIN] Epoch[6](709/1500); Loss: 0.107753; Backpropagation: 0.0990 sec; Batch: 0.4539 sec
0.2283 0.2136 0.1939 0.1480 0.1290 0.1071 0.0961 0.0842 0.0749 0.0699 0.0671 0.0646 0.0634 0.0620 0.0614 0.0606 

[TRAIN] Epoch[6](710/1500); Loss: 0.125628; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1765 0.1536 0.1500 0.1355 0.1315 0.1222 0.1202 0.1163 0.1157 0.1150 0.1133 0.1127 0.1123 0.1119 0.1117 0.1116 

[TRAIN] Epoch[6](711/1500); Loss: 0.111167; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.2788 0.2214 0.2093 0.1224 0.1069 0.0884 0.0803 0.0769 0.0747 0.0742 0.0741 0.0739 0.0739 0.0742 0.0745 0.0750 

[TRAIN] Epoch[6](712/1500); Loss: 0.120784; Backpropagation: 0.0983 sec; Batch: 0.4333 sec
0.2062 0.2434 0.1998 0.1603 0.1315 0.1082 0.0966 0.0909 0.0891 0.0874 0.0870 0.0863 0.0863 0.0866 0.0866 0.0862 

[TRAIN] Epoch[6](713/1500); Loss: 0.105712; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.3017 0.2301 0.2223 0.1140 0.0927 0.0784 0.0743 0.0665 0.0651 0.0647 0.0637 0.0632 0.0635 0.0635 0.0638 0.0640 

[TRAIN] Epoch[6](714/1500); Loss: 0.115848; Backpropagation: 0.1009 sec; Batch: 0.4356 sec
0.1829 0.2192 0.1797 0.1502 0.1256 0.1084 0.0989 0.0929 0.0893 0.0874 0.0865 0.0863 0.0863 0.0864 0.0866 0.0869 

[TRAIN] Epoch[6](715/1500); Loss: 0.156254; Backpropagation: 0.0986 sec; Batch: 0.4381 sec
0.2383 0.2046 0.2023 0.1767 0.1685 0.1519 0.1442 0.1388 0.1358 0.1350 0.1350 0.1342 0.1340 0.1337 0.1337 0.1334 

[TRAIN] Epoch[6](716/1500); Loss: 0.067134; Backpropagation: 0.0989 sec; Batch: 0.4749 sec
0.0814 0.0987 0.0755 0.0718 0.0671 0.0638 0.0620 0.0611 0.0613 0.0614 0.0613 0.0614 0.0616 0.0617 0.0619 0.0622 

[TRAIN] Epoch[6](717/1500); Loss: 0.091906; Backpropagation: 0.0991 sec; Batch: 0.4346 sec
0.1109 0.1219 0.1030 0.0951 0.0906 0.0884 0.0876 0.0869 0.0867 0.0862 0.0860 0.0857 0.0855 0.0854 0.0854 0.0854 

[TRAIN] Epoch[6](718/1500); Loss: 0.089590; Backpropagation: 0.0995 sec; Batch: 0.4352 sec
0.1752 0.2414 0.1767 0.1346 0.0938 0.0637 0.0564 0.0543 0.0531 0.0532 0.0537 0.0541 0.0546 0.0557 0.0562 0.0568 

[TRAIN] Epoch[6](719/1500); Loss: 0.100138; Backpropagation: 0.0992 sec; Batch: 0.4350 sec
0.1864 0.1517 0.1452 0.1087 0.1093 0.0991 0.0976 0.0934 0.0874 0.0832 0.0791 0.0761 0.0740 0.0718 0.0700 0.0691 

[TRAIN] Epoch[6](720/1500); Loss: 0.162382; Backpropagation: 0.1006 sec; Batch: 0.4351 sec
0.3355 0.3008 0.2801 0.2011 0.1736 0.1393 0.1174 0.1214 0.1167 0.1157 0.1153 0.1150 0.1161 0.1164 0.1167 0.1171 

[TRAIN] Epoch[6](721/1500); Loss: 0.066993; Backpropagation: 0.0988 sec; Batch: 0.4349 sec
0.1375 0.1839 0.1340 0.1033 0.0729 0.0495 0.0431 0.0395 0.0388 0.0382 0.0384 0.0381 0.0380 0.0382 0.0387 0.0393 

[TRAIN] Epoch[6](722/1500); Loss: 0.101758; Backpropagation: 0.0985 sec; Batch: 0.4341 sec
0.1575 0.1261 0.1242 0.1099 0.1070 0.0977 0.0956 0.0938 0.0925 0.0912 0.0901 0.0894 0.0888 0.0882 0.0880 0.0882 

[TRAIN] Epoch[6](723/1500); Loss: 0.071322; Backpropagation: 0.0991 sec; Batch: 0.4334 sec
0.1226 0.1264 0.1045 0.0811 0.0718 0.0652 0.0596 0.0576 0.0572 0.0568 0.0564 0.0561 0.0563 0.0563 0.0565 0.0567 

[TRAIN] Epoch[6](724/1500); Loss: 0.061502; Backpropagation: 0.0992 sec; Batch: 0.4360 sec
0.1676 0.1121 0.1083 0.0632 0.0586 0.0487 0.0460 0.0444 0.0426 0.0420 0.0420 0.0415 0.0417 0.0417 0.0416 0.0419 

[TRAIN] Epoch[6](725/1500); Loss: 0.091038; Backpropagation: 0.0988 sec; Batch: 0.4342 sec
0.1213 0.1184 0.1060 0.0989 0.0960 0.0896 0.0869 0.0850 0.0836 0.0827 0.0821 0.0815 0.0812 0.0811 0.0810 0.0813 

[TRAIN] Epoch[6](726/1500); Loss: 0.064275; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.0895 0.0963 0.0800 0.0733 0.0702 0.0635 0.0607 0.0589 0.0576 0.0563 0.0552 0.0544 0.0539 0.0532 0.0528 0.0526 

[TRAIN] Epoch[6](727/1500); Loss: 0.055685; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1552 0.0975 0.0930 0.0413 0.0507 0.0460 0.0398 0.0380 0.0372 0.0379 0.0387 0.0400 0.0409 0.0431 0.0450 0.0466 

[TRAIN] Epoch[6](728/1500); Loss: 0.106301; Backpropagation: 0.0983 sec; Batch: 0.4350 sec
0.2128 0.2175 0.1866 0.1300 0.1046 0.0880 0.0841 0.0774 0.0759 0.0753 0.0744 0.0744 0.0744 0.0747 0.0752 0.0754 

[TRAIN] Epoch[6](729/1500); Loss: 0.101685; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1830 0.1568 0.1456 0.1081 0.0999 0.0903 0.0876 0.0860 0.0850 0.0841 0.0839 0.0835 0.0834 0.0831 0.0832 0.0833 

[TRAIN] Epoch[6](730/1500); Loss: 0.088024; Backpropagation: 0.1027 sec; Batch: 0.4382 sec
0.1455 0.1619 0.1317 0.1062 0.0882 0.0786 0.0747 0.0729 0.0713 0.0703 0.0695 0.0688 0.0679 0.0674 0.0669 0.0666 

[TRAIN] Epoch[6](731/1500); Loss: 0.066448; Backpropagation: 0.1025 sec; Batch: 0.4388 sec
0.2254 0.1710 0.1662 0.0847 0.0653 0.0450 0.0399 0.0355 0.0343 0.0292 0.0284 0.0282 0.0276 0.0272 0.0274 0.0279 

[TRAIN] Epoch[6](732/1500); Loss: 0.163546; Backpropagation: 0.0987 sec; Batch: 0.4331 sec
0.1920 0.2102 0.1859 0.1784 0.1679 0.1627 0.1573 0.1560 0.1541 0.1533 0.1518 0.1509 0.1497 0.1496 0.1487 0.1483 

[TRAIN] Epoch[6](733/1500); Loss: 0.082502; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1384 0.1133 0.1065 0.0894 0.0874 0.0778 0.0749 0.0729 0.0715 0.0707 0.0702 0.0697 0.0694 0.0693 0.0692 0.0693 

[TRAIN] Epoch[6](734/1500); Loss: 0.213489; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.4241 0.3619 0.3554 0.2568 0.2286 0.1888 0.1610 0.1567 0.1628 0.1577 0.1594 0.1603 0.1603 0.1600 0.1606 0.1616 

[TRAIN] Epoch[6](735/1500); Loss: 0.133300; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.2023 0.1760 0.1721 0.1418 0.1374 0.1307 0.1263 0.1237 0.1206 0.1184 0.1164 0.1148 0.1134 0.1133 0.1129 0.1126 

[TRAIN] Epoch[6](736/1500); Loss: 0.098601; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1291 0.1428 0.1163 0.1031 0.0979 0.0927 0.0904 0.0895 0.0891 0.0890 0.0888 0.0889 0.0892 0.0900 0.0903 0.0905 

[TRAIN] Epoch[6](737/1500); Loss: 0.089705; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1344 0.1234 0.1120 0.1026 0.0931 0.0844 0.0817 0.0803 0.0791 0.0781 0.0778 0.0774 0.0774 0.0776 0.0778 0.0781 

[TRAIN] Epoch[6](738/1500); Loss: 0.120414; Backpropagation: 0.1001 sec; Batch: 0.4510 sec
0.2263 0.2998 0.2299 0.1771 0.1252 0.0878 0.0838 0.0807 0.0787 0.0776 0.0770 0.0768 0.0767 0.0765 0.0762 0.0766 

[TRAIN] Epoch[6](739/1500); Loss: 0.158374; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.2208 0.2105 0.2009 0.1851 0.1722 0.1550 0.1457 0.1408 0.1391 0.1379 0.1375 0.1373 0.1373 0.1377 0.1380 0.1382 

[TRAIN] Epoch[6](740/1500); Loss: 0.116043; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.2213 0.1859 0.1768 0.1350 0.1220 0.1029 0.0958 0.0926 0.0913 0.0909 0.0905 0.0905 0.0903 0.0903 0.0903 0.0904 

[TRAIN] Epoch[6](741/1500); Loss: 0.078714; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1404 0.1088 0.1019 0.0746 0.0761 0.0721 0.0690 0.0678 0.0669 0.0666 0.0673 0.0679 0.0683 0.0693 0.0706 0.0717 

[TRAIN] Epoch[6](742/1500); Loss: 0.080646; Backpropagation: 0.0995 sec; Batch: 0.4342 sec
0.2635 0.2023 0.1962 0.1025 0.0771 0.0410 0.0487 0.0433 0.0395 0.0392 0.0392 0.0399 0.0398 0.0396 0.0389 0.0398 

[TRAIN] Epoch[6](743/1500); Loss: 0.208100; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.3752 0.3193 0.3141 0.2347 0.2140 0.1860 0.1715 0.1697 0.1712 0.1688 0.1684 0.1681 0.1675 0.1675 0.1669 0.1666 

[TRAIN] Epoch[6](744/1500); Loss: 0.070636; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.1757 0.1287 0.1239 0.0743 0.0676 0.0575 0.0549 0.0520 0.0504 0.0501 0.0496 0.0492 0.0492 0.0490 0.0490 0.0490 

[TRAIN] Epoch[6](745/1500); Loss: 0.160574; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.2335 0.2717 0.2273 0.1968 0.1700 0.1487 0.1407 0.1351 0.1332 0.1323 0.1317 0.1307 0.1299 0.1292 0.1292 0.1292 

[TRAIN] Epoch[6](746/1500); Loss: 0.078635; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1022 0.1272 0.0988 0.0851 0.0771 0.0738 0.0722 0.0710 0.0700 0.0694 0.0688 0.0684 0.0683 0.0684 0.0686 0.0689 

[TRAIN] Epoch[6](747/1500); Loss: 0.126755; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1530 0.1373 0.1345 0.1412 0.1364 0.1257 0.1253 0.1239 0.1222 0.1209 0.1196 0.1185 0.1179 0.1175 0.1172 0.1168 

[TRAIN] Epoch[6](748/1500); Loss: 0.100390; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1225 0.1141 0.1040 0.1082 0.1060 0.0986 0.0968 0.0959 0.0950 0.0948 0.0947 0.0947 0.0951 0.0952 0.0953 0.0955 

[TRAIN] Epoch[6](749/1500); Loss: 0.116422; Backpropagation: 0.0994 sec; Batch: 0.4345 sec
0.1828 0.1530 0.1453 0.1251 0.1184 0.1072 0.1061 0.1048 0.1024 0.1016 0.1015 0.1019 0.1020 0.1026 0.1034 0.1046 

[TRAIN] Epoch[6](750/1500); Loss: 0.122678; Backpropagation: 0.0991 sec; Batch: 0.4342 sec
0.1987 0.1747 0.1602 0.1258 0.1211 0.1111 0.1114 0.1082 0.1077 0.1069 0.1064 0.1063 0.1060 0.1060 0.1061 0.1063 

[TRAIN] Epoch[6](751/1500); Loss: 0.070020; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1028 0.1243 0.0877 0.0800 0.0728 0.0654 0.0629 0.0608 0.0593 0.0585 0.0581 0.0578 0.0573 0.0573 0.0575 0.0579 

[TRAIN] Epoch[6](752/1500); Loss: 0.116159; Backpropagation: 0.0983 sec; Batch: 0.4336 sec
0.1496 0.1708 0.1385 0.1202 0.1142 0.1106 0.1084 0.1068 0.1059 0.1054 0.1049 0.1046 0.1048 0.1046 0.1047 0.1045 

[TRAIN] Epoch[6](753/1500); Loss: 0.103315; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1364 0.1388 0.1199 0.1191 0.1098 0.0998 0.0979 0.0957 0.0942 0.0932 0.0926 0.0919 0.0915 0.0910 0.0908 0.0904 

[TRAIN] Epoch[6](754/1500); Loss: 0.101873; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1383 0.1599 0.1262 0.1058 0.0983 0.0958 0.0946 0.0933 0.0917 0.0911 0.0902 0.0899 0.0890 0.0889 0.0886 0.0883 

[TRAIN] Epoch[6](755/1500); Loss: 0.099301; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1524 0.1495 0.1288 0.1114 0.1040 0.0934 0.0897 0.0866 0.0850 0.0843 0.0838 0.0836 0.0837 0.0838 0.0841 0.0846 

[TRAIN] Epoch[6](756/1500); Loss: 0.117151; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.2432 0.3075 0.2460 0.1994 0.1524 0.1105 0.0803 0.0679 0.0625 0.0590 0.0581 0.0579 0.0577 0.0572 0.0572 0.0575 

[TRAIN] Epoch[6](757/1500); Loss: 0.094460; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1319 0.1445 0.1202 0.1101 0.1023 0.0905 0.0862 0.0836 0.0815 0.0806 0.0801 0.0797 0.0800 0.0800 0.0799 0.0802 

[TRAIN] Epoch[6](758/1500); Loss: 0.095270; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.1550 0.1798 0.1462 0.1151 0.0962 0.0849 0.0795 0.0771 0.0759 0.0746 0.0740 0.0735 0.0732 0.0731 0.0731 0.0731 

[TRAIN] Epoch[6](759/1500); Loss: 0.134752; Backpropagation: 0.1026 sec; Batch: 0.4376 sec
0.1751 0.1754 0.1587 0.1410 0.1337 0.1289 0.1264 0.1249 0.1243 0.1239 0.1236 0.1237 0.1238 0.1241 0.1242 0.1244 

[TRAIN] Epoch[6](760/1500); Loss: 0.127147; Backpropagation: 0.1025 sec; Batch: 0.4370 sec
0.2157 0.2440 0.1994 0.1520 0.1326 0.1166 0.1071 0.1019 0.0998 0.0976 0.0961 0.0953 0.0946 0.0940 0.0937 0.0939 

[TRAIN] Epoch[6](761/1500); Loss: 0.055134; Backpropagation: 0.0988 sec; Batch: 0.4331 sec
0.1501 0.0930 0.0967 0.0793 0.0655 0.0382 0.0396 0.0367 0.0353 0.0350 0.0345 0.0354 0.0351 0.0352 0.0360 0.0366 

[TRAIN] Epoch[6](762/1500); Loss: 0.068129; Backpropagation: 0.1036 sec; Batch: 0.4383 sec
0.1433 0.1057 0.1030 0.0822 0.0767 0.0629 0.0593 0.0564 0.0527 0.0510 0.0505 0.0498 0.0494 0.0491 0.0491 0.0490 

[TRAIN] Epoch[6](763/1500); Loss: 0.091153; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1663 0.1403 0.1305 0.0965 0.0957 0.0863 0.0861 0.0817 0.0765 0.0740 0.0726 0.0706 0.0698 0.0701 0.0703 0.0711 

[TRAIN] Epoch[6](764/1500); Loss: 0.159384; Backpropagation: 0.0982 sec; Batch: 0.4324 sec
0.3963 0.3460 0.3355 0.2387 0.2112 0.1698 0.1362 0.1073 0.0856 0.0765 0.0829 0.0749 0.0733 0.0729 0.0717 0.0713 

[TRAIN] Epoch[6](765/1500); Loss: 0.231056; Backpropagation: 0.0994 sec; Batch: 0.4333 sec
0.3253 0.3081 0.2964 0.2589 0.2508 0.2325 0.2204 0.2092 0.2045 0.2019 0.1987 0.1980 0.1983 0.1980 0.1979 0.1981 

[TRAIN] Epoch[6](766/1500); Loss: 0.107218; Backpropagation: 0.0991 sec; Batch: 0.4343 sec
0.1593 0.1426 0.1269 0.1086 0.1039 0.0990 0.0982 0.0979 0.0972 0.0973 0.0970 0.0973 0.0971 0.0974 0.0976 0.0981 

[TRAIN] Epoch[6](767/1500); Loss: 0.173507; Backpropagation: 0.0993 sec; Batch: 0.4340 sec
0.2070 0.2070 0.1935 0.1809 0.1774 0.1738 0.1698 0.1678 0.1660 0.1646 0.1630 0.1618 0.1614 0.1611 0.1607 0.1601 

[TRAIN] Epoch[6](768/1500); Loss: 0.132217; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.1648 0.1870 0.1599 0.1453 0.1345 0.1278 0.1242 0.1222 0.1208 0.1200 0.1191 0.1185 0.1180 0.1177 0.1177 0.1179 

[TRAIN] Epoch[6](769/1500); Loss: 0.115736; Backpropagation: 0.0995 sec; Batch: 0.4343 sec
0.1726 0.1603 0.1439 0.1224 0.1163 0.1085 0.1059 0.1042 0.1031 0.1024 0.1020 0.1020 0.1021 0.1020 0.1020 0.1023 

[TRAIN] Epoch[6](770/1500); Loss: 0.113718; Backpropagation: 0.0982 sec; Batch: 0.4330 sec
0.3899 0.3115 0.3026 0.1678 0.1336 0.0805 0.0507 0.0481 0.0454 0.0430 0.0417 0.0407 0.0408 0.0409 0.0410 0.0413 

[TRAIN] Epoch[6](771/1500); Loss: 0.128208; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.4964 0.3954 0.3782 0.1942 0.1411 0.0630 0.0393 0.0433 0.0354 0.0367 0.0354 0.0364 0.0374 0.0391 0.0391 0.0408 

[TRAIN] Epoch[6](772/1500); Loss: 0.123880; Backpropagation: 0.0990 sec; Batch: 0.4336 sec
0.1536 0.1374 0.1323 0.1230 0.1201 0.1199 0.1190 0.1184 0.1184 0.1185 0.1189 0.1195 0.1202 0.1205 0.1210 0.1215 

[TRAIN] Epoch[6](773/1500); Loss: 0.114698; Backpropagation: 0.0989 sec; Batch: 0.4343 sec
0.1412 0.1362 0.1245 0.1276 0.1195 0.1135 0.1111 0.1095 0.1083 0.1073 0.1066 0.1062 0.1061 0.1059 0.1058 0.1059 

[TRAIN] Epoch[6](774/1500); Loss: 0.161644; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.2262 0.1992 0.1917 0.1694 0.1632 0.1552 0.1514 0.1500 0.1497 0.1488 0.1480 0.1475 0.1471 0.1465 0.1462 0.1462 

[TRAIN] Epoch[6](775/1500); Loss: 0.109489; Backpropagation: 0.0986 sec; Batch: 0.4324 sec
0.1761 0.1540 0.1435 0.1215 0.1132 0.1033 0.1009 0.0986 0.0960 0.0942 0.0932 0.0923 0.0915 0.0914 0.0913 0.0910 

[TRAIN] Epoch[6](776/1500); Loss: 0.104203; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1868 0.1525 0.1466 0.1124 0.1065 0.0978 0.0929 0.0870 0.0841 0.0840 0.0844 0.0852 0.0857 0.0864 0.0871 0.0880 

[TRAIN] Epoch[6](777/1500); Loss: 0.080962; Backpropagation: 0.0988 sec; Batch: 0.4332 sec
0.1244 0.1222 0.1045 0.0931 0.0857 0.0781 0.0739 0.0717 0.0704 0.0699 0.0686 0.0676 0.0672 0.0667 0.0659 0.0655 

[TRAIN] Epoch[6](778/1500); Loss: 0.079203; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.1259 0.1162 0.1047 0.0912 0.0838 0.0750 0.0721 0.0695 0.0676 0.0666 0.0661 0.0659 0.0657 0.0656 0.0656 0.0656 

[TRAIN] Epoch[6](779/1500); Loss: 0.066051; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1010 0.1152 0.0870 0.0765 0.0665 0.0593 0.0581 0.0563 0.0556 0.0551 0.0543 0.0542 0.0542 0.0543 0.0545 0.0548 

[TRAIN] Epoch[6](780/1500); Loss: 0.160706; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.2247 0.2162 0.2007 0.1840 0.1722 0.1570 0.1499 0.1459 0.1435 0.1420 0.1411 0.1399 0.1392 0.1388 0.1382 0.1379 

[TRAIN] Epoch[6](781/1500); Loss: 0.063690; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.0853 0.1441 0.0822 0.0745 0.0649 0.0604 0.0564 0.0537 0.0516 0.0505 0.0499 0.0492 0.0489 0.0488 0.0492 0.0495 

[TRAIN] Epoch[6](782/1500); Loss: 0.100225; Backpropagation: 0.0988 sec; Batch: 0.4331 sec
0.1849 0.1685 0.1486 0.1196 0.1047 0.0885 0.0827 0.0807 0.0792 0.0786 0.0783 0.0782 0.0780 0.0779 0.0777 0.0776 

[TRAIN] Epoch[6](783/1500); Loss: 0.060383; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1096 0.1007 0.0847 0.0751 0.0644 0.0540 0.0504 0.0488 0.0475 0.0471 0.0469 0.0468 0.0471 0.0474 0.0476 0.0480 

[TRAIN] Epoch[6](784/1500); Loss: 0.218564; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.2975 0.2870 0.2732 0.2423 0.2357 0.2208 0.2109 0.2009 0.1961 0.1936 0.1911 0.1902 0.1899 0.1892 0.1890 0.1895 

[TRAIN] Epoch[6](785/1500); Loss: 0.100402; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.2135 0.2429 0.1934 0.1271 0.0946 0.0755 0.0685 0.0668 0.0679 0.0671 0.0658 0.0652 0.0651 0.0648 0.0643 0.0641 

[TRAIN] Epoch[6](786/1500); Loss: 0.088247; Backpropagation: 0.1040 sec; Batch: 0.4387 sec
0.1189 0.1073 0.1010 0.0917 0.0893 0.0842 0.0832 0.0824 0.0820 0.0818 0.0817 0.0817 0.0815 0.0816 0.0818 0.0819 

[TRAIN] Epoch[6](787/1500); Loss: 0.058100; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1546 0.0924 0.0977 0.0747 0.0635 0.0440 0.0437 0.0427 0.0403 0.0397 0.0392 0.0388 0.0389 0.0392 0.0396 0.0403 

[TRAIN] Epoch[6](788/1500); Loss: 0.206942; Backpropagation: 0.1024 sec; Batch: 0.4371 sec
0.2870 0.2774 0.2624 0.2325 0.2239 0.2076 0.1976 0.1885 0.1838 0.1810 0.1789 0.1785 0.1787 0.1781 0.1779 0.1774 

[TRAIN] Epoch[6](789/1500); Loss: 0.058488; Backpropagation: 0.0998 sec; Batch: 0.4352 sec
0.1386 0.0946 0.0903 0.0699 0.0631 0.0498 0.0470 0.0458 0.0444 0.0424 0.0420 0.0420 0.0414 0.0412 0.0416 0.0416 

[TRAIN] Epoch[6](790/1500); Loss: 0.146811; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.2110 0.1851 0.1806 0.1633 0.1560 0.1438 0.1388 0.1354 0.1324 0.1307 0.1293 0.1287 0.1285 0.1284 0.1285 0.1284 

[TRAIN] Epoch[6](791/1500); Loss: 0.115773; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.2668 0.3315 0.2643 0.2079 0.1504 0.0984 0.0602 0.0542 0.0517 0.0510 0.0513 0.0523 0.0524 0.0529 0.0533 0.0537 

[TRAIN] Epoch[6](792/1500); Loss: 0.163138; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1798 0.1740 0.1703 0.1771 0.1742 0.1652 0.1636 0.1604 0.1592 0.1573 0.1560 0.1555 0.1552 0.1547 0.1541 0.1536 

[TRAIN] Epoch[6](793/1500); Loss: 0.202283; Backpropagation: 0.0985 sec; Batch: 0.4342 sec
0.3123 0.2822 0.2707 0.2203 0.2119 0.1949 0.1847 0.1773 0.1734 0.1724 0.1719 0.1723 0.1723 0.1726 0.1735 0.1738 

[TRAIN] Epoch[6](794/1500); Loss: 0.103151; Backpropagation: 0.1026 sec; Batch: 0.4372 sec
0.1249 0.1311 0.1139 0.1019 0.0976 0.0971 0.0967 0.0967 0.0969 0.0972 0.0977 0.0981 0.0987 0.0996 0.1006 0.1016 

[TRAIN] Epoch[6](795/1500); Loss: 0.075561; Backpropagation: 0.1025 sec; Batch: 0.4373 sec
0.1577 0.1337 0.1221 0.0908 0.0839 0.0696 0.0628 0.0581 0.0567 0.0547 0.0540 0.0534 0.0532 0.0528 0.0527 0.0528 

[TRAIN] Epoch[6](796/1500); Loss: 0.199531; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.3763 0.3209 0.3135 0.2238 0.2007 0.1684 0.1585 0.1639 0.1591 0.1599 0.1588 0.1578 0.1574 0.1579 0.1577 0.1578 

[TRAIN] Epoch[6](797/1500); Loss: 0.086142; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1238 0.1335 0.1094 0.0873 0.0821 0.0792 0.0780 0.0772 0.0767 0.0758 0.0754 0.0754 0.0759 0.0760 0.0761 0.0765 

[TRAIN] Epoch[6](798/1500); Loss: 0.121139; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1470 0.1412 0.1328 0.1275 0.1251 0.1207 0.1189 0.1171 0.1156 0.1145 0.1135 0.1130 0.1126 0.1127 0.1130 0.1132 

[TRAIN] Epoch[6](799/1500); Loss: 0.125533; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1516 0.1410 0.1344 0.1251 0.1236 0.1216 0.1211 0.1211 0.1211 0.1210 0.1210 0.1210 0.1210 0.1211 0.1213 0.1215 

[TRAIN] Epoch[6](800/1500); Loss: 0.197150; Backpropagation: 0.0996 sec; Batch: 0.4345 sec
0.3998 0.3382 0.3296 0.2267 0.1992 0.1601 0.1451 0.1536 0.1488 0.1492 0.1497 0.1499 0.1499 0.1509 0.1516 0.1521 

[TRAIN] Epoch[6](801/1500); Loss: 0.139553; Backpropagation: 0.0993 sec; Batch: 0.4345 sec
0.1769 0.1856 0.1641 0.1491 0.1410 0.1354 0.1328 0.1305 0.1292 0.1282 0.1273 0.1270 0.1267 0.1266 0.1264 0.1261 

[TRAIN] Epoch[6](802/1500); Loss: 0.112895; Backpropagation: 0.0992 sec; Batch: 0.4338 sec
0.1610 0.1741 0.1429 0.1169 0.1083 0.1045 0.1025 0.1016 0.1005 0.0997 0.0995 0.0992 0.0989 0.0989 0.0989 0.0989 

[TRAIN] Epoch[6](803/1500); Loss: 0.056196; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.1792 0.1122 0.1059 0.0502 0.0522 0.0533 0.0411 0.0377 0.0349 0.0327 0.0324 0.0332 0.0330 0.0331 0.0339 0.0342 

[TRAIN] Epoch[6](804/1500); Loss: 0.097097; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.1271 0.1104 0.1036 0.0999 0.0952 0.0920 0.0912 0.0906 0.0902 0.0905 0.0911 0.0919 0.0930 0.0942 0.0956 0.0973 

[TRAIN] Epoch[6](805/1500); Loss: 0.114389; Backpropagation: 0.0985 sec; Batch: 0.4334 sec
0.1619 0.1638 0.1442 0.1303 0.1204 0.1117 0.1052 0.1014 0.1001 0.0993 0.0988 0.0985 0.0986 0.0986 0.0986 0.0988 

[TRAIN] Epoch[6](806/1500); Loss: 0.128712; Backpropagation: 0.0988 sec; Batch: 0.4327 sec
0.1743 0.1541 0.1465 0.1347 0.1307 0.1255 0.1232 0.1217 0.1208 0.1196 0.1189 0.1184 0.1180 0.1181 0.1176 0.1173 

[TRAIN] Epoch[6](807/1500); Loss: 0.088476; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1676 0.2317 0.1646 0.1110 0.0719 0.0633 0.0603 0.0599 0.0615 0.0609 0.0602 0.0601 0.0603 0.0603 0.0607 0.0614 

[TRAIN] Epoch[6](808/1500); Loss: 0.136299; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1843 0.1676 0.1624 0.1427 0.1387 0.1340 0.1309 0.1287 0.1268 0.1254 0.1239 0.1231 0.1230 0.1231 0.1231 0.1230 

[TRAIN] Epoch[6](809/1500); Loss: 0.121069; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1310 0.1413 0.1282 0.1255 0.1229 0.1210 0.1195 0.1184 0.1175 0.1168 0.1164 0.1161 0.1159 0.1157 0.1155 0.1154 

[TRAIN] Epoch[6](810/1500); Loss: 0.124790; Backpropagation: 0.1038 sec; Batch: 0.4380 sec
0.1568 0.1418 0.1342 0.1294 0.1288 0.1243 0.1225 0.1210 0.1196 0.1184 0.1175 0.1170 0.1168 0.1168 0.1161 0.1158 

[TRAIN] Epoch[6](811/1500); Loss: 0.087620; Backpropagation: 0.0987 sec; Batch: 0.4340 sec
0.1210 0.1263 0.1052 0.0964 0.0913 0.0853 0.0828 0.0805 0.0787 0.0781 0.0773 0.0765 0.0761 0.0757 0.0755 0.0752 

[TRAIN] Epoch[6](812/1500); Loss: 0.090815; Backpropagation: 0.0992 sec; Batch: 0.4342 sec
0.1259 0.1282 0.1130 0.0970 0.0893 0.0849 0.0834 0.0825 0.0818 0.0813 0.0811 0.0809 0.0809 0.0809 0.0810 0.0811 

[TRAIN] Epoch[6](813/1500); Loss: 0.151381; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.2016 0.2055 0.1865 0.1680 0.1575 0.1477 0.1423 0.1385 0.1362 0.1351 0.1345 0.1342 0.1339 0.1336 0.1335 0.1335 

[TRAIN] Epoch[6](814/1500); Loss: 0.075665; Backpropagation: 0.0985 sec; Batch: 0.4341 sec
0.1384 0.1236 0.1071 0.0872 0.0796 0.0680 0.0647 0.0627 0.0614 0.0608 0.0601 0.0597 0.0594 0.0593 0.0593 0.0593 

[TRAIN] Epoch[6](815/1500); Loss: 0.124948; Backpropagation: 0.0991 sec; Batch: 0.4339 sec
0.1546 0.1371 0.1324 0.1259 0.1230 0.1223 0.1215 0.1209 0.1205 0.1203 0.1201 0.1200 0.1199 0.1200 0.1202 0.1204 

[TRAIN] Epoch[6](816/1500); Loss: 0.120638; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.1510 0.1568 0.1343 0.1258 0.1202 0.1144 0.1133 0.1127 0.1124 0.1121 0.1120 0.1121 0.1123 0.1129 0.1136 0.1142 

[TRAIN] Epoch[6](817/1500); Loss: 0.098645; Backpropagation: 0.1016 sec; Batch: 0.4378 sec
0.1509 0.1420 0.1187 0.1085 0.1037 0.0979 0.0946 0.0910 0.0889 0.0868 0.0849 0.0834 0.0822 0.0821 0.0814 0.0811 

[TRAIN] Epoch[6](818/1500); Loss: 0.133743; Backpropagation: 0.1025 sec; Batch: 0.4373 sec
0.1665 0.1576 0.1506 0.1352 0.1325 0.1301 0.1289 0.1286 0.1278 0.1273 0.1267 0.1265 0.1261 0.1254 0.1250 0.1251 

[TRAIN] Epoch[6](819/1500); Loss: 0.099240; Backpropagation: 0.1026 sec; Batch: 0.4373 sec
0.1161 0.1235 0.1100 0.1048 0.1011 0.0985 0.0968 0.0957 0.0947 0.0939 0.0932 0.0927 0.0922 0.0918 0.0914 0.0913 

[TRAIN] Epoch[6](820/1500); Loss: 0.137328; Backpropagation: 0.0992 sec; Batch: 0.4327 sec
0.2400 0.2203 0.2051 0.1584 0.1422 0.1247 0.1147 0.1116 0.1104 0.1101 0.1099 0.1096 0.1096 0.1101 0.1102 0.1104 

[TRAIN] Epoch[6](821/1500); Loss: 0.097341; Backpropagation: 0.0985 sec; Batch: 0.4339 sec
0.1404 0.1674 0.1278 0.1039 0.0938 0.0888 0.0871 0.0858 0.0850 0.0843 0.0837 0.0832 0.0824 0.0817 0.0813 0.0808 

[TRAIN] Epoch[6](822/1500); Loss: 0.111510; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.1383 0.1203 0.1175 0.1214 0.1159 0.1102 0.1089 0.1077 0.1068 0.1059 0.1055 0.1050 0.1049 0.1052 0.1054 0.1053 

[TRAIN] Epoch[6](823/1500); Loss: 0.076738; Backpropagation: 0.1024 sec; Batch: 0.4372 sec
0.1414 0.1221 0.0972 0.0923 0.0796 0.0674 0.0645 0.0634 0.0630 0.0625 0.0621 0.0622 0.0623 0.0623 0.0627 0.0628 

[TRAIN] Epoch[6](824/1500); Loss: 0.143211; Backpropagation: 0.1027 sec; Batch: 0.4378 sec
0.2485 0.2218 0.2126 0.1722 0.1606 0.1436 0.1341 0.1254 0.1178 0.1119 0.1077 0.1066 0.1082 0.1070 0.1068 0.1067 

[TRAIN] Epoch[6](825/1500); Loss: 0.134932; Backpropagation: 0.0987 sec; Batch: 0.4333 sec
0.4543 0.3676 0.3470 0.1762 0.1268 0.0635 0.0775 0.0649 0.0612 0.0590 0.0589 0.0594 0.0600 0.0602 0.0608 0.0616 

[TRAIN] Epoch[6](826/1500); Loss: 0.068146; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1044 0.1228 0.0940 0.0818 0.0694 0.0605 0.0579 0.0567 0.0561 0.0556 0.0553 0.0553 0.0551 0.0551 0.0553 0.0554 

[TRAIN] Epoch[6](827/1500); Loss: 0.101103; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1660 0.2050 0.1619 0.1328 0.1097 0.0936 0.0832 0.0770 0.0751 0.0744 0.0741 0.0736 0.0734 0.0729 0.0725 0.0725 

[TRAIN] Epoch[6](828/1500); Loss: 0.123787; Backpropagation: 0.0982 sec; Batch: 0.4340 sec
0.1584 0.1506 0.1414 0.1242 0.1213 0.1197 0.1183 0.1174 0.1167 0.1162 0.1162 0.1162 0.1162 0.1160 0.1160 0.1160 

[TRAIN] Epoch[6](829/1500); Loss: 0.126677; Backpropagation: 0.1081 sec; Batch: 0.4433 sec
0.2618 0.2340 0.2176 0.1582 0.1399 0.1178 0.1048 0.0942 0.0904 0.0890 0.0875 0.0868 0.0864 0.0862 0.0862 0.0862 

[TRAIN] Epoch[6](830/1500); Loss: 0.080756; Backpropagation: 0.1080 sec; Batch: 0.4428 sec
0.1421 0.1142 0.1092 0.0894 0.0785 0.0732 0.0728 0.0700 0.0690 0.0684 0.0677 0.0676 0.0676 0.0677 0.0674 0.0673 

[TRAIN] Epoch[6](831/1500); Loss: 0.124801; Backpropagation: 0.0990 sec; Batch: 0.4336 sec
0.2164 0.2686 0.2157 0.1756 0.1379 0.1137 0.0959 0.0890 0.0872 0.0862 0.0858 0.0856 0.0852 0.0847 0.0845 0.0846 

[TRAIN] Epoch[6](832/1500); Loss: 0.138177; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1900 0.1948 0.1688 0.1561 0.1391 0.1328 0.1274 0.1247 0.1233 0.1231 0.1222 0.1217 0.1215 0.1219 0.1217 0.1216 

[TRAIN] Epoch[6](833/1500); Loss: 0.064951; Backpropagation: 0.0987 sec; Batch: 0.4329 sec
0.0785 0.1049 0.0764 0.0700 0.0644 0.0606 0.0592 0.0585 0.0583 0.0580 0.0579 0.0579 0.0585 0.0585 0.0586 0.0589 

[TRAIN] Epoch[6](834/1500); Loss: 0.064282; Backpropagation: 0.0990 sec; Batch: 0.4341 sec
0.1124 0.0809 0.0798 0.0725 0.0650 0.0584 0.0577 0.0574 0.0563 0.0557 0.0554 0.0551 0.0550 0.0552 0.0556 0.0562 

[TRAIN] Epoch[6](835/1500); Loss: 0.058359; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1066 0.1171 0.0870 0.0800 0.0643 0.0498 0.0477 0.0454 0.0441 0.0432 0.0425 0.0418 0.0412 0.0412 0.0411 0.0410 

[TRAIN] Epoch[6](836/1500); Loss: 0.149503; Backpropagation: 0.0982 sec; Batch: 0.4329 sec
0.1928 0.1794 0.1716 0.1530 0.1487 0.1444 0.1424 0.1411 0.1405 0.1402 0.1401 0.1399 0.1396 0.1395 0.1395 0.1394 

[TRAIN] Epoch[6](837/1500); Loss: 0.089738; Backpropagation: 0.0983 sec; Batch: 0.4325 sec
0.1270 0.1442 0.1122 0.0915 0.0851 0.0824 0.0809 0.0800 0.0792 0.0790 0.0789 0.0788 0.0788 0.0792 0.0792 0.0794 

[TRAIN] Epoch[6](838/1500); Loss: 0.086289; Backpropagation: 0.0983 sec; Batch: 0.4333 sec
0.1226 0.1454 0.1147 0.1020 0.0856 0.0754 0.0747 0.0738 0.0737 0.0734 0.0735 0.0734 0.0732 0.0732 0.0730 0.0730 

[TRAIN] Epoch[6](839/1500); Loss: 0.139067; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.1887 0.2359 0.1842 0.1594 0.1365 0.1265 0.1229 0.1211 0.1207 0.1201 0.1192 0.1185 0.1182 0.1181 0.1178 0.1174 

[TRAIN] Epoch[6](840/1500); Loss: 0.076596; Backpropagation: 0.0985 sec; Batch: 0.4324 sec
0.0879 0.1108 0.0806 0.0756 0.0726 0.0713 0.0722 0.0721 0.0718 0.0719 0.0725 0.0727 0.0729 0.0731 0.0736 0.0739 

[TRAIN] Epoch[6](841/1500); Loss: 0.113245; Backpropagation: 0.0989 sec; Batch: 0.4338 sec
0.1670 0.1617 0.1471 0.1309 0.1212 0.1101 0.1051 0.1014 0.0990 0.0973 0.0966 0.0958 0.0952 0.0948 0.0944 0.0942 

[TRAIN] Epoch[6](842/1500); Loss: 0.066802; Backpropagation: 0.0993 sec; Batch: 0.4333 sec
0.0920 0.0927 0.0765 0.0671 0.0641 0.0633 0.0625 0.0618 0.0614 0.0612 0.0611 0.0610 0.0608 0.0609 0.0611 0.0613 

[TRAIN] Epoch[6](843/1500); Loss: 0.041473; Backpropagation: 0.0984 sec; Batch: 0.4326 sec
0.0732 0.0473 0.0450 0.0507 0.0431 0.0383 0.0365 0.0362 0.0360 0.0358 0.0360 0.0361 0.0365 0.0370 0.0376 0.0381 

[TRAIN] Epoch[6](844/1500); Loss: 0.152254; Backpropagation: 0.0982 sec; Batch: 0.4326 sec
0.2352 0.2126 0.1993 0.1612 0.1516 0.1415 0.1367 0.1352 0.1343 0.1332 0.1331 0.1327 0.1323 0.1323 0.1324 0.1325 

[TRAIN] Epoch[6](845/1500); Loss: 0.137605; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.2386 0.1971 0.1875 0.1397 0.1321 0.1302 0.1237 0.1210 0.1188 0.1167 0.1161 0.1160 0.1159 0.1159 0.1159 0.1165 

[TRAIN] Epoch[6](846/1500); Loss: 0.096946; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.1450 0.1508 0.1286 0.1116 0.0999 0.0899 0.0865 0.0845 0.0832 0.0825 0.0822 0.0818 0.0814 0.0812 0.0810 0.0810 

[TRAIN] Epoch[6](847/1500); Loss: 0.139229; Backpropagation: 0.1025 sec; Batch: 0.4370 sec
0.2164 0.1907 0.1788 0.1481 0.1391 0.1331 0.1279 0.1242 0.1225 0.1214 0.1209 0.1207 0.1209 0.1210 0.1211 0.1211 

[TRAIN] Epoch[6](848/1500); Loss: 0.122169; Backpropagation: 0.1028 sec; Batch: 0.4381 sec
0.1869 0.2435 0.1881 0.1502 0.1187 0.1038 0.0995 0.0972 0.0969 0.0967 0.0961 0.0957 0.0957 0.0953 0.0951 0.0952 

[TRAIN] Epoch[6](849/1500); Loss: 0.113112; Backpropagation: 0.0989 sec; Batch: 0.4331 sec
0.1612 0.1341 0.1287 0.1180 0.1144 0.1102 0.1086 0.1073 0.1062 0.1053 0.1044 0.1035 0.1029 0.1023 0.1017 0.1010 

[TRAIN] Epoch[6](850/1500); Loss: 0.097110; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.1322 0.1362 0.1174 0.1020 0.0971 0.0933 0.0905 0.0891 0.0878 0.0871 0.0867 0.0868 0.0872 0.0866 0.0867 0.0869 

[TRAIN] Epoch[6](851/1500); Loss: 0.072334; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2661 0.1969 0.1822 0.0715 0.0524 0.0389 0.0383 0.0338 0.0335 0.0335 0.0331 0.0332 0.0343 0.0356 0.0364 0.0375 

[TRAIN] Epoch[6](852/1500); Loss: 0.082613; Backpropagation: 0.1027 sec; Batch: 0.4374 sec
0.1831 0.2776 0.1837 0.1070 0.0624 0.0510 0.0451 0.0437 0.0438 0.0436 0.0437 0.0446 0.0460 0.0476 0.0484 0.0504 

[TRAIN] Epoch[6](853/1500); Loss: 0.124443; Backpropagation: 0.1026 sec; Batch: 0.4377 sec
0.1617 0.1824 0.1519 0.1329 0.1262 0.1199 0.1171 0.1147 0.1131 0.1120 0.1110 0.1103 0.1098 0.1097 0.1094 0.1090 

[TRAIN] Epoch[6](854/1500); Loss: 0.081870; Backpropagation: 0.0994 sec; Batch: 0.4334 sec
0.1297 0.1193 0.1048 0.1142 0.0950 0.0756 0.0719 0.0695 0.0681 0.0671 0.0665 0.0664 0.0662 0.0656 0.0651 0.0649 

[TRAIN] Epoch[6](855/1500); Loss: 0.146033; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2244 0.2478 0.2127 0.1813 0.1572 0.1367 0.1245 0.1185 0.1176 0.1175 0.1171 0.1169 0.1165 0.1162 0.1160 0.1157 

[TRAIN] Epoch[6](856/1500); Loss: 0.096066; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.1575 0.1974 0.1478 0.1214 0.0962 0.0812 0.0764 0.0748 0.0743 0.0734 0.0730 0.0727 0.0727 0.0727 0.0727 0.0727 

[TRAIN] Epoch[6](857/1500); Loss: 0.111659; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1598 0.1561 0.1371 0.1201 0.1110 0.1071 0.1028 0.1012 0.1002 0.0996 0.0991 0.0990 0.0986 0.0985 0.0982 0.0982 

[TRAIN] Epoch[6](858/1500); Loss: 0.044333; Backpropagation: 0.0989 sec; Batch: 0.4333 sec
0.0834 0.0537 0.0530 0.0416 0.0395 0.0381 0.0380 0.0377 0.0380 0.0385 0.0394 0.0397 0.0406 0.0417 0.0429 0.0435 

[TRAIN] Epoch[6](859/1500); Loss: 0.142848; Backpropagation: 0.0984 sec; Batch: 0.4337 sec
0.1724 0.1716 0.1578 0.1481 0.1423 0.1371 0.1372 0.1371 0.1365 0.1359 0.1355 0.1352 0.1349 0.1346 0.1346 0.1348 

[TRAIN] Epoch[6](860/1500); Loss: 0.099742; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.1453 0.1233 0.1169 0.1065 0.1041 0.0966 0.0954 0.0940 0.0926 0.0913 0.0902 0.0892 0.0885 0.0879 0.0873 0.0868 

[TRAIN] Epoch[6](861/1500); Loss: 0.063821; Backpropagation: 0.0986 sec; Batch: 0.4329 sec
0.1023 0.1386 0.0884 0.0698 0.0608 0.0564 0.0538 0.0526 0.0516 0.0507 0.0502 0.0496 0.0491 0.0489 0.0491 0.0492 

[TRAIN] Epoch[6](862/1500); Loss: 0.134604; Backpropagation: 0.0987 sec; Batch: 0.4338 sec
0.1780 0.1892 0.1674 0.1527 0.1411 0.1306 0.1250 0.1221 0.1210 0.1201 0.1191 0.1185 0.1178 0.1174 0.1170 0.1166 

[TRAIN] Epoch[6](863/1500); Loss: 0.085168; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1743 0.1418 0.1314 0.0887 0.0875 0.0794 0.0805 0.0758 0.0682 0.0661 0.0640 0.0619 0.0611 0.0606 0.0604 0.0610 

[TRAIN] Epoch[6](864/1500); Loss: 0.105875; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.2354 0.1866 0.1713 0.1015 0.0915 0.0876 0.0839 0.0822 0.0815 0.0810 0.0812 0.0812 0.0814 0.0820 0.0826 0.0830 

[TRAIN] Epoch[6](865/1500); Loss: 0.095069; Backpropagation: 0.0994 sec; Batch: 0.4342 sec
0.1596 0.1540 0.1334 0.1101 0.1003 0.0874 0.0824 0.0794 0.0780 0.0775 0.0769 0.0764 0.0765 0.0764 0.0764 0.0765 

[TRAIN] Epoch[6](866/1500); Loss: 0.049468; Backpropagation: 0.0991 sec; Batch: 0.4753 sec
0.0730 0.0598 0.0550 0.0505 0.0484 0.0465 0.0456 0.0453 0.0452 0.0452 0.0453 0.0454 0.0458 0.0463 0.0469 0.0473 

[TRAIN] Epoch[6](867/1500); Loss: 0.124095; Backpropagation: 0.0993 sec; Batch: 0.4351 sec
0.3051 0.3158 0.2711 0.1828 0.1393 0.1005 0.0731 0.0695 0.0676 0.0672 0.0669 0.0663 0.0658 0.0650 0.0648 0.0647 

[TRAIN] Epoch[6](868/1500); Loss: 0.068060; Backpropagation: 0.0982 sec; Batch: 0.4323 sec
0.1769 0.1229 0.1133 0.0584 0.0580 0.0662 0.0568 0.0536 0.0505 0.0483 0.0475 0.0479 0.0472 0.0469 0.0472 0.0474 

[TRAIN] Epoch[6](869/1500); Loss: 0.130370; Backpropagation: 0.0974 sec; Batch: 0.4325 sec
0.3227 0.2876 0.2695 0.1864 0.1649 0.1308 0.1040 0.0770 0.0672 0.0741 0.0691 0.0667 0.0661 0.0663 0.0665 0.0670 

[TRAIN] Epoch[6](870/1500); Loss: 0.205179; Backpropagation: 0.1027 sec; Batch: 0.4375 sec
0.3374 0.2910 0.2836 0.2140 0.1956 0.1816 0.1809 0.1795 0.1787 0.1784 0.1777 0.1779 0.1776 0.1766 0.1764 0.1759 

[TRAIN] Epoch[6](871/1500); Loss: 0.111268; Backpropagation: 0.1026 sec; Batch: 0.4372 sec
0.1322 0.1326 0.1212 0.1143 0.1115 0.1082 0.1064 0.1059 0.1056 0.1057 0.1056 0.1057 0.1059 0.1061 0.1065 0.1068 

[TRAIN] Epoch[6](872/1500); Loss: 0.149247; Backpropagation: 0.0975 sec; Batch: 0.4320 sec
0.1927 0.2076 0.1820 0.1656 0.1526 0.1432 0.1381 0.1353 0.1344 0.1339 0.1338 0.1338 0.1336 0.1336 0.1339 0.1342 

[TRAIN] Epoch[6](873/1500); Loss: 0.046900; Backpropagation: 0.0972 sec; Batch: 0.4323 sec
0.0806 0.0663 0.0595 0.0506 0.0472 0.0438 0.0421 0.0402 0.0394 0.0390 0.0392 0.0396 0.0402 0.0404 0.0408 0.0414 

[TRAIN] Epoch[6](874/1500); Loss: 0.085847; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.1194 0.1084 0.0971 0.0933 0.0875 0.0830 0.0811 0.0802 0.0796 0.0789 0.0784 0.0778 0.0775 0.0773 0.0772 0.0771 

[TRAIN] Epoch[6](875/1500); Loss: 0.055258; Backpropagation: 0.0982 sec; Batch: 0.4335 sec
0.1008 0.0664 0.0699 0.0605 0.0559 0.0542 0.0509 0.0496 0.0483 0.0476 0.0474 0.0471 0.0464 0.0463 0.0464 0.0464 

[TRAIN] Epoch[6](876/1500); Loss: 0.094870; Backpropagation: 0.0987 sec; Batch: 0.4330 sec
0.1190 0.1180 0.1060 0.1002 0.0959 0.0915 0.0900 0.0892 0.0889 0.0890 0.0888 0.0886 0.0884 0.0882 0.0881 0.0881 

[TRAIN] Epoch[6](877/1500); Loss: 0.096649; Backpropagation: 0.0993 sec; Batch: 0.4338 sec
0.1476 0.1349 0.1212 0.1238 0.1077 0.0931 0.0899 0.0859 0.0839 0.0819 0.0806 0.0797 0.0793 0.0792 0.0790 0.0787 

[TRAIN] Epoch[6](878/1500); Loss: 0.120998; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1614 0.1506 0.1408 0.1297 0.1254 0.1196 0.1175 0.1152 0.1132 0.1114 0.1102 0.1091 0.1085 0.1082 0.1078 0.1074 

[TRAIN] Epoch[6](879/1500); Loss: 0.068834; Backpropagation: 0.0987 sec; Batch: 0.4345 sec
0.1193 0.0811 0.0810 0.0699 0.0679 0.0637 0.0633 0.0621 0.0615 0.0615 0.0617 0.0617 0.0615 0.0615 0.0618 0.0620 

[TRAIN] Epoch[6](880/1500); Loss: 0.100055; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.1298 0.1320 0.1180 0.1107 0.1054 0.0997 0.0957 0.0926 0.0907 0.0902 0.0900 0.0898 0.0894 0.0891 0.0889 0.0888 

[TRAIN] Epoch[6](881/1500); Loss: 0.101386; Backpropagation: 0.0992 sec; Batch: 0.4337 sec
0.2466 0.3443 0.2601 0.2035 0.1276 0.0606 0.0481 0.0415 0.0383 0.0374 0.0376 0.0365 0.0357 0.0352 0.0345 0.0348 

[TRAIN] Epoch[6](882/1500); Loss: 0.081313; Backpropagation: 0.1061 sec; Batch: 0.4414 sec
0.1106 0.1516 0.1074 0.0889 0.0775 0.0722 0.0708 0.0701 0.0696 0.0693 0.0689 0.0686 0.0686 0.0688 0.0690 0.0692 

[TRAIN] Epoch[6](883/1500); Loss: 0.067245; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.1119 0.0811 0.0807 0.0698 0.0680 0.0649 0.0633 0.0617 0.0608 0.0602 0.0596 0.0592 0.0590 0.0587 0.0584 0.0586 

[TRAIN] Epoch[6](884/1500); Loss: 0.095051; Backpropagation: 0.0984 sec; Batch: 0.4324 sec
0.1391 0.1653 0.1322 0.1143 0.1008 0.0896 0.0837 0.0809 0.0792 0.0784 0.0780 0.0773 0.0764 0.0757 0.0751 0.0747 

[TRAIN] Epoch[6](885/1500); Loss: 0.123079; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.2648 0.2228 0.2127 0.1510 0.1363 0.1121 0.0971 0.0898 0.0877 0.0861 0.0854 0.0848 0.0846 0.0847 0.0848 0.0848 

[TRAIN] Epoch[6](886/1500); Loss: 0.122713; Backpropagation: 0.0983 sec; Batch: 0.4333 sec
0.2778 0.2557 0.2356 0.1712 0.1536 0.1263 0.1061 0.0844 0.0716 0.0693 0.0702 0.0695 0.0681 0.0679 0.0680 0.0683 

[TRAIN] Epoch[6](887/1500); Loss: 0.135564; Backpropagation: 0.0996 sec; Batch: 0.4337 sec
0.2822 0.2285 0.2207 0.1550 0.1407 0.1223 0.1140 0.1055 0.1026 0.1023 0.1009 0.1000 0.0992 0.0986 0.0985 0.0982 

[TRAIN] Epoch[6](888/1500); Loss: 0.103119; Backpropagation: 0.0994 sec; Batch: 0.4337 sec
0.2490 0.3515 0.2641 0.2035 0.1224 0.0561 0.0553 0.0451 0.0406 0.0386 0.0387 0.0373 0.0363 0.0371 0.0371 0.0372 

[TRAIN] Epoch[6](889/1500); Loss: 0.091347; Backpropagation: 0.0995 sec; Batch: 0.5002 sec
0.1307 0.1619 0.1257 0.1070 0.0916 0.0832 0.0789 0.0776 0.0771 0.0766 0.0759 0.0756 0.0753 0.0752 0.0748 0.0744 

[TRAIN] Epoch[6](890/1500); Loss: 0.103454; Backpropagation: 0.0982 sec; Batch: 0.4742 sec
0.1492 0.1667 0.1348 0.1087 0.0975 0.0941 0.0929 0.0925 0.0918 0.0910 0.0906 0.0901 0.0896 0.0890 0.0886 0.0884 

[TRAIN] Epoch[6](891/1500); Loss: 0.088561; Backpropagation: 0.0986 sec; Batch: 0.4327 sec
0.1342 0.1297 0.1110 0.0952 0.0877 0.0806 0.0790 0.0780 0.0774 0.0776 0.0776 0.0773 0.0777 0.0778 0.0780 0.0782 

[TRAIN] Epoch[6](892/1500); Loss: 0.127801; Backpropagation: 0.0986 sec; Batch: 0.4332 sec
0.1676 0.1864 0.1589 0.1383 0.1264 0.1202 0.1183 0.1167 0.1157 0.1152 0.1146 0.1140 0.1135 0.1134 0.1130 0.1126 

[TRAIN] Epoch[6](893/1500); Loss: 0.065462; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1264 0.0913 0.0853 0.0746 0.0695 0.0610 0.0588 0.0572 0.0559 0.0547 0.0536 0.0527 0.0523 0.0521 0.0513 0.0509 

[TRAIN] Epoch[6](894/1500); Loss: 0.061461; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.0838 0.0910 0.0731 0.0631 0.0588 0.0573 0.0563 0.0557 0.0556 0.0553 0.0553 0.0552 0.0553 0.0556 0.0559 0.0562 

[TRAIN] Epoch[6](895/1500); Loss: 0.132998; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1737 0.2064 0.1674 0.1464 0.1298 0.1232 0.1211 0.1207 0.1199 0.1190 0.1183 0.1175 0.1168 0.1164 0.1159 0.1155 

[TRAIN] Epoch[6](896/1500); Loss: 0.084101; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.1914 0.2132 0.1720 0.1233 0.0924 0.0666 0.0563 0.0515 0.0511 0.0498 0.0484 0.0472 0.0463 0.0457 0.0454 0.0452 

[TRAIN] Epoch[6](897/1500); Loss: 0.114051; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1550 0.1549 0.1391 0.1212 0.1169 0.1113 0.1080 0.1050 0.1038 0.1027 0.1020 0.1020 0.1014 0.1010 0.1005 0.1002 

[TRAIN] Epoch[6](898/1500); Loss: 0.066157; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1283 0.1006 0.0919 0.0747 0.0691 0.0607 0.0577 0.0551 0.0540 0.0533 0.0529 0.0525 0.0524 0.0519 0.0517 0.0518 

[TRAIN] Epoch[6](899/1500); Loss: 0.117600; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.1855 0.2237 0.1816 0.1490 0.1300 0.1137 0.1011 0.0937 0.0918 0.0903 0.0888 0.0878 0.0871 0.0862 0.0856 0.0857 

[TRAIN] Epoch[6](900/1500); Loss: 0.103963; Backpropagation: 0.0990 sec; Batch: 0.4359 sec
0.1581 0.1397 0.1322 0.1158 0.1080 0.0975 0.0954 0.0926 0.0914 0.0906 0.0905 0.0903 0.0902 0.0904 0.0904 0.0903 

[TRAIN] Epoch[6](901/1500); Loss: 0.094590; Backpropagation: 0.0991 sec; Batch: 0.4331 sec
0.1816 0.1655 0.1449 0.1208 0.1008 0.0865 0.0763 0.0728 0.0725 0.0716 0.0708 0.0705 0.0701 0.0698 0.0696 0.0693 

[TRAIN] Epoch[6](902/1500); Loss: 0.108594; Backpropagation: 0.0988 sec; Batch: 0.4332 sec
0.1979 0.1848 0.1677 0.1453 0.1303 0.1144 0.1021 0.0898 0.0802 0.0763 0.0751 0.0748 0.0746 0.0746 0.0747 0.0749 

[TRAIN] Epoch[6](903/1500); Loss: 0.069741; Backpropagation: 0.0994 sec; Batch: 0.4347 sec
0.1174 0.0795 0.0764 0.0917 0.0797 0.0629 0.0624 0.0612 0.0608 0.0605 0.0605 0.0605 0.0605 0.0606 0.0605 0.0607 

[TRAIN] Epoch[6](904/1500); Loss: 0.089083; Backpropagation: 0.0998 sec; Batch: 0.4346 sec
0.1097 0.1082 0.0952 0.0933 0.0898 0.0854 0.0846 0.0844 0.0842 0.0842 0.0841 0.0840 0.0842 0.0846 0.0847 0.0847 

[TRAIN] Epoch[6](905/1500); Loss: 0.112117; Backpropagation: 0.1027 sec; Batch: 0.4379 sec
0.1494 0.1371 0.1310 0.1334 0.1250 0.1104 0.1064 0.1026 0.1009 0.1003 0.0998 0.0996 0.0995 0.0996 0.0995 0.0995 

[TRAIN] Epoch[6](906/1500); Loss: 0.059361; Backpropagation: 0.1034 sec; Batch: 0.4392 sec
0.1315 0.0925 0.0890 0.0675 0.0586 0.0526 0.0489 0.0473 0.0464 0.0459 0.0455 0.0451 0.0448 0.0447 0.0447 0.0448 

[TRAIN] Epoch[6](907/1500); Loss: 0.062864; Backpropagation: 0.0997 sec; Batch: 0.4349 sec
0.1191 0.1082 0.0916 0.0767 0.0624 0.0533 0.0521 0.0512 0.0501 0.0494 0.0490 0.0487 0.0484 0.0483 0.0485 0.0488 

[TRAIN] Epoch[6](908/1500); Loss: 0.083270; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.1042 0.1225 0.0953 0.0850 0.0796 0.0755 0.0743 0.0745 0.0749 0.0754 0.0759 0.0767 0.0778 0.0789 0.0802 0.0816 

[TRAIN] Epoch[6](909/1500); Loss: 0.100600; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1357 0.1423 0.1247 0.1122 0.1045 0.0975 0.0936 0.0909 0.0901 0.0894 0.0889 0.0885 0.0882 0.0878 0.0877 0.0875 

[TRAIN] Epoch[6](910/1500); Loss: 0.100081; Backpropagation: 0.0995 sec; Batch: 0.4351 sec
0.1762 0.1445 0.1369 0.1017 0.0968 0.0908 0.0886 0.0863 0.0855 0.0847 0.0846 0.0847 0.0847 0.0849 0.0851 0.0854 

[TRAIN] Epoch[6](911/1500); Loss: 0.103018; Backpropagation: 0.0993 sec; Batch: 0.4351 sec
0.1604 0.1803 0.1474 0.1167 0.1019 0.0913 0.0876 0.0857 0.0852 0.0850 0.0845 0.0843 0.0842 0.0843 0.0846 0.0848 

[TRAIN] Epoch[6](912/1500); Loss: 0.118013; Backpropagation: 0.0987 sec; Batch: 0.4341 sec
0.1932 0.2037 0.1774 0.1424 0.1226 0.1064 0.0994 0.0974 0.0977 0.0964 0.0946 0.0932 0.0923 0.0913 0.0904 0.0899 

[TRAIN] Epoch[6](913/1500); Loss: 0.092627; Backpropagation: 0.0988 sec; Batch: 0.4336 sec
0.1212 0.0985 0.0957 0.1061 0.0971 0.0897 0.0886 0.0880 0.0874 0.0875 0.0871 0.0869 0.0869 0.0870 0.0871 0.0873 

[TRAIN] Epoch[6](914/1500); Loss: 0.068917; Backpropagation: 0.0982 sec; Batch: 0.4333 sec
0.1122 0.1440 0.0992 0.0763 0.0638 0.0582 0.0566 0.0552 0.0546 0.0542 0.0537 0.0535 0.0539 0.0551 0.0558 0.0565 

[TRAIN] Epoch[6](915/1500); Loss: 0.097621; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2473 0.3439 0.2597 0.1985 0.1193 0.0517 0.0488 0.0391 0.0350 0.0335 0.0319 0.0307 0.0300 0.0303 0.0306 0.0315 

[TRAIN] Epoch[6](916/1500); Loss: 0.081689; Backpropagation: 0.1004 sec; Batch: 0.4348 sec
0.1003 0.1067 0.0909 0.0852 0.0818 0.0790 0.0778 0.0773 0.0770 0.0769 0.0767 0.0762 0.0758 0.0754 0.0752 0.0749 

[TRAIN] Epoch[6](917/1500); Loss: 0.098449; Backpropagation: 0.0986 sec; Batch: 0.4358 sec
0.1673 0.1678 0.1443 0.1171 0.1035 0.0917 0.0847 0.0807 0.0789 0.0779 0.0774 0.0772 0.0769 0.0767 0.0767 0.0766 

[TRAIN] Epoch[6](918/1500); Loss: 0.117400; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.2294 0.2229 0.1986 0.1440 0.1240 0.1067 0.0976 0.0910 0.0876 0.0849 0.0836 0.0830 0.0820 0.0813 0.0810 0.0808 

[TRAIN] Epoch[6](919/1500); Loss: 0.121479; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.2934 0.3187 0.2673 0.1932 0.1425 0.0974 0.0697 0.0635 0.0618 0.0620 0.0639 0.0626 0.0625 0.0619 0.0618 0.0616 

[TRAIN] Epoch[6](920/1500); Loss: 0.097466; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1633 0.1360 0.1303 0.1114 0.1024 0.0896 0.0875 0.0845 0.0830 0.0821 0.0818 0.0818 0.0815 0.0813 0.0814 0.0815 

[TRAIN] Epoch[6](921/1500); Loss: 0.059740; Backpropagation: 0.0983 sec; Batch: 0.4333 sec
0.0869 0.0953 0.0758 0.0689 0.0645 0.0589 0.0566 0.0548 0.0531 0.0516 0.0501 0.0491 0.0483 0.0477 0.0473 0.0471 

[TRAIN] Epoch[6](922/1500); Loss: 0.102931; Backpropagation: 0.0995 sec; Batch: 0.4340 sec
0.1661 0.2047 0.1591 0.1220 0.0958 0.0866 0.0849 0.0822 0.0815 0.0813 0.0808 0.0807 0.0805 0.0804 0.0802 0.0801 

[TRAIN] Epoch[6](923/1500); Loss: 0.106901; Backpropagation: 0.0994 sec; Batch: 0.4339 sec
0.1607 0.1578 0.1393 0.1242 0.1129 0.1024 0.0965 0.0938 0.0926 0.0917 0.0910 0.0903 0.0898 0.0893 0.0892 0.0890 

[TRAIN] Epoch[6](924/1500); Loss: 0.059827; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.0920 0.0980 0.0760 0.0702 0.0596 0.0531 0.0517 0.0511 0.0508 0.0504 0.0502 0.0503 0.0508 0.0508 0.0508 0.0514 

[TRAIN] Epoch[6](925/1500); Loss: 0.132022; Backpropagation: 0.0984 sec; Batch: 0.4335 sec
0.1873 0.1792 0.1648 0.1451 0.1371 0.1291 0.1239 0.1205 0.1189 0.1179 0.1167 0.1156 0.1149 0.1146 0.1137 0.1131 

[TRAIN] Epoch[6](926/1500); Loss: 0.135899; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2614 0.2784 0.2440 0.1939 0.1664 0.1372 0.1128 0.0960 0.0893 0.0874 0.0865 0.0854 0.0846 0.0838 0.0836 0.0836 

[TRAIN] Epoch[6](927/1500); Loss: 0.085519; Backpropagation: 0.0986 sec; Batch: 0.4340 sec
0.1791 0.2784 0.1920 0.1309 0.0755 0.0534 0.0490 0.0461 0.0455 0.0454 0.0451 0.0443 0.0447 0.0456 0.0461 0.0470 

[TRAIN] Epoch[6](928/1500); Loss: 0.144600; Backpropagation: 0.0984 sec; Batch: 0.4322 sec
0.1766 0.1731 0.1593 0.1462 0.1419 0.1392 0.1391 0.1385 0.1379 0.1377 0.1376 0.1374 0.1374 0.1373 0.1373 0.1372 

[TRAIN] Epoch[6](929/1500); Loss: 0.052952; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1351 0.0886 0.0854 0.0689 0.0632 0.0456 0.0416 0.0387 0.0369 0.0360 0.0346 0.0345 0.0346 0.0344 0.0344 0.0348 

[TRAIN] Epoch[6](930/1500); Loss: 0.058756; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.2041 0.1444 0.1394 0.0715 0.0577 0.0363 0.0344 0.0311 0.0315 0.0271 0.0270 0.0272 0.0267 0.0266 0.0269 0.0280 

[TRAIN] Epoch[6](931/1500); Loss: 0.082741; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1825 0.1713 0.1437 0.1000 0.0845 0.0701 0.0662 0.0611 0.0583 0.0562 0.0552 0.0553 0.0549 0.0548 0.0547 0.0550 

[TRAIN] Epoch[6](932/1500); Loss: 0.110952; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1542 0.1634 0.1399 0.1244 0.1146 0.1050 0.1015 0.0997 0.0987 0.0976 0.0967 0.0963 0.0962 0.0959 0.0956 0.0957 

[TRAIN] Epoch[6](933/1500); Loss: 0.093248; Backpropagation: 0.0985 sec; Batch: 0.4332 sec
0.1971 0.2792 0.2020 0.1417 0.0841 0.0583 0.0574 0.0545 0.0533 0.0529 0.0530 0.0523 0.0517 0.0513 0.0514 0.0517 

[TRAIN] Epoch[6](934/1500); Loss: 0.119661; Backpropagation: 0.1028 sec; Batch: 0.4378 sec
0.1604 0.1914 0.1531 0.1295 0.1142 0.1097 0.1077 0.1065 0.1057 0.1055 0.1057 0.1054 0.1053 0.1051 0.1047 0.1045 

[TRAIN] Epoch[6](935/1500); Loss: 0.084788; Backpropagation: 0.1025 sec; Batch: 0.4371 sec
0.1287 0.1045 0.0973 0.0942 0.0888 0.0804 0.0793 0.0784 0.0772 0.0759 0.0756 0.0753 0.0753 0.0754 0.0753 0.0751 

[TRAIN] Epoch[6](936/1500); Loss: 0.118601; Backpropagation: 0.0990 sec; Batch: 0.4338 sec
0.1519 0.1372 0.1319 0.1347 0.1265 0.1185 0.1157 0.1134 0.1115 0.1097 0.1088 0.1082 0.1079 0.1074 0.1073 0.1070 

[TRAIN] Epoch[6](937/1500); Loss: 0.046057; Backpropagation: 0.0986 sec; Batch: 0.4346 sec
0.0870 0.0581 0.0571 0.0466 0.0445 0.0424 0.0420 0.0402 0.0398 0.0398 0.0397 0.0394 0.0396 0.0401 0.0400 0.0405 

[TRAIN] Epoch[6](938/1500); Loss: 0.097549; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.2403 0.2021 0.1868 0.1125 0.0917 0.0667 0.0638 0.0639 0.0643 0.0648 0.0655 0.0663 0.0672 0.0679 0.0685 0.0686 

[TRAIN] Epoch[6](939/1500); Loss: 0.052485; Backpropagation: 0.1081 sec; Batch: 0.4438 sec
0.1081 0.0715 0.0696 0.0594 0.0524 0.0465 0.0444 0.0435 0.0424 0.0423 0.0422 0.0426 0.0429 0.0434 0.0438 0.0447 

[TRAIN] Epoch[6](940/1500); Loss: 0.082987; Backpropagation: 0.1080 sec; Batch: 0.4427 sec
0.1661 0.1216 0.1201 0.0833 0.0753 0.0739 0.0731 0.0713 0.0692 0.0685 0.0678 0.0676 0.0673 0.0675 0.0676 0.0678 

[TRAIN] Epoch[6](941/1500); Loss: 0.076996; Backpropagation: 0.0989 sec; Batch: 0.4339 sec
0.1295 0.1722 0.1181 0.0903 0.0709 0.0611 0.0587 0.0578 0.0582 0.0588 0.0589 0.0590 0.0590 0.0594 0.0598 0.0604 

[TRAIN] Epoch[6](942/1500); Loss: 0.098525; Backpropagation: 0.0984 sec; Batch: 0.4325 sec
0.1678 0.1979 0.1564 0.1170 0.0930 0.0850 0.0809 0.0789 0.0769 0.0759 0.0750 0.0745 0.0744 0.0745 0.0743 0.0739 

[TRAIN] Epoch[6](943/1500); Loss: 0.093849; Backpropagation: 0.0985 sec; Batch: 0.4335 sec
0.2251 0.2489 0.2040 0.1558 0.1061 0.0630 0.0558 0.0516 0.0496 0.0486 0.0489 0.0488 0.0483 0.0483 0.0489 0.0499 

[TRAIN] Epoch[6](944/1500); Loss: 0.099371; Backpropagation: 0.0988 sec; Batch: 0.4355 sec
0.1601 0.1837 0.1507 0.1216 0.1048 0.0929 0.0859 0.0814 0.0788 0.0777 0.0770 0.0763 0.0753 0.0749 0.0746 0.0742 

[TRAIN] Epoch[6](945/1500); Loss: 0.140546; Backpropagation: 0.1025 sec; Batch: 0.4373 sec
0.4521 0.3648 0.3448 0.2074 0.1509 0.0859 0.0561 0.0977 0.0704 0.0653 0.0576 0.0574 0.0572 0.0614 0.0598 0.0599 

[TRAIN] Epoch[6](946/1500); Loss: 0.074873; Backpropagation: 0.1024 sec; Batch: 0.4370 sec
0.1321 0.1091 0.1016 0.0874 0.0812 0.0709 0.0672 0.0644 0.0631 0.0615 0.0607 0.0601 0.0599 0.0596 0.0595 0.0597 

[TRAIN] Epoch[6](947/1500); Loss: 0.111916; Backpropagation: 0.0988 sec; Batch: 0.4338 sec
0.1390 0.1410 0.1247 0.1190 0.1129 0.1068 0.1063 0.1059 0.1053 0.1049 0.1046 0.1045 0.1043 0.1040 0.1038 0.1037 

[TRAIN] Epoch[6](948/1500); Loss: 0.105730; Backpropagation: 0.0992 sec; Batch: 0.4343 sec
0.1354 0.1400 0.1181 0.1085 0.1043 0.1003 0.0994 0.0987 0.0981 0.0980 0.0984 0.0984 0.0983 0.0985 0.0986 0.0989 

[TRAIN] Epoch[6](949/1500); Loss: 0.091984; Backpropagation: 0.0984 sec; Batch: 0.4336 sec
0.1548 0.1814 0.1455 0.1169 0.0973 0.0841 0.0756 0.0709 0.0695 0.0687 0.0682 0.0679 0.0678 0.0677 0.0678 0.0677 

[TRAIN] Epoch[6](950/1500); Loss: 0.103682; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.2455 0.3402 0.2558 0.1787 0.0972 0.0501 0.0492 0.0491 0.0488 0.0493 0.0485 0.0484 0.0483 0.0490 0.0503 0.0507 

[TRAIN] Epoch[6](951/1500); Loss: 0.107467; Backpropagation: 0.0991 sec; Batch: 0.4340 sec
0.1466 0.1322 0.1249 0.1174 0.1101 0.1037 0.1010 0.0994 0.0985 0.0981 0.0980 0.0980 0.0979 0.0978 0.0979 0.0978 

[TRAIN] Epoch[6](952/1500); Loss: 0.084308; Backpropagation: 0.0986 sec; Batch: 0.4334 sec
0.1156 0.1352 0.1075 0.0866 0.0815 0.0767 0.0754 0.0749 0.0745 0.0741 0.0739 0.0741 0.0743 0.0744 0.0749 0.0753 

[TRAIN] Epoch[6](953/1500); Loss: 0.105833; Backpropagation: 0.0987 sec; Batch: 0.4358 sec
0.1281 0.1124 0.1093 0.1171 0.1113 0.1045 0.1032 0.1022 0.1015 0.1010 0.1007 0.1005 0.1004 0.1003 0.1003 0.1004 

[TRAIN] Epoch[6](954/1500); Loss: 0.079309; Backpropagation: 0.0988 sec; Batch: 0.4342 sec
0.1436 0.1540 0.1253 0.0942 0.0748 0.0680 0.0654 0.0642 0.0628 0.0619 0.0607 0.0599 0.0591 0.0586 0.0582 0.0581 

[TRAIN] Epoch[6](955/1500); Loss: 0.117345; Backpropagation: 0.0991 sec; Batch: 0.4786 sec
0.2187 0.2118 0.1864 0.1302 0.1097 0.0996 0.0955 0.0931 0.0920 0.0920 0.0912 0.0914 0.0915 0.0915 0.0914 0.0914 

[TRAIN] Epoch[6](956/1500); Loss: 0.108088; Backpropagation: 0.0989 sec; Batch: 0.4749 sec
0.1641 0.1425 0.1343 0.1133 0.1099 0.1024 0.1002 0.0982 0.0970 0.0961 0.0956 0.0954 0.0952 0.0952 0.0951 0.0950 

[TRAIN] Epoch[6](957/1500); Loss: 0.108931; Backpropagation: 0.0991 sec; Batch: 0.4743 sec
0.2081 0.1720 0.1686 0.1217 0.1111 0.0962 0.0884 0.0867 0.0862 0.0860 0.0856 0.0861 0.0859 0.0866 0.0864 0.0872 

[TRAIN] Epoch[6](958/1500); Loss: 0.127521; Backpropagation: 0.0991 sec; Batch: 0.4934 sec
0.1669 0.1883 0.1612 0.1428 0.1255 0.1179 0.1163 0.1150 0.1143 0.1137 0.1136 0.1133 0.1131 0.1129 0.1128 0.1128 

[TRAIN] Epoch[6](959/1500); Loss: 0.093751; Backpropagation: 0.0991 sec; Batch: 0.4769 sec
0.1625 0.1525 0.1300 0.0881 0.0833 0.0830 0.0821 0.0810 0.0801 0.0798 0.0798 0.0797 0.0796 0.0794 0.0796 0.0795 

[TRAIN] Epoch[6](960/1500); Loss: 0.132823; Backpropagation: 0.0990 sec; Batch: 0.4617 sec
0.2771 0.2353 0.2261 0.1579 0.1407 0.1177 0.1071 0.0988 0.0981 0.0962 0.0956 0.0952 0.0950 0.0952 0.0947 0.0944 

[TRAIN] Epoch[6](961/1500); Loss: 0.088677; Backpropagation: 0.0991 sec; Batch: 0.4712 sec
0.1676 0.1261 0.1184 0.0892 0.0814 0.0751 0.0736 0.0733 0.0730 0.0736 0.0744 0.0754 0.0768 0.0786 0.0804 0.0818 

[TRAIN] Epoch[6](962/1500); Loss: 0.062145; Backpropagation: 0.0983 sec; Batch: 0.4689 sec
0.0959 0.0949 0.0776 0.0701 0.0631 0.0567 0.0558 0.0545 0.0537 0.0535 0.0533 0.0533 0.0531 0.0529 0.0528 0.0533 

[TRAIN] Epoch[6](963/1500); Loss: 0.067847; Backpropagation: 0.0990 sec; Batch: 0.4719 sec
0.1040 0.1142 0.0869 0.0731 0.0663 0.0612 0.0596 0.0587 0.0582 0.0578 0.0576 0.0574 0.0574 0.0575 0.0577 0.0580 

[TRAIN] Epoch[6](964/1500); Loss: 0.080231; Backpropagation: 0.0993 sec; Batch: 0.4707 sec
0.1069 0.0890 0.0857 0.0786 0.0787 0.0781 0.0772 0.0766 0.0764 0.0763 0.0763 0.0763 0.0765 0.0768 0.0770 0.0773 

[TRAIN] Epoch[6](965/1500); Loss: 0.090968; Backpropagation: 0.0990 sec; Batch: 0.4748 sec
0.1520 0.1484 0.1307 0.1061 0.0943 0.0828 0.0781 0.0754 0.0759 0.0745 0.0737 0.0733 0.0730 0.0726 0.0724 0.0723 

[TRAIN] Epoch[6](966/1500); Loss: 0.106467; Backpropagation: 0.0989 sec; Batch: 0.4699 sec
0.1231 0.1371 0.1188 0.1074 0.1022 0.1013 0.1003 0.0998 0.0996 0.0998 0.1003 0.1010 0.1017 0.1026 0.1036 0.1048 

[TRAIN] Epoch[6](967/1500); Loss: 0.145193; Backpropagation: 0.0994 sec; Batch: 0.4719 sec
0.1690 0.1663 0.1560 0.1544 0.1493 0.1443 0.1421 0.1406 0.1393 0.1386 0.1379 0.1372 0.1370 0.1371 0.1371 0.1368 

[TRAIN] Epoch[6](968/1500); Loss: 0.103419; Backpropagation: 0.0991 sec; Batch: 0.5184 sec
0.1449 0.1681 0.1376 0.1182 0.1023 0.0913 0.0897 0.0899 0.0894 0.0888 0.0886 0.0890 0.0892 0.0891 0.0892 0.0894 

[TRAIN] Epoch[6](969/1500); Loss: 0.106983; Backpropagation: 0.0984 sec; Batch: 0.4709 sec
0.2445 0.2082 0.1921 0.1159 0.0942 0.0808 0.0843 0.0783 0.0770 0.0769 0.0765 0.0762 0.0764 0.0765 0.0768 0.0772 

[TRAIN] Epoch[6](970/1500); Loss: 0.166397; Backpropagation: 0.0989 sec; Batch: 0.4735 sec
0.2355 0.2332 0.2166 0.1868 0.1722 0.1550 0.1484 0.1467 0.1464 0.1462 0.1460 0.1459 0.1457 0.1457 0.1460 0.1462 

[TRAIN] Epoch[6](971/1500); Loss: 0.089189; Backpropagation: 0.0992 sec; Batch: 0.4848 sec
0.2623 0.2078 0.1979 0.1084 0.0847 0.0542 0.0566 0.0533 0.0518 0.0503 0.0498 0.0498 0.0501 0.0499 0.0500 0.0501 

[TRAIN] Epoch[6](972/1500); Loss: 0.096525; Backpropagation: 0.0990 sec; Batch: 0.4731 sec
0.1490 0.1469 0.1251 0.1113 0.0993 0.0880 0.0846 0.0829 0.0822 0.0824 0.0822 0.0818 0.0820 0.0823 0.0821 0.0822 

[TRAIN] Epoch[6](973/1500); Loss: 0.111164; Backpropagation: 0.0990 sec; Batch: 0.4739 sec
0.1786 0.1560 0.1450 0.1199 0.1124 0.1040 0.1005 0.0987 0.0975 0.0959 0.0955 0.0952 0.0950 0.0949 0.0949 0.0946 

[TRAIN] Epoch[6](974/1500); Loss: 0.103151; Backpropagation: 0.0990 sec; Batch: 0.4750 sec
0.1419 0.1618 0.1295 0.1064 0.0997 0.0974 0.0960 0.0945 0.0932 0.0918 0.0908 0.0905 0.0898 0.0894 0.0890 0.0888 

[TRAIN] Epoch[6](975/1500); Loss: 0.124050; Backpropagation: 0.0991 sec; Batch: 0.4739 sec
0.2447 0.2300 0.2101 0.1591 0.1376 0.1144 0.1037 0.0941 0.0889 0.0874 0.0871 0.0863 0.0855 0.0853 0.0853 0.0852 

[TRAIN] Epoch[6](976/1500); Loss: 0.110849; Backpropagation: 0.0989 sec; Batch: 0.4802 sec
0.1987 0.2586 0.2008 0.1534 0.1124 0.0856 0.0803 0.0774 0.0768 0.0762 0.0762 0.0760 0.0756 0.0753 0.0752 0.0751 

[TRAIN] Epoch[6](977/1500); Loss: 0.072318; Backpropagation: 0.0991 sec; Batch: 0.4667 sec
0.1431 0.1502 0.1239 0.0929 0.0772 0.0638 0.0568 0.0535 0.0518 0.0510 0.0497 0.0491 0.0487 0.0485 0.0484 0.0483 

[TRAIN] Epoch[6](978/1500); Loss: 0.096486; Backpropagation: 0.0990 sec; Batch: 0.4735 sec
0.1533 0.1699 0.1352 0.1113 0.0962 0.0866 0.0832 0.0813 0.0801 0.0793 0.0787 0.0783 0.0778 0.0777 0.0775 0.0773 

[TRAIN] Epoch[6](979/1500); Loss: 0.078640; Backpropagation: 0.0996 sec; Batch: 0.4349 sec
0.1367 0.1072 0.1000 0.0873 0.0815 0.0733 0.0719 0.0699 0.0685 0.0672 0.0666 0.0662 0.0657 0.0655 0.0653 0.0655 

[TRAIN] Epoch[6](980/1500); Loss: 0.059409; Backpropagation: 0.0989 sec; Batch: 0.4778 sec
0.0816 0.1356 0.0827 0.0635 0.0558 0.0506 0.0489 0.0491 0.0486 0.0479 0.0475 0.0479 0.0478 0.0475 0.0476 0.0479 

[TRAIN] Epoch[6](981/1500); Loss: 0.141014; Backpropagation: 0.0993 sec; Batch: 0.4348 sec
0.2275 0.1941 0.1857 0.1496 0.1383 0.1293 0.1261 0.1245 0.1232 0.1223 0.1219 0.1221 0.1223 0.1226 0.1233 0.1235 

[TRAIN] Epoch[6](982/1500); Loss: 0.135430; Backpropagation: 0.0989 sec; Batch: 0.4965 sec
0.2966 0.2987 0.2685 0.2002 0.1669 0.1291 0.1004 0.0826 0.0785 0.0781 0.0780 0.0776 0.0777 0.0778 0.0780 0.0783 

[TRAIN] Epoch[6](983/1500); Loss: 0.123830; Backpropagation: 0.0990 sec; Batch: 0.4709 sec
0.1477 0.1694 0.1422 0.1296 0.1235 0.1192 0.1177 0.1165 0.1157 0.1152 0.1147 0.1143 0.1138 0.1137 0.1139 0.1141 

[TRAIN] Epoch[6](984/1500); Loss: 0.109577; Backpropagation: 0.0991 sec; Batch: 0.4746 sec
0.1837 0.1942 0.1658 0.1268 0.1081 0.0963 0.0923 0.0900 0.0893 0.0887 0.0882 0.0871 0.0863 0.0857 0.0855 0.0852 

[TRAIN] Epoch[6](985/1500); Loss: 0.126086; Backpropagation: 0.0991 sec; Batch: 0.4706 sec
0.2574 0.2227 0.2098 0.1525 0.1327 0.1065 0.1011 0.0971 0.0957 0.0933 0.0922 0.0915 0.0912 0.0912 0.0912 0.0913 

[TRAIN] Epoch[6](986/1500); Loss: 0.094600; Backpropagation: 0.0989 sec; Batch: 0.4855 sec
0.1558 0.1255 0.1174 0.0962 0.0881 0.0854 0.0841 0.0848 0.0838 0.0837 0.0835 0.0849 0.0848 0.0848 0.0851 0.0855 

[TRAIN] Epoch[6](987/1500); Loss: 0.119369; Backpropagation: 0.0983 sec; Batch: 0.4720 sec
0.1493 0.1553 0.1378 0.1272 0.1204 0.1155 0.1133 0.1122 0.1116 0.1107 0.1103 0.1098 0.1093 0.1090 0.1091 0.1091 

[TRAIN] Epoch[6](988/1500); Loss: 0.098612; Backpropagation: 0.0984 sec; Batch: 0.4342 sec
0.1464 0.1315 0.1230 0.1132 0.1064 0.0970 0.0930 0.0898 0.0874 0.0861 0.0852 0.0845 0.0840 0.0835 0.0834 0.0831 

[TRAIN] Epoch[6](989/1500); Loss: 0.121239; Backpropagation: 0.0991 sec; Batch: 0.5152 sec
0.1651 0.1740 0.1438 0.1265 0.1183 0.1135 0.1117 0.1103 0.1098 0.1094 0.1094 0.1091 0.1091 0.1093 0.1100 0.1106 

[TRAIN] Epoch[6](990/1500); Loss: 0.054489; Backpropagation: 0.1040 sec; Batch: 0.4632 sec
0.1400 0.0920 0.0904 0.0597 0.0517 0.0430 0.0417 0.0417 0.0394 0.0391 0.0390 0.0388 0.0386 0.0388 0.0389 0.0390 

[TRAIN] Epoch[6](991/1500); Loss: 0.114882; Backpropagation: 0.0990 sec; Batch: 0.4729 sec
0.1547 0.1600 0.1436 0.1264 0.1181 0.1102 0.1056 0.1037 0.1031 0.1027 0.1022 0.1019 0.1016 0.1016 0.1014 0.1013 

[TRAIN] Epoch[6](992/1500); Loss: 0.102532; Backpropagation: 0.0991 sec; Batch: 0.4386 sec
0.1579 0.1589 0.1402 0.1145 0.1019 0.0928 0.0902 0.0889 0.0879 0.0875 0.0871 0.0869 0.0867 0.0865 0.0864 0.0862 

[TRAIN] Epoch[6](993/1500); Loss: 0.055319; Backpropagation: 0.0989 sec; Batch: 0.4751 sec
0.0892 0.0847 0.0665 0.0647 0.0547 0.0494 0.0485 0.0476 0.0468 0.0467 0.0467 0.0467 0.0471 0.0480 0.0486 0.0492 

[TRAIN] Epoch[6](994/1500); Loss: 0.102981; Backpropagation: 0.0993 sec; Batch: 0.4345 sec
0.1431 0.1372 0.1223 0.1081 0.1035 0.0991 0.0966 0.0949 0.0938 0.0932 0.0929 0.0926 0.0926 0.0926 0.0925 0.0926 

[TRAIN] Epoch[6](995/1500); Loss: 0.124048; Backpropagation: 0.0991 sec; Batch: 0.4821 sec
0.1885 0.2013 0.1759 0.1553 0.1373 0.1188 0.1085 0.1034 0.1011 0.1005 0.1001 0.0994 0.0989 0.0987 0.0985 0.0986 

[TRAIN] Epoch[6](996/1500); Loss: 0.117890; Backpropagation: 0.0990 sec; Batch: 0.4699 sec
0.2482 0.2122 0.2024 0.1454 0.1265 0.0998 0.0916 0.0901 0.0868 0.0850 0.0839 0.0832 0.0829 0.0827 0.0828 0.0829 

[TRAIN] Epoch[6](997/1500); Loss: 0.069672; Backpropagation: 0.0992 sec; Batch: 0.4753 sec
0.1394 0.1084 0.1023 0.0819 0.0754 0.0624 0.0578 0.0561 0.0557 0.0547 0.0538 0.0536 0.0534 0.0530 0.0533 0.0536 

[TRAIN] Epoch[6](998/1500); Loss: 0.135299; Backpropagation: 0.0991 sec; Batch: 0.5287 sec
0.1704 0.1638 0.1520 0.1473 0.1422 0.1343 0.1312 0.1287 0.1267 0.1250 0.1242 0.1239 0.1237 0.1237 0.1238 0.1239 

[TRAIN] Epoch[6](999/1500); Loss: 0.107142; Backpropagation: 0.0990 sec; Batch: 0.5327 sec
0.1374 0.1267 0.1190 0.1129 0.1095 0.1066 0.1045 0.1028 0.1016 0.1007 0.0999 0.0992 0.0988 0.0985 0.0981 0.0979 

[TRAIN] Epoch[6](1000/1500); Loss: 0.085679; Backpropagation: 0.0991 sec; Batch: 0.4747 sec
0.1001 0.1116 0.0904 0.0873 0.0852 0.0822 0.0818 0.0819 0.0815 0.0817 0.0810 0.0807 0.0809 0.0815 0.0815 0.0816 

[TRAIN] Epoch[6](1001/1500); Loss: 0.075196; Backpropagation: 0.1022 sec; Batch: 0.4774 sec
0.1216 0.0879 0.0878 0.0816 0.0763 0.0698 0.0697 0.0685 0.0678 0.0674 0.0673 0.0674 0.0674 0.0674 0.0675 0.0678 

[TRAIN] Epoch[6](1002/1500); Loss: 0.086186; Backpropagation: 0.1022 sec; Batch: 0.4788 sec
0.1098 0.0967 0.0905 0.0916 0.0895 0.0850 0.0839 0.0835 0.0828 0.0822 0.0813 0.0807 0.0804 0.0805 0.0803 0.0802 

[TRAIN] Epoch[6](1003/1500); Loss: 0.088652; Backpropagation: 0.0986 sec; Batch: 0.4507 sec
0.1315 0.1628 0.1211 0.0935 0.0839 0.0806 0.0787 0.0770 0.0759 0.0749 0.0742 0.0735 0.0732 0.0728 0.0724 0.0723 

[TRAIN] Epoch[6](1004/1500); Loss: 0.136006; Backpropagation: 0.0990 sec; Batch: 0.5066 sec
0.1896 0.1819 0.1682 0.1501 0.1398 0.1289 0.1245 0.1236 0.1231 0.1223 0.1216 0.1210 0.1208 0.1206 0.1202 0.1200 

[TRAIN] Epoch[6](1005/1500); Loss: 0.056579; Backpropagation: 0.0991 sec; Batch: 0.4746 sec
0.0752 0.1293 0.0766 0.0622 0.0534 0.0486 0.0475 0.0471 0.0464 0.0459 0.0454 0.0455 0.0457 0.0454 0.0453 0.0458 

[TRAIN] Epoch[6](1006/1500); Loss: 0.165897; Backpropagation: 0.1022 sec; Batch: 0.4786 sec
0.2365 0.2432 0.2185 0.1863 0.1702 0.1570 0.1513 0.1478 0.1465 0.1456 0.1445 0.1433 0.1424 0.1415 0.1405 0.1394 

[TRAIN] Epoch[6](1007/1500); Loss: 0.173735; Backpropagation: 0.1023 sec; Batch: 0.4586 sec
0.1895 0.1862 0.1812 0.1786 0.1764 0.1724 0.1721 0.1712 0.1703 0.1697 0.1694 0.1691 0.1688 0.1684 0.1682 0.1682 

[TRAIN] Epoch[6](1008/1500); Loss: 0.077337; Backpropagation: 0.0989 sec; Batch: 0.4656 sec
0.1558 0.2104 0.1529 0.1066 0.0688 0.0533 0.0509 0.0497 0.0495 0.0505 0.0502 0.0489 0.0480 0.0472 0.0474 0.0473 

[TRAIN] Epoch[6](1009/1500); Loss: 0.147144; Backpropagation: 0.0990 sec; Batch: 0.4762 sec
0.3693 0.3076 0.2880 0.1982 0.1535 0.1057 0.0884 0.1104 0.0966 0.0937 0.0903 0.0899 0.0901 0.0904 0.0909 0.0914 

[TRAIN] Epoch[6](1010/1500); Loss: 0.041680; Backpropagation: 0.0993 sec; Batch: 0.4347 sec
0.1142 0.0674 0.0646 0.0458 0.0443 0.0357 0.0326 0.0311 0.0296 0.0287 0.0284 0.0285 0.0286 0.0288 0.0291 0.0294 

[TRAIN] Epoch[6](1011/1500); Loss: 0.141347; Backpropagation: 0.1008 sec; Batch: 0.5035 sec
0.1781 0.1697 0.1587 0.1447 0.1408 0.1382 0.1359 0.1349 0.1341 0.1333 0.1328 0.1324 0.1322 0.1321 0.1319 0.1318 

[TRAIN] Epoch[6](1012/1500); Loss: 0.073548; Backpropagation: 0.1023 sec; Batch: 0.4711 sec
0.1248 0.1393 0.1013 0.0811 0.0710 0.0662 0.0639 0.0619 0.0600 0.0588 0.0575 0.0576 0.0577 0.0577 0.0583 0.0596 

[TRAIN] Epoch[6](1013/1500); Loss: 0.043188; Backpropagation: 0.1025 sec; Batch: 0.4872 sec
0.0576 0.0837 0.0522 0.0427 0.0403 0.0391 0.0391 0.0382 0.0375 0.0371 0.0372 0.0371 0.0370 0.0370 0.0374 0.0378 

[TRAIN] Epoch[6](1014/1500); Loss: 0.151474; Backpropagation: 0.0990 sec; Batch: 0.4742 sec
0.2300 0.2670 0.2228 0.1782 0.1513 0.1298 0.1278 0.1257 0.1246 0.1242 0.1243 0.1242 0.1236 0.1232 0.1235 0.1234 

[TRAIN] Epoch[6](1015/1500); Loss: 0.117874; Backpropagation: 0.0991 sec; Batch: 0.4716 sec
0.1789 0.2159 0.1754 0.1430 0.1209 0.1068 0.0984 0.0956 0.0955 0.0946 0.0941 0.0936 0.0934 0.0932 0.0933 0.0935 

[TRAIN] Epoch[6](1016/1500); Loss: 0.058031; Backpropagation: 0.0939 sec; Batch: 0.4621 sec
0.0688 0.0943 0.0663 0.0611 0.0578 0.0546 0.0527 0.0525 0.0523 0.0523 0.0522 0.0523 0.0525 0.0527 0.0530 0.0532 

[TRAIN] Epoch[6](1017/1500); Loss: 0.076077; Backpropagation: 0.0940 sec; Batch: 0.4841 sec
0.1459 0.2046 0.1465 0.1010 0.0697 0.0536 0.0506 0.0499 0.0502 0.0498 0.0495 0.0491 0.0492 0.0491 0.0492 0.0494 

[TRAIN] Epoch[6](1018/1500); Loss: 0.091135; Backpropagation: 0.0938 sec; Batch: 0.4811 sec
0.1917 0.2704 0.1947 0.1275 0.0799 0.0589 0.0556 0.0541 0.0535 0.0540 0.0531 0.0525 0.0524 0.0529 0.0532 0.0538 

[TRAIN] Epoch[6](1019/1500); Loss: 0.118495; Backpropagation: 0.0938 sec; Batch: 0.4669 sec
0.2722 0.3259 0.2676 0.2080 0.1536 0.1028 0.0606 0.0632 0.0595 0.0576 0.0560 0.0551 0.0541 0.0532 0.0529 0.0538 

[TRAIN] Epoch[6](1020/1500); Loss: 0.107073; Backpropagation: 0.0938 sec; Batch: 0.4664 sec
0.1558 0.1929 0.1536 0.1202 0.1006 0.0945 0.0918 0.0907 0.0906 0.0898 0.0892 0.0888 0.0885 0.0887 0.0887 0.0887 

[TRAIN] Epoch[6](1021/1500); Loss: 0.146169; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.1891 0.1822 0.1705 0.1537 0.1488 0.1410 0.1386 0.1371 0.1362 0.1355 0.1349 0.1345 0.1342 0.1342 0.1342 0.1340 

[TRAIN] Epoch[6](1022/1500); Loss: 0.114997; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.2120 0.2850 0.2152 0.1514 0.1032 0.0810 0.0780 0.0780 0.0779 0.0784 0.0789 0.0791 0.0794 0.0799 0.0809 0.0815 

[TRAIN] Epoch[6](1023/1500); Loss: 0.098130; Backpropagation: 0.0939 sec; Batch: 0.4702 sec
0.1363 0.1138 0.1054 0.1234 0.1023 0.0950 0.0913 0.0901 0.0894 0.0891 0.0888 0.0890 0.0892 0.0888 0.0887 0.0894 

[TRAIN] Epoch[6](1024/1500); Loss: 0.132999; Backpropagation: 0.0939 sec; Batch: 0.4914 sec
0.1744 0.1670 0.1523 0.1338 0.1289 0.1277 0.1255 0.1241 0.1242 0.1236 0.1238 0.1239 0.1241 0.1243 0.1248 0.1255 

[TRAIN] Epoch[6](1025/1500); Loss: 0.085273; Backpropagation: 0.0938 sec; Batch: 0.4653 sec
0.1140 0.1043 0.0971 0.0906 0.0849 0.0817 0.0807 0.0801 0.0796 0.0791 0.0788 0.0786 0.0786 0.0787 0.0788 0.0789 

[TRAIN] Epoch[6](1026/1500); Loss: 0.078052; Backpropagation: 0.0938 sec; Batch: 0.4723 sec
0.1096 0.0995 0.0883 0.0866 0.0806 0.0757 0.0738 0.0726 0.0716 0.0708 0.0702 0.0699 0.0697 0.0697 0.0700 0.0702 

[TRAIN] Epoch[6](1027/1500); Loss: 0.124903; Backpropagation: 0.0939 sec; Batch: 0.4703 sec
0.1540 0.1391 0.1321 0.1218 0.1195 0.1212 0.1205 0.1203 0.1205 0.1205 0.1206 0.1209 0.1211 0.1216 0.1221 0.1228 

[TRAIN] Epoch[6](1028/1500); Loss: 0.055482; Backpropagation: 0.0937 sec; Batch: 0.4656 sec
0.1173 0.0826 0.0750 0.0563 0.0580 0.0517 0.0469 0.0456 0.0448 0.0446 0.0441 0.0437 0.0439 0.0441 0.0442 0.0447 

[TRAIN] Epoch[6](1029/1500); Loss: 0.196879; Backpropagation: 0.0940 sec; Batch: 0.4711 sec
0.2459 0.2419 0.2251 0.2082 0.2036 0.1959 0.1919 0.1879 0.1855 0.1838 0.1822 0.1812 0.1800 0.1795 0.1790 0.1785 

[TRAIN] Epoch[6](1030/1500); Loss: 0.082275; Backpropagation: 0.0937 sec; Batch: 0.4710 sec
0.1161 0.0998 0.0935 0.0874 0.0821 0.0781 0.0772 0.0768 0.0764 0.0758 0.0757 0.0756 0.0756 0.0755 0.0754 0.0756 

[TRAIN] Epoch[6](1031/1500); Loss: 0.134722; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1700 0.1822 0.1626 0.1478 0.1382 0.1304 0.1271 0.1248 0.1231 0.1221 0.1216 0.1215 0.1212 0.1210 0.1210 0.1209 

[TRAIN] Epoch[6](1032/1500); Loss: 0.129194; Backpropagation: 0.0932 sec; Batch: 0.4669 sec
0.1888 0.1887 0.1674 0.1363 0.1261 0.1194 0.1172 0.1165 0.1154 0.1142 0.1137 0.1131 0.1127 0.1127 0.1124 0.1124 

[TRAIN] Epoch[6](1033/1500); Loss: 0.105544; Backpropagation: 0.0939 sec; Batch: 0.4878 sec
0.1572 0.1633 0.1373 0.1065 0.1016 0.0965 0.0951 0.0945 0.0937 0.0929 0.0924 0.0920 0.0914 0.0911 0.0914 0.0918 

[TRAIN] Epoch[6](1034/1500); Loss: 0.099494; Backpropagation: 0.0956 sec; Batch: 0.4692 sec
0.1718 0.2032 0.1605 0.1179 0.0959 0.0836 0.0790 0.0775 0.0771 0.0758 0.0755 0.0751 0.0748 0.0745 0.0747 0.0749 

[TRAIN] Epoch[6](1035/1500); Loss: 0.062268; Backpropagation: 0.0957 sec; Batch: 0.4787 sec
0.1263 0.0938 0.0894 0.0722 0.0665 0.0565 0.0534 0.0517 0.0510 0.0496 0.0488 0.0481 0.0475 0.0472 0.0471 0.0471 

[TRAIN] Epoch[6](1036/1500); Loss: 0.100200; Backpropagation: 0.0939 sec; Batch: 0.5049 sec
0.3064 0.2434 0.2335 0.1317 0.1025 0.0603 0.0581 0.0575 0.0523 0.0511 0.0508 0.0512 0.0507 0.0508 0.0514 0.0515 

[TRAIN] Epoch[6](1037/1500); Loss: 0.102421; Backpropagation: 0.0939 sec; Batch: 0.4308 sec
0.1613 0.1859 0.1499 0.1153 0.0991 0.0915 0.0885 0.0863 0.0840 0.0834 0.0830 0.0829 0.0822 0.0818 0.0820 0.0817 

[TRAIN] Epoch[6](1038/1500); Loss: 0.099316; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1576 0.1537 0.1379 0.1123 0.1033 0.0943 0.0885 0.0852 0.0834 0.0824 0.0822 0.0821 0.0819 0.0817 0.0814 0.0811 

[TRAIN] Epoch[6](1039/1500); Loss: 0.109566; Backpropagation: 0.0940 sec; Batch: 0.4487 sec
0.1780 0.1438 0.1407 0.1095 0.1062 0.1017 0.0996 0.0983 0.0975 0.0971 0.0968 0.0965 0.0966 0.0966 0.0968 0.0971 

[TRAIN] Epoch[6](1040/1500); Loss: 0.095463; Backpropagation: 0.0937 sec; Batch: 0.4702 sec
0.1538 0.1617 0.1398 0.1204 0.1072 0.0917 0.0831 0.0786 0.0768 0.0755 0.0743 0.0738 0.0733 0.0727 0.0725 0.0724 

[TRAIN] Epoch[6](1041/1500); Loss: 0.089610; Backpropagation: 0.0939 sec; Batch: 0.4679 sec
0.1495 0.1203 0.1127 0.1040 0.0933 0.0830 0.0807 0.0790 0.0778 0.0767 0.0762 0.0759 0.0763 0.0760 0.0761 0.0763 

[TRAIN] Epoch[6](1042/1500); Loss: 0.126794; Backpropagation: 0.0937 sec; Batch: 0.4656 sec
0.1803 0.1937 0.1673 0.1440 0.1277 0.1153 0.1127 0.1115 0.1107 0.1103 0.1100 0.1095 0.1093 0.1089 0.1088 0.1086 

[TRAIN] Epoch[6](1043/1500); Loss: 0.083039; Backpropagation: 0.0939 sec; Batch: 0.4716 sec
0.1787 0.2424 0.1784 0.1217 0.0764 0.0508 0.0504 0.0485 0.0481 0.0478 0.0473 0.0472 0.0473 0.0477 0.0479 0.0480 

[TRAIN] Epoch[6](1044/1500); Loss: 0.095207; Backpropagation: 0.0938 sec; Batch: 0.4659 sec
0.1556 0.1286 0.1227 0.0941 0.0912 0.0870 0.0860 0.0847 0.0843 0.0843 0.0842 0.0840 0.0841 0.0842 0.0842 0.0842 

[TRAIN] Epoch[6](1045/1500); Loss: 0.035721; Backpropagation: 0.0957 sec; Batch: 0.4725 sec
0.0619 0.0795 0.0450 0.0331 0.0340 0.0326 0.0304 0.0299 0.0294 0.0293 0.0284 0.0282 0.0278 0.0275 0.0273 0.0273 

[TRAIN] Epoch[6](1046/1500); Loss: 0.091489; Backpropagation: 0.0938 sec; Batch: 0.4362 sec
0.1398 0.1458 0.1184 0.0886 0.0852 0.0830 0.0819 0.0811 0.0809 0.0805 0.0801 0.0800 0.0799 0.0797 0.0794 0.0794 

[TRAIN] Epoch[6](1047/1500); Loss: 0.109591; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1757 0.2203 0.1723 0.1324 0.1096 0.0955 0.0873 0.0849 0.0845 0.0845 0.0844 0.0843 0.0842 0.0843 0.0845 0.0848 

[TRAIN] Epoch[6](1048/1500); Loss: 0.094120; Backpropagation: 0.0938 sec; Batch: 0.4451 sec
0.1340 0.1191 0.1112 0.1049 0.0977 0.0915 0.0887 0.0869 0.0858 0.0850 0.0845 0.0839 0.0836 0.0833 0.0831 0.0829 

[TRAIN] Epoch[6](1049/1500); Loss: 0.110956; Backpropagation: 0.0942 sec; Batch: 0.4919 sec
0.1834 0.1617 0.1508 0.1168 0.1072 0.1022 0.1009 0.0978 0.0965 0.0952 0.0950 0.0946 0.0941 0.0934 0.0929 0.0928 

[TRAIN] Epoch[6](1050/1500); Loss: 0.108585; Backpropagation: 0.0937 sec; Batch: 0.4658 sec
0.1295 0.1413 0.1236 0.1101 0.1053 0.1030 0.1020 0.1017 0.1012 0.1012 0.1015 0.1020 0.1025 0.1032 0.1040 0.1049 

[TRAIN] Epoch[6](1051/1500); Loss: 0.116060; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.1497 0.1624 0.1424 0.1243 0.1165 0.1102 0.1080 0.1068 0.1060 0.1051 0.1046 0.1043 0.1042 0.1042 0.1041 0.1042 

[TRAIN] Epoch[6](1052/1500); Loss: 0.108070; Backpropagation: 0.0936 sec; Batch: 0.4668 sec
0.2740 0.2129 0.1997 0.1179 0.1025 0.0842 0.0774 0.0763 0.0743 0.0736 0.0728 0.0734 0.0727 0.0724 0.0724 0.0725 

[TRAIN] Epoch[6](1053/1500); Loss: 0.036771; Backpropagation: 0.0938 sec; Batch: 0.4672 sec
0.0566 0.0832 0.0447 0.0352 0.0341 0.0318 0.0311 0.0319 0.0311 0.0300 0.0301 0.0299 0.0294 0.0293 0.0298 0.0301 

[TRAIN] Epoch[6](1054/1500); Loss: 0.113182; Backpropagation: 0.0937 sec; Batch: 0.4664 sec
0.1697 0.1596 0.1436 0.1201 0.1144 0.1078 0.1021 0.1010 0.1001 0.0985 0.0981 0.0984 0.0985 0.0988 0.0997 0.1006 

[TRAIN] Epoch[6](1055/1500); Loss: 0.097583; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.1248 0.1312 0.1133 0.1027 0.0977 0.0935 0.0920 0.0913 0.0907 0.0901 0.0897 0.0893 0.0891 0.0888 0.0886 0.0886 

[TRAIN] Epoch[6](1056/1500); Loss: 0.117025; Backpropagation: 0.0939 sec; Batch: 0.4706 sec
0.1562 0.1718 0.1421 0.1224 0.1120 0.1093 0.1079 0.1075 0.1062 0.1057 0.1052 0.1050 0.1051 0.1053 0.1054 0.1052 

[TRAIN] Epoch[6](1057/1500); Loss: 0.107220; Backpropagation: 0.0939 sec; Batch: 0.4715 sec
0.1522 0.1383 0.1235 0.1145 0.1075 0.1029 0.1013 0.0996 0.0984 0.0973 0.0969 0.0967 0.0967 0.0966 0.0965 0.0965 

[TRAIN] Epoch[6](1058/1500); Loss: 0.117298; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.1789 0.1755 0.1539 0.1254 0.1156 0.1070 0.1019 0.1033 0.1026 0.1008 0.1006 0.1009 0.1008 0.1016 0.1035 0.1047 

[TRAIN] Epoch[6](1059/1500); Loss: 0.131087; Backpropagation: 0.0940 sec; Batch: 0.4346 sec
0.1616 0.1416 0.1386 0.1430 0.1374 0.1287 0.1276 0.1262 0.1257 0.1254 0.1247 0.1241 0.1235 0.1234 0.1231 0.1228 

[TRAIN] Epoch[6](1060/1500); Loss: 0.102889; Backpropagation: 0.0937 sec; Batch: 0.4666 sec
0.1289 0.1119 0.1075 0.1167 0.1098 0.1000 0.0991 0.0980 0.0974 0.0971 0.0969 0.0966 0.0967 0.0965 0.0965 0.0967 

[TRAIN] Epoch[6](1061/1500); Loss: 0.117605; Backpropagation: 0.0937 sec; Batch: 0.4348 sec
0.1953 0.1813 0.1636 0.1384 0.1275 0.1120 0.1042 0.0984 0.0967 0.0956 0.0952 0.0950 0.0946 0.0945 0.0946 0.0948 

[TRAIN] Epoch[6](1062/1500); Loss: 0.116796; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1419 0.1326 0.1230 0.1219 0.1177 0.1141 0.1131 0.1125 0.1121 0.1118 0.1118 0.1117 0.1114 0.1112 0.1110 0.1109 

[TRAIN] Epoch[6](1063/1500); Loss: 0.097660; Backpropagation: 0.0933 sec; Batch: 0.4703 sec
0.1596 0.1743 0.1479 0.1373 0.1071 0.0830 0.0785 0.0769 0.0764 0.0755 0.0752 0.0747 0.0745 0.0741 0.0739 0.0738 

[TRAIN] Epoch[6](1064/1500); Loss: 0.113819; Backpropagation: 0.0922 sec; Batch: 0.4687 sec
0.1423 0.1530 0.1273 0.1177 0.1110 0.1065 0.1058 0.1056 0.1053 0.1054 0.1057 0.1061 0.1065 0.1068 0.1076 0.1084 

[TRAIN] Epoch[6](1065/1500); Loss: 0.132976; Backpropagation: 0.0934 sec; Batch: 0.5216 sec
0.1577 0.1488 0.1412 0.1317 0.1292 0.1285 0.1283 0.1280 0.1279 0.1282 0.1286 0.1289 0.1293 0.1298 0.1304 0.1309 

[TRAIN] Epoch[6](1066/1500); Loss: 0.118967; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1746 0.1662 0.1416 0.1241 0.1177 0.1126 0.1106 0.1087 0.1077 0.1066 0.1060 0.1054 0.1053 0.1052 0.1054 0.1058 

[TRAIN] Epoch[6](1067/1500); Loss: 0.080076; Backpropagation: 0.0982 sec; Batch: 0.4384 sec
0.1075 0.1318 0.0993 0.0848 0.0765 0.0723 0.0709 0.0705 0.0703 0.0704 0.0704 0.0706 0.0709 0.0712 0.0715 0.0721 

[TRAIN] Epoch[6](1068/1500); Loss: 0.118459; Backpropagation: 0.0940 sec; Batch: 0.4292 sec
0.1802 0.1767 0.1590 0.1427 0.1268 0.1114 0.1057 0.1027 0.1006 0.0995 0.0989 0.0983 0.0984 0.0983 0.0982 0.0979 

[TRAIN] Epoch[6](1069/1500); Loss: 0.083794; Backpropagation: 0.0935 sec; Batch: 0.4347 sec
0.1829 0.1337 0.1307 0.1085 0.0964 0.0784 0.0737 0.0691 0.0641 0.0614 0.0588 0.0573 0.0570 0.0567 0.0560 0.0558 

[TRAIN] Epoch[6](1070/1500); Loss: 0.056478; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.1387 0.0957 0.0910 0.0749 0.0575 0.0449 0.0421 0.0403 0.0399 0.0398 0.0397 0.0396 0.0397 0.0398 0.0400 0.0403 

[TRAIN] Epoch[6](1071/1500); Loss: 0.091867; Backpropagation: 0.0938 sec; Batch: 0.5026 sec
0.1734 0.1808 0.1489 0.1128 0.0890 0.0742 0.0719 0.0701 0.0685 0.0681 0.0680 0.0679 0.0682 0.0686 0.0694 0.0701 

[TRAIN] Epoch[6](1072/1500); Loss: 0.074937; Backpropagation: 0.0937 sec; Batch: 0.4702 sec
0.1688 0.1408 0.1281 0.0835 0.0712 0.0591 0.0593 0.0536 0.0537 0.0534 0.0533 0.0536 0.0540 0.0548 0.0554 0.0564 

[TRAIN] Epoch[6](1073/1500); Loss: 0.109526; Backpropagation: 0.0940 sec; Batch: 0.4677 sec
0.1542 0.1610 0.1388 0.1180 0.1111 0.1021 0.0991 0.0978 0.0978 0.0969 0.0966 0.0963 0.0958 0.0956 0.0957 0.0957 

[TRAIN] Epoch[6](1074/1500); Loss: 0.149108; Backpropagation: 0.0938 sec; Batch: 0.4655 sec
0.2067 0.2018 0.1873 0.1576 0.1463 0.1398 0.1362 0.1356 0.1355 0.1352 0.1348 0.1342 0.1338 0.1337 0.1336 0.1335 

[TRAIN] Epoch[6](1075/1500); Loss: 0.054265; Backpropagation: 0.0939 sec; Batch: 0.4888 sec
0.1163 0.1160 0.0904 0.0710 0.0575 0.0435 0.0414 0.0399 0.0387 0.0375 0.0367 0.0362 0.0358 0.0359 0.0357 0.0358 

[TRAIN] Epoch[6](1076/1500); Loss: 0.074680; Backpropagation: 0.0938 sec; Batch: 0.5290 sec
0.1379 0.1130 0.0936 0.0886 0.0764 0.0672 0.0637 0.0625 0.0618 0.0614 0.0615 0.0614 0.0614 0.0613 0.0616 0.0617 

[TRAIN] Epoch[6](1077/1500); Loss: 0.103251; Backpropagation: 0.0939 sec; Batch: 0.4665 sec
0.1734 0.1493 0.1378 0.1111 0.1015 0.0926 0.0926 0.0901 0.0893 0.0888 0.0883 0.0875 0.0873 0.0875 0.0874 0.0874 

[TRAIN] Epoch[6](1078/1500); Loss: 0.081093; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1126 0.1389 0.1048 0.0883 0.0784 0.0730 0.0704 0.0702 0.0699 0.0697 0.0697 0.0698 0.0700 0.0703 0.0705 0.0710 

[TRAIN] Epoch[6](1079/1500); Loss: 0.127943; Backpropagation: 0.0938 sec; Batch: 0.4687 sec
0.1669 0.1733 0.1516 0.1378 0.1281 0.1202 0.1184 0.1176 0.1170 0.1169 0.1169 0.1166 0.1164 0.1165 0.1164 0.1164 

[TRAIN] Epoch[6](1080/1500); Loss: 0.108106; Backpropagation: 0.0938 sec; Batch: 0.4633 sec
0.3038 0.2422 0.2320 0.1334 0.1088 0.0755 0.0671 0.0676 0.0651 0.0636 0.0622 0.0620 0.0617 0.0614 0.0616 0.0618 

[TRAIN] Epoch[6](1081/1500); Loss: 0.079878; Backpropagation: 0.0938 sec; Batch: 0.4726 sec
0.1165 0.1115 0.0954 0.0878 0.0817 0.0767 0.0752 0.0742 0.0727 0.0714 0.0705 0.0698 0.0692 0.0687 0.0683 0.0684 

[TRAIN] Epoch[6](1082/1500); Loss: 0.066049; Backpropagation: 0.0939 sec; Batch: 0.4402 sec
0.1534 0.1145 0.1011 0.0548 0.0539 0.0624 0.0568 0.0545 0.0519 0.0497 0.0493 0.0492 0.0500 0.0507 0.0519 0.0528 

[TRAIN] Epoch[6](1083/1500); Loss: 0.063484; Backpropagation: 0.0939 sec; Batch: 0.4706 sec
0.1803 0.1212 0.1148 0.0603 0.0537 0.0538 0.0472 0.0449 0.0434 0.0426 0.0423 0.0421 0.0421 0.0423 0.0425 0.0425 

[TRAIN] Epoch[6](1084/1500); Loss: 0.052948; Backpropagation: 0.0981 sec; Batch: 0.4668 sec
0.0962 0.0617 0.0598 0.0700 0.0529 0.0486 0.0462 0.0457 0.0454 0.0450 0.0451 0.0453 0.0460 0.0459 0.0464 0.0470 

[TRAIN] Epoch[6](1085/1500); Loss: 0.143409; Backpropagation: 0.0956 sec; Batch: 0.4681 sec
0.1836 0.2030 0.1730 0.1534 0.1431 0.1364 0.1342 0.1332 0.1317 0.1307 0.1297 0.1291 0.1285 0.1283 0.1282 0.1283 

[TRAIN] Epoch[6](1086/1500); Loss: 0.080457; Backpropagation: 0.0933 sec; Batch: 0.5077 sec
0.1174 0.0870 0.0844 0.0993 0.0854 0.0783 0.0757 0.0749 0.0741 0.0733 0.0729 0.0728 0.0728 0.0730 0.0730 0.0730 

[TRAIN] Epoch[6](1087/1500); Loss: 0.102930; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.1647 0.1483 0.1373 0.1146 0.1054 0.0983 0.0943 0.0911 0.0887 0.0876 0.0866 0.0860 0.0858 0.0859 0.0861 0.0861 

[TRAIN] Epoch[6](1088/1500); Loss: 0.074231; Backpropagation: 0.0937 sec; Batch: 0.4707 sec
0.1133 0.1187 0.0953 0.0779 0.0687 0.0662 0.0660 0.0652 0.0650 0.0649 0.0646 0.0642 0.0640 0.0640 0.0646 0.0650 

[TRAIN] Epoch[6](1089/1500); Loss: 0.141188; Backpropagation: 0.0941 sec; Batch: 0.4672 sec
0.1710 0.1650 0.1563 0.1510 0.1462 0.1406 0.1381 0.1362 0.1350 0.1333 0.1323 0.1316 0.1311 0.1308 0.1304 0.1301 

[TRAIN] Epoch[6](1090/1500); Loss: 0.128921; Backpropagation: 0.0956 sec; Batch: 0.4683 sec
0.2147 0.2003 0.1829 0.1445 0.1309 0.1180 0.1132 0.1101 0.1078 0.1065 0.1058 0.1055 0.1054 0.1056 0.1057 0.1059 

[TRAIN] Epoch[6](1091/1500); Loss: 0.126588; Backpropagation: 0.0938 sec; Batch: 0.5104 sec
0.1548 0.1522 0.1408 0.1334 0.1270 0.1239 0.1212 0.1206 0.1196 0.1190 0.1186 0.1184 0.1193 0.1191 0.1188 0.1186 

[TRAIN] Epoch[6](1092/1500); Loss: 0.113768; Backpropagation: 0.0939 sec; Batch: 0.4687 sec
0.1464 0.1428 0.1293 0.1196 0.1142 0.1103 0.1079 0.1069 0.1062 0.1057 0.1055 0.1052 0.1051 0.1050 0.1051 0.1052 

[TRAIN] Epoch[6](1093/1500); Loss: 0.137938; Backpropagation: 0.0938 sec; Batch: 0.4701 sec
0.2469 0.2064 0.1971 0.1491 0.1384 0.1240 0.1189 0.1167 0.1153 0.1148 0.1138 0.1133 0.1132 0.1131 0.1130 0.1130 

[TRAIN] Epoch[6](1094/1500); Loss: 0.068239; Backpropagation: 0.0938 sec; Batch: 0.4708 sec
0.1342 0.1231 0.1061 0.0867 0.0727 0.0657 0.0566 0.0545 0.0524 0.0506 0.0495 0.0489 0.0484 0.0478 0.0475 0.0472 

[TRAIN] Epoch[6](1095/1500); Loss: 0.050953; Backpropagation: 0.0986 sec; Batch: 0.4649 sec
0.1136 0.1120 0.0870 0.0670 0.0515 0.0405 0.0379 0.0365 0.0352 0.0343 0.0336 0.0332 0.0330 0.0329 0.0334 0.0335 

[TRAIN] Epoch[6](1096/1500); Loss: 0.114338; Backpropagation: 0.0941 sec; Batch: 0.4682 sec
0.2210 0.2436 0.2075 0.1707 0.1357 0.1029 0.0797 0.0759 0.0750 0.0744 0.0746 0.0740 0.0738 0.0735 0.0736 0.0735 

[TRAIN] Epoch[6](1097/1500); Loss: 0.112992; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.2499 0.2773 0.2319 0.1760 0.1354 0.0974 0.0702 0.0665 0.0646 0.0636 0.0629 0.0623 0.0626 0.0624 0.0623 0.0625 

[TRAIN] Epoch[6](1098/1500); Loss: 0.082133; Backpropagation: 0.0932 sec; Batch: 0.4650 sec
0.1487 0.1163 0.1097 0.0925 0.0841 0.0752 0.0729 0.0710 0.0697 0.0691 0.0680 0.0676 0.0673 0.0673 0.0674 0.0675 

[TRAIN] Epoch[6](1099/1500); Loss: 0.083483; Backpropagation: 0.0939 sec; Batch: 0.4763 sec
0.1227 0.1510 0.1089 0.0870 0.0785 0.0744 0.0728 0.0715 0.0710 0.0711 0.0709 0.0707 0.0710 0.0711 0.0713 0.0719 

[TRAIN] Epoch[6](1100/1500); Loss: 0.137345; Backpropagation: 0.0937 sec; Batch: 0.4660 sec
0.1866 0.2129 0.1779 0.1472 0.1363 0.1279 0.1236 0.1220 0.1212 0.1206 0.1205 0.1203 0.1201 0.1200 0.1201 0.1203 

[TRAIN] Epoch[6](1101/1500); Loss: 0.146271; Backpropagation: 0.0937 sec; Batch: 0.4284 sec
0.2936 0.2764 0.2580 0.2001 0.1761 0.1477 0.1259 0.1075 0.0983 0.0958 0.0946 0.0935 0.0933 0.0929 0.0934 0.0933 

[TRAIN] Epoch[6](1102/1500); Loss: 0.149391; Backpropagation: 0.0939 sec; Batch: 0.4690 sec
0.2362 0.2089 0.2018 0.1662 0.1542 0.1433 0.1372 0.1320 0.1289 0.1277 0.1273 0.1266 0.1257 0.1252 0.1248 0.1242 

[TRAIN] Epoch[6](1103/1500); Loss: 0.139527; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.1991 0.1784 0.1644 0.1466 0.1334 0.1381 0.1326 0.1309 0.1290 0.1270 0.1261 0.1255 0.1255 0.1253 0.1253 0.1253 

[TRAIN] Epoch[6](1104/1500); Loss: 0.049160; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.0710 0.0616 0.0565 0.0512 0.0491 0.0472 0.0461 0.0454 0.0451 0.0446 0.0445 0.0447 0.0445 0.0446 0.0449 0.0456 

[TRAIN] Epoch[6](1105/1500); Loss: 0.132521; Backpropagation: 0.0940 sec; Batch: 0.4713 sec
0.1675 0.1716 0.1516 0.1351 0.1288 0.1266 0.1254 0.1247 0.1241 0.1236 0.1233 0.1232 0.1233 0.1234 0.1237 0.1244 

[TRAIN] Epoch[6](1106/1500); Loss: 0.083757; Backpropagation: 0.0956 sec; Batch: 0.4676 sec
0.1330 0.1450 0.1181 0.0914 0.0795 0.0732 0.0710 0.0710 0.0704 0.0698 0.0698 0.0697 0.0697 0.0694 0.0694 0.0696 

[TRAIN] Epoch[6](1107/1500); Loss: 0.116686; Backpropagation: 0.0938 sec; Batch: 0.4767 sec
0.1771 0.2307 0.1721 0.1314 0.1095 0.0998 0.0976 0.0958 0.0954 0.0950 0.0946 0.0941 0.0938 0.0933 0.0935 0.0934 

[TRAIN] Epoch[6](1108/1500); Loss: 0.074888; Backpropagation: 0.0937 sec; Batch: 0.4718 sec
0.1340 0.1190 0.1040 0.0761 0.0684 0.0612 0.0646 0.0611 0.0615 0.0619 0.0625 0.0630 0.0637 0.0648 0.0658 0.0665 

[TRAIN] Epoch[6](1109/1500); Loss: 0.133966; Backpropagation: 0.0938 sec; Batch: 0.4779 sec
0.1837 0.1804 0.1637 0.1411 0.1338 0.1278 0.1250 0.1236 0.1225 0.1217 0.1209 0.1203 0.1199 0.1198 0.1196 0.1198 

[TRAIN] Epoch[6](1110/1500); Loss: 0.095757; Backpropagation: 0.0931 sec; Batch: 0.4696 sec
0.2564 0.1879 0.1750 0.0936 0.0843 0.0739 0.0668 0.0652 0.0659 0.0659 0.0655 0.0657 0.0657 0.0665 0.0668 0.0671 

[TRAIN] Epoch[6](1111/1500); Loss: 0.056949; Backpropagation: 0.0938 sec; Batch: 0.4675 sec
0.1262 0.0934 0.0883 0.0735 0.0624 0.0529 0.0479 0.0437 0.0420 0.0411 0.0404 0.0400 0.0399 0.0398 0.0398 0.0400 

[TRAIN] Epoch[6](1112/1500); Loss: 0.094515; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.1332 0.1620 0.1256 0.1051 0.0904 0.0841 0.0832 0.0828 0.0822 0.0815 0.0811 0.0807 0.0804 0.0802 0.0799 0.0799 

[TRAIN] Epoch[6](1113/1500); Loss: 0.108602; Backpropagation: 0.0939 sec; Batch: 0.4387 sec
0.1549 0.1917 0.1505 0.1228 0.1034 0.0967 0.0947 0.0937 0.0928 0.0920 0.0918 0.0914 0.0910 0.0905 0.0902 0.0898 

[TRAIN] Epoch[6](1114/1500); Loss: 0.107533; Backpropagation: 0.0932 sec; Batch: 0.4692 sec
0.2673 0.2249 0.2069 0.1176 0.0946 0.0811 0.0755 0.0763 0.0741 0.0731 0.0720 0.0714 0.0712 0.0713 0.0714 0.0718 

[TRAIN] Epoch[6](1115/1500); Loss: 0.075908; Backpropagation: 0.0934 sec; Batch: 0.4994 sec
0.0937 0.1026 0.0820 0.0767 0.0752 0.0726 0.0716 0.0712 0.0710 0.0711 0.0713 0.0710 0.0709 0.0709 0.0713 0.0716 

[TRAIN] Epoch[6](1116/1500); Loss: 0.171726; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.2188 0.2361 0.2064 0.1815 0.1705 0.1615 0.1585 0.1577 0.1577 0.1577 0.1572 0.1567 0.1570 0.1570 0.1568 0.1564 

[TRAIN] Epoch[6](1117/1500); Loss: 0.111004; Backpropagation: 0.0939 sec; Batch: 0.4704 sec
0.1646 0.1514 0.1406 0.1204 0.1114 0.1028 0.1002 0.1001 0.0999 0.0988 0.0981 0.0979 0.0975 0.0975 0.0973 0.0975 

[TRAIN] Epoch[6](1118/1500); Loss: 0.072093; Backpropagation: 0.0938 sec; Batch: 0.4709 sec
0.1141 0.1345 0.1005 0.0791 0.0706 0.0658 0.0628 0.0611 0.0599 0.0589 0.0582 0.0577 0.0575 0.0576 0.0575 0.0577 

[TRAIN] Epoch[6](1119/1500); Loss: 0.069001; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.1019 0.1402 0.0978 0.0736 0.0637 0.0596 0.0588 0.0578 0.0570 0.0566 0.0562 0.0561 0.0560 0.0561 0.0562 0.0564 

[TRAIN] Epoch[6](1120/1500); Loss: 0.057516; Backpropagation: 0.0938 sec; Batch: 0.4781 sec
0.1257 0.1180 0.0985 0.0763 0.0598 0.0506 0.0455 0.0430 0.0407 0.0391 0.0378 0.0372 0.0370 0.0370 0.0369 0.0372 

[TRAIN] Epoch[6](1121/1500); Loss: 0.062323; Backpropagation: 0.0938 sec; Batch: 0.4717 sec
0.1026 0.1198 0.0922 0.0735 0.0631 0.0572 0.0530 0.0504 0.0498 0.0491 0.0484 0.0480 0.0477 0.0475 0.0475 0.0474 

[TRAIN] Epoch[6](1122/1500); Loss: 0.046704; Backpropagation: 0.0938 sec; Batch: 0.4391 sec
0.0791 0.0554 0.0487 0.0679 0.0477 0.0486 0.0442 0.0422 0.0402 0.0389 0.0385 0.0390 0.0390 0.0389 0.0392 0.0396 

[TRAIN] Epoch[6](1123/1500); Loss: 0.125475; Backpropagation: 0.0957 sec; Batch: 0.4686 sec
0.1695 0.1870 0.1587 0.1371 0.1232 0.1161 0.1144 0.1129 0.1120 0.1114 0.1110 0.1108 0.1109 0.1108 0.1108 0.1109 

[TRAIN] Epoch[6](1124/1500); Loss: 0.092407; Backpropagation: 0.0981 sec; Batch: 0.4729 sec
0.1403 0.1746 0.1329 0.1024 0.0855 0.0796 0.0774 0.0765 0.0759 0.0757 0.0758 0.0758 0.0760 0.0763 0.0767 0.0771 

[TRAIN] Epoch[6](1125/1500); Loss: 0.201524; Backpropagation: 0.0940 sec; Batch: 0.4663 sec
0.2619 0.2566 0.2396 0.2181 0.2133 0.2045 0.1982 0.1913 0.1865 0.1834 0.1809 0.1797 0.1779 0.1781 0.1774 0.1771 

[TRAIN] Epoch[6](1126/1500); Loss: 0.082802; Backpropagation: 0.0937 sec; Batch: 0.4663 sec
0.1384 0.1288 0.1122 0.0945 0.0852 0.0775 0.0748 0.0725 0.0708 0.0692 0.0680 0.0670 0.0667 0.0665 0.0665 0.0664 

[TRAIN] Epoch[6](1127/1500); Loss: 0.135192; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1817 0.2090 0.1770 0.1481 0.1296 0.1243 0.1225 0.1215 0.1207 0.1197 0.1191 0.1183 0.1178 0.1178 0.1179 0.1179 

[TRAIN] Epoch[6](1128/1500); Loss: 0.052118; Backpropagation: 0.0939 sec; Batch: 0.4960 sec
0.1428 0.0925 0.0909 0.0577 0.0496 0.0386 0.0378 0.0383 0.0366 0.0353 0.0351 0.0352 0.0355 0.0360 0.0361 0.0361 

[TRAIN] Epoch[6](1129/1500); Loss: 0.076588; Backpropagation: 0.0939 sec; Batch: 0.4691 sec
0.1513 0.1867 0.1382 0.0957 0.0728 0.0621 0.0579 0.0549 0.0530 0.0507 0.0506 0.0504 0.0502 0.0504 0.0504 0.0503 

[TRAIN] Epoch[6](1130/1500); Loss: 0.113073; Backpropagation: 0.0937 sec; Batch: 0.4583 sec
0.1708 0.1471 0.1399 0.1231 0.1166 0.1081 0.1054 0.1027 0.1013 0.1004 0.0998 0.0993 0.0989 0.0985 0.0985 0.0987 

[TRAIN] Epoch[6](1131/1500); Loss: 0.097959; Backpropagation: 0.0943 sec; Batch: 0.5116 sec
0.1374 0.1436 0.1201 0.1116 0.0966 0.0923 0.0889 0.0879 0.0870 0.0864 0.0864 0.0860 0.0857 0.0857 0.0859 0.0858 

[TRAIN] Epoch[6](1132/1500); Loss: 0.108919; Backpropagation: 0.0935 sec; Batch: 0.4695 sec
0.1723 0.1452 0.1340 0.1167 0.1044 0.1029 0.0997 0.0992 0.0980 0.0970 0.0966 0.0957 0.0953 0.0952 0.0956 0.0951 

[TRAIN] Epoch[6](1133/1500); Loss: 0.138716; Backpropagation: 0.0938 sec; Batch: 0.4363 sec
0.2351 0.2360 0.2128 0.1699 0.1498 0.1282 0.1174 0.1107 0.1085 0.1081 0.1077 0.1071 0.1070 0.1070 0.1070 0.1071 

[TRAIN] Epoch[6](1134/1500); Loss: 0.091219; Backpropagation: 0.0941 sec; Batch: 0.4292 sec
0.1385 0.1237 0.1157 0.1006 0.0957 0.0882 0.0844 0.0821 0.0812 0.0800 0.0793 0.0786 0.0782 0.0778 0.0777 0.0777 

[TRAIN] Epoch[6](1135/1500); Loss: 0.066403; Backpropagation: 0.0933 sec; Batch: 0.4722 sec
0.1188 0.0915 0.0873 0.0739 0.0673 0.0620 0.0590 0.0580 0.0569 0.0563 0.0557 0.0553 0.0552 0.0551 0.0550 0.0551 

[TRAIN] Epoch[6](1136/1500); Loss: 0.114954; Backpropagation: 0.0937 sec; Batch: 0.4376 sec
0.2339 0.1966 0.1840 0.1295 0.1118 0.1020 0.0941 0.0911 0.0896 0.0877 0.0870 0.0866 0.0863 0.0864 0.0863 0.0862 

[TRAIN] Epoch[6](1137/1500); Loss: 0.069924; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1099 0.1348 0.0972 0.0738 0.0638 0.0622 0.0603 0.0588 0.0586 0.0583 0.0576 0.0571 0.0568 0.0568 0.0564 0.0564 

[TRAIN] Epoch[6](1138/1500); Loss: 0.121479; Backpropagation: 0.0936 sec; Batch: 0.4384 sec
0.2366 0.1973 0.1885 0.1322 0.1211 0.1023 0.0978 0.0974 0.0972 0.0966 0.0960 0.0958 0.0958 0.0962 0.0963 0.0967 

[TRAIN] Epoch[6](1139/1500); Loss: 0.086097; Backpropagation: 0.0933 sec; Batch: 0.4662 sec
0.1710 0.1291 0.1224 0.0868 0.0830 0.0761 0.0737 0.0722 0.0711 0.0704 0.0705 0.0706 0.0702 0.0700 0.0699 0.0705 

[TRAIN] Epoch[6](1140/1500); Loss: 0.087067; Backpropagation: 0.0933 sec; Batch: 0.4665 sec
0.1728 0.2453 0.1689 0.1074 0.0731 0.0621 0.0593 0.0578 0.0567 0.0561 0.0556 0.0553 0.0556 0.0558 0.0557 0.0557 

[TRAIN] Epoch[6](1141/1500); Loss: 0.125750; Backpropagation: 0.0941 sec; Batch: 0.4531 sec
0.1852 0.2356 0.1803 0.1401 0.1174 0.1082 0.1063 0.1048 0.1040 0.1040 0.1042 0.1043 0.1044 0.1045 0.1045 0.1041 

[TRAIN] Epoch[6](1142/1500); Loss: 0.126185; Backpropagation: 0.0938 sec; Batch: 0.4648 sec
0.1630 0.1662 0.1417 0.1238 0.1203 0.1189 0.1187 0.1179 0.1174 0.1173 0.1176 0.1181 0.1185 0.1191 0.1198 0.1208 

[TRAIN] Epoch[6](1143/1500); Loss: 0.073937; Backpropagation: 0.0938 sec; Batch: 0.4706 sec
0.1137 0.0979 0.0878 0.0748 0.0698 0.0662 0.0660 0.0655 0.0658 0.0663 0.0667 0.0671 0.0676 0.0683 0.0692 0.0702 

[TRAIN] Epoch[6](1144/1500); Loss: 0.122199; Backpropagation: 0.0937 sec; Batch: 0.4663 sec
0.1615 0.1358 0.1340 0.1298 0.1225 0.1187 0.1168 0.1173 0.1165 0.1159 0.1152 0.1148 0.1144 0.1140 0.1139 0.1141 

[TRAIN] Epoch[6](1145/1500); Loss: 0.124610; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1987 0.2403 0.1953 0.1591 0.1333 0.1151 0.1023 0.0968 0.0951 0.0942 0.0939 0.0936 0.0935 0.0938 0.0942 0.0945 

[TRAIN] Epoch[6](1146/1500); Loss: 0.060919; Backpropagation: 0.0932 sec; Batch: 0.4637 sec
0.1078 0.0798 0.0737 0.0614 0.0594 0.0584 0.0554 0.0543 0.0535 0.0533 0.0529 0.0528 0.0529 0.0530 0.0530 0.0533 

[TRAIN] Epoch[6](1147/1500); Loss: 0.093900; Backpropagation: 0.0935 sec; Batch: 0.4307 sec
0.1550 0.1350 0.1291 0.1059 0.0991 0.0880 0.0828 0.0792 0.0797 0.0789 0.0788 0.0784 0.0780 0.0781 0.0781 0.0783 

[TRAIN] Epoch[6](1148/1500); Loss: 0.151200; Backpropagation: 0.0933 sec; Batch: 0.4310 sec
0.2451 0.2293 0.2144 0.1708 0.1552 0.1389 0.1321 0.1288 0.1272 0.1266 0.1259 0.1251 0.1249 0.1249 0.1250 0.1248 

[TRAIN] Epoch[6](1149/1500); Loss: 0.100814; Backpropagation: 0.0933 sec; Batch: 0.4333 sec
0.2354 0.1814 0.1695 0.0952 0.0840 0.0845 0.0771 0.0771 0.0765 0.0759 0.0760 0.0761 0.0758 0.0760 0.0762 0.0764 

[TRAIN] Epoch[6](1150/1500); Loss: 0.150633; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1789 0.1687 0.1644 0.1589 0.1556 0.1498 0.1482 0.1465 0.1450 0.1438 0.1428 0.1421 0.1416 0.1414 0.1412 0.1412 

[TRAIN] Epoch[6](1151/1500); Loss: 0.107865; Backpropagation: 0.0942 sec; Batch: 0.4287 sec
0.1663 0.1563 0.1346 0.1124 0.1059 0.1037 0.1014 0.0995 0.0974 0.0959 0.0944 0.0930 0.0921 0.0913 0.0908 0.0908 

[TRAIN] Epoch[6](1152/1500); Loss: 0.129632; Backpropagation: 0.0937 sec; Batch: 0.4637 sec
0.1933 0.1673 0.1633 0.1391 0.1303 0.1238 0.1210 0.1184 0.1163 0.1151 0.1144 0.1141 0.1143 0.1143 0.1145 0.1146 

[TRAIN] Epoch[6](1153/1500); Loss: 0.061759; Backpropagation: 0.0939 sec; Batch: 0.4661 sec
0.1369 0.0865 0.0865 0.0719 0.0653 0.0588 0.0536 0.0517 0.0499 0.0483 0.0473 0.0466 0.0464 0.0460 0.0460 0.0463 

[TRAIN] Epoch[6](1154/1500); Loss: 0.130702; Backpropagation: 0.0937 sec; Batch: 0.4698 sec
0.1870 0.1929 0.1719 0.1456 0.1344 0.1251 0.1198 0.1175 0.1153 0.1133 0.1122 0.1118 0.1116 0.1114 0.1109 0.1106 

[TRAIN] Epoch[6](1155/1500); Loss: 0.104188; Backpropagation: 0.0938 sec; Batch: 0.4679 sec
0.1696 0.2039 0.1632 0.1314 0.1098 0.0945 0.0858 0.0816 0.0801 0.0795 0.0790 0.0786 0.0779 0.0775 0.0772 0.0771 

[TRAIN] Epoch[6](1156/1500); Loss: 0.045408; Backpropagation: 0.0937 sec; Batch: 0.4741 sec
0.0823 0.0489 0.0453 0.0661 0.0424 0.0482 0.0435 0.0413 0.0394 0.0381 0.0377 0.0383 0.0385 0.0385 0.0389 0.0391 

[TRAIN] Epoch[6](1157/1500); Loss: 0.037526; Backpropagation: 0.0938 sec; Batch: 0.4654 sec
0.0789 0.0694 0.0514 0.0382 0.0359 0.0338 0.0317 0.0309 0.0303 0.0299 0.0292 0.0286 0.0283 0.0280 0.0281 0.0279 

[TRAIN] Epoch[6](1158/1500); Loss: 0.065856; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.1022 0.1250 0.0905 0.0710 0.0634 0.0591 0.0575 0.0561 0.0552 0.0542 0.0537 0.0532 0.0530 0.0530 0.0533 0.0533 

[TRAIN] Epoch[6](1159/1500); Loss: 0.148025; Backpropagation: 0.0938 sec; Batch: 0.4703 sec
0.1966 0.1996 0.1823 0.1672 0.1542 0.1437 0.1390 0.1355 0.1337 0.1324 0.1315 0.1309 0.1307 0.1305 0.1303 0.1302 

[TRAIN] Epoch[6](1160/1500); Loss: 0.059570; Backpropagation: 0.0937 sec; Batch: 0.4700 sec
0.1718 0.1178 0.1101 0.0506 0.0510 0.0516 0.0461 0.0433 0.0403 0.0381 0.0371 0.0373 0.0388 0.0391 0.0396 0.0405 

[TRAIN] Epoch[6](1161/1500); Loss: 0.146920; Backpropagation: 0.0940 sec; Batch: 0.4705 sec
0.3225 0.2768 0.2594 0.1791 0.1507 0.1145 0.1063 0.1086 0.1059 0.1041 0.1033 0.1030 0.1034 0.1039 0.1046 0.1046 

[TRAIN] Epoch[6](1162/1500); Loss: 0.104268; Backpropagation: 0.0937 sec; Batch: 0.4661 sec
0.1473 0.1653 0.1369 0.1165 0.1017 0.0942 0.0924 0.0915 0.0911 0.0908 0.0905 0.0902 0.0901 0.0900 0.0899 0.0898 

[TRAIN] Epoch[6](1163/1500); Loss: 0.080522; Backpropagation: 0.0938 sec; Batch: 0.4587 sec
0.1710 0.2395 0.1725 0.1147 0.0731 0.0547 0.0502 0.0487 0.0476 0.0466 0.0460 0.0453 0.0448 0.0445 0.0446 0.0447 

[TRAIN] Epoch[6](1164/1500); Loss: 0.143813; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.2173 0.2504 0.2068 0.1656 0.1422 0.1300 0.1257 0.1232 0.1205 0.1189 0.1176 0.1170 0.1166 0.1165 0.1164 0.1163 

[TRAIN] Epoch[6](1165/1500); Loss: 0.083526; Backpropagation: 0.0933 sec; Batch: 0.4692 sec
0.1759 0.1827 0.1495 0.1039 0.0795 0.0671 0.0632 0.0599 0.0588 0.0580 0.0570 0.0564 0.0561 0.0560 0.0562 0.0562 

[TRAIN] Epoch[6](1166/1500); Loss: 0.090076; Backpropagation: 0.0931 sec; Batch: 0.4693 sec
0.1315 0.1121 0.1059 0.0986 0.0919 0.0870 0.0851 0.0838 0.0830 0.0820 0.0813 0.0807 0.0804 0.0798 0.0792 0.0789 

[TRAIN] Epoch[6](1167/1500); Loss: 0.099379; Backpropagation: 0.0939 sec; Batch: 0.4720 sec
0.1529 0.1617 0.1366 0.1099 0.0982 0.0895 0.0871 0.0858 0.0855 0.0846 0.0840 0.0834 0.0830 0.0826 0.0825 0.0826 

[TRAIN] Epoch[6](1168/1500); Loss: 0.143684; Backpropagation: 0.0957 sec; Batch: 0.4749 sec
0.2172 0.2032 0.1913 0.1644 0.1491 0.1343 0.1286 0.1259 0.1248 0.1239 0.1234 0.1231 0.1226 0.1223 0.1224 0.1225 

[TRAIN] Epoch[6](1169/1500); Loss: 0.095843; Backpropagation: 0.0956 sec; Batch: 0.4709 sec
0.1271 0.1114 0.1047 0.0992 0.0953 0.0922 0.0912 0.0909 0.0905 0.0903 0.0900 0.0899 0.0900 0.0901 0.0903 0.0903 

[TRAIN] Epoch[6](1170/1500); Loss: 0.101137; Backpropagation: 0.0937 sec; Batch: 0.5236 sec
0.2341 0.2262 0.1998 0.1319 0.1076 0.0775 0.0675 0.0712 0.0657 0.0640 0.0631 0.0623 0.0624 0.0620 0.0615 0.0615 

[TRAIN] Epoch[6](1171/1500); Loss: 0.131370; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.1808 0.1673 0.1541 0.1387 0.1310 0.1239 0.1219 0.1209 0.1201 0.1198 0.1197 0.1197 0.1201 0.1209 0.1213 0.1216 

[TRAIN] Epoch[6](1172/1500); Loss: 0.084577; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.1162 0.0968 0.0942 0.0881 0.0844 0.0818 0.0804 0.0804 0.0797 0.0791 0.0788 0.0787 0.0786 0.0786 0.0786 0.0787 

[TRAIN] Epoch[6](1173/1500); Loss: 0.116451; Backpropagation: 0.0938 sec; Batch: 0.4577 sec
0.3574 0.2791 0.2696 0.1568 0.1256 0.0840 0.0672 0.0609 0.0601 0.0591 0.0578 0.0571 0.0572 0.0570 0.0569 0.0574 

[TRAIN] Epoch[6](1174/1500); Loss: 0.134294; Backpropagation: 0.0938 sec; Batch: 0.5213 sec
0.1821 0.1874 0.1700 0.1557 0.1426 0.1305 0.1230 0.1199 0.1188 0.1181 0.1175 0.1172 0.1169 0.1166 0.1163 0.1161 

[TRAIN] Epoch[6](1175/1500); Loss: 0.080593; Backpropagation: 0.0939 sec; Batch: 0.4685 sec
0.1865 0.1414 0.1381 0.1020 0.0912 0.0674 0.0579 0.0577 0.0562 0.0570 0.0565 0.0557 0.0555 0.0553 0.0555 0.0554 

[TRAIN] Epoch[6](1176/1500); Loss: 0.086286; Backpropagation: 0.0937 sec; Batch: 0.4697 sec
0.1336 0.1732 0.1243 0.0930 0.0825 0.0772 0.0743 0.0719 0.0706 0.0694 0.0692 0.0687 0.0682 0.0680 0.0681 0.0684 

[TRAIN] Epoch[6](1177/1500); Loss: 0.098862; Backpropagation: 0.0938 sec; Batch: 0.4672 sec
0.1728 0.1687 0.1447 0.1116 0.0965 0.0856 0.0823 0.0814 0.0801 0.0801 0.0795 0.0793 0.0791 0.0795 0.0801 0.0806 

[TRAIN] Epoch[6](1178/1500); Loss: 0.083570; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1253 0.1125 0.0995 0.0905 0.0840 0.0784 0.0775 0.0765 0.0753 0.0745 0.0741 0.0737 0.0734 0.0736 0.0739 0.0744 

[TRAIN] Epoch[6](1179/1500); Loss: 0.113707; Backpropagation: 0.0940 sec; Batch: 0.4304 sec
0.1987 0.1588 0.1528 0.1084 0.1025 0.1042 0.1016 0.1006 0.0997 0.0992 0.0989 0.0990 0.0989 0.0984 0.0985 0.0991 

[TRAIN] Epoch[6](1180/1500); Loss: 0.130945; Backpropagation: 0.0937 sec; Batch: 0.4659 sec
0.1856 0.2206 0.1783 0.1447 0.1312 0.1234 0.1184 0.1150 0.1123 0.1104 0.1095 0.1093 0.1090 0.1092 0.1091 0.1091 

[TRAIN] Epoch[6](1181/1500); Loss: 0.125326; Backpropagation: 0.0939 sec; Batch: 0.4709 sec
0.1772 0.1719 0.1470 0.1273 0.1225 0.1174 0.1162 0.1142 0.1148 0.1144 0.1141 0.1135 0.1136 0.1134 0.1136 0.1140 

[TRAIN] Epoch[6](1182/1500); Loss: 0.142455; Backpropagation: 0.0937 sec; Batch: 0.4653 sec
0.2226 0.1913 0.1862 0.1569 0.1506 0.1379 0.1313 0.1277 0.1258 0.1242 0.1231 0.1219 0.1210 0.1202 0.1195 0.1191 

[TRAIN] Epoch[6](1183/1500); Loss: 0.077566; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.1474 0.2210 0.1470 0.0928 0.0634 0.0562 0.0533 0.0519 0.0510 0.0509 0.0506 0.0505 0.0507 0.0514 0.0514 0.0515 

[TRAIN] Epoch[6](1184/1500); Loss: 0.131141; Backpropagation: 0.0938 sec; Batch: 0.4676 sec
0.1516 0.1674 0.1442 0.1356 0.1330 0.1293 0.1266 0.1246 0.1240 0.1234 0.1232 0.1232 0.1231 0.1229 0.1230 0.1230 

[TRAIN] Epoch[6](1185/1500); Loss: 0.151655; Backpropagation: 0.0939 sec; Batch: 0.4689 sec
0.1980 0.1955 0.1785 0.1622 0.1524 0.1460 0.1422 0.1407 0.1398 0.1395 0.1390 0.1386 0.1384 0.1385 0.1386 0.1386 

[TRAIN] Epoch[6](1186/1500); Loss: 0.134326; Backpropagation: 0.0937 sec; Batch: 0.4670 sec
0.1919 0.2141 0.1831 0.1585 0.1434 0.1274 0.1168 0.1132 0.1128 0.1128 0.1124 0.1122 0.1122 0.1123 0.1127 0.1133 

[TRAIN] Epoch[6](1187/1500); Loss: 0.071599; Backpropagation: 0.0942 sec; Batch: 0.4749 sec
0.1331 0.1582 0.1201 0.0943 0.0731 0.0580 0.0520 0.0511 0.0504 0.0505 0.0504 0.0504 0.0505 0.0509 0.0514 0.0514 

[TRAIN] Epoch[6](1188/1500); Loss: 0.052466; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.1482 0.0925 0.0950 0.0722 0.0572 0.0357 0.0380 0.0388 0.0359 0.0332 0.0316 0.0318 0.0324 0.0324 0.0323 0.0320 

[TRAIN] Epoch[6](1189/1500); Loss: 0.062669; Backpropagation: 0.0939 sec; Batch: 0.4674 sec
0.0929 0.0707 0.0683 0.0722 0.0648 0.0619 0.0599 0.0585 0.0574 0.0568 0.0564 0.0562 0.0562 0.0566 0.0568 0.0571 

[TRAIN] Epoch[6](1190/1500); Loss: 0.054781; Backpropagation: 0.0937 sec; Batch: 0.4702 sec
0.0704 0.1236 0.0706 0.0536 0.0506 0.0483 0.0477 0.0467 0.0460 0.0463 0.0458 0.0455 0.0454 0.0454 0.0452 0.0453 

[TRAIN] Epoch[6](1191/1500); Loss: 0.111070; Backpropagation: 0.0939 sec; Batch: 0.4712 sec
0.1711 0.1492 0.1341 0.1285 0.1088 0.1087 0.1025 0.1003 0.0987 0.0978 0.0970 0.0966 0.0962 0.0958 0.0957 0.0961 

[TRAIN] Epoch[6](1192/1500); Loss: 0.100283; Backpropagation: 0.0937 sec; Batch: 0.4661 sec
0.2359 0.2153 0.1942 0.1324 0.1062 0.0781 0.0699 0.0654 0.0657 0.0638 0.0632 0.0628 0.0626 0.0629 0.0629 0.0631 

[TRAIN] Epoch[6](1193/1500); Loss: 0.085769; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.2147 0.1648 0.1563 0.0944 0.0753 0.0742 0.0608 0.0608 0.0592 0.0590 0.0594 0.0592 0.0589 0.0586 0.0582 0.0584 

[TRAIN] Epoch[6](1194/1500); Loss: 0.143394; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.1823 0.1798 0.1687 0.1542 0.1504 0.1412 0.1382 0.1356 0.1332 0.1312 0.1303 0.1302 0.1302 0.1297 0.1294 0.1296 

[TRAIN] Epoch[6](1195/1500); Loss: 0.131655; Backpropagation: 0.0982 sec; Batch: 0.4750 sec
0.2181 0.2201 0.1953 0.1562 0.1358 0.1145 0.1088 0.1088 0.1067 0.1064 0.1059 0.1057 0.1059 0.1060 0.1061 0.1063 

[TRAIN] Epoch[6](1196/1500); Loss: 0.102592; Backpropagation: 0.0981 sec; Batch: 0.4738 sec
0.1563 0.1422 0.1231 0.1158 0.1041 0.0981 0.0936 0.0920 0.0905 0.0896 0.0891 0.0892 0.0893 0.0893 0.0896 0.0899 

[TRAIN] Epoch[6](1197/1500); Loss: 0.092120; Backpropagation: 0.0939 sec; Batch: 0.4554 sec
0.3280 0.2526 0.2400 0.1137 0.0788 0.0436 0.0498 0.0442 0.0410 0.0394 0.0406 0.0412 0.0403 0.0398 0.0404 0.0405 

[TRAIN] Epoch[6](1198/1500); Loss: 0.034640; Backpropagation: 0.0936 sec; Batch: 0.4786 sec
0.0840 0.0450 0.0434 0.0354 0.0317 0.0327 0.0293 0.0286 0.0281 0.0279 0.0280 0.0281 0.0281 0.0278 0.0279 0.0283 

[TRAIN] Epoch[6](1199/1500); Loss: 0.109152; Backpropagation: 0.0937 sec; Batch: 0.4675 sec
0.1475 0.1735 0.1337 0.1113 0.1079 0.1033 0.1010 0.0990 0.0980 0.0973 0.0966 0.0960 0.0958 0.0953 0.0951 0.0951 

[TRAIN] Epoch[6](1200/1500); Loss: 0.090395; Backpropagation: 0.0936 sec; Batch: 0.4698 sec
0.2087 0.2330 0.1880 0.1357 0.0895 0.0582 0.0559 0.0544 0.0532 0.0521 0.0521 0.0531 0.0528 0.0526 0.0533 0.0537 

[TRAIN] Epoch[6](1201/1500); Loss: 0.062983; Backpropagation: 0.0937 sec; Batch: 0.4591 sec
0.1127 0.0950 0.0832 0.0798 0.0632 0.0568 0.0536 0.0527 0.0520 0.0515 0.0511 0.0509 0.0508 0.0513 0.0516 0.0517 

[TRAIN] Epoch[6](1202/1500); Loss: 0.132775; Backpropagation: 0.0936 sec; Batch: 0.4704 sec
0.1763 0.1953 0.1676 0.1438 0.1337 0.1267 0.1226 0.1202 0.1183 0.1177 0.1174 0.1171 0.1169 0.1169 0.1168 0.1170 

[TRAIN] Epoch[6](1203/1500); Loss: 0.123212; Backpropagation: 0.0938 sec; Batch: 0.4672 sec
0.1631 0.2008 0.1591 0.1309 0.1175 0.1114 0.1099 0.1087 0.1086 0.1086 0.1086 0.1083 0.1083 0.1086 0.1092 0.1098 

[TRAIN] Epoch[6](1204/1500); Loss: 0.140162; Backpropagation: 0.0931 sec; Batch: 0.4654 sec
0.3206 0.2653 0.2562 0.1923 0.1661 0.1245 0.0998 0.0920 0.0911 0.0909 0.0902 0.0903 0.0904 0.0909 0.0909 0.0909 

[TRAIN] Epoch[6](1205/1500); Loss: 0.169565; Backpropagation: 0.0930 sec; Batch: 0.4669 sec
0.1840 0.1887 0.1781 0.1752 0.1696 0.1651 0.1646 0.1638 0.1642 0.1645 0.1646 0.1648 0.1653 0.1659 0.1669 0.1677 

[TRAIN] Epoch[6](1206/1500); Loss: 0.108213; Backpropagation: 0.0936 sec; Batch: 0.4665 sec
0.1539 0.1521 0.1373 0.1293 0.1154 0.1042 0.0986 0.0960 0.0949 0.0942 0.0933 0.0926 0.0926 0.0926 0.0924 0.0922 

[TRAIN] Epoch[6](1207/1500); Loss: 0.140941; Backpropagation: 0.0937 sec; Batch: 0.4711 sec
0.1977 0.1817 0.1676 0.1495 0.1416 0.1364 0.1338 0.1321 0.1303 0.1293 0.1280 0.1272 0.1261 0.1251 0.1245 0.1241 

[TRAIN] Epoch[6](1208/1500); Loss: 0.137427; Backpropagation: 0.0936 sec; Batch: 0.4658 sec
0.2071 0.1875 0.1782 0.1553 0.1455 0.1319 0.1255 0.1225 0.1213 0.1198 0.1186 0.1177 0.1175 0.1172 0.1168 0.1163 

[TRAIN] Epoch[6](1209/1500); Loss: 0.119317; Backpropagation: 0.0937 sec; Batch: 0.4745 sec
0.1563 0.1759 0.1483 0.1298 0.1165 0.1114 0.1099 0.1089 0.1080 0.1072 0.1065 0.1063 0.1061 0.1060 0.1059 0.1059 

[TRAIN] Epoch[6](1210/1500); Loss: 0.093879; Backpropagation: 0.0941 sec; Batch: 0.7317 sec
0.1307 0.1135 0.1062 0.0999 0.0957 0.0917 0.0905 0.0894 0.0881 0.0870 0.0861 0.0854 0.0848 0.0846 0.0844 0.0841 

[TRAIN] Epoch[6](1211/1500); Loss: 0.161903; Backpropagation: 0.0937 sec; Batch: 0.4669 sec
0.2266 0.2167 0.2036 0.1756 0.1649 0.1506 0.1464 0.1449 0.1444 0.1446 0.1452 0.1452 0.1451 0.1454 0.1456 0.1456 

[TRAIN] Epoch[6](1212/1500); Loss: 0.052720; Backpropagation: 0.0936 sec; Batch: 0.4620 sec
0.0843 0.1266 0.0809 0.0602 0.0529 0.0460 0.0420 0.0405 0.0399 0.0389 0.0384 0.0381 0.0383 0.0384 0.0389 0.0392 

[TRAIN] Epoch[6](1213/1500); Loss: 0.102251; Backpropagation: 0.0937 sec; Batch: 0.4710 sec
0.1365 0.1415 0.1186 0.1038 0.0997 0.0966 0.0956 0.0949 0.0940 0.0938 0.0937 0.0934 0.0935 0.0936 0.0935 0.0935 

[TRAIN] Epoch[6](1214/1500); Loss: 0.105526; Backpropagation: 0.0936 sec; Batch: 0.4385 sec
0.1459 0.1370 0.1264 0.1160 0.1082 0.1025 0.0995 0.0967 0.0954 0.0948 0.0945 0.0942 0.0941 0.0942 0.0944 0.0947 

[TRAIN] Epoch[6](1215/1500); Loss: 0.124055; Backpropagation: 0.0937 sec; Batch: 0.4673 sec
0.1872 0.1832 0.1635 0.1422 0.1289 0.1181 0.1124 0.1083 0.1070 0.1067 0.1056 0.1051 0.1047 0.1043 0.1039 0.1037 

[TRAIN] Epoch[6](1216/1500); Loss: 0.064876; Backpropagation: 0.0930 sec; Batch: 0.4655 sec
0.1224 0.0921 0.0863 0.0747 0.0668 0.0603 0.0564 0.0542 0.0534 0.0537 0.0530 0.0528 0.0528 0.0528 0.0531 0.0533 

[TRAIN] Epoch[6](1217/1500); Loss: 0.135216; Backpropagation: 0.0939 sec; Batch: 0.4370 sec
0.2443 0.2030 0.1958 0.1500 0.1366 0.1237 0.1169 0.1153 0.1121 0.1113 0.1106 0.1100 0.1092 0.1085 0.1082 0.1080 

[TRAIN] Epoch[6](1218/1500); Loss: 0.135786; Backpropagation: 0.0936 sec; Batch: 0.4690 sec
0.2060 0.2341 0.1922 0.1451 0.1322 0.1209 0.1166 0.1150 0.1142 0.1135 0.1131 0.1134 0.1135 0.1138 0.1142 0.1146 

[TRAIN] Epoch[6](1219/1500); Loss: 0.051535; Backpropagation: 0.0936 sec; Batch: 0.4669 sec
0.0575 0.0843 0.0561 0.0530 0.0507 0.0495 0.0482 0.0480 0.0478 0.0475 0.0469 0.0474 0.0473 0.0469 0.0464 0.0470 

[TRAIN] Epoch[6](1220/1500); Loss: 0.095033; Backpropagation: 0.0940 sec; Batch: 0.4379 sec
0.1612 0.1303 0.1217 0.1000 0.0917 0.0898 0.0872 0.0853 0.0841 0.0834 0.0823 0.0815 0.0809 0.0804 0.0804 0.0803 

[TRAIN] Epoch[6](1221/1500); Loss: 0.056200; Backpropagation: 0.0937 sec; Batch: 0.5519 sec
0.1191 0.0958 0.0828 0.0643 0.0582 0.0498 0.0473 0.0474 0.0450 0.0433 0.0420 0.0413 0.0409 0.0406 0.0407 0.0408 

[TRAIN] Epoch[6](1222/1500); Loss: 0.078133; Backpropagation: 0.0936 sec; Batch: 0.4700 sec
0.1462 0.1368 0.1158 0.0900 0.0755 0.0704 0.0634 0.0631 0.0625 0.0620 0.0617 0.0613 0.0606 0.0604 0.0604 0.0602 

[TRAIN] Epoch[6](1223/1500); Loss: 0.121442; Backpropagation: 0.0937 sec; Batch: 0.4742 sec
0.1718 0.1537 0.1395 0.1403 0.1211 0.1199 0.1149 0.1128 0.1108 0.1090 0.1086 0.1081 0.1080 0.1079 0.1082 0.1085 

[TRAIN] Epoch[6](1224/1500); Loss: 0.097113; Backpropagation: 0.0936 sec; Batch: 0.4667 sec
0.1336 0.1397 0.1176 0.1051 0.0939 0.0908 0.0886 0.0884 0.0881 0.0873 0.0871 0.0872 0.0869 0.0865 0.0864 0.0866 

[TRAIN] Epoch[6](1225/1500); Loss: 0.072171; Backpropagation: 0.0937 sec; Batch: 0.4659 sec
0.1666 0.1484 0.1295 0.0908 0.0782 0.0664 0.0555 0.0499 0.0479 0.0465 0.0460 0.0457 0.0457 0.0456 0.0457 0.0463 

[TRAIN] Epoch[6](1226/1500); Loss: 0.105966; Backpropagation: 0.0936 sec; Batch: 0.4708 sec
0.1839 0.1481 0.1374 0.1170 0.1076 0.0997 0.0955 0.0934 0.0924 0.0908 0.0896 0.0891 0.0888 0.0882 0.0873 0.0867 

[TRAIN] Epoch[6](1227/1500); Loss: 0.141160; Backpropagation: 0.0938 sec; Batch: 0.4716 sec
0.1682 0.1591 0.1547 0.1450 0.1418 0.1375 0.1359 0.1347 0.1342 0.1342 0.1343 0.1346 0.1352 0.1359 0.1364 0.1368 

[TRAIN] Epoch[6](1228/1500); Loss: 0.201685; Backpropagation: 0.0937 sec; Batch: 0.4664 sec
0.3440 0.2953 0.2855 0.2171 0.1955 0.1718 0.1713 0.1758 0.1729 0.1719 0.1716 0.1711 0.1705 0.1712 0.1709 0.1704 

[TRAIN] Epoch[6](1229/1500); Loss: 0.142760; Backpropagation: 0.0936 sec; Batch: 0.5081 sec
0.2024 0.2417 0.1962 0.1584 0.1385 0.1273 0.1245 0.1231 0.1226 0.1225 0.1217 0.1214 0.1212 0.1211 0.1209 0.1207 

[TRAIN] Epoch[6](1230/1500); Loss: 0.095582; Backpropagation: 0.0931 sec; Batch: 0.4678 sec
0.1200 0.1259 0.1065 0.1020 0.0950 0.0909 0.0897 0.0891 0.0888 0.0884 0.0886 0.0888 0.0887 0.0888 0.0890 0.0891 

[TRAIN] Epoch[6](1231/1500); Loss: 0.110999; Backpropagation: 0.0937 sec; Batch: 0.4669 sec
0.1643 0.1690 0.1464 0.1267 0.1132 0.1017 0.0991 0.0973 0.0959 0.0953 0.0950 0.0947 0.0945 0.0944 0.0944 0.0942 

[TRAIN] Epoch[6](1232/1500); Loss: 0.114478; Backpropagation: 0.0936 sec; Batch: 0.4715 sec
0.1623 0.1600 0.1415 0.1262 0.1133 0.1074 0.1047 0.1033 0.1026 0.1021 0.1017 0.1017 0.1014 0.1012 0.1011 0.1011 

[TRAIN] Epoch[6](1233/1500); Loss: 0.123471; Backpropagation: 0.0935 sec; Batch: 0.4523 sec
0.1720 0.1561 0.1429 0.1326 0.1220 0.1162 0.1133 0.1130 0.1118 0.1118 0.1122 0.1126 0.1134 0.1142 0.1152 0.1163 

[TRAIN] Epoch[6](1234/1500); Loss: 0.076160; Backpropagation: 0.0936 sec; Batch: 0.4678 sec
0.1683 0.2055 0.1514 0.0871 0.0668 0.0559 0.0513 0.0500 0.0502 0.0476 0.0475 0.0472 0.0471 0.0474 0.0476 0.0475 

[TRAIN] Epoch[6](1235/1500); Loss: 0.126238; Backpropagation: 0.0937 sec; Batch: 0.4704 sec
0.2026 0.2521 0.2013 0.1551 0.1156 0.1042 0.1011 0.0996 0.0987 0.0982 0.0979 0.0979 0.0980 0.0987 0.0993 0.0996 

[TRAIN] Epoch[6](1236/1500); Loss: 0.055019; Backpropagation: 0.0935 sec; Batch: 0.4659 sec
0.0711 0.1260 0.0717 0.0563 0.0503 0.0488 0.0472 0.0468 0.0463 0.0454 0.0448 0.0450 0.0451 0.0451 0.0452 0.0453 

[TRAIN] Epoch[6](1237/1500); Loss: 0.083148; Backpropagation: 0.0938 sec; Batch: 0.5204 sec
0.2601 0.2167 0.2022 0.1056 0.0772 0.0445 0.0599 0.0421 0.0411 0.0399 0.0401 0.0400 0.0402 0.0399 0.0399 0.0409 

[TRAIN] Epoch[6](1238/1500); Loss: 0.120604; Backpropagation: 0.0936 sec; Batch: 0.4693 sec
0.1458 0.1372 0.1308 0.1277 0.1204 0.1203 0.1163 0.1151 0.1136 0.1132 0.1138 0.1145 0.1148 0.1148 0.1155 0.1158 

[TRAIN] Epoch[6](1239/1500); Loss: 0.123770; Backpropagation: 0.0938 sec; Batch: 0.4711 sec
0.1570 0.1566 0.1446 0.1286 0.1241 0.1194 0.1173 0.1165 0.1157 0.1153 0.1149 0.1146 0.1143 0.1141 0.1139 0.1134 

[TRAIN] Epoch[6](1240/1500); Loss: 0.065348; Backpropagation: 0.0937 sec; Batch: 0.4662 sec
0.0973 0.0888 0.0732 0.0757 0.0605 0.0591 0.0568 0.0566 0.0573 0.0576 0.0580 0.0587 0.0597 0.0608 0.0620 0.0636 

[TRAIN] Epoch[6](1241/1500); Loss: 0.117947; Backpropagation: 0.0938 sec; Batch: 0.4702 sec
0.1223 0.1364 0.1202 0.1184 0.1185 0.1168 0.1152 0.1151 0.1152 0.1154 0.1153 0.1153 0.1154 0.1156 0.1159 0.1162 

[TRAIN] Epoch[6](1242/1500); Loss: 0.054268; Backpropagation: 0.0939 sec; Batch: 0.4285 sec
0.0931 0.0621 0.0591 0.0651 0.0543 0.0558 0.0523 0.0503 0.0485 0.0470 0.0465 0.0462 0.0465 0.0467 0.0472 0.0475 

[TRAIN] Epoch[6](1243/1500); Loss: 0.062231; Backpropagation: 0.0938 sec; Batch: 0.4827 sec
0.1088 0.0897 0.0783 0.0684 0.0625 0.0581 0.0557 0.0547 0.0537 0.0533 0.0527 0.0522 0.0518 0.0518 0.0520 0.0520 

[TRAIN] Epoch[6](1244/1500); Loss: 0.116312; Backpropagation: 0.0939 sec; Batch: 0.4692 sec
0.1783 0.1647 0.1536 0.1301 0.1212 0.1069 0.1030 0.1025 0.1014 0.1006 0.1004 0.1000 0.0997 0.0993 0.0996 0.0995 

[TRAIN] Epoch[6](1245/1500); Loss: 0.128607; Backpropagation: 0.0932 sec; Batch: 0.4652 sec
0.1525 0.1500 0.1373 0.1279 0.1248 0.1233 0.1233 0.1234 0.1235 0.1237 0.1238 0.1241 0.1243 0.1247 0.1253 0.1258 

[TRAIN] Epoch[6](1246/1500); Loss: 0.078453; Backpropagation: 0.0940 sec; Batch: 0.4430 sec
0.1159 0.1112 0.0935 0.0854 0.0787 0.0743 0.0724 0.0712 0.0703 0.0696 0.0690 0.0686 0.0689 0.0690 0.0688 0.0685 

[TRAIN] Epoch[6](1247/1500); Loss: 0.076832; Backpropagation: 0.0936 sec; Batch: 0.4717 sec
0.2472 0.1826 0.1699 0.0656 0.0514 0.0628 0.0460 0.0456 0.0451 0.0448 0.0447 0.0444 0.0447 0.0450 0.0449 0.0448 

[TRAIN] Epoch[6](1248/1500); Loss: 0.120994; Backpropagation: 0.0931 sec; Batch: 0.4869 sec
0.2737 0.2194 0.2071 0.1263 0.1067 0.1001 0.0962 0.0936 0.0907 0.0887 0.0890 0.0887 0.0885 0.0889 0.0892 0.0891 

[TRAIN] Epoch[6](1249/1500); Loss: 0.076026; Backpropagation: 0.0936 sec; Batch: 0.4662 sec
0.1066 0.1075 0.0932 0.0828 0.0760 0.0730 0.0710 0.0694 0.0684 0.0676 0.0673 0.0669 0.0668 0.0666 0.0667 0.0667 

[TRAIN] Epoch[6](1250/1500); Loss: 0.073048; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1267 0.1154 0.0877 0.0958 0.0753 0.0661 0.0610 0.0601 0.0599 0.0601 0.0597 0.0598 0.0600 0.0603 0.0604 0.0605 

[TRAIN] Epoch[6](1251/1500); Loss: 0.145404; Backpropagation: 0.0931 sec; Batch: 0.4676 sec
0.2319 0.2403 0.2092 0.1639 0.1482 0.1304 0.1245 0.1220 0.1205 0.1200 0.1198 0.1194 0.1190 0.1189 0.1193 0.1193 

[TRAIN] Epoch[6](1252/1500); Loss: 0.072798; Backpropagation: 0.0931 sec; Batch: 0.4669 sec
0.1778 0.1272 0.1187 0.0658 0.0652 0.0596 0.0560 0.0554 0.0551 0.0548 0.0549 0.0548 0.0548 0.0549 0.0549 0.0550 

[TRAIN] Epoch[6](1253/1500); Loss: 0.125536; Backpropagation: 0.0937 sec; Batch: 0.4916 sec
0.2850 0.2342 0.2238 0.1541 0.1298 0.1027 0.0932 0.0876 0.0899 0.0861 0.0868 0.0867 0.0866 0.0868 0.0874 0.0877 

[TRAIN] Epoch[6](1254/1500); Loss: 0.102097; Backpropagation: 0.0936 sec; Batch: 0.4658 sec
0.1752 0.1576 0.1426 0.1157 0.1036 0.0906 0.0870 0.0864 0.0857 0.0850 0.0846 0.0842 0.0841 0.0840 0.0838 0.0836 

[TRAIN] Epoch[6](1255/1500); Loss: 0.064997; Backpropagation: 0.0932 sec; Batch: 0.4552 sec
0.0907 0.0858 0.0718 0.0635 0.0625 0.0634 0.0621 0.0610 0.0604 0.0599 0.0595 0.0597 0.0597 0.0598 0.0598 0.0602 

[TRAIN] Epoch[6](1256/1500); Loss: 0.104844; Backpropagation: 0.0930 sec; Batch: 0.5262 sec
0.1852 0.1477 0.1354 0.1069 0.0989 0.0973 0.0935 0.0926 0.0913 0.0903 0.0899 0.0897 0.0896 0.0898 0.0897 0.0899 

[TRAIN] Epoch[6](1257/1500); Loss: 0.079934; Backpropagation: 0.0937 sec; Batch: 0.4632 sec
0.1484 0.1303 0.1179 0.0925 0.0773 0.0664 0.0680 0.0656 0.0652 0.0645 0.0641 0.0637 0.0635 0.0637 0.0640 0.0640 

[TRAIN] Epoch[6](1258/1500); Loss: 0.136597; Backpropagation: 0.0936 sec; Batch: 0.4708 sec
0.2091 0.2159 0.1906 0.1515 0.1318 0.1189 0.1171 0.1176 0.1165 0.1164 0.1166 0.1165 0.1166 0.1167 0.1169 0.1170 

[TRAIN] Epoch[6](1259/1500); Loss: 0.069813; Backpropagation: 0.0936 sec; Batch: 0.4666 sec
0.1110 0.0919 0.0845 0.0756 0.0704 0.0656 0.0633 0.0625 0.0621 0.0617 0.0614 0.0613 0.0613 0.0614 0.0615 0.0616 

[TRAIN] Epoch[6](1260/1500); Loss: 0.121698; Backpropagation: 0.0940 sec; Batch: 0.4708 sec
0.1927 0.1670 0.1573 0.1352 0.1223 0.1127 0.1094 0.1077 0.1069 0.1062 0.1058 0.1053 0.1050 0.1047 0.1047 0.1045 

[TRAIN] Epoch[6](1261/1500); Loss: 0.088855; Backpropagation: 0.0940 sec; Batch: 0.4667 sec
0.1068 0.1156 0.0962 0.0892 0.0853 0.0844 0.0837 0.0833 0.0830 0.0830 0.0833 0.0841 0.0847 0.0853 0.0863 0.0875 

[TRAIN] Epoch[6](1262/1500); Loss: 0.060675; Backpropagation: 0.0936 sec; Batch: 0.4699 sec
0.1066 0.1133 0.0831 0.0630 0.0593 0.0563 0.0521 0.0510 0.0502 0.0491 0.0486 0.0484 0.0480 0.0475 0.0472 0.0471 

[TRAIN] Epoch[6](1263/1500); Loss: 0.114898; Backpropagation: 0.0936 sec; Batch: 0.4702 sec
0.1672 0.1600 0.1463 0.1227 0.1164 0.1087 0.1059 0.1041 0.1028 0.1022 0.1016 0.1007 0.1002 0.0999 0.0998 0.0999 

[TRAIN] Epoch[6](1264/1500); Loss: 0.133501; Backpropagation: 0.0936 sec; Batch: 0.4584 sec
0.1695 0.1571 0.1508 0.1432 0.1392 0.1321 0.1296 0.1273 0.1256 0.1243 0.1236 0.1229 0.1227 0.1227 0.1226 0.1227 

[TRAIN] Epoch[6](1265/1500); Loss: 0.089453; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1219 0.1026 0.0951 0.1229 0.0971 0.0849 0.0819 0.0809 0.0803 0.0801 0.0799 0.0801 0.0806 0.0808 0.0810 0.0812 

[TRAIN] Epoch[6](1266/1500); Loss: 0.097743; Backpropagation: 0.0936 sec; Batch: 0.4541 sec
0.1164 0.1095 0.1012 0.0987 0.0969 0.0954 0.0945 0.0941 0.0941 0.0941 0.0942 0.0944 0.0947 0.0949 0.0952 0.0955 

[TRAIN] Epoch[6](1267/1500); Loss: 0.098730; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.1253 0.1468 0.1159 0.1024 0.0929 0.0889 0.0870 0.0878 0.0881 0.0885 0.0893 0.0905 0.0917 0.0934 0.0948 0.0962 

[TRAIN] Epoch[6](1268/1500); Loss: 0.092415; Backpropagation: 0.0934 sec; Batch: 0.4693 sec
0.1232 0.1186 0.1031 0.0941 0.0896 0.0877 0.0867 0.0861 0.0859 0.0858 0.0855 0.0855 0.0858 0.0863 0.0869 0.0879 

[TRAIN] Epoch[6](1269/1500); Loss: 0.116659; Backpropagation: 0.0938 sec; Batch: 0.4293 sec
0.1421 0.1404 0.1257 0.1195 0.1173 0.1128 0.1112 0.1108 0.1108 0.1107 0.1108 0.1108 0.1109 0.1110 0.1109 0.1108 

[TRAIN] Epoch[6](1270/1500); Loss: 0.060900; Backpropagation: 0.0935 sec; Batch: 0.4687 sec
0.0995 0.0963 0.0765 0.0691 0.0609 0.0545 0.0537 0.0536 0.0525 0.0519 0.0517 0.0514 0.0509 0.0506 0.0506 0.0505 

[TRAIN] Epoch[6](1271/1500); Loss: 0.094573; Backpropagation: 0.0934 sec; Batch: 0.4283 sec
0.2330 0.3245 0.2365 0.1452 0.0639 0.0594 0.0500 0.0451 0.0433 0.0436 0.0432 0.0436 0.0439 0.0450 0.0458 0.0472 

[TRAIN] Epoch[6](1272/1500); Loss: 0.126683; Backpropagation: 0.0934 sec; Batch: 0.4668 sec
0.1779 0.1628 0.1490 0.1365 0.1269 0.1218 0.1180 0.1162 0.1146 0.1140 0.1139 0.1140 0.1143 0.1149 0.1158 0.1162 

[TRAIN] Epoch[6](1273/1500); Loss: 0.100199; Backpropagation: 0.0935 sec; Batch: 0.4266 sec
0.1229 0.1247 0.1094 0.1077 0.1015 0.0971 0.0954 0.0945 0.0941 0.0939 0.0937 0.0940 0.0937 0.0935 0.0934 0.0938 

[TRAIN] Epoch[6](1274/1500); Loss: 0.144421; Backpropagation: 0.0933 sec; Batch: 0.4664 sec
0.2283 0.2080 0.1947 0.1674 0.1532 0.1348 0.1268 0.1245 0.1236 0.1226 0.1219 0.1215 0.1210 0.1210 0.1208 0.1207 

[TRAIN] Epoch[6](1275/1500); Loss: 0.053331; Backpropagation: 0.0939 sec; Batch: 0.4663 sec
0.0904 0.1773 0.0896 0.0561 0.0453 0.0403 0.0391 0.0371 0.0359 0.0347 0.0343 0.0341 0.0342 0.0346 0.0348 0.0354 

[TRAIN] Epoch[6](1276/1500); Loss: 0.123891; Backpropagation: 0.0938 sec; Batch: 0.4708 sec
0.1666 0.1984 0.1587 0.1315 0.1196 0.1138 0.1117 0.1110 0.1102 0.1095 0.1091 0.1086 0.1084 0.1084 0.1083 0.1084 

[TRAIN] Epoch[6](1277/1500); Loss: 0.047823; Backpropagation: 0.0939 sec; Batch: 0.5108 sec
0.0632 0.0601 0.0478 0.0461 0.0453 0.0460 0.0448 0.0447 0.0448 0.0451 0.0451 0.0455 0.0460 0.0466 0.0468 0.0473 

[TRAIN] Epoch[6](1278/1500); Loss: 0.084503; Backpropagation: 0.0956 sec; Batch: 0.4690 sec
0.2275 0.3217 0.2285 0.1361 0.0512 0.0532 0.0437 0.0375 0.0355 0.0328 0.0318 0.0304 0.0298 0.0299 0.0305 0.0320 

[TRAIN] Epoch[6](1279/1500); Loss: 0.106953; Backpropagation: 0.0939 sec; Batch: 0.4683 sec
0.1763 0.1728 0.1552 0.1366 0.1201 0.1055 0.0947 0.0859 0.0833 0.0829 0.0827 0.0826 0.0829 0.0831 0.0833 0.0835 

[TRAIN] Epoch[6](1280/1500); Loss: 0.067444; Backpropagation: 0.0945 sec; Batch: 0.4669 sec
0.1051 0.1058 0.0849 0.0736 0.0691 0.0641 0.0610 0.0597 0.0584 0.0575 0.0573 0.0569 0.0565 0.0565 0.0563 0.0563 

[TRAIN] Epoch[6](1281/1500); Loss: 0.115852; Backpropagation: 0.0939 sec; Batch: 0.4660 sec
0.2156 0.2014 0.1789 0.1367 0.1159 0.0982 0.0935 0.0924 0.0900 0.0909 0.0906 0.0901 0.0897 0.0901 0.0899 0.0897 

[TRAIN] Epoch[6](1282/1500); Loss: 0.107665; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.2939 0.2412 0.2161 0.1116 0.0899 0.0763 0.0711 0.0707 0.0700 0.0692 0.0691 0.0689 0.0684 0.0682 0.0689 0.0693 

[TRAIN] Epoch[6](1283/1500); Loss: 0.069331; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1236 0.0852 0.0849 0.0750 0.0697 0.0659 0.0616 0.0609 0.0606 0.0602 0.0600 0.0599 0.0601 0.0604 0.0606 0.0608 

[TRAIN] Epoch[6](1284/1500); Loss: 0.093656; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1972 0.1980 0.1601 0.0943 0.0815 0.0742 0.0694 0.0685 0.0682 0.0683 0.0684 0.0686 0.0691 0.0701 0.0710 0.0715 

[TRAIN] Epoch[6](1285/1500); Loss: 0.088196; Backpropagation: 0.0933 sec; Batch: 0.4642 sec
0.1715 0.1712 0.1373 0.0871 0.0771 0.0723 0.0718 0.0708 0.0699 0.0691 0.0689 0.0688 0.0687 0.0688 0.0689 0.0691 

[TRAIN] Epoch[6](1286/1500); Loss: 0.098632; Backpropagation: 0.0933 sec; Batch: 0.4304 sec
0.1746 0.1577 0.1382 0.1058 0.1003 0.0948 0.0860 0.0839 0.0821 0.0806 0.0792 0.0786 0.0783 0.0786 0.0791 0.0804 

[TRAIN] Epoch[6](1287/1500); Loss: 0.107080; Backpropagation: 0.0939 sec; Batch: 0.4728 sec
0.1343 0.1314 0.1205 0.1147 0.1093 0.1032 0.1014 0.1009 0.1007 0.1001 0.0998 0.0995 0.0995 0.0993 0.0993 0.0993 

[TRAIN] Epoch[6](1288/1500); Loss: 0.142047; Backpropagation: 0.0932 sec; Batch: 0.4360 sec
0.1714 0.1752 0.1582 0.1486 0.1428 0.1372 0.1355 0.1350 0.1347 0.1340 0.1337 0.1336 0.1334 0.1331 0.1331 0.1331 

[TRAIN] Epoch[6](1289/1500); Loss: 0.092327; Backpropagation: 0.0934 sec; Batch: 0.4758 sec
0.1228 0.1127 0.1047 0.1034 0.0979 0.0884 0.0864 0.0851 0.0844 0.0840 0.0839 0.0840 0.0842 0.0844 0.0850 0.0857 

[TRAIN] Epoch[6](1290/1500); Loss: 0.096564; Backpropagation: 0.0932 sec; Batch: 0.4895 sec
0.1312 0.1397 0.1177 0.1039 0.0966 0.0907 0.0886 0.0877 0.0874 0.0866 0.0861 0.0859 0.0858 0.0857 0.0856 0.0856 

[TRAIN] Epoch[6](1291/1500); Loss: 0.065144; Backpropagation: 0.0947 sec; Batch: 0.4288 sec
0.1069 0.1020 0.0805 0.0704 0.0623 0.0598 0.0579 0.0565 0.0556 0.0551 0.0550 0.0552 0.0555 0.0558 0.0566 0.0572 

[TRAIN] Epoch[6](1292/1500); Loss: 0.161535; Backpropagation: 0.0932 sec; Batch: 0.4690 sec
0.2482 0.2248 0.2163 0.1815 0.1682 0.1541 0.1489 0.1403 0.1385 0.1378 0.1374 0.1376 0.1378 0.1378 0.1378 0.1377 

[TRAIN] Epoch[6](1293/1500); Loss: 0.058229; Backpropagation: 0.0938 sec; Batch: 0.4600 sec
0.0757 0.1276 0.0723 0.0578 0.0526 0.0509 0.0503 0.0496 0.0496 0.0493 0.0493 0.0492 0.0492 0.0493 0.0495 0.0495 

[TRAIN] Epoch[6](1294/1500); Loss: 0.129421; Backpropagation: 0.0939 sec; Batch: 0.4714 sec
0.2237 0.1889 0.1783 0.1358 0.1237 0.1145 0.1121 0.1109 0.1099 0.1100 0.1101 0.1102 0.1102 0.1103 0.1107 0.1114 

[TRAIN] Epoch[6](1295/1500); Loss: 0.040215; Backpropagation: 0.0938 sec; Batch: 0.5105 sec
0.0616 0.0684 0.0472 0.0425 0.0396 0.0384 0.0367 0.0353 0.0348 0.0342 0.0339 0.0338 0.0339 0.0341 0.0343 0.0347 

[TRAIN] Epoch[6](1296/1500); Loss: 0.136313; Backpropagation: 0.0938 sec; Batch: 0.4779 sec
0.1576 0.1594 0.1459 0.1409 0.1375 0.1339 0.1321 0.1310 0.1306 0.1304 0.1303 0.1302 0.1303 0.1303 0.1303 0.1303 

[TRAIN] Epoch[6](1297/1500); Loss: 0.076743; Backpropagation: 0.0939 sec; Batch: 0.4709 sec
0.1363 0.1122 0.1007 0.0904 0.0780 0.0716 0.0682 0.0677 0.0662 0.0647 0.0637 0.0627 0.0619 0.0613 0.0610 0.0611 

[TRAIN] Epoch[6](1298/1500); Loss: 0.102327; Backpropagation: 0.0937 sec; Batch: 0.4661 sec
0.2187 0.1779 0.1688 0.1259 0.1091 0.0926 0.0874 0.0786 0.0752 0.0730 0.0720 0.0718 0.0716 0.0714 0.0716 0.0718 

[TRAIN] Epoch[6](1299/1500); Loss: 0.095005; Backpropagation: 0.0938 sec; Batch: 0.4701 sec
0.1519 0.1469 0.1235 0.0942 0.0895 0.0854 0.0841 0.0838 0.0832 0.0828 0.0827 0.0826 0.0823 0.0823 0.0824 0.0826 

[TRAIN] Epoch[6](1300/1500); Loss: 0.111115; Backpropagation: 0.0948 sec; Batch: 0.4296 sec
0.2287 0.2320 0.1986 0.1524 0.1185 0.0893 0.0798 0.0780 0.0761 0.0756 0.0752 0.0750 0.0748 0.0746 0.0746 0.0747 

[TRAIN] Epoch[6](1301/1500); Loss: 0.097463; Backpropagation: 0.0982 sec; Batch: 0.4637 sec
0.1579 0.1593 0.1278 0.0927 0.0889 0.0870 0.0863 0.0852 0.0844 0.0844 0.0843 0.0842 0.0841 0.0842 0.0843 0.0846 

[TRAIN] Epoch[6](1302/1500); Loss: 0.133747; Backpropagation: 0.0956 sec; Batch: 0.4711 sec
0.2255 0.1956 0.1848 0.1517 0.1350 0.1209 0.1165 0.1133 0.1135 0.1127 0.1122 0.1119 0.1117 0.1115 0.1115 0.1116 

[TRAIN] Epoch[6](1303/1500); Loss: 0.101239; Backpropagation: 0.0939 sec; Batch: 0.4701 sec
0.1226 0.1526 0.1156 0.1057 0.0994 0.0959 0.0946 0.0940 0.0934 0.0930 0.0926 0.0923 0.0922 0.0919 0.0919 0.0920 

[TRAIN] Epoch[6](1304/1500); Loss: 0.197690; Backpropagation: 0.0938 sec; Batch: 0.4660 sec
0.3701 0.3138 0.3051 0.2264 0.2000 0.1706 0.1661 0.1606 0.1617 0.1578 0.1565 0.1554 0.1552 0.1546 0.1545 0.1546 

[TRAIN] Epoch[6](1305/1500); Loss: 0.093956; Backpropagation: 0.0938 sec; Batch: 0.4699 sec
0.1445 0.1252 0.1171 0.0916 0.0879 0.0891 0.0851 0.0847 0.0846 0.0842 0.0846 0.0847 0.0847 0.0848 0.0850 0.0854 

[TRAIN] Epoch[6](1306/1500); Loss: 0.120077; Backpropagation: 0.0955 sec; Batch: 0.4683 sec
0.1863 0.1594 0.1528 0.1269 0.1222 0.1134 0.1108 0.1082 0.1067 0.1060 0.1057 0.1051 0.1046 0.1044 0.1044 0.1043 

[TRAIN] Epoch[6](1307/1500); Loss: 0.067996; Backpropagation: 0.0941 sec; Batch: 0.4377 sec
0.0732 0.1135 0.0685 0.0656 0.0651 0.0640 0.0634 0.0633 0.0632 0.0632 0.0635 0.0635 0.0637 0.0643 0.0648 0.0650 

[TRAIN] Epoch[6](1308/1500); Loss: 0.065949; Backpropagation: 0.0933 sec; Batch: 0.4615 sec
0.1165 0.1035 0.0894 0.0791 0.0620 0.0568 0.0566 0.0560 0.0550 0.0547 0.0547 0.0543 0.0538 0.0538 0.0544 0.0546 

[TRAIN] Epoch[6](1309/1500); Loss: 0.128548; Backpropagation: 0.0938 sec; Batch: 0.4710 sec
0.1698 0.1705 0.1520 0.1358 0.1275 0.1225 0.1197 0.1186 0.1180 0.1175 0.1174 0.1172 0.1173 0.1175 0.1175 0.1179 

[TRAIN] Epoch[6](1310/1500); Loss: 0.137687; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.2184 0.2015 0.1880 0.1549 0.1380 0.1263 0.1236 0.1185 0.1173 0.1163 0.1162 0.1165 0.1165 0.1167 0.1170 0.1173 

[TRAIN] Epoch[6](1311/1500); Loss: 0.110474; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.1567 0.1667 0.1374 0.1199 0.1094 0.1033 0.1011 0.0997 0.0984 0.0974 0.0969 0.0965 0.0961 0.0960 0.0961 0.0961 

[TRAIN] Epoch[6](1312/1500); Loss: 0.067175; Backpropagation: 0.0937 sec; Batch: 0.4701 sec
0.1294 0.0894 0.0868 0.0815 0.0683 0.0622 0.0603 0.0585 0.0570 0.0556 0.0548 0.0542 0.0543 0.0542 0.0541 0.0543 

[TRAIN] Epoch[6](1313/1500); Loss: 0.129999; Backpropagation: 0.0941 sec; Batch: 0.4286 sec
0.1990 0.2247 0.1869 0.1538 0.1300 0.1153 0.1101 0.1087 0.1079 0.1075 0.1069 0.1064 0.1061 0.1058 0.1055 0.1054 

[TRAIN] Epoch[6](1314/1500); Loss: 0.081357; Backpropagation: 0.0932 sec; Batch: 0.5379 sec
0.1248 0.1149 0.1039 0.0892 0.0816 0.0757 0.0736 0.0719 0.0713 0.0709 0.0708 0.0707 0.0706 0.0705 0.0706 0.0707 

[TRAIN] Epoch[6](1315/1500); Loss: 0.111559; Backpropagation: 0.0934 sec; Batch: 0.4300 sec
0.2769 0.2368 0.2167 0.1287 0.1021 0.0840 0.0779 0.0779 0.0733 0.0740 0.0734 0.0730 0.0725 0.0724 0.0726 0.0728 

[TRAIN] Epoch[6](1316/1500); Loss: 0.098546; Backpropagation: 0.0954 sec; Batch: 0.4299 sec
0.2358 0.2125 0.1838 0.1125 0.0914 0.0751 0.0709 0.0677 0.0659 0.0656 0.0662 0.0660 0.0658 0.0658 0.0658 0.0658 

[TRAIN] Epoch[6](1317/1500); Loss: 0.095262; Backpropagation: 0.0939 sec; Batch: 0.4751 sec
0.1701 0.1851 0.1506 0.1070 0.0904 0.0818 0.0782 0.0751 0.0743 0.0737 0.0733 0.0731 0.0731 0.0728 0.0728 0.0731 

[TRAIN] Epoch[6](1318/1500); Loss: 0.071816; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.1251 0.0945 0.0869 0.0648 0.0631 0.0707 0.0681 0.0665 0.0645 0.0632 0.0626 0.0624 0.0627 0.0637 0.0647 0.0658 

[TRAIN] Epoch[6](1319/1500); Loss: 0.179269; Backpropagation: 0.0937 sec; Batch: 0.4702 sec
0.2822 0.2666 0.2532 0.2116 0.2001 0.1837 0.1763 0.1663 0.1593 0.1516 0.1461 0.1393 0.1356 0.1329 0.1320 0.1316 

[TRAIN] Epoch[6](1320/1500); Loss: 0.075794; Backpropagation: 0.0938 sec; Batch: 0.4714 sec
0.1129 0.1066 0.0937 0.0809 0.0738 0.0714 0.0700 0.0688 0.0681 0.0674 0.0668 0.0665 0.0664 0.0662 0.0664 0.0666 

[TRAIN] Epoch[6](1321/1500); Loss: 0.062111; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.0911 0.0937 0.0721 0.0635 0.0612 0.0595 0.0579 0.0570 0.0565 0.0556 0.0548 0.0545 0.0543 0.0542 0.0539 0.0540 

[TRAIN] Epoch[6](1322/1500); Loss: 0.059443; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.0825 0.0876 0.0701 0.0651 0.0597 0.0574 0.0559 0.0546 0.0536 0.0531 0.0525 0.0521 0.0519 0.0516 0.0517 0.0517 

[TRAIN] Epoch[6](1323/1500); Loss: 0.156451; Backpropagation: 0.0958 sec; Batch: 0.4695 sec
0.2115 0.2143 0.1920 0.1691 0.1557 0.1473 0.1463 0.1447 0.1434 0.1421 0.1414 0.1404 0.1395 0.1388 0.1383 0.1382 

[TRAIN] Epoch[6](1324/1500); Loss: 0.080296; Backpropagation: 0.0937 sec; Batch: 0.5357 sec
0.1222 0.1129 0.0981 0.0840 0.0805 0.0761 0.0738 0.0723 0.0717 0.0716 0.0711 0.0705 0.0703 0.0700 0.0698 0.0698 

[TRAIN] Epoch[6](1325/1500); Loss: 0.101419; Backpropagation: 0.0939 sec; Batch: 0.4701 sec
0.1408 0.1749 0.1247 0.0996 0.0942 0.0926 0.0920 0.0908 0.0902 0.0898 0.0894 0.0891 0.0891 0.0889 0.0884 0.0883 

[TRAIN] Epoch[6](1326/1500); Loss: 0.108666; Backpropagation: 0.0939 sec; Batch: 0.4276 sec
0.1658 0.1467 0.1342 0.1170 0.1112 0.1035 0.1007 0.0984 0.0974 0.0967 0.0957 0.0951 0.0947 0.0943 0.0938 0.0936 

[TRAIN] Epoch[6](1327/1500); Loss: 0.139748; Backpropagation: 0.0939 sec; Batch: 0.4660 sec
0.1823 0.1937 0.1678 0.1449 0.1405 0.1359 0.1341 0.1311 0.1294 0.1279 0.1269 0.1258 0.1250 0.1243 0.1235 0.1229 

[TRAIN] Epoch[6](1328/1500); Loss: 0.109399; Backpropagation: 0.0936 sec; Batch: 0.4284 sec
0.2366 0.2118 0.1948 0.1345 0.1177 0.0997 0.0898 0.0822 0.0769 0.0740 0.0731 0.0725 0.0721 0.0718 0.0715 0.0714 

[TRAIN] Epoch[6](1329/1500); Loss: 0.095077; Backpropagation: 0.0938 sec; Batch: 0.5286 sec
0.1649 0.1615 0.1379 0.1047 0.0939 0.0865 0.0820 0.0791 0.0779 0.0772 0.0766 0.0762 0.0758 0.0756 0.0757 0.0758 

[TRAIN] Epoch[6](1330/1500); Loss: 0.102962; Backpropagation: 0.0937 sec; Batch: 0.4666 sec
0.1674 0.1646 0.1451 0.1193 0.1068 0.0955 0.0892 0.0867 0.0857 0.0848 0.0844 0.0841 0.0836 0.0834 0.0834 0.0833 

[TRAIN] Epoch[6](1331/1500); Loss: 0.073664; Backpropagation: 0.0938 sec; Batch: 0.4826 sec
0.1133 0.1205 0.0916 0.0757 0.0727 0.0684 0.0675 0.0659 0.0650 0.0643 0.0635 0.0627 0.0622 0.0620 0.0618 0.0615 

[TRAIN] Epoch[6](1332/1500); Loss: 0.092416; Backpropagation: 0.0938 sec; Batch: 0.4654 sec
0.1611 0.1208 0.1202 0.1000 0.0951 0.0889 0.0861 0.0852 0.0824 0.0799 0.0784 0.0771 0.0766 0.0762 0.0756 0.0753 

[TRAIN] Epoch[6](1333/1500); Loss: 0.106884; Backpropagation: 0.0939 sec; Batch: 0.4676 sec
0.1995 0.1786 0.1633 0.1288 0.1063 0.0938 0.0910 0.0882 0.0860 0.0846 0.0838 0.0828 0.0819 0.0812 0.0804 0.0800 

[TRAIN] Epoch[6](1334/1500); Loss: 0.106869; Backpropagation: 0.0957 sec; Batch: 0.4721 sec
0.1676 0.2193 0.1535 0.1130 0.0962 0.0906 0.0884 0.0875 0.0873 0.0874 0.0871 0.0867 0.0864 0.0863 0.0862 0.0864 

[TRAIN] Epoch[6](1335/1500); Loss: 0.075577; Backpropagation: 0.0957 sec; Batch: 0.4714 sec
0.1303 0.1006 0.0943 0.0792 0.0747 0.0704 0.0692 0.0678 0.0672 0.0659 0.0654 0.0649 0.0648 0.0648 0.0648 0.0650 

[TRAIN] Epoch[6](1336/1500); Loss: 0.118329; Backpropagation: 0.0938 sec; Batch: 0.4961 sec
0.1686 0.1564 0.1463 0.1259 0.1221 0.1159 0.1126 0.1090 0.1076 0.1063 0.1052 0.1042 0.1038 0.1034 0.1031 0.1029 

[TRAIN] Epoch[6](1337/1500); Loss: 0.092626; Backpropagation: 0.0939 sec; Batch: 0.4670 sec
0.2238 0.3136 0.2157 0.1277 0.0439 0.0615 0.0645 0.0590 0.0562 0.0530 0.0504 0.0469 0.0437 0.0419 0.0405 0.0396 

[TRAIN] Epoch[6](1338/1500); Loss: 0.058192; Backpropagation: 0.0937 sec; Batch: 0.4664 sec
0.0951 0.1293 0.0764 0.0562 0.0515 0.0505 0.0498 0.0489 0.0479 0.0473 0.0470 0.0467 0.0464 0.0462 0.0460 0.0459 

[TRAIN] Epoch[6](1339/1500); Loss: 0.142986; Backpropagation: 0.0958 sec; Batch: 0.4733 sec
0.1803 0.1806 0.1646 0.1519 0.1464 0.1399 0.1369 0.1351 0.1340 0.1328 0.1322 0.1317 0.1312 0.1306 0.1300 0.1298 

[TRAIN] Epoch[6](1340/1500); Loss: 0.129798; Backpropagation: 0.0956 sec; Batch: 0.4687 sec
0.2488 0.2617 0.2269 0.1777 0.1470 0.1148 0.0953 0.0915 0.0897 0.0891 0.0891 0.0889 0.0888 0.0889 0.0892 0.0895 

[TRAIN] Epoch[6](1341/1500); Loss: 0.096592; Backpropagation: 0.0939 sec; Batch: 0.4651 sec
0.2428 0.2983 0.2304 0.1654 0.1079 0.0650 0.0469 0.0452 0.0444 0.0435 0.0429 0.0430 0.0428 0.0425 0.0423 0.0423 

[TRAIN] Epoch[6](1342/1500); Loss: 0.063447; Backpropagation: 0.0939 sec; Batch: 0.4667 sec
0.1105 0.0981 0.0831 0.0711 0.0640 0.0593 0.0567 0.0555 0.0542 0.0532 0.0525 0.0522 0.0518 0.0513 0.0509 0.0507 

[TRAIN] Epoch[6](1343/1500); Loss: 0.117045; Backpropagation: 0.0938 sec; Batch: 0.4663 sec
0.2078 0.2136 0.1822 0.1427 0.1113 0.0964 0.0951 0.0939 0.0924 0.0919 0.0917 0.0915 0.0907 0.0904 0.0905 0.0905 

[TRAIN] Epoch[6](1344/1500); Loss: 0.101476; Backpropagation: 0.0936 sec; Batch: 0.4703 sec
0.1405 0.1273 0.1170 0.1068 0.1022 0.0967 0.0955 0.0943 0.0940 0.0937 0.0931 0.0928 0.0926 0.0924 0.0923 0.0923 

[TRAIN] Epoch[6](1345/1500); Loss: 0.071787; Backpropagation: 0.0941 sec; Batch: 0.4278 sec
0.1434 0.1044 0.1022 0.0826 0.0757 0.0673 0.0627 0.0603 0.0583 0.0572 0.0566 0.0559 0.0557 0.0553 0.0553 0.0556 

[TRAIN] Epoch[6](1346/1500); Loss: 0.114444; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.2426 0.2792 0.2271 0.1765 0.1326 0.0938 0.0731 0.0695 0.0676 0.0671 0.0669 0.0668 0.0667 0.0669 0.0671 0.0674 

[TRAIN] Epoch[6](1347/1500); Loss: 0.081504; Backpropagation: 0.0938 sec; Batch: 0.5216 sec
0.2225 0.1702 0.1668 0.1101 0.0949 0.0604 0.0511 0.0537 0.0506 0.0481 0.0468 0.0462 0.0458 0.0453 0.0455 0.0461 

[TRAIN] Epoch[6](1348/1500); Loss: 0.095802; Backpropagation: 0.0937 sec; Batch: 0.4666 sec
0.1657 0.1366 0.1293 0.1062 0.0997 0.0899 0.0863 0.0837 0.0819 0.0804 0.0795 0.0794 0.0788 0.0785 0.0784 0.0785 

[TRAIN] Epoch[6](1349/1500); Loss: 0.075946; Backpropagation: 0.0939 sec; Batch: 0.4721 sec
0.1160 0.0868 0.0849 0.0759 0.0741 0.0718 0.0709 0.0704 0.0702 0.0703 0.0705 0.0708 0.0705 0.0706 0.0706 0.0709 

[TRAIN] Epoch[6](1350/1500); Loss: 0.090141; Backpropagation: 0.0956 sec; Batch: 0.4680 sec
0.1314 0.1158 0.1068 0.0961 0.0925 0.0877 0.0855 0.0832 0.0817 0.0808 0.0804 0.0802 0.0800 0.0798 0.0800 0.0803 

[TRAIN] Epoch[6](1351/1500); Loss: 0.052516; Backpropagation: 0.0958 sec; Batch: 0.4670 sec
0.1116 0.0711 0.0718 0.0581 0.0535 0.0456 0.0423 0.0423 0.0420 0.0423 0.0424 0.0425 0.0426 0.0434 0.0441 0.0446 

[TRAIN] Epoch[6](1352/1500); Loss: 0.136228; Backpropagation: 0.0938 sec; Batch: 0.4776 sec
0.2025 0.1889 0.1758 0.1464 0.1378 0.1251 0.1214 0.1217 0.1204 0.1200 0.1200 0.1198 0.1198 0.1198 0.1200 0.1203 

[TRAIN] Epoch[6](1353/1500); Loss: 0.090005; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.1469 0.1169 0.1143 0.0950 0.0908 0.0849 0.0824 0.0809 0.0798 0.0788 0.0785 0.0784 0.0781 0.0780 0.0781 0.0782 

[TRAIN] Epoch[6](1354/1500); Loss: 0.089564; Backpropagation: 0.0937 sec; Batch: 0.4698 sec
0.1508 0.1747 0.1360 0.1066 0.0906 0.0805 0.0750 0.0718 0.0703 0.0694 0.0689 0.0683 0.0678 0.0675 0.0674 0.0675 

[TRAIN] Epoch[6](1355/1500); Loss: 0.137518; Backpropagation: 0.0940 sec; Batch: 0.4681 sec
0.2284 0.2078 0.1942 0.1550 0.1449 0.1335 0.1244 0.1178 0.1149 0.1124 0.1118 0.1126 0.1110 0.1107 0.1104 0.1105 

[TRAIN] Epoch[6](1356/1500); Loss: 0.082355; Backpropagation: 0.0982 sec; Batch: 0.4739 sec
0.1340 0.1461 0.1161 0.0961 0.0831 0.0744 0.0714 0.0697 0.0684 0.0672 0.0665 0.0659 0.0654 0.0650 0.0644 0.0640 

[TRAIN] Epoch[6](1357/1500); Loss: 0.072521; Backpropagation: 0.0982 sec; Batch: 0.4703 sec
0.1258 0.1010 0.0962 0.0807 0.0734 0.0670 0.0636 0.0631 0.0622 0.0617 0.0614 0.0610 0.0608 0.0608 0.0609 0.0608 

[TRAIN] Epoch[6](1358/1500); Loss: 0.132881; Backpropagation: 0.0937 sec; Batch: 0.4723 sec
0.2095 0.2406 0.1964 0.1573 0.1271 0.1121 0.1109 0.1100 0.1093 0.1086 0.1081 0.1076 0.1073 0.1071 0.1071 0.1071 

[TRAIN] Epoch[6](1359/1500); Loss: 0.110581; Backpropagation: 0.0939 sec; Batch: 0.4638 sec
0.2598 0.2063 0.2015 0.1352 0.1220 0.0968 0.0873 0.0793 0.0757 0.0735 0.0726 0.0727 0.0719 0.0717 0.0716 0.0716 

[TRAIN] Epoch[6](1360/1500); Loss: 0.223674; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.3030 0.2916 0.2786 0.2527 0.2451 0.2303 0.2239 0.2116 0.2069 0.1997 0.1960 0.1920 0.1896 0.1874 0.1857 0.1848 

[TRAIN] Epoch[6](1361/1500); Loss: 0.186519; Backpropagation: 0.0937 sec; Batch: 0.4671 sec
0.2355 0.2193 0.2099 0.1920 0.1868 0.1826 0.1794 0.1781 0.1776 0.1772 0.1762 0.1755 0.1747 0.1740 0.1731 0.1725 

[TRAIN] Epoch[6](1362/1500); Loss: 0.134120; Backpropagation: 0.0938 sec; Batch: 0.4452 sec
0.1874 0.2020 0.1687 0.1447 0.1319 0.1240 0.1237 0.1217 0.1205 0.1191 0.1183 0.1176 0.1170 0.1165 0.1164 0.1164 

[TRAIN] Epoch[6](1363/1500); Loss: 0.148407; Backpropagation: 0.0939 sec; Batch: 0.4684 sec
0.2664 0.2179 0.2148 0.1644 0.1566 0.1412 0.1345 0.1280 0.1249 0.1211 0.1191 0.1183 0.1175 0.1170 0.1166 0.1162 

[TRAIN] Epoch[6](1364/1500); Loss: 0.099743; Backpropagation: 0.0931 sec; Batch: 0.4695 sec
0.1386 0.1273 0.1151 0.1052 0.0974 0.0949 0.0932 0.0919 0.0915 0.0913 0.0913 0.0913 0.0916 0.0917 0.0917 0.0919 

[TRAIN] Epoch[6](1365/1500); Loss: 0.082627; Backpropagation: 0.0933 sec; Batch: 0.5045 sec
0.1449 0.1370 0.1125 0.0803 0.0766 0.0743 0.0727 0.0707 0.0702 0.0694 0.0689 0.0690 0.0690 0.0689 0.0687 0.0689 

[TRAIN] Epoch[6](1366/1500); Loss: 0.134409; Backpropagation: 0.0937 sec; Batch: 0.4658 sec
0.2048 0.1770 0.1681 0.1447 0.1372 0.1276 0.1247 0.1227 0.1214 0.1203 0.1192 0.1183 0.1170 0.1163 0.1159 0.1153 

[TRAIN] Epoch[6](1367/1500); Loss: 0.051450; Backpropagation: 0.0956 sec; Batch: 0.4691 sec
0.0983 0.1079 0.0759 0.0598 0.0480 0.0437 0.0419 0.0407 0.0395 0.0386 0.0384 0.0383 0.0379 0.0380 0.0381 0.0383 

[TRAIN] Epoch[6](1368/1500); Loss: 0.094483; Backpropagation: 0.0957 sec; Batch: 0.4719 sec
0.1179 0.1306 0.0939 0.0852 0.0867 0.0876 0.0873 0.0879 0.0886 0.0898 0.0904 0.0914 0.0920 0.0934 0.0942 0.0949 

[TRAIN] Epoch[6](1369/1500); Loss: 0.145399; Backpropagation: 0.0939 sec; Batch: 0.4804 sec
0.2156 0.2056 0.1861 0.1598 0.1522 0.1420 0.1377 0.1322 0.1300 0.1275 0.1253 0.1240 0.1230 0.1223 0.1217 0.1214 

[TRAIN] Epoch[6](1370/1500); Loss: 0.090051; Backpropagation: 0.0932 sec; Batch: 0.4767 sec
0.1763 0.1402 0.1348 0.1016 0.0959 0.0846 0.0797 0.0762 0.0735 0.0703 0.0690 0.0681 0.0679 0.0675 0.0675 0.0676 

[TRAIN] Epoch[6](1371/1500); Loss: 0.070019; Backpropagation: 0.0939 sec; Batch: 0.4839 sec
0.1123 0.0920 0.0835 0.0743 0.0704 0.0658 0.0641 0.0629 0.0622 0.0620 0.0618 0.0616 0.0617 0.0618 0.0619 0.0620 

[TRAIN] Epoch[6](1372/1500); Loss: 0.123781; Backpropagation: 0.0937 sec; Batch: 0.4657 sec
0.2254 0.1924 0.1845 0.1473 0.1364 0.1191 0.1099 0.1011 0.0978 0.0972 0.0963 0.0954 0.0948 0.0944 0.0943 0.0943 

[TRAIN] Epoch[6](1373/1500); Loss: 0.075597; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.1872 0.1327 0.1301 0.0760 0.0640 0.0599 0.0572 0.0570 0.0561 0.0557 0.0552 0.0558 0.0558 0.0556 0.0555 0.0558 

[TRAIN] Epoch[6](1374/1500); Loss: 0.090469; Backpropagation: 0.0944 sec; Batch: 0.4677 sec
0.1310 0.1424 0.1148 0.0977 0.0902 0.0852 0.0815 0.0807 0.0797 0.0787 0.0780 0.0778 0.0775 0.0774 0.0775 0.0774 

[TRAIN] Epoch[6](1375/1500); Loss: 0.119372; Backpropagation: 0.0939 sec; Batch: 0.4700 sec
0.1557 0.1473 0.1390 0.1313 0.1239 0.1171 0.1132 0.1112 0.1097 0.1089 0.1088 0.1086 0.1087 0.1089 0.1088 0.1088 

[TRAIN] Epoch[6](1376/1500); Loss: 0.080641; Backpropagation: 0.0937 sec; Batch: 0.4700 sec
0.1477 0.1128 0.1086 0.0853 0.0789 0.0733 0.0701 0.0696 0.0686 0.0687 0.0681 0.0681 0.0677 0.0676 0.0676 0.0676 

[TRAIN] Epoch[6](1377/1500); Loss: 0.106864; Backpropagation: 0.0939 sec; Batch: 0.4704 sec
0.2470 0.1949 0.1847 0.1089 0.0976 0.0854 0.0805 0.0795 0.0783 0.0782 0.0777 0.0784 0.0791 0.0794 0.0797 0.0803 

[TRAIN] Epoch[6](1378/1500); Loss: 0.102243; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1611 0.1344 0.1282 0.1126 0.1020 0.0938 0.0920 0.0928 0.0918 0.0909 0.0901 0.0898 0.0894 0.0892 0.0890 0.0890 

[TRAIN] Epoch[6](1379/1500); Loss: 0.110747; Backpropagation: 0.0933 sec; Batch: 0.5429 sec
0.1443 0.1303 0.1249 0.1242 0.1158 0.1103 0.1074 0.1047 0.1031 0.1016 0.1012 0.1012 0.1008 0.1008 0.1007 0.1007 

[TRAIN] Epoch[6](1380/1500); Loss: 0.080384; Backpropagation: 0.0938 sec; Batch: 0.4671 sec
0.1223 0.1099 0.0980 0.0879 0.0824 0.0767 0.0746 0.0730 0.0720 0.0707 0.0703 0.0699 0.0696 0.0696 0.0695 0.0698 

[TRAIN] Epoch[6](1381/1500); Loss: 0.074793; Backpropagation: 0.0934 sec; Batch: 0.4663 sec
0.1491 0.1754 0.1329 0.0976 0.0687 0.0573 0.0548 0.0538 0.0522 0.0513 0.0507 0.0505 0.0505 0.0504 0.0506 0.0509 

[TRAIN] Epoch[6](1382/1500); Loss: 0.107493; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.1386 0.1246 0.1176 0.1160 0.1096 0.1045 0.1030 0.1014 0.1006 0.1004 0.1004 0.1005 0.1005 0.1004 0.1008 0.1009 

[TRAIN] Epoch[6](1383/1500); Loss: 0.111822; Backpropagation: 0.0939 sec; Batch: 0.4704 sec
0.1693 0.1579 0.1438 0.1200 0.1128 0.1039 0.1007 0.0989 0.0984 0.0983 0.0978 0.0977 0.0976 0.0973 0.0973 0.0974 

[TRAIN] Epoch[6](1384/1500); Loss: 0.089418; Backpropagation: 0.0939 sec; Batch: 0.4711 sec
0.1317 0.1188 0.1090 0.1004 0.0918 0.0875 0.0840 0.0816 0.0801 0.0789 0.0783 0.0783 0.0778 0.0775 0.0776 0.0776 

[TRAIN] Epoch[6](1385/1500); Loss: 0.070367; Backpropagation: 0.0938 sec; Batch: 0.4507 sec
0.1099 0.1321 0.0883 0.0662 0.0645 0.0629 0.0611 0.0610 0.0611 0.0608 0.0601 0.0592 0.0594 0.0599 0.0598 0.0598 

[TRAIN] Epoch[6](1386/1500); Loss: 0.154378; Backpropagation: 0.0939 sec; Batch: 0.4311 sec
0.2414 0.2425 0.2178 0.1774 0.1598 0.1428 0.1349 0.1329 0.1294 0.1284 0.1281 0.1280 0.1273 0.1268 0.1264 0.1261 

[TRAIN] Epoch[6](1387/1500); Loss: 0.130062; Backpropagation: 0.0935 sec; Batch: 0.4339 sec
0.1838 0.1998 0.1712 0.1421 0.1267 0.1170 0.1145 0.1136 0.1138 0.1149 0.1144 0.1135 0.1135 0.1138 0.1141 0.1142 

[TRAIN] Epoch[6](1388/1500); Loss: 0.089511; Backpropagation: 0.0947 sec; Batch: 0.4286 sec
0.1334 0.1197 0.1024 0.0984 0.0879 0.0853 0.0831 0.0819 0.0808 0.0801 0.0800 0.0798 0.0797 0.0798 0.0798 0.0801 

[TRAIN] Epoch[6](1389/1500); Loss: 0.051621; Backpropagation: 0.0957 sec; Batch: 0.4628 sec
0.0814 0.1008 0.0665 0.0565 0.0482 0.0437 0.0431 0.0430 0.0428 0.0424 0.0425 0.0426 0.0430 0.0429 0.0430 0.0435 

[TRAIN] Epoch[6](1390/1500); Loss: 0.070183; Backpropagation: 0.0954 sec; Batch: 0.4696 sec
0.2380 0.1769 0.1694 0.0935 0.0774 0.0498 0.0371 0.0313 0.0302 0.0325 0.0294 0.0303 0.0310 0.0311 0.0319 0.0331 

[TRAIN] Epoch[6](1391/1500); Loss: 0.080138; Backpropagation: 0.0939 sec; Batch: 0.4702 sec
0.1303 0.0967 0.0970 0.0894 0.0823 0.0751 0.0746 0.0710 0.0710 0.0704 0.0704 0.0704 0.0707 0.0710 0.0709 0.0710 

[TRAIN] Epoch[6](1392/1500); Loss: 0.049068; Backpropagation: 0.0933 sec; Batch: 0.4295 sec
0.1291 0.1267 0.0917 0.0481 0.0363 0.0371 0.0314 0.0319 0.0319 0.0320 0.0317 0.0313 0.0311 0.0314 0.0315 0.0318 

[TRAIN] Epoch[6](1393/1500); Loss: 0.151767; Backpropagation: 0.0948 sec; Batch: 0.4327 sec
0.4303 0.3581 0.3427 0.2211 0.1913 0.1189 0.0883 0.0836 0.0752 0.0764 0.0744 0.0737 0.0736 0.0737 0.0735 0.0736 

[TRAIN] Epoch[6](1394/1500); Loss: 0.108192; Backpropagation: 0.0934 sec; Batch: 0.4724 sec
0.1452 0.1722 0.1295 0.1078 0.1040 0.1020 0.1006 0.0991 0.0978 0.0967 0.0964 0.0962 0.0963 0.0956 0.0957 0.0957 

[TRAIN] Epoch[6](1395/1500); Loss: 0.097573; Backpropagation: 0.0939 sec; Batch: 0.5430 sec
0.2253 0.2839 0.2142 0.1539 0.1027 0.0695 0.0533 0.0513 0.0506 0.0502 0.0500 0.0503 0.0511 0.0515 0.0515 0.0518 

[TRAIN] Epoch[6](1396/1500); Loss: 0.054529; Backpropagation: 0.0937 sec; Batch: 0.4668 sec
0.1682 0.1215 0.1153 0.0764 0.0619 0.0413 0.0334 0.0302 0.0297 0.0278 0.0274 0.0274 0.0279 0.0277 0.0278 0.0286 

[TRAIN] Epoch[6](1397/1500); Loss: 0.080975; Backpropagation: 0.0939 sec; Batch: 0.4777 sec
0.1259 0.1150 0.1036 0.0922 0.0843 0.0760 0.0725 0.0717 0.0710 0.0696 0.0690 0.0690 0.0688 0.0689 0.0690 0.0691 

[TRAIN] Epoch[6](1398/1500); Loss: 0.109150; Backpropagation: 0.0934 sec; Batch: 0.4286 sec
0.2162 0.2197 0.1883 0.1446 0.1188 0.0929 0.0800 0.0785 0.0769 0.0768 0.0761 0.0761 0.0759 0.0755 0.0752 0.0749 

[TRAIN] Epoch[6](1399/1500); Loss: 0.093346; Backpropagation: 0.0939 sec; Batch: 0.4707 sec
0.2343 0.1883 0.1776 0.1080 0.0932 0.0657 0.0694 0.0642 0.0607 0.0604 0.0607 0.0606 0.0613 0.0620 0.0633 0.0638 

[TRAIN] Epoch[6](1400/1500); Loss: 0.110506; Backpropagation: 0.0943 sec; Batch: 0.4711 sec
0.1360 0.1274 0.1206 0.1168 0.1120 0.1074 0.1061 0.1054 0.1053 0.1049 0.1043 0.1044 0.1045 0.1044 0.1043 0.1044 

[TRAIN] Epoch[6](1401/1500); Loss: 0.118541; Backpropagation: 0.0937 sec; Batch: 0.4699 sec
0.2757 0.2769 0.2348 0.1564 0.1157 0.0851 0.0793 0.0773 0.0748 0.0746 0.0746 0.0742 0.0742 0.0740 0.0746 0.0745 

[TRAIN] Epoch[6](1402/1500); Loss: 0.092130; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.1454 0.1301 0.1231 0.1041 0.0995 0.0869 0.0821 0.0791 0.0798 0.0789 0.0780 0.0773 0.0777 0.0774 0.0773 0.0773 

[TRAIN] Epoch[6](1403/1500); Loss: 0.119284; Backpropagation: 0.0937 sec; Batch: 0.4662 sec
0.1873 0.1803 0.1608 0.1404 0.1234 0.1152 0.1084 0.1039 0.1022 0.1011 0.1004 0.0990 0.0974 0.0969 0.0960 0.0958 

[TRAIN] Epoch[6](1404/1500); Loss: 0.091812; Backpropagation: 0.0938 sec; Batch: 0.4719 sec
0.1459 0.1303 0.1153 0.0941 0.0910 0.0887 0.0838 0.0814 0.0809 0.0805 0.0794 0.0796 0.0794 0.0797 0.0794 0.0796 

[TRAIN] Epoch[6](1405/1500); Loss: 0.068578; Backpropagation: 0.0938 sec; Batch: 0.4894 sec
0.1222 0.0923 0.0841 0.0815 0.0750 0.0624 0.0595 0.0600 0.0593 0.0576 0.0569 0.0570 0.0577 0.0575 0.0572 0.0573 

[TRAIN] Epoch[6](1406/1500); Loss: 0.068619; Backpropagation: 0.0955 sec; Batch: 0.4293 sec
0.1045 0.1001 0.0859 0.0712 0.0674 0.0650 0.0619 0.0609 0.0601 0.0602 0.0606 0.0606 0.0599 0.0597 0.0598 0.0601 

[TRAIN] Epoch[6](1407/1500); Loss: 0.088188; Backpropagation: 0.0935 sec; Batch: 0.5082 sec
0.2059 0.2649 0.1937 0.1329 0.0827 0.0543 0.0475 0.0469 0.0469 0.0472 0.0473 0.0478 0.0475 0.0478 0.0485 0.0491 

[TRAIN] Epoch[6](1408/1500); Loss: 0.085742; Backpropagation: 0.0949 sec; Batch: 0.4290 sec
0.1376 0.1343 0.1097 0.0847 0.0816 0.0773 0.0766 0.0753 0.0747 0.0746 0.0743 0.0741 0.0743 0.0742 0.0741 0.0744 

[TRAIN] Epoch[6](1409/1500); Loss: 0.074778; Backpropagation: 0.0937 sec; Batch: 0.4396 sec
0.1523 0.1590 0.1286 0.0955 0.0720 0.0629 0.0574 0.0564 0.0538 0.0523 0.0512 0.0508 0.0508 0.0508 0.0511 0.0514 

[TRAIN] Epoch[6](1410/1500); Loss: 0.103231; Backpropagation: 0.0934 sec; Batch: 0.4329 sec
0.1775 0.1873 0.1555 0.1269 0.1080 0.0916 0.0835 0.0825 0.0810 0.0803 0.0799 0.0796 0.0795 0.0796 0.0797 0.0796 

[TRAIN] Epoch[6](1411/1500); Loss: 0.131195; Backpropagation: 0.0936 sec; Batch: 0.4282 sec
0.1896 0.1890 0.1692 0.1539 0.1355 0.1215 0.1177 0.1164 0.1154 0.1145 0.1135 0.1132 0.1127 0.1125 0.1122 0.1124 

[TRAIN] Epoch[6](1412/1500); Loss: 0.079644; Backpropagation: 0.0933 sec; Batch: 0.4707 sec
0.1944 0.2844 0.1840 0.1008 0.0446 0.0461 0.0436 0.0411 0.0440 0.0427 0.0414 0.0402 0.0399 0.0413 0.0425 0.0432 

[TRAIN] Epoch[6](1413/1500); Loss: 0.100585; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.1745 0.2069 0.1557 0.1115 0.0915 0.0846 0.0822 0.0795 0.0787 0.0786 0.0780 0.0776 0.0776 0.0776 0.0774 0.0776 

[TRAIN] Epoch[6](1414/1500); Loss: 0.158866; Backpropagation: 0.0939 sec; Batch: 0.5266 sec
0.2159 0.2253 0.1985 0.1721 0.1614 0.1514 0.1467 0.1449 0.1423 0.1420 0.1411 0.1407 0.1405 0.1397 0.1394 0.1398 

[TRAIN] Epoch[6](1415/1500); Loss: 0.103888; Backpropagation: 0.0939 sec; Batch: 0.4700 sec
0.1455 0.1568 0.1276 0.1092 0.0963 0.0936 0.0929 0.0930 0.0928 0.0927 0.0928 0.0931 0.0935 0.0936 0.0942 0.0946 

[TRAIN] Epoch[6](1416/1500); Loss: 0.141980; Backpropagation: 0.0938 sec; Batch: 0.4870 sec
0.1738 0.1625 0.1584 0.1541 0.1493 0.1408 0.1394 0.1367 0.1349 0.1327 0.1319 0.1316 0.1312 0.1315 0.1314 0.1314 

[TRAIN] Epoch[6](1417/1500); Loss: 0.091939; Backpropagation: 0.0934 sec; Batch: 0.4685 sec
0.1438 0.1844 0.1288 0.0967 0.0846 0.0807 0.0784 0.0769 0.0755 0.0749 0.0746 0.0748 0.0744 0.0745 0.0740 0.0740 

[TRAIN] Epoch[6](1418/1500); Loss: 0.090696; Backpropagation: 0.0937 sec; Batch: 0.4709 sec
0.1369 0.1076 0.1049 0.0954 0.0917 0.0870 0.0851 0.0837 0.0829 0.0824 0.0823 0.0823 0.0822 0.0822 0.0824 0.0822 

[TRAIN] Epoch[6](1419/1500); Loss: 0.093947; Backpropagation: 0.0938 sec; Batch: 0.4712 sec
0.1890 0.1696 0.1477 0.0952 0.0877 0.0813 0.0778 0.0759 0.0740 0.0732 0.0726 0.0723 0.0720 0.0717 0.0715 0.0715 

[TRAIN] Epoch[6](1420/1500); Loss: 0.096884; Backpropagation: 0.0938 sec; Batch: 0.4464 sec
0.1351 0.1371 0.1145 0.1027 0.0967 0.0931 0.0900 0.0899 0.0888 0.0880 0.0872 0.0863 0.0854 0.0853 0.0851 0.0848 

[TRAIN] Epoch[6](1421/1500); Loss: 0.048633; Backpropagation: 0.0939 sec; Batch: 0.4670 sec
0.1071 0.0656 0.0676 0.0620 0.0482 0.0422 0.0404 0.0387 0.0380 0.0378 0.0380 0.0381 0.0380 0.0383 0.0390 0.0391 

[TRAIN] Epoch[6](1422/1500); Loss: 0.102706; Backpropagation: 0.0937 sec; Batch: 0.4277 sec
0.1647 0.1767 0.1411 0.1129 0.1052 0.0965 0.0923 0.0883 0.0858 0.0853 0.0845 0.0834 0.0827 0.0819 0.0812 0.0807 

[TRAIN] Epoch[6](1423/1500); Loss: 0.100370; Backpropagation: 0.0933 sec; Batch: 0.4691 sec
0.1315 0.1138 0.1058 0.1094 0.0975 0.1000 0.0976 0.0964 0.0951 0.0945 0.0942 0.0938 0.0936 0.0937 0.0943 0.0948 

[TRAIN] Epoch[6](1424/1500); Loss: 0.053111; Backpropagation: 0.0931 sec; Batch: 0.4337 sec
0.0886 0.0689 0.0638 0.0722 0.0553 0.0489 0.0472 0.0459 0.0453 0.0446 0.0443 0.0447 0.0447 0.0446 0.0450 0.0457 

[TRAIN] Epoch[6](1425/1500); Loss: 0.102500; Backpropagation: 0.0934 sec; Batch: 0.4281 sec
0.2508 0.2061 0.1887 0.1118 0.1000 0.0828 0.0738 0.0747 0.0703 0.0700 0.0687 0.0684 0.0686 0.0684 0.0684 0.0686 

[TRAIN] Epoch[6](1426/1500); Loss: 0.056416; Backpropagation: 0.0937 sec; Batch: 0.4478 sec
0.0688 0.0789 0.0618 0.0597 0.0569 0.0556 0.0539 0.0529 0.0525 0.0523 0.0517 0.0514 0.0517 0.0516 0.0515 0.0514 

[TRAIN] Epoch[6](1427/1500); Loss: 0.076431; Backpropagation: 0.0940 sec; Batch: 0.4708 sec
0.1483 0.1010 0.0931 0.0790 0.0652 0.0795 0.0732 0.0710 0.0676 0.0644 0.0629 0.0631 0.0633 0.0636 0.0636 0.0642 

[TRAIN] Epoch[6](1428/1500); Loss: 0.088692; Backpropagation: 0.0956 sec; Batch: 0.4509 sec
0.1437 0.1769 0.1245 0.0893 0.0806 0.0789 0.0774 0.0752 0.0735 0.0725 0.0719 0.0712 0.0705 0.0707 0.0710 0.0713 

[TRAIN] Epoch[6](1429/1500); Loss: 0.102218; Backpropagation: 0.0956 sec; Batch: 0.4701 sec
0.1326 0.1374 0.1173 0.1104 0.1049 0.0982 0.0947 0.0936 0.0935 0.0932 0.0931 0.0928 0.0933 0.0935 0.0936 0.0935 

[TRAIN] Epoch[6](1430/1500); Loss: 0.135956; Backpropagation: 0.0939 sec; Batch: 0.4669 sec
0.1878 0.1955 0.1640 0.1408 0.1323 0.1286 0.1263 0.1243 0.1233 0.1225 0.1219 0.1218 0.1214 0.1213 0.1215 0.1220 

[TRAIN] Epoch[6](1431/1500); Loss: 0.102234; Backpropagation: 0.0938 sec; Batch: 0.4701 sec
0.1635 0.1386 0.1345 0.1198 0.1099 0.1004 0.0964 0.0911 0.0888 0.0862 0.0851 0.0849 0.0846 0.0840 0.0840 0.0840 

[TRAIN] Epoch[6](1432/1500); Loss: 0.110114; Backpropagation: 0.0937 sec; Batch: 0.4701 sec
0.1275 0.1110 0.1091 0.1179 0.1112 0.1110 0.1093 0.1076 0.1066 0.1065 0.1069 0.1071 0.1072 0.1074 0.1075 0.1079 

[TRAIN] Epoch[6](1433/1500); Loss: 0.075646; Backpropagation: 0.0939 sec; Batch: 0.4715 sec
0.1401 0.0973 0.0936 0.0804 0.0702 0.0747 0.0711 0.0692 0.0673 0.0655 0.0644 0.0635 0.0630 0.0630 0.0635 0.0636 

[TRAIN] Epoch[6](1434/1500); Loss: 0.199177; Backpropagation: 0.0938 sec; Batch: 0.4651 sec
0.3730 0.3158 0.3082 0.2315 0.2128 0.1731 0.1607 0.1578 0.1590 0.1581 0.1565 0.1559 0.1562 0.1560 0.1557 0.1564 

[TRAIN] Epoch[6](1435/1500); Loss: 0.102075; Backpropagation: 0.0939 sec; Batch: 0.5219 sec
0.2493 0.2235 0.2026 0.1355 0.1200 0.0872 0.0722 0.0631 0.0643 0.0627 0.0621 0.0607 0.0590 0.0577 0.0571 0.0563 

[TRAIN] Epoch[6](1436/1500); Loss: 0.106014; Backpropagation: 0.0939 sec; Batch: 0.4739 sec
0.1503 0.1268 0.1222 0.1145 0.1084 0.1027 0.0989 0.0974 0.0972 0.0971 0.0971 0.0969 0.0967 0.0967 0.0967 0.0969 

[TRAIN] Epoch[6](1437/1500); Loss: 0.135591; Backpropagation: 0.0939 sec; Batch: 0.4723 sec
0.1993 0.2294 0.1721 0.1388 0.1347 0.1267 0.1233 0.1191 0.1176 0.1168 0.1159 0.1152 0.1149 0.1150 0.1151 0.1154 

[TRAIN] Epoch[6](1438/1500); Loss: 0.080294; Backpropagation: 0.0937 sec; Batch: 0.4697 sec
0.0864 0.1252 0.0819 0.0817 0.0799 0.0780 0.0772 0.0760 0.0752 0.0748 0.0749 0.0748 0.0748 0.0745 0.0743 0.0750 

[TRAIN] Epoch[6](1439/1500); Loss: 0.079759; Backpropagation: 0.0936 sec; Batch: 0.4670 sec
0.1602 0.1542 0.1270 0.0928 0.0861 0.0724 0.0652 0.0597 0.0592 0.0585 0.0570 0.0570 0.0570 0.0569 0.0566 0.0562 

[TRAIN] Epoch[6](1440/1500); Loss: 0.092597; Backpropagation: 0.0932 sec; Batch: 0.4658 sec
0.2327 0.1842 0.1796 0.1220 0.1092 0.0814 0.0696 0.0588 0.0587 0.0582 0.0564 0.0546 0.0541 0.0540 0.0541 0.0540 

[TRAIN] Epoch[6](1441/1500); Loss: 0.062630; Backpropagation: 0.0934 sec; Batch: 0.5550 sec
0.1323 0.0881 0.0821 0.0560 0.0516 0.0609 0.0577 0.0556 0.0529 0.0507 0.0500 0.0504 0.0520 0.0528 0.0538 0.0551 

[TRAIN] Epoch[6](1442/1500); Loss: 0.068860; Backpropagation: 0.0937 sec; Batch: 0.4705 sec
0.1110 0.1109 0.0887 0.0758 0.0663 0.0610 0.0606 0.0603 0.0590 0.0585 0.0585 0.0582 0.0584 0.0583 0.0582 0.0581 

[TRAIN] Epoch[6](1443/1500); Loss: 0.097810; Backpropagation: 0.0939 sec; Batch: 0.4674 sec
0.1537 0.1864 0.1340 0.0974 0.0907 0.0877 0.0863 0.0852 0.0835 0.0822 0.0809 0.0798 0.0794 0.0794 0.0793 0.0790 

[TRAIN] Epoch[6](1444/1500); Loss: 0.093403; Backpropagation: 0.0937 sec; Batch: 0.4698 sec
0.1831 0.1582 0.1426 0.1004 0.0961 0.0800 0.0779 0.0767 0.0712 0.0710 0.0707 0.0713 0.0717 0.0728 0.0746 0.0762 

[TRAIN] Epoch[6](1445/1500); Loss: 0.129436; Backpropagation: 0.0982 sec; Batch: 0.4714 sec
0.2013 0.1690 0.1655 0.1381 0.1335 0.1262 0.1186 0.1150 0.1137 0.1134 0.1135 0.1128 0.1125 0.1125 0.1125 0.1130 

[TRAIN] Epoch[6](1446/1500); Loss: 0.089394; Backpropagation: 0.0957 sec; Batch: 0.4683 sec
0.1487 0.1443 0.1195 0.0983 0.0891 0.0810 0.0786 0.0782 0.0758 0.0745 0.0741 0.0739 0.0736 0.0735 0.0736 0.0736 

[TRAIN] Epoch[6](1447/1500); Loss: 0.061229; Backpropagation: 0.0939 sec; Batch: 0.4353 sec
0.1026 0.1097 0.0780 0.0658 0.0614 0.0573 0.0551 0.0529 0.0518 0.0507 0.0497 0.0492 0.0490 0.0488 0.0488 0.0491 

[TRAIN] Epoch[6](1448/1500); Loss: 0.137636; Backpropagation: 0.0937 sec; Batch: 0.4667 sec
0.2591 0.2393 0.2229 0.1732 0.1569 0.1315 0.1205 0.1072 0.1017 0.0992 0.0992 0.0985 0.0987 0.0985 0.0981 0.0977 

[TRAIN] Epoch[6](1449/1500); Loss: 0.085359; Backpropagation: 0.0939 sec; Batch: 0.4677 sec
0.1547 0.2117 0.1214 0.0774 0.0721 0.0706 0.0688 0.0674 0.0664 0.0656 0.0650 0.0647 0.0648 0.0650 0.0651 0.0652 

[TRAIN] Epoch[6](1450/1500); Loss: 0.150752; Backpropagation: 0.0935 sec; Batch: 0.4299 sec
0.2660 0.2301 0.2230 0.1829 0.1734 0.1531 0.1418 0.1266 0.1202 0.1161 0.1153 0.1144 0.1136 0.1126 0.1118 0.1111 

[TRAIN] Epoch[6](1451/1500); Loss: 0.122328; Backpropagation: 0.0934 sec; Batch: 0.4267 sec
0.2227 0.2118 0.1885 0.1499 0.1398 0.1202 0.1100 0.0973 0.0922 0.0935 0.0897 0.0898 0.0892 0.0884 0.0876 0.0869 

[TRAIN] Epoch[6](1452/1500); Loss: 0.056743; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.0749 0.1183 0.0688 0.0663 0.0600 0.0564 0.0530 0.0505 0.0493 0.0476 0.0459 0.0445 0.0435 0.0432 0.0429 0.0428 

[TRAIN] Epoch[6](1453/1500); Loss: 0.101768; Backpropagation: 0.0933 sec; Batch: 0.5411 sec
0.1627 0.1544 0.1342 0.1075 0.0996 0.0929 0.0909 0.0902 0.0887 0.0877 0.0870 0.0869 0.0867 0.0865 0.0864 0.0860 

[TRAIN] Epoch[6](1454/1500); Loss: 0.150089; Backpropagation: 0.0938 sec; Batch: 0.4796 sec
0.1921 0.1821 0.1722 0.1562 0.1514 0.1470 0.1448 0.1433 0.1418 0.1403 0.1396 0.1390 0.1385 0.1380 0.1375 0.1376 

[TRAIN] Epoch[6](1455/1500); Loss: 0.066187; Backpropagation: 0.0938 sec; Batch: 0.4707 sec
0.1073 0.1116 0.0850 0.0686 0.0656 0.0622 0.0594 0.0574 0.0559 0.0553 0.0548 0.0547 0.0549 0.0553 0.0554 0.0556 

[TRAIN] Epoch[6](1456/1500); Loss: 0.118726; Backpropagation: 0.0939 sec; Batch: 0.4662 sec
0.1386 0.1470 0.1279 0.1232 0.1199 0.1171 0.1156 0.1142 0.1132 0.1127 0.1123 0.1118 0.1118 0.1116 0.1114 0.1113 

[TRAIN] Epoch[6](1457/1500); Loss: 0.120152; Backpropagation: 0.0938 sec; Batch: 0.4670 sec
0.1488 0.1437 0.1330 0.1198 0.1176 0.1159 0.1150 0.1163 0.1146 0.1148 0.1139 0.1138 0.1135 0.1135 0.1140 0.1143 

[TRAIN] Epoch[6](1458/1500); Loss: 0.058590; Backpropagation: 0.0938 sec; Batch: 0.4659 sec
0.0782 0.1017 0.0696 0.0600 0.0541 0.0518 0.0509 0.0511 0.0520 0.0522 0.0517 0.0521 0.0530 0.0530 0.0527 0.0532 

[TRAIN] Epoch[6](1459/1500); Loss: 0.129290; Backpropagation: 0.0938 sec; Batch: 0.4681 sec
0.3061 0.2467 0.2389 0.1634 0.1498 0.1193 0.1048 0.0902 0.0865 0.0833 0.0810 0.0802 0.0800 0.0796 0.0795 0.0796 

[TRAIN] Epoch[6](1460/1500); Loss: 0.081275; Backpropagation: 0.0940 sec; Batch: 0.4303 sec
0.2010 0.2202 0.1591 0.0991 0.0623 0.0556 0.0527 0.0508 0.0501 0.0499 0.0500 0.0501 0.0497 0.0496 0.0500 0.0504 

[TRAIN] Epoch[6](1461/1500); Loss: 0.129292; Backpropagation: 0.0940 sec; Batch: 0.4307 sec
0.2450 0.2398 0.2094 0.1566 0.1419 0.1221 0.1123 0.0998 0.0965 0.0966 0.0929 0.0924 0.0917 0.0908 0.0905 0.0902 

[TRAIN] Epoch[6](1462/1500); Loss: 0.116736; Backpropagation: 0.0956 sec; Batch: 0.4670 sec
0.1691 0.1601 0.1412 0.1236 0.1134 0.1112 0.1086 0.1076 0.1064 0.1054 0.1047 0.1040 0.1036 0.1033 0.1029 0.1027 

[TRAIN] Epoch[6](1463/1500); Loss: 0.068513; Backpropagation: 0.0939 sec; Batch: 0.4691 sec
0.1477 0.1116 0.1048 0.0769 0.0689 0.0598 0.0569 0.0546 0.0536 0.0529 0.0521 0.0514 0.0513 0.0514 0.0511 0.0510 

[TRAIN] Epoch[6](1464/1500); Loss: 0.146640; Backpropagation: 0.0938 sec; Batch: 0.4705 sec
0.2731 0.2379 0.2301 0.1882 0.1746 0.1484 0.1351 0.1157 0.1090 0.1083 0.1052 0.1051 0.1045 0.1040 0.1036 0.1034 

[TRAIN] Epoch[6](1465/1500); Loss: 0.102628; Backpropagation: 0.0942 sec; Batch: 0.5077 sec
0.1502 0.1184 0.1150 0.1117 0.1005 0.1000 0.0974 0.0957 0.0948 0.0942 0.0938 0.0939 0.0938 0.0940 0.0943 0.0943 

[TRAIN] Epoch[6](1466/1500); Loss: 0.174091; Backpropagation: 0.0938 sec; Batch: 0.4697 sec
0.1912 0.1991 0.1793 0.1765 0.1740 0.1730 0.1719 0.1718 0.1707 0.1700 0.1691 0.1687 0.1682 0.1679 0.1673 0.1668 

[TRAIN] Epoch[6](1467/1500); Loss: 0.114105; Backpropagation: 0.0982 sec; Batch: 0.4730 sec
0.1754 0.1710 0.1434 0.1131 0.1064 0.1032 0.1026 0.1018 0.0990 0.0994 0.0997 0.1005 0.1009 0.1018 0.1029 0.1046 

[TRAIN] Epoch[6](1468/1500); Loss: 0.131523; Backpropagation: 0.0980 sec; Batch: 0.4735 sec
0.1532 0.1544 0.1421 0.1367 0.1326 0.1300 0.1278 0.1262 0.1256 0.1254 0.1253 0.1253 0.1250 0.1248 0.1249 0.1252 

[TRAIN] Epoch[6](1469/1500); Loss: 0.119330; Backpropagation: 0.0940 sec; Batch: 0.4337 sec
0.2343 0.2071 0.1922 0.1461 0.1311 0.1105 0.0964 0.0881 0.0872 0.0891 0.0870 0.0868 0.0877 0.0886 0.0886 0.0884 

[TRAIN] Epoch[6](1470/1500); Loss: 0.114379; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.1694 0.1863 0.1480 0.1228 0.1099 0.1029 0.1019 0.1015 0.1008 0.1003 0.0994 0.0986 0.0977 0.0972 0.0969 0.0966 

[TRAIN] Epoch[6](1471/1500); Loss: 0.115986; Backpropagation: 0.0938 sec; Batch: 0.4684 sec
0.1493 0.1329 0.1259 0.1199 0.1142 0.1128 0.1116 0.1106 0.1099 0.1097 0.1098 0.1097 0.1096 0.1096 0.1101 0.1103 

[TRAIN] Epoch[6](1472/1500); Loss: 0.069635; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1065 0.0753 0.0728 0.0881 0.0700 0.0705 0.0672 0.0658 0.0640 0.0624 0.0621 0.0618 0.0614 0.0620 0.0620 0.0622 

[TRAIN] Epoch[6](1473/1500); Loss: 0.108962; Backpropagation: 0.0958 sec; Batch: 0.4311 sec
0.1538 0.1635 0.1400 0.1195 0.1113 0.1040 0.1007 0.0984 0.0975 0.0963 0.0950 0.0936 0.0930 0.0927 0.0924 0.0916 

[TRAIN] Epoch[6](1474/1500); Loss: 0.113065; Backpropagation: 0.0937 sec; Batch: 0.4671 sec
0.1692 0.1503 0.1355 0.1207 0.1154 0.1080 0.1048 0.1044 0.1018 0.1011 0.1006 0.1002 0.0997 0.0994 0.0991 0.0990 

[TRAIN] Epoch[6](1475/1500); Loss: 0.076408; Backpropagation: 0.0938 sec; Batch: 0.4670 sec
0.1282 0.1074 0.0982 0.0865 0.0788 0.0717 0.0669 0.0663 0.0657 0.0654 0.0651 0.0648 0.0644 0.0642 0.0644 0.0646 

[TRAIN] Epoch[6](1476/1500); Loss: 0.098427; Backpropagation: 0.0938 sec; Batch: 0.4668 sec
0.1391 0.1320 0.1107 0.1102 0.0933 0.0949 0.0924 0.0910 0.0895 0.0890 0.0887 0.0886 0.0885 0.0885 0.0888 0.0894 

[TRAIN] Epoch[6](1477/1500); Loss: 0.078715; Backpropagation: 0.0939 sec; Batch: 0.4661 sec
0.1052 0.0838 0.0812 0.0923 0.0796 0.0763 0.0755 0.0752 0.0743 0.0739 0.0739 0.0739 0.0737 0.0737 0.0735 0.0735 

[TRAIN] Epoch[6](1478/1500); Loss: 0.142537; Backpropagation: 0.0942 sec; Batch: 0.4710 sec
0.1602 0.1815 0.1465 0.1401 0.1402 0.1393 0.1378 0.1379 0.1374 0.1370 0.1366 0.1370 0.1372 0.1372 0.1372 0.1375 

[TRAIN] Epoch[6](1479/1500); Loss: 0.097677; Backpropagation: 0.0938 sec; Batch: 0.4665 sec
0.1692 0.1967 0.1492 0.1127 0.0871 0.0822 0.0800 0.0781 0.0768 0.0760 0.0755 0.0753 0.0754 0.0759 0.0761 0.0766 

[TRAIN] Epoch[6](1480/1500); Loss: 0.136172; Backpropagation: 0.0938 sec; Batch: 0.4682 sec
0.1945 0.1812 0.1688 0.1439 0.1377 0.1299 0.1274 0.1240 0.1231 0.1220 0.1215 0.1209 0.1206 0.1209 0.1210 0.1213 

[TRAIN] Epoch[6](1481/1500); Loss: 0.065162; Backpropagation: 0.0940 sec; Batch: 0.4305 sec
0.1000 0.1413 0.0799 0.0622 0.0581 0.0571 0.0558 0.0547 0.0541 0.0538 0.0535 0.0536 0.0538 0.0544 0.0549 0.0554 

[TRAIN] Epoch[6](1482/1500); Loss: 0.107371; Backpropagation: 0.0938 sec; Batch: 0.4661 sec
0.1560 0.1329 0.1259 0.1147 0.1099 0.1049 0.1022 0.1007 0.0992 0.0978 0.0971 0.0965 0.0958 0.0953 0.0947 0.0943 

[TRAIN] Epoch[6](1483/1500); Loss: 0.088634; Backpropagation: 0.0938 sec; Batch: 0.4316 sec
0.1641 0.2116 0.1443 0.1018 0.0779 0.0679 0.0666 0.0656 0.0648 0.0643 0.0639 0.0639 0.0645 0.0652 0.0658 0.0662 

[TRAIN] Epoch[6](1484/1500); Loss: 0.118718; Backpropagation: 0.0940 sec; Batch: 0.4283 sec
0.1978 0.1617 0.1555 0.1259 0.1191 0.1111 0.1058 0.1056 0.1037 0.1030 0.1021 0.1026 0.1023 0.1018 0.1010 0.1005 

[TRAIN] Epoch[6](1485/1500); Loss: 0.096577; Backpropagation: 0.0939 sec; Batch: 0.4795 sec
0.1254 0.1030 0.1006 0.1111 0.0980 0.0951 0.0927 0.0922 0.0916 0.0910 0.0908 0.0908 0.0908 0.0908 0.0907 0.0906 

[TRAIN] Epoch[6](1486/1500); Loss: 0.093320; Backpropagation: 0.0938 sec; Batch: 0.4667 sec
0.2091 0.2904 0.1757 0.0823 0.0706 0.0747 0.0713 0.0683 0.0634 0.0590 0.0550 0.0528 0.0525 0.0541 0.0563 0.0576 

[TRAIN] Epoch[6](1487/1500); Loss: 0.094179; Backpropagation: 0.0938 sec; Batch: 0.4677 sec
0.1535 0.1432 0.1234 0.1025 0.0967 0.0888 0.0842 0.0812 0.0812 0.0801 0.0794 0.0787 0.0783 0.0784 0.0786 0.0786 

[TRAIN] Epoch[6](1488/1500); Loss: 0.116954; Backpropagation: 0.0936 sec; Batch: 0.4950 sec
0.1730 0.1488 0.1422 0.1230 0.1163 0.1153 0.1099 0.1077 0.1069 0.1044 0.1036 0.1034 0.1036 0.1036 0.1047 0.1049 

[TRAIN] Epoch[6](1489/1500); Loss: 0.106791; Backpropagation: 0.0938 sec; Batch: 0.4666 sec
0.2537 0.2659 0.2107 0.1299 0.0892 0.0758 0.0709 0.0715 0.0698 0.0689 0.0678 0.0672 0.0669 0.0668 0.0668 0.0669 

[TRAIN] Epoch[6](1490/1500); Loss: 0.088265; Backpropagation: 0.0938 sec; Batch: 0.5295 sec
0.1401 0.1205 0.1106 0.1171 0.0955 0.0867 0.0791 0.0760 0.0748 0.0740 0.0735 0.0731 0.0730 0.0729 0.0728 0.0727 

[TRAIN] Epoch[6](1491/1500); Loss: 0.109869; Backpropagation: 0.0938 sec; Batch: 0.4705 sec
0.1666 0.1534 0.1408 0.1219 0.1146 0.1035 0.0986 0.0962 0.0962 0.0959 0.0955 0.0952 0.0952 0.0949 0.0946 0.0947 

[TRAIN] Epoch[6](1492/1500); Loss: 0.078043; Backpropagation: 0.0937 sec; Batch: 0.4666 sec
0.1104 0.1338 0.0923 0.0830 0.0784 0.0731 0.0704 0.0696 0.0684 0.0680 0.0672 0.0671 0.0668 0.0669 0.0665 0.0668 

[TRAIN] Epoch[6](1493/1500); Loss: 0.055143; Backpropagation: 0.0939 sec; Batch: 0.4713 sec
0.0995 0.1102 0.0733 0.0566 0.0500 0.0477 0.0452 0.0448 0.0446 0.0441 0.0437 0.0438 0.0444 0.0446 0.0447 0.0448 

[TRAIN] Epoch[6](1494/1500); Loss: 0.138516; Backpropagation: 0.0938 sec; Batch: 0.4482 sec
0.1794 0.1669 0.1563 0.1475 0.1392 0.1329 0.1302 0.1287 0.1285 0.1288 0.1290 0.1288 0.1290 0.1298 0.1304 0.1307 

[TRAIN] Epoch[6](1495/1500); Loss: 0.150561; Backpropagation: 0.0939 sec; Batch: 0.4687 sec
0.1733 0.1842 0.1588 0.1528 0.1516 0.1517 0.1466 0.1453 0.1448 0.1443 0.1435 0.1425 0.1424 0.1425 0.1423 0.1422 

[TRAIN] Epoch[6](1496/1500); Loss: 0.087275; Backpropagation: 0.0937 sec; Batch: 0.4337 sec
0.1357 0.1215 0.1056 0.0927 0.0885 0.0825 0.0800 0.0795 0.0780 0.0770 0.0764 0.0760 0.0758 0.0758 0.0757 0.0756 

[TRAIN] Epoch[6](1497/1500); Loss: 0.074332; Backpropagation: 0.0939 sec; Batch: 0.4340 sec
0.1098 0.1269 0.0850 0.0705 0.0682 0.0662 0.0651 0.0656 0.0655 0.0651 0.0650 0.0655 0.0663 0.0672 0.0683 0.0693 

[TRAIN] Epoch[6](1498/1500); Loss: 0.054708; Backpropagation: 0.0937 sec; Batch: 0.4680 sec
0.0874 0.1155 0.0801 0.0688 0.0544 0.0488 0.0457 0.0427 0.0413 0.0410 0.0410 0.0411 0.0412 0.0415 0.0421 0.0425 

[TRAIN] Epoch[6](1499/1500); Loss: 0.090430; Backpropagation: 0.0935 sec; Batch: 0.4313 sec
0.1764 0.1415 0.1306 0.1040 0.0898 0.0842 0.0787 0.0762 0.0732 0.0705 0.0704 0.0713 0.0712 0.0704 0.0696 0.0689 

[TRAIN] Epoch[6](1500/1500); Loss: 0.095196; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1507 0.1321 0.1198 0.1021 0.0952 0.0922 0.0855 0.0855 0.0840 0.0821 0.0819 0.0824 0.0818 0.0820 0.0824 0.0836 

[TRAIN] Epoch[7](1/1500); Loss: 0.095604; Backpropagation: 0.0989 sec; Batch: 0.4954 sec
0.1368 0.1470 0.1184 0.0992 0.0913 0.0905 0.0871 0.0859 0.0850 0.0848 0.0845 0.0842 0.0838 0.0838 0.0838 0.0836 

[TRAIN] Epoch[7](2/1500); Loss: 0.155519; Backpropagation: 0.0948 sec; Batch: 0.4378 sec
0.1878 0.1832 0.1727 0.1619 0.1561 0.1536 0.1520 0.1503 0.1490 0.1474 0.1463 0.1457 0.1461 0.1458 0.1452 0.1452 

[TRAIN] Epoch[7](3/1500); Loss: 0.089793; Backpropagation: 0.0945 sec; Batch: 0.4301 sec
0.1531 0.2012 0.1358 0.0857 0.0752 0.0733 0.0713 0.0700 0.0693 0.0693 0.0700 0.0710 0.0718 0.0726 0.0735 0.0737 

[TRAIN] Epoch[7](4/1500); Loss: 0.072238; Backpropagation: 0.0993 sec; Batch: 0.4376 sec
0.1181 0.0925 0.0805 0.0973 0.0714 0.0681 0.0646 0.0636 0.0621 0.0638 0.0633 0.0628 0.0621 0.0617 0.0620 0.0620 

[TRAIN] Epoch[7](5/1500); Loss: 0.151548; Backpropagation: 0.0990 sec; Batch: 0.4415 sec
0.1686 0.1677 0.1603 0.1594 0.1554 0.1501 0.1481 0.1473 0.1467 0.1464 0.1463 0.1461 0.1455 0.1455 0.1457 0.1458 

[TRAIN] Epoch[7](6/1500); Loss: 0.077464; Backpropagation: 0.0995 sec; Batch: 0.4336 sec
0.2498 0.1872 0.1710 0.0826 0.0664 0.0567 0.0464 0.0407 0.0394 0.0391 0.0399 0.0406 0.0430 0.0440 0.0457 0.0469 

[TRAIN] Epoch[7](7/1500); Loss: 0.109001; Backpropagation: 0.0989 sec; Batch: 0.4336 sec
0.3294 0.2600 0.2492 0.1468 0.1249 0.0775 0.0599 0.0676 0.0542 0.0534 0.0525 0.0524 0.0544 0.0551 0.0538 0.0530 

[TRAIN] Epoch[7](8/1500); Loss: 0.094040; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1651 0.1864 0.1415 0.1119 0.0839 0.0795 0.0773 0.0756 0.0743 0.0739 0.0735 0.0730 0.0722 0.0720 0.0722 0.0723 

[TRAIN] Epoch[7](9/1500); Loss: 0.064533; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1595 0.1049 0.0959 0.0735 0.0600 0.0558 0.0523 0.0493 0.0485 0.0470 0.0471 0.0476 0.0471 0.0476 0.0482 0.0483 

[TRAIN] Epoch[7](10/1500); Loss: 0.080908; Backpropagation: 0.0989 sec; Batch: 0.4376 sec
0.1054 0.1448 0.0936 0.0774 0.0767 0.0756 0.0743 0.0737 0.0726 0.0720 0.0720 0.0716 0.0715 0.0711 0.0709 0.0713 

[TRAIN] Epoch[7](11/1500); Loss: 0.088366; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1219 0.1088 0.1001 0.1017 0.0944 0.0837 0.0817 0.0806 0.0801 0.0795 0.0794 0.0793 0.0795 0.0801 0.0809 0.0822 

[TRAIN] Epoch[7](12/1500); Loss: 0.115709; Backpropagation: 0.0994 sec; Batch: 0.4341 sec
0.1882 0.2331 0.1649 0.1151 0.1050 0.1042 0.1009 0.0984 0.0948 0.0920 0.0913 0.0920 0.0918 0.0925 0.0929 0.0943 

[TRAIN] Epoch[7](13/1500); Loss: 0.127097; Backpropagation: 0.0990 sec; Batch: 0.4340 sec
0.2119 0.1754 0.1656 0.1246 0.1188 0.1206 0.1155 0.1137 0.1119 0.1106 0.1109 0.1110 0.1109 0.1105 0.1107 0.1110 

[TRAIN] Epoch[7](14/1500); Loss: 0.103452; Backpropagation: 0.0992 sec; Batch: 0.4335 sec
0.1525 0.1701 0.1297 0.1099 0.0990 0.0946 0.0932 0.0921 0.0909 0.0900 0.0897 0.0894 0.0889 0.0884 0.0885 0.0884 

[TRAIN] Epoch[7](15/1500); Loss: 0.054997; Backpropagation: 0.1011 sec; Batch: 0.4358 sec
0.1154 0.0844 0.0753 0.0757 0.0565 0.0504 0.0481 0.0441 0.0423 0.0413 0.0416 0.0413 0.0404 0.0408 0.0416 0.0408 

[TRAIN] Epoch[7](16/1500); Loss: 0.082174; Backpropagation: 0.0983 sec; Batch: 0.4362 sec
0.1466 0.1207 0.1055 0.0949 0.0860 0.0796 0.0729 0.0705 0.0695 0.0688 0.0676 0.0669 0.0663 0.0666 0.0664 0.0660 

[TRAIN] Epoch[7](17/1500); Loss: 0.159535; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.2455 0.2432 0.2141 0.1728 0.1609 0.1539 0.1445 0.1417 0.1385 0.1370 0.1355 0.1341 0.1332 0.1327 0.1324 0.1326 

[TRAIN] Epoch[7](18/1500); Loss: 0.090436; Backpropagation: 0.0996 sec; Batch: 0.4338 sec
0.1321 0.1345 0.1112 0.1145 0.0912 0.0829 0.0805 0.0795 0.0794 0.0785 0.0779 0.0771 0.0770 0.0769 0.0768 0.0770 

[TRAIN] Epoch[7](19/1500); Loss: 0.075584; Backpropagation: 0.0993 sec; Batch: 0.4341 sec
0.1051 0.1112 0.0882 0.0821 0.0744 0.0711 0.0695 0.0686 0.0682 0.0678 0.0674 0.0673 0.0669 0.0672 0.0671 0.0671 

[TRAIN] Epoch[7](20/1500); Loss: 0.111222; Backpropagation: 0.0992 sec; Batch: 0.4337 sec
0.1375 0.1392 0.1161 0.1163 0.1058 0.1052 0.1051 0.1053 0.1043 0.1043 0.1043 0.1046 0.1056 0.1073 0.1087 0.1099 

[TRAIN] Epoch[7](21/1500); Loss: 0.098141; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.1079 0.1056 0.0949 0.0951 0.0927 0.0939 0.0930 0.0938 0.0948 0.0957 0.0970 0.0983 0.0996 0.1011 0.1027 0.1042 

[TRAIN] Epoch[7](22/1500); Loss: 0.075578; Backpropagation: 0.0982 sec; Batch: 0.4323 sec
0.1013 0.0870 0.0789 0.0789 0.0738 0.0687 0.0689 0.0690 0.0703 0.0701 0.0705 0.0721 0.0732 0.0740 0.0754 0.0771 

[TRAIN] Epoch[7](23/1500); Loss: 0.120975; Backpropagation: 0.0999 sec; Batch: 0.4351 sec
0.2149 0.1867 0.1672 0.1349 0.1207 0.1141 0.1065 0.1034 0.1011 0.1000 0.0988 0.0980 0.0970 0.0968 0.0978 0.0978 

[TRAIN] Epoch[7](24/1500); Loss: 0.104621; Backpropagation: 0.1081 sec; Batch: 0.4427 sec
0.1540 0.1500 0.1357 0.1216 0.1096 0.0987 0.0938 0.0920 0.0915 0.0909 0.0903 0.0896 0.0892 0.0893 0.0891 0.0888 

[TRAIN] Epoch[7](25/1500); Loss: 0.080819; Backpropagation: 0.1025 sec; Batch: 0.4369 sec
0.1166 0.0941 0.0883 0.0902 0.0838 0.0778 0.0761 0.0752 0.0746 0.0742 0.0739 0.0736 0.0736 0.0735 0.0737 0.0739 

[TRAIN] Epoch[7](26/1500); Loss: 0.115744; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1561 0.1803 0.1423 0.1163 0.1074 0.1072 0.1058 0.1053 0.1044 0.1038 0.1039 0.1041 0.1037 0.1034 0.1037 0.1041 

[TRAIN] Epoch[7](27/1500); Loss: 0.181682; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.2706 0.2401 0.2217 0.1832 0.1715 0.1687 0.1670 0.1651 0.1634 0.1649 0.1654 0.1645 0.1642 0.1655 0.1658 0.1654 

[TRAIN] Epoch[7](28/1500); Loss: 0.062178; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.0912 0.1099 0.0748 0.0614 0.0558 0.0577 0.0540 0.0534 0.0536 0.0544 0.0542 0.0542 0.0545 0.0548 0.0554 0.0554 

[TRAIN] Epoch[7](29/1500); Loss: 0.131086; Backpropagation: 0.1025 sec; Batch: 0.4371 sec
0.1707 0.1711 0.1504 0.1411 0.1321 0.1243 0.1232 0.1225 0.1215 0.1207 0.1199 0.1197 0.1197 0.1199 0.1201 0.1204 

[TRAIN] Epoch[7](30/1500); Loss: 0.068349; Backpropagation: 0.0993 sec; Batch: 0.4346 sec
0.0957 0.1020 0.0775 0.0833 0.0685 0.0633 0.0621 0.0609 0.0603 0.0602 0.0598 0.0596 0.0598 0.0600 0.0601 0.0606 

[TRAIN] Epoch[7](31/1500); Loss: 0.051696; Backpropagation: 0.0992 sec; Batch: 0.4339 sec
0.0652 0.1150 0.0604 0.0522 0.0484 0.0469 0.0457 0.0441 0.0442 0.0436 0.0439 0.0441 0.0435 0.0432 0.0434 0.0434 

[TRAIN] Epoch[7](32/1500); Loss: 0.094273; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.2199 0.2672 0.2006 0.1436 0.0925 0.0598 0.0564 0.0545 0.0534 0.0529 0.0520 0.0514 0.0517 0.0509 0.0506 0.0512 

[TRAIN] Epoch[7](33/1500); Loss: 0.062152; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.0976 0.1076 0.0763 0.0685 0.0639 0.0599 0.0561 0.0539 0.0534 0.0523 0.0516 0.0511 0.0510 0.0513 0.0501 0.0499 

[TRAIN] Epoch[7](34/1500); Loss: 0.068582; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1270 0.1388 0.1032 0.0706 0.0653 0.0582 0.0578 0.0546 0.0535 0.0528 0.0526 0.0527 0.0533 0.0522 0.0522 0.0524 

[TRAIN] Epoch[7](35/1500); Loss: 0.070583; Backpropagation: 0.0996 sec; Batch: 0.4337 sec
0.1836 0.1436 0.1108 0.0617 0.0524 0.0605 0.0484 0.0472 0.0471 0.0485 0.0500 0.0514 0.0531 0.0547 0.0570 0.0595 

[TRAIN] Epoch[7](36/1500); Loss: 0.180351; Backpropagation: 0.0993 sec; Batch: 0.4339 sec
0.2131 0.2209 0.1978 0.1901 0.1830 0.1771 0.1750 0.1731 0.1716 0.1704 0.1698 0.1697 0.1690 0.1680 0.1682 0.1688 

[TRAIN] Epoch[7](37/1500); Loss: 0.103331; Backpropagation: 0.0991 sec; Batch: 0.4341 sec
0.1315 0.1338 0.1140 0.1096 0.1025 0.0985 0.0974 0.0969 0.0965 0.0964 0.0959 0.0955 0.0954 0.0959 0.0965 0.0969 

[TRAIN] Epoch[7](38/1500); Loss: 0.115179; Backpropagation: 0.0990 sec; Batch: 0.4332 sec
0.1737 0.1577 0.1453 0.1326 0.1182 0.1039 0.1054 0.1023 0.1019 0.1009 0.1004 0.1001 0.1002 0.1000 0.0999 0.1003 

[TRAIN] Epoch[7](39/1500); Loss: 0.120734; Backpropagation: 0.0983 sec; Batch: 0.4335 sec
0.1593 0.1539 0.1415 0.1380 0.1265 0.1150 0.1109 0.1122 0.1101 0.1099 0.1097 0.1094 0.1090 0.1089 0.1087 0.1087 

[TRAIN] Epoch[7](40/1500); Loss: 0.143201; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.2225 0.1915 0.1794 0.1585 0.1491 0.1383 0.1328 0.1299 0.1278 0.1260 0.1243 0.1234 0.1224 0.1222 0.1218 0.1213 

[TRAIN] Epoch[7](41/1500); Loss: 0.064924; Backpropagation: 0.0990 sec; Batch: 0.4334 sec
0.1286 0.1134 0.0927 0.0708 0.0624 0.0611 0.0589 0.0558 0.0524 0.0494 0.0483 0.0505 0.0498 0.0485 0.0480 0.0482 

[TRAIN] Epoch[7](42/1500); Loss: 0.119622; Backpropagation: 0.0985 sec; Batch: 0.4326 sec
0.1870 0.1869 0.1588 0.1420 0.1145 0.1066 0.1057 0.1040 0.1029 0.1010 0.1008 0.1012 0.1014 0.1007 0.1004 0.1001 

[TRAIN] Epoch[7](43/1500); Loss: 0.119509; Backpropagation: 0.0986 sec; Batch: 0.4327 sec
0.1692 0.1663 0.1406 0.1277 0.1209 0.1135 0.1108 0.1096 0.1080 0.1073 0.1072 0.1065 0.1067 0.1061 0.1062 0.1056 

[TRAIN] Epoch[7](44/1500); Loss: 0.071742; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.1670 0.1219 0.1086 0.0874 0.0709 0.0595 0.0551 0.0538 0.0534 0.0524 0.0521 0.0525 0.0529 0.0534 0.0536 0.0533 

[TRAIN] Epoch[7](45/1500); Loss: 0.102775; Backpropagation: 0.0985 sec; Batch: 0.4328 sec
0.1641 0.2040 0.1515 0.1149 0.0957 0.0878 0.0848 0.0832 0.0820 0.0815 0.0820 0.0823 0.0823 0.0825 0.0827 0.0832 

[TRAIN] Epoch[7](46/1500); Loss: 0.081199; Backpropagation: 0.0985 sec; Batch: 0.4330 sec
0.1390 0.1664 0.1252 0.1009 0.0825 0.0686 0.0654 0.0636 0.0622 0.0622 0.0613 0.0607 0.0604 0.0602 0.0602 0.0604 

[TRAIN] Epoch[7](47/1500); Loss: 0.166551; Backpropagation: 0.1024 sec; Batch: 0.4375 sec
0.2150 0.2079 0.1950 0.1764 0.1663 0.1564 0.1563 0.1544 0.1549 0.1550 0.1544 0.1542 0.1542 0.1547 0.1548 0.1550 

[TRAIN] Epoch[7](48/1500); Loss: 0.098781; Backpropagation: 0.0997 sec; Batch: 0.4339 sec
0.1429 0.1304 0.1107 0.1092 0.0973 0.0976 0.0939 0.0919 0.0904 0.0886 0.0885 0.0879 0.0877 0.0876 0.0876 0.0883 

[TRAIN] Epoch[7](49/1500); Loss: 0.050224; Backpropagation: 0.0991 sec; Batch: 0.4338 sec
0.0831 0.0748 0.0579 0.0530 0.0478 0.0474 0.0442 0.0451 0.0440 0.0430 0.0424 0.0428 0.0429 0.0443 0.0449 0.0459 

[TRAIN] Epoch[7](50/1500); Loss: 0.087562; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.2889 0.2128 0.1929 0.0724 0.0588 0.0820 0.0526 0.0515 0.0489 0.0486 0.0478 0.0481 0.0487 0.0485 0.0484 0.0503 

[TRAIN] Epoch[7](51/1500); Loss: 0.072292; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.1297 0.1263 0.0999 0.0890 0.0701 0.0648 0.0600 0.0583 0.0572 0.0578 0.0577 0.0570 0.0565 0.0571 0.0575 0.0578 

[TRAIN] Epoch[7](52/1500); Loss: 0.127476; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.1673 0.1851 0.1557 0.1311 0.1220 0.1176 0.1171 0.1157 0.1153 0.1156 0.1160 0.1161 0.1164 0.1162 0.1161 0.1164 

[TRAIN] Epoch[7](53/1500); Loss: 0.086534; Backpropagation: 0.1047 sec; Batch: 0.4394 sec
0.1468 0.1515 0.1227 0.0978 0.0850 0.0795 0.0751 0.0720 0.0710 0.0707 0.0698 0.0694 0.0687 0.0681 0.0681 0.0684 

[TRAIN] Epoch[7](54/1500); Loss: 0.092960; Backpropagation: 0.1024 sec; Batch: 0.4368 sec
0.1476 0.1700 0.1338 0.1111 0.0942 0.0856 0.0801 0.0773 0.0756 0.0746 0.0740 0.0734 0.0728 0.0724 0.0722 0.0725 

[TRAIN] Epoch[7](55/1500); Loss: 0.123869; Backpropagation: 0.0988 sec; Batch: 0.4335 sec
0.1716 0.1710 0.1530 0.1412 0.1288 0.1184 0.1145 0.1124 0.1108 0.1100 0.1094 0.1090 0.1087 0.1082 0.1075 0.1073 

[TRAIN] Epoch[7](56/1500); Loss: 0.104147; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1454 0.1426 0.1250 0.1126 0.1027 0.1009 0.0977 0.0963 0.0951 0.0942 0.0936 0.0927 0.0920 0.0917 0.0919 0.0921 

[TRAIN] Epoch[7](57/1500); Loss: 0.106665; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1568 0.1800 0.1410 0.1098 0.1020 0.0963 0.0953 0.0941 0.0934 0.0924 0.0915 0.0909 0.0910 0.0913 0.0906 0.0901 

[TRAIN] Epoch[7](58/1500); Loss: 0.138005; Backpropagation: 0.0994 sec; Batch: 0.4336 sec
0.2153 0.2277 0.1908 0.1539 0.1367 0.1258 0.1211 0.1181 0.1171 0.1169 0.1159 0.1148 0.1142 0.1137 0.1134 0.1128 

[TRAIN] Epoch[7](59/1500); Loss: 0.129207; Backpropagation: 0.0992 sec; Batch: 0.4337 sec
0.2001 0.1719 0.1615 0.1417 0.1327 0.1198 0.1184 0.1160 0.1146 0.1136 0.1131 0.1132 0.1130 0.1128 0.1125 0.1125 

[TRAIN] Epoch[7](60/1500); Loss: 0.129340; Backpropagation: 0.0992 sec; Batch: 0.4333 sec
0.1725 0.1647 0.1455 0.1388 0.1312 0.1234 0.1230 0.1226 0.1214 0.1198 0.1189 0.1188 0.1179 0.1176 0.1169 0.1166 

[TRAIN] Epoch[7](61/1500); Loss: 0.076775; Backpropagation: 0.0987 sec; Batch: 0.4337 sec
0.2249 0.3132 0.2150 0.1172 0.0385 0.0376 0.0363 0.0328 0.0291 0.0256 0.0261 0.0258 0.0262 0.0262 0.0267 0.0273 

[TRAIN] Epoch[7](62/1500); Loss: 0.055634; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.1443 0.1039 0.0893 0.0574 0.0449 0.0555 0.0432 0.0429 0.0401 0.0385 0.0375 0.0375 0.0392 0.0389 0.0385 0.0385 

[TRAIN] Epoch[7](63/1500); Loss: 0.072916; Backpropagation: 0.0991 sec; Batch: 0.4345 sec
0.1119 0.1186 0.0935 0.0816 0.0718 0.0657 0.0638 0.0636 0.0631 0.0622 0.0619 0.0619 0.0615 0.0617 0.0618 0.0621 

[TRAIN] Epoch[7](64/1500); Loss: 0.122458; Backpropagation: 0.0987 sec; Batch: 0.4335 sec
0.1668 0.1768 0.1532 0.1313 0.1221 0.1147 0.1123 0.1112 0.1105 0.1096 0.1089 0.1083 0.1082 0.1082 0.1086 0.1086 

[TRAIN] Epoch[7](65/1500); Loss: 0.144685; Backpropagation: 0.0990 sec; Batch: 0.4335 sec
0.1727 0.1653 0.1597 0.1576 0.1515 0.1424 0.1402 0.1380 0.1373 0.1367 0.1357 0.1357 0.1356 0.1355 0.1355 0.1354 

[TRAIN] Epoch[7](66/1500); Loss: 0.117120; Backpropagation: 0.0991 sec; Batch: 0.4337 sec
0.1527 0.1521 0.1318 0.1209 0.1148 0.1121 0.1106 0.1093 0.1084 0.1081 0.1088 0.1087 0.1084 0.1087 0.1093 0.1092 

[TRAIN] Epoch[7](67/1500); Loss: 0.120148; Backpropagation: 0.0986 sec; Batch: 0.4337 sec
0.3749 0.3042 0.2652 0.1215 0.0813 0.0995 0.0678 0.0802 0.0739 0.0695 0.0639 0.0617 0.0628 0.0658 0.0655 0.0648 

[TRAIN] Epoch[7](68/1500); Loss: 0.070657; Backpropagation: 0.0985 sec; Batch: 0.4331 sec
0.0980 0.0964 0.0800 0.0738 0.0693 0.0680 0.0664 0.0656 0.0647 0.0642 0.0640 0.0636 0.0638 0.0641 0.0643 0.0643 

[TRAIN] Epoch[7](69/1500); Loss: 0.056171; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1475 0.0785 0.0598 0.0842 0.0546 0.0621 0.0523 0.0474 0.0408 0.0373 0.0379 0.0386 0.0394 0.0388 0.0393 0.0403 

[TRAIN] Epoch[7](70/1500); Loss: 0.072553; Backpropagation: 0.0986 sec; Batch: 0.4335 sec
0.1523 0.1076 0.0956 0.0755 0.0716 0.0645 0.0617 0.0608 0.0600 0.0593 0.0591 0.0587 0.0585 0.0584 0.0585 0.0587 

[TRAIN] Epoch[7](71/1500); Loss: 0.074820; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1425 0.1164 0.0967 0.0747 0.0665 0.0745 0.0651 0.0637 0.0627 0.0622 0.0620 0.0618 0.0616 0.0616 0.0624 0.0626 

[TRAIN] Epoch[7](72/1500); Loss: 0.069864; Backpropagation: 0.0982 sec; Batch: 0.4328 sec
0.1439 0.2255 0.1099 0.0630 0.0630 0.0586 0.0532 0.0479 0.0437 0.0412 0.0409 0.0422 0.0453 0.0462 0.0460 0.0472 

[TRAIN] Epoch[7](73/1500); Loss: 0.126107; Backpropagation: 0.0985 sec; Batch: 0.4338 sec
0.1512 0.1307 0.1210 0.1347 0.1229 0.1224 0.1213 0.1213 0.1217 0.1223 0.1230 0.1236 0.1243 0.1249 0.1257 0.1267 

[TRAIN] Epoch[7](74/1500); Loss: 0.114827; Backpropagation: 0.0984 sec; Batch: 0.4327 sec
0.1490 0.1607 0.1312 0.1187 0.1123 0.1085 0.1069 0.1057 0.1052 0.1050 0.1049 0.1051 0.1057 0.1058 0.1061 0.1064 

[TRAIN] Epoch[7](75/1500); Loss: 0.092516; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.1798 0.1660 0.1370 0.0927 0.0848 0.0818 0.0770 0.0758 0.0745 0.0733 0.0727 0.0734 0.0736 0.0729 0.0724 0.0725 

[TRAIN] Epoch[7](76/1500); Loss: 0.164185; Backpropagation: 0.0986 sec; Batch: 0.4330 sec
0.2200 0.2044 0.1895 0.1722 0.1655 0.1624 0.1598 0.1584 0.1554 0.1528 0.1505 0.1486 0.1478 0.1472 0.1469 0.1457 

[TRAIN] Epoch[7](77/1500); Loss: 0.090572; Backpropagation: 0.0986 sec; Batch: 0.4338 sec
0.1313 0.1088 0.1000 0.0937 0.0889 0.0854 0.0844 0.0839 0.0837 0.0837 0.0838 0.0840 0.0843 0.0844 0.0844 0.0845 

[TRAIN] Epoch[7](78/1500); Loss: 0.150869; Backpropagation: 0.0985 sec; Batch: 0.4327 sec
0.1833 0.2016 0.1675 0.1562 0.1494 0.1475 0.1433 0.1421 0.1416 0.1414 0.1409 0.1409 0.1400 0.1394 0.1393 0.1394 

[TRAIN] Epoch[7](79/1500); Loss: 0.092435; Backpropagation: 0.0983 sec; Batch: 0.4333 sec
0.1363 0.1330 0.1091 0.1028 0.0915 0.0867 0.0852 0.0838 0.0830 0.0821 0.0816 0.0813 0.0809 0.0806 0.0804 0.0806 

[TRAIN] Epoch[7](80/1500); Loss: 0.069529; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1099 0.1025 0.0859 0.0778 0.0694 0.0632 0.0624 0.0615 0.0609 0.0606 0.0600 0.0599 0.0599 0.0596 0.0596 0.0595 

[TRAIN] Epoch[7](81/1500); Loss: 0.071835; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1628 0.1232 0.1082 0.0664 0.0652 0.0698 0.0571 0.0563 0.0559 0.0557 0.0549 0.0549 0.0548 0.0548 0.0547 0.0547 

[TRAIN] Epoch[7](82/1500); Loss: 0.100346; Backpropagation: 0.1022 sec; Batch: 0.4368 sec
0.1648 0.1992 0.1445 0.1089 0.0917 0.0835 0.0835 0.0823 0.0812 0.0807 0.0804 0.0802 0.0803 0.0808 0.0814 0.0821 

[TRAIN] Epoch[7](83/1500); Loss: 0.057122; Backpropagation: 0.0996 sec; Batch: 0.4346 sec
0.1687 0.0987 0.0745 0.0570 0.0414 0.0514 0.0457 0.0428 0.0405 0.0423 0.0422 0.0419 0.0411 0.0410 0.0418 0.0430 

[TRAIN] Epoch[7](84/1500); Loss: 0.132299; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1649 0.1599 0.1443 0.1362 0.1312 0.1282 0.1276 0.1266 0.1259 0.1251 0.1248 0.1245 0.1245 0.1244 0.1244 0.1244 

[TRAIN] Epoch[7](85/1500); Loss: 0.125205; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1576 0.1483 0.1395 0.1310 0.1256 0.1243 0.1230 0.1214 0.1196 0.1181 0.1169 0.1162 0.1158 0.1157 0.1153 0.1149 

[TRAIN] Epoch[7](86/1500); Loss: 0.098825; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.1636 0.1316 0.1218 0.1030 0.0986 0.0919 0.0896 0.0885 0.0882 0.0869 0.0866 0.0864 0.0861 0.0859 0.0860 0.0865 

[TRAIN] Epoch[7](87/1500); Loss: 0.106751; Backpropagation: 0.0986 sec; Batch: 0.4336 sec
0.1312 0.1288 0.1154 0.1140 0.1067 0.1025 0.1015 0.1008 0.1008 0.1012 0.1012 0.1006 0.1005 0.1009 0.1010 0.1009 

[TRAIN] Epoch[7](88/1500); Loss: 0.082936; Backpropagation: 0.0986 sec; Batch: 0.4327 sec
0.1368 0.1026 0.0961 0.0884 0.0841 0.0831 0.0783 0.0766 0.0746 0.0734 0.0725 0.0726 0.0723 0.0717 0.0718 0.0721 

[TRAIN] Epoch[7](89/1500); Loss: 0.076092; Backpropagation: 0.0986 sec; Batch: 0.4330 sec
0.1183 0.1335 0.0835 0.0701 0.0660 0.0651 0.0646 0.0644 0.0653 0.0659 0.0668 0.0680 0.0695 0.0711 0.0721 0.0734 

[TRAIN] Epoch[7](90/1500); Loss: 0.087162; Backpropagation: 0.0985 sec; Batch: 0.4337 sec
0.1499 0.1530 0.1189 0.0975 0.0847 0.0800 0.0766 0.0751 0.0732 0.0720 0.0706 0.0696 0.0690 0.0685 0.0681 0.0681 

[TRAIN] Epoch[7](91/1500); Loss: 0.081863; Backpropagation: 0.0986 sec; Batch: 0.4331 sec
0.1129 0.1016 0.0947 0.0867 0.0829 0.0791 0.0777 0.0762 0.0753 0.0748 0.0746 0.0746 0.0749 0.0748 0.0745 0.0743 

[TRAIN] Epoch[7](92/1500); Loss: 0.122055; Backpropagation: 0.0985 sec; Batch: 0.4329 sec
0.1830 0.1627 0.1442 0.1274 0.1181 0.1167 0.1146 0.1129 0.1112 0.1100 0.1094 0.1092 0.1089 0.1086 0.1082 0.1077 

[TRAIN] Epoch[7](93/1500); Loss: 0.071521; Backpropagation: 0.0985 sec; Batch: 0.4333 sec
0.1205 0.1070 0.0900 0.0838 0.0695 0.0658 0.0642 0.0625 0.0610 0.0601 0.0596 0.0601 0.0601 0.0600 0.0599 0.0603 

[TRAIN] Epoch[7](94/1500); Loss: 0.083365; Backpropagation: 0.0990 sec; Batch: 0.4338 sec
0.1203 0.0959 0.0931 0.0851 0.0851 0.0818 0.0803 0.0789 0.0773 0.0766 0.0766 0.0762 0.0764 0.0765 0.0768 0.0771 

[TRAIN] Epoch[7](95/1500); Loss: 0.075455; Backpropagation: 0.0983 sec; Batch: 0.4330 sec
0.0991 0.1130 0.0799 0.0763 0.0744 0.0717 0.0706 0.0695 0.0688 0.0685 0.0685 0.0688 0.0691 0.0694 0.0696 0.0700 

[TRAIN] Epoch[7](96/1500); Loss: 0.067365; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1003 0.0815 0.0729 0.0696 0.0679 0.0675 0.0656 0.0642 0.0622 0.0616 0.0610 0.0607 0.0608 0.0605 0.0606 0.0610 

[TRAIN] Epoch[7](97/1500); Loss: 0.124442; Backpropagation: 0.0985 sec; Batch: 0.4727 sec
0.2087 0.1793 0.1657 0.1468 0.1310 0.1170 0.1089 0.1054 0.1051 0.1046 0.1038 0.1036 0.1030 0.1028 0.1027 0.1028 

[TRAIN] Epoch[7](98/1500); Loss: 0.089945; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.2495 0.1841 0.1520 0.1009 0.0784 0.0708 0.0666 0.0637 0.0620 0.0601 0.0587 0.0587 0.0588 0.0584 0.0581 0.0583 

[TRAIN] Epoch[7](99/1500); Loss: 0.155947; Backpropagation: 0.1082 sec; Batch: 0.4436 sec
0.1761 0.1788 0.1653 0.1590 0.1566 0.1541 0.1522 0.1512 0.1506 0.1507 0.1507 0.1505 0.1502 0.1497 0.1498 0.1496 

[TRAIN] Epoch[7](100/1500); Loss: 0.051529; Backpropagation: 0.1029 sec; Batch: 0.4375 sec
0.0955 0.0681 0.0638 0.0515 0.0511 0.0476 0.0456 0.0447 0.0439 0.0434 0.0438 0.0449 0.0446 0.0447 0.0452 0.0460 

[TRAIN] Epoch[7](101/1500); Loss: 0.104075; Backpropagation: 0.0989 sec; Batch: 0.4335 sec
0.1346 0.1483 0.1185 0.1046 0.0973 0.0957 0.0955 0.0947 0.0945 0.0947 0.0954 0.0968 0.0975 0.0983 0.0989 0.0999 

[TRAIN] Epoch[7](102/1500); Loss: 0.096864; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.1502 0.1255 0.1158 0.1010 0.0966 0.0923 0.0898 0.0892 0.0878 0.0867 0.0862 0.0865 0.0858 0.0854 0.0853 0.0855 

[TRAIN] Epoch[7](103/1500); Loss: 0.075584; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1009 0.1155 0.0836 0.0803 0.0774 0.0741 0.0718 0.0698 0.0686 0.0676 0.0671 0.0670 0.0663 0.0666 0.0665 0.0662 

[TRAIN] Epoch[7](104/1500); Loss: 0.126215; Backpropagation: 0.0984 sec; Batch: 0.4332 sec
0.1519 0.1548 0.1324 0.1246 0.1226 0.1214 0.1212 0.1213 0.1211 0.1208 0.1209 0.1211 0.1212 0.1213 0.1212 0.1214 

[TRAIN] Epoch[7](105/1500); Loss: 0.055546; Backpropagation: 0.0996 sec; Batch: 0.4341 sec
0.1086 0.0821 0.0756 0.0677 0.0578 0.0500 0.0483 0.0474 0.0462 0.0449 0.0442 0.0438 0.0432 0.0431 0.0429 0.0429 

[TRAIN] Epoch[7](106/1500); Loss: 0.197405; Backpropagation: 0.0989 sec; Batch: 0.4338 sec
0.2774 0.2612 0.2410 0.2167 0.2053 0.1901 0.1842 0.1812 0.1802 0.1779 0.1760 0.1748 0.1741 0.1733 0.1727 0.1724 

[TRAIN] Epoch[7](107/1500); Loss: 0.085988; Backpropagation: 0.0984 sec; Batch: 0.4331 sec
0.1481 0.1283 0.1114 0.0992 0.0881 0.0823 0.0744 0.0728 0.0721 0.0717 0.0716 0.0713 0.0711 0.0711 0.0712 0.0712 

[TRAIN] Epoch[7](108/1500); Loss: 0.095485; Backpropagation: 0.0984 sec; Batch: 0.4329 sec
0.1214 0.1297 0.1065 0.0976 0.0940 0.0924 0.0910 0.0893 0.0888 0.0883 0.0881 0.0880 0.0881 0.0881 0.0882 0.0883 

[TRAIN] Epoch[7](109/1500); Loss: 0.059327; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1386 0.0858 0.0669 0.0608 0.0543 0.0560 0.0524 0.0488 0.0480 0.0481 0.0481 0.0479 0.0479 0.0481 0.0484 0.0492 

[TRAIN] Epoch[7](110/1500); Loss: 0.078910; Backpropagation: 0.1008 sec; Batch: 0.4354 sec
0.1070 0.1380 0.0910 0.0878 0.0824 0.0769 0.0731 0.0705 0.0685 0.0670 0.0662 0.0659 0.0667 0.0671 0.0672 0.0672 

[TRAIN] Epoch[7](111/1500); Loss: 0.129512; Backpropagation: 0.0988 sec; Batch: 0.4337 sec
0.1893 0.2227 0.1591 0.1218 0.1249 0.1240 0.1200 0.1167 0.1145 0.1126 0.1113 0.1107 0.1106 0.1107 0.1114 0.1118 

[TRAIN] Epoch[7](112/1500); Loss: 0.131086; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.1874 0.1989 0.1598 0.1312 0.1256 0.1239 0.1217 0.1194 0.1178 0.1168 0.1164 0.1160 0.1158 0.1157 0.1155 0.1156 

[TRAIN] Epoch[7](113/1500); Loss: 0.149261; Backpropagation: 0.0984 sec; Batch: 0.4342 sec
0.2233 0.2111 0.1905 0.1551 0.1451 0.1375 0.1357 0.1355 0.1345 0.1333 0.1322 0.1315 0.1311 0.1308 0.1305 0.1305 

[TRAIN] Epoch[7](114/1500); Loss: 0.076008; Backpropagation: 0.0984 sec; Batch: 0.4330 sec
0.1059 0.1259 0.0863 0.0802 0.0749 0.0720 0.0692 0.0676 0.0677 0.0673 0.0664 0.0659 0.0667 0.0670 0.0667 0.0664 

[TRAIN] Epoch[7](115/1500); Loss: 0.092844; Backpropagation: 0.0983 sec; Batch: 0.4332 sec
0.1271 0.1182 0.1060 0.0939 0.0874 0.0860 0.0855 0.0850 0.0858 0.0863 0.0860 0.0861 0.0867 0.0879 0.0887 0.0887 

[TRAIN] Epoch[7](116/1500); Loss: 0.090412; Backpropagation: 0.0987 sec; Batch: 0.4334 sec
0.1489 0.1182 0.1102 0.0947 0.0877 0.0864 0.0824 0.0813 0.0801 0.0794 0.0796 0.0796 0.0793 0.0792 0.0795 0.0800 

[TRAIN] Epoch[7](117/1500); Loss: 0.051358; Backpropagation: 0.1083 sec; Batch: 0.4433 sec
0.0573 0.0906 0.0552 0.0588 0.0535 0.0504 0.0474 0.0457 0.0465 0.0466 0.0455 0.0443 0.0442 0.0448 0.0457 0.0452 

[TRAIN] Epoch[7](118/1500); Loss: 0.058395; Backpropagation: 0.1026 sec; Batch: 0.4375 sec
0.1368 0.1061 0.0925 0.0705 0.0569 0.0493 0.0446 0.0443 0.0434 0.0424 0.0412 0.0410 0.0409 0.0412 0.0415 0.0417 

[TRAIN] Epoch[7](119/1500); Loss: 0.103585; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.2174 0.2324 0.1786 0.1186 0.0811 0.0821 0.0834 0.0804 0.0775 0.0748 0.0731 0.0719 0.0714 0.0715 0.0716 0.0715 

[TRAIN] Epoch[7](120/1500); Loss: 0.156907; Backpropagation: 0.0981 sec; Batch: 0.4331 sec
0.2093 0.1845 0.1770 0.1589 0.1533 0.1480 0.1463 0.1456 0.1458 0.1466 0.1474 0.1479 0.1487 0.1496 0.1504 0.1511 

[TRAIN] Epoch[7](121/1500); Loss: 0.097199; Backpropagation: 0.0984 sec; Batch: 0.4334 sec
0.1482 0.1241 0.1107 0.1058 0.0951 0.0941 0.0906 0.0890 0.0873 0.0868 0.0867 0.0868 0.0871 0.0875 0.0878 0.0878 

[TRAIN] Epoch[7](122/1500); Loss: 0.063948; Backpropagation: 0.0987 sec; Batch: 0.4329 sec
0.1043 0.0848 0.0730 0.0667 0.0610 0.0601 0.0596 0.0582 0.0575 0.0572 0.0571 0.0569 0.0567 0.0564 0.0566 0.0571 

[TRAIN] Epoch[7](123/1500); Loss: 0.060475; Backpropagation: 0.0986 sec; Batch: 0.4326 sec
0.1030 0.1023 0.0766 0.0654 0.0595 0.0551 0.0532 0.0517 0.0510 0.0501 0.0498 0.0498 0.0499 0.0499 0.0502 0.0502 

[TRAIN] Epoch[7](124/1500); Loss: 0.108979; Backpropagation: 0.0985 sec; Batch: 0.4340 sec
0.1365 0.1521 0.1185 0.1113 0.1061 0.1030 0.1018 0.1010 0.1012 0.1012 0.1015 0.1015 0.1015 0.1019 0.1023 0.1024 

[TRAIN] Epoch[7](125/1500); Loss: 0.122800; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1482 0.1659 0.1346 0.1228 0.1210 0.1178 0.1164 0.1157 0.1153 0.1149 0.1146 0.1150 0.1155 0.1156 0.1156 0.1158 

[TRAIN] Epoch[7](126/1500); Loss: 0.157207; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1879 0.1992 0.1714 0.1623 0.1550 0.1531 0.1506 0.1496 0.1490 0.1483 0.1478 0.1477 0.1478 0.1483 0.1484 0.1488 

[TRAIN] Epoch[7](127/1500); Loss: 0.116673; Backpropagation: 0.0998 sec; Batch: 0.4347 sec
0.1430 0.1573 0.1236 0.1143 0.1128 0.1124 0.1121 0.1111 0.1110 0.1105 0.1099 0.1098 0.1097 0.1097 0.1097 0.1097 

[TRAIN] Epoch[7](128/1500); Loss: 0.116901; Backpropagation: 0.0994 sec; Batch: 0.4337 sec
0.2172 0.1842 0.1673 0.1325 0.1202 0.1030 0.0981 0.0948 0.0943 0.0945 0.0942 0.0937 0.0936 0.0938 0.0945 0.0944 

[TRAIN] Epoch[7](129/1500); Loss: 0.081566; Backpropagation: 0.0993 sec; Batch: 0.4336 sec
0.1322 0.1182 0.1028 0.0849 0.0777 0.0752 0.0739 0.0733 0.0724 0.0714 0.0707 0.0707 0.0707 0.0704 0.0704 0.0702 

[TRAIN] Epoch[7](130/1500); Loss: 0.102247; Backpropagation: 0.0992 sec; Batch: 0.4342 sec
0.2069 0.1786 0.1654 0.1264 0.1123 0.0908 0.0789 0.0751 0.0752 0.0762 0.0754 0.0746 0.0744 0.0752 0.0752 0.0752 

[TRAIN] Epoch[7](131/1500); Loss: 0.124492; Backpropagation: 0.0985 sec; Batch: 0.4340 sec
0.1718 0.1779 0.1519 0.1346 0.1212 0.1160 0.1147 0.1135 0.1125 0.1118 0.1117 0.1113 0.1109 0.1108 0.1106 0.1108 

[TRAIN] Epoch[7](132/1500); Loss: 0.103917; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1525 0.1376 0.1231 0.1073 0.1025 0.0993 0.0975 0.0955 0.0941 0.0933 0.0930 0.0934 0.0933 0.0934 0.0936 0.0934 

[TRAIN] Epoch[7](133/1500); Loss: 0.056530; Backpropagation: 0.0983 sec; Batch: 0.4327 sec
0.0898 0.0752 0.0670 0.0569 0.0536 0.0530 0.0528 0.0520 0.0511 0.0503 0.0500 0.0502 0.0504 0.0506 0.0506 0.0510 

[TRAIN] Epoch[7](134/1500); Loss: 0.100113; Backpropagation: 0.0995 sec; Batch: 0.4349 sec
0.1624 0.1500 0.1297 0.1107 0.1079 0.1031 0.0875 0.0866 0.0856 0.0837 0.0827 0.0827 0.0827 0.0823 0.0819 0.0823 

[TRAIN] Epoch[7](135/1500); Loss: 0.056713; Backpropagation: 0.0986 sec; Batch: 0.4333 sec
0.0888 0.0860 0.0690 0.0660 0.0635 0.0567 0.0544 0.0520 0.0500 0.0482 0.0467 0.0457 0.0452 0.0452 0.0451 0.0449 

[TRAIN] Epoch[7](136/1500); Loss: 0.067685; Backpropagation: 0.0983 sec; Batch: 0.4331 sec
0.1196 0.0882 0.0862 0.0690 0.0625 0.0623 0.0627 0.0626 0.0604 0.0584 0.0584 0.0585 0.0581 0.0583 0.0585 0.0592 

[TRAIN] Epoch[7](137/1500); Loss: 0.090334; Backpropagation: 0.0983 sec; Batch: 0.4326 sec
0.1369 0.1410 0.1120 0.0947 0.0850 0.0837 0.0823 0.0811 0.0799 0.0795 0.0788 0.0783 0.0780 0.0779 0.0781 0.0781 

[TRAIN] Epoch[7](138/1500); Loss: 0.101852; Backpropagation: 0.0983 sec; Batch: 0.4329 sec
0.1108 0.1381 0.1037 0.1029 0.1004 0.0985 0.0971 0.0969 0.0972 0.0970 0.0969 0.0973 0.0978 0.0982 0.0984 0.0984 

[TRAIN] Epoch[7](139/1500); Loss: 0.117728; Backpropagation: 0.0984 sec; Batch: 0.4328 sec
0.1808 0.1607 0.1400 0.1161 0.1104 0.1147 0.1121 0.1105 0.1081 0.1060 0.1048 0.1042 0.1043 0.1042 0.1036 0.1032 

[TRAIN] Epoch[7](140/1500); Loss: 0.121770; Backpropagation: 0.0958 sec; Batch: 0.4297 sec
0.1504 0.1430 0.1312 0.1239 0.1197 0.1183 0.1177 0.1168 0.1160 0.1155 0.1156 0.1158 0.1160 0.1160 0.1160 0.1163 

[TRAIN] Epoch[7](141/1500); Loss: 0.095094; Backpropagation: 0.0959 sec; Batch: 0.4305 sec
0.1355 0.1538 0.1120 0.0936 0.0909 0.0895 0.0878 0.0862 0.0851 0.0847 0.0842 0.0838 0.0836 0.0836 0.0836 0.0836 

[TRAIN] Epoch[7](142/1500); Loss: 0.101109; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1368 0.1281 0.1152 0.1080 0.1015 0.0965 0.0946 0.0931 0.0927 0.0927 0.0930 0.0931 0.0931 0.0931 0.0931 0.0934 

[TRAIN] Epoch[7](143/1500); Loss: 0.212606; Backpropagation: 0.0934 sec; Batch: 0.4266 sec
0.2570 0.2476 0.2316 0.2141 0.2098 0.2081 0.2053 0.2053 0.2049 0.2043 0.2036 0.2033 0.2028 0.2021 0.2011 0.2007 

[TRAIN] Epoch[7](144/1500); Loss: 0.166627; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.2463 0.2287 0.2137 0.1760 0.1627 0.1525 0.1501 0.1491 0.1490 0.1485 0.1478 0.1476 0.1479 0.1487 0.1488 0.1486 

[TRAIN] Epoch[7](145/1500); Loss: 0.046403; Backpropagation: 0.0940 sec; Batch: 0.4306 sec
0.0898 0.0627 0.0599 0.0458 0.0422 0.0409 0.0405 0.0404 0.0396 0.0392 0.0391 0.0394 0.0399 0.0405 0.0410 0.0416 

[TRAIN] Epoch[7](146/1500); Loss: 0.139103; Backpropagation: 0.0981 sec; Batch: 0.4324 sec
0.2656 0.2229 0.2113 0.1636 0.1443 0.1226 0.1138 0.1069 0.1084 0.1081 0.1088 0.1091 0.1092 0.1097 0.1105 0.1108 

[TRAIN] Epoch[7](147/1500); Loss: 0.059506; Backpropagation: 0.0959 sec; Batch: 0.4301 sec
0.0871 0.1015 0.0692 0.0623 0.0594 0.0561 0.0540 0.0523 0.0516 0.0515 0.0515 0.0509 0.0509 0.0512 0.0514 0.0513 

[TRAIN] Epoch[7](148/1500); Loss: 0.108557; Backpropagation: 0.0936 sec; Batch: 0.4273 sec
0.1884 0.2032 0.1527 0.1158 0.1068 0.0937 0.0894 0.0890 0.0887 0.0878 0.0866 0.0862 0.0863 0.0873 0.0875 0.0875 

[TRAIN] Epoch[7](149/1500); Loss: 0.086813; Backpropagation: 0.0939 sec; Batch: 0.4284 sec
0.1380 0.1201 0.1064 0.0925 0.0850 0.0798 0.0784 0.0780 0.0771 0.0765 0.0761 0.0760 0.0759 0.0761 0.0764 0.0768 

[TRAIN] Epoch[7](150/1500); Loss: 0.109350; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1407 0.1549 0.1219 0.1091 0.1058 0.1041 0.1026 0.1020 0.1015 0.1013 0.1009 0.1007 0.1007 0.1009 0.1011 0.1013 

[TRAIN] Epoch[7](151/1500); Loss: 0.096078; Backpropagation: 0.0948 sec; Batch: 0.4289 sec
0.1794 0.2029 0.1489 0.0997 0.0901 0.0834 0.0785 0.0762 0.0742 0.0725 0.0714 0.0713 0.0717 0.0721 0.0723 0.0725 

[TRAIN] Epoch[7](152/1500); Loss: 0.092479; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1946 0.2286 0.1602 0.0975 0.0751 0.0733 0.0691 0.0674 0.0655 0.0640 0.0640 0.0639 0.0639 0.0640 0.0640 0.0645 

[TRAIN] Epoch[7](153/1500); Loss: 0.098244; Backpropagation: 0.0941 sec; Batch: 0.4283 sec
0.1773 0.1449 0.1352 0.1105 0.0940 0.0907 0.0857 0.0844 0.0831 0.0819 0.0814 0.0812 0.0808 0.0805 0.0802 0.0801 

[TRAIN] Epoch[7](154/1500); Loss: 0.054824; Backpropagation: 0.0938 sec; Batch: 0.4274 sec
0.1357 0.1053 0.0856 0.0542 0.0454 0.0497 0.0472 0.0431 0.0403 0.0384 0.0380 0.0380 0.0384 0.0388 0.0393 0.0398 

[TRAIN] Epoch[7](155/1500); Loss: 0.059839; Backpropagation: 0.0934 sec; Batch: 0.4279 sec
0.1524 0.1007 0.0824 0.0741 0.0592 0.0516 0.0479 0.0449 0.0426 0.0422 0.0426 0.0421 0.0424 0.0433 0.0441 0.0450 

[TRAIN] Epoch[7](156/1500); Loss: 0.107937; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1512 0.1293 0.1180 0.1073 0.1011 0.1044 0.1034 0.1025 0.1015 0.1005 0.1005 0.1007 0.1013 0.1015 0.1015 0.1024 

[TRAIN] Epoch[7](157/1500); Loss: 0.143878; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.2072 0.2018 0.1811 0.1526 0.1427 0.1342 0.1317 0.1307 0.1298 0.1289 0.1281 0.1274 0.1269 0.1265 0.1264 0.1261 

[TRAIN] Epoch[7](158/1500); Loss: 0.080887; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1412 0.1098 0.0986 0.0853 0.0792 0.0811 0.0788 0.0753 0.0710 0.0680 0.0675 0.0672 0.0675 0.0675 0.0679 0.0682 

[TRAIN] Epoch[7](159/1500); Loss: 0.099059; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1371 0.1552 0.1124 0.0959 0.0933 0.0931 0.0916 0.0906 0.0903 0.0901 0.0894 0.0889 0.0894 0.0894 0.0892 0.0890 

[TRAIN] Epoch[7](160/1500); Loss: 0.113716; Backpropagation: 0.0934 sec; Batch: 0.4267 sec
0.1517 0.1233 0.1219 0.1151 0.1112 0.1126 0.1120 0.1107 0.1087 0.1073 0.1077 0.1080 0.1072 0.1063 0.1073 0.1085 

[TRAIN] Epoch[7](161/1500); Loss: 0.102809; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1389 0.1132 0.1075 0.1066 0.1019 0.1006 0.0995 0.0986 0.0979 0.0977 0.0974 0.0971 0.0969 0.0970 0.0971 0.0972 

[TRAIN] Epoch[7](162/1500); Loss: 0.153148; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2565 0.2288 0.2067 0.1626 0.1451 0.1375 0.1308 0.1320 0.1317 0.1312 0.1311 0.1311 0.1310 0.1311 0.1313 0.1316 

[TRAIN] Epoch[7](163/1500); Loss: 0.048786; Backpropagation: 0.0982 sec; Batch: 0.4336 sec
0.0813 0.0768 0.0583 0.0494 0.0465 0.0445 0.0427 0.0441 0.0431 0.0420 0.0414 0.0418 0.0415 0.0417 0.0424 0.0432 

[TRAIN] Epoch[7](164/1500); Loss: 0.077076; Backpropagation: 0.0981 sec; Batch: 0.4327 sec
0.1115 0.1041 0.0920 0.0797 0.0765 0.0733 0.0718 0.0704 0.0696 0.0692 0.0689 0.0688 0.0689 0.0691 0.0695 0.0698 

[TRAIN] Epoch[7](165/1500); Loss: 0.142992; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1686 0.1858 0.1580 0.1473 0.1419 0.1385 0.1381 0.1374 0.1366 0.1356 0.1350 0.1345 0.1335 0.1327 0.1323 0.1320 

[TRAIN] Epoch[7](166/1500); Loss: 0.114298; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1656 0.1562 0.1428 0.1258 0.1171 0.1091 0.1046 0.1028 0.1021 0.1012 0.1008 0.1005 0.1001 0.1002 0.1000 0.0999 

[TRAIN] Epoch[7](167/1500); Loss: 0.102371; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.1418 0.1206 0.1141 0.1100 0.1063 0.0993 0.0975 0.0959 0.0956 0.0953 0.0946 0.0941 0.0938 0.0932 0.0930 0.0929 

[TRAIN] Epoch[7](168/1500); Loss: 0.152312; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1724 0.1610 0.1574 0.1640 0.1587 0.1522 0.1503 0.1494 0.1489 0.1481 0.1472 0.1463 0.1460 0.1456 0.1451 0.1444 

[TRAIN] Epoch[7](169/1500); Loss: 0.139256; Backpropagation: 0.0959 sec; Batch: 0.4312 sec
0.2614 0.2129 0.1989 0.1436 0.1313 0.1179 0.1162 0.1169 0.1159 0.1158 0.1157 0.1160 0.1162 0.1162 0.1167 0.1168 

[TRAIN] Epoch[7](170/1500); Loss: 0.059600; Backpropagation: 0.0957 sec; Batch: 0.4307 sec
0.0885 0.0792 0.0658 0.0649 0.0593 0.0557 0.0553 0.0545 0.0538 0.0542 0.0534 0.0534 0.0535 0.0543 0.0539 0.0538 

[TRAIN] Epoch[7](171/1500); Loss: 0.062873; Backpropagation: 0.0936 sec; Batch: 0.4276 sec
0.0991 0.1170 0.0781 0.0639 0.0598 0.0569 0.0549 0.0534 0.0536 0.0534 0.0528 0.0524 0.0523 0.0526 0.0530 0.0529 

[TRAIN] Epoch[7](172/1500); Loss: 0.077861; Backpropagation: 0.0939 sec; Batch: 0.4283 sec
0.1625 0.1573 0.1263 0.0812 0.0723 0.0644 0.0625 0.0613 0.0594 0.0582 0.0580 0.0568 0.0563 0.0564 0.0564 0.0564 

[TRAIN] Epoch[7](173/1500); Loss: 0.080815; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1366 0.1255 0.1035 0.0940 0.0798 0.0731 0.0707 0.0696 0.0685 0.0677 0.0675 0.0673 0.0672 0.0670 0.0672 0.0678 

[TRAIN] Epoch[7](174/1500); Loss: 0.096799; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1434 0.1235 0.1133 0.1036 0.0968 0.0938 0.0901 0.0875 0.0876 0.0881 0.0874 0.0868 0.0867 0.0866 0.0865 0.0872 

[TRAIN] Epoch[7](175/1500); Loss: 0.131393; Backpropagation: 0.0942 sec; Batch: 0.4288 sec
0.1743 0.1702 0.1532 0.1388 0.1328 0.1244 0.1235 0.1227 0.1219 0.1210 0.1208 0.1206 0.1201 0.1192 0.1194 0.1193 

[TRAIN] Epoch[7](176/1500); Loss: 0.131985; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.1752 0.1733 0.1602 0.1472 0.1385 0.1289 0.1257 0.1234 0.1213 0.1202 0.1181 0.1170 0.1169 0.1158 0.1153 0.1147 

[TRAIN] Epoch[7](177/1500); Loss: 0.089913; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1209 0.1388 0.1078 0.0935 0.0893 0.0844 0.0814 0.0803 0.0803 0.0805 0.0801 0.0800 0.0804 0.0803 0.0801 0.0803 

[TRAIN] Epoch[7](178/1500); Loss: 0.057315; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.0889 0.1025 0.0662 0.0586 0.0587 0.0534 0.0501 0.0497 0.0497 0.0487 0.0481 0.0484 0.0487 0.0482 0.0483 0.0490 

[TRAIN] Epoch[7](179/1500); Loss: 0.107020; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.2161 0.2210 0.1821 0.1317 0.1022 0.0835 0.0792 0.0774 0.0775 0.0769 0.0783 0.0776 0.0773 0.0767 0.0773 0.0774 

[TRAIN] Epoch[7](180/1500); Loss: 0.157095; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1885 0.1866 0.1742 0.1712 0.1648 0.1538 0.1494 0.1484 0.1492 0.1491 0.1480 0.1468 0.1465 0.1461 0.1457 0.1451 

[TRAIN] Epoch[7](181/1500); Loss: 0.138667; Backpropagation: 0.0960 sec; Batch: 0.4305 sec
0.2306 0.1842 0.1740 0.1409 0.1293 0.1210 0.1222 0.1225 0.1212 0.1215 0.1231 0.1239 0.1247 0.1255 0.1267 0.1273 

[TRAIN] Epoch[7](182/1500); Loss: 0.093474; Backpropagation: 0.0942 sec; Batch: 0.4285 sec
0.1224 0.1146 0.1036 0.0954 0.0940 0.0905 0.0900 0.0895 0.0883 0.0872 0.0872 0.0868 0.0863 0.0863 0.0865 0.0871 

[TRAIN] Epoch[7](183/1500); Loss: 0.114132; Backpropagation: 0.0935 sec; Batch: 0.4280 sec
0.1507 0.1537 0.1310 0.1212 0.1156 0.1082 0.1074 0.1065 0.1058 0.1053 0.1046 0.1045 0.1040 0.1035 0.1022 0.1020 

[TRAIN] Epoch[7](184/1500); Loss: 0.057669; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.0975 0.1124 0.0763 0.0682 0.0575 0.0481 0.0482 0.0483 0.0491 0.0468 0.0459 0.0459 0.0457 0.0444 0.0434 0.0449 

[TRAIN] Epoch[7](185/1500); Loss: 0.085977; Backpropagation: 0.0937 sec; Batch: 0.4400 sec
0.1920 0.1531 0.1335 0.0914 0.0818 0.0725 0.0679 0.0658 0.0657 0.0669 0.0652 0.0634 0.0635 0.0643 0.0644 0.0642 

[TRAIN] Epoch[7](186/1500); Loss: 0.081296; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1438 0.1085 0.1001 0.0914 0.0854 0.0762 0.0708 0.0700 0.0709 0.0693 0.0685 0.0692 0.0696 0.0685 0.0686 0.0698 

[TRAIN] Epoch[7](187/1500); Loss: 0.098194; Backpropagation: 0.0942 sec; Batch: 0.4284 sec
0.1500 0.1365 0.1222 0.1270 0.1088 0.0889 0.0869 0.0863 0.0852 0.0840 0.0830 0.0828 0.0831 0.0825 0.0817 0.0822 

[TRAIN] Epoch[7](188/1500); Loss: 0.105513; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1552 0.1384 0.1204 0.1174 0.1091 0.0994 0.0980 0.0965 0.0953 0.0945 0.0942 0.0942 0.0937 0.0938 0.0941 0.0940 

[TRAIN] Epoch[7](189/1500); Loss: 0.117500; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1674 0.1768 0.1481 0.1247 0.1148 0.1091 0.1065 0.1058 0.1044 0.1041 0.1038 0.1031 0.1031 0.1025 0.1026 0.1032 

[TRAIN] Epoch[7](190/1500); Loss: 0.046178; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.0829 0.0595 0.0495 0.0680 0.0573 0.0381 0.0375 0.0386 0.0406 0.0370 0.0365 0.0376 0.0404 0.0383 0.0379 0.0390 

[TRAIN] Epoch[7](191/1500); Loss: 0.132160; Backpropagation: 0.0942 sec; Batch: 0.4280 sec
0.1683 0.1751 0.1550 0.1381 0.1323 0.1283 0.1255 0.1236 0.1224 0.1222 0.1216 0.1211 0.1201 0.1205 0.1202 0.1203 

[TRAIN] Epoch[7](192/1500); Loss: 0.084534; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.1305 0.1353 0.1057 0.0963 0.0871 0.0756 0.0740 0.0736 0.0740 0.0730 0.0726 0.0717 0.0713 0.0715 0.0703 0.0704 

[TRAIN] Epoch[7](193/1500); Loss: 0.086339; Backpropagation: 0.0958 sec; Batch: 0.4311 sec
0.1140 0.1342 0.0967 0.0878 0.0861 0.0801 0.0787 0.0779 0.0785 0.0781 0.0784 0.0783 0.0782 0.0780 0.0782 0.0784 

[TRAIN] Epoch[7](194/1500); Loss: 0.111540; Backpropagation: 0.0957 sec; Batch: 0.4305 sec
0.1352 0.1515 0.1275 0.1210 0.1142 0.1086 0.1056 0.1047 0.1038 0.1030 0.1025 0.1022 0.1017 0.1013 0.1011 0.1008 

[TRAIN] Epoch[7](195/1500); Loss: 0.065752; Backpropagation: 0.0940 sec; Batch: 0.4279 sec
0.1612 0.2411 0.1327 0.0511 0.0430 0.0383 0.0341 0.0337 0.0347 0.0414 0.0400 0.0373 0.0381 0.0394 0.0434 0.0425 

[TRAIN] Epoch[7](196/1500); Loss: 0.087527; Backpropagation: 0.0940 sec; Batch: 0.4278 sec
0.1237 0.1037 0.0963 0.1002 0.0901 0.0824 0.0808 0.0799 0.0793 0.0790 0.0794 0.0805 0.0806 0.0807 0.0815 0.0824 

[TRAIN] Epoch[7](197/1500); Loss: 0.105326; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1497 0.1301 0.1197 0.1097 0.1088 0.1002 0.0988 0.0988 0.0989 0.0968 0.0960 0.0956 0.0960 0.0953 0.0952 0.0956 

[TRAIN] Epoch[7](198/1500); Loss: 0.099801; Backpropagation: 0.0958 sec; Batch: 0.4300 sec
0.1630 0.1425 0.1284 0.1078 0.1053 0.1052 0.0828 0.0834 0.0820 0.0819 0.0828 0.0834 0.0851 0.0860 0.0876 0.0896 

[TRAIN] Epoch[7](199/1500); Loss: 0.105226; Backpropagation: 0.0942 sec; Batch: 0.4283 sec
0.1937 0.1422 0.1313 0.1083 0.1079 0.1011 0.0926 0.0915 0.0918 0.0894 0.0892 0.0894 0.0895 0.0882 0.0888 0.0886 

[TRAIN] Epoch[7](200/1500); Loss: 0.111597; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1502 0.1378 0.1261 0.1245 0.1169 0.1060 0.1034 0.1047 0.1034 0.1018 0.1020 0.1026 0.1018 0.1008 0.1015 0.1019 

[TRAIN] Epoch[7](201/1500); Loss: 0.063202; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.0893 0.0712 0.0616 0.0641 0.0666 0.0596 0.0583 0.0587 0.0585 0.0593 0.0584 0.0601 0.0597 0.0611 0.0621 0.0626 

[TRAIN] Epoch[7](202/1500); Loss: 0.108743; Backpropagation: 0.0939 sec; Batch: 0.4275 sec
0.1425 0.1651 0.1340 0.1184 0.1085 0.0999 0.0979 0.0966 0.0969 0.0971 0.0967 0.0971 0.0972 0.0975 0.0971 0.0973 

[TRAIN] Epoch[7](203/1500); Loss: 0.120934; Backpropagation: 0.0952 sec; Batch: 0.4297 sec
0.1985 0.1772 0.1560 0.1267 0.1164 0.1117 0.1109 0.1068 0.1049 0.1041 0.1047 0.1044 0.1026 0.1028 0.1032 0.1040 

[TRAIN] Epoch[7](204/1500); Loss: 0.099070; Backpropagation: 0.0941 sec; Batch: 0.4291 sec
0.1326 0.1179 0.1128 0.1113 0.1064 0.0966 0.0939 0.0937 0.0925 0.0907 0.0899 0.0900 0.0899 0.0895 0.0888 0.0887 

[TRAIN] Epoch[7](205/1500); Loss: 0.137845; Backpropagation: 0.0939 sec; Batch: 0.4292 sec
0.2288 0.2038 0.1902 0.1641 0.1483 0.1243 0.1211 0.1189 0.1151 0.1141 0.1142 0.1136 0.1125 0.1124 0.1120 0.1123 

[TRAIN] Epoch[7](206/1500); Loss: 0.058745; Backpropagation: 0.0933 sec; Batch: 0.4281 sec
0.1010 0.1461 0.0686 0.0538 0.0493 0.0491 0.0448 0.0492 0.0465 0.0452 0.0449 0.0475 0.0471 0.0470 0.0494 0.0505 

[TRAIN] Epoch[7](207/1500); Loss: 0.139973; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2011 0.1752 0.1661 0.1468 0.1418 0.1334 0.1317 0.1301 0.1288 0.1264 0.1263 0.1270 0.1268 0.1260 0.1258 0.1263 

[TRAIN] Epoch[7](208/1500); Loss: 0.141077; Backpropagation: 0.0931 sec; Batch: 0.4266 sec
0.2119 0.2008 0.1829 0.1497 0.1353 0.1279 0.1253 0.1246 0.1248 0.1252 0.1243 0.1239 0.1244 0.1251 0.1251 0.1261 

[TRAIN] Epoch[7](209/1500); Loss: 0.098144; Backpropagation: 0.0936 sec; Batch: 0.4277 sec
0.1146 0.1067 0.1020 0.1117 0.1020 0.0915 0.0930 0.0968 0.0944 0.0923 0.0924 0.0952 0.0934 0.0931 0.0948 0.0963 

[TRAIN] Epoch[7](210/1500); Loss: 0.121204; Backpropagation: 0.0982 sec; Batch: 0.4327 sec
0.1786 0.1571 0.1424 0.1338 0.1258 0.1174 0.1118 0.1100 0.1109 0.1086 0.1070 0.1070 0.1072 0.1072 0.1068 0.1076 

[TRAIN] Epoch[7](211/1500); Loss: 0.105914; Backpropagation: 0.0959 sec; Batch: 0.4299 sec
0.1291 0.1350 0.1163 0.1240 0.1082 0.1004 0.0997 0.0998 0.0990 0.0980 0.0977 0.0976 0.0969 0.0978 0.0976 0.0974 

[TRAIN] Epoch[7](212/1500); Loss: 0.086274; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2021 0.1905 0.1502 0.0804 0.0685 0.0793 0.0631 0.0622 0.0612 0.0604 0.0597 0.0607 0.0610 0.0601 0.0606 0.0605 

[TRAIN] Epoch[7](213/1500); Loss: 0.065792; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1000 0.0798 0.0752 0.0833 0.0676 0.0605 0.0595 0.0600 0.0591 0.0576 0.0570 0.0581 0.0583 0.0584 0.0589 0.0593 

[TRAIN] Epoch[7](214/1500); Loss: 0.146049; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.2040 0.2013 0.1732 0.1513 0.1431 0.1392 0.1340 0.1323 0.1329 0.1327 0.1324 0.1325 0.1323 0.1311 0.1320 0.1326 

[TRAIN] Epoch[7](215/1500); Loss: 0.070496; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.0934 0.1269 0.0786 0.0711 0.0710 0.0645 0.0640 0.0632 0.0624 0.0618 0.0625 0.0628 0.0617 0.0608 0.0614 0.0620 

[TRAIN] Epoch[7](216/1500); Loss: 0.057319; Backpropagation: 0.0940 sec; Batch: 0.4290 sec
0.0674 0.0746 0.0558 0.0564 0.0558 0.0539 0.0526 0.0541 0.0536 0.0538 0.0543 0.0565 0.0557 0.0566 0.0580 0.0581 

[TRAIN] Epoch[7](217/1500); Loss: 0.122581; Backpropagation: 0.0941 sec; Batch: 0.4288 sec
0.1635 0.1626 0.1433 0.1327 0.1249 0.1172 0.1156 0.1135 0.1124 0.1112 0.1107 0.1100 0.1106 0.1110 0.1113 0.1107 

[TRAIN] Epoch[7](218/1500); Loss: 0.111265; Backpropagation: 0.0938 sec; Batch: 0.4271 sec
0.1619 0.1493 0.1315 0.1203 0.1115 0.1075 0.1038 0.1016 0.1014 0.0991 0.0991 0.0995 0.0988 0.0983 0.0983 0.0983 

[TRAIN] Epoch[7](219/1500); Loss: 0.133141; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1999 0.1718 0.1611 0.1390 0.1350 0.1276 0.1225 0.1221 0.1210 0.1196 0.1192 0.1190 0.1180 0.1179 0.1176 0.1189 

[TRAIN] Epoch[7](220/1500); Loss: 0.150449; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.2370 0.2113 0.1998 0.1599 0.1486 0.1427 0.1334 0.1309 0.1309 0.1308 0.1300 0.1301 0.1303 0.1307 0.1304 0.1304 

[TRAIN] Epoch[7](221/1500); Loss: 0.105510; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1466 0.1214 0.1161 0.1182 0.1132 0.1005 0.0989 0.0987 0.0993 0.0968 0.0967 0.0969 0.0971 0.0968 0.0953 0.0958 

[TRAIN] Epoch[7](222/1500); Loss: 0.079589; Backpropagation: 0.0981 sec; Batch: 0.4325 sec
0.1141 0.1387 0.0888 0.0780 0.0782 0.0718 0.0707 0.0701 0.0699 0.0687 0.0712 0.0701 0.0696 0.0703 0.0727 0.0705 

[TRAIN] Epoch[7](223/1500); Loss: 0.094952; Backpropagation: 0.0958 sec; Batch: 0.4301 sec
0.1629 0.1925 0.1253 0.0947 0.0875 0.0815 0.0822 0.0779 0.0765 0.0770 0.0777 0.0766 0.0752 0.0760 0.0788 0.0771 

[TRAIN] Epoch[7](224/1500); Loss: 0.093699; Backpropagation: 0.0936 sec; Batch: 0.4271 sec
0.1476 0.1328 0.1142 0.1105 0.0995 0.0896 0.0846 0.0824 0.0809 0.0804 0.0785 0.0784 0.0795 0.0790 0.0800 0.0813 

[TRAIN] Epoch[7](225/1500); Loss: 0.084958; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1202 0.1302 0.1023 0.0878 0.0832 0.0796 0.0781 0.0779 0.0765 0.0756 0.0753 0.0748 0.0750 0.0747 0.0738 0.0743 

[TRAIN] Epoch[7](226/1500); Loss: 0.043354; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.0982 0.0662 0.0485 0.0644 0.0546 0.0331 0.0293 0.0308 0.0311 0.0321 0.0308 0.0320 0.0343 0.0342 0.0356 0.0386 

[TRAIN] Epoch[7](227/1500); Loss: 0.067435; Backpropagation: 0.0934 sec; Batch: 0.4276 sec
0.1144 0.0937 0.0784 0.0736 0.0708 0.0645 0.0614 0.0600 0.0587 0.0576 0.0579 0.0572 0.0571 0.0574 0.0583 0.0580 

[TRAIN] Epoch[7](228/1500); Loss: 0.105585; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1496 0.1615 0.1237 0.1069 0.1029 0.0973 0.0962 0.0966 0.0967 0.0952 0.0938 0.0938 0.0937 0.0939 0.0935 0.0938 

[TRAIN] Epoch[7](229/1500); Loss: 0.114014; Backpropagation: 0.0940 sec; Batch: 0.4281 sec
0.1382 0.1374 0.1252 0.1198 0.1145 0.1084 0.1085 0.1081 0.1082 0.1083 0.1082 0.1075 0.1078 0.1079 0.1080 0.1082 

[TRAIN] Epoch[7](230/1500); Loss: 0.107807; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.2178 0.1709 0.1525 0.1028 0.1030 0.0906 0.0881 0.0881 0.0881 0.0879 0.0875 0.0883 0.0896 0.0895 0.0894 0.0908 

[TRAIN] Epoch[7](231/1500); Loss: 0.153065; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.2491 0.2225 0.2069 0.1717 0.1564 0.1359 0.1311 0.1322 0.1305 0.1296 0.1294 0.1305 0.1305 0.1302 0.1304 0.1320 

[TRAIN] Epoch[7](232/1500); Loss: 0.116749; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.1393 0.1500 0.1265 0.1200 0.1172 0.1131 0.1118 0.1112 0.1112 0.1101 0.1094 0.1095 0.1095 0.1102 0.1095 0.1096 

[TRAIN] Epoch[7](233/1500); Loss: 0.129651; Backpropagation: 0.0935 sec; Batch: 0.4334 sec
0.1666 0.1655 0.1405 0.1334 0.1311 0.1234 0.1221 0.1230 0.1226 0.1222 0.1208 0.1211 0.1213 0.1203 0.1204 0.1202 

[TRAIN] Epoch[7](234/1500); Loss: 0.078906; Backpropagation: 0.0957 sec; Batch: 0.4298 sec
0.1211 0.0919 0.0875 0.1087 0.0917 0.0737 0.0716 0.0719 0.0718 0.0689 0.0679 0.0680 0.0682 0.0666 0.0663 0.0669 

[TRAIN] Epoch[7](235/1500); Loss: 0.082323; Backpropagation: 0.0942 sec; Batch: 0.4281 sec
0.1637 0.2338 0.0967 0.0740 0.0604 0.0557 0.0582 0.0639 0.0600 0.0590 0.0609 0.0653 0.0638 0.0644 0.0676 0.0697 

[TRAIN] Epoch[7](236/1500); Loss: 0.123282; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1650 0.1613 0.1428 0.1422 0.1318 0.1170 0.1170 0.1165 0.1148 0.1116 0.1094 0.1097 0.1090 0.1082 0.1078 0.1085 

[TRAIN] Epoch[7](237/1500); Loss: 0.088925; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1065 0.1251 0.0908 0.0899 0.0909 0.0919 0.0852 0.0824 0.0829 0.0824 0.0823 0.0815 0.0820 0.0825 0.0835 0.0831 

[TRAIN] Epoch[7](238/1500); Loss: 0.153718; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1913 0.1648 0.1573 0.1820 0.1682 0.1489 0.1463 0.1460 0.1466 0.1470 0.1448 0.1437 0.1439 0.1440 0.1423 0.1424 

[TRAIN] Epoch[7](239/1500); Loss: 0.105109; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1296 0.1098 0.1082 0.1310 0.1237 0.1059 0.0992 0.0971 0.0977 0.0976 0.0965 0.0963 0.0972 0.0979 0.0972 0.0970 

[TRAIN] Epoch[7](240/1500); Loss: 0.115825; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.2220 0.1931 0.1682 0.1140 0.1080 0.1158 0.1022 0.0945 0.0938 0.0937 0.0925 0.0915 0.0909 0.0911 0.0907 0.0911 

[TRAIN] Epoch[7](241/1500); Loss: 0.099406; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1254 0.1375 0.1048 0.1098 0.1074 0.0978 0.0923 0.0921 0.0919 0.0913 0.0907 0.0903 0.0893 0.0890 0.0898 0.0910 

[TRAIN] Epoch[7](242/1500); Loss: 0.069058; Backpropagation: 0.0934 sec; Batch: 0.4272 sec
0.1135 0.1108 0.0885 0.0829 0.0737 0.0637 0.0591 0.0583 0.0560 0.0549 0.0550 0.0553 0.0554 0.0574 0.0595 0.0611 

[TRAIN] Epoch[7](243/1500); Loss: 0.124925; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.2370 0.1962 0.1866 0.1322 0.1227 0.1072 0.1025 0.1011 0.1012 0.1006 0.1013 0.1013 0.1011 0.1015 0.1026 0.1038 

[TRAIN] Epoch[7](244/1500); Loss: 0.087850; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.1426 0.2071 0.0710 0.0691 0.0693 0.0727 0.0729 0.0736 0.0747 0.0754 0.0765 0.0783 0.0791 0.0799 0.0809 0.0824 

[TRAIN] Epoch[7](245/1500); Loss: 0.072804; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1004 0.0824 0.0783 0.0800 0.0878 0.0736 0.0649 0.0650 0.0661 0.0668 0.0662 0.0661 0.0665 0.0672 0.0668 0.0666 

[TRAIN] Epoch[7](246/1500); Loss: 0.118376; Backpropagation: 0.0932 sec; Batch: 0.4350 sec
0.1306 0.1296 0.1249 0.1340 0.1322 0.1198 0.1168 0.1145 0.1142 0.1134 0.1120 0.1110 0.1100 0.1099 0.1105 0.1105 

[TRAIN] Epoch[7](247/1500); Loss: 0.122817; Backpropagation: 0.0933 sec; Batch: 0.4294 sec
0.1374 0.1310 0.1240 0.1292 0.1326 0.1262 0.1212 0.1179 0.1180 0.1187 0.1188 0.1185 0.1187 0.1181 0.1175 0.1173 

[TRAIN] Epoch[7](248/1500); Loss: 0.116277; Backpropagation: 0.0934 sec; Batch: 0.4269 sec
0.1748 0.1423 0.1372 0.1166 0.1153 0.1204 0.1168 0.1086 0.1063 0.1053 0.1044 0.1031 0.1023 0.1025 0.1022 0.1021 

[TRAIN] Epoch[7](249/1500); Loss: 0.095932; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1618 0.1567 0.1445 0.1163 0.0986 0.0809 0.0807 0.0830 0.0786 0.0773 0.0766 0.0761 0.0762 0.0757 0.0757 0.0762 

[TRAIN] Epoch[7](250/1500); Loss: 0.128312; Backpropagation: 0.0938 sec; Batch: 0.4275 sec
0.2384 0.1969 0.1913 0.1394 0.1232 0.1124 0.1192 0.1047 0.1024 0.1036 0.1044 0.1037 0.1033 0.1036 0.1034 0.1030 

[TRAIN] Epoch[7](251/1500); Loss: 0.061623; Backpropagation: 0.0942 sec; Batch: 0.4290 sec
0.2112 0.1524 0.1396 0.0481 0.0387 0.0580 0.0624 0.0281 0.0295 0.0309 0.0311 0.0300 0.0300 0.0311 0.0323 0.0326 

[TRAIN] Epoch[7](252/1500); Loss: 0.076849; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1169 0.0843 0.0812 0.0985 0.0938 0.0735 0.0693 0.0676 0.0681 0.0682 0.0677 0.0674 0.0678 0.0682 0.0683 0.0688 

[TRAIN] Epoch[7](253/1500); Loss: 0.059471; Backpropagation: 0.0941 sec; Batch: 0.4279 sec
0.1283 0.1916 0.0459 0.0419 0.0409 0.0414 0.0428 0.0434 0.0439 0.0445 0.0454 0.0463 0.0474 0.0484 0.0491 0.0503 

[TRAIN] Epoch[7](254/1500); Loss: 0.131251; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1755 0.1766 0.1548 0.1342 0.1311 0.1268 0.1276 0.1235 0.1206 0.1207 0.1198 0.1185 0.1177 0.1172 0.1174 0.1180 

[TRAIN] Epoch[7](255/1500); Loss: 0.127643; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1847 0.1602 0.1547 0.1475 0.1308 0.1279 0.1226 0.1148 0.1139 0.1135 0.1128 0.1118 0.1117 0.1117 0.1117 0.1119 

[TRAIN] Epoch[7](256/1500); Loss: 0.096455; Backpropagation: 0.0934 sec; Batch: 0.4275 sec
0.2390 0.1933 0.1833 0.1183 0.1043 0.0787 0.0722 0.0640 0.0637 0.0624 0.0612 0.0599 0.0603 0.0609 0.0609 0.0610 

[TRAIN] Epoch[7](257/1500); Loss: 0.099358; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1433 0.1691 0.1200 0.0970 0.0879 0.0874 0.0871 0.0873 0.0876 0.0880 0.0886 0.0885 0.0888 0.0894 0.0897 0.0898 

[TRAIN] Epoch[7](258/1500); Loss: 0.138718; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1784 0.1582 0.1561 0.1443 0.1469 0.1471 0.1378 0.1320 0.1295 0.1290 0.1293 0.1270 0.1263 0.1261 0.1259 0.1257 

[TRAIN] Epoch[7](259/1500); Loss: 0.074859; Backpropagation: 0.0935 sec; Batch: 0.4274 sec
0.2424 0.1768 0.1640 0.0595 0.0454 0.0762 0.0599 0.0412 0.0411 0.0406 0.0408 0.0410 0.0410 0.0417 0.0426 0.0436 

[TRAIN] Epoch[7](260/1500); Loss: 0.148928; Backpropagation: 0.0936 sec; Batch: 0.4273 sec
0.2004 0.1829 0.1794 0.1606 0.1542 0.1428 0.1426 0.1397 0.1375 0.1361 0.1354 0.1345 0.1344 0.1342 0.1341 0.1339 

[TRAIN] Epoch[7](261/1500); Loss: 0.106229; Backpropagation: 0.0935 sec; Batch: 0.4279 sec
0.1457 0.1340 0.1270 0.1192 0.1146 0.1100 0.1069 0.1009 0.0968 0.0949 0.0937 0.0926 0.0914 0.0909 0.0907 0.0905 

[TRAIN] Epoch[7](262/1500); Loss: 0.071374; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1181 0.0861 0.0866 0.0704 0.0764 0.0793 0.0683 0.0618 0.0616 0.0620 0.0621 0.0615 0.0615 0.0620 0.0621 0.0621 

[TRAIN] Epoch[7](263/1500); Loss: 0.109289; Backpropagation: 0.0958 sec; Batch: 0.4301 sec
0.1486 0.1724 0.1253 0.1040 0.0985 0.0994 0.1015 0.1003 0.0992 0.0989 0.0992 0.0995 0.0998 0.1002 0.1008 0.1010 

[TRAIN] Epoch[7](264/1500); Loss: 0.144048; Backpropagation: 0.0946 sec; Batch: 0.4286 sec
0.1527 0.1510 0.1480 0.1544 0.1559 0.1560 0.1486 0.1447 0.1430 0.1405 0.1383 0.1361 0.1348 0.1341 0.1336 0.1330 

[TRAIN] Epoch[7](265/1500); Loss: 0.083265; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1639 0.1207 0.1143 0.0782 0.0809 0.0819 0.0733 0.0707 0.0689 0.0683 0.0680 0.0680 0.0681 0.0684 0.0689 0.0696 

[TRAIN] Epoch[7](266/1500); Loss: 0.080814; Backpropagation: 0.0924 sec; Batch: 0.4259 sec
0.1054 0.1006 0.0883 0.0794 0.0786 0.0777 0.0764 0.0764 0.0762 0.0761 0.0761 0.0763 0.0761 0.0762 0.0765 0.0768 

[TRAIN] Epoch[7](267/1500); Loss: 0.078562; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.1226 0.0964 0.0935 0.0933 0.0920 0.0788 0.0732 0.0705 0.0693 0.0685 0.0671 0.0666 0.0664 0.0662 0.0662 0.0664 

[TRAIN] Epoch[7](268/1500); Loss: 0.109018; Backpropagation: 0.0924 sec; Batch: 0.4266 sec
0.1489 0.1551 0.1267 0.1131 0.1114 0.1075 0.1024 0.1003 0.0988 0.0982 0.0981 0.0975 0.0968 0.0967 0.0964 0.0964 

[TRAIN] Epoch[7](269/1500); Loss: 0.066834; Backpropagation: 0.0927 sec; Batch: 0.4266 sec
0.1108 0.0836 0.0814 0.0851 0.0683 0.0639 0.0630 0.0606 0.0584 0.0570 0.0568 0.0564 0.0559 0.0560 0.0559 0.0563 

[TRAIN] Epoch[7](270/1500); Loss: 0.158816; Backpropagation: 0.0925 sec; Batch: 0.4264 sec
0.1784 0.1652 0.1640 0.1651 0.1679 0.1657 0.1586 0.1563 0.1550 0.1537 0.1529 0.1523 0.1517 0.1515 0.1514 0.1514 

[TRAIN] Epoch[7](271/1500); Loss: 0.105873; Backpropagation: 0.0925 sec; Batch: 0.4260 sec
0.1412 0.1201 0.1186 0.1071 0.1086 0.1093 0.1031 0.1001 0.0995 0.0990 0.0985 0.0981 0.0977 0.0976 0.0977 0.0978 

[TRAIN] Epoch[7](272/1500); Loss: 0.090249; Backpropagation: 0.0925 sec; Batch: 0.4260 sec
0.1207 0.1133 0.1037 0.0910 0.0875 0.0888 0.0912 0.0829 0.0830 0.0829 0.0829 0.0831 0.0831 0.0832 0.0832 0.0835 

[TRAIN] Epoch[7](273/1500); Loss: 0.087855; Backpropagation: 0.0925 sec; Batch: 0.4261 sec
0.1652 0.1337 0.1220 0.0993 0.0982 0.0864 0.0789 0.0744 0.0720 0.0706 0.0685 0.0676 0.0674 0.0673 0.0671 0.0670 

[TRAIN] Epoch[7](274/1500); Loss: 0.092610; Backpropagation: 0.0943 sec; Batch: 0.4281 sec
0.1343 0.1153 0.1119 0.0904 0.0906 0.0934 0.0911 0.0846 0.0837 0.0837 0.0838 0.0839 0.0837 0.0837 0.0839 0.0839 

[TRAIN] Epoch[7](275/1500); Loss: 0.137759; Backpropagation: 0.0935 sec; Batch: 0.4275 sec
0.1568 0.1457 0.1437 0.1456 0.1392 0.1355 0.1350 0.1349 0.1342 0.1334 0.1331 0.1331 0.1332 0.1334 0.1336 0.1339 

[TRAIN] Epoch[7](276/1500); Loss: 0.055198; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1077 0.1089 0.0763 0.0602 0.0600 0.0486 0.0453 0.0442 0.0432 0.0421 0.0414 0.0409 0.0409 0.0411 0.0411 0.0412 

[TRAIN] Epoch[7](277/1500); Loss: 0.063643; Backpropagation: 0.0926 sec; Batch: 0.4266 sec
0.0742 0.0821 0.0725 0.0706 0.0681 0.0652 0.0622 0.0602 0.0595 0.0586 0.0580 0.0578 0.0576 0.0572 0.0572 0.0574 

[TRAIN] Epoch[7](278/1500); Loss: 0.052950; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.0791 0.1292 0.0516 0.0443 0.0447 0.0451 0.0446 0.0443 0.0444 0.0443 0.0446 0.0451 0.0456 0.0461 0.0468 0.0475 

[TRAIN] Epoch[7](279/1500); Loss: 0.115390; Backpropagation: 0.0933 sec; Batch: 0.4279 sec
0.1995 0.1819 0.1672 0.1267 0.1164 0.1012 0.1097 0.0998 0.0953 0.0944 0.0931 0.0925 0.0922 0.0920 0.0920 0.0922 

[TRAIN] Epoch[7](280/1500); Loss: 0.140730; Backpropagation: 0.0936 sec; Batch: 0.4291 sec
0.1732 0.1557 0.1532 0.1496 0.1477 0.1408 0.1379 0.1366 0.1345 0.1325 0.1320 0.1318 0.1317 0.1316 0.1314 0.1315 

[TRAIN] Epoch[7](281/1500); Loss: 0.072573; Backpropagation: 0.0937 sec; Batch: 0.4272 sec
0.1529 0.1218 0.1172 0.0894 0.0754 0.0598 0.0584 0.0564 0.0556 0.0532 0.0529 0.0528 0.0532 0.0537 0.0541 0.0545 

[TRAIN] Epoch[7](282/1500); Loss: 0.086343; Backpropagation: 0.0932 sec; Batch: 0.4266 sec
0.1847 0.1472 0.1415 0.1045 0.0917 0.0677 0.0681 0.0693 0.0643 0.0636 0.0633 0.0633 0.0633 0.0631 0.0629 0.0630 

[TRAIN] Epoch[7](283/1500); Loss: 0.058601; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1505 0.1022 0.0922 0.0565 0.0689 0.0444 0.0427 0.0417 0.0412 0.0412 0.0414 0.0418 0.0423 0.0428 0.0434 0.0442 

[TRAIN] Epoch[7](284/1500); Loss: 0.130061; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1455 0.1462 0.1336 0.1433 0.1354 0.1285 0.1261 0.1253 0.1244 0.1239 0.1239 0.1240 0.1244 0.1249 0.1255 0.1261 

[TRAIN] Epoch[7](285/1500); Loss: 0.105940; Backpropagation: 0.0931 sec; Batch: 0.4271 sec
0.1214 0.1489 0.1115 0.1056 0.1050 0.1042 0.1027 0.1024 0.1015 0.1008 0.0998 0.0992 0.0986 0.0981 0.0977 0.0977 

[TRAIN] Epoch[7](286/1500); Loss: 0.112025; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1525 0.1307 0.1298 0.1239 0.1243 0.1115 0.1095 0.1046 0.1024 0.1020 0.1018 0.1006 0.0999 0.0998 0.0996 0.0993 

[TRAIN] Epoch[7](287/1500); Loss: 0.081502; Backpropagation: 0.0940 sec; Batch: 0.4275 sec
0.1381 0.1136 0.1095 0.0919 0.0865 0.0793 0.0739 0.0706 0.0692 0.0673 0.0672 0.0671 0.0672 0.0673 0.0675 0.0679 

[TRAIN] Epoch[7](288/1500); Loss: 0.119977; Backpropagation: 0.0937 sec; Batch: 0.4272 sec
0.1461 0.1477 0.1274 0.1231 0.1234 0.1211 0.1187 0.1165 0.1149 0.1135 0.1126 0.1117 0.1113 0.1109 0.1105 0.1102 

[TRAIN] Epoch[7](289/1500); Loss: 0.044962; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.0701 0.0508 0.0491 0.0583 0.0503 0.0406 0.0401 0.0395 0.0393 0.0392 0.0391 0.0394 0.0399 0.0405 0.0413 0.0421 

[TRAIN] Epoch[7](290/1500); Loss: 0.048982; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.0603 0.1067 0.0549 0.0485 0.0469 0.0442 0.0423 0.0418 0.0418 0.0417 0.0418 0.0420 0.0422 0.0425 0.0428 0.0433 

[TRAIN] Epoch[7](291/1500); Loss: 0.112642; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.1459 0.1246 0.1221 0.1155 0.1181 0.1154 0.1108 0.1082 0.1066 0.1061 0.1053 0.1050 0.1048 0.1048 0.1047 0.1045 

[TRAIN] Epoch[7](292/1500); Loss: 0.105109; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1528 0.1340 0.1212 0.1116 0.1083 0.1047 0.1013 0.0980 0.0969 0.0959 0.0949 0.0938 0.0929 0.0922 0.0918 0.0915 

[TRAIN] Epoch[7](293/1500); Loss: 0.058627; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1011 0.0888 0.0749 0.0608 0.0599 0.0562 0.0531 0.0502 0.0491 0.0482 0.0478 0.0478 0.0484 0.0494 0.0505 0.0519 

[TRAIN] Epoch[7](294/1500); Loss: 0.068549; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.1130 0.1441 0.0838 0.0657 0.0622 0.0614 0.0602 0.0578 0.0562 0.0558 0.0557 0.0557 0.0558 0.0561 0.0565 0.0568 

[TRAIN] Epoch[7](295/1500); Loss: 0.080637; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1560 0.1278 0.1174 0.0849 0.0795 0.0748 0.0708 0.0661 0.0652 0.0646 0.0641 0.0637 0.0635 0.0636 0.0639 0.0643 

[TRAIN] Epoch[7](296/1500); Loss: 0.081390; Backpropagation: 0.0933 sec; Batch: 0.4277 sec
0.1301 0.1937 0.0764 0.0649 0.0669 0.0671 0.0671 0.0677 0.0683 0.0690 0.0698 0.0705 0.0713 0.0721 0.0731 0.0742 

[TRAIN] Epoch[7](297/1500); Loss: 0.050854; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.0731 0.1026 0.0558 0.0515 0.0498 0.0479 0.0454 0.0441 0.0435 0.0430 0.0427 0.0426 0.0426 0.0427 0.0430 0.0434 

[TRAIN] Epoch[7](298/1500); Loss: 0.146834; Backpropagation: 0.0930 sec; Batch: 0.4340 sec
0.1791 0.1602 0.1584 0.1574 0.1541 0.1470 0.1406 0.1397 0.1393 0.1393 0.1391 0.1391 0.1390 0.1390 0.1389 0.1390 

[TRAIN] Epoch[7](299/1500); Loss: 0.095183; Backpropagation: 0.0930 sec; Batch: 0.4271 sec
0.1481 0.1675 0.1273 0.1054 0.0992 0.0895 0.0836 0.0813 0.0804 0.0793 0.0781 0.0774 0.0768 0.0765 0.0763 0.0763 

[TRAIN] Epoch[7](300/1500); Loss: 0.101494; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.2283 0.1821 0.1737 0.1249 0.1154 0.0924 0.0818 0.0731 0.0706 0.0706 0.0706 0.0686 0.0679 0.0679 0.0680 0.0681 

[TRAIN] Epoch[7](301/1500); Loss: 0.132557; Backpropagation: 0.0926 sec; Batch: 0.4271 sec
0.2034 0.1686 0.1635 0.1364 0.1341 0.1263 0.1232 0.1198 0.1186 0.1183 0.1181 0.1181 0.1180 0.1180 0.1182 0.1184 

[TRAIN] Epoch[7](302/1500); Loss: 0.084127; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1151 0.1153 0.0918 0.0904 0.0906 0.0834 0.0801 0.0782 0.0771 0.0760 0.0755 0.0750 0.0746 0.0744 0.0742 0.0742 

[TRAIN] Epoch[7](303/1500); Loss: 0.092550; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1569 0.1250 0.1205 0.1014 0.1020 0.0894 0.0846 0.0804 0.0795 0.0786 0.0778 0.0773 0.0770 0.0768 0.0766 0.0768 

[TRAIN] Epoch[7](304/1500); Loss: 0.055022; Backpropagation: 0.0940 sec; Batch: 0.4275 sec
0.1016 0.1328 0.0548 0.0430 0.0432 0.0472 0.0443 0.0442 0.0444 0.0447 0.0451 0.0455 0.0462 0.0469 0.0477 0.0486 

[TRAIN] Epoch[7](305/1500); Loss: 0.103806; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.1324 0.1159 0.1143 0.1236 0.1145 0.1004 0.0982 0.0965 0.0958 0.0956 0.0955 0.0955 0.0955 0.0956 0.0957 0.0959 

[TRAIN] Epoch[7](306/1500); Loss: 0.066794; Backpropagation: 0.0939 sec; Batch: 0.4274 sec
0.1295 0.0986 0.0925 0.0829 0.0804 0.0569 0.0561 0.0544 0.0528 0.0521 0.0517 0.0517 0.0518 0.0520 0.0523 0.0528 

[TRAIN] Epoch[7](307/1500); Loss: 0.072929; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1159 0.1085 0.0988 0.0896 0.0767 0.0652 0.0636 0.0612 0.0605 0.0604 0.0603 0.0603 0.0607 0.0612 0.0617 0.0623 

[TRAIN] Epoch[7](308/1500); Loss: 0.114235; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1584 0.1592 0.1405 0.1248 0.1188 0.1115 0.1074 0.1047 0.1032 0.1019 0.1008 0.1000 0.0996 0.0993 0.0989 0.0987 

[TRAIN] Epoch[7](309/1500); Loss: 0.070078; Backpropagation: 0.0931 sec; Batch: 0.4276 sec
0.1128 0.0941 0.0909 0.0813 0.0755 0.0669 0.0647 0.0627 0.0610 0.0599 0.0592 0.0587 0.0585 0.0583 0.0583 0.0584 

[TRAIN] Epoch[7](310/1500); Loss: 0.086388; Backpropagation: 0.0939 sec; Batch: 0.4273 sec
0.0942 0.0897 0.0927 0.0945 0.0927 0.0884 0.0857 0.0844 0.0837 0.0830 0.0826 0.0824 0.0822 0.0820 0.0820 0.0822 

[TRAIN] Epoch[7](311/1500); Loss: 0.122735; Backpropagation: 0.0937 sec; Batch: 0.4274 sec
0.1908 0.1650 0.1616 0.1494 0.1391 0.1170 0.1113 0.1076 0.1053 0.1039 0.1034 0.1022 0.1020 0.1018 0.1016 0.1016 

[TRAIN] Epoch[7](312/1500); Loss: 0.141597; Backpropagation: 0.0933 sec; Batch: 0.4269 sec
0.1831 0.2064 0.1539 0.1420 0.1396 0.1364 0.1338 0.1318 0.1308 0.1301 0.1295 0.1292 0.1291 0.1295 0.1299 0.1306 

[TRAIN] Epoch[7](313/1500); Loss: 0.106604; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1456 0.1262 0.1212 0.1182 0.1064 0.1022 0.1005 0.0990 0.0985 0.0983 0.0981 0.0981 0.0981 0.0982 0.0984 0.0987 

[TRAIN] Epoch[7](314/1500); Loss: 0.084524; Backpropagation: 0.0930 sec; Batch: 0.4265 sec
0.1712 0.1380 0.1311 0.0987 0.0895 0.0737 0.0691 0.0665 0.0656 0.0643 0.0642 0.0639 0.0639 0.0638 0.0642 0.0646 

[TRAIN] Epoch[7](315/1500); Loss: 0.072653; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1571 0.1182 0.1158 0.0864 0.0757 0.0616 0.0598 0.0562 0.0552 0.0552 0.0546 0.0535 0.0533 0.0533 0.0532 0.0532 

[TRAIN] Epoch[7](316/1500); Loss: 0.057218; Backpropagation: 0.0980 sec; Batch: 0.4326 sec
0.1238 0.1781 0.0596 0.0450 0.0444 0.0428 0.0421 0.0416 0.0413 0.0412 0.0413 0.0417 0.0421 0.0428 0.0435 0.0443 

[TRAIN] Epoch[7](317/1500); Loss: 0.050884; Backpropagation: 0.0958 sec; Batch: 0.4303 sec
0.0624 0.1160 0.0489 0.0460 0.0454 0.0451 0.0445 0.0441 0.0440 0.0441 0.0444 0.0447 0.0452 0.0458 0.0464 0.0472 

[TRAIN] Epoch[7](318/1500); Loss: 0.146730; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.2176 0.2007 0.1909 0.1609 0.1514 0.1404 0.1352 0.1319 0.1299 0.1284 0.1278 0.1271 0.1267 0.1265 0.1263 0.1262 

[TRAIN] Epoch[7](319/1500); Loss: 0.101889; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1304 0.1238 0.1143 0.1117 0.1069 0.0992 0.0967 0.0956 0.0949 0.0944 0.0940 0.0936 0.0936 0.0936 0.0937 0.0938 

[TRAIN] Epoch[7](320/1500); Loss: 0.082151; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1603 0.1313 0.1254 0.0988 0.0863 0.0731 0.0707 0.0672 0.0647 0.0639 0.0632 0.0624 0.0620 0.0617 0.0616 0.0617 

[TRAIN] Epoch[7](321/1500); Loss: 0.105809; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1782 0.1400 0.1349 0.1177 0.1098 0.0955 0.0931 0.0934 0.0928 0.0919 0.0914 0.0910 0.0908 0.0907 0.0908 0.0909 

[TRAIN] Epoch[7](322/1500); Loss: 0.098839; Backpropagation: 0.0945 sec; Batch: 0.4284 sec
0.1329 0.1425 0.1093 0.1078 0.0997 0.0931 0.0916 0.0907 0.0903 0.0899 0.0895 0.0892 0.0890 0.0888 0.0887 0.0886 

[TRAIN] Epoch[7](323/1500); Loss: 0.102210; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1798 0.1686 0.1524 0.1171 0.1072 0.0914 0.0871 0.0830 0.0821 0.0822 0.0814 0.0806 0.0805 0.0806 0.0806 0.0807 

[TRAIN] Epoch[7](324/1500); Loss: 0.138352; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.1923 0.1686 0.1640 0.1462 0.1440 0.1376 0.1343 0.1296 0.1270 0.1253 0.1238 0.1235 0.1234 0.1239 0.1245 0.1256 

[TRAIN] Epoch[7](325/1500); Loss: 0.116680; Backpropagation: 0.0938 sec; Batch: 0.4282 sec
0.1734 0.1439 0.1395 0.1169 0.1139 0.1113 0.1114 0.1104 0.1089 0.1072 0.1060 0.1054 0.1050 0.1048 0.1046 0.1044 

[TRAIN] Epoch[7](326/1500); Loss: 0.082407; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.1125 0.1098 0.0969 0.0857 0.0835 0.0791 0.0778 0.0764 0.0756 0.0752 0.0749 0.0746 0.0744 0.0741 0.0740 0.0740 

[TRAIN] Epoch[7](327/1500); Loss: 0.156841; Backpropagation: 0.0937 sec; Batch: 0.4279 sec
0.2192 0.2089 0.1982 0.1715 0.1606 0.1472 0.1437 0.1420 0.1408 0.1405 0.1399 0.1395 0.1394 0.1393 0.1394 0.1395 

[TRAIN] Epoch[7](328/1500); Loss: 0.116327; Backpropagation: 0.0938 sec; Batch: 0.4275 sec
0.2230 0.1835 0.1733 0.1276 0.1179 0.1089 0.0996 0.0949 0.0935 0.0927 0.0920 0.0915 0.0910 0.0907 0.0906 0.0905 

[TRAIN] Epoch[7](329/1500); Loss: 0.175910; Backpropagation: 0.0936 sec; Batch: 0.4274 sec
0.2109 0.1929 0.1897 0.1787 0.1769 0.1752 0.1723 0.1706 0.1697 0.1693 0.1688 0.1686 0.1683 0.1678 0.1676 0.1674 

[TRAIN] Epoch[7](330/1500); Loss: 0.159952; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.1852 0.1730 0.1726 0.1711 0.1676 0.1606 0.1586 0.1554 0.1535 0.1529 0.1526 0.1522 0.1517 0.1510 0.1507 0.1506 

[TRAIN] Epoch[7](331/1500); Loss: 0.190734; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.2229 0.2110 0.2035 0.1984 0.1944 0.1915 0.1881 0.1867 0.1854 0.1842 0.1830 0.1822 0.1812 0.1803 0.1798 0.1791 

[TRAIN] Epoch[7](332/1500); Loss: 0.088477; Backpropagation: 0.0932 sec; Batch: 0.4263 sec
0.1428 0.1220 0.1173 0.1030 0.0924 0.0799 0.0784 0.0785 0.0757 0.0752 0.0752 0.0751 0.0749 0.0749 0.0750 0.0753 

[TRAIN] Epoch[7](333/1500); Loss: 0.069531; Backpropagation: 0.0940 sec; Batch: 0.4275 sec
0.1271 0.1903 0.0670 0.0549 0.0546 0.0547 0.0545 0.0543 0.0545 0.0549 0.0555 0.0563 0.0571 0.0580 0.0590 0.0599 

[TRAIN] Epoch[7](334/1500); Loss: 0.147718; Backpropagation: 0.0956 sec; Batch: 0.4297 sec
0.2588 0.2295 0.2224 0.1838 0.1731 0.1521 0.1382 0.1296 0.1230 0.1135 0.1092 0.1082 0.1075 0.1056 0.1047 0.1042 

[TRAIN] Epoch[7](335/1500); Loss: 0.123615; Backpropagation: 0.0958 sec; Batch: 0.4304 sec
0.1949 0.1740 0.1654 0.1351 0.1282 0.1147 0.1121 0.1093 0.1075 0.1064 0.1057 0.1053 0.1050 0.1048 0.1047 0.1047 

[TRAIN] Epoch[7](336/1500); Loss: 0.115009; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1495 0.1386 0.1332 0.1345 0.1240 0.1098 0.1072 0.1066 0.1056 0.1049 0.1047 0.1045 0.1044 0.1042 0.1042 0.1043 

[TRAIN] Epoch[7](337/1500); Loss: 0.081958; Backpropagation: 0.0939 sec; Batch: 0.4279 sec
0.1348 0.1146 0.1019 0.0933 0.0906 0.0770 0.0735 0.0717 0.0706 0.0698 0.0693 0.0690 0.0688 0.0687 0.0687 0.0688 

[TRAIN] Epoch[7](338/1500); Loss: 0.064899; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1344 0.1087 0.1039 0.0743 0.0629 0.0524 0.0538 0.0493 0.0494 0.0492 0.0492 0.0493 0.0497 0.0502 0.0506 0.0510 

[TRAIN] Epoch[7](339/1500); Loss: 0.120096; Backpropagation: 0.0946 sec; Batch: 0.4299 sec
0.1662 0.1739 0.1390 0.1210 0.1183 0.1156 0.1121 0.1108 0.1089 0.1083 0.1081 0.1079 0.1077 0.1078 0.1079 0.1080 

[TRAIN] Epoch[7](340/1500); Loss: 0.150871; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.2655 0.2309 0.2241 0.1870 0.1758 0.1513 0.1324 0.1237 0.1193 0.1183 0.1179 0.1144 0.1137 0.1134 0.1132 0.1130 

[TRAIN] Epoch[7](341/1500); Loss: 0.112445; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1547 0.1378 0.1278 0.1183 0.1134 0.1084 0.1056 0.1039 0.1037 0.1035 0.1035 0.1035 0.1035 0.1036 0.1038 0.1041 

[TRAIN] Epoch[7](342/1500); Loss: 0.117955; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1976 0.1778 0.1663 0.1191 0.1109 0.1185 0.1029 0.1003 0.0998 0.0995 0.0994 0.0992 0.0992 0.0990 0.0989 0.0989 

[TRAIN] Epoch[7](343/1500); Loss: 0.138782; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.2398 0.2037 0.1964 0.1575 0.1469 0.1330 0.1231 0.1177 0.1158 0.1144 0.1130 0.1126 0.1122 0.1117 0.1114 0.1111 

[TRAIN] Epoch[7](344/1500); Loss: 0.116751; Backpropagation: 0.0932 sec; Batch: 0.4266 sec
0.1485 0.1350 0.1310 0.1248 0.1179 0.1132 0.1120 0.1109 0.1103 0.1098 0.1095 0.1092 0.1090 0.1089 0.1090 0.1090 

[TRAIN] Epoch[7](345/1500); Loss: 0.108251; Backpropagation: 0.0956 sec; Batch: 0.4307 sec
0.1476 0.1294 0.1272 0.1180 0.1147 0.1073 0.1038 0.1014 0.0999 0.0987 0.0979 0.0973 0.0971 0.0971 0.0973 0.0975 

[TRAIN] Epoch[7](346/1500); Loss: 0.104187; Backpropagation: 0.0951 sec; Batch: 0.4297 sec
0.2381 0.1907 0.1803 0.1054 0.0912 0.0950 0.0878 0.0775 0.0763 0.0759 0.0752 0.0746 0.0745 0.0746 0.0748 0.0751 

[TRAIN] Epoch[7](347/1500); Loss: 0.086966; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1397 0.1341 0.1115 0.0933 0.0889 0.0802 0.0775 0.0758 0.0749 0.0743 0.0740 0.0737 0.0735 0.0733 0.0733 0.0734 

[TRAIN] Epoch[7](348/1500); Loss: 0.121338; Backpropagation: 0.0930 sec; Batch: 0.4265 sec
0.1785 0.1686 0.1595 0.1416 0.1309 0.1174 0.1125 0.1079 0.1055 0.1041 0.1044 0.1033 0.1023 0.1019 0.1016 0.1014 

[TRAIN] Epoch[7](349/1500); Loss: 0.152138; Backpropagation: 0.0935 sec; Batch: 0.4271 sec
0.2383 0.2135 0.2048 0.1686 0.1583 0.1435 0.1361 0.1325 0.1310 0.1306 0.1304 0.1298 0.1295 0.1292 0.1291 0.1289 

[TRAIN] Epoch[7](350/1500); Loss: 0.091909; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.1169 0.1172 0.1028 0.0929 0.0915 0.0893 0.0877 0.0867 0.0862 0.0859 0.0858 0.0857 0.0856 0.0855 0.0854 0.0854 

[TRAIN] Epoch[7](351/1500); Loss: 0.075136; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.1569 0.1198 0.1125 0.0857 0.0765 0.0657 0.0638 0.0589 0.0582 0.0576 0.0574 0.0573 0.0575 0.0577 0.0580 0.0586 

[TRAIN] Epoch[7](352/1500); Loss: 0.112075; Backpropagation: 0.0933 sec; Batch: 0.4268 sec
0.2287 0.2029 0.1757 0.1217 0.1095 0.0966 0.0938 0.0884 0.0860 0.0851 0.0849 0.0844 0.0840 0.0838 0.0838 0.0837 

[TRAIN] Epoch[7](353/1500); Loss: 0.148076; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.1925 0.1830 0.1724 0.1536 0.1466 0.1426 0.1433 0.1398 0.1383 0.1380 0.1375 0.1369 0.1365 0.1362 0.1360 0.1359 

[TRAIN] Epoch[7](354/1500); Loss: 0.134628; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2393 0.2178 0.1967 0.1438 0.1342 0.1259 0.1190 0.1123 0.1105 0.1089 0.1085 0.1081 0.1077 0.1073 0.1070 0.1069 

[TRAIN] Epoch[7](355/1500); Loss: 0.054355; Backpropagation: 0.0933 sec; Batch: 0.4274 sec
0.0735 0.0755 0.0701 0.0667 0.0630 0.0538 0.0513 0.0497 0.0483 0.0471 0.0461 0.0454 0.0449 0.0447 0.0447 0.0450 

[TRAIN] Epoch[7](356/1500); Loss: 0.092450; Backpropagation: 0.0944 sec; Batch: 0.4290 sec
0.1219 0.1165 0.1068 0.1000 0.0946 0.0886 0.0873 0.0866 0.0860 0.0854 0.0849 0.0846 0.0843 0.0839 0.0838 0.0838 

[TRAIN] Epoch[7](357/1500); Loss: 0.192937; Backpropagation: 0.0955 sec; Batch: 0.4297 sec
0.3643 0.3067 0.2955 0.2163 0.1919 0.1555 0.1538 0.1613 0.1551 0.1543 0.1548 0.1553 0.1556 0.1555 0.1555 0.1556 

[TRAIN] Epoch[7](358/1500); Loss: 0.112571; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1474 0.1607 0.1310 0.1138 0.1103 0.1073 0.1059 0.1050 0.1041 0.1033 0.1027 0.1024 0.1021 0.1019 0.1016 0.1016 

[TRAIN] Epoch[7](359/1500); Loss: 0.083694; Backpropagation: 0.0935 sec; Batch: 0.4278 sec
0.1667 0.1348 0.1276 0.0915 0.0820 0.0733 0.0736 0.0669 0.0658 0.0654 0.0652 0.0650 0.0651 0.0653 0.0653 0.0656 

[TRAIN] Epoch[7](360/1500); Loss: 0.070996; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.1627 0.1229 0.1139 0.0885 0.0757 0.0595 0.0562 0.0521 0.0511 0.0515 0.0505 0.0501 0.0500 0.0501 0.0504 0.0508 

[TRAIN] Epoch[7](361/1500); Loss: 0.070427; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1371 0.1126 0.1021 0.0722 0.0661 0.0616 0.0606 0.0598 0.0589 0.0582 0.0575 0.0569 0.0563 0.0559 0.0556 0.0554 

[TRAIN] Epoch[7](362/1500); Loss: 0.070347; Backpropagation: 0.0930 sec; Batch: 0.4267 sec
0.1064 0.0822 0.0774 0.0870 0.0756 0.0660 0.0648 0.0640 0.0634 0.0628 0.0625 0.0625 0.0625 0.0626 0.0627 0.0630 

[TRAIN] Epoch[7](363/1500); Loss: 0.124288; Backpropagation: 0.0943 sec; Batch: 0.4422 sec
0.2108 0.1976 0.1784 0.1391 0.1249 0.1131 0.1106 0.1082 0.1064 0.1042 0.1021 0.1003 0.0994 0.0987 0.0979 0.0970 

[TRAIN] Epoch[7](364/1500); Loss: 0.085555; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.1498 0.1285 0.1189 0.0967 0.0874 0.0791 0.0766 0.0718 0.0710 0.0707 0.0702 0.0696 0.0694 0.0695 0.0697 0.0698 

[TRAIN] Epoch[7](365/1500); Loss: 0.103607; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1734 0.1562 0.1484 0.1155 0.1047 0.0904 0.0898 0.0882 0.0869 0.0863 0.0862 0.0862 0.0864 0.0863 0.0864 0.0865 

[TRAIN] Epoch[7](366/1500); Loss: 0.144016; Backpropagation: 0.0932 sec; Batch: 0.4269 sec
0.1864 0.1664 0.1610 0.1501 0.1444 0.1401 0.1376 0.1358 0.1354 0.1352 0.1352 0.1353 0.1353 0.1353 0.1354 0.1354 

[TRAIN] Epoch[7](367/1500); Loss: 0.115427; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1571 0.1515 0.1378 0.1296 0.1199 0.1085 0.1069 0.1055 0.1049 0.1046 0.1041 0.1035 0.1032 0.1031 0.1031 0.1033 

[TRAIN] Epoch[7](368/1500); Loss: 0.117217; Backpropagation: 0.0944 sec; Batch: 0.4281 sec
0.1602 0.1422 0.1348 0.1327 0.1203 0.1118 0.1089 0.1075 0.1069 0.1064 0.1060 0.1062 0.1069 0.1075 0.1082 0.1090 

[TRAIN] Epoch[7](369/1500); Loss: 0.116860; Backpropagation: 0.0940 sec; Batch: 0.4284 sec
0.2990 0.2455 0.2301 0.1430 0.1145 0.0817 0.0877 0.0768 0.0763 0.0752 0.0744 0.0737 0.0732 0.0730 0.0728 0.0729 

[TRAIN] Epoch[7](370/1500); Loss: 0.137513; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.2870 0.2269 0.2181 0.1523 0.1336 0.1118 0.1062 0.1075 0.1063 0.1064 0.1064 0.1068 0.1069 0.1073 0.1080 0.1087 

[TRAIN] Epoch[7](371/1500); Loss: 0.095032; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1697 0.1348 0.1295 0.1066 0.0997 0.0867 0.0863 0.0812 0.0803 0.0794 0.0785 0.0780 0.0777 0.0774 0.0773 0.0773 

[TRAIN] Epoch[7](372/1500); Loss: 0.075175; Backpropagation: 0.0930 sec; Batch: 0.4266 sec
0.1348 0.1153 0.0985 0.0753 0.0759 0.0699 0.0656 0.0641 0.0637 0.0633 0.0630 0.0628 0.0628 0.0627 0.0626 0.0625 

[TRAIN] Epoch[7](373/1500); Loss: 0.107596; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1608 0.1642 0.1310 0.1112 0.1064 0.0994 0.0967 0.0958 0.0950 0.0947 0.0945 0.0943 0.0942 0.0942 0.0944 0.0946 

[TRAIN] Epoch[7](374/1500); Loss: 0.096361; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1827 0.1854 0.1307 0.0949 0.0916 0.0868 0.0830 0.0803 0.0786 0.0773 0.0763 0.0755 0.0749 0.0747 0.0746 0.0745 

[TRAIN] Epoch[7](375/1500); Loss: 0.086648; Backpropagation: 0.0940 sec; Batch: 0.4280 sec
0.1411 0.1158 0.1101 0.0994 0.0945 0.0826 0.0772 0.0756 0.0750 0.0744 0.0738 0.0735 0.0733 0.0732 0.0733 0.0735 

[TRAIN] Epoch[7](376/1500); Loss: 0.132377; Backpropagation: 0.0936 sec; Batch: 0.4275 sec
0.1808 0.1568 0.1532 0.1371 0.1357 0.1325 0.1265 0.1242 0.1228 0.1214 0.1209 0.1207 0.1210 0.1214 0.1215 0.1216 

[TRAIN] Epoch[7](377/1500); Loss: 0.085380; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1688 0.1448 0.1274 0.0873 0.0827 0.0747 0.0800 0.0696 0.0685 0.0679 0.0667 0.0663 0.0658 0.0654 0.0651 0.0649 

[TRAIN] Epoch[7](378/1500); Loss: 0.124100; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.2240 0.1924 0.1857 0.1530 0.1387 0.1132 0.1040 0.1001 0.0997 0.0982 0.0970 0.0964 0.0962 0.0960 0.0957 0.0955 

[TRAIN] Epoch[7](379/1500); Loss: 0.130926; Backpropagation: 0.0930 sec; Batch: 0.4273 sec
0.1985 0.1846 0.1695 0.1450 0.1356 0.1235 0.1175 0.1163 0.1146 0.1137 0.1133 0.1131 0.1128 0.1125 0.1122 0.1122 

[TRAIN] Epoch[7](380/1500); Loss: 0.104057; Backpropagation: 0.0965 sec; Batch: 0.4308 sec
0.1381 0.1222 0.1195 0.1179 0.1126 0.1001 0.0971 0.0965 0.0961 0.0956 0.0952 0.0949 0.0947 0.0948 0.0949 0.0947 

[TRAIN] Epoch[7](381/1500); Loss: 0.089990; Backpropagation: 0.0957 sec; Batch: 0.4297 sec
0.1263 0.1755 0.0885 0.0782 0.0783 0.0787 0.0795 0.0801 0.0803 0.0806 0.0810 0.0814 0.0819 0.0825 0.0832 0.0838 

[TRAIN] Epoch[7](382/1500); Loss: 0.052415; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.0695 0.0702 0.0569 0.0687 0.0601 0.0506 0.0491 0.0484 0.0477 0.0468 0.0460 0.0454 0.0450 0.0448 0.0447 0.0448 

[TRAIN] Epoch[7](383/1500); Loss: 0.071112; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.0975 0.1011 0.0868 0.0790 0.0721 0.0676 0.0660 0.0647 0.0639 0.0632 0.0628 0.0625 0.0624 0.0626 0.0627 0.0630 

[TRAIN] Epoch[7](384/1500); Loss: 0.068915; Backpropagation: 0.0931 sec; Batch: 0.4268 sec
0.0952 0.0860 0.0768 0.0846 0.0693 0.0649 0.0626 0.0620 0.0615 0.0616 0.0617 0.0619 0.0626 0.0633 0.0641 0.0646 

[TRAIN] Epoch[7](385/1500); Loss: 0.089305; Backpropagation: 0.0934 sec; Batch: 0.4274 sec
0.1649 0.1302 0.1228 0.0951 0.0874 0.0830 0.0797 0.0763 0.0754 0.0748 0.0737 0.0732 0.0731 0.0731 0.0731 0.0731 

[TRAIN] Epoch[7](386/1500); Loss: 0.084656; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1886 0.1636 0.1253 0.0813 0.0785 0.0751 0.0672 0.0643 0.0639 0.0637 0.0635 0.0635 0.0636 0.0638 0.0641 0.0645 

[TRAIN] Epoch[7](387/1500); Loss: 0.090976; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1395 0.1266 0.1195 0.1019 0.0938 0.0867 0.0833 0.0796 0.0790 0.0786 0.0783 0.0778 0.0777 0.0777 0.0777 0.0778 

[TRAIN] Epoch[7](388/1500); Loss: 0.123814; Backpropagation: 0.0931 sec; Batch: 0.4273 sec
0.1486 0.1376 0.1337 0.1276 0.1220 0.1191 0.1188 0.1186 0.1186 0.1188 0.1189 0.1191 0.1194 0.1198 0.1201 0.1204 

[TRAIN] Epoch[7](389/1500); Loss: 0.065945; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1466 0.1203 0.0997 0.0753 0.0680 0.0539 0.0506 0.0502 0.0495 0.0487 0.0485 0.0484 0.0485 0.0486 0.0490 0.0494 

[TRAIN] Epoch[7](390/1500); Loss: 0.098743; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.1440 0.1344 0.1199 0.1178 0.1025 0.0931 0.0908 0.0887 0.0880 0.0870 0.0865 0.0860 0.0855 0.0853 0.0853 0.0853 

[TRAIN] Epoch[7](391/1500); Loss: 0.126727; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1505 0.1401 0.1370 0.1336 0.1332 0.1272 0.1236 0.1221 0.1215 0.1209 0.1204 0.1199 0.1195 0.1194 0.1194 0.1193 

[TRAIN] Epoch[7](392/1500); Loss: 0.087341; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1213 0.1255 0.1052 0.0910 0.0851 0.0823 0.0815 0.0792 0.0788 0.0786 0.0784 0.0781 0.0781 0.0781 0.0782 0.0783 

[TRAIN] Epoch[7](393/1500); Loss: 0.055194; Backpropagation: 0.0939 sec; Batch: 0.4289 sec
0.1162 0.0900 0.0813 0.0650 0.0585 0.0470 0.0451 0.0435 0.0427 0.0421 0.0417 0.0417 0.0418 0.0419 0.0422 0.0424 

[TRAIN] Epoch[7](394/1500); Loss: 0.122543; Backpropagation: 0.0938 sec; Batch: 0.4283 sec
0.1733 0.1535 0.1473 0.1289 0.1243 0.1172 0.1145 0.1129 0.1120 0.1116 0.1112 0.1109 0.1108 0.1108 0.1108 0.1107 

[TRAIN] Epoch[7](395/1500); Loss: 0.098635; Backpropagation: 0.0933 sec; Batch: 0.4266 sec
0.1703 0.1394 0.1297 0.1048 0.0937 0.0947 0.0875 0.0854 0.0850 0.0844 0.0840 0.0839 0.0838 0.0838 0.0838 0.0840 

[TRAIN] Epoch[7](396/1500); Loss: 0.067699; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1236 0.0877 0.0855 0.0804 0.0847 0.0628 0.0598 0.0580 0.0567 0.0556 0.0549 0.0548 0.0544 0.0546 0.0548 0.0549 

[TRAIN] Epoch[7](397/1500); Loss: 0.103464; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1176 0.1235 0.1139 0.1140 0.1079 0.1022 0.0999 0.0987 0.0980 0.0976 0.0974 0.0971 0.0970 0.0969 0.0969 0.0968 

[TRAIN] Epoch[7](398/1500); Loss: 0.127004; Backpropagation: 0.0934 sec; Batch: 0.4270 sec
0.1652 0.1503 0.1474 0.1435 0.1358 0.1249 0.1214 0.1187 0.1176 0.1167 0.1161 0.1155 0.1150 0.1149 0.1147 0.1144 

[TRAIN] Epoch[7](399/1500); Loss: 0.090745; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1575 0.1301 0.1202 0.0918 0.0973 0.0864 0.0818 0.0798 0.0783 0.0768 0.0760 0.0756 0.0752 0.0750 0.0750 0.0749 

[TRAIN] Epoch[7](400/1500); Loss: 0.119435; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1596 0.1451 0.1387 0.1334 0.1258 0.1176 0.1144 0.1125 0.1113 0.1096 0.1085 0.1077 0.1074 0.1068 0.1065 0.1061 

[TRAIN] Epoch[7](401/1500); Loss: 0.088825; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.1468 0.1580 0.1132 0.0855 0.0812 0.0769 0.0755 0.0752 0.0749 0.0749 0.0752 0.0755 0.0760 0.0767 0.0775 0.0783 

[TRAIN] Epoch[7](402/1500); Loss: 0.127327; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.3345 0.2893 0.2695 0.1835 0.1553 0.1063 0.0791 0.0709 0.0785 0.0694 0.0684 0.0677 0.0669 0.0661 0.0658 0.0658 

[TRAIN] Epoch[7](403/1500); Loss: 0.073230; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1296 0.0965 0.0885 0.0939 0.0788 0.0669 0.0652 0.0641 0.0628 0.0618 0.0611 0.0606 0.0603 0.0603 0.0605 0.0608 

[TRAIN] Epoch[7](404/1500); Loss: 0.063609; Backpropagation: 0.0954 sec; Batch: 0.4291 sec
0.1264 0.1892 0.0595 0.0484 0.0486 0.0480 0.0476 0.0477 0.0483 0.0488 0.0492 0.0497 0.0504 0.0512 0.0520 0.0530 

[TRAIN] Epoch[7](405/1500); Loss: 0.164829; Backpropagation: 0.0938 sec; Batch: 0.4280 sec
0.1794 0.1785 0.1732 0.1752 0.1665 0.1620 0.1601 0.1599 0.1598 0.1600 0.1600 0.1603 0.1602 0.1604 0.1608 0.1611 

[TRAIN] Epoch[7](406/1500); Loss: 0.059364; Backpropagation: 0.0937 sec; Batch: 0.4273 sec
0.1876 0.1426 0.1298 0.0719 0.0561 0.0417 0.0423 0.0335 0.0312 0.0306 0.0302 0.0303 0.0302 0.0303 0.0306 0.0308 

[TRAIN] Epoch[7](407/1500); Loss: 0.097993; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.1287 0.1256 0.1128 0.1058 0.0978 0.0926 0.0917 0.0912 0.0909 0.0907 0.0905 0.0903 0.0901 0.0899 0.0898 0.0897 

[TRAIN] Epoch[7](408/1500); Loss: 0.069174; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.0956 0.0923 0.0840 0.0773 0.0722 0.0654 0.0642 0.0634 0.0627 0.0621 0.0617 0.0615 0.0613 0.0611 0.0611 0.0612 

[TRAIN] Epoch[7](409/1500); Loss: 0.061486; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1307 0.1319 0.0874 0.0598 0.0537 0.0515 0.0523 0.0466 0.0464 0.0462 0.0462 0.0460 0.0461 0.0462 0.0463 0.0466 

[TRAIN] Epoch[7](410/1500); Loss: 0.108916; Backpropagation: 0.0933 sec; Batch: 0.4273 sec
0.1869 0.1968 0.1525 0.1129 0.1008 0.0935 0.0938 0.0915 0.0899 0.0895 0.0893 0.0891 0.0891 0.0889 0.0890 0.0893 

[TRAIN] Epoch[7](411/1500); Loss: 0.097322; Backpropagation: 0.0933 sec; Batch: 0.4272 sec
0.1138 0.1060 0.1025 0.0993 0.0974 0.0937 0.0933 0.0929 0.0929 0.0929 0.0933 0.0939 0.0947 0.0957 0.0969 0.0981 

[TRAIN] Epoch[7](412/1500); Loss: 0.141045; Backpropagation: 0.0930 sec; Batch: 0.4268 sec
0.1761 0.1611 0.1573 0.1467 0.1431 0.1386 0.1369 0.1353 0.1341 0.1336 0.1332 0.1327 0.1324 0.1321 0.1319 0.1317 

[TRAIN] Epoch[7](413/1500); Loss: 0.063886; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.1400 0.0946 0.0820 0.0756 0.0722 0.0550 0.0528 0.0520 0.0513 0.0504 0.0496 0.0493 0.0492 0.0493 0.0493 0.0496 

[TRAIN] Epoch[7](414/1500); Loss: 0.053907; Backpropagation: 0.0931 sec; Batch: 0.4267 sec
0.0616 0.0716 0.0618 0.0600 0.0535 0.0519 0.0517 0.0513 0.0506 0.0504 0.0502 0.0499 0.0495 0.0496 0.0495 0.0494 

[TRAIN] Epoch[7](415/1500); Loss: 0.076229; Backpropagation: 0.0931 sec; Batch: 0.4269 sec
0.1671 0.1869 0.1015 0.0695 0.0646 0.0613 0.0603 0.0590 0.0579 0.0571 0.0565 0.0561 0.0557 0.0554 0.0553 0.0554 

[TRAIN] Epoch[7](416/1500); Loss: 0.126791; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1751 0.1590 0.1513 0.1345 0.1276 0.1222 0.1197 0.1169 0.1161 0.1157 0.1155 0.1152 0.1150 0.1149 0.1150 0.1149 

[TRAIN] Epoch[7](417/1500); Loss: 0.097081; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1425 0.1330 0.1181 0.1026 0.0975 0.0918 0.0901 0.0888 0.0879 0.0871 0.0863 0.0860 0.0858 0.0856 0.0851 0.0851 

[TRAIN] Epoch[7](418/1500); Loss: 0.078847; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.1649 0.1444 0.1247 0.0895 0.0802 0.0687 0.0655 0.0602 0.0592 0.0586 0.0581 0.0577 0.0573 0.0573 0.0574 0.0576 

[TRAIN] Epoch[7](419/1500); Loss: 0.105769; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1506 0.1279 0.1246 0.1149 0.1076 0.1003 0.0996 0.0976 0.0970 0.0966 0.0962 0.0960 0.0960 0.0958 0.0958 0.0958 

[TRAIN] Epoch[7](420/1500); Loss: 0.110950; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.4129 0.3158 0.2786 0.1413 0.0788 0.0496 0.0755 0.0524 0.0502 0.0495 0.0477 0.0453 0.0446 0.0441 0.0443 0.0445 

[TRAIN] Epoch[7](421/1500); Loss: 0.064594; Backpropagation: 0.0932 sec; Batch: 0.4279 sec
0.1004 0.0793 0.0726 0.0697 0.0713 0.0600 0.0590 0.0585 0.0582 0.0579 0.0578 0.0575 0.0575 0.0578 0.0580 0.0582 

[TRAIN] Epoch[7](422/1500); Loss: 0.153344; Backpropagation: 0.0938 sec; Batch: 0.4279 sec
0.2261 0.2084 0.1946 0.1683 0.1578 0.1447 0.1386 0.1356 0.1357 0.1361 0.1351 0.1347 0.1345 0.1344 0.1343 0.1346 

[TRAIN] Epoch[7](423/1500); Loss: 0.094905; Backpropagation: 0.0934 sec; Batch: 0.4273 sec
0.1588 0.1355 0.1258 0.1070 0.0974 0.0866 0.0827 0.0818 0.0815 0.0811 0.0805 0.0800 0.0799 0.0799 0.0800 0.0799 

[TRAIN] Epoch[7](424/1500); Loss: 0.086496; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.1270 0.1459 0.0972 0.0919 0.0872 0.0803 0.0785 0.0774 0.0764 0.0756 0.0753 0.0750 0.0746 0.0742 0.0738 0.0736 

[TRAIN] Epoch[7](425/1500); Loss: 0.091082; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1112 0.1166 0.1057 0.0986 0.0929 0.0885 0.0872 0.0861 0.0852 0.0845 0.0841 0.0838 0.0835 0.0832 0.0831 0.0832 

[TRAIN] Epoch[7](426/1500); Loss: 0.075091; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1320 0.1255 0.0931 0.0825 0.0756 0.0701 0.0655 0.0638 0.0628 0.0618 0.0614 0.0612 0.0613 0.0614 0.0615 0.0618 

[TRAIN] Epoch[7](427/1500); Loss: 0.061034; Backpropagation: 0.0939 sec; Batch: 0.4278 sec
0.0917 0.0908 0.0798 0.0642 0.0602 0.0554 0.0542 0.0539 0.0535 0.0531 0.0531 0.0532 0.0532 0.0532 0.0534 0.0537 

[TRAIN] Epoch[7](428/1500); Loss: 0.088122; Backpropagation: 0.0936 sec; Batch: 0.4521 sec
0.1260 0.1685 0.0918 0.0805 0.0796 0.0788 0.0787 0.0783 0.0781 0.0780 0.0778 0.0779 0.0784 0.0788 0.0792 0.0797 

[TRAIN] Epoch[7](429/1500); Loss: 0.114972; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1373 0.1346 0.1257 0.1308 0.1162 0.1099 0.1096 0.1095 0.1090 0.1084 0.1083 0.1082 0.1081 0.1080 0.1079 0.1080 

[TRAIN] Epoch[7](430/1500); Loss: 0.065070; Backpropagation: 0.0932 sec; Batch: 0.4268 sec
0.1146 0.1273 0.0747 0.0637 0.0604 0.0557 0.0552 0.0549 0.0545 0.0540 0.0540 0.0541 0.0544 0.0544 0.0545 0.0547 

[TRAIN] Epoch[7](431/1500); Loss: 0.107165; Backpropagation: 0.0932 sec; Batch: 0.4276 sec
0.1568 0.1395 0.1320 0.1185 0.1121 0.1035 0.1000 0.0978 0.0967 0.0957 0.0951 0.0944 0.0938 0.0932 0.0928 0.0926 

[TRAIN] Epoch[7](432/1500); Loss: 0.091968; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1396 0.1168 0.1143 0.0958 0.0890 0.0867 0.0848 0.0838 0.0832 0.0828 0.0825 0.0823 0.0822 0.0823 0.0826 0.0828 

[TRAIN] Epoch[7](433/1500); Loss: 0.129142; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1841 0.1666 0.1592 0.1462 0.1325 0.1222 0.1204 0.1190 0.1172 0.1160 0.1150 0.1141 0.1136 0.1134 0.1133 0.1133 

[TRAIN] Epoch[7](434/1500); Loss: 0.093025; Backpropagation: 0.0938 sec; Batch: 0.4277 sec
0.2383 0.1810 0.1583 0.0840 0.0672 0.0926 0.0647 0.0661 0.0659 0.0652 0.0660 0.0669 0.0674 0.0677 0.0682 0.0688 

[TRAIN] Epoch[7](435/1500); Loss: 0.070013; Backpropagation: 0.0936 sec; Batch: 0.4278 sec
0.1297 0.0965 0.0858 0.0770 0.0761 0.0627 0.0597 0.0595 0.0593 0.0590 0.0589 0.0588 0.0590 0.0593 0.0594 0.0596 

[TRAIN] Epoch[7](436/1500); Loss: 0.081779; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1422 0.1107 0.1063 0.0930 0.0925 0.0791 0.0731 0.0710 0.0698 0.0694 0.0679 0.0673 0.0668 0.0666 0.0665 0.0661 

[TRAIN] Epoch[7](437/1500); Loss: 0.059515; Backpropagation: 0.0938 sec; Batch: 0.4291 sec
0.0922 0.0972 0.0747 0.0653 0.0610 0.0572 0.0543 0.0529 0.0515 0.0506 0.0500 0.0497 0.0491 0.0488 0.0488 0.0490 

[TRAIN] Epoch[7](438/1500); Loss: 0.081920; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1942 0.1543 0.1408 0.0934 0.0761 0.0635 0.0685 0.0595 0.0582 0.0575 0.0573 0.0572 0.0573 0.0574 0.0575 0.0578 

[TRAIN] Epoch[7](439/1500); Loss: 0.073311; Backpropagation: 0.0958 sec; Batch: 0.4307 sec
0.1482 0.1260 0.1068 0.0842 0.0815 0.0824 0.0612 0.0570 0.0554 0.0537 0.0530 0.0524 0.0522 0.0523 0.0529 0.0537 

[TRAIN] Epoch[7](440/1500); Loss: 0.077849; Backpropagation: 0.0956 sec; Batch: 0.4292 sec
0.1480 0.1336 0.1183 0.0921 0.0816 0.0721 0.0678 0.0645 0.0618 0.0607 0.0595 0.0586 0.0577 0.0569 0.0564 0.0561 

[TRAIN] Epoch[7](441/1500); Loss: 0.128954; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.2259 0.1939 0.1793 0.1425 0.1305 0.1172 0.1132 0.1110 0.1098 0.1085 0.1073 0.1063 0.1054 0.1045 0.1042 0.1039 

[TRAIN] Epoch[7](442/1500); Loss: 0.067434; Backpropagation: 0.0936 sec; Batch: 0.4273 sec
0.0972 0.0988 0.0760 0.0672 0.0642 0.0627 0.0621 0.0617 0.0612 0.0608 0.0608 0.0608 0.0609 0.0611 0.0615 0.0620 

[TRAIN] Epoch[7](443/1500); Loss: 0.092347; Backpropagation: 0.0932 sec; Batch: 0.4273 sec
0.1248 0.1134 0.1038 0.0975 0.0947 0.0884 0.0874 0.0866 0.0858 0.0856 0.0854 0.0851 0.0850 0.0849 0.0846 0.0846 

[TRAIN] Epoch[7](444/1500); Loss: 0.110692; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.2108 0.1920 0.1667 0.1317 0.1154 0.0985 0.0920 0.0864 0.0877 0.0851 0.0845 0.0844 0.0843 0.0843 0.0839 0.0836 

[TRAIN] Epoch[7](445/1500); Loss: 0.091420; Backpropagation: 0.0974 sec; Batch: 0.4315 sec
0.1197 0.1294 0.1019 0.0960 0.0920 0.0883 0.0871 0.0860 0.0851 0.0843 0.0835 0.0829 0.0823 0.0818 0.0815 0.0812 

[TRAIN] Epoch[7](446/1500); Loss: 0.092416; Backpropagation: 0.0956 sec; Batch: 0.4297 sec
0.1208 0.1518 0.0993 0.0906 0.0892 0.0870 0.0852 0.0848 0.0845 0.0841 0.0838 0.0836 0.0837 0.0835 0.0834 0.0835 

[TRAIN] Epoch[7](447/1500); Loss: 0.093925; Backpropagation: 0.0935 sec; Batch: 0.4276 sec
0.2902 0.2216 0.1954 0.1111 0.0786 0.0639 0.0635 0.0568 0.0557 0.0544 0.0528 0.0517 0.0515 0.0515 0.0519 0.0523 

[TRAIN] Epoch[7](448/1500); Loss: 0.050609; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1747 0.1316 0.1108 0.0600 0.0445 0.0329 0.0342 0.0254 0.0241 0.0240 0.0240 0.0239 0.0241 0.0245 0.0251 0.0259 

[TRAIN] Epoch[7](449/1500); Loss: 0.081616; Backpropagation: 0.0932 sec; Batch: 0.4270 sec
0.1332 0.1493 0.0952 0.0810 0.0763 0.0729 0.0710 0.0707 0.0701 0.0697 0.0695 0.0694 0.0694 0.0693 0.0693 0.0694 

[TRAIN] Epoch[7](450/1500); Loss: 0.123133; Backpropagation: 0.0931 sec; Batch: 0.4270 sec
0.1745 0.1710 0.1541 0.1312 0.1244 0.1160 0.1126 0.1124 0.1109 0.1099 0.1096 0.1093 0.1089 0.1086 0.1084 0.1083 

[TRAIN] Epoch[7](451/1500); Loss: 0.137725; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1827 0.1629 0.1581 0.1430 0.1381 0.1312 0.1303 0.1292 0.1290 0.1290 0.1285 0.1283 0.1282 0.1283 0.1283 0.1284 

[TRAIN] Epoch[7](452/1500); Loss: 0.070468; Backpropagation: 0.0938 sec; Batch: 0.4284 sec
0.1077 0.0798 0.0757 0.0898 0.0671 0.0657 0.0651 0.0644 0.0640 0.0638 0.0635 0.0634 0.0635 0.0642 0.0648 0.0649 

[TRAIN] Epoch[7](453/1500); Loss: 0.088064; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1369 0.1195 0.1124 0.1034 0.0893 0.0789 0.0782 0.0780 0.0765 0.0762 0.0762 0.0765 0.0764 0.0766 0.0768 0.0771 

[TRAIN] Epoch[7](454/1500); Loss: 0.076876; Backpropagation: 0.0937 sec; Batch: 0.4276 sec
0.1127 0.1051 0.0949 0.0865 0.0761 0.0706 0.0697 0.0685 0.0682 0.0680 0.0681 0.0681 0.0682 0.0683 0.0684 0.0687 

[TRAIN] Epoch[7](455/1500); Loss: 0.109290; Backpropagation: 0.0936 sec; Batch: 0.4281 sec
0.1974 0.1831 0.1567 0.1264 0.1130 0.0949 0.0903 0.0892 0.0886 0.0879 0.0875 0.0871 0.0868 0.0866 0.0866 0.0866 

[TRAIN] Epoch[7](456/1500); Loss: 0.080639; Backpropagation: 0.0940 sec; Batch: 0.4286 sec
0.1815 0.1457 0.1303 0.0919 0.0815 0.0710 0.0662 0.0605 0.0591 0.0585 0.0581 0.0577 0.0574 0.0571 0.0569 0.0569 

[TRAIN] Epoch[7](457/1500); Loss: 0.076127; Backpropagation: 0.0980 sec; Batch: 0.4327 sec
0.1626 0.1697 0.1043 0.0696 0.0659 0.0639 0.0630 0.0604 0.0588 0.0580 0.0576 0.0572 0.0568 0.0568 0.0568 0.0566 

[TRAIN] Epoch[7](458/1500); Loss: 0.093686; Backpropagation: 0.0957 sec; Batch: 0.4296 sec
0.1328 0.1475 0.1035 0.0997 0.0946 0.0885 0.0868 0.0854 0.0845 0.0839 0.0831 0.0825 0.0821 0.0817 0.0813 0.0811 

[TRAIN] Epoch[7](459/1500); Loss: 0.121931; Backpropagation: 0.0941 sec; Batch: 0.4281 sec
0.1683 0.1535 0.1423 0.1353 0.1232 0.1161 0.1143 0.1131 0.1122 0.1114 0.1109 0.1105 0.1102 0.1100 0.1098 0.1097 

[TRAIN] Epoch[7](460/1500); Loss: 0.140973; Backpropagation: 0.0940 sec; Batch: 0.4282 sec
0.1871 0.1728 0.1636 0.1530 0.1430 0.1345 0.1319 0.1313 0.1310 0.1306 0.1301 0.1296 0.1294 0.1293 0.1293 0.1291 

[TRAIN] Epoch[7](461/1500); Loss: 0.068281; Backpropagation: 0.0938 sec; Batch: 0.4278 sec
0.1213 0.1018 0.0946 0.0769 0.0704 0.0619 0.0601 0.0582 0.0574 0.0565 0.0558 0.0554 0.0554 0.0553 0.0556 0.0560 

[TRAIN] Epoch[7](462/1500); Loss: 0.050753; Backpropagation: 0.0945 sec; Batch: 0.4288 sec
0.1325 0.1055 0.0922 0.0566 0.0483 0.0413 0.0394 0.0345 0.0334 0.0330 0.0326 0.0322 0.0321 0.0324 0.0329 0.0332 

[TRAIN] Epoch[7](463/1500); Loss: 0.071491; Backpropagation: 0.0961 sec; Batch: 0.4311 sec
0.1359 0.1187 0.1008 0.0790 0.0769 0.0710 0.0608 0.0591 0.0574 0.0557 0.0549 0.0544 0.0543 0.0544 0.0549 0.0557 

[TRAIN] Epoch[7](464/1500); Loss: 0.116348; Backpropagation: 0.0956 sec; Batch: 0.4304 sec
0.1438 0.1555 0.1305 0.1199 0.1171 0.1121 0.1098 0.1089 0.1082 0.1081 0.1077 0.1076 0.1078 0.1079 0.1082 0.1085 

[TRAIN] Epoch[7](465/1500); Loss: 0.064505; Backpropagation: 0.0938 sec; Batch: 0.4289 sec
0.1547 0.1038 0.0919 0.0671 0.0631 0.0567 0.0527 0.0508 0.0499 0.0492 0.0488 0.0487 0.0487 0.0487 0.0486 0.0487 

[TRAIN] Epoch[7](466/1500); Loss: 0.097213; Backpropagation: 0.0938 sec; Batch: 0.4291 sec
0.2061 0.2003 0.1642 0.1119 0.0948 0.0771 0.0743 0.0740 0.0701 0.0692 0.0689 0.0688 0.0686 0.0686 0.0690 0.0694 

[TRAIN] Epoch[7](467/1500); Loss: 0.099432; Backpropagation: 0.0939 sec; Batch: 0.4287 sec
0.1585 0.1451 0.1274 0.1007 0.0988 0.0954 0.0923 0.0911 0.0891 0.0872 0.0853 0.0842 0.0839 0.0840 0.0840 0.0840 

[TRAIN] Epoch[7](468/1500); Loss: 0.061530; Backpropagation: 0.0935 sec; Batch: 0.4282 sec
0.1936 0.1486 0.1317 0.0775 0.0584 0.0381 0.0409 0.0353 0.0341 0.0327 0.0325 0.0326 0.0324 0.0321 0.0319 0.0321 

[TRAIN] Epoch[7](469/1500); Loss: 0.118967; Backpropagation: 0.0950 sec; Batch: 0.4297 sec
0.1479 0.1384 0.1258 0.1356 0.1222 0.1146 0.1134 0.1130 0.1125 0.1119 0.1117 0.1115 0.1114 0.1111 0.1112 0.1113 

[TRAIN] Epoch[7](470/1500); Loss: 0.096705; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.1400 0.1216 0.1141 0.1007 0.0990 0.0921 0.0907 0.0896 0.0887 0.0880 0.0876 0.0874 0.0871 0.0868 0.0869 0.0871 

[TRAIN] Epoch[7](471/1500); Loss: 0.106003; Backpropagation: 0.0937 sec; Batch: 0.4287 sec
0.1615 0.1399 0.1310 0.1107 0.1046 0.1007 0.0976 0.0958 0.0951 0.0947 0.0946 0.0943 0.0939 0.0939 0.0939 0.0937 

[TRAIN] Epoch[7](472/1500); Loss: 0.092668; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1223 0.1197 0.1057 0.0990 0.0920 0.0889 0.0880 0.0873 0.0865 0.0861 0.0853 0.0848 0.0845 0.0843 0.0841 0.0840 

[TRAIN] Epoch[7](473/1500); Loss: 0.084307; Backpropagation: 0.0940 sec; Batch: 0.4291 sec
0.1077 0.0978 0.0925 0.0887 0.0866 0.0790 0.0785 0.0782 0.0781 0.0782 0.0786 0.0793 0.0800 0.0809 0.0819 0.0831 

[TRAIN] Epoch[7](474/1500); Loss: 0.076382; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.1112 0.1171 0.0980 0.0842 0.0757 0.0703 0.0694 0.0685 0.0671 0.0666 0.0661 0.0659 0.0657 0.0655 0.0653 0.0654 

[TRAIN] Epoch[7](475/1500); Loss: 0.135968; Backpropagation: 0.0939 sec; Batch: 0.4282 sec
0.1706 0.1557 0.1526 0.1488 0.1427 0.1304 0.1286 0.1283 0.1285 0.1278 0.1272 0.1269 0.1267 0.1269 0.1269 0.1268 

[TRAIN] Epoch[7](476/1500); Loss: 0.090683; Backpropagation: 0.0937 sec; Batch: 0.4282 sec
0.1380 0.1102 0.1037 0.1097 0.0932 0.0849 0.0832 0.0822 0.0813 0.0810 0.0808 0.0807 0.0806 0.0805 0.0805 0.0804 

[TRAIN] Epoch[7](477/1500); Loss: 0.108867; Backpropagation: 0.0933 sec; Batch: 0.4276 sec
0.1377 0.1492 0.1222 0.1151 0.1093 0.1048 0.1032 0.1020 0.1011 0.1005 0.1002 0.0998 0.0994 0.0992 0.0991 0.0990 

[TRAIN] Epoch[7](478/1500); Loss: 0.109313; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1685 0.1427 0.1376 0.1170 0.1111 0.1014 0.0997 0.0986 0.0978 0.0970 0.0965 0.0963 0.0962 0.0961 0.0962 0.0961 

[TRAIN] Epoch[7](479/1500); Loss: 0.103522; Backpropagation: 0.0932 sec; Batch: 0.4274 sec
0.1398 0.1245 0.1200 0.1095 0.1040 0.0997 0.0978 0.0969 0.0964 0.0960 0.0957 0.0954 0.0952 0.0952 0.0951 0.0951 

[TRAIN] Epoch[7](480/1500); Loss: 0.109248; Backpropagation: 0.0956 sec; Batch: 0.4315 sec
0.1338 0.1260 0.1177 0.1149 0.1127 0.1083 0.1059 0.1050 0.1043 0.1039 0.1034 0.1029 0.1025 0.1023 0.1022 0.1022 

[TRAIN] Epoch[7](481/1500); Loss: 0.078865; Backpropagation: 0.0956 sec; Batch: 0.4296 sec
0.1214 0.1503 0.0866 0.0807 0.0756 0.0726 0.0705 0.0690 0.0679 0.0674 0.0672 0.0671 0.0666 0.0663 0.0662 0.0664 

[TRAIN] Epoch[7](482/1500); Loss: 0.199503; Backpropagation: 0.0934 sec; Batch: 0.4271 sec
0.3195 0.2787 0.2623 0.2164 0.1962 0.1744 0.1748 0.1778 0.1752 0.1744 0.1746 0.1743 0.1738 0.1735 0.1731 0.1730 

[TRAIN] Epoch[7](483/1500); Loss: 0.156536; Backpropagation: 0.0932 sec; Batch: 0.4275 sec
0.2649 0.2440 0.2271 0.1921 0.1772 0.1568 0.1427 0.1298 0.1237 0.1240 0.1238 0.1210 0.1199 0.1195 0.1193 0.1188 

[TRAIN] Epoch[7](484/1500); Loss: 0.066003; Backpropagation: 0.0932 sec; Batch: 0.4272 sec
0.1341 0.1529 0.0833 0.0685 0.0589 0.0539 0.0525 0.0512 0.0507 0.0504 0.0501 0.0499 0.0499 0.0499 0.0499 0.0501 

[TRAIN] Epoch[7](485/1500); Loss: 0.115178; Backpropagation: 0.0933 sec; Batch: 0.4275 sec
0.1598 0.1412 0.1348 0.1193 0.1148 0.1103 0.1074 0.1061 0.1054 0.1055 0.1057 0.1059 0.1063 0.1065 0.1067 0.1070 

[TRAIN] Epoch[7](486/1500); Loss: 0.070234; Backpropagation: 0.0979 sec; Batch: 0.4319 sec
0.1402 0.1064 0.0961 0.0759 0.0724 0.0640 0.0595 0.0581 0.0573 0.0564 0.0563 0.0560 0.0560 0.0561 0.0563 0.0567 

[TRAIN] Epoch[7](487/1500); Loss: 0.064018; Backpropagation: 0.0941 sec; Batch: 0.4282 sec
0.0925 0.0892 0.0773 0.0686 0.0657 0.0591 0.0587 0.0578 0.0572 0.0568 0.0567 0.0567 0.0567 0.0569 0.0570 0.0572 

[TRAIN] Epoch[7](488/1500); Loss: 0.092328; Backpropagation: 0.0937 sec; Batch: 0.4278 sec
0.1408 0.1180 0.1105 0.0971 0.0921 0.0875 0.0853 0.0848 0.0842 0.0835 0.0829 0.0825 0.0822 0.0820 0.0818 0.0818 

[TRAIN] Epoch[7](489/1500); Loss: 0.117558; Backpropagation: 0.0939 sec; Batch: 0.4277 sec
0.1404 0.1369 0.1285 0.1205 0.1169 0.1123 0.1123 0.1119 0.1120 0.1120 0.1123 0.1126 0.1126 0.1129 0.1132 0.1136 

[TRAIN] Epoch[7](490/1500); Loss: 0.111149; Backpropagation: 0.0931 sec; Batch: 0.4272 sec
0.1596 0.1500 0.1359 0.1193 0.1109 0.1036 0.1046 0.1015 0.1003 0.0995 0.0992 0.0988 0.0987 0.0987 0.0987 0.0990 

[TRAIN] Epoch[7](491/1500); Loss: 0.090838; Backpropagation: 0.0935 sec; Batch: 0.4277 sec
0.1452 0.1164 0.1062 0.1026 0.0933 0.0847 0.0839 0.0817 0.0806 0.0799 0.0797 0.0798 0.0798 0.0797 0.0798 0.0801 

[TRAIN] Epoch[7](492/1500); Loss: 0.154642; Backpropagation: 0.0939 sec; Batch: 0.4288 sec
0.1862 0.1766 0.1697 0.1616 0.1579 0.1540 0.1508 0.1481 0.1471 0.1470 0.1469 0.1466 0.1461 0.1455 0.1452 0.1451 

[TRAIN] Epoch[7](493/1500); Loss: 0.080382; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1624 0.1293 0.1171 0.0878 0.0795 0.0706 0.0667 0.0643 0.0647 0.0638 0.0633 0.0632 0.0633 0.0634 0.0634 0.0636 

[TRAIN] Epoch[7](494/1500); Loss: 0.064488; Backpropagation: 0.0938 sec; Batch: 0.4276 sec
0.1160 0.1098 0.0866 0.0725 0.0670 0.0568 0.0562 0.0546 0.0530 0.0519 0.0515 0.0514 0.0512 0.0511 0.0510 0.0512 

[TRAIN] Epoch[7](495/1500); Loss: 0.126308; Backpropagation: 0.0932 sec; Batch: 0.4271 sec
0.1568 0.1449 0.1387 0.1390 0.1329 0.1255 0.1238 0.1222 0.1204 0.1186 0.1173 0.1166 0.1163 0.1162 0.1159 0.1157 

[TRAIN] Epoch[7](496/1500); Loss: 0.109536; Backpropagation: 0.0932 sec; Batch: 0.4267 sec
0.1534 0.1570 0.1207 0.1142 0.1083 0.1035 0.1027 0.1012 0.1005 0.0999 0.0993 0.0989 0.0986 0.0983 0.0981 0.0979 

[TRAIN] Epoch[7](497/1500); Loss: 0.046393; Backpropagation: 0.0939 sec; Batch: 0.4281 sec
0.1289 0.0941 0.0892 0.0542 0.0447 0.0366 0.0362 0.0320 0.0302 0.0294 0.0288 0.0282 0.0277 0.0274 0.0272 0.0273 

[TRAIN] Epoch[7](498/1500); Loss: 0.042898; Backpropagation: 0.0939 sec; Batch: 0.4280 sec
0.0828 0.0743 0.0651 0.0466 0.0400 0.0332 0.0325 0.0314 0.0324 0.0339 0.0345 0.0346 0.0349 0.0357 0.0367 0.0376 

[TRAIN] Epoch[7](499/1500); Loss: 0.099794; Backpropagation: 0.0937 sec; Batch: 0.4275 sec
0.1407 0.1226 0.1179 0.1110 0.1008 0.0930 0.0919 0.0918 0.0915 0.0910 0.0908 0.0907 0.0906 0.0906 0.0907 0.0910 

[TRAIN] Epoch[7](500/1500); Loss: