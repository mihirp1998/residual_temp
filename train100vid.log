vid count  100
total images: 1500; total batches: 375
hypernet  602767200
encoder  0
decoder  0
binarizer  0
Loaded
[TRAIN] Epoch[1](1/375); Loss: 0.055140; Backpropagation: 0.3195 sec; Batch: 2.1973 sec
0.1169 0.0818 0.0664 0.0593 0.0548 0.0517 0.0494 0.0478 0.0465 0.0455 0.0447 0.0441 0.0437 0.0434 0.0432 0.0430 

[TRAIN] Epoch[1](2/375); Loss: 0.033782; Backpropagation: 0.2899 sec; Batch: 2.0815 sec
0.0921 0.0542 0.0412 0.0356 0.0323 0.0300 0.0284 0.0274 0.0265 0.0258 0.0252 0.0248 0.0246 0.0243 0.0241 0.0240 

[TRAIN] Epoch[1](3/375); Loss: 0.029125; Backpropagation: 0.2892 sec; Batch: 2.1077 sec
0.0787 0.0490 0.0381 0.0307 0.0272 0.0251 0.0237 0.0229 0.0223 0.0219 0.0215 0.0212 0.0210 0.0209 0.0209 0.0208 

[TRAIN] Epoch[1](4/375); Loss: 0.045979; Backpropagation: 0.2886 sec; Batch: 2.0879 sec
0.1320 0.0718 0.0576 0.0472 0.0430 0.0404 0.0384 0.0368 0.0355 0.0345 0.0339 0.0334 0.0331 0.0328 0.0327 0.0325 

[TRAIN] Epoch[1](5/375); Loss: 0.046438; Backpropagation: 0.2885 sec; Batch: 2.0901 sec
0.1048 0.0727 0.0582 0.0503 0.0463 0.0436 0.0414 0.0394 0.0378 0.0368 0.0362 0.0357 0.0353 0.0350 0.0348 0.0347 

[TRAIN] Epoch[1](6/375); Loss: 0.052908; Backpropagation: 0.2886 sec; Batch: 2.0876 sec
0.1126 0.0771 0.0646 0.0566 0.0527 0.0497 0.0478 0.0461 0.0447 0.0436 0.0428 0.0423 0.0418 0.0416 0.0414 0.0412 

[TRAIN] Epoch[1](7/375); Loss: 0.049796; Backpropagation: 0.2884 sec; Batch: 2.0872 sec
0.1064 0.0745 0.0602 0.0528 0.0491 0.0465 0.0445 0.0430 0.0419 0.0410 0.0402 0.0398 0.0395 0.0393 0.0391 0.0389 

[TRAIN] Epoch[1](8/375); Loss: 0.059173; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.1198 0.0856 0.0738 0.0643 0.0596 0.0562 0.0535 0.0517 0.0502 0.0491 0.0483 0.0477 0.0472 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](9/375); Loss: 0.033428; Backpropagation: 0.2885 sec; Batch: 2.0796 sec
0.0866 0.0490 0.0442 0.0377 0.0329 0.0302 0.0284 0.0272 0.0263 0.0257 0.0251 0.0248 0.0245 0.0243 0.0241 0.0240 

[TRAIN] Epoch[1](10/375); Loss: 0.053095; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.1163 0.0717 0.0618 0.0562 0.0523 0.0498 0.0476 0.0464 0.0453 0.0445 0.0438 0.0433 0.0430 0.0427 0.0425 0.0424 

[TRAIN] Epoch[1](11/375); Loss: 0.059762; Backpropagation: 0.2880 sec; Batch: 2.0753 sec
0.1140 0.0836 0.0706 0.0645 0.0607 0.0577 0.0553 0.0534 0.0520 0.0509 0.0500 0.0494 0.0489 0.0486 0.0483 0.0482 

[TRAIN] Epoch[1](12/375); Loss: 0.037930; Backpropagation: 0.2883 sec; Batch: 2.0789 sec
0.0801 0.0525 0.0441 0.0395 0.0370 0.0354 0.0341 0.0333 0.0326 0.0320 0.0316 0.0313 0.0311 0.0309 0.0308 0.0307 

[TRAIN] Epoch[1](13/375); Loss: 0.049708; Backpropagation: 0.2883 sec; Batch: 2.0773 sec
0.1160 0.0763 0.0587 0.0516 0.0478 0.0457 0.0439 0.0423 0.0412 0.0403 0.0396 0.0391 0.0386 0.0383 0.0380 0.0378 

[TRAIN] Epoch[1](14/375); Loss: 0.040729; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.0972 0.0635 0.0487 0.0428 0.0393 0.0369 0.0353 0.0342 0.0333 0.0326 0.0321 0.0316 0.0313 0.0311 0.0309 0.0308 

[TRAIN] Epoch[1](15/375); Loss: 0.041154; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1026 0.0567 0.0450 0.0411 0.0389 0.0374 0.0360 0.0350 0.0343 0.0339 0.0335 0.0331 0.0330 0.0328 0.0327 0.0326 

[TRAIN] Epoch[1](16/375); Loss: 0.037200; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.0992 0.0609 0.0457 0.0379 0.0346 0.0327 0.0312 0.0301 0.0292 0.0286 0.0281 0.0278 0.0275 0.0273 0.0272 0.0271 

[TRAIN] Epoch[1](17/375); Loss: 0.062172; Backpropagation: 0.2883 sec; Batch: 2.0816 sec
0.1172 0.0895 0.0749 0.0675 0.0635 0.0604 0.0578 0.0556 0.0539 0.0527 0.0517 0.0509 0.0503 0.0499 0.0496 0.0493 

[TRAIN] Epoch[1](18/375); Loss: 0.057697; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.1069 0.0825 0.0687 0.0620 0.0579 0.0555 0.0533 0.0517 0.0504 0.0493 0.0486 0.0479 0.0475 0.0472 0.0469 0.0467 

[TRAIN] Epoch[1](19/375); Loss: 0.056284; Backpropagation: 0.2882 sec; Batch: 2.0813 sec
0.1160 0.0813 0.0683 0.0621 0.0577 0.0542 0.0513 0.0491 0.0476 0.0464 0.0455 0.0448 0.0444 0.0441 0.0438 0.0436 

[TRAIN] Epoch[1](20/375); Loss: 0.058043; Backpropagation: 0.2884 sec; Batch: 2.0763 sec
0.1211 0.0816 0.0670 0.0602 0.0565 0.0542 0.0524 0.0510 0.0498 0.0491 0.0485 0.0480 0.0477 0.0474 0.0472 0.0470 

[TRAIN] Epoch[1](21/375); Loss: 0.042643; Backpropagation: 0.2883 sec; Batch: 2.0805 sec
0.1005 0.0649 0.0505 0.0439 0.0405 0.0388 0.0373 0.0362 0.0353 0.0345 0.0340 0.0336 0.0334 0.0331 0.0330 0.0328 

[TRAIN] Epoch[1](22/375); Loss: 0.036401; Backpropagation: 0.2881 sec; Batch: 2.0741 sec
0.0812 0.0540 0.0442 0.0388 0.0359 0.0339 0.0323 0.0311 0.0302 0.0295 0.0291 0.0288 0.0285 0.0284 0.0283 0.0282 

[TRAIN] Epoch[1](23/375); Loss: 0.040729; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.0850 0.0617 0.0503 0.0443 0.0413 0.0386 0.0366 0.0350 0.0340 0.0332 0.0327 0.0323 0.0320 0.0317 0.0316 0.0315 

[TRAIN] Epoch[1](24/375); Loss: 0.053672; Backpropagation: 0.2886 sec; Batch: 2.0773 sec
0.0981 0.0728 0.0646 0.0588 0.0551 0.0519 0.0496 0.0481 0.0469 0.0459 0.0453 0.0448 0.0445 0.0443 0.0441 0.0441 

[TRAIN] Epoch[1](25/375); Loss: 0.037971; Backpropagation: 0.2883 sec; Batch: 2.0751 sec
0.0866 0.0554 0.0458 0.0407 0.0376 0.0352 0.0334 0.0320 0.0310 0.0305 0.0302 0.0300 0.0298 0.0297 0.0297 0.0297 

[TRAIN] Epoch[1](26/375); Loss: 0.051786; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.0968 0.0695 0.0600 0.0556 0.0529 0.0502 0.0481 0.0465 0.0454 0.0446 0.0440 0.0435 0.0432 0.0430 0.0428 0.0426 

[TRAIN] Epoch[1](27/375); Loss: 0.030811; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.0729 0.0475 0.0386 0.0327 0.0299 0.0280 0.0267 0.0258 0.0251 0.0245 0.0241 0.0238 0.0235 0.0234 0.0233 0.0232 

[TRAIN] Epoch[1](28/375); Loss: 0.052891; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0933 0.0726 0.0620 0.0571 0.0541 0.0516 0.0496 0.0478 0.0466 0.0458 0.0451 0.0447 0.0443 0.0441 0.0439 0.0437 

[TRAIN] Epoch[1](29/375); Loss: 0.050697; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1034 0.0708 0.0607 0.0548 0.0511 0.0483 0.0461 0.0445 0.0433 0.0424 0.0417 0.0413 0.0410 0.0407 0.0406 0.0405 

[TRAIN] Epoch[1](30/375); Loss: 0.027584; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.0630 0.0433 0.0339 0.0295 0.0268 0.0252 0.0240 0.0230 0.0224 0.0220 0.0217 0.0215 0.0214 0.0213 0.0212 0.0211 

[TRAIN] Epoch[1](31/375); Loss: 0.031908; Backpropagation: 0.2883 sec; Batch: 2.0856 sec
0.0745 0.0466 0.0382 0.0335 0.0308 0.0290 0.0277 0.0269 0.0263 0.0259 0.0255 0.0254 0.0252 0.0251 0.0250 0.0249 

[TRAIN] Epoch[1](32/375); Loss: 0.051703; Backpropagation: 0.2885 sec; Batch: 2.0759 sec
0.0899 0.0695 0.0603 0.0555 0.0528 0.0505 0.0488 0.0473 0.0460 0.0451 0.0445 0.0440 0.0436 0.0433 0.0431 0.0430 

[TRAIN] Epoch[1](33/375); Loss: 0.022934; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0573 0.0347 0.0271 0.0231 0.0212 0.0203 0.0196 0.0191 0.0187 0.0184 0.0182 0.0180 0.0179 0.0178 0.0178 0.0177 

[TRAIN] Epoch[1](34/375); Loss: 0.059155; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1152 0.0822 0.0700 0.0639 0.0600 0.0567 0.0542 0.0523 0.0511 0.0502 0.0494 0.0489 0.0485 0.0482 0.0479 0.0476 

[TRAIN] Epoch[1](35/375); Loss: 0.040899; Backpropagation: 0.2887 sec; Batch: 2.0752 sec
0.0859 0.0601 0.0493 0.0438 0.0405 0.0384 0.0368 0.0355 0.0346 0.0339 0.0333 0.0329 0.0326 0.0323 0.0322 0.0321 

[TRAIN] Epoch[1](36/375); Loss: 0.041481; Backpropagation: 0.2886 sec; Batch: 2.0763 sec
0.0711 0.0540 0.0479 0.0441 0.0417 0.0399 0.0387 0.0378 0.0371 0.0366 0.0363 0.0360 0.0358 0.0357 0.0355 0.0355 

[TRAIN] Epoch[1](37/375); Loss: 0.050716; Backpropagation: 0.2941 sec; Batch: 2.0818 sec
0.1017 0.0747 0.0631 0.0551 0.0509 0.0483 0.0460 0.0443 0.0430 0.0421 0.0414 0.0408 0.0405 0.0401 0.0398 0.0397 

[TRAIN] Epoch[1](38/375); Loss: 0.044485; Backpropagation: 0.2917 sec; Batch: 2.0797 sec
0.1014 0.0649 0.0552 0.0469 0.0434 0.0411 0.0393 0.0379 0.0369 0.0361 0.0356 0.0351 0.0348 0.0346 0.0344 0.0342 

[TRAIN] Epoch[1](39/375); Loss: 0.045238; Backpropagation: 0.2899 sec; Batch: 2.0804 sec
0.0959 0.0664 0.0546 0.0483 0.0453 0.0428 0.0409 0.0392 0.0381 0.0374 0.0367 0.0362 0.0359 0.0356 0.0354 0.0352 

[TRAIN] Epoch[1](40/375); Loss: 0.042045; Backpropagation: 0.2898 sec; Batch: 2.0768 sec
0.0911 0.0625 0.0534 0.0470 0.0429 0.0399 0.0377 0.0359 0.0348 0.0339 0.0332 0.0327 0.0323 0.0320 0.0317 0.0315 

[TRAIN] Epoch[1](41/375); Loss: 0.040654; Backpropagation: 0.2900 sec; Batch: 2.0766 sec
0.0789 0.0587 0.0498 0.0442 0.0410 0.0388 0.0371 0.0357 0.0348 0.0341 0.0336 0.0332 0.0329 0.0327 0.0325 0.0324 

[TRAIN] Epoch[1](42/375); Loss: 0.049193; Backpropagation: 0.2882 sec; Batch: 2.0754 sec
0.0867 0.0703 0.0586 0.0528 0.0499 0.0476 0.0457 0.0442 0.0432 0.0423 0.0418 0.0413 0.0409 0.0407 0.0405 0.0403 

[TRAIN] Epoch[1](43/375); Loss: 0.052288; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1016 0.0769 0.0642 0.0570 0.0530 0.0503 0.0476 0.0459 0.0446 0.0436 0.0430 0.0425 0.0420 0.0417 0.0415 0.0413 

[TRAIN] Epoch[1](44/375); Loss: 0.031624; Backpropagation: 0.2881 sec; Batch: 2.0745 sec
0.0877 0.0548 0.0393 0.0330 0.0297 0.0276 0.0261 0.0249 0.0241 0.0236 0.0231 0.0228 0.0225 0.0223 0.0222 0.0221 

[TRAIN] Epoch[1](45/375); Loss: 0.052993; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.1092 0.0745 0.0614 0.0561 0.0524 0.0498 0.0480 0.0467 0.0455 0.0447 0.0442 0.0437 0.0433 0.0430 0.0428 0.0427 

[TRAIN] Epoch[1](46/375); Loss: 0.050117; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0995 0.0711 0.0593 0.0537 0.0506 0.0480 0.0461 0.0446 0.0433 0.0423 0.0415 0.0410 0.0405 0.0403 0.0401 0.0399 

[TRAIN] Epoch[1](47/375); Loss: 0.041952; Backpropagation: 0.2880 sec; Batch: 2.0753 sec
0.0988 0.0678 0.0531 0.0445 0.0406 0.0382 0.0365 0.0350 0.0338 0.0330 0.0324 0.0320 0.0317 0.0314 0.0313 0.0311 

[TRAIN] Epoch[1](48/375); Loss: 0.046347; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1080 0.0710 0.0571 0.0493 0.0455 0.0429 0.0407 0.0391 0.0380 0.0370 0.0363 0.0359 0.0356 0.0353 0.0351 0.0350 

[TRAIN] Epoch[1](49/375); Loss: 0.025349; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.0566 0.0408 0.0310 0.0260 0.0239 0.0227 0.0218 0.0212 0.0208 0.0205 0.0203 0.0201 0.0200 0.0200 0.0199 0.0199 

[TRAIN] Epoch[1](50/375); Loss: 0.046445; Backpropagation: 0.2882 sec; Batch: 2.0740 sec
0.0941 0.0655 0.0539 0.0496 0.0467 0.0442 0.0423 0.0409 0.0400 0.0391 0.0386 0.0382 0.0378 0.0376 0.0374 0.0372 

[TRAIN] Epoch[1](51/375); Loss: 0.036090; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0823 0.0552 0.0441 0.0384 0.0351 0.0328 0.0315 0.0305 0.0298 0.0292 0.0287 0.0283 0.0281 0.0279 0.0278 0.0277 

[TRAIN] Epoch[1](52/375); Loss: 0.047637; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0851 0.0700 0.0568 0.0513 0.0482 0.0459 0.0441 0.0427 0.0417 0.0409 0.0402 0.0396 0.0392 0.0390 0.0388 0.0387 

[TRAIN] Epoch[1](53/375); Loss: 0.056836; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.1185 0.0857 0.0687 0.0612 0.0564 0.0527 0.0507 0.0490 0.0478 0.0469 0.0462 0.0457 0.0453 0.0451 0.0448 0.0446 

[TRAIN] Epoch[1](54/375); Loss: 0.045027; Backpropagation: 0.2883 sec; Batch: 2.0801 sec
0.1007 0.0671 0.0549 0.0491 0.0447 0.0420 0.0399 0.0384 0.0373 0.0364 0.0358 0.0353 0.0350 0.0347 0.0346 0.0345 

[TRAIN] Epoch[1](55/375); Loss: 0.036467; Backpropagation: 0.2880 sec; Batch: 2.0747 sec
0.0834 0.0607 0.0468 0.0396 0.0360 0.0336 0.0318 0.0303 0.0292 0.0285 0.0279 0.0276 0.0273 0.0271 0.0269 0.0268 

[TRAIN] Epoch[1](56/375); Loss: 0.039345; Backpropagation: 0.2880 sec; Batch: 2.0733 sec
0.0691 0.0565 0.0471 0.0422 0.0397 0.0379 0.0364 0.0354 0.0345 0.0340 0.0334 0.0331 0.0328 0.0326 0.0324 0.0323 

[TRAIN] Epoch[1](57/375); Loss: 0.036395; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0777 0.0544 0.0442 0.0391 0.0357 0.0336 0.0322 0.0311 0.0304 0.0299 0.0295 0.0292 0.0290 0.0289 0.0288 0.0287 

[TRAIN] Epoch[1](58/375); Loss: 0.036862; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0909 0.0599 0.0482 0.0398 0.0358 0.0333 0.0314 0.0301 0.0291 0.0284 0.0279 0.0275 0.0271 0.0269 0.0268 0.0267 

[TRAIN] Epoch[1](59/375); Loss: 0.049133; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0910 0.0697 0.0589 0.0531 0.0493 0.0469 0.0450 0.0436 0.0427 0.0419 0.0414 0.0410 0.0407 0.0405 0.0403 0.0402 

[TRAIN] Epoch[1](60/375); Loss: 0.063030; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1120 0.0927 0.0775 0.0701 0.0645 0.0606 0.0581 0.0562 0.0548 0.0536 0.0526 0.0519 0.0514 0.0510 0.0508 0.0506 

[TRAIN] Epoch[1](61/375); Loss: 0.037199; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0903 0.0554 0.0443 0.0390 0.0358 0.0338 0.0325 0.0313 0.0304 0.0298 0.0294 0.0290 0.0288 0.0286 0.0284 0.0283 

[TRAIN] Epoch[1](62/375); Loss: 0.042893; Backpropagation: 0.2888 sec; Batch: 2.0729 sec
0.0978 0.0637 0.0507 0.0451 0.0417 0.0394 0.0380 0.0368 0.0358 0.0350 0.0345 0.0341 0.0338 0.0335 0.0333 0.0332 

[TRAIN] Epoch[1](63/375); Loss: 0.046084; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0863 0.0687 0.0564 0.0503 0.0462 0.0440 0.0422 0.0409 0.0397 0.0388 0.0382 0.0377 0.0373 0.0371 0.0369 0.0367 

[TRAIN] Epoch[1](64/375); Loss: 0.049703; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.1257 0.0891 0.0689 0.0583 0.0501 0.0448 0.0414 0.0389 0.0373 0.0361 0.0352 0.0346 0.0342 0.0338 0.0335 0.0333 

[TRAIN] Epoch[1](65/375); Loss: 0.051364; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0874 0.0732 0.0614 0.0560 0.0523 0.0499 0.0480 0.0466 0.0454 0.0445 0.0438 0.0433 0.0429 0.0426 0.0424 0.0421 

[TRAIN] Epoch[1](66/375); Loss: 0.044635; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0817 0.0649 0.0551 0.0486 0.0448 0.0424 0.0408 0.0396 0.0387 0.0379 0.0374 0.0369 0.0367 0.0364 0.0362 0.0361 

[TRAIN] Epoch[1](67/375); Loss: 0.054236; Backpropagation: 0.2880 sec; Batch: 2.0733 sec
0.1148 0.0926 0.0752 0.0632 0.0549 0.0499 0.0465 0.0444 0.0431 0.0420 0.0413 0.0407 0.0402 0.0399 0.0397 0.0395 

[TRAIN] Epoch[1](68/375); Loss: 0.053038; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.1100 0.0870 0.0702 0.0594 0.0535 0.0496 0.0466 0.0448 0.0432 0.0422 0.0415 0.0408 0.0404 0.0400 0.0398 0.0396 

[TRAIN] Epoch[1](69/375); Loss: 0.049138; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.0930 0.0716 0.0605 0.0533 0.0493 0.0467 0.0447 0.0433 0.0422 0.0415 0.0409 0.0404 0.0400 0.0398 0.0396 0.0394 

[TRAIN] Epoch[1](70/375); Loss: 0.038582; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0827 0.0586 0.0491 0.0426 0.0389 0.0361 0.0344 0.0329 0.0319 0.0313 0.0307 0.0302 0.0298 0.0295 0.0293 0.0292 

[TRAIN] Epoch[1](71/375); Loss: 0.038197; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0913 0.0598 0.0455 0.0403 0.0373 0.0348 0.0331 0.0318 0.0310 0.0304 0.0299 0.0296 0.0294 0.0291 0.0290 0.0288 

[TRAIN] Epoch[1](72/375); Loss: 0.049060; Backpropagation: 0.2882 sec; Batch: 2.0729 sec
0.0910 0.0745 0.0616 0.0552 0.0507 0.0475 0.0451 0.0432 0.0418 0.0409 0.0401 0.0394 0.0389 0.0386 0.0383 0.0381 

[TRAIN] Epoch[1](73/375); Loss: 0.053376; Backpropagation: 0.2886 sec; Batch: 2.0728 sec
0.0982 0.0751 0.0652 0.0591 0.0551 0.0524 0.0501 0.0482 0.0466 0.0454 0.0445 0.0437 0.0432 0.0427 0.0424 0.0421 

[TRAIN] Epoch[1](74/375); Loss: 0.058591; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.1092 0.0873 0.0745 0.0666 0.0608 0.0567 0.0536 0.0514 0.0499 0.0487 0.0477 0.0471 0.0466 0.0461 0.0458 0.0456 

[TRAIN] Epoch[1](75/375); Loss: 0.037842; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0826 0.0590 0.0497 0.0419 0.0381 0.0354 0.0335 0.0319 0.0308 0.0300 0.0294 0.0291 0.0288 0.0286 0.0284 0.0283 

[TRAIN] Epoch[1](76/375); Loss: 0.036580; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.0804 0.0604 0.0475 0.0405 0.0365 0.0338 0.0322 0.0310 0.0298 0.0289 0.0283 0.0278 0.0274 0.0271 0.0269 0.0268 

[TRAIN] Epoch[1](77/375); Loss: 0.057850; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1009 0.0801 0.0690 0.0630 0.0589 0.0561 0.0540 0.0524 0.0511 0.0502 0.0495 0.0488 0.0484 0.0480 0.0478 0.0476 

[TRAIN] Epoch[1](78/375); Loss: 0.048781; Backpropagation: 0.2883 sec; Batch: 2.0725 sec
0.0817 0.0671 0.0567 0.0519 0.0491 0.0473 0.0458 0.0446 0.0436 0.0429 0.0424 0.0420 0.0416 0.0414 0.0413 0.0412 

[TRAIN] Epoch[1](79/375); Loss: 0.049564; Backpropagation: 0.2880 sec; Batch: 2.0722 sec
0.0870 0.0688 0.0607 0.0543 0.0503 0.0478 0.0461 0.0447 0.0435 0.0427 0.0420 0.0416 0.0412 0.0409 0.0407 0.0406 

[TRAIN] Epoch[1](80/375); Loss: 0.048293; Backpropagation: 0.2886 sec; Batch: 2.0812 sec
0.0819 0.0709 0.0599 0.0523 0.0486 0.0460 0.0445 0.0432 0.0422 0.0415 0.0410 0.0406 0.0403 0.0401 0.0400 0.0399 

[TRAIN] Epoch[1](81/375); Loss: 0.042553; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0762 0.0610 0.0521 0.0472 0.0442 0.0415 0.0396 0.0380 0.0369 0.0361 0.0355 0.0350 0.0347 0.0344 0.0342 0.0341 

[TRAIN] Epoch[1](82/375); Loss: 0.033666; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.0713 0.0502 0.0415 0.0367 0.0338 0.0316 0.0300 0.0289 0.0282 0.0276 0.0271 0.0267 0.0265 0.0263 0.0262 0.0261 

[TRAIN] Epoch[1](83/375); Loss: 0.039248; Backpropagation: 0.2879 sec; Batch: 2.0715 sec
0.0927 0.0579 0.0453 0.0408 0.0380 0.0360 0.0348 0.0335 0.0326 0.0319 0.0314 0.0310 0.0307 0.0306 0.0304 0.0303 

[TRAIN] Epoch[1](84/375); Loss: 0.050344; Backpropagation: 0.2882 sec; Batch: 2.0738 sec
0.0959 0.0705 0.0610 0.0549 0.0514 0.0486 0.0466 0.0449 0.0437 0.0426 0.0418 0.0414 0.0409 0.0406 0.0404 0.0403 

[TRAIN] Epoch[1](85/375); Loss: 0.046254; Backpropagation: 0.2882 sec; Batch: 2.0728 sec
0.0967 0.0729 0.0603 0.0523 0.0467 0.0433 0.0408 0.0392 0.0381 0.0371 0.0363 0.0358 0.0355 0.0352 0.0350 0.0348 

[TRAIN] Epoch[1](86/375); Loss: 0.056336; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1038 0.0819 0.0674 0.0612 0.0573 0.0544 0.0523 0.0504 0.0490 0.0479 0.0471 0.0464 0.0460 0.0457 0.0454 0.0452 

[TRAIN] Epoch[1](87/375); Loss: 0.032633; Backpropagation: 0.2880 sec; Batch: 2.0731 sec
0.0684 0.0520 0.0408 0.0357 0.0327 0.0306 0.0291 0.0279 0.0270 0.0263 0.0259 0.0255 0.0253 0.0251 0.0250 0.0249 

[TRAIN] Epoch[1](88/375); Loss: 0.051839; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.0949 0.0716 0.0620 0.0555 0.0519 0.0494 0.0478 0.0464 0.0454 0.0446 0.0441 0.0436 0.0433 0.0431 0.0429 0.0428 

[TRAIN] Epoch[1](89/375); Loss: 0.037531; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.0921 0.0696 0.0519 0.0417 0.0373 0.0339 0.0317 0.0298 0.0285 0.0277 0.0269 0.0264 0.0260 0.0258 0.0256 0.0255 

[TRAIN] Epoch[1](90/375); Loss: 0.045266; Backpropagation: 0.2884 sec; Batch: 2.0722 sec
0.0825 0.0721 0.0571 0.0487 0.0450 0.0424 0.0408 0.0395 0.0386 0.0379 0.0374 0.0370 0.0367 0.0364 0.0362 0.0361 

[TRAIN] Epoch[1](91/375); Loss: 0.063172; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1109 0.0912 0.0755 0.0682 0.0639 0.0608 0.0587 0.0570 0.0556 0.0544 0.0535 0.0530 0.0525 0.0521 0.0518 0.0516 

[TRAIN] Epoch[1](92/375); Loss: 0.050411; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.1056 0.0829 0.0662 0.0563 0.0500 0.0467 0.0446 0.0428 0.0415 0.0404 0.0395 0.0388 0.0383 0.0380 0.0377 0.0375 

[TRAIN] Epoch[1](93/375); Loss: 0.049606; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.0991 0.0795 0.0625 0.0537 0.0499 0.0467 0.0445 0.0431 0.0417 0.0405 0.0397 0.0392 0.0388 0.0384 0.0382 0.0380 

[TRAIN] Epoch[1](94/375); Loss: 0.063601; Backpropagation: 0.2882 sec; Batch: 2.0727 sec
0.1104 0.0930 0.0785 0.0708 0.0662 0.0628 0.0599 0.0573 0.0555 0.0540 0.0528 0.0521 0.0516 0.0511 0.0509 0.0507 

[TRAIN] Epoch[1](95/375); Loss: 0.059943; Backpropagation: 0.2885 sec; Batch: 2.0737 sec
0.1093 0.0962 0.0770 0.0658 0.0610 0.0574 0.0548 0.0526 0.0509 0.0496 0.0486 0.0480 0.0474 0.0471 0.0468 0.0466 

[TRAIN] Epoch[1](96/375); Loss: 0.053319; Backpropagation: 0.2883 sec; Batch: 2.0719 sec
0.0973 0.0799 0.0648 0.0579 0.0541 0.0512 0.0489 0.0474 0.0462 0.0452 0.0444 0.0439 0.0434 0.0430 0.0428 0.0426 

[TRAIN] Epoch[1](97/375); Loss: 0.061046; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1043 0.0871 0.0743 0.0666 0.0625 0.0595 0.0570 0.0551 0.0536 0.0525 0.0516 0.0511 0.0508 0.0505 0.0503 0.0501 

[TRAIN] Epoch[1](98/375); Loss: 0.046092; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.0953 0.0778 0.0600 0.0495 0.0457 0.0427 0.0405 0.0388 0.0379 0.0370 0.0363 0.0357 0.0353 0.0352 0.0350 0.0349 

[TRAIN] Epoch[1](99/375); Loss: 0.065811; Backpropagation: 0.2892 sec; Batch: 2.0738 sec
0.1130 0.0975 0.0807 0.0723 0.0675 0.0639 0.0614 0.0594 0.0578 0.0564 0.0553 0.0545 0.0539 0.0534 0.0531 0.0529 

[TRAIN] Epoch[1](100/375); Loss: 0.050262; Backpropagation: 0.2881 sec; Batch: 2.0729 sec
0.0978 0.0835 0.0626 0.0553 0.0511 0.0481 0.0458 0.0437 0.0420 0.0408 0.0401 0.0394 0.0389 0.0386 0.0383 0.0381 

[TRAIN] Epoch[1](101/375); Loss: 0.045920; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0947 0.0762 0.0589 0.0497 0.0453 0.0425 0.0404 0.0388 0.0377 0.0370 0.0364 0.0360 0.0356 0.0354 0.0352 0.0350 

[TRAIN] Epoch[1](102/375); Loss: 0.051144; Backpropagation: 0.2884 sec; Batch: 2.0719 sec
0.1110 0.0876 0.0665 0.0559 0.0511 0.0476 0.0450 0.0429 0.0415 0.0403 0.0394 0.0388 0.0382 0.0378 0.0375 0.0373 

[TRAIN] Epoch[1](103/375); Loss: 0.043396; Backpropagation: 0.2885 sec; Batch: 2.0779 sec
0.1098 0.0871 0.0571 0.0472 0.0419 0.0383 0.0357 0.0340 0.0327 0.0316 0.0308 0.0303 0.0299 0.0296 0.0293 0.0291 

[TRAIN] Epoch[1](104/375); Loss: 0.052532; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1053 0.0811 0.0636 0.0557 0.0525 0.0500 0.0478 0.0461 0.0447 0.0436 0.0428 0.0422 0.0417 0.0414 0.0411 0.0409 

[TRAIN] Epoch[1](105/375); Loss: 0.033238; Backpropagation: 0.2884 sec; Batch: 2.0741 sec
0.0935 0.0745 0.0487 0.0344 0.0302 0.0279 0.0255 0.0240 0.0231 0.0223 0.0219 0.0215 0.0213 0.0211 0.0210 0.0209 

[TRAIN] Epoch[1](106/375); Loss: 0.053464; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.1112 0.0903 0.0674 0.0580 0.0528 0.0499 0.0474 0.0457 0.0441 0.0430 0.0421 0.0414 0.0410 0.0406 0.0403 0.0401 

[TRAIN] Epoch[1](107/375); Loss: 0.039578; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.0935 0.0722 0.0518 0.0427 0.0387 0.0358 0.0337 0.0322 0.0311 0.0302 0.0295 0.0290 0.0286 0.0283 0.0281 0.0280 

[TRAIN] Epoch[1](108/375); Loss: 0.050508; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1021 0.0846 0.0657 0.0562 0.0510 0.0477 0.0454 0.0433 0.0417 0.0406 0.0396 0.0389 0.0383 0.0379 0.0376 0.0374 

[TRAIN] Epoch[1](109/375); Loss: 0.046076; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0884 0.0757 0.0594 0.0513 0.0467 0.0435 0.0414 0.0398 0.0386 0.0376 0.0368 0.0362 0.0358 0.0355 0.0353 0.0352 

[TRAIN] Epoch[1](110/375); Loss: 0.040757; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.0989 0.0755 0.0546 0.0446 0.0405 0.0371 0.0347 0.0328 0.0314 0.0304 0.0296 0.0291 0.0286 0.0283 0.0281 0.0279 

[TRAIN] Epoch[1](111/375); Loss: 0.035043; Backpropagation: 0.2886 sec; Batch: 2.0741 sec
0.0720 0.0570 0.0426 0.0365 0.0337 0.0319 0.0307 0.0299 0.0292 0.0287 0.0284 0.0282 0.0281 0.0280 0.0279 0.0279 

[TRAIN] Epoch[1](112/375); Loss: 0.059819; Backpropagation: 0.2881 sec; Batch: 2.0738 sec
0.1094 0.0929 0.0756 0.0667 0.0621 0.0583 0.0552 0.0528 0.0508 0.0496 0.0486 0.0479 0.0474 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](113/375); Loss: 0.037460; Backpropagation: 0.2881 sec; Batch: 2.0729 sec
0.0867 0.0706 0.0515 0.0404 0.0366 0.0341 0.0319 0.0303 0.0291 0.0281 0.0275 0.0270 0.0267 0.0265 0.0263 0.0262 

[TRAIN] Epoch[1](114/375); Loss: 0.056506; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0989 0.0860 0.0680 0.0612 0.0576 0.0544 0.0523 0.0508 0.0492 0.0481 0.0473 0.0467 0.0463 0.0460 0.0458 0.0456 

[TRAIN] Epoch[1](115/375); Loss: 0.061409; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1162 0.1006 0.0811 0.0696 0.0629 0.0587 0.0556 0.0532 0.0512 0.0497 0.0487 0.0480 0.0474 0.0469 0.0466 0.0463 

[TRAIN] Epoch[1](116/375); Loss: 0.033839; Backpropagation: 0.2884 sec; Batch: 2.0733 sec
0.0877 0.0654 0.0443 0.0362 0.0315 0.0290 0.0276 0.0264 0.0255 0.0248 0.0243 0.0240 0.0237 0.0236 0.0236 0.0236 

[TRAIN] Epoch[1](117/375); Loss: 0.041883; Backpropagation: 0.2884 sec; Batch: 2.0807 sec
0.0892 0.0725 0.0545 0.0472 0.0419 0.0388 0.0368 0.0352 0.0338 0.0329 0.0321 0.0316 0.0312 0.0310 0.0308 0.0307 

[TRAIN] Epoch[1](118/375); Loss: 0.045813; Backpropagation: 0.2886 sec; Batch: 2.0746 sec
0.0984 0.0762 0.0598 0.0505 0.0457 0.0429 0.0406 0.0387 0.0374 0.0364 0.0355 0.0349 0.0345 0.0341 0.0339 0.0336 

[TRAIN] Epoch[1](119/375); Loss: 0.059290; Backpropagation: 0.2885 sec; Batch: 2.0783 sec
0.1192 0.0947 0.0725 0.0641 0.0595 0.0561 0.0534 0.0512 0.0497 0.0487 0.0479 0.0472 0.0466 0.0462 0.0459 0.0457 

[TRAIN] Epoch[1](120/375); Loss: 0.045987; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1008 0.0785 0.0616 0.0514 0.0464 0.0429 0.0405 0.0386 0.0371 0.0359 0.0350 0.0343 0.0337 0.0333 0.0331 0.0328 

[TRAIN] Epoch[1](121/375); Loss: 0.045516; Backpropagation: 0.2885 sec; Batch: 2.0735 sec
0.0971 0.0785 0.0620 0.0517 0.0461 0.0426 0.0401 0.0381 0.0366 0.0355 0.0344 0.0338 0.0334 0.0331 0.0327 0.0325 

[TRAIN] Epoch[1](122/375); Loss: 0.052862; Backpropagation: 0.2880 sec; Batch: 2.0732 sec
0.1018 0.0823 0.0642 0.0575 0.0537 0.0507 0.0482 0.0463 0.0449 0.0439 0.0432 0.0426 0.0421 0.0418 0.0415 0.0413 

[TRAIN] Epoch[1](123/375); Loss: 0.040332; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0831 0.0686 0.0524 0.0456 0.0407 0.0368 0.0350 0.0338 0.0328 0.0322 0.0317 0.0312 0.0308 0.0304 0.0302 0.0301 

[TRAIN] Epoch[1](124/375); Loss: 0.056428; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1013 0.0817 0.0678 0.0616 0.0571 0.0538 0.0518 0.0502 0.0491 0.0483 0.0476 0.0471 0.0468 0.0464 0.0462 0.0461 

[TRAIN] Epoch[1](125/375); Loss: 0.053729; Backpropagation: 0.2884 sec; Batch: 2.0732 sec
0.1190 0.0934 0.0693 0.0580 0.0518 0.0487 0.0463 0.0446 0.0432 0.0424 0.0416 0.0411 0.0406 0.0402 0.0399 0.0397 

[TRAIN] Epoch[1](126/375); Loss: 0.042145; Backpropagation: 0.2879 sec; Batch: 2.0729 sec
0.0835 0.0659 0.0531 0.0468 0.0429 0.0401 0.0380 0.0364 0.0356 0.0347 0.0339 0.0333 0.0329 0.0326 0.0324 0.0322 

[TRAIN] Epoch[1](127/375); Loss: 0.053057; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1126 0.0845 0.0654 0.0570 0.0525 0.0492 0.0472 0.0457 0.0443 0.0432 0.0423 0.0418 0.0413 0.0410 0.0406 0.0404 

[TRAIN] Epoch[1](128/375); Loss: 0.046467; Backpropagation: 0.2882 sec; Batch: 2.0737 sec
0.1006 0.0763 0.0554 0.0489 0.0448 0.0423 0.0405 0.0394 0.0383 0.0376 0.0372 0.0368 0.0366 0.0364 0.0362 0.0362 

[TRAIN] Epoch[1](129/375); Loss: 0.042304; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1002 0.0655 0.0519 0.0458 0.0417 0.0385 0.0366 0.0352 0.0342 0.0335 0.0330 0.0326 0.0323 0.0321 0.0320 0.0319 

[TRAIN] Epoch[1](130/375); Loss: 0.054353; Backpropagation: 0.2883 sec; Batch: 2.0775 sec
0.1081 0.0865 0.0697 0.0607 0.0551 0.0519 0.0493 0.0473 0.0455 0.0442 0.0432 0.0425 0.0419 0.0415 0.0413 0.0411 

[TRAIN] Epoch[1](131/375); Loss: 0.051218; Backpropagation: 0.2883 sec; Batch: 2.0744 sec
0.1023 0.0779 0.0640 0.0571 0.0517 0.0486 0.0464 0.0446 0.0432 0.0421 0.0413 0.0407 0.0403 0.0400 0.0397 0.0395 

[TRAIN] Epoch[1](132/375); Loss: 0.072914; Backpropagation: 0.2882 sec; Batch: 2.0730 sec
0.1224 0.1015 0.0881 0.0804 0.0752 0.0713 0.0684 0.0663 0.0646 0.0632 0.0623 0.0615 0.0609 0.0604 0.0602 0.0600 

[TRAIN] Epoch[1](133/375); Loss: 0.060773; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1276 0.0954 0.0783 0.0698 0.0632 0.0578 0.0541 0.0515 0.0497 0.0484 0.0474 0.0467 0.0461 0.0457 0.0454 0.0452 

[TRAIN] Epoch[1](134/375); Loss: 0.047810; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1091 0.0781 0.0613 0.0512 0.0459 0.0430 0.0412 0.0398 0.0388 0.0379 0.0373 0.0368 0.0365 0.0362 0.0360 0.0358 

[TRAIN] Epoch[1](135/375); Loss: 0.042422; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.0897 0.0663 0.0546 0.0467 0.0425 0.0398 0.0379 0.0364 0.0351 0.0341 0.0335 0.0330 0.0326 0.0324 0.0321 0.0319 

[TRAIN] Epoch[1](136/375); Loss: 0.051656; Backpropagation: 0.2884 sec; Batch: 2.0731 sec
0.1059 0.0802 0.0654 0.0572 0.0518 0.0484 0.0461 0.0445 0.0432 0.0422 0.0414 0.0407 0.0403 0.0399 0.0397 0.0395 

[TRAIN] Epoch[1](137/375); Loss: 0.042684; Backpropagation: 0.2883 sec; Batch: 2.0726 sec
0.0834 0.0643 0.0511 0.0458 0.0425 0.0403 0.0388 0.0374 0.0364 0.0356 0.0352 0.0348 0.0346 0.0344 0.0342 0.0341 

[TRAIN] Epoch[1](138/375); Loss: 0.052255; Backpropagation: 0.2887 sec; Batch: 2.0736 sec
0.0977 0.0777 0.0642 0.0569 0.0526 0.0500 0.0479 0.0464 0.0451 0.0440 0.0433 0.0427 0.0423 0.0420 0.0418 0.0416 

[TRAIN] Epoch[1](139/375); Loss: 0.043194; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.0707 0.0563 0.0506 0.0462 0.0435 0.0418 0.0407 0.0397 0.0389 0.0384 0.0379 0.0376 0.0374 0.0372 0.0371 0.0370 

[TRAIN] Epoch[1](140/375); Loss: 0.049118; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.1021 0.0809 0.0640 0.0552 0.0499 0.0465 0.0439 0.0418 0.0403 0.0390 0.0381 0.0375 0.0370 0.0367 0.0365 0.0363 

[TRAIN] Epoch[1](141/375); Loss: 0.043520; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0943 0.0713 0.0587 0.0501 0.0451 0.0414 0.0386 0.0367 0.0351 0.0339 0.0330 0.0324 0.0319 0.0315 0.0312 0.0310 

[TRAIN] Epoch[1](142/375); Loss: 0.044696; Backpropagation: 0.2883 sec; Batch: 2.0733 sec
0.0833 0.0700 0.0569 0.0489 0.0451 0.0423 0.0404 0.0392 0.0380 0.0371 0.0365 0.0360 0.0356 0.0354 0.0353 0.0352 

[TRAIN] Epoch[1](143/375); Loss: 0.057309; Backpropagation: 0.2883 sec; Batch: 2.0730 sec
0.1057 0.0821 0.0701 0.0631 0.0588 0.0549 0.0524 0.0505 0.0494 0.0485 0.0479 0.0474 0.0470 0.0466 0.0464 0.0461 

[TRAIN] Epoch[1](144/375); Loss: 0.049779; Backpropagation: 0.2886 sec; Batch: 2.0731 sec
0.1073 0.0812 0.0629 0.0520 0.0514 0.0493 0.0457 0.0424 0.0402 0.0391 0.0385 0.0379 0.0375 0.0372 0.0370 0.0367 

[TRAIN] Epoch[1](145/375); Loss: 0.050645; Backpropagation: 0.2884 sec; Batch: 2.0727 sec
0.0969 0.0719 0.0615 0.0561 0.0516 0.0485 0.0463 0.0447 0.0436 0.0427 0.0420 0.0415 0.0411 0.0409 0.0406 0.0404 

[TRAIN] Epoch[1](146/375); Loss: 0.036509; Backpropagation: 0.2888 sec; Batch: 2.0793 sec
0.0847 0.0609 0.0476 0.0398 0.0358 0.0334 0.0314 0.0301 0.0290 0.0283 0.0278 0.0274 0.0272 0.0270 0.0269 0.0268 

[TRAIN] Epoch[1](147/375); Loss: 0.046741; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1239 0.0815 0.0573 0.0464 0.0429 0.0407 0.0389 0.0377 0.0368 0.0359 0.0352 0.0347 0.0344 0.0341 0.0339 0.0337 

[TRAIN] Epoch[1](148/375); Loss: 0.054736; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.0951 0.0746 0.0635 0.0586 0.0556 0.0531 0.0512 0.0499 0.0487 0.0478 0.0471 0.0466 0.0464 0.0460 0.0458 0.0457 

[TRAIN] Epoch[1](149/375); Loss: 0.053848; Backpropagation: 0.2887 sec; Batch: 2.0737 sec
0.0971 0.0782 0.0651 0.0589 0.0553 0.0523 0.0499 0.0481 0.0468 0.0458 0.0451 0.0445 0.0441 0.0437 0.0435 0.0433 

[TRAIN] Epoch[1](150/375); Loss: 0.035699; Backpropagation: 0.2886 sec; Batch: 2.0733 sec
0.0820 0.0578 0.0435 0.0377 0.0348 0.0327 0.0311 0.0300 0.0290 0.0284 0.0280 0.0276 0.0274 0.0272 0.0270 0.0269 

[TRAIN] Epoch[1](151/375); Loss: 0.032389; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0617 0.0436 0.0369 0.0332 0.0316 0.0304 0.0296 0.0290 0.0285 0.0282 0.0279 0.0277 0.0276 0.0275 0.0275 0.0274 

[TRAIN] Epoch[1](152/375); Loss: 0.039963; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0816 0.0582 0.0497 0.0440 0.0410 0.0388 0.0367 0.0351 0.0339 0.0330 0.0322 0.0317 0.0312 0.0310 0.0307 0.0305 

[TRAIN] Epoch[1](153/375); Loss: 0.061423; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1174 0.0887 0.0739 0.0662 0.0617 0.0587 0.0565 0.0547 0.0532 0.0521 0.0513 0.0505 0.0500 0.0496 0.0493 0.0490 

[TRAIN] Epoch[1](154/375); Loss: 0.041649; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.0931 0.0645 0.0511 0.0453 0.0416 0.0387 0.0367 0.0352 0.0341 0.0334 0.0328 0.0325 0.0322 0.0320 0.0318 0.0316 

[TRAIN] Epoch[1](155/375); Loss: 0.054269; Backpropagation: 0.2882 sec; Batch: 2.0733 sec
0.1007 0.0778 0.0644 0.0580 0.0547 0.0519 0.0501 0.0485 0.0472 0.0463 0.0456 0.0452 0.0448 0.0445 0.0444 0.0442 

[TRAIN] Epoch[1](156/375); Loss: 0.041303; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.0830 0.0626 0.0517 0.0450 0.0416 0.0390 0.0372 0.0358 0.0348 0.0340 0.0335 0.0331 0.0327 0.0325 0.0323 0.0322 

[TRAIN] Epoch[1](157/375); Loss: 0.043959; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0924 0.0669 0.0561 0.0484 0.0440 0.0409 0.0388 0.0373 0.0364 0.0357 0.0351 0.0348 0.0345 0.0342 0.0340 0.0339 

[TRAIN] Epoch[1](158/375); Loss: 0.049438; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1095 0.0745 0.0608 0.0535 0.0495 0.0464 0.0442 0.0426 0.0412 0.0402 0.0394 0.0386 0.0381 0.0378 0.0375 0.0373 

[TRAIN] Epoch[1](159/375); Loss: 0.033107; Backpropagation: 0.2887 sec; Batch: 2.0741 sec
0.0679 0.0505 0.0421 0.0370 0.0338 0.0314 0.0297 0.0283 0.0275 0.0268 0.0263 0.0260 0.0258 0.0256 0.0255 0.0254 

[TRAIN] Epoch[1](160/375); Loss: 0.048213; Backpropagation: 0.2882 sec; Batch: 2.0734 sec
0.0974 0.0722 0.0591 0.0525 0.0485 0.0457 0.0437 0.0421 0.0408 0.0400 0.0393 0.0387 0.0383 0.0379 0.0376 0.0375 

[TRAIN] Epoch[1](161/375); Loss: 0.035960; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.0721 0.0559 0.0456 0.0396 0.0363 0.0339 0.0321 0.0308 0.0300 0.0293 0.0289 0.0285 0.0283 0.0281 0.0280 0.0279 

[TRAIN] Epoch[1](162/375); Loss: 0.049349; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1036 0.0702 0.0592 0.0525 0.0489 0.0464 0.0446 0.0431 0.0420 0.0411 0.0405 0.0400 0.0397 0.0395 0.0393 0.0391 

[TRAIN] Epoch[1](163/375); Loss: 0.046318; Backpropagation: 0.2886 sec; Batch: 2.0740 sec
0.0964 0.0725 0.0602 0.0518 0.0472 0.0441 0.0416 0.0399 0.0384 0.0374 0.0365 0.0358 0.0352 0.0349 0.0346 0.0345 

[TRAIN] Epoch[1](164/375); Loss: 0.030920; Backpropagation: 0.2884 sec; Batch: 2.0791 sec
0.0774 0.0520 0.0392 0.0328 0.0301 0.0279 0.0263 0.0252 0.0243 0.0237 0.0232 0.0229 0.0227 0.0225 0.0223 0.0222 

[TRAIN] Epoch[1](165/375); Loss: 0.051680; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1064 0.0801 0.0652 0.0569 0.0521 0.0488 0.0465 0.0446 0.0431 0.0421 0.0412 0.0407 0.0403 0.0399 0.0396 0.0394 

[TRAIN] Epoch[1](166/375); Loss: 0.050250; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1094 0.0834 0.0653 0.0555 0.0498 0.0464 0.0441 0.0421 0.0407 0.0396 0.0389 0.0384 0.0380 0.0376 0.0374 0.0372 

[TRAIN] Epoch[1](167/375); Loss: 0.044948; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.1014 0.0670 0.0551 0.0481 0.0443 0.0417 0.0398 0.0383 0.0371 0.0363 0.0358 0.0353 0.0350 0.0348 0.0346 0.0344 

[TRAIN] Epoch[1](168/375); Loss: 0.035383; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.0785 0.0572 0.0439 0.0374 0.0340 0.0318 0.0305 0.0297 0.0290 0.0285 0.0281 0.0278 0.0276 0.0274 0.0273 0.0272 

[TRAIN] Epoch[1](169/375); Loss: 0.034781; Backpropagation: 0.2889 sec; Batch: 2.0735 sec
0.0693 0.0535 0.0442 0.0387 0.0351 0.0330 0.0312 0.0300 0.0291 0.0285 0.0280 0.0276 0.0273 0.0271 0.0270 0.0269 

[TRAIN] Epoch[1](170/375); Loss: 0.045390; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0893 0.0690 0.0579 0.0508 0.0466 0.0435 0.0412 0.0395 0.0383 0.0373 0.0365 0.0359 0.0355 0.0352 0.0350 0.0348 

[TRAIN] Epoch[1](171/375); Loss: 0.031835; Backpropagation: 0.2889 sec; Batch: 2.0760 sec
0.0784 0.0491 0.0398 0.0347 0.0307 0.0286 0.0273 0.0263 0.0256 0.0250 0.0246 0.0242 0.0240 0.0239 0.0238 0.0237 

[TRAIN] Epoch[1](172/375); Loss: 0.045971; Backpropagation: 0.2886 sec; Batch: 2.0736 sec
0.0909 0.0700 0.0563 0.0495 0.0456 0.0430 0.0412 0.0398 0.0390 0.0383 0.0377 0.0373 0.0370 0.0368 0.0366 0.0365 

[TRAIN] Epoch[1](173/375); Loss: 0.041438; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0925 0.0662 0.0521 0.0457 0.0417 0.0389 0.0367 0.0351 0.0339 0.0330 0.0322 0.0317 0.0313 0.0310 0.0307 0.0305 

[TRAIN] Epoch[1](174/375); Loss: 0.052952; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.1009 0.0769 0.0644 0.0581 0.0547 0.0515 0.0489 0.0469 0.0453 0.0443 0.0436 0.0430 0.0426 0.0423 0.0420 0.0418 

[TRAIN] Epoch[1](175/375); Loss: 0.045643; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0958 0.0696 0.0575 0.0504 0.0462 0.0434 0.0409 0.0393 0.0380 0.0371 0.0364 0.0358 0.0354 0.0350 0.0347 0.0345 

[TRAIN] Epoch[1](176/375); Loss: 0.046510; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.0865 0.0661 0.0558 0.0499 0.0468 0.0446 0.0427 0.0414 0.0405 0.0397 0.0392 0.0388 0.0384 0.0381 0.0379 0.0378 

[TRAIN] Epoch[1](177/375); Loss: 0.037190; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.0771 0.0538 0.0439 0.0394 0.0368 0.0351 0.0336 0.0324 0.0316 0.0310 0.0305 0.0302 0.0301 0.0299 0.0298 0.0298 

[TRAIN] Epoch[1](178/375); Loss: 0.047336; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0886 0.0681 0.0572 0.0509 0.0475 0.0453 0.0435 0.0421 0.0411 0.0402 0.0396 0.0391 0.0388 0.0386 0.0384 0.0383 

[TRAIN] Epoch[1](179/375); Loss: 0.056511; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1207 0.0880 0.0738 0.0636 0.0572 0.0531 0.0501 0.0480 0.0466 0.0453 0.0443 0.0436 0.0431 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](180/375); Loss: 0.040419; Backpropagation: 0.2885 sec; Batch: 2.0740 sec
0.0905 0.0628 0.0486 0.0428 0.0394 0.0372 0.0355 0.0343 0.0335 0.0329 0.0323 0.0319 0.0315 0.0313 0.0311 0.0310 

[TRAIN] Epoch[1](181/375); Loss: 0.052259; Backpropagation: 0.2880 sec; Batch: 2.0740 sec
0.0989 0.0740 0.0628 0.0558 0.0522 0.0494 0.0479 0.0465 0.0455 0.0447 0.0440 0.0435 0.0431 0.0428 0.0427 0.0425 

[TRAIN] Epoch[1](182/375); Loss: 0.047279; Backpropagation: 0.2881 sec; Batch: 2.0750 sec
0.0924 0.0703 0.0588 0.0521 0.0482 0.0455 0.0432 0.0416 0.0403 0.0393 0.0384 0.0378 0.0375 0.0372 0.0369 0.0368 

[TRAIN] Epoch[1](183/375); Loss: 0.056265; Backpropagation: 0.2883 sec; Batch: 2.0759 sec
0.1038 0.0830 0.0682 0.0615 0.0577 0.0545 0.0521 0.0503 0.0487 0.0476 0.0467 0.0460 0.0455 0.0451 0.0448 0.0446 

[TRAIN] Epoch[1](184/375); Loss: 0.047082; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1021 0.0727 0.0612 0.0518 0.0471 0.0440 0.0418 0.0401 0.0389 0.0379 0.0370 0.0364 0.0360 0.0357 0.0355 0.0353 

[TRAIN] Epoch[1](185/375); Loss: 0.059118; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1118 0.0834 0.0706 0.0643 0.0600 0.0568 0.0544 0.0527 0.0513 0.0502 0.0493 0.0489 0.0485 0.0482 0.0479 0.0477 

[TRAIN] Epoch[1](186/375); Loss: 0.031405; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.0660 0.0485 0.0381 0.0344 0.0315 0.0297 0.0282 0.0271 0.0263 0.0257 0.0252 0.0248 0.0245 0.0243 0.0242 0.0241 

[TRAIN] Epoch[1](187/375); Loss: 0.033566; Backpropagation: 0.2883 sec; Batch: 2.0755 sec
0.0813 0.0544 0.0434 0.0364 0.0330 0.0304 0.0288 0.0276 0.0268 0.0261 0.0256 0.0251 0.0248 0.0246 0.0245 0.0244 

[TRAIN] Epoch[1](188/375); Loss: 0.055682; Backpropagation: 0.2886 sec; Batch: 2.0757 sec
0.1147 0.0853 0.0714 0.0638 0.0572 0.0530 0.0503 0.0480 0.0463 0.0448 0.0439 0.0432 0.0427 0.0423 0.0421 0.0419 

[TRAIN] Epoch[1](189/375); Loss: 0.045343; Backpropagation: 0.2886 sec; Batch: 2.0754 sec
0.1051 0.0724 0.0562 0.0488 0.0447 0.0420 0.0397 0.0381 0.0369 0.0360 0.0353 0.0347 0.0342 0.0339 0.0337 0.0335 

[TRAIN] Epoch[1](190/375); Loss: 0.037979; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.0870 0.0615 0.0479 0.0416 0.0372 0.0344 0.0328 0.0316 0.0309 0.0301 0.0296 0.0291 0.0288 0.0286 0.0284 0.0283 

[TRAIN] Epoch[1](191/375); Loss: 0.050896; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.0925 0.0704 0.0602 0.0554 0.0520 0.0496 0.0477 0.0462 0.0448 0.0439 0.0431 0.0424 0.0420 0.0416 0.0414 0.0413 

[TRAIN] Epoch[1](192/375); Loss: 0.051531; Backpropagation: 0.2879 sec; Batch: 2.0745 sec
0.0927 0.0712 0.0605 0.0551 0.0518 0.0495 0.0478 0.0465 0.0455 0.0447 0.0441 0.0437 0.0433 0.0430 0.0427 0.0425 

[TRAIN] Epoch[1](193/375); Loss: 0.047055; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0982 0.0740 0.0599 0.0531 0.0477 0.0443 0.0423 0.0403 0.0389 0.0379 0.0371 0.0365 0.0360 0.0357 0.0355 0.0353 

[TRAIN] Epoch[1](194/375); Loss: 0.049031; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.0941 0.0733 0.0606 0.0543 0.0507 0.0477 0.0453 0.0433 0.0419 0.0409 0.0401 0.0393 0.0388 0.0384 0.0381 0.0379 

[TRAIN] Epoch[1](195/375); Loss: 0.061732; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1202 0.0918 0.0768 0.0690 0.0637 0.0601 0.0571 0.0546 0.0526 0.0511 0.0500 0.0492 0.0485 0.0481 0.0477 0.0473 

[TRAIN] Epoch[1](196/375); Loss: 0.033308; Backpropagation: 0.2883 sec; Batch: 2.0804 sec
0.0767 0.0491 0.0414 0.0370 0.0338 0.0312 0.0293 0.0281 0.0273 0.0265 0.0261 0.0257 0.0254 0.0252 0.0251 0.0250 

[TRAIN] Epoch[1](197/375); Loss: 0.050695; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.1119 0.0802 0.0632 0.0551 0.0506 0.0473 0.0449 0.0431 0.0418 0.0406 0.0399 0.0393 0.0388 0.0384 0.0381 0.0379 

[TRAIN] Epoch[1](198/375); Loss: 0.042204; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0742 0.0591 0.0516 0.0462 0.0429 0.0406 0.0391 0.0379 0.0370 0.0363 0.0358 0.0354 0.0351 0.0349 0.0347 0.0346 

[TRAIN] Epoch[1](199/375); Loss: 0.044091; Backpropagation: 0.2884 sec; Batch: 2.0747 sec
0.1102 0.0744 0.0589 0.0479 0.0432 0.0402 0.0378 0.0359 0.0344 0.0333 0.0325 0.0319 0.0315 0.0312 0.0311 0.0309 

[TRAIN] Epoch[1](200/375); Loss: 0.043357; Backpropagation: 0.2881 sec; Batch: 2.0744 sec
0.1004 0.0659 0.0498 0.0445 0.0414 0.0392 0.0379 0.0368 0.0360 0.0354 0.0349 0.0346 0.0344 0.0342 0.0342 0.0341 

[TRAIN] Epoch[1](201/375); Loss: 0.050488; Backpropagation: 0.2882 sec; Batch: 2.0740 sec
0.0983 0.0750 0.0624 0.0558 0.0514 0.0487 0.0463 0.0446 0.0432 0.0421 0.0413 0.0406 0.0400 0.0397 0.0393 0.0391 

[TRAIN] Epoch[1](202/375); Loss: 0.041908; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.1068 0.0713 0.0521 0.0448 0.0400 0.0369 0.0351 0.0337 0.0327 0.0320 0.0315 0.0311 0.0308 0.0307 0.0306 0.0305 

[TRAIN] Epoch[1](203/375); Loss: 0.047155; Backpropagation: 0.2888 sec; Batch: 2.0764 sec
0.0862 0.0663 0.0569 0.0514 0.0479 0.0456 0.0438 0.0424 0.0412 0.0403 0.0397 0.0392 0.0388 0.0385 0.0382 0.0381 

[TRAIN] Epoch[1](204/375); Loss: 0.055513; Backpropagation: 0.2881 sec; Batch: 2.0754 sec
0.1254 0.0917 0.0709 0.0603 0.0557 0.0521 0.0491 0.0468 0.0450 0.0435 0.0426 0.0418 0.0413 0.0409 0.0407 0.0404 

[TRAIN] Epoch[1](205/375); Loss: 0.054473; Backpropagation: 0.2886 sec; Batch: 2.0767 sec
0.1189 0.0862 0.0693 0.0611 0.0554 0.0516 0.0485 0.0461 0.0443 0.0432 0.0424 0.0417 0.0412 0.0409 0.0406 0.0404 

[TRAIN] Epoch[1](206/375); Loss: 0.055254; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1094 0.0861 0.0687 0.0598 0.0556 0.0521 0.0499 0.0479 0.0464 0.0455 0.0448 0.0442 0.0438 0.0435 0.0432 0.0430 

[TRAIN] Epoch[1](207/375); Loss: 0.062753; Backpropagation: 0.2885 sec; Batch: 2.0753 sec
0.1252 0.0962 0.0778 0.0686 0.0634 0.0596 0.0565 0.0544 0.0529 0.0518 0.0509 0.0502 0.0496 0.0492 0.0489 0.0487 

[TRAIN] Epoch[1](208/375); Loss: 0.050947; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.1012 0.0769 0.0594 0.0543 0.0501 0.0476 0.0458 0.0444 0.0435 0.0428 0.0422 0.0418 0.0416 0.0413 0.0412 0.0410 

[TRAIN] Epoch[1](209/375); Loss: 0.057132; Backpropagation: 0.2886 sec; Batch: 2.0756 sec
0.1268 0.0861 0.0698 0.0632 0.0579 0.0540 0.0509 0.0486 0.0470 0.0460 0.0452 0.0446 0.0440 0.0436 0.0433 0.0431 

[TRAIN] Epoch[1](210/375); Loss: 0.044719; Backpropagation: 0.2884 sec; Batch: 2.0797 sec
0.1075 0.0752 0.0541 0.0472 0.0432 0.0403 0.0385 0.0370 0.0358 0.0350 0.0345 0.0340 0.0336 0.0334 0.0332 0.0331 

[TRAIN] Epoch[1](211/375); Loss: 0.060467; Backpropagation: 0.2882 sec; Batch: 2.0759 sec
0.1319 0.1006 0.0779 0.0674 0.0605 0.0559 0.0529 0.0506 0.0490 0.0478 0.0469 0.0462 0.0456 0.0451 0.0447 0.0445 

[TRAIN] Epoch[1](212/375); Loss: 0.045574; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1001 0.0700 0.0570 0.0501 0.0452 0.0426 0.0405 0.0389 0.0375 0.0367 0.0361 0.0355 0.0351 0.0348 0.0346 0.0344 

[TRAIN] Epoch[1](213/375); Loss: 0.035513; Backpropagation: 0.2879 sec; Batch: 2.0750 sec
0.0834 0.0568 0.0443 0.0382 0.0347 0.0327 0.0310 0.0296 0.0287 0.0281 0.0275 0.0271 0.0268 0.0266 0.0264 0.0263 

[TRAIN] Epoch[1](214/375); Loss: 0.034057; Backpropagation: 0.2884 sec; Batch: 2.0804 sec
0.0997 0.0685 0.0458 0.0356 0.0308 0.0285 0.0268 0.0255 0.0245 0.0238 0.0232 0.0229 0.0226 0.0224 0.0222 0.0221 

[TRAIN] Epoch[1](215/375); Loss: 0.057666; Backpropagation: 0.2884 sec; Batch: 2.0756 sec
0.1109 0.0821 0.0697 0.0630 0.0584 0.0554 0.0528 0.0510 0.0497 0.0488 0.0479 0.0474 0.0469 0.0465 0.0462 0.0459 

[TRAIN] Epoch[1](216/375); Loss: 0.055925; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1150 0.0839 0.0690 0.0597 0.0555 0.0523 0.0502 0.0487 0.0473 0.0463 0.0455 0.0450 0.0445 0.0442 0.0440 0.0438 

[TRAIN] Epoch[1](217/375); Loss: 0.058728; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.1086 0.0846 0.0726 0.0640 0.0590 0.0561 0.0538 0.0520 0.0508 0.0499 0.0491 0.0486 0.0481 0.0477 0.0474 0.0472 

[TRAIN] Epoch[1](218/375); Loss: 0.043192; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.0977 0.0692 0.0532 0.0461 0.0421 0.0396 0.0376 0.0362 0.0352 0.0345 0.0340 0.0336 0.0333 0.0331 0.0329 0.0328 

[TRAIN] Epoch[1](219/375); Loss: 0.063278; Backpropagation: 0.2885 sec; Batch: 2.0755 sec
0.1353 0.1010 0.0744 0.0658 0.0609 0.0574 0.0555 0.0541 0.0528 0.0520 0.0513 0.0509 0.0505 0.0503 0.0501 0.0500 

[TRAIN] Epoch[1](220/375); Loss: 0.046528; Backpropagation: 0.2881 sec; Batch: 2.0755 sec
0.0994 0.0851 0.0676 0.0582 0.0508 0.0450 0.0402 0.0368 0.0347 0.0336 0.0329 0.0325 0.0321 0.0319 0.0318 0.0317 

[TRAIN] Epoch[1](221/375); Loss: 0.036250; Backpropagation: 0.2884 sec; Batch: 2.0758 sec
0.1053 0.0644 0.0477 0.0397 0.0345 0.0314 0.0294 0.0281 0.0269 0.0260 0.0253 0.0249 0.0244 0.0241 0.0239 0.0238 

[TRAIN] Epoch[1](222/375); Loss: 0.050286; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1322 0.1082 0.0795 0.0624 0.0493 0.0420 0.0384 0.0363 0.0348 0.0337 0.0327 0.0320 0.0313 0.0309 0.0305 0.0303 

[TRAIN] Epoch[1](223/375); Loss: 0.060933; Backpropagation: 0.2881 sec; Batch: 2.0754 sec
0.1336 0.1066 0.0831 0.0709 0.0625 0.0574 0.0534 0.0501 0.0480 0.0467 0.0456 0.0446 0.0438 0.0433 0.0429 0.0425 

[TRAIN] Epoch[1](224/375); Loss: 0.054843; Backpropagation: 0.2882 sec; Batch: 2.0818 sec
0.1042 0.0826 0.0679 0.0601 0.0554 0.0524 0.0499 0.0482 0.0469 0.0459 0.0451 0.0445 0.0440 0.0437 0.0434 0.0433 

[TRAIN] Epoch[1](225/375); Loss: 0.058565; Backpropagation: 0.2884 sec; Batch: 2.0773 sec
0.1164 0.0950 0.0766 0.0661 0.0592 0.0549 0.0522 0.0501 0.0486 0.0474 0.0465 0.0457 0.0451 0.0447 0.0444 0.0443 

[TRAIN] Epoch[1](226/375); Loss: 0.044906; Backpropagation: 0.2881 sec; Batch: 2.0753 sec
0.1279 0.0743 0.0537 0.0469 0.0422 0.0393 0.0372 0.0357 0.0347 0.0338 0.0331 0.0326 0.0321 0.0319 0.0316 0.0315 

[TRAIN] Epoch[1](227/375); Loss: 0.054552; Backpropagation: 0.2886 sec; Batch: 2.0760 sec
0.1261 0.1087 0.0786 0.0639 0.0510 0.0447 0.0421 0.0414 0.0407 0.0402 0.0398 0.0394 0.0392 0.0390 0.0390 0.0389 

[TRAIN] Epoch[1](228/375); Loss: 0.067839; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1355 0.1125 0.0862 0.0745 0.0670 0.0637 0.0605 0.0583 0.0566 0.0550 0.0540 0.0531 0.0526 0.0522 0.0519 0.0517 

[TRAIN] Epoch[1](229/375); Loss: 0.056721; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.1061 0.0863 0.0710 0.0628 0.0569 0.0537 0.0517 0.0499 0.0485 0.0475 0.0466 0.0461 0.0456 0.0452 0.0450 0.0448 

[TRAIN] Epoch[1](230/375); Loss: 0.040742; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1099 0.0859 0.0603 0.0491 0.0399 0.0345 0.0309 0.0296 0.0282 0.0274 0.0269 0.0263 0.0260 0.0258 0.0256 0.0254 

[TRAIN] Epoch[1](231/375); Loss: 0.043244; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1105 0.0789 0.0591 0.0495 0.0425 0.0385 0.0360 0.0341 0.0328 0.0319 0.0310 0.0303 0.0297 0.0293 0.0290 0.0288 

[TRAIN] Epoch[1](232/375); Loss: 0.058614; Backpropagation: 0.2886 sec; Batch: 2.0750 sec
0.1173 0.0935 0.0758 0.0661 0.0596 0.0553 0.0524 0.0500 0.0484 0.0473 0.0464 0.0458 0.0453 0.0450 0.0449 0.0447 

[TRAIN] Epoch[1](233/375); Loss: 0.062727; Backpropagation: 0.2886 sec; Batch: 2.0749 sec
0.1380 0.1065 0.0823 0.0693 0.0614 0.0571 0.0544 0.0524 0.0508 0.0495 0.0484 0.0477 0.0470 0.0466 0.0463 0.0460 

[TRAIN] Epoch[1](234/375); Loss: 0.044592; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.1288 0.0964 0.0674 0.0502 0.0397 0.0343 0.0327 0.0314 0.0305 0.0298 0.0294 0.0290 0.0287 0.0285 0.0283 0.0282 

[TRAIN] Epoch[1](235/375); Loss: 0.048488; Backpropagation: 0.2884 sec; Batch: 2.0754 sec
0.1111 0.0840 0.0650 0.0538 0.0478 0.0440 0.0416 0.0398 0.0385 0.0374 0.0366 0.0360 0.0355 0.0352 0.0349 0.0347 

[TRAIN] Epoch[1](236/375); Loss: 0.042915; Backpropagation: 0.2885 sec; Batch: 2.0761 sec
0.1063 0.0834 0.0610 0.0511 0.0429 0.0383 0.0351 0.0331 0.0316 0.0306 0.0298 0.0293 0.0289 0.0286 0.0283 0.0282 

[TRAIN] Epoch[1](237/375); Loss: 0.029810; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.0811 0.0531 0.0375 0.0320 0.0280 0.0261 0.0245 0.0236 0.0228 0.0221 0.0216 0.0213 0.0210 0.0208 0.0207 0.0206 

[TRAIN] Epoch[1](238/375); Loss: 0.044323; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0948 0.0762 0.0596 0.0505 0.0454 0.0415 0.0388 0.0370 0.0356 0.0345 0.0336 0.0330 0.0325 0.0322 0.0320 0.0319 

[TRAIN] Epoch[1](239/375); Loss: 0.048301; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.1100 0.0871 0.0654 0.0555 0.0480 0.0440 0.0409 0.0389 0.0376 0.0367 0.0358 0.0352 0.0348 0.0345 0.0343 0.0342 

[TRAIN] Epoch[1](240/375); Loss: 0.048429; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1068 0.0872 0.0690 0.0579 0.0493 0.0442 0.0408 0.0386 0.0374 0.0365 0.0358 0.0351 0.0346 0.0342 0.0338 0.0336 

[TRAIN] Epoch[1](241/375); Loss: 0.052204; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1273 0.0955 0.0724 0.0586 0.0509 0.0465 0.0434 0.0411 0.0396 0.0386 0.0379 0.0374 0.0369 0.0366 0.0364 0.0363 

[TRAIN] Epoch[1](242/375); Loss: 0.072534; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.1276 0.1085 0.0921 0.0833 0.0771 0.0725 0.0685 0.0653 0.0627 0.0609 0.0592 0.0580 0.0571 0.0564 0.0559 0.0555 

[TRAIN] Epoch[1](243/375); Loss: 0.048357; Backpropagation: 0.2886 sec; Batch: 2.0753 sec
0.0877 0.0738 0.0592 0.0530 0.0490 0.0463 0.0442 0.0429 0.0418 0.0409 0.0402 0.0396 0.0392 0.0389 0.0386 0.0384 

[TRAIN] Epoch[1](244/375); Loss: 0.055971; Backpropagation: 0.2882 sec; Batch: 2.0751 sec
0.1190 0.0906 0.0675 0.0598 0.0552 0.0528 0.0498 0.0479 0.0464 0.0452 0.0445 0.0440 0.0435 0.0433 0.0431 0.0429 

[TRAIN] Epoch[1](245/375); Loss: 0.050875; Backpropagation: 0.2885 sec; Batch: 2.0812 sec
0.1245 0.0919 0.0694 0.0571 0.0495 0.0457 0.0430 0.0411 0.0396 0.0382 0.0371 0.0363 0.0357 0.0354 0.0350 0.0347 

[TRAIN] Epoch[1](246/375); Loss: 0.061691; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.1417 0.1043 0.0787 0.0654 0.0595 0.0555 0.0526 0.0506 0.0495 0.0484 0.0477 0.0473 0.0469 0.0465 0.0463 0.0462 

[TRAIN] Epoch[1](247/375); Loss: 0.038639; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.0916 0.0668 0.0519 0.0440 0.0384 0.0351 0.0330 0.0313 0.0301 0.0292 0.0286 0.0281 0.0278 0.0276 0.0274 0.0273 

[TRAIN] Epoch[1](248/375); Loss: 0.046239; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.1034 0.0770 0.0594 0.0514 0.0458 0.0425 0.0405 0.0389 0.0375 0.0363 0.0355 0.0349 0.0345 0.0343 0.0341 0.0339 

[TRAIN] Epoch[1](249/375); Loss: 0.049810; Backpropagation: 0.2887 sec; Batch: 2.0755 sec
0.0983 0.0789 0.0621 0.0565 0.0513 0.0474 0.0448 0.0429 0.0417 0.0407 0.0399 0.0392 0.0387 0.0384 0.0382 0.0380 

[TRAIN] Epoch[1](250/375); Loss: 0.067219; Backpropagation: 0.2881 sec; Batch: 2.0751 sec
0.1215 0.0993 0.0822 0.0732 0.0679 0.0644 0.0619 0.0597 0.0582 0.0570 0.0562 0.0555 0.0550 0.0547 0.0544 0.0543 

[TRAIN] Epoch[1](251/375); Loss: 0.046014; Backpropagation: 0.2890 sec; Batch: 2.0751 sec
0.1084 0.0790 0.0584 0.0498 0.0440 0.0412 0.0394 0.0378 0.0368 0.0359 0.0352 0.0346 0.0343 0.0340 0.0338 0.0337 

[TRAIN] Epoch[1](252/375); Loss: 0.041987; Backpropagation: 0.2883 sec; Batch: 2.0757 sec
0.0810 0.0609 0.0496 0.0449 0.0417 0.0396 0.0382 0.0371 0.0362 0.0356 0.0351 0.0348 0.0345 0.0343 0.0342 0.0341 

[TRAIN] Epoch[1](253/375); Loss: 0.044783; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.0955 0.0717 0.0560 0.0479 0.0442 0.0415 0.0395 0.0382 0.0373 0.0364 0.0356 0.0351 0.0347 0.0344 0.0343 0.0342 

[TRAIN] Epoch[1](254/375); Loss: 0.052178; Backpropagation: 0.2887 sec; Batch: 2.0750 sec
0.0991 0.0757 0.0627 0.0570 0.0526 0.0500 0.0480 0.0463 0.0449 0.0440 0.0433 0.0428 0.0424 0.0422 0.0420 0.0419 

[TRAIN] Epoch[1](255/375); Loss: 0.057213; Backpropagation: 0.2884 sec; Batch: 2.0759 sec
0.1022 0.0779 0.0672 0.0622 0.0585 0.0557 0.0535 0.0518 0.0505 0.0495 0.0487 0.0482 0.0478 0.0474 0.0472 0.0470 

[TRAIN] Epoch[1](256/375); Loss: 0.038497; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0743 0.0555 0.0462 0.0415 0.0383 0.0364 0.0352 0.0340 0.0332 0.0326 0.0321 0.0317 0.0314 0.0313 0.0312 0.0310 

[TRAIN] Epoch[1](257/375); Loss: 0.067714; Backpropagation: 0.2887 sec; Batch: 2.0759 sec
0.1162 0.0915 0.0783 0.0719 0.0685 0.0661 0.0640 0.0621 0.0606 0.0595 0.0586 0.0580 0.0575 0.0571 0.0569 0.0566 

[TRAIN] Epoch[1](258/375); Loss: 0.048601; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.0940 0.0714 0.0633 0.0557 0.0503 0.0470 0.0446 0.0426 0.0410 0.0399 0.0391 0.0385 0.0380 0.0377 0.0374 0.0372 

[TRAIN] Epoch[1](259/375); Loss: 0.051721; Backpropagation: 0.2885 sec; Batch: 2.0755 sec
0.0958 0.0789 0.0619 0.0553 0.0521 0.0492 0.0473 0.0457 0.0445 0.0437 0.0431 0.0426 0.0422 0.0419 0.0417 0.0416 

[TRAIN] Epoch[1](260/375); Loss: 0.062764; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1203 0.0937 0.0762 0.0678 0.0633 0.0599 0.0571 0.0550 0.0537 0.0527 0.0519 0.0512 0.0507 0.0504 0.0502 0.0500 

[TRAIN] Epoch[1](261/375); Loss: 0.039670; Backpropagation: 0.2882 sec; Batch: 2.0749 sec
0.0788 0.0599 0.0489 0.0436 0.0402 0.0378 0.0361 0.0348 0.0336 0.0328 0.0322 0.0317 0.0314 0.0311 0.0310 0.0308 

[TRAIN] Epoch[1](262/375); Loss: 0.068241; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1165 0.0922 0.0819 0.0747 0.0699 0.0665 0.0639 0.0619 0.0605 0.0594 0.0585 0.0579 0.0574 0.0571 0.0568 0.0567 

[TRAIN] Epoch[1](263/375); Loss: 0.043529; Backpropagation: 0.2884 sec; Batch: 2.0755 sec
0.0997 0.0644 0.0536 0.0475 0.0426 0.0403 0.0385 0.0371 0.0360 0.0352 0.0345 0.0340 0.0336 0.0334 0.0332 0.0330 

[TRAIN] Epoch[1](264/375); Loss: 0.037596; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.0873 0.0591 0.0470 0.0406 0.0373 0.0347 0.0330 0.0316 0.0306 0.0298 0.0292 0.0288 0.0284 0.0282 0.0280 0.0279 

[TRAIN] Epoch[1](265/375); Loss: 0.044288; Backpropagation: 0.2885 sec; Batch: 2.0846 sec
0.1000 0.0662 0.0544 0.0482 0.0440 0.0413 0.0393 0.0376 0.0366 0.0358 0.0351 0.0346 0.0342 0.0340 0.0337 0.0335 

[TRAIN] Epoch[1](266/375); Loss: 0.042416; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.0881 0.0579 0.0486 0.0454 0.0418 0.0400 0.0385 0.0373 0.0364 0.0357 0.0354 0.0350 0.0348 0.0347 0.0346 0.0345 

[TRAIN] Epoch[1](267/375); Loss: 0.046280; Backpropagation: 0.2882 sec; Batch: 2.0807 sec
0.0855 0.0663 0.0573 0.0510 0.0473 0.0446 0.0428 0.0414 0.0402 0.0392 0.0384 0.0379 0.0375 0.0374 0.0371 0.0369 

[TRAIN] Epoch[1](268/375); Loss: 0.038291; Backpropagation: 0.2883 sec; Batch: 2.0747 sec
0.0896 0.0595 0.0458 0.0393 0.0365 0.0344 0.0329 0.0320 0.0314 0.0309 0.0305 0.0303 0.0300 0.0298 0.0297 0.0297 

[TRAIN] Epoch[1](269/375); Loss: 0.039986; Backpropagation: 0.2882 sec; Batch: 2.0751 sec
0.0668 0.0556 0.0493 0.0444 0.0412 0.0391 0.0376 0.0365 0.0354 0.0347 0.0341 0.0335 0.0332 0.0330 0.0328 0.0326 

[TRAIN] Epoch[1](270/375); Loss: 0.032602; Backpropagation: 0.2886 sec; Batch: 2.0758 sec
0.0755 0.0515 0.0395 0.0349 0.0321 0.0301 0.0286 0.0273 0.0265 0.0259 0.0255 0.0252 0.0250 0.0248 0.0247 0.0245 

[TRAIN] Epoch[1](271/375); Loss: 0.050966; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.0987 0.0727 0.0610 0.0551 0.0515 0.0489 0.0469 0.0453 0.0440 0.0431 0.0424 0.0419 0.0415 0.0411 0.0408 0.0405 

[TRAIN] Epoch[1](272/375); Loss: 0.024703; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.0641 0.0449 0.0327 0.0266 0.0233 0.0216 0.0204 0.0195 0.0188 0.0184 0.0180 0.0177 0.0175 0.0174 0.0173 0.0172 

[TRAIN] Epoch[1](273/375); Loss: 0.047353; Backpropagation: 0.2885 sec; Batch: 2.0763 sec
0.0987 0.0696 0.0554 0.0502 0.0472 0.0449 0.0430 0.0415 0.0403 0.0394 0.0388 0.0383 0.0379 0.0377 0.0374 0.0373 

[TRAIN] Epoch[1](274/375); Loss: 0.062792; Backpropagation: 0.2880 sec; Batch: 2.0751 sec
0.1331 0.0981 0.0795 0.0683 0.0620 0.0586 0.0559 0.0538 0.0522 0.0509 0.0500 0.0493 0.0488 0.0483 0.0480 0.0477 

[TRAIN] Epoch[1](275/375); Loss: 0.023707; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.0598 0.0399 0.0303 0.0257 0.0228 0.0211 0.0199 0.0191 0.0185 0.0180 0.0177 0.0175 0.0174 0.0172 0.0172 0.0171 

[TRAIN] Epoch[1](276/375); Loss: 0.048523; Backpropagation: 0.2886 sec; Batch: 2.0760 sec
0.0946 0.0684 0.0577 0.0523 0.0483 0.0460 0.0444 0.0430 0.0420 0.0411 0.0406 0.0401 0.0398 0.0395 0.0393 0.0392 

[TRAIN] Epoch[1](277/375); Loss: 0.057446; Backpropagation: 0.2887 sec; Batch: 2.0755 sec
0.1143 0.0877 0.0704 0.0623 0.0578 0.0543 0.0519 0.0499 0.0487 0.0476 0.0468 0.0463 0.0458 0.0454 0.0451 0.0449 

[TRAIN] Epoch[1](278/375); Loss: 0.054155; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.1045 0.0859 0.0679 0.0597 0.0545 0.0513 0.0486 0.0468 0.0456 0.0447 0.0439 0.0433 0.0428 0.0425 0.0422 0.0420 

[TRAIN] Epoch[1](279/375); Loss: 0.045590; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.0836 0.0675 0.0567 0.0503 0.0464 0.0441 0.0422 0.0406 0.0393 0.0384 0.0377 0.0372 0.0368 0.0364 0.0362 0.0359 

[TRAIN] Epoch[1](280/375); Loss: 0.045120; Backpropagation: 0.2886 sec; Batch: 2.0772 sec
0.0907 0.0679 0.0546 0.0486 0.0450 0.0427 0.0407 0.0393 0.0383 0.0376 0.0369 0.0365 0.0361 0.0359 0.0356 0.0355 

[TRAIN] Epoch[1](281/375); Loss: 0.041381; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0842 0.0673 0.0543 0.0470 0.0421 0.0388 0.0364 0.0350 0.0339 0.0331 0.0325 0.0320 0.0317 0.0314 0.0313 0.0311 

[TRAIN] Epoch[1](282/375); Loss: 0.053434; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1029 0.0769 0.0640 0.0577 0.0539 0.0510 0.0489 0.0473 0.0461 0.0452 0.0445 0.0439 0.0436 0.0432 0.0430 0.0429 

[TRAIN] Epoch[1](283/375); Loss: 0.034462; Backpropagation: 0.2882 sec; Batch: 2.0752 sec
0.0835 0.0551 0.0429 0.0382 0.0345 0.0319 0.0298 0.0285 0.0275 0.0268 0.0263 0.0258 0.0255 0.0253 0.0250 0.0249 

[TRAIN] Epoch[1](284/375); Loss: 0.050643; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.0931 0.0741 0.0633 0.0566 0.0524 0.0492 0.0468 0.0451 0.0438 0.0427 0.0418 0.0411 0.0406 0.0402 0.0398 0.0396 

[TRAIN] Epoch[1](285/375); Loss: 0.053295; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1154 0.0801 0.0649 0.0587 0.0542 0.0510 0.0484 0.0463 0.0446 0.0433 0.0423 0.0416 0.0410 0.0406 0.0403 0.0400 

[TRAIN] Epoch[1](286/375); Loss: 0.059938; Backpropagation: 0.2883 sec; Batch: 2.0789 sec
0.1070 0.0840 0.0718 0.0656 0.0616 0.0584 0.0561 0.0542 0.0527 0.0516 0.0505 0.0498 0.0493 0.0490 0.0488 0.0486 

[TRAIN] Epoch[1](287/375); Loss: 0.049639; Backpropagation: 0.2885 sec; Batch: 2.0753 sec
0.1025 0.0743 0.0619 0.0542 0.0498 0.0469 0.0445 0.0427 0.0413 0.0404 0.0398 0.0394 0.0393 0.0391 0.0391 0.0392 

[TRAIN] Epoch[1](288/375); Loss: 0.049978; Backpropagation: 0.2883 sec; Batch: 2.0735 sec
0.0926 0.0677 0.0588 0.0538 0.0505 0.0480 0.0461 0.0447 0.0435 0.0428 0.0423 0.0420 0.0417 0.0416 0.0416 0.0417 

[TRAIN] Epoch[1](289/375); Loss: 0.042416; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0734 0.0602 0.0516 0.0463 0.0428 0.0405 0.0391 0.0379 0.0371 0.0365 0.0360 0.0357 0.0355 0.0354 0.0353 0.0353 

[TRAIN] Epoch[1](290/375); Loss: 0.053864; Backpropagation: 0.2882 sec; Batch: 2.0732 sec
0.1105 0.0801 0.0666 0.0599 0.0548 0.0510 0.0485 0.0467 0.0453 0.0442 0.0434 0.0428 0.0422 0.0421 0.0419 0.0418 

[TRAIN] Epoch[1](291/375); Loss: 0.052266; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0974 0.0755 0.0632 0.0568 0.0529 0.0500 0.0480 0.0464 0.0452 0.0443 0.0437 0.0431 0.0427 0.0425 0.0423 0.0422 

[TRAIN] Epoch[1](292/375); Loss: 0.033438; Backpropagation: 0.2881 sec; Batch: 2.0753 sec
0.0771 0.0512 0.0398 0.0349 0.0325 0.0310 0.0297 0.0286 0.0278 0.0271 0.0266 0.0262 0.0259 0.0257 0.0255 0.0254 

[TRAIN] Epoch[1](293/375); Loss: 0.061579; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1061 0.0862 0.0748 0.0675 0.0632 0.0602 0.0577 0.0558 0.0544 0.0532 0.0523 0.0517 0.0511 0.0507 0.0504 0.0501 

[TRAIN] Epoch[1](294/375); Loss: 0.044163; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.1013 0.0701 0.0568 0.0498 0.0445 0.0412 0.0385 0.0367 0.0355 0.0345 0.0339 0.0334 0.0330 0.0327 0.0325 0.0324 

[TRAIN] Epoch[1](295/375); Loss: 0.032356; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0685 0.0498 0.0397 0.0346 0.0317 0.0298 0.0285 0.0275 0.0269 0.0265 0.0262 0.0259 0.0257 0.0255 0.0254 0.0254 

[TRAIN] Epoch[1](296/375); Loss: 0.043723; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.0949 0.0651 0.0523 0.0465 0.0430 0.0405 0.0388 0.0377 0.0368 0.0360 0.0354 0.0350 0.0347 0.0345 0.0343 0.0342 

[TRAIN] Epoch[1](297/375); Loss: 0.048743; Backpropagation: 0.2885 sec; Batch: 2.0746 sec
0.1138 0.0774 0.0611 0.0525 0.0486 0.0452 0.0426 0.0408 0.0394 0.0385 0.0378 0.0371 0.0367 0.0363 0.0361 0.0358 

[TRAIN] Epoch[1](298/375); Loss: 0.066983; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1225 0.1007 0.0858 0.0744 0.0680 0.0639 0.0611 0.0591 0.0573 0.0561 0.0550 0.0544 0.0539 0.0534 0.0532 0.0529 

[TRAIN] Epoch[1](299/375); Loss: 0.053110; Backpropagation: 0.2882 sec; Batch: 2.0748 sec
0.1137 0.0919 0.0779 0.0666 0.0589 0.0529 0.0479 0.0434 0.0402 0.0386 0.0375 0.0367 0.0363 0.0359 0.0357 0.0356 

[TRAIN] Epoch[1](300/375); Loss: 0.045463; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.0812 0.0646 0.0537 0.0484 0.0453 0.0432 0.0418 0.0406 0.0399 0.0394 0.0389 0.0385 0.0382 0.0380 0.0379 0.0377 

[TRAIN] Epoch[1](301/375); Loss: 0.046005; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.0976 0.0711 0.0589 0.0518 0.0466 0.0433 0.0409 0.0391 0.0378 0.0369 0.0363 0.0357 0.0354 0.0351 0.0349 0.0347 

[TRAIN] Epoch[1](302/375); Loss: 0.051391; Backpropagation: 0.2886 sec; Batch: 2.0755 sec
0.1010 0.0745 0.0618 0.0554 0.0516 0.0487 0.0468 0.0452 0.0441 0.0434 0.0427 0.0421 0.0417 0.0413 0.0411 0.0409 

[TRAIN] Epoch[1](303/375); Loss: 0.051381; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.1002 0.0787 0.0665 0.0585 0.0531 0.0494 0.0466 0.0447 0.0430 0.0420 0.0411 0.0405 0.0399 0.0396 0.0393 0.0391 

[TRAIN] Epoch[1](304/375); Loss: 0.045883; Backpropagation: 0.2883 sec; Batch: 2.0880 sec
0.0842 0.0611 0.0524 0.0479 0.0459 0.0442 0.0428 0.0417 0.0408 0.0401 0.0395 0.0392 0.0389 0.0386 0.0384 0.0383 

[TRAIN] Epoch[1](305/375); Loss: 0.047821; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.0910 0.0685 0.0567 0.0515 0.0482 0.0458 0.0439 0.0425 0.0415 0.0407 0.0401 0.0395 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[1](306/375); Loss: 0.046096; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0808 0.0633 0.0541 0.0483 0.0455 0.0436 0.0425 0.0417 0.0410 0.0404 0.0399 0.0396 0.0394 0.0392 0.0391 0.0390 

[TRAIN] Epoch[1](307/375); Loss: 0.042780; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0804 0.0654 0.0544 0.0486 0.0440 0.0407 0.0382 0.0368 0.0359 0.0352 0.0347 0.0344 0.0342 0.0340 0.0339 0.0338 

[TRAIN] Epoch[1](308/375); Loss: 0.064507; Backpropagation: 0.2881 sec; Batch: 2.0738 sec
0.1168 0.0974 0.0821 0.0726 0.0663 0.0617 0.0585 0.0568 0.0553 0.0541 0.0531 0.0524 0.0518 0.0513 0.0510 0.0508 

[TRAIN] Epoch[1](309/375); Loss: 0.049076; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.0982 0.0756 0.0624 0.0548 0.0499 0.0465 0.0441 0.0425 0.0413 0.0402 0.0394 0.0389 0.0384 0.0380 0.0377 0.0375 

[TRAIN] Epoch[1](310/375); Loss: 0.053969; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.0934 0.0740 0.0644 0.0600 0.0557 0.0526 0.0504 0.0487 0.0476 0.0465 0.0459 0.0454 0.0450 0.0447 0.0446 0.0445 

[TRAIN] Epoch[1](311/375); Loss: 0.032587; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0864 0.0569 0.0420 0.0352 0.0313 0.0288 0.0271 0.0261 0.0251 0.0243 0.0237 0.0233 0.0230 0.0228 0.0227 0.0226 

[TRAIN] Epoch[1](312/375); Loss: 0.053848; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.1026 0.0796 0.0653 0.0583 0.0541 0.0514 0.0496 0.0478 0.0464 0.0455 0.0446 0.0440 0.0436 0.0432 0.0429 0.0427 

[TRAIN] Epoch[1](313/375); Loss: 0.043856; Backpropagation: 0.2884 sec; Batch: 2.0746 sec
0.0816 0.0628 0.0520 0.0483 0.0450 0.0422 0.0405 0.0391 0.0381 0.0373 0.0367 0.0362 0.0358 0.0356 0.0354 0.0352 

[TRAIN] Epoch[1](314/375); Loss: 0.038585; Backpropagation: 0.2887 sec; Batch: 2.0735 sec
0.0716 0.0577 0.0484 0.0430 0.0392 0.0367 0.0350 0.0337 0.0329 0.0323 0.0318 0.0313 0.0311 0.0309 0.0308 0.0308 

[TRAIN] Epoch[1](315/375); Loss: 0.049619; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.1008 0.0769 0.0615 0.0549 0.0504 0.0473 0.0447 0.0429 0.0416 0.0405 0.0398 0.0393 0.0388 0.0385 0.0382 0.0380 

[TRAIN] Epoch[1](316/375); Loss: 0.047182; Backpropagation: 0.2895 sec; Batch: 2.0750 sec
0.0987 0.0757 0.0609 0.0538 0.0490 0.0450 0.0425 0.0402 0.0388 0.0376 0.0367 0.0360 0.0355 0.0351 0.0348 0.0346 

[TRAIN] Epoch[1](317/375); Loss: 0.051481; Backpropagation: 0.2900 sec; Batch: 2.1155 sec
0.1112 0.0794 0.0634 0.0564 0.0513 0.0479 0.0457 0.0440 0.0429 0.0420 0.0412 0.0405 0.0400 0.0396 0.0393 0.0391 

[TRAIN] Epoch[1](318/375); Loss: 0.053031; Backpropagation: 0.2886 sec; Batch: 2.0786 sec
0.1009 0.0765 0.0632 0.0578 0.0539 0.0511 0.0490 0.0474 0.0462 0.0451 0.0442 0.0434 0.0430 0.0426 0.0423 0.0421 

[TRAIN] Epoch[1](319/375); Loss: 0.064786; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1237 0.0963 0.0784 0.0692 0.0644 0.0614 0.0592 0.0574 0.0559 0.0547 0.0537 0.0532 0.0527 0.0524 0.0521 0.0519 

[TRAIN] Epoch[1](320/375); Loss: 0.050386; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.1186 0.0819 0.0626 0.0529 0.0478 0.0451 0.0435 0.0422 0.0410 0.0402 0.0395 0.0389 0.0384 0.0381 0.0378 0.0377 

[TRAIN] Epoch[1](321/375); Loss: 0.056966; Backpropagation: 0.2881 sec; Batch: 2.0762 sec
0.1241 0.0854 0.0682 0.0606 0.0560 0.0531 0.0509 0.0492 0.0476 0.0468 0.0460 0.0455 0.0449 0.0446 0.0443 0.0441 

[TRAIN] Epoch[1](322/375); Loss: 0.051033; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1248 0.0828 0.0658 0.0555 0.0491 0.0459 0.0438 0.0419 0.0408 0.0396 0.0388 0.0382 0.0378 0.0374 0.0372 0.0370 

[TRAIN] Epoch[1](323/375); Loss: 0.045407; Backpropagation: 0.2881 sec; Batch: 2.0796 sec
0.1115 0.0703 0.0598 0.0492 0.0445 0.0413 0.0395 0.0375 0.0363 0.0352 0.0345 0.0340 0.0336 0.0333 0.0331 0.0330 

[TRAIN] Epoch[1](324/375); Loss: 0.043110; Backpropagation: 0.2880 sec; Batch: 2.0740 sec
0.0917 0.0699 0.0538 0.0470 0.0427 0.0401 0.0381 0.0368 0.0355 0.0346 0.0340 0.0335 0.0332 0.0330 0.0329 0.0328 

[TRAIN] Epoch[1](325/375); Loss: 0.044334; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1010 0.0655 0.0518 0.0452 0.0431 0.0409 0.0393 0.0381 0.0371 0.0364 0.0359 0.0354 0.0351 0.0350 0.0348 0.0347 

[TRAIN] Epoch[1](326/375); Loss: 0.048538; Backpropagation: 0.2881 sec; Batch: 2.0744 sec
0.1149 0.0786 0.0649 0.0528 0.0483 0.0449 0.0420 0.0401 0.0386 0.0375 0.0367 0.0361 0.0357 0.0353 0.0351 0.0350 

[TRAIN] Epoch[1](327/375); Loss: 0.052302; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1335 0.0781 0.0694 0.0583 0.0525 0.0481 0.0451 0.0427 0.0413 0.0401 0.0391 0.0385 0.0380 0.0377 0.0374 0.0372 

[TRAIN] Epoch[1](328/375); Loss: 0.053085; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.1341 0.0870 0.0658 0.0561 0.0517 0.0481 0.0456 0.0436 0.0421 0.0410 0.0401 0.0396 0.0391 0.0388 0.0385 0.0383 

[TRAIN] Epoch[1](329/375); Loss: 0.052199; Backpropagation: 0.2883 sec; Batch: 2.0747 sec
0.1382 0.0882 0.0651 0.0558 0.0503 0.0468 0.0441 0.0421 0.0407 0.0396 0.0387 0.0379 0.0374 0.0370 0.0367 0.0365 

[TRAIN] Epoch[1](330/375); Loss: 0.069105; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1391 0.1046 0.0896 0.0761 0.0699 0.0652 0.0614 0.0591 0.0575 0.0564 0.0556 0.0550 0.0545 0.0541 0.0538 0.0536 

[TRAIN] Epoch[1](331/375); Loss: 0.047588; Backpropagation: 0.2887 sec; Batch: 2.0742 sec
0.1175 0.0760 0.0694 0.0571 0.0507 0.0444 0.0408 0.0382 0.0360 0.0347 0.0339 0.0332 0.0328 0.0325 0.0322 0.0320 

[TRAIN] Epoch[1](332/375); Loss: 0.059557; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.1358 0.0992 0.0814 0.0663 0.0591 0.0537 0.0505 0.0484 0.0471 0.0461 0.0453 0.0447 0.0443 0.0439 0.0437 0.0435 

[TRAIN] Epoch[1](333/375); Loss: 0.061895; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.1454 0.0918 0.0743 0.0641 0.0595 0.0563 0.0544 0.0527 0.0514 0.0504 0.0495 0.0489 0.0484 0.0480 0.0477 0.0474 

[TRAIN] Epoch[1](334/375); Loss: 0.053992; Backpropagation: 0.2882 sec; Batch: 2.0862 sec
0.1298 0.0880 0.0746 0.0590 0.0516 0.0481 0.0459 0.0442 0.0428 0.0417 0.0409 0.0402 0.0398 0.0394 0.0391 0.0389 

[TRAIN] Epoch[1](335/375); Loss: 0.056362; Backpropagation: 0.2882 sec; Batch: 2.0755 sec
0.1219 0.0886 0.0722 0.0637 0.0579 0.0535 0.0504 0.0480 0.0461 0.0448 0.0437 0.0431 0.0425 0.0421 0.0418 0.0416 

[TRAIN] Epoch[1](336/375); Loss: 0.055940; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1322 0.1025 0.0840 0.0657 0.0559 0.0506 0.0469 0.0444 0.0424 0.0410 0.0400 0.0390 0.0383 0.0378 0.0374 0.0370 

[TRAIN] Epoch[1](337/375); Loss: 0.056122; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.1245 0.0875 0.0717 0.0641 0.0572 0.0530 0.0501 0.0480 0.0461 0.0445 0.0435 0.0425 0.0419 0.0415 0.0411 0.0409 

[TRAIN] Epoch[1](338/375); Loss: 0.056634; Backpropagation: 0.2879 sec; Batch: 2.0730 sec
0.1246 0.0942 0.0755 0.0649 0.0569 0.0522 0.0491 0.0471 0.0456 0.0444 0.0434 0.0426 0.0419 0.0415 0.0412 0.0410 

[TRAIN] Epoch[1](339/375); Loss: 0.053723; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1256 0.0867 0.0688 0.0604 0.0536 0.0487 0.0465 0.0447 0.0432 0.0420 0.0411 0.0405 0.0400 0.0395 0.0392 0.0390 

[TRAIN] Epoch[1](340/375); Loss: 0.058233; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.1301 0.0981 0.0766 0.0656 0.0585 0.0540 0.0510 0.0486 0.0468 0.0455 0.0444 0.0435 0.0429 0.0424 0.0420 0.0417 

[TRAIN] Epoch[1](341/375); Loss: 0.043761; Backpropagation: 0.2882 sec; Batch: 2.0741 sec
0.1046 0.0759 0.0638 0.0505 0.0439 0.0394 0.0366 0.0350 0.0337 0.0327 0.0319 0.0313 0.0308 0.0304 0.0300 0.0298 

[TRAIN] Epoch[1](342/375); Loss: 0.045698; Backpropagation: 0.2879 sec; Batch: 2.0752 sec
0.1019 0.0839 0.0635 0.0519 0.0468 0.0427 0.0395 0.0374 0.0358 0.0344 0.0334 0.0327 0.0322 0.0319 0.0317 0.0316 

[TRAIN] Epoch[1](343/375); Loss: 0.035504; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0905 0.0631 0.0466 0.0427 0.0359 0.0320 0.0296 0.0282 0.0269 0.0259 0.0253 0.0248 0.0245 0.0242 0.0240 0.0239 

[TRAIN] Epoch[1](344/375); Loss: 0.069353; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.1452 0.1111 0.0939 0.0785 0.0703 0.0661 0.0626 0.0596 0.0569 0.0551 0.0537 0.0526 0.0518 0.0512 0.0508 0.0505 

[TRAIN] Epoch[1](345/375); Loss: 0.060877; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1198 0.0883 0.0755 0.0659 0.0615 0.0574 0.0550 0.0534 0.0520 0.0508 0.0501 0.0494 0.0490 0.0488 0.0486 0.0485 

[TRAIN] Epoch[1](346/375); Loss: 0.050519; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.1133 0.0791 0.0679 0.0560 0.0502 0.0469 0.0444 0.0425 0.0411 0.0399 0.0390 0.0383 0.0379 0.0376 0.0373 0.0371 

[TRAIN] Epoch[1](347/375); Loss: 0.051131; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1172 0.0966 0.0696 0.0550 0.0481 0.0447 0.0428 0.0411 0.0399 0.0390 0.0383 0.0378 0.0374 0.0370 0.0369 0.0367 

[TRAIN] Epoch[1](348/375); Loss: 0.046448; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1020 0.0789 0.0660 0.0534 0.0456 0.0417 0.0393 0.0379 0.0367 0.0359 0.0352 0.0347 0.0343 0.0340 0.0339 0.0338 

[TRAIN] Epoch[1](349/375); Loss: 0.055227; Backpropagation: 0.2886 sec; Batch: 2.0841 sec
0.1378 0.1113 0.0817 0.0574 0.0528 0.0479 0.0452 0.0429 0.0412 0.0398 0.0389 0.0382 0.0377 0.0373 0.0369 0.0367 

[TRAIN] Epoch[1](350/375); Loss: 0.058780; Backpropagation: 0.2883 sec; Batch: 2.0753 sec
0.1341 0.1019 0.0782 0.0651 0.0570 0.0534 0.0506 0.0483 0.0468 0.0457 0.0446 0.0439 0.0433 0.0429 0.0425 0.0422 

[TRAIN] Epoch[1](351/375); Loss: 0.047660; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.0951 0.0700 0.0595 0.0512 0.0470 0.0448 0.0434 0.0419 0.0408 0.0398 0.0392 0.0386 0.0382 0.0379 0.0376 0.0375 

[TRAIN] Epoch[1](352/375); Loss: 0.046116; Backpropagation: 0.2880 sec; Batch: 2.0747 sec
0.1038 0.0850 0.0674 0.0537 0.0461 0.0420 0.0392 0.0373 0.0357 0.0345 0.0335 0.0328 0.0322 0.0318 0.0315 0.0313 

[TRAIN] Epoch[1](353/375); Loss: 0.065639; Backpropagation: 0.2882 sec; Batch: 2.0803 sec
0.1270 0.1074 0.0914 0.0748 0.0662 0.0613 0.0583 0.0556 0.0537 0.0525 0.0516 0.0510 0.0504 0.0500 0.0497 0.0495 

[TRAIN] Epoch[1](354/375); Loss: 0.062216; Backpropagation: 0.2886 sec; Batch: 2.0761 sec
0.1266 0.0950 0.0858 0.0755 0.0673 0.0615 0.0573 0.0537 0.0509 0.0491 0.0476 0.0463 0.0455 0.0449 0.0444 0.0442 

[TRAIN] Epoch[1](355/375); Loss: 0.068409; Backpropagation: 0.2887 sec; Batch: 2.0751 sec
0.1408 0.1066 0.0931 0.0788 0.0711 0.0657 0.0620 0.0596 0.0573 0.0552 0.0535 0.0519 0.0508 0.0500 0.0493 0.0489 

[TRAIN] Epoch[1](356/375); Loss: 0.066884; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1481 0.1074 0.0859 0.0740 0.0682 0.0639 0.0602 0.0569 0.0545 0.0527 0.0514 0.0505 0.0497 0.0493 0.0490 0.0487 

[TRAIN] Epoch[1](357/375); Loss: 0.034774; Backpropagation: 0.2882 sec; Batch: 2.0746 sec
0.0787 0.0541 0.0445 0.0374 0.0334 0.0314 0.0300 0.0290 0.0283 0.0277 0.0274 0.0271 0.0270 0.0268 0.0268 0.0268 

[TRAIN] Epoch[1](358/375); Loss: 0.050416; Backpropagation: 0.2884 sec; Batch: 2.0753 sec
0.1027 0.0914 0.0728 0.0575 0.0500 0.0460 0.0435 0.0417 0.0402 0.0390 0.0382 0.0374 0.0370 0.0367 0.0364 0.0362 

[TRAIN] Epoch[1](359/375); Loss: 0.053482; Backpropagation: 0.2881 sec; Batch: 2.0747 sec
0.1067 0.0843 0.0731 0.0609 0.0540 0.0501 0.0477 0.0458 0.0443 0.0430 0.0421 0.0414 0.0409 0.0406 0.0403 0.0402 

[TRAIN] Epoch[1](360/375); Loss: 0.032418; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0777 0.0519 0.0452 0.0355 0.0318 0.0293 0.0277 0.0265 0.0256 0.0249 0.0244 0.0240 0.0237 0.0235 0.0234 0.0234 

[TRAIN] Epoch[1](361/375); Loss: 0.062016; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.1300 0.0973 0.0784 0.0671 0.0613 0.0576 0.0550 0.0532 0.0516 0.0503 0.0495 0.0489 0.0485 0.0480 0.0478 0.0476 

[TRAIN] Epoch[1](362/375); Loss: 0.042274; Backpropagation: 0.2883 sec; Batch: 2.0745 sec
0.0994 0.0795 0.0601 0.0466 0.0404 0.0371 0.0349 0.0333 0.0322 0.0313 0.0309 0.0305 0.0303 0.0301 0.0300 0.0299 

[TRAIN] Epoch[1](363/375); Loss: 0.060448; Backpropagation: 0.2887 sec; Batch: 2.0857 sec
0.1189 0.0923 0.0804 0.0675 0.0614 0.0572 0.0544 0.0522 0.0504 0.0492 0.0484 0.0478 0.0473 0.0469 0.0466 0.0464 

[TRAIN] Epoch[1](364/375); Loss: 0.055902; Backpropagation: 0.2881 sec; Batch: 2.0758 sec
0.1246 0.0892 0.0747 0.0619 0.0550 0.0516 0.0490 0.0470 0.0454 0.0442 0.0435 0.0426 0.0421 0.0416 0.0412 0.0409 

[TRAIN] Epoch[1](365/375); Loss: 0.049411; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1148 0.0797 0.0668 0.0564 0.0490 0.0451 0.0429 0.0410 0.0394 0.0384 0.0374 0.0368 0.0363 0.0358 0.0356 0.0353 

[TRAIN] Epoch[1](366/375); Loss: 0.047515; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.1067 0.0729 0.0613 0.0501 0.0460 0.0431 0.0415 0.0401 0.0390 0.0383 0.0377 0.0372 0.0368 0.0367 0.0365 0.0364 

[TRAIN] Epoch[1](367/375); Loss: 0.047837; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1065 0.0836 0.0648 0.0533 0.0479 0.0440 0.0415 0.0394 0.0380 0.0367 0.0359 0.0354 0.0350 0.0347 0.0345 0.0343 

[TRAIN] Epoch[1](368/375); Loss: 0.076766; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.1410 0.1061 0.0934 0.0830 0.0779 0.0741 0.0714 0.0690 0.0672 0.0659 0.0648 0.0639 0.0632 0.0627 0.0624 0.0623 

[TRAIN] Epoch[1](369/375); Loss: 0.056504; Backpropagation: 0.2882 sec; Batch: 2.0844 sec
0.1265 0.0861 0.0760 0.0627 0.0572 0.0533 0.0504 0.0481 0.0461 0.0447 0.0437 0.0429 0.0421 0.0417 0.0413 0.0411 

[TRAIN] Epoch[1](370/375); Loss: 0.032225; Backpropagation: 0.2887 sec; Batch: 2.0764 sec
0.0808 0.0522 0.0407 0.0341 0.0309 0.0289 0.0276 0.0264 0.0255 0.0249 0.0244 0.0241 0.0239 0.0238 0.0237 0.0237 

[TRAIN] Epoch[1](371/375); Loss: 0.048367; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1079 0.0748 0.0661 0.0535 0.0483 0.0445 0.0425 0.0406 0.0393 0.0383 0.0375 0.0368 0.0363 0.0360 0.0358 0.0356 

[TRAIN] Epoch[1](372/375); Loss: 0.034469; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.0884 0.0605 0.0477 0.0379 0.0334 0.0304 0.0287 0.0274 0.0263 0.0255 0.0250 0.0246 0.0242 0.0239 0.0237 0.0237 

[TRAIN] Epoch[1](373/375); Loss: 0.044984; Backpropagation: 0.2884 sec; Batch: 2.0874 sec
0.1071 0.0748 0.0576 0.0479 0.0431 0.0404 0.0387 0.0374 0.0362 0.0354 0.0346 0.0340 0.0335 0.0332 0.0330 0.0329 

[TRAIN] Epoch[1](374/375); Loss: 0.052105; Backpropagation: 0.2880 sec; Batch: 2.0755 sec
0.1220 0.0821 0.0672 0.0558 0.0508 0.0475 0.0454 0.0436 0.0421 0.0412 0.0404 0.0398 0.0394 0.0391 0.0388 0.0386 

[TRAIN] Epoch[1](375/375); Loss: 0.029223; Backpropagation: 0.2881 sec; Batch: 2.0734 sec
0.0868 0.0543 0.0425 0.0317 0.0270 0.0241 0.0231 0.0217 0.0207 0.0201 0.0197 0.0194 0.0192 0.0191 0.0190 0.0190 

/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
train.py:248: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  len(train_loader), loss.data[0], bp_t1 - bp_t0, batch_t1 -
train.py:251: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  '\n').format(* [l.data[0] for l in losses]))
[TRAIN] Epoch[2](1/375); Loss: 0.064030; Backpropagation: 0.3022 sec; Batch: 2.1484 sec
0.1363 0.0925 0.0794 0.0681 0.0633 0.0600 0.0575 0.0557 0.0542 0.0530 0.0521 0.0513 0.0507 0.0503 0.0500 0.0498 

[TRAIN] Epoch[2](2/375); Loss: 0.066192; Backpropagation: 0.2908 sec; Batch: 2.1002 sec
0.1413 0.1034 0.0853 0.0730 0.0666 0.0623 0.0591 0.0565 0.0546 0.0531 0.0520 0.0513 0.0507 0.0503 0.0499 0.0497 

[TRAIN] Epoch[2](3/375); Loss: 0.052994; Backpropagation: 0.2910 sec; Batch: 2.0847 sec
0.1155 0.0813 0.0700 0.0586 0.0525 0.0492 0.0473 0.0454 0.0438 0.0427 0.0417 0.0409 0.0403 0.0399 0.0396 0.0393 

[TRAIN] Epoch[2](4/375); Loss: 0.048149; Backpropagation: 0.2881 sec; Batch: 2.0747 sec
0.1181 0.0791 0.0626 0.0526 0.0478 0.0443 0.0414 0.0393 0.0379 0.0368 0.0360 0.0355 0.0351 0.0349 0.0346 0.0345 

[TRAIN] Epoch[2](5/375); Loss: 0.049648; Backpropagation: 0.2880 sec; Batch: 2.0747 sec
0.0999 0.0763 0.0649 0.0535 0.0484 0.0462 0.0444 0.0430 0.0419 0.0408 0.0400 0.0395 0.0391 0.0389 0.0388 0.0387 

[TRAIN] Epoch[2](6/375); Loss: 0.058865; Backpropagation: 0.2880 sec; Batch: 2.0748 sec
0.1079 0.0889 0.0732 0.0639 0.0591 0.0565 0.0541 0.0522 0.0508 0.0497 0.0487 0.0481 0.0476 0.0473 0.0470 0.0468 

[TRAIN] Epoch[2](7/375); Loss: 0.054331; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1439 0.0979 0.0707 0.0630 0.0542 0.0483 0.0451 0.0423 0.0406 0.0394 0.0384 0.0377 0.0372 0.0370 0.0368 0.0367 

[TRAIN] Epoch[2](8/375); Loss: 0.051941; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.1237 0.0890 0.0721 0.0582 0.0498 0.0463 0.0434 0.0418 0.0403 0.0393 0.0387 0.0382 0.0379 0.0376 0.0375 0.0374 

[TRAIN] Epoch[2](9/375); Loss: 0.043376; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.1008 0.0696 0.0562 0.0475 0.0430 0.0403 0.0379 0.0362 0.0350 0.0340 0.0332 0.0327 0.0323 0.0320 0.0318 0.0316 

[TRAIN] Epoch[2](10/375); Loss: 0.051834; Backpropagation: 0.2885 sec; Batch: 2.0759 sec
0.1171 0.0808 0.0659 0.0567 0.0520 0.0484 0.0457 0.0438 0.0424 0.0414 0.0405 0.0398 0.0392 0.0388 0.0385 0.0383 

[TRAIN] Epoch[2](11/375); Loss: 0.051914; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.1185 0.0846 0.0689 0.0584 0.0521 0.0480 0.0453 0.0432 0.0416 0.0404 0.0394 0.0389 0.0383 0.0380 0.0377 0.0374 

[TRAIN] Epoch[2](12/375); Loss: 0.051171; Backpropagation: 0.2886 sec; Batch: 2.0757 sec
0.1104 0.0774 0.0628 0.0556 0.0510 0.0485 0.0461 0.0442 0.0428 0.0417 0.0409 0.0402 0.0398 0.0394 0.0391 0.0389 

[TRAIN] Epoch[2](13/375); Loss: 0.057641; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.1198 0.0854 0.0756 0.0629 0.0576 0.0542 0.0516 0.0498 0.0482 0.0471 0.0463 0.0456 0.0451 0.0447 0.0444 0.0441 

[TRAIN] Epoch[2](14/375); Loss: 0.049780; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.1056 0.0727 0.0634 0.0552 0.0502 0.0470 0.0447 0.0430 0.0416 0.0406 0.0398 0.0392 0.0387 0.0385 0.0382 0.0380 

[TRAIN] Epoch[2](15/375); Loss: 0.055666; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1106 0.0785 0.0703 0.0602 0.0560 0.0530 0.0509 0.0492 0.0479 0.0467 0.0458 0.0451 0.0446 0.0442 0.0439 0.0436 

[TRAIN] Epoch[2](16/375); Loss: 0.037440; Backpropagation: 0.2884 sec; Batch: 2.0762 sec
0.0868 0.0549 0.0480 0.0397 0.0367 0.0343 0.0328 0.0316 0.0307 0.0301 0.0296 0.0292 0.0289 0.0287 0.0286 0.0285 

[TRAIN] Epoch[2](17/375); Loss: 0.041496; Backpropagation: 0.2884 sec; Batch: 2.0756 sec
0.1064 0.0661 0.0535 0.0450 0.0401 0.0371 0.0353 0.0338 0.0326 0.0318 0.0313 0.0308 0.0304 0.0301 0.0299 0.0298 

[TRAIN] Epoch[2](18/375); Loss: 0.065151; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1224 0.0937 0.0809 0.0715 0.0660 0.0625 0.0598 0.0578 0.0562 0.0549 0.0541 0.0533 0.0528 0.0524 0.0522 0.0520 

[TRAIN] Epoch[2](19/375); Loss: 0.047435; Backpropagation: 0.2883 sec; Batch: 2.0803 sec
0.1154 0.0784 0.0632 0.0511 0.0465 0.0429 0.0404 0.0386 0.0374 0.0365 0.0358 0.0353 0.0348 0.0345 0.0342 0.0339 

[TRAIN] Epoch[2](20/375); Loss: 0.044148; Backpropagation: 0.2882 sec; Batch: 2.0756 sec
0.1018 0.0699 0.0569 0.0489 0.0437 0.0404 0.0381 0.0366 0.0356 0.0348 0.0340 0.0336 0.0333 0.0331 0.0328 0.0327 

[TRAIN] Epoch[2](21/375); Loss: 0.045065; Backpropagation: 0.2882 sec; Batch: 2.0860 sec
0.1043 0.0734 0.0555 0.0477 0.0442 0.0414 0.0393 0.0378 0.0365 0.0357 0.0351 0.0345 0.0341 0.0339 0.0337 0.0336 

[TRAIN] Epoch[2](22/375); Loss: 0.056558; Backpropagation: 0.2884 sec; Batch: 2.0837 sec
0.1295 0.0872 0.0706 0.0615 0.0568 0.0529 0.0501 0.0480 0.0464 0.0452 0.0441 0.0433 0.0429 0.0424 0.0421 0.0418 

[TRAIN] Epoch[2](23/375); Loss: 0.057068; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.1270 0.0895 0.0694 0.0601 0.0557 0.0526 0.0503 0.0486 0.0473 0.0463 0.0454 0.0448 0.0444 0.0441 0.0439 0.0437 

[TRAIN] Epoch[2](24/375); Loss: 0.052716; Backpropagation: 0.2882 sec; Batch: 2.0752 sec
0.1034 0.0692 0.0619 0.0561 0.0529 0.0507 0.0489 0.0474 0.0462 0.0452 0.0444 0.0439 0.0436 0.0433 0.0432 0.0431 

[TRAIN] Epoch[2](25/375); Loss: 0.022285; Backpropagation: 0.2882 sec; Batch: 2.0750 sec
0.0734 0.0371 0.0290 0.0239 0.0215 0.0192 0.0176 0.0167 0.0159 0.0153 0.0150 0.0147 0.0145 0.0144 0.0143 0.0142 

[TRAIN] Epoch[2](26/375); Loss: 0.039641; Backpropagation: 0.2885 sec; Batch: 2.0756 sec
0.0880 0.0600 0.0486 0.0422 0.0392 0.0369 0.0351 0.0339 0.0330 0.0322 0.0316 0.0312 0.0308 0.0306 0.0305 0.0304 

[TRAIN] Epoch[2](27/375); Loss: 0.051897; Backpropagation: 0.2884 sec; Batch: 2.0758 sec
0.0981 0.0744 0.0618 0.0561 0.0526 0.0496 0.0475 0.0460 0.0450 0.0440 0.0433 0.0429 0.0425 0.0423 0.0422 0.0421 

[TRAIN] Epoch[2](28/375); Loss: 0.039290; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.0952 0.0639 0.0485 0.0412 0.0377 0.0356 0.0339 0.0328 0.0318 0.0311 0.0304 0.0299 0.0296 0.0292 0.0290 0.0289 

[TRAIN] Epoch[2](29/375); Loss: 0.054491; Backpropagation: 0.2884 sec; Batch: 2.0756 sec
0.1018 0.0787 0.0645 0.0583 0.0546 0.0521 0.0501 0.0487 0.0476 0.0466 0.0459 0.0452 0.0448 0.0445 0.0443 0.0441 

[TRAIN] Epoch[2](30/375); Loss: 0.057466; Backpropagation: 0.2883 sec; Batch: 2.0758 sec
0.1166 0.0858 0.0702 0.0613 0.0578 0.0543 0.0520 0.0501 0.0488 0.0478 0.0470 0.0463 0.0458 0.0455 0.0452 0.0450 

[TRAIN] Epoch[2](31/375); Loss: 0.053545; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1056 0.0788 0.0633 0.0567 0.0530 0.0505 0.0487 0.0472 0.0460 0.0452 0.0445 0.0441 0.0437 0.0433 0.0431 0.0430 

[TRAIN] Epoch[2](32/375); Loss: 0.050685; Backpropagation: 0.2886 sec; Batch: 2.0754 sec
0.1282 0.0849 0.0653 0.0546 0.0487 0.0450 0.0427 0.0408 0.0396 0.0387 0.0380 0.0375 0.0371 0.0368 0.0366 0.0364 

[TRAIN] Epoch[2](33/375); Loss: 0.044041; Backpropagation: 0.2880 sec; Batch: 2.0754 sec
0.0976 0.0649 0.0533 0.0471 0.0441 0.0413 0.0393 0.0378 0.0368 0.0359 0.0352 0.0348 0.0344 0.0342 0.0340 0.0340 

[TRAIN] Epoch[2](34/375); Loss: 0.064850; Backpropagation: 0.2885 sec; Batch: 2.0758 sec
0.1342 0.0984 0.0818 0.0715 0.0655 0.0616 0.0589 0.0566 0.0547 0.0531 0.0519 0.0510 0.0502 0.0498 0.0494 0.0491 

[TRAIN] Epoch[2](35/375); Loss: 0.047119; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.1004 0.0665 0.0580 0.0510 0.0472 0.0445 0.0426 0.0409 0.0398 0.0391 0.0385 0.0378 0.0373 0.0370 0.0367 0.0365 

[TRAIN] Epoch[2](36/375); Loss: 0.027643; Backpropagation: 0.2888 sec; Batch: 2.0759 sec
0.0908 0.0487 0.0351 0.0279 0.0249 0.0230 0.0217 0.0207 0.0199 0.0193 0.0189 0.0186 0.0184 0.0182 0.0181 0.0180 

[TRAIN] Epoch[2](37/375); Loss: 0.061901; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1199 0.0876 0.0731 0.0672 0.0628 0.0594 0.0570 0.0550 0.0535 0.0524 0.0516 0.0509 0.0505 0.0501 0.0499 0.0496 

[TRAIN] Epoch[2](38/375); Loss: 0.040739; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.0970 0.0631 0.0495 0.0435 0.0397 0.0373 0.0356 0.0341 0.0331 0.0323 0.0318 0.0313 0.0311 0.0308 0.0307 0.0306 

[TRAIN] Epoch[2](39/375); Loss: 0.067099; Backpropagation: 0.2884 sec; Batch: 2.0757 sec
0.1218 0.0956 0.0814 0.0724 0.0684 0.0651 0.0624 0.0601 0.0584 0.0572 0.0564 0.0557 0.0552 0.0548 0.0545 0.0544 

[TRAIN] Epoch[2](40/375); Loss: 0.050400; Backpropagation: 0.2886 sec; Batch: 2.0756 sec
0.1164 0.0794 0.0637 0.0533 0.0486 0.0457 0.0434 0.0420 0.0410 0.0402 0.0396 0.0391 0.0388 0.0386 0.0384 0.0383 

[TRAIN] Epoch[2](41/375); Loss: 0.046689; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.1045 0.0778 0.0605 0.0522 0.0471 0.0437 0.0412 0.0391 0.0377 0.0366 0.0358 0.0351 0.0345 0.0341 0.0338 0.0336 

[TRAIN] Epoch[2](42/375); Loss: 0.040298; Backpropagation: 0.2883 sec; Batch: 2.0893 sec
0.1021 0.0666 0.0508 0.0438 0.0395 0.0363 0.0341 0.0327 0.0316 0.0307 0.0302 0.0297 0.0294 0.0292 0.0291 0.0290 

[TRAIN] Epoch[2](43/375); Loss: 0.033689; Backpropagation: 0.2882 sec; Batch: 2.0768 sec
0.0920 0.0569 0.0437 0.0374 0.0331 0.0302 0.0282 0.0268 0.0258 0.0248 0.0242 0.0237 0.0234 0.0231 0.0229 0.0228 

[TRAIN] Epoch[2](44/375); Loss: 0.032358; Backpropagation: 0.2883 sec; Batch: 2.0790 sec
0.0887 0.0566 0.0426 0.0361 0.0316 0.0288 0.0269 0.0255 0.0244 0.0236 0.0230 0.0225 0.0222 0.0219 0.0217 0.0216 

[TRAIN] Epoch[2](45/375); Loss: 0.056646; Backpropagation: 0.2884 sec; Batch: 2.0751 sec
0.1184 0.0847 0.0698 0.0614 0.0570 0.0536 0.0510 0.0493 0.0480 0.0468 0.0458 0.0451 0.0445 0.0440 0.0437 0.0434 

[TRAIN] Epoch[2](46/375); Loss: 0.060053; Backpropagation: 0.2884 sec; Batch: 2.0869 sec
0.1316 0.0917 0.0728 0.0648 0.0596 0.0558 0.0536 0.0516 0.0501 0.0489 0.0481 0.0474 0.0468 0.0464 0.0460 0.0458 

[TRAIN] Epoch[2](47/375); Loss: 0.045020; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.0934 0.0646 0.0527 0.0480 0.0448 0.0425 0.0408 0.0396 0.0385 0.0377 0.0371 0.0367 0.0363 0.0360 0.0358 0.0357 

[TRAIN] Epoch[2](48/375); Loss: 0.060044; Backpropagation: 0.2884 sec; Batch: 2.0804 sec
0.1187 0.0907 0.0757 0.0669 0.0615 0.0575 0.0547 0.0525 0.0508 0.0495 0.0484 0.0477 0.0472 0.0467 0.0463 0.0460 

[TRAIN] Epoch[2](49/375); Loss: 0.057791; Backpropagation: 0.2879 sec; Batch: 2.0749 sec
0.1249 0.0935 0.0749 0.0617 0.0562 0.0529 0.0506 0.0487 0.0474 0.0464 0.0456 0.0451 0.0446 0.0443 0.0441 0.0439 

[TRAIN] Epoch[2](50/375); Loss: 0.054586; Backpropagation: 0.2887 sec; Batch: 2.0761 sec
0.1184 0.0838 0.0689 0.0601 0.0549 0.0513 0.0487 0.0468 0.0453 0.0440 0.0431 0.0425 0.0420 0.0415 0.0412 0.0410 

[TRAIN] Epoch[2](51/375); Loss: 0.052839; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.1226 0.0866 0.0679 0.0591 0.0528 0.0483 0.0456 0.0437 0.0422 0.0413 0.0403 0.0396 0.0392 0.0389 0.0387 0.0385 

[TRAIN] Epoch[2](52/375); Loss: 0.044785; Backpropagation: 0.2887 sec; Batch: 2.0759 sec
0.1203 0.0824 0.0586 0.0505 0.0439 0.0396 0.0368 0.0350 0.0336 0.0324 0.0317 0.0311 0.0307 0.0302 0.0300 0.0297 

[TRAIN] Epoch[2](53/375); Loss: 0.054520; Backpropagation: 0.2884 sec; Batch: 2.0755 sec
0.1144 0.0864 0.0695 0.0588 0.0539 0.0505 0.0483 0.0466 0.0454 0.0444 0.0436 0.0430 0.0424 0.0420 0.0418 0.0415 

[TRAIN] Epoch[2](54/375); Loss: 0.058083; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1221 0.0917 0.0705 0.0627 0.0573 0.0537 0.0513 0.0499 0.0485 0.0476 0.0468 0.0462 0.0457 0.0453 0.0451 0.0449 

[TRAIN] Epoch[2](55/375); Loss: 0.045401; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.0921 0.0695 0.0584 0.0506 0.0453 0.0423 0.0406 0.0391 0.0381 0.0372 0.0365 0.0360 0.0356 0.0352 0.0350 0.0348 

[TRAIN] Epoch[2](56/375); Loss: 0.049021; Backpropagation: 0.2879 sec; Batch: 2.0745 sec
0.1037 0.0745 0.0615 0.0538 0.0496 0.0463 0.0440 0.0422 0.0409 0.0399 0.0391 0.0385 0.0381 0.0377 0.0375 0.0372 

[TRAIN] Epoch[2](57/375); Loss: 0.040079; Backpropagation: 0.2883 sec; Batch: 2.0839 sec
0.0975 0.0677 0.0545 0.0467 0.0409 0.0368 0.0344 0.0325 0.0312 0.0302 0.0294 0.0287 0.0282 0.0278 0.0275 0.0274 

[TRAIN] Epoch[2](58/375); Loss: 0.053251; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1110 0.0806 0.0644 0.0570 0.0524 0.0496 0.0475 0.0460 0.0448 0.0440 0.0433 0.0429 0.0425 0.0422 0.0420 0.0418 

[TRAIN] Epoch[2](59/375); Loss: 0.049441; Backpropagation: 0.2886 sec; Batch: 2.0757 sec
0.1123 0.0792 0.0633 0.0543 0.0497 0.0460 0.0434 0.0416 0.0402 0.0392 0.0381 0.0374 0.0370 0.0367 0.0365 0.0362 

[TRAIN] Epoch[2](60/375); Loss: 0.044374; Backpropagation: 0.2884 sec; Batch: 2.0752 sec
0.0980 0.0730 0.0563 0.0483 0.0443 0.0412 0.0391 0.0376 0.0363 0.0354 0.0346 0.0340 0.0335 0.0331 0.0328 0.0326 

[TRAIN] Epoch[2](61/375); Loss: 0.053237; Backpropagation: 0.2882 sec; Batch: 2.0755 sec
0.1100 0.0800 0.0661 0.0585 0.0536 0.0503 0.0480 0.0461 0.0448 0.0438 0.0429 0.0422 0.0418 0.0414 0.0412 0.0410 

[TRAIN] Epoch[2](62/375); Loss: 0.040594; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.1169 0.0840 0.0579 0.0442 0.0375 0.0338 0.0316 0.0300 0.0288 0.0278 0.0271 0.0266 0.0262 0.0259 0.0257 0.0256 

[TRAIN] Epoch[2](63/375); Loss: 0.030954; Backpropagation: 0.2883 sec; Batch: 2.0754 sec
0.0710 0.0496 0.0402 0.0340 0.0311 0.0283 0.0268 0.0257 0.0250 0.0245 0.0239 0.0235 0.0232 0.0230 0.0228 0.0227 

[TRAIN] Epoch[2](64/375); Loss: 0.049913; Backpropagation: 0.2888 sec; Batch: 2.0759 sec
0.1158 0.0795 0.0637 0.0552 0.0493 0.0456 0.0434 0.0416 0.0403 0.0394 0.0385 0.0379 0.0375 0.0371 0.0369 0.0368 

[TRAIN] Epoch[2](65/375); Loss: 0.029335; Backpropagation: 0.2883 sec; Batch: 2.0752 sec
0.0786 0.0515 0.0369 0.0310 0.0273 0.0256 0.0242 0.0232 0.0225 0.0220 0.0216 0.0213 0.0211 0.0209 0.0209 0.0208 

[TRAIN] Epoch[2](66/375); Loss: 0.037127; Backpropagation: 0.2879 sec; Batch: 2.0751 sec
0.0858 0.0602 0.0457 0.0394 0.0354 0.0333 0.0319 0.0308 0.0301 0.0296 0.0291 0.0288 0.0286 0.0285 0.0284 0.0283 

[TRAIN] Epoch[2](67/375); Loss: 0.028690; Backpropagation: 0.2881 sec; Batch: 2.0748 sec
0.0929 0.0522 0.0348 0.0281 0.0251 0.0233 0.0221 0.0213 0.0208 0.0204 0.0201 0.0198 0.0197 0.0196 0.0195 0.0194 

[TRAIN] Epoch[2](68/375); Loss: 0.057771; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1242 0.0743 0.0658 0.0608 0.0573 0.0544 0.0525 0.0510 0.0499 0.0491 0.0484 0.0479 0.0474 0.0472 0.0470 0.0469 

[TRAIN] Epoch[2](69/375); Loss: 0.038856; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.0794 0.0592 0.0486 0.0426 0.0383 0.0360 0.0346 0.0334 0.0326 0.0319 0.0314 0.0311 0.0308 0.0307 0.0306 0.0305 

[TRAIN] Epoch[2](70/375); Loss: 0.036498; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.0885 0.0602 0.0458 0.0381 0.0351 0.0326 0.0310 0.0299 0.0290 0.0284 0.0280 0.0277 0.0276 0.0274 0.0273 0.0272 

[TRAIN] Epoch[2](71/375); Loss: 0.061175; Backpropagation: 0.2885 sec; Batch: 2.0754 sec
0.1341 0.0924 0.0745 0.0651 0.0604 0.0573 0.0548 0.0529 0.0512 0.0498 0.0489 0.0483 0.0478 0.0474 0.0471 0.0469 

[TRAIN] Epoch[2](72/375); Loss: 0.048695; Backpropagation: 0.2883 sec; Batch: 2.0806 sec
0.1111 0.0768 0.0611 0.0530 0.0485 0.0452 0.0430 0.0412 0.0398 0.0386 0.0379 0.0373 0.0368 0.0365 0.0363 0.0361 

[TRAIN] Epoch[2](73/375); Loss: 0.041634; Backpropagation: 0.2883 sec; Batch: 2.0748 sec
0.0774 0.0609 0.0515 0.0462 0.0426 0.0402 0.0385 0.0371 0.0359 0.0350 0.0343 0.0338 0.0334 0.0332 0.0330 0.0329 

[TRAIN] Epoch[2](74/375); Loss: 0.048130; Backpropagation: 0.2881 sec; Batch: 2.0750 sec
0.1051 0.0723 0.0585 0.0511 0.0474 0.0447 0.0426 0.0412 0.0403 0.0394 0.0387 0.0382 0.0379 0.0377 0.0375 0.0375 

[TRAIN] Epoch[2](75/375); Loss: 0.055795; Backpropagation: 0.2882 sec; Batch: 2.0753 sec
0.1186 0.0816 0.0669 0.0592 0.0552 0.0524 0.0503 0.0484 0.0471 0.0461 0.0454 0.0449 0.0445 0.0442 0.0440 0.0439 

[TRAIN] Epoch[2](76/375); Loss: 0.052019; Backpropagation: 0.2882 sec; Batch: 2.0758 sec
0.1156 0.0802 0.0667 0.0569 0.0525 0.0490 0.0463 0.0443 0.0426 0.0415 0.0406 0.0399 0.0394 0.0391 0.0389 0.0388 

[TRAIN] Epoch[2](77/375); Loss: 0.048864; Backpropagation: 0.2883 sec; Batch: 2.0750 sec
0.1021 0.0734 0.0612 0.0538 0.0494 0.0463 0.0441 0.0424 0.0410 0.0399 0.0391 0.0385 0.0380 0.0377 0.0376 0.0374 

[TRAIN] Epoch[2](78/375); Loss: 0.066386; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.1126 0.0909 0.0777 0.0716 0.0670 0.0643 0.0621 0.0605 0.0592 0.0581 0.0575 0.0569 0.0564 0.0560 0.0558 0.0556 

[TRAIN] Epoch[2](79/375); Loss: 0.057418; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1165 0.0837 0.0708 0.0629 0.0581 0.0548 0.0521 0.0503 0.0489 0.0478 0.0468 0.0461 0.0455 0.0451 0.0448 0.0445 

[TRAIN] Epoch[2](80/375); Loss: 0.064267; Backpropagation: 0.2883 sec; Batch: 2.0754 sec
0.1168 0.0918 0.0786 0.0721 0.0660 0.0624 0.0595 0.0574 0.0556 0.0544 0.0535 0.0528 0.0524 0.0519 0.0517 0.0515 

[TRAIN] Epoch[2](81/375); Loss: 0.038812; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0836 0.0570 0.0468 0.0402 0.0379 0.0360 0.0346 0.0336 0.0328 0.0321 0.0317 0.0313 0.0311 0.0309 0.0307 0.0307 

[TRAIN] Epoch[2](82/375); Loss: 0.036637; Backpropagation: 0.2885 sec; Batch: 2.0755 sec
0.0816 0.0527 0.0450 0.0388 0.0360 0.0339 0.0326 0.0315 0.0308 0.0301 0.0296 0.0292 0.0289 0.0287 0.0285 0.0284 

[TRAIN] Epoch[2](83/375); Loss: 0.044858; Backpropagation: 0.2885 sec; Batch: 2.0751 sec
0.0936 0.0720 0.0559 0.0486 0.0438 0.0415 0.0397 0.0385 0.0374 0.0365 0.0358 0.0354 0.0351 0.0348 0.0346 0.0345 

[TRAIN] Epoch[2](84/375); Loss: 0.040909; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0978 0.0636 0.0493 0.0437 0.0399 0.0376 0.0358 0.0344 0.0333 0.0326 0.0319 0.0315 0.0312 0.0309 0.0307 0.0305 

[TRAIN] Epoch[2](85/375); Loss: 0.054272; Backpropagation: 0.2882 sec; Batch: 2.0747 sec
0.1056 0.0815 0.0667 0.0595 0.0544 0.0517 0.0495 0.0477 0.0463 0.0453 0.0445 0.0439 0.0434 0.0430 0.0426 0.0423 

[TRAIN] Epoch[2](86/375); Loss: 0.041714; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0853 0.0580 0.0489 0.0433 0.0406 0.0387 0.0375 0.0365 0.0359 0.0354 0.0351 0.0348 0.0346 0.0344 0.0343 0.0342 

[TRAIN] Epoch[2](87/375); Loss: 0.051978; Backpropagation: 0.2882 sec; Batch: 2.0741 sec
0.1036 0.0813 0.0644 0.0566 0.0522 0.0490 0.0470 0.0453 0.0440 0.0429 0.0420 0.0415 0.0410 0.0406 0.0403 0.0400 

[TRAIN] Epoch[2](88/375); Loss: 0.042070; Backpropagation: 0.2883 sec; Batch: 2.0792 sec
0.0791 0.0564 0.0495 0.0451 0.0423 0.0404 0.0391 0.0380 0.0372 0.0365 0.0358 0.0353 0.0349 0.0347 0.0345 0.0344 

[TRAIN] Epoch[2](89/375); Loss: 0.048047; Backpropagation: 0.2882 sec; Batch: 2.0757 sec
0.1077 0.0724 0.0599 0.0537 0.0484 0.0446 0.0426 0.0408 0.0395 0.0384 0.0378 0.0371 0.0367 0.0365 0.0363 0.0362 

[TRAIN] Epoch[2](90/375); Loss: 0.054753; Backpropagation: 0.2885 sec; Batch: 2.0757 sec
0.1203 0.0871 0.0700 0.0616 0.0553 0.0512 0.0483 0.0462 0.0445 0.0433 0.0425 0.0419 0.0414 0.0411 0.0408 0.0406 

[TRAIN] Epoch[2](91/375); Loss: 0.050074; Backpropagation: 0.2881 sec; Batch: 2.0737 sec
0.1064 0.0781 0.0642 0.0555 0.0502 0.0468 0.0446 0.0429 0.0414 0.0403 0.0395 0.0390 0.0385 0.0382 0.0379 0.0377 

[TRAIN] Epoch[2](92/375); Loss: 0.056857; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1106 0.0824 0.0692 0.0618 0.0571 0.0537 0.0514 0.0499 0.0489 0.0479 0.0472 0.0466 0.0461 0.0458 0.0456 0.0454 

[TRAIN] Epoch[2](93/375); Loss: 0.045553; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0994 0.0705 0.0581 0.0501 0.0447 0.0417 0.0398 0.0384 0.0374 0.0366 0.0361 0.0358 0.0354 0.0351 0.0349 0.0348 

[TRAIN] Epoch[2](94/375); Loss: 0.053108; Backpropagation: 0.2885 sec; Batch: 2.0739 sec
0.1048 0.0785 0.0663 0.0585 0.0535 0.0507 0.0484 0.0467 0.0453 0.0442 0.0433 0.0427 0.0423 0.0418 0.0415 0.0412 

[TRAIN] Epoch[2](95/375); Loss: 0.062644; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1138 0.0825 0.0744 0.0680 0.0642 0.0613 0.0588 0.0569 0.0555 0.0543 0.0533 0.0526 0.0521 0.0518 0.0516 0.0513 

[TRAIN] Epoch[2](96/375); Loss: 0.057789; Backpropagation: 0.2882 sec; Batch: 2.0738 sec
0.1118 0.0831 0.0705 0.0637 0.0588 0.0555 0.0530 0.0511 0.0498 0.0487 0.0477 0.0470 0.0465 0.0461 0.0458 0.0456 

[TRAIN] Epoch[2](97/375); Loss: 0.054958; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.1182 0.0894 0.0744 0.0640 0.0568 0.0515 0.0480 0.0459 0.0442 0.0430 0.0420 0.0412 0.0407 0.0403 0.0400 0.0398 

[TRAIN] Epoch[2](98/375); Loss: 0.037003; Backpropagation: 0.2880 sec; Batch: 2.0741 sec
0.0917 0.0634 0.0469 0.0407 0.0357 0.0328 0.0311 0.0300 0.0291 0.0284 0.0278 0.0274 0.0271 0.0269 0.0267 0.0266 

[TRAIN] Epoch[2](99/375); Loss: 0.049312; Backpropagation: 0.2886 sec; Batch: 2.0738 sec
0.1059 0.0764 0.0665 0.0568 0.0503 0.0461 0.0435 0.0417 0.0403 0.0392 0.0383 0.0377 0.0371 0.0367 0.0364 0.0362 

[TRAIN] Epoch[2](100/375); Loss: 0.052870; Backpropagation: 0.2877 sec; Batch: 2.0740 sec
0.1074 0.0788 0.0674 0.0590 0.0537 0.0499 0.0477 0.0461 0.0446 0.0435 0.0426 0.0419 0.0413 0.0409 0.0407 0.0404 

[TRAIN] Epoch[2](101/375); Loss: 0.049855; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.0932 0.0772 0.0647 0.0570 0.0517 0.0475 0.0450 0.0435 0.0421 0.0411 0.0404 0.0397 0.0392 0.0388 0.0385 0.0382 

[TRAIN] Epoch[2](102/375); Loss: 0.033182; Backpropagation: 0.2881 sec; Batch: 2.0743 sec
0.0900 0.0546 0.0423 0.0357 0.0316 0.0292 0.0276 0.0265 0.0256 0.0249 0.0245 0.0241 0.0238 0.0236 0.0235 0.0234 

[TRAIN] Epoch[2](103/375); Loss: 0.047224; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0886 0.0673 0.0595 0.0526 0.0481 0.0457 0.0438 0.0422 0.0408 0.0399 0.0390 0.0383 0.0379 0.0376 0.0373 0.0370 

[TRAIN] Epoch[2](104/375); Loss: 0.047070; Backpropagation: 0.2882 sec; Batch: 2.0742 sec
0.0967 0.0773 0.0642 0.0559 0.0498 0.0452 0.0418 0.0397 0.0381 0.0370 0.0360 0.0352 0.0346 0.0342 0.0339 0.0336 

[TRAIN] Epoch[2](105/375); Loss: 0.055424; Backpropagation: 0.2886 sec; Batch: 2.0838 sec
0.1143 0.0804 0.0665 0.0582 0.0538 0.0514 0.0498 0.0484 0.0474 0.0466 0.0459 0.0454 0.0450 0.0447 0.0446 0.0444 

[TRAIN] Epoch[2](106/375); Loss: 0.034005; Backpropagation: 0.2885 sec; Batch: 2.0752 sec
0.0742 0.0532 0.0418 0.0361 0.0328 0.0312 0.0301 0.0293 0.0284 0.0277 0.0272 0.0269 0.0266 0.0264 0.0262 0.0261 

[TRAIN] Epoch[2](107/375); Loss: 0.057203; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1218 0.0862 0.0720 0.0612 0.0556 0.0527 0.0505 0.0490 0.0478 0.0470 0.0462 0.0457 0.0453 0.0449 0.0447 0.0446 

[TRAIN] Epoch[2](108/375); Loss: 0.041043; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0942 0.0660 0.0542 0.0451 0.0403 0.0371 0.0354 0.0342 0.0331 0.0323 0.0317 0.0312 0.0309 0.0306 0.0303 0.0302 

[TRAIN] Epoch[2](109/375); Loss: 0.036026; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.0804 0.0643 0.0509 0.0410 0.0352 0.0320 0.0303 0.0290 0.0280 0.0274 0.0269 0.0265 0.0262 0.0261 0.0260 0.0260 

[TRAIN] Epoch[2](110/375); Loss: 0.050783; Backpropagation: 0.2883 sec; Batch: 2.0757 sec
0.1002 0.0790 0.0672 0.0581 0.0521 0.0481 0.0458 0.0440 0.0426 0.0415 0.0404 0.0396 0.0390 0.0386 0.0383 0.0381 

[TRAIN] Epoch[2](111/375); Loss: 0.044194; Backpropagation: 0.2883 sec; Batch: 2.0740 sec
0.1011 0.0756 0.0596 0.0492 0.0438 0.0404 0.0380 0.0366 0.0353 0.0343 0.0334 0.0327 0.0322 0.0318 0.0316 0.0313 

[TRAIN] Epoch[2](112/375); Loss: 0.050596; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.0994 0.0789 0.0651 0.0564 0.0504 0.0474 0.0451 0.0438 0.0425 0.0416 0.0408 0.0403 0.0398 0.0395 0.0392 0.0391 

[TRAIN] Epoch[2](113/375); Loss: 0.038610; Backpropagation: 0.2885 sec; Batch: 2.0745 sec
0.0770 0.0603 0.0502 0.0423 0.0378 0.0356 0.0340 0.0330 0.0323 0.0317 0.0312 0.0309 0.0306 0.0304 0.0303 0.0302 

[TRAIN] Epoch[2](114/375); Loss: 0.032922; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.0803 0.0517 0.0425 0.0355 0.0319 0.0298 0.0281 0.0271 0.0263 0.0257 0.0253 0.0249 0.0247 0.0245 0.0243 0.0242 

[TRAIN] Epoch[2](115/375); Loss: 0.058614; Backpropagation: 0.2885 sec; Batch: 2.0734 sec
0.1128 0.0877 0.0749 0.0659 0.0605 0.0566 0.0536 0.0514 0.0498 0.0485 0.0475 0.0467 0.0461 0.0456 0.0453 0.0450 

[TRAIN] Epoch[2](116/375); Loss: 0.040536; Backpropagation: 0.2885 sec; Batch: 2.0749 sec
0.0994 0.0624 0.0487 0.0427 0.0387 0.0366 0.0349 0.0337 0.0327 0.0321 0.0317 0.0314 0.0311 0.0309 0.0309 0.0308 

[TRAIN] Epoch[2](117/375); Loss: 0.060136; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1387 0.0928 0.0766 0.0650 0.0586 0.0553 0.0524 0.0504 0.0491 0.0480 0.0472 0.0465 0.0459 0.0455 0.0452 0.0450 

[TRAIN] Epoch[2](118/375); Loss: 0.041984; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1103 0.0762 0.0562 0.0441 0.0390 0.0364 0.0343 0.0330 0.0320 0.0312 0.0306 0.0302 0.0299 0.0296 0.0295 0.0294 

[TRAIN] Epoch[2](119/375); Loss: 0.035791; Backpropagation: 0.2885 sec; Batch: 2.0741 sec
0.0686 0.0542 0.0442 0.0385 0.0359 0.0340 0.0326 0.0314 0.0306 0.0299 0.0294 0.0290 0.0288 0.0286 0.0285 0.0284 

[TRAIN] Epoch[2](120/375); Loss: 0.055690; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.1259 0.0894 0.0711 0.0602 0.0549 0.0514 0.0489 0.0471 0.0456 0.0444 0.0434 0.0426 0.0420 0.0416 0.0414 0.0412 

[TRAIN] Epoch[2](121/375); Loss: 0.028622; Backpropagation: 0.2887 sec; Batch: 2.0752 sec
0.0676 0.0379 0.0327 0.0306 0.0282 0.0264 0.0254 0.0246 0.0240 0.0235 0.0232 0.0229 0.0228 0.0228 0.0227 0.0227 

[TRAIN] Epoch[2](122/375); Loss: 0.071664; Backpropagation: 0.2881 sec; Batch: 2.0795 sec
0.1270 0.1033 0.0891 0.0792 0.0732 0.0690 0.0661 0.0641 0.0623 0.0610 0.0601 0.0594 0.0588 0.0583 0.0579 0.0577 

[TRAIN] Epoch[2](123/375); Loss: 0.071149; Backpropagation: 0.2886 sec; Batch: 2.0750 sec
0.1427 0.1131 0.0957 0.0821 0.0734 0.0671 0.0628 0.0600 0.0581 0.0568 0.0557 0.0551 0.0546 0.0541 0.0538 0.0535 

[TRAIN] Epoch[2](124/375); Loss: 0.049748; Backpropagation: 0.2882 sec; Batch: 2.0744 sec
0.1097 0.0763 0.0631 0.0539 0.0493 0.0461 0.0439 0.0423 0.0412 0.0402 0.0395 0.0388 0.0384 0.0380 0.0377 0.0376 

[TRAIN] Epoch[2](125/375); Loss: 0.058091; Backpropagation: 0.2882 sec; Batch: 2.0748 sec
0.1125 0.0850 0.0715 0.0633 0.0585 0.0556 0.0532 0.0513 0.0499 0.0488 0.0479 0.0472 0.0467 0.0463 0.0461 0.0459 

[TRAIN] Epoch[2](126/375); Loss: 0.052257; Backpropagation: 0.2883 sec; Batch: 2.0749 sec
0.1064 0.0775 0.0648 0.0575 0.0528 0.0496 0.0472 0.0455 0.0442 0.0431 0.0424 0.0418 0.0413 0.0409 0.0407 0.0405 

[TRAIN] Epoch[2](127/375); Loss: 0.034752; Backpropagation: 0.2881 sec; Batch: 2.0739 sec
0.1045 0.0650 0.0432 0.0353 0.0315 0.0292 0.0274 0.0263 0.0256 0.0251 0.0245 0.0241 0.0238 0.0237 0.0235 0.0234 

[TRAIN] Epoch[2](128/375); Loss: 0.043368; Backpropagation: 0.2882 sec; Batch: 2.0736 sec
0.1006 0.0663 0.0537 0.0477 0.0432 0.0402 0.0383 0.0368 0.0355 0.0345 0.0339 0.0332 0.0328 0.0326 0.0324 0.0323 

[TRAIN] Epoch[2](129/375); Loss: 0.049789; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0974 0.0740 0.0616 0.0555 0.0509 0.0477 0.0455 0.0436 0.0422 0.0412 0.0404 0.0399 0.0395 0.0393 0.0391 0.0389 

[TRAIN] Epoch[2](130/375); Loss: 0.044838; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0948 0.0715 0.0569 0.0488 0.0443 0.0417 0.0398 0.0382 0.0370 0.0361 0.0355 0.0351 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[2](131/375); Loss: 0.042449; Backpropagation: 0.2885 sec; Batch: 2.0743 sec
0.1066 0.0667 0.0545 0.0460 0.0409 0.0383 0.0365 0.0350 0.0338 0.0330 0.0323 0.0317 0.0313 0.0310 0.0308 0.0307 

[TRAIN] Epoch[2](132/375); Loss: 0.055330; Backpropagation: 0.2882 sec; Batch: 2.0745 sec
0.1128 0.0814 0.0693 0.0617 0.0566 0.0528 0.0499 0.0481 0.0465 0.0454 0.0445 0.0439 0.0435 0.0432 0.0429 0.0427 

[TRAIN] Epoch[2](133/375); Loss: 0.040093; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0893 0.0695 0.0527 0.0432 0.0386 0.0361 0.0342 0.0331 0.0322 0.0315 0.0310 0.0305 0.0302 0.0300 0.0298 0.0297 

[TRAIN] Epoch[2](134/375); Loss: 0.046836; Backpropagation: 0.2881 sec; Batch: 2.0743 sec
0.1051 0.0782 0.0616 0.0513 0.0459 0.0429 0.0407 0.0390 0.0377 0.0367 0.0360 0.0355 0.0351 0.0348 0.0345 0.0344 

[TRAIN] Epoch[2](135/375); Loss: 0.056281; Backpropagation: 0.2883 sec; Batch: 2.0743 sec
0.1075 0.0806 0.0695 0.0622 0.0578 0.0547 0.0523 0.0501 0.0484 0.0473 0.0463 0.0456 0.0450 0.0446 0.0443 0.0441 

[TRAIN] Epoch[2](136/375); Loss: 0.075270; Backpropagation: 0.2885 sec; Batch: 2.0747 sec
0.1333 0.1050 0.0903 0.0811 0.0762 0.0724 0.0698 0.0678 0.0662 0.0650 0.0642 0.0635 0.0629 0.0625 0.0622 0.0620 

[TRAIN] Epoch[2](137/375); Loss: 0.043133; Backpropagation: 0.2884 sec; Batch: 2.0749 sec
0.1030 0.0681 0.0547 0.0466 0.0426 0.0396 0.0372 0.0356 0.0344 0.0336 0.0331 0.0327 0.0324 0.0323 0.0321 0.0320 

[TRAIN] Epoch[2](138/375); Loss: 0.050008; Backpropagation: 0.2880 sec; Batch: 2.0748 sec
0.0973 0.0728 0.0615 0.0547 0.0506 0.0476 0.0457 0.0440 0.0427 0.0417 0.0411 0.0406 0.0403 0.0400 0.0398 0.0397 

[TRAIN] Epoch[2](139/375); Loss: 0.051218; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1053 0.0762 0.0631 0.0556 0.0510 0.0484 0.0464 0.0446 0.0432 0.0423 0.0415 0.0410 0.0406 0.0403 0.0401 0.0399 

[TRAIN] Epoch[2](140/375); Loss: 0.054115; Backpropagation: 0.2884 sec; Batch: 2.0786 sec
0.1102 0.0790 0.0675 0.0609 0.0563 0.0524 0.0495 0.0472 0.0456 0.0442 0.0434 0.0427 0.0422 0.0419 0.0415 0.0413 

[TRAIN] Epoch[2](141/375); Loss: 0.053947; Backpropagation: 0.2883 sec; Batch: 2.0756 sec
0.1039 0.0791 0.0653 0.0579 0.0546 0.0516 0.0493 0.0476 0.0465 0.0455 0.0447 0.0441 0.0437 0.0433 0.0430 0.0428 

[TRAIN] Epoch[2](142/375); Loss: 0.046686; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.1150 0.0807 0.0603 0.0502 0.0452 0.0421 0.0399 0.0383 0.0370 0.0359 0.0350 0.0344 0.0338 0.0334 0.0330 0.0328 

[TRAIN] Epoch[2](143/375); Loss: 0.031140; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.0795 0.0560 0.0416 0.0333 0.0293 0.0274 0.0257 0.0247 0.0240 0.0234 0.0229 0.0225 0.0222 0.0220 0.0219 0.0218 

[TRAIN] Epoch[2](144/375); Loss: 0.038979; Backpropagation: 0.2881 sec; Batch: 2.0734 sec
0.0888 0.0616 0.0483 0.0421 0.0384 0.0359 0.0343 0.0330 0.0319 0.0311 0.0306 0.0301 0.0298 0.0295 0.0293 0.0291 

[TRAIN] Epoch[2](145/375); Loss: 0.056392; Backpropagation: 0.2883 sec; Batch: 2.0742 sec
0.1096 0.0838 0.0689 0.0614 0.0567 0.0538 0.0515 0.0497 0.0483 0.0472 0.0464 0.0456 0.0452 0.0449 0.0447 0.0445 

[TRAIN] Epoch[2](146/375); Loss: 0.062010; Backpropagation: 0.2884 sec; Batch: 2.0743 sec
0.1251 0.0961 0.0780 0.0677 0.0627 0.0590 0.0559 0.0539 0.0522 0.0508 0.0499 0.0491 0.0485 0.0480 0.0477 0.0474 

[TRAIN] Epoch[2](147/375); Loss: 0.046294; Backpropagation: 0.2887 sec; Batch: 2.0744 sec
0.0953 0.0667 0.0555 0.0492 0.0459 0.0434 0.0419 0.0405 0.0394 0.0387 0.0381 0.0377 0.0374 0.0372 0.0370 0.0368 

[TRAIN] Epoch[2](148/375); Loss: 0.035898; Backpropagation: 0.2885 sec; Batch: 2.0742 sec
0.0860 0.0591 0.0454 0.0390 0.0355 0.0330 0.0312 0.0297 0.0286 0.0279 0.0273 0.0268 0.0265 0.0263 0.0261 0.0259 

[TRAIN] Epoch[2](149/375); Loss: 0.054323; Backpropagation: 0.2883 sec; Batch: 2.0732 sec
0.1065 0.0763 0.0632 0.0579 0.0541 0.0515 0.0495 0.0481 0.0470 0.0462 0.0456 0.0452 0.0449 0.0446 0.0444 0.0443 

[TRAIN] Epoch[2](150/375); Loss: 0.051614; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1050 0.0741 0.0623 0.0572 0.0530 0.0496 0.0473 0.0454 0.0439 0.0427 0.0420 0.0414 0.0409 0.0406 0.0403 0.0401 

[TRAIN] Epoch[2](151/375); Loss: 0.050133; Backpropagation: 0.2884 sec; Batch: 2.0738 sec
0.0907 0.0653 0.0589 0.0534 0.0506 0.0484 0.0467 0.0453 0.0443 0.0437 0.0431 0.0428 0.0425 0.0423 0.0421 0.0420 

[TRAIN] Epoch[2](152/375); Loss: 0.052252; Backpropagation: 0.2882 sec; Batch: 2.0739 sec
0.1074 0.0750 0.0622 0.0556 0.0519 0.0493 0.0473 0.0460 0.0447 0.0438 0.0431 0.0425 0.0421 0.0419 0.0417 0.0415 

[TRAIN] Epoch[2](153/375); Loss: 0.043758; Backpropagation: 0.2881 sec; Batch: 2.0750 sec
0.1001 0.0650 0.0517 0.0460 0.0424 0.0402 0.0385 0.0374 0.0365 0.0358 0.0352 0.0347 0.0344 0.0342 0.0340 0.0339 

[TRAIN] Epoch[2](154/375); Loss: 0.059711; Backpropagation: 0.2884 sec; Batch: 2.0750 sec
0.1120 0.0830 0.0712 0.0638 0.0603 0.0574 0.0555 0.0536 0.0522 0.0511 0.0502 0.0497 0.0492 0.0489 0.0488 0.0486 

[TRAIN] Epoch[2](155/375); Loss: 0.066692; Backpropagation: 0.2879 sec; Batch: 2.0746 sec
0.1291 0.0950 0.0809 0.0742 0.0695 0.0650 0.0614 0.0589 0.0571 0.0557 0.0546 0.0539 0.0534 0.0531 0.0528 0.0525 

[TRAIN] Epoch[2](156/375); Loss: 0.049554; Backpropagation: 0.2888 sec; Batch: 2.0746 sec
0.1006 0.0739 0.0616 0.0543 0.0506 0.0473 0.0449 0.0432 0.0419 0.0408 0.0400 0.0394 0.0390 0.0387 0.0385 0.0384 

[TRAIN] Epoch[2](157/375); Loss: 0.036223; Backpropagation: 0.2883 sec; Batch: 2.0739 sec
0.0759 0.0537 0.0463 0.0388 0.0358 0.0337 0.0321 0.0312 0.0304 0.0297 0.0293 0.0289 0.0287 0.0285 0.0284 0.0283 

[TRAIN] Epoch[2](158/375); Loss: 0.038489; Backpropagation: 0.2885 sec; Batch: 2.0834 sec
0.0839 0.0557 0.0475 0.0420 0.0387 0.0364 0.0344 0.0332 0.0322 0.0314 0.0308 0.0304 0.0301 0.0298 0.0296 0.0295 

[TRAIN] Epoch[2](159/375); Loss: 0.050131; Backpropagation: 0.2880 sec; Batch: 2.0739 sec
0.0967 0.0724 0.0592 0.0528 0.0494 0.0472 0.0455 0.0444 0.0434 0.0427 0.0422 0.0418 0.0414 0.0412 0.0410 0.0408 

[TRAIN] Epoch[2](160/375); Loss: 0.045468; Backpropagation: 0.2883 sec; Batch: 2.0746 sec
0.0978 0.0668 0.0541 0.0488 0.0448 0.0426 0.0408 0.0394 0.0383 0.0375 0.0368 0.0364 0.0361 0.0359 0.0357 0.0356 

[TRAIN] Epoch[2](161/375); Loss: 0.029157; Backpropagation: 0.2886 sec; Batch: 2.0747 sec
0.0796 0.0468 0.0364 0.0314 0.0278 0.0261 0.0248 0.0237 0.0228 0.0221 0.0216 0.0212 0.0209 0.0207 0.0204 0.0203 

[TRAIN] Epoch[2](162/375); Loss: 0.039791; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0801 0.0576 0.0481 0.0429 0.0401 0.0379 0.0362 0.0349 0.0340 0.0333 0.0327 0.0323 0.0319 0.0317 0.0315 0.0314 

[TRAIN] Epoch[2](163/375); Loss: 0.052915; Backpropagation: 0.2884 sec; Batch: 2.0737 sec
0.1012 0.0759 0.0638 0.0572 0.0536 0.0510 0.0486 0.0470 0.0457 0.0446 0.0439 0.0435 0.0431 0.0427 0.0425 0.0424 

[TRAIN] Epoch[2](164/375); Loss: 0.046642; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0896 0.0664 0.0573 0.0508 0.0474 0.0450 0.0429 0.0413 0.0401 0.0394 0.0385 0.0381 0.0377 0.0374 0.0372 0.0371 

[TRAIN] Epoch[2](165/375); Loss: 0.035526; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0851 0.0546 0.0437 0.0384 0.0349 0.0325 0.0312 0.0299 0.0289 0.0281 0.0275 0.0272 0.0269 0.0267 0.0265 0.0265 

[TRAIN] Epoch[2](166/375); Loss: 0.047128; Backpropagation: 0.2884 sec; Batch: 2.0745 sec
0.1113 0.0694 0.0560 0.0494 0.0460 0.0435 0.0416 0.0402 0.0392 0.0382 0.0376 0.0370 0.0365 0.0363 0.0361 0.0359 

[TRAIN] Epoch[2](167/375); Loss: 0.047573; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.0964 0.0701 0.0564 0.0506 0.0465 0.0441 0.0425 0.0414 0.0405 0.0399 0.0394 0.0391 0.0388 0.0386 0.0385 0.0383 

[TRAIN] Epoch[2](168/375); Loss: 0.043648; Backpropagation: 0.2883 sec; Batch: 2.0736 sec
0.0825 0.0617 0.0532 0.0478 0.0447 0.0422 0.0405 0.0391 0.0380 0.0370 0.0363 0.0357 0.0353 0.0350 0.0348 0.0346 

[TRAIN] Epoch[2](169/375); Loss: 0.045367; Backpropagation: 0.2885 sec; Batch: 2.0738 sec
0.0891 0.0652 0.0548 0.0488 0.0455 0.0430 0.0413 0.0400 0.0389 0.0382 0.0376 0.0372 0.0369 0.0366 0.0364 0.0363 

[TRAIN] Epoch[2](170/375); Loss: 0.044302; Backpropagation: 0.2884 sec; Batch: 2.0748 sec
0.0914 0.0642 0.0547 0.0476 0.0436 0.0413 0.0397 0.0383 0.0374 0.0368 0.0363 0.0359 0.0357 0.0355 0.0353 0.0352 

[TRAIN] Epoch[2](171/375); Loss: 0.052780; Backpropagation: 0.2881 sec; Batch: 2.0727 sec
0.1107 0.0786 0.0666 0.0598 0.0549 0.0508 0.0479 0.0456 0.0441 0.0429 0.0419 0.0411 0.0404 0.0400 0.0397 0.0394 

[TRAIN] Epoch[2](172/375); Loss: 0.038398; Backpropagation: 0.2881 sec; Batch: 2.0744 sec
0.0840 0.0561 0.0467 0.0418 0.0389 0.0365 0.0346 0.0331 0.0321 0.0313 0.0306 0.0302 0.0299 0.0297 0.0295 0.0293 

[TRAIN] Epoch[2](173/375); Loss: 0.043865; Backpropagation: 0.2889 sec; Batch: 2.0757 sec
0.1012 0.0675 0.0527 0.0457 0.0424 0.0398 0.0381 0.0369 0.0360 0.0354 0.0349 0.0346 0.0343 0.0342 0.0341 0.0340 

[TRAIN] Epoch[2](174/375); Loss: 0.027129; Backpropagation: 0.2883 sec; Batch: 2.0751 sec
0.0756 0.0482 0.0352 0.0298 0.0261 0.0241 0.0224 0.0212 0.0203 0.0197 0.0192 0.0189 0.0186 0.0184 0.0183 0.0182 

[TRAIN] Epoch[2](175/375); Loss: 0.044152; Backpropagation: 0.2882 sec; Batch: 2.0743 sec
0.0926 0.0662 0.0549 0.0491 0.0451 0.0423 0.0400 0.0381 0.0367 0.0359 0.0352 0.0347 0.0343 0.0340 0.0338 0.0336 

[TRAIN] Epoch[2](176/375); Loss: 0.055617; Backpropagation: 0.2887 sec; Batch: 2.0740 sec
0.1004 0.0730 0.0669 0.0601 0.0563 0.0539 0.0519 0.0503 0.0492 0.0482 0.0475 0.0470 0.0466 0.0464 0.0462 0.0460 

[TRAIN] Epoch[2](177/375); Loss: 0.031943; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.0909 0.0520 0.0404 0.0343 0.0307 0.0283 0.0265 0.0253 0.0243 0.0236 0.0230 0.0227 0.0225 0.0223 0.0222 0.0221 

[TRAIN] Epoch[2](178/375); Loss: 0.045915; Backpropagation: 0.2886 sec; Batch: 2.0744 sec
0.1004 0.0720 0.0587 0.0505 0.0459 0.0434 0.0410 0.0392 0.0378 0.0367 0.0359 0.0353 0.0348 0.0345 0.0343 0.0341 

[TRAIN] Epoch[2](179/375); Loss: 0.041590; Backpropagation: 0.2886 sec; Batch: 2.0745 sec
0.0928 0.0599 0.0483 0.0434 0.0408 0.0384 0.0369 0.0358 0.0350 0.0343 0.0339 0.0336 0.0333 0.0331 0.0330 0.0329 

[TRAIN] Epoch[2](180/375); Loss: 0.035549; Backpropagation: 0.2884 sec; Batch: 2.0736 sec
0.0899 0.0552 0.0439 0.0376 0.0347 0.0324 0.0307 0.0294 0.0285 0.0278 0.0272 0.0268 0.0265 0.0263 0.0261 0.0260 

[TRAIN] Epoch[2](181/375); Loss: 0.052995; Backpropagation: 0.2884 sec; Batch: 2.0744 sec
0.1073 0.0745 0.0646 0.0583 0.0541 0.0507 0.0484 0.0465 0.0450 0.0442 0.0435 0.0430 0.0426 0.0421 0.0418 0.0415 

[TRAIN] Epoch[2](182/375); Loss: 0.059800; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1110 0.0866 0.0694 0.0633 0.0594 0.0569 0.0550 0.0535 0.0523 0.0515 0.0507 0.0501 0.0497 0.0493 0.0491 0.0489 

[TRAIN] Epoch[2](183/375); Loss: 0.049514; Backpropagation: 0.2881 sec; Batch: 2.0742 sec
0.1111 0.0846 0.0654 0.0558 0.0496 0.0450 0.0424 0.0408 0.0396 0.0386 0.0377 0.0371 0.0366 0.0362 0.0360 0.0357 

[TRAIN] Epoch[2](184/375); Loss: 0.054936; Backpropagation: 0.2883 sec; Batch: 2.0734 sec
0.1425 0.1051 0.0827 0.0666 0.0544 0.0472 0.0439 0.0413 0.0397 0.0385 0.0376 0.0369 0.0363 0.0358 0.0355 0.0352 

[TRAIN] Epoch[2](185/375); Loss: 0.068757; Backpropagation: 0.2883 sec; Batch: 2.0738 sec
0.1364 0.1197 0.0994 0.0843 0.0733 0.0656 0.0606 0.0572 0.0547 0.0526 0.0514 0.0503 0.0495 0.0489 0.0484 0.0479 

[TRAIN] Epoch[2](186/375); Loss: 0.058858; Backpropagation: 0.2880 sec; Batch: 2.0738 sec
0.1289 0.1130 0.0883 0.0702 0.0588 0.0516 0.0480 0.0465 0.0450 0.0438 0.0428 0.0420 0.0414 0.0408 0.0404 0.0401 

[TRAIN] Epoch[2](187/375); Loss: 0.059661; Backpropagation: 0.2883 sec; Batch: 2.0793 sec
0.1271 0.1070 0.0920 0.0765 0.0637 0.0557 0.0503 0.0470 0.0454 0.0439 0.0429 0.0420 0.0412 0.0405 0.0398 0.0393 

[TRAIN] Epoch[2](188/375); Loss: 0.099075; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.1825 0.1659 0.1457 0.1269 0.1121 0.1000 0.0907 0.0835 0.0789 0.0764 0.0742 0.0723 0.0709 0.0697 0.0683 0.0672 

[TRAIN] Epoch[2](189/375); Loss: 0.058918; Backpropagation: 0.2885 sec; Batch: 2.0736 sec
0.1113 0.0960 0.0835 0.0680 0.0603 0.0569 0.0535 0.0510 0.0489 0.0474 0.0463 0.0453 0.0445 0.0438 0.0432 0.0428 

[TRAIN] Epoch[2](190/375); Loss: 0.050246; Backpropagation: 0.2884 sec; Batch: 2.0742 sec
0.1084 0.0886 0.0715 0.0598 0.0519 0.0471 0.0433 0.0409 0.0394 0.0383 0.0374 0.0367 0.0359 0.0354 0.0348 0.0344 

[TRAIN] Epoch[2](191/375); Loss: 0.092004; Backpropagation: 0.2885 sec; Batch: 2.0744 sec
0.1431 0.1291 0.1138 0.1018 0.0946 0.0900 0.0870 0.0851 0.0831 0.0814 0.0799 0.0786 0.0775 0.0765 0.0757 0.0749 

[TRAIN] Epoch[2](192/375); Loss: 0.045623; Backpropagation: 0.2883 sec; Batch: 2.0737 sec
0.0862 0.0762 0.0691 0.0574 0.0495 0.0445 0.0409 0.0383 0.0366 0.0352 0.0341 0.0334 0.0328 0.0324 0.0319 0.0316 

[TRAIN] Epoch[2](193/375); Loss: 0.061365; Backpropagation: 0.2883 sec; Batch: 2.0741 sec
0.1236 0.1059 0.0879 0.0748 0.0642 0.0581 0.0545 0.0516 0.0497 0.0479 0.0460 0.0449 0.0441 0.0435 0.0428 0.0424 

[TRAIN] Epoch[2](194/375); Loss: 0.093851; Backpropagation: 0.2881 sec; Batch: 2.0733 sec
0.1680 0.1550 0.1330 0.1108 0.0998 0.0915 0.0853 0.0809 0.0780 0.0758 0.0737 0.0720 0.0707 0.0698 0.0690 0.0683 

[TRAIN] Epoch[2](195/375); Loss: 0.071138; Backpropagation: 0.2881 sec; Batch: 2.0730 sec
0.1359 0.1341 0.1082 0.0939 0.0811 0.0697 0.0630 0.0582 0.0545 0.0521 0.0504 0.0491 0.0482 0.0473 0.0466 0.0459 

[TRAIN] Epoch[2](196/375); Loss: 0.072499; Backpropagation: 0.2885 sec; Batch: 2.0748 sec
0.1278 0.1267 0.1074 0.0842 0.0715 0.0691 0.0651 0.0617 0.0595 0.0578 0.0566 0.0556 0.0550 0.0544 0.0540 0.0537 

[TRAIN] Epoch[2](197/375); Loss: 0.073218; Backpropagation: 0.2941 sec; Batch: 2.0806 sec
0.1615 0.1521 0.1322 0.1073 0.0843 0.0676 0.0586 0.0543 0.0513 0.0480 0.0453 0.0436 0.0424 0.0415 0.0410 0.0404 

[TRAIN] Epoch[2](198/375); Loss: 0.058329; Backpropagation: 0.2901 sec; Batch: 2.0765 sec
0.1260 0.1109 0.0811 0.0646 0.0614 0.0541 0.0495 0.0469 0.0451 0.0437 0.0429 0.0422 0.0416 0.0413 0.0410 0.0408 

[TRAIN] Epoch[2](199/375); Loss: 0.087769; Backpropagation: 0.2896 sec; Batch: 2.0755 sec
0.1731 0.1692 0.1521 0.1316 0.1113 0.0919 0.0762 0.0661 0.0604 0.0592 0.0571 0.0540 0.0523 0.0509 0.0498 0.0492 

[TRAIN] Epoch[2](200/375); Loss: 0.051645; Backpropagation: 0.2893 sec; Batch: 2.0740 sec
0.1154 0.1206 0.1012 0.0776 0.0596 0.0452 0.0379 0.0360 0.0341 0.0315 0.0299 0.0286 0.0277 0.0273 0.0269 0.0267 

[TRAIN] Epoch[2](201/375); Loss: 0.077505; Backpropagation: 0.2881 sec; Batch: 2.0746 sec
0.1664 0.1616 0.1421 0.1067 0.0782 0.0707 0.0652 0.0593 0.0548 0.0520 0.0502 0.0486 0.0473 0.0462 0.0456 0.0451 

[TRAIN] Epoch[2](202/375); Loss: 0.065842; Backpropagation: 0.2882 sec; Batch: 2.0748 sec
0.1253 0.1002 0.0818 0.0699 0.0653 0.0638 0.0619 0.0589 0.0563 0.0546 0.0536 0.0528 0.0524 0.0522 0.0522 0.0524 

[TRAIN] Epoch[2](203/375); Loss: 0.050245; Backpropagation: 0.2888 sec; Batch: 2.0765 sec