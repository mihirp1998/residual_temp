Traceback (most recent call last):
  File "train.py", line 7, in <module>
    import torch
ImportError: No module named torch
vid count  100
total images: 1500; total batches: 1500
hypernet  1170076544
encoder  0
decoder  0
binarizer  0
Loaded
[TRAIN] Epoch[1](1/1500); Loss: 0.101388; Backpropagation: 0.1474 sec; Batch: 1.2038 sec
0.1902 0.1782 0.1469 0.1000 0.0930 0.0906 0.0857 0.0850 0.0825 0.0820 0.0816 0.0814 0.0814 0.0814 0.0812 0.0811 

[TRAIN] Epoch[1](2/1500); Loss: 0.069073; Backpropagation: 0.0920 sec; Batch: 0.4411 sec
0.1076 0.0906 0.0814 0.0742 0.0689 0.0647 0.0635 0.0627 0.0622 0.0615 0.0614 0.0613 0.0613 0.0613 0.0612 0.0612 

[TRAIN] Epoch[1](3/1500); Loss: 0.144291; Backpropagation: 0.0976 sec; Batch: 0.4461 sec
0.2216 0.1994 0.1944 0.1696 0.1598 0.1399 0.1302 0.1247 0.1235 0.1218 0.1219 0.1213 0.1205 0.1202 0.1198 0.1201 

[TRAIN] Epoch[1](4/1500); Loss: 0.077801; Backpropagation: 0.0953 sec; Batch: 0.4274 sec
0.1431 0.1713 0.1264 0.0956 0.0783 0.0685 0.0654 0.0617 0.0592 0.0567 0.0553 0.0535 0.0528 0.0523 0.0523 0.0525 

[TRAIN] Epoch[1](5/1500); Loss: 0.098700; Backpropagation: 0.0953 sec; Batch: 0.4278 sec
0.1234 0.1281 0.1150 0.1051 0.0994 0.0952 0.0935 0.0923 0.0917 0.0911 0.0908 0.0907 0.0905 0.0906 0.0908 0.0910 

[TRAIN] Epoch[1](6/1500); Loss: 0.046990; Backpropagation: 0.0934 sec; Batch: 0.4259 sec
0.0528 0.0947 0.0486 0.0435 0.0429 0.0423 0.0418 0.0422 0.0423 0.0422 0.0421 0.0424 0.0427 0.0432 0.0437 0.0443 

[TRAIN] Epoch[1](7/1500); Loss: 0.130030; Backpropagation: 0.0934 sec; Batch: 0.4256 sec
0.1810 0.1594 0.1557 0.1342 0.1286 0.1241 0.1221 0.1215 0.1210 0.1201 0.1196 0.1191 0.1187 0.1185 0.1183 0.1184 

[TRAIN] Epoch[1](8/1500); Loss: 0.139784; Backpropagation: 0.0936 sec; Batch: 0.4257 sec
0.1561 0.1665 0.1511 0.1431 0.1396 0.1362 0.1354 0.1346 0.1342 0.1338 0.1338 0.1339 0.1341 0.1344 0.1347 0.1351 

[TRAIN] Epoch[1](9/1500); Loss: 0.203737; Backpropagation: 0.0935 sec; Batch: 0.4255 sec
0.2503 0.2578 0.2359 0.2169 0.2083 0.1994 0.1970 0.1938 0.1919 0.1896 0.1886 0.1877 0.1866 0.1857 0.1853 0.1850 

[TRAIN] Epoch[1](10/1500); Loss: 0.134654; Backpropagation: 0.0925 sec; Batch: 0.4398 sec
0.2025 0.2271 0.1920 0.1599 0.1366 0.1202 0.1140 0.1130 0.1114 0.1103 0.1104 0.1110 0.1113 0.1115 0.1116 0.1116 

[TRAIN] Epoch[1](11/1500); Loss: 0.116559; Backpropagation: 0.0928 sec; Batch: 0.4275 sec
0.2730 0.3675 0.2734 0.2049 0.1218 0.0521 0.0530 0.0664 0.0631 0.0607 0.0583 0.0568 0.0555 0.0540 0.0526 0.0519 

[TRAIN] Epoch[1](12/1500); Loss: 0.078216; Backpropagation: 0.0927 sec; Batch: 0.4251 sec
0.1972 0.1433 0.1381 0.0942 0.0838 0.0676 0.0584 0.0533 0.0525 0.0537 0.0517 0.0510 0.0512 0.0514 0.0519 0.0521 

[TRAIN] Epoch[1](13/1500); Loss: 0.095323; Backpropagation: 0.0929 sec; Batch: 0.4252 sec
0.1568 0.1724 0.1429 0.1292 0.1001 0.0823 0.0769 0.0756 0.0746 0.0739 0.0734 0.0731 0.0732 0.0735 0.0737 0.0738 

[TRAIN] Epoch[1](14/1500); Loss: 0.151251; Backpropagation: 0.0924 sec; Batch: 0.4241 sec
0.2479 0.2864 0.2342 0.1923 0.1519 0.1292 0.1222 0.1201 0.1194 0.1190 0.1174 0.1173 0.1163 0.1158 0.1154 0.1152 

[TRAIN] Epoch[1](15/1500); Loss: 0.074650; Backpropagation: 0.0929 sec; Batch: 0.4257 sec
0.1093 0.1068 0.0920 0.0784 0.0734 0.0712 0.0695 0.0664 0.0655 0.0647 0.0645 0.0656 0.0666 0.0666 0.0664 0.0673 

[TRAIN] Epoch[1](16/1500); Loss: 0.125614; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2260 0.2110 0.1910 0.1538 0.1412 0.1220 0.1081 0.0969 0.0957 0.0957 0.0947 0.0947 0.0952 0.0948 0.0946 0.0946 

[TRAIN] Epoch[1](17/1500); Loss: 0.125971; Backpropagation: 0.0924 sec; Batch: 0.4265 sec
0.2337 0.1971 0.1870 0.1453 0.1289 0.1033 0.1082 0.1018 0.1003 0.0998 0.1009 0.1013 0.1018 0.1015 0.1017 0.1028 

[TRAIN] Epoch[1](18/1500); Loss: 0.072257; Backpropagation: 0.0915 sec; Batch: 0.4325 sec
0.1165 0.1021 0.0918 0.0728 0.0684 0.0691 0.0684 0.0626 0.0628 0.0628 0.0626 0.0621 0.0624 0.0633 0.0639 0.0645 

[TRAIN] Epoch[1](19/1500); Loss: 0.088846; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1570 0.2014 0.1427 0.0995 0.0753 0.0697 0.0690 0.0682 0.0672 0.0666 0.0668 0.0670 0.0670 0.0674 0.0680 0.0687 

[TRAIN] Epoch[1](20/1500); Loss: 0.065238; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0892 0.1125 0.0822 0.0667 0.0611 0.0600 0.0595 0.0585 0.0575 0.0569 0.0564 0.0562 0.0563 0.0565 0.0568 0.0574 

[TRAIN] Epoch[1](21/1500); Loss: 0.107126; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1594 0.1558 0.1374 0.1150 0.1056 0.0983 0.0967 0.0960 0.0953 0.0943 0.0939 0.0935 0.0933 0.0932 0.0931 0.0931 

[TRAIN] Epoch[1](22/1500); Loss: 0.085729; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1417 0.1589 0.1246 0.0987 0.0761 0.0730 0.0720 0.0710 0.0706 0.0701 0.0697 0.0692 0.0689 0.0689 0.0691 0.0693 

[TRAIN] Epoch[1](23/1500); Loss: 0.132630; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1805 0.1551 0.1522 0.1412 0.1334 0.1268 0.1256 0.1240 0.1232 0.1227 0.1226 0.1228 0.1229 0.1229 0.1229 0.1232 

[TRAIN] Epoch[1](24/1500); Loss: 0.135283; Backpropagation: 0.0916 sec; Batch: 0.4263 sec
0.1821 0.1566 0.1559 0.1402 0.1369 0.1329 0.1315 0.1287 0.1277 0.1265 0.1254 0.1247 0.1241 0.1239 0.1236 0.1237 

[TRAIN] Epoch[1](25/1500); Loss: 0.076438; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1230 0.1528 0.1068 0.0794 0.0700 0.0688 0.0672 0.0654 0.0637 0.0618 0.0610 0.0606 0.0603 0.0604 0.0606 0.0612 

[TRAIN] Epoch[1](26/1500); Loss: 0.099346; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2074 0.2626 0.2001 0.1573 0.1035 0.0729 0.0607 0.0592 0.0582 0.0575 0.0575 0.0577 0.0577 0.0586 0.0594 0.0593 

[TRAIN] Epoch[1](27/1500); Loss: 0.164019; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1921 0.1789 0.1745 0.1675 0.1642 0.1611 0.1596 0.1586 0.1580 0.1579 0.1581 0.1582 0.1583 0.1586 0.1591 0.1597 

[TRAIN] Epoch[1](28/1500); Loss: 0.043029; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.0532 0.0670 0.0467 0.0444 0.0421 0.0415 0.0405 0.0406 0.0404 0.0394 0.0388 0.0386 0.0387 0.0388 0.0388 0.0389 

[TRAIN] Epoch[1](29/1500); Loss: 0.130625; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1683 0.1840 0.1588 0.1435 0.1291 0.1239 0.1220 0.1200 0.1189 0.1181 0.1177 0.1172 0.1170 0.1171 0.1172 0.1171 

[TRAIN] Epoch[1](30/1500); Loss: 0.065772; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1035 0.0944 0.0765 0.0696 0.0643 0.0594 0.0587 0.0601 0.0597 0.0578 0.0569 0.0576 0.0583 0.0591 0.0582 0.0582 

[TRAIN] Epoch[1](31/1500); Loss: 0.109102; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1331 0.1220 0.1139 0.1108 0.1093 0.1094 0.1070 0.1042 0.1040 0.1046 0.1047 0.1042 0.1040 0.1044 0.1049 0.1052 

[TRAIN] Epoch[1](32/1500); Loss: 0.109267; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1627 0.1460 0.1314 0.1161 0.1133 0.1064 0.1052 0.1015 0.1003 0.0979 0.0963 0.0957 0.0948 0.0940 0.0936 0.0931 

[TRAIN] Epoch[1](33/1500); Loss: 0.114338; Backpropagation: 0.0918 sec; Batch: 0.4394 sec
0.1701 0.1483 0.1405 0.1260 0.1219 0.1184 0.1081 0.1039 0.1024 0.1006 0.0991 0.0987 0.0989 0.0983 0.0974 0.0968 

[TRAIN] Epoch[1](34/1500); Loss: 0.124445; Backpropagation: 0.0918 sec; Batch: 0.4426 sec
0.1627 0.1495 0.1434 0.1355 0.1291 0.1210 0.1178 0.1161 0.1153 0.1160 0.1154 0.1141 0.1140 0.1139 0.1135 0.1137 

[TRAIN] Epoch[1](35/1500); Loss: 0.060297; Backpropagation: 0.0917 sec; Batch: 0.4596 sec
0.2161 0.1429 0.1387 0.0466 0.0308 0.0625 0.0331 0.0294 0.0302 0.0312 0.0324 0.0336 0.0334 0.0336 0.0347 0.0357 

[TRAIN] Epoch[1](36/1500); Loss: 0.123713; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2501 0.2043 0.2019 0.1546 0.1387 0.1072 0.0974 0.1002 0.0919 0.0911 0.0908 0.0908 0.0907 0.0898 0.0900 0.0901 

[TRAIN] Epoch[1](37/1500); Loss: 0.083606; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1739 0.2605 0.1718 0.1234 0.0425 0.0581 0.0504 0.0493 0.0480 0.0468 0.0476 0.0491 0.0507 0.0537 0.0548 0.0571 

[TRAIN] Epoch[1](38/1500); Loss: 0.114127; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1385 0.1556 0.1255 0.1160 0.1103 0.1085 0.1077 0.1076 0.1071 0.1074 0.1072 0.1070 0.1066 0.1066 0.1069 0.1075 

[TRAIN] Epoch[1](39/1500); Loss: 0.050880; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.0668 0.1100 0.0614 0.0493 0.0451 0.0452 0.0440 0.0430 0.0425 0.0435 0.0435 0.0433 0.0434 0.0439 0.0441 0.0452 

[TRAIN] Epoch[1](40/1500); Loss: 0.058953; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.0925 0.1537 0.0866 0.0628 0.0516 0.0487 0.0461 0.0450 0.0436 0.0428 0.0438 0.0447 0.0444 0.0452 0.0455 0.0460 

[TRAIN] Epoch[1](41/1500); Loss: 0.053068; Backpropagation: 0.0920 sec; Batch: 0.4280 sec
0.1242 0.1911 0.1154 0.0793 0.0292 0.0368 0.0326 0.0302 0.0280 0.0258 0.0256 0.0251 0.0265 0.0264 0.0264 0.0265 

[TRAIN] Epoch[1](42/1500); Loss: 0.070688; Backpropagation: 0.0919 sec; Batch: 0.4260 sec
0.1540 0.0976 0.0943 0.0707 0.0691 0.0723 0.0605 0.0569 0.0568 0.0568 0.0572 0.0571 0.0567 0.0566 0.0570 0.0574 

[TRAIN] Epoch[1](43/1500); Loss: 0.113355; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1952 0.1687 0.1553 0.1223 0.1098 0.0997 0.1047 0.0978 0.0950 0.0953 0.0953 0.0947 0.0948 0.0948 0.0950 0.0955 

[TRAIN] Epoch[1](44/1500); Loss: 0.143705; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2067 0.1987 0.1788 0.1555 0.1416 0.1340 0.1307 0.1291 0.1291 0.1281 0.1278 0.1275 0.1277 0.1280 0.1282 0.1280 

[TRAIN] Epoch[1](45/1500); Loss: 0.072710; Backpropagation: 0.0920 sec; Batch: 0.4258 sec
0.1064 0.0890 0.0831 0.0774 0.0737 0.0764 0.0706 0.0663 0.0652 0.0651 0.0650 0.0648 0.0647 0.0649 0.0652 0.0656 

[TRAIN] Epoch[1](46/1500); Loss: 0.044284; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.0854 0.0804 0.0544 0.0437 0.0366 0.0371 0.0362 0.0365 0.0360 0.0364 0.0367 0.0365 0.0371 0.0376 0.0384 0.0394 

[TRAIN] Epoch[1](47/1500); Loss: 0.097222; Backpropagation: 0.0917 sec; Batch: 0.4255 sec
0.1694 0.1611 0.1373 0.1066 0.0955 0.0859 0.0863 0.0826 0.0804 0.0799 0.0795 0.0788 0.0782 0.0779 0.0780 0.0781 

[TRAIN] Epoch[1](48/1500); Loss: 0.069052; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1095 0.0975 0.0841 0.0761 0.0697 0.0660 0.0637 0.0622 0.0612 0.0606 0.0598 0.0594 0.0591 0.0589 0.0587 0.0584 

[TRAIN] Epoch[1](49/1500); Loss: 0.051445; Backpropagation: 0.0917 sec; Batch: 0.4249 sec
0.1424 0.0809 0.0771 0.0372 0.0456 0.0665 0.0498 0.0373 0.0356 0.0357 0.0353 0.0353 0.0357 0.0359 0.0362 0.0366 

[TRAIN] Epoch[1](50/1500); Loss: 0.143548; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2755 0.2244 0.2199 0.1693 0.1534 0.1353 0.1240 0.1194 0.1153 0.1123 0.1100 0.1087 0.1079 0.1076 0.1072 0.1065 

[TRAIN] Epoch[1](51/1500); Loss: 0.139869; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2251 0.1849 0.1885 0.1651 0.1550 0.1442 0.1355 0.1311 0.1269 0.1225 0.1179 0.1141 0.1103 0.1076 0.1053 0.1039 

[TRAIN] Epoch[1](52/1500); Loss: 0.153161; Backpropagation: 0.0920 sec; Batch: 0.4412 sec
0.1796 0.1640 0.1646 0.1613 0.1573 0.1551 0.1531 0.1515 0.1499 0.1485 0.1472 0.1459 0.1447 0.1436 0.1426 0.1416 

[TRAIN] Epoch[1](53/1500); Loss: 0.143305; Backpropagation: 0.0918 sec; Batch: 0.4400 sec
0.1977 0.1759 0.1700 0.1557 0.1485 0.1407 0.1368 0.1343 0.1322 0.1308 0.1296 0.1289 0.1284 0.1280 0.1277 0.1276 

[TRAIN] Epoch[1](54/1500); Loss: 0.067378; Backpropagation: 0.0919 sec; Batch: 0.4392 sec
0.0862 0.0937 0.0720 0.0694 0.0674 0.0667 0.0656 0.0646 0.0635 0.0626 0.0620 0.0616 0.0611 0.0608 0.0606 0.0604 

[TRAIN] Epoch[1](55/1500); Loss: 0.059357; Backpropagation: 0.0920 sec; Batch: 0.4251 sec
0.0877 0.0869 0.0627 0.0585 0.0553 0.0532 0.0521 0.0517 0.0513 0.0514 0.0521 0.0534 0.0551 0.0571 0.0593 0.0618 

[TRAIN] Epoch[1](56/1500); Loss: 0.121518; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1410 0.1279 0.1290 0.1291 0.1280 0.1268 0.1248 0.1223 0.1197 0.1172 0.1157 0.1144 0.1133 0.1124 0.1117 0.1110 

[TRAIN] Epoch[1](57/1500); Loss: 0.073421; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1089 0.0848 0.0820 0.0729 0.0753 0.0791 0.0807 0.0779 0.0726 0.0686 0.0657 0.0633 0.0616 0.0607 0.0605 0.0603 

[TRAIN] Epoch[1](58/1500); Loss: 0.113827; Backpropagation: 0.0923 sec; Batch: 0.4236 sec
0.1240 0.1254 0.1172 0.1170 0.1172 0.1170 0.1156 0.1132 0.1114 0.1102 0.1094 0.1090 0.1089 0.1087 0.1086 0.1084 

[TRAIN] Epoch[1](59/1500); Loss: 0.109721; Backpropagation: 0.0918 sec; Batch: 0.4382 sec
0.1423 0.1271 0.1212 0.1166 0.1164 0.1159 0.1135 0.1098 0.1049 0.1017 0.0998 0.0984 0.0977 0.0971 0.0967 0.0965 

[TRAIN] Epoch[1](60/1500); Loss: 0.133516; Backpropagation: 0.0917 sec; Batch: 0.4322 sec
0.1532 0.1330 0.1398 0.1397 0.1371 0.1358 0.1343 0.1329 0.1316 0.1306 0.1297 0.1290 0.1282 0.1276 0.1271 0.1267 

[TRAIN] Epoch[1](61/1500); Loss: 0.101898; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1218 0.1157 0.1129 0.1083 0.1062 0.1034 0.1010 0.0992 0.0974 0.0960 0.0950 0.0947 0.0946 0.0946 0.0947 0.0948 

[TRAIN] Epoch[1](62/1500); Loss: 0.117744; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1387 0.1442 0.1301 0.1260 0.1198 0.1166 0.1147 0.1135 0.1125 0.1116 0.1107 0.1100 0.1095 0.1090 0.1087 0.1083 

[TRAIN] Epoch[1](63/1500); Loss: 0.071205; Backpropagation: 0.0920 sec; Batch: 0.4249 sec
0.1351 0.1880 0.1157 0.0893 0.0587 0.0517 0.0513 0.0501 0.0496 0.0493 0.0492 0.0494 0.0497 0.0502 0.0507 0.0514 

[TRAIN] Epoch[1](64/1500); Loss: 0.078891; Backpropagation: 0.0927 sec; Batch: 0.4246 sec
0.1290 0.1643 0.1034 0.0822 0.0723 0.0697 0.0688 0.0672 0.0659 0.0648 0.0637 0.0629 0.0623 0.0619 0.0617 0.0620 

[TRAIN] Epoch[1](65/1500); Loss: 0.074554; Backpropagation: 0.0920 sec; Batch: 0.4355 sec
0.0965 0.1099 0.0830 0.0775 0.0755 0.0733 0.0718 0.0706 0.0695 0.0684 0.0674 0.0667 0.0662 0.0657 0.0654 0.0653 

[TRAIN] Epoch[1](66/1500); Loss: 0.154403; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1839 0.1877 0.1724 0.1645 0.1569 0.1518 0.1482 0.1467 0.1461 0.1454 0.1450 0.1447 0.1445 0.1443 0.1442 0.1443 

[TRAIN] Epoch[1](67/1500); Loss: 0.120386; Backpropagation: 0.1065 sec; Batch: 0.4429 sec
0.1433 0.1290 0.1304 0.1286 0.1248 0.1227 0.1207 0.1190 0.1175 0.1161 0.1148 0.1137 0.1126 0.1118 0.1110 0.1103 

[TRAIN] Epoch[1](68/1500); Loss: 0.131261; Backpropagation: 0.0918 sec; Batch: 0.4270 sec
0.1471 0.1438 0.1351 0.1326 0.1303 0.1295 0.1292 0.1291 0.1287 0.1283 0.1280 0.1278 0.1277 0.1277 0.1276 0.1277 

[TRAIN] Epoch[1](69/1500); Loss: 0.103031; Backpropagation: 0.0918 sec; Batch: 0.4306 sec
0.1330 0.1143 0.1151 0.1110 0.1069 0.1039 0.1016 0.0998 0.0984 0.0972 0.0962 0.0955 0.0948 0.0942 0.0936 0.0931 

[TRAIN] Epoch[1](70/1500); Loss: 0.104414; Backpropagation: 0.0921 sec; Batch: 0.4277 sec
0.1302 0.1284 0.1141 0.1085 0.1040 0.1011 0.0998 0.0989 0.0985 0.0981 0.0980 0.0981 0.0983 0.0982 0.0983 0.0983 

[TRAIN] Epoch[1](71/1500); Loss: 0.121773; Backpropagation: 0.0932 sec; Batch: 0.4280 sec
0.2648 0.2183 0.1952 0.1590 0.1410 0.1208 0.1117 0.1007 0.0926 0.0853 0.0803 0.0772 0.0755 0.0748 0.0750 0.0762 

[TRAIN] Epoch[1](72/1500); Loss: 0.131962; Backpropagation: 0.0917 sec; Batch: 0.4308 sec
0.1640 0.1455 0.1413 0.1343 0.1317 0.1307 0.1299 0.1285 0.1263 0.1259 0.1259 0.1258 0.1256 0.1255 0.1254 0.1252 

[TRAIN] Epoch[1](73/1500); Loss: 0.056930; Backpropagation: 0.0923 sec; Batch: 0.4257 sec
0.0776 0.0719 0.0686 0.0702 0.0672 0.0642 0.0577 0.0499 0.0480 0.0485 0.0481 0.0477 0.0476 0.0477 0.0479 0.0482 

[TRAIN] Epoch[1](74/1500); Loss: 0.093054; Backpropagation: 0.0917 sec; Batch: 0.4303 sec
0.1279 0.1193 0.1010 0.0964 0.0946 0.0938 0.0910 0.0886 0.0869 0.0861 0.0853 0.0845 0.0839 0.0835 0.0831 0.0829 

[TRAIN] Epoch[1](75/1500); Loss: 0.058250; Backpropagation: 0.0917 sec; Batch: 0.4269 sec
0.0855 0.0937 0.0760 0.0754 0.0666 0.0607 0.0556 0.0517 0.0492 0.0474 0.0464 0.0455 0.0450 0.0446 0.0444 0.0442 

[TRAIN] Epoch[1](76/1500); Loss: 0.105579; Backpropagation: 0.0936 sec; Batch: 0.4254 sec
0.1333 0.1199 0.1078 0.1082 0.1085 0.1067 0.1020 0.1004 0.1010 0.1007 0.1003 0.0999 0.0997 0.0998 0.1003 0.1007 

[TRAIN] Epoch[1](77/1500); Loss: 0.120761; Backpropagation: 0.0979 sec; Batch: 0.4345 sec
0.1630 0.1969 0.1524 0.1391 0.1207 0.1142 0.1092 0.1061 0.1049 0.1043 0.1041 0.1040 0.1037 0.1034 0.1032 0.1029 

[TRAIN] Epoch[1](78/1500); Loss: 0.093926; Backpropagation: 0.0975 sec; Batch: 0.4301 sec
0.1097 0.1045 0.0964 0.1000 0.0996 0.1004 0.0951 0.0900 0.0882 0.0879 0.0878 0.0879 0.0882 0.0885 0.0890 0.0894 

[TRAIN] Epoch[1](79/1500); Loss: 0.063005; Backpropagation: 0.0927 sec; Batch: 0.4246 sec
0.0781 0.1020 0.0694 0.0638 0.0594 0.0587 0.0586 0.0585 0.0580 0.0573 0.0572 0.0574 0.0575 0.0574 0.0573 0.0575 

[TRAIN] Epoch[1](80/1500); Loss: 0.110302; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1720 0.1724 0.1327 0.1042 0.1039 0.1014 0.0990 0.0971 0.0971 0.0971 0.0977 0.0978 0.0979 0.0979 0.0981 0.0985 

[TRAIN] Epoch[1](81/1500); Loss: 0.086800; Backpropagation: 0.0918 sec; Batch: 0.4246 sec
0.1266 0.1161 0.1094 0.1029 0.0936 0.0887 0.0837 0.0802 0.0778 0.0759 0.0743 0.0730 0.0722 0.0717 0.0714 0.0712 

[TRAIN] Epoch[1](82/1500); Loss: 0.068392; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1046 0.0951 0.0851 0.0754 0.0707 0.0679 0.0647 0.0622 0.0602 0.0587 0.0577 0.0573 0.0576 0.0583 0.0590 0.0598 

[TRAIN] Epoch[1](83/1500); Loss: 0.092646; Backpropagation: 0.0918 sec; Batch: 0.4247 sec
0.1858 0.1439 0.1236 0.0751 0.0768 0.0893 0.0910 0.0807 0.0793 0.0775 0.0764 0.0757 0.0757 0.0762 0.0773 0.0780 

[TRAIN] Epoch[1](84/1500); Loss: 0.077831; Backpropagation: 0.0916 sec; Batch: 0.4366 sec
0.1803 0.2276 0.1575 0.1274 0.0686 0.0500 0.0493 0.0462 0.0450 0.0439 0.0429 0.0421 0.0412 0.0409 0.0411 0.0414 

[TRAIN] Epoch[1](85/1500); Loss: 0.172844; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2760 0.2328 0.2100 0.1569 0.1515 0.1536 0.1586 0.1615 0.1602 0.1566 0.1565 0.1572 0.1583 0.1584 0.1586 0.1586 

[TRAIN] Epoch[1](86/1500); Loss: 0.108919; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1528 0.1555 0.1366 0.1293 0.1212 0.1140 0.1051 0.0991 0.0957 0.0932 0.0913 0.0903 0.0900 0.0898 0.0895 0.0895 

[TRAIN] Epoch[1](87/1500); Loss: 0.053204; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0840 0.0890 0.0632 0.0563 0.0528 0.0498 0.0475 0.0460 0.0453 0.0451 0.0453 0.0453 0.0451 0.0452 0.0455 0.0459 

[TRAIN] Epoch[1](88/1500); Loss: 0.078440; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.0920 0.0902 0.0848 0.0880 0.0860 0.0790 0.0734 0.0728 0.0727 0.0730 0.0734 0.0736 0.0737 0.0738 0.0742 0.0747 

[TRAIN] Epoch[1](89/1500); Loss: 0.067169; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0973 0.0959 0.0784 0.0685 0.0647 0.0628 0.0619 0.0612 0.0610 0.0607 0.0606 0.0605 0.0604 0.0603 0.0603 0.0603 

[TRAIN] Epoch[1](90/1500); Loss: 0.114664; Backpropagation: 0.0920 sec; Batch: 0.4250 sec
0.1397 0.1533 0.1214 0.1144 0.1105 0.1102 0.1100 0.1097 0.1094 0.1088 0.1085 0.1081 0.1079 0.1078 0.1077 0.1073 

[TRAIN] Epoch[1](91/1500); Loss: 0.083101; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1064 0.0946 0.0873 0.0828 0.0839 0.0817 0.0798 0.0791 0.0789 0.0787 0.0788 0.0789 0.0792 0.0795 0.0798 0.0801 

[TRAIN] Epoch[1](92/1500); Loss: 0.082376; Backpropagation: 0.0917 sec; Batch: 0.4331 sec
0.0999 0.1129 0.0871 0.0827 0.0815 0.0800 0.0789 0.0782 0.0774 0.0767 0.0765 0.0766 0.0771 0.0776 0.0775 0.0774 

[TRAIN] Epoch[1](93/1500); Loss: 0.091882; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1151 0.1138 0.1004 0.0927 0.0913 0.0901 0.0887 0.0875 0.0871 0.0867 0.0864 0.0860 0.0858 0.0859 0.0861 0.0866 

[TRAIN] Epoch[1](94/1500); Loss: 0.125347; Backpropagation: 0.0918 sec; Batch: 0.4269 sec
0.1718 0.1486 0.1378 0.1239 0.1236 0.1227 0.1205 0.1193 0.1181 0.1171 0.1166 0.1166 0.1169 0.1173 0.1173 0.1176 

[TRAIN] Epoch[1](95/1500); Loss: 0.057091; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1372 0.1066 0.0948 0.0690 0.0602 0.0493 0.0448 0.0416 0.0400 0.0388 0.0392 0.0391 0.0384 0.0381 0.0381 0.0382 

[TRAIN] Epoch[1](96/1500); Loss: 0.059979; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.0984 0.0901 0.0723 0.0672 0.0618 0.0596 0.0564 0.0543 0.0525 0.0509 0.0499 0.0493 0.0494 0.0493 0.0491 0.0494 

[TRAIN] Epoch[1](97/1500); Loss: 0.120387; Backpropagation: 0.0918 sec; Batch: 0.4272 sec
0.1376 0.1336 0.1245 0.1227 0.1213 0.1203 0.1191 0.1182 0.1178 0.1171 0.1165 0.1161 0.1159 0.1156 0.1152 0.1147 

[TRAIN] Epoch[1](98/1500); Loss: 0.127914; Backpropagation: 0.0916 sec; Batch: 0.4266 sec
0.3497 0.2763 0.2547 0.1831 0.1557 0.1180 0.0925 0.0789 0.0660 0.0599 0.0605 0.0642 0.0692 0.0737 0.0729 0.0713 

[TRAIN] Epoch[1](99/1500); Loss: 0.148907; Backpropagation: 0.0920 sec; Batch: 0.4260 sec
0.1890 0.1829 0.1679 0.1578 0.1540 0.1490 0.1462 0.1435 0.1413 0.1393 0.1374 0.1361 0.1353 0.1346 0.1342 0.1339 

[TRAIN] Epoch[1](100/1500); Loss: 0.093955; Backpropagation: 0.0916 sec; Batch: 0.4334 sec
0.1505 0.1718 0.1325 0.1155 0.0969 0.0872 0.0793 0.0765 0.0760 0.0751 0.0745 0.0740 0.0735 0.0734 0.0732 0.0732 

[TRAIN] Epoch[1](101/1500); Loss: 0.120017; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1834 0.1774 0.1553 0.1340 0.1213 0.1119 0.1070 0.1051 0.1039 0.1033 0.1030 0.1029 0.1027 0.1028 0.1029 0.1031 

[TRAIN] Epoch[1](102/1500); Loss: 0.097528; Backpropagation: 0.0916 sec; Batch: 0.4578 sec
0.2065 0.1885 0.1505 0.1129 0.0888 0.0818 0.0784 0.0769 0.0741 0.0721 0.0713 0.0709 0.0714 0.0717 0.0725 0.0722 

[TRAIN] Epoch[1](103/1500); Loss: 0.104397; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1390 0.1335 0.1226 0.1144 0.1076 0.1013 0.0986 0.0970 0.0958 0.0950 0.0946 0.0948 0.0946 0.0941 0.0937 0.0936 

[TRAIN] Epoch[1](104/1500); Loss: 0.085628; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1485 0.1601 0.1153 0.0926 0.0863 0.0779 0.0737 0.0711 0.0692 0.0693 0.0687 0.0683 0.0673 0.0673 0.0674 0.0671 

[TRAIN] Epoch[1](105/1500); Loss: 0.091983; Backpropagation: 0.0919 sec; Batch: 0.4294 sec
0.1248 0.1487 0.1093 0.0951 0.0916 0.0868 0.0845 0.0829 0.0815 0.0808 0.0809 0.0814 0.0812 0.0807 0.0807 0.0809 

[TRAIN] Epoch[1](106/1500); Loss: 0.056421; Backpropagation: 0.0915 sec; Batch: 0.4398 sec
0.0980 0.0923 0.0723 0.0595 0.0533 0.0518 0.0496 0.0486 0.0478 0.0473 0.0471 0.0474 0.0468 0.0468 0.0468 0.0473 

[TRAIN] Epoch[1](107/1500); Loss: 0.122557; Backpropagation: 0.0919 sec; Batch: 0.4268 sec
0.1548 0.1545 0.1370 0.1301 0.1247 0.1208 0.1168 0.1147 0.1139 0.1140 0.1137 0.1132 0.1127 0.1131 0.1136 0.1135 

[TRAIN] Epoch[1](108/1500); Loss: 0.100421; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1718 0.1658 0.1104 0.0948 0.0913 0.0887 0.0888 0.0895 0.0889 0.0876 0.0879 0.0879 0.0877 0.0882 0.0887 0.0888 

[TRAIN] Epoch[1](109/1500); Loss: 0.118747; Backpropagation: 0.0921 sec; Batch: 0.4269 sec
0.1395 0.1429 0.1253 0.1204 0.1195 0.1170 0.1155 0.1145 0.1138 0.1135 0.1135 0.1134 0.1128 0.1127 0.1130 0.1129 

[TRAIN] Epoch[1](110/1500); Loss: 0.053624; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.1494 0.1196 0.0997 0.0638 0.0557 0.0435 0.0396 0.0375 0.0363 0.0333 0.0301 0.0281 0.0298 0.0307 0.0306 0.0303 

[TRAIN] Epoch[1](111/1500); Loss: 0.132851; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1699 0.1754 0.1518 0.1400 0.1317 0.1285 0.1261 0.1241 0.1227 0.1230 0.1226 0.1220 0.1216 0.1218 0.1222 0.1221 

[TRAIN] Epoch[1](112/1500); Loss: 0.108166; Backpropagation: 0.0921 sec; Batch: 0.4261 sec
0.2134 0.2038 0.1596 0.1290 0.1029 0.0931 0.0885 0.0856 0.0811 0.0842 0.0826 0.0819 0.0812 0.0811 0.0816 0.0812 

[TRAIN] Epoch[1](113/1500); Loss: 0.133563; Backpropagation: 0.0918 sec; Batch: 0.4264 sec
0.1596 0.1539 0.1426 0.1381 0.1363 0.1333 0.1309 0.1287 0.1282 0.1275 0.1270 0.1263 0.1259 0.1261 0.1262 0.1263 

[TRAIN] Epoch[1](114/1500); Loss: 0.076547; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1197 0.1549 0.0982 0.0743 0.0719 0.0671 0.0657 0.0646 0.0636 0.0636 0.0638 0.0630 0.0628 0.0639 0.0641 0.0634 

[TRAIN] Epoch[1](115/1500); Loss: 0.066836; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.0917 0.0922 0.0705 0.0670 0.0655 0.0634 0.0632 0.0621 0.0612 0.0607 0.0609 0.0611 0.0615 0.0620 0.0626 0.0636 

[TRAIN] Epoch[1](116/1500); Loss: 0.065608; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.0923 0.0709 0.0667 0.0809 0.0680 0.0611 0.0587 0.0576 0.0578 0.0589 0.0622 0.0615 0.0616 0.0625 0.0634 0.0656 

[TRAIN] Epoch[1](117/1500); Loss: 0.080132; Backpropagation: 0.0919 sec; Batch: 0.4427 sec
0.1300 0.1298 0.1009 0.0875 0.0770 0.0742 0.0707 0.0694 0.0685 0.0679 0.0680 0.0683 0.0677 0.0673 0.0672 0.0676 

[TRAIN] Epoch[1](118/1500); Loss: 0.112453; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1269 0.1205 0.1162 0.1141 0.1125 0.1109 0.1100 0.1096 0.1093 0.1094 0.1095 0.1098 0.1105 0.1103 0.1100 0.1098 

[TRAIN] Epoch[1](119/1500); Loss: 0.095436; Backpropagation: 0.0919 sec; Batch: 0.4253 sec
0.1271 0.1206 0.1076 0.0963 0.0943 0.0923 0.0902 0.0900 0.0896 0.0896 0.0887 0.0880 0.0883 0.0884 0.0882 0.0879 

[TRAIN] Epoch[1](120/1500); Loss: 0.093749; Backpropagation: 0.0921 sec; Batch: 0.4253 sec
0.1343 0.1303 0.1044 0.0942 0.0928 0.0899 0.0882 0.0870 0.0863 0.0856 0.0853 0.0847 0.0845 0.0843 0.0841 0.0840 

[TRAIN] Epoch[1](121/1500); Loss: 0.084296; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1037 0.0921 0.0841 0.0797 0.0797 0.0789 0.0783 0.0795 0.0805 0.0815 0.0825 0.0834 0.0842 0.0851 0.0868 0.0886 

[TRAIN] Epoch[1](122/1500); Loss: 0.123566; Backpropagation: 0.0921 sec; Batch: 0.4278 sec
0.2391 0.2146 0.1941 0.1510 0.1389 0.1215 0.1122 0.1069 0.1008 0.0949 0.0905 0.0874 0.0852 0.0819 0.0795 0.0784 

[TRAIN] Epoch[1](123/1500); Loss: 0.130773; Backpropagation: 0.0977 sec; Batch: 0.4304 sec
0.1961 0.1782 0.1702 0.1442 0.1379 0.1277 0.1228 0.1188 0.1161 0.1140 0.1127 0.1117 0.1110 0.1103 0.1103 0.1104 

[TRAIN] Epoch[1](124/1500); Loss: 0.176557; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2217 0.2146 0.2052 0.1885 0.1846 0.1757 0.1717 0.1681 0.1655 0.1635 0.1619 0.1612 0.1608 0.1604 0.1605 0.1611 

[TRAIN] Epoch[1](125/1500); Loss: 0.074750; Backpropagation: 0.0922 sec; Batch: 0.4254 sec
0.1345 0.1108 0.1024 0.0739 0.0695 0.0663 0.0689 0.0684 0.0646 0.0620 0.0617 0.0619 0.0623 0.0626 0.0632 0.0630 

[TRAIN] Epoch[1](126/1500); Loss: 0.067490; Backpropagation: 0.0919 sec; Batch: 0.4554 sec
0.1031 0.0953 0.0784 0.0719 0.0650 0.0626 0.0619 0.0612 0.0607 0.0603 0.0602 0.0595 0.0597 0.0598 0.0598 0.0603 

[TRAIN] Epoch[1](127/1500); Loss: 0.063701; Backpropagation: 0.0920 sec; Batch: 0.4265 sec
0.0844 0.0818 0.0748 0.0751 0.0684 0.0631 0.0594 0.0567 0.0553 0.0552 0.0563 0.0566 0.0569 0.0576 0.0587 0.0590 

[TRAIN] Epoch[1](128/1500); Loss: 0.176606; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2796 0.2512 0.2366 0.1916 0.1797 0.1582 0.1555 0.1543 0.1540 0.1514 0.1525 0.1524 0.1517 0.1520 0.1523 0.1526 

[TRAIN] Epoch[1](129/1500); Loss: 0.094582; Backpropagation: 0.0921 sec; Batch: 0.4263 sec
0.1236 0.1130 0.1042 0.0939 0.0935 0.0973 0.0962 0.0928 0.0886 0.0875 0.0875 0.0869 0.0873 0.0867 0.0871 0.0875 

[TRAIN] Epoch[1](130/1500); Loss: 0.130057; Backpropagation: 0.0921 sec; Batch: 0.4273 sec
0.1717 0.1721 0.1618 0.1578 0.1538 0.1450 0.1359 0.1276 0.1203 0.1141 0.1094 0.1059 0.1037 0.1018 0.1005 0.0997 

[TRAIN] Epoch[1](131/1500); Loss: 0.126666; Backpropagation: 0.0921 sec; Batch: 0.4270 sec
0.1589 0.1464 0.1402 0.1337 0.1335 0.1345 0.1307 0.1236 0.1195 0.1179 0.1167 0.1153 0.1141 0.1135 0.1139 0.1142 

[TRAIN] Epoch[1](132/1500); Loss: 0.094077; Backpropagation: 0.0916 sec; Batch: 0.4270 sec
0.1909 0.1683 0.1438 0.1099 0.1018 0.0870 0.0819 0.0777 0.0731 0.0706 0.0694 0.0681 0.0661 0.0653 0.0654 0.0656 

[TRAIN] Epoch[1](133/1500); Loss: 0.102827; Backpropagation: 0.0920 sec; Batch: 0.4275 sec
0.1589 0.1382 0.1244 0.1130 0.1070 0.0962 0.0923 0.0911 0.0901 0.0899 0.0913 0.0899 0.0900 0.0910 0.0906 0.0912 

[TRAIN] Epoch[1](134/1500); Loss: 0.094298; Backpropagation: 0.0917 sec; Batch: 0.4538 sec
0.1644 0.1584 0.1202 0.0938 0.0832 0.0814 0.0804 0.0810 0.0806 0.0796 0.0799 0.0805 0.0815 0.0807 0.0812 0.0821 

[TRAIN] Epoch[1](135/1500); Loss: 0.076299; Backpropagation: 0.0919 sec; Batch: 0.4274 sec
0.1311 0.1445 0.0910 0.0676 0.0645 0.0626 0.0626 0.0633 0.0646 0.0644 0.0647 0.0655 0.0667 0.0685 0.0687 0.0705 

[TRAIN] Epoch[1](136/1500); Loss: 0.078274; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1280 0.1057 0.0889 0.0808 0.0733 0.0716 0.0693 0.0691 0.0711 0.0697 0.0706 0.0695 0.0701 0.0712 0.0717 0.0717 

[TRAIN] Epoch[1](137/1500); Loss: 0.075079; Backpropagation: 0.0919 sec; Batch: 0.4250 sec
0.1251 0.1432 0.0975 0.0763 0.0701 0.0644 0.0615 0.0619 0.0607 0.0608 0.0644 0.0606 0.0620 0.0654 0.0639 0.0635 

[TRAIN] Epoch[1](138/1500); Loss: 0.071871; Backpropagation: 0.0917 sec; Batch: 0.4266 sec
0.1223 0.0970 0.0838 0.0747 0.0702 0.0678 0.0643 0.0630 0.0626 0.0628 0.0619 0.0641 0.0632 0.0632 0.0645 0.0644 

[TRAIN] Epoch[1](139/1500); Loss: 0.146659; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.2331 0.2020 0.1898 0.1558 0.1472 0.1295 0.1245 0.1237 0.1267 0.1286 0.1290 0.1296 0.1300 0.1303 0.1336 0.1332 

[TRAIN] Epoch[1](140/1500); Loss: 0.126982; Backpropagation: 0.0917 sec; Batch: 0.4537 sec
0.2052 0.1761 0.1604 0.1363 0.1254 0.1188 0.1139 0.1111 0.1105 0.1097 0.1095 0.1100 0.1104 0.1109 0.1118 0.1119 

[TRAIN] Epoch[1](141/1500); Loss: 0.134317; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1788 0.1700 0.1554 0.1449 0.1372 0.1324 0.1288 0.1265 0.1241 0.1226 0.1219 0.1212 0.1213 0.1211 0.1212 0.1219 

[TRAIN] Epoch[1](142/1500); Loss: 0.121364; Backpropagation: 0.0919 sec; Batch: 0.4275 sec
0.1865 0.2025 0.1511 0.1210 0.1166 0.1123 0.1080 0.1064 0.1066 0.1049 0.1037 0.1040 0.1034 0.1046 0.1048 0.1056 

[TRAIN] Epoch[1](143/1500); Loss: 0.109933; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.1551 0.1449 0.1311 0.1237 0.1177 0.1108 0.1078 0.1028 0.1005 0.0984 0.0969 0.0953 0.0945 0.0931 0.0930 0.0935 

[TRAIN] Epoch[1](144/1500); Loss: 0.167127; Backpropagation: 0.0927 sec; Batch: 0.4313 sec
0.2132 0.1842 0.1861 0.1804 0.1744 0.1700 0.1662 0.1627 0.1602 0.1576 0.1556 0.1539 0.1528 0.1526 0.1520 0.1520 

[TRAIN] Epoch[1](145/1500); Loss: 0.190065; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2263 0.1940 0.2061 0.2029 0.1977 0.1938 0.1905 0.1879 0.1855 0.1836 0.1818 0.1803 0.1791 0.1780 0.1771 0.1765 

[TRAIN] Epoch[1](146/1500); Loss: 0.190169; Backpropagation: 0.0920 sec; Batch: 0.4253 sec
0.2297 0.2074 0.2100 0.2017 0.1947 0.1903 0.1879 0.1855 0.1836 0.1824 0.1807 0.1795 0.1785 0.1779 0.1769 0.1759 

[TRAIN] Epoch[1](147/1500); Loss: 0.176515; Backpropagation: 0.0921 sec; Batch: 0.4269 sec
0.1945 0.1795 0.1872 0.1840 0.1805 0.1784 0.1766 0.1750 0.1737 0.1724 0.1716 0.1710 0.1705 0.1703 0.1695 0.1694 

[TRAIN] Epoch[1](148/1500); Loss: 0.279202; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.3389 0.2921 0.3114 0.3046 0.2976 0.2908 0.2859 0.2799 0.2749 0.2694 0.2646 0.2602 0.2553 0.2511 0.2472 0.2434 

[TRAIN] Epoch[1](149/1500); Loss: 0.344390; Backpropagation: 0.0917 sec; Batch: 0.4625 sec
0.3844 0.3395 0.3703 0.3648 0.3597 0.3548 0.3508 0.3464 0.3422 0.3382 0.3351 0.3315 0.3282 0.3248 0.3212 0.3185 

[TRAIN] Epoch[1](150/1500); Loss: 0.063462; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0629 0.1202 0.0585 0.0616 0.0561 0.0556 0.0553 0.0554 0.0563 0.0572 0.0586 0.0596 0.0614 0.0634 0.0657 0.0677 

[TRAIN] Epoch[1](151/1500); Loss: 0.102626; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1235 0.1167 0.1126 0.1091 0.1060 0.1031 0.1014 0.0994 0.0979 0.0967 0.0959 0.0954 0.0955 0.0957 0.0962 0.0967 

[TRAIN] Epoch[1](152/1500); Loss: 0.328239; Backpropagation: 0.0917 sec; Batch: 0.4384 sec
0.3728 0.3249 0.3529 0.3491 0.3445 0.3395 0.3359 0.3312 0.3271 0.3226 0.3185 0.3144 0.3103 0.3065 0.3028 0.2989 

[TRAIN] Epoch[1](153/1500); Loss: 0.271521; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3420 0.2945 0.3102 0.3017 0.2945 0.2855 0.2791 0.2721 0.2658 0.2595 0.2536 0.2479 0.2424 0.2369 0.2318 0.2269 

[TRAIN] Epoch[1](154/1500); Loss: 0.256077; Backpropagation: 0.0919 sec; Batch: 0.4265 sec
0.3032 0.2537 0.2890 0.2836 0.2780 0.2716 0.2660 0.2599 0.2547 0.2489 0.2439 0.2383 0.2337 0.2285 0.2244 0.2199 

[TRAIN] Epoch[1](155/1500); Loss: 0.100425; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1065 0.1190 0.1058 0.1036 0.1017 0.1001 0.0989 0.0977 0.0971 0.0965 0.0963 0.0963 0.0963 0.0965 0.0970 0.0974 

[TRAIN] Epoch[1](156/1500); Loss: 0.169712; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2406 0.1978 0.2114 0.1989 0.1922 0.1803 0.1747 0.1659 0.1608 0.1542 0.1498 0.1445 0.1409 0.1372 0.1345 0.1317 

[TRAIN] Epoch[1](157/1500); Loss: 0.192472; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2594 0.2040 0.2352 0.2277 0.2201 0.2104 0.2033 0.1943 0.1876 0.1793 0.1735 0.1667 0.1617 0.1561 0.1521 0.1482 

[TRAIN] Epoch[1](158/1500); Loss: 0.356933; Backpropagation: 0.0917 sec; Batch: 0.4254 sec
0.4349 0.3872 0.4067 0.3951 0.3893 0.3759 0.3701 0.3582 0.3524 0.3416 0.3360 0.3260 0.3207 0.3117 0.3065 0.2985 

[TRAIN] Epoch[1](159/1500); Loss: 0.146607; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2100 0.1710 0.1839 0.1769 0.1695 0.1583 0.1519 0.1429 0.1375 0.1308 0.1267 0.1223 0.1195 0.1165 0.1146 0.1133 

[TRAIN] Epoch[1](160/1500); Loss: 0.265243; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.3494 0.2988 0.3142 0.3009 0.2936 0.2775 0.2714 0.2597 0.2552 0.2460 0.2426 0.2351 0.2322 0.2259 0.2235 0.2180 

[TRAIN] Epoch[1](161/1500); Loss: 0.155852; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2597 0.2057 0.2052 0.1789 0.1749 0.1603 0.1546 0.1382 0.1353 0.1266 0.1259 0.1227 0.1240 0.1247 0.1273 0.1294 

[TRAIN] Epoch[1](162/1500); Loss: 0.209820; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2756 0.2286 0.2412 0.2311 0.2268 0.2147 0.2110 0.2010 0.1990 0.1922 0.1916 0.1879 0.1886 0.1875 0.1895 0.1910 

[TRAIN] Epoch[1](163/1500); Loss: 0.156000; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2145 0.1838 0.1775 0.1537 0.1502 0.1446 0.1442 0.1459 0.1467 0.1492 0.1474 0.1475 0.1482 0.1478 0.1476 0.1475 

[TRAIN] Epoch[1](164/1500); Loss: 0.160060; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.2041 0.1691 0.1685 0.1577 0.1570 0.1590 0.1579 0.1548 0.1548 0.1538 0.1537 0.1538 0.1535 0.1532 0.1544 0.1555 

[TRAIN] Epoch[1](165/1500); Loss: 0.140515; Backpropagation: 0.1006 sec; Batch: 0.4351 sec
0.1794 0.1712 0.1572 0.1491 0.1449 0.1376 0.1355 0.1297 0.1291 0.1266 0.1274 0.1274 0.1298 0.1317 0.1341 0.1374 

[TRAIN] Epoch[1](166/1500); Loss: 0.115742; Backpropagation: 0.0983 sec; Batch: 0.4314 sec
0.1383 0.1391 0.1244 0.1170 0.1155 0.1112 0.1097 0.1075 0.1079 0.1075 0.1088 0.1093 0.1108 0.1124 0.1147 0.1177 

[TRAIN] Epoch[1](167/1500); Loss: 0.187469; Backpropagation: 0.0984 sec; Batch: 0.4316 sec
0.2006 0.1983 0.1885 0.1855 0.1847 0.1824 0.1827 0.1834 0.1835 0.1845 0.1851 0.1862 0.1869 0.1882 0.1889 0.1902 

[TRAIN] Epoch[1](168/1500); Loss: 0.139421; Backpropagation: 0.0981 sec; Batch: 0.4320 sec
0.1738 0.1437 0.1440 0.1343 0.1318 0.1297 0.1299 0.1315 0.1320 0.1340 0.1356 0.1389 0.1401 0.1428 0.1438 0.1447 

[TRAIN] Epoch[1](169/1500); Loss: 0.145724; Backpropagation: 0.0922 sec; Batch: 0.4269 sec
0.1675 0.1435 0.1409 0.1402 0.1417 0.1455 0.1432 0.1429 0.1435 0.1445 0.1445 0.1447 0.1452 0.1464 0.1478 0.1496 

[TRAIN] Epoch[1](170/1500); Loss: 0.099214; Backpropagation: 0.0920 sec; Batch: 0.4270 sec
0.1280 0.1485 0.1145 0.1022 0.0996 0.0940 0.0922 0.0886 0.0886 0.0873 0.0880 0.0884 0.0896 0.0911 0.0925 0.0945 

[TRAIN] Epoch[1](171/1500); Loss: 0.152671; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2205 0.1850 0.1909 0.1809 0.1754 0.1594 0.1562 0.1405 0.1388 0.1288 0.1289 0.1254 0.1267 0.1266 0.1286 0.1301 

[TRAIN] Epoch[1](172/1500); Loss: 0.149267; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.1795 0.1613 0.1599 0.1554 0.1523 0.1460 0.1458 0.1449 0.1457 0.1447 0.1449 0.1437 0.1436 0.1409 0.1405 0.1392 

[TRAIN] Epoch[1](173/1500); Loss: 0.108457; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.1361 0.1245 0.1156 0.1110 0.1092 0.1063 0.1064 0.1103 0.1109 0.1124 0.1084 0.1000 0.0973 0.0956 0.0955 0.0958 

[TRAIN] Epoch[1](174/1500); Loss: 0.104110; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1312 0.1351 0.1157 0.1105 0.1080 0.1042 0.0982 0.0960 0.0951 0.0946 0.0950 0.0952 0.0960 0.0965 0.0970 0.0976 

[TRAIN] Epoch[1](175/1500); Loss: 0.098039; Backpropagation: 0.0920 sec; Batch: 0.4266 sec
0.1390 0.1158 0.1155 0.1107 0.1070 0.0990 0.0968 0.0923 0.0910 0.0858 0.0860 0.0858 0.0863 0.0860 0.0858 0.0858 

[TRAIN] Epoch[1](176/1500); Loss: 0.115159; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1531 0.1378 0.1310 0.1247 0.1216 0.1137 0.1117 0.1090 0.1088 0.1056 0.1049 0.1050 0.1045 0.1042 0.1037 0.1033 

[TRAIN] Epoch[1](177/1500); Loss: 0.150289; Backpropagation: 0.0920 sec; Batch: 0.4273 sec
0.1919 0.1729 0.1718 0.1659 0.1624 0.1533 0.1515 0.1439 0.1427 0.1368 0.1364 0.1341 0.1348 0.1351 0.1354 0.1355 

[TRAIN] Epoch[1](178/1500); Loss: 0.105470; Backpropagation: 0.0920 sec; Batch: 0.4269 sec
0.1375 0.1139 0.1153 0.1119 0.1102 0.1066 0.1038 0.0978 0.0976 0.0963 0.0968 0.0997 0.1003 0.1011 0.1002 0.0987 

[TRAIN] Epoch[1](179/1500); Loss: 0.104350; Backpropagation: 0.0917 sec; Batch: 0.4274 sec
0.1485 0.1452 0.1284 0.1216 0.1188 0.1089 0.1057 0.0960 0.0940 0.0867 0.0855 0.0849 0.0857 0.0876 0.0865 0.0856 

[TRAIN] Epoch[1](180/1500); Loss: 0.112915; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1393 0.1312 0.1245 0.1209 0.1187 0.1127 0.1108 0.1069 0.1063 0.1050 0.1053 0.1052 0.1051 0.1052 0.1048 0.1048 

[TRAIN] Epoch[1](181/1500); Loss: 0.157188; Backpropagation: 0.0921 sec; Batch: 0.4267 sec
0.1879 0.1793 0.1690 0.1594 0.1575 0.1539 0.1517 0.1534 0.1514 0.1514 0.1506 0.1503 0.1495 0.1494 0.1500 0.1504 

[TRAIN] Epoch[1](182/1500); Loss: 0.129750; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1813 0.1551 0.1475 0.1264 0.1240 0.1270 0.1250 0.1236 0.1206 0.1197 0.1201 0.1202 0.1207 0.1209 0.1216 0.1223 

[TRAIN] Epoch[1](183/1500); Loss: 0.079145; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.0967 0.0843 0.0793 0.0790 0.0821 0.0890 0.0828 0.0749 0.0751 0.0749 0.0736 0.0739 0.0743 0.0747 0.0755 0.0761 

[TRAIN] Epoch[1](184/1500); Loss: 0.090464; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1660 0.1292 0.1229 0.0984 0.0884 0.0730 0.0719 0.0761 0.0757 0.0759 0.0745 0.0760 0.0775 0.0790 0.0804 0.0826 

[TRAIN] Epoch[1](185/1500); Loss: 0.084035; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1052 0.1145 0.0925 0.0863 0.0852 0.0844 0.0824 0.0777 0.0763 0.0759 0.0764 0.0768 0.0760 0.0773 0.0784 0.0793 

[TRAIN] Epoch[1](186/1500); Loss: 0.146387; Backpropagation: 0.0918 sec; Batch: 0.4248 sec
0.1675 0.1622 0.1516 0.1484 0.1483 0.1476 0.1468 0.1474 0.1466 0.1414 0.1410 0.1400 0.1383 0.1386 0.1386 0.1377 

[TRAIN] Epoch[1](187/1500); Loss: 0.123847; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1836 0.1529 0.1553 0.1486 0.1457 0.1312 0.1290 0.1153 0.1129 0.1021 0.1006 0.1002 0.1009 0.1011 0.1010 0.1010 

[TRAIN] Epoch[1](188/1500); Loss: 0.131433; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1970 0.1592 0.1606 0.1508 0.1458 0.1289 0.1273 0.1229 0.1223 0.1205 0.1185 0.1142 0.1116 0.1097 0.1073 0.1063 

[TRAIN] Epoch[1](189/1500); Loss: 0.152423; Backpropagation: 0.0916 sec; Batch: 0.4573 sec
0.2010 0.1835 0.1759 0.1608 0.1570 0.1487 0.1429 0.1406 0.1403 0.1414 0.1398 0.1408 0.1405 0.1414 0.1419 0.1423 

[TRAIN] Epoch[1](190/1500); Loss: 0.099780; Backpropagation: 0.0921 sec; Batch: 0.4251 sec
0.1275 0.1222 0.1128 0.1117 0.1062 0.0975 0.0962 0.0928 0.0922 0.0918 0.0915 0.0916 0.0908 0.0900 0.0905 0.0912 

[TRAIN] Epoch[1](191/1500); Loss: 0.124212; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1406 0.1483 0.1297 0.1269 0.1252 0.1232 0.1232 0.1220 0.1212 0.1187 0.1183 0.1186 0.1173 0.1173 0.1183 0.1186 

[TRAIN] Epoch[1](192/1500); Loss: 0.099781; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1352 0.1204 0.1158 0.1083 0.1057 0.0999 0.0990 0.0942 0.0919 0.0892 0.0891 0.0896 0.0895 0.0894 0.0895 0.0898 

[TRAIN] Epoch[1](193/1500); Loss: 0.117059; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2050 0.1627 0.1614 0.1436 0.1391 0.1170 0.1116 0.0987 0.0957 0.0910 0.0886 0.0883 0.0896 0.0947 0.0940 0.0920 

[TRAIN] Epoch[1](194/1500); Loss: 0.106021; Backpropagation: 0.0916 sec; Batch: 0.4305 sec
0.1347 0.1295 0.1197 0.1143 0.1128 0.1063 0.1040 0.1000 0.0992 0.0978 0.0978 0.0976 0.0963 0.0952 0.0954 0.0956 

[TRAIN] Epoch[1](195/1500); Loss: 0.075392; Backpropagation: 0.0918 sec; Batch: 0.4296 sec
0.1079 0.1003 0.0877 0.0801 0.0775 0.0690 0.0681 0.0685 0.0679 0.0659 0.0652 0.0658 0.0673 0.0692 0.0716 0.0743 

[TRAIN] Epoch[1](196/1500); Loss: 0.119242; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1672 0.1438 0.1355 0.1261 0.1242 0.1158 0.1130 0.1121 0.1107 0.1111 0.1096 0.1075 0.1079 0.1081 0.1074 0.1079 

[TRAIN] Epoch[1](197/1500); Loss: 0.075130; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1149 0.1055 0.0930 0.0930 0.0909 0.0790 0.0748 0.0648 0.0632 0.0585 0.0588 0.0608 0.0615 0.0609 0.0611 0.0615 

[TRAIN] Epoch[1](198/1500); Loss: 0.103715; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1729 0.1521 0.1428 0.1325 0.1287 0.1075 0.1032 0.0900 0.0866 0.0813 0.0806 0.0774 0.0761 0.0758 0.0757 0.0763 

[TRAIN] Epoch[1](199/1500); Loss: 0.092290; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1862 0.1493 0.1293 0.0831 0.0781 0.0904 0.0863 0.0800 0.0788 0.0778 0.0758 0.0741 0.0727 0.0717 0.0714 0.0717 

[TRAIN] Epoch[1](200/1500); Loss: 0.084714; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1143 0.1127 0.0933 0.0872 0.0866 0.0847 0.0831 0.0795 0.0789 0.0774 0.0769 0.0756 0.0756 0.0761 0.0766 0.0770 

[TRAIN] Epoch[1](201/1500); Loss: 0.081884; Backpropagation: 0.0920 sec; Batch: 0.4250 sec
0.1304 0.1109 0.1050 0.0932 0.0908 0.0814 0.0785 0.0754 0.0731 0.0690 0.0675 0.0669 0.0665 0.0666 0.0671 0.0677 

[TRAIN] Epoch[1](202/1500); Loss: 0.099805; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1353 0.1451 0.1226 0.1083 0.1050 0.0969 0.0945 0.0923 0.0904 0.0879 0.0872 0.0863 0.0860 0.0859 0.0864 0.0867 

[TRAIN] Epoch[1](203/1500); Loss: 0.082296; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.1103 0.0912 0.0854 0.0861 0.0833 0.0837 0.0791 0.0765 0.0769 0.0783 0.0787 0.0772 0.0771 0.0776 0.0778 0.0776 

[TRAIN] Epoch[1](204/1500); Loss: 0.092136; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1367 0.1042 0.1034 0.1044 0.0985 0.0854 0.0846 0.0850 0.0853 0.0856 0.0860 0.0841 0.0843 0.0823 0.0821 0.0824 

[TRAIN] Epoch[1](205/1500); Loss: 0.103373; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1921 0.1594 0.1404 0.0990 0.0925 0.0888 0.0912 0.0933 0.0854 0.0842 0.0849 0.0865 0.0876 0.0882 0.0893 0.0910 

[TRAIN] Epoch[1](206/1500); Loss: 0.156416; Backpropagation: 0.0918 sec; Batch: 0.4257 sec
0.2219 0.2025 0.1901 0.1735 0.1693 0.1513 0.1468 0.1405 0.1391 0.1388 0.1381 0.1387 0.1387 0.1383 0.1377 0.1374 

[TRAIN] Epoch[1](207/1500); Loss: 0.116023; Backpropagation: 0.0918 sec; Batch: 0.4264 sec
0.1557 0.1384 0.1289 0.1271 0.1254 0.1172 0.1150 0.1104 0.1087 0.1064 0.1053 0.1044 0.1031 0.1032 0.1032 0.1038 

[TRAIN] Epoch[1](208/1500); Loss: 0.136620; Backpropagation: 0.0919 sec; Batch: 0.4277 sec
0.1793 0.1558 0.1498 0.1437 0.1420 0.1343 0.1337 0.1310 0.1304 0.1316 0.1302 0.1260 0.1249 0.1247 0.1244 0.1243 

[TRAIN] Epoch[1](209/1500); Loss: 0.184125; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2959 0.2655 0.2458 0.2016 0.1934 0.1589 0.1546 0.1634 0.1607 0.1579 0.1575 0.1573 0.1578 0.1581 0.1584 0.1591 

[TRAIN] Epoch[1](210/1500); Loss: 0.090149; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1857 0.1534 0.1435 0.1116 0.1056 0.0759 0.0727 0.0735 0.0709 0.0671 0.0657 0.0674 0.0646 0.0613 0.0617 0.0619 

[TRAIN] Epoch[1](211/1500); Loss: 0.090781; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1405 0.1299 0.1195 0.1075 0.1051 0.0923 0.0903 0.0841 0.0805 0.0738 0.0723 0.0726 0.0704 0.0712 0.0712 0.0713 

[TRAIN] Epoch[1](212/1500); Loss: 0.070301; Backpropagation: 0.0917 sec; Batch: 0.4250 sec
0.0968 0.0859 0.0717 0.0728 0.0767 0.0780 0.0680 0.0635 0.0626 0.0628 0.0633 0.0634 0.0649 0.0643 0.0647 0.0652 

[TRAIN] Epoch[1](213/1500); Loss: 0.095780; Backpropagation: 0.0918 sec; Batch: 0.4264 sec
0.1240 0.1297 0.1094 0.1003 0.0989 0.0939 0.0906 0.0872 0.0863 0.0874 0.0873 0.0864 0.0862 0.0875 0.0882 0.0892 

[TRAIN] Epoch[1](214/1500); Loss: 0.064778; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.0955 0.0725 0.0701 0.0635 0.0633 0.0641 0.0683 0.0683 0.0626 0.0584 0.0574 0.0575 0.0583 0.0584 0.0590 0.0592 

[TRAIN] Epoch[1](215/1500); Loss: 0.101349; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1655 0.1396 0.1299 0.1094 0.1071 0.0988 0.0957 0.0891 0.0875 0.0888 0.0880 0.0862 0.0850 0.0830 0.0837 0.0841 

[TRAIN] Epoch[1](216/1500); Loss: 0.058007; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.0662 0.1341 0.0427 0.0714 0.0558 0.0508 0.0459 0.0430 0.0488 0.0487 0.0509 0.0511 0.0526 0.0539 0.0549 0.0572 

[TRAIN] Epoch[1](217/1500); Loss: 0.063798; Backpropagation: 0.0918 sec; Batch: 0.4306 sec
0.1521 0.1020 0.0988 0.0711 0.0680 0.0543 0.0582 0.0687 0.0599 0.0462 0.0465 0.0396 0.0391 0.0392 0.0387 0.0384 

[TRAIN] Epoch[1](218/1500); Loss: 0.111926; Backpropagation: 0.0915 sec; Batch: 0.4552 sec
0.1286 0.1248 0.1169 0.1155 0.1168 0.1199 0.1179 0.1098 0.1084 0.1069 0.1065 0.1055 0.1046 0.1031 0.1029 0.1027 

[TRAIN] Epoch[1](219/1500); Loss: 0.119784; Backpropagation: 0.0917 sec; Batch: 0.4425 sec
0.1520 0.1366 0.1358 0.1299 0.1281 0.1226 0.1213 0.1162 0.1151 0.1115 0.1108 0.1081 0.1082 0.1072 0.1068 0.1064 

[TRAIN] Epoch[1](220/1500); Loss: 0.120934; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1446 0.1402 0.1349 0.1299 0.1283 0.1236 0.1218 0.1168 0.1164 0.1137 0.1134 0.1116 0.1114 0.1099 0.1093 0.1089 

[TRAIN] Epoch[1](221/1500); Loss: 0.114043; Backpropagation: 0.0919 sec; Batch: 0.4267 sec
0.1454 0.1378 0.1274 0.1207 0.1191 0.1152 0.1135 0.1096 0.1089 0.1068 0.1061 0.1040 0.1038 0.1028 0.1025 0.1012 

[TRAIN] Epoch[1](222/1500); Loss: 0.120157; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1422 0.1299 0.1270 0.1234 0.1224 0.1209 0.1197 0.1187 0.1176 0.1161 0.1152 0.1146 0.1144 0.1137 0.1134 0.1134 

[TRAIN] Epoch[1](223/1500); Loss: 0.129062; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1713 0.1455 0.1514 0.1439 0.1397 0.1346 0.1316 0.1278 0.1249 0.1216 0.1188 0.1153 0.1126 0.1103 0.1087 0.1070 

[TRAIN] Epoch[1](224/1500); Loss: 0.106152; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.1224 0.1175 0.1138 0.1096 0.1077 0.1046 0.1041 0.1034 0.1026 0.1022 0.1021 0.1016 0.1015 0.1016 0.1018 0.1020 

[TRAIN] Epoch[1](225/1500); Loss: 0.084952; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1000 0.0858 0.0912 0.0887 0.0870 0.0856 0.0846 0.0836 0.0828 0.0822 0.0818 0.0814 0.0812 0.0812 0.0810 0.0812 

[TRAIN] Epoch[1](226/1500); Loss: 0.129267; Backpropagation: 0.0918 sec; Batch: 0.4269 sec
0.1470 0.1461 0.1366 0.1331 0.1317 0.1301 0.1289 0.1276 0.1265 0.1254 0.1244 0.1236 0.1228 0.1221 0.1215 0.1209 

[TRAIN] Epoch[1](227/1500); Loss: 0.131768; Backpropagation: 0.0919 sec; Batch: 0.4273 sec
0.1548 0.1439 0.1371 0.1345 0.1333 0.1322 0.1309 0.1297 0.1289 0.1281 0.1272 0.1265 0.1259 0.1255 0.1251 0.1248 

[TRAIN] Epoch[1](228/1500); Loss: 0.145133; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1636 0.1579 0.1527 0.1479 0.1469 0.1448 0.1437 0.1425 0.1417 0.1410 0.1405 0.1401 0.1397 0.1398 0.1396 0.1397 

[TRAIN] Epoch[1](229/1500); Loss: 0.176707; Backpropagation: 0.0917 sec; Batch: 0.4253 sec
0.1932 0.1794 0.1830 0.1812 0.1796 0.1784 0.1772 0.1761 0.1751 0.1742 0.1733 0.1726 0.1719 0.1713 0.1707 0.1702 

[TRAIN] Epoch[1](230/1500); Loss: 0.169602; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1845 0.1763 0.1757 0.1725 0.1715 0.1701 0.1693 0.1685 0.1677 0.1670 0.1664 0.1657 0.1652 0.1647 0.1644 0.1641 

[TRAIN] Epoch[1](231/1500); Loss: 0.095746; Backpropagation: 0.0918 sec; Batch: 0.4270 sec
0.1032 0.1066 0.0980 0.0962 0.0954 0.0947 0.0941 0.0936 0.0935 0.0934 0.0933 0.0934 0.0937 0.0940 0.0943 0.0944 

[TRAIN] Epoch[1](232/1500); Loss: 0.165703; Backpropagation: 0.0918 sec; Batch: 0.4305 sec
0.1784 0.1717 0.1697 0.1678 0.1670 0.1663 0.1654 0.1645 0.1639 0.1632 0.1628 0.1624 0.1622 0.1621 0.1619 0.1619 

[TRAIN] Epoch[1](233/1500); Loss: 0.169437; Backpropagation: 0.0917 sec; Batch: 0.4586 sec
0.1925 0.1758 0.1748 0.1718 0.1709 0.1697 0.1688 0.1677 0.1669 0.1662 0.1657 0.1651 0.1645 0.1640 0.1635 0.1632 

[TRAIN] Epoch[1](234/1500); Loss: 0.157020; Backpropagation: 0.0918 sec; Batch: 0.4276 sec
0.1644 0.1462 0.1551 0.1569 0.1556 0.1561 0.1561 0.1563 0.1566 0.1570 0.1574 0.1578 0.1583 0.1589 0.1595 0.1602 

[TRAIN] Epoch[1](235/1500); Loss: 0.266981; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.3119 0.2905 0.2850 0.2749 0.2736 0.2694 0.2674 0.2648 0.2624 0.2600 0.2577 0.2553 0.2530 0.2507 0.2486 0.2466 

[TRAIN] Epoch[1](236/1500); Loss: 0.102982; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1042 0.1097 0.1048 0.1029 0.1024 0.1021 0.1018 0.1016 0.1016 0.1016 0.1017 0.1019 0.1022 0.1026 0.1030 0.1035 

[TRAIN] Epoch[1](237/1500); Loss: 0.142150; Backpropagation: 0.0917 sec; Batch: 0.4426 sec
0.1619 0.1534 0.1495 0.1468 0.1458 0.1438 0.1424 0.1411 0.1399 0.1387 0.1375 0.1365 0.1356 0.1346 0.1338 0.1331 

[TRAIN] Epoch[1](238/1500); Loss: 0.159623; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1723 0.1629 0.1626 0.1604 0.1594 0.1591 0.1586 0.1583 0.1580 0.1576 0.1575 0.1574 0.1574 0.1574 0.1575 0.1576 

[TRAIN] Epoch[1](239/1500); Loss: 0.184398; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1990 0.1787 0.1882 0.1875 0.1861 0.1856 0.1849 0.1843 0.1836 0.1831 0.1826 0.1821 0.1817 0.1814 0.1810 0.1807 

[TRAIN] Epoch[1](240/1500); Loss: 0.193001; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2098 0.1816 0.1953 0.1942 0.1932 0.1931 0.1929 0.1927 0.1925 0.1923 0.1921 0.1919 0.1918 0.1917 0.1915 0.1914 

[TRAIN] Epoch[1](241/1500); Loss: 0.171784; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1881 0.1650 0.1775 0.1762 0.1747 0.1740 0.1729 0.1720 0.1711 0.1703 0.1695 0.1688 0.1681 0.1674 0.1668 0.1662 

[TRAIN] Epoch[1](242/1500); Loss: 0.114364; Backpropagation: 0.0915 sec; Batch: 0.4515 sec
0.1368 0.1208 0.1262 0.1219 0.1188 0.1169 0.1151 0.1134 0.1118 0.1102 0.1088 0.1076 0.1066 0.1056 0.1048 0.1043 

[TRAIN] Epoch[1](243/1500); Loss: 0.078249; Backpropagation: 0.0918 sec; Batch: 0.4371 sec
0.0899 0.0933 0.0787 0.0762 0.0771 0.0761 0.0754 0.0750 0.0748 0.0749 0.0751 0.0756 0.0762 0.0769 0.0779 0.0789 

[TRAIN] Epoch[1](244/1500); Loss: 0.155047; Backpropagation: 0.0918 sec; Batch: 0.4323 sec
0.1739 0.1681 0.1605 0.1574 0.1560 0.1550 0.1539 0.1532 0.1524 0.1517 0.1510 0.1505 0.1499 0.1495 0.1491 0.1487 

[TRAIN] Epoch[1](245/1500); Loss: 0.110613; Backpropagation: 0.0918 sec; Batch: 0.4277 sec
0.1227 0.1228 0.1170 0.1145 0.1118 0.1102 0.1092 0.1085 0.1079 0.1075 0.1069 0.1064 0.1062 0.1061 0.1060 0.1060 

[TRAIN] Epoch[1](246/1500); Loss: 0.105985; Backpropagation: 0.0916 sec; Batch: 0.4248 sec
0.1273 0.1143 0.1103 0.1058 0.1052 0.1042 0.1032 0.1024 0.1022 0.1022 0.1022 0.1024 0.1027 0.1032 0.1037 0.1044 

[TRAIN] Epoch[1](247/1500); Loss: 0.202395; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2544 0.2294 0.2176 0.2061 0.2049 0.2013 0.1998 0.1979 0.1962 0.1944 0.1928 0.1913 0.1899 0.1886 0.1873 0.1862 

[TRAIN] Epoch[1](248/1500); Loss: 0.073448; Backpropagation: 0.0917 sec; Batch: 0.4500 sec
0.0866 0.0937 0.0797 0.0772 0.0752 0.0732 0.0720 0.0710 0.0700 0.0691 0.0687 0.0682 0.0677 0.0676 0.0676 0.0677 

[TRAIN] Epoch[1](249/1500); Loss: 0.159166; Backpropagation: 0.0919 sec; Batch: 0.4273 sec
0.1827 0.1764 0.1647 0.1613 0.1609 0.1591 0.1571 0.1557 0.1548 0.1538 0.1533 0.1532 0.1532 0.1532 0.1535 0.1539 

[TRAIN] Epoch[1](250/1500); Loss: 0.117130; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1365 0.1311 0.1238 0.1193 0.1179 0.1163 0.1152 0.1143 0.1135 0.1131 0.1124 0.1123 0.1122 0.1120 0.1120 0.1122 

[TRAIN] Epoch[1](251/1500); Loss: 0.077831; Backpropagation: 0.0918 sec; Batch: 0.4262 sec
0.0931 0.0807 0.0806 0.0788 0.0780 0.0773 0.0763 0.0759 0.0753 0.0749 0.0749 0.0750 0.0753 0.0758 0.0764 0.0771 

[TRAIN] Epoch[1](252/1500); Loss: 0.172501; Backpropagation: 0.0917 sec; Batch: 0.4276 sec
0.1925 0.1830 0.1789 0.1755 0.1743 0.1728 0.1716 0.1707 0.1697 0.1691 0.1683 0.1675 0.1669 0.1667 0.1664 0.1661 

[TRAIN] Epoch[1](253/1500); Loss: 0.227004; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.3028 0.2743 0.2549 0.2354 0.2323 0.2258 0.2240 0.2206 0.2178 0.2146 0.2110 0.2082 0.2056 0.2033 0.2015 0.2000 

[TRAIN] Epoch[1](254/1500); Loss: 0.179858; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.2160 0.2016 0.1919 0.1830 0.1818 0.1791 0.1776 0.1761 0.1748 0.1736 0.1726 0.1716 0.1707 0.1699 0.1691 0.1684 

[TRAIN] Epoch[1](255/1500); Loss: 0.110332; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1369 0.1451 0.1229 0.1165 0.1132 0.1097 0.1071 0.1053 0.1041 0.1028 0.1018 0.1011 0.1005 0.1000 0.0995 0.0990 

[TRAIN] Epoch[1](256/1500); Loss: 0.090471; Backpropagation: 0.0916 sec; Batch: 0.4421 sec
0.1360 0.1160 0.1062 0.0928 0.0908 0.0873 0.0857 0.0838 0.0824 0.0812 0.0804 0.0801 0.0802 0.0806 0.0815 0.0826 

[TRAIN] Epoch[1](257/1500); Loss: 0.085058; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1168 0.0984 0.0910 0.0862 0.0844 0.0824 0.0806 0.0800 0.0796 0.0794 0.0794 0.0795 0.0800 0.0804 0.0811 0.0818 

[TRAIN] Epoch[1](258/1500); Loss: 0.111629; Backpropagation: 0.0917 sec; Batch: 0.4276 sec
0.1306 0.1209 0.1165 0.1121 0.1113 0.1101 0.1095 0.1090 0.1085 0.1081 0.1080 0.1080 0.1080 0.1082 0.1085 0.1088 

[TRAIN] Epoch[1](259/1500); Loss: 0.082177; Backpropagation: 0.0918 sec; Batch: 0.4272 sec
0.1149 0.1052 0.0896 0.0867 0.0839 0.0795 0.0771 0.0764 0.0757 0.0750 0.0748 0.0747 0.0749 0.0751 0.0755 0.0759 

[TRAIN] Epoch[1](260/1500); Loss: 0.142891; Backpropagation: 0.0916 sec; Batch: 0.4271 sec
0.1929 0.1798 0.1682 0.1487 0.1445 0.1403 0.1388 0.1365 0.1346 0.1329 0.1313 0.1298 0.1285 0.1274 0.1264 0.1255 

[TRAIN] Epoch[1](261/1500); Loss: 0.145818; Backpropagation: 0.0917 sec; Batch: 0.4665 sec
0.1791 0.1638 0.1531 0.1463 0.1449 0.1439 0.1431 0.1420 0.1409 0.1404 0.1400 0.1397 0.1392 0.1390 0.1388 0.1388 

[TRAIN] Epoch[1](262/1500); Loss: 0.130252; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1902 0.1708 0.1597 0.1367 0.1313 0.1271 0.1256 0.1233 0.1212 0.1193 0.1172 0.1153 0.1137 0.1121 0.1108 0.1097 

[TRAIN] Epoch[1](263/1500); Loss: 0.154286; Backpropagation: 0.0917 sec; Batch: 0.4629 sec
0.1982 0.1831 0.1718 0.1581 0.1544 0.1517 0.1503 0.1488 0.1476 0.1465 0.1455 0.1444 0.1434 0.1423 0.1415 0.1408 

[TRAIN] Epoch[1](264/1500); Loss: 0.107157; Backpropagation: 0.0916 sec; Batch: 0.4581 sec
0.1316 0.1229 0.1116 0.1111 0.1114 0.1084 0.1051 0.1029 0.1018 0.1014 0.1010 0.1010 0.1007 0.1008 0.1011 0.1015 

[TRAIN] Epoch[1](265/1500); Loss: 0.149834; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1736 0.1609 0.1562 0.1499 0.1490 0.1485 0.1477 0.1468 0.1466 0.1463 0.1458 0.1457 0.1453 0.1450 0.1451 0.1451 

[TRAIN] Epoch[1](266/1500); Loss: 0.158679; Backpropagation: 0.0916 sec; Batch: 0.4267 sec
0.1776 0.1682 0.1643 0.1589 0.1576 0.1567 0.1562 0.1557 0.1555 0.1553 0.1552 0.1551 0.1553 0.1555 0.1558 0.1561 

[TRAIN] Epoch[1](267/1500); Loss: 0.131731; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1572 0.1380 0.1428 0.1414 0.1388 0.1363 0.1338 0.1317 0.1297 0.1278 0.1259 0.1241 0.1224 0.1207 0.1192 0.1178 

[TRAIN] Epoch[1](268/1500); Loss: 0.143171; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.1970 0.1697 0.1560 0.1474 0.1437 0.1413 0.1382 0.1364 0.1352 0.1340 0.1329 0.1324 0.1321 0.1317 0.1315 0.1313 

[TRAIN] Epoch[1](269/1500); Loss: 0.148200; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2105 0.1969 0.1758 0.1547 0.1480 0.1427 0.1410 0.1384 0.1367 0.1354 0.1343 0.1332 0.1321 0.1312 0.1305 0.1298 

[TRAIN] Epoch[1](270/1500); Loss: 0.149378; Backpropagation: 0.0916 sec; Batch: 0.4226 sec
0.3335 0.2909 0.2585 0.1667 0.1377 0.1102 0.1086 0.1046 0.1029 0.1041 0.1055 0.1077 0.1102 0.1130 0.1161 0.1199 

[TRAIN] Epoch[1](271/1500); Loss: 0.071790; Backpropagation: 0.0919 sec; Batch: 0.4252 sec
0.1043 0.0979 0.0779 0.0905 0.0851 0.0697 0.0671 0.0638 0.0631 0.0615 0.0612 0.0611 0.0610 0.0611 0.0614 0.0618 

[TRAIN] Epoch[1](272/1500); Loss: 0.100790; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1936 0.1625 0.1407 0.0951 0.0904 0.0882 0.0886 0.0868 0.0848 0.0838 0.0825 0.0814 0.0819 0.0830 0.0839 0.0855 

[TRAIN] Epoch[1](273/1500); Loss: 0.085910; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1042 0.0919 0.0910 0.0894 0.0877 0.0862 0.0849 0.0837 0.0828 0.0821 0.0817 0.0815 0.0814 0.0816 0.0820 0.0824 

[TRAIN] Epoch[1](274/1500); Loss: 0.084174; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1113 0.0985 0.0917 0.0837 0.0871 0.0861 0.0850 0.0812 0.0798 0.0785 0.0780 0.0772 0.0769 0.0772 0.0772 0.0772 

[TRAIN] Epoch[1](275/1500); Loss: 0.139369; Backpropagation: 0.0919 sec; Batch: 0.4281 sec
0.2185 0.1937 0.1664 0.1423 0.1365 0.1338 0.1286 0.1272 0.1259 0.1240 0.1224 0.1220 0.1218 0.1219 0.1222 0.1227 

[TRAIN] Epoch[1](276/1500); Loss: 0.093435; Backpropagation: 0.0919 sec; Batch: 0.4265 sec
0.1176 0.1121 0.0959 0.0921 0.0909 0.0911 0.0900 0.0885 0.0885 0.0885 0.0884 0.0890 0.0897 0.0902 0.0910 0.0917 

[TRAIN] Epoch[1](277/1500); Loss: 0.110177; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1494 0.1319 0.1254 0.1163 0.1168 0.1107 0.1080 0.1040 0.1028 0.1014 0.1005 0.1000 0.0994 0.0989 0.0988 0.0987 

[TRAIN] Epoch[1](278/1500); Loss: 0.149105; Backpropagation: 0.0917 sec; Batch: 0.4268 sec
0.2096 0.1972 0.1889 0.1644 0.1545 0.1428 0.1408 0.1381 0.1363 0.1344 0.1328 0.1313 0.1300 0.1289 0.1281 0.1275 

[TRAIN] Epoch[1](279/1500); Loss: 0.127028; Backpropagation: 0.0917 sec; Batch: 0.4313 sec
0.1929 0.1726 0.1534 0.1333 0.1266 0.1191 0.1168 0.1151 0.1142 0.1134 0.1129 0.1124 0.1123 0.1123 0.1124 0.1126 

[TRAIN] Epoch[1](280/1500); Loss: 0.119479; Backpropagation: 0.0919 sec; Batch: 0.4309 sec
0.1491 0.1344 0.1231 0.1208 0.1316 0.1304 0.1263 0.1168 0.1143 0.1123 0.1103 0.1089 0.1085 0.1081 0.1082 0.1085 

[TRAIN] Epoch[1](281/1500); Loss: 0.135905; Backpropagation: 0.0918 sec; Batch: 0.4275 sec
0.1443 0.1355 0.1308 0.1439 0.1534 0.1536 0.1452 0.1342 0.1325 0.1305 0.1295 0.1288 0.1284 0.1282 0.1280 0.1278 

[TRAIN] Epoch[1](282/1500); Loss: 0.082396; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2013 0.1782 0.1610 0.0853 0.0570 0.0500 0.0544 0.0646 0.0681 0.0703 0.0626 0.0544 0.0535 0.0527 0.0525 0.0524 

[TRAIN] Epoch[1](283/1500); Loss: 0.085208; Backpropagation: 0.0919 sec; Batch: 0.4262 sec
0.1144 0.1037 0.0927 0.0876 0.0862 0.0846 0.0829 0.0818 0.0808 0.0799 0.0791 0.0787 0.0781 0.0776 0.0775 0.0777 

[TRAIN] Epoch[1](284/1500); Loss: 0.082401; Backpropagation: 0.0919 sec; Batch: 0.4283 sec
0.1350 0.1162 0.1096 0.0893 0.0863 0.0784 0.0739 0.0714 0.0691 0.0682 0.0686 0.0688 0.0692 0.0702 0.0714 0.0729 

[TRAIN] Epoch[1](285/1500); Loss: 0.100961; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1129 0.1131 0.1044 0.1101 0.1080 0.1032 0.1018 0.0993 0.0962 0.0953 0.0950 0.0951 0.0951 0.0951 0.0953 0.0956 

[TRAIN] Epoch[1](286/1500); Loss: 0.124375; Backpropagation: 0.0921 sec; Batch: 0.4255 sec
0.1392 0.1370 0.1280 0.1269 0.1265 0.1250 0.1234 0.1216 0.1212 0.1209 0.1204 0.1200 0.1198 0.1199 0.1200 0.1202 

[TRAIN] Epoch[1](287/1500); Loss: 0.136908; Backpropagation: 0.0917 sec; Batch: 0.4307 sec
0.1859 0.1851 0.1635 0.1444 0.1380 0.1323 0.1301 0.1281 0.1262 0.1245 0.1234 0.1226 0.1221 0.1216 0.1214 0.1214 

[TRAIN] Epoch[1](288/1500); Loss: 0.127232; Backpropagation: 0.0917 sec; Batch: 0.4277 sec
0.1910 0.1608 0.1442 0.1270 0.1249 0.1224 0.1203 0.1136 0.1119 0.1119 0.1137 0.1151 0.1166 0.1183 0.1206 0.1234 

[TRAIN] Epoch[1](289/1500); Loss: 0.139337; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1977 0.1951 0.1706 0.1528 0.1483 0.1409 0.1278 0.1237 0.1219 0.1220 0.1215 0.1212 0.1214 0.1214 0.1215 0.1216 

[TRAIN] Epoch[1](290/1500); Loss: 0.154256; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.1983 0.1901 0.1707 0.1622 0.1608 0.1520 0.1479 0.1445 0.1435 0.1432 0.1427 0.1423 0.1423 0.1423 0.1425 0.1429 

[TRAIN] Epoch[1](291/1500); Loss: 0.127920; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1657 0.1544 0.1421 0.1339 0.1306 0.1245 0.1218 0.1193 0.1187 0.1184 0.1188 0.1190 0.1194 0.1196 0.1201 0.1206 

[TRAIN] Epoch[1](292/1500); Loss: 0.145507; Backpropagation: 0.0920 sec; Batch: 0.4271 sec
0.2008 0.1915 0.1708 0.1484 0.1420 0.1389 0.1376 0.1357 0.1350 0.1342 0.1333 0.1331 0.1325 0.1318 0.1315 0.1311 

[TRAIN] Epoch[1](293/1500); Loss: 0.121878; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1635 0.1417 0.1263 0.1191 0.1165 0.1139 0.1125 0.1123 0.1122 0.1132 0.1144 0.1162 0.1183 0.1205 0.1232 0.1263 

[TRAIN] Epoch[1](294/1500); Loss: 0.063510; Backpropagation: 0.0916 sec; Batch: 0.4306 sec
0.0927 0.0835 0.0804 0.0785 0.0745 0.0666 0.0630 0.0576 0.0559 0.0537 0.0527 0.0519 0.0514 0.0512 0.0513 0.0514 

[TRAIN] Epoch[1](295/1500); Loss: 0.106643; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1226 0.1172 0.1066 0.1194 0.1243 0.1143 0.1059 0.0996 0.0994 0.0988 0.0989 0.0989 0.0992 0.0998 0.1003 0.1008 

[TRAIN] Epoch[1](296/1500); Loss: 0.117707; Backpropagation: 0.0992 sec; Batch: 0.4362 sec
0.1469 0.1342 0.1311 0.1243 0.1234 0.1198 0.1171 0.1143 0.1121 0.1110 0.1097 0.1090 0.1082 0.1076 0.1073 0.1072 

[TRAIN] Epoch[1](297/1500); Loss: 0.107105; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1228 0.1136 0.1169 0.1254 0.1228 0.1112 0.1070 0.1054 0.1034 0.1015 0.0999 0.0986 0.0975 0.0966 0.0958 0.0952 

[TRAIN] Epoch[1](298/1500); Loss: 0.110798; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1355 0.1479 0.1219 0.1125 0.1103 0.1076 0.1060 0.1053 0.1047 0.1041 0.1036 0.1032 0.1029 0.1026 0.1024 0.1023 

[TRAIN] Epoch[1](299/1500); Loss: 0.117449; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1438 0.1327 0.1282 0.1224 0.1220 0.1188 0.1158 0.1141 0.1126 0.1116 0.1107 0.1100 0.1096 0.1092 0.1089 0.1087 

[TRAIN] Epoch[1](300/1500); Loss: 0.128115; Backpropagation: 0.0918 sec; Batch: 0.4249 sec
0.1654 0.1745 0.1467 0.1322 0.1282 0.1251 0.1229 0.1213 0.1198 0.1185 0.1175 0.1167 0.1160 0.1154 0.1150 0.1148 

[TRAIN] Epoch[1](301/1500); Loss: 0.116391; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1715 0.1480 0.1427 0.1270 0.1194 0.1127 0.1099 0.1080 0.1063 0.1049 0.1038 0.1027 0.1020 0.1015 0.1010 0.1009 

[TRAIN] Epoch[1](302/1500); Loss: 0.152962; Backpropagation: 0.0918 sec; Batch: 0.4250 sec
0.1861 0.1840 0.1690 0.1600 0.1544 0.1513 0.1494 0.1476 0.1462 0.1449 0.1440 0.1433 0.1426 0.1420 0.1415 0.1411 

[TRAIN] Epoch[1](303/1500); Loss: 0.050799; Backpropagation: 0.0921 sec; Batch: 0.4272 sec
0.0746 0.1369 0.0399 0.0417 0.0455 0.0436 0.0430 0.0423 0.0415 0.0415 0.0418 0.0421 0.0429 0.0438 0.0452 0.0464 

[TRAIN] Epoch[1](304/1500); Loss: 0.136301; Backpropagation: 0.0922 sec; Batch: 0.4232 sec
0.1680 0.1547 0.1484 0.1450 0.1422 0.1393 0.1371 0.1348 0.1327 0.1306 0.1288 0.1267 0.1252 0.1238 0.1224 0.1211 

[TRAIN] Epoch[1](305/1500); Loss: 0.083326; Backpropagation: 0.0917 sec; Batch: 0.4250 sec
0.1217 0.0921 0.0984 0.0958 0.0917 0.0882 0.0849 0.0821 0.0792 0.0765 0.0743 0.0724 0.0707 0.0694 0.0683 0.0675 

[TRAIN] Epoch[1](306/1500); Loss: 0.112031; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1408 0.1371 0.1236 0.1179 0.1129 0.1093 0.1081 0.1073 0.1061 0.1055 0.1050 0.1043 0.1041 0.1038 0.1034 0.1033 

[TRAIN] Epoch[1](307/1500); Loss: 0.108913; Backpropagation: 0.0919 sec; Batch: 0.4261 sec
0.1598 0.1514 0.1322 0.1136 0.1061 0.1046 0.1028 0.1013 0.0999 0.0986 0.0975 0.0965 0.0956 0.0948 0.0942 0.0938 

[TRAIN] Epoch[1](308/1500); Loss: 0.138546; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1728 0.1652 0.1480 0.1455 0.1482 0.1353 0.1307 0.1308 0.1303 0.1301 0.1300 0.1299 0.1300 0.1300 0.1299 0.1301 

[TRAIN] Epoch[1](309/1500); Loss: 0.091590; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1057 0.1087 0.0996 0.0953 0.0930 0.0910 0.0895 0.0883 0.0871 0.0867 0.0865 0.0865 0.0865 0.0866 0.0869 0.0872 

[TRAIN] Epoch[1](310/1500); Loss: 0.121150; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1717 0.1524 0.1337 0.1287 0.1253 0.1208 0.1178 0.1154 0.1132 0.1112 0.1107 0.1096 0.1085 0.1073 0.1070 0.1052 

[TRAIN] Epoch[1](311/1500); Loss: 0.069204; Backpropagation: 0.0921 sec; Batch: 0.4263 sec
0.1199 0.1025 0.0869 0.0583 0.0667 0.0688 0.0655 0.0620 0.0605 0.0600 0.0597 0.0593 0.0592 0.0592 0.0594 0.0594 

[TRAIN] Epoch[1](312/1500); Loss: 0.140653; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1607 0.1544 0.1504 0.1464 0.1438 0.1412 0.1388 0.1375 0.1362 0.1352 0.1348 0.1343 0.1342 0.1341 0.1342 0.1343 

[TRAIN] Epoch[1](313/1500); Loss: 0.137613; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1759 0.2041 0.1646 0.1500 0.1486 0.1415 0.1330 0.1287 0.1249 0.1220 0.1206 0.1191 0.1181 0.1176 0.1169 0.1164 

[TRAIN] Epoch[1](314/1500); Loss: 0.096799; Backpropagation: 0.0916 sec; Batch: 0.4588 sec
0.1394 0.1147 0.1131 0.1071 0.1025 0.0984 0.0950 0.0919 0.0897 0.0880 0.0864 0.0855 0.0849 0.0847 0.0843 0.0834 

[TRAIN] Epoch[1](315/1500); Loss: 0.147450; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1695 0.1746 0.1606 0.1533 0.1521 0.1498 0.1450 0.1440 0.1429 0.1415 0.1398 0.1385 0.1373 0.1369 0.1368 0.1367 

[TRAIN] Epoch[1](316/1500); Loss: 0.142535; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1604 0.1706 0.1498 0.1450 0.1447 0.1429 0.1404 0.1394 0.1384 0.1367 0.1360 0.1356 0.1355 0.1352 0.1351 0.1352 

[TRAIN] Epoch[1](317/1500); Loss: 0.105861; Backpropagation: 0.0918 sec; Batch: 0.4600 sec
0.1496 0.1453 0.1190 0.1127 0.1112 0.1036 0.0981 0.0952 0.0939 0.0934 0.0937 0.0942 0.0948 0.0955 0.0963 0.0971 

[TRAIN] Epoch[1](318/1500); Loss: 0.107832; Backpropagation: 0.0920 sec; Batch: 0.4316 sec
0.1262 0.1235 0.1122 0.1215 0.1201 0.1081 0.1039 0.1017 0.1005 0.1001 0.1002 0.1006 0.1011 0.1015 0.1019 0.1023 

[TRAIN] Epoch[1](319/1500); Loss: 0.070064; Backpropagation: 0.0918 sec; Batch: 0.4619 sec
0.0918 0.0801 0.0781 0.0753 0.0715 0.0696 0.0681 0.0668 0.0658 0.0652 0.0647 0.0645 0.0645 0.0647 0.0650 0.0655 

[TRAIN] Epoch[1](320/1500); Loss: 0.069587; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0998 0.0910 0.0755 0.0741 0.0706 0.0693 0.0676 0.0658 0.0642 0.0631 0.0623 0.0618 0.0617 0.0619 0.0621 0.0625 

[TRAIN] Epoch[1](321/1500); Loss: 0.161908; Backpropagation: 0.0919 sec; Batch: 0.4259 sec
0.2053 0.2014 0.1715 0.1666 0.1626 0.1563 0.1554 0.1544 0.1531 0.1528 0.1524 0.1517 0.1517 0.1516 0.1517 0.1521 

[TRAIN] Epoch[1](322/1500); Loss: 0.119150; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1617 0.1514 0.1388 0.1213 0.1159 0.1132 0.1122 0.1109 0.1102 0.1095 0.1092 0.1094 0.1097 0.1102 0.1110 0.1118 

[TRAIN] Epoch[1](323/1500); Loss: 0.120450; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1473 0.1521 0.1312 0.1248 0.1212 0.1173 0.1149 0.1133 0.1123 0.1121 0.1123 0.1124 0.1129 0.1135 0.1143 0.1152 

[TRAIN] Epoch[1](324/1500); Loss: 0.100013; Backpropagation: 0.0919 sec; Batch: 0.4279 sec
0.2083 0.2586 0.1813 0.1242 0.1169 0.0922 0.0673 0.0620 0.0591 0.0584 0.0586 0.0592 0.0608 0.0625 0.0642 0.0665 

[TRAIN] Epoch[1](325/1500); Loss: 0.190819; Backpropagation: 0.0920 sec; Batch: 0.4275 sec
0.2579 0.2591 0.2340 0.2078 0.2007 0.1912 0.1832 0.1782 0.1749 0.1720 0.1700 0.1681 0.1662 0.1648 0.1632 0.1619 

[TRAIN] Epoch[1](326/1500); Loss: 0.105650; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1272 0.1255 0.1171 0.1122 0.1109 0.1077 0.1038 0.1020 0.1000 0.0984 0.0977 0.0977 0.0975 0.0974 0.0975 0.0977 

[TRAIN] Epoch[1](327/1500); Loss: 0.127543; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.1629 0.1612 0.1391 0.1358 0.1322 0.1267 0.1223 0.1202 0.1188 0.1177 0.1171 0.1171 0.1170 0.1172 0.1173 0.1179 

[TRAIN] Epoch[1](328/1500); Loss: 0.165906; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1847 0.1851 0.1716 0.1682 0.1678 0.1650 0.1624 0.1616 0.1611 0.1607 0.1606 0.1606 0.1611 0.1613 0.1614 0.1614 

[TRAIN] Epoch[1](329/1500); Loss: 0.063492; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0874 0.0838 0.0734 0.0738 0.0730 0.0696 0.0625 0.0577 0.0558 0.0551 0.0542 0.0537 0.0536 0.0537 0.0539 0.0546 

[TRAIN] Epoch[1](330/1500); Loss: 0.106379; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1298 0.1194 0.1157 0.1130 0.1097 0.1070 0.1046 0.1025 0.1011 0.1002 0.0998 0.0996 0.0996 0.0997 0.0999 0.1002 

[TRAIN] Epoch[1](331/1500); Loss: 0.077637; Backpropagation: 0.0920 sec; Batch: 0.4273 sec
0.0920 0.0991 0.0852 0.0808 0.0790 0.0775 0.0761 0.0745 0.0733 0.0723 0.0718 0.0715 0.0715 0.0718 0.0725 0.0731 

[TRAIN] Epoch[1](332/1500); Loss: 0.122014; Backpropagation: 0.0918 sec; Batch: 0.4272 sec
0.1477 0.1474 0.1364 0.1300 0.1259 0.1227 0.1197 0.1174 0.1157 0.1142 0.1134 0.1129 0.1123 0.1121 0.1120 0.1123 

[TRAIN] Epoch[1](333/1500); Loss: 0.114987; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1780 0.1643 0.1072 0.1086 0.1043 0.1015 0.1007 0.1012 0.1026 0.1038 0.1055 0.1072 0.1097 0.1123 0.1149 0.1180 

[TRAIN] Epoch[1](334/1500); Loss: 0.136390; Backpropagation: 0.0920 sec; Batch: 0.4227 sec
0.1682 0.1645 0.1557 0.1511 0.1455 0.1388 0.1344 0.1317 0.1301 0.1279 0.1254 0.1234 0.1222 0.1216 0.1209 0.1208 

[TRAIN] Epoch[1](335/1500); Loss: 0.093891; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1311 0.1496 0.1212 0.1058 0.1041 0.0981 0.0879 0.0838 0.0807 0.0786 0.0771 0.0763 0.0763 0.0766 0.0774 0.0776 

[TRAIN] Epoch[1](336/1500); Loss: 0.079077; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0864 0.0841 0.0817 0.0803 0.0787 0.0772 0.0756 0.0746 0.0739 0.0747 0.0758 0.0773 0.0791 0.0808 0.0821 0.0830 

[TRAIN] Epoch[1](337/1500); Loss: 0.050343; Backpropagation: 0.0918 sec; Batch: 0.4302 sec
0.0607 0.0610 0.0628 0.0870 0.0744 0.0561 0.0487 0.0425 0.0401 0.0382 0.0378 0.0381 0.0384 0.0390 0.0402 0.0405 

[TRAIN] Epoch[1](338/1500); Loss: 0.218828; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.3014 0.2823 0.2406 0.2320 0.2224 0.2138 0.2106 0.2056 0.2020 0.2004 0.1996 0.1989 0.1986 0.1981 0.1975 0.1974 

[TRAIN] Epoch[1](339/1500); Loss: 0.147551; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2106 0.2388 0.2038 0.1775 0.1728 0.1625 0.1469 0.1343 0.1266 0.1211 0.1166 0.1134 0.1105 0.1099 0.1086 0.1068 

[TRAIN] Epoch[1](340/1500); Loss: 0.095754; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1580 0.1812 0.1387 0.1140 0.1105 0.0990 0.0870 0.0806 0.0756 0.0728 0.0707 0.0692 0.0686 0.0686 0.0685 0.0690 

[TRAIN] Epoch[1](341/1500); Loss: 0.093641; Backpropagation: 0.0919 sec; Batch: 0.4302 sec
0.1386 0.1533 0.1274 0.1120 0.1035 0.0920 0.0856 0.0818 0.0786 0.0772 0.0763 0.0749 0.0741 0.0742 0.0745 0.0743 

[TRAIN] Epoch[1](342/1500); Loss: 0.134921; Backpropagation: 0.0919 sec; Batch: 0.4439 sec
0.2361 0.2504 0.1932 0.1501 0.1496 0.1350 0.1153 0.1059 0.1036 0.1018 0.1020 0.1022 0.1027 0.1032 0.1035 0.1041 

[TRAIN] Epoch[1](343/1500); Loss: 0.077192; Backpropagation: 0.0919 sec; Batch: 0.4619 sec
0.1237 0.1484 0.1066 0.0808 0.0755 0.0670 0.0630 0.0614 0.0614 0.0607 0.0613 0.0620 0.0632 0.0647 0.0668 0.0686 

[TRAIN] Epoch[1](344/1500); Loss: 0.153594; Backpropagation: 0.0921 sec; Batch: 0.4226 sec
0.2103 0.2160 0.1954 0.1846 0.1773 0.1651 0.1545 0.1453 0.1364 0.1311 0.1275 0.1248 0.1232 0.1224 0.1220 0.1216 

[TRAIN] Epoch[1](345/1500); Loss: 0.116177; Backpropagation: 0.0918 sec; Batch: 0.4275 sec
0.1464 0.1433 0.1282 0.1290 0.1252 0.1242 0.1195 0.1118 0.1064 0.1030 0.1026 0.1027 0.1032 0.1039 0.1045 0.1050 

[TRAIN] Epoch[1](346/1500); Loss: 0.126883; Backpropagation: 0.0917 sec; Batch: 0.4271 sec
0.1787 0.1811 0.1615 0.1488 0.1425 0.1304 0.1193 0.1133 0.1100 0.1071 0.1058 0.1054 0.1055 0.1063 0.1069 0.1075 

[TRAIN] Epoch[1](347/1500); Loss: 0.115611; Backpropagation: 0.0917 sec; Batch: 0.4642 sec
0.2254 0.2135 0.1839 0.1412 0.1271 0.1063 0.0990 0.0910 0.0867 0.0839 0.0823 0.0818 0.0817 0.0817 0.0820 0.0824 

[TRAIN] Epoch[1](348/1500); Loss: 0.058291; Backpropagation: 0.0917 sec; Batch: 0.4260 sec
0.0857 0.0595 0.0428 0.0728 0.0928 0.1005 0.0732 0.0395 0.0382 0.0409 0.0475 0.0465 0.0466 0.0480 0.0486 0.0496 

[TRAIN] Epoch[1](349/1500); Loss: 0.109426; Backpropagation: 0.0919 sec; Batch: 0.4271 sec
0.1348 0.1360 0.1269 0.1343 0.1198 0.1053 0.1019 0.0998 0.0986 0.0983 0.0980 0.0983 0.0988 0.0993 0.0998 0.1008 

[TRAIN] Epoch[1](350/1500); Loss: 0.077154; Backpropagation: 0.0916 sec; Batch: 0.4268 sec
0.0908 0.0891 0.0792 0.0806 0.0741 0.0715 0.0718 0.0727 0.0734 0.0737 0.0743 0.0748 0.0756 0.0767 0.0775 0.0785 

[TRAIN] Epoch[1](351/1500); Loss: 0.084626; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0977 0.1009 0.0939 0.0910 0.0812 0.0787 0.0774 0.0770 0.0772 0.0774 0.0787 0.0802 0.0821 0.0845 0.0868 0.0893 

[TRAIN] Epoch[1](352/1500); Loss: 0.136752; Backpropagation: 0.0918 sec; Batch: 0.4303 sec
0.1961 0.1938 0.1696 0.1562 0.1494 0.1388 0.1339 0.1297 0.1254 0.1215 0.1185 0.1158 0.1123 0.1100 0.1091 0.1079 

[TRAIN] Epoch[1](353/1500); Loss: 0.114415; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.1774 0.1996 0.1527 0.1111 0.1040 0.1033 0.1012 0.1006 0.0996 0.0987 0.0980 0.0973 0.0968 0.0966 0.0966 0.0970 

[TRAIN] Epoch[1](354/1500); Loss: 0.087441; Backpropagation: 0.0919 sec; Batch: 0.4273 sec
0.1067 0.1168 0.0946 0.0893 0.0854 0.0850 0.0841 0.0833 0.0825 0.0818 0.0814 0.0812 0.0813 0.0815 0.0818 0.0823 

[TRAIN] Epoch[1](355/1500); Loss: 0.101008; Backpropagation: 0.0918 sec; Batch: 0.4666 sec
0.1444 0.1335 0.1048 0.1044 0.0994 0.0958 0.0930 0.0923 0.0923 0.0924 0.0926 0.0930 0.0934 0.0940 0.0948 0.0958 

[TRAIN] Epoch[1](356/1500); Loss: 0.082804; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1184 0.1224 0.1008 0.0927 0.0884 0.0837 0.0793 0.0758 0.0734 0.0714 0.0704 0.0698 0.0695 0.0694 0.0695 0.0699 

[TRAIN] Epoch[1](357/1500); Loss: 0.049036; Backpropagation: 0.0918 sec; Batch: 0.4594 sec
0.1303 0.1001 0.0755 0.0340 0.0354 0.0520 0.0575 0.0524 0.0406 0.0332 0.0300 0.0289 0.0283 0.0283 0.0288 0.0292 

[TRAIN] Epoch[1](358/1500); Loss: 0.110345; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1413 0.1388 0.1238 0.1201 0.1176 0.1134 0.1094 0.1049 0.1018 0.1000 0.0994 0.0990 0.0989 0.0989 0.0991 0.0993 

[TRAIN] Epoch[1](359/1500); Loss: 0.107375; Backpropagation: 0.0917 sec; Batch: 0.4525 sec
0.1335 0.1317 0.1161 0.1197 0.1151 0.1089 0.1019 0.1001 0.0991 0.0987 0.0985 0.0984 0.0985 0.0988 0.0993 0.0999 

[TRAIN] Epoch[1](360/1500); Loss: 0.134616; Backpropagation: 0.0917 sec; Batch: 0.4256 sec
0.1729 0.1643 0.1511 0.1482 0.1407 0.1365 0.1312 0.1252 0.1237 0.1238 0.1239 0.1235 0.1231 0.1225 0.1219 0.1214 

[TRAIN] Epoch[1](361/1500); Loss: 0.089540; Backpropagation: 0.0919 sec; Batch: 0.4273 sec
0.1269 0.1279 0.1141 0.1034 0.0942 0.0867 0.0808 0.0783 0.0776 0.0769 0.0772 0.0771 0.0772 0.0777 0.0781 0.0785 

[TRAIN] Epoch[1](362/1500); Loss: 0.077799; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.0924 0.0959 0.0975 0.1181 0.0909 0.0734 0.0709 0.0686 0.0682 0.0674 0.0666 0.0663 0.0663 0.0666 0.0670 0.0686 

[TRAIN] Epoch[1](363/1500); Loss: 0.103844; Backpropagation: 0.0918 sec; Batch: 0.4507 sec
0.1409 0.1360 0.1230 0.1140 0.1083 0.1019 0.0987 0.0959 0.0952 0.0946 0.0937 0.0930 0.0924 0.0918 0.0911 0.0911 

[TRAIN] Epoch[1](364/1500); Loss: 0.084738; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1345 0.1358 0.1127 0.0959 0.0847 0.0768 0.0728 0.0712 0.0709 0.0708 0.0710 0.0713 0.0717 0.0718 0.0720 0.0722 

[TRAIN] Epoch[1](365/1500); Loss: 0.150375; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.2299 0.2307 0.1964 0.1679 0.1520 0.1372 0.1364 0.1332 0.1319 0.1302 0.1288 0.1277 0.1267 0.1260 0.1255 0.1253 

[TRAIN] Epoch[1](366/1500); Loss: 0.100787; Backpropagation: 0.0916 sec; Batch: 0.4263 sec
0.1508 0.1476 0.1298 0.1184 0.1101 0.0995 0.0923 0.0896 0.0872 0.0851 0.0839 0.0837 0.0838 0.0836 0.0835 0.0837 

[TRAIN] Epoch[1](367/1500); Loss: 0.115855; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1515 0.1510 0.1325 0.1217 0.1168 0.1141 0.1107 0.1094 0.1080 0.1064 0.1061 0.1058 0.1055 0.1052 0.1046 0.1043 

[TRAIN] Epoch[1](368/1500); Loss: 0.064580; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1044 0.0902 0.0787 0.0745 0.0714 0.0682 0.0627 0.0564 0.0541 0.0534 0.0534 0.0531 0.0533 0.0530 0.0530 0.0533 

[TRAIN] Epoch[1](369/1500); Loss: 0.171343; Backpropagation: 0.0916 sec; Batch: 0.4298 sec
0.2689 0.2407 0.2145 0.1823 0.1732 0.1609 0.1583 0.1521 0.1492 0.1480 0.1487 0.1506 0.1514 0.1472 0.1477 0.1479 

[TRAIN] Epoch[1](370/1500); Loss: 0.141612; Backpropagation: 0.0920 sec; Batch: 0.4278 sec
0.1736 0.1609 0.1488 0.1464 0.1425 0.1396 0.1376 0.1362 0.1353 0.1351 0.1348 0.1347 0.1345 0.1348 0.1352 0.1357 

[TRAIN] Epoch[1](371/1500); Loss: 0.068077; Backpropagation: 0.0917 sec; Batch: 0.4271 sec
0.1022 0.0906 0.0839 0.0772 0.0725 0.0675 0.0631 0.0607 0.0597 0.0591 0.0589 0.0587 0.0584 0.0585 0.0590 0.0593 

[TRAIN] Epoch[1](372/1500); Loss: 0.107031; Backpropagation: 0.0917 sec; Batch: 0.4308 sec
0.1351 0.1368 0.1183 0.1086 0.1059 0.1030 0.1017 0.1007 0.1001 0.0997 0.0995 0.0997 0.1001 0.1006 0.1010 0.1016 

[TRAIN] Epoch[1](373/1500); Loss: 0.118450; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1577 0.1620 0.1343 0.1205 0.1165 0.1120 0.1110 0.1105 0.1098 0.1092 0.1086 0.1083 0.1083 0.1084 0.1088 0.1093 

[TRAIN] Epoch[1](374/1500); Loss: 0.097177; Backpropagation: 0.0917 sec; Batch: 0.4226 sec
0.1312 0.1221 0.1062 0.1031 0.0990 0.0965 0.0922 0.0899 0.0887 0.0886 0.0885 0.0889 0.0892 0.0896 0.0903 0.0908 

[TRAIN] Epoch[1](375/1500); Loss: 0.070687; Backpropagation: 0.0920 sec; Batch: 0.4229 sec
0.1092 0.1101 0.0876 0.0771 0.0716 0.0675 0.0635 0.0622 0.0611 0.0603 0.0598 0.0597 0.0596 0.0601 0.0605 0.0611 

[TRAIN] Epoch[1](376/1500); Loss: 0.120335; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2134 0.2037 0.1720 0.1371 0.1253 0.1030 0.0996 0.0971 0.0968 0.0969 0.0967 0.0966 0.0965 0.0966 0.0969 0.0972 

[TRAIN] Epoch[1](377/1500); Loss: 0.132685; Backpropagation: 0.0919 sec; Batch: 0.4271 sec
0.3234 0.2815 0.2390 0.1637 0.1343 0.1027 0.0973 0.0862 0.0822 0.0791 0.0774 0.0782 0.0806 0.0804 0.1114 0.1055 

[TRAIN] Epoch[1](378/1500); Loss: 0.056770; Backpropagation: 0.0917 sec; Batch: 0.4225 sec
0.0809 0.0627 0.0550 0.0763 0.0828 0.0783 0.0493 0.0481 0.0454 0.0448 0.0446 0.0450 0.0461 0.0475 0.0497 0.0518 

[TRAIN] Epoch[1](379/1500); Loss: 0.094074; Backpropagation: 0.0921 sec; Batch: 0.4227 sec
0.1295 0.1233 0.1085 0.1018 0.0964 0.0916 0.0883 0.0869 0.0863 0.0857 0.0853 0.0849 0.0845 0.0840 0.0840 0.0842 

[TRAIN] Epoch[1](380/1500); Loss: 0.108235; Backpropagation: 0.0917 sec; Batch: 0.4274 sec
0.1621 0.1474 0.1263 0.1125 0.1059 0.1015 0.0996 0.0987 0.0979 0.0975 0.0972 0.0970 0.0970 0.0969 0.0970 0.0974 

[TRAIN] Epoch[1](381/1500); Loss: 0.134774; Backpropagation: 0.0917 sec; Batch: 0.4506 sec
0.1571 0.1559 0.1424 0.1386 0.1360 0.1338 0.1325 0.1316 0.1305 0.1296 0.1290 0.1285 0.1281 0.1278 0.1275 0.1273 

[TRAIN] Epoch[1](382/1500); Loss: 0.117826; Backpropagation: 0.0920 sec; Batch: 0.4278 sec
0.1787 0.1736 0.1481 0.1278 0.1218 0.1102 0.1035 0.1020 0.1031 0.1028 0.1025 0.1022 0.1020 0.1022 0.1023 0.1025 

[TRAIN] Epoch[1](383/1500); Loss: 0.142879; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.2024 0.1896 0.1701 0.1559 0.1482 0.1408 0.1372 0.1339 0.1321 0.1301 0.1284 0.1267 0.1248 0.1234 0.1220 0.1206 

[TRAIN] Epoch[1](384/1500); Loss: 0.076206; Backpropagation: 0.0918 sec; Batch: 0.4312 sec
0.1091 0.1015 0.0877 0.0865 0.0822 0.0761 0.0731 0.0708 0.0695 0.0685 0.0689 0.0672 0.0659 0.0650 0.0641 0.0632 

[TRAIN] Epoch[1](385/1500); Loss: 0.111258; Backpropagation: 0.0920 sec; Batch: 0.4271 sec
0.1281 0.1256 0.1155 0.1136 0.1113 0.1082 0.1078 0.1074 0.1074 0.1073 0.1072 0.1073 0.1076 0.1080 0.1086 0.1092 

[TRAIN] Epoch[1](386/1500); Loss: 0.044741; Backpropagation: 0.0918 sec; Batch: 0.4302 sec
0.0510 0.0521 0.0534 0.0579 0.0455 0.0427 0.0415 0.0409 0.0401 0.0398 0.0412 0.0411 0.0411 0.0423 0.0426 0.0428 

[TRAIN] Epoch[1](387/1500); Loss: 0.088145; Backpropagation: 0.0937 sec; Batch: 0.4283 sec
0.1112 0.1087 0.0968 0.0929 0.0894 0.0860 0.0842 0.0838 0.0833 0.0827 0.0823 0.0820 0.0817 0.0816 0.0818 0.0820 

[TRAIN] Epoch[1](388/1500); Loss: 0.065606; Backpropagation: 0.0935 sec; Batch: 0.4294 sec
0.1026 0.0955 0.0753 0.0649 0.0641 0.0620 0.0598 0.0593 0.0589 0.0585 0.0583 0.0583 0.0582 0.0579 0.0578 0.0583 

[TRAIN] Epoch[1](389/1500); Loss: 0.124413; Backpropagation: 0.0924 sec; Batch: 0.4265 sec
0.2026 0.2002 0.1582 0.1223 0.1157 0.1139 0.1119 0.1100 0.1085 0.1077 0.1069 0.1062 0.1058 0.1058 0.1075 0.1075 

[TRAIN] Epoch[1](390/1500); Loss: 0.159418; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.2038 0.1889 0.1719 0.1648 0.1609 0.1571 0.1547 0.1531 0.1516 0.1509 0.1501 0.1495 0.1490 0.1485 0.1481 0.1478 

[TRAIN] Epoch[1](391/1500); Loss: 0.117404; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1512 0.1463 0.1271 0.1182 0.1147 0.1128 0.1124 0.1118 0.1112 0.1109 0.1106 0.1104 0.1103 0.1103 0.1103 0.1100 

[TRAIN] Epoch[1](392/1500); Loss: 0.122595; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1547 0.1536 0.1458 0.1373 0.1236 0.1190 0.1181 0.1153 0.1144 0.1137 0.1130 0.1121 0.1112 0.1105 0.1099 0.1094 

[TRAIN] Epoch[1](393/1500); Loss: 0.161726; Backpropagation: 0.0921 sec; Batch: 0.4269 sec
0.1942 0.1880 0.1760 0.1674 0.1637 0.1606 0.1588 0.1577 0.1565 0.1553 0.1542 0.1531 0.1520 0.1510 0.1500 0.1492 

[TRAIN] Epoch[1](394/1500); Loss: 0.059177; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1036 0.1231 0.0709 0.0639 0.0539 0.0509 0.0502 0.0490 0.0478 0.0468 0.0468 0.0470 0.0474 0.0480 0.0485 0.0491 

[TRAIN] Epoch[1](395/1500); Loss: 0.074254; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1873 0.2327 0.1544 0.0499 0.0469 0.0452 0.0441 0.0437 0.0437 0.0447 0.0509 0.0497 0.0491 0.0486 0.0485 0.0488 

[TRAIN] Epoch[1](396/1500); Loss: 0.119358; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1643 0.1350 0.1179 0.1148 0.1127 0.1144 0.1137 0.1134 0.1133 0.1133 0.1143 0.1146 0.1153 0.1163 0.1175 0.1190 

[TRAIN] Epoch[1](397/1500); Loss: 0.079016; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1160 0.0976 0.0874 0.0851 0.0775 0.0749 0.0738 0.0728 0.0723 0.0718 0.0717 0.0717 0.0721 0.0725 0.0732 0.0740 

[TRAIN] Epoch[1](398/1500); Loss: 0.117647; Backpropagation: 0.0918 sec; Batch: 0.4276 sec
0.1620 0.1395 0.1142 0.1115 0.1090 0.1095 0.1093 0.1098 0.1108 0.1115 0.1133 0.1142 0.1151 0.1164 0.1176 0.1187 

[TRAIN] Epoch[1](399/1500); Loss: 0.128735; Backpropagation: 0.0918 sec; Batch: 0.4276 sec
0.1695 0.1693 0.1466 0.1323 0.1290 0.1241 0.1211 0.1201 0.1191 0.1188 0.1186 0.1183 0.1182 0.1182 0.1182 0.1182 

[TRAIN] Epoch[1](400/1500); Loss: 0.146628; Backpropagation: 0.0915 sec; Batch: 0.4508 sec
0.2138 0.1947 0.1746 0.1583 0.1492 0.1423 0.1392 0.1369 0.1348 0.1332 0.1319 0.1303 0.1288 0.1273 0.1260 0.1247 

[TRAIN] Epoch[1](401/1500); Loss: 0.117421; Backpropagation: 0.0918 sec; Batch: 0.4382 sec
0.2036 0.1802 0.1485 0.1237 0.1185 0.1134 0.1110 0.1074 0.1045 0.1016 0.0991 0.0967 0.0948 0.0931 0.0918 0.0909 

[TRAIN] Epoch[1](402/1500); Loss: 0.090908; Backpropagation: 0.0916 sec; Batch: 0.4427 sec
0.1386 0.1340 0.1139 0.1014 0.0942 0.0876 0.0821 0.0798 0.0790 0.0782 0.0782 0.0779 0.0776 0.0773 0.0773 0.0774 

[TRAIN] Epoch[1](403/1500); Loss: 0.078356; Backpropagation: 0.0919 sec; Batch: 0.4606 sec
0.1018 0.1011 0.0866 0.0838 0.0780 0.0748 0.0734 0.0726 0.0721 0.0718 0.0720 0.0722 0.0723 0.0732 0.0738 0.0741 

[TRAIN] Epoch[1](404/1500); Loss: 0.056909; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.0993 0.0957 0.0817 0.0693 0.0602 0.0524 0.0503 0.0478 0.0464 0.0452 0.0443 0.0436 0.0431 0.0432 0.0437 0.0445 

[TRAIN] Epoch[1](405/1500); Loss: 0.161170; Backpropagation: 0.0917 sec; Batch: 0.4533 sec
0.2399 0.2252 0.1937 0.1678 0.1616 0.1556 0.1540 0.1507 0.1479 0.1454 0.1431 0.1411 0.1394 0.1382 0.1376 0.1375 

[TRAIN] Epoch[1](406/1500); Loss: 0.110490; Backpropagation: 0.0920 sec; Batch: 0.4250 sec
0.1540 0.1695 0.1375 0.1148 0.1087 0.1034 0.1006 0.0997 0.0989 0.0981 0.0976 0.0972 0.0970 0.0969 0.0968 0.0969 

[TRAIN] Epoch[1](407/1500); Loss: 0.050151; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1060 0.0854 0.0619 0.0452 0.0418 0.0411 0.0413 0.0408 0.0431 0.0422 0.0428 0.0425 0.0417 0.0419 0.0423 0.0425 

[TRAIN] Epoch[1](408/1500); Loss: 0.133598; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1593 0.1683 0.1464 0.1362 0.1342 0.1307 0.1279 0.1269 0.1264 0.1266 0.1263 0.1260 0.1258 0.1256 0.1255 0.1256 

[TRAIN] Epoch[1](409/1500); Loss: 0.075063; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0882 0.0834 0.0815 0.0786 0.0752 0.0736 0.0727 0.0720 0.0718 0.0719 0.0720 0.0718 0.0718 0.0719 0.0722 0.0723 

[TRAIN] Epoch[1](410/1500); Loss: 0.058557; Backpropagation: 0.0916 sec; Batch: 0.4263 sec
0.0757 0.0848 0.0676 0.0624 0.0588 0.0579 0.0568 0.0555 0.0544 0.0533 0.0525 0.0518 0.0514 0.0512 0.0512 0.0516 

[TRAIN] Epoch[1](411/1500); Loss: 0.153514; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2031 0.1964 0.1762 0.1610 0.1574 0.1529 0.1482 0.1454 0.1436 0.1423 0.1412 0.1401 0.1388 0.1375 0.1365 0.1356 

[TRAIN] Epoch[1](412/1500); Loss: 0.113098; Backpropagation: 0.0916 sec; Batch: 0.4584 sec
0.1582 0.1371 0.1262 0.1222 0.1179 0.1140 0.1115 0.1089 0.1064 0.1044 0.1030 0.1018 0.1005 0.0997 0.0992 0.0987 

[TRAIN] Epoch[1](413/1500); Loss: 0.090061; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1425 0.1393 0.1227 0.1062 0.1004 0.0922 0.0844 0.0786 0.0745 0.0725 0.0717 0.0713 0.0711 0.0710 0.0712 0.0715 

[TRAIN] Epoch[1](414/1500); Loss: 0.119533; Backpropagation: 0.0917 sec; Batch: 0.4272 sec
0.1768 0.1651 0.1480 0.1353 0.1275 0.1164 0.1107 0.1095 0.1080 0.1064 0.1043 0.1029 0.1019 0.1007 0.1000 0.0990 

[TRAIN] Epoch[1](415/1500); Loss: 0.080513; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.1871 0.1595 0.1313 0.0979 0.0901 0.0817 0.0775 0.0711 0.0656 0.0598 0.0543 0.0490 0.0446 0.0413 0.0392 0.0382 

[TRAIN] Epoch[1](416/1500); Loss: 0.059160; Backpropagation: 0.0917 sec; Batch: 0.4272 sec
0.1207 0.0970 0.0602 0.0549 0.0532 0.0518 0.0508 0.0499 0.0498 0.0498 0.0501 0.0504 0.0505 0.0517 0.0522 0.0535 

[TRAIN] Epoch[1](417/1500); Loss: 0.150978; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1959 0.1947 0.1677 0.1553 0.1521 0.1483 0.1441 0.1419 0.1410 0.1402 0.1397 0.1391 0.1393 0.1390 0.1388 0.1387 

[TRAIN] Epoch[1](418/1500); Loss: 0.081573; Backpropagation: 0.0919 sec; Batch: 0.4260 sec
0.1051 0.1007 0.0898 0.0849 0.0807 0.0783 0.0770 0.0763 0.0763 0.0762 0.0764 0.0766 0.0768 0.0768 0.0764 0.0770 

[TRAIN] Epoch[1](419/1500); Loss: 0.089116; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1473 0.1397 0.0983 0.0893 0.0853 0.0835 0.0816 0.0802 0.0793 0.0787 0.0783 0.0777 0.0774 0.0769 0.0764 0.0760 

[TRAIN] Epoch[1](420/1500); Loss: 0.116465; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1394 0.1379 0.1245 0.1198 0.1173 0.1152 0.1133 0.1123 0.1115 0.1109 0.1105 0.1101 0.1105 0.1102 0.1101 0.1098 

[TRAIN] Epoch[1](421/1500); Loss: 0.120695; Backpropagation: 0.0917 sec; Batch: 0.4306 sec
0.1540 0.1579 0.1403 0.1303 0.1263 0.1219 0.1165 0.1137 0.1115 0.1099 0.1090 0.1084 0.1080 0.1079 0.1079 0.1078 

[TRAIN] Epoch[1](422/1500); Loss: 0.089554; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1175 0.1177 0.1039 0.0968 0.0937 0.0894 0.0850 0.0826 0.0819 0.0813 0.0809 0.0809 0.0807 0.0804 0.0803 0.0801 

[TRAIN] Epoch[1](423/1500); Loss: 0.230532; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.2911 0.2784 0.2371 0.2322 0.2299 0.2241 0.2238 0.2231 0.2215 0.2209 0.2195 0.2187 0.2182 0.2175 0.2168 0.2158 

[TRAIN] Epoch[1](424/1500); Loss: 0.097307; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1332 0.1301 0.1086 0.1002 0.0950 0.0904 0.0880 0.0874 0.0878 0.0884 0.0892 0.0896 0.0904 0.0915 0.0929 0.0941 

[TRAIN] Epoch[1](425/1500); Loss: 0.069437; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.1270 0.1246 0.1037 0.0943 0.0878 0.0723 0.0616 0.0550 0.0505 0.0478 0.0472 0.0470 0.0473 0.0476 0.0484 0.0489 

[TRAIN] Epoch[1](426/1500); Loss: 0.112710; Backpropagation: 0.0918 sec; Batch: 0.4284 sec
0.1506 0.1539 0.1327 0.1220 0.1152 0.1114 0.1087 0.1057 0.1038 0.1018 0.1006 0.0998 0.0990 0.0988 0.0997 0.0997 

[TRAIN] Epoch[1](427/1500); Loss: 0.110799; Backpropagation: 0.0919 sec; Batch: 0.4249 sec
0.1343 0.1342 0.1219 0.1158 0.1136 0.1098 0.1076 0.1060 0.1046 0.1039 0.1036 0.1037 0.1036 0.1032 0.1033 0.1035 

[TRAIN] Epoch[1](428/1500); Loss: 0.089574; Backpropagation: 0.0915 sec; Batch: 0.4631 sec
0.1402 0.1660 0.1305 0.1117 0.1038 0.0921 0.0773 0.0701 0.0677 0.0677 0.0677 0.0675 0.0675 0.0673 0.0681 0.0680 

[TRAIN] Epoch[1](429/1500); Loss: 0.149435; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1987 0.1910 0.1633 0.1535 0.1490 0.1440 0.1417 0.1402 0.1410 0.1400 0.1396 0.1389 0.1384 0.1377 0.1372 0.1367 

[TRAIN] Epoch[1](430/1500); Loss: 0.083320; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1120 0.1282 0.0990 0.0863 0.0813 0.0788 0.0768 0.0755 0.0743 0.0734 0.0730 0.0731 0.0737 0.0746 0.0759 0.0773 

[TRAIN] Epoch[1](431/1500); Loss: 0.080351; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1001 0.0940 0.0850 0.0874 0.0803 0.0777 0.0768 0.0766 0.0765 0.0765 0.0762 0.0759 0.0757 0.0755 0.0757 0.0757 

[TRAIN] Epoch[1](432/1500); Loss: 0.081145; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1302 0.1608 0.1195 0.0915 0.0811 0.0663 0.0632 0.0626 0.0623 0.0628 0.0638 0.0651 0.0659 0.0669 0.0675 0.0688 

[TRAIN] Epoch[1](433/1500); Loss: 0.113293; Backpropagation: 0.0919 sec; Batch: 0.4279 sec
0.1392 0.1555 0.1281 0.1115 0.1088 0.1060 0.1054 0.1051 0.1052 0.1057 0.1060 0.1061 0.1066 0.1072 0.1078 0.1082 

[TRAIN] Epoch[1](434/1500); Loss: 0.095503; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1277 0.1329 0.1085 0.1083 0.1017 0.0992 0.0958 0.0931 0.0888 0.0857 0.0836 0.0813 0.0801 0.0804 0.0805 0.0804 

[TRAIN] Epoch[1](435/1500); Loss: 0.157659; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.2427 0.2116 0.1774 0.1538 0.1473 0.1469 0.1461 0.1436 0.1435 0.1432 0.1442 0.1449 0.1441 0.1451 0.1440 0.1442 

[TRAIN] Epoch[1](436/1500); Loss: 0.149113; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.2082 0.1923 0.1716 0.1586 0.1535 0.1469 0.1435 0.1406 0.1381 0.1364 0.1347 0.1334 0.1330 0.1322 0.1316 0.1312 

[TRAIN] Epoch[1](437/1500); Loss: 0.105424; Backpropagation: 0.0921 sec; Batch: 0.4261 sec
0.2999 0.2506 0.1861 0.1211 0.1041 0.0868 0.0811 0.0700 0.0632 0.0577 0.0550 0.0548 0.0565 0.0606 0.0662 0.0730 

[TRAIN] Epoch[1](438/1500); Loss: 0.134951; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1652 0.1510 0.1449 0.1408 0.1370 0.1357 0.1339 0.1323 0.1307 0.1292 0.1284 0.1272 0.1265 0.1261 0.1254 0.1248 

[TRAIN] Epoch[1](439/1500); Loss: 0.155018; Backpropagation: 0.0920 sec; Batch: 0.4260 sec
0.2006 0.1924 0.1722 0.1581 0.1551 0.1511 0.1500 0.1487 0.1475 0.1462 0.1451 0.1442 0.1435 0.1427 0.1418 0.1412 

[TRAIN] Epoch[1](440/1500); Loss: 0.153266; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.2143 0.1903 0.1644 0.1505 0.1478 0.1473 0.1477 0.1452 0.1456 0.1435 0.1431 0.1426 0.1425 0.1424 0.1425 0.1427 

[TRAIN] Epoch[1](441/1500); Loss: 0.155572; Backpropagation: 0.0920 sec; Batch: 0.4273 sec
0.2102 0.1931 0.1749 0.1611 0.1567 0.1530 0.1512 0.1489 0.1473 0.1458 0.1444 0.1430 0.1418 0.1404 0.1391 0.1383 

[TRAIN] Epoch[1](442/1500); Loss: 0.049780; Backpropagation: 0.0918 sec; Batch: 0.4309 sec
0.1067 0.0801 0.0529 0.0425 0.0474 0.0493 0.0456 0.0410 0.0419 0.0408 0.0409 0.0416 0.0412 0.0413 0.0414 0.0418 

[TRAIN] Epoch[1](443/1500); Loss: 0.135889; Backpropagation: 0.0919 sec; Batch: 0.4268 sec
0.2150 0.2023 0.1775 0.1547 0.1462 0.1330 0.1223 0.1188 0.1173 0.1151 0.1138 0.1132 0.1123 0.1116 0.1109 0.1103 

[TRAIN] Epoch[1](444/1500); Loss: 0.111073; Backpropagation: 0.0916 sec; Batch: 0.4580 sec
0.1582 0.1626 0.1375 0.1198 0.1124 0.1058 0.1022 0.0995 0.0980 0.0973 0.0971 0.0969 0.0969 0.0971 0.0976 0.0982 

[TRAIN] Epoch[1](445/1500); Loss: 0.066068; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.0970 0.0843 0.0714 0.0709 0.0660 0.0623 0.0614 0.0615 0.0610 0.0607 0.0602 0.0597 0.0597 0.0604 0.0605 0.0602 

[TRAIN] Epoch[1](446/1500); Loss: 0.095619; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.1407 0.1261 0.0947 0.0956 0.0910 0.0901 0.0883 0.0884 0.0884 0.0878 0.0877 0.0881 0.0896 0.0909 0.0911 0.0914 

[TRAIN] Epoch[1](447/1500); Loss: 0.064653; Backpropagation: 0.0917 sec; Batch: 0.4590 sec
0.1148 0.0988 0.0695 0.0668 0.0641 0.0615 0.0594 0.0580 0.0565 0.0553 0.0546 0.0546 0.0549 0.0549 0.0552 0.0555 

[TRAIN] Epoch[1](448/1500); Loss: 0.076144; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1382 0.1358 0.0994 0.0717 0.0661 0.0633 0.0623 0.0608 0.0605 0.0609 0.0618 0.0632 0.0652 0.0674 0.0696 0.0721 

[TRAIN] Epoch[1](449/1500); Loss: 0.105976; Backpropagation: 0.0920 sec; Batch: 0.4325 sec
0.1386 0.1268 0.1146 0.1105 0.1080 0.1032 0.1019 0.1012 0.1003 0.0996 0.0991 0.0988 0.0986 0.0984 0.0981 0.0980 

[TRAIN] Epoch[1](450/1500); Loss: 0.118384; Backpropagation: 0.0917 sec; Batch: 0.4255 sec
0.1527 0.1420 0.1311 0.1260 0.1213 0.1169 0.1148 0.1130 0.1115 0.1107 0.1098 0.1098 0.1090 0.1088 0.1084 0.1081 

[TRAIN] Epoch[1](451/1500); Loss: 0.137390; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2164 0.1787 0.1415 0.1369 0.1317 0.1288 0.1277 0.1275 0.1273 0.1270 0.1272 0.1273 0.1269 0.1247 0.1245 0.1242 

[TRAIN] Epoch[1](452/1500); Loss: 0.102764; Backpropagation: 0.0916 sec; Batch: 0.4302 sec
0.1267 0.1185 0.1093 0.1070 0.1049 0.1024 0.1006 0.0995 0.0984 0.0977 0.0971 0.0968 0.0965 0.0964 0.0963 0.0961 

[TRAIN] Epoch[1](453/1500); Loss: 0.107878; Backpropagation: 0.0919 sec; Batch: 0.4511 sec
0.1426 0.1348 0.1190 0.1093 0.1056 0.1033 0.1022 0.1016 0.1011 0.1009 0.1009 0.1007 0.1010 0.1010 0.1011 0.1012 

[TRAIN] Epoch[1](454/1500); Loss: 0.085387; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1202 0.1072 0.0982 0.0914 0.0870 0.0820 0.0798 0.0786 0.0785 0.0778 0.0774 0.0774 0.0775 0.0774 0.0773 0.0784 

[TRAIN] Epoch[1](455/1500); Loss: 0.057269; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0737 0.0837 0.0631 0.0579 0.0560 0.0549 0.0527 0.0525 0.0524 0.0522 0.0515 0.0521 0.0533 0.0534 0.0533 0.0537 

[TRAIN] Epoch[1](456/1500); Loss: 0.173544; Backpropagation: 0.0917 sec; Batch: 0.4259 sec
0.2465 0.2097 0.1798 0.1766 0.1704 0.1666 0.1652 0.1640 0.1632 0.1625 0.1618 0.1619 0.1623 0.1620 0.1618 0.1624 

[TRAIN] Epoch[1](457/1500); Loss: 0.185070; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2138 0.2032 0.1890 0.1875 0.1859 0.1828 0.1820 0.1812 0.1810 0.1802 0.1798 0.1793 0.1789 0.1792 0.1788 0.1785 

[TRAIN] Epoch[1](458/1500); Loss: 0.114056; Backpropagation: 0.0919 sec; Batch: 0.4257 sec
0.1578 0.1622 0.1294 0.1204 0.1139 0.1087 0.1063 0.1045 0.1032 0.1027 0.1025 0.1027 0.1025 0.1024 0.1026 0.1031 

[TRAIN] Epoch[1](459/1500); Loss: 0.132175; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2358 0.1897 0.1316 0.1281 0.1208 0.1177 0.1176 0.1175 0.1182 0.1189 0.1193 0.1194 0.1191 0.1199 0.1205 0.1207 

[TRAIN] Epoch[1](460/1500); Loss: 0.062435; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1527 0.2062 0.1318 0.0699 0.0517 0.0367 0.0386 0.0331 0.0330 0.0325 0.0339 0.0337 0.0341 0.0374 0.0365 0.0372 

[TRAIN] Epoch[1](461/1500); Loss: 0.072601; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1242 0.1208 0.0970 0.0796 0.0729 0.0664 0.0660 0.0630 0.0613 0.0615 0.0595 0.0588 0.0577 0.0575 0.0576 0.0578 

[TRAIN] Epoch[1](462/1500); Loss: 0.094973; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1305 0.1170 0.1030 0.0981 0.0951 0.0926 0.0912 0.0902 0.0887 0.0874 0.0872 0.0872 0.0873 0.0877 0.0879 0.0884 

[TRAIN] Epoch[1](463/1500); Loss: 0.127118; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1712 0.1692 0.1381 0.1279 0.1243 0.1214 0.1205 0.1196 0.1189 0.1180 0.1182 0.1175 0.1177 0.1169 0.1171 0.1174 

[TRAIN] Epoch[1](464/1500); Loss: 0.062006; Backpropagation: 0.0986 sec; Batch: 0.4493 sec
0.0952 0.0812 0.0737 0.0692 0.0648 0.0607 0.0581 0.0562 0.0550 0.0550 0.0539 0.0537 0.0536 0.0538 0.0539 0.0540 

[TRAIN] Epoch[1](465/1500); Loss: 0.096797; Backpropagation: 0.0984 sec; Batch: 0.4313 sec
0.1208 0.1132 0.1049 0.1008 0.0980 0.0959 0.0944 0.0932 0.0925 0.0917 0.0910 0.0904 0.0903 0.0904 0.0905 0.0907 

[TRAIN] Epoch[1](466/1500); Loss: 0.072719; Backpropagation: 0.0922 sec; Batch: 0.4293 sec
0.1098 0.0675 0.0881 0.0811 0.0783 0.0748 0.0715 0.0688 0.0672 0.0657 0.0647 0.0650 0.0642 0.0643 0.0662 0.0663 

[TRAIN] Epoch[1](467/1500); Loss: 0.113113; Backpropagation: 0.0922 sec; Batch: 0.4250 sec
0.1346 0.1562 0.1269 0.1117 0.1094 0.1089 0.1076 0.1066 0.1068 0.1058 0.1057 0.1057 0.1056 0.1057 0.1061 0.1066 

[TRAIN] Epoch[1](468/1500); Loss: 0.147409; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1719 0.1603 0.1538 0.1499 0.1477 0.1464 0.1449 0.1439 0.1429 0.1424 0.1421 0.1421 0.1426 0.1423 0.1424 0.1429 

[TRAIN] Epoch[1](469/1500); Loss: 0.103339; Backpropagation: 0.0919 sec; Batch: 0.4258 sec
0.1601 0.1332 0.1158 0.1064 0.1030 0.1000 0.0974 0.0960 0.0945 0.0935 0.0928 0.0923 0.0921 0.0924 0.0920 0.0919 

[TRAIN] Epoch[1](470/1500); Loss: 0.108684; Backpropagation: 0.0917 sec; Batch: 0.4591 sec
0.1279 0.1249 0.1153 0.1111 0.1074 0.1079 0.1070 0.1057 0.1050 0.1046 0.1037 0.1034 0.1034 0.1039 0.1037 0.1039 

[TRAIN] Epoch[1](471/1500); Loss: 0.115559; Backpropagation: 0.0939 sec; Batch: 0.4312 sec
0.1204 0.1375 0.1191 0.1127 0.1105 0.1126 0.1112 0.1111 0.1113 0.1127 0.1133 0.1139 0.1140 0.1154 0.1160 0.1171 

[TRAIN] Epoch[1](472/1500); Loss: 0.075123; Backpropagation: 0.0917 sec; Batch: 0.4639 sec
0.0961 0.0870 0.0855 0.0823 0.0786 0.0767 0.0720 0.0704 0.0701 0.0692 0.0690 0.0690 0.0685 0.0690 0.0688 0.0698 

[TRAIN] Epoch[1](473/1500); Loss: 0.084387; Backpropagation: 0.0919 sec; Batch: 0.4310 sec
0.1203 0.1544 0.1136 0.0904 0.0811 0.0758 0.0731 0.0718 0.0715 0.0712 0.0713 0.0709 0.0707 0.0712 0.0712 0.0717 

[TRAIN] Epoch[1](474/1500); Loss: 0.101609; Backpropagation: 0.0916 sec; Batch: 0.4263 sec
0.1325 0.1533 0.1221 0.1082 0.1028 0.0967 0.0910 0.0896 0.0890 0.0891 0.0896 0.0901 0.0910 0.0927 0.0937 0.0943 

[TRAIN] Epoch[1](475/1500); Loss: 0.092092; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1076 0.1110 0.0958 0.0899 0.0889 0.0891 0.0892 0.0887 0.0887 0.0889 0.0889 0.0896 0.0891 0.0894 0.0890 0.0897 

[TRAIN] Epoch[1](476/1500); Loss: 0.056672; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.0829 0.0747 0.0603 0.0559 0.0525 0.0512 0.0526 0.0522 0.0518 0.0524 0.0523 0.0527 0.0536 0.0533 0.0536 0.0546 

[TRAIN] Epoch[1](477/1500); Loss: 0.126891; Backpropagation: 0.0918 sec; Batch: 0.4527 sec
0.1625 0.1599 0.1415 0.1313 0.1269 0.1226 0.1207 0.1193 0.1187 0.1186 0.1183 0.1181 0.1179 0.1179 0.1180 0.1181 

[TRAIN] Epoch[1](478/1500); Loss: 0.056560; Backpropagation: 0.0919 sec; Batch: 0.4255 sec
0.1015 0.0922 0.0558 0.0563 0.0581 0.0519 0.0591 0.0523 0.0500 0.0485 0.0469 0.0468 0.0458 0.0462 0.0466 0.0472 

[TRAIN] Epoch[1](479/1500); Loss: 0.100978; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1348 0.1582 0.1265 0.1097 0.1038 0.0947 0.0890 0.0871 0.0869 0.0871 0.0873 0.0879 0.0888 0.0901 0.0913 0.0925 

[TRAIN] Epoch[1](480/1500); Loss: 0.072358; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1213 0.0995 0.0873 0.0810 0.0749 0.0705 0.0675 0.0655 0.0635 0.0621 0.0615 0.0612 0.0609 0.0607 0.0604 0.0603 

[TRAIN] Epoch[1](481/1500); Loss: 0.106080; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1539 0.1736 0.1457 0.1255 0.1141 0.1012 0.0931 0.0898 0.0883 0.0875 0.0873 0.0871 0.0871 0.0874 0.0877 0.0881 

[TRAIN] Epoch[1](482/1500); Loss: 0.079780; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1110 0.1031 0.0906 0.0848 0.0820 0.0794 0.0776 0.0759 0.0745 0.0735 0.0724 0.0714 0.0708 0.0702 0.0696 0.0696 

[TRAIN] Epoch[1](483/1500); Loss: 0.119122; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1434 0.1314 0.1270 0.1242 0.1215 0.1194 0.1176 0.1162 0.1151 0.1142 0.1136 0.1129 0.1126 0.1125 0.1122 0.1122 

[TRAIN] Epoch[1](484/1500); Loss: 0.109456; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1606 0.1342 0.1143 0.1107 0.1064 0.1049 0.1041 0.1029 0.1020 0.1015 0.1016 0.1013 0.1014 0.1017 0.1019 0.1019 

[TRAIN] Epoch[1](485/1500); Loss: 0.059905; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0827 0.0684 0.0644 0.0620 0.0595 0.0579 0.0563 0.0556 0.0552 0.0552 0.0555 0.0559 0.0564 0.0570 0.0578 0.0586 

[TRAIN] Epoch[1](486/1500); Loss: 0.122828; Backpropagation: 0.0917 sec; Batch: 0.4270 sec
0.1778 0.1716 0.1554 0.1415 0.1313 0.1204 0.1152 0.1122 0.1106 0.1084 0.1063 0.1048 0.1035 0.1025 0.1019 0.1017 

[TRAIN] Epoch[1](487/1500); Loss: 0.114754; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1419 0.1685 0.1326 0.1160 0.1093 0.1104 0.1075 0.1060 0.1058 0.1055 0.1056 0.1053 0.1054 0.1052 0.1055 0.1056 

[TRAIN] Epoch[1](488/1500); Loss: 0.078658; Backpropagation: 0.0916 sec; Batch: 0.4273 sec
0.1152 0.0966 0.0934 0.0860 0.0816 0.0779 0.0753 0.0738 0.0719 0.0709 0.0701 0.0694 0.0689 0.0690 0.0691 0.0695 

[TRAIN] Epoch[1](489/1500); Loss: 0.103399; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1365 0.1165 0.1219 0.1105 0.1058 0.1030 0.1014 0.0996 0.0980 0.0968 0.0956 0.0946 0.0940 0.0934 0.0935 0.0933 

[TRAIN] Epoch[1](490/1500); Loss: 0.074936; Backpropagation: 0.0920 sec; Batch: 0.4276 sec
0.0966 0.0857 0.0863 0.0790 0.0746 0.0723 0.0705 0.0697 0.0690 0.0689 0.0693 0.0701 0.0707 0.0714 0.0718 0.0732 

[TRAIN] Epoch[1](491/1500); Loss: 0.098979; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1311 0.1612 0.1272 0.1051 0.0961 0.0919 0.0894 0.0878 0.0868 0.0865 0.0864 0.0864 0.0865 0.0867 0.0870 0.0875 

[TRAIN] Epoch[1](492/1500); Loss: 0.166768; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1868 0.1999 0.1900 0.1843 0.1789 0.1745 0.1702 0.1663 0.1628 0.1593 0.1562 0.1531 0.1502 0.1477 0.1451 0.1429 

[TRAIN] Epoch[1](493/1500); Loss: 0.103006; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1372 0.1119 0.1092 0.1059 0.1034 0.1008 0.0993 0.0984 0.0978 0.0973 0.0970 0.0971 0.0970 0.0976 0.0986 0.0995 

[TRAIN] Epoch[1](494/1500); Loss: 0.081606; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0913 0.0923 0.0849 0.0824 0.0808 0.0798 0.0791 0.0789 0.0791 0.0792 0.0791 0.0794 0.0795 0.0796 0.0800 0.0803 

[TRAIN] Epoch[1](495/1500); Loss: 0.122673; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.1621 0.1509 0.1361 0.1301 0.1257 0.1216 0.1190 0.1178 0.1162 0.1149 0.1133 0.1124 0.1116 0.1110 0.1103 0.1100 

[TRAIN] Epoch[1](496/1500); Loss: 0.081674; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1196 0.1031 0.0848 0.0810 0.0776 0.0765 0.0758 0.0760 0.0759 0.0762 0.0762 0.0763 0.0766 0.0769 0.0769 0.0773 

[TRAIN] Epoch[1](497/1500); Loss: 0.130144; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1574 0.1633 0.1456 0.1380 0.1328 0.1276 0.1256 0.1240 0.1228 0.1216 0.1208 0.1206 0.1207 0.1205 0.1202 0.1206 

[TRAIN] Epoch[1](498/1500); Loss: 0.073179; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1167 0.0856 0.0806 0.0793 0.0754 0.0713 0.0688 0.0664 0.0652 0.0648 0.0642 0.0640 0.0656 0.0665 0.0676 0.0689 

[TRAIN] Epoch[1](499/1500); Loss: 0.113284; Backpropagation: 0.0921 sec; Batch: 0.4256 sec
0.1341 0.1673 0.1488 0.1404 0.1279 0.1213 0.1140 0.1090 0.1048 0.1002 0.0963 0.0933 0.0914 0.0891 0.0877 0.0869 

[TRAIN] Epoch[1](500/1500); Loss: 0.060771; Backpropagation: 0.0917 sec; Batch: 0.4224 sec
0.0939 0.1096 0.0763 0.0621 0.0571 0.0531 0.0521 0.0514 0.0502 0.0518 0.0518 0.0515 0.0516 0.0525 0.0528 0.0545 

[TRAIN] Epoch[1](501/1500); Loss: 0.105614; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1252 0.1241 0.1154 0.1109 0.1073 0.1044 0.1018 0.1011 0.1005 0.1001 0.0999 0.0997 0.0998 0.1000 0.1000 0.0996 

[TRAIN] Epoch[1](502/1500); Loss: 0.077104; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1012 0.0928 0.0847 0.0805 0.0778 0.0784 0.0754 0.0740 0.0725 0.0713 0.0717 0.0708 0.0705 0.0708 0.0706 0.0707 

[TRAIN] Epoch[1](503/1500); Loss: 0.140720; Backpropagation: 0.0918 sec; Batch: 0.4301 sec
0.1919 0.1685 0.1678 0.1652 0.1579 0.1477 0.1383 0.1319 0.1274 0.1245 0.1219 0.1204 0.1207 0.1217 0.1224 0.1232 

[TRAIN] Epoch[1](504/1500); Loss: 0.318917; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.3812 0.3019 0.3200 0.3307 0.3367 0.3351 0.3294 0.3236 0.3189 0.3151 0.3110 0.3076 0.3037 0.2995 0.2956 0.2927 

[TRAIN] Epoch[1](505/1500); Loss: 0.222712; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2395 0.1959 0.2058 0.2142 0.2210 0.2255 0.2259 0.2254 0.2252 0.2258 0.2265 0.2265 0.2263 0.2261 0.2265 0.2272 

[TRAIN] Epoch[1](506/1500); Loss: 0.300237; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.3200 0.2845 0.2882 0.2971 0.3042 0.3060 0.3031 0.3008 0.3010 0.3004 0.3003 0.3004 0.2996 0.2994 0.2998 0.2991 

[TRAIN] Epoch[1](507/1500); Loss: 0.199793; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2375 0.1974 0.2027 0.2122 0.2179 0.2144 0.2067 0.2027 0.1998 0.1967 0.1930 0.1889 0.1858 0.1831 0.1803 0.1777 

[TRAIN] Epoch[1](508/1500); Loss: 0.177029; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2161 0.2190 0.1995 0.1915 0.1807 0.1730 0.1644 0.1595 0.1575 0.1591 0.1635 0.1685 0.1703 0.1694 0.1700 0.1704 

[TRAIN] Epoch[1](509/1500); Loss: 0.207815; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.2680 0.2632 0.2543 0.2506 0.2439 0.2333 0.2206 0.2108 0.2015 0.1916 0.1820 0.1731 0.1655 0.1593 0.1548 0.1526 

[TRAIN] Epoch[1](510/1500); Loss: 0.091034; Backpropagation: 0.0915 sec; Batch: 0.4274 sec
0.1281 0.1019 0.0933 0.0938 0.0937 0.0901 0.0874 0.0855 0.0842 0.0839 0.0846 0.0843 0.0848 0.0856 0.0869 0.0884 

[TRAIN] Epoch[1](511/1500); Loss: 0.129489; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1637 0.1716 0.1557 0.1502 0.1421 0.1344 0.1285 0.1248 0.1220 0.1187 0.1156 0.1127 0.1107 0.1083 0.1067 0.1062 

[TRAIN] Epoch[1](512/1500); Loss: 0.121884; Backpropagation: 0.0940 sec; Batch: 0.4285 sec
0.2257 0.1559 0.1550 0.1555 0.1447 0.1251 0.1130 0.1051 0.0999 0.0961 0.0943 0.0938 0.0943 0.0954 0.0970 0.0995 

[TRAIN] Epoch[1](513/1500); Loss: 0.250669; Backpropagation: 0.0935 sec; Batch: 0.4269 sec
0.5006 0.3913 0.4006 0.3886 0.3535 0.3176 0.2798 0.2450 0.2126 0.1811 0.1540 0.1319 0.1168 0.1119 0.1134 0.1122 

[TRAIN] Epoch[1](514/1500); Loss: 0.209280; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.2965 0.2598 0.2545 0.2468 0.2331 0.2169 0.2057 0.1954 0.1887 0.1832 0.1802 0.1781 0.1770 0.1767 0.1774 0.1786 

[TRAIN] Epoch[1](515/1500); Loss: 0.176574; Backpropagation: 0.1029 sec; Batch: 0.4357 sec
0.2533 0.2292 0.2182 0.2135 0.2020 0.1863 0.1766 0.1668 0.1588 0.1528 0.1478 0.1449 0.1432 0.1431 0.1437 0.1449 

[TRAIN] Epoch[1](516/1500); Loss: 0.168889; Backpropagation: 0.0917 sec; Batch: 0.4244 sec
0.2511 0.1836 0.1795 0.1731 0.1634 0.1566 0.1539 0.1535 0.1542 0.1558 0.1580 0.1603 0.1622 0.1639 0.1657 0.1676 

[TRAIN] Epoch[1](517/1500); Loss: 0.145862; Backpropagation: 0.0919 sec; Batch: 0.4262 sec
0.1977 0.1503 0.1513 0.1465 0.1397 0.1370 0.1362 0.1381 0.1395 0.1404 0.1415 0.1420 0.1428 0.1432 0.1437 0.1440 

[TRAIN] Epoch[1](518/1500); Loss: 0.124058; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2402 0.1686 0.1708 0.1503 0.1238 0.1099 0.1007 0.0981 0.0982 0.0993 0.1011 0.1021 0.1034 0.1050 0.1063 0.1072 

[TRAIN] Epoch[1](519/1500); Loss: 0.098811; Backpropagation: 0.0917 sec; Batch: 0.4321 sec
0.1512 0.1323 0.1253 0.1194 0.1104 0.1045 0.0998 0.0948 0.0901 0.0857 0.0821 0.0789 0.0774 0.0767 0.0763 0.0761 

[TRAIN] Epoch[1](520/1500); Loss: 0.143394; Backpropagation: 0.0917 sec; Batch: 0.4251 sec
0.1939 0.1667 0.1540 0.1484 0.1430 0.1391 0.1369 0.1358 0.1351 0.1343 0.1339 0.1340 0.1343 0.1346 0.1349 0.1355 

[TRAIN] Epoch[1](521/1500); Loss: 0.115916; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2083 0.1436 0.1461 0.1262 0.1095 0.1066 0.1046 0.1026 0.1017 0.1012 0.1005 0.1007 0.1006 0.1006 0.1007 0.1012 

[TRAIN] Epoch[1](522/1500); Loss: 0.119194; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1552 0.1467 0.1375 0.1289 0.1193 0.1143 0.1114 0.1096 0.1083 0.1080 0.1089 0.1101 0.1111 0.1116 0.1125 0.1136 

[TRAIN] Epoch[1](523/1500); Loss: 0.142490; Backpropagation: 0.0917 sec; Batch: 0.4266 sec
0.1999 0.1910 0.1781 0.1654 0.1522 0.1462 0.1410 0.1367 0.1325 0.1288 0.1252 0.1218 0.1190 0.1162 0.1137 0.1120 

[TRAIN] Epoch[1](524/1500); Loss: 0.120597; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2293 0.1977 0.1852 0.1645 0.1414 0.1239 0.1062 0.0946 0.0906 0.0878 0.0859 0.0848 0.0844 0.0846 0.0845 0.0844 

[TRAIN] Epoch[1](525/1500); Loss: 0.099165; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1612 0.1157 0.1146 0.1023 0.0955 0.0923 0.0912 0.0912 0.0910 0.0908 0.0906 0.0903 0.0900 0.0900 0.0899 0.0899 

[TRAIN] Epoch[1](526/1500); Loss: 0.111327; Backpropagation: 0.0985 sec; Batch: 0.4458 sec
0.1702 0.1938 0.1700 0.1601 0.1427 0.1323 0.1206 0.1102 0.1001 0.0904 0.0811 0.0729 0.0657 0.0601 0.0564 0.0546 

[TRAIN] Epoch[1](527/1500); Loss: 0.113493; Backpropagation: 0.0984 sec; Batch: 0.4314 sec
0.1797 0.1361 0.1271 0.1225 0.1156 0.1107 0.1064 0.1035 0.1017 0.1006 0.1000 0.1003 0.1010 0.1020 0.1034 0.1054 

[TRAIN] Epoch[1](528/1500); Loss: 0.117128; Backpropagation: 0.0983 sec; Batch: 0.4319 sec
0.1955 0.1778 0.1552 0.1404 0.1232 0.1171 0.1100 0.1051 0.1002 0.0965 0.0938 0.0919 0.0911 0.0915 0.0922 0.0925 

[TRAIN] Epoch[1](529/1500); Loss: 0.100182; Backpropagation: 0.0987 sec; Batch: 0.4359 sec
0.3493 0.2008 0.1945 0.1338 0.1023 0.0782 0.0562 0.0514 0.0517 0.0518 0.0527 0.0538 0.0550 0.0559 0.0569 0.0588 

[TRAIN] Epoch[1](530/1500); Loss: 0.171408; Backpropagation: 0.0985 sec; Batch: 0.4396 sec
0.2543 0.2012 0.1906 0.1815 0.1750 0.1690 0.1636 0.1611 0.1587 0.1574 0.1564 0.1558 0.1552 0.1546 0.1542 0.1539 

[TRAIN] Epoch[1](531/1500); Loss: 0.098418; Backpropagation: 0.0984 sec; Batch: 0.4306 sec
0.1568 0.1177 0.1137 0.1063 0.0999 0.0960 0.0924 0.0895 0.0878 0.0874 0.0873 0.0874 0.0876 0.0879 0.0882 0.0888 

[TRAIN] Epoch[1](532/1500); Loss: 0.121972; Backpropagation: 0.0984 sec; Batch: 0.4325 sec
0.2804 0.1636 0.1532 0.1204 0.1088 0.1042 0.1013 0.1002 0.1003 0.1011 0.1016 0.1023 0.1024 0.1031 0.1040 0.1047 

[TRAIN] Epoch[1](533/1500); Loss: 0.071554; Backpropagation: 0.0985 sec; Batch: 0.4321 sec
0.1313 0.1690 0.1265 0.1085 0.0730 0.0636 0.0463 0.0394 0.0358 0.0390 0.0465 0.0557 0.0604 0.0526 0.0477 0.0497 

[TRAIN] Epoch[1](534/1500); Loss: 0.145946; Backpropagation: 0.0983 sec; Batch: 0.4324 sec
0.2313 0.1900 0.1730 0.1553 0.1432 0.1380 0.1333 0.1309 0.1289 0.1282 0.1283 0.1291 0.1302 0.1317 0.1323 0.1315 

[TRAIN] Epoch[1](535/1500); Loss: 0.096690; Backpropagation: 0.0984 sec; Batch: 0.4315 sec
0.2286 0.1722 0.1409 0.1106 0.0861 0.0771 0.0768 0.0744 0.0730 0.0723 0.0722 0.0727 0.0730 0.0724 0.0723 0.0727 

[TRAIN] Epoch[1](536/1500); Loss: 0.075827; Backpropagation: 0.1036 sec; Batch: 0.4363 sec
0.0974 0.0867 0.0787 0.0769 0.0742 0.0733 0.0725 0.0721 0.0722 0.0722 0.0722 0.0725 0.0725 0.0728 0.0733 0.0739 

[TRAIN] Epoch[1](537/1500); Loss: 0.108911; Backpropagation: 0.0922 sec; Batch: 0.4258 sec
0.1370 0.1514 0.1282 0.1206 0.1105 0.1078 0.1037 0.1005 0.0973 0.0969 0.0964 0.0971 0.0971 0.0982 0.0994 0.1006 

[TRAIN] Epoch[1](538/1500); Loss: 0.106040; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.4205 0.2832 0.2246 0.1410 0.0742 0.0408 0.0631 0.0562 0.0536 0.0522 0.0507 0.0489 0.0475 0.0469 0.0466 0.0469 

[TRAIN] Epoch[1](539/1500); Loss: 0.123581; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1681 0.1533 0.1362 0.1278 0.1236 0.1209 0.1181 0.1165 0.1151 0.1143 0.1140 0.1140 0.1137 0.1136 0.1138 0.1143 

[TRAIN] Epoch[1](540/1500); Loss: 0.115940; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1793 0.1343 0.1211 0.1158 0.1129 0.1096 0.1083 0.1079 0.1075 0.1075 0.1078 0.1077 0.1080 0.1085 0.1093 0.1096 

[TRAIN] Epoch[1](541/1500); Loss: 0.074335; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2265 0.1123 0.0853 0.0674 0.0629 0.0613 0.0598 0.0586 0.0577 0.0574 0.0568 0.0566 0.0562 0.0564 0.0567 0.0573 

[TRAIN] Epoch[1](542/1500); Loss: 0.075207; Backpropagation: 0.0916 sec; Batch: 0.4309 sec
0.0963 0.0970 0.0783 0.0740 0.0798 0.0754 0.0711 0.0697 0.0694 0.0694 0.0691 0.0692 0.0698 0.0708 0.0718 0.0722 

[TRAIN] Epoch[1](543/1500); Loss: 0.115698; Backpropagation: 0.0921 sec; Batch: 0.4278 sec
0.4291 0.2571 0.1668 0.0942 0.0575 0.1008 0.0896 0.0847 0.0798 0.0769 0.0747 0.0715 0.0686 0.0670 0.0663 0.0664 

[TRAIN] Epoch[1](544/1500); Loss: 0.115355; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1608 0.1443 0.1164 0.1106 0.1186 0.1149 0.1116 0.1084 0.1071 0.1065 0.1067 0.1073 0.1075 0.1078 0.1084 0.1088 

[TRAIN] Epoch[1](545/1500); Loss: 0.117952; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1763 0.1340 0.1257 0.1184 0.1138 0.1117 0.1106 0.1102 0.1098 0.1100 0.1107 0.1108 0.1107 0.1110 0.1115 0.1121 

[TRAIN] Epoch[1](546/1500); Loss: 0.171291; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2623 0.2112 0.1823 0.1714 0.1654 0.1643 0.1619 0.1615 0.1599 0.1590 0.1581 0.1576 0.1574 0.1567 0.1561 0.1555 

[TRAIN] Epoch[1](547/1500); Loss: 0.085681; Backpropagation: 0.0918 sec; Batch: 0.4387 sec
0.3678 0.1899 0.1041 0.0591 0.0584 0.0670 0.0593 0.0545 0.0511 0.0494 0.0492 0.0495 0.0512 0.0526 0.0534 0.0545 

[TRAIN] Epoch[1](548/1500); Loss: 0.102212; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1433 0.1225 0.1053 0.1010 0.0984 0.0967 0.0954 0.0951 0.0952 0.0955 0.0963 0.0967 0.0977 0.0980 0.0989 0.0995 

[TRAIN] Epoch[1](549/1500); Loss: 0.058287; Backpropagation: 0.0919 sec; Batch: 0.4279 sec
0.0819 0.0991 0.0675 0.0617 0.0558 0.0517 0.0499 0.0496 0.0501 0.0507 0.0520 0.0523 0.0519 0.0521 0.0526 0.0537 

[TRAIN] Epoch[1](550/1500); Loss: 0.106156; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2873 0.1992 0.1381 0.1011 0.0813 0.0974 0.0885 0.0840 0.0802 0.0770 0.0758 0.0757 0.0764 0.0778 0.0794 0.0790 

[TRAIN] Epoch[1](551/1500); Loss: 0.095682; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.4036 0.2444 0.1482 0.0803 0.0467 0.0793 0.0668 0.0605 0.0539 0.0491 0.0469 0.0460 0.0479 0.0504 0.0525 0.0545 

[TRAIN] Epoch[1](552/1500); Loss: 0.109273; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.3030 0.1819 0.1483 0.1171 0.0983 0.0869 0.0831 0.0820 0.0811 0.0804 0.0800 0.0804 0.0804 0.0808 0.0819 0.0829 

[TRAIN] Epoch[1](553/1500); Loss: 0.116988; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2605 0.1827 0.1383 0.1218 0.1089 0.1051 0.1042 0.1007 0.0977 0.0956 0.0943 0.0936 0.0930 0.0921 0.0918 0.0915 

[TRAIN] Epoch[1](554/1500); Loss: 0.059654; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1332 0.0818 0.0590 0.0566 0.0627 0.0543 0.0521 0.0501 0.0498 0.0504 0.0506 0.0506 0.0501 0.0504 0.0512 0.0516 

[TRAIN] Epoch[1](555/1500); Loss: 0.105590; Backpropagation: 0.0919 sec; Batch: 0.4283 sec
0.2417 0.1716 0.1373 0.1281 0.1075 0.1035 0.0931 0.0879 0.0828 0.0797 0.0773 0.0767 0.0756 0.0758 0.0756 0.0750 

[TRAIN] Epoch[1](556/1500); Loss: 0.103346; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.1699 0.1256 0.1085 0.1035 0.1004 0.0989 0.0978 0.0966 0.0950 0.0939 0.0936 0.0937 0.0940 0.0942 0.0941 0.0937 

[TRAIN] Epoch[1](557/1500); Loss: 0.106025; Backpropagation: 0.0921 sec; Batch: 0.4281 sec
0.1338 0.1345 0.1173 0.1120 0.1070 0.1035 0.1009 0.0995 0.0985 0.0977 0.0976 0.0980 0.0987 0.0992 0.0992 0.0990 

[TRAIN] Epoch[1](558/1500); Loss: 0.055273; Backpropagation: 0.0919 sec; Batch: 0.4257 sec
0.1187 0.0763 0.0579 0.0561 0.0529 0.0498 0.0483 0.0474 0.0471 0.0472 0.0473 0.0474 0.0468 0.0470 0.0467 0.0477 

[TRAIN] Epoch[1](559/1500); Loss: 0.100370; Backpropagation: 0.0994 sec; Batch: 0.4337 sec
0.2008 0.1552 0.1197 0.1145 0.0969 0.0928 0.0892 0.0858 0.0841 0.0836 0.0830 0.0815 0.0805 0.0801 0.0793 0.0791 

[TRAIN] Epoch[1](560/1500); Loss: 0.102433; Backpropagation: 0.0983 sec; Batch: 0.4315 sec
0.1716 0.1587 0.1209 0.1114 0.0981 0.0952 0.0898 0.0876 0.0871 0.0866 0.0866 0.0871 0.0878 0.0892 0.0906 0.0906 

[TRAIN] Epoch[1](561/1500); Loss: 0.074740; Backpropagation: 0.0984 sec; Batch: 0.4323 sec
0.1178 0.0988 0.0863 0.0789 0.0738 0.0709 0.0686 0.0672 0.0665 0.0665 0.0667 0.0662 0.0661 0.0667 0.0672 0.0676 

[TRAIN] Epoch[1](562/1500); Loss: 0.059132; Backpropagation: 0.0983 sec; Batch: 0.4310 sec
0.0820 0.0944 0.0739 0.0653 0.0700 0.0599 0.0533 0.0499 0.0492 0.0493 0.0500 0.0505 0.0492 0.0494 0.0495 0.0501 

[TRAIN] Epoch[1](563/1500); Loss: 0.114860; Backpropagation: 0.0984 sec; Batch: 0.4320 sec
0.1943 0.1240 0.1201 0.1132 0.1115 0.1094 0.1085 0.1071 0.1063 0.1056 0.1054 0.1060 0.1060 0.1060 0.1071 0.1073 

[TRAIN] Epoch[1](564/1500); Loss: 0.128707; Backpropagation: 0.0983 sec; Batch: 0.4321 sec
0.1809 0.1607 0.1489 0.1368 0.1318 0.1272 0.1229 0.1200 0.1179 0.1169 0.1165 0.1166 0.1161 0.1155 0.1153 0.1153 

[TRAIN] Epoch[1](565/1500); Loss: 0.081579; Backpropagation: 0.0922 sec; Batch: 0.4278 sec
0.1414 0.0995 0.0936 0.0839 0.0807 0.0784 0.0757 0.0747 0.0739 0.0732 0.0727 0.0721 0.0716 0.0715 0.0713 0.0711 

[TRAIN] Epoch[1](566/1500); Loss: 0.085668; Backpropagation: 0.0927 sec; Batch: 0.4256 sec
0.1167 0.1195 0.1058 0.0931 0.0861 0.0826 0.0793 0.0773 0.0759 0.0757 0.0759 0.0758 0.0761 0.0763 0.0766 0.0780 

[TRAIN] Epoch[1](567/1500); Loss: 0.068127; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2474 0.0879 0.0703 0.0596 0.0540 0.0506 0.0486 0.0481 0.0495 0.0506 0.0527 0.0532 0.0538 0.0539 0.0540 0.0559 

[TRAIN] Epoch[1](568/1500); Loss: 0.125776; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1586 0.1439 0.1449 0.1337 0.1289 0.1228 0.1201 0.1193 0.1183 0.1175 0.1174 0.1171 0.1171 0.1175 0.1178 0.1177 

[TRAIN] Epoch[1](569/1500); Loss: 0.089770; Backpropagation: 0.0921 sec; Batch: 0.4266 sec
0.1385 0.1396 0.1120 0.1003 0.0977 0.0867 0.0794 0.0775 0.0768 0.0759 0.0752 0.0750 0.0753 0.0752 0.0753 0.0760 

[TRAIN] Epoch[1](570/1500); Loss: 0.097006; Backpropagation: 0.0916 sec; Batch: 0.4425 sec
0.1695 0.1098 0.1112 0.0993 0.0954 0.0904 0.0889 0.0874 0.0869 0.0869 0.0873 0.0875 0.0880 0.0879 0.0878 0.0877 

[TRAIN] Epoch[1](571/1500); Loss: 0.079624; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1619 0.1121 0.1069 0.0933 0.0802 0.0730 0.0692 0.0674 0.0654 0.0642 0.0635 0.0634 0.0630 0.0635 0.0634 0.0637 

[TRAIN] Epoch[1](572/1500); Loss: 0.151810; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2287 0.1712 0.1856 0.1745 0.1580 0.1483 0.1438 0.1401 0.1369 0.1349 0.1343 0.1341 0.1341 0.1345 0.1348 0.1352 

[TRAIN] Epoch[1](573/1500); Loss: 0.113684; Backpropagation: 0.0919 sec; Batch: 0.4257 sec
0.1932 0.1241 0.1577 0.1455 0.1331 0.1145 0.1042 0.1012 0.0981 0.0948 0.0924 0.0916 0.0914 0.0916 0.0924 0.0932 

[TRAIN] Epoch[1](574/1500); Loss: 0.126415; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2398 0.2445 0.1704 0.1332 0.1123 0.1118 0.1024 0.0979 0.0975 0.1007 0.1013 0.1002 0.1005 0.1016 0.1037 0.1047 

[TRAIN] Epoch[1](575/1500); Loss: 0.148933; Backpropagation: 0.0921 sec; Batch: 0.4309 sec
0.1928 0.1800 0.1819 0.1668 0.1544 0.1486 0.1445 0.1406 0.1364 0.1348 0.1334 0.1323 0.1326 0.1336 0.1347 0.1356 

[TRAIN] Epoch[1](576/1500); Loss: 0.138998; Backpropagation: 0.0919 sec; Batch: 0.4255 sec
0.2828 0.1885 0.2253 0.1918 0.1483 0.1327 0.1240 0.1178 0.1112 0.1070 0.1025 0.1000 0.0987 0.0982 0.0974 0.0977 

[TRAIN] Epoch[1](577/1500); Loss: 0.074444; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1261 0.0930 0.0931 0.0823 0.0765 0.0724 0.0695 0.0669 0.0657 0.0641 0.0635 0.0636 0.0635 0.0634 0.0635 0.0640 

[TRAIN] Epoch[1](578/1500); Loss: 0.152289; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2258 0.1959 0.2036 0.1600 0.1541 0.1424 0.1391 0.1370 0.1346 0.1352 0.1350 0.1345 0.1344 0.1345 0.1351 0.1354 

[TRAIN] Epoch[1](579/1500); Loss: 0.122586; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.1576 0.1561 0.1317 0.1225 0.1383 0.1282 0.1192 0.1160 0.1130 0.1132 0.1118 0.1114 0.1111 0.1109 0.1103 0.1103 

[TRAIN] Epoch[1](580/1500); Loss: 0.128335; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2251 0.1791 0.1726 0.1423 0.1234 0.1139 0.1134 0.1113 0.1103 0.1096 0.1093 0.1086 0.1083 0.1084 0.1088 0.1089 

[TRAIN] Epoch[1](581/1500); Loss: 0.132714; Backpropagation: 0.0920 sec; Batch: 0.4264 sec
0.1816 0.1699 0.1619 0.1434 0.1362 0.1285 0.1248 0.1229 0.1208 0.1207 0.1201 0.1191 0.1185 0.1184 0.1184 0.1184 

[TRAIN] Epoch[1](582/1500); Loss: 0.135530; Backpropagation: 0.0917 sec; Batch: 0.4308 sec
0.2101 0.1685 0.0997 0.1228 0.1357 0.1357 0.1360 0.1313 0.1318 0.1295 0.1275 0.1278 0.1274 0.1283 0.1279 0.1284 

[TRAIN] Epoch[1](583/1500); Loss: 0.129139; Backpropagation: 0.0920 sec; Batch: 0.4275 sec
0.2247 0.1748 0.1740 0.1479 0.1301 0.1186 0.1124 0.1102 0.1098 0.1092 0.1088 0.1088 0.1090 0.1091 0.1093 0.1095 

[TRAIN] Epoch[1](584/1500); Loss: 0.155646; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1859 0.1805 0.1746 0.1634 0.1794 0.1682 0.1556 0.1473 0.1444 0.1428 0.1423 0.1419 0.1414 0.1410 0.1408 0.1408 

[TRAIN] Epoch[1](585/1500); Loss: 0.077813; Backpropagation: 0.0917 sec; Batch: 0.4251 sec
0.1650 0.0937 0.0823 0.0700 0.0757 0.0701 0.0666 0.0642 0.0647 0.0653 0.0662 0.0676 0.0696 0.0718 0.0745 0.0776 

[TRAIN] Epoch[1](586/1500); Loss: 0.093471; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0998 0.1126 0.0980 0.0944 0.1085 0.1008 0.0932 0.0874 0.0858 0.0858 0.0866 0.0870 0.0874 0.0885 0.0894 0.0905 

[TRAIN] Epoch[1](587/1500); Loss: 0.122844; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1887 0.1400 0.1445 0.1281 0.1212 0.1167 0.1118 0.1095 0.1087 0.1094 0.1109 0.1119 0.1134 0.1148 0.1166 0.1191 

[TRAIN] Epoch[1](588/1500); Loss: 0.221599; Backpropagation: 0.0916 sec; Batch: 0.4253 sec
0.2219 0.2020 0.1808 0.1681 0.2506 0.2873 0.3033 0.2843 0.2555 0.2346 0.2165 0.1984 0.1874 0.1833 0.1852 0.1864 

[TRAIN] Epoch[1](589/1500); Loss: 0.177682; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2064 0.2111 0.1900 0.1639 0.1865 0.2189 0.2332 0.2190 0.1919 0.1711 0.1552 0.1424 0.1389 0.1379 0.1381 0.1386 

[TRAIN] Epoch[1](590/1500); Loss: 0.096411; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1205 0.1193 0.1043 0.1083 0.1256 0.1183 0.1028 0.0918 0.0855 0.0821 0.0806 0.0802 0.0803 0.0807 0.0809 0.0814 

[TRAIN] Epoch[1](591/1500); Loss: 0.053492; Backpropagation: 0.0918 sec; Batch: 0.4329 sec
0.0811 0.0725 0.0614 0.0515 0.0492 0.0475 0.0468 0.0462 0.0465 0.0469 0.0478 0.0489 0.0503 0.0518 0.0529 0.0546 

[TRAIN] Epoch[1](592/1500); Loss: 0.104803; Backpropagation: 0.0915 sec; Batch: 0.4282 sec
0.1890 0.1735 0.1547 0.1156 0.0889 0.0878 0.1001 0.0990 0.0910 0.0837 0.0806 0.0805 0.0816 0.0821 0.0832 0.0857 

[TRAIN] Epoch[1](593/1500); Loss: 0.093935; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1997 0.1880 0.1637 0.1250 0.0949 0.0698 0.0629 0.0607 0.0610 0.0624 0.0639 0.0657 0.0677 0.0700 0.0725 0.0750 

[TRAIN] Epoch[1](594/1500); Loss: 0.134751; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.1541 0.1494 0.1440 0.1397 0.1430 0.1394 0.1342 0.1301 0.1292 0.1287 0.1283 0.1278 0.1273 0.1270 0.1268 0.1270 

[TRAIN] Epoch[1](595/1500); Loss: 0.144194; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1792 0.1627 0.1538 0.1486 0.1422 0.1389 0.1380 0.1376 0.1373 0.1373 0.1374 0.1378 0.1382 0.1387 0.1393 0.1402 

[TRAIN] Epoch[1](596/1500); Loss: 0.148851; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1751 0.1722 0.1618 0.1536 0.1661 0.1696 0.1658 0.1503 0.1388 0.1338 0.1318 0.1314 0.1317 0.1325 0.1333 0.1339 

[TRAIN] Epoch[1](597/1500); Loss: 0.122665; Backpropagation: 0.0921 sec; Batch: 0.4262 sec
0.1470 0.1456 0.1370 0.1292 0.1254 0.1220 0.1183 0.1155 0.1150 0.1149 0.1147 0.1149 0.1153 0.1155 0.1158 0.1166 

[TRAIN] Epoch[1](598/1500); Loss: 0.084229; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1404 0.1288 0.1103 0.0962 0.0857 0.0776 0.0711 0.0685 0.0685 0.0688 0.0693 0.0699 0.0710 0.0723 0.0738 0.0755 

[TRAIN] Epoch[1](599/1500); Loss: 0.107393; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1922 0.2080 0.1781 0.1312 0.1002 0.0885 0.0819 0.0802 0.0795 0.0792 0.0802 0.0811 0.0821 0.0837 0.0854 0.0868 

[TRAIN] Epoch[1](600/1500); Loss: 0.064374; Backpropagation: 0.0918 sec; Batch: 0.4355 sec
0.0889 0.1088 0.0822 0.0625 0.0569 0.0539 0.0550 0.0553 0.0555 0.0559 0.0567 0.0576 0.0586 0.0597 0.0607 0.0618 

[TRAIN] Epoch[1](601/1500); Loss: 0.142426; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2091 0.1958 0.1815 0.1661 0.1538 0.1400 0.1297 0.1252 0.1238 0.1227 0.1221 0.1217 0.1216 0.1217 0.1220 0.1222 

[TRAIN] Epoch[1](602/1500); Loss: 0.072540; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0954 0.1029 0.0778 0.0617 0.0637 0.0660 0.0715 0.0713 0.0700 0.0665 0.0656 0.0670 0.0682 0.0695 0.0712 0.0723 

[TRAIN] Epoch[1](603/1500); Loss: 0.076668; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1732 0.2390 0.1905 0.1188 0.0504 0.0371 0.0362 0.0367 0.0394 0.0402 0.0409 0.0418 0.0430 0.0447 0.0464 0.0483 

[TRAIN] Epoch[1](604/1500); Loss: 0.090561; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1608 0.1801 0.1445 0.1059 0.0768 0.0699 0.0688 0.0718 0.0714 0.0705 0.0700 0.0701 0.0707 0.0714 0.0724 0.0738 

[TRAIN] Epoch[1](605/1500); Loss: 0.131870; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.1704 0.1661 0.1538 0.1399 0.1297 0.1279 0.1270 0.1258 0.1233 0.1216 0.1211 0.1211 0.1208 0.1205 0.1204 0.1205 

[TRAIN] Epoch[1](606/1500); Loss: 0.131325; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1338 0.1416 0.1289 0.1260 0.1319 0.1287 0.1278 0.1282 0.1286 0.1293 0.1300 0.1309 0.1320 0.1331 0.1345 0.1359 

[TRAIN] Epoch[1](607/1500); Loss: 0.136507; Backpropagation: 0.0917 sec; Batch: 0.4629 sec
0.1641 0.1622 0.1477 0.1390 0.1323 0.1320 0.1313 0.1309 0.1307 0.1306 0.1305 0.1304 0.1305 0.1306 0.1306 0.1307 

[TRAIN] Epoch[1](608/1500); Loss: 0.057078; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.0744 0.0669 0.0628 0.0563 0.0530 0.0528 0.0530 0.0533 0.0537 0.0537 0.0539 0.0545 0.0554 0.0558 0.0565 0.0574 

[TRAIN] Epoch[1](609/1500); Loss: 0.132460; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1612 0.1638 0.1416 0.1388 0.1471 0.1340 0.1248 0.1228 0.1224 0.1226 0.1227 0.1229 0.1233 0.1235 0.1238 0.1242 

[TRAIN] Epoch[1](610/1500); Loss: 0.121330; Backpropagation: 0.0916 sec; Batch: 0.4600 sec
0.1522 0.1572 0.1427 0.1294 0.1208 0.1165 0.1144 0.1134 0.1128 0.1124 0.1118 0.1115 0.1114 0.1116 0.1116 0.1116 

[TRAIN] Epoch[1](611/1500); Loss: 0.112237; Backpropagation: 0.0919 sec; Batch: 0.4561 sec
0.1420 0.1303 0.1141 0.1099 0.1096 0.1089 0.1078 0.1074 0.1072 0.1072 0.1076 0.1080 0.1083 0.1087 0.1091 0.1097 

[TRAIN] Epoch[1](612/1500); Loss: 0.073273; Backpropagation: 0.0918 sec; Batch: 0.4311 sec
0.0966 0.0885 0.0808 0.0746 0.0720 0.0709 0.0697 0.0692 0.0690 0.0688 0.0686 0.0684 0.0685 0.0686 0.0688 0.0692 

[TRAIN] Epoch[1](613/1500); Loss: 0.059006; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1329 0.1886 0.1326 0.0545 0.0526 0.0380 0.0355 0.0360 0.0363 0.0347 0.0328 0.0322 0.0325 0.0335 0.0351 0.0362 

[TRAIN] Epoch[1](614/1500); Loss: 0.096279; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1151 0.1166 0.0977 0.0942 0.1044 0.0974 0.0933 0.0930 0.0923 0.0920 0.0915 0.0909 0.0905 0.0903 0.0904 0.0907 

[TRAIN] Epoch[1](615/1500); Loss: 0.094024; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1322 0.1370 0.1214 0.1032 0.0910 0.0883 0.0871 0.0853 0.0841 0.0835 0.0831 0.0825 0.0819 0.0814 0.0813 0.0812 

[TRAIN] Epoch[1](616/1500); Loss: 0.073205; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1158 0.0865 0.0777 0.0738 0.0711 0.0696 0.0685 0.0679 0.0674 0.0672 0.0672 0.0673 0.0674 0.0675 0.0680 0.0684 

[TRAIN] Epoch[1](617/1500); Loss: 0.080559; Backpropagation: 0.0920 sec; Batch: 0.4293 sec
0.1102 0.1094 0.0931 0.0837 0.0792 0.0766 0.0760 0.0753 0.0745 0.0740 0.0735 0.0730 0.0728 0.0726 0.0726 0.0725 

[TRAIN] Epoch[1](618/1500); Loss: 0.082820; Backpropagation: 0.0918 sec; Batch: 0.4356 sec
0.1150 0.1056 0.0877 0.0853 0.0816 0.0798 0.0780 0.0773 0.0769 0.0768 0.0768 0.0768 0.0768 0.0768 0.0769 0.0771 

[TRAIN] Epoch[1](619/1500); Loss: 0.142182; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1619 0.1593 0.1464 0.1437 0.1417 0.1403 0.1392 0.1388 0.1385 0.1382 0.1378 0.1377 0.1378 0.1379 0.1378 0.1377 

[TRAIN] Epoch[1](620/1500); Loss: 0.060339; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.0824 0.0827 0.0695 0.0575 0.0548 0.0548 0.0549 0.0552 0.0555 0.0560 0.0561 0.0562 0.0566 0.0573 0.0578 0.0582 

[TRAIN] Epoch[1](621/1500); Loss: 0.141811; Backpropagation: 0.0919 sec; Batch: 0.4249 sec
0.1630 0.1649 0.1586 0.1492 0.1400 0.1387 0.1372 0.1360 0.1356 0.1353 0.1350 0.1350 0.1351 0.1351 0.1351 0.1350 

[TRAIN] Epoch[1](622/1500); Loss: 0.059430; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0916 0.0907 0.0649 0.0598 0.0645 0.0587 0.0569 0.0539 0.0519 0.0511 0.0506 0.0503 0.0505 0.0511 0.0519 0.0524 

[TRAIN] Epoch[1](623/1500); Loss: 0.145685; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1857 0.1875 0.1741 0.1619 0.1513 0.1443 0.1392 0.1357 0.1338 0.1325 0.1320 0.1315 0.1309 0.1305 0.1301 0.1299 

[TRAIN] Epoch[1](624/1500); Loss: 0.143477; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1969 0.1917 0.1779 0.1650 0.1511 0.1391 0.1321 0.1280 0.1265 0.1268 0.1270 0.1270 0.1266 0.1263 0.1265 0.1269 

[TRAIN] Epoch[1](625/1500); Loss: 0.155741; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1645 0.1655 0.1609 0.1605 0.1603 0.1551 0.1532 0.1530 0.1528 0.1525 0.1522 0.1520 0.1521 0.1522 0.1525 0.1526 

[TRAIN] Epoch[1](626/1500); Loss: 0.122751; Backpropagation: 0.0918 sec; Batch: 0.4252 sec
0.1577 0.1514 0.1399 0.1298 0.1214 0.1189 0.1176 0.1163 0.1152 0.1146 0.1142 0.1137 0.1134 0.1132 0.1133 0.1133 

[TRAIN] Epoch[1](627/1500); Loss: 0.046792; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.0611 0.0711 0.0567 0.0479 0.0521 0.0484 0.0453 0.0405 0.0397 0.0398 0.0400 0.0402 0.0405 0.0411 0.0419 0.0425 

[TRAIN] Epoch[1](628/1500); Loss: 0.154294; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2276 0.2447 0.2098 0.1775 0.1453 0.1368 0.1326 0.1302 0.1321 0.1330 0.1330 0.1330 0.1326 0.1329 0.1335 0.1340 

[TRAIN] Epoch[1](629/1500); Loss: 0.134599; Backpropagation: 0.0923 sec; Batch: 0.4235 sec
0.1676 0.1663 0.1521 0.1388 0.1339 0.1284 0.1274 0.1287 0.1289 0.1270 0.1263 0.1257 0.1257 0.1258 0.1256 0.1253 

[TRAIN] Epoch[1](630/1500); Loss: 0.127617; Backpropagation: 0.0918 sec; Batch: 0.4254 sec
0.1779 0.1543 0.1410 0.1304 0.1260 0.1220 0.1206 0.1194 0.1188 0.1185 0.1184 0.1184 0.1185 0.1191 0.1192 0.1194 

[TRAIN] Epoch[1](631/1500); Loss: 0.071672; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0972 0.1075 0.0904 0.0741 0.0678 0.0658 0.0653 0.0644 0.0639 0.0637 0.0639 0.0639 0.0641 0.0646 0.0649 0.0653 

[TRAIN] Epoch[1](632/1500); Loss: 0.057782; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1124 0.0854 0.0692 0.0592 0.0551 0.0530 0.0520 0.0496 0.0477 0.0477 0.0481 0.0484 0.0486 0.0489 0.0493 0.0500 

[TRAIN] Epoch[1](633/1500); Loss: 0.106149; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1249 0.1157 0.1125 0.1114 0.1079 0.1033 0.1026 0.1023 0.1018 0.1016 0.1017 0.1020 0.1022 0.1025 0.1029 0.1033 

[TRAIN] Epoch[1](634/1500); Loss: 0.082145; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1784 0.1443 0.1225 0.0880 0.0735 0.0669 0.0675 0.0653 0.0642 0.0635 0.0631 0.0631 0.0632 0.0634 0.0635 0.0640 

[TRAIN] Epoch[1](635/1500); Loss: 0.097709; Backpropagation: 0.0917 sec; Batch: 0.4573 sec
0.2293 0.1414 0.1384 0.1040 0.0875 0.0816 0.0793 0.0778 0.0770 0.0771 0.0775 0.0779 0.0783 0.0784 0.0787 0.0791 

[TRAIN] Epoch[1](636/1500); Loss: 0.141001; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2283 0.1955 0.1890 0.1673 0.1530 0.1420 0.1338 0.1256 0.1221 0.1192 0.1171 0.1154 0.1139 0.1126 0.1112 0.1100 

[TRAIN] Epoch[1](637/1500); Loss: 0.090662; Backpropagation: 0.0916 sec; Batch: 0.4594 sec
0.1248 0.1027 0.0968 0.0921 0.0876 0.0864 0.0858 0.0857 0.0858 0.0857 0.0856 0.0858 0.0860 0.0862 0.0867 0.0870 

[TRAIN] Epoch[1](638/1500); Loss: 0.110932; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1946 0.1702 0.1550 0.1413 0.1313 0.1076 0.0908 0.0899 0.0881 0.0871 0.0861 0.0855 0.0858 0.0866 0.0873 0.0877 

[TRAIN] Epoch[1](639/1500); Loss: 0.082270; Backpropagation: 0.0919 sec; Batch: 0.4419 sec
0.1465 0.1123 0.0960 0.0835 0.0789 0.0764 0.0747 0.0727 0.0721 0.0719 0.0716 0.0714 0.0716 0.0718 0.0722 0.0725 

[TRAIN] Epoch[1](640/1500); Loss: 0.113843; Backpropagation: 0.0918 sec; Batch: 0.4275 sec
0.1796 0.1674 0.1460 0.1238 0.1223 0.1159 0.1096 0.1021 0.0970 0.0945 0.0939 0.0936 0.0935 0.0939 0.0941 0.0943 

[TRAIN] Epoch[1](641/1500); Loss: 0.145812; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1886 0.1681 0.1630 0.1576 0.1537 0.1457 0.1403 0.1372 0.1361 0.1353 0.1350 0.1347 0.1345 0.1343 0.1344 0.1344 

[TRAIN] Epoch[1](642/1500); Loss: 0.123841; Backpropagation: 0.0916 sec; Batch: 0.4623 sec
0.1880 0.1669 0.1523 0.1421 0.1385 0.1315 0.1217 0.1144 0.1090 0.1066 0.1041 0.1022 0.1014 0.1011 0.1009 0.1009 

[TRAIN] Epoch[1](643/1500); Loss: 0.117670; Backpropagation: 0.0917 sec; Batch: 0.4350 sec
0.2264 0.1417 0.1441 0.1229 0.1077 0.1041 0.1046 0.1043 0.1037 0.1033 0.1034 0.1034 0.1031 0.1031 0.1033 0.1036 

[TRAIN] Epoch[1](644/1500); Loss: 0.076525; Backpropagation: 0.0938 sec; Batch: 0.4285 sec
0.2046 0.0974 0.1044 0.0828 0.0693 0.0649 0.0617 0.0600 0.0596 0.0594 0.0593 0.0596 0.0598 0.0601 0.0605 0.0609 

[TRAIN] Epoch[1](645/1500); Loss: 0.203226; Backpropagation: 0.0935 sec; Batch: 0.4265 sec
0.3011 0.3122 0.2717 0.2195 0.1711 0.1744 0.1769 0.1845 0.1860 0.1788 0.1762 0.1780 0.1795 0.1795 0.1803 0.1820 

[TRAIN] Epoch[1](646/1500); Loss: 0.079147; Backpropagation: 0.0933 sec; Batch: 0.4452 sec
0.1555 0.1082 0.1029 0.0866 0.0737 0.0705 0.0695 0.0693 0.0683 0.0674 0.0666 0.0662 0.0658 0.0654 0.0653 0.0653 

[TRAIN] Epoch[1](647/1500); Loss: 0.094565; Backpropagation: 0.0938 sec; Batch: 0.4259 sec
0.1914 0.1403 0.1327 0.1117 0.0984 0.0878 0.0804 0.0778 0.0767 0.0754 0.0742 0.0737 0.0734 0.0732 0.0731 0.0730 

[TRAIN] Epoch[1](648/1500); Loss: 0.121020; Backpropagation: 0.0917 sec; Batch: 0.4252 sec
0.2315 0.1938 0.1754 0.1504 0.1392 0.1256 0.1076 0.0938 0.0915 0.0906 0.0901 0.0898 0.0893 0.0893 0.0892 0.0892 

[TRAIN] Epoch[1](649/1500); Loss: 0.126265; Backpropagation: 0.0915 sec; Batch: 0.4266 sec
0.2055 0.2115 0.1863 0.1588 0.1336 0.1145 0.1028 0.0987 0.1048 0.1058 0.1018 0.0990 0.0992 0.0992 0.0993 0.0996 

[TRAIN] Epoch[1](650/1500); Loss: 0.117632; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1690 0.1394 0.1311 0.1218 0.1166 0.1127 0.1107 0.1096 0.1092 0.1090 0.1089 0.1087 0.1087 0.1087 0.1089 0.1090 

[TRAIN] Epoch[1](651/1500); Loss: 0.089567; Backpropagation: 0.0916 sec; Batch: 0.4226 sec
0.1898 0.1319 0.1245 0.1049 0.0874 0.0822 0.0791 0.0744 0.0721 0.0710 0.0701 0.0694 0.0691 0.0690 0.0690 0.0691 

[TRAIN] Epoch[1](652/1500); Loss: 0.141326; Backpropagation: 0.0914 sec; Batch: 0.4302 sec
0.1596 0.1642 0.1490 0.1488 0.1517 0.1444 0.1397 0.1355 0.1342 0.1336 0.1334 0.1336 0.1336 0.1334 0.1333 0.1332 

[TRAIN] Epoch[1](653/1500); Loss: 0.110090; Backpropagation: 0.0917 sec; Batch: 0.4470 sec
0.2153 0.1355 0.1323 0.1120 0.1099 0.1044 0.0996 0.0970 0.0960 0.0954 0.0947 0.0944 0.0940 0.0938 0.0935 0.0935 

[TRAIN] Epoch[1](654/1500); Loss: 0.079218; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3006 0.1515 0.1508 0.0979 0.0644 0.0513 0.0518 0.0485 0.0460 0.0440 0.0432 0.0429 0.0429 0.0432 0.0438 0.0446 

[TRAIN] Epoch[1](655/1500); Loss: 0.083526; Backpropagation: 0.0916 sec; Batch: 0.4632 sec
0.1997 0.1089 0.1073 0.0884 0.0789 0.0748 0.0721 0.0697 0.0686 0.0676 0.0670 0.0669 0.0669 0.0666 0.0665 0.0666 

[TRAIN] Epoch[1](656/1500); Loss: 0.102100; Backpropagation: 0.0917 sec; Batch: 0.4273 sec
0.3024 0.1565 0.1464 0.0998 0.0783 0.0807 0.0789 0.0772 0.0761 0.0757 0.0757 0.0758 0.0764 0.0772 0.0775 0.0790 

[TRAIN] Epoch[1](657/1500); Loss: 0.123587; Backpropagation: 0.0916 sec; Batch: 0.4423 sec
0.1916 0.1681 0.1507 0.1324 0.1272 0.1191 0.1130 0.1121 0.1106 0.1087 0.1078 0.1075 0.1072 0.1070 0.1070 0.1072 

[TRAIN] Epoch[1](658/1500); Loss: 0.110538; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1515 0.1341 0.1198 0.1143 0.1127 0.1092 0.1056 0.1038 0.1031 0.1027 0.1025 0.1021 0.1018 0.1016 0.1019 0.1020 

[TRAIN] Epoch[1](659/1500); Loss: 0.146998; Backpropagation: 0.0919 sec; Batch: 0.4284 sec
0.1973 0.1713 0.1613 0.1494 0.1455 0.1418 0.1396 0.1390 0.1383 0.1382 0.1384 0.1386 0.1385 0.1383 0.1382 0.1380 

[TRAIN] Epoch[1](660/1500); Loss: 0.076177; Backpropagation: 0.0918 sec; Batch: 0.4259 sec
0.1381 0.1079 0.0982 0.0846 0.0772 0.0727 0.0686 0.0657 0.0650 0.0640 0.0635 0.0630 0.0627 0.0627 0.0624 0.0626 

[TRAIN] Epoch[1](661/1500); Loss: 0.121851; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.1987 0.1493 0.1413 0.1267 0.1188 0.1142 0.1110 0.1116 0.1121 0.1112 0.1102 0.1096 0.1093 0.1089 0.1085 0.1083 

[TRAIN] Epoch[1](662/1500); Loss: 0.088052; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1152 0.1119 0.1001 0.0936 0.0884 0.0858 0.0837 0.0820 0.0811 0.0807 0.0806 0.0807 0.0809 0.0811 0.0813 0.0818 

[TRAIN] Epoch[1](663/1500); Loss: 0.099463; Backpropagation: 0.0917 sec; Batch: 0.4263 sec
0.3476 0.2057 0.1694 0.1015 0.0642 0.0619 0.0631 0.0654 0.0650 0.0644 0.0636 0.0636 0.0637 0.0638 0.0640 0.0644 

[TRAIN] Epoch[1](664/1500); Loss: 0.096750; Backpropagation: 0.0920 sec; Batch: 0.4271 sec
0.1737 0.1234 0.1107 0.0963 0.0926 0.0904 0.0883 0.0869 0.0866 0.0858 0.0853 0.0852 0.0853 0.0856 0.0858 0.0858 

[TRAIN] Epoch[1](665/1500); Loss: 0.079349; Backpropagation: 0.0921 sec; Batch: 0.4272 sec
0.3569 0.2062 0.1577 0.0774 0.0444 0.0381 0.0385 0.0416 0.0401 0.0391 0.0374 0.0369 0.0373 0.0388 0.0391 0.0398 

[TRAIN] Epoch[1](666/1500); Loss: 0.086767; Backpropagation: 0.0928 sec; Batch: 0.4244 sec
0.1517 0.1163 0.1041 0.0920 0.0914 0.0832 0.0793 0.0772 0.0759 0.0750 0.0745 0.0741 0.0735 0.0734 0.0734 0.0733 

[TRAIN] Epoch[1](667/1500); Loss: 0.082151; Backpropagation: 0.0917 sec; Batch: 0.4297 sec
0.1321 0.1007 0.0901 0.0825 0.0795 0.0774 0.0764 0.0755 0.0746 0.0744 0.0741 0.0743 0.0747 0.0756 0.0759 0.0765 

[TRAIN] Epoch[1](668/1500); Loss: 0.107634; Backpropagation: 0.0915 sec; Batch: 0.4266 sec
0.2503 0.1761 0.1641 0.1325 0.1082 0.0952 0.0871 0.0841 0.0837 0.0812 0.0788 0.0772 0.0765 0.0760 0.0757 0.0756 

[TRAIN] Epoch[1](669/1500); Loss: 0.126352; Backpropagation: 0.0916 sec; Batch: 0.4273 sec
0.1826 0.1426 0.1355 0.1273 0.1220 0.1204 0.1197 0.1192 0.1188 0.1185 0.1184 0.1185 0.1188 0.1192 0.1198 0.1204 

[TRAIN] Epoch[1](670/1500); Loss: 0.068304; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1618 0.0857 0.0763 0.0682 0.0647 0.0617 0.0599 0.0581 0.0568 0.0565 0.0568 0.0569 0.0571 0.0573 0.0574 0.0575 

[TRAIN] Epoch[1](671/1500); Loss: 0.118106; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1905 0.1860 0.1459 0.1221 0.1323 0.1221 0.1110 0.0998 0.0969 0.0971 0.0971 0.0972 0.0973 0.0976 0.0980 0.0989 

[TRAIN] Epoch[1](672/1500); Loss: 0.111076; Backpropagation: 0.0916 sec; Batch: 0.4261 sec
0.1262 0.1350 0.1184 0.1114 0.1222 0.1168 0.1079 0.1046 0.1040 0.1039 0.1038 0.1043 0.1044 0.1045 0.1046 0.1052 

[TRAIN] Epoch[1](673/1500); Loss: 0.111773; Backpropagation: 0.0919 sec; Batch: 0.4274 sec
0.1848 0.1730 0.1450 0.1154 0.1156 0.1168 0.1108 0.0966 0.0909 0.0901 0.0902 0.0910 0.0914 0.0916 0.0922 0.0928 

[TRAIN] Epoch[1](674/1500); Loss: 0.146640; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1770 0.1728 0.1595 0.1524 0.1461 0.1433 0.1416 0.1407 0.1402 0.1396 0.1393 0.1392 0.1388 0.1387 0.1386 0.1384 

[TRAIN] Epoch[1](675/1500); Loss: 0.117044; Backpropagation: 0.0918 sec; Batch: 0.4270 sec
0.2371 0.1607 0.1495 0.1153 0.1056 0.1052 0.1071 0.1031 0.1001 0.0985 0.0983 0.0983 0.0983 0.0983 0.0985 0.0990 

[TRAIN] Epoch[1](676/1500); Loss: 0.096452; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1425 0.1176 0.1021 0.1051 0.1125 0.0983 0.0893 0.0870 0.0864 0.0856 0.0853 0.0852 0.0857 0.0863 0.0870 0.0874 

[TRAIN] Epoch[1](677/1500); Loss: 0.059745; Backpropagation: 0.0988 sec; Batch: 0.4483 sec
0.0769 0.1036 0.0773 0.0626 0.0724 0.0691 0.0580 0.0498 0.0480 0.0473 0.0476 0.0478 0.0479 0.0485 0.0491 0.0499 

[TRAIN] Epoch[1](678/1500); Loss: 0.103624; Backpropagation: 0.0984 sec; Batch: 0.4315 sec
0.2174 0.1217 0.1224 0.1019 0.0973 0.0939 0.0928 0.0916 0.0894 0.0886 0.0887 0.0894 0.0895 0.0902 0.0912 0.0919 

[TRAIN] Epoch[1](679/1500); Loss: 0.132450; Backpropagation: 0.0984 sec; Batch: 0.4322 sec
0.2050 0.1538 0.1488 0.1333 0.1260 0.1244 0.1235 0.1226 0.1226 0.1225 0.1225 0.1226 0.1226 0.1227 0.1233 0.1230 

[TRAIN] Epoch[1](680/1500); Loss: 0.083177; Backpropagation: 0.0984 sec; Batch: 0.4400 sec
0.1155 0.1294 0.0993 0.0911 0.0907 0.0810 0.0771 0.0753 0.0737 0.0723 0.0717 0.0713 0.0707 0.0705 0.0706 0.0707 

[TRAIN] Epoch[1](681/1500); Loss: 0.108682; Backpropagation: 0.0984 sec; Batch: 0.4316 sec
0.3038 0.1752 0.1751 0.1311 0.1077 0.0846 0.0879 0.0817 0.0784 0.0761 0.0744 0.0731 0.0726 0.0721 0.0720 0.0731 

[TRAIN] Epoch[1](682/1500); Loss: 0.100830; Backpropagation: 0.0925 sec; Batch: 0.4271 sec
0.1359 0.1193 0.1055 0.0999 0.1011 0.0982 0.0960 0.0960 0.0954 0.0951 0.0947 0.0947 0.0950 0.0952 0.0954 0.0958 

[TRAIN] Epoch[1](683/1500); Loss: 0.090288; Backpropagation: 0.0921 sec; Batch: 0.4267 sec
0.2629 0.1417 0.1312 0.0915 0.0793 0.0748 0.0712 0.0674 0.0662 0.0654 0.0655 0.0658 0.0655 0.0656 0.0654 0.0650 

[TRAIN] Epoch[1](684/1500); Loss: 0.105839; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.2015 0.1216 0.1120 0.1038 0.1016 0.1001 0.0985 0.0966 0.0953 0.0946 0.0944 0.0948 0.0947 0.0947 0.0946 0.0945 

[TRAIN] Epoch[1](685/1500); Loss: 0.110731; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2816 0.1363 0.1460 0.1145 0.1047 0.0953 0.0920 0.0912 0.0898 0.0888 0.0884 0.0885 0.0884 0.0883 0.0887 0.0894 

[TRAIN] Epoch[1](686/1500); Loss: 0.066834; Backpropagation: 0.0916 sec; Batch: 0.4627 sec
0.0850 0.0900 0.0970 0.0791 0.0687 0.0631 0.0611 0.0594 0.0586 0.0580 0.0579 0.0577 0.0578 0.0584 0.0586 0.0590 

[TRAIN] Epoch[1](687/1500); Loss: 0.130725; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2055 0.1717 0.1520 0.1401 0.1277 0.1235 0.1205 0.1185 0.1176 0.1168 0.1166 0.1160 0.1161 0.1162 0.1163 0.1165 

[TRAIN] Epoch[1](688/1500); Loss: 0.076285; Backpropagation: 0.0919 sec; Batch: 0.4279 sec
0.0917 0.1008 0.0759 0.0808 0.0891 0.0752 0.0735 0.0718 0.0709 0.0704 0.0701 0.0700 0.0700 0.0701 0.0700 0.0702 

[TRAIN] Epoch[1](689/1500); Loss: 0.083848; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.0932 0.1311 0.1037 0.0910 0.0891 0.0844 0.0783 0.0766 0.0745 0.0740 0.0740 0.0740 0.0741 0.0742 0.0744 0.0751 

[TRAIN] Epoch[1](690/1500); Loss: 0.104047; Backpropagation: 0.0917 sec; Batch: 0.4261 sec
0.1173 0.1458 0.1219 0.1130 0.1044 0.1013 0.1002 0.0987 0.0973 0.0963 0.0955 0.0950 0.0948 0.0946 0.0943 0.0943 

[TRAIN] Epoch[1](691/1500); Loss: 0.093050; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1274 0.1219 0.0963 0.0912 0.0885 0.0886 0.0871 0.0871 0.0861 0.0858 0.0863 0.0870 0.0878 0.0885 0.0891 0.0902 

[TRAIN] Epoch[1](692/1500); Loss: 0.120987; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2625 0.2562 0.2129 0.1598 0.1082 0.0923 0.0829 0.0864 0.0899 0.0850 0.0885 0.0833 0.0823 0.0816 0.0817 0.0822 

[TRAIN] Epoch[1](693/1500); Loss: 0.075900; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1059 0.1272 0.0991 0.0874 0.0746 0.0723 0.0696 0.0668 0.0648 0.0641 0.0635 0.0635 0.0635 0.0637 0.0639 0.0644 

[TRAIN] Epoch[1](694/1500); Loss: 0.086152; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1148 0.1482 0.1202 0.1073 0.0866 0.0825 0.0794 0.0770 0.0745 0.0723 0.0708 0.0698 0.0691 0.0688 0.0686 0.0686 

[TRAIN] Epoch[1](695/1500); Loss: 0.090407; Backpropagation: 0.0920 sec; Batch: 0.4271 sec
0.1401 0.1536 0.1280 0.1061 0.0858 0.0813 0.0773 0.0753 0.0747 0.0744 0.0740 0.0743 0.0745 0.0748 0.0756 0.0767 

[TRAIN] Epoch[1](696/1500); Loss: 0.064042; Backpropagation: 0.0917 sec; Batch: 0.4263 sec
0.1080 0.0804 0.0700 0.0650 0.0628 0.0606 0.0591 0.0578 0.0571 0.0567 0.0567 0.0569 0.0574 0.0579 0.0585 0.0595 

[TRAIN] Epoch[1](697/1500); Loss: 0.100536; Backpropagation: 0.0918 sec; Batch: 0.4380 sec
0.1271 0.1208 0.1060 0.1017 0.1011 0.0971 0.0960 0.0962 0.0957 0.0946 0.0946 0.0950 0.0954 0.0956 0.0957 0.0960 

[TRAIN] Epoch[1](698/1500); Loss: 0.091926; Backpropagation: 0.0916 sec; Batch: 0.4401 sec
0.1940 0.1274 0.1190 0.0867 0.0842 0.0801 0.0788 0.0778 0.0777 0.0777 0.0772 0.0775 0.0776 0.0782 0.0783 0.0788 

[TRAIN] Epoch[1](699/1500); Loss: 0.088087; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.0932 0.1146 0.1016 0.0953 0.0865 0.0840 0.0825 0.0820 0.0820 0.0821 0.0825 0.0831 0.0837 0.0845 0.0855 0.0863 

[TRAIN] Epoch[1](700/1500); Loss: 0.133046; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1517 0.1629 0.1414 0.1386 0.1368 0.1309 0.1292 0.1282 0.1275 0.1264 0.1262 0.1259 0.1258 0.1257 0.1256 0.1258 

[TRAIN] Epoch[1](701/1500); Loss: 0.153344; Backpropagation: 0.0920 sec; Batch: 0.4275 sec
0.2182 0.1902 0.1772 0.1580 0.1497 0.1469 0.1447 0.1436 0.1424 0.1417 0.1410 0.1407 0.1402 0.1398 0.1396 0.1395 

[TRAIN] Epoch[1](702/1500); Loss: 0.131423; Backpropagation: 0.0916 sec; Batch: 0.4260 sec
0.1927 0.1746 0.1579 0.1359 0.1260 0.1237 0.1214 0.1200 0.1199 0.1193 0.1186 0.1186 0.1186 0.1187 0.1186 0.1184 

[TRAIN] Epoch[1](703/1500); Loss: 0.123076; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1423 0.1479 0.1288 0.1255 0.1322 0.1230 0.1195 0.1176 0.1168 0.1170 0.1163 0.1162 0.1160 0.1167 0.1165 0.1168 

[TRAIN] Epoch[1](704/1500); Loss: 0.119012; Backpropagation: 0.0917 sec; Batch: 0.4266 sec
0.2467 0.1717 0.1544 0.1130 0.1112 0.1033 0.1010 0.1001 0.0995 0.1010 0.1005 0.0999 0.0997 0.1002 0.1008 0.1012 

[TRAIN] Epoch[1](705/1500); Loss: 0.050258; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0876 0.0898 0.0603 0.0483 0.0688 0.0569 0.0410 0.0380 0.0371 0.0370 0.0381 0.0386 0.0397 0.0398 0.0412 0.0418 

[TRAIN] Epoch[1](706/1500); Loss: 0.099010; Backpropagation: 0.0916 sec; Batch: 0.4392 sec
0.1337 0.1187 0.0991 0.1035 0.1109 0.0970 0.0950 0.0932 0.0917 0.0920 0.0921 0.0920 0.0914 0.0912 0.0914 0.0912 

[TRAIN] Epoch[1](707/1500); Loss: 0.108146; Backpropagation: 0.0923 sec; Batch: 0.4235 sec
0.1557 0.1336 0.1172 0.1048 0.1067 0.1056 0.1020 0.0998 0.0993 0.1001 0.1001 0.1004 0.1007 0.1007 0.1012 0.1025 

[TRAIN] Epoch[1](708/1500); Loss: 0.124067; Backpropagation: 0.0916 sec; Batch: 0.4268 sec
0.1458 0.1458 0.1301 0.1368 0.1347 0.1206 0.1192 0.1188 0.1177 0.1165 0.1169 0.1172 0.1168 0.1163 0.1159 0.1160 

[TRAIN] Epoch[1](709/1500); Loss: 0.087321; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1287 0.1157 0.1017 0.0902 0.0815 0.0808 0.0817 0.0802 0.0812 0.0792 0.0788 0.0790 0.0797 0.0795 0.0795 0.0797 

[TRAIN] Epoch[1](710/1500); Loss: 0.075248; Backpropagation: 0.0917 sec; Batch: 0.4270 sec
0.1229 0.1078 0.0851 0.0748 0.0711 0.0721 0.0699 0.0682 0.0668 0.0668 0.0670 0.0662 0.0662 0.0661 0.0663 0.0667 

[TRAIN] Epoch[1](711/1500); Loss: 0.047877; Backpropagation: 0.0939 sec; Batch: 0.4291 sec
0.0510 0.0597 0.0491 0.0529 0.0477 0.0455 0.0437 0.0444 0.0441 0.0452 0.0453 0.0456 0.0463 0.0480 0.0488 0.0487 

[TRAIN] Epoch[1](712/1500); Loss: 0.070161; Backpropagation: 0.0920 sec; Batch: 0.4409 sec
0.1213 0.0915 0.0803 0.0745 0.0727 0.0682 0.0644 0.0619 0.0610 0.0609 0.0608 0.0607 0.0616 0.0609 0.0608 0.0610 

[TRAIN] Epoch[1](713/1500); Loss: 0.077661; Backpropagation: 0.0922 sec; Batch: 0.4278 sec
0.1164 0.1167 0.0881 0.0815 0.0772 0.0737 0.0716 0.0702 0.0686 0.0681 0.0679 0.0687 0.0681 0.0683 0.0685 0.0690 

[TRAIN] Epoch[1](714/1500); Loss: 0.108790; Backpropagation: 0.0919 sec; Batch: 0.4258 sec
0.1555 0.1376 0.1154 0.1111 0.1080 0.1057 0.1042 0.1026 0.1012 0.1003 0.1002 0.0998 0.1000 0.0999 0.0997 0.0995 

[TRAIN] Epoch[1](715/1500); Loss: 0.132887; Backpropagation: 0.0916 sec; Batch: 0.4358 sec
0.1579 0.1816 0.1622 0.1438 0.1333 0.1276 0.1264 0.1266 0.1261 0.1225 0.1207 0.1200 0.1196 0.1196 0.1192 0.1192 

[TRAIN] Epoch[1](716/1500); Loss: 0.125818; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1753 0.1470 0.1354 0.1276 0.1254 0.1228 0.1212 0.1202 0.1189 0.1180 0.1175 0.1169 0.1174 0.1167 0.1164 0.1164 

[TRAIN] Epoch[1](717/1500); Loss: 0.070564; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.3622 0.1175 0.1361 0.0577 0.0420 0.0339 0.0332 0.0406 0.0381 0.0370 0.0366 0.0370 0.0382 0.0394 0.0389 0.0407 

[TRAIN] Epoch[1](718/1500); Loss: 0.114765; Backpropagation: 0.0991 sec; Batch: 0.4338 sec
0.2246 0.1274 0.1202 0.1123 0.1049 0.1038 0.1032 0.1035 0.1033 0.1032 0.1033 0.1039 0.1050 0.1054 0.1061 0.1063 

[TRAIN] Epoch[1](719/1500); Loss: 0.060493; Backpropagation: 0.0984 sec; Batch: 0.4313 sec
0.0471 0.0724 0.0416 0.0916 0.1174 0.0574 0.0493 0.0471 0.0480 0.0500 0.0520 0.0620 0.0592 0.0577 0.0573 0.0576 

[TRAIN] Epoch[1](720/1500); Loss: 0.104518; Backpropagation: 0.0983 sec; Batch: 0.4310 sec
0.1147 0.1247 0.1131 0.1166 0.1090 0.1028 0.1008 0.1010 0.1009 0.0993 0.0987 0.0987 0.0989 0.0980 0.0976 0.0975 

[TRAIN] Epoch[1](721/1500); Loss: 0.084935; Backpropagation: 0.0984 sec; Batch: 0.4318 sec
0.1196 0.1227 0.0989 0.0878 0.1036 0.0994 0.0847 0.0741 0.0711 0.0707 0.0705 0.0707 0.0718 0.0714 0.0710 0.0710 

[TRAIN] Epoch[1](722/1500); Loss: 0.068770; Backpropagation: 0.0984 sec; Batch: 0.4314 sec
0.1319 0.0961 0.0762 0.0658 0.0754 0.0689 0.0612 0.0588 0.0580 0.0574 0.0592 0.0583 0.0579 0.0579 0.0585 0.0589 

[TRAIN] Epoch[1](723/1500); Loss: 0.097079; Backpropagation: 0.0983 sec; Batch: 0.4313 sec
0.1436 0.1255 0.1071 0.1012 0.0943 0.0919 0.0902 0.0904 0.0889 0.0881 0.0879 0.0881 0.0890 0.0889 0.0889 0.0892 

[TRAIN] Epoch[1](724/1500); Loss: 0.106070; Backpropagation: 0.0925 sec; Batch: 0.4277 sec
0.1694 0.1497 0.1223 0.1003 0.1262 0.1238 0.1000 0.0930 0.0905 0.0898 0.0890 0.0887 0.0886 0.0883 0.0887 0.0887 

[TRAIN] Epoch[1](725/1500); Loss: 0.143491; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2335 0.1816 0.1644 0.1455 0.1367 0.1345 0.1327 0.1319 0.1301 0.1293 0.1290 0.1291 0.1291 0.1293 0.1295 0.1298 

[TRAIN] Epoch[1](726/1500); Loss: 0.113672; Backpropagation: 0.0916 sec; Batch: 0.4585 sec
0.1785 0.1416 0.1233 0.1185 0.1167 0.1124 0.1045 0.1043 0.1030 0.1023 0.1021 0.1023 0.1022 0.1021 0.1024 0.1025 

[TRAIN] Epoch[1](727/1500); Loss: 0.119767; Backpropagation: 0.0919 sec; Batch: 0.4279 sec
0.2058 0.1882 0.1603 0.1363 0.1173 0.1090 0.1023 0.1030 0.1033 0.1006 0.0987 0.0985 0.0983 0.0982 0.0983 0.0981 

[TRAIN] Epoch[1](728/1500); Loss: 0.076569; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1107 0.1334 0.1044 0.0759 0.0804 0.0755 0.0644 0.0663 0.0629 0.0619 0.0624 0.0634 0.0645 0.0654 0.0664 0.0673 

[TRAIN] Epoch[1](729/1500); Loss: 0.085284; Backpropagation: 0.0918 sec; Batch: 0.4251 sec
0.1204 0.1369 0.1125 0.1000 0.0895 0.0821 0.0746 0.0731 0.0725 0.0721 0.0718 0.0716 0.0717 0.0716 0.0722 0.0720 

[TRAIN] Epoch[1](730/1500); Loss: 0.144358; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2227 0.1772 0.1680 0.1500 0.1421 0.1374 0.1349 0.1332 0.1321 0.1311 0.1305 0.1305 0.1304 0.1300 0.1297 0.1299 

[TRAIN] Epoch[1](731/1500); Loss: 0.066346; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.0875 0.1189 0.0915 0.0766 0.0606 0.0610 0.0600 0.0572 0.0571 0.0557 0.0555 0.0554 0.0555 0.0562 0.0563 0.0565 

[TRAIN] Epoch[1](732/1500); Loss: 0.101059; Backpropagation: 0.0918 sec; Batch: 0.4264 sec
0.1298 0.1167 0.1115 0.1044 0.1023 0.0983 0.0964 0.0954 0.0957 0.0953 0.0950 0.0949 0.0950 0.0951 0.0954 0.0956 

[TRAIN] Epoch[1](733/1500); Loss: 0.170683; Backpropagation: 0.0916 sec; Batch: 0.4379 sec
0.2069 0.2159 0.2026 0.1838 0.1699 0.1654 0.1626 0.1620 0.1599 0.1586 0.1577 0.1571 0.1579 0.1573 0.1568 0.1568 

[TRAIN] Epoch[1](734/1500); Loss: 0.134857; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1962 0.1685 0.1529 0.1414 0.1357 0.1318 0.1272 0.1241 0.1232 0.1226 0.1222 0.1222 0.1222 0.1222 0.1226 0.1225 

[TRAIN] Epoch[1](735/1500); Loss: 0.142325; Backpropagation: 0.0917 sec; Batch: 0.4399 sec
0.1921 0.1727 0.1583 0.1471 0.1389 0.1363 0.1351 0.1342 0.1333 0.1330 0.1327 0.1326 0.1327 0.1329 0.1326 0.1327 

[TRAIN] Epoch[1](736/1500); Loss: 0.129433; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1867 0.1807 0.1477 0.1311 0.1521 0.1362 0.1169 0.1210 0.1155 0.1138 0.1120 0.1111 0.1127 0.1118 0.1109 0.1106 

[TRAIN] Epoch[1](737/1500); Loss: 0.118484; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1901 0.1861 0.1564 0.1348 0.1157 0.1102 0.1044 0.1019 0.1019 0.1015 0.0998 0.0991 0.0985 0.0985 0.0985 0.0984 

[TRAIN] Epoch[1](738/1500); Loss: 0.124971; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2258 0.1423 0.1407 0.1227 0.1178 0.1165 0.1154 0.1149 0.1145 0.1141 0.1135 0.1131 0.1124 0.1120 0.1118 0.1120 

[TRAIN] Epoch[1](739/1500); Loss: 0.077543; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0885 0.0925 0.0733 0.0819 0.0945 0.0799 0.0750 0.0729 0.0723 0.0727 0.0725 0.0728 0.0725 0.0730 0.0732 0.0733 

[TRAIN] Epoch[1](740/1500); Loss: 0.080459; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1397 0.1269 0.0928 0.0809 0.0932 0.0859 0.0725 0.0699 0.0673 0.0665 0.0657 0.0654 0.0651 0.0651 0.0652 0.0652 

[TRAIN] Epoch[1](741/1500); Loss: 0.122669; Backpropagation: 0.0918 sec; Batch: 0.4275 sec
0.1737 0.1495 0.1311 0.1222 0.1175 0.1164 0.1156 0.1150 0.1148 0.1145 0.1147 0.1149 0.1152 0.1155 0.1159 0.1162 

[TRAIN] Epoch[1](742/1500); Loss: 0.116362; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2200 0.1493 0.1364 0.1144 0.1111 0.1079 0.1050 0.1032 0.1023 0.1016 0.1013 0.1016 0.1016 0.1017 0.1022 0.1022 

[TRAIN] Epoch[1](743/1500); Loss: 0.081490; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1372 0.1023 0.0960 0.0853 0.0784 0.0766 0.0752 0.0740 0.0731 0.0727 0.0725 0.0722 0.0720 0.0720 0.0721 0.0722 

[TRAIN] Epoch[1](744/1500); Loss: 0.078676; Backpropagation: 0.0916 sec; Batch: 0.4254 sec
0.1711 0.1015 0.0982 0.0806 0.0744 0.0701 0.0677 0.0667 0.0662 0.0660 0.0662 0.0660 0.0659 0.0661 0.0661 0.0662 

[TRAIN] Epoch[1](745/1500); Loss: 0.118979; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1742 0.1566 0.1297 0.1222 0.1148 0.1118 0.1103 0.1099 0.1094 0.1094 0.1090 0.1090 0.1095 0.1091 0.1093 0.1097 

[TRAIN] Epoch[1](746/1500); Loss: 0.094709; Backpropagation: 0.0915 sec; Batch: 0.4238 sec
0.1238 0.1269 0.1039 0.0955 0.0908 0.0888 0.0876 0.0867 0.0874 0.0874 0.0880 0.0886 0.0892 0.0897 0.0901 0.0908 

[TRAIN] Epoch[1](747/1500); Loss: 0.044370; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.0369 0.0628 0.0417 0.0923 0.0849 0.0384 0.0483 0.0351 0.0325 0.0341 0.0330 0.0366 0.0342 0.0330 0.0329 0.0332 

[TRAIN] Epoch[1](748/1500); Loss: 0.109254; Backpropagation: 0.0917 sec; Batch: 0.4321 sec
0.1763 0.1545 0.1308 0.1154 0.1067 0.1018 0.0976 0.0959 0.0957 0.0959 0.0959 0.0959 0.0968 0.0961 0.0961 0.0964 

[TRAIN] Epoch[1](749/1500); Loss: 0.117124; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1546 0.1488 0.1243 0.1217 0.1209 0.1162 0.1114 0.1108 0.1092 0.1084 0.1082 0.1084 0.1080 0.1079 0.1076 0.1076 

[TRAIN] Epoch[1](750/1500); Loss: 0.090366; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1242 0.1105 0.1027 0.0928 0.0868 0.0858 0.0854 0.0847 0.0842 0.0843 0.0843 0.0840 0.0839 0.0840 0.0841 0.0841 

[TRAIN] Epoch[1](751/1500); Loss: 0.120510; Backpropagation: 0.0916 sec; Batch: 0.4446 sec
0.1556 0.1596 0.1277 0.1299 0.1333 0.1185 0.1132 0.1115 0.1107 0.1111 0.1100 0.1093 0.1094 0.1097 0.1094 0.1094 

[TRAIN] Epoch[1](752/1500); Loss: 0.180233; Backpropagation: 0.0917 sec; Batch: 0.4257 sec
0.2449 0.2424 0.2090 0.1901 0.1725 0.1697 0.1675 0.1669 0.1665 0.1652 0.1644 0.1645 0.1651 0.1648 0.1647 0.1656 

[TRAIN] Epoch[1](753/1500); Loss: 0.094533; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2029 0.1345 0.1167 0.1040 0.0926 0.0838 0.0812 0.0796 0.0785 0.0783 0.0772 0.0771 0.0767 0.0764 0.0766 0.0765 

[TRAIN] Epoch[1](754/1500); Loss: 0.123997; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1552 0.1505 0.1320 0.1281 0.1232 0.1207 0.1194 0.1186 0.1181 0.1175 0.1171 0.1169 0.1168 0.1166 0.1166 0.1165 

[TRAIN] Epoch[1](755/1500); Loss: 0.090179; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1232 0.1126 0.0976 0.0904 0.0872 0.0865 0.0857 0.0852 0.0848 0.0846 0.0844 0.0842 0.0841 0.0842 0.0841 0.0842 

[TRAIN] Epoch[1](756/1500); Loss: 0.116383; Backpropagation: 0.0916 sec; Batch: 0.4270 sec
0.1352 0.1382 0.1167 0.1266 0.1367 0.1160 0.1111 0.1104 0.1101 0.1095 0.1091 0.1089 0.1086 0.1084 0.1083 0.1084 

[TRAIN] Epoch[1](757/1500); Loss: 0.147608; Backpropagation: 0.0918 sec; Batch: 0.4444 sec
0.1674 0.1682 0.1561 0.1525 0.1497 0.1486 0.1461 0.1446 0.1434 0.1424 0.1416 0.1409 0.1405 0.1402 0.1399 0.1397 

[TRAIN] Epoch[1](758/1500); Loss: 0.105075; Backpropagation: 0.0916 sec; Batch: 0.4256 sec
0.1448 0.1253 0.1150 0.1069 0.1059 0.1044 0.1018 0.1007 0.0996 0.0988 0.0980 0.0972 0.0965 0.0959 0.0954 0.0951 

[TRAIN] Epoch[1](759/1500); Loss: 0.091242; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1992 0.1285 0.1143 0.0896 0.0838 0.0804 0.0809 0.0818 0.0808 0.0790 0.0772 0.0755 0.0739 0.0726 0.0715 0.0708 

[TRAIN] Epoch[1](760/1500); Loss: 0.152184; Backpropagation: 0.0974 sec; Batch: 0.4305 sec
0.2565 0.1868 0.1788 0.1510 0.1385 0.1367 0.1401 0.1410 0.1413 0.1416 0.1409 0.1397 0.1379 0.1362 0.1346 0.1334 

[TRAIN] Epoch[1](761/1500); Loss: 0.148693; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1968 0.1707 0.1674 0.1546 0.1489 0.1456 0.1433 0.1420 0.1416 0.1409 0.1399 0.1390 0.1381 0.1374 0.1367 0.1361 

[TRAIN] Epoch[1](762/1500); Loss: 0.128042; Backpropagation: 0.0916 sec; Batch: 0.4272 sec
0.2112 0.1632 0.1554 0.1416 0.1335 0.1291 0.1241 0.1182 0.1152 0.1135 0.1116 0.1097 0.1078 0.1062 0.1049 0.1036 

[TRAIN] Epoch[1](763/1500); Loss: 0.118857; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1842 0.1496 0.1419 0.1268 0.1183 0.1130 0.1092 0.1069 0.1062 0.1069 0.1072 0.1072 0.1069 0.1064 0.1058 0.1052 

[TRAIN] Epoch[1](764/1500); Loss: 0.111175; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1773 0.1254 0.1225 0.1063 0.1040 0.1076 0.1084 0.1075 0.1063 0.1049 0.1037 0.1026 0.1016 0.1008 0.1002 0.0997 

[TRAIN] Epoch[1](765/1500); Loss: 0.076439; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1402 0.1013 0.0936 0.0810 0.0755 0.0711 0.0686 0.0679 0.0679 0.0675 0.0667 0.0660 0.0650 0.0643 0.0635 0.0629 

[TRAIN] Epoch[1](766/1500); Loss: 0.085559; Backpropagation: 0.0987 sec; Batch: 0.4413 sec
0.1632 0.1119 0.1070 0.0833 0.0755 0.0772 0.0786 0.0779 0.0770 0.0760 0.0751 0.0741 0.0735 0.0731 0.0728 0.0725 

[TRAIN] Epoch[1](767/1500); Loss: 0.122389; Backpropagation: 0.0984 sec; Batch: 0.4319 sec
0.1646 0.1584 0.1198 0.1217 0.1284 0.1221 0.1173 0.1164 0.1157 0.1148 0.1142 0.1136 0.1132 0.1130 0.1127 0.1124 

[TRAIN] Epoch[1](768/1500); Loss: 0.122832; Backpropagation: 0.0983 sec; Batch: 0.4320 sec
0.2106 0.1615 0.1607 0.1390 0.1270 0.1173 0.1103 0.1062 0.1044 0.1045 0.1046 0.1045 0.1042 0.1038 0.1035 0.1033 

[TRAIN] Epoch[1](769/1500); Loss: 0.123732; Backpropagation: 0.0985 sec; Batch: 0.4313 sec
0.2453 0.1818 0.1798 0.1521 0.1330 0.1185 0.1067 0.0987 0.0959 0.0958 0.0957 0.0956 0.0956 0.0953 0.0951 0.0949 

[TRAIN] Epoch[1](770/1500); Loss: 0.142596; Backpropagation: 0.0983 sec; Batch: 0.4317 sec
0.3524 0.2447 0.2521 0.2052 0.1780 0.1491 0.1214 0.0981 0.0843 0.0830 0.0853 0.0861 0.0859 0.0856 0.0853 0.0849 

[TRAIN] Epoch[1](771/1500); Loss: 0.098416; Backpropagation: 0.1055 sec; Batch: 0.4382 sec
0.2148 0.1483 0.1498 0.1275 0.1123 0.0995 0.0868 0.0776 0.0719 0.0703 0.0701 0.0700 0.0697 0.0691 0.0687 0.0684 

[TRAIN] Epoch[1](772/1500); Loss: 0.138506; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1895 0.1609 0.1539 0.1426 0.1399 0.1368 0.1341 0.1322 0.1309 0.1299 0.1291 0.1283 0.1275 0.1270 0.1268 0.1267 

[TRAIN] Epoch[1](773/1500); Loss: 0.151032; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.3543 0.2641 0.2590 0.2161 0.1948 0.1662 0.1384 0.1148 0.0983 0.0899 0.0868 0.0871 0.0872 0.0868 0.0865 0.0863 

[TRAIN] Epoch[1](774/1500); Loss: 0.110991; Backpropagation: 0.0917 sec; Batch: 0.4266 sec
0.1906 0.1457 0.1376 0.1220 0.1146 0.1088 0.1032 0.1002 0.0978 0.0964 0.0948 0.0938 0.0932 0.0928 0.0924 0.0918 

[TRAIN] Epoch[1](775/1500); Loss: 0.134647; Backpropagation: 0.1003 sec; Batch: 0.4343 sec
0.2472 0.1891 0.1839 0.1674 0.1564 0.1444 0.1332 0.1218 0.1113 0.1028 0.0994 0.1004 0.0999 0.0995 0.0990 0.0986 

[TRAIN] Epoch[1](776/1500); Loss: 0.120581; Backpropagation: 0.0983 sec; Batch: 0.4314 sec
0.1604 0.1264 0.1216 0.1191 0.1181 0.1176 0.1173 0.1171 0.1171 0.1170 0.1166 0.1165 0.1163 0.1161 0.1161 0.1159 

[TRAIN] Epoch[1](777/1500); Loss: 0.098075; Backpropagation: 0.0920 sec; Batch: 0.4264 sec
0.2067 0.1604 0.1448 0.1160 0.1186 0.1028 0.0851 0.0757 0.0728 0.0716 0.0704 0.0696 0.0690 0.0688 0.0685 0.0684 

[TRAIN] Epoch[1](778/1500); Loss: 0.102075; Backpropagation: 0.0915 sec; Batch: 0.4541 sec
0.1097 0.1082 0.1027 0.1071 0.1078 0.1017 0.1001 0.0998 0.0994 0.0992 0.0991 0.0992 0.0994 0.0997 0.0999 0.1001 

[TRAIN] Epoch[1](779/1500); Loss: 0.152583; Backpropagation: 0.0920 sec; Batch: 0.4281 sec
0.4859 0.3261 0.3179 0.2510 0.1960 0.1418 0.0886 0.0653 0.0746 0.0729 0.0718 0.0708 0.0700 0.0696 0.0695 0.0696 

[TRAIN] Epoch[1](780/1500); Loss: 0.135739; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.2289 0.1698 0.1529 0.1389 0.1316 0.1283 0.1264 0.1250 0.1235 0.1223 0.1215 0.1210 0.1208 0.1205 0.1201 0.1203 

[TRAIN] Epoch[1](781/1500); Loss: 0.111993; Backpropagation: 0.0918 sec; Batch: 0.4279 sec
0.1891 0.1548 0.1432 0.1250 0.1146 0.1083 0.1024 0.0989 0.0965 0.0951 0.0949 0.0947 0.0941 0.0937 0.0935 0.0932 

[TRAIN] Epoch[1](782/1500); Loss: 0.102610; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2203 0.1146 0.1080 0.1125 0.1067 0.1022 0.0981 0.0943 0.0912 0.0886 0.0869 0.0859 0.0850 0.0837 0.0827 0.0812 

[TRAIN] Epoch[1](783/1500); Loss: 0.115721; Backpropagation: 0.1008 sec; Batch: 0.4372 sec
0.2391 0.1797 0.1672 0.1412 0.1249 0.1149 0.1056 0.0995 0.0944 0.0910 0.0876 0.0846 0.0820 0.0805 0.0797 0.0797 

[TRAIN] Epoch[1](784/1500); Loss: 0.064149; Backpropagation: 0.0983 sec; Batch: 0.4356 sec
0.1026 0.0946 0.0729 0.0684 0.0636 0.0618 0.0599 0.0586 0.0573 0.0563 0.0555 0.0552 0.0549 0.0549 0.0549 0.0549 

[TRAIN] Epoch[1](785/1500); Loss: 0.117941; Backpropagation: 0.0985 sec; Batch: 0.4392 sec
0.2506 0.1718 0.1598 0.1352 0.1225 0.1113 0.1029 0.0980 0.0959 0.0936 0.0923 0.0916 0.0910 0.0905 0.0901 0.0899 

[TRAIN] Epoch[1](786/1500); Loss: 0.113063; Backpropagation: 0.0983 sec; Batch: 0.4321 sec
0.1471 0.1433 0.1258 0.1244 0.1227 0.1144 0.1097 0.1066 0.1046 0.1032 0.1021 0.1015 0.1012 0.1010 0.1008 0.1004 

[TRAIN] Epoch[1](787/1500); Loss: 0.070853; Backpropagation: 0.0984 sec; Batch: 0.4316 sec
0.1700 0.1232 0.1066 0.0893 0.0777 0.0660 0.0584 0.0537 0.0514 0.0503 0.0495 0.0487 0.0479 0.0474 0.0469 0.0466 

[TRAIN] Epoch[1](788/1500); Loss: 0.128196; Backpropagation: 0.0984 sec; Batch: 0.4311 sec
0.2365 0.1840 0.1616 0.1331 0.1313 0.1206 0.1119 0.1097 0.1090 0.1085 0.1081 0.1078 0.1075 0.1072 0.1071 0.1073 

[TRAIN] Epoch[1](789/1500); Loss: 0.117033; Backpropagation: 0.0920 sec; Batch: 0.4307 sec
0.2483 0.2003 0.1728 0.1534 0.1361 0.1138 0.0960 0.0848 0.0872 0.0854 0.0844 0.0833 0.0823 0.0819 0.0815 0.0812 

[TRAIN] Epoch[1](790/1500); Loss: 0.109669; Backpropagation: 0.0917 sec; Batch: 0.4257 sec
0.1982 0.1312 0.1282 0.1126 0.1067 0.1035 0.1017 0.1001 0.0990 0.0978 0.0970 0.0963 0.0958 0.0956 0.0955 0.0955 

[TRAIN] Epoch[1](791/1500); Loss: 0.102752; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1748 0.1245 0.1165 0.1045 0.1015 0.0980 0.0956 0.0938 0.0930 0.0924 0.0921 0.0918 0.0915 0.0914 0.0912 0.0914 

[TRAIN] Epoch[1](792/1500); Loss: 0.121969; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.3885 0.2489 0.2411 0.1887 0.1517 0.1173 0.0892 0.0688 0.0586 0.0576 0.0571 0.0567 0.0566 0.0566 0.0569 0.0572 

[TRAIN] Epoch[1](793/1500); Loss: 0.072797; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1828 0.1142 0.0966 0.0789 0.0661 0.0617 0.0591 0.0580 0.0570 0.0566 0.0562 0.0558 0.0556 0.0555 0.0555 0.0552 

[TRAIN] Epoch[1](794/1500); Loss: 0.157682; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2291 0.1905 0.1820 0.1700 0.1626 0.1554 0.1502 0.1467 0.1442 0.1430 0.1425 0.1420 0.1416 0.1413 0.1410 0.1408 

[TRAIN] Epoch[1](795/1500); Loss: 0.117997; Backpropagation: 0.0989 sec; Batch: 0.4331 sec
0.2179 0.1736 0.1488 0.1325 0.1345 0.1200 0.1043 0.0986 0.0974 0.0961 0.0952 0.0945 0.0941 0.0937 0.0935 0.0934 

[TRAIN] Epoch[1](796/1500); Loss: 0.069230; Backpropagation: 0.0984 sec; Batch: 0.4312 sec
0.1579 0.1203 0.0937 0.0622 0.0628 0.0669 0.0567 0.0559 0.0538 0.0534 0.0531 0.0532 0.0536 0.0541 0.0546 0.0553 

[TRAIN] Epoch[1](797/1500); Loss: 0.068779; Backpropagation: 0.0985 sec; Batch: 0.4313 sec
0.1228 0.1064 0.0772 0.0713 0.0706 0.0666 0.0636 0.0609 0.0588 0.0573 0.0566 0.0566 0.0571 0.0576 0.0583 0.0587 

[TRAIN] Epoch[1](798/1500); Loss: 0.088519; Backpropagation: 0.0984 sec; Batch: 0.4316 sec
0.1391 0.1133 0.0975 0.0901 0.0848 0.0825 0.0813 0.0806 0.0804 0.0802 0.0801 0.0803 0.0811 0.0813 0.0816 0.0820 

[TRAIN] Epoch[1](799/1500); Loss: 0.130805; Backpropagation: 0.0983 sec; Batch: 0.4322 sec
0.1992 0.1678 0.1441 0.1375 0.1317 0.1267 0.1221 0.1196 0.1182 0.1184 0.1183 0.1180 0.1178 0.1178 0.1178 0.1179 

[TRAIN] Epoch[1](800/1500); Loss: 0.113374; Backpropagation: 0.0983 sec; Batch: 0.4315 sec
0.2897 0.1614 0.1438 0.1160 0.1019 0.0963 0.0949 0.0933 0.0928 0.0913 0.0901 0.0892 0.0888 0.0883 0.0882 0.0881 

[TRAIN] Epoch[1](801/1500); Loss: 0.113510; Backpropagation: 0.0938 sec; Batch: 0.4307 sec
0.2624 0.1510 0.1358 0.1146 0.1082 0.1028 0.0980 0.0952 0.0944 0.0938 0.0934 0.0933 0.0932 0.0932 0.0933 0.0936 

[TRAIN] Epoch[1](802/1500); Loss: 0.057701; Backpropagation: 0.0922 sec; Batch: 0.4256 sec
0.1061 0.0803 0.0645 0.0613 0.0565 0.0539 0.0520 0.0507 0.0502 0.0496 0.0495 0.0492 0.0495 0.0498 0.0499 0.0501 

[TRAIN] Epoch[1](803/1500); Loss: 0.136394; Backpropagation: 0.0919 sec; Batch: 0.4259 sec
0.1692 0.1569 0.1441 0.1386 0.1364 0.1348 0.1335 0.1329 0.1319 0.1309 0.1301 0.1294 0.1290 0.1286 0.1282 0.1278 

[TRAIN] Epoch[1](804/1500); Loss: 0.085472; Backpropagation: 0.0920 sec; Batch: 0.4266 sec
0.2091 0.1541 0.1257 0.0945 0.0849 0.0741 0.0704 0.0659 0.0638 0.0621 0.0609 0.0602 0.0605 0.0605 0.0604 0.0602 

[TRAIN] Epoch[1](805/1500); Loss: 0.072367; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1753 0.1107 0.0995 0.0804 0.0696 0.0624 0.0595 0.0575 0.0569 0.0562 0.0557 0.0553 0.0550 0.0548 0.0546 0.0546 

[TRAIN] Epoch[1](806/1500); Loss: 0.046550; Backpropagation: 0.0916 sec; Batch: 0.4622 sec
0.1002 0.0923 0.0630 0.0451 0.0510 0.0477 0.0380 0.0363 0.0344 0.0336 0.0333 0.0335 0.0338 0.0341 0.0342 0.0344 

[TRAIN] Epoch[1](807/1500); Loss: 0.080636; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.2537 0.1526 0.1332 0.0971 0.0730 0.0599 0.0565 0.0547 0.0532 0.0521 0.0512 0.0509 0.0507 0.0505 0.0503 0.0506 

[TRAIN] Epoch[1](808/1500); Loss: 0.094281; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1448 0.1305 0.1086 0.0985 0.0892 0.0870 0.0853 0.0848 0.0845 0.0844 0.0845 0.0850 0.0851 0.0852 0.0854 0.0857 

[TRAIN] Epoch[1](809/1500); Loss: 0.158120; Backpropagation: 0.0920 sec; Batch: 0.4268 sec
0.3554 0.2411 0.2133 0.1756 0.1461 0.1282 0.1315 0.1291 0.1279 0.1270 0.1263 0.1258 0.1256 0.1255 0.1253 0.1261 

[TRAIN] Epoch[1](810/1500); Loss: 0.162173; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.3421 0.2557 0.2434 0.2101 0.1858 0.1665 0.1490 0.1334 0.1216 0.1149 0.1128 0.1126 0.1122 0.1117 0.1115 0.1113 

[TRAIN] Epoch[1](811/1500); Loss: 0.162910; Backpropagation: 0.0917 sec; Batch: 0.4613 sec
0.1940 0.1820 0.1672 0.1654 0.1621 0.1598 0.1593 0.1587 0.1582 0.1579 0.1575 0.1573 0.1571 0.1569 0.1568 0.1565 

[TRAIN] Epoch[1](812/1500); Loss: 0.125510; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1612 0.1445 0.1330 0.1281 0.1230 0.1217 0.1210 0.1205 0.1204 0.1200 0.1194 0.1192 0.1193 0.1190 0.1189 0.1189 

[TRAIN] Epoch[1](813/1500); Loss: 0.142278; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3105 0.2208 0.2012 0.1705 0.1457 0.1263 0.1136 0.1117 0.1116 0.1105 0.1096 0.1090 0.1088 0.1088 0.1088 0.1091 

[TRAIN] Epoch[1](814/1500); Loss: 0.092371; Backpropagation: 0.0915 sec; Batch: 0.4543 sec
0.1976 0.1376 0.1221 0.1032 0.0899 0.0822 0.0777 0.0759 0.0755 0.0752 0.0746 0.0739 0.0736 0.0733 0.0729 0.0728 

[TRAIN] Epoch[1](815/1500); Loss: 0.063529; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1345 0.0982 0.0757 0.0660 0.0635 0.0576 0.0551 0.0543 0.0531 0.0522 0.0515 0.0512 0.0509 0.0509 0.0508 0.0508 

[TRAIN] Epoch[1](816/1500); Loss: 0.071306; Backpropagation: 0.0917 sec; Batch: 0.4308 sec
0.1300 0.0993 0.0806 0.0751 0.0668 0.0657 0.0641 0.0629 0.0620 0.0618 0.0617 0.0618 0.0621 0.0620 0.0624 0.0627 

[TRAIN] Epoch[1](817/1500); Loss: 0.036316; Backpropagation: 0.0918 sec; Batch: 0.4269 sec
0.0553 0.0691 0.0454 0.0325 0.0319 0.0316 0.0308 0.0334 0.0321 0.0316 0.0312 0.0312 0.0311 0.0311 0.0313 0.0315 

[TRAIN] Epoch[1](818/1500); Loss: 0.067296; Backpropagation: 0.0988 sec; Batch: 0.4321 sec
0.1279 0.0917 0.0776 0.0684 0.0649 0.0623 0.0604 0.0598 0.0594 0.0588 0.0582 0.0579 0.0577 0.0573 0.0573 0.0571 

[TRAIN] Epoch[1](819/1500); Loss: 0.079659; Backpropagation: 0.0984 sec; Batch: 0.4314 sec
0.1398 0.1198 0.0819 0.0719 0.0936 0.0828 0.0704 0.0712 0.0692 0.0685 0.0680 0.0677 0.0675 0.0674 0.0675 0.0675 

[TRAIN] Epoch[1](820/1500); Loss: 0.084992; Backpropagation: 0.0984 sec; Batch: 0.4314 sec
0.1259 0.0978 0.0890 0.0903 0.0869 0.0815 0.0802 0.0795 0.0793 0.0788 0.0787 0.0786 0.0784 0.0781 0.0782 0.0786 

[TRAIN] Epoch[1](821/1500); Loss: 0.113573; Backpropagation: 0.0924 sec; Batch: 0.4266 sec
0.1816 0.1356 0.1284 0.1203 0.1157 0.1118 0.1086 0.1060 0.1035 0.1016 0.1010 0.1013 0.1009 0.1004 0.1003 0.1003 

[TRAIN] Epoch[1](822/1500); Loss: 0.121708; Backpropagation: 0.0919 sec; Batch: 0.4253 sec
0.2320 0.1751 0.1344 0.1210 0.1141 0.1123 0.1103 0.1086 0.1073 0.1065 0.1058 0.1048 0.1043 0.1039 0.1038 0.1032 

[TRAIN] Epoch[1](823/1500); Loss: 0.129033; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2663 0.1904 0.1658 0.1401 0.1299 0.1185 0.1077 0.1075 0.1061 0.1052 0.1047 0.1044 0.1043 0.1044 0.1046 0.1048 

[TRAIN] Epoch[1](824/1500); Loss: 0.067730; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2248 0.1161 0.0937 0.0692 0.0587 0.0534 0.0494 0.0482 0.0470 0.0464 0.0461 0.0460 0.0461 0.0461 0.0462 0.0463 

[TRAIN] Epoch[1](825/1500); Loss: 0.077410; Backpropagation: 0.0918 sec; Batch: 0.4431 sec
0.1588 0.1233 0.1065 0.0902 0.0802 0.0712 0.0655 0.0636 0.0625 0.0614 0.0602 0.0597 0.0592 0.0589 0.0588 0.0587 

[TRAIN] Epoch[1](826/1500); Loss: 0.112828; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3053 0.2165 0.1863 0.1535 0.1258 0.0986 0.0780 0.0743 0.0734 0.0719 0.0711 0.0703 0.0700 0.0701 0.0701 0.0701 

[TRAIN] Epoch[1](827/1500); Loss: 0.096622; Backpropagation: 0.0920 sec; Batch: 0.4260 sec
0.1342 0.1056 0.0990 0.0998 0.0955 0.0945 0.0936 0.0928 0.0922 0.0917 0.0915 0.0913 0.0912 0.0910 0.0910 0.0908 

[TRAIN] Epoch[1](828/1500); Loss: 0.099431; Backpropagation: 0.0987 sec; Batch: 0.4342 sec
0.1516 0.1376 0.1070 0.1026 0.0974 0.0924 0.0918 0.0910 0.0906 0.0902 0.0901 0.0897 0.0896 0.0895 0.0898 0.0900 

[TRAIN] Epoch[1](829/1500); Loss: 0.112296; Backpropagation: 0.0985 sec; Batch: 0.4310 sec
0.1904 0.1494 0.1356 0.1214 0.1136 0.1093 0.1049 0.1017 0.0995 0.0983 0.0972 0.0962 0.0956 0.0950 0.0945 0.0941 

[TRAIN] Epoch[1](830/1500); Loss: 0.065809; Backpropagation: 0.0983 sec; Batch: 0.4313 sec
0.2088 0.1175 0.0974 0.0743 0.0556 0.0477 0.0495 0.0471 0.0458 0.0447 0.0441 0.0438 0.0437 0.0442 0.0444 0.0446 

[TRAIN] Epoch[1](831/1500); Loss: 0.065337; Backpropagation: 0.0924 sec; Batch: 0.4257 sec
0.1434 0.1043 0.0805 0.0691 0.0622 0.0593 0.0569 0.0551 0.0538 0.0529 0.0519 0.0514 0.0513 0.0511 0.0512 0.0511 

[TRAIN] Epoch[1](832/1500); Loss: 0.152414; Backpropagation: 0.0915 sec; Batch: 0.4400 sec
0.3371 0.2457 0.2282 0.1961 0.1714 0.1522 0.1351 0.1210 0.1114 0.1075 0.1067 0.1060 0.1056 0.1053 0.1048 0.1046 

[TRAIN] Epoch[1](833/1500); Loss: 0.080231; Backpropagation: 0.0923 sec; Batch: 0.4236 sec
0.2071 0.1136 0.0968 0.0794 0.0689 0.0690 0.0666 0.0658 0.0652 0.0650 0.0646 0.0645 0.0646 0.0644 0.0641 0.0642 

[TRAIN] Epoch[1](834/1500); Loss: 0.058467; Backpropagation: 0.0916 sec; Batch: 0.4257 sec
0.2041 0.0742 0.0560 0.0594 0.0515 0.0487 0.0465 0.0447 0.0436 0.0431 0.0431 0.0435 0.0437 0.0441 0.0445 0.0448 

[TRAIN] Epoch[1](835/1500); Loss: 0.061685; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1045 0.0717 0.0743 0.0609 0.0562 0.0548 0.0539 0.0538 0.0545 0.0560 0.0561 0.0562 0.0572 0.0586 0.0587 0.0595 

[TRAIN] Epoch[1](836/1500); Loss: 0.129940; Backpropagation: 0.0915 sec; Batch: 0.4273 sec
0.2584 0.1964 0.1737 0.1483 0.1268 0.1149 0.1095 0.1082 0.1071 0.1063 0.1057 0.1052 0.1050 0.1046 0.1044 0.1044 

[TRAIN] Epoch[1](837/1500); Loss: 0.093287; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1272 0.1150 0.0982 0.0940 0.0927 0.0892 0.0880 0.0876 0.0873 0.0872 0.0873 0.0872 0.0875 0.0878 0.0880 0.0882 

[TRAIN] Epoch[1](838/1500); Loss: 0.080821; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1753 0.1088 0.0897 0.0783 0.0738 0.0727 0.0715 0.0702 0.0695 0.0692 0.0690 0.0687 0.0686 0.0689 0.0693 0.0695 

[TRAIN] Epoch[1](839/1500); Loss: 0.124446; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.4009 0.2816 0.2412 0.1945 0.1503 0.1075 0.0700 0.0608 0.0612 0.0603 0.0600 0.0597 0.0611 0.0604 0.0606 0.0610 

[TRAIN] Epoch[1](840/1500); Loss: 0.093925; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.2569 0.1520 0.1202 0.0949 0.0801 0.0777 0.0758 0.0741 0.0728 0.0720 0.0714 0.0715 0.0711 0.0709 0.0707 0.0707 

[TRAIN] Epoch[1](841/1500); Loss: 0.130095; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1883 0.1618 0.1412 0.1298 0.1288 0.1236 0.1206 0.1206 0.1204 0.1204 0.1204 0.1206 0.1209 0.1211 0.1213 0.1216 

[TRAIN] Epoch[1](842/1500); Loss: 0.079915; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1534 0.1072 0.0908 0.0800 0.0758 0.0739 0.0727 0.0714 0.0708 0.0698 0.0691 0.0689 0.0687 0.0687 0.0688 0.0687 

[TRAIN] Epoch[1](843/1500); Loss: 0.095187; Backpropagation: 0.0915 sec; Batch: 0.4615 sec
0.3546 0.2030 0.1660 0.1169 0.0734 0.0571 0.0593 0.0568 0.0557 0.0545 0.0540 0.0539 0.0539 0.0543 0.0547 0.0550 

[TRAIN] Epoch[1](844/1500); Loss: 0.146177; Backpropagation: 0.0918 sec; Batch: 0.4271 sec
0.2441 0.2011 0.1788 0.1582 0.1405 0.1339 0.1334 0.1311 0.1299 0.1287 0.1279 0.1272 0.1267 0.1263 0.1259 0.1253 

[TRAIN] Epoch[1](845/1500); Loss: 0.127730; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.4213 0.2642 0.2178 0.1622 0.1100 0.0726 0.0940 0.0870 0.0847 0.0815 0.0786 0.0764 0.0744 0.0732 0.0727 0.0732 

[TRAIN] Epoch[1](846/1500); Loss: 0.124037; Backpropagation: 0.0914 sec; Batch: 0.4258 sec
0.2719 0.2354 0.1969 0.1630 0.1215 0.1128 0.1073 0.1008 0.0964 0.0926 0.0890 0.0856 0.0823 0.0791 0.0763 0.0738 

[TRAIN] Epoch[1](847/1500); Loss: 0.076515; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2269 0.1275 0.0949 0.0763 0.0708 0.0664 0.0633 0.0605 0.0583 0.0570 0.0558 0.0545 0.0537 0.0532 0.0526 0.0527 

[TRAIN] Epoch[1](848/1500); Loss: 0.106181; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.3440 0.2047 0.1676 0.1323 0.1045 0.0790 0.0649 0.0752 0.0712 0.0691 0.0673 0.0656 0.0642 0.0633 0.0630 0.0630 

[TRAIN] Epoch[1](849/1500); Loss: 0.072337; Backpropagation: 0.0918 sec; Batch: 0.4271 sec
0.1221 0.0901 0.0757 0.0708 0.0721 0.0678 0.0666 0.0662 0.0658 0.0657 0.0656 0.0656 0.0659 0.0659 0.0657 0.0658 

[TRAIN] Epoch[1](850/1500); Loss: 0.082987; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1535 0.1022 0.0865 0.0799 0.0790 0.0763 0.0755 0.0747 0.0744 0.0742 0.0743 0.0745 0.0749 0.0752 0.0759 0.0766 

[TRAIN] Epoch[1](851/1500); Loss: 0.126110; Backpropagation: 0.0919 sec; Batch: 0.4227 sec
0.1737 0.1579 0.1414 0.1344 0.1298 0.1227 0.1192 0.1177 0.1170 0.1159 0.1152 0.1149 0.1147 0.1144 0.1146 0.1143 

[TRAIN] Epoch[1](852/1500); Loss: 0.069525; Backpropagation: 0.0916 sec; Batch: 0.4273 sec
0.1675 0.0906 0.0797 0.0711 0.0672 0.0635 0.0603 0.0584 0.0575 0.0570 0.0568 0.0567 0.0566 0.0564 0.0564 0.0566 

[TRAIN] Epoch[1](853/1500); Loss: 0.116427; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1490 0.1377 0.1221 0.1182 0.1180 0.1133 0.1112 0.1111 0.1106 0.1103 0.1102 0.1100 0.1102 0.1102 0.1102 0.1104 

[TRAIN] Epoch[1](854/1500); Loss: 0.062107; Backpropagation: 0.0914 sec; Batch: 0.4229 sec
0.1898 0.0994 0.0901 0.0673 0.0564 0.0508 0.0480 0.0465 0.0455 0.0447 0.0435 0.0427 0.0421 0.0420 0.0422 0.0426 

[TRAIN] Epoch[1](855/1500); Loss: 0.107463; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.2058 0.1516 0.1169 0.1067 0.0995 0.0975 0.0953 0.0948 0.0943 0.0944 0.0938 0.0937 0.0939 0.0937 0.0938 0.0937 

[TRAIN] Epoch[1](856/1500); Loss: 0.105137; Backpropagation: 0.0915 sec; Batch: 0.4589 sec
0.2066 0.1324 0.1171 0.1057 0.0985 0.0936 0.0933 0.0930 0.0932 0.0932 0.0930 0.0928 0.0926 0.0925 0.0924 0.0924 

[TRAIN] Epoch[1](857/1500); Loss: 0.079588; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.1403 0.1057 0.0925 0.0846 0.0789 0.0741 0.0725 0.0710 0.0701 0.0697 0.0694 0.0691 0.0689 0.0687 0.0689 0.0690 

[TRAIN] Epoch[1](858/1500); Loss: 0.111093; Backpropagation: 0.0915 sec; Batch: 0.4269 sec
0.2456 0.1640 0.1373 0.1158 0.1041 0.0963 0.0965 0.0940 0.0923 0.0912 0.0904 0.0901 0.0902 0.0900 0.0898 0.0900 

[TRAIN] Epoch[1](859/1500); Loss: 0.127211; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2069 0.1791 0.1490 0.1356 0.1279 0.1182 0.1139 0.1126 0.1120 0.1116 0.1115 0.1114 0.1113 0.1115 0.1115 0.1114 

[TRAIN] Epoch[1](860/1500); Loss: 0.055907; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0747 0.0666 0.0813 0.0673 0.0626 0.0561 0.0516 0.0493 0.0485 0.0478 0.0475 0.0475 0.0482 0.0483 0.0485 0.0488 

[TRAIN] Epoch[1](861/1500); Loss: 0.101093; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2510 0.1997 0.1596 0.1201 0.0783 0.0737 0.0800 0.0735 0.0773 0.0749 0.0733 0.0722 0.0713 0.0712 0.0708 0.0707 

[TRAIN] Epoch[1](862/1500); Loss: 0.109621; Backpropagation: 0.0915 sec; Batch: 0.4228 sec
0.1364 0.1252 0.1157 0.1132 0.1138 0.1087 0.1064 0.1055 0.1048 0.1042 0.1038 0.1035 0.1034 0.1033 0.1032 0.1028 

[TRAIN] Epoch[1](863/1500); Loss: 0.109175; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.2069 0.1342 0.1158 0.1076 0.1054 0.0986 0.0979 0.0975 0.0976 0.0974 0.0972 0.0976 0.0977 0.0983 0.0986 0.0987 

[TRAIN] Epoch[1](864/1500); Loss: 0.087864; Backpropagation: 0.0914 sec; Batch: 0.4620 sec
0.2622 0.1519 0.1213 0.0959 0.0763 0.0671 0.0657 0.0641 0.0635 0.0627 0.0624 0.0623 0.0621 0.0623 0.0629 0.0631 

[TRAIN] Epoch[1](865/1500); Loss: 0.108045; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2098 0.1348 0.1172 0.1034 0.1055 0.0999 0.0971 0.0966 0.0961 0.0959 0.0956 0.0954 0.0954 0.0953 0.0953 0.0955 

[TRAIN] Epoch[1](866/1500); Loss: 0.082819; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.3558 0.1648 0.1042 0.0632 0.0636 0.0639 0.0586 0.0548 0.0515 0.0495 0.0488 0.0487 0.0489 0.0490 0.0496 0.0501 

[TRAIN] Epoch[1](867/1500); Loss: 0.082932; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.1675 0.1183 0.0986 0.0828 0.0763 0.0741 0.0727 0.0715 0.0710 0.0708 0.0706 0.0705 0.0703 0.0707 0.0706 0.0706 

[TRAIN] Epoch[1](868/1500); Loss: 0.115317; Backpropagation: 0.0915 sec; Batch: 0.4585 sec
0.1826 0.1584 0.1305 0.1165 0.1179 0.1099 0.1038 0.1033 0.1029 0.1026 0.1026 0.1023 0.1027 0.1027 0.1027 0.1036 

[TRAIN] Epoch[1](869/1500); Loss: 0.090038; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.2264 0.1157 0.0875 0.0861 0.0866 0.0826 0.0794 0.0775 0.0762 0.0753 0.0745 0.0745 0.0743 0.0743 0.0744 0.0753 

[TRAIN] Epoch[1](870/1500); Loss: 0.126939; Backpropagation: 0.0915 sec; Batch: 0.4279 sec
0.2435 0.1630 0.1390 0.1215 0.1200 0.1174 0.1152 0.1143 0.1136 0.1130 0.1125 0.1121 0.1117 0.1116 0.1113 0.1113 

[TRAIN] Epoch[1](871/1500); Loss: 0.150806; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2552 0.1891 0.1587 0.1476 0.1520 0.1431 0.1386 0.1377 0.1371 0.1368 0.1364 0.1360 0.1363 0.1365 0.1361 0.1358 

[TRAIN] Epoch[1](872/1500); Loss: 0.133815; Backpropagation: 0.0915 sec; Batch: 0.4263 sec
0.1643 0.1552 0.1416 0.1429 0.1464 0.1357 0.1308 0.1287 0.1274 0.1262 0.1254 0.1244 0.1240 0.1234 0.1225 0.1221 

[TRAIN] Epoch[1](873/1500); Loss: 0.111229; Backpropagation: 0.0917 sec; Batch: 0.4243 sec
0.2290 0.1418 0.1241 0.1121 0.1061 0.1020 0.0991 0.0982 0.0974 0.0968 0.0964 0.0961 0.0956 0.0952 0.0949 0.0949 

[TRAIN] Epoch[1](874/1500); Loss: 0.098766; Backpropagation: 0.0917 sec; Batch: 0.4261 sec
0.1951 0.1263 0.1066 0.0957 0.0944 0.0908 0.0893 0.0885 0.0880 0.0876 0.0868 0.0864 0.0862 0.0864 0.0861 0.0860 

[TRAIN] Epoch[1](875/1500); Loss: 0.086730; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.1725 0.1197 0.1067 0.0899 0.0802 0.0795 0.0782 0.0763 0.0751 0.0744 0.0735 0.0728 0.0723 0.0723 0.0722 0.0720 

[TRAIN] Epoch[1](876/1500); Loss: 0.095829; Backpropagation: 0.0917 sec; Batch: 0.4389 sec
0.2083 0.1208 0.0982 0.0932 0.0898 0.0888 0.0864 0.0848 0.0838 0.0832 0.0828 0.0827 0.0827 0.0825 0.0826 0.0826 

[TRAIN] Epoch[1](877/1500); Loss: 0.143109; Backpropagation: 0.0918 sec; Batch: 0.4272 sec
0.2148 0.1774 0.1567 0.1472 0.1418 0.1383 0.1356 0.1342 0.1333 0.1326 0.1317 0.1306 0.1296 0.1290 0.1286 0.1282 

[TRAIN] Epoch[1](878/1500); Loss: 0.150381; Backpropagation: 0.0915 sec; Batch: 0.4229 sec
0.2691 0.2228 0.1921 0.1675 0.1398 0.1325 0.1312 0.1331 0.1298 0.1293 0.1280 0.1273 0.1265 0.1260 0.1257 0.1253 

[TRAIN] Epoch[1](879/1500); Loss: 0.114629; Backpropagation: 0.0993 sec; Batch: 0.4326 sec
0.2210 0.1572 0.1334 0.1185 0.1106 0.1045 0.1013 0.0998 0.0991 0.0988 0.0982 0.0982 0.0985 0.0985 0.0981 0.0984 

[TRAIN] Epoch[1](880/1500); Loss: 0.134272; Backpropagation: 0.0981 sec; Batch: 0.4311 sec
0.2241 0.1593 0.1437 0.1328 0.1293 0.1275 0.1256 0.1244 0.1238 0.1231 0.1227 0.1225 0.1225 0.1223 0.1223 0.1225 

[TRAIN] Epoch[1](881/1500); Loss: 0.076220; Backpropagation: 0.0985 sec; Batch: 0.4319 sec
0.1917 0.1113 0.0896 0.0745 0.0713 0.0654 0.0642 0.0633 0.0626 0.0618 0.0613 0.0611 0.0608 0.0605 0.0602 0.0600 

[TRAIN] Epoch[1](882/1500); Loss: 0.127477; Backpropagation: 0.0984 sec; Batch: 0.4314 sec
0.1829 0.1458 0.1298 0.1258 0.1331 0.1257 0.1210 0.1201 0.1198 0.1197 0.1197 0.1197 0.1196 0.1192 0.1191 0.1189 

[TRAIN] Epoch[1](883/1500); Loss: 0.044564; Backpropagation: 0.0985 sec; Batch: 0.4319 sec
0.0419 0.0413 0.0596 0.0798 0.0401 0.0516 0.0439 0.0418 0.0400 0.0385 0.0383 0.0387 0.0390 0.0392 0.0396 0.0396 

[TRAIN] Epoch[1](884/1500); Loss: 0.053591; Backpropagation: 0.0982 sec; Batch: 0.4315 sec
0.1571 0.1281 0.0761 0.0429 0.0672 0.0473 0.0346 0.0392 0.0357 0.0341 0.0326 0.0319 0.0319 0.0324 0.0329 0.0335 

[TRAIN] Epoch[1](885/1500); Loss: 0.096868; Backpropagation: 0.0984 sec; Batch: 0.4313 sec
0.3723 0.1793 0.1181 0.0755 0.0755 0.0708 0.0689 0.0666 0.0654 0.0649 0.0651 0.0651 0.0651 0.0658 0.0658 0.0657 

[TRAIN] Epoch[1](886/1500); Loss: 0.075710; Backpropagation: 0.0982 sec; Batch: 0.4314 sec
0.3320 0.1660 0.1177 0.0682 0.0453 0.0496 0.0462 0.0445 0.0429 0.0423 0.0423 0.0424 0.0428 0.0431 0.0432 0.0429 

[TRAIN] Epoch[1](887/1500); Loss: 0.067433; Backpropagation: 0.0985 sec; Batch: 0.4309 sec
0.2411 0.1336 0.1037 0.0745 0.0580 0.0493 0.0464 0.0444 0.0429 0.0419 0.0412 0.0409 0.0406 0.0401 0.0402 0.0401 

[TRAIN] Epoch[1](888/1500); Loss: 0.082384; Backpropagation: 0.0995 sec; Batch: 0.4317 sec
0.1963 0.1254 0.0931 0.0775 0.0766 0.0737 0.0722 0.0705 0.0689 0.0676 0.0669 0.0665 0.0661 0.0657 0.0656 0.0657 

[TRAIN] Epoch[1](889/1500); Loss: 0.095347; Backpropagation: 0.0924 sec; Batch: 0.4254 sec
0.1409 0.1117 0.1003 0.0944 0.0931 0.0918 0.0904 0.0897 0.0893 0.0891 0.0889 0.0890 0.0892 0.0891 0.0893 0.0893 

[TRAIN] Epoch[1](890/1500); Loss: 0.108913; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2330 0.1600 0.1357 0.1104 0.0975 0.0967 0.0956 0.0938 0.0923 0.0909 0.0903 0.0898 0.0892 0.0892 0.0890 0.0893 

[TRAIN] Epoch[1](891/1500); Loss: 0.173744; Backpropagation: 0.0920 sec; Batch: 0.4256 sec
0.2393 0.2094 0.1839 0.1689 0.1667 0.1644 0.1637 0.1649 0.1644 0.1642 0.1642 0.1645 0.1647 0.1648 0.1657 0.1664 

[TRAIN] Epoch[1](892/1500); Loss: 0.083853; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1059 0.0929 0.0881 0.0870 0.0822 0.0816 0.0812 0.0807 0.0805 0.0804 0.0802 0.0802 0.0800 0.0801 0.0802 0.0803 

[TRAIN] Epoch[1](893/1500); Loss: 0.072456; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1366 0.1072 0.0911 0.0778 0.0696 0.0656 0.0637 0.0629 0.0618 0.0615 0.0608 0.0603 0.0600 0.0597 0.0601 0.0605 

[TRAIN] Epoch[1](894/1500); Loss: 0.114252; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.2476 0.1627 0.1345 0.1129 0.1024 0.0992 0.1011 0.1012 0.0997 0.0981 0.0970 0.0958 0.0950 0.0942 0.0935 0.0929 

[TRAIN] Epoch[1](895/1500); Loss: 0.133151; Backpropagation: 0.0920 sec; Batch: 0.4266 sec
0.2680 0.2007 0.1735 0.1488 0.1313 0.1203 0.1152 0.1111 0.1110 0.1112 0.1097 0.1082 0.1067 0.1058 0.1048 0.1043 

[TRAIN] Epoch[1](896/1500); Loss: 0.073185; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1389 0.1253 0.1023 0.0822 0.0702 0.0640 0.0605 0.0590 0.0586 0.0578 0.0579 0.0583 0.0583 0.0589 0.0591 0.0595 

[TRAIN] Epoch[1](897/1500); Loss: 0.040747; Backpropagation: 0.0916 sec; Batch: 0.4261 sec
0.0494 0.0382 0.0444 0.0393 0.0383 0.0380 0.0380 0.0387 0.0389 0.0394 0.0400 0.0408 0.0414 0.0418 0.0423 0.0432 

[TRAIN] Epoch[1](898/1500); Loss: 0.104435; Backpropagation: 0.0915 sec; Batch: 0.4236 sec
0.2299 0.1725 0.1558 0.1357 0.1186 0.1052 0.0930 0.0831 0.0754 0.0714 0.0710 0.0728 0.0727 0.0719 0.0713 0.0706 

[TRAIN] Epoch[1](899/1500); Loss: 0.122375; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2994 0.2198 0.1957 0.1638 0.1372 0.1146 0.0974 0.0863 0.0819 0.0827 0.0820 0.0813 0.0802 0.0793 0.0785 0.0780 

[TRAIN] Epoch[1](900/1500); Loss: 0.121257; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.2393 0.1905 0.1722 0.1505 0.1344 0.1207 0.1090 0.0996 0.0935 0.0931 0.0927 0.0918 0.0902 0.0888 0.0875 0.0864 

[TRAIN] Epoch[1](901/1500); Loss: 0.071469; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1310 0.1007 0.0865 0.0815 0.0735 0.0680 0.0648 0.0628 0.0614 0.0605 0.0597 0.0595 0.0590 0.0586 0.0582 0.0579 

[TRAIN] Epoch[1](902/1500); Loss: 0.068966; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1207 0.0924 0.0796 0.0723 0.0674 0.0652 0.0635 0.0624 0.0616 0.0609 0.0604 0.0597 0.0596 0.0595 0.0592 0.0591 

[TRAIN] Epoch[1](903/1500); Loss: 0.107464; Backpropagation: 0.0917 sec; Batch: 0.4272 sec
0.1743 0.1382 0.1314 0.1194 0.1110 0.1049 0.1000 0.0965 0.0940 0.0928 0.0928 0.0928 0.0928 0.0928 0.0928 0.0930 

[TRAIN] Epoch[1](904/1500); Loss: 0.097402; Backpropagation: 0.0916 sec; Batch: 0.4399 sec
0.2143 0.1680 0.1465 0.1264 0.1115 0.1008 0.0922 0.0844 0.0773 0.0707 0.0653 0.0618 0.0599 0.0596 0.0599 0.0598 

[TRAIN] Epoch[1](905/1500); Loss: 0.096670; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.2102 0.1485 0.1306 0.1056 0.0867 0.0779 0.0799 0.0813 0.0799 0.0787 0.0779 0.0776 0.0780 0.0784 0.0779 0.0777 

[TRAIN] Epoch[1](906/1500); Loss: 0.152413; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2367 0.1923 0.1792 0.1657 0.1561 0.1495 0.1443 0.1402 0.1370 0.1352 0.1344 0.1341 0.1337 0.1334 0.1334 0.1333 

[TRAIN] Epoch[1](907/1500); Loss: 0.062501; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1986 0.1239 0.1021 0.0738 0.0593 0.0537 0.0492 0.0458 0.0419 0.0387 0.0367 0.0356 0.0352 0.0350 0.0351 0.0352 

[TRAIN] Epoch[1](908/1500); Loss: 0.093509; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.2483 0.1807 0.1571 0.1278 0.1047 0.0859 0.0716 0.0629 0.0591 0.0582 0.0582 0.0571 0.0565 0.0561 0.0560 0.0558 

[TRAIN] Epoch[1](909/1500); Loss: 0.063224; Backpropagation: 0.0919 sec; Batch: 0.4226 sec
0.1255 0.1008 0.0880 0.0756 0.0647 0.0583 0.0538 0.0528 0.0511 0.0497 0.0488 0.0484 0.0483 0.0484 0.0485 0.0488 

[TRAIN] Epoch[1](910/1500); Loss: 0.136290; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2765 0.2189 0.2032 0.1785 0.1568 0.1394 0.1243 0.1129 0.1039 0.0972 0.0956 0.0960 0.0950 0.0946 0.0942 0.0938 

[TRAIN] Epoch[1](911/1500); Loss: 0.118905; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.2749 0.2073 0.1846 0.1597 0.1401 0.1224 0.1068 0.0936 0.0838 0.0796 0.0779 0.0762 0.0749 0.0743 0.0736 0.0728 

[TRAIN] Epoch[1](912/1500); Loss: 0.103829; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.1528 0.1220 0.1147 0.1102 0.1041 0.1009 0.0998 0.0982 0.0974 0.0964 0.0957 0.0951 0.0941 0.0937 0.0932 0.0928 

[TRAIN] Epoch[1](913/1500); Loss: 0.126438; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1658 0.1467 0.1386 0.1303 0.1250 0.1231 0.1216 0.1202 0.1195 0.1192 0.1191 0.1191 0.1191 0.1188 0.1185 0.1185 

[TRAIN] Epoch[1](914/1500); Loss: 0.123068; Backpropagation: 0.0916 sec; Batch: 0.4226 sec
0.1577 0.1368 0.1381 0.1341 0.1260 0.1214 0.1189 0.1173 0.1160 0.1152 0.1149 0.1147 0.1146 0.1146 0.1144 0.1143 

[TRAIN] Epoch[1](915/1500); Loss: 0.099415; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2544 0.1731 0.1561 0.1258 0.1029 0.0855 0.0756 0.0719 0.0710 0.0699 0.0689 0.0679 0.0673 0.0670 0.0668 0.0667 

[TRAIN] Epoch[1](916/1500); Loss: 0.113771; Backpropagation: 0.0916 sec; Batch: 0.4271 sec
0.2560 0.2277 0.1739 0.1163 0.0869 0.0877 0.0912 0.0864 0.0857 0.0860 0.0862 0.0870 0.0872 0.0874 0.0872 0.0875 

[TRAIN] Epoch[1](917/1500); Loss: 0.084547; Backpropagation: 0.0917 sec; Batch: 0.4349 sec
0.1500 0.1146 0.1041 0.0948 0.0839 0.0789 0.0758 0.0741 0.0731 0.0723 0.0722 0.0718 0.0715 0.0718 0.0720 0.0720 

[TRAIN] Epoch[1](918/1500); Loss: 0.101706; Backpropagation: 0.0915 sec; Batch: 0.4588 sec
0.2249 0.1754 0.1579 0.1374 0.1207 0.1074 0.0956 0.0858 0.0781 0.0714 0.0661 0.0627 0.0621 0.0610 0.0605 0.0601 

[TRAIN] Epoch[1](919/1500); Loss: 0.196396; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2454 0.2205 0.2078 0.2028 0.1984 0.1933 0.1909 0.1900 0.1889 0.1876 0.1872 0.1865 0.1860 0.1857 0.1857 0.1855 

[TRAIN] Epoch[1](920/1500); Loss: 0.131460; Backpropagation: 0.0915 sec; Batch: 0.4394 sec
0.2610 0.2049 0.1861 0.1628 0.1449 0.1306 0.1195 0.1103 0.1034 0.0993 0.0975 0.0971 0.0968 0.0964 0.0964 0.0963 

[TRAIN] Epoch[1](921/1500); Loss: 0.119895; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.1806 0.1515 0.1389 0.1292 0.1232 0.1185 0.1153 0.1123 0.1098 0.1079 0.1066 0.1057 0.1051 0.1048 0.1046 0.1044 

[TRAIN] Epoch[1](922/1500); Loss: 0.104472; Backpropagation: 0.0919 sec; Batch: 0.4268 sec
0.1547 0.1437 0.1169 0.1038 0.1022 0.0980 0.0963 0.0956 0.0952 0.0947 0.0950 0.0950 0.0950 0.0951 0.0951 0.0952 

[TRAIN] Epoch[1](923/1500); Loss: 0.055294; Backpropagation: 0.0918 sec; Batch: 0.4313 sec
0.1179 0.0971 0.0817 0.0668 0.0550 0.0472 0.0426 0.0424 0.0426 0.0420 0.0418 0.0414 0.0413 0.0415 0.0416 0.0419 

[TRAIN] Epoch[1](924/1500); Loss: 0.042414; Backpropagation: 0.0919 sec; Batch: 0.4274 sec
0.0627 0.0540 0.0595 0.0551 0.0411 0.0391 0.0365 0.0358 0.0360 0.0361 0.0361 0.0359 0.0365 0.0377 0.0379 0.0388 

[TRAIN] Epoch[1](925/1500); Loss: 0.067423; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1485 0.1101 0.0917 0.0757 0.0672 0.0589 0.0548 0.0541 0.0527 0.0522 0.0520 0.0521 0.0520 0.0521 0.0522 0.0525 

[TRAIN] Epoch[1](926/1500); Loss: 0.106267; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2089 0.1640 0.1443 0.1234 0.1089 0.0966 0.0891 0.0863 0.0851 0.0851 0.0843 0.0841 0.0843 0.0848 0.0855 0.0856 

[TRAIN] Epoch[1](927/1500); Loss: 0.123108; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1987 0.1721 0.1530 0.1436 0.1317 0.1217 0.1134 0.1074 0.1064 0.1048 0.1041 0.1034 0.1028 0.1025 0.1022 0.1019 

[TRAIN] Epoch[1](928/1500); Loss: 0.084442; Backpropagation: 0.0916 sec; Batch: 0.4249 sec
0.1260 0.1029 0.0945 0.0879 0.0827 0.0806 0.0792 0.0783 0.0777 0.0774 0.0773 0.0773 0.0772 0.0772 0.0773 0.0774 

[TRAIN] Epoch[1](929/1500); Loss: 0.043489; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0819 0.0749 0.0553 0.0434 0.0393 0.0374 0.0364 0.0364 0.0364 0.0362 0.0361 0.0360 0.0363 0.0363 0.0366 0.0368 

[TRAIN] Epoch[1](930/1500); Loss: 0.155289; Backpropagation: 0.0916 sec; Batch: 0.4289 sec
0.1716 0.1604 0.1568 0.1572 0.1569 0.1542 0.1532 0.1531 0.1535 0.1535 0.1534 0.1528 0.1524 0.1522 0.1518 0.1517 

[TRAIN] Epoch[1](931/1500); Loss: 0.145539; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.2358 0.1771 0.1601 0.1489 0.1411 0.1373 0.1359 0.1353 0.1350 0.1342 0.1332 0.1323 0.1313 0.1308 0.1303 0.1301 

[TRAIN] Epoch[1](932/1500); Loss: 0.116960; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.3061 0.2265 0.1988 0.1646 0.1374 0.1121 0.0936 0.0858 0.0769 0.0702 0.0671 0.0668 0.0663 0.0663 0.0663 0.0666 

[TRAIN] Epoch[1](933/1500); Loss: 0.118087; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2619 0.1784 0.1538 0.1292 0.1113 0.1004 0.0975 0.0966 0.0960 0.0957 0.0955 0.0950 0.0948 0.0947 0.0945 0.0940 

[TRAIN] Epoch[1](934/1500); Loss: 0.134818; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.2364 0.1949 0.1727 0.1510 0.1369 0.1288 0.1230 0.1191 0.1152 0.1135 0.1132 0.1120 0.1111 0.1103 0.1098 0.1092 

[TRAIN] Epoch[1](935/1500); Loss: 0.090678; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1456 0.1268 0.1108 0.0994 0.0921 0.0874 0.0838 0.0809 0.0798 0.0790 0.0785 0.0782 0.0776 0.0774 0.0769 0.0767 

[TRAIN] Epoch[1](936/1500); Loss: 0.135278; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2424 0.1882 0.1588 0.1412 0.1285 0.1231 0.1209 0.1196 0.1188 0.1180 0.1176 0.1175 0.1175 0.1173 0.1174 0.1177 

[TRAIN] Epoch[1](937/1500); Loss: 0.044597; Backpropagation: 0.0917 sec; Batch: 0.4351 sec
0.0739 0.0662 0.0481 0.0490 0.0445 0.0400 0.0398 0.0390 0.0387 0.0389 0.0388 0.0390 0.0392 0.0392 0.0394 0.0398 

[TRAIN] Epoch[1](938/1500); Loss: 0.083934; Backpropagation: 0.0918 sec; Batch: 0.4277 sec
0.1637 0.1081 0.0931 0.0774 0.0742 0.0770 0.0758 0.0748 0.0741 0.0739 0.0739 0.0744 0.0750 0.0757 0.0757 0.0762 

[TRAIN] Epoch[1](939/1500); Loss: 0.136908; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3970 0.2848 0.2494 0.2025 0.1622 0.1233 0.0880 0.0738 0.0873 0.0795 0.0773 0.0746 0.0732 0.0723 0.0724 0.0731 

[TRAIN] Epoch[1](940/1500); Loss: 0.111208; Backpropagation: 0.0916 sec; Batch: 0.4617 sec
0.1942 0.1688 0.1323 0.1145 0.1100 0.1006 0.0991 0.0970 0.0962 0.0958 0.0956 0.0953 0.0952 0.0949 0.0948 0.0950 

[TRAIN] Epoch[1](941/1500); Loss: 0.108617; Backpropagation: 0.0917 sec; Batch: 0.4271 sec
0.1616 0.1309 0.1165 0.1116 0.1071 0.1025 0.1011 0.1003 0.0999 0.1000 0.1002 0.1005 0.1006 0.1013 0.1016 0.1021 

[TRAIN] Epoch[1](942/1500); Loss: 0.087103; Backpropagation: 0.0916 sec; Batch: 0.4561 sec
0.1967 0.1357 0.1125 0.0948 0.0833 0.0744 0.0710 0.0715 0.0703 0.0696 0.0691 0.0689 0.0687 0.0690 0.0690 0.0691 

[TRAIN] Epoch[1](943/1500); Loss: 0.115700; Backpropagation: 0.0918 sec; Batch: 0.4295 sec
0.3015 0.1891 0.1641 0.1315 0.1075 0.0934 0.0893 0.0880 0.0873 0.0867 0.0865 0.0859 0.0857 0.0853 0.0849 0.0844 

[TRAIN] Epoch[1](944/1500); Loss: 0.125695; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1974 0.1615 0.1501 0.1330 0.1253 0.1187 0.1156 0.1140 0.1132 0.1123 0.1120 0.1118 0.1119 0.1118 0.1115 0.1111 

[TRAIN] Epoch[1](945/1500); Loss: 0.079958; Backpropagation: 0.0985 sec; Batch: 0.4442 sec
0.1537 0.1048 0.0914 0.0793 0.0771 0.0743 0.0729 0.0714 0.0703 0.0695 0.0690 0.0688 0.0689 0.0691 0.0692 0.0695 

[TRAIN] Epoch[1](946/1500); Loss: 0.042919; Backpropagation: 0.0920 sec; Batch: 0.4260 sec
0.0573 0.0505 0.0460 0.0424 0.0424 0.0412 0.0408 0.0403 0.0402 0.0405 0.0405 0.0405 0.0406 0.0410 0.0412 0.0413 

[TRAIN] Epoch[1](947/1500); Loss: 0.080721; Backpropagation: 0.0920 sec; Batch: 0.4267 sec
0.1857 0.1465 0.1116 0.0830 0.0734 0.0672 0.0665 0.0643 0.0634 0.0624 0.0619 0.0613 0.0608 0.0610 0.0614 0.0612 

[TRAIN] Epoch[1](948/1500); Loss: 0.170678; Backpropagation: 0.0918 sec; Batch: 0.4265 sec
0.2784 0.2208 0.1952 0.1699 0.1597 0.1566 0.1566 0.1553 0.1551 0.1545 0.1545 0.1548 0.1548 0.1545 0.1549 0.1552 

[TRAIN] Epoch[1](949/1500); Loss: 0.077378; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1285 0.1186 0.0807 0.0776 0.0700 0.0733 0.0697 0.0689 0.0685 0.0685 0.0691 0.0689 0.0689 0.0686 0.0688 0.0696 

[TRAIN] Epoch[1](950/1500); Loss: 0.107087; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.2437 0.1738 0.1364 0.1100 0.0970 0.0905 0.0918 0.0888 0.0873 0.0862 0.0855 0.0851 0.0848 0.0844 0.0841 0.0840 

[TRAIN] Epoch[1](951/1500); Loss: 0.050433; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0955 0.0736 0.0530 0.0668 0.0515 0.0460 0.0442 0.0430 0.0425 0.0423 0.0419 0.0417 0.0414 0.0412 0.0413 0.0411 

[TRAIN] Epoch[1](952/1500); Loss: 0.082742; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1379 0.1146 0.0915 0.0803 0.0763 0.0758 0.0751 0.0746 0.0748 0.0744 0.0747 0.0745 0.0745 0.0748 0.0750 0.0751 

[TRAIN] Epoch[1](953/1500); Loss: 0.065280; Backpropagation: 0.0919 sec; Batch: 0.4264 sec
0.1257 0.1021 0.0831 0.0714 0.0642 0.0602 0.0573 0.0552 0.0541 0.0536 0.0534 0.0531 0.0529 0.0527 0.0528 0.0527 

[TRAIN] Epoch[1](954/1500); Loss: 0.074562; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1977 0.1215 0.0932 0.0778 0.0669 0.0636 0.0607 0.0593 0.0581 0.0571 0.0564 0.0561 0.0561 0.0564 0.0561 0.0562 

[TRAIN] Epoch[1](955/1500); Loss: 0.080185; Backpropagation: 0.0918 sec; Batch: 0.4265 sec
0.1546 0.1078 0.0883 0.0784 0.0756 0.0729 0.0718 0.0702 0.0696 0.0697 0.0697 0.0699 0.0702 0.0706 0.0713 0.0722 

[TRAIN] Epoch[1](956/1500); Loss: 0.107960; Backpropagation: 0.0916 sec; Batch: 0.4512 sec
0.1635 0.1305 0.1158 0.1080 0.1051 0.1026 0.1010 0.1002 0.0998 0.0996 0.0996 0.0997 0.0998 0.1004 0.1006 0.1011 

[TRAIN] Epoch[1](957/1500); Loss: 0.070783; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1563 0.0980 0.0849 0.0778 0.0711 0.0632 0.0608 0.0595 0.0583 0.0580 0.0577 0.0576 0.0574 0.0573 0.0574 0.0571 

[TRAIN] Epoch[1](958/1500); Loss: 0.088026; Backpropagation: 0.0916 sec; Batch: 0.4617 sec
0.1595 0.1184 0.1091 0.0989 0.0940 0.0886 0.0836 0.0801 0.0763 0.0738 0.0719 0.0711 0.0712 0.0708 0.0706 0.0705 

[TRAIN] Epoch[1](959/1500); Loss: 0.121915; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.2862 0.1620 0.1416 0.1191 0.1083 0.1052 0.1037 0.1027 0.1022 0.1019 0.1020 0.1025 0.1028 0.1031 0.1036 0.1040 

[TRAIN] Epoch[1](960/1500); Loss: 0.053324; Backpropagation: 0.0916 sec; Batch: 0.4257 sec
0.1400 0.1065 0.0638 0.0679 0.0543 0.0409 0.0396 0.0376 0.0370 0.0364 0.0378 0.0374 0.0375 0.0386 0.0386 0.0394 

[TRAIN] Epoch[1](961/1500); Loss: 0.097413; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1662 0.1323 0.1047 0.1083 0.0986 0.0921 0.0895 0.0880 0.0867 0.0854 0.0851 0.0848 0.0847 0.0843 0.0840 0.0840 

[TRAIN] Epoch[1](962/1500); Loss: 0.100615; Backpropagation: 0.0915 sec; Batch: 0.4627 sec
0.1945 0.1414 0.1225 0.1108 0.0987 0.0915 0.0870 0.0868 0.0855 0.0845 0.0841 0.0845 0.0842 0.0842 0.0846 0.0851 

[TRAIN] Epoch[1](963/1500); Loss: 0.100973; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1959 0.1323 0.1285 0.1091 0.0977 0.0908 0.0879 0.0877 0.0869 0.0862 0.0860 0.0858 0.0853 0.0851 0.0851 0.0851 

[TRAIN] Epoch[1](964/1500); Loss: 0.104968; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.1904 0.1436 0.1270 0.1149 0.1052 0.1003 0.0964 0.0932 0.0910 0.0901 0.0895 0.0888 0.0882 0.0874 0.0868 0.0867 

[TRAIN] Epoch[1](965/1500); Loss: 0.077605; Backpropagation: 0.0924 sec; Batch: 0.4234 sec
0.1378 0.1279 0.0961 0.0836 0.0718 0.0676 0.0663 0.0661 0.0658 0.0655 0.0653 0.0654 0.0654 0.0655 0.0656 0.0658 

[TRAIN] Epoch[1](966/1500); Loss: 0.072113; Backpropagation: 0.0917 sec; Batch: 0.4262 sec
0.1328 0.0968 0.0779 0.0837 0.0750 0.0671 0.0649 0.0636 0.0623 0.0619 0.0616 0.0615 0.0612 0.0610 0.0610 0.0614 

[TRAIN] Epoch[1](967/1500); Loss: 0.093123; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1649 0.1209 0.1077 0.1017 0.0954 0.0905 0.0866 0.0836 0.0813 0.0801 0.0798 0.0798 0.0796 0.0794 0.0794 0.0792 

[TRAIN] Epoch[1](968/1500); Loss: 0.118614; Backpropagation: 0.0918 sec; Batch: 0.4275 sec
0.2455 0.1778 0.1550 0.1372 0.1230 0.1105 0.1008 0.0951 0.0944 0.0938 0.0939 0.0938 0.0938 0.0941 0.0944 0.0947 

[TRAIN] Epoch[1](969/1500); Loss: 0.105565; Backpropagation: 0.0918 sec; Batch: 0.4270 sec
0.1757 0.1567 0.1229 0.1234 0.1086 0.0961 0.0934 0.0918 0.0910 0.0906 0.0907 0.0903 0.0900 0.0895 0.0893 0.0891 

[TRAIN] Epoch[1](970/1500); Loss: 0.091499; Backpropagation: 0.0915 sec; Batch: 0.4248 sec
0.1889 0.1338 0.0981 0.0976 0.0932 0.0798 0.0793 0.0776 0.0772 0.0769 0.0768 0.0768 0.0769 0.0768 0.0770 0.0772 

[TRAIN] Epoch[1](971/1500); Loss: 0.093745; Backpropagation: 0.0922 sec; Batch: 0.4252 sec
0.1372 0.1051 0.0986 0.0955 0.0933 0.0918 0.0905 0.0894 0.0886 0.0880 0.0877 0.0873 0.0872 0.0871 0.0866 0.0863 

[TRAIN] Epoch[1](972/1500); Loss: 0.106763; Backpropagation: 0.0914 sec; Batch: 0.4630 sec
0.1795 0.1656 0.1217 0.1063 0.1025 0.0984 0.0976 0.0955 0.0943 0.0934 0.0927 0.0924 0.0922 0.0922 0.0921 0.0919 

[TRAIN] Epoch[1](973/1500); Loss: 0.062845; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2225 0.0966 0.0827 0.0680 0.0584 0.0549 0.0500 0.0462 0.0431 0.0416 0.0409 0.0403 0.0404 0.0402 0.0400 0.0398 

[TRAIN] Epoch[1](974/1500); Loss: 0.064358; Backpropagation: 0.0916 sec; Batch: 0.4347 sec
0.0690 0.0695 0.0741 0.0691 0.0652 0.0630 0.0624 0.0622 0.0621 0.0619 0.0617 0.0618 0.0618 0.0619 0.0620 0.0620 

[TRAIN] Epoch[1](975/1500); Loss: 0.082635; Backpropagation: 0.0918 sec; Batch: 0.4260 sec
0.1274 0.1239 0.0841 0.0810 0.0787 0.0774 0.0760 0.0752 0.0748 0.0747 0.0746 0.0746 0.0747 0.0748 0.0749 0.0753 

[TRAIN] Epoch[1](976/1500); Loss: 0.078059; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1154 0.0965 0.0857 0.0826 0.0764 0.0744 0.0734 0.0729 0.0723 0.0718 0.0714 0.0715 0.0714 0.0712 0.0711 0.0709 

[TRAIN] Epoch[1](977/1500); Loss: 0.074574; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2080 0.1116 0.0936 0.0760 0.0683 0.0633 0.0609 0.0595 0.0589 0.0578 0.0569 0.0565 0.0560 0.0555 0.0553 0.0550 

[TRAIN] Epoch[1](978/1500); Loss: 0.088131; Backpropagation: 0.0916 sec; Batch: 0.4269 sec
0.1862 0.1412 0.0997 0.1083 0.0903 0.0749 0.0747 0.0714 0.0707 0.0701 0.0700 0.0705 0.0708 0.0704 0.0705 0.0706 

[TRAIN] Epoch[1](979/1500); Loss: 0.126419; Backpropagation: 0.0918 sec; Batch: 0.4311 sec
0.2551 0.1737 0.1524 0.1330 0.1196 0.1131 0.1110 0.1096 0.1084 0.1076 0.1070 0.1068 0.1065 0.1064 0.1063 0.1062 

[TRAIN] Epoch[1](980/1500); Loss: 0.105309; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1767 0.1312 0.1254 0.1105 0.1026 0.0964 0.0950 0.0948 0.0943 0.0939 0.0939 0.0940 0.0942 0.0941 0.0939 0.0940 

[TRAIN] Epoch[1](981/1500); Loss: 0.055100; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1510 0.1058 0.0840 0.0716 0.0592 0.0477 0.0411 0.0390 0.0368 0.0358 0.0353 0.0350 0.0347 0.0346 0.0349 0.0351 

[TRAIN] Epoch[1](982/1500); Loss: 0.126935; Backpropagation: 0.0916 sec; Batch: 0.4268 sec
0.3595 0.2528 0.2244 0.1921 0.1579 0.1285 0.1022 0.0809 0.0658 0.0732 0.0676 0.0660 0.0650 0.0647 0.0649 0.0655 

[TRAIN] Epoch[1](983/1500); Loss: 0.115734; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1617 0.1467 0.1266 0.1223 0.1173 0.1130 0.1109 0.1092 0.1079 0.1066 0.1061 0.1055 0.1049 0.1044 0.1043 0.1043 

[TRAIN] Epoch[1](984/1500); Loss: 0.111680; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.2584 0.1706 0.1381 0.1195 0.1069 0.0977 0.0933 0.0911 0.0899 0.0892 0.0889 0.0888 0.0885 0.0887 0.0888 0.0885 

[TRAIN] Epoch[1](985/1500); Loss: 0.035954; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.0512 0.0585 0.0412 0.0368 0.0316 0.0314 0.0316 0.0314 0.0313 0.0315 0.0322 0.0325 0.0326 0.0332 0.0339 0.0343 

[TRAIN] Epoch[1](986/1500); Loss: 0.083986; Backpropagation: 0.0915 sec; Batch: 0.4230 sec
0.2090 0.1304 0.0975 0.0777 0.0715 0.0701 0.0699 0.0695 0.0705 0.0694 0.0686 0.0682 0.0679 0.0683 0.0679 0.0677 

[TRAIN] Epoch[1](987/1500); Loss: 0.095021; Backpropagation: 0.0917 sec; Batch: 0.4436 sec
0.1578 0.1229 0.1081 0.1011 0.0946 0.0906 0.0881 0.0865 0.0852 0.0846 0.0842 0.0838 0.0835 0.0834 0.0831 0.0828 

[TRAIN] Epoch[1](988/1500); Loss: 0.039997; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.0500 0.0632 0.0853 0.0517 0.0327 0.0321 0.0320 0.0341 0.0332 0.0310 0.0309 0.0323 0.0322 0.0329 0.0327 0.0338 

[TRAIN] Epoch[1](989/1500); Loss: 0.096291; Backpropagation: 0.0920 sec; Batch: 0.4267 sec
0.2396 0.1433 0.1208 0.0942 0.0836 0.0842 0.0798 0.0786 0.0776 0.0768 0.0766 0.0765 0.0772 0.0772 0.0773 0.0774 

[TRAIN] Epoch[1](990/1500); Loss: 0.112821; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2685 0.1991 0.1500 0.1226 0.1068 0.0964 0.0894 0.0887 0.0868 0.0857 0.0854 0.0855 0.0852 0.0851 0.0850 0.0850 

[TRAIN] Epoch[1](991/1500); Loss: 0.085401; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1014 0.0957 0.0945 0.0900 0.0831 0.0822 0.0817 0.0819 0.0816 0.0818 0.0820 0.0817 0.0820 0.0823 0.0820 0.0826 

[TRAIN] Epoch[1](992/1500); Loss: 0.065377; Backpropagation: 0.0916 sec; Batch: 0.4224 sec
0.1786 0.1025 0.0696 0.0652 0.0562 0.0554 0.0530 0.0522 0.0518 0.0515 0.0515 0.0515 0.0514 0.0515 0.0519 0.0522 

[TRAIN] Epoch[1](993/1500); Loss: 0.099110; Backpropagation: 0.0919 sec; Batch: 0.4416 sec
0.1412 0.1417 0.1157 0.1056 0.0952 0.0926 0.0910 0.0902 0.0894 0.0890 0.0890 0.0888 0.0888 0.0892 0.0892 0.0893 

[TRAIN] Epoch[1](994/1500); Loss: 0.111128; Backpropagation: 0.0916 sec; Batch: 0.4226 sec
0.3540 0.2200 0.1984 0.1564 0.1237 0.0961 0.0741 0.0652 0.0648 0.0628 0.0616 0.0607 0.0602 0.0600 0.0600 0.0600 

[TRAIN] Epoch[1](995/1500); Loss: 0.117298; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2240 0.1593 0.1470 0.1316 0.1207 0.1123 0.1062 0.1012 0.0979 0.0965 0.0972 0.0973 0.0971 0.0965 0.0960 0.0959 

[TRAIN] Epoch[1](996/1500); Loss: 0.109120; Backpropagation: 0.0916 sec; Batch: 0.4461 sec
0.1723 0.1282 0.1240 0.1166 0.1117 0.1075 0.1042 0.1013 0.0993 0.0984 0.0978 0.0972 0.0970 0.0968 0.0968 0.0967 

[TRAIN] Epoch[1](997/1500); Loss: 0.134723; Backpropagation: 0.0920 sec; Batch: 0.4257 sec
0.2038 0.1583 0.1490 0.1383 0.1321 0.1299 0.1278 0.1264 0.1251 0.1244 0.1238 0.1235 0.1234 0.1233 0.1232 0.1232 

[TRAIN] Epoch[1](998/1500); Loss: 0.069918; Backpropagation: 0.0915 sec; Batch: 0.4229 sec
0.0814 0.0937 0.0786 0.0786 0.0728 0.0709 0.0680 0.0667 0.0651 0.0644 0.0638 0.0632 0.0627 0.0629 0.0632 0.0629 

[TRAIN] Epoch[1](999/1500); Loss: 0.156995; Backpropagation: 0.0916 sec; Batch: 0.4404 sec
0.1982 0.1656 0.1635 0.1564 0.1546 0.1543 0.1541 0.1533 0.1528 0.1524 0.1519 0.1516 0.1510 0.1507 0.1507 0.1506 

[TRAIN] Epoch[1](1000/1500); Loss: 0.092030; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.2002 0.1485 0.1317 0.1102 0.0937 0.0835 0.0772 0.0754 0.0741 0.0722 0.0703 0.0690 0.0679 0.0670 0.0662 0.0655 

[TRAIN] Epoch[1](1001/1500); Loss: 0.107717; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1685 0.1358 0.1192 0.1088 0.1022 0.1000 0.0991 0.0992 0.0987 0.0982 0.0981 0.0984 0.0985 0.0986 0.0996 0.1006 

[TRAIN] Epoch[1](1002/1500); Loss: 0.114011; Backpropagation: 0.1013 sec; Batch: 0.4504 sec
0.1586 0.1336 0.1244 0.1143 0.1109 0.1092 0.1084 0.1079 0.1077 0.1073 0.1072 0.1072 0.1071 0.1070 0.1068 0.1066 

[TRAIN] Epoch[1](1003/1500); Loss: 0.088158; Backpropagation: 0.0925 sec; Batch: 0.4249 sec
0.2181 0.1483 0.1277 0.0956 0.0807 0.0726 0.0696 0.0688 0.0681 0.0670 0.0663 0.0657 0.0655 0.0655 0.0653 0.0656 

[TRAIN] Epoch[1](1004/1500); Loss: 0.109512; Backpropagation: 0.0927 sec; Batch: 0.4281 sec
0.1736 0.1455 0.1236 0.1113 0.1076 0.1033 0.1018 0.1002 0.0994 0.0989 0.0984 0.0978 0.0976 0.0977 0.0975 0.0980 

[TRAIN] Epoch[1](1005/1500); Loss: 0.096948; Backpropagation: 0.0921 sec; Batch: 0.4248 sec
0.1501 0.1164 0.1028 0.0928 0.0948 0.0914 0.0909 0.0905 0.0905 0.0901 0.0897 0.0898 0.0900 0.0901 0.0903 0.0909 

[TRAIN] Epoch[1](1006/1500); Loss: 0.103735; Backpropagation: 0.0918 sec; Batch: 0.4278 sec
0.1547 0.1425 0.1185 0.1114 0.1037 0.1005 0.0974 0.0958 0.0941 0.0929 0.0921 0.0917 0.0914 0.0912 0.0911 0.0909 

[TRAIN] Epoch[1](1007/1500); Loss: 0.126903; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2098 0.1834 0.1524 0.1397 0.1286 0.1217 0.1155 0.1115 0.1098 0.1090 0.1084 0.1080 0.1079 0.1081 0.1082 0.1084 

[TRAIN] Epoch[1](1008/1500); Loss: 0.198519; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2110 0.1949 0.2273 0.2034 0.2013 0.2009 0.1998 0.1978 0.1960 0.1952 0.1941 0.1927 0.1917 0.1909 0.1902 0.1891 

[TRAIN] Epoch[1](1009/1500); Loss: 0.068103; Backpropagation: 0.0921 sec; Batch: 0.4255 sec
0.0766 0.0813 0.0969 0.0802 0.0764 0.0725 0.0695 0.0663 0.0639 0.0617 0.0598 0.0584 0.0575 0.0567 0.0562 0.0558 

[TRAIN] Epoch[1](1010/1500); Loss: 0.121946; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.1727 0.1683 0.1423 0.1327 0.1230 0.1188 0.1157 0.1130 0.1112 0.1101 0.1091 0.1081 0.1075 0.1068 0.1063 0.1058 

[TRAIN] Epoch[1](1011/1500); Loss: 0.152122; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1872 0.1605 0.1781 0.1603 0.1536 0.1518 0.1505 0.1477 0.1458 0.1445 0.1436 0.1427 0.1422 0.1420 0.1418 0.1418 

[TRAIN] Epoch[1](1012/1500); Loss: 0.131566; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1695 0.1518 0.1371 0.1334 0.1293 0.1281 0.1275 0.1268 0.1262 0.1257 0.1253 0.1251 0.1250 0.1247 0.1248 0.1247 

[TRAIN] Epoch[1](1013/1500); Loss: 0.133161; Backpropagation: 0.0918 sec; Batch: 0.4271 sec
0.1764 0.1705 0.1446 0.1380 0.1316 0.1288 0.1272 0.1259 0.1253 0.1245 0.1237 0.1232 0.1229 0.1228 0.1226 0.1225 

[TRAIN] Epoch[1](1014/1500); Loss: 0.121546; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1987 0.1626 0.1362 0.1263 0.1184 0.1145 0.1128 0.1113 0.1100 0.1093 0.1084 0.1077 0.1073 0.1070 0.1072 0.1071 

[TRAIN] Epoch[1](1015/1500); Loss: 0.109529; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.4183 0.2941 0.2616 0.1880 0.1265 0.0676 0.0402 0.0448 0.0390 0.0377 0.0368 0.0374 0.0382 0.0391 0.0408 0.0424 

[TRAIN] Epoch[1](1016/1500); Loss: 0.096443; Backpropagation: 0.0951 sec; Batch: 0.4285 sec
0.2712 0.1902 0.1678 0.1284 0.1011 0.0778 0.0631 0.0618 0.0605 0.0599 0.0595 0.0595 0.0598 0.0603 0.0608 0.0614 

[TRAIN] Epoch[1](1017/1500); Loss: 0.072767; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.2267 0.1227 0.1080 0.0764 0.0654 0.0552 0.0525 0.0511 0.0503 0.0499 0.0500 0.0502 0.0504 0.0510 0.0517 0.0526 

[TRAIN] Epoch[1](1018/1500); Loss: 0.117700; Backpropagation: 0.0935 sec; Batch: 0.4266 sec
0.1703 0.1494 0.1402 0.1278 0.1202 0.1146 0.1120 0.1098 0.1083 0.1070 0.1056 0.1048 0.1040 0.1033 0.1030 0.1029 

[TRAIN] Epoch[1](1019/1500); Loss: 0.129573; Backpropagation: 0.0923 sec; Batch: 0.4270 sec
0.1693 0.1481 0.1430 0.1344 0.1300 0.1257 0.1234 0.1227 0.1220 0.1217 0.1217 0.1218 0.1220 0.1222 0.1225 0.1228 

[TRAIN] Epoch[1](1020/1500); Loss: 0.100279; Backpropagation: 0.0918 sec; Batch: 0.4255 sec
0.1565 0.1405 0.1163 0.1090 0.0985 0.0935 0.0921 0.0906 0.0900 0.0891 0.0886 0.0881 0.0878 0.0879 0.0878 0.0881 

[TRAIN] Epoch[1](1021/1500); Loss: 0.135480; Backpropagation: 0.0920 sec; Batch: 0.4268 sec
0.2649 0.2095 0.1970 0.1640 0.1433 0.1238 0.1106 0.1076 0.1064 0.1056 0.1054 0.1054 0.1056 0.1060 0.1062 0.1064 

[TRAIN] Epoch[1](1022/1500); Loss: 0.120225; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1871 0.1723 0.1345 0.1267 0.1185 0.1144 0.1122 0.1096 0.1078 0.1069 0.1063 0.1059 0.1054 0.1051 0.1053 0.1055 

[TRAIN] Epoch[1](1023/1500); Loss: 0.160915; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2224 0.2116 0.1930 0.1755 0.1617 0.1551 0.1526 0.1502 0.1484 0.1465 0.1455 0.1440 0.1430 0.1421 0.1419 0.1412 

[TRAIN] Epoch[1](1024/1500); Loss: 0.084052; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1998 0.1195 0.0977 0.0890 0.0810 0.0760 0.0730 0.0704 0.0696 0.0678 0.0666 0.0658 0.0657 0.0676 0.0675 0.0678 

[TRAIN] Epoch[1](1025/1500); Loss: 0.119243; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2624 0.2449 0.1981 0.1628 0.1302 0.1031 0.0852 0.0846 0.0817 0.0804 0.0793 0.0790 0.0786 0.0789 0.0793 0.0795 

[TRAIN] Epoch[1](1026/1500); Loss: 0.090121; Backpropagation: 0.0917 sec; Batch: 0.4415 sec
0.1228 0.1101 0.0969 0.0915 0.0883 0.0870 0.0858 0.0850 0.0845 0.0846 0.0844 0.0839 0.0842 0.0842 0.0845 0.0843 

[TRAIN] Epoch[1](1027/1500); Loss: 0.090079; Backpropagation: 0.0918 sec; Batch: 0.4287 sec
0.1587 0.1756 0.1279 0.1035 0.0825 0.0722 0.0725 0.0724 0.0711 0.0705 0.0703 0.0722 0.0721 0.0728 0.0730 0.0740 

[TRAIN] Epoch[1](1028/1500); Loss: 0.072621; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1123 0.1124 0.0768 0.0785 0.0724 0.0722 0.0678 0.0658 0.0639 0.0632 0.0629 0.0625 0.0625 0.0634 0.0629 0.0627 

[TRAIN] Epoch[1](1029/1500); Loss: 0.089555; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1247 0.1427 0.1091 0.0987 0.0898 0.0848 0.0821 0.0810 0.0802 0.0791 0.0781 0.0774 0.0770 0.0763 0.0762 0.0757 

[TRAIN] Epoch[1](1030/1500); Loss: 0.089873; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1211 0.1245 0.1047 0.0978 0.0921 0.0870 0.0840 0.0829 0.0818 0.0821 0.0811 0.0802 0.0796 0.0797 0.0798 0.0798 

[TRAIN] Epoch[1](1031/1500); Loss: 0.095292; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1409 0.1422 0.1154 0.0953 0.0895 0.0894 0.0883 0.0870 0.0860 0.0850 0.0848 0.0843 0.0840 0.0842 0.0842 0.0843 

[TRAIN] Epoch[1](1032/1500); Loss: 0.093492; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1557 0.1680 0.1319 0.1058 0.0884 0.0834 0.0817 0.0796 0.0778 0.0762 0.0754 0.0748 0.0744 0.0743 0.0742 0.0741 

[TRAIN] Epoch[1](1033/1500); Loss: 0.109186; Backpropagation: 0.0917 sec; Batch: 0.4638 sec
0.1463 0.1425 0.1187 0.1145 0.1079 0.1039 0.1031 0.1024 0.1021 0.1015 0.1010 0.1007 0.1006 0.1004 0.1006 0.1007 

[TRAIN] Epoch[1](1034/1500); Loss: 0.073821; Backpropagation: 0.0919 sec; Batch: 0.4273 sec
0.0809 0.0753 0.0694 0.0752 0.0727 0.0720 0.0713 0.0714 0.0716 0.0720 0.0727 0.0747 0.0746 0.0752 0.0757 0.0764 

[TRAIN] Epoch[1](1035/1500); Loss: 0.127258; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1863 0.1896 0.1256 0.1274 0.1210 0.1183 0.1172 0.1163 0.1158 0.1152 0.1159 0.1161 0.1167 0.1170 0.1186 0.1189 

[TRAIN] Epoch[1](1036/1500); Loss: 0.110619; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1721 0.1606 0.1262 0.1143 0.1120 0.1069 0.1045 0.1023 0.1002 0.0985 0.0973 0.0958 0.0953 0.0947 0.0945 0.0946 

[TRAIN] Epoch[1](1037/1500); Loss: 0.156712; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2077 0.2020 0.1677 0.1652 0.1583 0.1547 0.1522 0.1501 0.1483 0.1461 0.1447 0.1438 0.1424 0.1416 0.1415 0.1410 

[TRAIN] Epoch[1](1038/1500); Loss: 0.141381; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2323 0.2089 0.1590 0.1448 0.1377 0.1338 0.1315 0.1287 0.1270 0.1249 0.1232 0.1221 0.1220 0.1215 0.1224 0.1224 

[TRAIN] Epoch[1](1039/1500); Loss: 0.072387; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1051 0.1028 0.0930 0.0827 0.0744 0.0689 0.0674 0.0659 0.0646 0.0630 0.0628 0.0624 0.0618 0.0612 0.0614 0.0610 

[TRAIN] Epoch[1](1040/1500); Loss: 0.108687; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1133 0.1378 0.1236 0.1088 0.1104 0.1072 0.1053 0.1040 0.1035 0.1032 0.1029 0.1030 0.1029 0.1035 0.1046 0.1050 

[TRAIN] Epoch[1](1041/1500); Loss: 0.095277; Backpropagation: 0.0920 sec; Batch: 0.4289 sec
0.1516 0.1839 0.1420 0.1032 0.0799 0.0864 0.0818 0.0791 0.0772 0.0763 0.0762 0.0761 0.0768 0.0780 0.0779 0.0781 

[TRAIN] Epoch[1](1042/1500); Loss: 0.065396; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0666 0.0919 0.1013 0.0741 0.0601 0.0604 0.0605 0.0580 0.0576 0.0573 0.0579 0.0585 0.0612 0.0602 0.0600 0.0607 

[TRAIN] Epoch[1](1043/1500); Loss: 0.133595; Backpropagation: 0.0919 sec; Batch: 0.4251 sec
0.2179 0.2039 0.1565 0.1512 0.1371 0.1266 0.1207 0.1178 0.1181 0.1170 0.1153 0.1133 0.1119 0.1109 0.1100 0.1094 

[TRAIN] Epoch[1](1044/1500); Loss: 0.087799; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1570 0.1333 0.1057 0.1009 0.0893 0.0837 0.0815 0.0786 0.0773 0.0746 0.0730 0.0716 0.0704 0.0691 0.0697 0.0689 

[TRAIN] Epoch[1](1045/1500); Loss: 0.119527; Backpropagation: 0.0920 sec; Batch: 0.4275 sec
0.1857 0.1930 0.1518 0.1441 0.1248 0.1097 0.1014 0.1024 0.1047 0.1038 0.1017 0.1000 0.0986 0.0977 0.0968 0.0962 

[TRAIN] Epoch[1](1046/1500); Loss: 0.106703; Backpropagation: 0.0917 sec; Batch: 0.4554 sec
0.1588 0.1463 0.1112 0.1080 0.1014 0.1005 0.1005 0.0997 0.0986 0.0978 0.0972 0.0971 0.0972 0.0974 0.0974 0.0981 

[TRAIN] Epoch[1](1047/1500); Loss: 0.096192; Backpropagation: 0.0917 sec; Batch: 0.4672 sec
0.1867 0.1701 0.1125 0.1061 0.0931 0.0886 0.0871 0.0831 0.0804 0.0785 0.0771 0.0761 0.0754 0.0749 0.0747 0.0746 

[TRAIN] Epoch[1](1048/1500); Loss: 0.115524; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2306 0.1977 0.1429 0.1320 0.1189 0.1085 0.1019 0.0992 0.0986 0.0958 0.0931 0.0902 0.0880 0.0855 0.0835 0.0819 

[TRAIN] Epoch[1](1049/1500); Loss: 0.076041; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1084 0.1466 0.1189 0.0801 0.0636 0.0780 0.0745 0.0708 0.0674 0.0646 0.0618 0.0593 0.0573 0.0560 0.0550 0.0544 

[TRAIN] Epoch[1](1050/1500); Loss: 0.059470; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0759 0.0649 0.0602 0.0583 0.0573 0.0575 0.0572 0.0572 0.0577 0.0579 0.0578 0.0575 0.0576 0.0581 0.0581 0.0584 

[TRAIN] Epoch[1](1051/1500); Loss: 0.089570; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1542 0.1672 0.1055 0.1114 0.0885 0.0783 0.0777 0.0783 0.0781 0.0758 0.0734 0.0714 0.0698 0.0685 0.0677 0.0672 

[TRAIN] Epoch[1](1052/1500); Loss: 0.107770; Backpropagation: 0.0916 sec; Batch: 0.4384 sec
0.1563 0.1473 0.1178 0.1186 0.1096 0.1038 0.0992 0.0980 0.0990 0.0981 0.0976 0.0969 0.0963 0.0956 0.0954 0.0947 

[TRAIN] Epoch[1](1053/1500); Loss: 0.114609; Backpropagation: 0.0920 sec; Batch: 0.4313 sec
0.1876 0.1676 0.1255 0.1174 0.1125 0.1096 0.1074 0.1051 0.1035 0.1018 0.1012 0.1000 0.0991 0.0988 0.0984 0.0982 

[TRAIN] Epoch[1](1054/1500); Loss: 0.075436; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.0945 0.0913 0.0938 0.0802 0.0775 0.0751 0.0734 0.0715 0.0702 0.0692 0.0686 0.0682 0.0680 0.0684 0.0685 0.0687 

[TRAIN] Epoch[1](1055/1500); Loss: 0.111871; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1893 0.1620 0.1249 0.1138 0.1075 0.1063 0.1049 0.1032 0.1016 0.0999 0.0984 0.0972 0.0961 0.0953 0.0951 0.0943 

[TRAIN] Epoch[1](1056/1500); Loss: 0.120346; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1548 0.1484 0.1308 0.1241 0.1227 0.1200 0.1179 0.1159 0.1143 0.1131 0.1122 0.1111 0.1103 0.1102 0.1100 0.1096 

[TRAIN] Epoch[1](1057/1500); Loss: 0.093020; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1857 0.1974 0.1104 0.1215 0.0872 0.0728 0.0716 0.0811 0.0784 0.0755 0.0720 0.0694 0.0673 0.0661 0.0657 0.0664 

[TRAIN] Epoch[1](1058/1500); Loss: 0.081604; Backpropagation: 0.0919 sec; Batch: 0.4262 sec
0.1279 0.1282 0.0886 0.0826 0.0812 0.0801 0.0791 0.0763 0.0739 0.0718 0.0704 0.0695 0.0689 0.0692 0.0692 0.0688 

[TRAIN] Epoch[1](1059/1500); Loss: 0.135275; Backpropagation: 0.0923 sec; Batch: 0.4236 sec
0.1657 0.1612 0.1494 0.1417 0.1384 0.1354 0.1333 0.1313 0.1297 0.1283 0.1271 0.1261 0.1253 0.1244 0.1237 0.1235 

[TRAIN] Epoch[1](1060/1500); Loss: 0.128006; Backpropagation: 0.0918 sec; Batch: 0.4299 sec
0.1767 0.1898 0.1416 0.1454 0.1305 0.1237 0.1191 0.1170 0.1161 0.1151 0.1142 0.1132 0.1124 0.1117 0.1111 0.1107 

[TRAIN] Epoch[1](1061/1500); Loss: 0.082317; Backpropagation: 0.0920 sec; Batch: 0.4229 sec
0.1256 0.1020 0.0894 0.0835 0.0801 0.0782 0.0771 0.0764 0.0757 0.0755 0.0754 0.0753 0.0753 0.0756 0.0759 0.0760 

[TRAIN] Epoch[1](1062/1500); Loss: 0.080150; Backpropagation: 0.0917 sec; Batch: 0.4553 sec
0.1794 0.1363 0.0999 0.0808 0.0741 0.0713 0.0688 0.0664 0.0650 0.0639 0.0636 0.0628 0.0629 0.0626 0.0623 0.0622 

[TRAIN] Epoch[1](1063/1500); Loss: 0.142631; Backpropagation: 0.0992 sec; Batch: 0.4323 sec
0.1762 0.1687 0.1503 0.1436 0.1406 0.1387 0.1383 0.1373 0.1369 0.1366 0.1361 0.1358 0.1357 0.1356 0.1356 0.1361 

[TRAIN] Epoch[1](1064/1500); Loss: 0.087939; Backpropagation: 0.0983 sec; Batch: 0.4319 sec
0.0982 0.1136 0.1087 0.1010 0.0972 0.0925 0.0884 0.0849 0.0821 0.0797 0.0784 0.0775 0.0766 0.0772 0.0758 0.0751 

[TRAIN] Epoch[1](1065/1500); Loss: 0.168827; Backpropagation: 0.0984 sec; Batch: 0.4317 sec
0.2301 0.2028 0.1774 0.1672 0.1644 0.1624 0.1619 0.1616 0.1618 0.1607 0.1600 0.1592 0.1585 0.1579 0.1577 0.1577 

[TRAIN] Epoch[1](1066/1500); Loss: 0.105900; Backpropagation: 0.0983 sec; Batch: 0.4315 sec
0.1409 0.1310 0.1145 0.1062 0.1039 0.1016 0.1002 0.0995 0.0992 0.0992 0.0993 0.0995 0.0995 0.0995 0.0999 0.1004 

[TRAIN] Epoch[1](1067/1500); Loss: 0.083291; Backpropagation: 0.0984 sec; Batch: 0.4315 sec
0.1336 0.1255 0.0983 0.0862 0.0806 0.0777 0.0752 0.0742 0.0734 0.0730 0.0726 0.0727 0.0726 0.0722 0.0724 0.0723 

[TRAIN] Epoch[1](1068/1500); Loss: 0.122810; Backpropagation: 0.0983 sec; Batch: 0.4318 sec
0.1514 0.1450 0.1321 0.1246 0.1229 0.1210 0.1202 0.1193 0.1183 0.1173 0.1165 0.1160 0.1154 0.1152 0.1149 0.1150 

[TRAIN] Epoch[1](1069/1500); Loss: 0.077536; Backpropagation: 0.0932 sec; Batch: 0.4255 sec
0.1036 0.1014 0.0853 0.0889 0.0820 0.0774 0.0739 0.0717 0.0709 0.0709 0.0702 0.0695 0.0690 0.0684 0.0686 0.0690 

[TRAIN] Epoch[1](1070/1500); Loss: 0.134408; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1914 0.1831 0.1507 0.1460 0.1348 0.1293 0.1255 0.1237 0.1231 0.1223 0.1216 0.1208 0.1201 0.1196 0.1193 0.1194 

[TRAIN] Epoch[1](1071/1500); Loss: 0.067208; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1108 0.1267 0.0714 0.0753 0.0660 0.0620 0.0605 0.0598 0.0582 0.0569 0.0557 0.0550 0.0544 0.0541 0.0542 0.0544 

[TRAIN] Epoch[1](1072/1500); Loss: 0.135290; Backpropagation: 0.0917 sec; Batch: 0.4275 sec
0.1802 0.1708 0.1496 0.1357 0.1309 0.1295 0.1288 0.1279 0.1274 0.1264 0.1258 0.1259 0.1259 0.1263 0.1265 0.1269 

[TRAIN] Epoch[1](1073/1500); Loss: 0.103577; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1279 0.1209 0.1224 0.1075 0.1049 0.1015 0.0998 0.0985 0.0976 0.0970 0.0967 0.0964 0.0963 0.0965 0.0965 0.0965 

[TRAIN] Epoch[1](1074/1500); Loss: 0.131593; Backpropagation: 0.0915 sec; Batch: 0.4462 sec
0.1808 0.1759 0.1395 0.1269 0.1232 0.1238 0.1249 0.1241 0.1235 0.1232 0.1229 0.1225 0.1226 0.1227 0.1242 0.1248 

[TRAIN] Epoch[1](1075/1500); Loss: 0.095986; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1798 0.1412 0.1015 0.0871 0.0862 0.0832 0.0825 0.0830 0.0842 0.0856 0.0855 0.0856 0.0861 0.0870 0.0882 0.0890 

[TRAIN] Epoch[1](1076/1500); Loss: 0.081758; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1283 0.1040 0.0871 0.0868 0.0786 0.0765 0.0760 0.0749 0.0746 0.0741 0.0740 0.0744 0.0746 0.0746 0.0747 0.0749 

[TRAIN] Epoch[1](1077/1500); Loss: 0.105540; Backpropagation: 0.0917 sec; Batch: 0.4617 sec
0.1475 0.1409 0.1145 0.1109 0.1044 0.0987 0.0974 0.0972 0.0971 0.0969 0.0971 0.0969 0.0972 0.0967 0.0976 0.0976 

[TRAIN] Epoch[1](1078/1500); Loss: 0.118505; Backpropagation: 0.0916 sec; Batch: 0.4270 sec
0.1685 0.1661 0.1363 0.1279 0.1190 0.1152 0.1124 0.1096 0.1072 0.1064 0.1060 0.1054 0.1046 0.1040 0.1039 0.1037 

[TRAIN] Epoch[1](1079/1500); Loss: 0.138182; Backpropagation: 0.0917 sec; Batch: 0.4277 sec
0.2156 0.1926 0.1570 0.1420 0.1333 0.1299 0.1274 0.1253 0.1251 0.1247 0.1237 0.1231 0.1228 0.1228 0.1226 0.1232 

[TRAIN] Epoch[1](1080/1500); Loss: 0.094754; Backpropagation: 0.0915 sec; Batch: 0.4229 sec
0.1940 0.1714 0.1231 0.1080 0.0897 0.0833 0.0754 0.0737 0.0750 0.0736 0.0732 0.0730 0.0743 0.0751 0.0761 0.0771 

[TRAIN] Epoch[1](1081/1500); Loss: 0.136165; Backpropagation: 0.0917 sec; Batch: 0.4350 sec
0.2110 0.1845 0.1515 0.1476 0.1374 0.1281 0.1248 0.1231 0.1221 0.1221 0.1220 0.1215 0.1211 0.1207 0.1206 0.1205 

[TRAIN] Epoch[1](1082/1500); Loss: 0.064756; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.0987 0.1571 0.1045 0.0500 0.0510 0.0447 0.0447 0.0476 0.0479 0.0533 0.0526 0.0540 0.0545 0.0573 0.0580 0.0601 

[TRAIN] Epoch[1](1083/1500); Loss: 0.137205; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1719 0.1719 0.1460 0.1364 0.1347 0.1323 0.1316 0.1308 0.1302 0.1301 0.1300 0.1299 0.1296 0.1300 0.1300 0.1300 

[TRAIN] Epoch[1](1084/1500); Loss: 0.112664; Backpropagation: 0.0917 sec; Batch: 0.4224 sec
0.1607 0.1387 0.1149 0.1132 0.1096 0.1088 0.1075 0.1064 0.1053 0.1053 0.1051 0.1055 0.1056 0.1052 0.1052 0.1056 

[TRAIN] Epoch[1](1085/1500); Loss: 0.094567; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1609 0.1312 0.0901 0.0979 0.0876 0.0846 0.0884 0.0857 0.0847 0.0844 0.0846 0.0850 0.0857 0.0863 0.0875 0.0884 

[TRAIN] Epoch[1](1086/1500); Loss: 0.131493; Backpropagation: 0.0916 sec; Batch: 0.4241 sec
0.2001 0.1809 0.1349 0.1333 0.1258 0.1208 0.1183 0.1183 0.1180 0.1184 0.1195 0.1207 0.1223 0.1230 0.1242 0.1254 

[TRAIN] Epoch[1](1087/1500); Loss: 0.090337; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1626 0.1848 0.1076 0.1141 0.0850 0.0744 0.0721 0.0705 0.0696 0.0697 0.0696 0.0707 0.0718 0.0727 0.0742 0.0760 

[TRAIN] Epoch[1](1088/1500); Loss: 0.118377; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1419 0.1615 0.1214 0.1210 0.1159 0.1129 0.1104 0.1085 0.1090 0.1092 0.1098 0.1108 0.1125 0.1143 0.1165 0.1185 

[TRAIN] Epoch[1](1089/1500); Loss: 0.104283; Backpropagation: 0.0918 sec; Batch: 0.4373 sec
0.1265 0.1242 0.1022 0.1068 0.0991 0.0971 0.0964 0.0968 0.0975 0.0982 0.0991 0.1008 0.1025 0.1043 0.1070 0.1100 

[TRAIN] Epoch[1](1090/1500); Loss: 0.069036; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1385 0.1520 0.0860 0.0920 0.0623 0.0578 0.0518 0.0495 0.0488 0.0483 0.0490 0.0498 0.0510 0.0532 0.0556 0.0589 

[TRAIN] Epoch[1](1091/1500); Loss: 0.116562; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1284 0.1318 0.1181 0.1180 0.1128 0.1100 0.1110 0.1098 0.1105 0.1112 0.1121 0.1133 0.1156 0.1179 0.1207 0.1236 

[TRAIN] Epoch[1](1092/1500); Loss: 0.108986; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1131 0.0917 0.0977 0.1108 0.1009 0.1005 0.1020 0.1034 0.1034 0.1062 0.1104 0.1132 0.1166 0.1205 0.1242 0.1293 

[TRAIN] Epoch[1](1093/1500); Loss: 0.077329; Backpropagation: 0.0918 sec; Batch: 0.4281 sec
0.1093 0.1311 0.0766 0.0768 0.0731 0.0672 0.0684 0.0650 0.0651 0.0662 0.0675 0.0684 0.0705 0.0738 0.0773 0.0812 

[TRAIN] Epoch[1](1094/1500); Loss: 0.116426; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1595 0.1717 0.1285 0.1147 0.1030 0.1010 0.0989 0.0991 0.0992 0.1021 0.1046 0.1070 0.1114 0.1169 0.1199 0.1253 

[TRAIN] Epoch[1](1095/1500); Loss: 0.119530; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1308 0.1391 0.1327 0.1186 0.1181 0.1177 0.1158 0.1141 0.1146 0.1133 0.1129 0.1136 0.1154 0.1164 0.1187 0.1207 

[TRAIN] Epoch[1](1096/1500); Loss: 0.109607; Backpropagation: 0.0916 sec; Batch: 0.4262 sec
0.1424 0.1136 0.1060 0.1314 0.1129 0.1116 0.1093 0.1064 0.1040 0.1026 0.1013 0.1007 0.1004 0.1037 0.1034 0.1041 

[TRAIN] Epoch[1](1097/1500); Loss: 0.124236; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.1725 0.1722 0.1196 0.1194 0.1172 0.1153 0.1138 0.1126 0.1120 0.1121 0.1137 0.1152 0.1193 0.1220 0.1245 0.1266 

[TRAIN] Epoch[1](1098/1500); Loss: 0.157910; Backpropagation: 0.0916 sec; Batch: 0.4316 sec
0.1822 0.1807 0.1644 0.1629 0.1580 0.1554 0.1532 0.1522 0.1519 0.1511 0.1502 0.1506 0.1517 0.1526 0.1540 0.1557 

[TRAIN] Epoch[1](1099/1500); Loss: 0.157188; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2013 0.1793 0.1681 0.1682 0.1569 0.1558 0.1533 0.1505 0.1476 0.1468 0.1467 0.1460 0.1461 0.1478 0.1491 0.1515 

[TRAIN] Epoch[1](1100/1500); Loss: 0.155685; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1784 0.1985 0.1635 0.1542 0.1509 0.1506 0.1485 0.1474 0.1466 0.1458 0.1471 0.1483 0.1493 0.1509 0.1539 0.1570 

[TRAIN] Epoch[1](1101/1500); Loss: 0.090875; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1429 0.2020 0.1224 0.0596 0.0713 0.0722 0.0712 0.0686 0.0684 0.0709 0.0740 0.0759 0.0815 0.0857 0.0907 0.0966 

[TRAIN] Epoch[1](1102/1500); Loss: 0.082618; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0847 0.0836 0.0757 0.0856 0.0804 0.0803 0.0782 0.0783 0.0802 0.0810 0.0810 0.0827 0.0839 0.0865 0.0886 0.0911 

[TRAIN] Epoch[1](1103/1500); Loss: 0.115158; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1640 0.1439 0.1182 0.1173 0.1108 0.1095 0.1039 0.1006 0.1011 0.0987 0.1035 0.1033 0.1093 0.1095 0.1236 0.1252 

[TRAIN] Epoch[1](1104/1500); Loss: 0.101666; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1447 0.1496 0.1139 0.1059 0.0991 0.0948 0.0911 0.0910 0.0887 0.0889 0.0887 0.0916 0.0926 0.0934 0.0950 0.0976 

[TRAIN] Epoch[1](1105/1500); Loss: 0.076579; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1102 0.0996 0.0822 0.0749 0.0698 0.0692 0.0683 0.0677 0.0684 0.0681 0.0695 0.0708 0.0733 0.0752 0.0777 0.0804 

[TRAIN] Epoch[1](1106/1500); Loss: 0.129040; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1439 0.1439 0.1600 0.1481 0.1329 0.1241 0.1184 0.1145 0.1152 0.1168 0.1210 0.1208 0.1228 0.1255 0.1282 0.1287 

[TRAIN] Epoch[1](1107/1500); Loss: 0.069633; Backpropagation: 0.0916 sec; Batch: 0.4584 sec
0.0935 0.0579 0.0563 0.0694 0.0618 0.0697 0.0635 0.0658 0.0627 0.0695 0.0670 0.0707 0.0714 0.0755 0.0780 0.0812 

[TRAIN] Epoch[1](1108/1500); Loss: 0.103430; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1514 0.1284 0.1091 0.0976 0.0982 0.0969 0.0939 0.0935 0.0934 0.0957 0.0949 0.0974 0.0978 0.0999 0.1023 0.1042 

[TRAIN] Epoch[1](1109/1500); Loss: 0.106228; Backpropagation: 0.0919 sec; Batch: 0.4278 sec
0.1283 0.1276 0.1216 0.1131 0.1026 0.0991 0.0978 0.0974 0.0955 0.0976 0.0982 0.0992 0.1011 0.1030 0.1077 0.1098 

[TRAIN] Epoch[1](1110/1500); Loss: 0.091046; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1061 0.1171 0.1031 0.0956 0.0859 0.0847 0.0799 0.0814 0.0805 0.0833 0.0839 0.0872 0.0881 0.0907 0.0925 0.0969 

[TRAIN] Epoch[1](1111/1500); Loss: 0.148841; Backpropagation: 0.0917 sec; Batch: 0.4544 sec
0.2098 0.2137 0.1633 0.1589 0.1438 0.1393 0.1347 0.1350 0.1309 0.1308 0.1299 0.1330 0.1335 0.1372 0.1411 0.1465 

[TRAIN] Epoch[1](1112/1500); Loss: 0.136999; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1891 0.1993 0.1494 0.1463 0.1291 0.1226 0.1188 0.1220 0.1201 0.1248 0.1231 0.1267 0.1267 0.1283 0.1295 0.1361 

[TRAIN] Epoch[1](1113/1500); Loss: 0.118222; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1628 0.1403 0.1381 0.1188 0.1139 0.1186 0.1116 0.1067 0.1052 0.1079 0.1064 0.1090 0.1078 0.1135 0.1128 0.1180 

[TRAIN] Epoch[1](1114/1500); Loss: 0.153300; Backpropagation: 0.0919 sec; Batch: 0.4275 sec
0.1765 0.1676 0.1687 0.1776 0.1703 0.1581 0.1491 0.1477 0.1439 0.1408 0.1418 0.1407 0.1400 0.1410 0.1446 0.1443 

[TRAIN] Epoch[1](1115/1500); Loss: 0.168352; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2248 0.2588 0.2348 0.2074 0.1810 0.1564 0.1373 0.1306 0.1344 0.1424 0.1452 0.1452 0.1494 0.1522 0.1487 0.1448 

[TRAIN] Epoch[1](1116/1500); Loss: 0.281092; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2003 0.2055 0.1957 0.2037 0.2226 0.2428 0.2617 0.2797 0.2966 0.3116 0.3266 0.3343 0.3378 0.3495 0.3593 0.3698 

[TRAIN] Epoch[1](1117/1500); Loss: 0.294225; Backpropagation: 0.0915 sec; Batch: 0.4625 sec
0.2808 0.2886 0.2907 0.2887 0.2893 0.2898 0.2893 0.2884 0.2874 0.2893 0.2910 0.2949 0.2985 0.3048 0.3127 0.3236 

[TRAIN] Epoch[1](1118/1500); Loss: 0.290071; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2915 0.3093 0.2971 0.2809 0.2759 0.2740 0.2750 0.2731 0.2731 0.2757 0.2807 0.2861 0.2943 0.3059 0.3171 0.3312 

[TRAIN] Epoch[1](1119/1500); Loss: 0.222261; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.3153 0.3668 0.3295 0.2734 0.2448 0.2231 0.2088 0.1919 0.1793 0.1715 0.1657 0.1682 0.1671 0.1765 0.1806 0.1937 

[TRAIN] Epoch[1](1120/1500); Loss: 0.191706; Backpropagation: 0.0915 sec; Batch: 0.4235 sec
0.1434 0.1382 0.1414 0.1542 0.1625 0.1696 0.1732 0.1822 0.1889 0.1980 0.2070 0.2184 0.2284 0.2409 0.2537 0.2675 

[TRAIN] Epoch[1](1121/1500); Loss: 0.251710; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.3060 0.3248 0.3067 0.2829 0.2698 0.2595 0.2509 0.2425 0.2349 0.2283 0.2236 0.2214 0.2185 0.2184 0.2183 0.2208 

[TRAIN] Epoch[1](1122/1500); Loss: 0.208014; Backpropagation: 0.0917 sec; Batch: 0.4270 sec
0.1927 0.1969 0.1930 0.1915 0.1929 0.1954 0.1973 0.2009 0.2036 0.2080 0.2119 0.2172 0.2222 0.2290 0.2345 0.2412 

[TRAIN] Epoch[1](1123/1500); Loss: 0.180125; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1426 0.1368 0.1420 0.1552 0.1639 0.1712 0.1736 0.1802 0.1848 0.1898 0.1932 0.1988 0.2042 0.2102 0.2148 0.2207 

[TRAIN] Epoch[1](1124/1500); Loss: 0.474024; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.4184 0.3956 0.4259 0.4637 0.4777 0.4862 0.4821 0.4872 0.4896 0.4888 0.4893 0.4937 0.4937 0.4947 0.4976 0.5000 

[TRAIN] Epoch[1](1125/1500); Loss: 0.171384; Backpropagation: 0.0916 sec; Batch: 0.4591 sec
0.1688 0.1761 0.1728 0.1662 0.1654 0.1648 0.1657 0.1663 0.1670 0.1685 0.1705 0.1726 0.1750 0.1777 0.1806 0.1841 

[TRAIN] Epoch[1](1126/1500); Loss: 0.158846; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1594 0.1706 0.1581 0.1466 0.1463 0.1480 0.1505 0.1507 0.1527 0.1566 0.1588 0.1610 0.1654 0.1689 0.1717 0.1761 

[TRAIN] Epoch[1](1127/1500); Loss: 0.129391; Backpropagation: 0.0917 sec; Batch: 0.4269 sec
0.1342 0.1488 0.1390 0.1218 0.1197 0.1194 0.1206 0.1207 0.1217 0.1239 0.1260 0.1284 0.1313 0.1345 0.1381 0.1421 

[TRAIN] Epoch[1](1128/1500); Loss: 0.143316; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.1469 0.1719 0.1528 0.1230 0.1222 0.1239 0.1305 0.1308 0.1326 0.1393 0.1432 0.1451 0.1509 0.1566 0.1592 0.1641 

[TRAIN] Epoch[1](1129/1500); Loss: 0.151050; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1693 0.1877 0.1654 0.1392 0.1374 0.1394 0.1424 0.1405 0.1413 0.1451 0.1463 0.1470 0.1504 0.1532 0.1546 0.1577 

[TRAIN] Epoch[1](1130/1500); Loss: 0.145188; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1784 0.2006 0.1784 0.1467 0.1412 0.1384 0.1389 0.1349 0.1330 0.1331 0.1328 0.1317 0.1325 0.1333 0.1339 0.1352 

[TRAIN] Epoch[1](1131/1500); Loss: 0.259507; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2686 0.2729 0.2684 0.2640 0.2614 0.2599 0.2573 0.2566 0.2560 0.2546 0.2542 0.2548 0.2550 0.2552 0.2560 0.2570 

[TRAIN] Epoch[1](1132/1500); Loss: 0.130160; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1274 0.1287 0.1263 0.1257 0.1258 0.1262 0.1266 0.1275 0.1284 0.1295 0.1309 0.1323 0.1339 0.1357 0.1377 0.1400 

[TRAIN] Epoch[1](1133/1500); Loss: 0.100400; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1393 0.1543 0.1333 0.1084 0.0982 0.0913 0.0859 0.0825 0.0803 0.0813 0.0820 0.0855 0.0885 0.0937 0.0981 0.1039 

[TRAIN] Epoch[1](1134/1500); Loss: 0.155953; Backpropagation: 0.0915 sec; Batch: 0.4230 sec
0.2050 0.2201 0.2021 0.1778 0.1674 0.1596 0.1540 0.1478 0.1428 0.1380 0.1343 0.1312 0.1293 0.1285 0.1281 0.1291 

[TRAIN] Epoch[1](1135/1500); Loss: 0.140887; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2144 0.2269 0.2038 0.1750 0.1614 0.1511 0.1430 0.1327 0.1250 0.1166 0.1103 0.1042 0.1002 0.0973 0.0961 0.0960 

[TRAIN] Epoch[1](1136/1500); Loss: 0.162919; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1500 0.1504 0.1483 0.1492 0.1502 0.1515 0.1527 0.1556 0.1585 0.1622 0.1658 0.1709 0.1760 0.1820 0.1882 0.1952 

[TRAIN] Epoch[1](1137/1500); Loss: 0.128424; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1750 0.1875 0.1683 0.1432 0.1278 0.1159 0.1068 0.1019 0.0994 0.1010 0.1039 0.1097 0.1161 0.1242 0.1322 0.1418 

[TRAIN] Epoch[1](1138/1500); Loss: 0.270931; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.3448 0.3563 0.3398 0.3166 0.3007 0.2876 0.2750 0.2633 0.2525 0.2430 0.2341 0.2281 0.2231 0.2220 0.2217 0.2263 

[TRAIN] Epoch[1](1139/1500); Loss: 0.201369; Backpropagation: 0.0916 sec; Batch: 0.4621 sec
0.3642 0.3863 0.3491 0.2999 0.2646 0.2333 0.2042 0.1753 0.1488 0.1277 0.1139 0.1077 0.1046 0.1090 0.1112 0.1221 

[TRAIN] Epoch[1](1140/1500); Loss: 0.352244; Backpropagation: 0.0915 sec; Batch: 0.4227 sec
0.3045 0.3003 0.3183 0.3353 0.3429 0.3499 0.3488 0.3547 0.3565 0.3622 0.3655 0.3706 0.3738 0.3792 0.3838 0.3895 

[TRAIN] Epoch[1](1141/1500); Loss: 0.123931; Backpropagation: 0.0917 sec; Batch: 0.4282 sec
0.2100 0.2239 0.1963 0.1615 0.1363 0.1170 0.1018 0.0914 0.0852 0.0831 0.0837 0.0873 0.0915 0.0982 0.1040 0.1118 

[TRAIN] Epoch[1](1142/1500); Loss: 0.166775; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1529 0.1514 0.1514 0.1566 0.1589 0.1608 0.1599 0.1635 0.1652 0.1675 0.1708 0.1744 0.1779 0.1818 0.1857 0.1898 

[TRAIN] Epoch[1](1143/1500); Loss: 0.295805; Backpropagation: 0.0917 sec; Batch: 0.4377 sec
0.2721 0.2671 0.2770 0.2900 0.2945 0.2965 0.2944 0.2978 0.2991 0.2998 0.3021 0.3044 0.3058 0.3083 0.3110 0.3130 

[TRAIN] Epoch[1](1144/1500); Loss: 0.157572; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1883 0.1844 0.1684 0.1611 0.1561 0.1540 0.1491 0.1469 0.1455 0.1445 0.1453 0.1469 0.1501 0.1546 0.1599 0.1660 

[TRAIN] Epoch[1](1145/1500); Loss: 0.262480; Backpropagation: 0.0919 sec; Batch: 0.4253 sec
0.2588 0.2522 0.2588 0.2695 0.2692 0.2685 0.2645 0.2668 0.2648 0.2622 0.2633 0.2621 0.2598 0.2607 0.2602 0.2583 

[TRAIN] Epoch[1](1146/1500); Loss: 0.222896; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2836 0.2935 0.2707 0.2453 0.2337 0.2255 0.2213 0.2147 0.2117 0.2066 0.2021 0.1975 0.1945 0.1910 0.1887 0.1860 

[TRAIN] Epoch[1](1147/1500); Loss: 0.214710; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2302 0.2253 0.2270 0.2330 0.2294 0.2253 0.2192 0.2183 0.2144 0.2104 0.2081 0.2049 0.2012 0.1991 0.1961 0.1935 

[TRAIN] Epoch[1](1148/1500); Loss: 0.312275; Backpropagation: 0.0916 sec; Batch: 0.4263 sec
0.3358 0.3290 0.3331 0.3413 0.3346 0.3294 0.3179 0.3174 0.3116 0.3035 0.3011 0.2968 0.2902 0.2888 0.2850 0.2807 

[TRAIN] Epoch[1](1149/1500); Loss: 0.161189; Backpropagation: 0.0917 sec; Batch: 0.4518 sec
0.1930 0.1928 0.1866 0.1814 0.1743 0.1685 0.1626 0.1594 0.1550 0.1514 0.1481 0.1453 0.1424 0.1408 0.1391 0.1384 

[TRAIN] Epoch[1](1150/1500); Loss: 0.208955; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2105 0.2095 0.2102 0.2141 0.2133 0.2121 0.2086 0.2090 0.2080 0.2066 0.2067 0.2069 0.2066 0.2070 0.2068 0.2073 

[TRAIN] Epoch[1](1151/1500); Loss: 0.229884; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2822 0.2834 0.2699 0.2569 0.2473 0.2397 0.2335 0.2278 0.2219 0.2156 0.2107 0.2053 0.2011 0.1970 0.1942 0.1916 

[TRAIN] Epoch[1](1152/1500); Loss: 0.199096; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2393 0.2421 0.2323 0.2235 0.2160 0.2098 0.2025 0.1973 0.1918 0.1863 0.1811 0.1773 0.1736 0.1718 0.1705 0.1703 

[TRAIN] Epoch[1](1153/1500); Loss: 0.150004; Backpropagation: 0.0917 sec; Batch: 0.4279 sec
0.1579 0.1564 0.1534 0.1539 0.1518 0.1488 0.1467 0.1458 0.1451 0.1451 0.1458 0.1467 0.1481 0.1496 0.1514 0.1536 

[TRAIN] Epoch[1](1154/1500); Loss: 0.080739; Backpropagation: 0.0916 sec; Batch: 0.4308 sec
0.0891 0.0857 0.0853 0.0857 0.0824 0.0780 0.0759 0.0747 0.0743 0.0747 0.0758 0.0773 0.0794 0.0817 0.0844 0.0874 

[TRAIN] Epoch[1](1155/1500); Loss: 0.134937; Backpropagation: 0.0918 sec; Batch: 0.4311 sec
0.1411 0.1369 0.1370 0.1438 0.1411 0.1380 0.1329 0.1321 0.1307 0.1297 0.1301 0.1307 0.1316 0.1331 0.1342 0.1359 

[TRAIN] Epoch[1](1156/1500); Loss: 0.113004; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2093 0.2168 0.1866 0.1541 0.1292 0.1092 0.0937 0.0831 0.0770 0.0751 0.0760 0.0788 0.0796 0.0805 0.0799 0.0792 

[TRAIN] Epoch[1](1157/1500); Loss: 0.511952; Backpropagation: 0.0918 sec; Batch: 0.4301 sec
0.5952 0.5717 0.5839 0.6001 0.5829 0.5638 0.5438 0.5277 0.5141 0.4934 0.4777 0.4619 0.4438 0.4264 0.4106 0.3943 

[TRAIN] Epoch[1](1158/1500); Loss: 0.185347; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2066 0.2059 0.1994 0.1945 0.1894 0.1856 0.1825 0.1814 0.1802 0.1792 0.1778 0.1768 0.1764 0.1764 0.1765 0.1771 

[TRAIN] Epoch[1](1159/1500); Loss: 0.140077; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1662 0.1636 0.1594 0.1545 0.1494 0.1437 0.1396 0.1362 0.1330 0.1304 0.1287 0.1275 0.1269 0.1269 0.1272 0.1279 

[TRAIN] Epoch[1](1160/1500); Loss: 0.077933; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1217 0.1221 0.1056 0.0915 0.0807 0.0743 0.0702 0.0675 0.0648 0.0633 0.0624 0.0627 0.0631 0.0642 0.0656 0.0671 

[TRAIN] Epoch[1](1161/1500); Loss: 0.194620; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2298 0.2260 0.2192 0.2110 0.2039 0.1983 0.1933 0.1884 0.1844 0.1817 0.1799 0.1785 0.1781 0.1790 0.1804 0.1821 

[TRAIN] Epoch[1](1162/1500); Loss: 0.094229; Backpropagation: 0.0915 sec; Batch: 0.4386 sec
0.1250 0.1249 0.1081 0.0955 0.0895 0.0875 0.0854 0.0836 0.0836 0.0842 0.0850 0.0864 0.0883 0.0905 0.0935 0.0968 

[TRAIN] Epoch[1](1163/1500); Loss: 0.203744; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.2533 0.2518 0.2373 0.2243 0.2148 0.2070 0.2009 0.1961 0.1925 0.1890 0.1862 0.1838 0.1822 0.1808 0.1800 0.1800 

[TRAIN] Epoch[1](1164/1500); Loss: 0.147494; Backpropagation: 0.0915 sec; Batch: 0.4569 sec
0.1875 0.1781 0.1694 0.1561 0.1458 0.1354 0.1266 0.1218 0.1219 0.1255 0.1312 0.1386 0.1464 0.1530 0.1587 0.1640 

[TRAIN] Epoch[1](1165/1500); Loss: 0.137437; Backpropagation: 0.0917 sec; Batch: 0.4273 sec
0.2919 0.2848 0.2341 0.1916 0.1596 0.1318 0.1115 0.0962 0.0876 0.0846 0.0844 0.0854 0.0846 0.0868 0.0902 0.0939 

[TRAIN] Epoch[1](1166/1500); Loss: 0.171364; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1982 0.1965 0.1885 0.1821 0.1772 0.1727 0.1689 0.1656 0.1626 0.1609 0.1598 0.1599 0.1602 0.1616 0.1627 0.1644 

[TRAIN] Epoch[1](1167/1500); Loss: 0.072933; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0848 0.0844 0.0791 0.0759 0.0738 0.0722 0.0708 0.0698 0.0690 0.0686 0.0685 0.0687 0.0691 0.0698 0.0706 0.0717 

[TRAIN] Epoch[1](1168/1500); Loss: 0.159636; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2405 0.2361 0.2143 0.1925 0.1763 0.1616 0.1500 0.1418 0.1372 0.1357 0.1335 0.1293 0.1255 0.1253 0.1261 0.1285 

[TRAIN] Epoch[1](1169/1500); Loss: 0.151593; Backpropagation: 0.0919 sec; Batch: 0.4251 sec
0.1756 0.1749 0.1640 0.1568 0.1528 0.1512 0.1518 0.1525 0.1506 0.1472 0.1446 0.1425 0.1409 0.1401 0.1397 0.1401 

[TRAIN] Epoch[1](1170/1500); Loss: 0.199395; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2842 0.2820 0.2667 0.2487 0.2338 0.2195 0.2054 0.1931 0.1821 0.1727 0.1648 0.1581 0.1520 0.1464 0.1420 0.1388 

[TRAIN] Epoch[1](1171/1500); Loss: 0.114141; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1657 0.1638 0.1484 0.1374 0.1282 0.1180 0.1067 0.1000 0.0981 0.0972 0.0947 0.0931 0.0917 0.0922 0.0943 0.0969 

[TRAIN] Epoch[1](1172/1500); Loss: 0.197458; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2390 0.2370 0.2315 0.2222 0.2142 0.2056 0.1983 0.1925 0.1873 0.1828 0.1790 0.1762 0.1741 0.1730 0.1727 0.1738 

[TRAIN] Epoch[1](1173/1500); Loss: 0.158903; Backpropagation: 0.0919 sec; Batch: 0.4267 sec
0.3619 0.3554 0.3084 0.2629 0.2200 0.1792 0.1391 0.1009 0.0737 0.0633 0.0741 0.0869 0.0908 0.0830 0.0739 0.0689 

[TRAIN] Epoch[1](1174/1500); Loss: 0.100015; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1308 0.1270 0.1191 0.1112 0.1049 0.0976 0.0917 0.0877 0.0856 0.0861 0.0875 0.0892 0.0912 0.0941 0.0969 0.0996 

[TRAIN] Epoch[1](1175/1500); Loss: 0.170926; Backpropagation: 0.0918 sec; Batch: 0.4256 sec
0.2356 0.2305 0.2125 0.1928 0.1778 0.1657 0.1577 0.1526 0.1496 0.1477 0.1475 0.1482 0.1505 0.1534 0.1555 0.1573 

[TRAIN] Epoch[1](1176/1500); Loss: 0.165722; Backpropagation: 0.1004 sec; Batch: 0.4335 sec
0.2544 0.2483 0.2284 0.2077 0.1906 0.1738 0.1580 0.1449 0.1351 0.1305 0.1301 0.1307 0.1304 0.1297 0.1294 0.1297 

[TRAIN] Epoch[1](1177/1500); Loss: 0.106649; Backpropagation: 0.0983 sec; Batch: 0.4482 sec
0.1405 0.1357 0.1271 0.1201 0.1153 0.1089 0.1017 0.0967 0.0934 0.0922 0.0920 0.0926 0.0944 0.0966 0.0984 0.1010 

[TRAIN] Epoch[1](1178/1500); Loss: 0.139402; Backpropagation: 0.0983 sec; Batch: 0.4322 sec
0.1930 0.1873 0.1763 0.1610 0.1490 0.1377 0.1282 0.1216 0.1180 0.1171 0.1180 0.1197 0.1220 0.1250 0.1273 0.1292 

[TRAIN] Epoch[1](1179/1500); Loss: 0.081953; Backpropagation: 0.0985 sec; Batch: 0.4320 sec
0.1292 0.1238 0.1051 0.0936 0.0876 0.0842 0.0800 0.0739 0.0681 0.0654 0.0648 0.0652 0.0657 0.0670 0.0686 0.0691 

[TRAIN] Epoch[1](1180/1500); Loss: 0.116576; Backpropagation: 0.0983 sec; Batch: 0.4323 sec
0.1500 0.1419 0.1323 0.1210 0.1130 0.1073 0.1038 0.1024 0.1023 0.1037 0.1063 0.1106 0.1144 0.1166 0.1187 0.1207 

[TRAIN] Epoch[1](1181/1500); Loss: 0.178936; Backpropagation: 0.0984 sec; Batch: 0.4322 sec
0.2099 0.2097 0.2004 0.1844 0.1747 0.1648 0.1588 0.1561 0.1554 0.1567 0.1605 0.1678 0.1774 0.1871 0.1954 0.2039 

[TRAIN] Epoch[1](1182/1500); Loss: 0.138886; Backpropagation: 0.0982 sec; Batch: 0.4314 sec
0.1689 0.1654 0.1581 0.1504 0.1450 0.1411 0.1388 0.1364 0.1335 0.1307 0.1287 0.1266 0.1254 0.1251 0.1245 0.1238 

[TRAIN] Epoch[1](1183/1500); Loss: 0.116590; Backpropagation: 0.0984 sec; Batch: 0.4313 sec
0.1729 0.1665 0.1461 0.1297 0.1173 0.1084 0.1039 0.1023 0.1023 0.1013 0.1002 0.1004 0.1021 0.1034 0.1040 0.1048 

[TRAIN] Epoch[1](1184/1500); Loss: 0.181912; Backpropagation: 0.0983 sec; Batch: 0.4321 sec
0.2518 0.2464 0.2331 0.2156 0.2012 0.1876 0.1785 0.1724 0.1658 0.1596 0.1542 0.1500 0.1476 0.1467 0.1484 0.1516 

[TRAIN] Epoch[1](1185/1500); Loss: 0.251787; Backpropagation: 0.0936 sec; Batch: 0.4254 sec
0.3227 0.3160 0.3059 0.2917 0.2806 0.2696 0.2606 0.2522 0.2442 0.2363 0.2278 0.2192 0.2107 0.2036 0.1968 0.1909 

[TRAIN] Epoch[1](1186/1500); Loss: 0.069642; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1106 0.1057 0.0800 0.0698 0.0714 0.0752 0.0701 0.0598 0.0567 0.0557 0.0569 0.0576 0.0586 0.0601 0.0614 0.0646 

[TRAIN] Epoch[1](1187/1500); Loss: 0.088808; Backpropagation: 0.0919 sec; Batch: 0.4262 sec
0.1352 0.1303 0.1169 0.1042 0.0940 0.0866 0.0811 0.0762 0.0730 0.0728 0.0728 0.0735 0.0740 0.0755 0.0766 0.0782 

[TRAIN] Epoch[1](1188/1500); Loss: 0.125563; Backpropagation: 0.0916 sec; Batch: 0.4310 sec
0.2796 0.2563 0.1979 0.1558 0.1226 0.0990 0.0909 0.0965 0.0970 0.0881 0.0838 0.0841 0.0862 0.0875 0.0895 0.0944 

[TRAIN] Epoch[1](1189/1500); Loss: 0.116832; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2188 0.2107 0.1860 0.1626 0.1425 0.1242 0.1081 0.0950 0.0848 0.0788 0.0765 0.0765 0.0765 0.0755 0.0759 0.0768 

[TRAIN] Epoch[1](1190/1500); Loss: 0.093552; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1654 0.1619 0.1428 0.1264 0.1123 0.1000 0.0891 0.0794 0.0717 0.0663 0.0634 0.0623 0.0631 0.0640 0.0644 0.0642 

[TRAIN] Epoch[1](1191/1500); Loss: 0.186057; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2931 0.2834 0.2566 0.2351 0.2155 0.1958 0.1785 0.1649 0.1553 0.1506 0.1476 0.1437 0.1406 0.1394 0.1386 0.1384 

[TRAIN] Epoch[1](1192/1500); Loss: 0.159877; Backpropagation: 0.0916 sec; Batch: 0.4457 sec
0.2823 0.2733 0.2516 0.2216 0.1967 0.1666 0.1404 0.1186 0.1044 0.0991 0.1014 0.1091 0.1172 0.1221 0.1258 0.1278 

[TRAIN] Epoch[1](1193/1500); Loss: 0.095260; Backpropagation: 0.0987 sec; Batch: 0.4403 sec
0.1795 0.1638 0.1262 0.1045 0.0890 0.0800 0.0779 0.0755 0.0718 0.0721 0.0737 0.0750 0.0778 0.0824 0.0853 0.0897 

[TRAIN] Epoch[1](1194/1500); Loss: 0.158448; Backpropagation: 0.0929 sec; Batch: 0.4242 sec
0.2113 0.2062 0.1940 0.1811 0.1710 0.1608 0.1528 0.1472 0.1432 0.1411 0.1397 0.1383 0.1375 0.1369 0.1369 0.1371 

[TRAIN] Epoch[1](1195/1500); Loss: 0.093169; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1540 0.1473 0.1320 0.1151 0.1020 0.0873 0.0763 0.0704 0.0695 0.0705 0.0712 0.0729 0.0759 0.0789 0.0816 0.0859 

[TRAIN] Epoch[1](1196/1500); Loss: 0.118431; Backpropagation: 0.0916 sec; Batch: 0.4241 sec
0.1717 0.1629 0.1453 0.1303 0.1197 0.1124 0.1088 0.1067 0.1041 0.1026 0.1034 0.1038 0.1034 0.1048 0.1064 0.1085 

[TRAIN] Epoch[1](1197/1500); Loss: 0.119482; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1433 0.1380 0.1328 0.1273 0.1222 0.1185 0.1160 0.1136 0.1123 0.1114 0.1110 0.1116 0.1127 0.1129 0.1136 0.1144 

[TRAIN] Epoch[1](1198/1500); Loss: 0.121951; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1745 0.1679 0.1572 0.1471 0.1388 0.1312 0.1238 0.1174 0.1110 0.1050 0.1004 0.0975 0.0945 0.0936 0.0947 0.0966 

[TRAIN] Epoch[1](1199/1500); Loss: 0.205436; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2906 0.2837 0.2664 0.2480 0.2318 0.2171 0.2055 0.1954 0.1869 0.1796 0.1735 0.1681 0.1637 0.1606 0.1586 0.1573 

[TRAIN] Epoch[1](1200/1500); Loss: 0.161942; Backpropagation: 0.0916 sec; Batch: 0.4265 sec
0.2354 0.2287 0.2152 0.2009 0.1879 0.1736 0.1620 0.1512 0.1428 0.1358 0.1308 0.1268 0.1257 0.1248 0.1248 0.1247 

[TRAIN] Epoch[1](1201/1500); Loss: 0.061687; Backpropagation: 0.0917 sec; Batch: 0.4589 sec
0.1029 0.0929 0.0755 0.0664 0.0616 0.0609 0.0574 0.0527 0.0540 0.0540 0.0512 0.0518 0.0513 0.0504 0.0512 0.0528 

[TRAIN] Epoch[1](1202/1500); Loss: 0.140610; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2686 0.2569 0.2245 0.1962 0.1707 0.1471 0.1266 0.1122 0.1046 0.1002 0.0961 0.0925 0.0916 0.0894 0.0868 0.0859 

[TRAIN] Epoch[1](1203/1500); Loss: 0.127652; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.3591 0.3281 0.2667 0.2159 0.1675 0.1212 0.0803 0.0565 0.0548 0.0703 0.0666 0.0539 0.0501 0.0521 0.0498 0.0494 

[TRAIN] Epoch[1](1204/1500); Loss: 0.168588; Backpropagation: 0.0917 sec; Batch: 0.4420 sec
0.2251 0.2196 0.2071 0.1954 0.1859 0.1774 0.1704 0.1640 0.1588 0.1532 0.1480 0.1433 0.1408 0.1381 0.1354 0.1348 

[TRAIN] Epoch[1](1205/1500); Loss: 0.164895; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2564 0.2487 0.2278 0.2087 0.1916 0.1754 0.1621 0.1509 0.1411 0.1329 0.1272 0.1226 0.1202 0.1218 0.1252 0.1258 

[TRAIN] Epoch[1](1206/1500); Loss: 0.108704; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1816 0.1712 0.1502 0.1310 0.1155 0.1028 0.0951 0.0916 0.0899 0.0884 0.0864 0.0862 0.0866 0.0872 0.0876 0.0880 

[TRAIN] Epoch[1](1207/1500); Loss: 0.118964; Backpropagation: 0.0992 sec; Batch: 0.4326 sec
0.1796 0.1725 0.1544 0.1383 0.1258 0.1150 0.1086 0.1060 0.1044 0.1022 0.1004 0.0998 0.1000 0.0988 0.0984 0.0992 

[TRAIN] Epoch[1](1208/1500); Loss: 0.081185; Backpropagation: 0.0983 sec; Batch: 0.4328 sec
0.1119 0.0999 0.0850 0.0732 0.0663 0.0633 0.0635 0.0667 0.0677 0.0697 0.0751 0.0802 0.0851 0.0911 0.0971 0.1032 

[TRAIN] Epoch[1](1209/1500); Loss: 0.085779; Backpropagation: 0.0985 sec; Batch: 0.4392 sec
0.1524 0.1445 0.1305 0.1174 0.1034 0.0903 0.0787 0.0686 0.0622 0.0610 0.0607 0.0610 0.0602 0.0600 0.0599 0.0617 

[TRAIN] Epoch[1](1210/1500); Loss: 0.139528; Backpropagation: 0.0983 sec; Batch: 0.4318 sec
0.2237 0.2168 0.1952 0.1737 0.1541 0.1352 0.1210 0.1119 0.1087 0.1099 0.1110 0.1112 0.1120 0.1142 0.1168 0.1170 

[TRAIN] Epoch[1](1211/1500); Loss: 0.157764; Backpropagation: 0.0984 sec; Batch: 0.4323 sec
0.2424 0.2297 0.2050 0.1858 0.1697 0.1550 0.1436 0.1360 0.1325 0.1313 0.1308 0.1304 0.1316 0.1318 0.1338 0.1348 

[TRAIN] Epoch[1](1212/1500); Loss: 0.070625; Backpropagation: 0.0983 sec; Batch: 0.4313 sec
0.1172 0.1093 0.0956 0.0835 0.0729 0.0648 0.0586 0.0564 0.0573 0.0559 0.0562 0.0579 0.0588 0.0597 0.0621 0.0637 

[TRAIN] Epoch[1](1213/1500); Loss: 0.152836; Backpropagation: 0.0985 sec; Batch: 0.4325 sec
0.2388 0.2287 0.2069 0.1879 0.1708 0.1581 0.1491 0.1413 0.1332 0.1266 0.1199 0.1163 0.1157 0.1169 0.1177 0.1175 

[TRAIN] Epoch[1](1214/1500); Loss: 0.101771; Backpropagation: 0.0930 sec; Batch: 0.4251 sec
0.1629 0.1519 0.1261 0.1083 0.0956 0.0896 0.0879 0.0882 0.0866 0.0856 0.0864 0.0881 0.0904 0.0912 0.0937 0.0958 

[TRAIN] Epoch[1](1215/1500); Loss: 0.174133; Backpropagation: 0.0917 sec; Batch: 0.4251 sec
0.3093 0.2950 0.2642 0.2426 0.2233 0.2022 0.1802 0.1597 0.1412 0.1234 0.1105 0.1021 0.1027 0.1075 0.1120 0.1105 

[TRAIN] Epoch[1](1216/1500); Loss: 0.126755; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1736 0.1649 0.1470 0.1351 0.1271 0.1213 0.1170 0.1145 0.1136 0.1136 0.1139 0.1143 0.1157 0.1168 0.1192 0.1203 

[TRAIN] Epoch[1](1217/1500); Loss: 0.118772; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2607 0.2377 0.1945 0.1615 0.1317 0.1062 0.0859 0.0746 0.0796 0.0899 0.0868 0.0780 0.0757 0.0781 0.0799 0.0796 

[TRAIN] Epoch[1](1218/1500); Loss: 0.149005; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3208 0.2964 0.2576 0.2259 0.1968 0.1680 0.1409 0.1155 0.0942 0.0798 0.0794 0.0793 0.0798 0.0823 0.0832 0.0841 

[TRAIN] Epoch[1](1219/1500); Loss: 0.076355; Backpropagation: 0.0916 sec; Batch: 0.4492 sec
0.1307 0.1084 0.0879 0.0821 0.0819 0.0744 0.0661 0.0651 0.0669 0.0626 0.0626 0.0646 0.0637 0.0640 0.0684 0.0721 

[TRAIN] Epoch[1](1220/1500); Loss: 0.087846; Backpropagation: 0.0916 sec; Batch: 0.4383 sec
0.1078 0.1020 0.0924 0.0869 0.0842 0.0834 0.0835 0.0833 0.0829 0.0837 0.0848 0.0848 0.0852 0.0855 0.0869 0.0882 

[TRAIN] Epoch[1](1221/1500); Loss: 0.079391; Backpropagation: 0.0917 sec; Batch: 0.4250 sec
0.1702 0.1614 0.1301 0.0976 0.0685 0.0542 0.0588 0.0589 0.0532 0.0545 0.0543 0.0601 0.0597 0.0605 0.0623 0.0661 

[TRAIN] Epoch[1](1222/1500); Loss: 0.161487; Backpropagation: 0.0919 sec; Batch: 0.4271 sec
0.2235 0.2132 0.1960 0.1819 0.1691 0.1596 0.1524 0.1477 0.1452 0.1445 0.1422 0.1412 0.1410 0.1416 0.1422 0.1425 

[TRAIN] Epoch[1](1223/1500); Loss: 0.137728; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2059 0.1914 0.1728 0.1630 0.1536 0.1455 0.1390 0.1320 0.1255 0.1189 0.1139 0.1104 0.1086 0.1083 0.1077 0.1074 

[TRAIN] Epoch[1](1224/1500); Loss: 0.158611; Backpropagation: 0.0916 sec; Batch: 0.4302 sec
0.2161 0.2015 0.1835 0.1721 0.1655 0.1600 0.1554 0.1536 0.1489 0.1441 0.1413 0.1417 0.1386 0.1375 0.1378 0.1402 

[TRAIN] Epoch[1](1225/1500); Loss: 0.175998; Backpropagation: 0.0916 sec; Batch: 0.4588 sec
0.2004 0.1946 0.1874 0.1823 0.1774 0.1760 0.1741 0.1726 0.1706 0.1698 0.1686 0.1678 0.1682 0.1692 0.1686 0.1685 

[TRAIN] Epoch[1](1226/1500); Loss: 0.104059; Backpropagation: 0.0936 sec; Batch: 0.4294 sec
0.1451 0.1375 0.1219 0.1090 0.0978 0.0906 0.0885 0.0912 0.0952 0.0955 0.0934 0.0941 0.0985 0.1007 0.1012 0.1048 

[TRAIN] Epoch[1](1227/1500); Loss: 0.055502; Backpropagation: 0.0923 sec; Batch: 0.4256 sec
0.1023 0.0823 0.0653 0.0583 0.0553 0.0527 0.0468 0.0475 0.0482 0.0468 0.0458 0.0467 0.0459 0.0466 0.0492 0.0485 

[TRAIN] Epoch[1](1228/1500); Loss: 0.132634; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.2548 0.2253 0.1895 0.1629 0.1409 0.1235 0.1124 0.1049 0.1017 0.1007 0.1001 0.1017 0.0993 0.1012 0.1001 0.1032 

[TRAIN] Epoch[1](1229/1500); Loss: 0.115538; Backpropagation: 0.0921 sec; Batch: 0.4252 sec
0.2399 0.2078 0.1673 0.1373 0.1140 0.0995 0.0936 0.0860 0.0822 0.0817 0.0847 0.0861 0.0879 0.0902 0.0941 0.0966 

[TRAIN] Epoch[1](1230/1500); Loss: 0.114285; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1491 0.1411 0.1319 0.1248 0.1177 0.1133 0.1104 0.1083 0.1054 0.1039 0.1028 0.1023 0.1020 0.1037 0.1046 0.1071 

[TRAIN] Epoch[1](1231/1500); Loss: 0.056304; Backpropagation: 0.0917 sec; Batch: 0.4583 sec
0.0578 0.0557 0.0552 0.0511 0.0491 0.0486 0.0486 0.0507 0.0532 0.0542 0.0564 0.0598 0.0615 0.0623 0.0665 0.0703 

[TRAIN] Epoch[1](1232/1500); Loss: 0.158400; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2780 0.2648 0.2372 0.2118 0.1876 0.1623 0.1381 0.1200 0.1143 0.1179 0.1174 0.1146 0.1159 0.1172 0.1175 0.1199 

[TRAIN] Epoch[1](1233/1500); Loss: 0.133407; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1722 0.1639 0.1506 0.1415 0.1336 0.1281 0.1247 0.1235 0.1224 0.1224 0.1217 0.1230 0.1234 0.1260 0.1275 0.1301 

[TRAIN] Epoch[1](1234/1500); Loss: 0.134883; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2809 0.2570 0.2192 0.1894 0.1591 0.1314 0.1083 0.0968 0.0928 0.0914 0.0877 0.0871 0.0870 0.0887 0.0899 0.0915 

[TRAIN] Epoch[1](1235/1500); Loss: 0.056892; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0969 0.0891 0.0725 0.0608 0.0517 0.0499 0.0489 0.0476 0.0468 0.0479 0.0474 0.0482 0.0487 0.0505 0.0509 0.0522 

[TRAIN] Epoch[1](1236/1500); Loss: 0.123884; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1869 0.1703 0.1505 0.1391 0.1316 0.1240 0.1150 0.1102 0.1090 0.1077 0.1060 0.1046 0.1061 0.1063 0.1074 0.1076 

[TRAIN] Epoch[1](1237/1500); Loss: 0.094976; Backpropagation: 0.0917 sec; Batch: 0.4642 sec
0.2097 0.1765 0.1370 0.1103 0.0909 0.0820 0.0808 0.0762 0.0699 0.0701 0.0696 0.0685 0.0700 0.0690 0.0692 0.0700 

[TRAIN] Epoch[1](1238/1500); Loss: 0.092943; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1607 0.1442 0.1236 0.1078 0.0938 0.0830 0.0791 0.0785 0.0776 0.0752 0.0750 0.0762 0.0768 0.0760 0.0780 0.0815 

[TRAIN] Epoch[1](1239/1500); Loss: 0.116485; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1822 0.1645 0.1449 0.1322 0.1224 0.1151 0.1092 0.1039 0.1022 0.1003 0.0980 0.0971 0.0977 0.0975 0.0980 0.0985 

[TRAIN] Epoch[1](1240/1500); Loss: 0.096616; Backpropagation: 0.0917 sec; Batch: 0.4665 sec
0.1308 0.1258 0.1161 0.1087 0.1003 0.0957 0.0906 0.0891 0.0881 0.0855 0.0847 0.0851 0.0846 0.0849 0.0872 0.0885 

[TRAIN] Epoch[1](1241/1500); Loss: 0.081900; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.1252 0.1154 0.1014 0.0925 0.0855 0.0787 0.0747 0.0716 0.0698 0.0697 0.0698 0.0706 0.0702 0.0708 0.0719 0.0729 

[TRAIN] Epoch[1](1242/1500); Loss: 0.105576; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3526 0.2944 0.2262 0.1687 0.1145 0.0668 0.0440 0.0586 0.0591 0.0416 0.0427 0.0376 0.0468 0.0410 0.0479 0.0467 

[TRAIN] Epoch[1](1243/1500); Loss: 0.120097; Backpropagation: 0.0920 sec; Batch: 0.4279 sec
0.1819 0.1681 0.1493 0.1380 0.1283 0.1192 0.1118 0.1072 0.1046 0.1038 0.1024 0.1010 0.1015 0.1016 0.1013 0.1015 

[TRAIN] Epoch[1](1244/1500); Loss: 0.109662; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2274 0.2029 0.1709 0.1425 0.1177 0.0982 0.0894 0.0837 0.0797 0.0770 0.0766 0.0755 0.0766 0.0785 0.0799 0.0781 

[TRAIN] Epoch[1](1245/1500); Loss: 0.098544; Backpropagation: 0.0918 sec; Batch: 0.4263 sec
0.2846 0.2317 0.1778 0.1409 0.1121 0.0843 0.0586 0.0527 0.0544 0.0521 0.0524 0.0519 0.0542 0.0516 0.0564 0.0608 

[TRAIN] Epoch[1](1246/1500); Loss: 0.152917; Backpropagation: 0.0921 sec; Batch: 0.4278 sec
0.2097 0.1983 0.1834 0.1725 0.1610 0.1530 0.1468 0.1430 0.1386 0.1356 0.1337 0.1334 0.1341 0.1348 0.1343 0.1345 

[TRAIN] Epoch[1](1247/1500); Loss: 0.115870; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1397 0.1316 0.1273 0.1214 0.1160 0.1157 0.1126 0.1089 0.1074 0.1102 0.1079 0.1076 0.1098 0.1133 0.1120 0.1124 

[TRAIN] Epoch[1](1248/1500); Loss: 0.102456; Backpropagation: 0.0918 sec; Batch: 0.4298 sec
0.1639 0.1509 0.1322 0.1182 0.1088 0.1014 0.0951 0.0909 0.0896 0.0868 0.0843 0.0839 0.0839 0.0827 0.0827 0.0839 

[TRAIN] Epoch[1](1249/1500); Loss: 0.112876; Backpropagation: 0.0919 sec; Batch: 0.4278 sec
0.1426 0.1394 0.1305 0.1204 0.1132 0.1090 0.1060 0.1047 0.1043 0.1046 0.1050 0.1038 0.1041 0.1054 0.1063 0.1067 

[TRAIN] Epoch[1](1250/1500); Loss: 0.083838; Backpropagation: 0.0922 sec; Batch: 0.4270 sec
0.1198 0.1102 0.1004 0.0933 0.0858 0.0806 0.0781 0.0753 0.0736 0.0742 0.0747 0.0743 0.0741 0.0749 0.0760 0.0760 

[TRAIN] Epoch[1](1251/1500); Loss: 0.159137; Backpropagation: 0.0918 sec; Batch: 0.4556 sec
0.2288 0.2134 0.1951 0.1811 0.1713 0.1634 0.1559 0.1496 0.1434 0.1391 0.1354 0.1349 0.1341 0.1337 0.1331 0.1340 

[TRAIN] Epoch[1](1252/1500); Loss: 0.082264; Backpropagation: 0.0919 sec; Batch: 0.4267 sec
0.2415 0.1843 0.1233 0.0855 0.0656 0.0644 0.0657 0.0530 0.0469 0.0514 0.0538 0.0515 0.0523 0.0586 0.0599 0.0584 

[TRAIN] Epoch[1](1253/1500); Loss: 0.127798; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1895 0.1692 0.1534 0.1454 0.1388 0.1323 0.1222 0.1142 0.1118 0.1112 0.1095 0.1092 0.1081 0.1095 0.1103 0.1102 

[TRAIN] Epoch[1](1254/1500); Loss: 0.120405; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1845 0.1685 0.1456 0.1330 0.1232 0.1172 0.1116 0.1070 0.1042 0.1047 0.1041 0.1032 0.1039 0.1047 0.1052 0.1059 

[TRAIN] Epoch[1](1255/1500); Loss: 0.081867; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1257 0.1153 0.0951 0.0864 0.0811 0.0783 0.0746 0.0744 0.0727 0.0712 0.0705 0.0721 0.0711 0.0719 0.0746 0.0751 

[TRAIN] Epoch[1](1256/1500); Loss: 0.164423; Backpropagation: 0.0920 sec; Batch: 0.4281 sec
0.3627 0.3313 0.2611 0.1966 0.1700 0.1412 0.1122 0.1176 0.1247 0.1118 0.1104 0.1127 0.1211 0.1154 0.1189 0.1230 

[TRAIN] Epoch[1](1257/1500); Loss: 0.135629; Backpropagation: 0.0922 sec; Batch: 0.4261 sec
0.2151 0.1959 0.1661 0.1448 0.1312 0.1233 0.1207 0.1204 0.1203 0.1184 0.1182 0.1184 0.1192 0.1182 0.1195 0.1203 

[TRAIN] Epoch[1](1258/1500); Loss: 0.120542; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2102 0.1921 0.1642 0.1463 0.1322 0.1210 0.1107 0.1017 0.0946 0.0938 0.0921 0.0935 0.0932 0.0930 0.0940 0.0960 

[TRAIN] Epoch[1](1259/1500); Loss: 0.089371; Backpropagation: 0.0918 sec; Batch: 0.4253 sec
0.1395 0.1111 0.0978 0.0981 0.0933 0.0852 0.0818 0.0792 0.0782 0.0789 0.0780 0.0803 0.0805 0.0820 0.0818 0.0842 

[TRAIN] Epoch[1](1260/1500); Loss: 0.127712; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1655 0.1503 0.1409 0.1330 0.1265 0.1234 0.1219 0.1198 0.1190 0.1181 0.1187 0.1195 0.1197 0.1208 0.1224 0.1241 

[TRAIN] Epoch[1](1261/1500); Loss: 0.157267; Backpropagation: 0.0919 sec; Batch: 0.4308 sec
0.2194 0.1980 0.1785 0.1680 0.1612 0.1559 0.1503 0.1457 0.1450 0.1432 0.1413 0.1427 0.1421 0.1398 0.1423 0.1428 

[TRAIN] Epoch[1](1262/1500); Loss: 0.143290; Backpropagation: 0.0920 sec; Batch: 0.4314 sec
0.1647 0.1604 0.1534 0.1505 0.1447 0.1423 0.1405 0.1401 0.1389 0.1370 0.1368 0.1377 0.1361 0.1358 0.1366 0.1371 

[TRAIN] Epoch[1](1263/1500); Loss: 0.162628; Backpropagation: 0.0920 sec; Batch: 0.4629 sec
0.2300 0.2166 0.1991 0.1872 0.1749 0.1656 0.1556 0.1487 0.1437 0.1415 0.1401 0.1404 0.1396 0.1391 0.1401 0.1399 

[TRAIN] Epoch[1](1264/1500); Loss: 0.149023; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2379 0.2044 0.1706 0.1490 0.1345 0.1325 0.1370 0.1353 0.1336 0.1319 0.1363 0.1360 0.1345 0.1343 0.1385 0.1380 

[TRAIN] Epoch[1](1265/1500); Loss: 0.102672; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.2329 0.1824 0.1287 0.0970 0.0833 0.0808 0.0816 0.0829 0.0779 0.0782 0.0823 0.0868 0.0828 0.0828 0.0906 0.0919 

[TRAIN] Epoch[1](1266/1500); Loss: 0.131625; Backpropagation: 0.0919 sec; Batch: 0.4302 sec
0.1471 0.1423 0.1341 0.1290 0.1259 0.1244 0.1245 0.1256 0.1256 0.1257 0.1292 0.1299 0.1309 0.1331 0.1389 0.1397 

[TRAIN] Epoch[1](1267/1500); Loss: 0.135317; Backpropagation: 0.0919 sec; Batch: 0.4301 sec
0.2322 0.2108 0.1795 0.1577 0.1401 0.1300 0.1232 0.1171 0.1183 0.1119 0.1082 0.1073 0.1120 0.1057 0.1049 0.1061 

[TRAIN] Epoch[1](1268/1500); Loss: 0.070359; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1524 0.1393 0.0925 0.0706 0.0579 0.0524 0.0542 0.0580 0.0555 0.0535 0.0552 0.0556 0.0550 0.0562 0.0587 0.0587 

[TRAIN] Epoch[1](1269/1500); Loss: 0.121646; Backpropagation: 0.0917 sec; Batch: 0.4514 sec
0.1729 0.1533 0.1347 0.1258 0.1215 0.1189 0.1176 0.1136 0.1107 0.1092 0.1097 0.1107 0.1107 0.1103 0.1123 0.1144 

[TRAIN] Epoch[1](1270/1500); Loss: 0.155189; Backpropagation: 0.0917 sec; Batch: 0.4272 sec
0.1857 0.1762 0.1600 0.1547 0.1492 0.1479 0.1486 0.1490 0.1481 0.1487 0.1504 0.1520 0.1510 0.1527 0.1544 0.1544 

[TRAIN] Epoch[1](1271/1500); Loss: 0.078752; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1288 0.1061 0.0860 0.0772 0.0750 0.0744 0.0725 0.0706 0.0702 0.0696 0.0717 0.0701 0.0704 0.0718 0.0736 0.0719 

[TRAIN] Epoch[1](1272/1500); Loss: 0.120764; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2790 0.2576 0.1379 0.0980 0.0919 0.0893 0.0923 0.0907 0.0911 0.0959 0.0950 0.0975 0.1009 0.1025 0.1037 0.1087 

[TRAIN] Epoch[1](1273/1500); Loss: 0.168717; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1927 0.1834 0.1772 0.1741 0.1679 0.1669 0.1670 0.1625 0.1624 0.1631 0.1622 0.1616 0.1631 0.1647 0.1648 0.1661 

[TRAIN] Epoch[1](1274/1500); Loss: 0.083022; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1929 0.1648 0.1317 0.1082 0.0896 0.0745 0.0638 0.0551 0.0537 0.0531 0.0557 0.0546 0.0563 0.0559 0.0591 0.0592 

[TRAIN] Epoch[1](1275/1500); Loss: 0.154775; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1747 0.1689 0.1641 0.1609 0.1574 0.1551 0.1547 0.1543 0.1513 0.1493 0.1483 0.1474 0.1464 0.1467 0.1482 0.1484 

[TRAIN] Epoch[1](1276/1500); Loss: 0.084871; Backpropagation: 0.0918 sec; Batch: 0.4593 sec
0.2612 0.2103 0.1542 0.1169 0.0843 0.0558 0.0403 0.0473 0.0474 0.0442 0.0488 0.0467 0.0443 0.0500 0.0544 0.0518 

[TRAIN] Epoch[1](1277/1500); Loss: 0.078325; Backpropagation: 0.0921 sec; Batch: 0.4261 sec
0.0973 0.0858 0.0716 0.0715 0.0758 0.0791 0.0761 0.0746 0.0739 0.0743 0.0765 0.0781 0.0777 0.0777 0.0809 0.0822 

[TRAIN] Epoch[1](1278/1500); Loss: 0.163347; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1730 0.1642 0.1570 0.1567 0.1507 0.1509 0.1563 0.1624 0.1648 0.1657 0.1681 0.1709 0.1697 0.1675 0.1675 0.1681 

[TRAIN] Epoch[1](1279/1500); Loss: 0.144835; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1742 0.1644 0.1576 0.1545 0.1477 0.1454 0.1464 0.1424 0.1373 0.1343 0.1346 0.1358 0.1363 0.1367 0.1358 0.1343 

[TRAIN] Epoch[1](1280/1500); Loss: 0.057888; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1019 0.0765 0.0587 0.0551 0.0542 0.0517 0.0502 0.0507 0.0504 0.0491 0.0515 0.0532 0.0536 0.0536 0.0564 0.0593 

[TRAIN] Epoch[1](1281/1500); Loss: 0.169780; Backpropagation: 0.0920 sec; Batch: 0.4261 sec
0.2181 0.2095 0.1918 0.1886 0.1766 0.1708 0.1639 0.1597 0.1544 0.1511 0.1504 0.1527 0.1551 0.1573 0.1583 0.1583 

[TRAIN] Epoch[1](1282/1500); Loss: 0.074180; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1555 0.1360 0.1061 0.0934 0.0706 0.0578 0.0507 0.0509 0.0540 0.0579 0.0596 0.0587 0.0580 0.0589 0.0590 0.0597 

[TRAIN] Epoch[1](1283/1500); Loss: 0.097076; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1277 0.1211 0.1090 0.1060 0.1000 0.0976 0.0953 0.0917 0.0892 0.0883 0.0881 0.0878 0.0875 0.0877 0.0882 0.0880 

[TRAIN] Epoch[1](1284/1500); Loss: 0.268064; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.3781 0.3637 0.3231 0.3155 0.2820 0.2630 0.2336 0.2147 0.2005 0.1987 0.2091 0.2258 0.2467 0.2646 0.2816 0.2883 

[TRAIN] Epoch[1](1285/1500); Loss: 0.137476; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1797 0.1725 0.1574 0.1542 0.1438 0.1384 0.1319 0.1282 0.1261 0.1254 0.1250 0.1241 0.1234 0.1232 0.1228 0.1234 

[TRAIN] Epoch[1](1286/1500); Loss: 0.091809; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1394 0.1310 0.1076 0.1013 0.0864 0.0814 0.0744 0.0751 0.0773 0.0781 0.0795 0.0823 0.0855 0.0874 0.0896 0.0925 

[TRAIN] Epoch[1](1287/1500); Loss: 0.095566; Backpropagation: 0.0920 sec; Batch: 0.4257 sec
0.2298 0.1790 0.1265 0.0933 0.0753 0.0787 0.0774 0.0705 0.0686 0.0717 0.0714 0.0721 0.0762 0.0791 0.0777 0.0817 

[TRAIN] Epoch[1](1288/1500); Loss: 0.086135; Backpropagation: 0.0919 sec; Batch: 0.4260 sec
0.1080 0.1031 0.0959 0.0947 0.0917 0.0893 0.0849 0.0827 0.0805 0.0792 0.0779 0.0780 0.0773 0.0779 0.0778 0.0793 

[TRAIN] Epoch[1](1289/1500); Loss: 0.153367; Backpropagation: 0.0920 sec; Batch: 0.4275 sec
0.1792 0.1725 0.1634 0.1621 0.1595 0.1581 0.1521 0.1499 0.1486 0.1476 0.1446 0.1441 0.1441 0.1438 0.1418 0.1426 

[TRAIN] Epoch[1](1290/1500); Loss: 0.130348; Backpropagation: 0.0919 sec; Batch: 0.4315 sec
0.1730 0.1588 0.1456 0.1416 0.1373 0.1344 0.1276 0.1237 0.1206 0.1207 0.1175 0.1173 0.1173 0.1174 0.1153 0.1176 

[TRAIN] Epoch[1](1291/1500); Loss: 0.147634; Backpropagation: 0.0922 sec; Batch: 0.4269 sec
0.1854 0.1722 0.1555 0.1469 0.1439 0.1448 0.1381 0.1342 0.1364 0.1383 0.1367 0.1382 0.1436 0.1457 0.1481 0.1541 

[TRAIN] Epoch[1](1292/1500); Loss: 0.157168; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1976 0.1885 0.1761 0.1712 0.1678 0.1637 0.1553 0.1523 0.1499 0.1474 0.1437 0.1438 0.1418 0.1397 0.1379 0.1380 

[TRAIN] Epoch[1](1293/1500); Loss: 0.076811; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1407 0.1280 0.1010 0.0938 0.0779 0.0734 0.0617 0.0586 0.0588 0.0594 0.0591 0.0594 0.0626 0.0642 0.0641 0.0664 

[TRAIN] Epoch[1](1294/1500); Loss: 0.154365; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.2066 0.1922 0.1742 0.1674 0.1603 0.1596 0.1539 0.1484 0.1434 0.1413 0.1390 0.1375 0.1363 0.1369 0.1360 0.1367 

[TRAIN] Epoch[1](1295/1500); Loss: 0.079622; Backpropagation: 0.0922 sec; Batch: 0.4251 sec
0.2230 0.1792 0.1336 0.1006 0.0700 0.0520 0.0551 0.0628 0.0578 0.0468 0.0461 0.0477 0.0467 0.0475 0.0519 0.0530 

[TRAIN] Epoch[1](1296/1500); Loss: 0.115242; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1394 0.1313 0.1264 0.1239 0.1227 0.1201 0.1138 0.1091 0.1092 0.1088 0.1072 0.1061 0.1065 0.1062 0.1065 0.1066 

[TRAIN] Epoch[1](1297/1500); Loss: 0.158757; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.2020 0.1908 0.1781 0.1724 0.1663 0.1625 0.1563 0.1520 0.1494 0.1482 0.1461 0.1439 0.1432 0.1431 0.1431 0.1429 

[TRAIN] Epoch[1](1298/1500); Loss: 0.117881; Backpropagation: 0.0918 sec; Batch: 0.4356 sec
0.2341 0.1946 0.1545 0.1271 0.1055 0.0983 0.1044 0.1010 0.0955 0.0932 0.0940 0.0938 0.0965 0.0977 0.0977 0.0983 

[TRAIN] Epoch[1](1299/1500); Loss: 0.085407; Backpropagation: 0.0917 sec; Batch: 0.4335 sec
0.1262 0.1182 0.1023 0.0972 0.0903 0.0867 0.0813 0.0785 0.0761 0.0739 0.0725 0.0726 0.0727 0.0724 0.0724 0.0735 

[TRAIN] Epoch[1](1300/1500); Loss: 0.100825; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1459 0.1347 0.1210 0.1140 0.1063 0.1006 0.0954 0.0914 0.0897 0.0890 0.0872 0.0869 0.0872 0.0873 0.0878 0.0888 

[TRAIN] Epoch[1](1301/1500); Loss: 0.120802; Backpropagation: 0.0917 sec; Batch: 0.4257 sec
0.2583 0.2191 0.1786 0.1498 0.1236 0.1042 0.0960 0.0906 0.0887 0.0876 0.0862 0.0875 0.0882 0.0902 0.0920 0.0923 

[TRAIN] Epoch[1](1302/1500); Loss: 0.131340; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1820 0.1660 0.1559 0.1485 0.1398 0.1314 0.1261 0.1233 0.1204 0.1172 0.1163 0.1158 0.1144 0.1143 0.1152 0.1149 

[TRAIN] Epoch[1](1303/1500); Loss: 0.087923; Backpropagation: 0.0918 sec; Batch: 0.4278 sec
0.3270 0.2675 0.1998 0.1467 0.0927 0.0444 0.0297 0.0382 0.0313 0.0331 0.0261 0.0298 0.0289 0.0442 0.0337 0.0337 

[TRAIN] Epoch[1](1304/1500); Loss: 0.165869; Backpropagation: 0.0916 sec; Batch: 0.4346 sec
0.2219 0.2060 0.1864 0.1792 0.1699 0.1640 0.1587 0.1548 0.1519 0.1512 0.1505 0.1501 0.1512 0.1519 0.1528 0.1533 

[TRAIN] Epoch[1](1305/1500); Loss: 0.047892; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.0552 0.0540 0.0497 0.0479 0.0447 0.0437 0.0442 0.0445 0.0449 0.0442 0.0474 0.0472 0.0476 0.0478 0.0513 0.0519 

[TRAIN] Epoch[1](1306/1500); Loss: 0.129040; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.2338 0.2172 0.1814 0.1672 0.1430 0.1289 0.1094 0.0985 0.0935 0.0944 0.0992 0.1029 0.1009 0.0987 0.0975 0.0981 

[TRAIN] Epoch[1](1307/1500); Loss: 0.093877; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.1279 0.1172 0.1048 0.0970 0.0906 0.0878 0.0860 0.0861 0.0854 0.0867 0.0865 0.0869 0.0882 0.0905 0.0900 0.0903 

[TRAIN] Epoch[1](1308/1500); Loss: 0.164846; Backpropagation: 0.0916 sec; Batch: 0.4446 sec
0.2347 0.2169 0.1914 0.1792 0.1654 0.1594 0.1553 0.1536 0.1504 0.1484 0.1473 0.1484 0.1471 0.1465 0.1464 0.1472 

[TRAIN] Epoch[1](1309/1500); Loss: 0.137105; Backpropagation: 0.0918 sec; Batch: 0.4299 sec
0.2549 0.2502 0.2045 0.1976 0.1659 0.1534 0.1241 0.1063 0.0920 0.0876 0.0891 0.0934 0.0956 0.0946 0.0923 0.0923 

[TRAIN] Epoch[1](1310/1500); Loss: 0.071632; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1085 0.1016 0.0894 0.0806 0.0710 0.0664 0.0634 0.0625 0.0597 0.0609 0.0603 0.0627 0.0619 0.0637 0.0655 0.0680 

[TRAIN] Epoch[1](1311/1500); Loss: 0.072713; Backpropagation: 0.0918 sec; Batch: 0.4398 sec
0.1113 0.1035 0.0868 0.0838 0.0735 0.0689 0.0669 0.0655 0.0644 0.0635 0.0621 0.0616 0.0625 0.0629 0.0627 0.0635 

[TRAIN] Epoch[1](1312/1500); Loss: 0.074853; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.0996 0.0915 0.0853 0.0808 0.0759 0.0727 0.0707 0.0700 0.0687 0.0687 0.0701 0.0692 0.0679 0.0689 0.0688 0.0688 

[TRAIN] Epoch[1](1313/1500); Loss: 0.107004; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1305 0.1261 0.1179 0.1138 0.1087 0.1067 0.1039 0.1028 0.1017 0.1013 0.0999 0.0997 0.0997 0.0996 0.0997 0.1003 

[TRAIN] Epoch[1](1314/1500); Loss: 0.109545; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2052 0.1768 0.1475 0.1273 0.1083 0.0935 0.0885 0.0883 0.0868 0.0861 0.0874 0.0882 0.0896 0.0906 0.0931 0.0955 

[TRAIN] Epoch[1](1315/1500); Loss: 0.107826; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1405 0.1342 0.1266 0.1202 0.1113 0.1063 0.1032 0.0999 0.0986 0.0971 0.0976 0.0973 0.0973 0.0973 0.0982 0.0995 

[TRAIN] Epoch[1](1316/1500); Loss: 0.112351; Backpropagation: 0.0918 sec; Batch: 0.4345 sec
0.1561 0.1524 0.1354 0.1287 0.1182 0.1144 0.1089 0.1057 0.1021 0.0999 0.0979 0.0967 0.0952 0.0949 0.0954 0.0957 

[TRAIN] Epoch[1](1317/1500); Loss: 0.131196; Backpropagation: 0.0919 sec; Batch: 0.4261 sec
0.2010 0.1739 0.1495 0.1375 0.1291 0.1221 0.1183 0.1174 0.1175 0.1171 0.1168 0.1177 0.1191 0.1198 0.1198 0.1226 

[TRAIN] Epoch[1](1318/1500); Loss: 0.063487; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1576 0.1105 0.0726 0.0607 0.0587 0.0583 0.0530 0.0496 0.0499 0.0482 0.0484 0.0505 0.0490 0.0489 0.0489 0.0510 

[TRAIN] Epoch[1](1319/1500); Loss: 0.208746; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2969 0.2984 0.2587 0.2436 0.2066 0.1971 0.1758 0.1681 0.1673 0.1732 0.1853 0.1947 0.1993 0.1942 0.1898 0.1910 

[TRAIN] Epoch[1](1320/1500); Loss: 0.081358; Backpropagation: 0.0918 sec; Batch: 0.4263 sec
0.1019 0.0962 0.0893 0.0866 0.0827 0.0794 0.0780 0.0774 0.0758 0.0757 0.0762 0.0765 0.0759 0.0765 0.0766 0.0770 

[TRAIN] Epoch[1](1321/1500); Loss: 0.093710; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1916 0.1557 0.1199 0.0966 0.0854 0.0832 0.0811 0.0783 0.0750 0.0744 0.0740 0.0756 0.0755 0.0772 0.0778 0.0782 

[TRAIN] Epoch[1](1322/1500); Loss: 0.089315; Backpropagation: 0.0919 sec; Batch: 0.4260 sec
0.1101 0.1060 0.1000 0.0966 0.0905 0.0858 0.0838 0.0836 0.0834 0.0838 0.0841 0.0836 0.0836 0.0846 0.0848 0.0848 

[TRAIN] Epoch[1](1323/1500); Loss: 0.071221; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1157 0.1028 0.0887 0.0822 0.0737 0.0696 0.0652 0.0633 0.0603 0.0598 0.0586 0.0589 0.0586 0.0594 0.0604 0.0622 

[TRAIN] Epoch[1](1324/1500); Loss: 0.126954; Backpropagation: 0.0918 sec; Batch: 0.4280 sec
0.1710 0.1641 0.1447 0.1358 0.1263 0.1227 0.1187 0.1170 0.1169 0.1165 0.1156 0.1162 0.1167 0.1162 0.1158 0.1172 

[TRAIN] Epoch[1](1325/1500); Loss: 0.147276; Backpropagation: 0.0917 sec; Batch: 0.4620 sec
0.1891 0.1815 0.1646 0.1581 0.1500 0.1456 0.1406 0.1383 0.1370 0.1358 0.1355 0.1351 0.1364 0.1357 0.1367 0.1364 

[TRAIN] Epoch[1](1326/1500); Loss: 0.092273; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1142 0.1103 0.0982 0.0959 0.0914 0.0898 0.0878 0.0869 0.0863 0.0864 0.0867 0.0876 0.0874 0.0884 0.0890 0.0900 

[TRAIN] Epoch[1](1327/1500); Loss: 0.106833; Backpropagation: 0.0918 sec; Batch: 0.4281 sec
0.1862 0.1637 0.1386 0.1240 0.1120 0.1033 0.0958 0.0917 0.0884 0.0867 0.0857 0.0858 0.0853 0.0863 0.0872 0.0887 

[TRAIN] Epoch[1](1328/1500); Loss: 0.096489; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.2178 0.2149 0.1682 0.1435 0.1007 0.0876 0.0682 0.0638 0.0645 0.0630 0.0597 0.0580 0.0590 0.0580 0.0577 0.0592 

[TRAIN] Epoch[1](1329/1500); Loss: 0.098844; Backpropagation: 0.0918 sec; Batch: 0.4344 sec
0.1796 0.1610 0.1313 0.1137 0.0958 0.0877 0.0856 0.0832 0.0811 0.0805 0.0799 0.0803 0.0804 0.0802 0.0801 0.0810 

[TRAIN] Epoch[1](1330/1500); Loss: 0.137155; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.2383 0.2158 0.1790 0.1636 0.1396 0.1318 0.1192 0.1145 0.1109 0.1110 0.1146 0.1128 0.1099 0.1098 0.1118 0.1119 

[TRAIN] Epoch[1](1331/1500); Loss: 0.172325; Backpropagation: 0.0916 sec; Batch: 0.4594 sec
0.2334 0.2225 0.2036 0.1938 0.1817 0.1747 0.1661 0.1624 0.1584 0.1559 0.1531 0.1517 0.1505 0.1500 0.1496 0.1497 

[TRAIN] Epoch[1](1332/1500); Loss: 0.087836; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1940 0.1865 0.1410 0.1175 0.0802 0.0688 0.0621 0.0673 0.0663 0.0612 0.0599 0.0584 0.0630 0.0607 0.0595 0.0591 

[TRAIN] Epoch[1](1333/1500); Loss: 0.074088; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1015 0.0919 0.0836 0.0773 0.0720 0.0692 0.0675 0.0668 0.0668 0.0678 0.0680 0.0684 0.0690 0.0715 0.0717 0.0722 

[TRAIN] Epoch[1](1334/1500); Loss: 0.088740; Backpropagation: 0.0918 sec; Batch: 0.4263 sec
0.1614 0.1295 0.1026 0.0925 0.0844 0.0804 0.0784 0.0772 0.0749 0.0748 0.0760 0.0759 0.0768 0.0770 0.0786 0.0797 

[TRAIN] Epoch[1](1335/1500); Loss: 0.195965; Backpropagation: 0.0921 sec; Batch: 0.4277 sec
0.2767 0.2749 0.2308 0.2159 0.1856 0.1821 0.1753 0.1770 0.1792 0.1793 0.1761 0.1749 0.1756 0.1787 0.1776 0.1756 

[TRAIN] Epoch[1](1336/1500); Loss: 0.080276; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1576 0.1332 0.1090 0.0924 0.0799 0.0724 0.0676 0.0653 0.0644 0.0639 0.0632 0.0641 0.0634 0.0627 0.0629 0.0624 

[TRAIN] Epoch[1](1337/1500); Loss: 0.107032; Backpropagation: 0.0917 sec; Batch: 0.4253 sec
0.2173 0.1854 0.1450 0.1225 0.1046 0.0990 0.0904 0.0856 0.0831 0.0832 0.0830 0.0825 0.0828 0.0819 0.0822 0.0840 

[TRAIN] Epoch[1](1338/1500); Loss: 0.080295; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1463 0.1221 0.0934 0.0850 0.0770 0.0713 0.0693 0.0682 0.0685 0.0674 0.0678 0.0694 0.0690 0.0688 0.0702 0.0712 

[TRAIN] Epoch[1](1339/1500); Loss: 0.075755; Backpropagation: 0.0917 sec; Batch: 0.4312 sec
0.1858 0.1544 0.1200 0.0931 0.0648 0.0418 0.0421 0.0542 0.0532 0.0467 0.0481 0.0574 0.0590 0.0567 0.0633 0.0714 

[TRAIN] Epoch[1](1340/1500); Loss: 0.069219; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1334 0.1192 0.0987 0.0849 0.0707 0.0630 0.0586 0.0545 0.0530 0.0529 0.0522 0.0527 0.0525 0.0527 0.0545 0.0543 

[TRAIN] Epoch[1](1341/1500); Loss: 0.086945; Backpropagation: 0.0918 sec; Batch: 0.4346 sec
0.1496 0.1246 0.1042 0.0945 0.0884 0.0823 0.0770 0.0752 0.0745 0.0730 0.0729 0.0735 0.0738 0.0742 0.0760 0.0774 

[TRAIN] Epoch[1](1342/1500); Loss: 0.093813; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1349 0.1155 0.1020 0.1013 0.0961 0.0897 0.0880 0.0849 0.0848 0.0850 0.0871 0.0850 0.0855 0.0865 0.0870 0.0879 

[TRAIN] Epoch[1](1343/1500); Loss: 0.101438; Backpropagation: 0.0917 sec; Batch: 0.4671 sec
0.1450 0.1331 0.1135 0.1065 0.0998 0.0975 0.0931 0.0923 0.0920 0.0920 0.0906 0.0920 0.0929 0.0923 0.0943 0.0959 

[TRAIN] Epoch[1](1344/1500); Loss: 0.057036; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0725 0.0690 0.0645 0.0596 0.0544 0.0536 0.0537 0.0525 0.0524 0.0531 0.0533 0.0522 0.0541 0.0559 0.0556 0.0561 

[TRAIN] Epoch[1](1345/1500); Loss: 0.148908; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2103 0.2007 0.1755 0.1651 0.1528 0.1452 0.1371 0.1347 0.1331 0.1322 0.1316 0.1324 0.1320 0.1326 0.1337 0.1337 

[TRAIN] Epoch[1](1346/1500); Loss: 0.060529; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0884 0.0731 0.0701 0.0652 0.0598 0.0591 0.0548 0.0553 0.0548 0.0559 0.0530 0.0548 0.0552 0.0560 0.0551 0.0578 

[TRAIN] Epoch[1](1347/1500); Loss: 0.145767; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2065 0.1974 0.1732 0.1625 0.1506 0.1433 0.1362 0.1339 0.1310 0.1294 0.1282 0.1282 0.1273 0.1281 0.1282 0.1284 

[TRAIN] Epoch[1](1348/1500); Loss: 0.075611; Backpropagation: 0.0917 sec; Batch: 0.4287 sec
0.1643 0.1500 0.1026 0.0849 0.0623 0.0588 0.0607 0.0573 0.0550 0.0548 0.0597 0.0580 0.0571 0.0582 0.0637 0.0626 

[TRAIN] Epoch[1](1349/1500); Loss: 0.110658; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1581 0.1515 0.1310 0.1240 0.1134 0.1099 0.1050 0.1024 0.0999 0.0994 0.0976 0.0966 0.0957 0.0956 0.0950 0.0953 

[TRAIN] Epoch[1](1350/1500); Loss: 0.126770; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1681 0.1614 0.1440 0.1368 0.1259 0.1219 0.1187 0.1175 0.1170 0.1159 0.1163 0.1173 0.1170 0.1161 0.1168 0.1175 

[TRAIN] Epoch[1](1351/1500); Loss: 0.090837; Backpropagation: 0.0917 sec; Batch: 0.4565 sec
0.1149 0.1072 0.0990 0.0962 0.0905 0.0870 0.0853 0.0854 0.0849 0.0843 0.0850 0.0856 0.0856 0.0861 0.0874 0.0891 

[TRAIN] Epoch[1](1352/1500); Loss: 0.079546; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1400 0.1327 0.1062 0.0918 0.0715 0.0682 0.0700 0.0673 0.0666 0.0662 0.0658 0.0658 0.0657 0.0649 0.0650 0.0651 

[TRAIN] Epoch[1](1353/1500); Loss: 0.079624; Backpropagation: 0.0917 sec; Batch: 0.4615 sec
0.1321 0.1115 0.0942 0.0851 0.0769 0.0731 0.0724 0.0701 0.0695 0.0690 0.0709 0.0690 0.0698 0.0691 0.0705 0.0707 

[TRAIN] Epoch[1](1354/1500); Loss: 0.093925; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1621 0.1469 0.1290 0.1177 0.1054 0.0940 0.0876 0.0768 0.0720 0.0712 0.0718 0.0732 0.0720 0.0725 0.0743 0.0765 

[TRAIN] Epoch[1](1355/1500); Loss: 0.116755; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1462 0.1411 0.1297 0.1273 0.1199 0.1178 0.1126 0.1124 0.1102 0.1092 0.1076 0.1075 0.1062 0.1062 0.1071 0.1072 

[TRAIN] Epoch[1](1356/1500); Loss: 0.114998; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1496 0.1407 0.1315 0.1271 0.1189 0.1144 0.1103 0.1088 0.1062 0.1055 0.1052 0.1048 0.1042 0.1039 0.1042 0.1048 

[TRAIN] Epoch[1](1357/1500); Loss: 0.097003; Backpropagation: 0.0919 sec; Batch: 0.4263 sec
0.1253 0.1190 0.1092 0.1026 0.0953 0.0931 0.0924 0.0913 0.0905 0.0901 0.0905 0.0909 0.0906 0.0900 0.0906 0.0908 

[TRAIN] Epoch[1](1358/1500); Loss: 0.114533; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1842 0.1594 0.1355 0.1208 0.1134 0.1105 0.1066 0.1035 0.1010 0.1015 0.1002 0.1004 0.0989 0.0990 0.0986 0.0991 

[TRAIN] Epoch[1](1359/1500); Loss: 0.103225; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2111 0.1841 0.1452 0.1202 0.0989 0.0883 0.0858 0.0848 0.0801 0.0785 0.0781 0.0782 0.0784 0.0787 0.0807 0.0805 

[TRAIN] Epoch[1](1360/1500); Loss: 0.064977; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1130 0.0964 0.0782 0.0784 0.0671 0.0600 0.0524 0.0528 0.0523 0.0521 0.0531 0.0544 0.0550 0.0555 0.0582 0.0607 

[TRAIN] Epoch[1](1361/1500); Loss: 0.089286; Backpropagation: 0.0936 sec; Batch: 0.4341 sec
0.1269 0.1185 0.1039 0.1030 0.0970 0.0906 0.0861 0.0825 0.0809 0.0804 0.0787 0.0769 0.0761 0.0767 0.0757 0.0747 

[TRAIN] Epoch[1](1362/1500); Loss: 0.062763; Backpropagation: 0.0933 sec; Batch: 0.4267 sec
0.1195 0.0969 0.0769 0.0656 0.0581 0.0574 0.0545 0.0517 0.0515 0.0516 0.0517 0.0532 0.0527 0.0532 0.0538 0.0558 

[TRAIN] Epoch[1](1363/1500); Loss: 0.093570; Backpropagation: 0.0935 sec; Batch: 0.4265 sec
0.1105 0.1046 0.0997 0.0965 0.0933 0.0913 0.0903 0.0895 0.0886 0.0888 0.0895 0.0896 0.0901 0.0910 0.0919 0.0920 

[TRAIN] Epoch[1](1364/1500); Loss: 0.089246; Backpropagation: 0.0933 sec; Batch: 0.4271 sec
0.1202 0.1102 0.1004 0.0941 0.0875 0.0858 0.0862 0.0835 0.0825 0.0820 0.0824 0.0817 0.0821 0.0830 0.0835 0.0830 

[TRAIN] Epoch[1](1365/1500); Loss: 0.060166; Backpropagation: 0.0935 sec; Batch: 0.4269 sec
0.0670 0.0643 0.0471 0.0690 0.0662 0.0531 0.0515 0.0504 0.0550 0.0571 0.0564 0.0599 0.0640 0.0644 0.0644 0.0729 

[TRAIN] Epoch[1](1366/1500); Loss: 0.054654; Backpropagation: 0.0932 sec; Batch: 0.4248 sec
0.1098 0.0939 0.0736 0.0597 0.0513 0.0483 0.0466 0.0439 0.0422 0.0423 0.0424 0.0425 0.0425 0.0440 0.0450 0.0464 

[TRAIN] Epoch[1](1367/1500); Loss: 0.032668; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0469 0.0438 0.0336 0.0307 0.0296 0.0287 0.0284 0.0282 0.0287 0.0287 0.0296 0.0311 0.0312 0.0328 0.0350 0.0359 

[TRAIN] Epoch[1](1368/1500); Loss: 0.098951; Backpropagation: 0.0917 sec; Batch: 0.4438 sec
0.1506 0.1390 0.1275 0.1193 0.1087 0.0975 0.0907 0.0863 0.0829 0.0825 0.0824 0.0824 0.0822 0.0825 0.0834 0.0852 

[TRAIN] Epoch[1](1369/1500); Loss: 0.109226; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1774 0.1613 0.1371 0.1244 0.1126 0.1044 0.0976 0.0964 0.0942 0.0924 0.0918 0.0918 0.0911 0.0912 0.0916 0.0924 

[TRAIN] Epoch[1](1370/1500); Loss: 0.102363; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1342 0.1241 0.1147 0.1099 0.1045 0.1010 0.0985 0.0964 0.0957 0.0951 0.0947 0.0943 0.0936 0.0936 0.0937 0.0937 

[TRAIN] Epoch[1](1371/1500); Loss: 0.090882; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.3271 0.2736 0.2124 0.1618 0.1110 0.0619 0.0261 0.0387 0.0334 0.0253 0.0321 0.0290 0.0278 0.0315 0.0314 0.0311 

[TRAIN] Epoch[1](1372/1500); Loss: 0.124818; Backpropagation: 0.0919 sec; Batch: 0.4250 sec
0.3399 0.3208 0.2271 0.1754 0.0900 0.0707 0.0816 0.0839 0.0747 0.0739 0.0745 0.0753 0.0773 0.0776 0.0766 0.0778 

[TRAIN] Epoch[1](1373/1500); Loss: 0.085082; Backpropagation: 0.0917 sec; Batch: 0.4513 sec
0.1184 0.1094 0.1001 0.0958 0.0871 0.0828 0.0802 0.0775 0.0764 0.0765 0.0762 0.0761 0.0756 0.0763 0.0761 0.0768 

[TRAIN] Epoch[1](1374/1500); Loss: 0.114667; Backpropagation: 0.0917 sec; Batch: 0.4258 sec
0.1533 0.1371 0.1247 0.1196 0.1154 0.1115 0.1095 0.1089 0.1079 0.1071 0.1066 0.1070 0.1063 0.1064 0.1068 0.1067 

[TRAIN] Epoch[1](1375/1500); Loss: 0.058645; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1083 0.0974 0.0770 0.0721 0.0632 0.0527 0.0509 0.0495 0.0487 0.0463 0.0452 0.0450 0.0463 0.0453 0.0448 0.0455 

[TRAIN] Epoch[1](1376/1500); Loss: 0.119969; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.2038 0.1768 0.1523 0.1381 0.1238 0.1124 0.1045 0.1029 0.1016 0.1009 0.1002 0.0996 0.1006 0.1010 0.1002 0.1006 

[TRAIN] Epoch[1](1377/1500); Loss: 0.154191; Backpropagation: 0.0922 sec; Batch: 0.4601 sec
0.1721 0.1645 0.1588 0.1563 0.1542 0.1532 0.1515 0.1512 0.1505 0.1505 0.1500 0.1503 0.1503 0.1504 0.1511 0.1522 

[TRAIN] Epoch[1](1378/1500); Loss: 0.137170; Backpropagation: 0.0920 sec; Batch: 0.4265 sec
0.1904 0.1714 0.1483 0.1417 0.1380 0.1351 0.1240 0.1234 0.1232 0.1229 0.1235 0.1267 0.1276 0.1284 0.1335 0.1366 

[TRAIN] Epoch[1](1379/1500); Loss: 0.120733; Backpropagation: 0.0918 sec; Batch: 0.4349 sec
0.1568 0.1489 0.1393 0.1330 0.1256 0.1214 0.1181 0.1158 0.1128 0.1109 0.1098 0.1087 0.1078 0.1076 0.1078 0.1074 

[TRAIN] Epoch[1](1380/1500); Loss: 0.123433; Backpropagation: 0.0919 sec; Batch: 0.4279 sec
0.2033 0.1784 0.1510 0.1343 0.1207 0.1127 0.1098 0.1076 0.1069 0.1061 0.1060 0.1062 0.1079 0.1073 0.1078 0.1091 

[TRAIN] Epoch[1](1381/1500); Loss: 0.088175; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2215 0.1687 0.1144 0.0834 0.0725 0.0744 0.0680 0.0641 0.0642 0.0653 0.0652 0.0680 0.0691 0.0685 0.0696 0.0739 

[TRAIN] Epoch[1](1382/1500); Loss: 0.082385; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.3149 0.2556 0.1853 0.1299 0.0741 0.0313 0.0460 0.0397 0.0234 0.0333 0.0312 0.0273 0.0294 0.0310 0.0326 0.0332 

[TRAIN] Epoch[1](1383/1500); Loss: 0.127903; Backpropagation: 0.0917 sec; Batch: 0.4520 sec
0.1889 0.1729 0.1564 0.1469 0.1378 0.1288 0.1226 0.1161 0.1127 0.1105 0.1095 0.1096 0.1080 0.1084 0.1089 0.1084 

[TRAIN] Epoch[1](1384/1500); Loss: 0.070217; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1240 0.1042 0.0828 0.0717 0.0637 0.0606 0.0586 0.0587 0.0593 0.0594 0.0606 0.0617 0.0629 0.0632 0.0644 0.0678 

[TRAIN] Epoch[1](1385/1500); Loss: 0.052683; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1177 0.1058 0.0718 0.0558 0.0444 0.0432 0.0389 0.0370 0.0370 0.0368 0.0387 0.0393 0.0419 0.0421 0.0448 0.0478 

[TRAIN] Epoch[1](1386/1500); Loss: 0.055147; Backpropagation: 0.0918 sec; Batch: 0.4261 sec
0.1252 0.1071 0.0856 0.0689 0.0562 0.0474 0.0429 0.0394 0.0387 0.0380 0.0385 0.0375 0.0392 0.0393 0.0391 0.0394 

[TRAIN] Epoch[1](1387/1500); Loss: 0.070247; Backpropagation: 0.0918 sec; Batch: 0.4316 sec
0.1192 0.1026 0.0827 0.0750 0.0657 0.0613 0.0602 0.0591 0.0586 0.0597 0.0615 0.0610 0.0632 0.0647 0.0648 0.0647 

[TRAIN] Epoch[1](1388/1500); Loss: 0.068862; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2088 0.1574 0.1023 0.0702 0.0525 0.0529 0.0474 0.0428 0.0443 0.0443 0.0435 0.0473 0.0454 0.0456 0.0464 0.0506 

[TRAIN] Epoch[1](1389/1500); Loss: 0.057328; Backpropagation: 0.0917 sec; Batch: 0.4569 sec
0.0761 0.0696 0.0568 0.0565 0.0559 0.0531 0.0526 0.0558 0.0541 0.0528 0.0562 0.0554 0.0532 0.0569 0.0569 0.0554 

[TRAIN] Epoch[1](1390/1500); Loss: 0.136415; Backpropagation: 0.0921 sec; Batch: 0.4249 sec
0.1624 0.1536 0.1432 0.1408 0.1394 0.1375 0.1334 0.1322 0.1321 0.1300 0.1299 0.1304 0.1291 0.1291 0.1296 0.1298 

[TRAIN] Epoch[1](1391/1500); Loss: 0.144865; Backpropagation: 0.0917 sec; Batch: 0.4304 sec
0.1777 0.1648 0.1505 0.1431 0.1390 0.1379 0.1385 0.1383 0.1376 0.1378 0.1406 0.1399 0.1407 0.1428 0.1440 0.1445 

[TRAIN] Epoch[1](1392/1500); Loss: 0.057950; Backpropagation: 0.0917 sec; Batch: 0.4305 sec
0.0650 0.0612 0.0570 0.0569 0.0556 0.0550 0.0551 0.0549 0.0546 0.0557 0.0566 0.0571 0.0584 0.0601 0.0615 0.0625 

[TRAIN] Epoch[1](1393/1500); Loss: 0.092665; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.2095 0.2062 0.1525 0.1222 0.0848 0.0731 0.0639 0.0646 0.0628 0.0608 0.0632 0.0644 0.0623 0.0625 0.0657 0.0642 

[TRAIN] Epoch[1](1394/1500); Loss: 0.101834; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1298 0.1247 0.1120 0.1063 0.1017 0.0992 0.0982 0.0971 0.0958 0.0951 0.0955 0.0948 0.0947 0.0945 0.0948 0.0952 

[TRAIN] Epoch[1](1395/1500); Loss: 0.073276; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.0858 0.0829 0.0772 0.0751 0.0735 0.0725 0.0713 0.0704 0.0697 0.0697 0.0699 0.0694 0.0700 0.0712 0.0718 0.0720 

[TRAIN] Epoch[1](1396/1500); Loss: 0.081413; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1833 0.1626 0.1201 0.0932 0.0700 0.0637 0.0630 0.0604 0.0585 0.0585 0.0605 0.0595 0.0603 0.0613 0.0628 0.0650 

[TRAIN] Epoch[1](1397/1500); Loss: 0.075780; Backpropagation: 0.0919 sec; Batch: 0.4262 sec
0.2664 0.2118 0.1537 0.1136 0.0751 0.0438 0.0348 0.0312 0.0327 0.0393 0.0343 0.0336 0.0344 0.0326 0.0344 0.0408 

[TRAIN] Epoch[1](1398/1500); Loss: 0.089253; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1050 0.1006 0.0927 0.0915 0.0899 0.0877 0.0868 0.0867 0.0850 0.0854 0.0861 0.0854 0.0856 0.0867 0.0863 0.0863 

[TRAIN] Epoch[1](1399/1500); Loss: 0.152126; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2246 0.2176 0.1935 0.1806 0.1660 0.1603 0.1491 0.1406 0.1329 0.1271 0.1254 0.1258 0.1253 0.1222 0.1212 0.1220 

[TRAIN] Epoch[1](1400/1500); Loss: 0.159886; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1751 0.1696 0.1659 0.1636 0.1617 0.1597 0.1585 0.1572 0.1561 0.1557 0.1552 0.1553 0.1554 0.1560 0.1561 0.1569 

[TRAIN] Epoch[1](1401/1500); Loss: 0.049737; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.0635 0.0511 0.0537 0.0484 0.0467 0.0465 0.0461 0.0460 0.0495 0.0474 0.0463 0.0490 0.0498 0.0482 0.0509 0.0526 

[TRAIN] Epoch[1](1402/1500); Loss: 0.077636; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1163 0.1006 0.0905 0.0841 0.0774 0.0743 0.0727 0.0691 0.0688 0.0699 0.0691 0.0686 0.0707 0.0698 0.0691 0.0713 

[TRAIN] Epoch[1](1403/1500); Loss: 0.138084; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1955 0.1905 0.1687 0.1568 0.1454 0.1408 0.1338 0.1284 0.1250 0.1241 0.1218 0.1189 0.1172 0.1155 0.1136 0.1134 

[TRAIN] Epoch[1](1404/1500); Loss: 0.104774; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.2160 0.1830 0.1475 0.1208 0.0969 0.0841 0.0845 0.0827 0.0827 0.0820 0.0818 0.0828 0.0820 0.0826 0.0832 0.0839 

[TRAIN] Epoch[1](1405/1500); Loss: 0.058315; Backpropagation: 0.0917 sec; Batch: 0.4521 sec
0.1741 0.1600 0.1047 0.0739 0.0457 0.0353 0.0311 0.0309 0.0321 0.0318 0.0328 0.0337 0.0350 0.0357 0.0372 0.0391 

[TRAIN] Epoch[1](1406/1500); Loss: 0.139645; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.1889 0.1822 0.1562 0.1444 0.1360 0.1339 0.1331 0.1318 0.1306 0.1293 0.1287 0.1289 0.1278 0.1275 0.1276 0.1276 

[TRAIN] Epoch[1](1407/1500); Loss: 0.102648; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1358 0.1232 0.1103 0.1037 0.1008 0.0987 0.0976 0.0972 0.0967 0.0965 0.0965 0.0962 0.0973 0.0973 0.0971 0.0975 

[TRAIN] Epoch[1](1408/1500); Loss: 0.137295; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1487 0.1451 0.1392 0.1365 0.1346 0.1332 0.1333 0.1331 0.1335 0.1333 0.1354 0.1358 0.1370 0.1382 0.1395 0.1403 

[TRAIN] Epoch[1](1409/1500); Loss: 0.045329; Backpropagation: 0.0917 sec; Batch: 0.4224 sec
0.0660 0.0589 0.0468 0.0456 0.0439 0.0417 0.0410 0.0420 0.0416 0.0418 0.0419 0.0419 0.0424 0.0425 0.0434 0.0438 

[TRAIN] Epoch[1](1410/1500); Loss: 0.035202; Backpropagation: 0.0916 sec; Batch: 0.4627 sec
0.0457 0.0385 0.0301 0.0289 0.0305 0.0303 0.0316 0.0312 0.0318 0.0334 0.0355 0.0352 0.0367 0.0411 0.0407 0.0419 

[TRAIN] Epoch[1](1411/1500); Loss: 0.124531; Backpropagation: 0.0916 sec; Batch: 0.4270 sec
0.1608 0.1477 0.1366 0.1311 0.1277 0.1260 0.1221 0.1204 0.1186 0.1186 0.1164 0.1154 0.1139 0.1133 0.1122 0.1117 

[TRAIN] Epoch[1](1412/1500); Loss: 0.120889; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2034 0.1934 0.1556 0.1388 0.1209 0.1143 0.1064 0.1028 0.1002 0.1002 0.0989 0.0992 0.1003 0.0998 0.0993 0.1006 

[TRAIN] Epoch[1](1413/1500); Loss: 0.087520; Backpropagation: 0.0916 sec; Batch: 0.4429 sec
0.1104 0.1051 0.0981 0.0908 0.0860 0.0855 0.0846 0.0815 0.0800 0.0812 0.0808 0.0812 0.0820 0.0833 0.0843 0.0856 

[TRAIN] Epoch[1](1414/1500); Loss: 0.133772; Backpropagation: 0.0919 sec; Batch: 0.4273 sec
0.1843 0.1759 0.1517 0.1444 0.1349 0.1311 0.1257 0.1240 0.1227 0.1228 0.1216 0.1207 0.1210 0.1199 0.1195 0.1203 

[TRAIN] Epoch[1](1415/1500); Loss: 0.157232; Backpropagation: 0.0919 sec; Batch: 0.4268 sec
0.1839 0.1774 0.1652 0.1616 0.1564 0.1542 0.1527 0.1525 0.1530 0.1514 0.1504 0.1517 0.1513 0.1502 0.1516 0.1523 

[TRAIN] Epoch[1](1416/1500); Loss: 0.115956; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2004 0.1653 0.1325 0.1142 0.1065 0.1086 0.1065 0.1014 0.1024 0.1028 0.1014 0.1011 0.1030 0.1028 0.1024 0.1040 

[TRAIN] Epoch[1](1417/1500); Loss: 0.107088; Backpropagation: 0.0919 sec; Batch: 0.4265 sec
0.1357 0.1271 0.1180 0.1120 0.1088 0.1061 0.1034 0.1023 0.1017 0.1010 0.0998 0.0998 0.0998 0.0992 0.0990 0.0996 

[TRAIN] Epoch[1](1418/1500); Loss: 0.159832; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1937 0.1820 0.1720 0.1643 0.1596 0.1561 0.1545 0.1521 0.1529 0.1534 0.1521 0.1515 0.1532 0.1539 0.1525 0.1535 

[TRAIN] Epoch[1](1419/1500); Loss: 0.063277; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.0840 0.0809 0.0677 0.0617 0.0615 0.0601 0.0577 0.0587 0.0597 0.0581 0.0587 0.0610 0.0597 0.0592 0.0620 0.0619 

[TRAIN] Epoch[1](1420/1500); Loss: 0.141570; Backpropagation: 0.0920 sec; Batch: 0.4249 sec
0.2010 0.1920 0.1752 0.1619 0.1490 0.1406 0.1341 0.1280 0.1234 0.1218 0.1229 0.1226 0.1223 0.1226 0.1239 0.1239 

[TRAIN] Epoch[1](1421/1500); Loss: 0.120630; Backpropagation: 0.0920 sec; Batch: 0.4273 sec
0.3312 0.2911 0.2479 0.2050 0.1623 0.1208 0.0800 0.0530 0.0563 0.0556 0.0532 0.0529 0.0543 0.0539 0.0559 0.0566 

[TRAIN] Epoch[1](1422/1500); Loss: 0.098767; Backpropagation: 0.0985 sec; Batch: 0.4450 sec
0.1979 0.1768 0.1500 0.1239 0.1010 0.0826 0.0729 0.0739 0.0735 0.0720 0.0736 0.0746 0.0745 0.0758 0.0786 0.0786 

[TRAIN] Epoch[1](1423/1500); Loss: 0.118006; Backpropagation: 0.0984 sec; Batch: 0.4317 sec
0.2028 0.1775 0.1517 0.1340 0.1178 0.1048 0.0990 0.0977 0.0978 0.0987 0.0987 0.0995 0.1006 0.1020 0.1022 0.1033 

[TRAIN] Epoch[1](1424/1500); Loss: 0.124620; Backpropagation: 0.0982 sec; Batch: 0.4322 sec
0.2064 0.1890 0.1641 0.1455 0.1303 0.1233 0.1165 0.1096 0.1048 0.1018 0.1004 0.0998 0.1004 0.1007 0.1007 0.1009 

[TRAIN] Epoch[1](1425/1500); Loss: 0.066660; Backpropagation: 0.0985 sec; Batch: 0.4317 sec
0.0936 0.0854 0.0761 0.0731 0.0688 0.0664 0.0630 0.0619 0.0608 0.0606 0.0600 0.0597 0.0596 0.0594 0.0592 0.0590 

[TRAIN] Epoch[1](1426/1500); Loss: 0.055921; Backpropagation: 0.0983 sec; Batch: 0.4319 sec
0.1017 0.0694 0.0582 0.0566 0.0528 0.0501 0.0498 0.0490 0.0493 0.0500 0.0498 0.0498 0.0517 0.0523 0.0516 0.0525 

[TRAIN] Epoch[1](1427/1500); Loss: 0.121211; Backpropagation: 0.0984 sec; Batch: 0.4323 sec
0.1472 0.1393 0.1281 0.1276 0.1208 0.1193 0.1160 0.1149 0.1145 0.1143 0.1141 0.1153 0.1165 0.1165 0.1173 0.1177 

[TRAIN] Epoch[1](1428/1500); Loss: 0.080447; Backpropagation: 0.0983 sec; Batch: 0.4317 sec
0.1184 0.1050 0.0916 0.0855 0.0794 0.0766 0.0736 0.0724 0.0723 0.0719 0.0726 0.0728 0.0731 0.0734 0.0742 0.0743 

[TRAIN] Epoch[1](1429/1500); Loss: 0.095646; Backpropagation: 0.0984 sec; Batch: 0.4324 sec
0.1946 0.1749 0.1303 0.1114 0.0903 0.0838 0.0799 0.0769 0.0741 0.0742 0.0735 0.0730 0.0723 0.0733 0.0734 0.0746 

[TRAIN] Epoch[1](1430/1500); Loss: 0.101117; Backpropagation: 0.0983 sec; Batch: 0.4314 sec
0.1577 0.1428 0.1270 0.1176 0.1071 0.0998 0.0919 0.0867 0.0862 0.0854 0.0848 0.0846 0.0855 0.0862 0.0870 0.0876 

[TRAIN] Epoch[1](1431/1500); Loss: 0.101843; Backpropagation: 0.0933 sec; Batch: 0.4254 sec
0.1123 0.1073 0.1041 0.1030 0.1026 0.1015 0.1006 0.1002 0.1000 0.0996 0.0999 0.0998 0.0995 0.0994 0.0997 0.0997 

[TRAIN] Epoch[1](1432/1500); Loss: 0.077444; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0865 0.0824 0.0782 0.0760 0.0753 0.0754 0.0754 0.0753 0.0752 0.0752 0.0767 0.0767 0.0764 0.0773 0.0785 0.0786 

[TRAIN] Epoch[1](1433/1500); Loss: 0.067187; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1524 0.1095 0.0769 0.0649 0.0597 0.0570 0.0562 0.0560 0.0541 0.0553 0.0556 0.0543 0.0547 0.0570 0.0561 0.0554 

[TRAIN] Epoch[1](1434/1500); Loss: 0.064790; Backpropagation: 0.0917 sec; Batch: 0.4268 sec
0.0824 0.0790 0.0685 0.0650 0.0615 0.0612 0.0607 0.0612 0.0607 0.0611 0.0616 0.0618 0.0620 0.0628 0.0632 0.0638 

[TRAIN] Epoch[1](1435/1500); Loss: 0.102076; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1663 0.1472 0.1127 0.1057 0.1006 0.0964 0.0919 0.0899 0.0895 0.0900 0.0891 0.0890 0.0904 0.0916 0.0912 0.0916 

[TRAIN] Epoch[1](1436/1500); Loss: 0.103395; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2204 0.1680 0.1166 0.0907 0.0878 0.0861 0.0830 0.0856 0.0855 0.0860 0.0864 0.0893 0.0906 0.0904 0.0934 0.0945 

[TRAIN] Epoch[1](1437/1500); Loss: 0.067439; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1015 0.0886 0.0748 0.0691 0.0646 0.0634 0.0624 0.0617 0.0611 0.0609 0.0616 0.0615 0.0610 0.0618 0.0626 0.0625 

[TRAIN] Epoch[1](1438/1500); Loss: 0.124545; Backpropagation: 0.0919 sec; Batch: 0.4264 sec
0.1720 0.1570 0.1404 0.1348 0.1290 0.1252 0.1176 0.1150 0.1138 0.1128 0.1121 0.1119 0.1126 0.1114 0.1133 0.1139 

[TRAIN] Epoch[1](1439/1500); Loss: 0.126848; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1531 0.1409 0.1336 0.1295 0.1263 0.1249 0.1236 0.1224 0.1224 0.1211 0.1211 0.1213 0.1215 0.1215 0.1228 0.1235 

[TRAIN] Epoch[1](1440/1500); Loss: 0.085975; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.2528 0.2129 0.1576 0.1195 0.0821 0.0701 0.0553 0.0459 0.0470 0.0470 0.0453 0.0462 0.0486 0.0473 0.0483 0.0496 

[TRAIN] Epoch[1](1441/1500); Loss: 0.126463; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1623 0.1597 0.1324 0.1267 0.1186 0.1171 0.1182 0.1184 0.1192 0.1190 0.1188 0.1200 0.1207 0.1219 0.1243 0.1261 

[TRAIN] Epoch[1](1442/1500); Loss: 0.101980; Backpropagation: 0.0916 sec; Batch: 0.4247 sec
0.1566 0.1428 0.1111 0.1040 0.1004 0.0945 0.0914 0.0908 0.0921 0.0915 0.0912 0.0916 0.0923 0.0927 0.0931 0.0955 

[TRAIN] Epoch[1](1443/1500); Loss: 0.141350; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2700 0.2560 0.1940 0.1706 0.1302 0.1195 0.1130 0.1125 0.1106 0.1098 0.1120 0.1113 0.1105 0.1120 0.1133 0.1165 

[TRAIN] Epoch[1](1444/1500); Loss: 0.125759; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1767 0.1563 0.1376 0.1284 0.1225 0.1191 0.1178 0.1153 0.1153 0.1162 0.1160 0.1163 0.1172 0.1195 0.1186 0.1194 

[TRAIN] Epoch[1](1445/1500); Loss: 0.142598; Backpropagation: 0.0919 sec; Batch: 0.4251 sec
0.1873 0.1765 0.1565 0.1487 0.1413 0.1387 0.1359 0.1348 0.1333 0.1323 0.1325 0.1324 0.1320 0.1318 0.1339 0.1338 

[TRAIN] Epoch[1](1446/1500); Loss: 0.067717; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1927 0.1426 0.0925 0.0665 0.0559 0.0555 0.0511 0.0482 0.0453 0.0449 0.0462 0.0488 0.0472 0.0473 0.0493 0.0495 

[TRAIN] Epoch[1](1447/1500); Loss: 0.155486; Backpropagation: 0.0919 sec; Batch: 0.4265 sec
0.1849 0.1731 0.1638 0.1626 0.1588 0.1564 0.1530 0.1520 0.1498 0.1491 0.1479 0.1477 0.1465 0.1470 0.1472 0.1480 

[TRAIN] Epoch[1](1448/1500); Loss: 0.050418; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.0791 0.0572 0.0576 0.0545 0.0469 0.0462 0.0454 0.0456 0.0459 0.0470 0.0465 0.0456 0.0474 0.0473 0.0467 0.0478 

[TRAIN] Epoch[1](1449/1500); Loss: 0.123422; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.2073 0.1933 0.1663 0.1526 0.1364 0.1260 0.1143 0.1068 0.1011 0.0981 0.0972 0.0961 0.0953 0.0953 0.0945 0.0943 

[TRAIN] Epoch[1](1450/1500); Loss: 0.100470; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1728 0.1407 0.1129 0.0994 0.0927 0.0921 0.0904 0.0898 0.0906 0.0896 0.0890 0.0887 0.0892 0.0897 0.0894 0.0905 

[TRAIN] Epoch[1](1451/1500); Loss: 0.121332; Backpropagation: 0.0920 sec; Batch: 0.4261 sec
0.2290 0.1989 0.1592 0.1342 0.1139 0.1083 0.1027 0.1018 0.0990 0.0977 0.0980 0.0986 0.0980 0.0984 0.1011 0.1025 

[TRAIN] Epoch[1](1452/1500); Loss: 0.130498; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1548 0.1474 0.1370 0.1343 0.1286 0.1258 0.1259 0.1267 0.1246 0.1246 0.1254 0.1262 0.1259 0.1268 0.1273 0.1267 

[TRAIN] Epoch[1](1453/1500); Loss: 0.110773; Backpropagation: 0.0917 sec; Batch: 0.4304 sec
0.1278 0.1240 0.1136 0.1125 0.1094 0.1086 0.1067 0.1066 0.1072 0.1071 0.1062 0.1073 0.1080 0.1080 0.1090 0.1103 

[TRAIN] Epoch[1](1454/1500); Loss: 0.091310; Backpropagation: 0.0917 sec; Batch: 0.4272 sec
0.1562 0.1380 0.1134 0.0997 0.0874 0.0805 0.0769 0.0761 0.0757 0.0773 0.0776 0.0777 0.0790 0.0808 0.0817 0.0831 

[TRAIN] Epoch[1](1455/1500); Loss: 0.100058; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1807 0.1608 0.1381 0.1216 0.1046 0.0905 0.0833 0.0821 0.0804 0.0799 0.0796 0.0793 0.0804 0.0804 0.0799 0.0794 

[TRAIN] Epoch[1](1456/1500); Loss: 0.094059; Backpropagation: 0.0919 sec; Batch: 0.4271 sec
0.1429 0.1124 0.1019 0.0940 0.0887 0.0900 0.0888 0.0868 0.0873 0.0875 0.0870 0.0858 0.0896 0.0868 0.0870 0.0883 

[TRAIN] Epoch[1](1457/1500); Loss: 0.053521; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1069 0.0816 0.0615 0.0539 0.0490 0.0476 0.0464 0.0456 0.0447 0.0471 0.0457 0.0441 0.0443 0.0469 0.0457 0.0454 

[TRAIN] Epoch[1](1458/1500); Loss: 0.127797; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1889 0.1763 0.1450 0.1383 0.1272 0.1239 0.1179 0.1154 0.1159 0.1156 0.1140 0.1129 0.1131 0.1138 0.1129 0.1133 

[TRAIN] Epoch[1](1459/1500); Loss: 0.140746; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1930 0.1823 0.1614 0.1545 0.1458 0.1404 0.1342 0.1305 0.1280 0.1273 0.1269 0.1256 0.1255 0.1256 0.1256 0.1253 

[TRAIN] Epoch[1](1460/1500); Loss: 0.105946; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1341 0.1281 0.1122 0.1094 0.1073 0.1061 0.1029 0.1019 0.1009 0.1004 0.0991 0.0990 0.0986 0.0986 0.0982 0.0984 

[TRAIN] Epoch[1](1461/1500); Loss: 0.148334; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1696 0.1633 0.1544 0.1522 0.1496 0.1481 0.1467 0.1455 0.1445 0.1438 0.1434 0.1430 0.1427 0.1423 0.1423 0.1420 

[TRAIN] Epoch[1](1462/1500); Loss: 0.061194; Backpropagation: 0.0919 sec; Batch: 0.4283 sec
0.0915 0.0843 0.0705 0.0668 0.0624 0.0588 0.0564 0.0548 0.0536 0.0535 0.0539 0.0537 0.0545 0.0544 0.0544 0.0554 

[TRAIN] Epoch[1](1463/1500); Loss: 0.140864; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1739 0.1718 0.1469 0.1449 0.1390 0.1370 0.1360 0.1346 0.1326 0.1317 0.1337 0.1332 0.1329 0.1346 0.1355 0.1354 

[TRAIN] Epoch[1](1464/1500); Loss: 0.161373; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1791 0.1747 0.1659 0.1638 0.1620 0.1609 0.1599 0.1585 0.1586 0.1584 0.1574 0.1566 0.1569 0.1569 0.1562 0.1563 

[TRAIN] Epoch[1](1465/1500); Loss: 0.109636; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1757 0.1639 0.1397 0.1257 0.1112 0.0998 0.0965 0.0950 0.0937 0.0930 0.0929 0.0925 0.0941 0.0941 0.0933 0.0933 

[TRAIN] Epoch[1](1466/1500); Loss: 0.086372; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1834 0.1593 0.1262 0.1122 0.0931 0.0824 0.0754 0.0681 0.0645 0.0609 0.0608 0.0582 0.0586 0.0597 0.0595 0.0596 

[TRAIN] Epoch[1](1467/1500); Loss: 0.083436; Backpropagation: 0.0999 sec; Batch: 0.4338 sec
0.1074 0.1054 0.0937 0.0907 0.0860 0.0830 0.0794 0.0771 0.0759 0.0764 0.0760 0.0754 0.0763 0.0773 0.0770 0.0781 

[TRAIN] Epoch[1](1468/1500); Loss: 0.094074; Backpropagation: 0.0926 sec; Batch: 0.4251 sec
0.1386 0.1307 0.1168 0.1126 0.1005 0.0959 0.0893 0.0858 0.0826 0.0820 0.0781 0.0769 0.0772 0.0784 0.0791 0.0807 

[TRAIN] Epoch[1](1469/1500); Loss: 0.077108; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1451 0.1174 0.0921 0.0778 0.0707 0.0691 0.0676 0.0661 0.0649 0.0648 0.0657 0.0656 0.0656 0.0661 0.0673 0.0677 

[TRAIN] Epoch[1](1470/1500); Loss: 0.063757; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1302 0.1000 0.0771 0.0672 0.0623 0.0589 0.0550 0.0535 0.0521 0.0514 0.0510 0.0519 0.0516 0.0519 0.0531 0.0529 

[TRAIN] Epoch[1](1471/1500); Loss: 0.155555; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.2421 0.2410 0.1855 0.1774 0.1564 0.1490 0.1331 0.1266 0.1249 0.1279 0.1341 0.1374 0.1363 0.1352 0.1386 0.1433 

[TRAIN] Epoch[1](1472/1500); Loss: 0.076829; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1767 0.1585 0.1056 0.0921 0.0711 0.0631 0.0554 0.0595 0.0566 0.0551 0.0540 0.0571 0.0552 0.0552 0.0564 0.0578 

[TRAIN] Epoch[1](1473/1500); Loss: 0.124859; Backpropagation: 0.0920 sec; Batch: 0.4252 sec
0.1804 0.1730 0.1469 0.1415 0.1308 0.1248 0.1153 0.1126 0.1106 0.1092 0.1084 0.1079 0.1083 0.1087 0.1090 0.1102 

[TRAIN] Epoch[1](1474/1500); Loss: 0.100138; Backpropagation: 0.0917 sec; Batch: 0.4278 sec
0.1556 0.1364 0.1165 0.1085 0.0988 0.0914 0.0859 0.0871 0.0883 0.0888 0.0881 0.0896 0.0901 0.0908 0.0923 0.0941 

[TRAIN] Epoch[1](1475/1500); Loss: 0.107491; Backpropagation: 0.0919 sec; Batch: 0.4263 sec
0.1448 0.1342 0.1231 0.1163 0.1083 0.1037 0.1014 0.0999 0.0986 0.0979 0.0976 0.0979 0.0980 0.0984 0.0994 0.1004 

[TRAIN] Epoch[1](1476/1500); Loss: 0.108990; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1774 0.1702 0.1266 0.1200 0.1050 0.1002 0.0949 0.0938 0.0946 0.0928 0.0939 0.0931 0.0938 0.0937 0.0966 0.0972 

[TRAIN] Epoch[1](1477/1500); Loss: 0.083535; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1124 0.1088 0.0937 0.0886 0.0810 0.0799 0.0770 0.0758 0.0756 0.0764 0.0759 0.0770 0.0778 0.0782 0.0787 0.0798 

[TRAIN] Epoch[1](1478/1500); Loss: 0.120142; Backpropagation: 0.0942 sec; Batch: 0.4272 sec
0.1689 0.1511 0.1333 0.1265 0.1198 0.1165 0.1122 0.1113 0.1106 0.1101 0.1093 0.1096 0.1098 0.1106 0.1111 0.1115 

[TRAIN] Epoch[1](1479/1500); Loss: 0.139424; Backpropagation: 0.0935 sec; Batch: 0.4265 sec
0.1662 0.1523 0.1438 0.1417 0.1383 0.1364 0.1349 0.1349 0.1345 0.1341 0.1340 0.1345 0.1352 0.1358 0.1371 0.1372 

[TRAIN] Epoch[1](1480/1500); Loss: 0.090002; Backpropagation: 0.0934 sec; Batch: 0.4267 sec
0.1657 0.1316 0.1043 0.0935 0.0860 0.0814 0.0795 0.0785 0.0778 0.0774 0.0779 0.0774 0.0767 0.0770 0.0780 0.0773 

[TRAIN] Epoch[1](1481/1500); Loss: 0.118033; Backpropagation: 0.0934 sec; Batch: 0.4264 sec
0.1505 0.1415 0.1295 0.1256 0.1187 0.1142 0.1123 0.1118 0.1107 0.1095 0.1104 0.1107 0.1107 0.1101 0.1110 0.1115 

[TRAIN] Epoch[1](1482/1500); Loss: 0.099706; Backpropagation: 0.0933 sec; Batch: 0.4266 sec
0.1298 0.1147 0.1065 0.1037 0.0987 0.0965 0.0939 0.0938 0.0936 0.0943 0.0934 0.0941 0.0953 0.0957 0.0953 0.0959 

[TRAIN] Epoch[1](1483/1500); Loss: 0.095095; Backpropagation: 0.0935 sec; Batch: 0.4267 sec
0.1609 0.1442 0.1176 0.1204 0.1061 0.0993 0.0892 0.0852 0.0799 0.0745 0.0721 0.0737 0.0760 0.0739 0.0738 0.0748 

[TRAIN] Epoch[1](1484/1500); Loss: 0.107391; Backpropagation: 0.0934 sec; Batch: 0.4258 sec
0.1470 0.1344 0.1207 0.1135 0.1057 0.1022 0.1003 0.0999 0.0988 0.0983 0.0989 0.0990 0.0986 0.0999 0.1007 0.1003 

[TRAIN] Epoch[1](1485/1500); Loss: 0.081722; Backpropagation: 0.0935 sec; Batch: 0.4272 sec
0.1612 0.1201 0.0886 0.0777 0.0757 0.0731 0.0730 0.0713 0.0706 0.0713 0.0702 0.0704 0.0706 0.0710 0.0715 0.0714 

[TRAIN] Epoch[1](1486/1500); Loss: 0.090248; Backpropagation: 0.0934 sec; Batch: 0.4268 sec
0.1212 0.1129 0.1041 0.1008 0.0920 0.0880 0.0838 0.0824 0.0815 0.0810 0.0812 0.0814 0.0826 0.0828 0.0838 0.0847 

[TRAIN] Epoch[1](1487/1500); Loss: 0.115435; Backpropagation: 0.0934 sec; Batch: 0.4266 sec
0.1374 0.1319 0.1241 0.1228 0.1176 0.1143 0.1120 0.1116 0.1101 0.1092 0.1095 0.1093 0.1087 0.1094 0.1099 0.1094 

[TRAIN] Epoch[1](1488/1500); Loss: 0.099465; Backpropagation: 0.0930 sec; Batch: 0.4259 sec
0.1819 0.1574 0.1342 0.1175 0.1027 0.0926 0.0860 0.0813 0.0803 0.0798 0.0794 0.0793 0.0791 0.0795 0.0798 0.0806 

[TRAIN] Epoch[1](1489/1500); Loss: 0.144870; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1862 0.1744 0.1629 0.1547 0.1464 0.1408 0.1374 0.1356 0.1346 0.1346 0.1347 0.1342 0.1347 0.1352 0.1354 0.1361 

[TRAIN] Epoch[1](1490/1500); Loss: 0.038131; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.0615 0.0562 0.0401 0.0376 0.0350 0.0347 0.0340 0.0342 0.0338 0.0338 0.0341 0.0346 0.0345 0.0347 0.0355 0.0358 

[TRAIN] Epoch[1](1491/1500); Loss: 0.105138; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2493 0.2135 0.1670 0.1351 0.1078 0.0833 0.0704 0.0746 0.0718 0.0740 0.0709 0.0714 0.0715 0.0727 0.0741 0.0748 

[TRAIN] Epoch[1](1492/1500); Loss: 0.168881; Backpropagation: 0.0917 sec; Batch: 0.4526 sec
0.2169 0.2013 0.1847 0.1756 0.1691 0.1639 0.1606 0.1598 0.1592 0.1586 0.1579 0.1580 0.1592 0.1589 0.1589 0.1593 

[TRAIN] Epoch[1](1493/1500); Loss: 0.088868; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1413 0.1125 0.1005 0.0954 0.0897 0.0857 0.0822 0.0807 0.0805 0.0804 0.0799 0.0792 0.0795 0.0783 0.0779 0.0783 

[TRAIN] Epoch[1](1494/1500); Loss: 0.178986; Backpropagation: 0.0915 sec; Batch: 0.4378 sec
0.2417 0.2386 0.2010 0.1965 0.1772 0.1716 0.1636 0.1644 0.1666 0.1664 0.1634 0.1639 0.1639 0.1632 0.1606 0.1611 

[TRAIN] Epoch[1](1495/1500); Loss: 0.040868; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0410 0.0493 0.0530 0.0498 0.0391 0.0374 0.0370 0.0357 0.0364 0.0367 0.0379 0.0382 0.0384 0.0399 0.0421 0.0420 

[TRAIN] Epoch[1](1496/1500); Loss: 0.101991; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1529 0.1365 0.1214 0.1135 0.1042 0.0986 0.0946 0.0933 0.0913 0.0898 0.0885 0.0893 0.0896 0.0887 0.0884 0.0911 

[TRAIN] Epoch[1](1497/1500); Loss: 0.154118; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2162 0.2047 0.1850 0.1726 0.1587 0.1492 0.1446 0.1417 0.1392 0.1368 0.1368 0.1368 0.1369 0.1356 0.1355 0.1357 

[TRAIN] Epoch[1](1498/1500); Loss: 0.123844; Backpropagation: 0.0920 sec; Batch: 0.4257 sec
0.1688 0.1640 0.1478 0.1406 0.1300 0.1250 0.1199 0.1157 0.1108 0.1075 0.1069 0.1078 0.1083 0.1083 0.1097 0.1103 

[TRAIN] Epoch[1](1499/1500); Loss: 0.103651; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1470 0.1189 0.1031 0.1013 0.1054 0.1031 0.0978 0.0968 0.0985 0.0976 0.0966 0.0979 0.0988 0.0976 0.0978 0.1002 

[TRAIN] Epoch[1](1500/1500); Loss: 0.086009; Backpropagation: 0.0917 sec; Batch: 0.4272 sec
0.1173 0.1167 0.0962 0.0918 0.0851 0.0815 0.0805 0.0797 0.0791 0.0786 0.0778 0.0775 0.0782 0.0796 0.0779 0.0785 

/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
train.py:248: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  len(train_loader), loss.data[0], bp_t1 - bp_t0, batch_t1 -
train.py:251: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  '\n').format(* [l.data[0] for l in losses]))
[TRAIN] Epoch[2](1/1500); Loss: 0.101607; Backpropagation: 0.1015 sec; Batch: 0.4706 sec
0.1864 0.1577 0.1331 0.1149 0.0993 0.0902 0.0901 0.0884 0.0857 0.0832 0.0831 0.0821 0.0813 0.0826 0.0837 0.0842 

[TRAIN] Epoch[2](2/1500); Loss: 0.134044; Backpropagation: 0.0926 sec; Batch: 0.4297 sec
0.2052 0.1859 0.1722 0.1615 0.1466 0.1330 0.1218 0.1162 0.1182 0.1167 0.1128 0.1119 0.1130 0.1113 0.1091 0.1095 

[TRAIN] Epoch[2](3/1500); Loss: 0.080924; Backpropagation: 0.0923 sec; Batch: 0.4278 sec
0.1003 0.1037 0.0896 0.0857 0.0825 0.0813 0.0817 0.0788 0.0757 0.0742 0.0750 0.0743 0.0733 0.0725 0.0733 0.0730 

[TRAIN] Epoch[2](4/1500); Loss: 0.128525; Backpropagation: 0.0922 sec; Batch: 0.4250 sec
0.1479 0.1462 0.1411 0.1393 0.1330 0.1284 0.1238 0.1226 0.1208 0.1192 0.1208 0.1218 0.1210 0.1221 0.1240 0.1244 

[TRAIN] Epoch[2](5/1500); Loss: 0.076327; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.1087 0.0997 0.0913 0.0856 0.0783 0.0741 0.0719 0.0706 0.0686 0.0673 0.0664 0.0668 0.0679 0.0676 0.0673 0.0690 

[TRAIN] Epoch[2](6/1500); Loss: 0.086734; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1563 0.1264 0.1017 0.0868 0.0822 0.0849 0.0824 0.0761 0.0734 0.0729 0.0727 0.0727 0.0735 0.0742 0.0753 0.0761 

[TRAIN] Epoch[2](7/1500); Loss: 0.043480; Backpropagation: 0.0923 sec; Batch: 0.4267 sec
0.0523 0.0558 0.0547 0.0513 0.0416 0.0398 0.0400 0.0377 0.0383 0.0387 0.0389 0.0412 0.0403 0.0409 0.0417 0.0426 

[TRAIN] Epoch[2](8/1500); Loss: 0.085618; Backpropagation: 0.0924 sec; Batch: 0.4255 sec
0.1030 0.1039 0.0939 0.0918 0.0854 0.0825 0.0794 0.0796 0.0796 0.0795 0.0795 0.0813 0.0814 0.0818 0.0833 0.0840 

[TRAIN] Epoch[2](9/1500); Loss: 0.185598; Backpropagation: 0.0924 sec; Batch: 0.4252 sec
0.2215 0.2119 0.2045 0.1988 0.1924 0.1879 0.1849 0.1801 0.1775 0.1760 0.1771 0.1747 0.1714 0.1713 0.1708 0.1687 

[TRAIN] Epoch[2](10/1500); Loss: 0.068840; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.0955 0.0933 0.0889 0.0821 0.0676 0.0626 0.0605 0.0597 0.0602 0.0591 0.0597 0.0610 0.0612 0.0619 0.0639 0.0642 

[TRAIN] Epoch[2](11/1500); Loss: 0.112375; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.1288 0.1190 0.1145 0.1127 0.1111 0.1085 0.1093 0.1091 0.1091 0.1096 0.1099 0.1101 0.1106 0.1119 0.1117 0.1122 

[TRAIN] Epoch[2](12/1500); Loss: 0.113938; Backpropagation: 0.0920 sec; Batch: 0.4248 sec
0.1226 0.1213 0.1232 0.1200 0.1141 0.1129 0.1118 0.1107 0.1095 0.1095 0.1104 0.1104 0.1101 0.1113 0.1123 0.1131 

[TRAIN] Epoch[2](13/1500); Loss: 0.057516; Backpropagation: 0.0921 sec; Batch: 0.4251 sec
0.0671 0.0656 0.0733 0.0717 0.0635 0.0481 0.0461 0.0477 0.0493 0.0504 0.0505 0.0530 0.0551 0.0570 0.0585 0.0635 

[TRAIN] Epoch[2](14/1500); Loss: 0.213411; Backpropagation: 0.0923 sec; Batch: 0.4252 sec
0.2761 0.2633 0.2098 0.1960 0.1821 0.1830 0.1967 0.2015 0.2144 0.2162 0.2109 0.2042 0.2065 0.2149 0.2193 0.2197 

[TRAIN] Epoch[2](15/1500); Loss: 0.109647; Backpropagation: 0.0924 sec; Batch: 0.4252 sec
0.1523 0.1327 0.1165 0.1115 0.1065 0.1048 0.1042 0.1040 0.1038 0.1026 0.1019 0.1017 0.1018 0.1028 0.1035 0.1039 

[TRAIN] Epoch[2](16/1500); Loss: 0.106471; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1250 0.1230 0.1151 0.1114 0.1070 0.1017 0.1007 0.1010 0.1010 0.1007 0.1009 0.1016 0.1024 0.1032 0.1044 0.1045 

[TRAIN] Epoch[2](17/1500); Loss: 0.086961; Backpropagation: 0.0923 sec; Batch: 0.4248 sec
0.1109 0.1039 0.0923 0.0904 0.0870 0.0852 0.0854 0.0832 0.0815 0.0812 0.0814 0.0807 0.0809 0.0819 0.0829 0.0826 

[TRAIN] Epoch[2](18/1500); Loss: 0.135619; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.2427 0.2060 0.1686 0.1421 0.1256 0.1265 0.1249 0.1173 0.1139 0.1148 0.1141 0.1131 0.1152 0.1161 0.1146 0.1144 

[TRAIN] Epoch[2](19/1500); Loss: 0.085842; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1386 0.1224 0.1041 0.0929 0.0828 0.0816 0.0801 0.0763 0.0733 0.0723 0.0724 0.0723 0.0744 0.0753 0.0773 0.0772 

[TRAIN] Epoch[2](20/1500); Loss: 0.130055; Backpropagation: 0.0923 sec; Batch: 0.4255 sec
0.2086 0.1973 0.1652 0.1524 0.1339 0.1290 0.1167 0.1104 0.1063 0.1082 0.1098 0.1073 0.1082 0.1088 0.1091 0.1097 

[TRAIN] Epoch[2](21/1500); Loss: 0.111523; Backpropagation: 0.0924 sec; Batch: 0.4247 sec
0.1511 0.1363 0.1189 0.1117 0.1097 0.1086 0.1064 0.1052 0.1047 0.1042 0.1035 0.1036 0.1043 0.1047 0.1052 0.1063 

[TRAIN] Epoch[2](22/1500); Loss: 0.130578; Backpropagation: 0.0923 sec; Batch: 0.4249 sec
0.1927 0.1700 0.1491 0.1381 0.1278 0.1236 0.1218 0.1194 0.1185 0.1172 0.1167 0.1175 0.1186 0.1185 0.1192 0.1205 

[TRAIN] Epoch[2](23/1500); Loss: 0.074456; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.0998 0.0911 0.0813 0.0781 0.0728 0.0709 0.0707 0.0695 0.0687 0.0689 0.0700 0.0697 0.0692 0.0693 0.0706 0.0706 

[TRAIN] Epoch[2](24/1500); Loss: 0.096616; Backpropagation: 0.0922 sec; Batch: 0.4250 sec
0.1214 0.1094 0.1003 0.0980 0.0944 0.0934 0.0931 0.0919 0.0912 0.0920 0.0918 0.0924 0.0928 0.0939 0.0945 0.0953 

[TRAIN] Epoch[2](25/1500); Loss: 0.059249; Backpropagation: 0.0924 sec; Batch: 0.4252 sec
0.0919 0.0939 0.0641 0.0590 0.0537 0.0525 0.0517 0.0514 0.0524 0.0520 0.0521 0.0532 0.0537 0.0545 0.0548 0.0571 

[TRAIN] Epoch[2](26/1500); Loss: 0.119450; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.1850 0.1581 0.1357 0.1246 0.1188 0.1142 0.1113 0.1107 0.1085 0.1070 0.1064 0.1067 0.1054 0.1055 0.1069 0.1063 

[TRAIN] Epoch[2](27/1500); Loss: 0.152991; Backpropagation: 0.0922 sec; Batch: 0.4295 sec
0.1843 0.1728 0.1566 0.1499 0.1474 0.1486 0.1497 0.1488 0.1480 0.1481 0.1488 0.1478 0.1481 0.1488 0.1500 0.1501 

[TRAIN] Epoch[2](28/1500); Loss: 0.098371; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1420 0.1267 0.1093 0.1006 0.0930 0.0912 0.0908 0.0917 0.0915 0.0906 0.0905 0.0912 0.0915 0.0914 0.0910 0.0911 

[TRAIN] Epoch[2](29/1500); Loss: 0.103829; Backpropagation: 0.0924 sec; Batch: 0.4256 sec
0.1960 0.1782 0.1475 0.1282 0.1099 0.0951 0.0839 0.0811 0.0811 0.0803 0.0803 0.0792 0.0794 0.0797 0.0812 0.0802 

[TRAIN] Epoch[2](30/1500); Loss: 0.078850; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1706 0.1366 0.1090 0.0881 0.0716 0.0647 0.0641 0.0636 0.0630 0.0613 0.0612 0.0628 0.0610 0.0607 0.0614 0.0620 

[TRAIN] Epoch[2](31/1500); Loss: 0.070599; Backpropagation: 0.0921 sec; Batch: 0.4248 sec
0.1272 0.1000 0.0800 0.0724 0.0677 0.0653 0.0635 0.0605 0.0602 0.0606 0.0603 0.0610 0.0615 0.0625 0.0629 0.0641 

[TRAIN] Epoch[2](32/1500); Loss: 0.130054; Backpropagation: 0.0923 sec; Batch: 0.4254 sec
0.1449 0.1364 0.1289 0.1277 0.1275 0.1283 0.1283 0.1277 0.1281 0.1281 0.1278 0.1284 0.1294 0.1293 0.1296 0.1305 

[TRAIN] Epoch[2](33/1500); Loss: 0.109143; Backpropagation: 0.0926 sec; Batch: 0.4252 sec
0.1205 0.1142 0.1096 0.1073 0.1069 0.1069 0.1072 0.1070 0.1072 0.1072 0.1073 0.1077 0.1085 0.1090 0.1095 0.1104 

[TRAIN] Epoch[2](34/1500); Loss: 0.129576; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1843 0.1661 0.1520 0.1422 0.1334 0.1274 0.1227 0.1184 0.1157 0.1148 0.1144 0.1147 0.1151 0.1162 0.1173 0.1184 

[TRAIN] Epoch[2](35/1500); Loss: 0.067592; Backpropagation: 0.0923 sec; Batch: 0.4251 sec
0.1126 0.0965 0.0787 0.0760 0.0677 0.0635 0.0611 0.0605 0.0576 0.0575 0.0568 0.0572 0.0577 0.0588 0.0592 0.0602 

[TRAIN] Epoch[2](36/1500); Loss: 0.131729; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1504 0.1460 0.1419 0.1402 0.1328 0.1306 0.1288 0.1271 0.1259 0.1256 0.1262 0.1263 0.1262 0.1261 0.1265 0.1270 

[TRAIN] Epoch[2](37/1500); Loss: 0.135917; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1775 0.1582 0.1380 0.1365 0.1328 0.1294 0.1257 0.1263 0.1272 0.1281 0.1285 0.1297 0.1314 0.1330 0.1352 0.1370 

[TRAIN] Epoch[2](38/1500); Loss: 0.103532; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1308 0.1203 0.1125 0.1078 0.1034 0.1011 0.0997 0.0983 0.0976 0.0975 0.0975 0.0974 0.0976 0.0978 0.0983 0.0989 

[TRAIN] Epoch[2](39/1500); Loss: 0.110331; Backpropagation: 0.0927 sec; Batch: 0.4254 sec
0.1594 0.1434 0.1317 0.1222 0.1110 0.1048 0.1024 0.1008 0.1003 0.0989 0.0991 0.0981 0.0980 0.0982 0.0986 0.0983 

[TRAIN] Epoch[2](40/1500); Loss: 0.125798; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1416 0.1371 0.1284 0.1284 0.1263 0.1257 0.1245 0.1240 0.1233 0.1231 0.1224 0.1218 0.1216 0.1216 0.1213 0.1215 

[TRAIN] Epoch[2](41/1500); Loss: 0.105306; Backpropagation: 0.0921 sec; Batch: 0.4251 sec
0.1202 0.1167 0.1133 0.1125 0.1085 0.1032 0.1020 0.1019 0.1016 0.1005 0.1015 0.1003 0.0998 0.1009 0.1015 0.1006 

[TRAIN] Epoch[2](42/1500); Loss: 0.072479; Backpropagation: 0.0923 sec; Batch: 0.4250 sec
0.1303 0.1227 0.0907 0.0840 0.0749 0.0745 0.0677 0.0630 0.0609 0.0596 0.0578 0.0557 0.0543 0.0539 0.0544 0.0550 

[TRAIN] Epoch[2](43/1500); Loss: 0.099336; Backpropagation: 0.0922 sec; Batch: 0.4250 sec
0.1248 0.1176 0.1065 0.1027 0.1020 0.1026 0.1029 0.0987 0.0958 0.0936 0.0924 0.0911 0.0902 0.0895 0.0896 0.0893 

[TRAIN] Epoch[2](44/1500); Loss: 0.076017; Backpropagation: 0.0920 sec; Batch: 0.4250 sec
0.1001 0.0885 0.0823 0.0779 0.0734 0.0720 0.0717 0.0703 0.0696 0.0706 0.0711 0.0718 0.0733 0.0738 0.0738 0.0760 

[TRAIN] Epoch[2](45/1500); Loss: 0.115239; Backpropagation: 0.0924 sec; Batch: 0.4255 sec
0.1775 0.1596 0.1282 0.1184 0.1044 0.1024 0.1057 0.1055 0.1090 0.1071 0.1066 0.1053 0.1044 0.1030 0.1032 0.1037 

[TRAIN] Epoch[2](46/1500); Loss: 0.100958; Backpropagation: 0.0933 sec; Batch: 0.4263 sec
0.1155 0.1116 0.1080 0.1039 0.0991 0.0991 0.0989 0.0976 0.0967 0.0970 0.0967 0.0971 0.0980 0.0981 0.0983 0.0998 

[TRAIN] Epoch[2](47/1500); Loss: 0.163919; Backpropagation: 0.0923 sec; Batch: 0.4250 sec
0.2241 0.2148 0.1953 0.1813 0.1700 0.1644 0.1593 0.1551 0.1522 0.1478 0.1446 0.1430 0.1421 0.1423 0.1426 0.1438 

[TRAIN] Epoch[2](48/1500); Loss: 0.131968; Backpropagation: 0.0921 sec; Batch: 0.4253 sec
0.2133 0.1824 0.1767 0.1566 0.1411 0.1308 0.1249 0.1178 0.1119 0.1088 0.1095 0.1096 0.1079 0.1074 0.1066 0.1062 

[TRAIN] Epoch[2](49/1500); Loss: 0.163311; Backpropagation: 0.0923 sec; Batch: 0.4252 sec
0.2055 0.1910 0.1745 0.1637 0.1586 0.1577 0.1567 0.1561 0.1559 0.1556 0.1551 0.1561 0.1562 0.1557 0.1568 0.1578 

[TRAIN] Epoch[2](50/1500); Loss: 0.117107; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1284 0.1464 0.1492 0.1347 0.1289 0.1252 0.1190 0.1140 0.1093 0.1053 0.1022 0.1009 0.1008 0.1016 0.1031 0.1048 

[TRAIN] Epoch[2](51/1500); Loss: 0.097805; Backpropagation: 0.0924 sec; Batch: 0.4252 sec
0.1229 0.1254 0.1251 0.1129 0.1048 0.0990 0.0944 0.0901 0.0867 0.0857 0.0860 0.0854 0.0861 0.0869 0.0867 0.0869 

[TRAIN] Epoch[2](52/1500); Loss: 0.121435; Backpropagation: 0.0922 sec; Batch: 0.4253 sec
0.1559 0.1341 0.1286 0.1232 0.1224 0.1205 0.1167 0.1162 0.1179 0.1177 0.1153 0.1150 0.1153 0.1156 0.1140 0.1146 

[TRAIN] Epoch[2](53/1500); Loss: 0.099695; Backpropagation: 0.0921 sec; Batch: 0.4253 sec
0.1274 0.1188 0.0996 0.0939 0.0916 0.0909 0.0929 0.0951 0.0959 0.0964 0.0982 0.0978 0.0965 0.0995 0.1008 0.0999 

[TRAIN] Epoch[2](54/1500); Loss: 0.124478; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1393 0.1416 0.1438 0.1413 0.1303 0.1242 0.1202 0.1172 0.1170 0.1180 0.1165 0.1156 0.1177 0.1166 0.1147 0.1175 

[TRAIN] Epoch[2](55/1500); Loss: 0.157525; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.2017 0.1855 0.1742 0.1676 0.1638 0.1610 0.1581 0.1531 0.1499 0.1475 0.1457 0.1440 0.1432 0.1434 0.1414 0.1403 

[TRAIN] Epoch[2](56/1500); Loss: 0.082330; Backpropagation: 0.0922 sec; Batch: 0.4250 sec
0.1637 0.1193 0.0880 0.0764 0.0772 0.0816 0.0820 0.0772 0.0745 0.0709 0.0667 0.0680 0.0690 0.0667 0.0667 0.0695 

[TRAIN] Epoch[2](57/1500); Loss: 0.080622; Backpropagation: 0.0925 sec; Batch: 0.4253 sec
0.1010 0.0957 0.0922 0.0893 0.0827 0.0779 0.0742 0.0742 0.0748 0.0736 0.0740 0.0757 0.0754 0.0750 0.0772 0.0770 

[TRAIN] Epoch[2](58/1500); Loss: 0.142114; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1610 0.1623 0.1587 0.1566 0.1501 0.1450 0.1396 0.1355 0.1334 0.1325 0.1322 0.1326 0.1329 0.1325 0.1336 0.1354 

[TRAIN] Epoch[2](59/1500); Loss: 0.063902; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1025 0.0797 0.0687 0.0645 0.0627 0.0604 0.0584 0.0586 0.0575 0.0566 0.0584 0.0580 0.0574 0.0599 0.0596 0.0595 

[TRAIN] Epoch[2](60/1500); Loss: 0.078701; Backpropagation: 0.0921 sec; Batch: 0.4252 sec
0.1234 0.1089 0.0975 0.0884 0.0780 0.0735 0.0714 0.0704 0.0698 0.0688 0.0693 0.0684 0.0675 0.0686 0.0676 0.0676 

[TRAIN] Epoch[2](61/1500); Loss: 0.104576; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1293 0.1211 0.1154 0.1132 0.1052 0.1019 0.1002 0.0998 0.0984 0.0980 0.0984 0.0985 0.0979 0.0984 0.0986 0.0989 

[TRAIN] Epoch[2](62/1500); Loss: 0.067360; Backpropagation: 0.0922 sec; Batch: 0.4251 sec
0.1112 0.1202 0.0986 0.0889 0.0627 0.0558 0.0517 0.0524 0.0524 0.0518 0.0539 0.0543 0.0538 0.0553 0.0579 0.0569 

[TRAIN] Epoch[2](63/1500); Loss: 0.056234; Backpropagation: 0.0924 sec; Batch: 0.4252 sec
0.1447 0.0941 0.0611 0.0530 0.0536 0.0501 0.0449 0.0436 0.0431 0.0434 0.0443 0.0439 0.0441 0.0455 0.0453 0.0451 

[TRAIN] Epoch[2](64/1500); Loss: 0.140544; Backpropagation: 0.0920 sec; Batch: 0.4248 sec
0.2427 0.2120 0.1862 0.1729 0.1560 0.1405 0.1279 0.1203 0.1147 0.1120 0.1103 0.1099 0.1114 0.1104 0.1093 0.1123 

[TRAIN] Epoch[2](65/1500); Loss: 0.073016; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.1007 0.1178 0.0844 0.0735 0.0709 0.0717 0.0685 0.0659 0.0646 0.0646 0.0645 0.0642 0.0631 0.0649 0.0647 0.0643 

[TRAIN] Epoch[2](66/1500); Loss: 0.077386; Backpropagation: 0.0923 sec; Batch: 0.4253 sec
0.0970 0.0976 0.0910 0.0857 0.0767 0.0744 0.0721 0.0705 0.0700 0.0700 0.0703 0.0712 0.0717 0.0725 0.0733 0.0743 

[TRAIN] Epoch[2](67/1500); Loss: 0.108095; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1133 0.1215 0.1191 0.1133 0.1068 0.1060 0.1055 0.1054 0.1046 0.1046 0.1048 0.1044 0.1047 0.1051 0.1050 0.1055 

[TRAIN] Epoch[2](68/1500); Loss: 0.114292; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1421 0.1399 0.1360 0.1314 0.1213 0.1149 0.1131 0.1105 0.1069 0.1057 0.1045 0.1019 0.1010 0.1003 0.0995 0.0997 

[TRAIN] Epoch[2](69/1500); Loss: 0.117302; Backpropagation: 0.0927 sec; Batch: 0.4257 sec
0.1318 0.1315 0.1266 0.1223 0.1181 0.1166 0.1160 0.1150 0.1137 0.1129 0.1124 0.1121 0.1118 0.1116 0.1120 0.1124 

[TRAIN] Epoch[2](70/1500); Loss: 0.136874; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1936 0.1732 0.1594 0.1508 0.1448 0.1373 0.1311 0.1277 0.1257 0.1235 0.1220 0.1210 0.1198 0.1197 0.1203 0.1200 

[TRAIN] Epoch[2](71/1500); Loss: 0.027242; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.0289 0.0367 0.0384 0.0310 0.0237 0.0226 0.0229 0.0226 0.0234 0.0237 0.0241 0.0252 0.0263 0.0273 0.0289 0.0304 

[TRAIN] Epoch[2](72/1500); Loss: 0.094941; Backpropagation: 0.0924 sec; Batch: 0.4251 sec
0.1182 0.1220 0.1159 0.1097 0.0970 0.0933 0.0904 0.0884 0.0866 0.0856 0.0847 0.0846 0.0847 0.0850 0.0857 0.0871 

[TRAIN] Epoch[2](73/1500); Loss: 0.069014; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1075 0.1001 0.0851 0.0777 0.0680 0.0653 0.0633 0.0615 0.0605 0.0597 0.0589 0.0592 0.0589 0.0592 0.0593 0.0600 

[TRAIN] Epoch[2](74/1500); Loss: 0.079196; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.1195 0.1121 0.1038 0.0926 0.0804 0.0751 0.0715 0.0691 0.0683 0.0673 0.0675 0.0683 0.0675 0.0672 0.0683 0.0686 

[TRAIN] Epoch[2](75/1500); Loss: 0.120268; Backpropagation: 0.0924 sec; Batch: 0.4248 sec
0.2036 0.1887 0.1457 0.1418 0.1316 0.1252 0.1090 0.1027 0.0957 0.0966 0.0996 0.0979 0.0969 0.0964 0.0964 0.0966 

[TRAIN] Epoch[2](76/1500); Loss: 0.104961; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1557 0.1486 0.1358 0.1239 0.1080 0.1018 0.0982 0.0948 0.0931 0.0913 0.0898 0.0888 0.0888 0.0874 0.0868 0.0866 

[TRAIN] Epoch[2](77/1500); Loss: 0.153436; Backpropagation: 0.0924 sec; Batch: 0.4255 sec
0.1892 0.1779 0.1677 0.1626 0.1575 0.1528 0.1501 0.1473 0.1451 0.1439 0.1434 0.1433 0.1432 0.1434 0.1437 0.1439 

[TRAIN] Epoch[2](78/1500); Loss: 0.099715; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.2007 0.1621 0.1206 0.1061 0.0982 0.0931 0.0854 0.0822 0.0823 0.0804 0.0802 0.0798 0.0804 0.0808 0.0811 0.0821 

[TRAIN] Epoch[2](79/1500); Loss: 0.087948; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.1151 0.1141 0.1051 0.0990 0.0894 0.0857 0.0830 0.0821 0.0811 0.0796 0.0789 0.0789 0.0789 0.0790 0.0785 0.0787 

[TRAIN] Epoch[2](80/1500); Loss: 0.122816; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.2356 0.2157 0.1813 0.1571 0.1332 0.1105 0.0973 0.0966 0.0937 0.0926 0.0919 0.0915 0.0917 0.0916 0.0915 0.0932 

[TRAIN] Epoch[2](81/1500); Loss: 0.062404; Backpropagation: 0.0924 sec; Batch: 0.4253 sec
0.0933 0.0862 0.0644 0.0636 0.0585 0.0588 0.0572 0.0564 0.0563 0.0568 0.0569 0.0570 0.0575 0.0580 0.0586 0.0590 

[TRAIN] Epoch[2](82/1500); Loss: 0.098743; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1149 0.1062 0.1048 0.1021 0.0982 0.0956 0.0953 0.0950 0.0948 0.0953 0.0957 0.0956 0.0962 0.0965 0.0965 0.0972 

[TRAIN] Epoch[2](83/1500); Loss: 0.118367; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.2943 0.2564 0.2130 0.1791 0.1445 0.1121 0.0839 0.0676 0.0703 0.0687 0.0666 0.0666 0.0661 0.0668 0.0697 0.0680 

[TRAIN] Epoch[2](84/1500); Loss: 0.073368; Backpropagation: 0.0923 sec; Batch: 0.4249 sec
0.0857 0.0859 0.0837 0.0794 0.0737 0.0717 0.0711 0.0697 0.0690 0.0688 0.0687 0.0685 0.0689 0.0694 0.0698 0.0699 

[TRAIN] Epoch[2](85/1500); Loss: 0.061530; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.0747 0.0744 0.0723 0.0669 0.0601 0.0593 0.0586 0.0577 0.0573 0.0573 0.0570 0.0570 0.0574 0.0575 0.0583 0.0587 

[TRAIN] Epoch[2](86/1500); Loss: 0.099528; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.2367 0.2035 0.1069 0.0934 0.0743 0.0753 0.0830 0.0784 0.0784 0.0770 0.0788 0.0799 0.0796 0.0821 0.0822 0.0832 

[TRAIN] Epoch[2](87/1500); Loss: 0.104392; Backpropagation: 0.0924 sec; Batch: 0.4253 sec
0.1399 0.1276 0.1181 0.1143 0.1089 0.1036 0.1017 0.1001 0.0979 0.0959 0.0951 0.0940 0.0935 0.0935 0.0934 0.0928 

[TRAIN] Epoch[2](88/1500); Loss: 0.140271; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1791 0.1681 0.1517 0.1450 0.1422 0.1398 0.1377 0.1365 0.1346 0.1332 0.1318 0.1309 0.1295 0.1286 0.1280 0.1276 

[TRAIN] Epoch[2](89/1500); Loss: 0.114260; Backpropagation: 0.0921 sec; Batch: 0.4250 sec
0.1414 0.1454 0.1227 0.1133 0.1110 0.1116 0.1113 0.1097 0.1074 0.1078 0.1073 0.1070 0.1082 0.1079 0.1076 0.1084 

[TRAIN] Epoch[2](90/1500); Loss: 0.150336; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.2264 0.2079 0.1844 0.1721 0.1622 0.1529 0.1421 0.1346 0.1319 0.1308 0.1284 0.1262 0.1263 0.1257 0.1260 0.1274 

[TRAIN] Epoch[2](91/1500); Loss: 0.086121; Backpropagation: 0.0908 sec; Batch: 0.4329 sec
0.0879 0.0905 0.0877 0.0881 0.0875 0.0857 0.0853 0.0860 0.0850 0.0847 0.0851 0.0841 0.0843 0.0852 0.0854 0.0854 

[TRAIN] Epoch[2](92/1500); Loss: 0.158132; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.2151 0.1996 0.1796 0.1726 0.1643 0.1574 0.1497 0.1466 0.1454 0.1448 0.1434 0.1426 0.1424 0.1425 0.1418 0.1423 

[TRAIN] Epoch[2](93/1500); Loss: 0.049782; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1026 0.0637 0.0501 0.0536 0.0533 0.0471 0.0433 0.0428 0.0418 0.0424 0.0426 0.0431 0.0423 0.0423 0.0424 0.0429 

[TRAIN] Epoch[2](94/1500); Loss: 0.086192; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1237 0.1058 0.0818 0.0804 0.0774 0.0771 0.0786 0.0843 0.0833 0.0821 0.0862 0.0845 0.0818 0.0858 0.0843 0.0821 

[TRAIN] Epoch[2](95/1500); Loss: 0.104114; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1499 0.1291 0.1084 0.1080 0.1079 0.1038 0.0980 0.0958 0.0958 0.0948 0.0949 0.0950 0.0953 0.0954 0.0965 0.0972 

[TRAIN] Epoch[2](96/1500); Loss: 0.111356; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1770 0.1640 0.1495 0.1364 0.1193 0.1083 0.1021 0.0977 0.0957 0.0930 0.0908 0.0903 0.0899 0.0887 0.0894 0.0896 

[TRAIN] Epoch[2](97/1500); Loss: 0.072900; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1916 0.1462 0.1034 0.0760 0.0599 0.0573 0.0561 0.0512 0.0505 0.0515 0.0512 0.0525 0.0538 0.0536 0.0550 0.0567 

[TRAIN] Epoch[2](98/1500); Loss: 0.130764; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2038 0.1867 0.1620 0.1463 0.1338 0.1259 0.1215 0.1181 0.1161 0.1147 0.1126 0.1111 0.1107 0.1099 0.1094 0.1094 

[TRAIN] Epoch[2](99/1500); Loss: 0.092002; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1076 0.1048 0.0982 0.0985 0.0949 0.0901 0.0890 0.0891 0.0879 0.0874 0.0886 0.0874 0.0865 0.0881 0.0872 0.0868 

[TRAIN] Epoch[2](100/1500); Loss: 0.167895; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1906 0.1941 0.1810 0.1729 0.1676 0.1642 0.1618 0.1611 0.1608 0.1606 0.1608 0.1610 0.1623 0.1615 0.1626 0.1635 

[TRAIN] Epoch[2](101/1500); Loss: 0.063765; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1041 0.1136 0.0893 0.0789 0.0680 0.0579 0.0534 0.0535 0.0518 0.0506 0.0511 0.0499 0.0490 0.0500 0.0496 0.0494 

[TRAIN] Epoch[2](102/1500); Loss: 0.099866; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1880 0.1634 0.1222 0.1093 0.0976 0.0949 0.0871 0.0831 0.0814 0.0806 0.0808 0.0812 0.0814 0.0815 0.0825 0.0828 

[TRAIN] Epoch[2](103/1500); Loss: 0.114234; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1878 0.1681 0.1462 0.1330 0.1170 0.1041 0.1013 0.1018 0.0970 0.0962 0.0971 0.0944 0.0947 0.0972 0.0954 0.0966 

[TRAIN] Epoch[2](104/1500); Loss: 0.098828; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1496 0.1307 0.1193 0.1118 0.1024 0.0954 0.0904 0.0879 0.0866 0.0862 0.0861 0.0864 0.0865 0.0869 0.0870 0.0880 

[TRAIN] Epoch[2](105/1500); Loss: 0.074320; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1041 0.1022 0.0882 0.0812 0.0740 0.0707 0.0679 0.0663 0.0658 0.0660 0.0656 0.0660 0.0669 0.0672 0.0678 0.0693 

[TRAIN] Epoch[2](106/1500); Loss: 0.112273; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1683 0.1462 0.1326 0.1236 0.1159 0.1088 0.1053 0.1024 0.1005 0.0998 0.0988 0.0990 0.0983 0.0987 0.0988 0.0994 

[TRAIN] Epoch[2](107/1500); Loss: 0.132824; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2031 0.1751 0.1521 0.1402 0.1335 0.1272 0.1222 0.1217 0.1211 0.1194 0.1190 0.1188 0.1182 0.1183 0.1179 0.1174 

[TRAIN] Epoch[2](108/1500); Loss: 0.069306; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1049 0.1137 0.0919 0.0776 0.0700 0.0651 0.0611 0.0594 0.0575 0.0576 0.0582 0.0574 0.0581 0.0588 0.0581 0.0596 

[TRAIN] Epoch[2](109/1500); Loss: 0.071883; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0907 0.0986 0.0771 0.0737 0.0724 0.0700 0.0658 0.0675 0.0658 0.0647 0.0670 0.0660 0.0656 0.0680 0.0679 0.0694 

[TRAIN] Epoch[2](110/1500); Loss: 0.080834; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1260 0.1100 0.0936 0.0833 0.0770 0.0740 0.0728 0.0719 0.0710 0.0712 0.0719 0.0722 0.0729 0.0742 0.0749 0.0764 

[TRAIN] Epoch[2](111/1500); Loss: 0.126819; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2191 0.1932 0.1578 0.1418 0.1271 0.1180 0.1106 0.1087 0.1079 0.1071 0.1061 0.1058 0.1068 0.1063 0.1060 0.1069 

[TRAIN] Epoch[2](112/1500); Loss: 0.090131; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1203 0.1197 0.1060 0.0996 0.0924 0.0883 0.0859 0.0838 0.0817 0.0812 0.0809 0.0802 0.0805 0.0808 0.0802 0.0807 

[TRAIN] Epoch[2](113/1500); Loss: 0.131400; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1771 0.1697 0.1499 0.1424 0.1327 0.1292 0.1239 0.1217 0.1207 0.1197 0.1185 0.1192 0.1195 0.1191 0.1190 0.1200 

[TRAIN] Epoch[2](114/1500); Loss: 0.100216; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1093 0.1107 0.1097 0.1061 0.0999 0.0992 0.0977 0.0969 0.0967 0.0966 0.0963 0.0967 0.0968 0.0967 0.0971 0.0971 

[TRAIN] Epoch[2](115/1500); Loss: 0.041717; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0563 0.0573 0.0468 0.0452 0.0412 0.0388 0.0386 0.0378 0.0375 0.0376 0.0371 0.0375 0.0387 0.0382 0.0389 0.0398 

[TRAIN] Epoch[2](116/1500); Loss: 0.069792; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1309 0.1130 0.0691 0.0655 0.0649 0.0624 0.0610 0.0609 0.0606 0.0603 0.0615 0.0601 0.0607 0.0626 0.0614 0.0619 

[TRAIN] Epoch[2](117/1500); Loss: 0.093994; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1273 0.1262 0.1101 0.1026 0.0960 0.0905 0.0890 0.0878 0.0859 0.0854 0.0848 0.0838 0.0842 0.0835 0.0832 0.0835 

[TRAIN] Epoch[2](118/1500); Loss: 0.057621; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1050 0.0810 0.0558 0.0545 0.0502 0.0492 0.0514 0.0512 0.0507 0.0527 0.0521 0.0524 0.0540 0.0527 0.0532 0.0558 

[TRAIN] Epoch[2](119/1500); Loss: 0.129926; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1602 0.1490 0.1326 0.1299 0.1267 0.1259 0.1250 0.1253 0.1252 0.1249 0.1254 0.1258 0.1254 0.1253 0.1262 0.1260 

[TRAIN] Epoch[2](120/1500); Loss: 0.094013; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1163 0.1141 0.0991 0.0964 0.0927 0.0915 0.0912 0.0902 0.0889 0.0891 0.0891 0.0886 0.0892 0.0891 0.0889 0.0900 

[TRAIN] Epoch[2](121/1500); Loss: 0.108961; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1460 0.1372 0.1176 0.1136 0.1067 0.1052 0.1038 0.1033 0.1018 0.1013 0.1010 0.1012 0.1008 0.1012 0.1015 0.1011 

[TRAIN] Epoch[2](122/1500); Loss: 0.135375; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1615 0.1531 0.1454 0.1418 0.1376 0.1341 0.1318 0.1307 0.1290 0.1289 0.1292 0.1285 0.1284 0.1289 0.1284 0.1286 

[TRAIN] Epoch[2](123/1500); Loss: 0.082880; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.3189 0.2575 0.1905 0.1380 0.0844 0.0369 0.0268 0.0312 0.0296 0.0293 0.0280 0.0300 0.0298 0.0303 0.0319 0.0330 

[TRAIN] Epoch[2](124/1500); Loss: 0.152732; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1659 0.1648 0.1612 0.1588 0.1546 0.1532 0.1508 0.1496 0.1488 0.1482 0.1478 0.1478 0.1479 0.1478 0.1481 0.1483 

[TRAIN] Epoch[2](125/1500); Loss: 0.105703; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1793 0.1583 0.1329 0.1208 0.1071 0.0989 0.0938 0.0921 0.0904 0.0889 0.0884 0.0881 0.0871 0.0883 0.0881 0.0887 

[TRAIN] Epoch[2](126/1500); Loss: 0.108176; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2066 0.1767 0.1483 0.1283 0.1120 0.1019 0.0954 0.0892 0.0859 0.0845 0.0843 0.0829 0.0828 0.0837 0.0839 0.0844 

[TRAIN] Epoch[2](127/1500); Loss: 0.105067; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1226 0.1202 0.1160 0.1119 0.1061 0.1038 0.1009 0.0998 0.0991 0.0990 0.0993 0.0996 0.0995 0.1000 0.1011 0.1021 

[TRAIN] Epoch[2](128/1500); Loss: 0.084648; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1222 0.1079 0.1007 0.0936 0.0845 0.0805 0.0786 0.0763 0.0762 0.0759 0.0754 0.0759 0.0759 0.0759 0.0771 0.0777 

[TRAIN] Epoch[2](129/1500); Loss: 0.081680; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1238 0.1250 0.1016 0.0936 0.0826 0.0765 0.0715 0.0695 0.0672 0.0679 0.0685 0.0687 0.0709 0.0719 0.0728 0.0750 

[TRAIN] Epoch[2](130/1500); Loss: 0.067144; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1381 0.1077 0.0902 0.0737 0.0591 0.0560 0.0560 0.0544 0.0529 0.0542 0.0538 0.0539 0.0560 0.0548 0.0554 0.0582 

[TRAIN] Epoch[2](131/1500); Loss: 0.060703; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1718 0.1330 0.0927 0.0690 0.0527 0.0507 0.0462 0.0403 0.0397 0.0384 0.0378 0.0397 0.0385 0.0391 0.0409 0.0407 

[TRAIN] Epoch[2](132/1500); Loss: 0.121585; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1810 0.1665 0.1435 0.1317 0.1226 0.1167 0.1133 0.1112 0.1090 0.1087 0.1075 0.1071 0.1068 0.1070 0.1066 0.1062 

[TRAIN] Epoch[2](133/1500); Loss: 0.079579; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1356 0.1163 0.0934 0.0870 0.0810 0.0763 0.0720 0.0707 0.0694 0.0674 0.0676 0.0678 0.0670 0.0676 0.0671 0.0672 

[TRAIN] Epoch[2](134/1500); Loss: 0.057865; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0834 0.0814 0.0649 0.0701 0.0654 0.0582 0.0529 0.0508 0.0494 0.0490 0.0498 0.0494 0.0498 0.0504 0.0500 0.0509 

[TRAIN] Epoch[2](135/1500); Loss: 0.089360; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1342 0.1208 0.1055 0.0991 0.0917 0.0846 0.0817 0.0807 0.0787 0.0784 0.0783 0.0784 0.0786 0.0789 0.0801 0.0802 

[TRAIN] Epoch[2](136/1500); Loss: 0.091502; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1760 0.1437 0.1140 0.0975 0.0879 0.0826 0.0787 0.0768 0.0763 0.0759 0.0753 0.0755 0.0759 0.0755 0.0757 0.0768 

[TRAIN] Epoch[2](137/1500); Loss: 0.149570; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1904 0.1798 0.1686 0.1651 0.1578 0.1517 0.1458 0.1424 0.1400 0.1392 0.1379 0.1369 0.1353 0.1352 0.1337 0.1333 

[TRAIN] Epoch[2](138/1500); Loss: 0.104844; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2050 0.1725 0.1395 0.1154 0.0963 0.0932 0.0903 0.0893 0.0864 0.0856 0.0862 0.0847 0.0832 0.0844 0.0831 0.0825 

[TRAIN] Epoch[2](139/1500); Loss: 0.157987; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1987 0.1924 0.1722 0.1660 0.1603 0.1560 0.1520 0.1519 0.1491 0.1483 0.1481 0.1469 0.1465 0.1472 0.1464 0.1458 

[TRAIN] Epoch[2](140/1500); Loss: 0.118925; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2078 0.1660 0.1281 0.1091 0.1054 0.1042 0.1054 0.1063 0.1068 0.1064 0.1072 0.1082 0.1092 0.1097 0.1106 0.1122 

[TRAIN] Epoch[2](141/1500); Loss: 0.109311; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1461 0.1323 0.1179 0.1107 0.1066 0.1056 0.1039 0.1030 0.1030 0.1026 0.1025 0.1027 0.1023 0.1032 0.1033 0.1034 

[TRAIN] Epoch[2](142/1500); Loss: 0.063818; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1803 0.1316 0.1004 0.0780 0.0599 0.0451 0.0437 0.0423 0.0428 0.0408 0.0412 0.0427 0.0419 0.0419 0.0447 0.0438 

[TRAIN] Epoch[2](143/1500); Loss: 0.062949; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1039 0.1072 0.0810 0.0745 0.0649 0.0569 0.0529 0.0520 0.0514 0.0511 0.0515 0.0518 0.0513 0.0517 0.0525 0.0523 

[TRAIN] Epoch[2](144/1500); Loss: 0.148357; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1975 0.1849 0.1707 0.1635 0.1551 0.1479 0.1419 0.1384 0.1363 0.1353 0.1345 0.1339 0.1333 0.1334 0.1339 0.1333 

[TRAIN] Epoch[2](145/1500); Loss: 0.065129; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1345 0.1012 0.0801 0.0666 0.0601 0.0566 0.0559 0.0546 0.0539 0.0549 0.0533 0.0532 0.0547 0.0534 0.0536 0.0553 

[TRAIN] Epoch[2](146/1500); Loss: 0.078082; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1134 0.0980 0.0809 0.0854 0.0823 0.0747 0.0712 0.0699 0.0701 0.0701 0.0704 0.0708 0.0714 0.0724 0.0737 0.0746 

[TRAIN] Epoch[2](147/1500); Loss: 0.077011; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1797 0.1416 0.1088 0.0856 0.0704 0.0649 0.0606 0.0587 0.0573 0.0574 0.0577 0.0572 0.0570 0.0580 0.0585 0.0587 

[TRAIN] Epoch[2](148/1500); Loss: 0.097941; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.3112 0.2588 0.2046 0.1599 0.1154 0.0732 0.0405 0.0532 0.0489 0.0454 0.0414 0.0416 0.0449 0.0414 0.0419 0.0447 

[TRAIN] Epoch[2](149/1500); Loss: 0.066869; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1278 0.0932 0.0783 0.0701 0.0624 0.0594 0.0579 0.0580 0.0575 0.0573 0.0574 0.0581 0.0576 0.0582 0.0585 0.0583 

[TRAIN] Epoch[2](150/1500); Loss: 0.112204; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1403 0.1238 0.1124 0.1145 0.1117 0.1078 0.1075 0.1079 0.1078 0.1077 0.1088 0.1083 0.1077 0.1103 0.1096 0.1093 

[TRAIN] Epoch[2](151/1500); Loss: 0.120769; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1763 0.1660 0.1434 0.1354 0.1276 0.1205 0.1127 0.1080 0.1063 0.1060 0.1054 0.1054 0.1041 0.1048 0.1051 0.1053 

[TRAIN] Epoch[2](152/1500); Loss: 0.073921; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1201 0.0942 0.0842 0.0748 0.0709 0.0684 0.0665 0.0666 0.0668 0.0667 0.0665 0.0668 0.0674 0.0674 0.0676 0.0679 

[TRAIN] Epoch[2](153/1500); Loss: 0.140572; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1934 0.1732 0.1537 0.1463 0.1393 0.1370 0.1333 0.1320 0.1303 0.1308 0.1308 0.1299 0.1300 0.1302 0.1295 0.1295 

[TRAIN] Epoch[2](154/1500); Loss: 0.061307; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.0758 0.0651 0.0670 0.0676 0.0620 0.0585 0.0587 0.0577 0.0582 0.0573 0.0585 0.0583 0.0583 0.0597 0.0587 0.0596 

[TRAIN] Epoch[2](155/1500); Loss: 0.069184; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0898 0.0857 0.0763 0.0753 0.0710 0.0679 0.0654 0.0642 0.0645 0.0644 0.0637 0.0634 0.0634 0.0635 0.0641 0.0642 

[TRAIN] Epoch[2](156/1500); Loss: 0.065467; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0993 0.0887 0.0807 0.0707 0.0666 0.0648 0.0616 0.0595 0.0581 0.0578 0.0566 0.0570 0.0564 0.0566 0.0565 0.0565 

[TRAIN] Epoch[2](157/1500); Loss: 0.146603; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1946 0.1806 0.1659 0.1607 0.1537 0.1484 0.1432 0.1404 0.1370 0.1350 0.1326 0.1315 0.1310 0.1302 0.1304 0.1305 

[TRAIN] Epoch[2](158/1500); Loss: 0.106898; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2213 0.1836 0.1492 0.1224 0.0988 0.0868 0.0847 0.0844 0.0833 0.0833 0.0835 0.0843 0.0847 0.0861 0.0867 0.0874 

[TRAIN] Epoch[2](159/1500); Loss: 0.132922; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1810 0.1783 0.1533 0.1486 0.1398 0.1326 0.1285 0.1240 0.1217 0.1195 0.1179 0.1168 0.1165 0.1160 0.1162 0.1160 

[TRAIN] Epoch[2](160/1500); Loss: 0.100655; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1133 0.1137 0.1063 0.1059 0.1026 0.0997 0.0983 0.0975 0.0971 0.0967 0.0965 0.0965 0.0966 0.0964 0.0964 0.0970 

[TRAIN] Epoch[2](161/1500); Loss: 0.113559; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1446 0.1350 0.1199 0.1172 0.1117 0.1088 0.1088 0.1077 0.1070 0.1068 0.1071 0.1073 0.1086 0.1085 0.1083 0.1096 

[TRAIN] Epoch[2](162/1500); Loss: 0.113725; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1486 0.1321 0.1227 0.1209 0.1165 0.1119 0.1111 0.1094 0.1089 0.1071 0.1061 0.1055 0.1052 0.1047 0.1045 0.1042 

[TRAIN] Epoch[2](163/1500); Loss: 0.108897; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1259 0.1162 0.1147 0.1169 0.1141 0.1088 0.1063 0.1070 0.1046 0.1030 0.1043 0.1050 0.1034 0.1041 0.1050 0.1032 

[TRAIN] Epoch[2](164/1500); Loss: 0.080956; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0958 0.0904 0.0834 0.0809 0.0794 0.0787 0.0788 0.0785 0.0781 0.0785 0.0787 0.0787 0.0782 0.0784 0.0793 0.0794 

[TRAIN] Epoch[2](165/1500); Loss: 0.093414; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1157 0.1103 0.0999 0.0988 0.0950 0.0917 0.0899 0.0887 0.0878 0.0875 0.0878 0.0872 0.0879 0.0879 0.0890 0.0895 

[TRAIN] Epoch[2](166/1500); Loss: 0.099009; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1206 0.1107 0.1024 0.1010 0.1011 0.1007 0.0980 0.0959 0.0941 0.0927 0.0925 0.0930 0.0938 0.0947 0.0960 0.0968 

[TRAIN] Epoch[2](167/1500); Loss: 0.064319; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0788 0.0982 0.0929 0.0898 0.0752 0.0689 0.0606 0.0560 0.0529 0.0514 0.0505 0.0506 0.0505 0.0508 0.0507 0.0513 

[TRAIN] Epoch[2](168/1500); Loss: 0.115391; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2046 0.1688 0.1382 0.1237 0.1191 0.1238 0.1191 0.1067 0.1014 0.0973 0.0945 0.0903 0.0898 0.0896 0.0894 0.0899 

[TRAIN] Epoch[2](169/1500); Loss: 0.125028; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1463 0.1416 0.1362 0.1357 0.1304 0.1260 0.1239 0.1228 0.1200 0.1176 0.1159 0.1154 0.1163 0.1175 0.1179 0.1171 

[TRAIN] Epoch[2](170/1500); Loss: 0.102665; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1581 0.1395 0.1277 0.1210 0.1096 0.0972 0.0882 0.0868 0.0891 0.0901 0.0888 0.0881 0.0886 0.0889 0.0897 0.0912 

[TRAIN] Epoch[2](171/1500); Loss: 0.143617; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1896 0.1875 0.1711 0.1716 0.1580 0.1477 0.1362 0.1293 0.1254 0.1248 0.1251 0.1252 0.1247 0.1251 0.1269 0.1297 

[TRAIN] Epoch[2](172/1500); Loss: 0.108709; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1863 0.1429 0.1194 0.1194 0.1234 0.1261 0.1114 0.0970 0.0909 0.0920 0.0911 0.0878 0.0881 0.0879 0.0882 0.0875 

[TRAIN] Epoch[2](173/1500); Loss: 0.114336; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1771 0.1526 0.1303 0.1220 0.1217 0.1170 0.1069 0.1038 0.1028 0.1008 0.1006 0.1011 0.0990 0.0979 0.0984 0.0973 

[TRAIN] Epoch[2](174/1500); Loss: 0.142435; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1857 0.1791 0.1642 0.1615 0.1544 0.1482 0.1388 0.1342 0.1314 0.1294 0.1266 0.1259 0.1251 0.1252 0.1246 0.1247 

[TRAIN] Epoch[2](175/1500); Loss: 0.053736; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0807 0.0821 0.0824 0.0882 0.0701 0.0536 0.0423 0.0416 0.0408 0.0386 0.0395 0.0395 0.0396 0.0397 0.0397 0.0414 

[TRAIN] Epoch[2](176/1500); Loss: 0.160326; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2740 0.2527 0.2242 0.2185 0.2033 0.1933 0.1710 0.1567 0.1398 0.1285 0.1150 0.1066 0.1017 0.0976 0.0939 0.0883 

[TRAIN] Epoch[2](177/1500); Loss: 0.151500; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1982 0.1917 0.1792 0.1732 0.1622 0.1565 0.1484 0.1461 0.1424 0.1384 0.1346 0.1326 0.1311 0.1305 0.1301 0.1290 

[TRAIN] Epoch[2](178/1500); Loss: 0.140554; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2201 0.1994 0.1755 0.1633 0.1480 0.1428 0.1345 0.1273 0.1232 0.1220 0.1202 0.1167 0.1151 0.1146 0.1143 0.1118 

[TRAIN] Epoch[2](179/1500); Loss: 0.139649; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1934 0.1812 0.1642 0.1549 0.1428 0.1376 0.1327 0.1315 0.1301 0.1269 0.1248 0.1236 0.1235 0.1237 0.1222 0.1213 

[TRAIN] Epoch[2](180/1500); Loss: 0.109887; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1315 0.1326 0.1285 0.1253 0.1128 0.1080 0.1038 0.1025 0.1010 0.0994 0.0980 0.0999 0.1008 0.1013 0.1047 0.1082 

[TRAIN] Epoch[2](181/1500); Loss: 0.114170; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1627 0.1585 0.1433 0.1336 0.1187 0.1125 0.1053 0.1021 0.1013 0.1002 0.0991 0.0978 0.0977 0.0984 0.0980 0.0974 

[TRAIN] Epoch[2](182/1500); Loss: 0.104303; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1509 0.1511 0.1338 0.1355 0.1223 0.1133 0.0989 0.0937 0.0881 0.0860 0.0858 0.0831 0.0824 0.0821 0.0812 0.0805 

[TRAIN] Epoch[2](183/1500); Loss: 0.098783; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1602 0.1369 0.1173 0.1015 0.0916 0.0892 0.0900 0.0898 0.0910 0.0894 0.0869 0.0855 0.0866 0.0894 0.0880 0.0873 

[TRAIN] Epoch[2](184/1500); Loss: 0.153410; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1728 0.1733 0.1670 0.1634 0.1576 0.1554 0.1535 0.1513 0.1489 0.1473 0.1455 0.1445 0.1436 0.1433 0.1435 0.1438 

[TRAIN] Epoch[2](185/1500); Loss: 0.098000; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1248 0.1282 0.1095 0.1061 0.1028 0.0991 0.0944 0.0920 0.0908 0.0893 0.0885 0.0883 0.0882 0.0884 0.0885 0.0892 

[TRAIN] Epoch[2](186/1500); Loss: 0.147232; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2177 0.2022 0.1714 0.1647 0.1482 0.1419 0.1321 0.1273 0.1260 0.1275 0.1312 0.1328 0.1328 0.1324 0.1323 0.1351 

[TRAIN] Epoch[2](187/1500); Loss: 0.089431; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1143 0.1125 0.1031 0.0972 0.0886 0.0865 0.0853 0.0842 0.0835 0.0825 0.0823 0.0823 0.0818 0.0822 0.0826 0.0820 

[TRAIN] Epoch[2](188/1500); Loss: 0.079159; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1533 0.1270 0.1043 0.0933 0.0836 0.0783 0.0700 0.0672 0.0644 0.0619 0.0606 0.0615 0.0600 0.0600 0.0610 0.0600 

[TRAIN] Epoch[2](189/1500); Loss: 0.096715; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1261 0.1289 0.1208 0.1120 0.0965 0.0904 0.0899 0.0894 0.0874 0.0861 0.0865 0.0867 0.0856 0.0858 0.0880 0.0876 

[TRAIN] Epoch[2](190/1500); Loss: 0.122079; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1489 0.1547 0.1468 0.1405 0.1286 0.1243 0.1183 0.1146 0.1124 0.1112 0.1094 0.1086 0.1091 0.1086 0.1085 0.1090 

[TRAIN] Epoch[2](191/1500); Loss: 0.148325; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1776 0.1753 0.1660 0.1615 0.1537 0.1506 0.1466 0.1437 0.1413 0.1389 0.1377 0.1370 0.1363 0.1354 0.1357 0.1357 

[TRAIN] Epoch[2](192/1500); Loss: 0.109320; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1989 0.1567 0.1205 0.1084 0.1066 0.1026 0.0972 0.0962 0.0951 0.0930 0.0943 0.0964 0.0946 0.0940 0.0976 0.0969 

[TRAIN] Epoch[2](193/1500); Loss: 0.150692; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2140 0.1864 0.1671 0.1619 0.1546 0.1479 0.1456 0.1432 0.1402 0.1380 0.1368 0.1365 0.1357 0.1349 0.1340 0.1343 

[TRAIN] Epoch[2](194/1500); Loss: 0.071082; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1321 0.1193 0.0981 0.0865 0.0771 0.0691 0.0598 0.0569 0.0550 0.0540 0.0549 0.0543 0.0546 0.0540 0.0552 0.0564 

[TRAIN] Epoch[2](195/1500); Loss: 0.110009; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1738 0.1532 0.1359 0.1273 0.1169 0.1119 0.1054 0.1034 0.0987 0.0955 0.0933 0.0916 0.0888 0.0878 0.0888 0.0879 

[TRAIN] Epoch[2](196/1500); Loss: 0.059482; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0775 0.0688 0.0702 0.0649 0.0586 0.0583 0.0578 0.0539 0.0537 0.0542 0.0559 0.0542 0.0550 0.0548 0.0578 0.0561 

[TRAIN] Epoch[2](197/1500); Loss: 0.182308; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2412 0.2288 0.2177 0.2106 0.1990 0.1909 0.1815 0.1748 0.1682 0.1640 0.1606 0.1577 0.1564 0.1558 0.1552 0.1546 

[TRAIN] Epoch[2](198/1500); Loss: 0.117724; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2541 0.2122 0.1763 0.1507 0.1185 0.0922 0.1011 0.0962 0.0856 0.0883 0.0848 0.0842 0.0840 0.0864 0.0851 0.0839 

[TRAIN] Epoch[2](199/1500); Loss: 0.108604; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2734 0.2369 0.1987 0.1644 0.1280 0.0943 0.0656 0.0706 0.0683 0.0624 0.0634 0.0621 0.0617 0.0637 0.0613 0.0629 

[TRAIN] Epoch[2](200/1500); Loss: 0.113156; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1809 0.1543 0.1344 0.1224 0.1135 0.1059 0.1023 0.1008 0.1001 0.0989 0.0992 0.0989 0.0991 0.1001 0.0997 0.1001 

[TRAIN] Epoch[2](201/1500); Loss: 0.097241; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1167 0.1169 0.1085 0.1089 0.1017 0.0973 0.0920 0.0902 0.0924 0.0908 0.0896 0.0896 0.0894 0.0900 0.0911 0.0911 

[TRAIN] Epoch[2](202/1500); Loss: 0.169235; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1775 0.1783 0.1759 0.1718 0.1695 0.1697 0.1705 0.1672 0.1651 0.1661 0.1671 0.1651 0.1644 0.1667 0.1665 0.1663 

[TRAIN] Epoch[2](203/1500); Loss: 0.134129; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1762 0.1655 0.1530 0.1475 0.1379 0.1325 0.1270 0.1254 0.1238 0.1228 0.1221 0.1225 0.1220 0.1217 0.1228 0.1234 

[TRAIN] Epoch[2](204/1500); Loss: 0.140129; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1822 0.1750 0.1638 0.1567 0.1488 0.1442 0.1387 0.1343 0.1306 0.1272 0.1245 0.1238 0.1240 0.1233 0.1225 0.1225 

[TRAIN] Epoch[2](205/1500); Loss: 0.070821; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1012 0.0806 0.0920 0.0925 0.0785 0.0655 0.0636 0.0618 0.0614 0.0621 0.0617 0.0618 0.0620 0.0623 0.0629 0.0631 

[TRAIN] Epoch[2](206/1500); Loss: 0.093158; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1649 0.1452 0.1188 0.1131 0.0976 0.0883 0.0821 0.0791 0.0785 0.0757 0.0746 0.0737 0.0746 0.0751 0.0746 0.0748 

[TRAIN] Epoch[2](207/1500); Loss: 0.073560; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2253 0.1723 0.1316 0.1038 0.0715 0.0408 0.0487 0.0443 0.0396 0.0416 0.0415 0.0403 0.0437 0.0449 0.0431 0.0440 

[TRAIN] Epoch[2](208/1500); Loss: 0.052759; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1067 0.0891 0.0665 0.0560 0.0492 0.0474 0.0463 0.0443 0.0421 0.0425 0.0423 0.0422 0.0418 0.0428 0.0427 0.0422 

[TRAIN] Epoch[2](209/1500); Loss: 0.111996; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1445 0.1355 0.1271 0.1209 0.1128 0.1090 0.1066 0.1052 0.1044 0.1039 0.1042 0.1035 0.1033 0.1043 0.1036 0.1032 

[TRAIN] Epoch[2](210/1500); Loss: 0.088821; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1549 0.1419 0.1234 0.1117 0.0943 0.0817 0.0748 0.0754 0.0735 0.0699 0.0685 0.0680 0.0696 0.0706 0.0711 0.0718 

[TRAIN] Epoch[2](211/1500); Loss: 0.106096; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1230 0.1230 0.1161 0.1142 0.1080 0.1055 0.1033 0.1024 0.1012 0.1013 0.1008 0.1002 0.1000 0.1000 0.0993 0.0993 

[TRAIN] Epoch[2](212/1500); Loss: 0.178185; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2326 0.2181 0.2100 0.2048 0.1958 0.1867 0.1790 0.1716 0.1661 0.1618 0.1582 0.1553 0.1539 0.1528 0.1523 0.1517 

[TRAIN] Epoch[2](213/1500); Loss: 0.097558; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1275 0.1240 0.1119 0.1084 0.0966 0.0945 0.0919 0.0912 0.0894 0.0893 0.0883 0.0884 0.0893 0.0896 0.0896 0.0911 

[TRAIN] Epoch[2](214/1500); Loss: 0.138328; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1767 0.1674 0.1569 0.1547 0.1465 0.1403 0.1351 0.1316 0.1289 0.1268 0.1263 0.1257 0.1251 0.1242 0.1237 0.1235 

[TRAIN] Epoch[2](215/1500); Loss: 0.105033; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1408 0.1249 0.1148 0.1100 0.1034 0.1022 0.0997 0.0983 0.0976 0.0975 0.0979 0.0974 0.0983 0.0994 0.0992 0.0991 

[TRAIN] Epoch[2](216/1500); Loss: 0.089964; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2165 0.1783 0.1411 0.1112 0.0845 0.0668 0.0634 0.0647 0.0657 0.0645 0.0618 0.0624 0.0671 0.0629 0.0636 0.0649 

[TRAIN] Epoch[2](217/1500); Loss: 0.060909; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1842 0.1291 0.0942 0.0724 0.0482 0.0461 0.0460 0.0386 0.0392 0.0365 0.0370 0.0385 0.0383 0.0393 0.0428 0.0440 

[TRAIN] Epoch[2](218/1500); Loss: 0.097268; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1413 0.1301 0.1029 0.1022 0.0948 0.0905 0.0893 0.0866 0.0875 0.0869 0.0882 0.0884 0.0895 0.0912 0.0927 0.0942 

[TRAIN] Epoch[2](219/1500); Loss: 0.090476; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1563 0.1293 0.1049 0.0948 0.0851 0.0810 0.0793 0.0781 0.0797 0.0790 0.0790 0.0790 0.0785 0.0796 0.0809 0.0829 

[TRAIN] Epoch[2](220/1500); Loss: 0.098458; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1085 0.1053 0.1008 0.1023 0.1004 0.0993 0.0983 0.0965 0.0986 0.0963 0.0949 0.0946 0.0944 0.0941 0.0947 0.0963 

[TRAIN] Epoch[2](221/1500); Loss: 0.098795; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1254 0.1163 0.1084 0.1024 0.0966 0.0938 0.0936 0.0935 0.0922 0.0923 0.0928 0.0931 0.0937 0.0948 0.0953 0.0965 

[TRAIN] Epoch[2](222/1500); Loss: 0.085014; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1900 0.1298 0.0830 0.0721 0.0772 0.0736 0.0699 0.0672 0.0681 0.0694 0.0715 0.0722 0.0741 0.0788 0.0809 0.0824 

[TRAIN] Epoch[2](223/1500); Loss: 0.167466; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1859 0.1799 0.1736 0.1708 0.1684 0.1670 0.1658 0.1642 0.1637 0.1630 0.1632 0.1629 0.1637 0.1627 0.1625 0.1622 

[TRAIN] Epoch[2](224/1500); Loss: 0.171852; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2088 0.1910 0.1812 0.1786 0.1740 0.1713 0.1678 0.1675 0.1653 0.1643 0.1634 0.1632 0.1624 0.1640 0.1633 0.1636 

[TRAIN] Epoch[2](225/1500); Loss: 0.080713; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1041 0.0947 0.0891 0.0848 0.0808 0.0786 0.0773 0.0773 0.0760 0.0754 0.0752 0.0753 0.0752 0.0755 0.0759 0.0764 

[TRAIN] Epoch[2](226/1500); Loss: 0.077912; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0981 0.0891 0.0811 0.0864 0.0852 0.0817 0.0731 0.0738 0.0719 0.0695 0.0703 0.0702 0.0717 0.0732 0.0740 0.0774 

[TRAIN] Epoch[2](227/1500); Loss: 0.074593; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2892 0.2201 0.1469 0.0857 0.0282 0.0367 0.0494 0.0444 0.0314 0.0355 0.0369 0.0358 0.0362 0.0349 0.0419 0.0401 

[TRAIN] Epoch[2](228/1500); Loss: 0.087936; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.0990 0.0958 0.0957 0.0995 0.0978 0.0907 0.0871 0.0852 0.0829 0.0822 0.0816 0.0811 0.0812 0.0818 0.0830 0.0825 

[TRAIN] Epoch[2](229/1500); Loss: 0.156639; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2125 0.2012 0.1894 0.1791 0.1683 0.1605 0.1552 0.1515 0.1448 0.1430 0.1384 0.1368 0.1335 0.1325 0.1308 0.1287 

[TRAIN] Epoch[2](230/1500); Loss: 0.080980; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2533 0.1976 0.1466 0.1043 0.0704 0.0487 0.0474 0.0468 0.0461 0.0465 0.0459 0.0470 0.0467 0.0488 0.0493 0.0503 

[TRAIN] Epoch[2](231/1500); Loss: 0.091688; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1185 0.1102 0.1078 0.1072 0.1041 0.0956 0.0930 0.0905 0.0851 0.0845 0.0818 0.0797 0.0781 0.0775 0.0771 0.0763 

[TRAIN] Epoch[2](232/1500); Loss: 0.094406; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2694 0.2238 0.1781 0.1411 0.1056 0.0725 0.0467 0.0580 0.0578 0.0539 0.0495 0.0488 0.0503 0.0500 0.0528 0.0524 

[TRAIN] Epoch[2](233/1500); Loss: 0.202062; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2320 0.2278 0.2279 0.2298 0.2239 0.2158 0.2085 0.2053 0.1969 0.1948 0.1882 0.1853 0.1785 0.1765 0.1718 0.1699 

[TRAIN] Epoch[2](234/1500); Loss: 0.158491; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1809 0.1742 0.1727 0.1717 0.1673 0.1629 0.1597 0.1571 0.1541 0.1526 0.1508 0.1489 0.1476 0.1460 0.1451 0.1441 

[TRAIN] Epoch[2](235/1500); Loss: 0.088485; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1033 0.0994 0.0969 0.0971 0.0912 0.0885 0.0839 0.0830 0.0833 0.0828 0.0844 0.0846 0.0843 0.0840 0.0844 0.0846 

[TRAIN] Epoch[2](236/1500); Loss: 0.110328; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1526 0.1518 0.1472 0.1448 0.1281 0.1255 0.1101 0.1074 0.0959 0.0940 0.0869 0.0864 0.0834 0.0836 0.0839 0.0837 

[TRAIN] Epoch[2](237/1500); Loss: 0.125823; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1833 0.1580 0.1448 0.1396 0.1320 0.1291 0.1238 0.1222 0.1172 0.1150 0.1127 0.1098 0.1079 0.1060 0.1070 0.1048 

[TRAIN] Epoch[2](238/1500); Loss: 0.291147; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.4107 0.4006 0.3941 0.3870 0.3570 0.3513 0.3149 0.3112 0.2764 0.2721 0.2371 0.2327 0.1992 0.1935 0.1631 0.1573 

[TRAIN] Epoch[2](239/1500); Loss: 0.093145; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.2234 0.1870 0.1528 0.1223 0.0953 0.0760 0.0652 0.0628 0.0620 0.0640 0.0612 0.0617 0.0630 0.0648 0.0636 0.0652 

[TRAIN] Epoch[2](240/1500); Loss: 0.176586; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2447 0.2398 0.2358 0.2252 0.2096 0.2042 0.1843 0.1798 0.1640 0.1585 0.1456 0.1393 0.1310 0.1246 0.1210 0.1178 

[TRAIN] Epoch[2](241/1500); Loss: 0.084770; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1558 0.1318 0.1097 0.0934 0.0808 0.0764 0.0726 0.0711 0.0715 0.0700 0.0700 0.0706 0.0710 0.0695 0.0707 0.0714 

[TRAIN] Epoch[2](242/1500); Loss: 0.154777; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1863 0.1790 0.1711 0.1676 0.1589 0.1576 0.1511 0.1486 0.1469 0.1457 0.1447 0.1439 0.1443 0.1431 0.1435 0.1442 

[TRAIN] Epoch[2](243/1500); Loss: 0.108550; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1687 0.1547 0.1417 0.1290 0.1161 0.1086 0.1010 0.0979 0.0945 0.0920 0.0902 0.0887 0.0880 0.0879 0.0886 0.0895 

[TRAIN] Epoch[2](244/1500); Loss: 0.159294; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2037 0.1902 0.1789 0.1712 0.1636 0.1630 0.1563 0.1549 0.1513 0.1492 0.1457 0.1441 0.1440 0.1439 0.1440 0.1446 

[TRAIN] Epoch[2](245/1500); Loss: 0.171726; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2336 0.2112 0.1932 0.1833 0.1742 0.1670 0.1663 0.1645 0.1611 0.1596 0.1579 0.1562 0.1551 0.1549 0.1553 0.1542 

[TRAIN] Epoch[2](246/1500); Loss: 0.104100; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1441 0.1264 0.1149 0.1078 0.1025 0.0999 0.1003 0.0983 0.0961 0.0954 0.0967 0.0961 0.0954 0.0962 0.0979 0.0976 

[TRAIN] Epoch[2](247/1500); Loss: 0.122338; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1579 0.1464 0.1385 0.1322 0.1260 0.1221 0.1182 0.1161 0.1147 0.1131 0.1125 0.1120 0.1117 0.1120 0.1120 0.1119 

[TRAIN] Epoch[2](248/1500); Loss: 0.115116; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2263 0.1962 0.1677 0.1422 0.1206 0.1054 0.0968 0.0914 0.0873 0.0856 0.0851 0.0859 0.0865 0.0871 0.0881 0.0896 

[TRAIN] Epoch[2](249/1500); Loss: 0.076844; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0992 0.0956 0.0918 0.0872 0.0784 0.0766 0.0730 0.0716 0.0710 0.0705 0.0687 0.0680 0.0685 0.0693 0.0695 0.0707 

[TRAIN] Epoch[2](250/1500); Loss: 0.137444; Backpropagation: 0.0917 sec; Batch: 0.4249 sec
0.1842 0.1656 0.1506 0.1381 0.1321 0.1301 0.1300 0.1298 0.1298 0.1292 0.1295 0.1291 0.1297 0.1297 0.1307 0.1308 

[TRAIN] Epoch[2](251/1500); Loss: 0.077618; Backpropagation: 0.0924 sec; Batch: 0.4245 sec
0.3071 0.2422 0.1762 0.1184 0.0612 0.0189 0.0505 0.0432 0.0276 0.0285 0.0239 0.0281 0.0273 0.0292 0.0290 0.0307 

[TRAIN] Epoch[2](252/1500); Loss: 0.082140; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1087 0.1008 0.0927 0.0876 0.0829 0.0811 0.0813 0.0771 0.0738 0.0733 0.0740 0.0749 0.0750 0.0759 0.0772 0.0779 

[TRAIN] Epoch[2](253/1500); Loss: 0.064458; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0980 0.0958 0.0854 0.0849 0.0739 0.0675 0.0570 0.0544 0.0529 0.0518 0.0517 0.0513 0.0509 0.0508 0.0521 0.0529 

[TRAIN] Epoch[2](254/1500); Loss: 0.043809; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1047 0.0640 0.0435 0.0465 0.0468 0.0393 0.0365 0.0386 0.0354 0.0337 0.0335 0.0351 0.0348 0.0349 0.0359 0.0378 

[TRAIN] Epoch[2](255/1500); Loss: 0.145827; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1776 0.1730 0.1662 0.1578 0.1508 0.1466 0.1419 0.1383 0.1357 0.1348 0.1346 0.1352 0.1351 0.1347 0.1347 0.1360 

[TRAIN] Epoch[2](256/1500); Loss: 0.076601; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1078 0.1060 0.0965 0.0948 0.0845 0.0795 0.0715 0.0688 0.0660 0.0659 0.0649 0.0648 0.0634 0.0636 0.0636 0.0638 

[TRAIN] Epoch[2](257/1500); Loss: 0.128318; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2173 0.1917 0.1716 0.1561 0.1394 0.1245 0.1133 0.1121 0.1118 0.1067 0.1044 0.1027 0.1021 0.0999 0.0999 0.0995 

[TRAIN] Epoch[2](258/1500); Loss: 0.081638; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1251 0.1151 0.1083 0.0994 0.0906 0.0846 0.0786 0.0730 0.0693 0.0666 0.0664 0.0659 0.0663 0.0666 0.0654 0.0651 

[TRAIN] Epoch[2](259/1500); Loss: 0.084761; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1403 0.1262 0.1134 0.1000 0.0880 0.0820 0.0770 0.0740 0.0723 0.0707 0.0697 0.0694 0.0683 0.0682 0.0676 0.0690 

[TRAIN] Epoch[2](260/1500); Loss: 0.097686; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1265 0.1194 0.1143 0.1083 0.1028 0.0983 0.0943 0.0922 0.0909 0.0900 0.0892 0.0882 0.0876 0.0873 0.0869 0.0868 

[TRAIN] Epoch[2](261/1500); Loss: 0.080752; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1383 0.1182 0.1002 0.0867 0.0764 0.0707 0.0699 0.0693 0.0684 0.0690 0.0697 0.0701 0.0700 0.0705 0.0718 0.0728 

[TRAIN] Epoch[2](262/1500); Loss: 0.127266; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2290 0.2124 0.1990 0.1780 0.1547 0.1390 0.1253 0.1138 0.1011 0.0943 0.0870 0.0832 0.0804 0.0800 0.0799 0.0791 

[TRAIN] Epoch[2](263/1500); Loss: 0.151197; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2091 0.2018 0.1977 0.1879 0.1756 0.1672 0.1580 0.1493 0.1399 0.1323 0.1247 0.1181 0.1139 0.1130 0.1149 0.1157 

[TRAIN] Epoch[2](264/1500); Loss: 0.116986; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1951 0.1645 0.1408 0.1289 0.1179 0.1109 0.1049 0.1022 0.1013 0.1004 0.1001 0.1001 0.1005 0.1014 0.1012 0.1016 

[TRAIN] Epoch[2](265/1500); Loss: 0.133166; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2024 0.1961 0.1919 0.1809 0.1641 0.1529 0.1355 0.1247 0.1093 0.1001 0.0936 0.0918 0.0931 0.0973 0.1007 0.0962 

[TRAIN] Epoch[2](266/1500); Loss: 0.187948; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.3608 0.3430 0.3304 0.3021 0.2624 0.2327 0.1898 0.1565 0.1216 0.0993 0.0903 0.0961 0.1121 0.1119 0.1015 0.0965 

[TRAIN] Epoch[2](267/1500); Loss: 0.115136; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1516 0.1393 0.1288 0.1236 0.1175 0.1136 0.1112 0.1094 0.1074 0.1063 0.1048 0.1058 0.1054 0.1051 0.1053 0.1070 

[TRAIN] Epoch[2](268/1500); Loss: 0.095958; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1290 0.1192 0.1103 0.1041 0.0990 0.0962 0.0936 0.0901 0.0883 0.0867 0.0858 0.0853 0.0860 0.0867 0.0874 0.0876 

[TRAIN] Epoch[2](269/1500); Loss: 0.075106; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2006 0.1454 0.1018 0.0786 0.0651 0.0631 0.0552 0.0549 0.0552 0.0538 0.0540 0.0525 0.0580 0.0543 0.0544 0.0548 

[TRAIN] Epoch[2](270/1500); Loss: 0.081573; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1501 0.1216 0.0982 0.0820 0.0774 0.0756 0.0732 0.0701 0.0697 0.0692 0.0695 0.0688 0.0693 0.0699 0.0700 0.0706 

[TRAIN] Epoch[2](271/1500); Loss: 0.117683; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1419 0.1334 0.1314 0.1276 0.1159 0.1099 0.1089 0.1089 0.1070 0.1073 0.1102 0.1112 0.1116 0.1158 0.1197 0.1221 

[TRAIN] Epoch[2](272/1500); Loss: 0.111357; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1883 0.1604 0.1394 0.1235 0.1098 0.1013 0.0984 0.0976 0.0965 0.0952 0.0941 0.0942 0.0965 0.0955 0.0955 0.0955 

[TRAIN] Epoch[2](273/1500); Loss: 0.067221; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.0788 0.0729 0.0690 0.0674 0.0655 0.0651 0.0638 0.0644 0.0644 0.0653 0.0648 0.0656 0.0662 0.0665 0.0679 0.0678 

[TRAIN] Epoch[2](274/1500); Loss: 0.095781; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1914 0.1707 0.1476 0.1241 0.1026 0.0863 0.0731 0.0717 0.0704 0.0687 0.0684 0.0696 0.0691 0.0732 0.0727 0.0728 

[TRAIN] Epoch[2](275/1500); Loss: 0.072380; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0953 0.0896 0.0850 0.0793 0.0729 0.0704 0.0691 0.0669 0.0660 0.0654 0.0652 0.0649 0.0662 0.0668 0.0669 0.0683 

[TRAIN] Epoch[2](276/1500); Loss: 0.137619; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1632 0.1542 0.1491 0.1407 0.1360 0.1348 0.1333 0.1323 0.1313 0.1318 0.1323 0.1318 0.1324 0.1323 0.1330 0.1333 

[TRAIN] Epoch[2](277/1500); Loss: 0.136471; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1960 0.1821 0.1697 0.1550 0.1417 0.1331 0.1283 0.1242 0.1215 0.1199 0.1191 0.1188 0.1181 0.1183 0.1186 0.1192 

[TRAIN] Epoch[2](278/1500); Loss: 0.141450; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1816 0.1672 0.1562 0.1471 0.1405 0.1365 0.1350 0.1339 0.1329 0.1324 0.1326 0.1328 0.1329 0.1333 0.1337 0.1347 

[TRAIN] Epoch[2](279/1500); Loss: 0.121388; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1747 0.1657 0.1575 0.1415 0.1253 0.1148 0.1082 0.1055 0.1061 0.1059 0.1058 0.1048 0.1061 0.1062 0.1068 0.1071 

[TRAIN] Epoch[2](280/1500); Loss: 0.134145; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1891 0.1731 0.1616 0.1511 0.1421 0.1349 0.1289 0.1246 0.1217 0.1198 0.1184 0.1175 0.1162 0.1158 0.1153 0.1163 

[TRAIN] Epoch[2](281/1500); Loss: 0.109911; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1421 0.1343 0.1279 0.1188 0.1117 0.1085 0.1054 0.1030 0.1015 0.1011 0.1005 0.1004 0.1005 0.1008 0.1012 0.1008 

[TRAIN] Epoch[2](282/1500); Loss: 0.075874; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0896 0.0865 0.0828 0.0810 0.0776 0.0764 0.0751 0.0738 0.0723 0.0717 0.0709 0.0706 0.0705 0.0714 0.0716 0.0719 

[TRAIN] Epoch[2](283/1500); Loss: 0.051865; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0825 0.0582 0.0541 0.0551 0.0505 0.0501 0.0495 0.0471 0.0467 0.0486 0.0480 0.0470 0.0471 0.0493 0.0481 0.0480 

[TRAIN] Epoch[2](284/1500); Loss: 0.117961; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1678 0.1549 0.1426 0.1317 0.1226 0.1160 0.1109 0.1081 0.1064 0.1051 0.1041 0.1036 0.1035 0.1035 0.1031 0.1035 

[TRAIN] Epoch[2](285/1500); Loss: 0.092186; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1292 0.1127 0.1009 0.0933 0.0895 0.0884 0.0873 0.0862 0.0854 0.0849 0.0855 0.0856 0.0850 0.0864 0.0877 0.0871 

[TRAIN] Epoch[2](286/1500); Loss: 0.079398; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2279 0.1855 0.1474 0.1159 0.0879 0.0651 0.0513 0.0455 0.0424 0.0427 0.0448 0.0429 0.0424 0.0427 0.0437 0.0424 

[TRAIN] Epoch[2](287/1500); Loss: 0.050419; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.0830 0.0641 0.0557 0.0574 0.0522 0.0468 0.0464 0.0459 0.0452 0.0446 0.0450 0.0442 0.0446 0.0444 0.0437 0.0438 

[TRAIN] Epoch[2](288/1500); Loss: 0.103566; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1677 0.1588 0.1521 0.1350 0.1178 0.1057 0.0950 0.0866 0.0814 0.0812 0.0823 0.0805 0.0793 0.0780 0.0776 0.0780 

[TRAIN] Epoch[2](289/1500); Loss: 0.179464; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2104 0.2040 0.2003 0.1923 0.1857 0.1831 0.1792 0.1732 0.1718 0.1710 0.1685 0.1678 0.1665 0.1663 0.1656 0.1655 

[TRAIN] Epoch[2](290/1500); Loss: 0.202799; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2803 0.2667 0.2606 0.2432 0.2242 0.2089 0.1947 0.1820 0.1759 0.1740 0.1740 0.1732 0.1735 0.1724 0.1711 0.1701 

[TRAIN] Epoch[2](291/1500); Loss: 0.075176; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0904 0.0855 0.0830 0.0776 0.0746 0.0733 0.0727 0.0718 0.0709 0.0716 0.0721 0.0715 0.0711 0.0724 0.0721 0.0722 

[TRAIN] Epoch[2](292/1500); Loss: 0.106529; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1707 0.1518 0.1353 0.1212 0.1107 0.1053 0.1003 0.0938 0.0914 0.0905 0.0895 0.0890 0.0887 0.0890 0.0883 0.0889 

[TRAIN] Epoch[2](293/1500); Loss: 0.132265; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.2257 0.2165 0.2111 0.1885 0.1649 0.1464 0.1288 0.1137 0.1015 0.0936 0.0905 0.0902 0.0889 0.0868 0.0848 0.0842 

[TRAIN] Epoch[2](294/1500); Loss: 0.091030; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1237 0.1152 0.1065 0.0972 0.0907 0.0882 0.0848 0.0831 0.0832 0.0829 0.0824 0.0827 0.0835 0.0839 0.0838 0.0848 

[TRAIN] Epoch[2](295/1500); Loss: 0.075695; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.3041 0.2402 0.1763 0.1187 0.0615 0.0164 0.0498 0.0381 0.0201 0.0340 0.0194 0.0270 0.0209 0.0352 0.0231 0.0264 

[TRAIN] Epoch[2](296/1500); Loss: 0.112363; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1566 0.1474 0.1362 0.1294 0.1166 0.1090 0.1071 0.1056 0.1006 0.1009 0.0996 0.0981 0.0969 0.0979 0.0983 0.0975 

[TRAIN] Epoch[2](297/1500); Loss: 0.167075; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1934 0.1858 0.1773 0.1763 0.1698 0.1662 0.1642 0.1641 0.1613 0.1600 0.1602 0.1604 0.1581 0.1585 0.1587 0.1591 

[TRAIN] Epoch[2](298/1500); Loss: 0.069986; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1634 0.1472 0.1393 0.1166 0.0906 0.0723 0.0576 0.0477 0.0419 0.0390 0.0373 0.0348 0.0337 0.0341 0.0325 0.0318 

[TRAIN] Epoch[2](299/1500); Loss: 0.107988; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1327 0.1303 0.1197 0.1142 0.1087 0.1051 0.1006 0.0997 0.1005 0.1004 0.1001 0.1013 0.1024 0.1028 0.1038 0.1056 

[TRAIN] Epoch[2](300/1500); Loss: 0.065834; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0899 0.0856 0.0781 0.0785 0.0699 0.0680 0.0631 0.0610 0.0590 0.0590 0.0568 0.0566 0.0560 0.0571 0.0567 0.0581 

[TRAIN] Epoch[2](301/1500); Loss: 0.187608; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3874 0.3550 0.3391 0.3062 0.2659 0.2353 0.2040 0.1670 0.1293 0.1059 0.0862 0.0831 0.0960 0.0840 0.0788 0.0787 

[TRAIN] Epoch[2](302/1500); Loss: 0.150516; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2725 0.2440 0.2206 0.1946 0.1745 0.1676 0.1485 0.1355 0.1275 0.1188 0.1070 0.1042 0.1004 0.0964 0.0977 0.0984 

[TRAIN] Epoch[2](303/1500); Loss: 0.098331; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1658 0.1468 0.1317 0.1166 0.1053 0.0992 0.0902 0.0874 0.0838 0.0817 0.0791 0.0798 0.0763 0.0757 0.0762 0.0777 

[TRAIN] Epoch[2](304/1500); Loss: 0.066628; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1064 0.0939 0.0780 0.0742 0.0677 0.0639 0.0605 0.0579 0.0576 0.0572 0.0573 0.0578 0.0586 0.0581 0.0583 0.0585 

[TRAIN] Epoch[2](305/1500); Loss: 0.140856; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2341 0.2090 0.1848 0.1638 0.1471 0.1408 0.1296 0.1247 0.1206 0.1175 0.1144 0.1141 0.1137 0.1133 0.1131 0.1132 

[TRAIN] Epoch[2](306/1500); Loss: 0.033345; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0557 0.0504 0.0318 0.0340 0.0311 0.0258 0.0302 0.0300 0.0272 0.0270 0.0285 0.0294 0.0301 0.0323 0.0347 0.0352 

[TRAIN] Epoch[2](307/1500); Loss: 0.092834; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1718 0.1439 0.1213 0.1036 0.0915 0.0870 0.0810 0.0785 0.0761 0.0759 0.0767 0.0760 0.0742 0.0756 0.0762 0.0760 

[TRAIN] Epoch[2](308/1500); Loss: 0.074310; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1062 0.0959 0.0852 0.0814 0.0761 0.0720 0.0718 0.0707 0.0686 0.0666 0.0656 0.0660 0.0654 0.0649 0.0662 0.0665 

[TRAIN] Epoch[2](309/1500); Loss: 0.109347; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1562 0.1474 0.1332 0.1274 0.1172 0.1124 0.1039 0.0998 0.0972 0.0947 0.0951 0.0942 0.0922 0.0919 0.0930 0.0937 

[TRAIN] Epoch[2](310/1500); Loss: 0.122036; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1783 0.1651 0.1497 0.1399 0.1274 0.1190 0.1139 0.1112 0.1081 0.1058 0.1062 0.1062 0.1063 0.1053 0.1051 0.1051 

[TRAIN] Epoch[2](311/1500); Loss: 0.117710; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1675 0.1535 0.1434 0.1328 0.1239 0.1183 0.1131 0.1087 0.1044 0.1025 0.1036 0.1035 0.1023 0.1016 0.1021 0.1025 

[TRAIN] Epoch[2](312/1500); Loss: 0.105998; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1918 0.1658 0.1451 0.1277 0.1146 0.1054 0.0981 0.0927 0.0877 0.0837 0.0816 0.0803 0.0806 0.0801 0.0804 0.0805 

[TRAIN] Epoch[2](313/1500); Loss: 0.062584; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0946 0.0822 0.0773 0.0738 0.0676 0.0624 0.0590 0.0520 0.0510 0.0540 0.0540 0.0533 0.0526 0.0552 0.0551 0.0572 

[TRAIN] Epoch[2](314/1500); Loss: 0.077456; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1376 0.1070 0.0949 0.0851 0.0740 0.0683 0.0710 0.0706 0.0669 0.0646 0.0658 0.0669 0.0671 0.0652 0.0672 0.0672 

[TRAIN] Epoch[2](315/1500); Loss: 0.126761; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1583 0.1463 0.1404 0.1380 0.1333 0.1291 0.1279 0.1256 0.1221 0.1196 0.1176 0.1165 0.1144 0.1141 0.1132 0.1118 

[TRAIN] Epoch[2](316/1500); Loss: 0.115093; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2367 0.2032 0.1743 0.1461 0.1223 0.1042 0.0922 0.0864 0.0847 0.0841 0.0840 0.0839 0.0833 0.0855 0.0856 0.0850 

[TRAIN] Epoch[2](317/1500); Loss: 0.069792; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1005 0.0866 0.0810 0.0711 0.0672 0.0659 0.0649 0.0629 0.0613 0.0618 0.0626 0.0624 0.0648 0.0658 0.0670 0.0707 

[TRAIN] Epoch[2](318/1500); Loss: 0.160440; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2398 0.2271 0.2183 0.2032 0.1842 0.1696 0.1557 0.1440 0.1349 0.1300 0.1284 0.1277 0.1273 0.1261 0.1253 0.1253 

[TRAIN] Epoch[2](319/1500); Loss: 0.117807; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1577 0.1500 0.1383 0.1305 0.1218 0.1149 0.1107 0.1081 0.1060 0.1051 0.1055 0.1074 0.1074 0.1065 0.1066 0.1083 

[TRAIN] Epoch[2](320/1500); Loss: 0.086756; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1309 0.1143 0.1032 0.1016 0.0918 0.0818 0.0765 0.0754 0.0722 0.0718 0.0731 0.0737 0.0759 0.0785 0.0823 0.0853 

[TRAIN] Epoch[2](321/1500); Loss: 0.064022; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0933 0.0831 0.0722 0.0648 0.0632 0.0613 0.0581 0.0568 0.0570 0.0580 0.0570 0.0576 0.0585 0.0610 0.0606 0.0619 

[TRAIN] Epoch[2](322/1500); Loss: 0.126695; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1574 0.1455 0.1369 0.1304 0.1264 0.1242 0.1220 0.1205 0.1198 0.1190 0.1188 0.1205 0.1216 0.1213 0.1209 0.1221 

[TRAIN] Epoch[2](323/1500); Loss: 0.084693; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1150 0.1073 0.0997 0.0943 0.0908 0.0877 0.0842 0.0806 0.0776 0.0763 0.0746 0.0729 0.0724 0.0730 0.0742 0.0742 

[TRAIN] Epoch[2](324/1500); Loss: 0.068676; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1346 0.0991 0.0766 0.0694 0.0614 0.0583 0.0625 0.0618 0.0569 0.0562 0.0567 0.0617 0.0585 0.0589 0.0622 0.0640 

[TRAIN] Epoch[2](325/1500); Loss: 0.084368; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1720 0.1475 0.1222 0.1026 0.0862 0.0772 0.0735 0.0698 0.0651 0.0602 0.0614 0.0607 0.0626 0.0626 0.0633 0.0631 

[TRAIN] Epoch[2](326/1500); Loss: 0.084576; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1154 0.1030 0.0915 0.0886 0.0854 0.0870 0.0868 0.0819 0.0763 0.0746 0.0763 0.0788 0.0761 0.0764 0.0767 0.0783 

[TRAIN] Epoch[2](327/1500); Loss: 0.112370; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1453 0.1361 0.1249 0.1194 0.1140 0.1122 0.1119 0.1109 0.1074 0.1052 0.1024 0.1010 0.1011 0.1009 0.1022 0.1031 

[TRAIN] Epoch[2](328/1500); Loss: 0.121319; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1753 0.1641 0.1409 0.1393 0.1290 0.1222 0.1145 0.1069 0.1060 0.1058 0.1060 0.1034 0.1034 0.1037 0.1102 0.1102 

[TRAIN] Epoch[2](329/1500); Loss: 0.070619; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1180 0.1000 0.0872 0.0793 0.0709 0.0658 0.0660 0.0646 0.0607 0.0590 0.0594 0.0596 0.0584 0.0591 0.0600 0.0618 

[TRAIN] Epoch[2](330/1500); Loss: 0.068527; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.0944 0.0827 0.0740 0.0711 0.0717 0.0770 0.0812 0.0768 0.0707 0.0632 0.0575 0.0548 0.0542 0.0549 0.0555 0.0566 

[TRAIN] Epoch[2](331/1500); Loss: 0.085413; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1867 0.1498 0.1181 0.0953 0.0787 0.0688 0.0671 0.0708 0.0691 0.0654 0.0640 0.0648 0.0647 0.0657 0.0671 0.0705 

[TRAIN] Epoch[2](332/1500); Loss: 0.098990; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1210 0.1159 0.1070 0.1001 0.0982 0.0966 0.0961 0.0944 0.0944 0.0945 0.0942 0.0940 0.0941 0.0939 0.0945 0.0950 

[TRAIN] Epoch[2](333/1500); Loss: 0.092954; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1555 0.1258 0.1041 0.0896 0.0832 0.0842 0.0851 0.0862 0.0820 0.0812 0.0823 0.0853 0.0840 0.0847 0.0858 0.0883 

[TRAIN] Epoch[2](334/1500); Loss: 0.082033; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0957 0.0937 0.0901 0.0888 0.0882 0.0890 0.0852 0.0801 0.0774 0.0752 0.0735 0.0738 0.0750 0.0750 0.0751 0.0768 

[TRAIN] Epoch[2](335/1500); Loss: 0.067663; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2231 0.1649 0.1189 0.0873 0.0560 0.0408 0.0432 0.0387 0.0413 0.0372 0.0360 0.0364 0.0405 0.0383 0.0387 0.0412 

[TRAIN] Epoch[2](336/1500); Loss: 0.087085; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1329 0.1177 0.1053 0.0907 0.0844 0.0843 0.0815 0.0780 0.0759 0.0756 0.0762 0.0767 0.0775 0.0777 0.0791 0.0799 

[TRAIN] Epoch[2](337/1500); Loss: 0.070882; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1618 0.1165 0.0870 0.0763 0.0698 0.0628 0.0571 0.0565 0.0547 0.0534 0.0545 0.0548 0.0558 0.0562 0.0578 0.0590 

[TRAIN] Epoch[2](338/1500); Loss: 0.126507; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1379 0.1308 0.1322 0.1359 0.1315 0.1242 0.1224 0.1252 0.1237 0.1223 0.1219 0.1221 0.1226 0.1227 0.1238 0.1252 

[TRAIN] Epoch[2](339/1500); Loss: 0.105406; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1931 0.1599 0.1352 0.1220 0.1128 0.1054 0.0976 0.0912 0.0873 0.0856 0.0825 0.0806 0.0820 0.0830 0.0834 0.0849 

[TRAIN] Epoch[2](340/1500); Loss: 0.127637; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1940 0.1693 0.1540 0.1456 0.1401 0.1356 0.1264 0.1226 0.1217 0.1155 0.1068 0.1029 0.1020 0.1010 0.1019 0.1025 

[TRAIN] Epoch[2](341/1500); Loss: 0.120671; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2305 0.1894 0.1560 0.1335 0.1183 0.1103 0.1120 0.1145 0.1069 0.0970 0.0925 0.0926 0.0912 0.0928 0.0955 0.0976 

[TRAIN] Epoch[2](342/1500); Loss: 0.113141; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1866 0.1759 0.1689 0.1519 0.1274 0.1105 0.0952 0.0889 0.0914 0.0872 0.0845 0.0859 0.0866 0.0897 0.0887 0.0910 

[TRAIN] Epoch[2](343/1500); Loss: 0.081189; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1027 0.0924 0.1005 0.1070 0.1012 0.0836 0.0759 0.0739 0.0693 0.0693 0.0692 0.0699 0.0694 0.0707 0.0707 0.0735 

[TRAIN] Epoch[2](344/1500); Loss: 0.090756; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1453 0.1303 0.1132 0.1041 0.0954 0.0885 0.0823 0.0784 0.0754 0.0757 0.0747 0.0743 0.0771 0.0794 0.0784 0.0796 

[TRAIN] Epoch[2](345/1500); Loss: 0.137094; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1556 0.1469 0.1424 0.1391 0.1366 0.1350 0.1334 0.1330 0.1325 0.1312 0.1311 0.1321 0.1344 0.1356 0.1364 0.1381 

[TRAIN] Epoch[2](346/1500); Loss: 0.102382; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1548 0.1342 0.1255 0.1238 0.1170 0.1049 0.0984 0.0936 0.0895 0.0869 0.0857 0.0840 0.0849 0.0847 0.0849 0.0852 

[TRAIN] Epoch[2](347/1500); Loss: 0.084048; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.3127 0.2502 0.1844 0.1296 0.0735 0.0274 0.0391 0.0469 0.0352 0.0288 0.0327 0.0298 0.0354 0.0386 0.0397 0.0410 

[TRAIN] Epoch[2](348/1500); Loss: 0.121847; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2003 0.1914 0.1812 0.1644 0.1401 0.1222 0.1053 0.0974 0.0997 0.0962 0.0933 0.0913 0.0915 0.0926 0.0913 0.0913 

[TRAIN] Epoch[2](349/1500); Loss: 0.071119; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0935 0.0914 0.0879 0.0842 0.0742 0.0664 0.0650 0.0638 0.0612 0.0618 0.0625 0.0638 0.0641 0.0643 0.0670 0.0667 

[TRAIN] Epoch[2](350/1500); Loss: 0.077337; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1239 0.1109 0.0986 0.0884 0.0800 0.0749 0.0695 0.0667 0.0658 0.0647 0.0640 0.0641 0.0669 0.0657 0.0662 0.0672 

[TRAIN] Epoch[2](351/1500); Loss: 0.094370; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2118 0.1752 0.1437 0.1208 0.1005 0.0833 0.0715 0.0696 0.0691 0.0687 0.0679 0.0648 0.0643 0.0657 0.0668 0.0663 

[TRAIN] Epoch[2](352/1500); Loss: 0.111939; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2337 0.1934 0.1561 0.1284 0.1152 0.1085 0.0963 0.0913 0.0885 0.0833 0.0819 0.0814 0.0823 0.0865 0.0825 0.0817 

[TRAIN] Epoch[2](353/1500); Loss: 0.104242; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1681 0.1505 0.1309 0.1181 0.1030 0.0959 0.0909 0.0878 0.0874 0.0883 0.0902 0.0896 0.0898 0.0905 0.0923 0.0943 

[TRAIN] Epoch[2](354/1500); Loss: 0.094937; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1297 0.1298 0.1173 0.1109 0.0981 0.0927 0.0892 0.0876 0.0850 0.0824 0.0819 0.0818 0.0825 0.0824 0.0827 0.0850 

[TRAIN] Epoch[2](355/1500); Loss: 0.076064; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0917 0.0906 0.0814 0.0777 0.0750 0.0740 0.0735 0.0715 0.0708 0.0710 0.0717 0.0726 0.0726 0.0731 0.0743 0.0756 

[TRAIN] Epoch[2](356/1500); Loss: 0.076067; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.3026 0.2358 0.1639 0.1057 0.0484 0.0225 0.0525 0.0415 0.0335 0.0264 0.0287 0.0258 0.0260 0.0380 0.0324 0.0333 

[TRAIN] Epoch[2](357/1500); Loss: 0.076021; Backpropagation: 0.0919 sec; Batch: 0.4284 sec
0.2178 0.1666 0.1320 0.1130 0.0852 0.0548 0.0466 0.0433 0.0380 0.0528 0.0409 0.0425 0.0407 0.0431 0.0540 0.0449 

[TRAIN] Epoch[2](358/1500); Loss: 0.044681; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.0524 0.0494 0.0590 0.0556 0.0477 0.0444 0.0420 0.0406 0.0410 0.0392 0.0396 0.0393 0.0395 0.0412 0.0413 0.0426 

[TRAIN] Epoch[2](359/1500); Loss: 0.062232; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0899 0.0790 0.0861 0.0822 0.0716 0.0579 0.0587 0.0566 0.0521 0.0508 0.0506 0.0520 0.0524 0.0516 0.0523 0.0519 

[TRAIN] Epoch[2](360/1500); Loss: 0.145011; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1881 0.1812 0.1691 0.1577 0.1470 0.1427 0.1389 0.1344 0.1316 0.1321 0.1338 0.1340 0.1326 0.1319 0.1321 0.1329 

[TRAIN] Epoch[2](361/1500); Loss: 0.075775; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0839 0.0754 0.0798 0.0769 0.0685 0.0699 0.0683 0.0691 0.0691 0.0712 0.0736 0.0756 0.0767 0.0832 0.0849 0.0863 

[TRAIN] Epoch[2](362/1500); Loss: 0.138074; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1740 0.1690 0.1576 0.1499 0.1416 0.1395 0.1347 0.1297 0.1262 0.1250 0.1264 0.1261 0.1261 0.1276 0.1271 0.1285 

[TRAIN] Epoch[2](363/1500); Loss: 0.165203; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1652 0.1676 0.1617 0.1607 0.1609 0.1547 0.1559 0.1563 0.1588 0.1580 0.1636 0.1657 0.1718 0.1774 0.1816 0.1833 

[TRAIN] Epoch[2](364/1500); Loss: 0.107750; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1373 0.1251 0.1195 0.1132 0.1074 0.1044 0.1025 0.1026 0.1022 0.1008 0.1004 0.1020 0.1022 0.1004 0.1008 0.1032 

[TRAIN] Epoch[2](365/1500); Loss: 0.086841; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1068 0.1077 0.1083 0.1048 0.0926 0.0837 0.0798 0.0793 0.0781 0.0767 0.0766 0.0778 0.0778 0.0778 0.0804 0.0814 

[TRAIN] Epoch[2](366/1500); Loss: 0.062448; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0902 0.0787 0.0703 0.0643 0.0601 0.0617 0.0580 0.0574 0.0553 0.0556 0.0556 0.0564 0.0579 0.0575 0.0596 0.0607 

[TRAIN] Epoch[2](367/1500); Loss: 0.129306; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1522 0.1491 0.1432 0.1370 0.1323 0.1303 0.1273 0.1249 0.1240 0.1233 0.1213 0.1206 0.1206 0.1207 0.1207 0.1214 

[TRAIN] Epoch[2](368/1500); Loss: 0.102028; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2149 0.1832 0.1478 0.1237 0.0993 0.0824 0.0818 0.0783 0.0747 0.0846 0.0764 0.0751 0.0754 0.0795 0.0781 0.0772 

[TRAIN] Epoch[2](369/1500); Loss: 0.074198; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2778 0.2029 0.1172 0.0608 0.0451 0.0488 0.0400 0.0461 0.0433 0.0409 0.0387 0.0426 0.0510 0.0421 0.0424 0.0476 

[TRAIN] Epoch[2](370/1500); Loss: 0.079056; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1479 0.1299 0.1048 0.0817 0.0651 0.0741 0.0788 0.0665 0.0620 0.0615 0.0665 0.0645 0.0637 0.0640 0.0672 0.0668 

[TRAIN] Epoch[2](371/1500); Loss: 0.069965; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1496 0.1081 0.0769 0.0638 0.0578 0.0566 0.0613 0.0590 0.0566 0.0572 0.0593 0.0607 0.0607 0.0630 0.0639 0.0650 

[TRAIN] Epoch[2](372/1500); Loss: 0.138918; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1873 0.1735 0.1593 0.1501 0.1432 0.1408 0.1374 0.1335 0.1278 0.1252 0.1268 0.1255 0.1223 0.1220 0.1235 0.1246 

[TRAIN] Epoch[2](373/1500); Loss: 0.089711; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0988 0.0957 0.0889 0.0877 0.0897 0.0927 0.0910 0.0881 0.0872 0.0869 0.0878 0.0879 0.0872 0.0876 0.0895 0.0886 

[TRAIN] Epoch[2](374/1500); Loss: 0.093569; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1558 0.1205 0.0996 0.0893 0.0880 0.0878 0.0871 0.0859 0.0841 0.0844 0.0850 0.0848 0.0861 0.0857 0.0864 0.0866 

[TRAIN] Epoch[2](375/1500); Loss: 0.062382; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1302 0.0913 0.0735 0.0624 0.0537 0.0527 0.0533 0.0520 0.0509 0.0524 0.0532 0.0529 0.0536 0.0544 0.0560 0.0556 

[TRAIN] Epoch[2](376/1500); Loss: 0.066598; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.0864 0.0761 0.0765 0.0718 0.0631 0.0634 0.0600 0.0605 0.0602 0.0605 0.0618 0.0623 0.0632 0.0653 0.0666 0.0678 

[TRAIN] Epoch[2](377/1500); Loss: 0.048249; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0912 0.0827 0.0616 0.0469 0.0413 0.0391 0.0400 0.0385 0.0385 0.0374 0.0390 0.0406 0.0424 0.0424 0.0446 0.0456 

[TRAIN] Epoch[2](378/1500); Loss: 0.093818; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1561 0.1345 0.1194 0.1135 0.1054 0.0942 0.0877 0.0854 0.0804 0.0766 0.0748 0.0736 0.0731 0.0744 0.0749 0.0772 

[TRAIN] Epoch[2](379/1500); Loss: 0.091155; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1421 0.1261 0.1127 0.1008 0.0920 0.0861 0.0892 0.0819 0.0792 0.0775 0.0791 0.0783 0.0777 0.0779 0.0786 0.0792 

[TRAIN] Epoch[2](380/1500); Loss: 0.075503; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1004 0.0940 0.0824 0.0791 0.0745 0.0736 0.0768 0.0702 0.0681 0.0677 0.0700 0.0691 0.0692 0.0696 0.0715 0.0719 

[TRAIN] Epoch[2](381/1500); Loss: 0.090961; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1099 0.1050 0.0967 0.0931 0.0902 0.0878 0.0871 0.0866 0.0864 0.0862 0.0868 0.0874 0.0872 0.0874 0.0884 0.0893 

[TRAIN] Epoch[2](382/1500); Loss: 0.052771; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1072 0.0642 0.0557 0.0527 0.0489 0.0477 0.0479 0.0455 0.0441 0.0465 0.0461 0.0460 0.0464 0.0481 0.0489 0.0484 

[TRAIN] Epoch[2](383/1500); Loss: 0.151426; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1863 0.1797 0.1697 0.1652 0.1557 0.1520 0.1496 0.1483 0.1446 0.1433 0.1415 0.1404 0.1384 0.1373 0.1361 0.1347 

[TRAIN] Epoch[2](384/1500); Loss: 0.094629; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1208 0.1064 0.0936 0.0890 0.0863 0.0881 0.0890 0.0883 0.0884 0.0893 0.0901 0.0920 0.0939 0.0967 0.0991 0.1029 

[TRAIN] Epoch[2](385/1500); Loss: 0.087654; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1237 0.1050 0.0985 0.0899 0.0829 0.0851 0.0814 0.0799 0.0786 0.0807 0.0811 0.0816 0.0811 0.0844 0.0844 0.0843 

[TRAIN] Epoch[2](386/1500); Loss: 0.107138; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1354 0.1355 0.1296 0.1263 0.1229 0.1166 0.1077 0.0999 0.0941 0.0897 0.0902 0.0919 0.0941 0.0930 0.0936 0.0936 

[TRAIN] Epoch[2](387/1500); Loss: 0.143454; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1719 0.1655 0.1598 0.1521 0.1460 0.1463 0.1452 0.1393 0.1350 0.1335 0.1331 0.1327 0.1334 0.1339 0.1336 0.1340 

[TRAIN] Epoch[2](388/1500); Loss: 0.069852; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0888 0.0974 0.0951 0.0836 0.0690 0.0702 0.0641 0.0606 0.0603 0.0614 0.0598 0.0604 0.0615 0.0610 0.0615 0.0630 

[TRAIN] Epoch[2](389/1500); Loss: 0.058505; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1652 0.1101 0.0854 0.0702 0.0503 0.0427 0.0409 0.0379 0.0426 0.0401 0.0396 0.0404 0.0420 0.0425 0.0427 0.0435 

[TRAIN] Epoch[2](390/1500); Loss: 0.114812; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1600 0.1542 0.1449 0.1339 0.1162 0.1094 0.1053 0.1017 0.1000 0.1020 0.1003 0.0999 0.1006 0.1023 0.1024 0.1039 

[TRAIN] Epoch[2](391/1500); Loss: 0.123099; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1604 0.1426 0.1294 0.1221 0.1178 0.1201 0.1187 0.1172 0.1176 0.1176 0.1166 0.1164 0.1181 0.1182 0.1179 0.1189 

[TRAIN] Epoch[2](392/1500); Loss: 0.123529; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1430 0.1392 0.1315 0.1261 0.1221 0.1228 0.1257 0.1222 0.1188 0.1180 0.1192 0.1174 0.1164 0.1169 0.1186 0.1187 

[TRAIN] Epoch[2](393/1500); Loss: 0.090580; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1455 0.1276 0.1209 0.1114 0.0979 0.0899 0.0830 0.0801 0.0787 0.0751 0.0724 0.0711 0.0726 0.0728 0.0736 0.0766 

[TRAIN] Epoch[2](394/1500); Loss: 0.086102; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1643 0.1164 0.1032 0.1049 0.0923 0.0766 0.0803 0.0729 0.0706 0.0689 0.0730 0.0698 0.0680 0.0720 0.0719 0.0727 

[TRAIN] Epoch[2](395/1500); Loss: 0.109110; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1242 0.1065 0.1195 0.1212 0.1122 0.1035 0.1029 0.1038 0.1036 0.1039 0.1052 0.1059 0.1063 0.1075 0.1090 0.1104 

[TRAIN] Epoch[2](396/1500); Loss: 0.126102; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1884 0.1931 0.1818 0.1673 0.1338 0.1170 0.1036 0.0968 0.0987 0.1021 0.1013 0.1017 0.1034 0.1060 0.1101 0.1125 

[TRAIN] Epoch[2](397/1500); Loss: 0.124876; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1611 0.1526 0.1421 0.1344 0.1268 0.1237 0.1217 0.1190 0.1165 0.1145 0.1146 0.1146 0.1138 0.1140 0.1145 0.1143 

[TRAIN] Epoch[2](398/1500); Loss: 0.112580; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1345 0.1308 0.1280 0.1223 0.1146 0.1129 0.1098 0.1074 0.1065 0.1052 0.1045 0.1049 0.1053 0.1051 0.1047 0.1048 

[TRAIN] Epoch[2](399/1500); Loss: 0.132471; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1699 0.1606 0.1524 0.1439 0.1334 0.1296 0.1246 0.1231 0.1230 0.1236 0.1233 0.1217 0.1216 0.1223 0.1237 0.1227 

[TRAIN] Epoch[2](400/1500); Loss: 0.076838; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1542 0.1131 0.0830 0.0858 0.0710 0.0648 0.0669 0.0642 0.0629 0.0628 0.0675 0.0648 0.0642 0.0685 0.0678 0.0680 

[TRAIN] Epoch[2](401/1500); Loss: 0.077617; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1534 0.1155 0.0905 0.0766 0.0720 0.0643 0.0683 0.0694 0.0651 0.0638 0.0657 0.0662 0.0648 0.0689 0.0689 0.0685 

[TRAIN] Epoch[2](402/1500); Loss: 0.059573; Backpropagation: 0.0916 sec; Batch: 0.4323 sec
0.0803 0.0822 0.0718 0.0618 0.0581 0.0583 0.0550 0.0530 0.0522 0.0530 0.0532 0.0531 0.0539 0.0550 0.0554 0.0569 

[TRAIN] Epoch[2](403/1500); Loss: 0.099754; Backpropagation: 0.0917 sec; Batch: 0.4391 sec
0.2715 0.2201 0.1558 0.1057 0.0702 0.0818 0.0724 0.0662 0.0731 0.0657 0.0651 0.0669 0.0699 0.0686 0.0664 0.0766 

[TRAIN] Epoch[2](404/1500); Loss: 0.088527; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1166 0.1119 0.1040 0.0943 0.0849 0.0863 0.0847 0.0825 0.0814 0.0812 0.0810 0.0808 0.0812 0.0812 0.0817 0.0827 

[TRAIN] Epoch[2](405/1500); Loss: 0.085451; Backpropagation: 0.0920 sec; Batch: 0.4275 sec
0.1205 0.1163 0.1131 0.1061 0.0910 0.0826 0.0795 0.0781 0.0765 0.0741 0.0741 0.0725 0.0718 0.0711 0.0707 0.0693 

[TRAIN] Epoch[2](406/1500); Loss: 0.106159; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1674 0.1406 0.1175 0.1108 0.1046 0.0993 0.1028 0.0974 0.0955 0.0942 0.0953 0.0938 0.0951 0.0950 0.0950 0.0943 

[TRAIN] Epoch[2](407/1500); Loss: 0.056656; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1321 0.0869 0.0825 0.0725 0.0580 0.0443 0.0443 0.0412 0.0423 0.0417 0.0443 0.0431 0.0432 0.0430 0.0437 0.0433 

[TRAIN] Epoch[2](408/1500); Loss: 0.066500; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0927 0.0856 0.0791 0.0721 0.0633 0.0678 0.0694 0.0637 0.0602 0.0582 0.0582 0.0580 0.0586 0.0581 0.0594 0.0596 

[TRAIN] Epoch[2](409/1500); Loss: 0.132807; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1641 0.1528 0.1426 0.1373 0.1310 0.1274 0.1262 0.1257 0.1255 0.1256 0.1265 0.1271 0.1280 0.1277 0.1278 0.1296 

[TRAIN] Epoch[2](410/1500); Loss: 0.099443; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1184 0.1329 0.1514 0.1498 0.1376 0.1075 0.0856 0.0777 0.0751 0.0715 0.0730 0.0727 0.0788 0.0841 0.0861 0.0891 

[TRAIN] Epoch[2](411/1500); Loss: 0.099171; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1414 0.1456 0.1355 0.1261 0.1046 0.0915 0.0862 0.0868 0.0854 0.0837 0.0839 0.0848 0.0827 0.0812 0.0837 0.0837 

[TRAIN] Epoch[2](412/1500); Loss: 0.110394; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1596 0.1415 0.1427 0.1355 0.1236 0.1111 0.1023 0.0970 0.0939 0.0926 0.0907 0.0908 0.0912 0.0933 0.0990 0.1013 

[TRAIN] Epoch[2](413/1500); Loss: 0.060878; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0827 0.0777 0.0767 0.0779 0.0665 0.0587 0.0575 0.0512 0.0526 0.0509 0.0521 0.0519 0.0529 0.0517 0.0543 0.0589 

[TRAIN] Epoch[2](414/1500); Loss: 0.081772; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0941 0.0860 0.1010 0.1211 0.1141 0.0916 0.0765 0.0715 0.0702 0.0738 0.0695 0.0657 0.0695 0.0702 0.0664 0.0672 

[TRAIN] Epoch[2](415/1500); Loss: 0.114458; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1389 0.1434 0.1482 0.1438 0.1303 0.1122 0.1024 0.1012 0.1011 0.0998 0.1002 0.0995 0.1004 0.1017 0.1037 0.1047 

[TRAIN] Epoch[2](416/1500); Loss: 0.090988; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1369 0.1207 0.1067 0.1026 0.1012 0.0957 0.0891 0.0818 0.0804 0.0791 0.0772 0.0768 0.0756 0.0770 0.0773 0.0777 

[TRAIN] Epoch[2](417/1500); Loss: 0.108787; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1178 0.1214 0.1224 0.1190 0.1086 0.1057 0.1067 0.1043 0.1028 0.1021 0.1023 0.1028 0.1055 0.1061 0.1062 0.1070 

[TRAIN] Epoch[2](418/1500); Loss: 0.088610; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1603 0.1216 0.0954 0.0910 0.1050 0.1046 0.0840 0.0680 0.0744 0.0809 0.0721 0.0699 0.0695 0.0725 0.0749 0.0736 

[TRAIN] Epoch[2](419/1500); Loss: 0.124549; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1514 0.1476 0.1486 0.1440 0.1312 0.1222 0.1204 0.1178 0.1140 0.1124 0.1119 0.1121 0.1135 0.1141 0.1147 0.1167 

[TRAIN] Epoch[2](420/1500); Loss: 0.134443; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1625 0.1571 0.1490 0.1412 0.1286 0.1240 0.1267 0.1268 0.1250 0.1250 0.1254 0.1278 0.1310 0.1321 0.1333 0.1356 

[TRAIN] Epoch[2](421/1500); Loss: 0.158818; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1934 0.1792 0.1802 0.1806 0.1750 0.1633 0.1528 0.1497 0.1524 0.1491 0.1449 0.1429 0.1425 0.1450 0.1454 0.1448 

[TRAIN] Epoch[2](422/1500); Loss: 0.092695; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2481 0.1930 0.1298 0.0810 0.0631 0.0721 0.0650 0.0661 0.0788 0.0737 0.0641 0.0637 0.0683 0.0731 0.0723 0.0710 

[TRAIN] Epoch[2](423/1500); Loss: 0.091608; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1767 0.1108 0.0707 0.1021 0.1259 0.1142 0.0786 0.0661 0.0782 0.0828 0.0734 0.0695 0.0719 0.0791 0.0836 0.0823 

[TRAIN] Epoch[2](424/1500); Loss: 0.049593; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0597 0.0521 0.0540 0.0559 0.0488 0.0397 0.0471 0.0575 0.0574 0.0514 0.0456 0.0418 0.0423 0.0440 0.0472 0.0490 

[TRAIN] Epoch[2](425/1500); Loss: 0.073663; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1221 0.1055 0.0789 0.0683 0.0696 0.0702 0.0684 0.0665 0.0636 0.0621 0.0636 0.0649 0.0667 0.0683 0.0687 0.0714 

[TRAIN] Epoch[2](426/1500); Loss: 0.152016; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.2262 0.2251 0.2161 0.2100 0.1867 0.1699 0.1535 0.1374 0.1218 0.1121 0.1144 0.1149 0.1110 0.1100 0.1116 0.1115 

[TRAIN] Epoch[2](427/1500); Loss: 0.144278; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1794 0.1674 0.1584 0.1568 0.1483 0.1435 0.1403 0.1366 0.1351 0.1342 0.1335 0.1344 0.1344 0.1347 0.1358 0.1354 

[TRAIN] Epoch[2](428/1500); Loss: 0.127563; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1482 0.1510 0.1439 0.1387 0.1267 0.1206 0.1210 0.1231 0.1220 0.1179 0.1167 0.1180 0.1205 0.1235 0.1242 0.1251 

[TRAIN] Epoch[2](429/1500); Loss: 0.121066; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1494 0.1482 0.1461 0.1448 0.1301 0.1183 0.1156 0.1184 0.1188 0.1141 0.1090 0.1056 0.1047 0.1045 0.1045 0.1049 

[TRAIN] Epoch[2](430/1500); Loss: 0.069873; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1088 0.1013 0.0880 0.0909 0.0766 0.0633 0.0619 0.0636 0.0583 0.0578 0.0574 0.0570 0.0568 0.0581 0.0575 0.0607 

[TRAIN] Epoch[2](431/1500); Loss: 0.089174; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1449 0.1235 0.1050 0.0899 0.0814 0.0822 0.0854 0.0868 0.0854 0.0808 0.0761 0.0757 0.0764 0.0774 0.0784 0.0775 

[TRAIN] Epoch[2](432/1500); Loss: 0.155165; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2265 0.2089 0.1914 0.1778 0.1656 0.1580 0.1554 0.1505 0.1451 0.1417 0.1375 0.1328 0.1277 0.1236 0.1205 0.1197 

[TRAIN] Epoch[2](433/1500); Loss: 0.090156; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1442 0.1106 0.0934 0.0899 0.0924 0.0922 0.0880 0.0861 0.0850 0.0830 0.0805 0.0777 0.0769 0.0796 0.0815 0.0817 

[TRAIN] Epoch[2](434/1500); Loss: 0.063508; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0933 0.0819 0.0636 0.0565 0.0609 0.0682 0.0685 0.0633 0.0580 0.0551 0.0558 0.0559 0.0564 0.0586 0.0590 0.0609 

[TRAIN] Epoch[2](435/1500); Loss: 0.132264; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1957 0.1716 0.1566 0.1461 0.1322 0.1264 0.1254 0.1244 0.1224 0.1211 0.1197 0.1161 0.1153 0.1150 0.1146 0.1135 

[TRAIN] Epoch[2](436/1500); Loss: 0.119563; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1537 0.1406 0.1296 0.1227 0.1197 0.1165 0.1140 0.1131 0.1135 0.1136 0.1134 0.1135 0.1127 0.1114 0.1112 0.1136 

[TRAIN] Epoch[2](437/1500); Loss: 0.077096; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1005 0.0956 0.0920 0.0855 0.0766 0.0720 0.0769 0.0785 0.0731 0.0693 0.0692 0.0679 0.0694 0.0683 0.0692 0.0696 

[TRAIN] Epoch[2](438/1500); Loss: 0.093582; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1242 0.1079 0.0980 0.1081 0.1031 0.0920 0.0887 0.0926 0.0908 0.0858 0.0842 0.0838 0.0838 0.0836 0.0847 0.0860 

[TRAIN] Epoch[2](439/1500); Loss: 0.142120; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1598 0.1557 0.1503 0.1475 0.1444 0.1453 0.1438 0.1410 0.1396 0.1386 0.1374 0.1357 0.1347 0.1336 0.1331 0.1332 

[TRAIN] Epoch[2](440/1500); Loss: 0.089261; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1111 0.0952 0.0880 0.0853 0.0865 0.0915 0.0936 0.0912 0.0877 0.0856 0.0846 0.0845 0.0852 0.0857 0.0861 0.0863 

[TRAIN] Epoch[2](441/1500); Loss: 0.116884; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1494 0.1408 0.1265 0.1200 0.1151 0.1173 0.1168 0.1127 0.1096 0.1081 0.1078 0.1078 0.1080 0.1086 0.1104 0.1112 

[TRAIN] Epoch[2](442/1500); Loss: 0.130457; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2066 0.1806 0.1482 0.1362 0.1347 0.1310 0.1254 0.1245 0.1238 0.1171 0.1100 0.1090 0.1115 0.1136 0.1094 0.1055 

[TRAIN] Epoch[2](443/1500); Loss: 0.077243; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1063 0.1026 0.0921 0.0834 0.0781 0.0767 0.0779 0.0774 0.0749 0.0714 0.0679 0.0654 0.0648 0.0654 0.0658 0.0658 

[TRAIN] Epoch[2](444/1500); Loss: 0.143566; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2303 0.1973 0.1715 0.1589 0.1463 0.1399 0.1324 0.1313 0.1281 0.1253 0.1251 0.1224 0.1215 0.1228 0.1220 0.1220 

[TRAIN] Epoch[2](445/1500); Loss: 0.085198; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1503 0.1223 0.0949 0.0841 0.0799 0.0782 0.0794 0.0780 0.0742 0.0727 0.0740 0.0735 0.0722 0.0737 0.0783 0.0772 

[TRAIN] Epoch[2](446/1500); Loss: 0.195346; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2785 0.2682 0.2382 0.2194 0.2039 0.1933 0.1861 0.1811 0.1791 0.1769 0.1744 0.1703 0.1675 0.1644 0.1626 0.1616 

[TRAIN] Epoch[2](447/1500); Loss: 0.163682; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2208 0.2007 0.1800 0.1709 0.1630 0.1568 0.1528 0.1513 0.1533 0.1546 0.1539 0.1546 0.1530 0.1514 0.1508 0.1508 

[TRAIN] Epoch[2](448/1500); Loss: 0.133740; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2436 0.2045 0.1675 0.1471 0.1289 0.1172 0.1126 0.1125 0.1146 0.1158 0.1142 0.1113 0.1099 0.1117 0.1139 0.1147 

[TRAIN] Epoch[2](449/1500); Loss: 0.154235; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2214 0.1941 0.1615 0.1492 0.1429 0.1398 0.1425 0.1438 0.1430 0.1430 0.1442 0.1464 0.1463 0.1472 0.1500 0.1525 

[TRAIN] Epoch[2](450/1500); Loss: 0.201474; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3344 0.2515 0.1544 0.0942 0.1098 0.1558 0.2024 0.2340 0.2493 0.2482 0.2405 0.2239 0.2061 0.1864 0.1719 0.1608 

[TRAIN] Epoch[2](451/1500); Loss: 0.169221; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2370 0.2218 0.1883 0.1720 0.1630 0.1600 0.1627 0.1648 0.1643 0.1599 0.1549 0.1510 0.1495 0.1492 0.1525 0.1566 

[TRAIN] Epoch[2](452/1500); Loss: 0.126099; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1984 0.1595 0.1294 0.1188 0.1135 0.1105 0.1171 0.1258 0.1264 0.1178 0.1132 0.1160 0.1200 0.1172 0.1157 0.1185 

[TRAIN] Epoch[2](453/1500); Loss: 0.092958; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1334 0.1325 0.1074 0.0980 0.0870 0.0864 0.0883 0.0882 0.0894 0.0894 0.0857 0.0813 0.0786 0.0783 0.0804 0.0829 

[TRAIN] Epoch[2](454/1500); Loss: 0.112952; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3227 0.2591 0.1897 0.1368 0.0864 0.0760 0.0759 0.0714 0.0750 0.0806 0.0746 0.0668 0.0690 0.0739 0.0754 0.0741 

[TRAIN] Epoch[2](455/1500); Loss: 0.100521; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1377 0.1158 0.0972 0.0911 0.0926 0.0985 0.1006 0.0986 0.0956 0.0951 0.0962 0.0975 0.0971 0.0972 0.0980 0.0996 

[TRAIN] Epoch[2](456/1500); Loss: 0.175518; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2245 0.2040 0.1772 0.1700 0.1659 0.1692 0.1753 0.1798 0.1787 0.1732 0.1681 0.1657 0.1649 0.1641 0.1647 0.1628 

[TRAIN] Epoch[2](457/1500); Loss: 0.090960; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1257 0.1256 0.1116 0.1077 0.0944 0.0880 0.0822 0.0837 0.0882 0.0851 0.0805 0.0775 0.0747 0.0757 0.0783 0.0765 

[TRAIN] Epoch[2](458/1500); Loss: 0.159073; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1939 0.1749 0.1538 0.1482 0.1501 0.1556 0.1599 0.1570 0.1541 0.1530 0.1539 0.1554 0.1570 0.1581 0.1590 0.1612 

[TRAIN] Epoch[2](459/1500); Loss: 0.059139; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0704 0.0639 0.0642 0.0599 0.0637 0.0675 0.0620 0.0523 0.0522 0.0550 0.0592 0.0533 0.0518 0.0547 0.0599 0.0562 

[TRAIN] Epoch[2](460/1500); Loss: 0.092088; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1268 0.1173 0.0992 0.0961 0.0871 0.0874 0.0885 0.0896 0.0865 0.0832 0.0830 0.0833 0.0842 0.0849 0.0873 0.0891 

[TRAIN] Epoch[2](461/1500); Loss: 0.066578; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1085 0.0923 0.0747 0.0682 0.0652 0.0640 0.0644 0.0587 0.0564 0.0561 0.0579 0.0572 0.0576 0.0597 0.0625 0.0620 

[TRAIN] Epoch[2](462/1500); Loss: 0.126040; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1508 0.1298 0.1267 0.1237 0.1225 0.1267 0.1320 0.1290 0.1229 0.1210 0.1231 0.1230 0.1194 0.1202 0.1240 0.1218 

[TRAIN] Epoch[2](463/1500); Loss: 0.124961; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.1728 0.1575 0.1324 0.1293 0.1234 0.1224 0.1227 0.1188 0.1144 0.1129 0.1145 0.1142 0.1141 0.1152 0.1169 0.1180 

[TRAIN] Epoch[2](464/1500); Loss: 0.206844; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2861 0.2947 0.2559 0.2557 0.2366 0.2146 0.1879 0.1727 0.1696 0.1765 0.1839 0.1797 0.1725 0.1716 0.1743 0.1771 

[TRAIN] Epoch[2](465/1500); Loss: 0.113287; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1639 0.1285 0.1116 0.1103 0.1070 0.1054 0.1107 0.1108 0.1060 0.1053 0.1074 0.1091 0.1070 0.1077 0.1094 0.1124 

[TRAIN] Epoch[2](466/1500); Loss: 0.065557; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1063 0.1116 0.0705 0.0705 0.0530 0.0562 0.0636 0.0557 0.0550 0.0542 0.0569 0.0567 0.0568 0.0599 0.0594 0.0625 

[TRAIN] Epoch[2](467/1500); Loss: 0.161236; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2324 0.2054 0.1771 0.1667 0.1592 0.1574 0.1569 0.1564 0.1524 0.1476 0.1459 0.1466 0.1455 0.1427 0.1426 0.1451 

[TRAIN] Epoch[2](468/1500); Loss: 0.092542; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1192 0.1104 0.0991 0.0964 0.0929 0.0900 0.0894 0.0881 0.0861 0.0856 0.0857 0.0860 0.0873 0.0871 0.0880 0.0894 

[TRAIN] Epoch[2](469/1500); Loss: 0.114432; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2418 0.2086 0.1568 0.1294 0.1011 0.1000 0.0966 0.0910 0.0920 0.0896 0.0870 0.0866 0.0860 0.0883 0.0877 0.0884 

[TRAIN] Epoch[2](470/1500); Loss: 0.109251; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1383 0.1135 0.1100 0.1072 0.1052 0.1064 0.1077 0.1071 0.1045 0.1042 0.1060 0.1067 0.1059 0.1068 0.1089 0.1095 

[TRAIN] Epoch[2](471/1500); Loss: 0.142913; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1777 0.1569 0.1484 0.1446 0.1440 0.1449 0.1415 0.1380 0.1378 0.1388 0.1350 0.1356 0.1364 0.1348 0.1349 0.1372 

[TRAIN] Epoch[2](472/1500); Loss: 0.124801; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1629 0.1473 0.1319 0.1269 0.1242 0.1229 0.1214 0.1195 0.1187 0.1189 0.1176 0.1168 0.1173 0.1170 0.1164 0.1171 

[TRAIN] Epoch[2](473/1500); Loss: 0.054073; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1146 0.1213 0.0715 0.0695 0.0379 0.0422 0.0494 0.0405 0.0380 0.0379 0.0398 0.0404 0.0389 0.0399 0.0417 0.0418 

[TRAIN] Epoch[2](474/1500); Loss: 0.141994; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1629 0.1451 0.1369 0.1375 0.1375 0.1364 0.1351 0.1362 0.1385 0.1399 0.1408 0.1423 0.1427 0.1444 0.1469 0.1488 

[TRAIN] Epoch[2](475/1500); Loss: 0.122148; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1557 0.1395 0.1335 0.1377 0.1340 0.1274 0.1206 0.1183 0.1154 0.1141 0.1118 0.1099 0.1097 0.1093 0.1085 0.1089 

[TRAIN] Epoch[2](476/1500); Loss: 0.147507; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1519 0.1491 0.1493 0.1514 0.1503 0.1476 0.1456 0.1453 0.1455 0.1449 0.1443 0.1452 0.1465 0.1470 0.1477 0.1486 

[TRAIN] Epoch[2](477/1500); Loss: 0.188086; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2717 0.2729 0.2292 0.2287 0.2105 0.1810 0.1610 0.1552 0.1622 0.1647 0.1591 0.1591 0.1607 0.1642 0.1640 0.1652 

[TRAIN] Epoch[2](478/1500); Loss: 0.127099; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1501 0.1312 0.1256 0.1272 0.1219 0.1190 0.1188 0.1202 0.1207 0.1214 0.1234 0.1253 0.1280 0.1308 0.1325 0.1372 

[TRAIN] Epoch[2](479/1500); Loss: 0.063451; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1106 0.0937 0.0876 0.0759 0.0703 0.0637 0.0576 0.0548 0.0512 0.0510 0.0488 0.0497 0.0488 0.0514 0.0495 0.0505 

[TRAIN] Epoch[2](480/1500); Loss: 0.089078; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1246 0.1032 0.0934 0.0902 0.0932 0.0884 0.0837 0.0834 0.0855 0.0825 0.0822 0.0824 0.0844 0.0823 0.0826 0.0833 

[TRAIN] Epoch[2](481/1500); Loss: 0.076356; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1065 0.1044 0.0863 0.0882 0.0839 0.0766 0.0711 0.0675 0.0669 0.0668 0.0662 0.0660 0.0665 0.0677 0.0680 0.0691 

[TRAIN] Epoch[2](482/1500); Loss: 0.134536; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1836 0.1650 0.1513 0.1407 0.1340 0.1308 0.1290 0.1270 0.1250 0.1234 0.1230 0.1230 0.1246 0.1237 0.1239 0.1246 

[TRAIN] Epoch[2](483/1500); Loss: 0.099609; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1403 0.1193 0.1084 0.1077 0.1015 0.0978 0.0936 0.0921 0.0915 0.0915 0.0914 0.0911 0.0918 0.0916 0.0919 0.0923 

[TRAIN] Epoch[2](484/1500); Loss: 0.059791; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2350 0.1499 0.0464 0.0547 0.0612 0.0476 0.0312 0.0384 0.0307 0.0307 0.0335 0.0374 0.0403 0.0367 0.0410 0.0419 

[TRAIN] Epoch[2](485/1500); Loss: 0.113207; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1680 0.1460 0.1226 0.1194 0.1190 0.1159 0.1102 0.1060 0.1032 0.1021 0.1011 0.1000 0.0997 0.0998 0.0993 0.0991 

[TRAIN] Epoch[2](486/1500); Loss: 0.163362; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1789 0.1746 0.1675 0.1668 0.1652 0.1627 0.1607 0.1603 0.1603 0.1598 0.1588 0.1590 0.1594 0.1594 0.1601 0.1604 

[TRAIN] Epoch[2](487/1500); Loss: 0.075462; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.1187 0.1003 0.0863 0.0812 0.0738 0.0694 0.0669 0.0667 0.0668 0.0666 0.0668 0.0675 0.0682 0.0689 0.0688 0.0705 

[TRAIN] Epoch[2](488/1500); Loss: 0.117968; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1980 0.1664 0.1391 0.1267 0.1191 0.1121 0.1061 0.1031 0.1014 0.1007 0.1002 0.1012 0.1015 0.1027 0.1042 0.1052 

[TRAIN] Epoch[2](489/1500); Loss: 0.144569; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1758 0.1625 0.1536 0.1544 0.1505 0.1438 0.1405 0.1383 0.1369 0.1354 0.1362 0.1364 0.1370 0.1365 0.1373 0.1380 

[TRAIN] Epoch[2](490/1500); Loss: 0.144102; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1883 0.1818 0.1659 0.1694 0.1643 0.1552 0.1465 0.1412 0.1355 0.1301 0.1249 0.1212 0.1199 0.1199 0.1207 0.1209 

[TRAIN] Epoch[2](491/1500); Loss: 0.161376; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2047 0.1973 0.1785 0.1849 0.1798 0.1695 0.1613 0.1569 0.1519 0.1478 0.1437 0.1408 0.1400 0.1407 0.1418 0.1425 

[TRAIN] Epoch[2](492/1500); Loss: 0.091616; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1118 0.0999 0.0914 0.0934 0.0925 0.0896 0.0866 0.0868 0.0865 0.0871 0.0883 0.0884 0.0887 0.0903 0.0918 0.0927 

[TRAIN] Epoch[2](493/1500); Loss: 0.162943; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.1843 0.1694 0.1654 0.1664 0.1619 0.1595 0.1589 0.1585 0.1596 0.1591 0.1594 0.1598 0.1601 0.1606 0.1618 0.1624 

[TRAIN] Epoch[2](494/1500); Loss: 0.069645; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0777 0.0685 0.0902 0.0894 0.0783 0.0655 0.0636 0.0624 0.0621 0.0624 0.0642 0.0642 0.0651 0.0652 0.0672 0.0684 

[TRAIN] Epoch[2](495/1500); Loss: 0.144235; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1932 0.1853 0.1592 0.1660 0.1611 0.1503 0.1410 0.1360 0.1312 0.1282 0.1268 0.1259 0.1257 0.1260 0.1257 0.1262 

[TRAIN] Epoch[2](496/1500); Loss: 0.095011; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1419 0.1346 0.1036 0.1076 0.0998 0.0895 0.0840 0.0823 0.0825 0.0824 0.0824 0.0834 0.0845 0.0864 0.0866 0.0887 

[TRAIN] Epoch[2](497/1500); Loss: 0.137280; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1690 0.1531 0.1382 0.1364 0.1368 0.1359 0.1335 0.1317 0.1317 0.1323 0.1318 0.1317 0.1327 0.1336 0.1337 0.1344 

[TRAIN] Epoch[2](498/1500); Loss: 0.076800; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1432 0.1066 0.0739 0.1081 0.1212 0.1045 0.0791 0.0698 0.0525 0.0453 0.0454 0.0499 0.0606 0.0597 0.0558 0.0531 

[TRAIN] Epoch[2](499/1500); Loss: 0.117489; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1810 0.1503 0.1111 0.1242 0.1301 0.1242 0.1131 0.1106 0.1041 0.1015 0.1019 0.1032 0.1049 0.1060 0.1062 0.1074 

[TRAIN] Epoch[2](500/1500); Loss: 0.093729; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1400 0.1293 0.1005 0.1027 0.0923 0.0853 0.0845 0.0821 0.0826 0.0822 0.0843 0.0844 0.0859 0.0856 0.0891 0.0890 

[TRAIN] Epoch[2](501/1500); Loss: 0.143771; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2136 0.1906 0.1644 0.1563 0.1503 0.1452 0.1396 0.1347 0.1310 0.1282 0.1265 0.1258 0.1248 0.1233 0.1229 0.1229 

[TRAIN] Epoch[2](502/1500); Loss: 0.103115; Backpropagation: 0.1001 sec; Batch: 0.4478 sec
0.1512 0.1290 0.1209 0.1223 0.1193 0.1042 0.0945 0.0884 0.0888 0.0883 0.0875 0.0880 0.0898 0.0917 0.0924 0.0936 

[TRAIN] Epoch[2](503/1500); Loss: 0.084041; Backpropagation: 0.0930 sec; Batch: 0.4250 sec
0.0972 0.0889 0.0830 0.0825 0.0807 0.0783 0.0783 0.0777 0.0785 0.0798 0.0817 0.0833 0.0849 0.0878 0.0901 0.0920 

[TRAIN] Epoch[2](504/1500); Loss: 0.083833; Backpropagation: 0.0925 sec; Batch: 0.4242 sec
0.1093 0.0943 0.0884 0.0853 0.0849 0.0800 0.0770 0.0759 0.0760 0.0762 0.0775 0.0796 0.0811 0.0833 0.0851 0.0873 

[TRAIN] Epoch[2](505/1500); Loss: 0.093979; Backpropagation: 0.0928 sec; Batch: 0.4243 sec
0.1271 0.1193 0.1007 0.0894 0.0896 0.0886 0.0906 0.0864 0.0838 0.0842 0.0882 0.0880 0.0881 0.0894 0.0947 0.0954 

[TRAIN] Epoch[2](506/1500); Loss: 0.166781; Backpropagation: 0.0924 sec; Batch: 0.4236 sec
0.1825 0.1756 0.1773 0.1737 0.1689 0.1630 0.1603 0.1595 0.1591 0.1604 0.1611 0.1621 0.1630 0.1652 0.1668 0.1698 

[TRAIN] Epoch[2](507/1500); Loss: 0.110137; Backpropagation: 0.0928 sec; Batch: 0.4249 sec
0.1515 0.1064 0.1265 0.1480 0.1444 0.1214 0.1089 0.0962 0.0905 0.0909 0.0941 0.0929 0.0945 0.0958 0.0989 0.1012 

[TRAIN] Epoch[2](508/1500); Loss: 0.127738; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.1734 0.1488 0.1290 0.1326 0.1336 0.1257 0.1180 0.1161 0.1173 0.1182 0.1181 0.1193 0.1207 0.1226 0.1243 0.1259 

[TRAIN] Epoch[2](509/1500); Loss: 0.109869; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1243 0.1163 0.1214 0.1165 0.1126 0.1062 0.1052 0.1018 0.1006 0.0995 0.1010 0.1038 0.1075 0.1098 0.1137 0.1177 

[TRAIN] Epoch[2](510/1500); Loss: 0.092267; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2278 0.1625 0.0796 0.0873 0.1130 0.1079 0.0808 0.0713 0.0605 0.0646 0.0668 0.0681 0.0668 0.0724 0.0725 0.0745 

[TRAIN] Epoch[2](511/1500); Loss: 0.141819; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1570 0.1490 0.1356 0.1387 0.1409 0.1379 0.1352 0.1351 0.1362 0.1370 0.1384 0.1406 0.1430 0.1456 0.1479 0.1509 

[TRAIN] Epoch[2](512/1500); Loss: 0.085494; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1542 0.1449 0.1015 0.0841 0.0888 0.0879 0.0800 0.0712 0.0666 0.0664 0.0678 0.0671 0.0690 0.0707 0.0725 0.0750 

[TRAIN] Epoch[2](513/1500); Loss: 0.091960; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1102 0.1071 0.1126 0.0898 0.0858 0.0883 0.0875 0.0846 0.0826 0.0841 0.0849 0.0866 0.0881 0.0902 0.0930 0.0960 

[TRAIN] Epoch[2](514/1500); Loss: 0.077383; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1008 0.0919 0.0950 0.0747 0.0706 0.0714 0.0685 0.0689 0.0693 0.0710 0.0711 0.0725 0.0750 0.0782 0.0790 0.0802 

[TRAIN] Epoch[2](515/1500); Loss: 0.063619; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0664 0.0598 0.0699 0.0708 0.0706 0.0619 0.0601 0.0593 0.0598 0.0586 0.0593 0.0610 0.0623 0.0639 0.0655 0.0687 

[TRAIN] Epoch[2](516/1500); Loss: 0.141093; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1605 0.1592 0.1579 0.1477 0.1455 0.1422 0.1389 0.1377 0.1374 0.1356 0.1331 0.1324 0.1320 0.1321 0.1323 0.1330 

[TRAIN] Epoch[2](517/1500); Loss: 0.083150; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2211 0.1289 0.0666 0.0793 0.0670 0.0548 0.0576 0.0680 0.0616 0.0692 0.0750 0.0704 0.0729 0.0782 0.0808 0.0790 

[TRAIN] Epoch[2](518/1500); Loss: 0.094883; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1646 0.1574 0.1612 0.1032 0.0808 0.0807 0.0779 0.0800 0.0756 0.0750 0.0753 0.0759 0.0761 0.0768 0.0786 0.0788 

[TRAIN] Epoch[2](519/1500); Loss: 0.115408; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1689 0.1544 0.1571 0.1195 0.1034 0.1043 0.1052 0.1084 0.1061 0.1040 0.1024 0.1030 0.1016 0.1009 0.1031 0.1043 

[TRAIN] Epoch[2](520/1500); Loss: 0.123437; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1858 0.1729 0.1616 0.1337 0.1187 0.1107 0.1121 0.1117 0.1099 0.1089 0.1086 0.1064 0.1073 0.1094 0.1094 0.1079 

[TRAIN] Epoch[2](521/1500); Loss: 0.161282; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2185 0.2277 0.2325 0.1868 0.1542 0.1404 0.1390 0.1435 0.1413 0.1399 0.1407 0.1447 0.1414 0.1407 0.1433 0.1460 

[TRAIN] Epoch[2](522/1500); Loss: 0.179691; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2330 0.2414 0.2672 0.2115 0.1713 0.1610 0.1616 0.1677 0.1633 0.1602 0.1565 0.1545 0.1565 0.1570 0.1548 0.1573 

[TRAIN] Epoch[2](523/1500); Loss: 0.162459; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2101 0.2225 0.2280 0.1850 0.1553 0.1436 0.1456 0.1503 0.1462 0.1450 0.1454 0.1448 0.1431 0.1441 0.1443 0.1461 

[TRAIN] Epoch[2](524/1500); Loss: 0.073063; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0942 0.0870 0.1285 0.0930 0.0689 0.0649 0.0624 0.0649 0.0654 0.0618 0.0589 0.0613 0.0633 0.0618 0.0632 0.0695 

[TRAIN] Epoch[2](525/1500); Loss: 0.178009; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2243 0.2229 0.2463 0.2060 0.1743 0.1634 0.1642 0.1659 0.1620 0.1600 0.1586 0.1584 0.1592 0.1602 0.1607 0.1617 

[TRAIN] Epoch[2](526/1500); Loss: 0.100841; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1143 0.1305 0.1972 0.1567 0.1072 0.0866 0.0864 0.0915 0.0892 0.0830 0.0802 0.0794 0.0775 0.0777 0.0777 0.0784 

[TRAIN] Epoch[2](527/1500); Loss: 0.147136; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.2161 0.2342 0.2464 0.1866 0.1379 0.1273 0.1279 0.1320 0.1269 0.1232 0.1208 0.1172 0.1151 0.1150 0.1151 0.1127 

[TRAIN] Epoch[2](528/1500); Loss: 0.169976; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2726 0.2868 0.2680 0.2089 0.1671 0.1528 0.1489 0.1469 0.1397 0.1384 0.1364 0.1336 0.1320 0.1308 0.1281 0.1287 

[TRAIN] Epoch[2](529/1500); Loss: 0.108516; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1980 0.1988 0.1693 0.1201 0.0954 0.0906 0.0919 0.0913 0.0862 0.0857 0.0855 0.0824 0.0839 0.0855 0.0854 0.0863 

[TRAIN] Epoch[2](530/1500); Loss: 0.126245; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1821 0.1884 0.1649 0.1196 0.1128 0.1107 0.1096 0.1111 0.1133 0.1112 0.1119 0.1143 0.1160 0.1149 0.1181 0.1210 

[TRAIN] Epoch[2](531/1500); Loss: 0.145505; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1812 0.1889 0.2100 0.1711 0.1419 0.1322 0.1321 0.1348 0.1328 0.1300 0.1293 0.1295 0.1275 0.1276 0.1293 0.1299 

[TRAIN] Epoch[2](532/1500); Loss: 0.146761; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2139 0.2149 0.2148 0.1760 0.1530 0.1391 0.1332 0.1297 0.1255 0.1243 0.1229 0.1193 0.1189 0.1205 0.1210 0.1211 

[TRAIN] Epoch[2](533/1500); Loss: 0.141175; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1980 0.2067 0.2027 0.1648 0.1419 0.1316 0.1279 0.1257 0.1230 0.1214 0.1214 0.1208 0.1186 0.1179 0.1183 0.1179 

[TRAIN] Epoch[2](534/1500); Loss: 0.135735; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1965 0.2022 0.1787 0.1399 0.1227 0.1197 0.1196 0.1221 0.1216 0.1204 0.1202 0.1200 0.1206 0.1222 0.1229 0.1225 

[TRAIN] Epoch[2](535/1500); Loss: 0.127542; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1957 0.1887 0.1655 0.1299 0.1163 0.1115 0.1109 0.1114 0.1104 0.1104 0.1118 0.1132 0.1134 0.1149 0.1174 0.1192 

[TRAIN] Epoch[2](536/1500); Loss: 0.116041; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1942 0.1892 0.1402 0.1124 0.1070 0.1014 0.0984 0.0973 0.0992 0.0988 0.0995 0.1018 0.1005 0.1029 0.1059 0.1080 

[TRAIN] Epoch[2](537/1500); Loss: 0.129409; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1910 0.1891 0.1503 0.1246 0.1230 0.1182 0.1133 0.1125 0.1127 0.1136 0.1152 0.1173 0.1186 0.1216 0.1245 0.1251 

[TRAIN] Epoch[2](538/1500); Loss: 0.147338; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2076 0.2090 0.1745 0.1491 0.1416 0.1380 0.1354 0.1336 0.1320 0.1314 0.1317 0.1326 0.1329 0.1342 0.1361 0.1377 

[TRAIN] Epoch[2](539/1500); Loss: 0.133730; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1940 0.1914 0.1654 0.1385 0.1263 0.1224 0.1211 0.1210 0.1195 0.1189 0.1189 0.1189 0.1192 0.1198 0.1215 0.1229 

[TRAIN] Epoch[2](540/1500); Loss: 0.106798; Backpropagation: 0.0915 sec; Batch: 0.4231 sec
0.1363 0.1295 0.1142 0.1103 0.1043 0.0996 0.0957 0.0954 0.0958 0.0976 0.0989 0.1010 0.1030 0.1065 0.1093 0.1114 

[TRAIN] Epoch[2](541/1500); Loss: 0.124669; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1458 0.1410 0.1239 0.1140 0.1295 0.1389 0.1358 0.1267 0.1210 0.1176 0.1143 0.1138 0.1153 0.1166 0.1184 0.1219 

[TRAIN] Epoch[2](542/1500); Loss: 0.108485; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1400 0.1257 0.1232 0.1165 0.1082 0.1043 0.1030 0.1008 0.0997 0.0986 0.0992 0.1004 0.1013 0.1028 0.1057 0.1063 

[TRAIN] Epoch[2](543/1500); Loss: 0.095631; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1312 0.1279 0.1242 0.0975 0.0891 0.0859 0.0835 0.0830 0.0828 0.0833 0.0845 0.0866 0.0889 0.0908 0.0937 0.0971 

[TRAIN] Epoch[2](544/1500); Loss: 0.099333; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1478 0.1333 0.1081 0.0970 0.0941 0.0904 0.0877 0.0877 0.0876 0.0880 0.0897 0.0912 0.0932 0.0956 0.0974 0.1006 

[TRAIN] Epoch[2](545/1500); Loss: 0.060065; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0884 0.0873 0.0751 0.0605 0.0523 0.0497 0.0500 0.0500 0.0499 0.0512 0.0532 0.0542 0.0560 0.0590 0.0612 0.0630 

[TRAIN] Epoch[2](546/1500); Loss: 0.125682; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1846 0.1727 0.1460 0.1316 0.1318 0.1279 0.1217 0.1160 0.1118 0.1083 0.1070 0.1078 0.1085 0.1099 0.1116 0.1137 

[TRAIN] Epoch[2](547/1500); Loss: 0.104993; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1481 0.1396 0.1188 0.1064 0.1038 0.1009 0.0977 0.0953 0.0943 0.0938 0.0942 0.0952 0.0959 0.0973 0.0984 0.1001 

[TRAIN] Epoch[2](548/1500); Loss: 0.075531; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1240 0.1087 0.0858 0.0773 0.0733 0.0700 0.0667 0.0641 0.0640 0.0644 0.0648 0.0656 0.0673 0.0688 0.0709 0.0729 

[TRAIN] Epoch[2](549/1500); Loss: 0.059132; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0762 0.0692 0.0673 0.0616 0.0585 0.0562 0.0545 0.0541 0.0542 0.0538 0.0540 0.0549 0.0556 0.0566 0.0587 0.0606 

[TRAIN] Epoch[2](550/1500); Loss: 0.096074; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1513 0.1450 0.1181 0.0968 0.0895 0.0867 0.0852 0.0842 0.0837 0.0836 0.0839 0.0843 0.0850 0.0859 0.0866 0.0876 

[TRAIN] Epoch[2](551/1500); Loss: 0.154489; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2030 0.1977 0.1714 0.1574 0.1519 0.1506 0.1495 0.1476 0.1458 0.1443 0.1435 0.1429 0.1422 0.1416 0.1414 0.1412 

[TRAIN] Epoch[2](552/1500); Loss: 0.097669; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1466 0.1306 0.1126 0.1022 0.1005 0.0956 0.0914 0.0897 0.0882 0.0865 0.0870 0.0863 0.0854 0.0864 0.0865 0.0870 

[TRAIN] Epoch[2](553/1500); Loss: 0.111924; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1569 0.1462 0.1243 0.1168 0.1157 0.1128 0.1082 0.1051 0.1030 0.1014 0.1005 0.1004 0.0999 0.0998 0.0996 0.1002 

[TRAIN] Epoch[2](554/1500); Loss: 0.081092; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1342 0.1118 0.0876 0.0813 0.0766 0.0736 0.0734 0.0713 0.0690 0.0703 0.0710 0.0706 0.0729 0.0755 0.0770 0.0811 

[TRAIN] Epoch[2](555/1500); Loss: 0.120668; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1684 0.1502 0.1363 0.1270 0.1205 0.1166 0.1146 0.1119 0.1107 0.1099 0.1100 0.1103 0.1105 0.1106 0.1111 0.1121 

[TRAIN] Epoch[2](556/1500); Loss: 0.089693; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1283 0.1264 0.1003 0.0891 0.0912 0.0892 0.0835 0.0816 0.0801 0.0801 0.0798 0.0798 0.0808 0.0811 0.0815 0.0823 

[TRAIN] Epoch[2](557/1500); Loss: 0.117325; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1689 0.1402 0.1221 0.1209 0.1171 0.1136 0.1103 0.1094 0.1084 0.1087 0.1084 0.1089 0.1096 0.1096 0.1103 0.1108 

[TRAIN] Epoch[2](558/1500); Loss: 0.135456; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1727 0.1555 0.1440 0.1383 0.1358 0.1325 0.1299 0.1291 0.1281 0.1270 0.1279 0.1284 0.1283 0.1288 0.1297 0.1312 

[TRAIN] Epoch[2](559/1500); Loss: 0.149859; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1931 0.1917 0.1637 0.1496 0.1462 0.1446 0.1430 0.1424 0.1414 0.1406 0.1403 0.1400 0.1402 0.1406 0.1400 0.1404 

[TRAIN] Epoch[2](560/1500); Loss: 0.070126; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.0953 0.0941 0.0828 0.0744 0.0729 0.0694 0.0657 0.0651 0.0633 0.0614 0.0619 0.0616 0.0621 0.0634 0.0636 0.0652 

[TRAIN] Epoch[2](561/1500); Loss: 0.106953; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1421 0.1245 0.1064 0.1119 0.1111 0.1068 0.1022 0.1007 0.0993 0.0987 0.0992 0.0997 0.1003 0.1016 0.1032 0.1036 

[TRAIN] Epoch[2](562/1500); Loss: 0.124434; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1509 0.1449 0.1374 0.1292 0.1252 0.1221 0.1205 0.1195 0.1183 0.1176 0.1174 0.1168 0.1170 0.1179 0.1181 0.1183 

[TRAIN] Epoch[2](563/1500); Loss: 0.098908; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1136 0.1108 0.1038 0.0992 0.0956 0.0952 0.0947 0.0936 0.0936 0.0956 0.0962 0.0963 0.0970 0.0982 0.0989 0.1002 

[TRAIN] Epoch[2](564/1500); Loss: 0.177943; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1874 0.1761 0.1790 0.1770 0.1770 0.1785 0.1785 0.1759 0.1760 0.1770 0.1765 0.1764 0.1772 0.1772 0.1775 0.1797 

[TRAIN] Epoch[2](565/1500); Loss: 0.188520; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1807 0.1779 0.1694 0.1812 0.1901 0.1891 0.1906 0.1956 0.1924 0.1888 0.1926 0.1915 0.1900 0.1958 0.1961 0.1944 

[TRAIN] Epoch[2](566/1500); Loss: 0.142992; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1773 0.1388 0.1143 0.1178 0.1194 0.1327 0.1374 0.1369 0.1378 0.1447 0.1480 0.1496 0.1530 0.1556 0.1599 0.1645 

[TRAIN] Epoch[2](567/1500); Loss: 0.159429; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1495 0.1372 0.1284 0.1397 0.1449 0.1499 0.1542 0.1572 0.1606 0.1639 0.1678 0.1710 0.1749 0.1799 0.1839 0.1878 

[TRAIN] Epoch[2](568/1500); Loss: 0.222794; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1563 0.1271 0.1374 0.1480 0.1587 0.1856 0.2073 0.2173 0.2249 0.2408 0.2560 0.2720 0.2860 0.2999 0.3162 0.3313 

[TRAIN] Epoch[2](569/1500); Loss: 0.227886; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2291 0.2076 0.1961 0.2173 0.2253 0.2293 0.2298 0.2309 0.2312 0.2297 0.2328 0.2355 0.2345 0.2375 0.2400 0.2398 

[TRAIN] Epoch[2](570/1500); Loss: 0.204635; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1872 0.1757 0.1724 0.1953 0.2061 0.2103 0.2077 0.2078 0.2102 0.2105 0.2112 0.2135 0.2135 0.2154 0.2184 0.2189 

[TRAIN] Epoch[2](571/1500); Loss: 0.139325; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1517 0.1402 0.1387 0.1485 0.1480 0.1468 0.1431 0.1403 0.1384 0.1370 0.1342 0.1329 0.1334 0.1323 0.1315 0.1320 

[TRAIN] Epoch[2](572/1500); Loss: 0.197902; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2418 0.2156 0.1985 0.2162 0.2122 0.2071 0.2015 0.1985 0.1934 0.1897 0.1875 0.1846 0.1815 0.1803 0.1800 0.1783 

[TRAIN] Epoch[2](573/1500); Loss: 0.112005; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1325 0.1083 0.0978 0.1290 0.1272 0.1185 0.1139 0.1138 0.1089 0.1049 0.1058 0.1045 0.1040 0.1071 0.1076 0.1084 

[TRAIN] Epoch[2](574/1500); Loss: 0.126336; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1708 0.1620 0.1545 0.1557 0.1441 0.1364 0.1264 0.1197 0.1137 0.1086 0.1066 0.1046 0.1028 0.1037 0.1053 0.1064 

[TRAIN] Epoch[2](575/1500); Loss: 0.182170; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2027 0.1910 0.1823 0.1971 0.1946 0.1861 0.1811 0.1791 0.1761 0.1758 0.1751 0.1744 0.1735 0.1755 0.1753 0.1749 

[TRAIN] Epoch[2](576/1500); Loss: 0.096286; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1689 0.0786 0.0758 0.1079 0.1041 0.0984 0.1033 0.0866 0.0902 0.0870 0.0753 0.0891 0.0920 0.0858 0.0961 0.1014 

[TRAIN] Epoch[2](577/1500); Loss: 0.179939; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2505 0.2488 0.2343 0.2304 0.2068 0.2036 0.1880 0.1724 0.1646 0.1561 0.1445 0.1407 0.1384 0.1328 0.1326 0.1346 

[TRAIN] Epoch[2](578/1500); Loss: 0.146168; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1679 0.1555 0.1545 0.1595 0.1509 0.1442 0.1412 0.1388 0.1375 0.1383 0.1371 0.1389 0.1410 0.1417 0.1445 0.1472 

[TRAIN] Epoch[2](579/1500); Loss: 0.150294; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1904 0.1718 0.1668 0.1641 0.1536 0.1505 0.1487 0.1451 0.1419 0.1411 0.1399 0.1383 0.1371 0.1376 0.1387 0.1390 

[TRAIN] Epoch[2](580/1500); Loss: 0.164565; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2015 0.1975 0.1904 0.1848 0.1758 0.1702 0.1637 0.1596 0.1546 0.1500 0.1473 0.1475 0.1468 0.1468 0.1473 0.1493 

[TRAIN] Epoch[2](581/1500); Loss: 0.160288; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1879 0.1675 0.1616 0.1757 0.1708 0.1620 0.1581 0.1568 0.1517 0.1496 0.1493 0.1489 0.1506 0.1560 0.1581 0.1600 

[TRAIN] Epoch[2](582/1500); Loss: 0.264075; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3738 0.3677 0.3595 0.3428 0.3153 0.3040 0.2854 0.2683 0.2501 0.2370 0.2199 0.2045 0.1913 0.1792 0.1673 0.1590 

[TRAIN] Epoch[2](583/1500); Loss: 0.120114; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1347 0.1180 0.1187 0.1256 0.1141 0.1107 0.1145 0.1141 0.1130 0.1162 0.1169 0.1200 0.1211 0.1257 0.1271 0.1314 

[TRAIN] Epoch[2](584/1500); Loss: 0.152438; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1907 0.1774 0.1679 0.1810 0.1705 0.1581 0.1489 0.1469 0.1407 0.1360 0.1347 0.1374 0.1361 0.1353 0.1372 0.1401 

[TRAIN] Epoch[2](585/1500); Loss: 0.178571; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2142 0.2255 0.2418 0.2345 0.2124 0.1953 0.1922 0.1800 0.1609 0.1530 0.1487 0.1415 0.1378 0.1378 0.1388 0.1426 

[TRAIN] Epoch[2](586/1500); Loss: 0.177934; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1410 0.1639 0.1878 0.2046 0.2092 0.2010 0.1961 0.1865 0.1758 0.1707 0.1680 0.1612 0.1653 0.1741 0.1745 0.1673 

[TRAIN] Epoch[2](587/1500); Loss: 0.425196; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3113 0.3824 0.4292 0.4417 0.4415 0.4499 0.4554 0.4427 0.4206 0.4340 0.4360 0.4245 0.4193 0.4355 0.4424 0.4368 

[TRAIN] Epoch[2](588/1500); Loss: 0.338429; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2744 0.3079 0.3629 0.3757 0.3798 0.3683 0.3712 0.3642 0.3516 0.3352 0.3318 0.3274 0.3199 0.3160 0.3146 0.3141 

[TRAIN] Epoch[2](589/1500); Loss: 0.207508; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2313 0.2727 0.2768 0.2778 0.2598 0.2337 0.2270 0.2141 0.1927 0.1716 0.1684 0.1632 0.1568 0.1536 0.1602 0.1606 

[TRAIN] Epoch[2](590/1500); Loss: 0.381693; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.3165 0.3508 0.3989 0.4201 0.4269 0.4213 0.4174 0.4054 0.3931 0.3826 0.3754 0.3675 0.3655 0.3614 0.3560 0.3483 

[TRAIN] Epoch[2](591/1500); Loss: 0.208320; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1847 0.2098 0.2357 0.2578 0.2593 0.2404 0.2277 0.2141 0.1979 0.1864 0.1814 0.1818 0.1847 0.1847 0.1892 0.1975 

[TRAIN] Epoch[2](592/1500); Loss: 0.204622; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1613 0.1690 0.2132 0.2390 0.2394 0.2253 0.2178 0.2115 0.2011 0.1891 0.1968 0.1976 0.1962 0.1963 0.2075 0.2126 

[TRAIN] Epoch[2](593/1500); Loss: 0.126896; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1178 0.1221 0.1303 0.1443 0.1416 0.1227 0.1250 0.1249 0.1181 0.1122 0.1226 0.1250 0.1232 0.1252 0.1376 0.1378 

[TRAIN] Epoch[2](594/1500); Loss: 0.160929; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1881 0.2238 0.2009 0.2051 0.1927 0.1599 0.1513 0.1445 0.1340 0.1295 0.1351 0.1358 0.1368 0.1435 0.1460 0.1478 

[TRAIN] Epoch[2](595/1500); Loss: 0.175167; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1172 0.1054 0.1811 0.2314 0.2383 0.2187 0.1985 0.1792 0.1721 0.1593 0.1541 0.1607 0.1666 0.1622 0.1704 0.1873 

[TRAIN] Epoch[2](596/1500); Loss: 0.244331; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2736 0.3183 0.3116 0.3161 0.2993 0.2583 0.2432 0.2293 0.2137 0.2034 0.2038 0.2031 0.2012 0.2052 0.2129 0.2162 

[TRAIN] Epoch[2](597/1500); Loss: 0.139846; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1647 0.1945 0.1961 0.1889 0.1572 0.1294 0.1166 0.1114 0.1072 0.1080 0.1132 0.1177 0.1218 0.1299 0.1385 0.1426 

[TRAIN] Epoch[2](598/1500); Loss: 0.147311; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1477 0.1891 0.1822 0.1902 0.1787 0.1371 0.1316 0.1258 0.1211 0.1239 0.1309 0.1288 0.1305 0.1437 0.1481 0.1475 

[TRAIN] Epoch[2](599/1500); Loss: 0.200791; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2576 0.2955 0.2855 0.2825 0.2547 0.2174 0.2004 0.1820 0.1625 0.1518 0.1481 0.1448 0.1480 0.1571 0.1617 0.1630 

[TRAIN] Epoch[2](600/1500); Loss: 0.158978; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2186 0.2359 0.2004 0.2030 0.1975 0.1604 0.1427 0.1328 0.1260 0.1219 0.1225 0.1269 0.1332 0.1353 0.1405 0.1458 

[TRAIN] Epoch[2](601/1500); Loss: 0.185982; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2577 0.2942 0.2796 0.2722 0.2343 0.1889 0.1614 0.1440 0.1333 0.1332 0.1350 0.1366 0.1409 0.1489 0.1551 0.1605 

[TRAIN] Epoch[2](602/1500); Loss: 0.139454; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1788 0.2004 0.1813 0.1710 0.1467 0.1262 0.1176 0.1156 0.1157 0.1160 0.1188 0.1226 0.1252 0.1272 0.1315 0.1367 

[TRAIN] Epoch[2](603/1500); Loss: 0.178700; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2279 0.2493 0.2306 0.2167 0.1881 0.1686 0.1576 0.1508 0.1497 0.1498 0.1515 0.1553 0.1598 0.1630 0.1677 0.1727 

[TRAIN] Epoch[2](604/1500); Loss: 0.129491; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1745 0.1614 0.1631 0.1783 0.1719 0.1395 0.1212 0.1153 0.1118 0.1044 0.1036 0.1024 0.1010 0.1034 0.1085 0.1114 

[TRAIN] Epoch[2](605/1500); Loss: 0.129632; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1358 0.1507 0.1404 0.1428 0.1361 0.1237 0.1186 0.1178 0.1191 0.1229 0.1219 0.1225 0.1254 0.1308 0.1321 0.1336 

[TRAIN] Epoch[2](606/1500); Loss: 0.195987; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2331 0.2664 0.2414 0.2415 0.2247 0.1968 0.1828 0.1740 0.1705 0.1691 0.1683 0.1705 0.1736 0.1729 0.1732 0.1771 

[TRAIN] Epoch[2](607/1500); Loss: 0.213514; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3135 0.3418 0.3188 0.3105 0.2770 0.2407 0.2119 0.1851 0.1648 0.1529 0.1463 0.1449 0.1477 0.1514 0.1533 0.1556 

[TRAIN] Epoch[2](608/1500); Loss: 0.116553; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1286 0.1426 0.1323 0.1271 0.1152 0.1081 0.1056 0.1039 0.1061 0.1062 0.1066 0.1093 0.1138 0.1166 0.1189 0.1238 

[TRAIN] Epoch[2](609/1500); Loss: 0.098067; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1199 0.1474 0.1186 0.1214 0.1087 0.0879 0.0780 0.0771 0.0794 0.0833 0.0819 0.0843 0.0896 0.0943 0.0968 0.1007 

[TRAIN] Epoch[2](610/1500); Loss: 0.128111; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1584 0.1710 0.1586 0.1478 0.1246 0.1146 0.1091 0.1112 0.1104 0.1149 0.1142 0.1185 0.1192 0.1218 0.1249 0.1304 

[TRAIN] Epoch[2](611/1500); Loss: 0.251978; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.3282 0.3320 0.3240 0.3054 0.2745 0.2544 0.2333 0.2174 0.2140 0.2127 0.2153 0.2174 0.2225 0.2241 0.2264 0.2298 

[TRAIN] Epoch[2](612/1500); Loss: 0.154418; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1830 0.2093 0.1847 0.1834 0.1714 0.1521 0.1436 0.1388 0.1376 0.1377 0.1349 0.1353 0.1363 0.1395 0.1405 0.1425 

[TRAIN] Epoch[2](613/1500); Loss: 0.150646; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1688 0.1847 0.1794 0.1884 0.1746 0.1520 0.1428 0.1402 0.1345 0.1355 0.1291 0.1309 0.1323 0.1390 0.1377 0.1405 

[TRAIN] Epoch[2](614/1500); Loss: 0.075235; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.0813 0.1095 0.1133 0.0970 0.0717 0.0623 0.0584 0.0580 0.0620 0.0644 0.0636 0.0655 0.0692 0.0728 0.0756 0.0791 

[TRAIN] Epoch[2](615/1500); Loss: 0.128184; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2145 0.2362 0.2284 0.2013 0.1498 0.1149 0.0890 0.0807 0.0822 0.0819 0.0818 0.0946 0.0960 0.0921 0.0960 0.1115 

[TRAIN] Epoch[2](616/1500); Loss: 0.120137; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1397 0.1624 0.1457 0.1463 0.1362 0.1196 0.1104 0.1053 0.1031 0.1028 0.1039 0.1040 0.1051 0.1090 0.1135 0.1152 

[TRAIN] Epoch[2](617/1500); Loss: 0.128830; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1761 0.1721 0.1619 0.1661 0.1516 0.1414 0.1280 0.1192 0.1121 0.1125 0.1041 0.1004 0.1001 0.1059 0.1047 0.1050 

[TRAIN] Epoch[2](618/1500); Loss: 0.105208; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1656 0.1822 0.1630 0.1323 0.0884 0.0748 0.0749 0.0771 0.0811 0.0836 0.0848 0.0872 0.0929 0.0951 0.0986 0.1018 

[TRAIN] Epoch[2](619/1500); Loss: 0.166753; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2469 0.2811 0.2601 0.2431 0.2001 0.1656 0.1397 0.1232 0.1220 0.1210 0.1184 0.1196 0.1290 0.1320 0.1328 0.1335 

[TRAIN] Epoch[2](620/1500); Loss: 0.080545; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1149 0.1374 0.1133 0.1150 0.1040 0.0803 0.0658 0.0603 0.0591 0.0595 0.0590 0.0626 0.0618 0.0626 0.0639 0.0691 

[TRAIN] Epoch[2](621/1500); Loss: 0.159638; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1737 0.1945 0.1673 0.1713 0.1648 0.1492 0.1458 0.1446 0.1471 0.1496 0.1515 0.1519 0.1596 0.1593 0.1613 0.1627 

[TRAIN] Epoch[2](622/1500); Loss: 0.198960; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2594 0.2742 0.2495 0.2441 0.2235 0.2078 0.1947 0.1815 0.1732 0.1716 0.1660 0.1647 0.1646 0.1685 0.1696 0.1703 

[TRAIN] Epoch[2](623/1500); Loss: 0.167826; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2066 0.2410 0.2078 0.2058 0.1863 0.1651 0.1545 0.1494 0.1483 0.1462 0.1432 0.1439 0.1446 0.1479 0.1463 0.1482 

[TRAIN] Epoch[2](624/1500); Loss: 0.184623; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2019 0.2302 0.1998 0.2050 0.1969 0.1807 0.1757 0.1741 0.1769 0.1729 0.1700 0.1723 0.1797 0.1725 0.1718 0.1736 

[TRAIN] Epoch[2](625/1500); Loss: 0.123034; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1569 0.1692 0.1600 0.1416 0.1157 0.1081 0.1055 0.1066 0.1071 0.1093 0.1090 0.1121 0.1127 0.1170 0.1176 0.1201 

[TRAIN] Epoch[2](626/1500); Loss: 0.161395; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1815 0.1958 0.1727 0.1730 0.1667 0.1585 0.1561 0.1535 0.1525 0.1524 0.1530 0.1515 0.1517 0.1536 0.1543 0.1556 

[TRAIN] Epoch[2](627/1500); Loss: 0.143850; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1591 0.1800 0.1503 0.1504 0.1435 0.1359 0.1378 0.1374 0.1372 0.1369 0.1367 0.1362 0.1374 0.1391 0.1412 0.1427 

[TRAIN] Epoch[2](628/1500); Loss: 0.130259; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1869 0.2033 0.1933 0.1755 0.1389 0.1174 0.1050 0.1036 0.1016 0.1008 0.1030 0.1081 0.1084 0.1068 0.1120 0.1194 

[TRAIN] Epoch[2](629/1500); Loss: 0.146558; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2108 0.2327 0.2045 0.1964 0.1711 0.1472 0.1290 0.1184 0.1161 0.1168 0.1134 0.1147 0.1171 0.1192 0.1173 0.1201 

[TRAIN] Epoch[2](630/1500); Loss: 0.144392; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1727 0.1774 0.1630 0.1535 0.1422 0.1391 0.1358 0.1343 0.1365 0.1354 0.1334 0.1347 0.1375 0.1379 0.1372 0.1398 

[TRAIN] Epoch[2](631/1500); Loss: 0.096791; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1440 0.1405 0.1243 0.1079 0.0926 0.0876 0.0855 0.0831 0.0828 0.0839 0.0834 0.0831 0.0842 0.0868 0.0896 0.0894 

[TRAIN] Epoch[2](632/1500); Loss: 0.212537; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2711 0.2757 0.2594 0.2492 0.2275 0.2143 0.2025 0.1949 0.1905 0.1890 0.1882 0.1888 0.1860 0.1863 0.1883 0.1887 

[TRAIN] Epoch[2](633/1500); Loss: 0.105797; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1189 0.1342 0.1284 0.1245 0.1133 0.1024 0.0990 0.0981 0.0971 0.0968 0.0964 0.0956 0.0965 0.0971 0.0973 0.0971 

[TRAIN] Epoch[2](634/1500); Loss: 0.117178; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1387 0.1291 0.1191 0.1194 0.1176 0.1190 0.1115 0.1108 0.1116 0.1159 0.1091 0.1105 0.1145 0.1155 0.1154 0.1171 

[TRAIN] Epoch[2](635/1500); Loss: 0.114571; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1408 0.1632 0.1329 0.1344 0.1261 0.1114 0.1050 0.1041 0.1024 0.1021 0.1009 0.1023 0.1012 0.1012 0.1024 0.1027 

[TRAIN] Epoch[2](636/1500); Loss: 0.139817; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2314 0.2452 0.2191 0.2052 0.1743 0.1457 0.1260 0.1104 0.1011 0.0967 0.0968 0.0978 0.0963 0.0957 0.0968 0.0985 

[TRAIN] Epoch[2](637/1500); Loss: 0.094989; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1240 0.1394 0.1136 0.1160 0.1085 0.0920 0.0882 0.0842 0.0830 0.0825 0.0795 0.0801 0.0808 0.0826 0.0820 0.0835 

[TRAIN] Epoch[2](638/1500); Loss: 0.081875; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1192 0.1115 0.0857 0.0809 0.0787 0.0772 0.0758 0.0737 0.0757 0.0771 0.0742 0.0734 0.0770 0.0753 0.0759 0.0786 

[TRAIN] Epoch[2](639/1500); Loss: 0.108443; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1516 0.1304 0.1130 0.1248 0.1171 0.1108 0.1020 0.1064 0.1003 0.1017 0.0962 0.0974 0.0958 0.0951 0.0964 0.0959 

[TRAIN] Epoch[2](640/1500); Loss: 0.155237; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1896 0.1897 0.1704 0.1712 0.1656 0.1603 0.1535 0.1485 0.1451 0.1462 0.1412 0.1406 0.1389 0.1407 0.1408 0.1412 

[TRAIN] Epoch[2](641/1500); Loss: 0.142586; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1747 0.1797 0.1663 0.1556 0.1422 0.1374 0.1353 0.1334 0.1326 0.1321 0.1308 0.1307 0.1319 0.1333 0.1318 0.1335 

[TRAIN] Epoch[2](642/1500); Loss: 0.061628; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0597 0.0801 0.0650 0.0711 0.0671 0.0632 0.0564 0.0555 0.0536 0.0547 0.0557 0.0575 0.0555 0.0624 0.0648 0.0637 

[TRAIN] Epoch[2](643/1500); Loss: 0.135490; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1761 0.1874 0.1624 0.1639 0.1549 0.1400 0.1281 0.1225 0.1181 0.1164 0.1152 0.1185 0.1149 0.1160 0.1156 0.1179 

[TRAIN] Epoch[2](644/1500); Loss: 0.090643; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1136 0.1245 0.1004 0.0973 0.0918 0.0831 0.0812 0.0814 0.0813 0.0801 0.0816 0.0845 0.0841 0.0861 0.0879 0.0915 

[TRAIN] Epoch[2](645/1500); Loss: 0.097164; Backpropagation: 0.0925 sec; Batch: 0.4241 sec
0.1295 0.1301 0.1234 0.1174 0.1032 0.0955 0.0859 0.0836 0.0826 0.0834 0.0829 0.0848 0.0861 0.0864 0.0882 0.0916 

[TRAIN] Epoch[2](646/1500); Loss: 0.083865; Backpropagation: 0.0915 sec; Batch: 0.4328 sec
0.0951 0.1037 0.1121 0.1036 0.0884 0.0785 0.0749 0.0741 0.0745 0.0772 0.0741 0.0744 0.0774 0.0773 0.0776 0.0790 

[TRAIN] Epoch[2](647/1500); Loss: 0.111195; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.1561 0.1658 0.1256 0.1231 0.1185 0.1023 0.0989 0.0975 0.0963 0.0960 0.0944 0.0979 0.0963 0.1006 0.1037 0.1060 

[TRAIN] Epoch[2](648/1500); Loss: 0.106906; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1566 0.1716 0.1384 0.1327 0.1160 0.0995 0.0909 0.0883 0.0875 0.0894 0.0878 0.0898 0.0882 0.0909 0.0900 0.0929 

[TRAIN] Epoch[2](649/1500); Loss: 0.096447; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1297 0.1377 0.1052 0.1063 0.0959 0.0797 0.0769 0.0767 0.0759 0.0811 0.0846 0.0867 0.0944 0.0991 0.1036 0.1096 

[TRAIN] Epoch[2](650/1500); Loss: 0.180932; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2447 0.2475 0.2331 0.2214 0.2018 0.1876 0.1750 0.1625 0.1549 0.1511 0.1514 0.1508 0.1518 0.1521 0.1543 0.1547 

[TRAIN] Epoch[2](651/1500); Loss: 0.078364; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1065 0.1041 0.0857 0.0831 0.0783 0.0727 0.0710 0.0706 0.0705 0.0728 0.0709 0.0708 0.0719 0.0743 0.0746 0.0758 

[TRAIN] Epoch[2](652/1500); Loss: 0.067664; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1139 0.1281 0.0988 0.0921 0.0796 0.0599 0.0495 0.0475 0.0503 0.0491 0.0485 0.0505 0.0510 0.0524 0.0531 0.0583 

[TRAIN] Epoch[2](653/1500); Loss: 0.105272; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1366 0.1424 0.1259 0.1194 0.1096 0.1012 0.0973 0.0944 0.0943 0.0939 0.0926 0.0935 0.0949 0.0962 0.0960 0.0962 

[TRAIN] Epoch[2](654/1500); Loss: 0.142995; Backpropagation: 0.0918 sec; Batch: 0.4250 sec
0.1763 0.1943 0.1590 0.1608 0.1534 0.1430 0.1404 0.1353 0.1333 0.1316 0.1306 0.1266 0.1260 0.1258 0.1258 0.1258 

[TRAIN] Epoch[2](655/1500); Loss: 0.073340; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0776 0.0854 0.0758 0.0671 0.0646 0.0643 0.0643 0.0662 0.0675 0.0689 0.0698 0.0744 0.0768 0.0785 0.0836 0.0887 

[TRAIN] Epoch[2](656/1500); Loss: 0.103961; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1835 0.1892 0.1696 0.1523 0.1155 0.0861 0.0780 0.0749 0.0741 0.0711 0.0759 0.0790 0.0743 0.0765 0.0804 0.0830 

[TRAIN] Epoch[2](657/1500); Loss: 0.116292; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1586 0.1621 0.1542 0.1459 0.1315 0.1138 0.1060 0.1024 0.0982 0.0977 0.0971 0.0972 0.0974 0.0991 0.0993 0.1001 

[TRAIN] Epoch[2](658/1500); Loss: 0.125698; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1470 0.1450 0.1340 0.1319 0.1238 0.1210 0.1185 0.1206 0.1188 0.1197 0.1192 0.1212 0.1196 0.1220 0.1240 0.1249 

[TRAIN] Epoch[2](659/1500); Loss: 0.112164; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1470 0.1359 0.1178 0.1135 0.1118 0.1075 0.1051 0.1017 0.1013 0.1008 0.1055 0.1052 0.1049 0.1065 0.1141 0.1159 

[TRAIN] Epoch[2](660/1500); Loss: 0.103879; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1431 0.1450 0.1182 0.1138 0.1102 0.0992 0.0956 0.0933 0.0935 0.0930 0.0884 0.0905 0.0932 0.0929 0.0945 0.0979 

[TRAIN] Epoch[2](661/1500); Loss: 0.161994; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2188 0.2186 0.1962 0.1882 0.1759 0.1621 0.1566 0.1487 0.1441 0.1424 0.1421 0.1396 0.1397 0.1405 0.1392 0.1393 

[TRAIN] Epoch[2](662/1500); Loss: 0.061377; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0647 0.0679 0.0588 0.0621 0.0590 0.0565 0.0538 0.0558 0.0537 0.0563 0.0603 0.0593 0.0607 0.0694 0.0711 0.0725 

[TRAIN] Epoch[2](663/1500); Loss: 0.111892; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1480 0.1541 0.1310 0.1282 0.1219 0.1111 0.1059 0.0997 0.0968 0.0960 0.0986 0.0970 0.0972 0.0983 0.1030 0.1036 

[TRAIN] Epoch[2](664/1500); Loss: 0.070333; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1125 0.1124 0.0956 0.0753 0.0610 0.0577 0.0574 0.0561 0.0617 0.0585 0.0570 0.0604 0.0621 0.0624 0.0647 0.0706 

[TRAIN] Epoch[2](665/1500); Loss: 0.122314; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1454 0.1449 0.1336 0.1246 0.1223 0.1163 0.1150 0.1137 0.1163 0.1164 0.1150 0.1150 0.1168 0.1204 0.1196 0.1218 

[TRAIN] Epoch[2](666/1500); Loss: 0.170087; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.3383 0.3511 0.3341 0.2990 0.2278 0.1697 0.1093 0.0836 0.0904 0.0882 0.0888 0.1001 0.1087 0.1045 0.1071 0.1209 

[TRAIN] Epoch[2](667/1500); Loss: 0.076238; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1128 0.1201 0.0984 0.0918 0.0805 0.0687 0.0626 0.0618 0.0615 0.0619 0.0628 0.0644 0.0648 0.0677 0.0697 0.0702 

[TRAIN] Epoch[2](668/1500); Loss: 0.165131; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3095 0.3202 0.3028 0.2732 0.2106 0.1613 0.1118 0.0952 0.0979 0.0948 0.0973 0.1105 0.1126 0.1086 0.1135 0.1222 

[TRAIN] Epoch[2](669/1500); Loss: 0.122284; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1593 0.1635 0.1434 0.1327 0.1201 0.1159 0.1136 0.1111 0.1117 0.1129 0.1110 0.1101 0.1119 0.1137 0.1125 0.1131 

[TRAIN] Epoch[2](670/1500); Loss: 0.205853; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.3019 0.3012 0.2859 0.2658 0.2283 0.2011 0.1779 0.1685 0.1700 0.1689 0.1679 0.1692 0.1703 0.1722 0.1709 0.1736 

[TRAIN] Epoch[2](671/1500); Loss: 0.055235; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0904 0.0991 0.0781 0.0512 0.0507 0.0413 0.0401 0.0411 0.0439 0.0455 0.0436 0.0482 0.0509 0.0495 0.0530 0.0572 

[TRAIN] Epoch[2](672/1500); Loss: 0.077428; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1100 0.1047 0.0873 0.0765 0.0731 0.0702 0.0693 0.0689 0.0709 0.0687 0.0687 0.0705 0.0723 0.0724 0.0766 0.0787 

[TRAIN] Epoch[2](673/1500); Loss: 0.086164; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0999 0.1136 0.0961 0.0939 0.0909 0.0854 0.0845 0.0806 0.0797 0.0790 0.0787 0.0785 0.0787 0.0789 0.0798 0.0805 

[TRAIN] Epoch[2](674/1500); Loss: 0.173930; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2152 0.2129 0.2002 0.1917 0.1815 0.1705 0.1650 0.1630 0.1609 0.1595 0.1592 0.1596 0.1595 0.1596 0.1612 0.1633 

[TRAIN] Epoch[2](675/1500); Loss: 0.108175; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1291 0.1344 0.1163 0.1149 0.1120 0.1046 0.1041 0.1024 0.1010 0.1023 0.1003 0.1011 0.1003 0.1022 0.1025 0.1031 

[TRAIN] Epoch[2](676/1500); Loss: 0.101079; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1249 0.1336 0.1096 0.1084 0.1031 0.0982 0.0957 0.0956 0.0941 0.0948 0.0923 0.0933 0.0925 0.0933 0.0937 0.0941 

[TRAIN] Epoch[2](677/1500); Loss: 0.210171; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2465 0.2448 0.2314 0.2243 0.2144 0.2082 0.2054 0.2026 0.2013 0.2004 0.1978 0.1981 0.1980 0.1967 0.1958 0.1969 

[TRAIN] Epoch[2](678/1500); Loss: 0.158040; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1868 0.1805 0.1707 0.1638 0.1602 0.1575 0.1544 0.1524 0.1513 0.1507 0.1496 0.1496 0.1501 0.1498 0.1501 0.1511 

[TRAIN] Epoch[2](679/1500); Loss: 0.114892; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1453 0.1521 0.1341 0.1291 0.1226 0.1111 0.1071 0.1044 0.1050 0.1039 0.1043 0.1023 0.1033 0.1038 0.1043 0.1055 

[TRAIN] Epoch[2](680/1500); Loss: 0.158234; Backpropagation: 0.0915 sec; Batch: 0.4235 sec
0.2099 0.2117 0.1889 0.1792 0.1665 0.1549 0.1487 0.1443 0.1415 0.1409 0.1394 0.1396 0.1415 0.1422 0.1407 0.1417 

[TRAIN] Epoch[2](681/1500); Loss: 0.144070; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1803 0.1798 0.1615 0.1554 0.1455 0.1400 0.1358 0.1351 0.1338 0.1352 0.1337 0.1330 0.1338 0.1349 0.1335 0.1338 

[TRAIN] Epoch[2](682/1500); Loss: 0.063962; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0718 0.0775 0.0748 0.0649 0.0609 0.0603 0.0600 0.0592 0.0606 0.0603 0.0597 0.0618 0.0625 0.0618 0.0621 0.0653 

[TRAIN] Epoch[2](683/1500); Loss: 0.102673; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1225 0.1282 0.1097 0.1156 0.1103 0.1028 0.0961 0.0967 0.0934 0.0946 0.0949 0.0945 0.0941 0.0957 0.0975 0.0963 

[TRAIN] Epoch[2](684/1500); Loss: 0.099900; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1151 0.1385 0.1123 0.1146 0.1077 0.0998 0.0937 0.0933 0.0915 0.0921 0.0894 0.0898 0.0892 0.0902 0.0913 0.0899 

[TRAIN] Epoch[2](685/1500); Loss: 0.103483; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1485 0.1433 0.1178 0.1124 0.1058 0.0979 0.0911 0.0908 0.0911 0.0909 0.0901 0.0905 0.0929 0.0946 0.0970 0.1009 

[TRAIN] Epoch[2](686/1500); Loss: 0.111076; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1682 0.1723 0.1513 0.1333 0.1108 0.0998 0.0948 0.0940 0.0926 0.0920 0.0920 0.0942 0.0926 0.0942 0.0958 0.0991 

[TRAIN] Epoch[2](687/1500); Loss: 0.143355; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2281 0.2352 0.2121 0.1958 0.1632 0.1359 0.1167 0.1121 0.1109 0.1089 0.1101 0.1114 0.1125 0.1108 0.1131 0.1168 

[TRAIN] Epoch[2](688/1500); Loss: 0.070415; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0898 0.1225 0.0806 0.0865 0.0769 0.0689 0.0571 0.0607 0.0590 0.0640 0.0562 0.0582 0.0580 0.0608 0.0631 0.0643 

[TRAIN] Epoch[2](689/1500); Loss: 0.109387; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1556 0.1687 0.1331 0.1305 0.1236 0.1052 0.0941 0.0916 0.0931 0.0946 0.0910 0.0917 0.0932 0.0946 0.0940 0.0956 

[TRAIN] Epoch[2](690/1500); Loss: 0.136456; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1782 0.1860 0.1683 0.1567 0.1379 0.1276 0.1234 0.1225 0.1212 0.1235 0.1218 0.1213 0.1219 0.1245 0.1252 0.1234 

[TRAIN] Epoch[2](691/1500); Loss: 0.081773; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1051 0.1070 0.0890 0.0951 0.0889 0.0814 0.0738 0.0771 0.0728 0.0763 0.0728 0.0734 0.0722 0.0762 0.0742 0.0732 

[TRAIN] Epoch[2](692/1500); Loss: 0.140424; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1615 0.1647 0.1496 0.1513 0.1459 0.1392 0.1365 0.1344 0.1327 0.1321 0.1332 0.1316 0.1327 0.1336 0.1338 0.1341 

[TRAIN] Epoch[2](693/1500); Loss: 0.110296; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1398 0.1361 0.1154 0.1264 0.1254 0.1125 0.1040 0.1022 0.1024 0.1000 0.0962 0.1010 0.0996 0.0985 0.1008 0.1045 

[TRAIN] Epoch[2](694/1500); Loss: 0.108376; Backpropagation: 0.0916 sec; Batch: 0.4224 sec
0.1466 0.1473 0.1325 0.1242 0.1065 0.1016 0.1004 0.0973 0.0943 0.0960 0.0956 0.0954 0.0952 0.1007 0.0998 0.1008 

[TRAIN] Epoch[2](695/1500); Loss: 0.101328; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1244 0.1468 0.1222 0.1363 0.1278 0.1079 0.0900 0.0814 0.0829 0.0814 0.0826 0.0829 0.0860 0.0871 0.0903 0.0914 

[TRAIN] Epoch[2](696/1500); Loss: 0.134222; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1782 0.1822 0.1648 0.1574 0.1362 0.1247 0.1221 0.1193 0.1166 0.1169 0.1204 0.1195 0.1184 0.1203 0.1262 0.1241 

[TRAIN] Epoch[2](697/1500); Loss: 0.078652; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1262 0.1324 0.1031 0.1040 0.0905 0.0723 0.0635 0.0637 0.0638 0.0615 0.0624 0.0619 0.0618 0.0626 0.0646 0.0641 

[TRAIN] Epoch[2](698/1500); Loss: 0.073754; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1130 0.1131 0.0880 0.0884 0.0835 0.0704 0.0635 0.0627 0.0632 0.0605 0.0601 0.0611 0.0617 0.0628 0.0643 0.0637 

[TRAIN] Epoch[2](699/1500); Loss: 0.156012; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1638 0.1664 0.1596 0.1586 0.1569 0.1539 0.1555 0.1528 0.1529 0.1526 0.1537 0.1535 0.1531 0.1532 0.1544 0.1552 

[TRAIN] Epoch[2](700/1500); Loss: 0.098503; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1435 0.1434 0.1113 0.1089 0.1070 0.0971 0.0878 0.0867 0.0859 0.0830 0.0857 0.0854 0.0852 0.0880 0.0875 0.0900 

[TRAIN] Epoch[2](701/1500); Loss: 0.079898; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0860 0.1014 0.0846 0.1006 0.0976 0.0838 0.0739 0.0723 0.0732 0.0710 0.0709 0.0721 0.0711 0.0720 0.0736 0.0743 

[TRAIN] Epoch[2](702/1500); Loss: 0.070083; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2003 0.1613 0.0780 0.0432 0.0593 0.0553 0.0491 0.0502 0.0540 0.0470 0.0503 0.0510 0.0531 0.0531 0.0576 0.0585 

[TRAIN] Epoch[2](703/1500); Loss: 0.143235; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1750 0.1795 0.1607 0.1628 0.1536 0.1407 0.1339 0.1316 0.1307 0.1302 0.1299 0.1311 0.1317 0.1321 0.1331 0.1352 

[TRAIN] Epoch[2](704/1500); Loss: 0.118220; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1404 0.1392 0.1237 0.1223 0.1192 0.1128 0.1104 0.1114 0.1119 0.1095 0.1121 0.1139 0.1134 0.1151 0.1182 0.1179 

[TRAIN] Epoch[2](705/1500); Loss: 0.109713; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1482 0.1310 0.0990 0.1197 0.1120 0.1068 0.1041 0.1065 0.0992 0.1006 0.1026 0.1041 0.0992 0.1043 0.1098 0.1085 

[TRAIN] Epoch[2](706/1500); Loss: 0.099220; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1751 0.2003 0.1516 0.1676 0.1575 0.1250 0.0787 0.0563 0.0577 0.0601 0.0551 0.0577 0.0615 0.0595 0.0596 0.0643 

[TRAIN] Epoch[2](707/1500); Loss: 0.160769; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1843 0.1893 0.1719 0.1724 0.1661 0.1580 0.1548 0.1538 0.1532 0.1514 0.1521 0.1522 0.1522 0.1525 0.1536 0.1545 

[TRAIN] Epoch[2](708/1500); Loss: 0.097157; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1104 0.1231 0.1053 0.1100 0.1079 0.0970 0.0933 0.0888 0.0902 0.0895 0.0880 0.0883 0.0889 0.0898 0.0911 0.0929 

[TRAIN] Epoch[2](709/1500); Loss: 0.116205; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1338 0.1352 0.1225 0.1183 0.1146 0.1093 0.1097 0.1096 0.1092 0.1116 0.1112 0.1124 0.1147 0.1148 0.1147 0.1176 

[TRAIN] Epoch[2](710/1500); Loss: 0.078056; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1571 0.1400 0.1124 0.0916 0.0593 0.0547 0.0579 0.0553 0.0523 0.0588 0.0649 0.0598 0.0636 0.0750 0.0729 0.0734 

[TRAIN] Epoch[2](711/1500); Loss: 0.119289; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1400 0.1474 0.1407 0.1377 0.1284 0.1179 0.1104 0.1092 0.1086 0.1071 0.1074 0.1088 0.1088 0.1107 0.1123 0.1132 

[TRAIN] Epoch[2](712/1500); Loss: 0.091146; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1665 0.1554 0.1348 0.1133 0.0762 0.0728 0.0708 0.0757 0.0708 0.0688 0.0754 0.0731 0.0724 0.0767 0.0769 0.0787 

[TRAIN] Epoch[2](713/1500); Loss: 0.138261; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1758 0.1795 0.1613 0.1602 0.1525 0.1394 0.1284 0.1256 0.1243 0.1228 0.1218 0.1217 0.1233 0.1238 0.1247 0.1271 

[TRAIN] Epoch[2](714/1500); Loss: 0.196898; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.3124 0.2972 0.2832 0.2504 0.1956 0.1549 0.1592 0.1609 0.1615 0.1595 0.1617 0.1672 0.1673 0.1685 0.1736 0.1774 

[TRAIN] Epoch[2](715/1500); Loss: 0.122869; Backpropagation: 0.0925 sec; Batch: 0.4236 sec
0.1367 0.1358 0.1270 0.1326 0.1303 0.1235 0.1204 0.1182 0.1176 0.1163 0.1167 0.1174 0.1165 0.1172 0.1199 0.1196 

[TRAIN] Epoch[2](716/1500); Loss: 0.174216; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1913 0.1992 0.1952 0.1884 0.1766 0.1684 0.1688 0.1666 0.1657 0.1664 0.1664 0.1656 0.1650 0.1686 0.1679 0.1674 

[TRAIN] Epoch[2](717/1500); Loss: 0.115581; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1341 0.1331 0.1198 0.1197 0.1173 0.1118 0.1109 0.1105 0.1097 0.1092 0.1105 0.1112 0.1115 0.1122 0.1129 0.1148 

[TRAIN] Epoch[2](718/1500); Loss: 0.133945; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1529 0.1537 0.1390 0.1396 0.1374 0.1318 0.1306 0.1289 0.1279 0.1274 0.1274 0.1275 0.1276 0.1293 0.1307 0.1314 

[TRAIN] Epoch[2](719/1500); Loss: 0.148796; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3249 0.3028 0.2791 0.2343 0.1498 0.0845 0.0825 0.0926 0.0890 0.0976 0.0950 0.1050 0.1024 0.1064 0.1146 0.1203 

[TRAIN] Epoch[2](720/1500); Loss: 0.053697; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0844 0.0825 0.0567 0.0573 0.0517 0.0455 0.0458 0.0457 0.0457 0.0477 0.0474 0.0472 0.0485 0.0503 0.0506 0.0522 

[TRAIN] Epoch[2](721/1500); Loss: 0.128718; Backpropagation: 0.0923 sec; Batch: 0.4233 sec
0.1461 0.1501 0.1427 0.1325 0.1280 0.1245 0.1237 0.1228 0.1238 0.1237 0.1219 0.1224 0.1234 0.1230 0.1244 0.1264 

[TRAIN] Epoch[2](722/1500); Loss: 0.158722; Backpropagation: 0.0915 sec; Batch: 0.4233 sec
0.2104 0.2053 0.1872 0.1768 0.1657 0.1549 0.1478 0.1460 0.1452 0.1434 0.1427 0.1412 0.1423 0.1428 0.1434 0.1445 

[TRAIN] Epoch[2](723/1500); Loss: 0.126343; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1840 0.1790 0.1658 0.1508 0.1325 0.1166 0.1096 0.1086 0.1073 0.1067 0.1068 0.1079 0.1086 0.1109 0.1121 0.1143 

[TRAIN] Epoch[2](724/1500); Loss: 0.096280; Backpropagation: 0.0915 sec; Batch: 0.4234 sec
0.2160 0.1903 0.1447 0.1030 0.0791 0.0792 0.0744 0.0717 0.0733 0.0714 0.0698 0.0689 0.0734 0.0732 0.0753 0.0767 

[TRAIN] Epoch[2](725/1500); Loss: 0.079506; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1272 0.1172 0.0906 0.0880 0.0850 0.0753 0.0711 0.0699 0.0693 0.0681 0.0678 0.0671 0.0676 0.0690 0.0691 0.0700 

[TRAIN] Epoch[2](726/1500); Loss: 0.091222; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1173 0.1229 0.1029 0.1014 0.0958 0.0850 0.0829 0.0801 0.0808 0.0797 0.0819 0.0827 0.0843 0.0857 0.0874 0.0888 

[TRAIN] Epoch[2](727/1500); Loss: 0.098760; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1278 0.1468 0.1112 0.1186 0.1117 0.0949 0.0940 0.0877 0.0876 0.0854 0.0849 0.0854 0.0840 0.0837 0.0869 0.0895 

[TRAIN] Epoch[2](728/1500); Loss: 0.070374; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1013 0.0944 0.0659 0.0756 0.0770 0.0678 0.0694 0.0620 0.0657 0.0630 0.0627 0.0628 0.0624 0.0640 0.0672 0.0647 

[TRAIN] Epoch[2](729/1500); Loss: 0.150522; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.1873 0.1853 0.1738 0.1686 0.1561 0.1462 0.1418 0.1418 0.1398 0.1394 0.1368 0.1373 0.1369 0.1386 0.1386 0.1400 

[TRAIN] Epoch[2](730/1500); Loss: 0.073816; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.0991 0.0938 0.0861 0.0796 0.0757 0.0706 0.0674 0.0666 0.0656 0.0658 0.0666 0.0666 0.0676 0.0691 0.0695 0.0714 

[TRAIN] Epoch[2](731/1500); Loss: 0.105507; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1572 0.1436 0.1196 0.1038 0.0990 0.0950 0.0934 0.0941 0.0936 0.0943 0.0952 0.0967 0.0975 0.0994 0.1018 0.1040 

[TRAIN] Epoch[2](732/1500); Loss: 0.156287; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1843 0.1876 0.1756 0.1741 0.1672 0.1543 0.1498 0.1488 0.1481 0.1447 0.1464 0.1448 0.1442 0.1427 0.1444 0.1437 

[TRAIN] Epoch[2](733/1500); Loss: 0.106821; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1334 0.1312 0.1214 0.1127 0.1056 0.1000 0.0983 0.0979 0.0983 0.0983 0.0991 0.0992 0.1014 0.1032 0.1038 0.1054 

[TRAIN] Epoch[2](734/1500); Loss: 0.097200; Backpropagation: 0.0917 sec; Batch: 0.4245 sec
0.1521 0.1379 0.1075 0.1050 0.1046 0.0971 0.0882 0.0791 0.0814 0.0800 0.0801 0.0825 0.0861 0.0859 0.0906 0.0971 

[TRAIN] Epoch[2](735/1500); Loss: 0.132099; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1471 0.1464 0.1356 0.1364 0.1357 0.1320 0.1310 0.1273 0.1276 0.1279 0.1275 0.1261 0.1278 0.1281 0.1282 0.1287 

[TRAIN] Epoch[2](736/1500); Loss: 0.081683; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1842 0.1326 0.0615 0.0790 0.0879 0.0726 0.0710 0.0630 0.0743 0.0656 0.0705 0.0650 0.0708 0.0675 0.0694 0.0722 

[TRAIN] Epoch[2](737/1500); Loss: 0.139193; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1684 0.1628 0.1558 0.1484 0.1411 0.1316 0.1309 0.1305 0.1315 0.1311 0.1302 0.1308 0.1329 0.1331 0.1334 0.1344 

[TRAIN] Epoch[2](738/1500); Loss: 0.092645; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1159 0.1184 0.0975 0.1084 0.1035 0.0926 0.0868 0.0860 0.0821 0.0812 0.0811 0.0852 0.0830 0.0849 0.0859 0.0899 

[TRAIN] Epoch[2](739/1500); Loss: 0.085592; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1094 0.1227 0.0924 0.0996 0.0949 0.0829 0.0787 0.0763 0.0773 0.0758 0.0755 0.0754 0.0764 0.0772 0.0770 0.0779 

[TRAIN] Epoch[2](740/1500); Loss: 0.081071; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1034 0.1060 0.0955 0.0948 0.0864 0.0785 0.0743 0.0711 0.0709 0.0720 0.0715 0.0711 0.0732 0.0749 0.0760 0.0777 

[TRAIN] Epoch[2](741/1500); Loss: 0.071887; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1045 0.1150 0.0946 0.0959 0.0853 0.0677 0.0601 0.0583 0.0577 0.0554 0.0563 0.0569 0.0582 0.0598 0.0614 0.0631 

[TRAIN] Epoch[2](742/1500); Loss: 0.120803; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1317 0.1407 0.1299 0.1336 0.1290 0.1200 0.1152 0.1133 0.1123 0.1129 0.1135 0.1141 0.1148 0.1159 0.1170 0.1188 

[TRAIN] Epoch[2](743/1500); Loss: 0.144513; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1548 0.1510 0.1631 0.1734 0.1629 0.1440 0.1341 0.1321 0.1319 0.1313 0.1329 0.1345 0.1365 0.1397 0.1435 0.1465 

[TRAIN] Epoch[2](744/1500); Loss: 0.089823; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0992 0.1205 0.1133 0.1176 0.1102 0.0969 0.0851 0.0765 0.0737 0.0732 0.0730 0.0741 0.0772 0.0798 0.0822 0.0848 

[TRAIN] Epoch[2](745/1500); Loss: 0.141796; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1766 0.1683 0.1627 0.1674 0.1537 0.1360 0.1279 0.1255 0.1232 0.1245 0.1268 0.1287 0.1314 0.1352 0.1388 0.1419 

[TRAIN] Epoch[2](746/1500); Loss: 0.092643; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1413 0.1460 0.1350 0.1232 0.0985 0.0786 0.0720 0.0705 0.0701 0.0708 0.0729 0.0745 0.0776 0.0803 0.0831 0.0879 

[TRAIN] Epoch[2](747/1500); Loss: 0.133620; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1117 0.0693 0.1412 0.1809 0.1785 0.1681 0.1538 0.1322 0.1228 0.1119 0.1122 0.1127 0.1214 0.1293 0.1411 0.1506 

[TRAIN] Epoch[2](748/1500); Loss: 0.193989; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2107 0.2145 0.2306 0.2372 0.2231 0.2045 0.1908 0.1800 0.1741 0.1710 0.1710 0.1727 0.1741 0.1785 0.1833 0.1875 

[TRAIN] Epoch[2](749/1500); Loss: 0.171843; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2381 0.2537 0.2629 0.2572 0.2319 0.2010 0.1749 0.1503 0.1316 0.1187 0.1141 0.1150 0.1181 0.1218 0.1270 0.1332 

[TRAIN] Epoch[2](750/1500); Loss: 0.119812; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1261 0.0932 0.1238 0.1550 0.1528 0.1379 0.1197 0.1043 0.0982 0.0975 0.1016 0.1080 0.1141 0.1205 0.1283 0.1360 

[TRAIN] Epoch[2](751/1500); Loss: 0.156394; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1843 0.1789 0.2019 0.2058 0.1896 0.1663 0.1483 0.1351 0.1294 0.1295 0.1315 0.1332 0.1368 0.1403 0.1432 0.1480 

[TRAIN] Epoch[2](752/1500); Loss: 0.149997; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1695 0.1718 0.1693 0.1669 0.1568 0.1469 0.1419 0.1391 0.1374 0.1373 0.1386 0.1404 0.1422 0.1446 0.1474 0.1500 

[TRAIN] Epoch[2](753/1500); Loss: 0.164079; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1739 0.1937 0.2120 0.2259 0.2138 0.1899 0.1740 0.1551 0.1465 0.1356 0.1330 0.1302 0.1315 0.1324 0.1370 0.1408 

[TRAIN] Epoch[2](754/1500); Loss: 0.093745; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1071 0.1181 0.1120 0.1166 0.1071 0.0956 0.0892 0.0838 0.0805 0.0787 0.0790 0.0802 0.0830 0.0860 0.0894 0.0938 

[TRAIN] Epoch[2](755/1500); Loss: 0.128262; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1514 0.1445 0.1471 0.1549 0.1422 0.1260 0.1157 0.1102 0.1095 0.1111 0.1137 0.1161 0.1197 0.1252 0.1301 0.1346 

[TRAIN] Epoch[2](756/1500); Loss: 0.110502; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1482 0.1354 0.1034 0.1121 0.1070 0.1002 0.0963 0.0951 0.0972 0.0990 0.1015 0.1056 0.1100 0.1147 0.1183 0.1242 

[TRAIN] Epoch[2](757/1500); Loss: 0.181010; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.2081 0.2232 0.2252 0.2327 0.2201 0.1980 0.1854 0.1696 0.1617 0.1533 0.1514 0.1500 0.1509 0.1519 0.1554 0.1591 

[TRAIN] Epoch[2](758/1500); Loss: 0.158492; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1662 0.1910 0.2064 0.2260 0.2146 0.1882 0.1754 0.1525 0.1420 0.1269 0.1223 0.1188 0.1216 0.1234 0.1290 0.1315 

[TRAIN] Epoch[2](759/1500); Loss: 0.182903; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1842 0.1920 0.2040 0.2228 0.2142 0.1951 0.1873 0.1749 0.1711 0.1666 0.1662 0.1653 0.1671 0.1682 0.1721 0.1753 

[TRAIN] Epoch[2](760/1500); Loss: 0.084916; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1086 0.1101 0.0994 0.0902 0.0803 0.0758 0.0748 0.0744 0.0754 0.0758 0.0763 0.0781 0.0814 0.0835 0.0851 0.0894 

[TRAIN] Epoch[2](761/1500); Loss: 0.151537; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1629 0.1700 0.1655 0.1779 0.1701 0.1556 0.1519 0.1439 0.1409 0.1390 0.1384 0.1385 0.1393 0.1416 0.1433 0.1457 

[TRAIN] Epoch[2](762/1500); Loss: 0.165556; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2077 0.2145 0.1925 0.2012 0.1941 0.1754 0.1647 0.1530 0.1473 0.1423 0.1403 0.1396 0.1402 0.1422 0.1450 0.1489 

[TRAIN] Epoch[2](763/1500); Loss: 0.108383; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1227 0.1312 0.1282 0.1441 0.1336 0.1130 0.1053 0.0943 0.0912 0.0886 0.0896 0.0895 0.0948 0.0988 0.1028 0.1064 

[TRAIN] Epoch[2](764/1500); Loss: 0.157783; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1768 0.1793 0.1740 0.1751 0.1647 0.1543 0.1493 0.1468 0.1453 0.1457 0.1478 0.1497 0.1509 0.1523 0.1549 0.1574 

[TRAIN] Epoch[2](765/1500); Loss: 0.172863; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2416 0.2390 0.2176 0.2109 0.1951 0.1813 0.1697 0.1604 0.1511 0.1464 0.1425 0.1401 0.1400 0.1408 0.1428 0.1464 

[TRAIN] Epoch[2](766/1500); Loss: 0.090069; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1034 0.1130 0.0890 0.1100 0.1015 0.0829 0.0795 0.0726 0.0754 0.0760 0.0799 0.0818 0.0893 0.0911 0.0967 0.0991 

[TRAIN] Epoch[2](767/1500); Loss: 0.143255; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1570 0.1624 0.1534 0.1484 0.1424 0.1391 0.1376 0.1365 0.1358 0.1364 0.1375 0.1382 0.1393 0.1410 0.1426 0.1444 

[TRAIN] Epoch[2](768/1500); Loss: 0.085870; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1773 0.1443 0.0540 0.0861 0.0793 0.0623 0.0581 0.0582 0.0686 0.0674 0.0712 0.0745 0.0894 0.0888 0.0945 0.0998 

[TRAIN] Epoch[2](769/1500); Loss: 0.110698; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.1443 0.1425 0.1180 0.1167 0.1101 0.1047 0.1029 0.1017 0.1005 0.1006 0.1013 0.1020 0.1033 0.1053 0.1071 0.1101 

[TRAIN] Epoch[2](770/1500); Loss: 0.148110; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1706 0.1763 0.1696 0.1635 0.1537 0.1457 0.1406 0.1381 0.1374 0.1365 0.1364 0.1381 0.1393 0.1399 0.1409 0.1432 

[TRAIN] Epoch[2](771/1500); Loss: 0.146090; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1573 0.1590 0.1520 0.1499 0.1471 0.1448 0.1428 0.1408 0.1402 0.1393 0.1394 0.1412 0.1428 0.1447 0.1466 0.1497 

[TRAIN] Epoch[2](772/1500); Loss: 0.131306; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1543 0.1554 0.1504 0.1415 0.1357 0.1305 0.1260 0.1221 0.1209 0.1204 0.1206 0.1210 0.1225 0.1246 0.1261 0.1287 

[TRAIN] Epoch[2](773/1500); Loss: 0.101439; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1195 0.1194 0.1124 0.1102 0.1033 0.0986 0.0969 0.0956 0.0943 0.0934 0.0939 0.0946 0.0952 0.0966 0.0986 0.1005 

[TRAIN] Epoch[2](774/1500); Loss: 0.105514; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1392 0.1397 0.1207 0.1183 0.1089 0.1019 0.0992 0.0974 0.0949 0.0939 0.0943 0.0937 0.0933 0.0955 0.0977 0.0999 

[TRAIN] Epoch[2](775/1500); Loss: 0.084419; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1076 0.1121 0.1025 0.0936 0.0822 0.0760 0.0745 0.0743 0.0747 0.0753 0.0763 0.0772 0.0782 0.0801 0.0823 0.0840 

[TRAIN] Epoch[2](776/1500); Loss: 0.076654; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1129 0.1044 0.0779 0.1029 0.0919 0.0708 0.0651 0.0560 0.0554 0.0587 0.0629 0.0638 0.0683 0.0716 0.0814 0.0826 

[TRAIN] Epoch[2](777/1500); Loss: 0.163175; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1836 0.1796 0.1672 0.1619 0.1588 0.1574 0.1566 0.1561 0.1562 0.1571 0.1579 0.1594 0.1613 0.1636 0.1659 0.1682 

[TRAIN] Epoch[2](778/1500); Loss: 0.077353; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0957 0.0901 0.0870 0.0833 0.0770 0.0719 0.0709 0.0695 0.0695 0.0705 0.0715 0.0723 0.0739 0.0763 0.0781 0.0801 

[TRAIN] Epoch[2](779/1500); Loss: 0.072958; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1287 0.1307 0.1150 0.0990 0.0752 0.0607 0.0533 0.0500 0.0512 0.0525 0.0540 0.0551 0.0571 0.0593 0.0616 0.0639 

[TRAIN] Epoch[2](780/1500); Loss: 0.120655; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1602 0.1664 0.1592 0.1567 0.1411 0.1260 0.1156 0.1076 0.1010 0.0971 0.0962 0.0978 0.0991 0.0999 0.1017 0.1050 

[TRAIN] Epoch[2](781/1500); Loss: 0.085822; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0987 0.1107 0.1029 0.1023 0.0901 0.0777 0.0741 0.0748 0.0747 0.0755 0.0763 0.0791 0.0806 0.0822 0.0851 0.0884 

[TRAIN] Epoch[2](782/1500); Loss: 0.062168; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0702 0.0776 0.0807 0.0703 0.0593 0.0546 0.0542 0.0538 0.0541 0.0551 0.0562 0.0582 0.0590 0.0605 0.0643 0.0666 

[TRAIN] Epoch[2](783/1500); Loss: 0.126421; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1425 0.1424 0.1304 0.1295 0.1263 0.1239 0.1215 0.1203 0.1198 0.1201 0.1204 0.1219 0.1234 0.1246 0.1269 0.1289 

[TRAIN] Epoch[2](784/1500); Loss: 0.141811; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1566 0.1670 0.1602 0.1597 0.1509 0.1417 0.1374 0.1336 0.1306 0.1293 0.1296 0.1303 0.1320 0.1345 0.1374 0.1381 

[TRAIN] Epoch[2](785/1500); Loss: 0.174913; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2030 0.2034 0.1965 0.1908 0.1840 0.1779 0.1725 0.1686 0.1650 0.1630 0.1621 0.1618 0.1612 0.1615 0.1632 0.1640 

[TRAIN] Epoch[2](786/1500); Loss: 0.117592; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1373 0.1429 0.1313 0.1363 0.1276 0.1179 0.1133 0.1096 0.1072 0.1063 0.1062 0.1066 0.1077 0.1084 0.1101 0.1127 

[TRAIN] Epoch[2](787/1500); Loss: 0.087775; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1268 0.1268 0.0871 0.0959 0.0876 0.0778 0.0754 0.0773 0.0748 0.0750 0.0777 0.0806 0.0810 0.0829 0.0880 0.0897 

[TRAIN] Epoch[2](788/1500); Loss: 0.165462; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2152 0.2112 0.2054 0.1895 0.1801 0.1681 0.1593 0.1532 0.1500 0.1467 0.1450 0.1441 0.1444 0.1438 0.1445 0.1470 

[TRAIN] Epoch[2](789/1500); Loss: 0.108553; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1779 0.1661 0.0867 0.1131 0.1143 0.1050 0.0955 0.0923 0.0936 0.0955 0.0941 0.0950 0.0990 0.1005 0.1017 0.1066 

[TRAIN] Epoch[2](790/1500); Loss: 0.121423; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2105 0.2005 0.1875 0.1725 0.1523 0.1298 0.1122 0.0994 0.0890 0.0839 0.0822 0.0837 0.0837 0.0839 0.0846 0.0872 

[TRAIN] Epoch[2](791/1500); Loss: 0.181233; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2189 0.2163 0.2108 0.1991 0.1925 0.1839 0.1768 0.1723 0.1694 0.1670 0.1654 0.1648 0.1651 0.1648 0.1655 0.1671 

[TRAIN] Epoch[2](792/1500); Loss: 0.145005; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2069 0.2039 0.1800 0.1694 0.1606 0.1484 0.1400 0.1321 0.1274 0.1237 0.1217 0.1210 0.1212 0.1213 0.1208 0.1217 

[TRAIN] Epoch[2](793/1500); Loss: 0.162963; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1675 0.1688 0.1644 0.1621 0.1599 0.1589 0.1582 0.1589 0.1596 0.1606 0.1612 0.1626 0.1638 0.1651 0.1670 0.1689 

[TRAIN] Epoch[2](794/1500); Loss: 0.093872; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1358 0.1359 0.1028 0.1035 0.0955 0.0873 0.0843 0.0818 0.0814 0.0814 0.0826 0.0827 0.0835 0.0862 0.0879 0.0895 

[TRAIN] Epoch[2](795/1500); Loss: 0.111187; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1498 0.1543 0.1375 0.1342 0.1174 0.1125 0.1055 0.1011 0.0994 0.0966 0.0938 0.0935 0.0951 0.0949 0.0956 0.0977 

[TRAIN] Epoch[2](796/1500); Loss: 0.129367; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1407 0.1517 0.1519 0.1488 0.1367 0.1286 0.1234 0.1224 0.1208 0.1206 0.1206 0.1204 0.1201 0.1208 0.1213 0.1211 

[TRAIN] Epoch[2](797/1500); Loss: 0.138410; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1778 0.1792 0.1712 0.1661 0.1550 0.1403 0.1315 0.1255 0.1222 0.1205 0.1204 0.1201 0.1207 0.1207 0.1211 0.1223 

[TRAIN] Epoch[2](798/1500); Loss: 0.138159; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1640 0.1682 0.1540 0.1533 0.1428 0.1346 0.1297 0.1283 0.1274 0.1274 0.1282 0.1287 0.1299 0.1308 0.1313 0.1319 

[TRAIN] Epoch[2](799/1500); Loss: 0.137074; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1437 0.1451 0.1397 0.1377 0.1346 0.1336 0.1335 0.1334 0.1338 0.1341 0.1350 0.1357 0.1364 0.1375 0.1390 0.1402 

[TRAIN] Epoch[2](800/1500); Loss: 0.095507; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1230 0.1178 0.1099 0.1039 0.0989 0.0937 0.0903 0.0879 0.0870 0.0861 0.0863 0.0871 0.0879 0.0882 0.0895 0.0907 

[TRAIN] Epoch[2](801/1500); Loss: 0.091071; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1232 0.1362 0.1289 0.1242 0.1066 0.0959 0.0862 0.0790 0.0751 0.0727 0.0714 0.0711 0.0715 0.0711 0.0715 0.0726 

[TRAIN] Epoch[2](802/1500); Loss: 0.109658; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1600 0.1720 0.1607 0.1519 0.1294 0.1126 0.0975 0.0890 0.0859 0.0841 0.0848 0.0842 0.0851 0.0849 0.0861 0.0862 

[TRAIN] Epoch[2](803/1500); Loss: 0.099649; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1041 0.1126 0.1369 0.1418 0.1289 0.1071 0.0939 0.0846 0.0818 0.0824 0.0828 0.0839 0.0875 0.0871 0.0879 0.0910 

[TRAIN] Epoch[2](804/1500); Loss: 0.167551; Backpropagation: 0.0916 sec; Batch: 0.4245 sec
0.2089 0.2043 0.1947 0.1879 0.1806 0.1721 0.1656 0.1601 0.1559 0.1526 0.1504 0.1495 0.1491 0.1489 0.1495 0.1509 

[TRAIN] Epoch[2](805/1500); Loss: 0.121480; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1481 0.1543 0.1453 0.1431 0.1300 0.1232 0.1164 0.1123 0.1091 0.1077 0.1079 0.1086 0.1081 0.1090 0.1106 0.1102 

[TRAIN] Epoch[2](806/1500); Loss: 0.116065; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1618 0.1640 0.1478 0.1328 0.1195 0.1097 0.1040 0.1016 0.1004 0.0999 0.1004 0.1012 0.1013 0.1026 0.1041 0.1060 

[TRAIN] Epoch[2](807/1500); Loss: 0.135384; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1608 0.1639 0.1615 0.1578 0.1473 0.1389 0.1316 0.1267 0.1240 0.1226 0.1210 0.1207 0.1212 0.1222 0.1224 0.1235 

[TRAIN] Epoch[2](808/1500); Loss: 0.115039; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1269 0.1363 0.1537 0.1543 0.1392 0.1200 0.1087 0.1016 0.0991 0.0985 0.0984 0.0984 0.0996 0.1006 0.1023 0.1031 

[TRAIN] Epoch[2](809/1500); Loss: 0.160842; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1920 0.1899 0.2050 0.2058 0.1960 0.1754 0.1656 0.1505 0.1428 0.1370 0.1350 0.1347 0.1360 0.1351 0.1357 0.1368 

[TRAIN] Epoch[2](810/1500); Loss: 0.086549; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0902 0.1003 0.1082 0.1074 0.0957 0.0848 0.0806 0.0795 0.0775 0.0781 0.0794 0.0789 0.0789 0.0808 0.0821 0.0823 

[TRAIN] Epoch[2](811/1500); Loss: 0.114484; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1519 0.1597 0.1554 0.1489 0.1313 0.1175 0.1062 0.1001 0.0975 0.0945 0.0937 0.0942 0.0956 0.0947 0.0945 0.0959 

[TRAIN] Epoch[2](812/1500); Loss: 0.188648; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2311 0.2302 0.2256 0.2187 0.2102 0.2006 0.1935 0.1860 0.1788 0.1726 0.1670 0.1627 0.1609 0.1602 0.1600 0.1603 

[TRAIN] Epoch[2](813/1500); Loss: 0.140530; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1855 0.1814 0.1507 0.1518 0.1442 0.1384 0.1345 0.1330 0.1301 0.1293 0.1286 0.1280 0.1279 0.1282 0.1280 0.1289 

[TRAIN] Epoch[2](814/1500); Loss: 0.105853; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1626 0.1612 0.1435 0.1342 0.1188 0.1052 0.0945 0.0885 0.0859 0.0851 0.0854 0.0856 0.0847 0.0856 0.0862 0.0866 

[TRAIN] Epoch[2](815/1500); Loss: 0.140552; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1580 0.1591 0.1569 0.1547 0.1479 0.1420 0.1391 0.1368 0.1344 0.1325 0.1317 0.1314 0.1309 0.1308 0.1313 0.1315 

[TRAIN] Epoch[2](816/1500); Loss: 0.067695; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1744 0.1436 0.0365 0.0819 0.0771 0.0604 0.0493 0.0439 0.0481 0.0493 0.0461 0.0488 0.0567 0.0562 0.0547 0.0560 

[TRAIN] Epoch[2](817/1500); Loss: 0.110861; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1223 0.1388 0.1412 0.1393 0.1212 0.1087 0.1014 0.0991 0.0982 0.0986 0.0987 0.0999 0.1002 0.1008 0.1020 0.1033 

[TRAIN] Epoch[2](818/1500); Loss: 0.103559; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1104 0.1128 0.1101 0.1088 0.1042 0.1024 0.1018 0.1015 0.1006 0.1007 0.1001 0.1001 0.1005 0.1005 0.1008 0.1016 

[TRAIN] Epoch[2](819/1500); Loss: 0.106912; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1151 0.1157 0.1163 0.1138 0.1084 0.1028 0.1013 0.0997 0.1004 0.1017 0.1038 0.1037 0.1052 0.1061 0.1080 0.1086 

[TRAIN] Epoch[2](820/1500); Loss: 0.070948; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0963 0.0952 0.0888 0.0822 0.0754 0.0705 0.0666 0.0626 0.0604 0.0607 0.0602 0.0609 0.0618 0.0630 0.0646 0.0661 

[TRAIN] Epoch[2](821/1500); Loss: 0.109201; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1602 0.1274 0.1050 0.1576 0.1637 0.1492 0.1277 0.1108 0.0902 0.0795 0.0720 0.0754 0.0781 0.0803 0.0832 0.0869 

[TRAIN] Epoch[2](822/1500); Loss: 0.075312; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0813 0.1027 0.1098 0.1058 0.0860 0.0728 0.0655 0.0617 0.0616 0.0616 0.0633 0.0644 0.0652 0.0655 0.0673 0.0702 

[TRAIN] Epoch[2](823/1500); Loss: 0.084309; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1212 0.1421 0.1385 0.1317 0.1078 0.0935 0.0775 0.0663 0.0600 0.0562 0.0567 0.0582 0.0584 0.0583 0.0603 0.0622 

[TRAIN] Epoch[2](824/1500); Loss: 0.146736; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1701 0.1722 0.1696 0.1638 0.1542 0.1469 0.1409 0.1379 0.1364 0.1360 0.1353 0.1354 0.1360 0.1367 0.1375 0.1387 

[TRAIN] Epoch[2](825/1500); Loss: 0.153138; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1782 0.1873 0.2018 0.2028 0.1921 0.1743 0.1604 0.1478 0.1390 0.1318 0.1261 0.1242 0.1215 0.1199 0.1209 0.1220 

[TRAIN] Epoch[2](826/1500); Loss: 0.141145; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1794 0.1774 0.1791 0.1717 0.1601 0.1448 0.1327 0.1231 0.1208 0.1223 0.1221 0.1224 0.1235 0.1258 0.1263 0.1267 

[TRAIN] Epoch[2](827/1500); Loss: 0.097450; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1203 0.1312 0.1359 0.1379 0.1229 0.1063 0.0930 0.0861 0.0824 0.0783 0.0768 0.0766 0.0772 0.0771 0.0780 0.0790 

[TRAIN] Epoch[2](828/1500); Loss: 0.106309; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1939 0.2032 0.1921 0.1820 0.1537 0.1332 0.1062 0.0821 0.0632 0.0560 0.0541 0.0551 0.0556 0.0564 0.0565 0.0576 

[TRAIN] Epoch[2](829/1500); Loss: 0.097287; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1268 0.1201 0.1133 0.1044 0.0992 0.0948 0.0920 0.0898 0.0889 0.0883 0.0885 0.0884 0.0888 0.0900 0.0912 0.0921 

[TRAIN] Epoch[2](830/1500); Loss: 0.143530; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2801 0.2622 0.2521 0.2211 0.2047 0.1748 0.1516 0.1228 0.0980 0.0787 0.0717 0.0743 0.0773 0.0746 0.0751 0.0776 

[TRAIN] Epoch[2](831/1500); Loss: 0.107376; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1618 0.1485 0.1437 0.1310 0.1179 0.1022 0.0936 0.0913 0.0919 0.0890 0.0892 0.0896 0.0921 0.0900 0.0920 0.0943 

[TRAIN] Epoch[2](832/1500); Loss: 0.113149; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1257 0.1169 0.1339 0.1589 0.1536 0.1336 0.1181 0.1039 0.0962 0.0960 0.0943 0.0951 0.0952 0.0956 0.0964 0.0970 

[TRAIN] Epoch[2](833/1500); Loss: 0.107730; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1373 0.1269 0.1142 0.1122 0.1084 0.1047 0.1040 0.1020 0.1005 0.1005 0.1009 0.1008 0.1014 0.1027 0.1032 0.1040 

[TRAIN] Epoch[2](834/1500); Loss: 0.075620; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1738 0.1541 0.1357 0.1033 0.0796 0.0556 0.0490 0.0480 0.0492 0.0481 0.0526 0.0504 0.0503 0.0508 0.0548 0.0548 

[TRAIN] Epoch[2](835/1500); Loss: 0.140437; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1637 0.1581 0.1526 0.1478 0.1423 0.1380 0.1364 0.1353 0.1338 0.1329 0.1330 0.1336 0.1335 0.1342 0.1355 0.1363 

[TRAIN] Epoch[2](836/1500); Loss: 0.165034; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2042 0.1946 0.1741 0.1721 0.1686 0.1649 0.1605 0.1582 0.1564 0.1554 0.1559 0.1545 0.1547 0.1552 0.1557 0.1556 

[TRAIN] Epoch[2](837/1500); Loss: 0.117576; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1792 0.1692 0.1234 0.1284 0.1234 0.1156 0.1084 0.1048 0.1029 0.1024 0.1028 0.1016 0.1016 0.1045 0.1065 0.1065 

[TRAIN] Epoch[2](838/1500); Loss: 0.220267; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2619 0.2652 0.2594 0.2474 0.2369 0.2259 0.2175 0.2101 0.2049 0.2021 0.1982 0.1971 0.1983 0.1990 0.1993 0.2009 

[TRAIN] Epoch[2](839/1500); Loss: 0.136106; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1609 0.1593 0.1536 0.1518 0.1448 0.1380 0.1348 0.1319 0.1288 0.1266 0.1248 0.1245 0.1249 0.1241 0.1241 0.1247 

[TRAIN] Epoch[2](840/1500); Loss: 0.144853; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1770 0.1864 0.1863 0.1749 0.1586 0.1483 0.1399 0.1342 0.1291 0.1256 0.1236 0.1244 0.1253 0.1273 0.1275 0.1293 

[TRAIN] Epoch[2](841/1500); Loss: 0.093954; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1304 0.1433 0.1395 0.1306 0.1092 0.0979 0.0915 0.0816 0.0771 0.0714 0.0725 0.0701 0.0707 0.0708 0.0736 0.0733 

[TRAIN] Epoch[2](842/1500); Loss: 0.095364; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1473 0.1603 0.1495 0.1377 0.1141 0.0994 0.0866 0.0759 0.0719 0.0692 0.0687 0.0682 0.0688 0.0687 0.0690 0.0704 

[TRAIN] Epoch[2](843/1500); Loss: 0.113427; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1307 0.1266 0.1257 0.1294 0.1227 0.1150 0.1104 0.1081 0.1069 0.1064 0.1062 0.1053 0.1052 0.1054 0.1053 0.1056 

[TRAIN] Epoch[2](844/1500); Loss: 0.107446; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1343 0.1340 0.1169 0.1167 0.1101 0.1048 0.1016 0.1001 0.0997 0.0991 0.1000 0.0995 0.0998 0.1002 0.1010 0.1014 

[TRAIN] Epoch[2](845/1500); Loss: 0.084972; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1338 0.1309 0.1138 0.1028 0.0889 0.0751 0.0726 0.0698 0.0695 0.0699 0.0712 0.0701 0.0712 0.0721 0.0733 0.0746 

[TRAIN] Epoch[2](846/1500); Loss: 0.067848; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1606 0.1350 0.0529 0.0884 0.0839 0.0697 0.0567 0.0493 0.0473 0.0477 0.0468 0.0477 0.0478 0.0478 0.0506 0.0534 

[TRAIN] Epoch[2](847/1500); Loss: 0.088486; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1256 0.1194 0.1150 0.1109 0.1018 0.0902 0.0829 0.0771 0.0744 0.0749 0.0732 0.0731 0.0733 0.0748 0.0743 0.0748 

[TRAIN] Epoch[2](848/1500); Loss: 0.139744; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1820 0.1695 0.1596 0.1475 0.1388 0.1348 0.1356 0.1309 0.1288 0.1294 0.1301 0.1285 0.1283 0.1305 0.1311 0.1305 

[TRAIN] Epoch[2](849/1500); Loss: 0.122296; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1414 0.1375 0.1312 0.1281 0.1251 0.1221 0.1194 0.1182 0.1180 0.1166 0.1164 0.1158 0.1158 0.1167 0.1173 0.1171 

[TRAIN] Epoch[2](850/1500); Loss: 0.069497; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1769 0.1483 0.1249 0.0961 0.0689 0.0502 0.0439 0.0420 0.0406 0.0447 0.0442 0.0435 0.0440 0.0474 0.0476 0.0488 

[TRAIN] Epoch[2](851/1500); Loss: 0.073126; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1534 0.1222 0.0762 0.1027 0.0943 0.0693 0.0576 0.0500 0.0474 0.0512 0.0543 0.0535 0.0571 0.0593 0.0606 0.0609 

[TRAIN] Epoch[2](852/1500); Loss: 0.174009; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1966 0.2008 0.1901 0.1846 0.1763 0.1715 0.1708 0.1695 0.1665 0.1660 0.1668 0.1658 0.1640 0.1644 0.1665 0.1636 

[TRAIN] Epoch[2](853/1500); Loss: 0.131888; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1499 0.1531 0.1436 0.1404 0.1335 0.1312 0.1295 0.1287 0.1270 0.1262 0.1246 0.1252 0.1240 0.1239 0.1238 0.1254 

[TRAIN] Epoch[2](854/1500); Loss: 0.146171; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1799 0.1710 0.1505 0.1468 0.1451 0.1443 0.1431 0.1414 0.1394 0.1390 0.1388 0.1387 0.1390 0.1397 0.1406 0.1413 

[TRAIN] Epoch[2](855/1500); Loss: 0.075034; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0786 0.0766 0.0821 0.0838 0.0796 0.0740 0.0722 0.0713 0.0709 0.0696 0.0703 0.0736 0.0725 0.0728 0.0743 0.0783 

[TRAIN] Epoch[2](856/1500); Loss: 0.116724; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1370 0.1350 0.1286 0.1239 0.1170 0.1159 0.1189 0.1135 0.1110 0.1105 0.1101 0.1085 0.1085 0.1092 0.1097 0.1103 

[TRAIN] Epoch[2](857/1500); Loss: 0.075591; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1848 0.1596 0.0771 0.0850 0.0785 0.0658 0.0574 0.0540 0.0575 0.0531 0.0549 0.0539 0.0557 0.0559 0.0569 0.0593 

[TRAIN] Epoch[2](858/1500); Loss: 0.091105; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1091 0.1102 0.0989 0.0956 0.0915 0.0887 0.0886 0.0855 0.0845 0.0850 0.0853 0.0847 0.0861 0.0868 0.0879 0.0892 

[TRAIN] Epoch[2](859/1500); Loss: 0.079653; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.0925 0.0852 0.0827 0.0812 0.0819 0.0782 0.0772 0.0770 0.0771 0.0761 0.0762 0.0770 0.0771 0.0778 0.0780 0.0793 

[TRAIN] Epoch[2](860/1500); Loss: 0.114263; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1335 0.1323 0.1265 0.1199 0.1130 0.1120 0.1100 0.1091 0.1084 0.1080 0.1081 0.1086 0.1085 0.1089 0.1102 0.1113 

[TRAIN] Epoch[2](861/1500); Loss: 0.110238; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1736 0.1656 0.1186 0.1193 0.1157 0.1096 0.1029 0.0974 0.0953 0.0944 0.0954 0.0942 0.0959 0.0947 0.0956 0.0956 

[TRAIN] Epoch[2](862/1500); Loss: 0.082351; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0903 0.0839 0.1032 0.1018 0.0937 0.0847 0.0804 0.0780 0.0778 0.0753 0.0735 0.0741 0.0741 0.0745 0.0756 0.0767 

[TRAIN] Epoch[2](863/1500); Loss: 0.062295; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0721 0.0813 0.0729 0.0715 0.0624 0.0563 0.0566 0.0561 0.0546 0.0553 0.0570 0.0575 0.0583 0.0600 0.0617 0.0630 

[TRAIN] Epoch[2](864/1500); Loss: 0.083453; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1308 0.1351 0.1143 0.1030 0.0868 0.0768 0.0734 0.0674 0.0670 0.0674 0.0682 0.0670 0.0680 0.0695 0.0695 0.0709 

[TRAIN] Epoch[2](865/1500); Loss: 0.067212; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1018 0.0903 0.0807 0.0716 0.0671 0.0640 0.0593 0.0584 0.0583 0.0579 0.0587 0.0596 0.0603 0.0613 0.0622 0.0640 

[TRAIN] Epoch[2](866/1500); Loss: 0.174815; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2258 0.2210 0.2063 0.1959 0.1806 0.1685 0.1610 0.1591 0.1586 0.1575 0.1591 0.1600 0.1601 0.1594 0.1611 0.1628 

[TRAIN] Epoch[2](867/1500); Loss: 0.123567; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1377 0.1296 0.1264 0.1266 0.1235 0.1191 0.1177 0.1190 0.1212 0.1227 0.1216 0.1216 0.1223 0.1220 0.1222 0.1239 

[TRAIN] Epoch[2](868/1500); Loss: 0.101117; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1178 0.1083 0.1126 0.1205 0.1159 0.1048 0.0985 0.0957 0.0937 0.0930 0.0924 0.0921 0.0923 0.0928 0.0933 0.0941 

[TRAIN] Epoch[2](869/1500); Loss: 0.086954; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1326 0.1330 0.1065 0.0957 0.0848 0.0803 0.0799 0.0777 0.0755 0.0748 0.0746 0.0742 0.0746 0.0750 0.0757 0.0764 

[TRAIN] Epoch[2](870/1500); Loss: 0.057134; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0704 0.0889 0.0635 0.0568 0.0525 0.0544 0.0499 0.0516 0.0500 0.0533 0.0512 0.0521 0.0523 0.0549 0.0552 0.0569 

[TRAIN] Epoch[2](871/1500); Loss: 0.117725; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1285 0.1260 0.1282 0.1293 0.1246 0.1196 0.1154 0.1124 0.1126 0.1141 0.1119 0.1109 0.1114 0.1116 0.1129 0.1142 

[TRAIN] Epoch[2](872/1500); Loss: 0.130101; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1474 0.1488 0.1360 0.1309 0.1293 0.1304 0.1289 0.1277 0.1258 0.1250 0.1243 0.1251 0.1254 0.1250 0.1252 0.1265 

[TRAIN] Epoch[2](873/1500); Loss: 0.104412; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1223 0.1133 0.1211 0.1183 0.1142 0.1068 0.1042 0.1005 0.0981 0.0974 0.0959 0.0949 0.0951 0.0957 0.0959 0.0968 

[TRAIN] Epoch[2](874/1500); Loss: 0.158016; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2023 0.1962 0.1683 0.1606 0.1555 0.1543 0.1536 0.1523 0.1502 0.1490 0.1483 0.1480 0.1474 0.1472 0.1474 0.1477 

[TRAIN] Epoch[2](875/1500); Loss: 0.108310; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1443 0.1402 0.1249 0.1213 0.1147 0.1081 0.1042 0.1007 0.0976 0.0962 0.0961 0.0960 0.0957 0.0961 0.0974 0.0995 

[TRAIN] Epoch[2](876/1500); Loss: 0.159358; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2378 0.2256 0.2062 0.1961 0.1822 0.1670 0.1530 0.1402 0.1338 0.1335 0.1293 0.1277 0.1282 0.1299 0.1297 0.1295 

[TRAIN] Epoch[2](877/1500); Loss: 0.103782; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1225 0.1277 0.1189 0.1137 0.1096 0.1034 0.0997 0.0979 0.0949 0.0940 0.0946 0.0957 0.0957 0.0963 0.0974 0.0986 

[TRAIN] Epoch[2](878/1500); Loss: 0.117611; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1208 0.1230 0.1282 0.1282 0.1209 0.1127 0.1119 0.1151 0.1136 0.1123 0.1123 0.1135 0.1152 0.1162 0.1181 0.1198 

[TRAIN] Epoch[2](879/1500); Loss: 0.060523; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0726 0.0620 0.0657 0.0695 0.0707 0.0623 0.0573 0.0580 0.0580 0.0553 0.0551 0.0558 0.0564 0.0554 0.0561 0.0582 

[TRAIN] Epoch[2](880/1500); Loss: 0.105633; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1072 0.1111 0.1487 0.1603 0.1486 0.1263 0.1140 0.0974 0.0880 0.0851 0.0860 0.0856 0.0825 0.0813 0.0837 0.0845 

[TRAIN] Epoch[2](881/1500); Loss: 0.111250; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1606 0.1378 0.1323 0.1456 0.1380 0.1221 0.1092 0.1007 0.0989 0.0955 0.0914 0.0885 0.0899 0.0898 0.0889 0.0907 

[TRAIN] Epoch[2](882/1500); Loss: 0.119845; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1324 0.1316 0.1266 0.1264 0.1232 0.1197 0.1202 0.1198 0.1161 0.1150 0.1142 0.1140 0.1141 0.1142 0.1150 0.1151 

[TRAIN] Epoch[2](883/1500); Loss: 0.104479; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1578 0.1569 0.1362 0.1260 0.1111 0.0987 0.0933 0.0944 0.0896 0.0861 0.0854 0.0870 0.0863 0.0867 0.0877 0.0886 

[TRAIN] Epoch[2](884/1500); Loss: 0.115559; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1538 0.1590 0.1689 0.1679 0.1497 0.1296 0.1117 0.0980 0.0897 0.0888 0.0874 0.0875 0.0874 0.0888 0.0895 0.0913 

[TRAIN] Epoch[2](885/1500); Loss: 0.075553; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1086 0.1146 0.1000 0.0821 0.0730 0.0704 0.0700 0.0650 0.0640 0.0646 0.0649 0.0645 0.0655 0.0660 0.0671 0.0687 

[TRAIN] Epoch[2](886/1500); Loss: 0.113296; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1129 0.1109 0.1413 0.1575 0.1468 0.1279 0.1194 0.1072 0.1019 0.0973 0.0957 0.0988 0.0985 0.0982 0.0982 0.1003 

[TRAIN] Epoch[2](887/1500); Loss: 0.137850; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1752 0.1662 0.1557 0.1459 0.1398 0.1399 0.1364 0.1301 0.1297 0.1288 0.1282 0.1257 0.1255 0.1255 0.1269 0.1261 

[TRAIN] Epoch[2](888/1500); Loss: 0.112578; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1290 0.1279 0.1233 0.1222 0.1183 0.1130 0.1126 0.1121 0.1092 0.1054 0.1048 0.1057 0.1045 0.1035 0.1040 0.1058 

[TRAIN] Epoch[2](889/1500); Loss: 0.122715; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1228 0.1250 0.1305 0.1292 0.1245 0.1229 0.1229 0.1217 0.1189 0.1179 0.1186 0.1189 0.1204 0.1223 0.1229 0.1241 

[TRAIN] Epoch[2](890/1500); Loss: 0.097487; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1173 0.1290 0.1226 0.1022 0.0884 0.0853 0.0916 0.0885 0.0875 0.0875 0.0918 0.0906 0.0911 0.0921 0.0968 0.0975 

[TRAIN] Epoch[2](891/1500); Loss: 0.101258; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1459 0.1391 0.1268 0.1245 0.1164 0.1045 0.0952 0.0914 0.0910 0.0848 0.0839 0.0838 0.0840 0.0823 0.0828 0.0837 

[TRAIN] Epoch[2](892/1500); Loss: 0.136873; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2102 0.1903 0.1673 0.1559 0.1453 0.1343 0.1261 0.1210 0.1227 0.1210 0.1164 0.1150 0.1174 0.1170 0.1147 0.1153 

[TRAIN] Epoch[2](893/1500); Loss: 0.072929; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1021 0.0976 0.0977 0.1096 0.0963 0.0780 0.0674 0.0599 0.0593 0.0608 0.0556 0.0547 0.0561 0.0583 0.0565 0.0569 

[TRAIN] Epoch[2](894/1500); Loss: 0.128234; Backpropagation: 0.0915 sec; Batch: 0.4237 sec
0.1762 0.1588 0.1370 0.1288 0.1277 0.1296 0.1238 0.1217 0.1219 0.1216 0.1180 0.1170 0.1179 0.1192 0.1164 0.1160 

[TRAIN] Epoch[2](895/1500); Loss: 0.136098; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2369 0.2100 0.1504 0.1408 0.1316 0.1261 0.1229 0.1187 0.1163 0.1165 0.1164 0.1169 0.1162 0.1175 0.1191 0.1211 

[TRAIN] Epoch[2](896/1500); Loss: 0.204789; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2443 0.2427 0.2312 0.2185 0.2095 0.2040 0.2001 0.1984 0.1958 0.1935 0.1929 0.1901 0.1885 0.1889 0.1893 0.1889 

[TRAIN] Epoch[2](897/1500); Loss: 0.107016; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1369 0.1313 0.1162 0.1150 0.1120 0.1059 0.1046 0.1012 0.1000 0.0980 0.0977 0.0972 0.0979 0.0983 0.0996 0.1004 

[TRAIN] Epoch[2](898/1500); Loss: 0.123962; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1344 0.1341 0.1310 0.1348 0.1316 0.1248 0.1226 0.1226 0.1212 0.1189 0.1184 0.1179 0.1175 0.1176 0.1176 0.1182 

[TRAIN] Epoch[2](899/1500); Loss: 0.100860; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1320 0.1380 0.1390 0.1258 0.1093 0.0979 0.0922 0.0881 0.0880 0.0849 0.0850 0.0851 0.0857 0.0863 0.0873 0.0892 

[TRAIN] Epoch[2](900/1500); Loss: 0.093265; Backpropagation: 0.0915 sec; Batch: 0.4230 sec
0.1114 0.1116 0.1040 0.1061 0.1009 0.0962 0.0947 0.0915 0.0864 0.0844 0.0833 0.0838 0.0834 0.0838 0.0849 0.0859 

[TRAIN] Epoch[2](901/1500); Loss: 0.107895; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1273 0.1245 0.1146 0.1152 0.1134 0.1097 0.1063 0.1045 0.1030 0.1007 0.1004 0.1009 0.1007 0.1008 0.1016 0.1029 

[TRAIN] Epoch[2](902/1500); Loss: 0.067241; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1082 0.0980 0.0782 0.0696 0.0669 0.0607 0.0617 0.0591 0.0583 0.0579 0.0586 0.0577 0.0595 0.0600 0.0602 0.0612 

[TRAIN] Epoch[2](903/1500); Loss: 0.079707; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1355 0.1246 0.0780 0.0867 0.0816 0.0747 0.0720 0.0707 0.0684 0.0676 0.0676 0.0683 0.0681 0.0688 0.0708 0.0718 

[TRAIN] Epoch[2](904/1500); Loss: 0.091530; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1325 0.1106 0.0954 0.0924 0.0959 0.0895 0.0874 0.0852 0.0855 0.0842 0.0845 0.0836 0.0838 0.0847 0.0845 0.0849 

[TRAIN] Epoch[2](905/1500); Loss: 0.092832; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1172 0.1234 0.1105 0.1051 0.0927 0.0869 0.0824 0.0807 0.0799 0.0804 0.0813 0.0830 0.0856 0.0892 0.0922 0.0949 

[TRAIN] Epoch[2](906/1500); Loss: 0.091771; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1564 0.1362 0.1066 0.0998 0.0911 0.0846 0.0821 0.0806 0.0790 0.0775 0.0778 0.0787 0.0791 0.0787 0.0798 0.0803 

[TRAIN] Epoch[2](907/1500); Loss: 0.121061; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1475 0.1420 0.1241 0.1242 0.1216 0.1200 0.1193 0.1175 0.1153 0.1148 0.1147 0.1141 0.1145 0.1153 0.1158 0.1162 

[TRAIN] Epoch[2](908/1500); Loss: 0.081246; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0933 0.0958 0.0828 0.0856 0.0823 0.0795 0.0791 0.0780 0.0774 0.0773 0.0771 0.0772 0.0775 0.0784 0.0788 0.0798 

[TRAIN] Epoch[2](909/1500); Loss: 0.097004; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1206 0.1298 0.1196 0.1083 0.1001 0.0952 0.0899 0.0875 0.0875 0.0865 0.0860 0.0865 0.0875 0.0882 0.0891 0.0897 

[TRAIN] Epoch[2](910/1500); Loss: 0.060122; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.0942 0.0800 0.0653 0.0662 0.0617 0.0558 0.0556 0.0539 0.0526 0.0522 0.0530 0.0534 0.0535 0.0536 0.0552 0.0556 

[TRAIN] Epoch[2](911/1500); Loss: 0.059723; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1756 0.1281 0.0981 0.0740 0.0549 0.0446 0.0391 0.0357 0.0360 0.0378 0.0376 0.0365 0.0377 0.0393 0.0395 0.0412 

[TRAIN] Epoch[2](912/1500); Loss: 0.095438; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1179 0.1001 0.1226 0.1633 0.1567 0.1325 0.1159 0.0942 0.0768 0.0651 0.0618 0.0623 0.0638 0.0626 0.0644 0.0670 

[TRAIN] Epoch[2](913/1500); Loss: 0.075320; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1081 0.1012 0.0927 0.0992 0.0901 0.0769 0.0695 0.0661 0.0639 0.0605 0.0607 0.0619 0.0625 0.0624 0.0633 0.0659 

[TRAIN] Epoch[2](914/1500); Loss: 0.139782; Backpropagation: 0.0917 sec; Batch: 0.4296 sec
0.1545 0.1589 0.1471 0.1388 0.1382 0.1438 0.1426 0.1367 0.1354 0.1362 0.1358 0.1335 0.1335 0.1338 0.1339 0.1337 

[TRAIN] Epoch[2](915/1500); Loss: 0.067747; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.0884 0.0764 0.0708 0.0716 0.0702 0.0655 0.0644 0.0633 0.0635 0.0641 0.0633 0.0635 0.0637 0.0647 0.0649 0.0657 

[TRAIN] Epoch[2](916/1500); Loss: 0.115940; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1403 0.1446 0.1495 0.1442 0.1308 0.1185 0.1104 0.1050 0.1013 0.1002 0.0999 0.1003 0.1012 0.1018 0.1028 0.1042 

[TRAIN] Epoch[2](917/1500); Loss: 0.109254; Backpropagation: 0.0919 sec; Batch: 0.4248 sec
0.1383 0.1328 0.1178 0.1154 0.1113 0.1081 0.1074 0.1054 0.1027 0.1016 0.1011 0.1007 0.1006 0.1014 0.1017 0.1018 

[TRAIN] Epoch[2](918/1500); Loss: 0.067511; Backpropagation: 0.0917 sec; Batch: 0.4252 sec
0.0981 0.1034 0.0839 0.0834 0.0753 0.0651 0.0578 0.0557 0.0559 0.0552 0.0556 0.0564 0.0574 0.0577 0.0591 0.0602 

[TRAIN] Epoch[2](919/1500); Loss: 0.139031; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1598 0.1508 0.1483 0.1468 0.1438 0.1405 0.1362 0.1341 0.1332 0.1339 0.1331 0.1322 0.1323 0.1332 0.1333 0.1331 

[TRAIN] Epoch[2](920/1500); Loss: 0.091093; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1114 0.1072 0.0917 0.0917 0.0910 0.0883 0.0882 0.0876 0.0870 0.0864 0.0869 0.0870 0.0871 0.0879 0.0889 0.0891 

[TRAIN] Epoch[2](921/1500); Loss: 0.112317; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1261 0.1219 0.1187 0.1185 0.1155 0.1101 0.1074 0.1082 0.1092 0.1111 0.1096 0.1091 0.1070 0.1069 0.1079 0.1098 

[TRAIN] Epoch[2](922/1500); Loss: 0.059282; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1016 0.0913 0.0693 0.0562 0.0545 0.0507 0.0501 0.0484 0.0495 0.0492 0.0512 0.0513 0.0539 0.0551 0.0575 0.0587 

[TRAIN] Epoch[2](923/1500); Loss: 0.046209; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0610 0.0602 0.0463 0.0461 0.0422 0.0390 0.0392 0.0398 0.0404 0.0411 0.0430 0.0448 0.0462 0.0478 0.0500 0.0523 

[TRAIN] Epoch[2](924/1500); Loss: 0.078670; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1593 0.1280 0.0824 0.1321 0.1261 0.1020 0.0823 0.0609 0.0456 0.0434 0.0472 0.0482 0.0479 0.0476 0.0524 0.0532 

[TRAIN] Epoch[2](925/1500); Loss: 0.083013; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.0806 0.0883 0.0991 0.0981 0.0922 0.0833 0.0799 0.0786 0.0786 0.0759 0.0763 0.0764 0.0794 0.0797 0.0803 0.0815 

[TRAIN] Epoch[2](926/1500); Loss: 0.072394; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1579 0.1127 0.0896 0.0679 0.0603 0.0613 0.0567 0.0577 0.0569 0.0613 0.0605 0.0602 0.0606 0.0631 0.0661 0.0655 

[TRAIN] Epoch[2](927/1500); Loss: 0.106673; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1400 0.1253 0.1122 0.1120 0.1089 0.1047 0.1032 0.1022 0.1008 0.0999 0.0992 0.0989 0.0993 0.0999 0.0999 0.1004 

[TRAIN] Epoch[2](928/1500); Loss: 0.081201; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1065 0.1037 0.0888 0.0976 0.0891 0.0785 0.0748 0.0753 0.0751 0.0735 0.0712 0.0714 0.0719 0.0727 0.0735 0.0754 

[TRAIN] Epoch[2](929/1500); Loss: 0.123427; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1544 0.1513 0.1351 0.1314 0.1275 0.1222 0.1181 0.1165 0.1162 0.1158 0.1147 0.1140 0.1142 0.1145 0.1141 0.1146 

[TRAIN] Epoch[2](930/1500); Loss: 0.115709; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1380 0.1397 0.1251 0.1213 0.1165 0.1145 0.1147 0.1133 0.1104 0.1088 0.1083 0.1080 0.1080 0.1085 0.1080 0.1083 

[TRAIN] Epoch[2](931/1500); Loss: 0.087862; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1517 0.1477 0.1153 0.1048 0.0937 0.0823 0.0757 0.0761 0.0721 0.0698 0.0692 0.0696 0.0690 0.0690 0.0697 0.0700 

[TRAIN] Epoch[2](932/1500); Loss: 0.081682; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1289 0.1198 0.0936 0.1053 0.0954 0.0795 0.0727 0.0736 0.0708 0.0675 0.0655 0.0669 0.0663 0.0662 0.0664 0.0687 

[TRAIN] Epoch[2](933/1500); Loss: 0.139764; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1517 0.1505 0.1442 0.1422 0.1403 0.1390 0.1377 0.1366 0.1363 0.1362 0.1364 0.1361 0.1364 0.1367 0.1378 0.1380 

[TRAIN] Epoch[2](934/1500); Loss: 0.077394; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1064 0.0986 0.0794 0.0809 0.0771 0.0737 0.0734 0.0737 0.0719 0.0706 0.0713 0.0717 0.0712 0.0720 0.0732 0.0734 

[TRAIN] Epoch[2](935/1500); Loss: 0.083059; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1117 0.1079 0.0957 0.0874 0.0818 0.0784 0.0772 0.0755 0.0749 0.0751 0.0754 0.0757 0.0769 0.0773 0.0786 0.0795 

[TRAIN] Epoch[2](936/1500); Loss: 0.134088; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.3172 0.2644 0.2335 0.1924 0.1520 0.1104 0.0790 0.0826 0.0854 0.0813 0.0822 0.0913 0.0915 0.0901 0.0922 0.1000 

[TRAIN] Epoch[2](937/1500); Loss: 0.128469; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1663 0.1598 0.1512 0.1473 0.1409 0.1297 0.1243 0.1207 0.1178 0.1149 0.1144 0.1141 0.1135 0.1132 0.1133 0.1142 

[TRAIN] Epoch[2](938/1500); Loss: 0.136768; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1594 0.1572 0.1449 0.1413 0.1384 0.1363 0.1342 0.1328 0.1318 0.1311 0.1300 0.1297 0.1297 0.1300 0.1304 0.1310 

[TRAIN] Epoch[2](939/1500); Loss: 0.068427; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.0961 0.1030 0.0823 0.0820 0.0715 0.0636 0.0616 0.0592 0.0588 0.0576 0.0580 0.0588 0.0589 0.0600 0.0611 0.0624 

[TRAIN] Epoch[2](940/1500); Loss: 0.124684; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1682 0.1608 0.1565 0.1518 0.1415 0.1272 0.1176 0.1108 0.1093 0.1093 0.1070 0.1058 0.1061 0.1079 0.1080 0.1073 

[TRAIN] Epoch[2](941/1500); Loss: 0.097740; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1591 0.1513 0.1016 0.1036 0.0991 0.0928 0.0884 0.0867 0.0855 0.0849 0.0838 0.0845 0.0847 0.0851 0.0859 0.0868 

[TRAIN] Epoch[2](942/1500); Loss: 0.120015; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1580 0.1587 0.1383 0.1316 0.1250 0.1191 0.1147 0.1112 0.1089 0.1071 0.1070 0.1072 0.1076 0.1080 0.1086 0.1092 

[TRAIN] Epoch[2](943/1500); Loss: 0.091947; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1258 0.1216 0.0998 0.0964 0.0906 0.0870 0.0861 0.0851 0.0835 0.0835 0.0830 0.0838 0.0846 0.0852 0.0869 0.0880 

[TRAIN] Epoch[2](944/1500); Loss: 0.151919; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1712 0.1755 0.1544 0.1522 0.1521 0.1512 0.1501 0.1487 0.1471 0.1467 0.1467 0.1468 0.1465 0.1465 0.1472 0.1478 

[TRAIN] Epoch[2](945/1500); Loss: 0.061553; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2057 0.1722 0.0336 0.0625 0.0630 0.0524 0.0394 0.0414 0.0397 0.0360 0.0352 0.0393 0.0397 0.0397 0.0400 0.0451 

[TRAIN] Epoch[2](946/1500); Loss: 0.078210; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1766 0.1430 0.0749 0.1082 0.0975 0.0728 0.0619 0.0518 0.0507 0.0595 0.0558 0.0533 0.0564 0.0638 0.0633 0.0617 

[TRAIN] Epoch[2](947/1500); Loss: 0.145015; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1676 0.1659 0.1457 0.1510 0.1439 0.1384 0.1370 0.1381 0.1407 0.1421 0.1428 0.1420 0.1420 0.1410 0.1409 0.1412 

[TRAIN] Epoch[2](948/1500); Loss: 0.101308; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1470 0.1503 0.1507 0.1416 0.1249 0.1066 0.0922 0.0833 0.0803 0.0807 0.0780 0.0753 0.0755 0.0774 0.0782 0.0789 

[TRAIN] Epoch[2](949/1500); Loss: 0.133446; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1454 0.1433 0.1340 0.1333 0.1334 0.1325 0.1320 0.1307 0.1302 0.1308 0.1308 0.1307 0.1313 0.1319 0.1321 0.1328 

[TRAIN] Epoch[2](950/1500); Loss: 0.114932; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1352 0.1333 0.1251 0.1213 0.1174 0.1135 0.1108 0.1096 0.1088 0.1081 0.1082 0.1083 0.1086 0.1092 0.1102 0.1110 

[TRAIN] Epoch[2](951/1500); Loss: 0.110405; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1417 0.1296 0.1279 0.1261 0.1208 0.1128 0.1092 0.1050 0.1011 0.1011 0.0992 0.0983 0.0979 0.0979 0.0989 0.0989 

[TRAIN] Epoch[2](952/1500); Loss: 0.122434; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1674 0.1584 0.1316 0.1309 0.1275 0.1240 0.1192 0.1155 0.1141 0.1110 0.1102 0.1096 0.1100 0.1094 0.1095 0.1105 

[TRAIN] Epoch[2](953/1500); Loss: 0.063242; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0834 0.0840 0.0662 0.0708 0.0665 0.0599 0.0581 0.0601 0.0567 0.0551 0.0565 0.0580 0.0571 0.0580 0.0606 0.0608 

[TRAIN] Epoch[2](954/1500); Loss: 0.101588; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1276 0.1296 0.1098 0.1036 0.0997 0.0978 0.0966 0.0960 0.0955 0.0947 0.0947 0.0947 0.0950 0.0958 0.0968 0.0975 

[TRAIN] Epoch[2](955/1500); Loss: 0.102523; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1225 0.1173 0.1377 0.1368 0.1257 0.1080 0.0993 0.0937 0.0908 0.0917 0.0873 0.0849 0.0853 0.0866 0.0861 0.0868 

[TRAIN] Epoch[2](956/1500); Loss: 0.075666; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1078 0.1002 0.0891 0.0908 0.0842 0.0750 0.0725 0.0721 0.0689 0.0651 0.0637 0.0635 0.0640 0.0639 0.0644 0.0651 

[TRAIN] Epoch[2](957/1500); Loss: 0.087362; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1092 0.1207 0.0942 0.0929 0.0888 0.0836 0.0829 0.0837 0.0816 0.0800 0.0798 0.0794 0.0794 0.0801 0.0807 0.0808 

[TRAIN] Epoch[2](958/1500); Loss: 0.077157; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1178 0.1008 0.0849 0.0779 0.0779 0.0747 0.0707 0.0694 0.0696 0.0687 0.0696 0.0692 0.0697 0.0705 0.0718 0.0716 

[TRAIN] Epoch[2](959/1500); Loss: 0.131612; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1496 0.1443 0.1420 0.1425 0.1371 0.1304 0.1270 0.1275 0.1287 0.1272 0.1254 0.1246 0.1244 0.1243 0.1252 0.1256 

[TRAIN] Epoch[2](960/1500); Loss: 0.107063; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1338 0.1392 0.1164 0.1124 0.1093 0.1058 0.1033 0.1014 0.1003 0.0991 0.0984 0.0984 0.0983 0.0983 0.0989 0.0999 

[TRAIN] Epoch[2](961/1500); Loss: 0.063053; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0833 0.0979 0.0857 0.0664 0.0593 0.0637 0.0620 0.0564 0.0527 0.0538 0.0538 0.0529 0.0527 0.0560 0.0568 0.0556 

[TRAIN] Epoch[2](962/1500); Loss: 0.082916; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1081 0.0821 0.1285 0.1505 0.1395 0.1090 0.0939 0.0708 0.0573 0.0551 0.0567 0.0575 0.0527 0.0534 0.0548 0.0569 

[TRAIN] Epoch[2](963/1500); Loss: 0.098628; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1282 0.1285 0.1285 0.1268 0.1155 0.1016 0.0923 0.0874 0.0855 0.0871 0.0828 0.0808 0.0820 0.0837 0.0832 0.0840 

[TRAIN] Epoch[2](964/1500); Loss: 0.101437; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1848 0.1678 0.1229 0.1128 0.1056 0.0973 0.0899 0.0865 0.0848 0.0822 0.0816 0.0806 0.0806 0.0806 0.0827 0.0822 

[TRAIN] Epoch[2](965/1500); Loss: 0.093481; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1031 0.1050 0.1075 0.1047 0.0987 0.0903 0.0883 0.0923 0.0901 0.0873 0.0867 0.0872 0.0874 0.0878 0.0889 0.0903 

[TRAIN] Epoch[2](966/1500); Loss: 0.139014; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1992 0.1819 0.1394 0.1383 0.1361 0.1339 0.1319 0.1319 0.1312 0.1297 0.1290 0.1290 0.1284 0.1279 0.1285 0.1280 

[TRAIN] Epoch[2](967/1500); Loss: 0.082510; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.0874 0.0951 0.0923 0.0873 0.0834 0.0827 0.0802 0.0772 0.0772 0.0773 0.0781 0.0786 0.0791 0.0808 0.0814 0.0819 

[TRAIN] Epoch[2](968/1500); Loss: 0.108742; Backpropagation: 0.0915 sec; Batch: 0.4229 sec
0.1609 0.1530 0.1411 0.1294 0.1198 0.1129 0.1100 0.1031 0.0972 0.0947 0.0929 0.0878 0.0863 0.0857 0.0830 0.0821 

[TRAIN] Epoch[2](969/1500); Loss: 0.165010; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1958 0.1900 0.1781 0.1743 0.1700 0.1659 0.1631 0.1597 0.1574 0.1567 0.1559 0.1545 0.1543 0.1549 0.1546 0.1549 

[TRAIN] Epoch[2](970/1500); Loss: 0.071859; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0950 0.1022 0.0938 0.0858 0.0793 0.0709 0.0665 0.0638 0.0620 0.0611 0.0608 0.0607 0.0607 0.0613 0.0622 0.0635 

[TRAIN] Epoch[2](971/1500); Loss: 0.106697; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1527 0.1493 0.1213 0.1144 0.1083 0.1027 0.1008 0.1002 0.0979 0.0959 0.0951 0.0945 0.0936 0.0931 0.0938 0.0935 

[TRAIN] Epoch[2](972/1500); Loss: 0.088207; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1252 0.1050 0.0976 0.1007 0.0981 0.0899 0.0838 0.0805 0.0805 0.0827 0.0793 0.0764 0.0780 0.0784 0.0776 0.0774 

[TRAIN] Epoch[2](973/1500); Loss: 0.098555; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1112 0.1121 0.1115 0.1089 0.1021 0.0955 0.0958 0.0973 0.0941 0.0922 0.0918 0.0925 0.0922 0.0921 0.0930 0.0946 

[TRAIN] Epoch[2](974/1500); Loss: 0.075188; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0912 0.0985 0.0875 0.0776 0.0739 0.0755 0.0741 0.0708 0.0693 0.0686 0.0688 0.0686 0.0694 0.0691 0.0698 0.0704 

[TRAIN] Epoch[2](975/1500); Loss: 0.064605; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0956 0.0994 0.0843 0.0733 0.0659 0.0595 0.0566 0.0548 0.0542 0.0538 0.0543 0.0547 0.0556 0.0564 0.0573 0.0581 

[TRAIN] Epoch[2](976/1500); Loss: 0.091861; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1950 0.1693 0.0750 0.0937 0.0869 0.0784 0.0761 0.0843 0.0773 0.0745 0.0743 0.0768 0.0755 0.0744 0.0798 0.0785 

[TRAIN] Epoch[2](977/1500); Loss: 0.104257; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1481 0.1305 0.1121 0.1024 0.1021 0.1030 0.0991 0.0969 0.0960 0.0965 0.0960 0.0960 0.0970 0.0974 0.0973 0.0979 

[TRAIN] Epoch[2](978/1500); Loss: 0.109844; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1168 0.1268 0.1198 0.1145 0.1130 0.1098 0.1088 0.1069 0.1064 0.1045 0.1044 0.1041 0.1056 0.1050 0.1055 0.1057 

[TRAIN] Epoch[2](979/1500); Loss: 0.119308; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1654 0.1624 0.1481 0.1344 0.1261 0.1188 0.1125 0.1090 0.1071 0.1049 0.1031 0.1034 0.1031 0.1029 0.1033 0.1044 

[TRAIN] Epoch[2](980/1500); Loss: 0.088931; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1003 0.1055 0.1255 0.1305 0.1190 0.0988 0.0906 0.0798 0.0756 0.0748 0.0750 0.0711 0.0681 0.0691 0.0699 0.0693 

[TRAIN] Epoch[2](981/1500); Loss: 0.143557; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2008 0.1938 0.1536 0.1481 0.1450 0.1392 0.1367 0.1359 0.1329 0.1318 0.1302 0.1302 0.1298 0.1296 0.1297 0.1295 

[TRAIN] Epoch[2](982/1500); Loss: 0.125330; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1632 0.1582 0.1408 0.1378 0.1309 0.1238 0.1206 0.1218 0.1202 0.1164 0.1136 0.1128 0.1114 0.1108 0.1116 0.1114 

[TRAIN] Epoch[2](983/1500); Loss: 0.099574; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1250 0.1287 0.1245 0.1130 0.1024 0.0972 0.0955 0.0931 0.0904 0.0889 0.0888 0.0882 0.0888 0.0886 0.0900 0.0899 

[TRAIN] Epoch[2](984/1500); Loss: 0.158859; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.2455 0.2217 0.2097 0.1917 0.1751 0.1678 0.1522 0.1385 0.1328 0.1296 0.1310 0.1283 0.1277 0.1289 0.1309 0.1303 

[TRAIN] Epoch[2](985/1500); Loss: 0.114638; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1908 0.1758 0.1654 0.1493 0.1339 0.1280 0.1147 0.1007 0.0921 0.0839 0.0832 0.0824 0.0832 0.0830 0.0840 0.0839 

[TRAIN] Epoch[2](986/1500); Loss: 0.076568; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0905 0.1036 0.0994 0.0934 0.0834 0.0756 0.0724 0.0706 0.0688 0.0667 0.0657 0.0661 0.0661 0.0670 0.0674 0.0684 

[TRAIN] Epoch[2](987/1500); Loss: 0.053759; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.0740 0.0876 0.0531 0.0591 0.0517 0.0480 0.0469 0.0480 0.0467 0.0468 0.0476 0.0487 0.0486 0.0499 0.0514 0.0520 

[TRAIN] Epoch[2](988/1500); Loss: 0.080441; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1173 0.1202 0.0949 0.0847 0.0790 0.0751 0.0729 0.0714 0.0699 0.0696 0.0696 0.0705 0.0713 0.0721 0.0733 0.0752 

[TRAIN] Epoch[2](989/1500); Loss: 0.067633; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0751 0.0815 0.0677 0.0726 0.0693 0.0648 0.0646 0.0649 0.0641 0.0639 0.0644 0.0649 0.0655 0.0656 0.0662 0.0670 

[TRAIN] Epoch[2](990/1500); Loss: 0.112098; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1239 0.1252 0.1215 0.1228 0.1183 0.1111 0.1084 0.1084 0.1089 0.1071 0.1062 0.1060 0.1059 0.1059 0.1064 0.1075 

[TRAIN] Epoch[2](991/1500); Loss: 0.087114; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1268 0.1386 0.1236 0.1063 0.0964 0.0875 0.0811 0.0784 0.0742 0.0705 0.0692 0.0683 0.0672 0.0672 0.0688 0.0698 

[TRAIN] Epoch[2](992/1500); Loss: 0.124706; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1466 0.1484 0.1452 0.1384 0.1302 0.1238 0.1202 0.1184 0.1178 0.1156 0.1151 0.1150 0.1144 0.1150 0.1153 0.1157 

[TRAIN] Epoch[2](993/1500); Loss: 0.097266; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1312 0.1284 0.1052 0.0999 0.0964 0.0947 0.0924 0.0905 0.0891 0.0887 0.0886 0.0886 0.0898 0.0903 0.0907 0.0918 

[TRAIN] Epoch[2](994/1500); Loss: 0.106003; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1385 0.1386 0.1294 0.1171 0.1091 0.1028 0.0986 0.0972 0.0964 0.0954 0.0950 0.0955 0.0954 0.0953 0.0957 0.0961 

[TRAIN] Epoch[2](995/1500); Loss: 0.095947; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1547 0.1655 0.1530 0.1262 0.1079 0.0923 0.0811 0.0757 0.0740 0.0723 0.0716 0.0714 0.0720 0.0722 0.0720 0.0730 

[TRAIN] Epoch[2](996/1500); Loss: 0.097908; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1316 0.1442 0.1372 0.1154 0.1013 0.0930 0.0903 0.0858 0.0828 0.0816 0.0827 0.0828 0.0831 0.0837 0.0851 0.0859 

[TRAIN] Epoch[2](997/1500); Loss: 0.138923; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1742 0.1634 0.1555 0.1462 0.1404 0.1373 0.1344 0.1322 0.1311 0.1302 0.1298 0.1293 0.1292 0.1294 0.1298 0.1303 

[TRAIN] Epoch[2](998/1500); Loss: 0.117258; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1659 0.1516 0.1347 0.1250 0.1164 0.1125 0.1089 0.1085 0.1065 0.1061 0.1063 0.1063 0.1063 0.1066 0.1068 0.1078 

[TRAIN] Epoch[2](999/1500); Loss: 0.083645; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1584 0.1290 0.1032 0.0890 0.0759 0.0714 0.0734 0.0723 0.0697 0.0691 0.0694 0.0702 0.0707 0.0713 0.0723 0.0731 

[TRAIN] Epoch[2](1000/1500); Loss: 0.066290; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0877 0.0811 0.0713 0.0717 0.0700 0.0653 0.0627 0.0612 0.0613 0.0609 0.0605 0.0606 0.0608 0.0613 0.0616 0.0627 

[TRAIN] Epoch[2](1001/1500); Loss: 0.060665; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1207 0.1140 0.0646 0.0753 0.0651 0.0543 0.0516 0.0494 0.0492 0.0462 0.0457 0.0468 0.0455 0.0473 0.0481 0.0468 

[TRAIN] Epoch[2](1002/1500); Loss: 0.145645; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2317 0.2054 0.1888 0.1742 0.1590 0.1525 0.1416 0.1320 0.1262 0.1201 0.1178 0.1169 0.1167 0.1155 0.1156 0.1161 

[TRAIN] Epoch[2](1003/1500); Loss: 0.114256; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1173 0.1230 0.1177 0.1140 0.1130 0.1127 0.1124 0.1118 0.1114 0.1114 0.1105 0.1119 0.1133 0.1140 0.1160 0.1178 

[TRAIN] Epoch[2](1004/1500); Loss: 0.070140; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0950 0.0944 0.0850 0.0807 0.0763 0.0695 0.0666 0.0649 0.0628 0.0616 0.0611 0.0605 0.0604 0.0603 0.0612 0.0618 

[TRAIN] Epoch[2](1005/1500); Loss: 0.099036; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1344 0.1360 0.1156 0.1118 0.1048 0.1003 0.0965 0.0928 0.0896 0.0877 0.0870 0.0859 0.0852 0.0855 0.0857 0.0857 

[TRAIN] Epoch[2](1006/1500); Loss: 0.124939; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1415 0.1519 0.1454 0.1337 0.1262 0.1221 0.1222 0.1217 0.1194 0.1176 0.1167 0.1165 0.1164 0.1161 0.1159 0.1157 

[TRAIN] Epoch[2](1007/1500); Loss: 0.086205; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0758 0.0902 0.0860 0.0828 0.0828 0.0845 0.0840 0.0849 0.0844 0.0853 0.0861 0.0877 0.0886 0.0907 0.0918 0.0937 

[TRAIN] Epoch[2](1008/1500); Loss: 0.112405; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1404 0.1480 0.1397 0.1242 0.1150 0.1100 0.1083 0.1056 0.1034 0.1015 0.1010 0.1008 0.1002 0.0999 0.1003 0.1002 

[TRAIN] Epoch[2](1009/1500); Loss: 0.062350; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0941 0.0848 0.0684 0.0616 0.0585 0.0551 0.0553 0.0553 0.0554 0.0561 0.0562 0.0572 0.0586 0.0592 0.0604 0.0614 

[TRAIN] Epoch[2](1010/1500); Loss: 0.123640; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1400 0.1500 0.1435 0.1319 0.1249 0.1209 0.1220 0.1208 0.1180 0.1163 0.1157 0.1153 0.1147 0.1147 0.1146 0.1150 

[TRAIN] Epoch[2](1011/1500); Loss: 0.118724; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1667 0.1651 0.1330 0.1240 0.1175 0.1138 0.1119 0.1090 0.1070 0.1065 0.1063 0.1069 0.1069 0.1077 0.1085 0.1088 

[TRAIN] Epoch[2](1012/1500); Loss: 0.145336; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1898 0.1829 0.1624 0.1558 0.1485 0.1442 0.1403 0.1369 0.1358 0.1335 0.1325 0.1325 0.1326 0.1326 0.1324 0.1326 

[TRAIN] Epoch[2](1013/1500); Loss: 0.131151; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2000 0.1987 0.1483 0.1473 0.1341 0.1279 0.1242 0.1188 0.1162 0.1136 0.1128 0.1114 0.1110 0.1107 0.1108 0.1126 

[TRAIN] Epoch[2](1014/1500); Loss: 0.097713; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1114 0.1160 0.1071 0.1013 0.0979 0.0969 0.0964 0.0936 0.0923 0.0922 0.0917 0.0919 0.0927 0.0932 0.0941 0.0947 

[TRAIN] Epoch[2](1015/1500); Loss: 0.091686; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1204 0.1266 0.1148 0.1017 0.0946 0.0899 0.0865 0.0838 0.0818 0.0804 0.0801 0.0802 0.0805 0.0815 0.0818 0.0824 

[TRAIN] Epoch[2](1016/1500); Loss: 0.072357; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1114 0.1231 0.1020 0.0871 0.0766 0.0690 0.0623 0.0585 0.0571 0.0568 0.0570 0.0577 0.0585 0.0589 0.0601 0.0618 

[TRAIN] Epoch[2](1017/1500); Loss: 0.124659; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1341 0.1418 0.1341 0.1272 0.1258 0.1258 0.1253 0.1219 0.1204 0.1201 0.1194 0.1193 0.1194 0.1195 0.1200 0.1201 

[TRAIN] Epoch[2](1018/1500); Loss: 0.103136; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1183 0.1289 0.1182 0.1034 0.0965 0.0982 0.1010 0.0967 0.0956 0.0963 0.0967 0.0970 0.0986 0.1004 0.1015 0.1028 

[TRAIN] Epoch[2](1019/1500); Loss: 0.109486; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1251 0.1287 0.1132 0.1099 0.1086 0.1085 0.1074 0.1059 0.1049 0.1049 0.1048 0.1051 0.1055 0.1058 0.1066 0.1070 

[TRAIN] Epoch[2](1020/1500); Loss: 0.045116; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0945 0.0479 0.0437 0.0384 0.0427 0.0401 0.0361 0.0380 0.0376 0.0383 0.0400 0.0411 0.0428 0.0442 0.0475 0.0490 

[TRAIN] Epoch[2](1021/1500); Loss: 0.142725; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1987 0.1913 0.1763 0.1603 0.1497 0.1411 0.1342 0.1299 0.1274 0.1256 0.1244 0.1243 0.1246 0.1247 0.1253 0.1258 

[TRAIN] Epoch[2](1022/1500); Loss: 0.121191; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1388 0.1398 0.1282 0.1226 0.1199 0.1192 0.1179 0.1166 0.1158 0.1154 0.1161 0.1166 0.1169 0.1178 0.1185 0.1189 

[TRAIN] Epoch[2](1023/1500); Loss: 0.166543; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2803 0.2510 0.2385 0.2089 0.1786 0.1657 0.1455 0.1294 0.1313 0.1373 0.1331 0.1316 0.1318 0.1353 0.1330 0.1333 

[TRAIN] Epoch[2](1024/1500); Loss: 0.071222; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0964 0.1109 0.0911 0.0813 0.0772 0.0709 0.0677 0.0656 0.0617 0.0606 0.0599 0.0589 0.0588 0.0591 0.0593 0.0602 

[TRAIN] Epoch[2](1025/1500); Loss: 0.125951; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1435 0.1438 0.1284 0.1264 0.1255 0.1250 0.1230 0.1223 0.1222 0.1215 0.1213 0.1216 0.1218 0.1223 0.1230 0.1237 

[TRAIN] Epoch[2](1026/1500); Loss: 0.119543; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1365 0.1367 0.1202 0.1199 0.1192 0.1180 0.1164 0.1153 0.1150 0.1152 0.1152 0.1154 0.1159 0.1170 0.1178 0.1189 

[TRAIN] Epoch[2](1027/1500); Loss: 0.152635; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1710 0.1746 0.1649 0.1585 0.1548 0.1520 0.1495 0.1479 0.1468 0.1460 0.1461 0.1460 0.1459 0.1458 0.1459 0.1463 

[TRAIN] Epoch[2](1028/1500); Loss: 0.059817; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0910 0.0916 0.0608 0.0596 0.0576 0.0568 0.0538 0.0536 0.0537 0.0526 0.0531 0.0538 0.0537 0.0541 0.0553 0.0560 

[TRAIN] Epoch[2](1029/1500); Loss: 0.127192; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1920 0.1773 0.1612 0.1493 0.1358 0.1288 0.1201 0.1115 0.1079 0.1080 0.1075 0.1072 0.1069 0.1072 0.1073 0.1073 

[TRAIN] Epoch[2](1030/1500); Loss: 0.108041; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1406 0.1375 0.1119 0.1111 0.1078 0.1061 0.1040 0.1023 0.1014 0.1008 0.1006 0.1004 0.1005 0.1008 0.1011 0.1019 

[TRAIN] Epoch[2](1031/1500); Loss: 0.099826; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.2027 0.1956 0.1208 0.0986 0.0914 0.0873 0.0829 0.0828 0.0804 0.0790 0.0790 0.0788 0.0781 0.0795 0.0800 0.0804 

[TRAIN] Epoch[2](1032/1500); Loss: 0.071586; Backpropagation: 0.0916 sec; Batch: 0.4246 sec
0.1059 0.1092 0.0972 0.0809 0.0700 0.0667 0.0667 0.0631 0.0608 0.0603 0.0606 0.0598 0.0603 0.0611 0.0610 0.0617 

[TRAIN] Epoch[2](1033/1500); Loss: 0.101662; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1590 0.1615 0.1472 0.1244 0.1105 0.1040 0.0988 0.0907 0.0857 0.0818 0.0793 0.0774 0.0768 0.0764 0.0765 0.0765 

[TRAIN] Epoch[2](1034/1500); Loss: 0.093813; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1081 0.1039 0.0984 0.0960 0.0946 0.0918 0.0909 0.0899 0.0898 0.0899 0.0898 0.0903 0.0906 0.0910 0.0926 0.0934 

[TRAIN] Epoch[2](1035/1500); Loss: 0.129670; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1830 0.1724 0.1577 0.1423 0.1328 0.1277 0.1219 0.1186 0.1172 0.1156 0.1144 0.1143 0.1138 0.1141 0.1145 0.1146 

[TRAIN] Epoch[2](1036/1500); Loss: 0.096746; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1126 0.1206 0.1045 0.1061 0.1010 0.0945 0.0897 0.0894 0.0892 0.0891 0.0887 0.0894 0.0912 0.0920 0.0943 0.0957 

[TRAIN] Epoch[2](1037/1500); Loss: 0.149201; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1700 0.1717 0.1588 0.1553 0.1530 0.1510 0.1477 0.1452 0.1436 0.1427 0.1418 0.1413 0.1409 0.1413 0.1413 0.1416 

[TRAIN] Epoch[2](1038/1500); Loss: 0.064107; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1484 0.1288 0.0489 0.0677 0.0565 0.0467 0.0523 0.0472 0.0501 0.0476 0.0510 0.0532 0.0525 0.0562 0.0588 0.0599 

[TRAIN] Epoch[2](1039/1500); Loss: 0.088175; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1443 0.1182 0.1046 0.0925 0.0880 0.0822 0.0799 0.0790 0.0775 0.0767 0.0763 0.0768 0.0772 0.0777 0.0798 0.0803 

[TRAIN] Epoch[2](1040/1500); Loss: 0.110263; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1422 0.1401 0.1279 0.1177 0.1116 0.1060 0.1039 0.1028 0.1016 0.1013 0.1013 0.1010 0.1012 0.1013 0.1019 0.1025 

[TRAIN] Epoch[2](1041/1500); Loss: 0.114721; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1385 0.1371 0.1225 0.1166 0.1141 0.1127 0.1109 0.1101 0.1096 0.1091 0.1086 0.1085 0.1087 0.1088 0.1096 0.1101 

[TRAIN] Epoch[2](1042/1500); Loss: 0.120941; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1460 0.1478 0.1350 0.1286 0.1244 0.1224 0.1195 0.1167 0.1142 0.1120 0.1109 0.1107 0.1113 0.1116 0.1117 0.1123 

[TRAIN] Epoch[2](1043/1500); Loss: 0.140051; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1709 0.1692 0.1582 0.1541 0.1466 0.1401 0.1361 0.1337 0.1322 0.1301 0.1287 0.1283 0.1278 0.1277 0.1281 0.1287 

[TRAIN] Epoch[2](1044/1500); Loss: 0.083952; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.0933 0.0951 0.0878 0.0838 0.0826 0.0814 0.0814 0.0810 0.0807 0.0808 0.0808 0.0812 0.0821 0.0831 0.0835 0.0844 

[TRAIN] Epoch[2](1045/1500); Loss: 0.108735; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1383 0.1301 0.1203 0.1122 0.1082 0.1070 0.1044 0.1027 0.1020 0.1013 0.1012 0.1014 0.1020 0.1022 0.1028 0.1037 

[TRAIN] Epoch[2](1046/1500); Loss: 0.154209; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1700 0.1805 0.1670 0.1566 0.1522 0.1491 0.1481 0.1479 0.1478 0.1482 0.1492 0.1487 0.1495 0.1505 0.1505 0.1515 

[TRAIN] Epoch[2](1047/1500); Loss: 0.044341; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0624 0.0816 0.0475 0.0387 0.0378 0.0362 0.0366 0.0371 0.0370 0.0386 0.0395 0.0400 0.0421 0.0433 0.0447 0.0464 

[TRAIN] Epoch[2](1048/1500); Loss: 0.117433; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1420 0.1405 0.1278 0.1197 0.1166 0.1147 0.1128 0.1117 0.1112 0.1108 0.1106 0.1108 0.1113 0.1119 0.1128 0.1137 

[TRAIN] Epoch[2](1049/1500); Loss: 0.101907; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1288 0.1300 0.1157 0.1058 0.1020 0.0987 0.0960 0.0946 0.0941 0.0930 0.0933 0.0940 0.0943 0.0955 0.0968 0.0980 

[TRAIN] Epoch[2](1050/1500); Loss: 0.116704; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1529 0.1526 0.1223 0.1162 0.1133 0.1118 0.1104 0.1093 0.1090 0.1088 0.1087 0.1091 0.1097 0.1105 0.1111 0.1115 

[TRAIN] Epoch[2](1051/1500); Loss: 0.093062; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1314 0.1304 0.1130 0.1041 0.0950 0.0920 0.0882 0.0836 0.0816 0.0811 0.0805 0.0809 0.0815 0.0814 0.0820 0.0824 

[TRAIN] Epoch[2](1052/1500); Loss: 0.176246; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2068 0.2059 0.1982 0.1849 0.1771 0.1738 0.1722 0.1702 0.1678 0.1671 0.1665 0.1655 0.1655 0.1659 0.1659 0.1667 

[TRAIN] Epoch[2](1053/1500); Loss: 0.146676; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1538 0.1554 0.1476 0.1458 0.1445 0.1432 0.1429 0.1428 0.1429 0.1438 0.1444 0.1451 0.1464 0.1479 0.1494 0.1509 

[TRAIN] Epoch[2](1054/1500); Loss: 0.090728; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1486 0.1498 0.1319 0.1090 0.0972 0.0878 0.0805 0.0762 0.0744 0.0724 0.0713 0.0713 0.0702 0.0703 0.0706 0.0702 

[TRAIN] Epoch[2](1055/1500); Loss: 0.071820; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1371 0.1398 0.1182 0.0897 0.0743 0.0629 0.0565 0.0536 0.0520 0.0512 0.0515 0.0510 0.0515 0.0523 0.0532 0.0544 

[TRAIN] Epoch[2](1056/1500); Loss: 0.094060; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1267 0.1288 0.1162 0.1051 0.0998 0.0949 0.0913 0.0885 0.0869 0.0848 0.0826 0.0814 0.0797 0.0798 0.0794 0.0790 

[TRAIN] Epoch[2](1057/1500); Loss: 0.096792; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1272 0.1251 0.1136 0.1031 0.0976 0.0951 0.0920 0.0893 0.0883 0.0871 0.0870 0.0873 0.0877 0.0886 0.0894 0.0901 

[TRAIN] Epoch[2](1058/1500); Loss: 0.141053; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1808 0.1708 0.1572 0.1464 0.1408 0.1393 0.1363 0.1342 0.1328 0.1318 0.1312 0.1310 0.1307 0.1309 0.1312 0.1312 

[TRAIN] Epoch[2](1059/1500); Loss: 0.101961; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1247 0.1189 0.1077 0.1019 0.1002 0.0989 0.0980 0.0974 0.0973 0.0971 0.0972 0.0978 0.0978 0.0983 0.0991 0.0992 

[TRAIN] Epoch[2](1060/1500); Loss: 0.088602; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1303 0.1266 0.1118 0.0975 0.0889 0.0861 0.0824 0.0795 0.0786 0.0773 0.0761 0.0761 0.0759 0.0761 0.0768 0.0778 

[TRAIN] Epoch[2](1061/1500); Loss: 0.055528; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0719 0.0661 0.0583 0.0553 0.0539 0.0526 0.0503 0.0492 0.0501 0.0501 0.0506 0.0524 0.0542 0.0551 0.0578 0.0606 

[TRAIN] Epoch[2](1062/1500); Loss: 0.130730; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1575 0.1606 0.1355 0.1309 0.1293 0.1278 0.1257 0.1245 0.1238 0.1239 0.1238 0.1243 0.1248 0.1254 0.1263 0.1277 

[TRAIN] Epoch[2](1063/1500); Loss: 0.125578; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1476 0.1558 0.1464 0.1410 0.1314 0.1221 0.1204 0.1179 0.1163 0.1154 0.1151 0.1151 0.1152 0.1161 0.1162 0.1174 

[TRAIN] Epoch[2](1064/1500); Loss: 0.076198; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1057 0.1076 0.0881 0.0790 0.0753 0.0730 0.0701 0.0689 0.0684 0.0679 0.0675 0.0676 0.0682 0.0692 0.0703 0.0725 

[TRAIN] Epoch[2](1065/1500); Loss: 0.069364; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1088 0.1159 0.0940 0.0793 0.0693 0.0631 0.0586 0.0571 0.0566 0.0564 0.0564 0.0572 0.0579 0.0586 0.0597 0.0608 

[TRAIN] Epoch[2](1066/1500); Loss: 0.195321; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2199 0.2281 0.2149 0.1994 0.1926 0.1907 0.1922 0.1924 0.1913 0.1885 0.1880 0.1869 0.1851 0.1855 0.1851 0.1847 

[TRAIN] Epoch[2](1067/1500); Loss: 0.090778; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1220 0.1265 0.1114 0.0986 0.0919 0.0869 0.0840 0.0821 0.0812 0.0804 0.0798 0.0804 0.0807 0.0809 0.0823 0.0833 

[TRAIN] Epoch[2](1068/1500); Loss: 0.140546; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1682 0.1567 0.1493 0.1431 0.1389 0.1369 0.1352 0.1344 0.1340 0.1342 0.1345 0.1350 0.1358 0.1365 0.1374 0.1388 

[TRAIN] Epoch[2](1069/1500); Loss: 0.107608; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1586 0.1490 0.1244 0.1133 0.1042 0.1001 0.0981 0.0979 0.0971 0.0966 0.0965 0.0965 0.0968 0.0973 0.0977 0.0978 

[TRAIN] Epoch[2](1070/1500); Loss: 0.096702; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1231 0.1292 0.1099 0.1057 0.0974 0.0950 0.0917 0.0890 0.0874 0.0869 0.0868 0.0876 0.0882 0.0885 0.0898 0.0911 

[TRAIN] Epoch[2](1071/1500); Loss: 0.060389; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0838 0.0939 0.0746 0.0628 0.0611 0.0565 0.0553 0.0534 0.0533 0.0531 0.0519 0.0535 0.0528 0.0523 0.0539 0.0540 

[TRAIN] Epoch[2](1072/1500); Loss: 0.146442; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1811 0.1723 0.1586 0.1494 0.1457 0.1438 0.1416 0.1403 0.1393 0.1388 0.1386 0.1383 0.1385 0.1388 0.1387 0.1390 

[TRAIN] Epoch[2](1073/1500); Loss: 0.123537; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1668 0.1681 0.1496 0.1326 0.1258 0.1214 0.1174 0.1150 0.1131 0.1116 0.1104 0.1095 0.1092 0.1084 0.1085 0.1093 

[TRAIN] Epoch[2](1074/1500); Loss: 0.133213; Backpropagation: 0.0915 sec; Batch: 0.4231 sec
0.1725 0.1618 0.1496 0.1397 0.1327 0.1300 0.1271 0.1253 0.1249 0.1243 0.1241 0.1239 0.1236 0.1237 0.1239 0.1243 

[TRAIN] Epoch[2](1075/1500); Loss: 0.126667; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1793 0.1740 0.1406 0.1276 0.1225 0.1197 0.1176 0.1155 0.1152 0.1153 0.1162 0.1153 0.1157 0.1170 0.1174 0.1177 

[TRAIN] Epoch[2](1076/1500); Loss: 0.173713; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.2449 0.2261 0.2144 0.2002 0.1850 0.1782 0.1681 0.1589 0.1551 0.1521 0.1501 0.1497 0.1494 0.1490 0.1490 0.1491 

[TRAIN] Epoch[2](1077/1500); Loss: 0.110199; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2061 0.1707 0.1579 0.1370 0.1170 0.1098 0.0990 0.0894 0.0875 0.0861 0.0845 0.0840 0.0833 0.0833 0.0837 0.0840 

[TRAIN] Epoch[2](1078/1500); Loss: 0.077347; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1553 0.1479 0.0816 0.0706 0.0661 0.0642 0.0636 0.0632 0.0629 0.0639 0.0639 0.0646 0.0660 0.0665 0.0680 0.0693 

[TRAIN] Epoch[2](1079/1500); Loss: 0.138279; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1856 0.1873 0.1566 0.1465 0.1424 0.1357 0.1311 0.1277 0.1255 0.1249 0.1244 0.1240 0.1245 0.1251 0.1254 0.1259 

[TRAIN] Epoch[2](1080/1500); Loss: 0.105735; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1360 0.1382 0.1159 0.1107 0.1077 0.1044 0.1018 0.1002 0.0986 0.0976 0.0967 0.0963 0.0963 0.0964 0.0970 0.0981 

[TRAIN] Epoch[2](1081/1500); Loss: 0.081754; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1548 0.1315 0.1070 0.0960 0.0810 0.0758 0.0706 0.0688 0.0666 0.0655 0.0651 0.0649 0.0649 0.0646 0.0650 0.0658 

[TRAIN] Epoch[2](1082/1500); Loss: 0.099718; Backpropagation: 0.0915 sec; Batch: 0.4233 sec
0.1812 0.1766 0.1317 0.1085 0.0967 0.0900 0.0829 0.0809 0.0796 0.0796 0.0797 0.0800 0.0809 0.0813 0.0823 0.0834 

[TRAIN] Epoch[2](1083/1500); Loss: 0.091174; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1241 0.1239 0.1092 0.1018 0.0950 0.0927 0.0888 0.0839 0.0817 0.0799 0.0794 0.0791 0.0789 0.0792 0.0800 0.0812 

[TRAIN] Epoch[2](1084/1500); Loss: 0.103080; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1855 0.1696 0.1254 0.1111 0.0962 0.0926 0.0892 0.0876 0.0874 0.0860 0.0859 0.0860 0.0859 0.0866 0.0870 0.0872 

[TRAIN] Epoch[2](1085/1500); Loss: 0.109626; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1332 0.1329 0.1180 0.1121 0.1089 0.1070 0.1062 0.1051 0.1040 0.1038 0.1032 0.1034 0.1037 0.1036 0.1042 0.1049 

[TRAIN] Epoch[2](1086/1500); Loss: 0.125287; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1449 0.1441 0.1344 0.1301 0.1260 0.1235 0.1220 0.1214 0.1209 0.1206 0.1196 0.1190 0.1189 0.1194 0.1199 0.1198 

[TRAIN] Epoch[2](1087/1500); Loss: 0.102113; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1337 0.1342 0.1188 0.1083 0.1011 0.0978 0.0951 0.0933 0.0942 0.0939 0.0934 0.0939 0.0934 0.0935 0.0947 0.0945 

[TRAIN] Epoch[2](1088/1500); Loss: 0.132778; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1923 0.1727 0.1591 0.1507 0.1364 0.1290 0.1215 0.1177 0.1181 0.1168 0.1170 0.1175 0.1173 0.1183 0.1195 0.1205 

[TRAIN] Epoch[2](1089/1500); Loss: 0.102496; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1728 0.1574 0.1216 0.1124 0.1007 0.0951 0.0910 0.0889 0.0877 0.0866 0.0865 0.0862 0.0872 0.0879 0.0886 0.0894 

[TRAIN] Epoch[2](1090/1500); Loss: 0.118970; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1960 0.1927 0.1199 0.1305 0.1277 0.1193 0.1075 0.1035 0.1004 0.1004 0.0987 0.1018 0.1006 0.1007 0.1013 0.1024 

[TRAIN] Epoch[2](1091/1500); Loss: 0.157963; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1897 0.1669 0.1708 0.1690 0.1650 0.1585 0.1539 0.1524 0.1499 0.1484 0.1488 0.1488 0.1492 0.1509 0.1520 0.1533 

[TRAIN] Epoch[2](1092/1500); Loss: 0.175273; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2180 0.2014 0.1926 0.1902 0.1864 0.1802 0.1743 0.1704 0.1666 0.1639 0.1621 0.1603 0.1597 0.1597 0.1593 0.1593 

[TRAIN] Epoch[2](1093/1500); Loss: 0.121843; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1487 0.1466 0.1028 0.1241 0.1184 0.1198 0.1163 0.1151 0.1131 0.1132 0.1152 0.1165 0.1200 0.1224 0.1264 0.1308 

[TRAIN] Epoch[2](1094/1500); Loss: 0.212068; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2173 0.2157 0.2137 0.2140 0.2129 0.2112 0.2098 0.2094 0.2092 0.2092 0.2093 0.2099 0.2108 0.2122 0.2136 0.2149 

[TRAIN] Epoch[2](1095/1500); Loss: 0.248356; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2238 0.2280 0.2377 0.2447 0.2468 0.2493 0.2499 0.2515 0.2518 0.2529 0.2533 0.2543 0.2555 0.2566 0.2582 0.2595 

[TRAIN] Epoch[2](1096/1500); Loss: 0.456292; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2958 0.3023 0.3458 0.3796 0.4001 0.4206 0.4387 0.4562 0.4724 0.4904 0.5063 0.5245 0.5407 0.5585 0.5755 0.5933 

[TRAIN] Epoch[2](1097/1500); Loss: 0.150764; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1848 0.1835 0.1332 0.1260 0.1302 0.1361 0.1393 0.1436 0.1464 0.1494 0.1507 0.1532 0.1549 0.1577 0.1601 0.1631 

[TRAIN] Epoch[2](1098/1500); Loss: 0.270077; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1349 0.1374 0.1227 0.1672 0.1957 0.2256 0.2492 0.2726 0.2896 0.3100 0.3255 0.3450 0.3599 0.3790 0.3943 0.4128 

[TRAIN] Epoch[2](1099/1500); Loss: 0.139577; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1151 0.1197 0.1254 0.1304 0.1320 0.1350 0.1378 0.1400 0.1426 0.1448 0.1469 0.1489 0.1508 0.1526 0.1547 0.1563 

[TRAIN] Epoch[2](1100/1500); Loss: 0.214888; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1611 0.1663 0.1633 0.1835 0.1978 0.2072 0.2142 0.2200 0.2249 0.2294 0.2337 0.2384 0.2427 0.2473 0.2518 0.2566 

[TRAIN] Epoch[2](1101/1500); Loss: 0.227097; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2228 0.2184 0.2057 0.2116 0.2175 0.2217 0.2239 0.2268 0.2283 0.2309 0.2323 0.2347 0.2364 0.2387 0.2407 0.2431 

[TRAIN] Epoch[2](1102/1500); Loss: 0.314159; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2983 0.2955 0.2942 0.2993 0.3050 0.3099 0.3115 0.3146 0.3162 0.3191 0.3209 0.3237 0.3257 0.3285 0.3307 0.3334 

[TRAIN] Epoch[2](1103/1500); Loss: 0.157014; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1553 0.1536 0.1522 0.1546 0.1550 0.1553 0.1552 0.1558 0.1561 0.1570 0.1576 0.1586 0.1595 0.1608 0.1621 0.1635 

[TRAIN] Epoch[2](1104/1500); Loss: 0.179453; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1601 0.1664 0.1621 0.1693 0.1731 0.1760 0.1781 0.1799 0.1815 0.1833 0.1850 0.1870 0.1890 0.1912 0.1935 0.1959 

[TRAIN] Epoch[2](1105/1500); Loss: 0.261921; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2565 0.2586 0.2568 0.2594 0.2598 0.2610 0.2610 0.2619 0.2620 0.2630 0.2633 0.2642 0.2646 0.2655 0.2661 0.2671 

[TRAIN] Epoch[2](1106/1500); Loss: 0.265399; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.2644 0.2629 0.2631 0.2652 0.2645 0.2647 0.2644 0.2650 0.2649 0.2656 0.2657 0.2663 0.2666 0.2672 0.2676 0.2683 

[TRAIN] Epoch[2](1107/1500); Loss: 0.172020; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1764 0.1785 0.1723 0.1728 0.1715 0.1712 0.1707 0.1707 0.1703 0.1705 0.1704 0.1707 0.1709 0.1713 0.1717 0.1723 

[TRAIN] Epoch[2](1108/1500); Loss: 0.112714; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1480 0.1440 0.0955 0.1014 0.1027 0.1033 0.1051 0.1054 0.1068 0.1078 0.1094 0.1109 0.1127 0.1146 0.1167 0.1190 

[TRAIN] Epoch[2](1109/1500); Loss: 0.202417; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2033 0.2020 0.2049 0.2059 0.2053 0.2038 0.2027 0.2021 0.2014 0.2011 0.2007 0.2007 0.2007 0.2009 0.2012 0.2017 

[TRAIN] Epoch[2](1110/1500); Loss: 0.194980; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1753 0.1823 0.1907 0.1970 0.1972 0.1980 0.1971 0.1978 0.1970 0.1977 0.1973 0.1979 0.1978 0.1985 0.1986 0.1994 

[TRAIN] Epoch[2](1111/1500); Loss: 0.130586; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1594 0.1610 0.1318 0.1261 0.1242 0.1246 0.1239 0.1243 0.1241 0.1248 0.1251 0.1261 0.1268 0.1280 0.1290 0.1304 

[TRAIN] Epoch[2](1112/1500); Loss: 0.176264; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1592 0.1648 0.1630 0.1721 0.1741 0.1753 0.1760 0.1770 0.1778 0.1790 0.1800 0.1814 0.1828 0.1843 0.1859 0.1876 

[TRAIN] Epoch[2](1113/1500); Loss: 0.662357; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.6445 0.6387 0.6526 0.6584 0.6596 0.6617 0.6618 0.6640 0.6644 0.6664 0.6672 0.6690 0.6700 0.6717 0.6730 0.6746 

[TRAIN] Epoch[2](1114/1500); Loss: 0.153324; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1430 0.1514 0.1546 0.1572 0.1567 0.1562 0.1549 0.1546 0.1537 0.1535 0.1529 0.1528 0.1526 0.1528 0.1530 0.1534 

[TRAIN] Epoch[2](1115/1500); Loss: 0.133411; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1341 0.1363 0.1359 0.1366 0.1360 0.1349 0.1340 0.1334 0.1327 0.1323 0.1318 0.1315 0.1313 0.1312 0.1312 0.1314 

[TRAIN] Epoch[2](1116/1500); Loss: 0.129584; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1330 0.1311 0.1334 0.1336 0.1320 0.1297 0.1281 0.1271 0.1262 0.1259 0.1259 0.1264 0.1274 0.1290 0.1310 0.1335 

[TRAIN] Epoch[2](1117/1500); Loss: 0.111573; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1226 0.1238 0.1219 0.1201 0.1175 0.1147 0.1124 0.1103 0.1085 0.1069 0.1057 0.1048 0.1042 0.1039 0.1038 0.1040 

[TRAIN] Epoch[2](1118/1500); Loss: 0.121327; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1311 0.1314 0.1239 0.1214 0.1202 0.1190 0.1185 0.1183 0.1183 0.1184 0.1187 0.1192 0.1197 0.1203 0.1210 0.1218 

[TRAIN] Epoch[2](1119/1500); Loss: 0.149702; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1584 0.1576 0.1535 0.1521 0.1495 0.1478 0.1464 0.1456 0.1452 0.1452 0.1456 0.1465 0.1478 0.1494 0.1513 0.1535 

[TRAIN] Epoch[2](1120/1500); Loss: 0.174734; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1830 0.1810 0.1802 0.1800 0.1783 0.1769 0.1755 0.1743 0.1732 0.1722 0.1714 0.1708 0.1702 0.1698 0.1696 0.1694 

[TRAIN] Epoch[2](1121/1500); Loss: 0.254056; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2733 0.2679 0.2704 0.2688 0.2656 0.2622 0.2590 0.2559 0.2528 0.2498 0.2469 0.2440 0.2412 0.2384 0.2357 0.2330 

[TRAIN] Epoch[2](1122/1500); Loss: 0.143261; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1545 0.1565 0.1515 0.1499 0.1475 0.1451 0.1432 0.1415 0.1402 0.1390 0.1381 0.1374 0.1370 0.1368 0.1369 0.1373 

[TRAIN] Epoch[2](1123/1500); Loss: 0.157363; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1671 0.1648 0.1629 0.1611 0.1592 0.1576 0.1564 0.1554 0.1546 0.1541 0.1538 0.1536 0.1537 0.1539 0.1544 0.1551 

[TRAIN] Epoch[2](1124/1500); Loss: 0.067624; Backpropagation: 0.0916 sec; Batch: 0.4245 sec
0.0829 0.0913 0.0723 0.0695 0.0670 0.0656 0.0641 0.0635 0.0628 0.0626 0.0624 0.0626 0.0629 0.0635 0.0641 0.0650 

[TRAIN] Epoch[2](1125/1500); Loss: 0.156159; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2515 0.2432 0.1868 0.1642 0.1525 0.1428 0.1369 0.1354 0.1350 0.1349 0.1349 0.1351 0.1355 0.1360 0.1365 0.1373 

[TRAIN] Epoch[2](1126/1500); Loss: 0.216490; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2373 0.2318 0.2334 0.2315 0.2282 0.2245 0.2211 0.2178 0.2147 0.2116 0.2087 0.2058 0.2031 0.2005 0.1980 0.1956 

[TRAIN] Epoch[2](1127/1500); Loss: 0.070240; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0930 0.0987 0.0757 0.0713 0.0687 0.0668 0.0650 0.0644 0.0639 0.0640 0.0640 0.0643 0.0648 0.0655 0.0663 0.0674 

[TRAIN] Epoch[2](1128/1500); Loss: 0.123552; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1295 0.1326 0.1264 0.1262 0.1251 0.1241 0.1230 0.1224 0.1217 0.1213 0.1209 0.1207 0.1206 0.1206 0.1208 0.1210 

[TRAIN] Epoch[2](1129/1500); Loss: 0.117353; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1284 0.1310 0.1209 0.1184 0.1162 0.1147 0.1139 0.1133 0.1131 0.1132 0.1136 0.1141 0.1149 0.1159 0.1172 0.1188 

[TRAIN] Epoch[2](1130/1500); Loss: 0.251374; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2626 0.2601 0.2587 0.2569 0.2553 0.2538 0.2524 0.2512 0.2500 0.2489 0.2477 0.2467 0.2457 0.2448 0.2439 0.2432 

[TRAIN] Epoch[2](1131/1500); Loss: 0.090089; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0946 0.0968 0.0910 0.0891 0.0883 0.0879 0.0879 0.0880 0.0885 0.0890 0.0895 0.0897 0.0900 0.0902 0.0904 0.0903 

[TRAIN] Epoch[2](1132/1500); Loss: 0.169049; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1763 0.1767 0.1690 0.1664 0.1656 0.1652 0.1651 0.1652 0.1658 0.1666 0.1677 0.1687 0.1699 0.1710 0.1723 0.1735 

[TRAIN] Epoch[2](1133/1500); Loss: 0.096079; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1026 0.0986 0.0970 0.0950 0.0930 0.0919 0.0915 0.0917 0.0923 0.0932 0.0944 0.0960 0.0976 0.0993 0.1009 0.1024 

[TRAIN] Epoch[2](1134/1500); Loss: 0.065208; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0644 0.0768 0.0715 0.0711 0.0691 0.0670 0.0651 0.0637 0.0624 0.0616 0.0611 0.0610 0.0612 0.0617 0.0625 0.0634 

[TRAIN] Epoch[2](1135/1500); Loss: 0.193222; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2081 0.2058 0.1972 0.1955 0.1941 0.1929 0.1920 0.1913 0.1906 0.1901 0.1897 0.1893 0.1891 0.1888 0.1886 0.1884 

[TRAIN] Epoch[2](1136/1500); Loss: 0.154028; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1706 0.1726 0.1535 0.1532 0.1520 0.1513 0.1507 0.1503 0.1502 0.1502 0.1505 0.1507 0.1513 0.1518 0.1525 0.1532 

[TRAIN] Epoch[2](1137/1500); Loss: 0.147507; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1657 0.1624 0.1562 0.1525 0.1499 0.1477 0.1462 0.1449 0.1439 0.1429 0.1422 0.1416 0.1412 0.1409 0.1409 0.1410 

[TRAIN] Epoch[2](1138/1500); Loss: 0.117221; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1404 0.1414 0.1208 0.1170 0.1154 0.1149 0.1134 0.1130 0.1121 0.1120 0.1117 0.1119 0.1120 0.1126 0.1131 0.1138 

[TRAIN] Epoch[2](1139/1500); Loss: 0.201038; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1792 0.1756 0.1818 0.1823 0.1859 0.1875 0.1907 0.1937 0.1976 0.2020 0.2072 0.2130 0.2194 0.2262 0.2335 0.2411 

[TRAIN] Epoch[2](1140/1500); Loss: 0.160019; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1644 0.1632 0.1615 0.1603 0.1588 0.1578 0.1570 0.1567 0.1567 0.1570 0.1576 0.1586 0.1600 0.1616 0.1635 0.1656 

[TRAIN] Epoch[2](1141/1500); Loss: 0.225292; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2374 0.2299 0.2365 0.2359 0.2338 0.2315 0.2294 0.2273 0.2252 0.2231 0.2210 0.2189 0.2168 0.2147 0.2127 0.2107 

[TRAIN] Epoch[2](1142/1500); Loss: 0.103263; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1116 0.1113 0.1118 0.1111 0.1091 0.1070 0.1050 0.1032 0.1016 0.1002 0.0988 0.0977 0.0968 0.0961 0.0956 0.0953 

[TRAIN] Epoch[2](1143/1500); Loss: 0.105045; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1206 0.1168 0.1129 0.1099 0.1062 0.1035 0.1014 0.1001 0.0994 0.0991 0.0994 0.1000 0.1009 0.1022 0.1035 0.1049 

[TRAIN] Epoch[2](1144/1500); Loss: 0.160160; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1844 0.1772 0.1783 0.1757 0.1718 0.1676 0.1638 0.1603 0.1570 0.1540 0.1512 0.1487 0.1463 0.1441 0.1420 0.1401 

[TRAIN] Epoch[2](1145/1500); Loss: 0.253550; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2627 0.2678 0.2554 0.2553 0.2536 0.2531 0.2520 0.2516 0.2509 0.2507 0.2503 0.2503 0.2503 0.2506 0.2509 0.2514 

[TRAIN] Epoch[2](1146/1500); Loss: 0.107873; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2261 0.2191 0.1416 0.1088 0.0916 0.0861 0.0842 0.0840 0.0834 0.0837 0.0838 0.0847 0.0854 0.0866 0.0876 0.0890 

[TRAIN] Epoch[2](1147/1500); Loss: 0.152574; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1857 0.1830 0.1595 0.1539 0.1514 0.1496 0.1478 0.1468 0.1460 0.1456 0.1452 0.1451 0.1451 0.1452 0.1455 0.1459 

[TRAIN] Epoch[2](1148/1500); Loss: 0.148493; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1590 0.1606 0.1475 0.1467 0.1456 0.1455 0.1451 0.1453 0.1454 0.1458 0.1463 0.1470 0.1477 0.1486 0.1495 0.1504 

[TRAIN] Epoch[2](1149/1500); Loss: 0.148793; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1781 0.1782 0.1594 0.1522 0.1499 0.1474 0.1453 0.1433 0.1423 0.1411 0.1409 0.1402 0.1402 0.1401 0.1407 0.1411 

[TRAIN] Epoch[2](1150/1500); Loss: 0.113101; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1225 0.1208 0.1209 0.1195 0.1175 0.1155 0.1138 0.1123 0.1110 0.1098 0.1089 0.1081 0.1076 0.1072 0.1071 0.1071 

[TRAIN] Epoch[2](1151/1500); Loss: 0.171926; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1727 0.1755 0.1746 0.1752 0.1741 0.1734 0.1723 0.1717 0.1710 0.1707 0.1702 0.1700 0.1698 0.1698 0.1699 0.1700 

[TRAIN] Epoch[2](1152/1500); Loss: 0.076358; Backpropagation: 0.0915 sec; Batch: 0.4226 sec
0.0965 0.1003 0.0796 0.0786 0.0761 0.0742 0.0728 0.0717 0.0710 0.0705 0.0705 0.0706 0.0711 0.0718 0.0727 0.0737 

[TRAIN] Epoch[2](1153/1500); Loss: 0.385483; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.4019 0.3973 0.4011 0.3993 0.3965 0.3934 0.3906 0.3877 0.3848 0.3820 0.3792 0.3764 0.3736 0.3708 0.3680 0.3653 

[TRAIN] Epoch[2](1154/1500); Loss: 0.188844; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1978 0.1972 0.1938 0.1919 0.1904 0.1889 0.1878 0.1870 0.1865 0.1860 0.1858 0.1856 0.1856 0.1856 0.1857 0.1859 

[TRAIN] Epoch[2](1155/1500); Loss: 0.085320; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0978 0.0978 0.0886 0.0877 0.0859 0.0845 0.0833 0.0825 0.0819 0.0816 0.0815 0.0817 0.0820 0.0824 0.0829 0.0833 

[TRAIN] Epoch[2](1156/1500); Loss: 0.084161; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.0883 0.0845 0.0826 0.0808 0.0798 0.0797 0.0803 0.0814 0.0828 0.0840 0.0852 0.0862 0.0869 0.0874 0.0880 0.0888 

[TRAIN] Epoch[2](1157/1500); Loss: 0.061249; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0584 0.0702 0.0609 0.0625 0.0612 0.0601 0.0589 0.0585 0.0584 0.0586 0.0592 0.0600 0.0611 0.0624 0.0639 0.0656 

[TRAIN] Epoch[2](1158/1500); Loss: 0.066391; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.0848 0.0881 0.0620 0.0617 0.0610 0.0610 0.0611 0.0616 0.0625 0.0637 0.0643 0.0646 0.0651 0.0658 0.0669 0.0680 

[TRAIN] Epoch[2](1159/1500); Loss: 0.125265; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1370 0.1337 0.1336 0.1324 0.1303 0.1281 0.1261 0.1244 0.1229 0.1216 0.1205 0.1196 0.1190 0.1185 0.1183 0.1183 

[TRAIN] Epoch[2](1160/1500); Loss: 0.150366; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1765 0.1776 0.1507 0.1519 0.1492 0.1480 0.1466 0.1457 0.1450 0.1446 0.1444 0.1444 0.1446 0.1450 0.1455 0.1462 

[TRAIN] Epoch[2](1161/1500); Loss: 0.086155; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1081 0.1135 0.0941 0.0907 0.0882 0.0848 0.0833 0.0813 0.0807 0.0797 0.0794 0.0788 0.0787 0.0785 0.0791 0.0794 

[TRAIN] Epoch[2](1162/1500); Loss: 0.144563; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1620 0.1639 0.1496 0.1456 0.1435 0.1419 0.1407 0.1400 0.1397 0.1396 0.1399 0.1401 0.1406 0.1411 0.1420 0.1430 

[TRAIN] Epoch[2](1163/1500); Loss: 0.072334; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0930 0.0888 0.0797 0.0755 0.0728 0.0704 0.0686 0.0673 0.0665 0.0662 0.0663 0.0668 0.0675 0.0682 0.0693 0.0704 

[TRAIN] Epoch[2](1164/1500); Loss: 0.099645; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1786 0.1755 0.1254 0.1058 0.0941 0.0864 0.0832 0.0825 0.0823 0.0820 0.0822 0.0822 0.0827 0.0831 0.0839 0.0844 

[TRAIN] Epoch[2](1165/1500); Loss: 0.132997; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1433 0.1431 0.1385 0.1366 0.1349 0.1332 0.1321 0.1309 0.1302 0.1294 0.1291 0.1289 0.1289 0.1291 0.1296 0.1302 

[TRAIN] Epoch[2](1166/1500); Loss: 0.160014; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1744 0.1728 0.1700 0.1675 0.1647 0.1623 0.1603 0.1584 0.1569 0.1554 0.1543 0.1532 0.1527 0.1524 0.1523 0.1524 

[TRAIN] Epoch[2](1167/1500); Loss: 0.159626; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1661 0.1634 0.1656 0.1649 0.1634 0.1618 0.1604 0.1592 0.1582 0.1573 0.1566 0.1560 0.1556 0.1553 0.1551 0.1550 

[TRAIN] Epoch[2](1168/1500); Loss: 0.186167; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1929 0.1899 0.1909 0.1901 0.1889 0.1876 0.1865 0.1856 0.1848 0.1842 0.1836 0.1832 0.1829 0.1826 0.1826 0.1825 

[TRAIN] Epoch[2](1169/1500); Loss: 0.092551; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1040 0.1008 0.1001 0.0991 0.0969 0.0948 0.0928 0.0912 0.0897 0.0886 0.0876 0.0870 0.0867 0.0867 0.0870 0.0877 

[TRAIN] Epoch[2](1170/1500); Loss: 0.123682; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1594 0.1599 0.1249 0.1182 0.1168 0.1160 0.1159 0.1160 0.1164 0.1170 0.1177 0.1185 0.1193 0.1200 0.1208 0.1218 

[TRAIN] Epoch[2](1171/1500); Loss: 0.121140; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1319 0.1335 0.1255 0.1236 0.1223 0.1211 0.1201 0.1194 0.1188 0.1181 0.1177 0.1173 0.1171 0.1171 0.1174 0.1175 

[TRAIN] Epoch[2](1172/1500); Loss: 0.181977; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1955 0.1935 0.1904 0.1880 0.1859 0.1838 0.1820 0.1804 0.1791 0.1780 0.1770 0.1763 0.1758 0.1755 0.1753 0.1751 

[TRAIN] Epoch[2](1173/1500); Loss: 0.148248; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1622 0.1610 0.1578 0.1550 0.1527 0.1504 0.1487 0.1470 0.1456 0.1443 0.1433 0.1422 0.1414 0.1406 0.1401 0.1396 

[TRAIN] Epoch[2](1174/1500); Loss: 0.239242; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2645 0.2584 0.2604 0.2580 0.2539 0.2495 0.2453 0.2413 0.2374 0.2335 0.2297 0.2260 0.2225 0.2191 0.2158 0.2127 

[TRAIN] Epoch[2](1175/1500); Loss: 0.076894; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0915 0.0865 0.0843 0.0822 0.0799 0.0776 0.0756 0.0740 0.0728 0.0720 0.0716 0.0715 0.0718 0.0722 0.0729 0.0737 

[TRAIN] Epoch[2](1176/1500); Loss: 0.188456; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.2164 0.2110 0.2109 0.2080 0.2036 0.1990 0.1947 0.1905 0.1864 0.1822 0.1781 0.1741 0.1703 0.1666 0.1633 0.1602 

[TRAIN] Epoch[2](1177/1500); Loss: 0.197386; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2053 0.2066 0.2010 0.1999 0.1983 0.1971 0.1961 0.1953 0.1948 0.1944 0.1943 0.1943 0.1945 0.1949 0.1953 0.1959 

[TRAIN] Epoch[2](1178/1500); Loss: 0.078884; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.0933 0.0857 0.0856 0.0830 0.0804 0.0779 0.0765 0.0758 0.0757 0.0758 0.0761 0.0764 0.0761 0.0752 0.0744 0.0743 

[TRAIN] Epoch[2](1179/1500); Loss: 0.181437; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2060 0.2028 0.1975 0.1939 0.1903 0.1868 0.1837 0.1808 0.1779 0.1752 0.1729 0.1707 0.1688 0.1670 0.1653 0.1635 

[TRAIN] Epoch[2](1180/1500); Loss: 0.228033; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2393 0.2391 0.2353 0.2330 0.2312 0.2298 0.2284 0.2271 0.2260 0.2250 0.2241 0.2234 0.2226 0.2220 0.2214 0.2209 

[TRAIN] Epoch[2](1181/1500); Loss: 0.131820; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1354 0.1354 0.1312 0.1303 0.1297 0.1295 0.1294 0.1296 0.1300 0.1304 0.1311 0.1318 0.1327 0.1334 0.1343 0.1350 

[TRAIN] Epoch[2](1182/1500); Loss: 0.118834; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1336 0.1325 0.1262 0.1229 0.1208 0.1187 0.1171 0.1156 0.1148 0.1141 0.1140 0.1139 0.1140 0.1141 0.1144 0.1147 

[TRAIN] Epoch[2](1183/1500); Loss: 0.304880; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.3155 0.3119 0.3146 0.3133 0.3111 0.3092 0.3072 0.3054 0.3036 0.3020 0.3005 0.2991 0.2978 0.2966 0.2956 0.2947 

[TRAIN] Epoch[2](1184/1500); Loss: 0.205218; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2153 0.2127 0.2136 0.2126 0.2104 0.2083 0.2064 0.2048 0.2033 0.2021 0.2010 0.2000 0.1992 0.1984 0.1978 0.1974 

[TRAIN] Epoch[2](1185/1500); Loss: 0.194108; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2355 0.2255 0.2263 0.2220 0.2160 0.2092 0.2029 0.1968 0.1908 0.1849 0.1792 0.1736 0.1683 0.1631 0.1582 0.1536 

[TRAIN] Epoch[2](1186/1500); Loss: 0.258131; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2818 0.2778 0.2756 0.2723 0.2689 0.2653 0.2621 0.2588 0.2558 0.2527 0.2499 0.2470 0.2444 0.2417 0.2392 0.2368 

[TRAIN] Epoch[2](1187/1500); Loss: 0.123735; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1525 0.1510 0.1390 0.1349 0.1312 0.1278 0.1247 0.1219 0.1191 0.1167 0.1144 0.1122 0.1104 0.1089 0.1079 0.1073 

[TRAIN] Epoch[2](1188/1500); Loss: 0.302489; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.3319 0.3281 0.3265 0.3224 0.3179 0.3132 0.3089 0.3043 0.3001 0.2956 0.2915 0.2874 0.2836 0.2797 0.2761 0.2726 

[TRAIN] Epoch[2](1189/1500); Loss: 0.132936; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1474 0.1471 0.1403 0.1373 0.1349 0.1327 0.1311 0.1296 0.1287 0.1280 0.1277 0.1275 0.1278 0.1282 0.1290 0.1297 

[TRAIN] Epoch[2](1190/1500); Loss: 0.155425; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1703 0.1694 0.1660 0.1646 0.1620 0.1592 0.1567 0.1545 0.1525 0.1508 0.1492 0.1479 0.1469 0.1461 0.1455 0.1451 

[TRAIN] Epoch[2](1191/1500); Loss: 0.133009; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1410 0.1392 0.1360 0.1342 0.1328 0.1318 0.1311 0.1307 0.1305 0.1305 0.1307 0.1310 0.1314 0.1318 0.1324 0.1330 

[TRAIN] Epoch[2](1192/1500); Loss: 0.209841; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2345 0.2332 0.2233 0.2190 0.2154 0.2124 0.2096 0.2072 0.2052 0.2033 0.2019 0.2004 0.1992 0.1983 0.1976 0.1971 

[TRAIN] Epoch[2](1193/1500); Loss: 0.399027; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.4169 0.4130 0.4141 0.4122 0.4093 0.4062 0.4035 0.4006 0.3979 0.3952 0.3925 0.3898 0.3872 0.3846 0.3820 0.3794 

[TRAIN] Epoch[2](1194/1500); Loss: 0.053735; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.0655 0.0687 0.0572 0.0550 0.0538 0.0527 0.0516 0.0503 0.0496 0.0496 0.0498 0.0501 0.0505 0.0509 0.0517 0.0527 

[TRAIN] Epoch[2](1195/1500); Loss: 0.254741; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2759 0.2723 0.2723 0.2695 0.2659 0.2623 0.2590 0.2558 0.2526 0.2496 0.2467 0.2439 0.2412 0.2386 0.2362 0.2339 

[TRAIN] Epoch[2](1196/1500); Loss: 0.058425; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0570 0.0669 0.0574 0.0589 0.0574 0.0554 0.0541 0.0538 0.0541 0.0551 0.0566 0.0583 0.0599 0.0615 0.0633 0.0653 

[TRAIN] Epoch[2](1197/1500); Loss: 0.110882; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1366 0.1337 0.1242 0.1194 0.1156 0.1124 0.1098 0.1077 0.1059 0.1043 0.1029 0.1017 0.1008 0.1000 0.0996 0.0995 

[TRAIN] Epoch[2](1198/1500); Loss: 0.094078; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1285 0.1213 0.1106 0.1046 0.1001 0.0951 0.0910 0.0879 0.0854 0.0837 0.0827 0.0822 0.0822 0.0824 0.0832 0.0844 

[TRAIN] Epoch[2](1199/1500); Loss: 0.246541; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.2802 0.2740 0.2724 0.2688 0.2636 0.2581 0.2531 0.2482 0.2435 0.2389 0.2344 0.2301 0.2258 0.2217 0.2178 0.2140 

[TRAIN] Epoch[2](1200/1500); Loss: 0.158325; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1990 0.1948 0.1720 0.1667 0.1628 0.1590 0.1558 0.1531 0.1508 0.1489 0.1474 0.1462 0.1453 0.1445 0.1438 0.1431 

[TRAIN] Epoch[2](1201/1500); Loss: 0.145007; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1636 0.1649 0.1524 0.1485 0.1464 0.1444 0.1428 0.1412 0.1403 0.1395 0.1391 0.1387 0.1388 0.1392 0.1399 0.1405 

[TRAIN] Epoch[2](1202/1500); Loss: 0.118085; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1381 0.1335 0.1282 0.1254 0.1225 0.1198 0.1175 0.1156 0.1140 0.1128 0.1118 0.1109 0.1102 0.1096 0.1097 0.1097 

[TRAIN] Epoch[2](1203/1500); Loss: 0.080210; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1227 0.1298 0.0859 0.0808 0.0775 0.0747 0.0725 0.0712 0.0702 0.0699 0.0699 0.0701 0.0706 0.0715 0.0724 0.0737 

[TRAIN] Epoch[2](1204/1500); Loss: 0.424379; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.4583 0.4539 0.4509 0.4468 0.4415 0.4363 0.4315 0.4267 0.4219 0.4171 0.4124 0.4078 0.4031 0.3985 0.3939 0.3893 

[TRAIN] Epoch[2](1205/1500); Loss: 0.137807; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1592 0.1584 0.1454 0.1407 0.1381 0.1356 0.1336 0.1321 0.1313 0.1311 0.1314 0.1318 0.1326 0.1333 0.1346 0.1358 

[TRAIN] Epoch[2](1206/1500); Loss: 0.094672; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1246 0.1218 0.1010 0.0948 0.0909 0.0884 0.0874 0.0870 0.0872 0.0877 0.0883 0.0891 0.0903 0.0913 0.0921 0.0928 

[TRAIN] Epoch[2](1207/1500); Loss: 0.105766; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1203 0.1217 0.1069 0.1043 0.1028 0.1018 0.1014 0.1015 0.1018 0.1023 0.1029 0.1037 0.1042 0.1049 0.1054 0.1060 

[TRAIN] Epoch[2](1208/1500); Loss: 0.117543; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1376 0.1384 0.1249 0.1202 0.1177 0.1158 0.1145 0.1135 0.1126 0.1121 0.1118 0.1117 0.1119 0.1122 0.1127 0.1132 

[TRAIN] Epoch[2](1209/1500); Loss: 0.117971; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1488 0.1501 0.1178 0.1168 0.1146 0.1131 0.1118 0.1110 0.1107 0.1108 0.1113 0.1122 0.1132 0.1141 0.1152 0.1161 

[TRAIN] Epoch[2](1210/1500); Loss: 0.129451; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1618 0.1558 0.1538 0.1499 0.1447 0.1391 0.1338 0.1287 0.1238 0.1192 0.1151 0.1118 0.1094 0.1081 0.1078 0.1085 

[TRAIN] Epoch[2](1211/1500); Loss: 0.135866; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2286 0.2290 0.1653 0.1416 0.1267 0.1179 0.1159 0.1156 0.1152 0.1152 0.1155 0.1160 0.1167 0.1173 0.1181 0.1191 

[TRAIN] Epoch[2](1212/1500); Loss: 0.252327; Backpropagation: 0.0917 sec; Batch: 0.4224 sec
0.2930 0.2859 0.2859 0.2813 0.2750 0.2684 0.2621 0.2559 0.2497 0.2436 0.2375 0.2315 0.2256 0.2197 0.2139 0.2082 

[TRAIN] Epoch[2](1213/1500); Loss: 0.155716; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1706 0.1709 0.1574 0.1539 0.1516 0.1506 0.1505 0.1507 0.1512 0.1520 0.1530 0.1540 0.1551 0.1561 0.1567 0.1573 

[TRAIN] Epoch[2](1214/1500); Loss: 0.081153; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1373 0.1421 0.0705 0.0800 0.0764 0.0738 0.0720 0.0698 0.0689 0.0686 0.0692 0.0704 0.0720 0.0736 0.0758 0.0783 

[TRAIN] Epoch[2](1215/1500); Loss: 0.108802; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1262 0.1241 0.1188 0.1165 0.1136 0.1107 0.1083 0.1064 0.1048 0.1034 0.1024 0.1014 0.1009 0.1008 0.1011 0.1015 

[TRAIN] Epoch[2](1216/1500); Loss: 0.141871; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1728 0.1751 0.1538 0.1478 0.1438 0.1400 0.1374 0.1356 0.1347 0.1337 0.1334 0.1329 0.1326 0.1323 0.1322 0.1319 

[TRAIN] Epoch[2](1217/1500); Loss: 0.108834; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1351 0.1365 0.1127 0.1076 0.1044 0.1025 0.1017 0.1017 0.1021 0.1029 0.1039 0.1047 0.1056 0.1061 0.1067 0.1072 

[TRAIN] Epoch[2](1218/1500); Loss: 0.122307; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1366 0.1325 0.1294 0.1265 0.1239 0.1214 0.1196 0.1185 0.1179 0.1175 0.1175 0.1180 0.1185 0.1190 0.1196 0.1206 

[TRAIN] Epoch[2](1219/1500); Loss: 0.107381; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1081 0.1077 0.1053 0.1049 0.1046 0.1047 0.1051 0.1054 0.1061 0.1071 0.1083 0.1092 0.1096 0.1100 0.1106 0.1113 

[TRAIN] Epoch[2](1220/1500); Loss: 0.188835; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2318 0.2276 0.2091 0.2003 0.1958 0.1920 0.1886 0.1854 0.1825 0.1799 0.1774 0.1750 0.1727 0.1701 0.1678 0.1652 

[TRAIN] Epoch[2](1221/1500); Loss: 0.208351; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.2340 0.2311 0.2227 0.2182 0.2143 0.2105 0.2071 0.2037 0.2019 0.2006 0.1999 0.1992 0.1986 0.1979 0.1974 0.1966 

[TRAIN] Epoch[2](1222/1500); Loss: 0.090495; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0994 0.0998 0.0927 0.0901 0.0885 0.0876 0.0874 0.0877 0.0879 0.0879 0.0883 0.0887 0.0893 0.0901 0.0909 0.0916 

[TRAIN] Epoch[2](1223/1500); Loss: 0.288555; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.3282 0.3222 0.3223 0.3174 0.3108 0.3040 0.2978 0.2914 0.2853 0.2793 0.2734 0.2678 0.2622 0.2568 0.2515 0.2464 

[TRAIN] Epoch[2](1224/1500); Loss: 0.144410; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1697 0.1692 0.1522 0.1455 0.1409 0.1387 0.1377 0.1373 0.1373 0.1377 0.1383 0.1390 0.1399 0.1411 0.1424 0.1436 

[TRAIN] Epoch[2](1225/1500); Loss: 0.171971; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1716 0.1710 0.1704 0.1702 0.1700 0.1700 0.1703 0.1709 0.1717 0.1725 0.1733 0.1740 0.1743 0.1740 0.1737 0.1737 

[TRAIN] Epoch[2](1226/1500); Loss: 0.222552; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2548 0.2534 0.2380 0.2364 0.2323 0.2283 0.2244 0.2208 0.2176 0.2148 0.2123 0.2101 0.2080 0.2058 0.2032 0.2008 

[TRAIN] Epoch[2](1227/1500); Loss: 0.074018; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0989 0.0974 0.0857 0.0828 0.0789 0.0745 0.0712 0.0684 0.0666 0.0654 0.0647 0.0644 0.0650 0.0659 0.0666 0.0680 

[TRAIN] Epoch[2](1228/1500); Loss: 0.176358; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1879 0.1889 0.1826 0.1812 0.1791 0.1774 0.1759 0.1747 0.1738 0.1731 0.1724 0.1718 0.1713 0.1709 0.1705 0.1701 

[TRAIN] Epoch[2](1229/1500); Loss: 0.189019; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2425 0.2335 0.2324 0.2265 0.2183 0.2100 0.2018 0.1936 0.1854 0.1772 0.1691 0.1612 0.1535 0.1463 0.1396 0.1334 

[TRAIN] Epoch[2](1230/1500); Loss: 0.077437; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0840 0.0807 0.0780 0.0765 0.0764 0.0771 0.0771 0.0764 0.0758 0.0753 0.0757 0.0764 0.0767 0.0770 0.0774 0.0785 

[TRAIN] Epoch[2](1231/1500); Loss: 0.090477; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1232 0.1262 0.0977 0.0914 0.0874 0.0845 0.0833 0.0830 0.0832 0.0839 0.0837 0.0837 0.0842 0.0843 0.0839 0.0841 

[TRAIN] Epoch[2](1232/1500); Loss: 0.118389; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1503 0.1565 0.1173 0.1216 0.1190 0.1164 0.1143 0.1120 0.1105 0.1096 0.1092 0.1093 0.1099 0.1110 0.1126 0.1146 

[TRAIN] Epoch[2](1233/1500); Loss: 0.123113; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1431 0.1415 0.1304 0.1268 0.1243 0.1224 0.1212 0.1203 0.1195 0.1186 0.1178 0.1169 0.1164 0.1164 0.1169 0.1173 

[TRAIN] Epoch[2](1234/1500); Loss: 0.123812; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1439 0.1423 0.1319 0.1277 0.1241 0.1213 0.1195 0.1188 0.1189 0.1190 0.1187 0.1184 0.1185 0.1187 0.1193 0.1200 

[TRAIN] Epoch[2](1235/1500); Loss: 0.168117; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1944 0.1891 0.1878 0.1842 0.1796 0.1750 0.1710 0.1674 0.1641 0.1610 0.1581 0.1554 0.1531 0.1513 0.1499 0.1486 

[TRAIN] Epoch[2](1236/1500); Loss: 0.177529; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2200 0.2183 0.1952 0.1877 0.1820 0.1781 0.1752 0.1728 0.1707 0.1687 0.1668 0.1648 0.1628 0.1609 0.1592 0.1573 

[TRAIN] Epoch[2](1237/1500); Loss: 0.171033; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1985 0.1955 0.1846 0.1795 0.1757 0.1727 0.1703 0.1680 0.1660 0.1642 0.1628 0.1618 0.1608 0.1598 0.1587 0.1576 

[TRAIN] Epoch[2](1238/1500); Loss: 0.089955; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1018 0.1013 0.0911 0.0899 0.0881 0.0863 0.0853 0.0851 0.0857 0.0869 0.0881 0.0891 0.0895 0.0897 0.0903 0.0911 

[TRAIN] Epoch[2](1239/1500); Loss: 0.104425; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2354 0.2342 0.1507 0.1120 0.0843 0.0826 0.0822 0.0803 0.0788 0.0766 0.0756 0.0752 0.0751 0.0753 0.0758 0.0767 

[TRAIN] Epoch[2](1240/1500); Loss: 0.213023; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.2533 0.2492 0.2398 0.2331 0.2264 0.2201 0.2145 0.2095 0.2055 0.2021 0.1990 0.1961 0.1934 0.1909 0.1886 0.1867 

[TRAIN] Epoch[2](1241/1500); Loss: 0.111069; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1237 0.1269 0.1124 0.1103 0.1084 0.1069 0.1064 0.1065 0.1072 0.1081 0.1091 0.1099 0.1105 0.1104 0.1101 0.1103 

[TRAIN] Epoch[2](1242/1500); Loss: 0.100680; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1101 0.1101 0.1021 0.1009 0.0996 0.0976 0.0965 0.0957 0.0959 0.0964 0.0979 0.0998 0.1016 0.1019 0.1022 0.1025 

[TRAIN] Epoch[2](1243/1500); Loss: 0.076688; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1281 0.1385 0.0806 0.0758 0.0708 0.0665 0.0624 0.0603 0.0602 0.0609 0.0627 0.0653 0.0685 0.0716 0.0753 0.0795 

[TRAIN] Epoch[2](1244/1500); Loss: 0.118360; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1435 0.1363 0.1279 0.1228 0.1185 0.1144 0.1113 0.1094 0.1086 0.1088 0.1098 0.1117 0.1140 0.1165 0.1190 0.1212 

[TRAIN] Epoch[2](1245/1500); Loss: 0.131505; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1394 0.1392 0.1354 0.1339 0.1330 0.1323 0.1313 0.1302 0.1291 0.1283 0.1282 0.1285 0.1285 0.1286 0.1290 0.1292 

[TRAIN] Epoch[2](1246/1500); Loss: 0.116859; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1573 0.1622 0.1210 0.1121 0.1086 0.1068 0.1065 0.1075 0.1084 0.1090 0.1098 0.1103 0.1109 0.1119 0.1132 0.1143 

[TRAIN] Epoch[2](1247/1500); Loss: 0.120561; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1549 0.1524 0.1344 0.1261 0.1205 0.1161 0.1130 0.1111 0.1103 0.1103 0.1109 0.1119 0.1131 0.1138 0.1145 0.1156 

[TRAIN] Epoch[2](1248/1500); Loss: 0.149669; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2190 0.2055 0.2014 0.1928 0.1824 0.1714 0.1611 0.1509 0.1412 0.1320 0.1234 0.1155 0.1083 0.1019 0.0962 0.0917 

[TRAIN] Epoch[2](1249/1500); Loss: 0.123834; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1771 0.1682 0.1635 0.1566 0.1481 0.1396 0.1314 0.1235 0.1159 0.1087 0.1021 0.0964 0.0918 0.0884 0.0857 0.0843 

[TRAIN] Epoch[2](1250/1500); Loss: 0.066067; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1804 0.1842 0.0907 0.0613 0.0487 0.0500 0.0480 0.0453 0.0430 0.0418 0.0416 0.0420 0.0429 0.0444 0.0456 0.0473 

[TRAIN] Epoch[2](1251/1500); Loss: 0.101173; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1335 0.1291 0.1157 0.1104 0.1056 0.1011 0.0978 0.0959 0.0949 0.0943 0.0933 0.0917 0.0907 0.0895 0.0883 0.0872 

[TRAIN] Epoch[2](1252/1500); Loss: 0.077625; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1061 0.1043 0.0882 0.0832 0.0794 0.0762 0.0744 0.0736 0.0727 0.0712 0.0696 0.0683 0.0680 0.0682 0.0687 0.0699 

[TRAIN] Epoch[2](1253/1500); Loss: 0.074234; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0794 0.0844 0.0763 0.0748 0.0729 0.0714 0.0709 0.0712 0.0716 0.0718 0.0722 0.0730 0.0742 0.0747 0.0744 0.0745 

[TRAIN] Epoch[2](1254/1500); Loss: 0.256331; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3043 0.2996 0.2879 0.2798 0.2726 0.2655 0.2594 0.2539 0.2489 0.2444 0.2402 0.2362 0.2324 0.2290 0.2254 0.2219 

[TRAIN] Epoch[2](1255/1500); Loss: 0.306536; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.3751 0.3646 0.3603 0.3520 0.3422 0.3321 0.3222 0.3123 0.3024 0.2925 0.2827 0.2728 0.2630 0.2532 0.2435 0.2337 

[TRAIN] Epoch[2](1256/1500); Loss: 0.096766; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0970 0.1008 0.0935 0.0925 0.0919 0.0920 0.0928 0.0939 0.0950 0.0955 0.0964 0.0981 0.1002 0.1019 0.1029 0.1036 

[TRAIN] Epoch[2](1257/1500); Loss: 0.082530; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1024 0.0988 0.0921 0.0884 0.0845 0.0810 0.0788 0.0773 0.0762 0.0753 0.0749 0.0754 0.0764 0.0780 0.0797 0.0814 

[TRAIN] Epoch[2](1258/1500); Loss: 0.081320; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1030 0.0970 0.0921 0.0869 0.0816 0.0775 0.0751 0.0738 0.0734 0.0738 0.0748 0.0761 0.0780 0.0795 0.0794 0.0790 

[TRAIN] Epoch[2](1259/1500); Loss: 0.169468; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1777 0.1807 0.1721 0.1705 0.1682 0.1669 0.1657 0.1651 0.1648 0.1651 0.1658 0.1670 0.1685 0.1700 0.1713 0.1721 

[TRAIN] Epoch[2](1260/1500); Loss: 0.060192; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0669 0.0718 0.0628 0.0599 0.0569 0.0547 0.0545 0.0554 0.0566 0.0571 0.0579 0.0591 0.0605 0.0622 0.0632 0.0636 

[TRAIN] Epoch[2](1261/1500); Loss: 0.172528; Backpropagation: 0.0917 sec; Batch: 0.4226 sec
0.2169 0.2185 0.1931 0.1850 0.1788 0.1733 0.1687 0.1656 0.1633 0.1614 0.1595 0.1579 0.1562 0.1551 0.1538 0.1533 

[TRAIN] Epoch[2](1262/1500); Loss: 0.169655; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2044 0.2048 0.1827 0.1791 0.1749 0.1708 0.1670 0.1641 0.1618 0.1602 0.1593 0.1586 0.1579 0.1572 0.1564 0.1552 

[TRAIN] Epoch[2](1263/1500); Loss: 0.073095; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1125 0.1138 0.0856 0.0791 0.0745 0.0706 0.0673 0.0646 0.0625 0.0610 0.0601 0.0605 0.0620 0.0635 0.0654 0.0669 

[TRAIN] Epoch[2](1264/1500); Loss: 0.114305; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2153 0.2155 0.1412 0.1087 0.0956 0.0978 0.0965 0.0951 0.0936 0.0933 0.0939 0.0941 0.0953 0.0960 0.0975 0.0993 

[TRAIN] Epoch[2](1265/1500); Loss: 0.270092; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3406 0.3301 0.3248 0.3162 0.3062 0.2960 0.2859 0.2759 0.2657 0.2555 0.2455 0.2355 0.2256 0.2157 0.2060 0.1963 

[TRAIN] Epoch[2](1266/1500); Loss: 0.133189; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.1649 0.1663 0.1429 0.1385 0.1336 0.1306 0.1280 0.1261 0.1243 0.1235 0.1231 0.1235 0.1243 0.1256 0.1270 0.1289 

[TRAIN] Epoch[2](1267/1500); Loss: 0.146242; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1661 0.1684 0.1533 0.1522 0.1500 0.1479 0.1460 0.1445 0.1428 0.1406 0.1389 0.1379 0.1375 0.1375 0.1380 0.1382 

[TRAIN] Epoch[2](1268/1500); Loss: 0.189118; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2413 0.2318 0.2251 0.2180 0.2098 0.2015 0.1942 0.1869 0.1804 0.1746 0.1694 0.1646 0.1608 0.1576 0.1556 0.1544 

[TRAIN] Epoch[2](1269/1500); Loss: 0.083171; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1098 0.1107 0.0943 0.0888 0.0855 0.0827 0.0811 0.0793 0.0768 0.0749 0.0739 0.0739 0.0744 0.0746 0.0748 0.0753 

[TRAIN] Epoch[2](1270/1500); Loss: 0.132334; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1314 0.1319 0.1291 0.1285 0.1286 0.1295 0.1311 0.1324 0.1330 0.1335 0.1342 0.1349 0.1352 0.1347 0.1347 0.1347 

[TRAIN] Epoch[2](1271/1500); Loss: 0.063766; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0955 0.0937 0.0732 0.0656 0.0613 0.0578 0.0562 0.0559 0.0557 0.0558 0.0559 0.0564 0.0572 0.0588 0.0602 0.0611 

[TRAIN] Epoch[2](1272/1500); Loss: 0.199517; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2859 0.2737 0.2673 0.2552 0.2409 0.2265 0.2123 0.1985 0.1854 0.1734 0.1628 0.1537 0.1463 0.1405 0.1362 0.1336 

[TRAIN] Epoch[2](1273/1500); Loss: 0.081190; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0917 0.0954 0.0903 0.0881 0.0846 0.0805 0.0772 0.0748 0.0737 0.0741 0.0756 0.0770 0.0778 0.0784 0.0790 0.0807 

[TRAIN] Epoch[2](1274/1500); Loss: 0.078382; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0864 0.0882 0.0805 0.0789 0.0779 0.0762 0.0757 0.0760 0.0777 0.0789 0.0784 0.0763 0.0758 0.0759 0.0756 0.0756 

[TRAIN] Epoch[2](1275/1500); Loss: 0.169058; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1904 0.1894 0.1824 0.1785 0.1752 0.1726 0.1705 0.1687 0.1665 0.1644 0.1623 0.1603 0.1583 0.1565 0.1550 0.1539 

[TRAIN] Epoch[2](1276/1500); Loss: 0.059724; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0750 0.0677 0.0631 0.0597 0.0583 0.0567 0.0550 0.0543 0.0548 0.0555 0.0568 0.0575 0.0583 0.0591 0.0610 0.0625 

[TRAIN] Epoch[2](1277/1500); Loss: 0.164435; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1992 0.1985 0.1821 0.1747 0.1685 0.1629 0.1585 0.1555 0.1540 0.1531 0.1527 0.1527 0.1530 0.1541 0.1551 0.1562 

[TRAIN] Epoch[2](1278/1500); Loss: 0.065839; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0889 0.0967 0.0683 0.0680 0.0657 0.0620 0.0589 0.0577 0.0583 0.0603 0.0618 0.0619 0.0614 0.0607 0.0608 0.0620 

[TRAIN] Epoch[2](1279/1500); Loss: 0.046069; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0508 0.0511 0.0452 0.0449 0.0442 0.0435 0.0440 0.0442 0.0437 0.0438 0.0447 0.0454 0.0462 0.0472 0.0486 0.0497 

[TRAIN] Epoch[2](1280/1500); Loss: 0.188138; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2242 0.2173 0.2113 0.2051 0.1988 0.1930 0.1883 0.1846 0.1814 0.1790 0.1767 0.1743 0.1719 0.1701 0.1681 0.1661 

[TRAIN] Epoch[2](1281/1500); Loss: 0.131915; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1788 0.1823 0.1498 0.1382 0.1313 0.1258 0.1227 0.1212 0.1204 0.1197 0.1193 0.1196 0.1199 0.1199 0.1205 0.1212 

[TRAIN] Epoch[2](1282/1500); Loss: 0.143217; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2288 0.2153 0.2067 0.1956 0.1826 0.1693 0.1560 0.1427 0.1297 0.1170 0.1056 0.0964 0.0897 0.0857 0.0845 0.0858 

[TRAIN] Epoch[2](1283/1500); Loss: 0.102469; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1290 0.1249 0.1160 0.1101 0.1047 0.1005 0.0974 0.0958 0.0952 0.0956 0.0957 0.0952 0.0947 0.0946 0.0947 0.0953 

[TRAIN] Epoch[2](1284/1500); Loss: 0.106869; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2061 0.2129 0.1479 0.1252 0.1087 0.0909 0.0808 0.0790 0.0793 0.0800 0.0802 0.0803 0.0828 0.0835 0.0849 0.0874 

[TRAIN] Epoch[2](1285/1500); Loss: 0.112841; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1556 0.1538 0.1239 0.1218 0.1172 0.1121 0.1074 0.1039 0.1022 0.1019 0.1021 0.1016 0.1005 0.1000 0.1002 0.1012 

[TRAIN] Epoch[2](1286/1500); Loss: 0.146076; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1571 0.1582 0.1520 0.1498 0.1477 0.1460 0.1448 0.1437 0.1426 0.1421 0.1420 0.1418 0.1419 0.1420 0.1426 0.1432 

[TRAIN] Epoch[2](1287/1500); Loss: 0.056239; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0709 0.0795 0.0634 0.0609 0.0571 0.0538 0.0524 0.0527 0.0526 0.0520 0.0518 0.0509 0.0497 0.0503 0.0507 0.0510 

[TRAIN] Epoch[2](1288/1500); Loss: 0.144161; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1971 0.1951 0.1676 0.1551 0.1448 0.1377 0.1354 0.1332 0.1315 0.1307 0.1306 0.1303 0.1295 0.1291 0.1292 0.1297 

[TRAIN] Epoch[2](1289/1500); Loss: 0.103975; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1566 0.1500 0.1376 0.1295 0.1209 0.1127 0.1052 0.0981 0.0918 0.0859 0.0806 0.0778 0.0771 0.0776 0.0797 0.0824 

[TRAIN] Epoch[2](1290/1500); Loss: 0.136879; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1544 0.1574 0.1422 0.1404 0.1380 0.1352 0.1327 0.1310 0.1299 0.1303 0.1314 0.1327 0.1337 0.1338 0.1337 0.1334 

[TRAIN] Epoch[2](1291/1500); Loss: 0.146042; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1722 0.1746 0.1572 0.1528 0.1486 0.1449 0.1418 0.1400 0.1393 0.1391 0.1390 0.1390 0.1379 0.1369 0.1367 0.1368 

[TRAIN] Epoch[2](1292/1500); Loss: 0.086303; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1131 0.1047 0.0948 0.0892 0.0857 0.0836 0.0824 0.0815 0.0809 0.0811 0.0810 0.0807 0.0806 0.0802 0.0804 0.0810 

[TRAIN] Epoch[2](1293/1500); Loss: 0.072762; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0855 0.0901 0.0797 0.0768 0.0741 0.0710 0.0690 0.0679 0.0682 0.0681 0.0673 0.0669 0.0679 0.0689 0.0707 0.0721 

[TRAIN] Epoch[2](1294/1500); Loss: 0.150074; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1785 0.1748 0.1680 0.1630 0.1582 0.1537 0.1497 0.1465 0.1436 0.1410 0.1391 0.1382 0.1374 0.1365 0.1363 0.1367 

[TRAIN] Epoch[2](1295/1500); Loss: 0.098811; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1215 0.1190 0.1075 0.1035 0.0999 0.0966 0.0944 0.0932 0.0929 0.0930 0.0932 0.0932 0.0934 0.0934 0.0931 0.0931 

[TRAIN] Epoch[2](1296/1500); Loss: 0.119678; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1335 0.1390 0.1165 0.1152 0.1129 0.1119 0.1117 0.1126 0.1141 0.1162 0.1185 0.1208 0.1223 0.1231 0.1231 0.1233 

[TRAIN] Epoch[2](1297/1500); Loss: 0.168015; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2278 0.2188 0.2090 0.2009 0.1920 0.1831 0.1751 0.1675 0.1602 0.1529 0.1458 0.1395 0.1342 0.1298 0.1267 0.1248 

[TRAIN] Epoch[2](1298/1500); Loss: 0.107478; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1232 0.1196 0.1120 0.1088 0.1066 0.1056 0.1049 0.1043 0.1039 0.1038 0.1036 0.1034 0.1038 0.1047 0.1054 0.1060 

[TRAIN] Epoch[2](1299/1500); Loss: 0.118117; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2227 0.2228 0.1637 0.1394 0.1161 0.1017 0.0994 0.0973 0.0946 0.0923 0.0905 0.0902 0.0910 0.0894 0.0891 0.0896 

[TRAIN] Epoch[2](1300/1500); Loss: 0.124233; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1483 0.1426 0.1361 0.1318 0.1284 0.1257 0.1231 0.1202 0.1179 0.1165 0.1156 0.1152 0.1152 0.1159 0.1171 0.1183 

[TRAIN] Epoch[2](1301/1500); Loss: 0.187284; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2502 0.2391 0.2317 0.2225 0.2125 0.2023 0.1927 0.1838 0.1760 0.1689 0.1628 0.1576 0.1535 0.1500 0.1474 0.1455 

[TRAIN] Epoch[2](1302/1500); Loss: 0.146721; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2213 0.2170 0.1645 0.1538 0.1499 0.1477 0.1430 0.1381 0.1343 0.1323 0.1310 0.1278 0.1244 0.1223 0.1207 0.1194 

[TRAIN] Epoch[2](1303/1500); Loss: 0.089103; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1189 0.1200 0.0994 0.0962 0.0930 0.0897 0.0865 0.0842 0.0824 0.0808 0.0797 0.0790 0.0790 0.0791 0.0790 0.0787 

[TRAIN] Epoch[2](1304/1500); Loss: 0.120811; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1610 0.1594 0.1356 0.1279 0.1217 0.1183 0.1157 0.1134 0.1117 0.1108 0.1105 0.1102 0.1097 0.1091 0.1088 0.1091 

[TRAIN] Epoch[2](1305/1500); Loss: 0.120249; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1455 0.1473 0.1222 0.1210 0.1193 0.1177 0.1165 0.1160 0.1159 0.1157 0.1151 0.1144 0.1139 0.1142 0.1145 0.1147 

[TRAIN] Epoch[2](1306/1500); Loss: 0.106831; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1532 0.1457 0.1358 0.1285 0.1209 0.1138 0.1076 0.1021 0.0964 0.0913 0.0878 0.0861 0.0852 0.0845 0.0847 0.0859 

[TRAIN] Epoch[2](1307/1500); Loss: 0.139931; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1793 0.1770 0.1584 0.1524 0.1468 0.1420 0.1376 0.1337 0.1303 0.1277 0.1261 0.1253 0.1250 0.1254 0.1258 0.1261 

[TRAIN] Epoch[2](1308/1500); Loss: 0.122706; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1803 0.1766 0.1402 0.1334 0.1267 0.1208 0.1162 0.1118 0.1092 0.1084 0.1087 0.1077 0.1054 0.1047 0.1057 0.1073 

[TRAIN] Epoch[2](1309/1500); Loss: 0.097401; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1020 0.1003 0.0977 0.0968 0.0963 0.0962 0.0968 0.0979 0.0975 0.0963 0.0960 0.0965 0.0966 0.0966 0.0970 0.0979 

[TRAIN] Epoch[2](1310/1500); Loss: 0.141968; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1844 0.1798 0.1644 0.1564 0.1488 0.1420 0.1361 0.1318 0.1291 0.1273 0.1264 0.1266 0.1275 0.1291 0.1307 0.1310 

[TRAIN] Epoch[2](1311/1500); Loss: 0.150768; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2356 0.2281 0.1940 0.1803 0.1684 0.1601 0.1527 0.1451 0.1380 0.1311 0.1243 0.1180 0.1131 0.1099 0.1077 0.1060 

[TRAIN] Epoch[2](1312/1500); Loss: 0.119854; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1701 0.1629 0.1448 0.1350 0.1269 0.1210 0.1170 0.1136 0.1105 0.1076 0.1054 0.1036 0.1014 0.0994 0.0988 0.0995 

[TRAIN] Epoch[2](1313/1500); Loss: 0.071779; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0871 0.0893 0.0812 0.0773 0.0738 0.0708 0.0685 0.0667 0.0660 0.0652 0.0654 0.0658 0.0667 0.0672 0.0682 0.0694 

[TRAIN] Epoch[2](1314/1500); Loss: 0.106461; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1729 0.1662 0.1384 0.1234 0.1105 0.0989 0.0914 0.0890 0.0881 0.0883 0.0896 0.0906 0.0901 0.0891 0.0884 0.0884 

[TRAIN] Epoch[2](1315/1500); Loss: 0.148559; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1759 0.1723 0.1643 0.1601 0.1559 0.1523 0.1497 0.1481 0.1461 0.1434 0.1406 0.1380 0.1355 0.1332 0.1312 0.1303 

[TRAIN] Epoch[2](1316/1500); Loss: 0.097937; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.1387 0.1425 0.1003 0.0941 0.0910 0.0896 0.0901 0.0915 0.0916 0.0899 0.0896 0.0904 0.0905 0.0914 0.0925 0.0933 

[TRAIN] Epoch[2](1317/1500); Loss: 0.131700; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1484 0.1492 0.1383 0.1349 0.1323 0.1298 0.1281 0.1273 0.1269 0.1265 0.1267 0.1268 0.1269 0.1277 0.1283 0.1291 

[TRAIN] Epoch[2](1318/1500); Loss: 0.066732; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.0922 0.0959 0.0674 0.0664 0.0645 0.0622 0.0613 0.0625 0.0640 0.0631 0.0621 0.0611 0.0604 0.0610 0.0616 0.0621 

[TRAIN] Epoch[2](1319/1500); Loss: 0.087787; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1121 0.1032 0.0968 0.0923 0.0891 0.0870 0.0857 0.0838 0.0816 0.0804 0.0805 0.0807 0.0815 0.0825 0.0834 0.0843 

[TRAIN] Epoch[2](1320/1500); Loss: 0.131491; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1744 0.1761 0.1457 0.1393 0.1330 0.1282 0.1248 0.1227 0.1207 0.1197 0.1195 0.1197 0.1197 0.1197 0.1200 0.1206 

[TRAIN] Epoch[2](1321/1500); Loss: 0.105284; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1225 0.1265 0.1054 0.1050 0.1029 0.1013 0.1003 0.1003 0.1008 0.1013 0.1014 0.1018 0.1023 0.1034 0.1043 0.1049 

[TRAIN] Epoch[2](1322/1500); Loss: 0.076442; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1914 0.1837 0.0577 0.0733 0.0690 0.0662 0.0618 0.0549 0.0518 0.0525 0.0562 0.0592 0.0588 0.0594 0.0621 0.0652 

[TRAIN] Epoch[2](1323/1500); Loss: 0.087287; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1062 0.1058 0.0965 0.0924 0.0890 0.0863 0.0848 0.0835 0.0813 0.0807 0.0805 0.0810 0.0818 0.0820 0.0821 0.0826 

[TRAIN] Epoch[2](1324/1500); Loss: 0.301544; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.3736 0.3623 0.3537 0.3443 0.3341 0.3242 0.3144 0.3047 0.2953 0.2860 0.2768 0.2677 0.2588 0.2502 0.2423 0.2362 

[TRAIN] Epoch[2](1325/1500); Loss: 0.124840; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1547 0.1524 0.1366 0.1312 0.1263 0.1234 0.1214 0.1198 0.1180 0.1170 0.1163 0.1161 0.1157 0.1157 0.1161 0.1168 

[TRAIN] Epoch[2](1326/1500); Loss: 0.069882; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0831 0.0866 0.0696 0.0656 0.0641 0.0635 0.0650 0.0671 0.0672 0.0658 0.0663 0.0682 0.0697 0.0705 0.0718 0.0741 

[TRAIN] Epoch[2](1327/1500); Loss: 0.073346; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1162 0.1049 0.0923 0.0819 0.0721 0.0641 0.0608 0.0626 0.0651 0.0641 0.0622 0.0621 0.0637 0.0659 0.0672 0.0682 

[TRAIN] Epoch[2](1328/1500); Loss: 0.054221; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0742 0.0634 0.0576 0.0535 0.0521 0.0518 0.0521 0.0517 0.0514 0.0508 0.0500 0.0504 0.0511 0.0518 0.0522 0.0534 

[TRAIN] Epoch[2](1329/1500); Loss: 0.161021; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1787 0.1794 0.1681 0.1650 0.1614 0.1593 0.1578 0.1570 0.1568 0.1566 0.1559 0.1559 0.1561 0.1559 0.1562 0.1560 

[TRAIN] Epoch[2](1330/1500); Loss: 0.094835; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1204 0.1154 0.1072 0.1028 0.0978 0.0939 0.0908 0.0884 0.0868 0.0867 0.0873 0.0879 0.0881 0.0878 0.0879 0.0880 

[TRAIN] Epoch[2](1331/1500); Loss: 0.081197; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1151 0.1101 0.0948 0.0869 0.0816 0.0784 0.0777 0.0772 0.0751 0.0721 0.0709 0.0713 0.0721 0.0721 0.0717 0.0719 

[TRAIN] Epoch[2](1332/1500); Loss: 0.088057; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1431 0.1305 0.1206 0.1101 0.0996 0.0896 0.0811 0.0744 0.0693 0.0664 0.0661 0.0674 0.0696 0.0720 0.0739 0.0754 

[TRAIN] Epoch[2](1333/1500); Loss: 0.128120; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1662 0.1662 0.1452 0.1391 0.1339 0.1296 0.1254 0.1217 0.1186 0.1165 0.1151 0.1142 0.1141 0.1143 0.1148 0.1149 

[TRAIN] Epoch[2](1334/1500); Loss: 0.101680; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1307 0.1269 0.1181 0.1122 0.1067 0.1017 0.0976 0.0945 0.0926 0.0915 0.0912 0.0918 0.0926 0.0932 0.0931 0.0926 

[TRAIN] Epoch[2](1335/1500); Loss: 0.150978; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2031 0.2022 0.1732 0.1626 0.1546 0.1506 0.1487 0.1456 0.1423 0.1392 0.1366 0.1346 0.1327 0.1310 0.1296 0.1289 

[TRAIN] Epoch[2](1336/1500); Loss: 0.123639; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1511 0.1451 0.1371 0.1318 0.1274 0.1237 0.1210 0.1187 0.1169 0.1156 0.1149 0.1149 0.1147 0.1149 0.1150 0.1155 

[TRAIN] Epoch[2](1337/1500); Loss: 0.112800; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1414 0.1388 0.1319 0.1255 0.1196 0.1147 0.1109 0.1080 0.1054 0.1034 0.1021 0.1010 0.1005 0.1004 0.1004 0.1007 

[TRAIN] Epoch[2](1338/1500); Loss: 0.107518; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1567 0.1551 0.1258 0.1145 0.1062 0.0989 0.0950 0.0940 0.0948 0.0954 0.0958 0.0960 0.0966 0.0975 0.0985 0.0995 

[TRAIN] Epoch[2](1339/1500); Loss: 0.207043; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2546 0.2505 0.2308 0.2236 0.2172 0.2118 0.2068 0.2030 0.2001 0.1978 0.1958 0.1933 0.1895 0.1843 0.1788 0.1747 

[TRAIN] Epoch[2](1340/1500); Loss: 0.167558; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2076 0.2053 0.1860 0.1791 0.1732 0.1678 0.1634 0.1599 0.1574 0.1555 0.1543 0.1539 0.1538 0.1540 0.1548 0.1549 

[TRAIN] Epoch[2](1341/1500); Loss: 0.137188; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1766 0.1711 0.1558 0.1492 0.1422 0.1360 0.1310 0.1277 0.1257 0.1244 0.1241 0.1250 0.1257 0.1261 0.1266 0.1280 

[TRAIN] Epoch[2](1342/1500); Loss: 0.169225; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1983 0.1947 0.1849 0.1791 0.1740 0.1699 0.1668 0.1644 0.1621 0.1601 0.1590 0.1584 0.1584 0.1588 0.1593 0.1594 

[TRAIN] Epoch[2](1343/1500); Loss: 0.079656; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1210 0.1168 0.0922 0.0840 0.0790 0.0758 0.0736 0.0718 0.0709 0.0714 0.0711 0.0696 0.0688 0.0688 0.0697 0.0701 

[TRAIN] Epoch[2](1344/1500); Loss: 0.111091; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1407 0.1363 0.1195 0.1146 0.1101 0.1073 0.1053 0.1041 0.1032 0.1026 0.1027 0.1039 0.1056 0.1066 0.1072 0.1076 

[TRAIN] Epoch[2](1345/1500); Loss: 0.154177; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1965 0.1920 0.1739 0.1651 0.1589 0.1540 0.1509 0.1486 0.1461 0.1439 0.1421 0.1405 0.1393 0.1388 0.1384 0.1380 

[TRAIN] Epoch[2](1346/1500); Loss: 0.103643; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1804 0.1778 0.1356 0.1177 0.1031 0.0902 0.0870 0.0864 0.0862 0.0856 0.0847 0.0841 0.0843 0.0845 0.0851 0.0857 

[TRAIN] Epoch[2](1347/1500); Loss: 0.166743; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2384 0.2274 0.2157 0.2051 0.1939 0.1829 0.1727 0.1631 0.1544 0.1465 0.1394 0.1334 0.1285 0.1246 0.1218 0.1201 

[TRAIN] Epoch[2](1348/1500); Loss: 0.162840; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2749 0.2572 0.2430 0.2276 0.2109 0.1938 0.1770 0.1602 0.1439 0.1284 0.1147 0.1035 0.0957 0.0916 0.0907 0.0922 

[TRAIN] Epoch[2](1349/1500); Loss: 0.073178; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1217 0.1204 0.0880 0.0770 0.0691 0.0646 0.0625 0.0615 0.0619 0.0624 0.0632 0.0631 0.0630 0.0632 0.0643 0.0649 

[TRAIN] Epoch[2](1350/1500); Loss: 0.090737; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1444 0.1455 0.1090 0.0941 0.0829 0.0789 0.0797 0.0796 0.0789 0.0785 0.0781 0.0784 0.0795 0.0808 0.0816 0.0820 

[TRAIN] Epoch[2](1351/1500); Loss: 0.102967; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1374 0.1312 0.1223 0.1118 0.1029 0.0963 0.0921 0.0901 0.0903 0.0916 0.0932 0.0947 0.0973 0.0992 0.0988 0.0985 

[TRAIN] Epoch[2](1352/1500); Loss: 0.104116; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1349 0.1295 0.1176 0.1109 0.1061 0.1029 0.1012 0.1002 0.0985 0.0970 0.0959 0.0949 0.0941 0.0938 0.0939 0.0944 

[TRAIN] Epoch[2](1353/1500); Loss: 0.193920; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2382 0.2329 0.2238 0.2158 0.2082 0.2016 0.1961 0.1919 0.1884 0.1850 0.1809 0.1753 0.1704 0.1668 0.1646 0.1627 

[TRAIN] Epoch[2](1354/1500); Loss: 0.050147; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0657 0.0733 0.0603 0.0549 0.0510 0.0483 0.0478 0.0469 0.0448 0.0435 0.0434 0.0438 0.0441 0.0443 0.0446 0.0457 

[TRAIN] Epoch[2](1355/1500); Loss: 0.068365; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1078 0.0958 0.0838 0.0755 0.0685 0.0628 0.0591 0.0582 0.0595 0.0610 0.0604 0.0594 0.0597 0.0606 0.0610 0.0608 

[TRAIN] Epoch[2](1356/1500); Loss: 0.106382; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1270 0.1253 0.1153 0.1108 0.1074 0.1051 0.1036 0.1023 0.1022 0.1021 0.1016 0.1009 0.0998 0.0993 0.0996 0.0999 

[TRAIN] Epoch[2](1357/1500); Loss: 0.125847; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1465 0.1452 0.1352 0.1312 0.1285 0.1267 0.1254 0.1243 0.1222 0.1204 0.1192 0.1183 0.1179 0.1179 0.1176 0.1171 

[TRAIN] Epoch[2](1358/1500); Loss: 0.091257; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1357 0.1223 0.1119 0.1018 0.0934 0.0874 0.0838 0.0821 0.0812 0.0803 0.0795 0.0796 0.0804 0.0804 0.0802 0.0801 

[TRAIN] Epoch[2](1359/1500); Loss: 0.124776; Backpropagation: 0.0917 sec; Batch: 0.4295 sec
0.1452 0.1451 0.1341 0.1300 0.1260 0.1232 0.1212 0.1199 0.1197 0.1196 0.1191 0.1187 0.1186 0.1185 0.1188 0.1187 

[TRAIN] Epoch[2](1360/1500); Loss: 0.076205; Backpropagation: 0.0918 sec; Batch: 0.4249 sec
0.1042 0.0932 0.0825 0.0765 0.0734 0.0735 0.0748 0.0747 0.0721 0.0698 0.0693 0.0695 0.0703 0.0711 0.0717 0.0726 

[TRAIN] Epoch[2](1361/1500); Loss: 0.241101; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2800 0.2762 0.2625 0.2576 0.2516 0.2469 0.2424 0.2385 0.2347 0.2316 0.2284 0.2254 0.2229 0.2210 0.2196 0.2182 

[TRAIN] Epoch[2](1362/1500); Loss: 0.130495; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1606 0.1619 0.1438 0.1386 0.1342 0.1301 0.1268 0.1241 0.1222 0.1210 0.1204 0.1203 0.1205 0.1208 0.1209 0.1216 

[TRAIN] Epoch[2](1363/1500); Loss: 0.283644; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.3696 0.3559 0.3440 0.3325 0.3204 0.3086 0.2972 0.2857 0.2747 0.2636 0.2529 0.2423 0.2326 0.2248 0.2189 0.2147 

[TRAIN] Epoch[2](1364/1500); Loss: 0.111854; Backpropagation: 0.0920 sec; Batch: 0.4248 sec
0.1301 0.1260 0.1207 0.1173 0.1144 0.1121 0.1101 0.1089 0.1075 0.1066 0.1062 0.1055 0.1055 0.1056 0.1062 0.1070 

[TRAIN] Epoch[2](1365/1500); Loss: 0.060985; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0980 0.0857 0.0772 0.0696 0.0636 0.0580 0.0537 0.0511 0.0508 0.0510 0.0513 0.0514 0.0517 0.0527 0.0542 0.0557 

[TRAIN] Epoch[2](1366/1500); Loss: 0.127597; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1556 0.1509 0.1440 0.1385 0.1330 0.1289 0.1264 0.1244 0.1222 0.1197 0.1178 0.1168 0.1163 0.1159 0.1155 0.1155 

[TRAIN] Epoch[2](1367/1500); Loss: 0.141112; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1568 0.1535 0.1491 0.1469 0.1463 0.1456 0.1428 0.1395 0.1376 0.1368 0.1364 0.1349 0.1337 0.1332 0.1327 0.1319 

[TRAIN] Epoch[2](1368/1500); Loss: 0.186057; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3072 0.2980 0.2553 0.2298 0.2065 0.1910 0.1832 0.1753 0.1664 0.1585 0.1518 0.1456 0.1372 0.1292 0.1234 0.1184 

[TRAIN] Epoch[2](1369/1500); Loss: 0.091941; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1436 0.1344 0.1142 0.1046 0.0955 0.0877 0.0819 0.0790 0.0789 0.0804 0.0812 0.0788 0.0771 0.0768 0.0782 0.0786 

[TRAIN] Epoch[2](1370/1500); Loss: 0.293926; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.4267 0.4091 0.3914 0.3741 0.3556 0.3377 0.3198 0.3017 0.2836 0.2651 0.2472 0.2295 0.2125 0.1967 0.1822 0.1697 

[TRAIN] Epoch[2](1371/1500); Loss: 0.119618; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1743 0.1686 0.1455 0.1353 0.1288 0.1231 0.1178 0.1135 0.1103 0.1071 0.1037 0.1004 0.0979 0.0966 0.0959 0.0952 

[TRAIN] Epoch[2](1372/1500); Loss: 0.093084; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1570 0.1539 0.0924 0.0921 0.0902 0.0875 0.0837 0.0823 0.0849 0.0848 0.0798 0.0787 0.0786 0.0800 0.0815 0.0817 

[TRAIN] Epoch[2](1373/1500); Loss: 0.092435; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1142 0.1107 0.0986 0.0937 0.0907 0.0889 0.0879 0.0874 0.0873 0.0872 0.0877 0.0882 0.0886 0.0888 0.0891 0.0899 

[TRAIN] Epoch[2](1374/1500); Loss: 0.165386; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1856 0.1827 0.1723 0.1676 0.1642 0.1622 0.1611 0.1603 0.1596 0.1595 0.1597 0.1605 0.1614 0.1624 0.1631 0.1640 

[TRAIN] Epoch[2](1375/1500); Loss: 0.149297; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2370 0.2234 0.2020 0.1870 0.1734 0.1604 0.1483 0.1377 0.1294 0.1231 0.1186 0.1150 0.1122 0.1090 0.1067 0.1054 

[TRAIN] Epoch[2](1376/1500); Loss: 0.148774; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1959 0.1881 0.1723 0.1631 0.1549 0.1480 0.1431 0.1396 0.1372 0.1361 0.1358 0.1353 0.1350 0.1336 0.1317 0.1307 

[TRAIN] Epoch[2](1377/1500); Loss: 0.094381; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1840 0.1732 0.1162 0.0983 0.0837 0.0810 0.0819 0.0809 0.0785 0.0780 0.0775 0.0762 0.0743 0.0736 0.0756 0.0773 

[TRAIN] Epoch[2](1378/1500); Loss: 0.088367; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1039 0.0972 0.0891 0.0854 0.0843 0.0852 0.0872 0.0891 0.0896 0.0876 0.0853 0.0848 0.0855 0.0871 0.0868 0.0857 

[TRAIN] Epoch[2](1379/1500); Loss: 0.216797; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2809 0.2713 0.2444 0.2352 0.2273 0.2202 0.2141 0.2088 0.2040 0.2000 0.1961 0.1936 0.1926 0.1929 0.1934 0.1937 

[TRAIN] Epoch[2](1380/1500); Loss: 0.157422; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1810 0.1795 0.1674 0.1634 0.1608 0.1583 0.1565 0.1551 0.1532 0.1510 0.1497 0.1487 0.1484 0.1484 0.1485 0.1488 

[TRAIN] Epoch[2](1381/1500); Loss: 0.105922; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1860 0.1806 0.1353 0.1195 0.1053 0.0955 0.0917 0.0898 0.0877 0.0858 0.0852 0.0850 0.0856 0.0863 0.0869 0.0886 

[TRAIN] Epoch[2](1382/1500); Loss: 0.161260; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2402 0.2273 0.1929 0.1783 0.1670 0.1606 0.1559 0.1524 0.1502 0.1479 0.1426 0.1363 0.1326 0.1312 0.1317 0.1332 

[TRAIN] Epoch[2](1383/1500); Loss: 0.123054; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1760 0.1638 0.1435 0.1326 0.1253 0.1203 0.1176 0.1157 0.1142 0.1117 0.1086 0.1069 0.1070 0.1074 0.1084 0.1100 

[TRAIN] Epoch[2](1384/1500); Loss: 0.140510; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2068 0.1990 0.1672 0.1539 0.1436 0.1360 0.1312 0.1281 0.1261 0.1250 0.1232 0.1230 0.1228 0.1219 0.1209 0.1194 

[TRAIN] Epoch[2](1385/1500); Loss: 0.115163; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2315 0.2096 0.1923 0.1719 0.1505 0.1285 0.1074 0.0880 0.0727 0.0637 0.0617 0.0655 0.0718 0.0761 0.0765 0.0748 

[TRAIN] Epoch[2](1386/1500); Loss: 0.134631; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1817 0.1721 0.1575 0.1465 0.1383 0.1324 0.1287 0.1267 0.1258 0.1256 0.1249 0.1222 0.1191 0.1173 0.1173 0.1180 

[TRAIN] Epoch[2](1387/1500); Loss: 0.143514; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1979 0.1864 0.1548 0.1461 0.1401 0.1360 0.1344 0.1352 0.1369 0.1376 0.1351 0.1317 0.1308 0.1306 0.1309 0.1318 

[TRAIN] Epoch[2](1388/1500); Loss: 0.078030; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0960 0.0896 0.0798 0.0771 0.0753 0.0737 0.0733 0.0744 0.0764 0.0769 0.0756 0.0740 0.0732 0.0753 0.0784 0.0793 

[TRAIN] Epoch[2](1389/1500); Loss: 0.211368; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.3461 0.3251 0.3102 0.2925 0.2737 0.2544 0.2354 0.2164 0.1977 0.1790 0.1605 0.1427 0.1270 0.1148 0.1060 0.1005 

[TRAIN] Epoch[2](1390/1500); Loss: 0.281063; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3883 0.3703 0.3585 0.3439 0.3285 0.3130 0.2983 0.2834 0.2689 0.2545 0.2403 0.2266 0.2153 0.2067 0.2014 0.1993 

[TRAIN] Epoch[2](1391/1500); Loss: 0.129630; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1995 0.1860 0.1570 0.1468 0.1349 0.1239 0.1164 0.1126 0.1121 0.1117 0.1121 0.1123 0.1121 0.1117 0.1120 0.1130 

[TRAIN] Epoch[2](1392/1500); Loss: 0.139018; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2619 0.2438 0.1664 0.1405 0.1203 0.1173 0.1152 0.1142 0.1151 0.1183 0.1209 0.1174 0.1154 0.1164 0.1189 0.1222 

[TRAIN] Epoch[2](1393/1500); Loss: 0.156060; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1841 0.1826 0.1573 0.1566 0.1535 0.1529 0.1529 0.1531 0.1515 0.1498 0.1496 0.1496 0.1499 0.1507 0.1510 0.1518 

[TRAIN] Epoch[2](1394/1500); Loss: 0.109077; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1541 0.1427 0.1210 0.1140 0.1087 0.1049 0.1028 0.1018 0.1012 0.1006 0.0994 0.0983 0.0979 0.0981 0.0993 0.1004 

[TRAIN] Epoch[2](1395/1500); Loss: 0.153599; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1964 0.1890 0.1724 0.1632 0.1571 0.1527 0.1496 0.1454 0.1422 0.1406 0.1407 0.1414 0.1418 0.1414 0.1416 0.1420 

[TRAIN] Epoch[2](1396/1500); Loss: 0.246430; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.3812 0.3640 0.3445 0.3239 0.3035 0.2836 0.2658 0.2479 0.2300 0.2125 0.1961 0.1807 0.1666 0.1553 0.1467 0.1406 

[TRAIN] Epoch[2](1397/1500); Loss: 0.133043; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2080 0.1945 0.1735 0.1561 0.1405 0.1278 0.1186 0.1132 0.1125 0.1143 0.1153 0.1118 0.1100 0.1096 0.1107 0.1121 

[TRAIN] Epoch[2](1398/1500); Loss: 0.157732; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2606 0.2465 0.2062 0.1859 0.1700 0.1572 0.1469 0.1379 0.1312 0.1265 0.1244 0.1236 0.1241 0.1255 0.1284 0.1289 

[TRAIN] Epoch[2](1399/1500); Loss: 0.153202; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2499 0.2320 0.1772 0.1572 0.1490 0.1440 0.1394 0.1358 0.1339 0.1350 0.1369 0.1357 0.1326 0.1301 0.1303 0.1322 

[TRAIN] Epoch[2](1400/1500); Loss: 0.114551; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2476 0.2178 0.1358 0.1080 0.0913 0.0907 0.0895 0.0882 0.0895 0.0939 0.0979 0.0974 0.0943 0.0948 0.0968 0.0994 

[TRAIN] Epoch[2](1401/1500); Loss: 0.148183; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1924 0.1827 0.1721 0.1643 0.1565 0.1491 0.1435 0.1404 0.1393 0.1394 0.1378 0.1343 0.1312 0.1296 0.1289 0.1294 

[TRAIN] Epoch[2](1402/1500); Loss: 0.124956; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1607 0.1489 0.1324 0.1257 0.1208 0.1182 0.1175 0.1181 0.1180 0.1180 0.1182 0.1185 0.1189 0.1200 0.1219 0.1234 

[TRAIN] Epoch[2](1403/1500); Loss: 0.154852; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2767 0.2557 0.2370 0.2136 0.1894 0.1660 0.1454 0.1285 0.1162 0.1089 0.1062 0.1059 0.1075 0.1091 0.1074 0.1042 

[TRAIN] Epoch[2](1404/1500); Loss: 0.168670; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2420 0.2283 0.2103 0.1976 0.1867 0.1775 0.1700 0.1633 0.1562 0.1497 0.1448 0.1408 0.1375 0.1339 0.1311 0.1291 

[TRAIN] Epoch[2](1405/1500); Loss: 0.143711; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.2234 0.2059 0.1645 0.1474 0.1360 0.1319 0.1320 0.1314 0.1300 0.1287 0.1283 0.1279 0.1271 0.1274 0.1280 0.1294 

[TRAIN] Epoch[2](1406/1500); Loss: 0.076729; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1316 0.1232 0.0841 0.0799 0.0746 0.0700 0.0674 0.0670 0.0680 0.0668 0.0648 0.0643 0.0649 0.0662 0.0675 0.0673 

[TRAIN] Epoch[2](1407/1500); Loss: 0.145922; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1664 0.1636 0.1552 0.1525 0.1501 0.1476 0.1455 0.1434 0.1421 0.1407 0.1396 0.1381 0.1377 0.1374 0.1375 0.1373 

[TRAIN] Epoch[2](1408/1500); Loss: 0.093175; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1425 0.1269 0.1137 0.1013 0.0919 0.0866 0.0846 0.0833 0.0829 0.0825 0.0814 0.0809 0.0818 0.0824 0.0838 0.0844 

[TRAIN] Epoch[2](1409/1500); Loss: 0.059569; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0741 0.0721 0.0697 0.0662 0.0613 0.0567 0.0539 0.0546 0.0565 0.0569 0.0541 0.0526 0.0543 0.0564 0.0572 0.0566 

[TRAIN] Epoch[2](1410/1500); Loss: 0.183433; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3289 0.3029 0.2573 0.2308 0.2097 0.1950 0.1805 0.1665 0.1543 0.1436 0.1352 0.1289 0.1261 0.1244 0.1244 0.1263 

[TRAIN] Epoch[2](1411/1500); Loss: 0.088685; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1049 0.1010 0.0964 0.0929 0.0898 0.0883 0.0893 0.0880 0.0841 0.0824 0.0824 0.0825 0.0831 0.0840 0.0844 0.0853 

[TRAIN] Epoch[2](1412/1500); Loss: 0.112974; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1362 0.1295 0.1187 0.1155 0.1130 0.1111 0.1093 0.1089 0.1087 0.1075 0.1070 0.1074 0.1076 0.1081 0.1091 0.1100 

[TRAIN] Epoch[2](1413/1500); Loss: 0.106474; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1294 0.1241 0.1192 0.1153 0.1118 0.1081 0.1054 0.1030 0.1009 0.0985 0.0974 0.0973 0.0977 0.0976 0.0985 0.0994 

[TRAIN] Epoch[2](1414/1500); Loss: 0.071481; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1567 0.1378 0.0957 0.0814 0.0703 0.0618 0.0569 0.0563 0.0559 0.0534 0.0536 0.0530 0.0523 0.0527 0.0528 0.0531 

[TRAIN] Epoch[2](1415/1500); Loss: 0.077981; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1594 0.1402 0.0681 0.0679 0.0640 0.0630 0.0651 0.0661 0.0637 0.0645 0.0656 0.0678 0.0705 0.0731 0.0739 0.0748 

[TRAIN] Epoch[2](1416/1500); Loss: 0.137170; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1846 0.1729 0.1610 0.1516 0.1430 0.1357 0.1308 0.1273 0.1250 0.1244 0.1239 0.1217 0.1211 0.1222 0.1244 0.1252 

[TRAIN] Epoch[2](1417/1500); Loss: 0.127361; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1954 0.1760 0.1537 0.1376 0.1259 0.1187 0.1165 0.1180 0.1211 0.1162 0.1099 0.1083 0.1080 0.1095 0.1117 0.1112 

[TRAIN] Epoch[2](1418/1500); Loss: 0.226633; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.3429 0.3236 0.3044 0.2892 0.2728 0.2568 0.2418 0.2262 0.2103 0.1937 0.1785 0.1654 0.1567 0.1528 0.1531 0.1581 

[TRAIN] Epoch[2](1419/1500); Loss: 0.182397; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2357 0.2277 0.2074 0.1998 0.1921 0.1848 0.1787 0.1744 0.1721 0.1693 0.1659 0.1626 0.1608 0.1606 0.1622 0.1642 

[TRAIN] Epoch[2](1420/1500); Loss: 0.185094; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.3378 0.3123 0.2929 0.2705 0.2468 0.2223 0.1986 0.1755 0.1534 0.1329 0.1145 0.1011 0.0948 0.0948 0.1011 0.1121 

[TRAIN] Epoch[2](1421/1500); Loss: 0.178853; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2251 0.2186 0.2052 0.1959 0.1888 0.1822 0.1763 0.1717 0.1677 0.1646 0.1627 0.1612 0.1603 0.1601 0.1602 0.1610 

[TRAIN] Epoch[2](1422/1500); Loss: 0.172766; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2625 0.2420 0.2220 0.2091 0.1953 0.1814 0.1693 0.1596 0.1529 0.1470 0.1387 0.1325 0.1313 0.1343 0.1401 0.1464 

[TRAIN] Epoch[2](1423/1500); Loss: 0.117884; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1689 0.1598 0.1394 0.1306 0.1221 0.1155 0.1083 0.1032 0.0998 0.1008 0.0997 0.1014 0.1039 0.1077 0.1107 0.1143 

[TRAIN] Epoch[2](1424/1500); Loss: 0.145592; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1809 0.1745 0.1620 0.1546 0.1487 0.1451 0.1416 0.1395 0.1372 0.1360 0.1357 0.1351 0.1338 0.1340 0.1349 0.1360 

[TRAIN] Epoch[2](1425/1500); Loss: 0.152924; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2034 0.1899 0.1703 0.1602 0.1517 0.1452 0.1424 0.1439 0.1471 0.1435 0.1407 0.1405 0.1411 0.1418 0.1431 0.1420 

[TRAIN] Epoch[2](1426/1500); Loss: 0.123609; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1627 0.1519 0.1408 0.1332 0.1262 0.1216 0.1168 0.1130 0.1119 0.1127 0.1123 0.1124 0.1129 0.1148 0.1161 0.1183 

[TRAIN] Epoch[2](1427/1500); Loss: 0.185008; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2448 0.2361 0.2254 0.2156 0.2061 0.1970 0.1888 0.1811 0.1738 0.1673 0.1621 0.1578 0.1543 0.1511 0.1493 0.1496 

[TRAIN] Epoch[2](1428/1500); Loss: 0.139605; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2191 0.2024 0.1813 0.1691 0.1574 0.1456 0.1356 0.1284 0.1244 0.1206 0.1156 0.1104 0.1073 0.1056 0.1051 0.1058 

[TRAIN] Epoch[2](1429/1500); Loss: 0.084403; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1315 0.1208 0.0981 0.0892 0.0820 0.0757 0.0726 0.0709 0.0726 0.0786 0.0803 0.0756 0.0725 0.0740 0.0762 0.0800 

[TRAIN] Epoch[2](1430/1500); Loss: 0.155079; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2478 0.2302 0.2015 0.1868 0.1763 0.1665 0.1575 0.1478 0.1394 0.1320 0.1250 0.1192 0.1145 0.1118 0.1115 0.1133 

[TRAIN] Epoch[2](1431/1500); Loss: 0.166593; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.3284 0.3017 0.2787 0.2530 0.2258 0.1985 0.1713 0.1447 0.1200 0.0995 0.0863 0.0831 0.0888 0.0964 0.0975 0.0917 

[TRAIN] Epoch[2](1432/1500); Loss: 0.155447; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1725 0.1692 0.1649 0.1620 0.1599 0.1569 0.1541 0.1522 0.1510 0.1509 0.1502 0.1490 0.1482 0.1482 0.1487 0.1492 

[TRAIN] Epoch[2](1433/1500); Loss: 0.077601; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1189 0.1090 0.1030 0.0908 0.0798 0.0732 0.0695 0.0688 0.0703 0.0672 0.0654 0.0650 0.0646 0.0653 0.0657 0.0651 

[TRAIN] Epoch[2](1434/1500); Loss: 0.066370; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.0680 0.0727 0.0759 0.0700 0.0668 0.0671 0.0608 0.0611 0.0613 0.0606 0.0630 0.0647 0.0660 0.0661 0.0675 0.0704 

[TRAIN] Epoch[2](1435/1500); Loss: 0.137720; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.2338 0.2192 0.1749 0.1586 0.1467 0.1361 0.1281 0.1233 0.1191 0.1148 0.1126 0.1109 0.1081 0.1067 0.1060 0.1046 

[TRAIN] Epoch[2](1436/1500); Loss: 0.112293; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1736 0.1589 0.1362 0.1251 0.1170 0.1120 0.1097 0.1080 0.1031 0.0977 0.0933 0.0911 0.0919 0.0944 0.0937 0.0912 

[TRAIN] Epoch[2](1437/1500); Loss: 0.152613; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1975 0.1872 0.1770 0.1676 0.1585 0.1507 0.1464 0.1452 0.1460 0.1444 0.1396 0.1369 0.1356 0.1356 0.1365 0.1371 

[TRAIN] Epoch[2](1438/1500); Loss: 0.189552; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2569 0.2471 0.2338 0.2226 0.2128 0.2051 0.1956 0.1862 0.1769 0.1683 0.1620 0.1564 0.1525 0.1510 0.1517 0.1540 

[TRAIN] Epoch[2](1439/1500); Loss: 0.125604; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1930 0.1836 0.1535 0.1413 0.1281 0.1181 0.1105 0.1075 0.1041 0.1034 0.1039 0.1061 0.1095 0.1132 0.1149 0.1189 

[TRAIN] Epoch[2](1440/1500); Loss: 0.099708; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1469 0.1363 0.1061 0.1008 0.0964 0.0945 0.0932 0.0928 0.0920 0.0900 0.0888 0.0897 0.0911 0.0922 0.0931 0.0918 

[TRAIN] Epoch[2](1441/1500); Loss: 0.085473; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1288 0.1193 0.1069 0.0979 0.0898 0.0836 0.0795 0.0764 0.0737 0.0730 0.0735 0.0723 0.0717 0.0724 0.0735 0.0754 

[TRAIN] Epoch[2](1442/1500); Loss: 0.128864; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2429 0.2219 0.1831 0.1643 0.1468 0.1296 0.1120 0.0980 0.0912 0.0889 0.0903 0.0969 0.1039 0.1001 0.0965 0.0953 

[TRAIN] Epoch[2](1443/1500); Loss: 0.074676; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1516 0.1291 0.1104 0.0917 0.0759 0.0655 0.0614 0.0606 0.0595 0.0579 0.0565 0.0544 0.0540 0.0546 0.0553 0.0563 

[TRAIN] Epoch[2](1444/1500); Loss: 0.089230; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1218 0.1186 0.1023 0.1006 0.0950 0.0886 0.0842 0.0831 0.0821 0.0789 0.0779 0.0770 0.0769 0.0794 0.0806 0.0807 

[TRAIN] Epoch[2](1445/1500); Loss: 0.102103; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1272 0.1224 0.1140 0.1091 0.1033 0.0993 0.0986 0.0984 0.0956 0.0932 0.0933 0.0936 0.0940 0.0957 0.0977 0.0984 

[TRAIN] Epoch[2](1446/1500); Loss: 0.076570; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1205 0.1130 0.0869 0.0793 0.0727 0.0688 0.0704 0.0729 0.0683 0.0649 0.0642 0.0650 0.0669 0.0689 0.0703 0.0721 

[TRAIN] Epoch[2](1447/1500); Loss: 0.135081; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2006 0.1917 0.1544 0.1478 0.1393 0.1332 0.1278 0.1235 0.1194 0.1173 0.1166 0.1167 0.1172 0.1177 0.1185 0.1198 

[TRAIN] Epoch[2](1448/1500); Loss: 0.154587; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2305 0.2177 0.2018 0.1890 0.1783 0.1680 0.1577 0.1478 0.1378 0.1304 0.1244 0.1189 0.1165 0.1166 0.1187 0.1195 

[TRAIN] Epoch[2](1449/1500); Loss: 0.077611; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1090 0.1019 0.0916 0.0855 0.0794 0.0742 0.0721 0.0725 0.0700 0.0666 0.0648 0.0657 0.0693 0.0722 0.0735 0.0736 

[TRAIN] Epoch[2](1450/1500); Loss: 0.138296; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2155 0.1959 0.1689 0.1529 0.1410 0.1335 0.1302 0.1270 0.1212 0.1187 0.1182 0.1179 0.1179 0.1178 0.1176 0.1185 

[TRAIN] Epoch[2](1451/1500); Loss: 0.061185; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1123 0.0957 0.0824 0.0740 0.0650 0.0535 0.0521 0.0567 0.0535 0.0470 0.0455 0.0466 0.0474 0.0480 0.0492 0.0500 

[TRAIN] Epoch[2](1452/1500); Loss: 0.069706; Backpropagation: 0.0918 sec; Batch: 0.4226 sec
0.1311 0.1120 0.0940 0.0787 0.0683 0.0636 0.0620 0.0610 0.0602 0.0584 0.0542 0.0528 0.0533 0.0542 0.0547 0.0568 

[TRAIN] Epoch[2](1453/1500); Loss: 0.084210; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1771 0.1545 0.1313 0.1071 0.0863 0.0716 0.0644 0.0618 0.0617 0.0635 0.0651 0.0651 0.0627 0.0599 0.0583 0.0572 

[TRAIN] Epoch[2](1454/1500); Loss: 0.098592; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1308 0.1334 0.1327 0.1223 0.1130 0.1082 0.0988 0.0897 0.0849 0.0824 0.0839 0.0817 0.0796 0.0792 0.0781 0.0787 

[TRAIN] Epoch[2](1455/1500); Loss: 0.088156; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1097 0.1030 0.0978 0.0932 0.0876 0.0829 0.0818 0.0824 0.0819 0.0821 0.0825 0.0832 0.0838 0.0851 0.0861 0.0873 

[TRAIN] Epoch[2](1456/1500); Loss: 0.118981; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1668 0.1529 0.1398 0.1294 0.1224 0.1185 0.1128 0.1075 0.1048 0.1046 0.1050 0.1061 0.1073 0.1085 0.1087 0.1086 

[TRAIN] Epoch[2](1457/1500); Loss: 0.077783; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1041 0.0918 0.0878 0.0810 0.0755 0.0729 0.0749 0.0771 0.0731 0.0711 0.0707 0.0717 0.0716 0.0719 0.0739 0.0754 

[TRAIN] Epoch[2](1458/1500); Loss: 0.091870; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1033 0.0989 0.0996 0.0972 0.0932 0.0894 0.0894 0.0915 0.0898 0.0871 0.0862 0.0867 0.0873 0.0884 0.0902 0.0920 

[TRAIN] Epoch[2](1459/1500); Loss: 0.103561; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1719 0.1615 0.1175 0.1076 0.0978 0.0913 0.0899 0.0908 0.0913 0.0914 0.0908 0.0901 0.0905 0.0907 0.0915 0.0924 

[TRAIN] Epoch[2](1460/1500); Loss: 0.171053; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2836 0.2645 0.2426 0.2216 0.2014 0.1817 0.1632 0.1466 0.1346 0.1283 0.1271 0.1291 0.1299 0.1296 0.1281 0.1249 

[TRAIN] Epoch[2](1461/1500); Loss: 0.091385; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1347 0.1283 0.1181 0.1090 0.1002 0.0934 0.0893 0.0847 0.0812 0.0784 0.0757 0.0742 0.0728 0.0726 0.0738 0.0757 

[TRAIN] Epoch[2](1462/1500); Loss: 0.107042; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1483 0.1353 0.1218 0.1121 0.1043 0.0996 0.0971 0.0966 0.0989 0.1006 0.0995 0.0987 0.0987 0.0992 0.1002 0.1017 

[TRAIN] Epoch[2](1463/1500); Loss: 0.164025; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2342 0.2183 0.1962 0.1824 0.1718 0.1636 0.1581 0.1547 0.1523 0.1489 0.1444 0.1415 0.1400 0.1394 0.1391 0.1396 

[TRAIN] Epoch[2](1464/1500); Loss: 0.130255; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1726 0.1647 0.1567 0.1448 0.1352 0.1262 0.1209 0.1210 0.1250 0.1257 0.1213 0.1144 0.1132 0.1123 0.1140 0.1160 

[TRAIN] Epoch[2](1465/1500); Loss: 0.117261; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1634 0.1516 0.1222 0.1185 0.1150 0.1120 0.1111 0.1113 0.1098 0.1082 0.1081 0.1079 0.1083 0.1088 0.1095 0.1104 

[TRAIN] Epoch[2](1466/1500); Loss: 0.072580; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1551 0.1357 0.0632 0.0638 0.0598 0.0595 0.0619 0.0637 0.0639 0.0615 0.0606 0.0603 0.0617 0.0625 0.0633 0.0648 

[TRAIN] Epoch[2](1467/1500); Loss: 0.075518; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1599 0.1408 0.1211 0.1020 0.0834 0.0665 0.0555 0.0550 0.0605 0.0593 0.0541 0.0501 0.0491 0.0491 0.0498 0.0520 

[TRAIN] Epoch[2](1468/1500); Loss: 0.155365; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2242 0.2102 0.2005 0.1866 0.1738 0.1614 0.1520 0.1449 0.1378 0.1317 0.1281 0.1261 0.1251 0.1260 0.1279 0.1295 

[TRAIN] Epoch[2](1469/1500); Loss: 0.090902; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1491 0.1329 0.1198 0.1058 0.0941 0.0852 0.0804 0.0770 0.0758 0.0772 0.0768 0.0759 0.0756 0.0758 0.0762 0.0769 

[TRAIN] Epoch[2](1470/1500); Loss: 0.075294; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1219 0.1162 0.0838 0.0761 0.0699 0.0677 0.0671 0.0676 0.0667 0.0661 0.0659 0.0660 0.0663 0.0670 0.0679 0.0684 

[TRAIN] Epoch[2](1471/1500); Loss: 0.096852; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1299 0.1183 0.1070 0.0996 0.0941 0.0911 0.0895 0.0890 0.0896 0.0899 0.0901 0.0907 0.0913 0.0922 0.0931 0.0944 

[TRAIN] Epoch[2](1472/1500); Loss: 0.089696; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1196 0.1098 0.1030 0.0965 0.0917 0.0892 0.0871 0.0839 0.0820 0.0804 0.0803 0.0805 0.0811 0.0824 0.0835 0.0843 

[TRAIN] Epoch[2](1473/1500); Loss: 0.116818; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1443 0.1394 0.1240 0.1195 0.1150 0.1124 0.1106 0.1096 0.1094 0.1094 0.1098 0.1104 0.1117 0.1131 0.1146 0.1159 

[TRAIN] Epoch[2](1474/1500); Loss: 0.122005; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1623 0.1513 0.1384 0.1296 0.1233 0.1185 0.1149 0.1134 0.1125 0.1118 0.1116 0.1116 0.1119 0.1126 0.1137 0.1147 

[TRAIN] Epoch[2](1475/1500); Loss: 0.058498; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1034 0.0905 0.0796 0.0676 0.0586 0.0529 0.0505 0.0487 0.0467 0.0460 0.0463 0.0468 0.0477 0.0492 0.0501 0.0514 

[TRAIN] Epoch[2](1476/1500); Loss: 0.139255; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1773 0.1684 0.1614 0.1520 0.1434 0.1365 0.1322 0.1303 0.1295 0.1287 0.1278 0.1272 0.1274 0.1279 0.1286 0.1294 

[TRAIN] Epoch[2](1477/1500); Loss: 0.167895; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1882 0.1820 0.1771 0.1741 0.1714 0.1694 0.1679 0.1664 0.1646 0.1631 0.1620 0.1609 0.1601 0.1597 0.1595 0.1598 

[TRAIN] Epoch[2](1478/1500); Loss: 0.129997; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2277 0.2096 0.1885 0.1684 0.1497 0.1330 0.1209 0.1126 0.1066 0.1009 0.0960 0.0935 0.0926 0.0932 0.0931 0.0936 

[TRAIN] Epoch[2](1479/1500); Loss: 0.142501; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2223 0.2023 0.1744 0.1588 0.1476 0.1404 0.1380 0.1325 0.1258 0.1212 0.1187 0.1175 0.1187 0.1199 0.1203 0.1215 

[TRAIN] Epoch[2](1480/1500); Loss: 0.100207; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1998 0.1794 0.1579 0.1320 0.1076 0.0880 0.0768 0.0757 0.0771 0.0769 0.0744 0.0708 0.0703 0.0705 0.0719 0.0742 

[TRAIN] Epoch[2](1481/1500); Loss: 0.077872; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1027 0.1036 0.0864 0.0814 0.0748 0.0716 0.0703 0.0703 0.0702 0.0704 0.0712 0.0720 0.0730 0.0741 0.0757 0.0783 

[TRAIN] Epoch[2](1482/1500); Loss: 0.261295; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.3807 0.3633 0.3473 0.3288 0.3097 0.2899 0.2703 0.2504 0.2307 0.2145 0.2032 0.1975 0.1963 0.1979 0.1988 0.2016 

[TRAIN] Epoch[2](1483/1500); Loss: 0.164801; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2651 0.2428 0.2215 0.2067 0.1935 0.1814 0.1679 0.1547 0.1445 0.1351 0.1267 0.1212 0.1189 0.1179 0.1193 0.1197 

[TRAIN] Epoch[2](1484/1500); Loss: 0.065113; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0898 0.0827 0.0743 0.0679 0.0627 0.0593 0.0601 0.0609 0.0581 0.0582 0.0583 0.0600 0.0603 0.0614 0.0631 0.0646 

[TRAIN] Epoch[2](1485/1500); Loss: 0.250396; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2703 0.2682 0.2626 0.2590 0.2548 0.2527 0.2494 0.2484 0.2460 0.2448 0.2439 0.2427 0.2418 0.2410 0.2407 0.2400 

[TRAIN] Epoch[2](1486/1500); Loss: 0.138315; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2567 0.2372 0.2083 0.1835 0.1610 0.1423 0.1265 0.1125 0.1000 0.0976 0.0991 0.0975 0.0978 0.0968 0.0977 0.0985 

[TRAIN] Epoch[2](1487/1500); Loss: 0.061339; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0904 0.0794 0.0721 0.0633 0.0594 0.0570 0.0539 0.0532 0.0527 0.0532 0.0538 0.0547 0.0568 0.0584 0.0602 0.0630 

[TRAIN] Epoch[2](1488/1500); Loss: 0.113418; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1496 0.1386 0.1224 0.1171 0.1092 0.1078 0.1049 0.1032 0.1023 0.1036 0.1038 0.1058 0.1075 0.1095 0.1128 0.1165 

[TRAIN] Epoch[2](1489/1500); Loss: 0.103322; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1401 0.1273 0.1113 0.1000 0.0943 0.0961 0.0960 0.0970 0.0960 0.0959 0.0966 0.0974 0.0987 0.1000 0.1021 0.1043 

[TRAIN] Epoch[2](1490/1500); Loss: 0.139098; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1542 0.1495 0.1465 0.1439 0.1406 0.1379 0.1359 0.1348 0.1341 0.1341 0.1344 0.1348 0.1349 0.1355 0.1365 0.1379 

[TRAIN] Epoch[2](1491/1500); Loss: 0.128183; Backpropagation: 0.0920 sec; Batch: 0.4229 sec
0.1411 0.1364 0.1356 0.1326 0.1296 0.1279 0.1264 0.1255 0.1247 0.1240 0.1240 0.1240 0.1242 0.1243 0.1249 0.1257 

[TRAIN] Epoch[2](1492/1500); Loss: 0.096983; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1811 0.1633 0.1081 0.0995 0.0980 0.0918 0.0831 0.0799 0.0849 0.0837 0.0786 0.0790 0.0794 0.0795 0.0800 0.0817 

[TRAIN] Epoch[2](1493/1500); Loss: 0.098974; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1740 0.1585 0.1001 0.0922 0.0904 0.0896 0.0897 0.0908 0.0878 0.0869 0.0861 0.0863 0.0858 0.0866 0.0884 0.0904 

[TRAIN] Epoch[2](1494/1500); Loss: 0.140681; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1721 0.1641 0.1485 0.1450 0.1423 0.1392 0.1366 0.1345 0.1331 0.1327 0.1320 0.1328 0.1331 0.1341 0.1348 0.1360 

[TRAIN] Epoch[2](1495/1500); Loss: 0.122350; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1382 0.1340 0.1314 0.1280 0.1241 0.1210 0.1189 0.1175 0.1168 0.1176 0.1174 0.1170 0.1177 0.1185 0.1192 0.1203 

[TRAIN] Epoch[2](1496/1500); Loss: 0.134981; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1991 0.1856 0.1540 0.1482 0.1424 0.1336 0.1255 0.1225 0.1215 0.1188 0.1182 0.1171 0.1180 0.1179 0.1183 0.1190 

[TRAIN] Epoch[2](1497/1500); Loss: 0.082435; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1278 0.1134 0.0989 0.0897 0.0859 0.0803 0.0761 0.0744 0.0734 0.0727 0.0714 0.0711 0.0711 0.0706 0.0708 0.0715 

[TRAIN] Epoch[2](1498/1500); Loss: 0.161288; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1688 0.1707 0.1725 0.1694 0.1639 0.1595 0.1595 0.1610 0.1594 0.1573 0.1558 0.1559 0.1561 0.1569 0.1569 0.1570 

[TRAIN] Epoch[2](1499/1500); Loss: 0.081535; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1069 0.1037 0.1002 0.0956 0.0890 0.0802 0.0748 0.0734 0.0744 0.0718 0.0697 0.0703 0.0718 0.0723 0.0742 0.0764 

[TRAIN] Epoch[2](1500/1500); Loss: 0.125528; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1561 0.1473 0.1336 0.1281 0.1242 0.1205 0.1184 0.1188 0.1178 0.1173 0.1176 0.1189 0.1201 0.1217 0.1232 0.1247 

[TRAIN] Epoch[3](1/1500); Loss: 0.080999; Backpropagation: 0.0981 sec; Batch: 0.4720 sec
0.1090 0.1058 0.1038 0.0961 0.0874 0.0798 0.0752 0.0734 0.0725 0.0720 0.0712 0.0706 0.0701 0.0696 0.0695 0.0700 

[TRAIN] Epoch[3](2/1500); Loss: 0.162451; Backpropagation: 0.0956 sec; Batch: 0.4484 sec
0.3204 0.2976 0.2710 0.2410 0.2092 0.1781 0.1506 0.1291 0.1134 0.1011 0.0987 0.0984 0.0976 0.0985 0.0977 0.0968 

[TRAIN] Epoch[3](3/1500); Loss: 0.072424; Backpropagation: 0.0923 sec; Batch: 0.4270 sec
0.1016 0.1026 0.0992 0.0909 0.0806 0.0724 0.0686 0.0645 0.0613 0.0594 0.0590 0.0593 0.0585 0.0591 0.0606 0.0613 

[TRAIN] Epoch[3](4/1500); Loss: 0.084390; Backpropagation: 0.0919 sec; Batch: 0.4262 sec
0.1371 0.1224 0.1068 0.0951 0.0883 0.0833 0.0781 0.0760 0.0742 0.0727 0.0715 0.0702 0.0695 0.0691 0.0679 0.0682 

[TRAIN] Epoch[3](5/1500); Loss: 0.138649; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1996 0.1882 0.1561 0.1466 0.1411 0.1375 0.1322 0.1288 0.1284 0.1272 0.1240 0.1228 0.1221 0.1216 0.1210 0.1212 

[TRAIN] Epoch[3](6/1500); Loss: 0.107258; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1554 0.1382 0.1130 0.1069 0.1037 0.1022 0.1013 0.1001 0.0995 0.0986 0.0984 0.0988 0.0993 0.0996 0.1003 0.1006 

[TRAIN] Epoch[3](7/1500); Loss: 0.091841; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2648 0.2392 0.1282 0.0854 0.0668 0.0676 0.0635 0.0609 0.0633 0.0620 0.0594 0.0598 0.0615 0.0618 0.0622 0.0631 

[TRAIN] Epoch[3](8/1500); Loss: 0.063931; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0692 0.0684 0.0690 0.0672 0.0646 0.0618 0.0601 0.0596 0.0606 0.0609 0.0613 0.0620 0.0632 0.0638 0.0649 0.0661 

[TRAIN] Epoch[3](9/1500); Loss: 0.155054; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.2055 0.1959 0.1813 0.1706 0.1611 0.1535 0.1478 0.1453 0.1424 0.1409 0.1394 0.1394 0.1394 0.1395 0.1391 0.1397 

[TRAIN] Epoch[3](10/1500); Loss: 0.088839; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1232 0.1088 0.0942 0.0894 0.0911 0.0869 0.0826 0.0816 0.0812 0.0808 0.0816 0.0827 0.0830 0.0837 0.0848 0.0859 

[TRAIN] Epoch[3](11/1500); Loss: 0.103480; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1324 0.1294 0.1231 0.1150 0.1063 0.1003 0.0978 0.0960 0.0941 0.0938 0.0938 0.0940 0.0942 0.0949 0.0950 0.0956 

[TRAIN] Epoch[3](12/1500); Loss: 0.104392; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1621 0.1483 0.1190 0.1114 0.1038 0.0975 0.0949 0.0944 0.0929 0.0919 0.0919 0.0924 0.0917 0.0920 0.0930 0.0931 

[TRAIN] Epoch[3](13/1500); Loss: 0.139596; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1785 0.1704 0.1553 0.1474 0.1415 0.1399 0.1377 0.1345 0.1319 0.1310 0.1302 0.1284 0.1274 0.1268 0.1264 0.1260 

[TRAIN] Epoch[3](14/1500); Loss: 0.128814; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1763 0.1667 0.1360 0.1315 0.1278 0.1244 0.1229 0.1225 0.1205 0.1190 0.1182 0.1187 0.1191 0.1189 0.1192 0.1193 

[TRAIN] Epoch[3](15/1500); Loss: 0.093111; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1314 0.1197 0.1054 0.0985 0.0930 0.0909 0.0875 0.0839 0.0824 0.0827 0.0836 0.0843 0.0851 0.0861 0.0870 0.0884 

[TRAIN] Epoch[3](16/1500); Loss: 0.133793; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1510 0.1465 0.1390 0.1361 0.1333 0.1315 0.1302 0.1295 0.1295 0.1294 0.1295 0.1297 0.1302 0.1307 0.1317 0.1329 

[TRAIN] Epoch[3](17/1500); Loss: 0.130986; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2117 0.1961 0.1206 0.1206 0.1182 0.1171 0.1165 0.1171 0.1183 0.1189 0.1205 0.1221 0.1227 0.1235 0.1251 0.1269 

[TRAIN] Epoch[3](18/1500); Loss: 0.070160; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1116 0.1074 0.0960 0.0852 0.0730 0.0656 0.0658 0.0655 0.0616 0.0576 0.0559 0.0550 0.0549 0.0551 0.0557 0.0566 

[TRAIN] Epoch[3](19/1500); Loss: 0.095757; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1281 0.1222 0.1121 0.1046 0.0974 0.0918 0.0882 0.0878 0.0900 0.0898 0.0879 0.0867 0.0864 0.0863 0.0863 0.0865 

[TRAIN] Epoch[3](20/1500); Loss: 0.094092; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1782 0.1611 0.1038 0.0895 0.0883 0.0885 0.0851 0.0810 0.0810 0.0802 0.0787 0.0769 0.0772 0.0777 0.0792 0.0792 

[TRAIN] Epoch[3](21/1500); Loss: 0.061011; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0922 0.0827 0.0683 0.0633 0.0583 0.0538 0.0539 0.0585 0.0583 0.0551 0.0544 0.0545 0.0546 0.0553 0.0559 0.0571 

[TRAIN] Epoch[3](22/1500); Loss: 0.249971; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.4720 0.4498 0.4202 0.3866 0.3506 0.3133 0.2764 0.2397 0.2030 0.1662 0.1341 0.1133 0.1067 0.1126 0.1250 0.1300 

[TRAIN] Epoch[3](23/1500); Loss: 0.157211; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1749 0.1688 0.1599 0.1558 0.1524 0.1509 0.1508 0.1515 0.1529 0.1543 0.1551 0.1558 0.1568 0.1574 0.1587 0.1597 

[TRAIN] Epoch[3](24/1500); Loss: 0.150417; Backpropagation: 0.0917 sec; Batch: 0.4318 sec
0.2780 0.2629 0.2431 0.2215 0.1980 0.1738 0.1498 0.1271 0.1077 0.0947 0.0920 0.0948 0.0950 0.0900 0.0886 0.0897 

[TRAIN] Epoch[3](25/1500); Loss: 0.085023; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1083 0.1053 0.0961 0.0916 0.0868 0.0841 0.0827 0.0813 0.0799 0.0787 0.0778 0.0774 0.0773 0.0774 0.0777 0.0779 

[TRAIN] Epoch[3](26/1500); Loss: 0.138494; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.2819 0.2644 0.2414 0.2145 0.1849 0.1539 0.1229 0.0953 0.0765 0.0710 0.0785 0.0915 0.0927 0.0842 0.0819 0.0805 

[TRAIN] Epoch[3](27/1500); Loss: 0.098918; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.1192 0.1093 0.1006 0.0974 0.0966 0.0974 0.0967 0.0950 0.0944 0.0947 0.0951 0.0958 0.0965 0.0972 0.0980 0.0989 

[TRAIN] Epoch[3](28/1500); Loss: 0.076522; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0919 0.0951 0.0905 0.0803 0.0752 0.0795 0.0837 0.0782 0.0715 0.0675 0.0667 0.0665 0.0682 0.0692 0.0696 0.0708 

[TRAIN] Epoch[3](29/1500); Loss: 0.101867; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1143 0.1117 0.1066 0.1019 0.1000 0.1001 0.0995 0.0990 0.0981 0.0980 0.0980 0.0987 0.0998 0.1007 0.1014 0.1020 

[TRAIN] Epoch[3](30/1500); Loss: 0.139786; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1964 0.1813 0.1667 0.1580 0.1479 0.1383 0.1313 0.1280 0.1277 0.1254 0.1228 0.1226 0.1227 0.1222 0.1225 0.1228 

[TRAIN] Epoch[3](31/1500); Loss: 0.090877; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1064 0.1042 0.0966 0.0922 0.0910 0.0910 0.0890 0.0879 0.0869 0.0863 0.0855 0.0857 0.0864 0.0872 0.0881 0.0895 

[TRAIN] Epoch[3](32/1500); Loss: 0.167346; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.2266 0.2163 0.1924 0.1808 0.1736 0.1687 0.1633 0.1583 0.1546 0.1527 0.1504 0.1485 0.1478 0.1473 0.1481 0.1483 

[TRAIN] Epoch[3](33/1500); Loss: 0.095761; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1310 0.1229 0.1128 0.1052 0.0984 0.0946 0.0922 0.0903 0.0879 0.0857 0.0847 0.0849 0.0853 0.0855 0.0856 0.0853 

[TRAIN] Epoch[3](34/1500); Loss: 0.117687; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1811 0.1659 0.1302 0.1176 0.1100 0.1075 0.1065 0.1074 0.1097 0.1087 0.1070 0.1058 0.1054 0.1060 0.1067 0.1074 

[TRAIN] Epoch[3](35/1500); Loss: 0.152861; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2277 0.2163 0.2036 0.1907 0.1765 0.1626 0.1499 0.1394 0.1314 0.1259 0.1220 0.1208 0.1203 0.1204 0.1199 0.1184 

[TRAIN] Epoch[3](36/1500); Loss: 0.143981; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2181 0.2035 0.1620 0.1484 0.1400 0.1381 0.1345 0.1317 0.1316 0.1317 0.1307 0.1284 0.1266 0.1260 0.1260 0.1264 

[TRAIN] Epoch[3](37/1500); Loss: 0.144641; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2085 0.1957 0.1686 0.1609 0.1529 0.1450 0.1375 0.1327 0.1302 0.1284 0.1266 0.1262 0.1255 0.1252 0.1251 0.1252 

[TRAIN] Epoch[3](38/1500); Loss: 0.176440; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2921 0.2770 0.2572 0.2368 0.2152 0.1933 0.1725 0.1544 0.1408 0.1334 0.1296 0.1269 0.1253 0.1246 0.1227 0.1214 

[TRAIN] Epoch[3](39/1500); Loss: 0.139898; Backpropagation: 0.0923 sec; Batch: 0.4248 sec
0.1551 0.1532 0.1493 0.1460 0.1427 0.1401 0.1384 0.1373 0.1361 0.1353 0.1344 0.1341 0.1339 0.1340 0.1339 0.1344 

[TRAIN] Epoch[3](40/1500); Loss: 0.117168; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1358 0.1295 0.1184 0.1146 0.1132 0.1128 0.1126 0.1131 0.1138 0.1144 0.1145 0.1153 0.1158 0.1162 0.1169 0.1177 

[TRAIN] Epoch[3](41/1500); Loss: 0.172776; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1901 0.1916 0.1831 0.1784 0.1734 0.1699 0.1680 0.1680 0.1682 0.1684 0.1678 0.1676 0.1666 0.1671 0.1677 0.1686 

[TRAIN] Epoch[3](42/1500); Loss: 0.112113; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1341 0.1333 0.1212 0.1150 0.1116 0.1115 0.1103 0.1072 0.1060 0.1054 0.1051 0.1055 0.1061 0.1067 0.1072 0.1078 

[TRAIN] Epoch[3](43/1500); Loss: 0.150705; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1982 0.1899 0.1774 0.1692 0.1608 0.1542 0.1494 0.1455 0.1420 0.1385 0.1347 0.1320 0.1302 0.1295 0.1296 0.1302 

[TRAIN] Epoch[3](44/1500); Loss: 0.083346; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.0996 0.1021 0.0971 0.0858 0.0808 0.0829 0.0862 0.0829 0.0794 0.0769 0.0760 0.0755 0.0761 0.0764 0.0774 0.0782 

[TRAIN] Epoch[3](45/1500); Loss: 0.110270; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1660 0.1562 0.1180 0.1116 0.1085 0.1057 0.1033 0.1015 0.1007 0.1005 0.0998 0.0989 0.0987 0.0982 0.0981 0.0985 

[TRAIN] Epoch[3](46/1500); Loss: 0.075574; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1318 0.1168 0.1000 0.0839 0.0694 0.0630 0.0684 0.0670 0.0637 0.0613 0.0611 0.0614 0.0630 0.0646 0.0658 0.0680 

[TRAIN] Epoch[3](47/1500); Loss: 0.162450; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2170 0.2041 0.1841 0.1727 0.1636 0.1574 0.1525 0.1499 0.1491 0.1496 0.1497 0.1492 0.1494 0.1497 0.1504 0.1509 

[TRAIN] Epoch[3](48/1500); Loss: 0.073546; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1071 0.1034 0.0740 0.0708 0.0668 0.0645 0.0650 0.0664 0.0660 0.0662 0.0670 0.0683 0.0701 0.0721 0.0736 0.0755 

[TRAIN] Epoch[3](49/1500); Loss: 0.137854; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2770 0.2564 0.2295 0.1997 0.1692 0.1400 0.1161 0.0995 0.0924 0.0932 0.0952 0.0920 0.0873 0.0861 0.0861 0.0860 

[TRAIN] Epoch[3](50/1500); Loss: 0.259052; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.3827 0.3686 0.3509 0.3316 0.3111 0.2902 0.2693 0.2485 0.2277 0.2088 0.1969 0.1910 0.1895 0.1913 0.1927 0.1940 

[TRAIN] Epoch[3](51/1500); Loss: 0.066109; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1021 0.0929 0.0798 0.0676 0.0625 0.0654 0.0656 0.0603 0.0576 0.0565 0.0564 0.0567 0.0575 0.0580 0.0591 0.0596 

[TRAIN] Epoch[3](52/1500); Loss: 0.129003; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1711 0.1677 0.1513 0.1423 0.1342 0.1289 0.1261 0.1240 0.1223 0.1203 0.1158 0.1135 0.1118 0.1113 0.1114 0.1118 

[TRAIN] Epoch[3](53/1500); Loss: 0.158519; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3119 0.2920 0.2692 0.2446 0.2178 0.1904 0.1640 0.1394 0.1175 0.0999 0.0859 0.0786 0.0805 0.0846 0.0815 0.0787 

[TRAIN] Epoch[3](54/1500); Loss: 0.069178; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0845 0.0800 0.0803 0.0741 0.0692 0.0668 0.0674 0.0680 0.0660 0.0638 0.0647 0.0640 0.0635 0.0645 0.0649 0.0653 

[TRAIN] Epoch[3](55/1500); Loss: 0.111243; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1921 0.1823 0.1404 0.1231 0.1110 0.1060 0.0998 0.0960 0.0937 0.0928 0.0910 0.0899 0.0900 0.0900 0.0909 0.0910 

[TRAIN] Epoch[3](56/1500); Loss: 0.113088; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1231 0.1203 0.1164 0.1134 0.1120 0.1109 0.1098 0.1100 0.1100 0.1101 0.1103 0.1109 0.1117 0.1127 0.1136 0.1142 

[TRAIN] Epoch[3](57/1500); Loss: 0.164964; Backpropagation: 0.0930 sec; Batch: 0.4258 sec
0.2301 0.2179 0.1994 0.1866 0.1738 0.1622 0.1540 0.1496 0.1479 0.1467 0.1463 0.1454 0.1448 0.1445 0.1448 0.1454 

[TRAIN] Epoch[3](58/1500); Loss: 0.142322; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.2806 0.2582 0.2043 0.1790 0.1609 0.1497 0.1374 0.1249 0.1148 0.1072 0.0985 0.0918 0.0898 0.0922 0.0946 0.0931 

[TRAIN] Epoch[3](59/1500); Loss: 0.139319; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2231 0.2124 0.1894 0.1717 0.1549 0.1415 0.1299 0.1209 0.1150 0.1124 0.1113 0.1110 0.1097 0.1088 0.1087 0.1086 

[TRAIN] Epoch[3](60/1500); Loss: 0.093271; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1162 0.1171 0.1207 0.1115 0.1021 0.0920 0.0857 0.0858 0.0895 0.0867 0.0836 0.0790 0.0790 0.0793 0.0813 0.0829 

[TRAIN] Epoch[3](61/1500); Loss: 0.130460; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1724 0.1628 0.1462 0.1404 0.1340 0.1289 0.1255 0.1248 0.1240 0.1213 0.1187 0.1170 0.1160 0.1169 0.1185 0.1200 

[TRAIN] Epoch[3](62/1500); Loss: 0.072510; Backpropagation: 0.0917 sec; Batch: 0.4442 sec
0.0860 0.0848 0.0850 0.0830 0.0784 0.0741 0.0724 0.0718 0.0690 0.0658 0.0644 0.0645 0.0645 0.0649 0.0654 0.0662 

[TRAIN] Epoch[3](63/1500); Loss: 0.081299; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1186 0.1124 0.1037 0.0964 0.0905 0.0828 0.0768 0.0722 0.0701 0.0693 0.0684 0.0678 0.0672 0.0674 0.0681 0.0691 

[TRAIN] Epoch[3](64/1500); Loss: 0.085834; Backpropagation: 0.0919 sec; Batch: 0.4280 sec
0.1113 0.1052 0.0927 0.0871 0.0833 0.0814 0.0807 0.0820 0.0806 0.0798 0.0798 0.0804 0.0813 0.0818 0.0826 0.0834 

[TRAIN] Epoch[3](65/1500); Loss: 0.111396; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1897 0.1763 0.1569 0.1430 0.1271 0.1113 0.0987 0.0919 0.0897 0.0882 0.0873 0.0857 0.0841 0.0836 0.0842 0.0847 

[TRAIN] Epoch[3](66/1500); Loss: 0.154685; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2070 0.1986 0.1796 0.1747 0.1673 0.1585 0.1502 0.1446 0.1426 0.1410 0.1371 0.1354 0.1351 0.1346 0.1344 0.1342 

[TRAIN] Epoch[3](67/1500); Loss: 0.063259; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1082 0.1028 0.0987 0.0811 0.0651 0.0553 0.0534 0.0537 0.0525 0.0503 0.0480 0.0475 0.0481 0.0491 0.0485 0.0497 

[TRAIN] Epoch[3](68/1500); Loss: 0.238218; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.3571 0.3412 0.3223 0.3025 0.2818 0.2610 0.2408 0.2211 0.2023 0.1871 0.1833 0.1818 0.1812 0.1826 0.1827 0.1827 

[TRAIN] Epoch[3](69/1500); Loss: 0.163289; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2298 0.2152 0.1926 0.1875 0.1799 0.1714 0.1625 0.1561 0.1523 0.1462 0.1414 0.1385 0.1366 0.1352 0.1339 0.1335 

[TRAIN] Epoch[3](70/1500); Loss: 0.127242; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1657 0.1579 0.1438 0.1372 0.1308 0.1264 0.1218 0.1190 0.1175 0.1165 0.1161 0.1156 0.1163 0.1162 0.1174 0.1177 

[TRAIN] Epoch[3](71/1500); Loss: 0.096175; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1034 0.1044 0.0973 0.0914 0.0922 0.0986 0.0974 0.0938 0.0930 0.0929 0.0932 0.0943 0.0956 0.0962 0.0968 0.0985 

[TRAIN] Epoch[3](72/1500); Loss: 0.104045; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1519 0.1480 0.1236 0.1140 0.1027 0.0941 0.0872 0.0846 0.0849 0.0874 0.0894 0.0923 0.0952 0.0990 0.1035 0.1071 

[TRAIN] Epoch[3](73/1500); Loss: 0.253117; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.4093 0.3895 0.3665 0.3412 0.3145 0.2875 0.2610 0.2350 0.2094 0.1876 0.1751 0.1710 0.1731 0.1759 0.1758 0.1775 

[TRAIN] Epoch[3](74/1500); Loss: 0.117706; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1840 0.1759 0.1692 0.1520 0.1347 0.1179 0.1038 0.0967 0.0955 0.0962 0.0929 0.0910 0.0921 0.0934 0.0939 0.0941 

[TRAIN] Epoch[3](75/1500); Loss: 0.150933; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2101 0.1976 0.1852 0.1762 0.1660 0.1552 0.1459 0.1380 0.1322 0.1298 0.1304 0.1303 0.1286 0.1291 0.1300 0.1305 

[TRAIN] Epoch[3](76/1500); Loss: 0.155639; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.2927 0.2710 0.2461 0.2193 0.1930 0.1693 0.1489 0.1314 0.1174 0.1083 0.1036 0.1012 0.0993 0.0969 0.0962 0.0957 

[TRAIN] Epoch[3](77/1500); Loss: 0.106376; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1133 0.1113 0.1083 0.1074 0.1065 0.1063 0.1053 0.1043 0.1042 0.1042 0.1045 0.1048 0.1047 0.1049 0.1056 0.1064 

[TRAIN] Epoch[3](78/1500); Loss: 0.070594; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1992 0.1735 0.0350 0.0527 0.0484 0.0496 0.0544 0.0574 0.0505 0.0498 0.0522 0.0586 0.0622 0.0591 0.0615 0.0653 

[TRAIN] Epoch[3](79/1500); Loss: 0.062481; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1284 0.1140 0.0646 0.0626 0.0576 0.0520 0.0494 0.0504 0.0545 0.0539 0.0491 0.0495 0.0512 0.0519 0.0543 0.0565 

[TRAIN] Epoch[3](80/1500); Loss: 0.110279; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1792 0.1621 0.1467 0.1324 0.1182 0.1050 0.0957 0.0927 0.0930 0.0930 0.0913 0.0905 0.0904 0.0909 0.0913 0.0920 

[TRAIN] Epoch[3](81/1500); Loss: 0.136182; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1542 0.1491 0.1436 0.1402 0.1374 0.1360 0.1337 0.1317 0.1315 0.1314 0.1315 0.1315 0.1317 0.1319 0.1317 0.1317 

[TRAIN] Epoch[3](82/1500); Loss: 0.078071; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1175 0.1097 0.0913 0.0825 0.0772 0.0725 0.0701 0.0704 0.0702 0.0689 0.0688 0.0689 0.0690 0.0698 0.0708 0.0714 

[TRAIN] Epoch[3](83/1500); Loss: 0.195639; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.2862 0.2716 0.2549 0.2405 0.2260 0.2119 0.1991 0.1879 0.1782 0.1693 0.1609 0.1540 0.1483 0.1459 0.1469 0.1484 

[TRAIN] Epoch[3](84/1500); Loss: 0.118163; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1864 0.1760 0.1450 0.1314 0.1191 0.1107 0.1072 0.1057 0.1039 0.1023 0.1012 0.1004 0.1002 0.1003 0.1003 0.1006 

[TRAIN] Epoch[3](85/1500); Loss: 0.135047; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2940 0.2709 0.2447 0.2153 0.1844 0.1539 0.1247 0.0985 0.0796 0.0733 0.0737 0.0756 0.0712 0.0682 0.0664 0.0664 

[TRAIN] Epoch[3](86/1500); Loss: 0.057713; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0826 0.0752 0.0689 0.0619 0.0569 0.0525 0.0516 0.0529 0.0521 0.0508 0.0515 0.0521 0.0523 0.0533 0.0537 0.0549 

[TRAIN] Epoch[3](87/1500); Loss: 0.176130; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2324 0.2175 0.2017 0.1931 0.1862 0.1799 0.1737 0.1686 0.1646 0.1607 0.1584 0.1572 0.1562 0.1559 0.1560 0.1560 

[TRAIN] Epoch[3](88/1500); Loss: 0.120788; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1502 0.1434 0.1321 0.1253 0.1189 0.1163 0.1142 0.1141 0.1138 0.1135 0.1136 0.1139 0.1147 0.1154 0.1163 0.1170 

[TRAIN] Epoch[3](89/1500); Loss: 0.138009; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1647 0.1603 0.1512 0.1477 0.1434 0.1396 0.1367 0.1340 0.1312 0.1291 0.1282 0.1280 0.1277 0.1285 0.1287 0.1291 

[TRAIN] Epoch[3](90/1500); Loss: 0.147273; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1842 0.1737 0.1581 0.1507 0.1463 0.1455 0.1444 0.1422 0.1406 0.1398 0.1392 0.1386 0.1384 0.1383 0.1380 0.1384 

[TRAIN] Epoch[3](91/1500); Loss: 0.089880; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.2234 0.1974 0.1679 0.1345 0.0986 0.0651 0.0461 0.0503 0.0668 0.0569 0.0552 0.0531 0.0541 0.0545 0.0564 0.0578 

[TRAIN] Epoch[3](92/1500); Loss: 0.141079; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1783 0.1656 0.1507 0.1401 0.1328 0.1254 0.1209 0.1205 0.1270 0.1313 0.1351 0.1379 0.1425 0.1454 0.1498 0.1540 

[TRAIN] Epoch[3](93/1500); Loss: 0.173915; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.2679 0.2539 0.2387 0.2243 0.2095 0.1947 0.1807 0.1681 0.1564 0.1457 0.1360 0.1278 0.1216 0.1191 0.1197 0.1186 

[TRAIN] Epoch[3](94/1500); Loss: 0.119576; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2363 0.2199 0.1665 0.1414 0.1226 0.1136 0.1041 0.0975 0.0931 0.0902 0.0886 0.0882 0.0885 0.0874 0.0876 0.0878 

[TRAIN] Epoch[3](95/1500); Loss: 0.173865; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2824 0.2663 0.2462 0.2250 0.2034 0.1841 0.1682 0.1558 0.1465 0.1388 0.1321 0.1280 0.1261 0.1258 0.1270 0.1263 

[TRAIN] Epoch[3](96/1500); Loss: 0.197322; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2992 0.2829 0.2616 0.2460 0.2312 0.2175 0.2044 0.1920 0.1807 0.1695 0.1584 0.1485 0.1421 0.1406 0.1425 0.1401 

[TRAIN] Epoch[3](97/1500); Loss: 0.086584; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1001 0.0958 0.0908 0.0876 0.0860 0.0857 0.0853 0.0834 0.0829 0.0828 0.0831 0.0834 0.0841 0.0844 0.0847 0.0852 

[TRAIN] Epoch[3](98/1500); Loss: 0.158341; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1995 0.1883 0.1754 0.1688 0.1620 0.1581 0.1533 0.1518 0.1494 0.1490 0.1474 0.1473 0.1459 0.1458 0.1455 0.1457 

[TRAIN] Epoch[3](99/1500); Loss: 0.094183; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1608 0.1395 0.1164 0.0978 0.0870 0.0851 0.0813 0.0803 0.0817 0.0808 0.0809 0.0807 0.0818 0.0829 0.0842 0.0857 

[TRAIN] Epoch[3](100/1500); Loss: 0.107691; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1651 0.1528 0.1282 0.1159 0.1072 0.1037 0.1006 0.0978 0.0953 0.0945 0.0940 0.0936 0.0935 0.0936 0.0936 0.0938 

[TRAIN] Epoch[3](101/1500); Loss: 0.232855; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.4781 0.4516 0.4177 0.3778 0.3356 0.2923 0.2491 0.2063 0.1636 0.1240 0.0988 0.0949 0.1076 0.1106 0.1091 0.1084 

[TRAIN] Epoch[3](102/1500); Loss: 0.085412; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1535 0.1372 0.1076 0.0954 0.0838 0.0776 0.0742 0.0716 0.0698 0.0688 0.0686 0.0695 0.0707 0.0714 0.0728 0.0741 

[TRAIN] Epoch[3](103/1500); Loss: 0.085745; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1427 0.1276 0.0859 0.0820 0.0788 0.0768 0.0758 0.0754 0.0757 0.0772 0.0773 0.0776 0.0782 0.0794 0.0803 0.0814 

[TRAIN] Epoch[3](104/1500); Loss: 0.081156; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1028 0.0922 0.0841 0.0827 0.0839 0.0825 0.0791 0.0767 0.0755 0.0755 0.0758 0.0766 0.0766 0.0771 0.0783 0.0791 

[TRAIN] Epoch[3](105/1500); Loss: 0.128624; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2875 0.2654 0.1773 0.1508 0.1421 0.1324 0.1184 0.1049 0.0934 0.0887 0.0875 0.0814 0.0816 0.0813 0.0827 0.0827 

[TRAIN] Epoch[3](106/1500); Loss: 0.166029; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2403 0.2237 0.2047 0.1888 0.1749 0.1642 0.1540 0.1475 0.1446 0.1444 0.1446 0.1436 0.1440 0.1445 0.1453 0.1474 

[TRAIN] Epoch[3](107/1500); Loss: 0.056492; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0639 0.0615 0.0583 0.0548 0.0555 0.0518 0.0504 0.0523 0.0535 0.0532 0.0545 0.0555 0.0573 0.0590 0.0608 0.0617 

[TRAIN] Epoch[3](108/1500); Loss: 0.107769; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1984 0.1786 0.1406 0.1204 0.1052 0.0959 0.0913 0.0899 0.0886 0.0876 0.0871 0.0873 0.0878 0.0883 0.0884 0.0889 

[TRAIN] Epoch[3](109/1500); Loss: 0.102376; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1198 0.1153 0.1073 0.1048 0.1018 0.1006 0.1015 0.1007 0.0974 0.0975 0.0982 0.0984 0.0984 0.0984 0.0986 0.0995 

[TRAIN] Epoch[3](110/1500); Loss: 0.110936; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1742 0.1597 0.1409 0.1273 0.1134 0.1033 0.0964 0.0935 0.0926 0.0925 0.0932 0.0943 0.0955 0.0971 0.0993 0.1018 

[TRAIN] Epoch[3](111/1500); Loss: 0.127583; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2185 0.2049 0.1686 0.1501 0.1329 0.1231 0.1138 0.1078 0.1049 0.1029 0.1026 0.1023 0.1017 0.1020 0.1023 0.1029 

[TRAIN] Epoch[3](112/1500); Loss: 0.133132; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1962 0.1838 0.1689 0.1549 0.1414 0.1316 0.1254 0.1208 0.1177 0.1152 0.1130 0.1127 0.1120 0.1118 0.1122 0.1127 

[TRAIN] Epoch[3](113/1500); Loss: 0.093988; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1537 0.1417 0.1292 0.1172 0.1067 0.0974 0.0879 0.0796 0.0744 0.0723 0.0730 0.0757 0.0745 0.0733 0.0735 0.0738 

[TRAIN] Epoch[3](114/1500); Loss: 0.096937; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1302 0.1222 0.1099 0.1027 0.0952 0.0917 0.0891 0.0888 0.0884 0.0883 0.0888 0.0893 0.0900 0.0911 0.0920 0.0935 

[TRAIN] Epoch[3](115/1500); Loss: 0.173133; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1852 0.1821 0.1754 0.1720 0.1703 0.1692 0.1685 0.1682 0.1687 0.1694 0.1703 0.1713 0.1726 0.1743 0.1758 0.1768 

[TRAIN] Epoch[3](116/1500); Loss: 0.074622; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2021 0.1750 0.1441 0.1117 0.0781 0.0486 0.0354 0.0468 0.0516 0.0421 0.0397 0.0409 0.0426 0.0433 0.0450 0.0470 

[TRAIN] Epoch[3](117/1500); Loss: 0.124773; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1656 0.1555 0.1478 0.1402 0.1329 0.1269 0.1222 0.1181 0.1131 0.1106 0.1106 0.1117 0.1116 0.1105 0.1097 0.1093 

[TRAIN] Epoch[3](118/1500); Loss: 0.116723; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1581 0.1533 0.1381 0.1281 0.1217 0.1157 0.1120 0.1095 0.1076 0.1048 0.1029 0.1017 0.1018 0.1024 0.1045 0.1054 

[TRAIN] Epoch[3](119/1500); Loss: 0.147388; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1817 0.1737 0.1595 0.1533 0.1481 0.1446 0.1435 0.1424 0.1405 0.1393 0.1383 0.1382 0.1384 0.1382 0.1388 0.1395 

[TRAIN] Epoch[3](120/1500); Loss: 0.080667; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1164 0.1091 0.1022 0.0897 0.0791 0.0737 0.0732 0.0732 0.0714 0.0701 0.0698 0.0704 0.0708 0.0722 0.0738 0.0755 

[TRAIN] Epoch[3](121/1500); Loss: 0.088313; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1129 0.1117 0.1059 0.0975 0.0912 0.0890 0.0858 0.0830 0.0810 0.0803 0.0792 0.0786 0.0783 0.0788 0.0796 0.0801 

[TRAIN] Epoch[3](122/1500); Loss: 0.087829; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1317 0.1222 0.1110 0.0997 0.0913 0.0861 0.0813 0.0782 0.0767 0.0759 0.0752 0.0749 0.0748 0.0750 0.0754 0.0759 

[TRAIN] Epoch[3](123/1500); Loss: 0.066493; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1107 0.0969 0.0809 0.0725 0.0660 0.0615 0.0574 0.0556 0.0567 0.0568 0.0562 0.0568 0.0575 0.0592 0.0590 0.0602 

[TRAIN] Epoch[3](124/1500); Loss: 0.143809; Backpropagation: 0.0924 sec; Batch: 0.4249 sec
0.2082 0.1941 0.1775 0.1645 0.1525 0.1437 0.1359 0.1314 0.1287 0.1265 0.1245 0.1240 0.1226 0.1223 0.1221 0.1222 

[TRAIN] Epoch[3](125/1500); Loss: 0.082141; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1033 0.0980 0.0897 0.0854 0.0813 0.0786 0.0771 0.0766 0.0765 0.0766 0.0774 0.0775 0.0779 0.0788 0.0796 0.0800 

[TRAIN] Epoch[3](126/1500); Loss: 0.100578; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1562 0.1400 0.1226 0.1120 0.1028 0.0948 0.0903 0.0892 0.0888 0.0881 0.0876 0.0873 0.0870 0.0870 0.0875 0.0881 

[TRAIN] Epoch[3](127/1500); Loss: 0.077274; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1275 0.1129 0.0982 0.0893 0.0822 0.0762 0.0708 0.0673 0.0652 0.0639 0.0638 0.0638 0.0638 0.0638 0.0636 0.0641 

[TRAIN] Epoch[3](128/1500); Loss: 0.112937; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1641 0.1508 0.1287 0.1196 0.1130 0.1082 0.1059 0.1050 0.1025 0.1012 0.1006 0.1004 0.1005 0.1011 0.1023 0.1031 

[TRAIN] Epoch[3](129/1500); Loss: 0.153148; Backpropagation: 0.0923 sec; Batch: 0.4249 sec
0.1824 0.1727 0.1598 0.1570 0.1541 0.1519 0.1501 0.1484 0.1470 0.1464 0.1464 0.1464 0.1468 0.1468 0.1468 0.1473 

[TRAIN] Epoch[3](130/1500); Loss: 0.122573; Backpropagation: 0.0921 sec; Batch: 0.4251 sec
0.1571 0.1490 0.1276 0.1228 0.1195 0.1188 0.1177 0.1171 0.1166 0.1165 0.1160 0.1166 0.1162 0.1164 0.1162 0.1170 

[TRAIN] Epoch[3](131/1500); Loss: 0.101226; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1616 0.1478 0.1134 0.1047 0.0975 0.0938 0.0930 0.0916 0.0908 0.0903 0.0894 0.0891 0.0891 0.0894 0.0890 0.0895 

[TRAIN] Epoch[3](132/1500); Loss: 0.100569; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1530 0.1369 0.1005 0.0981 0.0944 0.0926 0.0935 0.0949 0.0934 0.0927 0.0923 0.0922 0.0926 0.0933 0.0942 0.0945 

[TRAIN] Epoch[3](133/1500); Loss: 0.086045; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1786 0.1573 0.0854 0.0820 0.0776 0.0752 0.0738 0.0728 0.0716 0.0711 0.0712 0.0713 0.0716 0.0719 0.0725 0.0727 

[TRAIN] Epoch[3](134/1500); Loss: 0.076012; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0950 0.0880 0.0801 0.0782 0.0773 0.0773 0.0741 0.0725 0.0716 0.0711 0.0716 0.0712 0.0715 0.0717 0.0721 0.0729 

[TRAIN] Epoch[3](135/1500); Loss: 0.152967; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1924 0.1842 0.1751 0.1681 0.1635 0.1592 0.1532 0.1492 0.1450 0.1411 0.1383 0.1367 0.1359 0.1352 0.1348 0.1355 

[TRAIN] Epoch[3](136/1500); Loss: 0.105091; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1689 0.1505 0.1285 0.1172 0.1072 0.0986 0.0935 0.0922 0.0924 0.0907 0.0900 0.0896 0.0902 0.0904 0.0905 0.0911 

[TRAIN] Epoch[3](137/1500); Loss: 0.103691; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1749 0.1507 0.0994 0.0965 0.0950 0.0935 0.0946 0.0954 0.0951 0.0941 0.0935 0.0934 0.0944 0.0955 0.0959 0.0971 

[TRAIN] Epoch[3](138/1500); Loss: 0.169153; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2229 0.2114 0.1944 0.1854 0.1769 0.1692 0.1632 0.1584 0.1550 0.1532 0.1527 0.1523 0.1523 0.1524 0.1531 0.1536 

[TRAIN] Epoch[3](139/1500); Loss: 0.086449; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1542 0.1364 0.1175 0.0992 0.0836 0.0742 0.0716 0.0746 0.0710 0.0694 0.0688 0.0698 0.0709 0.0723 0.0734 0.0762 

[TRAIN] Epoch[3](140/1500); Loss: 0.127622; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1631 0.1535 0.1429 0.1384 0.1342 0.1296 0.1258 0.1215 0.1188 0.1175 0.1164 0.1155 0.1159 0.1164 0.1162 0.1163 

[TRAIN] Epoch[3](141/1500); Loss: 0.085876; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1932 0.1671 0.0892 0.0747 0.0718 0.0708 0.0690 0.0712 0.0724 0.0700 0.0690 0.0697 0.0704 0.0707 0.0714 0.0733 

[TRAIN] Epoch[3](142/1500); Loss: 0.085740; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.2306 0.2034 0.1728 0.1392 0.1037 0.0694 0.0447 0.0430 0.0580 0.0583 0.0475 0.0404 0.0390 0.0394 0.0407 0.0417 

[TRAIN] Epoch[3](143/1500); Loss: 0.138544; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1765 0.1669 0.1395 0.1366 0.1345 0.1346 0.1339 0.1330 0.1330 0.1322 0.1315 0.1320 0.1328 0.1329 0.1332 0.1334 

[TRAIN] Epoch[3](144/1500); Loss: 0.079262; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1002 0.0930 0.0839 0.0808 0.0796 0.0781 0.0766 0.0756 0.0750 0.0750 0.0749 0.0749 0.0748 0.0749 0.0752 0.0757 

[TRAIN] Epoch[3](145/1500); Loss: 0.144351; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2193 0.2044 0.1783 0.1641 0.1545 0.1477 0.1389 0.1310 0.1253 0.1215 0.1198 0.1207 0.1217 0.1211 0.1206 0.1209 

[TRAIN] Epoch[3](146/1500); Loss: 0.126816; Backpropagation: 0.0918 sec; Batch: 0.4246 sec
0.1539 0.1462 0.1377 0.1315 0.1279 0.1247 0.1228 0.1215 0.1203 0.1202 0.1200 0.1198 0.1200 0.1204 0.1208 0.1214 

[TRAIN] Epoch[3](147/1500); Loss: 0.129700; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1759 0.1649 0.1446 0.1359 0.1304 0.1262 0.1227 0.1207 0.1197 0.1193 0.1193 0.1190 0.1188 0.1189 0.1193 0.1197 

[TRAIN] Epoch[3](148/1500); Loss: 0.068399; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.0864 0.0877 0.0785 0.0709 0.0663 0.0638 0.0625 0.0628 0.0621 0.0628 0.0636 0.0628 0.0642 0.0663 0.0660 0.0675 

[TRAIN] Epoch[3](149/1500); Loss: 0.096148; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1798 0.1641 0.1004 0.0933 0.0880 0.0861 0.0847 0.0846 0.0822 0.0818 0.0819 0.0816 0.0821 0.0821 0.0827 0.0829 

[TRAIN] Epoch[3](150/1500); Loss: 0.129041; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1624 0.1556 0.1397 0.1341 0.1301 0.1272 0.1247 0.1230 0.1220 0.1211 0.1207 0.1207 0.1208 0.1206 0.1209 0.1213 

[TRAIN] Epoch[3](151/1500); Loss: 0.096311; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1675 0.1490 0.1246 0.1126 0.1031 0.0958 0.0910 0.0867 0.0813 0.0780 0.0763 0.0750 0.0748 0.0745 0.0750 0.0758 

[TRAIN] Epoch[3](152/1500); Loss: 0.060819; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0833 0.0760 0.0684 0.0608 0.0585 0.0607 0.0579 0.0559 0.0551 0.0553 0.0554 0.0559 0.0565 0.0566 0.0577 0.0592 

[TRAIN] Epoch[3](153/1500); Loss: 0.093358; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1276 0.1215 0.1132 0.1031 0.0960 0.0935 0.0898 0.0862 0.0845 0.0833 0.0824 0.0818 0.0819 0.0823 0.0830 0.0835 

[TRAIN] Epoch[3](154/1500); Loss: 0.087139; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1189 0.1068 0.0929 0.0865 0.0844 0.0848 0.0835 0.0818 0.0815 0.0813 0.0815 0.0816 0.0817 0.0820 0.0824 0.0827 

[TRAIN] Epoch[3](155/1500); Loss: 0.082661; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.1184 0.1109 0.0977 0.0890 0.0802 0.0768 0.0739 0.0729 0.0730 0.0730 0.0735 0.0740 0.0753 0.0763 0.0782 0.0794 

[TRAIN] Epoch[3](156/1500); Loss: 0.090097; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1431 0.1260 0.1096 0.0983 0.0894 0.0824 0.0837 0.0866 0.0805 0.0775 0.0775 0.0780 0.0767 0.0769 0.0776 0.0779 

[TRAIN] Epoch[3](157/1500); Loss: 0.058385; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1037 0.0864 0.0677 0.0551 0.0524 0.0541 0.0557 0.0512 0.0490 0.0498 0.0500 0.0500 0.0505 0.0523 0.0529 0.0534 

[TRAIN] Epoch[3](158/1500); Loss: 0.088465; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1137 0.1066 0.0986 0.0911 0.0871 0.0860 0.0858 0.0839 0.0826 0.0826 0.0825 0.0827 0.0827 0.0828 0.0833 0.0836 

[TRAIN] Epoch[3](159/1500); Loss: 0.100260; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1823 0.1662 0.1124 0.1000 0.0958 0.0942 0.0900 0.0868 0.0855 0.0861 0.0845 0.0840 0.0839 0.0842 0.0842 0.0842 

[TRAIN] Epoch[3](160/1500); Loss: 0.138527; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2749 0.2544 0.2302 0.2043 0.1775 0.1510 0.1259 0.1044 0.0908 0.0891 0.0894 0.0858 0.0839 0.0845 0.0846 0.0856 

[TRAIN] Epoch[3](161/1500); Loss: 0.072572; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.0934 0.0862 0.0790 0.0752 0.0742 0.0713 0.0696 0.0687 0.0678 0.0674 0.0669 0.0668 0.0676 0.0682 0.0687 0.0701 

[TRAIN] Epoch[3](162/1500); Loss: 0.119676; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1840 0.1733 0.1452 0.1290 0.1148 0.1100 0.1096 0.1079 0.1062 0.1053 0.1046 0.1037 0.1044 0.1053 0.1054 0.1059 

[TRAIN] Epoch[3](163/1500); Loss: 0.116884; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1406 0.1340 0.1255 0.1202 0.1159 0.1133 0.1126 0.1118 0.1117 0.1112 0.1116 0.1115 0.1119 0.1123 0.1129 0.1133 

[TRAIN] Epoch[3](164/1500); Loss: 0.101257; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1464 0.1324 0.1125 0.1041 0.0982 0.0959 0.0947 0.0934 0.0924 0.0923 0.0923 0.0925 0.0927 0.0930 0.0933 0.0939 

[TRAIN] Epoch[3](165/1500); Loss: 0.101796; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2405 0.2114 0.1461 0.1261 0.1106 0.1033 0.0955 0.0880 0.0790 0.0715 0.0652 0.0607 0.0577 0.0573 0.0584 0.0575 

[TRAIN] Epoch[3](166/1500); Loss: 0.061789; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1664 0.1551 0.0711 0.0510 0.0561 0.0552 0.0510 0.0467 0.0417 0.0433 0.0411 0.0402 0.0399 0.0414 0.0442 0.0441 

[TRAIN] Epoch[3](167/1500); Loss: 0.075810; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1283 0.1192 0.1008 0.0890 0.0800 0.0717 0.0665 0.0636 0.0630 0.0629 0.0617 0.0609 0.0611 0.0611 0.0615 0.0617 

[TRAIN] Epoch[3](168/1500); Loss: 0.058998; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.0872 0.0774 0.0661 0.0595 0.0564 0.0567 0.0541 0.0529 0.0524 0.0527 0.0530 0.0532 0.0547 0.0549 0.0554 0.0573 

[TRAIN] Epoch[3](169/1500); Loss: 0.208450; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.2949 0.2845 0.2704 0.2554 0.2410 0.2265 0.2127 0.2000 0.1886 0.1791 0.1710 0.1630 0.1600 0.1630 0.1633 0.1618 

[TRAIN] Epoch[3](170/1500); Loss: 0.147643; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2081 0.1949 0.1803 0.1678 0.1567 0.1482 0.1416 0.1360 0.1318 0.1293 0.1278 0.1271 0.1268 0.1280 0.1286 0.1294 

[TRAIN] Epoch[3](171/1500); Loss: 0.095913; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.1822 0.1653 0.1277 0.1174 0.1080 0.1001 0.0927 0.0865 0.0815 0.0765 0.0724 0.0678 0.0645 0.0637 0.0639 0.0644 

[TRAIN] Epoch[3](172/1500); Loss: 0.149070; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1781 0.1712 0.1616 0.1554 0.1505 0.1465 0.1436 0.1423 0.1416 0.1413 0.1416 0.1418 0.1420 0.1423 0.1424 0.1430 

[TRAIN] Epoch[3](173/1500); Loss: 0.137818; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2207 0.2024 0.1812 0.1612 0.1440 0.1318 0.1250 0.1208 0.1179 0.1155 0.1141 0.1139 0.1142 0.1142 0.1141 0.1142 

[TRAIN] Epoch[3](174/1500); Loss: 0.081833; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1968 0.1704 0.1435 0.1151 0.0854 0.0594 0.0477 0.0563 0.0576 0.0519 0.0514 0.0516 0.0544 0.0550 0.0559 0.0570 

[TRAIN] Epoch[3](175/1500); Loss: 0.080105; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1152 0.1058 0.0934 0.0859 0.0818 0.0783 0.0754 0.0736 0.0719 0.0714 0.0710 0.0708 0.0711 0.0716 0.0719 0.0724 

[TRAIN] Epoch[3](176/1500); Loss: 0.067886; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1137 0.0995 0.0840 0.0734 0.0649 0.0609 0.0608 0.0591 0.0584 0.0577 0.0580 0.0583 0.0582 0.0587 0.0599 0.0605 

[TRAIN] Epoch[3](177/1500); Loss: 0.116205; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1459 0.1364 0.1227 0.1183 0.1156 0.1137 0.1126 0.1119 0.1104 0.1098 0.1102 0.1099 0.1098 0.1101 0.1106 0.1112 

[TRAIN] Epoch[3](178/1500); Loss: 0.070255; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1324 0.1210 0.1084 0.0911 0.0738 0.0600 0.0541 0.0581 0.0548 0.0518 0.0520 0.0523 0.0524 0.0527 0.0543 0.0551 

[TRAIN] Epoch[3](179/1500); Loss: 0.138721; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.1890 0.1779 0.1466 0.1400 0.1369 0.1354 0.1336 0.1319 0.1311 0.1294 0.1290 0.1282 0.1281 0.1277 0.1276 0.1272 

[TRAIN] Epoch[3](180/1500); Loss: 0.109329; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1256 0.1212 0.1152 0.1123 0.1114 0.1099 0.1074 0.1060 0.1051 0.1047 0.1049 0.1048 0.1047 0.1049 0.1054 0.1056 

[TRAIN] Epoch[3](181/1500); Loss: 0.105176; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1649 0.1501 0.1349 0.1215 0.1122 0.1025 0.0945 0.0918 0.0911 0.0905 0.0889 0.0881 0.0882 0.0881 0.0879 0.0876 

[TRAIN] Epoch[3](182/1500); Loss: 0.074471; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1124 0.1125 0.0941 0.0848 0.0772 0.0713 0.0666 0.0644 0.0634 0.0623 0.0624 0.0625 0.0625 0.0641 0.0650 0.0660 

[TRAIN] Epoch[3](183/1500); Loss: 0.100321; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1785 0.1598 0.1256 0.1166 0.1086 0.1016 0.0989 0.0954 0.0884 0.0829 0.0807 0.0786 0.0749 0.0716 0.0710 0.0719 

[TRAIN] Epoch[3](184/1500); Loss: 0.097315; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1545 0.1477 0.1109 0.1005 0.0941 0.0910 0.0876 0.0860 0.0863 0.0849 0.0850 0.0850 0.0855 0.0854 0.0859 0.0869 

[TRAIN] Epoch[3](185/1500); Loss: 0.149040; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2230 0.2084 0.1912 0.1793 0.1680 0.1574 0.1486 0.1413 0.1353 0.1288 0.1234 0.1187 0.1154 0.1145 0.1160 0.1154 

[TRAIN] Epoch[3](186/1500); Loss: 0.057855; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2248 0.2044 0.0533 0.0388 0.0344 0.0312 0.0292 0.0320 0.0332 0.0322 0.0298 0.0298 0.0356 0.0394 0.0389 0.0386 

[TRAIN] Epoch[3](187/1500); Loss: 0.087819; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1524 0.1401 0.1076 0.0933 0.0833 0.0807 0.0776 0.0760 0.0750 0.0747 0.0740 0.0734 0.0739 0.0743 0.0744 0.0746 

[TRAIN] Epoch[3](188/1500); Loss: 0.070978; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1941 0.1761 0.0312 0.0517 0.0523 0.0483 0.0477 0.0498 0.0542 0.0519 0.0541 0.0585 0.0642 0.0645 0.0656 0.0714 

[TRAIN] Epoch[3](189/1500); Loss: 0.121572; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1529 0.1467 0.1285 0.1222 0.1179 0.1155 0.1150 0.1144 0.1145 0.1146 0.1150 0.1158 0.1166 0.1173 0.1182 0.1200 

[TRAIN] Epoch[3](190/1500); Loss: 0.127463; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1600 0.1499 0.1411 0.1355 0.1312 0.1275 0.1245 0.1232 0.1222 0.1206 0.1193 0.1181 0.1172 0.1165 0.1165 0.1162 

[TRAIN] Epoch[3](191/1500); Loss: 0.099902; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1201 0.1136 0.1064 0.0992 0.0948 0.0925 0.0928 0.0928 0.0926 0.0938 0.0954 0.0971 0.0984 0.1003 0.1032 0.1054 

[TRAIN] Epoch[3](192/1500); Loss: 0.113479; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1554 0.1426 0.1300 0.1215 0.1142 0.1090 0.1045 0.1031 0.1024 0.1029 0.1040 0.1042 0.1047 0.1051 0.1056 0.1065 

[TRAIN] Epoch[3](193/1500); Loss: 0.078263; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1534 0.1412 0.0824 0.0700 0.0670 0.0672 0.0659 0.0658 0.0646 0.0660 0.0654 0.0664 0.0670 0.0684 0.0697 0.0717 

[TRAIN] Epoch[3](194/1500); Loss: 0.117707; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1592 0.1515 0.1264 0.1157 0.1125 0.1089 0.1085 0.1102 0.1126 0.1113 0.1095 0.1100 0.1104 0.1107 0.1121 0.1137 

[TRAIN] Epoch[3](195/1500); Loss: 0.074561; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1039 0.0986 0.0940 0.0834 0.0759 0.0700 0.0704 0.0693 0.0658 0.0639 0.0642 0.0646 0.0653 0.0671 0.0676 0.0687 

[TRAIN] Epoch[3](196/1500); Loss: 0.126611; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2478 0.2225 0.1758 0.1589 0.1456 0.1348 0.1261 0.1148 0.1015 0.0923 0.0866 0.0828 0.0838 0.0867 0.0830 0.0830 

[TRAIN] Epoch[3](197/1500); Loss: 0.090497; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.1409 0.1263 0.1103 0.0966 0.0870 0.0838 0.0857 0.0816 0.0793 0.0778 0.0782 0.0784 0.0788 0.0800 0.0811 0.0824 

[TRAIN] Epoch[3](198/1500); Loss: 0.199864; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2500 0.2414 0.2294 0.2192 0.2088 0.2006 0.1940 0.1888 0.1862 0.1843 0.1835 0.1831 0.1819 0.1817 0.1824 0.1826 

[TRAIN] Epoch[3](199/1500); Loss: 0.088810; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1338 0.1199 0.1036 0.0947 0.0920 0.0902 0.0868 0.0821 0.0792 0.0778 0.0770 0.0772 0.0766 0.0763 0.0766 0.0771 

[TRAIN] Epoch[3](200/1500); Loss: 0.108095; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1952 0.1757 0.1527 0.1307 0.1125 0.0999 0.0924 0.0894 0.0884 0.0869 0.0865 0.0850 0.0842 0.0833 0.0833 0.0836 

[TRAIN] Epoch[3](201/1500); Loss: 0.163991; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2412 0.2269 0.1964 0.1845 0.1755 0.1684 0.1637 0.1585 0.1509 0.1430 0.1383 0.1355 0.1346 0.1358 0.1352 0.1354 

[TRAIN] Epoch[3](202/1500); Loss: 0.088434; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1968 0.1682 0.0665 0.0648 0.0636 0.0647 0.0715 0.0861 0.0813 0.0697 0.0710 0.0767 0.0820 0.0803 0.0831 0.0886 

[TRAIN] Epoch[3](203/1500); Loss: 0.128177; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1679 0.1584 0.1380 0.1325 0.1291 0.1267 0.1250 0.1231 0.1202 0.1182 0.1173 0.1174 0.1182 0.1188 0.1197 0.1203 

[TRAIN] Epoch[3](204/1500); Loss: 0.096321; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1602 0.1494 0.1200 0.1048 0.0922 0.0874 0.0879 0.0860 0.0824 0.0801 0.0799 0.0803 0.0813 0.0824 0.0830 0.0840 

[TRAIN] Epoch[3](205/1500); Loss: 0.065973; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.0770 0.0762 0.0727 0.0712 0.0701 0.0714 0.0685 0.0635 0.0601 0.0593 0.0595 0.0598 0.0608 0.0612 0.0615 0.0628 

[TRAIN] Epoch[3](206/1500); Loss: 0.104185; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1857 0.1650 0.1252 0.1161 0.1071 0.1000 0.0951 0.0905 0.0853 0.0846 0.0860 0.0861 0.0847 0.0845 0.0854 0.0857 

[TRAIN] Epoch[3](207/1500); Loss: 0.128717; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1763 0.1643 0.1522 0.1434 0.1346 0.1251 0.1187 0.1168 0.1166 0.1174 0.1156 0.1154 0.1155 0.1152 0.1158 0.1167 

[TRAIN] Epoch[3](208/1500); Loss: 0.076177; Backpropagation: 0.0919 sec; Batch: 0.4247 sec
0.1880 0.1579 0.0579 0.0544 0.0529 0.0525 0.0580 0.0756 0.0811 0.0561 0.0581 0.0615 0.0602 0.0642 0.0695 0.0708 

[TRAIN] Epoch[3](209/1500); Loss: 0.134248; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1423 0.1406 0.1336 0.1333 0.1344 0.1338 0.1325 0.1319 0.1318 0.1321 0.1323 0.1326 0.1331 0.1337 0.1345 0.1353 

[TRAIN] Epoch[3](210/1500); Loss: 0.074115; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1021 0.0996 0.0839 0.0752 0.0704 0.0706 0.0724 0.0707 0.0671 0.0653 0.0658 0.0661 0.0672 0.0686 0.0697 0.0712 

[TRAIN] Epoch[3](211/1500); Loss: 0.079404; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2236 0.1941 0.1609 0.1243 0.0860 0.0518 0.0376 0.0519 0.0663 0.0570 0.0429 0.0350 0.0323 0.0346 0.0366 0.0356 

[TRAIN] Epoch[3](212/1500); Loss: 0.141330; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1867 0.1754 0.1618 0.1547 0.1489 0.1426 0.1367 0.1340 0.1311 0.1297 0.1275 0.1268 0.1263 0.1264 0.1261 0.1264 

[TRAIN] Epoch[3](213/1500); Loss: 0.165998; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2228 0.2119 0.1844 0.1753 0.1706 0.1683 0.1636 0.1580 0.1539 0.1510 0.1497 0.1501 0.1497 0.1491 0.1488 0.1487 

[TRAIN] Epoch[3](214/1500); Loss: 0.161308; Backpropagation: 0.0922 sec; Batch: 0.4251 sec
0.2496 0.2300 0.2091 0.1888 0.1715 0.1585 0.1501 0.1447 0.1404 0.1373 0.1360 0.1352 0.1343 0.1330 0.1315 0.1309 

[TRAIN] Epoch[3](215/1500); Loss: 0.128169; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1660 0.1571 0.1350 0.1281 0.1236 0.1218 0.1250 0.1322 0.1327 0.1256 0.1204 0.1183 0.1173 0.1165 0.1161 0.1150 

[TRAIN] Epoch[3](216/1500); Loss: 0.139235; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.2014 0.1857 0.1677 0.1525 0.1413 0.1368 0.1348 0.1319 0.1276 0.1242 0.1224 0.1214 0.1202 0.1201 0.1202 0.1196 

[TRAIN] Epoch[3](217/1500); Loss: 0.103605; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1243 0.1200 0.1106 0.1052 0.1035 0.1035 0.1028 0.1007 0.0986 0.0977 0.0979 0.0979 0.0986 0.0985 0.0986 0.0992 

[TRAIN] Epoch[3](218/1500); Loss: 0.075545; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1274 0.1128 0.0834 0.0753 0.0701 0.0656 0.0662 0.0753 0.0797 0.0692 0.0616 0.0615 0.0620 0.0641 0.0662 0.0684 

[TRAIN] Epoch[3](219/1500); Loss: 0.075234; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1190 0.1086 0.0953 0.0826 0.0755 0.0721 0.0695 0.0667 0.0641 0.0631 0.0630 0.0627 0.0635 0.0647 0.0662 0.0673 

[TRAIN] Epoch[3](220/1500); Loss: 0.111391; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1841 0.1714 0.1253 0.1148 0.1108 0.1069 0.1028 0.1010 0.1014 0.0979 0.0952 0.0942 0.0941 0.0941 0.0941 0.0942 

[TRAIN] Epoch[3](221/1500); Loss: 0.082633; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1976 0.1715 0.1407 0.1087 0.0827 0.0689 0.0675 0.0689 0.0661 0.0573 0.0505 0.0483 0.0472 0.0483 0.0484 0.0495 

[TRAIN] Epoch[3](222/1500); Loss: 0.094297; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1146 0.1116 0.1103 0.0974 0.0910 0.0860 0.0840 0.0874 0.0926 0.0939 0.0932 0.0885 0.0873 0.0887 0.0903 0.0919 

[TRAIN] Epoch[3](223/1500); Loss: 0.065884; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0942 0.0876 0.0732 0.0660 0.0636 0.0644 0.0622 0.0601 0.0590 0.0589 0.0593 0.0600 0.0603 0.0610 0.0619 0.0626 

[TRAIN] Epoch[3](224/1500); Loss: 0.127120; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1697 0.1609 0.1459 0.1346 0.1263 0.1248 0.1255 0.1230 0.1187 0.1166 0.1152 0.1140 0.1143 0.1146 0.1147 0.1149 

[TRAIN] Epoch[3](225/1500); Loss: 0.165513; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2231 0.2146 0.1954 0.1861 0.1773 0.1688 0.1608 0.1557 0.1520 0.1505 0.1489 0.1467 0.1443 0.1423 0.1412 0.1403 

[TRAIN] Epoch[3](226/1500); Loss: 0.206566; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.3515 0.3316 0.3071 0.2791 0.2511 0.2257 0.2048 0.1869 0.1634 0.1425 0.1358 0.1409 0.1488 0.1486 0.1442 0.1431 

[TRAIN] Epoch[3](227/1500); Loss: 0.228277; Backpropagation: 0.0925 sec; Batch: 0.4247 sec
0.3304 0.3111 0.2905 0.2720 0.2540 0.2365 0.2200 0.2055 0.1942 0.1911 0.1902 0.1909 0.1922 0.1913 0.1912 0.1913 

[TRAIN] Epoch[3](228/1500); Loss: 0.106130; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1408 0.1373 0.1165 0.1101 0.1057 0.1039 0.1025 0.1000 0.0980 0.0976 0.0971 0.0973 0.0976 0.0974 0.0978 0.0985 

[TRAIN] Epoch[3](229/1500); Loss: 0.137647; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1895 0.1789 0.1692 0.1616 0.1543 0.1453 0.1358 0.1275 0.1217 0.1186 0.1177 0.1169 0.1157 0.1160 0.1165 0.1172 

[TRAIN] Epoch[3](230/1500); Loss: 0.108751; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1285 0.1341 0.1433 0.1295 0.1167 0.1051 0.0993 0.1007 0.1033 0.1022 0.0968 0.0955 0.0956 0.0942 0.0967 0.0984 

[TRAIN] Epoch[3](231/1500); Loss: 0.124139; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1569 0.1495 0.1377 0.1313 0.1279 0.1263 0.1234 0.1179 0.1143 0.1128 0.1131 0.1135 0.1147 0.1157 0.1154 0.1158 

[TRAIN] Epoch[3](232/1500); Loss: 0.060376; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.0763 0.0771 0.0644 0.0602 0.0586 0.0581 0.0607 0.0579 0.0554 0.0554 0.0557 0.0558 0.0565 0.0568 0.0578 0.0593 

[TRAIN] Epoch[3](233/1500); Loss: 0.115922; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1935 0.1731 0.1488 0.1280 0.1135 0.1088 0.1094 0.1073 0.1005 0.0967 0.0952 0.0950 0.0955 0.0960 0.0963 0.0972 

[TRAIN] Epoch[3](234/1500); Loss: 0.233322; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3725 0.3495 0.3249 0.3003 0.2753 0.2509 0.2273 0.2043 0.1834 0.1747 0.1743 0.1765 0.1803 0.1796 0.1798 0.1796 

[TRAIN] Epoch[3](235/1500); Loss: 0.077459; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1201 0.1063 0.0955 0.0832 0.0768 0.0744 0.0758 0.0751 0.0703 0.0655 0.0647 0.0650 0.0649 0.0663 0.0677 0.0676 

[TRAIN] Epoch[3](236/1500); Loss: 0.105785; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1370 0.1289 0.1042 0.0994 0.0976 0.0981 0.1026 0.1088 0.1077 0.1010 0.1005 0.1000 0.1002 0.1017 0.1022 0.1026 

[TRAIN] Epoch[3](237/1500); Loss: 0.062139; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.0823 0.0869 0.0746 0.0676 0.0600 0.0585 0.0626 0.0611 0.0542 0.0537 0.0533 0.0540 0.0550 0.0556 0.0567 0.0583 

[TRAIN] Epoch[3](238/1500); Loss: 0.140402; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1843 0.1748 0.1525 0.1443 0.1380 0.1365 0.1356 0.1348 0.1332 0.1318 0.1308 0.1296 0.1298 0.1299 0.1299 0.1305 

[TRAIN] Epoch[3](239/1500); Loss: 0.119051; Backpropagation: 0.0925 sec; Batch: 0.4249 sec
0.1894 0.1782 0.1718 0.1523 0.1354 0.1219 0.1108 0.1029 0.0987 0.0952 0.0919 0.0904 0.0904 0.0917 0.0919 0.0919 

[TRAIN] Epoch[3](240/1500); Loss: 0.088213; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1412 0.1349 0.0954 0.0922 0.0877 0.0844 0.0827 0.0824 0.0801 0.0768 0.0760 0.0759 0.0749 0.0750 0.0759 0.0758 

[TRAIN] Epoch[3](241/1500); Loss: 0.055361; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1858 0.1642 0.0370 0.0388 0.0382 0.0357 0.0375 0.0398 0.0367 0.0368 0.0376 0.0386 0.0379 0.0394 0.0404 0.0414 

[TRAIN] Epoch[3](242/1500); Loss: 0.145841; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2560 0.2369 0.2152 0.1939 0.1733 0.1539 0.1348 0.1185 0.1104 0.1090 0.1096 0.1076 0.1035 0.1028 0.1033 0.1047 

[TRAIN] Epoch[3](243/1500); Loss: 0.085598; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1019 0.0987 0.0893 0.0871 0.0846 0.0829 0.0820 0.0816 0.0814 0.0815 0.0817 0.0823 0.0830 0.0834 0.0838 0.0843 

[TRAIN] Epoch[3](244/1500); Loss: 0.102599; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2108 0.1938 0.1091 0.1039 0.0982 0.0911 0.0862 0.0867 0.0852 0.0828 0.0818 0.0801 0.0829 0.0815 0.0835 0.0840 

[TRAIN] Epoch[3](245/1500); Loss: 0.116424; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1910 0.1810 0.1560 0.1438 0.1321 0.1223 0.1145 0.1074 0.1000 0.0943 0.0891 0.0855 0.0851 0.0870 0.0868 0.0869 

[TRAIN] Epoch[3](246/1500); Loss: 0.063741; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0973 0.0881 0.0897 0.0772 0.0680 0.0596 0.0541 0.0562 0.0569 0.0528 0.0512 0.0521 0.0532 0.0533 0.0547 0.0557 

[TRAIN] Epoch[3](247/1500); Loss: 0.077444; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1068 0.1050 0.0946 0.0863 0.0801 0.0754 0.0720 0.0703 0.0694 0.0688 0.0678 0.0674 0.0676 0.0685 0.0692 0.0700 

[TRAIN] Epoch[3](248/1500); Loss: 0.098198; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1639 0.1542 0.1030 0.0996 0.0952 0.0921 0.0880 0.0859 0.0850 0.0849 0.0850 0.0855 0.0860 0.0868 0.0874 0.0885 

[TRAIN] Epoch[3](249/1500); Loss: 0.103362; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1626 0.1561 0.1142 0.1050 0.0973 0.0948 0.0933 0.0916 0.0913 0.0918 0.0915 0.0914 0.0925 0.0926 0.0929 0.0948 

[TRAIN] Epoch[3](250/1500); Loss: 0.092154; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1186 0.1121 0.1036 0.0969 0.0935 0.0928 0.0895 0.0875 0.0865 0.0859 0.0854 0.0848 0.0846 0.0844 0.0843 0.0842 

[TRAIN] Epoch[3](251/1500); Loss: 0.174340; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.2815 0.2651 0.2470 0.2295 0.2098 0.1907 0.1747 0.1608 0.1487 0.1386 0.1303 0.1245 0.1218 0.1211 0.1224 0.1230 

[TRAIN] Epoch[3](252/1500); Loss: 0.094708; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1129 0.1114 0.1116 0.1013 0.0909 0.0842 0.0815 0.0829 0.0851 0.0873 0.0886 0.0910 0.0927 0.0953 0.0978 0.1011 

[TRAIN] Epoch[3](253/1500); Loss: 0.075852; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1125 0.1082 0.0963 0.0828 0.0723 0.0686 0.0670 0.0674 0.0670 0.0663 0.0664 0.0670 0.0670 0.0670 0.0683 0.0695 

[TRAIN] Epoch[3](254/1500); Loss: 0.106848; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1626 0.1541 0.1295 0.1187 0.1088 0.1003 0.0957 0.0972 0.0972 0.0930 0.0916 0.0912 0.0916 0.0922 0.0926 0.0933 

[TRAIN] Epoch[3](255/1500); Loss: 0.138469; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1768 0.1687 0.1548 0.1485 0.1423 0.1381 0.1355 0.1331 0.1306 0.1289 0.1280 0.1267 0.1260 0.1256 0.1259 0.1261 

[TRAIN] Epoch[3](256/1500); Loss: 0.075664; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0897 0.0866 0.0819 0.0760 0.0735 0.0721 0.0722 0.0723 0.0718 0.0719 0.0721 0.0727 0.0736 0.0743 0.0745 0.0754 

[TRAIN] Epoch[3](257/1500); Loss: 0.072565; Backpropagation: 0.0923 sec; Batch: 0.4249 sec
0.1937 0.1708 0.0571 0.0595 0.0580 0.0551 0.0583 0.0590 0.0542 0.0517 0.0518 0.0561 0.0573 0.0581 0.0590 0.0613 

[TRAIN] Epoch[3](258/1500); Loss: 0.127168; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1700 0.1631 0.1471 0.1398 0.1335 0.1260 0.1222 0.1205 0.1168 0.1152 0.1144 0.1136 0.1135 0.1129 0.1128 0.1134 

[TRAIN] Epoch[3](259/1500); Loss: 0.118728; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1590 0.1506 0.1373 0.1287 0.1223 0.1162 0.1129 0.1152 0.1129 0.1074 0.1054 0.1050 0.1051 0.1056 0.1072 0.1090 

[TRAIN] Epoch[3](260/1500); Loss: 0.138821; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1949 0.1937 0.1894 0.1738 0.1621 0.1518 0.1418 0.1314 0.1243 0.1193 0.1126 0.1068 0.1041 0.1040 0.1046 0.1064 

[TRAIN] Epoch[3](261/1500); Loss: 0.075258; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1629 0.1332 0.0928 0.0767 0.0769 0.0684 0.0573 0.0499 0.0515 0.0646 0.0670 0.0558 0.0541 0.0564 0.0644 0.0724 

[TRAIN] Epoch[3](262/1500); Loss: 0.094107; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1272 0.1284 0.1288 0.1141 0.1010 0.0927 0.0869 0.0850 0.0830 0.0812 0.0799 0.0792 0.0791 0.0793 0.0796 0.0803 

[TRAIN] Epoch[3](263/1500); Loss: 0.146660; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2011 0.1895 0.1773 0.1660 0.1570 0.1491 0.1422 0.1365 0.1318 0.1301 0.1293 0.1287 0.1277 0.1268 0.1266 0.1267 

[TRAIN] Epoch[3](264/1500); Loss: 0.173625; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1981 0.1947 0.1876 0.1807 0.1756 0.1735 0.1706 0.1688 0.1690 0.1670 0.1655 0.1652 0.1649 0.1648 0.1654 0.1666 

[TRAIN] Epoch[3](265/1500); Loss: 0.143714; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1903 0.1805 0.1665 0.1573 0.1483 0.1415 0.1377 0.1348 0.1315 0.1301 0.1295 0.1294 0.1297 0.1305 0.1307 0.1311 

[TRAIN] Epoch[3](266/1500); Loss: 0.120837; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1586 0.1476 0.1333 0.1224 0.1170 0.1180 0.1184 0.1153 0.1131 0.1122 0.1113 0.1120 0.1117 0.1131 0.1144 0.1151 

[TRAIN] Epoch[3](267/1500); Loss: 0.088384; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1465 0.1444 0.1459 0.1254 0.1045 0.0869 0.0740 0.0668 0.0681 0.0703 0.0639 0.0620 0.0625 0.0634 0.0643 0.0654 

[TRAIN] Epoch[3](268/1500); Loss: 0.060811; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0742 0.0743 0.0704 0.0676 0.0640 0.0601 0.0587 0.0578 0.0553 0.0548 0.0553 0.0552 0.0555 0.0559 0.0566 0.0575 

[TRAIN] Epoch[3](269/1500); Loss: 0.086296; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.1719 0.1437 0.1017 0.0866 0.0852 0.0768 0.0667 0.0610 0.0668 0.0825 0.0818 0.0649 0.0661 0.0716 0.0757 0.0778 

[TRAIN] Epoch[3](270/1500); Loss: 0.071441; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1093 0.1049 0.0858 0.0775 0.0707 0.0658 0.0660 0.0687 0.0642 0.0606 0.0602 0.0607 0.0612 0.0614 0.0626 0.0632 

[TRAIN] Epoch[3](271/1500); Loss: 0.082239; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.0891 0.0903 0.0930 0.0869 0.0839 0.0807 0.0795 0.0783 0.0786 0.0784 0.0786 0.0785 0.0790 0.0795 0.0802 0.0812 

[TRAIN] Epoch[3](272/1500); Loss: 0.089946; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1154 0.1101 0.1019 0.0967 0.0916 0.0872 0.0857 0.0837 0.0822 0.0826 0.0827 0.0833 0.0830 0.0838 0.0841 0.0850 

[TRAIN] Epoch[3](273/1500); Loss: 0.087570; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1708 0.1544 0.1344 0.1169 0.0998 0.0831 0.0698 0.0659 0.0701 0.0695 0.0633 0.0606 0.0606 0.0606 0.0606 0.0607 

[TRAIN] Epoch[3](274/1500); Loss: 0.124328; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1535 0.1498 0.1424 0.1318 0.1259 0.1236 0.1233 0.1224 0.1192 0.1134 0.1120 0.1129 0.1138 0.1143 0.1153 0.1156 

[TRAIN] Epoch[3](275/1500); Loss: 0.214876; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.4445 0.4136 0.3796 0.3418 0.3021 0.2620 0.2213 0.1809 0.1413 0.1075 0.0915 0.0983 0.1171 0.1168 0.1100 0.1096 

[TRAIN] Epoch[3](276/1500); Loss: 0.114527; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1553 0.1454 0.1324 0.1261 0.1220 0.1171 0.1102 0.1057 0.1036 0.1037 0.1034 0.1019 0.1013 0.1013 0.1012 0.1019 

[TRAIN] Epoch[3](277/1500); Loss: 0.077080; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1053 0.1094 0.1069 0.0916 0.0816 0.0778 0.0753 0.0681 0.0632 0.0640 0.0642 0.0634 0.0640 0.0650 0.0663 0.0672 

[TRAIN] Epoch[3](278/1500); Loss: 0.118697; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1355 0.1311 0.1243 0.1205 0.1180 0.1165 0.1157 0.1159 0.1143 0.1137 0.1139 0.1144 0.1152 0.1160 0.1168 0.1176 

[TRAIN] Epoch[3](279/1500); Loss: 0.120847; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2941 0.2661 0.2343 0.1990 0.1619 0.1273 0.0981 0.0756 0.0624 0.0599 0.0618 0.0640 0.0624 0.0581 0.0546 0.0538 

[TRAIN] Epoch[3](280/1500); Loss: 0.211538; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2520 0.2468 0.2343 0.2263 0.2195 0.2148 0.2103 0.2043 0.1991 0.1959 0.1944 0.1943 0.1949 0.1972 0.1993 0.2014 

[TRAIN] Epoch[3](281/1500); Loss: 0.160048; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1662 0.1653 0.1609 0.1625 0.1659 0.1632 0.1600 0.1587 0.1579 0.1578 0.1569 0.1566 0.1565 0.1573 0.1574 0.1577 

[TRAIN] Epoch[3](282/1500); Loss: 0.150311; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2178 0.2030 0.1792 0.1656 0.1535 0.1458 0.1405 0.1356 0.1336 0.1334 0.1328 0.1327 0.1329 0.1329 0.1329 0.1328 

[TRAIN] Epoch[3](283/1500); Loss: 0.145505; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1952 0.1826 0.1580 0.1518 0.1477 0.1442 0.1405 0.1370 0.1353 0.1343 0.1336 0.1335 0.1336 0.1333 0.1336 0.1339 

[TRAIN] Epoch[3](284/1500); Loss: 0.109397; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1395 0.1345 0.1269 0.1139 0.1056 0.1022 0.1036 0.1065 0.1058 0.1007 0.0997 0.1006 0.1017 0.1019 0.1028 0.1044 

[TRAIN] Epoch[3](285/1500); Loss: 0.102933; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1142 0.1131 0.1082 0.1059 0.1038 0.1013 0.0996 0.0993 0.0991 0.0992 0.0994 0.0998 0.1002 0.1006 0.1011 0.1021 

[TRAIN] Epoch[3](286/1500); Loss: 0.061197; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1064 0.1077 0.0729 0.0597 0.0478 0.0418 0.0386 0.0408 0.0446 0.0469 0.0498 0.0537 0.0591 0.0646 0.0698 0.0749 

[TRAIN] Epoch[3](287/1500); Loss: 0.099094; Backpropagation: 0.0920 sec; Batch: 0.4324 sec
0.1271 0.1226 0.1125 0.1064 0.1005 0.0968 0.0955 0.0944 0.0917 0.0909 0.0906 0.0905 0.0905 0.0910 0.0917 0.0927 

[TRAIN] Epoch[3](288/1500); Loss: 0.100858; Backpropagation: 0.0918 sec; Batch: 0.4250 sec
0.1509 0.1413 0.1151 0.1082 0.1026 0.0981 0.0945 0.0928 0.0913 0.0900 0.0889 0.0884 0.0881 0.0879 0.0877 0.0880 

[TRAIN] Epoch[3](289/1500); Loss: 0.124471; Backpropagation: 0.0920 sec; Batch: 0.4251 sec
0.2188 0.1986 0.1894 0.1657 0.1473 0.1276 0.1080 0.0938 0.0902 0.0953 0.1000 0.0963 0.0919 0.0902 0.0885 0.0898 

[TRAIN] Epoch[3](290/1500); Loss: 0.113901; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2021 0.1875 0.1522 0.1361 0.1198 0.1070 0.0997 0.0951 0.0948 0.0940 0.0908 0.0890 0.0888 0.0884 0.0885 0.0884 

[TRAIN] Epoch[3](291/1500); Loss: 0.127523; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1786 0.1743 0.1630 0.1509 0.1407 0.1345 0.1314 0.1240 0.1152 0.1090 0.1046 0.1024 0.1019 0.1031 0.1035 0.1033 

[TRAIN] Epoch[3](292/1500); Loss: 0.128181; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1815 0.1690 0.1520 0.1411 0.1322 0.1248 0.1186 0.1146 0.1137 0.1141 0.1144 0.1144 0.1144 0.1147 0.1153 0.1162 

[TRAIN] Epoch[3](293/1500); Loss: 0.074301; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1513 0.1223 0.0953 0.0744 0.0650 0.0650 0.0643 0.0624 0.0600 0.0577 0.0582 0.0592 0.0612 0.0626 0.0640 0.0659 

[TRAIN] Epoch[3](294/1500); Loss: 0.134776; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1754 0.1660 0.1512 0.1446 0.1386 0.1346 0.1317 0.1295 0.1268 0.1247 0.1232 0.1224 0.1217 0.1219 0.1218 0.1223 

[TRAIN] Epoch[3](295/1500); Loss: 0.197215; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.3359 0.3163 0.2946 0.2683 0.2428 0.2199 0.1985 0.1782 0.1560 0.1346 0.1276 0.1331 0.1398 0.1389 0.1357 0.1351 

[TRAIN] Epoch[3](296/1500); Loss: 0.187599; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2831 0.2685 0.2479 0.2293 0.2131 0.2006 0.1912 0.1797 0.1605 0.1459 0.1413 0.1455 0.1492 0.1487 0.1487 0.1485 

[TRAIN] Epoch[3](297/1500); Loss: 0.084902; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1171 0.1047 0.0895 0.0843 0.0853 0.0835 0.0804 0.0784 0.0774 0.0777 0.0784 0.0788 0.0797 0.0800 0.0811 0.0820 

[TRAIN] Epoch[3](298/1500); Loss: 0.146395; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1761 0.1699 0.1577 0.1523 0.1486 0.1458 0.1440 0.1415 0.1394 0.1388 0.1385 0.1381 0.1378 0.1378 0.1379 0.1381 

[TRAIN] Epoch[3](299/1500); Loss: 0.083477; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2155 0.1937 0.0753 0.0802 0.0762 0.0691 0.0660 0.0662 0.0705 0.0632 0.0607 0.0589 0.0593 0.0599 0.0606 0.0604 

[TRAIN] Epoch[3](300/1500); Loss: 0.116499; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1723 0.1611 0.1316 0.1235 0.1176 0.1133 0.1097 0.1065 0.1046 0.1036 0.1035 0.1035 0.1032 0.1031 0.1033 0.1035 

[TRAIN] Epoch[3](301/1500); Loss: 0.077732; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1407 0.1300 0.1263 0.1006 0.0809 0.0702 0.0679 0.0655 0.0620 0.0590 0.0568 0.0564 0.0561 0.0569 0.0571 0.0574 

[TRAIN] Epoch[3](302/1500); Loss: 0.180927; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2095 0.2075 0.1978 0.1908 0.1854 0.1821 0.1805 0.1778 0.1721 0.1706 0.1706 0.1700 0.1694 0.1694 0.1697 0.1715 

[TRAIN] Epoch[3](303/1500); Loss: 0.096032; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1352 0.1242 0.1093 0.1021 0.0967 0.0919 0.0906 0.0882 0.0865 0.0859 0.0865 0.0868 0.0873 0.0878 0.0883 0.0892 

[TRAIN] Epoch[3](304/1500); Loss: 0.072673; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1731 0.1546 0.0768 0.0699 0.0655 0.0595 0.0556 0.0578 0.0600 0.0609 0.0543 0.0546 0.0550 0.0543 0.0550 0.0559 

[TRAIN] Epoch[3](305/1500); Loss: 0.115224; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1731 0.1566 0.1440 0.1311 0.1215 0.1135 0.1078 0.1036 0.1020 0.1016 0.0991 0.0977 0.0974 0.0979 0.0981 0.0984 

[TRAIN] Epoch[3](306/1500); Loss: 0.176886; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2607 0.2458 0.2295 0.2130 0.1968 0.1811 0.1670 0.1540 0.1468 0.1482 0.1510 0.1485 0.1470 0.1469 0.1469 0.1469 

[TRAIN] Epoch[3](307/1500); Loss: 0.176990; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.2090 0.2039 0.1927 0.1857 0.1812 0.1778 0.1738 0.1717 0.1704 0.1692 0.1682 0.1667 0.1659 0.1651 0.1655 0.1649 

[TRAIN] Epoch[3](308/1500); Loss: 0.154443; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2285 0.2101 0.1908 0.1752 0.1623 0.1541 0.1497 0.1451 0.1392 0.1329 0.1308 0.1306 0.1308 0.1305 0.1300 0.1305 

[TRAIN] Epoch[3](309/1500); Loss: 0.103612; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1184 0.1153 0.1084 0.1054 0.1035 0.1023 0.1014 0.1004 0.1001 0.0999 0.1000 0.1002 0.1004 0.1006 0.1007 0.1008 

[TRAIN] Epoch[3](310/1500); Loss: 0.131566; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2307 0.2100 0.1846 0.1622 0.1426 0.1292 0.1218 0.1150 0.1084 0.1037 0.1012 0.1001 0.0998 0.0989 0.0984 0.0984 

[TRAIN] Epoch[3](311/1500); Loss: 0.151129; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1690 0.1657 0.1598 0.1560 0.1526 0.1504 0.1489 0.1477 0.1470 0.1463 0.1459 0.1456 0.1457 0.1457 0.1457 0.1460 

[TRAIN] Epoch[3](312/1500); Loss: 0.062134; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1786 0.1443 0.1100 0.0761 0.0464 0.0356 0.0544 0.0524 0.0366 0.0343 0.0341 0.0360 0.0365 0.0376 0.0403 0.0409 

[TRAIN] Epoch[3](313/1500); Loss: 0.150947; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3816 0.3457 0.3092 0.2706 0.2294 0.1886 0.1481 0.1083 0.0727 0.0496 0.0505 0.0649 0.0591 0.0475 0.0447 0.0448 

[TRAIN] Epoch[3](314/1500); Loss: 0.088210; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1631 0.1545 0.0884 0.0851 0.0784 0.0761 0.0751 0.0757 0.0743 0.0742 0.0753 0.0756 0.0770 0.0783 0.0794 0.0808 

[TRAIN] Epoch[3](315/1500); Loss: 0.095816; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1345 0.1242 0.1192 0.1020 0.0922 0.0894 0.0905 0.0905 0.0865 0.0844 0.0845 0.0854 0.0859 0.0871 0.0878 0.0889 

[TRAIN] Epoch[3](316/1500); Loss: 0.171462; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2019 0.2010 0.1825 0.1785 0.1748 0.1716 0.1691 0.1678 0.1651 0.1629 0.1615 0.1618 0.1616 0.1611 0.1610 0.1611 

[TRAIN] Epoch[3](317/1500); Loss: 0.105347; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1619 0.1503 0.1070 0.1019 0.0987 0.0983 0.0992 0.0977 0.0967 0.0956 0.0955 0.0955 0.0966 0.0966 0.0967 0.0975 

[TRAIN] Epoch[3](318/1500); Loss: 0.113736; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1590 0.1496 0.1186 0.1156 0.1137 0.1115 0.1099 0.1081 0.1056 0.1049 0.1046 0.1039 0.1035 0.1036 0.1039 0.1039 

[TRAIN] Epoch[3](319/1500); Loss: 0.098767; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1453 0.1308 0.1166 0.1041 0.0948 0.0905 0.0896 0.0896 0.0892 0.0894 0.0892 0.0891 0.0895 0.0903 0.0909 0.0914 

[TRAIN] Epoch[3](320/1500); Loss: 0.101637; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1745 0.1586 0.1096 0.1027 0.0987 0.0950 0.0925 0.0910 0.0897 0.0879 0.0873 0.0870 0.0872 0.0881 0.0882 0.0882 

[TRAIN] Epoch[3](321/1500); Loss: 0.111347; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1509 0.1410 0.1267 0.1193 0.1159 0.1137 0.1083 0.1038 0.1015 0.1006 0.0998 0.0999 0.1001 0.0996 0.1000 0.1005 

[TRAIN] Epoch[3](322/1500); Loss: 0.095469; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1272 0.1183 0.1063 0.0974 0.0929 0.0926 0.0932 0.0903 0.0887 0.0885 0.0881 0.0885 0.0888 0.0883 0.0888 0.0896 

[TRAIN] Epoch[3](323/1500); Loss: 0.128761; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1610 0.1537 0.1405 0.1356 0.1308 0.1266 0.1247 0.1233 0.1211 0.1202 0.1205 0.1203 0.1201 0.1202 0.1203 0.1212 

[TRAIN] Epoch[3](324/1500); Loss: 0.092849; Backpropagation: 0.0936 sec; Batch: 0.4261 sec
0.1522 0.1416 0.1195 0.1067 0.1003 0.0878 0.0795 0.0783 0.0775 0.0752 0.0752 0.0766 0.0769 0.0778 0.0793 0.0812 

[TRAIN] Epoch[3](325/1500); Loss: 0.076913; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1314 0.1141 0.0981 0.0785 0.0691 0.0743 0.0758 0.0705 0.0676 0.0635 0.0635 0.0639 0.0639 0.0643 0.0656 0.0664 

[TRAIN] Epoch[3](326/1500); Loss: 0.126350; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1766 0.1620 0.1481 0.1366 0.1265 0.1204 0.1169 0.1145 0.1148 0.1153 0.1150 0.1148 0.1146 0.1149 0.1151 0.1154 

[TRAIN] Epoch[3](327/1500); Loss: 0.065484; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1118 0.1051 0.1030 0.0884 0.0747 0.0645 0.0577 0.0534 0.0494 0.0488 0.0477 0.0472 0.0478 0.0490 0.0490 0.0502 

[TRAIN] Epoch[3](328/1500); Loss: 0.124602; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1897 0.1787 0.1623 0.1453 0.1310 0.1225 0.1187 0.1139 0.1079 0.1067 0.1044 0.1033 0.1025 0.1019 0.1020 0.1029 

[TRAIN] Epoch[3](329/1500); Loss: 0.072388; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1078 0.1004 0.0861 0.0774 0.0737 0.0730 0.0735 0.0678 0.0643 0.0626 0.0625 0.0619 0.0615 0.0617 0.0620 0.0621 

[TRAIN] Epoch[3](330/1500); Loss: 0.064441; Backpropagation: 0.0919 sec; Batch: 0.4249 sec
0.0825 0.0769 0.0731 0.0675 0.0623 0.0601 0.0600 0.0601 0.0597 0.0595 0.0596 0.0609 0.0612 0.0615 0.0624 0.0638 

[TRAIN] Epoch[3](331/1500); Loss: 0.092826; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1051 0.1024 0.0978 0.0954 0.0932 0.0919 0.0912 0.0899 0.0895 0.0894 0.0894 0.0895 0.0897 0.0900 0.0903 0.0906 

[TRAIN] Epoch[3](332/1500); Loss: 0.084711; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1301 0.1152 0.0985 0.0864 0.0804 0.0805 0.0762 0.0752 0.0749 0.0751 0.0751 0.0756 0.0764 0.0773 0.0786 0.0798 

[TRAIN] Epoch[3](333/1500); Loss: 0.154699; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2481 0.2300 0.2101 0.1924 0.1783 0.1641 0.1533 0.1425 0.1318 0.1229 0.1175 0.1174 0.1196 0.1163 0.1155 0.1154 

[TRAIN] Epoch[3](334/1500); Loss: 0.105079; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1265 0.1251 0.1114 0.1067 0.1039 0.1027 0.1022 0.1010 0.0999 0.1000 0.1000 0.1001 0.1000 0.1003 0.1008 0.1009 

[TRAIN] Epoch[3](335/1500); Loss: 0.159671; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2712 0.2509 0.2264 0.2042 0.1822 0.1619 0.1431 0.1328 0.1322 0.1288 0.1240 0.1220 0.1198 0.1184 0.1184 0.1184 

[TRAIN] Epoch[3](336/1500); Loss: 0.107300; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1333 0.1254 0.1152 0.1098 0.1078 0.1051 0.1030 0.1024 0.1020 0.1017 0.1016 0.1015 0.1020 0.1020 0.1019 0.1020 

[TRAIN] Epoch[3](337/1500); Loss: 0.110464; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1530 0.1442 0.1310 0.1208 0.1124 0.1058 0.1015 0.1024 0.1015 0.0994 0.0991 0.0993 0.0992 0.0992 0.0995 0.0992 

[TRAIN] Epoch[3](338/1500); Loss: 0.124553; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1670 0.1621 0.1487 0.1404 0.1365 0.1276 0.1209 0.1176 0.1126 0.1089 0.1074 0.1076 0.1088 0.1085 0.1085 0.1100 

[TRAIN] Epoch[3](339/1500); Loss: 0.105587; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1377 0.1282 0.1147 0.1080 0.1042 0.1030 0.1016 0.1006 0.0999 0.0993 0.0987 0.0983 0.0984 0.0986 0.0990 0.0993 

[TRAIN] Epoch[3](340/1500); Loss: 0.130150; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2543 0.2280 0.2007 0.1719 0.1460 0.1221 0.1021 0.0938 0.0981 0.1019 0.0985 0.0944 0.0921 0.0924 0.0925 0.0937 

[TRAIN] Epoch[3](341/1500); Loss: 0.132611; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2567 0.2336 0.2061 0.1807 0.1540 0.1277 0.1065 0.0974 0.1005 0.1024 0.0952 0.0931 0.0922 0.0916 0.0913 0.0928 

[TRAIN] Epoch[3](342/1500); Loss: 0.079263; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1654 0.1404 0.1127 0.0898 0.0743 0.0707 0.0711 0.0671 0.0621 0.0595 0.0583 0.0588 0.0592 0.0592 0.0595 0.0602 

[TRAIN] Epoch[3](343/1500); Loss: 0.076036; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1211 0.1080 0.1136 0.0896 0.0816 0.0702 0.0594 0.0560 0.0639 0.0691 0.0654 0.0607 0.0630 0.0662 0.0645 0.0643 

[TRAIN] Epoch[3](344/1500); Loss: 0.071071; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1164 0.1034 0.0869 0.0756 0.0714 0.0698 0.0650 0.0626 0.0619 0.0613 0.0607 0.0607 0.0605 0.0601 0.0603 0.0607 

[TRAIN] Epoch[3](345/1500); Loss: 0.111037; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1296 0.1247 0.1191 0.1132 0.1125 0.1090 0.1071 0.1079 0.1072 0.1056 0.1060 0.1059 0.1064 0.1068 0.1075 0.1081 

[TRAIN] Epoch[3](346/1500); Loss: 0.095849; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1478 0.1351 0.1226 0.1109 0.1009 0.0937 0.0869 0.0829 0.0823 0.0840 0.0825 0.0811 0.0804 0.0806 0.0809 0.0810 

[TRAIN] Epoch[3](347/1500); Loss: 0.088972; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1535 0.1265 0.0989 0.0856 0.0863 0.0784 0.0781 0.0779 0.0760 0.0764 0.0775 0.0793 0.0807 0.0815 0.0823 0.0845 

[TRAIN] Epoch[3](348/1500); Loss: 0.123580; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1717 0.1646 0.1600 0.1441 0.1305 0.1187 0.1136 0.1150 0.1132 0.1091 0.1065 0.1054 0.1056 0.1057 0.1067 0.1069 

[TRAIN] Epoch[3](349/1500); Loss: 0.110302; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2662 0.2381 0.2013 0.1657 0.1283 0.0928 0.0689 0.0623 0.0778 0.0737 0.0644 0.0644 0.0641 0.0648 0.0658 0.0662 

[TRAIN] Epoch[3](350/1500); Loss: 0.101723; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2044 0.1764 0.1463 0.1204 0.0999 0.0899 0.0853 0.0800 0.0776 0.0779 0.0764 0.0767 0.0777 0.0787 0.0795 0.0804 

[TRAIN] Epoch[3](351/1500); Loss: 0.098286; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1724 0.1586 0.1218 0.1099 0.0988 0.0901 0.0825 0.0829 0.0863 0.0836 0.0808 0.0804 0.0807 0.0801 0.0813 0.0823 

[TRAIN] Epoch[3](352/1500); Loss: 0.104767; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1272 0.1198 0.1117 0.1066 0.1040 0.1024 0.1013 0.1005 0.0998 0.0995 0.0995 0.0998 0.1002 0.1008 0.1013 0.1018 

[TRAIN] Epoch[3](353/1500); Loss: 0.096395; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1171 0.1124 0.1049 0.1007 0.0966 0.0942 0.0927 0.0920 0.0923 0.0909 0.0909 0.0908 0.0911 0.0914 0.0918 0.0926 

[TRAIN] Epoch[3](354/1500); Loss: 0.140701; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1926 0.1803 0.1571 0.1486 0.1395 0.1326 0.1286 0.1277 0.1281 0.1289 0.1298 0.1305 0.1312 0.1314 0.1315 0.1329 

[TRAIN] Epoch[3](355/1500); Loss: 0.057790; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0664 0.0692 0.0664 0.0625 0.0587 0.0556 0.0553 0.0559 0.0550 0.0540 0.0539 0.0538 0.0541 0.0544 0.0547 0.0549 

[TRAIN] Epoch[3](356/1500); Loss: 0.089147; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1273 0.1138 0.0994 0.0926 0.0869 0.0832 0.0831 0.0825 0.0812 0.0810 0.0812 0.0817 0.0819 0.0825 0.0836 0.0845 

[TRAIN] Epoch[3](357/1500); Loss: 0.048266; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0976 0.0794 0.0640 0.0526 0.0483 0.0451 0.0416 0.0400 0.0379 0.0366 0.0373 0.0371 0.0377 0.0386 0.0389 0.0395 

[TRAIN] Epoch[3](358/1500); Loss: 0.149113; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1776 0.1731 0.1517 0.1518 0.1529 0.1465 0.1447 0.1430 0.1432 0.1429 0.1420 0.1418 0.1431 0.1439 0.1439 0.1438 

[TRAIN] Epoch[3](359/1500); Loss: 0.142108; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1689 0.1623 0.1545 0.1489 0.1436 0.1398 0.1384 0.1375 0.1362 0.1349 0.1345 0.1346 0.1346 0.1348 0.1352 0.1351 

[TRAIN] Epoch[3](360/1500); Loss: 0.109646; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1515 0.1462 0.1108 0.1089 0.1062 0.1046 0.1039 0.1031 0.1028 0.1023 0.1021 0.1021 0.1021 0.1024 0.1024 0.1029 

[TRAIN] Epoch[3](361/1500); Loss: 0.096021; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1762 0.1644 0.1057 0.0989 0.0937 0.0879 0.0833 0.0826 0.0832 0.0807 0.0789 0.0797 0.0795 0.0797 0.0810 0.0810 

[TRAIN] Epoch[3](362/1500); Loss: 0.136721; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1742 0.1682 0.1451 0.1410 0.1408 0.1376 0.1343 0.1313 0.1293 0.1279 0.1271 0.1264 0.1259 0.1259 0.1262 0.1264 

[TRAIN] Epoch[3](363/1500); Loss: 0.097452; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1064 0.1095 0.1191 0.1086 0.1017 0.0947 0.0906 0.0915 0.0926 0.0914 0.0908 0.0915 0.0918 0.0922 0.0930 0.0939 

[TRAIN] Epoch[3](364/1500); Loss: 0.090600; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1331 0.1198 0.1083 0.1031 0.0974 0.0905 0.0866 0.0849 0.0825 0.0809 0.0791 0.0789 0.0770 0.0761 0.0758 0.0758 

[TRAIN] Epoch[3](365/1500); Loss: 0.106712; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1487 0.1437 0.1234 0.1137 0.1049 0.0997 0.0959 0.0945 0.0941 0.0942 0.0954 0.0963 0.0973 0.0995 0.1019 0.1041 

[TRAIN] Epoch[3](366/1500); Loss: 0.055771; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1017 0.0840 0.0674 0.0561 0.0515 0.0495 0.0486 0.0474 0.0467 0.0466 0.0470 0.0479 0.0480 0.0489 0.0502 0.0507 

[TRAIN] Epoch[3](367/1500); Loss: 0.139550; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2870 0.2547 0.2193 0.1871 0.1598 0.1370 0.1186 0.1056 0.0989 0.0977 0.0954 0.0947 0.0939 0.0939 0.0945 0.0947 

[TRAIN] Epoch[3](368/1500); Loss: 0.112252; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1556 0.1448 0.1301 0.1195 0.1127 0.1083 0.1057 0.1043 0.1027 0.1016 0.1014 0.1013 0.1014 0.1018 0.1021 0.1027 

[TRAIN] Epoch[3](369/1500); Loss: 0.059463; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1097 0.1063 0.0805 0.0726 0.0681 0.0573 0.0474 0.0423 0.0457 0.0490 0.0451 0.0441 0.0456 0.0457 0.0454 0.0465 

[TRAIN] Epoch[3](370/1500); Loss: 0.092446; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1592 0.1529 0.1465 0.1216 0.1004 0.0847 0.0801 0.0760 0.0710 0.0702 0.0686 0.0677 0.0686 0.0700 0.0702 0.0714 

[TRAIN] Epoch[3](371/1500); Loss: 0.075398; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1237 0.1133 0.0889 0.0789 0.0753 0.0709 0.0658 0.0648 0.0648 0.0643 0.0647 0.0651 0.0653 0.0662 0.0669 0.0675 

[TRAIN] Epoch[3](372/1500); Loss: 0.115836; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1786 0.1584 0.1387 0.1211 0.1103 0.1070 0.1057 0.1028 0.1025 0.1027 0.1028 0.1032 0.1036 0.1042 0.1056 0.1063 

[TRAIN] Epoch[3](373/1500); Loss: 0.156180; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2400 0.2258 0.2016 0.1905 0.1752 0.1636 0.1527 0.1418 0.1343 0.1282 0.1252 0.1239 0.1239 0.1235 0.1237 0.1249 

[TRAIN] Epoch[3](374/1500); Loss: 0.091768; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1108 0.1081 0.1019 0.0953 0.0916 0.0889 0.0878 0.0875 0.0872 0.0862 0.0861 0.0863 0.0870 0.0875 0.0878 0.0881 

[TRAIN] Epoch[3](375/1500); Loss: 0.066069; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0833 0.0844 0.0809 0.0747 0.0726 0.0689 0.0633 0.0613 0.0594 0.0581 0.0581 0.0583 0.0583 0.0584 0.0583 0.0587 

[TRAIN] Epoch[3](376/1500); Loss: 0.128905; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1637 0.1547 0.1416 0.1325 0.1268 0.1245 0.1241 0.1229 0.1219 0.1214 0.1210 0.1211 0.1213 0.1216 0.1216 0.1220 

[TRAIN] Epoch[3](377/1500); Loss: 0.072308; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1011 0.1038 0.1012 0.0728 0.0629 0.0682 0.0637 0.0639 0.0633 0.0621 0.0626 0.0643 0.0647 0.0650 0.0681 0.0692 

[TRAIN] Epoch[3](378/1500); Loss: 0.093408; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1455 0.1437 0.1274 0.1163 0.1067 0.0948 0.0853 0.0808 0.0767 0.0744 0.0732 0.0726 0.0738 0.0743 0.0744 0.0748 

[TRAIN] Epoch[3](379/1500); Loss: 0.112412; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1632 0.1581 0.1569 0.1314 0.1105 0.0999 0.1032 0.1025 0.0997 0.0961 0.0947 0.0942 0.0945 0.0957 0.0977 0.1002 

[TRAIN] Epoch[3](380/1500); Loss: 0.157906; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2084 0.1984 0.1722 0.1633 0.1578 0.1532 0.1496 0.1472 0.1463 0.1459 0.1465 0.1471 0.1471 0.1474 0.1476 0.1486 

[TRAIN] Epoch[3](381/1500); Loss: 0.123285; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1889 0.1791 0.1759 0.1514 0.1298 0.1136 0.1079 0.1119 0.1076 0.1040 0.1000 0.0991 0.0999 0.1003 0.1009 0.1021 

[TRAIN] Epoch[3](382/1500); Loss: 0.116644; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.1590 0.1519 0.1425 0.1271 0.1182 0.1151 0.1120 0.1111 0.1080 0.1044 0.1031 0.1022 0.1025 0.1033 0.1028 0.1030 

[TRAIN] Epoch[3](383/1500); Loss: 0.072867; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0974 0.0947 0.1080 0.0933 0.0813 0.0698 0.0644 0.0642 0.0625 0.0605 0.0602 0.0610 0.0612 0.0620 0.0628 0.0626 

[TRAIN] Epoch[3](384/1500); Loss: 0.071424; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1050 0.0956 0.0903 0.0772 0.0676 0.0644 0.0622 0.0635 0.0641 0.0644 0.0632 0.0634 0.0647 0.0653 0.0656 0.0663 

[TRAIN] Epoch[3](385/1500); Loss: 0.055120; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0932 0.0810 0.0712 0.0580 0.0515 0.0498 0.0479 0.0465 0.0462 0.0462 0.0469 0.0472 0.0478 0.0485 0.0495 0.0505 

[TRAIN] Epoch[3](386/1500); Loss: 0.199960; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2644 0.2535 0.2417 0.2223 0.2057 0.1939 0.1871 0.1828 0.1824 0.1826 0.1810 0.1811 0.1797 0.1802 0.1805 0.1807 

[TRAIN] Epoch[3](387/1500); Loss: 0.111600; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1818 0.1576 0.1271 0.1107 0.1063 0.1134 0.1089 0.1026 0.0994 0.0978 0.0964 0.0968 0.0976 0.0966 0.0960 0.0967 

[TRAIN] Epoch[3](388/1500); Loss: 0.088397; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1647 0.1469 0.1394 0.1158 0.0992 0.0851 0.0735 0.0718 0.0706 0.0672 0.0647 0.0643 0.0631 0.0625 0.0627 0.0629 

[TRAIN] Epoch[3](389/1500); Loss: 0.075302; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1004 0.0908 0.0788 0.0726 0.0745 0.0709 0.0707 0.0700 0.0696 0.0707 0.0707 0.0711 0.0719 0.0733 0.0739 0.0751 

[TRAIN] Epoch[3](390/1500); Loss: 0.064886; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0725 0.0705 0.0659 0.0635 0.0621 0.0609 0.0617 0.0621 0.0623 0.0629 0.0635 0.0644 0.0650 0.0659 0.0668 0.0684 

[TRAIN] Epoch[3](391/1500); Loss: 0.095737; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1300 0.1128 0.1003 0.1003 0.0953 0.0916 0.0902 0.0899 0.0894 0.0900 0.0888 0.0889 0.0898 0.0903 0.0912 0.0929 

[TRAIN] Epoch[3](392/1500); Loss: 0.134888; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.3761 0.3330 0.2828 0.2324 0.1828 0.1333 0.0918 0.0663 0.0627 0.0769 0.0671 0.0557 0.0491 0.0485 0.0492 0.0503 

[TRAIN] Epoch[3](393/1500); Loss: 0.150269; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2312 0.2137 0.1928 0.1730 0.1565 0.1429 0.1353 0.1335 0.1312 0.1295 0.1282 0.1277 0.1277 0.1270 0.1269 0.1272 

[TRAIN] Epoch[3](394/1500); Loss: 0.151094; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1993 0.1885 0.1818 0.1668 0.1592 0.1525 0.1437 0.1397 0.1396 0.1372 0.1348 0.1351 0.1346 0.1345 0.1350 0.1353 

[TRAIN] Epoch[3](395/1500); Loss: 0.070265; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1816 0.1619 0.0640 0.0629 0.0561 0.0553 0.0545 0.0587 0.0540 0.0533 0.0559 0.0546 0.0529 0.0528 0.0528 0.0528 

[TRAIN] Epoch[3](396/1500); Loss: 0.169970; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1969 0.1958 0.1982 0.1825 0.1726 0.1674 0.1641 0.1637 0.1614 0.1603 0.1592 0.1590 0.1591 0.1596 0.1596 0.1600 

[TRAIN] Epoch[3](397/1500); Loss: 0.137057; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1931 0.1806 0.1724 0.1527 0.1398 0.1320 0.1270 0.1252 0.1252 0.1223 0.1201 0.1202 0.1198 0.1203 0.1209 0.1213 

[TRAIN] Epoch[3](398/1500); Loss: 0.045259; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0953 0.0733 0.0551 0.0431 0.0441 0.0440 0.0398 0.0385 0.0370 0.0358 0.0355 0.0358 0.0357 0.0361 0.0371 0.0380 

[TRAIN] Epoch[3](399/1500); Loss: 0.097711; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1662 0.1544 0.1017 0.0990 0.0960 0.0913 0.0875 0.0876 0.0877 0.0860 0.0845 0.0838 0.0842 0.0840 0.0843 0.0852 

[TRAIN] Epoch[3](400/1500); Loss: 0.114191; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1360 0.1322 0.1306 0.1185 0.1152 0.1148 0.1105 0.1090 0.1082 0.1071 0.1077 0.1073 0.1067 0.1067 0.1077 0.1088 

[TRAIN] Epoch[3](401/1500); Loss: 0.103996; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1318 0.1189 0.1082 0.1038 0.1040 0.1032 0.1006 0.0993 0.0994 0.0992 0.0990 0.0987 0.0987 0.0995 0.0998 0.0998 

[TRAIN] Epoch[3](402/1500); Loss: 0.101546; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1216 0.1195 0.1164 0.1071 0.1041 0.1011 0.0979 0.0966 0.0964 0.0952 0.0950 0.0948 0.0949 0.0946 0.0948 0.0949 

[TRAIN] Epoch[3](403/1500); Loss: 0.106819; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1546 0.1446 0.1270 0.1150 0.1037 0.0949 0.0926 0.0917 0.0928 0.0934 0.0950 0.0962 0.0985 0.1004 0.1034 0.1052 

[TRAIN] Epoch[3](404/1500); Loss: 0.127380; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.3562 0.3136 0.2643 0.2143 0.1651 0.1177 0.0812 0.0639 0.0698 0.0764 0.0633 0.0531 0.0490 0.0494 0.0508 0.0503 

[TRAIN] Epoch[3](405/1500); Loss: 0.103420; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1226 0.1196 0.1177 0.1084 0.1060 0.1031 0.0997 0.0990 0.0981 0.0974 0.0977 0.0976 0.0973 0.0968 0.0968 0.0970 

[TRAIN] Epoch[3](406/1500); Loss: 0.107898; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1307 0.1268 0.1263 0.1141 0.1058 0.1013 0.1009 0.1031 0.1058 0.1026 0.1003 0.1008 0.1013 0.1014 0.1023 0.1028 

[TRAIN] Epoch[3](407/1500); Loss: 0.135923; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2036 0.1912 0.1801 0.1589 0.1417 0.1276 0.1187 0.1165 0.1188 0.1192 0.1170 0.1159 0.1156 0.1164 0.1167 0.1169 

[TRAIN] Epoch[3](408/1500); Loss: 0.076760; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0813 0.0865 0.1001 0.0930 0.0860 0.0741 0.0747 0.0756 0.0718 0.0699 0.0686 0.0678 0.0692 0.0700 0.0695 0.0699 

[TRAIN] Epoch[3](409/1500); Loss: 0.091031; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1244 0.1163 0.1294 0.1121 0.0986 0.0839 0.0763 0.0855 0.0918 0.0790 0.0774 0.0772 0.0772 0.0759 0.0757 0.0758 

[TRAIN] Epoch[3](410/1500); Loss: 0.116228; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.2669 0.2354 0.1896 0.1569 0.1282 0.1069 0.0938 0.0821 0.0773 0.0793 0.0746 0.0735 0.0734 0.0735 0.0738 0.0742 

[TRAIN] Epoch[3](411/1500); Loss: 0.068488; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1091 0.1012 0.0860 0.0753 0.0700 0.0622 0.0598 0.0594 0.0594 0.0583 0.0593 0.0588 0.0589 0.0589 0.0596 0.0596 

[TRAIN] Epoch[3](412/1500); Loss: 0.120446; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2062 0.1795 0.1483 0.1265 0.1121 0.1081 0.1124 0.1071 0.1050 0.1035 0.1024 0.1029 0.1035 0.1031 0.1029 0.1035 

[TRAIN] Epoch[3](413/1500); Loss: 0.089732; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1209 0.1175 0.1057 0.0944 0.0869 0.0844 0.0844 0.0829 0.0820 0.0818 0.0816 0.0819 0.0823 0.0824 0.0828 0.0838 

[TRAIN] Epoch[3](414/1500); Loss: 0.138647; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1959 0.1839 0.1546 0.1457 0.1416 0.1344 0.1290 0.1271 0.1247 0.1250 0.1262 0.1262 0.1255 0.1256 0.1266 0.1266 

[TRAIN] Epoch[3](415/1500); Loss: 0.056464; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.0602 0.0656 0.0622 0.0631 0.0695 0.0575 0.0550 0.0539 0.0535 0.0521 0.0521 0.0516 0.0513 0.0517 0.0522 0.0518 

[TRAIN] Epoch[3](416/1500); Loss: 0.069202; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1157 0.1026 0.0888 0.0762 0.0711 0.0658 0.0626 0.0599 0.0583 0.0574 0.0580 0.0581 0.0580 0.0584 0.0582 0.0584 

[TRAIN] Epoch[3](417/1500); Loss: 0.093300; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1336 0.1180 0.1038 0.0938 0.0897 0.0875 0.0874 0.0862 0.0853 0.0852 0.0857 0.0860 0.0866 0.0871 0.0881 0.0889 

[TRAIN] Epoch[3](418/1500); Loss: 0.068571; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1236 0.1055 0.0896 0.0774 0.0622 0.0578 0.0641 0.0644 0.0603 0.0571 0.0556 0.0559 0.0558 0.0556 0.0559 0.0564 

[TRAIN] Epoch[3](419/1500); Loss: 0.073490; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.0661 0.0734 0.0858 0.0764 0.0720 0.0721 0.0762 0.0776 0.0722 0.0712 0.0719 0.0711 0.0722 0.0726 0.0723 0.0727 

[TRAIN] Epoch[3](420/1500); Loss: 0.098929; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0931 0.0914 0.1081 0.1019 0.0963 0.0935 0.0913 0.0905 0.0938 0.0979 0.1001 0.1014 0.1031 0.1051 0.1066 0.1087 

[TRAIN] Epoch[3](421/1500); Loss: 0.100530; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1261 0.1219 0.1125 0.1043 0.1026 0.1017 0.0992 0.0974 0.0951 0.0930 0.0923 0.0926 0.0920 0.0925 0.0926 0.0927 

[TRAIN] Epoch[3](422/1500); Loss: 0.063704; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1481 0.1288 0.0875 0.0690 0.0575 0.0487 0.0501 0.0515 0.0568 0.0517 0.0446 0.0438 0.0442 0.0448 0.0450 0.0473 

[TRAIN] Epoch[3](423/1500); Loss: 0.105070; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1337 0.1282 0.1289 0.1137 0.1021 0.0965 0.1018 0.1147 0.1140 0.0994 0.0934 0.0908 0.0908 0.0907 0.0914 0.0911 

[TRAIN] Epoch[3](424/1500); Loss: 0.156544; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2228 0.2039 0.1814 0.1644 0.1542 0.1497 0.1472 0.1476 0.1461 0.1431 0.1412 0.1398 0.1400 0.1404 0.1410 0.1419 

[TRAIN] Epoch[3](425/1500); Loss: 0.095929; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1337 0.1161 0.1023 0.0992 0.0997 0.1037 0.0988 0.0920 0.0870 0.0845 0.0842 0.0856 0.0850 0.0865 0.0883 0.0883 

[TRAIN] Epoch[3](426/1500); Loss: 0.108973; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1314 0.1288 0.1347 0.1194 0.1094 0.1077 0.1107 0.1129 0.1088 0.1007 0.0967 0.0956 0.0957 0.0969 0.0972 0.0969 

[TRAIN] Epoch[3](427/1500); Loss: 0.139576; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1647 0.1617 0.1557 0.1478 0.1468 0.1489 0.1462 0.1394 0.1321 0.1275 0.1261 0.1271 0.1281 0.1281 0.1269 0.1264 

[TRAIN] Epoch[3](428/1500); Loss: 0.167744; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2571 0.2420 0.2236 0.2029 0.1864 0.1736 0.1644 0.1564 0.1471 0.1398 0.1357 0.1340 0.1344 0.1321 0.1285 0.1261 

[TRAIN] Epoch[3](429/1500); Loss: 0.084099; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1473 0.1289 0.1103 0.0954 0.0852 0.0777 0.0773 0.0801 0.0760 0.0707 0.0670 0.0656 0.0655 0.0657 0.0665 0.0662 

[TRAIN] Epoch[3](430/1500); Loss: 0.091733; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1170 0.1094 0.1071 0.1009 0.0983 0.0957 0.0965 0.0938 0.0880 0.0830 0.0792 0.0785 0.0792 0.0798 0.0806 0.0807 

[TRAIN] Epoch[3](431/1500); Loss: 0.124416; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2082 0.1877 0.1294 0.1147 0.1048 0.1005 0.1115 0.1330 0.1319 0.1185 0.1139 0.1091 0.1070 0.1053 0.1059 0.1093 

[TRAIN] Epoch[3](432/1500); Loss: 0.216237; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3732 0.3422 0.3081 0.2767 0.2472 0.2186 0.1911 0.1674 0.1596 0.1637 0.1725 0.1744 0.1688 0.1671 0.1645 0.1646 

[TRAIN] Epoch[3](433/1500); Loss: 0.125818; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1520 0.1540 0.1537 0.1390 0.1344 0.1377 0.1343 0.1267 0.1188 0.1123 0.1100 0.1087 0.1083 0.1081 0.1081 0.1069 

[TRAIN] Epoch[3](434/1500); Loss: 0.100328; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.2126 0.1847 0.1546 0.1285 0.1106 0.0983 0.0875 0.0784 0.0726 0.0706 0.0703 0.0700 0.0690 0.0668 0.0654 0.0651 

[TRAIN] Epoch[3](435/1500); Loss: 0.090785; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1268 0.1226 0.1398 0.1158 0.0933 0.0742 0.0662 0.0760 0.0956 0.1016 0.0850 0.0746 0.0690 0.0692 0.0702 0.0726 

[TRAIN] Epoch[3](436/1500); Loss: 0.094080; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1318 0.1228 0.1136 0.1044 0.0974 0.0919 0.0908 0.0935 0.0913 0.0849 0.0811 0.0798 0.0804 0.0809 0.0804 0.0800 

[TRAIN] Epoch[3](437/1500); Loss: 0.111275; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1374 0.1335 0.1177 0.1122 0.1086 0.1065 0.1056 0.1050 0.1044 0.1044 0.1045 0.1056 0.1071 0.1078 0.1092 0.1109 

[TRAIN] Epoch[3](438/1500); Loss: 0.088333; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1289 0.1273 0.1280 0.1078 0.0909 0.0838 0.0807 0.0786 0.0760 0.0746 0.0726 0.0715 0.0719 0.0725 0.0730 0.0751 

[TRAIN] Epoch[3](439/1500); Loss: 0.121329; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1570 0.1421 0.1309 0.1263 0.1263 0.1234 0.1212 0.1190 0.1149 0.1121 0.1111 0.1111 0.1113 0.1114 0.1115 0.1117 

[TRAIN] Epoch[3](440/1500); Loss: 0.110386; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1575 0.1456 0.1339 0.1226 0.1144 0.1097 0.1083 0.1061 0.1022 0.0980 0.0958 0.0945 0.0945 0.0943 0.0945 0.0944 

[TRAIN] Epoch[3](441/1500); Loss: 0.092397; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1208 0.1090 0.0986 0.0918 0.0892 0.0887 0.0899 0.0896 0.0876 0.0867 0.0867 0.0872 0.0881 0.0881 0.0879 0.0885 

[TRAIN] Epoch[3](442/1500); Loss: 0.127863; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1587 0.1548 0.1474 0.1400 0.1344 0.1310 0.1294 0.1259 0.1209 0.1178 0.1161 0.1143 0.1137 0.1136 0.1136 0.1142 

[TRAIN] Epoch[3](443/1500); Loss: 0.081521; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1491 0.1521 0.1761 0.1361 0.0938 0.0656 0.0556 0.0628 0.0671 0.0624 0.0524 0.0463 0.0441 0.0454 0.0487 0.0467 

[TRAIN] Epoch[3](444/1500); Loss: 0.071450; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2107 0.1686 0.1196 0.0745 0.0409 0.0385 0.0680 0.0638 0.0450 0.0402 0.0399 0.0431 0.0472 0.0467 0.0463 0.0502 

[TRAIN] Epoch[3](445/1500); Loss: 0.149170; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1887 0.1834 0.1735 0.1640 0.1563 0.1512 0.1465 0.1415 0.1370 0.1349 0.1353 0.1349 0.1346 0.1350 0.1348 0.1352 

[TRAIN] Epoch[3](446/1500); Loss: 0.088072; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1218 0.1191 0.1142 0.0927 0.0881 0.0901 0.0900 0.0851 0.0785 0.0754 0.0726 0.0725 0.0754 0.0763 0.0778 0.0795 

[TRAIN] Epoch[3](447/1500); Loss: 0.069810; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1249 0.1056 0.0867 0.0777 0.0757 0.0719 0.0637 0.0594 0.0588 0.0571 0.0559 0.0558 0.0556 0.0555 0.0563 0.0563 

[TRAIN] Epoch[3](448/1500); Loss: 0.147458; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1996 0.1877 0.1722 0.1582 0.1461 0.1394 0.1375 0.1388 0.1367 0.1349 0.1347 0.1341 0.1345 0.1347 0.1347 0.1352 

[TRAIN] Epoch[3](449/1500); Loss: 0.080231; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1278 0.1161 0.1041 0.0879 0.0755 0.0663 0.0686 0.0776 0.0786 0.0695 0.0659 0.0666 0.0672 0.0690 0.0712 0.0718 

[TRAIN] Epoch[3](450/1500); Loss: 0.131542; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3481 0.3075 0.2606 0.2175 0.1759 0.1356 0.0987 0.0707 0.0604 0.0683 0.0746 0.0647 0.0558 0.0547 0.0554 0.0562 

[TRAIN] Epoch[3](451/1500); Loss: 0.125077; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1618 0.1583 0.1382 0.1277 0.1191 0.1156 0.1165 0.1157 0.1156 0.1161 0.1169 0.1182 0.1190 0.1198 0.1210 0.1218 

[TRAIN] Epoch[3](452/1500); Loss: 0.103736; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1442 0.1371 0.1224 0.1106 0.1046 0.1017 0.0995 0.0965 0.0948 0.0932 0.0924 0.0926 0.0923 0.0926 0.0927 0.0926 

[TRAIN] Epoch[3](453/1500); Loss: 0.099558; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1514 0.1527 0.1637 0.1340 0.1094 0.1003 0.1008 0.0897 0.0784 0.0754 0.0759 0.0739 0.0713 0.0709 0.0723 0.0729 

[TRAIN] Epoch[3](454/1500); Loss: 0.101946; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1754 0.1680 0.1369 0.1230 0.1116 0.1044 0.0970 0.0868 0.0806 0.0797 0.0826 0.0805 0.0770 0.0756 0.0754 0.0766 

[TRAIN] Epoch[3](455/1500); Loss: 0.121186; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1736 0.1603 0.1431 0.1297 0.1198 0.1143 0.1107 0.1097 0.1091 0.1089 0.1094 0.1096 0.1092 0.1097 0.1106 0.1114 

[TRAIN] Epoch[3](456/1500); Loss: 0.143724; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2287 0.2118 0.1910 0.1747 0.1613 0.1484 0.1339 0.1239 0.1236 0.1210 0.1157 0.1139 0.1130 0.1124 0.1128 0.1136 

[TRAIN] Epoch[3](457/1500); Loss: 0.111838; Backpropagation: 0.0923 sec; Batch: 0.4235 sec
0.1403 0.1320 0.1298 0.1204 0.1164 0.1139 0.1101 0.1059 0.1041 0.1028 0.1016 0.1017 0.1029 0.1030 0.1022 0.1023 

[TRAIN] Epoch[3](458/1500); Loss: 0.079594; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1380 0.1312 0.1097 0.0888 0.0841 0.0810 0.0644 0.0604 0.0599 0.0619 0.0609 0.0625 0.0647 0.0659 0.0685 0.0717 

[TRAIN] Epoch[3](459/1500); Loss: 0.070223; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1470 0.1155 0.1225 0.0862 0.0695 0.0479 0.0360 0.0534 0.0527 0.0444 0.0416 0.0456 0.0617 0.0780 0.0588 0.0626 

[TRAIN] Epoch[3](460/1500); Loss: 0.224242; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2858 0.2793 0.2651 0.2458 0.2313 0.2216 0.2133 0.2085 0.2056 0.2030 0.2017 0.2027 0.2046 0.2066 0.2060 0.2069 

[TRAIN] Epoch[3](461/1500); Loss: 0.086557; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1318 0.1256 0.0990 0.0845 0.0790 0.0844 0.0899 0.0848 0.0773 0.0752 0.0752 0.0744 0.0757 0.0762 0.0755 0.0766 

[TRAIN] Epoch[3](462/1500); Loss: 0.127315; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1669 0.1500 0.1364 0.1293 0.1264 0.1242 0.1227 0.1209 0.1198 0.1193 0.1194 0.1197 0.1201 0.1204 0.1205 0.1210 

[TRAIN] Epoch[3](463/1500); Loss: 0.115310; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1757 0.1667 0.1546 0.1398 0.1298 0.1198 0.1115 0.1046 0.0976 0.0930 0.0905 0.0911 0.0927 0.0923 0.0923 0.0928 

[TRAIN] Epoch[3](464/1500); Loss: 0.085987; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1183 0.1151 0.1125 0.0972 0.0896 0.0873 0.0854 0.0794 0.0752 0.0740 0.0736 0.0733 0.0731 0.0732 0.0739 0.0748 

[TRAIN] Epoch[3](465/1500); Loss: 0.142432; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1668 0.1593 0.1502 0.1439 0.1428 0.1423 0.1403 0.1383 0.1374 0.1369 0.1365 0.1363 0.1368 0.1370 0.1369 0.1372 

[TRAIN] Epoch[3](466/1500); Loss: 0.059642; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1419 0.1090 0.0768 0.0544 0.0505 0.0633 0.0542 0.0437 0.0399 0.0415 0.0433 0.0433 0.0439 0.0481 0.0500 0.0503 

[TRAIN] Epoch[3](467/1500); Loss: 0.129744; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1716 0.1601 0.1490 0.1363 0.1291 0.1254 0.1233 0.1225 0.1207 0.1199 0.1198 0.1198 0.1196 0.1192 0.1196 0.1201 

[TRAIN] Epoch[3](468/1500); Loss: 0.114698; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1334 0.1327 0.1301 0.1226 0.1181 0.1173 0.1180 0.1159 0.1088 0.1056 0.1047 0.1048 0.1050 0.1058 0.1069 0.1055 

[TRAIN] Epoch[3](469/1500); Loss: 0.060095; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.0825 0.0770 0.0707 0.0581 0.0552 0.0557 0.0556 0.0545 0.0541 0.0546 0.0554 0.0555 0.0561 0.0574 0.0590 0.0601 

[TRAIN] Epoch[3](470/1500); Loss: 0.064612; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0902 0.0993 0.1033 0.0746 0.0664 0.0751 0.0719 0.0565 0.0496 0.0484 0.0482 0.0497 0.0493 0.0487 0.0509 0.0516 

[TRAIN] Epoch[3](471/1500); Loss: 0.081623; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1221 0.1142 0.1268 0.1051 0.0877 0.0725 0.0653 0.0726 0.0804 0.0718 0.0639 0.0635 0.0637 0.0634 0.0653 0.0676 

[TRAIN] Epoch[3](472/1500); Loss: 0.054982; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0854 0.0884 0.0900 0.0675 0.0526 0.0473 0.0527 0.0521 0.0433 0.0410 0.0415 0.0421 0.0428 0.0437 0.0444 0.0447 

[TRAIN] Epoch[3](473/1500); Loss: 0.121858; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1563 0.1540 0.1453 0.1298 0.1242 0.1277 0.1239 0.1157 0.1127 0.1107 0.1094 0.1095 0.1077 0.1070 0.1077 0.1082 

[TRAIN] Epoch[3](474/1500); Loss: 0.077088; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1426 0.1257 0.1102 0.0932 0.0838 0.0776 0.0719 0.0651 0.0590 0.0565 0.0558 0.0586 0.0593 0.0575 0.0577 0.0590 

[TRAIN] Epoch[3](475/1500); Loss: 0.124643; Backpropagation: 0.0924 sec; Batch: 0.4247 sec
0.2103 0.1968 0.1781 0.1566 0.1389 0.1224 0.1087 0.1014 0.1039 0.1041 0.0974 0.0945 0.0950 0.0945 0.0953 0.0965 

[TRAIN] Epoch[3](476/1500); Loss: 0.082554; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1693 0.1455 0.1204 0.0988 0.0835 0.0741 0.0685 0.0648 0.0643 0.0635 0.0620 0.0607 0.0608 0.0613 0.0615 0.0618 

[TRAIN] Epoch[3](477/1500); Loss: 0.145951; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1713 0.1662 0.1558 0.1496 0.1534 0.1544 0.1467 0.1400 0.1364 0.1363 0.1380 0.1387 0.1367 0.1369 0.1373 0.1374 

[TRAIN] Epoch[3](478/1500); Loss: 0.122428; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1831 0.1730 0.1648 0.1438 0.1296 0.1246 0.1218 0.1133 0.1059 0.1015 0.1001 0.0998 0.1001 0.0995 0.0989 0.0989 

[TRAIN] Epoch[3](479/1500); Loss: 0.131088; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1876 0.1781 0.1719 0.1479 0.1308 0.1233 0.1245 0.1268 0.1204 0.1132 0.1115 0.1107 0.1110 0.1122 0.1130 0.1145 

[TRAIN] Epoch[3](480/1500); Loss: 0.095941; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1999 0.1757 0.0934 0.0774 0.0696 0.0806 0.0965 0.0769 0.0779 0.0802 0.0825 0.0834 0.0821 0.0833 0.0870 0.0887 

[TRAIN] Epoch[3](481/1500); Loss: 0.156405; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2154 0.1992 0.1858 0.1677 0.1564 0.1487 0.1482 0.1536 0.1505 0.1429 0.1403 0.1382 0.1389 0.1385 0.1386 0.1395 

[TRAIN] Epoch[3](482/1500); Loss: 0.066628; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.0859 0.0874 0.0810 0.0742 0.0763 0.0778 0.0710 0.0612 0.0559 0.0548 0.0554 0.0561 0.0566 0.0565 0.0573 0.0585 

[TRAIN] Epoch[3](483/1500); Loss: 0.110945; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1597 0.1480 0.1345 0.1194 0.1138 0.1109 0.1047 0.1009 0.1005 0.0998 0.0979 0.0976 0.0967 0.0963 0.0967 0.0976 

[TRAIN] Epoch[3](484/1500); Loss: 0.094536; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1557 0.1368 0.1186 0.1121 0.1062 0.0942 0.0861 0.0814 0.0786 0.0772 0.0776 0.0775 0.0771 0.0776 0.0781 0.0779 

[TRAIN] Epoch[3](485/1500); Loss: 0.125829; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1656 0.1564 0.1482 0.1375 0.1298 0.1280 0.1288 0.1253 0.1173 0.1123 0.1103 0.1108 0.1110 0.1107 0.1102 0.1111 

[TRAIN] Epoch[3](486/1500); Loss: 0.119305; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1539 0.1531 0.1424 0.1276 0.1198 0.1189 0.1162 0.1135 0.1103 0.1083 0.1074 0.1063 0.1069 0.1083 0.1079 0.1083 

[TRAIN] Epoch[3](487/1500); Loss: 0.081434; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1139 0.1152 0.0952 0.0815 0.0738 0.0740 0.0768 0.0744 0.0726 0.0723 0.0726 0.0732 0.0745 0.0763 0.0776 0.0789 

[TRAIN] Epoch[3](488/1500); Loss: 0.118731; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1587 0.1474 0.1334 0.1260 0.1230 0.1215 0.1171 0.1120 0.1089 0.1073 0.1070 0.1077 0.1079 0.1075 0.1071 0.1072 

[TRAIN] Epoch[3](489/1500); Loss: 0.140658; Backpropagation: 0.0917 sec; Batch: 0.4225 sec
0.1621 0.1554 0.1444 0.1433 0.1455 0.1451 0.1413 0.1370 0.1338 0.1333 0.1340 0.1349 0.1347 0.1345 0.1352 0.1362 

[TRAIN] Epoch[3](490/1500); Loss: 0.106866; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1431 0.1359 0.1196 0.1121 0.1086 0.1064 0.1058 0.1028 0.0996 0.0981 0.0977 0.0970 0.0966 0.0960 0.0953 0.0953 

[TRAIN] Epoch[3](491/1500); Loss: 0.138592; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2194 0.2035 0.1820 0.1649 0.1492 0.1356 0.1243 0.1172 0.1187 0.1199 0.1158 0.1135 0.1127 0.1126 0.1134 0.1148 

[TRAIN] Epoch[3](492/1500); Loss: 0.084718; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1343 0.1255 0.0897 0.0776 0.0754 0.0827 0.0876 0.0825 0.0751 0.0739 0.0736 0.0745 0.0750 0.0749 0.0758 0.0774 

[TRAIN] Epoch[3](493/1500); Loss: 0.104051; Backpropagation: 0.0925 sec; Batch: 0.4245 sec
0.1794 0.1593 0.1334 0.1166 0.1054 0.0983 0.0977 0.0967 0.0910 0.0858 0.0836 0.0829 0.0833 0.0842 0.0835 0.0840 

[TRAIN] Epoch[3](494/1500); Loss: 0.142557; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2592 0.2306 0.1992 0.1750 0.1565 0.1420 0.1303 0.1211 0.1143 0.1129 0.1126 0.1088 0.1056 0.1046 0.1043 0.1042 

[TRAIN] Epoch[3](495/1500); Loss: 0.068981; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1123 0.0949 0.0815 0.0709 0.0719 0.0692 0.0638 0.0609 0.0595 0.0597 0.0592 0.0593 0.0596 0.0598 0.0602 0.0610 

[TRAIN] Epoch[3](496/1500); Loss: 0.098250; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1474 0.1370 0.0988 0.0925 0.0900 0.0937 0.0965 0.0939 0.0898 0.0878 0.0877 0.0891 0.0911 0.0917 0.0916 0.0935 

[TRAIN] Epoch[3](497/1500); Loss: 0.095429; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1423 0.1325 0.0985 0.0948 0.0900 0.0879 0.0884 0.0882 0.0872 0.0868 0.0868 0.0867 0.0879 0.0894 0.0893 0.0901 

[TRAIN] Epoch[3](498/1500); Loss: 0.122321; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1580 0.1533 0.1448 0.1323 0.1253 0.1236 0.1254 0.1205 0.1116 0.1096 0.1090 0.1088 0.1086 0.1077 0.1089 0.1099 

[TRAIN] Epoch[3](499/1500); Loss: 0.111028; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1535 0.1447 0.1307 0.1188 0.1114 0.1069 0.1040 0.1024 0.1012 0.1005 0.1003 0.1002 0.1000 0.1006 0.1006 0.1007 

[TRAIN] Epoch[3](500/1500); Loss: 0.115247; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1701 0.1555 0.1327 0.1194 0.1094 0.1023 0.0955 0.0986 0.1012 0.1011 0.1019 0.1064 0.1100 0.1107 0.1124 0.1169 

[TRAIN] Epoch[3](501/1500); Loss: 0.116116; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1640 0.1540 0.1447 0.1227 0.1074 0.1043 0.1119 0.1136 0.1076 0.1039 0.1015 0.1026 0.1033 0.1056 0.1049 0.1058 

[TRAIN] Epoch[3](502/1500); Loss: 0.065823; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0710 0.0765 0.0723 0.0634 0.0626 0.0660 0.0702 0.0660 0.0614 0.0617 0.0623 0.0626 0.0631 0.0642 0.0643 0.0653 

[TRAIN] Epoch[3](503/1500); Loss: 0.064897; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0947 0.0881 0.0852 0.0745 0.0707 0.0642 0.0641 0.0597 0.0535 0.0527 0.0544 0.0544 0.0541 0.0558 0.0558 0.0565 

[TRAIN] Epoch[3](504/1500); Loss: 0.054987; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.1066 0.0878 0.0728 0.0651 0.0588 0.0506 0.0448 0.0438 0.0430 0.0422 0.0418 0.0421 0.0435 0.0446 0.0451 0.0471 

[TRAIN] Epoch[3](505/1500); Loss: 0.088978; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1555 0.1484 0.0908 0.0832 0.0801 0.0816 0.0820 0.0780 0.0761 0.0763 0.0769 0.0777 0.0783 0.0789 0.0795 0.0803 

[TRAIN] Epoch[3](506/1500); Loss: 0.128706; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1590 0.1530 0.1386 0.1329 0.1310 0.1283 0.1246 0.1221 0.1211 0.1207 0.1207 0.1209 0.1210 0.1212 0.1218 0.1221 

[TRAIN] Epoch[3](507/1500); Loss: 0.096610; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2005 0.1781 0.0911 0.0772 0.0732 0.0901 0.1035 0.0798 0.0766 0.0783 0.0793 0.0807 0.0806 0.0832 0.0864 0.0871 

[TRAIN] Epoch[3](508/1500); Loss: 0.111460; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1346 0.1297 0.1217 0.1150 0.1100 0.1083 0.1072 0.1066 0.1064 0.1059 0.1057 0.1060 0.1060 0.1061 0.1068 0.1074 

[TRAIN] Epoch[3](509/1500); Loss: 0.083664; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1295 0.1187 0.0898 0.0828 0.0810 0.0829 0.0814 0.0758 0.0740 0.0739 0.0743 0.0743 0.0742 0.0745 0.0753 0.0763 

[TRAIN] Epoch[3](510/1500); Loss: 0.158909; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2250 0.2134 0.1857 0.1761 0.1698 0.1640 0.1559 0.1497 0.1444 0.1407 0.1372 0.1348 0.1376 0.1384 0.1348 0.1349 

[TRAIN] Epoch[3](511/1500); Loss: 0.104643; Backpropagation: 0.0928 sec; Batch: 0.4250 sec
0.1609 0.1580 0.1204 0.1094 0.1021 0.1005 0.0973 0.0957 0.0935 0.0925 0.0919 0.0911 0.0906 0.0904 0.0900 0.0899 

[TRAIN] Epoch[3](512/1500); Loss: 0.102745; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1436 0.1285 0.1135 0.1041 0.0995 0.0980 0.0974 0.0969 0.0956 0.0947 0.0946 0.0951 0.0953 0.0953 0.0955 0.0960 

[TRAIN] Epoch[3](513/1500); Loss: 0.081413; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1241 0.1106 0.0997 0.0898 0.0863 0.0817 0.0767 0.0733 0.0713 0.0701 0.0695 0.0696 0.0692 0.0695 0.0701 0.0710 

[TRAIN] Epoch[3](514/1500); Loss: 0.115939; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2004 0.1788 0.1449 0.1248 0.1111 0.1061 0.1038 0.1010 0.0989 0.0976 0.0972 0.0967 0.0972 0.0985 0.0992 0.0988 

[TRAIN] Epoch[3](515/1500); Loss: 0.084458; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1403 0.1264 0.1150 0.0975 0.0850 0.0776 0.0762 0.0770 0.0736 0.0708 0.0694 0.0690 0.0689 0.0677 0.0682 0.0686 

[TRAIN] Epoch[3](516/1500); Loss: 0.094371; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1388 0.1281 0.1216 0.1060 0.0933 0.0875 0.0855 0.0828 0.0824 0.0828 0.0830 0.0829 0.0833 0.0831 0.0838 0.0851 

[TRAIN] Epoch[3](517/1500); Loss: 0.069355; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1234 0.1042 0.0865 0.0793 0.0782 0.0695 0.0614 0.0582 0.0577 0.0569 0.0554 0.0551 0.0549 0.0556 0.0563 0.0570 

[TRAIN] Epoch[3](518/1500); Loss: 0.085626; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0998 0.0953 0.0884 0.0811 0.0812 0.0807 0.0800 0.0799 0.0803 0.0814 0.0839 0.0850 0.0860 0.0874 0.0891 0.0905 

[TRAIN] Epoch[3](519/1500); Loss: 0.110894; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1630 0.1527 0.1298 0.1205 0.1120 0.1049 0.1015 0.0989 0.0976 0.0983 0.0978 0.0982 0.0983 0.0995 0.1004 0.1009 

[TRAIN] Epoch[3](520/1500); Loss: 0.132108; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1625 0.1572 0.1504 0.1413 0.1366 0.1372 0.1364 0.1267 0.1230 0.1216 0.1205 0.1206 0.1200 0.1188 0.1200 0.1209 

[TRAIN] Epoch[3](521/1500); Loss: 0.142340; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2230 0.2064 0.1851 0.1711 0.1559 0.1404 0.1267 0.1207 0.1226 0.1204 0.1191 0.1183 0.1182 0.1171 0.1163 0.1159 

[TRAIN] Epoch[3](522/1500); Loss: 0.132062; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1725 0.1634 0.1534 0.1425 0.1370 0.1320 0.1276 0.1231 0.1219 0.1208 0.1200 0.1194 0.1194 0.1197 0.1201 0.1204 

[TRAIN] Epoch[3](523/1500); Loss: 0.101775; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1766 0.1603 0.1370 0.1153 0.0968 0.0896 0.0951 0.0907 0.0858 0.0817 0.0800 0.0818 0.0830 0.0829 0.0852 0.0866 

[TRAIN] Epoch[3](524/1500); Loss: 0.145161; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1999 0.1843 0.1575 0.1451 0.1379 0.1371 0.1390 0.1376 0.1351 0.1344 0.1348 0.1353 0.1358 0.1360 0.1362 0.1367 

[TRAIN] Epoch[3](525/1500); Loss: 0.132202; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1875 0.1694 0.1510 0.1383 0.1348 0.1324 0.1266 0.1239 0.1214 0.1196 0.1183 0.1175 0.1177 0.1184 0.1188 0.1196 

[TRAIN] Epoch[3](526/1500); Loss: 0.088439; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1439 0.1352 0.1176 0.0982 0.0881 0.0850 0.0797 0.0745 0.0737 0.0748 0.0736 0.0733 0.0740 0.0743 0.0745 0.0747 

[TRAIN] Epoch[3](527/1500); Loss: 0.130182; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1623 0.1551 0.1438 0.1324 0.1304 0.1298 0.1286 0.1258 0.1243 0.1229 0.1223 0.1218 0.1211 0.1208 0.1207 0.1210 

[TRAIN] Epoch[3](528/1500); Loss: 0.095077; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1390 0.1274 0.1160 0.1007 0.0978 0.0960 0.0879 0.0860 0.0833 0.0831 0.0837 0.0844 0.0828 0.0842 0.0843 0.0845 

[TRAIN] Epoch[3](529/1500); Loss: 0.124480; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2737 0.2389 0.2007 0.1656 0.1359 0.1101 0.0889 0.0850 0.0911 0.0874 0.0849 0.0847 0.0854 0.0860 0.0866 0.0868 

[TRAIN] Epoch[3](530/1500); Loss: 0.110333; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1265 0.1263 0.1235 0.1162 0.1237 0.1250 0.1104 0.1037 0.1009 0.0999 0.1001 0.1015 0.1016 0.1019 0.1025 0.1019 

[TRAIN] Epoch[3](531/1500); Loss: 0.121623; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1921 0.1807 0.1481 0.1336 0.1244 0.1181 0.1084 0.1065 0.1048 0.1043 0.1045 0.1036 0.1037 0.1038 0.1045 0.1049 

[TRAIN] Epoch[3](532/1500); Loss: 0.088456; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1198 0.1168 0.1018 0.0917 0.0891 0.0877 0.0853 0.0827 0.0804 0.0804 0.0805 0.0797 0.0797 0.0798 0.0796 0.0803 

[TRAIN] Epoch[3](533/1500); Loss: 0.115566; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2475 0.2279 0.1554 0.1382 0.1237 0.1113 0.0999 0.0916 0.0835 0.0799 0.0796 0.0803 0.0807 0.0813 0.0829 0.0852 

[TRAIN] Epoch[3](534/1500); Loss: 0.151425; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2392 0.2263 0.2056 0.1840 0.1702 0.1634 0.1514 0.1387 0.1305 0.1226 0.1162 0.1151 0.1164 0.1148 0.1143 0.1140 

[TRAIN] Epoch[3](535/1500); Loss: 0.064000; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0953 0.0972 0.0988 0.0758 0.0628 0.0567 0.0595 0.0618 0.0511 0.0506 0.0513 0.0520 0.0519 0.0520 0.0533 0.0539 

[TRAIN] Epoch[3](536/1500); Loss: 0.071368; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1446 0.1182 0.0918 0.0728 0.0635 0.0656 0.0611 0.0574 0.0567 0.0572 0.0567 0.0572 0.0582 0.0592 0.0599 0.0617 

[TRAIN] Epoch[3](537/1500); Loss: 0.077426; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1165 0.1073 0.1065 0.0924 0.0782 0.0710 0.0713 0.0678 0.0661 0.0657 0.0659 0.0660 0.0654 0.0657 0.0665 0.0666 

[TRAIN] Epoch[3](538/1500); Loss: 0.111477; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1384 0.1335 0.1200 0.1130 0.1094 0.1078 0.1083 0.1070 0.1050 0.1053 0.1056 0.1055 0.1061 0.1061 0.1059 0.1067 

[TRAIN] Epoch[3](539/1500); Loss: 0.090505; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1543 0.1469 0.1297 0.1064 0.0963 0.0928 0.0767 0.0724 0.0703 0.0702 0.0716 0.0699 0.0708 0.0713 0.0731 0.0755 

[TRAIN] Epoch[3](540/1500); Loss: 0.140028; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1552 0.1513 0.1460 0.1441 0.1467 0.1434 0.1398 0.1377 0.1365 0.1354 0.1345 0.1339 0.1338 0.1337 0.1341 0.1345 

[TRAIN] Epoch[3](541/1500); Loss: 0.124594; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2310 0.2016 0.1653 0.1444 0.1302 0.1195 0.1103 0.1031 0.0999 0.0995 0.0991 0.0981 0.0974 0.0978 0.0987 0.0976 

[TRAIN] Epoch[3](542/1500); Loss: 0.125331; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1527 0.1461 0.1331 0.1252 0.1208 0.1188 0.1173 0.1170 0.1180 0.1180 0.1186 0.1196 0.1214 0.1238 0.1263 0.1286 

[TRAIN] Epoch[3](543/1500); Loss: 0.114210; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1861 0.1729 0.1500 0.1317 0.1192 0.1109 0.1019 0.0955 0.0954 0.0978 0.0950 0.0937 0.0940 0.0948 0.0948 0.0938 

[TRAIN] Epoch[3](544/1500); Loss: 0.131701; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1685 0.1624 0.1516 0.1444 0.1405 0.1358 0.1305 0.1250 0.1217 0.1200 0.1189 0.1182 0.1174 0.1174 0.1175 0.1173 

[TRAIN] Epoch[3](545/1500); Loss: 0.122267; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1592 0.1550 0.1278 0.1247 0.1197 0.1169 0.1154 0.1144 0.1143 0.1141 0.1144 0.1151 0.1154 0.1159 0.1164 0.1174 

[TRAIN] Epoch[3](546/1500); Loss: 0.186984; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2387 0.2325 0.2169 0.1977 0.1860 0.1804 0.1764 0.1732 0.1735 0.1761 0.1735 0.1730 0.1735 0.1731 0.1731 0.1739 

[TRAIN] Epoch[3](547/1500); Loss: 0.164842; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2728 0.2497 0.2227 0.1991 0.1766 0.1573 0.1439 0.1425 0.1424 0.1372 0.1348 0.1332 0.1328 0.1321 0.1305 0.1300 

[TRAIN] Epoch[3](548/1500); Loss: 0.155882; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1940 0.1899 0.1836 0.1633 0.1515 0.1453 0.1445 0.1486 0.1458 0.1462 0.1470 0.1469 0.1476 0.1462 0.1466 0.1469 

[TRAIN] Epoch[3](549/1500); Loss: 0.091861; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1277 0.1200 0.1112 0.0968 0.0926 0.0927 0.0885 0.0848 0.0834 0.0830 0.0819 0.0804 0.0813 0.0816 0.0815 0.0821 

[TRAIN] Epoch[3](550/1500); Loss: 0.100594; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1437 0.1415 0.1391 0.1190 0.1108 0.1032 0.0912 0.0875 0.0865 0.0870 0.0839 0.0832 0.0832 0.0828 0.0830 0.0839 

[TRAIN] Epoch[3](551/1500); Loss: 0.083325; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1131 0.1075 0.1011 0.0879 0.0831 0.0813 0.0785 0.0770 0.0762 0.0758 0.0754 0.0751 0.0753 0.0754 0.0752 0.0754 

[TRAIN] Epoch[3](552/1500); Loss: 0.126426; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2110 0.2013 0.1853 0.1628 0.1463 0.1376 0.1269 0.1080 0.0968 0.0931 0.0939 0.0952 0.0916 0.0896 0.0908 0.0926 

[TRAIN] Epoch[3](553/1500); Loss: 0.138874; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1680 0.1617 0.1535 0.1487 0.1466 0.1423 0.1371 0.1343 0.1313 0.1302 0.1289 0.1281 0.1281 0.1281 0.1275 0.1276 

[TRAIN] Epoch[3](554/1500); Loss: 0.067426; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1141 0.0984 0.0858 0.0706 0.0608 0.0598 0.0633 0.0620 0.0576 0.0570 0.0573 0.0574 0.0585 0.0582 0.0583 0.0595 

[TRAIN] Epoch[3](555/1500); Loss: 0.069326; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1024 0.1082 0.1153 0.0827 0.0687 0.0710 0.0660 0.0574 0.0549 0.0554 0.0555 0.0536 0.0543 0.0550 0.0540 0.0548 

[TRAIN] Epoch[3](556/1500); Loss: 0.051273; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.0840 0.0644 0.0627 0.0583 0.0525 0.0455 0.0437 0.0433 0.0447 0.0454 0.0439 0.0453 0.0456 0.0456 0.0474 0.0481 

[TRAIN] Epoch[3](557/1500); Loss: 0.106885; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1893 0.1771 0.1424 0.1259 0.1054 0.0959 0.0915 0.0895 0.0882 0.0879 0.0865 0.0862 0.0861 0.0854 0.0863 0.0865 

[TRAIN] Epoch[3](558/1500); Loss: 0.059490; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0879 0.0838 0.0835 0.0676 0.0559 0.0516 0.0562 0.0532 0.0503 0.0502 0.0511 0.0505 0.0512 0.0524 0.0527 0.0538 

[TRAIN] Epoch[3](559/1500); Loss: 0.168454; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1951 0.1971 0.1914 0.1786 0.1707 0.1670 0.1637 0.1613 0.1595 0.1585 0.1592 0.1580 0.1579 0.1586 0.1592 0.1595 

[TRAIN] Epoch[3](560/1500); Loss: 0.145359; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.3123 0.2862 0.2578 0.2292 0.2047 0.1792 0.1527 0.1260 0.1012 0.0799 0.0659 0.0646 0.0718 0.0677 0.0635 0.0631 

[TRAIN] Epoch[3](561/1500); Loss: 0.124910; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1680 0.1564 0.1386 0.1294 0.1223 0.1181 0.1157 0.1140 0.1145 0.1145 0.1150 0.1154 0.1168 0.1186 0.1198 0.1214 

[TRAIN] Epoch[3](562/1500); Loss: 0.157075; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1897 0.1800 0.1706 0.1585 0.1481 0.1432 0.1418 0.1409 0.1433 0.1464 0.1502 0.1558 0.1586 0.1599 0.1616 0.1644 

[TRAIN] Epoch[3](563/1500); Loss: 0.064647; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0894 0.0860 0.0844 0.0727 0.0620 0.0587 0.0583 0.0569 0.0571 0.0570 0.0566 0.0572 0.0585 0.0584 0.0593 0.0617 

[TRAIN] Epoch[3](564/1500); Loss: 0.137214; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2124 0.1915 0.1708 0.1512 0.1343 0.1240 0.1199 0.1201 0.1208 0.1193 0.1202 0.1217 0.1216 0.1216 0.1224 0.1235 

[TRAIN] Epoch[3](565/1500); Loss: 0.223565; Backpropagation: 0.0919 sec; Batch: 0.4267 sec
0.4010 0.3654 0.3265 0.2916 0.2585 0.2265 0.1952 0.1692 0.1579 0.1635 0.1730 0.1714 0.1681 0.1690 0.1689 0.1713 

[TRAIN] Epoch[3](566/1500); Loss: 0.138204; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2010 0.1820 0.1586 0.1449 0.1364 0.1305 0.1264 0.1256 0.1259 0.1249 0.1248 0.1248 0.1253 0.1259 0.1268 0.1276 

[TRAIN] Epoch[3](567/1500); Loss: 0.076024; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1559 0.1335 0.1095 0.0876 0.0771 0.0731 0.0690 0.0607 0.0559 0.0561 0.0550 0.0549 0.0565 0.0569 0.0564 0.0583 

[TRAIN] Epoch[3](568/1500); Loss: 0.072180; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0873 0.0887 0.0945 0.0822 0.0744 0.0689 0.0669 0.0681 0.0661 0.0650 0.0653 0.0652 0.0650 0.0657 0.0657 0.0659 

[TRAIN] Epoch[3](569/1500); Loss: 0.115710; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1247 0.1226 0.1188 0.1149 0.1136 0.1137 0.1117 0.1111 0.1114 0.1123 0.1134 0.1143 0.1153 0.1165 0.1178 0.1192 

[TRAIN] Epoch[3](570/1500); Loss: 0.110297; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1381 0.1335 0.1216 0.1109 0.1104 0.1085 0.1021 0.1035 0.1037 0.1036 0.1036 0.1040 0.1041 0.1047 0.1058 0.1069 

[TRAIN] Epoch[3](571/1500); Loss: 0.070324; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1333 0.1133 0.0959 0.0835 0.0711 0.0630 0.0583 0.0573 0.0560 0.0555 0.0553 0.0557 0.0559 0.0564 0.0573 0.0576 

[TRAIN] Epoch[3](572/1500); Loss: 0.174918; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2205 0.2080 0.1999 0.1840 0.1723 0.1664 0.1668 0.1672 0.1630 0.1620 0.1624 0.1633 0.1658 0.1656 0.1653 0.1661 

[TRAIN] Epoch[3](573/1500); Loss: 0.099715; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1445 0.1365 0.1218 0.1063 0.0991 0.0968 0.0911 0.0897 0.0886 0.0877 0.0880 0.0880 0.0886 0.0890 0.0896 0.0901 

[TRAIN] Epoch[3](574/1500); Loss: 0.069339; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0725 0.0765 0.0743 0.0654 0.0614 0.0635 0.0645 0.0654 0.0658 0.0671 0.0684 0.0699 0.0708 0.0729 0.0748 0.0760 

[TRAIN] Epoch[3](575/1500); Loss: 0.122089; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1689 0.1575 0.1414 0.1324 0.1278 0.1231 0.1153 0.1108 0.1092 0.1099 0.1102 0.1092 0.1089 0.1091 0.1096 0.1102 

[TRAIN] Epoch[3](576/1500); Loss: 0.071896; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1139 0.1057 0.0916 0.0772 0.0747 0.0694 0.0653 0.0635 0.0617 0.0615 0.0613 0.0603 0.0606 0.0612 0.0611 0.0615 

[TRAIN] Epoch[3](577/1500); Loss: 0.121864; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1822 0.1686 0.1542 0.1376 0.1257 0.1182 0.1140 0.1099 0.1078 0.1066 0.1053 0.1040 0.1034 0.1036 0.1039 0.1049 

[TRAIN] Epoch[3](578/1500); Loss: 0.051749; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1039 0.0828 0.0690 0.0573 0.0499 0.0461 0.0411 0.0393 0.0400 0.0394 0.0403 0.0412 0.0422 0.0432 0.0454 0.0470 

[TRAIN] Epoch[3](579/1500); Loss: 0.151659; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1764 0.1749 0.1665 0.1569 0.1531 0.1512 0.1475 0.1452 0.1446 0.1446 0.1448 0.1443 0.1432 0.1440 0.1446 0.1448 

[TRAIN] Epoch[3](580/1500); Loss: 0.081012; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1353 0.1194 0.1019 0.0861 0.0785 0.0741 0.0724 0.0715 0.0711 0.0703 0.0693 0.0694 0.0691 0.0694 0.0690 0.0693 

[TRAIN] Epoch[3](581/1500); Loss: 0.149386; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1631 0.1592 0.1520 0.1506 0.1498 0.1477 0.1468 0.1467 0.1464 0.1466 0.1468 0.1467 0.1467 0.1468 0.1470 0.1472 

[TRAIN] Epoch[3](582/1500); Loss: 0.050283; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1289 0.1130 0.0639 0.0460 0.0380 0.0415 0.0476 0.0356 0.0349 0.0349 0.0352 0.0355 0.0363 0.0372 0.0375 0.0385 

[TRAIN] Epoch[3](583/1500); Loss: 0.126774; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1550 0.1506 0.1363 0.1284 0.1251 0.1241 0.1239 0.1218 0.1200 0.1201 0.1202 0.1199 0.1199 0.1206 0.1208 0.1216 

[TRAIN] Epoch[3](584/1500); Loss: 0.127935; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1838 0.1758 0.1643 0.1474 0.1343 0.1278 0.1246 0.1173 0.1108 0.1091 0.1093 0.1103 0.1078 0.1080 0.1076 0.1087 

[TRAIN] Epoch[3](585/1500); Loss: 0.153267; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2021 0.1942 0.1664 0.1582 0.1536 0.1520 0.1483 0.1452 0.1428 0.1419 0.1419 0.1408 0.1406 0.1407 0.1415 0.1422 

[TRAIN] Epoch[3](586/1500); Loss: 0.075355; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1430 0.1446 0.1542 0.1107 0.0772 0.0624 0.0550 0.0551 0.0515 0.0491 0.0497 0.0509 0.0503 0.0501 0.0507 0.0511 

[TRAIN] Epoch[3](587/1500); Loss: 0.080115; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1331 0.1155 0.0995 0.0852 0.0791 0.0760 0.0736 0.0714 0.0688 0.0699 0.0692 0.0679 0.0678 0.0683 0.0681 0.0685 

[TRAIN] Epoch[3](588/1500); Loss: 0.117397; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2559 0.2231 0.1862 0.1530 0.1232 0.0967 0.0847 0.0925 0.0843 0.0845 0.0829 0.0814 0.0815 0.0826 0.0826 0.0833 

[TRAIN] Epoch[3](589/1500); Loss: 0.152827; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1991 0.1900 0.1737 0.1622 0.1554 0.1511 0.1465 0.1450 0.1423 0.1408 0.1406 0.1406 0.1400 0.1392 0.1390 0.1397 

[TRAIN] Epoch[3](590/1500); Loss: 0.071803; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0995 0.0899 0.0778 0.0711 0.0727 0.0689 0.0681 0.0671 0.0661 0.0660 0.0662 0.0661 0.0663 0.0667 0.0674 0.0690 

[TRAIN] Epoch[3](591/1500); Loss: 0.159395; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1726 0.1738 0.1776 0.1710 0.1619 0.1591 0.1561 0.1544 0.1564 0.1547 0.1519 0.1526 0.1524 0.1521 0.1517 0.1523 

[TRAIN] Epoch[3](592/1500); Loss: 0.073529; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1055 0.0886 0.0772 0.0767 0.0697 0.0723 0.0699 0.0670 0.0669 0.0686 0.0671 0.0679 0.0683 0.0697 0.0699 0.0712 

[TRAIN] Epoch[3](593/1500); Loss: 0.077924; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1248 0.1194 0.1148 0.0947 0.0827 0.0719 0.0675 0.0652 0.0645 0.0638 0.0631 0.0626 0.0625 0.0630 0.0632 0.0632 

[TRAIN] Epoch[3](594/1500); Loss: 0.109340; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1796 0.1619 0.1410 0.1240 0.1159 0.1053 0.0983 0.0927 0.0901 0.0901 0.0909 0.0913 0.0912 0.0915 0.0925 0.0932 

[TRAIN] Epoch[3](595/1500); Loss: 0.071110; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1485 0.1269 0.1005 0.0794 0.0646 0.0570 0.0597 0.0584 0.0544 0.0536 0.0543 0.0564 0.0566 0.0552 0.0558 0.0565 

[TRAIN] Epoch[3](596/1500); Loss: 0.060301; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0998 0.0795 0.0646 0.0625 0.0589 0.0575 0.0549 0.0549 0.0551 0.0533 0.0527 0.0527 0.0541 0.0533 0.0544 0.0565 

[TRAIN] Epoch[3](597/1500); Loss: 0.101496; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1514 0.1347 0.1199 0.1102 0.1041 0.0989 0.0950 0.0920 0.0913 0.0905 0.0902 0.0890 0.0890 0.0892 0.0894 0.0893 

[TRAIN] Epoch[3](598/1500); Loss: 0.078946; Backpropagation: 0.0917 sec; Batch: 0.4225 sec
0.1429 0.1230 0.0989 0.0840 0.0768 0.0709 0.0686 0.0684 0.0665 0.0658 0.0659 0.0655 0.0659 0.0664 0.0667 0.0669 

[TRAIN] Epoch[3](599/1500); Loss: 0.122104; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1778 0.1635 0.1486 0.1326 0.1206 0.1150 0.1130 0.1111 0.1089 0.1083 0.1084 0.1091 0.1086 0.1094 0.1094 0.1095 

[TRAIN] Epoch[3](600/1500); Loss: 0.105943; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1385 0.1266 0.1157 0.1082 0.1051 0.1026 0.1008 0.1002 0.1001 0.0996 0.0996 0.0994 0.0995 0.0995 0.0997 0.1000 

[TRAIN] Epoch[3](601/1500); Loss: 0.056336; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1518 0.1305 0.0825 0.0611 0.0490 0.0443 0.0417 0.0369 0.0361 0.0360 0.0365 0.0360 0.0380 0.0402 0.0401 0.0408 

[TRAIN] Epoch[3](602/1500); Loss: 0.135487; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1522 0.1503 0.1620 0.1493 0.1391 0.1312 0.1293 0.1311 0.1290 0.1281 0.1277 0.1272 0.1274 0.1277 0.1280 0.1283 

[TRAIN] Epoch[3](603/1500); Loss: 0.102428; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1146 0.1182 0.1104 0.1055 0.1076 0.1016 0.1023 0.0998 0.0969 0.0968 0.0974 0.0972 0.0971 0.0976 0.0981 0.0977 

[TRAIN] Epoch[3](604/1500); Loss: 0.116191; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1461 0.1405 0.1292 0.1205 0.1152 0.1127 0.1119 0.1101 0.1097 0.1093 0.1089 0.1088 0.1086 0.1089 0.1091 0.1095 

[TRAIN] Epoch[3](605/1500); Loss: 0.139731; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1942 0.1760 0.1574 0.1455 0.1410 0.1350 0.1313 0.1290 0.1292 0.1287 0.1279 0.1274 0.1278 0.1280 0.1285 0.1289 

[TRAIN] Epoch[3](606/1500); Loss: 0.140838; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1733 0.1648 0.1532 0.1437 0.1413 0.1396 0.1371 0.1350 0.1342 0.1337 0.1333 0.1330 0.1328 0.1327 0.1327 0.1332 

[TRAIN] Epoch[3](607/1500); Loss: 0.063273; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1213 0.0994 0.0781 0.0658 0.0588 0.0553 0.0563 0.0536 0.0528 0.0530 0.0529 0.0528 0.0526 0.0530 0.0532 0.0534 

[TRAIN] Epoch[3](608/1500); Loss: 0.139494; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2359 0.2171 0.2055 0.1798 0.1582 0.1395 0.1282 0.1173 0.1085 0.1072 0.1051 0.1067 0.1055 0.1042 0.1049 0.1083 

[TRAIN] Epoch[3](609/1500); Loss: 0.113881; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1780 0.1569 0.1343 0.1190 0.1118 0.1069 0.1056 0.1028 0.1014 0.1009 0.1007 0.1008 0.1007 0.1004 0.1007 0.1013 

[TRAIN] Epoch[3](610/1500); Loss: 0.097043; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1136 0.1103 0.1085 0.1004 0.0952 0.0945 0.0939 0.0935 0.0927 0.0926 0.0927 0.0925 0.0927 0.0929 0.0932 0.0936 

[TRAIN] Epoch[3](611/1500); Loss: 0.122612; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.3520 0.3059 0.2485 0.2050 0.1667 0.1238 0.0824 0.0579 0.0566 0.0556 0.0507 0.0507 0.0484 0.0494 0.0550 0.0532 

[TRAIN] Epoch[3](612/1500); Loss: 0.182491; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.4840 0.4314 0.3610 0.3001 0.2423 0.1820 0.1224 0.0822 0.0735 0.0974 0.0885 0.0791 0.0808 0.0855 0.0998 0.1099 

[TRAIN] Epoch[3](613/1500); Loss: 0.104925; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1506 0.1446 0.1246 0.1131 0.1091 0.1038 0.0998 0.0967 0.0942 0.0944 0.0928 0.0914 0.0913 0.0911 0.0907 0.0906 

[TRAIN] Epoch[3](614/1500); Loss: 0.114397; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1996 0.1862 0.1551 0.1341 0.1156 0.1042 0.0999 0.0942 0.0931 0.0927 0.0928 0.0928 0.0922 0.0922 0.0925 0.0932 

[TRAIN] Epoch[3](615/1500); Loss: 0.099246; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1518 0.1358 0.1192 0.1021 0.0950 0.0916 0.0921 0.0885 0.0859 0.0866 0.0897 0.0900 0.0881 0.0890 0.0911 0.0914 

[TRAIN] Epoch[3](616/1500); Loss: 0.111766; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1526 0.1440 0.1287 0.1156 0.1068 0.1040 0.1048 0.1037 0.1023 0.1023 0.1030 0.1036 0.1030 0.1035 0.1051 0.1055 

[TRAIN] Epoch[3](617/1500); Loss: 0.156654; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1672 0.1654 0.1581 0.1564 0.1624 0.1602 0.1551 0.1542 0.1544 0.1549 0.1550 0.1534 0.1532 0.1531 0.1519 0.1515 

[TRAIN] Epoch[3](618/1500); Loss: 0.118796; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1511 0.1452 0.1349 0.1224 0.1164 0.1115 0.1106 0.1088 0.1099 0.1098 0.1098 0.1112 0.1123 0.1134 0.1158 0.1177 

[TRAIN] Epoch[3](619/1500); Loss: 0.114088; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2791 0.2442 0.1977 0.1570 0.1219 0.0943 0.0807 0.0817 0.0767 0.0715 0.0698 0.0686 0.0701 0.0728 0.0696 0.0698 

[TRAIN] Epoch[3](620/1500); Loss: 0.107711; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2104 0.1899 0.1532 0.1342 0.1183 0.1005 0.0870 0.0831 0.0874 0.0819 0.0799 0.0793 0.0797 0.0796 0.0795 0.0794 

[TRAIN] Epoch[3](621/1500); Loss: 0.122302; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1823 0.1721 0.1273 0.1157 0.1199 0.1150 0.1132 0.1115 0.1114 0.1153 0.1124 0.1105 0.1112 0.1128 0.1126 0.1137 

[TRAIN] Epoch[3](622/1500); Loss: 0.077334; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0981 0.0970 0.0873 0.0771 0.0733 0.0742 0.0731 0.0721 0.0716 0.0722 0.0723 0.0724 0.0733 0.0740 0.0742 0.0749 

[TRAIN] Epoch[3](623/1500); Loss: 0.071018; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1094 0.1043 0.0861 0.0733 0.0695 0.0676 0.0635 0.0626 0.0619 0.0619 0.0620 0.0623 0.0627 0.0623 0.0629 0.0640 

[TRAIN] Epoch[3](624/1500); Loss: 0.062424; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0990 0.0894 0.0722 0.0644 0.0629 0.0574 0.0574 0.0552 0.0553 0.0560 0.0548 0.0546 0.0545 0.0548 0.0550 0.0558 

[TRAIN] Epoch[3](625/1500); Loss: 0.057763; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1104 0.0979 0.0865 0.0648 0.0496 0.0487 0.0488 0.0461 0.0447 0.0450 0.0457 0.0459 0.0463 0.0478 0.0477 0.0484 

[TRAIN] Epoch[3](626/1500); Loss: 0.122147; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2331 0.2196 0.1947 0.1712 0.1593 0.1374 0.1160 0.0994 0.0847 0.0755 0.0769 0.0777 0.0777 0.0773 0.0766 0.0773 

[TRAIN] Epoch[3](627/1500); Loss: 0.079793; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1158 0.1162 0.1125 0.0911 0.0824 0.0767 0.0725 0.0696 0.0679 0.0666 0.0666 0.0674 0.0680 0.0672 0.0679 0.0684 

[TRAIN] Epoch[3](628/1500); Loss: 0.056274; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1128 0.0989 0.0917 0.0656 0.0493 0.0442 0.0482 0.0451 0.0436 0.0422 0.0414 0.0434 0.0431 0.0430 0.0439 0.0438 

[TRAIN] Epoch[3](629/1500); Loss: 0.091892; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1383 0.1229 0.1082 0.0933 0.0892 0.0859 0.0834 0.0832 0.0830 0.0826 0.0824 0.0828 0.0833 0.0836 0.0838 0.0843 

[TRAIN] Epoch[3](630/1500); Loss: 0.048775; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0755 0.0803 0.0674 0.0516 0.0590 0.0499 0.0430 0.0401 0.0387 0.0393 0.0402 0.0377 0.0382 0.0390 0.0403 0.0403 

[TRAIN] Epoch[3](631/1500); Loss: 0.078780; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1325 0.1247 0.0927 0.0794 0.0711 0.0702 0.0688 0.0688 0.0684 0.0684 0.0685 0.0686 0.0690 0.0695 0.0700 0.0701 

[TRAIN] Epoch[3](632/1500); Loss: 0.152708; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1872 0.1790 0.1578 0.1533 0.1520 0.1498 0.1479 0.1475 0.1468 0.1461 0.1454 0.1454 0.1456 0.1462 0.1464 0.1468 

[TRAIN] Epoch[3](633/1500); Loss: 0.081622; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1812 0.1706 0.0870 0.0804 0.0752 0.0679 0.0648 0.0643 0.0639 0.0632 0.0634 0.0644 0.0636 0.0640 0.0656 0.0663 

[TRAIN] Epoch[3](634/1500); Loss: 0.173313; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2635 0.2482 0.2291 0.2110 0.1974 0.1836 0.1701 0.1575 0.1474 0.1403 0.1380 0.1385 0.1373 0.1378 0.1370 0.1362 

[TRAIN] Epoch[3](635/1500); Loss: 0.153819; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1724 0.1677 0.1606 0.1577 0.1555 0.1542 0.1525 0.1509 0.1495 0.1485 0.1484 0.1482 0.1482 0.1484 0.1490 0.1493 

[TRAIN] Epoch[3](636/1500); Loss: 0.085718; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1244 0.1211 0.1103 0.0992 0.0905 0.0829 0.0794 0.0757 0.0728 0.0728 0.0734 0.0718 0.0735 0.0747 0.0738 0.0752 

[TRAIN] Epoch[3](637/1500); Loss: 0.110794; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1279 0.1281 0.1213 0.1120 0.1162 0.1105 0.1089 0.1074 0.1062 0.1058 0.1052 0.1048 0.1047 0.1042 0.1046 0.1049 

[TRAIN] Epoch[3](638/1500); Loss: 0.119369; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1691 0.1574 0.1465 0.1306 0.1178 0.1144 0.1137 0.1085 0.1060 0.1059 0.1070 0.1065 0.1063 0.1066 0.1066 0.1070 

[TRAIN] Epoch[3](639/1500); Loss: 0.123716; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2617 0.2393 0.1688 0.1505 0.1389 0.1245 0.1088 0.0980 0.0893 0.0856 0.0859 0.0853 0.0857 0.0855 0.0851 0.0865 

[TRAIN] Epoch[3](640/1500); Loss: 0.090962; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1300 0.1133 0.1026 0.0957 0.0895 0.0859 0.0835 0.0835 0.0843 0.0832 0.0828 0.0835 0.0837 0.0842 0.0847 0.0852 

[TRAIN] Epoch[3](641/1500); Loss: 0.074471; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1286 0.1213 0.0926 0.0773 0.0704 0.0682 0.0653 0.0638 0.0631 0.0628 0.0628 0.0624 0.0628 0.0635 0.0632 0.0634 

[TRAIN] Epoch[3](642/1500); Loss: 0.123252; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1610 0.1552 0.1316 0.1257 0.1203 0.1187 0.1175 0.1166 0.1159 0.1157 0.1156 0.1156 0.1153 0.1155 0.1157 0.1161 

[TRAIN] Epoch[3](643/1500); Loss: 0.067807; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0716 0.0722 0.0738 0.0660 0.0625 0.0609 0.0638 0.0654 0.0639 0.0651 0.0666 0.0675 0.0687 0.0704 0.0721 0.0743 

[TRAIN] Epoch[3](644/1500); Loss: 0.134244; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1992 0.1804 0.1614 0.1483 0.1385 0.1317 0.1267 0.1223 0.1189 0.1171 0.1162 0.1166 0.1172 0.1175 0.1179 0.1182 

[TRAIN] Epoch[3](645/1500); Loss: 0.068540; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0969 0.0915 0.0857 0.0743 0.0695 0.0676 0.0652 0.0634 0.0618 0.0606 0.0600 0.0596 0.0597 0.0599 0.0603 0.0604 

[TRAIN] Epoch[3](646/1500); Loss: 0.128161; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1720 0.1613 0.1486 0.1368 0.1314 0.1297 0.1229 0.1206 0.1191 0.1174 0.1158 0.1152 0.1149 0.1148 0.1150 0.1150 

[TRAIN] Epoch[3](647/1500); Loss: 0.154248; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2167 0.1984 0.1804 0.1711 0.1620 0.1528 0.1467 0.1422 0.1414 0.1400 0.1390 0.1373 0.1359 0.1350 0.1347 0.1343 

[TRAIN] Epoch[3](648/1500); Loss: 0.168208; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2174 0.2020 0.1831 0.1736 0.1682 0.1627 0.1601 0.1602 0.1593 0.1586 0.1578 0.1579 0.1576 0.1577 0.1575 0.1577 

[TRAIN] Epoch[3](649/1500); Loss: 0.069383; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1081 0.0964 0.0870 0.0757 0.0729 0.0660 0.0633 0.0615 0.0609 0.0601 0.0594 0.0598 0.0594 0.0595 0.0601 0.0600 

[TRAIN] Epoch[3](650/1500); Loss: 0.069022; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1381 0.1286 0.1170 0.0864 0.0604 0.0525 0.0524 0.0503 0.0471 0.0484 0.0513 0.0520 0.0530 0.0537 0.0560 0.0572 

[TRAIN] Epoch[3](651/1500); Loss: 0.061988; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.0812 0.0870 0.1063 0.0778 0.0601 0.0509 0.0549 0.0532 0.0514 0.0490 0.0514 0.0545 0.0516 0.0522 0.0541 0.0564 

[TRAIN] Epoch[3](652/1500); Loss: 0.123489; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1541 0.1474 0.1347 0.1275 0.1237 0.1206 0.1193 0.1181 0.1178 0.1165 0.1165 0.1158 0.1157 0.1160 0.1160 0.1161 

[TRAIN] Epoch[3](653/1500); Loss: 0.076727; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1130 0.1087 0.1024 0.0840 0.0758 0.0710 0.0665 0.0658 0.0668 0.0666 0.0673 0.0671 0.0677 0.0681 0.0684 0.0684 

[TRAIN] Epoch[3](654/1500); Loss: 0.087950; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1494 0.1410 0.0976 0.0886 0.0810 0.0787 0.0777 0.0777 0.0776 0.0767 0.0766 0.0765 0.0764 0.0769 0.0773 0.0775 

[TRAIN] Epoch[3](655/1500); Loss: 0.077029; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1593 0.1306 0.1037 0.0849 0.0736 0.0658 0.0650 0.0634 0.0625 0.0617 0.0610 0.0610 0.0603 0.0603 0.0599 0.0596 

[TRAIN] Epoch[3](656/1500); Loss: 0.055620; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1384 0.1328 0.0437 0.0505 0.0563 0.0425 0.0422 0.0422 0.0415 0.0423 0.0425 0.0421 0.0424 0.0429 0.0435 0.0442 

[TRAIN] Epoch[3](657/1500); Loss: 0.143881; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2136 0.1975 0.1788 0.1614 0.1498 0.1402 0.1306 0.1246 0.1244 0.1253 0.1256 0.1254 0.1252 0.1260 0.1266 0.1268 

[TRAIN] Epoch[3](658/1500); Loss: 0.065974; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1330 0.1123 0.0898 0.0696 0.0589 0.0578 0.0595 0.0561 0.0528 0.0521 0.0530 0.0524 0.0516 0.0517 0.0528 0.0524 

[TRAIN] Epoch[3](659/1500); Loss: 0.080256; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1254 0.1175 0.1046 0.0914 0.0835 0.0758 0.0722 0.0705 0.0694 0.0684 0.0676 0.0671 0.0675 0.0677 0.0677 0.0679 

[TRAIN] Epoch[3](660/1500); Loss: 0.115643; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1491 0.1403 0.1274 0.1193 0.1141 0.1112 0.1105 0.1097 0.1084 0.1083 0.1082 0.1081 0.1084 0.1088 0.1092 0.1093 

[TRAIN] Epoch[3](661/1500); Loss: 0.070252; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1400 0.1263 0.0764 0.0714 0.0647 0.0615 0.0597 0.0584 0.0581 0.0570 0.0570 0.0577 0.0580 0.0584 0.0590 0.0605 

[TRAIN] Epoch[3](662/1500); Loss: 0.083371; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1292 0.1194 0.0943 0.0865 0.0824 0.0804 0.0778 0.0764 0.0758 0.0744 0.0736 0.0737 0.0732 0.0722 0.0722 0.0725 

[TRAIN] Epoch[3](663/1500); Loss: 0.098471; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1967 0.1803 0.1205 0.1099 0.0971 0.0879 0.0832 0.0805 0.0805 0.0818 0.0768 0.0768 0.0765 0.0752 0.0754 0.0765 

[TRAIN] Epoch[3](664/1500); Loss: 0.105531; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1650 0.1541 0.1463 0.1195 0.0982 0.0923 0.0921 0.0904 0.0907 0.0892 0.0900 0.0908 0.0916 0.0917 0.0927 0.0939 

[TRAIN] Epoch[3](665/1500); Loss: 0.102880; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1445 0.1456 0.1288 0.1174 0.1067 0.1001 0.0958 0.0929 0.0909 0.0892 0.0888 0.0880 0.0885 0.0888 0.0898 0.0902 

[TRAIN] Epoch[3](666/1500); Loss: 0.110310; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1300 0.1279 0.1269 0.1154 0.1103 0.1075 0.1076 0.1056 0.1035 0.1040 0.1047 0.1036 0.1037 0.1041 0.1047 0.1054 

[TRAIN] Epoch[3](667/1500); Loss: 0.095103; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1236 0.1195 0.1044 0.0984 0.0927 0.0909 0.0898 0.0898 0.0889 0.0885 0.0887 0.0886 0.0889 0.0891 0.0898 0.0900 

[TRAIN] Epoch[3](668/1500); Loss: 0.130070; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1688 0.1634 0.1568 0.1429 0.1326 0.1252 0.1222 0.1204 0.1191 0.1182 0.1183 0.1181 0.1182 0.1181 0.1191 0.1198 

[TRAIN] Epoch[3](669/1500); Loss: 0.093981; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1746 0.1621 0.1203 0.1055 0.0967 0.0872 0.0820 0.0796 0.0774 0.0770 0.0752 0.0740 0.0732 0.0731 0.0731 0.0726 

[TRAIN] Epoch[3](670/1500); Loss: 0.079301; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1063 0.1038 0.0889 0.0809 0.0766 0.0731 0.0732 0.0724 0.0723 0.0725 0.0733 0.0733 0.0740 0.0751 0.0757 0.0772 

[TRAIN] Epoch[3](671/1500); Loss: 0.139794; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2116 0.1928 0.1629 0.1511 0.1438 0.1366 0.1315 0.1275 0.1240 0.1232 0.1229 0.1221 0.1220 0.1217 0.1215 0.1215 

[TRAIN] Epoch[3](672/1500); Loss: 0.135083; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1770 0.1642 0.1523 0.1437 0.1388 0.1342 0.1313 0.1279 0.1265 0.1258 0.1238 0.1237 0.1231 0.1232 0.1227 0.1231 

[TRAIN] Epoch[3](673/1500); Loss: 0.132909; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1674 0.1595 0.1492 0.1404 0.1365 0.1313 0.1290 0.1271 0.1261 0.1247 0.1239 0.1232 0.1228 0.1223 0.1217 0.1214 

[TRAIN] Epoch[3](674/1500); Loss: 0.069032; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0825 0.0884 0.0846 0.0680 0.0702 0.0686 0.0631 0.0626 0.0617 0.0624 0.0648 0.0639 0.0642 0.0652 0.0671 0.0672 

[TRAIN] Epoch[3](675/1500); Loss: 0.109391; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.2102 0.1969 0.1052 0.1094 0.1067 0.1008 0.0961 0.0957 0.0912 0.0927 0.0916 0.0902 0.0913 0.0901 0.0911 0.0913 

[TRAIN] Epoch[3](676/1500); Loss: 0.079457; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1231 0.1149 0.0879 0.0805 0.0780 0.0739 0.0726 0.0718 0.0711 0.0708 0.0703 0.0705 0.0710 0.0710 0.0716 0.0722 

[TRAIN] Epoch[3](677/1500); Loss: 0.113129; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2076 0.1895 0.1508 0.1343 0.1191 0.1068 0.1005 0.0943 0.0914 0.0894 0.0863 0.0880 0.0885 0.0875 0.0875 0.0886 

[TRAIN] Epoch[3](678/1500); Loss: 0.071314; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1211 0.1046 0.0902 0.0792 0.0741 0.0690 0.0659 0.0625 0.0602 0.0592 0.0588 0.0589 0.0587 0.0593 0.0596 0.0599 

[TRAIN] Epoch[3](679/1500); Loss: 0.095238; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1453 0.1310 0.1092 0.1000 0.0958 0.0927 0.0908 0.0879 0.0857 0.0844 0.0837 0.0831 0.0833 0.0832 0.0835 0.0843 

[TRAIN] Epoch[3](680/1500); Loss: 0.097225; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1173 0.1131 0.0983 0.0957 0.0956 0.0940 0.0939 0.0933 0.0933 0.0934 0.0937 0.0939 0.0941 0.0948 0.0955 0.0958 

[TRAIN] Epoch[3](681/1500); Loss: 0.128341; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.3193 0.2745 0.2204 0.1812 0.1499 0.1232 0.1026 0.0865 0.0761 0.0741 0.0755 0.0745 0.0731 0.0727 0.0749 0.0751 

[TRAIN] Epoch[3](682/1500); Loss: 0.101990; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1586 0.1408 0.1242 0.1177 0.1117 0.1038 0.0966 0.0915 0.0881 0.0862 0.0850 0.0848 0.0853 0.0851 0.0857 0.0868 

[TRAIN] Epoch[3](683/1500); Loss: 0.130590; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1512 0.1450 0.1357 0.1326 0.1313 0.1294 0.1276 0.1266 0.1261 0.1259 0.1259 0.1259 0.1260 0.1264 0.1267 0.1271 

[TRAIN] Epoch[3](684/1500); Loss: 0.107084; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1646 0.1511 0.1379 0.1168 0.1037 0.0995 0.0985 0.0961 0.0944 0.0932 0.0926 0.0925 0.0927 0.0930 0.0934 0.0933 

[TRAIN] Epoch[3](685/1500); Loss: 0.142622; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1654 0.1568 0.1468 0.1430 0.1420 0.1405 0.1397 0.1388 0.1383 0.1385 0.1383 0.1383 0.1384 0.1385 0.1391 0.1397 

[TRAIN] Epoch[3](686/1500); Loss: 0.070317; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0951 0.0961 0.0930 0.0785 0.0703 0.0634 0.0619 0.0626 0.0623 0.0624 0.0619 0.0625 0.0627 0.0630 0.0643 0.0650 

[TRAIN] Epoch[3](687/1500); Loss: 0.079280; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1325 0.1252 0.0955 0.0812 0.0725 0.0707 0.0704 0.0691 0.0681 0.0682 0.0688 0.0684 0.0688 0.0693 0.0697 0.0701 

[TRAIN] Epoch[3](688/1500); Loss: 0.089844; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1232 0.1174 0.1075 0.0966 0.0893 0.0843 0.0827 0.0828 0.0823 0.0819 0.0813 0.0817 0.0818 0.0818 0.0813 0.0816 

[TRAIN] Epoch[3](689/1500); Loss: 0.073051; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1148 0.1143 0.0953 0.0857 0.0763 0.0712 0.0667 0.0645 0.0630 0.0609 0.0605 0.0596 0.0592 0.0590 0.0589 0.0590 

[TRAIN] Epoch[3](690/1500); Loss: 0.108428; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1444 0.1362 0.1298 0.1148 0.1061 0.1034 0.1030 0.1010 0.1001 0.0998 0.0999 0.0996 0.0993 0.0990 0.0991 0.0993 

[TRAIN] Epoch[3](691/1500); Loss: 0.114842; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1617 0.1551 0.1452 0.1299 0.1192 0.1114 0.1079 0.1022 0.1011 0.1014 0.1002 0.0995 0.1004 0.1008 0.1006 0.1010 

[TRAIN] Epoch[3](692/1500); Loss: 0.090654; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1405 0.1292 0.1050 0.0946 0.0887 0.0867 0.0851 0.0833 0.0818 0.0808 0.0802 0.0794 0.0791 0.0789 0.0785 0.0787 

[TRAIN] Epoch[3](693/1500); Loss: 0.093127; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1364 0.1314 0.0998 0.0948 0.0920 0.0893 0.0875 0.0864 0.0851 0.0845 0.0840 0.0836 0.0837 0.0836 0.0837 0.0841 

[TRAIN] Epoch[3](694/1500); Loss: 0.150500; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2180 0.2064 0.1875 0.1761 0.1672 0.1593 0.1510 0.1426 0.1350 0.1287 0.1243 0.1231 0.1233 0.1225 0.1219 0.1213 

[TRAIN] Epoch[3](695/1500); Loss: 0.075421; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1222 0.1089 0.1039 0.0884 0.0754 0.0695 0.0714 0.0652 0.0624 0.0623 0.0622 0.0623 0.0626 0.0632 0.0633 0.0633 

[TRAIN] Epoch[3](696/1500); Loss: 0.106728; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2483 0.2081 0.1646 0.1341 0.1124 0.0956 0.0847 0.0783 0.0749 0.0740 0.0731 0.0722 0.0722 0.0719 0.0716 0.0716 

[TRAIN] Epoch[3](697/1500); Loss: 0.132521; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1869 0.1770 0.1476 0.1370 0.1313 0.1271 0.1241 0.1223 0.1201 0.1203 0.1210 0.1212 0.1208 0.1206 0.1211 0.1219 

[TRAIN] Epoch[3](698/1500); Loss: 0.069683; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.0912 0.0939 0.0808 0.0728 0.0684 0.0653 0.0650 0.0637 0.0632 0.0629 0.0630 0.0638 0.0643 0.0648 0.0658 0.0660 

[TRAIN] Epoch[3](699/1500); Loss: 0.052137; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.0632 0.0688 0.0614 0.0567 0.0664 0.0542 0.0486 0.0473 0.0466 0.0467 0.0457 0.0456 0.0458 0.0455 0.0453 0.0463 

[TRAIN] Epoch[3](700/1500); Loss: 0.095299; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1296 0.1176 0.1034 0.0944 0.0923 0.0916 0.0896 0.0900 0.0894 0.0894 0.0892 0.0895 0.0895 0.0896 0.0899 0.0900 

[TRAIN] Epoch[3](701/1500); Loss: 0.133988; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1709 0.1612 0.1442 0.1371 0.1334 0.1313 0.1295 0.1284 0.1272 0.1268 0.1262 0.1261 0.1253 0.1254 0.1253 0.1255 

[TRAIN] Epoch[3](702/1500); Loss: 0.079211; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1185 0.1091 0.0946 0.0831 0.0770 0.0739 0.0732 0.0721 0.0715 0.0708 0.0704 0.0704 0.0704 0.0707 0.0709 0.0708 

[TRAIN] Epoch[3](703/1500); Loss: 0.057187; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0981 0.0974 0.0861 0.0667 0.0584 0.0472 0.0469 0.0466 0.0459 0.0456 0.0452 0.0451 0.0461 0.0460 0.0460 0.0476 

[TRAIN] Epoch[3](704/1500); Loss: 0.101675; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1247 0.1222 0.1103 0.0994 0.0975 0.0982 0.0984 0.0966 0.0963 0.0969 0.0967 0.0970 0.0973 0.0979 0.0986 0.0989 

[TRAIN] Epoch[3](705/1500); Loss: 0.095447; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1411 0.1299 0.1120 0.1022 0.0952 0.0905 0.0874 0.0868 0.0859 0.0856 0.0848 0.0849 0.0852 0.0853 0.0851 0.0852 

[TRAIN] Epoch[3](706/1500); Loss: 0.076957; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1334 0.1233 0.1059 0.0842 0.0743 0.0696 0.0673 0.0648 0.0644 0.0642 0.0634 0.0629 0.0634 0.0633 0.0632 0.0639 

[TRAIN] Epoch[3](707/1500); Loss: 0.104049; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1643 0.1410 0.1195 0.1084 0.1023 0.0985 0.0967 0.0942 0.0933 0.0927 0.0925 0.0921 0.0919 0.0922 0.0925 0.0927 

[TRAIN] Epoch[3](708/1500); Loss: 0.071992; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0950 0.0864 0.0768 0.0731 0.0720 0.0704 0.0693 0.0684 0.0679 0.0674 0.0668 0.0669 0.0668 0.0673 0.0684 0.0690 

[TRAIN] Epoch[3](709/1500); Loss: 0.107218; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1342 0.1314 0.1148 0.1078 0.1059 0.1046 0.1035 0.1018 0.1017 0.1018 0.1014 0.1015 0.1008 0.1008 0.1015 0.1019 

[TRAIN] Epoch[3](710/1500); Loss: 0.091331; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1797 0.1524 0.1263 0.1074 0.0942 0.0846 0.0783 0.0742 0.0720 0.0708 0.0705 0.0706 0.0701 0.0698 0.0703 0.0700 

[TRAIN] Epoch[3](711/1500); Loss: 0.087216; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1322 0.1201 0.1046 0.0940 0.0868 0.0837 0.0821 0.0800 0.0779 0.0771 0.0766 0.0763 0.0759 0.0762 0.0760 0.0761 

[TRAIN] Epoch[3](712/1500); Loss: 0.144431; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3011 0.2669 0.2210 0.1935 0.1688 0.1463 0.1255 0.1098 0.1009 0.0988 0.0982 0.0965 0.0956 0.0959 0.0963 0.0959 

[TRAIN] Epoch[3](713/1500); Loss: 0.123709; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1356 0.1347 0.1302 0.1271 0.1244 0.1227 0.1219 0.1214 0.1208 0.1206 0.1202 0.1200 0.1201 0.1199 0.1196 0.1199 

[TRAIN] Epoch[3](714/1500); Loss: 0.118914; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1394 0.1360 0.1384 0.1219 0.1159 0.1129 0.1136 0.1128 0.1131 0.1131 0.1132 0.1133 0.1138 0.1144 0.1152 0.1157 

[TRAIN] Epoch[3](715/1500); Loss: 0.104372; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1687 0.1549 0.1252 0.1153 0.1079 0.1008 0.0947 0.0896 0.0883 0.0884 0.0877 0.0883 0.0885 0.0898 0.0902 0.0916 

[TRAIN] Epoch[3](716/1500); Loss: 0.138167; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1893 0.1782 0.1579 0.1487 0.1421 0.1373 0.1341 0.1312 0.1287 0.1271 0.1248 0.1230 0.1226 0.1220 0.1221 0.1215 

[TRAIN] Epoch[3](717/1500); Loss: 0.107029; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1527 0.1427 0.1159 0.1087 0.1031 0.1013 0.0997 0.0987 0.0985 0.0983 0.0987 0.0984 0.0988 0.0990 0.0988 0.0993 

[TRAIN] Epoch[3](718/1500); Loss: 0.115949; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1868 0.1682 0.1357 0.1233 0.1157 0.1102 0.1063 0.1035 0.1023 0.1017 0.1005 0.1006 0.1003 0.0997 0.1000 0.1003 

[TRAIN] Epoch[3](719/1500); Loss: 0.097583; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1138 0.1147 0.1025 0.1011 0.1021 0.0978 0.0943 0.0936 0.0938 0.0934 0.0920 0.0918 0.0923 0.0929 0.0925 0.0924 

[TRAIN] Epoch[3](720/1500); Loss: 0.120440; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1643 0.1487 0.1327 0.1230 0.1184 0.1146 0.1123 0.1108 0.1103 0.1107 0.1117 0.1124 0.1133 0.1136 0.1145 0.1157 

[TRAIN] Epoch[3](721/1500); Loss: 0.219643; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.3858 0.3496 0.3110 0.2791 0.2514 0.2220 0.1933 0.1714 0.1632 0.1683 0.1737 0.1688 0.1675 0.1687 0.1697 0.1707 

[TRAIN] Epoch[3](722/1500); Loss: 0.110920; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1218 0.1225 0.1118 0.1140 0.1168 0.1094 0.1080 0.1081 0.1088 0.1093 0.1071 0.1069 0.1072 0.1078 0.1084 0.1068 

[TRAIN] Epoch[3](723/1500); Loss: 0.092662; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2540 0.2117 0.1669 0.1279 0.0927 0.0643 0.0597 0.0727 0.0599 0.0525 0.0518 0.0530 0.0525 0.0525 0.0552 0.0551 

[TRAIN] Epoch[3](724/1500); Loss: 0.115810; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1821 0.1731 0.1614 0.1428 0.1276 0.1158 0.1064 0.0985 0.0957 0.0940 0.0934 0.0919 0.0920 0.0926 0.0926 0.0931 

[TRAIN] Epoch[3](725/1500); Loss: 0.157257; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2228 0.2030 0.1798 0.1651 0.1553 0.1479 0.1455 0.1469 0.1444 0.1435 0.1431 0.1436 0.1439 0.1436 0.1433 0.1445 

[TRAIN] Epoch[3](726/1500); Loss: 0.139851; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2135 0.1999 0.1877 0.1702 0.1549 0.1420 0.1332 0.1254 0.1184 0.1153 0.1155 0.1153 0.1123 0.1113 0.1111 0.1116 

[TRAIN] Epoch[3](727/1500); Loss: 0.162567; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2262 0.2077 0.1872 0.1734 0.1645 0.1572 0.1545 0.1536 0.1497 0.1477 0.1466 0.1474 0.1473 0.1468 0.1458 0.1454 

[TRAIN] Epoch[3](728/1500); Loss: 0.079252; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1381 0.1253 0.1391 0.1060 0.0861 0.0729 0.0674 0.0662 0.0629 0.0602 0.0578 0.0564 0.0582 0.0568 0.0569 0.0576 

[TRAIN] Epoch[3](729/1500); Loss: 0.118101; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1518 0.1366 0.1247 0.1206 0.1174 0.1154 0.1146 0.1133 0.1132 0.1125 0.1120 0.1121 0.1114 0.1113 0.1115 0.1112 

[TRAIN] Epoch[3](730/1500); Loss: 0.122288; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1815 0.1723 0.1605 0.1457 0.1317 0.1226 0.1209 0.1157 0.1095 0.1050 0.1018 0.0994 0.0977 0.0976 0.0977 0.0970 

[TRAIN] Epoch[3](731/1500); Loss: 0.113359; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1549 0.1424 0.1284 0.1154 0.1120 0.1085 0.1060 0.1048 0.1049 0.1053 0.1048 0.1047 0.1048 0.1050 0.1055 0.1063 

[TRAIN] Epoch[3](732/1500); Loss: 0.097007; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1430 0.1375 0.1258 0.1063 0.0977 0.0919 0.0900 0.0866 0.0846 0.0847 0.0842 0.0841 0.0834 0.0841 0.0843 0.0839 

[TRAIN] Epoch[3](733/1500); Loss: 0.110166; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1462 0.1417 0.1255 0.1178 0.1121 0.1069 0.1042 0.1029 0.1023 0.1005 0.1005 0.1000 0.0999 0.1005 0.1008 0.1007 

[TRAIN] Epoch[3](734/1500); Loss: 0.087315; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1233 0.1205 0.1010 0.0921 0.0859 0.0830 0.0822 0.0802 0.0788 0.0780 0.0782 0.0779 0.0783 0.0788 0.0793 0.0796 

[TRAIN] Epoch[3](735/1500); Loss: 0.066991; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.0980 0.0926 0.0859 0.0739 0.0665 0.0638 0.0608 0.0595 0.0587 0.0590 0.0584 0.0584 0.0588 0.0587 0.0591 0.0596 

[TRAIN] Epoch[3](736/1500); Loss: 0.083566; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1197 0.1147 0.1080 0.0906 0.0837 0.0793 0.0767 0.0744 0.0739 0.0737 0.0734 0.0732 0.0735 0.0735 0.0743 0.0745 

[TRAIN] Epoch[3](737/1500); Loss: 0.142470; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1670 0.1607 0.1502 0.1452 0.1428 0.1415 0.1397 0.1384 0.1377 0.1375 0.1370 0.1364 0.1363 0.1366 0.1364 0.1361 

[TRAIN] Epoch[3](738/1500); Loss: 0.064656; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1573 0.1274 0.1107 0.0669 0.0486 0.0401 0.0482 0.0470 0.0425 0.0395 0.0427 0.0507 0.0496 0.0494 0.0533 0.0605 

[TRAIN] Epoch[3](739/1500); Loss: 0.100312; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1532 0.1441 0.1114 0.1038 0.0974 0.0932 0.0925 0.0916 0.0880 0.0881 0.0892 0.0893 0.0892 0.0910 0.0912 0.0919 

[TRAIN] Epoch[3](740/1500); Loss: 0.085601; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2067 0.1681 0.1280 0.0999 0.0863 0.0760 0.0683 0.0623 0.0599 0.0611 0.0597 0.0581 0.0581 0.0591 0.0589 0.0592 

[TRAIN] Epoch[3](741/1500); Loss: 0.117983; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1507 0.1437 0.1344 0.1266 0.1250 0.1188 0.1140 0.1121 0.1101 0.1092 0.1075 0.1075 0.1072 0.1068 0.1068 0.1072 

[TRAIN] Epoch[3](742/1500); Loss: 0.091428; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1533 0.1407 0.1042 0.0983 0.0929 0.0858 0.0820 0.0818 0.0783 0.0772 0.0778 0.0770 0.0769 0.0783 0.0791 0.0793 

[TRAIN] Epoch[3](743/1500); Loss: 0.107399; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1242 0.1253 0.1169 0.1116 0.1135 0.1082 0.1035 0.1029 0.1021 0.1012 0.1017 0.1018 0.1017 0.1015 0.1010 0.1013 

[TRAIN] Epoch[3](744/1500); Loss: 0.117801; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1695 0.1553 0.1378 0.1244 0.1172 0.1142 0.1104 0.1078 0.1078 0.1060 0.1051 0.1059 0.1057 0.1053 0.1058 0.1067 

[TRAIN] Epoch[3](745/1500); Loss: 0.070340; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1424 0.1271 0.0746 0.0631 0.0656 0.0657 0.0609 0.0574 0.0582 0.0581 0.0570 0.0582 0.0593 0.0584 0.0592 0.0602 

[TRAIN] Epoch[3](746/1500); Loss: 0.103579; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1807 0.1500 0.1149 0.1048 0.1027 0.0960 0.0937 0.0920 0.0898 0.0890 0.0900 0.0903 0.0900 0.0910 0.0912 0.0911 

[TRAIN] Epoch[3](747/1500); Loss: 0.083857; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1230 0.1168 0.1200 0.0935 0.0850 0.0771 0.0739 0.0747 0.0711 0.0699 0.0705 0.0714 0.0721 0.0733 0.0740 0.0754 

[TRAIN] Epoch[3](748/1500); Loss: 0.088354; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1577 0.1379 0.1367 0.1143 0.0953 0.0818 0.0822 0.0751 0.0683 0.0697 0.0672 0.0659 0.0651 0.0664 0.0656 0.0645 

[TRAIN] Epoch[3](749/1500); Loss: 0.139675; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1756 0.1656 0.1538 0.1440 0.1397 0.1369 0.1345 0.1328 0.1316 0.1318 0.1317 0.1310 0.1312 0.1315 0.1315 0.1316 

[TRAIN] Epoch[3](750/1500); Loss: 0.109806; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1252 0.1198 0.1133 0.1109 0.1099 0.1081 0.1068 0.1069 0.1060 0.1060 0.1057 0.1060 0.1070 0.1079 0.1087 0.1087 

[TRAIN] Epoch[3](751/1500); Loss: 0.083571; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1599 0.1356 0.1206 0.1051 0.0905 0.0777 0.0712 0.0671 0.0654 0.0658 0.0635 0.0624 0.0627 0.0637 0.0629 0.0628 

[TRAIN] Epoch[3](752/1500); Loss: 0.222481; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.3432 0.3176 0.2910 0.2675 0.2458 0.2245 0.2036 0.1885 0.1859 0.1875 0.1871 0.1844 0.1848 0.1839 0.1820 0.1822 

[TRAIN] Epoch[3](753/1500); Loss: 0.178495; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.4385 0.3884 0.3317 0.2814 0.2345 0.1882 0.1430 0.1025 0.0827 0.0968 0.0960 0.0918 0.0912 0.0939 0.0976 0.0977 

[TRAIN] Epoch[3](754/1500); Loss: 0.045986; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0612 0.0538 0.0446 0.0461 0.0446 0.0415 0.0419 0.0419 0.0424 0.0429 0.0436 0.0446 0.0450 0.0461 0.0473 0.0480 

[TRAIN] Epoch[3](755/1500); Loss: 0.081794; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1262 0.1202 0.0959 0.0866 0.0807 0.0775 0.0771 0.0739 0.0711 0.0711 0.0712 0.0704 0.0713 0.0715 0.0715 0.0726 

[TRAIN] Epoch[3](756/1500); Loss: 0.063672; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1364 0.1128 0.0869 0.0697 0.0614 0.0562 0.0532 0.0511 0.0491 0.0490 0.0494 0.0484 0.0483 0.0491 0.0489 0.0488 

[TRAIN] Epoch[3](757/1500); Loss: 0.044484; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1123 0.0863 0.0690 0.0496 0.0390 0.0396 0.0374 0.0327 0.0308 0.0308 0.0311 0.0300 0.0305 0.0307 0.0307 0.0312 

[TRAIN] Epoch[3](758/1500); Loss: 0.090853; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1030 0.1004 0.0969 0.0935 0.0918 0.0920 0.0895 0.0871 0.0870 0.0873 0.0863 0.0866 0.0873 0.0882 0.0882 0.0885 

[TRAIN] Epoch[3](759/1500); Loss: 0.077557; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1163 0.1022 0.0903 0.0809 0.0769 0.0745 0.0716 0.0711 0.0699 0.0698 0.0696 0.0693 0.0691 0.0692 0.0701 0.0701 

[TRAIN] Epoch[3](760/1500); Loss: 0.037759; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0615 0.0507 0.0362 0.0357 0.0371 0.0332 0.0319 0.0322 0.0327 0.0332 0.0341 0.0354 0.0359 0.0370 0.0382 0.0392 

[TRAIN] Epoch[3](761/1500); Loss: 0.110236; Backpropagation: 0.0929 sec; Batch: 0.4242 sec
0.1644 0.1546 0.1434 0.1262 0.1140 0.1033 0.0999 0.1021 0.0972 0.0954 0.0941 0.0943 0.0939 0.0937 0.0937 0.0935 

[TRAIN] Epoch[3](762/1500); Loss: 0.109885; Backpropagation: 0.0926 sec; Batch: 0.4246 sec
0.1514 0.1415 0.1224 0.1164 0.1148 0.1100 0.1041 0.1020 0.1007 0.0996 0.0990 0.0992 0.0992 0.0987 0.0992 0.0998 

[TRAIN] Epoch[3](763/1500); Loss: 0.101079; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1490 0.1412 0.1285 0.1126 0.1011 0.0947 0.0941 0.0927 0.0887 0.0881 0.0874 0.0871 0.0878 0.0877 0.0880 0.0886 

[TRAIN] Epoch[3](764/1500); Loss: 0.064340; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1349 0.1261 0.0740 0.0644 0.0599 0.0558 0.0530 0.0528 0.0518 0.0512 0.0504 0.0507 0.0503 0.0509 0.0514 0.0518 

[TRAIN] Epoch[3](765/1500); Loss: 0.140170; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1600 0.1567 0.1469 0.1435 0.1466 0.1418 0.1359 0.1351 0.1349 0.1345 0.1338 0.1339 0.1353 0.1349 0.1342 0.1348 

[TRAIN] Epoch[3](766/1500); Loss: 0.090137; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1487 0.1406 0.0972 0.0889 0.0875 0.0840 0.0796 0.0802 0.0792 0.0783 0.0778 0.0790 0.0793 0.0798 0.0807 0.0814 

[TRAIN] Epoch[3](767/1500); Loss: 0.088188; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1535 0.1374 0.1278 0.1079 0.0934 0.0850 0.0827 0.0773 0.0713 0.0689 0.0678 0.0677 0.0671 0.0676 0.0678 0.0678 

[TRAIN] Epoch[3](768/1500); Loss: 0.137893; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1818 0.1776 0.1527 0.1430 0.1349 0.1312 0.1299 0.1300 0.1282 0.1274 0.1275 0.1279 0.1285 0.1281 0.1284 0.1291 

[TRAIN] Epoch[3](769/1500); Loss: 0.085308; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1236 0.1233 0.1208 0.1028 0.0905 0.0820 0.0773 0.0750 0.0729 0.0715 0.0713 0.0709 0.0703 0.0703 0.0709 0.0715 

[TRAIN] Epoch[3](770/1500); Loss: 0.073629; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1995 0.1723 0.0931 0.0675 0.0610 0.0618 0.0585 0.0520 0.0502 0.0518 0.0509 0.0493 0.0508 0.0524 0.0537 0.0534 

[TRAIN] Epoch[3](771/1500); Loss: 0.147513; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1641 0.1554 0.1473 0.1444 0.1433 0.1435 0.1437 0.1441 0.1447 0.1451 0.1453 0.1461 0.1472 0.1480 0.1488 0.1493 

[TRAIN] Epoch[3](772/1500); Loss: 0.134522; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1649 0.1531 0.1422 0.1364 0.1327 0.1316 0.1303 0.1293 0.1290 0.1290 0.1289 0.1290 0.1289 0.1289 0.1289 0.1293 

[TRAIN] Epoch[3](773/1500); Loss: 0.174861; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2148 0.2108 0.2040 0.1895 0.1800 0.1738 0.1691 0.1657 0.1625 0.1612 0.1604 0.1607 0.1605 0.1611 0.1614 0.1624 

[TRAIN] Epoch[3](774/1500); Loss: 0.130744; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1646 0.1544 0.1433 0.1356 0.1294 0.1274 0.1270 0.1253 0.1238 0.1231 0.1232 0.1226 0.1224 0.1229 0.1233 0.1236 

[TRAIN] Epoch[3](775/1500); Loss: 0.061632; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1164 0.0950 0.0815 0.0652 0.0543 0.0561 0.0559 0.0531 0.0513 0.0507 0.0509 0.0506 0.0509 0.0511 0.0514 0.0517 

[TRAIN] Epoch[3](776/1500); Loss: 0.148577; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2200 0.2039 0.1864 0.1691 0.1560 0.1455 0.1356 0.1289 0.1288 0.1308 0.1296 0.1289 0.1282 0.1282 0.1284 0.1288 

[TRAIN] Epoch[3](777/1500); Loss: 0.132594; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2113 0.1949 0.1747 0.1584 0.1448 0.1326 0.1229 0.1166 0.1130 0.1108 0.1096 0.1084 0.1067 0.1060 0.1057 0.1052 

[TRAIN] Epoch[3](778/1500); Loss: 0.080788; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.0985 0.0964 0.0908 0.0844 0.0799 0.0794 0.0785 0.0768 0.0763 0.0759 0.0758 0.0757 0.0759 0.0759 0.0761 0.0764 

[TRAIN] Epoch[3](779/1500); Loss: 0.102353; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1271 0.1224 0.1126 0.1058 0.1018 0.0994 0.0986 0.0975 0.0969 0.0969 0.0967 0.0964 0.0963 0.0964 0.0964 0.0966 

[TRAIN] Epoch[3](780/1500); Loss: 0.076816; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1256 0.1145 0.0997 0.0895 0.0811 0.0727 0.0684 0.0666 0.0649 0.0638 0.0633 0.0631 0.0630 0.0634 0.0647 0.0645 

[TRAIN] Epoch[3](781/1500); Loss: 0.083200; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0959 0.0900 0.0896 0.0872 0.0840 0.0809 0.0803 0.0806 0.0798 0.0795 0.0800 0.0800 0.0802 0.0808 0.0810 0.0814 

[TRAIN] Epoch[3](782/1500); Loss: 0.159486; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2359 0.2165 0.2012 0.1876 0.1744 0.1632 0.1542 0.1466 0.1401 0.1350 0.1325 0.1325 0.1325 0.1326 0.1333 0.1333 

[TRAIN] Epoch[3](783/1500); Loss: 0.177469; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.3019 0.2815 0.2544 0.2244 0.2002 0.1821 0.1655 0.1462 0.1316 0.1313 0.1396 0.1377 0.1347 0.1355 0.1360 0.1370 

[TRAIN] Epoch[3](784/1500); Loss: 0.160734; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2158 0.1981 0.1820 0.1678 0.1581 0.1523 0.1494 0.1508 0.1499 0.1492 0.1489 0.1494 0.1501 0.1499 0.1499 0.1501 

[TRAIN] Epoch[3](785/1500); Loss: 0.090181; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1258 0.1249 0.1144 0.1042 0.0951 0.0885 0.0852 0.0815 0.0783 0.0783 0.0776 0.0775 0.0775 0.0779 0.0782 0.0781 

[TRAIN] Epoch[3](786/1500); Loss: 0.057920; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0727 0.0685 0.0609 0.0581 0.0554 0.0546 0.0544 0.0541 0.0543 0.0546 0.0553 0.0556 0.0564 0.0569 0.0571 0.0579 

[TRAIN] Epoch[3](787/1500); Loss: 0.051403; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.0982 0.0889 0.0791 0.0571 0.0446 0.0455 0.0449 0.0405 0.0395 0.0397 0.0399 0.0400 0.0403 0.0408 0.0413 0.0420 

[TRAIN] Epoch[3](788/1500); Loss: 0.157271; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1694 0.1620 0.1584 0.1557 0.1541 0.1532 0.1541 0.1548 0.1554 0.1555 0.1558 0.1560 0.1568 0.1577 0.1583 0.1591 

[TRAIN] Epoch[3](789/1500); Loss: 0.072441; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1241 0.1157 0.1058 0.0880 0.0742 0.0684 0.0638 0.0594 0.0586 0.0575 0.0575 0.0568 0.0566 0.0571 0.0576 0.0581 

[TRAIN] Epoch[3](790/1500); Loss: 0.068316; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1016 0.0865 0.0831 0.0770 0.0689 0.0674 0.0644 0.0614 0.0613 0.0607 0.0598 0.0601 0.0602 0.0602 0.0599 0.0602 

[TRAIN] Epoch[3](791/1500); Loss: 0.097227; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1250 0.1274 0.1276 0.1123 0.1015 0.0969 0.0943 0.0900 0.0856 0.0855 0.0851 0.0842 0.0846 0.0844 0.0851 0.0861 

[TRAIN] Epoch[3](792/1500); Loss: 0.115648; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1372 0.1340 0.1345 0.1209 0.1142 0.1118 0.1121 0.1133 0.1106 0.1085 0.1089 0.1087 0.1088 0.1087 0.1092 0.1089 

[TRAIN] Epoch[3](793/1500); Loss: 0.079601; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1421 0.1253 0.1118 0.0923 0.0772 0.0730 0.0719 0.0683 0.0663 0.0650 0.0643 0.0636 0.0632 0.0631 0.0631 0.0632 

[TRAIN] Epoch[3](794/1500); Loss: 0.056203; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1032 0.1007 0.0995 0.0725 0.0603 0.0517 0.0456 0.0427 0.0412 0.0394 0.0399 0.0397 0.0398 0.0404 0.0414 0.0413 

[TRAIN] Epoch[3](795/1500); Loss: 0.075094; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1006 0.0959 0.1452 0.1044 0.0913 0.0799 0.0682 0.0592 0.0576 0.0578 0.0565 0.0550 0.0561 0.0569 0.0579 0.0593 

[TRAIN] Epoch[3](796/1500); Loss: 0.144281; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1677 0.1622 0.1538 0.1478 0.1450 0.1431 0.1411 0.1405 0.1396 0.1388 0.1386 0.1385 0.1384 0.1380 0.1376 0.1377 

[TRAIN] Epoch[3](797/1500); Loss: 0.092848; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1454 0.1328 0.1362 0.1104 0.0927 0.0835 0.0853 0.0863 0.0794 0.0775 0.0770 0.0763 0.0757 0.0760 0.0753 0.0757 

[TRAIN] Epoch[3](798/1500); Loss: 0.049435; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0761 0.0686 0.0551 0.0473 0.0466 0.0462 0.0445 0.0441 0.0439 0.0442 0.0443 0.0446 0.0453 0.0461 0.0464 0.0474 

[TRAIN] Epoch[3](799/1500); Loss: 0.101172; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1969 0.1735 0.1591 0.1344 0.1110 0.0928 0.0863 0.0817 0.0772 0.0758 0.0723 0.0713 0.0714 0.0723 0.0718 0.0710 

[TRAIN] Epoch[3](800/1500); Loss: 0.122677; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1753 0.1627 0.1546 0.1384 0.1270 0.1198 0.1165 0.1145 0.1091 0.1071 0.1064 0.1060 0.1062 0.1061 0.1064 0.1067 

[TRAIN] Epoch[3](801/1500); Loss: 0.118240; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1741 0.1619 0.1535 0.1350 0.1199 0.1121 0.1112 0.1104 0.1040 0.1019 0.1015 0.1012 0.1013 0.1009 0.1015 0.1016 

[TRAIN] Epoch[3](802/1500); Loss: 0.108403; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1762 0.1596 0.1405 0.1228 0.1096 0.1007 0.0963 0.0937 0.0932 0.0916 0.0914 0.0913 0.0916 0.0917 0.0922 0.0920 

[TRAIN] Epoch[3](803/1500); Loss: 0.108447; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1562 0.1447 0.1298 0.1179 0.1079 0.1032 0.1007 0.0994 0.0978 0.0971 0.0969 0.0969 0.0965 0.0965 0.0966 0.0970 

[TRAIN] Epoch[3](804/1500); Loss: 0.059385; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0999 0.0959 0.0886 0.0722 0.0611 0.0573 0.0547 0.0507 0.0478 0.0465 0.0461 0.0457 0.0459 0.0460 0.0459 0.0460 

[TRAIN] Epoch[3](805/1500); Loss: 0.107248; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1347 0.1297 0.1164 0.1098 0.1054 0.1039 0.1024 0.1017 0.1013 0.1010 0.1010 0.1011 0.1012 0.1015 0.1021 0.1027 

[TRAIN] Epoch[3](806/1500); Loss: 0.138685; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1880 0.1751 0.1633 0.1499 0.1424 0.1367 0.1328 0.1299 0.1276 0.1261 0.1254 0.1247 0.1244 0.1240 0.1245 0.1244 

[TRAIN] Epoch[3](807/1500); Loss: 0.077630; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2401 0.1992 0.1574 0.1201 0.0878 0.0637 0.0492 0.0411 0.0392 0.0396 0.0351 0.0329 0.0335 0.0333 0.0344 0.0354 

[TRAIN] Epoch[3](808/1500); Loss: 0.060830; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0964 0.0897 0.0865 0.0706 0.0611 0.0571 0.0567 0.0543 0.0508 0.0499 0.0499 0.0496 0.0497 0.0501 0.0502 0.0506 

[TRAIN] Epoch[3](809/1500); Loss: 0.135699; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2399 0.2070 0.1748 0.1492 0.1295 0.1186 0.1155 0.1180 0.1161 0.1136 0.1135 0.1147 0.1147 0.1143 0.1154 0.1163 

[TRAIN] Epoch[3](810/1500); Loss: 0.180112; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1966 0.1931 0.1851 0.1826 0.1808 0.1799 0.1784 0.1773 0.1766 0.1763 0.1762 0.1758 0.1758 0.1757 0.1758 0.1758 

[TRAIN] Epoch[3](811/1500); Loss: 0.085449; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1307 0.1214 0.1073 0.0935 0.0854 0.0803 0.0767 0.0757 0.0746 0.0743 0.0741 0.0738 0.0742 0.0745 0.0750 0.0757 

[TRAIN] Epoch[3](812/1500); Loss: 0.153033; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2091 0.1951 0.1822 0.1731 0.1650 0.1572 0.1489 0.1426 0.1378 0.1349 0.1343 0.1345 0.1345 0.1334 0.1329 0.1330 

[TRAIN] Epoch[3](813/1500); Loss: 0.114822; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1641 0.1445 0.1271 0.1178 0.1118 0.1084 0.1058 0.1051 0.1045 0.1054 0.1059 0.1062 0.1063 0.1074 0.1081 0.1090 

[TRAIN] Epoch[3](814/1500); Loss: 0.121899; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1589 0.1497 0.1434 0.1315 0.1240 0.1224 0.1212 0.1165 0.1122 0.1112 0.1109 0.1103 0.1097 0.1097 0.1095 0.1092 

[TRAIN] Epoch[3](815/1500); Loss: 0.058223; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.0631 0.0669 0.0610 0.0627 0.0736 0.0658 0.0573 0.0554 0.0540 0.0537 0.0537 0.0526 0.0523 0.0530 0.0531 0.0531 

[TRAIN] Epoch[3](816/1500); Loss: 0.078489; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2373 0.1930 0.1499 0.1100 0.0728 0.0467 0.0488 0.0637 0.0525 0.0400 0.0384 0.0385 0.0398 0.0401 0.0413 0.0430 

[TRAIN] Epoch[3](817/1500); Loss: 0.104189; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1881 0.1629 0.1369 0.1209 0.1111 0.0992 0.0901 0.0876 0.0858 0.0848 0.0841 0.0834 0.0829 0.0829 0.0831 0.0832 

[TRAIN] Epoch[3](818/1500); Loss: 0.075849; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1346 0.1138 0.0959 0.0853 0.0772 0.0692 0.0673 0.0656 0.0633 0.0622 0.0622 0.0626 0.0627 0.0629 0.0640 0.0647 

[TRAIN] Epoch[3](819/1500); Loss: 0.088345; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1338 0.1262 0.1039 0.0941 0.0877 0.0846 0.0846 0.0815 0.0773 0.0764 0.0766 0.0768 0.0767 0.0774 0.0778 0.0780 

[TRAIN] Epoch[3](820/1500); Loss: 0.137249; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1769 0.1678 0.1614 0.1490 0.1419 0.1386 0.1347 0.1298 0.1270 0.1249 0.1246 0.1243 0.1235 0.1236 0.1237 0.1244 

[TRAIN] Epoch[3](821/1500); Loss: 0.138803; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2114 0.1866 0.1642 0.1501 0.1399 0.1324 0.1278 0.1258 0.1241 0.1234 0.1231 0.1221 0.1221 0.1224 0.1226 0.1230 

[TRAIN] Epoch[3](822/1500); Loss: 0.124950; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2014 0.1824 0.1640 0.1472 0.1354 0.1270 0.1180 0.1101 0.1053 0.1029 0.1020 0.1016 0.1009 0.1003 0.1004 0.1004 

[TRAIN] Epoch[3](823/1500); Loss: 0.091285; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1984 0.1683 0.1629 0.1254 0.1008 0.0813 0.0686 0.0665 0.0659 0.0638 0.0593 0.0588 0.0590 0.0596 0.0604 0.0616 

[TRAIN] Epoch[3](824/1500); Loss: 0.104626; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1817 0.1670 0.1150 0.1010 0.1007 0.0994 0.0975 0.0923 0.0886 0.0884 0.0885 0.0895 0.0903 0.0904 0.0911 0.0925 

[TRAIN] Epoch[3](825/1500); Loss: 0.080791; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1154 0.1062 0.0984 0.0893 0.0805 0.0763 0.0744 0.0733 0.0721 0.0720 0.0718 0.0717 0.0725 0.0723 0.0729 0.0735 

[TRAIN] Epoch[3](826/1500); Loss: 0.128869; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2484 0.2237 0.1906 0.1589 0.1348 0.1196 0.1106 0.1025 0.0975 0.0979 0.0952 0.0949 0.0961 0.0965 0.0968 0.0978 

[TRAIN] Epoch[3](827/1500); Loss: 0.079252; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1397 0.1320 0.0878 0.0789 0.0745 0.0735 0.0718 0.0699 0.0681 0.0674 0.0667 0.0669 0.0672 0.0673 0.0676 0.0686 

[TRAIN] Epoch[3](828/1500); Loss: 0.073569; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1174 0.1088 0.0965 0.0845 0.0777 0.0753 0.0730 0.0669 0.0626 0.0607 0.0596 0.0594 0.0589 0.0586 0.0586 0.0587 

[TRAIN] Epoch[3](829/1500); Loss: 0.083763; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1046 0.0951 0.0913 0.0891 0.0853 0.0817 0.0797 0.0792 0.0790 0.0789 0.0788 0.0790 0.0791 0.0794 0.0798 0.0803 

[TRAIN] Epoch[3](830/1500); Loss: 0.110707; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1930 0.1709 0.1490 0.1350 0.1222 0.1064 0.0966 0.0933 0.0919 0.0914 0.0887 0.0868 0.0863 0.0866 0.0866 0.0867 

[TRAIN] Epoch[3](831/1500); Loss: 0.111605; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1688 0.1572 0.1389 0.1231 0.1141 0.1095 0.1051 0.1019 0.0990 0.0978 0.0964 0.0955 0.0951 0.0947 0.0943 0.0943 

[TRAIN] Epoch[3](832/1500); Loss: 0.072558; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1127 0.1090 0.1014 0.0824 0.0749 0.0738 0.0685 0.0642 0.0614 0.0593 0.0588 0.0584 0.0586 0.0591 0.0589 0.0596 

[TRAIN] Epoch[3](833/1500); Loss: 0.141632; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1643 0.1552 0.1483 0.1442 0.1408 0.1387 0.1374 0.1365 0.1363 0.1366 0.1371 0.1372 0.1377 0.1381 0.1385 0.1391 

[TRAIN] Epoch[3](834/1500); Loss: 0.081442; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1505 0.1454 0.1380 0.1104 0.0870 0.0712 0.0660 0.0687 0.0660 0.0603 0.0566 0.0561 0.0559 0.0564 0.0572 0.0574 

[TRAIN] Epoch[3](835/1500); Loss: 0.097682; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1155 0.1168 0.1272 0.1073 0.0999 0.0959 0.0941 0.0914 0.0910 0.0906 0.0872 0.0862 0.0876 0.0900 0.0911 0.0911 

[TRAIN] Epoch[3](836/1500); Loss: 0.142356; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1695 0.1621 0.1552 0.1548 0.1533 0.1457 0.1390 0.1355 0.1340 0.1337 0.1332 0.1320 0.1315 0.1321 0.1326 0.1334 

[TRAIN] Epoch[3](837/1500); Loss: 0.055440; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0869 0.0897 0.0854 0.0658 0.0568 0.0549 0.0524 0.0505 0.0447 0.0420 0.0420 0.0426 0.0429 0.0427 0.0435 0.0442 

[TRAIN] Epoch[3](838/1500); Loss: 0.087090; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1449 0.1247 0.1035 0.0954 0.0909 0.0858 0.0816 0.0784 0.0763 0.0752 0.0737 0.0728 0.0725 0.0725 0.0725 0.0728 

[TRAIN] Epoch[3](839/1500); Loss: 0.123762; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1628 0.1565 0.1354 0.1267 0.1220 0.1217 0.1208 0.1182 0.1158 0.1144 0.1150 0.1146 0.1139 0.1140 0.1142 0.1142 

[TRAIN] Epoch[3](840/1500); Loss: 0.047108; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0761 0.0654 0.0497 0.0447 0.0474 0.0486 0.0450 0.0418 0.0407 0.0406 0.0409 0.0413 0.0419 0.0424 0.0433 0.0441 

[TRAIN] Epoch[3](841/1500); Loss: 0.096670; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1269 0.1318 0.1215 0.1073 0.0997 0.0984 0.0980 0.0919 0.0862 0.0839 0.0838 0.0837 0.0834 0.0831 0.0829 0.0842 

[TRAIN] Epoch[3](842/1500); Loss: 0.104756; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1299 0.1234 0.1119 0.1073 0.1039 0.1028 0.1017 0.1004 0.0993 0.0992 0.0994 0.0995 0.0992 0.0991 0.0994 0.0998 

[TRAIN] Epoch[3](843/1500); Loss: 0.100001; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1241 0.1200 0.1032 0.0963 0.0945 0.0981 0.1013 0.0998 0.0968 0.0952 0.0939 0.0943 0.0953 0.0952 0.0955 0.0966 

[TRAIN] Epoch[3](844/1500); Loss: 0.083067; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.0988 0.1036 0.0953 0.0785 0.0766 0.0875 0.0871 0.0800 0.0764 0.0765 0.0768 0.0772 0.0776 0.0781 0.0791 0.0799 

[TRAIN] Epoch[3](845/1500); Loss: 0.101916; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1631 0.1450 0.1449 0.1268 0.1151 0.1059 0.0977 0.0919 0.0867 0.0817 0.0797 0.0793 0.0786 0.0775 0.0780 0.0790 

[TRAIN] Epoch[3](846/1500); Loss: 0.136676; Backpropagation: 0.0918 sec; Batch: 0.4257 sec
0.1832 0.1714 0.1636 0.1555 0.1457 0.1385 0.1336 0.1295 0.1263 0.1228 0.1198 0.1187 0.1186 0.1194 0.1199 0.1204 

[TRAIN] Epoch[3](847/1500); Loss: 0.060374; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.1504 0.1158 0.1188 0.0763 0.0625 0.0496 0.0365 0.0311 0.0424 0.0465 0.0360 0.0362 0.0390 0.0387 0.0414 0.0447 

[TRAIN] Epoch[3](848/1500); Loss: 0.143523; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1778 0.1687 0.1576 0.1511 0.1453 0.1414 0.1391 0.1376 0.1366 0.1357 0.1349 0.1342 0.1341 0.1340 0.1341 0.1344 

[TRAIN] Epoch[3](849/1500); Loss: 0.085584; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1163 0.1062 0.0986 0.0920 0.0859 0.0838 0.0816 0.0799 0.0791 0.0786 0.0785 0.0781 0.0777 0.0776 0.0776 0.0779 

[TRAIN] Epoch[3](850/1500); Loss: 0.162667; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2075 0.1927 0.1745 0.1659 0.1608 0.1587 0.1572 0.1561 0.1552 0.1537 0.1529 0.1531 0.1534 0.1534 0.1535 0.1541 

[TRAIN] Epoch[3](851/1500); Loss: 0.067883; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1125 0.1043 0.0857 0.0709 0.0649 0.0643 0.0651 0.0636 0.0586 0.0567 0.0567 0.0557 0.0565 0.0563 0.0568 0.0575 

[TRAIN] Epoch[3](852/1500); Loss: 0.063121; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1092 0.1021 0.0937 0.0764 0.0622 0.0556 0.0563 0.0544 0.0510 0.0498 0.0497 0.0495 0.0497 0.0498 0.0500 0.0505 

[TRAIN] Epoch[3](853/1500); Loss: 0.091882; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1124 0.1226 0.1284 0.1105 0.0966 0.0870 0.0841 0.0855 0.0842 0.0805 0.0790 0.0781 0.0793 0.0799 0.0804 0.0819 

[TRAIN] Epoch[3](854/1500); Loss: 0.155038; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2312 0.2162 0.1997 0.1872 0.1773 0.1679 0.1582 0.1490 0.1401 0.1322 0.1255 0.1207 0.1188 0.1192 0.1189 0.1186 

[TRAIN] Epoch[3](855/1500); Loss: 0.132789; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2062 0.1936 0.1772 0.1600 0.1451 0.1346 0.1262 0.1170 0.1109 0.1086 0.1083 0.1076 0.1069 0.1073 0.1075 0.1076 

[TRAIN] Epoch[3](856/1500); Loss: 0.111465; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1369 0.1335 0.1256 0.1168 0.1114 0.1104 0.1098 0.1084 0.1059 0.1044 0.1035 0.1032 0.1030 0.1032 0.1035 0.1039 

[TRAIN] Epoch[3](857/1500); Loss: 0.108753; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1616 0.1514 0.1475 0.1274 0.1119 0.1027 0.0999 0.0993 0.0960 0.0936 0.0916 0.0910 0.0915 0.0905 0.0916 0.0926 

[TRAIN] Epoch[3](858/1500); Loss: 0.114053; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1757 0.1685 0.1599 0.1410 0.1271 0.1181 0.1118 0.1041 0.0968 0.0916 0.0896 0.0892 0.0882 0.0876 0.0876 0.0881 

[TRAIN] Epoch[3](859/1500); Loss: 0.097677; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1678 0.1537 0.1303 0.1151 0.1039 0.0947 0.0882 0.0836 0.0810 0.0793 0.0777 0.0776 0.0774 0.0769 0.0779 0.0778 

[TRAIN] Epoch[3](860/1500); Loss: 0.086611; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1309 0.1192 0.1290 0.1067 0.0903 0.0788 0.0760 0.0803 0.0786 0.0724 0.0709 0.0701 0.0709 0.0701 0.0701 0.0715 

[TRAIN] Epoch[3](861/1500); Loss: 0.115268; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1426 0.1416 0.1336 0.1241 0.1174 0.1141 0.1125 0.1113 0.1088 0.1067 0.1057 0.1053 0.1050 0.1051 0.1051 0.1054 

[TRAIN] Epoch[3](862/1500); Loss: 0.158407; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2550 0.2331 0.2198 0.1965 0.1776 0.1613 0.1484 0.1400 0.1351 0.1310 0.1278 0.1241 0.1219 0.1209 0.1210 0.1209 

[TRAIN] Epoch[3](863/1500); Loss: 0.134453; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2447 0.2164 0.1875 0.1674 0.1512 0.1373 0.1246 0.1138 0.1060 0.1019 0.1008 0.1004 0.0993 0.0996 0.1000 0.1002 

[TRAIN] Epoch[3](864/1500); Loss: 0.091921; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1381 0.1278 0.1123 0.1008 0.0928 0.0890 0.0877 0.0853 0.0819 0.0801 0.0795 0.0792 0.0791 0.0791 0.0789 0.0791 

[TRAIN] Epoch[3](865/1500); Loss: 0.089251; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1763 0.1527 0.1277 0.1045 0.0870 0.0779 0.0740 0.0750 0.0763 0.0736 0.0693 0.0668 0.0660 0.0664 0.0669 0.0678 

[TRAIN] Epoch[3](866/1500); Loss: 0.158615; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1896 0.1863 0.1746 0.1673 0.1640 0.1632 0.1605 0.1560 0.1517 0.1496 0.1482 0.1467 0.1458 0.1453 0.1445 0.1445 

[TRAIN] Epoch[3](867/1500); Loss: 0.068663; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0928 0.0937 0.0819 0.0715 0.0651 0.0639 0.0655 0.0647 0.0624 0.0613 0.0614 0.0617 0.0623 0.0624 0.0634 0.0645 

[TRAIN] Epoch[3](868/1500); Loss: 0.097185; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1429 0.1344 0.1135 0.1064 0.1031 0.1021 0.0982 0.0922 0.0867 0.0832 0.0831 0.0827 0.0817 0.0816 0.0817 0.0814 

[TRAIN] Epoch[3](869/1500); Loss: 0.110970; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1321 0.1361 0.1266 0.1168 0.1111 0.1109 0.1120 0.1096 0.1055 0.1029 0.1022 0.1019 0.1018 0.1017 0.1021 0.1023 

[TRAIN] Epoch[3](870/1500); Loss: 0.116562; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2731 0.2414 0.2034 0.1709 0.1421 0.1173 0.0950 0.0783 0.0721 0.0730 0.0686 0.0653 0.0659 0.0661 0.0663 0.0662 

[TRAIN] Epoch[3](871/1500); Loss: 0.097361; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2455 0.2104 0.1762 0.1438 0.1148 0.0920 0.0749 0.0621 0.0571 0.0583 0.0595 0.0565 0.0527 0.0510 0.0509 0.0521 

[TRAIN] Epoch[3](872/1500); Loss: 0.097721; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1355 0.1385 0.1319 0.1129 0.0971 0.0925 0.0970 0.0934 0.0868 0.0837 0.0820 0.0821 0.0817 0.0821 0.0829 0.0834 

[TRAIN] Epoch[3](873/1500); Loss: 0.115688; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1468 0.1428 0.1450 0.1244 0.1160 0.1110 0.1079 0.1056 0.1069 0.1074 0.1056 0.1054 0.1060 0.1061 0.1071 0.1070 

[TRAIN] Epoch[3](874/1500); Loss: 0.109639; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1452 0.1281 0.1154 0.1095 0.1074 0.1069 0.1058 0.1045 0.1041 0.1041 0.1036 0.1034 0.1040 0.1040 0.1039 0.1043 

[TRAIN] Epoch[3](875/1500); Loss: 0.163809; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1862 0.1807 0.1733 0.1708 0.1693 0.1671 0.1637 0.1612 0.1590 0.1574 0.1563 0.1557 0.1554 0.1551 0.1549 0.1549 

[TRAIN] Epoch[3](876/1500); Loss: 0.099891; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1595 0.1569 0.1467 0.1224 0.1035 0.0925 0.0894 0.0882 0.0868 0.0838 0.0801 0.0793 0.0777 0.0774 0.0771 0.0770 

[TRAIN] Epoch[3](877/1500); Loss: 0.047771; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1816 0.1505 0.0598 0.0346 0.0234 0.0272 0.0388 0.0350 0.0263 0.0233 0.0248 0.0251 0.0264 0.0268 0.0295 0.0312 

[TRAIN] Epoch[3](878/1500); Loss: 0.086610; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1311 0.1215 0.1154 0.0948 0.0824 0.0806 0.0833 0.0794 0.0745 0.0743 0.0740 0.0736 0.0746 0.0756 0.0749 0.0758 

[TRAIN] Epoch[3](879/1500); Loss: 0.133601; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1968 0.1776 0.1591 0.1462 0.1371 0.1322 0.1296 0.1257 0.1218 0.1192 0.1169 0.1155 0.1146 0.1149 0.1149 0.1155 

[TRAIN] Epoch[3](880/1500); Loss: 0.088319; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1578 0.1376 0.1291 0.1052 0.0897 0.0832 0.0798 0.0729 0.0698 0.0689 0.0685 0.0683 0.0689 0.0697 0.0712 0.0726 

[TRAIN] Epoch[3](881/1500); Loss: 0.055572; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1750 0.1258 0.0781 0.0475 0.0352 0.0444 0.0371 0.0359 0.0342 0.0367 0.0374 0.0365 0.0390 0.0408 0.0415 0.0440 

[TRAIN] Epoch[3](882/1500); Loss: 0.109596; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1881 0.1644 0.1419 0.1164 0.1012 0.0977 0.0931 0.0889 0.0882 0.0901 0.0929 0.0940 0.0945 0.0976 0.1006 0.1038 

[TRAIN] Epoch[3](883/1500); Loss: 0.095870; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1320 0.1274 0.1288 0.0986 0.0886 0.0882 0.0841 0.0816 0.0810 0.0828 0.0836 0.0855 0.0892 0.0910 0.0939 0.0977 

[TRAIN] Epoch[3](884/1500); Loss: 0.119770; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2071 0.1789 0.1479 0.1286 0.1161 0.1050 0.0993 0.0987 0.0995 0.1007 0.1011 0.1023 0.1050 0.1070 0.1082 0.1109 

[TRAIN] Epoch[3](885/1500); Loss: 0.115794; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1796 0.1668 0.1424 0.1287 0.1168 0.1079 0.1042 0.1028 0.1004 0.1005 0.0995 0.0988 0.0995 0.1008 0.1010 0.1032 

[TRAIN] Epoch[3](886/1500); Loss: 0.092307; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1922 0.1798 0.0675 0.0622 0.0780 0.0667 0.0572 0.0561 0.0649 0.0745 0.0804 0.0824 0.0908 0.1033 0.1079 0.1129 

[TRAIN] Epoch[3](887/1500); Loss: 0.164798; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2358 0.2159 0.1927 0.1798 0.1695 0.1598 0.1528 0.1483 0.1465 0.1445 0.1446 0.1467 0.1483 0.1488 0.1500 0.1528 

[TRAIN] Epoch[3](888/1500); Loss: 0.103353; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1455 0.1434 0.1379 0.1067 0.0951 0.0924 0.0869 0.0839 0.0825 0.0853 0.0875 0.0909 0.0972 0.1028 0.1055 0.1101 

[TRAIN] Epoch[3](889/1500); Loss: 0.069984; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1157 0.0974 0.0794 0.0712 0.0656 0.0623 0.0605 0.0601 0.0603 0.0605 0.0612 0.0628 0.0631 0.0646 0.0671 0.0679 

[TRAIN] Epoch[3](890/1500); Loss: 0.109575; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1393 0.1280 0.1168 0.1088 0.1044 0.1022 0.1011 0.1005 0.1012 0.1020 0.1027 0.1047 0.1067 0.1089 0.1119 0.1141 

[TRAIN] Epoch[3](891/1500); Loss: 0.139059; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2719 0.2291 0.1918 0.1671 0.1484 0.1328 0.1197 0.1095 0.1040 0.1036 0.1060 0.1076 0.1062 0.1066 0.1094 0.1113 

[TRAIN] Epoch[3](892/1500); Loss: 0.068247; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1977 0.1564 0.1145 0.0815 0.0551 0.0424 0.0378 0.0402 0.0397 0.0410 0.0425 0.0447 0.0454 0.0491 0.0508 0.0531 

[TRAIN] Epoch[3](893/1500); Loss: 0.077908; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1145 0.0943 0.0778 0.0732 0.0701 0.0699 0.0698 0.0694 0.0699 0.0706 0.0731 0.0747 0.0758 0.0794 0.0810 0.0831 

[TRAIN] Epoch[3](894/1500); Loss: 0.136013; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2474 0.2176 0.1884 0.1662 0.1476 0.1332 0.1191 0.1091 0.1043 0.1012 0.1002 0.1040 0.1066 0.1074 0.1096 0.1146 

[TRAIN] Epoch[3](895/1500); Loss: 0.134538; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2195 0.1956 0.1522 0.1447 0.1350 0.1224 0.1154 0.1121 0.1119 0.1160 0.1175 0.1182 0.1190 0.1221 0.1241 0.1269 

[TRAIN] Epoch[3](896/1500); Loss: 0.073712; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1330 0.1055 0.0811 0.0669 0.0586 0.0570 0.0587 0.0584 0.0591 0.0615 0.0647 0.0678 0.0704 0.0755 0.0793 0.0818 

[TRAIN] Epoch[3](897/1500); Loss: 0.161462; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1987 0.1931 0.1644 0.1610 0.1605 0.1555 0.1521 0.1500 0.1505 0.1530 0.1525 0.1531 0.1563 0.1591 0.1606 0.1630 

[TRAIN] Epoch[3](898/1500); Loss: 0.086982; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.2215 0.1744 0.1299 0.0936 0.0675 0.0584 0.0589 0.0568 0.0578 0.0585 0.0605 0.0642 0.0667 0.0698 0.0747 0.0784 

[TRAIN] Epoch[3](899/1500); Loss: 0.116926; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1504 0.1355 0.1174 0.1128 0.1084 0.1062 0.1064 0.1062 0.1067 0.1077 0.1120 0.1137 0.1161 0.1200 0.1236 0.1278 

[TRAIN] Epoch[3](900/1500); Loss: 0.107917; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1136 0.1124 0.1102 0.1094 0.1044 0.1038 0.1050 0.1044 0.1044 0.1057 0.1061 0.1068 0.1085 0.1090 0.1104 0.1125 

[TRAIN] Epoch[3](901/1500); Loss: 0.128452; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1559 0.1487 0.1323 0.1251 0.1215 0.1180 0.1164 0.1171 0.1173 0.1188 0.1217 0.1252 0.1277 0.1315 0.1374 0.1406 

[TRAIN] Epoch[3](902/1500); Loss: 0.104952; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1686 0.1428 0.1094 0.0961 0.0921 0.0891 0.0879 0.0875 0.0902 0.0933 0.0942 0.0976 0.1033 0.1078 0.1079 0.1114 

[TRAIN] Epoch[3](903/1500); Loss: 0.120227; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1603 0.1564 0.1128 0.1166 0.1125 0.1057 0.1054 0.1079 0.1084 0.1099 0.1128 0.1161 0.1185 0.1223 0.1275 0.1306 

[TRAIN] Epoch[3](904/1500); Loss: 0.074848; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1071 0.1020 0.0845 0.0804 0.0748 0.0710 0.0685 0.0663 0.0651 0.0654 0.0657 0.0664 0.0681 0.0695 0.0706 0.0721 

[TRAIN] Epoch[3](905/1500); Loss: 0.117995; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2322 0.2263 0.1271 0.1300 0.0899 0.0919 0.0920 0.0915 0.0900 0.0925 0.0979 0.0988 0.1005 0.1040 0.1104 0.1128 

[TRAIN] Epoch[3](906/1500); Loss: 0.104863; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1300 0.1163 0.1077 0.1032 0.0988 0.0959 0.0959 0.0957 0.0965 0.0979 0.1010 0.1030 0.1046 0.1077 0.1107 0.1129 

[TRAIN] Epoch[3](907/1500); Loss: 0.097351; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1431 0.1333 0.0995 0.1002 0.1043 0.0918 0.0829 0.0836 0.0828 0.0836 0.0866 0.0886 0.0908 0.0928 0.0951 0.0986 

[TRAIN] Epoch[3](908/1500); Loss: 0.161915; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1835 0.1865 0.1355 0.1465 0.1598 0.1517 0.1418 0.1462 0.1520 0.1574 0.1580 0.1632 0.1671 0.1735 0.1809 0.1869 

[TRAIN] Epoch[3](909/1500); Loss: 0.108952; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1859 0.1812 0.0926 0.1099 0.1219 0.1024 0.0825 0.0848 0.0880 0.0884 0.0898 0.0949 0.0987 0.1016 0.1077 0.1130 

[TRAIN] Epoch[3](910/1500); Loss: 0.082300; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0998 0.0905 0.0785 0.0774 0.0785 0.0711 0.0695 0.0710 0.0738 0.0758 0.0777 0.0817 0.0861 0.0906 0.0950 0.0998 

[TRAIN] Epoch[3](911/1500); Loss: 0.086547; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1538 0.1220 0.0982 0.0849 0.0788 0.0767 0.0746 0.0738 0.0747 0.0763 0.0754 0.0761 0.0777 0.0795 0.0803 0.0818 

[TRAIN] Epoch[3](912/1500); Loss: 0.105142; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2083 0.1740 0.1284 0.1094 0.0984 0.0900 0.0841 0.0836 0.0832 0.0826 0.0851 0.0856 0.0868 0.0907 0.0954 0.0967 

[TRAIN] Epoch[3](913/1500); Loss: 0.090218; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1100 0.1025 0.0910 0.0901 0.0884 0.0860 0.0834 0.0827 0.0836 0.0846 0.0860 0.0869 0.0888 0.0910 0.0928 0.0956 

[TRAIN] Epoch[3](914/1500); Loss: 0.057554; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1346 0.0990 0.0771 0.0636 0.0442 0.0361 0.0372 0.0409 0.0375 0.0400 0.0441 0.0467 0.0483 0.0532 0.0563 0.0620 

[TRAIN] Epoch[3](915/1500); Loss: 0.141929; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1707 0.1711 0.1560 0.1532 0.1517 0.1465 0.1409 0.1370 0.1307 0.1288 0.1288 0.1285 0.1298 0.1314 0.1321 0.1335 

[TRAIN] Epoch[3](916/1500); Loss: 0.161890; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2154 0.1981 0.1761 0.1675 0.1590 0.1537 0.1495 0.1481 0.1472 0.1485 0.1503 0.1518 0.1530 0.1547 0.1573 0.1601 

[TRAIN] Epoch[3](917/1500); Loss: 0.093817; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1663 0.1648 0.0765 0.0975 0.0964 0.0795 0.0730 0.0764 0.0756 0.0761 0.0813 0.0810 0.0827 0.0877 0.0922 0.0941 

[TRAIN] Epoch[3](918/1500); Loss: 0.166287; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2181 0.1978 0.1775 0.1675 0.1606 0.1588 0.1582 0.1569 0.1557 0.1554 0.1556 0.1562 0.1579 0.1595 0.1608 0.1638 

[TRAIN] Epoch[3](919/1500); Loss: 0.110214; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2217 0.2216 0.0396 0.1016 0.1014 0.0806 0.0726 0.0768 0.0829 0.0891 0.0932 0.1008 0.1087 0.1174 0.1233 0.1320 

[TRAIN] Epoch[3](920/1500); Loss: 0.102051; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1231 0.1147 0.1100 0.1030 0.0994 0.0984 0.0978 0.0967 0.0961 0.0962 0.0967 0.0974 0.0982 0.0998 0.1016 0.1036 

[TRAIN] Epoch[3](921/1500); Loss: 0.150037; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2482 0.2414 0.1485 0.1750 0.1757 0.1613 0.1403 0.1324 0.1216 0.1142 0.1117 0.1147 0.1215 0.1250 0.1305 0.1387 

[TRAIN] Epoch[3](922/1500); Loss: 0.097067; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1079 0.1107 0.0989 0.0986 0.0927 0.0918 0.0911 0.0899 0.0878 0.0896 0.0906 0.0938 0.0968 0.1003 0.1039 0.1088 

[TRAIN] Epoch[3](923/1500); Loss: 0.105325; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1226 0.1174 0.1116 0.1074 0.1060 0.1056 0.1028 0.1007 0.0996 0.0992 0.0989 0.1001 0.1005 0.1022 0.1041 0.1061 

[TRAIN] Epoch[3](924/1500); Loss: 0.130620; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1606 0.1534 0.1431 0.1387 0.1298 0.1249 0.1228 0.1223 0.1215 0.1215 0.1225 0.1223 0.1237 0.1256 0.1278 0.1295 

[TRAIN] Epoch[3](925/1500); Loss: 0.199459; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2862 0.2624 0.2273 0.2166 0.2045 0.1872 0.1771 0.1756 0.1745 0.1765 0.1771 0.1784 0.1819 0.1852 0.1873 0.1935 

[TRAIN] Epoch[3](926/1500); Loss: 0.130745; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1706 0.1589 0.1335 0.1312 0.1318 0.1272 0.1223 0.1219 0.1214 0.1219 0.1224 0.1235 0.1236 0.1256 0.1273 0.1289 

[TRAIN] Epoch[3](927/1500); Loss: 0.174083; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2162 0.2039 0.1897 0.1822 0.1764 0.1725 0.1692 0.1677 0.1655 0.1631 0.1629 0.1636 0.1636 0.1628 0.1626 0.1634 

[TRAIN] Epoch[3](928/1500); Loss: 0.105809; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1216 0.1074 0.1061 0.1030 0.0950 0.0933 0.0951 0.0988 0.0989 0.1007 0.1031 0.1058 0.1103 0.1141 0.1173 0.1223 

[TRAIN] Epoch[3](929/1500); Loss: 0.127320; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1378 0.1357 0.0968 0.1132 0.1266 0.1219 0.1154 0.1179 0.1203 0.1238 0.1251 0.1308 0.1359 0.1408 0.1450 0.1501 

[TRAIN] Epoch[3](930/1500); Loss: 0.142471; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1575 0.1529 0.1481 0.1479 0.1462 0.1428 0.1367 0.1344 0.1340 0.1354 0.1358 0.1365 0.1392 0.1424 0.1441 0.1459 

[TRAIN] Epoch[3](931/1500); Loss: 0.129769; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1477 0.1457 0.1085 0.1231 0.1390 0.1319 0.1220 0.1223 0.1210 0.1235 0.1231 0.1264 0.1298 0.1339 0.1373 0.1411 

[TRAIN] Epoch[3](932/1500); Loss: 0.133687; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1547 0.1541 0.1331 0.1387 0.1336 0.1306 0.1272 0.1256 0.1225 0.1237 0.1257 0.1280 0.1301 0.1335 0.1370 0.1407 

[TRAIN] Epoch[3](933/1500); Loss: 0.121649; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1431 0.1401 0.1334 0.1301 0.1215 0.1186 0.1181 0.1157 0.1152 0.1155 0.1156 0.1153 0.1149 0.1159 0.1165 0.1170 

[TRAIN] Epoch[3](934/1500); Loss: 0.167281; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2066 0.1967 0.1801 0.1790 0.1743 0.1680 0.1609 0.1589 0.1570 0.1535 0.1537 0.1548 0.1556 0.1574 0.1586 0.1613 

[TRAIN] Epoch[3](935/1500); Loss: 0.132221; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1682 0.1621 0.1418 0.1431 0.1383 0.1328 0.1286 0.1249 0.1208 0.1210 0.1197 0.1204 0.1203 0.1227 0.1238 0.1270 

[TRAIN] Epoch[3](936/1500); Loss: 0.131935; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1631 0.1541 0.1430 0.1385 0.1286 0.1249 0.1242 0.1207 0.1214 0.1221 0.1239 0.1250 0.1266 0.1287 0.1315 0.1347 

[TRAIN] Epoch[3](937/1500); Loss: 0.088000; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0958 0.0842 0.0815 0.0877 0.0824 0.0807 0.0812 0.0850 0.0849 0.0865 0.0886 0.0903 0.0910 0.0942 0.0956 0.0985 

[TRAIN] Epoch[3](938/1500); Loss: 0.101841; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2385 0.2071 0.1492 0.1302 0.1052 0.0784 0.0677 0.0725 0.0713 0.0687 0.0697 0.0729 0.0727 0.0725 0.0754 0.0775 

[TRAIN] Epoch[3](939/1500); Loss: 0.100754; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1535 0.1287 0.1168 0.1062 0.0954 0.0933 0.0928 0.0897 0.0895 0.0911 0.0899 0.0897 0.0922 0.0929 0.0940 0.0964 

[TRAIN] Epoch[3](940/1500); Loss: 0.065293; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0673 0.0734 0.0571 0.0587 0.0665 0.0602 0.0539 0.0565 0.0607 0.0608 0.0622 0.0650 0.0718 0.0737 0.0765 0.0805 

[TRAIN] Epoch[3](941/1500); Loss: 0.158819; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2266 0.2122 0.1772 0.1755 0.1685 0.1539 0.1436 0.1396 0.1372 0.1381 0.1405 0.1421 0.1438 0.1451 0.1473 0.1500 

[TRAIN] Epoch[3](942/1500); Loss: 0.075798; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1315 0.1271 0.0854 0.0883 0.0729 0.0643 0.0627 0.0604 0.0599 0.0628 0.0625 0.0627 0.0657 0.0675 0.0680 0.0710 

[TRAIN] Epoch[3](943/1500); Loss: 0.125932; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2403 0.2327 0.1308 0.1543 0.1568 0.1304 0.1027 0.0945 0.0894 0.0884 0.0917 0.0944 0.0966 0.0999 0.1045 0.1074 

[TRAIN] Epoch[3](944/1500); Loss: 0.142436; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1771 0.1679 0.1430 0.1411 0.1379 0.1343 0.1327 0.1329 0.1336 0.1353 0.1364 0.1370 0.1396 0.1412 0.1431 0.1459 

[TRAIN] Epoch[3](945/1500); Loss: 0.091811; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1223 0.1061 0.0884 0.0856 0.0866 0.0864 0.0819 0.0838 0.0862 0.0847 0.0871 0.0887 0.0911 0.0942 0.0962 0.0995 

[TRAIN] Epoch[3](946/1500); Loss: 0.123737; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.2043 0.1684 0.1414 0.1267 0.1178 0.1133 0.1103 0.1096 0.1094 0.1093 0.1092 0.1097 0.1112 0.1123 0.1127 0.1143 

[TRAIN] Epoch[3](947/1500); Loss: 0.109852; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1305 0.1233 0.1131 0.1108 0.1084 0.1070 0.1060 0.1054 0.1048 0.1055 0.1056 0.1056 0.1063 0.1075 0.1084 0.1096 

[TRAIN] Epoch[3](948/1500); Loss: 0.099951; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1082 0.1039 0.1007 0.0998 0.0991 0.0979 0.0973 0.0967 0.0970 0.0979 0.0976 0.0986 0.0996 0.1006 0.1017 0.1027 

[TRAIN] Epoch[3](949/1500); Loss: 0.096368; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1895 0.1702 0.1076 0.1038 0.0898 0.0812 0.0789 0.0789 0.0788 0.0790 0.0791 0.0793 0.0804 0.0814 0.0814 0.0829 

[TRAIN] Epoch[3](950/1500); Loss: 0.088117; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0981 0.0951 0.0921 0.0890 0.0859 0.0851 0.0855 0.0846 0.0845 0.0851 0.0860 0.0860 0.0870 0.0883 0.0887 0.0888 

[TRAIN] Epoch[3](951/1500); Loss: 0.110247; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.3011 0.2763 0.1336 0.1407 0.1100 0.0807 0.0572 0.0597 0.0642 0.0682 0.0683 0.0721 0.0771 0.0798 0.0839 0.0911 

[TRAIN] Epoch[3](952/1500); Loss: 0.091611; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1178 0.1046 0.0968 0.0917 0.0870 0.0857 0.0850 0.0856 0.0856 0.0861 0.0871 0.0881 0.0886 0.0904 0.0924 0.0933 

[TRAIN] Epoch[3](953/1500); Loss: 0.109949; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1258 0.1198 0.1071 0.1160 0.1151 0.1075 0.1026 0.1039 0.1027 0.1027 0.1049 0.1074 0.1081 0.1095 0.1119 0.1141 

[TRAIN] Epoch[3](954/1500); Loss: 0.065982; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0854 0.0778 0.0775 0.0649 0.0613 0.0635 0.0599 0.0593 0.0604 0.0607 0.0597 0.0615 0.0644 0.0651 0.0655 0.0689 

[TRAIN] Epoch[3](955/1500); Loss: 0.127492; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.3352 0.2797 0.2271 0.1866 0.1497 0.1132 0.0805 0.0669 0.0704 0.0730 0.0732 0.0710 0.0743 0.0794 0.0783 0.0813 

[TRAIN] Epoch[3](956/1500); Loss: 0.059005; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1699 0.1108 0.0611 0.0438 0.0454 0.0444 0.0447 0.0403 0.0419 0.0447 0.0429 0.0442 0.0494 0.0504 0.0516 0.0586 

[TRAIN] Epoch[3](957/1500); Loss: 0.103725; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1573 0.1431 0.1008 0.0996 0.1076 0.1054 0.0914 0.0909 0.0887 0.0895 0.0922 0.0930 0.0966 0.1003 0.1001 0.1032 

[TRAIN] Epoch[3](958/1500); Loss: 0.122518; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2164 0.1940 0.1366 0.1285 0.1200 0.1162 0.1105 0.1058 0.1032 0.1012 0.1013 0.1022 0.1038 0.1049 0.1071 0.1087 

[TRAIN] Epoch[3](959/1500); Loss: 0.085020; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.0999 0.0921 0.0854 0.0838 0.0828 0.0808 0.0811 0.0814 0.0814 0.0818 0.0824 0.0838 0.0848 0.0851 0.0857 0.0880 

[TRAIN] Epoch[3](960/1500); Loss: 0.144597; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2414 0.2238 0.1645 0.1607 0.1486 0.1347 0.1236 0.1214 0.1207 0.1214 0.1226 0.1231 0.1250 0.1257 0.1278 0.1285 

[TRAIN] Epoch[3](961/1500); Loss: 0.135538; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2576 0.2198 0.1816 0.1593 0.1391 0.1244 0.1139 0.1085 0.1084 0.1074 0.1075 0.1065 0.1072 0.1084 0.1089 0.1103 

[TRAIN] Epoch[3](962/1500); Loss: 0.090556; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1391 0.1275 0.0852 0.0956 0.0987 0.0888 0.0811 0.0792 0.0769 0.0765 0.0784 0.0808 0.0811 0.0839 0.0871 0.0891 

[TRAIN] Epoch[3](963/1500); Loss: 0.156858; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2321 0.2083 0.1820 0.1675 0.1553 0.1483 0.1446 0.1423 0.1408 0.1400 0.1402 0.1403 0.1409 0.1413 0.1425 0.1432 

[TRAIN] Epoch[3](964/1500); Loss: 0.139374; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1774 0.1663 0.1432 0.1434 0.1450 0.1406 0.1337 0.1311 0.1303 0.1302 0.1298 0.1305 0.1307 0.1311 0.1325 0.1340 

[TRAIN] Epoch[3](965/1500); Loss: 0.116490; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1600 0.1562 0.1050 0.1161 0.1250 0.1174 0.1072 0.1059 0.1044 0.1039 0.1055 0.1076 0.1094 0.1115 0.1134 0.1151 

[TRAIN] Epoch[3](966/1500); Loss: 0.091782; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1418 0.1327 0.0860 0.0940 0.0928 0.0833 0.0766 0.0780 0.0777 0.0777 0.0798 0.0843 0.0864 0.0884 0.0928 0.0962 

[TRAIN] Epoch[3](967/1500); Loss: 0.125134; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1814 0.1650 0.1135 0.1201 0.1336 0.1251 0.1142 0.1132 0.1114 0.1118 0.1118 0.1141 0.1177 0.1207 0.1225 0.1260 

[TRAIN] Epoch[3](968/1500); Loss: 0.140567; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2424 0.2168 0.1848 0.1675 0.1524 0.1407 0.1293 0.1194 0.1131 0.1117 0.1121 0.1127 0.1112 0.1103 0.1116 0.1130 

[TRAIN] Epoch[3](969/1500); Loss: 0.139805; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1650 0.1533 0.1434 0.1402 0.1385 0.1364 0.1356 0.1343 0.1342 0.1346 0.1351 0.1355 0.1370 0.1369 0.1375 0.1393 

[TRAIN] Epoch[3](970/1500); Loss: 0.144999; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2145 0.1909 0.1676 0.1533 0.1443 0.1378 0.1340 0.1316 0.1304 0.1306 0.1308 0.1301 0.1301 0.1314 0.1316 0.1310 

[TRAIN] Epoch[3](971/1500); Loss: 0.115425; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1386 0.1323 0.1106 0.1177 0.1227 0.1159 0.1097 0.1094 0.1083 0.1079 0.1083 0.1114 0.1113 0.1126 0.1144 0.1159 

[TRAIN] Epoch[3](972/1500); Loss: 0.075917; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1540 0.1314 0.0959 0.0806 0.0687 0.0628 0.0611 0.0609 0.0598 0.0606 0.0609 0.0616 0.0622 0.0635 0.0644 0.0662 

[TRAIN] Epoch[3](973/1500); Loss: 0.088518; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1525 0.1395 0.0991 0.0979 0.0905 0.0812 0.0769 0.0747 0.0741 0.0745 0.0741 0.0747 0.0755 0.0760 0.0767 0.0783 

[TRAIN] Epoch[3](974/1500); Loss: 0.075899; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1562 0.1208 0.0937 0.0768 0.0704 0.0660 0.0617 0.0590 0.0604 0.0604 0.0612 0.0616 0.0640 0.0651 0.0676 0.0696 

[TRAIN] Epoch[3](975/1500); Loss: 0.103144; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1541 0.1366 0.1029 0.1095 0.1057 0.0984 0.0919 0.0908 0.0899 0.0919 0.0920 0.0928 0.0953 0.0981 0.0992 0.1011 

[TRAIN] Epoch[3](976/1500); Loss: 0.087613; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2511 0.1961 0.1450 0.1042 0.0698 0.0537 0.0587 0.0587 0.0556 0.0527 0.0560 0.0585 0.0566 0.0593 0.0637 0.0621 

[TRAIN] Epoch[3](977/1500); Loss: 0.088766; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1818 0.1520 0.1067 0.0970 0.0881 0.0789 0.0729 0.0700 0.0702 0.0701 0.0696 0.0708 0.0711 0.0716 0.0749 0.0745 

[TRAIN] Epoch[3](978/1500); Loss: 0.147349; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1749 0.1633 0.1563 0.1508 0.1475 0.1449 0.1432 0.1423 0.1412 0.1411 0.1413 0.1415 0.1417 0.1418 0.1428 0.1430 

[TRAIN] Epoch[3](979/1500); Loss: 0.150451; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2350 0.2045 0.1775 0.1607 0.1490 0.1420 0.1371 0.1352 0.1343 0.1332 0.1327 0.1324 0.1328 0.1325 0.1335 0.1348 

[TRAIN] Epoch[3](980/1500); Loss: 0.065979; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1449 0.1029 0.0730 0.0607 0.0561 0.0561 0.0554 0.0554 0.0544 0.0551 0.0557 0.0558 0.0567 0.0584 0.0572 0.0581 

[TRAIN] Epoch[3](981/1500); Loss: 0.073026; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0983 0.0851 0.0782 0.0718 0.0683 0.0681 0.0688 0.0687 0.0681 0.0679 0.0691 0.0690 0.0696 0.0724 0.0724 0.0727 

[TRAIN] Epoch[3](982/1500); Loss: 0.081712; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1185 0.1154 0.0918 0.0887 0.0853 0.0785 0.0745 0.0736 0.0721 0.0706 0.0713 0.0724 0.0715 0.0733 0.0750 0.0751 

[TRAIN] Epoch[3](983/1500); Loss: 0.099811; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1086 0.1010 0.1074 0.1021 0.0962 0.0953 0.0967 0.0957 0.0938 0.0954 0.1000 0.0978 0.0975 0.0997 0.1046 0.1052 

[TRAIN] Epoch[3](984/1500); Loss: 0.136580; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1751 0.1580 0.1414 0.1354 0.1340 0.1331 0.1318 0.1305 0.1305 0.1304 0.1294 0.1300 0.1303 0.1312 0.1322 0.1318 

[TRAIN] Epoch[3](985/1500); Loss: 0.112073; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1349 0.1263 0.1127 0.1115 0.1101 0.1089 0.1081 0.1080 0.1091 0.1084 0.1077 0.1092 0.1086 0.1088 0.1107 0.1102 

[TRAIN] Epoch[3](986/1500); Loss: 0.111270; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2437 0.2033 0.1507 0.1333 0.1183 0.1040 0.0907 0.0808 0.0787 0.0807 0.0791 0.0789 0.0814 0.0851 0.0854 0.0862 

[TRAIN] Epoch[3](987/1500); Loss: 0.050560; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1125 0.0836 0.0665 0.0549 0.0478 0.0410 0.0366 0.0392 0.0404 0.0378 0.0380 0.0415 0.0403 0.0400 0.0439 0.0451 

[TRAIN] Epoch[3](988/1500); Loss: 0.136860; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2045 0.1824 0.1562 0.1442 0.1348 0.1288 0.1242 0.1207 0.1199 0.1216 0.1231 0.1240 0.1230 0.1242 0.1279 0.1303 

[TRAIN] Epoch[3](989/1500); Loss: 0.103991; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1442 0.1347 0.1027 0.0976 0.0984 0.0946 0.0947 0.0926 0.0925 0.0963 0.0969 0.0976 0.1006 0.1051 0.1065 0.1088 

[TRAIN] Epoch[3](990/1500); Loss: 0.063889; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.0875 0.0761 0.0723 0.0690 0.0632 0.0603 0.0587 0.0586 0.0572 0.0570 0.0582 0.0584 0.0593 0.0607 0.0621 0.0637 

[TRAIN] Epoch[3](991/1500); Loss: 0.136223; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1878 0.1744 0.1413 0.1358 0.1320 0.1315 0.1284 0.1257 0.1259 0.1256 0.1240 0.1276 0.1270 0.1288 0.1319 0.1318 

[TRAIN] Epoch[3](992/1500); Loss: 0.126668; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1559 0.1467 0.1318 0.1295 0.1268 0.1251 0.1223 0.1207 0.1209 0.1197 0.1198 0.1202 0.1206 0.1203 0.1222 0.1242 

[TRAIN] Epoch[3](993/1500); Loss: 0.112845; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1680 0.1475 0.1178 0.1120 0.1080 0.1054 0.1055 0.1047 0.1047 0.1053 0.1038 0.1033 0.1049 0.1047 0.1044 0.1056 

[TRAIN] Epoch[3](994/1500); Loss: 0.056036; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1390 0.1043 0.0789 0.0592 0.0466 0.0423 0.0412 0.0436 0.0415 0.0393 0.0402 0.0434 0.0419 0.0424 0.0452 0.0477 

[TRAIN] Epoch[3](995/1500); Loss: 0.049737; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0673 0.0553 0.0516 0.0472 0.0464 0.0461 0.0468 0.0469 0.0467 0.0467 0.0482 0.0487 0.0481 0.0494 0.0504 0.0500 

[TRAIN] Epoch[3](996/1500); Loss: 0.140447; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2004 0.1786 0.1506 0.1396 0.1313 0.1310 0.1296 0.1298 0.1284 0.1321 0.1311 0.1305 0.1310 0.1348 0.1343 0.1340 

[TRAIN] Epoch[3](997/1500); Loss: 0.227994; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.3806 0.3411 0.3024 0.2721 0.2490 0.2254 0.2040 0.1918 0.1844 0.1829 0.1832 0.1860 0.1850 0.1833 0.1857 0.1911 

[TRAIN] Epoch[3](998/1500); Loss: 0.137968; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1571 0.1456 0.1354 0.1358 0.1362 0.1348 0.1337 0.1342 0.1350 0.1351 0.1351 0.1360 0.1374 0.1379 0.1384 0.1398 

[TRAIN] Epoch[3](999/1500); Loss: 0.080641; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1273 0.1017 0.0835 0.0763 0.0764 0.0755 0.0740 0.0735 0.0735 0.0728 0.0745 0.0754 0.0753 0.0748 0.0769 0.0787 

[TRAIN] Epoch[3](1000/1500); Loss: 0.119649; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2163 0.1847 0.1529 0.1335 0.1168 0.1048 0.0992 0.0988 0.1017 0.1002 0.0984 0.0994 0.1016 0.1003 0.1007 0.1050 

[TRAIN] Epoch[3](1001/1500); Loss: 0.117503; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1557 0.1431 0.1252 0.1216 0.1157 0.1127 0.1116 0.1116 0.1108 0.1097 0.1083 0.1097 0.1107 0.1097 0.1117 0.1125 

[TRAIN] Epoch[3](1002/1500); Loss: 0.117451; Backpropagation: 0.0998 sec; Batch: 0.4493 sec
0.2691 0.2218 0.1781 0.1570 0.1414 0.1203 0.0990 0.0829 0.0781 0.0765 0.0749 0.0749 0.0764 0.0743 0.0758 0.0787 

[TRAIN] Epoch[3](1003/1500); Loss: 0.069283; Backpropagation: 0.0932 sec; Batch: 0.4252 sec
0.1664 0.1252 0.0940 0.0744 0.0610 0.0552 0.0538 0.0534 0.0531 0.0506 0.0512 0.0538 0.0520 0.0525 0.0559 0.0561 

[TRAIN] Epoch[3](1004/1500); Loss: 0.093754; Backpropagation: 0.0929 sec; Batch: 0.4246 sec
0.1271 0.1153 0.1126 0.1012 0.0928 0.0902 0.0900 0.0861 0.0823 0.0837 0.0858 0.0847 0.0838 0.0866 0.0896 0.0885 

[TRAIN] Epoch[3](1005/1500); Loss: 0.074632; Backpropagation: 0.0928 sec; Batch: 0.4245 sec
0.1045 0.0816 0.0748 0.0728 0.0749 0.0734 0.0710 0.0706 0.0722 0.0713 0.0702 0.0708 0.0717 0.0708 0.0713 0.0721 

[TRAIN] Epoch[3](1006/1500); Loss: 0.066622; Backpropagation: 0.0921 sec; Batch: 0.4248 sec
0.0736 0.0672 0.0659 0.0686 0.0687 0.0642 0.0607 0.0649 0.0678 0.0643 0.0625 0.0671 0.0677 0.0648 0.0661 0.0718 

[TRAIN] Epoch[3](1007/1500); Loss: 0.057096; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0746 0.0657 0.0781 0.0602 0.0540 0.0496 0.0548 0.0532 0.0489 0.0491 0.0550 0.0527 0.0504 0.0536 0.0578 0.0558 

[TRAIN] Epoch[3](1008/1500); Loss: 0.116061; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1360 0.1279 0.1165 0.1165 0.1181 0.1152 0.1126 0.1133 0.1120 0.1109 0.1128 0.1122 0.1117 0.1141 0.1133 0.1139 

[TRAIN] Epoch[3](1009/1500); Loss: 0.110010; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1718 0.1433 0.1216 0.1111 0.1056 0.1013 0.0995 0.0995 0.0993 0.0981 0.0980 0.1009 0.1014 0.1011 0.1023 0.1051 

[TRAIN] Epoch[3](1010/1500); Loss: 0.097802; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1121 0.1049 0.1000 0.0982 0.0953 0.0939 0.0949 0.0957 0.0944 0.0936 0.0941 0.0957 0.0966 0.0968 0.0983 0.1003 

[TRAIN] Epoch[3](1011/1500); Loss: 0.128313; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2122 0.1926 0.1453 0.1372 0.1294 0.1237 0.1199 0.1158 0.1120 0.1100 0.1097 0.1086 0.1075 0.1092 0.1100 0.1100 

[TRAIN] Epoch[3](1012/1500); Loss: 0.120887; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1941 0.1622 0.1281 0.1192 0.1157 0.1131 0.1102 0.1089 0.1089 0.1097 0.1098 0.1091 0.1104 0.1104 0.1121 0.1124 

[TRAIN] Epoch[3](1013/1500); Loss: 0.107596; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1935 0.1623 0.1288 0.1154 0.1065 0.0999 0.0976 0.0941 0.0906 0.0888 0.0912 0.0917 0.0900 0.0881 0.0894 0.0934 

[TRAIN] Epoch[3](1014/1500); Loss: 0.118655; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1536 0.1397 0.1261 0.1238 0.1196 0.1173 0.1155 0.1140 0.1107 0.1103 0.1123 0.1102 0.1094 0.1130 0.1115 0.1116 

[TRAIN] Epoch[3](1015/1500); Loss: 0.102017; Backpropagation: 0.0915 sec; Batch: 0.4234 sec
0.1272 0.1181 0.1083 0.1038 0.1007 0.0989 0.0987 0.0979 0.0974 0.0971 0.0962 0.0965 0.0968 0.0977 0.0979 0.0992 

[TRAIN] Epoch[3](1016/1500); Loss: 0.092288; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1317 0.1152 0.1080 0.0986 0.0882 0.0836 0.0862 0.0851 0.0830 0.0822 0.0837 0.0839 0.0850 0.0865 0.0876 0.0880 

[TRAIN] Epoch[3](1017/1500); Loss: 0.103797; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1144 0.1073 0.1060 0.1039 0.1018 0.1014 0.1026 0.1017 0.1009 0.1015 0.1019 0.1018 0.1027 0.1033 0.1042 0.1055 

[TRAIN] Epoch[3](1018/1500); Loss: 0.095965; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2408 0.1950 0.1515 0.1237 0.0959 0.0694 0.0602 0.0635 0.0670 0.0642 0.0638 0.0675 0.0667 0.0661 0.0691 0.0710 

[TRAIN] Epoch[3](1019/1500); Loss: 0.174176; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2292 0.2128 0.1988 0.1871 0.1804 0.1732 0.1659 0.1621 0.1609 0.1606 0.1586 0.1581 0.1594 0.1598 0.1597 0.1602 

[TRAIN] Epoch[3](1020/1500); Loss: 0.116617; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1779 0.1602 0.1367 0.1243 0.1142 0.1089 0.1029 0.1009 0.0987 0.1005 0.1006 0.1018 0.1052 0.1080 0.1100 0.1149 

[TRAIN] Epoch[3](1021/1500); Loss: 0.090386; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2142 0.1797 0.1016 0.0909 0.0802 0.0723 0.0682 0.0674 0.0691 0.0687 0.0680 0.0699 0.0725 0.0724 0.0746 0.0765 

[TRAIN] Epoch[3](1022/1500); Loss: 0.136031; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1564 0.1475 0.1391 0.1372 0.1397 0.1377 0.1340 0.1312 0.1338 0.1340 0.1324 0.1298 0.1302 0.1322 0.1313 0.1301 

[TRAIN] Epoch[3](1023/1500); Loss: 0.051935; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0622 0.0556 0.0514 0.0529 0.0535 0.0506 0.0484 0.0491 0.0501 0.0496 0.0500 0.0498 0.0506 0.0524 0.0518 0.0530 

[TRAIN] Epoch[3](1024/1500); Loss: 0.075948; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.1050 0.0874 0.0833 0.0793 0.0721 0.0704 0.0718 0.0718 0.0701 0.0709 0.0706 0.0699 0.0733 0.0728 0.0726 0.0738 

[TRAIN] Epoch[3](1025/1500); Loss: 0.098705; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1699 0.1603 0.1182 0.1090 0.0942 0.0906 0.0875 0.0854 0.0840 0.0826 0.0836 0.0821 0.0822 0.0823 0.0835 0.0838 

[TRAIN] Epoch[3](1026/1500); Loss: 0.108073; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2015 0.1630 0.1307 0.1142 0.1021 0.0930 0.0892 0.0908 0.0908 0.0902 0.0911 0.0933 0.0929 0.0938 0.0960 0.0966 

[TRAIN] Epoch[3](1027/1500); Loss: 0.100487; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1421 0.1322 0.1075 0.1006 0.0948 0.0933 0.0895 0.0885 0.0888 0.0913 0.0916 0.0915 0.0943 0.0986 0.1004 0.1026 

[TRAIN] Epoch[3](1028/1500); Loss: 0.091951; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2952 0.2699 0.1167 0.0938 0.0504 0.0561 0.0504 0.0563 0.0566 0.0525 0.0561 0.0619 0.0608 0.0602 0.0653 0.0689 

[TRAIN] Epoch[3](1029/1500); Loss: 0.156410; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1720 0.1638 0.1612 0.1613 0.1587 0.1566 0.1550 0.1544 0.1537 0.1530 0.1522 0.1524 0.1525 0.1519 0.1518 0.1521 

[TRAIN] Epoch[3](1030/1500); Loss: 0.073062; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1341 0.1096 0.0803 0.0791 0.0706 0.0623 0.0583 0.0618 0.0640 0.0615 0.0608 0.0634 0.0649 0.0641 0.0643 0.0699 

[TRAIN] Epoch[3](1031/1500); Loss: 0.141104; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2003 0.1858 0.1638 0.1536 0.1410 0.1386 0.1350 0.1301 0.1267 0.1256 0.1262 0.1255 0.1270 0.1266 0.1253 0.1268 

[TRAIN] Epoch[3](1032/1500); Loss: 0.060568; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.0786 0.0653 0.0705 0.0673 0.0603 0.0548 0.0524 0.0546 0.0542 0.0543 0.0543 0.0562 0.0586 0.0603 0.0626 0.0648 

[TRAIN] Epoch[3](1033/1500); Loss: 0.108791; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1740 0.1574 0.1275 0.1151 0.0979 0.0981 0.1009 0.0998 0.0971 0.0943 0.0971 0.0971 0.0944 0.0948 0.0967 0.0984 

[TRAIN] Epoch[3](1034/1500); Loss: 0.103967; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1163 0.1094 0.1111 0.1089 0.1038 0.1010 0.1014 0.1016 0.1005 0.0994 0.0989 0.1008 0.1017 0.1020 0.1025 0.1041 

[TRAIN] Epoch[3](1035/1500); Loss: 0.143947; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2671 0.2265 0.1874 0.1726 0.1680 0.1495 0.1292 0.1179 0.1114 0.1097 0.1112 0.1098 0.1088 0.1089 0.1117 0.1137 

[TRAIN] Epoch[3](1036/1500); Loss: 0.118741; Backpropagation: 0.0918 sec; Batch: 0.4245 sec
0.1375 0.1306 0.1228 0.1182 0.1174 0.1167 0.1142 0.1129 0.1132 0.1160 0.1159 0.1164 0.1158 0.1155 0.1178 0.1189 

[TRAIN] Epoch[3](1037/1500); Loss: 0.083563; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1296 0.1228 0.0984 0.0951 0.0762 0.0755 0.0733 0.0708 0.0694 0.0710 0.0732 0.0738 0.0730 0.0761 0.0795 0.0792 

[TRAIN] Epoch[3](1038/1500); Loss: 0.112954; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1474 0.1366 0.1285 0.1218 0.1168 0.1140 0.1107 0.1060 0.1037 0.1031 0.1027 0.1029 0.1028 0.1025 0.1031 0.1046 

[TRAIN] Epoch[3](1039/1500); Loss: 0.099279; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1325 0.1193 0.1131 0.1103 0.1000 0.0948 0.0920 0.0922 0.0910 0.0908 0.0904 0.0908 0.0911 0.0922 0.0932 0.0950 

[TRAIN] Epoch[3](1040/1500); Loss: 0.051590; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.0548 0.0426 0.0439 0.0602 0.0564 0.0494 0.0446 0.0457 0.0517 0.0511 0.0497 0.0515 0.0540 0.0545 0.0562 0.0591 

[TRAIN] Epoch[3](1041/1500); Loss: 0.080266; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0788 0.0783 0.0899 0.0866 0.0766 0.0755 0.0783 0.0785 0.0764 0.0770 0.0793 0.0792 0.0806 0.0818 0.0829 0.0845 

[TRAIN] Epoch[3](1042/1500); Loss: 0.157635; Backpropagation: 0.0915 sec; Batch: 0.4235 sec
0.1653 0.1627 0.1639 0.1603 0.1570 0.1564 0.1552 0.1554 0.1560 0.1566 0.1554 0.1546 0.1543 0.1558 0.1566 0.1566 

[TRAIN] Epoch[3](1043/1500); Loss: 0.123984; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2021 0.1888 0.1167 0.1153 0.1228 0.1188 0.1113 0.1097 0.1134 0.1149 0.1108 0.1089 0.1104 0.1141 0.1126 0.1131 

[TRAIN] Epoch[3](1044/1500); Loss: 0.161031; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2417 0.2154 0.1754 0.1700 0.1660 0.1560 0.1449 0.1414 0.1443 0.1450 0.1436 0.1429 0.1447 0.1462 0.1491 0.1497 

[TRAIN] Epoch[3](1045/1500); Loss: 0.164472; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2044 0.1913 0.1814 0.1726 0.1693 0.1659 0.1599 0.1554 0.1537 0.1541 0.1540 0.1526 0.1526 0.1550 0.1550 0.1544 

[TRAIN] Epoch[3](1046/1500); Loss: 0.107629; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1543 0.1352 0.1109 0.1115 0.1101 0.1075 0.1010 0.0984 0.0996 0.0993 0.0983 0.0974 0.0972 0.0999 0.1003 0.1012 

[TRAIN] Epoch[3](1047/1500); Loss: 0.113712; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2190 0.2124 0.0881 0.0964 0.1081 0.0992 0.0914 0.0907 0.1026 0.1029 0.0971 0.0951 0.0990 0.1062 0.1056 0.1057 

[TRAIN] Epoch[3](1048/1500); Loss: 0.081648; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1318 0.1201 0.0927 0.0847 0.0801 0.0799 0.0764 0.0721 0.0699 0.0706 0.0710 0.0698 0.0706 0.0715 0.0717 0.0734 

[TRAIN] Epoch[3](1049/1500); Loss: 0.065151; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0838 0.0774 0.0691 0.0568 0.0533 0.0730 0.0692 0.0614 0.0547 0.0619 0.0649 0.0609 0.0594 0.0660 0.0659 0.0646 

[TRAIN] Epoch[3](1050/1500); Loss: 0.108034; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1125 0.1011 0.1055 0.1080 0.1050 0.1022 0.1038 0.1073 0.1063 0.1064 0.1067 0.1092 0.1110 0.1123 0.1144 0.1167 

[TRAIN] Epoch[3](1051/1500); Loss: 0.090886; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.1371 0.1219 0.1265 0.1125 0.0946 0.0795 0.0773 0.0802 0.0788 0.0752 0.0741 0.0762 0.0784 0.0787 0.0802 0.0832 

[TRAIN] Epoch[3](1052/1500); Loss: 0.145343; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2277 0.1979 0.1708 0.1646 0.1616 0.1502 0.1359 0.1267 0.1247 0.1246 0.1240 0.1236 0.1228 0.1223 0.1234 0.1246 

[TRAIN] Epoch[3](1053/1500); Loss: 0.098376; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1629 0.1503 0.1235 0.1100 0.0953 0.0901 0.0852 0.0824 0.0816 0.0827 0.0836 0.0812 0.0815 0.0865 0.0887 0.0886 

[TRAIN] Epoch[3](1054/1500); Loss: 0.175431; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.3943 0.3405 0.2894 0.2494 0.2126 0.1684 0.1302 0.1072 0.1054 0.1127 0.1112 0.1090 0.1149 0.1224 0.1196 0.1197 

[TRAIN] Epoch[3](1055/1500); Loss: 0.157873; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1860 0.1764 0.1666 0.1592 0.1548 0.1530 0.1522 0.1533 0.1527 0.1521 0.1522 0.1522 0.1526 0.1528 0.1544 0.1555 

[TRAIN] Epoch[3](1056/1500); Loss: 0.110208; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1298 0.1305 0.1568 0.1383 0.1155 0.1057 0.1078 0.1054 0.0986 0.0959 0.0962 0.0966 0.0951 0.0957 0.0978 0.0976 

[TRAIN] Epoch[3](1057/1500); Loss: 0.069353; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1099 0.0929 0.0725 0.0744 0.0675 0.0643 0.0634 0.0632 0.0614 0.0610 0.0611 0.0619 0.0613 0.0645 0.0650 0.0654 

[TRAIN] Epoch[3](1058/1500); Loss: 0.141508; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1785 0.1672 0.1620 0.1523 0.1414 0.1359 0.1328 0.1320 0.1316 0.1324 0.1325 0.1315 0.1312 0.1339 0.1342 0.1347 

[TRAIN] Epoch[3](1059/1500); Loss: 0.171608; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.4550 0.3884 0.3148 0.2636 0.2178 0.1613 0.1123 0.0840 0.0876 0.0935 0.0896 0.0870 0.0953 0.1008 0.0967 0.0980 

[TRAIN] Epoch[3](1060/1500); Loss: 0.155489; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2336 0.2053 0.1620 0.1540 0.1501 0.1447 0.1419 0.1423 0.1435 0.1423 0.1416 0.1429 0.1449 0.1446 0.1454 0.1489 

[TRAIN] Epoch[3](1061/1500); Loss: 0.160710; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1722 0.1677 0.1657 0.1634 0.1611 0.1589 0.1583 0.1587 0.1579 0.1582 0.1581 0.1583 0.1582 0.1580 0.1585 0.1581 

[TRAIN] Epoch[3](1062/1500); Loss: 0.083244; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1097 0.0959 0.0922 0.0870 0.0832 0.0798 0.0785 0.0771 0.0771 0.0780 0.0777 0.0775 0.0788 0.0794 0.0795 0.0806 

[TRAIN] Epoch[3](1063/1500); Loss: 0.154696; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2352 0.2017 0.1716 0.1609 0.1570 0.1488 0.1426 0.1405 0.1408 0.1398 0.1389 0.1387 0.1399 0.1384 0.1388 0.1417 

[TRAIN] Epoch[3](1064/1500); Loss: 0.147170; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.2052 0.1887 0.1628 0.1534 0.1469 0.1442 0.1384 0.1333 0.1327 0.1347 0.1351 0.1345 0.1347 0.1353 0.1371 0.1377 

[TRAIN] Epoch[3](1065/1500); Loss: 0.129011; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1882 0.1618 0.1403 0.1302 0.1267 0.1223 0.1209 0.1221 0.1199 0.1182 0.1183 0.1189 0.1187 0.1182 0.1195 0.1200 

[TRAIN] Epoch[3](1066/1500); Loss: 0.166358; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2460 0.2219 0.1947 0.1784 0.1694 0.1622 0.1549 0.1507 0.1503 0.1482 0.1466 0.1465 0.1480 0.1478 0.1474 0.1488 

[TRAIN] Epoch[3](1067/1500); Loss: 0.099906; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2102 0.1693 0.1174 0.0994 0.0867 0.0816 0.0810 0.0791 0.0796 0.0802 0.0823 0.0831 0.0832 0.0856 0.0890 0.0906 

[TRAIN] Epoch[3](1068/1500); Loss: 0.101927; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1200 0.1115 0.1071 0.1030 0.1016 0.0996 0.0982 0.0985 0.0980 0.0970 0.0969 0.0988 0.0989 0.0990 0.1014 0.1014 

[TRAIN] Epoch[3](1069/1500); Loss: 0.083412; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2423 0.1984 0.0902 0.0648 0.0663 0.0616 0.0577 0.0593 0.0580 0.0581 0.0581 0.0613 0.0613 0.0614 0.0666 0.0693 

[TRAIN] Epoch[3](1070/1500); Loss: 0.106988; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2066 0.1759 0.0878 0.0931 0.0986 0.0931 0.0888 0.0882 0.0903 0.0933 0.0931 0.0930 0.0988 0.1019 0.1031 0.1063 

[TRAIN] Epoch[3](1071/1500); Loss: 0.113340; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1516 0.1368 0.1251 0.1177 0.1122 0.1079 0.1060 0.1073 0.1058 0.1046 0.1054 0.1064 0.1056 0.1061 0.1074 0.1076 

[TRAIN] Epoch[3](1072/1500); Loss: 0.115789; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2005 0.1595 0.1145 0.1061 0.1043 0.1014 0.1004 0.1000 0.1027 0.1041 0.1049 0.1052 0.1099 0.1127 0.1121 0.1144 

[TRAIN] Epoch[3](1073/1500); Loss: 0.110785; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1406 0.1264 0.1169 0.1112 0.1105 0.1088 0.1066 0.1053 0.1055 0.1057 0.1047 0.1057 0.1050 0.1051 0.1076 0.1069 

[TRAIN] Epoch[3](1074/1500); Loss: 0.081274; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.1077 0.0937 0.0868 0.0824 0.0780 0.0768 0.0772 0.0766 0.0761 0.0767 0.0768 0.0768 0.0782 0.0784 0.0788 0.0794 

[TRAIN] Epoch[3](1075/1500); Loss: 0.058376; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1501 0.0986 0.0570 0.0490 0.0494 0.0475 0.0460 0.0467 0.0474 0.0443 0.0447 0.0477 0.0477 0.0501 0.0521 0.0556 

[TRAIN] Epoch[3](1076/1500); Loss: 0.140930; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2379 0.2059 0.1731 0.1516 0.1382 0.1283 0.1249 0.1199 0.1186 0.1182 0.1191 0.1200 0.1207 0.1224 0.1261 0.1299 

[TRAIN] Epoch[3](1077/1500); Loss: 0.068070; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0750 0.0702 0.0718 0.0681 0.0684 0.0656 0.0649 0.0649 0.0661 0.0659 0.0659 0.0666 0.0680 0.0680 0.0689 0.0706 

[TRAIN] Epoch[3](1078/1500); Loss: 0.173849; Backpropagation: 0.0916 sec; Batch: 0.4239 sec
0.4264 0.3663 0.2979 0.2505 0.2117 0.1645 0.1217 0.0974 0.1008 0.1024 0.1011 0.1015 0.1061 0.1134 0.1102 0.1097 

[TRAIN] Epoch[3](1079/1500); Loss: 0.094375; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1408 0.1214 0.1066 0.0978 0.0947 0.0903 0.0867 0.0861 0.0847 0.0844 0.0844 0.0853 0.0861 0.0860 0.0864 0.0882 

[TRAIN] Epoch[3](1080/1500); Loss: 0.072819; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.0789 0.0775 0.0753 0.0723 0.0704 0.0696 0.0702 0.0701 0.0705 0.0708 0.0711 0.0723 0.0732 0.0731 0.0741 0.0756 

[TRAIN] Epoch[3](1081/1500); Loss: 0.139644; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2078 0.1818 0.1628 0.1516 0.1462 0.1422 0.1364 0.1302 0.1248 0.1215 0.1200 0.1200 0.1212 0.1215 0.1223 0.1241 

[TRAIN] Epoch[3](1082/1500); Loss: 0.069027; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0818 0.0688 0.0658 0.0640 0.0671 0.0668 0.0646 0.0639 0.0668 0.0665 0.0675 0.0686 0.0695 0.0727 0.0748 0.0753 

[TRAIN] Epoch[3](1083/1500); Loss: 0.090962; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1139 0.1045 0.0975 0.0902 0.0873 0.0874 0.0875 0.0873 0.0863 0.0872 0.0869 0.0865 0.0871 0.0881 0.0880 0.0897 

[TRAIN] Epoch[3](1084/1500); Loss: 0.114562; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1666 0.1477 0.1309 0.1205 0.1153 0.1098 0.1071 0.1046 0.1046 0.1036 0.1034 0.1027 0.1031 0.1035 0.1041 0.1052 

[TRAIN] Epoch[3](1085/1500); Loss: 0.210929; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.3573 0.3167 0.2747 0.2452 0.2251 0.2033 0.1817 0.1736 0.1755 0.1785 0.1728 0.1728 0.1732 0.1747 0.1737 0.1762 

[TRAIN] Epoch[3](1086/1500); Loss: 0.126274; Backpropagation: 0.0915 sec; Batch: 0.4238 sec
0.1920 0.1736 0.1359 0.1240 0.1189 0.1195 0.1154 0.1172 0.1132 0.1135 0.1137 0.1165 0.1162 0.1156 0.1171 0.1181 

[TRAIN] Epoch[3](1087/1500); Loss: 0.108574; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1842 0.1519 0.1183 0.1073 0.1017 0.0987 0.0986 0.0980 0.0975 0.0969 0.0955 0.0963 0.0976 0.0971 0.0983 0.0993 

[TRAIN] Epoch[3](1088/1500); Loss: 0.076762; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1263 0.1046 0.0885 0.0780 0.0741 0.0724 0.0703 0.0680 0.0673 0.0676 0.0677 0.0680 0.0676 0.0684 0.0694 0.0701 

[TRAIN] Epoch[3](1089/1500); Loss: 0.097317; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1484 0.1293 0.1063 0.1004 0.0949 0.0903 0.0897 0.0877 0.0887 0.0876 0.0872 0.0885 0.0885 0.0884 0.0898 0.0913 

[TRAIN] Epoch[3](1090/1500); Loss: 0.125265; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1553 0.1512 0.1346 0.1254 0.1215 0.1204 0.1194 0.1191 0.1184 0.1178 0.1178 0.1187 0.1196 0.1201 0.1211 0.1238 

[TRAIN] Epoch[3](1091/1500); Loss: 0.121101; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2761 0.2284 0.1807 0.1532 0.1293 0.1012 0.0842 0.0848 0.0900 0.0887 0.0843 0.0836 0.0892 0.0895 0.0861 0.0884 

[TRAIN] Epoch[3](1092/1500); Loss: 0.128133; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1711 0.1542 0.1391 0.1379 0.1346 0.1283 0.1251 0.1237 0.1192 0.1170 0.1159 0.1172 0.1176 0.1161 0.1156 0.1175 

[TRAIN] Epoch[3](1093/1500); Loss: 0.115832; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2166 0.1936 0.1132 0.1106 0.1113 0.1077 0.1028 0.1006 0.0989 0.0964 0.0989 0.0981 0.0996 0.0988 0.1004 0.1057 

[TRAIN] Epoch[3](1094/1500); Loss: 0.073371; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.0976 0.0904 0.0754 0.0718 0.0731 0.0663 0.0646 0.0633 0.0637 0.0677 0.0703 0.0690 0.0690 0.0741 0.0792 0.0785 

[TRAIN] Epoch[3](1095/1500); Loss: 0.093899; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1427 0.1217 0.1079 0.0969 0.0910 0.0874 0.0857 0.0846 0.0831 0.0833 0.0837 0.0856 0.0850 0.0858 0.0879 0.0901 

[TRAIN] Epoch[3](1096/1500); Loss: 0.100207; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1812 0.1593 0.1130 0.1046 0.1008 0.0954 0.0869 0.0847 0.0828 0.0843 0.0839 0.0836 0.0849 0.0855 0.0861 0.0863 

[TRAIN] Epoch[3](1097/1500); Loss: 0.140019; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2114 0.1882 0.1664 0.1606 0.1532 0.1441 0.1358 0.1274 0.1206 0.1173 0.1170 0.1174 0.1198 0.1207 0.1198 0.1206 

[TRAIN] Epoch[3](1098/1500); Loss: 0.101312; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2111 0.1898 0.1117 0.0972 0.0828 0.0826 0.0788 0.0784 0.0841 0.0852 0.0833 0.0819 0.0853 0.0886 0.0913 0.0890 

[TRAIN] Epoch[3](1099/1500); Loss: 0.076563; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2257 0.1984 0.0869 0.0627 0.0616 0.0617 0.0537 0.0551 0.0476 0.0529 0.0513 0.0501 0.0537 0.0544 0.0539 0.0553 

[TRAIN] Epoch[3](1100/1500); Loss: 0.115630; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1589 0.1441 0.1252 0.1174 0.1140 0.1085 0.1044 0.1050 0.1052 0.1040 0.1059 0.1083 0.1079 0.1115 0.1141 0.1157 

[TRAIN] Epoch[3](1101/1500); Loss: 0.132082; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2051 0.1814 0.1578 0.1445 0.1381 0.1250 0.1153 0.1114 0.1146 0.1166 0.1168 0.1154 0.1156 0.1186 0.1187 0.1184 

[TRAIN] Epoch[3](1102/1500); Loss: 0.089408; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1535 0.1293 0.0930 0.0923 0.0894 0.0837 0.0823 0.0778 0.0758 0.0759 0.0771 0.0761 0.0785 0.0818 0.0817 0.0823 

[TRAIN] Epoch[3](1103/1500); Loss: 0.084554; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2266 0.2032 0.1053 0.0793 0.0609 0.0602 0.0580 0.0540 0.0538 0.0534 0.0617 0.0701 0.0646 0.0601 0.0656 0.0761 

[TRAIN] Epoch[3](1104/1500); Loss: 0.086688; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1185 0.1126 0.0968 0.0901 0.0864 0.0816 0.0799 0.0781 0.0772 0.0780 0.0767 0.0770 0.0811 0.0827 0.0829 0.0877 

[TRAIN] Epoch[3](1105/1500); Loss: 0.094436; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1282 0.1182 0.1017 0.0961 0.0941 0.0911 0.0870 0.0854 0.0860 0.0855 0.0868 0.0878 0.0881 0.0898 0.0917 0.0933 

[TRAIN] Epoch[3](1106/1500); Loss: 0.147332; Backpropagation: 0.0915 sec; Batch: 0.4229 sec
0.1824 0.1711 0.1434 0.1399 0.1432 0.1418 0.1402 0.1412 0.1400 0.1424 0.1431 0.1432 0.1430 0.1462 0.1484 0.1477 

[TRAIN] Epoch[3](1107/1500); Loss: 0.105335; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1481 0.1237 0.1088 0.1016 0.1017 0.1009 0.0953 0.0976 0.0958 0.0987 0.0984 0.0996 0.1018 0.1029 0.1040 0.1066 

[TRAIN] Epoch[3](1108/1500); Loss: 0.109767; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1821 0.1479 0.1128 0.1016 0.1003 0.1001 0.0986 0.0988 0.0986 0.0989 0.0994 0.1007 0.1019 0.1034 0.1051 0.1061 

[TRAIN] Epoch[3](1109/1500); Loss: 0.084435; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1178 0.1062 0.0858 0.0847 0.0808 0.0785 0.0783 0.0785 0.0784 0.0790 0.0790 0.0797 0.0807 0.0799 0.0812 0.0825 

[TRAIN] Epoch[3](1110/1500); Loss: 0.130107; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2119 0.1821 0.1489 0.1370 0.1307 0.1238 0.1178 0.1113 0.1113 0.1120 0.1131 0.1147 0.1149 0.1150 0.1175 0.1197 

[TRAIN] Epoch[3](1111/1500); Loss: 0.122544; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1769 0.1627 0.1355 0.1234 0.1150 0.1141 0.1140 0.1126 0.1127 0.1118 0.1121 0.1138 0.1132 0.1123 0.1140 0.1166 

[TRAIN] Epoch[3](1112/1500); Loss: 0.143928; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2094 0.1877 0.1705 0.1623 0.1561 0.1496 0.1424 0.1345 0.1275 0.1227 0.1224 0.1227 0.1228 0.1241 0.1241 0.1241 

[TRAIN] Epoch[3](1113/1500); Loss: 0.078589; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1402 0.1214 0.0923 0.0762 0.0696 0.0664 0.0650 0.0632 0.0644 0.0655 0.0659 0.0682 0.0704 0.0728 0.0771 0.0789 

[TRAIN] Epoch[3](1114/1500); Loss: 0.140719; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2009 0.1823 0.1572 0.1494 0.1435 0.1389 0.1327 0.1279 0.1264 0.1254 0.1258 0.1275 0.1278 0.1285 0.1275 0.1297 

[TRAIN] Epoch[3](1115/1500); Loss: 0.093971; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1198 0.1090 0.0964 0.0928 0.0924 0.0931 0.0909 0.0886 0.0874 0.0892 0.0892 0.0891 0.0903 0.0914 0.0916 0.0924 

[TRAIN] Epoch[3](1116/1500); Loss: 0.154937; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1730 0.1656 0.1624 0.1538 0.1515 0.1514 0.1521 0.1520 0.1511 0.1504 0.1518 0.1529 0.1521 0.1515 0.1533 0.1543 

[TRAIN] Epoch[3](1117/1500); Loss: 0.080765; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1163 0.0955 0.0862 0.0795 0.0795 0.0779 0.0749 0.0730 0.0760 0.0757 0.0739 0.0745 0.0781 0.0767 0.0758 0.0784 

[TRAIN] Epoch[3](1118/1500); Loss: 0.120930; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2315 0.1994 0.1245 0.1204 0.1191 0.1113 0.1055 0.1004 0.1031 0.1023 0.0998 0.0998 0.1008 0.1042 0.1052 0.1076 

[TRAIN] Epoch[3](1119/1500); Loss: 0.086294; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1263 0.1104 0.0880 0.0861 0.0765 0.0828 0.0805 0.0783 0.0786 0.0824 0.0815 0.0790 0.0819 0.0834 0.0828 0.0823 

[TRAIN] Epoch[3](1120/1500); Loss: 0.143647; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1979 0.1795 0.1584 0.1519 0.1479 0.1434 0.1382 0.1360 0.1333 0.1310 0.1298 0.1305 0.1303 0.1301 0.1299 0.1303 

[TRAIN] Epoch[3](1121/1500); Loss: 0.074492; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0791 0.0756 0.0757 0.0747 0.0704 0.0715 0.0721 0.0717 0.0701 0.0726 0.0728 0.0749 0.0746 0.0787 0.0789 0.0783 

[TRAIN] Epoch[3](1122/1500); Loss: 0.099367; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1229 0.1104 0.0993 0.0932 0.0953 0.0974 0.0942 0.0930 0.0981 0.0973 0.0943 0.0944 0.0977 0.1004 0.0998 0.1023 

[TRAIN] Epoch[3](1123/1500); Loss: 0.162107; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2005 0.1904 0.1749 0.1675 0.1613 0.1583 0.1562 0.1552 0.1543 0.1543 0.1531 0.1519 0.1527 0.1546 0.1543 0.1540 

[TRAIN] Epoch[3](1124/1500); Loss: 0.054315; Backpropagation: 0.0915 sec; Batch: 0.4234 sec
0.0808 0.0632 0.0551 0.0523 0.0519 0.0520 0.0500 0.0478 0.0502 0.0532 0.0514 0.0503 0.0520 0.0532 0.0522 0.0536 

[TRAIN] Epoch[3](1125/1500); Loss: 0.094741; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1491 0.1368 0.1188 0.1073 0.0965 0.0927 0.0852 0.0811 0.0795 0.0790 0.0771 0.0775 0.0810 0.0846 0.0833 0.0864 

[TRAIN] Epoch[3](1126/1500); Loss: 0.151630; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1620 0.1529 0.1483 0.1472 0.1465 0.1476 0.1482 0.1477 0.1480 0.1512 0.1519 0.1510 0.1530 0.1558 0.1563 0.1583 

[TRAIN] Epoch[3](1127/1500); Loss: 0.095563; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1559 0.1286 0.1026 0.0943 0.0927 0.0892 0.0881 0.0856 0.0858 0.0852 0.0850 0.0870 0.0865 0.0867 0.0877 0.0883 

[TRAIN] Epoch[3](1128/1500); Loss: 0.106042; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2106 0.1701 0.1355 0.1219 0.1109 0.0958 0.0842 0.0807 0.0832 0.0839 0.0833 0.0846 0.0857 0.0882 0.0889 0.0893 

[TRAIN] Epoch[3](1129/1500); Loss: 0.115777; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1405 0.1328 0.1239 0.1193 0.1175 0.1151 0.1121 0.1099 0.1091 0.1086 0.1097 0.1108 0.1109 0.1091 0.1097 0.1134 

[TRAIN] Epoch[3](1130/1500); Loss: 0.116317; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1436 0.1312 0.1255 0.1217 0.1169 0.1144 0.1115 0.1097 0.1105 0.1096 0.1097 0.1097 0.1101 0.1116 0.1125 0.1130 

[TRAIN] Epoch[3](1131/1500); Loss: 0.138425; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2108 0.1796 0.1535 0.1427 0.1365 0.1307 0.1268 0.1238 0.1230 0.1230 0.1262 0.1265 0.1251 0.1250 0.1276 0.1340 

[TRAIN] Epoch[3](1132/1500); Loss: 0.122836; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1881 0.1598 0.1352 0.1323 0.1275 0.1190 0.1126 0.1118 0.1135 0.1111 0.1086 0.1089 0.1092 0.1082 0.1081 0.1115 

[TRAIN] Epoch[3](1133/1500); Loss: 0.153866; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2009 0.1855 0.1749 0.1650 0.1575 0.1544 0.1499 0.1459 0.1443 0.1433 0.1429 0.1403 0.1393 0.1393 0.1397 0.1386 

[TRAIN] Epoch[3](1134/1500); Loss: 0.046392; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0597 0.0522 0.0469 0.0457 0.0467 0.0436 0.0414 0.0418 0.0429 0.0428 0.0430 0.0444 0.0461 0.0470 0.0479 0.0502 

[TRAIN] Epoch[3](1135/1500); Loss: 0.120072; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1717 0.1457 0.1255 0.1225 0.1162 0.1135 0.1103 0.1131 0.1117 0.1102 0.1100 0.1114 0.1131 0.1129 0.1153 0.1179 

[TRAIN] Epoch[3](1136/1500); Loss: 0.084277; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.1268 0.1103 0.0917 0.0788 0.0754 0.0857 0.0830 0.0762 0.0729 0.0765 0.0808 0.0777 0.0764 0.0774 0.0801 0.0788 

[TRAIN] Epoch[3](1137/1500); Loss: 0.076869; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1010 0.0861 0.0828 0.0784 0.0766 0.0737 0.0736 0.0706 0.0728 0.0724 0.0712 0.0722 0.0740 0.0743 0.0743 0.0759 

[TRAIN] Epoch[3](1138/1500); Loss: 0.093138; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1957 0.1558 0.1272 0.1141 0.1065 0.0935 0.0808 0.0741 0.0701 0.0659 0.0656 0.0674 0.0684 0.0671 0.0674 0.0703 

[TRAIN] Epoch[3](1139/1500); Loss: 0.135219; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1952 0.1602 0.1471 0.1454 0.1370 0.1286 0.1265 0.1260 0.1249 0.1224 0.1225 0.1233 0.1247 0.1256 0.1254 0.1287 

[TRAIN] Epoch[3](1140/1500); Loss: 0.145070; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2002 0.1707 0.1575 0.1503 0.1448 0.1376 0.1361 0.1357 0.1361 0.1336 0.1331 0.1339 0.1379 0.1374 0.1375 0.1389 

[TRAIN] Epoch[3](1141/1500); Loss: 0.114805; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2005 0.1678 0.1524 0.1381 0.1279 0.1127 0.1035 0.0982 0.0939 0.0908 0.0906 0.0915 0.0915 0.0911 0.0924 0.0940 

[TRAIN] Epoch[3](1142/1500); Loss: 0.158545; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1751 0.1679 0.1680 0.1657 0.1620 0.1586 0.1550 0.1547 0.1547 0.1540 0.1528 0.1541 0.1535 0.1525 0.1536 0.1545 

[TRAIN] Epoch[3](1143/1500); Loss: 0.131999; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1815 0.1630 0.1550 0.1506 0.1406 0.1312 0.1232 0.1210 0.1201 0.1185 0.1160 0.1155 0.1182 0.1178 0.1190 0.1208 

[TRAIN] Epoch[3](1144/1500); Loss: 0.100013; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1927 0.1577 0.1201 0.1039 0.0998 0.0893 0.0806 0.0815 0.0835 0.0838 0.0796 0.0785 0.0846 0.0892 0.0879 0.0874 

[TRAIN] Epoch[3](1145/1500); Loss: 0.079185; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0959 0.0813 0.0782 0.0780 0.0781 0.0769 0.0764 0.0770 0.0769 0.0765 0.0776 0.0778 0.0779 0.0788 0.0800 0.0800 

[TRAIN] Epoch[3](1146/1500); Loss: 0.110191; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1283 0.1088 0.1274 0.1278 0.1194 0.1058 0.1011 0.1010 0.1045 0.1040 0.1024 0.1030 0.1059 0.1062 0.1073 0.1102 

[TRAIN] Epoch[3](1147/1500); Loss: 0.074293; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1015 0.0772 0.0965 0.0943 0.0811 0.0665 0.0638 0.0658 0.0673 0.0643 0.0648 0.0677 0.0675 0.0671 0.0695 0.0739 

[TRAIN] Epoch[3](1148/1500); Loss: 0.117412; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1583 0.1484 0.1393 0.1335 0.1241 0.1149 0.1088 0.1046 0.1038 0.1026 0.1031 0.1045 0.1043 0.1055 0.1109 0.1121 

[TRAIN] Epoch[3](1149/1500); Loss: 0.113298; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1989 0.1544 0.1129 0.1120 0.1167 0.1084 0.0992 0.0977 0.0993 0.0991 0.0980 0.1011 0.1041 0.1037 0.1024 0.1049 

[TRAIN] Epoch[3](1150/1500); Loss: 0.086761; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0950 0.0911 0.0920 0.0865 0.0852 0.0853 0.0862 0.0847 0.0844 0.0843 0.0848 0.0854 0.0856 0.0852 0.0855 0.0869 

[TRAIN] Epoch[3](1151/1500); Loss: 0.089209; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1175 0.1112 0.1102 0.0984 0.0928 0.0879 0.0838 0.0813 0.0811 0.0818 0.0809 0.0794 0.0794 0.0804 0.0806 0.0806 

[TRAIN] Epoch[3](1152/1500); Loss: 0.163162; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2087 0.1918 0.1751 0.1683 0.1642 0.1582 0.1556 0.1540 0.1547 0.1533 0.1526 0.1528 0.1537 0.1545 0.1558 0.1574 

[TRAIN] Epoch[3](1153/1500); Loss: 0.092344; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1231 0.1142 0.1100 0.0996 0.0911 0.0864 0.0845 0.0818 0.0820 0.0829 0.0834 0.0839 0.0858 0.0884 0.0895 0.0909 

[TRAIN] Epoch[3](1154/1500); Loss: 0.118205; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1604 0.1415 0.1323 0.1258 0.1206 0.1157 0.1125 0.1108 0.1087 0.1079 0.1082 0.1091 0.1087 0.1091 0.1096 0.1104 

[TRAIN] Epoch[3](1155/1500); Loss: 0.105205; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1391 0.1276 0.1153 0.1067 0.1042 0.1033 0.1015 0.0977 0.0962 0.0966 0.0976 0.0966 0.0977 0.1005 0.1001 0.1026 

[TRAIN] Epoch[3](1156/1500); Loss: 0.091639; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1277 0.1025 0.1081 0.1012 0.0933 0.0808 0.0808 0.0828 0.0839 0.0808 0.0813 0.0844 0.0880 0.0884 0.0895 0.0927 

[TRAIN] Epoch[3](1157/1500); Loss: 0.154763; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.2135 0.1882 0.1665 0.1600 0.1578 0.1512 0.1458 0.1448 0.1456 0.1442 0.1427 0.1424 0.1432 0.1428 0.1432 0.1443 

[TRAIN] Epoch[3](1158/1500); Loss: 0.144544; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2005 0.1819 0.1675 0.1612 0.1593 0.1525 0.1445 0.1377 0.1335 0.1299 0.1250 0.1228 0.1229 0.1248 0.1241 0.1247 

[TRAIN] Epoch[3](1159/1500); Loss: 0.099859; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1676 0.1432 0.1375 0.1190 0.1086 0.0931 0.0832 0.0799 0.0788 0.0792 0.0825 0.0843 0.0842 0.0830 0.0847 0.0889 

[TRAIN] Epoch[3](1160/1500); Loss: 0.125612; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1803 0.1624 0.1430 0.1329 0.1258 0.1193 0.1148 0.1127 0.1114 0.1113 0.1115 0.1125 0.1145 0.1164 0.1189 0.1221 

[TRAIN] Epoch[3](1161/1500); Loss: 0.096348; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1219 0.1002 0.1312 0.1168 0.0981 0.0853 0.0825 0.0830 0.0831 0.0847 0.0861 0.0910 0.0917 0.0926 0.0953 0.0983 

[TRAIN] Epoch[3](1162/1500); Loss: 0.090485; Backpropagation: 0.0915 sec; Batch: 0.4235 sec
0.1429 0.1249 0.1079 0.1001 0.0988 0.0949 0.0894 0.0817 0.0761 0.0756 0.0762 0.0750 0.0750 0.0756 0.0762 0.0773 

[TRAIN] Epoch[3](1163/1500); Loss: 0.085702; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1647 0.1333 0.0932 0.0848 0.0839 0.0770 0.0713 0.0694 0.0701 0.0713 0.0702 0.0712 0.0754 0.0771 0.0779 0.0805 

[TRAIN] Epoch[3](1164/1500); Loss: 0.134178; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2848 0.2378 0.1995 0.1833 0.1775 0.1525 0.1210 0.0995 0.0907 0.0850 0.0823 0.0837 0.0877 0.0867 0.0865 0.0882 

[TRAIN] Epoch[3](1165/1500); Loss: 0.143592; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2204 0.1841 0.1480 0.1474 0.1503 0.1422 0.1338 0.1291 0.1299 0.1293 0.1284 0.1281 0.1304 0.1311 0.1319 0.1329 

[TRAIN] Epoch[3](1166/1500); Loss: 0.140311; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2800 0.2408 0.1953 0.1795 0.1806 0.1626 0.1370 0.1168 0.1058 0.0980 0.0899 0.0887 0.0914 0.0934 0.0913 0.0939 

[TRAIN] Epoch[3](1167/1500); Loss: 0.109000; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1887 0.1674 0.1442 0.1377 0.1337 0.1223 0.1069 0.0948 0.0865 0.0814 0.0785 0.0790 0.0817 0.0818 0.0797 0.0797 

[TRAIN] Epoch[3](1168/1500); Loss: 0.164712; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.2600 0.2338 0.2339 0.2165 0.1965 0.1767 0.1641 0.1515 0.1429 0.1329 0.1264 0.1222 0.1196 0.1184 0.1186 0.1213 

[TRAIN] Epoch[3](1169/1500); Loss: 0.069145; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0665 0.0731 0.0944 0.0825 0.0742 0.0638 0.0635 0.0610 0.0616 0.0625 0.0637 0.0647 0.0656 0.0672 0.0701 0.0717 

[TRAIN] Epoch[3](1170/1500); Loss: 0.144827; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2288 0.1959 0.1655 0.1574 0.1539 0.1459 0.1376 0.1329 0.1295 0.1250 0.1238 0.1221 0.1244 0.1243 0.1255 0.1249 

[TRAIN] Epoch[3](1171/1500); Loss: 0.134913; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1759 0.1537 0.1383 0.1360 0.1370 0.1348 0.1320 0.1291 0.1282 0.1279 0.1278 0.1267 0.1270 0.1275 0.1281 0.1286 

[TRAIN] Epoch[3](1172/1500); Loss: 0.085047; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1490 0.1159 0.0957 0.0964 0.0920 0.0821 0.0758 0.0753 0.0756 0.0728 0.0712 0.0718 0.0718 0.0709 0.0714 0.0730 

[TRAIN] Epoch[3](1173/1500); Loss: 0.082052; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2154 0.1358 0.0572 0.0718 0.0684 0.0600 0.0557 0.0661 0.0670 0.0673 0.0637 0.0692 0.0754 0.0794 0.0798 0.0805 

[TRAIN] Epoch[3](1174/1500); Loss: 0.086212; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1291 0.1138 0.0988 0.0892 0.0875 0.0816 0.0782 0.0772 0.0763 0.0759 0.0766 0.0769 0.0775 0.0789 0.0803 0.0815 

[TRAIN] Epoch[3](1175/1500); Loss: 0.111554; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2511 0.1960 0.1408 0.1259 0.1224 0.1064 0.0926 0.0837 0.0816 0.0793 0.0808 0.0810 0.0839 0.0850 0.0856 0.0887 

[TRAIN] Epoch[3](1176/1500); Loss: 0.094708; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1330 0.1212 0.1303 0.1131 0.0987 0.0866 0.0851 0.0826 0.0814 0.0790 0.0820 0.0833 0.0836 0.0839 0.0843 0.0875 

[TRAIN] Epoch[3](1177/1500); Loss: 0.137513; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1693 0.1555 0.1490 0.1427 0.1393 0.1364 0.1342 0.1328 0.1317 0.1305 0.1296 0.1294 0.1298 0.1298 0.1295 0.1305 

[TRAIN] Epoch[3](1178/1500); Loss: 0.098399; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1178 0.1096 0.1056 0.1002 0.0974 0.0966 0.0941 0.0923 0.0923 0.0944 0.0946 0.0942 0.0949 0.0970 0.0969 0.0965 

[TRAIN] Epoch[3](1179/1500); Loss: 0.121633; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1669 0.1348 0.1498 0.1326 0.1166 0.1090 0.1123 0.1100 0.1087 0.1085 0.1119 0.1168 0.1151 0.1133 0.1164 0.1235 

[TRAIN] Epoch[3](1180/1500); Loss: 0.065588; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1558 0.1167 0.0802 0.0807 0.0778 0.0620 0.0462 0.0485 0.0474 0.0462 0.0438 0.0485 0.0498 0.0475 0.0473 0.0510 

[TRAIN] Epoch[3](1181/1500); Loss: 0.116033; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1741 0.1498 0.1292 0.1226 0.1187 0.1127 0.1067 0.1062 0.1056 0.1050 0.1032 0.1025 0.1039 0.1046 0.1051 0.1066 

[TRAIN] Epoch[3](1182/1500); Loss: 0.090444; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1571 0.1422 0.1240 0.1099 0.1043 0.0958 0.0855 0.0744 0.0695 0.0695 0.0696 0.0678 0.0681 0.0692 0.0704 0.0696 

[TRAIN] Epoch[3](1183/1500); Loss: 0.107768; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2554 0.1967 0.1141 0.0992 0.1196 0.1088 0.0918 0.0791 0.0806 0.0819 0.0805 0.0775 0.0804 0.0877 0.0869 0.0841 

[TRAIN] Epoch[3](1184/1500); Loss: 0.137368; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2234 0.2099 0.2042 0.1928 0.1788 0.1574 0.1383 0.1238 0.1143 0.1034 0.0935 0.0907 0.0923 0.0929 0.0903 0.0921 

[TRAIN] Epoch[3](1185/1500); Loss: 0.075046; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.0989 0.0785 0.1021 0.1030 0.0891 0.0704 0.0635 0.0631 0.0639 0.0622 0.0634 0.0679 0.0685 0.0665 0.0676 0.0721 

[TRAIN] Epoch[3](1186/1500); Loss: 0.070984; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1293 0.1030 0.0871 0.0810 0.0741 0.0654 0.0613 0.0607 0.0594 0.0580 0.0581 0.0590 0.0587 0.0592 0.0604 0.0611 

[TRAIN] Epoch[3](1187/1500); Loss: 0.109186; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1297 0.1343 0.1531 0.1420 0.1244 0.1076 0.0994 0.0963 0.0944 0.0930 0.0927 0.0942 0.0966 0.0959 0.0957 0.0978 

[TRAIN] Epoch[3](1188/1500); Loss: 0.134714; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1963 0.1746 0.1553 0.1472 0.1443 0.1359 0.1285 0.1238 0.1221 0.1210 0.1185 0.1170 0.1182 0.1182 0.1169 0.1175 

[TRAIN] Epoch[3](1189/1500); Loss: 0.140980; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.1689 0.1654 0.1659 0.1583 0.1519 0.1434 0.1364 0.1316 0.1286 0.1288 0.1283 0.1287 0.1286 0.1292 0.1302 0.1316 

[TRAIN] Epoch[3](1190/1500); Loss: 0.122281; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.2132 0.1754 0.1599 0.1575 0.1533 0.1355 0.1150 0.1069 0.1037 0.0998 0.0922 0.0889 0.0881 0.0884 0.0885 0.0900 

[TRAIN] Epoch[3](1191/1500); Loss: 0.080782; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2027 0.1314 0.0694 0.0825 0.0965 0.0854 0.0691 0.0614 0.0615 0.0620 0.0611 0.0599 0.0614 0.0625 0.0623 0.0634 

[TRAIN] Epoch[3](1192/1500); Loss: 0.106400; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1416 0.1239 0.1155 0.1132 0.1103 0.1035 0.0989 0.0979 0.0988 0.0985 0.0975 0.0988 0.1003 0.1007 0.1008 0.1023 

[TRAIN] Epoch[3](1193/1500); Loss: 0.108554; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1396 0.1381 0.1357 0.1172 0.1071 0.1013 0.1013 0.0969 0.0960 0.0954 0.0989 0.0981 0.0998 0.1009 0.1042 0.1062 

[TRAIN] Epoch[3](1194/1500); Loss: 0.073096; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0656 0.0914 0.1195 0.1080 0.0864 0.0682 0.0608 0.0612 0.0614 0.0617 0.0607 0.0627 0.0639 0.0638 0.0657 0.0684 

[TRAIN] Epoch[3](1195/1500); Loss: 0.089319; Backpropagation: 0.0926 sec; Batch: 0.4254 sec
0.1983 0.1205 0.0732 0.1111 0.1324 0.1167 0.0900 0.0677 0.0605 0.0619 0.0632 0.0629 0.0622 0.0655 0.0720 0.0709 

[TRAIN] Epoch[3](1196/1500); Loss: 0.110878; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1813 0.1613 0.1367 0.1292 0.1264 0.1177 0.1063 0.0975 0.0929 0.0904 0.0900 0.0887 0.0887 0.0888 0.0884 0.0896 

[TRAIN] Epoch[3](1197/1500); Loss: 0.131026; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1832 0.1639 0.1678 0.1598 0.1476 0.1335 0.1230 0.1193 0.1180 0.1155 0.1109 0.1100 0.1100 0.1114 0.1111 0.1114 

[TRAIN] Epoch[3](1198/1500); Loss: 0.113943; Backpropagation: 0.0915 sec; Batch: 0.4236 sec
0.1249 0.1206 0.1227 0.1192 0.1135 0.1100 0.1106 0.1096 0.1092 0.1095 0.1109 0.1111 0.1114 0.1124 0.1135 0.1141 

[TRAIN] Epoch[3](1199/1500); Loss: 0.091267; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2135 0.1829 0.1504 0.1285 0.1144 0.0943 0.0756 0.0650 0.0592 0.0567 0.0537 0.0530 0.0528 0.0527 0.0535 0.0540 

[TRAIN] Epoch[3](1200/1500); Loss: 0.061557; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1202 0.1317 0.1218 0.0846 0.0558 0.0449 0.0444 0.0428 0.0394 0.0403 0.0425 0.0420 0.0414 0.0434 0.0449 0.0448 

[TRAIN] Epoch[3](1201/1500); Loss: 0.134138; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1598 0.1553 0.1548 0.1490 0.1423 0.1369 0.1334 0.1305 0.1273 0.1245 0.1236 0.1222 0.1210 0.1210 0.1226 0.1219 

[TRAIN] Epoch[3](1202/1500); Loss: 0.085941; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1302 0.1202 0.1225 0.1039 0.0875 0.0742 0.0733 0.0707 0.0703 0.0698 0.0701 0.0707 0.0736 0.0770 0.0795 0.0817 

[TRAIN] Epoch[3](1203/1500); Loss: 0.184742; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2521 0.2307 0.2104 0.1992 0.1920 0.1828 0.1743 0.1715 0.1692 0.1686 0.1674 0.1675 0.1673 0.1672 0.1677 0.1680 

[TRAIN] Epoch[3](1204/1500); Loss: 0.150412; Backpropagation: 0.0915 sec; Batch: 0.4235 sec
0.2239 0.1980 0.1701 0.1589 0.1553 0.1481 0.1403 0.1399 0.1372 0.1353 0.1343 0.1330 0.1326 0.1337 0.1337 0.1323 

[TRAIN] Epoch[3](1205/1500); Loss: 0.126219; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2102 0.1782 0.1650 0.1514 0.1367 0.1192 0.1110 0.1031 0.1034 0.1044 0.1045 0.1036 0.1057 0.1075 0.1072 0.1083 

[TRAIN] Epoch[3](1206/1500); Loss: 0.099004; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2616 0.2125 0.1627 0.1277 0.0964 0.0772 0.0723 0.0643 0.0599 0.0596 0.0602 0.0646 0.0633 0.0631 0.0690 0.0696 

[TRAIN] Epoch[3](1207/1500); Loss: 0.114457; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1550 0.1447 0.1346 0.1244 0.1193 0.1158 0.1111 0.1074 0.1048 0.1033 0.1015 0.1007 0.1012 0.1025 0.1025 0.1025 

[TRAIN] Epoch[3](1208/1500); Loss: 0.098821; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1241 0.0965 0.1036 0.1034 0.0979 0.0943 0.0952 0.0936 0.0938 0.0946 0.0958 0.0962 0.0964 0.0974 0.0985 0.0999 

[TRAIN] Epoch[3](1209/1500); Loss: 0.113091; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2367 0.1865 0.1244 0.1141 0.1204 0.1069 0.0934 0.0901 0.0908 0.0890 0.0866 0.0908 0.0946 0.0972 0.0932 0.0946 

[TRAIN] Epoch[3](1210/1500); Loss: 0.124778; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1477 0.1381 0.1338 0.1251 0.1240 0.1231 0.1211 0.1195 0.1184 0.1196 0.1203 0.1193 0.1202 0.1214 0.1224 0.1226 

[TRAIN] Epoch[3](1211/1500); Loss: 0.107234; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1535 0.1199 0.1185 0.1156 0.1079 0.1021 0.1053 0.0998 0.0986 0.0987 0.0990 0.0985 0.0982 0.1004 0.1002 0.0993 

[TRAIN] Epoch[3](1212/1500); Loss: 0.061104; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0728 0.0664 0.0671 0.0596 0.0578 0.0552 0.0579 0.0561 0.0569 0.0563 0.0579 0.0616 0.0608 0.0610 0.0646 0.0658 

[TRAIN] Epoch[3](1213/1500); Loss: 0.100409; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2634 0.2215 0.1756 0.1424 0.1142 0.0895 0.0783 0.0659 0.0617 0.0603 0.0590 0.0557 0.0546 0.0539 0.0555 0.0550 

[TRAIN] Epoch[3](1214/1500); Loss: 0.104921; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.2047 0.1428 0.1230 0.1210 0.1076 0.0921 0.0934 0.0882 0.0862 0.0845 0.0860 0.0878 0.0884 0.0883 0.0910 0.0937 

[TRAIN] Epoch[3](1215/1500); Loss: 0.072519; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1072 0.0987 0.0818 0.0733 0.0693 0.0657 0.0631 0.0619 0.0624 0.0644 0.0632 0.0640 0.0680 0.0721 0.0719 0.0735 

[TRAIN] Epoch[3](1216/1500); Loss: 0.173609; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2845 0.2569 0.2311 0.2133 0.1978 0.1832 0.1691 0.1548 0.1437 0.1373 0.1377 0.1347 0.1335 0.1340 0.1336 0.1326 

[TRAIN] Epoch[3](1217/1500); Loss: 0.061747; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1002 0.0806 0.0655 0.0626 0.0602 0.0593 0.0558 0.0537 0.0540 0.0533 0.0539 0.0561 0.0566 0.0567 0.0589 0.0606 

[TRAIN] Epoch[3](1218/1500); Loss: 0.076282; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1103 0.0765 0.1016 0.1021 0.0877 0.0655 0.0636 0.0625 0.0619 0.0624 0.0663 0.0698 0.0694 0.0701 0.0744 0.0765 

[TRAIN] Epoch[3](1219/1500); Loss: 0.080582; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1640 0.1015 0.0764 0.0747 0.0690 0.0620 0.0642 0.0656 0.0666 0.0657 0.0722 0.0747 0.0743 0.0799 0.0886 0.0896 

[TRAIN] Epoch[3](1220/1500); Loss: 0.149446; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1788 0.1672 0.1568 0.1570 0.1522 0.1462 0.1446 0.1413 0.1406 0.1413 0.1420 0.1425 0.1424 0.1448 0.1461 0.1473 

[TRAIN] Epoch[3](1221/1500); Loss: 0.107501; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2088 0.1526 0.1076 0.1056 0.0999 0.0950 0.0963 0.0917 0.0916 0.0907 0.0947 0.0951 0.0965 0.0951 0.0968 0.1021 

[TRAIN] Epoch[3](1222/1500); Loss: 0.091533; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1810 0.1273 0.0884 0.0782 0.0731 0.0721 0.0760 0.0767 0.0770 0.0778 0.0825 0.0860 0.0865 0.0879 0.0958 0.0983 

[TRAIN] Epoch[3](1223/1500); Loss: 0.050925; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0917 0.0674 0.0558 0.0452 0.0504 0.0480 0.0442 0.0441 0.0456 0.0448 0.0449 0.0447 0.0469 0.0460 0.0472 0.0480 

[TRAIN] Epoch[3](1224/1500); Loss: 0.060161; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0988 0.0729 0.0693 0.0627 0.0578 0.0565 0.0550 0.0523 0.0517 0.0529 0.0540 0.0539 0.0547 0.0564 0.0566 0.0570 

[TRAIN] Epoch[3](1225/1500); Loss: 0.060785; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0797 0.0676 0.0623 0.0608 0.0572 0.0602 0.0560 0.0536 0.0546 0.0571 0.0579 0.0578 0.0594 0.0602 0.0631 0.0650 

[TRAIN] Epoch[3](1226/1500); Loss: 0.100386; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1335 0.1037 0.1142 0.1089 0.0993 0.0893 0.0915 0.0889 0.0892 0.0956 0.0972 0.0957 0.0938 0.0987 0.1028 0.1039 

[TRAIN] Epoch[3](1227/1500); Loss: 0.126692; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1642 0.1436 0.1333 0.1332 0.1276 0.1217 0.1189 0.1204 0.1191 0.1187 0.1197 0.1199 0.1201 0.1221 0.1219 0.1227 

[TRAIN] Epoch[3](1228/1500); Loss: 0.221607; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.3959 0.3547 0.3064 0.2730 0.2487 0.2200 0.1914 0.1757 0.1706 0.1741 0.1686 0.1699 0.1717 0.1769 0.1721 0.1760 

[TRAIN] Epoch[3](1229/1500); Loss: 0.111168; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1996 0.1188 0.1096 0.1219 0.1069 0.0927 0.0923 0.0944 0.0983 0.0985 0.1023 0.1042 0.1041 0.1087 0.1128 0.1136 

[TRAIN] Epoch[3](1230/1500); Loss: 0.073512; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1265 0.0811 0.0821 0.0793 0.0710 0.0677 0.0666 0.0634 0.0638 0.0646 0.0663 0.0667 0.0672 0.0688 0.0701 0.0708 

[TRAIN] Epoch[3](1231/1500); Loss: 0.073368; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1393 0.0954 0.0754 0.0782 0.0709 0.0653 0.0623 0.0617 0.0621 0.0623 0.0638 0.0645 0.0657 0.0674 0.0688 0.0707 

[TRAIN] Epoch[3](1232/1500); Loss: 0.110263; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1877 0.1402 0.1075 0.1037 0.1025 0.1026 0.1018 0.0997 0.1003 0.1009 0.1012 0.1019 0.1018 0.1030 0.1042 0.1053 

[TRAIN] Epoch[3](1233/1500); Loss: 0.090055; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1969 0.1512 0.1018 0.0808 0.0753 0.0686 0.0734 0.0681 0.0738 0.0735 0.0784 0.0751 0.0797 0.0800 0.0803 0.0840 

[TRAIN] Epoch[3](1234/1500); Loss: 0.165271; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1759 0.1680 0.1703 0.1692 0.1610 0.1594 0.1590 0.1612 0.1607 0.1603 0.1620 0.1635 0.1656 0.1667 0.1689 0.1728 

[TRAIN] Epoch[3](1235/1500); Loss: 0.081297; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1094 0.0953 0.0881 0.0832 0.0795 0.0769 0.0750 0.0743 0.0734 0.0740 0.0753 0.0763 0.0775 0.0789 0.0808 0.0828 

[TRAIN] Epoch[3](1236/1500); Loss: 0.104698; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1371 0.1127 0.1051 0.0991 0.0963 0.0948 0.0945 0.0948 0.0979 0.0983 0.1006 0.1022 0.1058 0.1087 0.1119 0.1155 

[TRAIN] Epoch[3](1237/1500); Loss: 0.142218; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2127 0.1738 0.1375 0.1337 0.1311 0.1295 0.1291 0.1300 0.1310 0.1314 0.1343 0.1356 0.1370 0.1400 0.1436 0.1452 

[TRAIN] Epoch[3](1238/1500); Loss: 0.105847; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1388 0.1192 0.1076 0.1021 0.0992 0.0963 0.0955 0.0964 0.0974 0.0985 0.1009 0.1035 0.1052 0.1088 0.1110 0.1132 

[TRAIN] Epoch[3](1239/1500); Loss: 0.141492; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1860 0.1652 0.1472 0.1407 0.1368 0.1330 0.1308 0.1280 0.1288 0.1306 0.1325 0.1349 0.1379 0.1405 0.1435 0.1475 

[TRAIN] Epoch[3](1240/1500); Loss: 0.060359; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0697 0.0538 0.0577 0.0524 0.0531 0.0512 0.0530 0.0559 0.0571 0.0570 0.0620 0.0626 0.0661 0.0690 0.0702 0.0750 

[TRAIN] Epoch[3](1241/1500); Loss: 0.229120; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.3652 0.3286 0.2911 0.2656 0.2528 0.2327 0.2111 0.1935 0.1883 0.1859 0.1884 0.1907 0.1887 0.1924 0.1944 0.1965 

[TRAIN] Epoch[3](1242/1500); Loss: 0.162414; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.3128 0.2578 0.1789 0.1472 0.1459 0.1407 0.1365 0.1345 0.1341 0.1343 0.1361 0.1400 0.1441 0.1466 0.1514 0.1579 

[TRAIN] Epoch[3](1243/1500); Loss: 0.095374; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1187 0.1072 0.1015 0.0975 0.0926 0.0884 0.0868 0.0863 0.0865 0.0872 0.0888 0.0918 0.0941 0.0962 0.1003 0.1022 

[TRAIN] Epoch[3](1244/1500); Loss: 0.094088; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1380 0.1035 0.0819 0.0825 0.0805 0.0808 0.0823 0.0844 0.0854 0.0888 0.0918 0.0939 0.0978 0.1007 0.1045 0.1084 

[TRAIN] Epoch[3](1245/1500); Loss: 0.145257; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1779 0.1638 0.1550 0.1512 0.1475 0.1436 0.1402 0.1375 0.1352 0.1344 0.1340 0.1352 0.1382 0.1403 0.1431 0.1470 

[TRAIN] Epoch[3](1246/1500); Loss: 0.138133; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1890 0.1660 0.1474 0.1385 0.1357 0.1329 0.1307 0.1292 0.1287 0.1282 0.1276 0.1273 0.1286 0.1311 0.1335 0.1357 

[TRAIN] Epoch[3](1247/1500); Loss: 0.138493; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2943 0.2498 0.2062 0.1818 0.1649 0.1423 0.1197 0.1037 0.0928 0.0877 0.0887 0.0916 0.0964 0.0951 0.0992 0.1018 

[TRAIN] Epoch[3](1248/1500); Loss: 0.136576; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2412 0.2049 0.1623 0.1441 0.1343 0.1238 0.1147 0.1107 0.1099 0.1113 0.1143 0.1166 0.1192 0.1229 0.1260 0.1290 

[TRAIN] Epoch[3](1249/1500); Loss: 0.150602; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2419 0.2120 0.1782 0.1587 0.1466 0.1389 0.1334 0.1297 0.1282 0.1284 0.1301 0.1322 0.1340 0.1364 0.1390 0.1418 

[TRAIN] Epoch[3](1250/1500); Loss: 0.127798; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1922 0.1644 0.1395 0.1290 0.1242 0.1194 0.1145 0.1117 0.1110 0.1122 0.1144 0.1175 0.1189 0.1221 0.1262 0.1275 

[TRAIN] Epoch[3](1251/1500); Loss: 0.092125; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1183 0.1045 0.0993 0.0906 0.0848 0.0794 0.0800 0.0818 0.0831 0.0852 0.0885 0.0901 0.0927 0.0964 0.0984 0.1009 

[TRAIN] Epoch[3](1252/1500); Loss: 0.135288; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.2445 0.2073 0.1547 0.1312 0.1208 0.1157 0.1134 0.1128 0.1131 0.1147 0.1169 0.1186 0.1209 0.1242 0.1268 0.1291 

[TRAIN] Epoch[3](1253/1500); Loss: 0.146460; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2645 0.2223 0.1592 0.1279 0.1206 0.1184 0.1191 0.1209 0.1235 0.1269 0.1291 0.1330 0.1379 0.1416 0.1466 0.1519 

[TRAIN] Epoch[3](1254/1500); Loss: 0.134464; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2337 0.1984 0.1562 0.1343 0.1235 0.1187 0.1167 0.1150 0.1149 0.1150 0.1161 0.1179 0.1195 0.1213 0.1239 0.1263 

[TRAIN] Epoch[3](1255/1500); Loss: 0.118031; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1958 0.1669 0.1325 0.1143 0.1046 0.1013 0.0992 0.0995 0.1007 0.1021 0.1043 0.1072 0.1103 0.1135 0.1163 0.1201 

[TRAIN] Epoch[3](1256/1500); Loss: 0.086794; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2263 0.1793 0.1381 0.1096 0.0860 0.0663 0.0535 0.0491 0.0496 0.0530 0.0548 0.0588 0.0608 0.0640 0.0686 0.0709 

[TRAIN] Epoch[3](1257/1500); Loss: 0.052985; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0516 0.0416 0.0452 0.0407 0.0426 0.0421 0.0456 0.0490 0.0494 0.0539 0.0576 0.0585 0.0626 0.0675 0.0676 0.0724 

[TRAIN] Epoch[3](1258/1500); Loss: 0.152181; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1946 0.1750 0.1624 0.1560 0.1509 0.1450 0.1396 0.1377 0.1396 0.1404 0.1429 0.1457 0.1474 0.1497 0.1524 0.1555 

[TRAIN] Epoch[3](1259/1500); Loss: 0.131142; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1805 0.1541 0.1370 0.1307 0.1282 0.1251 0.1222 0.1216 0.1208 0.1210 0.1225 0.1233 0.1252 0.1275 0.1285 0.1301 

[TRAIN] Epoch[3](1260/1500); Loss: 0.165957; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2042 0.1834 0.1741 0.1685 0.1648 0.1618 0.1589 0.1571 0.1560 0.1560 0.1589 0.1594 0.1599 0.1616 0.1642 0.1666 

[TRAIN] Epoch[3](1261/1500); Loss: 0.140573; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.2539 0.2048 0.1449 0.1250 0.1241 0.1212 0.1193 0.1201 0.1228 0.1229 0.1249 0.1279 0.1300 0.1327 0.1359 0.1389 

[TRAIN] Epoch[3](1262/1500); Loss: 0.180999; Backpropagation: 0.0915 sec; Batch: 0.4237 sec
0.3749 0.3244 0.2797 0.2529 0.2335 0.2075 0.1773 0.1529 0.1335 0.1161 0.1036 0.1022 0.1073 0.1098 0.1089 0.1116 

[TRAIN] Epoch[3](1263/1500); Loss: 0.119189; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1560 0.1230 0.1253 0.1229 0.1178 0.1113 0.1102 0.1106 0.1106 0.1119 0.1137 0.1151 0.1167 0.1190 0.1204 0.1226 

[TRAIN] Epoch[3](1264/1500); Loss: 0.067190; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.0678 0.0619 0.0573 0.0600 0.0587 0.0580 0.0605 0.0637 0.0644 0.0662 0.0701 0.0726 0.0736 0.0775 0.0806 0.0823 

[TRAIN] Epoch[3](1265/1500); Loss: 0.174910; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.3381 0.2928 0.2542 0.2312 0.2140 0.1916 0.1670 0.1461 0.1321 0.1205 0.1134 0.1140 0.1186 0.1203 0.1211 0.1236 

[TRAIN] Epoch[3](1266/1500); Loss: 0.148291; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1919 0.1708 0.1543 0.1492 0.1454 0.1413 0.1388 0.1390 0.1386 0.1386 0.1397 0.1411 0.1429 0.1449 0.1467 0.1493 

[TRAIN] Epoch[3](1267/1500); Loss: 0.122921; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1587 0.1426 0.1288 0.1235 0.1197 0.1156 0.1135 0.1131 0.1135 0.1145 0.1159 0.1168 0.1197 0.1211 0.1233 0.1262 

[TRAIN] Epoch[3](1268/1500); Loss: 0.108038; Backpropagation: 0.0915 sec; Batch: 0.4234 sec
0.1763 0.1426 0.1139 0.1026 0.0995 0.0952 0.0944 0.0944 0.0947 0.0958 0.0975 0.1008 0.1016 0.1037 0.1073 0.1084 

[TRAIN] Epoch[3](1269/1500); Loss: 0.088966; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1550 0.1200 0.0937 0.0889 0.0853 0.0811 0.0775 0.0771 0.0763 0.0769 0.0777 0.0795 0.0808 0.0823 0.0849 0.0866 

[TRAIN] Epoch[3](1270/1500); Loss: 0.133858; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1913 0.1560 0.1316 0.1308 0.1278 0.1254 0.1247 0.1248 0.1242 0.1242 0.1257 0.1274 0.1283 0.1307 0.1336 0.1351 

[TRAIN] Epoch[3](1271/1500); Loss: 0.094018; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1493 0.1123 0.0864 0.0857 0.0871 0.0837 0.0832 0.0842 0.0854 0.0864 0.0881 0.0902 0.0925 0.0948 0.0963 0.0988 

[TRAIN] Epoch[3](1272/1500); Loss: 0.180935; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.2108 0.1964 0.1872 0.1842 0.1802 0.1769 0.1749 0.1737 0.1747 0.1742 0.1747 0.1755 0.1767 0.1774 0.1781 0.1794 

[TRAIN] Epoch[3](1273/1500); Loss: 0.076931; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1060 0.0812 0.0737 0.0704 0.0692 0.0689 0.0700 0.0709 0.0719 0.0737 0.0747 0.0765 0.0786 0.0797 0.0819 0.0835 

[TRAIN] Epoch[3](1274/1500); Loss: 0.106611; Backpropagation: 0.0915 sec; Batch: 0.4236 sec
0.2208 0.1759 0.1326 0.1213 0.1149 0.1049 0.0959 0.0913 0.0863 0.0819 0.0795 0.0781 0.0781 0.0794 0.0810 0.0837 

[TRAIN] Epoch[3](1275/1500); Loss: 0.086575; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1334 0.0929 0.0975 0.0980 0.0888 0.0799 0.0755 0.0758 0.0752 0.0766 0.0776 0.0796 0.0803 0.0827 0.0845 0.0869 

[TRAIN] Epoch[3](1276/1500); Loss: 0.068748; Backpropagation: 0.0914 sec; Batch: 0.4231 sec
0.1568 0.1135 0.0781 0.0579 0.0530 0.0516 0.0495 0.0524 0.0514 0.0561 0.0555 0.0599 0.0617 0.0648 0.0669 0.0709 

[TRAIN] Epoch[3](1277/1500); Loss: 0.097355; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1256 0.1126 0.1028 0.0989 0.0949 0.0904 0.0892 0.0892 0.0899 0.0915 0.0923 0.0931 0.0941 0.0960 0.0979 0.0993 

[TRAIN] Epoch[3](1278/1500); Loss: 0.128913; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2936 0.2405 0.1675 0.1194 0.1183 0.1145 0.1066 0.0995 0.1000 0.1002 0.0986 0.0989 0.0998 0.1014 0.1015 0.1022 

[TRAIN] Epoch[3](1279/1500); Loss: 0.144063; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1587 0.1468 0.1479 0.1460 0.1436 0.1415 0.1400 0.1402 0.1406 0.1414 0.1415 0.1418 0.1421 0.1436 0.1441 0.1451 

[TRAIN] Epoch[3](1280/1500); Loss: 0.065617; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1425 0.0778 0.0691 0.0714 0.0633 0.0561 0.0527 0.0527 0.0523 0.0541 0.0561 0.0578 0.0580 0.0601 0.0623 0.0636 

[TRAIN] Epoch[3](1281/1500); Loss: 0.138449; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2784 0.2040 0.1548 0.1488 0.1421 0.1313 0.1227 0.1216 0.1173 0.1125 0.1110 0.1128 0.1115 0.1135 0.1165 0.1163 

[TRAIN] Epoch[3](1282/1500); Loss: 0.122971; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2843 0.2239 0.1672 0.1468 0.1360 0.1208 0.1062 0.0966 0.0892 0.0844 0.0814 0.0832 0.0856 0.0855 0.0870 0.0896 

[TRAIN] Epoch[3](1283/1500); Loss: 0.214345; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3729 0.3300 0.2960 0.2652 0.2390 0.2138 0.1900 0.1739 0.1684 0.1679 0.1679 0.1662 0.1686 0.1688 0.1700 0.1710 

[TRAIN] Epoch[3](1284/1500); Loss: 0.144417; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.3081 0.2409 0.1752 0.1411 0.1462 0.1401 0.1297 0.1205 0.1164 0.1148 0.1117 0.1118 0.1130 0.1127 0.1132 0.1153 

[TRAIN] Epoch[3](1285/1500); Loss: 0.136625; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2373 0.2116 0.1923 0.1781 0.1631 0.1467 0.1298 0.1167 0.1051 0.0977 0.0976 0.1006 0.1022 0.1008 0.1022 0.1042 

[TRAIN] Epoch[3](1286/1500); Loss: 0.137622; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2657 0.2108 0.1647 0.1464 0.1450 0.1345 0.1212 0.1134 0.1110 0.1117 0.1103 0.1105 0.1127 0.1137 0.1137 0.1166 

[TRAIN] Epoch[3](1287/1500); Loss: 0.153078; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2843 0.2254 0.1749 0.1502 0.1431 0.1438 0.1411 0.1370 0.1338 0.1321 0.1307 0.1306 0.1301 0.1303 0.1308 0.1311 

[TRAIN] Epoch[3](1288/1500); Loss: 0.145540; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1993 0.1735 0.1609 0.1520 0.1449 0.1394 0.1349 0.1331 0.1335 0.1345 0.1346 0.1350 0.1360 0.1371 0.1391 0.1407 

[TRAIN] Epoch[3](1289/1500); Loss: 0.198019; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2824 0.2579 0.2432 0.2362 0.2279 0.2154 0.2012 0.1897 0.1825 0.1749 0.1665 0.1604 0.1585 0.1584 0.1572 0.1560 

[TRAIN] Epoch[3](1290/1500); Loss: 0.087058; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1635 0.0996 0.0789 0.0959 0.0912 0.0803 0.0719 0.0712 0.0725 0.0731 0.0758 0.0786 0.0808 0.0829 0.0868 0.0898 

[TRAIN] Epoch[3](1291/1500); Loss: 0.138470; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1842 0.1531 0.1378 0.1398 0.1434 0.1438 0.1392 0.1340 0.1306 0.1292 0.1290 0.1291 0.1294 0.1300 0.1311 0.1317 

[TRAIN] Epoch[3](1292/1500); Loss: 0.145735; Backpropagation: 0.0915 sec; Batch: 0.4230 sec
0.2740 0.2223 0.2014 0.2032 0.1913 0.1706 0.1467 0.1281 0.1153 0.1046 0.0965 0.0938 0.0963 0.0963 0.0957 0.0955 

[TRAIN] Epoch[3](1293/1500); Loss: 0.128575; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2910 0.2209 0.1579 0.1198 0.1096 0.1207 0.1187 0.1114 0.1043 0.1008 0.1016 0.0988 0.0988 0.1004 0.1012 0.1013 

[TRAIN] Epoch[3](1294/1500); Loss: 0.086172; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1513 0.1168 0.1009 0.0929 0.0885 0.0878 0.0820 0.0768 0.0721 0.0704 0.0713 0.0715 0.0717 0.0732 0.0752 0.0764 

[TRAIN] Epoch[3](1295/1500); Loss: 0.126984; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.3250 0.2752 0.2327 0.1958 0.1645 0.1332 0.1010 0.0748 0.0620 0.0612 0.0642 0.0678 0.0655 0.0650 0.0700 0.0739 

[TRAIN] Epoch[3](1296/1500); Loss: 0.137820; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1913 0.1446 0.1229 0.1287 0.1481 0.1536 0.1468 0.1364 0.1289 0.1291 0.1299 0.1287 0.1269 0.1277 0.1305 0.1310 

[TRAIN] Epoch[3](1297/1500); Loss: 0.126735; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2599 0.2205 0.1912 0.1658 0.1414 0.1177 0.0991 0.0901 0.0892 0.0898 0.0912 0.0911 0.0917 0.0951 0.0966 0.0973 

[TRAIN] Epoch[3](1298/1500); Loss: 0.076615; Backpropagation: 0.0915 sec; Batch: 0.4233 sec
0.0914 0.0823 0.0983 0.0958 0.0855 0.0758 0.0710 0.0698 0.0681 0.0668 0.0667 0.0688 0.0689 0.0703 0.0724 0.0739 

[TRAIN] Epoch[3](1299/1500); Loss: 0.156514; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2053 0.1764 0.1648 0.1658 0.1668 0.1612 0.1536 0.1482 0.1459 0.1454 0.1447 0.1433 0.1438 0.1457 0.1467 0.1464 

[TRAIN] Epoch[3](1300/1500); Loss: 0.049308; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.0796 0.0592 0.0549 0.0486 0.0452 0.0402 0.0409 0.0411 0.0415 0.0424 0.0444 0.0465 0.0476 0.0497 0.0525 0.0548 

[TRAIN] Epoch[3](1301/1500); Loss: 0.124022; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2273 0.1683 0.1266 0.1141 0.1283 0.1346 0.1258 0.1146 0.1062 0.1047 0.1065 0.1048 0.1045 0.1045 0.1064 0.1073 

[TRAIN] Epoch[3](1302/1500); Loss: 0.111257; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1558 0.1301 0.1238 0.1255 0.1242 0.1190 0.1113 0.1051 0.1005 0.0978 0.0972 0.0979 0.0972 0.0976 0.0979 0.0994 

[TRAIN] Epoch[3](1303/1500); Loss: 0.086144; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1416 0.1161 0.1025 0.0952 0.0894 0.0824 0.0764 0.0735 0.0729 0.0726 0.0718 0.0734 0.0750 0.0768 0.0782 0.0804 

[TRAIN] Epoch[3](1304/1500); Loss: 0.131708; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1681 0.1459 0.1331 0.1314 0.1341 0.1364 0.1356 0.1330 0.1300 0.1264 0.1233 0.1221 0.1227 0.1223 0.1212 0.1218 

[TRAIN] Epoch[3](1305/1500); Loss: 0.128613; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1844 0.1490 0.1435 0.1498 0.1543 0.1434 0.1275 0.1155 0.1108 0.1119 0.1097 0.1079 0.1083 0.1125 0.1138 0.1156 

[TRAIN] Epoch[3](1306/1500); Loss: 0.120331; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1861 0.1543 0.1349 0.1220 0.1167 0.1179 0.1177 0.1157 0.1128 0.1080 0.1048 0.1046 0.1060 0.1064 0.1075 0.1101 

[TRAIN] Epoch[3](1307/1500); Loss: 0.143874; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1964 0.1679 0.1575 0.1598 0.1592 0.1539 0.1446 0.1365 0.1315 0.1304 0.1288 0.1275 0.1263 0.1261 0.1274 0.1283 

[TRAIN] Epoch[3](1308/1500); Loss: 0.133209; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.3612 0.2620 0.1741 0.1298 0.1058 0.1014 0.1109 0.1051 0.1024 0.0963 0.0927 0.0953 0.0953 0.0970 0.0994 0.1027 

[TRAIN] Epoch[3](1309/1500); Loss: 0.145052; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1859 0.1620 0.1521 0.1541 0.1571 0.1529 0.1474 0.1407 0.1367 0.1350 0.1339 0.1325 0.1319 0.1325 0.1331 0.1332 

[TRAIN] Epoch[3](1310/1500); Loss: 0.134708; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1854 0.1592 0.1475 0.1448 0.1436 0.1391 0.1348 0.1296 0.1257 0.1237 0.1217 0.1199 0.1195 0.1199 0.1202 0.1207 

[TRAIN] Epoch[3](1311/1500); Loss: 0.228656; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.4022 0.3587 0.3241 0.2914 0.2605 0.2312 0.2046 0.1826 0.1712 0.1715 0.1745 0.1730 0.1755 0.1780 0.1789 0.1805 

[TRAIN] Epoch[3](1312/1500); Loss: 0.138921; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2377 0.1927 0.1561 0.1394 0.1337 0.1380 0.1398 0.1351 0.1270 0.1208 0.1181 0.1189 0.1177 0.1161 0.1153 0.1163 

[TRAIN] Epoch[3](1313/1500); Loss: 0.100399; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1302 0.1153 0.1094 0.1094 0.1074 0.1035 0.1003 0.0964 0.0936 0.0920 0.0914 0.0913 0.0909 0.0913 0.0918 0.0923 

[TRAIN] Epoch[3](1314/1500); Loss: 0.166866; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.4677 0.3495 0.2345 0.1369 0.1040 0.1338 0.1294 0.1264 0.1186 0.1131 0.1238 0.1201 0.1218 0.1244 0.1283 0.1376 

[TRAIN] Epoch[3](1315/1500); Loss: 0.084602; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1180 0.0900 0.0798 0.0844 0.0827 0.0810 0.0770 0.0757 0.0765 0.0791 0.0811 0.0820 0.0837 0.0852 0.0878 0.0896 

[TRAIN] Epoch[3](1316/1500); Loss: 0.098474; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2057 0.1380 0.1010 0.1030 0.1043 0.1007 0.0904 0.0834 0.0801 0.0795 0.0787 0.0793 0.0806 0.0823 0.0835 0.0852 

[TRAIN] Epoch[3](1317/1500); Loss: 0.120923; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1842 0.1475 0.1374 0.1330 0.1267 0.1236 0.1164 0.1108 0.1066 0.1047 0.1053 0.1069 0.1065 0.1068 0.1076 0.1107 

[TRAIN] Epoch[3](1318/1500); Loss: 0.110037; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1575 0.1317 0.1196 0.1181 0.1194 0.1193 0.1160 0.1095 0.1028 0.0980 0.0959 0.0955 0.0945 0.0939 0.0940 0.0948 

[TRAIN] Epoch[3](1319/1500); Loss: 0.133899; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2118 0.1762 0.1498 0.1404 0.1359 0.1316 0.1266 0.1229 0.1205 0.1191 0.1182 0.1176 0.1179 0.1181 0.1178 0.1181 

[TRAIN] Epoch[3](1320/1500); Loss: 0.117986; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1697 0.1322 0.1140 0.1133 0.1190 0.1184 0.1131 0.1102 0.1088 0.1084 0.1092 0.1116 0.1121 0.1131 0.1159 0.1189 

[TRAIN] Epoch[3](1321/1500); Loss: 0.134848; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.3558 0.3040 0.2637 0.2253 0.1891 0.1534 0.1178 0.0851 0.0623 0.0541 0.0547 0.0589 0.0577 0.0549 0.0567 0.0640 

[TRAIN] Epoch[3](1322/1500); Loss: 0.141501; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2193 0.1782 0.1546 0.1529 0.1511 0.1471 0.1360 0.1288 0.1249 0.1239 0.1241 0.1232 0.1234 0.1244 0.1257 0.1265 

[TRAIN] Epoch[3](1323/1500); Loss: 0.179226; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.3025 0.2493 0.2101 0.1852 0.1820 0.1859 0.1780 0.1676 0.1578 0.1519 0.1502 0.1487 0.1482 0.1486 0.1505 0.1513 

[TRAIN] Epoch[3](1324/1500); Loss: 0.121400; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1742 0.1501 0.1391 0.1335 0.1260 0.1193 0.1131 0.1104 0.1098 0.1090 0.1095 0.1096 0.1090 0.1089 0.1100 0.1112 

[TRAIN] Epoch[3](1325/1500); Loss: 0.147698; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2106 0.1859 0.1816 0.1715 0.1580 0.1461 0.1405 0.1416 0.1423 0.1366 0.1300 0.1253 0.1243 0.1246 0.1226 0.1214 

[TRAIN] Epoch[3](1326/1500); Loss: 0.141461; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2560 0.2181 0.1876 0.1698 0.1543 0.1410 0.1296 0.1217 0.1176 0.1139 0.1106 0.1092 0.1079 0.1080 0.1086 0.1096 

[TRAIN] Epoch[3](1327/1500); Loss: 0.048776; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0919 0.0656 0.0527 0.0461 0.0446 0.0405 0.0408 0.0399 0.0408 0.0417 0.0434 0.0436 0.0446 0.0460 0.0484 0.0499 

[TRAIN] Epoch[3](1328/1500); Loss: 0.144355; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1350 0.1416 0.1490 0.1422 0.1395 0.1389 0.1413 0.1435 0.1426 0.1420 0.1442 0.1469 0.1469 0.1492 0.1525 0.1545 

[TRAIN] Epoch[3](1329/1500); Loss: 0.077716; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1204 0.0970 0.0951 0.0898 0.0824 0.0761 0.0704 0.0675 0.0667 0.0658 0.0664 0.0674 0.0682 0.0691 0.0698 0.0712 

[TRAIN] Epoch[3](1330/1500); Loss: 0.085838; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.1967 0.1612 0.1351 0.1115 0.0897 0.0723 0.0638 0.0614 0.0595 0.0602 0.0584 0.0589 0.0602 0.0613 0.0611 0.0621 

[TRAIN] Epoch[3](1331/1500); Loss: 0.144286; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2122 0.1828 0.1631 0.1519 0.1465 0.1447 0.1413 0.1375 0.1336 0.1307 0.1295 0.1280 0.1270 0.1260 0.1264 0.1273 

[TRAIN] Epoch[3](1332/1500); Loss: 0.140450; Backpropagation: 0.0915 sec; Batch: 0.4231 sec
0.2057 0.1696 0.1591 0.1508 0.1468 0.1422 0.1349 0.1301 0.1266 0.1251 0.1264 0.1258 0.1249 0.1252 0.1264 0.1276 

[TRAIN] Epoch[3](1333/1500); Loss: 0.157854; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1752 0.1625 0.1630 0.1661 0.1644 0.1602 0.1553 0.1523 0.1519 0.1524 0.1523 0.1522 0.1527 0.1541 0.1552 0.1558 

[TRAIN] Epoch[3](1334/1500); Loss: 0.092754; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1397 0.1158 0.1081 0.1013 0.0949 0.0911 0.0875 0.0847 0.0828 0.0813 0.0814 0.0818 0.0822 0.0832 0.0837 0.0846 

[TRAIN] Epoch[3](1335/1500); Loss: 0.126083; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3183 0.2418 0.1738 0.1250 0.1010 0.1070 0.1098 0.1027 0.0947 0.0895 0.0897 0.0919 0.0915 0.0921 0.0940 0.0945 

[TRAIN] Epoch[3](1336/1500); Loss: 0.167252; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2579 0.2263 0.2081 0.1935 0.1806 0.1689 0.1609 0.1551 0.1497 0.1452 0.1412 0.1385 0.1373 0.1380 0.1379 0.1369 

[TRAIN] Epoch[3](1337/1500); Loss: 0.141756; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1886 0.1656 0.1593 0.1527 0.1447 0.1389 0.1351 0.1334 0.1328 0.1312 0.1298 0.1301 0.1303 0.1314 0.1317 0.1324 

[TRAIN] Epoch[3](1338/1500); Loss: 0.180506; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.3502 0.2958 0.2521 0.2210 0.1975 0.1816 0.1728 0.1646 0.1545 0.1417 0.1316 0.1259 0.1248 0.1245 0.1244 0.1250 

[TRAIN] Epoch[3](1339/1500); Loss: 0.150733; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2136 0.1874 0.1770 0.1736 0.1663 0.1546 0.1431 0.1361 0.1335 0.1329 0.1317 0.1315 0.1318 0.1323 0.1329 0.1334 

[TRAIN] Epoch[3](1340/1500); Loss: 0.040978; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0867 0.0579 0.0399 0.0384 0.0358 0.0325 0.0333 0.0335 0.0334 0.0341 0.0345 0.0366 0.0381 0.0389 0.0400 0.0420 

[TRAIN] Epoch[3](1341/1500); Loss: 0.123900; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1840 0.1543 0.1398 0.1338 0.1307 0.1268 0.1212 0.1148 0.1109 0.1099 0.1095 0.1085 0.1086 0.1095 0.1097 0.1105 

[TRAIN] Epoch[3](1342/1500); Loss: 0.146754; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.3089 0.2457 0.2039 0.1734 0.1465 0.1315 0.1285 0.1204 0.1153 0.1121 0.1102 0.1106 0.1093 0.1098 0.1103 0.1117 

[TRAIN] Epoch[3](1343/1500); Loss: 0.080236; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1271 0.0993 0.0830 0.0810 0.0786 0.0749 0.0716 0.0701 0.0714 0.0717 0.0728 0.0740 0.0755 0.0755 0.0774 0.0799 

[TRAIN] Epoch[3](1344/1500); Loss: 0.080111; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1220 0.1076 0.1104 0.1018 0.0867 0.0750 0.0697 0.0673 0.0671 0.0651 0.0652 0.0661 0.0675 0.0686 0.0697 0.0719 

[TRAIN] Epoch[3](1345/1500); Loss: 0.131447; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2554 0.1985 0.1745 0.1752 0.1643 0.1462 0.1267 0.1133 0.1026 0.0962 0.0908 0.0905 0.0906 0.0927 0.0923 0.0934 

[TRAIN] Epoch[3](1346/1500); Loss: 0.137663; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2073 0.1791 0.1700 0.1589 0.1439 0.1327 0.1285 0.1280 0.1247 0.1209 0.1182 0.1177 0.1189 0.1179 0.1175 0.1183 

[TRAIN] Epoch[3](1347/1500); Loss: 0.066730; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0921 0.0703 0.0737 0.0767 0.0743 0.0679 0.0630 0.0603 0.0596 0.0586 0.0589 0.0608 0.0607 0.0618 0.0631 0.0659 

[TRAIN] Epoch[3](1348/1500); Loss: 0.137731; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1891 0.1646 0.1532 0.1458 0.1411 0.1386 0.1333 0.1299 0.1272 0.1254 0.1251 0.1248 0.1256 0.1257 0.1269 0.1274 

[TRAIN] Epoch[3](1349/1500); Loss: 0.153125; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.4652 0.3383 0.2246 0.1241 0.0961 0.1184 0.1097 0.1035 0.0987 0.1029 0.1093 0.1050 0.1065 0.1112 0.1168 0.1196 

[TRAIN] Epoch[3](1350/1500); Loss: 0.155967; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.2547 0.2234 0.2018 0.1851 0.1679 0.1515 0.1402 0.1347 0.1318 0.1299 0.1269 0.1259 0.1284 0.1295 0.1314 0.1322 

[TRAIN] Epoch[3](1351/1500); Loss: 0.144921; Backpropagation: 0.0916 sec; Batch: 0.4254 sec
0.3534 0.2714 0.2010 0.1540 0.1243 0.1130 0.1139 0.1071 0.1052 0.1055 0.1072 0.1075 0.1090 0.1137 0.1156 0.1170 

[TRAIN] Epoch[3](1352/1500); Loss: 0.177777; Backpropagation: 0.0919 sec; Batch: 0.4247 sec
0.2566 0.2279 0.2114 0.1993 0.1877 0.1780 0.1725 0.1684 0.1638 0.1599 0.1560 0.1543 0.1524 0.1520 0.1522 0.1520 

[TRAIN] Epoch[3](1353/1500); Loss: 0.110070; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1876 0.1432 0.1216 0.1171 0.1177 0.1155 0.1086 0.1006 0.0958 0.0931 0.0931 0.0924 0.0928 0.0931 0.0938 0.0950 

[TRAIN] Epoch[3](1354/1500); Loss: 0.075424; Backpropagation: 0.0916 sec; Batch: 0.4242 sec
0.2020 0.1170 0.0672 0.0741 0.0755 0.0679 0.0602 0.0576 0.0577 0.0574 0.0583 0.0601 0.0611 0.0617 0.0637 0.0653 

[TRAIN] Epoch[3](1355/1500); Loss: 0.120272; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2048 0.1689 0.1414 0.1222 0.1118 0.1079 0.1067 0.1060 0.1050 0.1043 0.1057 0.1071 0.1071 0.1069 0.1081 0.1104 

[TRAIN] Epoch[3](1356/1500); Loss: 0.098189; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1664 0.1352 0.1153 0.1040 0.0978 0.0946 0.0917 0.0890 0.0864 0.0846 0.0841 0.0840 0.0840 0.0840 0.0847 0.0852 

[TRAIN] Epoch[3](1357/1500); Loss: 0.177116; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2905 0.2587 0.2415 0.2285 0.2140 0.1973 0.1804 0.1643 0.1503 0.1392 0.1313 0.1277 0.1273 0.1266 0.1287 0.1275 

[TRAIN] Epoch[3](1358/1500); Loss: 0.108473; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2690 0.1987 0.1453 0.1084 0.0983 0.0986 0.0912 0.0828 0.0790 0.0789 0.0799 0.0782 0.0797 0.0809 0.0833 0.0834 

[TRAIN] Epoch[3](1359/1500); Loss: 0.125513; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1817 0.1566 0.1417 0.1352 0.1315 0.1278 0.1222 0.1174 0.1152 0.1140 0.1134 0.1125 0.1109 0.1099 0.1092 0.1091 

[TRAIN] Epoch[3](1360/1500); Loss: 0.060608; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1527 0.1156 0.0920 0.0734 0.0579 0.0479 0.0434 0.0407 0.0398 0.0405 0.0404 0.0415 0.0437 0.0446 0.0470 0.0486 

[TRAIN] Epoch[3](1361/1500); Loss: 0.130545; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2371 0.1931 0.1618 0.1435 0.1329 0.1271 0.1212 0.1165 0.1129 0.1109 0.1087 0.1068 0.1044 0.1033 0.1041 0.1044 

[TRAIN] Epoch[3](1362/1500); Loss: 0.106770; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2687 0.2151 0.1663 0.1357 0.1121 0.0936 0.0805 0.0742 0.0717 0.0713 0.0705 0.0700 0.0699 0.0693 0.0694 0.0700 

[TRAIN] Epoch[3](1363/1500); Loss: 0.131259; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1695 0.1497 0.1452 0.1431 0.1380 0.1324 0.1277 0.1241 0.1224 0.1210 0.1203 0.1203 0.1211 0.1211 0.1214 0.1228 

[TRAIN] Epoch[3](1364/1500); Loss: 0.121343; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2175 0.1682 0.1514 0.1397 0.1318 0.1259 0.1168 0.1071 0.0983 0.0950 0.0949 0.0962 0.0961 0.0983 0.1012 0.1031 

[TRAIN] Epoch[3](1365/1500); Loss: 0.108090; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2084 0.1751 0.1540 0.1369 0.1168 0.0956 0.0838 0.0831 0.0811 0.0830 0.0820 0.0815 0.0843 0.0858 0.0882 0.0899 

[TRAIN] Epoch[3](1366/1500); Loss: 0.132657; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.3972 0.3159 0.2360 0.1691 0.1167 0.0873 0.0844 0.0857 0.0817 0.0776 0.0772 0.0775 0.0780 0.0773 0.0803 0.0808 

[TRAIN] Epoch[3](1367/1500); Loss: 0.117811; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1807 0.1539 0.1405 0.1308 0.1227 0.1183 0.1125 0.1068 0.1047 0.1030 0.1025 0.1017 0.1015 0.1014 0.1019 0.1021 

[TRAIN] Epoch[3](1368/1500); Loss: 0.045528; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0555 0.0444 0.0501 0.0487 0.0426 0.0417 0.0440 0.0419 0.0420 0.0422 0.0426 0.0443 0.0450 0.0464 0.0475 0.0495 

[TRAIN] Epoch[3](1369/1500); Loss: 0.115908; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1979 0.1565 0.1337 0.1222 0.1160 0.1123 0.1086 0.1041 0.1010 0.0992 0.0986 0.0985 0.0998 0.1000 0.1018 0.1043 

[TRAIN] Epoch[3](1370/1500); Loss: 0.104179; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2129 0.1475 0.1156 0.1198 0.1149 0.1043 0.0921 0.0853 0.0835 0.0813 0.0827 0.0830 0.0834 0.0841 0.0867 0.0897 

[TRAIN] Epoch[3](1371/1500); Loss: 0.161655; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2316 0.2034 0.1860 0.1757 0.1708 0.1641 0.1582 0.1516 0.1477 0.1456 0.1437 0.1422 0.1409 0.1414 0.1417 0.1417 

[TRAIN] Epoch[3](1372/1500); Loss: 0.181233; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.3404 0.2566 0.2046 0.1751 0.1796 0.1773 0.1674 0.1594 0.1557 0.1565 0.1541 0.1527 0.1536 0.1552 0.1555 0.1561 

[TRAIN] Epoch[3](1373/1500); Loss: 0.202594; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2620 0.2285 0.2154 0.2145 0.2140 0.2111 0.2068 0.2012 0.1947 0.1899 0.1865 0.1850 0.1844 0.1831 0.1824 0.1821 

[TRAIN] Epoch[3](1374/1500); Loss: 0.104501; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2116 0.1453 0.1007 0.1090 0.1114 0.1028 0.0904 0.0859 0.0851 0.0864 0.0863 0.0893 0.0904 0.0912 0.0911 0.0950 

[TRAIN] Epoch[3](1375/1500); Loss: 0.156684; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.3241 0.2601 0.2091 0.1824 0.1669 0.1559 0.1502 0.1403 0.1294 0.1201 0.1145 0.1132 0.1107 0.1102 0.1092 0.1107 

[TRAIN] Epoch[3](1376/1500); Loss: 0.189949; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.4520 0.3941 0.3577 0.3166 0.2712 0.2251 0.1809 0.1410 0.1072 0.0859 0.0839 0.0842 0.0843 0.0833 0.0847 0.0870 

[TRAIN] Epoch[3](1377/1500); Loss: 0.183946; Backpropagation: 0.0921 sec; Batch: 0.4248 sec
0.2988 0.2663 0.2494 0.2320 0.2123 0.1940 0.1827 0.1722 0.1628 0.1537 0.1450 0.1400 0.1368 0.1341 0.1329 0.1301 

[TRAIN] Epoch[3](1378/1500); Loss: 0.108330; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1672 0.1315 0.1239 0.1239 0.1200 0.1137 0.1054 0.1005 0.0952 0.0926 0.0928 0.0937 0.0931 0.0926 0.0930 0.0941 

[TRAIN] Epoch[3](1379/1500); Loss: 0.165456; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2578 0.2297 0.2101 0.1958 0.1835 0.1702 0.1564 0.1455 0.1396 0.1372 0.1365 0.1354 0.1354 0.1373 0.1389 0.1379 

[TRAIN] Epoch[3](1380/1500); Loss: 0.152605; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.3175 0.2583 0.2257 0.1961 0.1595 0.1377 0.1371 0.1256 0.1173 0.1114 0.1097 0.1123 0.1081 0.1073 0.1080 0.1101 

[TRAIN] Epoch[3](1381/1500); Loss: 0.135726; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3736 0.2923 0.2367 0.1756 0.1193 0.1078 0.1030 0.0941 0.0867 0.0834 0.0863 0.0828 0.0807 0.0814 0.0829 0.0850 

[TRAIN] Epoch[3](1382/1500); Loss: 0.193018; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2485 0.2127 0.2020 0.1998 0.2000 0.1977 0.1922 0.1863 0.1828 0.1817 0.1808 0.1804 0.1805 0.1803 0.1813 0.1814 

[TRAIN] Epoch[3](1383/1500); Loss: 0.145611; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2759 0.2196 0.1975 0.1993 0.1884 0.1699 0.1492 0.1340 0.1199 0.1085 0.0997 0.0944 0.0922 0.0927 0.0940 0.0945 

[TRAIN] Epoch[3](1384/1500); Loss: 0.170133; Backpropagation: 0.0915 sec; Batch: 0.4228 sec
0.3965 0.3033 0.2345 0.1797 0.1435 0.1542 0.1483 0.1393 0.1286 0.1308 0.1298 0.1258 0.1264 0.1267 0.1262 0.1284 

[TRAIN] Epoch[3](1385/1500); Loss: 0.158311; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2889 0.2283 0.1800 0.1515 0.1599 0.1622 0.1540 0.1437 0.1365 0.1355 0.1355 0.1328 0.1313 0.1308 0.1315 0.1304 

[TRAIN] Epoch[3](1386/1500); Loss: 0.133061; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.3861 0.2605 0.1686 0.1016 0.1245 0.1242 0.1119 0.0967 0.0918 0.0954 0.0930 0.0900 0.0921 0.0947 0.1001 0.0978 

[TRAIN] Epoch[3](1387/1500); Loss: 0.145166; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2281 0.1830 0.1683 0.1609 0.1636 0.1577 0.1461 0.1346 0.1270 0.1232 0.1221 0.1215 0.1199 0.1208 0.1222 0.1237 

[TRAIN] Epoch[3](1388/1500); Loss: 0.131636; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1829 0.1528 0.1354 0.1299 0.1316 0.1293 0.1242 0.1201 0.1187 0.1196 0.1217 0.1240 0.1260 0.1275 0.1300 0.1326 

[TRAIN] Epoch[3](1389/1500); Loss: 0.106850; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1966 0.1415 0.1151 0.1170 0.1254 0.1213 0.1085 0.0956 0.0885 0.0868 0.0871 0.0847 0.0840 0.0852 0.0862 0.0859 

[TRAIN] Epoch[3](1390/1500); Loss: 0.136199; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2949 0.2207 0.1698 0.1425 0.1326 0.1389 0.1314 0.1191 0.1087 0.1065 0.1081 0.1038 0.1016 0.1004 0.1008 0.0994 

[TRAIN] Epoch[3](1391/1500); Loss: 0.125353; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.3325 0.2347 0.1664 0.1276 0.1081 0.1087 0.1024 0.0929 0.0875 0.0890 0.0889 0.0885 0.0915 0.0940 0.0958 0.0972 

[TRAIN] Epoch[3](1392/1500); Loss: 0.086827; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1513 0.1008 0.0993 0.1066 0.1026 0.0928 0.0813 0.0747 0.0730 0.0720 0.0712 0.0708 0.0715 0.0724 0.0739 0.0749 

[TRAIN] Epoch[3](1393/1500); Loss: 0.202286; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.4492 0.3894 0.3589 0.3273 0.2911 0.2495 0.2047 0.1651 0.1317 0.1059 0.0950 0.0936 0.0930 0.0934 0.0941 0.0946 

[TRAIN] Epoch[3](1394/1500); Loss: 0.150141; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2622 0.2061 0.1681 0.1496 0.1542 0.1545 0.1468 0.1377 0.1317 0.1295 0.1293 0.1275 0.1267 0.1264 0.1257 0.1264 

[TRAIN] Epoch[3](1395/1500); Loss: 0.148334; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2005 0.1699 0.1525 0.1513 0.1510 0.1463 0.1410 0.1394 0.1395 0.1394 0.1396 0.1395 0.1402 0.1406 0.1410 0.1417 

[TRAIN] Epoch[3](1396/1500); Loss: 0.072161; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1921 0.1342 0.0876 0.0591 0.0655 0.0635 0.0573 0.0523 0.0509 0.0522 0.0526 0.0543 0.0563 0.0577 0.0586 0.0604 

[TRAIN] Epoch[3](1397/1500); Loss: 0.083794; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1295 0.1062 0.0987 0.0912 0.0890 0.0827 0.0763 0.0735 0.0724 0.0729 0.0719 0.0723 0.0738 0.0757 0.0766 0.0780 

[TRAIN] Epoch[3](1398/1500); Loss: 0.187603; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.3637 0.3068 0.2635 0.2317 0.2094 0.1922 0.1691 0.1502 0.1374 0.1337 0.1381 0.1363 0.1405 0.1411 0.1421 0.1457 

[TRAIN] Epoch[3](1399/1500); Loss: 0.165001; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2450 0.2086 0.1819 0.1718 0.1728 0.1682 0.1600 0.1534 0.1500 0.1478 0.1470 0.1459 0.1461 0.1461 0.1475 0.1478 

[TRAIN] Epoch[3](1400/1500); Loss: 0.135924; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1953 0.1753 0.1639 0.1570 0.1491 0.1415 0.1345 0.1277 0.1220 0.1172 0.1144 0.1139 0.1146 0.1152 0.1162 0.1170 

[TRAIN] Epoch[3](1401/1500); Loss: 0.090429; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1966 0.1448 0.1088 0.0883 0.0839 0.0784 0.0730 0.0713 0.0720 0.0718 0.0720 0.0738 0.0763 0.0775 0.0780 0.0803 

[TRAIN] Epoch[3](1402/1500); Loss: 0.129785; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2555 0.1997 0.1742 0.1532 0.1347 0.1213 0.1197 0.1125 0.1065 0.1014 0.0997 0.0998 0.0995 0.0987 0.0993 0.1008 

[TRAIN] Epoch[3](1403/1500); Loss: 0.080223; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1532 0.1300 0.1132 0.0936 0.0774 0.0670 0.0612 0.0618 0.0612 0.0618 0.0639 0.0650 0.0663 0.0676 0.0695 0.0707 

[TRAIN] Epoch[3](1404/1500); Loss: 0.129310; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2973 0.2055 0.1411 0.1321 0.1389 0.1301 0.1145 0.1021 0.1007 0.0992 0.0974 0.0976 0.1010 0.1019 0.1037 0.1056 

[TRAIN] Epoch[3](1405/1500); Loss: 0.110615; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2016 0.1598 0.1279 0.1114 0.1019 0.0970 0.0952 0.0942 0.0939 0.0947 0.0953 0.0969 0.0977 0.0992 0.1006 0.1024 

[TRAIN] Epoch[3](1406/1500); Loss: 0.115272; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1605 0.1292 0.1245 0.1216 0.1195 0.1155 0.1097 0.1068 0.1047 0.1048 0.1053 0.1061 0.1067 0.1082 0.1098 0.1115 

[TRAIN] Epoch[3](1407/1500); Loss: 0.124596; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.3010 0.2498 0.2064 0.1732 0.1450 0.1205 0.1011 0.0844 0.0762 0.0735 0.0752 0.0761 0.0762 0.0757 0.0780 0.0813 

[TRAIN] Epoch[3](1408/1500); Loss: 0.130966; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1737 0.1393 0.1383 0.1404 0.1374 0.1307 0.1256 0.1231 0.1209 0.1206 0.1223 0.1231 0.1239 0.1238 0.1252 0.1270 

[TRAIN] Epoch[3](1409/1500); Loss: 0.132564; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2506 0.1964 0.1607 0.1490 0.1386 0.1288 0.1193 0.1131 0.1099 0.1086 0.1080 0.1071 0.1065 0.1068 0.1085 0.1092 

[TRAIN] Epoch[3](1410/1500); Loss: 0.139169; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2844 0.2263 0.1776 0.1480 0.1399 0.1292 0.1176 0.1106 0.1080 0.1090 0.1093 0.1091 0.1114 0.1134 0.1159 0.1169 

[TRAIN] Epoch[3](1411/1500); Loss: 0.078539; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1413 0.1073 0.0818 0.0723 0.0744 0.0684 0.0685 0.0674 0.0680 0.0689 0.0693 0.0703 0.0721 0.0737 0.0754 0.0776 

[TRAIN] Epoch[3](1412/1500); Loss: 0.074642; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1694 0.0881 0.0679 0.0799 0.0743 0.0638 0.0598 0.0606 0.0583 0.0590 0.0618 0.0681 0.0700 0.0682 0.0701 0.0750 

[TRAIN] Epoch[3](1413/1500); Loss: 0.153749; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1964 0.1769 0.1742 0.1665 0.1572 0.1496 0.1450 0.1441 0.1431 0.1418 0.1419 0.1428 0.1440 0.1444 0.1453 0.1468 

[TRAIN] Epoch[3](1414/1500); Loss: 0.076894; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1734 0.1298 0.0973 0.0759 0.0651 0.0637 0.0622 0.0601 0.0595 0.0596 0.0609 0.0626 0.0635 0.0640 0.0655 0.0671 

[TRAIN] Epoch[3](1415/1500); Loss: 0.140926; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2170 0.1761 0.1500 0.1387 0.1372 0.1343 0.1309 0.1294 0.1295 0.1286 0.1289 0.1297 0.1306 0.1307 0.1311 0.1320 

[TRAIN] Epoch[3](1416/1500); Loss: 0.163910; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2496 0.2205 0.1976 0.1831 0.1740 0.1665 0.1590 0.1528 0.1472 0.1425 0.1389 0.1380 0.1383 0.1382 0.1378 0.1385 

[TRAIN] Epoch[3](1417/1500); Loss: 0.095078; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1717 0.1321 0.1064 0.0977 0.0898 0.0812 0.0773 0.0799 0.0799 0.0799 0.0809 0.0835 0.0871 0.0888 0.0910 0.0939 

[TRAIN] Epoch[3](1418/1500); Loss: 0.126213; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.4419 0.3076 0.1899 0.0886 0.0879 0.0855 0.0781 0.0698 0.0839 0.0757 0.0747 0.0780 0.0851 0.0874 0.0903 0.0951 

[TRAIN] Epoch[3](1419/1500); Loss: 0.147503; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2372 0.2123 0.1951 0.1793 0.1635 0.1480 0.1345 0.1254 0.1207 0.1194 0.1189 0.1197 0.1207 0.1212 0.1218 0.1223 

[TRAIN] Epoch[3](1420/1500); Loss: 0.109209; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.3728 0.2605 0.1707 0.1080 0.0756 0.0781 0.0705 0.0666 0.0669 0.0668 0.0649 0.0638 0.0683 0.0717 0.0711 0.0713 

[TRAIN] Epoch[3](1421/1500); Loss: 0.140728; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1825 0.1569 0.1414 0.1357 0.1348 0.1352 0.1352 0.1341 0.1339 0.1343 0.1354 0.1362 0.1370 0.1383 0.1396 0.1413 

[TRAIN] Epoch[3](1422/1500); Loss: 0.141766; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.3110 0.2343 0.1765 0.1430 0.1296 0.1233 0.1183 0.1120 0.1111 0.1110 0.1116 0.1124 0.1152 0.1184 0.1198 0.1209 

[TRAIN] Epoch[3](1423/1500); Loss: 0.135555; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2485 0.2054 0.1733 0.1526 0.1371 0.1254 0.1161 0.1107 0.1092 0.1087 0.1111 0.1123 0.1135 0.1135 0.1148 0.1166 

[TRAIN] Epoch[3](1424/1500); Loss: 0.062095; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0744 0.0705 0.0778 0.0703 0.0613 0.0548 0.0553 0.0547 0.0543 0.0553 0.0575 0.0587 0.0596 0.0609 0.0633 0.0649 

[TRAIN] Epoch[3](1425/1500); Loss: 0.060673; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1809 0.1207 0.0725 0.0472 0.0462 0.0450 0.0399 0.0412 0.0422 0.0434 0.0439 0.0454 0.0479 0.0498 0.0513 0.0531 

[TRAIN] Epoch[3](1426/1500); Loss: 0.137189; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2589 0.2037 0.1625 0.1388 0.1265 0.1215 0.1190 0.1174 0.1179 0.1170 0.1171 0.1176 0.1183 0.1187 0.1195 0.1206 

[TRAIN] Epoch[3](1427/1500); Loss: 0.103675; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2303 0.1753 0.1323 0.1059 0.0983 0.0945 0.0884 0.0843 0.0805 0.0797 0.0790 0.0795 0.0802 0.0816 0.0831 0.0857 

[TRAIN] Epoch[3](1428/1500); Loss: 0.101805; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1610 0.1341 0.1204 0.1114 0.1027 0.0951 0.0920 0.0933 0.0902 0.0890 0.0889 0.0893 0.0901 0.0901 0.0902 0.0912 

[TRAIN] Epoch[3](1429/1500); Loss: 0.106615; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2553 0.1807 0.1425 0.1053 0.0989 0.0933 0.0828 0.0755 0.0798 0.0774 0.0787 0.0812 0.0847 0.0863 0.0890 0.0944 

[TRAIN] Epoch[3](1430/1500); Loss: 0.122854; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.2823 0.2292 0.1820 0.1477 0.1280 0.1199 0.1117 0.1021 0.0947 0.0892 0.0838 0.0803 0.0805 0.0789 0.0776 0.0778 

[TRAIN] Epoch[3](1431/1500); Loss: 0.098494; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2091 0.1630 0.1291 0.1126 0.0958 0.0799 0.0750 0.0777 0.0740 0.0742 0.0753 0.0779 0.0801 0.0809 0.0840 0.0875 

[TRAIN] Epoch[3](1432/1500); Loss: 0.088900; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1347 0.1063 0.0996 0.0976 0.0913 0.0846 0.0810 0.0801 0.0796 0.0796 0.0796 0.0802 0.0811 0.0813 0.0823 0.0834 

[TRAIN] Epoch[3](1433/1500); Loss: 0.103235; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1639 0.1248 0.1121 0.1127 0.1106 0.1032 0.0951 0.0924 0.0935 0.0909 0.0909 0.0914 0.0920 0.0927 0.0925 0.0932 

[TRAIN] Epoch[3](1434/1500); Loss: 0.172130; Backpropagation: 0.0915 sec; Batch: 0.4233 sec
0.2316 0.1994 0.1862 0.1813 0.1764 0.1701 0.1638 0.1608 0.1597 0.1594 0.1589 0.1599 0.1609 0.1614 0.1614 0.1628 

[TRAIN] Epoch[3](1435/1500); Loss: 0.103629; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1843 0.1498 0.1236 0.1091 0.1029 0.0985 0.0939 0.0900 0.0889 0.0884 0.0876 0.0873 0.0876 0.0884 0.0885 0.0891 

[TRAIN] Epoch[3](1436/1500); Loss: 0.108831; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1198 0.1148 0.1190 0.1138 0.1049 0.1011 0.0997 0.1007 0.1019 0.1036 0.1065 0.1069 0.1088 0.1108 0.1134 0.1156 

[TRAIN] Epoch[3](1437/1500); Loss: 0.114303; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1619 0.1375 0.1268 0.1166 0.1131 0.1090 0.1048 0.1026 0.1024 0.1041 0.1042 0.1056 0.1069 0.1092 0.1107 0.1134 

[TRAIN] Epoch[3](1438/1500); Loss: 0.171094; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.3120 0.2455 0.1927 0.1797 0.1733 0.1647 0.1524 0.1473 0.1462 0.1449 0.1433 0.1442 0.1469 0.1477 0.1486 0.1481 

[TRAIN] Epoch[3](1439/1500); Loss: 0.066479; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1688 0.0815 0.0571 0.0755 0.0715 0.0597 0.0536 0.0519 0.0517 0.0521 0.0527 0.0562 0.0566 0.0562 0.0578 0.0608 

[TRAIN] Epoch[3](1440/1500); Loss: 0.106902; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.1755 0.1255 0.1182 0.1243 0.1181 0.1047 0.0928 0.0949 0.0925 0.0913 0.0914 0.0939 0.0977 0.0956 0.0959 0.0981 

[TRAIN] Epoch[3](1441/1500); Loss: 0.152257; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1772 0.1651 0.1627 0.1614 0.1595 0.1556 0.1505 0.1465 0.1454 0.1471 0.1466 0.1444 0.1421 0.1422 0.1444 0.1454 

[TRAIN] Epoch[3](1442/1500); Loss: 0.155804; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1832 0.1645 0.1604 0.1629 0.1617 0.1578 0.1536 0.1516 0.1499 0.1492 0.1490 0.1491 0.1492 0.1496 0.1503 0.1509 

[TRAIN] Epoch[3](1443/1500); Loss: 0.129735; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1464 0.1393 0.1467 0.1451 0.1389 0.1324 0.1283 0.1274 0.1243 0.1227 0.1217 0.1213 0.1208 0.1205 0.1200 0.1200 

[TRAIN] Epoch[3](1444/1500); Loss: 0.757203; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.3429 0.4243 0.5213 0.5965 0.6562 0.7036 0.7430 0.7787 0.8119 0.8424 0.8733 0.9058 0.9372 0.9648 0.9931 1.0202 

[TRAIN] Epoch[3](1445/1500); Loss: 0.117613; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1912 0.1477 0.1223 0.1279 0.1238 0.1142 0.1063 0.1088 0.1044 0.1030 0.1025 0.1054 0.1079 0.1047 0.1050 0.1067 

[TRAIN] Epoch[3](1446/1500); Loss: 0.096801; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1525 0.1317 0.1189 0.1081 0.0993 0.0947 0.0910 0.0866 0.0829 0.0820 0.0824 0.0831 0.0827 0.0832 0.0847 0.0852 

[TRAIN] Epoch[3](1447/1500); Loss: 0.079006; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1520 0.0906 0.0823 0.0949 0.0874 0.0737 0.0676 0.0646 0.0643 0.0648 0.0665 0.0710 0.0700 0.0700 0.0709 0.0735 

[TRAIN] Epoch[3](1448/1500); Loss: 0.148519; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1880 0.1689 0.1590 0.1492 0.1440 0.1422 0.1410 0.1400 0.1404 0.1411 0.1423 0.1432 0.1432 0.1435 0.1441 0.1463 

[TRAIN] Epoch[3](1449/1500); Loss: 0.136410; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2290 0.1800 0.1615 0.1617 0.1545 0.1421 0.1312 0.1291 0.1200 0.1150 0.1120 0.1123 0.1117 0.1074 0.1068 0.1081 

[TRAIN] Epoch[3](1450/1500); Loss: 0.126876; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1855 0.1628 0.1529 0.1417 0.1361 0.1277 0.1191 0.1135 0.1097 0.1080 0.1081 0.1090 0.1113 0.1131 0.1148 0.1166 

[TRAIN] Epoch[3](1451/1500); Loss: 0.085064; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1205 0.1048 0.1043 0.0948 0.0856 0.0796 0.0776 0.0777 0.0767 0.0757 0.0756 0.0766 0.0767 0.0772 0.0782 0.0795 

[TRAIN] Epoch[3](1452/1500); Loss: 0.128643; Backpropagation: 0.0915 sec; Batch: 0.4233 sec
0.1966 0.1680 0.1502 0.1380 0.1319 0.1257 0.1202 0.1170 0.1148 0.1141 0.1131 0.1131 0.1133 0.1134 0.1141 0.1149 

[TRAIN] Epoch[3](1453/1500); Loss: 0.131794; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2228 0.1830 0.1539 0.1366 0.1256 0.1233 0.1191 0.1174 0.1157 0.1147 0.1147 0.1145 0.1159 0.1164 0.1166 0.1185 

[TRAIN] Epoch[3](1454/1500); Loss: 0.161566; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2720 0.2465 0.2204 0.1970 0.1776 0.1641 0.1529 0.1427 0.1334 0.1282 0.1258 0.1252 0.1251 0.1244 0.1245 0.1250 

[TRAIN] Epoch[3](1455/1500); Loss: 0.139492; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2129 0.1689 0.1484 0.1476 0.1484 0.1422 0.1341 0.1292 0.1268 0.1253 0.1241 0.1238 0.1246 0.1245 0.1250 0.1262 

[TRAIN] Epoch[3](1456/1500); Loss: 0.113089; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2183 0.1706 0.1359 0.1178 0.1111 0.1046 0.0999 0.0967 0.0956 0.0944 0.0937 0.0934 0.0943 0.0943 0.0941 0.0946 

[TRAIN] Epoch[3](1457/1500); Loss: 0.124438; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2807 0.2046 0.1584 0.1300 0.1162 0.1114 0.1040 0.1018 0.1011 0.0977 0.0952 0.0957 0.0990 0.0985 0.0979 0.0990 

[TRAIN] Epoch[3](1458/1500); Loss: 0.142968; Backpropagation: 0.0915 sec; Batch: 0.4231 sec
0.2479 0.2134 0.1890 0.1720 0.1582 0.1464 0.1360 0.1267 0.1183 0.1125 0.1105 0.1111 0.1103 0.1111 0.1118 0.1122 

[TRAIN] Epoch[3](1459/1500); Loss: 0.099012; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2566 0.2026 0.1557 0.1188 0.0877 0.0711 0.0717 0.0671 0.0655 0.0653 0.0663 0.0694 0.0685 0.0695 0.0731 0.0755 

[TRAIN] Epoch[3](1460/1500); Loss: 0.122969; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2720 0.1985 0.1508 0.1360 0.1300 0.1156 0.1027 0.0991 0.0955 0.0931 0.0925 0.0942 0.0967 0.0968 0.0961 0.0979 

[TRAIN] Epoch[3](1461/1500); Loss: 0.167091; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2913 0.2353 0.1910 0.1643 0.1648 0.1611 0.1554 0.1491 0.1464 0.1452 0.1445 0.1437 0.1438 0.1458 0.1459 0.1459 

[TRAIN] Epoch[3](1462/1500); Loss: 0.116305; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.2029 0.1596 0.1350 0.1252 0.1181 0.1101 0.1035 0.1010 0.1005 0.0995 0.1000 0.0999 0.1010 0.1011 0.1016 0.1018 

[TRAIN] Epoch[3](1463/1500); Loss: 0.119257; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2601 0.1730 0.1201 0.1034 0.1211 0.1174 0.1086 0.1007 0.0990 0.0985 0.0997 0.1003 0.1009 0.1008 0.1017 0.1029 

[TRAIN] Epoch[3](1464/1500); Loss: 0.119748; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2857 0.2098 0.1534 0.1189 0.1121 0.1061 0.0994 0.0913 0.0903 0.0902 0.0893 0.0898 0.0921 0.0957 0.0959 0.0959 

[TRAIN] Epoch[3](1465/1500); Loss: 0.147865; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2236 0.1885 0.1685 0.1578 0.1497 0.1442 0.1386 0.1361 0.1352 0.1340 0.1323 0.1314 0.1314 0.1319 0.1314 0.1312 

[TRAIN] Epoch[3](1466/1500); Loss: 0.113545; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1639 0.1415 0.1351 0.1293 0.1218 0.1143 0.1082 0.1040 0.1019 0.1010 0.0998 0.0991 0.0991 0.0992 0.0994 0.0993 

[TRAIN] Epoch[3](1467/1500); Loss: 0.139113; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2198 0.1855 0.1626 0.1489 0.1386 0.1313 0.1274 0.1266 0.1252 0.1234 0.1219 0.1222 0.1231 0.1234 0.1229 0.1231 

[TRAIN] Epoch[3](1468/1500); Loss: 0.076116; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1019 0.0850 0.0991 0.1008 0.0918 0.0775 0.0668 0.0642 0.0617 0.0629 0.0637 0.0659 0.0672 0.0679 0.0699 0.0717 

[TRAIN] Epoch[3](1469/1500); Loss: 0.067890; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1209 0.0969 0.0859 0.0730 0.0629 0.0605 0.0581 0.0563 0.0561 0.0570 0.0574 0.0586 0.0593 0.0602 0.0612 0.0621 

[TRAIN] Epoch[3](1470/1500); Loss: 0.091490; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2011 0.1355 0.1134 0.1063 0.1048 0.0921 0.0784 0.0728 0.0678 0.0680 0.0676 0.0690 0.0710 0.0711 0.0714 0.0737 

[TRAIN] Epoch[3](1471/1500); Loss: 0.061304; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0654 0.0633 0.0741 0.0688 0.0608 0.0588 0.0592 0.0564 0.0551 0.0569 0.0585 0.0582 0.0591 0.0610 0.0628 0.0625 

[TRAIN] Epoch[3](1472/1500); Loss: 0.091950; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2208 0.1555 0.1154 0.0940 0.0887 0.0824 0.0754 0.0727 0.0706 0.0691 0.0691 0.0698 0.0703 0.0709 0.0725 0.0740 

[TRAIN] Epoch[3](1473/1500); Loss: 0.162440; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2527 0.2164 0.1893 0.1692 0.1544 0.1492 0.1481 0.1454 0.1455 0.1453 0.1452 0.1464 0.1466 0.1475 0.1483 0.1496 

[TRAIN] Epoch[3](1474/1500); Loss: 0.119036; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1652 0.1377 0.1384 0.1377 0.1302 0.1177 0.1083 0.1056 0.1055 0.1061 0.1064 0.1070 0.1086 0.1090 0.1100 0.1111 

[TRAIN] Epoch[3](1475/1500); Loss: 0.073046; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1358 0.1004 0.0810 0.0734 0.0735 0.0695 0.0661 0.0616 0.0597 0.0615 0.0622 0.0629 0.0637 0.0640 0.0663 0.0672 

[TRAIN] Epoch[3](1476/1500); Loss: 0.147757; Backpropagation: 0.0915 sec; Batch: 0.4233 sec
0.3419 0.2827 0.2490 0.2235 0.1905 0.1557 0.1259 0.1010 0.0876 0.0886 0.0869 0.0876 0.0863 0.0850 0.0851 0.0868 

[TRAIN] Epoch[3](1477/1500); Loss: 0.069827; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1073 0.0823 0.0898 0.0851 0.0741 0.0649 0.0635 0.0604 0.0596 0.0594 0.0610 0.0607 0.0610 0.0617 0.0632 0.0634 

[TRAIN] Epoch[3](1478/1500); Loss: 0.101884; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1552 0.1196 0.1074 0.1080 0.1066 0.1010 0.0951 0.0933 0.0930 0.0929 0.0925 0.0923 0.0930 0.0933 0.0930 0.0939 

[TRAIN] Epoch[3](1479/1500); Loss: 0.137417; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2250 0.1982 0.1801 0.1641 0.1504 0.1383 0.1288 0.1214 0.1163 0.1127 0.1105 0.1108 0.1105 0.1103 0.1105 0.1107 

[TRAIN] Epoch[3](1480/1500); Loss: 0.076234; Backpropagation: 0.0915 sec; Batch: 0.4231 sec
0.1329 0.1068 0.1003 0.0936 0.0812 0.0702 0.0685 0.0655 0.0618 0.0614 0.0616 0.0624 0.0624 0.0626 0.0637 0.0650 

[TRAIN] Epoch[3](1481/1500); Loss: 0.086410; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1934 0.1338 0.1045 0.0958 0.0908 0.0809 0.0723 0.0681 0.0655 0.0657 0.0650 0.0658 0.0670 0.0692 0.0712 0.0740 

[TRAIN] Epoch[3](1482/1500); Loss: 0.140619; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2141 0.1751 0.1537 0.1478 0.1423 0.1342 0.1294 0.1300 0.1301 0.1273 0.1264 0.1270 0.1283 0.1278 0.1277 0.1287 

[TRAIN] Epoch[3](1483/1500); Loss: 0.088561; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1696 0.1272 0.1075 0.0954 0.0901 0.0809 0.0728 0.0729 0.0736 0.0719 0.0727 0.0736 0.0769 0.0762 0.0766 0.0791 

[TRAIN] Epoch[3](1484/1500); Loss: 0.135529; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2849 0.2050 0.1508 0.1277 0.1334 0.1271 0.1175 0.1125 0.1150 0.1119 0.1126 0.1119 0.1141 0.1148 0.1143 0.1150 

[TRAIN] Epoch[3](1485/1500); Loss: 0.081934; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2152 0.1418 0.0822 0.0683 0.0713 0.0661 0.0641 0.0669 0.0639 0.0642 0.0640 0.0670 0.0686 0.0679 0.0689 0.0706 

[TRAIN] Epoch[3](1486/1500); Loss: 0.124118; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1980 0.1637 0.1461 0.1364 0.1270 0.1195 0.1150 0.1131 0.1106 0.1085 0.1076 0.1067 0.1070 0.1081 0.1087 0.1099 

[TRAIN] Epoch[3](1487/1500); Loss: 0.110385; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1844 0.1474 0.1296 0.1219 0.1148 0.1063 0.1001 0.0965 0.0949 0.0948 0.0942 0.0947 0.0950 0.0961 0.0970 0.0984 

[TRAIN] Epoch[3](1488/1500); Loss: 0.128259; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1875 0.1599 0.1437 0.1339 0.1275 0.1224 0.1194 0.1179 0.1176 0.1169 0.1169 0.1170 0.1175 0.1177 0.1178 0.1188 

[TRAIN] Epoch[3](1489/1500); Loss: 0.127572; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2051 0.1491 0.1375 0.1465 0.1436 0.1333 0.1217 0.1180 0.1150 0.1106 0.1096 0.1093 0.1103 0.1104 0.1102 0.1109 

[TRAIN] Epoch[3](1490/1500); Loss: 0.149228; Backpropagation: 0.0915 sec; Batch: 0.4236 sec
0.2071 0.1792 0.1637 0.1520 0.1436 0.1405 0.1392 0.1381 0.1381 0.1381 0.1387 0.1392 0.1406 0.1414 0.1431 0.1451 

[TRAIN] Epoch[3](1491/1500); Loss: 0.136977; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1898 0.1725 0.1654 0.1580 0.1496 0.1408 0.1329 0.1280 0.1242 0.1210 0.1188 0.1184 0.1184 0.1179 0.1178 0.1180 

[TRAIN] Epoch[3](1492/1500); Loss: 0.081877; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1413 0.1090 0.0904 0.0795 0.0811 0.0767 0.0727 0.0715 0.0705 0.0707 0.0714 0.0724 0.0741 0.0748 0.0759 0.0780 

[TRAIN] Epoch[3](1493/1500); Loss: 0.163659; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1845 0.1738 0.1766 0.1739 0.1680 0.1636 0.1594 0.1589 0.1586 0.1567 0.1565 0.1569 0.1580 0.1574 0.1574 0.1582 

[TRAIN] Epoch[3](1494/1500); Loss: 0.062349; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0699 0.0628 0.0737 0.0708 0.0637 0.0599 0.0623 0.0605 0.0567 0.0568 0.0582 0.0589 0.0594 0.0600 0.0614 0.0626 

[TRAIN] Epoch[3](1495/1500); Loss: 0.149165; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2559 0.2101 0.1795 0.1610 0.1469 0.1373 0.1332 0.1329 0.1307 0.1295 0.1287 0.1279 0.1274 0.1280 0.1285 0.1291 

[TRAIN] Epoch[3](1496/1500); Loss: 0.122467; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.3470 0.2880 0.2357 0.1880 0.1440 0.1039 0.0751 0.0679 0.0706 0.0637 0.0629 0.0618 0.0624 0.0628 0.0626 0.0631 

[TRAIN] Epoch[3](1497/1500); Loss: 0.091014; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1638 0.1295 0.1129 0.0978 0.0885 0.0825 0.0791 0.0779 0.0772 0.0766 0.0766 0.0780 0.0778 0.0779 0.0791 0.0811 

[TRAIN] Epoch[3](1498/1500); Loss: 0.113158; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1580 0.1262 0.1171 0.1158 0.1122 0.1073 0.1059 0.1089 0.1076 0.1058 0.1056 0.1060 0.1074 0.1085 0.1089 0.1092 

[TRAIN] Epoch[3](1499/1500); Loss: 0.107786; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.4101 0.2906 0.1917 0.1106 0.0624 0.0653 0.0604 0.0608 0.0590 0.0588 0.0563 0.0568 0.0598 0.0598 0.0587 0.0633 

[TRAIN] Epoch[3](1500/1500); Loss: 0.144205; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1963 0.1797 0.1719 0.1609 0.1498 0.1385 0.1320 0.1307 0.1291 0.1289 0.1290 0.1303 0.1318 0.1320 0.1329 0.1336 

[TRAIN] Epoch[4](1/1500); Loss: 0.118753; Backpropagation: 0.0976 sec; Batch: 0.4780 sec
0.3424 0.2658 0.2018 0.1429 0.1035 0.0935 0.0843 0.0778 0.0723 0.0720 0.0729 0.0720 0.0719 0.0743 0.0765 0.0764 

[TRAIN] Epoch[4](2/1500); Loss: 0.143754; Backpropagation: 0.0935 sec; Batch: 0.4284 sec
0.2200 0.1833 0.1612 0.1470 0.1375 0.1338 0.1325 0.1322 0.1319 0.1312 0.1307 0.1309 0.1313 0.1317 0.1320 0.1330 

[TRAIN] Epoch[4](3/1500); Loss: 0.096975; Backpropagation: 0.0934 sec; Batch: 0.4252 sec
0.2060 0.1472 0.1095 0.0906 0.0828 0.0819 0.0822 0.0834 0.0834 0.0823 0.0819 0.0827 0.0834 0.0841 0.0849 0.0853 

[TRAIN] Epoch[4](4/1500); Loss: 0.064678; Backpropagation: 0.0934 sec; Batch: 0.4285 sec
0.1452 0.1084 0.0867 0.0716 0.0599 0.0540 0.0520 0.0495 0.0485 0.0489 0.0493 0.0497 0.0508 0.0518 0.0535 0.0551 

[TRAIN] Epoch[4](5/1500); Loss: 0.122301; Backpropagation: 0.0937 sec; Batch: 0.4256 sec
0.1886 0.1469 0.1268 0.1173 0.1188 0.1177 0.1167 0.1156 0.1121 0.1110 0.1121 0.1132 0.1141 0.1146 0.1152 0.1162 

[TRAIN] Epoch[4](6/1500); Loss: 0.117738; Backpropagation: 0.0937 sec; Batch: 0.4258 sec
0.2708 0.1994 0.1518 0.1231 0.1101 0.1050 0.0960 0.0907 0.0909 0.0898 0.0891 0.0899 0.0922 0.0938 0.0950 0.0962 

[TRAIN] Epoch[4](7/1500); Loss: 0.120007; Backpropagation: 0.0933 sec; Batch: 0.4251 sec
0.1835 0.1476 0.1381 0.1313 0.1228 0.1163 0.1124 0.1102 0.1073 0.1057 0.1056 0.1062 0.1070 0.1077 0.1087 0.1096 

[TRAIN] Epoch[4](8/1500); Loss: 0.112262; Backpropagation: 0.0934 sec; Batch: 0.4249 sec
0.2073 0.1582 0.1329 0.1188 0.1094 0.1049 0.1029 0.0999 0.0968 0.0954 0.0949 0.0945 0.0948 0.0947 0.0952 0.0958 

[TRAIN] Epoch[4](9/1500); Loss: 0.116415; Backpropagation: 0.0937 sec; Batch: 0.4258 sec
0.1654 0.1410 0.1284 0.1216 0.1177 0.1129 0.1094 0.1074 0.1070 0.1068 0.1069 0.1066 0.1069 0.1076 0.1083 0.1090 

[TRAIN] Epoch[4](10/1500); Loss: 0.102535; Backpropagation: 0.0933 sec; Batch: 0.4270 sec
0.1791 0.1401 0.1179 0.1075 0.0972 0.0889 0.0868 0.0846 0.0855 0.0869 0.0885 0.0906 0.0924 0.0952 0.0982 0.1011 

[TRAIN] Epoch[4](11/1500); Loss: 0.115577; Backpropagation: 0.0934 sec; Batch: 0.4262 sec
0.2521 0.1978 0.1534 0.1267 0.1109 0.1010 0.0954 0.0942 0.0920 0.0904 0.0890 0.0884 0.0892 0.0893 0.0896 0.0897 

[TRAIN] Epoch[4](12/1500); Loss: 0.104894; Backpropagation: 0.0935 sec; Batch: 0.4265 sec
0.1883 0.1523 0.1255 0.1108 0.1030 0.0965 0.0934 0.0914 0.0896 0.0885 0.0881 0.0885 0.0893 0.0898 0.0909 0.0924 

[TRAIN] Epoch[4](13/1500); Loss: 0.082983; Backpropagation: 0.0937 sec; Batch: 0.4263 sec
0.1600 0.1218 0.0976 0.0807 0.0722 0.0729 0.0758 0.0722 0.0698 0.0699 0.0701 0.0709 0.0716 0.0726 0.0740 0.0756 

[TRAIN] Epoch[4](14/1500); Loss: 0.102271; Backpropagation: 0.0936 sec; Batch: 0.4272 sec
0.1124 0.1010 0.1085 0.1093 0.1051 0.0997 0.0992 0.1018 0.1007 0.0991 0.0987 0.0988 0.0993 0.1002 0.1011 0.1015 

[TRAIN] Epoch[4](15/1500); Loss: 0.152177; Backpropagation: 0.0938 sec; Batch: 0.4256 sec
0.1994 0.1738 0.1630 0.1552 0.1519 0.1496 0.1484 0.1465 0.1445 0.1422 0.1417 0.1423 0.1436 0.1444 0.1441 0.1445 

[TRAIN] Epoch[4](16/1500); Loss: 0.065094; Backpropagation: 0.0934 sec; Batch: 0.4260 sec
0.1895 0.0983 0.0504 0.0699 0.0682 0.0583 0.0512 0.0532 0.0529 0.0476 0.0470 0.0473 0.0506 0.0518 0.0519 0.0534 

[TRAIN] Epoch[4](17/1500); Loss: 0.069344; Backpropagation: 0.1013 sec; Batch: 0.4345 sec
0.1680 0.0915 0.0706 0.0819 0.0754 0.0621 0.0562 0.0592 0.0554 0.0518 0.0509 0.0533 0.0565 0.0572 0.0584 0.0612 

[TRAIN] Epoch[4](18/1500); Loss: 0.093795; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1374 0.1075 0.0949 0.0948 0.0929 0.0892 0.0870 0.0892 0.0876 0.0850 0.0844 0.0858 0.0884 0.0903 0.0925 0.0938 

[TRAIN] Epoch[4](19/1500); Loss: 0.098745; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1546 0.1252 0.1102 0.1068 0.1043 0.0993 0.0933 0.0901 0.0909 0.0891 0.0867 0.0854 0.0854 0.0858 0.0859 0.0869 

[TRAIN] Epoch[4](20/1500); Loss: 0.083095; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1499 0.1136 0.1063 0.1017 0.0932 0.0799 0.0715 0.0696 0.0709 0.0697 0.0673 0.0663 0.0664 0.0668 0.0678 0.0686 

[TRAIN] Epoch[4](21/1500); Loss: 0.140951; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2401 0.2056 0.1830 0.1640 0.1447 0.1293 0.1231 0.1227 0.1195 0.1181 0.1164 0.1158 0.1173 0.1181 0.1184 0.1190 

[TRAIN] Epoch[4](22/1500); Loss: 0.126955; Backpropagation: 0.0918 sec; Batch: 0.4250 sec
0.2154 0.1562 0.1280 0.1313 0.1334 0.1280 0.1191 0.1142 0.1141 0.1139 0.1126 0.1126 0.1120 0.1129 0.1135 0.1140 

[TRAIN] Epoch[4](23/1500); Loss: 0.065740; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0543 0.0750 0.0911 0.0856 0.0759 0.0644 0.0591 0.0589 0.0579 0.0588 0.0585 0.0603 0.0614 0.0626 0.0636 0.0644 

[TRAIN] Epoch[4](24/1500); Loss: 0.129110; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.2492 0.1696 0.1280 0.1295 0.1455 0.1397 0.1265 0.1149 0.1108 0.1102 0.1085 0.1070 0.1058 0.1062 0.1072 0.1069 

[TRAIN] Epoch[4](25/1500); Loss: 0.095936; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.2152 0.1394 0.1072 0.1085 0.1218 0.1120 0.0943 0.0798 0.0716 0.0682 0.0663 0.0688 0.0690 0.0694 0.0710 0.0726 

[TRAIN] Epoch[4](26/1500); Loss: 0.118143; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1414 0.1271 0.1370 0.1376 0.1296 0.1196 0.1145 0.1132 0.1100 0.1076 0.1073 0.1081 0.1086 0.1091 0.1093 0.1100 

[TRAIN] Epoch[4](27/1500); Loss: 0.093274; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1825 0.1264 0.0986 0.1018 0.1047 0.0925 0.0810 0.0786 0.0791 0.0781 0.0768 0.0770 0.0780 0.0791 0.0786 0.0795 

[TRAIN] Epoch[4](28/1500); Loss: 0.073353; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1561 0.1118 0.0900 0.0794 0.0735 0.0668 0.0621 0.0592 0.0587 0.0579 0.0576 0.0586 0.0592 0.0596 0.0609 0.0624 

[TRAIN] Epoch[4](29/1500); Loss: 0.105631; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.2132 0.1591 0.1271 0.1114 0.1078 0.1072 0.0982 0.0887 0.0864 0.0861 0.0834 0.0835 0.0829 0.0845 0.0855 0.0850 

[TRAIN] Epoch[4](30/1500); Loss: 0.139586; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2022 0.1721 0.1608 0.1580 0.1526 0.1409 0.1294 0.1252 0.1250 0.1239 0.1220 0.1221 0.1230 0.1236 0.1254 0.1272 

[TRAIN] Epoch[4](31/1500); Loss: 0.101667; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1973 0.1443 0.1210 0.1204 0.1211 0.1073 0.0902 0.0855 0.0827 0.0797 0.0778 0.0781 0.0816 0.0799 0.0795 0.0803 

[TRAIN] Epoch[4](32/1500); Loss: 0.158919; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2362 0.2012 0.1868 0.1769 0.1734 0.1691 0.1595 0.1499 0.1446 0.1396 0.1358 0.1345 0.1345 0.1340 0.1334 0.1332 

[TRAIN] Epoch[4](33/1500); Loss: 0.151923; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2722 0.2157 0.1839 0.1666 0.1605 0.1656 0.1550 0.1413 0.1309 0.1250 0.1241 0.1208 0.1185 0.1172 0.1165 0.1171 

[TRAIN] Epoch[4](34/1500); Loss: 0.157350; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1936 0.1758 0.1805 0.1757 0.1688 0.1631 0.1554 0.1515 0.1492 0.1440 0.1433 0.1438 0.1447 0.1436 0.1415 0.1431 

[TRAIN] Epoch[4](35/1500); Loss: 0.158954; Backpropagation: 0.0925 sec; Batch: 0.4249 sec
0.2575 0.2184 0.2087 0.2061 0.1899 0.1704 0.1509 0.1378 0.1307 0.1257 0.1241 0.1236 0.1247 0.1253 0.1239 0.1255 

[TRAIN] Epoch[4](36/1500); Loss: 0.104327; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1799 0.1363 0.1170 0.1164 0.1082 0.0990 0.0923 0.0905 0.0917 0.0915 0.0901 0.0907 0.0914 0.0912 0.0913 0.0919 

[TRAIN] Epoch[4](37/1500); Loss: 0.120390; Backpropagation: 0.0924 sec; Batch: 0.4255 sec
0.1890 0.1589 0.1511 0.1456 0.1371 0.1240 0.1120 0.1078 0.1033 0.1005 0.0987 0.0985 0.0985 0.0989 0.1002 0.1020 

[TRAIN] Epoch[4](38/1500); Loss: 0.141412; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2880 0.2113 0.1595 0.1397 0.1664 0.1634 0.1463 0.1249 0.1110 0.1121 0.1072 0.1057 0.1050 0.1065 0.1079 0.1077 

[TRAIN] Epoch[4](39/1500); Loss: 0.109361; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.4236 0.2908 0.1763 0.0711 0.0706 0.1006 0.0905 0.0689 0.0562 0.0592 0.0544 0.0546 0.0553 0.0586 0.0592 0.0598 

[TRAIN] Epoch[4](40/1500); Loss: 0.076258; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1378 0.1044 0.1007 0.1009 0.0946 0.0811 0.0698 0.0643 0.0604 0.0588 0.0577 0.0581 0.0579 0.0574 0.0576 0.0586 

[TRAIN] Epoch[4](41/1500); Loss: 0.158413; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.2437 0.1955 0.1733 0.1680 0.1821 0.1832 0.1705 0.1526 0.1437 0.1391 0.1351 0.1320 0.1296 0.1288 0.1289 0.1285 

[TRAIN] Epoch[4](42/1500); Loss: 0.102204; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1807 0.1470 0.1304 0.1149 0.1061 0.0972 0.0888 0.0842 0.0834 0.0853 0.0851 0.0843 0.0856 0.0879 0.0874 0.0870 

[TRAIN] Epoch[4](43/1500); Loss: 0.058832; Backpropagation: 0.0919 sec; Batch: 0.4249 sec
0.1491 0.1001 0.0642 0.0469 0.0555 0.0447 0.0415 0.0425 0.0428 0.0442 0.0458 0.0478 0.0499 0.0533 0.0551 0.0577 

[TRAIN] Epoch[4](44/1500); Loss: 0.080774; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1292 0.1042 0.1013 0.0981 0.0896 0.0805 0.0744 0.0694 0.0701 0.0685 0.0673 0.0674 0.0677 0.0681 0.0681 0.0686 

[TRAIN] Epoch[4](45/1500); Loss: 0.085552; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1649 0.1261 0.1189 0.1129 0.0993 0.0913 0.0808 0.0707 0.0667 0.0632 0.0634 0.0621 0.0614 0.0612 0.0630 0.0629 

[TRAIN] Epoch[4](46/1500); Loss: 0.108701; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1588 0.1243 0.1255 0.1386 0.1418 0.1294 0.1110 0.0991 0.0979 0.0923 0.0888 0.0874 0.0870 0.0870 0.0851 0.0854 

[TRAIN] Epoch[4](47/1500); Loss: 0.143538; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.2192 0.1813 0.1628 0.1623 0.1669 0.1564 0.1429 0.1332 0.1285 0.1259 0.1223 0.1202 0.1194 0.1187 0.1185 0.1180 

[TRAIN] Epoch[4](48/1500); Loss: 0.144459; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2112 0.1967 0.1890 0.1724 0.1537 0.1406 0.1298 0.1236 0.1227 0.1226 0.1226 0.1231 0.1245 0.1254 0.1264 0.1271 

[TRAIN] Epoch[4](49/1500); Loss: 0.211222; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2810 0.2401 0.2304 0.2357 0.2333 0.2201 0.2080 0.1995 0.1955 0.1926 0.1901 0.1902 0.1910 0.1907 0.1903 0.1909 

[TRAIN] Epoch[4](50/1500); Loss: 0.087057; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1359 0.0644 0.1028 0.1467 0.1403 0.1194 0.0877 0.0647 0.0646 0.0631 0.0640 0.0644 0.0653 0.0688 0.0696 0.0713 

[TRAIN] Epoch[4](51/1500); Loss: 0.147506; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2394 0.1957 0.1919 0.1953 0.1808 0.1765 0.1561 0.1352 0.1226 0.1133 0.1116 0.1087 0.1079 0.1080 0.1082 0.1087 

[TRAIN] Epoch[4](52/1500); Loss: 0.113928; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1931 0.1429 0.1277 0.1467 0.1497 0.1351 0.1148 0.0987 0.0925 0.0909 0.0884 0.0868 0.0878 0.0893 0.0893 0.0891 

[TRAIN] Epoch[4](53/1500); Loss: 0.148561; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2236 0.1837 0.1672 0.1605 0.1642 0.1590 0.1474 0.1370 0.1338 0.1321 0.1287 0.1283 0.1272 0.1277 0.1283 0.1282 

[TRAIN] Epoch[4](54/1500); Loss: 0.118467; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1832 0.1393 0.1268 0.1345 0.1336 0.1242 0.1150 0.1087 0.1063 0.1050 0.1029 0.1023 0.1028 0.1037 0.1041 0.1031 

[TRAIN] Epoch[4](55/1500); Loss: 0.128723; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1446 0.1416 0.1520 0.1483 0.1407 0.1335 0.1278 0.1226 0.1194 0.1187 0.1184 0.1185 0.1180 0.1181 0.1188 0.1187 

[TRAIN] Epoch[4](56/1500); Loss: 0.100890; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.3251 0.1879 0.0880 0.0764 0.1358 0.1361 0.1161 0.0843 0.0620 0.0582 0.0556 0.0557 0.0549 0.0569 0.0599 0.0612 

[TRAIN] Epoch[4](57/1500); Loss: 0.076599; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0942 0.0773 0.0797 0.0850 0.0806 0.0772 0.0748 0.0735 0.0722 0.0719 0.0718 0.0721 0.0729 0.0733 0.0740 0.0752 

[TRAIN] Epoch[4](58/1500); Loss: 0.104698; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1753 0.1364 0.1238 0.1184 0.1138 0.1047 0.0944 0.0868 0.0859 0.0874 0.0886 0.0894 0.0900 0.0918 0.0934 0.0951 

[TRAIN] Epoch[4](59/1500); Loss: 0.133345; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2821 0.2157 0.1751 0.1641 0.1470 0.1323 0.1146 0.1038 0.1006 0.0988 0.0986 0.0969 0.0983 0.1003 0.1022 0.1030 

[TRAIN] Epoch[4](60/1500); Loss: 0.113613; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.4094 0.2538 0.1239 0.0648 0.1172 0.1096 0.0899 0.0706 0.0702 0.0661 0.0657 0.0651 0.0723 0.0781 0.0815 0.0795 

[TRAIN] Epoch[4](61/1500); Loss: 0.087026; Backpropagation: 0.0920 sec; Batch: 0.4256 sec
0.1524 0.1226 0.1244 0.1199 0.1045 0.0866 0.0759 0.0739 0.0693 0.0669 0.0651 0.0652 0.0656 0.0659 0.0663 0.0679 

[TRAIN] Epoch[4](62/1500); Loss: 0.141596; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2054 0.1900 0.1793 0.1636 0.1503 0.1385 0.1311 0.1274 0.1243 0.1226 0.1216 0.1216 0.1217 0.1216 0.1226 0.1238 

[TRAIN] Epoch[4](63/1500); Loss: 0.124072; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2325 0.1900 0.1589 0.1359 0.1242 0.1149 0.1071 0.1029 0.1025 0.1020 0.1011 0.1019 0.1021 0.1026 0.1028 0.1038 

[TRAIN] Epoch[4](64/1500); Loss: 0.087558; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1454 0.1248 0.1185 0.1022 0.0976 0.0952 0.0857 0.0760 0.0705 0.0690 0.0677 0.0681 0.0683 0.0694 0.0704 0.0721 

[TRAIN] Epoch[4](65/1500); Loss: 0.117493; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.3723 0.2816 0.2079 0.1290 0.0869 0.0970 0.0876 0.0753 0.0730 0.0683 0.0661 0.0649 0.0660 0.0670 0.0675 0.0693 

[TRAIN] Epoch[4](66/1500); Loss: 0.129809; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2702 0.1954 0.1458 0.1221 0.1418 0.1468 0.1324 0.1129 0.1043 0.1028 0.1010 0.0993 0.0991 0.1007 0.1015 0.1008 

[TRAIN] Epoch[4](67/1500); Loss: 0.091182; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1893 0.1594 0.1452 0.1230 0.1001 0.0794 0.0703 0.0724 0.0658 0.0650 0.0640 0.0650 0.0644 0.0649 0.0652 0.0655 

[TRAIN] Epoch[4](68/1500); Loss: 0.147977; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.2487 0.1965 0.1737 0.1777 0.1771 0.1627 0.1445 0.1312 0.1268 0.1209 0.1183 0.1174 0.1175 0.1189 0.1180 0.1177 

[TRAIN] Epoch[4](69/1500); Loss: 0.095302; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1403 0.1055 0.1072 0.1093 0.1080 0.0996 0.0897 0.0861 0.0863 0.0845 0.0843 0.0840 0.0850 0.0850 0.0850 0.0851 

[TRAIN] Epoch[4](70/1500); Loss: 0.128878; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1708 0.1598 0.1697 0.1642 0.1568 0.1470 0.1315 0.1198 0.1132 0.1069 0.1046 0.1036 0.1034 0.1029 0.1032 0.1048 

[TRAIN] Epoch[4](71/1500); Loss: 0.092235; Backpropagation: 0.0921 sec; Batch: 0.4250 sec
0.2568 0.1995 0.1556 0.1161 0.0825 0.0660 0.0673 0.0584 0.0582 0.0572 0.0574 0.0578 0.0585 0.0599 0.0620 0.0625 

[TRAIN] Epoch[4](72/1500); Loss: 0.173593; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2319 0.2032 0.1951 0.1886 0.1828 0.1795 0.1706 0.1639 0.1596 0.1581 0.1571 0.1563 0.1566 0.1576 0.1581 0.1584 

[TRAIN] Epoch[4](73/1500); Loss: 0.109840; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1885 0.1518 0.1381 0.1291 0.1177 0.1059 0.0966 0.0924 0.0896 0.0890 0.0885 0.0894 0.0905 0.0937 0.0961 0.1004 

[TRAIN] Epoch[4](74/1500); Loss: 0.130126; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1952 0.1674 0.1551 0.1460 0.1344 0.1233 0.1184 0.1188 0.1146 0.1150 0.1146 0.1153 0.1155 0.1158 0.1163 0.1163 

[TRAIN] Epoch[4](75/1500); Loss: 0.108458; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1944 0.1521 0.1395 0.1298 0.1350 0.1204 0.1041 0.0938 0.0852 0.0843 0.0812 0.0821 0.0822 0.0824 0.0836 0.0853 

[TRAIN] Epoch[4](76/1500); Loss: 0.086541; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1526 0.1203 0.1096 0.1085 0.1022 0.0890 0.0773 0.0733 0.0701 0.0683 0.0681 0.0692 0.0688 0.0687 0.0690 0.0698 

[TRAIN] Epoch[4](77/1500); Loss: 0.108503; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1361 0.1223 0.1290 0.1280 0.1227 0.1139 0.1053 0.0998 0.0980 0.0966 0.0962 0.0960 0.0968 0.0973 0.0985 0.0996 

[TRAIN] Epoch[4](78/1500); Loss: 0.079844; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1090 0.0987 0.1037 0.0996 0.0888 0.0784 0.0766 0.0745 0.0708 0.0697 0.0684 0.0680 0.0679 0.0680 0.0672 0.0681 

[TRAIN] Epoch[4](79/1500); Loss: 0.112244; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.2371 0.1657 0.1281 0.1262 0.1199 0.1132 0.1025 0.0916 0.0910 0.0872 0.0871 0.0875 0.0885 0.0895 0.0897 0.0910 

[TRAIN] Epoch[4](80/1500); Loss: 0.051688; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0898 0.0635 0.0570 0.0599 0.0554 0.0463 0.0443 0.0442 0.0445 0.0445 0.0449 0.0451 0.0461 0.0466 0.0469 0.0481 

[TRAIN] Epoch[4](81/1500); Loss: 0.121031; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2194 0.1429 0.1298 0.1620 0.1632 0.1451 0.1195 0.1011 0.0962 0.0932 0.0925 0.0917 0.0925 0.0940 0.0968 0.0968 

[TRAIN] Epoch[4](82/1500); Loss: 0.088144; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1003 0.0932 0.1001 0.0998 0.0929 0.0861 0.0831 0.0825 0.0827 0.0832 0.0832 0.0826 0.0835 0.0849 0.0859 0.0861 

[TRAIN] Epoch[4](83/1500); Loss: 0.098326; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1467 0.1174 0.1101 0.1117 0.1098 0.1014 0.0934 0.0911 0.0897 0.0864 0.0858 0.0853 0.0854 0.0860 0.0863 0.0867 

[TRAIN] Epoch[4](84/1500); Loss: 0.148840; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.2329 0.1804 0.1640 0.1603 0.1567 0.1475 0.1399 0.1376 0.1348 0.1335 0.1318 0.1321 0.1319 0.1325 0.1324 0.1330 

[TRAIN] Epoch[4](85/1500); Loss: 0.082447; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1837 0.1314 0.0982 0.0798 0.0804 0.0812 0.0726 0.0654 0.0628 0.0636 0.0642 0.0648 0.0661 0.0671 0.0684 0.0694 

[TRAIN] Epoch[4](86/1500); Loss: 0.123025; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1470 0.1372 0.1614 0.1730 0.1617 0.1395 0.1192 0.1094 0.1039 0.1008 0.1009 0.1008 0.1011 0.1030 0.1040 0.1055 

[TRAIN] Epoch[4](87/1500); Loss: 0.103891; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.4034 0.2487 0.1167 0.0610 0.0912 0.0800 0.0641 0.0722 0.0575 0.0591 0.0570 0.0635 0.0672 0.0704 0.0726 0.0778 

[TRAIN] Epoch[4](88/1500); Loss: 0.157319; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2234 0.1916 0.1779 0.1741 0.1696 0.1642 0.1566 0.1499 0.1441 0.1406 0.1383 0.1370 0.1369 0.1369 0.1376 0.1383 

[TRAIN] Epoch[4](89/1500); Loss: 0.119204; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1582 0.1244 0.1250 0.1286 0.1256 0.1176 0.1120 0.1137 0.1143 0.1123 0.1114 0.1113 0.1123 0.1136 0.1134 0.1136 

[TRAIN] Epoch[4](90/1500); Loss: 0.156638; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.2834 0.1896 0.1474 0.1691 0.1836 0.1697 0.1517 0.1380 0.1330 0.1319 0.1337 0.1320 0.1310 0.1326 0.1391 0.1405 

[TRAIN] Epoch[4](91/1500); Loss: 0.150456; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.2946 0.2357 0.1946 0.1685 0.1517 0.1453 0.1402 0.1322 0.1224 0.1194 0.1168 0.1156 0.1161 0.1170 0.1181 0.1192 

[TRAIN] Epoch[4](92/1500); Loss: 0.077143; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2129 0.1564 0.1201 0.0901 0.0670 0.0568 0.0590 0.0591 0.0520 0.0499 0.0504 0.0499 0.0514 0.0522 0.0527 0.0543 

[TRAIN] Epoch[4](93/1500); Loss: 0.148472; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.2342 0.1989 0.1813 0.1679 0.1553 0.1448 0.1378 0.1348 0.1306 0.1267 0.1274 0.1272 0.1273 0.1266 0.1269 0.1280 

[TRAIN] Epoch[4](94/1500); Loss: 0.127129; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2955 0.2322 0.1850 0.1427 0.1152 0.1050 0.1112 0.1045 0.0943 0.0926 0.0917 0.0922 0.0934 0.0924 0.0922 0.0939 

[TRAIN] Epoch[4](95/1500); Loss: 0.164985; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.2428 0.2064 0.1886 0.1835 0.1837 0.1729 0.1611 0.1545 0.1495 0.1459 0.1419 0.1408 0.1412 0.1418 0.1425 0.1426 

[TRAIN] Epoch[4](96/1500); Loss: 0.104626; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.2894 0.1770 0.1020 0.0854 0.1226 0.1242 0.1057 0.0804 0.0702 0.0707 0.0699 0.0712 0.0704 0.0757 0.0792 0.0801 

[TRAIN] Epoch[4](97/1500); Loss: 0.077720; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1120 0.0918 0.1022 0.1012 0.0915 0.0771 0.0699 0.0692 0.0659 0.0657 0.0648 0.0652 0.0664 0.0662 0.0665 0.0680 

[TRAIN] Epoch[4](98/1500); Loss: 0.090608; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3590 0.2529 0.1611 0.0778 0.0573 0.0645 0.0554 0.0446 0.0524 0.0451 0.0464 0.0443 0.0451 0.0484 0.0478 0.0475 

[TRAIN] Epoch[4](99/1500); Loss: 0.069877; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1599 0.1034 0.0736 0.0786 0.0801 0.0678 0.0542 0.0579 0.0550 0.0527 0.0527 0.0542 0.0570 0.0563 0.0566 0.0580 

[TRAIN] Epoch[4](100/1500); Loss: 0.089768; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1311 0.0975 0.0917 0.0933 0.0940 0.0861 0.0826 0.0833 0.0828 0.0833 0.0832 0.0841 0.0849 0.0856 0.0861 0.0867 

[TRAIN] Epoch[4](101/1500); Loss: 0.109863; Backpropagation: 0.0919 sec; Batch: 0.4449 sec
0.2107 0.1512 0.1547 0.1546 0.1369 0.1129 0.0984 0.0885 0.0833 0.0807 0.0781 0.0806 0.0809 0.0825 0.0817 0.0822 

[TRAIN] Epoch[4](102/1500); Loss: 0.146220; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2011 0.1735 0.1642 0.1608 0.1565 0.1493 0.1439 0.1421 0.1381 0.1337 0.1306 0.1295 0.1293 0.1283 0.1291 0.1294 

[TRAIN] Epoch[4](103/1500); Loss: 0.081209; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.1887 0.1175 0.0914 0.1010 0.0994 0.0859 0.0684 0.0623 0.0584 0.0591 0.0586 0.0577 0.0605 0.0625 0.0632 0.0648 

[TRAIN] Epoch[4](104/1500); Loss: 0.118166; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1883 0.1481 0.1235 0.1109 0.1102 0.1095 0.1075 0.1071 0.1068 0.1068 0.1088 0.1103 0.1111 0.1120 0.1142 0.1158 

[TRAIN] Epoch[4](105/1500); Loss: 0.090816; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1750 0.1478 0.1274 0.1060 0.0895 0.0803 0.0774 0.0736 0.0707 0.0696 0.0706 0.0709 0.0722 0.0733 0.0739 0.0748 

[TRAIN] Epoch[4](106/1500); Loss: 0.226316; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.3926 0.3445 0.3058 0.2665 0.2292 0.1971 0.1856 0.1910 0.1890 0.1847 0.1861 0.1872 0.1901 0.1893 0.1901 0.1923 

[TRAIN] Epoch[4](107/1500); Loss: 0.102237; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1487 0.1263 0.1226 0.1216 0.1134 0.1025 0.0939 0.0908 0.0895 0.0892 0.0886 0.0887 0.0892 0.0897 0.0896 0.0916 

[TRAIN] Epoch[4](108/1500); Loss: 0.070748; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1004 0.0779 0.0747 0.0755 0.0706 0.0664 0.0666 0.0663 0.0657 0.0659 0.0658 0.0668 0.0666 0.0668 0.0675 0.0686 

[TRAIN] Epoch[4](109/1500); Loss: 0.117651; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2989 0.2445 0.1964 0.1538 0.1211 0.0992 0.0873 0.0799 0.0761 0.0762 0.0752 0.0746 0.0738 0.0749 0.0760 0.0746 

[TRAIN] Epoch[4](110/1500); Loss: 0.106929; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2046 0.1529 0.1254 0.1113 0.1065 0.1065 0.0993 0.0942 0.0910 0.0897 0.0879 0.0878 0.0879 0.0884 0.0887 0.0887 

[TRAIN] Epoch[4](111/1500); Loss: 0.065948; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1460 0.0654 0.0841 0.0961 0.0839 0.0630 0.0518 0.0500 0.0505 0.0497 0.0469 0.0515 0.0521 0.0541 0.0533 0.0567 

[TRAIN] Epoch[4](112/1500); Loss: 0.143239; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3151 0.2315 0.1699 0.1358 0.1430 0.1424 0.1299 0.1165 0.1177 0.1141 0.1126 0.1114 0.1123 0.1139 0.1132 0.1127 

[TRAIN] Epoch[4](113/1500); Loss: 0.173943; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.3062 0.2565 0.2314 0.2044 0.1759 0.1543 0.1505 0.1465 0.1443 0.1417 0.1420 0.1429 0.1453 0.1461 0.1471 0.1479 

[TRAIN] Epoch[4](114/1500); Loss: 0.108594; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1696 0.1328 0.1292 0.1258 0.1157 0.1033 0.0984 0.0992 0.0944 0.0940 0.0936 0.0946 0.0959 0.0962 0.0965 0.0982 

[TRAIN] Epoch[4](115/1500); Loss: 0.156869; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2628 0.2179 0.1949 0.1768 0.1659 0.1614 0.1519 0.1426 0.1354 0.1317 0.1298 0.1290 0.1281 0.1272 0.1275 0.1270 

[TRAIN] Epoch[4](116/1500); Loss: 0.097559; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1275 0.1182 0.1209 0.1135 0.1055 0.0983 0.0931 0.0893 0.0876 0.0874 0.0859 0.0851 0.0859 0.0869 0.0874 0.0885 

[TRAIN] Epoch[4](117/1500); Loss: 0.127027; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.3215 0.2438 0.1898 0.1516 0.1292 0.1188 0.1076 0.0964 0.0922 0.0829 0.0823 0.0816 0.0826 0.0836 0.0835 0.0850 

[TRAIN] Epoch[4](118/1500); Loss: 0.093900; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1926 0.1255 0.0951 0.1007 0.1013 0.0913 0.0820 0.0809 0.0796 0.0798 0.0781 0.0770 0.0805 0.0781 0.0804 0.0795 

[TRAIN] Epoch[4](119/1500); Loss: 0.130619; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1710 0.1413 0.1382 0.1368 0.1307 0.1248 0.1253 0.1261 0.1239 0.1234 0.1229 0.1232 0.1244 0.1252 0.1258 0.1269 

[TRAIN] Epoch[4](120/1500); Loss: 0.129128; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1738 0.1414 0.1252 0.1241 0.1230 0.1194 0.1174 0.1230 0.1216 0.1220 0.1232 0.1248 0.1288 0.1306 0.1331 0.1348 

[TRAIN] Epoch[4](121/1500); Loss: 0.116827; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1956 0.1492 0.1362 0.1395 0.1343 0.1223 0.1102 0.1039 0.1008 0.0975 0.0957 0.0955 0.0969 0.0963 0.0973 0.0981 

[TRAIN] Epoch[4](122/1500); Loss: 0.151453; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2568 0.1956 0.1626 0.1524 0.1641 0.1582 0.1453 0.1343 0.1367 0.1335 0.1304 0.1295 0.1304 0.1328 0.1303 0.1304 

[TRAIN] Epoch[4](123/1500); Loss: 0.078495; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0965 0.0876 0.1021 0.1075 0.0973 0.0838 0.0721 0.0675 0.0652 0.0645 0.0656 0.0668 0.0675 0.0673 0.0702 0.0744 

[TRAIN] Epoch[4](124/1500); Loss: 0.112806; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2513 0.1898 0.1495 0.1118 0.1078 0.1064 0.0981 0.0910 0.0922 0.0861 0.0856 0.0844 0.0863 0.0859 0.0890 0.0897 

[TRAIN] Epoch[4](125/1500); Loss: 0.151394; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2112 0.1787 0.1703 0.1676 0.1627 0.1525 0.1438 0.1413 0.1389 0.1377 0.1369 0.1368 0.1363 0.1359 0.1359 0.1359 

[TRAIN] Epoch[4](126/1500); Loss: 0.119326; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.1964 0.1442 0.1211 0.1279 0.1256 0.1165 0.1081 0.1071 0.1065 0.1052 0.1057 0.1060 0.1082 0.1092 0.1098 0.1116 

[TRAIN] Epoch[4](127/1500); Loss: 0.092863; Backpropagation: 0.0924 sec; Batch: 0.4247 sec
0.1586 0.1182 0.1029 0.0973 0.0939 0.0899 0.0870 0.0836 0.0799 0.0802 0.0801 0.0806 0.0815 0.0831 0.0837 0.0852 

[TRAIN] Epoch[4](128/1500); Loss: 0.099722; Backpropagation: 0.0922 sec; Batch: 0.4252 sec
0.1975 0.1467 0.1195 0.1066 0.0994 0.0966 0.0906 0.0873 0.0848 0.0811 0.0805 0.0799 0.0807 0.0815 0.0817 0.0810 

[TRAIN] Epoch[4](129/1500); Loss: 0.119867; Backpropagation: 0.0923 sec; Batch: 0.4248 sec
0.3937 0.2900 0.1973 0.1144 0.0923 0.0927 0.0832 0.0722 0.0737 0.0719 0.0712 0.0685 0.0698 0.0728 0.0781 0.0761 

[TRAIN] Epoch[4](130/1500); Loss: 0.073777; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1703 0.1112 0.0857 0.0858 0.0860 0.0758 0.0634 0.0603 0.0570 0.0564 0.0556 0.0543 0.0547 0.0548 0.0545 0.0545 

[TRAIN] Epoch[4](131/1500); Loss: 0.070108; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1071 0.0854 0.0982 0.0906 0.0807 0.0679 0.0609 0.0578 0.0588 0.0571 0.0572 0.0578 0.0600 0.0594 0.0601 0.0627 

[TRAIN] Epoch[4](132/1500); Loss: 0.128479; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1382 0.1389 0.1511 0.1450 0.1370 0.1299 0.1252 0.1220 0.1208 0.1201 0.1206 0.1211 0.1215 0.1215 0.1210 0.1218 

[TRAIN] Epoch[4](133/1500); Loss: 0.080072; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.1101 0.0945 0.1052 0.1007 0.0888 0.0772 0.0761 0.0728 0.0702 0.0694 0.0686 0.0691 0.0696 0.0690 0.0694 0.0704 

[TRAIN] Epoch[4](134/1500); Loss: 0.096635; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2820 0.1595 0.0907 0.0986 0.1260 0.1170 0.0934 0.0699 0.0614 0.0615 0.0637 0.0620 0.0596 0.0632 0.0687 0.0689 

[TRAIN] Epoch[4](135/1500); Loss: 0.111931; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2977 0.1949 0.1329 0.1045 0.1069 0.1037 0.0892 0.0795 0.0820 0.0792 0.0810 0.0819 0.0851 0.0884 0.0913 0.0928 

[TRAIN] Epoch[4](136/1500); Loss: 0.167501; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2747 0.2280 0.1978 0.1944 0.1877 0.1714 0.1550 0.1473 0.1439 0.1434 0.1419 0.1393 0.1389 0.1374 0.1396 0.1392 

[TRAIN] Epoch[4](137/1500); Loss: 0.128567; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2251 0.1809 0.1522 0.1343 0.1295 0.1232 0.1153 0.1123 0.1126 0.1105 0.1102 0.1094 0.1088 0.1104 0.1114 0.1109 

[TRAIN] Epoch[4](138/1500); Loss: 0.121906; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1776 0.1495 0.1375 0.1371 0.1352 0.1262 0.1162 0.1128 0.1080 0.1084 0.1080 0.1061 0.1060 0.1055 0.1083 0.1079 

[TRAIN] Epoch[4](139/1500); Loss: 0.087028; Backpropagation: 0.0924 sec; Batch: 0.4246 sec
0.2244 0.1492 0.0962 0.0823 0.0975 0.0915 0.0761 0.0636 0.0622 0.0598 0.0652 0.0635 0.0616 0.0619 0.0659 0.0715 

[TRAIN] Epoch[4](140/1500); Loss: 0.144781; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1879 0.1698 0.1650 0.1627 0.1524 0.1409 0.1329 0.1322 0.1311 0.1331 0.1328 0.1335 0.1342 0.1353 0.1354 0.1373 

[TRAIN] Epoch[4](141/1500); Loss: 0.128379; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1749 0.1596 0.1535 0.1497 0.1437 0.1330 0.1201 0.1119 0.1138 0.1135 0.1131 0.1121 0.1122 0.1126 0.1150 0.1152 

[TRAIN] Epoch[4](142/1500); Loss: 0.140321; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.2609 0.1987 0.1660 0.1546 0.1542 0.1409 0.1254 0.1159 0.1139 0.1140 0.1156 0.1135 0.1139 0.1158 0.1198 0.1220 

[TRAIN] Epoch[4](143/1500); Loss: 0.091880; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1402 0.1148 0.1211 0.1165 0.1015 0.0869 0.0778 0.0761 0.0758 0.0771 0.0771 0.0771 0.0793 0.0814 0.0836 0.0837 

[TRAIN] Epoch[4](144/1500); Loss: 0.089387; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1620 0.1164 0.0997 0.1021 0.1040 0.0940 0.0803 0.0726 0.0710 0.0742 0.0763 0.0730 0.0714 0.0728 0.0794 0.0812 

[TRAIN] Epoch[4](145/1500); Loss: 0.095673; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2087 0.1572 0.1214 0.0976 0.0886 0.0899 0.0803 0.0756 0.0758 0.0740 0.0744 0.0746 0.0772 0.0763 0.0791 0.0802 

[TRAIN] Epoch[4](146/1500); Loss: 0.129360; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1660 0.1465 0.1410 0.1406 0.1317 0.1239 0.1204 0.1192 0.1194 0.1207 0.1223 0.1214 0.1212 0.1237 0.1253 0.1264 

[TRAIN] Epoch[4](147/1500); Loss: 0.086069; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1263 0.0897 0.0772 0.0850 0.0787 0.0756 0.0706 0.0711 0.0760 0.0841 0.0846 0.0831 0.0858 0.0933 0.0979 0.0983 

[TRAIN] Epoch[4](148/1500); Loss: 0.065975; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.0965 0.0865 0.0871 0.0809 0.0757 0.0636 0.0548 0.0532 0.0539 0.0551 0.0544 0.0548 0.0584 0.0593 0.0606 0.0610 

[TRAIN] Epoch[4](149/1500); Loss: 0.090841; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1395 0.1130 0.1077 0.1009 0.0918 0.0831 0.0796 0.0773 0.0784 0.0792 0.0789 0.0795 0.0821 0.0850 0.0877 0.0897 

[TRAIN] Epoch[4](150/1500); Loss: 0.143963; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.3004 0.2404 0.2095 0.1916 0.1634 0.1323 0.1107 0.1035 0.1117 0.1097 0.1050 0.1023 0.1034 0.1016 0.1081 0.1096 

[TRAIN] Epoch[4](151/1500); Loss: 0.158419; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1959 0.1802 0.1770 0.1748 0.1714 0.1618 0.1524 0.1484 0.1460 0.1460 0.1473 0.1471 0.1467 0.1454 0.1469 0.1474 

[TRAIN] Epoch[4](152/1500); Loss: 0.161827; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.3218 0.2364 0.1869 0.1565 0.1846 0.1913 0.1731 0.1464 0.1248 0.1265 0.1174 0.1232 0.1219 0.1219 0.1252 0.1314 

[TRAIN] Epoch[4](153/1500); Loss: 0.118890; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1564 0.1219 0.1332 0.1537 0.1541 0.1427 0.1243 0.1094 0.1034 0.1006 0.1012 0.0999 0.0983 0.1001 0.1018 0.1013 

[TRAIN] Epoch[4](154/1500); Loss: 0.125887; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2160 0.1703 0.1449 0.1368 0.1383 0.1286 0.1168 0.1095 0.1059 0.1066 0.1080 0.1055 0.1038 0.1052 0.1082 0.1099 

[TRAIN] Epoch[4](155/1500); Loss: 0.083698; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.2526 0.1893 0.1357 0.0934 0.0661 0.0562 0.0611 0.0587 0.0499 0.0497 0.0525 0.0535 0.0564 0.0528 0.0555 0.0559 

[TRAIN] Epoch[4](156/1500); Loss: 0.122063; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1755 0.1466 0.1392 0.1375 0.1331 0.1243 0.1133 0.1060 0.1037 0.1060 0.1077 0.1074 0.1079 0.1101 0.1155 0.1191 

[TRAIN] Epoch[4](157/1500); Loss: 0.065433; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1161 0.0870 0.0772 0.0692 0.0661 0.0590 0.0537 0.0548 0.0551 0.0550 0.0559 0.0565 0.0576 0.0595 0.0616 0.0624 

[TRAIN] Epoch[4](158/1500); Loss: 0.128260; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1658 0.1432 0.1526 0.1593 0.1513 0.1333 0.1161 0.1123 0.1110 0.1134 0.1142 0.1126 0.1132 0.1170 0.1175 0.1193 

[TRAIN] Epoch[4](159/1500); Loss: 0.073310; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0968 0.0796 0.0914 0.0945 0.0847 0.0728 0.0632 0.0616 0.0619 0.0651 0.0636 0.0627 0.0654 0.0681 0.0713 0.0704 

[TRAIN] Epoch[4](160/1500); Loss: 0.144492; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2206 0.1827 0.1790 0.1762 0.1654 0.1500 0.1347 0.1251 0.1237 0.1255 0.1241 0.1198 0.1184 0.1202 0.1237 0.1228 

[TRAIN] Epoch[4](161/1500); Loss: 0.092222; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2606 0.1895 0.1285 0.0866 0.0718 0.0811 0.0771 0.0629 0.0624 0.0618 0.0626 0.0655 0.0634 0.0645 0.0675 0.0697 

[TRAIN] Epoch[4](162/1500); Loss: 0.129219; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1924 0.1736 0.1632 0.1554 0.1423 0.1261 0.1168 0.1120 0.1100 0.1109 0.1115 0.1096 0.1085 0.1097 0.1121 0.1132 

[TRAIN] Epoch[4](163/1500); Loss: 0.153714; Backpropagation: 0.0924 sec; Batch: 0.4249 sec
0.2323 0.1939 0.1768 0.1707 0.1740 0.1685 0.1535 0.1400 0.1349 0.1314 0.1313 0.1333 0.1310 0.1285 0.1292 0.1301 

[TRAIN] Epoch[4](164/1500); Loss: 0.136382; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2459 0.1902 0.1553 0.1372 0.1514 0.1489 0.1353 0.1186 0.1142 0.1112 0.1152 0.1153 0.1116 0.1095 0.1094 0.1129 

[TRAIN] Epoch[4](165/1500); Loss: 0.092693; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.1175 0.0992 0.1139 0.1166 0.1068 0.0908 0.0842 0.0871 0.0818 0.0829 0.0814 0.0815 0.0841 0.0843 0.0855 0.0857 

[TRAIN] Epoch[4](166/1500); Loss: 0.089568; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1711 0.1438 0.1259 0.1044 0.0940 0.0893 0.0811 0.0699 0.0719 0.0690 0.0685 0.0677 0.0670 0.0689 0.0695 0.0710 

[TRAIN] Epoch[4](167/1500); Loss: 0.100364; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1770 0.1007 0.1033 0.1229 0.1162 0.0964 0.0790 0.0851 0.0820 0.0883 0.0889 0.0867 0.0896 0.0951 0.0957 0.0990 

[TRAIN] Epoch[4](168/1500); Loss: 0.135645; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1999 0.1675 0.1531 0.1478 0.1404 0.1318 0.1266 0.1248 0.1209 0.1205 0.1209 0.1206 0.1219 0.1231 0.1244 0.1261 

[TRAIN] Epoch[4](169/1500); Loss: 0.073409; Backpropagation: 0.0924 sec; Batch: 0.4248 sec
0.1038 0.1002 0.1000 0.0874 0.0823 0.0727 0.0633 0.0593 0.0622 0.0609 0.0609 0.0615 0.0622 0.0651 0.0669 0.0659 

[TRAIN] Epoch[4](170/1500); Loss: 0.083619; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1498 0.0798 0.0971 0.1111 0.1056 0.0850 0.0674 0.0726 0.0681 0.0720 0.0718 0.0671 0.0679 0.0743 0.0725 0.0758 

[TRAIN] Epoch[4](171/1500); Loss: 0.208931; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2816 0.2654 0.2466 0.2337 0.2197 0.2065 0.1961 0.1906 0.1862 0.1850 0.1901 0.1897 0.1888 0.1870 0.1867 0.1890 

[TRAIN] Epoch[4](172/1500); Loss: 0.133974; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2549 0.2116 0.1768 0.1667 0.1549 0.1373 0.1209 0.1175 0.1057 0.1043 0.1009 0.0975 0.0971 0.0985 0.0984 0.1003 

[TRAIN] Epoch[4](173/1500); Loss: 0.161496; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2222 0.1959 0.1816 0.1777 0.1748 0.1657 0.1562 0.1518 0.1482 0.1456 0.1441 0.1420 0.1424 0.1442 0.1454 0.1461 

[TRAIN] Epoch[4](174/1500); Loss: 0.146530; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1873 0.1542 0.1590 0.1650 0.1581 0.1461 0.1398 0.1444 0.1398 0.1367 0.1363 0.1347 0.1354 0.1367 0.1348 0.1362 

[TRAIN] Epoch[4](175/1500); Loss: 0.128318; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1573 0.1421 0.1458 0.1417 0.1330 0.1270 0.1271 0.1242 0.1183 0.1178 0.1179 0.1183 0.1196 0.1205 0.1212 0.1215 

[TRAIN] Epoch[4](176/1500); Loss: 0.099964; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.3089 0.2417 0.1786 0.1204 0.0750 0.0604 0.0748 0.0765 0.0584 0.0541 0.0559 0.0583 0.0578 0.0572 0.0598 0.0617 

[TRAIN] Epoch[4](177/1500); Loss: 0.055468; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0534 0.0635 0.0684 0.0595 0.0494 0.0504 0.0556 0.0497 0.0481 0.0497 0.0513 0.0533 0.0557 0.0573 0.0600 0.0622 

[TRAIN] Epoch[4](178/1500); Loss: 0.146887; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2138 0.1873 0.1748 0.1591 0.1457 0.1377 0.1340 0.1331 0.1311 0.1322 0.1311 0.1310 0.1326 0.1345 0.1364 0.1358 

[TRAIN] Epoch[4](179/1500); Loss: 0.127224; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2777 0.2126 0.1571 0.1280 0.1148 0.1060 0.1051 0.1008 0.1001 0.1015 0.1033 0.1027 0.1040 0.1048 0.1083 0.1086 

[TRAIN] Epoch[4](180/1500); Loss: 0.128943; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.3733 0.2567 0.1633 0.0911 0.1256 0.1371 0.1228 0.0957 0.0834 0.0853 0.0857 0.0929 0.0867 0.0837 0.0889 0.0908 

[TRAIN] Epoch[4](181/1500); Loss: 0.118258; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.3909 0.2378 0.1094 0.0799 0.1080 0.0953 0.0752 0.0748 0.0685 0.0855 0.0835 0.0834 0.0960 0.0988 0.1032 0.1018 

[TRAIN] Epoch[4](182/1500); Loss: 0.106380; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2237 0.1596 0.1303 0.1185 0.1161 0.1068 0.0932 0.0863 0.0828 0.0820 0.0825 0.0800 0.0799 0.0834 0.0871 0.0899 

[TRAIN] Epoch[4](183/1500); Loss: 0.095786; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1175 0.1036 0.1096 0.1066 0.0982 0.0917 0.0905 0.0905 0.0887 0.0885 0.0892 0.0896 0.0904 0.0916 0.0932 0.0932 

[TRAIN] Epoch[4](184/1500); Loss: 0.136805; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2033 0.1752 0.1682 0.1649 0.1528 0.1341 0.1233 0.1183 0.1154 0.1141 0.1131 0.1142 0.1188 0.1212 0.1245 0.1275 

[TRAIN] Epoch[4](185/1500); Loss: 0.118942; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1760 0.1582 0.1448 0.1309 0.1197 0.1094 0.1068 0.1036 0.1027 0.1042 0.1030 0.1034 0.1058 0.1095 0.1122 0.1128 

[TRAIN] Epoch[4](186/1500); Loss: 0.114080; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1904 0.1536 0.1276 0.1170 0.1087 0.1063 0.1055 0.1016 0.1006 0.1004 0.1002 0.1001 0.1019 0.1029 0.1037 0.1047 

[TRAIN] Epoch[4](187/1500); Loss: 0.056764; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1136 0.0779 0.0676 0.0616 0.0532 0.0478 0.0445 0.0441 0.0457 0.0474 0.0470 0.0485 0.0501 0.0518 0.0528 0.0548 

[TRAIN] Epoch[4](188/1500); Loss: 0.112185; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2365 0.1504 0.1162 0.1256 0.1177 0.1039 0.0940 0.0994 0.0942 0.0929 0.0925 0.0900 0.0920 0.0976 0.0947 0.0973 

[TRAIN] Epoch[4](189/1500); Loss: 0.155072; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1984 0.1802 0.1756 0.1663 0.1562 0.1471 0.1437 0.1450 0.1429 0.1436 0.1440 0.1442 0.1456 0.1481 0.1497 0.1504 

[TRAIN] Epoch[4](190/1500); Loss: 0.077955; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1508 0.1121 0.0983 0.0888 0.0798 0.0735 0.0728 0.0676 0.0610 0.0602 0.0599 0.0624 0.0637 0.0638 0.0650 0.0675 

[TRAIN] Epoch[4](191/1500); Loss: 0.101518; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1279 0.1104 0.1110 0.1120 0.1050 0.0975 0.0968 0.0989 0.0952 0.0945 0.0951 0.0951 0.0959 0.0959 0.0962 0.0970 

[TRAIN] Epoch[4](192/1500); Loss: 0.107561; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2343 0.1507 0.0977 0.1155 0.1215 0.1069 0.0895 0.0839 0.0852 0.0863 0.0908 0.0876 0.0870 0.0929 0.0920 0.0993 

[TRAIN] Epoch[4](193/1500); Loss: 0.114205; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.2797 0.1948 0.1426 0.1133 0.1016 0.0943 0.0863 0.0862 0.0872 0.0857 0.0866 0.0892 0.0933 0.0938 0.0963 0.0963 

[TRAIN] Epoch[4](194/1500); Loss: 0.137638; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.2698 0.2200 0.1764 0.1495 0.1368 0.1269 0.1240 0.1152 0.1127 0.1101 0.1082 0.1083 0.1100 0.1089 0.1129 0.1123 

[TRAIN] Epoch[4](195/1500); Loss: 0.135787; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1864 0.1534 0.1439 0.1418 0.1367 0.1295 0.1272 0.1284 0.1262 0.1273 0.1272 0.1265 0.1282 0.1293 0.1300 0.1308 

[TRAIN] Epoch[4](196/1500); Loss: 0.111215; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2355 0.1643 0.1240 0.1105 0.1183 0.1113 0.1011 0.0944 0.0909 0.0911 0.0916 0.0888 0.0873 0.0898 0.0901 0.0905 

[TRAIN] Epoch[4](197/1500); Loss: 0.153489; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.2065 0.1783 0.1653 0.1608 0.1559 0.1482 0.1437 0.1429 0.1413 0.1423 0.1433 0.1435 0.1444 0.1457 0.1461 0.1475 

[TRAIN] Epoch[4](198/1500); Loss: 0.073961; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1386 0.0690 0.0910 0.0985 0.0892 0.0673 0.0599 0.0685 0.0592 0.0598 0.0589 0.0602 0.0675 0.0646 0.0650 0.0663 

[TRAIN] Epoch[4](199/1500); Loss: 0.220046; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2921 0.2622 0.2507 0.2444 0.2334 0.2195 0.2091 0.2033 0.1993 0.1983 0.1985 0.1991 0.2001 0.2020 0.2036 0.2049 

[TRAIN] Epoch[4](200/1500); Loss: 0.136201; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1910 0.1968 0.1772 0.1573 0.1410 0.1260 0.1193 0.1185 0.1178 0.1174 0.1183 0.1187 0.1185 0.1193 0.1193 0.1225 

[TRAIN] Epoch[4](201/1500); Loss: 0.130741; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2891 0.2127 0.1612 0.1276 0.1172 0.1139 0.1071 0.1057 0.1118 0.1047 0.1031 0.1031 0.1057 0.1106 0.1102 0.1082 

[TRAIN] Epoch[4](202/1500); Loss: 0.107319; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2665 0.1852 0.1235 0.1031 0.0973 0.0964 0.0880 0.0804 0.0824 0.0825 0.0838 0.0823 0.0826 0.0877 0.0857 0.0897 

[TRAIN] Epoch[4](203/1500); Loss: 0.161935; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2469 0.2290 0.2014 0.1847 0.1715 0.1560 0.1446 0.1390 0.1370 0.1378 0.1388 0.1383 0.1394 0.1413 0.1423 0.1430 

[TRAIN] Epoch[4](204/1500); Loss: 0.070516; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1474 0.1117 0.0898 0.0781 0.0743 0.0677 0.0601 0.0536 0.0540 0.0531 0.0544 0.0552 0.0560 0.0565 0.0570 0.0592 

[TRAIN] Epoch[4](205/1500); Loss: 0.095201; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1500 0.1155 0.1079 0.1100 0.1057 0.0906 0.0832 0.0852 0.0841 0.0843 0.0835 0.0826 0.0843 0.0860 0.0849 0.0854 

[TRAIN] Epoch[4](206/1500); Loss: 0.138254; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2296 0.2124 0.1959 0.1732 0.1497 0.1276 0.1188 0.1138 0.1114 0.1113 0.1132 0.1112 0.1103 0.1098 0.1115 0.1124 

[TRAIN] Epoch[4](207/1500); Loss: 0.100255; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.2084 0.1456 0.1225 0.1111 0.1054 0.0967 0.0887 0.0862 0.0833 0.0803 0.0790 0.0786 0.0794 0.0797 0.0797 0.0794 

[TRAIN] Epoch[4](208/1500); Loss: 0.090559; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1513 0.1208 0.1036 0.0931 0.0930 0.0873 0.0798 0.0784 0.0785 0.0786 0.0782 0.0780 0.0796 0.0813 0.0835 0.0839 

[TRAIN] Epoch[4](209/1500); Loss: 0.113359; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1686 0.1392 0.1303 0.1294 0.1253 0.1162 0.1040 0.0997 0.0987 0.1000 0.1013 0.0988 0.0978 0.1006 0.1012 0.1028 

[TRAIN] Epoch[4](210/1500); Loss: 0.143433; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2157 0.1948 0.1810 0.1635 0.1470 0.1403 0.1338 0.1277 0.1235 0.1254 0.1248 0.1253 0.1239 0.1224 0.1231 0.1227 

[TRAIN] Epoch[4](211/1500); Loss: 0.084568; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1396 0.1108 0.0949 0.0958 0.0841 0.0788 0.0760 0.0721 0.0732 0.0750 0.0732 0.0737 0.0729 0.0752 0.0764 0.0815 

[TRAIN] Epoch[4](212/1500); Loss: 0.113339; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2084 0.1631 0.1367 0.1157 0.1072 0.1040 0.1002 0.0980 0.0971 0.0968 0.0971 0.0975 0.0973 0.0979 0.0976 0.0988 

[TRAIN] Epoch[4](213/1500); Loss: 0.121207; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1804 0.1558 0.1475 0.1427 0.1342 0.1199 0.1104 0.1049 0.1038 0.1040 0.1050 0.1046 0.1053 0.1059 0.1070 0.1078 

[TRAIN] Epoch[4](214/1500); Loss: 0.156357; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2519 0.2214 0.1948 0.1754 0.1576 0.1446 0.1368 0.1344 0.1346 0.1335 0.1350 0.1350 0.1355 0.1357 0.1364 0.1391 

[TRAIN] Epoch[4](215/1500); Loss: 0.204322; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.3089 0.2785 0.2461 0.2264 0.2101 0.1944 0.1847 0.1796 0.1770 0.1783 0.1800 0.1794 0.1798 0.1815 0.1819 0.1827 

[TRAIN] Epoch[4](216/1500); Loss: 0.077660; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1053 0.1077 0.1168 0.1052 0.0847 0.0662 0.0681 0.0639 0.0654 0.0639 0.0613 0.0642 0.0659 0.0686 0.0675 0.0677 

[TRAIN] Epoch[4](217/1500); Loss: 0.076821; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1667 0.1085 0.0967 0.0964 0.0835 0.0654 0.0653 0.0605 0.0608 0.0585 0.0578 0.0604 0.0601 0.0634 0.0619 0.0633 

[TRAIN] Epoch[4](218/1500); Loss: 0.136027; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1838 0.1908 0.1904 0.1732 0.1534 0.1336 0.1181 0.1146 0.1142 0.1157 0.1122 0.1107 0.1125 0.1155 0.1199 0.1178 

[TRAIN] Epoch[4](219/1500); Loss: 0.071788; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1897 0.1231 0.0829 0.0779 0.0734 0.0595 0.0545 0.0518 0.0535 0.0550 0.0524 0.0519 0.0545 0.0564 0.0561 0.0561 

[TRAIN] Epoch[4](220/1500); Loss: 0.106569; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1874 0.1325 0.1107 0.1137 0.1106 0.1013 0.0954 0.0974 0.0941 0.0941 0.0934 0.0928 0.0935 0.0948 0.0964 0.0971 

[TRAIN] Epoch[4](221/1500); Loss: 0.137997; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2520 0.1831 0.1486 0.1449 0.1425 0.1332 0.1254 0.1234 0.1214 0.1207 0.1199 0.1186 0.1174 0.1188 0.1184 0.1196 

[TRAIN] Epoch[4](222/1500); Loss: 0.128790; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1643 0.1481 0.1576 0.1558 0.1453 0.1298 0.1195 0.1169 0.1137 0.1158 0.1145 0.1137 0.1147 0.1159 0.1176 0.1176 

[TRAIN] Epoch[4](223/1500); Loss: 0.102273; Backpropagation: 0.0923 sec; Batch: 0.4248 sec
0.2611 0.1809 0.1232 0.1076 0.0951 0.0915 0.0857 0.0755 0.0740 0.0753 0.0764 0.0763 0.0749 0.0795 0.0786 0.0808 

[TRAIN] Epoch[4](224/1500); Loss: 0.093583; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1495 0.1107 0.1278 0.1254 0.1089 0.0879 0.0839 0.0811 0.0786 0.0775 0.0748 0.0752 0.0791 0.0781 0.0800 0.0790 

[TRAIN] Epoch[4](225/1500); Loss: 0.099467; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1145 0.1176 0.1251 0.1163 0.1058 0.0961 0.0911 0.0895 0.0896 0.0909 0.0902 0.0908 0.0916 0.0929 0.0943 0.0952 

[TRAIN] Epoch[4](226/1500); Loss: 0.111297; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2804 0.2163 0.1618 0.1175 0.0929 0.0887 0.0958 0.0872 0.0814 0.0803 0.0794 0.0794 0.0790 0.0793 0.0804 0.0810 

[TRAIN] Epoch[4](227/1500); Loss: 0.112664; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.3940 0.2670 0.1602 0.0729 0.0987 0.1121 0.1001 0.0757 0.0639 0.0653 0.0647 0.0646 0.0606 0.0639 0.0668 0.0720 

[TRAIN] Epoch[4](228/1500); Loss: 0.156139; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2661 0.2238 0.1896 0.1683 0.1529 0.1454 0.1416 0.1372 0.1382 0.1359 0.1339 0.1321 0.1321 0.1350 0.1342 0.1322 

[TRAIN] Epoch[4](229/1500); Loss: 0.143373; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.1952 0.1663 0.1507 0.1450 0.1369 0.1327 0.1312 0.1301 0.1311 0.1336 0.1351 0.1363 0.1374 0.1404 0.1443 0.1478 

[TRAIN] Epoch[4](230/1500); Loss: 0.138988; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2135 0.1808 0.1621 0.1472 0.1363 0.1286 0.1266 0.1254 0.1233 0.1221 0.1216 0.1237 0.1262 0.1280 0.1288 0.1294 

[TRAIN] Epoch[4](231/1500); Loss: 0.072559; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1830 0.1359 0.1069 0.0792 0.0675 0.0617 0.0584 0.0591 0.0526 0.0494 0.0492 0.0502 0.0529 0.0509 0.0518 0.0525 

[TRAIN] Epoch[4](232/1500); Loss: 0.069053; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1683 0.1076 0.0670 0.0682 0.0643 0.0559 0.0542 0.0606 0.0570 0.0552 0.0542 0.0555 0.0589 0.0577 0.0599 0.0604 

[TRAIN] Epoch[4](233/1500); Loss: 0.153236; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1807 0.1691 0.1616 0.1565 0.1525 0.1468 0.1434 0.1432 0.1447 0.1452 0.1471 0.1484 0.1496 0.1518 0.1541 0.1569 

[TRAIN] Epoch[4](234/1500); Loss: 0.138196; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.2544 0.2025 0.1728 0.1514 0.1371 0.1284 0.1206 0.1168 0.1161 0.1167 0.1157 0.1141 0.1130 0.1155 0.1175 0.1186 

[TRAIN] Epoch[4](235/1500); Loss: 0.113047; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2411 0.1714 0.1339 0.1183 0.1115 0.1002 0.0899 0.0876 0.0900 0.0912 0.0907 0.0915 0.0947 0.0972 0.0994 0.1002 

[TRAIN] Epoch[4](236/1500); Loss: 0.111278; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1959 0.1437 0.1253 0.1191 0.1159 0.1042 0.1002 0.0970 0.0975 0.0976 0.0969 0.0970 0.0970 0.0975 0.0979 0.0975 

[TRAIN] Epoch[4](237/1500); Loss: 0.095808; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1562 0.1186 0.0975 0.0974 0.0923 0.0898 0.0896 0.0858 0.0856 0.0865 0.0874 0.0879 0.0878 0.0892 0.0900 0.0914 

[TRAIN] Epoch[4](238/1500); Loss: 0.109206; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1187 0.1149 0.1206 0.1181 0.1110 0.1085 0.1104 0.1074 0.1042 0.1041 0.1039 0.1050 0.1045 0.1049 0.1053 0.1058 

[TRAIN] Epoch[4](239/1500); Loss: 0.101509; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2001 0.1610 0.1270 0.0992 0.0885 0.0982 0.0956 0.0827 0.0834 0.0822 0.0831 0.0830 0.0842 0.0850 0.0859 0.0851 

[TRAIN] Epoch[4](240/1500); Loss: 0.146587; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1743 0.1620 0.1643 0.1605 0.1518 0.1445 0.1425 0.1420 0.1383 0.1377 0.1372 0.1377 0.1385 0.1379 0.1379 0.1382 

[TRAIN] Epoch[4](241/1500); Loss: 0.080905; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1364 0.1001 0.0981 0.0971 0.0870 0.0737 0.0724 0.0753 0.0705 0.0690 0.0679 0.0686 0.0697 0.0698 0.0692 0.0696 

[TRAIN] Epoch[4](242/1500); Loss: 0.100589; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2062 0.1383 0.0976 0.1115 0.1115 0.0993 0.0842 0.0786 0.0784 0.0839 0.0888 0.0852 0.0815 0.0840 0.0870 0.0934 

[TRAIN] Epoch[4](243/1500); Loss: 0.135270; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1948 0.1576 0.1471 0.1440 0.1397 0.1318 0.1217 0.1186 0.1198 0.1232 0.1247 0.1239 0.1255 0.1286 0.1310 0.1324 

[TRAIN] Epoch[4](244/1500); Loss: 0.111843; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.3930 0.2389 0.1107 0.0764 0.0993 0.0870 0.0686 0.0722 0.0626 0.0737 0.0698 0.0723 0.0851 0.0954 0.0960 0.0885 

[TRAIN] Epoch[4](245/1500); Loss: 0.143579; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2985 0.2443 0.1935 0.1535 0.1298 0.1261 0.1225 0.1195 0.1173 0.1164 0.1134 0.1123 0.1124 0.1138 0.1126 0.1113 

[TRAIN] Epoch[4](246/1500); Loss: 0.085988; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.1507 0.1344 0.1201 0.1014 0.0898 0.0793 0.0720 0.0692 0.0697 0.0690 0.0686 0.0685 0.0692 0.0711 0.0713 0.0715 

[TRAIN] Epoch[4](247/1500); Loss: 0.103034; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.3958 0.2361 0.1044 0.0657 0.0893 0.0771 0.0585 0.0624 0.0529 0.0634 0.0581 0.0616 0.0758 0.0843 0.0857 0.0774 

[TRAIN] Epoch[4](248/1500); Loss: 0.144408; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2738 0.2175 0.1761 0.1481 0.1341 0.1318 0.1268 0.1229 0.1225 0.1228 0.1230 0.1225 0.1211 0.1215 0.1227 0.1235 

[TRAIN] Epoch[4](249/1500); Loss: 0.082650; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0878 0.0890 0.1109 0.1060 0.0931 0.0790 0.0698 0.0711 0.0722 0.0769 0.0761 0.0744 0.0744 0.0771 0.0811 0.0835 

[TRAIN] Epoch[4](250/1500); Loss: 0.096283; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.3975 0.2337 0.0995 0.0569 0.0803 0.0682 0.0503 0.0555 0.0441 0.0544 0.0486 0.0527 0.0664 0.0801 0.0810 0.0714 

[TRAIN] Epoch[4](251/1500); Loss: 0.060931; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1524 0.0643 0.0721 0.0900 0.0793 0.0553 0.0411 0.0392 0.0467 0.0508 0.0447 0.0420 0.0477 0.0487 0.0509 0.0497 

[TRAIN] Epoch[4](252/1500); Loss: 0.070682; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1513 0.1140 0.0926 0.0773 0.0743 0.0653 0.0595 0.0582 0.0538 0.0536 0.0551 0.0546 0.0555 0.0545 0.0547 0.0566 

[TRAIN] Epoch[4](253/1500); Loss: 0.098423; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2558 0.1764 0.1322 0.1118 0.1079 0.0941 0.0820 0.0745 0.0692 0.0656 0.0678 0.0669 0.0660 0.0667 0.0690 0.0690 

[TRAIN] Epoch[4](254/1500); Loss: 0.059172; Backpropagation: 0.0925 sec; Batch: 0.4249 sec
0.1071 0.1014 0.0845 0.0666 0.0543 0.0520 0.0524 0.0435 0.0434 0.0447 0.0485 0.0474 0.0480 0.0488 0.0513 0.0526 

[TRAIN] Epoch[4](255/1500); Loss: 0.112270; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2361 0.1776 0.1368 0.1222 0.1181 0.1084 0.0958 0.0958 0.0897 0.0920 0.0896 0.0859 0.0846 0.0867 0.0888 0.0883 

[TRAIN] Epoch[4](256/1500); Loss: 0.127832; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2903 0.2116 0.1618 0.1270 0.1179 0.1142 0.1052 0.1020 0.1073 0.0993 0.0994 0.0984 0.1003 0.1039 0.1031 0.1037 

[TRAIN] Epoch[4](257/1500); Loss: 0.102859; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2532 0.1946 0.1446 0.1108 0.0907 0.0842 0.0847 0.0785 0.0776 0.0764 0.0742 0.0747 0.0750 0.0760 0.0754 0.0751 

[TRAIN] Epoch[4](258/1500); Loss: 0.118763; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.3466 0.2809 0.2154 0.1570 0.1050 0.0759 0.0800 0.0718 0.0758 0.0764 0.0702 0.0643 0.0688 0.0665 0.0744 0.0713 

[TRAIN] Epoch[4](259/1500); Loss: 0.080666; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2120 0.1177 0.0850 0.0887 0.0866 0.0739 0.0588 0.0566 0.0527 0.0626 0.0618 0.0577 0.0602 0.0648 0.0753 0.0762 

[TRAIN] Epoch[4](260/1500); Loss: 0.116227; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1920 0.1498 0.1278 0.1214 0.1176 0.1123 0.1081 0.1077 0.1034 0.1028 0.1021 0.1026 0.1037 0.1024 0.1023 0.1035 

[TRAIN] Epoch[4](261/1500); Loss: 0.111972; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2047 0.1603 0.1286 0.1186 0.1173 0.1114 0.1034 0.1009 0.0963 0.0977 0.0958 0.0930 0.0905 0.0914 0.0909 0.0906 

[TRAIN] Epoch[4](262/1500); Loss: 0.169123; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2494 0.2185 0.1978 0.1823 0.1729 0.1656 0.1598 0.1574 0.1559 0.1539 0.1496 0.1463 0.1470 0.1498 0.1505 0.1492 

[TRAIN] Epoch[4](263/1500); Loss: 0.164166; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2361 0.1911 0.1767 0.1749 0.1796 0.1703 0.1558 0.1489 0.1502 0.1498 0.1504 0.1478 0.1467 0.1477 0.1503 0.1505 

[TRAIN] Epoch[4](264/1500); Loss: 0.142568; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2669 0.2026 0.1606 0.1492 0.1519 0.1403 0.1275 0.1232 0.1194 0.1244 0.1241 0.1174 0.1145 0.1188 0.1182 0.1223 

[TRAIN] Epoch[4](265/1500); Loss: 0.110398; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.4061 0.2430 0.1167 0.0723 0.0861 0.0757 0.0641 0.0714 0.0713 0.0805 0.0707 0.0649 0.0797 0.0882 0.0928 0.0829 

[TRAIN] Epoch[4](266/1500); Loss: 0.089474; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.2188 0.1582 0.1172 0.0961 0.0906 0.0801 0.0718 0.0715 0.0686 0.0669 0.0652 0.0630 0.0647 0.0646 0.0663 0.0678 

[TRAIN] Epoch[4](267/1500); Loss: 0.154132; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2234 0.1816 0.1750 0.1759 0.1699 0.1565 0.1452 0.1396 0.1366 0.1389 0.1372 0.1354 0.1366 0.1380 0.1383 0.1380 

[TRAIN] Epoch[4](268/1500); Loss: 0.114603; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.3195 0.2260 0.1642 0.1130 0.0962 0.0919 0.0820 0.0834 0.0885 0.0790 0.0792 0.0786 0.0833 0.0843 0.0825 0.0819 

[TRAIN] Epoch[4](269/1500); Loss: 0.092394; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2286 0.1454 0.1048 0.0984 0.0956 0.0833 0.0780 0.0748 0.0727 0.0724 0.0692 0.0705 0.0724 0.0723 0.0709 0.0688 

[TRAIN] Epoch[4](270/1500); Loss: 0.144555; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.3065 0.2309 0.1743 0.1359 0.1382 0.1320 0.1237 0.1174 0.1195 0.1185 0.1196 0.1184 0.1197 0.1197 0.1198 0.1187 

[TRAIN] Epoch[4](271/1500); Loss: 0.113054; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1712 0.1474 0.1359 0.1223 0.1171 0.1073 0.1025 0.0988 0.1013 0.1010 0.0997 0.0988 0.0982 0.1018 0.1035 0.1021 

[TRAIN] Epoch[4](272/1500); Loss: 0.158904; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.2630 0.2064 0.1887 0.1772 0.1672 0.1568 0.1449 0.1409 0.1353 0.1373 0.1375 0.1352 0.1353 0.1363 0.1400 0.1404 

[TRAIN] Epoch[4](273/1500); Loss: 0.122155; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1807 0.1534 0.1460 0.1410 0.1335 0.1222 0.1154 0.1136 0.1091 0.1083 0.1064 0.1053 0.1046 0.1055 0.1048 0.1047 

[TRAIN] Epoch[4](274/1500); Loss: 0.189425; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.4018 0.3149 0.2423 0.1657 0.1404 0.1643 0.1613 0.1533 0.1527 0.1540 0.1578 0.1619 0.1627 0.1631 0.1658 0.1690 

[TRAIN] Epoch[4](275/1500); Loss: 0.115209; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2535 0.1880 0.1440 0.1260 0.1151 0.0980 0.0909 0.0956 0.0893 0.0903 0.0891 0.0905 0.0917 0.0933 0.0937 0.0945 

[TRAIN] Epoch[4](276/1500); Loss: 0.065698; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1155 0.1022 0.0912 0.0739 0.0636 0.0551 0.0555 0.0569 0.0526 0.0528 0.0543 0.0547 0.0553 0.0546 0.0556 0.0574 

[TRAIN] Epoch[4](277/1500); Loss: 0.158380; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2469 0.2168 0.1988 0.1789 0.1622 0.1546 0.1488 0.1408 0.1374 0.1359 0.1363 0.1366 0.1354 0.1343 0.1349 0.1355 

[TRAIN] Epoch[4](278/1500); Loss: 0.158677; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.2494 0.2146 0.1952 0.1795 0.1672 0.1551 0.1443 0.1398 0.1384 0.1405 0.1381 0.1345 0.1335 0.1347 0.1375 0.1366 

[TRAIN] Epoch[4](279/1500); Loss: 0.093785; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1731 0.1157 0.1022 0.0970 0.0955 0.0867 0.0857 0.0836 0.0814 0.0798 0.0795 0.0818 0.0829 0.0832 0.0850 0.0875 

[TRAIN] Epoch[4](280/1500); Loss: 0.069939; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1658 0.1182 0.0880 0.0668 0.0543 0.0626 0.0581 0.0524 0.0534 0.0546 0.0548 0.0562 0.0572 0.0578 0.0587 0.0603 

[TRAIN] Epoch[4](281/1500); Loss: 0.098824; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1490 0.1160 0.1125 0.1070 0.0993 0.0907 0.0908 0.0943 0.0905 0.0891 0.0888 0.0889 0.0905 0.0904 0.0910 0.0924 

[TRAIN] Epoch[4](282/1500); Loss: 0.100416; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1384 0.1214 0.1446 0.1522 0.1332 0.0999 0.0822 0.0788 0.0878 0.0875 0.0809 0.0767 0.0809 0.0816 0.0810 0.0795 

[TRAIN] Epoch[4](283/1500); Loss: 0.125932; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1871 0.1633 0.1650 0.1582 0.1437 0.1229 0.1116 0.1046 0.1058 0.1041 0.1013 0.1032 0.1081 0.1121 0.1114 0.1125 

[TRAIN] Epoch[4](284/1500); Loss: 0.118188; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1389 0.1238 0.1303 0.1248 0.1139 0.1124 0.1184 0.1139 0.1122 0.1125 0.1133 0.1134 0.1141 0.1151 0.1161 0.1177 

[TRAIN] Epoch[4](285/1500); Loss: 0.114379; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2450 0.1528 0.1138 0.1200 0.1223 0.1106 0.0990 0.1021 0.0957 0.0994 0.0959 0.0924 0.0923 0.0959 0.0972 0.0957 

[TRAIN] Epoch[4](286/1500); Loss: 0.123466; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2666 0.1829 0.1328 0.1183 0.1142 0.1094 0.1054 0.1042 0.1013 0.1026 0.1020 0.1039 0.1074 0.1072 0.1079 0.1091 

[TRAIN] Epoch[4](287/1500); Loss: 0.138829; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.3174 0.2344 0.1697 0.1449 0.1324 0.1287 0.1139 0.1124 0.1100 0.1082 0.1042 0.1038 0.1096 0.1129 0.1118 0.1068 

[TRAIN] Epoch[4](288/1500); Loss: 0.168713; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2459 0.2226 0.2065 0.1881 0.1731 0.1623 0.1550 0.1525 0.1532 0.1514 0.1495 0.1482 0.1480 0.1485 0.1474 0.1473 

[TRAIN] Epoch[4](289/1500); Loss: 0.184488; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2477 0.2119 0.2113 0.2106 0.2013 0.1856 0.1737 0.1689 0.1671 0.1729 0.1725 0.1672 0.1648 0.1646 0.1653 0.1664 

[TRAIN] Epoch[4](290/1500); Loss: 0.146886; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.1976 0.1936 0.1851 0.1680 0.1494 0.1339 0.1323 0.1332 0.1362 0.1341 0.1315 0.1302 0.1323 0.1316 0.1301 0.1312 

[TRAIN] Epoch[4](291/1500); Loss: 0.099332; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.4082 0.2383 0.1078 0.0558 0.0697 0.0612 0.0541 0.0606 0.0600 0.0663 0.0566 0.0542 0.0682 0.0768 0.0807 0.0708 

[TRAIN] Epoch[4](292/1500); Loss: 0.115073; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2309 0.1734 0.1333 0.1095 0.0963 0.1005 0.0995 0.0985 0.0980 0.0980 0.1001 0.1012 0.1001 0.0992 0.1006 0.1022 

[TRAIN] Epoch[4](293/1500); Loss: 0.106390; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2306 0.1679 0.1317 0.1032 0.0982 0.0904 0.0893 0.0886 0.0882 0.0872 0.0870 0.0877 0.0863 0.0880 0.0893 0.0886 

[TRAIN] Epoch[4](294/1500); Loss: 0.082343; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2322 0.1574 0.1105 0.0808 0.0722 0.0678 0.0627 0.0586 0.0616 0.0604 0.0578 0.0583 0.0604 0.0596 0.0583 0.0590 

[TRAIN] Epoch[4](295/1500); Loss: 0.140688; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2081 0.1631 0.1427 0.1428 0.1391 0.1376 0.1331 0.1320 0.1314 0.1313 0.1303 0.1295 0.1300 0.1327 0.1336 0.1337 

[TRAIN] Epoch[4](296/1500); Loss: 0.120540; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.2233 0.1737 0.1476 0.1229 0.1186 0.1117 0.1012 0.1009 0.1006 0.1061 0.1029 0.1000 0.1033 0.1047 0.1070 0.1041 

[TRAIN] Epoch[4](297/1500); Loss: 0.150908; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2581 0.2051 0.1754 0.1625 0.1581 0.1453 0.1353 0.1338 0.1320 0.1324 0.1305 0.1280 0.1289 0.1305 0.1298 0.1288 

[TRAIN] Epoch[4](298/1500); Loss: 0.116089; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2666 0.1802 0.1471 0.1295 0.1081 0.0915 0.0996 0.0984 0.0905 0.0915 0.0913 0.0923 0.0926 0.0916 0.0926 0.0941 

[TRAIN] Epoch[4](299/1500); Loss: 0.060182; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.0856 0.0549 0.0613 0.0620 0.0565 0.0510 0.0551 0.0567 0.0565 0.0555 0.0557 0.0595 0.0609 0.0609 0.0626 0.0682 

[TRAIN] Epoch[4](300/1500); Loss: 0.056767; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0567 0.0610 0.0748 0.0676 0.0523 0.0579 0.0571 0.0507 0.0514 0.0511 0.0522 0.0530 0.0536 0.0553 0.0565 0.0573 

[TRAIN] Epoch[4](301/1500); Loss: 0.083516; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1479 0.1102 0.1052 0.1001 0.0890 0.0762 0.0754 0.0758 0.0702 0.0701 0.0692 0.0687 0.0688 0.0690 0.0698 0.0706 

[TRAIN] Epoch[4](302/1500); Loss: 0.103559; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.2065 0.1591 0.1443 0.1248 0.1279 0.1042 0.0689 0.0700 0.0722 0.0785 0.0793 0.0753 0.0795 0.0866 0.0892 0.0908 

[TRAIN] Epoch[4](303/1500); Loss: 0.056362; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0741 0.0647 0.0667 0.0578 0.0529 0.0651 0.0582 0.0492 0.0478 0.0480 0.0494 0.0507 0.0518 0.0530 0.0557 0.0568 

[TRAIN] Epoch[4](304/1500); Loss: 0.107435; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1552 0.1174 0.1087 0.1082 0.1058 0.1028 0.1013 0.1006 0.1003 0.1001 0.1003 0.1016 0.1031 0.1040 0.1046 0.1050 

[TRAIN] Epoch[4](305/1500); Loss: 0.147499; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2363 0.1917 0.1659 0.1571 0.1525 0.1439 0.1345 0.1335 0.1340 0.1304 0.1273 0.1280 0.1300 0.1317 0.1316 0.1316 

[TRAIN] Epoch[4](306/1500); Loss: 0.125212; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.2218 0.1522 0.1366 0.1455 0.1364 0.1186 0.1096 0.1060 0.1119 0.1121 0.1065 0.1055 0.1058 0.1134 0.1129 0.1083 

[TRAIN] Epoch[4](307/1500); Loss: 0.119721; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2192 0.1643 0.1343 0.1268 0.1215 0.1076 0.1036 0.1078 0.1036 0.1055 0.1018 0.1010 0.1048 0.1049 0.1056 0.1031 

[TRAIN] Epoch[4](308/1500); Loss: 0.203173; Backpropagation: 0.0924 sec; Batch: 0.4251 sec
0.2484 0.2069 0.2211 0.2278 0.2168 0.2004 0.1902 0.1867 0.1919 0.1959 0.1933 0.1901 0.1901 0.1950 0.1988 0.1976 

[TRAIN] Epoch[4](309/1500); Loss: 0.087051; Backpropagation: 0.0922 sec; Batch: 0.4256 sec
0.1224 0.1080 0.1243 0.1181 0.0978 0.0730 0.0675 0.0673 0.0750 0.0739 0.0704 0.0718 0.0760 0.0827 0.0818 0.0827 

[TRAIN] Epoch[4](310/1500); Loss: 0.099646; Backpropagation: 0.0919 sec; Batch: 0.4248 sec
0.1532 0.1062 0.0996 0.1059 0.0979 0.0919 0.0947 0.0920 0.0927 0.0916 0.0923 0.0926 0.0955 0.0954 0.0953 0.0976 

[TRAIN] Epoch[4](311/1500); Loss: 0.097267; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2051 0.1301 0.1274 0.1315 0.1090 0.0786 0.0811 0.0817 0.0745 0.0774 0.0730 0.0741 0.0761 0.0777 0.0791 0.0799 

[TRAIN] Epoch[4](312/1500); Loss: 0.096546; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1525 0.1184 0.1187 0.1131 0.1017 0.0896 0.0882 0.0848 0.0851 0.0834 0.0819 0.0834 0.0848 0.0853 0.0859 0.0880 

[TRAIN] Epoch[4](313/1500); Loss: 0.158584; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2527 0.2210 0.2053 0.1823 0.1628 0.1561 0.1481 0.1388 0.1365 0.1375 0.1334 0.1325 0.1315 0.1335 0.1333 0.1320 

[TRAIN] Epoch[4](314/1500); Loss: 0.140322; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1838 0.1508 0.1636 0.1691 0.1618 0.1440 0.1298 0.1253 0.1230 0.1299 0.1276 0.1244 0.1238 0.1250 0.1317 0.1317 

[TRAIN] Epoch[4](315/1500); Loss: 0.116252; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1468 0.1262 0.1219 0.1222 0.1149 0.1101 0.1146 0.1113 0.1113 0.1100 0.1095 0.1101 0.1123 0.1121 0.1122 0.1144 

[TRAIN] Epoch[4](316/1500); Loss: 0.120726; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.2535 0.1777 0.1505 0.1373 0.1281 0.1163 0.1080 0.0997 0.1011 0.0977 0.0934 0.0889 0.0921 0.0955 0.0970 0.0947 

[TRAIN] Epoch[4](317/1500); Loss: 0.046229; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0366 0.0507 0.0478 0.0448 0.0429 0.0415 0.0427 0.0446 0.0428 0.0445 0.0457 0.0476 0.0498 0.0506 0.0529 0.0542 

[TRAIN] Epoch[4](318/1500); Loss: 0.156069; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2527 0.2081 0.1876 0.1891 0.1792 0.1599 0.1392 0.1332 0.1273 0.1366 0.1336 0.1283 0.1278 0.1274 0.1350 0.1323 

[TRAIN] Epoch[4](319/1500); Loss: 0.130395; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2017 0.1598 0.1485 0.1436 0.1340 0.1242 0.1197 0.1210 0.1181 0.1171 0.1165 0.1151 0.1155 0.1169 0.1174 0.1173 

[TRAIN] Epoch[4](320/1500); Loss: 0.110919; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1690 0.1316 0.1266 0.1302 0.1200 0.1034 0.0950 0.0964 0.0989 0.1017 0.0984 0.0976 0.0985 0.0997 0.1047 0.1029 

[TRAIN] Epoch[4](321/1500); Loss: 0.075900; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0944 0.0827 0.0868 0.0848 0.0766 0.0667 0.0681 0.0649 0.0713 0.0692 0.0675 0.0695 0.0744 0.0800 0.0785 0.0791 

[TRAIN] Epoch[4](322/1500); Loss: 0.082070; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1170 0.0867 0.0854 0.0881 0.0810 0.0802 0.0842 0.0774 0.0766 0.0757 0.0759 0.0764 0.0773 0.0770 0.0763 0.0778 

[TRAIN] Epoch[4](323/1500); Loss: 0.063963; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1357 0.0582 0.0795 0.0973 0.0820 0.0528 0.0514 0.0439 0.0596 0.0570 0.0457 0.0448 0.0500 0.0590 0.0565 0.0499 

[TRAIN] Epoch[4](324/1500); Loss: 0.138147; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1938 0.1729 0.1618 0.1515 0.1413 0.1339 0.1302 0.1258 0.1241 0.1231 0.1231 0.1242 0.1254 0.1250 0.1260 0.1283 

[TRAIN] Epoch[4](325/1500); Loss: 0.126000; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1899 0.1504 0.1387 0.1334 0.1257 0.1183 0.1166 0.1156 0.1153 0.1148 0.1140 0.1151 0.1163 0.1166 0.1170 0.1182 

[TRAIN] Epoch[4](326/1500); Loss: 0.156438; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2324 0.1867 0.1714 0.1673 0.1668 0.1556 0.1453 0.1434 0.1434 0.1437 0.1415 0.1403 0.1406 0.1411 0.1427 0.1410 

[TRAIN] Epoch[4](327/1500); Loss: 0.116729; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1920 0.1427 0.1334 0.1379 0.1330 0.1155 0.1024 0.1031 0.1030 0.1036 0.1000 0.0982 0.0992 0.1011 0.1025 0.1002 

[TRAIN] Epoch[4](328/1500); Loss: 0.110112; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1450 0.1315 0.1450 0.1531 0.1390 0.1114 0.0991 0.0922 0.0957 0.0973 0.0919 0.0896 0.0898 0.0955 0.0949 0.0907 

[TRAIN] Epoch[4](329/1500); Loss: 0.107240; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2152 0.1563 0.1270 0.1143 0.1064 0.1004 0.0942 0.0920 0.0903 0.0895 0.0894 0.0878 0.0876 0.0886 0.0889 0.0880 

[TRAIN] Epoch[4](330/1500); Loss: 0.175989; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2484 0.2207 0.1997 0.1882 0.1828 0.1704 0.1633 0.1603 0.1600 0.1614 0.1601 0.1585 0.1586 0.1605 0.1612 0.1618 

[TRAIN] Epoch[4](331/1500); Loss: 0.140322; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1866 0.1536 0.1569 0.1562 0.1464 0.1344 0.1355 0.1318 0.1314 0.1313 0.1306 0.1288 0.1286 0.1304 0.1313 0.1314 

[TRAIN] Epoch[4](332/1500); Loss: 0.072616; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1125 0.0891 0.0825 0.0839 0.0777 0.0702 0.0713 0.0665 0.0638 0.0650 0.0627 0.0622 0.0633 0.0643 0.0631 0.0637 

[TRAIN] Epoch[4](333/1500); Loss: 0.103945; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.3046 0.1875 0.1074 0.0753 0.0980 0.0921 0.0753 0.0695 0.0702 0.0776 0.0800 0.0785 0.0813 0.0850 0.0896 0.0913 

[TRAIN] Epoch[4](334/1500); Loss: 0.128886; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2322 0.1598 0.1372 0.1446 0.1375 0.1215 0.1130 0.1141 0.1142 0.1169 0.1116 0.1080 0.1105 0.1145 0.1154 0.1110 

[TRAIN] Epoch[4](335/1500); Loss: 0.068768; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1150 0.0865 0.0867 0.0843 0.0738 0.0670 0.0689 0.0567 0.0554 0.0548 0.0554 0.0550 0.0564 0.0583 0.0611 0.0649 

[TRAIN] Epoch[4](336/1500); Loss: 0.075303; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1127 0.0632 0.1028 0.1106 0.0914 0.0624 0.0671 0.0637 0.0712 0.0672 0.0608 0.0631 0.0676 0.0692 0.0664 0.0654 

[TRAIN] Epoch[4](337/1500); Loss: 0.081499; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1260 0.1145 0.1103 0.0997 0.0855 0.0738 0.0747 0.0699 0.0701 0.0686 0.0668 0.0673 0.0706 0.0689 0.0682 0.0691 

[TRAIN] Epoch[4](338/1500); Loss: 0.075219; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.2249 0.1072 0.0614 0.0796 0.0786 0.0637 0.0579 0.0590 0.0610 0.0636 0.0572 0.0542 0.0575 0.0606 0.0608 0.0564 

[TRAIN] Epoch[4](339/1500); Loss: 0.143306; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1976 0.1675 0.1762 0.1716 0.1608 0.1410 0.1307 0.1289 0.1272 0.1296 0.1270 0.1237 0.1247 0.1256 0.1315 0.1293 

[TRAIN] Epoch[4](340/1500); Loss: 0.091103; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1411 0.1112 0.1181 0.1098 0.0965 0.0782 0.0830 0.0835 0.0821 0.0795 0.0767 0.0764 0.0817 0.0810 0.0788 0.0799 

[TRAIN] Epoch[4](341/1500); Loss: 0.106656; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2513 0.1561 0.1040 0.1046 0.1161 0.1012 0.0832 0.0845 0.0798 0.0907 0.0891 0.0838 0.0864 0.0884 0.0932 0.0941 

[TRAIN] Epoch[4](342/1500); Loss: 0.147668; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2769 0.2045 0.1817 0.1846 0.1857 0.1637 0.1314 0.1153 0.1160 0.1163 0.1174 0.1133 0.1110 0.1151 0.1142 0.1157 

[TRAIN] Epoch[4](343/1500); Loss: 0.173127; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2498 0.2134 0.2171 0.2047 0.1869 0.1674 0.1493 0.1591 0.1547 0.1506 0.1484 0.1500 0.1538 0.1540 0.1558 0.1550 

[TRAIN] Epoch[4](344/1500); Loss: 0.130935; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1706 0.1544 0.1666 0.1630 0.1502 0.1300 0.1216 0.1161 0.1186 0.1176 0.1136 0.1123 0.1138 0.1161 0.1155 0.1148 

[TRAIN] Epoch[4](345/1500); Loss: 0.082625; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.1333 0.0894 0.0939 0.1009 0.0907 0.0780 0.0795 0.0708 0.0799 0.0767 0.0701 0.0697 0.0700 0.0765 0.0729 0.0697 

[TRAIN] Epoch[4](346/1500); Loss: 0.140776; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2760 0.2295 0.2639 0.2626 0.2307 0.1674 0.0865 0.0718 0.0785 0.0895 0.0881 0.0795 0.0761 0.0787 0.0867 0.0868 

[TRAIN] Epoch[4](347/1500); Loss: 0.157770; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.2265 0.2019 0.2171 0.2169 0.2012 0.1762 0.1502 0.1284 0.1291 0.1302 0.1256 0.1251 0.1250 0.1249 0.1244 0.1216 

[TRAIN] Epoch[4](348/1500); Loss: 0.117287; Backpropagation: 0.0925 sec; Batch: 0.4238 sec
0.2547 0.1722 0.1287 0.1141 0.1156 0.1102 0.1039 0.1036 0.0990 0.0964 0.0971 0.0971 0.0972 0.0967 0.0953 0.0949 

[TRAIN] Epoch[4](349/1500); Loss: 0.126571; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1627 0.1426 0.1565 0.1585 0.1489 0.1274 0.1156 0.1134 0.1127 0.1148 0.1110 0.1095 0.1123 0.1125 0.1145 0.1122 

[TRAIN] Epoch[4](350/1500); Loss: 0.134736; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2084 0.1738 0.1624 0.1707 0.1644 0.1449 0.1238 0.1141 0.1089 0.1198 0.1164 0.1093 0.1037 0.1095 0.1117 0.1139 

[TRAIN] Epoch[4](351/1500); Loss: 0.095816; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1092 0.1067 0.1156 0.1156 0.1051 0.0938 0.0937 0.0915 0.0905 0.0886 0.0866 0.0864 0.0878 0.0879 0.0870 0.0872 

[TRAIN] Epoch[4](352/1500); Loss: 0.074435; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2487 0.1696 0.1195 0.0757 0.0698 0.0592 0.0446 0.0485 0.0538 0.0434 0.0420 0.0404 0.0449 0.0459 0.0439 0.0410 

[TRAIN] Epoch[4](353/1500); Loss: 0.079087; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2135 0.0998 0.0678 0.0859 0.0847 0.0688 0.0631 0.0646 0.0676 0.0691 0.0631 0.0593 0.0658 0.0647 0.0657 0.0620 

[TRAIN] Epoch[4](354/1500); Loss: 0.092813; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1156 0.0959 0.1109 0.1117 0.0999 0.0878 0.0907 0.0879 0.0888 0.0867 0.0833 0.0831 0.0869 0.0876 0.0840 0.0842 

[TRAIN] Epoch[4](355/1500); Loss: 0.163777; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2676 0.2123 0.1906 0.1801 0.1816 0.1706 0.1527 0.1404 0.1415 0.1421 0.1472 0.1438 0.1381 0.1356 0.1361 0.1401 

[TRAIN] Epoch[4](356/1500); Loss: 0.084009; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.2157 0.1444 0.1014 0.0808 0.0841 0.0778 0.0675 0.0638 0.0646 0.0638 0.0632 0.0618 0.0626 0.0630 0.0643 0.0654 

[TRAIN] Epoch[4](357/1500); Loss: 0.081017; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0919 0.0609 0.0678 0.0732 0.0696 0.0714 0.0761 0.0772 0.0790 0.0796 0.0823 0.0872 0.0899 0.0928 0.0964 0.1010 

[TRAIN] Epoch[4](358/1500); Loss: 0.154692; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2378 0.1912 0.1723 0.1619 0.1687 0.1593 0.1453 0.1352 0.1338 0.1351 0.1420 0.1385 0.1354 0.1355 0.1383 0.1450 

[TRAIN] Epoch[4](359/1500); Loss: 0.116676; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1288 0.1256 0.1355 0.1302 0.1213 0.1175 0.1181 0.1120 0.1094 0.1084 0.1093 0.1102 0.1098 0.1097 0.1099 0.1111 

[TRAIN] Epoch[4](360/1500); Loss: 0.089174; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1499 0.1099 0.1095 0.1119 0.1038 0.0887 0.0801 0.0818 0.0760 0.0721 0.0720 0.0732 0.0731 0.0749 0.0747 0.0750 

[TRAIN] Epoch[4](361/1500); Loss: 0.118197; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1579 0.1412 0.1409 0.1328 0.1206 0.1161 0.1154 0.1106 0.1093 0.1070 0.1052 0.1056 0.1064 0.1070 0.1072 0.1079 

[TRAIN] Epoch[4](362/1500); Loss: 0.092202; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1950 0.1230 0.1068 0.1150 0.1130 0.0914 0.0735 0.0705 0.0694 0.0776 0.0744 0.0705 0.0706 0.0722 0.0771 0.0752 

[TRAIN] Epoch[4](363/1500); Loss: 0.066720; Backpropagation: 0.0924 sec; Batch: 0.4246 sec
0.1395 0.0933 0.0781 0.0768 0.0738 0.0639 0.0647 0.0639 0.0499 0.0490 0.0489 0.0497 0.0521 0.0527 0.0554 0.0561 

[TRAIN] Epoch[4](364/1500); Loss: 0.133509; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2531 0.1764 0.1314 0.1343 0.1455 0.1388 0.1246 0.1164 0.1139 0.1152 0.1170 0.1122 0.1100 0.1153 0.1144 0.1177 

[TRAIN] Epoch[4](365/1500); Loss: 0.125332; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2339 0.1760 0.1441 0.1256 0.1324 0.1294 0.1211 0.1077 0.1081 0.1048 0.1065 0.1048 0.1029 0.1024 0.1030 0.1028 

[TRAIN] Epoch[4](366/1500); Loss: 0.161533; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2546 0.2170 0.1950 0.1777 0.1622 0.1525 0.1499 0.1480 0.1455 0.1451 0.1421 0.1402 0.1394 0.1397 0.1383 0.1373 

[TRAIN] Epoch[4](367/1500); Loss: 0.126999; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.3132 0.2184 0.1593 0.1384 0.1422 0.1252 0.0997 0.0957 0.0911 0.0965 0.0993 0.0907 0.0835 0.0864 0.0951 0.0974 

[TRAIN] Epoch[4](368/1500); Loss: 0.073672; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1821 0.0858 0.0797 0.1007 0.0923 0.0688 0.0573 0.0546 0.0566 0.0639 0.0567 0.0519 0.0547 0.0578 0.0595 0.0563 

[TRAIN] Epoch[4](369/1500); Loss: 0.091665; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1811 0.1303 0.1224 0.1131 0.0975 0.0793 0.0712 0.0640 0.0695 0.0679 0.0672 0.0703 0.0758 0.0830 0.0854 0.0886 

[TRAIN] Epoch[4](370/1500); Loss: 0.135115; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1653 0.1679 0.1842 0.1776 0.1633 0.1444 0.1261 0.1214 0.1180 0.1145 0.1131 0.1142 0.1123 0.1129 0.1138 0.1127 

[TRAIN] Epoch[4](371/1500); Loss: 0.114253; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2018 0.1417 0.1204 0.1203 0.1171 0.1066 0.1028 0.1047 0.1027 0.1013 0.1003 0.1003 0.1026 0.1017 0.1009 0.1028 

[TRAIN] Epoch[4](372/1500); Loss: 0.090999; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1375 0.1096 0.1017 0.1061 0.0984 0.0857 0.0804 0.0802 0.0801 0.0815 0.0797 0.0802 0.0817 0.0841 0.0842 0.0849 

[TRAIN] Epoch[4](373/1500); Loss: 0.160915; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2313 0.1911 0.1712 0.1645 0.1624 0.1601 0.1531 0.1491 0.1484 0.1485 0.1481 0.1492 0.1491 0.1494 0.1493 0.1499 

[TRAIN] Epoch[4](374/1500); Loss: 0.148650; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2501 0.1811 0.1519 0.1529 0.1572 0.1438 0.1312 0.1313 0.1291 0.1378 0.1375 0.1328 0.1310 0.1321 0.1387 0.1399 

[TRAIN] Epoch[4](375/1500); Loss: 0.115723; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1765 0.1246 0.1101 0.1219 0.1198 0.1135 0.1031 0.1033 0.1044 0.1097 0.1092 0.1078 0.1079 0.1110 0.1140 0.1147 

[TRAIN] Epoch[4](376/1500); Loss: 0.116079; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2501 0.1841 0.1599 0.1393 0.1216 0.1065 0.0940 0.0912 0.0916 0.0916 0.0886 0.0875 0.0881 0.0884 0.0889 0.0860 

[TRAIN] Epoch[4](377/1500); Loss: 0.104790; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.3991 0.2334 0.1020 0.0614 0.0863 0.0716 0.0509 0.0763 0.0565 0.0911 0.0860 0.0662 0.0630 0.0688 0.0748 0.0892 

[TRAIN] Epoch[4](378/1500); Loss: 0.154601; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2849 0.2122 0.1860 0.1881 0.1784 0.1596 0.1399 0.1279 0.1278 0.1321 0.1253 0.1198 0.1206 0.1242 0.1250 0.1219 

[TRAIN] Epoch[4](379/1500); Loss: 0.112584; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1776 0.1306 0.1258 0.1206 0.1098 0.1014 0.1088 0.1023 0.1023 0.1026 0.1004 0.1018 0.1028 0.1042 0.1043 0.1059 

[TRAIN] Epoch[4](380/1500); Loss: 0.110969; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1467 0.1162 0.1175 0.1190 0.1133 0.1054 0.1096 0.1131 0.1045 0.1044 0.1036 0.1034 0.1042 0.1044 0.1048 0.1053 

[TRAIN] Epoch[4](381/1500); Loss: 0.063303; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.1010 0.0583 0.0501 0.0535 0.0540 0.0548 0.0546 0.0553 0.0561 0.0596 0.0627 0.0630 0.0666 0.0716 0.0749 0.0767 

[TRAIN] Epoch[4](382/1500); Loss: 0.054505; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0492 0.0586 0.0692 0.0606 0.0503 0.0579 0.0569 0.0498 0.0476 0.0489 0.0514 0.0512 0.0526 0.0537 0.0562 0.0581 

[TRAIN] Epoch[4](383/1500); Loss: 0.146726; Backpropagation: 0.0923 sec; Batch: 0.4248 sec
0.2972 0.2249 0.1793 0.1510 0.1550 0.1438 0.1274 0.1231 0.1239 0.1172 0.1199 0.1169 0.1166 0.1177 0.1159 0.1177 

[TRAIN] Epoch[4](384/1500); Loss: 0.135023; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1789 0.1730 0.1732 0.1611 0.1436 0.1276 0.1248 0.1208 0.1191 0.1188 0.1186 0.1177 0.1196 0.1210 0.1213 0.1212 

[TRAIN] Epoch[4](385/1500); Loss: 0.072391; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1099 0.0592 0.0981 0.1037 0.0845 0.0590 0.0724 0.0669 0.0642 0.0609 0.0575 0.0647 0.0657 0.0659 0.0626 0.0630 

[TRAIN] Epoch[4](386/1500); Loss: 0.081893; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1387 0.1104 0.1084 0.0983 0.0825 0.0734 0.0745 0.0716 0.0699 0.0699 0.0678 0.0678 0.0682 0.0690 0.0696 0.0703 

[TRAIN] Epoch[4](387/1500); Loss: 0.079360; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.0962 0.0855 0.0917 0.0907 0.0822 0.0769 0.0809 0.0756 0.0741 0.0724 0.0723 0.0726 0.0734 0.0747 0.0746 0.0760 

[TRAIN] Epoch[4](388/1500); Loss: 0.106388; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.4144 0.2742 0.1590 0.0573 0.0751 0.0871 0.0711 0.0434 0.0671 0.0492 0.0751 0.0712 0.0573 0.0502 0.0800 0.0704 

[TRAIN] Epoch[4](389/1500); Loss: 0.139300; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1675 0.1437 0.1458 0.1467 0.1408 0.1341 0.1313 0.1311 0.1326 0.1349 0.1338 0.1336 0.1354 0.1385 0.1392 0.1397 

[TRAIN] Epoch[4](390/1500); Loss: 0.119272; Backpropagation: 0.0919 sec; Batch: 0.4275 sec
0.1720 0.1360 0.1270 0.1340 0.1332 0.1234 0.1126 0.1091 0.1084 0.1097 0.1081 0.1065 0.1064 0.1067 0.1079 0.1075 

[TRAIN] Epoch[4](391/1500); Loss: 0.091574; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1996 0.1260 0.0968 0.1003 0.0980 0.0847 0.0725 0.0738 0.0715 0.0786 0.0760 0.0733 0.0747 0.0792 0.0811 0.0790 

[TRAIN] Epoch[4](392/1500); Loss: 0.052329; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.0527 0.0769 0.0447 0.0454 0.0466 0.0437 0.0509 0.0546 0.0479 0.0482 0.0497 0.0512 0.0529 0.0553 0.0572 0.0594 

[TRAIN] Epoch[4](393/1500); Loss: 0.101500; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1643 0.1294 0.1180 0.1080 0.1031 0.0938 0.0901 0.0878 0.0892 0.0874 0.0880 0.0901 0.0922 0.0923 0.0938 0.0965 

[TRAIN] Epoch[4](394/1500); Loss: 0.110770; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1722 0.1267 0.1316 0.1319 0.1234 0.1066 0.1035 0.1006 0.1007 0.0989 0.0953 0.0959 0.0965 0.0979 0.0963 0.0943 

[TRAIN] Epoch[4](395/1500); Loss: 0.081516; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0916 0.0971 0.1202 0.1219 0.1051 0.0821 0.0713 0.0704 0.0675 0.0677 0.0656 0.0671 0.0689 0.0689 0.0689 0.0701 

[TRAIN] Epoch[4](396/1500); Loss: 0.114131; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1604 0.1247 0.1245 0.1270 0.1210 0.1104 0.1107 0.1099 0.1058 0.1047 0.1034 0.1038 0.1046 0.1050 0.1047 0.1054 

[TRAIN] Epoch[4](397/1500); Loss: 0.080165; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1541 0.0752 0.0954 0.1081 0.0929 0.0668 0.0691 0.0640 0.0728 0.0726 0.0646 0.0650 0.0746 0.0703 0.0700 0.0672 

[TRAIN] Epoch[4](398/1500); Loss: 0.117457; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1671 0.1231 0.1270 0.1363 0.1321 0.1202 0.1127 0.1108 0.1070 0.1078 0.1064 0.1053 0.1062 0.1058 0.1056 0.1061 

[TRAIN] Epoch[4](399/1500); Loss: 0.085184; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.2956 0.1908 0.1212 0.0745 0.0702 0.0636 0.0532 0.0592 0.0639 0.0531 0.0509 0.0491 0.0524 0.0559 0.0560 0.0531 

[TRAIN] Epoch[4](400/1500); Loss: 0.122568; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2535 0.1766 0.1438 0.1397 0.1329 0.1186 0.1022 0.0985 0.0976 0.1009 0.0994 0.0995 0.0975 0.0998 0.1000 0.1006 

[TRAIN] Epoch[4](401/1500); Loss: 0.137065; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1721 0.1642 0.1669 0.1659 0.1531 0.1384 0.1246 0.1232 0.1255 0.1216 0.1235 0.1252 0.1211 0.1207 0.1219 0.1252 

[TRAIN] Epoch[4](402/1500); Loss: 0.146731; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2912 0.2099 0.1844 0.1853 0.1708 0.1447 0.1230 0.1158 0.1127 0.1180 0.1121 0.1125 0.1196 0.1162 0.1173 0.1143 

[TRAIN] Epoch[4](403/1500); Loss: 0.113762; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2354 0.1702 0.1491 0.1368 0.1250 0.1073 0.1027 0.1042 0.0947 0.0865 0.0843 0.0862 0.0874 0.0846 0.0828 0.0829 

[TRAIN] Epoch[4](404/1500); Loss: 0.072650; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1002 0.0841 0.0798 0.0757 0.0672 0.0602 0.0616 0.0631 0.0646 0.0649 0.0660 0.0685 0.0722 0.0742 0.0779 0.0820 

[TRAIN] Epoch[4](405/1500); Loss: 0.143515; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1746 0.1548 0.1547 0.1515 0.1481 0.1424 0.1419 0.1381 0.1365 0.1350 0.1350 0.1364 0.1370 0.1370 0.1366 0.1369 

[TRAIN] Epoch[4](406/1500); Loss: 0.080517; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1627 0.0998 0.0764 0.0856 0.0794 0.0688 0.0731 0.0748 0.0681 0.0691 0.0675 0.0684 0.0721 0.0735 0.0737 0.0754 

[TRAIN] Epoch[4](407/1500); Loss: 0.094916; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1189 0.1036 0.0956 0.0948 0.0935 0.0929 0.0960 0.0925 0.0897 0.0902 0.0904 0.0915 0.0916 0.0920 0.0924 0.0932 

[TRAIN] Epoch[4](408/1500); Loss: 0.093641; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0931 0.0964 0.1109 0.1084 0.0980 0.0913 0.0939 0.0866 0.0885 0.0877 0.0877 0.0914 0.0899 0.0900 0.0904 0.0940 

[TRAIN] Epoch[4](409/1500); Loss: 0.068941; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.0798 0.0808 0.0756 0.0666 0.0710 0.0852 0.0721 0.0628 0.0607 0.0607 0.0616 0.0627 0.0633 0.0646 0.0669 0.0688 

[TRAIN] Epoch[4](410/1500); Loss: 0.157927; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1954 0.1722 0.1707 0.1677 0.1619 0.1554 0.1549 0.1527 0.1499 0.1492 0.1483 0.1483 0.1486 0.1497 0.1507 0.1513 

[TRAIN] Epoch[4](411/1500); Loss: 0.086983; Backpropagation: 0.0924 sec; Batch: 0.4242 sec
0.2024 0.1084 0.0881 0.1058 0.0986 0.0794 0.0723 0.0764 0.0707 0.0729 0.0680 0.0670 0.0720 0.0715 0.0709 0.0676 

[TRAIN] Epoch[4](412/1500); Loss: 0.127096; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2515 0.1817 0.1464 0.1254 0.1186 0.1129 0.1097 0.1134 0.1085 0.1076 0.1068 0.1079 0.1097 0.1104 0.1113 0.1118 

[TRAIN] Epoch[4](413/1500); Loss: 0.078378; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1465 0.0828 0.1009 0.0985 0.0823 0.0756 0.0773 0.0634 0.0679 0.0643 0.0645 0.0652 0.0656 0.0667 0.0642 0.0684 

[TRAIN] Epoch[4](414/1500); Loss: 0.158109; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2441 0.2064 0.1874 0.1711 0.1569 0.1506 0.1459 0.1437 0.1427 0.1413 0.1393 0.1392 0.1399 0.1407 0.1401 0.1404 

[TRAIN] Epoch[4](415/1500); Loss: 0.111081; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1407 0.1213 0.1228 0.1201 0.1118 0.1078 0.1076 0.1023 0.1022 0.1016 0.1034 0.1043 0.1065 0.1073 0.1073 0.1103 

[TRAIN] Epoch[4](416/1500); Loss: 0.088242; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1243 0.0995 0.0962 0.0938 0.0875 0.0915 0.0909 0.0819 0.0796 0.0794 0.0823 0.0810 0.0797 0.0786 0.0822 0.0835 

[TRAIN] Epoch[4](417/1500); Loss: 0.117602; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2960 0.1664 0.1074 0.1240 0.1234 0.1070 0.0954 0.1003 0.0885 0.0976 0.0924 0.0898 0.0993 0.0971 0.1003 0.0967 

[TRAIN] Epoch[4](418/1500); Loss: 0.138282; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1933 0.1548 0.1545 0.1586 0.1500 0.1363 0.1340 0.1302 0.1276 0.1270 0.1238 0.1240 0.1239 0.1256 0.1245 0.1245 

[TRAIN] Epoch[4](419/1500); Loss: 0.066598; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.0601 0.0801 0.0864 0.0781 0.0653 0.0724 0.0690 0.0592 0.0596 0.0590 0.0602 0.0606 0.0618 0.0632 0.0647 0.0661 

[TRAIN] Epoch[4](420/1500); Loss: 0.160660; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2648 0.2039 0.1704 0.1607 0.1574 0.1543 0.1513 0.1485 0.1428 0.1430 0.1440 0.1462 0.1448 0.1444 0.1460 0.1481 

[TRAIN] Epoch[4](421/1500); Loss: 0.141265; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1756 0.1494 0.1459 0.1441 0.1409 0.1380 0.1407 0.1364 0.1342 0.1343 0.1348 0.1361 0.1360 0.1365 0.1377 0.1395 

[TRAIN] Epoch[4](422/1500); Loss: 0.133323; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2104 0.1681 0.1507 0.1438 0.1367 0.1267 0.1229 0.1223 0.1194 0.1175 0.1184 0.1185 0.1181 0.1185 0.1199 0.1212 

[TRAIN] Epoch[4](423/1500); Loss: 0.090616; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1279 0.1045 0.0991 0.1015 0.0958 0.0864 0.0939 0.0930 0.0813 0.0801 0.0795 0.0813 0.0805 0.0807 0.0813 0.0831 

[TRAIN] Epoch[4](424/1500); Loss: 0.105877; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1851 0.1456 0.1259 0.1071 0.1002 0.1062 0.0969 0.0959 0.0892 0.0875 0.0903 0.0915 0.0927 0.0916 0.0926 0.0958 

[TRAIN] Epoch[4](425/1500); Loss: 0.076747; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1297 0.0925 0.0902 0.0875 0.0780 0.0710 0.0752 0.0688 0.0663 0.0653 0.0658 0.0666 0.0667 0.0667 0.0682 0.0696 

[TRAIN] Epoch[4](426/1500); Loss: 0.074327; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1773 0.1112 0.0770 0.0691 0.0650 0.0626 0.0611 0.0588 0.0588 0.0591 0.0600 0.0625 0.0634 0.0650 0.0677 0.0705 

[TRAIN] Epoch[4](427/1500); Loss: 0.101458; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1830 0.1401 0.1177 0.1040 0.0951 0.0885 0.0853 0.0858 0.0862 0.0873 0.0879 0.0888 0.0906 0.0927 0.0948 0.0956 

[TRAIN] Epoch[4](428/1500); Loss: 0.126081; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3156 0.2149 0.1472 0.1101 0.1113 0.1052 0.0990 0.1064 0.1044 0.0976 0.0978 0.0979 0.1022 0.1037 0.1021 0.1019 

[TRAIN] Epoch[4](429/1500); Loss: 0.042301; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.0440 0.0553 0.0465 0.0358 0.0396 0.0561 0.0501 0.0389 0.0360 0.0354 0.0363 0.0374 0.0392 0.0405 0.0419 0.0438 

[TRAIN] Epoch[4](430/1500); Loss: 0.163543; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2033 0.1800 0.1777 0.1786 0.1722 0.1636 0.1594 0.1580 0.1552 0.1534 0.1525 0.1543 0.1536 0.1519 0.1517 0.1514 

[TRAIN] Epoch[4](431/1500); Loss: 0.089620; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1885 0.1341 0.1141 0.1027 0.0926 0.0837 0.0771 0.0716 0.0699 0.0693 0.0690 0.0700 0.0711 0.0717 0.0730 0.0754 

[TRAIN] Epoch[4](432/1500); Loss: 0.073391; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1002 0.0823 0.0791 0.0716 0.0669 0.0639 0.0699 0.0686 0.0671 0.0658 0.0669 0.0712 0.0721 0.0732 0.0757 0.0798 

[TRAIN] Epoch[4](433/1500); Loss: 0.120482; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2146 0.1497 0.1451 0.1458 0.1336 0.1199 0.1155 0.1042 0.1021 0.0982 0.0977 0.0993 0.0999 0.1009 0.1007 0.1004 

[TRAIN] Epoch[4](434/1500); Loss: 0.113361; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1717 0.1386 0.1292 0.1227 0.1132 0.1060 0.1048 0.1023 0.1013 0.1015 0.1013 0.1028 0.1033 0.1044 0.1048 0.1060 

[TRAIN] Epoch[4](435/1500); Loss: 0.120613; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.2075 0.1430 0.1295 0.1251 0.1179 0.1093 0.1125 0.1119 0.1071 0.1070 0.1053 0.1081 0.1101 0.1109 0.1118 0.1130 

[TRAIN] Epoch[4](436/1500); Loss: 0.102317; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1835 0.1258 0.1004 0.1055 0.1001 0.0936 0.0958 0.0961 0.0904 0.0910 0.0901 0.0914 0.0917 0.0925 0.0939 0.0953 

[TRAIN] Epoch[4](437/1500); Loss: 0.145498; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2138 0.1851 0.1741 0.1590 0.1473 0.1425 0.1381 0.1334 0.1307 0.1291 0.1300 0.1288 0.1285 0.1289 0.1292 0.1294 

[TRAIN] Epoch[4](438/1500); Loss: 0.097952; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2531 0.1516 0.1060 0.1036 0.0979 0.0834 0.0763 0.0882 0.0785 0.0713 0.0710 0.0764 0.0803 0.0752 0.0761 0.0782 

[TRAIN] Epoch[4](439/1500); Loss: 0.145301; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2761 0.1973 0.1947 0.1901 0.1691 0.1397 0.1171 0.1188 0.1141 0.1144 0.1150 0.1175 0.1160 0.1142 0.1150 0.1156 

[TRAIN] Epoch[4](440/1500); Loss: 0.092506; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1257 0.1029 0.1055 0.1048 0.0969 0.0875 0.0954 0.0918 0.0805 0.0795 0.0801 0.0827 0.0851 0.0852 0.0870 0.0897 

[TRAIN] Epoch[4](441/1500); Loss: 0.160601; Backpropagation: 0.0925 sec; Batch: 0.4243 sec
0.2807 0.2185 0.1978 0.1941 0.1845 0.1690 0.1492 0.1367 0.1345 0.1321 0.1283 0.1295 0.1300 0.1300 0.1276 0.1271 

[TRAIN] Epoch[4](442/1500); Loss: 0.108665; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1533 0.1270 0.1159 0.1113 0.1066 0.1043 0.1089 0.1072 0.1008 0.0984 0.0988 0.0996 0.1006 0.1010 0.1020 0.1028 

[TRAIN] Epoch[4](443/1500); Loss: 0.094100; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2065 0.1286 0.0979 0.0970 0.0905 0.0843 0.0867 0.0843 0.0780 0.0778 0.0773 0.0785 0.0783 0.0789 0.0799 0.0811 

[TRAIN] Epoch[4](444/1500); Loss: 0.109999; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2833 0.2004 0.1509 0.1157 0.0908 0.0896 0.0884 0.0856 0.0856 0.0820 0.0798 0.0795 0.0823 0.0825 0.0819 0.0816 

[TRAIN] Epoch[4](445/1500); Loss: 0.112660; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1472 0.1198 0.1148 0.1103 0.1105 0.1100 0.1063 0.1064 0.1060 0.1071 0.1087 0.1090 0.1101 0.1106 0.1118 0.1139 

[TRAIN] Epoch[4](446/1500); Loss: 0.102728; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2475 0.1541 0.1049 0.0962 0.0944 0.0849 0.0858 0.0930 0.0806 0.0821 0.0824 0.0835 0.0868 0.0856 0.0894 0.0923 

[TRAIN] Epoch[4](447/1500); Loss: 0.138732; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1879 0.1655 0.1601 0.1512 0.1424 0.1356 0.1288 0.1261 0.1260 0.1255 0.1264 0.1265 0.1271 0.1288 0.1301 0.1317 

[TRAIN] Epoch[4](448/1500); Loss: 0.094468; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1059 0.0980 0.1032 0.0994 0.0913 0.0869 0.0912 0.0945 0.0909 0.0875 0.0879 0.0916 0.0940 0.0942 0.0959 0.0991 

[TRAIN] Epoch[4](449/1500); Loss: 0.115732; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1722 0.1265 0.1227 0.1196 0.1151 0.1130 0.1168 0.1095 0.1059 0.1057 0.1055 0.1068 0.1071 0.1076 0.1082 0.1097 

[TRAIN] Epoch[4](450/1500); Loss: 0.135991; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2148 0.1565 0.1505 0.1501 0.1413 0.1316 0.1383 0.1392 0.1278 0.1202 0.1182 0.1173 0.1174 0.1175 0.1171 0.1182 

[TRAIN] Epoch[4](451/1500); Loss: 0.075308; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1316 0.0963 0.0890 0.0819 0.0751 0.0725 0.0743 0.0660 0.0632 0.0624 0.0631 0.0652 0.0639 0.0654 0.0671 0.0679 

[TRAIN] Epoch[4](452/1500); Loss: 0.144807; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2522 0.1857 0.1590 0.1473 0.1419 0.1371 0.1371 0.1391 0.1304 0.1253 0.1244 0.1260 0.1289 0.1291 0.1264 0.1271 

[TRAIN] Epoch[4](453/1500); Loss: 0.103132; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1374 0.1171 0.1177 0.1054 0.0967 0.0952 0.0983 0.0964 0.0948 0.0938 0.0957 0.0981 0.0986 0.1002 0.1012 0.1036 

[TRAIN] Epoch[4](454/1500); Loss: 0.106652; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2391 0.1765 0.1361 0.1086 0.0939 0.0903 0.0898 0.0872 0.0896 0.0859 0.0841 0.0835 0.0837 0.0849 0.0858 0.0875 

[TRAIN] Epoch[4](455/1500); Loss: 0.076506; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1167 0.0963 0.0900 0.0772 0.0729 0.0668 0.0690 0.0711 0.0671 0.0664 0.0671 0.0689 0.0706 0.0729 0.0744 0.0768 

[TRAIN] Epoch[4](456/1500); Loss: 0.101096; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2222 0.1595 0.1247 0.1035 0.0907 0.0855 0.0842 0.0824 0.0811 0.0799 0.0802 0.0811 0.0832 0.0842 0.0865 0.0886 

[TRAIN] Epoch[4](457/1500); Loss: 0.124452; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2056 0.1641 0.1416 0.1228 0.1204 0.1191 0.1134 0.1155 0.1102 0.1090 0.1096 0.1105 0.1107 0.1117 0.1133 0.1137 

[TRAIN] Epoch[4](458/1500); Loss: 0.085872; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1466 0.0791 0.0795 0.0776 0.0686 0.0710 0.1063 0.1048 0.0822 0.0753 0.0749 0.0802 0.0805 0.0819 0.0820 0.0835 

[TRAIN] Epoch[4](459/1500); Loss: 0.156191; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2146 0.1854 0.1739 0.1624 0.1541 0.1520 0.1521 0.1469 0.1448 0.1437 0.1425 0.1433 0.1442 0.1453 0.1463 0.1475 

[TRAIN] Epoch[4](460/1500); Loss: 0.060681; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0934 0.0920 0.0837 0.0621 0.0502 0.0584 0.0591 0.0485 0.0487 0.0488 0.0508 0.0530 0.0534 0.0541 0.0564 0.0582 

[TRAIN] Epoch[4](461/1500); Loss: 0.111135; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1747 0.1370 0.1266 0.1201 0.1145 0.1079 0.1061 0.1049 0.0981 0.0971 0.0975 0.0977 0.0989 0.0980 0.0989 0.1002 

[TRAIN] Epoch[4](462/1500); Loss: 0.169017; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2608 0.2025 0.1753 0.1678 0.1635 0.1625 0.1610 0.1571 0.1558 0.1568 0.1562 0.1557 0.1559 0.1582 0.1582 0.1569 

[TRAIN] Epoch[4](463/1500); Loss: 0.149862; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1612 0.1392 0.1407 0.1397 0.1365 0.1353 0.1396 0.1434 0.1466 0.1512 0.1512 0.1539 0.1592 0.1640 0.1666 0.1694 

[TRAIN] Epoch[4](464/1500); Loss: 0.143743; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2389 0.1780 0.1485 0.1383 0.1360 0.1350 0.1364 0.1342 0.1313 0.1322 0.1313 0.1316 0.1310 0.1311 0.1321 0.1338 

[TRAIN] Epoch[4](465/1500); Loss: 0.139535; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2284 0.1745 0.1524 0.1451 0.1402 0.1333 0.1286 0.1272 0.1246 0.1231 0.1237 0.1246 0.1257 0.1257 0.1271 0.1285 

[TRAIN] Epoch[4](466/1500); Loss: 0.073378; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0609 0.0856 0.0955 0.0862 0.0717 0.0682 0.0669 0.0673 0.0684 0.0674 0.0680 0.0703 0.0721 0.0734 0.0751 0.0771 

[TRAIN] Epoch[4](467/1500); Loss: 0.140956; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2318 0.1760 0.1642 0.1520 0.1380 0.1299 0.1306 0.1288 0.1254 0.1252 0.1245 0.1234 0.1243 0.1258 0.1266 0.1287 

[TRAIN] Epoch[4](468/1500); Loss: 0.098837; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1609 0.1220 0.1010 0.0976 0.0873 0.0753 0.0815 0.0803 0.0828 0.0849 0.0867 0.0911 0.0987 0.1066 0.1102 0.1146 

[TRAIN] Epoch[4](469/1500); Loss: 0.158069; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.2569 0.2003 0.1692 0.1607 0.1559 0.1477 0.1435 0.1428 0.1424 0.1434 0.1435 0.1435 0.1437 0.1445 0.1450 0.1461 

[TRAIN] Epoch[4](470/1500); Loss: 0.067277; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0593 0.0782 0.0877 0.0753 0.0627 0.0671 0.0665 0.0591 0.0599 0.0606 0.0627 0.0641 0.0652 0.0665 0.0696 0.0718 

[TRAIN] Epoch[4](471/1500); Loss: 0.081497; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1866 0.1180 0.0945 0.0836 0.0739 0.0656 0.0651 0.0582 0.0607 0.0594 0.0622 0.0663 0.0712 0.0746 0.0789 0.0851 

[TRAIN] Epoch[4](472/1500); Loss: 0.087460; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1178 0.0946 0.0926 0.0856 0.0827 0.0760 0.0772 0.0862 0.0813 0.0830 0.0804 0.0824 0.0877 0.0905 0.0901 0.0912 

[TRAIN] Epoch[4](473/1500); Loss: 0.102988; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1726 0.1136 0.1080 0.1050 0.0969 0.0944 0.1013 0.0918 0.0919 0.0907 0.0924 0.0986 0.0956 0.0975 0.0980 0.0994 

[TRAIN] Epoch[4](474/1500); Loss: 0.154169; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.3010 0.2125 0.1713 0.1581 0.1536 0.1402 0.1328 0.1378 0.1294 0.1329 0.1318 0.1299 0.1311 0.1347 0.1347 0.1350 

[TRAIN] Epoch[4](475/1500); Loss: 0.137791; Backpropagation: 0.0922 sec; Batch: 0.4232 sec
0.1828 0.1717 0.1499 0.1314 0.1223 0.1146 0.1197 0.1227 0.1256 0.1248 0.1263 0.1312 0.1387 0.1443 0.1474 0.1512 

[TRAIN] Epoch[4](476/1500); Loss: 0.149227; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2834 0.2227 0.1829 0.1598 0.1478 0.1395 0.1328 0.1285 0.1248 0.1229 0.1216 0.1218 0.1228 0.1242 0.1257 0.1264 

[TRAIN] Epoch[4](477/1500); Loss: 0.102106; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2322 0.1345 0.1054 0.1072 0.0916 0.0712 0.0889 0.1249 0.1128 0.0888 0.0840 0.0812 0.0794 0.0776 0.0773 0.0767 

[TRAIN] Epoch[4](478/1500); Loss: 0.157222; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2327 0.1916 0.1730 0.1621 0.1574 0.1563 0.1492 0.1439 0.1422 0.1420 0.1433 0.1430 0.1430 0.1438 0.1453 0.1467 

[TRAIN] Epoch[4](479/1500); Loss: 0.093546; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1450 0.1165 0.1128 0.1004 0.0871 0.0926 0.0957 0.0826 0.0809 0.0798 0.0804 0.0825 0.0832 0.0835 0.0855 0.0883 

[TRAIN] Epoch[4](480/1500); Loss: 0.152568; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.3073 0.2377 0.1890 0.1605 0.1457 0.1378 0.1324 0.1290 0.1272 0.1253 0.1239 0.1233 0.1239 0.1247 0.1258 0.1276 

[TRAIN] Epoch[4](481/1500); Loss: 0.139386; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2517 0.1850 0.1521 0.1358 0.1297 0.1279 0.1256 0.1241 0.1242 0.1236 0.1230 0.1237 0.1247 0.1258 0.1259 0.1274 

[TRAIN] Epoch[4](482/1500); Loss: 0.180883; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3866 0.2643 0.2498 0.2680 0.2429 0.1787 0.1095 0.1259 0.1693 0.1471 0.1256 0.1234 0.1206 0.1264 0.1277 0.1282 

[TRAIN] Epoch[4](483/1500); Loss: 0.086635; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1543 0.0850 0.0979 0.0974 0.0826 0.0755 0.0983 0.0802 0.0729 0.0733 0.0734 0.0785 0.0766 0.0784 0.0794 0.0823 

[TRAIN] Epoch[4](484/1500); Loss: 0.072597; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1907 0.0885 0.0751 0.0727 0.0620 0.0562 0.0743 0.0614 0.0581 0.0569 0.0563 0.0596 0.0602 0.0616 0.0623 0.0657 

[TRAIN] Epoch[4](485/1500); Loss: 0.078457; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1105 0.0907 0.0918 0.0858 0.0772 0.0741 0.0736 0.0709 0.0717 0.0706 0.0697 0.0712 0.0731 0.0738 0.0747 0.0759 

[TRAIN] Epoch[4](486/1500); Loss: 0.170173; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2639 0.1931 0.1799 0.1875 0.1736 0.1503 0.1433 0.1502 0.1526 0.1512 0.1555 0.1574 0.1600 0.1642 0.1682 0.1717 

[TRAIN] Epoch[4](487/1500); Loss: 0.121610; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1837 0.1485 0.1333 0.1231 0.1177 0.1136 0.1136 0.1128 0.1101 0.1098 0.1111 0.1115 0.1122 0.1138 0.1144 0.1166 

[TRAIN] Epoch[4](488/1500); Loss: 0.102778; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1302 0.1060 0.1055 0.1028 0.1001 0.1008 0.1029 0.0989 0.0971 0.0978 0.0980 0.0986 0.0996 0.1004 0.1020 0.1038 

[TRAIN] Epoch[4](489/1500); Loss: 0.078806; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.2375 0.1267 0.0815 0.0708 0.0611 0.0565 0.0669 0.0616 0.0601 0.0583 0.0576 0.0630 0.0624 0.0660 0.0645 0.0665 

[TRAIN] Epoch[4](490/1500); Loss: 0.139870; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2476 0.1884 0.1561 0.1429 0.1360 0.1310 0.1278 0.1259 0.1226 0.1212 0.1217 0.1219 0.1227 0.1231 0.1244 0.1246 

[TRAIN] Epoch[4](491/1500); Loss: 0.055301; Backpropagation: 0.0931 sec; Batch: 0.4254 sec
0.1072 0.0646 0.0537 0.0490 0.0474 0.0574 0.0569 0.0477 0.0458 0.0461 0.0473 0.0486 0.0500 0.0522 0.0545 0.0563 

[TRAIN] Epoch[4](492/1500); Loss: 0.169878; Backpropagation: 0.0932 sec; Batch: 0.4253 sec
0.3559 0.2420 0.2299 0.2458 0.2252 0.1723 0.1109 0.1289 0.1612 0.1324 0.1174 0.1164 0.1165 0.1228 0.1201 0.1204 

[TRAIN] Epoch[4](493/1500); Loss: 0.210000; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.3227 0.2519 0.2373 0.2472 0.2350 0.2011 0.1811 0.2069 0.1980 0.1840 0.1797 0.1784 0.1792 0.1837 0.1861 0.1877 

[TRAIN] Epoch[4](494/1500); Loss: 0.115849; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.4114 0.2509 0.1296 0.0623 0.0918 0.0859 0.0738 0.0786 0.0763 0.0807 0.0888 0.0815 0.0790 0.0837 0.0878 0.0915 

[TRAIN] Epoch[4](495/1500); Loss: 0.085009; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2999 0.1524 0.0723 0.0719 0.0752 0.0590 0.0556 0.0627 0.0560 0.0695 0.0613 0.0540 0.0644 0.0646 0.0736 0.0678 

[TRAIN] Epoch[4](496/1500); Loss: 0.069864; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1452 0.0902 0.0805 0.0776 0.0676 0.0510 0.0706 0.0916 0.0668 0.0548 0.0500 0.0493 0.0532 0.0560 0.0577 0.0558 

[TRAIN] Epoch[4](497/1500); Loss: 0.126579; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1907 0.1421 0.1348 0.1328 0.1282 0.1187 0.1203 0.1180 0.1163 0.1134 0.1151 0.1192 0.1183 0.1198 0.1179 0.1195 

[TRAIN] Epoch[4](498/1500); Loss: 0.139155; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2019 0.1570 0.1502 0.1467 0.1391 0.1307 0.1296 0.1300 0.1287 0.1282 0.1282 0.1290 0.1298 0.1322 0.1324 0.1327 

[TRAIN] Epoch[4](499/1500); Loss: 0.133946; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1788 0.1455 0.1419 0.1422 0.1373 0.1333 0.1365 0.1310 0.1245 0.1243 0.1231 0.1229 0.1249 0.1254 0.1254 0.1261 

[TRAIN] Epoch[4](500/1500); Loss: 0.166821; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.3912 0.2598 0.2369 0.2521 0.2289 0.1680 0.1002 0.1158 0.1412 0.1151 0.1078 0.1079 0.1105 0.1186 0.1075 0.1076 

[TRAIN] Epoch[4](501/1500); Loss: 0.122629; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1815 0.1381 0.1260 0.1242 0.1199 0.1139 0.1162 0.1171 0.1163 0.1151 0.1128 0.1142 0.1152 0.1183 0.1176 0.1156 

[TRAIN] Epoch[4](502/1500); Loss: 0.141750; Backpropagation: 0.1000 sec; Batch: 0.4429 sec
0.3109 0.2386 0.1867 0.1435 0.1236 0.1195 0.1134 0.1122 0.1163 0.1155 0.1150 0.1127 0.1124 0.1141 0.1177 0.1160 

[TRAIN] Epoch[4](503/1500); Loss: 0.119667; Backpropagation: 0.0928 sec; Batch: 0.4249 sec
0.2555 0.1826 0.1451 0.1177 0.1152 0.1055 0.1001 0.0993 0.1003 0.1006 0.0961 0.0944 0.0991 0.1013 0.1028 0.0991 

[TRAIN] Epoch[4](504/1500); Loss: 0.096954; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2012 0.1279 0.1058 0.0990 0.0914 0.0797 0.0792 0.0751 0.0833 0.0835 0.0804 0.0813 0.0860 0.0923 0.0921 0.0930 

[TRAIN] Epoch[4](505/1500); Loss: 0.113102; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1467 0.1170 0.1303 0.1245 0.1116 0.1068 0.1122 0.1059 0.1034 0.1023 0.1045 0.1067 0.1097 0.1089 0.1075 0.1117 

[TRAIN] Epoch[4](506/1500); Loss: 0.132362; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2032 0.1851 0.1707 0.1493 0.1290 0.1255 0.1219 0.1160 0.1153 0.1140 0.1131 0.1130 0.1133 0.1158 0.1159 0.1166 

[TRAIN] Epoch[4](507/1500); Loss: 0.195026; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2657 0.2166 0.2111 0.2094 0.2004 0.1892 0.1820 0.1782 0.1820 0.1835 0.1814 0.1799 0.1801 0.1857 0.1880 0.1872 

[TRAIN] Epoch[4](508/1500); Loss: 0.138332; Backpropagation: 0.0915 sec; Batch: 0.4229 sec
0.2100 0.1651 0.1548 0.1536 0.1437 0.1266 0.1202 0.1221 0.1200 0.1221 0.1236 0.1242 0.1272 0.1303 0.1331 0.1366 

[TRAIN] Epoch[4](509/1500); Loss: 0.116101; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.2350 0.1470 0.1237 0.1321 0.1201 0.1036 0.1025 0.1024 0.0976 0.0994 0.0952 0.0964 0.1004 0.1005 0.1025 0.0993 

[TRAIN] Epoch[4](510/1500); Loss: 0.111422; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1866 0.1187 0.1078 0.1121 0.1052 0.0982 0.1105 0.1073 0.1020 0.1030 0.1024 0.1019 0.1043 0.1064 0.1077 0.1088 

[TRAIN] Epoch[4](511/1500); Loss: 0.135624; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2181 0.1585 0.1508 0.1490 0.1366 0.1234 0.1317 0.1317 0.1208 0.1192 0.1190 0.1221 0.1234 0.1222 0.1213 0.1224 

[TRAIN] Epoch[4](512/1500); Loss: 0.051854; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.0559 0.0674 0.0761 0.0658 0.0487 0.0474 0.0425 0.0445 0.0452 0.0444 0.0434 0.0458 0.0491 0.0482 0.0504 0.0547 

[TRAIN] Epoch[4](513/1500); Loss: 0.090050; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1184 0.0942 0.0933 0.0880 0.0864 0.0946 0.0912 0.0853 0.0836 0.0835 0.0844 0.0855 0.0865 0.0871 0.0892 0.0894 

[TRAIN] Epoch[4](514/1500); Loss: 0.126252; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2399 0.1552 0.1301 0.1368 0.1290 0.1187 0.1174 0.1158 0.1116 0.1098 0.1090 0.1076 0.1083 0.1106 0.1116 0.1086 

[TRAIN] Epoch[4](515/1500); Loss: 0.092805; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1887 0.1295 0.1194 0.1156 0.1022 0.0839 0.0796 0.0851 0.0803 0.0716 0.0694 0.0701 0.0708 0.0727 0.0730 0.0728 

[TRAIN] Epoch[4](516/1500); Loss: 0.046089; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0298 0.0617 0.0606 0.0454 0.0494 0.0552 0.0448 0.0389 0.0382 0.0392 0.0405 0.0425 0.0453 0.0470 0.0485 0.0505 

[TRAIN] Epoch[4](517/1500); Loss: 0.108210; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1533 0.1118 0.1197 0.1234 0.1123 0.0989 0.1116 0.1123 0.1019 0.0980 0.0954 0.0961 0.0986 0.1016 0.0994 0.0969 

[TRAIN] Epoch[4](518/1500); Loss: 0.084700; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1914 0.1391 0.1063 0.0818 0.0725 0.0671 0.0668 0.0694 0.0665 0.0679 0.0675 0.0675 0.0705 0.0729 0.0734 0.0747 

[TRAIN] Epoch[4](519/1500); Loss: 0.081162; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1060 0.0923 0.0949 0.0857 0.0718 0.0798 0.0888 0.0707 0.0702 0.0706 0.0714 0.0762 0.0757 0.0796 0.0800 0.0850 

[TRAIN] Epoch[4](520/1500); Loss: 0.118099; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1891 0.1456 0.1236 0.1100 0.1077 0.1059 0.1067 0.1106 0.1077 0.1075 0.1093 0.1115 0.1122 0.1128 0.1131 0.1163 

[TRAIN] Epoch[4](521/1500); Loss: 0.216601; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.3655 0.2718 0.2572 0.2749 0.2575 0.2108 0.1670 0.1852 0.1911 0.1812 0.1788 0.1793 0.1829 0.1862 0.1886 0.1878 

[TRAIN] Epoch[4](522/1500); Loss: 0.079963; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.2236 0.1113 0.0781 0.0718 0.0673 0.0604 0.0698 0.0630 0.0656 0.0642 0.0609 0.0663 0.0662 0.0718 0.0708 0.0682 

[TRAIN] Epoch[4](523/1500); Loss: 0.121862; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1657 0.1214 0.1238 0.1282 0.1188 0.1092 0.1154 0.1134 0.1174 0.1156 0.1129 0.1163 0.1210 0.1246 0.1227 0.1236 

[TRAIN] Epoch[4](524/1500); Loss: 0.121716; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2938 0.1481 0.0976 0.1355 0.1270 0.1064 0.0967 0.0992 0.0981 0.1140 0.1069 0.0958 0.1022 0.0969 0.1152 0.1141 

[TRAIN] Epoch[4](525/1500); Loss: 0.123406; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1697 0.1367 0.1259 0.1235 0.1224 0.1210 0.1186 0.1167 0.1155 0.1156 0.1166 0.1180 0.1169 0.1178 0.1190 0.1205 

[TRAIN] Epoch[4](526/1500); Loss: 0.091994; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.2687 0.1510 0.0916 0.0821 0.0873 0.0742 0.0656 0.0651 0.0653 0.0730 0.0675 0.0678 0.0737 0.0779 0.0826 0.0785 

[TRAIN] Epoch[4](527/1500); Loss: 0.089733; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.3039 0.1607 0.1131 0.0750 0.0818 0.0684 0.0712 0.0561 0.0653 0.0617 0.0622 0.0604 0.0642 0.0591 0.0641 0.0684 

[TRAIN] Epoch[4](528/1500); Loss: 0.106578; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1435 0.1321 0.1373 0.1274 0.1112 0.1006 0.1022 0.0940 0.0968 0.0940 0.0927 0.0923 0.0951 0.0963 0.0943 0.0953 

[TRAIN] Epoch[4](529/1500); Loss: 0.107457; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1443 0.1271 0.1261 0.1165 0.1061 0.1039 0.1043 0.0981 0.0980 0.0964 0.0968 0.0983 0.0999 0.1003 0.1010 0.1022 

[TRAIN] Epoch[4](530/1500); Loss: 0.174218; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.3718 0.2567 0.2414 0.2586 0.2366 0.1800 0.1161 0.1333 0.1465 0.1244 0.1166 0.1166 0.1215 0.1270 0.1205 0.1200 

[TRAIN] Epoch[4](531/1500); Loss: 0.114454; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2004 0.1473 0.1343 0.1283 0.1195 0.1098 0.1083 0.1006 0.0999 0.0980 0.0960 0.0961 0.0960 0.0984 0.0990 0.0993 

[TRAIN] Epoch[4](532/1500); Loss: 0.127241; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2637 0.1810 0.1428 0.1238 0.1192 0.1141 0.1139 0.1132 0.1068 0.1077 0.1072 0.1077 0.1072 0.1083 0.1098 0.1092 

[TRAIN] Epoch[4](533/1500); Loss: 0.120514; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2464 0.1706 0.1324 0.1199 0.1144 0.1054 0.1033 0.1126 0.1090 0.1009 0.0989 0.1001 0.1039 0.1042 0.1029 0.1032 

[TRAIN] Epoch[4](534/1500); Loss: 0.087162; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1825 0.0966 0.0928 0.0913 0.0833 0.0808 0.0933 0.0763 0.0758 0.0723 0.0713 0.0744 0.0764 0.0755 0.0744 0.0775 

[TRAIN] Epoch[4](535/1500); Loss: 0.085834; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1814 0.1427 0.1124 0.0853 0.0742 0.0687 0.0671 0.0695 0.0685 0.0691 0.0693 0.0698 0.0722 0.0732 0.0741 0.0758 

[TRAIN] Epoch[4](536/1500); Loss: 0.122125; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.2624 0.1751 0.1630 0.1759 0.1565 0.1154 0.0865 0.1104 0.1037 0.0889 0.0862 0.0840 0.0864 0.0883 0.0852 0.0860 

[TRAIN] Epoch[4](537/1500); Loss: 0.077125; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1293 0.0958 0.0892 0.0843 0.0771 0.0736 0.0729 0.0665 0.0670 0.0659 0.0662 0.0683 0.0682 0.0682 0.0697 0.0718 

[TRAIN] Epoch[4](538/1500); Loss: 0.098332; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2417 0.1426 0.0966 0.0949 0.0908 0.0830 0.0830 0.0803 0.0834 0.0816 0.0797 0.0826 0.0823 0.0848 0.0819 0.0842 

[TRAIN] Epoch[4](539/1500); Loss: 0.126958; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1432 0.1371 0.1374 0.1315 0.1282 0.1258 0.1235 0.1227 0.1223 0.1223 0.1217 0.1220 0.1231 0.1231 0.1232 0.1242 

[TRAIN] Epoch[4](540/1500); Loss: 0.061407; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.0734 0.0853 0.0880 0.0683 0.0612 0.0542 0.0509 0.0545 0.0546 0.0528 0.0526 0.0542 0.0560 0.0572 0.0584 0.0608 

[TRAIN] Epoch[4](541/1500); Loss: 0.078286; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1161 0.0731 0.0735 0.0724 0.0658 0.0638 0.0695 0.0708 0.0746 0.0726 0.0732 0.0786 0.0844 0.0875 0.0860 0.0907 

[TRAIN] Epoch[4](542/1500); Loss: 0.131708; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.3115 0.1569 0.0848 0.1455 0.1418 0.1224 0.0960 0.0998 0.0910 0.1378 0.1357 0.1196 0.1006 0.1052 0.1134 0.1455 

[TRAIN] Epoch[4](543/1500); Loss: 0.105546; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2071 0.1088 0.1061 0.1243 0.1117 0.0931 0.0949 0.0942 0.0963 0.0946 0.0887 0.0881 0.0945 0.0962 0.0970 0.0931 

[TRAIN] Epoch[4](544/1500); Loss: 0.107133; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1796 0.1280 0.1119 0.1028 0.0911 0.0841 0.0846 0.0836 0.0913 0.0933 0.0977 0.1011 0.1064 0.1140 0.1186 0.1258 

[TRAIN] Epoch[4](545/1500); Loss: 0.136239; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1748 0.1623 0.1558 0.1450 0.1380 0.1342 0.1283 0.1251 0.1245 0.1256 0.1259 0.1260 0.1278 0.1288 0.1281 0.1295 

[TRAIN] Epoch[4](546/1500); Loss: 0.114421; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1601 0.1398 0.1462 0.1375 0.1216 0.1081 0.1038 0.1007 0.1035 0.0993 0.0987 0.1008 0.1026 0.1025 0.1014 0.1041 

[TRAIN] Epoch[4](547/1500); Loss: 0.105831; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1814 0.1304 0.1198 0.1274 0.1195 0.1068 0.0876 0.0907 0.0963 0.0890 0.0884 0.0891 0.0894 0.0909 0.0924 0.0942 

[TRAIN] Epoch[4](548/1500); Loss: 0.139763; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2112 0.1696 0.1626 0.1618 0.1510 0.1382 0.1295 0.1228 0.1252 0.1227 0.1211 0.1210 0.1217 0.1258 0.1263 0.1258 

[TRAIN] Epoch[4](549/1500); Loss: 0.121463; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2468 0.1679 0.1306 0.1157 0.1122 0.1089 0.1107 0.1103 0.1046 0.1034 0.1035 0.1039 0.1046 0.1056 0.1063 0.1083 

[TRAIN] Epoch[4](550/1500); Loss: 0.136512; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2196 0.1717 0.1540 0.1401 0.1375 0.1278 0.1210 0.1183 0.1220 0.1245 0.1218 0.1203 0.1213 0.1275 0.1296 0.1272 

[TRAIN] Epoch[4](551/1500); Loss: 0.100837; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1168 0.1103 0.1098 0.1035 0.0974 0.0965 0.0933 0.0946 0.0946 0.0946 0.0956 0.0982 0.0988 0.1005 0.1028 0.1062 

[TRAIN] Epoch[4](552/1500); Loss: 0.156065; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1812 0.1702 0.1694 0.1650 0.1601 0.1565 0.1532 0.1499 0.1490 0.1481 0.1474 0.1480 0.1489 0.1499 0.1494 0.1509 

[TRAIN] Epoch[4](553/1500); Loss: 0.083118; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1809 0.1247 0.1038 0.0886 0.0788 0.0720 0.0696 0.0701 0.0686 0.0667 0.0654 0.0669 0.0687 0.0680 0.0678 0.0694 

[TRAIN] Epoch[4](554/1500); Loss: 0.138380; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2971 0.1633 0.1145 0.1471 0.1405 0.1223 0.1108 0.1105 0.1095 0.1380 0.1340 0.1224 0.1181 0.1124 0.1238 0.1496 

[TRAIN] Epoch[4](555/1500); Loss: 0.124934; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1685 0.1277 0.1346 0.1347 0.1274 0.1187 0.1215 0.1183 0.1182 0.1169 0.1155 0.1176 0.1188 0.1211 0.1198 0.1194 

[TRAIN] Epoch[4](556/1500); Loss: 0.116735; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1650 0.1334 0.1260 0.1275 0.1213 0.1154 0.1082 0.1057 0.1060 0.1061 0.1071 0.1076 0.1087 0.1092 0.1096 0.1110 

[TRAIN] Epoch[4](557/1500); Loss: 0.144100; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2016 0.1580 0.1526 0.1556 0.1479 0.1392 0.1347 0.1341 0.1347 0.1335 0.1328 0.1335 0.1350 0.1362 0.1374 0.1389 

[TRAIN] Epoch[4](558/1500); Loss: 0.111293; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1867 0.1408 0.1263 0.1197 0.1126 0.1059 0.1009 0.0988 0.0990 0.0993 0.0986 0.0980 0.0979 0.0990 0.0989 0.0983 

[TRAIN] Epoch[4](559/1500); Loss: 0.086470; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1068 0.1020 0.1062 0.0981 0.0871 0.0850 0.0817 0.0795 0.0786 0.0757 0.0763 0.0794 0.0806 0.0812 0.0817 0.0837 

[TRAIN] Epoch[4](560/1500); Loss: 0.132954; Backpropagation: 0.0928 sec; Batch: 0.4248 sec
0.1780 0.1527 0.1548 0.1564 0.1472 0.1378 0.1282 0.1202 0.1176 0.1156 0.1158 0.1179 0.1197 0.1195 0.1216 0.1242 

[TRAIN] Epoch[4](561/1500); Loss: 0.150680; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2257 0.1779 0.1609 0.1551 0.1472 0.1418 0.1412 0.1388 0.1401 0.1384 0.1380 0.1386 0.1411 0.1409 0.1414 0.1438 

[TRAIN] Epoch[4](562/1500); Loss: 0.155780; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2782 0.2018 0.1640 0.1677 0.1639 0.1511 0.1372 0.1329 0.1298 0.1386 0.1366 0.1335 0.1336 0.1374 0.1440 0.1422 

[TRAIN] Epoch[4](563/1500); Loss: 0.091246; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.3266 0.2101 0.1291 0.0700 0.0682 0.0636 0.0559 0.0581 0.0578 0.0598 0.0568 0.0530 0.0577 0.0643 0.0663 0.0626 

[TRAIN] Epoch[4](564/1500); Loss: 0.070245; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0842 0.0814 0.0826 0.0721 0.0647 0.0684 0.0624 0.0641 0.0625 0.0623 0.0646 0.0681 0.0677 0.0689 0.0731 0.0768 

[TRAIN] Epoch[4](565/1500); Loss: 0.093740; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1342 0.1275 0.1166 0.0946 0.0926 0.0865 0.0848 0.0916 0.0872 0.0847 0.0802 0.0805 0.0843 0.0883 0.0843 0.0819 

[TRAIN] Epoch[4](566/1500); Loss: 0.099956; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2193 0.1381 0.1034 0.1027 0.0978 0.0839 0.0762 0.0756 0.0854 0.0851 0.0801 0.0791 0.0863 0.0987 0.0965 0.0911 

[TRAIN] Epoch[4](567/1500); Loss: 0.113716; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2198 0.1412 0.1108 0.1052 0.1042 0.0954 0.0878 0.0898 0.0965 0.1043 0.1031 0.1019 0.1060 0.1149 0.1195 0.1193 

[TRAIN] Epoch[4](568/1500); Loss: 0.091723; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2123 0.1260 0.0971 0.0936 0.0860 0.0734 0.0717 0.0700 0.0817 0.0784 0.0721 0.0716 0.0805 0.0880 0.0840 0.0810 

[TRAIN] Epoch[4](569/1500); Loss: 0.144197; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1845 0.1603 0.1606 0.1615 0.1537 0.1474 0.1416 0.1359 0.1325 0.1311 0.1309 0.1318 0.1336 0.1335 0.1330 0.1352 

[TRAIN] Epoch[4](570/1500); Loss: 0.157477; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2450 0.1951 0.1797 0.1623 0.1541 0.1520 0.1451 0.1439 0.1405 0.1410 0.1425 0.1435 0.1434 0.1427 0.1434 0.1455 

[TRAIN] Epoch[4](571/1500); Loss: 0.175709; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2833 0.2290 0.2126 0.2177 0.2092 0.1950 0.1762 0.1593 0.1453 0.1424 0.1409 0.1411 0.1414 0.1403 0.1384 0.1393 

[TRAIN] Epoch[4](572/1500); Loss: 0.114917; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1590 0.1303 0.1272 0.1228 0.1165 0.1118 0.1116 0.1080 0.1072 0.1064 0.1058 0.1059 0.1058 0.1066 0.1068 0.1069 

[TRAIN] Epoch[4](573/1500); Loss: 0.109680; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.3100 0.2218 0.1655 0.1051 0.0921 0.0815 0.0716 0.0678 0.0742 0.0819 0.0779 0.0695 0.0684 0.0821 0.0949 0.0908 

[TRAIN] Epoch[4](574/1500); Loss: 0.056149; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0988 0.0695 0.0632 0.0553 0.0530 0.0614 0.0550 0.0478 0.0478 0.0473 0.0481 0.0486 0.0497 0.0494 0.0509 0.0526 

[TRAIN] Epoch[4](575/1500); Loss: 0.097115; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2004 0.1421 0.1221 0.1047 0.0959 0.0901 0.0863 0.0810 0.0797 0.0773 0.0762 0.0780 0.0802 0.0788 0.0785 0.0826 

[TRAIN] Epoch[4](576/1500); Loss: 0.105219; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2632 0.1850 0.1227 0.1070 0.0999 0.0891 0.0819 0.0865 0.0811 0.0790 0.0777 0.0813 0.0832 0.0835 0.0811 0.0814 

[TRAIN] Epoch[4](577/1500); Loss: 0.141595; Backpropagation: 0.0924 sec; Batch: 0.4241 sec
0.2475 0.1986 0.1660 0.1430 0.1335 0.1289 0.1249 0.1235 0.1251 0.1259 0.1245 0.1225 0.1227 0.1256 0.1266 0.1268 

[TRAIN] Epoch[4](578/1500); Loss: 0.143897; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2241 0.1859 0.1662 0.1519 0.1433 0.1327 0.1331 0.1303 0.1316 0.1290 0.1263 0.1279 0.1300 0.1330 0.1294 0.1275 

[TRAIN] Epoch[4](579/1500); Loss: 0.087675; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1454 0.1116 0.1028 0.0968 0.0840 0.0789 0.0763 0.0750 0.0757 0.0751 0.0745 0.0772 0.0791 0.0809 0.0826 0.0869 

[TRAIN] Epoch[4](580/1500); Loss: 0.071408; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1124 0.0864 0.0867 0.0827 0.0746 0.0729 0.0664 0.0633 0.0636 0.0617 0.0609 0.0604 0.0614 0.0619 0.0625 0.0648 

[TRAIN] Epoch[4](581/1500); Loss: 0.079622; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0993 0.0938 0.0920 0.0857 0.0769 0.0762 0.0754 0.0752 0.0732 0.0725 0.0731 0.0742 0.0756 0.0754 0.0763 0.0794 

[TRAIN] Epoch[4](582/1500); Loss: 0.081671; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1009 0.0887 0.0958 0.0900 0.0791 0.0776 0.0789 0.0770 0.0767 0.0752 0.0748 0.0770 0.0791 0.0783 0.0778 0.0800 

[TRAIN] Epoch[4](583/1500); Loss: 0.122470; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1717 0.1481 0.1472 0.1352 0.1213 0.1175 0.1146 0.1118 0.1090 0.1076 0.1101 0.1126 0.1140 0.1120 0.1118 0.1149 

[TRAIN] Epoch[4](584/1500); Loss: 0.076760; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2107 0.1272 0.0843 0.0760 0.0719 0.0642 0.0606 0.0627 0.0598 0.0588 0.0565 0.0574 0.0581 0.0588 0.0593 0.0619 

[TRAIN] Epoch[4](585/1500); Loss: 0.191519; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.3073 0.2182 0.2086 0.2436 0.2306 0.2015 0.1658 0.1462 0.1459 0.1535 0.1612 0.1696 0.1709 0.1740 0.1793 0.1882 

[TRAIN] Epoch[4](586/1500); Loss: 0.135471; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1954 0.1693 0.1674 0.1760 0.1628 0.1502 0.1300 0.1150 0.1101 0.1100 0.1135 0.1140 0.1117 0.1108 0.1142 0.1171 

[TRAIN] Epoch[4](587/1500); Loss: 0.110038; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1620 0.1316 0.1329 0.1259 0.1159 0.1068 0.1045 0.1004 0.1014 0.0991 0.0970 0.0962 0.0978 0.0958 0.0959 0.0976 

[TRAIN] Epoch[4](588/1500); Loss: 0.122969; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1681 0.1412 0.1361 0.1340 0.1270 0.1201 0.1165 0.1154 0.1145 0.1126 0.1128 0.1129 0.1135 0.1135 0.1140 0.1151 

[TRAIN] Epoch[4](589/1500); Loss: 0.156941; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1972 0.1817 0.1765 0.1667 0.1582 0.1553 0.1499 0.1471 0.1467 0.1463 0.1480 0.1479 0.1473 0.1466 0.1468 0.1488 

[TRAIN] Epoch[4](590/1500); Loss: 0.147714; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2134 0.1740 0.1616 0.1610 0.1557 0.1482 0.1412 0.1364 0.1335 0.1336 0.1344 0.1340 0.1334 0.1338 0.1342 0.1350 

[TRAIN] Epoch[4](591/1500); Loss: 0.109378; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2061 0.1512 0.1295 0.1151 0.1065 0.1010 0.0975 0.0938 0.0931 0.0919 0.0902 0.0916 0.0952 0.0970 0.0947 0.0958 

[TRAIN] Epoch[4](592/1500); Loss: 0.221142; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.3319 0.2653 0.2534 0.2765 0.2689 0.2487 0.2155 0.1856 0.1874 0.1890 0.1853 0.1854 0.1833 0.1842 0.1883 0.1897 

[TRAIN] Epoch[4](593/1500); Loss: 0.092144; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1478 0.1086 0.0964 0.1012 0.0958 0.0870 0.0832 0.0825 0.0831 0.0815 0.0814 0.0826 0.0849 0.0842 0.0853 0.0888 

[TRAIN] Epoch[4](594/1500); Loss: 0.121479; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1569 0.1268 0.1288 0.1321 0.1263 0.1209 0.1173 0.1197 0.1160 0.1136 0.1120 0.1133 0.1150 0.1147 0.1154 0.1148 

[TRAIN] Epoch[4](595/1500); Loss: 0.112004; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.1929 0.1273 0.1138 0.1229 0.1180 0.1102 0.1036 0.0987 0.0997 0.1009 0.0996 0.0994 0.1000 0.1008 0.1020 0.1023 

[TRAIN] Epoch[4](596/1500); Loss: 0.078673; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1175 0.0932 0.0916 0.0890 0.0808 0.0796 0.0740 0.0732 0.0711 0.0694 0.0694 0.0696 0.0697 0.0691 0.0703 0.0712 

[TRAIN] Epoch[4](597/1500); Loss: 0.111940; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2380 0.1327 0.1048 0.1251 0.1132 0.0962 0.0885 0.0926 0.0992 0.1044 0.0965 0.0952 0.0922 0.1023 0.1058 0.1044 

[TRAIN] Epoch[4](598/1500); Loss: 0.091067; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1451 0.1137 0.1074 0.1034 0.0975 0.0948 0.0829 0.0768 0.0789 0.0775 0.0796 0.0793 0.0800 0.0790 0.0800 0.0811 

[TRAIN] Epoch[4](599/1500); Loss: 0.143267; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1546 0.1499 0.1528 0.1478 0.1426 0.1392 0.1399 0.1389 0.1406 0.1390 0.1389 0.1398 0.1409 0.1422 0.1424 0.1427 

[TRAIN] Epoch[4](600/1500); Loss: 0.117316; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1420 0.1300 0.1319 0.1307 0.1228 0.1177 0.1116 0.1121 0.1118 0.1104 0.1092 0.1091 0.1098 0.1086 0.1089 0.1103 

[TRAIN] Epoch[4](601/1500); Loss: 0.109240; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2471 0.1394 0.1060 0.1332 0.1255 0.1051 0.0845 0.0802 0.0875 0.1008 0.0913 0.0797 0.0814 0.0862 0.1025 0.0974 

[TRAIN] Epoch[4](602/1500); Loss: 0.155753; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2067 0.1859 0.1785 0.1662 0.1553 0.1538 0.1498 0.1441 0.1429 0.1423 0.1447 0.1447 0.1434 0.1432 0.1438 0.1466 

[TRAIN] Epoch[4](603/1500); Loss: 0.111841; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2019 0.1185 0.1106 0.1391 0.1309 0.1146 0.0946 0.0968 0.1006 0.0977 0.0933 0.0918 0.0935 0.1030 0.1024 0.1000 

[TRAIN] Epoch[4](604/1500); Loss: 0.058699; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1354 0.0810 0.0642 0.0617 0.0572 0.0542 0.0565 0.0451 0.0449 0.0446 0.0459 0.0456 0.0465 0.0479 0.0524 0.0562 

[TRAIN] Epoch[4](605/1500); Loss: 0.120958; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1789 0.1393 0.1303 0.1353 0.1335 0.1268 0.1159 0.1072 0.1090 0.1075 0.1095 0.1087 0.1081 0.1078 0.1083 0.1092 

[TRAIN] Epoch[4](606/1500); Loss: 0.078698; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1272 0.1014 0.0976 0.0871 0.0765 0.0739 0.0744 0.0700 0.0691 0.0684 0.0675 0.0678 0.0687 0.0696 0.0697 0.0702 

[TRAIN] Epoch[4](607/1500); Loss: 0.103629; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.1415 0.1148 0.1153 0.1118 0.1050 0.0991 0.1011 0.0978 0.0974 0.0966 0.0957 0.0961 0.0961 0.0964 0.0965 0.0967 

[TRAIN] Epoch[4](608/1500); Loss: 0.099388; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1354 0.1051 0.0958 0.0998 0.0939 0.0873 0.0856 0.0938 0.0946 0.0951 0.0922 0.0951 0.1001 0.1081 0.1045 0.1038 

[TRAIN] Epoch[4](609/1500); Loss: 0.138154; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1885 0.1667 0.1568 0.1515 0.1394 0.1287 0.1237 0.1269 0.1317 0.1294 0.1252 0.1265 0.1231 0.1302 0.1317 0.1304 

[TRAIN] Epoch[4](610/1500); Loss: 0.175529; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2104 0.1799 0.1858 0.1866 0.1806 0.1749 0.1705 0.1698 0.1715 0.1688 0.1671 0.1683 0.1690 0.1706 0.1682 0.1666 

[TRAIN] Epoch[4](611/1500); Loss: 0.081654; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0868 0.0991 0.1006 0.0854 0.0819 0.0775 0.0768 0.0807 0.0770 0.0774 0.0750 0.0758 0.0784 0.0794 0.0778 0.0768 

[TRAIN] Epoch[4](612/1500); Loss: 0.128051; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.2148 0.1516 0.1349 0.1361 0.1281 0.1154 0.1119 0.1130 0.1175 0.1175 0.1135 0.1124 0.1156 0.1236 0.1232 0.1196 

[TRAIN] Epoch[4](613/1500); Loss: 0.109222; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2297 0.1787 0.1477 0.1257 0.1056 0.0928 0.0902 0.0902 0.0861 0.0867 0.0845 0.0852 0.0856 0.0875 0.0863 0.0850 

[TRAIN] Epoch[4](614/1500); Loss: 0.092934; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.3386 0.1895 0.1008 0.0628 0.0820 0.0711 0.0597 0.0501 0.0693 0.0645 0.0671 0.0576 0.0635 0.0629 0.0737 0.0737 

[TRAIN] Epoch[4](615/1500); Loss: 0.102125; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.3811 0.1955 0.0627 0.0921 0.0926 0.0724 0.0489 0.0770 0.0475 0.0972 0.0963 0.0773 0.0537 0.0750 0.0604 0.1045 

[TRAIN] Epoch[4](616/1500); Loss: 0.100036; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1341 0.1142 0.1178 0.1094 0.0989 0.0904 0.0908 0.0921 0.0952 0.0911 0.0910 0.0931 0.0967 0.0966 0.0937 0.0955 

[TRAIN] Epoch[4](617/1500); Loss: 0.109186; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1526 0.1248 0.1198 0.1159 0.1101 0.1080 0.1057 0.1020 0.1017 0.1009 0.1008 0.1003 0.1007 0.1005 0.1009 0.1023 

[TRAIN] Epoch[4](618/1500); Loss: 0.120063; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.3079 0.2096 0.1445 0.0980 0.1119 0.1061 0.0926 0.0849 0.0964 0.0903 0.1023 0.0979 0.0922 0.0880 0.0990 0.0996 

[TRAIN] Epoch[4](619/1500); Loss: 0.123478; Backpropagation: 0.0924 sec; Batch: 0.4238 sec
0.1704 0.1328 0.1369 0.1385 0.1310 0.1209 0.1182 0.1158 0.1185 0.1167 0.1137 0.1129 0.1143 0.1126 0.1107 0.1117 

[TRAIN] Epoch[4](620/1500); Loss: 0.117666; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.3822 0.2053 0.0801 0.1094 0.1092 0.0893 0.0666 0.0902 0.0712 0.1110 0.1075 0.0894 0.0764 0.0909 0.0855 0.1184 

[TRAIN] Epoch[4](621/1500); Loss: 0.193833; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.3630 0.2659 0.2512 0.2904 0.2803 0.2505 0.2007 0.1453 0.1174 0.1381 0.1280 0.1328 0.1290 0.1268 0.1358 0.1461 

[TRAIN] Epoch[4](622/1500); Loss: 0.118400; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2977 0.1999 0.1379 0.1110 0.1115 0.1021 0.1005 0.0978 0.0926 0.0914 0.0879 0.0908 0.0934 0.0964 0.0927 0.0909 

[TRAIN] Epoch[4](623/1500); Loss: 0.098452; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1213 0.1252 0.1227 0.1089 0.0993 0.0942 0.0912 0.0920 0.0903 0.0873 0.0879 0.0898 0.0912 0.0890 0.0901 0.0947 

[TRAIN] Epoch[4](624/1500); Loss: 0.076099; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.0878 0.0874 0.0933 0.0790 0.0691 0.0780 0.0685 0.0742 0.0715 0.0685 0.0703 0.0735 0.0760 0.0727 0.0718 0.0759 

[TRAIN] Epoch[4](625/1500); Loss: 0.132976; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1747 0.1478 0.1409 0.1367 0.1273 0.1243 0.1225 0.1249 0.1244 0.1237 0.1254 0.1274 0.1301 0.1303 0.1317 0.1356 

[TRAIN] Epoch[4](626/1500); Loss: 0.131011; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3564 0.2358 0.1735 0.1420 0.1493 0.1370 0.1098 0.0843 0.0916 0.0819 0.0948 0.0915 0.0845 0.0813 0.0900 0.0926 

[TRAIN] Epoch[4](627/1500); Loss: 0.183404; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.3659 0.2597 0.2400 0.2740 0.2644 0.2365 0.1857 0.1308 0.1061 0.1280 0.1189 0.1254 0.1208 0.1185 0.1262 0.1336 

[TRAIN] Epoch[4](628/1500); Loss: 0.182730; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2873 0.2359 0.2231 0.2347 0.2269 0.2117 0.1865 0.1604 0.1445 0.1450 0.1437 0.1435 0.1418 0.1440 0.1488 0.1461 

[TRAIN] Epoch[4](629/1500); Loss: 0.110356; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3370 0.2344 0.1599 0.0865 0.0955 0.0888 0.0764 0.0678 0.0829 0.0686 0.0822 0.0813 0.0729 0.0721 0.0812 0.0785 

[TRAIN] Epoch[4](630/1500); Loss: 0.094572; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3908 0.2385 0.1246 0.0416 0.0732 0.0709 0.0596 0.0450 0.0564 0.0497 0.0654 0.0631 0.0562 0.0528 0.0634 0.0619 

[TRAIN] Epoch[4](631/1500); Loss: 0.129579; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1995 0.1449 0.1410 0.1571 0.1496 0.1355 0.1183 0.1087 0.1084 0.1099 0.1126 0.1143 0.1142 0.1164 0.1202 0.1226 

[TRAIN] Epoch[4](632/1500); Loss: 0.110816; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2531 0.1673 0.1166 0.0992 0.1007 0.0939 0.0913 0.0966 0.0921 0.0914 0.0905 0.0915 0.0955 0.0980 0.0966 0.0987 

[TRAIN] Epoch[4](633/1500); Loss: 0.136969; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1998 0.1483 0.1450 0.1610 0.1519 0.1366 0.1196 0.1187 0.1213 0.1269 0.1254 0.1231 0.1242 0.1283 0.1302 0.1313 

[TRAIN] Epoch[4](634/1500); Loss: 0.146065; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2259 0.1842 0.1681 0.1601 0.1495 0.1401 0.1366 0.1340 0.1299 0.1300 0.1295 0.1307 0.1303 0.1291 0.1294 0.1294 

[TRAIN] Epoch[4](635/1500); Loss: 0.124090; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1896 0.1448 0.1320 0.1364 0.1272 0.1184 0.1119 0.1116 0.1138 0.1126 0.1103 0.1135 0.1135 0.1166 0.1171 0.1160 

[TRAIN] Epoch[4](636/1500); Loss: 0.120440; Backpropagation: 0.0915 sec; Batch: 0.4230 sec
0.2941 0.1894 0.1265 0.1096 0.1111 0.1012 0.0940 0.1039 0.0944 0.1021 0.0987 0.0970 0.0997 0.0995 0.1038 0.1019 

[TRAIN] Epoch[4](637/1500); Loss: 0.208254; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.2920 0.2356 0.2272 0.2327 0.2238 0.2111 0.1980 0.1866 0.1879 0.1889 0.1868 0.1852 0.1891 0.1951 0.1967 0.1953 

[TRAIN] Epoch[4](638/1500); Loss: 0.093091; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2482 0.1625 0.1225 0.1078 0.0899 0.0793 0.0742 0.0653 0.0695 0.0681 0.0638 0.0676 0.0680 0.0691 0.0678 0.0659 

[TRAIN] Epoch[4](639/1500); Loss: 0.160715; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2796 0.2049 0.1884 0.2017 0.1913 0.1737 0.1426 0.1250 0.1286 0.1294 0.1317 0.1298 0.1328 0.1353 0.1378 0.1389 

[TRAIN] Epoch[4](640/1500); Loss: 0.097991; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2185 0.1356 0.0995 0.1089 0.1054 0.0912 0.0806 0.0928 0.0854 0.0807 0.0764 0.0748 0.0797 0.0794 0.0808 0.0780 

[TRAIN] Epoch[4](641/1500); Loss: 0.102776; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1516 0.1095 0.1055 0.1123 0.1070 0.0992 0.0990 0.1045 0.0953 0.0929 0.0931 0.0935 0.0938 0.0944 0.0959 0.0968 

[TRAIN] Epoch[4](642/1500); Loss: 0.076102; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1128 0.0733 0.1019 0.0976 0.0799 0.0670 0.0780 0.0684 0.0686 0.0654 0.0645 0.0688 0.0690 0.0685 0.0658 0.0681 

[TRAIN] Epoch[4](643/1500); Loss: 0.114799; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1671 0.1330 0.1285 0.1339 0.1289 0.1167 0.1006 0.1023 0.1058 0.1022 0.1018 0.1014 0.1019 0.1032 0.1046 0.1048 

[TRAIN] Epoch[4](644/1500); Loss: 0.127762; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1722 0.1408 0.1323 0.1322 0.1294 0.1256 0.1194 0.1196 0.1205 0.1203 0.1210 0.1203 0.1213 0.1222 0.1233 0.1238 

[TRAIN] Epoch[4](645/1500); Loss: 0.090699; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1419 0.1059 0.0977 0.1008 0.0964 0.0880 0.0832 0.0836 0.0824 0.0813 0.0786 0.0793 0.0811 0.0840 0.0833 0.0837 

[TRAIN] Epoch[4](646/1500); Loss: 0.187891; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.4105 0.2818 0.2660 0.3180 0.3055 0.2661 0.1933 0.1139 0.0845 0.1243 0.1132 0.1063 0.1006 0.1008 0.1086 0.1129 

[TRAIN] Epoch[4](647/1500); Loss: 0.156955; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2040 0.1822 0.1743 0.1715 0.1629 0.1562 0.1492 0.1451 0.1449 0.1461 0.1459 0.1453 0.1448 0.1451 0.1466 0.1472 

[TRAIN] Epoch[4](648/1500); Loss: 0.108601; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1450 0.1418 0.1339 0.1234 0.1174 0.1103 0.1028 0.0961 0.0945 0.0950 0.0961 0.0961 0.0963 0.0951 0.0966 0.0971 

[TRAIN] Epoch[4](649/1500); Loss: 0.104297; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1472 0.1089 0.1167 0.1283 0.1164 0.0996 0.0891 0.0967 0.1016 0.0990 0.0907 0.0911 0.0920 0.1012 0.0980 0.0924 

[TRAIN] Epoch[4](650/1500); Loss: 0.122419; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1781 0.1340 0.1411 0.1396 0.1310 0.1190 0.1192 0.1104 0.1134 0.1133 0.1094 0.1087 0.1096 0.1121 0.1117 0.1083 

[TRAIN] Epoch[4](651/1500); Loss: 0.104891; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.4008 0.2494 0.1332 0.0392 0.0973 0.1047 0.0849 0.0480 0.0579 0.0466 0.0807 0.0772 0.0615 0.0475 0.0801 0.0693 

[TRAIN] Epoch[4](652/1500); Loss: 0.059269; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1277 0.0431 0.0403 0.0623 0.0513 0.0359 0.0638 0.0863 0.0610 0.0505 0.0473 0.0506 0.0563 0.0605 0.0556 0.0559 

[TRAIN] Epoch[4](653/1500); Loss: 0.091732; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1586 0.1125 0.1023 0.1097 0.0983 0.0863 0.0797 0.0860 0.0866 0.0776 0.0764 0.0770 0.0774 0.0778 0.0794 0.0822 

[TRAIN] Epoch[4](654/1500); Loss: 0.077298; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1144 0.0938 0.0985 0.0874 0.0751 0.0721 0.0681 0.0689 0.0698 0.0675 0.0660 0.0696 0.0698 0.0722 0.0714 0.0722 

[TRAIN] Epoch[4](655/1500); Loss: 0.122095; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2410 0.1495 0.1396 0.1774 0.1654 0.1353 0.0936 0.0923 0.1057 0.0913 0.0906 0.0906 0.0904 0.0937 0.0984 0.0989 

[TRAIN] Epoch[4](656/1500); Loss: 0.069337; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0974 0.0819 0.0930 0.0843 0.0695 0.0617 0.0586 0.0601 0.0617 0.0590 0.0575 0.0628 0.0640 0.0655 0.0658 0.0666 

[TRAIN] Epoch[4](657/1500); Loss: 0.121977; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2948 0.1485 0.0935 0.1397 0.1349 0.1147 0.0990 0.0943 0.0909 0.1146 0.1076 0.0954 0.1009 0.0940 0.1076 0.1212 

[TRAIN] Epoch[4](658/1500); Loss: 0.130322; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2139 0.1638 0.1415 0.1310 0.1285 0.1204 0.1191 0.1170 0.1193 0.1193 0.1172 0.1167 0.1174 0.1197 0.1197 0.1205 

[TRAIN] Epoch[4](659/1500); Loss: 0.131138; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2133 0.1540 0.1374 0.1463 0.1400 0.1288 0.1195 0.1172 0.1162 0.1176 0.1145 0.1147 0.1176 0.1203 0.1217 0.1191 

[TRAIN] Epoch[4](660/1500); Loss: 0.113110; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1839 0.1176 0.1084 0.1252 0.1193 0.1068 0.0972 0.1089 0.1056 0.1025 0.1028 0.1027 0.1040 0.1066 0.1099 0.1084 

[TRAIN] Epoch[4](661/1500); Loss: 0.061721; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0955 0.0739 0.0726 0.0672 0.0599 0.0525 0.0587 0.0699 0.0577 0.0535 0.0519 0.0531 0.0540 0.0546 0.0558 0.0567 

[TRAIN] Epoch[4](662/1500); Loss: 0.204465; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.3278 0.2515 0.2356 0.2595 0.2508 0.2236 0.1835 0.1669 0.1885 0.1726 0.1686 0.1656 0.1642 0.1684 0.1721 0.1723 

[TRAIN] Epoch[4](663/1500); Loss: 0.155776; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2811 0.2156 0.1831 0.1615 0.1495 0.1469 0.1421 0.1349 0.1348 0.1353 0.1344 0.1334 0.1339 0.1356 0.1355 0.1348 

[TRAIN] Epoch[4](664/1500); Loss: 0.115392; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2689 0.1741 0.1210 0.1194 0.1194 0.1071 0.0950 0.1013 0.1005 0.0934 0.0891 0.0881 0.0906 0.0932 0.0921 0.0931 

[TRAIN] Epoch[4](665/1500); Loss: 0.119588; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1620 0.1240 0.1107 0.1079 0.1065 0.0987 0.0979 0.0998 0.1068 0.1148 0.1165 0.1194 0.1251 0.1361 0.1424 0.1449 

[TRAIN] Epoch[4](666/1500); Loss: 0.146294; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2467 0.1805 0.1543 0.1466 0.1451 0.1428 0.1350 0.1311 0.1291 0.1306 0.1308 0.1315 0.1322 0.1340 0.1349 0.1355 

[TRAIN] Epoch[4](667/1500); Loss: 0.114399; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2479 0.1845 0.1432 0.1086 0.1072 0.0988 0.0887 0.0904 0.0973 0.0932 0.0960 0.0933 0.0922 0.0925 0.0983 0.0984 

[TRAIN] Epoch[4](668/1500); Loss: 0.060690; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0543 0.0899 0.0976 0.0713 0.0573 0.0543 0.0564 0.0550 0.0538 0.0524 0.0521 0.0558 0.0545 0.0556 0.0544 0.0562 

[TRAIN] Epoch[4](669/1500); Loss: 0.085547; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.3153 0.1682 0.0897 0.0692 0.0779 0.0647 0.0569 0.0563 0.0571 0.0579 0.0574 0.0558 0.0617 0.0580 0.0599 0.0628 

[TRAIN] Epoch[4](670/1500); Loss: 0.125358; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1627 0.1415 0.1355 0.1276 0.1234 0.1191 0.1162 0.1148 0.1181 0.1206 0.1184 0.1177 0.1205 0.1220 0.1232 0.1243 

[TRAIN] Epoch[4](671/1500); Loss: 0.122871; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1483 0.1433 0.1426 0.1342 0.1248 0.1185 0.1152 0.1152 0.1150 0.1147 0.1138 0.1137 0.1158 0.1168 0.1164 0.1177 

[TRAIN] Epoch[4](672/1500); Loss: 0.150789; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2022 0.1651 0.1690 0.1659 0.1585 0.1530 0.1530 0.1425 0.1400 0.1375 0.1363 0.1372 0.1385 0.1393 0.1372 0.1373 

[TRAIN] Epoch[4](673/1500); Loss: 0.098919; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1464 0.1080 0.0990 0.0999 0.0967 0.0970 0.1022 0.1022 0.0935 0.0908 0.0909 0.0909 0.0913 0.0907 0.0917 0.0916 

[TRAIN] Epoch[4](674/1500); Loss: 0.105937; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2246 0.1618 0.1311 0.1103 0.0971 0.0891 0.0904 0.0897 0.0889 0.0874 0.0862 0.0878 0.0884 0.0879 0.0870 0.0873 

[TRAIN] Epoch[4](675/1500); Loss: 0.059652; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0506 0.0905 0.0959 0.0699 0.0547 0.0568 0.0567 0.0515 0.0526 0.0509 0.0519 0.0536 0.0526 0.0540 0.0548 0.0573 

[TRAIN] Epoch[4](676/1500); Loss: 0.067759; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1462 0.1098 0.0831 0.0726 0.0703 0.0615 0.0592 0.0654 0.0506 0.0543 0.0507 0.0501 0.0547 0.0506 0.0538 0.0512 

[TRAIN] Epoch[4](677/1500); Loss: 0.128153; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1636 0.1486 0.1449 0.1378 0.1273 0.1236 0.1218 0.1204 0.1197 0.1195 0.1187 0.1193 0.1205 0.1208 0.1212 0.1227 

[TRAIN] Epoch[4](678/1500); Loss: 0.124217; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1682 0.1465 0.1414 0.1394 0.1309 0.1206 0.1122 0.1144 0.1130 0.1128 0.1124 0.1127 0.1128 0.1155 0.1174 0.1173 

[TRAIN] Epoch[4](679/1500); Loss: 0.127366; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1531 0.1318 0.1318 0.1307 0.1341 0.1388 0.1276 0.1201 0.1198 0.1207 0.1207 0.1203 0.1213 0.1222 0.1221 0.1229 

[TRAIN] Epoch[4](680/1500); Loss: 0.150497; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2507 0.1978 0.1854 0.1906 0.1771 0.1579 0.1341 0.1319 0.1297 0.1279 0.1245 0.1208 0.1205 0.1196 0.1209 0.1185 

[TRAIN] Epoch[4](681/1500); Loss: 0.157516; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2538 0.2057 0.1884 0.1872 0.1780 0.1664 0.1550 0.1408 0.1325 0.1319 0.1311 0.1296 0.1295 0.1294 0.1300 0.1309 

[TRAIN] Epoch[4](682/1500); Loss: 0.181526; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3241 0.2418 0.2336 0.2665 0.2579 0.2267 0.1709 0.1248 0.1228 0.1279 0.1274 0.1234 0.1238 0.1388 0.1539 0.1405 

[TRAIN] Epoch[4](683/1500); Loss: 0.079990; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2725 0.1287 0.0767 0.0813 0.0759 0.0603 0.0595 0.0671 0.0528 0.0586 0.0536 0.0539 0.0608 0.0599 0.0602 0.0580 

[TRAIN] Epoch[4](684/1500); Loss: 0.076274; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1988 0.1202 0.0841 0.0743 0.0717 0.0662 0.0645 0.0660 0.0583 0.0603 0.0589 0.0581 0.0587 0.0591 0.0608 0.0603 

[TRAIN] Epoch[4](685/1500); Loss: 0.103767; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2318 0.1296 0.0919 0.1111 0.1039 0.0892 0.0877 0.0961 0.0869 0.0904 0.0849 0.0849 0.0941 0.0927 0.0935 0.0918 

[TRAIN] Epoch[4](686/1500); Loss: 0.161941; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2301 0.1923 0.1870 0.1943 0.1859 0.1713 0.1558 0.1429 0.1380 0.1398 0.1409 0.1410 0.1411 0.1423 0.1432 0.1448 

[TRAIN] Epoch[4](687/1500); Loss: 0.089479; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1367 0.1129 0.1102 0.1127 0.1051 0.0961 0.0824 0.0784 0.0790 0.0740 0.0736 0.0739 0.0737 0.0736 0.0740 0.0754 

[TRAIN] Epoch[4](688/1500); Loss: 0.162823; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2191 0.1857 0.1801 0.1782 0.1733 0.1676 0.1615 0.1561 0.1515 0.1489 0.1481 0.1483 0.1472 0.1463 0.1463 0.1468 

[TRAIN] Epoch[4](689/1500); Loss: 0.158478; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2202 0.1683 0.1672 0.1638 0.1562 0.1513 0.1485 0.1477 0.1511 0.1498 0.1486 0.1494 0.1512 0.1537 0.1536 0.1549 

[TRAIN] Epoch[4](690/1500); Loss: 0.103266; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1912 0.1211 0.1014 0.1063 0.1015 0.0942 0.0955 0.0983 0.0923 0.0920 0.0912 0.0917 0.0920 0.0938 0.0949 0.0948 

[TRAIN] Epoch[4](691/1500); Loss: 0.062854; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1386 0.0496 0.0441 0.0660 0.0549 0.0392 0.0678 0.0954 0.0719 0.0537 0.0476 0.0508 0.0550 0.0590 0.0559 0.0562 

[TRAIN] Epoch[4](692/1500); Loss: 0.101038; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.3517 0.2371 0.1551 0.0764 0.0810 0.0743 0.0633 0.0539 0.0797 0.0622 0.0639 0.0617 0.0599 0.0664 0.0662 0.0638 

[TRAIN] Epoch[4](693/1500); Loss: 0.100506; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2210 0.1556 0.1239 0.0997 0.0950 0.0920 0.0878 0.0836 0.0814 0.0804 0.0806 0.0791 0.0802 0.0804 0.0825 0.0851 

[TRAIN] Epoch[4](694/1500); Loss: 0.120686; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2860 0.1963 0.1389 0.1053 0.1039 0.1004 0.0960 0.1022 0.1062 0.0968 0.0961 0.0975 0.1027 0.1004 0.1005 0.1018 

[TRAIN] Epoch[4](695/1500); Loss: 0.137575; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1933 0.1644 0.1590 0.1602 0.1516 0.1408 0.1295 0.1254 0.1249 0.1217 0.1219 0.1208 0.1199 0.1211 0.1221 0.1247 

[TRAIN] Epoch[4](696/1500); Loss: 0.109994; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2400 0.1601 0.1274 0.1281 0.1231 0.1092 0.0959 0.0935 0.0927 0.0845 0.0844 0.0852 0.0827 0.0842 0.0834 0.0855 

[TRAIN] Epoch[4](697/1500); Loss: 0.081450; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1070 0.0931 0.0927 0.0868 0.0863 0.0907 0.0817 0.0739 0.0729 0.0737 0.0741 0.0728 0.0728 0.0736 0.0754 0.0758 

[TRAIN] Epoch[4](698/1500); Loss: 0.118014; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1854 0.1368 0.1249 0.1220 0.1158 0.1121 0.1150 0.1150 0.1087 0.1078 0.1068 0.1069 0.1076 0.1073 0.1072 0.1089 

[TRAIN] Epoch[4](699/1500); Loss: 0.102298; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1453 0.1125 0.1043 0.1065 0.1012 0.0951 0.0971 0.0970 0.0931 0.0954 0.0929 0.0946 0.0973 0.0999 0.1030 0.1017 

[TRAIN] Epoch[4](700/1500); Loss: 0.121336; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2720 0.1470 0.1161 0.1329 0.1216 0.1051 0.1075 0.1060 0.1015 0.1076 0.1019 0.0998 0.1096 0.1015 0.1059 0.1055 

[TRAIN] Epoch[4](701/1500); Loss: 0.059898; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0455 0.0985 0.1027 0.0692 0.0585 0.0536 0.0503 0.0493 0.0498 0.0507 0.0521 0.0530 0.0538 0.0556 0.0569 0.0589 

[TRAIN] Epoch[4](702/1500); Loss: 0.144946; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2647 0.1915 0.1590 0.1635 0.1580 0.1437 0.1282 0.1328 0.1294 0.1230 0.1200 0.1201 0.1220 0.1206 0.1208 0.1217 

[TRAIN] Epoch[4](703/1500); Loss: 0.096205; Backpropagation: 0.0918 sec; Batch: 0.4263 sec
0.1643 0.1260 0.1211 0.1089 0.0993 0.0932 0.0836 0.0806 0.0802 0.0793 0.0780 0.0782 0.0828 0.0865 0.0877 0.0895 

[TRAIN] Epoch[4](704/1500); Loss: 0.111271; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.2638 0.1739 0.1332 0.1051 0.0995 0.0951 0.0964 0.0959 0.0932 0.0886 0.0870 0.0895 0.0926 0.0889 0.0884 0.0891 

[TRAIN] Epoch[4](705/1500); Loss: 0.109934; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1574 0.1284 0.1170 0.1095 0.1042 0.1028 0.1073 0.1109 0.1046 0.1010 0.1012 0.1022 0.1021 0.1025 0.1038 0.1040 

[TRAIN] Epoch[4](706/1500); Loss: 0.070453; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1032 0.0878 0.0889 0.0738 0.0643 0.0625 0.0616 0.0601 0.0598 0.0602 0.0619 0.0644 0.0655 0.0683 0.0709 0.0741 

[TRAIN] Epoch[4](707/1500); Loss: 0.083640; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1710 0.0935 0.1011 0.1022 0.0883 0.0717 0.0783 0.0740 0.0690 0.0691 0.0660 0.0686 0.0726 0.0700 0.0715 0.0716 

[TRAIN] Epoch[4](708/1500); Loss: 0.066050; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1421 0.0946 0.0816 0.0675 0.0580 0.0615 0.0716 0.0565 0.0521 0.0508 0.0524 0.0538 0.0516 0.0526 0.0551 0.0549 

[TRAIN] Epoch[4](709/1500); Loss: 0.101133; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1370 0.1131 0.1151 0.1105 0.1025 0.1004 0.1002 0.0938 0.0930 0.0920 0.0915 0.0918 0.0923 0.0939 0.0955 0.0954 

[TRAIN] Epoch[4](710/1500); Loss: 0.115114; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1444 0.1204 0.1191 0.1167 0.1171 0.1223 0.1167 0.1084 0.1068 0.1071 0.1082 0.1088 0.1096 0.1110 0.1120 0.1133 

[TRAIN] Epoch[4](711/1500); Loss: 0.154437; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2408 0.1949 0.1861 0.1923 0.1786 0.1610 0.1426 0.1424 0.1352 0.1341 0.1308 0.1270 0.1262 0.1263 0.1268 0.1260 

[TRAIN] Epoch[4](712/1500); Loss: 0.073806; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1440 0.0721 0.0855 0.0800 0.0699 0.0672 0.0847 0.0737 0.0621 0.0599 0.0599 0.0650 0.0624 0.0637 0.0629 0.0679 

[TRAIN] Epoch[4](713/1500); Loss: 0.091622; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2154 0.1411 0.1091 0.0902 0.0819 0.0801 0.0865 0.0829 0.0754 0.0720 0.0719 0.0739 0.0731 0.0698 0.0708 0.0719 

[TRAIN] Epoch[4](714/1500); Loss: 0.095297; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1106 0.1091 0.1121 0.1056 0.0982 0.0947 0.0931 0.0930 0.0910 0.0872 0.0865 0.0894 0.0868 0.0885 0.0883 0.0907 

[TRAIN] Epoch[4](715/1500); Loss: 0.078976; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1133 0.0953 0.0933 0.0884 0.0867 0.0876 0.0740 0.0688 0.0676 0.0674 0.0681 0.0698 0.0699 0.0700 0.0711 0.0724 

[TRAIN] Epoch[4](716/1500); Loss: 0.116559; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1508 0.1429 0.1398 0.1374 0.1276 0.1192 0.1113 0.1052 0.1047 0.1038 0.1024 0.1039 0.1045 0.1041 0.1035 0.1037 

[TRAIN] Epoch[4](717/1500); Loss: 0.100056; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2166 0.1324 0.1030 0.1046 0.0979 0.0846 0.0864 0.0964 0.0822 0.0825 0.0818 0.0836 0.0878 0.0866 0.0866 0.0880 

[TRAIN] Epoch[4](718/1500); Loss: 0.073876; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1187 0.0761 0.0741 0.0725 0.0671 0.0662 0.0703 0.0658 0.0684 0.0656 0.0674 0.0703 0.0718 0.0746 0.0752 0.0777 

[TRAIN] Epoch[4](719/1500); Loss: 0.143068; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2556 0.1809 0.1495 0.1546 0.1515 0.1390 0.1295 0.1330 0.1239 0.1283 0.1251 0.1230 0.1231 0.1242 0.1239 0.1240 

[TRAIN] Epoch[4](720/1500); Loss: 0.122235; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1578 0.1346 0.1308 0.1283 0.1243 0.1213 0.1164 0.1167 0.1147 0.1141 0.1148 0.1154 0.1157 0.1161 0.1166 0.1182 

[TRAIN] Epoch[4](721/1500); Loss: 0.170107; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2037 0.1726 0.1635 0.1622 0.1629 0.1616 0.1613 0.1621 0.1641 0.1677 0.1698 0.1700 0.1712 0.1738 0.1769 0.1785 

[TRAIN] Epoch[4](722/1500); Loss: 0.108063; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2411 0.1788 0.1396 0.1030 0.1006 0.0933 0.0841 0.0810 0.0873 0.0865 0.0903 0.0882 0.0865 0.0831 0.0918 0.0937 

[TRAIN] Epoch[4](723/1500); Loss: 0.059400; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0888 0.0782 0.0806 0.0704 0.0627 0.0563 0.0531 0.0552 0.0515 0.0501 0.0498 0.0493 0.0498 0.0505 0.0519 0.0521 

[TRAIN] Epoch[4](724/1500); Loss: 0.097522; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1038 0.1150 0.1197 0.1062 0.0975 0.0952 0.0969 0.0935 0.0913 0.0907 0.0910 0.0925 0.0927 0.0906 0.0906 0.0930 

[TRAIN] Epoch[4](725/1500); Loss: 0.076673; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2052 0.0940 0.0709 0.0746 0.0681 0.0619 0.0740 0.0627 0.0639 0.0629 0.0608 0.0675 0.0646 0.0661 0.0646 0.0650 

[TRAIN] Epoch[4](726/1500); Loss: 0.175086; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2650 0.2035 0.1844 0.1860 0.1789 0.1696 0.1645 0.1593 0.1625 0.1644 0.1607 0.1575 0.1573 0.1629 0.1633 0.1617 

[TRAIN] Epoch[4](727/1500); Loss: 0.073973; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1127 0.0796 0.0834 0.0819 0.0762 0.0771 0.0740 0.0668 0.0669 0.0653 0.0652 0.0653 0.0669 0.0672 0.0675 0.0677 

[TRAIN] Epoch[4](728/1500); Loss: 0.132933; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1993 0.1523 0.1404 0.1406 0.1344 0.1269 0.1252 0.1257 0.1221 0.1221 0.1223 0.1230 0.1215 0.1225 0.1231 0.1254 

[TRAIN] Epoch[4](729/1500); Loss: 0.162801; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1919 0.1721 0.1717 0.1679 0.1629 0.1612 0.1620 0.1582 0.1578 0.1576 0.1566 0.1565 0.1566 0.1571 0.1569 0.1578 

[TRAIN] Epoch[4](730/1500); Loss: 0.112831; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2841 0.1891 0.1253 0.0991 0.1121 0.1028 0.0923 0.0944 0.0907 0.0893 0.0871 0.0834 0.0875 0.0878 0.0914 0.0888 

[TRAIN] Epoch[4](731/1500); Loss: 0.087688; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2808 0.1819 0.1200 0.0730 0.0736 0.0674 0.0631 0.0661 0.0672 0.0584 0.0571 0.0549 0.0589 0.0592 0.0599 0.0614 

[TRAIN] Epoch[4](732/1500); Loss: 0.097767; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2239 0.1375 0.1007 0.1137 0.1099 0.0920 0.0805 0.0963 0.0816 0.0763 0.0735 0.0732 0.0770 0.0764 0.0747 0.0770 

[TRAIN] Epoch[4](733/1500); Loss: 0.080675; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1137 0.0943 0.0982 0.0894 0.0796 0.0736 0.0751 0.0737 0.0739 0.0722 0.0716 0.0746 0.0750 0.0753 0.0741 0.0765 

[TRAIN] Epoch[4](734/1500); Loss: 0.143965; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.2552 0.1803 0.1508 0.1601 0.1552 0.1404 0.1282 0.1336 0.1233 0.1291 0.1257 0.1223 0.1233 0.1250 0.1265 0.1241 

[TRAIN] Epoch[4](735/1500); Loss: 0.104493; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1492 0.1108 0.1082 0.1068 0.1028 0.0994 0.1074 0.1080 0.0983 0.0967 0.0954 0.0972 0.0981 0.0972 0.0978 0.0986 

[TRAIN] Epoch[4](736/1500); Loss: 0.083216; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1313 0.1231 0.1109 0.0884 0.0761 0.0732 0.0716 0.0713 0.0721 0.0711 0.0709 0.0733 0.0724 0.0741 0.0748 0.0768 

[TRAIN] Epoch[4](737/1500); Loss: 0.090186; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1476 0.1190 0.1092 0.0978 0.0893 0.0817 0.0863 0.0892 0.0798 0.0776 0.0768 0.0766 0.0768 0.0779 0.0790 0.0782 

[TRAIN] Epoch[4](738/1500); Loss: 0.108973; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.3323 0.2310 0.1657 0.1040 0.0941 0.0867 0.0746 0.0743 0.0790 0.0701 0.0699 0.0653 0.0710 0.0757 0.0770 0.0729 

[TRAIN] Epoch[4](739/1500); Loss: 0.062261; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1534 0.0512 0.0437 0.0739 0.0606 0.0376 0.0602 0.0874 0.0632 0.0489 0.0449 0.0492 0.0539 0.0560 0.0561 0.0562 

[TRAIN] Epoch[4](740/1500); Loss: 0.131451; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1711 0.1445 0.1457 0.1453 0.1380 0.1295 0.1262 0.1242 0.1246 0.1245 0.1214 0.1207 0.1210 0.1221 0.1225 0.1219 

[TRAIN] Epoch[4](741/1500); Loss: 0.151801; Backpropagation: 0.0927 sec; Batch: 0.4254 sec
0.2289 0.1704 0.1625 0.1732 0.1668 0.1562 0.1447 0.1388 0.1372 0.1355 0.1351 0.1347 0.1347 0.1355 0.1364 0.1383 

[TRAIN] Epoch[4](742/1500); Loss: 0.080021; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0925 0.0959 0.0961 0.0851 0.0738 0.0771 0.0853 0.0717 0.0704 0.0711 0.0726 0.0751 0.0754 0.0768 0.0788 0.0824 

[TRAIN] Epoch[4](743/1500); Loss: 0.080199; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0902 0.0898 0.0949 0.0860 0.0782 0.0815 0.0846 0.0764 0.0739 0.0738 0.0740 0.0749 0.0754 0.0757 0.0768 0.0770 

[TRAIN] Epoch[4](744/1500); Loss: 0.102874; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2118 0.1443 0.1153 0.1041 0.0982 0.0940 0.0940 0.0929 0.0893 0.0871 0.0862 0.0870 0.0857 0.0850 0.0849 0.0862 

[TRAIN] Epoch[4](745/1500); Loss: 0.085961; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1026 0.0879 0.0900 0.0865 0.0823 0.0890 0.0944 0.0849 0.0810 0.0806 0.0813 0.0824 0.0823 0.0825 0.0832 0.0845 

[TRAIN] Epoch[4](746/1500); Loss: 0.109066; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1497 0.1313 0.1289 0.1187 0.1121 0.1045 0.1026 0.1022 0.1006 0.0997 0.0990 0.0992 0.0996 0.0993 0.0988 0.0989 

[TRAIN] Epoch[4](747/1500); Loss: 0.125677; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2347 0.1903 0.1626 0.1419 0.1269 0.1174 0.1071 0.1053 0.1048 0.1031 0.1015 0.1014 0.1013 0.1041 0.1051 0.1035 

[TRAIN] Epoch[4](748/1500); Loss: 0.059424; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1538 0.0517 0.0442 0.0749 0.0618 0.0383 0.0587 0.0640 0.0528 0.0456 0.0425 0.0490 0.0537 0.0557 0.0504 0.0538 

[TRAIN] Epoch[4](749/1500); Loss: 0.163647; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2711 0.2021 0.1712 0.1695 0.1691 0.1585 0.1514 0.1524 0.1448 0.1472 0.1454 0.1454 0.1485 0.1461 0.1480 0.1477 

[TRAIN] Epoch[4](750/1500); Loss: 0.104135; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1252 0.1245 0.1256 0.1159 0.1080 0.1022 0.1002 0.0994 0.0968 0.0958 0.0951 0.0952 0.0948 0.0956 0.0957 0.0961 

[TRAIN] Epoch[4](751/1500); Loss: 0.156053; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2175 0.1827 0.1749 0.1652 0.1599 0.1542 0.1487 0.1446 0.1437 0.1455 0.1454 0.1430 0.1420 0.1420 0.1429 0.1448 

[TRAIN] Epoch[4](752/1500); Loss: 0.184188; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3384 0.2525 0.2334 0.2634 0.2534 0.2238 0.1748 0.1314 0.1339 0.1304 0.1334 0.1306 0.1332 0.1441 0.1377 0.1326 

[TRAIN] Epoch[4](753/1500); Loss: 0.058755; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.0971 0.0692 0.0635 0.0568 0.0572 0.0686 0.0624 0.0522 0.0496 0.0494 0.0507 0.0521 0.0510 0.0524 0.0533 0.0547 

[TRAIN] Epoch[4](754/1500); Loss: 0.104411; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2188 0.1224 0.0990 0.1290 0.1207 0.1023 0.0879 0.0942 0.0876 0.0913 0.0868 0.0823 0.0831 0.0879 0.0905 0.0868 

[TRAIN] Epoch[4](755/1500); Loss: 0.095787; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2284 0.1532 0.1208 0.1201 0.1146 0.1003 0.0854 0.0762 0.0727 0.0674 0.0665 0.0665 0.0646 0.0638 0.0646 0.0672 

[TRAIN] Epoch[4](756/1500); Loss: 0.071975; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1976 0.0902 0.0748 0.1148 0.0996 0.0657 0.0432 0.0654 0.0570 0.0467 0.0467 0.0461 0.0482 0.0498 0.0523 0.0535 

[TRAIN] Epoch[4](757/1500); Loss: 0.111601; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1502 0.1159 0.1199 0.1221 0.1156 0.1097 0.1108 0.1056 0.1044 0.1047 0.1041 0.1030 0.1041 0.1046 0.1052 0.1056 

[TRAIN] Epoch[4](758/1500); Loss: 0.066163; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0878 0.0954 0.0967 0.0734 0.0662 0.0644 0.0579 0.0603 0.0588 0.0561 0.0543 0.0546 0.0563 0.0591 0.0581 0.0591 

[TRAIN] Epoch[4](759/1500); Loss: 0.107480; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1253 0.1160 0.1175 0.1104 0.1085 0.1042 0.1054 0.1091 0.1031 0.1034 0.1014 0.1013 0.1026 0.1035 0.1040 0.1038 

[TRAIN] Epoch[4](760/1500); Loss: 0.196795; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2500 0.2097 0.2126 0.2107 0.2023 0.1959 0.1931 0.1884 0.1889 0.1870 0.1845 0.1838 0.1852 0.1865 0.1856 0.1846 

[TRAIN] Epoch[4](761/1500); Loss: 0.071096; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0662 0.0789 0.0802 0.0764 0.0716 0.0800 0.0725 0.0655 0.0651 0.0661 0.0669 0.0675 0.0674 0.0694 0.0722 0.0715 

[TRAIN] Epoch[4](762/1500); Loss: 0.106923; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1351 0.1260 0.1394 0.1327 0.1177 0.1062 0.0995 0.0951 0.0972 0.0941 0.0934 0.0938 0.0944 0.0956 0.0946 0.0959 

[TRAIN] Epoch[4](763/1500); Loss: 0.102290; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2437 0.1586 0.1077 0.1088 0.1129 0.0963 0.0759 0.0756 0.0718 0.0819 0.0806 0.0762 0.0803 0.0858 0.0899 0.0907 

[TRAIN] Epoch[4](764/1500); Loss: 0.100165; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1107 0.1217 0.1230 0.1128 0.1059 0.0988 0.0935 0.0927 0.0948 0.0923 0.0912 0.0914 0.0924 0.0933 0.0945 0.0936 

[TRAIN] Epoch[4](765/1500); Loss: 0.077455; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1147 0.0836 0.0781 0.0785 0.0751 0.0743 0.0802 0.0834 0.0737 0.0706 0.0703 0.0703 0.0708 0.0712 0.0718 0.0728 

[TRAIN] Epoch[4](766/1500); Loss: 0.089974; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2681 0.1327 0.0979 0.0937 0.1061 0.0914 0.0715 0.0599 0.0602 0.0635 0.0689 0.0615 0.0670 0.0604 0.0671 0.0696 

[TRAIN] Epoch[4](767/1500); Loss: 0.134635; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1956 0.1504 0.1431 0.1473 0.1429 0.1345 0.1297 0.1297 0.1246 0.1250 0.1232 0.1210 0.1213 0.1217 0.1223 0.1215 

[TRAIN] Epoch[4](768/1500); Loss: 0.063968; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0996 0.0721 0.0708 0.0607 0.0558 0.0543 0.0583 0.0578 0.0574 0.0574 0.0566 0.0598 0.0625 0.0650 0.0661 0.0694 

[TRAIN] Epoch[4](769/1500); Loss: 0.074431; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1198 0.0777 0.0760 0.0742 0.0689 0.0665 0.0718 0.0730 0.0676 0.0679 0.0666 0.0677 0.0703 0.0744 0.0742 0.0744 

[TRAIN] Epoch[4](770/1500); Loss: 0.101560; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1789 0.1335 0.1121 0.1082 0.1070 0.0978 0.0922 0.0925 0.0885 0.0903 0.0879 0.0854 0.0857 0.0881 0.0895 0.0875 

[TRAIN] Epoch[4](771/1500); Loss: 0.143898; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1942 0.1717 0.1684 0.1760 0.1685 0.1531 0.1339 0.1232 0.1301 0.1279 0.1275 0.1236 0.1231 0.1263 0.1268 0.1279 

[TRAIN] Epoch[4](772/1500); Loss: 0.096744; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1665 0.1124 0.0968 0.0976 0.0974 0.0909 0.0901 0.0926 0.0865 0.0901 0.0873 0.0852 0.0880 0.0880 0.0901 0.0885 

[TRAIN] Epoch[4](773/1500); Loss: 0.133518; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2333 0.1825 0.1541 0.1312 0.1372 0.1325 0.1255 0.1168 0.1202 0.1153 0.1162 0.1146 0.1121 0.1143 0.1144 0.1162 

[TRAIN] Epoch[4](774/1500); Loss: 0.081379; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1302 0.1029 0.1007 0.0933 0.0829 0.0760 0.0761 0.0724 0.0703 0.0709 0.0710 0.0709 0.0700 0.0710 0.0716 0.0715 

[TRAIN] Epoch[4](775/1500); Loss: 0.124966; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2669 0.1475 0.1174 0.1558 0.1498 0.1262 0.0997 0.0975 0.0946 0.1183 0.1130 0.1019 0.0945 0.1002 0.1057 0.1103 

[TRAIN] Epoch[4](776/1500); Loss: 0.106570; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1861 0.1411 0.1231 0.1119 0.1095 0.1035 0.0955 0.0900 0.0889 0.0922 0.0916 0.0907 0.0921 0.0970 0.0965 0.0955 

[TRAIN] Epoch[4](777/1500); Loss: 0.092948; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1640 0.1187 0.1092 0.1051 0.0977 0.0931 0.0882 0.0806 0.0799 0.0784 0.0779 0.0800 0.0782 0.0785 0.0783 0.0796 

[TRAIN] Epoch[4](778/1500); Loss: 0.144807; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2076 0.1680 0.1507 0.1582 0.1503 0.1359 0.1271 0.1273 0.1300 0.1361 0.1335 0.1316 0.1347 0.1395 0.1430 0.1433 

[TRAIN] Epoch[4](779/1500); Loss: 0.138302; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2253 0.1735 0.1581 0.1641 0.1593 0.1455 0.1304 0.1212 0.1185 0.1172 0.1167 0.1160 0.1158 0.1158 0.1170 0.1183 

[TRAIN] Epoch[4](780/1500); Loss: 0.134194; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2639 0.1744 0.1755 0.1985 0.1878 0.1658 0.1392 0.0981 0.0901 0.0985 0.0924 0.0930 0.0908 0.0910 0.0940 0.0941 

[TRAIN] Epoch[4](781/1500); Loss: 0.075897; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1030 0.0929 0.0963 0.0885 0.0837 0.0781 0.0706 0.0721 0.0672 0.0666 0.0662 0.0645 0.0654 0.0650 0.0674 0.0669 

[TRAIN] Epoch[4](782/1500); Loss: 0.139345; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2364 0.1755 0.1523 0.1667 0.1617 0.1449 0.1228 0.1233 0.1223 0.1177 0.1164 0.1160 0.1173 0.1199 0.1179 0.1184 

[TRAIN] Epoch[4](783/1500); Loss: 0.122456; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2632 0.1699 0.1309 0.1205 0.1226 0.1139 0.1076 0.1061 0.1070 0.1049 0.1037 0.1005 0.1000 0.1025 0.1031 0.1029 

[TRAIN] Epoch[4](784/1500); Loss: 0.101236; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2639 0.1717 0.1277 0.1231 0.1136 0.1000 0.0740 0.0776 0.0820 0.0692 0.0696 0.0675 0.0677 0.0702 0.0702 0.0717 

[TRAIN] Epoch[4](785/1500); Loss: 0.132020; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2291 0.1836 0.1707 0.1551 0.1486 0.1356 0.1199 0.1079 0.1118 0.1071 0.1117 0.1072 0.1037 0.1039 0.1083 0.1081 

[TRAIN] Epoch[4](786/1500); Loss: 0.071132; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1091 0.0960 0.0894 0.0792 0.0706 0.0648 0.0630 0.0615 0.0628 0.0615 0.0603 0.0608 0.0640 0.0645 0.0643 0.0663 

[TRAIN] Epoch[4](787/1500); Loss: 0.091739; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1917 0.1138 0.0897 0.1028 0.0998 0.0862 0.0751 0.0774 0.0759 0.0815 0.0780 0.0746 0.0756 0.0808 0.0830 0.0819 

[TRAIN] Epoch[4](788/1500); Loss: 0.057920; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0486 0.0862 0.0814 0.0573 0.0536 0.0511 0.0497 0.0508 0.0513 0.0530 0.0536 0.0543 0.0559 0.0583 0.0600 0.0617 

[TRAIN] Epoch[4](789/1500); Loss: 0.164875; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.2481 0.2041 0.1874 0.1793 0.1781 0.1708 0.1594 0.1508 0.1496 0.1463 0.1465 0.1439 0.1426 0.1433 0.1435 0.1442 

[TRAIN] Epoch[4](790/1500); Loss: 0.156354; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1647 0.1665 0.1762 0.1711 0.1650 0.1583 0.1546 0.1525 0.1506 0.1508 0.1492 0.1484 0.1477 0.1483 0.1493 0.1486 

[TRAIN] Epoch[4](791/1500); Loss: 0.103451; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2260 0.1534 0.1195 0.1171 0.1194 0.1061 0.0900 0.0876 0.0835 0.0795 0.0790 0.0775 0.0782 0.0789 0.0794 0.0803 

[TRAIN] Epoch[4](792/1500); Loss: 0.078225; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1897 0.1260 0.0923 0.0748 0.0785 0.0726 0.0649 0.0677 0.0634 0.0609 0.0607 0.0589 0.0599 0.0592 0.0622 0.0600 

[TRAIN] Epoch[4](793/1500); Loss: 0.144562; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1672 0.1495 0.1571 0.1558 0.1500 0.1429 0.1424 0.1419 0.1401 0.1395 0.1370 0.1363 0.1369 0.1386 0.1390 0.1387 

[TRAIN] Epoch[4](794/1500); Loss: 0.156550; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1703 0.1689 0.1762 0.1720 0.1668 0.1588 0.1534 0.1529 0.1499 0.1501 0.1487 0.1473 0.1475 0.1477 0.1476 0.1467 

[TRAIN] Epoch[4](795/1500); Loss: 0.094447; Backpropagation: 0.0924 sec; Batch: 0.4245 sec
0.1197 0.1057 0.1186 0.1091 0.0988 0.0894 0.0944 0.0922 0.0858 0.0848 0.0842 0.0859 0.0857 0.0854 0.0851 0.0861 

[TRAIN] Epoch[4](796/1500); Loss: 0.094013; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1802 0.1350 0.1154 0.0982 0.0966 0.0899 0.0819 0.0771 0.0839 0.0806 0.0779 0.0766 0.0772 0.0783 0.0784 0.0768 

[TRAIN] Epoch[4](797/1500); Loss: 0.097684; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1316 0.1004 0.0965 0.0995 0.0979 0.0992 0.1035 0.0963 0.0926 0.0920 0.0919 0.0924 0.0921 0.0923 0.0925 0.0924 

[TRAIN] Epoch[4](798/1500); Loss: 0.095080; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.3600 0.2182 0.1148 0.0566 0.0917 0.0924 0.0726 0.0559 0.0508 0.0533 0.0688 0.0594 0.0506 0.0519 0.0607 0.0636 

[TRAIN] Epoch[4](799/1500); Loss: 0.110243; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2953 0.2079 0.1518 0.1016 0.0998 0.0980 0.0862 0.0746 0.0877 0.0763 0.0863 0.0841 0.0787 0.0760 0.0771 0.0825 

[TRAIN] Epoch[4](800/1500); Loss: 0.153755; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2406 0.1932 0.1712 0.1642 0.1597 0.1532 0.1435 0.1363 0.1368 0.1398 0.1385 0.1349 0.1351 0.1366 0.1388 0.1377 

[TRAIN] Epoch[4](801/1500); Loss: 0.091782; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1693 0.1297 0.1062 0.0958 0.0891 0.0841 0.0815 0.0809 0.0797 0.0794 0.0788 0.0787 0.0780 0.0787 0.0790 0.0795 

[TRAIN] Epoch[4](802/1500); Loss: 0.113326; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1482 0.1278 0.1294 0.1295 0.1219 0.1137 0.1073 0.1023 0.1028 0.1018 0.1008 0.1018 0.1061 0.1062 0.1053 0.1082 

[TRAIN] Epoch[4](803/1500); Loss: 0.101751; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1955 0.1316 0.1141 0.1226 0.1202 0.1102 0.0992 0.0878 0.0797 0.0806 0.0798 0.0786 0.0804 0.0820 0.0823 0.0834 

[TRAIN] Epoch[4](804/1500); Loss: 0.167236; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.2713 0.1960 0.1921 0.1884 0.1858 0.1705 0.1634 0.1428 0.1487 0.1488 0.1471 0.1420 0.1438 0.1432 0.1473 0.1445 

[TRAIN] Epoch[4](805/1500); Loss: 0.124741; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1972 0.1594 0.1423 0.1345 0.1303 0.1249 0.1191 0.1149 0.1114 0.1089 0.1091 0.1096 0.1101 0.1086 0.1075 0.1082 

[TRAIN] Epoch[4](806/1500); Loss: 0.069911; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1202 0.0736 0.0729 0.0761 0.0692 0.0602 0.0707 0.0831 0.0648 0.0636 0.0584 0.0580 0.0618 0.0613 0.0637 0.0609 

[TRAIN] Epoch[4](807/1500); Loss: 0.094604; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1582 0.1288 0.1143 0.1023 0.0977 0.0945 0.0871 0.0876 0.0836 0.0802 0.0805 0.0795 0.0807 0.0794 0.0794 0.0801 

[TRAIN] Epoch[4](808/1500); Loss: 0.074268; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1106 0.0990 0.0953 0.0822 0.0713 0.0690 0.0713 0.0663 0.0663 0.0644 0.0636 0.0645 0.0648 0.0650 0.0665 0.0684 

[TRAIN] Epoch[4](809/1500); Loss: 0.105566; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1894 0.1197 0.1041 0.1163 0.1091 0.0967 0.0949 0.1001 0.0918 0.0939 0.0934 0.0941 0.0942 0.0960 0.0978 0.0975 

[TRAIN] Epoch[4](810/1500); Loss: 0.076776; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2505 0.1568 0.0947 0.0662 0.0677 0.0636 0.0558 0.0608 0.0575 0.0509 0.0508 0.0495 0.0507 0.0505 0.0504 0.0520 

[TRAIN] Epoch[4](811/1500); Loss: 0.119564; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.2744 0.1991 0.1474 0.1076 0.1052 0.1011 0.0927 0.0893 0.0957 0.0941 0.0996 0.0988 0.0976 0.0997 0.1037 0.1069 

[TRAIN] Epoch[4](812/1500); Loss: 0.066540; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.0880 0.0844 0.0900 0.0677 0.0627 0.0595 0.0572 0.0592 0.0586 0.0580 0.0601 0.0611 0.0606 0.0626 0.0674 0.0677 

[TRAIN] Epoch[4](813/1500); Loss: 0.112612; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1566 0.1184 0.1157 0.1165 0.1140 0.1094 0.1099 0.1073 0.1056 0.1064 0.1059 0.1063 0.1070 0.1075 0.1074 0.1079 

[TRAIN] Epoch[4](814/1500); Loss: 0.098748; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1983 0.1215 0.0991 0.1067 0.0997 0.0907 0.0894 0.0907 0.0869 0.0871 0.0845 0.0833 0.0840 0.0859 0.0866 0.0857 

[TRAIN] Epoch[4](815/1500); Loss: 0.112554; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1397 0.1373 0.1362 0.1222 0.1151 0.1126 0.1111 0.1088 0.1041 0.1017 0.1018 0.1035 0.1022 0.1008 0.1009 0.1028 

[TRAIN] Epoch[4](816/1500); Loss: 0.170344; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2819 0.2250 0.2058 0.2121 0.2045 0.1905 0.1720 0.1520 0.1381 0.1408 0.1376 0.1351 0.1341 0.1324 0.1323 0.1313 

[TRAIN] Epoch[4](817/1500); Loss: 0.151373; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2718 0.2061 0.1706 0.1603 0.1633 0.1526 0.1389 0.1321 0.1315 0.1281 0.1302 0.1280 0.1270 0.1275 0.1269 0.1270 

[TRAIN] Epoch[4](818/1500); Loss: 0.093662; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1184 0.1174 0.1169 0.1062 0.1006 0.0949 0.0881 0.0888 0.0874 0.0858 0.0841 0.0826 0.0821 0.0826 0.0817 0.0810 

[TRAIN] Epoch[4](819/1500); Loss: 0.121584; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1532 0.1414 0.1558 0.1520 0.1363 0.1196 0.1180 0.1102 0.1103 0.1100 0.1070 0.1068 0.1073 0.1054 0.1061 0.1059 

[TRAIN] Epoch[4](820/1500); Loss: 0.100193; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2610 0.1781 0.1178 0.0954 0.0928 0.0858 0.0784 0.0823 0.0780 0.0775 0.0757 0.0741 0.0759 0.0778 0.0770 0.0756 

[TRAIN] Epoch[4](821/1500); Loss: 0.088868; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1679 0.1172 0.1015 0.0927 0.0858 0.0863 0.0928 0.0822 0.0768 0.0755 0.0754 0.0746 0.0723 0.0730 0.0740 0.0738 

[TRAIN] Epoch[4](822/1500); Loss: 0.076310; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.0854 0.0905 0.1031 0.0913 0.0755 0.0701 0.0694 0.0701 0.0705 0.0659 0.0678 0.0735 0.0701 0.0726 0.0726 0.0727 

[TRAIN] Epoch[4](823/1500); Loss: 0.131574; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1816 0.1499 0.1481 0.1484 0.1404 0.1294 0.1200 0.1133 0.1144 0.1217 0.1194 0.1175 0.1188 0.1227 0.1292 0.1306 

[TRAIN] Epoch[4](824/1500); Loss: 0.087527; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1839 0.1129 0.0991 0.0975 0.0911 0.0787 0.0751 0.0733 0.0714 0.0739 0.0712 0.0707 0.0728 0.0769 0.0763 0.0757 

[TRAIN] Epoch[4](825/1500); Loss: 0.113408; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1581 0.1342 0.1304 0.1324 0.1293 0.1180 0.1073 0.1081 0.1027 0.1021 0.0993 0.0967 0.0989 0.0975 0.1010 0.0986 

[TRAIN] Epoch[4](826/1500); Loss: 0.060115; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0638 0.0728 0.0764 0.0645 0.0571 0.0586 0.0626 0.0595 0.0561 0.0542 0.0539 0.0547 0.0549 0.0560 0.0574 0.0594 

[TRAIN] Epoch[4](827/1500); Loss: 0.103276; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2182 0.1359 0.1047 0.1095 0.1097 0.0982 0.0889 0.0911 0.0871 0.0852 0.0847 0.0854 0.0880 0.0888 0.0880 0.0890 

[TRAIN] Epoch[4](828/1500); Loss: 0.103812; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1371 0.1339 0.1293 0.1209 0.1141 0.1075 0.0981 0.0936 0.0920 0.0914 0.0920 0.0900 0.0895 0.0893 0.0905 0.0917 

[TRAIN] Epoch[4](829/1500); Loss: 0.099786; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1026 0.1199 0.1236 0.1029 0.1023 0.0949 0.0921 0.0917 0.0948 0.0953 0.0939 0.0919 0.0940 0.0979 0.1002 0.0986 

[TRAIN] Epoch[4](830/1500); Loss: 0.101180; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1370 0.1181 0.1225 0.1179 0.1113 0.1007 0.0954 0.0905 0.0893 0.0896 0.0884 0.0889 0.0907 0.0925 0.0923 0.0938 

[TRAIN] Epoch[4](831/1500); Loss: 0.118310; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1664 0.1321 0.1147 0.1122 0.1114 0.1091 0.1099 0.1127 0.1099 0.1103 0.1119 0.1144 0.1167 0.1173 0.1208 0.1230 

[TRAIN] Epoch[4](832/1500); Loss: 0.120187; Backpropagation: 0.0916 sec; Batch: 0.4241 sec
0.1778 0.1275 0.1356 0.1351 0.1274 0.1175 0.1203 0.1106 0.1129 0.1107 0.1078 0.1078 0.1086 0.1085 0.1074 0.1076 

[TRAIN] Epoch[4](833/1500); Loss: 0.122995; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3010 0.2047 0.1399 0.1155 0.1189 0.1113 0.0986 0.0976 0.0989 0.0989 0.1003 0.0967 0.0938 0.0952 0.0985 0.0981 

[TRAIN] Epoch[4](834/1500); Loss: 0.112106; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1377 0.1238 0.1240 0.1204 0.1155 0.1140 0.1107 0.1057 0.1050 0.1051 0.1046 0.1046 0.1054 0.1056 0.1053 0.1063 

[TRAIN] Epoch[4](835/1500); Loss: 0.061192; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0714 0.0864 0.0896 0.0688 0.0607 0.0566 0.0563 0.0542 0.0528 0.0531 0.0531 0.0535 0.0544 0.0550 0.0558 0.0572 

[TRAIN] Epoch[4](836/1500); Loss: 0.072436; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1285 0.0959 0.0913 0.0857 0.0776 0.0683 0.0651 0.0711 0.0674 0.0599 0.0567 0.0570 0.0579 0.0580 0.0594 0.0591 

[TRAIN] Epoch[4](837/1500); Loss: 0.120090; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1649 0.1469 0.1388 0.1307 0.1238 0.1156 0.1116 0.1129 0.1110 0.1093 0.1062 0.1091 0.1095 0.1116 0.1110 0.1085 

[TRAIN] Epoch[4](838/1500); Loss: 0.124653; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2155 0.1650 0.1398 0.1341 0.1318 0.1212 0.1130 0.1148 0.1085 0.1111 0.1086 0.1063 0.1071 0.1068 0.1050 0.1059 

[TRAIN] Epoch[4](839/1500); Loss: 0.116304; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2090 0.1477 0.1341 0.1390 0.1305 0.1174 0.1064 0.1027 0.0998 0.0968 0.0955 0.0954 0.0956 0.0958 0.0975 0.0977 

[TRAIN] Epoch[4](840/1500); Loss: 0.128243; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1771 0.1526 0.1446 0.1384 0.1352 0.1263 0.1208 0.1183 0.1187 0.1183 0.1161 0.1160 0.1156 0.1188 0.1179 0.1171 

[TRAIN] Epoch[4](841/1500); Loss: 0.084785; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1085 0.1002 0.1144 0.1055 0.0865 0.0706 0.0771 0.0701 0.0781 0.0761 0.0731 0.0751 0.0773 0.0831 0.0810 0.0796 

[TRAIN] Epoch[4](842/1500); Loss: 0.127790; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1810 0.1413 0.1318 0.1274 0.1238 0.1240 0.1238 0.1208 0.1200 0.1191 0.1229 0.1226 0.1210 0.1214 0.1216 0.1221 

[TRAIN] Epoch[4](843/1500); Loss: 0.076880; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1460 0.1072 0.0964 0.0882 0.0773 0.0692 0.0698 0.0652 0.0627 0.0643 0.0639 0.0637 0.0633 0.0638 0.0643 0.0647 

[TRAIN] Epoch[4](844/1500); Loss: 0.119799; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.2740 0.1751 0.1582 0.1996 0.1868 0.1544 0.0997 0.0722 0.0826 0.0774 0.0738 0.0706 0.0716 0.0750 0.0726 0.0732 

[TRAIN] Epoch[4](845/1500); Loss: 0.152993; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2833 0.2031 0.1604 0.1517 0.1573 0.1494 0.1378 0.1323 0.1377 0.1374 0.1364 0.1321 0.1291 0.1312 0.1345 0.1342 

[TRAIN] Epoch[4](846/1500); Loss: 0.080821; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.0794 0.1089 0.1164 0.0884 0.0783 0.0764 0.0754 0.0761 0.0759 0.0736 0.0736 0.0746 0.0742 0.0735 0.0733 0.0751 

[TRAIN] Epoch[4](847/1500); Loss: 0.115407; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2082 0.1254 0.1116 0.1434 0.1365 0.1151 0.0993 0.1053 0.0965 0.1055 0.1019 0.0968 0.0983 0.1010 0.1020 0.0996 

[TRAIN] Epoch[4](848/1500); Loss: 0.120899; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1893 0.1332 0.1281 0.1393 0.1316 0.1187 0.1134 0.1170 0.1122 0.1079 0.1072 0.1059 0.1063 0.1071 0.1088 0.1083 

[TRAIN] Epoch[4](849/1500); Loss: 0.069972; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1275 0.0837 0.0763 0.0842 0.0816 0.0682 0.0597 0.0731 0.0636 0.0592 0.0578 0.0547 0.0556 0.0579 0.0597 0.0568 

[TRAIN] Epoch[4](850/1500); Loss: 0.135037; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2414 0.1828 0.1660 0.1523 0.1434 0.1324 0.1192 0.1139 0.1122 0.1179 0.1158 0.1106 0.1093 0.1128 0.1170 0.1137 

[TRAIN] Epoch[4](851/1500); Loss: 0.135766; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.2198 0.1636 0.1386 0.1479 0.1446 0.1340 0.1238 0.1276 0.1253 0.1238 0.1210 0.1203 0.1205 0.1211 0.1207 0.1196 

[TRAIN] Epoch[4](852/1500); Loss: 0.124722; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2416 0.1737 0.1408 0.1238 0.1212 0.1160 0.1110 0.1104 0.1068 0.1072 0.1069 0.1065 0.1071 0.1073 0.1072 0.1080 

[TRAIN] Epoch[4](853/1500); Loss: 0.105512; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1109 0.1204 0.1237 0.1159 0.1029 0.1028 0.0998 0.0981 0.0995 0.0980 0.1003 0.1010 0.1015 0.1035 0.1041 0.1059 

[TRAIN] Epoch[4](854/1500); Loss: 0.123472; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1952 0.1616 0.1530 0.1503 0.1349 0.1173 0.1080 0.1038 0.1079 0.1067 0.1041 0.1009 0.1044 0.1083 0.1090 0.1100 

[TRAIN] Epoch[4](855/1500); Loss: 0.126402; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2196 0.1547 0.1412 0.1552 0.1461 0.1270 0.1093 0.1114 0.1077 0.1102 0.1072 0.1048 0.1055 0.1055 0.1092 0.1078 

[TRAIN] Epoch[4](856/1500); Loss: 0.125716; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2827 0.1978 0.1434 0.1169 0.1241 0.1176 0.1054 0.1008 0.1026 0.1003 0.1027 0.1016 0.1020 0.1040 0.1043 0.1053 

[TRAIN] Epoch[4](857/1500); Loss: 0.096195; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1187 0.1240 0.1226 0.1107 0.1016 0.0947 0.0911 0.0897 0.0885 0.0862 0.0853 0.0853 0.0846 0.0843 0.0859 0.0860 

[TRAIN] Epoch[4](858/1500); Loss: 0.100638; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2110 0.1595 0.1287 0.1050 0.0991 0.0962 0.0906 0.0841 0.0825 0.0814 0.0800 0.0789 0.0782 0.0781 0.0783 0.0787 

[TRAIN] Epoch[4](859/1500); Loss: 0.110713; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1697 0.1317 0.1218 0.1194 0.1124 0.1078 0.1050 0.1024 0.1007 0.0998 0.0999 0.1003 0.0999 0.0995 0.1001 0.1010 

[TRAIN] Epoch[4](860/1500); Loss: 0.118237; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1484 0.1360 0.1380 0.1339 0.1252 0.1175 0.1119 0.1099 0.1092 0.1086 0.1077 0.1072 0.1082 0.1089 0.1101 0.1111 

[TRAIN] Epoch[4](861/1500); Loss: 0.162547; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2574 0.2131 0.1947 0.1864 0.1723 0.1680 0.1558 0.1450 0.1372 0.1391 0.1378 0.1408 0.1386 0.1375 0.1378 0.1392 

[TRAIN] Epoch[4](862/1500); Loss: 0.106185; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1599 0.1255 0.1183 0.1152 0.1044 0.0936 0.0883 0.0877 0.0970 0.0961 0.0938 0.0954 0.1014 0.1059 0.1065 0.1100 

[TRAIN] Epoch[4](863/1500); Loss: 0.071204; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1203 0.0888 0.0867 0.0889 0.0786 0.0685 0.0665 0.0632 0.0614 0.0608 0.0591 0.0583 0.0591 0.0598 0.0599 0.0595 

[TRAIN] Epoch[4](864/1500); Loss: 0.109185; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2134 0.1429 0.1098 0.1180 0.1170 0.1064 0.0960 0.0970 0.0933 0.0958 0.0933 0.0924 0.0927 0.0930 0.0933 0.0927 

[TRAIN] Epoch[4](865/1500); Loss: 0.116101; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2227 0.1435 0.1130 0.1266 0.1319 0.1158 0.0967 0.0942 0.0954 0.1043 0.1033 0.0978 0.0975 0.1000 0.1070 0.1078 

[TRAIN] Epoch[4](866/1500); Loss: 0.105860; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2053 0.1222 0.1098 0.1273 0.1179 0.0999 0.0961 0.0962 0.0915 0.0904 0.0883 0.0880 0.0886 0.0913 0.0908 0.0903 

[TRAIN] Epoch[4](867/1500); Loss: 0.168627; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2729 0.2108 0.1974 0.2035 0.1982 0.1815 0.1591 0.1382 0.1399 0.1410 0.1422 0.1416 0.1417 0.1425 0.1435 0.1441 

[TRAIN] Epoch[4](868/1500); Loss: 0.118805; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1858 0.1398 0.1308 0.1296 0.1275 0.1184 0.1103 0.1064 0.1086 0.1093 0.1062 0.1051 0.1050 0.1064 0.1066 0.1052 

[TRAIN] Epoch[4](869/1500); Loss: 0.153582; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1806 0.1646 0.1646 0.1693 0.1631 0.1553 0.1505 0.1479 0.1474 0.1473 0.1474 0.1442 0.1432 0.1438 0.1448 0.1435 

[TRAIN] Epoch[4](870/1500); Loss: 0.096434; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1611 0.1268 0.1264 0.1305 0.1166 0.0981 0.0818 0.0778 0.0825 0.0781 0.0739 0.0742 0.0780 0.0818 0.0782 0.0773 

[TRAIN] Epoch[4](871/1500); Loss: 0.091213; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1890 0.1127 0.0945 0.1031 0.1014 0.0871 0.0743 0.0722 0.0745 0.0813 0.0766 0.0729 0.0734 0.0812 0.0842 0.0811 

[TRAIN] Epoch[4](872/1500); Loss: 0.166070; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2702 0.1984 0.1691 0.1798 0.1791 0.1661 0.1512 0.1434 0.1459 0.1490 0.1488 0.1479 0.1484 0.1538 0.1536 0.1526 

[TRAIN] Epoch[4](873/1500); Loss: 0.087188; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1436 0.1145 0.1059 0.0935 0.0849 0.0790 0.0777 0.0762 0.0791 0.0760 0.0757 0.0764 0.0771 0.0775 0.0787 0.0792 

[TRAIN] Epoch[4](874/1500); Loss: 0.124827; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1952 0.1498 0.1336 0.1323 0.1299 0.1227 0.1181 0.1171 0.1172 0.1146 0.1119 0.1102 0.1114 0.1119 0.1108 0.1104 

[TRAIN] Epoch[4](875/1500); Loss: 0.099530; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2683 0.1487 0.0879 0.1230 0.1205 0.0969 0.0687 0.0713 0.0654 0.0828 0.0759 0.0689 0.0683 0.0825 0.0847 0.0785 

[TRAIN] Epoch[4](876/1500); Loss: 0.140041; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2075 0.1823 0.1803 0.1703 0.1633 0.1450 0.1275 0.1181 0.1237 0.1205 0.1185 0.1129 0.1141 0.1183 0.1203 0.1182 

[TRAIN] Epoch[4](877/1500); Loss: 0.104281; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1907 0.1242 0.1087 0.1201 0.1124 0.0984 0.0921 0.0917 0.0916 0.0924 0.0902 0.0899 0.0902 0.0924 0.0919 0.0915 

[TRAIN] Epoch[4](878/1500); Loss: 0.117909; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2803 0.1880 0.1294 0.1107 0.1101 0.1072 0.1010 0.0967 0.0940 0.0937 0.0928 0.0943 0.0963 0.0968 0.0980 0.0974 

[TRAIN] Epoch[4](879/1500); Loss: 0.128865; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1916 0.1444 0.1371 0.1435 0.1418 0.1334 0.1232 0.1178 0.1163 0.1192 0.1164 0.1139 0.1137 0.1162 0.1167 0.1167 

[TRAIN] Epoch[4](880/1500); Loss: 0.101601; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.2252 0.1567 0.1203 0.1137 0.1150 0.1024 0.0890 0.0838 0.0810 0.0792 0.0771 0.0782 0.0754 0.0773 0.0763 0.0749 

[TRAIN] Epoch[4](881/1500); Loss: 0.101355; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1312 0.0932 0.1285 0.1280 0.1113 0.0919 0.0880 0.0872 0.0977 0.0935 0.0907 0.0921 0.0959 0.0982 0.0962 0.0981 

[TRAIN] Epoch[4](882/1500); Loss: 0.139465; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2147 0.1639 0.1481 0.1581 0.1580 0.1417 0.1241 0.1201 0.1195 0.1294 0.1293 0.1237 0.1214 0.1233 0.1263 0.1299 

[TRAIN] Epoch[4](883/1500); Loss: 0.145717; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1729 0.1629 0.1501 0.1464 0.1451 0.1395 0.1332 0.1276 0.1352 0.1391 0.1405 0.1401 0.1411 0.1498 0.1539 0.1540 

[TRAIN] Epoch[4](884/1500); Loss: 0.088358; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1235 0.1024 0.1086 0.1101 0.0978 0.0826 0.0775 0.0745 0.0781 0.0772 0.0761 0.0770 0.0788 0.0821 0.0828 0.0846 

[TRAIN] Epoch[4](885/1500); Loss: 0.095804; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1686 0.1369 0.1277 0.1085 0.0933 0.0901 0.0863 0.0827 0.0791 0.0823 0.0803 0.0798 0.0792 0.0791 0.0792 0.0798 

[TRAIN] Epoch[4](886/1500); Loss: 0.083535; Backpropagation: 0.0921 sec; Batch: 0.4229 sec
0.2070 0.1406 0.1037 0.0887 0.0874 0.0679 0.0510 0.0549 0.0601 0.0629 0.0585 0.0622 0.0665 0.0753 0.0757 0.0742 

[TRAIN] Epoch[4](887/1500); Loss: 0.106050; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1559 0.1327 0.1211 0.1105 0.1061 0.1010 0.0969 0.0963 0.0976 0.0966 0.0955 0.0949 0.0961 0.0991 0.0987 0.0976 

[TRAIN] Epoch[4](888/1500); Loss: 0.178191; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2842 0.2230 0.2082 0.2171 0.2040 0.1798 0.1544 0.1536 0.1542 0.1540 0.1524 0.1499 0.1516 0.1537 0.1565 0.1546 

[TRAIN] Epoch[4](889/1500); Loss: 0.127190; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1892 0.1560 0.1438 0.1354 0.1264 0.1266 0.1229 0.1173 0.1141 0.1150 0.1142 0.1168 0.1152 0.1144 0.1133 0.1143 

[TRAIN] Epoch[4](890/1500); Loss: 0.098257; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2089 0.1257 0.0961 0.1103 0.1150 0.1002 0.0830 0.0777 0.0766 0.0867 0.0828 0.0782 0.0781 0.0837 0.0845 0.0844 

[TRAIN] Epoch[4](891/1500); Loss: 0.097755; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2830 0.1700 0.0871 0.0755 0.0993 0.0898 0.0728 0.0699 0.0629 0.0801 0.0780 0.0732 0.0727 0.0794 0.0827 0.0876 

[TRAIN] Epoch[4](892/1500); Loss: 0.114432; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1317 0.1237 0.1228 0.1160 0.1143 0.1128 0.1095 0.1087 0.1091 0.1123 0.1118 0.1103 0.1099 0.1113 0.1137 0.1132 

[TRAIN] Epoch[4](893/1500); Loss: 0.165825; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1642 0.1680 0.1838 0.1829 0.1768 0.1675 0.1628 0.1626 0.1607 0.1608 0.1597 0.1615 0.1612 0.1603 0.1604 0.1600 

[TRAIN] Epoch[4](894/1500); Loss: 0.142194; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2058 0.1567 0.1494 0.1576 0.1537 0.1443 0.1355 0.1336 0.1302 0.1309 0.1311 0.1295 0.1282 0.1279 0.1306 0.1303 

[TRAIN] Epoch[4](895/1500); Loss: 0.123668; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2114 0.1572 0.1322 0.1247 0.1288 0.1240 0.1139 0.1073 0.1105 0.1125 0.1100 0.1072 0.1076 0.1094 0.1118 0.1102 

[TRAIN] Epoch[4](896/1500); Loss: 0.130382; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1889 0.1376 0.1436 0.1543 0.1464 0.1315 0.1185 0.1222 0.1167 0.1222 0.1194 0.1157 0.1146 0.1173 0.1187 0.1184 

[TRAIN] Epoch[4](897/1500); Loss: 0.141513; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1981 0.1702 0.1752 0.1778 0.1715 0.1614 0.1427 0.1300 0.1220 0.1202 0.1178 0.1139 0.1137 0.1143 0.1174 0.1178 

[TRAIN] Epoch[4](898/1500); Loss: 0.142758; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.2022 0.1701 0.1579 0.1519 0.1499 0.1419 0.1348 0.1330 0.1323 0.1324 0.1308 0.1288 0.1281 0.1296 0.1305 0.1300 

[TRAIN] Epoch[4](899/1500); Loss: 0.127391; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1706 0.1574 0.1537 0.1492 0.1425 0.1324 0.1224 0.1162 0.1168 0.1135 0.1135 0.1125 0.1106 0.1093 0.1085 0.1092 

[TRAIN] Epoch[4](900/1500); Loss: 0.121882; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1676 0.1420 0.1412 0.1428 0.1362 0.1216 0.1122 0.1062 0.1122 0.1132 0.1090 0.1063 0.1077 0.1090 0.1125 0.1106 

[TRAIN] Epoch[4](901/1500); Loss: 0.088037; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1758 0.1154 0.0930 0.0991 0.1015 0.0907 0.0785 0.0760 0.0721 0.0748 0.0728 0.0699 0.0707 0.0713 0.0745 0.0724 

[TRAIN] Epoch[4](902/1500); Loss: 0.139457; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2349 0.1883 0.1729 0.1650 0.1529 0.1418 0.1292 0.1192 0.1189 0.1171 0.1161 0.1154 0.1154 0.1144 0.1146 0.1152 

[TRAIN] Epoch[4](903/1500); Loss: 0.114092; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1335 0.1354 0.1596 0.1613 0.1435 0.1202 0.1053 0.0993 0.0996 0.1013 0.0978 0.0951 0.0932 0.0921 0.0937 0.0945 

[TRAIN] Epoch[4](904/1500); Loss: 0.218781; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.3743 0.2800 0.2598 0.2923 0.2797 0.2444 0.1896 0.1590 0.1783 0.1686 0.1761 0.1784 0.1761 0.1782 0.1805 0.1853 

[TRAIN] Epoch[4](905/1500); Loss: 0.164770; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2336 0.1970 0.1857 0.1914 0.1860 0.1766 0.1620 0.1492 0.1427 0.1428 0.1433 0.1445 0.1441 0.1442 0.1462 0.1470 

[TRAIN] Epoch[4](906/1500); Loss: 0.148559; Backpropagation: 0.0923 sec; Batch: 0.4236 sec
0.1757 0.1614 0.1633 0.1624 0.1576 0.1539 0.1501 0.1431 0.1407 0.1399 0.1391 0.1394 0.1379 0.1375 0.1373 0.1376 

[TRAIN] Epoch[4](907/1500); Loss: 0.080810; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0932 0.0901 0.0994 0.0965 0.0894 0.0794 0.0775 0.0759 0.0760 0.0757 0.0730 0.0715 0.0721 0.0745 0.0748 0.0738 

[TRAIN] Epoch[4](908/1500); Loss: 0.127134; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.3788 0.2595 0.1615 0.0814 0.1298 0.1504 0.1314 0.0948 0.0686 0.0781 0.0785 0.0856 0.0796 0.0808 0.0812 0.0939 

[TRAIN] Epoch[4](909/1500); Loss: 0.148784; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2004 0.1742 0.1742 0.1667 0.1587 0.1497 0.1420 0.1367 0.1369 0.1354 0.1347 0.1337 0.1337 0.1346 0.1345 0.1346 

[TRAIN] Epoch[4](910/1500); Loss: 0.115868; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1576 0.1347 0.1253 0.1191 0.1145 0.1104 0.1042 0.1031 0.1034 0.1079 0.1083 0.1080 0.1095 0.1152 0.1164 0.1165 

[TRAIN] Epoch[4](911/1500); Loss: 0.127747; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1908 0.1515 0.1344 0.1365 0.1372 0.1303 0.1211 0.1195 0.1167 0.1158 0.1159 0.1145 0.1152 0.1149 0.1149 0.1147 

[TRAIN] Epoch[4](912/1500); Loss: 0.143444; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1619 0.1496 0.1564 0.1588 0.1541 0.1469 0.1407 0.1366 0.1359 0.1363 0.1356 0.1353 0.1353 0.1364 0.1374 0.1380 

[TRAIN] Epoch[4](913/1500); Loss: 0.057328; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1353 0.0691 0.0586 0.0752 0.0656 0.0481 0.0507 0.0578 0.0413 0.0460 0.0448 0.0424 0.0442 0.0452 0.0468 0.0461 

[TRAIN] Epoch[4](914/1500); Loss: 0.165634; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1979 0.1685 0.1778 0.1845 0.1791 0.1707 0.1629 0.1571 0.1572 0.1573 0.1566 0.1569 0.1559 0.1550 0.1557 0.1570 

[TRAIN] Epoch[4](915/1500); Loss: 0.151448; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2129 0.1887 0.1793 0.1661 0.1539 0.1467 0.1457 0.1439 0.1378 0.1345 0.1337 0.1347 0.1367 0.1362 0.1361 0.1364 

[TRAIN] Epoch[4](916/1500); Loss: 0.118135; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.3114 0.2221 0.1628 0.1156 0.1129 0.1200 0.1044 0.0879 0.0811 0.0823 0.0817 0.0796 0.0785 0.0810 0.0855 0.0835 

[TRAIN] Epoch[4](917/1500); Loss: 0.052747; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1287 0.0492 0.0444 0.0619 0.0546 0.0397 0.0509 0.0548 0.0457 0.0435 0.0410 0.0419 0.0446 0.0478 0.0468 0.0484 

[TRAIN] Epoch[4](918/1500); Loss: 0.078729; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1558 0.1046 0.0876 0.0880 0.0873 0.0767 0.0712 0.0686 0.0651 0.0648 0.0628 0.0645 0.0654 0.0658 0.0657 0.0657 

[TRAIN] Epoch[4](919/1500); Loss: 0.120824; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2446 0.1925 0.1527 0.1173 0.1309 0.1370 0.1211 0.0999 0.0918 0.0902 0.0963 0.0936 0.0896 0.0892 0.0912 0.0953 

[TRAIN] Epoch[4](920/1500); Loss: 0.089358; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1333 0.1094 0.1037 0.1032 0.1001 0.0930 0.0850 0.0826 0.0791 0.0789 0.0780 0.0761 0.0765 0.0775 0.0772 0.0764 

[TRAIN] Epoch[4](921/1500); Loss: 0.061011; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1713 0.0717 0.0552 0.0891 0.0750 0.0482 0.0496 0.0619 0.0402 0.0453 0.0427 0.0416 0.0434 0.0470 0.0474 0.0465 

[TRAIN] Epoch[4](922/1500); Loss: 0.121250; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.3792 0.2779 0.1936 0.1078 0.1001 0.1207 0.1046 0.0777 0.0664 0.0670 0.0721 0.0696 0.0678 0.0689 0.0817 0.0849 

[TRAIN] Epoch[4](923/1500); Loss: 0.145380; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1833 0.1660 0.1784 0.1763 0.1721 0.1555 0.1392 0.1300 0.1277 0.1297 0.1301 0.1275 0.1253 0.1278 0.1281 0.1290 

[TRAIN] Epoch[4](924/1500); Loss: 0.153707; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1734 0.1594 0.1672 0.1704 0.1655 0.1582 0.1504 0.1472 0.1460 0.1473 0.1460 0.1449 0.1459 0.1454 0.1466 0.1456 

[TRAIN] Epoch[4](925/1500); Loss: 0.148022; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2101 0.1657 0.1540 0.1601 0.1599 0.1510 0.1425 0.1407 0.1386 0.1387 0.1358 0.1336 0.1329 0.1354 0.1351 0.1342 

[TRAIN] Epoch[4](926/1500); Loss: 0.074971; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.0894 0.0922 0.0918 0.0793 0.0777 0.0753 0.0711 0.0698 0.0697 0.0691 0.0692 0.0684 0.0683 0.0692 0.0693 0.0698 

[TRAIN] Epoch[4](927/1500); Loss: 0.170202; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.3260 0.2348 0.2251 0.2610 0.2474 0.2137 0.1594 0.1109 0.1160 0.1126 0.1262 0.1228 0.1169 0.1138 0.1192 0.1175 

[TRAIN] Epoch[4](928/1500); Loss: 0.138849; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1696 0.1535 0.1533 0.1489 0.1438 0.1421 0.1422 0.1356 0.1316 0.1304 0.1295 0.1295 0.1284 0.1276 0.1277 0.1279 

[TRAIN] Epoch[4](929/1500); Loss: 0.052332; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0585 0.0803 0.0853 0.0684 0.0642 0.0531 0.0457 0.0470 0.0440 0.0448 0.0411 0.0390 0.0404 0.0422 0.0419 0.0415 

[TRAIN] Epoch[4](930/1500); Loss: 0.065145; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1280 0.0864 0.0727 0.0759 0.0739 0.0654 0.0592 0.0584 0.0515 0.0509 0.0511 0.0529 0.0543 0.0522 0.0539 0.0556 

[TRAIN] Epoch[4](931/1500); Loss: 0.139388; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2302 0.1804 0.1540 0.1536 0.1611 0.1502 0.1338 0.1237 0.1187 0.1197 0.1207 0.1170 0.1162 0.1165 0.1177 0.1168 

[TRAIN] Epoch[4](932/1500); Loss: 0.114129; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1500 0.1226 0.1223 0.1223 0.1159 0.1097 0.1104 0.1087 0.1069 0.1081 0.1073 0.1075 0.1078 0.1089 0.1090 0.1087 

[TRAIN] Epoch[4](933/1500); Loss: 0.151515; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2291 0.1778 0.1688 0.1819 0.1733 0.1561 0.1398 0.1364 0.1348 0.1356 0.1328 0.1314 0.1307 0.1337 0.1317 0.1304 

[TRAIN] Epoch[4](934/1500); Loss: 0.128580; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1638 0.1423 0.1447 0.1454 0.1413 0.1312 0.1214 0.1177 0.1164 0.1192 0.1180 0.1173 0.1179 0.1183 0.1201 0.1222 

[TRAIN] Epoch[4](935/1500); Loss: 0.209817; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2604 0.2352 0.2239 0.2219 0.2179 0.2137 0.2097 0.2025 0.2000 0.1985 0.1973 0.1951 0.1934 0.1964 0.1961 0.1952 

[TRAIN] Epoch[4](936/1500); Loss: 0.100365; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.3754 0.2097 0.0743 0.0727 0.1028 0.0856 0.0547 0.0532 0.0479 0.0709 0.0601 0.0590 0.0668 0.0936 0.0951 0.0842 

[TRAIN] Epoch[4](937/1500); Loss: 0.069710; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1359 0.0600 0.0843 0.0997 0.0877 0.0659 0.0533 0.0558 0.0606 0.0618 0.0569 0.0544 0.0568 0.0588 0.0628 0.0606 

[TRAIN] Epoch[4](938/1500); Loss: 0.101361; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1812 0.1320 0.1124 0.1207 0.1200 0.1057 0.0909 0.0963 0.0874 0.0875 0.0858 0.0827 0.0791 0.0781 0.0814 0.0808 

[TRAIN] Epoch[4](939/1500); Loss: 0.094321; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1819 0.1466 0.1213 0.1007 0.0977 0.0935 0.0848 0.0799 0.0789 0.0772 0.0763 0.0749 0.0739 0.0739 0.0739 0.0739 

[TRAIN] Epoch[4](940/1500); Loss: 0.104125; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1718 0.1385 0.1254 0.1100 0.1053 0.1044 0.0996 0.0963 0.0906 0.0900 0.0898 0.0901 0.0892 0.0881 0.0881 0.0889 

[TRAIN] Epoch[4](941/1500); Loss: 0.146823; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1983 0.1672 0.1732 0.1801 0.1712 0.1538 0.1371 0.1317 0.1300 0.1345 0.1322 0.1276 0.1259 0.1268 0.1303 0.1293 

[TRAIN] Epoch[4](942/1500); Loss: 0.102618; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1208 0.1194 0.1222 0.1147 0.1052 0.0992 0.0975 0.0957 0.0951 0.0945 0.0943 0.0954 0.0957 0.0962 0.0971 0.0988 

[TRAIN] Epoch[4](943/1500); Loss: 0.070665; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2101 0.1011 0.0575 0.0755 0.0749 0.0619 0.0538 0.0537 0.0587 0.0580 0.0517 0.0498 0.0530 0.0599 0.0578 0.0533 

[TRAIN] Epoch[4](944/1500); Loss: 0.108247; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1488 0.1220 0.1163 0.1133 0.1078 0.1034 0.1054 0.1053 0.1039 0.1018 0.1002 0.1004 0.1011 0.1013 0.1004 0.1007 

[TRAIN] Epoch[4](945/1500); Loss: 0.051238; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1176 0.0488 0.0449 0.0600 0.0550 0.0416 0.0445 0.0537 0.0427 0.0459 0.0425 0.0415 0.0422 0.0471 0.0463 0.0456 

[TRAIN] Epoch[4](946/1500); Loss: 0.080753; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1425 0.0768 0.0977 0.1111 0.1075 0.0883 0.0717 0.0672 0.0654 0.0680 0.0663 0.0645 0.0643 0.0669 0.0680 0.0660 

[TRAIN] Epoch[4](947/1500); Loss: 0.094119; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1173 0.1075 0.1063 0.1008 0.0960 0.0942 0.0962 0.0910 0.0871 0.0866 0.0868 0.0873 0.0863 0.0867 0.0875 0.0884 

[TRAIN] Epoch[4](948/1500); Loss: 0.093450; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1247 0.1061 0.1160 0.1146 0.1055 0.0931 0.0888 0.0878 0.0858 0.0843 0.0828 0.0824 0.0810 0.0810 0.0804 0.0809 

[TRAIN] Epoch[4](949/1500); Loss: 0.101689; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1366 0.1225 0.1255 0.1222 0.1150 0.1048 0.0963 0.0914 0.0914 0.0900 0.0892 0.0885 0.0888 0.0880 0.0882 0.0885 

[TRAIN] Epoch[4](950/1500); Loss: 0.116940; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2017 0.1437 0.1263 0.1321 0.1400 0.1288 0.1118 0.1010 0.0986 0.1004 0.1015 0.0980 0.0961 0.0970 0.0980 0.0960 

[TRAIN] Epoch[4](951/1500); Loss: 0.108983; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1792 0.1197 0.1160 0.1290 0.1208 0.1076 0.1003 0.1010 0.0975 0.0977 0.0962 0.0951 0.0952 0.0955 0.0968 0.0962 

[TRAIN] Epoch[4](952/1500); Loss: 0.088745; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2471 0.1548 0.1115 0.1131 0.1050 0.0874 0.0599 0.0671 0.0698 0.0576 0.0580 0.0565 0.0567 0.0576 0.0588 0.0591 

[TRAIN] Epoch[4](953/1500); Loss: 0.087370; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2087 0.1490 0.1179 0.1035 0.0963 0.0834 0.0676 0.0636 0.0622 0.0660 0.0624 0.0603 0.0629 0.0635 0.0663 0.0644 

[TRAIN] Epoch[4](954/1500); Loss: 0.087755; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1297 0.1052 0.0934 0.0992 0.0967 0.0874 0.0791 0.0753 0.0763 0.0802 0.0798 0.0773 0.0773 0.0802 0.0833 0.0835 

[TRAIN] Epoch[4](955/1500); Loss: 0.061729; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1345 0.0647 0.0566 0.0732 0.0649 0.0480 0.0623 0.0611 0.0545 0.0510 0.0483 0.0499 0.0537 0.0559 0.0541 0.0552 

[TRAIN] Epoch[4](956/1500); Loss: 0.079331; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1331 0.1046 0.0969 0.0925 0.0844 0.0753 0.0724 0.0708 0.0676 0.0676 0.0669 0.0672 0.0670 0.0673 0.0675 0.0681 

[TRAIN] Epoch[4](957/1500); Loss: 0.091433; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1366 0.1060 0.1049 0.1029 0.0984 0.0896 0.0849 0.0817 0.0826 0.0819 0.0806 0.0822 0.0816 0.0833 0.0823 0.0834 

[TRAIN] Epoch[4](958/1500); Loss: 0.122175; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2680 0.1816 0.1266 0.1321 0.1422 0.1262 0.1041 0.0960 0.0939 0.1065 0.1015 0.0950 0.0902 0.0961 0.0956 0.0993 

[TRAIN] Epoch[4](959/1500); Loss: 0.099731; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1931 0.1501 0.1309 0.1158 0.1006 0.0924 0.0875 0.0814 0.0778 0.0791 0.0799 0.0795 0.0792 0.0812 0.0833 0.0837 

[TRAIN] Epoch[4](960/1500); Loss: 0.125259; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1534 0.1433 0.1473 0.1435 0.1422 0.1293 0.1179 0.1128 0.1143 0.1203 0.1167 0.1124 0.1100 0.1117 0.1152 0.1140 

[TRAIN] Epoch[4](961/1500); Loss: 0.089556; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0820 0.1114 0.1206 0.1059 0.0988 0.0909 0.0827 0.0809 0.0807 0.0834 0.0824 0.0816 0.0820 0.0829 0.0838 0.0829 

[TRAIN] Epoch[4](962/1500); Loss: 0.115935; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.3880 0.2854 0.1978 0.1088 0.0872 0.0986 0.0826 0.0600 0.0743 0.0582 0.0807 0.0750 0.0648 0.0563 0.0711 0.0663 

[TRAIN] Epoch[4](963/1500); Loss: 0.101113; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1912 0.1423 0.1174 0.1056 0.1007 0.0974 0.0956 0.0919 0.0878 0.0854 0.0845 0.0850 0.0843 0.0826 0.0827 0.0834 

[TRAIN] Epoch[4](964/1500); Loss: 0.096105; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1769 0.1426 0.1203 0.1057 0.0994 0.0961 0.0883 0.0828 0.0800 0.0793 0.0786 0.0778 0.0774 0.0775 0.0774 0.0775 

[TRAIN] Epoch[4](965/1500); Loss: 0.113395; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2318 0.1579 0.1317 0.1365 0.1334 0.1243 0.1071 0.0929 0.0885 0.0921 0.0886 0.0854 0.0852 0.0847 0.0879 0.0864 

[TRAIN] Epoch[4](966/1500); Loss: 0.077189; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1495 0.0998 0.0862 0.0890 0.0822 0.0724 0.0691 0.0661 0.0648 0.0653 0.0644 0.0642 0.0655 0.0651 0.0657 0.0657 

[TRAIN] Epoch[4](967/1500); Loss: 0.171383; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2409 0.2096 0.1942 0.1842 0.1774 0.1712 0.1651 0.1593 0.1580 0.1562 0.1551 0.1540 0.1540 0.1542 0.1544 0.1543 

[TRAIN] Epoch[4](968/1500); Loss: 0.154955; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1743 0.1625 0.1687 0.1685 0.1633 0.1564 0.1515 0.1489 0.1486 0.1492 0.1481 0.1471 0.1475 0.1482 0.1481 0.1484 

[TRAIN] Epoch[4](969/1500); Loss: 0.116725; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2470 0.1714 0.1286 0.1138 0.1178 0.1113 0.1030 0.1047 0.1019 0.0973 0.0951 0.0947 0.0967 0.0966 0.0948 0.0932 

[TRAIN] Epoch[4](970/1500); Loss: 0.069277; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1001 0.0823 0.1079 0.1038 0.0845 0.0615 0.0589 0.0547 0.0608 0.0575 0.0550 0.0561 0.0564 0.0568 0.0551 0.0573 

[TRAIN] Epoch[4](971/1500); Loss: 0.137391; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1503 0.1439 0.1583 0.1605 0.1533 0.1408 0.1309 0.1296 0.1308 0.1320 0.1298 0.1278 0.1278 0.1282 0.1276 0.1266 

[TRAIN] Epoch[4](972/1500); Loss: 0.172628; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2374 0.2058 0.1881 0.1837 0.1793 0.1718 0.1639 0.1619 0.1596 0.1615 0.1607 0.1587 0.1569 0.1570 0.1576 0.1583 

[TRAIN] Epoch[4](973/1500); Loss: 0.084363; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2991 0.1558 0.0618 0.0872 0.1025 0.0855 0.0578 0.0541 0.0412 0.0633 0.0597 0.0537 0.0491 0.0604 0.0587 0.0601 

[TRAIN] Epoch[4](974/1500); Loss: 0.155817; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2349 0.1812 0.1673 0.1783 0.1701 0.1549 0.1408 0.1364 0.1357 0.1376 0.1409 0.1410 0.1409 0.1419 0.1443 0.1469 

[TRAIN] Epoch[4](975/1500); Loss: 0.138703; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2424 0.1794 0.1656 0.1807 0.1702 0.1460 0.1160 0.1174 0.1139 0.1149 0.1123 0.1105 0.1104 0.1120 0.1146 0.1131 

[TRAIN] Epoch[4](976/1500); Loss: 0.116762; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1548 0.1274 0.1313 0.1331 0.1270 0.1172 0.1130 0.1114 0.1079 0.1074 0.1071 0.1065 0.1059 0.1058 0.1060 0.1066 

[TRAIN] Epoch[4](977/1500); Loss: 0.120424; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1911 0.1493 0.1323 0.1275 0.1237 0.1190 0.1139 0.1107 0.1081 0.1072 0.1066 0.1064 0.1071 0.1079 0.1078 0.1081 

[TRAIN] Epoch[4](978/1500); Loss: 0.157328; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2190 0.1826 0.1747 0.1748 0.1684 0.1575 0.1494 0.1452 0.1439 0.1438 0.1429 0.1429 0.1433 0.1437 0.1427 0.1425 

[TRAIN] Epoch[4](979/1500); Loss: 0.165925; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3311 0.2403 0.2184 0.2423 0.2296 0.1978 0.1522 0.1116 0.1173 0.1136 0.1191 0.1177 0.1145 0.1144 0.1182 0.1166 

[TRAIN] Epoch[4](980/1500); Loss: 0.128819; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1991 0.1626 0.1464 0.1420 0.1378 0.1302 0.1224 0.1181 0.1150 0.1127 0.1132 0.1136 0.1128 0.1115 0.1115 0.1121 

[TRAIN] Epoch[4](981/1500); Loss: 0.125261; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2388 0.1687 0.1369 0.1483 0.1471 0.1314 0.1079 0.1058 0.1077 0.1033 0.1024 0.1004 0.1010 0.1020 0.1021 0.1004 

[TRAIN] Epoch[4](982/1500); Loss: 0.127408; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2547 0.1929 0.1493 0.1202 0.1305 0.1300 0.1184 0.1047 0.1074 0.1042 0.1086 0.1053 0.1018 0.1019 0.1033 0.1053 

[TRAIN] Epoch[4](983/1500); Loss: 0.102667; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1607 0.1334 0.1207 0.1295 0.1179 0.1025 0.0909 0.0867 0.0887 0.0915 0.0877 0.0857 0.0864 0.0871 0.0877 0.0857 

[TRAIN] Epoch[4](984/1500); Loss: 0.161668; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1809 0.1677 0.1694 0.1771 0.1766 0.1691 0.1625 0.1548 0.1530 0.1568 0.1559 0.1531 0.1507 0.1513 0.1543 0.1537 

[TRAIN] Epoch[4](985/1500); Loss: 0.103129; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1825 0.1285 0.1155 0.1276 0.1266 0.1139 0.0976 0.0872 0.0836 0.0885 0.0866 0.0818 0.0803 0.0805 0.0852 0.0841 

[TRAIN] Epoch[4](986/1500); Loss: 0.139061; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1804 0.1512 0.1475 0.1486 0.1449 0.1406 0.1363 0.1339 0.1309 0.1320 0.1308 0.1298 0.1289 0.1291 0.1301 0.1300 

[TRAIN] Epoch[4](987/1500); Loss: 0.077538; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1216 0.0950 0.0917 0.0910 0.0826 0.0738 0.0708 0.0697 0.0690 0.0688 0.0671 0.0671 0.0671 0.0685 0.0684 0.0683 

[TRAIN] Epoch[4](988/1500); Loss: 0.082762; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1394 0.0815 0.1113 0.1197 0.1053 0.0809 0.0678 0.0731 0.0695 0.0726 0.0679 0.0644 0.0663 0.0680 0.0690 0.0678 

[TRAIN] Epoch[4](989/1500); Loss: 0.121763; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1598 0.1410 0.1366 0.1383 0.1322 0.1205 0.1111 0.1159 0.1107 0.1124 0.1116 0.1104 0.1114 0.1127 0.1110 0.1126 

[TRAIN] Epoch[4](990/1500); Loss: 0.115237; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2064 0.1629 0.1462 0.1514 0.1408 0.1178 0.0978 0.0924 0.0902 0.0963 0.0928 0.0892 0.0872 0.0913 0.0916 0.0894 

[TRAIN] Epoch[4](991/1500); Loss: 0.156303; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2102 0.1856 0.1785 0.1787 0.1712 0.1629 0.1523 0.1435 0.1421 0.1403 0.1405 0.1402 0.1393 0.1387 0.1385 0.1387 

[TRAIN] Epoch[4](992/1500); Loss: 0.099740; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2691 0.1733 0.1190 0.0919 0.0878 0.0886 0.0784 0.0712 0.0684 0.0706 0.0762 0.0780 0.0774 0.0783 0.0815 0.0863 

[TRAIN] Epoch[4](993/1500); Loss: 0.087919; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1633 0.0971 0.0956 0.1061 0.0966 0.0810 0.0780 0.0761 0.0786 0.0762 0.0734 0.0757 0.0761 0.0788 0.0775 0.0766 

[TRAIN] Epoch[4](994/1500); Loss: 0.081497; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1346 0.0895 0.1012 0.1046 0.0941 0.0776 0.0699 0.0706 0.0711 0.0708 0.0683 0.0689 0.0709 0.0705 0.0707 0.0706 

[TRAIN] Epoch[4](995/1500); Loss: 0.124615; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2542 0.2000 0.1583 0.1258 0.1354 0.1328 0.1174 0.1016 0.1011 0.0969 0.1001 0.0961 0.0941 0.0931 0.0935 0.0933 

[TRAIN] Epoch[4](996/1500); Loss: 0.139193; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2352 0.1851 0.1555 0.1358 0.1374 0.1341 0.1282 0.1264 0.1231 0.1226 0.1245 0.1231 0.1234 0.1231 0.1240 0.1257 

[TRAIN] Epoch[4](997/1500); Loss: 0.067095; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1454 0.0947 0.0715 0.0698 0.0689 0.0637 0.0607 0.0615 0.0541 0.0513 0.0520 0.0537 0.0573 0.0556 0.0550 0.0582 

[TRAIN] Epoch[4](998/1500); Loss: 0.095638; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2348 0.1490 0.1158 0.1215 0.1152 0.1028 0.0812 0.0710 0.0661 0.0705 0.0702 0.0667 0.0656 0.0648 0.0673 0.0677 

[TRAIN] Epoch[4](999/1500); Loss: 0.116575; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2977 0.2121 0.1441 0.0969 0.1082 0.1118 0.1003 0.0875 0.0900 0.0855 0.0876 0.0865 0.0889 0.0906 0.0890 0.0885 

[TRAIN] Epoch[4](1000/1500); Loss: 0.135247; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2680 0.1757 0.1484 0.1785 0.1690 0.1487 0.1266 0.1130 0.1064 0.1058 0.1060 0.1043 0.1026 0.1027 0.1040 0.1041 

[TRAIN] Epoch[4](1001/1500); Loss: 0.100900; Backpropagation: 0.0924 sec; Batch: 0.4239 sec
0.1356 0.1100 0.1028 0.1115 0.1087 0.0989 0.0912 0.0939 0.0951 0.0942 0.0919 0.0923 0.0936 0.0986 0.0992 0.0971 

[TRAIN] Epoch[4](1002/1500); Loss: 0.065639; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0595 0.0838 0.0904 0.0793 0.0689 0.0610 0.0603 0.0584 0.0625 0.0609 0.0589 0.0592 0.0610 0.0621 0.0616 0.0623 

[TRAIN] Epoch[4](1003/1500); Loss: 0.101865; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1482 0.1111 0.1061 0.1094 0.1051 0.0995 0.0976 0.0970 0.0937 0.0934 0.0936 0.0943 0.0945 0.0947 0.0955 0.0961 

[TRAIN] Epoch[4](1004/1500); Loss: 0.108633; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2521 0.1490 0.1269 0.1583 0.1455 0.1152 0.0853 0.0936 0.0893 0.0796 0.0769 0.0730 0.0719 0.0737 0.0749 0.0728 

[TRAIN] Epoch[4](1005/1500); Loss: 0.118942; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2293 0.1720 0.1360 0.1204 0.1249 0.1172 0.1078 0.1045 0.1015 0.1000 0.0997 0.0983 0.0986 0.0976 0.0979 0.0974 

[TRAIN] Epoch[4](1006/1500); Loss: 0.084784; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2666 0.1502 0.0745 0.0897 0.1078 0.0929 0.0687 0.0570 0.0532 0.0599 0.0568 0.0530 0.0524 0.0583 0.0578 0.0576 

[TRAIN] Epoch[4](1007/1500); Loss: 0.110393; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1368 0.1344 0.1269 0.1118 0.1135 0.1088 0.1054 0.1033 0.1035 0.1029 0.1027 0.1022 0.1028 0.1031 0.1036 0.1045 

[TRAIN] Epoch[4](1008/1500); Loss: 0.089684; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1357 0.1320 0.1236 0.1032 0.0953 0.0886 0.0840 0.0818 0.0767 0.0756 0.0741 0.0729 0.0736 0.0727 0.0725 0.0726 

[TRAIN] Epoch[4](1009/1500); Loss: 0.092743; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1253 0.1276 0.1301 0.1157 0.0978 0.0869 0.0891 0.0826 0.0807 0.0800 0.0780 0.0782 0.0773 0.0788 0.0775 0.0783 

[TRAIN] Epoch[4](1010/1500); Loss: 0.081861; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1733 0.1173 0.0896 0.0869 0.0881 0.0796 0.0714 0.0708 0.0681 0.0674 0.0664 0.0651 0.0658 0.0662 0.0669 0.0669 

[TRAIN] Epoch[4](1011/1500); Loss: 0.104537; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1723 0.1293 0.1157 0.1097 0.1070 0.1030 0.0984 0.0973 0.0939 0.0936 0.0919 0.0916 0.0920 0.0921 0.0924 0.0923 

[TRAIN] Epoch[4](1012/1500); Loss: 0.113899; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2339 0.1691 0.1307 0.1195 0.1175 0.1093 0.0982 0.0930 0.0973 0.0936 0.0924 0.0925 0.0938 0.0941 0.0934 0.0941 

[TRAIN] Epoch[4](1013/1500); Loss: 0.074896; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1761 0.0984 0.0857 0.1118 0.1000 0.0756 0.0531 0.0653 0.0643 0.0520 0.0512 0.0506 0.0508 0.0551 0.0542 0.0542 

[TRAIN] Epoch[4](1014/1500); Loss: 0.099407; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2414 0.1683 0.1378 0.1351 0.1310 0.1147 0.0910 0.0728 0.0711 0.0684 0.0622 0.0595 0.0596 0.0596 0.0590 0.0590 

[TRAIN] Epoch[4](1015/1500); Loss: 0.095374; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1204 0.1184 0.1177 0.1058 0.0971 0.0910 0.0892 0.0885 0.0887 0.0859 0.0853 0.0866 0.0875 0.0871 0.0872 0.0894 

[TRAIN] Epoch[4](1016/1500); Loss: 0.131991; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1898 0.1824 0.1683 0.1527 0.1417 0.1347 0.1280 0.1184 0.1155 0.1129 0.1135 0.1120 0.1108 0.1098 0.1103 0.1112 

[TRAIN] Epoch[4](1017/1500); Loss: 0.087188; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1632 0.0888 0.0955 0.1041 0.0924 0.0771 0.0757 0.0784 0.0739 0.0741 0.0735 0.0771 0.0789 0.0787 0.0810 0.0824 

[TRAIN] Epoch[4](1018/1500); Loss: 0.074182; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1320 0.0870 0.0799 0.0834 0.0768 0.0693 0.0711 0.0717 0.0658 0.0645 0.0640 0.0637 0.0636 0.0641 0.0646 0.0652 

[TRAIN] Epoch[4](1019/1500); Loss: 0.123703; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1810 0.1536 0.1439 0.1339 0.1238 0.1195 0.1159 0.1115 0.1103 0.1103 0.1106 0.1105 0.1116 0.1128 0.1140 0.1160 

[TRAIN] Epoch[4](1020/1500); Loss: 0.102609; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1713 0.1196 0.1056 0.1177 0.1142 0.1024 0.0924 0.0917 0.0901 0.0915 0.0904 0.0892 0.0895 0.0895 0.0931 0.0935 

[TRAIN] Epoch[4](1021/1500); Loss: 0.113087; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.3047 0.1650 0.0886 0.1232 0.1286 0.1120 0.0877 0.0865 0.0812 0.0980 0.0951 0.0864 0.0843 0.0859 0.0895 0.0926 

[TRAIN] Epoch[4](1022/1500); Loss: 0.150805; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2412 0.2020 0.1795 0.1646 0.1531 0.1455 0.1399 0.1371 0.1346 0.1327 0.1312 0.1302 0.1298 0.1299 0.1303 0.1311 

[TRAIN] Epoch[4](1023/1500); Loss: 0.078340; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1366 0.0883 0.0777 0.0851 0.0810 0.0756 0.0806 0.0798 0.0695 0.0674 0.0675 0.0678 0.0682 0.0689 0.0693 0.0702 

[TRAIN] Epoch[4](1024/1500); Loss: 0.055706; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0464 0.0768 0.0826 0.0692 0.0537 0.0514 0.0592 0.0484 0.0491 0.0486 0.0485 0.0498 0.0505 0.0512 0.0525 0.0536 

[TRAIN] Epoch[4](1025/1500); Loss: 0.117902; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2973 0.2031 0.1344 0.0974 0.1181 0.1141 0.1031 0.0955 0.0932 0.0879 0.0932 0.0913 0.0898 0.0886 0.0888 0.0907 

[TRAIN] Epoch[4](1026/1500); Loss: 0.120568; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2164 0.1572 0.1377 0.1327 0.1309 0.1184 0.1069 0.1067 0.1031 0.1034 0.1033 0.1013 0.1014 0.1028 0.1035 0.1032 

[TRAIN] Epoch[4](1027/1500); Loss: 0.061903; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1581 0.0710 0.0552 0.0771 0.0650 0.0450 0.0578 0.0778 0.0528 0.0445 0.0441 0.0449 0.0466 0.0482 0.0505 0.0519 

[TRAIN] Epoch[4](1028/1500); Loss: 0.141418; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2209 0.1905 0.1694 0.1509 0.1397 0.1347 0.1298 0.1277 0.1254 0.1249 0.1248 0.1239 0.1246 0.1252 0.1252 0.1249 

[TRAIN] Epoch[4](1029/1500); Loss: 0.112026; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1749 0.1371 0.1242 0.1165 0.1143 0.1098 0.1060 0.1045 0.1020 0.1012 0.1004 0.1003 0.1003 0.0999 0.1002 0.1009 

[TRAIN] Epoch[4](1030/1500); Loss: 0.131900; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2607 0.1720 0.1323 0.1528 0.1465 0.1293 0.1141 0.1220 0.1137 0.1116 0.1094 0.1067 0.1105 0.1112 0.1093 0.1083 

[TRAIN] Epoch[4](1031/1500); Loss: 0.147579; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2196 0.1761 0.1595 0.1582 0.1521 0.1423 0.1362 0.1351 0.1350 0.1341 0.1334 0.1337 0.1347 0.1352 0.1367 0.1394 

[TRAIN] Epoch[4](1032/1500); Loss: 0.125243; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1496 0.1372 0.1442 0.1415 0.1331 0.1227 0.1224 0.1205 0.1184 0.1180 0.1168 0.1161 0.1157 0.1159 0.1158 0.1160 

[TRAIN] Epoch[4](1033/1500); Loss: 0.078488; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1559 0.1068 0.1087 0.1010 0.0860 0.0792 0.0718 0.0652 0.0620 0.0606 0.0601 0.0593 0.0576 0.0584 0.0607 0.0624 

[TRAIN] Epoch[4](1034/1500); Loss: 0.093178; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1204 0.1256 0.1219 0.1073 0.0968 0.0913 0.0876 0.0863 0.0842 0.0825 0.0813 0.0814 0.0806 0.0806 0.0817 0.0812 

[TRAIN] Epoch[4](1035/1500); Loss: 0.103762; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1849 0.1404 0.1249 0.1100 0.1052 0.0986 0.0969 0.0909 0.0926 0.0888 0.0889 0.0892 0.0876 0.0872 0.0865 0.0875 

[TRAIN] Epoch[4](1036/1500); Loss: 0.129423; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1857 0.1521 0.1401 0.1393 0.1353 0.1238 0.1152 0.1125 0.1159 0.1193 0.1188 0.1188 0.1200 0.1221 0.1249 0.1269 

[TRAIN] Epoch[4](1037/1500); Loss: 0.097078; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.4036 0.2687 0.1552 0.0519 0.0701 0.0757 0.0596 0.0362 0.0668 0.0451 0.0617 0.0559 0.0454 0.0455 0.0552 0.0568 

[TRAIN] Epoch[4](1038/1500); Loss: 0.122744; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3691 0.2586 0.1754 0.0972 0.1098 0.1084 0.0934 0.0725 0.0969 0.0792 0.0899 0.0850 0.0776 0.0794 0.0844 0.0871 

[TRAIN] Epoch[4](1039/1500); Loss: 0.118525; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2066 0.1653 0.1407 0.1206 0.1100 0.1059 0.1052 0.1062 0.1037 0.1024 0.1023 0.1034 0.1052 0.1055 0.1063 0.1073 

[TRAIN] Epoch[4](1040/1500); Loss: 0.082606; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.3316 0.1999 0.1109 0.0609 0.0696 0.0629 0.0535 0.0475 0.0531 0.0453 0.0484 0.0477 0.0466 0.0468 0.0467 0.0504 

[TRAIN] Epoch[4](1041/1500); Loss: 0.111216; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.1820 0.1365 0.1305 0.1247 0.1155 0.1079 0.1020 0.0976 0.0974 0.0961 0.0949 0.0951 0.0968 0.0988 0.1006 0.1031 

[TRAIN] Epoch[4](1042/1500); Loss: 0.146638; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1769 0.1585 0.1593 0.1582 0.1531 0.1476 0.1426 0.1399 0.1395 0.1383 0.1376 0.1378 0.1388 0.1385 0.1390 0.1405 

[TRAIN] Epoch[4](1043/1500); Loss: 0.062229; Backpropagation: 0.0920 sec; Batch: 0.4264 sec
0.1460 0.0939 0.0680 0.0630 0.0606 0.0575 0.0579 0.0549 0.0472 0.0463 0.0479 0.0493 0.0479 0.0486 0.0522 0.0543 

[TRAIN] Epoch[4](1044/1500); Loss: 0.099528; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1666 0.1350 0.1158 0.1105 0.0984 0.0875 0.0843 0.0823 0.0853 0.0847 0.0843 0.0863 0.0880 0.0926 0.0946 0.0961 

[TRAIN] Epoch[4](1045/1500); Loss: 0.116235; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1581 0.1405 0.1350 0.1271 0.1188 0.1153 0.1105 0.1073 0.1068 0.1057 0.1050 0.1053 0.1058 0.1060 0.1061 0.1064 

[TRAIN] Epoch[4](1046/1500); Loss: 0.118260; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.3739 0.2545 0.1606 0.0794 0.1092 0.1114 0.0929 0.0692 0.0843 0.0712 0.0892 0.0841 0.0757 0.0728 0.0844 0.0794 

[TRAIN] Epoch[4](1047/1500); Loss: 0.148584; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2155 0.1745 0.1708 0.1790 0.1718 0.1611 0.1479 0.1343 0.1294 0.1288 0.1282 0.1281 0.1267 0.1265 0.1272 0.1277 

[TRAIN] Epoch[4](1048/1500); Loss: 0.115323; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1396 0.1299 0.1301 0.1241 0.1173 0.1139 0.1140 0.1102 0.1095 0.1094 0.1087 0.1081 0.1075 0.1077 0.1075 0.1077 

[TRAIN] Epoch[4](1049/1500); Loss: 0.113692; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1794 0.1650 0.1513 0.1338 0.1167 0.1018 0.0978 0.0969 0.0970 0.0967 0.0962 0.0961 0.0969 0.0971 0.0981 0.0982 

[TRAIN] Epoch[4](1050/1500); Loss: 0.068948; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1405 0.0946 0.0801 0.0757 0.0743 0.0654 0.0664 0.0711 0.0564 0.0546 0.0533 0.0530 0.0540 0.0541 0.0545 0.0552 

[TRAIN] Epoch[4](1051/1500); Loss: 0.108665; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1334 0.1360 0.1315 0.1132 0.1044 0.1010 0.0999 0.0999 0.1007 0.0997 0.1003 0.1018 0.1031 0.1039 0.1046 0.1052 

[TRAIN] Epoch[4](1052/1500); Loss: 0.085426; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1619 0.1127 0.0870 0.0817 0.0798 0.0775 0.0801 0.0795 0.0718 0.0721 0.0742 0.0758 0.0748 0.0775 0.0800 0.0803 

[TRAIN] Epoch[4](1053/1500); Loss: 0.106209; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2600 0.1658 0.1124 0.1149 0.1160 0.1028 0.0859 0.0807 0.0804 0.0858 0.0837 0.0808 0.0803 0.0817 0.0840 0.0840 

[TRAIN] Epoch[4](1054/1500); Loss: 0.099151; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1552 0.1269 0.1134 0.1031 0.0966 0.0942 0.0931 0.0909 0.0892 0.0889 0.0887 0.0887 0.0887 0.0890 0.0896 0.0902 

[TRAIN] Epoch[4](1055/1500); Loss: 0.151467; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2282 0.1937 0.1759 0.1600 0.1488 0.1430 0.1396 0.1375 0.1366 0.1363 0.1369 0.1370 0.1370 0.1372 0.1377 0.1383 

[TRAIN] Epoch[4](1056/1500); Loss: 0.095343; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2116 0.1514 0.1179 0.1011 0.0975 0.0814 0.0760 0.0716 0.0764 0.0761 0.0736 0.0763 0.0764 0.0779 0.0788 0.0813 

[TRAIN] Epoch[4](1057/1500); Loss: 0.116863; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2337 0.1538 0.1224 0.1291 0.1224 0.1121 0.1045 0.0989 0.0994 0.0980 0.0982 0.0983 0.0993 0.0990 0.0998 0.1012 

[TRAIN] Epoch[4](1058/1500); Loss: 0.135689; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2010 0.1645 0.1412 0.1373 0.1312 0.1251 0.1240 0.1233 0.1249 0.1249 0.1248 0.1268 0.1285 0.1290 0.1311 0.1336 

[TRAIN] Epoch[4](1059/1500); Loss: 0.110378; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.3224 0.1715 0.0895 0.1069 0.1006 0.0873 0.0833 0.0870 0.0847 0.0887 0.0862 0.0884 0.0917 0.0906 0.0919 0.0955 

[TRAIN] Epoch[4](1060/1500); Loss: 0.152606; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2450 0.1980 0.1873 0.1957 0.1858 0.1684 0.1455 0.1271 0.1279 0.1267 0.1221 0.1220 0.1218 0.1226 0.1225 0.1234 

[TRAIN] Epoch[4](1061/1500); Loss: 0.064174; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1154 0.0927 0.0850 0.0766 0.0659 0.0538 0.0543 0.0620 0.0527 0.0499 0.0503 0.0509 0.0522 0.0537 0.0549 0.0565 

[TRAIN] Epoch[4](1062/1500); Loss: 0.071432; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.0616 0.0753 0.0790 0.0747 0.0766 0.0775 0.0712 0.0680 0.0672 0.0672 0.0676 0.0685 0.0699 0.0715 0.0728 0.0744 

[TRAIN] Epoch[4](1063/1500); Loss: 0.129229; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1722 0.1376 0.1332 0.1327 0.1294 0.1278 0.1268 0.1234 0.1216 0.1221 0.1222 0.1226 0.1228 0.1236 0.1246 0.1249 

[TRAIN] Epoch[4](1064/1500); Loss: 0.103623; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2832 0.1797 0.1166 0.0931 0.0876 0.0835 0.0811 0.0788 0.0777 0.0782 0.0793 0.0808 0.0818 0.0836 0.0856 0.0873 

[TRAIN] Epoch[4](1065/1500); Loss: 0.157652; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.4030 0.2651 0.1843 0.1571 0.1519 0.1417 0.1359 0.1270 0.1230 0.1183 0.1168 0.1159 0.1175 0.1192 0.1215 0.1241 

[TRAIN] Epoch[4](1066/1500); Loss: 0.106538; Backpropagation: 0.0917 sec; Batch: 0.4226 sec
0.1133 0.0895 0.0943 0.0945 0.0874 0.0843 0.0845 0.0881 0.0940 0.1014 0.1088 0.1163 0.1244 0.1327 0.1411 0.1498 

[TRAIN] Epoch[4](1067/1500); Loss: 0.157870; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1612 0.1096 0.1083 0.1183 0.1278 0.1282 0.1324 0.1406 0.1519 0.1624 0.1719 0.1817 0.1921 0.2025 0.2132 0.2239 

[TRAIN] Epoch[4](1068/1500); Loss: 0.170765; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1975 0.1391 0.1385 0.1416 0.1423 0.1445 0.1488 0.1543 0.1617 0.1689 0.1766 0.1850 0.1943 0.2035 0.2129 0.2227 

[TRAIN] Epoch[4](1069/1500); Loss: 0.171258; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1295 0.1122 0.1217 0.1207 0.1267 0.1346 0.1448 0.1565 0.1691 0.1804 0.1923 0.2045 0.2177 0.2303 0.2432 0.2559 

[TRAIN] Epoch[4](1070/1500); Loss: 0.108685; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.0748 0.0881 0.1027 0.0683 0.0638 0.0670 0.0765 0.0860 0.0983 0.1089 0.1211 0.1323 0.1448 0.1564 0.1690 0.1809 

[TRAIN] Epoch[4](1071/1500); Loss: 0.226305; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1537 0.1240 0.1338 0.1450 0.1605 0.1770 0.1930 0.2095 0.2276 0.2451 0.2631 0.2808 0.2993 0.3176 0.3363 0.3545 

[TRAIN] Epoch[4](1072/1500); Loss: 0.243512; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1931 0.1768 0.1855 0.1934 0.1963 0.2029 0.2108 0.2234 0.2375 0.2517 0.2655 0.2805 0.2956 0.3116 0.3276 0.3440 

[TRAIN] Epoch[4](1073/1500); Loss: 0.220446; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1483 0.1355 0.1512 0.1612 0.1675 0.1754 0.1849 0.1992 0.2163 0.2338 0.2501 0.2660 0.2828 0.3004 0.3185 0.3361 

[TRAIN] Epoch[4](1074/1500); Loss: 0.276776; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1832 0.1721 0.1911 0.2051 0.2160 0.2282 0.2415 0.2585 0.2776 0.2959 0.3138 0.3319 0.3504 0.3690 0.3878 0.4065 

[TRAIN] Epoch[4](1075/1500); Loss: 0.318216; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2309 0.2065 0.2241 0.2450 0.2539 0.2642 0.2761 0.2940 0.3150 0.3353 0.3547 0.3752 0.3967 0.4184 0.4399 0.4615 

[TRAIN] Epoch[4](1076/1500); Loss: 0.330363; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2051 0.1769 0.2069 0.2403 0.2554 0.2640 0.2780 0.3023 0.3316 0.3583 0.3808 0.4048 0.4310 0.4578 0.4835 0.5090 

[TRAIN] Epoch[4](1077/1500); Loss: 0.212417; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.3051 0.2369 0.2136 0.2270 0.2143 0.1869 0.1593 0.1735 0.1701 0.1675 0.1749 0.1888 0.2117 0.2345 0.2558 0.2786 

[TRAIN] Epoch[4](1078/1500); Loss: 0.345164; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2495 0.2400 0.2580 0.2758 0.2807 0.2878 0.2970 0.3129 0.3353 0.3573 0.3785 0.4004 0.4239 0.4489 0.4753 0.5014 

[TRAIN] Epoch[4](1079/1500); Loss: 0.114665; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2944 0.1731 0.1453 0.1848 0.1605 0.1161 0.0604 0.0703 0.0740 0.0514 0.0574 0.0594 0.0719 0.0885 0.1055 0.1217 

[TRAIN] Epoch[4](1080/1500); Loss: 0.182889; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2356 0.1697 0.1580 0.1685 0.1595 0.1446 0.1361 0.1500 0.1617 0.1597 0.1705 0.1832 0.2020 0.2225 0.2425 0.2622 

[TRAIN] Epoch[4](1081/1500); Loss: 0.272204; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1865 0.2054 0.2312 0.2396 0.2418 0.2472 0.2549 0.2655 0.2762 0.2859 0.2954 0.3050 0.3151 0.3251 0.3352 0.3452 

[TRAIN] Epoch[4](1082/1500); Loss: 0.298830; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1778 0.1870 0.2212 0.2349 0.2345 0.2425 0.2556 0.2759 0.2982 0.3185 0.3378 0.3578 0.3783 0.3994 0.4203 0.4414 

[TRAIN] Epoch[4](1083/1500); Loss: 0.517203; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3407 0.3387 0.3971 0.4406 0.4425 0.4472 0.4628 0.4874 0.5204 0.5497 0.5726 0.5968 0.6262 0.6568 0.6844 0.7113 

[TRAIN] Epoch[4](1084/1500); Loss: 0.182907; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1143 0.1250 0.1454 0.1326 0.1345 0.1402 0.1518 0.1660 0.1798 0.1923 0.2059 0.2193 0.2338 0.2476 0.2621 0.2759 

[TRAIN] Epoch[4](1085/1500); Loss: 0.391242; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2666 0.2707 0.3109 0.3375 0.3405 0.3483 0.3599 0.3777 0.3981 0.4150 0.4306 0.4470 0.4639 0.4809 0.4978 0.5146 

[TRAIN] Epoch[4](1086/1500); Loss: 0.468712; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.3261 0.3229 0.3744 0.4088 0.4076 0.4151 0.4281 0.4503 0.4770 0.4971 0.5136 0.5333 0.5548 0.5761 0.5968 0.6174 

[TRAIN] Epoch[4](1087/1500); Loss: 0.177395; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1027 0.1346 0.1556 0.1438 0.1443 0.1491 0.1573 0.1668 0.1768 0.1859 0.1957 0.2050 0.2152 0.2250 0.2353 0.2452 

[TRAIN] Epoch[4](1088/1500); Loss: 0.204424; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2051 0.1709 0.1771 0.1880 0.1837 0.1822 0.1886 0.1945 0.1978 0.2041 0.2098 0.2178 0.2253 0.2339 0.2417 0.2504 

[TRAIN] Epoch[4](1089/1500); Loss: 0.116092; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.2200 0.1388 0.1209 0.1407 0.1256 0.1021 0.0879 0.1019 0.0936 0.0920 0.0936 0.0979 0.1019 0.1082 0.1128 0.1197 

[TRAIN] Epoch[4](1090/1500); Loss: 0.206619; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1808 0.1710 0.1820 0.1863 0.1900 0.1939 0.1976 0.2023 0.2073 0.2122 0.2174 0.2224 0.2278 0.2329 0.2384 0.2436 

[TRAIN] Epoch[4](1091/1500); Loss: 0.168757; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2845 0.2048 0.1847 0.2025 0.1869 0.1622 0.1408 0.1344 0.1377 0.1403 0.1459 0.1482 0.1502 0.1548 0.1589 0.1633 

[TRAIN] Epoch[4](1092/1500); Loss: 0.258188; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1867 0.1987 0.2364 0.2392 0.2270 0.2309 0.2372 0.2478 0.2590 0.2676 0.2764 0.2855 0.2951 0.3046 0.3146 0.3242 

[TRAIN] Epoch[4](1093/1500); Loss: 0.210957; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2953 0.2337 0.2338 0.2557 0.2378 0.2118 0.1748 0.1585 0.1821 0.1781 0.1789 0.1874 0.1947 0.2064 0.2169 0.2293 

[TRAIN] Epoch[4](1094/1500); Loss: 0.239630; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2200 0.2104 0.2273 0.2302 0.2264 0.2283 0.2302 0.2342 0.2380 0.2423 0.2464 0.2510 0.2553 0.2601 0.2645 0.2693 

[TRAIN] Epoch[4](1095/1500); Loss: 0.136674; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1227 0.1326 0.1447 0.1289 0.1275 0.1286 0.1304 0.1321 0.1340 0.1362 0.1387 0.1409 0.1436 0.1459 0.1488 0.1512 

[TRAIN] Epoch[4](1096/1500); Loss: 0.138650; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1407 0.1331 0.1434 0.1380 0.1345 0.1341 0.1348 0.1362 0.1362 0.1371 0.1381 0.1394 0.1408 0.1424 0.1440 0.1458 

[TRAIN] Epoch[4](1097/1500); Loss: 0.206461; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2438 0.2046 0.2101 0.2208 0.2112 0.1995 0.1861 0.1922 0.1931 0.1949 0.1986 0.2014 0.2057 0.2094 0.2140 0.2179 

[TRAIN] Epoch[4](1098/1500); Loss: 0.236684; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.2609 0.2262 0.2389 0.2463 0.2340 0.2278 0.2206 0.2188 0.2221 0.2260 0.2293 0.2339 0.2406 0.2476 0.2531 0.2609 

[TRAIN] Epoch[4](1099/1500); Loss: 0.115019; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1493 0.1229 0.1196 0.1223 0.1163 0.1104 0.1102 0.1115 0.1088 0.1087 0.1086 0.1091 0.1096 0.1102 0.1108 0.1118 

[TRAIN] Epoch[4](1100/1500); Loss: 0.149541; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1592 0.1478 0.1554 0.1464 0.1463 0.1464 0.1463 0.1469 0.1472 0.1477 0.1482 0.1490 0.1498 0.1508 0.1521 0.1533 

[TRAIN] Epoch[4](1101/1500); Loss: 0.239068; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.2884 0.2347 0.2386 0.2506 0.2447 0.2368 0.2267 0.2244 0.2281 0.2292 0.2307 0.2324 0.2351 0.2386 0.2415 0.2448 

[TRAIN] Epoch[4](1102/1500); Loss: 0.176599; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2011 0.1747 0.1805 0.1823 0.1758 0.1712 0.1696 0.1706 0.1697 0.1710 0.1720 0.1736 0.1754 0.1773 0.1793 0.1816 

[TRAIN] Epoch[4](1103/1500); Loss: 0.201033; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2324 0.2041 0.2118 0.2101 0.2088 0.2068 0.2039 0.2015 0.1988 0.1965 0.1942 0.1925 0.1907 0.1895 0.1881 0.1871 

[TRAIN] Epoch[4](1104/1500); Loss: 0.299133; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.3323 0.3022 0.3097 0.3098 0.3093 0.3077 0.3040 0.3012 0.2976 0.2952 0.2919 0.2897 0.2868 0.2850 0.2826 0.2813 

[TRAIN] Epoch[4](1105/1500); Loss: 0.100508; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1200 0.1133 0.1170 0.1052 0.1019 0.0995 0.0971 0.0954 0.0943 0.0934 0.0934 0.0934 0.0942 0.0953 0.0967 0.0981 

[TRAIN] Epoch[4](1106/1500); Loss: 0.113319; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1266 0.1212 0.1302 0.1210 0.1169 0.1148 0.1125 0.1105 0.1087 0.1075 0.1067 0.1064 0.1065 0.1069 0.1078 0.1088 

[TRAIN] Epoch[4](1107/1500); Loss: 0.097390; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1189 0.1054 0.1090 0.1010 0.0977 0.0953 0.0938 0.0922 0.0915 0.0912 0.0913 0.0919 0.0929 0.0938 0.0954 0.0970 

[TRAIN] Epoch[4](1108/1500); Loss: 0.242288; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.3020 0.2607 0.2680 0.2686 0.2641 0.2585 0.2515 0.2450 0.2383 0.2319 0.2261 0.2209 0.2162 0.2120 0.2080 0.2047 

[TRAIN] Epoch[4](1109/1500); Loss: 0.090775; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2233 0.1328 0.1097 0.1347 0.1166 0.0874 0.0615 0.0760 0.0671 0.0607 0.0618 0.0621 0.0629 0.0640 0.0660 0.0660 

[TRAIN] Epoch[4](1110/1500); Loss: 0.120078; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1562 0.1309 0.1309 0.1295 0.1254 0.1212 0.1179 0.1151 0.1132 0.1120 0.1113 0.1109 0.1109 0.1112 0.1119 0.1127 

[TRAIN] Epoch[4](1111/1500); Loss: 0.359783; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.4383 0.3819 0.3941 0.3950 0.3875 0.3805 0.3716 0.3638 0.3548 0.3470 0.3391 0.3324 0.3256 0.3202 0.3146 0.3102 

[TRAIN] Epoch[4](1112/1500); Loss: 0.152822; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1923 0.1705 0.1692 0.1626 0.1583 0.1538 0.1486 0.1450 0.1433 0.1424 0.1418 0.1414 0.1417 0.1430 0.1446 0.1466 

[TRAIN] Epoch[4](1113/1500); Loss: 0.241494; Backpropagation: 0.0920 sec; Batch: 0.4228 sec
0.3429 0.2883 0.2877 0.2907 0.2824 0.2704 0.2552 0.2401 0.2286 0.2190 0.2103 0.2020 0.1946 0.1885 0.1835 0.1795 

[TRAIN] Epoch[4](1114/1500); Loss: 0.164459; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.2321 0.1928 0.1854 0.1862 0.1800 0.1706 0.1602 0.1515 0.1474 0.1462 0.1460 0.1453 0.1453 0.1461 0.1475 0.1488 

[TRAIN] Epoch[4](1115/1500); Loss: 0.162531; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2093 0.1881 0.1888 0.1847 0.1777 0.1695 0.1594 0.1510 0.1470 0.1459 0.1451 0.1451 0.1456 0.1465 0.1478 0.1491 

[TRAIN] Epoch[4](1116/1500); Loss: 0.197406; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2566 0.2333 0.2412 0.2295 0.2203 0.2127 0.2049 0.1974 0.1904 0.1833 0.1771 0.1713 0.1659 0.1613 0.1579 0.1553 

[TRAIN] Epoch[4](1117/1500); Loss: 0.098622; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1739 0.1125 0.1185 0.1191 0.1111 0.1020 0.0933 0.0863 0.0816 0.0787 0.0781 0.0792 0.0812 0.0836 0.0873 0.0915 

[TRAIN] Epoch[4](1118/1500); Loss: 0.143860; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1991 0.1669 0.1661 0.1595 0.1527 0.1451 0.1381 0.1326 0.1290 0.1274 0.1272 0.1279 0.1293 0.1311 0.1334 0.1362 

[TRAIN] Epoch[4](1119/1500); Loss: 0.129971; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2283 0.1505 0.1449 0.1586 0.1483 0.1314 0.1208 0.1141 0.1137 0.1094 0.1052 0.1065 0.1080 0.1111 0.1125 0.1163 

[TRAIN] Epoch[4](1120/1500); Loss: 0.156689; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2620 0.2034 0.2027 0.1981 0.1841 0.1684 0.1541 0.1418 0.1321 0.1251 0.1217 0.1201 0.1206 0.1218 0.1240 0.1271 

[TRAIN] Epoch[4](1121/1500); Loss: 0.274640; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.4263 0.3484 0.3569 0.3554 0.3383 0.3186 0.2992 0.2799 0.2607 0.2422 0.2255 0.2103 0.1969 0.1860 0.1778 0.1718 

[TRAIN] Epoch[4](1122/1500); Loss: 0.157437; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2339 0.1939 0.1888 0.1891 0.1788 0.1667 0.1513 0.1372 0.1317 0.1321 0.1315 0.1323 0.1359 0.1366 0.1389 0.1404 

[TRAIN] Epoch[4](1123/1500); Loss: 0.277215; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.4560 0.3671 0.3737 0.3717 0.3512 0.3272 0.3030 0.2791 0.2558 0.2335 0.2142 0.1985 0.1865 0.1775 0.1719 0.1684 

[TRAIN] Epoch[4](1124/1500); Loss: 0.089765; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1474 0.1102 0.1018 0.1087 0.1015 0.0903 0.0767 0.0762 0.0751 0.0782 0.0774 0.0753 0.0767 0.0801 0.0802 0.0804 

[TRAIN] Epoch[4](1125/1500); Loss: 0.144202; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2511 0.2004 0.1983 0.1926 0.1785 0.1632 0.1508 0.1398 0.1293 0.1193 0.1107 0.1034 0.0972 0.0930 0.0904 0.0893 

[TRAIN] Epoch[4](1126/1500); Loss: 0.180347; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2882 0.2184 0.2255 0.2239 0.2078 0.1903 0.1758 0.1634 0.1526 0.1449 0.1410 0.1409 0.1441 0.1502 0.1568 0.1619 

[TRAIN] Epoch[4](1127/1500); Loss: 0.120213; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1759 0.1398 0.1401 0.1379 0.1305 0.1228 0.1177 0.1138 0.1102 0.1074 0.1056 0.1044 0.1041 0.1039 0.1040 0.1053 

[TRAIN] Epoch[4](1128/1500); Loss: 0.084766; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1121 0.0984 0.0947 0.0878 0.0839 0.0805 0.0786 0.0771 0.0765 0.0768 0.0769 0.0780 0.0803 0.0820 0.0849 0.0877 

[TRAIN] Epoch[4](1129/1500); Loss: 0.113947; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1595 0.1230 0.1176 0.1179 0.1108 0.1052 0.1034 0.1024 0.1032 0.1038 0.1046 0.1073 0.1113 0.1143 0.1174 0.1214 

[TRAIN] Epoch[4](1130/1500); Loss: 0.207853; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.3561 0.2901 0.2867 0.2851 0.2638 0.2384 0.2141 0.1965 0.1786 0.1643 0.1513 0.1424 0.1385 0.1379 0.1399 0.1419 

[TRAIN] Epoch[4](1131/1500); Loss: 0.167445; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2395 0.2013 0.2023 0.1985 0.1888 0.1782 0.1695 0.1617 0.1543 0.1477 0.1425 0.1388 0.1371 0.1370 0.1392 0.1428 

[TRAIN] Epoch[4](1132/1500); Loss: 0.129367; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1708 0.1479 0.1450 0.1413 0.1349 0.1291 0.1246 0.1217 0.1193 0.1170 0.1168 0.1181 0.1193 0.1201 0.1213 0.1226 

[TRAIN] Epoch[4](1133/1500); Loss: 0.169508; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2527 0.2110 0.2090 0.2042 0.1936 0.1816 0.1718 0.1628 0.1547 0.1479 0.1424 0.1380 0.1355 0.1348 0.1355 0.1366 

[TRAIN] Epoch[4](1134/1500); Loss: 0.088953; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1400 0.0945 0.0967 0.0912 0.0831 0.0779 0.0748 0.0741 0.0754 0.0776 0.0808 0.0841 0.0870 0.0914 0.0957 0.0990 

[TRAIN] Epoch[4](1135/1500); Loss: 0.081326; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1427 0.1256 0.0939 0.0899 0.0806 0.0679 0.0636 0.0552 0.0634 0.0613 0.0629 0.0665 0.0749 0.0810 0.0830 0.0885 

[TRAIN] Epoch[4](1136/1500); Loss: 0.112671; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2243 0.1398 0.1229 0.1476 0.1320 0.1064 0.0850 0.0859 0.0917 0.0937 0.0898 0.0893 0.0939 0.0999 0.0996 0.1009 

[TRAIN] Epoch[4](1137/1500); Loss: 0.072605; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1000 0.0848 0.0819 0.0737 0.0695 0.0664 0.0657 0.0649 0.0667 0.0671 0.0675 0.0683 0.0691 0.0700 0.0722 0.0740 

[TRAIN] Epoch[4](1138/1500); Loss: 0.049614; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0579 0.0579 0.0558 0.0485 0.0450 0.0432 0.0422 0.0420 0.0431 0.0446 0.0467 0.0489 0.0509 0.0531 0.0556 0.0584 

[TRAIN] Epoch[4](1139/1500); Loss: 0.111924; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1716 0.1329 0.1311 0.1267 0.1190 0.1115 0.1061 0.1018 0.0993 0.0986 0.0984 0.0982 0.0980 0.0980 0.0992 0.1004 

[TRAIN] Epoch[4](1140/1500); Loss: 0.117720; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2501 0.1682 0.1686 0.1668 0.1503 0.1282 0.1083 0.0927 0.0815 0.0760 0.0756 0.0783 0.0819 0.0837 0.0853 0.0881 

[TRAIN] Epoch[4](1141/1500); Loss: 0.072413; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1221 0.0982 0.0880 0.0811 0.0719 0.0601 0.0606 0.0612 0.0580 0.0599 0.0609 0.0641 0.0637 0.0668 0.0711 0.0708 

[TRAIN] Epoch[4](1142/1500); Loss: 0.242638; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.3108 0.2600 0.2598 0.2745 0.2641 0.2499 0.2342 0.2265 0.2240 0.2228 0.2212 0.2206 0.2241 0.2291 0.2304 0.2303 

[TRAIN] Epoch[4](1143/1500); Loss: 0.191104; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2711 0.2241 0.2302 0.2290 0.2201 0.2100 0.2003 0.1914 0.1826 0.1741 0.1666 0.1599 0.1543 0.1502 0.1476 0.1462 

[TRAIN] Epoch[4](1144/1500); Loss: 0.149810; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1565 0.1501 0.1485 0.1472 0.1461 0.1461 0.1473 0.1487 0.1497 0.1496 0.1496 0.1503 0.1511 0.1514 0.1519 0.1529 

[TRAIN] Epoch[4](1145/1500); Loss: 0.066440; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0948 0.0769 0.0744 0.0735 0.0702 0.0636 0.0615 0.0598 0.0590 0.0587 0.0586 0.0595 0.0604 0.0617 0.0641 0.0661 

[TRAIN] Epoch[4](1146/1500); Loss: 0.054114; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1441 0.0558 0.0443 0.0588 0.0484 0.0425 0.0495 0.0398 0.0421 0.0411 0.0439 0.0456 0.0485 0.0514 0.0534 0.0568 

[TRAIN] Epoch[4](1147/1500); Loss: 0.168905; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2461 0.1828 0.1936 0.1988 0.1904 0.1804 0.1719 0.1646 0.1581 0.1522 0.1480 0.1445 0.1427 0.1420 0.1424 0.1439 

[TRAIN] Epoch[4](1148/1500); Loss: 0.359363; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.4684 0.3729 0.3981 0.4120 0.4019 0.3882 0.3753 0.3643 0.3531 0.3421 0.3322 0.3231 0.3146 0.3071 0.3008 0.2956 

[TRAIN] Epoch[4](1149/1500); Loss: 0.142536; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1910 0.1593 0.1573 0.1562 0.1507 0.1450 0.1395 0.1343 0.1318 0.1305 0.1299 0.1301 0.1307 0.1310 0.1314 0.1320 

[TRAIN] Epoch[4](1150/1500); Loss: 0.224486; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.3048 0.2525 0.2599 0.2613 0.2566 0.2464 0.2371 0.2291 0.2205 0.2115 0.2032 0.1954 0.1881 0.1810 0.1751 0.1693 

[TRAIN] Epoch[4](1151/1500); Loss: 0.081764; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0954 0.1046 0.1086 0.0864 0.0828 0.0792 0.0762 0.0738 0.0727 0.0724 0.0728 0.0737 0.0750 0.0760 0.0782 0.0805 

[TRAIN] Epoch[4](1152/1500); Loss: 0.100793; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1821 0.1259 0.1106 0.1153 0.1052 0.0908 0.0955 0.0975 0.0843 0.0837 0.0834 0.0849 0.0859 0.0878 0.0897 0.0904 

[TRAIN] Epoch[4](1153/1500); Loss: 0.173505; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2502 0.1848 0.1967 0.2054 0.1996 0.1878 0.1798 0.1730 0.1668 0.1596 0.1537 0.1485 0.1451 0.1423 0.1414 0.1413 

[TRAIN] Epoch[4](1154/1500); Loss: 0.181666; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2926 0.2073 0.2216 0.2295 0.2207 0.2065 0.1929 0.1808 0.1693 0.1577 0.1486 0.1414 0.1366 0.1339 0.1333 0.1339 

[TRAIN] Epoch[4](1155/1500); Loss: 0.112670; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1708 0.1272 0.1308 0.1372 0.1293 0.1182 0.1075 0.1009 0.0969 0.0955 0.0964 0.0959 0.0958 0.0976 0.0999 0.1029 

[TRAIN] Epoch[4](1156/1500); Loss: 0.117885; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1540 0.1408 0.1438 0.1347 0.1294 0.1240 0.1186 0.1143 0.1103 0.1071 0.1045 0.1023 0.1009 0.1003 0.1003 0.1009 

[TRAIN] Epoch[4](1157/1500); Loss: 0.134880; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1772 0.1439 0.1508 0.1512 0.1440 0.1378 0.1333 0.1296 0.1269 0.1251 0.1238 0.1230 0.1224 0.1226 0.1229 0.1237 

[TRAIN] Epoch[4](1158/1500); Loss: 0.094514; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1556 0.1173 0.1153 0.1139 0.1053 0.0950 0.0881 0.0856 0.0809 0.0785 0.0779 0.0777 0.0786 0.0790 0.0807 0.0828 

[TRAIN] Epoch[4](1159/1500); Loss: 0.204711; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3402 0.2598 0.2658 0.2679 0.2570 0.2397 0.2219 0.2059 0.1907 0.1764 0.1637 0.1524 0.1428 0.1354 0.1298 0.1260 

[TRAIN] Epoch[4](1160/1500); Loss: 0.196931; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2897 0.2268 0.2357 0.2386 0.2292 0.2167 0.2050 0.1949 0.1856 0.1773 0.1702 0.1645 0.1596 0.1557 0.1522 0.1491 

[TRAIN] Epoch[4](1161/1500); Loss: 0.200876; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.3355 0.2594 0.2681 0.2710 0.2567 0.2391 0.2216 0.2054 0.1890 0.1728 0.1577 0.1443 0.1330 0.1245 0.1193 0.1168 

[TRAIN] Epoch[4](1162/1500); Loss: 0.145931; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2267 0.1808 0.1794 0.1791 0.1706 0.1595 0.1478 0.1374 0.1302 0.1256 0.1218 0.1187 0.1158 0.1141 0.1137 0.1138 

[TRAIN] Epoch[4](1163/1500); Loss: 0.086153; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1644 0.1127 0.1061 0.1039 0.0942 0.0816 0.0747 0.0745 0.0695 0.0675 0.0681 0.0693 0.0711 0.0714 0.0736 0.0759 

[TRAIN] Epoch[4](1164/1500); Loss: 0.083728; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1066 0.1089 0.1119 0.0924 0.0871 0.0822 0.0780 0.0746 0.0734 0.0730 0.0730 0.0734 0.0748 0.0749 0.0765 0.0787 

[TRAIN] Epoch[4](1165/1500); Loss: 0.205000; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2942 0.2467 0.2507 0.2491 0.2384 0.2262 0.2139 0.2023 0.1921 0.1832 0.1754 0.1690 0.1636 0.1598 0.1579 0.1575 

[TRAIN] Epoch[4](1166/1500); Loss: 0.148739; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2486 0.1819 0.1882 0.1905 0.1810 0.1673 0.1548 0.1440 0.1341 0.1256 0.1187 0.1130 0.1093 0.1075 0.1071 0.1081 

[TRAIN] Epoch[4](1167/1500); Loss: 0.112348; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1695 0.1349 0.1313 0.1307 0.1214 0.1140 0.1144 0.1092 0.1034 0.1010 0.0987 0.0962 0.0948 0.0935 0.0925 0.0922 

[TRAIN] Epoch[4](1168/1500); Loss: 0.165735; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2299 0.1857 0.1877 0.1877 0.1791 0.1696 0.1619 0.1559 0.1519 0.1494 0.1476 0.1468 0.1470 0.1486 0.1505 0.1526 

[TRAIN] Epoch[4](1169/1500); Loss: 0.150815; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1994 0.1698 0.1644 0.1631 0.1576 0.1509 0.1447 0.1406 0.1391 0.1385 0.1389 0.1391 0.1399 0.1411 0.1424 0.1437 

[TRAIN] Epoch[4](1170/1500); Loss: 0.155643; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2526 0.2028 0.1960 0.1956 0.1840 0.1692 0.1553 0.1504 0.1410 0.1323 0.1264 0.1214 0.1175 0.1154 0.1152 0.1150 

[TRAIN] Epoch[4](1171/1500); Loss: 0.173089; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.2655 0.2168 0.2108 0.2129 0.1998 0.1829 0.1655 0.1640 0.1553 0.1473 0.1442 0.1415 0.1404 0.1403 0.1408 0.1416 

[TRAIN] Epoch[4](1172/1500); Loss: 0.127564; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1810 0.1456 0.1457 0.1398 0.1326 0.1256 0.1203 0.1176 0.1156 0.1144 0.1145 0.1151 0.1162 0.1170 0.1189 0.1211 

[TRAIN] Epoch[4](1173/1500); Loss: 0.103320; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1499 0.1333 0.1305 0.1198 0.1108 0.1016 0.0937 0.0887 0.0874 0.0873 0.0877 0.0892 0.0911 0.0920 0.0939 0.0963 

[TRAIN] Epoch[4](1174/1500); Loss: 0.175985; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2747 0.2164 0.2025 0.2119 0.1991 0.1778 0.1555 0.1537 0.1548 0.1517 0.1512 0.1512 0.1531 0.1527 0.1539 0.1555 

[TRAIN] Epoch[4](1175/1500); Loss: 0.159719; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2247 0.2035 0.2091 0.1932 0.1805 0.1694 0.1601 0.1519 0.1446 0.1379 0.1332 0.1299 0.1280 0.1287 0.1300 0.1308 

[TRAIN] Epoch[4](1176/1500); Loss: 0.156485; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2371 0.1916 0.1860 0.1819 0.1718 0.1591 0.1507 0.1452 0.1386 0.1343 0.1330 0.1331 0.1334 0.1344 0.1358 0.1378 

[TRAIN] Epoch[4](1177/1500); Loss: 0.127728; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1805 0.1445 0.1457 0.1402 0.1309 0.1226 0.1175 0.1140 0.1126 0.1137 0.1147 0.1172 0.1187 0.1211 0.1238 0.1260 

[TRAIN] Epoch[4](1178/1500); Loss: 0.137389; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1561 0.1456 0.1443 0.1386 0.1349 0.1331 0.1323 0.1325 0.1331 0.1333 0.1337 0.1337 0.1341 0.1355 0.1378 0.1397 

[TRAIN] Epoch[4](1179/1500); Loss: 0.086647; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1991 0.1264 0.1237 0.1159 0.0955 0.0768 0.0663 0.0631 0.0629 0.0613 0.0625 0.0635 0.0640 0.0668 0.0688 0.0697 

[TRAIN] Epoch[4](1180/1500); Loss: 0.166656; Backpropagation: 0.0918 sec; Batch: 0.4225 sec
0.2915 0.2210 0.2220 0.2215 0.2088 0.1907 0.1729 0.1574 0.1432 0.1305 0.1211 0.1155 0.1140 0.1157 0.1186 0.1221 

[TRAIN] Epoch[4](1181/1500); Loss: 0.073622; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1633 0.1164 0.1096 0.0995 0.0829 0.0687 0.0590 0.0538 0.0525 0.0519 0.0519 0.0516 0.0525 0.0533 0.0546 0.0564 

[TRAIN] Epoch[4](1182/1500); Loss: 0.067455; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1468 0.0866 0.0694 0.0727 0.0649 0.0535 0.0533 0.0558 0.0533 0.0548 0.0563 0.0585 0.0611 0.0621 0.0637 0.0666 

[TRAIN] Epoch[4](1183/1500); Loss: 0.133729; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2773 0.1822 0.1772 0.1959 0.1753 0.1444 0.1237 0.1128 0.0984 0.0930 0.0888 0.0892 0.0931 0.0953 0.0954 0.0977 

[TRAIN] Epoch[4](1184/1500); Loss: 0.150680; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2926 0.2185 0.2135 0.2038 0.1799 0.1570 0.1385 0.1246 0.1160 0.1099 0.1063 0.1060 0.1085 0.1099 0.1118 0.1142 

[TRAIN] Epoch[4](1185/1500); Loss: 0.187237; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2385 0.2018 0.2061 0.2047 0.1955 0.1877 0.1821 0.1781 0.1747 0.1731 0.1724 0.1727 0.1740 0.1758 0.1781 0.1807 

[TRAIN] Epoch[4](1186/1500); Loss: 0.162473; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.3792 0.2673 0.2638 0.2583 0.2262 0.1837 0.1481 0.1191 0.0974 0.0875 0.0869 0.0912 0.0923 0.0971 0.0984 0.1031 

[TRAIN] Epoch[4](1187/1500); Loss: 0.161349; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.3171 0.2436 0.2325 0.2243 0.2004 0.1775 0.1578 0.1415 0.1299 0.1194 0.1116 0.1058 0.1029 0.1035 0.1057 0.1080 

[TRAIN] Epoch[4](1188/1500); Loss: 0.104994; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1666 0.1266 0.1235 0.1185 0.1093 0.1026 0.0985 0.0960 0.0954 0.0944 0.0922 0.0914 0.0917 0.0903 0.0906 0.0924 

[TRAIN] Epoch[4](1189/1500); Loss: 0.108982; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1723 0.1282 0.1237 0.1244 0.1124 0.1021 0.0986 0.0956 0.0947 0.0937 0.0937 0.0965 0.0991 0.0999 0.1021 0.1067 

[TRAIN] Epoch[4](1190/1500); Loss: 0.083443; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1971 0.1156 0.0933 0.1030 0.0905 0.0721 0.0792 0.0756 0.0620 0.0625 0.0606 0.0630 0.0649 0.0634 0.0647 0.0676 

[TRAIN] Epoch[4](1191/1500); Loss: 0.156355; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3286 0.2418 0.2366 0.2260 0.1977 0.1683 0.1458 0.1269 0.1112 0.1015 0.0996 0.0993 0.1016 0.1037 0.1050 0.1081 

[TRAIN] Epoch[4](1192/1500); Loss: 0.150454; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2065 0.1712 0.1688 0.1646 0.1554 0.1469 0.1411 0.1371 0.1348 0.1344 0.1352 0.1370 0.1395 0.1426 0.1446 0.1475 

[TRAIN] Epoch[4](1193/1500); Loss: 0.116360; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1824 0.1359 0.1306 0.1330 0.1227 0.1127 0.1090 0.1053 0.1027 0.1018 0.1009 0.1020 0.1024 0.1041 0.1073 0.1090 

[TRAIN] Epoch[4](1194/1500); Loss: 0.158160; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2709 0.2028 0.2006 0.1957 0.1761 0.1549 0.1405 0.1326 0.1297 0.1302 0.1304 0.1307 0.1320 0.1327 0.1340 0.1367 

[TRAIN] Epoch[4](1195/1500); Loss: 0.157282; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2297 0.1939 0.1888 0.1816 0.1708 0.1613 0.1545 0.1488 0.1442 0.1408 0.1372 0.1340 0.1327 0.1327 0.1322 0.1332 

[TRAIN] Epoch[4](1196/1500); Loss: 0.146050; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2329 0.1837 0.1782 0.1732 0.1596 0.1475 0.1389 0.1329 0.1278 0.1238 0.1232 0.1228 0.1223 0.1213 0.1236 0.1251 

[TRAIN] Epoch[4](1197/1500); Loss: 0.052255; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0983 0.0744 0.0677 0.0584 0.0497 0.0413 0.0442 0.0421 0.0396 0.0413 0.0417 0.0435 0.0451 0.0468 0.0495 0.0525 

[TRAIN] Epoch[4](1198/1500); Loss: 0.152839; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2906 0.2168 0.2121 0.2021 0.1770 0.1532 0.1363 0.1243 0.1162 0.1137 0.1141 0.1138 0.1153 0.1182 0.1201 0.1215 

[TRAIN] Epoch[4](1199/1500); Loss: 0.146243; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2783 0.2126 0.2070 0.1976 0.1757 0.1540 0.1370 0.1219 0.1111 0.1047 0.1035 0.1059 0.1078 0.1074 0.1068 0.1086 

[TRAIN] Epoch[4](1200/1500); Loss: 0.088777; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1439 0.1145 0.1095 0.1018 0.0921 0.0823 0.0768 0.0739 0.0742 0.0749 0.0746 0.0773 0.0777 0.0793 0.0822 0.0855 

[TRAIN] Epoch[4](1201/1500); Loss: 0.118933; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1617 0.1335 0.1264 0.1258 0.1202 0.1144 0.1114 0.1109 0.1107 0.1104 0.1102 0.1107 0.1121 0.1130 0.1147 0.1168 

[TRAIN] Epoch[4](1202/1500); Loss: 0.161491; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2465 0.1995 0.1954 0.1893 0.1742 0.1589 0.1479 0.1418 0.1398 0.1388 0.1389 0.1393 0.1411 0.1430 0.1438 0.1455 

[TRAIN] Epoch[4](1203/1500); Loss: 0.090699; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1292 0.1085 0.1073 0.0972 0.0904 0.0859 0.0826 0.0802 0.0804 0.0810 0.0811 0.0825 0.0836 0.0847 0.0875 0.0891 

[TRAIN] Epoch[4](1204/1500); Loss: 0.168534; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.2253 0.2028 0.2031 0.1963 0.1861 0.1772 0.1697 0.1622 0.1564 0.1518 0.1480 0.1439 0.1419 0.1425 0.1439 0.1455 

[TRAIN] Epoch[4](1205/1500); Loss: 0.066085; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1060 0.0780 0.0766 0.0696 0.0643 0.0606 0.0574 0.0558 0.0555 0.0572 0.0578 0.0592 0.0616 0.0634 0.0657 0.0687 

[TRAIN] Epoch[4](1206/1500); Loss: 0.128532; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1864 0.1541 0.1511 0.1472 0.1383 0.1298 0.1225 0.1180 0.1156 0.1136 0.1127 0.1121 0.1123 0.1132 0.1140 0.1157 

[TRAIN] Epoch[4](1207/1500); Loss: 0.185670; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2513 0.1953 0.1994 0.2008 0.1937 0.1838 0.1776 0.1741 0.1714 0.1708 0.1706 0.1718 0.1737 0.1775 0.1788 0.1803 

[TRAIN] Epoch[4](1208/1500); Loss: 0.143669; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2335 0.1822 0.1746 0.1762 0.1657 0.1519 0.1389 0.1331 0.1297 0.1235 0.1202 0.1177 0.1158 0.1135 0.1120 0.1103 

[TRAIN] Epoch[4](1209/1500); Loss: 0.182131; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3511 0.2408 0.2434 0.2494 0.2336 0.2050 0.1774 0.1564 0.1395 0.1278 0.1252 0.1269 0.1306 0.1334 0.1353 0.1383 

[TRAIN] Epoch[4](1210/1500); Loss: 0.110582; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1771 0.1281 0.1229 0.1246 0.1162 0.1060 0.1016 0.1010 0.0965 0.0962 0.0971 0.0982 0.0988 0.1000 0.1017 0.1032 

[TRAIN] Epoch[4](1211/1500); Loss: 0.125084; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1498 0.1581 0.1637 0.1402 0.1299 0.1230 0.1172 0.1145 0.1130 0.1122 0.1129 0.1129 0.1132 0.1133 0.1132 0.1142 

[TRAIN] Epoch[4](1212/1500); Loss: 0.153869; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2888 0.2182 0.2117 0.2051 0.1855 0.1652 0.1481 0.1359 0.1289 0.1219 0.1161 0.1113 0.1078 0.1062 0.1056 0.1057 

[TRAIN] Epoch[4](1213/1500); Loss: 0.128277; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2033 0.1595 0.1642 0.1590 0.1462 0.1351 0.1275 0.1182 0.1108 0.1063 0.1043 0.1032 0.1024 0.1033 0.1041 0.1051 

[TRAIN] Epoch[4](1214/1500); Loss: 0.151504; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.3131 0.2212 0.2236 0.2208 0.2010 0.1738 0.1500 0.1291 0.1112 0.0988 0.0937 0.0939 0.0944 0.0972 0.1002 0.1021 

[TRAIN] Epoch[4](1215/1500); Loss: 0.137035; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2677 0.1931 0.1906 0.1948 0.1785 0.1576 0.1374 0.1215 0.1085 0.0998 0.0938 0.0902 0.0887 0.0886 0.0896 0.0922 

[TRAIN] Epoch[4](1216/1500); Loss: 0.104692; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2302 0.1523 0.1504 0.1443 0.1261 0.1102 0.0966 0.0844 0.0752 0.0697 0.0682 0.0683 0.0700 0.0729 0.0769 0.0793 

[TRAIN] Epoch[4](1217/1500); Loss: 0.073572; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1073 0.0867 0.0908 0.0822 0.0731 0.0666 0.0642 0.0631 0.0628 0.0634 0.0645 0.0662 0.0681 0.0699 0.0727 0.0755 

[TRAIN] Epoch[4](1218/1500); Loss: 0.130185; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1700 0.1443 0.1445 0.1394 0.1354 0.1315 0.1273 0.1226 0.1207 0.1204 0.1201 0.1201 0.1210 0.1212 0.1219 0.1227 

[TRAIN] Epoch[4](1219/1500); Loss: 0.077678; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1485 0.1094 0.1039 0.0971 0.0856 0.0752 0.0677 0.0627 0.0604 0.0598 0.0604 0.0606 0.0608 0.0621 0.0638 0.0651 

[TRAIN] Epoch[4](1220/1500); Loss: 0.088459; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1176 0.1083 0.1091 0.0973 0.0917 0.0869 0.0835 0.0816 0.0811 0.0797 0.0785 0.0786 0.0788 0.0800 0.0806 0.0820 

[TRAIN] Epoch[4](1221/1500); Loss: 0.146015; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1988 0.1696 0.1709 0.1640 0.1556 0.1482 0.1421 0.1367 0.1332 0.1309 0.1299 0.1298 0.1297 0.1304 0.1323 0.1342 

[TRAIN] Epoch[4](1222/1500); Loss: 0.121286; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1709 0.1362 0.1377 0.1393 0.1284 0.1191 0.1138 0.1117 0.1086 0.1081 0.1078 0.1081 0.1101 0.1123 0.1135 0.1150 

[TRAIN] Epoch[4](1223/1500); Loss: 0.133880; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2023 0.1668 0.1673 0.1612 0.1529 0.1443 0.1371 0.1295 0.1232 0.1176 0.1129 0.1093 0.1068 0.1045 0.1033 0.1030 

[TRAIN] Epoch[4](1224/1500); Loss: 0.086544; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1366 0.1059 0.1078 0.1021 0.0921 0.0848 0.0802 0.0772 0.0751 0.0736 0.0730 0.0734 0.0742 0.0747 0.0759 0.0782 

[TRAIN] Epoch[4](1225/1500); Loss: 0.058379; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1341 0.0859 0.0744 0.0705 0.0610 0.0470 0.0477 0.0503 0.0425 0.0400 0.0417 0.0435 0.0453 0.0478 0.0497 0.0526 

[TRAIN] Epoch[4](1226/1500); Loss: 0.138799; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2302 0.1875 0.1781 0.1809 0.1708 0.1551 0.1320 0.1088 0.1061 0.1113 0.1083 0.1073 0.1092 0.1109 0.1116 0.1126 

[TRAIN] Epoch[4](1227/1500); Loss: 0.085928; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1616 0.1159 0.1085 0.1066 0.0982 0.0864 0.0762 0.0703 0.0694 0.0672 0.0666 0.0674 0.0683 0.0693 0.0708 0.0720 

[TRAIN] Epoch[4](1228/1500); Loss: 0.120147; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2177 0.1536 0.1567 0.1543 0.1419 0.1268 0.1134 0.1040 0.0972 0.0924 0.0900 0.0906 0.0923 0.0952 0.0973 0.0989 

[TRAIN] Epoch[4](1229/1500); Loss: 0.139658; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2031 0.1716 0.1653 0.1609 0.1531 0.1436 0.1351 0.1295 0.1264 0.1238 0.1221 0.1208 0.1200 0.1196 0.1196 0.1201 

[TRAIN] Epoch[4](1230/1500); Loss: 0.137631; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1832 0.1530 0.1522 0.1479 0.1427 0.1380 0.1354 0.1330 0.1300 0.1280 0.1272 0.1265 0.1258 0.1260 0.1262 0.1269 

[TRAIN] Epoch[4](1231/1500); Loss: 0.175101; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2002 0.1861 0.1852 0.1809 0.1774 0.1747 0.1730 0.1719 0.1712 0.1700 0.1696 0.1691 0.1683 0.1678 0.1682 0.1680 

[TRAIN] Epoch[4](1232/1500); Loss: 0.134145; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1732 0.1484 0.1467 0.1440 0.1400 0.1359 0.1328 0.1301 0.1278 0.1258 0.1243 0.1228 0.1226 0.1233 0.1241 0.1246 

[TRAIN] Epoch[4](1233/1500); Loss: 0.177287; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2536 0.2092 0.2051 0.2028 0.1943 0.1832 0.1742 0.1684 0.1623 0.1581 0.1547 0.1528 0.1522 0.1536 0.1555 0.1566 

[TRAIN] Epoch[4](1234/1500); Loss: 0.126387; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2060 0.1553 0.1557 0.1510 0.1394 0.1284 0.1205 0.1144 0.1083 0.1049 0.1035 0.1041 0.1051 0.1071 0.1094 0.1090 

[TRAIN] Epoch[4](1235/1500); Loss: 0.100262; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1394 0.1119 0.1161 0.1039 0.0985 0.0944 0.0929 0.0914 0.0906 0.0910 0.0919 0.0926 0.0946 0.0970 0.0978 0.1002 

[TRAIN] Epoch[4](1236/1500); Loss: 0.054679; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1323 0.0662 0.0531 0.0548 0.0492 0.0460 0.0513 0.0447 0.0416 0.0427 0.0443 0.0460 0.0470 0.0499 0.0516 0.0541 

[TRAIN] Epoch[4](1237/1500); Loss: 0.149095; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2189 0.1716 0.1783 0.1751 0.1639 0.1525 0.1441 0.1371 0.1323 0.1286 0.1268 0.1273 0.1293 0.1310 0.1332 0.1356 

[TRAIN] Epoch[4](1238/1500); Loss: 0.087126; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1460 0.1285 0.1271 0.1119 0.1022 0.0917 0.0826 0.0749 0.0697 0.0667 0.0654 0.0635 0.0637 0.0648 0.0668 0.0685 

[TRAIN] Epoch[4](1239/1500); Loss: 0.065157; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0803 0.0718 0.0733 0.0636 0.0614 0.0596 0.0591 0.0584 0.0592 0.0608 0.0617 0.0631 0.0648 0.0667 0.0682 0.0704 

[TRAIN] Epoch[4](1240/1500); Loss: 0.097416; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1244 0.1136 0.1144 0.1035 0.0989 0.0948 0.0936 0.0917 0.0895 0.0891 0.0891 0.0899 0.0902 0.0908 0.0918 0.0934 

[TRAIN] Epoch[4](1241/1500); Loss: 0.137179; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1724 0.1529 0.1520 0.1471 0.1406 0.1345 0.1299 0.1267 0.1254 0.1255 0.1268 0.1288 0.1303 0.1321 0.1342 0.1357 

[TRAIN] Epoch[4](1242/1500); Loss: 0.154831; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2059 0.1804 0.1786 0.1750 0.1681 0.1602 0.1535 0.1499 0.1461 0.1423 0.1395 0.1370 0.1356 0.1347 0.1347 0.1357 

[TRAIN] Epoch[4](1243/1500); Loss: 0.159593; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.3676 0.2557 0.2509 0.2469 0.2219 0.1882 0.1611 0.1369 0.1144 0.0963 0.0854 0.0830 0.0860 0.0847 0.0857 0.0886 

[TRAIN] Epoch[4](1244/1500); Loss: 0.076239; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1261 0.0865 0.0822 0.0787 0.0727 0.0713 0.0700 0.0678 0.0673 0.0678 0.0690 0.0690 0.0697 0.0723 0.0741 0.0754 

[TRAIN] Epoch[4](1245/1500); Loss: 0.100980; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2149 0.1378 0.1355 0.1324 0.1192 0.1037 0.0925 0.0838 0.0770 0.0733 0.0715 0.0710 0.0719 0.0744 0.0773 0.0797 

[TRAIN] Epoch[4](1246/1500); Loss: 0.152878; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2590 0.1966 0.1969 0.1921 0.1756 0.1598 0.1482 0.1389 0.1305 0.1248 0.1213 0.1194 0.1190 0.1206 0.1216 0.1219 

[TRAIN] Epoch[4](1247/1500); Loss: 0.162355; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2330 0.1913 0.1898 0.1871 0.1798 0.1709 0.1637 0.1572 0.1512 0.1462 0.1419 0.1384 0.1367 0.1359 0.1368 0.1378 

[TRAIN] Epoch[4](1248/1500); Loss: 0.105380; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1232 0.1201 0.1201 0.1109 0.1077 0.1047 0.1022 0.1002 0.0992 0.0988 0.0986 0.0989 0.0992 0.0998 0.1007 0.1016 

[TRAIN] Epoch[4](1249/1500); Loss: 0.092003; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1548 0.1215 0.1224 0.1127 0.0998 0.0905 0.0840 0.0792 0.0755 0.0732 0.0737 0.0744 0.0750 0.0771 0.0781 0.0802 

[TRAIN] Epoch[4](1250/1500); Loss: 0.143362; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2093 0.1666 0.1697 0.1629 0.1527 0.1433 0.1360 0.1310 0.1279 0.1254 0.1249 0.1259 0.1274 0.1296 0.1299 0.1314 

[TRAIN] Epoch[4](1251/1500); Loss: 0.116764; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2115 0.1503 0.1407 0.1417 0.1310 0.1183 0.1109 0.1083 0.0999 0.0956 0.0942 0.0932 0.0930 0.0930 0.0932 0.0934 

[TRAIN] Epoch[4](1252/1500); Loss: 0.134342; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2214 0.1719 0.1706 0.1685 0.1566 0.1448 0.1357 0.1267 0.1187 0.1125 0.1077 0.1048 0.1026 0.1017 0.1021 0.1032 

[TRAIN] Epoch[4](1253/1500); Loss: 0.096432; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1749 0.1368 0.1355 0.1284 0.1137 0.0998 0.0883 0.0788 0.0722 0.0689 0.0705 0.0721 0.0734 0.0744 0.0765 0.0788 

[TRAIN] Epoch[4](1254/1500); Loss: 0.150246; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3219 0.2397 0.2348 0.2286 0.2079 0.1831 0.1619 0.1416 0.1219 0.1039 0.0885 0.0772 0.0716 0.0712 0.0738 0.0762 

[TRAIN] Epoch[4](1255/1500); Loss: 0.141381; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1873 0.1691 0.1721 0.1596 0.1504 0.1430 0.1377 0.1334 0.1300 0.1270 0.1243 0.1233 0.1242 0.1252 0.1270 0.1285 

[TRAIN] Epoch[4](1256/1500); Loss: 0.115880; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2274 0.1576 0.1526 0.1568 0.1377 0.1172 0.1046 0.0984 0.0901 0.0859 0.0850 0.0869 0.0887 0.0883 0.0885 0.0884 

[TRAIN] Epoch[4](1257/1500); Loss: 0.077080; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1207 0.0901 0.0851 0.0814 0.0755 0.0717 0.0711 0.0690 0.0681 0.0687 0.0689 0.0700 0.0714 0.0725 0.0737 0.0754 

[TRAIN] Epoch[4](1258/1500); Loss: 0.091966; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2347 0.1456 0.1390 0.1322 0.1102 0.0868 0.0715 0.0631 0.0613 0.0596 0.0598 0.0600 0.0601 0.0604 0.0625 0.0647 

[TRAIN] Epoch[4](1259/1500); Loss: 0.153440; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2197 0.1807 0.1769 0.1736 0.1655 0.1573 0.1503 0.1452 0.1417 0.1374 0.1356 0.1343 0.1339 0.1344 0.1342 0.1343 

[TRAIN] Epoch[4](1260/1500); Loss: 0.112224; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1538 0.1300 0.1287 0.1259 0.1205 0.1151 0.1115 0.1085 0.1060 0.1038 0.1019 0.1003 0.0989 0.0976 0.0969 0.0963 

[TRAIN] Epoch[4](1261/1500); Loss: 0.153337; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1828 0.1714 0.1673 0.1590 0.1552 0.1520 0.1489 0.1475 0.1469 0.1461 0.1462 0.1457 0.1461 0.1459 0.1461 0.1463 

[TRAIN] Epoch[4](1262/1500); Loss: 0.104307; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1387 0.1204 0.1185 0.1128 0.1071 0.1027 0.0995 0.0976 0.0961 0.0958 0.0954 0.0954 0.0962 0.0962 0.0973 0.0991 

[TRAIN] Epoch[4](1263/1500); Loss: 0.143920; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2173 0.1765 0.1758 0.1715 0.1615 0.1525 0.1453 0.1381 0.1315 0.1263 0.1221 0.1192 0.1174 0.1163 0.1158 0.1157 

[TRAIN] Epoch[4](1264/1500); Loss: 0.114666; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2076 0.1580 0.1609 0.1554 0.1387 0.1247 0.1138 0.1035 0.0952 0.0880 0.0831 0.0812 0.0803 0.0806 0.0811 0.0825 

[TRAIN] Epoch[4](1265/1500); Loss: 0.135835; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2372 0.1778 0.1794 0.1802 0.1616 0.1425 0.1273 0.1163 0.1083 0.1057 0.1053 0.1056 0.1056 0.1056 0.1075 0.1075 

[TRAIN] Epoch[4](1266/1500); Loss: 0.089789; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1616 0.1120 0.1105 0.1099 0.0995 0.0884 0.0808 0.0761 0.0740 0.0737 0.0737 0.0741 0.0739 0.0742 0.0766 0.0776 

[TRAIN] Epoch[4](1267/1500); Loss: 0.164725; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2700 0.2113 0.2075 0.2106 0.1950 0.1762 0.1570 0.1482 0.1406 0.1356 0.1333 0.1316 0.1322 0.1294 0.1282 0.1289 

[TRAIN] Epoch[4](1268/1500); Loss: 0.111099; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2181 0.1527 0.1472 0.1397 0.1219 0.1069 0.0961 0.0896 0.0876 0.0861 0.0862 0.0873 0.0882 0.0889 0.0897 0.0914 

[TRAIN] Epoch[4](1269/1500); Loss: 0.160866; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1762 0.1674 0.1666 0.1617 0.1592 0.1576 0.1573 0.1579 0.1579 0.1573 0.1579 0.1586 0.1584 0.1593 0.1601 0.1605 

[TRAIN] Epoch[4](1270/1500); Loss: 0.089635; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.2314 0.1443 0.1317 0.1230 0.1002 0.0794 0.0683 0.0637 0.0603 0.0591 0.0599 0.0602 0.0608 0.0623 0.0641 0.0656 

[TRAIN] Epoch[4](1271/1500); Loss: 0.131602; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1748 0.1460 0.1495 0.1420 0.1357 0.1308 0.1277 0.1264 0.1230 0.1213 0.1210 0.1209 0.1208 0.1210 0.1219 0.1228 

[TRAIN] Epoch[4](1272/1500); Loss: 0.134584; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2195 0.1736 0.1673 0.1601 0.1482 0.1357 0.1267 0.1227 0.1173 0.1137 0.1113 0.1113 0.1108 0.1109 0.1114 0.1129 

[TRAIN] Epoch[4](1273/1500); Loss: 0.082589; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1475 0.1091 0.1051 0.1016 0.0930 0.0852 0.0797 0.0750 0.0706 0.0674 0.0657 0.0651 0.0644 0.0639 0.0636 0.0645 

[TRAIN] Epoch[4](1274/1500); Loss: 0.134625; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1990 0.1673 0.1634 0.1555 0.1466 0.1384 0.1312 0.1260 0.1219 0.1190 0.1165 0.1148 0.1151 0.1130 0.1126 0.1137 

[TRAIN] Epoch[4](1275/1500); Loss: 0.186558; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2472 0.2227 0.2163 0.2139 0.2053 0.1951 0.1825 0.1728 0.1702 0.1677 0.1662 0.1648 0.1645 0.1646 0.1651 0.1660 

[TRAIN] Epoch[4](1276/1500); Loss: 0.102937; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1342 0.1126 0.1102 0.1081 0.1043 0.1005 0.1001 0.0989 0.0974 0.0980 0.0974 0.0958 0.0969 0.0974 0.0970 0.0982 

[TRAIN] Epoch[4](1277/1500); Loss: 0.061798; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1239 0.0674 0.0646 0.0627 0.0567 0.0546 0.0539 0.0540 0.0534 0.0540 0.0552 0.0551 0.0562 0.0582 0.0585 0.0604 

[TRAIN] Epoch[4](1278/1500); Loss: 0.118372; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1588 0.1435 0.1445 0.1317 0.1232 0.1173 0.1123 0.1087 0.1067 0.1050 0.1053 0.1062 0.1061 0.1070 0.1083 0.1093 

[TRAIN] Epoch[4](1279/1500); Loss: 0.193981; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2335 0.2033 0.2019 0.2040 0.1993 0.1964 0.1932 0.1897 0.1875 0.1869 0.1842 0.1839 0.1862 0.1848 0.1836 0.1853 

[TRAIN] Epoch[4](1280/1500); Loss: 0.154951; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3757 0.2556 0.2293 0.2629 0.2349 0.1846 0.1126 0.0920 0.0923 0.0917 0.0902 0.0927 0.0978 0.0883 0.0885 0.0901 

[TRAIN] Epoch[4](1281/1500); Loss: 0.094488; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1359 0.1132 0.1126 0.1041 0.0980 0.0938 0.0905 0.0880 0.0857 0.0844 0.0837 0.0834 0.0836 0.0844 0.0850 0.0853 

[TRAIN] Epoch[4](1282/1500); Loss: 0.072817; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0848 0.0799 0.0768 0.0716 0.0711 0.0682 0.0686 0.0683 0.0689 0.0689 0.0702 0.0709 0.0718 0.0736 0.0750 0.0764 

[TRAIN] Epoch[4](1283/1500); Loss: 0.149467; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2000 0.1890 0.1846 0.1739 0.1651 0.1572 0.1502 0.1442 0.1394 0.1346 0.1308 0.1275 0.1250 0.1233 0.1231 0.1235 

[TRAIN] Epoch[4](1284/1500); Loss: 0.159308; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2152 0.1920 0.1900 0.1843 0.1765 0.1688 0.1627 0.1564 0.1497 0.1438 0.1390 0.1353 0.1327 0.1322 0.1339 0.1364 

[TRAIN] Epoch[4](1285/1500); Loss: 0.114050; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1211 0.1281 0.1284 0.1141 0.1108 0.1093 0.1100 0.1103 0.1106 0.1099 0.1108 0.1112 0.1109 0.1122 0.1135 0.1136 

[TRAIN] Epoch[4](1286/1500); Loss: 0.107995; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2377 0.1617 0.1468 0.1515 0.1351 0.1164 0.0933 0.0741 0.0790 0.0746 0.0754 0.0749 0.0749 0.0760 0.0775 0.0791 

[TRAIN] Epoch[4](1287/1500); Loss: 0.117254; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1691 0.1454 0.1439 0.1354 0.1263 0.1191 0.1129 0.1080 0.1041 0.1022 0.1012 0.1009 0.1016 0.1018 0.1017 0.1025 

[TRAIN] Epoch[4](1288/1500); Loss: 0.094038; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1227 0.1020 0.0985 0.0970 0.0942 0.0907 0.0892 0.0888 0.0887 0.0884 0.0890 0.0895 0.0903 0.0912 0.0919 0.0926 

[TRAIN] Epoch[4](1289/1500); Loss: 0.172431; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3282 0.2557 0.2480 0.2492 0.2256 0.1987 0.1782 0.1600 0.1409 0.1242 0.1131 0.1087 0.1083 0.1072 0.1065 0.1065 

[TRAIN] Epoch[4](1290/1500); Loss: 0.069556; Backpropagation: 0.0917 sec; Batch: 0.4226 sec
0.0666 0.0941 0.0899 0.0708 0.0653 0.0635 0.0629 0.0622 0.0626 0.0638 0.0647 0.0667 0.0676 0.0686 0.0704 0.0734 

[TRAIN] Epoch[4](1291/1500); Loss: 0.231370; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.3170 0.2598 0.2544 0.2683 0.2563 0.2390 0.2189 0.2093 0.2059 0.2052 0.2079 0.2107 0.2115 0.2104 0.2127 0.2147 

[TRAIN] Epoch[4](1292/1500); Loss: 0.088948; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1587 0.1263 0.1182 0.1133 0.1047 0.0965 0.0892 0.0828 0.0773 0.0718 0.0675 0.0647 0.0629 0.0623 0.0631 0.0639 

[TRAIN] Epoch[4](1293/1500); Loss: 0.141319; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2036 0.1652 0.1590 0.1579 0.1494 0.1407 0.1336 0.1314 0.1281 0.1280 0.1284 0.1275 0.1270 0.1268 0.1269 0.1275 

[TRAIN] Epoch[4](1294/1500); Loss: 0.177248; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.3462 0.2763 0.2574 0.2486 0.2260 0.1992 0.1767 0.1562 0.1383 0.1251 0.1180 0.1145 0.1137 0.1121 0.1138 0.1139 

[TRAIN] Epoch[4](1295/1500); Loss: 0.127534; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1684 0.1469 0.1469 0.1424 0.1341 0.1273 0.1223 0.1211 0.1183 0.1170 0.1151 0.1148 0.1158 0.1161 0.1165 0.1176 

[TRAIN] Epoch[4](1296/1500); Loss: 0.173747; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.3803 0.2948 0.2680 0.2551 0.2217 0.1839 0.1498 0.1268 0.1155 0.1156 0.1108 0.1100 0.1106 0.1097 0.1157 0.1113 

[TRAIN] Epoch[4](1297/1500); Loss: 0.075121; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.1405 0.1065 0.0995 0.0879 0.0752 0.0677 0.0637 0.0606 0.0608 0.0615 0.0616 0.0616 0.0624 0.0631 0.0647 0.0646 

[TRAIN] Epoch[4](1298/1500); Loss: 0.068379; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1025 0.0879 0.0815 0.0729 0.0663 0.0621 0.0603 0.0601 0.0598 0.0610 0.0603 0.0620 0.0616 0.0643 0.0643 0.0672 

[TRAIN] Epoch[4](1299/1500); Loss: 0.107580; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1314 0.1322 0.1264 0.1150 0.1094 0.1046 0.1018 0.1007 0.1002 0.0993 0.0987 0.0994 0.0992 0.1002 0.1008 0.1022 

[TRAIN] Epoch[4](1300/1500); Loss: 0.108213; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.2683 0.1909 0.1658 0.1551 0.1301 0.1038 0.0848 0.0715 0.0651 0.0670 0.0697 0.0687 0.0691 0.0741 0.0736 0.0740 

[TRAIN] Epoch[4](1301/1500); Loss: 0.085649; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1760 0.1267 0.1102 0.1041 0.0929 0.0821 0.0758 0.0712 0.0686 0.0668 0.0658 0.0655 0.0644 0.0650 0.0669 0.0682 

[TRAIN] Epoch[4](1302/1500); Loss: 0.144220; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.2419 0.1980 0.1882 0.1846 0.1691 0.1521 0.1371 0.1272 0.1172 0.1130 0.1124 0.1139 0.1122 0.1115 0.1128 0.1161 

[TRAIN] Epoch[4](1303/1500); Loss: 0.114759; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1528 0.1328 0.1268 0.1224 0.1174 0.1134 0.1105 0.1087 0.1070 0.1059 0.1056 0.1056 0.1058 0.1065 0.1072 0.1077 

[TRAIN] Epoch[4](1304/1500); Loss: 0.070924; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1137 0.0971 0.0940 0.0750 0.0714 0.0657 0.0647 0.0603 0.0611 0.0610 0.0615 0.0616 0.0619 0.0616 0.0615 0.0626 

[TRAIN] Epoch[4](1305/1500); Loss: 0.106733; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1539 0.1316 0.1254 0.1198 0.1137 0.1070 0.1041 0.1011 0.0979 0.0949 0.0930 0.0931 0.0920 0.0923 0.0941 0.0940 

[TRAIN] Epoch[4](1306/1500); Loss: 0.083279; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2078 0.1206 0.0966 0.1131 0.0988 0.0757 0.0711 0.0758 0.0621 0.0588 0.0571 0.0574 0.0580 0.0598 0.0592 0.0606 

[TRAIN] Epoch[4](1307/1500); Loss: 0.156758; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.3979 0.2795 0.2530 0.2474 0.2205 0.1734 0.1361 0.1063 0.0875 0.0868 0.0806 0.0829 0.0856 0.0893 0.0888 0.0927 

[TRAIN] Epoch[4](1308/1500); Loss: 0.075545; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2193 0.1235 0.0994 0.1285 0.1081 0.0759 0.0391 0.0646 0.0580 0.0396 0.0395 0.0400 0.0410 0.0426 0.0444 0.0452 

[TRAIN] Epoch[4](1309/1500); Loss: 0.135981; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1863 0.1529 0.1462 0.1444 0.1391 0.1331 0.1312 0.1295 0.1274 0.1261 0.1256 0.1258 0.1258 0.1265 0.1274 0.1283 

[TRAIN] Epoch[4](1310/1500); Loss: 0.140417; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1649 0.1455 0.1427 0.1433 0.1419 0.1397 0.1380 0.1369 0.1364 0.1359 0.1359 0.1360 0.1364 0.1369 0.1379 0.1384 

[TRAIN] Epoch[4](1311/1500); Loss: 0.138863; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2498 0.1740 0.1658 0.1690 0.1643 0.1527 0.1443 0.1360 0.1271 0.1198 0.1128 0.1075 0.1030 0.1000 0.0980 0.0977 

[TRAIN] Epoch[4](1312/1500); Loss: 0.088659; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1653 0.1011 0.0978 0.1003 0.0963 0.0892 0.0855 0.0810 0.0769 0.0752 0.0743 0.0741 0.0742 0.0749 0.0757 0.0768 

[TRAIN] Epoch[4](1313/1500); Loss: 0.112136; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1323 0.1277 0.1245 0.1177 0.1133 0.1113 0.1095 0.1082 0.1071 0.1064 0.1057 0.1056 0.1058 0.1060 0.1063 0.1070 

[TRAIN] Epoch[4](1314/1500); Loss: 0.070954; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1040 0.0630 0.0645 0.0691 0.0648 0.0625 0.0684 0.0667 0.0662 0.0672 0.0686 0.0700 0.0722 0.0738 0.0762 0.0780 

[TRAIN] Epoch[4](1315/1500); Loss: 0.139372; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2351 0.1812 0.1716 0.1811 0.1696 0.1540 0.1347 0.1189 0.1099 0.1105 0.1087 0.1098 0.1096 0.1106 0.1118 0.1129 

[TRAIN] Epoch[4](1316/1500); Loss: 0.126371; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1842 0.1358 0.1306 0.1417 0.1333 0.1228 0.1161 0.1176 0.1165 0.1158 0.1158 0.1165 0.1171 0.1182 0.1192 0.1206 

[TRAIN] Epoch[4](1317/1500); Loss: 0.145855; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1772 0.1505 0.1504 0.1506 0.1461 0.1426 0.1405 0.1396 0.1396 0.1398 0.1404 0.1413 0.1421 0.1432 0.1443 0.1454 

[TRAIN] Epoch[4](1318/1500); Loss: 0.190322; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2472 0.2132 0.2107 0.2191 0.2122 0.2036 0.1928 0.1825 0.1730 0.1678 0.1665 0.1696 0.1701 0.1704 0.1723 0.1740 

[TRAIN] Epoch[4](1319/1500); Loss: 0.224160; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2478 0.2216 0.2240 0.2301 0.2256 0.2218 0.2174 0.2154 0.2156 0.2182 0.2193 0.2213 0.2232 0.2260 0.2282 0.2311 

[TRAIN] Epoch[4](1320/1500); Loss: 0.239156; Backpropagation: 0.0918 sec; Batch: 0.4226 sec
0.3062 0.2455 0.2397 0.2460 0.2409 0.2354 0.2300 0.2296 0.2313 0.2298 0.2302 0.2309 0.2314 0.2324 0.2331 0.2342 

[TRAIN] Epoch[4](1321/1500); Loss: 0.096213; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0935 0.0809 0.0879 0.0880 0.0814 0.0831 0.0859 0.0891 0.0928 0.0964 0.1002 0.1041 0.1080 0.1120 0.1160 0.1202 

[TRAIN] Epoch[4](1322/1500); Loss: 0.181059; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2184 0.1699 0.1692 0.1752 0.1752 0.1743 0.1750 0.1767 0.1772 0.1789 0.1800 0.1820 0.1833 0.1855 0.1870 0.1893 

[TRAIN] Epoch[4](1323/1500); Loss: 0.229613; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.3209 0.2266 0.2236 0.2341 0.2321 0.2274 0.2257 0.2251 0.2228 0.2221 0.2204 0.2201 0.2186 0.2188 0.2175 0.2181 

[TRAIN] Epoch[4](1324/1500); Loss: 0.164856; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2120 0.1646 0.1679 0.1694 0.1660 0.1634 0.1632 0.1620 0.1599 0.1597 0.1591 0.1583 0.1580 0.1580 0.1580 0.1582 

[TRAIN] Epoch[4](1325/1500); Loss: 0.231658; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2561 0.2173 0.2257 0.2316 0.2280 0.2266 0.2244 0.2234 0.2228 0.2258 0.2295 0.2324 0.2351 0.2391 0.2425 0.2462 

[TRAIN] Epoch[4](1326/1500); Loss: 0.135589; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1799 0.1680 0.1622 0.1613 0.1542 0.1451 0.1319 0.1193 0.1098 0.1105 0.1123 0.1157 0.1186 0.1220 0.1271 0.1316 

[TRAIN] Epoch[4](1327/1500); Loss: 0.093090; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0655 0.0692 0.0745 0.0719 0.0743 0.0768 0.0813 0.0859 0.0913 0.0963 0.1023 0.1078 0.1141 0.1199 0.1262 0.1322 

[TRAIN] Epoch[4](1328/1500); Loss: 0.113929; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1307 0.1074 0.1091 0.1117 0.1095 0.1093 0.1094 0.1099 0.1107 0.1123 0.1132 0.1147 0.1161 0.1178 0.1195 0.1216 

[TRAIN] Epoch[4](1329/1500); Loss: 0.094941; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1454 0.1024 0.0934 0.0974 0.0930 0.0874 0.0865 0.0875 0.0863 0.0871 0.0881 0.0897 0.0911 0.0929 0.0944 0.0966 

[TRAIN] Epoch[4](1330/1500); Loss: 0.139195; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.2460 0.1654 0.1590 0.1800 0.1658 0.1440 0.1203 0.1100 0.1137 0.1140 0.1108 0.1130 0.1155 0.1193 0.1229 0.1273 

[TRAIN] Epoch[4](1331/1500); Loss: 0.140930; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3118 0.2228 0.2147 0.2465 0.2270 0.1977 0.1544 0.1094 0.0729 0.0729 0.0726 0.0698 0.0678 0.0684 0.0716 0.0746 

[TRAIN] Epoch[4](1332/1500); Loss: 0.235504; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2994 0.2614 0.2584 0.2670 0.2572 0.2465 0.2339 0.2222 0.2135 0.2102 0.2096 0.2121 0.2164 0.2192 0.2191 0.2221 

[TRAIN] Epoch[4](1333/1500); Loss: 0.250687; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.3259 0.2595 0.2543 0.2599 0.2564 0.2514 0.2504 0.2487 0.2458 0.2431 0.2417 0.2391 0.2367 0.2344 0.2329 0.2307 

[TRAIN] Epoch[4](1334/1500); Loss: 0.094602; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1423 0.0999 0.0923 0.0960 0.0913 0.0862 0.0860 0.0880 0.0873 0.0877 0.0887 0.0903 0.0917 0.0935 0.0952 0.0972 

[TRAIN] Epoch[4](1335/1500); Loss: 0.140404; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1545 0.1288 0.1284 0.1297 0.1304 0.1311 0.1331 0.1355 0.1371 0.1397 0.1421 0.1452 0.1479 0.1512 0.1542 0.1576 

[TRAIN] Epoch[4](1336/1500); Loss: 0.201721; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3097 0.2115 0.2056 0.2158 0.2126 0.2043 0.1997 0.1972 0.1928 0.1897 0.1860 0.1838 0.1808 0.1801 0.1786 0.1794 

[TRAIN] Epoch[4](1337/1500); Loss: 0.141211; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1817 0.1447 0.1451 0.1531 0.1451 0.1393 0.1351 0.1343 0.1334 0.1333 0.1331 0.1343 0.1350 0.1361 0.1371 0.1387 

[TRAIN] Epoch[4](1338/1500); Loss: 0.115210; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1269 0.1059 0.1061 0.1087 0.1096 0.1099 0.1109 0.1123 0.1133 0.1148 0.1164 0.1180 0.1198 0.1217 0.1236 0.1255 

[TRAIN] Epoch[4](1339/1500); Loss: 0.139257; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1980 0.1494 0.1405 0.1507 0.1432 0.1330 0.1265 0.1276 0.1271 0.1272 0.1281 0.1302 0.1323 0.1352 0.1377 0.1414 

[TRAIN] Epoch[4](1340/1500); Loss: 0.212756; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2741 0.2279 0.2237 0.2310 0.2252 0.2170 0.2070 0.1984 0.1960 0.2006 0.1982 0.1987 0.1992 0.2012 0.2021 0.2039 

[TRAIN] Epoch[4](1341/1500); Loss: 0.180352; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.2253 0.1876 0.1858 0.1888 0.1850 0.1814 0.1801 0.1782 0.1762 0.1744 0.1728 0.1717 0.1710 0.1699 0.1689 0.1685 

[TRAIN] Epoch[4](1342/1500); Loss: 0.153888; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1681 0.1487 0.1475 0.1496 0.1503 0.1500 0.1506 0.1512 0.1515 0.1523 0.1534 0.1549 0.1565 0.1577 0.1591 0.1608 

[TRAIN] Epoch[4](1343/1500); Loss: 0.133286; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1798 0.1471 0.1413 0.1448 0.1386 0.1318 0.1261 0.1229 0.1221 0.1221 0.1229 0.1240 0.1252 0.1266 0.1279 0.1294 

[TRAIN] Epoch[4](1344/1500); Loss: 0.171735; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2211 0.1709 0.1732 0.1781 0.1745 0.1728 0.1725 0.1705 0.1689 0.1677 0.1658 0.1643 0.1632 0.1622 0.1613 0.1607 

[TRAIN] Epoch[4](1345/1500); Loss: 0.193681; Backpropagation: 0.0917 sec; Batch: 0.4226 sec
0.2197 0.1948 0.1949 0.1977 0.1945 0.1924 0.1901 0.1897 0.1900 0.1901 0.1898 0.1903 0.1906 0.1909 0.1913 0.1919 

[TRAIN] Epoch[4](1346/1500); Loss: 0.170942; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2160 0.1816 0.1802 0.1810 0.1753 0.1728 0.1714 0.1687 0.1668 0.1647 0.1631 0.1616 0.1598 0.1586 0.1573 0.1560 

[TRAIN] Epoch[4](1347/1500); Loss: 0.188173; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2174 0.1935 0.1944 0.1936 0.1908 0.1894 0.1882 0.1865 0.1852 0.1839 0.1830 0.1821 0.1814 0.1807 0.1803 0.1801 

[TRAIN] Epoch[4](1348/1500); Loss: 0.111840; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1725 0.1183 0.1134 0.1236 0.1132 0.1030 0.1034 0.1026 0.1005 0.1015 0.1024 0.1037 0.1053 0.1068 0.1086 0.1106 

[TRAIN] Epoch[4](1349/1500); Loss: 0.183038; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.3103 0.2316 0.2183 0.2210 0.2151 0.2010 0.1917 0.1815 0.1695 0.1590 0.1495 0.1424 0.1370 0.1345 0.1335 0.1325 

[TRAIN] Epoch[4](1350/1500); Loss: 0.172296; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2888 0.2064 0.1915 0.1964 0.1920 0.1797 0.1707 0.1632 0.1557 0.1498 0.1449 0.1430 0.1426 0.1433 0.1439 0.1448 

[TRAIN] Epoch[4](1351/1500); Loss: 0.119459; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1604 0.1239 0.1255 0.1217 0.1206 0.1196 0.1186 0.1168 0.1165 0.1156 0.1140 0.1131 0.1121 0.1115 0.1108 0.1106 

[TRAIN] Epoch[4](1352/1500); Loss: 0.143669; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2048 0.1674 0.1591 0.1578 0.1530 0.1469 0.1434 0.1397 0.1362 0.1331 0.1304 0.1283 0.1263 0.1249 0.1239 0.1234 

[TRAIN] Epoch[4](1353/1500); Loss: 0.107227; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1232 0.1140 0.1150 0.1147 0.1102 0.1072 0.1058 0.1055 0.1041 0.1028 0.1028 0.1021 0.1019 0.1018 0.1021 0.1025 

[TRAIN] Epoch[4](1354/1500); Loss: 0.184776; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.2577 0.2133 0.2041 0.2056 0.2008 0.1922 0.1852 0.1786 0.1731 0.1704 0.1679 0.1656 0.1633 0.1612 0.1594 0.1580 

[TRAIN] Epoch[4](1355/1500); Loss: 0.161990; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2216 0.1808 0.1732 0.1759 0.1726 0.1664 0.1608 0.1553 0.1513 0.1505 0.1487 0.1481 0.1470 0.1467 0.1463 0.1464 

[TRAIN] Epoch[4](1356/1500); Loss: 0.134065; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1812 0.1588 0.1495 0.1451 0.1405 0.1364 0.1328 0.1296 0.1267 0.1242 0.1227 0.1211 0.1200 0.1193 0.1186 0.1186 

[TRAIN] Epoch[4](1357/1500); Loss: 0.150914; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2131 0.1740 0.1709 0.1765 0.1680 0.1580 0.1456 0.1369 0.1366 0.1354 0.1336 0.1334 0.1330 0.1333 0.1332 0.1331 

[TRAIN] Epoch[4](1358/1500); Loss: 0.132962; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1949 0.1541 0.1452 0.1452 0.1427 0.1368 0.1342 0.1310 0.1267 0.1238 0.1206 0.1180 0.1158 0.1141 0.1127 0.1115 

[TRAIN] Epoch[4](1359/1500); Loss: 0.126952; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2706 0.1801 0.1493 0.1490 0.1415 0.1224 0.1106 0.1025 0.0979 0.0970 0.0996 0.0982 0.1000 0.1040 0.1033 0.1052 

[TRAIN] Epoch[4](1360/1500); Loss: 0.156466; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2577 0.2081 0.1867 0.1852 0.1799 0.1695 0.1620 0.1536 0.1455 0.1380 0.1300 0.1239 0.1188 0.1154 0.1142 0.1148 

[TRAIN] Epoch[4](1361/1500); Loss: 0.160919; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2819 0.2151 0.1938 0.1926 0.1858 0.1701 0.1595 0.1488 0.1387 0.1318 0.1287 0.1264 0.1259 0.1256 0.1243 0.1260 

[TRAIN] Epoch[4](1362/1500); Loss: 0.118079; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1725 0.1331 0.1260 0.1261 0.1227 0.1180 0.1158 0.1129 0.1103 0.1087 0.1075 0.1067 0.1065 0.1068 0.1073 0.1083 

[TRAIN] Epoch[4](1363/1500); Loss: 0.172301; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.2213 0.1819 0.1748 0.1769 0.1752 0.1717 0.1705 0.1691 0.1677 0.1667 0.1653 0.1644 0.1636 0.1629 0.1623 0.1624 

[TRAIN] Epoch[4](1364/1500); Loss: 0.119339; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1572 0.1287 0.1252 0.1288 0.1241 0.1193 0.1178 0.1154 0.1134 0.1120 0.1113 0.1110 0.1108 0.1111 0.1113 0.1119 

[TRAIN] Epoch[4](1365/1500); Loss: 0.062027; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1241 0.0852 0.0762 0.0823 0.0738 0.0626 0.0542 0.0492 0.0464 0.0461 0.0464 0.0470 0.0477 0.0490 0.0503 0.0519 

[TRAIN] Epoch[4](1366/1500); Loss: 0.144327; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1403 0.1255 0.1255 0.1277 0.1372 0.1408 0.1385 0.1398 0.1445 0.1455 0.1477 0.1531 0.1546 0.1577 0.1644 0.1665 

[TRAIN] Epoch[4](1367/1500); Loss: 0.121621; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1620 0.1454 0.1375 0.1279 0.1216 0.1185 0.1156 0.1134 0.1121 0.1114 0.1105 0.1112 0.1123 0.1129 0.1149 0.1188 

[TRAIN] Epoch[4](1368/1500); Loss: 0.153121; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.2114 0.1768 0.1664 0.1656 0.1627 0.1581 0.1548 0.1502 0.1464 0.1426 0.1394 0.1370 0.1355 0.1346 0.1342 0.1341 

[TRAIN] Epoch[4](1369/1500); Loss: 0.113229; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1976 0.1407 0.1263 0.1254 0.1215 0.1129 0.1081 0.1038 0.1012 0.0992 0.0981 0.0969 0.0958 0.0953 0.0945 0.0945 

[TRAIN] Epoch[4](1370/1500); Loss: 0.172347; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2546 0.2140 0.2022 0.2004 0.1948 0.1861 0.1787 0.1704 0.1614 0.1542 0.1474 0.1425 0.1394 0.1372 0.1368 0.1376 

[TRAIN] Epoch[4](1371/1500); Loss: 0.120328; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2467 0.1659 0.1287 0.1258 0.1182 0.1061 0.1029 0.1022 0.1016 0.1000 0.1008 0.1014 0.1029 0.1052 0.1065 0.1103 

[TRAIN] Epoch[4](1372/1500); Loss: 0.103312; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1445 0.1152 0.1118 0.1152 0.1100 0.1036 0.0981 0.0954 0.0942 0.0939 0.0943 0.0944 0.0949 0.0951 0.0957 0.0968 

[TRAIN] Epoch[4](1373/1500); Loss: 0.076802; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1147 0.0869 0.0822 0.0821 0.0797 0.0754 0.0741 0.0722 0.0704 0.0696 0.0691 0.0691 0.0696 0.0701 0.0712 0.0724 

[TRAIN] Epoch[4](1374/1500); Loss: 0.073721; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.0981 0.0799 0.0771 0.0762 0.0729 0.0700 0.0695 0.0688 0.0685 0.0689 0.0691 0.0697 0.0709 0.0718 0.0734 0.0749 

[TRAIN] Epoch[4](1375/1500); Loss: 0.121628; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.1744 0.1345 0.1291 0.1332 0.1298 0.1241 0.1209 0.1184 0.1162 0.1142 0.1118 0.1103 0.1086 0.1076 0.1066 0.1062 

[TRAIN] Epoch[4](1376/1500); Loss: 0.128015; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1793 0.1449 0.1398 0.1468 0.1396 0.1304 0.1213 0.1157 0.1133 0.1134 0.1142 0.1152 0.1164 0.1179 0.1191 0.1208 

[TRAIN] Epoch[4](1377/1500); Loss: 0.164357; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1984 0.1746 0.1721 0.1709 0.1681 0.1653 0.1636 0.1613 0.1596 0.1584 0.1572 0.1566 0.1559 0.1557 0.1560 0.1560 

[TRAIN] Epoch[4](1378/1500); Loss: 0.175112; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2530 0.2031 0.2001 0.2050 0.1989 0.1891 0.1788 0.1690 0.1605 0.1543 0.1510 0.1500 0.1490 0.1478 0.1465 0.1457 

[TRAIN] Epoch[4](1379/1500); Loss: 0.073132; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.0922 0.0727 0.0744 0.0755 0.0730 0.0715 0.0708 0.0699 0.0704 0.0705 0.0699 0.0705 0.0711 0.0714 0.0725 0.0738 

[TRAIN] Epoch[4](1380/1500); Loss: 0.116389; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1625 0.1293 0.1254 0.1244 0.1185 0.1142 0.1125 0.1103 0.1092 0.1081 0.1076 0.1072 0.1073 0.1078 0.1085 0.1092 

[TRAIN] Epoch[4](1381/1500); Loss: 0.182663; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2581 0.1972 0.1948 0.2006 0.1973 0.1911 0.1868 0.1822 0.1774 0.1729 0.1690 0.1652 0.1618 0.1588 0.1559 0.1535 

[TRAIN] Epoch[4](1382/1500); Loss: 0.056235; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0752 0.0620 0.0589 0.0592 0.0539 0.0485 0.0486 0.0500 0.0501 0.0513 0.0524 0.0542 0.0559 0.0578 0.0598 0.0619 

[TRAIN] Epoch[4](1383/1500); Loss: 0.139383; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1856 0.1566 0.1497 0.1522 0.1485 0.1429 0.1392 0.1360 0.1313 0.1278 0.1261 0.1260 0.1265 0.1268 0.1271 0.1278 

[TRAIN] Epoch[4](1384/1500); Loss: 0.178825; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2766 0.2098 0.2059 0.2181 0.2084 0.1973 0.1835 0.1709 0.1596 0.1510 0.1487 0.1492 0.1462 0.1456 0.1447 0.1456 

[TRAIN] Epoch[4](1385/1500); Loss: 0.111060; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1277 0.1196 0.1160 0.1121 0.1110 0.1095 0.1090 0.1085 0.1080 0.1077 0.1076 0.1074 0.1077 0.1080 0.1085 0.1087 

[TRAIN] Epoch[4](1386/1500); Loss: 0.181027; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2036 0.1842 0.1832 0.1836 0.1826 0.1808 0.1799 0.1790 0.1780 0.1775 0.1771 0.1771 0.1770 0.1773 0.1777 0.1781 

[TRAIN] Epoch[4](1387/1500); Loss: 0.138924; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1827 0.1570 0.1529 0.1512 0.1464 0.1418 0.1386 0.1351 0.1325 0.1299 0.1281 0.1267 0.1253 0.1248 0.1249 0.1249 

[TRAIN] Epoch[4](1388/1500); Loss: 0.148689; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1786 0.1556 0.1527 0.1535 0.1498 0.1462 0.1437 0.1428 0.1428 0.1429 0.1435 0.1440 0.1445 0.1453 0.1460 0.1471 

[TRAIN] Epoch[4](1389/1500); Loss: 0.111359; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1551 0.1100 0.1117 0.1167 0.1142 0.1114 0.1097 0.1086 0.1070 0.1058 0.1051 0.1047 0.1046 0.1051 0.1056 0.1064 

[TRAIN] Epoch[4](1390/1500); Loss: 0.170079; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2122 0.1616 0.1638 0.1702 0.1688 0.1672 0.1672 0.1672 0.1670 0.1671 0.1669 0.1675 0.1677 0.1685 0.1686 0.1696 

[TRAIN] Epoch[4](1391/1500); Loss: 0.143032; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1901 0.1555 0.1509 0.1534 0.1503 0.1453 0.1423 0.1403 0.1379 0.1361 0.1343 0.1327 0.1313 0.1302 0.1293 0.1287 

[TRAIN] Epoch[4](1392/1500); Loss: 0.201465; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2507 0.2204 0.2134 0.2125 0.2091 0.2043 0.1991 0.1945 0.1914 0.1909 0.1904 0.1900 0.1894 0.1893 0.1891 0.1891 

[TRAIN] Epoch[4](1393/1500); Loss: 0.290799; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3815 0.3032 0.3039 0.3138 0.3100 0.3029 0.2981 0.2928 0.2878 0.2816 0.2768 0.2708 0.2656 0.2598 0.2548 0.2492 

[TRAIN] Epoch[4](1394/1500); Loss: 0.148064; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.3402 0.2436 0.2368 0.2737 0.2538 0.2226 0.1756 0.1231 0.0716 0.0617 0.0650 0.0641 0.0592 0.0575 0.0599 0.0608 

[TRAIN] Epoch[4](1395/1500); Loss: 0.292281; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3791 0.3032 0.3051 0.3135 0.3103 0.3045 0.2991 0.2941 0.2898 0.2842 0.2792 0.2737 0.2681 0.2629 0.2575 0.2523 

[TRAIN] Epoch[4](1396/1500); Loss: 0.122353; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1320 0.1223 0.1257 0.1224 0.1206 0.1200 0.1199 0.1197 0.1196 0.1199 0.1205 0.1211 0.1220 0.1229 0.1241 0.1251 

[TRAIN] Epoch[4](1397/1500); Loss: 0.144026; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2034 0.1453 0.1471 0.1544 0.1520 0.1478 0.1448 0.1422 0.1394 0.1370 0.1348 0.1331 0.1318 0.1309 0.1302 0.1301 

[TRAIN] Epoch[4](1398/1500); Loss: 0.128066; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1545 0.1364 0.1356 0.1364 0.1318 0.1289 0.1273 0.1257 0.1243 0.1231 0.1218 0.1211 0.1207 0.1203 0.1205 0.1209 

[TRAIN] Epoch[4](1399/1500); Loss: 0.148427; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.3006 0.2164 0.2018 0.2205 0.2023 0.1743 0.1385 0.1103 0.0969 0.0989 0.0993 0.0988 0.1001 0.1029 0.1053 0.1079 

[TRAIN] Epoch[4](1400/1500); Loss: 0.221832; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3739 0.2991 0.2859 0.3068 0.2916 0.2644 0.2266 0.1837 0.1564 0.1658 0.1641 0.1617 0.1623 0.1674 0.1699 0.1697 

[TRAIN] Epoch[4](1401/1500); Loss: 0.110530; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1613 0.1216 0.1225 0.1264 0.1208 0.1145 0.1082 0.1049 0.1024 0.0999 0.0984 0.0975 0.0974 0.0973 0.0975 0.0978 

[TRAIN] Epoch[4](1402/1500); Loss: 0.178386; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2094 0.1871 0.1869 0.1877 0.1832 0.1802 0.1767 0.1739 0.1729 0.1721 0.1713 0.1707 0.1706 0.1703 0.1705 0.1707 

[TRAIN] Epoch[4](1403/1500); Loss: 0.131553; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1773 0.1535 0.1476 0.1445 0.1393 0.1346 0.1307 0.1267 0.1237 0.1213 0.1189 0.1177 0.1174 0.1169 0.1172 0.1178 

[TRAIN] Epoch[4](1404/1500); Loss: 0.180573; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2418 0.1908 0.1888 0.1952 0.1923 0.1872 0.1842 0.1806 0.1766 0.1731 0.1697 0.1668 0.1639 0.1614 0.1592 0.1575 

[TRAIN] Epoch[4](1405/1500); Loss: 0.134497; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1704 0.1455 0.1409 0.1401 0.1367 0.1330 0.1305 0.1295 0.1289 0.1284 0.1281 0.1279 0.1278 0.1280 0.1282 0.1283 

[TRAIN] Epoch[4](1406/1500); Loss: 0.119734; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1518 0.1264 0.1234 0.1246 0.1234 0.1201 0.1188 0.1170 0.1153 0.1141 0.1132 0.1128 0.1128 0.1132 0.1141 0.1149 

[TRAIN] Epoch[4](1407/1500); Loss: 0.099869; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1243 0.1050 0.1031 0.1023 0.1000 0.0978 0.0972 0.0966 0.0960 0.0957 0.0956 0.0959 0.0962 0.0966 0.0975 0.0979 

[TRAIN] Epoch[4](1408/1500); Loss: 0.195955; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.3657 0.2947 0.2892 0.3129 0.2978 0.2740 0.2378 0.1981 0.1564 0.1147 0.0938 0.1015 0.1034 0.0995 0.0981 0.0978 

[TRAIN] Epoch[4](1409/1500); Loss: 0.141956; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2093 0.1639 0.1600 0.1628 0.1589 0.1521 0.1470 0.1414 0.1360 0.1309 0.1262 0.1223 0.1188 0.1160 0.1136 0.1121 

[TRAIN] Epoch[4](1410/1500); Loss: 0.051238; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0855 0.0604 0.0601 0.0602 0.0533 0.0463 0.0391 0.0393 0.0409 0.0419 0.0432 0.0453 0.0475 0.0498 0.0523 0.0549 

[TRAIN] Epoch[4](1411/1500); Loss: 0.129480; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1842 0.1387 0.1360 0.1393 0.1367 0.1319 0.1293 0.1263 0.1233 0.1207 0.1188 0.1176 0.1167 0.1167 0.1172 0.1181 

[TRAIN] Epoch[4](1412/1500); Loss: 0.126786; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1547 0.1421 0.1346 0.1306 0.1274 0.1256 0.1237 0.1220 0.1209 0.1204 0.1197 0.1200 0.1202 0.1208 0.1223 0.1236 

[TRAIN] Epoch[4](1413/1500); Loss: 0.104866; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1461 0.1171 0.1107 0.1111 0.1090 0.1057 0.1036 0.1016 0.0996 0.0981 0.0969 0.0961 0.0956 0.0955 0.0956 0.0957 

[TRAIN] Epoch[4](1414/1500); Loss: 0.066411; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1374 0.0848 0.0754 0.0860 0.0761 0.0637 0.0549 0.0523 0.0520 0.0525 0.0520 0.0526 0.0537 0.0550 0.0562 0.0579 

[TRAIN] Epoch[4](1415/1500); Loss: 0.061975; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.0698 0.0682 0.0675 0.0632 0.0606 0.0593 0.0580 0.0571 0.0568 0.0573 0.0586 0.0600 0.0612 0.0628 0.0647 0.0667 

[TRAIN] Epoch[4](1416/1500); Loss: 0.147201; Backpropagation: 0.0918 sec; Batch: 0.4262 sec
0.2341 0.1620 0.1613 0.1710 0.1655 0.1548 0.1493 0.1437 0.1377 0.1328 0.1294 0.1263 0.1238 0.1218 0.1210 0.1210 

[TRAIN] Epoch[4](1417/1500); Loss: 0.120924; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1452 0.1265 0.1244 0.1247 0.1233 0.1213 0.1202 0.1188 0.1177 0.1168 0.1163 0.1161 0.1160 0.1158 0.1159 0.1160 

[TRAIN] Epoch[4](1418/1500); Loss: 0.235498; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3469 0.2783 0.2712 0.2768 0.2716 0.2594 0.2494 0.2396 0.2290 0.2182 0.2087 0.1992 0.1907 0.1827 0.1760 0.1704 

[TRAIN] Epoch[4](1419/1500); Loss: 0.156139; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1822 0.1666 0.1628 0.1611 0.1593 0.1571 0.1556 0.1535 0.1520 0.1510 0.1503 0.1496 0.1493 0.1490 0.1492 0.1495 

[TRAIN] Epoch[4](1420/1500); Loss: 0.145416; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.2032 0.1668 0.1611 0.1626 0.1574 0.1511 0.1439 0.1359 0.1312 0.1306 0.1303 0.1301 0.1296 0.1302 0.1310 0.1317 

[TRAIN] Epoch[4](1421/1500); Loss: 0.121020; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2376 0.1481 0.1436 0.1521 0.1448 0.1310 0.1192 0.1105 0.1026 0.0962 0.0923 0.0901 0.0898 0.0909 0.0924 0.0951 

[TRAIN] Epoch[4](1422/1500); Loss: 0.138262; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1822 0.1526 0.1480 0.1482 0.1448 0.1396 0.1355 0.1327 0.1314 0.1301 0.1290 0.1280 0.1276 0.1274 0.1274 0.1276 

[TRAIN] Epoch[4](1423/1500); Loss: 0.164454; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1946 0.1703 0.1677 0.1695 0.1667 0.1638 0.1612 0.1597 0.1592 0.1585 0.1586 0.1590 0.1592 0.1602 0.1609 0.1621 

[TRAIN] Epoch[4](1424/1500); Loss: 0.137849; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1356 0.1236 0.1233 0.1260 0.1341 0.1343 0.1322 0.1356 0.1363 0.1369 0.1416 0.1433 0.1455 0.1498 0.1520 0.1555 

[TRAIN] Epoch[4](1425/1500); Loss: 0.098593; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1472 0.1138 0.1102 0.1104 0.1055 0.0996 0.0951 0.0915 0.0892 0.0881 0.0870 0.0869 0.0868 0.0874 0.0886 0.0902 

[TRAIN] Epoch[4](1426/1500); Loss: 0.165600; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2502 0.1919 0.1866 0.1888 0.1835 0.1733 0.1654 0.1582 0.1514 0.1464 0.1429 0.1410 0.1406 0.1418 0.1435 0.1440 

[TRAIN] Epoch[4](1427/1500); Loss: 0.103947; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1695 0.1267 0.1177 0.1171 0.1113 0.1034 0.0990 0.0945 0.0923 0.0907 0.0876 0.0880 0.0900 0.0884 0.0909 0.0961 

[TRAIN] Epoch[4](1428/1500); Loss: 0.138811; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1783 0.1536 0.1451 0.1452 0.1433 0.1398 0.1369 0.1341 0.1316 0.1301 0.1293 0.1292 0.1298 0.1309 0.1313 0.1322 

[TRAIN] Epoch[4](1429/1500); Loss: 0.153409; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2505 0.1877 0.1771 0.1790 0.1739 0.1628 0.1553 0.1478 0.1408 0.1350 0.1299 0.1262 0.1236 0.1220 0.1213 0.1215 

[TRAIN] Epoch[4](1430/1500); Loss: 0.096960; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1580 0.1226 0.1156 0.1179 0.1117 0.1013 0.0883 0.0796 0.0832 0.0826 0.0806 0.0806 0.0808 0.0819 0.0829 0.0838 

[TRAIN] Epoch[4](1431/1500); Loss: 0.162793; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.3011 0.2237 0.2058 0.2078 0.2012 0.1836 0.1721 0.1601 0.1462 0.1347 0.1244 0.1161 0.1100 0.1067 0.1054 0.1058 

[TRAIN] Epoch[4](1432/1500); Loss: 0.142961; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1711 0.1516 0.1452 0.1441 0.1434 0.1410 0.1397 0.1391 0.1386 0.1382 0.1383 0.1389 0.1387 0.1394 0.1399 0.1402 

[TRAIN] Epoch[4](1433/1500); Loss: 0.145561; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.2216 0.1728 0.1608 0.1614 0.1592 0.1517 0.1469 0.1425 0.1370 0.1330 0.1288 0.1257 0.1231 0.1216 0.1211 0.1217 

[TRAIN] Epoch[4](1434/1500); Loss: 0.056553; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1017 0.0676 0.0601 0.0579 0.0547 0.0524 0.0513 0.0506 0.0493 0.0494 0.0506 0.0495 0.0507 0.0529 0.0523 0.0537 

[TRAIN] Epoch[4](1435/1500); Loss: 0.063923; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1717 0.0951 0.0885 0.1110 0.0949 0.0722 0.0451 0.0353 0.0399 0.0385 0.0357 0.0355 0.0371 0.0396 0.0405 0.0420 

[TRAIN] Epoch[4](1436/1500); Loss: 0.100242; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1148 0.1047 0.1024 0.1016 0.1005 0.0994 0.0988 0.0981 0.0979 0.0974 0.0975 0.0975 0.0976 0.0977 0.0987 0.0992 

[TRAIN] Epoch[4](1437/1500); Loss: 0.067931; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1460 0.0995 0.0821 0.0811 0.0716 0.0594 0.0565 0.0524 0.0528 0.0506 0.0510 0.0538 0.0536 0.0552 0.0608 0.0605 

[TRAIN] Epoch[4](1438/1500); Loss: 0.074534; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1191 0.0808 0.0755 0.0759 0.0735 0.0715 0.0698 0.0694 0.0693 0.0674 0.0672 0.0699 0.0684 0.0696 0.0725 0.0727 

[TRAIN] Epoch[4](1439/1500); Loss: 0.157158; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2351 0.1943 0.1816 0.1795 0.1728 0.1643 0.1568 0.1499 0.1444 0.1397 0.1361 0.1339 0.1320 0.1311 0.1316 0.1314 

[TRAIN] Epoch[4](1440/1500); Loss: 0.154693; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1831 0.1645 0.1606 0.1595 0.1562 0.1532 0.1510 0.1499 0.1493 0.1492 0.1490 0.1491 0.1495 0.1499 0.1502 0.1508 

[TRAIN] Epoch[4](1441/1500); Loss: 0.135014; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2088 0.1662 0.1516 0.1496 0.1434 0.1347 0.1290 0.1243 0.1209 0.1191 0.1181 0.1191 0.1184 0.1189 0.1185 0.1195 

[TRAIN] Epoch[4](1442/1500); Loss: 0.120120; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1697 0.1371 0.1297 0.1297 0.1252 0.1196 0.1169 0.1145 0.1107 0.1091 0.1100 0.1081 0.1086 0.1108 0.1101 0.1121 

[TRAIN] Epoch[4](1443/1500); Loss: 0.105535; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2093 0.1372 0.1215 0.1211 0.1157 0.1063 0.1005 0.0968 0.0908 0.0872 0.0832 0.0824 0.0820 0.0832 0.0844 0.0871 

[TRAIN] Epoch[4](1444/1500); Loss: 0.117963; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1866 0.1468 0.1354 0.1405 0.1335 0.1215 0.1068 0.1012 0.1015 0.1032 0.1012 0.1001 0.1015 0.1017 0.1019 0.1041 

[TRAIN] Epoch[4](1445/1500); Loss: 0.088130; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1619 0.1208 0.1042 0.1005 0.0945 0.0865 0.0808 0.0762 0.0732 0.0712 0.0714 0.0714 0.0718 0.0744 0.0748 0.0767 

[TRAIN] Epoch[4](1446/1500); Loss: 0.132888; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2626 0.2057 0.1747 0.1672 0.1558 0.1383 0.1251 0.1144 0.1062 0.1010 0.0981 0.0957 0.0951 0.0947 0.0957 0.0960 

[TRAIN] Epoch[4](1447/1500); Loss: 0.178817; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2435 0.2182 0.2064 0.2016 0.1967 0.1894 0.1805 0.1705 0.1625 0.1581 0.1566 0.1565 0.1556 0.1553 0.1546 0.1551 

[TRAIN] Epoch[4](1448/1500); Loss: 0.078304; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1149 0.0981 0.0928 0.0876 0.0814 0.0772 0.0740 0.0712 0.0698 0.0689 0.0684 0.0680 0.0692 0.0690 0.0709 0.0716 

[TRAIN] Epoch[4](1449/1500); Loss: 0.041161; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0440 0.0469 0.0417 0.0384 0.0371 0.0349 0.0347 0.0363 0.0371 0.0383 0.0403 0.0416 0.0438 0.0454 0.0477 0.0505 

[TRAIN] Epoch[4](1450/1500); Loss: 0.115938; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1694 0.1336 0.1219 0.1199 0.1170 0.1146 0.1124 0.1109 0.1091 0.1075 0.1071 0.1059 0.1057 0.1076 0.1063 0.1062 

[TRAIN] Epoch[4](1451/1500); Loss: 0.091418; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1793 0.1268 0.1147 0.1178 0.1081 0.0938 0.0780 0.0724 0.0723 0.0717 0.0712 0.0705 0.0704 0.0717 0.0716 0.0726 

[TRAIN] Epoch[4](1452/1500); Loss: 0.140782; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1892 0.1538 0.1465 0.1523 0.1458 0.1386 0.1325 0.1283 0.1272 0.1275 0.1293 0.1322 0.1329 0.1355 0.1398 0.1411 

[TRAIN] Epoch[4](1453/1500); Loss: 0.197267; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2991 0.2593 0.2448 0.2439 0.2357 0.2240 0.2093 0.1928 0.1760 0.1632 0.1560 0.1532 0.1518 0.1503 0.1488 0.1480 

[TRAIN] Epoch[4](1454/1500); Loss: 0.179174; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2956 0.2333 0.2261 0.2435 0.2309 0.2123 0.1882 0.1634 0.1434 0.1335 0.1294 0.1307 0.1319 0.1340 0.1353 0.1353 

[TRAIN] Epoch[4](1455/1500); Loss: 0.130667; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1892 0.1502 0.1435 0.1442 0.1379 0.1314 0.1285 0.1237 0.1222 0.1198 0.1179 0.1173 0.1158 0.1157 0.1169 0.1165 

[TRAIN] Epoch[4](1456/1500); Loss: 0.076522; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1667 0.1007 0.0820 0.0816 0.0778 0.0715 0.0680 0.0662 0.0645 0.0620 0.0625 0.0628 0.0623 0.0651 0.0640 0.0667 

[TRAIN] Epoch[4](1457/1500); Loss: 0.086765; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1219 0.1026 0.0946 0.0910 0.0861 0.0815 0.0791 0.0770 0.0775 0.0771 0.0778 0.0800 0.0824 0.0833 0.0870 0.0892 

[TRAIN] Epoch[4](1458/1500); Loss: 0.141548; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1715 0.1580 0.1490 0.1449 0.1408 0.1385 0.1372 0.1362 0.1361 0.1349 0.1351 0.1349 0.1354 0.1370 0.1369 0.1383 

[TRAIN] Epoch[4](1459/1500); Loss: 0.157089; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2041 0.1809 0.1751 0.1744 0.1689 0.1629 0.1552 0.1486 0.1453 0.1438 0.1428 0.1425 0.1419 0.1418 0.1426 0.1426 

[TRAIN] Epoch[4](1460/1500); Loss: 0.078579; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1084 0.0885 0.0835 0.0826 0.0785 0.0747 0.0734 0.0735 0.0729 0.0728 0.0734 0.0736 0.0739 0.0750 0.0766 0.0760 

[TRAIN] Epoch[4](1461/1500); Loss: 0.075424; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1256 0.0945 0.0860 0.0882 0.0828 0.0757 0.0692 0.0652 0.0628 0.0630 0.0636 0.0636 0.0645 0.0659 0.0675 0.0687 

[TRAIN] Epoch[4](1462/1500); Loss: 0.158958; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2216 0.1866 0.1777 0.1760 0.1679 0.1612 0.1566 0.1506 0.1480 0.1456 0.1434 0.1426 0.1420 0.1412 0.1415 0.1408 

[TRAIN] Epoch[4](1463/1500); Loss: 0.174436; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2226 0.1972 0.1881 0.1851 0.1825 0.1772 0.1737 0.1695 0.1661 0.1635 0.1615 0.1602 0.1603 0.1602 0.1608 0.1624 

[TRAIN] Epoch[4](1464/1500); Loss: 0.092272; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1123 0.1021 0.0986 0.0963 0.0934 0.0907 0.0889 0.0881 0.0877 0.0874 0.0875 0.0874 0.0876 0.0884 0.0895 0.0903 

[TRAIN] Epoch[4](1465/1500); Loss: 0.155706; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2320 0.1930 0.1849 0.1876 0.1812 0.1724 0.1618 0.1509 0.1411 0.1327 0.1269 0.1252 0.1252 0.1260 0.1253 0.1251 

[TRAIN] Epoch[4](1466/1500); Loss: 0.079413; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0981 0.0877 0.0832 0.0815 0.0792 0.0777 0.0774 0.0760 0.0758 0.0757 0.0755 0.0758 0.0760 0.0764 0.0769 0.0776 

[TRAIN] Epoch[4](1467/1500); Loss: 0.079527; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1135 0.0908 0.0847 0.0852 0.0823 0.0783 0.0754 0.0731 0.0720 0.0722 0.0724 0.0726 0.0737 0.0747 0.0755 0.0761 

[TRAIN] Epoch[4](1468/1500); Loss: 0.121964; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1729 0.1529 0.1395 0.1359 0.1314 0.1241 0.1174 0.1113 0.1083 0.1056 0.1053 0.1056 0.1066 0.1082 0.1117 0.1146 

[TRAIN] Epoch[4](1469/1500); Loss: 0.102513; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1164 0.1080 0.1055 0.1043 0.1008 0.0988 0.0978 0.0980 0.0981 0.0984 0.0998 0.0999 0.1011 0.1038 0.1039 0.1055 

[TRAIN] Epoch[4](1470/1500); Loss: 0.200222; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3736 0.2913 0.2858 0.3088 0.2904 0.2620 0.2202 0.1745 0.1340 0.1255 0.1255 0.1251 0.1223 0.1218 0.1234 0.1193 

[TRAIN] Epoch[4](1471/1500); Loss: 0.160709; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2267 0.1922 0.1871 0.1913 0.1823 0.1710 0.1574 0.1475 0.1430 0.1424 0.1411 0.1389 0.1379 0.1385 0.1372 0.1368 

[TRAIN] Epoch[4](1472/1500); Loss: 0.063454; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0764 0.0695 0.0693 0.0667 0.0628 0.0618 0.0603 0.0594 0.0584 0.0582 0.0588 0.0600 0.0614 0.0627 0.0640 0.0656 

[TRAIN] Epoch[4](1473/1500); Loss: 0.118774; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2075 0.1611 0.1545 0.1684 0.1573 0.1416 0.1206 0.1050 0.0903 0.0856 0.0859 0.0844 0.0845 0.0845 0.0843 0.0849 

[TRAIN] Epoch[4](1474/1500); Loss: 0.138090; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1770 0.1555 0.1482 0.1463 0.1432 0.1388 0.1356 0.1326 0.1304 0.1293 0.1288 0.1286 0.1287 0.1288 0.1290 0.1286 

[TRAIN] Epoch[4](1475/1500); Loss: 0.068201; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.0745 0.0803 0.0787 0.0703 0.0681 0.0666 0.0645 0.0635 0.0624 0.0628 0.0640 0.0643 0.0658 0.0674 0.0680 0.0698 

[TRAIN] Epoch[4](1476/1500); Loss: 0.160828; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2595 0.2058 0.1994 0.2099 0.1961 0.1796 0.1577 0.1371 0.1350 0.1303 0.1318 0.1278 0.1257 0.1261 0.1265 0.1250 

[TRAIN] Epoch[4](1477/1500); Loss: 0.086109; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1666 0.1054 0.0942 0.0937 0.0885 0.0791 0.0749 0.0724 0.0712 0.0711 0.0732 0.0735 0.0757 0.0788 0.0790 0.0805 

[TRAIN] Epoch[4](1478/1500); Loss: 0.132007; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2084 0.1501 0.1435 0.1445 0.1376 0.1320 0.1279 0.1242 0.1212 0.1185 0.1174 0.1166 0.1159 0.1172 0.1184 0.1189 

[TRAIN] Epoch[4](1479/1500); Loss: 0.066973; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1645 0.0898 0.0751 0.0747 0.0672 0.0563 0.0520 0.0512 0.0510 0.0511 0.0547 0.0529 0.0554 0.0584 0.0573 0.0599 

[TRAIN] Epoch[4](1480/1500); Loss: 0.139639; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2341 0.1767 0.1664 0.1709 0.1608 0.1487 0.1360 0.1252 0.1189 0.1152 0.1135 0.1123 0.1126 0.1145 0.1137 0.1148 

[TRAIN] Epoch[4](1481/1500); Loss: 0.106330; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1310 0.1134 0.1087 0.1070 0.1060 0.1044 0.1034 0.1028 0.1020 0.1019 0.1023 0.1024 0.1029 0.1037 0.1042 0.1053 

[TRAIN] Epoch[4](1482/1500); Loss: 0.137980; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1800 0.1538 0.1489 0.1469 0.1425 0.1374 0.1342 0.1312 0.1300 0.1288 0.1277 0.1283 0.1278 0.1287 0.1307 0.1308 

[TRAIN] Epoch[4](1483/1500); Loss: 0.134853; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1625 0.1487 0.1426 0.1398 0.1360 0.1335 0.1318 0.1297 0.1286 0.1282 0.1275 0.1278 0.1294 0.1297 0.1298 0.1322 

[TRAIN] Epoch[4](1484/1500); Loss: 0.156036; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2104 0.1684 0.1632 0.1626 0.1554 0.1503 0.1474 0.1464 0.1454 0.1452 0.1466 0.1472 0.1487 0.1512 0.1534 0.1549 

[TRAIN] Epoch[4](1485/1500); Loss: 0.154314; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2226 0.1868 0.1791 0.1844 0.1759 0.1647 0.1515 0.1417 0.1355 0.1334 0.1332 0.1321 0.1321 0.1313 0.1319 0.1329 

[TRAIN] Epoch[4](1486/1500); Loss: 0.089944; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1162 0.1015 0.0956 0.0940 0.0908 0.0880 0.0854 0.0843 0.0839 0.0847 0.0843 0.0846 0.0856 0.0858 0.0867 0.0877 

[TRAIN] Epoch[4](1487/1500); Loss: 0.094443; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2430 0.1583 0.1481 0.1712 0.1531 0.1262 0.0916 0.0610 0.0449 0.0447 0.0443 0.0438 0.0437 0.0446 0.0456 0.0470 

[TRAIN] Epoch[4](1488/1500); Loss: 0.149440; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2226 0.1808 0.1687 0.1653 0.1592 0.1515 0.1451 0.1389 0.1345 0.1321 0.1315 0.1312 0.1314 0.1319 0.1323 0.1340 

[TRAIN] Epoch[4](1489/1500); Loss: 0.208832; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.3712 0.2985 0.2868 0.2855 0.2708 0.2478 0.2309 0.2128 0.1920 0.1720 0.1541 0.1392 0.1271 0.1196 0.1163 0.1167 

[TRAIN] Epoch[4](1490/1500); Loss: 0.156048; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.2542 0.2060 0.1923 0.1893 0.1812 0.1693 0.1602 0.1512 0.1424 0.1349 0.1277 0.1217 0.1176 0.1156 0.1157 0.1175 

[TRAIN] Epoch[4](1491/1500); Loss: 0.102881; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.1542 0.1174 0.1126 0.1125 0.1091 0.1040 0.1018 0.0994 0.0970 0.0951 0.0933 0.0916 0.0907 0.0897 0.0890 0.0886 

[TRAIN] Epoch[4](1492/1500); Loss: 0.073645; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1465 0.0937 0.0884 0.1008 0.0894 0.0756 0.0600 0.0630 0.0588 0.0590 0.0565 0.0569 0.0566 0.0574 0.0575 0.0583 

[TRAIN] Epoch[4](1493/1500); Loss: 0.060917; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1055 0.0769 0.0704 0.0731 0.0671 0.0603 0.0538 0.0496 0.0486 0.0499 0.0507 0.0511 0.0525 0.0539 0.0548 0.0565 

[TRAIN] Epoch[4](1494/1500); Loss: 0.182707; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.3004 0.2417 0.2266 0.2244 0.2153 0.2012 0.1885 0.1753 0.1639 0.1569 0.1497 0.1445 0.1397 0.1352 0.1312 0.1289 

[TRAIN] Epoch[4](1495/1500); Loss: 0.077610; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1085 0.0956 0.0917 0.0844 0.0792 0.0763 0.0739 0.0714 0.0700 0.0695 0.0688 0.0685 0.0699 0.0701 0.0710 0.0731 

[TRAIN] Epoch[4](1496/1500); Loss: 0.152307; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2221 0.1780 0.1670 0.1684 0.1630 0.1554 0.1494 0.1453 0.1432 0.1403 0.1382 0.1361 0.1344 0.1332 0.1319 0.1311 

[TRAIN] Epoch[4](1497/1500); Loss: 0.050200; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.0579 0.0615 0.0519 0.0486 0.0467 0.0452 0.0451 0.0455 0.0460 0.0469 0.0478 0.0489 0.0504 0.0519 0.0532 0.0554 

[TRAIN] Epoch[4](1498/1500); Loss: 0.122987; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1523 0.1342 0.1298 0.1280 0.1249 0.1223 0.1206 0.1190 0.1175 0.1167 0.1164 0.1163 0.1166 0.1171 0.1177 0.1184 

[TRAIN] Epoch[4](1499/1500); Loss: 0.147715; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2489 0.1859 0.1779 0.1774 0.1664 0.1515 0.1418 0.1332 0.1260 0.1218 0.1203 0.1204 0.1202 0.1216 0.1256 0.1246 

[TRAIN] Epoch[4](1500/1500); Loss: 0.124104; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1509 0.1351 0.1330 0.1316 0.1281 0.1245 0.1213 0.1196 0.1184 0.1176 0.1174 0.1170 0.1173 0.1176 0.1178 0.1183 

[TRAIN] Epoch[5](1/1500); Loss: 0.158353; Backpropagation: 0.0980 sec; Batch: 0.4670 sec
0.3065 0.2092 0.2008 0.2054 0.1907 0.1686 0.1512 0.1382 0.1266 0.1194 0.1173 0.1181 0.1175 0.1198 0.1209 0.1234 

[TRAIN] Epoch[5](2/1500); Loss: 0.130277; Backpropagation: 0.0926 sec; Batch: 0.4292 sec
0.2238 0.1563 0.1487 0.1534 0.1436 0.1328 0.1244 0.1189 0.1143 0.1103 0.1089 0.1092 0.1090 0.1093 0.1100 0.1116 

[TRAIN] Epoch[5](3/1500); Loss: 0.104121; Backpropagation: 0.0922 sec; Batch: 0.4256 sec
0.1536 0.1247 0.1182 0.1157 0.1102 0.1045 0.1005 0.0972 0.0942 0.0923 0.0913 0.0912 0.0921 0.0922 0.0936 0.0946 

[TRAIN] Epoch[5](4/1500); Loss: 0.123545; Backpropagation: 0.0922 sec; Batch: 0.4253 sec
0.2069 0.1548 0.1482 0.1494 0.1402 0.1284 0.1186 0.1115 0.1058 0.1017 0.1001 0.0993 0.1005 0.1016 0.1041 0.1056 

[TRAIN] Epoch[5](5/1500); Loss: 0.122777; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2555 0.1871 0.1680 0.1788 0.1649 0.1439 0.1163 0.0919 0.0944 0.0867 0.0847 0.0814 0.0803 0.0781 0.0766 0.0757 

[TRAIN] Epoch[5](6/1500); Loss: 0.069516; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0721 0.0681 0.0719 0.0693 0.0656 0.0655 0.0655 0.0659 0.0667 0.0678 0.0691 0.0703 0.0717 0.0729 0.0743 0.0756 

[TRAIN] Epoch[5](7/1500); Loss: 0.053143; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1275 0.0729 0.0567 0.0549 0.0490 0.0479 0.0430 0.0407 0.0399 0.0396 0.0418 0.0423 0.0436 0.0486 0.0497 0.0522 

[TRAIN] Epoch[5](8/1500); Loss: 0.139568; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2944 0.2215 0.2132 0.2396 0.2229 0.1977 0.1587 0.1156 0.0772 0.0725 0.0704 0.0702 0.0693 0.0697 0.0699 0.0702 

[TRAIN] Epoch[5](9/1500); Loss: 0.109854; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2119 0.1507 0.1407 0.1462 0.1352 0.1216 0.1071 0.0943 0.0886 0.0833 0.0829 0.0799 0.0784 0.0789 0.0783 0.0794 

[TRAIN] Epoch[5](10/1500); Loss: 0.118883; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2218 0.1464 0.1417 0.1603 0.1470 0.1302 0.1100 0.0974 0.0958 0.0937 0.0919 0.0909 0.0921 0.0933 0.0938 0.0958 

[TRAIN] Epoch[5](11/1500); Loss: 0.100653; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1398 0.1215 0.1126 0.1079 0.1031 0.0981 0.0958 0.0943 0.0922 0.0916 0.0922 0.0908 0.0916 0.0929 0.0921 0.0939 

[TRAIN] Epoch[5](12/1500); Loss: 0.096948; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1766 0.1193 0.1126 0.1139 0.1071 0.0974 0.0923 0.0880 0.0847 0.0817 0.0800 0.0789 0.0783 0.0789 0.0801 0.0813 

[TRAIN] Epoch[5](13/1500); Loss: 0.065238; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1596 0.0828 0.0727 0.0968 0.0804 0.0575 0.0449 0.0574 0.0511 0.0483 0.0471 0.0475 0.0481 0.0485 0.0495 0.0516 

[TRAIN] Epoch[5](14/1500); Loss: 0.044292; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0506 0.0580 0.0474 0.0422 0.0400 0.0379 0.0395 0.0394 0.0401 0.0410 0.0416 0.0432 0.0448 0.0457 0.0476 0.0496 

[TRAIN] Epoch[5](15/1500); Loss: 0.106241; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2068 0.1525 0.1396 0.1367 0.1258 0.1123 0.1025 0.0936 0.0858 0.0804 0.0777 0.0765 0.0759 0.0765 0.0775 0.0797 

[TRAIN] Epoch[5](16/1500); Loss: 0.136335; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1897 0.1579 0.1488 0.1521 0.1458 0.1380 0.1304 0.1260 0.1243 0.1237 0.1237 0.1233 0.1234 0.1239 0.1249 0.1256 

[TRAIN] Epoch[5](17/1500); Loss: 0.128183; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1591 0.1377 0.1328 0.1331 0.1300 0.1270 0.1270 0.1245 0.1227 0.1223 0.1224 0.1220 0.1222 0.1227 0.1227 0.1229 

[TRAIN] Epoch[5](18/1500); Loss: 0.077768; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1699 0.1140 0.1067 0.1189 0.1068 0.0906 0.0681 0.0529 0.0568 0.0542 0.0513 0.0497 0.0501 0.0510 0.0514 0.0519 

[TRAIN] Epoch[5](19/1500); Loss: 0.184820; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.3472 0.2794 0.2664 0.2620 0.2444 0.2198 0.2007 0.1807 0.1591 0.1395 0.1243 0.1135 0.1073 0.1055 0.1043 0.1031 

[TRAIN] Epoch[5](20/1500); Loss: 0.102646; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1784 0.1329 0.1218 0.1189 0.1109 0.1019 0.0963 0.0923 0.0892 0.0867 0.0852 0.0841 0.0833 0.0861 0.0867 0.0876 

[TRAIN] Epoch[5](21/1500); Loss: 0.117994; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1753 0.1284 0.1236 0.1279 0.1204 0.1129 0.1097 0.1070 0.1071 0.1067 0.1080 0.1101 0.1101 0.1114 0.1143 0.1149 

[TRAIN] Epoch[5](22/1500); Loss: 0.075078; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0956 0.0804 0.0796 0.0780 0.0752 0.0739 0.0727 0.0719 0.0721 0.0710 0.0716 0.0710 0.0713 0.0721 0.0718 0.0729 

[TRAIN] Epoch[5](23/1500); Loss: 0.093408; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1207 0.1049 0.1005 0.0993 0.0953 0.0919 0.0897 0.0882 0.0875 0.0868 0.0871 0.0876 0.0879 0.0882 0.0892 0.0898 

[TRAIN] Epoch[5](24/1500); Loss: 0.080292; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1296 0.0982 0.0937 0.0933 0.0878 0.0823 0.0775 0.0735 0.0699 0.0688 0.0685 0.0681 0.0678 0.0682 0.0684 0.0690 

[TRAIN] Epoch[5](25/1500); Loss: 0.202414; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.3960 0.2858 0.2745 0.2795 0.2607 0.2288 0.2045 0.1843 0.1631 0.1464 0.1383 0.1354 0.1357 0.1353 0.1338 0.1365 

[TRAIN] Epoch[5](26/1500); Loss: 0.082046; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1511 0.0985 0.0888 0.0884 0.0830 0.0772 0.0744 0.0731 0.0726 0.0715 0.0710 0.0714 0.0725 0.0717 0.0730 0.0744 

[TRAIN] Epoch[5](27/1500); Loss: 0.137732; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1818 0.1589 0.1507 0.1478 0.1438 0.1395 0.1359 0.1324 0.1280 0.1257 0.1258 0.1260 0.1261 0.1267 0.1269 0.1276 

[TRAIN] Epoch[5](28/1500); Loss: 0.173910; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2691 0.2100 0.2004 0.2014 0.1964 0.1847 0.1784 0.1716 0.1636 0.1571 0.1514 0.1460 0.1420 0.1388 0.1365 0.1350 

[TRAIN] Epoch[5](29/1500); Loss: 0.099028; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1201 0.1112 0.1047 0.0998 0.0973 0.0960 0.0944 0.0942 0.0940 0.0942 0.0943 0.0949 0.0961 0.0966 0.0973 0.0994 

[TRAIN] Epoch[5](30/1500); Loss: 0.133654; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1689 0.1496 0.1438 0.1404 0.1358 0.1314 0.1280 0.1270 0.1264 0.1256 0.1259 0.1269 0.1264 0.1266 0.1279 0.1277 

[TRAIN] Epoch[5](31/1500); Loss: 0.145759; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2362 0.1866 0.1776 0.1766 0.1696 0.1581 0.1503 0.1418 0.1327 0.1253 0.1189 0.1140 0.1112 0.1107 0.1109 0.1117 

[TRAIN] Epoch[5](32/1500); Loss: 0.126388; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1744 0.1380 0.1312 0.1378 0.1310 0.1237 0.1178 0.1138 0.1134 0.1145 0.1162 0.1183 0.1193 0.1221 0.1243 0.1264 

[TRAIN] Epoch[5](33/1500); Loss: 0.144263; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.3223 0.2175 0.2033 0.2034 0.1837 0.1531 0.1315 0.1137 0.0993 0.0931 0.0917 0.0936 0.0960 0.0987 0.1008 0.1064 

[TRAIN] Epoch[5](34/1500); Loss: 0.046518; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.0461 0.0580 0.0536 0.0433 0.0430 0.0434 0.0433 0.0429 0.0432 0.0450 0.0442 0.0454 0.0474 0.0467 0.0482 0.0507 

[TRAIN] Epoch[5](35/1500); Loss: 0.057266; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1287 0.0718 0.0645 0.0810 0.0697 0.0558 0.0489 0.0440 0.0428 0.0430 0.0426 0.0429 0.0436 0.0452 0.0452 0.0466 

[TRAIN] Epoch[5](36/1500); Loss: 0.091346; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2018 0.1282 0.1149 0.1144 0.1057 0.0911 0.0829 0.0760 0.0707 0.0680 0.0667 0.0658 0.0670 0.0690 0.0688 0.0706 

[TRAIN] Epoch[5](37/1500); Loss: 0.056045; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0537 0.0581 0.0567 0.0538 0.0531 0.0521 0.0551 0.0541 0.0531 0.0577 0.0548 0.0555 0.0603 0.0572 0.0580 0.0633 

[TRAIN] Epoch[5](38/1500); Loss: 0.145933; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2149 0.1768 0.1711 0.1688 0.1614 0.1532 0.1469 0.1402 0.1341 0.1295 0.1259 0.1236 0.1222 0.1219 0.1216 0.1229 

[TRAIN] Epoch[5](39/1500); Loss: 0.111959; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1775 0.1420 0.1345 0.1306 0.1219 0.1141 0.1075 0.1016 0.0982 0.0957 0.0945 0.0934 0.0926 0.0943 0.0956 0.0973 

[TRAIN] Epoch[5](40/1500); Loss: 0.114942; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1505 0.1363 0.1252 0.1156 0.1099 0.1072 0.1051 0.1028 0.1041 0.1052 0.1040 0.1076 0.1117 0.1140 0.1172 0.1224 

[TRAIN] Epoch[5](41/1500); Loss: 0.191087; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.4022 0.3050 0.2870 0.2855 0.2658 0.2317 0.2082 0.1831 0.1556 0.1322 0.1152 0.1039 0.0983 0.0987 0.0923 0.0927 

[TRAIN] Epoch[5](42/1500); Loss: 0.144122; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1785 0.1557 0.1520 0.1514 0.1477 0.1443 0.1410 0.1382 0.1370 0.1362 0.1359 0.1361 0.1367 0.1376 0.1386 0.1393 

[TRAIN] Epoch[5](43/1500); Loss: 0.091778; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1365 0.1093 0.1030 0.1013 0.0982 0.0940 0.0908 0.0886 0.0860 0.0840 0.0831 0.0810 0.0798 0.0785 0.0772 0.0769 

[TRAIN] Epoch[5](44/1500); Loss: 0.132371; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1811 0.1522 0.1458 0.1433 0.1393 0.1333 0.1282 0.1262 0.1242 0.1228 0.1217 0.1209 0.1203 0.1196 0.1195 0.1194 

[TRAIN] Epoch[5](45/1500); Loss: 0.086664; Backpropagation: 0.0924 sec; Batch: 0.4245 sec
0.1507 0.1096 0.0981 0.0980 0.0891 0.0801 0.0775 0.0751 0.0754 0.0753 0.0748 0.0753 0.0756 0.0765 0.0776 0.0779 

[TRAIN] Epoch[5](46/1500); Loss: 0.130245; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1829 0.1442 0.1380 0.1424 0.1360 0.1296 0.1250 0.1224 0.1229 0.1217 0.1201 0.1203 0.1199 0.1192 0.1194 0.1201 

[TRAIN] Epoch[5](47/1500); Loss: 0.109568; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1478 0.1223 0.1174 0.1168 0.1121 0.1083 0.1053 0.1034 0.1027 0.1020 0.1017 0.1017 0.1016 0.1027 0.1038 0.1033 

[TRAIN] Epoch[5](48/1500); Loss: 0.086374; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1468 0.1028 0.0967 0.0976 0.0925 0.0861 0.0822 0.0791 0.0763 0.0743 0.0740 0.0737 0.0739 0.0746 0.0751 0.0761 

[TRAIN] Epoch[5](49/1500); Loss: 0.156141; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2214 0.1835 0.1773 0.1752 0.1696 0.1621 0.1563 0.1508 0.1455 0.1416 0.1388 0.1367 0.1351 0.1346 0.1347 0.1350 

[TRAIN] Epoch[5](50/1500); Loss: 0.134263; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2132 0.1735 0.1594 0.1561 0.1498 0.1400 0.1325 0.1252 0.1191 0.1148 0.1118 0.1097 0.1094 0.1104 0.1112 0.1120 

[TRAIN] Epoch[5](51/1500); Loss: 0.084460; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1005 0.0856 0.0837 0.0830 0.0819 0.0818 0.0814 0.0813 0.0823 0.0821 0.0826 0.0837 0.0841 0.0850 0.0861 0.0862 

[TRAIN] Epoch[5](52/1500); Loss: 0.139139; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2451 0.1873 0.1735 0.1795 0.1693 0.1553 0.1422 0.1308 0.1227 0.1163 0.1108 0.1052 0.1010 0.0980 0.0954 0.0939 

[TRAIN] Epoch[5](53/1500); Loss: 0.070735; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.0964 0.0814 0.0770 0.0753 0.0741 0.0718 0.0699 0.0686 0.0670 0.0657 0.0650 0.0639 0.0638 0.0636 0.0636 0.0648 

[TRAIN] Epoch[5](54/1500); Loss: 0.100471; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1834 0.1351 0.1258 0.1306 0.1212 0.1091 0.0956 0.0855 0.0799 0.0781 0.0772 0.0768 0.0766 0.0769 0.0774 0.0782 

[TRAIN] Epoch[5](55/1500); Loss: 0.216093; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.2979 0.2534 0.2429 0.2450 0.2362 0.2252 0.2134 0.2019 0.1942 0.1910 0.1894 0.1893 0.1921 0.1942 0.1945 0.1970 

[TRAIN] Epoch[5](56/1500); Loss: 0.100334; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1848 0.1377 0.1250 0.1229 0.1140 0.1016 0.0942 0.0878 0.0821 0.0800 0.0780 0.0787 0.0795 0.0775 0.0798 0.0818 

[TRAIN] Epoch[5](57/1500); Loss: 0.158109; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1843 0.1677 0.1641 0.1629 0.1603 0.1576 0.1562 0.1547 0.1539 0.1528 0.1524 0.1525 0.1524 0.1523 0.1529 0.1526 

[TRAIN] Epoch[5](58/1500); Loss: 0.185876; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.3842 0.2918 0.2821 0.3084 0.2872 0.2528 0.1996 0.1410 0.0978 0.1075 0.0992 0.1049 0.1022 0.1006 0.1087 0.1059 

[TRAIN] Epoch[5](59/1500); Loss: 0.157755; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2433 0.1894 0.1771 0.1764 0.1704 0.1612 0.1553 0.1505 0.1459 0.1417 0.1388 0.1369 0.1346 0.1340 0.1350 0.1336 

[TRAIN] Epoch[5](60/1500); Loss: 0.100952; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2327 0.1596 0.1431 0.1404 0.1291 0.1095 0.0974 0.0851 0.0732 0.0658 0.0622 0.0624 0.0622 0.0638 0.0634 0.0653 

[TRAIN] Epoch[5](61/1500); Loss: 0.184548; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.3875 0.2938 0.2811 0.3035 0.2826 0.2486 0.1968 0.1401 0.0998 0.1075 0.0985 0.1045 0.1017 0.0998 0.1050 0.1020 

[TRAIN] Epoch[5](62/1500); Loss: 0.091740; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1201 0.1053 0.0977 0.0987 0.0926 0.0887 0.0869 0.0860 0.0856 0.0838 0.0842 0.0861 0.0857 0.0865 0.0905 0.0893 

[TRAIN] Epoch[5](63/1500); Loss: 0.160204; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.3441 0.2432 0.2234 0.2222 0.2019 0.1667 0.1421 0.1219 0.1083 0.1063 0.1091 0.1073 0.1096 0.1182 0.1179 0.1211 

[TRAIN] Epoch[5](64/1500); Loss: 0.069076; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1694 0.1059 0.0922 0.1014 0.0888 0.0697 0.0545 0.0535 0.0484 0.0466 0.0458 0.0453 0.0459 0.0456 0.0457 0.0464 

[TRAIN] Epoch[5](65/1500); Loss: 0.153846; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3047 0.2357 0.2149 0.2115 0.1971 0.1756 0.1577 0.1383 0.1211 0.1102 0.1042 0.0990 0.0979 0.0998 0.0963 0.0977 

[TRAIN] Epoch[5](66/1500); Loss: 0.124811; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2128 0.1742 0.1599 0.1547 0.1450 0.1338 0.1253 0.1161 0.1081 0.1015 0.0959 0.0928 0.0920 0.0937 0.0951 0.0961 

[TRAIN] Epoch[5](67/1500); Loss: 0.152340; Backpropagation: 0.0924 sec; Batch: 0.4249 sec
0.3155 0.2363 0.2244 0.2381 0.2216 0.1974 0.1659 0.1317 0.1017 0.0877 0.0901 0.0847 0.0860 0.0856 0.0852 0.0855 

[TRAIN] Epoch[5](68/1500); Loss: 0.125386; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1851 0.1418 0.1332 0.1395 0.1326 0.1241 0.1177 0.1157 0.1170 0.1158 0.1144 0.1140 0.1136 0.1136 0.1138 0.1143 

[TRAIN] Epoch[5](69/1500); Loss: 0.119966; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1568 0.1352 0.1298 0.1279 0.1257 0.1212 0.1189 0.1167 0.1141 0.1127 0.1114 0.1100 0.1097 0.1090 0.1095 0.1109 

[TRAIN] Epoch[5](70/1500); Loss: 0.152572; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.2610 0.2061 0.1918 0.1973 0.1842 0.1673 0.1487 0.1326 0.1220 0.1198 0.1196 0.1179 0.1184 0.1169 0.1188 0.1188 

[TRAIN] Epoch[5](71/1500); Loss: 0.103923; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1755 0.1285 0.1216 0.1272 0.1198 0.1091 0.0996 0.0940 0.0901 0.0893 0.0870 0.0851 0.0845 0.0836 0.0835 0.0843 

[TRAIN] Epoch[5](72/1500); Loss: 0.057082; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1485 0.0766 0.0611 0.0591 0.0523 0.0459 0.0428 0.0438 0.0462 0.0446 0.0470 0.0476 0.0468 0.0502 0.0505 0.0503 

[TRAIN] Epoch[5](73/1500); Loss: 0.093983; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1355 0.1104 0.1026 0.1015 0.0986 0.0945 0.0914 0.0884 0.0866 0.0855 0.0847 0.0840 0.0845 0.0849 0.0850 0.0857 

[TRAIN] Epoch[5](74/1500); Loss: 0.110869; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.2426 0.1546 0.1412 0.1617 0.1457 0.1211 0.0965 0.0877 0.0831 0.0801 0.0787 0.0770 0.0758 0.0760 0.0761 0.0761 

[TRAIN] Epoch[5](75/1500); Loss: 0.092247; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1663 0.1143 0.1043 0.1107 0.1031 0.0929 0.0868 0.0830 0.0807 0.0783 0.0768 0.0761 0.0752 0.0752 0.0760 0.0761 

[TRAIN] Epoch[5](76/1500); Loss: 0.149956; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2691 0.2104 0.1990 0.2037 0.1891 0.1700 0.1519 0.1373 0.1252 0.1174 0.1101 0.1051 0.1027 0.1021 0.1018 0.1044 

[TRAIN] Epoch[5](77/1500); Loss: 0.178202; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2572 0.2086 0.2043 0.2059 0.1954 0.1838 0.1759 0.1698 0.1614 0.1564 0.1554 0.1556 0.1560 0.1553 0.1552 0.1550 

[TRAIN] Epoch[5](78/1500); Loss: 0.071342; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1019 0.0794 0.0764 0.0750 0.0726 0.0703 0.0683 0.0664 0.0656 0.0658 0.0655 0.0658 0.0659 0.0669 0.0675 0.0681 

[TRAIN] Epoch[5](79/1500); Loss: 0.161735; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2358 0.2043 0.1930 0.1918 0.1861 0.1773 0.1683 0.1579 0.1478 0.1399 0.1355 0.1328 0.1308 0.1292 0.1282 0.1291 

[TRAIN] Epoch[5](80/1500); Loss: 0.133905; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1935 0.1591 0.1515 0.1499 0.1449 0.1381 0.1332 0.1287 0.1236 0.1205 0.1179 0.1163 0.1169 0.1155 0.1157 0.1170 

[TRAIN] Epoch[5](81/1500); Loss: 0.176920; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.4346 0.3159 0.3023 0.3356 0.3090 0.2646 0.1954 0.1180 0.0641 0.0795 0.0665 0.0714 0.0687 0.0673 0.0695 0.0683 

[TRAIN] Epoch[5](82/1500); Loss: 0.143587; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1670 0.1526 0.1494 0.1477 0.1458 0.1433 0.1417 0.1407 0.1393 0.1390 0.1391 0.1381 0.1384 0.1387 0.1383 0.1386 

[TRAIN] Epoch[5](83/1500); Loss: 0.082113; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0924 0.0869 0.0876 0.0827 0.0811 0.0787 0.0781 0.0778 0.0782 0.0787 0.0793 0.0801 0.0816 0.0823 0.0834 0.0851 

[TRAIN] Epoch[5](84/1500); Loss: 0.169030; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.2130 0.1903 0.1824 0.1787 0.1742 0.1701 0.1660 0.1625 0.1607 0.1592 0.1584 0.1573 0.1572 0.1579 0.1579 0.1586 

[TRAIN] Epoch[5](85/1500); Loss: 0.123370; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1899 0.1453 0.1383 0.1380 0.1318 0.1254 0.1214 0.1164 0.1136 0.1112 0.1090 0.1072 0.1065 0.1067 0.1062 0.1070 

[TRAIN] Epoch[5](86/1500); Loss: 0.112494; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1711 0.1431 0.1303 0.1236 0.1181 0.1095 0.1048 0.1026 0.0999 0.0982 0.0982 0.0976 0.0979 0.1003 0.1009 0.1039 

[TRAIN] Epoch[5](87/1500); Loss: 0.131073; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2310 0.1735 0.1551 0.1497 0.1391 0.1257 0.1178 0.1121 0.1094 0.1105 0.1104 0.1114 0.1113 0.1122 0.1149 0.1132 

[TRAIN] Epoch[5](88/1500); Loss: 0.127650; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2071 0.1579 0.1485 0.1534 0.1452 0.1348 0.1281 0.1207 0.1159 0.1123 0.1096 0.1059 0.1032 0.1016 0.0995 0.0986 

[TRAIN] Epoch[5](89/1500); Loss: 0.113499; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1560 0.1312 0.1228 0.1205 0.1174 0.1136 0.1109 0.1078 0.1057 0.1052 0.1044 0.1040 0.1041 0.1039 0.1038 0.1046 

[TRAIN] Epoch[5](90/1500); Loss: 0.125223; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1834 0.1508 0.1425 0.1421 0.1373 0.1298 0.1244 0.1196 0.1151 0.1113 0.1100 0.1076 0.1058 0.1083 0.1070 0.1086 

[TRAIN] Epoch[5](91/1500); Loss: 0.104889; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.2106 0.1360 0.1244 0.1310 0.1204 0.1047 0.0909 0.0855 0.0818 0.0824 0.0819 0.0820 0.0845 0.0863 0.0865 0.0893 

[TRAIN] Epoch[5](92/1500); Loss: 0.080269; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.1313 0.1000 0.0903 0.0865 0.0811 0.0780 0.0748 0.0729 0.0710 0.0698 0.0700 0.0699 0.0699 0.0719 0.0729 0.0741 

[TRAIN] Epoch[5](93/1500); Loss: 0.044102; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.0499 0.0486 0.0479 0.0442 0.0403 0.0399 0.0398 0.0397 0.0405 0.0414 0.0423 0.0436 0.0448 0.0461 0.0476 0.0492 

[TRAIN] Epoch[5](94/1500); Loss: 0.148990; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2170 0.1773 0.1645 0.1616 0.1568 0.1501 0.1451 0.1411 0.1372 0.1346 0.1338 0.1329 0.1330 0.1331 0.1328 0.1329 

[TRAIN] Epoch[5](95/1500); Loss: 0.152394; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1685 0.1592 0.1576 0.1558 0.1534 0.1513 0.1505 0.1500 0.1494 0.1492 0.1492 0.1488 0.1490 0.1488 0.1486 0.1489 

[TRAIN] Epoch[5](96/1500); Loss: 0.096580; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1350 0.1184 0.1111 0.1080 0.1019 0.0970 0.0938 0.0907 0.0880 0.0867 0.0860 0.0853 0.0855 0.0853 0.0859 0.0868 

[TRAIN] Epoch[5](97/1500); Loss: 0.126824; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2297 0.1753 0.1649 0.1709 0.1587 0.1411 0.1285 0.1169 0.1047 0.0962 0.0910 0.0872 0.0889 0.0913 0.0918 0.0920 

[TRAIN] Epoch[5](98/1500); Loss: 0.105847; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1261 0.1193 0.1140 0.1092 0.1063 0.1038 0.1034 0.1017 0.1010 0.1018 0.1005 0.1006 0.1008 0.1007 0.1015 0.1028 

[TRAIN] Epoch[5](99/1500); Loss: 0.125662; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1870 0.1481 0.1401 0.1452 0.1378 0.1284 0.1184 0.1130 0.1125 0.1111 0.1114 0.1109 0.1113 0.1113 0.1118 0.1122 

[TRAIN] Epoch[5](100/1500); Loss: 0.120585; Backpropagation: 0.0921 sec; Batch: 0.4260 sec
0.2031 0.1581 0.1458 0.1475 0.1393 0.1284 0.1174 0.1090 0.1039 0.1001 0.0988 0.0975 0.0959 0.0953 0.0947 0.0947 

[TRAIN] Epoch[5](101/1500); Loss: 0.122218; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1571 0.1374 0.1248 0.1237 0.1242 0.1183 0.1125 0.1090 0.1106 0.1118 0.1121 0.1168 0.1189 0.1218 0.1263 0.1301 

[TRAIN] Epoch[5](102/1500); Loss: 0.072823; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1105 0.0966 0.0839 0.0759 0.0722 0.0685 0.0669 0.0644 0.0642 0.0633 0.0632 0.0637 0.0654 0.0661 0.0680 0.0725 

[TRAIN] Epoch[5](103/1500); Loss: 0.108590; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.1233 0.1199 0.1162 0.1122 0.1088 0.1068 0.1059 0.1052 0.1049 0.1045 0.1048 0.1047 0.1045 0.1055 0.1053 0.1050 

[TRAIN] Epoch[5](104/1500); Loss: 0.117551; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2551 0.1701 0.1618 0.1894 0.1718 0.1445 0.1106 0.0873 0.0731 0.0741 0.0730 0.0734 0.0744 0.0737 0.0737 0.0748 

[TRAIN] Epoch[5](105/1500); Loss: 0.130948; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2422 0.1789 0.1621 0.1655 0.1525 0.1366 0.1224 0.1096 0.1039 0.1023 0.1035 0.1038 0.1010 0.1025 0.1048 0.1036 

[TRAIN] Epoch[5](106/1500); Loss: 0.151518; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1686 0.1590 0.1570 0.1547 0.1529 0.1512 0.1503 0.1489 0.1481 0.1472 0.1471 0.1473 0.1473 0.1480 0.1482 0.1485 

[TRAIN] Epoch[5](107/1500); Loss: 0.123410; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2627 0.2114 0.1843 0.1751 0.1538 0.1290 0.1079 0.0903 0.0809 0.0805 0.0793 0.0815 0.0813 0.0832 0.0854 0.0880 

[TRAIN] Epoch[5](108/1500); Loss: 0.116087; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1701 0.1361 0.1261 0.1240 0.1200 0.1152 0.1113 0.1103 0.1077 0.1069 0.1064 0.1043 0.1048 0.1041 0.1046 0.1053 

[TRAIN] Epoch[5](109/1500); Loss: 0.066470; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1099 0.0830 0.0722 0.0753 0.0701 0.0638 0.0618 0.0597 0.0582 0.0589 0.0577 0.0569 0.0583 0.0584 0.0588 0.0606 

[TRAIN] Epoch[5](110/1500); Loss: 0.116011; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1956 0.1450 0.1276 0.1257 0.1168 0.1105 0.1075 0.1033 0.1028 0.1024 0.1020 0.1026 0.1034 0.1031 0.1032 0.1047 

[TRAIN] Epoch[5](111/1500); Loss: 0.069940; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1749 0.1068 0.0911 0.1026 0.0898 0.0706 0.0567 0.0533 0.0495 0.0497 0.0469 0.0445 0.0453 0.0461 0.0458 0.0456 

[TRAIN] Epoch[5](112/1500); Loss: 0.173923; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2618 0.2118 0.1936 0.1958 0.1852 0.1767 0.1643 0.1568 0.1536 0.1536 0.1529 0.1536 0.1552 0.1548 0.1551 0.1577 

[TRAIN] Epoch[5](113/1500); Loss: 0.220114; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2741 0.2465 0.2392 0.2414 0.2334 0.2266 0.2191 0.2107 0.2061 0.2043 0.2026 0.2015 0.2028 0.2041 0.2048 0.2047 

[TRAIN] Epoch[5](114/1500); Loss: 0.166479; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1942 0.1725 0.1666 0.1651 0.1615 0.1619 0.1627 0.1616 0.1610 0.1617 0.1635 0.1632 0.1652 0.1655 0.1679 0.1697 

[TRAIN] Epoch[5](115/1500); Loss: 0.059465; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1279 0.0709 0.0623 0.0778 0.0663 0.0520 0.0562 0.0505 0.0491 0.0491 0.0471 0.0484 0.0487 0.0473 0.0490 0.0489 

[TRAIN] Epoch[5](116/1500); Loss: 0.138543; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2380 0.1889 0.1742 0.1790 0.1702 0.1605 0.1458 0.1301 0.1172 0.1059 0.1011 0.1026 0.1013 0.1007 0.1007 0.1006 

[TRAIN] Epoch[5](117/1500); Loss: 0.090345; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1777 0.1220 0.0923 0.0857 0.0830 0.0779 0.0780 0.0773 0.0776 0.0792 0.0778 0.0791 0.0822 0.0824 0.0845 0.0889 

[TRAIN] Epoch[5](118/1500); Loss: 0.120176; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1366 0.1295 0.1255 0.1228 0.1209 0.1193 0.1183 0.1177 0.1168 0.1166 0.1165 0.1166 0.1164 0.1164 0.1167 0.1163 

[TRAIN] Epoch[5](119/1500); Loss: 0.094072; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1567 0.1174 0.1048 0.1076 0.1005 0.0893 0.0808 0.0793 0.0785 0.0778 0.0790 0.0805 0.0829 0.0872 0.0896 0.0930 

[TRAIN] Epoch[5](120/1500); Loss: 0.122050; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1832 0.1411 0.1350 0.1268 0.1181 0.1134 0.1115 0.1098 0.1086 0.1091 0.1117 0.1124 0.1153 0.1170 0.1191 0.1207 

[TRAIN] Epoch[5](121/1500); Loss: 0.073978; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0995 0.0858 0.0770 0.0722 0.0679 0.0669 0.0653 0.0644 0.0667 0.0678 0.0682 0.0729 0.0725 0.0758 0.0785 0.0821 

[TRAIN] Epoch[5](122/1500); Loss: 0.073069; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1437 0.0864 0.0740 0.0801 0.0738 0.0666 0.0645 0.0617 0.0624 0.0626 0.0628 0.0639 0.0648 0.0658 0.0673 0.0688 

[TRAIN] Epoch[5](123/1500); Loss: 0.126886; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1780 0.1533 0.1390 0.1361 0.1339 0.1260 0.1207 0.1176 0.1158 0.1149 0.1148 0.1155 0.1146 0.1155 0.1170 0.1173 

[TRAIN] Epoch[5](124/1500); Loss: 0.113801; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1406 0.1276 0.1212 0.1162 0.1139 0.1113 0.1093 0.1084 0.1069 0.1071 0.1078 0.1074 0.1087 0.1101 0.1110 0.1133 

[TRAIN] Epoch[5](125/1500); Loss: 0.157111; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2264 0.1846 0.1719 0.1734 0.1667 0.1575 0.1519 0.1464 0.1428 0.1415 0.1409 0.1408 0.1411 0.1414 0.1427 0.1439 

[TRAIN] Epoch[5](126/1500); Loss: 0.085745; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1386 0.0777 0.0693 0.0774 0.0775 0.0751 0.0774 0.0788 0.0799 0.0828 0.0840 0.0856 0.0883 0.0910 0.0924 0.0963 

[TRAIN] Epoch[5](127/1500); Loss: 0.121345; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.1424 0.1226 0.1215 0.1244 0.1226 0.1212 0.1209 0.1198 0.1190 0.1185 0.1180 0.1177 0.1176 0.1181 0.1186 0.1186 

[TRAIN] Epoch[5](128/1500); Loss: 0.103761; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1356 0.1151 0.1128 0.1136 0.1088 0.1036 0.0973 0.0945 0.0949 0.0936 0.0959 0.0969 0.0970 0.0990 0.1003 0.1013 

[TRAIN] Epoch[5](129/1500); Loss: 0.149425; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1652 0.1472 0.1470 0.1536 0.1500 0.1483 0.1472 0.1459 0.1460 0.1463 0.1464 0.1473 0.1482 0.1494 0.1509 0.1520 

[TRAIN] Epoch[5](130/1500); Loss: 0.219481; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2182 0.2104 0.2136 0.2160 0.2129 0.2137 0.2138 0.2157 0.2163 0.2188 0.2206 0.2233 0.2243 0.2281 0.2311 0.2350 

[TRAIN] Epoch[5](131/1500); Loss: 0.192272; Backpropagation: 0.0930 sec; Batch: 0.4250 sec
0.2221 0.1803 0.1837 0.1991 0.1946 0.1879 0.1792 0.1755 0.1815 0.1821 0.1853 0.1905 0.1952 0.2007 0.2062 0.2126 

[TRAIN] Epoch[5](132/1500); Loss: 0.103617; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1003 0.0821 0.0832 0.0879 0.0883 0.0907 0.0927 0.0969 0.0998 0.1051 0.1087 0.1143 0.1186 0.1247 0.1291 0.1354 

[TRAIN] Epoch[5](133/1500); Loss: 0.114989; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.1289 0.0895 0.0777 0.0811 0.0771 0.0727 0.0789 0.0842 0.0893 0.1006 0.1159 0.1327 0.1498 0.1674 0.1869 0.2071 

[TRAIN] Epoch[5](134/1500); Loss: 0.203656; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1844 0.1592 0.1645 0.1751 0.1807 0.1839 0.1893 0.1955 0.2025 0.2100 0.2175 0.2249 0.2320 0.2388 0.2460 0.2542 

[TRAIN] Epoch[5](135/1500); Loss: 0.124997; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1353 0.1007 0.1009 0.1099 0.1054 0.1031 0.1069 0.1152 0.1176 0.1226 0.1294 0.1367 0.1432 0.1499 0.1573 0.1657 

[TRAIN] Epoch[5](136/1500); Loss: 0.560067; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.3671 0.3091 0.3379 0.3731 0.4146 0.4578 0.4941 0.5306 0.5691 0.6101 0.6506 0.6904 0.7295 0.7689 0.8089 0.8492 

[TRAIN] Epoch[5](137/1500); Loss: 0.412520; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2000 0.1760 0.2037 0.2381 0.2723 0.3047 0.3391 0.3771 0.4200 0.4599 0.4992 0.5382 0.5801 0.6220 0.6647 0.7052 

[TRAIN] Epoch[5](138/1500); Loss: 0.157069; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1474 0.1320 0.1338 0.1365 0.1341 0.1369 0.1420 0.1481 0.1531 0.1585 0.1647 0.1708 0.1774 0.1854 0.1927 0.1996 

[TRAIN] Epoch[5](139/1500); Loss: 0.097703; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.0753 0.0544 0.0555 0.0539 0.0554 0.0627 0.0720 0.0787 0.0880 0.1000 0.1124 0.1245 0.1376 0.1510 0.1644 0.1773 

[TRAIN] Epoch[5](140/1500); Loss: 0.209343; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1710 0.1420 0.1525 0.1597 0.1603 0.1670 0.1779 0.1901 0.2023 0.2157 0.2302 0.2451 0.2602 0.2759 0.2918 0.3078 

[TRAIN] Epoch[5](141/1500); Loss: 0.218601; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1982 0.1762 0.1813 0.1939 0.1950 0.1947 0.1957 0.2005 0.2116 0.2175 0.2262 0.2370 0.2498 0.2615 0.2730 0.2856 

[TRAIN] Epoch[5](142/1500); Loss: 0.186208; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1241 0.1057 0.1139 0.1234 0.1357 0.1459 0.1578 0.1717 0.1861 0.2006 0.2153 0.2299 0.2449 0.2596 0.2748 0.2901 

[TRAIN] Epoch[5](143/1500); Loss: 0.345350; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1809 0.1603 0.1790 0.2052 0.2293 0.2502 0.2749 0.3058 0.3426 0.3758 0.4093 0.4448 0.4845 0.5230 0.5613 0.5988 

[TRAIN] Epoch[5](144/1500); Loss: 0.316772; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1347 0.1231 0.1468 0.1806 0.2031 0.2238 0.2520 0.2878 0.3250 0.3575 0.3887 0.4208 0.4549 0.4900 0.5236 0.5561 

[TRAIN] Epoch[5](145/1500); Loss: 0.183477; Backpropagation: 0.0926 sec; Batch: 0.4245 sec
0.1524 0.1406 0.1491 0.1548 0.1565 0.1605 0.1672 0.1749 0.1817 0.1892 0.1975 0.2059 0.2135 0.2217 0.2310 0.2392 

[TRAIN] Epoch[5](146/1500); Loss: 0.101588; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2367 0.1488 0.1358 0.1566 0.1348 0.1042 0.0660 0.0562 0.0579 0.0596 0.0604 0.0670 0.0719 0.0807 0.0884 0.1004 

[TRAIN] Epoch[5](147/1500); Loss: 0.075278; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1549 0.0950 0.0772 0.0775 0.0683 0.0581 0.0623 0.0573 0.0581 0.0613 0.0630 0.0655 0.0696 0.0742 0.0785 0.0836 

[TRAIN] Epoch[5](148/1500); Loss: 0.147999; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2856 0.1976 0.1893 0.2175 0.1961 0.1676 0.1289 0.0940 0.0850 0.0904 0.0941 0.0999 0.1093 0.1221 0.1369 0.1537 

[TRAIN] Epoch[5](149/1500); Loss: 0.168718; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1723 0.1137 0.1174 0.1370 0.1379 0.1363 0.1448 0.1511 0.1595 0.1689 0.1798 0.1907 0.2028 0.2149 0.2292 0.2431 

[TRAIN] Epoch[5](150/1500); Loss: 0.222747; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.3233 0.2549 0.2442 0.2641 0.2513 0.2277 0.1985 0.1776 0.1795 0.1890 0.1883 0.1957 0.2032 0.2126 0.2216 0.2325 

[TRAIN] Epoch[5](151/1500); Loss: 0.249524; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.2120 0.1879 0.1971 0.2079 0.2124 0.2171 0.2247 0.2358 0.2456 0.2555 0.2669 0.2799 0.2928 0.3054 0.3186 0.3326 

[TRAIN] Epoch[5](152/1500); Loss: 0.208002; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1812 0.1589 0.1666 0.1705 0.1678 0.1711 0.1786 0.1898 0.2002 0.2113 0.2223 0.2357 0.2479 0.2617 0.2749 0.2894 

[TRAIN] Epoch[5](153/1500); Loss: 0.177297; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1622 0.1498 0.1515 0.1574 0.1585 0.1603 0.1646 0.1698 0.1748 0.1800 0.1853 0.1917 0.1980 0.2044 0.2108 0.2177 

[TRAIN] Epoch[5](154/1500); Loss: 0.243853; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.3526 0.2894 0.2777 0.2928 0.2771 0.2532 0.2231 0.1976 0.1937 0.2045 0.2033 0.2106 0.2169 0.2271 0.2352 0.2467 

[TRAIN] Epoch[5](155/1500); Loss: 0.196092; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1850 0.1393 0.1466 0.1719 0.1696 0.1643 0.1630 0.1684 0.1792 0.1897 0.2031 0.2181 0.2346 0.2507 0.2679 0.2859 

[TRAIN] Epoch[5](156/1500); Loss: 0.447350; Backpropagation: 0.0920 sec; Batch: 0.4254 sec
0.3144 0.2288 0.2588 0.2962 0.3302 0.3651 0.3924 0.4218 0.4547 0.4888 0.5205 0.5519 0.5844 0.6174 0.6500 0.6824 

[TRAIN] Epoch[5](157/1500); Loss: 0.130524; Backpropagation: 0.0920 sec; Batch: 0.4262 sec
0.1209 0.1041 0.1102 0.1170 0.1182 0.1203 0.1234 0.1268 0.1299 0.1340 0.1374 0.1412 0.1451 0.1494 0.1530 0.1575 

[TRAIN] Epoch[5](158/1500); Loss: 0.220754; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1820 0.1746 0.1801 0.1852 0.1889 0.1950 0.2023 0.2093 0.2176 0.2269 0.2365 0.2461 0.2562 0.2664 0.2768 0.2879 

[TRAIN] Epoch[5](159/1500); Loss: 0.209172; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2011 0.1685 0.1765 0.1892 0.1866 0.1857 0.1919 0.1979 0.2010 0.2072 0.2158 0.2254 0.2348 0.2448 0.2547 0.2654 

[TRAIN] Epoch[5](160/1500); Loss: 0.137475; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1397 0.1235 0.1248 0.1287 0.1306 0.1313 0.1323 0.1344 0.1362 0.1386 0.1407 0.1432 0.1454 0.1478 0.1499 0.1525 

[TRAIN] Epoch[5](161/1500); Loss: 0.128154; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1163 0.0953 0.1033 0.1093 0.1064 0.1090 0.1152 0.1210 0.1250 0.1302 0.1368 0.1434 0.1502 0.1567 0.1630 0.1693 

[TRAIN] Epoch[5](162/1500); Loss: 0.237600; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2357 0.1634 0.1675 0.1909 0.2023 0.2068 0.2153 0.2264 0.2367 0.2477 0.2573 0.2688 0.2792 0.2905 0.3007 0.3124 

[TRAIN] Epoch[5](163/1500); Loss: 0.207325; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1803 0.1578 0.1676 0.1765 0.1819 0.1859 0.1923 0.1995 0.2068 0.2144 0.2224 0.2304 0.2381 0.2462 0.2543 0.2629 

[TRAIN] Epoch[5](164/1500); Loss: 0.042834; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0455 0.0366 0.0396 0.0391 0.0357 0.0365 0.0374 0.0378 0.0393 0.0410 0.0430 0.0453 0.0479 0.0507 0.0536 0.0565 

[TRAIN] Epoch[5](165/1500); Loss: 0.110617; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0791 0.0644 0.0748 0.0853 0.0859 0.0912 0.0965 0.1036 0.1111 0.1178 0.1250 0.1321 0.1397 0.1469 0.1546 0.1619 

[TRAIN] Epoch[5](166/1500); Loss: 0.202684; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1829 0.1791 0.1870 0.1891 0.1881 0.1917 0.1956 0.1989 0.2020 0.2058 0.2099 0.2140 0.2180 0.2225 0.2267 0.2315 

[TRAIN] Epoch[5](167/1500); Loss: 0.231243; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2875 0.2352 0.2405 0.2614 0.2519 0.2391 0.2240 0.2128 0.2072 0.2043 0.2077 0.2136 0.2193 0.2256 0.2314 0.2383 

[TRAIN] Epoch[5](168/1500); Loss: 0.272108; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2570 0.2046 0.2123 0.2308 0.2384 0.2427 0.2517 0.2617 0.2698 0.2804 0.2903 0.3015 0.3115 0.3227 0.3333 0.3450 

[TRAIN] Epoch[5](169/1500); Loss: 0.212291; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2001 0.1789 0.1855 0.1931 0.1936 0.1973 0.2021 0.2073 0.2115 0.2166 0.2215 0.2271 0.2322 0.2378 0.2431 0.2490 

[TRAIN] Epoch[5](170/1500); Loss: 0.080776; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1049 0.0880 0.0838 0.0795 0.0767 0.0764 0.0739 0.0717 0.0721 0.0730 0.0743 0.0768 0.0799 0.0835 0.0867 0.0914 

[TRAIN] Epoch[5](171/1500); Loss: 0.177306; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1610 0.1012 0.1082 0.1291 0.1415 0.1461 0.1534 0.1649 0.1765 0.1881 0.1986 0.2105 0.2218 0.2338 0.2451 0.2571 

[TRAIN] Epoch[5](172/1500); Loss: 0.172278; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1458 0.1298 0.1436 0.1489 0.1499 0.1539 0.1599 0.1662 0.1719 0.1784 0.1845 0.1913 0.1978 0.2047 0.2114 0.2184 

[TRAIN] Epoch[5](173/1500); Loss: 0.181043; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1913 0.1659 0.1683 0.1757 0.1702 0.1682 0.1688 0.1727 0.1754 0.1793 0.1832 0.1874 0.1915 0.1952 0.1996 0.2041 

[TRAIN] Epoch[5](174/1500); Loss: 0.210543; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2172 0.1972 0.2012 0.2071 0.2050 0.2039 0.2036 0.2043 0.2056 0.2085 0.2116 0.2145 0.2176 0.2207 0.2238 0.2269 

[TRAIN] Epoch[5](175/1500); Loss: 0.096035; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0941 0.0856 0.0899 0.0895 0.0893 0.0907 0.0922 0.0933 0.0948 0.0965 0.0983 0.1003 0.1022 0.1044 0.1065 0.1090 

[TRAIN] Epoch[5](176/1500); Loss: 0.082018; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1452 0.1033 0.0890 0.0869 0.0790 0.0711 0.0699 0.0671 0.0672 0.0679 0.0693 0.0719 0.0756 0.0789 0.0825 0.0874 

[TRAIN] Epoch[5](177/1500); Loss: 0.154603; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1876 0.1477 0.1477 0.1617 0.1612 0.1543 0.1475 0.1437 0.1426 0.1426 0.1447 0.1493 0.1540 0.1582 0.1629 0.1678 

[TRAIN] Epoch[5](178/1500); Loss: 0.107407; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1131 0.0873 0.0928 0.0972 0.0982 0.0997 0.1026 0.1041 0.1064 0.1097 0.1116 0.1143 0.1165 0.1193 0.1214 0.1245 

[TRAIN] Epoch[5](179/1500); Loss: 0.104799; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0868 0.0808 0.0840 0.0938 0.0855 0.0884 0.0931 0.0978 0.1026 0.1073 0.1124 0.1178 0.1232 0.1288 0.1343 0.1402 

[TRAIN] Epoch[5](180/1500); Loss: 0.188204; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2215 0.1795 0.1802 0.1941 0.1917 0.1854 0.1801 0.1773 0.1787 0.1819 0.1839 0.1867 0.1887 0.1913 0.1937 0.1966 

[TRAIN] Epoch[5](181/1500); Loss: 0.186518; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1976 0.1875 0.1861 0.1858 0.1847 0.1839 0.1835 0.1832 0.1838 0.1842 0.1851 0.1859 0.1869 0.1877 0.1888 0.1897 

[TRAIN] Epoch[5](182/1500); Loss: 0.142350; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1627 0.1098 0.1128 0.1276 0.1254 0.1215 0.1273 0.1304 0.1332 0.1408 0.1474 0.1536 0.1602 0.1673 0.1749 0.1826 

[TRAIN] Epoch[5](183/1500); Loss: 0.079313; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1968 0.1147 0.1060 0.1269 0.1086 0.0850 0.0599 0.0454 0.0436 0.0471 0.0494 0.0510 0.0541 0.0570 0.0601 0.0634 

[TRAIN] Epoch[5](184/1500); Loss: 0.069692; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1791 0.0932 0.0840 0.1098 0.0886 0.0607 0.0403 0.0450 0.0434 0.0458 0.0461 0.0498 0.0528 0.0554 0.0588 0.0622 

[TRAIN] Epoch[5](185/1500); Loss: 0.165585; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1656 0.1376 0.1423 0.1515 0.1521 0.1541 0.1572 0.1618 0.1653 0.1693 0.1722 0.1765 0.1798 0.1842 0.1876 0.1922 

[TRAIN] Epoch[5](186/1500); Loss: 0.145532; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1514 0.1264 0.1279 0.1368 0.1351 0.1347 0.1375 0.1405 0.1431 0.1463 0.1492 0.1526 0.1557 0.1598 0.1636 0.1680 

[TRAIN] Epoch[5](187/1500); Loss: 0.150433; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1824 0.1513 0.1528 0.1588 0.1541 0.1499 0.1462 0.1437 0.1431 0.1429 0.1434 0.1449 0.1459 0.1476 0.1493 0.1507 

[TRAIN] Epoch[5](188/1500); Loss: 0.179771; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2044 0.1660 0.1660 0.1752 0.1737 0.1706 0.1695 0.1706 0.1727 0.1759 0.1794 0.1833 0.1868 0.1906 0.1940 0.1978 

[TRAIN] Epoch[5](189/1500); Loss: 0.174849; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1925 0.1683 0.1709 0.1769 0.1718 0.1693 0.1672 0.1669 0.1677 0.1702 0.1724 0.1753 0.1776 0.1808 0.1831 0.1866 

[TRAIN] Epoch[5](190/1500); Loss: 0.090258; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1339 0.0986 0.0941 0.0995 0.0933 0.0856 0.0798 0.0798 0.0803 0.0814 0.0820 0.0836 0.0850 0.0870 0.0890 0.0913 

[TRAIN] Epoch[5](191/1500); Loss: 0.113637; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1416 0.1133 0.1107 0.1145 0.1116 0.1084 0.1093 0.1079 0.1093 0.1097 0.1102 0.1118 0.1127 0.1140 0.1157 0.1175 

[TRAIN] Epoch[5](192/1500); Loss: 0.109076; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1295 0.1133 0.1095 0.1073 0.1043 0.1027 0.1019 0.1017 0.1020 0.1032 0.1050 0.1068 0.1097 0.1124 0.1163 0.1196 

[TRAIN] Epoch[5](193/1500); Loss: 0.096613; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0892 0.0778 0.0867 0.0918 0.0856 0.0881 0.0904 0.0927 0.0957 0.0977 0.1002 0.1030 0.1061 0.1097 0.1134 0.1176 

[TRAIN] Epoch[5](194/1500); Loss: 0.167457; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2325 0.1952 0.1894 0.1949 0.1888 0.1805 0.1697 0.1596 0.1523 0.1477 0.1438 0.1431 0.1439 0.1454 0.1457 0.1468 

[TRAIN] Epoch[5](195/1500); Loss: 0.095052; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1007 0.0933 0.0922 0.0916 0.0917 0.0916 0.0917 0.0923 0.0930 0.0938 0.0949 0.0961 0.0972 0.0989 0.1000 0.1019 

[TRAIN] Epoch[5](196/1500); Loss: 0.176242; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1907 0.1703 0.1731 0.1760 0.1739 0.1734 0.1722 0.1721 0.1733 0.1743 0.1753 0.1766 0.1776 0.1791 0.1802 0.1819 

[TRAIN] Epoch[5](197/1500); Loss: 0.096438; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1229 0.0768 0.0745 0.0851 0.0888 0.0871 0.0893 0.0912 0.0936 0.0962 0.0987 0.1013 0.1044 0.1074 0.1112 0.1143 

[TRAIN] Epoch[5](198/1500); Loss: 0.141737; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2135 0.1560 0.1372 0.1457 0.1482 0.1425 0.1399 0.1375 0.1346 0.1322 0.1310 0.1301 0.1293 0.1296 0.1298 0.1307 

[TRAIN] Epoch[5](199/1500); Loss: 0.110536; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1304 0.1152 0.1113 0.1071 0.1047 0.1039 0.1033 0.1035 0.1047 0.1057 0.1071 0.1094 0.1113 0.1142 0.1165 0.1201 

[TRAIN] Epoch[5](200/1500); Loss: 0.075119; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0951 0.0721 0.0677 0.0717 0.0702 0.0684 0.0687 0.0689 0.0697 0.0714 0.0733 0.0756 0.0781 0.0808 0.0836 0.0866 

[TRAIN] Epoch[5](201/1500); Loss: 0.108832; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1145 0.0953 0.0977 0.1057 0.0990 0.1003 0.1029 0.1051 0.1070 0.1088 0.1107 0.1134 0.1158 0.1187 0.1215 0.1250 

[TRAIN] Epoch[5](202/1500); Loss: 0.143313; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1858 0.1422 0.1377 0.1448 0.1411 0.1388 0.1396 0.1372 0.1379 0.1389 0.1388 0.1398 0.1405 0.1418 0.1432 0.1451 

[TRAIN] Epoch[5](203/1500); Loss: 0.084324; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2137 0.1302 0.1208 0.1455 0.1246 0.0960 0.0584 0.0424 0.0460 0.0496 0.0469 0.0487 0.0536 0.0539 0.0575 0.0612 

[TRAIN] Epoch[5](204/1500); Loss: 0.123659; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1252 0.1125 0.1115 0.1168 0.1175 0.1164 0.1182 0.1200 0.1222 0.1243 0.1261 0.1284 0.1307 0.1335 0.1361 0.1391 

[TRAIN] Epoch[5](205/1500); Loss: 0.179680; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2327 0.1954 0.1925 0.2002 0.1908 0.1807 0.1716 0.1636 0.1617 0.1644 0.1657 0.1673 0.1693 0.1710 0.1729 0.1749 

[TRAIN] Epoch[5](206/1500); Loss: 0.132016; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.2343 0.1666 0.1523 0.1675 0.1588 0.1431 0.1237 0.1090 0.1055 0.1087 0.1067 0.1050 0.1067 0.1074 0.1076 0.1094 

[TRAIN] Epoch[5](207/1500); Loss: 0.144225; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3024 0.2156 0.2078 0.2374 0.2160 0.1860 0.1464 0.1117 0.0906 0.0799 0.0798 0.0843 0.0843 0.0847 0.0898 0.0909 

[TRAIN] Epoch[5](208/1500); Loss: 0.124249; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1496 0.1277 0.1241 0.1266 0.1259 0.1239 0.1227 0.1214 0.1203 0.1201 0.1198 0.1198 0.1202 0.1210 0.1218 0.1231 

[TRAIN] Epoch[5](209/1500); Loss: 0.126720; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1447 0.1230 0.1201 0.1237 0.1243 0.1226 0.1221 0.1220 0.1225 0.1236 0.1249 0.1266 0.1286 0.1306 0.1329 0.1354 

[TRAIN] Epoch[5](210/1500); Loss: 0.135333; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1806 0.1421 0.1393 0.1507 0.1437 0.1389 0.1335 0.1289 0.1263 0.1241 0.1224 0.1222 0.1243 0.1272 0.1297 0.1314 

[TRAIN] Epoch[5](211/1500); Loss: 0.054638; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1495 0.0566 0.0495 0.0747 0.0577 0.0357 0.0460 0.0358 0.0341 0.0374 0.0397 0.0446 0.0482 0.0499 0.0536 0.0611 

[TRAIN] Epoch[5](212/1500); Loss: 0.199161; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2371 0.1602 0.1575 0.1808 0.1897 0.1855 0.1867 0.1929 0.1968 0.2017 0.2042 0.2094 0.2132 0.2188 0.2235 0.2288 

[TRAIN] Epoch[5](213/1500); Loss: 0.104488; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1293 0.1108 0.1081 0.1086 0.1039 0.1009 0.0986 0.0975 0.0979 0.0982 0.0990 0.1004 0.1018 0.1036 0.1056 0.1077 

[TRAIN] Epoch[5](214/1500); Loss: 0.223671; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2539 0.2315 0.2296 0.2344 0.2273 0.2223 0.2188 0.2157 0.2146 0.2143 0.2149 0.2160 0.2184 0.2198 0.2225 0.2247 

[TRAIN] Epoch[5](215/1500); Loss: 0.161464; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1945 0.1705 0.1708 0.1716 0.1664 0.1627 0.1569 0.1525 0.1523 0.1529 0.1531 0.1537 0.1545 0.1556 0.1570 0.1584 

[TRAIN] Epoch[5](216/1500); Loss: 0.112968; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1495 0.0950 0.0896 0.1025 0.1066 0.1037 0.1049 0.1070 0.1093 0.1116 0.1138 0.1163 0.1195 0.1224 0.1262 0.1296 

[TRAIN] Epoch[5](217/1500); Loss: 0.085736; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1283 0.0910 0.0820 0.0850 0.0830 0.0806 0.0793 0.0785 0.0780 0.0784 0.0792 0.0810 0.0830 0.0855 0.0880 0.0908 

[TRAIN] Epoch[5](218/1500); Loss: 0.166510; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1990 0.1700 0.1666 0.1699 0.1696 0.1674 0.1658 0.1644 0.1631 0.1621 0.1612 0.1610 0.1606 0.1607 0.1611 0.1619 

[TRAIN] Epoch[5](219/1500); Loss: 0.079208; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.0972 0.0833 0.0758 0.0733 0.0723 0.0722 0.0722 0.0727 0.0738 0.0753 0.0770 0.0794 0.0815 0.0845 0.0868 0.0901 

[TRAIN] Epoch[5](220/1500); Loss: 0.201710; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2577 0.1997 0.1870 0.2031 0.2092 0.2043 0.2021 0.2012 0.1998 0.1994 0.1966 0.1953 0.1936 0.1932 0.1924 0.1931 

[TRAIN] Epoch[5](221/1500); Loss: 0.130198; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1721 0.1272 0.1238 0.1318 0.1299 0.1274 0.1272 0.1252 0.1261 0.1257 0.1257 0.1266 0.1270 0.1278 0.1293 0.1304 

[TRAIN] Epoch[5](222/1500); Loss: 0.094133; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2467 0.1579 0.1427 0.1711 0.1493 0.1187 0.0761 0.0434 0.0419 0.0491 0.0469 0.0467 0.0508 0.0526 0.0547 0.0577 

[TRAIN] Epoch[5](223/1500); Loss: 0.082264; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1053 0.0897 0.0849 0.0815 0.0767 0.0749 0.0740 0.0736 0.0742 0.0753 0.0773 0.0792 0.0827 0.0850 0.0895 0.0922 

[TRAIN] Epoch[5](224/1500); Loss: 0.155502; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.2342 0.1736 0.1651 0.1814 0.1732 0.1623 0.1537 0.1481 0.1433 0.1406 0.1372 0.1359 0.1349 0.1344 0.1347 0.1355 

[TRAIN] Epoch[5](225/1500); Loss: 0.128478; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1584 0.1330 0.1317 0.1358 0.1325 0.1292 0.1256 0.1222 0.1213 0.1212 0.1219 0.1223 0.1232 0.1245 0.1256 0.1273 

[TRAIN] Epoch[5](226/1500); Loss: 0.123135; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1577 0.1174 0.1138 0.1222 0.1198 0.1154 0.1160 0.1150 0.1155 0.1169 0.1190 0.1213 0.1249 0.1280 0.1310 0.1362 

[TRAIN] Epoch[5](227/1500); Loss: 0.085331; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0987 0.0897 0.0897 0.0854 0.0822 0.0818 0.0814 0.0808 0.0807 0.0813 0.0821 0.0830 0.0846 0.0859 0.0883 0.0895 

[TRAIN] Epoch[5](228/1500); Loss: 0.122914; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1386 0.1065 0.1036 0.1132 0.1165 0.1142 0.1152 0.1184 0.1211 0.1240 0.1251 0.1278 0.1299 0.1339 0.1370 0.1418 

[TRAIN] Epoch[5](229/1500); Loss: 0.053365; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0546 0.0650 0.0558 0.0483 0.0484 0.0475 0.0474 0.0480 0.0491 0.0503 0.0519 0.0531 0.0556 0.0576 0.0593 0.0621 

[TRAIN] Epoch[5](230/1500); Loss: 0.165164; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1942 0.1680 0.1638 0.1686 0.1686 0.1667 0.1649 0.1633 0.1617 0.1609 0.1599 0.1596 0.1595 0.1601 0.1609 0.1620 

[TRAIN] Epoch[5](231/1500); Loss: 0.133960; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1464 0.1408 0.1411 0.1366 0.1349 0.1343 0.1325 0.1319 0.1303 0.1300 0.1297 0.1299 0.1300 0.1308 0.1313 0.1328 

[TRAIN] Epoch[5](232/1500); Loss: 0.103832; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1569 0.1143 0.1089 0.1148 0.1111 0.1045 0.0979 0.0930 0.0911 0.0916 0.0927 0.0938 0.0950 0.0969 0.0983 0.1006 

[TRAIN] Epoch[5](233/1500); Loss: 0.134158; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2299 0.1657 0.1573 0.1751 0.1614 0.1420 0.1203 0.1093 0.1083 0.1093 0.1083 0.1095 0.1112 0.1120 0.1126 0.1143 

[TRAIN] Epoch[5](234/1500); Loss: 0.107609; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1290 0.1091 0.1060 0.1107 0.1020 0.1023 0.1029 0.1019 0.1031 0.1033 0.1038 0.1053 0.1076 0.1089 0.1119 0.1139 

[TRAIN] Epoch[5](235/1500); Loss: 0.120425; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1591 0.1161 0.1120 0.1176 0.1172 0.1138 0.1126 0.1122 0.1128 0.1140 0.1155 0.1186 0.1212 0.1239 0.1283 0.1317 

[TRAIN] Epoch[5](236/1500); Loss: 0.153382; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1668 0.1604 0.1577 0.1554 0.1539 0.1525 0.1514 0.1503 0.1494 0.1491 0.1492 0.1495 0.1503 0.1514 0.1526 0.1542 

[TRAIN] Epoch[5](237/1500); Loss: 0.114020; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1138 0.1128 0.1105 0.1094 0.1082 0.1074 0.1086 0.1093 0.1110 0.1121 0.1147 0.1164 0.1186 0.1213 0.1234 0.1266 

[TRAIN] Epoch[5](238/1500); Loss: 0.177105; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2302 0.1997 0.1905 0.1910 0.1879 0.1821 0.1753 0.1686 0.1647 0.1631 0.1619 0.1616 0.1625 0.1636 0.1649 0.1661 

[TRAIN] Epoch[5](239/1500); Loss: 0.070385; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1013 0.0811 0.0701 0.0697 0.0701 0.0650 0.0632 0.0634 0.0633 0.0640 0.0648 0.0665 0.0675 0.0703 0.0717 0.0741 

[TRAIN] Epoch[5](240/1500); Loss: 0.108024; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1277 0.1141 0.1072 0.1063 0.1062 0.1046 0.1037 0.1038 0.1036 0.1042 0.1049 0.1062 0.1069 0.1084 0.1095 0.1113 

[TRAIN] Epoch[5](241/1500); Loss: 0.071897; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0691 0.0642 0.0729 0.0683 0.0611 0.0627 0.0641 0.0655 0.0678 0.0704 0.0735 0.0748 0.0796 0.0817 0.0853 0.0895 

[TRAIN] Epoch[5](242/1500); Loss: 0.150135; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.2271 0.1719 0.1613 0.1715 0.1660 0.1561 0.1457 0.1371 0.1344 0.1335 0.1325 0.1328 0.1324 0.1324 0.1332 0.1342 

[TRAIN] Epoch[5](243/1500); Loss: 0.126529; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1752 0.1380 0.1299 0.1331 0.1310 0.1266 0.1247 0.1212 0.1194 0.1182 0.1173 0.1172 0.1170 0.1179 0.1183 0.1195 

[TRAIN] Epoch[5](244/1500); Loss: 0.156985; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1784 0.1593 0.1580 0.1603 0.1569 0.1555 0.1545 0.1539 0.1535 0.1533 0.1533 0.1536 0.1541 0.1547 0.1558 0.1568 

[TRAIN] Epoch[5](245/1500); Loss: 0.106219; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1554 0.1302 0.1214 0.1232 0.1170 0.1098 0.1014 0.0957 0.0931 0.0917 0.0910 0.0914 0.0927 0.0937 0.0954 0.0964 

[TRAIN] Epoch[5](246/1500); Loss: 0.157732; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1853 0.1656 0.1614 0.1634 0.1601 0.1564 0.1536 0.1520 0.1508 0.1511 0.1513 0.1522 0.1531 0.1543 0.1556 0.1574 

[TRAIN] Epoch[5](247/1500); Loss: 0.156154; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1934 0.1709 0.1659 0.1680 0.1639 0.1583 0.1526 0.1493 0.1479 0.1466 0.1460 0.1455 0.1460 0.1468 0.1480 0.1493 

[TRAIN] Epoch[5](248/1500); Loss: 0.125801; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2350 0.1525 0.1235 0.1361 0.1409 0.1332 0.1264 0.1192 0.1126 0.1080 0.1044 0.1030 0.1023 0.1034 0.1047 0.1076 

[TRAIN] Epoch[5](249/1500); Loss: 0.125572; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1521 0.1309 0.1289 0.1294 0.1263 0.1236 0.1220 0.1205 0.1202 0.1202 0.1202 0.1209 0.1218 0.1227 0.1240 0.1255 

[TRAIN] Epoch[5](250/1500); Loss: 0.113605; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1840 0.1284 0.1195 0.1319 0.1228 0.1104 0.1013 0.1000 0.1028 0.1000 0.0993 0.1014 0.1017 0.1032 0.1051 0.1059 

[TRAIN] Epoch[5](251/1500); Loss: 0.128474; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1532 0.1356 0.1336 0.1349 0.1295 0.1273 0.1256 0.1229 0.1221 0.1214 0.1213 0.1225 0.1236 0.1255 0.1268 0.1298 

[TRAIN] Epoch[5](252/1500); Loss: 0.063379; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1227 0.0734 0.0651 0.0747 0.0668 0.0579 0.0541 0.0529 0.0530 0.0533 0.0536 0.0544 0.0557 0.0573 0.0583 0.0607 

[TRAIN] Epoch[5](253/1500); Loss: 0.140585; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1674 0.1471 0.1371 0.1364 0.1350 0.1332 0.1319 0.1322 0.1328 0.1348 0.1366 0.1390 0.1419 0.1449 0.1481 0.1507 

[TRAIN] Epoch[5](254/1500); Loss: 0.152326; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1734 0.1659 0.1632 0.1586 0.1547 0.1529 0.1502 0.1477 0.1464 0.1455 0.1453 0.1451 0.1458 0.1465 0.1475 0.1485 

[TRAIN] Epoch[5](255/1500); Loss: 0.090445; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1304 0.1004 0.0900 0.0924 0.0900 0.0865 0.0851 0.0834 0.0830 0.0833 0.0835 0.0848 0.0862 0.0873 0.0896 0.0912 

[TRAIN] Epoch[5](256/1500); Loss: 0.146290; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2178 0.1770 0.1602 0.1621 0.1590 0.1511 0.1434 0.1366 0.1322 0.1298 0.1282 0.1281 0.1278 0.1283 0.1291 0.1300 

[TRAIN] Epoch[5](257/1500); Loss: 0.132141; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1900 0.1546 0.1466 0.1492 0.1416 0.1320 0.1236 0.1202 0.1194 0.1188 0.1181 0.1184 0.1190 0.1199 0.1207 0.1221 

[TRAIN] Epoch[5](258/1500); Loss: 0.118240; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2056 0.1334 0.1300 0.1544 0.1405 0.1230 0.1053 0.0971 0.0969 0.0963 0.0959 0.0984 0.0999 0.1030 0.1038 0.1082 

[TRAIN] Epoch[5](259/1500); Loss: 0.102664; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1286 0.0989 0.0904 0.0930 0.0951 0.0926 0.0926 0.0943 0.0973 0.0985 0.1010 0.1052 0.1065 0.1128 0.1147 0.1211 

[TRAIN] Epoch[5](260/1500); Loss: 0.130205; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.2057 0.1548 0.1497 0.1638 0.1520 0.1376 0.1202 0.1103 0.1090 0.1110 0.1097 0.1092 0.1110 0.1117 0.1128 0.1149 

[TRAIN] Epoch[5](261/1500); Loss: 0.063868; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0857 0.0735 0.0650 0.0619 0.0599 0.0581 0.0578 0.0578 0.0578 0.0590 0.0593 0.0619 0.0625 0.0654 0.0665 0.0699 

[TRAIN] Epoch[5](262/1500); Loss: 0.080251; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0958 0.0900 0.0845 0.0795 0.0771 0.0764 0.0757 0.0754 0.0754 0.0759 0.0768 0.0771 0.0795 0.0795 0.0824 0.0831 

[TRAIN] Epoch[5](263/1500); Loss: 0.071624; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1392 0.0911 0.0775 0.0788 0.0705 0.0623 0.0607 0.0589 0.0578 0.0584 0.0606 0.0604 0.0639 0.0661 0.0678 0.0719 

[TRAIN] Epoch[5](264/1500); Loss: 0.113024; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1452 0.1166 0.1129 0.1169 0.1129 0.1097 0.1087 0.1074 0.1079 0.1080 0.1083 0.1089 0.1095 0.1106 0.1117 0.1130 

[TRAIN] Epoch[5](265/1500); Loss: 0.102635; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1141 0.1085 0.1072 0.1017 0.0999 0.0994 0.0983 0.0983 0.0983 0.0991 0.0996 0.1010 0.1019 0.1035 0.1046 0.1068 

[TRAIN] Epoch[5](266/1500); Loss: 0.160887; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1753 0.1642 0.1586 0.1592 0.1566 0.1549 0.1557 0.1551 0.1553 0.1557 0.1577 0.1595 0.1621 0.1647 0.1678 0.1717 

[TRAIN] Epoch[5](267/1500); Loss: 0.073351; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0763 0.0738 0.0696 0.0705 0.0667 0.0682 0.0682 0.0671 0.0707 0.0705 0.0740 0.0741 0.0772 0.0799 0.0831 0.0837 

[TRAIN] Epoch[5](268/1500); Loss: 0.154597; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2038 0.1703 0.1658 0.1743 0.1670 0.1588 0.1514 0.1440 0.1408 0.1402 0.1412 0.1411 0.1414 0.1430 0.1444 0.1459 

[TRAIN] Epoch[5](269/1500); Loss: 0.089571; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1222 0.1019 0.0956 0.0969 0.0901 0.0866 0.0836 0.0822 0.0817 0.0818 0.0826 0.0830 0.0846 0.0852 0.0875 0.0876 

[TRAIN] Epoch[5](270/1500); Loss: 0.170160; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2169 0.1857 0.1852 0.1920 0.1868 0.1804 0.1739 0.1673 0.1618 0.1577 0.1542 0.1526 0.1521 0.1516 0.1519 0.1526 

[TRAIN] Epoch[5](271/1500); Loss: 0.118779; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1446 0.1581 0.1448 0.1349 0.1332 0.1281 0.1177 0.1126 0.1059 0.1017 0.1015 0.1022 0.1025 0.1029 0.1040 0.1056 

[TRAIN] Epoch[5](272/1500); Loss: 0.092836; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1266 0.1023 0.0944 0.1006 0.0953 0.0899 0.0885 0.0870 0.0868 0.0866 0.0867 0.0872 0.0877 0.0876 0.0893 0.0887 

[TRAIN] Epoch[5](273/1500); Loss: 0.112654; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1344 0.1236 0.1169 0.1129 0.1088 0.1078 0.1064 0.1056 0.1058 0.1066 0.1074 0.1093 0.1110 0.1131 0.1155 0.1176 

[TRAIN] Epoch[5](274/1500); Loss: 0.193927; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.3413 0.2495 0.2426 0.2751 0.2530 0.2221 0.1862 0.1590 0.1421 0.1355 0.1361 0.1441 0.1494 0.1506 0.1554 0.1610 

[TRAIN] Epoch[5](275/1500); Loss: 0.095590; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1580 0.1149 0.1001 0.1009 0.0989 0.0949 0.0922 0.0889 0.0865 0.0847 0.0833 0.0830 0.0843 0.0848 0.0864 0.0877 

[TRAIN] Epoch[5](276/1500); Loss: 0.076861; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0991 0.0830 0.0766 0.0737 0.0725 0.0709 0.0698 0.0704 0.0700 0.0720 0.0726 0.0757 0.0765 0.0801 0.0815 0.0856 

[TRAIN] Epoch[5](277/1500); Loss: 0.190210; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2785 0.2359 0.2271 0.2356 0.2262 0.2136 0.1983 0.1837 0.1723 0.1634 0.1556 0.1508 0.1500 0.1503 0.1509 0.1512 

[TRAIN] Epoch[5](278/1500); Loss: 0.168620; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2844 0.2158 0.2173 0.2410 0.2281 0.2080 0.1840 0.1596 0.1407 0.1257 0.1167 0.1142 0.1150 0.1152 0.1159 0.1161 

[TRAIN] Epoch[5](279/1500); Loss: 0.146303; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2122 0.1710 0.1650 0.1752 0.1662 0.1555 0.1420 0.1305 0.1245 0.1253 0.1269 0.1261 0.1276 0.1293 0.1307 0.1328 

[TRAIN] Epoch[5](280/1500); Loss: 0.090626; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1176 0.0989 0.0966 0.0995 0.0936 0.0910 0.0878 0.0855 0.0828 0.0825 0.0827 0.0833 0.0844 0.0861 0.0877 0.0899 

[TRAIN] Epoch[5](281/1500); Loss: 0.142435; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2094 0.1559 0.1455 0.1528 0.1512 0.1444 0.1385 0.1339 0.1306 0.1304 0.1292 0.1304 0.1302 0.1318 0.1315 0.1331 

[TRAIN] Epoch[5](282/1500); Loss: 0.160283; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2027 0.1695 0.1652 0.1687 0.1672 0.1617 0.1570 0.1530 0.1504 0.1488 0.1492 0.1499 0.1522 0.1536 0.1567 0.1586 

[TRAIN] Epoch[5](283/1500); Loss: 0.177792; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2204 0.1979 0.1931 0.1958 0.1916 0.1852 0.1778 0.1720 0.1678 0.1649 0.1638 0.1628 0.1626 0.1628 0.1627 0.1635 

[TRAIN] Epoch[5](284/1500); Loss: 0.111161; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1615 0.1311 0.1236 0.1296 0.1235 0.1151 0.1089 0.1016 0.0971 0.0965 0.0966 0.0969 0.0976 0.0986 0.0998 0.1007 

[TRAIN] Epoch[5](285/1500); Loss: 0.148261; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1982 0.1690 0.1622 0.1650 0.1601 0.1539 0.1485 0.1411 0.1379 0.1352 0.1336 0.1327 0.1322 0.1330 0.1342 0.1353 

[TRAIN] Epoch[5](286/1500); Loss: 0.089483; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1563 0.1063 0.0968 0.1038 0.0994 0.0920 0.0847 0.0782 0.0742 0.0742 0.0742 0.0762 0.0763 0.0787 0.0788 0.0817 

[TRAIN] Epoch[5](287/1500); Loss: 0.077796; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1534 0.1076 0.0931 0.1001 0.0902 0.0789 0.0654 0.0598 0.0607 0.0608 0.0607 0.0613 0.0620 0.0623 0.0632 0.0651 

[TRAIN] Epoch[5](288/1500); Loss: 0.122107; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1480 0.1280 0.1203 0.1195 0.1171 0.1142 0.1127 0.1125 0.1129 0.1147 0.1171 0.1200 0.1234 0.1275 0.1308 0.1351 

[TRAIN] Epoch[5](289/1500); Loss: 0.053723; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1144 0.0638 0.0522 0.0562 0.0495 0.0463 0.0435 0.0423 0.0427 0.0431 0.0443 0.0463 0.0492 0.0510 0.0557 0.0590 

[TRAIN] Epoch[5](290/1500); Loss: 0.095097; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1262 0.1012 0.0957 0.1040 0.0990 0.0921 0.0902 0.0878 0.0864 0.0878 0.0886 0.0895 0.0909 0.0920 0.0942 0.0960 

[TRAIN] Epoch[5](291/1500); Loss: 0.156100; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1646 0.1596 0.1577 0.1615 0.1569 0.1549 0.1539 0.1528 0.1523 0.1527 0.1531 0.1531 0.1546 0.1556 0.1563 0.1580 

[TRAIN] Epoch[5](292/1500); Loss: 0.148813; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1639 0.1539 0.1481 0.1448 0.1436 0.1428 0.1426 0.1432 0.1441 0.1454 0.1466 0.1484 0.1502 0.1525 0.1544 0.1567 

[TRAIN] Epoch[5](293/1500); Loss: 0.079676; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1233 0.0942 0.0876 0.0889 0.0874 0.0816 0.0755 0.0718 0.0702 0.0687 0.0675 0.0699 0.0697 0.0720 0.0728 0.0736 

[TRAIN] Epoch[5](294/1500); Loss: 0.092461; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1485 0.0990 0.0879 0.0947 0.0927 0.0861 0.0839 0.0824 0.0828 0.0832 0.0847 0.0854 0.0884 0.0901 0.0936 0.0960 

[TRAIN] Epoch[5](295/1500); Loss: 0.133615; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1796 0.1512 0.1461 0.1519 0.1448 0.1371 0.1291 0.1251 0.1222 0.1203 0.1197 0.1194 0.1207 0.1228 0.1233 0.1248 

[TRAIN] Epoch[5](296/1500); Loss: 0.156903; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1856 0.1677 0.1628 0.1624 0.1583 0.1559 0.1540 0.1519 0.1509 0.1497 0.1495 0.1496 0.1509 0.1519 0.1539 0.1554 

[TRAIN] Epoch[5](297/1500); Loss: 0.129180; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1591 0.1425 0.1350 0.1335 0.1327 0.1297 0.1276 0.1251 0.1234 0.1225 0.1216 0.1218 0.1217 0.1226 0.1237 0.1244 

[TRAIN] Epoch[5](298/1500); Loss: 0.123108; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1503 0.1370 0.1243 0.1160 0.1118 0.1096 0.1086 0.1088 0.1114 0.1128 0.1178 0.1205 0.1278 0.1309 0.1391 0.1430 

[TRAIN] Epoch[5](299/1500); Loss: 0.081319; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0933 0.0881 0.0819 0.0788 0.0765 0.0766 0.0764 0.0770 0.0774 0.0784 0.0794 0.0807 0.0819 0.0833 0.0849 0.0866 

[TRAIN] Epoch[5](300/1500); Loss: 0.126984; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1591 0.1434 0.1366 0.1353 0.1305 0.1266 0.1230 0.1199 0.1190 0.1180 0.1179 0.1183 0.1196 0.1203 0.1215 0.1227 

[TRAIN] Epoch[5](301/1500); Loss: 0.142286; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2039 0.1589 0.1537 0.1676 0.1598 0.1477 0.1392 0.1318 0.1271 0.1219 0.1216 0.1202 0.1261 0.1282 0.1336 0.1353 

[TRAIN] Epoch[5](302/1500); Loss: 0.075559; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0932 0.0854 0.0782 0.0744 0.0720 0.0714 0.0708 0.0707 0.0708 0.0714 0.0719 0.0734 0.0738 0.0758 0.0769 0.0788 

[TRAIN] Epoch[5](303/1500); Loss: 0.072899; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.0956 0.0823 0.0740 0.0734 0.0696 0.0680 0.0672 0.0675 0.0679 0.0683 0.0686 0.0701 0.0708 0.0729 0.0743 0.0757 

[TRAIN] Epoch[5](304/1500); Loss: 0.111576; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1639 0.1247 0.1152 0.1194 0.1138 0.1066 0.1018 0.0995 0.0989 0.0996 0.1020 0.1027 0.1059 0.1078 0.1105 0.1130 

[TRAIN] Epoch[5](305/1500); Loss: 0.147575; Backpropagation: 0.0930 sec; Batch: 0.4255 sec
0.2420 0.1976 0.1975 0.2118 0.1968 0.1820 0.1611 0.1406 0.1235 0.1087 0.0979 0.0971 0.0992 0.1007 0.1000 0.1044 

[TRAIN] Epoch[5](306/1500); Loss: 0.166032; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2063 0.1809 0.1754 0.1751 0.1716 0.1678 0.1638 0.1596 0.1570 0.1555 0.1545 0.1546 0.1558 0.1574 0.1593 0.1619 

[TRAIN] Epoch[5](307/1500); Loss: 0.077127; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1339 0.0762 0.0671 0.0744 0.0736 0.0710 0.0704 0.0701 0.0687 0.0714 0.0706 0.0746 0.0733 0.0784 0.0779 0.0825 

[TRAIN] Epoch[5](308/1500); Loss: 0.048044; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0673 0.0574 0.0472 0.0427 0.0439 0.0420 0.0416 0.0429 0.0429 0.0437 0.0458 0.0463 0.0481 0.0508 0.0520 0.0541 

[TRAIN] Epoch[5](309/1500); Loss: 0.109267; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2145 0.1323 0.1048 0.1150 0.1187 0.1061 0.0957 0.0915 0.0898 0.0899 0.0922 0.0945 0.0967 0.0997 0.1009 0.1060 

[TRAIN] Epoch[5](310/1500); Loss: 0.097186; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1959 0.1246 0.1203 0.1406 0.1270 0.1087 0.0940 0.0811 0.0712 0.0688 0.0696 0.0693 0.0697 0.0707 0.0711 0.0724 

[TRAIN] Epoch[5](311/1500); Loss: 0.130298; Backpropagation: 0.0928 sec; Batch: 0.4241 sec
0.1496 0.1410 0.1385 0.1358 0.1321 0.1315 0.1294 0.1274 0.1262 0.1254 0.1248 0.1241 0.1238 0.1242 0.1248 0.1261 

[TRAIN] Epoch[5](312/1500); Loss: 0.096889; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2440 0.1526 0.1493 0.1831 0.1613 0.1322 0.0968 0.0656 0.0490 0.0427 0.0432 0.0438 0.0443 0.0459 0.0476 0.0487 

[TRAIN] Epoch[5](313/1500); Loss: 0.078535; Backpropagation: 0.0928 sec; Batch: 0.4244 sec
0.1163 0.0766 0.0725 0.0767 0.0735 0.0716 0.0728 0.0728 0.0722 0.0746 0.0745 0.0776 0.0779 0.0804 0.0821 0.0844 

[TRAIN] Epoch[5](314/1500); Loss: 0.088282; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1482 0.1028 0.0933 0.1024 0.0941 0.0854 0.0798 0.0772 0.0775 0.0769 0.0775 0.0777 0.0786 0.0795 0.0801 0.0815 

[TRAIN] Epoch[5](315/1500); Loss: 0.077139; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1387 0.0983 0.0856 0.0944 0.0859 0.0772 0.0695 0.0636 0.0644 0.0638 0.0634 0.0642 0.0648 0.0655 0.0669 0.0681 

[TRAIN] Epoch[5](316/1500); Loss: 0.090403; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1282 0.1089 0.0972 0.0984 0.0943 0.0892 0.0866 0.0837 0.0825 0.0818 0.0815 0.0815 0.0823 0.0825 0.0836 0.0844 

[TRAIN] Epoch[5](317/1500); Loss: 0.130935; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2322 0.1596 0.1397 0.1510 0.1488 0.1354 0.1241 0.1158 0.1098 0.1086 0.1075 0.1095 0.1098 0.1128 0.1128 0.1177 

[TRAIN] Epoch[5](318/1500); Loss: 0.103392; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1215 0.1150 0.1117 0.1044 0.1029 0.1023 0.1004 0.0998 0.0990 0.0988 0.0987 0.0987 0.0995 0.0996 0.1007 0.1011 

[TRAIN] Epoch[5](319/1500); Loss: 0.145544; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1819 0.1637 0.1548 0.1568 0.1526 0.1490 0.1450 0.1399 0.1361 0.1361 0.1363 0.1351 0.1351 0.1348 0.1359 0.1355 

[TRAIN] Epoch[5](320/1500); Loss: 0.118741; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1454 0.1225 0.1193 0.1231 0.1188 0.1161 0.1154 0.1148 0.1152 0.1146 0.1141 0.1149 0.1150 0.1160 0.1165 0.1181 

[TRAIN] Epoch[5](321/1500); Loss: 0.070920; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0825 0.0795 0.0746 0.0701 0.0686 0.0677 0.0670 0.0662 0.0670 0.0668 0.0682 0.0692 0.0698 0.0716 0.0726 0.0735 

[TRAIN] Epoch[5](322/1500); Loss: 0.069527; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1535 0.0960 0.0854 0.1025 0.0891 0.0721 0.0594 0.0521 0.0492 0.0485 0.0481 0.0494 0.0496 0.0520 0.0522 0.0534 

[TRAIN] Epoch[5](323/1500); Loss: 0.035240; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0384 0.0547 0.0373 0.0311 0.0300 0.0294 0.0293 0.0295 0.0303 0.0319 0.0326 0.0346 0.0359 0.0376 0.0397 0.0415 

[TRAIN] Epoch[5](324/1500); Loss: 0.089938; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1180 0.1041 0.0928 0.0896 0.0879 0.0863 0.0853 0.0845 0.0841 0.0844 0.0845 0.0862 0.0859 0.0877 0.0878 0.0901 

[TRAIN] Epoch[5](325/1500); Loss: 0.089380; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1267 0.1038 0.0959 0.0963 0.0911 0.0877 0.0852 0.0827 0.0817 0.0808 0.0810 0.0821 0.0820 0.0837 0.0834 0.0859 

[TRAIN] Epoch[5](326/1500); Loss: 0.151334; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1728 0.1563 0.1545 0.1591 0.1551 0.1515 0.1494 0.1483 0.1468 0.1459 0.1455 0.1461 0.1457 0.1476 0.1470 0.1495 

[TRAIN] Epoch[5](327/1500); Loss: 0.145195; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.1913 0.1648 0.1576 0.1596 0.1544 0.1481 0.1430 0.1388 0.1362 0.1344 0.1336 0.1327 0.1323 0.1319 0.1320 0.1324 

[TRAIN] Epoch[5](328/1500); Loss: 0.132753; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1717 0.1496 0.1419 0.1428 0.1373 0.1317 0.1278 0.1252 0.1241 0.1233 0.1238 0.1240 0.1243 0.1250 0.1255 0.1262 

[TRAIN] Epoch[5](329/1500); Loss: 0.134710; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1908 0.1530 0.1475 0.1586 0.1502 0.1397 0.1307 0.1240 0.1193 0.1179 0.1180 0.1188 0.1198 0.1209 0.1221 0.1241 

[TRAIN] Epoch[5](330/1500); Loss: 0.144727; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2334 0.1847 0.1727 0.1832 0.1698 0.1541 0.1381 0.1266 0.1210 0.1177 0.1174 0.1184 0.1183 0.1186 0.1202 0.1214 

[TRAIN] Epoch[5](331/1500); Loss: 0.073095; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1085 0.0957 0.0785 0.0701 0.0667 0.0661 0.0641 0.0647 0.0660 0.0665 0.0676 0.0681 0.0693 0.0709 0.0725 0.0743 

[TRAIN] Epoch[5](332/1500); Loss: 0.080706; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1366 0.0951 0.0878 0.0969 0.0890 0.0809 0.0750 0.0712 0.0695 0.0692 0.0694 0.0694 0.0693 0.0699 0.0705 0.0716 

[TRAIN] Epoch[5](333/1500); Loss: 0.124664; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1722 0.1450 0.1398 0.1441 0.1373 0.1311 0.1235 0.1155 0.1105 0.1094 0.1100 0.1099 0.1100 0.1113 0.1120 0.1131 

[TRAIN] Epoch[5](334/1500); Loss: 0.130132; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1583 0.1395 0.1343 0.1370 0.1326 0.1309 0.1293 0.1263 0.1255 0.1244 0.1239 0.1234 0.1233 0.1239 0.1242 0.1253 

[TRAIN] Epoch[5](335/1500); Loss: 0.139482; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1999 0.1597 0.1538 0.1624 0.1566 0.1441 0.1344 0.1258 0.1216 0.1222 0.1228 0.1227 0.1242 0.1253 0.1275 0.1288 

[TRAIN] Epoch[5](336/1500); Loss: 0.093039; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1289 0.1077 0.0995 0.1023 0.0959 0.0914 0.0894 0.0874 0.0868 0.0859 0.0855 0.0851 0.0853 0.0855 0.0857 0.0863 

[TRAIN] Epoch[5](337/1500); Loss: 0.153198; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1796 0.1630 0.1594 0.1615 0.1571 0.1553 0.1535 0.1508 0.1497 0.1480 0.1468 0.1465 0.1447 0.1452 0.1449 0.1452 

[TRAIN] Epoch[5](338/1500); Loss: 0.139649; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2224 0.1657 0.1509 0.1544 0.1510 0.1403 0.1332 0.1265 0.1221 0.1208 0.1211 0.1227 0.1232 0.1252 0.1263 0.1285 

[TRAIN] Epoch[5](339/1500); Loss: 0.087179; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1501 0.0574 0.0557 0.0711 0.0727 0.0637 0.0669 0.0704 0.0768 0.0821 0.0880 0.0937 0.1016 0.1074 0.1158 0.1217 

[TRAIN] Epoch[5](340/1500); Loss: 0.105209; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1303 0.1147 0.1094 0.1079 0.1055 0.1038 0.1026 0.1016 0.1007 0.1004 0.1000 0.1001 0.1007 0.1010 0.1019 0.1028 

[TRAIN] Epoch[5](341/1500); Loss: 0.145406; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1997 0.1656 0.1641 0.1662 0.1613 0.1550 0.1482 0.1406 0.1356 0.1315 0.1287 0.1265 0.1254 0.1255 0.1259 0.1267 

[TRAIN] Epoch[5](342/1500); Loss: 0.087712; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1087 0.0946 0.0905 0.0901 0.0871 0.0850 0.0840 0.0830 0.0824 0.0826 0.0827 0.0841 0.0848 0.0865 0.0879 0.0894 

[TRAIN] Epoch[5](343/1500); Loss: 0.072276; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1282 0.0883 0.0782 0.0893 0.0820 0.0716 0.0665 0.0650 0.0627 0.0612 0.0602 0.0596 0.0600 0.0599 0.0616 0.0621 

[TRAIN] Epoch[5](344/1500); Loss: 0.104725; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1441 0.1147 0.1074 0.1090 0.1061 0.1019 0.1014 0.0988 0.0986 0.0980 0.0979 0.0985 0.0984 0.0997 0.0997 0.1015 

[TRAIN] Epoch[5](345/1500); Loss: 0.091077; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1202 0.1040 0.0998 0.1008 0.0934 0.0899 0.0857 0.0823 0.0830 0.0830 0.0831 0.0839 0.0848 0.0864 0.0872 0.0897 

[TRAIN] Epoch[5](346/1500); Loss: 0.132089; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2818 0.1979 0.1948 0.2273 0.2074 0.1802 0.1442 0.1064 0.0774 0.0689 0.0734 0.0696 0.0686 0.0716 0.0716 0.0722 

[TRAIN] Epoch[5](347/1500); Loss: 0.203465; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2527 0.2309 0.2217 0.2219 0.2153 0.2079 0.1998 0.1957 0.1932 0.1911 0.1893 0.1883 0.1879 0.1869 0.1865 0.1864 

[TRAIN] Epoch[5](348/1500); Loss: 0.138374; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1724 0.1515 0.1476 0.1453 0.1401 0.1356 0.1331 0.1304 0.1289 0.1288 0.1290 0.1297 0.1327 0.1337 0.1370 0.1383 

[TRAIN] Epoch[5](349/1500); Loss: 0.105855; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1529 0.1117 0.1095 0.1182 0.1140 0.1077 0.1038 0.0998 0.0963 0.0955 0.0949 0.0955 0.0958 0.0977 0.0988 0.1017 

[TRAIN] Epoch[5](350/1500); Loss: 0.071828; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1010 0.0891 0.0765 0.0728 0.0726 0.0701 0.0679 0.0673 0.0657 0.0649 0.0656 0.0650 0.0660 0.0673 0.0681 0.0693 

[TRAIN] Epoch[5](351/1500); Loss: 0.158105; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2170 0.1759 0.1717 0.1793 0.1735 0.1646 0.1569 0.1513 0.1458 0.1433 0.1420 0.1407 0.1411 0.1417 0.1423 0.1425 

[TRAIN] Epoch[5](352/1500); Loss: 0.165973; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2191 0.1913 0.1847 0.1844 0.1782 0.1720 0.1651 0.1587 0.1542 0.1518 0.1507 0.1497 0.1485 0.1488 0.1491 0.1494 

[TRAIN] Epoch[5](353/1500); Loss: 0.104516; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1213 0.1116 0.1073 0.1066 0.1027 0.1021 0.1021 0.1013 0.1011 0.1007 0.1008 0.1015 0.1017 0.1029 0.1035 0.1050 

[TRAIN] Epoch[5](354/1500); Loss: 0.093232; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0990 0.0878 0.0860 0.0860 0.0861 0.0875 0.0882 0.0904 0.0909 0.0934 0.0949 0.0963 0.0986 0.1004 0.1021 0.1042 

[TRAIN] Epoch[5](355/1500); Loss: 0.103644; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.2114 0.1421 0.1311 0.1459 0.1350 0.1180 0.0979 0.0781 0.0719 0.0730 0.0735 0.0738 0.0747 0.0765 0.0767 0.0788 

[TRAIN] Epoch[5](356/1500); Loss: 0.157509; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2284 0.1831 0.1755 0.1865 0.1770 0.1643 0.1518 0.1446 0.1409 0.1382 0.1369 0.1375 0.1378 0.1386 0.1393 0.1396 

[TRAIN] Epoch[5](357/1500); Loss: 0.156547; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.2500 0.2028 0.2002 0.2165 0.2054 0.1898 0.1710 0.1511 0.1349 0.1193 0.1097 0.1101 0.1105 0.1099 0.1113 0.1124 

[TRAIN] Epoch[5](358/1500); Loss: 0.090964; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1550 0.0921 0.0862 0.0998 0.0977 0.0855 0.0829 0.0817 0.0804 0.0809 0.0820 0.0815 0.0852 0.0859 0.0887 0.0901 

[TRAIN] Epoch[5](359/1500); Loss: 0.190517; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.4035 0.2965 0.2944 0.3314 0.3054 0.2649 0.2139 0.1601 0.1149 0.0917 0.1043 0.0911 0.0937 0.0928 0.0927 0.0971 

[TRAIN] Epoch[5](360/1500); Loss: 0.110580; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1477 0.1111 0.1105 0.1140 0.1090 0.1073 0.1056 0.1043 0.1048 0.1047 0.1049 0.1060 0.1071 0.1093 0.1100 0.1129 

[TRAIN] Epoch[5](361/1500); Loss: 0.069277; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0707 0.0705 0.0705 0.0661 0.0636 0.0634 0.0633 0.0639 0.0648 0.0674 0.0676 0.0707 0.0722 0.0756 0.0769 0.0812 

[TRAIN] Epoch[5](362/1500); Loss: 0.200117; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2947 0.2476 0.2364 0.2472 0.2367 0.2185 0.1987 0.1794 0.1696 0.1695 0.1699 0.1676 0.1676 0.1664 0.1662 0.1657 

[TRAIN] Epoch[5](363/1500); Loss: 0.110716; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1678 0.0955 0.0955 0.1103 0.1090 0.1002 0.0999 0.1017 0.1014 0.1062 0.1055 0.1109 0.1101 0.1170 0.1165 0.1241 

[TRAIN] Epoch[5](364/1500); Loss: 0.073469; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1184 0.0744 0.0698 0.0728 0.0699 0.0666 0.0664 0.0672 0.0665 0.0671 0.0679 0.0698 0.0713 0.0736 0.0757 0.0782 

[TRAIN] Epoch[5](365/1500); Loss: 0.112428; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1822 0.1242 0.1191 0.1290 0.1268 0.1153 0.1103 0.1049 0.0995 0.0967 0.0956 0.0967 0.0978 0.0990 0.1002 0.1016 

[TRAIN] Epoch[5](366/1500); Loss: 0.151976; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.2051 0.1740 0.1663 0.1669 0.1604 0.1531 0.1480 0.1426 0.1402 0.1382 0.1374 0.1379 0.1387 0.1391 0.1415 0.1421 

[TRAIN] Epoch[5](367/1500); Loss: 0.121119; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1462 0.1296 0.1239 0.1229 0.1215 0.1188 0.1176 0.1172 0.1163 0.1166 0.1169 0.1168 0.1177 0.1179 0.1189 0.1193 

[TRAIN] Epoch[5](368/1500); Loss: 0.050523; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0909 0.0722 0.0605 0.0580 0.0547 0.0493 0.0447 0.0406 0.0395 0.0398 0.0409 0.0408 0.0429 0.0428 0.0455 0.0453 

[TRAIN] Epoch[5](369/1500); Loss: 0.104856; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1378 0.1188 0.1116 0.1101 0.1054 0.1028 0.1014 0.0994 0.0981 0.0976 0.0976 0.0981 0.0982 0.0993 0.0999 0.1018 

[TRAIN] Epoch[5](370/1500); Loss: 0.098520; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1604 0.1101 0.1048 0.1156 0.1072 0.0974 0.0893 0.0874 0.0889 0.0871 0.0864 0.0876 0.0873 0.0886 0.0886 0.0897 

[TRAIN] Epoch[5](371/1500); Loss: 0.092952; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1775 0.0983 0.0972 0.1143 0.1084 0.0915 0.0839 0.0782 0.0746 0.0733 0.0722 0.0763 0.0763 0.0846 0.0858 0.0951 

[TRAIN] Epoch[5](372/1500); Loss: 0.109808; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1651 0.1150 0.1120 0.1196 0.1169 0.1116 0.1090 0.1064 0.1043 0.1024 0.0993 0.0990 0.0978 0.0991 0.0988 0.1007 

[TRAIN] Epoch[5](373/1500); Loss: 0.092846; Backpropagation: 0.0919 sec; Batch: 0.4227 sec
0.1290 0.1106 0.0982 0.0970 0.0924 0.0894 0.0886 0.0872 0.0857 0.0849 0.0847 0.0857 0.0857 0.0879 0.0876 0.0909 

[TRAIN] Epoch[5](374/1500); Loss: 0.166258; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2110 0.1893 0.1823 0.1844 0.1799 0.1756 0.1691 0.1608 0.1559 0.1534 0.1524 0.1508 0.1496 0.1491 0.1482 0.1484 

[TRAIN] Epoch[5](375/1500); Loss: 0.124176; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.1458 0.1279 0.1251 0.1270 0.1266 0.1233 0.1216 0.1212 0.1203 0.1195 0.1194 0.1203 0.1206 0.1212 0.1230 0.1240 

[TRAIN] Epoch[5](376/1500); Loss: 0.112010; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1696 0.1294 0.1204 0.1247 0.1185 0.1097 0.1050 0.1017 0.1003 0.0990 0.0987 0.0995 0.1011 0.1026 0.1044 0.1076 

[TRAIN] Epoch[5](377/1500); Loss: 0.131648; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1688 0.1389 0.1365 0.1415 0.1409 0.1335 0.1300 0.1280 0.1254 0.1239 0.1233 0.1223 0.1231 0.1224 0.1240 0.1240 

[TRAIN] Epoch[5](378/1500); Loss: 0.089859; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1012 0.1017 0.0998 0.0953 0.0939 0.0929 0.0894 0.0870 0.0858 0.0852 0.0848 0.0843 0.0843 0.0840 0.0842 0.0841 

[TRAIN] Epoch[5](379/1500); Loss: 0.129469; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2058 0.1719 0.1653 0.1773 0.1708 0.1574 0.1407 0.1248 0.1121 0.0993 0.0901 0.0902 0.0911 0.0905 0.0909 0.0933 

[TRAIN] Epoch[5](380/1500); Loss: 0.121921; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1957 0.1340 0.1321 0.1493 0.1457 0.1291 0.1165 0.1086 0.1042 0.1027 0.1020 0.1028 0.1039 0.1063 0.1078 0.1101 

[TRAIN] Epoch[5](381/1500); Loss: 0.110475; Backpropagation: 0.0923 sec; Batch: 0.4234 sec
0.2236 0.1426 0.1356 0.1471 0.1447 0.1273 0.1140 0.1015 0.0899 0.0813 0.0761 0.0737 0.0742 0.0762 0.0797 0.0805 

[TRAIN] Epoch[5](382/1500); Loss: 0.104242; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1564 0.1189 0.1131 0.1192 0.1149 0.1076 0.1034 0.0985 0.0963 0.0940 0.0925 0.0915 0.0910 0.0901 0.0904 0.0901 

[TRAIN] Epoch[5](383/1500); Loss: 0.058567; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1691 0.0704 0.0609 0.0965 0.0749 0.0468 0.0362 0.0466 0.0375 0.0383 0.0389 0.0403 0.0422 0.0439 0.0463 0.0483 

[TRAIN] Epoch[5](384/1500); Loss: 0.139675; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1810 0.1503 0.1484 0.1542 0.1483 0.1409 0.1352 0.1318 0.1304 0.1299 0.1291 0.1300 0.1299 0.1305 0.1316 0.1332 

[TRAIN] Epoch[5](385/1500); Loss: 0.078201; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1147 0.0970 0.0855 0.0803 0.0777 0.0758 0.0742 0.0728 0.0719 0.0712 0.0707 0.0710 0.0707 0.0718 0.0725 0.0734 

[TRAIN] Epoch[5](386/1500); Loss: 0.140976; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2211 0.1646 0.1565 0.1653 0.1630 0.1503 0.1395 0.1311 0.1257 0.1226 0.1202 0.1200 0.1189 0.1197 0.1178 0.1192 

[TRAIN] Epoch[5](387/1500); Loss: 0.155778; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.2132 0.1759 0.1662 0.1715 0.1647 0.1556 0.1472 0.1445 0.1440 0.1434 0.1437 0.1436 0.1437 0.1443 0.1451 0.1456 

[TRAIN] Epoch[5](388/1500); Loss: 0.100603; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1087 0.1052 0.1037 0.1008 0.1000 0.0994 0.0984 0.0977 0.0975 0.0977 0.0978 0.0987 0.0990 0.1007 0.1016 0.1027 

[TRAIN] Epoch[5](389/1500); Loss: 0.168879; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1881 0.1777 0.1747 0.1735 0.1713 0.1691 0.1673 0.1657 0.1647 0.1640 0.1636 0.1636 0.1640 0.1642 0.1648 0.1657 

[TRAIN] Epoch[5](390/1500); Loss: 0.088456; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1082 0.0981 0.0932 0.0906 0.0861 0.0847 0.0840 0.0822 0.0825 0.0824 0.0835 0.0848 0.0863 0.0875 0.0896 0.0915 

[TRAIN] Epoch[5](391/1500); Loss: 0.153412; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2503 0.1965 0.1887 0.1962 0.1902 0.1749 0.1615 0.1481 0.1373 0.1274 0.1206 0.1163 0.1138 0.1117 0.1105 0.1105 

[TRAIN] Epoch[5](392/1500); Loss: 0.144258; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2554 0.1650 0.1627 0.1824 0.1861 0.1655 0.1526 0.1425 0.1330 0.1240 0.1168 0.1102 0.1056 0.1024 0.1020 0.1019 

[TRAIN] Epoch[5](393/1500); Loss: 0.098712; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1555 0.1223 0.1130 0.1158 0.1095 0.1023 0.0939 0.0873 0.0845 0.0830 0.0831 0.0844 0.0847 0.0857 0.0864 0.0880 

[TRAIN] Epoch[5](394/1500); Loss: 0.119327; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1979 0.1513 0.1441 0.1461 0.1430 0.1320 0.1230 0.1140 0.1054 0.0987 0.0937 0.0907 0.0896 0.0903 0.0930 0.0963 

[TRAIN] Epoch[5](395/1500); Loss: 0.070133; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.0892 0.0832 0.0758 0.0701 0.0692 0.0675 0.0659 0.0650 0.0649 0.0646 0.0659 0.0662 0.0673 0.0681 0.0691 0.0703 

[TRAIN] Epoch[5](396/1500); Loss: 0.101963; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1558 0.1135 0.1040 0.1104 0.1100 0.1029 0.0991 0.0950 0.0935 0.0917 0.0910 0.0907 0.0924 0.0927 0.0941 0.0947 

[TRAIN] Epoch[5](397/1500); Loss: 0.078046; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1072 0.0869 0.0799 0.0753 0.0724 0.0703 0.0700 0.0698 0.0710 0.0712 0.0737 0.0746 0.0777 0.0793 0.0836 0.0859 

[TRAIN] Epoch[5](398/1500); Loss: 0.053782; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0814 0.0713 0.0590 0.0541 0.0526 0.0499 0.0486 0.0476 0.0475 0.0472 0.0482 0.0489 0.0489 0.0509 0.0516 0.0528 

[TRAIN] Epoch[5](399/1500); Loss: 0.145414; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.2072 0.1804 0.1683 0.1667 0.1580 0.1504 0.1432 0.1362 0.1321 0.1292 0.1278 0.1270 0.1254 0.1251 0.1251 0.1247 

[TRAIN] Epoch[5](400/1500); Loss: 0.170065; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2753 0.2252 0.2206 0.2367 0.2251 0.2088 0.1881 0.1660 0.1471 0.1294 0.1177 0.1167 0.1160 0.1157 0.1160 0.1166 

[TRAIN] Epoch[5](401/1500); Loss: 0.086061; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1224 0.1028 0.0968 0.0937 0.0916 0.0876 0.0846 0.0821 0.0796 0.0785 0.0767 0.0758 0.0751 0.0759 0.0760 0.0777 

[TRAIN] Epoch[5](402/1500); Loss: 0.094126; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1285 0.1121 0.1030 0.0961 0.0945 0.0912 0.0880 0.0874 0.0862 0.0856 0.0862 0.0867 0.0875 0.0891 0.0908 0.0931 

[TRAIN] Epoch[5](403/1500); Loss: 0.090372; Backpropagation: 0.0930 sec; Batch: 0.4243 sec
0.1730 0.1169 0.1097 0.1188 0.1136 0.1002 0.0874 0.0765 0.0717 0.0689 0.0677 0.0676 0.0676 0.0681 0.0689 0.0694 

[TRAIN] Epoch[5](404/1500); Loss: 0.097244; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1554 0.1039 0.0996 0.1080 0.1095 0.0994 0.0938 0.0896 0.0877 0.0852 0.0849 0.0849 0.0857 0.0867 0.0890 0.0924 

[TRAIN] Epoch[5](405/1500); Loss: 0.103460; Backpropagation: 0.0930 sec; Batch: 0.4250 sec
0.1450 0.1137 0.1031 0.1068 0.1034 0.0961 0.0930 0.0923 0.0935 0.0945 0.0966 0.0979 0.1009 0.1028 0.1064 0.1093 

[TRAIN] Epoch[5](406/1500); Loss: 0.116704; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1848 0.1324 0.1248 0.1329 0.1334 0.1236 0.1173 0.1112 0.1056 0.1021 0.1006 0.1000 0.0996 0.0993 0.1002 0.0995 

[TRAIN] Epoch[5](407/1500); Loss: 0.057869; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1396 0.0798 0.0660 0.0774 0.0663 0.0542 0.0474 0.0448 0.0441 0.0438 0.0427 0.0431 0.0430 0.0434 0.0447 0.0454 

[TRAIN] Epoch[5](408/1500); Loss: 0.121517; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2300 0.1645 0.1523 0.1651 0.1567 0.1386 0.1171 0.1007 0.0977 0.0924 0.0899 0.0897 0.0875 0.0870 0.0872 0.0879 

[TRAIN] Epoch[5](409/1500); Loss: 0.148812; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2251 0.1742 0.1672 0.1772 0.1683 0.1559 0.1466 0.1381 0.1328 0.1299 0.1291 0.1277 0.1273 0.1271 0.1270 0.1275 

[TRAIN] Epoch[5](410/1500); Loss: 0.076710; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1263 0.0833 0.0788 0.0878 0.0933 0.0783 0.0724 0.0715 0.0690 0.0659 0.0640 0.0637 0.0648 0.0665 0.0697 0.0720 

[TRAIN] Epoch[5](411/1500); Loss: 0.076659; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1220 0.0839 0.0769 0.0798 0.0764 0.0734 0.0711 0.0688 0.0691 0.0697 0.0696 0.0712 0.0716 0.0732 0.0740 0.0758 

[TRAIN] Epoch[5](412/1500); Loss: 0.074617; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1193 0.0894 0.0800 0.0811 0.0762 0.0714 0.0702 0.0676 0.0674 0.0673 0.0667 0.0665 0.0668 0.0671 0.0678 0.0688 

[TRAIN] Epoch[5](413/1500); Loss: 0.130016; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2140 0.1603 0.1543 0.1645 0.1568 0.1434 0.1299 0.1158 0.1103 0.1085 0.1055 0.1047 0.1034 0.1025 0.1034 0.1030 

[TRAIN] Epoch[5](414/1500); Loss: 0.099685; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1568 0.1072 0.1071 0.1235 0.1183 0.1062 0.0936 0.0880 0.0857 0.0848 0.0842 0.0844 0.0858 0.0874 0.0896 0.0923 

[TRAIN] Epoch[5](415/1500); Loss: 0.103030; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1240 0.1134 0.1118 0.1095 0.1069 0.1047 0.1028 0.1006 0.0989 0.0976 0.0968 0.0963 0.0960 0.0960 0.0963 0.0967 

[TRAIN] Epoch[5](416/1500); Loss: 0.125279; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1434 0.1398 0.1378 0.1325 0.1288 0.1273 0.1250 0.1221 0.1200 0.1189 0.1180 0.1177 0.1180 0.1180 0.1184 0.1188 

[TRAIN] Epoch[5](417/1500); Loss: 0.123117; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2980 0.2001 0.1932 0.2320 0.2091 0.1766 0.1326 0.0885 0.0607 0.0589 0.0555 0.0529 0.0528 0.0513 0.0539 0.0538 

[TRAIN] Epoch[5](418/1500); Loss: 0.097327; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2014 0.1267 0.1185 0.1395 0.1286 0.1085 0.0883 0.0762 0.0725 0.0711 0.0707 0.0714 0.0699 0.0703 0.0711 0.0724 

[TRAIN] Epoch[5](419/1500); Loss: 0.095262; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2277 0.1484 0.1392 0.1664 0.1486 0.1206 0.0821 0.0578 0.0573 0.0521 0.0517 0.0523 0.0530 0.0544 0.0555 0.0571 

[TRAIN] Epoch[5](420/1500); Loss: 0.100658; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1847 0.1298 0.1265 0.1368 0.1291 0.1173 0.1047 0.0920 0.0839 0.0759 0.0707 0.0723 0.0717 0.0714 0.0720 0.0716 

[TRAIN] Epoch[5](421/1500); Loss: 0.058740; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.0721 0.0736 0.0645 0.0600 0.0584 0.0578 0.0569 0.0557 0.0536 0.0531 0.0537 0.0538 0.0543 0.0564 0.0566 0.0593 

[TRAIN] Epoch[5](422/1500); Loss: 0.089926; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1136 0.1005 0.0961 0.0932 0.0895 0.0871 0.0852 0.0841 0.0839 0.0839 0.0840 0.0852 0.0859 0.0873 0.0894 0.0898 

[TRAIN] Epoch[5](423/1500); Loss: 0.093025; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1080 0.1002 0.0953 0.0949 0.0935 0.0918 0.0905 0.0896 0.0891 0.0888 0.0890 0.0897 0.0905 0.0914 0.0925 0.0938 

[TRAIN] Epoch[5](424/1500); Loss: 0.171311; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.3063 0.2064 0.2053 0.2369 0.2334 0.2080 0.1836 0.1641 0.1502 0.1377 0.1278 0.1206 0.1160 0.1148 0.1143 0.1156 

[TRAIN] Epoch[5](425/1500); Loss: 0.113843; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2035 0.1408 0.1377 0.1608 0.1482 0.1311 0.1126 0.0992 0.0910 0.0876 0.0861 0.0851 0.0844 0.0842 0.0844 0.0848 

[TRAIN] Epoch[5](426/1500); Loss: 0.158792; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1964 0.1701 0.1678 0.1680 0.1660 0.1619 0.1577 0.1538 0.1516 0.1499 0.1490 0.1486 0.1488 0.1495 0.1503 0.1510 

[TRAIN] Epoch[5](427/1500); Loss: 0.143876; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2106 0.1736 0.1637 0.1738 0.1704 0.1605 0.1504 0.1407 0.1321 0.1242 0.1179 0.1154 0.1165 0.1169 0.1176 0.1178 

[TRAIN] Epoch[5](428/1500); Loss: 0.073116; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0869 0.0832 0.0783 0.0731 0.0715 0.0702 0.0698 0.0689 0.0683 0.0688 0.0691 0.0702 0.0709 0.0722 0.0736 0.0748 

[TRAIN] Epoch[5](429/1500); Loss: 0.088006; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1142 0.0966 0.0916 0.0929 0.0906 0.0877 0.0875 0.0845 0.0835 0.0835 0.0822 0.0819 0.0822 0.0821 0.0831 0.0840 

[TRAIN] Epoch[5](430/1500); Loss: 0.138672; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1934 0.1532 0.1470 0.1521 0.1483 0.1437 0.1391 0.1323 0.1309 0.1287 0.1263 0.1262 0.1246 0.1243 0.1245 0.1242 

[TRAIN] Epoch[5](431/1500); Loss: 0.126387; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1556 0.1407 0.1297 0.1275 0.1296 0.1255 0.1234 0.1211 0.1205 0.1200 0.1195 0.1203 0.1207 0.1214 0.1228 0.1239 

[TRAIN] Epoch[5](432/1500); Loss: 0.130827; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2159 0.1629 0.1540 0.1656 0.1544 0.1405 0.1256 0.1131 0.1058 0.1036 0.1046 0.1062 0.1080 0.1089 0.1112 0.1130 

[TRAIN] Epoch[5](433/1500); Loss: 0.194664; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2351 0.2150 0.2145 0.2203 0.2123 0.2070 0.2009 0.1930 0.1859 0.1824 0.1800 0.1768 0.1757 0.1727 0.1725 0.1706 

[TRAIN] Epoch[5](434/1500); Loss: 0.125822; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1508 0.1342 0.1320 0.1342 0.1321 0.1278 0.1249 0.1221 0.1203 0.1197 0.1189 0.1184 0.1190 0.1189 0.1196 0.1203 

[TRAIN] Epoch[5](435/1500); Loss: 0.089007; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1430 0.1068 0.0994 0.1015 0.0930 0.0865 0.0861 0.0792 0.0777 0.0775 0.0764 0.0775 0.0777 0.0790 0.0805 0.0822 

[TRAIN] Epoch[5](436/1500); Loss: 0.091793; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1108 0.1021 0.1003 0.0988 0.0952 0.0931 0.0913 0.0886 0.0874 0.0862 0.0854 0.0849 0.0850 0.0855 0.0865 0.0876 

[TRAIN] Epoch[5](437/1500); Loss: 0.123400; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1403 0.1230 0.1210 0.1221 0.1210 0.1185 0.1177 0.1174 0.1184 0.1197 0.1211 0.1227 0.1247 0.1267 0.1288 0.1313 

[TRAIN] Epoch[5](438/1500); Loss: 0.103829; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1633 0.1404 0.1201 0.1204 0.1140 0.1023 0.0916 0.0829 0.0832 0.0820 0.0840 0.0872 0.0905 0.0947 0.0995 0.1052 

[TRAIN] Epoch[5](439/1500); Loss: 0.102732; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1458 0.1169 0.1107 0.1122 0.1085 0.1030 0.0991 0.0954 0.0925 0.0918 0.0909 0.0920 0.0929 0.0956 0.0970 0.0993 

[TRAIN] Epoch[5](440/1500); Loss: 0.131327; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1968 0.1608 0.1523 0.1561 0.1487 0.1391 0.1296 0.1220 0.1168 0.1142 0.1127 0.1114 0.1108 0.1101 0.1099 0.1101 

[TRAIN] Epoch[5](441/1500); Loss: 0.197336; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2318 0.2144 0.2150 0.2198 0.2155 0.2097 0.2023 0.1952 0.1909 0.1862 0.1846 0.1816 0.1800 0.1775 0.1777 0.1750 

[TRAIN] Epoch[5](442/1500); Loss: 0.116107; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2141 0.1385 0.1347 0.1621 0.1485 0.1272 0.1092 0.1002 0.0940 0.0914 0.0915 0.0907 0.0893 0.0890 0.0887 0.0887 

[TRAIN] Epoch[5](443/1500); Loss: 0.132758; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1739 0.1512 0.1415 0.1370 0.1335 0.1257 0.1216 0.1202 0.1199 0.1206 0.1225 0.1245 0.1277 0.1318 0.1338 0.1388 

[TRAIN] Epoch[5](444/1500); Loss: 0.085246; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1060 0.0970 0.0911 0.0888 0.0888 0.0862 0.0845 0.0832 0.0817 0.0808 0.0799 0.0797 0.0792 0.0791 0.0790 0.0789 

[TRAIN] Epoch[5](445/1500); Loss: 0.044075; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0594 0.0640 0.0548 0.0426 0.0424 0.0423 0.0396 0.0388 0.0383 0.0384 0.0390 0.0394 0.0400 0.0411 0.0418 0.0431 

[TRAIN] Epoch[5](446/1500); Loss: 0.130231; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1480 0.1351 0.1347 0.1359 0.1345 0.1322 0.1296 0.1277 0.1256 0.1255 0.1255 0.1253 0.1256 0.1259 0.1262 0.1263 

[TRAIN] Epoch[5](447/1500); Loss: 0.144768; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1863 0.1548 0.1517 0.1577 0.1577 0.1509 0.1464 0.1419 0.1373 0.1350 0.1334 0.1326 0.1320 0.1320 0.1327 0.1339 

[TRAIN] Epoch[5](448/1500); Loss: 0.126606; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1879 0.1505 0.1420 0.1479 0.1396 0.1302 0.1217 0.1157 0.1119 0.1100 0.1092 0.1098 0.1107 0.1121 0.1129 0.1137 

[TRAIN] Epoch[5](449/1500); Loss: 0.150536; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1983 0.1533 0.1505 0.1578 0.1584 0.1510 0.1466 0.1438 0.1422 0.1416 0.1414 0.1421 0.1427 0.1440 0.1466 0.1483 

[TRAIN] Epoch[5](450/1500); Loss: 0.078266; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0918 0.0927 0.0833 0.0773 0.0764 0.0757 0.0761 0.0741 0.0742 0.0746 0.0747 0.0750 0.0754 0.0763 0.0767 0.0777 

[TRAIN] Epoch[5](451/1500); Loss: 0.108951; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1293 0.1171 0.1109 0.1114 0.1149 0.1093 0.1060 0.1052 0.1041 0.1032 0.1017 0.1028 0.1036 0.1058 0.1079 0.1100 

[TRAIN] Epoch[5](452/1500); Loss: 0.060174; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1033 0.0851 0.0667 0.0598 0.0578 0.0550 0.0530 0.0522 0.0517 0.0511 0.0520 0.0519 0.0532 0.0547 0.0568 0.0585 

[TRAIN] Epoch[5](453/1500); Loss: 0.118964; Backpropagation: 0.0919 sec; Batch: 0.4443 sec
0.1428 0.1285 0.1240 0.1230 0.1201 0.1180 0.1170 0.1160 0.1147 0.1140 0.1138 0.1137 0.1138 0.1139 0.1148 0.1154 

[TRAIN] Epoch[5](454/1500); Loss: 0.115260; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2416 0.1127 0.1116 0.1445 0.1614 0.1303 0.1131 0.1056 0.0961 0.0898 0.0854 0.0857 0.0855 0.0906 0.0949 0.0954 

[TRAIN] Epoch[5](455/1500); Loss: 0.137702; Backpropagation: 0.0919 sec; Batch: 0.4281 sec
0.2459 0.1596 0.1607 0.1946 0.1836 0.1604 0.1349 0.1158 0.1078 0.1062 0.1059 0.1041 0.1044 0.1054 0.1066 0.1073 

[TRAIN] Epoch[5](456/1500); Loss: 0.141820; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2082 0.1713 0.1662 0.1731 0.1664 0.1571 0.1457 0.1351 0.1272 0.1211 0.1175 0.1169 0.1162 0.1154 0.1157 0.1159 

[TRAIN] Epoch[5](457/1500); Loss: 0.167767; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2165 0.1859 0.1841 0.1913 0.1870 0.1786 0.1714 0.1639 0.1577 0.1534 0.1512 0.1492 0.1484 0.1485 0.1485 0.1487 

[TRAIN] Epoch[5](458/1500); Loss: 0.119868; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1216 0.1204 0.1203 0.1177 0.1169 0.1172 0.1178 0.1178 0.1177 0.1181 0.1192 0.1199 0.1210 0.1227 0.1239 0.1258 

[TRAIN] Epoch[5](459/1500); Loss: 0.120467; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1451 0.1379 0.1307 0.1264 0.1248 0.1220 0.1191 0.1165 0.1147 0.1135 0.1132 0.1128 0.1125 0.1123 0.1127 0.1135 

[TRAIN] Epoch[5](460/1500); Loss: 0.118426; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1483 0.1338 0.1277 0.1243 0.1217 0.1196 0.1173 0.1147 0.1130 0.1120 0.1106 0.1107 0.1100 0.1103 0.1102 0.1107 

[TRAIN] Epoch[5](461/1500); Loss: 0.086665; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2391 0.1467 0.1361 0.1693 0.1481 0.1184 0.0800 0.0494 0.0368 0.0376 0.0357 0.0373 0.0367 0.0373 0.0385 0.0396 

[TRAIN] Epoch[5](462/1500); Loss: 0.158147; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1726 0.1601 0.1562 0.1561 0.1548 0.1533 0.1534 0.1540 0.1549 0.1555 0.1567 0.1581 0.1589 0.1606 0.1617 0.1634 

[TRAIN] Epoch[5](463/1500); Loss: 0.108781; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1728 0.1200 0.1140 0.1215 0.1209 0.1117 0.1053 0.0996 0.0960 0.0946 0.0946 0.0953 0.0961 0.0980 0.0989 0.1011 

[TRAIN] Epoch[5](464/1500); Loss: 0.102236; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1635 0.1430 0.1232 0.1166 0.1110 0.1007 0.0922 0.0842 0.0822 0.0813 0.0815 0.0836 0.0867 0.0904 0.0951 0.1006 

[TRAIN] Epoch[5](465/1500); Loss: 0.149647; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2263 0.1816 0.1763 0.1861 0.1781 0.1650 0.1496 0.1345 0.1276 0.1275 0.1250 0.1242 0.1239 0.1230 0.1231 0.1226 

[TRAIN] Epoch[5](466/1500); Loss: 0.061055; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.0904 0.0601 0.0579 0.0601 0.0609 0.0581 0.0570 0.0570 0.0580 0.0573 0.0582 0.0592 0.0582 0.0611 0.0613 0.0621 

[TRAIN] Epoch[5](467/1500); Loss: 0.072802; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1076 0.0915 0.0860 0.0775 0.0727 0.0688 0.0661 0.0639 0.0630 0.0624 0.0633 0.0640 0.0662 0.0674 0.0708 0.0735 

[TRAIN] Epoch[5](468/1500); Loss: 0.125392; Backpropagation: 0.0918 sec; Batch: 0.4251 sec
0.2474 0.1246 0.1227 0.1538 0.1692 0.1405 0.1217 0.1124 0.1033 0.0995 0.0986 0.0986 0.0987 0.1013 0.1072 0.1068 

[TRAIN] Epoch[5](469/1500); Loss: 0.050312; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0803 0.0618 0.0565 0.0534 0.0501 0.0466 0.0450 0.0439 0.0443 0.0440 0.0444 0.0447 0.0462 0.0465 0.0481 0.0491 

[TRAIN] Epoch[5](470/1500); Loss: 0.062856; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1176 0.0741 0.0660 0.0639 0.0600 0.0607 0.0558 0.0550 0.0550 0.0544 0.0543 0.0554 0.0558 0.0574 0.0591 0.0612 

[TRAIN] Epoch[5](471/1500); Loss: 0.116799; Backpropagation: 0.0920 sec; Batch: 0.4228 sec
0.2500 0.1700 0.1608 0.1879 0.1695 0.1445 0.1108 0.0802 0.0772 0.0745 0.0736 0.0729 0.0731 0.0736 0.0736 0.0765 

[TRAIN] Epoch[5](472/1500); Loss: 0.083357; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1273 0.1056 0.0990 0.0954 0.0918 0.0866 0.0817 0.0771 0.0733 0.0707 0.0695 0.0692 0.0695 0.0710 0.0721 0.0737 

[TRAIN] Epoch[5](473/1500); Loss: 0.110264; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1716 0.1378 0.1287 0.1317 0.1282 0.1191 0.1093 0.1003 0.0963 0.0937 0.0921 0.0912 0.0908 0.0905 0.0913 0.0915 

[TRAIN] Epoch[5](474/1500); Loss: 0.120896; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1633 0.1316 0.1294 0.1351 0.1313 0.1255 0.1199 0.1148 0.1124 0.1109 0.1101 0.1100 0.1096 0.1099 0.1100 0.1105 

[TRAIN] Epoch[5](475/1500); Loss: 0.123878; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2149 0.1556 0.1451 0.1594 0.1519 0.1368 0.1219 0.1097 0.1020 0.0991 0.0980 0.0969 0.0975 0.0970 0.0979 0.0983 

[TRAIN] Epoch[5](476/1500); Loss: 0.120307; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1619 0.1231 0.1187 0.1233 0.1276 0.1214 0.1172 0.1152 0.1136 0.1129 0.1125 0.1131 0.1139 0.1149 0.1169 0.1187 

[TRAIN] Epoch[5](477/1500); Loss: 0.084726; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1453 0.0961 0.0900 0.0947 0.0932 0.0861 0.0811 0.0770 0.0742 0.0731 0.0718 0.0722 0.0727 0.0742 0.0756 0.0782 

[TRAIN] Epoch[5](478/1500); Loss: 0.154182; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1919 0.1638 0.1613 0.1649 0.1650 0.1590 0.1559 0.1530 0.1502 0.1479 0.1458 0.1438 0.1425 0.1412 0.1406 0.1400 

[TRAIN] Epoch[5](479/1500); Loss: 0.086180; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1422 0.1033 0.0962 0.1008 0.0946 0.0887 0.0842 0.0791 0.0765 0.0747 0.0738 0.0731 0.0727 0.0728 0.0730 0.0732 

[TRAIN] Epoch[5](480/1500); Loss: 0.128136; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1689 0.1336 0.1291 0.1337 0.1354 0.1306 0.1268 0.1244 0.1228 0.1214 0.1202 0.1194 0.1196 0.1202 0.1212 0.1226 

[TRAIN] Epoch[5](481/1500); Loss: 0.068507; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0960 0.0815 0.0726 0.0703 0.0674 0.0641 0.0643 0.0634 0.0627 0.0625 0.0623 0.0632 0.0642 0.0661 0.0662 0.0693 

[TRAIN] Epoch[5](482/1500); Loss: 0.066359; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0871 0.0786 0.0686 0.0656 0.0645 0.0630 0.0622 0.0614 0.0619 0.0614 0.0619 0.0634 0.0637 0.0644 0.0668 0.0671 

[TRAIN] Epoch[5](483/1500); Loss: 0.109430; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1803 0.1307 0.1242 0.1298 0.1299 0.1200 0.1126 0.1058 0.0991 0.0939 0.0904 0.0878 0.0865 0.0857 0.0864 0.0876 

[TRAIN] Epoch[5](484/1500); Loss: 0.087968; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2169 0.1365 0.1247 0.1533 0.1353 0.1082 0.0766 0.0606 0.0533 0.0492 0.0493 0.0496 0.0482 0.0480 0.0485 0.0495 

[TRAIN] Epoch[5](485/1500); Loss: 0.122963; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1787 0.1308 0.1234 0.1303 0.1351 0.1268 0.1227 0.1203 0.1173 0.1147 0.1129 0.1113 0.1105 0.1104 0.1106 0.1115 

[TRAIN] Epoch[5](486/1500); Loss: 0.111238; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1663 0.1300 0.1210 0.1233 0.1244 0.1169 0.1123 0.1082 0.1046 0.1016 0.0985 0.0967 0.0952 0.0941 0.0934 0.0935 

[TRAIN] Epoch[5](487/1500); Loss: 0.118730; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1831 0.1251 0.1179 0.1280 0.1331 0.1245 0.1201 0.1160 0.1124 0.1097 0.1067 0.1053 0.1045 0.1042 0.1045 0.1045 

[TRAIN] Epoch[5](488/1500); Loss: 0.101883; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1686 0.1171 0.1090 0.1180 0.1129 0.1031 0.0959 0.0927 0.0911 0.0892 0.0886 0.0882 0.0885 0.0887 0.0892 0.0894 

[TRAIN] Epoch[5](489/1500); Loss: 0.107607; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1407 0.1166 0.1111 0.1124 0.1126 0.1082 0.1051 0.1032 0.1019 0.1010 0.1008 0.1006 0.1010 0.1017 0.1020 0.1028 

[TRAIN] Epoch[5](490/1500); Loss: 0.174534; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2656 0.2208 0.2195 0.2360 0.2224 0.2047 0.1849 0.1619 0.1398 0.1328 0.1399 0.1333 0.1321 0.1333 0.1332 0.1323 

[TRAIN] Epoch[5](491/1500); Loss: 0.138452; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1874 0.1554 0.1508 0.1560 0.1487 0.1407 0.1341 0.1289 0.1280 0.1270 0.1266 0.1265 0.1260 0.1261 0.1264 0.1267 

[TRAIN] Epoch[5](492/1500); Loss: 0.170827; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2546 0.1267 0.1261 0.1588 0.1886 0.1775 0.1667 0.1695 0.1728 0.1753 0.1729 0.1726 0.1694 0.1684 0.1664 0.1668 

[TRAIN] Epoch[5](493/1500); Loss: 0.173754; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2563 0.1337 0.1325 0.1637 0.1922 0.1811 0.1706 0.1732 0.1760 0.1780 0.1752 0.1742 0.1707 0.1689 0.1670 0.1667 

[TRAIN] Epoch[5](494/1500); Loss: 0.157432; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2452 0.2062 0.1926 0.1971 0.1870 0.1749 0.1599 0.1457 0.1353 0.1295 0.1261 0.1253 0.1246 0.1238 0.1229 0.1229 

[TRAIN] Epoch[5](495/1500); Loss: 0.087553; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0991 0.1062 0.0950 0.0876 0.0862 0.0853 0.0842 0.0829 0.0828 0.0828 0.0831 0.0834 0.0842 0.0850 0.0860 0.0868 

[TRAIN] Epoch[5](496/1500); Loss: 0.070047; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1014 0.0926 0.0814 0.0738 0.0695 0.0665 0.0640 0.0631 0.0633 0.0619 0.0628 0.0624 0.0636 0.0637 0.0652 0.0655 

[TRAIN] Epoch[5](497/1500); Loss: 0.102241; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.1395 0.1105 0.1031 0.1089 0.1049 0.0978 0.0948 0.0928 0.0927 0.0933 0.0951 0.0961 0.0987 0.0997 0.1031 0.1047 

[TRAIN] Epoch[5](498/1500); Loss: 0.153082; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2669 0.1824 0.1683 0.1828 0.1886 0.1755 0.1634 0.1530 0.1428 0.1346 0.1273 0.1212 0.1158 0.1116 0.1088 0.1064 

[TRAIN] Epoch[5](499/1500); Loss: 0.094314; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1148 0.1071 0.0998 0.0979 0.0965 0.0932 0.0915 0.0906 0.0896 0.0893 0.0889 0.0893 0.0897 0.0898 0.0902 0.0907 

[TRAIN] Epoch[5](500/1500); Loss: 0.150944; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2357 0.1790 0.1719 0.1845 0.1807 0.1661 0.1545 0.1454 0.1384 0.1329 0.1289 0.1246 0.1212 0.1185 0.1169 0.1159 

[TRAIN] Epoch[5](501/1500); Loss: 0.124563; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2180 0.1599 0.1478 0.1524 0.1487 0.1371 0.1259 0.1152 0.1074 0.1031 0.1007 0.0982 0.0966 0.0952 0.0938 0.0932 

[TRAIN] Epoch[5](502/1500); Loss: 0.148615; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1587 0.1578 0.1566 0.1527 0.1506 0.1489 0.1485 0.1462 0.1455 0.1451 0.1445 0.1444 0.1443 0.1444 0.1445 0.1451 

[TRAIN] Epoch[5](503/1500); Loss: 0.092980; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1312 0.0975 0.0935 0.0995 0.0969 0.0900 0.0891 0.0866 0.0859 0.0861 0.0872 0.0871 0.0868 0.0886 0.0903 0.0914 

[TRAIN] Epoch[5](504/1500); Loss: 0.106385; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1618 0.1189 0.1099 0.1121 0.1126 0.1069 0.1029 0.1001 0.0979 0.0969 0.0963 0.0963 0.0963 0.0968 0.0979 0.0985 

[TRAIN] Epoch[5](505/1500); Loss: 0.119078; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1811 0.1409 0.1326 0.1383 0.1307 0.1208 0.1124 0.1074 0.1063 0.1059 0.1049 0.1048 0.1051 0.1044 0.1047 0.1051 

[TRAIN] Epoch[5](506/1500); Loss: 0.141645; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2139 0.1648 0.1554 0.1667 0.1564 0.1433 0.1320 0.1296 0.1271 0.1256 0.1259 0.1251 0.1247 0.1251 0.1252 0.1256 

[TRAIN] Epoch[5](507/1500); Loss: 0.125316; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1587 0.1395 0.1321 0.1325 0.1311 0.1252 0.1211 0.1204 0.1192 0.1182 0.1177 0.1175 0.1171 0.1176 0.1182 0.1189 

[TRAIN] Epoch[5](508/1500); Loss: 0.130717; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1755 0.1573 0.1462 0.1458 0.1452 0.1370 0.1313 0.1276 0.1233 0.1199 0.1168 0.1144 0.1131 0.1127 0.1121 0.1134 

[TRAIN] Epoch[5](509/1500); Loss: 0.176692; Backpropagation: 0.0924 sec; Batch: 0.4245 sec
0.3682 0.2730 0.2656 0.3009 0.2790 0.2474 0.2066 0.1620 0.1237 0.0912 0.0864 0.0879 0.0842 0.0839 0.0839 0.0831 

[TRAIN] Epoch[5](510/1500); Loss: 0.102924; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1634 0.1296 0.1203 0.1247 0.1170 0.1060 0.0944 0.0877 0.0888 0.0875 0.0872 0.0865 0.0872 0.0888 0.0884 0.0893 

[TRAIN] Epoch[5](511/1500); Loss: 0.148151; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1860 0.1623 0.1607 0.1631 0.1584 0.1532 0.1476 0.1431 0.1394 0.1375 0.1364 0.1365 0.1359 0.1365 0.1367 0.1373 

[TRAIN] Epoch[5](512/1500); Loss: 0.143626; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1744 0.1539 0.1473 0.1503 0.1491 0.1439 0.1420 0.1399 0.1382 0.1374 0.1367 0.1363 0.1364 0.1368 0.1374 0.1381 

[TRAIN] Epoch[5](513/1500); Loss: 0.127912; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2046 0.1376 0.1375 0.1619 0.1553 0.1403 0.1240 0.1133 0.1107 0.1076 0.1073 0.1076 0.1088 0.1088 0.1099 0.1112 

[TRAIN] Epoch[5](514/1500); Loss: 0.071674; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1104 0.0859 0.0786 0.0767 0.0735 0.0703 0.0684 0.0661 0.0658 0.0654 0.0644 0.0643 0.0643 0.0640 0.0641 0.0646 

[TRAIN] Epoch[5](515/1500); Loss: 0.100512; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1308 0.1114 0.1072 0.1078 0.1027 0.0998 0.0982 0.0957 0.0942 0.0940 0.0937 0.0936 0.0939 0.0945 0.0950 0.0959 

[TRAIN] Epoch[5](516/1500); Loss: 0.056627; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1042 0.0767 0.0656 0.0623 0.0609 0.0560 0.0541 0.0495 0.0483 0.0474 0.0472 0.0462 0.0462 0.0472 0.0468 0.0475 

[TRAIN] Epoch[5](517/1500); Loss: 0.125199; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1719 0.1369 0.1282 0.1304 0.1307 0.1254 0.1208 0.1171 0.1156 0.1150 0.1150 0.1162 0.1177 0.1190 0.1207 0.1225 

[TRAIN] Epoch[5](518/1500); Loss: 0.148217; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1893 0.1669 0.1570 0.1581 0.1578 0.1522 0.1481 0.1446 0.1412 0.1387 0.1376 0.1362 0.1359 0.1356 0.1362 0.1361 

[TRAIN] Epoch[5](519/1500); Loss: 0.104677; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1306 0.1113 0.1058 0.1062 0.1043 0.1019 0.1009 0.1005 0.1004 0.1004 0.1007 0.1014 0.1021 0.1019 0.1028 0.1037 

[TRAIN] Epoch[5](520/1500); Loss: 0.109294; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1478 0.1340 0.1216 0.1180 0.1145 0.1082 0.1064 0.1032 0.1012 0.1005 0.0989 0.0987 0.0982 0.0989 0.0982 0.1003 

[TRAIN] Epoch[5](521/1500); Loss: 0.037341; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0371 0.0491 0.0408 0.0331 0.0324 0.0321 0.0322 0.0334 0.0336 0.0348 0.0363 0.0373 0.0388 0.0405 0.0421 0.0439 

[TRAIN] Epoch[5](522/1500); Loss: 0.137209; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2906 0.1797 0.1515 0.1727 0.1863 0.1717 0.1538 0.1374 0.1232 0.1113 0.1012 0.0916 0.0856 0.0808 0.0785 0.0793 

[TRAIN] Epoch[5](523/1500); Loss: 0.129918; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2261 0.1840 0.1768 0.1870 0.1733 0.1583 0.1383 0.1169 0.1015 0.0909 0.0862 0.0878 0.0878 0.0875 0.0874 0.0889 

[TRAIN] Epoch[5](524/1500); Loss: 0.120861; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2363 0.1688 0.1567 0.1773 0.1652 0.1459 0.1222 0.0998 0.0863 0.0875 0.0826 0.0820 0.0809 0.0800 0.0813 0.0809 

[TRAIN] Epoch[5](525/1500); Loss: 0.065316; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.0817 0.0756 0.0708 0.0686 0.0648 0.0627 0.0622 0.0613 0.0611 0.0613 0.0614 0.0613 0.0622 0.0627 0.0627 0.0647 

[TRAIN] Epoch[5](526/1500); Loss: 0.148267; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1699 0.1623 0.1590 0.1554 0.1509 0.1486 0.1469 0.1448 0.1434 0.1428 0.1420 0.1418 0.1407 0.1412 0.1413 0.1414 

[TRAIN] Epoch[5](527/1500); Loss: 0.111033; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1919 0.1428 0.1270 0.1312 0.1281 0.1188 0.1099 0.1009 0.0946 0.0905 0.0880 0.0872 0.0878 0.0901 0.0920 0.0956 

[TRAIN] Epoch[5](528/1500); Loss: 0.081395; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1082 0.0865 0.0808 0.0779 0.0780 0.0765 0.0761 0.0766 0.0770 0.0776 0.0785 0.0792 0.0806 0.0815 0.0832 0.0842 

[TRAIN] Epoch[5](529/1500); Loss: 0.065881; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1027 0.0927 0.0816 0.0704 0.0660 0.0608 0.0596 0.0579 0.0557 0.0564 0.0553 0.0568 0.0563 0.0588 0.0601 0.0630 

[TRAIN] Epoch[5](530/1500); Loss: 0.104691; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1248 0.1181 0.1106 0.1064 0.1048 0.1032 0.1024 0.1010 0.1005 0.1002 0.1001 0.1001 0.1004 0.1006 0.1009 0.1012 

[TRAIN] Epoch[5](531/1500); Loss: 0.123312; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1898 0.1317 0.1236 0.1344 0.1403 0.1304 0.1226 0.1185 0.1141 0.1115 0.1099 0.1085 0.1085 0.1089 0.1097 0.1106 

[TRAIN] Epoch[5](532/1500); Loss: 0.103631; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1786 0.1151 0.1019 0.1104 0.1156 0.1088 0.1019 0.0960 0.0926 0.0905 0.0894 0.0892 0.0900 0.0906 0.0929 0.0946 

[TRAIN] Epoch[5](533/1500); Loss: 0.067845; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1223 0.0691 0.0587 0.0599 0.0614 0.0600 0.0593 0.0610 0.0612 0.0634 0.0640 0.0664 0.0670 0.0694 0.0699 0.0726 

[TRAIN] Epoch[5](534/1500); Loss: 0.103073; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1623 0.1229 0.1100 0.1106 0.1096 0.1042 0.1005 0.0967 0.0938 0.0921 0.0910 0.0904 0.0905 0.0909 0.0913 0.0924 

[TRAIN] Epoch[5](535/1500); Loss: 0.076447; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0978 0.0869 0.0834 0.0797 0.0770 0.0757 0.0742 0.0723 0.0721 0.0719 0.0718 0.0712 0.0717 0.0719 0.0726 0.0731 

[TRAIN] Epoch[5](536/1500); Loss: 0.099400; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1712 0.1163 0.1133 0.1284 0.1172 0.1035 0.0945 0.0859 0.0815 0.0820 0.0827 0.0822 0.0822 0.0821 0.0831 0.0845 

[TRAIN] Epoch[5](537/1500); Loss: 0.108013; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1745 0.1234 0.1126 0.1173 0.1206 0.1128 0.1084 0.1043 0.1004 0.0972 0.0946 0.0929 0.0922 0.0920 0.0920 0.0930 

[TRAIN] Epoch[5](538/1500); Loss: 0.083985; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1305 0.1168 0.0994 0.0929 0.0848 0.0796 0.0718 0.0713 0.0728 0.0704 0.0710 0.0717 0.0742 0.0753 0.0797 0.0816 

[TRAIN] Epoch[5](539/1500); Loss: 0.103630; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1586 0.1325 0.1165 0.1121 0.1052 0.0982 0.0945 0.0935 0.0915 0.0913 0.0914 0.0918 0.0929 0.0943 0.0959 0.0979 

[TRAIN] Epoch[5](540/1500); Loss: 0.172027; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2182 0.1952 0.1890 0.1896 0.1855 0.1786 0.1722 0.1665 0.1630 0.1606 0.1581 0.1566 0.1556 0.1549 0.1545 0.1543 

[TRAIN] Epoch[5](541/1500); Loss: 0.081983; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1458 0.0954 0.0827 0.0858 0.0854 0.0800 0.0793 0.0738 0.0724 0.0726 0.0722 0.0730 0.0722 0.0731 0.0737 0.0744 

[TRAIN] Epoch[5](542/1500); Loss: 0.132305; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1679 0.1533 0.1449 0.1417 0.1373 0.1329 0.1299 0.1273 0.1254 0.1245 0.1237 0.1229 0.1218 0.1215 0.1210 0.1209 

[TRAIN] Epoch[5](543/1500); Loss: 0.085972; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1460 0.1134 0.0986 0.0978 0.0945 0.0885 0.0825 0.0788 0.0766 0.0736 0.0722 0.0708 0.0698 0.0704 0.0707 0.0713 

[TRAIN] Epoch[5](544/1500); Loss: 0.140280; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1908 0.1641 0.1525 0.1535 0.1520 0.1455 0.1399 0.1348 0.1309 0.1277 0.1264 0.1253 0.1251 0.1250 0.1254 0.1256 

[TRAIN] Epoch[5](545/1500); Loss: 0.148619; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1895 0.1674 0.1583 0.1584 0.1566 0.1513 0.1475 0.1443 0.1417 0.1397 0.1385 0.1377 0.1369 0.1368 0.1365 0.1367 

[TRAIN] Epoch[5](546/1500); Loss: 0.131452; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1530 0.1462 0.1399 0.1369 0.1356 0.1323 0.1294 0.1277 0.1260 0.1252 0.1248 0.1240 0.1244 0.1250 0.1257 0.1273 

[TRAIN] Epoch[5](547/1500); Loss: 0.115535; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1301 0.1252 0.1199 0.1157 0.1140 0.1138 0.1132 0.1118 0.1120 0.1121 0.1123 0.1127 0.1131 0.1135 0.1144 0.1148 

[TRAIN] Epoch[5](548/1500); Loss: 0.050194; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1021 0.0605 0.0557 0.0523 0.0477 0.0503 0.0454 0.0433 0.0416 0.0411 0.0431 0.0409 0.0415 0.0454 0.0448 0.0475 

[TRAIN] Epoch[5](549/1500); Loss: 0.114451; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2311 0.1531 0.1288 0.1372 0.1409 0.1294 0.1176 0.1057 0.0967 0.0896 0.0845 0.0823 0.0815 0.0826 0.0838 0.0864 

[TRAIN] Epoch[5](550/1500); Loss: 0.173593; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.3250 0.2401 0.2188 0.2381 0.2195 0.1898 0.1565 0.1327 0.1246 0.1330 0.1301 0.1305 0.1318 0.1348 0.1355 0.1367 

[TRAIN] Epoch[5](551/1500); Loss: 0.089112; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1744 0.1283 0.1109 0.1057 0.1008 0.0894 0.0807 0.0734 0.0694 0.0676 0.0665 0.0675 0.0680 0.0714 0.0735 0.0782 

[TRAIN] Epoch[5](552/1500); Loss: 0.141442; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1840 0.1700 0.1603 0.1533 0.1463 0.1423 0.1390 0.1354 0.1326 0.1307 0.1294 0.1285 0.1279 0.1277 0.1278 0.1279 

[TRAIN] Epoch[5](553/1500); Loss: 0.099383; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1444 0.1392 0.1158 0.1037 0.1009 0.0936 0.0882 0.0838 0.0815 0.0838 0.0841 0.0873 0.0899 0.0934 0.0975 0.1032 

[TRAIN] Epoch[5](554/1500); Loss: 0.104415; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1959 0.1264 0.1076 0.1169 0.1218 0.1116 0.1021 0.0940 0.0886 0.0855 0.0843 0.0842 0.0854 0.0869 0.0889 0.0905 

[TRAIN] Epoch[5](555/1500); Loss: 0.090110; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1702 0.1164 0.1005 0.1038 0.1041 0.0959 0.0889 0.0815 0.0757 0.0724 0.0705 0.0703 0.0706 0.0721 0.0739 0.0747 

[TRAIN] Epoch[5](556/1500); Loss: 0.042048; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0783 0.0636 0.0523 0.0460 0.0419 0.0383 0.0377 0.0344 0.0340 0.0348 0.0346 0.0346 0.0355 0.0348 0.0362 0.0360 

[TRAIN] Epoch[5](557/1500); Loss: 0.129120; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1609 0.1492 0.1400 0.1361 0.1322 0.1288 0.1254 0.1227 0.1221 0.1222 0.1212 0.1206 0.1209 0.1207 0.1211 0.1219 

[TRAIN] Epoch[5](558/1500); Loss: 0.100509; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1180 0.1184 0.1094 0.1026 0.0997 0.0975 0.0966 0.0945 0.0940 0.0943 0.0944 0.0953 0.0958 0.0974 0.0992 0.1011 

[TRAIN] Epoch[5](559/1500); Loss: 0.072004; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1202 0.0844 0.0738 0.0701 0.0676 0.0681 0.0653 0.0645 0.0644 0.0641 0.0652 0.0657 0.0667 0.0693 0.0704 0.0723 

[TRAIN] Epoch[5](560/1500); Loss: 0.086418; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1112 0.0942 0.0922 0.0899 0.0871 0.0851 0.0832 0.0819 0.0818 0.0813 0.0816 0.0816 0.0821 0.0823 0.0830 0.0840 

[TRAIN] Epoch[5](561/1500); Loss: 0.076969; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1554 0.1045 0.0868 0.0887 0.0889 0.0807 0.0744 0.0680 0.0637 0.0608 0.0594 0.0594 0.0593 0.0596 0.0600 0.0618 

[TRAIN] Epoch[5](562/1500); Loss: 0.141037; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1841 0.1636 0.1508 0.1455 0.1409 0.1354 0.1325 0.1303 0.1289 0.1299 0.1316 0.1332 0.1347 0.1368 0.1384 0.1399 

[TRAIN] Epoch[5](563/1500); Loss: 0.158669; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1637 0.1594 0.1484 0.1453 0.1432 0.1432 0.1484 0.1499 0.1515 0.1559 0.1607 0.1642 0.1692 0.1734 0.1791 0.1831 

[TRAIN] Epoch[5](564/1500); Loss: 0.076450; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1452 0.1070 0.0904 0.0906 0.0808 0.0705 0.0672 0.0652 0.0659 0.0635 0.0632 0.0631 0.0625 0.0624 0.0627 0.0629 

[TRAIN] Epoch[5](565/1500); Loss: 0.095662; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1459 0.1200 0.1115 0.1093 0.1033 0.0973 0.0908 0.0856 0.0833 0.0826 0.0823 0.0826 0.0825 0.0837 0.0845 0.0854 

[TRAIN] Epoch[5](566/1500); Loss: 0.083032; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1487 0.1077 0.0982 0.0986 0.0918 0.0842 0.0773 0.0728 0.0697 0.0690 0.0681 0.0680 0.0684 0.0682 0.0686 0.0693 

[TRAIN] Epoch[5](567/1500); Loss: 0.169527; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.3150 0.2284 0.2067 0.2215 0.2024 0.1749 0.1468 0.1263 0.1217 0.1289 0.1319 0.1373 0.1373 0.1412 0.1447 0.1475 

[TRAIN] Epoch[5](568/1500); Loss: 0.116153; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1599 0.1246 0.1158 0.1186 0.1163 0.1120 0.1106 0.1081 0.1070 0.1083 0.1083 0.1103 0.1120 0.1139 0.1154 0.1174 

[TRAIN] Epoch[5](569/1500); Loss: 0.138753; Backpropagation: 0.0924 sec; Batch: 0.4238 sec
0.2022 0.1777 0.1578 0.1559 0.1551 0.1468 0.1391 0.1318 0.1256 0.1214 0.1184 0.1168 0.1167 0.1168 0.1183 0.1195 

[TRAIN] Epoch[5](570/1500); Loss: 0.166407; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2838 0.2276 0.2153 0.2244 0.2117 0.1944 0.1729 0.1506 0.1333 0.1219 0.1180 0.1207 0.1211 0.1214 0.1219 0.1234 

[TRAIN] Epoch[5](571/1500); Loss: 0.100044; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1613 0.1223 0.1086 0.1085 0.1042 0.0969 0.0921 0.0909 0.0903 0.0895 0.0888 0.0889 0.0890 0.0893 0.0895 0.0906 

[TRAIN] Epoch[5](572/1500); Loss: 0.081247; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1202 0.1087 0.0936 0.0880 0.0847 0.0789 0.0750 0.0729 0.0719 0.0719 0.0713 0.0714 0.0716 0.0724 0.0732 0.0742 

[TRAIN] Epoch[5](573/1500); Loss: 0.132932; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1716 0.1514 0.1441 0.1435 0.1408 0.1351 0.1325 0.1301 0.1261 0.1239 0.1230 0.1212 0.1207 0.1208 0.1209 0.1212 

[TRAIN] Epoch[5](574/1500); Loss: 0.097435; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1457 0.1156 0.1049 0.1046 0.1037 0.1003 0.0967 0.0932 0.0909 0.0888 0.0871 0.0857 0.0851 0.0850 0.0856 0.0860 

[TRAIN] Epoch[5](575/1500); Loss: 0.117738; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.1721 0.1345 0.1205 0.1213 0.1220 0.1185 0.1150 0.1108 0.1079 0.1067 0.1061 0.1067 0.1076 0.1097 0.1112 0.1130 

[TRAIN] Epoch[5](576/1500); Loss: 0.076137; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.1095 0.0946 0.0827 0.0799 0.0773 0.0720 0.0706 0.0694 0.0683 0.0683 0.0692 0.0693 0.0701 0.0709 0.0721 0.0741 

[TRAIN] Epoch[5](577/1500); Loss: 0.097683; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1342 0.1190 0.1094 0.1060 0.1027 0.0973 0.0943 0.0917 0.0893 0.0881 0.0876 0.0871 0.0876 0.0884 0.0894 0.0909 

[TRAIN] Epoch[5](578/1500); Loss: 0.044891; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0549 0.0532 0.0461 0.0432 0.0414 0.0436 0.0414 0.0414 0.0417 0.0416 0.0422 0.0434 0.0442 0.0453 0.0467 0.0480 

[TRAIN] Epoch[5](579/1500); Loss: 0.077165; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0973 0.0870 0.0829 0.0785 0.0762 0.0758 0.0738 0.0726 0.0727 0.0725 0.0732 0.0735 0.0734 0.0745 0.0749 0.0758 

[TRAIN] Epoch[5](580/1500); Loss: 0.142436; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2911 0.2081 0.1830 0.1973 0.1788 0.1520 0.1245 0.1043 0.0970 0.1030 0.1014 0.1034 0.1039 0.1087 0.1102 0.1123 

[TRAIN] Epoch[5](581/1500); Loss: 0.057521; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1347 0.0624 0.0562 0.0672 0.0602 0.0519 0.0617 0.0485 0.0468 0.0479 0.0460 0.0482 0.0460 0.0461 0.0490 0.0476 

[TRAIN] Epoch[5](582/1500); Loss: 0.090571; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1433 0.1267 0.1128 0.1037 0.0930 0.0866 0.0829 0.0789 0.0782 0.0757 0.0760 0.0746 0.0770 0.0770 0.0796 0.0834 

[TRAIN] Epoch[5](583/1500); Loss: 0.111707; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1462 0.1305 0.1223 0.1196 0.1171 0.1136 0.1106 0.1077 0.1059 0.1039 0.1027 0.1021 0.1013 0.1009 0.1013 0.1017 

[TRAIN] Epoch[5](584/1500); Loss: 0.142327; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2165 0.1763 0.1587 0.1621 0.1595 0.1494 0.1384 0.1307 0.1279 0.1247 0.1232 0.1221 0.1216 0.1216 0.1218 0.1227 

[TRAIN] Epoch[5](585/1500); Loss: 0.082403; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1229 0.0989 0.0910 0.0891 0.0871 0.0836 0.0804 0.0765 0.0734 0.0718 0.0723 0.0717 0.0734 0.0744 0.0752 0.0768 

[TRAIN] Epoch[5](586/1500); Loss: 0.106522; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2517 0.1580 0.1423 0.1703 0.1514 0.1233 0.0933 0.0761 0.0750 0.0679 0.0672 0.0673 0.0657 0.0649 0.0643 0.0658 

[TRAIN] Epoch[5](587/1500); Loss: 0.148669; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.2271 0.1739 0.1583 0.1630 0.1640 0.1558 0.1473 0.1415 0.1364 0.1331 0.1307 0.1292 0.1289 0.1290 0.1297 0.1308 

[TRAIN] Epoch[5](588/1500); Loss: 0.085351; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1303 0.1066 0.0945 0.0946 0.0900 0.0857 0.0817 0.0803 0.0776 0.0754 0.0741 0.0733 0.0738 0.0745 0.0757 0.0774 

[TRAIN] Epoch[5](589/1500); Loss: 0.161312; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2091 0.1715 0.1639 0.1677 0.1736 0.1678 0.1622 0.1589 0.1565 0.1544 0.1524 0.1500 0.1489 0.1481 0.1480 0.1482 

[TRAIN] Epoch[5](590/1500); Loss: 0.161124; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2411 0.2020 0.1899 0.1950 0.1878 0.1769 0.1632 0.1496 0.1407 0.1357 0.1344 0.1333 0.1320 0.1323 0.1320 0.1321 

[TRAIN] Epoch[5](591/1500); Loss: 0.057060; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0671 0.0722 0.0619 0.0566 0.0575 0.0543 0.0541 0.0528 0.0539 0.0543 0.0534 0.0537 0.0547 0.0544 0.0559 0.0563 

[TRAIN] Epoch[5](592/1500); Loss: 0.105663; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1297 0.1091 0.1041 0.1043 0.1041 0.1006 0.1003 0.0996 0.1000 0.1010 0.1020 0.1038 0.1049 0.1074 0.1087 0.1111 

[TRAIN] Epoch[5](593/1500); Loss: 0.062442; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.0704 0.0778 0.0669 0.0607 0.0611 0.0617 0.0579 0.0567 0.0579 0.0583 0.0586 0.0597 0.0606 0.0617 0.0633 0.0657 

[TRAIN] Epoch[5](594/1500); Loss: 0.084113; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1645 0.1259 0.1111 0.1134 0.1020 0.0877 0.0701 0.0658 0.0640 0.0635 0.0629 0.0632 0.0627 0.0626 0.0629 0.0633 

[TRAIN] Epoch[5](595/1500); Loss: 0.160469; Backpropagation: 0.0919 sec; Batch: 0.4288 sec
0.2352 0.1893 0.1810 0.1839 0.1781 0.1685 0.1602 0.1516 0.1454 0.1439 0.1417 0.1392 0.1378 0.1372 0.1370 0.1375 

[TRAIN] Epoch[5](596/1500); Loss: 0.071198; Backpropagation: 0.0920 sec; Batch: 0.4251 sec
0.1301 0.0903 0.0763 0.0701 0.0699 0.0660 0.0635 0.0621 0.0621 0.0613 0.0618 0.0632 0.0632 0.0649 0.0668 0.0675 

[TRAIN] Epoch[5](597/1500); Loss: 0.063777; Backpropagation: 0.0919 sec; Batch: 0.4265 sec
0.1533 0.0939 0.0744 0.0777 0.0702 0.0602 0.0585 0.0518 0.0517 0.0517 0.0496 0.0466 0.0459 0.0453 0.0449 0.0449 

[TRAIN] Epoch[5](598/1500); Loss: 0.067812; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0810 0.0798 0.0729 0.0706 0.0671 0.0664 0.0656 0.0651 0.0645 0.0642 0.0643 0.0642 0.0643 0.0644 0.0651 0.0656 

[TRAIN] Epoch[5](599/1500); Loss: 0.090208; Backpropagation: 0.0923 sec; Batch: 0.4236 sec
0.1222 0.1094 0.1001 0.0980 0.0980 0.0930 0.0894 0.0870 0.0849 0.0826 0.0814 0.0801 0.0795 0.0794 0.0791 0.0793 

[TRAIN] Epoch[5](600/1500); Loss: 0.155315; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2014 0.1823 0.1738 0.1674 0.1622 0.1571 0.1525 0.1487 0.1463 0.1436 0.1423 0.1414 0.1410 0.1411 0.1416 0.1422 

[TRAIN] Epoch[5](601/1500); Loss: 0.072667; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1321 0.0992 0.0838 0.0774 0.0705 0.0656 0.0636 0.0640 0.0628 0.0623 0.0624 0.0626 0.0629 0.0638 0.0644 0.0654 

[TRAIN] Epoch[5](602/1500); Loss: 0.049869; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1425 0.0547 0.0472 0.0511 0.0498 0.0497 0.0387 0.0385 0.0402 0.0371 0.0402 0.0386 0.0395 0.0423 0.0427 0.0449 

[TRAIN] Epoch[5](603/1500); Loss: 0.111274; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1308 0.1235 0.1190 0.1124 0.1112 0.1108 0.1086 0.1079 0.1075 0.1069 0.1064 0.1066 0.1064 0.1071 0.1073 0.1082 

[TRAIN] Epoch[5](604/1500); Loss: 0.046981; Backpropagation: 0.0917 sec; Batch: 0.4243 sec
0.0722 0.0572 0.0540 0.0474 0.0450 0.0447 0.0436 0.0424 0.0420 0.0423 0.0423 0.0425 0.0429 0.0437 0.0442 0.0451 

[TRAIN] Epoch[5](605/1500); Loss: 0.083982; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1533 0.1225 0.1064 0.0987 0.0919 0.0809 0.0747 0.0708 0.0674 0.0652 0.0647 0.0646 0.0667 0.0684 0.0726 0.0749 

[TRAIN] Epoch[5](606/1500); Loss: 0.117757; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2530 0.1817 0.1623 0.1592 0.1427 0.1219 0.1015 0.0906 0.0861 0.0845 0.0835 0.0843 0.0829 0.0829 0.0835 0.0835 

[TRAIN] Epoch[5](607/1500); Loss: 0.077580; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1341 0.0890 0.0810 0.0826 0.0815 0.0772 0.0724 0.0695 0.0695 0.0689 0.0684 0.0686 0.0687 0.0694 0.0699 0.0707 

[TRAIN] Epoch[5](608/1500); Loss: 0.051716; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1321 0.0556 0.0520 0.0512 0.0540 0.0559 0.0464 0.0421 0.0453 0.0427 0.0400 0.0419 0.0407 0.0415 0.0426 0.0433 

[TRAIN] Epoch[5](609/1500); Loss: 0.125056; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2249 0.1671 0.1451 0.1484 0.1471 0.1359 0.1267 0.1167 0.1086 0.1024 0.0978 0.0957 0.0952 0.0951 0.0969 0.0973 

[TRAIN] Epoch[5](610/1500); Loss: 0.171347; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.3100 0.2261 0.2053 0.2178 0.2236 0.2121 0.1967 0.1797 0.1643 0.1491 0.1345 0.1215 0.1102 0.1018 0.0959 0.0930 

[TRAIN] Epoch[5](611/1500); Loss: 0.134627; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2234 0.1623 0.1494 0.1578 0.1613 0.1509 0.1416 0.1318 0.1225 0.1155 0.1100 0.1069 0.1052 0.1049 0.1051 0.1054 

[TRAIN] Epoch[5](612/1500); Loss: 0.121890; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1477 0.1360 0.1292 0.1265 0.1235 0.1175 0.1149 0.1141 0.1126 0.1135 0.1132 0.1152 0.1173 0.1191 0.1232 0.1266 

[TRAIN] Epoch[5](613/1500); Loss: 0.047759; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1310 0.0816 0.0643 0.0561 0.0490 0.0440 0.0385 0.0335 0.0330 0.0329 0.0313 0.0324 0.0331 0.0327 0.0346 0.0361 

[TRAIN] Epoch[5](614/1500); Loss: 0.174720; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2080 0.1894 0.1839 0.1819 0.1824 0.1771 0.1716 0.1698 0.1683 0.1665 0.1657 0.1652 0.1655 0.1662 0.1668 0.1672 

[TRAIN] Epoch[5](615/1500); Loss: 0.099560; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1275 0.1093 0.1047 0.1034 0.1004 0.0976 0.0964 0.0949 0.0945 0.0934 0.0941 0.0937 0.0945 0.0951 0.0964 0.0971 

[TRAIN] Epoch[5](616/1500); Loss: 0.124808; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1474 0.1406 0.1361 0.1339 0.1300 0.1259 0.1232 0.1209 0.1195 0.1182 0.1178 0.1167 0.1166 0.1162 0.1168 0.1171 

[TRAIN] Epoch[5](617/1500); Loss: 0.057202; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1463 0.0831 0.0691 0.0686 0.0648 0.0588 0.0523 0.0491 0.0441 0.0420 0.0394 0.0388 0.0385 0.0390 0.0401 0.0413 

[TRAIN] Epoch[5](618/1500); Loss: 0.063684; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0897 0.0892 0.0806 0.0689 0.0631 0.0607 0.0595 0.0569 0.0560 0.0559 0.0549 0.0557 0.0554 0.0573 0.0562 0.0591 

[TRAIN] Epoch[5](619/1500); Loss: 0.114858; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2136 0.1504 0.1334 0.1350 0.1287 0.1141 0.1041 0.1020 0.0974 0.0948 0.0947 0.0937 0.0938 0.0937 0.0941 0.0941 

[TRAIN] Epoch[5](620/1500); Loss: 0.123727; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1943 0.1540 0.1424 0.1432 0.1410 0.1330 0.1273 0.1206 0.1148 0.1098 0.1059 0.1028 0.1002 0.0982 0.0967 0.0952 

[TRAIN] Epoch[5](621/1500); Loss: 0.121867; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1821 0.1422 0.1324 0.1356 0.1371 0.1295 0.1234 0.1171 0.1122 0.1086 0.1059 0.1047 0.1039 0.1045 0.1049 0.1058 

[TRAIN] Epoch[5](622/1500); Loss: 0.101651; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1451 0.1199 0.1073 0.1063 0.1072 0.1010 0.0933 0.0916 0.0917 0.0908 0.0906 0.0919 0.0934 0.0963 0.0985 0.1013 

[TRAIN] Epoch[5](623/1500); Loss: 0.155477; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1642 0.1639 0.1630 0.1593 0.1560 0.1539 0.1537 0.1529 0.1521 0.1522 0.1519 0.1520 0.1527 0.1527 0.1531 0.1538 

[TRAIN] Epoch[5](624/1500); Loss: 0.068296; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1383 0.0804 0.0690 0.0632 0.0634 0.0624 0.0600 0.0609 0.0603 0.0603 0.0612 0.0609 0.0618 0.0630 0.0634 0.0642 

[TRAIN] Epoch[5](625/1500); Loss: 0.140664; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2866 0.2084 0.1914 0.2032 0.1877 0.1641 0.1364 0.1107 0.0986 0.0990 0.0948 0.0950 0.0939 0.0950 0.0938 0.0921 

[TRAIN] Epoch[5](626/1500); Loss: 0.109810; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1789 0.1341 0.1222 0.1248 0.1220 0.1115 0.1014 0.0956 0.0951 0.0947 0.0935 0.0945 0.0954 0.0964 0.0975 0.0994 

[TRAIN] Epoch[5](627/1500); Loss: 0.139939; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1873 0.1646 0.1554 0.1496 0.1422 0.1368 0.1335 0.1313 0.1297 0.1290 0.1285 0.1283 0.1292 0.1299 0.1315 0.1323 

[TRAIN] Epoch[5](628/1500); Loss: 0.132249; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1931 0.1588 0.1481 0.1448 0.1399 0.1335 0.1285 0.1248 0.1220 0.1198 0.1182 0.1176 0.1172 0.1166 0.1164 0.1167 

[TRAIN] Epoch[5](629/1500); Loss: 0.098701; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2327 0.1589 0.1310 0.1291 0.1125 0.0902 0.0893 0.0780 0.0790 0.0710 0.0696 0.0682 0.0679 0.0663 0.0668 0.0686 

[TRAIN] Epoch[5](630/1500); Loss: 0.131985; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1957 0.1609 0.1455 0.1439 0.1417 0.1346 0.1287 0.1245 0.1214 0.1185 0.1171 0.1165 0.1160 0.1160 0.1153 0.1154 

[TRAIN] Epoch[5](631/1500); Loss: 0.072215; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0771 0.0886 0.0761 0.0691 0.0733 0.0693 0.0676 0.0681 0.0691 0.0687 0.0693 0.0693 0.0711 0.0712 0.0734 0.0741 

[TRAIN] Epoch[5](632/1500); Loss: 0.067569; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1259 0.0810 0.0704 0.0669 0.0641 0.0623 0.0605 0.0602 0.0599 0.0596 0.0601 0.0606 0.0614 0.0617 0.0626 0.0637 

[TRAIN] Epoch[5](633/1500); Loss: 0.071307; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0896 0.0921 0.0845 0.0741 0.0712 0.0706 0.0683 0.0666 0.0659 0.0656 0.0651 0.0650 0.0654 0.0651 0.0654 0.0662 

[TRAIN] Epoch[5](634/1500); Loss: 0.075783; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0838 0.0941 0.0889 0.0745 0.0742 0.0738 0.0718 0.0712 0.0715 0.0715 0.0717 0.0722 0.0724 0.0731 0.0737 0.0741 

[TRAIN] Epoch[5](635/1500); Loss: 0.052835; Backpropagation: 0.0925 sec; Batch: 0.4246 sec
0.0740 0.0633 0.0567 0.0550 0.0576 0.0509 0.0481 0.0477 0.0485 0.0476 0.0482 0.0484 0.0484 0.0494 0.0502 0.0513 

[TRAIN] Epoch[5](636/1500); Loss: 0.140768; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2110 0.1707 0.1585 0.1605 0.1606 0.1527 0.1460 0.1390 0.1335 0.1283 0.1231 0.1182 0.1155 0.1124 0.1112 0.1109 

[TRAIN] Epoch[5](637/1500); Loss: 0.114065; Backpropagation: 0.0921 sec; Batch: 0.4249 sec
0.1542 0.1407 0.1283 0.1248 0.1218 0.1133 0.1078 0.1056 0.1055 0.1044 0.1031 0.1027 0.1025 0.1028 0.1035 0.1042 

[TRAIN] Epoch[5](638/1500); Loss: 0.096199; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1095 0.1030 0.0984 0.0939 0.0923 0.0929 0.0933 0.0932 0.0940 0.0940 0.0944 0.0952 0.0955 0.0958 0.0967 0.0972 

[TRAIN] Epoch[5](639/1500); Loss: 0.052018; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.0771 0.0608 0.0543 0.0539 0.0560 0.0489 0.0470 0.0467 0.0476 0.0469 0.0475 0.0478 0.0479 0.0486 0.0504 0.0507 

[TRAIN] Epoch[5](640/1500); Loss: 0.138253; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3087 0.2030 0.1654 0.1824 0.1920 0.1771 0.1558 0.1338 0.1152 0.1003 0.0888 0.0815 0.0767 0.0761 0.0761 0.0790 

[TRAIN] Epoch[5](641/1500); Loss: 0.066406; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0788 0.0811 0.0751 0.0695 0.0669 0.0649 0.0618 0.0613 0.0616 0.0614 0.0619 0.0627 0.0629 0.0636 0.0645 0.0645 

[TRAIN] Epoch[5](642/1500); Loss: 0.066827; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.0996 0.0836 0.0770 0.0706 0.0681 0.0662 0.0629 0.0607 0.0610 0.0596 0.0592 0.0598 0.0591 0.0605 0.0607 0.0607 

[TRAIN] Epoch[5](643/1500); Loss: 0.125190; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2539 0.1882 0.1707 0.1771 0.1604 0.1404 0.1177 0.0977 0.0894 0.0891 0.0863 0.0872 0.0861 0.0858 0.0868 0.0863 

[TRAIN] Epoch[5](644/1500); Loss: 0.076294; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0899 0.0956 0.0877 0.0788 0.0769 0.0762 0.0744 0.0729 0.0723 0.0713 0.0708 0.0706 0.0702 0.0706 0.0707 0.0717 

[TRAIN] Epoch[5](645/1500); Loss: 0.138932; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2160 0.1805 0.1644 0.1577 0.1482 0.1374 0.1294 0.1238 0.1223 0.1215 0.1206 0.1198 0.1199 0.1201 0.1206 0.1208 

[TRAIN] Epoch[5](646/1500); Loss: 0.117784; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2180 0.1537 0.1338 0.1361 0.1318 0.1197 0.1114 0.1064 0.1011 0.0997 0.0974 0.0967 0.0952 0.0950 0.0943 0.0942 

[TRAIN] Epoch[5](647/1500); Loss: 0.042405; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0776 0.0597 0.0546 0.0452 0.0438 0.0429 0.0379 0.0359 0.0364 0.0348 0.0340 0.0344 0.0349 0.0345 0.0359 0.0359 

[TRAIN] Epoch[5](648/1500); Loss: 0.068076; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1196 0.0891 0.0767 0.0763 0.0747 0.0688 0.0640 0.0599 0.0582 0.0576 0.0564 0.0576 0.0566 0.0573 0.0576 0.0589 

[TRAIN] Epoch[5](649/1500); Loss: 0.120671; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1882 0.1536 0.1403 0.1381 0.1298 0.1213 0.1126 0.1108 0.1085 0.1063 0.1046 0.1039 0.1035 0.1024 0.1028 0.1040 

[TRAIN] Epoch[5](650/1500); Loss: 0.131542; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2417 0.1777 0.1506 0.1548 0.1474 0.1310 0.1187 0.1155 0.1100 0.1092 0.1073 0.1065 0.1078 0.1073 0.1086 0.1106 

[TRAIN] Epoch[5](651/1500); Loss: 0.128759; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1977 0.1665 0.1478 0.1459 0.1412 0.1317 0.1252 0.1185 0.1139 0.1112 0.1088 0.1079 0.1087 0.1092 0.1117 0.1142 

[TRAIN] Epoch[5](652/1500); Loss: 0.154936; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.4064 0.2871 0.2546 0.2745 0.2408 0.1941 0.1339 0.0805 0.0760 0.0727 0.0772 0.0842 0.0727 0.0757 0.0767 0.0718 

[TRAIN] Epoch[5](653/1500); Loss: 0.097801; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1345 0.1218 0.1100 0.1022 0.0956 0.0933 0.0917 0.0910 0.0900 0.0889 0.0887 0.0890 0.0898 0.0912 0.0924 0.0949 

[TRAIN] Epoch[5](654/1500); Loss: 0.112453; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1504 0.1392 0.1256 0.1213 0.1186 0.1137 0.1092 0.1063 0.1055 0.1038 0.1025 0.1018 0.1011 0.1010 0.0999 0.0992 

[TRAIN] Epoch[5](655/1500); Loss: 0.084450; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1212 0.1038 0.0897 0.0870 0.0844 0.0824 0.0809 0.0792 0.0782 0.0776 0.0768 0.0776 0.0775 0.0782 0.0785 0.0783 

[TRAIN] Epoch[5](656/1500); Loss: 0.050622; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0558 0.0713 0.0640 0.0488 0.0485 0.0481 0.0464 0.0463 0.0470 0.0462 0.0467 0.0474 0.0471 0.0482 0.0489 0.0494 

[TRAIN] Epoch[5](657/1500); Loss: 0.212872; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2502 0.2338 0.2244 0.2209 0.2177 0.2105 0.2065 0.2046 0.2030 0.2030 0.2030 0.2036 0.2045 0.2055 0.2068 0.2080 

[TRAIN] Epoch[5](658/1500); Loss: 0.162939; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1924 0.1783 0.1706 0.1680 0.1644 0.1589 0.1561 0.1550 0.1546 0.1545 0.1550 0.1564 0.1574 0.1596 0.1620 0.1640 

[TRAIN] Epoch[5](659/1500); Loss: 0.219991; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2939 0.2561 0.2436 0.2453 0.2366 0.2238 0.2125 0.2039 0.1990 0.1972 0.1966 0.1974 0.2004 0.2031 0.2041 0.2065 

[TRAIN] Epoch[5](660/1500); Loss: 0.155636; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2060 0.1815 0.1692 0.1669 0.1625 0.1561 0.1507 0.1482 0.1471 0.1454 0.1442 0.1427 0.1426 0.1422 0.1425 0.1422 

[TRAIN] Epoch[5](661/1500); Loss: 0.087469; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1139 0.1014 0.0954 0.0911 0.0885 0.0853 0.0833 0.0818 0.0810 0.0808 0.0809 0.0814 0.0822 0.0829 0.0840 0.0857 

[TRAIN] Epoch[5](662/1500); Loss: 0.105813; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1288 0.1241 0.1175 0.1122 0.1091 0.1062 0.1038 0.1020 0.1006 0.0999 0.0983 0.0986 0.0979 0.0980 0.0978 0.0982 

[TRAIN] Epoch[5](663/1500); Loss: 0.076585; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1115 0.0997 0.0864 0.0803 0.0788 0.0747 0.0725 0.0711 0.0685 0.0681 0.0681 0.0680 0.0685 0.0692 0.0694 0.0703 

[TRAIN] Epoch[5](664/1500); Loss: 0.057018; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0813 0.0796 0.0662 0.0556 0.0529 0.0535 0.0521 0.0507 0.0512 0.0515 0.0511 0.0525 0.0521 0.0538 0.0529 0.0554 

[TRAIN] Epoch[5](665/1500); Loss: 0.107241; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1824 0.1274 0.1135 0.1157 0.1082 0.1002 0.0974 0.0974 0.0956 0.0953 0.0958 0.0958 0.0971 0.0970 0.0985 0.0986 

[TRAIN] Epoch[5](666/1500); Loss: 0.084679; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1161 0.1021 0.0920 0.0852 0.0836 0.0823 0.0791 0.0792 0.0781 0.0776 0.0781 0.0793 0.0794 0.0797 0.0814 0.0819 

[TRAIN] Epoch[5](667/1500); Loss: 0.095701; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1327 0.1097 0.1017 0.0992 0.0973 0.0955 0.0929 0.0909 0.0906 0.0895 0.0889 0.0889 0.0885 0.0881 0.0884 0.0883 

[TRAIN] Epoch[5](668/1500); Loss: 0.076889; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1291 0.1009 0.0852 0.0797 0.0735 0.0698 0.0691 0.0684 0.0678 0.0680 0.0685 0.0685 0.0691 0.0703 0.0705 0.0718 

[TRAIN] Epoch[5](669/1500); Loss: 0.116127; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1645 0.1313 0.1250 0.1239 0.1217 0.1165 0.1133 0.1114 0.1087 0.1071 0.1061 0.1052 0.1052 0.1053 0.1064 0.1065 

[TRAIN] Epoch[5](670/1500); Loss: 0.089044; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1829 0.1112 0.0947 0.1029 0.1060 0.0943 0.0846 0.0755 0.0709 0.0689 0.0685 0.0701 0.0709 0.0723 0.0747 0.0760 

[TRAIN] Epoch[5](671/1500); Loss: 0.044512; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0623 0.0555 0.0470 0.0441 0.0420 0.0431 0.0409 0.0402 0.0408 0.0403 0.0399 0.0418 0.0423 0.0424 0.0441 0.0454 

[TRAIN] Epoch[5](672/1500); Loss: 0.110873; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1509 0.1332 0.1227 0.1165 0.1119 0.1080 0.1043 0.1015 0.1003 0.1005 0.1007 0.1022 0.1026 0.1049 0.1057 0.1080 

[TRAIN] Epoch[5](673/1500); Loss: 0.217680; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.3604 0.2876 0.2646 0.2747 0.2570 0.2305 0.1976 0.1769 0.1772 0.1733 0.1760 0.1807 0.1795 0.1808 0.1814 0.1847 

[TRAIN] Epoch[5](674/1500); Loss: 0.149660; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1955 0.1680 0.1585 0.1586 0.1576 0.1532 0.1488 0.1446 0.1415 0.1393 0.1377 0.1371 0.1378 0.1389 0.1386 0.1387 

[TRAIN] Epoch[5](675/1500); Loss: 0.078481; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1069 0.0936 0.0880 0.0810 0.0798 0.0784 0.0746 0.0730 0.0724 0.0717 0.0719 0.0722 0.0725 0.0729 0.0731 0.0737 

[TRAIN] Epoch[5](676/1500); Loss: 0.136079; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2087 0.1656 0.1523 0.1521 0.1423 0.1322 0.1252 0.1235 0.1215 0.1208 0.1203 0.1209 0.1215 0.1225 0.1234 0.1246 

[TRAIN] Epoch[5](677/1500); Loss: 0.108883; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1472 0.1219 0.1141 0.1109 0.1072 0.1037 0.1021 0.1022 0.1028 0.1023 0.1032 0.1036 0.1046 0.1048 0.1058 0.1058 

[TRAIN] Epoch[5](678/1500); Loss: 0.095468; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1414 0.1108 0.1056 0.1048 0.0998 0.0944 0.0902 0.0875 0.0855 0.0872 0.0868 0.0856 0.0866 0.0872 0.0864 0.0877 

[TRAIN] Epoch[5](679/1500); Loss: 0.082320; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1029 0.0903 0.0835 0.0812 0.0817 0.0802 0.0780 0.0773 0.0786 0.0781 0.0795 0.0793 0.0800 0.0811 0.0824 0.0829 

[TRAIN] Epoch[5](680/1500); Loss: 0.117240; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1849 0.1345 0.1232 0.1230 0.1170 0.1114 0.1095 0.1085 0.1076 0.1073 0.1076 0.1074 0.1078 0.1083 0.1086 0.1094 

[TRAIN] Epoch[5](681/1500); Loss: 0.113477; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1655 0.1428 0.1292 0.1206 0.1160 0.1083 0.1038 0.1006 0.0987 0.0982 0.0988 0.1005 0.1027 0.1061 0.1096 0.1142 

[TRAIN] Epoch[5](682/1500); Loss: 0.126673; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1449 0.1412 0.1337 0.1274 0.1237 0.1217 0.1210 0.1210 0.1210 0.1211 0.1224 0.1228 0.1241 0.1259 0.1267 0.1282 

[TRAIN] Epoch[5](683/1500); Loss: 0.141513; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1790 0.1580 0.1498 0.1481 0.1454 0.1393 0.1365 0.1348 0.1343 0.1345 0.1336 0.1335 0.1339 0.1342 0.1341 0.1352 

[TRAIN] Epoch[5](684/1500); Loss: 0.152322; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1670 0.1573 0.1522 0.1506 0.1483 0.1478 0.1484 0.1483 0.1490 0.1501 0.1508 0.1514 0.1527 0.1536 0.1545 0.1552 

[TRAIN] Epoch[5](685/1500); Loss: 0.135942; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2580 0.1783 0.1588 0.1688 0.1648 0.1495 0.1354 0.1234 0.1148 0.1081 0.1039 0.1017 0.1014 0.1020 0.1033 0.1028 

[TRAIN] Epoch[5](686/1500); Loss: 0.163529; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2085 0.1881 0.1780 0.1748 0.1716 0.1657 0.1618 0.1582 0.1546 0.1520 0.1503 0.1496 0.1495 0.1502 0.1511 0.1524 

[TRAIN] Epoch[5](687/1500); Loss: 0.092439; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1387 0.1052 0.0981 0.0988 0.0926 0.0877 0.0858 0.0849 0.0843 0.0841 0.0850 0.0847 0.0863 0.0861 0.0884 0.0885 

[TRAIN] Epoch[5](688/1500); Loss: 0.062849; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1165 0.0644 0.0589 0.0613 0.0613 0.0592 0.0575 0.0571 0.0570 0.0571 0.0581 0.0580 0.0582 0.0594 0.0601 0.0611 

[TRAIN] Epoch[5](689/1500); Loss: 0.092792; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1717 0.1141 0.0984 0.1006 0.1004 0.0909 0.0859 0.0818 0.0805 0.0787 0.0794 0.0791 0.0799 0.0804 0.0809 0.0819 

[TRAIN] Epoch[5](690/1500); Loss: 0.115505; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.2964 0.1849 0.1424 0.1577 0.1634 0.1436 0.1186 0.0950 0.0782 0.0685 0.0641 0.0633 0.0651 0.0692 0.0664 0.0711 

[TRAIN] Epoch[5](691/1500); Loss: 0.148900; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1904 0.1678 0.1614 0.1615 0.1591 0.1523 0.1481 0.1444 0.1411 0.1391 0.1379 0.1368 0.1358 0.1354 0.1355 0.1359 

[TRAIN] Epoch[5](692/1500); Loss: 0.127452; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2216 0.1412 0.1207 0.1322 0.1354 0.1232 0.1137 0.1110 0.1099 0.1097 0.1126 0.1148 0.1194 0.1195 0.1261 0.1282 

[TRAIN] Epoch[5](693/1500); Loss: 0.130599; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2350 0.1814 0.1591 0.1641 0.1606 0.1470 0.1339 0.1210 0.1094 0.1008 0.0955 0.0935 0.0940 0.0966 0.0982 0.0995 

[TRAIN] Epoch[5](694/1500); Loss: 0.125801; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2183 0.1600 0.1441 0.1505 0.1404 0.1250 0.1129 0.1139 0.1064 0.1073 0.1065 0.1043 0.1067 0.1047 0.1049 0.1069 

[TRAIN] Epoch[5](695/1500); Loss: 0.122511; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1820 0.1429 0.1335 0.1352 0.1314 0.1269 0.1206 0.1151 0.1125 0.1094 0.1089 0.1088 0.1085 0.1078 0.1084 0.1083 

[TRAIN] Epoch[5](696/1500); Loss: 0.095274; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1532 0.1229 0.1129 0.1082 0.1010 0.0942 0.0878 0.0834 0.0820 0.0821 0.0817 0.0819 0.0825 0.0827 0.0834 0.0845 

[TRAIN] Epoch[5](697/1500); Loss: 0.151984; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.2351 0.1929 0.1812 0.1838 0.1767 0.1656 0.1535 0.1409 0.1313 0.1258 0.1263 0.1238 0.1243 0.1237 0.1234 0.1236 

[TRAIN] Epoch[5](698/1500); Loss: 0.121279; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2148 0.1517 0.1327 0.1381 0.1362 0.1235 0.1129 0.1082 0.1042 0.1026 0.1019 0.1019 0.1014 0.1030 0.1026 0.1047 

[TRAIN] Epoch[5](699/1500); Loss: 0.171958; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.3759 0.2780 0.2582 0.2816 0.2562 0.2186 0.1678 0.1145 0.0959 0.1155 0.0962 0.0964 0.1004 0.0999 0.0971 0.0990 

[TRAIN] Epoch[5](700/1500); Loss: 0.059225; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1029 0.0581 0.0539 0.0569 0.0566 0.0557 0.0539 0.0545 0.0560 0.0547 0.0554 0.0569 0.0565 0.0577 0.0591 0.0586 

[TRAIN] Epoch[5](701/1500); Loss: 0.125024; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2268 0.1606 0.1438 0.1517 0.1517 0.1407 0.1285 0.1164 0.1078 0.1017 0.0970 0.0951 0.0938 0.0950 0.0946 0.0952 

[TRAIN] Epoch[5](702/1500); Loss: 0.163077; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2190 0.1943 0.1853 0.1840 0.1786 0.1705 0.1627 0.1558 0.1517 0.1481 0.1460 0.1439 0.1430 0.1424 0.1422 0.1418 

[TRAIN] Epoch[5](703/1500); Loss: 0.129485; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1866 0.1441 0.1373 0.1362 0.1328 0.1292 0.1261 0.1223 0.1206 0.1205 0.1196 0.1189 0.1191 0.1192 0.1193 0.1200 

[TRAIN] Epoch[5](704/1500); Loss: 0.098699; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2040 0.1251 0.1063 0.1157 0.1199 0.1081 0.0980 0.0890 0.0828 0.0779 0.0757 0.0740 0.0745 0.0745 0.0755 0.0781 

[TRAIN] Epoch[5](705/1500); Loss: 0.131706; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2355 0.1866 0.1605 0.1626 0.1611 0.1490 0.1363 0.1229 0.1117 0.1031 0.0970 0.0943 0.0945 0.0959 0.0976 0.0985 

[TRAIN] Epoch[5](706/1500); Loss: 0.072444; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0917 0.0807 0.0722 0.0700 0.0728 0.0698 0.0688 0.0680 0.0694 0.0689 0.0692 0.0705 0.0693 0.0712 0.0735 0.0731 

[TRAIN] Epoch[5](707/1500); Loss: 0.080470; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1555 0.1126 0.0933 0.0863 0.0760 0.0716 0.0707 0.0691 0.0685 0.0680 0.0687 0.0686 0.0683 0.0700 0.0702 0.0701 

[TRAIN] Epoch[5](708/1500); Loss: 0.092788; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1483 0.1137 0.1025 0.1017 0.0988 0.0931 0.0887 0.0849 0.0821 0.0812 0.0806 0.0798 0.0816 0.0809 0.0830 0.0838 

[TRAIN] Epoch[5](709/1500); Loss: 0.049324; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0459 0.0682 0.0539 0.0454 0.0442 0.0440 0.0441 0.0442 0.0449 0.0468 0.0468 0.0489 0.0511 0.0513 0.0535 0.0560 

[TRAIN] Epoch[5](710/1500); Loss: 0.115762; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2244 0.1309 0.1040 0.1162 0.1200 0.1088 0.0993 0.0970 0.0970 0.0994 0.1016 0.1029 0.1074 0.1103 0.1142 0.1189 

[TRAIN] Epoch[5](711/1500); Loss: 0.095741; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1350 0.1177 0.1009 0.0986 0.0959 0.0910 0.0904 0.0901 0.0890 0.0880 0.0880 0.0879 0.0885 0.0896 0.0903 0.0909 

[TRAIN] Epoch[5](712/1500); Loss: 0.145600; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1682 0.1562 0.1561 0.1523 0.1485 0.1459 0.1434 0.1411 0.1402 0.1396 0.1391 0.1393 0.1394 0.1398 0.1401 0.1404 

[TRAIN] Epoch[5](713/1500); Loss: 0.063665; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1049 0.0748 0.0678 0.0677 0.0654 0.0634 0.0609 0.0589 0.0573 0.0565 0.0561 0.0555 0.0561 0.0567 0.0575 0.0591 

[TRAIN] Epoch[5](714/1500); Loss: 0.112132; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1174 0.1157 0.1172 0.1141 0.1116 0.1108 0.1108 0.1100 0.1097 0.1099 0.1097 0.1103 0.1107 0.1111 0.1123 0.1129 

[TRAIN] Epoch[5](715/1500); Loss: 0.064178; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1976 0.1202 0.0983 0.0999 0.0816 0.0609 0.0433 0.0369 0.0357 0.0349 0.0353 0.0355 0.0349 0.0366 0.0376 0.0376 

[TRAIN] Epoch[5](716/1500); Loss: 0.093468; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1382 0.1103 0.0988 0.0989 0.0982 0.0929 0.0875 0.0853 0.0845 0.0842 0.0840 0.0855 0.0854 0.0866 0.0870 0.0881 

[TRAIN] Epoch[5](717/1500); Loss: 0.087233; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2664 0.1730 0.1460 0.1487 0.1215 0.0868 0.0569 0.0464 0.0467 0.0415 0.0438 0.0434 0.0419 0.0438 0.0442 0.0448 

[TRAIN] Epoch[5](718/1500); Loss: 0.160186; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2342 0.1816 0.1685 0.1707 0.1642 0.1565 0.1514 0.1489 0.1475 0.1476 0.1468 0.1471 0.1480 0.1489 0.1495 0.1513 

[TRAIN] Epoch[5](719/1500); Loss: 0.062339; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1030 0.0878 0.0708 0.0667 0.0614 0.0608 0.0571 0.0556 0.0545 0.0540 0.0534 0.0538 0.0536 0.0542 0.0553 0.0554 

[TRAIN] Epoch[5](720/1500); Loss: 0.076209; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1086 0.1094 0.0959 0.0879 0.0836 0.0753 0.0706 0.0679 0.0667 0.0645 0.0652 0.0632 0.0651 0.0643 0.0654 0.0658 

[TRAIN] Epoch[5](721/1500); Loss: 0.105978; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1862 0.1313 0.1098 0.1112 0.1112 0.1043 0.0980 0.0947 0.0923 0.0922 0.0906 0.0920 0.0923 0.0946 0.0962 0.0988 

[TRAIN] Epoch[5](722/1500); Loss: 0.116043; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1466 0.1371 0.1276 0.1215 0.1193 0.1166 0.1143 0.1124 0.1098 0.1087 0.1080 0.1070 0.1066 0.1067 0.1074 0.1072 

[TRAIN] Epoch[5](723/1500); Loss: 0.095344; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1179 0.1169 0.1085 0.1027 0.0985 0.0939 0.0909 0.0892 0.0873 0.0864 0.0866 0.0870 0.0875 0.0892 0.0906 0.0924 

[TRAIN] Epoch[5](724/1500); Loss: 0.087962; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2326 0.1475 0.1233 0.1214 0.0950 0.0680 0.0663 0.0584 0.0642 0.0610 0.0594 0.0613 0.0604 0.0621 0.0628 0.0636 

[TRAIN] Epoch[5](725/1500); Loss: 0.085095; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1805 0.1021 0.0828 0.0890 0.0928 0.0838 0.0769 0.0730 0.0707 0.0708 0.0706 0.0711 0.0738 0.0728 0.0751 0.0759 

[TRAIN] Epoch[5](726/1500); Loss: 0.107051; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1406 0.1194 0.1109 0.1105 0.1094 0.1060 0.1041 0.1025 0.1014 0.1010 0.1009 0.1006 0.1014 0.1014 0.1011 0.1014 

[TRAIN] Epoch[5](727/1500); Loss: 0.159396; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2574 0.1897 0.1733 0.1803 0.1729 0.1596 0.1480 0.1414 0.1388 0.1375 0.1381 0.1393 0.1409 0.1424 0.1441 0.1467 

[TRAIN] Epoch[5](728/1500); Loss: 0.087690; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1407 0.1065 0.0976 0.0892 0.0845 0.0834 0.0791 0.0783 0.0788 0.0782 0.0791 0.0794 0.0800 0.0816 0.0826 0.0842 

[TRAIN] Epoch[5](729/1500); Loss: 0.056713; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0842 0.0753 0.0676 0.0573 0.0569 0.0563 0.0528 0.0515 0.0509 0.0497 0.0501 0.0499 0.0500 0.0512 0.0513 0.0523 

[TRAIN] Epoch[5](730/1500); Loss: 0.107754; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1370 0.1169 0.1083 0.1117 0.1075 0.1039 0.1029 0.1016 0.1020 0.1020 0.1026 0.1037 0.1039 0.1057 0.1068 0.1077 

[TRAIN] Epoch[5](731/1500); Loss: 0.130929; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2633 0.1951 0.1611 0.1654 0.1623 0.1453 0.1291 0.1127 0.0994 0.0912 0.0881 0.0896 0.0925 0.0968 0.1008 0.1022 

[TRAIN] Epoch[5](732/1500); Loss: 0.079483; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1288 0.0992 0.0910 0.0852 0.0784 0.0746 0.0724 0.0710 0.0694 0.0699 0.0688 0.0709 0.0705 0.0727 0.0734 0.0755 

[TRAIN] Epoch[5](733/1500); Loss: 0.110525; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1680 0.1251 0.1165 0.1167 0.1148 0.1093 0.1058 0.1039 0.1018 0.1006 0.1004 0.1001 0.1007 0.1011 0.1012 0.1026 

[TRAIN] Epoch[5](734/1500); Loss: 0.069622; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1062 0.0755 0.0740 0.0683 0.0685 0.0679 0.0657 0.0660 0.0651 0.0648 0.0650 0.0647 0.0651 0.0656 0.0654 0.0663 

[TRAIN] Epoch[5](735/1500); Loss: 0.142109; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1948 0.1623 0.1518 0.1484 0.1440 0.1392 0.1355 0.1335 0.1329 0.1324 0.1323 0.1321 0.1329 0.1332 0.1337 0.1347 

[TRAIN] Epoch[5](736/1500); Loss: 0.080847; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1109 0.0974 0.0892 0.0842 0.0812 0.0784 0.0769 0.0760 0.0753 0.0748 0.0746 0.0746 0.0746 0.0746 0.0754 0.0754 

[TRAIN] Epoch[5](737/1500); Loss: 0.112057; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1538 0.1292 0.1197 0.1170 0.1138 0.1094 0.1075 0.1061 0.1048 0.1042 0.1043 0.1039 0.1042 0.1044 0.1049 0.1057 

[TRAIN] Epoch[5](738/1500); Loss: 0.071606; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1516 0.0896 0.0756 0.0831 0.0842 0.0727 0.0656 0.0613 0.0576 0.0566 0.0557 0.0566 0.0564 0.0580 0.0599 0.0613 

[TRAIN] Epoch[5](739/1500); Loss: 0.073967; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1033 0.0787 0.0703 0.0749 0.0697 0.0656 0.0668 0.0674 0.0660 0.0687 0.0715 0.0715 0.0746 0.0764 0.0764 0.0816 

[TRAIN] Epoch[5](740/1500); Loss: 0.054815; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0698 0.0657 0.0604 0.0529 0.0527 0.0509 0.0506 0.0517 0.0500 0.0517 0.0522 0.0516 0.0528 0.0547 0.0538 0.0555 

[TRAIN] Epoch[5](741/1500); Loss: 0.059306; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1011 0.0657 0.0693 0.0578 0.0546 0.0545 0.0517 0.0518 0.0510 0.0532 0.0520 0.0529 0.0557 0.0558 0.0579 0.0638 

[TRAIN] Epoch[5](742/1500); Loss: 0.142891; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1890 0.1657 0.1555 0.1533 0.1495 0.1442 0.1401 0.1368 0.1349 0.1336 0.1322 0.1310 0.1302 0.1302 0.1301 0.1301 

[TRAIN] Epoch[5](743/1500); Loss: 0.160198; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2717 0.2247 0.2098 0.2028 0.1883 0.1707 0.1517 0.1347 0.1288 0.1284 0.1268 0.1253 0.1246 0.1250 0.1246 0.1252 

[TRAIN] Epoch[5](744/1500); Loss: 0.076707; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1147 0.1000 0.0856 0.0794 0.0770 0.0753 0.0728 0.0700 0.0691 0.0694 0.0687 0.0683 0.0690 0.0686 0.0682 0.0712 

[TRAIN] Epoch[5](745/1500); Loss: 0.082506; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1279 0.0968 0.0867 0.0852 0.0830 0.0797 0.0757 0.0734 0.0728 0.0724 0.0742 0.0747 0.0771 0.0781 0.0812 0.0814 

[TRAIN] Epoch[5](746/1500); Loss: 0.102538; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2345 0.1468 0.1244 0.1194 0.1033 0.0928 0.0888 0.0825 0.0826 0.0820 0.0816 0.0804 0.0790 0.0809 0.0810 0.0805 

[TRAIN] Epoch[5](747/1500); Loss: 0.103388; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2591 0.1650 0.1425 0.1470 0.1327 0.1064 0.0820 0.0676 0.0689 0.0650 0.0671 0.0677 0.0686 0.0697 0.0719 0.0729 

[TRAIN] Epoch[5](748/1500); Loss: 0.082555; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1844 0.1059 0.0949 0.1073 0.1074 0.0887 0.0775 0.0700 0.0644 0.0604 0.0583 0.0574 0.0583 0.0615 0.0624 0.0622 

[TRAIN] Epoch[5](749/1500); Loss: 0.120783; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1520 0.1372 0.1303 0.1287 0.1275 0.1219 0.1190 0.1159 0.1149 0.1141 0.1125 0.1119 0.1118 0.1111 0.1119 0.1118 

[TRAIN] Epoch[5](750/1500); Loss: 0.084455; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1380 0.1020 0.0927 0.0908 0.0874 0.0825 0.0778 0.0755 0.0728 0.0737 0.0720 0.0753 0.0741 0.0782 0.0778 0.0805 

[TRAIN] Epoch[5](751/1500); Loss: 0.106863; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1320 0.1190 0.1139 0.1106 0.1079 0.1054 0.1025 0.1006 0.1004 0.1000 0.1006 0.1008 0.1024 0.1030 0.1045 0.1062 

[TRAIN] Epoch[5](752/1500); Loss: 0.081342; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1156 0.0953 0.0850 0.0842 0.0793 0.0769 0.0751 0.0760 0.0759 0.0740 0.0755 0.0758 0.0767 0.0773 0.0787 0.0799 

[TRAIN] Epoch[5](753/1500); Loss: 0.170745; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2320 0.1986 0.1848 0.1807 0.1713 0.1647 0.1619 0.1620 0.1602 0.1598 0.1600 0.1589 0.1586 0.1593 0.1594 0.1597 

[TRAIN] Epoch[5](754/1500); Loss: 0.110996; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1367 0.1220 0.1187 0.1155 0.1105 0.1091 0.1081 0.1069 0.1064 0.1055 0.1055 0.1055 0.1056 0.1063 0.1067 0.1071 

[TRAIN] Epoch[5](755/1500); Loss: 0.086689; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1141 0.0972 0.0950 0.0895 0.0855 0.0839 0.0827 0.0820 0.0814 0.0810 0.0814 0.0815 0.0821 0.0825 0.0831 0.0839 

[TRAIN] Epoch[5](756/1500); Loss: 0.111043; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1504 0.1320 0.1203 0.1178 0.1126 0.1120 0.1081 0.1056 0.1052 0.1028 0.1019 0.1025 0.1008 0.1004 0.1028 0.1016 

[TRAIN] Epoch[5](757/1500); Loss: 0.092253; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1288 0.1092 0.1006 0.0968 0.0940 0.0914 0.0883 0.0866 0.0854 0.0843 0.0846 0.0846 0.0845 0.0852 0.0853 0.0864 

[TRAIN] Epoch[5](758/1500); Loss: 0.053700; Backpropagation: 0.0930 sec; Batch: 0.4241 sec
0.0580 0.0679 0.0597 0.0516 0.0492 0.0485 0.0485 0.0481 0.0483 0.0498 0.0506 0.0520 0.0545 0.0548 0.0577 0.0600 

[TRAIN] Epoch[5](759/1500); Loss: 0.132816; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2159 0.1500 0.1432 0.1498 0.1471 0.1318 0.1240 0.1188 0.1167 0.1158 0.1164 0.1171 0.1182 0.1187 0.1212 0.1204 

[TRAIN] Epoch[5](760/1500); Loss: 0.096977; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1278 0.1100 0.1012 0.0967 0.0948 0.0933 0.0921 0.0920 0.0918 0.0917 0.0915 0.0927 0.0928 0.0937 0.0944 0.0951 

[TRAIN] Epoch[5](761/1500); Loss: 0.103360; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1453 0.1214 0.1153 0.1079 0.1013 0.0995 0.0986 0.0972 0.0964 0.0959 0.0957 0.0955 0.0956 0.0958 0.0961 0.0963 

[TRAIN] Epoch[5](762/1500); Loss: 0.137372; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1708 0.1541 0.1476 0.1414 0.1342 0.1334 0.1340 0.1320 0.1310 0.1312 0.1307 0.1307 0.1311 0.1315 0.1320 0.1322 

[TRAIN] Epoch[5](763/1500); Loss: 0.105286; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1736 0.1359 0.1234 0.1213 0.1174 0.1093 0.1034 0.0982 0.0939 0.0907 0.0874 0.0860 0.0852 0.0862 0.0859 0.0867 

[TRAIN] Epoch[5](764/1500); Loss: 0.122789; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1982 0.1553 0.1477 0.1433 0.1341 0.1214 0.1148 0.1104 0.1077 0.1060 0.1045 0.1044 0.1038 0.1045 0.1039 0.1047 

[TRAIN] Epoch[5](765/1500); Loss: 0.062854; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0836 0.0749 0.0661 0.0674 0.0634 0.0608 0.0589 0.0588 0.0586 0.0577 0.0586 0.0583 0.0583 0.0597 0.0604 0.0601 

[TRAIN] Epoch[5](766/1500); Loss: 0.088762; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1342 0.1105 0.1012 0.0910 0.0860 0.0823 0.0805 0.0796 0.0791 0.0781 0.0802 0.0802 0.0816 0.0829 0.0858 0.0869 

[TRAIN] Epoch[5](767/1500); Loss: 0.096951; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1871 0.1301 0.1099 0.0965 0.0892 0.0897 0.0868 0.0850 0.0846 0.0848 0.0838 0.0841 0.0846 0.0845 0.0850 0.0855 

[TRAIN] Epoch[5](768/1500); Loss: 0.132684; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2014 0.1572 0.1471 0.1481 0.1453 0.1331 0.1278 0.1242 0.1205 0.1175 0.1166 0.1161 0.1162 0.1163 0.1174 0.1182 

[TRAIN] Epoch[5](769/1500); Loss: 0.097444; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1224 0.1138 0.1061 0.1039 0.1009 0.0990 0.0963 0.0946 0.0936 0.0916 0.0904 0.0897 0.0888 0.0889 0.0895 0.0896 

[TRAIN] Epoch[5](770/1500); Loss: 0.133560; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2193 0.1694 0.1538 0.1441 0.1318 0.1276 0.1238 0.1226 0.1205 0.1191 0.1177 0.1176 0.1171 0.1173 0.1173 0.1178 

[TRAIN] Epoch[5](771/1500); Loss: 0.098336; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1277 0.1102 0.1073 0.1037 0.1018 0.0979 0.0957 0.0947 0.0934 0.0927 0.0925 0.0918 0.0912 0.0907 0.0908 0.0912 

[TRAIN] Epoch[5](772/1500); Loss: 0.121526; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2777 0.1727 0.1638 0.1812 0.1774 0.1419 0.1153 0.0974 0.0832 0.0738 0.0712 0.0732 0.0758 0.0806 0.0776 0.0816 

[TRAIN] Epoch[5](773/1500); Loss: 0.115159; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1957 0.1454 0.1339 0.1299 0.1290 0.1222 0.1158 0.1100 0.1048 0.1006 0.0971 0.0938 0.0923 0.0912 0.0900 0.0906 

[TRAIN] Epoch[5](774/1500); Loss: 0.061914; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.0941 0.0800 0.0699 0.0668 0.0634 0.0575 0.0550 0.0541 0.0552 0.0541 0.0545 0.0554 0.0557 0.0573 0.0582 0.0594 

[TRAIN] Epoch[5](775/1500); Loss: 0.086001; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1162 0.0983 0.0947 0.0900 0.0863 0.0853 0.0815 0.0801 0.0804 0.0789 0.0785 0.0801 0.0799 0.0803 0.0823 0.0831 

[TRAIN] Epoch[5](776/1500); Loss: 0.063375; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1784 0.1137 0.0799 0.0599 0.0534 0.0542 0.0481 0.0461 0.0463 0.0457 0.0457 0.0463 0.0486 0.0476 0.0488 0.0515 

[TRAIN] Epoch[5](777/1500); Loss: 0.082472; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1253 0.0946 0.0894 0.0835 0.0811 0.0798 0.0765 0.0758 0.0762 0.0761 0.0766 0.0757 0.0766 0.0771 0.0772 0.0780 

[TRAIN] Epoch[5](778/1500); Loss: 0.222334; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.3504 0.2940 0.2682 0.2538 0.2310 0.2064 0.1917 0.1873 0.1900 0.1908 0.1964 0.1952 0.1971 0.2001 0.2016 0.2034 

[TRAIN] Epoch[5](779/1500); Loss: 0.114698; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1450 0.1237 0.1206 0.1178 0.1142 0.1117 0.1103 0.1094 0.1094 0.1091 0.1093 0.1096 0.1101 0.1111 0.1115 0.1123 

[TRAIN] Epoch[5](780/1500); Loss: 0.115131; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1477 0.1334 0.1218 0.1154 0.1136 0.1106 0.1071 0.1062 0.1067 0.1067 0.1074 0.1086 0.1111 0.1130 0.1148 0.1180 

[TRAIN] Epoch[5](781/1500); Loss: 0.073086; Backpropagation: 0.0924 sec; Batch: 0.4245 sec
0.1175 0.0866 0.0786 0.0772 0.0737 0.0707 0.0677 0.0659 0.0661 0.0653 0.0652 0.0651 0.0662 0.0669 0.0676 0.0691 

[TRAIN] Epoch[5](782/1500); Loss: 0.054540; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1365 0.0783 0.0614 0.0569 0.0489 0.0512 0.0471 0.0439 0.0439 0.0430 0.0427 0.0427 0.0427 0.0439 0.0440 0.0456 

[TRAIN] Epoch[5](783/1500); Loss: 0.080621; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1281 0.0950 0.0844 0.0805 0.0798 0.0774 0.0766 0.0746 0.0747 0.0742 0.0738 0.0744 0.0739 0.0741 0.0744 0.0744 

[TRAIN] Epoch[5](784/1500); Loss: 0.110563; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1405 0.1253 0.1163 0.1171 0.1112 0.1076 0.1065 0.1058 0.1045 0.1043 0.1037 0.1043 0.1045 0.1049 0.1062 0.1064 

[TRAIN] Epoch[5](785/1500); Loss: 0.119070; Backpropagation: 0.0922 sec; Batch: 0.4232 sec
0.2634 0.1616 0.1556 0.1753 0.1711 0.1344 0.1104 0.0956 0.0848 0.0775 0.0757 0.0759 0.0782 0.0823 0.0786 0.0847 

[TRAIN] Epoch[5](786/1500); Loss: 0.124539; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1464 0.1322 0.1291 0.1291 0.1266 0.1228 0.1214 0.1198 0.1193 0.1197 0.1197 0.1196 0.1202 0.1208 0.1221 0.1237 

[TRAIN] Epoch[5](787/1500); Loss: 0.094860; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1622 0.1311 0.1216 0.1158 0.1059 0.0966 0.0872 0.0803 0.0774 0.0762 0.0755 0.0766 0.0768 0.0769 0.0787 0.0790 

[TRAIN] Epoch[5](788/1500); Loss: 0.205300; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3006 0.2582 0.2440 0.2399 0.2234 0.2040 0.1892 0.1799 0.1761 0.1763 0.1787 0.1805 0.1802 0.1825 0.1841 0.1873 

[TRAIN] Epoch[5](789/1500); Loss: 0.060446; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0910 0.0620 0.0590 0.0612 0.0601 0.0569 0.0558 0.0557 0.0575 0.0560 0.0568 0.0582 0.0575 0.0587 0.0606 0.0601 

[TRAIN] Epoch[5](790/1500); Loss: 0.100195; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1313 0.1069 0.1045 0.1059 0.1030 0.0982 0.0965 0.0955 0.0950 0.0946 0.0944 0.0953 0.0953 0.0952 0.0957 0.0959 

[TRAIN] Epoch[5](791/1500); Loss: 0.095051; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2347 0.1498 0.1353 0.1392 0.1307 0.1058 0.0858 0.0697 0.0591 0.0558 0.0566 0.0575 0.0590 0.0594 0.0603 0.0623 

[TRAIN] Epoch[5](792/1500); Loss: 0.098884; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1546 0.1213 0.1129 0.1118 0.1072 0.0999 0.0951 0.0911 0.0882 0.0873 0.0854 0.0858 0.0845 0.0856 0.0852 0.0864 

[TRAIN] Epoch[5](793/1500); Loss: 0.126750; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1664 0.1432 0.1403 0.1402 0.1331 0.1281 0.1247 0.1199 0.1167 0.1153 0.1150 0.1153 0.1169 0.1172 0.1173 0.1184 

[TRAIN] Epoch[5](794/1500); Loss: 0.110917; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1888 0.1195 0.1149 0.1239 0.1203 0.1041 0.0995 0.0987 0.0997 0.0971 0.0994 0.0987 0.1005 0.1012 0.1019 0.1066 

[TRAIN] Epoch[5](795/1500); Loss: 0.092316; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1227 0.1059 0.0974 0.0981 0.0930 0.0924 0.0897 0.0882 0.0873 0.0864 0.0852 0.0860 0.0865 0.0856 0.0865 0.0863 

[TRAIN] Epoch[5](796/1500); Loss: 0.085229; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1663 0.1139 0.1043 0.1050 0.0963 0.0842 0.0737 0.0699 0.0681 0.0680 0.0686 0.0683 0.0685 0.0686 0.0695 0.0706 

[TRAIN] Epoch[5](797/1500); Loss: 0.093481; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1804 0.1233 0.1097 0.1121 0.1094 0.0931 0.0828 0.0771 0.0749 0.0727 0.0740 0.0760 0.0749 0.0777 0.0770 0.0806 

[TRAIN] Epoch[5](798/1500); Loss: 0.132053; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1931 0.1626 0.1504 0.1442 0.1353 0.1286 0.1230 0.1164 0.1152 0.1140 0.1142 0.1174 0.1199 0.1219 0.1264 0.1302 

[TRAIN] Epoch[5](799/1500); Loss: 0.053494; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0902 0.0615 0.0549 0.0541 0.0515 0.0490 0.0482 0.0475 0.0470 0.0478 0.0480 0.0486 0.0503 0.0517 0.0516 0.0540 

[TRAIN] Epoch[5](800/1500); Loss: 0.108320; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1200 0.1226 0.1224 0.1144 0.1074 0.1070 0.1061 0.1032 0.1039 0.1027 0.1025 0.1029 0.1040 0.1035 0.1043 0.1062 

[TRAIN] Epoch[5](801/1500); Loss: 0.138732; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2156 0.1841 0.1748 0.1709 0.1601 0.1476 0.1330 0.1207 0.1133 0.1131 0.1138 0.1144 0.1134 0.1142 0.1151 0.1157 

[TRAIN] Epoch[5](802/1500); Loss: 0.152966; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1796 0.1641 0.1648 0.1642 0.1590 0.1554 0.1530 0.1501 0.1479 0.1460 0.1448 0.1443 0.1438 0.1435 0.1432 0.1437 

[TRAIN] Epoch[5](803/1500); Loss: 0.094690; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1084 0.1025 0.0965 0.0939 0.0926 0.0924 0.0918 0.0923 0.0925 0.0924 0.0926 0.0927 0.0931 0.0931 0.0937 0.0944 

[TRAIN] Epoch[5](804/1500); Loss: 0.057982; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1052 0.0862 0.0511 0.0639 0.0613 0.0512 0.0498 0.0508 0.0501 0.0493 0.0489 0.0528 0.0499 0.0519 0.0534 0.0520 

[TRAIN] Epoch[5](805/1500); Loss: 0.149850; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1842 0.1623 0.1565 0.1580 0.1564 0.1487 0.1453 0.1437 0.1429 0.1415 0.1421 0.1422 0.1423 0.1427 0.1443 0.1446 

[TRAIN] Epoch[5](806/1500); Loss: 0.119635; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.2237 0.1576 0.1422 0.1454 0.1370 0.1226 0.1108 0.1032 0.0992 0.0967 0.0960 0.0951 0.0956 0.0969 0.0956 0.0963 

[TRAIN] Epoch[5](807/1500); Loss: 0.050794; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0509 0.0600 0.0598 0.0543 0.0500 0.0460 0.0456 0.0462 0.0476 0.0463 0.0487 0.0498 0.0504 0.0503 0.0529 0.0541 

[TRAIN] Epoch[5](808/1500); Loss: 0.066347; Backpropagation: 0.0917 sec; Batch: 0.4268 sec
0.0805 0.0756 0.0828 0.0755 0.0648 0.0623 0.0601 0.0599 0.0610 0.0602 0.0606 0.0618 0.0620 0.0641 0.0644 0.0661 

[TRAIN] Epoch[5](809/1500); Loss: 0.126795; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2225 0.1745 0.1627 0.1601 0.1492 0.1352 0.1223 0.1120 0.1050 0.1014 0.0986 0.0970 0.0960 0.0971 0.0971 0.0983 

[TRAIN] Epoch[5](810/1500); Loss: 0.113144; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1503 0.1252 0.1203 0.1191 0.1130 0.1116 0.1097 0.1077 0.1069 0.1072 0.1065 0.1063 0.1064 0.1066 0.1064 0.1069 

[TRAIN] Epoch[5](811/1500); Loss: 0.056811; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0698 0.0746 0.0725 0.0609 0.0576 0.0543 0.0523 0.0513 0.0495 0.0504 0.0514 0.0506 0.0530 0.0529 0.0532 0.0545 

[TRAIN] Epoch[5](812/1500); Loss: 0.119114; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2390 0.1596 0.1497 0.1585 0.1528 0.1292 0.1113 0.0969 0.0873 0.0842 0.0847 0.0870 0.0907 0.0894 0.0933 0.0922 

[TRAIN] Epoch[5](813/1500); Loss: 0.093398; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1077 0.0973 0.0950 0.0938 0.0928 0.0899 0.0888 0.0895 0.0892 0.0895 0.0904 0.0910 0.0923 0.0943 0.0956 0.0972 

[TRAIN] Epoch[5](814/1500); Loss: 0.105055; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1390 0.1113 0.1070 0.1151 0.1098 0.1013 0.1000 0.1004 0.1001 0.0982 0.0987 0.0993 0.0993 0.0994 0.1005 0.1014 

[TRAIN] Epoch[5](815/1500); Loss: 0.066616; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1542 0.0846 0.0747 0.0838 0.0810 0.0624 0.0535 0.0520 0.0509 0.0483 0.0515 0.0493 0.0526 0.0532 0.0557 0.0580 

[TRAIN] Epoch[5](816/1500); Loss: 0.164792; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2164 0.1880 0.1841 0.1834 0.1768 0.1685 0.1622 0.1575 0.1547 0.1522 0.1508 0.1492 0.1486 0.1482 0.1481 0.1480 

[TRAIN] Epoch[5](817/1500); Loss: 0.077915; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1140 0.0779 0.0739 0.0777 0.0738 0.0726 0.0710 0.0713 0.0710 0.0713 0.0738 0.0746 0.0770 0.0785 0.0826 0.0857 

[TRAIN] Epoch[5](818/1500); Loss: 0.067907; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0962 0.0856 0.0778 0.0717 0.0687 0.0672 0.0641 0.0625 0.0612 0.0610 0.0608 0.0608 0.0615 0.0621 0.0624 0.0630 

[TRAIN] Epoch[5](819/1500); Loss: 0.079018; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1660 0.1107 0.0899 0.0916 0.0875 0.0736 0.0659 0.0630 0.0643 0.0613 0.0626 0.0643 0.0635 0.0650 0.0674 0.0678 

[TRAIN] Epoch[5](820/1500); Loss: 0.063251; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1120 0.0898 0.0708 0.0653 0.0605 0.0601 0.0556 0.0540 0.0538 0.0537 0.0528 0.0545 0.0550 0.0565 0.0585 0.0590 

[TRAIN] Epoch[5](821/1500); Loss: 0.063235; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0931 0.0761 0.0688 0.0672 0.0653 0.0615 0.0584 0.0566 0.0575 0.0558 0.0561 0.0579 0.0576 0.0579 0.0611 0.0609 

[TRAIN] Epoch[5](822/1500); Loss: 0.042507; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0886 0.0643 0.0403 0.0448 0.0409 0.0364 0.0345 0.0345 0.0361 0.0344 0.0354 0.0377 0.0360 0.0377 0.0398 0.0386 

[TRAIN] Epoch[5](823/1500); Loss: 0.124214; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1720 0.1439 0.1386 0.1365 0.1306 0.1246 0.1197 0.1173 0.1159 0.1143 0.1137 0.1129 0.1120 0.1118 0.1117 0.1119 

[TRAIN] Epoch[5](824/1500); Loss: 0.133944; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1549 0.1380 0.1318 0.1298 0.1287 0.1286 0.1293 0.1295 0.1306 0.1316 0.1314 0.1335 0.1343 0.1352 0.1370 0.1387 

[TRAIN] Epoch[5](825/1500); Loss: 0.091371; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1756 0.0851 0.0831 0.0989 0.0966 0.0761 0.0715 0.0715 0.0767 0.0766 0.0817 0.0852 0.0900 0.0925 0.0986 0.1022 

[TRAIN] Epoch[5](826/1500); Loss: 0.076404; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1110 0.0945 0.0798 0.0822 0.0736 0.0728 0.0716 0.0717 0.0702 0.0697 0.0713 0.0700 0.0702 0.0714 0.0710 0.0715 

[TRAIN] Epoch[5](827/1500); Loss: 0.102595; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1309 0.1165 0.1074 0.1040 0.1022 0.1002 0.0983 0.0979 0.0973 0.0969 0.0980 0.0978 0.0975 0.0983 0.0990 0.0993 

[TRAIN] Epoch[5](828/1500); Loss: 0.071281; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0798 0.0781 0.0798 0.0772 0.0718 0.0691 0.0673 0.0663 0.0668 0.0668 0.0670 0.0695 0.0685 0.0699 0.0714 0.0714 

[TRAIN] Epoch[5](829/1500); Loss: 0.128007; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1376 0.1426 0.1405 0.1351 0.1308 0.1256 0.1233 0.1235 0.1236 0.1227 0.1232 0.1233 0.1231 0.1238 0.1250 0.1245 

[TRAIN] Epoch[5](830/1500); Loss: 0.091265; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1754 0.0856 0.0820 0.0968 0.0952 0.0763 0.0726 0.0719 0.0761 0.0779 0.0810 0.0851 0.0895 0.0939 0.0984 0.1025 

[TRAIN] Epoch[5](831/1500); Loss: 0.092772; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1580 0.1190 0.1105 0.1108 0.0958 0.0844 0.0865 0.0794 0.0809 0.0798 0.0799 0.0794 0.0790 0.0796 0.0806 0.0809 

[TRAIN] Epoch[5](832/1500); Loss: 0.068630; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1589 0.0920 0.0793 0.0861 0.0819 0.0662 0.0554 0.0529 0.0526 0.0513 0.0500 0.0528 0.0519 0.0528 0.0558 0.0583 

[TRAIN] Epoch[5](833/1500); Loss: 0.162015; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1768 0.1717 0.1702 0.1689 0.1641 0.1607 0.1595 0.1592 0.1572 0.1578 0.1573 0.1568 0.1574 0.1585 0.1577 0.1585 

[TRAIN] Epoch[5](834/1500); Loss: 0.126465; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1911 0.1443 0.1377 0.1369 0.1290 0.1247 0.1192 0.1175 0.1165 0.1151 0.1147 0.1149 0.1146 0.1151 0.1157 0.1164 

[TRAIN] Epoch[5](835/1500); Loss: 0.128119; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2234 0.1578 0.1494 0.1662 0.1516 0.1359 0.1188 0.1068 0.1044 0.1025 0.1053 0.1036 0.1043 0.1060 0.1068 0.1071 

[TRAIN] Epoch[5](836/1500); Loss: 0.081348; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1014 0.0919 0.0871 0.0857 0.0819 0.0789 0.0781 0.0777 0.0772 0.0766 0.0765 0.0775 0.0770 0.0776 0.0784 0.0782 

[TRAIN] Epoch[5](837/1500); Loss: 0.064051; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0905 0.0785 0.0694 0.0658 0.0618 0.0589 0.0591 0.0593 0.0585 0.0588 0.0595 0.0592 0.0602 0.0612 0.0610 0.0631 

[TRAIN] Epoch[5](838/1500); Loss: 0.177597; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2267 0.1911 0.1859 0.1881 0.1803 0.1732 0.1672 0.1634 0.1631 0.1652 0.1672 0.1687 0.1713 0.1747 0.1765 0.1790 

[TRAIN] Epoch[5](839/1500); Loss: 0.153452; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2118 0.1833 0.1773 0.1785 0.1710 0.1637 0.1546 0.1452 0.1392 0.1358 0.1339 0.1332 0.1323 0.1315 0.1319 0.1318 

[TRAIN] Epoch[5](840/1500); Loss: 0.177378; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2406 0.1972 0.1904 0.1955 0.1855 0.1754 0.1694 0.1649 0.1631 0.1634 0.1635 0.1639 0.1654 0.1659 0.1662 0.1679 

[TRAIN] Epoch[5](841/1500); Loss: 0.075622; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1346 0.0917 0.0808 0.0844 0.0749 0.0689 0.0743 0.0666 0.0661 0.0671 0.0676 0.0661 0.0665 0.0666 0.0662 0.0675 

[TRAIN] Epoch[5](842/1500); Loss: 0.134530; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2292 0.1839 0.1738 0.1777 0.1679 0.1544 0.1385 0.1211 0.1090 0.1007 0.0981 0.0992 0.1003 0.0992 0.0991 0.1003 

[TRAIN] Epoch[5](843/1500); Loss: 0.149784; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2164 0.1680 0.1575 0.1646 0.1558 0.1455 0.1417 0.1401 0.1388 0.1390 0.1389 0.1387 0.1385 0.1377 0.1373 0.1379 

[TRAIN] Epoch[5](844/1500); Loss: 0.120931; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1746 0.1391 0.1312 0.1317 0.1277 0.1194 0.1149 0.1122 0.1110 0.1103 0.1109 0.1105 0.1099 0.1101 0.1113 0.1100 

[TRAIN] Epoch[5](845/1500); Loss: 0.133818; Backpropagation: 0.0927 sec; Batch: 0.4245 sec
0.1983 0.1680 0.1554 0.1536 0.1444 0.1316 0.1251 0.1215 0.1200 0.1179 0.1171 0.1175 0.1174 0.1172 0.1178 0.1182 

[TRAIN] Epoch[5](846/1500); Loss: 0.048597; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.0760 0.0664 0.0525 0.0448 0.0437 0.0441 0.0427 0.0430 0.0435 0.0435 0.0450 0.0449 0.0454 0.0469 0.0472 0.0480 

[TRAIN] Epoch[5](847/1500); Loss: 0.122286; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1935 0.1492 0.1422 0.1462 0.1380 0.1283 0.1192 0.1107 0.1062 0.1027 0.1050 0.1033 0.1024 0.1027 0.1034 0.1035 

[TRAIN] Epoch[5](848/1500); Loss: 0.119924; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1489 0.1314 0.1216 0.1210 0.1190 0.1183 0.1160 0.1152 0.1154 0.1152 0.1151 0.1154 0.1158 0.1161 0.1172 0.1174 

[TRAIN] Epoch[5](849/1500); Loss: 0.069309; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1005 0.0881 0.0781 0.0726 0.0684 0.0661 0.0649 0.0640 0.0627 0.0629 0.0629 0.0627 0.0631 0.0632 0.0642 0.0645 

[TRAIN] Epoch[5](850/1500); Loss: 0.123606; Backpropagation: 0.0926 sec; Batch: 0.4243 sec
0.1850 0.1513 0.1407 0.1392 0.1339 0.1254 0.1179 0.1135 0.1104 0.1085 0.1091 0.1091 0.1078 0.1085 0.1097 0.1079 

[TRAIN] Epoch[5](851/1500); Loss: 0.093860; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1144 0.1026 0.0977 0.0954 0.0936 0.0922 0.0914 0.0906 0.0901 0.0899 0.0900 0.0899 0.0904 0.0906 0.0911 0.0920 

[TRAIN] Epoch[5](852/1500); Loss: 0.086712; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1314 0.1038 0.0962 0.0950 0.0896 0.0844 0.0806 0.0787 0.0769 0.0764 0.0765 0.0760 0.0783 0.0786 0.0804 0.0846 

[TRAIN] Epoch[5](853/1500); Loss: 0.093328; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1753 0.1192 0.1040 0.1077 0.1054 0.0902 0.0817 0.0772 0.0763 0.0771 0.0777 0.0785 0.0785 0.0805 0.0819 0.0819 

[TRAIN] Epoch[5](854/1500); Loss: 0.146098; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1870 0.1578 0.1517 0.1546 0.1530 0.1449 0.1412 0.1400 0.1393 0.1375 0.1373 0.1375 0.1382 0.1384 0.1389 0.1403 

[TRAIN] Epoch[5](855/1500); Loss: 0.135904; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1751 0.1540 0.1476 0.1508 0.1455 0.1402 0.1354 0.1322 0.1286 0.1248 0.1228 0.1228 0.1231 0.1237 0.1240 0.1240 

[TRAIN] Epoch[5](856/1500); Loss: 0.083459; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1048 0.0912 0.0869 0.0847 0.0830 0.0820 0.0809 0.0801 0.0792 0.0794 0.0795 0.0798 0.0801 0.0808 0.0811 0.0817 

[TRAIN] Epoch[5](857/1500); Loss: 0.082326; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0876 0.0982 0.0932 0.0836 0.0823 0.0827 0.0809 0.0789 0.0793 0.0792 0.0782 0.0786 0.0783 0.0780 0.0793 0.0789 

[TRAIN] Epoch[5](858/1500); Loss: 0.123514; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1520 0.1399 0.1348 0.1314 0.1281 0.1243 0.1205 0.1176 0.1163 0.1156 0.1156 0.1157 0.1156 0.1156 0.1159 0.1171 

[TRAIN] Epoch[5](859/1500); Loss: 0.135377; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1730 0.1520 0.1471 0.1483 0.1446 0.1386 0.1337 0.1295 0.1268 0.1250 0.1245 0.1245 0.1242 0.1241 0.1248 0.1254 

[TRAIN] Epoch[5](860/1500); Loss: 0.154539; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2183 0.1846 0.1757 0.1746 0.1670 0.1571 0.1495 0.1432 0.1394 0.1371 0.1360 0.1366 0.1375 0.1379 0.1383 0.1398 

[TRAIN] Epoch[5](861/1500); Loss: 0.085904; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1305 0.1053 0.0992 0.0995 0.0942 0.0888 0.0822 0.0770 0.0739 0.0728 0.0731 0.0739 0.0746 0.0751 0.0767 0.0777 

[TRAIN] Epoch[5](862/1500); Loss: 0.102398; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1903 0.1404 0.1289 0.1341 0.1278 0.1148 0.1019 0.0901 0.0824 0.0774 0.0768 0.0753 0.0744 0.0747 0.0746 0.0746 

[TRAIN] Epoch[5](863/1500); Loss: 0.078620; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1406 0.1021 0.0950 0.1027 0.0938 0.0842 0.0754 0.0673 0.0622 0.0613 0.0619 0.0614 0.0616 0.0627 0.0626 0.0633 

[TRAIN] Epoch[5](864/1500); Loss: 0.066754; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1064 0.0852 0.0781 0.0764 0.0689 0.0636 0.0601 0.0586 0.0579 0.0565 0.0565 0.0572 0.0576 0.0602 0.0613 0.0636 

[TRAIN] Epoch[5](865/1500); Loss: 0.117188; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2174 0.1497 0.1418 0.1602 0.1464 0.1258 0.1055 0.0946 0.0962 0.0914 0.0911 0.0918 0.0897 0.0905 0.0909 0.0922 

[TRAIN] Epoch[5](866/1500); Loss: 0.108621; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1223 0.1162 0.1113 0.1109 0.1112 0.1072 0.1051 0.1057 0.1062 0.1049 0.1051 0.1053 0.1055 0.1066 0.1068 0.1076 

[TRAIN] Epoch[5](867/1500); Loss: 0.132274; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1633 0.1513 0.1460 0.1459 0.1414 0.1366 0.1316 0.1285 0.1250 0.1224 0.1201 0.1199 0.1207 0.1213 0.1208 0.1215 

[TRAIN] Epoch[5](868/1500); Loss: 0.147327; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1512 0.1532 0.1556 0.1507 0.1459 0.1466 0.1465 0.1456 0.1453 0.1451 0.1443 0.1454 0.1449 0.1454 0.1460 0.1456 

[TRAIN] Epoch[5](869/1500); Loss: 0.123951; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2188 0.1527 0.1494 0.1750 0.1602 0.1367 0.1169 0.1044 0.0974 0.0973 0.0954 0.0954 0.0952 0.0954 0.0964 0.0966 

[TRAIN] Epoch[5](870/1500); Loss: 0.177110; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2765 0.2298 0.2236 0.2355 0.2245 0.2095 0.1907 0.1689 0.1508 0.1364 0.1294 0.1305 0.1313 0.1323 0.1314 0.1325 

[TRAIN] Epoch[5](871/1500); Loss: 0.122138; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1533 0.1388 0.1337 0.1335 0.1285 0.1237 0.1188 0.1152 0.1136 0.1129 0.1125 0.1129 0.1135 0.1137 0.1145 0.1152 

[TRAIN] Epoch[5](872/1500); Loss: 0.132378; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1789 0.1541 0.1424 0.1463 0.1409 0.1388 0.1320 0.1257 0.1224 0.1206 0.1193 0.1198 0.1194 0.1194 0.1187 0.1194 

[TRAIN] Epoch[5](873/1500); Loss: 0.081753; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1129 0.0960 0.0890 0.0878 0.0854 0.0826 0.0804 0.0785 0.0768 0.0750 0.0741 0.0736 0.0741 0.0737 0.0740 0.0742 

[TRAIN] Epoch[5](874/1500); Loss: 0.077710; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1188 0.0913 0.0807 0.0809 0.0775 0.0739 0.0733 0.0724 0.0710 0.0707 0.0718 0.0709 0.0713 0.0729 0.0725 0.0735 

[TRAIN] Epoch[5](875/1500); Loss: 0.097343; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1170 0.1091 0.1022 0.0997 0.0966 0.0939 0.0928 0.0932 0.0939 0.0929 0.0927 0.0940 0.0937 0.0944 0.0953 0.0959 

[TRAIN] Epoch[5](876/1500); Loss: 0.136983; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1810 0.1520 0.1461 0.1467 0.1419 0.1352 0.1316 0.1292 0.1285 0.1274 0.1272 0.1279 0.1278 0.1288 0.1296 0.1307 

[TRAIN] Epoch[5](877/1500); Loss: 0.071252; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1114 0.0964 0.0773 0.0708 0.0686 0.0653 0.0641 0.0643 0.0637 0.0637 0.0644 0.0648 0.0651 0.0661 0.0668 0.0673 

[TRAIN] Epoch[5](878/1500); Loss: 0.133952; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1487 0.1335 0.1288 0.1289 0.1286 0.1278 0.1274 0.1282 0.1282 0.1306 0.1314 0.1344 0.1372 0.1401 0.1434 0.1462 

[TRAIN] Epoch[5](879/1500); Loss: 0.149122; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1715 0.1649 0.1602 0.1568 0.1525 0.1500 0.1481 0.1461 0.1444 0.1430 0.1420 0.1415 0.1411 0.1412 0.1411 0.1417 

[TRAIN] Epoch[5](880/1500); Loss: 0.144433; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2187 0.1691 0.1615 0.1747 0.1640 0.1504 0.1369 0.1306 0.1281 0.1267 0.1243 0.1247 0.1248 0.1249 0.1255 0.1260 

[TRAIN] Epoch[5](881/1500); Loss: 0.146516; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1811 0.1643 0.1597 0.1605 0.1569 0.1488 0.1444 0.1414 0.1386 0.1365 0.1349 0.1342 0.1351 0.1356 0.1355 0.1367 

[TRAIN] Epoch[5](882/1500); Loss: 0.112071; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2393 0.1595 0.1555 0.1849 0.1662 0.1408 0.1067 0.0752 0.0727 0.0704 0.0704 0.0696 0.0693 0.0703 0.0699 0.0725 

[TRAIN] Epoch[5](883/1500); Loss: 0.083563; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2287 0.1028 0.0959 0.1215 0.1121 0.0602 0.0494 0.0539 0.0499 0.0583 0.0546 0.0638 0.0623 0.0689 0.0785 0.0763 

[TRAIN] Epoch[5](884/1500); Loss: 0.075850; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1343 0.0910 0.0823 0.0842 0.0793 0.0719 0.0684 0.0680 0.0664 0.0652 0.0664 0.0663 0.0660 0.0670 0.0681 0.0688 

[TRAIN] Epoch[5](885/1500); Loss: 0.111045; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1620 0.1227 0.1160 0.1178 0.1134 0.1069 0.1047 0.1028 0.1025 0.1022 0.1026 0.1028 0.1039 0.1044 0.1054 0.1064 

[TRAIN] Epoch[5](886/1500); Loss: 0.076602; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1143 0.0971 0.0805 0.0747 0.0758 0.0732 0.0703 0.0710 0.0696 0.0696 0.0723 0.0697 0.0702 0.0728 0.0723 0.0723 

[TRAIN] Epoch[5](887/1500); Loss: 0.134324; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1835 0.1494 0.1438 0.1499 0.1444 0.1380 0.1307 0.1265 0.1228 0.1224 0.1218 0.1221 0.1219 0.1222 0.1246 0.1253 

[TRAIN] Epoch[5](888/1500); Loss: 0.138674; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.2690 0.1950 0.1893 0.2184 0.2021 0.1791 0.1475 0.1126 0.0896 0.0853 0.0880 0.0889 0.0859 0.0891 0.0904 0.0886 

[TRAIN] Epoch[5](889/1500); Loss: 0.082389; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1156 0.0912 0.0831 0.0824 0.0802 0.0783 0.0768 0.0763 0.0758 0.0770 0.0770 0.0786 0.0785 0.0805 0.0826 0.0844 

[TRAIN] Epoch[5](890/1500); Loss: 0.117125; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2494 0.1719 0.1602 0.1691 0.1591 0.1294 0.1060 0.0901 0.0820 0.0792 0.0770 0.0799 0.0773 0.0811 0.0799 0.0826 

[TRAIN] Epoch[5](891/1500); Loss: 0.108285; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1261 0.1152 0.1090 0.1092 0.1065 0.1053 0.1063 0.1063 0.1045 0.1048 0.1067 0.1053 0.1055 0.1083 0.1071 0.1066 

[TRAIN] Epoch[5](892/1500); Loss: 0.073405; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1021 0.0943 0.0817 0.0760 0.0731 0.0710 0.0682 0.0669 0.0657 0.0652 0.0648 0.0663 0.0674 0.0696 0.0707 0.0716 

[TRAIN] Epoch[5](893/1500); Loss: 0.077529; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1371 0.0797 0.0738 0.0833 0.0774 0.0711 0.0665 0.0649 0.0697 0.0670 0.0679 0.0737 0.0725 0.0753 0.0808 0.0797 

[TRAIN] Epoch[5](894/1500); Loss: 0.168664; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2359 0.2018 0.1936 0.1995 0.1925 0.1808 0.1690 0.1595 0.1536 0.1492 0.1456 0.1440 0.1437 0.1434 0.1430 0.1435 

[TRAIN] Epoch[5](895/1500); Loss: 0.109950; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1400 0.1271 0.1153 0.1133 0.1100 0.1073 0.1038 0.1029 0.1020 0.1021 0.1024 0.1036 0.1047 0.1063 0.1080 0.1105 

[TRAIN] Epoch[5](896/1500); Loss: 0.079829; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.0941 0.0837 0.0853 0.0803 0.0788 0.0769 0.0774 0.0763 0.0759 0.0768 0.0772 0.0777 0.0787 0.0788 0.0791 0.0803 

[TRAIN] Epoch[5](897/1500); Loss: 0.088436; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1671 0.1036 0.0974 0.1068 0.0999 0.0923 0.0832 0.0800 0.0749 0.0739 0.0710 0.0715 0.0714 0.0719 0.0750 0.0751 

[TRAIN] Epoch[5](898/1500); Loss: 0.163470; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2370 0.1951 0.1944 0.2085 0.1988 0.1861 0.1719 0.1609 0.1538 0.1463 0.1386 0.1313 0.1255 0.1227 0.1217 0.1228 

[TRAIN] Epoch[5](899/1500); Loss: 0.150106; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1586 0.1531 0.1524 0.1522 0.1507 0.1498 0.1487 0.1480 0.1481 0.1482 0.1475 0.1484 0.1485 0.1483 0.1496 0.1497 

[TRAIN] Epoch[5](900/1500); Loss: 0.175748; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2490 0.2097 0.2105 0.2193 0.2109 0.1986 0.1841 0.1690 0.1633 0.1558 0.1421 0.1369 0.1404 0.1403 0.1402 0.1417 

[TRAIN] Epoch[5](901/1500); Loss: 0.115595; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1703 0.1362 0.1269 0.1302 0.1237 0.1135 0.1086 0.1059 0.1044 0.1032 0.1038 0.1033 0.1033 0.1050 0.1050 0.1061 

[TRAIN] Epoch[5](902/1500); Loss: 0.096113; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1062 0.1049 0.1010 0.0965 0.0954 0.0952 0.0939 0.0935 0.0942 0.0933 0.0932 0.0946 0.0937 0.0936 0.0945 0.0941 

[TRAIN] Epoch[5](903/1500); Loss: 0.155890; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1979 0.1770 0.1698 0.1706 0.1672 0.1607 0.1553 0.1514 0.1485 0.1460 0.1440 0.1419 0.1413 0.1407 0.1410 0.1411 

[TRAIN] Epoch[5](904/1500); Loss: 0.103465; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2500 0.1518 0.1196 0.1243 0.1193 0.0864 0.0752 0.0783 0.0705 0.0772 0.0854 0.0794 0.0807 0.0859 0.0851 0.0865 

[TRAIN] Epoch[5](905/1500); Loss: 0.069257; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.0962 0.0830 0.0740 0.0709 0.0689 0.0676 0.0636 0.0639 0.0633 0.0629 0.0641 0.0655 0.0640 0.0659 0.0668 0.0675 

[TRAIN] Epoch[5](906/1500); Loss: 0.047441; Backpropagation: 0.0918 sec; Batch: 0.4262 sec
0.0485 0.0587 0.0551 0.0438 0.0402 0.0445 0.0433 0.0413 0.0428 0.0460 0.0452 0.0453 0.0490 0.0488 0.0511 0.0553 

[TRAIN] Epoch[5](907/1500); Loss: 0.135559; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2323 0.1643 0.1530 0.1674 0.1591 0.1498 0.1356 0.1269 0.1249 0.1174 0.1108 0.1086 0.1046 0.1039 0.1049 0.1054 

[TRAIN] Epoch[5](908/1500); Loss: 0.058748; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0911 0.0729 0.0639 0.0702 0.0641 0.0581 0.0549 0.0533 0.0510 0.0506 0.0511 0.0509 0.0508 0.0518 0.0524 0.0527 

[TRAIN] Epoch[5](909/1500); Loss: 0.157097; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2428 0.1935 0.1863 0.2014 0.1928 0.1813 0.1663 0.1554 0.1503 0.1426 0.1325 0.1239 0.1174 0.1121 0.1079 0.1070 

[TRAIN] Epoch[5](910/1500); Loss: 0.113070; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1724 0.1258 0.1197 0.1329 0.1238 0.1138 0.1054 0.1014 0.0998 0.0998 0.1003 0.1011 0.1019 0.1029 0.1035 0.1047 

[TRAIN] Epoch[5](911/1500); Loss: 0.106545; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1540 0.1170 0.1074 0.1076 0.1057 0.1030 0.1008 0.0980 0.0984 0.0985 0.0998 0.0993 0.1011 0.1037 0.1041 0.1062 

[TRAIN] Epoch[5](912/1500); Loss: 0.163312; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1789 0.1751 0.1697 0.1674 0.1658 0.1647 0.1623 0.1608 0.1601 0.1591 0.1581 0.1577 0.1574 0.1581 0.1587 0.1591 

[TRAIN] Epoch[5](913/1500); Loss: 0.105950; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1475 0.1211 0.1149 0.1223 0.1161 0.1102 0.1041 0.1003 0.0980 0.0954 0.0943 0.0939 0.0936 0.0939 0.0943 0.0952 

[TRAIN] Epoch[5](914/1500); Loss: 0.078457; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1462 0.1031 0.0931 0.1053 0.0956 0.0828 0.0710 0.0634 0.0619 0.0613 0.0616 0.0613 0.0618 0.0618 0.0623 0.0626 

[TRAIN] Epoch[5](915/1500); Loss: 0.075060; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1243 0.1028 0.0836 0.0856 0.0813 0.0742 0.0681 0.0647 0.0635 0.0640 0.0638 0.0639 0.0648 0.0649 0.0656 0.0660 

[TRAIN] Epoch[5](916/1500); Loss: 0.123019; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1901 0.1428 0.1325 0.1406 0.1364 0.1307 0.1219 0.1166 0.1147 0.1131 0.1088 0.1061 0.1052 0.1038 0.1024 0.1028 

[TRAIN] Epoch[5](917/1500); Loss: 0.114909; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1524 0.1375 0.1219 0.1236 0.1203 0.1142 0.1083 0.1056 0.1061 0.1058 0.1053 0.1064 0.1069 0.1075 0.1083 0.1085 

[TRAIN] Epoch[5](918/1500); Loss: 0.096008; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1765 0.1313 0.1146 0.1230 0.1152 0.0989 0.0869 0.0806 0.0798 0.0762 0.0758 0.0758 0.0746 0.0746 0.0766 0.0758 

[TRAIN] Epoch[5](919/1500); Loss: 0.195988; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.3656 0.2757 0.2774 0.3116 0.2918 0.2585 0.2256 0.1942 0.1721 0.1459 0.1138 0.0964 0.0986 0.1034 0.1025 0.1028 

[TRAIN] Epoch[5](920/1500); Loss: 0.143543; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2179 0.1695 0.1552 0.1600 0.1522 0.1407 0.1346 0.1311 0.1280 0.1272 0.1270 0.1277 0.1291 0.1303 0.1323 0.1340 

[TRAIN] Epoch[5](921/1500); Loss: 0.123570; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2306 0.1486 0.1500 0.1834 0.1669 0.1423 0.1213 0.1089 0.1021 0.0954 0.0889 0.0852 0.0863 0.0884 0.0885 0.0902 

[TRAIN] Epoch[5](922/1500); Loss: 0.077712; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2535 0.1394 0.0871 0.0929 0.0883 0.0572 0.0496 0.0436 0.0474 0.0546 0.0508 0.0528 0.0510 0.0586 0.0590 0.0577 

[TRAIN] Epoch[5](923/1500); Loss: 0.129825; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1782 0.1495 0.1424 0.1461 0.1407 0.1340 0.1283 0.1237 0.1205 0.1178 0.1162 0.1157 0.1164 0.1159 0.1155 0.1163 

[TRAIN] Epoch[5](924/1500); Loss: 0.152201; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1898 0.1692 0.1610 0.1617 0.1572 0.1502 0.1457 0.1464 0.1446 0.1433 0.1432 0.1449 0.1441 0.1433 0.1453 0.1454 

[TRAIN] Epoch[5](925/1500); Loss: 0.100706; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1347 0.1088 0.0994 0.1119 0.1055 0.0973 0.0940 0.0952 0.0924 0.0915 0.0927 0.0933 0.0957 0.0974 0.0993 0.1022 

[TRAIN] Epoch[5](926/1500); Loss: 0.085994; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1187 0.1004 0.0926 0.0949 0.0906 0.0865 0.0833 0.0823 0.0804 0.0788 0.0781 0.0774 0.0776 0.0780 0.0779 0.0784 

[TRAIN] Epoch[5](927/1500); Loss: 0.101877; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1182 0.1133 0.1061 0.1022 0.1005 0.0997 0.0988 0.0981 0.0979 0.0981 0.0979 0.0984 0.0989 0.0996 0.1007 0.1016 

[TRAIN] Epoch[5](928/1500); Loss: 0.110421; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1626 0.1349 0.1215 0.1275 0.1194 0.1085 0.1018 0.0993 0.0985 0.0983 0.0973 0.0971 0.0986 0.0992 0.1003 0.1017 

[TRAIN] Epoch[5](929/1500); Loss: 0.100888; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1337 0.1222 0.1067 0.1066 0.1029 0.0973 0.0948 0.0911 0.0911 0.0926 0.0936 0.0928 0.0943 0.0972 0.0982 0.0991 

[TRAIN] Epoch[5](930/1500); Loss: 0.145870; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.3024 0.2111 0.2112 0.2518 0.2315 0.2011 0.1697 0.1415 0.1178 0.0923 0.0707 0.0643 0.0657 0.0690 0.0666 0.0673 

[TRAIN] Epoch[5](931/1500); Loss: 0.137075; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1939 0.1654 0.1581 0.1639 0.1581 0.1469 0.1377 0.1304 0.1254 0.1201 0.1155 0.1136 0.1142 0.1159 0.1165 0.1178 

[TRAIN] Epoch[5](932/1500); Loss: 0.105799; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1732 0.1198 0.1209 0.1433 0.1319 0.1163 0.1027 0.0939 0.0889 0.0853 0.0844 0.0850 0.0850 0.0858 0.0879 0.0885 

[TRAIN] Epoch[5](933/1500); Loss: 0.106478; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1624 0.1345 0.1218 0.1189 0.1128 0.1067 0.1005 0.0974 0.0953 0.0937 0.0924 0.0929 0.0925 0.0925 0.0947 0.0947 

[TRAIN] Epoch[5](934/1500); Loss: 0.073153; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1183 0.0958 0.0845 0.0806 0.0784 0.0741 0.0700 0.0672 0.0654 0.0629 0.0627 0.0625 0.0620 0.0616 0.0621 0.0623 

[TRAIN] Epoch[5](935/1500); Loss: 0.067353; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0915 0.0733 0.0673 0.0669 0.0653 0.0645 0.0620 0.0605 0.0629 0.0634 0.0628 0.0654 0.0666 0.0661 0.0701 0.0691 

[TRAIN] Epoch[5](936/1500); Loss: 0.042935; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0463 0.0506 0.0553 0.0391 0.0371 0.0405 0.0386 0.0363 0.0381 0.0413 0.0402 0.0416 0.0441 0.0442 0.0456 0.0480 

[TRAIN] Epoch[5](937/1500); Loss: 0.181684; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.3202 0.2450 0.2341 0.2569 0.2400 0.2105 0.1841 0.1625 0.1421 0.1290 0.1283 0.1309 0.1290 0.1312 0.1310 0.1320 

[TRAIN] Epoch[5](938/1500); Loss: 0.050750; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0879 0.0666 0.0474 0.0544 0.0493 0.0412 0.0411 0.0471 0.0450 0.0431 0.0468 0.0454 0.0474 0.0500 0.0485 0.0508 

[TRAIN] Epoch[5](939/1500); Loss: 0.114514; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2158 0.1350 0.1265 0.1428 0.1345 0.1198 0.1090 0.1023 0.0996 0.0924 0.0893 0.0916 0.0917 0.0915 0.0950 0.0955 

[TRAIN] Epoch[5](940/1500); Loss: 0.069572; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0883 0.0840 0.0751 0.0734 0.0702 0.0699 0.0657 0.0643 0.0645 0.0651 0.0643 0.0648 0.0652 0.0655 0.0664 0.0665 

[TRAIN] Epoch[5](941/1500); Loss: 0.107853; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1408 0.1250 0.1160 0.1133 0.1106 0.1079 0.1056 0.1035 0.1028 0.1012 0.0999 0.0996 0.0999 0.0999 0.0998 0.0998 

[TRAIN] Epoch[5](942/1500); Loss: 0.165525; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2444 0.2094 0.1910 0.1971 0.1889 0.1762 0.1661 0.1604 0.1564 0.1501 0.1428 0.1390 0.1364 0.1323 0.1294 0.1285 

[TRAIN] Epoch[5](943/1500); Loss: 0.124266; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1710 0.1502 0.1348 0.1276 0.1213 0.1170 0.1151 0.1135 0.1130 0.1129 0.1139 0.1156 0.1172 0.1196 0.1213 0.1242 

[TRAIN] Epoch[5](944/1500); Loss: 0.085834; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1218 0.1294 0.1147 0.1046 0.0928 0.0852 0.0795 0.0744 0.0728 0.0714 0.0693 0.0707 0.0708 0.0707 0.0717 0.0735 

[TRAIN] Epoch[5](945/1500); Loss: 0.083718; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1018 0.1167 0.1013 0.0942 0.0843 0.0779 0.0759 0.0747 0.0741 0.0760 0.0758 0.0752 0.0768 0.0782 0.0771 0.0795 

[TRAIN] Epoch[5](946/1500); Loss: 0.106102; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1377 0.1224 0.1083 0.1019 0.0976 0.0962 0.0951 0.0942 0.0960 0.0985 0.1009 0.1036 0.1067 0.1096 0.1123 0.1166 

[TRAIN] Epoch[5](947/1500); Loss: 0.153970; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1963 0.1958 0.1808 0.1708 0.1613 0.1517 0.1454 0.1411 0.1388 0.1391 0.1394 0.1395 0.1400 0.1411 0.1410 0.1416 

[TRAIN] Epoch[5](948/1500); Loss: 0.065024; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0948 0.0765 0.0714 0.0698 0.0651 0.0609 0.0598 0.0614 0.0591 0.0581 0.0582 0.0614 0.0595 0.0601 0.0621 0.0622 

[TRAIN] Epoch[5](949/1500); Loss: 0.150313; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2790 0.2349 0.2002 0.1925 0.1834 0.1661 0.1495 0.1346 0.1232 0.1157 0.1100 0.1054 0.1028 0.1030 0.1031 0.1018 

[TRAIN] Epoch[5](950/1500); Loss: 0.091968; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1597 0.1493 0.1290 0.1174 0.1016 0.0855 0.0742 0.0713 0.0733 0.0737 0.0715 0.0719 0.0737 0.0724 0.0724 0.0747 

[TRAIN] Epoch[5](951/1500); Loss: 0.134901; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1977 0.1891 0.1694 0.1530 0.1422 0.1325 0.1265 0.1210 0.1176 0.1162 0.1146 0.1144 0.1147 0.1157 0.1165 0.1172 

[TRAIN] Epoch[5](952/1500); Loss: 0.064369; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2522 0.1351 0.0526 0.0616 0.0625 0.0446 0.0405 0.0355 0.0382 0.0457 0.0415 0.0383 0.0458 0.0450 0.0419 0.0489 

[TRAIN] Epoch[5](953/1500); Loss: 0.059376; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0481 0.1118 0.0970 0.0709 0.0500 0.0482 0.0457 0.0495 0.0465 0.0485 0.0515 0.0547 0.0541 0.0548 0.0589 0.0597 

[TRAIN] Epoch[5](954/1500); Loss: 0.101276; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1528 0.1263 0.1101 0.1061 0.1000 0.0941 0.0900 0.0870 0.0866 0.0875 0.0894 0.0928 0.0955 0.0979 0.1007 0.1037 

[TRAIN] Epoch[5](955/1500); Loss: 0.160379; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.2539 0.2357 0.2034 0.1876 0.1752 0.1620 0.1492 0.1403 0.1347 0.1333 0.1328 0.1321 0.1305 0.1310 0.1320 0.1325 

[TRAIN] Epoch[5](956/1500); Loss: 0.108464; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1727 0.1802 0.1533 0.1305 0.1126 0.0984 0.0877 0.0845 0.0851 0.0876 0.0865 0.0881 0.0897 0.0912 0.0929 0.0943 

[TRAIN] Epoch[5](957/1500); Loss: 0.172934; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1896 0.1985 0.1902 0.1811 0.1744 0.1709 0.1695 0.1680 0.1668 0.1665 0.1662 0.1655 0.1649 0.1648 0.1651 0.1650 

[TRAIN] Epoch[5](958/1500); Loss: 0.074247; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1348 0.1050 0.0917 0.0852 0.0794 0.0702 0.0652 0.0622 0.0602 0.0594 0.0597 0.0603 0.0611 0.0628 0.0645 0.0665 

[TRAIN] Epoch[5](959/1500); Loss: 0.085236; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1269 0.1348 0.1239 0.1131 0.1000 0.0870 0.0773 0.0712 0.0670 0.0648 0.0639 0.0644 0.0653 0.0661 0.0679 0.0700 

[TRAIN] Epoch[5](960/1500); Loss: 0.115193; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1793 0.1514 0.1308 0.1253 0.1190 0.1117 0.1076 0.1055 0.1037 0.1022 0.1010 0.1009 0.1006 0.1007 0.1015 0.1018 

[TRAIN] Epoch[5](961/1500); Loss: 0.107078; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1632 0.1279 0.1129 0.1080 0.1070 0.1044 0.1018 0.1005 0.0982 0.0970 0.0977 0.0971 0.0978 0.1007 0.0994 0.0997 

[TRAIN] Epoch[5](962/1500); Loss: 0.122284; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1938 0.1959 0.1651 0.1358 0.1153 0.1057 0.1009 0.1008 0.1039 0.1011 0.1005 0.1041 0.1074 0.1067 0.1075 0.1120 

[TRAIN] Epoch[5](963/1500); Loss: 0.153179; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2087 0.1869 0.1722 0.1671 0.1621 0.1541 0.1489 0.1452 0.1415 0.1389 0.1380 0.1374 0.1366 0.1369 0.1379 0.1385 

[TRAIN] Epoch[5](964/1500); Loss: 0.108465; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1715 0.1456 0.1326 0.1259 0.1200 0.1105 0.1053 0.0994 0.0950 0.0921 0.0902 0.0894 0.0893 0.0892 0.0896 0.0900 

[TRAIN] Epoch[5](965/1500); Loss: 0.062159; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1246 0.0878 0.0744 0.0668 0.0603 0.0546 0.0517 0.0493 0.0492 0.0500 0.0524 0.0515 0.0521 0.0541 0.0574 0.0586 

[TRAIN] Epoch[5](966/1500); Loss: 0.150627; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2147 0.2084 0.1904 0.1740 0.1605 0.1503 0.1428 0.1366 0.1322 0.1298 0.1287 0.1281 0.1278 0.1276 0.1287 0.1295 

[TRAIN] Epoch[5](967/1500); Loss: 0.127610; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1950 0.1885 0.1645 0.1431 0.1270 0.1174 0.1123 0.1106 0.1101 0.1102 0.1096 0.1097 0.1103 0.1105 0.1111 0.1120 

[TRAIN] Epoch[5](968/1500); Loss: 0.109632; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1198 0.1550 0.1486 0.1299 0.1129 0.1065 0.1027 0.1010 0.0980 0.0965 0.0987 0.0967 0.0964 0.0977 0.0971 0.0966 

[TRAIN] Epoch[5](969/1500); Loss: 0.136227; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2134 0.2037 0.1895 0.1693 0.1516 0.1360 0.1243 0.1143 0.1088 0.1087 0.1105 0.1098 0.1093 0.1095 0.1105 0.1106 

[TRAIN] Epoch[5](970/1500); Loss: 0.166527; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1833 0.1903 0.1827 0.1737 0.1657 0.1613 0.1600 0.1594 0.1585 0.1583 0.1590 0.1601 0.1611 0.1620 0.1636 0.1654 

[TRAIN] Epoch[5](971/1500); Loss: 0.147858; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1946 0.1970 0.1798 0.1638 0.1501 0.1419 0.1359 0.1335 0.1327 0.1329 0.1325 0.1323 0.1332 0.1346 0.1352 0.1358 

[TRAIN] Epoch[5](972/1500); Loss: 0.094256; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1853 0.1767 0.1479 0.1196 0.0926 0.0769 0.0699 0.0707 0.0706 0.0690 0.0689 0.0705 0.0717 0.0711 0.0722 0.0743 

[TRAIN] Epoch[5](973/1500); Loss: 0.067785; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0867 0.1088 0.0968 0.0841 0.0693 0.0596 0.0564 0.0583 0.0575 0.0567 0.0568 0.0574 0.0580 0.0587 0.0593 0.0602 

[TRAIN] Epoch[5](974/1500); Loss: 0.064673; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0676 0.1030 0.0949 0.0749 0.0580 0.0595 0.0563 0.0580 0.0534 0.0550 0.0567 0.0592 0.0571 0.0584 0.0603 0.0626 

[TRAIN] Epoch[5](975/1500); Loss: 0.090404; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.0973 0.1497 0.1400 0.1169 0.0952 0.0801 0.0787 0.0774 0.0764 0.0742 0.0765 0.0763 0.0757 0.0761 0.0781 0.0779 

[TRAIN] Epoch[5](976/1500); Loss: 0.157496; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.3169 0.3016 0.2653 0.2294 0.1929 0.1589 0.1267 0.1028 0.0977 0.1030 0.1059 0.1023 0.1019 0.1040 0.1061 0.1046 

[TRAIN] Epoch[5](977/1500); Loss: 0.077508; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2220 0.0921 0.0597 0.0583 0.0583 0.0655 0.0623 0.0587 0.0643 0.0681 0.0672 0.0653 0.0709 0.0747 0.0760 0.0767 

[TRAIN] Epoch[5](978/1500); Loss: 0.188711; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3818 0.3765 0.3348 0.2876 0.2455 0.2108 0.1740 0.1378 0.1150 0.1079 0.1053 0.1090 0.1080 0.1072 0.1078 0.1104 

[TRAIN] Epoch[5](979/1500); Loss: 0.113613; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2129 0.1932 0.1606 0.1322 0.1109 0.1018 0.0960 0.0928 0.0905 0.0903 0.0899 0.0898 0.0886 0.0882 0.0902 0.0899 

[TRAIN] Epoch[5](980/1500); Loss: 0.157112; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1758 0.1839 0.1766 0.1678 0.1582 0.1521 0.1487 0.1472 0.1467 0.1473 0.1486 0.1495 0.1505 0.1520 0.1536 0.1553 

[TRAIN] Epoch[5](981/1500); Loss: 0.064936; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1161 0.0890 0.0920 0.0794 0.0648 0.0532 0.0536 0.0530 0.0514 0.0532 0.0536 0.0530 0.0535 0.0561 0.0578 0.0593 

[TRAIN] Epoch[5](982/1500); Loss: 0.084301; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1493 0.1456 0.1228 0.1039 0.0844 0.0718 0.0672 0.0672 0.0678 0.0661 0.0661 0.0674 0.0667 0.0671 0.0678 0.0676 

[TRAIN] Epoch[5](983/1500); Loss: 0.110595; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1427 0.1412 0.1335 0.1251 0.1144 0.1049 0.1007 0.0993 0.0994 0.0991 0.0995 0.1001 0.1006 0.1017 0.1028 0.1045 

[TRAIN] Epoch[5](984/1500); Loss: 0.131639; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1583 0.1776 0.1705 0.1586 0.1438 0.1302 0.1205 0.1154 0.1147 0.1157 0.1158 0.1159 0.1162 0.1171 0.1176 0.1183 

[TRAIN] Epoch[5](985/1500); Loss: 0.175037; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2367 0.2309 0.2148 0.2023 0.1887 0.1765 0.1677 0.1622 0.1576 0.1543 0.1526 0.1514 0.1507 0.1511 0.1513 0.1517 

[TRAIN] Epoch[5](986/1500); Loss: 0.128033; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2334 0.2121 0.1735 0.1446 0.1239 0.1121 0.1071 0.1056 0.1047 0.1042 0.1040 0.1040 0.1043 0.1043 0.1051 0.1055 

[TRAIN] Epoch[5](987/1500); Loss: 0.088016; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1120 0.1022 0.1105 0.1012 0.0901 0.0810 0.0776 0.0779 0.0778 0.0792 0.0793 0.0801 0.0821 0.0834 0.0857 0.0884 

[TRAIN] Epoch[5](988/1500); Loss: 0.150057; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1783 0.1865 0.1751 0.1647 0.1532 0.1456 0.1425 0.1407 0.1392 0.1384 0.1382 0.1387 0.1393 0.1398 0.1403 0.1404 

[TRAIN] Epoch[5](989/1500); Loss: 0.195511; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2255 0.2442 0.2339 0.2200 0.2045 0.1953 0.1896 0.1869 0.1840 0.1796 0.1794 0.1797 0.1773 0.1758 0.1769 0.1757 

[TRAIN] Epoch[5](990/1500); Loss: 0.093136; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1645 0.1554 0.1385 0.1184 0.1014 0.0883 0.0781 0.0695 0.0680 0.0695 0.0713 0.0710 0.0721 0.0740 0.0741 0.0762 

[TRAIN] Epoch[5](991/1500); Loss: 0.143068; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1625 0.2077 0.1985 0.1813 0.1608 0.1423 0.1291 0.1242 0.1252 0.1234 0.1228 0.1214 0.1218 0.1233 0.1225 0.1223 

[TRAIN] Epoch[5](992/1500); Loss: 0.077391; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.0785 0.1118 0.1128 0.0955 0.0771 0.0687 0.0716 0.0705 0.0674 0.0663 0.0678 0.0697 0.0687 0.0697 0.0711 0.0712 

[TRAIN] Epoch[5](993/1500); Loss: 0.125716; Backpropagation: 0.0924 sec; Batch: 0.4241 sec
0.1633 0.2049 0.1870 0.1648 0.1431 0.1231 0.1065 0.1014 0.1012 0.1018 0.1010 0.1012 0.1020 0.1023 0.1032 0.1048 

[TRAIN] Epoch[5](994/1500); Loss: 0.096445; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1258 0.1536 0.1359 0.1163 0.0987 0.0866 0.0829 0.0833 0.0833 0.0826 0.0820 0.0819 0.0822 0.0823 0.0827 0.0831 

[TRAIN] Epoch[5](995/1500); Loss: 0.091104; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1253 0.1630 0.1588 0.1426 0.1202 0.0960 0.0747 0.0625 0.0625 0.0638 0.0638 0.0621 0.0646 0.0661 0.0655 0.0664 

[TRAIN] Epoch[5](996/1500); Loss: 0.085326; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1116 0.1514 0.1379 0.1211 0.0993 0.0791 0.0685 0.0671 0.0676 0.0653 0.0648 0.0661 0.0661 0.0652 0.0667 0.0673 

[TRAIN] Epoch[5](997/1500); Loss: 0.068252; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1038 0.0897 0.0952 0.0823 0.0665 0.0571 0.0571 0.0564 0.0556 0.0577 0.0586 0.0585 0.0600 0.0637 0.0650 0.0649 

[TRAIN] Epoch[5](998/1500); Loss: 0.118274; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1509 0.1599 0.1511 0.1400 0.1302 0.1195 0.1107 0.1058 0.1047 0.1040 0.1022 0.1019 0.1024 0.1024 0.1026 0.1041 

[TRAIN] Epoch[5](999/1500); Loss: 0.160464; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.2047 0.2132 0.2025 0.1896 0.1756 0.1619 0.1516 0.1469 0.1431 0.1413 0.1405 0.1397 0.1393 0.1391 0.1388 0.1395 

[TRAIN] Epoch[5](1000/1500); Loss: 0.082219; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1241 0.1127 0.1093 0.0944 0.0812 0.0760 0.0750 0.0725 0.0729 0.0716 0.0700 0.0703 0.0703 0.0707 0.0714 0.0731 

[TRAIN] Epoch[5](1001/1500); Loss: 0.143377; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1796 0.2061 0.1929 0.1772 0.1598 0.1423 0.1315 0.1293 0.1240 0.1209 0.1218 0.1222 0.1212 0.1213 0.1220 0.1221 

[TRAIN] Epoch[5](1002/1500); Loss: 0.166267; Backpropagation: 0.0992 sec; Batch: 0.4364 sec
0.2115 0.2165 0.1995 0.1826 0.1687 0.1611 0.1576 0.1552 0.1538 0.1527 0.1513 0.1506 0.1499 0.1496 0.1494 0.1501 

[TRAIN] Epoch[5](1003/1500); Loss: 0.095601; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1577 0.1460 0.1336 0.1162 0.1017 0.0913 0.0814 0.0784 0.0784 0.0770 0.0761 0.0775 0.0774 0.0775 0.0794 0.0799 

[TRAIN] Epoch[5](1004/1500); Loss: 0.131929; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1961 0.1835 0.1710 0.1549 0.1396 0.1292 0.1224 0.1185 0.1144 0.1129 0.1116 0.1116 0.1118 0.1114 0.1111 0.1110 

[TRAIN] Epoch[5](1005/1500); Loss: 0.159007; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2408 0.2299 0.2022 0.1786 0.1605 0.1507 0.1444 0.1408 0.1386 0.1379 0.1370 0.1364 0.1364 0.1365 0.1366 0.1366 

[TRAIN] Epoch[5](1006/1500); Loss: 0.117460; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1936 0.1819 0.1677 0.1477 0.1289 0.1133 0.1012 0.0952 0.0942 0.0947 0.0930 0.0930 0.0933 0.0937 0.0937 0.0944 

[TRAIN] Epoch[5](1007/1500); Loss: 0.127327; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.1665 0.1819 0.1756 0.1602 0.1432 0.1270 0.1156 0.1108 0.1070 0.1061 0.1059 0.1062 0.1064 0.1071 0.1081 0.1098 

[TRAIN] Epoch[5](1008/1500); Loss: 0.108303; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1535 0.1766 0.1644 0.1459 0.1245 0.1062 0.0928 0.0852 0.0809 0.0799 0.0823 0.0845 0.0857 0.0877 0.0899 0.0927 

[TRAIN] Epoch[5](1009/1500); Loss: 0.068663; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1116 0.1264 0.1157 0.0959 0.0742 0.0588 0.0534 0.0522 0.0502 0.0506 0.0509 0.0502 0.0507 0.0524 0.0522 0.0534 

[TRAIN] Epoch[5](1010/1500); Loss: 0.129678; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1772 0.1781 0.1611 0.1467 0.1356 0.1259 0.1193 0.1188 0.1158 0.1141 0.1133 0.1137 0.1134 0.1134 0.1139 0.1144 

[TRAIN] Epoch[5](1011/1500); Loss: 0.156616; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2079 0.2329 0.2154 0.1918 0.1685 0.1509 0.1428 0.1379 0.1347 0.1326 0.1319 0.1314 0.1318 0.1315 0.1318 0.1321 

[TRAIN] Epoch[5](1012/1500); Loss: 0.153344; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2272 0.2509 0.2287 0.2083 0.1834 0.1581 0.1379 0.1273 0.1215 0.1204 0.1172 0.1155 0.1147 0.1146 0.1139 0.1139 

[TRAIN] Epoch[5](1013/1500); Loss: 0.131524; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1699 0.1913 0.1754 0.1612 0.1450 0.1296 0.1185 0.1154 0.1138 0.1131 0.1114 0.1109 0.1121 0.1116 0.1119 0.1134 

[TRAIN] Epoch[5](1014/1500); Loss: 0.154286; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2258 0.2042 0.1814 0.1701 0.1586 0.1497 0.1435 0.1406 0.1381 0.1368 0.1361 0.1360 0.1361 0.1362 0.1371 0.1382 

[TRAIN] Epoch[5](1015/1500); Loss: 0.105938; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1959 0.1571 0.1447 0.1290 0.1123 0.0983 0.0901 0.0846 0.0838 0.0847 0.0847 0.0844 0.0847 0.0856 0.0871 0.0879 

[TRAIN] Epoch[5](1016/1500); Loss: 0.116838; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1828 0.1805 0.1753 0.1598 0.1420 0.1266 0.1142 0.1050 0.0968 0.0903 0.0849 0.0812 0.0802 0.0815 0.0831 0.0851 

[TRAIN] Epoch[5](1017/1500); Loss: 0.148096; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1999 0.2049 0.1865 0.1750 0.1612 0.1450 0.1345 0.1308 0.1314 0.1296 0.1286 0.1286 0.1286 0.1283 0.1279 0.1286 

[TRAIN] Epoch[5](1018/1500); Loss: 0.128782; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1743 0.1736 0.1619 0.1473 0.1340 0.1250 0.1189 0.1174 0.1155 0.1142 0.1134 0.1130 0.1126 0.1127 0.1132 0.1135 

[TRAIN] Epoch[5](1019/1500); Loss: 0.217553; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.4729 0.4586 0.4085 0.3565 0.3041 0.2521 0.2002 0.1460 0.1114 0.1120 0.1122 0.1085 0.1077 0.1133 0.1096 0.1072 

[TRAIN] Epoch[5](1020/1500); Loss: 0.192728; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3327 0.3232 0.2984 0.2691 0.2411 0.2168 0.1904 0.1652 0.1443 0.1332 0.1278 0.1294 0.1282 0.1275 0.1276 0.1287 

[TRAIN] Epoch[5](1021/1500); Loss: 0.150748; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1709 0.2259 0.2282 0.2044 0.1757 0.1514 0.1364 0.1289 0.1259 0.1248 0.1232 0.1213 0.1228 0.1238 0.1239 0.1247 

[TRAIN] Epoch[5](1022/1500); Loss: 0.100897; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1348 0.1368 0.1325 0.1226 0.1092 0.0954 0.0880 0.0872 0.0872 0.0877 0.0873 0.0873 0.0881 0.0888 0.0898 0.0916 

[TRAIN] Epoch[5](1023/1500); Loss: 0.085301; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0915 0.1695 0.1697 0.1480 0.1190 0.0889 0.0674 0.0575 0.0545 0.0563 0.0556 0.0563 0.0563 0.0574 0.0578 0.0589 

[TRAIN] Epoch[5](1024/1500); Loss: 0.068279; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1234 0.1183 0.0982 0.0861 0.0733 0.0592 0.0517 0.0520 0.0528 0.0525 0.0526 0.0530 0.0539 0.0551 0.0549 0.0554 

[TRAIN] Epoch[5](1025/1500); Loss: 0.117540; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2216 0.2080 0.1839 0.1567 0.1321 0.1144 0.1023 0.0929 0.0882 0.0850 0.0826 0.0824 0.0827 0.0821 0.0825 0.0831 

[TRAIN] Epoch[5](1026/1500); Loss: 0.120631; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1715 0.1631 0.1489 0.1368 0.1244 0.1169 0.1153 0.1114 0.1076 0.1062 0.1062 0.1052 0.1043 0.1044 0.1040 0.1039 

[TRAIN] Epoch[5](1027/1500); Loss: 0.139502; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1849 0.1875 0.1746 0.1604 0.1458 0.1372 0.1323 0.1265 0.1239 0.1237 0.1231 0.1226 0.1225 0.1223 0.1222 0.1225 

[TRAIN] Epoch[5](1028/1500); Loss: 0.079589; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1168 0.1102 0.0920 0.0869 0.0772 0.0744 0.0701 0.0710 0.0713 0.0706 0.0708 0.0715 0.0716 0.0723 0.0732 0.0733 

[TRAIN] Epoch[5](1029/1500); Loss: 0.155097; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2507 0.2553 0.2320 0.2063 0.1808 0.1601 0.1425 0.1276 0.1191 0.1193 0.1160 0.1152 0.1140 0.1139 0.1142 0.1145 

[TRAIN] Epoch[5](1030/1500); Loss: 0.103077; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1238 0.1869 0.1721 0.1482 0.1178 0.0921 0.0851 0.0847 0.0784 0.0775 0.0802 0.0799 0.0780 0.0799 0.0829 0.0816 

[TRAIN] Epoch[5](1031/1500); Loss: 0.173506; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1894 0.2031 0.1980 0.1893 0.1797 0.1728 0.1686 0.1655 0.1647 0.1644 0.1642 0.1637 0.1632 0.1630 0.1631 0.1635 

[TRAIN] Epoch[5](1032/1500); Loss: 0.082533; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1145 0.1451 0.1321 0.1128 0.0927 0.0773 0.0683 0.0651 0.0627 0.0624 0.0627 0.0633 0.0636 0.0655 0.0662 0.0663 

[TRAIN] Epoch[5](1033/1500); Loss: 0.166522; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2710 0.2519 0.2185 0.1970 0.1801 0.1646 0.1544 0.1460 0.1404 0.1366 0.1355 0.1351 0.1343 0.1331 0.1329 0.1330 

[TRAIN] Epoch[5](1034/1500); Loss: 0.159116; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1814 0.1750 0.1722 0.1676 0.1632 0.1575 0.1554 0.1542 0.1526 0.1516 0.1518 0.1520 0.1520 0.1528 0.1531 0.1535 

[TRAIN] Epoch[5](1035/1500); Loss: 0.103412; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1956 0.1688 0.1288 0.1076 0.0985 0.0914 0.0883 0.0860 0.0872 0.0852 0.0844 0.0858 0.0858 0.0859 0.0869 0.0884 

[TRAIN] Epoch[5](1036/1500); Loss: 0.070606; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0997 0.0934 0.1039 0.0904 0.0737 0.0621 0.0600 0.0579 0.0573 0.0585 0.0589 0.0606 0.0606 0.0620 0.0641 0.0665 

[TRAIN] Epoch[5](1037/1500); Loss: 0.138598; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1785 0.1993 0.1843 0.1669 0.1470 0.1331 0.1265 0.1239 0.1216 0.1204 0.1202 0.1194 0.1186 0.1189 0.1193 0.1197 

[TRAIN] Epoch[5](1038/1500); Loss: 0.117095; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1362 0.1448 0.1417 0.1324 0.1220 0.1151 0.1128 0.1109 0.1096 0.1087 0.1079 0.1070 0.1065 0.1061 0.1058 0.1060 

[TRAIN] Epoch[5](1039/1500); Loss: 0.113165; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1435 0.1341 0.1198 0.1114 0.1086 0.1088 0.1084 0.1081 0.1083 0.1081 0.1080 0.1082 0.1083 0.1085 0.1090 0.1096 

[TRAIN] Epoch[5](1040/1500); Loss: 0.084761; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1267 0.1357 0.1213 0.1077 0.0929 0.0782 0.0702 0.0686 0.0686 0.0688 0.0686 0.0686 0.0688 0.0696 0.0706 0.0714 

[TRAIN] Epoch[5](1041/1500); Loss: 0.139268; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1879 0.2008 0.1823 0.1692 0.1535 0.1383 0.1298 0.1247 0.1230 0.1198 0.1179 0.1168 0.1165 0.1158 0.1158 0.1162 

[TRAIN] Epoch[5](1042/1500); Loss: 0.120504; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1713 0.1721 0.1536 0.1375 0.1224 0.1128 0.1073 0.1053 0.1052 0.1050 0.1041 0.1042 0.1050 0.1059 0.1070 0.1094 

[TRAIN] Epoch[5](1043/1500); Loss: 0.138884; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1942 0.1657 0.1646 0.1561 0.1469 0.1386 0.1344 0.1289 0.1260 0.1248 0.1235 0.1224 0.1228 0.1236 0.1239 0.1256 

[TRAIN] Epoch[5](1044/1500); Loss: 0.139851; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2157 0.2089 0.1878 0.1679 0.1512 0.1404 0.1314 0.1243 0.1193 0.1160 0.1136 0.1123 0.1119 0.1123 0.1124 0.1124 

[TRAIN] Epoch[5](1045/1500); Loss: 0.093384; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1334 0.1672 0.1480 0.1265 0.1040 0.0848 0.0767 0.0750 0.0724 0.0715 0.0719 0.0724 0.0717 0.0726 0.0728 0.0731 

[TRAIN] Epoch[5](1046/1500); Loss: 0.087650; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1719 0.1196 0.1011 0.0947 0.0870 0.0814 0.0761 0.0743 0.0752 0.0734 0.0721 0.0738 0.0747 0.0746 0.0753 0.0772 

[TRAIN] Epoch[5](1047/1500); Loss: 0.106713; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1316 0.1565 0.1477 0.1315 0.1151 0.1035 0.0995 0.0943 0.0927 0.0913 0.0905 0.0900 0.0901 0.0902 0.0910 0.0918 

[TRAIN] Epoch[5](1048/1500); Loss: 0.088138; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0911 0.1184 0.1494 0.1322 0.1115 0.0907 0.0758 0.0716 0.0698 0.0702 0.0694 0.0704 0.0710 0.0715 0.0723 0.0750 

[TRAIN] Epoch[5](1049/1500); Loss: 0.086246; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1162 0.1223 0.1226 0.1065 0.0912 0.0792 0.0740 0.0742 0.0737 0.0724 0.0730 0.0740 0.0742 0.0743 0.0757 0.0765 

[TRAIN] Epoch[5](1050/1500); Loss: 0.208842; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2809 0.2788 0.2588 0.2457 0.2317 0.2190 0.2074 0.1967 0.1884 0.1830 0.1792 0.1774 0.1751 0.1741 0.1730 0.1722 

[TRAIN] Epoch[5](1051/1500); Loss: 0.131515; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1849 0.1990 0.1807 0.1618 0.1435 0.1289 0.1208 0.1166 0.1119 0.1094 0.1086 0.1079 0.1076 0.1073 0.1074 0.1078 

[TRAIN] Epoch[5](1052/1500); Loss: 0.106547; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1438 0.1373 0.1265 0.1156 0.1057 0.1007 0.1010 0.0983 0.0967 0.0966 0.0970 0.0963 0.0962 0.0972 0.0977 0.0981 

[TRAIN] Epoch[5](1053/1500); Loss: 0.129036; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1649 0.1875 0.1774 0.1652 0.1486 0.1321 0.1190 0.1130 0.1095 0.1080 0.1065 0.1065 0.1063 0.1059 0.1066 0.1075 

[TRAIN] Epoch[5](1054/1500); Loss: 0.122745; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1854 0.1603 0.1527 0.1427 0.1326 0.1212 0.1175 0.1129 0.1097 0.1072 0.1039 0.1025 0.1036 0.1037 0.1034 0.1046 

[TRAIN] Epoch[5](1055/1500); Loss: 0.153842; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2082 0.1958 0.1768 0.1674 0.1599 0.1532 0.1490 0.1454 0.1426 0.1401 0.1385 0.1376 0.1369 0.1365 0.1365 0.1369 

[TRAIN] Epoch[5](1056/1500); Loss: 0.115465; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1461 0.1570 0.1663 0.1506 0.1332 0.1160 0.1055 0.1001 0.0982 0.0967 0.0963 0.0960 0.0963 0.0964 0.0961 0.0966 

[TRAIN] Epoch[5](1057/1500); Loss: 0.137520; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1588 0.2002 0.2057 0.1888 0.1676 0.1463 0.1318 0.1230 0.1166 0.1124 0.1112 0.1093 0.1080 0.1069 0.1072 0.1067 

[TRAIN] Epoch[5](1058/1500); Loss: 0.088024; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1287 0.1139 0.1076 0.1003 0.0888 0.0841 0.0821 0.0788 0.0776 0.0778 0.0772 0.0775 0.0778 0.0780 0.0785 0.0799 

[TRAIN] Epoch[5](1059/1500); Loss: 0.104376; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1572 0.1684 0.1738 0.1571 0.1378 0.1158 0.0940 0.0783 0.0721 0.0720 0.0729 0.0722 0.0728 0.0736 0.0753 0.0768 

[TRAIN] Epoch[5](1060/1500); Loss: 0.160359; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.3705 0.3381 0.2775 0.2340 0.2004 0.1623 0.1283 0.1068 0.0971 0.0955 0.0925 0.0912 0.0930 0.0942 0.0920 0.0923 

[TRAIN] Epoch[5](1061/1500); Loss: 0.135717; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2409 0.2269 0.2125 0.1873 0.1624 0.1389 0.1216 0.1103 0.1019 0.0998 0.0964 0.0942 0.0945 0.0950 0.0942 0.0947 

[TRAIN] Epoch[5](1062/1500); Loss: 0.215126; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.4118 0.3804 0.3260 0.2867 0.2623 0.2271 0.1887 0.1621 0.1510 0.1535 0.1494 0.1486 0.1483 0.1484 0.1494 0.1484 

[TRAIN] Epoch[5](1063/1500); Loss: 0.109603; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1489 0.1733 0.1616 0.1499 0.1331 0.1136 0.0981 0.0900 0.0888 0.0870 0.0866 0.0860 0.0858 0.0843 0.0833 0.0834 

[TRAIN] Epoch[5](1064/1500); Loss: 0.078314; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1454 0.1262 0.1015 0.0890 0.0785 0.0683 0.0646 0.0660 0.0642 0.0637 0.0637 0.0638 0.0639 0.0643 0.0649 0.0651 

[TRAIN] Epoch[5](1065/1500); Loss: 0.116926; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1862 0.1826 0.1567 0.1420 0.1272 0.1125 0.1035 0.1005 0.0982 0.0965 0.0949 0.0943 0.0940 0.0937 0.0936 0.0945 

[TRAIN] Epoch[5](1066/1500); Loss: 0.110802; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1769 0.1699 0.1525 0.1341 0.1186 0.1064 0.0998 0.0961 0.0924 0.0895 0.0883 0.0888 0.0889 0.0892 0.0901 0.0913 

[TRAIN] Epoch[5](1067/1500); Loss: 0.125277; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1561 0.1661 0.1550 0.1422 0.1292 0.1207 0.1164 0.1149 0.1141 0.1139 0.1133 0.1129 0.1127 0.1123 0.1123 0.1123 

[TRAIN] Epoch[5](1068/1500); Loss: 0.150952; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2353 0.2647 0.2404 0.2130 0.1836 0.1589 0.1409 0.1260 0.1175 0.1113 0.1064 0.1037 0.1030 0.1036 0.1036 0.1034 

[TRAIN] Epoch[5](1069/1500); Loss: 0.130324; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1743 0.1875 0.1802 0.1611 0.1410 0.1279 0.1228 0.1172 0.1123 0.1104 0.1095 0.1086 0.1081 0.1076 0.1084 0.1085 

[TRAIN] Epoch[5](1070/1500); Loss: 0.132996; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1722 0.1842 0.1668 0.1508 0.1369 0.1296 0.1256 0.1214 0.1186 0.1179 0.1171 0.1169 0.1171 0.1175 0.1177 0.1176 

[TRAIN] Epoch[5](1071/1500); Loss: 0.082872; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1137 0.1354 0.1282 0.1159 0.0979 0.0790 0.0670 0.0639 0.0638 0.0639 0.0643 0.0652 0.0654 0.0660 0.0675 0.0690 

[TRAIN] Epoch[5](1072/1500); Loss: 0.095663; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1173 0.1303 0.1326 0.1233 0.1092 0.0970 0.0872 0.0809 0.0787 0.0781 0.0784 0.0798 0.0811 0.0830 0.0855 0.0882 

[TRAIN] Epoch[5](1073/1500); Loss: 0.106652; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1579 0.1490 0.1302 0.1233 0.1134 0.1047 0.0986 0.0958 0.0944 0.0929 0.0918 0.0914 0.0910 0.0903 0.0905 0.0911 

[TRAIN] Epoch[5](1074/1500); Loss: 0.136160; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.3049 0.2756 0.2303 0.1951 0.1598 0.1237 0.0977 0.0911 0.0891 0.0880 0.0874 0.0867 0.0868 0.0869 0.0872 0.0882 

[TRAIN] Epoch[5](1075/1500); Loss: 0.131489; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1731 0.1907 0.1792 0.1592 0.1386 0.1245 0.1206 0.1167 0.1146 0.1128 0.1122 0.1117 0.1117 0.1124 0.1126 0.1133 

[TRAIN] Epoch[5](1076/1500); Loss: 0.097206; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1938 0.1344 0.0985 0.0904 0.0877 0.0855 0.0849 0.0847 0.0851 0.0855 0.0858 0.0863 0.0875 0.0879 0.0883 0.0892 

[TRAIN] Epoch[5](1077/1500); Loss: 0.079935; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1127 0.0973 0.0855 0.0834 0.0752 0.0741 0.0745 0.0738 0.0734 0.0742 0.0746 0.0748 0.0753 0.0759 0.0767 0.0776 

[TRAIN] Epoch[5](1078/1500); Loss: 0.140952; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1867 0.1622 0.1752 0.1630 0.1515 0.1404 0.1331 0.1315 0.1292 0.1265 0.1254 0.1264 0.1256 0.1255 0.1266 0.1266 

[TRAIN] Epoch[5](1079/1500); Loss: 0.121219; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2028 0.1651 0.1640 0.1471 0.1305 0.1167 0.1099 0.1044 0.1016 0.1019 0.0990 0.0982 0.0989 0.0991 0.0996 0.1007 

[TRAIN] Epoch[5](1080/1500); Loss: 0.152572; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1727 0.1743 0.1841 0.1744 0.1622 0.1529 0.1462 0.1416 0.1385 0.1373 0.1376 0.1393 0.1407 0.1438 0.1469 0.1488 

[TRAIN] Epoch[5](1081/1500); Loss: 0.065759; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0953 0.1100 0.0967 0.0816 0.0674 0.0579 0.0525 0.0533 0.0528 0.0523 0.0533 0.0537 0.0541 0.0563 0.0570 0.0579 

[TRAIN] Epoch[5](1082/1500); Loss: 0.101523; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1827 0.1534 0.1325 0.1193 0.1088 0.0977 0.0919 0.0883 0.0855 0.0830 0.0812 0.0807 0.0801 0.0794 0.0795 0.0803 

[TRAIN] Epoch[5](1083/1500); Loss: 0.085599; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1150 0.1576 0.1471 0.1283 0.1056 0.0870 0.0732 0.0655 0.0610 0.0601 0.0601 0.0605 0.0606 0.0615 0.0625 0.0641 

[TRAIN] Epoch[5](1084/1500); Loss: 0.123205; Backpropagation: 0.0926 sec; Batch: 0.4244 sec
0.1438 0.1910 0.1835 0.1669 0.1458 0.1264 0.1103 0.1044 0.1056 0.1001 0.0981 0.0990 0.0990 0.0981 0.0993 0.1001 

[TRAIN] Epoch[5](1085/1500); Loss: 0.076345; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1290 0.1469 0.1245 0.1042 0.0884 0.0724 0.0592 0.0534 0.0554 0.0556 0.0533 0.0538 0.0562 0.0550 0.0557 0.0586 

[TRAIN] Epoch[5](1086/1500); Loss: 0.184245; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3192 0.3223 0.2856 0.2509 0.2192 0.1872 0.1627 0.1449 0.1370 0.1346 0.1317 0.1305 0.1300 0.1301 0.1307 0.1316 

[TRAIN] Epoch[5](1087/1500); Loss: 0.092406; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1957 0.1251 0.1067 0.0979 0.0903 0.0815 0.0793 0.0770 0.0752 0.0771 0.0770 0.0762 0.0775 0.0797 0.0807 0.0815 

[TRAIN] Epoch[5](1088/1500); Loss: 0.103344; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1776 0.1392 0.1219 0.1125 0.1052 0.0987 0.0938 0.0914 0.0917 0.0893 0.0891 0.0893 0.0886 0.0884 0.0885 0.0883 

[TRAIN] Epoch[5](1089/1500); Loss: 0.096227; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1639 0.1515 0.1326 0.1159 0.1009 0.0906 0.0842 0.0814 0.0789 0.0774 0.0768 0.0770 0.0766 0.0768 0.0774 0.0778 

[TRAIN] Epoch[5](1090/1500); Loss: 0.080643; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1140 0.0977 0.1095 0.1014 0.0913 0.0792 0.0699 0.0662 0.0661 0.0659 0.0666 0.0684 0.0698 0.0720 0.0747 0.0777 

[TRAIN] Epoch[5](1091/1500); Loss: 0.083054; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0786 0.1429 0.1372 0.1169 0.0935 0.0739 0.0784 0.0683 0.0642 0.0651 0.0670 0.0669 0.0670 0.0687 0.0700 0.0702 

[TRAIN] Epoch[5](1092/1500); Loss: 0.089239; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1310 0.1176 0.1032 0.0975 0.0925 0.0876 0.0843 0.0824 0.0808 0.0792 0.0787 0.0784 0.0782 0.0782 0.0794 0.0789 

[TRAIN] Epoch[5](1093/1500); Loss: 0.061650; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1636 0.1304 0.0973 0.0767 0.0570 0.0493 0.0441 0.0410 0.0399 0.0397 0.0404 0.0403 0.0403 0.0414 0.0423 0.0427 

[TRAIN] Epoch[5](1094/1500); Loss: 0.120720; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1470 0.1571 0.1590 0.1450 0.1298 0.1172 0.1118 0.1076 0.1082 0.1074 0.1063 0.1059 0.1064 0.1071 0.1073 0.1081 

[TRAIN] Epoch[5](1095/1500); Loss: 0.128661; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1731 0.1858 0.1816 0.1649 0.1455 0.1284 0.1152 0.1089 0.1094 0.1068 0.1054 0.1063 0.1068 0.1066 0.1066 0.1072 

[TRAIN] Epoch[5](1096/1500); Loss: 0.118530; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1657 0.1798 0.1720 0.1554 0.1381 0.1226 0.1100 0.1001 0.0926 0.0905 0.0905 0.0913 0.0930 0.0958 0.0983 0.1010 

[TRAIN] Epoch[5](1097/1500); Loss: 0.170332; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2884 0.2782 0.2525 0.2282 0.2047 0.1818 0.1608 0.1432 0.1305 0.1261 0.1256 0.1227 0.1210 0.1209 0.1204 0.1202 

[TRAIN] Epoch[5](1098/1500); Loss: 0.077647; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1212 0.1133 0.1035 0.0897 0.0761 0.0717 0.0714 0.0671 0.0654 0.0661 0.0648 0.0648 0.0665 0.0658 0.0664 0.0687 

[TRAIN] Epoch[5](1099/1500); Loss: 0.068809; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2107 0.0739 0.0852 0.0616 0.0444 0.0398 0.0473 0.0544 0.0519 0.0515 0.0558 0.0592 0.0592 0.0624 0.0705 0.0730 

[TRAIN] Epoch[5](1100/1500); Loss: 0.179371; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2327 0.2351 0.2250 0.2105 0.1961 0.1835 0.1726 0.1652 0.1599 0.1579 0.1565 0.1553 0.1549 0.1548 0.1547 0.1553 

[TRAIN] Epoch[5](1101/1500); Loss: 0.132650; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1599 0.2088 0.2048 0.1850 0.1624 0.1413 0.1265 0.1154 0.1079 0.1049 0.1032 0.1017 0.1002 0.1002 0.1001 0.1000 

[TRAIN] Epoch[5](1102/1500); Loss: 0.086074; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1279 0.1276 0.1209 0.1061 0.0920 0.0835 0.0767 0.0738 0.0718 0.0711 0.0709 0.0707 0.0707 0.0704 0.0711 0.0719 

[TRAIN] Epoch[5](1103/1500); Loss: 0.118298; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1941 0.1819 0.1533 0.1336 0.1197 0.1082 0.1026 0.1022 0.1001 0.0996 0.0998 0.0992 0.0993 0.1002 0.0992 0.0996 

[TRAIN] Epoch[5](1104/1500); Loss: 0.196010; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.4724 0.4278 0.3603 0.3114 0.2689 0.2136 0.1560 0.1147 0.1013 0.1180 0.1010 0.0972 0.0973 0.1006 0.1000 0.0957 

[TRAIN] Epoch[5](1105/1500); Loss: 0.131262; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1725 0.1811 0.1675 0.1532 0.1410 0.1310 0.1235 0.1191 0.1168 0.1146 0.1137 0.1134 0.1131 0.1132 0.1132 0.1133 

[TRAIN] Epoch[5](1106/1500); Loss: 0.077420; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0822 0.0896 0.1429 0.1279 0.1109 0.0869 0.0689 0.0592 0.0572 0.0577 0.0564 0.0567 0.0595 0.0609 0.0603 0.0614 

[TRAIN] Epoch[5](1107/1500); Loss: 0.160412; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2440 0.2660 0.2416 0.2168 0.1916 0.1692 0.1489 0.1336 0.1248 0.1234 0.1217 0.1188 0.1172 0.1171 0.1167 0.1153 

[TRAIN] Epoch[5](1108/1500); Loss: 0.112011; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1862 0.1711 0.1427 0.1262 0.1132 0.1029 0.0986 0.0956 0.0945 0.0940 0.0940 0.0943 0.0945 0.0944 0.0946 0.0953 

[TRAIN] Epoch[5](1109/1500); Loss: 0.115878; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1431 0.1938 0.1832 0.1642 0.1405 0.1185 0.0997 0.0925 0.0961 0.0908 0.0878 0.0891 0.0899 0.0885 0.0877 0.0887 

[TRAIN] Epoch[5](1110/1500); Loss: 0.112751; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1364 0.1730 0.1758 0.1578 0.1368 0.1163 0.1010 0.0934 0.0899 0.0883 0.0881 0.0876 0.0877 0.0896 0.0909 0.0912 

[TRAIN] Epoch[5](1111/1500); Loss: 0.110132; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1691 0.1417 0.1284 0.1177 0.1101 0.1035 0.1000 0.0992 0.0994 0.0990 0.0986 0.0985 0.0983 0.0986 0.0996 0.1005 

[TRAIN] Epoch[5](1112/1500); Loss: 0.114887; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1899 0.1998 0.1746 0.1501 0.1251 0.1073 0.1001 0.0937 0.0902 0.0885 0.0874 0.0870 0.0864 0.0861 0.0858 0.0861 

[TRAIN] Epoch[5](1113/1500); Loss: 0.149701; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2201 0.2085 0.1920 0.1795 0.1671 0.1540 0.1439 0.1370 0.1314 0.1279 0.1254 0.1233 0.1221 0.1214 0.1207 0.1211 

[TRAIN] Epoch[5](1114/1500); Loss: 0.098146; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1231 0.1623 0.1662 0.1531 0.1342 0.1137 0.0936 0.0790 0.0701 0.0676 0.0670 0.0665 0.0673 0.0683 0.0686 0.0698 

[TRAIN] Epoch[5](1115/1500); Loss: 0.161617; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2007 0.1943 0.1916 0.1816 0.1708 0.1624 0.1572 0.1544 0.1521 0.1499 0.1483 0.1472 0.1458 0.1442 0.1433 0.1422 

[TRAIN] Epoch[5](1116/1500); Loss: 0.073157; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1070 0.1020 0.0938 0.0817 0.0715 0.0681 0.0676 0.0650 0.0638 0.0641 0.0637 0.0633 0.0648 0.0638 0.0641 0.0662 

[TRAIN] Epoch[5](1117/1500); Loss: 0.090985; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1192 0.1373 0.1366 0.1188 0.1011 0.0892 0.0838 0.0788 0.0765 0.0765 0.0746 0.0728 0.0723 0.0723 0.0730 0.0730 

[TRAIN] Epoch[5](1118/1500); Loss: 0.062390; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0688 0.0785 0.1059 0.0941 0.0784 0.0605 0.0522 0.0559 0.0510 0.0495 0.0501 0.0499 0.0498 0.0506 0.0509 0.0521 

[TRAIN] Epoch[5](1119/1500); Loss: 0.161375; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2338 0.2194 0.2017 0.1880 0.1758 0.1663 0.1597 0.1543 0.1485 0.1439 0.1403 0.1362 0.1326 0.1298 0.1268 0.1248 

[TRAIN] Epoch[5](1120/1500); Loss: 0.122334; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1907 0.1694 0.1495 0.1402 0.1298 0.1210 0.1149 0.1098 0.1075 0.1053 0.1040 0.1039 0.1030 0.1022 0.1029 0.1031 

[TRAIN] Epoch[5](1121/1500); Loss: 0.069837; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1336 0.0708 0.1103 0.0930 0.0768 0.0630 0.0566 0.0555 0.0536 0.0533 0.0552 0.0566 0.0576 0.0586 0.0610 0.0617 

[TRAIN] Epoch[5](1122/1500); Loss: 0.112426; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1854 0.1460 0.1230 0.1157 0.1117 0.1088 0.1044 0.1028 0.1021 0.1010 0.1000 0.1002 0.0996 0.0987 0.0996 0.0997 

[TRAIN] Epoch[5](1123/1500); Loss: 0.120832; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1570 0.1402 0.1422 0.1321 0.1222 0.1174 0.1179 0.1154 0.1135 0.1130 0.1114 0.1107 0.1101 0.1098 0.1100 0.1105 

[TRAIN] Epoch[5](1124/1500); Loss: 0.138185; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1910 0.1813 0.1800 0.1658 0.1504 0.1364 0.1278 0.1240 0.1219 0.1188 0.1180 0.1185 0.1186 0.1190 0.1196 0.1199 

[TRAIN] Epoch[5](1125/1500); Loss: 0.068310; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1085 0.1052 0.0892 0.0811 0.0703 0.0637 0.0577 0.0562 0.0567 0.0560 0.0561 0.0574 0.0568 0.0587 0.0598 0.0596 

[TRAIN] Epoch[5](1126/1500); Loss: 0.077882; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2115 0.0781 0.1003 0.0765 0.0563 0.0483 0.0551 0.0651 0.0639 0.0580 0.0658 0.0694 0.0689 0.0700 0.0767 0.0823 

[TRAIN] Epoch[5](1127/1500); Loss: 0.095671; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1388 0.1457 0.1282 0.1168 0.1023 0.0892 0.0848 0.0845 0.0811 0.0797 0.0806 0.0797 0.0791 0.0804 0.0798 0.0799 

[TRAIN] Epoch[5](1128/1500); Loss: 0.134803; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1606 0.1691 0.1583 0.1471 0.1354 0.1274 0.1235 0.1229 0.1241 0.1242 0.1250 0.1258 0.1270 0.1277 0.1288 0.1300 

[TRAIN] Epoch[5](1129/1500); Loss: 0.109367; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1283 0.1345 0.1358 0.1252 0.1144 0.1072 0.1040 0.1018 0.0999 0.1002 0.0999 0.0996 0.0994 0.0994 0.1001 0.1001 

[TRAIN] Epoch[5](1130/1500); Loss: 0.123123; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1502 0.1552 0.1552 0.1425 0.1309 0.1225 0.1182 0.1146 0.1128 0.1113 0.1094 0.1094 0.1093 0.1090 0.1092 0.1101 

[TRAIN] Epoch[5](1131/1500); Loss: 0.090754; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1579 0.1285 0.1064 0.0938 0.0871 0.0839 0.0809 0.0801 0.0798 0.0787 0.0783 0.0785 0.0790 0.0788 0.0798 0.0806 

[TRAIN] Epoch[5](1132/1500); Loss: 0.070762; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1135 0.0838 0.0986 0.0883 0.0759 0.0665 0.0603 0.0575 0.0574 0.0582 0.0592 0.0606 0.0605 0.0625 0.0649 0.0645 

[TRAIN] Epoch[5](1133/1500); Loss: 0.069478; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1372 0.1118 0.0920 0.0779 0.0654 0.0600 0.0562 0.0550 0.0554 0.0557 0.0555 0.0565 0.0571 0.0578 0.0586 0.0595 

[TRAIN] Epoch[5](1134/1500); Loss: 0.108697; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1221 0.1398 0.1344 0.1260 0.1156 0.1064 0.1029 0.1015 0.0998 0.0986 0.0988 0.0985 0.0984 0.0986 0.0987 0.0990 

[TRAIN] Epoch[5](1135/1500); Loss: 0.149219; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2172 0.2004 0.1790 0.1665 0.1572 0.1491 0.1430 0.1377 0.1338 0.1310 0.1295 0.1289 0.1285 0.1282 0.1285 0.1290 

[TRAIN] Epoch[5](1136/1500); Loss: 0.146094; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2103 0.1994 0.1796 0.1653 0.1530 0.1427 0.1379 0.1344 0.1304 0.1283 0.1277 0.1267 0.1258 0.1254 0.1255 0.1254 

[TRAIN] Epoch[5](1137/1500); Loss: 0.096959; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1113 0.1679 0.1645 0.1458 0.1234 0.1017 0.0854 0.0773 0.0723 0.0692 0.0712 0.0711 0.0711 0.0718 0.0739 0.0737 

[TRAIN] Epoch[5](1138/1500); Loss: 0.137566; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1790 0.1904 0.1824 0.1662 0.1504 0.1395 0.1327 0.1268 0.1207 0.1172 0.1170 0.1169 0.1159 0.1150 0.1153 0.1155 

[TRAIN] Epoch[5](1139/1500); Loss: 0.088854; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1294 0.1686 0.1525 0.1370 0.1173 0.0963 0.0796 0.0680 0.0613 0.0580 0.0583 0.0581 0.0589 0.0591 0.0591 0.0599 

[TRAIN] Epoch[5](1140/1500); Loss: 0.102979; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1753 0.1503 0.1293 0.1160 0.1057 0.0965 0.0919 0.0896 0.0883 0.0875 0.0867 0.0860 0.0862 0.0859 0.0858 0.0866 

[TRAIN] Epoch[5](1141/1500); Loss: 0.091185; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1404 0.1547 0.1418 0.1248 0.1077 0.0939 0.0835 0.0757 0.0707 0.0684 0.0680 0.0670 0.0661 0.0660 0.0654 0.0650 

[TRAIN] Epoch[5](1142/1500); Loss: 0.105517; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1491 0.1608 0.1653 0.1488 0.1308 0.1127 0.0982 0.0882 0.0823 0.0802 0.0783 0.0770 0.0777 0.0791 0.0795 0.0802 

[TRAIN] Epoch[5](1143/1500); Loss: 0.129098; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2496 0.1983 0.1550 0.1422 0.1340 0.1267 0.1194 0.1123 0.1076 0.1038 0.1009 0.1012 0.1029 0.1029 0.1038 0.1050 

[TRAIN] Epoch[5](1144/1500); Loss: 0.134774; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1834 0.1896 0.1742 0.1602 0.1475 0.1367 0.1273 0.1221 0.1185 0.1162 0.1153 0.1141 0.1133 0.1132 0.1128 0.1120 

[TRAIN] Epoch[5](1145/1500); Loss: 0.116274; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1471 0.1811 0.1742 0.1532 0.1310 0.1173 0.1096 0.1046 0.0999 0.0967 0.0944 0.0923 0.0899 0.0892 0.0896 0.0903 

[TRAIN] Epoch[5](1146/1500); Loss: 0.265836; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.4470 0.4344 0.3912 0.3583 0.3392 0.3141 0.2819 0.2470 0.2201 0.1959 0.1755 0.1682 0.1718 0.1696 0.1698 0.1695 

[TRAIN] Epoch[5](1147/1500); Loss: 0.114641; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1425 0.1595 0.1628 0.1479 0.1314 0.1165 0.1070 0.1001 0.0964 0.0967 0.0968 0.0946 0.0946 0.0951 0.0958 0.0964 

[TRAIN] Epoch[5](1148/1500); Loss: 0.060728; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1105 0.0879 0.0779 0.0682 0.0617 0.0560 0.0530 0.0515 0.0525 0.0499 0.0492 0.0510 0.0493 0.0499 0.0520 0.0511 

[TRAIN] Epoch[5](1149/1500); Loss: 0.066532; Backpropagation: 0.0922 sec; Batch: 0.4232 sec
0.1221 0.0610 0.1132 0.0954 0.0773 0.0606 0.0523 0.0512 0.0518 0.0511 0.0505 0.0528 0.0549 0.0548 0.0561 0.0597 

[TRAIN] Epoch[5](1150/1500); Loss: 0.097580; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2551 0.1822 0.1077 0.1013 0.0917 0.0900 0.0839 0.0767 0.0744 0.0716 0.0715 0.0703 0.0704 0.0709 0.0711 0.0725 

[TRAIN] Epoch[5](1151/1500); Loss: 0.168815; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2282 0.2265 0.2086 0.1937 0.1815 0.1735 0.1665 0.1595 0.1544 0.1512 0.1479 0.1451 0.1433 0.1421 0.1402 0.1388 

[TRAIN] Epoch[5](1152/1500); Loss: 0.099982; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1676 0.0901 0.1254 0.1111 0.0995 0.0927 0.0895 0.0886 0.0866 0.0870 0.0893 0.0904 0.0924 0.0940 0.0965 0.0991 

[TRAIN] Epoch[5](1153/1500); Loss: 0.093839; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2267 0.2211 0.1813 0.1448 0.1219 0.1038 0.0796 0.0552 0.0466 0.0466 0.0460 0.0450 0.0456 0.0464 0.0446 0.0462 

[TRAIN] Epoch[5](1154/1500); Loss: 0.122127; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2267 0.2282 0.2015 0.1769 0.1549 0.1342 0.1154 0.0999 0.0878 0.0793 0.0754 0.0744 0.0742 0.0751 0.0750 0.0752 

[TRAIN] Epoch[5](1155/1500); Loss: 0.131001; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1889 0.2055 0.1902 0.1716 0.1538 0.1411 0.1298 0.1186 0.1098 0.1040 0.0996 0.0969 0.0966 0.0965 0.0965 0.0967 

[TRAIN] Epoch[5](1156/1500); Loss: 0.118674; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1385 0.1535 0.1482 0.1352 0.1223 0.1144 0.1117 0.1097 0.1086 0.1088 0.1087 0.1078 0.1074 0.1076 0.1080 0.1083 

[TRAIN] Epoch[5](1157/1500); Loss: 0.124282; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1678 0.1725 0.1534 0.1434 0.1316 0.1217 0.1158 0.1126 0.1109 0.1099 0.1086 0.1079 0.1074 0.1079 0.1084 0.1088 

[TRAIN] Epoch[5](1158/1500); Loss: 0.126635; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1825 0.1777 0.1631 0.1499 0.1388 0.1302 0.1231 0.1173 0.1121 0.1086 0.1063 0.1046 0.1035 0.1030 0.1027 0.1027 

[TRAIN] Epoch[5](1159/1500); Loss: 0.091671; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1040 0.1197 0.1190 0.1096 0.0990 0.0906 0.0854 0.0829 0.0819 0.0819 0.0815 0.0816 0.0817 0.0819 0.0828 0.0833 

[TRAIN] Epoch[5](1160/1500); Loss: 0.091671; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1899 0.1461 0.1039 0.0951 0.0878 0.0836 0.0803 0.0777 0.0754 0.0743 0.0744 0.0740 0.0752 0.0758 0.0764 0.0767 

[TRAIN] Epoch[5](1161/1500); Loss: 0.115703; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1501 0.1665 0.1520 0.1367 0.1223 0.1114 0.1054 0.1036 0.1033 0.1011 0.1001 0.1003 0.0998 0.0992 0.0996 0.0998 

[TRAIN] Epoch[5](1162/1500); Loss: 0.090666; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1785 0.1189 0.0914 0.0910 0.0893 0.0807 0.0773 0.0772 0.0781 0.0789 0.0789 0.0800 0.0809 0.0819 0.0833 0.0847 

[TRAIN] Epoch[5](1163/1500); Loss: 0.152705; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1805 0.1759 0.1760 0.1677 0.1593 0.1536 0.1503 0.1473 0.1449 0.1433 0.1421 0.1416 0.1408 0.1402 0.1399 0.1400 

[TRAIN] Epoch[5](1164/1500); Loss: 0.085360; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1435 0.1089 0.0877 0.0831 0.0792 0.0789 0.0807 0.0782 0.0779 0.0775 0.0768 0.0775 0.0792 0.0779 0.0788 0.0800 

[TRAIN] Epoch[5](1165/1500); Loss: 0.057915; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0832 0.0768 0.0727 0.0649 0.0593 0.0569 0.0534 0.0506 0.0508 0.0504 0.0492 0.0503 0.0508 0.0512 0.0526 0.0535 

[TRAIN] Epoch[5](1166/1500); Loss: 0.087675; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1539 0.1542 0.1336 0.1160 0.1011 0.0891 0.0775 0.0685 0.0647 0.0640 0.0639 0.0631 0.0629 0.0638 0.0630 0.0635 

[TRAIN] Epoch[5](1167/1500); Loss: 0.104586; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1698 0.1443 0.1272 0.1193 0.1104 0.1016 0.0959 0.0921 0.0904 0.0895 0.0888 0.0886 0.0888 0.0886 0.0890 0.0891 

[TRAIN] Epoch[5](1168/1500); Loss: 0.114330; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2349 0.2246 0.1964 0.1729 0.1550 0.1383 0.1174 0.0956 0.0762 0.0634 0.0575 0.0579 0.0603 0.0596 0.0586 0.0607 

[TRAIN] Epoch[5](1169/1500); Loss: 0.254067; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.3876 0.3774 0.3416 0.3162 0.3020 0.2846 0.2635 0.2405 0.2232 0.2087 0.1946 0.1866 0.1848 0.1862 0.1839 0.1836 

[TRAIN] Epoch[5](1170/1500); Loss: 0.083918; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2118 0.0792 0.1023 0.0805 0.0665 0.0565 0.0585 0.0702 0.0706 0.0706 0.0721 0.0737 0.0779 0.0802 0.0837 0.0883 

[TRAIN] Epoch[5](1171/1500); Loss: 0.113745; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1687 0.1457 0.1339 0.1260 0.1195 0.1129 0.1086 0.1053 0.1025 0.1001 0.0995 0.0992 0.0992 0.0992 0.0997 0.1000 

[TRAIN] Epoch[5](1172/1500); Loss: 0.060011; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1689 0.0911 0.0733 0.0629 0.0575 0.0515 0.0471 0.0435 0.0433 0.0453 0.0433 0.0430 0.0460 0.0472 0.0473 0.0489 

[TRAIN] Epoch[5](1173/1500); Loss: 0.102704; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1407 0.1575 0.1432 0.1266 0.1118 0.1017 0.0958 0.0916 0.0871 0.0853 0.0850 0.0838 0.0831 0.0833 0.0834 0.0834 

[TRAIN] Epoch[5](1174/1500); Loss: 0.087776; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1327 0.1381 0.1306 0.1151 0.1004 0.0897 0.0824 0.0774 0.0725 0.0693 0.0675 0.0658 0.0650 0.0651 0.0659 0.0667 

[TRAIN] Epoch[5](1175/1500); Loss: 0.195911; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3878 0.3775 0.3311 0.2916 0.2684 0.2455 0.2147 0.1812 0.1527 0.1320 0.1117 0.0959 0.0890 0.0853 0.0851 0.0851 

[TRAIN] Epoch[5](1176/1500); Loss: 0.089324; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1955 0.1934 0.1587 0.1290 0.1101 0.0936 0.0758 0.0598 0.0534 0.0527 0.0523 0.0511 0.0507 0.0512 0.0510 0.0509 

[TRAIN] Epoch[5](1177/1500); Loss: 0.109806; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1911 0.1818 0.1564 0.1352 0.1207 0.1115 0.1034 0.0966 0.0902 0.0854 0.0827 0.0812 0.0800 0.0800 0.0801 0.0806 

[TRAIN] Epoch[5](1178/1500); Loss: 0.166628; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2368 0.2508 0.2308 0.2116 0.1941 0.1791 0.1649 0.1527 0.1424 0.1356 0.1319 0.1294 0.1271 0.1264 0.1261 0.1263 

[TRAIN] Epoch[5](1179/1500); Loss: 0.158750; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2026 0.1804 0.1830 0.1757 0.1683 0.1616 0.1572 0.1542 0.1511 0.1484 0.1464 0.1445 0.1427 0.1415 0.1411 0.1413 

[TRAIN] Epoch[5](1180/1500); Loss: 0.057444; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.0819 0.0788 0.0764 0.0676 0.0606 0.0579 0.0526 0.0497 0.0491 0.0487 0.0481 0.0480 0.0488 0.0492 0.0500 0.0518 

[TRAIN] Epoch[5](1181/1500); Loss: 0.125330; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1258 0.1450 0.1481 0.1407 0.1314 0.1237 0.1206 0.1208 0.1198 0.1187 0.1185 0.1178 0.1176 0.1183 0.1189 0.1195 

[TRAIN] Epoch[5](1182/1500); Loss: 0.087580; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1182 0.1332 0.1256 0.1121 0.0991 0.0870 0.0780 0.0750 0.0737 0.0730 0.0716 0.0709 0.0707 0.0704 0.0713 0.0715 

[TRAIN] Epoch[5](1183/1500); Loss: 0.109794; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1703 0.1484 0.1410 0.1344 0.1250 0.1117 0.1043 0.0986 0.0951 0.0928 0.0896 0.0884 0.0893 0.0880 0.0889 0.0908 

[TRAIN] Epoch[5](1184/1500); Loss: 0.125242; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1410 0.1775 0.1681 0.1535 0.1395 0.1278 0.1195 0.1135 0.1111 0.1084 0.1075 0.1069 0.1073 0.1071 0.1077 0.1075 

[TRAIN] Epoch[5](1185/1500); Loss: 0.076415; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1043 0.1400 0.1276 0.1101 0.0908 0.0710 0.0599 0.0578 0.0586 0.0576 0.0569 0.0569 0.0574 0.0574 0.0578 0.0587 

[TRAIN] Epoch[5](1186/1500); Loss: 0.172489; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2230 0.2134 0.1983 0.1884 0.1810 0.1738 0.1675 0.1626 0.1606 0.1594 0.1577 0.1565 0.1557 0.1545 0.1539 0.1535 

[TRAIN] Epoch[5](1187/1500); Loss: 0.061834; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1325 0.0755 0.0959 0.0830 0.0728 0.0599 0.0515 0.0467 0.0467 0.0459 0.0439 0.0443 0.0470 0.0465 0.0476 0.0496 

[TRAIN] Epoch[5](1188/1500); Loss: 0.104407; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1217 0.1625 0.1516 0.1357 0.1168 0.1019 0.0943 0.0912 0.0889 0.0885 0.0879 0.0869 0.0862 0.0858 0.0854 0.0852 

[TRAIN] Epoch[5](1189/1500); Loss: 0.116768; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1362 0.1401 0.1365 0.1285 0.1204 0.1159 0.1156 0.1109 0.1085 0.1084 0.1074 0.1071 0.1078 0.1077 0.1081 0.1092 

[TRAIN] Epoch[5](1190/1500); Loss: 0.111346; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1192 0.1415 0.1456 0.1340 0.1200 0.1097 0.1053 0.1048 0.1034 0.1010 0.1007 0.0993 0.0990 0.0994 0.0996 0.0990 

[TRAIN] Epoch[5](1191/1500); Loss: 0.108958; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1952 0.1893 0.1675 0.1464 0.1289 0.1139 0.0998 0.0890 0.0829 0.0786 0.0767 0.0767 0.0757 0.0750 0.0741 0.0738 

[TRAIN] Epoch[5](1192/1500); Loss: 0.193384; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.3831 0.3786 0.3385 0.3056 0.2807 0.2532 0.2188 0.1844 0.1533 0.1243 0.0957 0.0762 0.0723 0.0758 0.0780 0.0756 

[TRAIN] Epoch[5](1193/1500); Loss: 0.218992; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3420 0.3319 0.2955 0.2706 0.2571 0.2399 0.2190 0.1981 0.1845 0.1738 0.1676 0.1668 0.1666 0.1639 0.1635 0.1630 

[TRAIN] Epoch[5](1194/1500); Loss: 0.098813; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1692 0.1704 0.1477 0.1286 0.1131 0.0994 0.0875 0.0797 0.0749 0.0730 0.0724 0.0726 0.0726 0.0727 0.0734 0.0738 

[TRAIN] Epoch[5](1195/1500); Loss: 0.169465; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1966 0.2189 0.2073 0.1925 0.1788 0.1691 0.1628 0.1592 0.1576 0.1557 0.1542 0.1526 0.1518 0.1517 0.1512 0.1515 

[TRAIN] Epoch[5](1196/1500); Loss: 0.120970; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1414 0.1845 0.1737 0.1588 0.1405 0.1272 0.1156 0.1072 0.1017 0.0983 0.0973 0.0976 0.0970 0.0971 0.0983 0.0994 

[TRAIN] Epoch[5](1197/1500); Loss: 0.140126; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1704 0.1798 0.1740 0.1615 0.1490 0.1418 0.1357 0.1299 0.1263 0.1237 0.1218 0.1222 0.1236 0.1252 0.1268 0.1302 

[TRAIN] Epoch[5](1198/1500); Loss: 0.087673; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1146 0.1068 0.1000 0.0931 0.0888 0.0885 0.0841 0.0807 0.0806 0.0797 0.0787 0.0799 0.0802 0.0810 0.0826 0.0836 

[TRAIN] Epoch[5](1199/1500); Loss: 0.122758; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1367 0.1508 0.1437 0.1344 0.1269 0.1232 0.1201 0.1175 0.1158 0.1145 0.1138 0.1135 0.1132 0.1131 0.1132 0.1138 

[TRAIN] Epoch[5](1200/1500); Loss: 0.113160; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1545 0.1774 0.1613 0.1434 0.1261 0.1131 0.1054 0.1007 0.0968 0.0946 0.0922 0.0905 0.0893 0.0887 0.0883 0.0883 

[TRAIN] Epoch[5](1201/1500); Loss: 0.172372; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2462 0.2411 0.2197 0.2027 0.1906 0.1789 0.1673 0.1572 0.1498 0.1459 0.1444 0.1441 0.1430 0.1424 0.1424 0.1423 

[TRAIN] Epoch[5](1202/1500); Loss: 0.068889; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1543 0.1361 0.1057 0.0883 0.0764 0.0662 0.0591 0.0525 0.0476 0.0457 0.0443 0.0441 0.0451 0.0452 0.0453 0.0462 

[TRAIN] Epoch[5](1203/1500); Loss: 0.112473; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1582 0.1397 0.1284 0.1227 0.1173 0.1116 0.1079 0.1045 0.1027 0.1013 0.1005 0.1003 0.1009 0.1008 0.1010 0.1017 

[TRAIN] Epoch[5](1204/1500); Loss: 0.132637; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1521 0.1648 0.1639 0.1536 0.1423 0.1325 0.1275 0.1243 0.1231 0.1220 0.1204 0.1197 0.1197 0.1191 0.1185 0.1186 

[TRAIN] Epoch[5](1205/1500); Loss: 0.180323; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2729 0.2735 0.2487 0.2298 0.2152 0.2013 0.1870 0.1743 0.1639 0.1532 0.1436 0.1347 0.1272 0.1218 0.1192 0.1187 

[TRAIN] Epoch[5](1206/1500); Loss: 0.097141; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1353 0.1593 0.1462 0.1293 0.1104 0.0928 0.0817 0.0801 0.0786 0.0776 0.0763 0.0770 0.0771 0.0770 0.0776 0.0780 

[TRAIN] Epoch[5](1207/1500); Loss: 0.079155; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1862 0.1189 0.0860 0.0802 0.0745 0.0697 0.0670 0.0650 0.0644 0.0642 0.0636 0.0642 0.0646 0.0657 0.0658 0.0665 

[TRAIN] Epoch[5](1208/1500); Loss: 0.093332; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1293 0.1553 0.1389 0.1215 0.1052 0.0930 0.0850 0.0788 0.0758 0.0745 0.0729 0.0728 0.0725 0.0727 0.0724 0.0726 

[TRAIN] Epoch[5](1209/1500); Loss: 0.098717; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1441 0.1235 0.1144 0.1073 0.1006 0.0930 0.0916 0.0900 0.0893 0.0891 0.0882 0.0878 0.0884 0.0899 0.0903 0.0920 

[TRAIN] Epoch[5](1210/1500); Loss: 0.161263; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2014 0.2047 0.1905 0.1789 0.1696 0.1636 0.1585 0.1539 0.1514 0.1490 0.1466 0.1446 0.1431 0.1422 0.1414 0.1408 

[TRAIN] Epoch[5](1211/1500); Loss: 0.065322; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1495 0.1261 0.0953 0.0813 0.0701 0.0617 0.0553 0.0500 0.0457 0.0440 0.0430 0.0437 0.0444 0.0439 0.0451 0.0460 

[TRAIN] Epoch[5](1212/1500); Loss: 0.160260; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.2478 0.2470 0.2196 0.1990 0.1839 0.1679 0.1523 0.1385 0.1304 0.1260 0.1259 0.1254 0.1247 0.1251 0.1253 0.1256 

[TRAIN] Epoch[5](1213/1500); Loss: 0.118941; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1593 0.1533 0.1491 0.1377 0.1267 0.1163 0.1103 0.1066 0.1066 0.1061 0.1060 0.1050 0.1046 0.1045 0.1050 0.1060 

[TRAIN] Epoch[5](1214/1500); Loss: 0.077305; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0921 0.1010 0.0991 0.0905 0.0813 0.0751 0.0719 0.0704 0.0699 0.0693 0.0690 0.0689 0.0689 0.0694 0.0699 0.0703 

[TRAIN] Epoch[5](1215/1500); Loss: 0.110310; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1685 0.1596 0.1427 0.1283 0.1171 0.1090 0.1035 0.0989 0.0955 0.0938 0.0924 0.0921 0.0913 0.0904 0.0908 0.0911 

[TRAIN] Epoch[5](1216/1500); Loss: 0.114702; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1701 0.1580 0.1374 0.1272 0.1206 0.1130 0.1069 0.1029 0.1011 0.1002 0.0997 0.0994 0.0992 0.0995 0.0999 0.1003 

[TRAIN] Epoch[5](1217/1500); Loss: 0.146813; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1911 0.1612 0.1727 0.1611 0.1480 0.1420 0.1374 0.1347 0.1342 0.1357 0.1360 0.1374 0.1382 0.1385 0.1397 0.1411 

[TRAIN] Epoch[5](1218/1500); Loss: 0.158688; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1973 0.1978 0.1825 0.1746 0.1678 0.1588 0.1510 0.1482 0.1478 0.1449 0.1449 0.1456 0.1438 0.1440 0.1456 0.1444 

[TRAIN] Epoch[5](1219/1500); Loss: 0.113061; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1706 0.1435 0.1323 0.1240 0.1165 0.1098 0.1056 0.1034 0.1023 0.1018 0.1012 0.1002 0.0992 0.0993 0.0995 0.0998 

[TRAIN] Epoch[5](1220/1500); Loss: 0.159593; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1979 0.2075 0.1974 0.1820 0.1679 0.1578 0.1531 0.1513 0.1477 0.1442 0.1436 0.1424 0.1408 0.1405 0.1398 0.1397 

[TRAIN] Epoch[5](1221/1500); Loss: 0.128852; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2867 0.2679 0.2284 0.2021 0.1789 0.1514 0.1189 0.0924 0.0741 0.0662 0.0690 0.0659 0.0650 0.0650 0.0653 0.0645 

[TRAIN] Epoch[5](1222/1500); Loss: 0.180070; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1975 0.2242 0.2090 0.1977 0.1897 0.1838 0.1760 0.1703 0.1654 0.1614 0.1603 0.1610 0.1637 0.1679 0.1735 0.1797 

[TRAIN] Epoch[5](1223/1500); Loss: 0.108243; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1767 0.1737 0.1515 0.1310 0.1162 0.1038 0.0950 0.0925 0.0889 0.0865 0.0863 0.0858 0.0850 0.0851 0.0864 0.0875 

[TRAIN] Epoch[5](1224/1500); Loss: 0.146568; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2185 0.2212 0.1958 0.1786 0.1634 0.1490 0.1371 0.1286 0.1222 0.1193 0.1192 0.1189 0.1184 0.1181 0.1183 0.1183 

[TRAIN] Epoch[5](1225/1500); Loss: 0.104413; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2750 0.2517 0.2067 0.1773 0.1510 0.1179 0.0801 0.0538 0.0454 0.0488 0.0451 0.0438 0.0442 0.0432 0.0425 0.0441 

[TRAIN] Epoch[5](1226/1500); Loss: 0.151715; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1870 0.1976 0.1815 0.1691 0.1576 0.1485 0.1442 0.1423 0.1399 0.1388 0.1388 0.1368 0.1365 0.1364 0.1363 0.1363 

[TRAIN] Epoch[5](1227/1500); Loss: 0.083761; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1568 0.1372 0.1181 0.0991 0.0830 0.0718 0.0710 0.0726 0.0666 0.0669 0.0673 0.0658 0.0657 0.0660 0.0657 0.0666 

[TRAIN] Epoch[5](1228/1500); Loss: 0.090462; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1918 0.1417 0.0988 0.0932 0.0866 0.0817 0.0789 0.0755 0.0746 0.0740 0.0735 0.0746 0.0746 0.0749 0.0764 0.0766 

[TRAIN] Epoch[5](1229/1500); Loss: 0.155529; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2104 0.2100 0.1962 0.1806 0.1672 0.1587 0.1542 0.1490 0.1430 0.1388 0.1346 0.1316 0.1299 0.1284 0.1280 0.1278 

[TRAIN] Epoch[5](1230/1500); Loss: 0.101433; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2788 0.2440 0.1963 0.1661 0.1413 0.1116 0.0815 0.0595 0.0476 0.0448 0.0415 0.0427 0.0417 0.0416 0.0420 0.0422 

[TRAIN] Epoch[5](1231/1500); Loss: 0.093554; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1227 0.1528 0.1373 0.1140 0.0941 0.0847 0.0833 0.0794 0.0790 0.0782 0.0775 0.0778 0.0778 0.0781 0.0793 0.0808 

[TRAIN] Epoch[5](1232/1500); Loss: 0.176976; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2394 0.2319 0.2203 0.2102 0.2004 0.1904 0.1815 0.1733 0.1658 0.1586 0.1517 0.1456 0.1417 0.1409 0.1406 0.1395 

[TRAIN] Epoch[5](1233/1500); Loss: 0.105802; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1421 0.1604 0.1545 0.1425 0.1252 0.1086 0.0965 0.0889 0.0835 0.0815 0.0836 0.0824 0.0825 0.0851 0.0869 0.0887 

[TRAIN] Epoch[5](1234/1500); Loss: 0.163010; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2452 0.2230 0.1929 0.1810 0.1718 0.1629 0.1567 0.1519 0.1483 0.1451 0.1422 0.1402 0.1388 0.1370 0.1356 0.1356 

[TRAIN] Epoch[5](1235/1500); Loss: 0.127461; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1470 0.1606 0.1485 0.1380 0.1288 0.1235 0.1228 0.1216 0.1210 0.1196 0.1190 0.1182 0.1177 0.1176 0.1175 0.1179 

[TRAIN] Epoch[5](1236/1500); Loss: 0.224060; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3734 0.3451 0.3007 0.2725 0.2605 0.2362 0.2077 0.1853 0.1776 0.1751 0.1792 0.1743 0.1743 0.1750 0.1754 0.1727 

[TRAIN] Epoch[5](1237/1500); Loss: 0.144687; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2232 0.1928 0.1879 0.1750 0.1633 0.1528 0.1423 0.1328 0.1253 0.1203 0.1180 0.1177 0.1162 0.1153 0.1162 0.1158 

[TRAIN] Epoch[5](1238/1500); Loss: 0.089043; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1311 0.1359 0.1164 0.1012 0.0906 0.0860 0.0831 0.0796 0.0773 0.0756 0.0746 0.0741 0.0741 0.0744 0.0751 0.0755 

[TRAIN] Epoch[5](1239/1500); Loss: 0.060048; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0583 0.0896 0.0912 0.0737 0.0560 0.0489 0.0619 0.0523 0.0493 0.0515 0.0534 0.0525 0.0539 0.0551 0.0557 0.0577 

[TRAIN] Epoch[5](1240/1500); Loss: 0.092655; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1165 0.1450 0.1417 0.1293 0.1128 0.0982 0.0863 0.0785 0.0735 0.0708 0.0711 0.0712 0.0701 0.0710 0.0730 0.0735 

[TRAIN] Epoch[5](1241/1500); Loss: 0.154295; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2446 0.2290 0.2062 0.1918 0.1819 0.1697 0.1561 0.1450 0.1358 0.1269 0.1184 0.1133 0.1127 0.1127 0.1125 0.1123 

[TRAIN] Epoch[5](1242/1500); Loss: 0.132552; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1904 0.1781 0.1593 0.1512 0.1412 0.1307 0.1232 0.1204 0.1189 0.1162 0.1151 0.1150 0.1150 0.1148 0.1155 0.1158 

[TRAIN] Epoch[5](1243/1500); Loss: 0.067059; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.0871 0.0880 0.1105 0.0973 0.0813 0.0660 0.0603 0.0594 0.0571 0.0536 0.0532 0.0522 0.0510 0.0513 0.0524 0.0521 

[TRAIN] Epoch[5](1244/1500); Loss: 0.100137; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1837 0.1471 0.1367 0.1240 0.1117 0.1020 0.0920 0.0792 0.0777 0.0807 0.0775 0.0767 0.0778 0.0775 0.0785 0.0795 

[TRAIN] Epoch[5](1245/1500); Loss: 0.128718; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2038 0.1640 0.1401 0.1385 0.1356 0.1280 0.1228 0.1198 0.1181 0.1152 0.1132 0.1124 0.1120 0.1116 0.1119 0.1125 

[TRAIN] Epoch[5](1246/1500); Loss: 0.129138; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2200 0.1709 0.1468 0.1446 0.1408 0.1292 0.1187 0.1139 0.1116 0.1107 0.1094 0.1086 0.1093 0.1107 0.1107 0.1105 

[TRAIN] Epoch[5](1247/1500); Loss: 0.095712; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1167 0.1539 0.1521 0.1335 0.1135 0.0971 0.0907 0.0813 0.0781 0.0784 0.0751 0.0733 0.0735 0.0718 0.0705 0.0720 

[TRAIN] Epoch[5](1248/1500); Loss: 0.158570; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1883 0.1931 0.1809 0.1717 0.1631 0.1575 0.1564 0.1563 0.1525 0.1495 0.1480 0.1461 0.1442 0.1433 0.1433 0.1429 

[TRAIN] Epoch[5](1249/1500); Loss: 0.095504; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1341 0.1564 0.1499 0.1341 0.1180 0.1025 0.0861 0.0760 0.0710 0.0708 0.0713 0.0716 0.0707 0.0710 0.0726 0.0720 

[TRAIN] Epoch[5](1250/1500); Loss: 0.241018; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.3044 0.3102 0.2937 0.2790 0.2646 0.2538 0.2429 0.2329 0.2241 0.2162 0.2100 0.2069 0.2050 0.2040 0.2040 0.2044 

[TRAIN] Epoch[5](1251/1500); Loss: 0.105710; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2077 0.1831 0.1555 0.1359 0.1205 0.1065 0.0959 0.0872 0.0800 0.0779 0.0767 0.0743 0.0728 0.0731 0.0722 0.0722 

[TRAIN] Epoch[5](1252/1500); Loss: 0.050959; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.0600 0.0718 0.0671 0.0567 0.0482 0.0492 0.0460 0.0457 0.0450 0.0458 0.0449 0.0452 0.0468 0.0459 0.0472 0.0499 

[TRAIN] Epoch[5](1253/1500); Loss: 0.095410; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1409 0.1467 0.1279 0.1152 0.1040 0.0928 0.0852 0.0847 0.0802 0.0794 0.0790 0.0779 0.0778 0.0783 0.0781 0.0783 

[TRAIN] Epoch[5](1254/1500); Loss: 0.119738; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1820 0.1691 0.1491 0.1414 0.1326 0.1231 0.1156 0.1080 0.1037 0.1023 0.0999 0.0985 0.0980 0.0974 0.0974 0.0979 

[TRAIN] Epoch[5](1255/1500); Loss: 0.104723; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1506 0.1575 0.1413 0.1265 0.1127 0.1013 0.0945 0.0916 0.0885 0.0873 0.0877 0.0874 0.0867 0.0868 0.0878 0.0874 

[TRAIN] Epoch[5](1256/1500); Loss: 0.092048; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1503 0.1363 0.1147 0.1065 0.0972 0.0904 0.0847 0.0828 0.0801 0.0779 0.0771 0.0764 0.0750 0.0749 0.0743 0.0742 

[TRAIN] Epoch[5](1257/1500); Loss: 0.146024; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2439 0.2058 0.1810 0.1696 0.1602 0.1494 0.1409 0.1343 0.1289 0.1238 0.1211 0.1188 0.1158 0.1151 0.1145 0.1135 

[TRAIN] Epoch[5](1258/1500); Loss: 0.082125; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1244 0.1267 0.1083 0.0949 0.0860 0.0784 0.0744 0.0718 0.0703 0.0687 0.0683 0.0679 0.0678 0.0685 0.0686 0.0691 

[TRAIN] Epoch[5](1259/1500); Loss: 0.136399; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1787 0.1719 0.1619 0.1530 0.1444 0.1359 0.1299 0.1261 0.1242 0.1224 0.1216 0.1214 0.1216 0.1225 0.1232 0.1237 

[TRAIN] Epoch[5](1260/1500); Loss: 0.072621; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2088 0.0726 0.0877 0.0658 0.0528 0.0429 0.0534 0.0545 0.0541 0.0563 0.0643 0.0669 0.0646 0.0674 0.0735 0.0764 

[TRAIN] Epoch[5](1261/1500); Loss: 0.070408; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1626 0.1497 0.1099 0.0840 0.0701 0.0580 0.0541 0.0508 0.0484 0.0468 0.0475 0.0463 0.0474 0.0489 0.0500 0.0520 

[TRAIN] Epoch[5](1262/1500); Loss: 0.116441; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2444 0.2161 0.1792 0.1591 0.1443 0.1273 0.1101 0.0975 0.0869 0.0793 0.0730 0.0694 0.0690 0.0694 0.0691 0.0690 

[TRAIN] Epoch[5](1263/1500); Loss: 0.195375; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.4555 0.4061 0.3419 0.3031 0.2771 0.2302 0.1766 0.1313 0.1054 0.1018 0.1081 0.0957 0.0987 0.1010 0.0978 0.0958 

[TRAIN] Epoch[5](1264/1500); Loss: 0.193328; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.5037 0.4480 0.3706 0.3229 0.2907 0.2321 0.1662 0.1111 0.0825 0.0855 0.0837 0.0766 0.0805 0.0819 0.0776 0.0796 

[TRAIN] Epoch[5](1265/1500); Loss: 0.188966; Backpropagation: 0.0922 sec; Batch: 0.4307 sec
0.1904 0.2318 0.2176 0.2043 0.1936 0.1874 0.1794 0.1748 0.1716 0.1695 0.1715 0.1756 0.1793 0.1852 0.1921 0.1992 

[TRAIN] Epoch[5](1266/1500); Loss: 0.065711; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0917 0.0710 0.0882 0.0802 0.0700 0.0604 0.0607 0.0608 0.0578 0.0586 0.0589 0.0574 0.0582 0.0587 0.0588 0.0601 

[TRAIN] Epoch[5](1267/1500); Loss: 0.151097; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2421 0.2199 0.1878 0.1771 0.1650 0.1524 0.1421 0.1355 0.1319 0.1282 0.1252 0.1235 0.1223 0.1215 0.1217 0.1215 

[TRAIN] Epoch[5](1268/1500); Loss: 0.099133; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1598 0.1844 0.1620 0.1390 0.1166 0.0999 0.0895 0.0798 0.0721 0.0701 0.0712 0.0697 0.0681 0.0682 0.0678 0.0677 

[TRAIN] Epoch[5](1269/1500); Loss: 0.070504; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1353 0.0963 0.0811 0.0771 0.0724 0.0665 0.0630 0.0609 0.0595 0.0585 0.0586 0.0584 0.0586 0.0595 0.0610 0.0615 

[TRAIN] Epoch[5](1270/1500); Loss: 0.145528; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2256 0.1947 0.1651 0.1615 0.1539 0.1436 0.1363 0.1318 0.1293 0.1277 0.1266 0.1269 0.1268 0.1263 0.1264 0.1261 

[TRAIN] Epoch[5](1271/1500); Loss: 0.225824; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.3803 0.3440 0.2991 0.2707 0.2580 0.2303 0.2023 0.1856 0.1811 0.1869 0.1805 0.1783 0.1791 0.1804 0.1784 0.1782 

[TRAIN] Epoch[5](1272/1500); Loss: 0.173927; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.3004 0.2796 0.2384 0.2097 0.1941 0.1710 0.1555 0.1438 0.1376 0.1368 0.1347 0.1348 0.1355 0.1363 0.1367 0.1378 

[TRAIN] Epoch[5](1273/1500); Loss: 0.119905; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1712 0.1552 0.1393 0.1300 0.1212 0.1148 0.1102 0.1085 0.1089 0.1084 0.1081 0.1084 0.1081 0.1083 0.1086 0.1093 

[TRAIN] Epoch[5](1274/1500); Loss: 0.088002; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1457 0.1520 0.1398 0.1259 0.1115 0.0934 0.0743 0.0654 0.0612 0.0600 0.0619 0.0612 0.0611 0.0631 0.0649 0.0665 

[TRAIN] Epoch[5](1275/1500); Loss: 0.069107; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0977 0.1054 0.0946 0.0830 0.0714 0.0658 0.0627 0.0591 0.0580 0.0577 0.0574 0.0574 0.0582 0.0584 0.0587 0.0600 

[TRAIN] Epoch[5](1276/1500); Loss: 0.116090; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2322 0.1706 0.1372 0.1305 0.1243 0.1153 0.1073 0.1021 0.0981 0.0941 0.0928 0.0915 0.0903 0.0904 0.0905 0.0902 

[TRAIN] Epoch[5](1277/1500); Loss: 0.101232; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1333 0.1408 0.1417 0.1233 0.1047 0.0925 0.0940 0.0906 0.0872 0.0887 0.0876 0.0866 0.0869 0.0865 0.0871 0.0883 

[TRAIN] Epoch[5](1278/1500); Loss: 0.145350; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1644 0.1755 0.1668 0.1572 0.1485 0.1439 0.1423 0.1399 0.1374 0.1369 0.1364 0.1352 0.1355 0.1351 0.1353 0.1355 

[TRAIN] Epoch[5](1279/1500); Loss: 0.079191; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0881 0.1387 0.1400 0.1204 0.0986 0.0801 0.0684 0.0632 0.0563 0.0587 0.0594 0.0587 0.0577 0.0596 0.0601 0.0590 

[TRAIN] Epoch[5](1280/1500); Loss: 0.115874; Backpropagation: 0.0919 sec; Batch: 0.4253 sec
0.1400 0.1395 0.1318 0.1243 0.1184 0.1144 0.1119 0.1091 0.1085 0.1081 0.1074 0.1072 0.1077 0.1082 0.1082 0.1093 

[TRAIN] Epoch[5](1281/1500); Loss: 0.119408; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2713 0.2077 0.1457 0.1409 0.1338 0.1157 0.1016 0.0920 0.0877 0.0874 0.0868 0.0871 0.0873 0.0871 0.0884 0.0901 

[TRAIN] Epoch[5](1282/1500); Loss: 0.105083; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1875 0.1585 0.1260 0.1109 0.1033 0.0977 0.0975 0.0916 0.0906 0.0903 0.0883 0.0880 0.0880 0.0874 0.0875 0.0880 

[TRAIN] Epoch[5](1283/1500); Loss: 0.107285; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1589 0.1311 0.1186 0.1134 0.1100 0.1054 0.1000 0.0979 0.0988 0.0976 0.0966 0.0976 0.0973 0.0967 0.0979 0.0985 

[TRAIN] Epoch[5](1284/1500); Loss: 0.123110; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.1653 0.1748 0.1566 0.1409 0.1276 0.1178 0.1131 0.1096 0.1078 0.1078 0.1077 0.1074 0.1077 0.1079 0.1085 0.1093 

[TRAIN] Epoch[5](1285/1500); Loss: 0.165870; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2248 0.2184 0.1946 0.1796 0.1698 0.1618 0.1584 0.1551 0.1527 0.1511 0.1499 0.1491 0.1484 0.1476 0.1467 0.1461 

[TRAIN] Epoch[5](1286/1500); Loss: 0.098557; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2019 0.1551 0.1238 0.1148 0.1081 0.0966 0.0867 0.0797 0.0765 0.0776 0.0762 0.0755 0.0747 0.0766 0.0767 0.0763 

[TRAIN] Epoch[5](1287/1500); Loss: 0.166406; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2235 0.2123 0.1934 0.1838 0.1767 0.1672 0.1605 0.1565 0.1528 0.1503 0.1480 0.1471 0.1472 0.1478 0.1476 0.1479 

[TRAIN] Epoch[5](1288/1500); Loss: 0.052738; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2035 0.1142 0.0501 0.0512 0.0455 0.0363 0.0319 0.0314 0.0339 0.0320 0.0334 0.0354 0.0339 0.0359 0.0378 0.0374 

[TRAIN] Epoch[5](1289/1500); Loss: 0.161644; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.2269 0.2103 0.2035 0.1924 0.1816 0.1721 0.1649 0.1550 0.1478 0.1418 0.1361 0.1322 0.1316 0.1307 0.1294 0.1300 

[TRAIN] Epoch[5](1290/1500); Loss: 0.065222; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1009 0.1098 0.0899 0.0774 0.0648 0.0565 0.0525 0.0516 0.0515 0.0536 0.0538 0.0542 0.0551 0.0563 0.0568 0.0589 

[TRAIN] Epoch[5](1291/1500); Loss: 0.147583; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1968 0.1859 0.1695 0.1600 0.1523 0.1453 0.1390 0.1377 0.1382 0.1358 0.1353 0.1352 0.1332 0.1326 0.1329 0.1317 

[TRAIN] Epoch[5](1292/1500); Loss: 0.069618; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0754 0.1021 0.0981 0.0824 0.0672 0.0653 0.0675 0.0626 0.0601 0.0637 0.0613 0.0602 0.0610 0.0618 0.0621 0.0629 

[TRAIN] Epoch[5](1293/1500); Loss: 0.091519; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1124 0.1130 0.1120 0.1028 0.0935 0.0895 0.0909 0.0860 0.0832 0.0839 0.0841 0.0826 0.0822 0.0824 0.0828 0.0832 

[TRAIN] Epoch[5](1294/1500); Loss: 0.145023; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1884 0.1859 0.1713 0.1602 0.1502 0.1420 0.1369 0.1342 0.1328 0.1323 0.1319 0.1311 0.1306 0.1309 0.1308 0.1308 

[TRAIN] Epoch[5](1295/1500); Loss: 0.109089; Backpropagation: 0.0924 sec; Batch: 0.4239 sec
0.2321 0.1856 0.1483 0.1317 0.1203 0.1050 0.0920 0.0837 0.0818 0.0803 0.0802 0.0806 0.0802 0.0806 0.0819 0.0812 

[TRAIN] Epoch[5](1296/1500); Loss: 0.103520; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1637 0.1354 0.1143 0.1120 0.1082 0.1011 0.0956 0.0940 0.0924 0.0915 0.0912 0.0912 0.0911 0.0912 0.0918 0.0918 

[TRAIN] Epoch[5](1297/1500); Loss: 0.153952; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2070 0.1931 0.1784 0.1699 0.1618 0.1539 0.1475 0.1433 0.1410 0.1402 0.1386 0.1378 0.1379 0.1375 0.1375 0.1380 

[TRAIN] Epoch[5](1298/1500); Loss: 0.186137; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2563 0.2484 0.2242 0.2076 0.1958 0.1847 0.1769 0.1703 0.1677 0.1662 0.1645 0.1638 0.1632 0.1633 0.1628 0.1625 

[TRAIN] Epoch[5](1299/1500); Loss: 0.072150; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0981 0.0790 0.0754 0.0725 0.0711 0.0707 0.0664 0.0667 0.0672 0.0662 0.0674 0.0685 0.0683 0.0708 0.0731 0.0730 

[TRAIN] Epoch[5](1300/1500); Loss: 0.144233; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1801 0.1732 0.1639 0.1562 0.1500 0.1476 0.1444 0.1396 0.1361 0.1337 0.1318 0.1305 0.1302 0.1302 0.1300 0.1302 

[TRAIN] Epoch[5](1301/1500); Loss: 0.144095; Backpropagation: 0.0923 sec; Batch: 0.4238 sec
0.1871 0.1705 0.1555 0.1483 0.1418 0.1385 0.1366 0.1354 0.1343 0.1344 0.1344 0.1351 0.1362 0.1377 0.1391 0.1407 

[TRAIN] Epoch[5](1302/1500); Loss: 0.109576; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1652 0.1433 0.1274 0.1224 0.1150 0.1063 0.1017 0.0978 0.0960 0.0958 0.0962 0.0960 0.0964 0.0971 0.0976 0.0991 

[TRAIN] Epoch[5](1303/1500); Loss: 0.123676; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1417 0.1624 0.1494 0.1355 0.1250 0.1198 0.1201 0.1181 0.1148 0.1146 0.1141 0.1126 0.1121 0.1123 0.1128 0.1136 

[TRAIN] Epoch[5](1304/1500); Loss: 0.126496; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1965 0.1826 0.1634 0.1490 0.1385 0.1273 0.1160 0.1099 0.1075 0.1062 0.1049 0.1049 0.1039 0.1041 0.1046 0.1047 

[TRAIN] Epoch[5](1305/1500); Loss: 0.093798; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1184 0.1293 0.1162 0.1054 0.0964 0.0914 0.0894 0.0865 0.0843 0.0841 0.0831 0.0824 0.0826 0.0833 0.0837 0.0842 

[TRAIN] Epoch[5](1306/1500); Loss: 0.052758; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0539 0.0748 0.0861 0.0714 0.0554 0.0476 0.0507 0.0456 0.0443 0.0448 0.0451 0.0437 0.0447 0.0451 0.0450 0.0458 

[TRAIN] Epoch[5](1307/1500); Loss: 0.058376; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.0506 0.1140 0.1069 0.0839 0.0590 0.0452 0.0525 0.0483 0.0451 0.0471 0.0474 0.0457 0.0456 0.0471 0.0464 0.0491 

[TRAIN] Epoch[5](1308/1500); Loss: 0.114664; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1660 0.1722 0.1484 0.1319 0.1191 0.1109 0.1047 0.1007 0.0975 0.0964 0.0962 0.0968 0.0970 0.0976 0.0988 0.1004 

[TRAIN] Epoch[5](1309/1500); Loss: 0.151948; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2218 0.2186 0.1963 0.1819 0.1676 0.1547 0.1468 0.1371 0.1312 0.1303 0.1280 0.1248 0.1238 0.1234 0.1226 0.1224 

[TRAIN] Epoch[5](1310/1500); Loss: 0.072683; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1595 0.1256 0.0950 0.0884 0.0795 0.0668 0.0578 0.0559 0.0535 0.0527 0.0523 0.0534 0.0540 0.0544 0.0561 0.0579 

[TRAIN] Epoch[5](1311/1500); Loss: 0.071994; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1246 0.0905 0.0785 0.0709 0.0670 0.0657 0.0650 0.0640 0.0641 0.0645 0.0646 0.0651 0.0658 0.0662 0.0672 0.0682 

[TRAIN] Epoch[5](1312/1500); Loss: 0.163325; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2094 0.2029 0.1901 0.1834 0.1767 0.1689 0.1618 0.1564 0.1519 0.1484 0.1459 0.1442 0.1434 0.1432 0.1431 0.1436 

[TRAIN] Epoch[5](1313/1500); Loss: 0.085183; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1436 0.1431 0.1216 0.1106 0.0971 0.0831 0.0732 0.0679 0.0667 0.0639 0.0635 0.0642 0.0653 0.0656 0.0661 0.0675 

[TRAIN] Epoch[5](1314/1500); Loss: 0.114504; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1904 0.1311 0.1302 0.1221 0.1154 0.1126 0.1082 0.1043 0.1034 0.1031 0.1013 0.1006 0.1014 0.1014 0.1026 0.1039 

[TRAIN] Epoch[5](1315/1500); Loss: 0.154612; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1877 0.1950 0.1789 0.1662 0.1569 0.1521 0.1521 0.1474 0.1438 0.1435 0.1427 0.1414 0.1411 0.1415 0.1416 0.1419 

[TRAIN] Epoch[5](1316/1500); Loss: 0.092632; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1171 0.1127 0.1021 0.0974 0.0926 0.0892 0.0884 0.0875 0.0866 0.0865 0.0866 0.0863 0.0865 0.0870 0.0876 0.0881 

[TRAIN] Epoch[5](1317/1500); Loss: 0.109451; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2742 0.2288 0.1864 0.1696 0.1482 0.1159 0.0815 0.0634 0.0627 0.0599 0.0595 0.0592 0.0599 0.0601 0.0608 0.0610 

[TRAIN] Epoch[5](1318/1500); Loss: 0.061823; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1852 0.1167 0.0703 0.0717 0.0622 0.0450 0.0408 0.0415 0.0413 0.0424 0.0424 0.0444 0.0454 0.0449 0.0468 0.0483 

[TRAIN] Epoch[5](1319/1500); Loss: 0.106130; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1914 0.1524 0.1212 0.1151 0.1089 0.1003 0.0960 0.0918 0.0908 0.0912 0.0902 0.0897 0.0899 0.0893 0.0901 0.0898 

[TRAIN] Epoch[5](1320/1500); Loss: 0.082352; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1096 0.0740 0.0892 0.0827 0.0778 0.0770 0.0778 0.0774 0.0775 0.0794 0.0795 0.0808 0.0821 0.0828 0.0845 0.0855 

[TRAIN] Epoch[5](1321/1500); Loss: 0.134306; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2197 0.1889 0.1612 0.1490 0.1408 0.1336 0.1301 0.1205 0.1160 0.1144 0.1133 0.1123 0.1125 0.1125 0.1118 0.1124 

[TRAIN] Epoch[5](1322/1500); Loss: 0.096074; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1801 0.1381 0.1106 0.1081 0.1035 0.0934 0.0864 0.0834 0.0814 0.0797 0.0792 0.0797 0.0784 0.0779 0.0788 0.0784 

[TRAIN] Epoch[5](1323/1500); Loss: 0.063118; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2203 0.0868 0.0487 0.0440 0.0429 0.0496 0.0436 0.0445 0.0494 0.0479 0.0472 0.0543 0.0552 0.0543 0.0585 0.0628 

[TRAIN] Epoch[5](1324/1500); Loss: 0.105334; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2772 0.2259 0.1910 0.1816 0.1606 0.1309 0.1006 0.0758 0.0564 0.0438 0.0406 0.0399 0.0398 0.0397 0.0407 0.0408 

[TRAIN] Epoch[5](1325/1500); Loss: 0.064517; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.0534 0.1429 0.1301 0.1074 0.0813 0.0570 0.0402 0.0457 0.0478 0.0436 0.0459 0.0474 0.0461 0.0448 0.0487 0.0502 

[TRAIN] Epoch[5](1326/1500); Loss: 0.116883; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1544 0.1124 0.1591 0.1444 0.1287 0.1135 0.1055 0.1010 0.1013 0.1009 0.1026 0.1063 0.1078 0.1095 0.1113 0.1113 

[TRAIN] Epoch[5](1327/1500); Loss: 0.148668; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1783 0.1849 0.1769 0.1682 0.1594 0.1519 0.1475 0.1450 0.1419 0.1387 0.1358 0.1329 0.1307 0.1298 0.1286 0.1282 

[TRAIN] Epoch[5](1328/1500); Loss: 0.133391; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1564 0.1537 0.1528 0.1451 0.1363 0.1296 0.1283 0.1287 0.1278 0.1271 0.1265 0.1256 0.1245 0.1239 0.1242 0.1237 

[TRAIN] Epoch[5](1329/1500); Loss: 0.169719; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2481 0.2359 0.2196 0.2083 0.1982 0.1882 0.1781 0.1675 0.1582 0.1495 0.1400 0.1318 0.1257 0.1221 0.1214 0.1230 

[TRAIN] Epoch[5](1330/1500); Loss: 0.096734; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1565 0.1087 0.1134 0.1055 0.0975 0.0902 0.0874 0.0855 0.0855 0.0870 0.0880 0.0869 0.0883 0.0888 0.0888 0.0896 

[TRAIN] Epoch[5](1331/1500); Loss: 0.155183; Backpropagation: 0.0924 sec; Batch: 0.4238 sec
0.2207 0.2004 0.1894 0.1826 0.1755 0.1650 0.1584 0.1492 0.1408 0.1353 0.1307 0.1271 0.1259 0.1267 0.1272 0.1278 

[TRAIN] Epoch[5](1332/1500); Loss: 0.135456; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1567 0.1720 0.1663 0.1586 0.1480 0.1393 0.1325 0.1267 0.1224 0.1212 0.1204 0.1198 0.1199 0.1210 0.1211 0.1214 

[TRAIN] Epoch[5](1333/1500); Loss: 0.106485; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1667 0.1236 0.1392 0.1302 0.1186 0.1067 0.0997 0.0980 0.0959 0.0938 0.0907 0.0897 0.0890 0.0881 0.0870 0.0868 

[TRAIN] Epoch[5](1334/1500); Loss: 0.095780; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1439 0.1253 0.1071 0.0989 0.0942 0.0909 0.0899 0.0895 0.0889 0.0882 0.0870 0.0859 0.0855 0.0861 0.0857 0.0855 

[TRAIN] Epoch[5](1335/1500); Loss: 0.156320; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1559 0.1544 0.1976 0.1882 0.1765 0.1618 0.1497 0.1428 0.1406 0.1423 0.1438 0.1461 0.1496 0.1507 0.1500 0.1511 

[TRAIN] Epoch[5](1336/1500); Loss: 0.093418; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1707 0.1574 0.1372 0.1235 0.1095 0.0968 0.0848 0.0746 0.0681 0.0661 0.0681 0.0671 0.0668 0.0671 0.0684 0.0685 

[TRAIN] Epoch[5](1337/1500); Loss: 0.099483; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.0812 0.1902 0.1905 0.1750 0.1531 0.1281 0.1001 0.0747 0.0563 0.0536 0.0635 0.0648 0.0617 0.0645 0.0674 0.0669 

[TRAIN] Epoch[5](1338/1500); Loss: 0.219889; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2562 0.2570 0.2607 0.2495 0.2375 0.2255 0.2149 0.2070 0.2021 0.2000 0.2000 0.2013 0.2028 0.2029 0.2012 0.1996 

[TRAIN] Epoch[5](1339/1500); Loss: 0.123791; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1095 0.1715 0.2068 0.1957 0.1786 0.1590 0.1380 0.1188 0.1027 0.0926 0.0882 0.0872 0.0834 0.0822 0.0829 0.0835 

[TRAIN] Epoch[5](1340/1500); Loss: 0.176074; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2471 0.2480 0.2440 0.2276 0.2126 0.1960 0.1789 0.1633 0.1509 0.1411 0.1340 0.1316 0.1326 0.1354 0.1375 0.1367 

[TRAIN] Epoch[5](1341/1500); Loss: 0.154741; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1781 0.1899 0.1842 0.1753 0.1647 0.1552 0.1484 0.1448 0.1438 0.1432 0.1425 0.1421 0.1416 0.1401 0.1407 0.1411 

[TRAIN] Epoch[5](1342/1500); Loss: 0.102973; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1220 0.1686 0.1618 0.1492 0.1311 0.1133 0.0982 0.0881 0.0815 0.0797 0.0785 0.0776 0.0757 0.0743 0.0737 0.0744 

[TRAIN] Epoch[5](1343/1500); Loss: 0.156814; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1930 0.2216 0.2144 0.2030 0.1848 0.1699 0.1557 0.1449 0.1373 0.1331 0.1318 0.1306 0.1263 0.1223 0.1202 0.1201 

[TRAIN] Epoch[5](1344/1500); Loss: 0.126836; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1976 0.1489 0.1374 0.1337 0.1275 0.1225 0.1176 0.1151 0.1139 0.1140 0.1140 0.1151 0.1165 0.1175 0.1186 0.1194 

[TRAIN] Epoch[5](1345/1500); Loss: 0.124042; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0903 0.1591 0.2027 0.1916 0.1744 0.1537 0.1335 0.1164 0.1028 0.0947 0.0921 0.0924 0.0943 0.0953 0.0949 0.0965 

[TRAIN] Epoch[5](1346/1500); Loss: 0.147439; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1564 0.2328 0.2326 0.2180 0.1986 0.1797 0.1604 0.1424 0.1264 0.1150 0.1070 0.1019 0.0985 0.0966 0.0963 0.0964 

[TRAIN] Epoch[5](1347/1500); Loss: 0.167004; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1576 0.1927 0.2045 0.1977 0.1875 0.1746 0.1634 0.1557 0.1528 0.1548 0.1562 0.1542 0.1532 0.1554 0.1562 0.1556 

[TRAIN] Epoch[5](1348/1500); Loss: 0.144625; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2167 0.1693 0.1564 0.1523 0.1450 0.1396 0.1356 0.1334 0.1321 0.1319 0.1311 0.1314 0.1330 0.1340 0.1354 0.1369 

[TRAIN] Epoch[5](1349/1500); Loss: 0.185040; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2101 0.2528 0.2614 0.2465 0.2306 0.2127 0.1943 0.1774 0.1627 0.1520 0.1456 0.1433 0.1435 0.1433 0.1422 0.1420 

[TRAIN] Epoch[5](1350/1500); Loss: 0.120554; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1278 0.1473 0.1589 0.1530 0.1418 0.1308 0.1215 0.1138 0.1073 0.1028 0.1005 0.0999 0.1017 0.1049 0.1073 0.1095 

[TRAIN] Epoch[5](1351/1500); Loss: 0.202151; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2149 0.2459 0.2451 0.2341 0.2278 0.2195 0.2102 0.2015 0.1947 0.1886 0.1825 0.1778 0.1747 0.1723 0.1714 0.1733 

[TRAIN] Epoch[5](1352/1500); Loss: 0.115106; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1631 0.1508 0.1324 0.1225 0.1166 0.1108 0.1065 0.1041 0.1037 0.1047 0.1056 0.1049 0.1039 0.1038 0.1039 0.1043 

[TRAIN] Epoch[5](1353/1500); Loss: 0.124636; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1503 0.1435 0.1677 0.1599 0.1495 0.1355 0.1238 0.1161 0.1120 0.1094 0.1076 0.1057 0.1043 0.1037 0.1026 0.1027 

[TRAIN] Epoch[5](1354/1500); Loss: 0.127106; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1322 0.1747 0.1788 0.1684 0.1543 0.1403 0.1284 0.1199 0.1135 0.1082 0.1033 0.1020 0.1028 0.1024 0.1020 0.1025 

[TRAIN] Epoch[5](1355/1500); Loss: 0.197407; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.3598 0.3406 0.3112 0.2891 0.2705 0.2474 0.2215 0.1970 0.1736 0.1489 0.1246 0.1056 0.0938 0.0899 0.0924 0.0927 

[TRAIN] Epoch[5](1356/1500); Loss: 0.188471; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2726 0.2806 0.2752 0.2582 0.2410 0.2203 0.1999 0.1839 0.1730 0.1613 0.1482 0.1348 0.1251 0.1179 0.1121 0.1114 

[TRAIN] Epoch[5](1357/1500); Loss: 0.128440; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1107 0.1562 0.2018 0.1960 0.1835 0.1656 0.1480 0.1313 0.1161 0.1036 0.0949 0.0897 0.0877 0.0886 0.0902 0.0913 

[TRAIN] Epoch[5](1358/1500); Loss: 0.248953; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.5068 0.4780 0.4310 0.3969 0.3681 0.3284 0.2820 0.2378 0.1962 0.1516 0.1113 0.0902 0.0909 0.1104 0.1036 0.1000 

[TRAIN] Epoch[5](1359/1500); Loss: 0.153567; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2510 0.2368 0.2150 0.1963 0.1801 0.1628 0.1463 0.1362 0.1302 0.1242 0.1162 0.1136 0.1151 0.1123 0.1100 0.1110 

[TRAIN] Epoch[5](1360/1500); Loss: 0.089903; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1004 0.1097 0.1446 0.1343 0.1216 0.1056 0.0902 0.0781 0.0696 0.0670 0.0694 0.0685 0.0678 0.0680 0.0710 0.0727 

[TRAIN] Epoch[5](1361/1500); Loss: 0.089922; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1187 0.1601 0.1521 0.1389 0.1213 0.1029 0.0847 0.0704 0.0623 0.0615 0.0643 0.0616 0.0594 0.0596 0.0602 0.0608 

[TRAIN] Epoch[5](1362/1500); Loss: 0.148998; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2840 0.2599 0.2314 0.2144 0.2001 0.1816 0.1594 0.1383 0.1187 0.1011 0.0869 0.0792 0.0787 0.0842 0.0840 0.0820 

[TRAIN] Epoch[5](1363/1500); Loss: 0.126639; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1621 0.1489 0.1630 0.1544 0.1422 0.1288 0.1178 0.1112 0.1096 0.1099 0.1100 0.1108 0.1122 0.1143 0.1147 0.1162 

[TRAIN] Epoch[5](1364/1500); Loss: 0.193258; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2316 0.2545 0.2618 0.2502 0.2345 0.2183 0.2025 0.1881 0.1762 0.1657 0.1579 0.1528 0.1492 0.1483 0.1494 0.1511 

[TRAIN] Epoch[5](1365/1500); Loss: 0.088069; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0602 0.1039 0.1552 0.1464 0.1310 0.1101 0.0902 0.0749 0.0671 0.0679 0.0678 0.0690 0.0675 0.0665 0.0656 0.0659 

[TRAIN] Epoch[5](1366/1500); Loss: 0.158950; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1927 0.2034 0.1956 0.1861 0.1755 0.1651 0.1563 0.1508 0.1489 0.1475 0.1448 0.1403 0.1369 0.1351 0.1328 0.1313 

[TRAIN] Epoch[5](1367/1500); Loss: 0.056247; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0684 0.0827 0.0802 0.0725 0.0634 0.0556 0.0503 0.0465 0.0439 0.0441 0.0465 0.0473 0.0475 0.0489 0.0505 0.0519 

[TRAIN] Epoch[5](1368/1500); Loss: 0.149806; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1723 0.1910 0.2005 0.1863 0.1733 0.1572 0.1419 0.1303 0.1241 0.1229 0.1262 0.1305 0.1314 0.1338 0.1373 0.1379 

[TRAIN] Epoch[5](1369/1500); Loss: 0.193111; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2359 0.2655 0.2592 0.2441 0.2296 0.2146 0.1998 0.1859 0.1740 0.1649 0.1582 0.1532 0.1506 0.1506 0.1518 0.1519 

[TRAIN] Epoch[5](1370/1500); Loss: 0.118368; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1737 0.1709 0.1513 0.1385 0.1301 0.1219 0.1160 0.1119 0.1062 0.1012 0.0993 0.0970 0.0960 0.0945 0.0924 0.0931 

[TRAIN] Epoch[5](1371/1500); Loss: 0.160899; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1581 0.1563 0.2051 0.1991 0.1893 0.1753 0.1626 0.1533 0.1467 0.1423 0.1412 0.1430 0.1460 0.1491 0.1525 0.1547 

[TRAIN] Epoch[5](1372/1500); Loss: 0.173881; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2545 0.2478 0.2446 0.2287 0.2143 0.1967 0.1776 0.1603 0.1457 0.1337 0.1253 0.1232 0.1250 0.1309 0.1379 0.1358 

[TRAIN] Epoch[5](1373/1500); Loss: 0.222210; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.3434 0.3372 0.3141 0.2973 0.2810 0.2607 0.2382 0.2193 0.2025 0.1863 0.1708 0.1590 0.1473 0.1370 0.1306 0.1305 

[TRAIN] Epoch[5](1374/1500); Loss: 0.078312; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1390 0.1170 0.1029 0.0913 0.0820 0.0725 0.0671 0.0660 0.0662 0.0650 0.0630 0.0632 0.0638 0.0641 0.0650 0.0649 

[TRAIN] Epoch[5](1375/1500); Loss: 0.165720; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1892 0.2004 0.1963 0.1868 0.1770 0.1683 0.1617 0.1583 0.1572 0.1573 0.1539 0.1509 0.1485 0.1486 0.1491 0.1479 

[TRAIN] Epoch[5](1376/1500); Loss: 0.152040; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2075 0.2215 0.1985 0.1813 0.1767 0.1687 0.1584 0.1481 0.1402 0.1325 0.1239 0.1166 0.1127 0.1113 0.1141 0.1206 

[TRAIN] Epoch[5](1377/1500); Loss: 0.142660; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1577 0.2016 0.2024 0.1900 0.1727 0.1542 0.1378 0.1254 0.1181 0.1168 0.1187 0.1208 0.1181 0.1156 0.1160 0.1168 

[TRAIN] Epoch[5](1378/1500); Loss: 0.177662; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2336 0.2218 0.2206 0.2099 0.1985 0.1857 0.1730 0.1620 0.1540 0.1489 0.1470 0.1487 0.1535 0.1607 0.1633 0.1614 

[TRAIN] Epoch[5](1379/1500); Loss: 0.118546; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1451 0.1670 0.1620 0.1533 0.1409 0.1290 0.1188 0.1095 0.1014 0.0971 0.0962 0.0967 0.0949 0.0946 0.0953 0.0949 

[TRAIN] Epoch[5](1380/1500); Loss: 0.181935; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2977 0.2806 0.2575 0.2430 0.2286 0.2119 0.1934 0.1780 0.1635 0.1491 0.1360 0.1260 0.1182 0.1117 0.1082 0.1076 

[TRAIN] Epoch[5](1381/1500); Loss: 0.138475; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2454 0.2256 0.2196 0.2015 0.1815 0.1574 0.1307 0.1088 0.0949 0.0906 0.0939 0.0946 0.0936 0.0920 0.0929 0.0928 

[TRAIN] Epoch[5](1382/1500); Loss: 0.183898; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.3831 0.3531 0.3046 0.2762 0.2564 0.2255 0.1898 0.1574 0.1303 0.1083 0.0950 0.0895 0.0909 0.0984 0.0941 0.0897 

[TRAIN] Epoch[5](1383/1500); Loss: 0.161181; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2345 0.2418 0.2203 0.2033 0.1883 0.1737 0.1608 0.1508 0.1415 0.1347 0.1292 0.1230 0.1192 0.1203 0.1206 0.1168 

[TRAIN] Epoch[5](1384/1500); Loss: 0.132005; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1858 0.1799 0.1596 0.1451 0.1362 0.1272 0.1220 0.1214 0.1183 0.1162 0.1159 0.1163 0.1154 0.1161 0.1186 0.1181 

[TRAIN] Epoch[5](1385/1500); Loss: 0.164587; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2171 0.2261 0.2166 0.2018 0.1862 0.1699 0.1550 0.1449 0.1409 0.1395 0.1392 0.1410 0.1408 0.1385 0.1379 0.1380 

[TRAIN] Epoch[5](1386/1500); Loss: 0.170564; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1920 0.1927 0.1847 0.1792 0.1748 0.1709 0.1681 0.1668 0.1652 0.1621 0.1615 0.1624 0.1610 0.1614 0.1629 0.1634 

[TRAIN] Epoch[5](1387/1500); Loss: 0.138322; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2207 0.1953 0.1824 0.1729 0.1623 0.1505 0.1387 0.1279 0.1181 0.1101 0.1046 0.1031 0.1055 0.1085 0.1073 0.1051 

[TRAIN] Epoch[5](1388/1500); Loss: 0.120853; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1296 0.1446 0.1399 0.1330 0.1265 0.1213 0.1172 0.1165 0.1188 0.1181 0.1149 0.1120 0.1112 0.1099 0.1099 0.1103 

[TRAIN] Epoch[5](1389/1500); Loss: 0.145377; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2213 0.1965 0.1844 0.1702 0.1568 0.1429 0.1317 0.1258 0.1258 0.1269 0.1237 0.1236 0.1240 0.1237 0.1238 0.1249 

[TRAIN] Epoch[5](1390/1500); Loss: 0.162875; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1771 0.2227 0.2421 0.2289 0.2110 0.1908 0.1706 0.1521 0.1369 0.1270 0.1237 0.1241 0.1249 0.1254 0.1256 0.1232 

[TRAIN] Epoch[5](1391/1500); Loss: 0.165245; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1751 0.1820 0.2126 0.2047 0.1937 0.1797 0.1667 0.1566 0.1491 0.1447 0.1434 0.1447 0.1468 0.1475 0.1485 0.1481 

[TRAIN] Epoch[5](1392/1500); Loss: 0.136492; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1537 0.1352 0.1666 0.1611 0.1512 0.1381 0.1283 0.1243 0.1258 0.1309 0.1328 0.1286 0.1273 0.1280 0.1269 0.1250 

[TRAIN] Epoch[5](1393/1500); Loss: 0.116760; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1950 0.1611 0.1441 0.1317 0.1213 0.1097 0.1020 0.1001 0.1016 0.1018 0.0989 0.0979 0.1001 0.1012 0.1008 0.1008 

[TRAIN] Epoch[5](1394/1500); Loss: 0.180187; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.2783 0.2602 0.2351 0.2191 0.2071 0.1924 0.1784 0.1686 0.1599 0.1493 0.1428 0.1415 0.1405 0.1382 0.1355 0.1363 

[TRAIN] Epoch[5](1395/1500); Loss: 0.182823; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2460 0.2459 0.2307 0.2181 0.2065 0.1941 0.1829 0.1751 0.1697 0.1647 0.1567 0.1502 0.1476 0.1481 0.1465 0.1424 

[TRAIN] Epoch[5](1396/1500); Loss: 0.135425; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1577 0.1916 0.1913 0.1821 0.1641 0.1498 0.1358 0.1222 0.1131 0.1095 0.1065 0.1043 0.1052 0.1076 0.1113 0.1147 

[TRAIN] Epoch[5](1397/1500); Loss: 0.106178; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1484 0.1408 0.1355 0.1253 0.1157 0.1051 0.0990 0.0955 0.0959 0.0930 0.0906 0.0905 0.0901 0.0896 0.0913 0.0927 

[TRAIN] Epoch[5](1398/1500); Loss: 0.070819; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1955 0.0597 0.1005 0.1044 0.0887 0.0643 0.0436 0.0372 0.0459 0.0497 0.0550 0.0528 0.0539 0.0580 0.0598 0.0640 

[TRAIN] Epoch[5](1399/1500); Loss: 0.131818; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1631 0.1997 0.1907 0.1805 0.1641 0.1459 0.1275 0.1137 0.1050 0.1017 0.1032 0.1068 0.1018 0.0998 0.1015 0.1043 

[TRAIN] Epoch[5](1400/1500); Loss: 0.126757; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1714 0.1549 0.1829 0.1726 0.1587 0.1419 0.1243 0.1093 0.1009 0.0984 0.1016 0.1031 0.1006 0.1000 0.1032 0.1042 

[TRAIN] Epoch[5](1401/1500); Loss: 0.147393; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1444 0.0930 0.2136 0.2073 0.1943 0.1751 0.1592 0.1440 0.1333 0.1241 0.1208 0.1235 0.1261 0.1300 0.1342 0.1356 

[TRAIN] Epoch[5](1402/1500); Loss: 0.160987; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2585 0.2487 0.2278 0.2146 0.2034 0.1890 0.1732 0.1584 0.1442 0.1294 0.1157 0.1057 0.0999 0.0990 0.1036 0.1046 

[TRAIN] Epoch[5](1403/1500); Loss: 0.115519; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1495 0.1425 0.1287 0.1227 0.1184 0.1136 0.1100 0.1088 0.1083 0.1071 0.1060 0.1059 0.1063 0.1069 0.1065 0.1071 

[TRAIN] Epoch[5](1404/1500); Loss: 0.080093; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1040 0.1202 0.1161 0.1018 0.0908 0.0808 0.0727 0.0672 0.0641 0.0649 0.0676 0.0660 0.0646 0.0659 0.0669 0.0678 

[TRAIN] Epoch[5](1405/1500); Loss: 0.099634; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1129 0.1048 0.1093 0.1064 0.1016 0.0973 0.0971 0.0992 0.0952 0.0947 0.0958 0.0943 0.0949 0.0956 0.0964 0.0985 

[TRAIN] Epoch[5](1406/1500); Loss: 0.084224; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1085 0.1054 0.1347 0.1270 0.1144 0.0952 0.0793 0.0710 0.0695 0.0666 0.0614 0.0613 0.0641 0.0637 0.0620 0.0637 

[TRAIN] Epoch[5](1407/1500); Loss: 0.122022; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1658 0.1789 0.1695 0.1586 0.1442 0.1293 0.1174 0.1103 0.1056 0.1014 0.0982 0.0960 0.0955 0.0945 0.0931 0.0940 

[TRAIN] Epoch[5](1408/1500); Loss: 0.138403; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1647 0.1493 0.1489 0.1464 0.1424 0.1383 0.1365 0.1356 0.1342 0.1324 0.1325 0.1317 0.1306 0.1304 0.1297 0.1306 

[TRAIN] Epoch[5](1409/1500); Loss: 0.115382; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1390 0.1472 0.1507 0.1412 0.1289 0.1166 0.1076 0.1008 0.1002 0.1008 0.1009 0.1008 0.1011 0.1020 0.1036 0.1048 

[TRAIN] Epoch[5](1410/1500); Loss: 0.108421; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1353 0.1297 0.1313 0.1244 0.1168 0.1079 0.1018 0.0984 0.0966 0.0979 0.0982 0.0980 0.0995 0.1001 0.0990 0.0999 

[TRAIN] Epoch[5](1411/1500); Loss: 0.197415; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2798 0.2441 0.2389 0.2508 0.2421 0.2290 0.2128 0.1984 0.1888 0.1779 0.1649 0.1543 0.1478 0.1430 0.1415 0.1446 

[TRAIN] Epoch[5](1412/1500); Loss: 0.121395; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1528 0.1296 0.1330 0.1288 0.1225 0.1172 0.1163 0.1156 0.1155 0.1170 0.1167 0.1148 0.1144 0.1156 0.1164 0.1160 

[TRAIN] Epoch[5](1413/1500); Loss: 0.107281; Backpropagation: 0.0929 sec; Batch: 0.4241 sec
0.1355 0.1115 0.1239 0.1238 0.1155 0.1061 0.1010 0.0987 0.1014 0.0994 0.0992 0.1008 0.0996 0.0987 0.1005 0.1008 

[TRAIN] Epoch[5](1414/1500); Loss: 0.099137; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0687 0.1424 0.1919 0.1800 0.1569 0.1267 0.0982 0.0790 0.0716 0.0678 0.0624 0.0645 0.0695 0.0683 0.0682 0.0700 

[TRAIN] Epoch[5](1415/1500); Loss: 0.141257; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.2090 0.1632 0.1681 0.1790 0.1704 0.1559 0.1403 0.1298 0.1242 0.1181 0.1165 0.1179 0.1166 0.1141 0.1170 0.1200 

[TRAIN] Epoch[5](1416/1500); Loss: 0.067896; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1055 0.1315 0.1202 0.0954 0.0694 0.0537 0.0492 0.0485 0.0490 0.0488 0.0492 0.0509 0.0522 0.0525 0.0542 0.0562 

[TRAIN] Epoch[5](1417/1500); Loss: 0.125378; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1343 0.1412 0.1422 0.1373 0.1285 0.1220 0.1216 0.1222 0.1192 0.1185 0.1203 0.1206 0.1196 0.1192 0.1194 0.1200 

[TRAIN] Epoch[5](1418/1500); Loss: 0.124900; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1519 0.1421 0.1406 0.1405 0.1349 0.1283 0.1241 0.1216 0.1179 0.1185 0.1171 0.1144 0.1120 0.1129 0.1116 0.1100 

[TRAIN] Epoch[5](1419/1500); Loss: 0.183653; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1795 0.2052 0.2311 0.2237 0.2089 0.1934 0.1804 0.1710 0.1652 0.1640 0.1655 0.1683 0.1703 0.1696 0.1705 0.1718 

[TRAIN] Epoch[5](1420/1500); Loss: 0.164118; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1823 0.1825 0.1766 0.1707 0.1644 0.1612 0.1608 0.1594 0.1589 0.1588 0.1585 0.1574 0.1581 0.1584 0.1587 0.1591 

[TRAIN] Epoch[5](1421/1500); Loss: 0.094327; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1512 0.1068 0.1039 0.1219 0.1142 0.1034 0.0930 0.0861 0.0809 0.0800 0.0814 0.0793 0.0766 0.0764 0.0774 0.0767 

[TRAIN] Epoch[5](1422/1500); Loss: 0.163418; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1689 0.1909 0.1996 0.1919 0.1794 0.1663 0.1581 0.1557 0.1537 0.1525 0.1525 0.1500 0.1493 0.1491 0.1487 0.1481 

[TRAIN] Epoch[5](1423/1500); Loss: 0.101028; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1519 0.0988 0.1321 0.1244 0.1111 0.0936 0.0893 0.0900 0.0872 0.0870 0.0918 0.0919 0.0897 0.0910 0.0933 0.0933 

[TRAIN] Epoch[5](1424/1500); Loss: 0.169913; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2515 0.1955 0.1986 0.2257 0.2155 0.1992 0.1762 0.1580 0.1501 0.1426 0.1385 0.1359 0.1338 0.1303 0.1332 0.1341 

[TRAIN] Epoch[5](1425/1500); Loss: 0.098211; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1477 0.1077 0.1309 0.1239 0.1145 0.1036 0.0934 0.0852 0.0821 0.0799 0.0814 0.0827 0.0822 0.0819 0.0854 0.0889 

[TRAIN] Epoch[5](1426/1500); Loss: 0.102433; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0912 0.1471 0.1599 0.1438 0.1216 0.0980 0.0854 0.0866 0.0928 0.0864 0.0846 0.0858 0.0894 0.0902 0.0872 0.0890 

[TRAIN] Epoch[5](1427/1500); Loss: 0.093305; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1427 0.1030 0.1448 0.1358 0.1197 0.0949 0.0809 0.0784 0.0774 0.0738 0.0740 0.0747 0.0725 0.0709 0.0739 0.0754 

[TRAIN] Epoch[5](1428/1500); Loss: 0.168070; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2157 0.1899 0.1829 0.1898 0.1850 0.1782 0.1689 0.1609 0.1582 0.1574 0.1554 0.1517 0.1495 0.1482 0.1483 0.1491 

[TRAIN] Epoch[5](1429/1500); Loss: 0.159121; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2390 0.1932 0.1817 0.1900 0.1823 0.1697 0.1569 0.1454 0.1377 0.1341 0.1333 0.1323 0.1346 0.1385 0.1385 0.1386 

[TRAIN] Epoch[5](1430/1500); Loss: 0.202596; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2388 0.2250 0.2161 0.2215 0.2194 0.2110 0.2020 0.1960 0.1905 0.1873 0.1868 0.1858 0.1880 0.1901 0.1916 0.1919 

[TRAIN] Epoch[5](1431/1500); Loss: 0.072567; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0757 0.1234 0.1197 0.1014 0.0825 0.0684 0.0587 0.0572 0.0586 0.0588 0.0584 0.0580 0.0588 0.0591 0.0606 0.0616 

[TRAIN] Epoch[5](1432/1500); Loss: 0.152762; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2133 0.1852 0.1852 0.1922 0.1846 0.1764 0.1662 0.1513 0.1462 0.1423 0.1350 0.1239 0.1155 0.1126 0.1085 0.1058 

[TRAIN] Epoch[5](1433/1500); Loss: 0.128722; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2215 0.1574 0.1579 0.1785 0.1704 0.1552 0.1322 0.1136 0.1077 0.1014 0.0917 0.0909 0.0987 0.0965 0.0928 0.0931 

[TRAIN] Epoch[5](1434/1500); Loss: 0.089583; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1526 0.0322 0.1693 0.1601 0.1444 0.1142 0.0800 0.0581 0.0482 0.0713 0.0603 0.0586 0.0608 0.0710 0.0775 0.0746 

[TRAIN] Epoch[5](1435/1500); Loss: 0.120808; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1322 0.1347 0.1338 0.1264 0.1203 0.1181 0.1169 0.1170 0.1163 0.1164 0.1165 0.1164 0.1166 0.1164 0.1170 0.1179 

[TRAIN] Epoch[5](1436/1500); Loss: 0.102669; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1718 0.1161 0.1073 0.1051 0.1004 0.0964 0.0966 0.0960 0.0936 0.0931 0.0934 0.0942 0.0931 0.0938 0.0958 0.0962 

[TRAIN] Epoch[5](1437/1500); Loss: 0.152251; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1710 0.1804 0.1794 0.1709 0.1597 0.1499 0.1464 0.1453 0.1437 0.1436 0.1431 0.1412 0.1404 0.1410 0.1403 0.1395 

[TRAIN] Epoch[5](1438/1500); Loss: 0.101325; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1163 0.1310 0.1282 0.1188 0.1079 0.1007 0.0986 0.0928 0.0917 0.0923 0.0894 0.0888 0.0893 0.0930 0.0908 0.0915 

[TRAIN] Epoch[5](1439/1500); Loss: 0.078459; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.0989 0.1022 0.0975 0.0945 0.0818 0.0719 0.0713 0.0720 0.0695 0.0681 0.0685 0.0703 0.0727 0.0705 0.0725 0.0732 

[TRAIN] Epoch[5](1440/1500); Loss: 0.168708; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2117 0.1946 0.2045 0.2044 0.1935 0.1790 0.1684 0.1623 0.1610 0.1582 0.1538 0.1474 0.1421 0.1408 0.1398 0.1380 

[TRAIN] Epoch[5](1441/1500); Loss: 0.143375; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1687 0.1373 0.1865 0.1799 0.1698 0.1504 0.1335 0.1268 0.1268 0.1303 0.1290 0.1277 0.1303 0.1312 0.1322 0.1336 

[TRAIN] Epoch[5](1442/1500); Loss: 0.099564; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1587 0.1407 0.1289 0.1215 0.1121 0.1001 0.0921 0.0875 0.0840 0.0832 0.0829 0.0801 0.0795 0.0799 0.0816 0.0803 

[TRAIN] Epoch[5](1443/1500); Loss: 0.133953; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1408 0.1033 0.2053 0.1959 0.1806 0.1540 0.1303 0.1166 0.1072 0.1109 0.1096 0.1107 0.1156 0.1188 0.1204 0.1231 

[TRAIN] Epoch[5](1444/1500); Loss: 0.091626; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1023 0.1528 0.1523 0.1321 0.1053 0.0830 0.0763 0.0725 0.0729 0.0723 0.0718 0.0729 0.0726 0.0748 0.0756 0.0766 

[TRAIN] Epoch[5](1445/1500); Loss: 0.078553; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0958 0.0805 0.0838 0.0772 0.0711 0.0707 0.0752 0.0715 0.0713 0.0746 0.0764 0.0767 0.0799 0.0810 0.0847 0.0864 

[TRAIN] Epoch[5](1446/1500); Loss: 0.104394; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1158 0.1360 0.1402 0.1316 0.1167 0.1025 0.0968 0.0929 0.0882 0.0871 0.0892 0.0897 0.0919 0.0948 0.0974 0.0995 

[TRAIN] Epoch[5](1447/1500); Loss: 0.050141; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0597 0.0710 0.0634 0.0524 0.0491 0.0451 0.0454 0.0437 0.0442 0.0457 0.0453 0.0450 0.0482 0.0475 0.0477 0.0487 

[TRAIN] Epoch[5](1448/1500); Loss: 0.116669; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1341 0.1190 0.1921 0.1866 0.1726 0.1453 0.1165 0.0998 0.0913 0.0927 0.0886 0.0842 0.0844 0.0856 0.0867 0.0872 

[TRAIN] Epoch[5](1449/1500); Loss: 0.108981; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1313 0.1235 0.1228 0.1178 0.1106 0.1060 0.1072 0.1035 0.1023 0.1034 0.1043 0.1020 0.1018 0.1025 0.1023 0.1021 

[TRAIN] Epoch[5](1450/1500); Loss: 0.110845; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1270 0.1183 0.1607 0.1532 0.1403 0.1196 0.1020 0.0946 0.0903 0.0922 0.0925 0.0920 0.0952 0.0968 0.0983 0.1005 

[TRAIN] Epoch[5](1451/1500); Loss: 0.121628; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2017 0.1412 0.1571 0.1626 0.1519 0.1339 0.1128 0.1020 0.1005 0.0994 0.0946 0.0935 0.0993 0.0974 0.0982 0.0999 

[TRAIN] Epoch[5](1452/1500); Loss: 0.150747; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1655 0.1872 0.1835 0.1765 0.1673 0.1556 0.1458 0.1383 0.1338 0.1318 0.1311 0.1326 0.1358 0.1398 0.1422 0.1452 

[TRAIN] Epoch[5](1453/1500); Loss: 0.217404; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.4028 0.2933 0.3017 0.3546 0.3369 0.3023 0.2487 0.1977 0.1827 0.1598 0.1309 0.1047 0.1130 0.1140 0.1144 0.1209 

[TRAIN] Epoch[5](1454/1500); Loss: 0.115398; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1515 0.1769 0.1666 0.1563 0.1351 0.1169 0.1066 0.0983 0.0916 0.0888 0.0896 0.0891 0.0923 0.0935 0.0951 0.0981 

[TRAIN] Epoch[5](1455/1500); Loss: 0.155497; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2299 0.1949 0.1909 0.2144 0.2064 0.1924 0.1708 0.1494 0.1448 0.1379 0.1274 0.1097 0.1029 0.1011 0.1057 0.1094 

[TRAIN] Epoch[5](1456/1500); Loss: 0.080266; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.0904 0.1208 0.1312 0.1198 0.1037 0.0834 0.0705 0.0661 0.0645 0.0650 0.0640 0.0614 0.0611 0.0610 0.0604 0.0611 

[TRAIN] Epoch[5](1457/1500); Loss: 0.039624; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0611 0.0758 0.0610 0.0427 0.0319 0.0295 0.0300 0.0300 0.0306 0.0319 0.0321 0.0328 0.0348 0.0357 0.0366 0.0376 

[TRAIN] Epoch[5](1458/1500); Loss: 0.137296; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1815 0.1614 0.1562 0.1603 0.1516 0.1417 0.1331 0.1272 0.1241 0.1231 0.1218 0.1217 0.1213 0.1217 0.1239 0.1262 

[TRAIN] Epoch[5](1459/1500); Loss: 0.079566; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0694 0.0877 0.1436 0.1347 0.1187 0.0923 0.0693 0.0623 0.0605 0.0623 0.0605 0.0603 0.0629 0.0626 0.0626 0.0633 

[TRAIN] Epoch[5](1460/1500); Loss: 0.139366; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1807 0.1583 0.1658 0.1616 0.1505 0.1379 0.1345 0.1312 0.1289 0.1279 0.1268 0.1241 0.1226 0.1242 0.1272 0.1277 

[TRAIN] Epoch[5](1461/1500); Loss: 0.143646; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2091 0.1633 0.1692 0.1747 0.1669 0.1539 0.1403 0.1331 0.1284 0.1255 0.1224 0.1229 0.1225 0.1208 0.1220 0.1233 

[TRAIN] Epoch[5](1462/1500); Loss: 0.160581; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1730 0.2078 0.2187 0.2081 0.1897 0.1691 0.1552 0.1475 0.1403 0.1377 0.1367 0.1357 0.1378 0.1382 0.1362 0.1375 

[TRAIN] Epoch[5](1463/1500); Loss: 0.079368; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1236 0.0877 0.0801 0.0901 0.0853 0.0790 0.0759 0.0743 0.0707 0.0710 0.0734 0.0719 0.0704 0.0723 0.0729 0.0714 

[TRAIN] Epoch[5](1464/1500); Loss: 0.120406; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1433 0.0808 0.1792 0.1701 0.1557 0.1313 0.1103 0.1015 0.0972 0.1053 0.1023 0.1033 0.1067 0.1118 0.1125 0.1151 

[TRAIN] Epoch[5](1465/1500); Loss: 0.115002; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1368 0.1256 0.1313 0.1272 0.1184 0.1117 0.1090 0.1074 0.1060 0.1061 0.1078 0.1088 0.1083 0.1096 0.1116 0.1143 

[TRAIN] Epoch[5](1466/1500); Loss: 0.096428; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1289 0.1085 0.1036 0.1090 0.0994 0.0930 0.0928 0.0899 0.0887 0.0890 0.0906 0.0904 0.0885 0.0896 0.0899 0.0911 

[TRAIN] Epoch[5](1467/1500); Loss: 0.200189; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.3206 0.2492 0.2658 0.2993 0.2848 0.2598 0.2249 0.1975 0.1915 0.1808 0.1635 0.1376 0.1135 0.1059 0.1040 0.1046 

[TRAIN] Epoch[5](1468/1500); Loss: 0.136072; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.2036 0.1542 0.1484 0.1657 0.1589 0.1477 0.1356 0.1273 0.1225 0.1195 0.1175 0.1172 0.1153 0.1125 0.1134 0.1179 

[TRAIN] Epoch[5](1469/1500); Loss: 0.136792; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1943 0.1607 0.1484 0.1505 0.1465 0.1417 0.1369 0.1297 0.1262 0.1252 0.1242 0.1215 0.1192 0.1197 0.1225 0.1215 

[TRAIN] Epoch[5](1470/1500); Loss: 0.135497; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1750 0.1467 0.1423 0.1530 0.1476 0.1402 0.1346 0.1322 0.1291 0.1282 0.1290 0.1256 0.1217 0.1222 0.1211 0.1193 

[TRAIN] Epoch[5](1471/1500); Loss: 0.157169; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1850 0.1790 0.1748 0.1714 0.1639 0.1575 0.1538 0.1492 0.1482 0.1479 0.1463 0.1467 0.1474 0.1473 0.1481 0.1482 

[TRAIN] Epoch[5](1472/1500); Loss: 0.129149; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1619 0.1607 0.1538 0.1487 0.1386 0.1290 0.1240 0.1193 0.1179 0.1182 0.1181 0.1151 0.1144 0.1156 0.1154 0.1158 

[TRAIN] Epoch[5](1473/1500); Loss: 0.126050; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1812 0.1647 0.1388 0.1384 0.1281 0.1199 0.1149 0.1141 0.1122 0.1141 0.1150 0.1144 0.1139 0.1138 0.1161 0.1170 

[TRAIN] Epoch[5](1474/1500); Loss: 0.162579; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3029 0.2104 0.2156 0.2659 0.2515 0.2266 0.1861 0.1496 0.1379 0.1228 0.1033 0.0838 0.0844 0.0829 0.0856 0.0920 

[TRAIN] Epoch[5](1475/1500); Loss: 0.137546; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1712 0.1559 0.1748 0.1660 0.1550 0.1393 0.1294 0.1265 0.1234 0.1222 0.1219 0.1219 0.1220 0.1230 0.1238 0.1244 

[TRAIN] Epoch[5](1476/1500); Loss: 0.157930; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2203 0.1801 0.1797 0.1943 0.1867 0.1772 0.1590 0.1460 0.1434 0.1391 0.1334 0.1311 0.1352 0.1326 0.1335 0.1354 

[TRAIN] Epoch[5](1477/1500); Loss: 0.117996; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1400 0.1266 0.1539 0.1471 0.1365 0.1211 0.1114 0.1090 0.1076 0.1072 0.1068 0.1049 0.1037 0.1038 0.1044 0.1038 

[TRAIN] Epoch[5](1478/1500); Loss: 0.155441; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2221 0.1967 0.1976 0.2120 0.1993 0.1833 0.1689 0.1509 0.1470 0.1414 0.1333 0.1183 0.1060 0.1024 0.1031 0.1048 

[TRAIN] Epoch[5](1479/1500); Loss: 0.111741; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1460 0.1437 0.1374 0.1350 0.1255 0.1161 0.1085 0.1035 0.1009 0.0995 0.0966 0.0958 0.0952 0.0945 0.0943 0.0953 

[TRAIN] Epoch[5](1480/1500); Loss: 0.090257; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0948 0.1601 0.1569 0.1364 0.1113 0.0885 0.0774 0.0750 0.0755 0.0694 0.0671 0.0665 0.0656 0.0638 0.0667 0.0692 

[TRAIN] Epoch[5](1481/1500); Loss: 0.154838; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1923 0.1663 0.1646 0.1739 0.1678 0.1591 0.1523 0.1484 0.1463 0.1455 0.1460 0.1446 0.1418 0.1421 0.1433 0.1432 

[TRAIN] Epoch[5](1482/1500); Loss: 0.135490; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1949 0.1474 0.1488 0.1748 0.1672 0.1558 0.1397 0.1276 0.1228 0.1190 0.1143 0.1125 0.1117 0.1085 0.1106 0.1122 

[TRAIN] Epoch[5](1483/1500); Loss: 0.163965; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2166 0.1807 0.2026 0.1994 0.1894 0.1724 0.1575 0.1503 0.1469 0.1479 0.1456 0.1421 0.1424 0.1435 0.1428 0.1434 

[TRAIN] Epoch[5](1484/1500); Loss: 0.154531; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1852 0.1928 0.1980 0.1903 0.1739 0.1589 0.1504 0.1430 0.1359 0.1325 0.1331 0.1341 0.1341 0.1349 0.1367 0.1387 

[TRAIN] Epoch[5](1485/1500); Loss: 0.067787; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1102 0.0829 0.0742 0.0833 0.0775 0.0716 0.0699 0.0584 0.0571 0.0560 0.0573 0.0585 0.0560 0.0564 0.0571 0.0583 

[TRAIN] Epoch[5](1486/1500); Loss: 0.088107; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1241 0.1300 0.1182 0.0930 0.0779 0.0750 0.0764 0.0730 0.0776 0.0757 0.0783 0.0794 0.0800 0.0817 0.0832 0.0861 

[TRAIN] Epoch[5](1487/1500); Loss: 0.105740; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1511 0.1355 0.1286 0.1273 0.1176 0.1064 0.0994 0.0944 0.0913 0.0913 0.0904 0.0907 0.0914 0.0911 0.0921 0.0933 

[TRAIN] Epoch[5](1488/1500); Loss: 0.077432; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1819 0.0832 0.0799 0.1270 0.1115 0.0839 0.0531 0.0496 0.0543 0.0642 0.0515 0.0526 0.0611 0.0711 0.0572 0.0568 

[TRAIN] Epoch[5](1489/1500); Loss: 0.082176; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1063 0.0961 0.1115 0.1019 0.0879 0.0776 0.0780 0.0738 0.0707 0.0714 0.0728 0.0724 0.0720 0.0742 0.0742 0.0740 

[TRAIN] Epoch[5](1490/1500); Loss: 0.111734; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1363 0.1320 0.1256 0.1208 0.1160 0.1126 0.1093 0.1061 0.1047 0.1039 0.1038 0.1032 0.1034 0.1021 0.1034 0.1046 

[TRAIN] Epoch[5](1491/1500); Loss: 0.086380; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1328 0.1039 0.0980 0.1064 0.0978 0.0888 0.0809 0.0766 0.0739 0.0746 0.0757 0.0734 0.0732 0.0755 0.0756 0.0749 

[TRAIN] Epoch[5](1492/1500); Loss: 0.143027; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2040 0.1903 0.1909 0.1929 0.1761 0.1550 0.1380 0.1298 0.1205 0.1155 0.1159 0.1136 0.1112 0.1116 0.1121 0.1112 

[TRAIN] Epoch[5](1493/1500); Loss: 0.200140; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2921 0.2449 0.2432 0.2610 0.2535 0.2396 0.2168 0.1969 0.1907 0.1828 0.1696 0.1538 0.1437 0.1381 0.1374 0.1381 

[TRAIN] Epoch[5](1494/1500); Loss: 0.179595; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2222 0.2060 0.1991 0.1978 0.1922 0.1850 0.1784 0.1734 0.1700 0.1680 0.1655 0.1642 0.1625 0.1626 0.1630 0.1637 

[TRAIN] Epoch[5](1495/1500); Loss: 0.124385; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.1481 0.1391 0.1391 0.1365 0.1313 0.1266 0.1225 0.1197 0.1174 0.1167 0.1166 0.1158 0.1153 0.1144 0.1153 0.1157 

[TRAIN] Epoch[5](1496/1500); Loss: 0.146031; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1861 0.1687 0.1659 0.1684 0.1599 0.1510 0.1440 0.1397 0.1375 0.1362 0.1335 0.1298 0.1292 0.1289 0.1282 0.1293 

[TRAIN] Epoch[5](1497/1500); Loss: 0.097128; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1138 0.1487 0.1583 0.1429 0.1216 0.1002 0.0872 0.0815 0.0761 0.0741 0.0740 0.0730 0.0740 0.0763 0.0757 0.0766 

[TRAIN] Epoch[5](1498/1500); Loss: 0.100756; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1651 0.0521 0.1634 0.1533 0.1380 0.1102 0.0796 0.0688 0.0733 0.0813 0.0793 0.0809 0.0859 0.0920 0.0932 0.0958 

[TRAIN] Epoch[5](1499/1500); Loss: 0.096977; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1235 0.1189 0.1136 0.1085 0.1003 0.0950 0.0939 0.0894 0.0885 0.0898 0.0907 0.0878 0.0869 0.0883 0.0883 0.0883 

[TRAIN] Epoch[5](1500/1500); Loss: 0.085204; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1363 0.0799 0.1278 0.1186 0.1048 0.0813 0.0700 0.0750 0.0746 0.0724 0.0709 0.0715 0.0696 0.0694 0.0695 0.0717 

[TRAIN] Epoch[6](1/1500); Loss: 0.114475; Backpropagation: 0.0974 sec; Batch: 0.4711 sec
0.1268 0.1316 0.1259 0.1179 0.1144 0.1143 0.1139 0.1105 0.1093 0.1093 0.1100 0.1090 0.1089 0.1093 0.1099 0.1105 

[TRAIN] Epoch[6](2/1500); Loss: 0.099714; Backpropagation: 0.0935 sec; Batch: 0.4294 sec
0.1268 0.1049 0.1419 0.1310 0.1145 0.0937 0.0873 0.0887 0.0867 0.0858 0.0867 0.0905 0.0871 0.0886 0.0897 0.0915 

[TRAIN] Epoch[6](3/1500); Loss: 0.145518; Backpropagation: 0.0933 sec; Batch: 0.4302 sec
0.2633 0.1887 0.1896 0.2236 0.2093 0.1864 0.1550 0.1312 0.1226 0.1096 0.0979 0.0908 0.0929 0.0884 0.0889 0.0900 

[TRAIN] Epoch[6](4/1500); Loss: 0.086181; Backpropagation: 0.0933 sec; Batch: 0.4264 sec
0.1069 0.1028 0.0998 0.0945 0.0875 0.0839 0.0826 0.0805 0.0798 0.0794 0.0793 0.0797 0.0793 0.0803 0.0810 0.0817 

[TRAIN] Epoch[6](5/1500); Loss: 0.090078; Backpropagation: 0.0935 sec; Batch: 0.4254 sec
0.1005 0.1035 0.0952 0.0934 0.0899 0.0875 0.0868 0.0879 0.0860 0.0860 0.0868 0.0874 0.0863 0.0870 0.0887 0.0883 

[TRAIN] Epoch[6](6/1500); Loss: 0.142967; Backpropagation: 0.0936 sec; Batch: 0.4262 sec
0.1659 0.1520 0.1539 0.1524 0.1475 0.1415 0.1378 0.1364 0.1360 0.1357 0.1360 0.1370 0.1374 0.1382 0.1390 0.1407 

[TRAIN] Epoch[6](7/1500); Loss: 0.111969; Backpropagation: 0.0934 sec; Batch: 0.4258 sec
0.1818 0.1507 0.1452 0.1429 0.1335 0.1207 0.1076 0.0990 0.0964 0.0943 0.0907 0.0859 0.0841 0.0856 0.0861 0.0870 

[TRAIN] Epoch[6](8/1500); Loss: 0.093775; Backpropagation: 0.0936 sec; Batch: 0.4262 sec
0.1218 0.1203 0.1162 0.1121 0.1041 0.0953 0.0907 0.0881 0.0848 0.0824 0.0811 0.0805 0.0800 0.0799 0.0812 0.0817 

[TRAIN] Epoch[6](9/1500); Loss: 0.173529; Backpropagation: 0.0934 sec; Batch: 0.4257 sec
0.2196 0.2164 0.2172 0.2232 0.2073 0.1892 0.1725 0.1625 0.1599 0.1552 0.1475 0.1420 0.1415 0.1396 0.1401 0.1428 

[TRAIN] Epoch[6](10/1500); Loss: 0.068644; Backpropagation: 0.0934 sec; Batch: 0.4250 sec
0.1408 0.0815 0.0659 0.0709 0.0647 0.0586 0.0679 0.0564 0.0561 0.0608 0.0608 0.0600 0.0628 0.0634 0.0632 0.0646 

[TRAIN] Epoch[6](11/1500); Loss: 0.152520; Backpropagation: 0.0935 sec; Batch: 0.4259 sec
0.1969 0.1678 0.1644 0.1717 0.1665 0.1594 0.1517 0.1469 0.1442 0.1422 0.1401 0.1386 0.1375 0.1375 0.1373 0.1376 

[TRAIN] Epoch[6](12/1500); Loss: 0.122517; Backpropagation: 0.0932 sec; Batch: 0.4255 sec
0.1555 0.1443 0.1373 0.1335 0.1270 0.1217 0.1191 0.1153 0.1138 0.1142 0.1128 0.1123 0.1123 0.1127 0.1139 0.1144 

[TRAIN] Epoch[6](13/1500); Loss: 0.099992; Backpropagation: 0.0934 sec; Batch: 0.4255 sec
0.1204 0.1151 0.1345 0.1246 0.1114 0.0990 0.0948 0.0893 0.0887 0.0886 0.0900 0.0879 0.0885 0.0883 0.0888 0.0900 

[TRAIN] Epoch[6](14/1500); Loss: 0.142174; Backpropagation: 0.0936 sec; Batch: 0.4314 sec
0.1726 0.1781 0.1755 0.1675 0.1529 0.1421 0.1381 0.1338 0.1297 0.1285 0.1254 0.1248 0.1244 0.1252 0.1270 0.1292 

[TRAIN] Epoch[6](15/1500); Loss: 0.120931; Backpropagation: 0.0934 sec; Batch: 0.4262 sec
0.2230 0.1547 0.1585 0.1887 0.1764 0.1556 0.1222 0.0944 0.0850 0.0803 0.0781 0.0880 0.0797 0.0804 0.0832 0.0867 

[TRAIN] Epoch[6](16/1500); Loss: 0.149482; Backpropagation: 0.0933 sec; Batch: 0.4261 sec
0.2201 0.1869 0.1841 0.1947 0.1823 0.1680 0.1500 0.1361 0.1314 0.1266 0.1210 0.1181 0.1195 0.1166 0.1180 0.1183 

[TRAIN] Epoch[6](17/1500); Loss: 0.108614; Backpropagation: 0.0935 sec; Batch: 0.4259 sec
0.1553 0.1236 0.1319 0.1247 0.1156 0.1056 0.0999 0.0963 0.0947 0.0959 0.0980 0.0966 0.0970 0.0994 0.1014 0.1017 

[TRAIN] Epoch[6](18/1500); Loss: 0.109500; Backpropagation: 0.0933 sec; Batch: 0.4248 sec
0.2259 0.1279 0.1181 0.1270 0.1181 0.1036 0.0929 0.0893 0.0888 0.0902 0.0916 0.0921 0.0939 0.0958 0.0975 0.0994 

[TRAIN] Epoch[6](19/1500); Loss: 0.143921; Backpropagation: 0.1032 sec; Batch: 0.4349 sec
0.1745 0.1572 0.1551 0.1521 0.1474 0.1427 0.1417 0.1384 0.1371 0.1370 0.1373 0.1364 0.1358 0.1369 0.1367 0.1366 

[TRAIN] Epoch[6](20/1500); Loss: 0.134458; Backpropagation: 0.0922 sec; Batch: 0.4250 sec
0.1639 0.1462 0.1418 0.1387 0.1351 0.1318 0.1307 0.1304 0.1293 0.1293 0.1299 0.1284 0.1281 0.1296 0.1295 0.1288 

[TRAIN] Epoch[6](21/1500); Loss: 0.094300; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1047 0.1178 0.1267 0.1203 0.1103 0.0956 0.0883 0.0823 0.0815 0.0843 0.0824 0.0806 0.0826 0.0826 0.0834 0.0854 

[TRAIN] Epoch[6](22/1500); Loss: 0.146961; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1885 0.1602 0.1538 0.1537 0.1503 0.1466 0.1440 0.1385 0.1381 0.1395 0.1400 0.1381 0.1387 0.1405 0.1409 0.1399 

[TRAIN] Epoch[6](23/1500); Loss: 0.077213; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0913 0.0943 0.1243 0.1160 0.1006 0.0793 0.0654 0.0610 0.0599 0.0628 0.0620 0.0610 0.0622 0.0635 0.0648 0.0672 

[TRAIN] Epoch[6](24/1500); Loss: 0.115868; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1425 0.1450 0.1371 0.1272 0.1186 0.1124 0.1100 0.1094 0.1082 0.1068 0.1062 0.1061 0.1059 0.1056 0.1062 0.1066 

[TRAIN] Epoch[6](25/1500); Loss: 0.103129; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2210 0.1367 0.1379 0.1751 0.1610 0.1369 0.0995 0.0738 0.0635 0.0622 0.0687 0.0645 0.0595 0.0624 0.0637 0.0636 

[TRAIN] Epoch[6](26/1500); Loss: 0.095745; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1101 0.1053 0.1058 0.1018 0.0984 0.0955 0.0923 0.0901 0.0889 0.0905 0.0904 0.0901 0.0899 0.0922 0.0951 0.0956 

[TRAIN] Epoch[6](27/1500); Loss: 0.077057; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1456 0.1087 0.1019 0.1049 0.0933 0.0805 0.0680 0.0612 0.0569 0.0588 0.0613 0.0562 0.0572 0.0606 0.0591 0.0586 

[TRAIN] Epoch[6](28/1500); Loss: 0.096933; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1203 0.1369 0.1252 0.1100 0.1016 0.0923 0.0902 0.0853 0.0851 0.0871 0.0872 0.0844 0.0837 0.0867 0.0871 0.0878 

[TRAIN] Epoch[6](29/1500); Loss: 0.066498; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0562 0.0857 0.0865 0.0779 0.0675 0.0615 0.0638 0.0595 0.0614 0.0611 0.0632 0.0614 0.0628 0.0642 0.0652 0.0660 

[TRAIN] Epoch[6](30/1500); Loss: 0.091247; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1098 0.1115 0.1227 0.1141 0.0997 0.0873 0.0859 0.0816 0.0810 0.0808 0.0796 0.0790 0.0795 0.0811 0.0827 0.0837 

[TRAIN] Epoch[6](31/1500); Loss: 0.074844; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0806 0.0988 0.0901 0.0777 0.0742 0.0723 0.0710 0.0700 0.0697 0.0702 0.0696 0.0692 0.0697 0.0711 0.0712 0.0721 

[TRAIN] Epoch[6](32/1500); Loss: 0.099735; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1417 0.1196 0.1124 0.1162 0.1082 0.1014 0.0948 0.0912 0.0887 0.0882 0.0887 0.0891 0.0875 0.0879 0.0898 0.0904 

[TRAIN] Epoch[6](33/1500); Loss: 0.094329; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1440 0.1090 0.1122 0.1144 0.1090 0.1050 0.0938 0.0843 0.0817 0.0806 0.0790 0.0800 0.0787 0.0781 0.0783 0.0811 

[TRAIN] Epoch[6](34/1500); Loss: 0.125798; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1612 0.1532 0.1473 0.1451 0.1402 0.1351 0.1278 0.1222 0.1196 0.1174 0.1134 0.1089 0.1056 0.1047 0.1050 0.1060 

[TRAIN] Epoch[6](35/1500); Loss: 0.087790; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0915 0.1040 0.1132 0.1013 0.0887 0.0802 0.0827 0.0810 0.0807 0.0799 0.0820 0.0826 0.0827 0.0824 0.0851 0.0866 

[TRAIN] Epoch[6](36/1500); Loss: 0.148643; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.1915 0.1455 0.1725 0.1641 0.1548 0.1433 0.1392 0.1346 0.1353 0.1393 0.1405 0.1398 0.1406 0.1438 0.1459 0.1475 

[TRAIN] Epoch[6](37/1500); Loss: 0.089772; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2180 0.1194 0.1074 0.0996 0.0866 0.0693 0.0804 0.0756 0.0733 0.0670 0.0661 0.0739 0.0726 0.0718 0.0742 0.0811 

[TRAIN] Epoch[6](38/1500); Loss: 0.139677; Backpropagation: 0.0919 sec; Batch: 0.4386 sec
0.1778 0.1415 0.1412 0.1450 0.1404 0.1364 0.1407 0.1335 0.1321 0.1332 0.1367 0.1362 0.1332 0.1350 0.1355 0.1365 

[TRAIN] Epoch[6](39/1500); Loss: 0.077533; Backpropagation: 0.0920 sec; Batch: 0.4263 sec
0.1111 0.1210 0.1195 0.1039 0.0857 0.0730 0.0681 0.0634 0.0611 0.0612 0.0621 0.0610 0.0610 0.0621 0.0632 0.0632 

[TRAIN] Epoch[6](40/1500); Loss: 0.089354; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0941 0.0924 0.1012 0.0953 0.0862 0.0815 0.0803 0.0808 0.0816 0.0833 0.0865 0.0881 0.0904 0.0937 0.0963 0.0980 

[TRAIN] Epoch[6](41/1500); Loss: 0.125185; Backpropagation: 0.0919 sec; Batch: 0.4251 sec
0.1994 0.1457 0.1609 0.1690 0.1568 0.1368 0.1254 0.1094 0.1079 0.1039 0.0993 0.0980 0.1002 0.0961 0.0956 0.0984 

[TRAIN] Epoch[6](42/1500); Loss: 0.112861; Backpropagation: 0.0997 sec; Batch: 0.4333 sec
0.1939 0.1418 0.1247 0.1174 0.1110 0.1065 0.1030 0.0996 0.0981 0.1001 0.1007 0.0995 0.0999 0.1019 0.1026 0.1050 

[TRAIN] Epoch[6](43/1500); Loss: 0.155949; Backpropagation: 0.0920 sec; Batch: 0.4311 sec
0.2556 0.1948 0.1909 0.2177 0.2064 0.1903 0.1660 0.1470 0.1400 0.1358 0.1280 0.1152 0.1045 0.1011 0.1014 0.1004 

[TRAIN] Epoch[6](44/1500); Loss: 0.146014; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2561 0.1879 0.1896 0.2224 0.2037 0.1759 0.1423 0.1179 0.1138 0.1089 0.1074 0.1022 0.1016 0.0990 0.1039 0.1036 

[TRAIN] Epoch[6](45/1500); Loss: 0.142329; Backpropagation: 0.0920 sec; Batch: 0.4260 sec
0.1879 0.1745 0.1607 0.1534 0.1459 0.1400 0.1354 0.1319 0.1320 0.1302 0.1304 0.1308 0.1291 0.1301 0.1323 0.1327 

[TRAIN] Epoch[6](46/1500); Loss: 0.151063; Backpropagation: 0.0916 sec; Batch: 0.4311 sec
0.1749 0.1645 0.1617 0.1613 0.1578 0.1550 0.1490 0.1461 0.1452 0.1448 0.1443 0.1427 0.1421 0.1421 0.1427 0.1430 

[TRAIN] Epoch[6](47/1500); Loss: 0.140973; Backpropagation: 0.0992 sec; Batch: 0.4319 sec
0.1776 0.1418 0.1844 0.1744 0.1605 0.1409 0.1308 0.1295 0.1273 0.1252 0.1261 0.1285 0.1260 0.1258 0.1279 0.1288 

[TRAIN] Epoch[6](48/1500); Loss: 0.104992; Backpropagation: 0.0921 sec; Batch: 0.4257 sec
0.1415 0.1260 0.1162 0.1121 0.1061 0.1021 0.0995 0.0985 0.0968 0.0965 0.0973 0.0976 0.0968 0.0970 0.0979 0.0979 

[TRAIN] Epoch[6](49/1500); Loss: 0.089683; Backpropagation: 0.0920 sec; Batch: 0.4262 sec
0.1611 0.1113 0.0949 0.0928 0.0872 0.0843 0.0817 0.0783 0.0772 0.0784 0.0784 0.0779 0.0799 0.0823 0.0840 0.0851 

[TRAIN] Epoch[6](50/1500); Loss: 0.087915; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1025 0.1129 0.1033 0.0909 0.0848 0.0818 0.0803 0.0786 0.0797 0.0810 0.0815 0.0827 0.0836 0.0861 0.0877 0.0890 

[TRAIN] Epoch[6](51/1500); Loss: 0.060457; Backpropagation: 0.0919 sec; Batch: 0.4263 sec
0.0533 0.0797 0.0783 0.0710 0.0630 0.0559 0.0590 0.0539 0.0549 0.0556 0.0561 0.0570 0.0555 0.0570 0.0586 0.0586 

[TRAIN] Epoch[6](52/1500); Loss: 0.161712; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2420 0.1877 0.1856 0.1961 0.1866 0.1718 0.1579 0.1488 0.1445 0.1419 0.1398 0.1399 0.1363 0.1354 0.1365 0.1367 

[TRAIN] Epoch[6](53/1500); Loss: 0.069607; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1967 0.0670 0.1025 0.0931 0.0776 0.0442 0.0460 0.0543 0.0557 0.0459 0.0434 0.0673 0.0574 0.0522 0.0517 0.0587 

[TRAIN] Epoch[6](54/1500); Loss: 0.117813; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1286 0.1485 0.1436 0.1352 0.1275 0.1192 0.1138 0.1122 0.1122 0.1115 0.1061 0.1054 0.1058 0.1057 0.1044 0.1053 

[TRAIN] Epoch[6](55/1500); Loss: 0.101786; Backpropagation: 0.0918 sec; Batch: 0.4502 sec
0.1665 0.1432 0.1224 0.1169 0.1103 0.0996 0.0896 0.0837 0.0808 0.0823 0.0828 0.0849 0.0858 0.0893 0.0936 0.0969 

[TRAIN] Epoch[6](56/1500); Loss: 0.116494; Backpropagation: 0.0924 sec; Batch: 0.4267 sec
0.1309 0.1428 0.1409 0.1290 0.1176 0.1111 0.1145 0.1078 0.1090 0.1081 0.1090 0.1084 0.1070 0.1086 0.1089 0.1105 

[TRAIN] Epoch[6](57/1500); Loss: 0.083264; Backpropagation: 0.0920 sec; Batch: 0.4249 sec
0.1026 0.1021 0.0951 0.0900 0.0857 0.0819 0.0805 0.0785 0.0785 0.0778 0.0768 0.0761 0.0756 0.0765 0.0772 0.0772 

[TRAIN] Epoch[6](58/1500); Loss: 0.085210; Backpropagation: 0.0917 sec; Batch: 0.4271 sec
0.1106 0.0978 0.1004 0.0967 0.0895 0.0842 0.0819 0.0774 0.0766 0.0775 0.0774 0.0768 0.0769 0.0785 0.0804 0.0806 

[TRAIN] Epoch[6](59/1500); Loss: 0.131492; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1545 0.1463 0.1432 0.1393 0.1349 0.1336 0.1334 0.1260 0.1249 0.1252 0.1251 0.1232 0.1231 0.1234 0.1238 0.1239 

[TRAIN] Epoch[6](60/1500); Loss: 0.078085; Backpropagation: 0.0919 sec; Batch: 0.4253 sec
0.1112 0.1139 0.0996 0.0876 0.0818 0.0731 0.0693 0.0690 0.0697 0.0679 0.0679 0.0685 0.0671 0.0668 0.0685 0.0675 

[TRAIN] Epoch[6](61/1500); Loss: 0.106801; Backpropagation: 0.0918 sec; Batch: 0.4286 sec
0.1425 0.1271 0.1213 0.1177 0.1101 0.1043 0.1024 0.0992 0.0973 0.0972 0.0978 0.0985 0.0977 0.0978 0.0984 0.0996 

[TRAIN] Epoch[6](62/1500); Loss: 0.081726; Backpropagation: 0.0918 sec; Batch: 0.4331 sec
0.1021 0.0831 0.1210 0.1070 0.0882 0.0741 0.0685 0.0696 0.0693 0.0705 0.0705 0.0746 0.0755 0.0755 0.0773 0.0807 

[TRAIN] Epoch[6](63/1500); Loss: 0.134810; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1570 0.1600 0.1656 0.1557 0.1434 0.1313 0.1242 0.1225 0.1210 0.1215 0.1221 0.1232 0.1239 0.1259 0.1282 0.1314 

[TRAIN] Epoch[6](64/1500); Loss: 0.135902; Backpropagation: 0.0919 sec; Batch: 0.4415 sec
0.1411 0.1566 0.1698 0.1596 0.1471 0.1336 0.1290 0.1259 0.1261 0.1263 0.1265 0.1264 0.1259 0.1267 0.1264 0.1274 

[TRAIN] Epoch[6](65/1500); Loss: 0.115602; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2040 0.1489 0.1443 0.1496 0.1407 0.1268 0.1100 0.0953 0.0909 0.0899 0.0929 0.0952 0.0896 0.0904 0.0907 0.0903 

[TRAIN] Epoch[6](66/1500); Loss: 0.082357; Backpropagation: 0.0918 sec; Batch: 0.4259 sec
0.1295 0.0772 0.1549 0.1456 0.1293 0.0946 0.0590 0.0603 0.0570 0.0577 0.0544 0.0552 0.0584 0.0624 0.0610 0.0613 

[TRAIN] Epoch[6](67/1500); Loss: 0.068340; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0791 0.0873 0.0897 0.0815 0.0712 0.0669 0.0650 0.0636 0.0604 0.0604 0.0618 0.0598 0.0609 0.0604 0.0625 0.0629 

[TRAIN] Epoch[6](68/1500); Loss: 0.073040; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1137 0.1154 0.1076 0.0946 0.0790 0.0650 0.0591 0.0575 0.0570 0.0565 0.0562 0.0573 0.0596 0.0610 0.0634 0.0655 

[TRAIN] Epoch[6](69/1500); Loss: 0.090242; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1262 0.1197 0.1086 0.1006 0.0923 0.0858 0.0834 0.0800 0.0794 0.0796 0.0804 0.0803 0.0806 0.0822 0.0820 0.0830 

[TRAIN] Epoch[6](70/1500); Loss: 0.127124; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1648 0.1484 0.1469 0.1410 0.1342 0.1286 0.1282 0.1228 0.1180 0.1165 0.1160 0.1141 0.1132 0.1135 0.1139 0.1141 

[TRAIN] Epoch[6](71/1500); Loss: 0.101573; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1204 0.1127 0.1226 0.1182 0.1095 0.0998 0.1002 0.0968 0.0944 0.0927 0.0936 0.0942 0.0925 0.0918 0.0926 0.0933 

[TRAIN] Epoch[6](72/1500); Loss: 0.164117; Backpropagation: 0.0918 sec; Batch: 0.4281 sec
0.2184 0.1829 0.1803 0.1854 0.1787 0.1685 0.1590 0.1543 0.1508 0.1499 0.1516 0.1487 0.1486 0.1502 0.1492 0.1494 

[TRAIN] Epoch[6](73/1500); Loss: 0.090565; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1122 0.0695 0.1737 0.1636 0.1491 0.1145 0.0755 0.0614 0.0657 0.0677 0.0628 0.0614 0.0642 0.0689 0.0687 0.0701 

[TRAIN] Epoch[6](74/1500); Loss: 0.151702; Backpropagation: 0.0919 sec; Batch: 0.4261 sec
0.1442 0.1994 0.2302 0.2165 0.1984 0.1733 0.1491 0.1325 0.1222 0.1207 0.1202 0.1215 0.1226 0.1248 0.1248 0.1268 

[TRAIN] Epoch[6](75/1500); Loss: 0.123282; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1557 0.1424 0.1719 0.1599 0.1446 0.1239 0.1104 0.1114 0.1081 0.1058 0.1048 0.1065 0.1076 0.1056 0.1057 0.1084 

[TRAIN] Epoch[6](76/1500); Loss: 0.094644; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.1509 0.1445 0.1527 0.1381 0.1180 0.0941 0.0739 0.0740 0.0691 0.0675 0.0694 0.0711 0.0710 0.0706 0.0735 0.0758 

[TRAIN] Epoch[6](77/1500); Loss: 0.130094; Backpropagation: 0.0919 sec; Batch: 0.4268 sec
0.1773 0.1593 0.1536 0.1547 0.1491 0.1424 0.1341 0.1255 0.1189 0.1142 0.1103 0.1077 0.1072 0.1086 0.1094 0.1094 

[TRAIN] Epoch[6](78/1500); Loss: 0.083822; Backpropagation: 0.0998 sec; Batch: 0.4360 sec
0.1619 0.1103 0.1011 0.1163 0.1084 0.0957 0.0837 0.0715 0.0644 0.0611 0.0612 0.0613 0.0606 0.0602 0.0609 0.0627 

[TRAIN] Epoch[6](79/1500); Loss: 0.090477; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1073 0.1267 0.1245 0.1036 0.0910 0.0830 0.0767 0.0788 0.0784 0.0777 0.0793 0.0816 0.0827 0.0841 0.0855 0.0868 

[TRAIN] Epoch[6](80/1500); Loss: 0.094276; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0952 0.1418 0.1697 0.1558 0.1341 0.1046 0.0781 0.0695 0.0711 0.0703 0.0672 0.0675 0.0710 0.0699 0.0702 0.0725 

[TRAIN] Epoch[6](81/1500); Loss: 0.203980; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.3927 0.2867 0.2935 0.3310 0.3140 0.2829 0.2373 0.1853 0.1319 0.1071 0.1237 0.1147 0.1117 0.1146 0.1220 0.1146 

[TRAIN] Epoch[6](82/1500); Loss: 0.117928; Backpropagation: 0.0915 sec; Batch: 0.4386 sec
0.1482 0.1351 0.1462 0.1401 0.1301 0.1183 0.1111 0.1071 0.1053 0.1060 0.1050 0.1060 0.1059 0.1069 0.1068 0.1087 

[TRAIN] Epoch[6](83/1500); Loss: 0.126339; Backpropagation: 0.0918 sec; Batch: 0.4278 sec
0.1531 0.1510 0.1514 0.1445 0.1348 0.1266 0.1199 0.1166 0.1131 0.1124 0.1133 0.1126 0.1150 0.1174 0.1184 0.1211 

[TRAIN] Epoch[6](84/1500); Loss: 0.187379; Backpropagation: 0.0916 sec; Batch: 0.4263 sec
0.1825 0.2167 0.2392 0.2302 0.2152 0.1986 0.1839 0.1746 0.1703 0.1694 0.1689 0.1693 0.1688 0.1689 0.1709 0.1708 

[TRAIN] Epoch[6](85/1500); Loss: 0.129358; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1350 0.1287 0.1291 0.1265 0.1231 0.1217 0.1234 0.1258 0.1256 0.1268 0.1289 0.1315 0.1331 0.1343 0.1369 0.1393 

[TRAIN] Epoch[6](86/1500); Loss: 0.090364; Backpropagation: 0.0918 sec; Batch: 0.4350 sec
0.1643 0.1179 0.1094 0.1215 0.1140 0.1026 0.0915 0.0805 0.0726 0.0689 0.0677 0.0676 0.0665 0.0665 0.0669 0.0674 

[TRAIN] Epoch[6](87/1500); Loss: 0.121462; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1402 0.1191 0.1593 0.1524 0.1423 0.1256 0.1158 0.1155 0.1168 0.1099 0.1055 0.1068 0.1089 0.1088 0.1083 0.1080 

[TRAIN] Epoch[6](88/1500); Loss: 0.107175; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1547 0.1125 0.1212 0.1239 0.1175 0.1075 0.1002 0.0984 0.0965 0.0962 0.0968 0.0972 0.0977 0.0967 0.0974 0.1002 

[TRAIN] Epoch[6](89/1500); Loss: 0.149458; Backpropagation: 0.0920 sec; Batch: 0.4270 sec
0.2036 0.1863 0.1779 0.1768 0.1681 0.1562 0.1428 0.1341 0.1311 0.1304 0.1300 0.1302 0.1314 0.1314 0.1305 0.1307 

[TRAIN] Epoch[6](90/1500); Loss: 0.195763; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.4374 0.3080 0.3137 0.3596 0.3393 0.3000 0.2414 0.1740 0.1042 0.0672 0.0870 0.0772 0.0753 0.0783 0.0883 0.0812 

[TRAIN] Epoch[6](91/1500); Loss: 0.138102; Backpropagation: 0.0992 sec; Batch: 0.4380 sec
0.2944 0.2033 0.1955 0.2250 0.2103 0.1876 0.1551 0.1183 0.0881 0.0734 0.0758 0.0780 0.0744 0.0759 0.0785 0.0762 

[TRAIN] Epoch[6](92/1500); Loss: 0.073580; Backpropagation: 0.0927 sec; Batch: 0.4249 sec
0.1045 0.0855 0.0831 0.0881 0.0815 0.0733 0.0673 0.0689 0.0656 0.0628 0.0644 0.0664 0.0653 0.0660 0.0670 0.0678 

[TRAIN] Epoch[6](93/1500); Loss: 0.112651; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1659 0.1183 0.1211 0.1281 0.1226 0.1133 0.1060 0.1052 0.1031 0.1026 0.1019 0.1020 0.1032 0.1026 0.1028 0.1037 

[TRAIN] Epoch[6](94/1500); Loss: 0.093338; Backpropagation: 0.0916 sec; Batch: 0.4411 sec
0.1644 0.1335 0.1218 0.1164 0.1060 0.0937 0.0850 0.0782 0.0737 0.0725 0.0726 0.0730 0.0748 0.0751 0.0754 0.0773 

[TRAIN] Epoch[6](95/1500); Loss: 0.147234; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2830 0.1963 0.1948 0.2280 0.2160 0.1939 0.1593 0.1234 0.0977 0.0942 0.0959 0.0937 0.0934 0.0962 0.0960 0.0938 

[TRAIN] Epoch[6](96/1500); Loss: 0.111683; Backpropagation: 0.0917 sec; Batch: 0.4597 sec
0.0986 0.1402 0.1947 0.1846 0.1699 0.1450 0.1164 0.0927 0.0834 0.0831 0.0776 0.0753 0.0789 0.0823 0.0814 0.0828 

[TRAIN] Epoch[6](97/1500); Loss: 0.155309; Backpropagation: 0.0917 sec; Batch: 0.4269 sec
0.1738 0.1651 0.1647 0.1587 0.1561 0.1548 0.1540 0.1529 0.1505 0.1492 0.1499 0.1512 0.1511 0.1502 0.1508 0.1519 

[TRAIN] Epoch[6](98/1500); Loss: 0.126714; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2054 0.1394 0.1923 0.1941 0.1807 0.1544 0.1237 0.1071 0.1064 0.0931 0.0866 0.0863 0.0876 0.0885 0.0908 0.0909 

[TRAIN] Epoch[6](99/1500); Loss: 0.119606; Backpropagation: 0.0920 sec; Batch: 0.4267 sec
0.1462 0.1423 0.1392 0.1308 0.1247 0.1198 0.1162 0.1130 0.1116 0.1103 0.1098 0.1099 0.1094 0.1089 0.1106 0.1110 

[TRAIN] Epoch[6](100/1500); Loss: 0.123183; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1226 0.1336 0.1308 0.1262 0.1195 0.1160 0.1167 0.1177 0.1178 0.1190 0.1208 0.1224 0.1244 0.1256 0.1278 0.1301 

[TRAIN] Epoch[6](101/1500); Loss: 0.145991; Backpropagation: 0.0918 sec; Batch: 0.4256 sec
0.1875 0.1643 0.1822 0.1754 0.1612 0.1408 0.1298 0.1349 0.1315 0.1300 0.1308 0.1319 0.1324 0.1326 0.1347 0.1358 

[TRAIN] Epoch[6](102/1500); Loss: 0.127364; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2186 0.1507 0.1383 0.1548 0.1456 0.1302 0.1149 0.1088 0.1136 0.1081 0.1073 0.1088 0.1112 0.1078 0.1082 0.1108 

[TRAIN] Epoch[6](103/1500); Loss: 0.085069; Backpropagation: 0.0997 sec; Batch: 0.4344 sec
0.1099 0.1336 0.1266 0.1087 0.0909 0.0787 0.0744 0.0715 0.0700 0.0706 0.0699 0.0699 0.0708 0.0710 0.0719 0.0727 

[TRAIN] Epoch[6](104/1500); Loss: 0.159014; Backpropagation: 0.0926 sec; Batch: 0.4249 sec
0.2153 0.1742 0.1945 0.1917 0.1825 0.1647 0.1491 0.1414 0.1403 0.1385 0.1383 0.1399 0.1414 0.1431 0.1440 0.1454 

[TRAIN] Epoch[6](105/1500); Loss: 0.103906; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1499 0.1102 0.1245 0.1232 0.1157 0.1031 0.0959 0.0960 0.0944 0.0933 0.0921 0.0925 0.0931 0.0924 0.0929 0.0933 

[TRAIN] Epoch[6](106/1500); Loss: 0.064230; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1031 0.0850 0.0801 0.0762 0.0715 0.0657 0.0631 0.0559 0.0524 0.0534 0.0541 0.0524 0.0534 0.0538 0.0531 0.0545 

[TRAIN] Epoch[6](107/1500); Loss: 0.175694; Backpropagation: 0.0919 sec; Batch: 0.4264 sec
0.3602 0.2682 0.2607 0.2833 0.2653 0.2350 0.1909 0.1418 0.1004 0.0979 0.1070 0.0983 0.0979 0.1011 0.1014 0.1017 

[TRAIN] Epoch[6](108/1500); Loss: 0.056976; Backpropagation: 0.0919 sec; Batch: 0.4292 sec
0.0735 0.0854 0.0811 0.0624 0.0524 0.0517 0.0502 0.0481 0.0490 0.0495 0.0500 0.0503 0.0507 0.0516 0.0526 0.0532 

[TRAIN] Epoch[6](109/1500); Loss: 0.145360; Backpropagation: 0.0972 sec; Batch: 0.4295 sec
0.2681 0.2031 0.1957 0.2126 0.1990 0.1778 0.1485 0.1202 0.1027 0.1006 0.1004 0.0994 0.0984 0.1000 0.0992 0.1000 

[TRAIN] Epoch[6](110/1500); Loss: 0.124063; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2047 0.1445 0.1350 0.1386 0.1327 0.1252 0.1183 0.1112 0.1088 0.1091 0.1077 0.1090 0.1096 0.1105 0.1100 0.1101 

[TRAIN] Epoch[6](111/1500); Loss: 0.115418; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.1539 0.1482 0.1367 0.1266 0.1173 0.1124 0.1101 0.1047 0.1029 0.1034 0.1040 0.1040 0.1041 0.1047 0.1059 0.1078 

[TRAIN] Epoch[6](112/1500); Loss: 0.110614; Backpropagation: 0.0917 sec; Batch: 0.4260 sec
0.1361 0.1125 0.1103 0.1097 0.1094 0.1095 0.1107 0.1086 0.1069 0.1071 0.1083 0.1079 0.1076 0.1080 0.1086 0.1087 

[TRAIN] Epoch[6](113/1500); Loss: 0.109654; Backpropagation: 0.0918 sec; Batch: 0.4631 sec
0.1275 0.1771 0.1861 0.1710 0.1493 0.1227 0.0983 0.0848 0.0847 0.0784 0.0768 0.0780 0.0787 0.0780 0.0808 0.0824 

[TRAIN] Epoch[6](114/1500); Loss: 0.104224; Backpropagation: 0.0920 sec; Batch: 0.4267 sec
0.1400 0.1372 0.1263 0.1189 0.1104 0.1042 0.0983 0.0958 0.0924 0.0923 0.0918 0.0911 0.0911 0.0920 0.0931 0.0927 

[TRAIN] Epoch[6](115/1500); Loss: 0.075581; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1127 0.1156 0.1066 0.0894 0.0786 0.0695 0.0663 0.0652 0.0626 0.0616 0.0621 0.0630 0.0624 0.0635 0.0648 0.0654 

[TRAIN] Epoch[6](116/1500); Loss: 0.088280; Backpropagation: 0.0920 sec; Batch: 0.4259 sec
0.1576 0.0683 0.1403 0.1436 0.1302 0.0989 0.0696 0.0625 0.0660 0.0635 0.0627 0.0621 0.0691 0.0720 0.0723 0.0736 

[TRAIN] Epoch[6](117/1500); Loss: 0.109016; Backpropagation: 0.0922 sec; Batch: 0.4263 sec
0.1024 0.1700 0.1993 0.1838 0.1612 0.1301 0.1001 0.0831 0.0766 0.0790 0.0754 0.0742 0.0761 0.0773 0.0772 0.0784 

[TRAIN] Epoch[6](118/1500); Loss: 0.115888; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1349 0.1602 0.1672 0.1538 0.1366 0.1195 0.1068 0.1023 0.1031 0.0973 0.0954 0.0951 0.0957 0.0955 0.0950 0.0960 

[TRAIN] Epoch[6](119/1500); Loss: 0.087618; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1207 0.1461 0.1334 0.1174 0.0994 0.0806 0.0713 0.0737 0.0721 0.0696 0.0691 0.0694 0.0698 0.0694 0.0700 0.0700 

[TRAIN] Epoch[6](120/1500); Loss: 0.089467; Backpropagation: 0.0918 sec; Batch: 0.4499 sec
0.1113 0.0924 0.1555 0.1463 0.1342 0.1090 0.0825 0.0686 0.0701 0.0664 0.0635 0.0630 0.0655 0.0665 0.0676 0.0690 

[TRAIN] Epoch[6](121/1500); Loss: 0.118769; Backpropagation: 0.0985 sec; Batch: 0.4382 sec
0.1393 0.1476 0.1516 0.1465 0.1358 0.1216 0.1143 0.1128 0.1068 0.1046 0.1042 0.1034 0.1041 0.1022 0.1018 0.1036 

[TRAIN] Epoch[6](122/1500); Loss: 0.079112; Backpropagation: 0.0926 sec; Batch: 0.4246 sec
0.1021 0.0896 0.1216 0.1130 0.0984 0.0768 0.0681 0.0740 0.0641 0.0656 0.0636 0.0645 0.0657 0.0669 0.0659 0.0659 

[TRAIN] Epoch[6](123/1500); Loss: 0.094408; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1860 0.1003 0.1293 0.1255 0.1142 0.0940 0.0779 0.0688 0.0736 0.0735 0.0738 0.0764 0.0770 0.0789 0.0788 0.0827 

[TRAIN] Epoch[6](124/1500); Loss: 0.148404; Backpropagation: 0.0918 sec; Batch: 0.4302 sec
0.1778 0.1692 0.1664 0.1602 0.1511 0.1440 0.1433 0.1420 0.1388 0.1393 0.1402 0.1399 0.1400 0.1405 0.1408 0.1411 

[TRAIN] Epoch[6](125/1500); Loss: 0.145767; Backpropagation: 0.0918 sec; Batch: 0.4342 sec
0.1692 0.1577 0.1852 0.1786 0.1668 0.1488 0.1364 0.1368 0.1352 0.1299 0.1289 0.1305 0.1324 0.1311 0.1316 0.1330 

[TRAIN] Epoch[6](126/1500); Loss: 0.151427; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1624 0.1545 0.2022 0.1912 0.1800 0.1594 0.1421 0.1351 0.1342 0.1365 0.1382 0.1362 0.1370 0.1383 0.1375 0.1381 

[TRAIN] Epoch[6](127/1500); Loss: 0.095381; Backpropagation: 0.0919 sec; Batch: 0.4308 sec
0.1178 0.1131 0.1703 0.1593 0.1427 0.1121 0.0840 0.0759 0.0754 0.0696 0.0666 0.0669 0.0676 0.0672 0.0679 0.0696 

[TRAIN] Epoch[6](128/1500); Loss: 0.156964; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1848 0.1683 0.1865 0.1795 0.1706 0.1573 0.1509 0.1536 0.1506 0.1469 0.1439 0.1440 0.1446 0.1450 0.1428 0.1422 

[TRAIN] Epoch[6](129/1500); Loss: 0.100400; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1266 0.1201 0.1205 0.1121 0.1045 0.0980 0.0955 0.0937 0.0919 0.0918 0.0920 0.0915 0.0911 0.0915 0.0923 0.0931 

[TRAIN] Epoch[6](130/1500); Loss: 0.115521; Backpropagation: 0.0917 sec; Batch: 0.4635 sec
0.1313 0.1420 0.1556 0.1460 0.1334 0.1176 0.1081 0.1084 0.1071 0.1024 0.1015 0.1009 0.1004 0.0986 0.0976 0.0975 

[TRAIN] Epoch[6](131/1500); Loss: 0.098846; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0785 0.0973 0.1554 0.1468 0.1346 0.1103 0.0897 0.0830 0.0936 0.0832 0.0837 0.0838 0.0839 0.0851 0.0866 0.0859 

[TRAIN] Epoch[6](132/1500); Loss: 0.103263; Backpropagation: 0.0918 sec; Batch: 0.4458 sec
0.1040 0.1300 0.1740 0.1630 0.1465 0.1206 0.0951 0.0818 0.0812 0.0806 0.0763 0.0763 0.0795 0.0810 0.0809 0.0815 

[TRAIN] Epoch[6](133/1500); Loss: 0.091698; Backpropagation: 0.0989 sec; Batch: 0.4519 sec
0.1212 0.1347 0.1375 0.1212 0.1063 0.0940 0.0829 0.0742 0.0729 0.0724 0.0708 0.0727 0.0745 0.0760 0.0770 0.0791 

[TRAIN] Epoch[6](134/1500); Loss: 0.107403; Backpropagation: 0.0934 sec; Batch: 0.4258 sec
0.1252 0.2055 0.2004 0.1817 0.1558 0.1252 0.0971 0.0750 0.0688 0.0695 0.0675 0.0677 0.0687 0.0692 0.0689 0.0723 

[TRAIN] Epoch[6](135/1500); Loss: 0.128263; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1552 0.1463 0.1503 0.1428 0.1344 0.1262 0.1244 0.1257 0.1197 0.1173 0.1185 0.1194 0.1176 0.1172 0.1189 0.1184 

[TRAIN] Epoch[6](136/1500); Loss: 0.129213; Backpropagation: 0.0917 sec; Batch: 0.4348 sec
0.2391 0.1748 0.1471 0.1549 0.1485 0.1364 0.1226 0.1153 0.1070 0.1019 0.1031 0.1040 0.1032 0.1027 0.1032 0.1037 

[TRAIN] Epoch[6](137/1500); Loss: 0.119620; Backpropagation: 0.0918 sec; Batch: 0.4334 sec
0.1530 0.1435 0.1352 0.1330 0.1261 0.1185 0.1136 0.1122 0.1103 0.1095 0.1097 0.1097 0.1097 0.1096 0.1099 0.1104 

[TRAIN] Epoch[6](138/1500); Loss: 0.109377; Backpropagation: 0.0918 sec; Batch: 0.4315 sec
0.1078 0.1661 0.2088 0.1951 0.1740 0.1420 0.1075 0.0814 0.0727 0.0735 0.0706 0.0687 0.0692 0.0716 0.0706 0.0704 

[TRAIN] Epoch[6](139/1500); Loss: 0.122479; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.1702 0.1385 0.1287 0.1339 0.1302 0.1230 0.1153 0.1150 0.1122 0.1133 0.1132 0.1130 0.1129 0.1132 0.1138 0.1136 

[TRAIN] Epoch[6](140/1500); Loss: 0.102724; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1635 0.0971 0.1397 0.1388 0.1253 0.1002 0.0852 0.0921 0.0889 0.0845 0.0848 0.0880 0.0894 0.0875 0.0883 0.0903 

[TRAIN] Epoch[6](141/1500); Loss: 0.105639; Backpropagation: 0.0921 sec; Batch: 0.4392 sec
0.1324 0.1223 0.1291 0.1193 0.1128 0.1036 0.1004 0.0980 0.0989 0.0970 0.0954 0.0943 0.0971 0.0969 0.0964 0.0965 

[TRAIN] Epoch[6](142/1500); Loss: 0.184733; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2847 0.2389 0.2240 0.2296 0.2224 0.2088 0.1904 0.1727 0.1592 0.1493 0.1459 0.1447 0.1467 0.1464 0.1464 0.1456 

[TRAIN] Epoch[6](143/1500); Loss: 0.107190; Backpropagation: 0.0920 sec; Batch: 0.4296 sec
0.1290 0.1317 0.1238 0.1163 0.1100 0.1067 0.1031 0.1009 0.1005 0.1001 0.0991 0.0984 0.0979 0.0983 0.0996 0.0997 

[TRAIN] Epoch[6](144/1500); Loss: 0.125838; Backpropagation: 0.0921 sec; Batch: 0.4257 sec
0.1210 0.1557 0.1809 0.1681 0.1521 0.1322 0.1204 0.1148 0.1144 0.1102 0.1061 0.1086 0.1082 0.1067 0.1074 0.1066 

[TRAIN] Epoch[6](145/1500); Loss: 0.152558; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1894 0.1752 0.1735 0.1673 0.1596 0.1537 0.1493 0.1470 0.1439 0.1415 0.1396 0.1414 0.1399 0.1396 0.1398 0.1402 

[TRAIN] Epoch[6](146/1500); Loss: 0.142941; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1638 0.1646 0.1580 0.1531 0.1468 0.1424 0.1388 0.1371 0.1359 0.1345 0.1346 0.1349 0.1349 0.1353 0.1357 0.1365 

[TRAIN] Epoch[6](147/1500); Loss: 0.102925; Backpropagation: 0.0920 sec; Batch: 0.4317 sec
0.0921 0.1165 0.1664 0.1573 0.1427 0.1175 0.0938 0.0846 0.0855 0.0858 0.0826 0.0829 0.0841 0.0842 0.0846 0.0861 

[TRAIN] Epoch[6](148/1500); Loss: 0.152630; Backpropagation: 0.0918 sec; Batch: 0.4311 sec
0.1316 0.1936 0.2729 0.2584 0.2372 0.2031 0.1655 0.1325 0.1076 0.1015 0.1057 0.1082 0.1031 0.1046 0.1090 0.1075 

[TRAIN] Epoch[6](149/1500); Loss: 0.066963; Backpropagation: 0.0919 sec; Batch: 0.4625 sec
0.1292 0.0981 0.0856 0.0794 0.0707 0.0603 0.0565 0.0526 0.0508 0.0530 0.0543 0.0541 0.0543 0.0559 0.0581 0.0585 

[TRAIN] Epoch[6](150/1500); Loss: 0.095576; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0833 0.1558 0.1668 0.1492 0.1264 0.1006 0.0835 0.0826 0.0739 0.0705 0.0697 0.0716 0.0735 0.0733 0.0737 0.0748 

[TRAIN] Epoch[6](151/1500); Loss: 0.126960; Backpropagation: 0.0919 sec; Batch: 0.4258 sec
0.2218 0.1734 0.1578 0.1570 0.1495 0.1391 0.1275 0.1130 0.1036 0.0996 0.0979 0.0973 0.0971 0.0985 0.0985 0.0996 

[TRAIN] Epoch[6](152/1500); Loss: 0.119622; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1115 0.1579 0.2111 0.1970 0.1777 0.1486 0.1181 0.0967 0.0881 0.0907 0.0869 0.0846 0.0835 0.0850 0.0884 0.0883 

[TRAIN] Epoch[6](153/1500); Loss: 0.125256; Backpropagation: 0.0920 sec; Batch: 0.4265 sec
0.1719 0.1574 0.1457 0.1358 0.1291 0.1218 0.1153 0.1138 0.1132 0.1144 0.1135 0.1132 0.1135 0.1153 0.1152 0.1151 

[TRAIN] Epoch[6](154/1500); Loss: 0.227392; Backpropagation: 0.0917 sec; Batch: 0.4257 sec
0.3050 0.2788 0.2618 0.2629 0.2513 0.2375 0.2235 0.2133 0.2057 0.2006 0.1978 0.1978 0.1986 0.2010 0.2018 0.2009 

[TRAIN] Epoch[6](155/1500); Loss: 0.195293; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2495 0.2200 0.2099 0.2113 0.2051 0.1981 0.1917 0.1876 0.1835 0.1824 0.1814 0.1808 0.1807 0.1808 0.1811 0.1808 

[TRAIN] Epoch[6](156/1500); Loss: 0.144940; Backpropagation: 0.0919 sec; Batch: 0.4284 sec
0.1693 0.1675 0.1682 0.1587 0.1519 0.1447 0.1407 0.1396 0.1390 0.1352 0.1341 0.1349 0.1350 0.1336 0.1329 0.1336 

[TRAIN] Epoch[6](157/1500); Loss: 0.092390; Backpropagation: 0.1001 sec; Batch: 0.4353 sec
0.1009 0.1159 0.1202 0.1106 0.0992 0.0908 0.0901 0.0864 0.0837 0.0830 0.0836 0.0830 0.0823 0.0824 0.0829 0.0833 

[TRAIN] Epoch[6](158/1500); Loss: 0.138997; Backpropagation: 0.0929 sec; Batch: 0.4246 sec
0.1975 0.1937 0.1852 0.1808 0.1639 0.1459 0.1320 0.1232 0.1168 0.1130 0.1143 0.1117 0.1113 0.1103 0.1113 0.1130 

[TRAIN] Epoch[6](159/1500); Loss: 0.055307; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1544 0.0585 0.0490 0.0545 0.0498 0.0459 0.0587 0.0439 0.0431 0.0452 0.0475 0.0437 0.0463 0.0487 0.0471 0.0488 

[TRAIN] Epoch[6](160/1500); Loss: 0.086055; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2361 0.1364 0.1153 0.1339 0.1211 0.0965 0.0658 0.0528 0.0658 0.0468 0.0502 0.0508 0.0518 0.0501 0.0518 0.0518 

[TRAIN] Epoch[6](161/1500); Loss: 0.112294; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1309 0.2049 0.2062 0.1858 0.1573 0.1233 0.0924 0.0763 0.0784 0.0779 0.0749 0.0741 0.0764 0.0794 0.0800 0.0783 

[TRAIN] Epoch[6](162/1500); Loss: 0.103568; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1476 0.1956 0.1881 0.1673 0.1393 0.1112 0.0886 0.0765 0.0719 0.0685 0.0650 0.0662 0.0679 0.0666 0.0673 0.0694 

[TRAIN] Epoch[6](163/1500); Loss: 0.076697; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2352 0.1291 0.1025 0.1194 0.1049 0.0782 0.0502 0.0490 0.0513 0.0435 0.0446 0.0454 0.0422 0.0429 0.0455 0.0432 

[TRAIN] Epoch[6](164/1500); Loss: 0.070725; Backpropagation: 0.0919 sec; Batch: 0.4335 sec
0.0984 0.1064 0.1014 0.0859 0.0719 0.0639 0.0645 0.0599 0.0595 0.0592 0.0595 0.0598 0.0593 0.0602 0.0608 0.0609 

[TRAIN] Epoch[6](165/1500); Loss: 0.098730; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1415 0.1531 0.1718 0.1503 0.1298 0.1030 0.0820 0.0724 0.0733 0.0693 0.0691 0.0707 0.0713 0.0728 0.0744 0.0749 

[TRAIN] Epoch[6](166/1500); Loss: 0.101457; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1293 0.1256 0.1227 0.1134 0.1045 0.0995 0.0971 0.0941 0.0926 0.0920 0.0914 0.0917 0.0926 0.0921 0.0919 0.0926 

[TRAIN] Epoch[6](167/1500); Loss: 0.116468; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1557 0.1322 0.1565 0.1503 0.1376 0.1194 0.1056 0.1053 0.1035 0.0993 0.0990 0.0991 0.0991 0.0995 0.1007 0.1007 

[TRAIN] Epoch[6](168/1500); Loss: 0.143260; Backpropagation: 0.1008 sec; Batch: 0.4365 sec
0.1491 0.1348 0.2226 0.2128 0.1988 0.1689 0.1374 0.1212 0.1224 0.1230 0.1197 0.1175 0.1166 0.1157 0.1152 0.1164 

[TRAIN] Epoch[6](169/1500); Loss: 0.101865; Backpropagation: 0.0924 sec; Batch: 0.4259 sec
0.1222 0.1327 0.1384 0.1238 0.1103 0.0983 0.0952 0.0957 0.0924 0.0894 0.0884 0.0889 0.0891 0.0887 0.0880 0.0884 

[TRAIN] Epoch[6](170/1500); Loss: 0.145161; Backpropagation: 0.0918 sec; Batch: 0.4296 sec
0.1763 0.1636 0.1768 0.1666 0.1570 0.1454 0.1390 0.1364 0.1340 0.1327 0.1322 0.1328 0.1327 0.1326 0.1324 0.1321 

[TRAIN] Epoch[6](171/1500); Loss: 0.167491; Backpropagation: 0.0920 sec; Batch: 0.4264 sec
0.1918 0.1804 0.1794 0.1748 0.1707 0.1672 0.1637 0.1609 0.1595 0.1598 0.1610 0.1622 0.1617 0.1620 0.1622 0.1625 

[TRAIN] Epoch[6](172/1500); Loss: 0.127025; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1895 0.1513 0.1613 0.1554 0.1484 0.1361 0.1243 0.1256 0.1139 0.1099 0.1070 0.1048 0.1024 0.1011 0.1005 0.1010 

[TRAIN] Epoch[6](173/1500); Loss: 0.090332; Backpropagation: 0.0918 sec; Batch: 0.4601 sec
0.1862 0.1235 0.1080 0.1073 0.0997 0.0796 0.0718 0.0835 0.0681 0.0727 0.0725 0.0732 0.0737 0.0737 0.0745 0.0774 

[TRAIN] Epoch[6](174/1500); Loss: 0.122864; Backpropagation: 0.0919 sec; Batch: 0.4261 sec
0.1771 0.1415 0.1321 0.1274 0.1239 0.1178 0.1157 0.1163 0.1115 0.1135 0.1135 0.1146 0.1136 0.1153 0.1157 0.1163 

[TRAIN] Epoch[6](175/1500); Loss: 0.155296; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2079 0.2050 0.2409 0.2290 0.2100 0.1809 0.1506 0.1296 0.1218 0.1219 0.1127 0.1136 0.1146 0.1166 0.1142 0.1153 

[TRAIN] Epoch[6](176/1500); Loss: 0.117017; Backpropagation: 0.0920 sec; Batch: 0.4430 sec
0.1334 0.1212 0.1565 0.1466 0.1343 0.1171 0.1064 0.1115 0.1100 0.1039 0.1031 0.1054 0.1067 0.1053 0.1047 0.1062 

[TRAIN] Epoch[6](177/1500); Loss: 0.158010; Backpropagation: 0.0923 sec; Batch: 0.4251 sec
0.2359 0.1877 0.1984 0.1936 0.1829 0.1653 0.1481 0.1380 0.1341 0.1349 0.1339 0.1331 0.1350 0.1363 0.1350 0.1359 

[TRAIN] Epoch[6](178/1500); Loss: 0.135327; Backpropagation: 0.0917 sec; Batch: 0.4664 sec
0.1708 0.1745 0.1702 0.1543 0.1400 0.1314 0.1281 0.1236 0.1197 0.1212 0.1227 0.1215 0.1202 0.1221 0.1225 0.1224 

[TRAIN] Epoch[6](179/1500); Loss: 0.098356; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1179 0.1096 0.1082 0.1007 0.0969 0.0954 0.0947 0.0938 0.0937 0.0939 0.0938 0.0944 0.0948 0.0946 0.0956 0.0958 

[TRAIN] Epoch[6](180/1500); Loss: 0.139363; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1921 0.1532 0.1454 0.1481 0.1411 0.1343 0.1329 0.1322 0.1302 0.1297 0.1300 0.1315 0.1319 0.1313 0.1321 0.1337 

[TRAIN] Epoch[6](181/1500); Loss: 0.146494; Backpropagation: 0.0918 sec; Batch: 0.4254 sec
0.1640 0.1504 0.1851 0.1759 0.1652 0.1482 0.1358 0.1341 0.1376 0.1351 0.1333 0.1338 0.1364 0.1360 0.1366 0.1363 

[TRAIN] Epoch[6](182/1500); Loss: 0.106101; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1667 0.1243 0.1412 0.1364 0.1219 0.1008 0.0966 0.0971 0.0929 0.0875 0.0867 0.0882 0.0887 0.0888 0.0891 0.0907 

[TRAIN] Epoch[6](183/1500); Loss: 0.133591; Backpropagation: 0.0922 sec; Batch: 0.4305 sec
0.1476 0.1434 0.1453 0.1435 0.1394 0.1316 0.1289 0.1299 0.1288 0.1264 0.1268 0.1292 0.1279 0.1284 0.1303 0.1301 

[TRAIN] Epoch[6](184/1500); Loss: 0.093331; Backpropagation: 0.0917 sec; Batch: 0.4302 sec
0.1185 0.1445 0.1529 0.1241 0.1058 0.0942 0.0813 0.0738 0.0762 0.0719 0.0706 0.0728 0.0762 0.0756 0.0757 0.0791 

[TRAIN] Epoch[6](185/1500); Loss: 0.103224; Backpropagation: 0.0920 sec; Batch: 0.4278 sec
0.2238 0.1649 0.1377 0.1257 0.1139 0.0994 0.0878 0.0806 0.0765 0.0774 0.0762 0.0772 0.0761 0.0771 0.0781 0.0791 

[TRAIN] Epoch[6](186/1500); Loss: 0.128439; Backpropagation: 0.1011 sec; Batch: 0.4336 sec
0.1283 0.1618 0.1910 0.1768 0.1605 0.1424 0.1254 0.1169 0.1021 0.1035 0.1047 0.1057 0.1084 0.1093 0.1086 0.1097 

[TRAIN] Epoch[6](187/1500); Loss: 0.190057; Backpropagation: 0.0921 sec; Batch: 0.4298 sec
0.1954 0.2224 0.2250 0.2140 0.2005 0.1901 0.1866 0.1849 0.1790 0.1784 0.1788 0.1774 0.1755 0.1771 0.1787 0.1771 

[TRAIN] Epoch[6](188/1500); Loss: 0.130724; Backpropagation: 0.0918 sec; Batch: 0.4355 sec
0.2549 0.1773 0.1608 0.1527 0.1366 0.1192 0.1128 0.1051 0.1093 0.1059 0.1079 0.1077 0.1091 0.1102 0.1103 0.1118 

[TRAIN] Epoch[6](189/1500); Loss: 0.163732; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2403 0.2060 0.2012 0.1924 0.1811 0.1696 0.1574 0.1465 0.1432 0.1417 0.1402 0.1402 0.1400 0.1403 0.1395 0.1402 

[TRAIN] Epoch[6](190/1500); Loss: 0.161660; Backpropagation: 0.0918 sec; Batch: 0.4256 sec
0.1812 0.1760 0.1819 0.1727 0.1658 0.1636 0.1634 0.1593 0.1559 0.1547 0.1534 0.1521 0.1519 0.1519 0.1514 0.1515 

[TRAIN] Epoch[6](191/1500); Loss: 0.104112; Backpropagation: 0.0919 sec; Batch: 0.4311 sec
0.1445 0.1128 0.1304 0.1254 0.1166 0.0996 0.0937 0.0970 0.0944 0.0906 0.0907 0.0929 0.0925 0.0930 0.0945 0.0972 

[TRAIN] Epoch[6](192/1500); Loss: 0.072537; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1040 0.1015 0.0943 0.0752 0.0676 0.0635 0.0650 0.0643 0.0634 0.0636 0.0650 0.0653 0.0655 0.0656 0.0678 0.0690 

[TRAIN] Epoch[6](193/1500); Loss: 0.066024; Backpropagation: 0.0920 sec; Batch: 0.4265 sec
0.0968 0.0683 0.1019 0.0943 0.0823 0.0644 0.0575 0.0592 0.0559 0.0523 0.0530 0.0549 0.0529 0.0525 0.0552 0.0550 

[TRAIN] Epoch[6](194/1500); Loss: 0.105580; Backpropagation: 0.0921 sec; Batch: 0.4274 sec
0.1680 0.1253 0.1426 0.1374 0.1227 0.1005 0.0931 0.0925 0.0897 0.0868 0.0857 0.0877 0.0878 0.0877 0.0885 0.0933 

[TRAIN] Epoch[6](195/1500); Loss: 0.120114; Backpropagation: 0.0917 sec; Batch: 0.4490 sec
0.1494 0.1491 0.1550 0.1329 0.1251 0.1178 0.1106 0.1108 0.1104 0.1082 0.1077 0.1073 0.1091 0.1080 0.1100 0.1102 

[TRAIN] Epoch[6](196/1500); Loss: 0.203984; Backpropagation: 0.0918 sec; Batch: 0.4281 sec
0.3383 0.2602 0.2331 0.2317 0.2209 0.2001 0.1838 0.1730 0.1821 0.1746 0.1768 0.1766 0.1767 0.1789 0.1789 0.1779 

[TRAIN] Epoch[6](197/1500); Loss: 0.128953; Backpropagation: 0.0921 sec; Batch: 0.4271 sec
0.1888 0.1650 0.1578 0.1530 0.1482 0.1399 0.1287 0.1171 0.1088 0.1071 0.1092 0.1064 0.1075 0.1078 0.1086 0.1093 

[TRAIN] Epoch[6](198/1500); Loss: 0.138312; Backpropagation: 0.0998 sec; Batch: 0.4353 sec
0.1647 0.1483 0.1526 0.1444 0.1399 0.1378 0.1369 0.1326 0.1310 0.1321 0.1314 0.1303 0.1313 0.1345 0.1327 0.1325 

[TRAIN] Epoch[6](199/1500); Loss: 0.132325; Backpropagation: 0.0921 sec; Batch: 0.4257 sec
0.1642 0.1530 0.1427 0.1386 0.1339 0.1303 0.1285 0.1269 0.1251 0.1240 0.1244 0.1246 0.1242 0.1248 0.1260 0.1262 

[TRAIN] Epoch[6](200/1500); Loss: 0.148247; Backpropagation: 0.0919 sec; Batch: 0.4354 sec
0.2165 0.1741 0.1689 0.1702 0.1620 0.1501 0.1396 0.1329 0.1351 0.1296 0.1315 0.1330 0.1324 0.1307 0.1325 0.1331 

[TRAIN] Epoch[6](201/1500); Loss: 0.106171; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1243 0.1210 0.1177 0.1141 0.1114 0.1063 0.1038 0.1028 0.1011 0.0998 0.0991 0.0993 0.0994 0.0991 0.0998 0.0997 

[TRAIN] Epoch[6](202/1500); Loss: 0.139218; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1674 0.1667 0.1591 0.1467 0.1441 0.1354 0.1341 0.1330 0.1311 0.1306 0.1303 0.1297 0.1296 0.1297 0.1297 0.1303 

[TRAIN] Epoch[6](203/1500); Loss: 0.068186; Backpropagation: 0.0918 sec; Batch: 0.4456 sec
0.0842 0.1043 0.0889 0.0674 0.0638 0.0597 0.0591 0.0591 0.0602 0.0609 0.0613 0.0617 0.0635 0.0642 0.0654 0.0671 

[TRAIN] Epoch[6](204/1500); Loss: 0.124166; Backpropagation: 0.0919 sec; Batch: 0.4264 sec
0.1444 0.1312 0.1326 0.1264 0.1226 0.1222 0.1221 0.1195 0.1195 0.1206 0.1200 0.1203 0.1206 0.1214 0.1215 0.1216 

[TRAIN] Epoch[6](205/1500); Loss: 0.105706; Backpropagation: 0.0928 sec; Batch: 0.4247 sec
0.1409 0.1167 0.1154 0.1137 0.1102 0.1047 0.1035 0.0976 0.0976 0.0982 0.0988 0.0970 0.0985 0.0989 0.0986 0.1010 

[TRAIN] Epoch[6](206/1500); Loss: 0.069818; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1365 0.0839 0.0718 0.0651 0.0644 0.0611 0.0629 0.0615 0.0621 0.0619 0.0629 0.0628 0.0640 0.0641 0.0655 0.0664 

[TRAIN] Epoch[6](207/1500); Loss: 0.111771; Backpropagation: 0.0921 sec; Batch: 0.4280 sec
0.1317 0.1256 0.1343 0.1214 0.1241 0.1077 0.1022 0.1048 0.1050 0.1031 0.1041 0.1037 0.1040 0.1045 0.1051 0.1070 

[TRAIN] Epoch[6](208/1500); Loss: 0.073550; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1381 0.0960 0.0811 0.0823 0.0768 0.0685 0.0787 0.0672 0.0575 0.0585 0.0617 0.0648 0.0598 0.0592 0.0618 0.0651 

[TRAIN] Epoch[6](209/1500); Loss: 0.124242; Backpropagation: 0.0920 sec; Batch: 0.4256 sec
0.2472 0.1542 0.1373 0.1406 0.1323 0.1178 0.1083 0.1059 0.1044 0.1006 0.1018 0.1051 0.1087 0.1072 0.1073 0.1090 

[TRAIN] Epoch[6](210/1500); Loss: 0.073388; Backpropagation: 0.0917 sec; Batch: 0.4303 sec
0.1134 0.0853 0.0803 0.0786 0.0752 0.0741 0.0699 0.0712 0.0667 0.0653 0.0672 0.0664 0.0648 0.0661 0.0646 0.0650 

[TRAIN] Epoch[6](211/1500); Loss: 0.072529; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0979 0.0884 0.0832 0.0714 0.0670 0.0662 0.0671 0.0650 0.0655 0.0662 0.0671 0.0680 0.0697 0.0711 0.0726 0.0739 

[TRAIN] Epoch[6](212/1500); Loss: 0.156384; Backpropagation: 0.0917 sec; Batch: 0.4464 sec
0.2336 0.1740 0.1724 0.1743 0.1670 0.1570 0.1492 0.1444 0.1450 0.1400 0.1425 0.1410 0.1414 0.1389 0.1405 0.1409 

[TRAIN] Epoch[6](213/1500); Loss: 0.088578; Backpropagation: 0.0921 sec; Batch: 0.4280 sec
0.1034 0.0846 0.1628 0.1497 0.1328 0.1038 0.0758 0.0668 0.0651 0.0664 0.0640 0.0650 0.0674 0.0691 0.0693 0.0714 

[TRAIN] Epoch[6](214/1500); Loss: 0.112028; Backpropagation: 0.0920 sec; Batch: 0.4262 sec
0.1945 0.1439 0.1200 0.1132 0.1044 0.0968 0.1022 0.1000 0.0989 0.0969 0.0995 0.1034 0.1013 0.1017 0.1049 0.1109 

[TRAIN] Epoch[6](215/1500); Loss: 0.098854; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1570 0.0415 0.1876 0.1743 0.1571 0.1195 0.0750 0.0527 0.0766 0.0708 0.0714 0.0668 0.0708 0.0864 0.0901 0.0840 

[TRAIN] Epoch[6](216/1500); Loss: 0.095480; Backpropagation: 0.0918 sec; Batch: 0.4253 sec
0.1549 0.1036 0.1183 0.1083 0.0980 0.0858 0.0884 0.0892 0.0828 0.0808 0.0820 0.0850 0.0881 0.0866 0.0868 0.0891 

[TRAIN] Epoch[6](217/1500); Loss: 0.079245; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2249 0.1248 0.0946 0.0826 0.0647 0.0653 0.0686 0.0580 0.0623 0.0621 0.0603 0.0596 0.0603 0.0603 0.0581 0.0613 

[TRAIN] Epoch[6](218/1500); Loss: 0.090827; Backpropagation: 0.0922 sec; Batch: 0.4265 sec
0.0921 0.0869 0.1007 0.1038 0.0994 0.0944 0.0888 0.0839 0.0845 0.0833 0.0864 0.0861 0.0867 0.0882 0.0945 0.0935 

[TRAIN] Epoch[6](219/1500); Loss: 0.095797; Backpropagation: 0.0920 sec; Batch: 0.4264 sec
0.1403 0.1180 0.1078 0.0987 0.0987 0.0911 0.0878 0.0858 0.0862 0.0873 0.0877 0.0881 0.0886 0.0887 0.0881 0.0897 

[TRAIN] Epoch[6](220/1500); Loss: 0.151793; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1652 0.1620 0.1616 0.1552 0.1503 0.1475 0.1485 0.1489 0.1468 0.1471 0.1480 0.1488 0.1488 0.1485 0.1501 0.1515 

[TRAIN] Epoch[6](221/1500); Loss: 0.202091; Backpropagation: 0.0920 sec; Batch: 0.4626 sec
0.2602 0.2386 0.2227 0.2181 0.2127 0.1999 0.1935 0.1907 0.1885 0.1872 0.1856 0.1872 0.1858 0.1864 0.1878 0.1883 

[TRAIN] Epoch[6](222/1500); Loss: 0.069485; Backpropagation: 0.0917 sec; Batch: 0.4668 sec
0.0824 0.0782 0.0680 0.0902 0.0781 0.0681 0.0645 0.0602 0.0606 0.0636 0.0637 0.0642 0.0646 0.0684 0.0683 0.0689 

[TRAIN] Epoch[6](223/1500); Loss: 0.082444; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1037 0.0930 0.0945 0.0862 0.0789 0.0770 0.0790 0.0772 0.0770 0.0773 0.0783 0.0782 0.0785 0.0797 0.0804 0.0802 

[TRAIN] Epoch[6](224/1500); Loss: 0.103398; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1531 0.1263 0.1161 0.1089 0.1046 0.0952 0.0955 0.0958 0.0941 0.0929 0.0942 0.0950 0.0943 0.0952 0.0964 0.0968 

[TRAIN] Epoch[6](225/1500); Loss: 0.196633; Backpropagation: 0.0918 sec; Batch: 0.4525 sec
0.3304 0.2557 0.2225 0.2055 0.1895 0.1766 0.1832 0.1750 0.1757 0.1766 0.1766 0.1763 0.1744 0.1752 0.1771 0.1759 

[TRAIN] Epoch[6](226/1500); Loss: 0.072919; Backpropagation: 0.0917 sec; Batch: 0.4352 sec
0.1214 0.1150 0.1053 0.0775 0.0691 0.0618 0.0633 0.0618 0.0605 0.0589 0.0617 0.0607 0.0608 0.0621 0.0628 0.0638 

[TRAIN] Epoch[6](227/1500); Loss: 0.139374; Backpropagation: 0.0994 sec; Batch: 0.4368 sec
0.1760 0.1557 0.1561 0.1523 0.1468 0.1385 0.1352 0.1324 0.1300 0.1295 0.1300 0.1292 0.1292 0.1295 0.1297 0.1301 

[TRAIN] Epoch[6](228/1500); Loss: 0.092185; Backpropagation: 0.0921 sec; Batch: 0.4253 sec
0.1514 0.0899 0.1113 0.1032 0.0926 0.0802 0.0882 0.0906 0.0817 0.0806 0.0833 0.0838 0.0848 0.0837 0.0849 0.0848 

[TRAIN] Epoch[6](229/1500); Loss: 0.065285; Backpropagation: 0.0919 sec; Batch: 0.4308 sec
0.1201 0.0774 0.0731 0.0653 0.0626 0.0600 0.0601 0.0582 0.0579 0.0573 0.0573 0.0580 0.0588 0.0585 0.0596 0.0605 

[TRAIN] Epoch[6](230/1500); Loss: 0.149567; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.2137 0.1651 0.1573 0.1533 0.1479 0.1470 0.1437 0.1430 0.1415 0.1407 0.1408 0.1397 0.1398 0.1400 0.1390 0.1404 

[TRAIN] Epoch[6](231/1500); Loss: 0.114570; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1332 0.1272 0.1292 0.1190 0.1113 0.1089 0.1112 0.1106 0.1075 0.1079 0.1094 0.1108 0.1091 0.1105 0.1133 0.1139 

[TRAIN] Epoch[6](232/1500); Loss: 0.103613; Backpropagation: 0.1000 sec; Batch: 0.4344 sec
0.1722 0.1164 0.1276 0.1181 0.1081 0.0938 0.1011 0.0917 0.0893 0.0916 0.0894 0.0902 0.0914 0.0909 0.0916 0.0946 

[TRAIN] Epoch[6](233/1500); Loss: 0.057907; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.0984 0.0759 0.0747 0.0609 0.0508 0.0509 0.0502 0.0500 0.0490 0.0501 0.0501 0.0516 0.0517 0.0528 0.0541 0.0553 

[TRAIN] Epoch[6](234/1500); Loss: 0.120268; Backpropagation: 0.0919 sec; Batch: 0.4277 sec
0.1685 0.1412 0.1342 0.1251 0.1187 0.1144 0.1152 0.1132 0.1100 0.1100 0.1102 0.1116 0.1118 0.1119 0.1134 0.1148 

[TRAIN] Epoch[6](235/1500); Loss: 0.202805; Backpropagation: 0.0920 sec; Batch: 0.4269 sec
0.2544 0.2302 0.2215 0.2145 0.2056 0.1999 0.1977 0.1944 0.1936 0.1927 0.1906 0.1899 0.1901 0.1902 0.1897 0.1898 

[TRAIN] Epoch[6](236/1500); Loss: 0.139873; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2036 0.1689 0.1615 0.1457 0.1333 0.1308 0.1326 0.1279 0.1286 0.1279 0.1291 0.1283 0.1285 0.1292 0.1313 0.1308 

[TRAIN] Epoch[6](237/1500); Loss: 0.090885; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1106 0.1010 0.1016 0.0969 0.0879 0.0869 0.0868 0.0865 0.0855 0.0858 0.0864 0.0865 0.0871 0.0877 0.0878 0.0891 

[TRAIN] Epoch[6](238/1500); Loss: 0.135177; Backpropagation: 0.0916 sec; Batch: 0.4647 sec
0.2993 0.1934 0.1775 0.1607 0.1368 0.1172 0.1269 0.1096 0.1047 0.1076 0.1094 0.1069 0.1005 0.1034 0.1053 0.1035 

[TRAIN] Epoch[6](239/1500); Loss: 0.092517; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1151 0.1122 0.1076 0.0960 0.0896 0.0884 0.0873 0.0867 0.0862 0.0860 0.0854 0.0860 0.0871 0.0891 0.0888 0.0889 

[TRAIN] Epoch[6](240/1500); Loss: 0.065602; Backpropagation: 0.0915 sec; Batch: 0.4310 sec
0.0539 0.0566 0.0725 0.0939 0.0738 0.0654 0.0613 0.0616 0.0626 0.0625 0.0612 0.0631 0.0637 0.0633 0.0666 0.0675 

[TRAIN] Epoch[6](241/1500); Loss: 0.134917; Backpropagation: 0.0917 sec; Batch: 0.4273 sec
0.1671 0.1427 0.1461 0.1460 0.1392 0.1385 0.1310 0.1271 0.1284 0.1296 0.1275 0.1246 0.1266 0.1307 0.1266 0.1269 

[TRAIN] Epoch[6](242/1500); Loss: 0.110762; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2087 0.1368 0.1416 0.1320 0.1190 0.1002 0.1043 0.0981 0.0924 0.0904 0.0926 0.0918 0.0895 0.0913 0.0925 0.0910 

[TRAIN] Epoch[6](243/1500); Loss: 0.082680; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.1201 0.0921 0.0934 0.0845 0.0800 0.0778 0.0768 0.0769 0.0775 0.0759 0.0762 0.0775 0.0779 0.0780 0.0780 0.0803 

[TRAIN] Epoch[6](244/1500); Loss: 0.117877; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1415 0.1196 0.1297 0.1291 0.1200 0.1123 0.1127 0.1106 0.1117 0.1118 0.1145 0.1149 0.1127 0.1131 0.1157 0.1162 

[TRAIN] Epoch[6](245/1500); Loss: 0.105641; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1212 0.1115 0.1115 0.1109 0.1054 0.1021 0.1017 0.1010 0.1011 0.1012 0.1028 0.1022 0.1031 0.1037 0.1050 0.1058 

[TRAIN] Epoch[6](246/1500); Loss: 0.089068; Backpropagation: 0.0919 sec; Batch: 0.4260 sec
0.1138 0.1203 0.1342 0.1067 0.1000 0.0819 0.0771 0.0782 0.0746 0.0737 0.0750 0.0759 0.0763 0.0780 0.0792 0.0802 

[TRAIN] Epoch[6](247/1500); Loss: 0.078266; Backpropagation: 0.0986 sec; Batch: 0.4357 sec
0.1157 0.1010 0.0950 0.0798 0.0756 0.0724 0.0707 0.0697 0.0708 0.0701 0.0719 0.0701 0.0723 0.0711 0.0725 0.0735 

[TRAIN] Epoch[6](248/1500); Loss: 0.089912; Backpropagation: 0.0934 sec; Batch: 0.4256 sec
0.1649 0.1067 0.1072 0.0993 0.0945 0.0966 0.0797 0.0829 0.0782 0.0763 0.0776 0.0735 0.0759 0.0762 0.0732 0.0759 

[TRAIN] Epoch[6](249/1500); Loss: 0.079310; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0800 0.0802 0.0906 0.0755 0.0903 0.0715 0.0728 0.0686 0.0695 0.0779 0.0765 0.0760 0.0815 0.0844 0.0847 0.0889 

[TRAIN] Epoch[6](250/1500); Loss: 0.126409; Backpropagation: 0.0918 sec; Batch: 0.4278 sec
0.1534 0.1543 0.1582 0.1396 0.1248 0.1168 0.1130 0.1131 0.1129 0.1124 0.1138 0.1157 0.1182 0.1218 0.1261 0.1287 

[TRAIN] Epoch[6](251/1500); Loss: 0.077484; Backpropagation: 0.0920 sec; Batch: 0.4262 sec
0.1018 0.0807 0.1058 0.0960 0.0875 0.0729 0.0807 0.0701 0.0653 0.0662 0.0679 0.0673 0.0688 0.0693 0.0690 0.0702 

[TRAIN] Epoch[6](252/1500); Loss: 0.116918; Backpropagation: 0.0916 sec; Batch: 0.4616 sec
0.1429 0.1321 0.1335 0.1227 0.1164 0.1142 0.1122 0.1107 0.1094 0.1102 0.1111 0.1099 0.1096 0.1105 0.1122 0.1131 

[TRAIN] Epoch[6](253/1500); Loss: 0.099069; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.1127 0.1142 0.1152 0.1033 0.1017 0.0946 0.0918 0.0921 0.0919 0.0929 0.0940 0.0947 0.0951 0.0956 0.0970 0.0984 

[TRAIN] Epoch[6](254/1500); Loss: 0.088503; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1067 0.0873 0.1273 0.1200 0.1141 0.0907 0.0762 0.0863 0.0776 0.0764 0.0738 0.0754 0.0768 0.0761 0.0750 0.0763 

[TRAIN] Epoch[6](255/1500); Loss: 0.126072; Backpropagation: 0.0918 sec; Batch: 0.4441 sec
0.1409 0.1412 0.1525 0.1406 0.1329 0.1213 0.1181 0.1239 0.1178 0.1169 0.1165 0.1177 0.1183 0.1192 0.1191 0.1203 

[TRAIN] Epoch[6](256/1500); Loss: 0.080623; Backpropagation: 0.0917 sec; Batch: 0.4288 sec
0.1366 0.1076 0.0938 0.0775 0.0808 0.0711 0.0696 0.0694 0.0700 0.0706 0.0720 0.0725 0.0731 0.0737 0.0761 0.0756 

[TRAIN] Epoch[6](257/1500); Loss: 0.095360; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1608 0.1096 0.1089 0.1077 0.1004 0.0908 0.0886 0.0890 0.0864 0.0820 0.0828 0.0839 0.0847 0.0831 0.0834 0.0836 

[TRAIN] Epoch[6](258/1500); Loss: 0.078318; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1214 0.0975 0.1160 0.1025 0.0919 0.0780 0.0752 0.0668 0.0654 0.0623 0.0605 0.0636 0.0638 0.0620 0.0621 0.0639 

[TRAIN] Epoch[6](259/1500); Loss: 0.169795; Backpropagation: 0.0915 sec; Batch: 0.4305 sec
0.2118 0.1953 0.1943 0.1794 0.1781 0.1668 0.1622 0.1595 0.1586 0.1574 0.1576 0.1578 0.1588 0.1585 0.1599 0.1604 

[TRAIN] Epoch[6](260/1500); Loss: 0.102729; Backpropagation: 0.0914 sec; Batch: 0.4440 sec
0.1577 0.1291 0.1267 0.1094 0.1072 0.0976 0.0903 0.0920 0.0918 0.0903 0.0910 0.0907 0.0916 0.0912 0.0933 0.0941 

[TRAIN] Epoch[6](261/1500); Loss: 0.113631; Backpropagation: 0.0919 sec; Batch: 0.4248 sec
0.1195 0.1154 0.1256 0.1198 0.1145 0.1091 0.1154 0.1123 0.1077 0.1071 0.1082 0.1101 0.1107 0.1118 0.1144 0.1166 

[TRAIN] Epoch[6](262/1500); Loss: 0.113743; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.1557 0.1168 0.1566 0.1481 0.1375 0.1137 0.1033 0.1058 0.1011 0.0982 0.0962 0.0963 0.0974 0.0984 0.0971 0.0976 

[TRAIN] Epoch[6](263/1500); Loss: 0.116885; Backpropagation: 0.0918 sec; Batch: 0.4410 sec
0.1551 0.1243 0.1833 0.1759 0.1615 0.1300 0.1057 0.1046 0.1009 0.0942 0.0896 0.0885 0.0891 0.0889 0.0880 0.0906 

[TRAIN] Epoch[6](264/1500); Loss: 0.080954; Backpropagation: 0.0919 sec; Batch: 0.4252 sec
0.1357 0.1009 0.1069 0.0863 0.0745 0.0717 0.0703 0.0714 0.0685 0.0701 0.0706 0.0723 0.0734 0.0719 0.0743 0.0767 

[TRAIN] Epoch[6](265/1500); Loss: 0.082283; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.0791 0.0807 0.1282 0.1149 0.1147 0.0876 0.0724 0.0704 0.0685 0.0703 0.0710 0.0687 0.0694 0.0722 0.0750 0.0733 

[TRAIN] Epoch[6](266/1500); Loss: 0.135969; Backpropagation: 0.0916 sec; Batch: 0.4442 sec
0.1909 0.1724 0.1628 0.1423 0.1388 0.1269 0.1218 0.1235 0.1214 0.1230 0.1236 0.1238 0.1254 0.1253 0.1259 0.1279 

[TRAIN] Epoch[6](267/1500); Loss: 0.096493; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1541 0.1480 0.1675 0.1333 0.1078 0.0912 0.0782 0.0805 0.0754 0.0728 0.0709 0.0727 0.0724 0.0714 0.0728 0.0750 

[TRAIN] Epoch[6](268/1500); Loss: 0.109534; Backpropagation: 0.0917 sec; Batch: 0.4226 sec
0.1799 0.1361 0.1374 0.1224 0.1093 0.1021 0.1015 0.0970 0.0969 0.0947 0.0938 0.0941 0.0966 0.0968 0.0964 0.0977 

[TRAIN] Epoch[6](269/1500); Loss: 0.109226; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1680 0.1647 0.1529 0.1079 0.1077 0.0978 0.0983 0.0963 0.0924 0.0905 0.0943 0.0968 0.0945 0.0933 0.0951 0.0970 

[TRAIN] Epoch[6](270/1500); Loss: 0.121668; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1662 0.1674 0.1683 0.1459 0.1347 0.1207 0.1100 0.1065 0.1055 0.1035 0.1030 0.1019 0.1024 0.1039 0.1032 0.1035 

[TRAIN] Epoch[6](271/1500); Loss: 0.077043; Backpropagation: 0.0991 sec; Batch: 0.4356 sec
0.0704 0.0945 0.1070 0.0875 0.1032 0.0790 0.0748 0.0677 0.0652 0.0667 0.0677 0.0665 0.0685 0.0701 0.0718 0.0721 

[TRAIN] Epoch[6](272/1500); Loss: 0.103451; Backpropagation: 0.0930 sec; Batch: 0.4248 sec
0.1719 0.1296 0.1185 0.1089 0.1021 0.0992 0.0968 0.0945 0.0938 0.0924 0.0921 0.0911 0.0913 0.0907 0.0906 0.0916 

[TRAIN] Epoch[6](273/1500); Loss: 0.116579; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1404 0.1560 0.1756 0.1554 0.1313 0.1124 0.1074 0.1045 0.0997 0.0997 0.0978 0.0968 0.0968 0.0968 0.0976 0.0970 

[TRAIN] Epoch[6](274/1500); Loss: 0.170979; Backpropagation: 0.0915 sec; Batch: 0.4332 sec
0.2757 0.2315 0.2094 0.1873 0.1675 0.1532 0.1533 0.1530 0.1495 0.1508 0.1494 0.1496 0.1502 0.1514 0.1522 0.1517 

[TRAIN] Epoch[6](275/1500); Loss: 0.100101; Backpropagation: 0.0986 sec; Batch: 0.4529 sec
0.1080 0.1566 0.1603 0.1220 0.0895 0.0963 0.0946 0.0880 0.0866 0.0846 0.0848 0.0845 0.0861 0.0845 0.0869 0.0884 

[TRAIN] Epoch[6](276/1500); Loss: 0.076362; Backpropagation: 0.0936 sec; Batch: 0.4251 sec
0.1749 0.0892 0.0807 0.0893 0.0717 0.0667 0.0661 0.0634 0.0644 0.0634 0.0637 0.0651 0.0640 0.0669 0.0658 0.0665 

[TRAIN] Epoch[6](277/1500); Loss: 0.096249; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1045 0.1359 0.1707 0.1519 0.1315 0.1080 0.0856 0.0779 0.0812 0.0723 0.0690 0.0690 0.0703 0.0699 0.0705 0.0718 

[TRAIN] Epoch[6](278/1500); Loss: 0.133619; Backpropagation: 0.0917 sec; Batch: 0.4578 sec
0.1963 0.1432 0.1804 0.1747 0.1579 0.1320 0.1143 0.1293 0.1222 0.1172 0.1131 0.1105 0.1102 0.1126 0.1124 0.1116 

[TRAIN] Epoch[6](279/1500); Loss: 0.139377; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1731 0.1527 0.1968 0.1899 0.1764 0.1514 0.1279 0.1270 0.1255 0.1199 0.1159 0.1127 0.1128 0.1155 0.1166 0.1160 

[TRAIN] Epoch[6](280/1500); Loss: 0.113668; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1256 0.1456 0.1532 0.1349 0.1160 0.1065 0.1072 0.1051 0.1022 0.1012 0.1010 0.1023 0.1037 0.1037 0.1043 0.1061 

[TRAIN] Epoch[6](281/1500); Loss: 0.079629; Backpropagation: 0.0916 sec; Batch: 0.4376 sec
0.1208 0.1211 0.1360 0.1250 0.1008 0.0697 0.0556 0.0751 0.0668 0.0576 0.0568 0.0568 0.0583 0.0575 0.0575 0.0586 

[TRAIN] Epoch[6](282/1500); Loss: 0.113625; Backpropagation: 0.0916 sec; Batch: 0.4264 sec
0.1278 0.1503 0.1576 0.1376 0.1164 0.1065 0.1070 0.1028 0.0991 0.0999 0.1000 0.1008 0.1020 0.1021 0.1031 0.1051 

[TRAIN] Epoch[6](283/1500); Loss: 0.107267; Backpropagation: 0.0921 sec; Batch: 0.4229 sec
0.0909 0.0878 0.2167 0.2116 0.1980 0.1616 0.1052 0.0662 0.0694 0.0810 0.0743 0.0705 0.0652 0.0676 0.0752 0.0750 

[TRAIN] Epoch[6](284/1500); Loss: 0.154108; Backpropagation: 0.0915 sec; Batch: 0.4596 sec
0.1845 0.2080 0.2026 0.1834 0.1609 0.1458 0.1460 0.1449 0.1390 0.1363 0.1360 0.1357 0.1358 0.1354 0.1353 0.1360 

[TRAIN] Epoch[6](285/1500); Loss: 0.170123; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2229 0.2251 0.2206 0.1967 0.1740 0.1579 0.1518 0.1556 0.1551 0.1513 0.1503 0.1505 0.1501 0.1516 0.1538 0.1547 

[TRAIN] Epoch[6](286/1500); Loss: 0.150677; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1700 0.2173 0.2633 0.2452 0.2229 0.1918 0.1533 0.1182 0.1148 0.1110 0.1030 0.0995 0.0996 0.0998 0.1006 0.1005 

[TRAIN] Epoch[6](287/1500); Loss: 0.120010; Backpropagation: 0.0918 sec; Batch: 0.4250 sec
0.1480 0.1833 0.1939 0.1759 0.1451 0.1066 0.0878 0.1018 0.1063 0.0999 0.0968 0.0953 0.0956 0.0949 0.0942 0.0947 

[TRAIN] Epoch[6](288/1500); Loss: 0.111092; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1342 0.1204 0.1532 0.1501 0.1403 0.1190 0.1015 0.1004 0.1040 0.0959 0.0919 0.0921 0.0919 0.0941 0.0940 0.0946 

[TRAIN] Epoch[6](289/1500); Loss: 0.149537; Backpropagation: 0.0915 sec; Batch: 0.4543 sec
0.1721 0.2026 0.2032 0.1838 0.1585 0.1379 0.1352 0.1464 0.1402 0.1328 0.1310 0.1299 0.1293 0.1296 0.1302 0.1299 

[TRAIN] Epoch[6](290/1500); Loss: 0.168015; Backpropagation: 0.0918 sec; Batch: 0.4310 sec
0.1974 0.2282 0.2666 0.2497 0.2246 0.1844 0.1486 0.1384 0.1433 0.1389 0.1318 0.1277 0.1267 0.1267 0.1277 0.1276 

[TRAIN] Epoch[6](291/1500); Loss: 0.174696; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2112 0.2425 0.2552 0.2397 0.2144 0.1823 0.1544 0.1500 0.1557 0.1473 0.1403 0.1392 0.1389 0.1397 0.1413 0.1431 

[TRAIN] Epoch[6](292/1500); Loss: 0.110684; Backpropagation: 0.0917 sec; Batch: 0.4252 sec
0.0965 0.1667 0.2028 0.1839 0.1544 0.1132 0.0853 0.0981 0.0981 0.0852 0.0813 0.0793 0.0805 0.0817 0.0811 0.0829 

[TRAIN] Epoch[6](293/1500); Loss: 0.140212; Backpropagation: 0.0920 sec; Batch: 0.4273 sec
0.1850 0.1785 0.1964 0.1933 0.1794 0.1550 0.1328 0.1298 0.1203 0.1123 0.1106 0.1081 0.1088 0.1094 0.1112 0.1123 

[TRAIN] Epoch[6](294/1500); Loss: 0.110782; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.0882 0.1133 0.2035 0.1925 0.1773 0.1411 0.0952 0.0799 0.1034 0.0943 0.0834 0.0812 0.0796 0.0810 0.0792 0.0796 

[TRAIN] Epoch[6](295/1500); Loss: 0.168169; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1914 0.2029 0.2337 0.2233 0.2064 0.1804 0.1549 0.1431 0.1513 0.1564 0.1466 0.1407 0.1394 0.1389 0.1397 0.1417 

[TRAIN] Epoch[6](296/1500); Loss: 0.155470; Backpropagation: 0.0916 sec; Batch: 0.4347 sec
0.1579 0.1734 0.2280 0.2160 0.2007 0.1725 0.1426 0.1337 0.1457 0.1420 0.1342 0.1293 0.1281 0.1281 0.1275 0.1279 

[TRAIN] Epoch[6](297/1500); Loss: 0.114805; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.1154 0.0974 0.1683 0.1601 0.1461 0.1177 0.0950 0.1033 0.1196 0.1066 0.1018 0.1009 0.1008 0.1016 0.1011 0.1011 

[TRAIN] Epoch[6](298/1500); Loss: 0.097155; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1076 0.1467 0.1538 0.1368 0.1087 0.0768 0.0726 0.0999 0.0954 0.0845 0.0794 0.0784 0.0783 0.0772 0.0784 0.0798 

[TRAIN] Epoch[6](299/1500); Loss: 0.102948; Backpropagation: 0.0918 sec; Batch: 0.4254 sec
0.1507 0.0683 0.1502 0.1910 0.1832 0.1606 0.1167 0.0727 0.0669 0.0835 0.0660 0.0672 0.0645 0.0632 0.0688 0.0735 

[TRAIN] Epoch[6](300/1500); Loss: 0.183770; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1320 0.2211 0.3438 0.3323 0.3148 0.2762 0.2169 0.1566 0.1223 0.1345 0.1247 0.1151 0.1128 0.1102 0.1124 0.1147 

[TRAIN] Epoch[6](301/1500); Loss: 0.168436; Backpropagation: 0.0999 sec; Batch: 0.4395 sec
0.1999 0.2189 0.2402 0.2240 0.2021 0.1772 0.1545 0.1456 0.1467 0.1441 0.1421 0.1405 0.1390 0.1396 0.1405 0.1402 

[TRAIN] Epoch[6](302/1500); Loss: 0.131431; Backpropagation: 0.0933 sec; Batch: 0.4378 sec
0.2558 0.1846 0.1663 0.1486 0.1437 0.1359 0.1163 0.1024 0.1079 0.1065 0.1031 0.1047 0.1039 0.1048 0.1082 0.1103 

[TRAIN] Epoch[6](303/1500); Loss: 0.149507; Backpropagation: 0.0921 sec; Batch: 0.4272 sec
0.2596 0.2187 0.2020 0.1689 0.1434 0.1414 0.1313 0.1242 0.1242 0.1252 0.1236 0.1244 0.1242 0.1253 0.1270 0.1287 

[TRAIN] Epoch[6](304/1500); Loss: 0.132661; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1326 0.1329 0.2392 0.2276 0.2118 0.1728 0.1240 0.1059 0.1114 0.1042 0.0980 0.0911 0.0885 0.0926 0.0941 0.0957 

[TRAIN] Epoch[6](305/1500); Loss: 0.104228; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1544 0.0602 0.1463 0.2006 0.1935 0.1729 0.1297 0.0806 0.0633 0.0803 0.0615 0.0665 0.0643 0.0599 0.0634 0.0704 

[TRAIN] Epoch[6](306/1500); Loss: 0.101786; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1172 0.0647 0.1832 0.1957 0.1847 0.1540 0.1018 0.0633 0.0793 0.0739 0.0707 0.0690 0.0643 0.0638 0.0695 0.0734 

[TRAIN] Epoch[6](307/1500); Loss: 0.132977; Backpropagation: 0.0917 sec; Batch: 0.4351 sec
0.1110 0.1384 0.2307 0.2208 0.2039 0.1644 0.1114 0.0881 0.1255 0.1232 0.1088 0.1034 0.0993 0.0976 0.1002 0.1011 

[TRAIN] Epoch[6](308/1500); Loss: 0.159899; Backpropagation: 0.1000 sec; Batch: 0.4341 sec
0.1965 0.2045 0.1963 0.1816 0.1671 0.1566 0.1491 0.1524 0.1480 0.1441 0.1435 0.1428 0.1433 0.1436 0.1439 0.1450 

[TRAIN] Epoch[6](309/1500); Loss: 0.104405; Backpropagation: 0.0920 sec; Batch: 0.4279 sec
0.1372 0.1942 0.1919 0.1706 0.1328 0.0919 0.0741 0.0951 0.0888 0.0754 0.0711 0.0696 0.0687 0.0696 0.0696 0.0698 

[TRAIN] Epoch[6](310/1500); Loss: 0.122138; Backpropagation: 0.0917 sec; Batch: 0.4329 sec
0.1578 0.1994 0.1995 0.1874 0.1639 0.1329 0.1033 0.0945 0.0933 0.0895 0.0876 0.0869 0.0869 0.0903 0.0902 0.0908 

[TRAIN] Epoch[6](311/1500); Loss: 0.085603; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1759 0.1242 0.1096 0.0980 0.0952 0.0841 0.0715 0.0676 0.0668 0.0665 0.0669 0.0672 0.0690 0.0688 0.0682 0.0702 

[TRAIN] Epoch[6](312/1500); Loss: 0.138225; Backpropagation: 0.0917 sec; Batch: 0.4275 sec
0.0948 0.1186 0.2737 0.2647 0.2507 0.2144 0.1549 0.0977 0.0906 0.1053 0.0986 0.0937 0.0874 0.0852 0.0895 0.0918 

[TRAIN] Epoch[6](313/1500); Loss: 0.119067; Backpropagation: 0.0922 sec; Batch: 0.4260 sec
0.1667 0.1573 0.1946 0.1756 0.1572 0.1349 0.1077 0.0993 0.1059 0.0925 0.0862 0.0839 0.0832 0.0870 0.0859 0.0872 

[TRAIN] Epoch[6](314/1500); Loss: 0.167655; Backpropagation: 0.0925 sec; Batch: 0.4240 sec
0.2520 0.2320 0.2182 0.1918 0.1721 0.1604 0.1565 0.1520 0.1470 0.1454 0.1440 0.1422 0.1421 0.1420 0.1422 0.1426 

[TRAIN] Epoch[6](315/1500); Loss: 0.157989; Backpropagation: 0.0918 sec; Batch: 0.4350 sec
0.2127 0.2022 0.2420 0.2245 0.2166 0.1892 0.1525 0.1314 0.1322 0.1297 0.1225 0.1175 0.1135 0.1138 0.1132 0.1143 

[TRAIN] Epoch[6](316/1500); Loss: 0.123081; Backpropagation: 0.0919 sec; Batch: 0.4493 sec
0.3155 0.2187 0.1450 0.0933 0.1051 0.1063 0.1053 0.0973 0.0988 0.0953 0.0965 0.0978 0.0972 0.0956 0.0996 0.1019 

[TRAIN] Epoch[6](317/1500); Loss: 0.089939; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1516 0.1212 0.1109 0.1008 0.0875 0.0817 0.0819 0.0795 0.0778 0.0768 0.0772 0.0785 0.0776 0.0771 0.0787 0.0801 

[TRAIN] Epoch[6](318/1500); Loss: 0.187744; Backpropagation: 0.1018 sec; Batch: 0.4350 sec
0.1984 0.2649 0.3019 0.2839 0.2557 0.2152 0.1782 0.1655 0.1637 0.1574 0.1492 0.1390 0.1341 0.1315 0.1318 0.1334 

[TRAIN] Epoch[6](319/1500); Loss: 0.145443; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1104 0.1107 0.2750 0.2673 0.2543 0.2224 0.1662 0.1105 0.0872 0.1082 0.1060 0.1020 0.0988 0.0997 0.1035 0.1048 

[TRAIN] Epoch[6](320/1500); Loss: 0.113249; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1814 0.2433 0.2479 0.2335 0.2002 0.1540 0.0985 0.0550 0.0630 0.0532 0.0481 0.0478 0.0459 0.0468 0.0472 0.0462 

[TRAIN] Epoch[6](321/1500); Loss: 0.167304; Backpropagation: 0.0919 sec; Batch: 0.4300 sec
0.2056 0.1999 0.2414 0.2214 0.2056 0.1838 0.1557 0.1491 0.1568 0.1492 0.1386 0.1345 0.1328 0.1343 0.1341 0.1342 

[TRAIN] Epoch[6](322/1500); Loss: 0.122350; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1532 0.1749 0.1679 0.1509 0.1299 0.1155 0.1168 0.1135 0.1069 0.1042 0.1034 0.1032 0.1039 0.1046 0.1043 0.1044 

[TRAIN] Epoch[6](323/1500); Loss: 0.113750; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1793 0.1362 0.1445 0.1658 0.1572 0.1387 0.1115 0.0872 0.0857 0.0923 0.0866 0.0854 0.0845 0.0861 0.0879 0.0911 

[TRAIN] Epoch[6](324/1500); Loss: 0.136691; Backpropagation: 0.0992 sec; Batch: 0.4338 sec
0.1692 0.1492 0.1585 0.1572 0.1476 0.1338 0.1276 0.1246 0.1262 0.1255 0.1263 0.1270 0.1282 0.1279 0.1286 0.1295 

[TRAIN] Epoch[6](325/1500); Loss: 0.100017; Backpropagation: 0.0925 sec; Batch: 0.4243 sec
0.0667 0.1002 0.1991 0.1890 0.1734 0.1374 0.0903 0.0680 0.0847 0.0790 0.0699 0.0688 0.0671 0.0683 0.0695 0.0692 

[TRAIN] Epoch[6](326/1500); Loss: 0.183530; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1240 0.2229 0.3449 0.3343 0.3177 0.2805 0.2233 0.1631 0.1200 0.1300 0.1246 0.1125 0.1129 0.1088 0.1086 0.1085 

[TRAIN] Epoch[6](327/1500); Loss: 0.175445; Backpropagation: 0.0917 sec; Batch: 0.4283 sec
0.3459 0.2857 0.2490 0.1885 0.1583 0.1792 0.1617 0.1460 0.1410 0.1359 0.1322 0.1334 0.1366 0.1372 0.1375 0.1390 

[TRAIN] Epoch[6](328/1500); Loss: 0.140961; Backpropagation: 0.0917 sec; Batch: 0.4273 sec
0.2015 0.1654 0.1720 0.1636 0.1499 0.1364 0.1292 0.1314 0.1305 0.1257 0.1241 0.1233 0.1248 0.1256 0.1251 0.1268 

[TRAIN] Epoch[6](329/1500); Loss: 0.193786; Backpropagation: 0.0917 sec; Batch: 0.4621 sec
0.2326 0.2211 0.2715 0.2606 0.2499 0.2238 0.1913 0.1723 0.1728 0.1701 0.1612 0.1561 0.1542 0.1540 0.1542 0.1548 

[TRAIN] Epoch[6](330/1500); Loss: 0.090734; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1234 0.1309 0.1451 0.1298 0.1071 0.0873 0.0745 0.0762 0.0772 0.0718 0.0713 0.0707 0.0719 0.0716 0.0714 0.0715 

[TRAIN] Epoch[6](331/1500); Loss: 0.142241; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.1594 0.1418 0.2062 0.2001 0.1892 0.1623 0.1308 0.1241 0.1359 0.1264 0.1176 0.1157 0.1159 0.1167 0.1172 0.1164 

[TRAIN] Epoch[6](332/1500); Loss: 0.158423; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.1806 0.2866 0.3186 0.3049 0.2774 0.2335 0.1751 0.1165 0.0873 0.0910 0.0871 0.0765 0.0745 0.0744 0.0764 0.0743 

[TRAIN] Epoch[6](333/1500); Loss: 0.160212; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.3583 0.2849 0.2457 0.2052 0.1645 0.1296 0.1236 0.1384 0.1189 0.1120 0.1140 0.1132 0.1134 0.1123 0.1138 0.1157 

[TRAIN] Epoch[6](334/1500); Loss: 0.151973; Backpropagation: 0.0917 sec; Batch: 0.4256 sec
0.2614 0.2450 0.2498 0.2185 0.1858 0.1534 0.1313 0.1211 0.1165 0.1123 0.1070 0.1051 0.1057 0.1062 0.1065 0.1059 

[TRAIN] Epoch[6](335/1500); Loss: 0.161455; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2030 0.2286 0.2488 0.2292 0.2058 0.1795 0.1543 0.1389 0.1329 0.1282 0.1235 0.1224 0.1221 0.1215 0.1216 0.1228 

[TRAIN] Epoch[6](336/1500); Loss: 0.113411; Backpropagation: 0.0917 sec; Batch: 0.4259 sec
0.1478 0.1407 0.1614 0.1550 0.1389 0.1178 0.1010 0.1022 0.1019 0.0943 0.0924 0.0919 0.0921 0.0929 0.0922 0.0921 

[TRAIN] Epoch[6](337/1500); Loss: 0.095256; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1505 0.1453 0.1396 0.1299 0.1136 0.0924 0.0777 0.0771 0.0782 0.0750 0.0741 0.0732 0.0734 0.0743 0.0747 0.0750 

[TRAIN] Epoch[6](338/1500); Loss: 0.109274; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1499 0.1634 0.1642 0.1512 0.1291 0.1043 0.0925 0.0936 0.0911 0.0869 0.0858 0.0858 0.0871 0.0873 0.0880 0.0881 

[TRAIN] Epoch[6](339/1500); Loss: 0.172603; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2907 0.2473 0.2370 0.2040 0.1878 0.1772 0.1516 0.1428 0.1469 0.1449 0.1410 0.1398 0.1376 0.1381 0.1375 0.1376 

[TRAIN] Epoch[6](340/1500); Loss: 0.120294; Backpropagation: 0.0920 sec; Batch: 0.4254 sec
0.1510 0.1720 0.1679 0.1533 0.1298 0.1096 0.1055 0.1093 0.1063 0.1029 0.1021 0.1018 0.1022 0.1036 0.1035 0.1039 

[TRAIN] Epoch[6](341/1500); Loss: 0.191032; Backpropagation: 0.0918 sec; Batch: 0.4474 sec
0.2916 0.2585 0.2255 0.2001 0.1851 0.1819 0.1751 0.1763 0.1700 0.1685 0.1712 0.1719 0.1700 0.1687 0.1681 0.1739 

[TRAIN] Epoch[6](342/1500); Loss: 0.171977; Backpropagation: 0.0916 sec; Batch: 0.4257 sec
0.1918 0.2167 0.2490 0.2342 0.2141 0.1856 0.1613 0.1546 0.1561 0.1478 0.1413 0.1401 0.1396 0.1396 0.1398 0.1400 

[TRAIN] Epoch[6](343/1500); Loss: 0.077338; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0926 0.1177 0.1299 0.1044 0.0895 0.0765 0.0633 0.0605 0.0665 0.0609 0.0597 0.0601 0.0640 0.0639 0.0637 0.0641 

[TRAIN] Epoch[6](344/1500); Loss: 0.157261; Backpropagation: 0.0918 sec; Batch: 0.4279 sec
0.1735 0.2232 0.2628 0.2445 0.2174 0.1800 0.1418 0.1240 0.1305 0.1262 0.1155 0.1149 0.1158 0.1154 0.1152 0.1154 

[TRAIN] Epoch[6](345/1500); Loss: 0.146809; Backpropagation: 0.0920 sec; Batch: 0.4266 sec
0.2327 0.1882 0.1792 0.1923 0.1824 0.1643 0.1418 0.1248 0.1295 0.1211 0.1189 0.1154 0.1134 0.1131 0.1166 0.1152 

[TRAIN] Epoch[6](346/1500); Loss: 0.087839; Backpropagation: 0.0997 sec; Batch: 0.4348 sec
0.1337 0.0911 0.0903 0.0992 0.0897 0.0814 0.0804 0.0798 0.0799 0.0808 0.0813 0.0821 0.0826 0.0833 0.0845 0.0853 

[TRAIN] Epoch[6](347/1500); Loss: 0.139976; Backpropagation: 0.0920 sec; Batch: 0.4269 sec
0.1576 0.1544 0.1726 0.1683 0.1564 0.1396 0.1279 0.1334 0.1352 0.1282 0.1264 0.1266 0.1274 0.1281 0.1282 0.1294 

[TRAIN] Epoch[6](348/1500); Loss: 0.119801; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1558 0.1618 0.1765 0.1727 0.1553 0.1343 0.1104 0.0933 0.0921 0.0924 0.0917 0.0915 0.0930 0.0954 0.0993 0.1013 

[TRAIN] Epoch[6](349/1500); Loss: 0.145675; Backpropagation: 0.0918 sec; Batch: 0.4302 sec
0.1768 0.2055 0.1973 0.1803 0.1610 0.1432 0.1352 0.1326 0.1279 0.1252 0.1241 0.1239 0.1246 0.1244 0.1243 0.1247 

[TRAIN] Epoch[6](350/1500); Loss: 0.077606; Backpropagation: 0.0918 sec; Batch: 0.4270 sec
0.1700 0.1243 0.0939 0.0860 0.0840 0.0657 0.0615 0.0636 0.0615 0.0608 0.0611 0.0614 0.0620 0.0618 0.0616 0.0626 

[TRAIN] Epoch[6](351/1500); Loss: 0.168145; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1820 0.2321 0.2489 0.2320 0.2054 0.1747 0.1542 0.1575 0.1532 0.1402 0.1358 0.1349 0.1348 0.1354 0.1349 0.1345 

[TRAIN] Epoch[6](352/1500); Loss: 0.144520; Backpropagation: 0.0988 sec; Batch: 0.4341 sec
0.1496 0.1797 0.2650 0.2519 0.2323 0.1940 0.1468 0.1165 0.1074 0.1024 0.0996 0.0950 0.0920 0.0919 0.0929 0.0954 

[TRAIN] Epoch[6](353/1500); Loss: 0.155101; Backpropagation: 0.0927 sec; Batch: 0.4242 sec
0.1793 0.2524 0.2862 0.2702 0.2412 0.1971 0.1437 0.1069 0.1088 0.1083 0.1013 0.0980 0.0957 0.0951 0.0992 0.0981 

[TRAIN] Epoch[6](354/1500); Loss: 0.096616; Backpropagation: 0.0917 sec; Batch: 0.4260 sec
0.1327 0.1285 0.1344 0.1308 0.1107 0.0901 0.0816 0.0832 0.0843 0.0813 0.0810 0.0808 0.0814 0.0810 0.0813 0.0827 

[TRAIN] Epoch[6](355/1500); Loss: 0.136810; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1097 0.1010 0.2596 0.2520 0.2390 0.2087 0.1590 0.1120 0.0852 0.0939 0.0965 0.0947 0.0915 0.0918 0.0962 0.0982 

[TRAIN] Epoch[6](356/1500); Loss: 0.057450; Backpropagation: 0.0919 sec; Batch: 0.4253 sec
0.1589 0.0689 0.0587 0.0804 0.0597 0.0457 0.0448 0.0410 0.0449 0.0447 0.0442 0.0460 0.0431 0.0448 0.0454 0.0481 

[TRAIN] Epoch[6](357/1500); Loss: 0.088552; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.1069 0.0886 0.1048 0.0974 0.0870 0.0848 0.0849 0.0845 0.0843 0.0836 0.0840 0.0846 0.0852 0.0850 0.0853 0.0862 

[TRAIN] Epoch[6](358/1500); Loss: 0.112186; Backpropagation: 0.0917 sec; Batch: 0.4580 sec
0.1572 0.2012 0.2069 0.1855 0.1519 0.1148 0.0845 0.0767 0.0860 0.0795 0.0762 0.0743 0.0737 0.0755 0.0757 0.0756 

[TRAIN] Epoch[6](359/1500); Loss: 0.097650; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.1434 0.1700 0.1684 0.1424 0.1134 0.0909 0.0828 0.0807 0.0753 0.0724 0.0711 0.0706 0.0702 0.0697 0.0702 0.0708 

[TRAIN] Epoch[6](360/1500); Loss: 0.145604; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1923 0.1852 0.1844 0.1682 0.1543 0.1410 0.1329 0.1347 0.1319 0.1289 0.1277 0.1281 0.1295 0.1298 0.1305 0.1303 

[TRAIN] Epoch[6](361/1500); Loss: 0.101367; Backpropagation: 0.0993 sec; Batch: 0.4352 sec
0.1791 0.1736 0.1531 0.1334 0.1171 0.0884 0.0756 0.0893 0.0827 0.0759 0.0749 0.0752 0.0752 0.0759 0.0761 0.0764 

[TRAIN] Epoch[6](362/1500); Loss: 0.163337; Backpropagation: 0.0930 sec; Batch: 0.4248 sec
0.2456 0.2375 0.2420 0.2193 0.2058 0.1774 0.1501 0.1336 0.1284 0.1293 0.1241 0.1226 0.1234 0.1244 0.1242 0.1257 

[TRAIN] Epoch[6](363/1500); Loss: 0.131321; Backpropagation: 0.0918 sec; Batch: 0.4680 sec
0.1607 0.2408 0.2571 0.2456 0.2170 0.1786 0.1370 0.1036 0.0803 0.0717 0.0699 0.0650 0.0652 0.0679 0.0696 0.0711 

[TRAIN] Epoch[6](364/1500); Loss: 0.175515; Backpropagation: 0.0916 sec; Batch: 0.4267 sec
0.2013 0.2198 0.2234 0.2080 0.1881 0.1726 0.1625 0.1598 0.1602 0.1588 0.1572 0.1581 0.1589 0.1591 0.1596 0.1610 

[TRAIN] Epoch[6](365/1500); Loss: 0.143700; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1899 0.1910 0.1929 0.1730 0.1515 0.1341 0.1284 0.1303 0.1281 0.1252 0.1244 0.1245 0.1249 0.1257 0.1272 0.1281 

[TRAIN] Epoch[6](366/1500); Loss: 0.154307; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2770 0.2326 0.2187 0.1854 0.1717 0.1546 0.1358 0.1285 0.1273 0.1235 0.1222 0.1184 0.1174 0.1177 0.1186 0.1196 

[TRAIN] Epoch[6](367/1500); Loss: 0.086342; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1131 0.1048 0.1274 0.1149 0.0989 0.0869 0.0786 0.0802 0.0783 0.0728 0.0714 0.0712 0.0710 0.0702 0.0701 0.0717 

[TRAIN] Epoch[6](368/1500); Loss: 0.076779; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.1177 0.1017 0.1245 0.1236 0.1074 0.0830 0.0629 0.0710 0.0680 0.0562 0.0520 0.0513 0.0518 0.0517 0.0524 0.0534 

[TRAIN] Epoch[6](369/1500); Loss: 0.121343; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1925 0.1308 0.1645 0.1761 0.1614 0.1386 0.1118 0.0978 0.1014 0.0979 0.0966 0.0937 0.0936 0.0937 0.0965 0.0946 

[TRAIN] Epoch[6](370/1500); Loss: 0.143925; Backpropagation: 0.0918 sec; Batch: 0.4264 sec
0.3878 0.3038 0.2471 0.1872 0.1334 0.1038 0.1101 0.0927 0.0970 0.1000 0.0952 0.0897 0.0956 0.0847 0.0886 0.0861 

[TRAIN] Epoch[6](371/1500); Loss: 0.158085; Backpropagation: 0.0917 sec; Batch: 0.4545 sec
0.1877 0.2173 0.2627 0.2488 0.2262 0.1871 0.1452 0.1221 0.1280 0.1272 0.1150 0.1117 0.1119 0.1130 0.1130 0.1125 

[TRAIN] Epoch[6](372/1500); Loss: 0.129392; Backpropagation: 0.0917 sec; Batch: 0.4279 sec
0.1594 0.1639 0.1554 0.1409 0.1295 0.1222 0.1212 0.1273 0.1237 0.1188 0.1175 0.1180 0.1186 0.1184 0.1174 0.1181 

[TRAIN] Epoch[6](373/1500); Loss: 0.154700; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1665 0.1784 0.2307 0.2207 0.2036 0.1746 0.1446 0.1350 0.1450 0.1324 0.1257 0.1239 0.1232 0.1237 0.1240 0.1229 

[TRAIN] Epoch[6](374/1500); Loss: 0.108538; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1552 0.1211 0.1114 0.1109 0.1113 0.1031 0.1009 0.1022 0.1011 0.1010 0.1017 0.1026 0.1028 0.1033 0.1038 0.1043 

[TRAIN] Epoch[6](375/1500); Loss: 0.103327; Backpropagation: 0.0917 sec; Batch: 0.4258 sec
0.1195 0.1504 0.1661 0.1555 0.1363 0.1081 0.0865 0.0882 0.0882 0.0807 0.0788 0.0784 0.0782 0.0786 0.0795 0.0801 

[TRAIN] Epoch[6](376/1500); Loss: 0.167073; Backpropagation: 0.0918 sec; Batch: 0.4226 sec
0.1319 0.1477 0.2958 0.2863 0.2726 0.2421 0.1946 0.1495 0.1180 0.1163 0.1244 0.1209 0.1159 0.1160 0.1189 0.1221 

[TRAIN] Epoch[6](377/1500); Loss: 0.160865; Backpropagation: 0.0984 sec; Batch: 0.4401 sec
0.2183 0.2362 0.2459 0.2289 0.2100 0.1849 0.1580 0.1385 0.1300 0.1227 0.1173 0.1155 0.1171 0.1177 0.1161 0.1166 

[TRAIN] Epoch[6](378/1500); Loss: 0.144036; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2439 0.2261 0.2099 0.1785 0.1469 0.1252 0.1188 0.1239 0.1187 0.1153 0.1142 0.1144 0.1164 0.1171 0.1170 0.1182 

[TRAIN] Epoch[6](379/1500); Loss: 0.105336; Backpropagation: 0.0917 sec; Batch: 0.4250 sec
0.0923 0.0983 0.1819 0.1739 0.1615 0.1332 0.0986 0.0834 0.0864 0.0839 0.0816 0.0797 0.0795 0.0818 0.0846 0.0849 

[TRAIN] Epoch[6](380/1500); Loss: 0.076074; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1130 0.0906 0.0914 0.0809 0.0715 0.0682 0.0689 0.0687 0.0687 0.0692 0.0696 0.0701 0.0701 0.0715 0.0720 0.0730 

[TRAIN] Epoch[6](381/1500); Loss: 0.098723; Backpropagation: 0.0919 sec; Batch: 0.4256 sec
0.1744 0.1708 0.1388 0.1173 0.1088 0.0869 0.0840 0.0774 0.0695 0.0658 0.0681 0.0740 0.0777 0.0830 0.0881 0.0951 

[TRAIN] Epoch[6](382/1500); Loss: 0.175534; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1420 0.2365 0.3331 0.3194 0.2991 0.2626 0.2120 0.1600 0.1211 0.1148 0.1102 0.1026 0.0985 0.0981 0.0982 0.1005 

[TRAIN] Epoch[6](383/1500); Loss: 0.192264; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.3404 0.2716 0.2211 0.1812 0.1686 0.1788 0.1740 0.1718 0.1667 0.1672 0.1760 0.1750 0.1743 0.1699 0.1691 0.1705 

[TRAIN] Epoch[6](384/1500); Loss: 0.089845; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.2209 0.1543 0.1170 0.0813 0.0907 0.0848 0.0672 0.0662 0.0659 0.0660 0.0666 0.0682 0.0717 0.0710 0.0719 0.0736 

[TRAIN] Epoch[6](385/1500); Loss: 0.115497; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1475 0.0990 0.1727 0.1835 0.1713 0.1425 0.1061 0.0866 0.0991 0.0912 0.0888 0.0881 0.0880 0.0917 0.0956 0.0962 

[TRAIN] Epoch[6](386/1500); Loss: 0.103190; Backpropagation: 0.0920 sec; Batch: 0.4270 sec
0.1350 0.1440 0.1550 0.1442 0.1244 0.1017 0.0861 0.0881 0.0889 0.0857 0.0833 0.0821 0.0832 0.0833 0.0834 0.0826 

[TRAIN] Epoch[6](387/1500); Loss: 0.139846; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1739 0.1827 0.1762 0.1651 0.1484 0.1334 0.1278 0.1278 0.1257 0.1254 0.1250 0.1246 0.1252 0.1246 0.1257 0.1259 

[TRAIN] Epoch[6](388/1500); Loss: 0.095118; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1574 0.1253 0.1180 0.1029 0.0899 0.0844 0.0839 0.0837 0.0813 0.0839 0.0823 0.0843 0.0853 0.0854 0.0857 0.0882 

[TRAIN] Epoch[6](389/1500); Loss: 0.102267; Backpropagation: 0.0920 sec; Batch: 0.4255 sec
0.1644 0.1390 0.1349 0.1133 0.0968 0.0905 0.0910 0.0893 0.0887 0.0885 0.0882 0.0889 0.0892 0.0894 0.0918 0.0923 

[TRAIN] Epoch[6](390/1500); Loss: 0.106805; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2054 0.1501 0.1422 0.1257 0.1115 0.0977 0.0921 0.0912 0.0888 0.0884 0.0853 0.0855 0.0854 0.0867 0.0868 0.0861 

[TRAIN] Epoch[6](391/1500); Loss: 0.126995; Backpropagation: 0.0919 sec; Batch: 0.4263 sec
0.1518 0.1429 0.1761 0.1689 0.1573 0.1376 0.1201 0.1141 0.1127 0.1114 0.1080 0.1068 0.1069 0.1064 0.1049 0.1060 

[TRAIN] Epoch[6](392/1500); Loss: 0.128599; Backpropagation: 0.0917 sec; Batch: 0.4312 sec
0.1738 0.1728 0.1632 0.1481 0.1330 0.1202 0.1133 0.1140 0.1141 0.1137 0.1131 0.1135 0.1148 0.1159 0.1167 0.1173 

[TRAIN] Epoch[6](393/1500); Loss: 0.117264; Backpropagation: 0.0919 sec; Batch: 0.4268 sec
0.1066 0.1339 0.2131 0.2040 0.1902 0.1635 0.1311 0.1050 0.0854 0.0768 0.0763 0.0774 0.0759 0.0772 0.0781 0.0817 

[TRAIN] Epoch[6](394/1500); Loss: 0.108003; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1272 0.0750 0.1712 0.1997 0.1893 0.1658 0.1283 0.0922 0.0699 0.0644 0.0706 0.0756 0.0737 0.0728 0.0744 0.0779 

[TRAIN] Epoch[6](395/1500); Loss: 0.066668; Backpropagation: 0.0918 sec; Batch: 0.4314 sec
0.1179 0.0935 0.0863 0.0716 0.0632 0.0582 0.0566 0.0565 0.0560 0.0566 0.0565 0.0573 0.0575 0.0586 0.0596 0.0606 

[TRAIN] Epoch[6](396/1500); Loss: 0.161542; Backpropagation: 0.0916 sec; Batch: 0.4625 sec
0.1691 0.1614 0.2532 0.2423 0.2274 0.1986 0.1644 0.1423 0.1331 0.1309 0.1303 0.1273 0.1259 0.1254 0.1250 0.1280 

[TRAIN] Epoch[6](397/1500); Loss: 0.147519; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2433 0.1922 0.1767 0.1588 0.1462 0.1356 0.1314 0.1321 0.1323 0.1322 0.1304 0.1287 0.1293 0.1298 0.1308 0.1304 

[TRAIN] Epoch[6](398/1500); Loss: 0.099429; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1287 0.0982 0.1664 0.1627 0.1482 0.1204 0.0900 0.0757 0.0764 0.0765 0.0740 0.0731 0.0725 0.0757 0.0762 0.0761 

[TRAIN] Epoch[6](399/1500); Loss: 0.132926; Backpropagation: 0.0919 sec; Batch: 0.4252 sec
0.1814 0.1444 0.1599 0.1822 0.1733 0.1561 0.1329 0.1160 0.1121 0.1118 0.1118 0.1087 0.1078 0.1079 0.1091 0.1113 

[TRAIN] Epoch[6](400/1500); Loss: 0.167308; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1988 0.2216 0.2150 0.1981 0.1803 0.1665 0.1584 0.1547 0.1515 0.1489 0.1474 0.1470 0.1466 0.1467 0.1474 0.1482 

[TRAIN] Epoch[6](401/1500); Loss: 0.142040; Backpropagation: 0.0917 sec; Batch: 0.4623 sec
0.1909 0.1849 0.1778 0.1648 0.1531 0.1417 0.1348 0.1316 0.1273 0.1248 0.1237 0.1228 0.1232 0.1239 0.1240 0.1235 

[TRAIN] Epoch[6](402/1500); Loss: 0.149827; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1813 0.1922 0.2042 0.1884 0.1702 0.1496 0.1347 0.1336 0.1320 0.1326 0.1299 0.1282 0.1285 0.1309 0.1310 0.1299 

[TRAIN] Epoch[6](403/1500); Loss: 0.147743; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2487 0.2430 0.2247 0.2007 0.1803 0.1568 0.1365 0.1216 0.1121 0.1065 0.1060 0.1060 0.1051 0.1048 0.1052 0.1060 

[TRAIN] Epoch[6](404/1500); Loss: 0.142957; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.2026 0.2262 0.2224 0.2116 0.1883 0.1616 0.1367 0.1200 0.1117 0.1039 0.0994 0.0990 0.0999 0.1009 0.1011 0.1020 

[TRAIN] Epoch[6](405/1500); Loss: 0.095610; Backpropagation: 0.0920 sec; Batch: 0.4227 sec
0.1329 0.0918 0.1406 0.1551 0.1441 0.1217 0.0947 0.0774 0.0712 0.0714 0.0705 0.0686 0.0699 0.0717 0.0746 0.0734 

[TRAIN] Epoch[6](406/1500); Loss: 0.085780; Backpropagation: 0.0916 sec; Batch: 0.4305 sec
0.0652 0.1353 0.1640 0.1481 0.1249 0.0954 0.0705 0.0611 0.0618 0.0636 0.0622 0.0618 0.0626 0.0637 0.0656 0.0667 

[TRAIN] Epoch[6](407/1500); Loss: 0.162938; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1714 0.1799 0.1924 0.1873 0.1786 0.1682 0.1590 0.1541 0.1514 0.1505 0.1504 0.1504 0.1513 0.1526 0.1539 0.1557 

[TRAIN] Epoch[6](408/1500); Loss: 0.155015; Backpropagation: 0.0917 sec; Batch: 0.4299 sec
0.1434 0.1575 0.2318 0.2221 0.2093 0.1850 0.1589 0.1433 0.1333 0.1302 0.1270 0.1259 0.1264 0.1275 0.1282 0.1303 

[TRAIN] Epoch[6](409/1500); Loss: 0.152577; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.1735 0.1698 0.2007 0.1944 0.1800 0.1595 0.1439 0.1412 0.1399 0.1373 0.1347 0.1336 0.1336 0.1335 0.1328 0.1328 

[TRAIN] Epoch[6](410/1500); Loss: 0.143713; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1414 0.1808 0.2231 0.2136 0.1977 0.1750 0.1516 0.1341 0.1206 0.1125 0.1091 0.1072 0.1065 0.1071 0.1086 0.1103 

[TRAIN] Epoch[6](411/1500); Loss: 0.143659; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2324 0.2043 0.1997 0.1830 0.1687 0.1528 0.1396 0.1292 0.1199 0.1122 0.1088 0.1093 0.1098 0.1100 0.1094 0.1095 

[TRAIN] Epoch[6](412/1500); Loss: 0.152032; Backpropagation: 0.0919 sec; Batch: 0.4248 sec
0.4594 0.3379 0.2873 0.2403 0.1996 0.1468 0.0965 0.0619 0.0788 0.0761 0.0766 0.0723 0.0704 0.0774 0.0768 0.0744 

[TRAIN] Epoch[6](413/1500); Loss: 0.160027; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1781 0.1961 0.1932 0.1819 0.1688 0.1579 0.1520 0.1496 0.1487 0.1481 0.1472 0.1467 0.1469 0.1481 0.1484 0.1488 

[TRAIN] Epoch[6](414/1500); Loss: 0.107230; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1435 0.1744 0.1690 0.1502 0.1300 0.1106 0.0953 0.0846 0.0797 0.0790 0.0806 0.0816 0.0821 0.0835 0.0850 0.0865 

[TRAIN] Epoch[6](415/1500); Loss: 0.165600; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.1771 0.2246 0.2345 0.2198 0.1986 0.1760 0.1575 0.1492 0.1456 0.1407 0.1388 0.1380 0.1376 0.1372 0.1371 0.1375 

[TRAIN] Epoch[6](416/1500); Loss: 0.157530; Backpropagation: 0.0916 sec; Batch: 0.4347 sec
0.2068 0.1987 0.2055 0.1954 0.1828 0.1669 0.1524 0.1439 0.1385 0.1354 0.1336 0.1322 0.1318 0.1317 0.1321 0.1328 

[TRAIN] Epoch[6](417/1500); Loss: 0.155413; Backpropagation: 0.0920 sec; Batch: 0.4274 sec
0.1668 0.1875 0.2606 0.2449 0.2268 0.1989 0.1656 0.1382 0.1175 0.1099 0.1106 0.1120 0.1111 0.1106 0.1113 0.1143 

[TRAIN] Epoch[6](418/1500); Loss: 0.126912; Backpropagation: 0.0918 sec; Batch: 0.4260 sec
0.1605 0.1938 0.2086 0.1961 0.1780 0.1565 0.1356 0.1180 0.1036 0.0921 0.0842 0.0816 0.0808 0.0801 0.0803 0.0808 

[TRAIN] Epoch[6](419/1500); Loss: 0.120262; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1806 0.2482 0.2456 0.2293 0.2006 0.1667 0.1321 0.1002 0.0714 0.0489 0.0415 0.0500 0.0532 0.0501 0.0513 0.0545 

[TRAIN] Epoch[6](420/1500); Loss: 0.100968; Backpropagation: 0.0917 sec; Batch: 0.4464 sec
0.1204 0.0799 0.1864 0.1738 0.1578 0.1271 0.0919 0.0765 0.0786 0.0800 0.0739 0.0687 0.0694 0.0738 0.0793 0.0780 

[TRAIN] Epoch[6](421/1500); Loss: 0.121034; Backpropagation: 0.0920 sec; Batch: 0.4278 sec
0.1785 0.1920 0.1865 0.1656 0.1453 0.1272 0.1124 0.1003 0.0936 0.0902 0.0910 0.0916 0.0902 0.0895 0.0905 0.0922 

[TRAIN] Epoch[6](422/1500); Loss: 0.052549; Backpropagation: 0.0920 sec; Batch: 0.4269 sec
0.1484 0.0627 0.0538 0.0470 0.0457 0.0453 0.0447 0.0413 0.0406 0.0425 0.0432 0.0439 0.0429 0.0450 0.0467 0.0471 

[TRAIN] Epoch[6](423/1500); Loss: 0.124347; Backpropagation: 0.0919 sec; Batch: 0.4307 sec
0.1015 0.1364 0.2174 0.2054 0.1901 0.1649 0.1368 0.1145 0.0967 0.0881 0.0878 0.0883 0.0879 0.0894 0.0914 0.0931 

[TRAIN] Epoch[6](424/1500); Loss: 0.167907; Backpropagation: 0.0919 sec; Batch: 0.4274 sec
0.1529 0.1840 0.2382 0.2295 0.2142 0.1921 0.1699 0.1546 0.1443 0.1401 0.1403 0.1416 0.1430 0.1455 0.1475 0.1487 

[TRAIN] Epoch[6](425/1500); Loss: 0.135887; Backpropagation: 0.0918 sec; Batch: 0.4305 sec
0.1879 0.1667 0.1809 0.1760 0.1599 0.1411 0.1227 0.1137 0.1130 0.1175 0.1139 0.1122 0.1139 0.1178 0.1196 0.1173 

[TRAIN] Epoch[6](426/1500); Loss: 0.120415; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1810 0.1434 0.1317 0.1236 0.1178 0.1140 0.1121 0.1099 0.1099 0.1094 0.1103 0.1110 0.1116 0.1124 0.1135 0.1149 

[TRAIN] Epoch[6](427/1500); Loss: 0.147837; Backpropagation: 0.0917 sec; Batch: 0.4589 sec
0.2331 0.2118 0.2022 0.1841 0.1686 0.1532 0.1414 0.1297 0.1205 0.1155 0.1159 0.1176 0.1176 0.1166 0.1178 0.1198 

[TRAIN] Epoch[6](428/1500); Loss: 0.162456; Backpropagation: 0.0920 sec; Batch: 0.4554 sec
0.2208 0.2210 0.2425 0.2247 0.2047 0.1803 0.1575 0.1415 0.1333 0.1297 0.1278 0.1248 0.1229 0.1222 0.1223 0.1236 

[TRAIN] Epoch[6](429/1500); Loss: 0.146067; Backpropagation: 0.0918 sec; Batch: 0.4461 sec
0.1470 0.2004 0.2515 0.2351 0.2136 0.1847 0.1533 0.1266 0.1076 0.1006 0.1002 0.1016 0.1012 0.1035 0.1040 0.1061 

[TRAIN] Epoch[6](430/1500); Loss: 0.090859; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.1768 0.1291 0.1168 0.1036 0.0947 0.0859 0.0798 0.0766 0.0746 0.0737 0.0730 0.0730 0.0730 0.0733 0.0745 0.0753 

[TRAIN] Epoch[6](431/1500); Loss: 0.154161; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1952 0.2284 0.2678 0.2450 0.2175 0.1820 0.1460 0.1218 0.1138 0.1145 0.1105 0.1063 0.1034 0.1031 0.1044 0.1070 

[TRAIN] Epoch[6](432/1500); Loss: 0.109557; Backpropagation: 0.0919 sec; Batch: 0.4258 sec
0.1547 0.1507 0.1512 0.1400 0.1263 0.1121 0.1006 0.0940 0.0910 0.0893 0.0882 0.0882 0.0899 0.0916 0.0918 0.0932 

[TRAIN] Epoch[6](433/1500); Loss: 0.158514; Backpropagation: 0.0918 sec; Batch: 0.4436 sec
0.2188 0.2034 0.1973 0.1846 0.1729 0.1602 0.1499 0.1433 0.1401 0.1385 0.1378 0.1370 0.1371 0.1378 0.1389 0.1385 

[TRAIN] Epoch[6](434/1500); Loss: 0.148043; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1802 0.1786 0.1979 0.1856 0.1714 0.1553 0.1416 0.1341 0.1309 0.1291 0.1271 0.1268 0.1271 0.1269 0.1274 0.1287 

[TRAIN] Epoch[6](435/1500); Loss: 0.157654; Backpropagation: 0.0921 sec; Batch: 0.4260 sec
0.1784 0.1875 0.2172 0.2018 0.1858 0.1665 0.1494 0.1411 0.1384 0.1386 0.1372 0.1368 0.1360 0.1355 0.1357 0.1366 

[TRAIN] Epoch[6](436/1500); Loss: 0.194946; Backpropagation: 0.0918 sec; Batch: 0.4256 sec
0.2318 0.2697 0.2953 0.2801 0.2611 0.2363 0.2099 0.1885 0.1706 0.1557 0.1450 0.1390 0.1363 0.1341 0.1333 0.1324 

[TRAIN] Epoch[6](437/1500); Loss: 0.110146; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1345 0.1230 0.1359 0.1281 0.1203 0.1112 0.1037 0.0998 0.0986 0.0975 0.0980 0.0995 0.0999 0.1028 0.1039 0.1057 

[TRAIN] Epoch[6](438/1500); Loss: 0.164957; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.2523 0.2156 0.1979 0.1855 0.1754 0.1657 0.1566 0.1519 0.1478 0.1442 0.1409 0.1411 0.1417 0.1410 0.1401 0.1415 

[TRAIN] Epoch[6](439/1500); Loss: 0.145270; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1773 0.1760 0.1775 0.1710 0.1582 0.1450 0.1369 0.1346 0.1328 0.1317 0.1306 0.1303 0.1305 0.1304 0.1304 0.1312 

[TRAIN] Epoch[6](440/1500); Loss: 0.113985; Backpropagation: 0.0917 sec; Batch: 0.4264 sec
0.1501 0.1369 0.1681 0.1596 0.1430 0.1199 0.1021 0.0957 0.0938 0.0912 0.0919 0.0929 0.0953 0.0935 0.0944 0.0954 

[TRAIN] Epoch[6](441/1500); Loss: 0.119902; Backpropagation: 0.0920 sec; Batch: 0.4264 sec
0.1698 0.1489 0.1386 0.1269 0.1186 0.1133 0.1100 0.1086 0.1086 0.1092 0.1090 0.1096 0.1106 0.1114 0.1120 0.1135 

[TRAIN] Epoch[6](442/1500); Loss: 0.121421; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1472 0.1434 0.1872 0.1812 0.1655 0.1423 0.1173 0.1012 0.0946 0.0945 0.0950 0.0936 0.0933 0.0942 0.0967 0.0955 

[TRAIN] Epoch[6](443/1500); Loss: 0.092822; Backpropagation: 0.0918 sec; Batch: 0.4265 sec
0.1415 0.1692 0.1617 0.1415 0.1165 0.0914 0.0731 0.0644 0.0666 0.0670 0.0648 0.0641 0.0651 0.0651 0.0664 0.0668 

[TRAIN] Epoch[6](444/1500); Loss: 0.180240; Backpropagation: 0.1047 sec; Batch: 0.4585 sec
0.1886 0.2213 0.2228 0.2067 0.1937 0.1829 0.1735 0.1672 0.1652 0.1672 0.1664 0.1657 0.1662 0.1655 0.1649 0.1661 

[TRAIN] Epoch[6](445/1500); Loss: 0.155274; Backpropagation: 0.0922 sec; Batch: 0.4271 sec
0.1850 0.2299 0.2495 0.2269 0.2015 0.1744 0.1510 0.1343 0.1247 0.1199 0.1176 0.1158 0.1140 0.1129 0.1130 0.1139 

[TRAIN] Epoch[6](446/1500); Loss: 0.159727; Backpropagation: 0.0922 sec; Batch: 0.4267 sec
0.1802 0.1875 0.1990 0.1866 0.1728 0.1595 0.1513 0.1506 0.1472 0.1446 0.1447 0.1448 0.1446 0.1458 0.1480 0.1486 

[TRAIN] Epoch[6](447/1500); Loss: 0.170215; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2494 0.2445 0.2439 0.2252 0.2081 0.1895 0.1707 0.1540 0.1422 0.1343 0.1281 0.1255 0.1273 0.1265 0.1272 0.1271 

[TRAIN] Epoch[6](448/1500); Loss: 0.150077; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1876 0.1982 0.1906 0.1753 0.1608 0.1498 0.1440 0.1424 0.1381 0.1342 0.1316 0.1300 0.1300 0.1296 0.1297 0.1294 

[TRAIN] Epoch[6](449/1500); Loss: 0.149228; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1575 0.2006 0.2335 0.2164 0.1959 0.1694 0.1451 0.1295 0.1228 0.1186 0.1171 0.1155 0.1158 0.1170 0.1160 0.1170 

[TRAIN] Epoch[6](450/1500); Loss: 0.057721; Backpropagation: 0.0917 sec; Batch: 0.4252 sec
0.1079 0.0746 0.0712 0.0601 0.0563 0.0533 0.0504 0.0497 0.0494 0.0496 0.0487 0.0489 0.0504 0.0511 0.0502 0.0517 

[TRAIN] Epoch[6](451/1500); Loss: 0.096190; Backpropagation: 0.0918 sec; Batch: 0.4588 sec
0.0799 0.1415 0.1716 0.1545 0.1323 0.1038 0.0801 0.0738 0.0752 0.0744 0.0741 0.0743 0.0757 0.0757 0.0754 0.0766 

[TRAIN] Epoch[6](452/1500); Loss: 0.121986; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1668 0.1499 0.1431 0.1302 0.1217 0.1169 0.1141 0.1141 0.1127 0.1124 0.1116 0.1120 0.1112 0.1110 0.1116 0.1125 

[TRAIN] Epoch[6](453/1500); Loss: 0.136150; Backpropagation: 0.0917 sec; Batch: 0.4250 sec
0.2438 0.2192 0.2069 0.1826 0.1602 0.1360 0.1164 0.1090 0.1078 0.1054 0.1017 0.0990 0.0979 0.0982 0.0973 0.0969 

[TRAIN] Epoch[6](454/1500); Loss: 0.106233; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1345 0.1655 0.1637 0.1471 0.1262 0.1074 0.0944 0.0889 0.0863 0.0848 0.0834 0.0827 0.0832 0.0832 0.0834 0.0850 

[TRAIN] Epoch[6](455/1500); Loss: 0.089499; Backpropagation: 0.0919 sec; Batch: 0.4431 sec
0.1063 0.0963 0.1128 0.1017 0.0927 0.0823 0.0773 0.0761 0.0812 0.0819 0.0816 0.0838 0.0869 0.0879 0.0899 0.0933 

[TRAIN] Epoch[6](456/1500); Loss: 0.097598; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.2065 0.1221 0.0983 0.1379 0.1310 0.1153 0.0897 0.0701 0.0656 0.0716 0.0734 0.0703 0.0709 0.0744 0.0802 0.0844 

[TRAIN] Epoch[6](457/1500); Loss: 0.158133; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.2114 0.2194 0.2110 0.1924 0.1737 0.1573 0.1452 0.1391 0.1371 0.1355 0.1338 0.1342 0.1342 0.1349 0.1350 0.1359 

[TRAIN] Epoch[6](458/1500); Loss: 0.074657; Backpropagation: 0.0918 sec; Batch: 0.4269 sec
0.0998 0.0721 0.1163 0.1114 0.1009 0.0813 0.0651 0.0620 0.0609 0.0599 0.0583 0.0592 0.0600 0.0613 0.0622 0.0639 

[TRAIN] Epoch[6](459/1500); Loss: 0.096081; Backpropagation: 0.0917 sec; Batch: 0.4257 sec
0.1336 0.1556 0.1465 0.1323 0.1160 0.0988 0.0872 0.0797 0.0755 0.0745 0.0740 0.0729 0.0722 0.0722 0.0732 0.0731 

[TRAIN] Epoch[6](460/1500); Loss: 0.094111; Backpropagation: 0.0935 sec; Batch: 0.4608 sec
0.2996 0.2071 0.1752 0.1489 0.1242 0.0930 0.0656 0.0478 0.0426 0.0430 0.0437 0.0435 0.0416 0.0425 0.0438 0.0436 

[TRAIN] Epoch[6](461/1500); Loss: 0.099804; Backpropagation: 0.0918 sec; Batch: 0.4263 sec
0.1138 0.1119 0.1698 0.1655 0.1495 0.1235 0.0961 0.0812 0.0773 0.0743 0.0723 0.0721 0.0718 0.0710 0.0721 0.0745 

[TRAIN] Epoch[6](462/1500); Loss: 0.067630; Backpropagation: 0.0917 sec; Batch: 0.4340 sec
0.2230 0.1394 0.1148 0.0934 0.0759 0.0569 0.0437 0.0381 0.0364 0.0385 0.0365 0.0362 0.0363 0.0378 0.0372 0.0380 

[TRAIN] Epoch[6](463/1500); Loss: 0.097529; Backpropagation: 0.0948 sec; Batch: 0.4285 sec
0.1548 0.1589 0.1508 0.1313 0.1132 0.0954 0.0828 0.0775 0.0749 0.0747 0.0745 0.0737 0.0740 0.0744 0.0746 0.0750 

[TRAIN] Epoch[6](464/1500); Loss: 0.123285; Backpropagation: 0.0920 sec; Batch: 0.4607 sec
0.1606 0.1579 0.1516 0.1426 0.1314 0.1197 0.1125 0.1104 0.1084 0.1079 0.1092 0.1100 0.1106 0.1118 0.1130 0.1149 

[TRAIN] Epoch[6](465/1500); Loss: 0.069926; Backpropagation: 0.0917 sec; Batch: 0.4303 sec
0.0864 0.0961 0.1205 0.1047 0.0921 0.0760 0.0616 0.0584 0.0557 0.0537 0.0523 0.0516 0.0527 0.0525 0.0521 0.0524 

[TRAIN] Epoch[6](466/1500); Loss: 0.136328; Backpropagation: 0.0917 sec; Batch: 0.4310 sec
0.1469 0.1499 0.1894 0.1780 0.1645 0.1445 0.1264 0.1182 0.1156 0.1169 0.1207 0.1213 0.1198 0.1218 0.1231 0.1242 

[TRAIN] Epoch[6](467/1500); Loss: 0.117217; Backpropagation: 0.0999 sec; Batch: 0.4323 sec
0.2483 0.1945 0.1736 0.1539 0.1369 0.1192 0.1040 0.0915 0.0846 0.0820 0.0814 0.0811 0.0804 0.0797 0.0812 0.0832 

[TRAIN] Epoch[6](468/1500); Loss: 0.086603; Backpropagation: 0.0925 sec; Batch: 0.4235 sec
0.0902 0.1618 0.1648 0.1456 0.1167 0.0852 0.0650 0.0649 0.0638 0.0599 0.0592 0.0616 0.0615 0.0607 0.0608 0.0640 

[TRAIN] Epoch[6](469/1500); Loss: 0.060470; Backpropagation: 0.0919 sec; Batch: 0.4247 sec
0.0628 0.0698 0.0636 0.0612 0.0588 0.0539 0.0519 0.0546 0.0556 0.0554 0.0578 0.0601 0.0639 0.0648 0.0655 0.0677 

[TRAIN] Epoch[6](470/1500); Loss: 0.049787; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0669 0.0807 0.0692 0.0508 0.0448 0.0430 0.0449 0.0438 0.0419 0.0428 0.0437 0.0434 0.0439 0.0446 0.0454 0.0467 

[TRAIN] Epoch[6](471/1500); Loss: 0.107749; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.0953 0.1591 0.1931 0.1772 0.1562 0.1296 0.1050 0.0902 0.0810 0.0782 0.0757 0.0741 0.0759 0.0770 0.0778 0.0787 

[TRAIN] Epoch[6](472/1500); Loss: 0.162347; Backpropagation: 0.0920 sec; Batch: 0.4229 sec
0.2437 0.2390 0.2270 0.2017 0.1824 0.1699 0.1580 0.1465 0.1377 0.1310 0.1288 0.1277 0.1268 0.1259 0.1257 0.1257 

[TRAIN] Epoch[6](473/1500); Loss: 0.136303; Backpropagation: 0.0916 sec; Batch: 0.4225 sec
0.1946 0.1557 0.1635 0.1570 0.1450 0.1335 0.1264 0.1260 0.1237 0.1220 0.1211 0.1220 0.1220 0.1220 0.1222 0.1241 

[TRAIN] Epoch[6](474/1500); Loss: 0.102427; Backpropagation: 0.0916 sec; Batch: 0.4305 sec
0.1219 0.1243 0.1477 0.1404 0.1279 0.1102 0.0967 0.0910 0.0877 0.0860 0.0842 0.0845 0.0839 0.0838 0.0839 0.0846 

[TRAIN] Epoch[6](475/1500); Loss: 0.120417; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1739 0.1491 0.1663 0.1634 0.1469 0.1252 0.1070 0.1001 0.0982 0.0973 0.0973 0.0987 0.0997 0.0998 0.1011 0.1027 

[TRAIN] Epoch[6](476/1500); Loss: 0.121254; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2102 0.1585 0.1459 0.1346 0.1270 0.1189 0.1119 0.1050 0.1034 0.1032 0.1037 0.1024 0.1025 0.1030 0.1055 0.1044 

[TRAIN] Epoch[6](477/1500); Loss: 0.150710; Backpropagation: 0.0916 sec; Batch: 0.4250 sec
0.1827 0.1975 0.2139 0.2037 0.1858 0.1658 0.1473 0.1345 0.1273 0.1237 0.1217 0.1213 0.1210 0.1209 0.1217 0.1227 

[TRAIN] Epoch[6](478/1500); Loss: 0.109163; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1212 0.1269 0.1308 0.1206 0.1117 0.1053 0.1044 0.1027 0.1014 0.1021 0.1018 0.1027 0.1026 0.1031 0.1041 0.1052 

[TRAIN] Epoch[6](479/1500); Loss: 0.122591; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1584 0.0568 0.2164 0.2060 0.1894 0.1598 0.1226 0.0995 0.0816 0.0773 0.0838 0.1019 0.0984 0.0994 0.1032 0.1068 

[TRAIN] Epoch[6](480/1500); Loss: 0.180477; Backpropagation: 0.0918 sec; Batch: 0.4269 sec
0.3414 0.3003 0.2759 0.2511 0.2254 0.1997 0.1714 0.1419 0.1247 0.1206 0.1249 0.1233 0.1231 0.1221 0.1204 0.1215 

[TRAIN] Epoch[6](481/1500); Loss: 0.098392; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1326 0.1420 0.1414 0.1260 0.1123 0.1003 0.0915 0.0852 0.0821 0.0803 0.0798 0.0799 0.0798 0.0796 0.0806 0.0808 

[TRAIN] Epoch[6](482/1500); Loss: 0.093925; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1124 0.0782 0.1728 0.1710 0.1559 0.1281 0.0957 0.0766 0.0659 0.0624 0.0626 0.0608 0.0633 0.0637 0.0652 0.0683 

[TRAIN] Epoch[6](483/1500); Loss: 0.121969; Backpropagation: 0.0920 sec; Batch: 0.4252 sec
0.1588 0.0575 0.2156 0.2050 0.1883 0.1590 0.1229 0.1006 0.0827 0.0776 0.0831 0.0925 0.1006 0.0996 0.1026 0.1051 

[TRAIN] Epoch[6](484/1500); Loss: 0.153077; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1668 0.1706 0.1920 0.1857 0.1734 0.1571 0.1470 0.1442 0.1424 0.1401 0.1381 0.1380 0.1380 0.1385 0.1382 0.1391 

[TRAIN] Epoch[6](485/1500); Loss: 0.112610; Backpropagation: 0.0916 sec; Batch: 0.4575 sec
0.1715 0.1325 0.1342 0.1281 0.1201 0.1097 0.1022 0.1014 0.1008 0.0999 0.0993 0.0996 0.0994 0.0996 0.1010 0.1022 

[TRAIN] Epoch[6](486/1500); Loss: 0.091591; Backpropagation: 0.0915 sec; Batch: 0.4268 sec
0.1319 0.1564 0.1436 0.1190 0.0991 0.0854 0.0784 0.0752 0.0735 0.0722 0.0713 0.0714 0.0718 0.0721 0.0717 0.0725 

[TRAIN] Epoch[6](487/1500); Loss: 0.124013; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1542 0.1372 0.2065 0.1930 0.1750 0.1468 0.1194 0.1086 0.1033 0.0987 0.0927 0.0880 0.0871 0.0896 0.0925 0.0916 

[TRAIN] Epoch[6](488/1500); Loss: 0.070204; Backpropagation: 0.0915 sec; Batch: 0.4578 sec
0.1050 0.0988 0.1239 0.1073 0.0934 0.0769 0.0631 0.0578 0.0540 0.0509 0.0486 0.0495 0.0485 0.0474 0.0480 0.0502 

[TRAIN] Epoch[6](489/1500); Loss: 0.179501; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.2555 0.2313 0.2233 0.2136 0.2040 0.1939 0.1833 0.1741 0.1667 0.1605 0.1542 0.1481 0.1432 0.1405 0.1397 0.1401 

[TRAIN] Epoch[6](490/1500); Loss: 0.060820; Backpropagation: 0.0916 sec; Batch: 0.4256 sec
0.0737 0.0724 0.0926 0.0853 0.0748 0.0615 0.0548 0.0544 0.0503 0.0507 0.0510 0.0495 0.0497 0.0506 0.0511 0.0508 

[TRAIN] Epoch[6](491/1500); Loss: 0.122556; Backpropagation: 0.0917 sec; Batch: 0.4225 sec
0.1492 0.1412 0.1870 0.1741 0.1577 0.1318 0.1100 0.1090 0.1055 0.1020 0.1000 0.1009 0.0988 0.0972 0.0979 0.0985 

[TRAIN] Epoch[6](492/1500); Loss: 0.116819; Backpropagation: 0.0989 sec; Batch: 0.4322 sec
0.2253 0.1709 0.1382 0.1440 0.1331 0.1169 0.1029 0.0975 0.0942 0.0906 0.0894 0.0901 0.0928 0.0941 0.0941 0.0950 

[TRAIN] Epoch[6](493/1500); Loss: 0.162958; Backpropagation: 0.0921 sec; Batch: 0.4266 sec
0.2260 0.2395 0.2329 0.2158 0.1969 0.1805 0.1648 0.1505 0.1382 0.1289 0.1231 0.1209 0.1222 0.1227 0.1217 0.1225 

[TRAIN] Epoch[6](494/1500); Loss: 0.091089; Backpropagation: 0.0915 sec; Batch: 0.4494 sec
0.1473 0.1540 0.1437 0.1257 0.1085 0.0933 0.0814 0.0738 0.0689 0.0668 0.0653 0.0653 0.0652 0.0652 0.0662 0.0667 

[TRAIN] Epoch[6](495/1500); Loss: 0.159682; Backpropagation: 0.0919 sec; Batch: 0.4277 sec
0.2116 0.2222 0.2185 0.2021 0.1850 0.1689 0.1550 0.1448 0.1379 0.1340 0.1318 0.1298 0.1292 0.1287 0.1280 0.1274 

[TRAIN] Epoch[6](496/1500); Loss: 0.178448; Backpropagation: 0.0917 sec; Batch: 0.4547 sec
0.1860 0.2156 0.2378 0.2261 0.2102 0.1947 0.1809 0.1703 0.1627 0.1580 0.1547 0.1535 0.1530 0.1516 0.1502 0.1498 

[TRAIN] Epoch[6](497/1500); Loss: 0.060285; Backpropagation: 0.1002 sec; Batch: 0.4333 sec
0.0714 0.0771 0.0892 0.0807 0.0709 0.0609 0.0543 0.0536 0.0513 0.0508 0.0508 0.0503 0.0501 0.0505 0.0510 0.0516 

[TRAIN] Epoch[6](498/1500); Loss: 0.144717; Backpropagation: 0.0930 sec; Batch: 0.4245 sec
0.1783 0.1789 0.1854 0.1719 0.1579 0.1441 0.1368 0.1355 0.1320 0.1298 0.1292 0.1286 0.1275 0.1264 0.1263 0.1269 

[TRAIN] Epoch[6](499/1500); Loss: 0.112777; Backpropagation: 0.0917 sec; Batch: 0.4314 sec
0.1898 0.1414 0.1287 0.1258 0.1185 0.1088 0.0996 0.0971 0.0987 0.0984 0.0973 0.0976 0.0992 0.1006 0.1012 0.1018 

[TRAIN] Epoch[6](500/1500); Loss: 0.155904; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1939 0.1978 0.1883 0.1732 0.1623 0.1561 0.1521 0.1488 0.1457 0.1430 0.1410 0.1398 0.1389 0.1383 0.1377 0.1375 

[TRAIN] Epoch[6](501/1500); Loss: 0.182384; Backpropagation: 0.0917 sec; Batch: 0.4294 sec
0.2341 0.2210 0.2372 0.2302 0.2175 0.1999 0.1828 0.1729 0.1658 0.1607 0.1566 0.1524 0.1489 0.1460 0.1459 0.1461 

[TRAIN] Epoch[6](502/1500); Loss: 0.131522; Backpropagation: 0.0999 sec; Batch: 0.4528 sec
0.2388 0.2143 0.2018 0.1909 0.1703 0.1436 0.1171 0.1022 0.0948 0.0910 0.0912 0.0915 0.0893 0.0900 0.0886 0.0889 

[TRAIN] Epoch[6](503/1500); Loss: 0.196072; Backpropagation: 0.0920 sec; Batch: 0.4253 sec
0.3804 0.2963 0.2573 0.2511 0.2373 0.2123 0.1767 0.1491 0.1454 0.1450 0.1482 0.1432 0.1494 0.1487 0.1486 0.1481 

[TRAIN] Epoch[6](504/1500); Loss: 0.151463; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1846 0.1915 0.2209 0.2105 0.1939 0.1729 0.1527 0.1398 0.1307 0.1233 0.1202 0.1178 0.1167 0.1157 0.1160 0.1161 

[TRAIN] Epoch[6](505/1500); Loss: 0.177479; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2251 0.2064 0.2014 0.1973 0.1907 0.1822 0.1748 0.1699 0.1670 0.1641 0.1616 0.1598 0.1597 0.1603 0.1599 0.1594 

[TRAIN] Epoch[6](506/1500); Loss: 0.101948; Backpropagation: 0.0918 sec; Batch: 0.4269 sec
0.1113 0.1131 0.1248 0.1184 0.1095 0.1004 0.0960 0.0953 0.0942 0.0940 0.0946 0.0951 0.0947 0.0957 0.0967 0.0975 

[TRAIN] Epoch[6](507/1500); Loss: 0.111661; Backpropagation: 0.0918 sec; Batch: 0.4296 sec
0.1845 0.1304 0.1189 0.1217 0.1163 0.1081 0.0997 0.0980 0.0988 0.1001 0.1000 0.1000 0.1011 0.1018 0.1032 0.1040 

[TRAIN] Epoch[6](508/1500); Loss: 0.163514; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2871 0.2588 0.2397 0.2352 0.2172 0.1945 0.1703 0.1540 0.1436 0.1324 0.1174 0.1032 0.0927 0.0886 0.0888 0.0929 

[TRAIN] Epoch[6](509/1500); Loss: 0.122550; Backpropagation: 0.0917 sec; Batch: 0.4266 sec
0.1658 0.1600 0.1646 0.1544 0.1412 0.1284 0.1191 0.1134 0.1076 0.1041 0.1024 0.1014 0.1003 0.0997 0.0993 0.0992 

[TRAIN] Epoch[6](510/1500); Loss: 0.135782; Backpropagation: 0.0916 sec; Batch: 0.4595 sec
0.1834 0.1615 0.1523 0.1472 0.1412 0.1348 0.1289 0.1257 0.1241 0.1235 0.1237 0.1238 0.1248 0.1253 0.1257 0.1266 

[TRAIN] Epoch[6](511/1500); Loss: 0.180915; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1623 0.1645 0.2635 0.2519 0.2371 0.2155 0.1963 0.1839 0.1692 0.1584 0.1524 0.1494 0.1488 0.1492 0.1460 0.1462 

[TRAIN] Epoch[6](512/1500); Loss: 0.140956; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.1899 0.1774 0.1694 0.1627 0.1522 0.1425 0.1358 0.1322 0.1297 0.1274 0.1255 0.1234 0.1231 0.1220 0.1214 0.1207 

[TRAIN] Epoch[6](513/1500); Loss: 0.093285; Backpropagation: 0.0919 sec; Batch: 0.4226 sec
0.1320 0.1498 0.1485 0.1337 0.1161 0.1004 0.0886 0.0810 0.0751 0.0704 0.0671 0.0656 0.0653 0.0662 0.0662 0.0664 

[TRAIN] Epoch[6](514/1500); Loss: 0.084108; Backpropagation: 0.0918 sec; Batch: 0.4261 sec
0.1565 0.1019 0.0896 0.0905 0.0864 0.0798 0.0748 0.0731 0.0727 0.0729 0.0729 0.0733 0.0743 0.0749 0.0755 0.0766 

[TRAIN] Epoch[6](515/1500); Loss: 0.149737; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1691 0.1954 0.2104 0.2006 0.1868 0.1720 0.1575 0.1464 0.1362 0.1279 0.1218 0.1178 0.1151 0.1133 0.1129 0.1124 

[TRAIN] Epoch[6](516/1500); Loss: 0.114515; Backpropagation: 0.0917 sec; Batch: 0.4261 sec
0.1540 0.1243 0.1495 0.1461 0.1350 0.1216 0.1124 0.1072 0.1037 0.1003 0.0979 0.0964 0.0955 0.0956 0.0961 0.0966 

[TRAIN] Epoch[6](517/1500); Loss: 0.068018; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.0911 0.0904 0.1071 0.1001 0.0896 0.0758 0.0647 0.0596 0.0566 0.0537 0.0512 0.0497 0.0496 0.0497 0.0496 0.0499 

[TRAIN] Epoch[6](518/1500); Loss: 0.152939; Backpropagation: 0.0983 sec; Batch: 0.4427 sec
0.2189 0.2110 0.2014 0.1909 0.1775 0.1623 0.1498 0.1402 0.1347 0.1296 0.1251 0.1221 0.1206 0.1208 0.1210 0.1211 

[TRAIN] Epoch[6](519/1500); Loss: 0.110708; Backpropagation: 0.0923 sec; Batch: 0.4257 sec
0.1053 0.1431 0.1655 0.1559 0.1406 0.1240 0.1109 0.1023 0.0959 0.0921 0.0895 0.0888 0.0884 0.0886 0.0893 0.0911 

[TRAIN] Epoch[6](520/1500); Loss: 0.090963; Backpropagation: 0.0917 sec; Batch: 0.4312 sec
0.2295 0.1467 0.1279 0.1449 0.1332 0.1121 0.0851 0.0684 0.0578 0.0491 0.0460 0.0505 0.0523 0.0511 0.0497 0.0511 

[TRAIN] Epoch[6](521/1500); Loss: 0.135796; Backpropagation: 0.0918 sec; Batch: 0.4272 sec
0.1597 0.1743 0.1769 0.1684 0.1571 0.1458 0.1371 0.1313 0.1261 0.1216 0.1179 0.1153 0.1130 0.1104 0.1091 0.1085 

[TRAIN] Epoch[6](522/1500); Loss: 0.162680; Backpropagation: 0.0917 sec; Batch: 0.4359 sec
0.2021 0.2138 0.2097 0.1957 0.1811 0.1690 0.1604 0.1531 0.1476 0.1428 0.1407 0.1398 0.1380 0.1363 0.1365 0.1363 

[TRAIN] Epoch[6](523/1500); Loss: 0.127009; Backpropagation: 0.0997 sec; Batch: 0.4347 sec
0.1858 0.1589 0.1512 0.1505 0.1421 0.1322 0.1222 0.1176 0.1139 0.1111 0.1087 0.1080 0.1073 0.1076 0.1074 0.1075 

[TRAIN] Epoch[6](524/1500); Loss: 0.154419; Backpropagation: 0.0925 sec; Batch: 0.4242 sec
0.1626 0.2083 0.2078 0.1942 0.1794 0.1659 0.1540 0.1431 0.1358 0.1325 0.1313 0.1301 0.1298 0.1309 0.1318 0.1333 

[TRAIN] Epoch[6](525/1500); Loss: 0.156582; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1972 0.1963 0.1884 0.1770 0.1671 0.1595 0.1536 0.1487 0.1447 0.1418 0.1402 0.1390 0.1378 0.1380 0.1380 0.1380 

[TRAIN] Epoch[6](526/1500); Loss: 0.072468; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.1089 0.1218 0.1296 0.1153 0.0977 0.0806 0.0664 0.0572 0.0513 0.0482 0.0464 0.0461 0.0469 0.0476 0.0474 0.0481 

[TRAIN] Epoch[6](527/1500); Loss: 0.168978; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2315 0.2132 0.2031 0.1964 0.1873 0.1777 0.1690 0.1625 0.1573 0.1529 0.1486 0.1454 0.1429 0.1404 0.1385 0.1369 

[TRAIN] Epoch[6](528/1500); Loss: 0.177755; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2881 0.2518 0.2235 0.2136 0.2018 0.1871 0.1683 0.1554 0.1496 0.1454 0.1419 0.1418 0.1419 0.1440 0.1447 0.1453 

[TRAIN] Epoch[6](529/1500); Loss: 0.065005; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1155 0.0900 0.0775 0.0763 0.0700 0.0624 0.0555 0.0534 0.0542 0.0554 0.0549 0.0533 0.0536 0.0550 0.0570 0.0563 

[TRAIN] Epoch[6](530/1500); Loss: 0.135829; Backpropagation: 0.0920 sec; Batch: 0.4256 sec
0.2370 0.1907 0.1699 0.1651 0.1565 0.1455 0.1347 0.1279 0.1231 0.1169 0.1103 0.1048 0.1014 0.0984 0.0962 0.0947 

[TRAIN] Epoch[6](531/1500); Loss: 0.102265; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.1378 0.1813 0.1783 0.1615 0.1388 0.1176 0.1018 0.0884 0.0772 0.0688 0.0646 0.0635 0.0635 0.0635 0.0638 0.0658 

[TRAIN] Epoch[6](532/1500); Loss: 0.101881; Backpropagation: 0.0918 sec; Batch: 0.4265 sec
0.1709 0.1739 0.1665 0.1529 0.1332 0.1147 0.0986 0.0867 0.0775 0.0701 0.0660 0.0646 0.0653 0.0644 0.0631 0.0619 

[TRAIN] Epoch[6](533/1500); Loss: 0.164031; Backpropagation: 0.0921 sec; Batch: 0.4278 sec
0.1993 0.2056 0.1998 0.1877 0.1755 0.1665 0.1598 0.1550 0.1516 0.1491 0.1478 0.1463 0.1455 0.1453 0.1450 0.1450 

[TRAIN] Epoch[6](534/1500); Loss: 0.076548; Backpropagation: 0.0918 sec; Batch: 0.4298 sec
0.1063 0.0989 0.1242 0.1160 0.1040 0.0868 0.0736 0.0661 0.0605 0.0574 0.0561 0.0548 0.0547 0.0545 0.0550 0.0557 

[TRAIN] Epoch[6](535/1500); Loss: 0.081921; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1707 0.1098 0.1004 0.1092 0.1011 0.0879 0.0742 0.0670 0.0652 0.0620 0.0602 0.0604 0.0607 0.0601 0.0605 0.0612 

[TRAIN] Epoch[6](536/1500); Loss: 0.110609; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1648 0.1399 0.1334 0.1300 0.1215 0.1146 0.1080 0.1029 0.0996 0.0974 0.0954 0.0932 0.0927 0.0922 0.0919 0.0923 

[TRAIN] Epoch[6](537/1500); Loss: 0.098529; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.1361 0.1609 0.1523 0.1329 0.1145 0.1008 0.0911 0.0836 0.0785 0.0762 0.0748 0.0743 0.0741 0.0745 0.0756 0.0761 

[TRAIN] Epoch[6](538/1500); Loss: 0.107175; Backpropagation: 0.0916 sec; Batch: 0.4257 sec
0.1852 0.1627 0.1533 0.1486 0.1337 0.1187 0.1020 0.0910 0.0850 0.0785 0.0733 0.0717 0.0747 0.0782 0.0790 0.0792 

[TRAIN] Epoch[6](539/1500); Loss: 0.061853; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0756 0.0782 0.0854 0.0767 0.0699 0.0619 0.0572 0.0564 0.0546 0.0537 0.0532 0.0530 0.0529 0.0531 0.0535 0.0542 

[TRAIN] Epoch[6](540/1500); Loss: 0.080189; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1826 0.1313 0.1194 0.1258 0.1144 0.0977 0.0794 0.0681 0.0607 0.0522 0.0444 0.0412 0.0409 0.0417 0.0414 0.0421 

[TRAIN] Epoch[6](541/1500); Loss: 0.094816; Backpropagation: 0.0918 sec; Batch: 0.4254 sec
0.1086 0.1305 0.1262 0.1120 0.0986 0.0910 0.0878 0.0854 0.0832 0.0832 0.0839 0.0845 0.0848 0.0851 0.0855 0.0867 

[TRAIN] Epoch[6](542/1500); Loss: 0.138523; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1556 0.1918 0.2212 0.2019 0.1818 0.1603 0.1413 0.1285 0.1168 0.1072 0.1030 0.1022 0.1032 0.1014 0.1003 0.0999 

[TRAIN] Epoch[6](543/1500); Loss: 0.158657; Backpropagation: 0.0917 sec; Batch: 0.4619 sec
0.2799 0.2094 0.1916 0.2077 0.1989 0.1817 0.1599 0.1463 0.1373 0.1277 0.1212 0.1188 0.1177 0.1151 0.1126 0.1126 

[TRAIN] Epoch[6](544/1500); Loss: 0.145968; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1704 0.2332 0.2355 0.2118 0.1863 0.1646 0.1492 0.1363 0.1244 0.1149 0.1078 0.1024 0.1002 0.0993 0.0992 0.1001 

[TRAIN] Epoch[6](545/1500); Loss: 0.103249; Backpropagation: 0.0917 sec; Batch: 0.4379 sec
0.1478 0.1367 0.1315 0.1267 0.1179 0.1086 0.0999 0.0945 0.0910 0.0885 0.0856 0.0843 0.0838 0.0841 0.0847 0.0861 

[TRAIN] Epoch[6](546/1500); Loss: 0.130685; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2606 0.1647 0.1435 0.1718 0.1651 0.1498 0.1289 0.1140 0.1084 0.1040 0.0997 0.0968 0.0951 0.0952 0.0961 0.0973 

[TRAIN] Epoch[6](547/1500); Loss: 0.139642; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1626 0.1680 0.1735 0.1623 0.1527 0.1442 0.1376 0.1337 0.1303 0.1284 0.1260 0.1244 0.1234 0.1227 0.1224 0.1222 

[TRAIN] Epoch[6](548/1500); Loss: 0.128029; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1604 0.1612 0.1800 0.1656 0.1490 0.1315 0.1191 0.1138 0.1104 0.1086 0.1075 0.1070 0.1081 0.1083 0.1083 0.1095 

[TRAIN] Epoch[6](549/1500); Loss: 0.122110; Backpropagation: 0.0921 sec; Batch: 0.4285 sec
0.1438 0.1784 0.1782 0.1644 0.1496 0.1377 0.1263 0.1165 0.1077 0.1008 0.0962 0.0933 0.0908 0.0895 0.0901 0.0905 

[TRAIN] Epoch[6](550/1500); Loss: 0.088446; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1369 0.1336 0.1358 0.1185 0.1029 0.0930 0.0844 0.0796 0.0728 0.0674 0.0660 0.0657 0.0648 0.0653 0.0639 0.0645 

[TRAIN] Epoch[6](551/1500); Loss: 0.111894; Backpropagation: 0.0919 sec; Batch: 0.4286 sec
0.1832 0.1371 0.1317 0.1403 0.1336 0.1218 0.1072 0.0993 0.0966 0.0936 0.0928 0.0925 0.0908 0.0903 0.0898 0.0899 

[TRAIN] Epoch[6](552/1500); Loss: 0.195565; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2147 0.2323 0.2400 0.2317 0.2195 0.2079 0.1977 0.1902 0.1844 0.1796 0.1763 0.1738 0.1720 0.1708 0.1694 0.1689 

[TRAIN] Epoch[6](553/1500); Loss: 0.228707; Backpropagation: 0.0984 sec; Batch: 0.4387 sec
0.3739 0.3097 0.2834 0.2887 0.2784 0.2580 0.2302 0.2076 0.1940 0.1827 0.1741 0.1746 0.1745 0.1759 0.1765 0.1771 

[TRAIN] Epoch[6](554/1500); Loss: 0.080349; Backpropagation: 0.0919 sec; Batch: 0.4588 sec
0.1235 0.0850 0.0851 0.0915 0.0883 0.0817 0.0758 0.0740 0.0735 0.0729 0.0722 0.0722 0.0726 0.0720 0.0721 0.0732 

[TRAIN] Epoch[6](555/1500); Loss: 0.148074; Backpropagation: 0.0923 sec; Batch: 0.4277 sec
0.2017 0.2103 0.2094 0.1979 0.1818 0.1653 0.1507 0.1393 0.1298 0.1217 0.1158 0.1115 0.1089 0.1084 0.1084 0.1084 

[TRAIN] Epoch[6](556/1500); Loss: 0.095271; Backpropagation: 0.0928 sec; Batch: 0.4242 sec
0.1029 0.0799 0.1291 0.1239 0.1150 0.1010 0.0888 0.0811 0.0758 0.0752 0.0779 0.0827 0.0896 0.0943 0.1001 0.1071 

[TRAIN] Epoch[6](557/1500); Loss: 0.087631; Backpropagation: 0.0917 sec; Batch: 0.4453 sec
0.1360 0.1521 0.1416 0.1151 0.0926 0.0800 0.0733 0.0693 0.0683 0.0671 0.0670 0.0672 0.0676 0.0679 0.0683 0.0688 

[TRAIN] Epoch[6](558/1500); Loss: 0.081226; Backpropagation: 0.0916 sec; Batch: 0.4249 sec
0.1068 0.1191 0.1201 0.1040 0.0897 0.0795 0.0751 0.0718 0.0687 0.0670 0.0663 0.0665 0.0654 0.0655 0.0665 0.0677 

[TRAIN] Epoch[6](559/1500); Loss: 0.234058; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2956 0.2819 0.2758 0.2729 0.2640 0.2520 0.2384 0.2274 0.2195 0.2130 0.2077 0.2032 0.2003 0.1986 0.1977 0.1971 

[TRAIN] Epoch[6](560/1500); Loss: 0.118338; Backpropagation: 0.0917 sec; Batch: 0.4262 sec
0.1599 0.1478 0.1493 0.1417 0.1332 0.1226 0.1150 0.1100 0.1065 0.1039 0.1026 0.1014 0.1009 0.0998 0.0998 0.0991 

[TRAIN] Epoch[6](561/1500); Loss: 0.104676; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1570 0.1396 0.1339 0.1263 0.1178 0.1065 0.0986 0.0947 0.0917 0.0889 0.0870 0.0872 0.0863 0.0860 0.0862 0.0870 

[TRAIN] Epoch[6](562/1500); Loss: 0.086149; Backpropagation: 0.0915 sec; Batch: 0.4663 sec
0.1116 0.1339 0.1274 0.1066 0.0899 0.0808 0.0774 0.0740 0.0716 0.0716 0.0723 0.0719 0.0714 0.0721 0.0730 0.0730 

[TRAIN] Epoch[6](563/1500); Loss: 0.067288; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.1158 0.1027 0.0931 0.0857 0.0748 0.0647 0.0584 0.0559 0.0540 0.0526 0.0525 0.0529 0.0522 0.0529 0.0536 0.0548 

[TRAIN] Epoch[6](564/1500); Loss: 0.089013; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1103 0.1325 0.1440 0.1285 0.1109 0.0935 0.0834 0.0795 0.0741 0.0703 0.0685 0.0675 0.0657 0.0649 0.0648 0.0658 

[TRAIN] Epoch[6](565/1500); Loss: 0.098697; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.2208 0.1437 0.1023 0.1129 0.1045 0.0911 0.0809 0.0784 0.0795 0.0780 0.0777 0.0787 0.0793 0.0817 0.0836 0.0861 

[TRAIN] Epoch[6](566/1500); Loss: 0.126667; Backpropagation: 0.0917 sec; Batch: 0.4270 sec
0.1640 0.1540 0.1955 0.1848 0.1709 0.1513 0.1304 0.1174 0.1066 0.0994 0.0951 0.0937 0.0913 0.0904 0.0912 0.0907 

[TRAIN] Epoch[6](567/1500); Loss: 0.187244; Backpropagation: 0.0987 sec; Batch: 0.4509 sec
0.2207 0.2223 0.2339 0.2274 0.2162 0.2036 0.1918 0.1836 0.1767 0.1705 0.1653 0.1609 0.1581 0.1559 0.1548 0.1544 

[TRAIN] Epoch[6](568/1500); Loss: 0.173399; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.1778 0.1942 0.2215 0.2117 0.1981 0.1828 0.1706 0.1631 0.1575 0.1556 0.1549 0.1552 0.1561 0.1565 0.1582 0.1608 

[TRAIN] Epoch[6](569/1500); Loss: 0.107741; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1678 0.1440 0.1337 0.1243 0.1142 0.1063 0.1000 0.0964 0.0936 0.0922 0.0920 0.0920 0.0915 0.0913 0.0919 0.0924 

[TRAIN] Epoch[6](570/1500); Loss: 0.142758; Backpropagation: 0.0917 sec; Batch: 0.4286 sec
0.1827 0.1786 0.1812 0.1668 0.1536 0.1422 0.1352 0.1330 0.1297 0.1273 0.1267 0.1260 0.1256 0.1250 0.1252 0.1253 

[TRAIN] Epoch[6](571/1500); Loss: 0.157763; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1838 0.1832 0.2134 0.2009 0.1899 0.1728 0.1579 0.1488 0.1411 0.1362 0.1332 0.1321 0.1316 0.1322 0.1335 0.1338 

[TRAIN] Epoch[6](572/1500); Loss: 0.116266; Backpropagation: 0.0918 sec; Batch: 0.4474 sec
0.1514 0.1538 0.1416 0.1257 0.1166 0.1125 0.1080 0.1060 0.1050 0.1052 0.1048 0.1046 0.1054 0.1061 0.1064 0.1070 

[TRAIN] Epoch[6](573/1500); Loss: 0.089094; Backpropagation: 0.0921 sec; Batch: 0.4273 sec
0.1384 0.1320 0.1215 0.1011 0.0885 0.0809 0.0768 0.0756 0.0752 0.0748 0.0748 0.0758 0.0763 0.0770 0.0780 0.0788 

[TRAIN] Epoch[6](574/1500); Loss: 0.126835; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1534 0.1810 0.2124 0.1908 0.1696 0.1466 0.1277 0.1160 0.1063 0.0983 0.0925 0.0890 0.0873 0.0860 0.0863 0.0862 

[TRAIN] Epoch[6](575/1500); Loss: 0.114388; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.1564 0.0575 0.2026 0.1907 0.1747 0.1474 0.1165 0.0985 0.0798 0.0701 0.0719 0.0802 0.0989 0.0928 0.0948 0.0973 

[TRAIN] Epoch[6](576/1500); Loss: 0.137301; Backpropagation: 0.0916 sec; Batch: 0.4371 sec
0.1722 0.1779 0.1818 0.1671 0.1523 0.1409 0.1326 0.1259 0.1211 0.1184 0.1179 0.1171 0.1166 0.1175 0.1180 0.1195 

[TRAIN] Epoch[6](577/1500); Loss: 0.138441; Backpropagation: 0.0921 sec; Batch: 0.4283 sec
0.1800 0.1947 0.1901 0.1718 0.1541 0.1403 0.1319 0.1255 0.1216 0.1193 0.1172 0.1151 0.1139 0.1132 0.1133 0.1131 

[TRAIN] Epoch[6](578/1500); Loss: 0.167001; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1955 0.2071 0.2016 0.1879 0.1751 0.1657 0.1584 0.1564 0.1549 0.1532 0.1514 0.1510 0.1533 0.1539 0.1535 0.1531 

[TRAIN] Epoch[6](579/1500); Loss: 0.097531; Backpropagation: 0.0927 sec; Batch: 0.4263 sec
0.1187 0.1340 0.1281 0.1171 0.1042 0.0946 0.0887 0.0876 0.0870 0.0854 0.0844 0.0855 0.0861 0.0860 0.0855 0.0875 

[TRAIN] Epoch[6](580/1500); Loss: 0.078221; Backpropagation: 0.0997 sec; Batch: 0.4325 sec
0.1017 0.1139 0.1069 0.1000 0.0879 0.0785 0.0726 0.0681 0.0659 0.0643 0.0635 0.0632 0.0643 0.0662 0.0670 0.0677 

[TRAIN] Epoch[6](581/1500); Loss: 0.128370; Backpropagation: 0.0921 sec; Batch: 0.4297 sec
0.1657 0.1600 0.1530 0.1414 0.1315 0.1244 0.1197 0.1178 0.1159 0.1159 0.1161 0.1167 0.1175 0.1186 0.1195 0.1203 

[TRAIN] Epoch[6](582/1500); Loss: 0.101741; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1499 0.1688 0.1623 0.1453 0.1250 0.1063 0.0933 0.0857 0.0788 0.0748 0.0738 0.0732 0.0722 0.0714 0.0734 0.0737 

[TRAIN] Epoch[6](583/1500); Loss: 0.137868; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.2028 0.1788 0.1844 0.1768 0.1652 0.1489 0.1349 0.1265 0.1208 0.1174 0.1122 0.1090 0.1076 0.1073 0.1072 0.1061 

[TRAIN] Epoch[6](584/1500); Loss: 0.141494; Backpropagation: 0.0916 sec; Batch: 0.4627 sec
0.1694 0.1580 0.1722 0.1633 0.1519 0.1381 0.1332 0.1343 0.1328 0.1309 0.1305 0.1296 0.1296 0.1301 0.1299 0.1300 

[TRAIN] Epoch[6](585/1500); Loss: 0.101729; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.1981 0.1012 0.1394 0.1552 0.1416 0.1188 0.0908 0.0729 0.0691 0.0720 0.0771 0.0750 0.0757 0.0776 0.0790 0.0842 

[TRAIN] Epoch[6](586/1500); Loss: 0.172502; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.2793 0.2311 0.2156 0.2207 0.2106 0.1967 0.1785 0.1655 0.1571 0.1496 0.1407 0.1323 0.1260 0.1216 0.1183 0.1164 

[TRAIN] Epoch[6](587/1500); Loss: 0.127505; Backpropagation: 0.0919 sec; Batch: 0.4259 sec
0.1899 0.1922 0.1794 0.1616 0.1445 0.1300 0.1195 0.1120 0.1061 0.1030 0.1014 0.1010 0.1004 0.0998 0.0997 0.0998 

[TRAIN] Epoch[6](588/1500); Loss: 0.094664; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1316 0.1306 0.1467 0.1381 0.1259 0.1089 0.0920 0.0822 0.0765 0.0745 0.0716 0.0691 0.0675 0.0669 0.0665 0.0662 

[TRAIN] Epoch[6](589/1500); Loss: 0.061730; Backpropagation: 0.0918 sec; Batch: 0.4263 sec
0.1169 0.0824 0.0717 0.0736 0.0682 0.0610 0.0569 0.0514 0.0501 0.0503 0.0502 0.0501 0.0505 0.0513 0.0519 0.0512 

[TRAIN] Epoch[6](590/1500); Loss: 0.177691; Backpropagation: 0.0917 sec; Batch: 0.4279 sec
0.2432 0.2159 0.2026 0.1963 0.1914 0.1848 0.1759 0.1701 0.1675 0.1641 0.1601 0.1561 0.1547 0.1538 0.1531 0.1535 

[TRAIN] Epoch[6](591/1500); Loss: 0.102976; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1247 0.1673 0.1691 0.1546 0.1340 0.1148 0.1009 0.0906 0.0823 0.0767 0.0735 0.0717 0.0708 0.0712 0.0717 0.0738 

[TRAIN] Epoch[6](592/1500); Loss: 0.157807; Backpropagation: 0.0919 sec; Batch: 0.4249 sec
0.3221 0.2487 0.2263 0.2413 0.2286 0.2084 0.1786 0.1524 0.1309 0.1087 0.0850 0.0740 0.0756 0.0805 0.0831 0.0808 

[TRAIN] Epoch[6](593/1500); Loss: 0.142242; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1960 0.1893 0.1816 0.1680 0.1568 0.1477 0.1394 0.1330 0.1280 0.1255 0.1228 0.1203 0.1177 0.1165 0.1166 0.1168 

[TRAIN] Epoch[6](594/1500); Loss: 0.103096; Backpropagation: 0.0916 sec; Batch: 0.4659 sec
0.2211 0.1583 0.1414 0.1478 0.1375 0.1210 0.0998 0.0805 0.0696 0.0654 0.0690 0.0665 0.0665 0.0666 0.0694 0.0693 

[TRAIN] Epoch[6](595/1500); Loss: 0.126711; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1414 0.1467 0.1786 0.1669 0.1539 0.1364 0.1212 0.1147 0.1122 0.1113 0.1087 0.1073 0.1070 0.1071 0.1068 0.1073 

[TRAIN] Epoch[6](596/1500); Loss: 0.167673; Backpropagation: 0.0918 sec; Batch: 0.4283 sec
0.2593 0.2419 0.2236 0.1974 0.1761 0.1657 0.1597 0.1533 0.1476 0.1436 0.1396 0.1362 0.1352 0.1351 0.1344 0.1341 

[TRAIN] Epoch[6](597/1500); Loss: 0.048815; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.0721 0.0692 0.0562 0.0490 0.0457 0.0445 0.0431 0.0428 0.0432 0.0434 0.0432 0.0448 0.0449 0.0448 0.0463 0.0478 

[TRAIN] Epoch[6](598/1500); Loss: 0.113134; Backpropagation: 0.0916 sec; Batch: 0.4256 sec
0.1730 0.1521 0.1370 0.1224 0.1114 0.1024 0.0980 0.0980 0.0969 0.0984 0.0996 0.1012 0.1018 0.1035 0.1058 0.1086 

[TRAIN] Epoch[6](599/1500); Loss: 0.106102; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1356 0.1887 0.1879 0.1632 0.1349 0.1112 0.0943 0.0826 0.0758 0.0720 0.0707 0.0728 0.0747 0.0752 0.0778 0.0801 

[TRAIN] Epoch[6](600/1500); Loss: 0.117994; Backpropagation: 0.0916 sec; Batch: 0.4276 sec
0.1848 0.1737 0.1575 0.1418 0.1271 0.1139 0.1059 0.1005 0.0987 0.0979 0.0965 0.0959 0.0968 0.0972 0.0990 0.1007 

[TRAIN] Epoch[6](601/1500); Loss: 0.202691; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.3328 0.2714 0.2432 0.2418 0.2327 0.2143 0.1887 0.1690 0.1705 0.1703 0.1723 0.1657 0.1691 0.1678 0.1675 0.1660 

[TRAIN] Epoch[6](602/1500); Loss: 0.106562; Backpropagation: 0.0918 sec; Batch: 0.4359 sec
0.1397 0.1844 0.1832 0.1600 0.1332 0.1110 0.0941 0.0824 0.0753 0.0737 0.0753 0.0754 0.0775 0.0784 0.0794 0.0819 

[TRAIN] Epoch[6](603/1500); Loss: 0.082589; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1183 0.0915 0.0858 0.0880 0.0845 0.0798 0.0783 0.0774 0.0769 0.0769 0.0767 0.0769 0.0768 0.0777 0.0777 0.0780 

[TRAIN] Epoch[6](604/1500); Loss: 0.119342; Backpropagation: 0.0987 sec; Batch: 0.4498 sec
0.1973 0.1250 0.1612 0.1511 0.1372 0.1113 0.0957 0.1056 0.1066 0.1047 0.0989 0.0967 0.1031 0.1100 0.1026 0.1024 

[TRAIN] Epoch[6](605/1500); Loss: 0.081653; Backpropagation: 0.0921 sec; Batch: 0.4257 sec
0.0810 0.0997 0.1183 0.1043 0.0903 0.0781 0.0705 0.0702 0.0722 0.0715 0.0722 0.0735 0.0749 0.0754 0.0763 0.0780 

[TRAIN] Epoch[6](606/1500); Loss: 0.150565; Backpropagation: 0.0917 sec; Batch: 0.4542 sec
0.1687 0.1621 0.1600 0.1523 0.1491 0.1476 0.1478 0.1482 0.1459 0.1458 0.1465 0.1469 0.1466 0.1464 0.1478 0.1473 

[TRAIN] Epoch[6](607/1500); Loss: 0.155169; Backpropagation: 0.0918 sec; Batch: 0.4347 sec
0.1357 0.2071 0.2619 0.2437 0.2214 0.1922 0.1616 0.1374 0.1211 0.1128 0.1118 0.1148 0.1159 0.1136 0.1152 0.1163 

[TRAIN] Epoch[6](608/1500); Loss: 0.102027; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1641 0.1528 0.1382 0.1201 0.1070 0.0976 0.0906 0.0866 0.0847 0.0840 0.0839 0.0841 0.0842 0.0841 0.0847 0.0857 

[TRAIN] Epoch[6](609/1500); Loss: 0.137717; Backpropagation: 0.0916 sec; Batch: 0.4617 sec
0.1788 0.1627 0.1715 0.1590 0.1465 0.1328 0.1261 0.1299 0.1276 0.1237 0.1232 0.1255 0.1246 0.1226 0.1236 0.1255 

[TRAIN] Epoch[6](610/1500); Loss: 0.107057; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1329 0.1378 0.1313 0.1186 0.1095 0.1041 0.1010 0.0984 0.0974 0.0968 0.0968 0.0967 0.0968 0.0976 0.0983 0.0990 

[TRAIN] Epoch[6](611/1500); Loss: 0.094152; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1592 0.1075 0.0977 0.0948 0.0908 0.0889 0.0879 0.0863 0.0865 0.0857 0.0860 0.0862 0.0864 0.0869 0.0879 0.0877 

[TRAIN] Epoch[6](612/1500); Loss: 0.066201; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1035 0.0760 0.0870 0.0811 0.0726 0.0622 0.0607 0.0604 0.0568 0.0550 0.0564 0.0578 0.0561 0.0562 0.0582 0.0593 

[TRAIN] Epoch[6](613/1500); Loss: 0.084513; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1367 0.1153 0.1070 0.1010 0.0921 0.0833 0.0784 0.0761 0.0720 0.0704 0.0708 0.0703 0.0691 0.0697 0.0704 0.0695 

[TRAIN] Epoch[6](614/1500); Loss: 0.151817; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2103 0.1908 0.1884 0.1762 0.1636 0.1507 0.1429 0.1404 0.1364 0.1340 0.1337 0.1323 0.1312 0.1316 0.1324 0.1341 

[TRAIN] Epoch[6](615/1500); Loss: 0.099069; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1421 0.1158 0.1179 0.1121 0.1043 0.0964 0.0920 0.0907 0.0887 0.0881 0.0888 0.0890 0.0881 0.0892 0.0904 0.0917 

[TRAIN] Epoch[6](616/1500); Loss: 0.079079; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1306 0.0674 0.1401 0.1268 0.1137 0.0864 0.0625 0.0585 0.0551 0.0574 0.0572 0.0593 0.0598 0.0606 0.0641 0.0657 

[TRAIN] Epoch[6](617/1500); Loss: 0.092314; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1409 0.0944 0.1274 0.1169 0.1043 0.0846 0.0779 0.0832 0.0792 0.0773 0.0783 0.0823 0.0818 0.0803 0.0822 0.0859 

[TRAIN] Epoch[6](618/1500); Loss: 0.162722; Backpropagation: 0.0917 sec; Batch: 0.4389 sec
0.2115 0.1944 0.1891 0.1800 0.1728 0.1662 0.1616 0.1556 0.1516 0.1489 0.1470 0.1452 0.1451 0.1442 0.1454 0.1451 

[TRAIN] Epoch[6](619/1500); Loss: 0.111877; Backpropagation: 0.0922 sec; Batch: 0.4262 sec
0.1407 0.1552 0.1512 0.1337 0.1210 0.1090 0.1067 0.1018 0.0981 0.0969 0.0969 0.0952 0.0949 0.0962 0.0961 0.0964 

[TRAIN] Epoch[6](620/1500); Loss: 0.082294; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1385 0.0920 0.1120 0.1012 0.0891 0.0734 0.0705 0.0712 0.0718 0.0704 0.0707 0.0701 0.0707 0.0709 0.0714 0.0730 

[TRAIN] Epoch[6](621/1500); Loss: 0.081736; Backpropagation: 0.0920 sec; Batch: 0.4263 sec
0.0773 0.1360 0.1311 0.1033 0.0784 0.0653 0.0654 0.0675 0.0680 0.0703 0.0713 0.0721 0.0735 0.0747 0.0756 0.0781 

[TRAIN] Epoch[6](622/1500); Loss: 0.122107; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1400 0.1139 0.1722 0.1615 0.1493 0.1274 0.1081 0.1027 0.1081 0.1072 0.1077 0.1084 0.1108 0.1123 0.1118 0.1124 

[TRAIN] Epoch[6](623/1500); Loss: 0.156168; Backpropagation: 0.0918 sec; Batch: 0.4627 sec
0.2381 0.2089 0.1948 0.1802 0.1676 0.1585 0.1515 0.1452 0.1379 0.1340 0.1318 0.1309 0.1306 0.1294 0.1292 0.1301 

[TRAIN] Epoch[6](624/1500); Loss: 0.128790; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1650 0.1690 0.1626 0.1476 0.1324 0.1226 0.1200 0.1159 0.1147 0.1130 0.1130 0.1144 0.1152 0.1172 0.1177 0.1203 

[TRAIN] Epoch[6](625/1500); Loss: 0.144381; Backpropagation: 0.0918 sec; Batch: 0.4511 sec
0.1584 0.1481 0.1755 0.1668 0.1566 0.1430 0.1339 0.1313 0.1328 0.1338 0.1356 0.1389 0.1379 0.1379 0.1392 0.1405 

[TRAIN] Epoch[6](626/1500); Loss: 0.082030; Backpropagation: 0.0917 sec; Batch: 0.4303 sec
0.1210 0.1064 0.1006 0.0912 0.0826 0.0778 0.0801 0.0752 0.0734 0.0732 0.0723 0.0713 0.0719 0.0715 0.0720 0.0720 

[TRAIN] Epoch[6](627/1500); Loss: 0.089583; Backpropagation: 0.0917 sec; Batch: 0.4620 sec
0.1137 0.1071 0.0991 0.0918 0.0893 0.0877 0.0861 0.0847 0.0846 0.0843 0.0841 0.0837 0.0837 0.0843 0.0842 0.0850 

[TRAIN] Epoch[6](628/1500); Loss: 0.114235; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1488 0.1522 0.1433 0.1232 0.1150 0.1129 0.1079 0.1056 0.1035 0.1024 0.1026 0.1016 0.1015 0.1021 0.1026 0.1025 

[TRAIN] Epoch[6](629/1500); Loss: 0.091758; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1300 0.1050 0.0962 0.0926 0.0918 0.0924 0.0920 0.0876 0.0860 0.0863 0.0851 0.0846 0.0845 0.0845 0.0848 0.0848 

[TRAIN] Epoch[6](630/1500); Loss: 0.143440; Backpropagation: 0.0918 sec; Batch: 0.4262 sec
0.1992 0.1999 0.1954 0.1802 0.1632 0.1484 0.1358 0.1275 0.1227 0.1203 0.1189 0.1184 0.1165 0.1168 0.1159 0.1161 

[TRAIN] Epoch[6](631/1500); Loss: 0.087079; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0938 0.1314 0.1384 0.1159 0.0937 0.0783 0.0714 0.0732 0.0736 0.0722 0.0752 0.0745 0.0743 0.0750 0.0750 0.0773 

[TRAIN] Epoch[6](632/1500); Loss: 0.136671; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2223 0.1716 0.1697 0.1668 0.1585 0.1474 0.1353 0.1262 0.1173 0.1118 0.1126 0.1106 0.1096 0.1091 0.1090 0.1091 

[TRAIN] Epoch[6](633/1500); Loss: 0.156520; Backpropagation: 0.0918 sec; Batch: 0.4257 sec
0.2109 0.1844 0.1766 0.1692 0.1625 0.1561 0.1509 0.1483 0.1474 0.1438 0.1428 0.1432 0.1423 0.1416 0.1421 0.1422 

[TRAIN] Epoch[6](634/1500); Loss: 0.167581; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2097 0.1953 0.1951 0.1847 0.1750 0.1672 0.1647 0.1642 0.1618 0.1561 0.1544 0.1520 0.1507 0.1508 0.1495 0.1499 

[TRAIN] Epoch[6](635/1500); Loss: 0.140645; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1926 0.1963 0.1911 0.1720 0.1534 0.1388 0.1291 0.1251 0.1227 0.1231 0.1191 0.1174 0.1171 0.1173 0.1176 0.1177 

[TRAIN] Epoch[6](636/1500); Loss: 0.132161; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.3041 0.2174 0.2201 0.2221 0.2062 0.1788 0.1439 0.1119 0.0823 0.0626 0.0568 0.0611 0.0607 0.0616 0.0630 0.0619 

[TRAIN] Epoch[6](637/1500); Loss: 0.104257; Backpropagation: 0.0917 sec; Batch: 0.4615 sec
0.1638 0.1171 0.1148 0.1102 0.1055 0.1026 0.0994 0.0953 0.0941 0.0953 0.0946 0.0936 0.0945 0.0949 0.0955 0.0969 

[TRAIN] Epoch[6](638/1500); Loss: 0.114376; Backpropagation: 0.0929 sec; Batch: 0.4245 sec
0.1132 0.0952 0.1834 0.1697 0.1554 0.1339 0.1099 0.0948 0.0875 0.0898 0.0937 0.0956 0.1001 0.1027 0.1021 0.1032 

[TRAIN] Epoch[6](639/1500); Loss: 0.142443; Backpropagation: 0.0919 sec; Batch: 0.4259 sec
0.1732 0.1684 0.1602 0.1488 0.1418 0.1386 0.1365 0.1358 0.1353 0.1336 0.1333 0.1329 0.1331 0.1346 0.1362 0.1369 

[TRAIN] Epoch[6](640/1500); Loss: 0.097331; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2094 0.1360 0.1369 0.1349 0.1247 0.1083 0.0938 0.0814 0.0741 0.0666 0.0666 0.0666 0.0644 0.0643 0.0651 0.0643 

[TRAIN] Epoch[6](641/1500); Loss: 0.106111; Backpropagation: 0.0917 sec; Batch: 0.4623 sec
0.1544 0.1401 0.1264 0.1114 0.1006 0.0911 0.0839 0.0830 0.0853 0.0898 0.0932 0.0979 0.1017 0.1079 0.1139 0.1172 

[TRAIN] Epoch[6](642/1500); Loss: 0.105632; Backpropagation: 0.0919 sec; Batch: 0.4274 sec
0.1255 0.1366 0.1333 0.1213 0.1084 0.1002 0.0987 0.0989 0.0977 0.0981 0.0959 0.0948 0.0959 0.0951 0.0946 0.0952 

[TRAIN] Epoch[6](643/1500); Loss: 0.129592; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1561 0.1447 0.1394 0.1326 0.1329 0.1295 0.1253 0.1246 0.1221 0.1229 0.1237 0.1230 0.1235 0.1240 0.1248 0.1245 

[TRAIN] Epoch[6](644/1500); Loss: 0.122028; Backpropagation: 0.0918 sec; Batch: 0.4584 sec
0.1512 0.1332 0.1311 0.1254 0.1231 0.1236 0.1197 0.1175 0.1177 0.1171 0.1154 0.1152 0.1154 0.1153 0.1154 0.1163 

[TRAIN] Epoch[6](645/1500); Loss: 0.077865; Backpropagation: 0.0917 sec; Batch: 0.4631 sec
0.1114 0.1023 0.0940 0.0820 0.0751 0.0751 0.0740 0.0702 0.0698 0.0702 0.0693 0.0697 0.0699 0.0702 0.0709 0.0714 

[TRAIN] Epoch[6](646/1500); Loss: 0.089151; Backpropagation: 0.0920 sec; Batch: 0.4278 sec
0.1478 0.0480 0.1563 0.1413 0.1270 0.1022 0.0732 0.0554 0.0504 0.0624 0.0778 0.0728 0.0668 0.0753 0.0828 0.0868 

[TRAIN] Epoch[6](647/1500); Loss: 0.168982; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.2105 0.1989 0.1971 0.1827 0.1748 0.1718 0.1682 0.1627 0.1591 0.1557 0.1545 0.1537 0.1537 0.1533 0.1532 0.1537 

[TRAIN] Epoch[6](648/1500); Loss: 0.208778; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.4319 0.3359 0.3390 0.3438 0.3271 0.2957 0.2543 0.2090 0.1608 0.1173 0.0854 0.0869 0.0969 0.0843 0.0834 0.0890 

[TRAIN] Epoch[6](649/1500); Loss: 0.107501; Backpropagation: 0.0918 sec; Batch: 0.4579 sec
0.1249 0.1235 0.1181 0.1102 0.1084 0.1071 0.1051 0.1028 0.1029 0.1024 0.1020 0.1019 0.1022 0.1025 0.1027 0.1033 

[TRAIN] Epoch[6](650/1500); Loss: 0.151744; Backpropagation: 0.0918 sec; Batch: 0.4310 sec
0.1840 0.1686 0.1608 0.1526 0.1486 0.1486 0.1492 0.1483 0.1491 0.1468 0.1454 0.1452 0.1455 0.1443 0.1452 0.1457 

[TRAIN] Epoch[6](651/1500); Loss: 0.101493; Backpropagation: 0.0920 sec; Batch: 0.4269 sec
0.1451 0.1496 0.1643 0.1356 0.1107 0.0920 0.0822 0.0811 0.0854 0.0821 0.0817 0.0803 0.0818 0.0832 0.0848 0.0840 

[TRAIN] Epoch[6](652/1500); Loss: 0.046996; Backpropagation: 0.0916 sec; Batch: 0.4588 sec
0.0857 0.0607 0.0529 0.0497 0.0475 0.0475 0.0412 0.0398 0.0411 0.0395 0.0403 0.0407 0.0406 0.0414 0.0415 0.0419 

[TRAIN] Epoch[6](653/1500); Loss: 0.135046; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2187 0.1712 0.1683 0.1639 0.1551 0.1433 0.1329 0.1233 0.1141 0.1123 0.1135 0.1094 0.1081 0.1096 0.1083 0.1089 

[TRAIN] Epoch[6](654/1500); Loss: 0.102342; Backpropagation: 0.0918 sec; Batch: 0.4303 sec
0.1950 0.1097 0.1329 0.1213 0.1091 0.0869 0.0739 0.0835 0.0866 0.0878 0.0876 0.0892 0.0953 0.0955 0.0903 0.0928 

[TRAIN] Epoch[6](655/1500); Loss: 0.078761; Backpropagation: 0.0919 sec; Batch: 0.4312 sec
0.1698 0.1235 0.1189 0.1084 0.0944 0.0775 0.0650 0.0618 0.0605 0.0552 0.0541 0.0540 0.0537 0.0541 0.0544 0.0550 

[TRAIN] Epoch[6](656/1500); Loss: 0.075353; Backpropagation: 0.0919 sec; Batch: 0.4271 sec
0.1675 0.1031 0.1085 0.1034 0.0927 0.0759 0.0635 0.0580 0.0586 0.0568 0.0546 0.0513 0.0523 0.0535 0.0524 0.0538 

[TRAIN] Epoch[6](657/1500); Loss: 0.229406; Backpropagation: 0.0921 sec; Batch: 0.4273 sec
0.3701 0.3118 0.2967 0.2864 0.2691 0.2440 0.2144 0.1913 0.1848 0.1952 0.1809 0.1844 0.1857 0.1901 0.1813 0.1842 

[TRAIN] Epoch[6](658/1500); Loss: 0.109519; Backpropagation: 0.0918 sec; Batch: 0.4304 sec
0.1685 0.1379 0.1270 0.1129 0.1062 0.1035 0.0982 0.0973 0.0962 0.0956 0.0978 0.0996 0.0999 0.1017 0.1043 0.1058 

[TRAIN] Epoch[6](659/1500); Loss: 0.122658; Backpropagation: 0.0919 sec; Batch: 0.4271 sec
0.1523 0.1399 0.1314 0.1260 0.1230 0.1222 0.1221 0.1195 0.1187 0.1175 0.1160 0.1152 0.1151 0.1145 0.1147 0.1145 

[TRAIN] Epoch[6](660/1500); Loss: 0.101688; Backpropagation: 0.0918 sec; Batch: 0.4627 sec
0.1565 0.0618 0.1665 0.1518 0.1375 0.1132 0.0852 0.0683 0.0633 0.0740 0.0894 0.0870 0.0812 0.0893 0.0978 0.1041 

[TRAIN] Epoch[6](661/1500); Loss: 0.103261; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1518 0.1400 0.1283 0.1132 0.1046 0.0989 0.0974 0.0941 0.0927 0.0900 0.0902 0.0885 0.0883 0.0904 0.0919 0.0918 

[TRAIN] Epoch[6](662/1500); Loss: 0.071709; Backpropagation: 0.0920 sec; Batch: 0.4264 sec
0.1069 0.1169 0.1034 0.0828 0.0692 0.0629 0.0604 0.0595 0.0592 0.0587 0.0593 0.0606 0.0608 0.0611 0.0623 0.0636 

[TRAIN] Epoch[6](663/1500); Loss: 0.165904; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2459 0.2113 0.2095 0.2015 0.1921 0.1811 0.1686 0.1559 0.1428 0.1364 0.1384 0.1341 0.1337 0.1348 0.1349 0.1334 

[TRAIN] Epoch[6](664/1500); Loss: 0.177364; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.2232 0.1973 0.1985 0.1897 0.1808 0.1727 0.1680 0.1671 0.1671 0.1686 0.1687 0.1659 0.1664 0.1684 0.1673 0.1682 

[TRAIN] Epoch[6](665/1500); Loss: 0.080753; Backpropagation: 0.0984 sec; Batch: 0.4333 sec
0.1847 0.0825 0.1145 0.1037 0.0910 0.0655 0.0493 0.0586 0.0622 0.0615 0.0605 0.0648 0.0728 0.0752 0.0706 0.0748 

[TRAIN] Epoch[6](666/1500); Loss: 0.122528; Backpropagation: 0.0926 sec; Batch: 0.4242 sec
0.2000 0.1472 0.1258 0.1218 0.1162 0.1127 0.1161 0.1119 0.1105 0.1113 0.1128 0.1143 0.1147 0.1141 0.1148 0.1162 

[TRAIN] Epoch[6](667/1500); Loss: 0.082427; Backpropagation: 0.0918 sec; Batch: 0.4281 sec
0.1059 0.1241 0.1200 0.0917 0.0778 0.0760 0.0753 0.0723 0.0718 0.0721 0.0730 0.0705 0.0711 0.0716 0.0724 0.0730 

[TRAIN] Epoch[6](668/1500); Loss: 0.092828; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1402 0.1278 0.1186 0.0978 0.0892 0.0878 0.0862 0.0821 0.0822 0.0817 0.0807 0.0811 0.0821 0.0821 0.0825 0.0831 

[TRAIN] Epoch[6](669/1500); Loss: 0.135262; Backpropagation: 0.0936 sec; Batch: 0.4328 sec
0.1684 0.1621 0.1520 0.1393 0.1362 0.1376 0.1329 0.1306 0.1288 0.1260 0.1254 0.1252 0.1246 0.1245 0.1252 0.1254 

[TRAIN] Epoch[6](670/1500); Loss: 0.163474; Backpropagation: 0.0935 sec; Batch: 0.4263 sec
0.2718 0.2221 0.2237 0.2195 0.2101 0.1947 0.1758 0.1591 0.1440 0.1302 0.1193 0.1134 0.1109 0.1095 0.1059 0.1056 

[TRAIN] Epoch[6](671/1500); Loss: 0.083962; Backpropagation: 0.0929 sec; Batch: 0.4244 sec
0.1417 0.1138 0.1088 0.0992 0.0923 0.0843 0.0791 0.0754 0.0709 0.0690 0.0686 0.0674 0.0675 0.0682 0.0683 0.0689 

[TRAIN] Epoch[6](672/1500); Loss: 0.156554; Backpropagation: 0.0919 sec; Batch: 0.4255 sec
0.3440 0.2613 0.2680 0.2639 0.2475 0.2197 0.1855 0.1519 0.1161 0.0837 0.0618 0.0587 0.0623 0.0588 0.0591 0.0626 

[TRAIN] Epoch[6](673/1500); Loss: 0.106671; Backpropagation: 0.0917 sec; Batch: 0.4303 sec
0.1642 0.1289 0.1460 0.1346 0.1217 0.1046 0.0956 0.0953 0.0978 0.0903 0.0887 0.0899 0.0880 0.0872 0.0864 0.0878 

[TRAIN] Epoch[6](674/1500); Loss: 0.201518; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2126 0.2359 0.2356 0.2207 0.2077 0.1988 0.1934 0.1908 0.1909 0.1915 0.1921 0.1924 0.1918 0.1902 0.1897 0.1901 

[TRAIN] Epoch[6](675/1500); Loss: 0.144855; Backpropagation: 0.0916 sec; Batch: 0.4263 sec
0.2198 0.1921 0.1909 0.1762 0.1635 0.1527 0.1436 0.1364 0.1283 0.1220 0.1164 0.1150 0.1149 0.1165 0.1147 0.1147 

[TRAIN] Epoch[6](676/1500); Loss: 0.139312; Backpropagation: 0.0917 sec; Batch: 0.4268 sec
0.2024 0.1823 0.1692 0.1548 0.1435 0.1363 0.1332 0.1304 0.1271 0.1252 0.1230 0.1217 0.1214 0.1195 0.1195 0.1196 

[TRAIN] Epoch[6](677/1500); Loss: 0.072606; Backpropagation: 0.0918 sec; Batch: 0.4271 sec
0.0903 0.1088 0.1056 0.0769 0.0694 0.0685 0.0676 0.0630 0.0622 0.0630 0.0650 0.0630 0.0636 0.0647 0.0648 0.0653 

[TRAIN] Epoch[6](678/1500); Loss: 0.150237; Backpropagation: 0.0915 sec; Batch: 0.4530 sec
0.2090 0.1705 0.1712 0.1672 0.1602 0.1518 0.1457 0.1414 0.1393 0.1377 0.1355 0.1355 0.1349 0.1353 0.1347 0.1340 

[TRAIN] Epoch[6](679/1500); Loss: 0.089309; Backpropagation: 0.0917 sec; Batch: 0.4289 sec
0.1846 0.1341 0.1373 0.1316 0.1205 0.1039 0.0846 0.0677 0.0615 0.0636 0.0582 0.0559 0.0572 0.0575 0.0558 0.0547 

[TRAIN] Epoch[6](680/1500); Loss: 0.130777; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.2273 0.1506 0.1645 0.1546 0.1423 0.1223 0.1079 0.1096 0.1155 0.1136 0.1111 0.1109 0.1147 0.1191 0.1137 0.1147 

[TRAIN] Epoch[6](681/1500); Loss: 0.161392; Backpropagation: 0.0916 sec; Batch: 0.4372 sec
0.1761 0.1771 0.1720 0.1656 0.1610 0.1603 0.1601 0.1605 0.1583 0.1575 0.1563 0.1553 0.1553 0.1553 0.1555 0.1558 

[TRAIN] Epoch[6](682/1500); Loss: 0.099042; Backpropagation: 0.0915 sec; Batch: 0.4600 sec
0.1395 0.0982 0.1353 0.1255 0.1135 0.0957 0.0849 0.0844 0.0908 0.0889 0.0858 0.0863 0.0889 0.0891 0.0887 0.0891 

[TRAIN] Epoch[6](683/1500); Loss: 0.097403; Backpropagation: 0.0949 sec; Batch: 0.4543 sec
0.1138 0.1339 0.1248 0.1113 0.0995 0.0929 0.0908 0.0884 0.0880 0.0869 0.0871 0.0875 0.0882 0.0882 0.0884 0.0889 

[TRAIN] Epoch[6](684/1500); Loss: 0.218698; Backpropagation: 0.0928 sec; Batch: 0.4255 sec
0.3736 0.3116 0.3200 0.3199 0.3055 0.2820 0.2539 0.2282 0.2001 0.1727 0.1454 0.1200 0.1116 0.1215 0.1173 0.1160 

[TRAIN] Epoch[6](685/1500); Loss: 0.088198; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1120 0.1247 0.1238 0.1138 0.1010 0.0892 0.0800 0.0742 0.0715 0.0705 0.0706 0.0715 0.0741 0.0758 0.0780 0.0805 

[TRAIN] Epoch[6](686/1500); Loss: 0.125342; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2845 0.2037 0.2202 0.2176 0.2027 0.1779 0.1484 0.1210 0.0944 0.0703 0.0521 0.0441 0.0391 0.0432 0.0430 0.0433 

[TRAIN] Epoch[6](687/1500); Loss: 0.145988; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1680 0.2283 0.2248 0.2098 0.1900 0.1698 0.1514 0.1352 0.1219 0.1123 0.1068 0.1041 0.1045 0.1026 0.1026 0.1037 

[TRAIN] Epoch[6](688/1500); Loss: 0.074259; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1223 0.0846 0.0733 0.0662 0.0666 0.0640 0.0658 0.0664 0.0662 0.0676 0.0691 0.0711 0.0736 0.0752 0.0766 0.0796 

[TRAIN] Epoch[6](689/1500); Loss: 0.136101; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1622 0.1832 0.1769 0.1671 0.1550 0.1445 0.1349 0.1269 0.1210 0.1177 0.1160 0.1153 0.1151 0.1137 0.1137 0.1144 

[TRAIN] Epoch[6](690/1500); Loss: 0.045383; Backpropagation: 0.0918 sec; Batch: 0.4627 sec
0.0625 0.0790 0.0685 0.0536 0.0417 0.0373 0.0357 0.0357 0.0358 0.0365 0.0374 0.0384 0.0392 0.0403 0.0421 0.0425 

[TRAIN] Epoch[6](691/1500); Loss: 0.076074; Backpropagation: 0.0919 sec; Batch: 0.4271 sec
0.0583 0.1234 0.1305 0.1164 0.0976 0.0778 0.0634 0.0565 0.0581 0.0629 0.0611 0.0584 0.0608 0.0623 0.0641 0.0654 

[TRAIN] Epoch[6](692/1500); Loss: 0.122356; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1519 0.1392 0.1402 0.1292 0.1215 0.1164 0.1119 0.1099 0.1111 0.1145 0.1162 0.1154 0.1170 0.1193 0.1214 0.1227 

[TRAIN] Epoch[6](693/1500); Loss: 0.099520; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1304 0.1175 0.1263 0.1200 0.1105 0.1009 0.0941 0.0910 0.0893 0.0891 0.0858 0.0874 0.0880 0.0871 0.0877 0.0872 

[TRAIN] Epoch[6](694/1500); Loss: 0.111035; Backpropagation: 0.0917 sec; Batch: 0.4262 sec
0.1324 0.1339 0.1285 0.1222 0.1145 0.1093 0.1079 0.1081 0.1041 0.1034 0.1030 0.1015 0.1021 0.1018 0.1024 0.1016 

[TRAIN] Epoch[6](695/1500); Loss: 0.096359; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1572 0.1604 0.1583 0.1472 0.1306 0.1124 0.0963 0.0850 0.0754 0.0682 0.0651 0.0600 0.0580 0.0561 0.0552 0.0564 

[TRAIN] Epoch[6](696/1500); Loss: 0.055265; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.0976 0.0499 0.0479 0.0503 0.0438 0.0437 0.0459 0.0479 0.0492 0.0503 0.0552 0.0548 0.0577 0.0608 0.0638 0.0653 

[TRAIN] Epoch[6](697/1500); Loss: 0.103255; Backpropagation: 0.0918 sec; Batch: 0.4264 sec
0.1458 0.1623 0.1585 0.1448 0.1258 0.1060 0.0923 0.0865 0.0778 0.0749 0.0768 0.0787 0.0779 0.0789 0.0809 0.0842 

[TRAIN] Epoch[6](698/1500); Loss: 0.124393; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.1835 0.1542 0.1582 0.1531 0.1425 0.1310 0.1217 0.1149 0.1098 0.1067 0.1034 0.1019 0.1017 0.1015 0.1028 0.1032 

[TRAIN] Epoch[6](699/1500); Loss: 0.174374; Backpropagation: 0.0920 sec; Batch: 0.4273 sec
0.1730 0.2344 0.2371 0.2255 0.2089 0.1932 0.1796 0.1687 0.1598 0.1526 0.1473 0.1437 0.1419 0.1409 0.1416 0.1417 

[TRAIN] Epoch[6](700/1500); Loss: 0.147519; Backpropagation: 0.0918 sec; Batch: 0.4261 sec
0.1817 0.1744 0.1628 0.1565 0.1514 0.1465 0.1431 0.1408 0.1393 0.1386 0.1377 0.1377 0.1374 0.1373 0.1374 0.1377 

[TRAIN] Epoch[6](701/1500); Loss: 0.096643; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1439 0.1217 0.1145 0.1078 0.0992 0.0926 0.0900 0.0884 0.0889 0.0875 0.0862 0.0849 0.0859 0.0849 0.0849 0.0850 

[TRAIN] Epoch[6](702/1500); Loss: 0.147106; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1791 0.1814 0.1771 0.1703 0.1588 0.1495 0.1430 0.1392 0.1365 0.1323 0.1305 0.1291 0.1308 0.1315 0.1313 0.1333 

[TRAIN] Epoch[6](703/1500); Loss: 0.109511; Backpropagation: 0.0918 sec; Batch: 0.4672 sec
0.1338 0.1053 0.1337 0.1283 0.1198 0.1088 0.1023 0.1020 0.1055 0.1023 0.1017 0.1016 0.1016 0.1018 0.1019 0.1016 

[TRAIN] Epoch[6](704/1500); Loss: 0.171795; Backpropagation: 0.0997 sec; Batch: 0.4394 sec
0.2146 0.2029 0.1937 0.1884 0.1815 0.1750 0.1704 0.1645 0.1621 0.1603 0.1593 0.1563 0.1553 0.1557 0.1544 0.1543 

[TRAIN] Epoch[6](705/1500); Loss: 0.086127; Backpropagation: 0.0920 sec; Batch: 0.4261 sec
0.1158 0.1033 0.1015 0.0965 0.0908 0.0871 0.0849 0.0821 0.0801 0.0781 0.0771 0.0766 0.0754 0.0759 0.0759 0.0769 

[TRAIN] Epoch[6](706/1500); Loss: 0.093060; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1282 0.1235 0.1154 0.1073 0.0958 0.0871 0.0843 0.0866 0.0872 0.0812 0.0817 0.0823 0.0842 0.0805 0.0807 0.0830 

[TRAIN] Epoch[6](707/1500); Loss: 0.097572; Backpropagation: 0.0918 sec; Batch: 0.4302 sec
0.1481 0.0450 0.1769 0.1649 0.1488 0.1239 0.0964 0.0747 0.0598 0.0549 0.0599 0.0688 0.0917 0.0805 0.0823 0.0844 

[TRAIN] Epoch[6](708/1500); Loss: 0.077755; Backpropagation: 0.0917 sec; Batch: 0.4276 sec
0.1124 0.1051 0.0874 0.0776 0.0734 0.0733 0.0711 0.0708 0.0708 0.0705 0.0709 0.0715 0.0712 0.0719 0.0732 0.0731 

[TRAIN] Epoch[6](709/1500); Loss: 0.101082; Backpropagation: 0.0917 sec; Batch: 0.4627 sec
0.1268 0.1146 0.1258 0.1188 0.1104 0.1016 0.0975 0.0944 0.0950 0.0914 0.0901 0.0903 0.0909 0.0898 0.0905 0.0896 

[TRAIN] Epoch[6](710/1500); Loss: 0.129514; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1900 0.1542 0.1908 0.1810 0.1680 0.1489 0.1299 0.1157 0.1074 0.1052 0.1015 0.0970 0.0940 0.0952 0.0966 0.0967 

[TRAIN] Epoch[6](711/1500); Loss: 0.122190; Backpropagation: 0.0934 sec; Batch: 0.4347 sec
0.1731 0.1548 0.1538 0.1444 0.1325 0.1216 0.1141 0.1102 0.1087 0.1058 0.1056 0.1057 0.1057 0.1059 0.1062 0.1071 

[TRAIN] Epoch[6](712/1500); Loss: 0.113543; Backpropagation: 0.0933 sec; Batch: 0.4240 sec
0.1324 0.1451 0.1394 0.1304 0.1215 0.1148 0.1077 0.1041 0.1009 0.1007 0.1018 0.1028 0.1030 0.1034 0.1037 0.1051 

[TRAIN] Epoch[6](713/1500); Loss: 0.078705; Backpropagation: 0.0919 sec; Batch: 0.4252 sec
0.2122 0.1433 0.1416 0.1303 0.1110 0.0872 0.0652 0.0454 0.0389 0.0413 0.0403 0.0391 0.0405 0.0409 0.0411 0.0409 

[TRAIN] Epoch[6](714/1500); Loss: 0.109005; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1379 0.1385 0.1549 0.1441 0.1301 0.1168 0.1063 0.0985 0.0970 0.0959 0.0887 0.0866 0.0873 0.0871 0.0875 0.0867 

[TRAIN] Epoch[6](715/1500); Loss: 0.119299; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1458 0.1391 0.1361 0.1257 0.1194 0.1141 0.1118 0.1086 0.1073 0.1107 0.1126 0.1134 0.1127 0.1160 0.1175 0.1178 

[TRAIN] Epoch[6](716/1500); Loss: 0.093244; Backpropagation: 0.0920 sec; Batch: 0.4250 sec
0.1157 0.1097 0.1065 0.1017 0.0973 0.0943 0.0901 0.0884 0.0869 0.0875 0.0859 0.0858 0.0850 0.0858 0.0850 0.0861 

[TRAIN] Epoch[6](717/1500); Loss: 0.124364; Backpropagation: 0.0921 sec; Batch: 0.4270 sec
0.1352 0.1622 0.1549 0.1433 0.1298 0.1194 0.1137 0.1122 0.1149 0.1157 0.1130 0.1129 0.1146 0.1169 0.1150 0.1161 

[TRAIN] Epoch[6](718/1500); Loss: 0.151222; Backpropagation: 0.0917 sec; Batch: 0.4263 sec
0.1809 0.1852 0.2042 0.1935 0.1794 0.1638 0.1503 0.1412 0.1364 0.1324 0.1299 0.1265 0.1250 0.1243 0.1236 0.1230 

[TRAIN] Epoch[6](719/1500); Loss: 0.160916; Backpropagation: 0.0920 sec; Batch: 0.4268 sec
0.1869 0.1905 0.1814 0.1712 0.1631 0.1569 0.1528 0.1502 0.1477 0.1486 0.1511 0.1527 0.1539 0.1554 0.1555 0.1567 

[TRAIN] Epoch[6](720/1500); Loss: 0.139935; Backpropagation: 0.0917 sec; Batch: 0.4264 sec
0.1469 0.1605 0.1628 0.1566 0.1472 0.1393 0.1341 0.1314 0.1307 0.1312 0.1308 0.1312 0.1326 0.1338 0.1348 0.1351 

[TRAIN] Epoch[6](721/1500); Loss: 0.080212; Backpropagation: 0.0919 sec; Batch: 0.4643 sec
0.1294 0.1036 0.0944 0.0903 0.0852 0.0790 0.0765 0.0739 0.0699 0.0696 0.0682 0.0690 0.0681 0.0685 0.0685 0.0692 

[TRAIN] Epoch[6](722/1500); Loss: 0.125685; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.1228 0.1012 0.2041 0.1908 0.1765 0.1536 0.1301 0.1127 0.1008 0.0967 0.0980 0.0990 0.1010 0.1056 0.1085 0.1096 

[TRAIN] Epoch[6](723/1500); Loss: 0.210313; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2412 0.2457 0.2377 0.2263 0.2167 0.2089 0.2031 0.1991 0.1971 0.1962 0.1971 0.1983 0.1981 0.1992 0.1995 0.2008 

[TRAIN] Epoch[6](724/1500); Loss: 0.056692; Backpropagation: 0.0918 sec; Batch: 0.4274 sec
0.1495 0.0765 0.0702 0.0512 0.0417 0.0454 0.0484 0.0423 0.0419 0.0446 0.0487 0.0464 0.0454 0.0480 0.0520 0.0548 

[TRAIN] Epoch[6](725/1500); Loss: 0.071293; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1243 0.1008 0.0951 0.0861 0.0755 0.0680 0.0645 0.0605 0.0582 0.0591 0.0584 0.0581 0.0573 0.0582 0.0582 0.0584 

[TRAIN] Epoch[6](726/1500); Loss: 0.115029; Backpropagation: 0.0919 sec; Batch: 0.4263 sec
0.1123 0.2107 0.2091 0.1934 0.1711 0.1459 0.1212 0.1001 0.0848 0.0761 0.0693 0.0673 0.0662 0.0667 0.0711 0.0752 

[TRAIN] Epoch[6](727/1500); Loss: 0.143181; Backpropagation: 0.0918 sec; Batch: 0.4255 sec
0.1836 0.1775 0.1751 0.1674 0.1560 0.1459 0.1398 0.1361 0.1326 0.1300 0.1268 0.1259 0.1238 0.1234 0.1236 0.1234 

[TRAIN] Epoch[6](728/1500); Loss: 0.080983; Backpropagation: 0.0920 sec; Batch: 0.4284 sec
0.1151 0.1042 0.1057 0.0977 0.0872 0.0793 0.0745 0.0740 0.0699 0.0691 0.0691 0.0699 0.0691 0.0691 0.0703 0.0715 

[TRAIN] Epoch[6](729/1500); Loss: 0.201654; Backpropagation: 0.0919 sec; Batch: 0.4252 sec
0.3180 0.2827 0.2856 0.2796 0.2642 0.2427 0.2208 0.2003 0.1803 0.1595 0.1378 0.1274 0.1342 0.1319 0.1309 0.1304 

[TRAIN] Epoch[6](730/1500); Loss: 0.100968; Backpropagation: 0.0916 sec; Batch: 0.4557 sec
0.1347 0.1839 0.1708 0.1573 0.1411 0.1236 0.1055 0.0885 0.0741 0.0634 0.0601 0.0608 0.0626 0.0621 0.0629 0.0639 

[TRAIN] Epoch[6](731/1500); Loss: 0.079584; Backpropagation: 0.0918 sec; Batch: 0.4580 sec
0.1073 0.1237 0.1186 0.1082 0.0945 0.0815 0.0737 0.0674 0.0645 0.0631 0.0616 0.0614 0.0617 0.0614 0.0623 0.0623 

[TRAIN] Epoch[6](732/1500); Loss: 0.125991; Backpropagation: 0.0934 sec; Batch: 0.4292 sec
0.1722 0.1443 0.1397 0.1357 0.1301 0.1248 0.1213 0.1187 0.1168 0.1157 0.1154 0.1155 0.1155 0.1159 0.1168 0.1173 

[TRAIN] Epoch[6](733/1500); Loss: 0.114542; Backpropagation: 0.0920 sec; Batch: 0.4284 sec
0.1585 0.1584 0.1493 0.1400 0.1281 0.1155 0.1058 0.0995 0.0970 0.0960 0.0961 0.0966 0.0976 0.0972 0.0978 0.0993 

[TRAIN] Epoch[6](734/1500); Loss: 0.093523; Backpropagation: 0.0916 sec; Batch: 0.4631 sec
0.1186 0.1063 0.1251 0.1169 0.1054 0.0934 0.0849 0.0815 0.0839 0.0825 0.0841 0.0820 0.0823 0.0824 0.0836 0.0836 

[TRAIN] Epoch[6](735/1500); Loss: 0.123797; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1830 0.1499 0.1256 0.1202 0.1172 0.1158 0.1161 0.1176 0.1169 0.1155 0.1157 0.1172 0.1165 0.1169 0.1184 0.1182 

[TRAIN] Epoch[6](736/1500); Loss: 0.190885; Backpropagation: 0.0917 sec; Batch: 0.4268 sec
0.1996 0.2408 0.2490 0.2379 0.2218 0.2055 0.1914 0.1810 0.1733 0.1686 0.1663 0.1653 0.1640 0.1635 0.1631 0.1631 

[TRAIN] Epoch[6](737/1500); Loss: 0.077543; Backpropagation: 0.0917 sec; Batch: 0.4345 sec
0.0953 0.1087 0.0962 0.0868 0.0804 0.0754 0.0722 0.0709 0.0698 0.0693 0.0688 0.0684 0.0688 0.0690 0.0698 0.0709 

[TRAIN] Epoch[6](738/1500); Loss: 0.117537; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1289 0.1187 0.1882 0.1750 0.1600 0.1352 0.1127 0.0992 0.0945 0.0937 0.0956 0.0960 0.0957 0.0960 0.0950 0.0961 

[TRAIN] Epoch[6](739/1500); Loss: 0.089051; Backpropagation: 0.1055 sec; Batch: 0.4389 sec
0.1277 0.1126 0.1395 0.1304 0.1171 0.0990 0.0841 0.0798 0.0738 0.0696 0.0663 0.0656 0.0650 0.0638 0.0653 0.0652 

[TRAIN] Epoch[6](740/1500); Loss: 0.156568; Backpropagation: 0.0920 sec; Batch: 0.4268 sec
0.1732 0.1690 0.1986 0.1904 0.1793 0.1644 0.1513 0.1435 0.1400 0.1396 0.1394 0.1406 0.1427 0.1442 0.1442 0.1445 

[TRAIN] Epoch[6](741/1500); Loss: 0.135217; Backpropagation: 0.0919 sec; Batch: 0.4276 sec
0.1421 0.1785 0.1746 0.1626 0.1491 0.1365 0.1262 0.1196 0.1187 0.1201 0.1200 0.1191 0.1212 0.1230 0.1253 0.1267 

[TRAIN] Epoch[6](742/1500); Loss: 0.140568; Backpropagation: 0.0917 sec; Batch: 0.4300 sec
0.1607 0.1575 0.1536 0.1487 0.1423 0.1375 0.1344 0.1331 0.1330 0.1333 0.1337 0.1349 0.1353 0.1359 0.1368 0.1383 

[TRAIN] Epoch[6](743/1500); Loss: 0.095104; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1237 0.1422 0.1617 0.1485 0.1308 0.1091 0.0893 0.0746 0.0682 0.0677 0.0667 0.0665 0.0657 0.0676 0.0697 0.0699 

[TRAIN] Epoch[6](744/1500); Loss: 0.148386; Backpropagation: 0.0986 sec; Batch: 0.4517 sec
0.2352 0.2064 0.2213 0.2160 0.2004 0.1789 0.1569 0.1388 0.1216 0.1083 0.1015 0.0998 0.0990 0.0989 0.0966 0.0945 

[TRAIN] Epoch[6](745/1500); Loss: 0.113203; Backpropagation: 0.0923 sec; Batch: 0.4266 sec
0.1766 0.1238 0.1490 0.1408 0.1300 0.1137 0.1029 0.0954 0.0942 0.0946 0.0958 0.0964 0.0974 0.0981 0.1007 0.1017 

[TRAIN] Epoch[6](746/1500); Loss: 0.154001; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1742 0.2068 0.2269 0.2167 0.2004 0.1805 0.1610 0.1447 0.1320 0.1240 0.1197 0.1170 0.1144 0.1143 0.1157 0.1159 

[TRAIN] Epoch[6](747/1500); Loss: 0.184109; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.2488 0.2136 0.2190 0.2186 0.2131 0.2034 0.1919 0.1829 0.1753 0.1688 0.1626 0.1570 0.1523 0.1483 0.1456 0.1445 

[TRAIN] Epoch[6](748/1500); Loss: 0.074349; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1393 0.0966 0.1015 0.0966 0.0867 0.0744 0.0660 0.0606 0.0590 0.0574 0.0578 0.0584 0.0577 0.0582 0.0593 0.0601 

[TRAIN] Epoch[6](749/1500); Loss: 0.074127; Backpropagation: 0.0917 sec; Batch: 0.4572 sec
0.0705 0.1322 0.1394 0.1253 0.1051 0.0813 0.0625 0.0536 0.0540 0.0526 0.0501 0.0508 0.0519 0.0514 0.0524 0.0530 

[TRAIN] Epoch[6](750/1500); Loss: 0.112744; Backpropagation: 0.0916 sec; Batch: 0.4266 sec
0.1359 0.1177 0.1181 0.1167 0.1141 0.1108 0.1086 0.1075 0.1076 0.1081 0.1085 0.1091 0.1096 0.1100 0.1105 0.1112 

[TRAIN] Epoch[6](751/1500); Loss: 0.141514; Backpropagation: 0.0999 sec; Batch: 0.4330 sec
0.1782 0.1908 0.1771 0.1677 0.1559 0.1450 0.1355 0.1285 0.1258 0.1242 0.1244 0.1235 0.1218 0.1222 0.1222 0.1216 

[TRAIN] Epoch[6](752/1500); Loss: 0.110009; Backpropagation: 0.0923 sec; Batch: 0.4263 sec
0.1550 0.1233 0.1532 0.1456 0.1346 0.1175 0.1045 0.1028 0.0984 0.0936 0.0914 0.0903 0.0871 0.0874 0.0876 0.0877 

[TRAIN] Epoch[6](753/1500); Loss: 0.072454; Backpropagation: 0.0920 sec; Batch: 0.4255 sec
0.0888 0.0829 0.0972 0.0912 0.0824 0.0717 0.0666 0.0661 0.0652 0.0636 0.0636 0.0643 0.0633 0.0635 0.0643 0.0645 

[TRAIN] Epoch[6](754/1500); Loss: 0.134667; Backpropagation: 0.0917 sec; Batch: 0.4225 sec
0.1995 0.1539 0.1605 0.1585 0.1506 0.1376 0.1273 0.1224 0.1202 0.1188 0.1177 0.1182 0.1193 0.1168 0.1163 0.1172 

[TRAIN] Epoch[6](755/1500); Loss: 0.154122; Backpropagation: 0.0917 sec; Batch: 0.4552 sec
0.1853 0.2212 0.2192 0.2072 0.1876 0.1684 0.1530 0.1427 0.1335 0.1283 0.1249 0.1214 0.1174 0.1192 0.1189 0.1179 

[TRAIN] Epoch[6](756/1500); Loss: 0.104291; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1373 0.1184 0.1217 0.1148 0.1065 0.0990 0.0967 0.0962 0.0975 0.0972 0.0965 0.0965 0.0974 0.0980 0.0973 0.0975 

[TRAIN] Epoch[6](757/1500); Loss: 0.152014; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.1667 0.1562 0.2160 0.2049 0.1921 0.1721 0.1535 0.1400 0.1313 0.1275 0.1286 0.1285 0.1279 0.1286 0.1293 0.1290 

[TRAIN] Epoch[6](758/1500); Loss: 0.104540; Backpropagation: 0.0918 sec; Batch: 0.4267 sec
0.1685 0.1193 0.1299 0.1273 0.1197 0.1077 0.0995 0.0949 0.0900 0.0884 0.0881 0.0881 0.0876 0.0876 0.0874 0.0886 

[TRAIN] Epoch[6](759/1500); Loss: 0.216274; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.3365 0.2713 0.2766 0.2749 0.2660 0.2457 0.2221 0.1980 0.1754 0.1716 0.1706 0.1766 0.1661 0.1685 0.1690 0.1717 

[TRAIN] Epoch[6](760/1500); Loss: 0.062350; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1131 0.0692 0.0834 0.0776 0.0695 0.0579 0.0542 0.0540 0.0547 0.0521 0.0520 0.0511 0.0524 0.0518 0.0519 0.0529 

[TRAIN] Epoch[6](761/1500); Loss: 0.087773; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1174 0.1603 0.1469 0.1319 0.1130 0.0947 0.0807 0.0714 0.0656 0.0626 0.0624 0.0596 0.0598 0.0593 0.0588 0.0599 

[TRAIN] Epoch[6](762/1500); Loss: 0.105796; Backpropagation: 0.0917 sec; Batch: 0.4225 sec
0.1258 0.1318 0.1311 0.1232 0.1119 0.1033 0.1006 0.0998 0.0966 0.0951 0.0959 0.0961 0.0950 0.0951 0.0960 0.0955 

[TRAIN] Epoch[6](763/1500); Loss: 0.114431; Backpropagation: 0.0996 sec; Batch: 0.4334 sec
0.1438 0.1486 0.1422 0.1336 0.1208 0.1134 0.1063 0.1045 0.1006 0.0994 0.1017 0.1010 0.1013 0.1025 0.1050 0.1062 

[TRAIN] Epoch[6](764/1500); Loss: 0.122614; Backpropagation: 0.0922 sec; Batch: 0.4259 sec
0.1585 0.1733 0.1689 0.1589 0.1453 0.1314 0.1210 0.1138 0.1063 0.1009 0.0982 0.0978 0.0974 0.0968 0.0963 0.0970 

[TRAIN] Epoch[6](765/1500); Loss: 0.071225; Backpropagation: 0.0918 sec; Batch: 0.4260 sec
0.0573 0.0962 0.1275 0.1145 0.0968 0.0765 0.0619 0.0577 0.0583 0.0549 0.0551 0.0574 0.0573 0.0557 0.0558 0.0567 

[TRAIN] Epoch[6](766/1500); Loss: 0.069765; Backpropagation: 0.0919 sec; Batch: 0.4274 sec
0.0663 0.1319 0.1361 0.1216 0.1005 0.0762 0.0571 0.0495 0.0489 0.0462 0.0451 0.0462 0.0463 0.0477 0.0480 0.0486 

[TRAIN] Epoch[6](767/1500); Loss: 0.099591; Backpropagation: 0.0921 sec; Batch: 0.4272 sec
0.1181 0.1092 0.1735 0.1595 0.1433 0.1190 0.0960 0.0805 0.0720 0.0707 0.0732 0.0747 0.0741 0.0749 0.0772 0.0775 

[TRAIN] Epoch[6](768/1500); Loss: 0.149033; Backpropagation: 0.0916 sec; Batch: 0.4261 sec
0.1787 0.1974 0.2043 0.1951 0.1792 0.1616 0.1458 0.1349 0.1287 0.1262 0.1239 0.1234 0.1226 0.1223 0.1201 0.1203 

[TRAIN] Epoch[6](769/1500); Loss: 0.129870; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1565 0.1764 0.1689 0.1591 0.1465 0.1346 0.1250 0.1176 0.1138 0.1121 0.1118 0.1110 0.1112 0.1108 0.1112 0.1113 

[TRAIN] Epoch[6](770/1500); Loss: 0.155410; Backpropagation: 0.0916 sec; Batch: 0.4427 sec
0.3212 0.2122 0.2494 0.2554 0.2403 0.2104 0.1773 0.1486 0.1205 0.0975 0.0819 0.0752 0.0747 0.0738 0.0735 0.0745 

[TRAIN] Epoch[6](771/1500); Loss: 0.152384; Backpropagation: 0.0919 sec; Batch: 0.4277 sec
0.1875 0.1833 0.1834 0.1765 0.1662 0.1563 0.1495 0.1459 0.1425 0.1384 0.1375 0.1360 0.1345 0.1343 0.1336 0.1327 

[TRAIN] Epoch[6](772/1500); Loss: 0.100362; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1512 0.1189 0.1464 0.1413 0.1321 0.1181 0.1032 0.0932 0.0862 0.0770 0.0721 0.0730 0.0731 0.0725 0.0729 0.0744 

[TRAIN] Epoch[6](773/1500); Loss: 0.115229; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1889 0.1491 0.1546 0.1520 0.1442 0.1309 0.1162 0.1029 0.0915 0.0858 0.0871 0.0869 0.0881 0.0875 0.0886 0.0893 

[TRAIN] Epoch[6](774/1500); Loss: 0.070361; Backpropagation: 0.0989 sec; Batch: 0.4331 sec
0.1050 0.1460 0.1298 0.1113 0.0926 0.0729 0.0574 0.0480 0.0466 0.0452 0.0448 0.0445 0.0450 0.0451 0.0454 0.0463 

[TRAIN] Epoch[6](775/1500); Loss: 0.136790; Backpropagation: 0.0931 sec; Batch: 0.4244 sec
0.1804 0.1826 0.1630 0.1547 0.1433 0.1351 0.1292 0.1271 0.1275 0.1246 0.1220 0.1205 0.1202 0.1199 0.1192 0.1193 

[TRAIN] Epoch[6](776/1500); Loss: 0.108167; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1614 0.1258 0.1545 0.1444 0.1307 0.1106 0.0973 0.0939 0.0954 0.0925 0.0886 0.0892 0.0872 0.0862 0.0860 0.0868 

[TRAIN] Epoch[6](777/1500); Loss: 0.129818; Backpropagation: 0.0917 sec; Batch: 0.4305 sec
0.1486 0.1564 0.1522 0.1460 0.1373 0.1294 0.1234 0.1206 0.1206 0.1206 0.1201 0.1199 0.1205 0.1206 0.1201 0.1208 

[TRAIN] Epoch[6](778/1500); Loss: 0.139685; Backpropagation: 0.0916 sec; Batch: 0.4267 sec
0.1576 0.1615 0.1664 0.1575 0.1452 0.1341 0.1313 0.1332 0.1355 0.1335 0.1327 0.1309 0.1295 0.1290 0.1280 0.1289 

[TRAIN] Epoch[6](779/1500); Loss: 0.169332; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1934 0.2137 0.2079 0.1990 0.1852 0.1733 0.1643 0.1593 0.1581 0.1583 0.1536 0.1498 0.1492 0.1493 0.1473 0.1478 

[TRAIN] Epoch[6](780/1500); Loss: 0.114366; Backpropagation: 0.0918 sec; Batch: 0.4258 sec
0.1327 0.1437 0.1442 0.1350 0.1242 0.1135 0.1040 0.0979 0.0957 0.0954 0.0979 0.1019 0.1060 0.1087 0.1130 0.1159 

[TRAIN] Epoch[6](781/1500); Loss: 0.154139; Backpropagation: 0.0970 sec; Batch: 0.4303 sec
0.2260 0.1863 0.1828 0.1759 0.1689 0.1586 0.1491 0.1421 0.1380 0.1351 0.1346 0.1347 0.1336 0.1338 0.1335 0.1334 

[TRAIN] Epoch[6](782/1500); Loss: 0.068640; Backpropagation: 0.0935 sec; Batch: 0.4359 sec
0.1158 0.1104 0.1111 0.1013 0.0865 0.0709 0.0624 0.0589 0.0530 0.0483 0.0474 0.0468 0.0456 0.0478 0.0453 0.0467 

[TRAIN] Epoch[6](783/1500); Loss: 0.093249; Backpropagation: 0.0922 sec; Batch: 0.4261 sec
0.1104 0.1229 0.1191 0.1115 0.1029 0.0948 0.0898 0.0866 0.0847 0.0831 0.0818 0.0818 0.0804 0.0805 0.0805 0.0812 

[TRAIN] Epoch[6](784/1500); Loss: 0.097775; Backpropagation: 0.0916 sec; Batch: 0.4262 sec
0.1402 0.1068 0.1112 0.1100 0.1050 0.0984 0.0930 0.0902 0.0894 0.0877 0.0881 0.0881 0.0883 0.0890 0.0891 0.0898 

[TRAIN] Epoch[6](785/1500); Loss: 0.058141; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0789 0.0910 0.0796 0.0666 0.0577 0.0538 0.0516 0.0507 0.0496 0.0493 0.0494 0.0494 0.0497 0.0502 0.0508 0.0517 

[TRAIN] Epoch[6](786/1500); Loss: 0.103065; Backpropagation: 0.0918 sec; Batch: 0.4265 sec
0.1242 0.1024 0.1680 0.1563 0.1412 0.1169 0.0962 0.0849 0.0836 0.0795 0.0833 0.0793 0.0796 0.0823 0.0857 0.0855 

[TRAIN] Epoch[6](787/1500); Loss: 0.074072; Backpropagation: 0.0918 sec; Batch: 0.4306 sec
0.1124 0.0772 0.0790 0.0758 0.0747 0.0674 0.0679 0.0683 0.0673 0.0682 0.0690 0.0686 0.0709 0.0719 0.0719 0.0744 

[TRAIN] Epoch[6](788/1500); Loss: 0.085096; Backpropagation: 0.0916 sec; Batch: 0.4539 sec
0.1169 0.1412 0.1235 0.1132 0.1029 0.0908 0.0804 0.0727 0.0670 0.0649 0.0636 0.0645 0.0643 0.0643 0.0655 0.0658 

[TRAIN] Epoch[6](789/1500); Loss: 0.140359; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.1538 0.1539 0.1525 0.1480 0.1419 0.1378 0.1376 0.1363 0.1365 0.1362 0.1358 0.1357 0.1352 0.1348 0.1347 0.1350 

[TRAIN] Epoch[6](790/1500); Loss: 0.088294; Backpropagation: 0.0914 sec; Batch: 0.4619 sec
0.1193 0.1088 0.1059 0.1013 0.0951 0.0894 0.0856 0.0845 0.0811 0.0792 0.0789 0.0784 0.0764 0.0760 0.0769 0.0759 

[TRAIN] Epoch[6](791/1500); Loss: 0.073183; Backpropagation: 0.0917 sec; Batch: 0.4269 sec
0.1352 0.0859 0.0896 0.0864 0.0788 0.0705 0.0663 0.0643 0.0618 0.0610 0.0620 0.0609 0.0618 0.0613 0.0624 0.0626 

[TRAIN] Epoch[6](792/1500); Loss: 0.099851; Backpropagation: 0.0917 sec; Batch: 0.4262 sec
0.1138 0.1437 0.1385 0.1282 0.1148 0.1026 0.0951 0.0912 0.0861 0.0848 0.0844 0.0839 0.0828 0.0826 0.0824 0.0826 

[TRAIN] Epoch[6](793/1500); Loss: 0.141251; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1906 0.2004 0.2043 0.1955 0.1786 0.1608 0.1474 0.1390 0.1238 0.1172 0.1114 0.1038 0.0974 0.0953 0.0975 0.0969 

[TRAIN] Epoch[6](794/1500); Loss: 0.107061; Backpropagation: 0.0916 sec; Batch: 0.4336 sec
0.1362 0.1027 0.1600 0.1494 0.1351 0.1126 0.0947 0.0891 0.0912 0.0920 0.0913 0.0900 0.0929 0.0921 0.0915 0.0921 

[TRAIN] Epoch[6](795/1500); Loss: 0.134349; Backpropagation: 0.0916 sec; Batch: 0.4470 sec
0.1704 0.1515 0.1585 0.1554 0.1487 0.1407 0.1357 0.1320 0.1266 0.1237 0.1218 0.1186 0.1167 0.1166 0.1168 0.1160 

[TRAIN] Epoch[6](796/1500); Loss: 0.088159; Backpropagation: 0.0918 sec; Batch: 0.4273 sec
0.1311 0.1368 0.1212 0.1095 0.0984 0.0882 0.0806 0.0752 0.0708 0.0694 0.0692 0.0695 0.0705 0.0719 0.0739 0.0741 

[TRAIN] Epoch[6](797/1500); Loss: 0.150060; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.1817 0.1723 0.1745 0.1709 0.1648 0.1587 0.1539 0.1481 0.1436 0.1377 0.1339 0.1335 0.1322 0.1325 0.1314 0.1313 

[TRAIN] Epoch[6](798/1500); Loss: 0.129417; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1815 0.1478 0.1636 0.1595 0.1490 0.1353 0.1252 0.1218 0.1165 0.1125 0.1116 0.1107 0.1095 0.1087 0.1089 0.1085 

[TRAIN] Epoch[6](799/1500); Loss: 0.096660; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1371 0.1240 0.1237 0.1201 0.1112 0.1028 0.0930 0.0871 0.0853 0.0835 0.0801 0.0792 0.0805 0.0800 0.0792 0.0796 

[TRAIN] Epoch[6](800/1500); Loss: 0.107787; Backpropagation: 0.0918 sec; Batch: 0.4272 sec
0.1399 0.1341 0.1313 0.1248 0.1151 0.1070 0.1045 0.1018 0.1000 0.0991 0.0962 0.0955 0.0944 0.0943 0.0938 0.0928 

[TRAIN] Epoch[6](801/1500); Loss: 0.082620; Backpropagation: 0.0919 sec; Batch: 0.4275 sec
0.1078 0.1474 0.1256 0.1100 0.0985 0.0893 0.0788 0.0714 0.0658 0.0616 0.0600 0.0600 0.0605 0.0611 0.0619 0.0624 

[TRAIN] Epoch[6](802/1500); Loss: 0.084822; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1316 0.1159 0.1171 0.1104 0.0985 0.0854 0.0769 0.0734 0.0704 0.0696 0.0690 0.0685 0.0676 0.0677 0.0679 0.0674 

[TRAIN] Epoch[6](803/1500); Loss: 0.072260; Backpropagation: 0.0916 sec; Batch: 0.4252 sec
0.1684 0.0618 0.1133 0.1128 0.0961 0.0697 0.0475 0.0423 0.0467 0.0506 0.0505 0.0544 0.0573 0.0602 0.0628 0.0617 

[TRAIN] Epoch[6](804/1500); Loss: 0.162338; Backpropagation: 0.0987 sec; Batch: 0.4512 sec
0.1682 0.1831 0.1739 0.1689 0.1660 0.1638 0.1608 0.1584 0.1581 0.1580 0.1568 0.1570 0.1558 0.1565 0.1563 0.1560 

[TRAIN] Epoch[6](805/1500); Loss: 0.101454; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1219 0.1400 0.1313 0.1223 0.1130 0.1045 0.0985 0.0938 0.0903 0.0879 0.0875 0.0860 0.0863 0.0870 0.0866 0.0862 

[TRAIN] Epoch[6](806/1500); Loss: 0.127341; Backpropagation: 0.0916 sec; Batch: 0.4535 sec
0.1676 0.1927 0.1805 0.1695 0.1546 0.1382 0.1233 0.1115 0.1033 0.0998 0.0992 0.0999 0.0993 0.0986 0.0994 0.1001 

[TRAIN] Epoch[6](807/1500); Loss: 0.138691; Backpropagation: 0.0918 sec; Batch: 0.4265 sec
0.1896 0.1706 0.1654 0.1590 0.1496 0.1401 0.1337 0.1310 0.1307 0.1256 0.1230 0.1227 0.1211 0.1200 0.1186 0.1185 

[TRAIN] Epoch[6](808/1500); Loss: 0.129273; Backpropagation: 0.0916 sec; Batch: 0.4272 sec
0.1475 0.1434 0.1394 0.1352 0.1307 0.1272 0.1253 0.1241 0.1239 0.1237 0.1238 0.1238 0.1245 0.1246 0.1252 0.1261 

[TRAIN] Epoch[6](809/1500); Loss: 0.060400; Backpropagation: 0.0917 sec; Batch: 0.4265 sec
0.1595 0.0678 0.0923 0.0926 0.0811 0.0585 0.0422 0.0395 0.0435 0.0406 0.0411 0.0411 0.0412 0.0416 0.0414 0.0424 

[TRAIN] Epoch[6](810/1500); Loss: 0.155179; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1881 0.1936 0.1924 0.1868 0.1781 0.1691 0.1603 0.1521 0.1445 0.1370 0.1324 0.1316 0.1300 0.1294 0.1290 0.1287 

[TRAIN] Epoch[6](811/1500); Loss: 0.150084; Backpropagation: 0.0935 sec; Batch: 0.4428 sec
0.1600 0.1741 0.2272 0.2173 0.2017 0.1802 0.1581 0.1403 0.1261 0.1178 0.1154 0.1178 0.1162 0.1154 0.1170 0.1168 

[TRAIN] Epoch[6](812/1500); Loss: 0.126358; Backpropagation: 0.0921 sec; Batch: 0.4636 sec
0.1390 0.1964 0.1977 0.1851 0.1680 0.1491 0.1315 0.1162 0.1043 0.0969 0.0932 0.0889 0.0877 0.0883 0.0887 0.0907 

[TRAIN] Epoch[6](813/1500); Loss: 0.118826; Backpropagation: 0.0918 sec; Batch: 0.4253 sec
0.1315 0.0895 0.1967 0.1831 0.1678 0.1428 0.1185 0.1014 0.0900 0.0876 0.0913 0.0960 0.0974 0.0996 0.1029 0.1050 

[TRAIN] Epoch[6](814/1500); Loss: 0.116276; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1408 0.1399 0.1410 0.1346 0.1249 0.1165 0.1123 0.1104 0.1074 0.1080 0.1062 0.1042 0.1043 0.1033 0.1037 0.1029 

[TRAIN] Epoch[6](815/1500); Loss: 0.150148; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1779 0.1664 0.1842 0.1772 0.1660 0.1526 0.1431 0.1385 0.1365 0.1365 0.1370 0.1369 0.1363 0.1369 0.1375 0.1387 

[TRAIN] Epoch[6](816/1500); Loss: 0.147324; Backpropagation: 0.0916 sec; Batch: 0.4289 sec
0.2215 0.1927 0.1976 0.1933 0.1821 0.1678 0.1538 0.1422 0.1288 0.1140 0.1108 0.1110 0.1115 0.1103 0.1094 0.1103 

[TRAIN] Epoch[6](817/1500); Loss: 0.159756; Backpropagation: 0.0918 sec; Batch: 0.4253 sec
0.2508 0.2000 0.1965 0.1879 0.1778 0.1640 0.1518 0.1420 0.1368 0.1345 0.1350 0.1346 0.1358 0.1354 0.1370 0.1362 

[TRAIN] Epoch[6](818/1500); Loss: 0.121794; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1376 0.1847 0.1788 0.1669 0.1495 0.1340 0.1193 0.1081 0.1012 0.0973 0.0961 0.0958 0.0951 0.0944 0.0951 0.0950 

[TRAIN] Epoch[6](819/1500); Loss: 0.128000; Backpropagation: 0.0918 sec; Batch: 0.4290 sec
0.1466 0.1410 0.1573 0.1498 0.1386 0.1266 0.1202 0.1199 0.1212 0.1198 0.1183 0.1184 0.1179 0.1184 0.1170 0.1171 

[TRAIN] Epoch[6](820/1500); Loss: 0.102711; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1400 0.1169 0.1240 0.1214 0.1139 0.1063 0.1012 0.0980 0.0936 0.0898 0.0896 0.0896 0.0895 0.0892 0.0907 0.0894 

[TRAIN] Epoch[6](821/1500); Loss: 0.120577; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1625 0.1373 0.1652 0.1588 0.1492 0.1340 0.1200 0.1128 0.1111 0.1059 0.1005 0.0969 0.0958 0.0936 0.0928 0.0928 

[TRAIN] Epoch[6](822/1500); Loss: 0.162091; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.3392 0.2417 0.2723 0.2741 0.2601 0.2332 0.2013 0.1703 0.1373 0.1049 0.0754 0.0550 0.0520 0.0589 0.0600 0.0578 

[TRAIN] Epoch[6](823/1500); Loss: 0.118390; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1811 0.1373 0.1413 0.1390 0.1322 0.1227 0.1166 0.1081 0.1067 0.1019 0.1013 0.1015 0.1006 0.1014 0.1006 0.1018 

[TRAIN] Epoch[6](824/1500); Loss: 0.144774; Backpropagation: 0.0920 sec; Batch: 0.4274 sec
0.1730 0.2445 0.2458 0.2292 0.2058 0.1807 0.1564 0.1338 0.1144 0.0992 0.0901 0.0889 0.0924 0.0888 0.0866 0.0868 

[TRAIN] Epoch[6](825/1500); Loss: 0.132137; Backpropagation: 0.0919 sec; Batch: 0.4259 sec
0.1490 0.1725 0.1702 0.1580 0.1431 0.1299 0.1215 0.1171 0.1195 0.1185 0.1184 0.1196 0.1184 0.1189 0.1201 0.1197 

[TRAIN] Epoch[6](826/1500); Loss: 0.111267; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1394 0.1599 0.1594 0.1490 0.1319 0.1143 0.1036 0.0971 0.0951 0.0941 0.0914 0.0906 0.0885 0.0886 0.0892 0.0881 

[TRAIN] Epoch[6](827/1500); Loss: 0.091913; Backpropagation: 0.0917 sec; Batch: 0.4418 sec
0.1387 0.1310 0.1304 0.1218 0.1084 0.0936 0.0834 0.0787 0.0758 0.0739 0.0731 0.0725 0.0723 0.0722 0.0723 0.0725 

[TRAIN] Epoch[6](828/1500); Loss: 0.152646; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2172 0.1907 0.1816 0.1727 0.1638 0.1541 0.1458 0.1405 0.1386 0.1366 0.1357 0.1341 0.1332 0.1330 0.1324 0.1323 

[TRAIN] Epoch[6](829/1500); Loss: 0.091083; Backpropagation: 0.0917 sec; Batch: 0.4543 sec
0.1038 0.1169 0.1103 0.1026 0.0950 0.0894 0.0860 0.0845 0.0833 0.0831 0.0832 0.0836 0.0834 0.0837 0.0841 0.0843 

[TRAIN] Epoch[6](830/1500); Loss: 0.121571; Backpropagation: 0.0917 sec; Batch: 0.4301 sec
0.1347 0.1489 0.1842 0.1718 0.1554 0.1346 0.1176 0.1077 0.1046 0.1020 0.0989 0.0977 0.0972 0.0968 0.0965 0.0965 

[TRAIN] Epoch[6](831/1500); Loss: 0.138723; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1791 0.1906 0.1799 0.1713 0.1594 0.1465 0.1357 0.1271 0.1212 0.1176 0.1168 0.1159 0.1151 0.1146 0.1144 0.1144 

[TRAIN] Epoch[6](832/1500); Loss: 0.126854; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1737 0.1561 0.1419 0.1346 0.1286 0.1224 0.1173 0.1144 0.1134 0.1138 0.1139 0.1157 0.1176 0.1187 0.1217 0.1258 

[TRAIN] Epoch[6](833/1500); Loss: 0.097040; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.1350 0.1336 0.1450 0.1347 0.1205 0.1046 0.0927 0.0850 0.0793 0.0766 0.0752 0.0739 0.0732 0.0742 0.0740 0.0751 

[TRAIN] Epoch[6](834/1500); Loss: 0.093440; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.1309 0.1244 0.1185 0.1103 0.0984 0.0902 0.0883 0.0892 0.0823 0.0807 0.0815 0.0810 0.0796 0.0797 0.0796 0.0804 

[TRAIN] Epoch[6](835/1500); Loss: 0.098321; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1492 0.0418 0.1934 0.1815 0.1636 0.1338 0.1019 0.0777 0.0590 0.0527 0.0581 0.0684 0.0693 0.0705 0.0752 0.0770 

[TRAIN] Epoch[6](836/1500); Loss: 0.105804; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1351 0.1293 0.1288 0.1229 0.1141 0.1053 0.0995 0.0968 0.0966 0.0960 0.0948 0.0949 0.0943 0.0949 0.0947 0.0948 

[TRAIN] Epoch[6](837/1500); Loss: 0.133325; Backpropagation: 0.0918 sec; Batch: 0.4611 sec
0.1749 0.1562 0.1682 0.1588 0.1472 0.1337 0.1290 0.1251 0.1208 0.1183 0.1169 0.1162 0.1165 0.1164 0.1172 0.1177 

[TRAIN] Epoch[6](838/1500); Loss: 0.119407; Backpropagation: 0.0989 sec; Batch: 0.4350 sec
0.1448 0.1442 0.1371 0.1303 0.1224 0.1188 0.1145 0.1123 0.1103 0.1092 0.1083 0.1093 0.1103 0.1111 0.1130 0.1147 

[TRAIN] Epoch[6](839/1500); Loss: 0.079103; Backpropagation: 0.0923 sec; Batch: 0.4277 sec
0.1548 0.1158 0.1164 0.1102 0.0986 0.0834 0.0702 0.0628 0.0594 0.0563 0.0563 0.0557 0.0563 0.0560 0.0565 0.0569 

[TRAIN] Epoch[6](840/1500); Loss: 0.145585; Backpropagation: 0.0919 sec; Batch: 0.4260 sec
0.1956 0.1883 0.1802 0.1732 0.1636 0.1526 0.1429 0.1357 0.1305 0.1271 0.1250 0.1238 0.1229 0.1227 0.1230 0.1223 

[TRAIN] Epoch[6](841/1500); Loss: 0.133876; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.2090 0.1864 0.1759 0.1692 0.1554 0.1397 0.1295 0.1192 0.1128 0.1084 0.1070 0.1058 0.1066 0.1057 0.1056 0.1058 

[TRAIN] Epoch[6](842/1500); Loss: 0.138113; Backpropagation: 0.0921 sec; Batch: 0.4263 sec
0.1531 0.1691 0.1618 0.1520 0.1421 0.1357 0.1333 0.1334 0.1325 0.1307 0.1291 0.1287 0.1277 0.1269 0.1270 0.1267 

[TRAIN] Epoch[6](843/1500); Loss: 0.144749; Backpropagation: 0.1010 sec; Batch: 0.4356 sec
0.1790 0.1931 0.1855 0.1756 0.1641 0.1530 0.1441 0.1371 0.1313 0.1269 0.1234 0.1215 0.1208 0.1203 0.1201 0.1202 

[TRAIN] Epoch[6](844/1500); Loss: 0.096552; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1113 0.1403 0.1369 0.1244 0.1087 0.0950 0.0878 0.0851 0.0832 0.0825 0.0812 0.0816 0.0820 0.0816 0.0815 0.0817 

[TRAIN] Epoch[6](845/1500); Loss: 0.176445; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2220 0.2180 0.2153 0.2088 0.1999 0.1884 0.1777 0.1684 0.1612 0.1569 0.1536 0.1525 0.1514 0.1505 0.1498 0.1487 

[TRAIN] Epoch[6](846/1500); Loss: 0.179942; Backpropagation: 0.0917 sec; Batch: 0.4270 sec
0.2494 0.2229 0.2231 0.2183 0.2100 0.1994 0.1885 0.1797 0.1697 0.1600 0.1517 0.1454 0.1417 0.1399 0.1397 0.1397 

[TRAIN] Epoch[6](847/1500); Loss: 0.082469; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.0942 0.0892 0.1667 0.1524 0.1327 0.1046 0.0785 0.0610 0.0537 0.0542 0.0550 0.0531 0.0545 0.0549 0.0578 0.0569 

[TRAIN] Epoch[6](848/1500); Loss: 0.096423; Backpropagation: 0.0918 sec; Batch: 0.4303 sec
0.1291 0.1558 0.1454 0.1332 0.1183 0.1040 0.0914 0.0814 0.0774 0.0739 0.0719 0.0717 0.0719 0.0718 0.0726 0.0731 

[TRAIN] Epoch[6](849/1500); Loss: 0.135584; Backpropagation: 0.0917 sec; Batch: 0.4306 sec
0.1505 0.1832 0.1775 0.1661 0.1517 0.1394 0.1316 0.1276 0.1229 0.1204 0.1178 0.1172 0.1169 0.1159 0.1151 0.1154 

[TRAIN] Epoch[6](850/1500); Loss: 0.107556; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1019 0.1763 0.1838 0.1671 0.1451 0.1211 0.1006 0.0863 0.0803 0.0800 0.0795 0.0793 0.0790 0.0797 0.0808 0.0801 

[TRAIN] Epoch[6](851/1500); Loss: 0.163055; Backpropagation: 0.0918 sec; Batch: 0.4259 sec
0.2399 0.2236 0.2275 0.2213 0.2079 0.1910 0.1740 0.1593 0.1455 0.1340 0.1252 0.1179 0.1132 0.1109 0.1093 0.1083 

[TRAIN] Epoch[6](852/1500); Loss: 0.132051; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1740 0.1701 0.1594 0.1475 0.1380 0.1267 0.1159 0.1085 0.1059 0.1076 0.1133 0.1197 0.1243 0.1292 0.1341 0.1386 

[TRAIN] Epoch[6](853/1500); Loss: 0.105260; Backpropagation: 0.0917 sec; Batch: 0.4622 sec
0.1830 0.1277 0.1388 0.1354 0.1262 0.1131 0.1033 0.0965 0.0886 0.0849 0.0815 0.0814 0.0813 0.0816 0.0804 0.0806 

[TRAIN] Epoch[6](854/1500); Loss: 0.170200; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1941 0.2126 0.2092 0.2003 0.1877 0.1751 0.1641 0.1597 0.1570 0.1550 0.1532 0.1519 0.1511 0.1507 0.1504 0.1510 

[TRAIN] Epoch[6](855/1500); Loss: 0.115403; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1363 0.1257 0.1438 0.1359 0.1243 0.1123 0.1079 0.1097 0.1094 0.1067 0.1065 0.1056 0.1056 0.1054 0.1051 0.1063 

[TRAIN] Epoch[6](856/1500); Loss: 0.151921; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1806 0.1763 0.1773 0.1695 0.1600 0.1511 0.1468 0.1453 0.1452 0.1438 0.1409 0.1399 0.1401 0.1386 0.1375 0.1380 

[TRAIN] Epoch[6](857/1500); Loss: 0.087936; Backpropagation: 0.0917 sec; Batch: 0.4244 sec
0.1205 0.1064 0.1168 0.1096 0.0997 0.0886 0.0828 0.0779 0.0787 0.0767 0.0760 0.0751 0.0746 0.0744 0.0743 0.0750 

[TRAIN] Epoch[6](858/1500); Loss: 0.056476; Backpropagation: 0.0915 sec; Batch: 0.4505 sec
0.1151 0.0834 0.0742 0.0695 0.0620 0.0529 0.0458 0.0455 0.0445 0.0443 0.0437 0.0439 0.0437 0.0440 0.0451 0.0461 

[TRAIN] Epoch[6](859/1500); Loss: 0.109792; Backpropagation: 0.0935 sec; Batch: 0.4363 sec
0.1038 0.1820 0.1881 0.1707 0.1478 0.1228 0.1015 0.0869 0.0822 0.0837 0.0819 0.0806 0.0812 0.0808 0.0806 0.0822 

[TRAIN] Epoch[6](860/1500); Loss: 0.193164; Backpropagation: 0.0934 sec; Batch: 0.4262 sec
0.3309 0.2654 0.2848 0.2786 0.2620 0.2357 0.2102 0.1870 0.1610 0.1376 0.1220 0.1199 0.1256 0.1230 0.1236 0.1233 

[TRAIN] Epoch[6](861/1500); Loss: 0.123210; Backpropagation: 0.0925 sec; Batch: 0.4246 sec
0.1600 0.1875 0.1742 0.1637 0.1490 0.1335 0.1196 0.1083 0.1001 0.0963 0.0971 0.0968 0.0965 0.0957 0.0964 0.0967 

[TRAIN] Epoch[6](862/1500); Loss: 0.152946; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.2070 0.1983 0.1961 0.1880 0.1781 0.1675 0.1584 0.1506 0.1421 0.1352 0.1283 0.1232 0.1190 0.1185 0.1185 0.1183 

[TRAIN] Epoch[6](863/1500); Loss: 0.079927; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1358 0.1234 0.1306 0.1202 0.1025 0.0829 0.0692 0.0568 0.0543 0.0564 0.0576 0.0557 0.0556 0.0580 0.0599 0.0599 

[TRAIN] Epoch[6](864/1500); Loss: 0.117679; Backpropagation: 0.0916 sec; Batch: 0.4582 sec
0.1990 0.1875 0.1568 0.1368 0.1272 0.1177 0.1099 0.1034 0.0987 0.0957 0.0935 0.0918 0.0913 0.0911 0.0911 0.0916 

[TRAIN] Epoch[6](865/1500); Loss: 0.090659; Backpropagation: 0.0917 sec; Batch: 0.4268 sec
0.1203 0.1090 0.1075 0.1021 0.0953 0.0885 0.0854 0.0830 0.0826 0.0814 0.0816 0.0816 0.0828 0.0828 0.0830 0.0837 

[TRAIN] Epoch[6](866/1500); Loss: 0.130392; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1551 0.1660 0.1614 0.1527 0.1386 0.1298 0.1238 0.1201 0.1171 0.1154 0.1169 0.1166 0.1153 0.1168 0.1198 0.1208 

[TRAIN] Epoch[6](867/1500); Loss: 0.126343; Backpropagation: 0.0917 sec; Batch: 0.4497 sec
0.1480 0.1679 0.1678 0.1549 0.1385 0.1250 0.1193 0.1182 0.1134 0.1114 0.1112 0.1113 0.1107 0.1085 0.1072 0.1082 

[TRAIN] Epoch[6](868/1500); Loss: 0.066588; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1173 0.1084 0.1064 0.0957 0.0804 0.0663 0.0610 0.0564 0.0494 0.0468 0.0468 0.0466 0.0458 0.0458 0.0460 0.0463 

[TRAIN] Epoch[6](869/1500); Loss: 0.101396; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1288 0.1209 0.1625 0.1486 0.1313 0.1076 0.0898 0.0831 0.0798 0.0775 0.0795 0.0797 0.0822 0.0819 0.0831 0.0860 

[TRAIN] Epoch[6](870/1500); Loss: 0.129538; Backpropagation: 0.0916 sec; Batch: 0.4544 sec
0.1867 0.1720 0.1652 0.1580 0.1460 0.1339 0.1262 0.1175 0.1132 0.1089 0.1072 0.1071 0.1069 0.1074 0.1078 0.1085 

[TRAIN] Epoch[6](871/1500); Loss: 0.119579; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1446 0.1642 0.1629 0.1529 0.1382 0.1244 0.1137 0.1086 0.1024 0.1001 0.0993 0.1001 0.0991 0.1006 0.1009 0.1013 

[TRAIN] Epoch[6](872/1500); Loss: 0.109562; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1884 0.1323 0.1393 0.1352 0.1256 0.1108 0.0989 0.0926 0.0925 0.0928 0.0918 0.0904 0.0908 0.0906 0.0903 0.0907 

[TRAIN] Epoch[6](873/1500); Loss: 0.084529; Backpropagation: 0.0916 sec; Batch: 0.4260 sec
0.2235 0.1351 0.1535 0.1484 0.1309 0.1008 0.0668 0.0433 0.0459 0.0468 0.0457 0.0420 0.0423 0.0432 0.0430 0.0413 

[TRAIN] Epoch[6](874/1500); Loss: 0.069095; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1056 0.0934 0.0839 0.0787 0.0735 0.0668 0.0612 0.0619 0.0600 0.0601 0.0589 0.0606 0.0602 0.0596 0.0602 0.0609 

[TRAIN] Epoch[6](875/1500); Loss: 0.146385; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1773 0.2129 0.2022 0.1879 0.1711 0.1555 0.1423 0.1323 0.1250 0.1195 0.1205 0.1198 0.1195 0.1186 0.1185 0.1191 

[TRAIN] Epoch[6](876/1500); Loss: 0.179996; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2715 0.2354 0.2377 0.2318 0.2216 0.2075 0.1909 0.1753 0.1607 0.1480 0.1385 0.1326 0.1316 0.1322 0.1328 0.1318 

[TRAIN] Epoch[6](877/1500); Loss: 0.165003; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2138 0.1929 0.1901 0.1860 0.1809 0.1753 0.1687 0.1608 0.1556 0.1510 0.1473 0.1447 0.1439 0.1431 0.1436 0.1424 

[TRAIN] Epoch[6](878/1500); Loss: 0.094525; Backpropagation: 0.0916 sec; Batch: 0.4493 sec
0.1292 0.1486 0.1384 0.1267 0.1046 0.0907 0.0863 0.0828 0.0737 0.0735 0.0777 0.0738 0.0715 0.0749 0.0815 0.0786 

[TRAIN] Epoch[6](879/1500); Loss: 0.057579; Backpropagation: 0.0916 sec; Batch: 0.4586 sec
0.1567 0.0620 0.0807 0.0770 0.0655 0.0461 0.0445 0.0476 0.0432 0.0426 0.0425 0.0422 0.0415 0.0416 0.0441 0.0434 

[TRAIN] Epoch[6](880/1500); Loss: 0.163790; Backpropagation: 0.0915 sec; Batch: 0.4630 sec
0.2104 0.1923 0.1779 0.1744 0.1694 0.1655 0.1600 0.1577 0.1553 0.1533 0.1518 0.1518 0.1503 0.1499 0.1506 0.1499 

[TRAIN] Epoch[6](881/1500); Loss: 0.058741; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1031 0.0639 0.0599 0.0581 0.0561 0.0547 0.0562 0.0505 0.0522 0.0514 0.0526 0.0536 0.0549 0.0555 0.0579 0.0591 

[TRAIN] Epoch[6](882/1500); Loss: 0.146563; Backpropagation: 0.0915 sec; Batch: 0.4259 sec
0.1796 0.1781 0.1761 0.1681 0.1574 0.1481 0.1436 0.1382 0.1352 0.1333 0.1325 0.1315 0.1315 0.1304 0.1306 0.1308 

[TRAIN] Epoch[6](883/1500); Loss: 0.106472; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1471 0.1871 0.1718 0.1546 0.1339 0.1153 0.0991 0.0866 0.0780 0.0752 0.0759 0.0739 0.0745 0.0753 0.0771 0.0780 

[TRAIN] Epoch[6](884/1500); Loss: 0.175228; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.1911 0.2177 0.2109 0.2013 0.1894 0.1782 0.1686 0.1624 0.1596 0.1612 0.1605 0.1612 0.1605 0.1609 0.1602 0.1598 

[TRAIN] Epoch[6](885/1500); Loss: 0.160788; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.2247 0.2084 0.2026 0.1946 0.1837 0.1723 0.1599 0.1500 0.1421 0.1377 0.1359 0.1330 0.1317 0.1319 0.1320 0.1320 

[TRAIN] Epoch[6](886/1500); Loss: 0.103003; Backpropagation: 0.0916 sec; Batch: 0.4494 sec
0.1162 0.1384 0.1323 0.1215 0.1092 0.1000 0.0973 0.0963 0.0934 0.0926 0.0925 0.0916 0.0913 0.0917 0.0918 0.0920 

[TRAIN] Epoch[6](887/1500); Loss: 0.092941; Backpropagation: 0.0917 sec; Batch: 0.4470 sec
0.1253 0.1201 0.1314 0.1228 0.1100 0.0965 0.0873 0.0836 0.0797 0.0766 0.0756 0.0755 0.0754 0.0754 0.0759 0.0758 

[TRAIN] Epoch[6](888/1500); Loss: 0.136255; Backpropagation: 0.0983 sec; Batch: 0.4358 sec
0.2963 0.2076 0.2309 0.2275 0.2113 0.1817 0.1453 0.1102 0.0800 0.0655 0.0699 0.0720 0.0698 0.0684 0.0710 0.0726 

[TRAIN] Epoch[6](889/1500); Loss: 0.153168; Backpropagation: 0.0930 sec; Batch: 0.4245 sec
0.2182 0.1924 0.2072 0.2010 0.1876 0.1706 0.1547 0.1437 0.1344 0.1251 0.1202 0.1181 0.1184 0.1189 0.1197 0.1205 

[TRAIN] Epoch[6](890/1500); Loss: 0.151251; Backpropagation: 0.0916 sec; Batch: 0.4439 sec
0.2652 0.2467 0.2176 0.2053 0.1863 0.1679 0.1510 0.1363 0.1220 0.1136 0.1078 0.1008 0.0992 0.1000 0.1001 0.1001 

[TRAIN] Epoch[6](891/1500); Loss: 0.065189; Backpropagation: 0.0916 sec; Batch: 0.4309 sec
0.1483 0.0833 0.0691 0.0589 0.0585 0.0529 0.0536 0.0532 0.0543 0.0553 0.0552 0.0577 0.0577 0.0598 0.0619 0.0632 

[TRAIN] Epoch[6](892/1500); Loss: 0.092918; Backpropagation: 0.0915 sec; Batch: 0.4545 sec
0.1388 0.1517 0.1323 0.1167 0.1026 0.0909 0.0815 0.0749 0.0720 0.0717 0.0743 0.0736 0.0743 0.0758 0.0771 0.0784 

[TRAIN] Epoch[6](893/1500); Loss: 0.067430; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1889 0.0644 0.0995 0.1065 0.0866 0.0565 0.0297 0.0365 0.0561 0.0526 0.0443 0.0386 0.0471 0.0639 0.0549 0.0527 

[TRAIN] Epoch[6](894/1500); Loss: 0.115196; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.1395 0.1395 0.1375 0.1294 0.1216 0.1143 0.1107 0.1090 0.1060 0.1055 0.1053 0.1053 0.1046 0.1049 0.1046 0.1054 

[TRAIN] Epoch[6](895/1500); Loss: 0.076421; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0997 0.1190 0.1103 0.0979 0.0837 0.0748 0.0683 0.0656 0.0645 0.0629 0.0626 0.0624 0.0625 0.0626 0.0628 0.0632 

[TRAIN] Epoch[6](896/1500); Loss: 0.129659; Backpropagation: 0.0920 sec; Batch: 0.4229 sec
0.2112 0.1627 0.1666 0.1630 0.1551 0.1433 0.1305 0.1187 0.1079 0.1031 0.1044 0.1019 0.1013 0.1011 0.1029 0.1009 

[TRAIN] Epoch[6](897/1500); Loss: 0.108822; Backpropagation: 0.0920 sec; Batch: 0.4250 sec
0.1356 0.1726 0.1697 0.1578 0.1385 0.1214 0.1049 0.0925 0.0863 0.0778 0.0749 0.0758 0.0774 0.0797 0.0852 0.0911 

[TRAIN] Epoch[6](898/1500); Loss: 0.104657; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1884 0.1326 0.1563 0.1514 0.1388 0.1177 0.0965 0.0817 0.0762 0.0795 0.0770 0.0751 0.0752 0.0769 0.0760 0.0753 

[TRAIN] Epoch[6](899/1500); Loss: 0.095225; Backpropagation: 0.0916 sec; Batch: 0.4460 sec
0.1659 0.1407 0.1411 0.1316 0.1170 0.0991 0.0823 0.0751 0.0769 0.0734 0.0719 0.0710 0.0703 0.0695 0.0687 0.0691 

[TRAIN] Epoch[6](900/1500); Loss: 0.054078; Backpropagation: 0.0918 sec; Batch: 0.4270 sec
0.0914 0.0617 0.0526 0.0491 0.0490 0.0469 0.0481 0.0486 0.0475 0.0507 0.0497 0.0500 0.0531 0.0534 0.0550 0.0586 

[TRAIN] Epoch[6](901/1500); Loss: 0.123724; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.1539 0.1591 0.1513 0.1398 0.1286 0.1219 0.1191 0.1148 0.1129 0.1122 0.1117 0.1115 0.1111 0.1106 0.1109 0.1103 

[TRAIN] Epoch[6](902/1500); Loss: 0.112394; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1177 0.0925 0.1933 0.1782 0.1612 0.1343 0.1075 0.0890 0.0813 0.0857 0.0877 0.0890 0.0910 0.0962 0.0971 0.0966 

[TRAIN] Epoch[6](903/1500); Loss: 0.087090; Backpropagation: 0.0918 sec; Batch: 0.4253 sec
0.1056 0.1177 0.1072 0.0969 0.0895 0.0844 0.0800 0.0796 0.0792 0.0783 0.0784 0.0788 0.0790 0.0791 0.0796 0.0803 

[TRAIN] Epoch[6](904/1500); Loss: 0.087971; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1416 0.1353 0.1312 0.1196 0.1044 0.0904 0.0832 0.0752 0.0688 0.0672 0.0677 0.0656 0.0644 0.0644 0.0649 0.0637 

[TRAIN] Epoch[6](905/1500); Loss: 0.110164; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1508 0.1344 0.1534 0.1429 0.1279 0.1086 0.0984 0.0989 0.0976 0.0938 0.0940 0.0934 0.0923 0.0914 0.0920 0.0926 

[TRAIN] Epoch[6](906/1500); Loss: 0.226026; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3622 0.2966 0.2986 0.2938 0.2821 0.2573 0.2264 0.1943 0.1771 0.1764 0.1790 0.1712 0.1752 0.1762 0.1736 0.1765 

[TRAIN] Epoch[6](907/1500); Loss: 0.142022; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1889 0.2209 0.2008 0.1842 0.1620 0.1423 0.1312 0.1260 0.1176 0.1153 0.1151 0.1150 0.1144 0.1136 0.1125 0.1126 

[TRAIN] Epoch[6](908/1500); Loss: 0.123659; Backpropagation: 0.0918 sec; Batch: 0.4253 sec
0.1723 0.2077 0.2023 0.1823 0.1564 0.1289 0.1061 0.0937 0.0934 0.0948 0.0895 0.0889 0.0907 0.0935 0.0895 0.0886 

[TRAIN] Epoch[6](909/1500); Loss: 0.164852; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.2728 0.2104 0.2335 0.2301 0.2168 0.1949 0.1718 0.1512 0.1323 0.1214 0.1175 0.1175 0.1166 0.1160 0.1172 0.1176 

[TRAIN] Epoch[6](910/1500); Loss: 0.150000; Backpropagation: 0.0915 sec; Batch: 0.4227 sec
0.2083 0.1913 0.1797 0.1682 0.1579 0.1486 0.1427 0.1401 0.1376 0.1348 0.1332 0.1337 0.1316 0.1312 0.1303 0.1306 

[TRAIN] Epoch[6](911/1500); Loss: 0.106198; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1817 0.1258 0.1324 0.1282 0.1187 0.1056 0.0941 0.0906 0.0913 0.0912 0.0900 0.0897 0.0899 0.0903 0.0898 0.0899 

[TRAIN] Epoch[6](912/1500); Loss: 0.076585; Backpropagation: 0.0916 sec; Batch: 0.4586 sec
0.0967 0.1035 0.1024 0.0919 0.0802 0.0730 0.0709 0.0662 0.0658 0.0653 0.0663 0.0674 0.0672 0.0677 0.0701 0.0708 

[TRAIN] Epoch[6](913/1500); Loss: 0.091775; Backpropagation: 0.0916 sec; Batch: 0.4267 sec
0.1242 0.1217 0.1221 0.1118 0.0973 0.0850 0.0831 0.0852 0.0809 0.0809 0.0806 0.0798 0.0788 0.0792 0.0789 0.0787 

[TRAIN] Epoch[6](914/1500); Loss: 0.077363; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1151 0.0967 0.0917 0.0875 0.0823 0.0785 0.0725 0.0715 0.0694 0.0685 0.0679 0.0675 0.0671 0.0670 0.0672 0.0674 

[TRAIN] Epoch[6](915/1500); Loss: 0.114702; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1616 0.2142 0.2035 0.1818 0.1527 0.1220 0.0952 0.0806 0.0800 0.0815 0.0768 0.0766 0.0780 0.0775 0.0757 0.0773 

[TRAIN] Epoch[6](916/1500); Loss: 0.119147; Backpropagation: 0.0916 sec; Batch: 0.4267 sec
0.1632 0.1395 0.1758 0.1660 0.1504 0.1271 0.1070 0.0993 0.0984 0.0972 0.0949 0.0965 0.0983 0.0979 0.0963 0.0985 

[TRAIN] Epoch[6](917/1500); Loss: 0.067364; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.1420 0.0861 0.0963 0.0920 0.0818 0.0691 0.0602 0.0527 0.0489 0.0512 0.0496 0.0496 0.0486 0.0495 0.0497 0.0507 

[TRAIN] Epoch[6](918/1500); Loss: 0.184424; Backpropagation: 0.1011 sec; Batch: 0.4374 sec
0.2992 0.2362 0.2582 0.2558 0.2425 0.2218 0.2001 0.1808 0.1636 0.1464 0.1327 0.1247 0.1217 0.1211 0.1232 0.1227 

[TRAIN] Epoch[6](919/1500); Loss: 0.088485; Backpropagation: 0.0922 sec; Batch: 0.4251 sec
0.1244 0.1390 0.1247 0.1132 0.1001 0.0874 0.0789 0.0750 0.0733 0.0724 0.0716 0.0710 0.0709 0.0710 0.0712 0.0714 

[TRAIN] Epoch[6](920/1500); Loss: 0.137044; Backpropagation: 0.0923 sec; Batch: 0.4236 sec
0.1597 0.1721 0.1727 0.1634 0.1482 0.1368 0.1303 0.1271 0.1250 0.1219 0.1218 0.1212 0.1228 0.1227 0.1229 0.1241 

[TRAIN] Epoch[6](921/1500); Loss: 0.108549; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1725 0.1446 0.1305 0.1231 0.1138 0.1057 0.1010 0.0986 0.0948 0.0939 0.0928 0.0926 0.0928 0.0927 0.0936 0.0939 

[TRAIN] Epoch[6](922/1500); Loss: 0.114437; Backpropagation: 0.0919 sec; Batch: 0.4253 sec
0.1604 0.1522 0.1407 0.1294 0.1211 0.1166 0.1129 0.1075 0.1025 0.1002 0.0981 0.0974 0.0975 0.0979 0.0979 0.0986 

[TRAIN] Epoch[6](923/1500); Loss: 0.078115; Backpropagation: 0.0918 sec; Batch: 0.4594 sec
0.1361 0.1027 0.1140 0.1067 0.0943 0.0790 0.0692 0.0649 0.0617 0.0609 0.0600 0.0602 0.0596 0.0596 0.0602 0.0607 

[TRAIN] Epoch[6](924/1500); Loss: 0.071186; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1122 0.0937 0.0950 0.0862 0.0738 0.0654 0.0648 0.0621 0.0594 0.0591 0.0603 0.0611 0.0595 0.0614 0.0620 0.0629 

[TRAIN] Epoch[6](925/1500); Loss: 0.155648; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.1653 0.2045 0.2004 0.1871 0.1706 0.1565 0.1470 0.1443 0.1417 0.1409 0.1412 0.1387 0.1379 0.1386 0.1381 0.1375 

[TRAIN] Epoch[6](926/1500); Loss: 0.055873; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.0814 0.0765 0.0605 0.0595 0.0553 0.0535 0.0511 0.0498 0.0486 0.0498 0.0505 0.0501 0.0508 0.0514 0.0524 0.0526 

[TRAIN] Epoch[6](927/1500); Loss: 0.160995; Backpropagation: 0.0989 sec; Batch: 0.4348 sec
0.1777 0.1809 0.1757 0.1686 0.1614 0.1585 0.1591 0.1567 0.1565 0.1563 0.1547 0.1543 0.1547 0.1539 0.1538 0.1532 

[TRAIN] Epoch[6](928/1500); Loss: 0.079515; Backpropagation: 0.0922 sec; Batch: 0.4254 sec
0.1318 0.1117 0.1090 0.0995 0.0870 0.0735 0.0685 0.0672 0.0658 0.0650 0.0660 0.0654 0.0649 0.0650 0.0655 0.0664 

[TRAIN] Epoch[6](929/1500); Loss: 0.151462; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2333 0.1973 0.2241 0.2169 0.2007 0.1787 0.1567 0.1401 0.1235 0.1157 0.1078 0.1067 0.1063 0.1054 0.1053 0.1050 

[TRAIN] Epoch[6](930/1500); Loss: 0.128561; Backpropagation: 0.0917 sec; Batch: 0.4611 sec
0.1526 0.2064 0.2113 0.1943 0.1711 0.1451 0.1207 0.1026 0.0933 0.0923 0.0947 0.0926 0.0928 0.0936 0.0978 0.0958 

[TRAIN] Epoch[6](931/1500); Loss: 0.140175; Backpropagation: 0.0919 sec; Batch: 0.4270 sec
0.1425 0.1737 0.1719 0.1609 0.1481 0.1384 0.1334 0.1336 0.1327 0.1311 0.1305 0.1303 0.1289 0.1293 0.1294 0.1279 

[TRAIN] Epoch[6](932/1500); Loss: 0.159739; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1973 0.1985 0.1974 0.1893 0.1773 0.1647 0.1582 0.1507 0.1441 0.1407 0.1426 0.1410 0.1387 0.1373 0.1393 0.1387 

[TRAIN] Epoch[6](933/1500); Loss: 0.113891; Backpropagation: 0.0921 sec; Batch: 0.4257 sec
0.1465 0.1584 0.1911 0.1756 0.1557 0.1278 0.1056 0.0961 0.0861 0.0831 0.0826 0.0822 0.0817 0.0831 0.0828 0.0839 

[TRAIN] Epoch[6](934/1500); Loss: 0.107013; Backpropagation: 0.0918 sec; Batch: 0.4269 sec
0.1400 0.1266 0.1354 0.1281 0.1178 0.1070 0.1017 0.0974 0.0969 0.0954 0.0940 0.0939 0.0942 0.0945 0.0946 0.0949 

[TRAIN] Epoch[6](935/1500); Loss: 0.130327; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1552 0.1308 0.1953 0.1834 0.1690 0.1444 0.1223 0.1130 0.1168 0.1119 0.1091 0.1083 0.1092 0.1058 0.1052 0.1054 

[TRAIN] Epoch[6](936/1500); Loss: 0.074660; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1287 0.1135 0.0787 0.0659 0.0650 0.0663 0.0654 0.0653 0.0653 0.0676 0.0671 0.0671 0.0681 0.0696 0.0704 0.0705 

[TRAIN] Epoch[6](937/1500); Loss: 0.074675; Backpropagation: 0.0923 sec; Batch: 0.4258 sec
0.0727 0.1469 0.1387 0.1206 0.0946 0.0705 0.0575 0.0589 0.0572 0.0548 0.0541 0.0560 0.0531 0.0528 0.0531 0.0533 

[TRAIN] Epoch[6](938/1500); Loss: 0.121511; Backpropagation: 0.0918 sec; Batch: 0.4308 sec
0.1985 0.1378 0.1445 0.1422 0.1335 0.1211 0.1135 0.1092 0.1064 0.1053 0.1051 0.1051 0.1055 0.1050 0.1055 0.1060 

[TRAIN] Epoch[6](939/1500); Loss: 0.100687; Backpropagation: 0.0918 sec; Batch: 0.4259 sec
0.1342 0.1666 0.1573 0.1388 0.1155 0.0967 0.0895 0.0788 0.0762 0.0780 0.0789 0.0767 0.0780 0.0811 0.0821 0.0825 

[TRAIN] Epoch[6](940/1500); Loss: 0.116167; Backpropagation: 0.0917 sec; Batch: 0.4269 sec
0.2561 0.1627 0.1854 0.1815 0.1658 0.1376 0.1088 0.0867 0.0736 0.0755 0.0726 0.0726 0.0703 0.0705 0.0701 0.0689 

[TRAIN] Epoch[6](941/1500); Loss: 0.091067; Backpropagation: 0.0918 sec; Batch: 0.4588 sec
0.1468 0.0356 0.1909 0.1773 0.1589 0.1269 0.0909 0.0593 0.0396 0.0469 0.0739 0.0698 0.0616 0.0549 0.0572 0.0668 

[TRAIN] Epoch[6](942/1500); Loss: 0.104646; Backpropagation: 0.0918 sec; Batch: 0.4316 sec
0.1658 0.1272 0.1721 0.1643 0.1492 0.1249 0.0982 0.0779 0.0698 0.0778 0.0739 0.0729 0.0733 0.0774 0.0753 0.0743 

[TRAIN] Epoch[6](943/1500); Loss: 0.190536; Backpropagation: 0.0918 sec; Batch: 0.4264 sec
0.3670 0.2849 0.3043 0.2991 0.2804 0.2481 0.2131 0.1772 0.1380 0.1090 0.0986 0.1162 0.1000 0.1023 0.1025 0.1081 

[TRAIN] Epoch[6](944/1500); Loss: 0.236321; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.3346 0.3146 0.3037 0.2881 0.2720 0.2535 0.2349 0.2182 0.2054 0.1973 0.1935 0.1890 0.1902 0.1939 0.1959 0.1961 

[TRAIN] Epoch[6](945/1500); Loss: 0.085373; Backpropagation: 0.0917 sec; Batch: 0.4267 sec
0.1187 0.1296 0.1170 0.1050 0.0921 0.0822 0.0757 0.0729 0.0728 0.0712 0.0710 0.0711 0.0712 0.0715 0.0718 0.0721 

[TRAIN] Epoch[6](946/1500); Loss: 0.131731; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1474 0.1452 0.1415 0.1356 0.1298 0.1276 0.1284 0.1268 0.1271 0.1278 0.1275 0.1279 0.1279 0.1284 0.1293 0.1294 

[TRAIN] Epoch[6](947/1500); Loss: 0.169171; Backpropagation: 0.0918 sec; Batch: 0.4266 sec
0.2631 0.2665 0.2503 0.2365 0.2165 0.1951 0.1740 0.1534 0.1365 0.1252 0.1195 0.1148 0.1130 0.1131 0.1140 0.1153 

[TRAIN] Epoch[6](948/1500); Loss: 0.104895; Backpropagation: 0.0918 sec; Batch: 0.4246 sec
0.1908 0.1375 0.1713 0.1648 0.1502 0.1262 0.1006 0.0796 0.0680 0.0718 0.0708 0.0680 0.0674 0.0704 0.0714 0.0696 

[TRAIN] Epoch[6](949/1500); Loss: 0.108805; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1371 0.1663 0.1635 0.1512 0.1335 0.1173 0.1027 0.0928 0.0873 0.0841 0.0842 0.0834 0.0833 0.0841 0.0847 0.0852 

[TRAIN] Epoch[6](950/1500); Loss: 0.074585; Backpropagation: 0.0920 sec; Batch: 0.4268 sec
0.0975 0.1190 0.1100 0.0964 0.0813 0.0715 0.0678 0.0630 0.0611 0.0603 0.0599 0.0604 0.0605 0.0606 0.0618 0.0624 

[TRAIN] Epoch[6](951/1500); Loss: 0.152525; Backpropagation: 0.0918 sec; Batch: 0.4424 sec
0.2091 0.1832 0.1852 0.1802 0.1727 0.1626 0.1539 0.1457 0.1397 0.1359 0.1322 0.1300 0.1286 0.1281 0.1269 0.1264 

[TRAIN] Epoch[6](952/1500); Loss: 0.117065; Backpropagation: 0.0916 sec; Batch: 0.4274 sec
0.1389 0.1374 0.1491 0.1402 0.1296 0.1194 0.1111 0.1078 0.1043 0.1055 0.1048 0.1041 0.1031 0.1048 0.1060 0.1070 

[TRAIN] Epoch[6](953/1500); Loss: 0.109835; Backpropagation: 0.0918 sec; Batch: 0.4272 sec
0.1437 0.1827 0.1820 0.1665 0.1428 0.1193 0.1036 0.0972 0.0863 0.0814 0.0775 0.0764 0.0733 0.0743 0.0744 0.0758 

[TRAIN] Epoch[6](954/1500); Loss: 0.157317; Backpropagation: 0.0919 sec; Batch: 0.4269 sec
0.2046 0.1969 0.1972 0.1887 0.1772 0.1653 0.1558 0.1508 0.1453 0.1382 0.1353 0.1337 0.1321 0.1320 0.1320 0.1319 

[TRAIN] Epoch[6](955/1500); Loss: 0.164713; Backpropagation: 0.0920 sec; Batch: 0.4265 sec
0.2343 0.2205 0.2201 0.2107 0.1968 0.1822 0.1709 0.1595 0.1486 0.1385 0.1313 0.1258 0.1238 0.1238 0.1242 0.1244 

[TRAIN] Epoch[6](956/1500); Loss: 0.102668; Backpropagation: 0.0922 sec; Batch: 0.4276 sec
0.1559 0.1577 0.1490 0.1351 0.1185 0.1042 0.0956 0.0881 0.0858 0.0825 0.0796 0.0778 0.0777 0.0772 0.0792 0.0789 

[TRAIN] Epoch[6](957/1500); Loss: 0.120867; Backpropagation: 0.0920 sec; Batch: 0.4259 sec
0.1628 0.2033 0.1885 0.1730 0.1513 0.1295 0.1109 0.0978 0.0900 0.0890 0.0903 0.0894 0.0887 0.0889 0.0903 0.0902 

[TRAIN] Epoch[6](958/1500); Loss: 0.113452; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1695 0.1423 0.1363 0.1309 0.1178 0.1062 0.1039 0.1008 0.1008 0.1005 0.1000 0.1000 0.1005 0.1014 0.1020 0.1022 

[TRAIN] Epoch[6](959/1500); Loss: 0.133944; Backpropagation: 0.0919 sec; Batch: 0.4273 sec
0.1769 0.1561 0.1546 0.1478 0.1388 0.1314 0.1267 0.1235 0.1231 0.1234 0.1225 0.1229 0.1235 0.1235 0.1239 0.1244 

[TRAIN] Epoch[6](960/1500); Loss: 0.169099; Backpropagation: 0.1001 sec; Batch: 0.4363 sec
0.2273 0.2210 0.2164 0.2026 0.1871 0.1721 0.1620 0.1529 0.1499 0.1478 0.1467 0.1435 0.1432 0.1438 0.1444 0.1447 

[TRAIN] Epoch[6](961/1500); Loss: 0.146304; Backpropagation: 0.0919 sec; Batch: 0.4445 sec
0.1796 0.1826 0.1893 0.1776 0.1622 0.1495 0.1403 0.1326 0.1286 0.1273 0.1271 0.1267 0.1279 0.1292 0.1302 0.1303 

[TRAIN] Epoch[6](962/1500); Loss: 0.108858; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1533 0.1300 0.1763 0.1666 0.1510 0.1278 0.1042 0.0859 0.0787 0.0813 0.0815 0.0796 0.0797 0.0819 0.0820 0.0819 

[TRAIN] Epoch[6](963/1500); Loss: 0.144057; Backpropagation: 0.0917 sec; Batch: 0.4256 sec
0.1705 0.2175 0.2237 0.2046 0.1780 0.1508 0.1304 0.1200 0.1187 0.1150 0.1143 0.1118 0.1124 0.1127 0.1133 0.1113 

[TRAIN] Epoch[6](964/1500); Loss: 0.184406; Backpropagation: 0.0919 sec; Batch: 0.4266 sec
0.2055 0.2231 0.2274 0.2168 0.2021 0.1874 0.1776 0.1719 0.1695 0.1697 0.1698 0.1686 0.1676 0.1657 0.1638 0.1641 

[TRAIN] Epoch[6](965/1500); Loss: 0.104395; Backpropagation: 0.0918 sec; Batch: 0.4662 sec
0.1458 0.1849 0.1751 0.1583 0.1375 0.1172 0.1002 0.0864 0.0783 0.0731 0.0709 0.0691 0.0683 0.0681 0.0687 0.0686 

[TRAIN] Epoch[6](966/1500); Loss: 0.112101; Backpropagation: 0.0917 sec; Batch: 0.4305 sec
0.1363 0.1349 0.1275 0.1197 0.1125 0.1078 0.1069 0.1045 0.1046 0.1048 0.1045 0.1053 0.1053 0.1060 0.1063 0.1068 

[TRAIN] Epoch[6](967/1500); Loss: 0.105478; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1279 0.1272 0.1153 0.1101 0.1066 0.1046 0.1034 0.1008 0.1000 0.0991 0.0990 0.0985 0.0987 0.0984 0.0988 0.0991 

[TRAIN] Epoch[6](968/1500); Loss: 0.174955; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2229 0.2114 0.2193 0.2100 0.1973 0.1822 0.1730 0.1674 0.1620 0.1565 0.1530 0.1508 0.1495 0.1487 0.1482 0.1471 

[TRAIN] Epoch[6](969/1500); Loss: 0.151574; Backpropagation: 0.0921 sec; Batch: 0.4260 sec
0.1913 0.1852 0.1851 0.1757 0.1631 0.1510 0.1446 0.1426 0.1388 0.1389 0.1371 0.1354 0.1351 0.1345 0.1333 0.1335 

[TRAIN] Epoch[6](970/1500); Loss: 0.096130; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1380 0.1727 0.1619 0.1434 0.1201 0.0987 0.0829 0.0737 0.0717 0.0701 0.0683 0.0673 0.0674 0.0673 0.0675 0.0672 

[TRAIN] Epoch[6](971/1500); Loss: 0.136915; Backpropagation: 0.0917 sec; Batch: 0.4622 sec
0.1626 0.1735 0.1714 0.1612 0.1486 0.1377 0.1290 0.1227 0.1203 0.1190 0.1199 0.1206 0.1221 0.1248 0.1271 0.1301 

[TRAIN] Epoch[6](972/1500); Loss: 0.126190; Backpropagation: 0.0917 sec; Batch: 0.4264 sec
0.1488 0.1455 0.1441 0.1382 0.1306 0.1274 0.1249 0.1212 0.1195 0.1180 0.1175 0.1168 0.1168 0.1166 0.1167 0.1165 

[TRAIN] Epoch[6](973/1500); Loss: 0.098779; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1426 0.1150 0.1403 0.1330 0.1207 0.1078 0.0975 0.0875 0.0819 0.0791 0.0772 0.0776 0.0788 0.0797 0.0802 0.0815 

[TRAIN] Epoch[6](974/1500); Loss: 0.099479; Backpropagation: 0.0917 sec; Batch: 0.4623 sec
0.2024 0.1405 0.1493 0.1448 0.1331 0.1152 0.0981 0.0806 0.0667 0.0654 0.0668 0.0667 0.0652 0.0657 0.0656 0.0654 

[TRAIN] Epoch[6](975/1500); Loss: 0.109858; Backpropagation: 0.0917 sec; Batch: 0.4262 sec
0.1576 0.1661 0.1538 0.1389 0.1234 0.1094 0.0990 0.0928 0.0900 0.0899 0.0890 0.0893 0.0890 0.0891 0.0898 0.0906 

[TRAIN] Epoch[6](976/1500); Loss: 0.130691; Backpropagation: 0.0918 sec; Batch: 0.4280 sec
0.1882 0.1590 0.1599 0.1534 0.1431 0.1316 0.1245 0.1197 0.1163 0.1146 0.1149 0.1137 0.1134 0.1130 0.1124 0.1132 

[TRAIN] Epoch[6](977/1500); Loss: 0.092798; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1376 0.1197 0.1187 0.1109 0.1015 0.0930 0.0862 0.0810 0.0802 0.0800 0.0795 0.0785 0.0791 0.0798 0.0796 0.0795 

[TRAIN] Epoch[6](978/1500); Loss: 0.140445; Backpropagation: 0.0916 sec; Batch: 0.4605 sec
0.1716 0.1530 0.1721 0.1623 0.1521 0.1387 0.1314 0.1317 0.1294 0.1287 0.1292 0.1298 0.1283 0.1289 0.1295 0.1305 

[TRAIN] Epoch[6](979/1500); Loss: 0.112806; Backpropagation: 0.0921 sec; Batch: 0.4273 sec
0.1586 0.2186 0.2082 0.1864 0.1560 0.1246 0.0968 0.0800 0.0783 0.0753 0.0712 0.0712 0.0713 0.0707 0.0688 0.0691 

[TRAIN] Epoch[6](980/1500); Loss: 0.145517; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.1876 0.1768 0.2136 0.2020 0.1850 0.1619 0.1410 0.1268 0.1173 0.1160 0.1190 0.1177 0.1150 0.1157 0.1162 0.1169 

[TRAIN] Epoch[6](981/1500); Loss: 0.136459; Backpropagation: 0.0921 sec; Batch: 0.4265 sec
0.3286 0.2237 0.2509 0.2483 0.2319 0.2000 0.1625 0.1239 0.0837 0.0533 0.0414 0.0475 0.0486 0.0476 0.0460 0.0454 

[TRAIN] Epoch[6](982/1500); Loss: 0.190467; Backpropagation: 0.0935 sec; Batch: 0.4375 sec
0.4105 0.3033 0.3256 0.3222 0.3039 0.2686 0.2266 0.1827 0.1331 0.0919 0.0713 0.0900 0.0788 0.0806 0.0780 0.0806 

[TRAIN] Epoch[6](983/1500); Loss: 0.086447; Backpropagation: 0.0933 sec; Batch: 0.4244 sec
0.1897 0.1087 0.1180 0.1149 0.1003 0.0817 0.0734 0.0681 0.0646 0.0625 0.0623 0.0661 0.0679 0.0663 0.0686 0.0702 

[TRAIN] Epoch[6](984/1500); Loss: 0.139296; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1835 0.1892 0.1770 0.1672 0.1512 0.1384 0.1297 0.1236 0.1225 0.1225 0.1212 0.1198 0.1200 0.1204 0.1209 0.1216 

[TRAIN] Epoch[6](985/1500); Loss: 0.098782; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1163 0.1342 0.1261 0.1156 0.1051 0.0972 0.0918 0.0885 0.0886 0.0876 0.0875 0.0879 0.0879 0.0883 0.0886 0.0892 

[TRAIN] Epoch[6](986/1500); Loss: 0.135260; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1733 0.2223 0.2204 0.2034 0.1802 0.1560 0.1332 0.1146 0.1018 0.0946 0.0966 0.0942 0.0923 0.0929 0.0943 0.0942 

[TRAIN] Epoch[6](987/1500); Loss: 0.087601; Backpropagation: 0.0920 sec; Batch: 0.4272 sec
0.1179 0.1193 0.1124 0.1024 0.0922 0.0845 0.0809 0.0776 0.0765 0.0761 0.0763 0.0762 0.0764 0.0771 0.0775 0.0783 

[TRAIN] Epoch[6](988/1500); Loss: 0.081326; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1272 0.1042 0.0999 0.0921 0.0823 0.0761 0.0753 0.0740 0.0714 0.0708 0.0708 0.0709 0.0706 0.0716 0.0716 0.0724 

[TRAIN] Epoch[6](989/1500); Loss: 0.127517; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1499 0.1569 0.1660 0.1535 0.1393 0.1263 0.1183 0.1152 0.1166 0.1149 0.1148 0.1131 0.1132 0.1135 0.1144 0.1144 

[TRAIN] Epoch[6](990/1500); Loss: 0.092300; Backpropagation: 0.0918 sec; Batch: 0.4251 sec
0.1467 0.0353 0.1930 0.1795 0.1612 0.1297 0.0952 0.0651 0.0430 0.0430 0.0624 0.0725 0.0638 0.0608 0.0603 0.0655 

[TRAIN] Epoch[6](991/1500); Loss: 0.154163; Backpropagation: 0.0917 sec; Batch: 0.4550 sec
0.1978 0.2074 0.2164 0.2046 0.1896 0.1712 0.1544 0.1417 0.1329 0.1247 0.1218 0.1213 0.1211 0.1203 0.1205 0.1208 

[TRAIN] Epoch[6](992/1500); Loss: 0.148424; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1960 0.2110 0.2060 0.1930 0.1779 0.1621 0.1478 0.1359 0.1287 0.1232 0.1213 0.1177 0.1143 0.1129 0.1135 0.1136 

[TRAIN] Epoch[6](993/1500); Loss: 0.119824; Backpropagation: 0.0918 sec; Batch: 0.4254 sec
0.1448 0.1445 0.1488 0.1383 0.1281 0.1189 0.1130 0.1120 0.1105 0.1096 0.1078 0.1082 0.1078 0.1079 0.1078 0.1091 

[TRAIN] Epoch[6](994/1500); Loss: 0.064495; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1558 0.0785 0.0885 0.0829 0.0710 0.0538 0.0540 0.0527 0.0520 0.0504 0.0514 0.0478 0.0472 0.0479 0.0500 0.0483 

[TRAIN] Epoch[6](995/1500); Loss: 0.138634; Backpropagation: 0.0917 sec; Batch: 0.4260 sec
0.1854 0.1974 0.2154 0.1972 0.1749 0.1478 0.1261 0.1151 0.1118 0.1125 0.1065 0.1057 0.1053 0.1065 0.1059 0.1047 

[TRAIN] Epoch[6](996/1500); Loss: 0.146657; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2352 0.2110 0.2175 0.2067 0.1882 0.1646 0.1433 0.1265 0.1113 0.1072 0.1070 0.1074 0.1070 0.1051 0.1035 0.1050 

[TRAIN] Epoch[6](997/1500); Loss: 0.121790; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.2166 0.1923 0.1739 0.1637 0.1456 0.1262 0.1159 0.1014 0.0937 0.0889 0.0895 0.0896 0.0874 0.0865 0.0879 0.0896 

[TRAIN] Epoch[6](998/1500); Loss: 0.134525; Backpropagation: 0.0925 sec; Batch: 0.4242 sec
0.1408 0.1640 0.2195 0.2061 0.1879 0.1629 0.1385 0.1196 0.1074 0.1028 0.1049 0.0989 0.0992 0.0994 0.1002 0.1004 

[TRAIN] Epoch[6](999/1500); Loss: 0.112874; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1494 0.2024 0.1856 0.1628 0.1367 0.1148 0.1006 0.0860 0.0802 0.0805 0.0839 0.0820 0.0833 0.0847 0.0863 0.0868 

[TRAIN] Epoch[6](1000/1500); Loss: 0.085865; Backpropagation: 0.0918 sec; Batch: 0.4265 sec
0.1348 0.1630 0.1479 0.1280 0.1039 0.0814 0.0668 0.0620 0.0622 0.0602 0.0604 0.0598 0.0612 0.0605 0.0606 0.0611 

[TRAIN] Epoch[6](1001/1500); Loss: 0.094982; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1194 0.1362 0.1268 0.1143 0.1011 0.0910 0.0855 0.0836 0.0817 0.0826 0.0822 0.0823 0.0825 0.0831 0.0834 0.0841 

[TRAIN] Epoch[6](1002/1500); Loss: 0.124357; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1629 0.1469 0.1431 0.1368 0.1289 0.1234 0.1229 0.1180 0.1164 0.1149 0.1143 0.1128 0.1122 0.1121 0.1120 0.1121 

[TRAIN] Epoch[6](1003/1500); Loss: 0.128210; Backpropagation: 0.0918 sec; Batch: 0.4224 sec
0.1748 0.1546 0.1478 0.1392 0.1304 0.1236 0.1190 0.1179 0.1173 0.1169 0.1173 0.1176 0.1178 0.1184 0.1189 0.1199 

[TRAIN] Epoch[6](1004/1500); Loss: 0.091556; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2256 0.1445 0.1629 0.1570 0.1388 0.1102 0.0809 0.0602 0.0488 0.0483 0.0470 0.0465 0.0476 0.0486 0.0477 0.0502 

[TRAIN] Epoch[6](1005/1500); Loss: 0.119175; Backpropagation: 0.0922 sec; Batch: 0.4252 sec
0.1574 0.1672 0.1510 0.1420 0.1296 0.1194 0.1103 0.1041 0.1018 0.1034 0.1034 0.1027 0.1025 0.1036 0.1038 0.1045 

[TRAIN] Epoch[6](1006/1500); Loss: 0.140986; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1774 0.2053 0.2062 0.1917 0.1723 0.1518 0.1359 0.1242 0.1164 0.1120 0.1126 0.1100 0.1091 0.1099 0.1107 0.1104 

[TRAIN] Epoch[6](1007/1500); Loss: 0.136125; Backpropagation: 0.0918 sec; Batch: 0.4259 sec
0.1633 0.1611 0.1581 0.1496 0.1395 0.1332 0.1318 0.1273 0.1273 0.1266 0.1259 0.1267 0.1267 0.1264 0.1271 0.1273 

[TRAIN] Epoch[6](1008/1500); Loss: 0.117264; Backpropagation: 0.0919 sec; Batch: 0.4268 sec
0.1479 0.1588 0.1475 0.1343 0.1221 0.1138 0.1094 0.1078 0.1053 0.1049 0.1047 0.1042 0.1039 0.1039 0.1037 0.1041 

[TRAIN] Epoch[6](1009/1500); Loss: 0.159047; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1878 0.1978 0.2002 0.1891 0.1754 0.1623 0.1546 0.1514 0.1492 0.1452 0.1418 0.1401 0.1384 0.1378 0.1369 0.1366 

[TRAIN] Epoch[6](1010/1500); Loss: 0.082556; Backpropagation: 0.0920 sec; Batch: 0.4228 sec
0.1022 0.1219 0.1419 0.1273 0.1092 0.0877 0.0704 0.0630 0.0654 0.0614 0.0610 0.0606 0.0638 0.0607 0.0612 0.0631 

[TRAIN] Epoch[6](1011/1500); Loss: 0.117594; Backpropagation: 0.0920 sec; Batch: 0.4262 sec
0.1573 0.1419 0.1466 0.1382 0.1267 0.1145 0.1092 0.1075 0.1069 0.1046 0.1042 0.1055 0.1044 0.1044 0.1046 0.1050 

[TRAIN] Epoch[6](1012/1500); Loss: 0.119804; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1432 0.1289 0.1563 0.1497 0.1378 0.1231 0.1170 0.1153 0.1126 0.1071 0.1068 0.1059 0.1056 0.1030 0.1025 0.1021 

[TRAIN] Epoch[6](1013/1500); Loss: 0.062223; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1821 0.0809 0.0947 0.0900 0.0748 0.0491 0.0384 0.0479 0.0431 0.0442 0.0407 0.0419 0.0412 0.0423 0.0408 0.0435 

[TRAIN] Epoch[6](1014/1500); Loss: 0.101139; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1612 0.1165 0.1251 0.1193 0.1094 0.0980 0.0950 0.0913 0.0900 0.0893 0.0882 0.0867 0.0869 0.0872 0.0872 0.0869 

[TRAIN] Epoch[6](1015/1500); Loss: 0.108531; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1452 0.1237 0.1180 0.1135 0.1086 0.1053 0.1033 0.1025 0.1021 0.1015 0.1017 0.1013 0.1021 0.1023 0.1027 0.1027 

[TRAIN] Epoch[6](1016/1500); Loss: 0.057659; Backpropagation: 0.0916 sec; Batch: 0.4312 sec
0.0855 0.0882 0.0837 0.0734 0.0637 0.0569 0.0514 0.0487 0.0476 0.0460 0.0453 0.0448 0.0456 0.0463 0.0476 0.0479 

[TRAIN] Epoch[6](1017/1500); Loss: 0.097812; Backpropagation: 0.0918 sec; Batch: 0.4268 sec
0.0869 0.0677 0.2146 0.1996 0.1822 0.1510 0.1179 0.0884 0.0626 0.0533 0.0536 0.0543 0.0555 0.0572 0.0582 0.0620 

[TRAIN] Epoch[6](1018/1500); Loss: 0.106787; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1453 0.1269 0.1222 0.1138 0.1084 0.1053 0.1025 0.1007 0.0988 0.0977 0.0974 0.0970 0.0968 0.0982 0.0987 0.0989 

[TRAIN] Epoch[6](1019/1500); Loss: 0.126608; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.1524 0.2033 0.1955 0.1768 0.1534 0.1315 0.1149 0.1064 0.1028 0.0990 0.0982 0.0986 0.0989 0.0986 0.0974 0.0981 

[TRAIN] Epoch[6](1020/1500); Loss: 0.138093; Backpropagation: 0.0916 sec; Batch: 0.4307 sec
0.1887 0.1624 0.1584 0.1512 0.1419 0.1350 0.1297 0.1272 0.1263 0.1259 0.1261 0.1265 0.1267 0.1273 0.1278 0.1285 

[TRAIN] Epoch[6](1021/1500); Loss: 0.133433; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1857 0.1631 0.1532 0.1462 0.1383 0.1306 0.1254 0.1231 0.1222 0.1216 0.1206 0.1205 0.1204 0.1210 0.1213 0.1219 

[TRAIN] Epoch[6](1022/1500); Loss: 0.124124; Backpropagation: 0.0988 sec; Batch: 0.4518 sec
0.1695 0.1889 0.1912 0.1764 0.1543 0.1335 0.1207 0.1076 0.1038 0.0963 0.0930 0.0891 0.0915 0.0893 0.0908 0.0900 

[TRAIN] Epoch[6](1023/1500); Loss: 0.105943; Backpropagation: 0.0932 sec; Batch: 0.4245 sec
0.1570 0.0535 0.2058 0.1916 0.1735 0.1417 0.1072 0.0780 0.0575 0.0599 0.0761 0.0777 0.0724 0.0751 0.0803 0.0875 

[TRAIN] Epoch[6](1024/1500); Loss: 0.076938; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1039 0.1130 0.1409 0.1289 0.1063 0.0795 0.0610 0.0606 0.0578 0.0545 0.0532 0.0544 0.0534 0.0531 0.0540 0.0565 

[TRAIN] Epoch[6](1025/1500); Loss: 0.094503; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1126 0.1088 0.1550 0.1427 0.1275 0.1036 0.0841 0.0785 0.0804 0.0711 0.0741 0.0734 0.0769 0.0722 0.0746 0.0765 

[TRAIN] Epoch[6](1026/1500); Loss: 0.147855; Backpropagation: 0.0917 sec; Batch: 0.4626 sec
0.1720 0.1735 0.1681 0.1607 0.1526 0.1462 0.1420 0.1400 0.1392 0.1393 0.1390 0.1383 0.1387 0.1384 0.1389 0.1389 

[TRAIN] Epoch[6](1027/1500); Loss: 0.211405; Backpropagation: 0.1073 sec; Batch: 0.4437 sec
0.3698 0.2889 0.2890 0.2839 0.2689 0.2395 0.2060 0.1737 0.1570 0.1574 0.1575 0.1559 0.1587 0.1583 0.1578 0.1602 

[TRAIN] Epoch[6](1028/1500); Loss: 0.080239; Backpropagation: 0.0917 sec; Batch: 0.4612 sec
0.0669 0.0864 0.1453 0.1320 0.1150 0.0918 0.0755 0.0685 0.0644 0.0636 0.0622 0.0616 0.0621 0.0618 0.0625 0.0642 

[TRAIN] Epoch[6](1029/1500); Loss: 0.175421; Backpropagation: 0.0917 sec; Batch: 0.4270 sec
0.2219 0.2053 0.2311 0.2194 0.2052 0.1851 0.1688 0.1582 0.1533 0.1527 0.1522 0.1511 0.1513 0.1508 0.1504 0.1499 

[TRAIN] Epoch[6](1030/1500); Loss: 0.108523; Backpropagation: 0.0918 sec; Batch: 0.4503 sec
0.1199 0.1644 0.1982 0.1816 0.1591 0.1313 0.1067 0.0891 0.0810 0.0764 0.0719 0.0715 0.0715 0.0716 0.0708 0.0712 

[TRAIN] Epoch[6](1031/1500); Loss: 0.066390; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0980 0.1231 0.1106 0.0963 0.0816 0.0679 0.0562 0.0483 0.0468 0.0459 0.0465 0.0469 0.0475 0.0483 0.0486 0.0499 

[TRAIN] Epoch[6](1032/1500); Loss: 0.134775; Backpropagation: 0.0988 sec; Batch: 0.4519 sec
0.1884 0.1665 0.1713 0.1629 0.1506 0.1365 0.1285 0.1240 0.1178 0.1161 0.1164 0.1154 0.1153 0.1151 0.1159 0.1157 

[TRAIN] Epoch[6](1033/1500); Loss: 0.126033; Backpropagation: 0.0935 sec; Batch: 0.4259 sec
0.1534 0.1936 0.1878 0.1736 0.1528 0.1342 0.1192 0.1094 0.1034 0.1006 0.0987 0.0978 0.0980 0.0977 0.0978 0.0985 

[TRAIN] Epoch[6](1034/1500); Loss: 0.108067; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1450 0.1711 0.1554 0.1410 0.1258 0.1124 0.1002 0.0914 0.0866 0.0850 0.0851 0.0853 0.0853 0.0859 0.0864 0.0872 

[TRAIN] Epoch[6](1035/1500); Loss: 0.093808; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1458 0.1461 0.1381 0.1258 0.1101 0.0956 0.0848 0.0783 0.0740 0.0723 0.0715 0.0713 0.0711 0.0712 0.0723 0.0725 

[TRAIN] Epoch[6](1036/1500); Loss: 0.151686; Backpropagation: 0.0918 sec; Batch: 0.4256 sec
0.2213 0.1863 0.1865 0.1812 0.1719 0.1596 0.1486 0.1402 0.1330 0.1293 0.1286 0.1287 0.1282 0.1276 0.1282 0.1278 

[TRAIN] Epoch[6](1037/1500); Loss: 0.151140; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1749 0.1858 0.1756 0.1668 0.1588 0.1524 0.1469 0.1426 0.1407 0.1395 0.1390 0.1389 0.1387 0.1387 0.1392 0.1396 

[TRAIN] Epoch[6](1038/1500); Loss: 0.084075; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1229 0.0990 0.0925 0.0887 0.0856 0.0828 0.0813 0.0800 0.0787 0.0777 0.0773 0.0763 0.0760 0.0756 0.0755 0.0754 

[TRAIN] Epoch[6](1039/1500); Loss: 0.133129; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1774 0.1803 0.1665 0.1539 0.1400 0.1283 0.1213 0.1194 0.1183 0.1184 0.1192 0.1178 0.1172 0.1171 0.1174 0.1177 

[TRAIN] Epoch[6](1040/1500); Loss: 0.083824; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1095 0.1241 0.1421 0.1305 0.1146 0.0936 0.0762 0.0691 0.0655 0.0613 0.0588 0.0597 0.0591 0.0589 0.0582 0.0601 

[TRAIN] Epoch[6](1041/1500); Loss: 0.086636; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1324 0.1249 0.1165 0.1055 0.0940 0.0848 0.0771 0.0736 0.0728 0.0719 0.0716 0.0718 0.0720 0.0722 0.0721 0.0730 

[TRAIN] Epoch[6](1042/1500); Loss: 0.056598; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.0849 0.0833 0.0661 0.0555 0.0519 0.0501 0.0501 0.0501 0.0500 0.0505 0.0506 0.0513 0.0519 0.0521 0.0531 0.0542 

[TRAIN] Epoch[6](1043/1500); Loss: 0.136133; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1623 0.1544 0.1487 0.1421 0.1358 0.1310 0.1298 0.1288 0.1288 0.1288 0.1296 0.1302 0.1307 0.1313 0.1323 0.1335 

[TRAIN] Epoch[6](1044/1500); Loss: 0.178795; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2357 0.2178 0.2173 0.2107 0.2015 0.1920 0.1833 0.1750 0.1671 0.1610 0.1556 0.1511 0.1484 0.1478 0.1479 0.1485 

[TRAIN] Epoch[6](1045/1500); Loss: 0.050167; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0727 0.0806 0.0665 0.0524 0.0446 0.0431 0.0427 0.0428 0.0423 0.0433 0.0433 0.0441 0.0450 0.0453 0.0464 0.0475 

[TRAIN] Epoch[6](1046/1500); Loss: 0.061357; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1050 0.0674 0.0722 0.0677 0.0614 0.0566 0.0578 0.0544 0.0543 0.0546 0.0544 0.0543 0.0544 0.0552 0.0559 0.0560 

[TRAIN] Epoch[6](1047/1500); Loss: 0.049909; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0687 0.0742 0.0612 0.0506 0.0460 0.0441 0.0439 0.0432 0.0434 0.0439 0.0440 0.0453 0.0461 0.0464 0.0484 0.0490 

[TRAIN] Epoch[6](1048/1500); Loss: 0.057953; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0528 0.1105 0.1052 0.0882 0.0661 0.0518 0.0514 0.0489 0.0450 0.0449 0.0470 0.0441 0.0427 0.0429 0.0432 0.0425 

[TRAIN] Epoch[6](1049/1500); Loss: 0.116902; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1639 0.1261 0.1259 0.1215 0.1159 0.1132 0.1119 0.1121 0.1120 0.1104 0.1097 0.1095 0.1093 0.1097 0.1098 0.1097 

[TRAIN] Epoch[6](1050/1500); Loss: 0.127695; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2148 0.1759 0.1633 0.1530 0.1387 0.1236 0.1152 0.1092 0.1058 0.1053 0.1057 0.1060 0.1049 0.1060 0.1072 0.1085 

[TRAIN] Epoch[6](1051/1500); Loss: 0.093263; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1183 0.0584 0.1826 0.1667 0.1508 0.1207 0.0912 0.0701 0.0610 0.0640 0.0641 0.0653 0.0672 0.0699 0.0703 0.0714 

[TRAIN] Epoch[6](1052/1500); Loss: 0.070702; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.0678 0.0921 0.1259 0.1112 0.0921 0.0714 0.0619 0.0617 0.0558 0.0550 0.0550 0.0570 0.0558 0.0550 0.0565 0.0571 

[TRAIN] Epoch[6](1053/1500); Loss: 0.080819; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1175 0.1448 0.1288 0.1139 0.0980 0.0852 0.0733 0.0657 0.0612 0.0585 0.0566 0.0574 0.0576 0.0572 0.0589 0.0585 

[TRAIN] Epoch[6](1054/1500); Loss: 0.105770; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1392 0.1296 0.1393 0.1295 0.1137 0.0989 0.0959 0.0994 0.0937 0.0921 0.0937 0.0953 0.0929 0.0916 0.0929 0.0945 

[TRAIN] Epoch[6](1055/1500); Loss: 0.100089; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1428 0.1264 0.1235 0.1157 0.1067 0.0989 0.0939 0.0897 0.0889 0.0872 0.0868 0.0872 0.0876 0.0883 0.0887 0.0893 

[TRAIN] Epoch[6](1056/1500); Loss: 0.153013; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2268 0.1926 0.1922 0.1835 0.1710 0.1572 0.1472 0.1403 0.1359 0.1310 0.1294 0.1294 0.1289 0.1278 0.1276 0.1274 

[TRAIN] Epoch[6](1057/1500); Loss: 0.103729; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1169 0.0825 0.1873 0.1713 0.1541 0.1257 0.0995 0.0823 0.0761 0.0781 0.0798 0.0795 0.0791 0.0809 0.0827 0.0836 

[TRAIN] Epoch[6](1058/1500); Loss: 0.140806; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1674 0.1739 0.1838 0.1711 0.1560 0.1433 0.1379 0.1342 0.1308 0.1272 0.1258 0.1237 0.1213 0.1196 0.1186 0.1182 

[TRAIN] Epoch[6](1059/1500); Loss: 0.079509; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2212 0.1279 0.0714 0.0807 0.0670 0.0557 0.0650 0.0656 0.0642 0.0599 0.0622 0.0667 0.0650 0.0645 0.0649 0.0702 

[TRAIN] Epoch[6](1060/1500); Loss: 0.096713; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1225 0.1424 0.1305 0.1150 0.1002 0.0913 0.0864 0.0852 0.0840 0.0836 0.0840 0.0837 0.0840 0.0840 0.0851 0.0855 

[TRAIN] Epoch[6](1061/1500); Loss: 0.077789; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1354 0.1096 0.1065 0.0969 0.0854 0.0745 0.0673 0.0654 0.0637 0.0628 0.0626 0.0626 0.0625 0.0629 0.0627 0.0638 

[TRAIN] Epoch[6](1062/1500); Loss: 0.096645; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2149 0.1419 0.1517 0.1457 0.1292 0.1037 0.0775 0.0621 0.0650 0.0670 0.0659 0.0631 0.0635 0.0651 0.0653 0.0647 

[TRAIN] Epoch[6](1063/1500); Loss: 0.091000; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1372 0.1532 0.1446 0.1287 0.1098 0.0934 0.0824 0.0749 0.0701 0.0678 0.0663 0.0650 0.0658 0.0654 0.0655 0.0659 

[TRAIN] Epoch[6](1064/1500); Loss: 0.074580; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.1160 0.0808 0.1450 0.1378 0.1167 0.0868 0.0604 0.0498 0.0567 0.0504 0.0483 0.0470 0.0497 0.0494 0.0483 0.0502 

[TRAIN] Epoch[6](1065/1500); Loss: 0.106573; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1222 0.1306 0.1237 0.1132 0.1046 0.1007 0.0997 0.0996 0.0997 0.1000 0.1004 0.1011 0.1016 0.1022 0.1026 0.1033 

[TRAIN] Epoch[6](1066/1500); Loss: 0.084393; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1407 0.1335 0.1242 0.1089 0.0935 0.0813 0.0736 0.0694 0.0672 0.0665 0.0654 0.0650 0.0649 0.0652 0.0654 0.0656 

[TRAIN] Epoch[6](1067/1500); Loss: 0.148473; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1772 0.1824 0.1732 0.1625 0.1539 0.1470 0.1420 0.1398 0.1385 0.1376 0.1369 0.1367 0.1366 0.1368 0.1371 0.1373 

[TRAIN] Epoch[6](1068/1500); Loss: 0.114511; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1760 0.1615 0.1691 0.1530 0.1356 0.1174 0.1038 0.0979 0.0949 0.0920 0.0912 0.0889 0.0881 0.0871 0.0874 0.0883 

[TRAIN] Epoch[6](1069/1500); Loss: 0.181494; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2050 0.2243 0.2407 0.2265 0.2065 0.1844 0.1694 0.1671 0.1645 0.1605 0.1605 0.1615 0.1586 0.1578 0.1578 0.1588 

[TRAIN] Epoch[6](1070/1500); Loss: 0.075878; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0903 0.0853 0.1510 0.1343 0.1133 0.0833 0.0569 0.0452 0.0517 0.0517 0.0544 0.0553 0.0588 0.0594 0.0601 0.0631 

[TRAIN] Epoch[6](1071/1500); Loss: 0.088614; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1195 0.1250 0.1187 0.1082 0.0971 0.0885 0.0820 0.0776 0.0759 0.0752 0.0749 0.0752 0.0743 0.0751 0.0748 0.0758 

[TRAIN] Epoch[6](1072/1500); Loss: 0.087970; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1474 0.1503 0.1379 0.1239 0.1076 0.0922 0.0803 0.0697 0.0639 0.0630 0.0624 0.0619 0.0611 0.0617 0.0619 0.0623 

[TRAIN] Epoch[6](1073/1500); Loss: 0.113054; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1741 0.1511 0.1605 0.1528 0.1355 0.1140 0.1041 0.0995 0.0941 0.0907 0.0901 0.0887 0.0881 0.0880 0.0886 0.0891 

[TRAIN] Epoch[6](1074/1500); Loss: 0.097532; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1650 0.1178 0.1487 0.1414 0.1276 0.1059 0.0860 0.0749 0.0785 0.0747 0.0723 0.0727 0.0749 0.0732 0.0726 0.0744 

[TRAIN] Epoch[6](1075/1500); Loss: 0.140666; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1827 0.1729 0.1730 0.1644 0.1521 0.1404 0.1348 0.1335 0.1274 0.1257 0.1266 0.1240 0.1236 0.1240 0.1224 0.1232 

[TRAIN] Epoch[6](1076/1500); Loss: 0.080661; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2058 0.1376 0.1387 0.1278 0.1081 0.0843 0.0632 0.0504 0.0442 0.0446 0.0452 0.0458 0.0470 0.0477 0.0499 0.0503 

[TRAIN] Epoch[6](1077/1500); Loss: 0.132994; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1989 0.1647 0.1525 0.1483 0.1415 0.1338 0.1270 0.1229 0.1191 0.1172 0.1163 0.1162 0.1166 0.1170 0.1176 0.1183 

[TRAIN] Epoch[6](1078/1500); Loss: 0.074155; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1183 0.1179 0.1046 0.0926 0.0824 0.0728 0.0639 0.0593 0.0587 0.0584 0.0586 0.0589 0.0592 0.0600 0.0603 0.0606 

[TRAIN] Epoch[6](1079/1500); Loss: 0.086506; Backpropagation: 0.0936 sec; Batch: 0.4285 sec
0.1380 0.1475 0.1352 0.1191 0.1017 0.0846 0.0720 0.0687 0.0666 0.0650 0.0644 0.0636 0.0642 0.0642 0.0641 0.0651 

[TRAIN] Epoch[6](1080/1500); Loss: 0.116412; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2144 0.1548 0.1649 0.1552 0.1381 0.1164 0.1037 0.0970 0.0900 0.0901 0.0909 0.0902 0.0893 0.0894 0.0895 0.0886 

[TRAIN] Epoch[6](1081/1500); Loss: 0.076545; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1138 0.1180 0.1045 0.0937 0.0848 0.0761 0.0686 0.0658 0.0647 0.0628 0.0623 0.0619 0.0617 0.0617 0.0619 0.0624 

[TRAIN] Epoch[6](1082/1500); Loss: 0.148551; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2053 0.1791 0.1926 0.1828 0.1692 0.1525 0.1447 0.1405 0.1339 0.1292 0.1278 0.1258 0.1238 0.1235 0.1231 0.1231 

[TRAIN] Epoch[6](1083/1500); Loss: 0.161886; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2145 0.2021 0.1911 0.1837 0.1737 0.1651 0.1598 0.1533 0.1495 0.1463 0.1431 0.1425 0.1419 0.1414 0.1410 0.1411 

[TRAIN] Epoch[6](1084/1500); Loss: 0.219391; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3265 0.2683 0.2656 0.2608 0.2512 0.2311 0.2092 0.1932 0.1884 0.1892 0.1873 0.1873 0.1878 0.1881 0.1877 0.1887 

[TRAIN] Epoch[6](1085/1500); Loss: 0.079126; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1821 0.0749 0.1120 0.1366 0.1191 0.0923 0.0613 0.0490 0.0526 0.0535 0.0507 0.0514 0.0561 0.0580 0.0565 0.0597 

[TRAIN] Epoch[6](1086/1500); Loss: 0.106309; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1252 0.1661 0.1944 0.1775 0.1549 0.1285 0.1065 0.0902 0.0807 0.0731 0.0687 0.0679 0.0688 0.0662 0.0660 0.0663 

[TRAIN] Epoch[6](1087/1500); Loss: 0.089119; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1021 0.0982 0.1022 0.0968 0.0906 0.0874 0.0850 0.0842 0.0840 0.0832 0.0839 0.0839 0.0847 0.0855 0.0869 0.0874 

[TRAIN] Epoch[6](1088/1500); Loss: 0.145717; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.2123 0.1823 0.1830 0.1755 0.1644 0.1524 0.1412 0.1324 0.1252 0.1252 0.1241 0.1231 0.1224 0.1225 0.1225 0.1229 

[TRAIN] Epoch[6](1089/1500); Loss: 0.087744; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1503 0.1413 0.1221 0.1080 0.0930 0.0820 0.0751 0.0731 0.0700 0.0694 0.0696 0.0694 0.0696 0.0697 0.0701 0.0711 

[TRAIN] Epoch[6](1090/1500); Loss: 0.140331; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1953 0.1719 0.1656 0.1566 0.1476 0.1402 0.1338 0.1293 0.1264 0.1254 0.1250 0.1253 0.1253 0.1257 0.1256 0.1265 

[TRAIN] Epoch[6](1091/1500); Loss: 0.135850; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1852 0.1701 0.1651 0.1558 0.1462 0.1388 0.1352 0.1283 0.1253 0.1230 0.1195 0.1174 0.1163 0.1154 0.1158 0.1162 

[TRAIN] Epoch[6](1092/1500); Loss: 0.065329; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0895 0.1164 0.0933 0.0808 0.0715 0.0650 0.0572 0.0527 0.0512 0.0498 0.0499 0.0517 0.0528 0.0530 0.0544 0.0561 

[TRAIN] Epoch[6](1093/1500); Loss: 0.126594; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1668 0.1808 0.1678 0.1523 0.1373 0.1245 0.1155 0.1117 0.1098 0.1090 0.1086 0.1079 0.1080 0.1082 0.1086 0.1086 

[TRAIN] Epoch[6](1094/1500); Loss: 0.141715; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1933 0.1788 0.1651 0.1580 0.1495 0.1407 0.1353 0.1311 0.1279 0.1269 0.1268 0.1260 0.1262 0.1269 0.1271 0.1277 

[TRAIN] Epoch[6](1095/1500); Loss: 0.204907; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2411 0.2436 0.2311 0.2198 0.2117 0.2050 0.1994 0.1947 0.1922 0.1911 0.1908 0.1920 0.1919 0.1912 0.1910 0.1922 

[TRAIN] Epoch[6](1096/1500); Loss: 0.115071; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1079 0.1121 0.1638 0.1529 0.1402 0.1205 0.1080 0.1032 0.1044 0.1040 0.1041 0.1056 0.1046 0.1036 0.1029 0.1033 

[TRAIN] Epoch[6](1097/1500); Loss: 0.108612; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2277 0.1633 0.1594 0.1531 0.1363 0.1137 0.0969 0.0854 0.0794 0.0773 0.0745 0.0754 0.0748 0.0735 0.0735 0.0738 

[TRAIN] Epoch[6](1098/1500); Loss: 0.113710; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1340 0.1225 0.1179 0.1153 0.1126 0.1107 0.1101 0.1102 0.1098 0.1100 0.1101 0.1104 0.1108 0.1110 0.1116 0.1123 

[TRAIN] Epoch[6](1099/1500); Loss: 0.157507; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1802 0.1747 0.2064 0.1956 0.1822 0.1638 0.1519 0.1448 0.1425 0.1430 0.1426 0.1404 0.1395 0.1386 0.1369 0.1370 

[TRAIN] Epoch[6](1100/1500); Loss: 0.132191; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1785 0.1602 0.1570 0.1507 0.1444 0.1390 0.1306 0.1238 0.1191 0.1177 0.1163 0.1161 0.1155 0.1153 0.1152 0.1158 

[TRAIN] Epoch[6](1101/1500); Loss: 0.141920; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1857 0.1936 0.1746 0.1594 0.1490 0.1399 0.1301 0.1237 0.1216 0.1215 0.1225 0.1253 0.1270 0.1292 0.1321 0.1357 

[TRAIN] Epoch[6](1102/1500); Loss: 0.112254; Backpropagation: 0.0924 sec; Batch: 0.4235 sec
0.1283 0.1110 0.1974 0.1806 0.1617 0.1294 0.1024 0.0900 0.0875 0.0893 0.0881 0.0864 0.0869 0.0873 0.0853 0.0845 

[TRAIN] Epoch[6](1103/1500); Loss: 0.130237; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1843 0.1595 0.1538 0.1483 0.1414 0.1348 0.1272 0.1213 0.1171 0.1151 0.1136 0.1132 0.1134 0.1134 0.1133 0.1139 

[TRAIN] Epoch[6](1104/1500); Loss: 0.086650; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1183 0.1366 0.1236 0.1082 0.0935 0.0816 0.0752 0.0742 0.0728 0.0723 0.0716 0.0712 0.0715 0.0713 0.0720 0.0724 

[TRAIN] Epoch[6](1105/1500); Loss: 0.072870; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0932 0.1018 0.0981 0.0852 0.0767 0.0724 0.0682 0.0660 0.0637 0.0638 0.0625 0.0625 0.0625 0.0622 0.0631 0.0640 

[TRAIN] Epoch[6](1106/1500); Loss: 0.108510; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1377 0.1355 0.1333 0.1238 0.1135 0.1078 0.1051 0.1010 0.0998 0.0977 0.0970 0.0968 0.0965 0.0966 0.0970 0.0969 

[TRAIN] Epoch[6](1107/1500); Loss: 0.049171; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0668 0.0771 0.0624 0.0497 0.0437 0.0427 0.0422 0.0425 0.0428 0.0429 0.0436 0.0442 0.0449 0.0458 0.0474 0.0482 

[TRAIN] Epoch[6](1108/1500); Loss: 0.044386; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0832 0.0618 0.0544 0.0479 0.0440 0.0417 0.0374 0.0366 0.0374 0.0371 0.0364 0.0370 0.0379 0.0385 0.0392 0.0399 

[TRAIN] Epoch[6](1109/1500); Loss: 0.100657; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1165 0.1152 0.1273 0.1192 0.1079 0.0973 0.0956 0.0956 0.0920 0.0923 0.0922 0.0918 0.0915 0.0918 0.0921 0.0924 

[TRAIN] Epoch[6](1110/1500); Loss: 0.071948; Backpropagation: 0.0917 sec; Batch: 0.4249 sec
0.0879 0.1009 0.0866 0.0753 0.0708 0.0683 0.0670 0.0662 0.0656 0.0649 0.0650 0.0649 0.0655 0.0666 0.0674 0.0684 

[TRAIN] Epoch[6](1111/1500); Loss: 0.158756; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2026 0.2038 0.2036 0.1901 0.1748 0.1611 0.1531 0.1499 0.1457 0.1407 0.1386 0.1374 0.1355 0.1348 0.1342 0.1342 

[TRAIN] Epoch[6](1112/1500); Loss: 0.059324; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.0750 0.0687 0.0759 0.0689 0.0612 0.0578 0.0580 0.0512 0.0529 0.0535 0.0530 0.0536 0.0537 0.0545 0.0557 0.0556 

[TRAIN] Epoch[6](1113/1500); Loss: 0.093556; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2154 0.1338 0.1059 0.1127 0.0977 0.0798 0.0726 0.0741 0.0736 0.0734 0.0738 0.0772 0.0750 0.0756 0.0770 0.0793 

[TRAIN] Epoch[6](1114/1500); Loss: 0.104401; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1507 0.2065 0.1933 0.1696 0.1408 0.1129 0.0902 0.0738 0.0686 0.0649 0.0646 0.0657 0.0661 0.0672 0.0681 0.0675 

[TRAIN] Epoch[6](1115/1500); Loss: 0.121606; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1767 0.1625 0.1566 0.1459 0.1346 0.1250 0.1175 0.1083 0.1045 0.1037 0.1018 0.1015 0.1016 0.1016 0.1018 0.1020 

[TRAIN] Epoch[6](1116/1500); Loss: 0.042426; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1005 0.0651 0.0577 0.0513 0.0440 0.0387 0.0327 0.0312 0.0323 0.0314 0.0307 0.0317 0.0317 0.0325 0.0332 0.0342 

[TRAIN] Epoch[6](1117/1500); Loss: 0.100744; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1289 0.1277 0.1198 0.1105 0.1028 0.0985 0.0956 0.0932 0.0927 0.0922 0.0917 0.0912 0.0913 0.0916 0.0919 0.0922 

[TRAIN] Epoch[6](1118/1500); Loss: 0.138960; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.2010 0.1735 0.2005 0.1880 0.1731 0.1519 0.1375 0.1313 0.1200 0.1124 0.1089 0.1073 0.1058 0.1046 0.1039 0.1037 

[TRAIN] Epoch[6](1119/1500); Loss: 0.108433; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1807 0.1546 0.1232 0.1143 0.1062 0.1031 0.1003 0.0956 0.0954 0.0941 0.0939 0.0940 0.0940 0.0944 0.0954 0.0958 

[TRAIN] Epoch[6](1120/1500); Loss: 0.145508; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1669 0.1639 0.1564 0.1499 0.1451 0.1418 0.1400 0.1396 0.1394 0.1395 0.1396 0.1402 0.1407 0.1411 0.1418 0.1424 

[TRAIN] Epoch[6](1121/1500); Loss: 0.185455; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3719 0.2909 0.2993 0.2901 0.2681 0.2322 0.1952 0.1609 0.1237 0.1029 0.1026 0.1069 0.1053 0.1053 0.1059 0.1059 

[TRAIN] Epoch[6](1122/1500); Loss: 0.156809; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1742 0.1790 0.1709 0.1626 0.1583 0.1553 0.1537 0.1526 0.1517 0.1507 0.1503 0.1500 0.1497 0.1499 0.1500 0.1501 

[TRAIN] Epoch[6](1123/1500); Loss: 0.069499; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1029 0.0839 0.0916 0.0835 0.0731 0.0649 0.0644 0.0595 0.0597 0.0591 0.0598 0.0604 0.0612 0.0619 0.0625 0.0635 

[TRAIN] Epoch[6](1124/1500); Loss: 0.105055; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1958 0.1475 0.1431 0.1381 0.1266 0.1116 0.0967 0.0848 0.0788 0.0824 0.0794 0.0790 0.0788 0.0802 0.0791 0.0788 

[TRAIN] Epoch[6](1125/1500); Loss: 0.124366; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.2001 0.1647 0.1644 0.1552 0.1422 0.1267 0.1160 0.1078 0.1035 0.1026 0.1018 0.1015 0.1008 0.1002 0.1010 0.1013 

[TRAIN] Epoch[6](1126/1500); Loss: 0.078678; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1467 0.0329 0.1667 0.1500 0.1315 0.0990 0.0665 0.0443 0.0398 0.0584 0.0538 0.0514 0.0477 0.0477 0.0596 0.0630 

[TRAIN] Epoch[6](1127/1500); Loss: 0.080046; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0920 0.0904 0.0823 0.0793 0.0779 0.0771 0.0766 0.0770 0.0771 0.0775 0.0782 0.0784 0.0785 0.0790 0.0796 0.0799 

[TRAIN] Epoch[6](1128/1500); Loss: 0.123017; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2211 0.2039 0.1628 0.1557 0.1368 0.1218 0.1161 0.1039 0.0986 0.0945 0.0947 0.0924 0.0915 0.0907 0.0911 0.0926 

[TRAIN] Epoch[6](1129/1500); Loss: 0.113564; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1402 0.1450 0.1335 0.1230 0.1156 0.1111 0.1083 0.1064 0.1052 0.1045 0.1042 0.1041 0.1040 0.1038 0.1038 0.1044 

[TRAIN] Epoch[6](1130/1500); Loss: 0.086402; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0832 0.0654 0.1929 0.1753 0.1572 0.1251 0.0931 0.0685 0.0537 0.0519 0.0505 0.0532 0.0524 0.0526 0.0542 0.0533 

[TRAIN] Epoch[6](1131/1500); Loss: 0.139451; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1925 0.1815 0.1891 0.1723 0.1544 0.1360 0.1277 0.1275 0.1237 0.1194 0.1188 0.1193 0.1173 0.1172 0.1168 0.1178 

[TRAIN] Epoch[6](1132/1500); Loss: 0.135834; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2277 0.1857 0.1835 0.1751 0.1626 0.1449 0.1283 0.1154 0.1063 0.1078 0.1059 0.1056 0.1048 0.1068 0.1061 0.1069 

[TRAIN] Epoch[6](1133/1500); Loss: 0.146704; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1901 0.1905 0.1780 0.1646 0.1545 0.1463 0.1414 0.1369 0.1346 0.1329 0.1309 0.1297 0.1293 0.1292 0.1290 0.1294 

[TRAIN] Epoch[6](1134/1500); Loss: 0.125518; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1589 0.1867 0.1726 0.1530 0.1359 0.1242 0.1168 0.1090 0.1088 0.1073 0.1070 0.1056 0.1053 0.1058 0.1059 0.1056 

[TRAIN] Epoch[6](1135/1500); Loss: 0.077342; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0841 0.1008 0.0877 0.0798 0.0772 0.0754 0.0742 0.0731 0.0726 0.0720 0.0714 0.0718 0.0732 0.0738 0.0746 0.0756 

[TRAIN] Epoch[6](1136/1500); Loss: 0.071824; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1233 0.0880 0.0919 0.0888 0.0755 0.0620 0.0642 0.0670 0.0622 0.0605 0.0608 0.0619 0.0605 0.0602 0.0606 0.0618 

[TRAIN] Epoch[6](1137/1500); Loss: 0.108531; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1541 0.1325 0.1721 0.1568 0.1379 0.1126 0.0974 0.0896 0.0882 0.0876 0.0848 0.0857 0.0852 0.0859 0.0836 0.0827 

[TRAIN] Epoch[6](1138/1500); Loss: 0.137448; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1653 0.1609 0.1685 0.1588 0.1474 0.1380 0.1353 0.1315 0.1284 0.1265 0.1249 0.1238 0.1231 0.1219 0.1222 0.1226 

[TRAIN] Epoch[6](1139/1500); Loss: 0.056324; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1069 0.0777 0.0724 0.0669 0.0604 0.0532 0.0486 0.0459 0.0452 0.0454 0.0453 0.0457 0.0460 0.0466 0.0472 0.0476 

[TRAIN] Epoch[6](1140/1500); Loss: 0.092480; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1493 0.1501 0.1349 0.1158 0.0987 0.0863 0.0791 0.0777 0.0756 0.0744 0.0732 0.0732 0.0730 0.0728 0.0725 0.0731 

[TRAIN] Epoch[6](1141/1500); Loss: 0.130307; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1843 0.1969 0.1842 0.1646 0.1440 0.1286 0.1183 0.1119 0.1083 0.1072 0.1069 0.1060 0.1053 0.1058 0.1060 0.1065 

[TRAIN] Epoch[6](1142/1500); Loss: 0.133709; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2398 0.1934 0.1909 0.1818 0.1679 0.1463 0.1253 0.1086 0.0998 0.0981 0.0979 0.0976 0.0996 0.0969 0.0973 0.0981 

[TRAIN] Epoch[6](1143/1500); Loss: 0.134380; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1819 0.1547 0.1457 0.1405 0.1348 0.1321 0.1306 0.1274 0.1265 0.1256 0.1257 0.1245 0.1245 0.1250 0.1251 0.1255 

[TRAIN] Epoch[6](1144/1500); Loss: 0.084966; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.0774 0.0798 0.1750 0.1562 0.1364 0.1064 0.0807 0.0659 0.0560 0.0564 0.0624 0.0613 0.0608 0.0624 0.0603 0.0620 

[TRAIN] Epoch[6](1145/1500); Loss: 0.058310; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1572 0.0987 0.1020 0.0945 0.0809 0.0626 0.0441 0.0352 0.0308 0.0318 0.0310 0.0327 0.0315 0.0322 0.0327 0.0353 

[TRAIN] Epoch[6](1146/1500); Loss: 0.095110; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1303 0.1104 0.1149 0.1088 0.0987 0.0919 0.0942 0.0909 0.0855 0.0863 0.0872 0.0845 0.0844 0.0847 0.0842 0.0849 

[TRAIN] Epoch[6](1147/1500); Loss: 0.061464; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0608 0.0833 0.0886 0.0736 0.0635 0.0611 0.0580 0.0550 0.0557 0.0555 0.0543 0.0539 0.0540 0.0552 0.0555 0.0554 

[TRAIN] Epoch[6](1148/1500); Loss: 0.166607; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2771 0.2312 0.2249 0.2179 0.2062 0.1916 0.1757 0.1610 0.1465 0.1329 0.1219 0.1164 0.1167 0.1156 0.1154 0.1147 

[TRAIN] Epoch[6](1149/1500); Loss: 0.116609; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2041 0.1840 0.1493 0.1245 0.1190 0.1105 0.1046 0.0998 0.0983 0.0961 0.0964 0.0955 0.0958 0.0955 0.0960 0.0963 

[TRAIN] Epoch[6](1150/1500); Loss: 0.129478; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1814 0.1881 0.1785 0.1624 0.1470 0.1364 0.1257 0.1148 0.1096 0.1065 0.1037 0.1030 0.1037 0.1031 0.1027 0.1049 

[TRAIN] Epoch[6](1151/1500); Loss: 0.140446; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1871 0.1852 0.1875 0.1718 0.1560 0.1433 0.1365 0.1317 0.1241 0.1211 0.1199 0.1178 0.1164 0.1162 0.1167 0.1159 

[TRAIN] Epoch[6](1152/1500); Loss: 0.068547; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0695 0.1065 0.1052 0.0823 0.0634 0.0612 0.0611 0.0589 0.0586 0.0595 0.0606 0.0598 0.0606 0.0621 0.0634 0.0641 

[TRAIN] Epoch[6](1153/1500); Loss: 0.076540; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0891 0.0828 0.1006 0.0903 0.0790 0.0712 0.0706 0.0701 0.0686 0.0696 0.0702 0.0705 0.0711 0.0726 0.0737 0.0746 

[TRAIN] Epoch[6](1154/1500); Loss: 0.118250; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1608 0.1451 0.1260 0.1210 0.1166 0.1150 0.1128 0.1113 0.1109 0.1104 0.1103 0.1103 0.1100 0.1101 0.1104 0.1108 

[TRAIN] Epoch[6](1155/1500); Loss: 0.117757; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1707 0.1595 0.1514 0.1395 0.1284 0.1176 0.1074 0.1034 0.1022 0.1012 0.1004 0.1002 0.1007 0.1002 0.1003 0.1010 

[TRAIN] Epoch[6](1156/1500); Loss: 0.077497; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1462 0.0355 0.1559 0.1381 0.1204 0.0899 0.0595 0.0416 0.0493 0.0625 0.0620 0.0558 0.0491 0.0563 0.0597 0.0580 

[TRAIN] Epoch[6](1157/1500); Loss: 0.129241; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1765 0.1769 0.1643 0.1509 0.1378 0.1276 0.1213 0.1171 0.1139 0.1128 0.1117 0.1109 0.1106 0.1117 0.1119 0.1120 

[TRAIN] Epoch[6](1158/1500); Loss: 0.084870; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1284 0.1180 0.1026 0.0918 0.0847 0.0808 0.0765 0.0755 0.0746 0.0743 0.0741 0.0746 0.0746 0.0753 0.0762 0.0762 

[TRAIN] Epoch[6](1159/1500); Loss: 0.125063; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1641 0.1659 0.1574 0.1431 0.1290 0.1205 0.1198 0.1155 0.1128 0.1140 0.1119 0.1107 0.1098 0.1091 0.1087 0.1086 

[TRAIN] Epoch[6](1160/1500); Loss: 0.092471; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1398 0.1339 0.1194 0.1058 0.0952 0.0891 0.0842 0.0805 0.0785 0.0787 0.0784 0.0785 0.0789 0.0790 0.0795 0.0800 

[TRAIN] Epoch[6](1161/1500); Loss: 0.097217; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1538 0.1239 0.1207 0.1136 0.1055 0.0978 0.0913 0.0867 0.0833 0.0820 0.0816 0.0819 0.0823 0.0829 0.0837 0.0843 

[TRAIN] Epoch[6](1162/1500); Loss: 0.122979; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1650 0.1930 0.1771 0.1569 0.1377 0.1225 0.1126 0.1049 0.1016 0.1014 0.1000 0.0990 0.0987 0.0988 0.0990 0.0995 

[TRAIN] Epoch[6](1163/1500); Loss: 0.066216; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1509 0.0896 0.0850 0.0808 0.0671 0.0534 0.0557 0.0567 0.0488 0.0508 0.0522 0.0546 0.0508 0.0521 0.0541 0.0569 

[TRAIN] Epoch[6](1164/1500); Loss: 0.109205; Backpropagation: 0.0916 sec; Batch: 0.4239 sec
0.2086 0.1573 0.1549 0.1475 0.1347 0.1180 0.1003 0.0855 0.0814 0.0821 0.0812 0.0797 0.0803 0.0790 0.0786 0.0784 

[TRAIN] Epoch[6](1165/1500); Loss: 0.104343; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1360 0.1530 0.1446 0.1286 0.1132 0.1003 0.0920 0.0868 0.0848 0.0854 0.0857 0.0876 0.0894 0.0923 0.0932 0.0967 

[TRAIN] Epoch[6](1166/1500); Loss: 0.108564; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1135 0.1002 0.1818 0.1640 0.1471 0.1223 0.1024 0.0911 0.0894 0.0873 0.0903 0.0908 0.0897 0.0890 0.0895 0.0886 

[TRAIN] Epoch[6](1167/1500); Loss: 0.096201; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1532 0.1544 0.1422 0.1214 0.1047 0.0936 0.0822 0.0753 0.0748 0.0757 0.0754 0.0763 0.0765 0.0768 0.0780 0.0789 

[TRAIN] Epoch[6](1168/1500); Loss: 0.081635; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0951 0.0990 0.0902 0.0846 0.0813 0.0787 0.0776 0.0771 0.0772 0.0773 0.0773 0.0774 0.0779 0.0780 0.0784 0.0790 

[TRAIN] Epoch[6](1169/1500); Loss: 0.077444; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1261 0.1422 0.1249 0.1032 0.0840 0.0713 0.0624 0.0622 0.0592 0.0585 0.0588 0.0564 0.0576 0.0581 0.0567 0.0575 

[TRAIN] Epoch[6](1170/1500); Loss: 0.144828; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2242 0.1786 0.2010 0.1910 0.1762 0.1555 0.1406 0.1351 0.1226 0.1174 0.1145 0.1136 0.1117 0.1117 0.1113 0.1122 

[TRAIN] Epoch[6](1171/1500); Loss: 0.102570; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1477 0.1502 0.1356 0.1208 0.1063 0.0967 0.0908 0.0897 0.0889 0.0884 0.0882 0.0882 0.0875 0.0871 0.0874 0.0875 

[TRAIN] Epoch[6](1172/1500); Loss: 0.097383; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1419 0.1200 0.1224 0.1134 0.1041 0.0960 0.0907 0.0863 0.0873 0.0864 0.0854 0.0845 0.0851 0.0852 0.0842 0.0851 

[TRAIN] Epoch[6](1173/1500); Loss: 0.127248; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1851 0.1673 0.1603 0.1510 0.1412 0.1293 0.1218 0.1142 0.1099 0.1092 0.1082 0.1078 0.1074 0.1074 0.1080 0.1078 

[TRAIN] Epoch[6](1174/1500); Loss: 0.122399; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1581 0.1232 0.1764 0.1626 0.1476 0.1241 0.1103 0.1115 0.1100 0.1064 0.1064 0.1043 0.1050 0.1044 0.1036 0.1043 

[TRAIN] Epoch[6](1175/1500); Loss: 0.159410; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2136 0.1959 0.1839 0.1771 0.1701 0.1644 0.1590 0.1525 0.1470 0.1435 0.1418 0.1411 0.1406 0.1399 0.1399 0.1402 

[TRAIN] Epoch[6](1176/1500); Loss: 0.099016; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1467 0.1287 0.1210 0.1140 0.1083 0.1007 0.0937 0.0891 0.0865 0.0851 0.0846 0.0845 0.0847 0.0850 0.0855 0.0859 

[TRAIN] Epoch[6](1177/1500); Loss: 0.128368; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1965 0.1779 0.1536 0.1457 0.1365 0.1284 0.1206 0.1144 0.1123 0.1096 0.1093 0.1095 0.1094 0.1093 0.1103 0.1105 

[TRAIN] Epoch[6](1178/1500); Loss: 0.054111; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1051 0.0723 0.0659 0.0597 0.0535 0.0478 0.0472 0.0459 0.0459 0.0452 0.0452 0.0457 0.0457 0.0464 0.0470 0.0474 

[TRAIN] Epoch[6](1179/1500); Loss: 0.059527; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0866 0.1021 0.0795 0.0666 0.0572 0.0529 0.0494 0.0492 0.0494 0.0492 0.0501 0.0503 0.0507 0.0522 0.0532 0.0537 

[TRAIN] Epoch[6](1180/1500); Loss: 0.105021; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1986 0.1672 0.1337 0.1240 0.1101 0.1002 0.0902 0.0872 0.0827 0.0847 0.0839 0.0834 0.0832 0.0843 0.0834 0.0836 

[TRAIN] Epoch[6](1181/1500); Loss: 0.121458; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1817 0.1505 0.1441 0.1343 0.1270 0.1185 0.1137 0.1106 0.1079 0.1089 0.1073 0.1079 0.1068 0.1079 0.1078 0.1083 

[TRAIN] Epoch[6](1182/1500); Loss: 0.069718; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1101 0.0753 0.0696 0.0662 0.0640 0.0633 0.0634 0.0638 0.0638 0.0648 0.0652 0.0671 0.0671 0.0699 0.0702 0.0717 

[TRAIN] Epoch[6](1183/1500); Loss: 0.135175; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1908 0.1698 0.1617 0.1511 0.1407 0.1324 0.1273 0.1246 0.1229 0.1215 0.1208 0.1201 0.1199 0.1196 0.1196 0.1198 

[TRAIN] Epoch[6](1184/1500); Loss: 0.087351; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1652 0.0919 0.0996 0.0943 0.0845 0.0768 0.0796 0.0780 0.0777 0.0769 0.0795 0.0770 0.0775 0.0785 0.0813 0.0793 

[TRAIN] Epoch[6](1185/1500); Loss: 0.093787; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1191 0.1542 0.1561 0.1345 0.1104 0.0928 0.0836 0.0787 0.0714 0.0748 0.0706 0.0721 0.0697 0.0710 0.0703 0.0713 

[TRAIN] Epoch[6](1186/1500); Loss: 0.143961; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1749 0.2106 0.2031 0.1860 0.1646 0.1462 0.1345 0.1283 0.1237 0.1242 0.1199 0.1198 0.1184 0.1171 0.1165 0.1157 

[TRAIN] Epoch[6](1187/1500); Loss: 0.168720; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1818 0.2069 0.2068 0.1939 0.1787 0.1680 0.1619 0.1599 0.1580 0.1586 0.1575 0.1555 0.1550 0.1542 0.1515 0.1513 

[TRAIN] Epoch[6](1188/1500); Loss: 0.107702; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1545 0.1772 0.1586 0.1377 0.1186 0.1073 0.1023 0.0925 0.0889 0.0877 0.0863 0.0840 0.0830 0.0817 0.0818 0.0812 

[TRAIN] Epoch[6](1189/1500); Loss: 0.117577; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1393 0.1382 0.1612 0.1480 0.1332 0.1185 0.1115 0.1091 0.1071 0.1031 0.1035 0.1018 0.1024 0.1010 0.1020 0.1012 

[TRAIN] Epoch[6](1190/1500); Loss: 0.057974; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1579 0.0861 0.0706 0.0634 0.0523 0.0435 0.0522 0.0430 0.0463 0.0431 0.0457 0.0433 0.0451 0.0442 0.0451 0.0458 

[TRAIN] Epoch[6](1191/1500); Loss: 0.159455; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1698 0.2112 0.2005 0.1849 0.1683 0.1572 0.1525 0.1506 0.1486 0.1485 0.1447 0.1438 0.1429 0.1432 0.1426 0.1418 

[TRAIN] Epoch[6](1192/1500); Loss: 0.047201; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0632 0.0635 0.0637 0.0539 0.0496 0.0480 0.0430 0.0413 0.0414 0.0409 0.0403 0.0410 0.0395 0.0416 0.0418 0.0424 

[TRAIN] Epoch[6](1193/1500); Loss: 0.084664; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1347 0.1374 0.1300 0.1175 0.1029 0.0887 0.0787 0.0687 0.0638 0.0621 0.0619 0.0607 0.0611 0.0618 0.0619 0.0626 

[TRAIN] Epoch[6](1194/1500); Loss: 0.087613; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1117 0.1748 0.1579 0.1321 0.1005 0.0776 0.0706 0.0647 0.0644 0.0630 0.0647 0.0625 0.0652 0.0623 0.0656 0.0641 

[TRAIN] Epoch[6](1195/1500); Loss: 0.093045; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1491 0.1041 0.1000 0.0977 0.0939 0.0914 0.0882 0.0865 0.0857 0.0861 0.0847 0.0844 0.0844 0.0838 0.0842 0.0846 

[TRAIN] Epoch[6](1196/1500); Loss: 0.188887; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2490 0.2419 0.2349 0.2212 0.2068 0.1922 0.1814 0.1751 0.1687 0.1654 0.1658 0.1656 0.1641 0.1639 0.1632 0.1630 

[TRAIN] Epoch[6](1197/1500); Loss: 0.128754; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1769 0.1751 0.1576 0.1435 0.1344 0.1256 0.1169 0.1124 0.1112 0.1109 0.1111 0.1119 0.1147 0.1174 0.1189 0.1215 

[TRAIN] Epoch[6](1198/1500); Loss: 0.078538; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1416 0.1133 0.1079 0.0978 0.0854 0.0730 0.0678 0.0638 0.0635 0.0631 0.0628 0.0631 0.0627 0.0630 0.0635 0.0642 

[TRAIN] Epoch[6](1199/1500); Loss: 0.123967; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.2318 0.1892 0.1938 0.1819 0.1623 0.1378 0.1141 0.0952 0.0877 0.0879 0.0853 0.0846 0.0832 0.0831 0.0834 0.0821 

[TRAIN] Epoch[6](1200/1500); Loss: 0.104125; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1428 0.1393 0.1236 0.1157 0.1072 0.1024 0.0985 0.0941 0.0942 0.0930 0.0917 0.0917 0.0925 0.0926 0.0931 0.0936 

[TRAIN] Epoch[6](1201/1500); Loss: 0.122352; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1652 0.1501 0.1418 0.1318 0.1232 0.1175 0.1144 0.1125 0.1121 0.1119 0.1117 0.1120 0.1126 0.1130 0.1136 0.1142 

[TRAIN] Epoch[6](1202/1500); Loss: 0.067940; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0717 0.0915 0.0784 0.0692 0.0660 0.0649 0.0638 0.0636 0.0631 0.0632 0.0638 0.0638 0.0647 0.0656 0.0663 0.0676 

[TRAIN] Epoch[6](1203/1500); Loss: 0.136241; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1896 0.1835 0.1719 0.1629 0.1530 0.1443 0.1345 0.1274 0.1223 0.1175 0.1137 0.1120 0.1115 0.1121 0.1119 0.1119 

[TRAIN] Epoch[6](1204/1500); Loss: 0.125783; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1694 0.1757 0.1729 0.1584 0.1408 0.1251 0.1159 0.1119 0.1079 0.1043 0.1057 0.1052 0.1051 0.1039 0.1053 0.1049 

[TRAIN] Epoch[6](1205/1500); Loss: 0.147162; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2117 0.1832 0.1804 0.1738 0.1649 0.1546 0.1457 0.1391 0.1327 0.1291 0.1248 0.1227 0.1233 0.1228 0.1227 0.1230 

[TRAIN] Epoch[6](1206/1500); Loss: 0.171220; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2860 0.2428 0.2313 0.2178 0.1989 0.1743 0.1532 0.1371 0.1367 0.1379 0.1355 0.1369 0.1365 0.1374 0.1382 0.1391 

[TRAIN] Epoch[6](1207/1500); Loss: 0.111194; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1632 0.1343 0.1519 0.1425 0.1283 0.1118 0.1058 0.1051 0.0901 0.0924 0.0934 0.0925 0.0917 0.0916 0.0928 0.0919 

[TRAIN] Epoch[6](1208/1500); Loss: 0.073889; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1001 0.0861 0.0766 0.0725 0.0703 0.0697 0.0697 0.0685 0.0683 0.0686 0.0693 0.0701 0.0714 0.0721 0.0735 0.0753 

[TRAIN] Epoch[6](1209/1500); Loss: 0.102755; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1262 0.1745 0.1607 0.1390 0.1158 0.1032 0.0867 0.0845 0.0831 0.0811 0.0814 0.0821 0.0803 0.0813 0.0816 0.0826 

[TRAIN] Epoch[6](1210/1500); Loss: 0.093051; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1643 0.1406 0.1245 0.1151 0.1000 0.0879 0.0813 0.0792 0.0764 0.0768 0.0743 0.0728 0.0732 0.0748 0.0736 0.0741 

[TRAIN] Epoch[6](1211/1500); Loss: 0.074559; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.0995 0.0973 0.0896 0.0818 0.0756 0.0730 0.0724 0.0672 0.0672 0.0668 0.0667 0.0665 0.0665 0.0670 0.0678 0.0682 

[TRAIN] Epoch[6](1212/1500); Loss: 0.056016; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1852 0.0762 0.0903 0.0896 0.0692 0.0380 0.0240 0.0449 0.0341 0.0349 0.0294 0.0327 0.0376 0.0329 0.0351 0.0421 

[TRAIN] Epoch[6](1213/1500); Loss: 0.127263; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1954 0.1566 0.1751 0.1656 0.1522 0.1349 0.1207 0.1111 0.1040 0.1042 0.1037 0.1033 0.1015 0.1025 0.1031 0.1021 

[TRAIN] Epoch[6](1214/1500); Loss: 0.083890; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1277 0.1432 0.1240 0.1077 0.0934 0.0810 0.0740 0.0687 0.0669 0.0672 0.0645 0.0645 0.0645 0.0650 0.0646 0.0652 

[TRAIN] Epoch[6](1215/1500); Loss: 0.130924; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1501 0.1442 0.1358 0.1315 0.1299 0.1309 0.1284 0.1266 0.1270 0.1268 0.1267 0.1265 0.1269 0.1274 0.1278 0.1283 

[TRAIN] Epoch[6](1216/1500); Loss: 0.104076; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1446 0.1518 0.1511 0.1334 0.1152 0.1040 0.1012 0.0890 0.0869 0.0856 0.0848 0.0833 0.0832 0.0833 0.0840 0.0836 

[TRAIN] Epoch[6](1217/1500); Loss: 0.095968; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1241 0.1134 0.1067 0.1007 0.0965 0.0938 0.0908 0.0899 0.0905 0.0898 0.0894 0.0890 0.0896 0.0898 0.0904 0.0910 

[TRAIN] Epoch[6](1218/1500); Loss: 0.127198; Backpropagation: 0.0925 sec; Batch: 0.4245 sec
0.2744 0.1889 0.1755 0.1724 0.1575 0.1359 0.1236 0.1085 0.0967 0.0879 0.0851 0.0845 0.0849 0.0860 0.0867 0.0867 

[TRAIN] Epoch[6](1219/1500); Loss: 0.111950; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1654 0.1441 0.1174 0.1106 0.1075 0.1052 0.1029 0.1031 0.1022 0.1026 0.1030 0.1040 0.1046 0.1054 0.1061 0.1070 

[TRAIN] Epoch[6](1220/1500); Loss: 0.077945; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1045 0.1331 0.1237 0.1070 0.0908 0.0819 0.0729 0.0666 0.0629 0.0600 0.0586 0.0571 0.0571 0.0570 0.0567 0.0573 

[TRAIN] Epoch[6](1221/1500); Loss: 0.160715; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1758 0.2225 0.2099 0.1924 0.1744 0.1620 0.1535 0.1478 0.1457 0.1435 0.1415 0.1410 0.1410 0.1413 0.1399 0.1393 

[TRAIN] Epoch[6](1222/1500); Loss: 0.131551; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1657 0.1666 0.1625 0.1518 0.1389 0.1292 0.1247 0.1210 0.1198 0.1189 0.1182 0.1186 0.1188 0.1168 0.1168 0.1164 

[TRAIN] Epoch[6](1223/1500); Loss: 0.086210; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1395 0.1624 0.1481 0.1284 0.1077 0.0890 0.0710 0.0610 0.0601 0.0594 0.0576 0.0581 0.0585 0.0587 0.0597 0.0602 

[TRAIN] Epoch[6](1224/1500); Loss: 0.104136; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1425 0.1453 0.1349 0.1244 0.1142 0.1053 0.0983 0.0910 0.0906 0.0884 0.0885 0.0874 0.0881 0.0886 0.0889 0.0896 

[TRAIN] Epoch[6](1225/1500); Loss: 0.088746; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1263 0.1132 0.1151 0.1060 0.0955 0.0880 0.0865 0.0824 0.0789 0.0784 0.0757 0.0749 0.0750 0.0743 0.0748 0.0749 

[TRAIN] Epoch[6](1226/1500); Loss: 0.101314; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1115 0.1209 0.1229 0.1127 0.1030 0.1004 0.0999 0.0945 0.0948 0.0949 0.0940 0.0941 0.0937 0.0946 0.0943 0.0950 

[TRAIN] Epoch[6](1227/1500); Loss: 0.117952; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1380 0.1438 0.1391 0.1290 0.1219 0.1178 0.1136 0.1104 0.1085 0.1087 0.1085 0.1086 0.1086 0.1091 0.1104 0.1110 

[TRAIN] Epoch[6](1228/1500); Loss: 0.104001; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1434 0.1217 0.1179 0.1125 0.1062 0.1031 0.1005 0.0966 0.0962 0.0953 0.0947 0.0946 0.0949 0.0950 0.0954 0.0960 

[TRAIN] Epoch[6](1229/1500); Loss: 0.075707; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1469 0.0372 0.1516 0.1320 0.1142 0.0835 0.0544 0.0415 0.0568 0.0607 0.0592 0.0521 0.0477 0.0580 0.0603 0.0553 

[TRAIN] Epoch[6](1230/1500); Loss: 0.103556; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1313 0.1326 0.1249 0.1146 0.1078 0.1020 0.0983 0.0951 0.0939 0.0943 0.0933 0.0929 0.0932 0.0933 0.0940 0.0953 

[TRAIN] Epoch[6](1231/1500); Loss: 0.084861; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1026 0.1137 0.0972 0.0907 0.0860 0.0830 0.0796 0.0781 0.0777 0.0775 0.0775 0.0776 0.0782 0.0789 0.0793 0.0802 

[TRAIN] Epoch[6](1232/1500); Loss: 0.122715; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1444 0.1604 0.1628 0.1460 0.1287 0.1174 0.1183 0.1159 0.1121 0.1111 0.1109 0.1100 0.1075 0.1053 0.1056 0.1072 

[TRAIN] Epoch[6](1233/1500); Loss: 0.128646; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1531 0.1848 0.1711 0.1525 0.1328 0.1194 0.1171 0.1168 0.1131 0.1125 0.1135 0.1147 0.1134 0.1134 0.1142 0.1159 

[TRAIN] Epoch[6](1234/1500); Loss: 0.132253; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1678 0.1905 0.1800 0.1650 0.1477 0.1334 0.1240 0.1184 0.1160 0.1137 0.1107 0.1092 0.1099 0.1094 0.1095 0.1106 

[TRAIN] Epoch[6](1235/1500); Loss: 0.110691; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1361 0.1501 0.1357 0.1196 0.1108 0.1078 0.1051 0.1012 0.1018 0.1010 0.1002 0.1004 0.1000 0.1002 0.1002 0.1008 

[TRAIN] Epoch[6](1236/1500); Loss: 0.136158; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1686 0.1628 0.1592 0.1500 0.1411 0.1346 0.1290 0.1259 0.1252 0.1252 0.1249 0.1257 0.1261 0.1260 0.1267 0.1276 

[TRAIN] Epoch[6](1237/1500); Loss: 0.126634; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1794 0.1631 0.1566 0.1482 0.1406 0.1311 0.1220 0.1139 0.1093 0.1098 0.1097 0.1089 0.1081 0.1081 0.1087 0.1087 

[TRAIN] Epoch[6](1238/1500); Loss: 0.144450; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1954 0.1951 0.1802 0.1665 0.1531 0.1422 0.1362 0.1320 0.1283 0.1266 0.1272 0.1262 0.1256 0.1258 0.1256 0.1252 

[TRAIN] Epoch[6](1239/1500); Loss: 0.103884; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1405 0.0775 0.1551 0.1395 0.1246 0.1010 0.0869 0.0853 0.0930 0.0886 0.0903 0.0922 0.0969 0.0965 0.0963 0.0980 

[TRAIN] Epoch[6](1240/1500); Loss: 0.100979; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1507 0.1473 0.1503 0.1367 0.1172 0.0999 0.0921 0.0893 0.0816 0.0807 0.0796 0.0792 0.0786 0.0773 0.0777 0.0775 

[TRAIN] Epoch[6](1241/1500); Loss: 0.102603; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1878 0.1317 0.1381 0.1326 0.1215 0.1053 0.0913 0.0848 0.0810 0.0818 0.0804 0.0816 0.0808 0.0807 0.0808 0.0815 

[TRAIN] Epoch[6](1242/1500); Loss: 0.096010; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1216 0.1231 0.1130 0.1036 0.0959 0.0910 0.0891 0.0884 0.0879 0.0878 0.0878 0.0881 0.0886 0.0892 0.0903 0.0906 

[TRAIN] Epoch[6](1243/1500); Loss: 0.064997; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0620 0.0806 0.1007 0.0848 0.0701 0.0645 0.0610 0.0598 0.0577 0.0590 0.0566 0.0560 0.0566 0.0574 0.0561 0.0572 

[TRAIN] Epoch[6](1244/1500); Loss: 0.130711; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1770 0.1585 0.1520 0.1437 0.1367 0.1279 0.1228 0.1206 0.1189 0.1190 0.1184 0.1187 0.1186 0.1190 0.1198 0.1199 

[TRAIN] Epoch[6](1245/1500); Loss: 0.055919; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1175 0.0853 0.0778 0.0687 0.0606 0.0507 0.0425 0.0433 0.0430 0.0419 0.0421 0.0431 0.0435 0.0440 0.0449 0.0459 

[TRAIN] Epoch[6](1246/1500); Loss: 0.070892; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1913 0.0953 0.1034 0.0920 0.0737 0.0455 0.0473 0.0648 0.0635 0.0539 0.0401 0.0616 0.0529 0.0510 0.0469 0.0511 

[TRAIN] Epoch[6](1247/1500); Loss: 0.117117; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1404 0.1395 0.1301 0.1229 0.1184 0.1162 0.1131 0.1117 0.1112 0.1108 0.1102 0.1096 0.1098 0.1097 0.1099 0.1105 

[TRAIN] Epoch[6](1248/1500); Loss: 0.137892; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2264 0.1840 0.1685 0.1527 0.1405 0.1307 0.1246 0.1206 0.1211 0.1197 0.1195 0.1193 0.1190 0.1196 0.1196 0.1207 

[TRAIN] Epoch[6](1249/1500); Loss: 0.135739; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2120 0.1961 0.1805 0.1646 0.1493 0.1363 0.1255 0.1183 0.1130 0.1121 0.1117 0.1107 0.1097 0.1104 0.1109 0.1109 

[TRAIN] Epoch[6](1250/1500); Loss: 0.097054; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1265 0.1223 0.1143 0.1047 0.0996 0.0959 0.0918 0.0895 0.0898 0.0880 0.0880 0.0878 0.0881 0.0882 0.0889 0.0896 

[TRAIN] Epoch[6](1251/1500); Loss: 0.108118; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1517 0.1438 0.1325 0.1229 0.1158 0.1082 0.1026 0.1000 0.0965 0.0948 0.0955 0.0938 0.0931 0.0927 0.0926 0.0935 

[TRAIN] Epoch[6](1252/1500); Loss: 0.103283; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1332 0.1384 0.1229 0.1087 0.1025 0.1002 0.0966 0.0955 0.0956 0.0943 0.0945 0.0938 0.0939 0.0939 0.0941 0.0945 

[TRAIN] Epoch[6](1253/1500); Loss: 0.051331; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0732 0.0599 0.0560 0.0563 0.0583 0.0455 0.0467 0.0499 0.0438 0.0464 0.0466 0.0453 0.0475 0.0483 0.0475 0.0501 

[TRAIN] Epoch[6](1254/1500); Loss: 0.150032; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2090 0.1672 0.1669 0.1630 0.1562 0.1467 0.1411 0.1424 0.1392 0.1388 0.1390 0.1383 0.1381 0.1380 0.1381 0.1387 

[TRAIN] Epoch[6](1255/1500); Loss: 0.058916; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1717 0.0686 0.0794 0.0721 0.0568 0.0413 0.0567 0.0420 0.0429 0.0432 0.0491 0.0409 0.0427 0.0446 0.0457 0.0448 

[TRAIN] Epoch[6](1256/1500); Loss: 0.085773; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1542 0.1084 0.1115 0.1090 0.1074 0.0896 0.0807 0.0756 0.0732 0.0692 0.0662 0.0658 0.0659 0.0650 0.0647 0.0661 

[TRAIN] Epoch[6](1257/1500); Loss: 0.082105; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1253 0.1073 0.1054 0.0928 0.0828 0.0821 0.0721 0.0693 0.0715 0.0717 0.0693 0.0705 0.0721 0.0725 0.0737 0.0753 

[TRAIN] Epoch[6](1258/1500); Loss: 0.120737; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1931 0.1611 0.1552 0.1520 0.1455 0.1325 0.1211 0.1103 0.1020 0.0952 0.0933 0.0933 0.0940 0.0938 0.0944 0.0949 

[TRAIN] Epoch[6](1259/1500); Loss: 0.074199; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1022 0.0955 0.0885 0.0849 0.0797 0.0741 0.0697 0.0672 0.0658 0.0656 0.0650 0.0653 0.0652 0.0658 0.0661 0.0668 

[TRAIN] Epoch[6](1260/1500); Loss: 0.136775; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1700 0.1527 0.1512 0.1505 0.1498 0.1378 0.1324 0.1291 0.1297 0.1280 0.1272 0.1264 0.1261 0.1261 0.1254 0.1261 

[TRAIN] Epoch[6](1261/1500); Loss: 0.079907; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1132 0.1101 0.0968 0.0894 0.0828 0.0766 0.0735 0.0729 0.0709 0.0707 0.0704 0.0697 0.0700 0.0702 0.0706 0.0706 

[TRAIN] Epoch[6](1262/1500); Loss: 0.127538; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1727 0.1499 0.1336 0.1321 0.1311 0.1252 0.1209 0.1204 0.1193 0.1212 0.1177 0.1188 0.1186 0.1185 0.1198 0.1207 

[TRAIN] Epoch[6](1263/1500); Loss: 0.106858; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1276 0.1318 0.1181 0.1106 0.1140 0.1048 0.1021 0.1026 0.1014 0.1009 0.0998 0.0987 0.0989 0.1004 0.0982 0.0997 

[TRAIN] Epoch[6](1264/1500); Loss: 0.097444; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1293 0.1122 0.1061 0.1026 0.1020 0.0945 0.0941 0.0937 0.0921 0.0913 0.0906 0.0904 0.0901 0.0902 0.0897 0.0899 

[TRAIN] Epoch[6](1265/1500); Loss: 0.098723; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2027 0.1659 0.1233 0.1141 0.0990 0.0900 0.0839 0.0811 0.0746 0.0757 0.0809 0.0759 0.0766 0.0783 0.0794 0.0782 

[TRAIN] Epoch[6](1266/1500); Loss: 0.080649; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.0929 0.1320 0.1144 0.0919 0.0783 0.0751 0.0731 0.0698 0.0705 0.0697 0.0691 0.0696 0.0690 0.0711 0.0715 0.0723 

[TRAIN] Epoch[6](1267/1500); Loss: 0.128753; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1417 0.1540 0.1436 0.1321 0.1352 0.1260 0.1235 0.1251 0.1247 0.1227 0.1221 0.1213 0.1222 0.1223 0.1212 0.1222 

[TRAIN] Epoch[6](1268/1500); Loss: 0.056333; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0928 0.0659 0.0576 0.0543 0.0540 0.0525 0.0515 0.0513 0.0507 0.0518 0.0509 0.0523 0.0520 0.0535 0.0545 0.0556 

[TRAIN] Epoch[6](1269/1500); Loss: 0.136190; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1517 0.1520 0.1445 0.1388 0.1363 0.1343 0.1330 0.1319 0.1318 0.1317 0.1315 0.1317 0.1320 0.1321 0.1323 0.1332 

[TRAIN] Epoch[6](1270/1500); Loss: 0.067857; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1088 0.1008 0.0915 0.0789 0.0697 0.0600 0.0548 0.0517 0.0520 0.0509 0.0538 0.0560 0.0588 0.0635 0.0655 0.0691 

[TRAIN] Epoch[6](1271/1500); Loss: 0.080974; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1048 0.0895 0.0866 0.0841 0.0822 0.0795 0.0782 0.0772 0.0763 0.0759 0.0762 0.0762 0.0765 0.0768 0.0775 0.0779 

[TRAIN] Epoch[6](1272/1500); Loss: 0.131914; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2298 0.1736 0.1752 0.1712 0.1591 0.1407 0.1217 0.1079 0.1059 0.1059 0.1037 0.1029 0.1054 0.1020 0.1025 0.1031 

[TRAIN] Epoch[6](1273/1500); Loss: 0.105496; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1331 0.1210 0.1089 0.1084 0.1075 0.1053 0.1023 0.1012 0.1006 0.0998 0.0994 0.1000 0.0997 0.0995 0.1002 0.1012 

[TRAIN] Epoch[6](1274/1500); Loss: 0.167488; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1892 0.2075 0.1939 0.1789 0.1701 0.1659 0.1622 0.1600 0.1587 0.1584 0.1560 0.1567 0.1565 0.1544 0.1551 0.1563 

[TRAIN] Epoch[6](1275/1500); Loss: 0.095263; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1222 0.1087 0.0964 0.0960 0.1029 0.0952 0.0919 0.0934 0.0904 0.0905 0.0903 0.0900 0.0894 0.0890 0.0891 0.0887 

[TRAIN] Epoch[6](1276/1500); Loss: 0.130399; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1598 0.1556 0.1466 0.1374 0.1319 0.1282 0.1264 0.1249 0.1237 0.1225 0.1218 0.1217 0.1212 0.1216 0.1215 0.1216 

[TRAIN] Epoch[6](1277/1500); Loss: 0.159188; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2072 0.1811 0.1789 0.1794 0.1727 0.1634 0.1571 0.1519 0.1480 0.1447 0.1443 0.1435 0.1432 0.1436 0.1437 0.1443 

[TRAIN] Epoch[6](1278/1500); Loss: 0.059764; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1351 0.0756 0.0745 0.0685 0.0577 0.0512 0.0506 0.0485 0.0483 0.0481 0.0487 0.0489 0.0490 0.0496 0.0508 0.0511 

[TRAIN] Epoch[6](1279/1500); Loss: 0.069636; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1088 0.0999 0.0888 0.0775 0.0688 0.0643 0.0616 0.0603 0.0604 0.0596 0.0596 0.0600 0.0603 0.0610 0.0613 0.0620 

[TRAIN] Epoch[6](1280/1500); Loss: 0.090676; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1161 0.1046 0.0963 0.0912 0.0872 0.0841 0.0842 0.0846 0.0846 0.0849 0.0858 0.0867 0.0881 0.0894 0.0906 0.0924 

[TRAIN] Epoch[6](1281/1500); Loss: 0.082768; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1301 0.0972 0.0964 0.0982 0.0936 0.0849 0.0797 0.0749 0.0697 0.0725 0.0707 0.0706 0.0710 0.0707 0.0724 0.0717 

[TRAIN] Epoch[6](1282/1500); Loss: 0.087858; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1403 0.1213 0.1050 0.0957 0.0888 0.0847 0.0770 0.0764 0.0772 0.0758 0.0767 0.0765 0.0764 0.0775 0.0777 0.0785 

[TRAIN] Epoch[6](1283/1500); Loss: 0.082941; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1165 0.1290 0.1144 0.0965 0.0881 0.0764 0.0714 0.0704 0.0719 0.0695 0.0691 0.0695 0.0691 0.0712 0.0715 0.0726 

[TRAIN] Epoch[6](1284/1500); Loss: 0.069673; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0814 0.0918 0.0786 0.0708 0.0674 0.0657 0.0641 0.0638 0.0643 0.0645 0.0650 0.0657 0.0665 0.0675 0.0681 0.0695 

[TRAIN] Epoch[6](1285/1500); Loss: 0.138502; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1805 0.1586 0.1530 0.1478 0.1414 0.1357 0.1332 0.1316 0.1302 0.1298 0.1288 0.1287 0.1290 0.1288 0.1290 0.1297 

[TRAIN] Epoch[6](1286/1500); Loss: 0.073497; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1072 0.0777 0.0763 0.0748 0.0725 0.0713 0.0711 0.0693 0.0698 0.0690 0.0689 0.0690 0.0686 0.0698 0.0699 0.0708 

[TRAIN] Epoch[6](1287/1500); Loss: 0.142805; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2106 0.1674 0.1671 0.1672 0.1615 0.1444 0.1302 0.1277 0.1267 0.1262 0.1261 0.1250 0.1268 0.1256 0.1256 0.1267 

[TRAIN] Epoch[6](1288/1500); Loss: 0.097429; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1484 0.1529 0.1345 0.1144 0.1029 0.0889 0.0857 0.0829 0.0819 0.0816 0.0806 0.0802 0.0804 0.0802 0.0813 0.0821 

[TRAIN] Epoch[6](1289/1500); Loss: 0.126286; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1655 0.1471 0.1419 0.1389 0.1353 0.1226 0.1190 0.1187 0.1191 0.1169 0.1162 0.1154 0.1158 0.1152 0.1162 0.1168 

[TRAIN] Epoch[6](1290/1500); Loss: 0.093922; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1862 0.1212 0.1009 0.0935 0.0870 0.0836 0.0978 0.0775 0.0798 0.0814 0.0862 0.0789 0.0803 0.0807 0.0859 0.0819 

[TRAIN] Epoch[6](1291/1500); Loss: 0.137042; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1839 0.1580 0.1388 0.1348 0.1333 0.1339 0.1337 0.1324 0.1309 0.1294 0.1300 0.1292 0.1292 0.1317 0.1313 0.1323 

[TRAIN] Epoch[6](1292/1500); Loss: 0.119099; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1342 0.1325 0.1271 0.1257 0.1206 0.1183 0.1190 0.1158 0.1162 0.1152 0.1144 0.1137 0.1138 0.1132 0.1130 0.1129 

[TRAIN] Epoch[6](1293/1500); Loss: 0.109158; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1375 0.1126 0.1116 0.1137 0.1162 0.1063 0.1056 0.1068 0.1045 0.1035 0.1048 0.1031 0.1037 0.1048 0.1049 0.1070 

[TRAIN] Epoch[6](1294/1500); Loss: 0.105378; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1200 0.0999 0.0998 0.1023 0.1102 0.0981 0.0999 0.1028 0.1074 0.1029 0.1037 0.1059 0.1076 0.1078 0.1080 0.1096 

[TRAIN] Epoch[6](1295/1500); Loss: 0.121055; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1596 0.1450 0.1287 0.1248 0.1213 0.1151 0.1143 0.1138 0.1146 0.1123 0.1117 0.1132 0.1140 0.1150 0.1159 0.1178 

[TRAIN] Epoch[6](1296/1500); Loss: 0.124299; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1589 0.1352 0.1373 0.1334 0.1246 0.1214 0.1204 0.1199 0.1186 0.1182 0.1174 0.1164 0.1170 0.1167 0.1168 0.1165 

[TRAIN] Epoch[6](1297/1500); Loss: 0.121515; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1773 0.1384 0.1361 0.1373 0.1290 0.1260 0.1182 0.1159 0.1137 0.1110 0.1100 0.1081 0.1061 0.1057 0.1057 0.1056 

[TRAIN] Epoch[6](1298/1500); Loss: 0.092602; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1026 0.0981 0.1014 0.0997 0.0920 0.0924 0.0920 0.0895 0.0903 0.0894 0.0892 0.0889 0.0884 0.0890 0.0888 0.0898 

[TRAIN] Epoch[6](1299/1500); Loss: 0.136098; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1509 0.1383 0.1378 0.1358 0.1381 0.1322 0.1333 0.1348 0.1330 0.1341 0.1330 0.1339 0.1344 0.1348 0.1360 0.1370 

[TRAIN] Epoch[6](1300/1500); Loss: 0.075325; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1040 0.0990 0.0808 0.0768 0.0704 0.0714 0.0721 0.0685 0.0703 0.0695 0.0690 0.0710 0.0700 0.0702 0.0709 0.0714 

[TRAIN] Epoch[6](1301/1500); Loss: 0.090666; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1273 0.1002 0.0975 0.0921 0.0896 0.0866 0.0861 0.0856 0.0852 0.0851 0.0851 0.0851 0.0857 0.0859 0.0866 0.0870 

[TRAIN] Epoch[6](1302/1500); Loss: 0.175995; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1745 0.1719 0.1704 0.1747 0.1698 0.1699 0.1700 0.1729 0.1736 0.1761 0.1767 0.1780 0.1804 0.1829 0.1856 0.1886 

[TRAIN] Epoch[6](1303/1500); Loss: 0.097204; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1149 0.1062 0.1053 0.0990 0.0949 0.0963 0.0965 0.0941 0.0950 0.0939 0.0934 0.0929 0.0929 0.0934 0.0933 0.0934 

[TRAIN] Epoch[6](1304/1500); Loss: 0.174169; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1917 0.1773 0.1867 0.1872 0.1772 0.1731 0.1718 0.1711 0.1706 0.1695 0.1686 0.1687 0.1683 0.1677 0.1687 0.1684 

[TRAIN] Epoch[6](1305/1500); Loss: 0.199613; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1730 0.1578 0.1695 0.1894 0.1876 0.1820 0.1861 0.1946 0.1989 0.2018 0.2091 0.2153 0.2220 0.2287 0.2353 0.2427 

[TRAIN] Epoch[6](1306/1500); Loss: 0.132924; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.2035 0.1724 0.1662 0.1632 0.1490 0.1300 0.1150 0.1100 0.1132 0.1116 0.1116 0.1151 0.1142 0.1153 0.1174 0.1190 

[TRAIN] Epoch[6](1307/1500); Loss: 0.145580; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2681 0.1865 0.1908 0.1830 0.1617 0.1345 0.1237 0.1147 0.1185 0.1159 0.1190 0.1187 0.1226 0.1216 0.1233 0.1267 

[TRAIN] Epoch[6](1308/1500); Loss: 0.138120; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1316 0.1290 0.1296 0.1381 0.1272 0.1230 0.1295 0.1349 0.1366 0.1356 0.1401 0.1455 0.1469 0.1500 0.1539 0.1584 

[TRAIN] Epoch[6](1309/1500); Loss: 0.155008; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1230 0.1135 0.1314 0.1580 0.1501 0.1433 0.1496 0.1542 0.1563 0.1585 0.1616 0.1669 0.1715 0.1767 0.1802 0.1854 

[TRAIN] Epoch[6](1310/1500); Loss: 0.082000; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1110 0.0974 0.0919 0.0832 0.0783 0.0768 0.0765 0.0781 0.0751 0.0752 0.0772 0.0766 0.0767 0.0783 0.0790 0.0806 

[TRAIN] Epoch[6](1311/1500); Loss: 0.079258; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0785 0.0783 0.0754 0.0845 0.0809 0.0740 0.0760 0.0753 0.0744 0.0759 0.0779 0.0785 0.0810 0.0836 0.0857 0.0883 

[TRAIN] Epoch[6](1312/1500); Loss: 0.091038; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1093 0.0956 0.0971 0.0973 0.0913 0.0893 0.0900 0.0887 0.0874 0.0874 0.0869 0.0865 0.0868 0.0867 0.0875 0.0887 

[TRAIN] Epoch[6](1313/1500); Loss: 0.151665; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1546 0.1465 0.1477 0.1481 0.1441 0.1421 0.1450 0.1457 0.1463 0.1498 0.1522 0.1554 0.1575 0.1608 0.1638 0.1671 

[TRAIN] Epoch[6](1314/1500); Loss: 0.087730; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2243 0.1332 0.1249 0.1066 0.0750 0.0716 0.0661 0.0679 0.0663 0.0633 0.0653 0.0640 0.0670 0.0684 0.0684 0.0714 

[TRAIN] Epoch[6](1315/1500); Loss: 0.173025; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1769 0.1683 0.1776 0.1779 0.1677 0.1673 0.1692 0.1693 0.1677 0.1715 0.1717 0.1739 0.1742 0.1767 0.1782 0.1806 

[TRAIN] Epoch[6](1316/1500); Loss: 0.082367; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1053 0.0963 0.1002 0.0897 0.0827 0.0838 0.0816 0.0781 0.0791 0.0757 0.0752 0.0747 0.0733 0.0741 0.0740 0.0740 

[TRAIN] Epoch[6](1317/1500); Loss: 0.163284; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1709 0.1667 0.1697 0.1615 0.1588 0.1615 0.1609 0.1594 0.1602 0.1612 0.1617 0.1618 0.1634 0.1639 0.1649 0.1660 

[TRAIN] Epoch[6](1318/1500); Loss: 0.085707; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1098 0.0897 0.0907 0.0880 0.0842 0.0836 0.0802 0.0802 0.0795 0.0795 0.0804 0.0820 0.0832 0.0846 0.0864 0.0893 

[TRAIN] Epoch[6](1319/1500); Loss: 0.091589; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0951 0.0881 0.0955 0.0838 0.0804 0.0804 0.0835 0.0855 0.0862 0.0891 0.0924 0.0944 0.0974 0.1008 0.1046 0.1082 

[TRAIN] Epoch[6](1320/1500); Loss: 0.143042; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1552 0.1588 0.1599 0.1561 0.1471 0.1426 0.1415 0.1419 0.1378 0.1369 0.1349 0.1337 0.1352 0.1350 0.1356 0.1366 

[TRAIN] Epoch[6](1321/1500); Loss: 0.088112; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0983 0.1039 0.1211 0.1010 0.0929 0.0901 0.0892 0.0849 0.0830 0.0792 0.0800 0.0770 0.0775 0.0770 0.0776 0.0772 

[TRAIN] Epoch[6](1322/1500); Loss: 0.160757; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2058 0.1808 0.1867 0.1802 0.1708 0.1634 0.1551 0.1500 0.1506 0.1481 0.1480 0.1481 0.1462 0.1449 0.1472 0.1461 

[TRAIN] Epoch[6](1323/1500); Loss: 0.082906; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1017 0.1023 0.0907 0.0798 0.0800 0.0799 0.0779 0.0790 0.0772 0.0784 0.0779 0.0791 0.0791 0.0805 0.0811 0.0818 

[TRAIN] Epoch[6](1324/1500); Loss: 0.140563; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1953 0.1724 0.1591 0.1486 0.1429 0.1332 0.1312 0.1310 0.1291 0.1294 0.1310 0.1273 0.1295 0.1295 0.1292 0.1302 

[TRAIN] Epoch[6](1325/1500); Loss: 0.145267; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2203 0.1860 0.2022 0.1983 0.1808 0.1652 0.1495 0.1341 0.1238 0.1115 0.1031 0.1041 0.1118 0.1113 0.1103 0.1117 

[TRAIN] Epoch[6](1326/1500); Loss: 0.098683; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1343 0.1191 0.1206 0.1161 0.1098 0.1004 0.0920 0.0868 0.0841 0.0831 0.0870 0.0864 0.0869 0.0885 0.0922 0.0916 

[TRAIN] Epoch[6](1327/1500); Loss: 0.172928; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1895 0.1860 0.1938 0.1865 0.1768 0.1728 0.1712 0.1676 0.1669 0.1651 0.1648 0.1644 0.1644 0.1646 0.1657 0.1667 

[TRAIN] Epoch[6](1328/1500); Loss: 0.108540; Backpropagation: 0.0915 sec; Batch: 0.4232 sec
0.1376 0.1071 0.1159 0.1227 0.1144 0.1033 0.0958 0.0962 0.0941 0.0944 0.0994 0.1050 0.1066 0.1106 0.1145 0.1190 

[TRAIN] Epoch[6](1329/1500); Loss: 0.091525; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1233 0.0808 0.0800 0.0779 0.0791 0.0767 0.0787 0.0835 0.0835 0.0879 0.0935 0.0946 0.0996 0.1044 0.1086 0.1123 

[TRAIN] Epoch[6](1330/1500); Loss: 0.092782; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1117 0.1039 0.1030 0.0997 0.0935 0.0901 0.0866 0.0842 0.0854 0.0848 0.0851 0.0870 0.0890 0.0911 0.0929 0.0964 

[TRAIN] Epoch[6](1331/1500); Loss: 0.151266; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2367 0.2105 0.2085 0.2091 0.1779 0.1538 0.1430 0.1306 0.1238 0.1173 0.1152 0.1145 0.1156 0.1177 0.1208 0.1254 

[TRAIN] Epoch[6](1332/1500); Loss: 0.087284; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1131 0.0924 0.0913 0.0948 0.0893 0.0827 0.0785 0.0792 0.0804 0.0797 0.0810 0.0821 0.0853 0.0864 0.0891 0.0913 

[TRAIN] Epoch[6](1333/1500); Loss: 0.152073; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2391 0.2033 0.1864 0.1924 0.1701 0.1470 0.1359 0.1285 0.1242 0.1215 0.1217 0.1236 0.1282 0.1332 0.1368 0.1413 

[TRAIN] Epoch[6](1334/1500); Loss: 0.086061; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1099 0.0959 0.0930 0.0961 0.0917 0.0860 0.0792 0.0773 0.0785 0.0776 0.0770 0.0790 0.0804 0.0826 0.0849 0.0878 

[TRAIN] Epoch[6](1335/1500); Loss: 0.163407; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2120 0.1875 0.1774 0.1776 0.1647 0.1544 0.1489 0.1462 0.1471 0.1472 0.1501 0.1524 0.1554 0.1599 0.1652 0.1685 

[TRAIN] Epoch[6](1336/1500); Loss: 0.112718; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1278 0.1141 0.1154 0.1152 0.1116 0.1081 0.1040 0.1049 0.1062 0.1071 0.1085 0.1106 0.1136 0.1156 0.1186 0.1222 

[TRAIN] Epoch[6](1337/1500); Loss: 0.153703; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1696 0.1566 0.1568 0.1587 0.1543 0.1506 0.1480 0.1471 0.1466 0.1465 0.1479 0.1495 0.1509 0.1540 0.1602 0.1619 

[TRAIN] Epoch[6](1338/1500); Loss: 0.127965; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1484 0.1188 0.1243 0.1377 0.1340 0.1284 0.1234 0.1227 0.1231 0.1225 0.1223 0.1238 0.1264 0.1281 0.1305 0.1332 

[TRAIN] Epoch[6](1339/1500); Loss: 0.140007; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1803 0.1589 0.1487 0.1488 0.1373 0.1292 0.1273 0.1258 0.1267 0.1283 0.1309 0.1319 0.1360 0.1408 0.1433 0.1459 

[TRAIN] Epoch[6](1340/1500); Loss: 0.207486; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2337 0.2042 0.2132 0.2317 0.2250 0.2151 0.2050 0.2037 0.2044 0.2000 0.1961 0.1960 0.1973 0.1971 0.1980 0.1990 

[TRAIN] Epoch[6](1341/1500); Loss: 0.114085; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1412 0.1247 0.1144 0.1097 0.1089 0.1053 0.1031 0.1029 0.1050 0.1060 0.1079 0.1124 0.1154 0.1186 0.1223 0.1274 

[TRAIN] Epoch[6](1342/1500); Loss: 0.166404; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1530 0.1519 0.1528 0.1510 0.1533 0.1549 0.1572 0.1605 0.1642 0.1673 0.1723 0.1766 0.1798 0.1833 0.1897 0.1946 

[TRAIN] Epoch[6](1343/1500); Loss: 0.106406; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1079 0.0952 0.0875 0.0898 0.0883 0.0882 0.0899 0.0948 0.0997 0.1052 0.1113 0.1175 0.1211 0.1280 0.1364 0.1417 

[TRAIN] Epoch[6](1344/1500); Loss: 0.158073; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1941 0.1734 0.1580 0.1623 0.1576 0.1509 0.1475 0.1465 0.1478 0.1487 0.1498 0.1523 0.1557 0.1585 0.1615 0.1647 

[TRAIN] Epoch[6](1345/1500); Loss: 0.112397; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1321 0.1163 0.1125 0.1158 0.1117 0.1092 0.1063 0.1064 0.1064 0.1066 0.1078 0.1078 0.1114 0.1144 0.1151 0.1187 

[TRAIN] Epoch[6](1346/1500); Loss: 0.182898; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2280 0.1997 0.1856 0.1981 0.1871 0.1775 0.1697 0.1704 0.1731 0.1713 0.1683 0.1719 0.1784 0.1810 0.1810 0.1852 

[TRAIN] Epoch[6](1347/1500); Loss: 0.242249; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2658 0.2457 0.2483 0.2669 0.2592 0.2490 0.2381 0.2369 0.2376 0.2329 0.2263 0.2294 0.2349 0.2345 0.2339 0.2365 

[TRAIN] Epoch[6](1348/1500); Loss: 0.119012; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1287 0.1244 0.1205 0.1182 0.1151 0.1148 0.1131 0.1128 0.1137 0.1154 0.1156 0.1174 0.1200 0.1223 0.1242 0.1280 

[TRAIN] Epoch[6](1349/1500); Loss: 0.127839; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1288 0.1192 0.1141 0.1133 0.1142 0.1161 0.1152 0.1166 0.1202 0.1259 0.1299 0.1352 0.1406 0.1453 0.1516 0.1592 

[TRAIN] Epoch[6](1350/1500); Loss: 0.133966; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1399 0.1353 0.1331 0.1362 0.1335 0.1303 0.1287 0.1302 0.1297 0.1297 0.1304 0.1324 0.1339 0.1365 0.1396 0.1440 

[TRAIN] Epoch[6](1351/1500); Loss: 0.158976; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2192 0.1890 0.1576 0.1607 0.1526 0.1458 0.1429 0.1422 0.1448 0.1461 0.1483 0.1519 0.1556 0.1586 0.1623 0.1658 

[TRAIN] Epoch[6](1352/1500); Loss: 0.122645; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1174 0.1108 0.1114 0.1134 0.1122 0.1117 0.1124 0.1179 0.1195 0.1210 0.1251 0.1308 0.1325 0.1374 0.1432 0.1456 

[TRAIN] Epoch[6](1353/1500); Loss: 0.202724; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2151 0.1937 0.2026 0.2219 0.2170 0.2105 0.2025 0.2024 0.2049 0.2013 0.1948 0.1941 0.1969 0.1958 0.1939 0.1962 

[TRAIN] Epoch[6](1354/1500); Loss: 0.162289; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1761 0.1499 0.1554 0.1764 0.1725 0.1656 0.1561 0.1562 0.1594 0.1588 0.1572 0.1591 0.1606 0.1629 0.1646 0.1659 

[TRAIN] Epoch[6](1355/1500); Loss: 0.260524; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.3154 0.2599 0.2783 0.3307 0.3167 0.2889 0.2583 0.2600 0.2640 0.2461 0.2231 0.2241 0.2358 0.2289 0.2199 0.2183 

[TRAIN] Epoch[6](1356/1500); Loss: 0.100831; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1045 0.1007 0.0957 0.0918 0.0936 0.0941 0.0943 0.0961 0.0979 0.0994 0.1020 0.1044 0.1056 0.1086 0.1113 0.1133 

[TRAIN] Epoch[6](1357/1500); Loss: 0.121063; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1326 0.1089 0.1063 0.1180 0.1153 0.1125 0.1081 0.1107 0.1169 0.1176 0.1198 0.1249 0.1316 0.1330 0.1378 0.1432 

[TRAIN] Epoch[6](1358/1500); Loss: 0.150282; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1205 0.1309 0.1248 0.1250 0.1336 0.1333 0.1319 0.1345 0.1409 0.1498 0.1566 0.1641 0.1736 0.1848 0.1946 0.2057 

[TRAIN] Epoch[6](1359/1500); Loss: 0.175004; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1864 0.1695 0.1649 0.1669 0.1661 0.1645 0.1644 0.1655 0.1680 0.1717 0.1743 0.1781 0.1830 0.1870 0.1920 0.1978 

[TRAIN] Epoch[6](1360/1500); Loss: 0.163919; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2119 0.1756 0.1822 0.1956 0.1888 0.1782 0.1648 0.1591 0.1575 0.1510 0.1435 0.1411 0.1423 0.1423 0.1433 0.1455 

[TRAIN] Epoch[6](1361/1500); Loss: 0.113382; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1223 0.1132 0.1111 0.1155 0.1130 0.1102 0.1082 0.1082 0.1086 0.1100 0.1106 0.1121 0.1148 0.1167 0.1184 0.1212 

[TRAIN] Epoch[6](1362/1500); Loss: 0.137289; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1807 0.1438 0.1464 0.1646 0.1589 0.1476 0.1359 0.1326 0.1333 0.1281 0.1206 0.1200 0.1197 0.1196 0.1205 0.1243 

[TRAIN] Epoch[6](1363/1500); Loss: 0.079818; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0739 0.0693 0.0743 0.0731 0.0725 0.0730 0.0750 0.0764 0.0795 0.0815 0.0823 0.0838 0.0882 0.0894 0.0918 0.0932 

[TRAIN] Epoch[6](1364/1500); Loss: 0.114669; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1212 0.1014 0.0962 0.0873 0.0893 0.1147 0.1111 0.1064 0.1047 0.1070 0.1171 0.1217 0.1291 0.1369 0.1425 0.1482 

[TRAIN] Epoch[6](1365/1500); Loss: 0.104976; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1404 0.1253 0.1140 0.1044 0.0971 0.0993 0.0943 0.0888 0.0886 0.0926 0.0945 0.0981 0.1058 0.1071 0.1120 0.1174 

[TRAIN] Epoch[6](1366/1500); Loss: 0.123418; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1320 0.1164 0.1110 0.1110 0.1085 0.1085 0.1095 0.1157 0.1180 0.1203 0.1235 0.1299 0.1357 0.1388 0.1449 0.1509 

[TRAIN] Epoch[6](1367/1500); Loss: 0.113595; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1490 0.1296 0.1114 0.1073 0.1011 0.0967 0.0976 0.0992 0.1013 0.1055 0.1085 0.1125 0.1178 0.1232 0.1266 0.1302 

[TRAIN] Epoch[6](1368/1500); Loss: 0.072935; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0683 0.0658 0.0608 0.0621 0.0629 0.0627 0.0635 0.0667 0.0699 0.0709 0.0758 0.0804 0.0817 0.0867 0.0922 0.0965 

[TRAIN] Epoch[6](1369/1500); Loss: 0.141158; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1689 0.1529 0.1461 0.1494 0.1460 0.1406 0.1366 0.1351 0.1331 0.1320 0.1323 0.1326 0.1336 0.1368 0.1396 0.1429 

[TRAIN] Epoch[6](1370/1500); Loss: 0.188161; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2183 0.2013 0.1915 0.1911 0.1860 0.1803 0.1773 0.1765 0.1769 0.1786 0.1802 0.1838 0.1867 0.1901 0.1940 0.1980 

[TRAIN] Epoch[6](1371/1500); Loss: 0.097675; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1463 0.1173 0.0816 0.0893 0.0902 0.0875 0.0841 0.0843 0.0908 0.0956 0.0911 0.0917 0.0967 0.1057 0.1027 0.1080 

[TRAIN] Epoch[6](1372/1500); Loss: 0.081959; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1124 0.0979 0.0849 0.0770 0.0748 0.0743 0.0741 0.0740 0.0740 0.0753 0.0777 0.0785 0.0810 0.0830 0.0857 0.0869 

[TRAIN] Epoch[6](1373/1500); Loss: 0.108064; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1102 0.1141 0.1073 0.1032 0.1021 0.1020 0.1039 0.1035 0.1040 0.1059 0.1069 0.1094 0.1117 0.1122 0.1148 0.1178 

[TRAIN] Epoch[6](1374/1500); Loss: 0.086810; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1126 0.0939 0.0887 0.0937 0.0889 0.0818 0.0770 0.0776 0.0793 0.0792 0.0806 0.0817 0.0859 0.0870 0.0891 0.0921 

[TRAIN] Epoch[6](1375/1500); Loss: 0.138268; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1757 0.1510 0.1501 0.1566 0.1504 0.1417 0.1336 0.1303 0.1275 0.1240 0.1237 0.1262 0.1277 0.1282 0.1310 0.1346 

[TRAIN] Epoch[6](1376/1500); Loss: 0.131988; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1694 0.1397 0.1417 0.1522 0.1444 0.1326 0.1208 0.1172 0.1181 0.1198 0.1190 0.1215 0.1249 0.1292 0.1283 0.1328 

[TRAIN] Epoch[6](1377/1500); Loss: 0.185351; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2123 0.1920 0.1904 0.1915 0.1873 0.1813 0.1759 0.1755 0.1750 0.1789 0.1801 0.1795 0.1824 0.1858 0.1885 0.1894 

[TRAIN] Epoch[6](1378/1500); Loss: 0.160130; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2032 0.1848 0.1747 0.1728 0.1674 0.1609 0.1559 0.1523 0.1488 0.1490 0.1457 0.1448 0.1464 0.1515 0.1508 0.1531 

[TRAIN] Epoch[6](1379/1500); Loss: 0.078711; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0791 0.0708 0.0699 0.0684 0.0647 0.0670 0.0695 0.0724 0.0743 0.0762 0.0798 0.0859 0.0896 0.0913 0.0971 0.1035 

[TRAIN] Epoch[6](1380/1500); Loss: 0.109081; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1699 0.1231 0.1131 0.1135 0.0979 0.0883 0.0907 0.0964 0.0940 0.0961 0.1023 0.1071 0.1060 0.1097 0.1163 0.1207 

[TRAIN] Epoch[6](1381/1500); Loss: 0.089543; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1088 0.0977 0.0943 0.0955 0.0927 0.0877 0.0828 0.0809 0.0790 0.0807 0.0825 0.0849 0.0871 0.0901 0.0924 0.0958 

[TRAIN] Epoch[6](1382/1500); Loss: 0.174932; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2067 0.1920 0.1914 0.1941 0.1887 0.1826 0.1733 0.1679 0.1641 0.1594 0.1583 0.1598 0.1624 0.1634 0.1659 0.1691 

[TRAIN] Epoch[6](1383/1500); Loss: 0.113456; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1290 0.1187 0.1140 0.1094 0.1070 0.1079 0.1077 0.1063 0.1081 0.1091 0.1104 0.1131 0.1149 0.1173 0.1202 0.1223 

[TRAIN] Epoch[6](1384/1500); Loss: 0.095449; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1052 0.0747 0.0758 0.0766 0.0724 0.0792 0.0846 0.0856 0.0878 0.0893 0.1011 0.1119 0.1119 0.1161 0.1209 0.1340 

[TRAIN] Epoch[6](1385/1500); Loss: 0.152785; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2200 0.1963 0.1880 0.1877 0.1779 0.1635 0.1502 0.1412 0.1332 0.1268 0.1230 0.1230 0.1248 0.1260 0.1290 0.1339 

[TRAIN] Epoch[6](1386/1500); Loss: 0.142320; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1981 0.1709 0.1648 0.1700 0.1637 0.1504 0.1390 0.1321 0.1227 0.1172 0.1180 0.1207 0.1225 0.1269 0.1295 0.1307 

[TRAIN] Epoch[6](1387/1500); Loss: 0.079315; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1121 0.0897 0.0866 0.0921 0.0833 0.0745 0.0641 0.0627 0.0647 0.0659 0.0698 0.0750 0.0760 0.0794 0.0855 0.0878 

[TRAIN] Epoch[6](1388/1500); Loss: 0.139735; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1534 0.1471 0.1435 0.1416 0.1382 0.1362 0.1364 0.1345 0.1349 0.1359 0.1356 0.1367 0.1379 0.1392 0.1414 0.1431 

[TRAIN] Epoch[6](1389/1500); Loss: 0.174896; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2710 0.2213 0.2331 0.2466 0.2331 0.2091 0.1760 0.1531 0.1320 0.1216 0.1259 0.1288 0.1298 0.1340 0.1402 0.1429 

[TRAIN] Epoch[6](1390/1500); Loss: 0.085079; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1180 0.1016 0.0891 0.0838 0.0741 0.0727 0.0727 0.0740 0.0747 0.0786 0.0811 0.0819 0.0851 0.0888 0.0904 0.0946 

[TRAIN] Epoch[6](1391/1500); Loss: 0.205405; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.2634 0.2406 0.2392 0.2439 0.2368 0.2261 0.2148 0.2044 0.1940 0.1831 0.1741 0.1701 0.1706 0.1740 0.1755 0.1759 

[TRAIN] Epoch[6](1392/1500); Loss: 0.134712; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1760 0.1481 0.1499 0.1531 0.1469 0.1361 0.1267 0.1253 0.1243 0.1231 0.1223 0.1223 0.1224 0.1239 0.1258 0.1292 

[TRAIN] Epoch[6](1393/1500); Loss: 0.189912; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2691 0.2407 0.2371 0.2405 0.2325 0.2183 0.1994 0.1850 0.1695 0.1571 0.1478 0.1447 0.1458 0.1484 0.1498 0.1528 

[TRAIN] Epoch[6](1394/1500); Loss: 0.197554; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2583 0.2356 0.2320 0.2348 0.2290 0.2182 0.2059 0.1964 0.1858 0.1762 0.1668 0.1610 0.1631 0.1647 0.1656 0.1674 

[TRAIN] Epoch[6](1395/1500); Loss: 0.132132; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1699 0.1545 0.1374 0.1311 0.1230 0.1188 0.1181 0.1186 0.1205 0.1225 0.1247 0.1281 0.1314 0.1353 0.1380 0.1421 

[TRAIN] Epoch[6](1396/1500); Loss: 0.136253; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2511 0.1857 0.2049 0.2117 0.1959 0.1665 0.1282 0.1009 0.0813 0.0827 0.0894 0.0877 0.0893 0.0994 0.1043 0.1010 

[TRAIN] Epoch[6](1397/1500); Loss: 0.131391; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1483 0.1429 0.1289 0.1190 0.1149 0.1160 0.1177 0.1194 0.1225 0.1271 0.1300 0.1335 0.1378 0.1434 0.1476 0.1533 

[TRAIN] Epoch[6](1398/1500); Loss: 0.124753; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1402 0.1269 0.1277 0.1317 0.1278 0.1227 0.1200 0.1174 0.1140 0.1157 0.1192 0.1217 0.1217 0.1245 0.1297 0.1352 

[TRAIN] Epoch[6](1399/1500); Loss: 0.179770; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2335 0.2127 0.1818 0.1885 0.1813 0.1715 0.1682 0.1689 0.1664 0.1642 0.1650 0.1679 0.1716 0.1742 0.1781 0.1825 

[TRAIN] Epoch[6](1400/1500); Loss: 0.184085; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1878 0.1865 0.1811 0.1807 0.1747 0.1755 0.1766 0.1765 0.1775 0.1805 0.1836 0.1859 0.1875 0.1914 0.1974 0.2023 

[TRAIN] Epoch[6](1401/1500); Loss: 0.134029; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1631 0.1456 0.1391 0.1304 0.1290 0.1284 0.1247 0.1240 0.1272 0.1285 0.1278 0.1309 0.1334 0.1354 0.1383 0.1387 

[TRAIN] Epoch[6](1402/1500); Loss: 0.132501; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1479 0.1401 0.1335 0.1309 0.1281 0.1277 0.1250 0.1242 0.1260 0.1283 0.1296 0.1312 0.1330 0.1347 0.1381 0.1417 

[TRAIN] Epoch[6](1403/1500); Loss: 0.180170; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2721 0.2353 0.2305 0.2305 0.2116 0.1884 0.1622 0.1467 0.1370 0.1372 0.1477 0.1493 0.1489 0.1535 0.1628 0.1690 

[TRAIN] Epoch[6](1404/1500); Loss: 0.063778; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.0618 0.0633 0.0602 0.0537 0.0510 0.0523 0.0557 0.0564 0.0595 0.0642 0.0643 0.0682 0.0725 0.0756 0.0804 0.0815 

[TRAIN] Epoch[6](1405/1500); Loss: 0.173318; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2412 0.2062 0.2031 0.2131 0.2068 0.1909 0.1745 0.1613 0.1475 0.1403 0.1422 0.1448 0.1452 0.1485 0.1522 0.1550 

[TRAIN] Epoch[6](1406/1500); Loss: 0.105370; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1754 0.1339 0.1381 0.1415 0.1297 0.1111 0.0941 0.0839 0.0804 0.0806 0.0832 0.0829 0.0861 0.0865 0.0879 0.0906 

[TRAIN] Epoch[6](1407/1500); Loss: 0.146514; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1740 0.1638 0.1492 0.1492 0.1454 0.1426 0.1406 0.1398 0.1392 0.1393 0.1400 0.1416 0.1419 0.1443 0.1461 0.1473 

[TRAIN] Epoch[6](1408/1500); Loss: 0.096307; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1136 0.1050 0.0926 0.0940 0.0918 0.0931 0.0919 0.0933 0.0924 0.0938 0.0935 0.0960 0.0955 0.0969 0.0984 0.0992 

[TRAIN] Epoch[6](1409/1500); Loss: 0.112775; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1544 0.1206 0.1066 0.1118 0.1079 0.1043 0.0993 0.1013 0.1058 0.1049 0.1054 0.1106 0.1133 0.1145 0.1204 0.1233 

[TRAIN] Epoch[6](1410/1500); Loss: 0.118706; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1970 0.1259 0.0943 0.0845 0.0797 0.0923 0.1051 0.1012 0.0961 0.1041 0.1244 0.1286 0.1300 0.1339 0.1486 0.1538 

[TRAIN] Epoch[6](1411/1500); Loss: 0.122303; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1788 0.1481 0.1270 0.1297 0.1230 0.1161 0.1106 0.1109 0.1098 0.1086 0.1136 0.1118 0.1139 0.1159 0.1183 0.1209 

[TRAIN] Epoch[6](1412/1500); Loss: 0.133965; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2199 0.1669 0.1282 0.1343 0.1306 0.1279 0.1261 0.1247 0.1227 0.1208 0.1215 0.1215 0.1212 0.1242 0.1248 0.1283 

[TRAIN] Epoch[6](1413/1500); Loss: 0.097331; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0994 0.0838 0.0879 0.0870 0.0860 0.0866 0.0891 0.0923 0.0930 0.0954 0.0994 0.1036 0.1069 0.1114 0.1148 0.1207 

[TRAIN] Epoch[6](1414/1500); Loss: 0.108772; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1281 0.1065 0.1035 0.0978 0.0992 0.1010 0.1022 0.0995 0.1088 0.1069 0.1081 0.1058 0.1187 0.1163 0.1189 0.1193 

[TRAIN] Epoch[6](1415/1500); Loss: 0.159601; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2226 0.1787 0.1793 0.1891 0.1825 0.1752 0.1612 0.1518 0.1440 0.1386 0.1321 0.1352 0.1361 0.1379 0.1430 0.1465 

[TRAIN] Epoch[6](1416/1500); Loss: 0.133151; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1588 0.1304 0.1338 0.1471 0.1424 0.1359 0.1304 0.1256 0.1241 0.1240 0.1262 0.1276 0.1282 0.1302 0.1324 0.1333 

[TRAIN] Epoch[6](1417/1500); Loss: 0.202821; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2976 0.2483 0.2532 0.2788 0.2681 0.2461 0.2165 0.1991 0.1792 0.1605 0.1496 0.1430 0.1428 0.1474 0.1564 0.1585 

[TRAIN] Epoch[6](1418/1500); Loss: 0.099716; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1329 0.0998 0.1059 0.1192 0.1100 0.0995 0.0919 0.0888 0.0858 0.0892 0.0868 0.0912 0.0931 0.0963 0.1023 0.1027 

[TRAIN] Epoch[6](1419/1500); Loss: 0.136744; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1527 0.1337 0.1338 0.1388 0.1334 0.1295 0.1224 0.1233 0.1287 0.1308 0.1333 0.1335 0.1444 0.1481 0.1521 0.1493 

[TRAIN] Epoch[6](1420/1500); Loss: 0.140336; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2102 0.1837 0.1506 0.1371 0.1285 0.1234 0.1230 0.1233 0.1257 0.1271 0.1287 0.1310 0.1341 0.1364 0.1392 0.1433 

[TRAIN] Epoch[6](1421/1500); Loss: 0.145961; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1614 0.1420 0.1348 0.1319 0.1343 0.1380 0.1409 0.1419 0.1442 0.1457 0.1465 0.1492 0.1530 0.1548 0.1569 0.1598 

[TRAIN] Epoch[6](1422/1500); Loss: 0.138245; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2208 0.1718 0.1320 0.1196 0.1109 0.1168 0.1161 0.1156 0.1288 0.1293 0.1283 0.1352 0.1414 0.1434 0.1447 0.1572 

[TRAIN] Epoch[6](1423/1500); Loss: 0.171333; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2468 0.2005 0.1651 0.1644 0.1627 0.1640 0.1600 0.1629 0.1661 0.1604 0.1586 0.1594 0.1678 0.1653 0.1647 0.1724 

[TRAIN] Epoch[6](1424/1500); Loss: 0.105143; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1198 0.0964 0.1038 0.1055 0.1004 0.1022 0.1015 0.1003 0.1011 0.1034 0.1054 0.1051 0.1053 0.1088 0.1100 0.1132 

[TRAIN] Epoch[6](1425/1500); Loss: 0.178739; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1894 0.1767 0.1846 0.1867 0.1841 0.1803 0.1756 0.1730 0.1760 0.1740 0.1694 0.1735 0.1788 0.1761 0.1787 0.1830 

[TRAIN] Epoch[6](1426/1500); Loss: 0.119558; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1977 0.1615 0.1241 0.1128 0.1041 0.1014 0.1003 0.1043 0.1058 0.1080 0.1115 0.1110 0.1142 0.1163 0.1186 0.1213 

[TRAIN] Epoch[6](1427/1500); Loss: 0.169294; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.2233 0.1957 0.1648 0.1572 0.1524 0.1543 0.1542 0.1565 0.1578 0.1615 0.1634 0.1689 0.1677 0.1697 0.1792 0.1822 

[TRAIN] Epoch[6](1428/1500); Loss: 0.281737; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.4819 0.4022 0.4076 0.4352 0.4172 0.3785 0.3298 0.2958 0.2552 0.2046 0.1683 0.1462 0.1389 0.1441 0.1527 0.1497 

[TRAIN] Epoch[6](1429/1500); Loss: 0.227244; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2892 0.2523 0.2598 0.2718 0.2649 0.2547 0.2427 0.2335 0.2215 0.2094 0.2023 0.1971 0.1890 0.1845 0.1833 0.1802 

[TRAIN] Epoch[6](1430/1500); Loss: 0.140483; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1581 0.1394 0.1370 0.1361 0.1348 0.1343 0.1330 0.1337 0.1363 0.1380 0.1388 0.1413 0.1427 0.1459 0.1486 0.1497 

[TRAIN] Epoch[6](1431/1500); Loss: 0.111440; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1800 0.1441 0.1126 0.1015 0.0969 0.0947 0.0949 0.0944 0.1043 0.1025 0.1036 0.1080 0.1076 0.1092 0.1141 0.1147 

[TRAIN] Epoch[6](1432/1500); Loss: 0.269107; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.4419 0.3737 0.3752 0.3892 0.3719 0.3400 0.3049 0.2747 0.2379 0.1981 0.1725 0.1601 0.1598 0.1649 0.1700 0.1707 

[TRAIN] Epoch[6](1433/1500); Loss: 0.199750; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2639 0.2166 0.2173 0.2340 0.2249 0.2169 0.2058 0.1974 0.1932 0.1883 0.1824 0.1750 0.1705 0.1709 0.1701 0.1688 

[TRAIN] Epoch[6](1434/1500); Loss: 0.190105; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2092 0.1895 0.1938 0.2042 0.1990 0.1970 0.1885 0.1834 0.1813 0.1819 0.1814 0.1836 0.1852 0.1850 0.1872 0.1917 

[TRAIN] Epoch[6](1435/1500); Loss: 0.144184; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1993 0.1765 0.1439 0.1355 0.1316 0.1301 0.1264 0.1326 0.1323 0.1330 0.1390 0.1427 0.1410 0.1448 0.1480 0.1501 

[TRAIN] Epoch[6](1436/1500); Loss: 0.088445; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0955 0.0825 0.0781 0.0777 0.0801 0.0815 0.0791 0.0836 0.0830 0.0888 0.0887 0.0928 0.0959 0.0988 0.1050 0.1040 

[TRAIN] Epoch[6](1437/1500); Loss: 0.108003; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2463 0.1702 0.0771 0.0620 0.0640 0.0670 0.0846 0.0853 0.0849 0.0889 0.1074 0.1092 0.1103 0.1148 0.1184 0.1378 

[TRAIN] Epoch[6](1438/1500); Loss: 0.104007; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1096 0.0908 0.0904 0.0827 0.0872 0.0897 0.0933 0.0943 0.1037 0.1020 0.1106 0.1124 0.1198 0.1179 0.1241 0.1358 

[TRAIN] Epoch[6](1439/1500); Loss: 0.125995; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1482 0.1287 0.1255 0.1190 0.1209 0.1205 0.1209 0.1212 0.1218 0.1240 0.1233 0.1255 0.1276 0.1288 0.1273 0.1326 

[TRAIN] Epoch[6](1440/1500); Loss: 0.175978; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1791 0.1764 0.1782 0.1743 0.1775 0.1762 0.1757 0.1744 0.1743 0.1734 0.1736 0.1750 0.1752 0.1757 0.1775 0.1792 

[TRAIN] Epoch[6](1441/1500); Loss: 0.127285; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1884 0.1656 0.1352 0.1224 0.1129 0.1134 0.1094 0.1121 0.1114 0.1167 0.1167 0.1205 0.1228 0.1261 0.1282 0.1348 

[TRAIN] Epoch[6](1442/1500); Loss: 0.184766; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2436 0.2190 0.2055 0.1983 0.1922 0.1897 0.1826 0.1792 0.1771 0.1716 0.1672 0.1658 0.1655 0.1642 0.1671 0.1678 

[TRAIN] Epoch[6](1443/1500); Loss: 0.088860; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0823 0.0698 0.0888 0.0849 0.0789 0.0807 0.0888 0.0857 0.0865 0.0936 0.0923 0.0930 0.0941 0.0981 0.0996 0.1044 

[TRAIN] Epoch[6](1444/1500); Loss: 0.111756; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1425 0.1165 0.1163 0.1173 0.1156 0.1094 0.1102 0.1070 0.1081 0.1070 0.1033 0.1061 0.1059 0.1074 0.1055 0.1102 

[TRAIN] Epoch[6](1445/1500); Loss: 0.136663; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1334 0.1231 0.1299 0.1279 0.1282 0.1308 0.1350 0.1316 0.1378 0.1366 0.1400 0.1405 0.1430 0.1474 0.1509 0.1506 

[TRAIN] Epoch[6](1446/1500); Loss: 0.096221; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1164 0.1031 0.0999 0.0937 0.0885 0.0881 0.0932 0.0896 0.0880 0.0908 0.0935 0.0946 0.0962 0.0978 0.0998 0.1064 

[TRAIN] Epoch[6](1447/1500); Loss: 0.123554; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1691 0.1499 0.1310 0.1217 0.1170 0.1190 0.1159 0.1131 0.1129 0.1153 0.1134 0.1156 0.1191 0.1179 0.1221 0.1240 

[TRAIN] Epoch[6](1448/1500); Loss: 0.174484; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2040 0.1866 0.1927 0.1939 0.1901 0.1848 0.1793 0.1789 0.1720 0.1671 0.1618 0.1595 0.1570 0.1566 0.1537 0.1537 

[TRAIN] Epoch[6](1449/1500); Loss: 0.139325; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1625 0.1390 0.1332 0.1342 0.1284 0.1260 0.1341 0.1403 0.1358 0.1363 0.1321 0.1476 0.1434 0.1427 0.1427 0.1509 

[TRAIN] Epoch[6](1450/1500); Loss: 0.224057; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2743 0.2531 0.2580 0.2564 0.2507 0.2418 0.2334 0.2260 0.2185 0.2120 0.2055 0.1977 0.1916 0.1882 0.1885 0.1890 

[TRAIN] Epoch[6](1451/1500); Loss: 0.098872; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1475 0.1206 0.1095 0.0971 0.0915 0.0923 0.0891 0.0859 0.0838 0.0930 0.0902 0.0907 0.0892 0.1003 0.0984 0.1029 

[TRAIN] Epoch[6](1452/1500); Loss: 0.171458; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2422 0.2162 0.2003 0.1911 0.1784 0.1699 0.1619 0.1575 0.1496 0.1422 0.1473 0.1512 0.1551 0.1562 0.1616 0.1627 

[TRAIN] Epoch[6](1453/1500); Loss: 0.101681; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1172 0.1040 0.1036 0.1006 0.1008 0.0959 0.0957 0.0989 0.0968 0.0959 0.0976 0.1035 0.1020 0.1014 0.1047 0.1082 

[TRAIN] Epoch[6](1454/1500); Loss: 0.056038; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0524 0.0493 0.0540 0.0513 0.0475 0.0572 0.0534 0.0516 0.0559 0.0569 0.0544 0.0625 0.0596 0.0621 0.0629 0.0655 

[TRAIN] Epoch[6](1455/1500); Loss: 0.119861; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1529 0.1267 0.1235 0.1231 0.1191 0.1136 0.1140 0.1144 0.1143 0.1135 0.1147 0.1156 0.1153 0.1187 0.1176 0.1207 

[TRAIN] Epoch[6](1456/1500); Loss: 0.108584; Backpropagation: 0.0915 sec; Batch: 0.4236 sec
0.1896 0.1368 0.1083 0.1031 0.0961 0.0991 0.1009 0.0983 0.0952 0.1004 0.0974 0.0982 0.0977 0.1047 0.1044 0.1069 

[TRAIN] Epoch[6](1457/1500); Loss: 0.137326; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1687 0.1458 0.1381 0.1299 0.1263 0.1248 0.1270 0.1232 0.1259 0.1254 0.1290 0.1383 0.1404 0.1440 0.1512 0.1590 

[TRAIN] Epoch[6](1458/1500); Loss: 0.143856; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2111 0.1738 0.1455 0.1429 0.1407 0.1397 0.1353 0.1322 0.1326 0.1320 0.1310 0.1322 0.1358 0.1386 0.1384 0.1399 

[TRAIN] Epoch[6](1459/1500); Loss: 0.150562; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1966 0.1739 0.1572 0.1488 0.1460 0.1441 0.1438 0.1436 0.1433 0.1431 0.1437 0.1429 0.1447 0.1450 0.1463 0.1459 

[TRAIN] Epoch[6](1460/1500); Loss: 0.164283; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2188 0.1945 0.1732 0.1612 0.1577 0.1606 0.1611 0.1557 0.1488 0.1611 0.1570 0.1521 0.1518 0.1571 0.1599 0.1581 

[TRAIN] Epoch[6](1461/1500); Loss: 0.146722; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3004 0.2481 0.1900 0.1625 0.1381 0.1228 0.1145 0.1100 0.1113 0.1099 0.1173 0.1204 0.1236 0.1211 0.1273 0.1303 

[TRAIN] Epoch[6](1462/1500); Loss: 0.127753; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1403 0.1325 0.1374 0.1363 0.1307 0.1351 0.1276 0.1236 0.1181 0.1253 0.1229 0.1212 0.1161 0.1270 0.1255 0.1246 

[TRAIN] Epoch[6](1463/1500); Loss: 0.110935; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2579 0.1991 0.1443 0.1205 0.0990 0.0835 0.0800 0.0804 0.0854 0.0834 0.0854 0.0919 0.0884 0.0897 0.0904 0.0956 

[TRAIN] Epoch[6](1464/1500); Loss: 0.156333; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1851 0.1585 0.1638 0.1716 0.1663 0.1605 0.1524 0.1520 0.1507 0.1474 0.1498 0.1479 0.1482 0.1473 0.1486 0.1511 

[TRAIN] Epoch[6](1465/1500); Loss: 0.148921; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2092 0.1751 0.1626 0.1546 0.1485 0.1452 0.1414 0.1397 0.1363 0.1383 0.1385 0.1359 0.1406 0.1396 0.1373 0.1399 

[TRAIN] Epoch[6](1466/1500); Loss: 0.170696; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2155 0.1882 0.1897 0.1946 0.1890 0.1786 0.1681 0.1619 0.1591 0.1564 0.1544 0.1529 0.1553 0.1559 0.1560 0.1556 

[TRAIN] Epoch[6](1467/1500); Loss: 0.104019; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1281 0.0961 0.1022 0.0932 0.0992 0.0981 0.1032 0.0946 0.1046 0.1001 0.1035 0.1001 0.1080 0.1104 0.1102 0.1127 

[TRAIN] Epoch[6](1468/1500); Loss: 0.100838; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1199 0.1058 0.0992 0.0959 0.0964 0.0964 0.0990 0.0983 0.0988 0.0995 0.0994 0.0998 0.1000 0.1002 0.1022 0.1026 

[TRAIN] Epoch[6](1469/1500); Loss: 0.081259; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1410 0.0785 0.0697 0.0632 0.0610 0.0744 0.0730 0.0713 0.0692 0.0750 0.0841 0.0868 0.0816 0.0866 0.0898 0.0950 

[TRAIN] Epoch[6](1470/1500); Loss: 0.097821; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1399 0.1152 0.1132 0.1121 0.1121 0.1026 0.0955 0.0887 0.0860 0.0848 0.0815 0.0860 0.0872 0.0842 0.0882 0.0880 

[TRAIN] Epoch[6](1471/1500); Loss: 0.138957; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1857 0.1604 0.1461 0.1400 0.1350 0.1338 0.1262 0.1235 0.1310 0.1294 0.1286 0.1276 0.1372 0.1365 0.1415 0.1408 

[TRAIN] Epoch[6](1472/1500); Loss: 0.117493; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1698 0.1303 0.1212 0.1224 0.1114 0.1040 0.1091 0.1095 0.1087 0.1048 0.1161 0.1135 0.1098 0.1127 0.1199 0.1165 

[TRAIN] Epoch[6](1473/1500); Loss: 0.167487; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2868 0.2326 0.1991 0.1852 0.1721 0.1605 0.1510 0.1476 0.1465 0.1432 0.1420 0.1421 0.1404 0.1403 0.1460 0.1444 

[TRAIN] Epoch[6](1474/1500); Loss: 0.155733; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1918 0.1724 0.1666 0.1597 0.1531 0.1542 0.1516 0.1477 0.1476 0.1485 0.1458 0.1481 0.1504 0.1488 0.1512 0.1541 

[TRAIN] Epoch[6](1475/1500); Loss: 0.082293; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1245 0.0656 0.0686 0.0614 0.0627 0.0646 0.0730 0.0756 0.0764 0.0750 0.0863 0.0891 0.0938 0.0923 0.1007 0.1071 

[TRAIN] Epoch[6](1476/1500); Loss: 0.194079; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2721 0.2339 0.2436 0.2509 0.2432 0.2267 0.2134 0.1992 0.1839 0.1706 0.1607 0.1486 0.1429 0.1416 0.1379 0.1361 

[TRAIN] Epoch[6](1477/1500); Loss: 0.143834; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2070 0.1699 0.1530 0.1423 0.1373 0.1343 0.1334 0.1332 0.1357 0.1326 0.1344 0.1330 0.1378 0.1391 0.1378 0.1405 

[TRAIN] Epoch[6](1478/1500); Loss: 0.184273; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2255 0.1927 0.1810 0.1769 0.1763 0.1767 0.1740 0.1738 0.1763 0.1790 0.1802 0.1796 0.1871 0.1872 0.1889 0.1933 

[TRAIN] Epoch[6](1479/1500); Loss: 0.069981; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1206 0.0891 0.0661 0.0585 0.0567 0.0597 0.0608 0.0635 0.0644 0.0642 0.0656 0.0684 0.0691 0.0702 0.0714 0.0716 

[TRAIN] Epoch[6](1480/1500); Loss: 0.194900; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2508 0.2230 0.2195 0.2160 0.2086 0.2041 0.1969 0.1910 0.1858 0.1826 0.1781 0.1756 0.1757 0.1708 0.1696 0.1703 

[TRAIN] Epoch[6](1481/1500); Loss: 0.097717; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1406 0.1098 0.0953 0.0907 0.0940 0.0915 0.0888 0.0900 0.0947 0.0920 0.0900 0.0960 0.0970 0.0950 0.0986 0.0994 

[TRAIN] Epoch[6](1482/1500); Loss: 0.122069; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1996 0.1376 0.1220 0.1159 0.1120 0.1098 0.1107 0.1096 0.1071 0.1159 0.1168 0.1146 0.1156 0.1210 0.1216 0.1233 

[TRAIN] Epoch[6](1483/1500); Loss: 0.109994; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1357 0.1187 0.1128 0.1122 0.1089 0.1066 0.1055 0.1051 0.1046 0.1057 0.1056 0.1066 0.1071 0.1071 0.1081 0.1097 

[TRAIN] Epoch[6](1484/1500); Loss: 0.162311; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1815 0.1685 0.1658 0.1645 0.1645 0.1639 0.1625 0.1613 0.1614 0.1592 0.1590 0.1579 0.1585 0.1566 0.1560 0.1558 

[TRAIN] Epoch[6](1485/1500); Loss: 0.140072; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.2130 0.1819 0.1510 0.1402 0.1364 0.1334 0.1255 0.1293 0.1257 0.1252 0.1289 0.1262 0.1265 0.1298 0.1358 0.1324 

[TRAIN] Epoch[6](1486/1500); Loss: 0.117721; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1867 0.1238 0.1186 0.1105 0.1033 0.1122 0.1080 0.1064 0.1057 0.1158 0.1119 0.1082 0.1160 0.1203 0.1188 0.1173 

[TRAIN] Epoch[6](1487/1500); Loss: 0.186224; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2207 0.1966 0.1897 0.1874 0.1835 0.1790 0.1783 0.1777 0.1787 0.1806 0.1808 0.1833 0.1885 0.1851 0.1840 0.1858 

[TRAIN] Epoch[6](1488/1500); Loss: 0.248650; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.3230 0.2915 0.2842 0.2722 0.2581 0.2464 0.2373 0.2311 0.2272 0.2239 0.2250 0.2264 0.2272 0.2318 0.2366 0.2366 

[TRAIN] Epoch[6](1489/1500); Loss: 0.215074; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.3576 0.3002 0.2852 0.2663 0.2436 0.2166 0.1901 0.1740 0.1728 0.1756 0.1764 0.1747 0.1753 0.1771 0.1772 0.1784 

[TRAIN] Epoch[6](1490/1500); Loss: 0.183739; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.3638 0.2792 0.2002 0.1968 0.1847 0.1530 0.1415 0.1396 0.1382 0.1426 0.1534 0.1611 0.1617 0.1788 0.1732 0.1721 

[TRAIN] Epoch[6](1491/1500); Loss: 0.097249; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1246 0.0914 0.0892 0.0859 0.0870 0.0871 0.0880 0.0873 0.0939 0.0976 0.0979 0.0989 0.1011 0.1073 0.1084 0.1105 

[TRAIN] Epoch[6](1492/1500); Loss: 0.142860; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2007 0.1646 0.1617 0.1634 0.1570 0.1481 0.1385 0.1355 0.1308 0.1272 0.1242 0.1267 0.1259 0.1250 0.1282 0.1285 

[TRAIN] Epoch[6](1493/1500); Loss: 0.115748; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1611 0.1251 0.1298 0.1301 0.1221 0.1130 0.1106 0.1071 0.1067 0.1062 0.1061 0.1035 0.1058 0.1078 0.1074 0.1096 

[TRAIN] Epoch[6](1494/1500); Loss: 0.111624; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1311 0.1174 0.1211 0.1207 0.1218 0.1148 0.1065 0.1094 0.1050 0.1024 0.1052 0.1050 0.1042 0.1076 0.1052 0.1086 

[TRAIN] Epoch[6](1495/1500); Loss: 0.105434; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1575 0.1238 0.1051 0.1004 0.0997 0.0952 0.0938 0.0979 0.0979 0.0997 0.0994 0.1017 0.1014 0.0993 0.1092 0.1051 

[TRAIN] Epoch[6](1496/1500); Loss: 0.151242; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3576 0.2277 0.1162 0.1260 0.1249 0.0958 0.0915 0.0974 0.1143 0.1225 0.1348 0.1431 0.1543 0.1641 0.1687 0.1811 

[TRAIN] Epoch[6](1497/1500); Loss: 0.113837; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1438 0.1250 0.1126 0.1072 0.1042 0.1049 0.1052 0.1093 0.1082 0.1100 0.1122 0.1116 0.1162 0.1157 0.1168 0.1188 

[TRAIN] Epoch[6](1498/1500); Loss: 0.158707; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2369 0.1912 0.1709 0.1716 0.1655 0.1545 0.1469 0.1431 0.1397 0.1411 0.1414 0.1420 0.1432 0.1479 0.1515 0.1518 

[TRAIN] Epoch[6](1499/1500); Loss: 0.113928; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1940 0.1547 0.1290 0.1276 0.1220 0.1116 0.1071 0.1022 0.0978 0.0973 0.0952 0.0942 0.0954 0.0978 0.0975 0.0994 

[TRAIN] Epoch[6](1500/1500); Loss: 0.099500; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1672 0.1134 0.0991 0.0988 0.0961 0.0902 0.0859 0.0918 0.0918 0.0917 0.0902 0.0952 0.0930 0.0942 0.0945 0.0988 

[TRAIN] Epoch[7](1/1500); Loss: 0.202191; Backpropagation: 0.0980 sec; Batch: 0.4558 sec
0.2514 0.2179 0.2133 0.2135 0.2078 0.2019 0.1973 0.1952 0.1940 0.1908 0.1905 0.1921 0.1917 0.1914 0.1928 0.1936 

[TRAIN] Epoch[7](2/1500); Loss: 0.188816; Backpropagation: 0.0939 sec; Batch: 0.4317 sec
0.3397 0.2574 0.1942 0.1978 0.1913 0.1676 0.1602 0.1570 0.1523 0.1557 0.1587 0.1632 0.1688 0.1775 0.1841 0.1956 

[TRAIN] Epoch[7](3/1500); Loss: 0.147597; Backpropagation: 0.0929 sec; Batch: 0.4280 sec
0.2099 0.1780 0.1525 0.1522 0.1501 0.1392 0.1348 0.1326 0.1329 0.1324 0.1343 0.1349 0.1399 0.1420 0.1456 0.1500 

[TRAIN] Epoch[7](4/1500); Loss: 0.180539; Backpropagation: 0.0918 sec; Batch: 0.4246 sec
0.2968 0.2343 0.2162 0.2208 0.2118 0.1941 0.1777 0.1672 0.1570 0.1459 0.1433 0.1389 0.1416 0.1436 0.1478 0.1515 

[TRAIN] Epoch[7](5/1500); Loss: 0.172768; Backpropagation: 0.0923 sec; Batch: 0.4248 sec
0.3083 0.2446 0.1929 0.1965 0.1908 0.1640 0.1511 0.1461 0.1382 0.1377 0.1422 0.1398 0.1443 0.1519 0.1559 0.1602 

[TRAIN] Epoch[7](6/1500); Loss: 0.161128; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.2691 0.2233 0.2234 0.2231 0.2094 0.1863 0.1595 0.1361 0.1201 0.1128 0.1163 0.1196 0.1170 0.1177 0.1213 0.1230 

[TRAIN] Epoch[7](7/1500); Loss: 0.135205; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2114 0.1541 0.1310 0.1297 0.1301 0.1257 0.1216 0.1218 0.1216 0.1226 0.1224 0.1274 0.1290 0.1330 0.1379 0.1439 

[TRAIN] Epoch[7](8/1500); Loss: 0.170616; Backpropagation: 0.0920 sec; Batch: 0.4254 sec
0.2234 0.1907 0.1695 0.1729 0.1692 0.1634 0.1629 0.1616 0.1624 0.1617 0.1658 0.1645 0.1652 0.1651 0.1661 0.1655 

[TRAIN] Epoch[7](9/1500); Loss: 0.154908; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2418 0.2009 0.1620 0.1657 0.1582 0.1408 0.1339 0.1350 0.1332 0.1349 0.1370 0.1399 0.1432 0.1474 0.1506 0.1542 

[TRAIN] Epoch[7](10/1500); Loss: 0.166769; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2464 0.2028 0.2024 0.2041 0.1968 0.1837 0.1650 0.1519 0.1398 0.1360 0.1367 0.1379 0.1386 0.1406 0.1412 0.1444 

[TRAIN] Epoch[7](11/1500); Loss: 0.194451; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.2559 0.2248 0.2131 0.2135 0.2092 0.1991 0.1910 0.1844 0.1785 0.1768 0.1744 0.1738 0.1781 0.1777 0.1790 0.1820 

[TRAIN] Epoch[7](12/1500); Loss: 0.140872; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.1764 0.1541 0.1518 0.1494 0.1461 0.1444 0.1376 0.1341 0.1311 0.1308 0.1314 0.1312 0.1312 0.1338 0.1349 0.1357 

[TRAIN] Epoch[7](13/1500); Loss: 0.219710; Backpropagation: 0.0922 sec; Batch: 0.4270 sec
0.3613 0.3080 0.2923 0.2703 0.2456 0.2184 0.1926 0.1773 0.1768 0.1829 0.1811 0.1813 0.1802 0.1826 0.1824 0.1824 

[TRAIN] Epoch[7](14/1500); Loss: 0.143738; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1811 0.1554 0.1519 0.1517 0.1458 0.1391 0.1358 0.1347 0.1353 0.1360 0.1363 0.1380 0.1377 0.1387 0.1412 0.1411 

[TRAIN] Epoch[7](15/1500); Loss: 0.103353; Backpropagation: 0.0919 sec; Batch: 0.4264 sec
0.1362 0.1131 0.1159 0.1127 0.1094 0.1015 0.0957 0.0960 0.0966 0.0950 0.0947 0.0972 0.0952 0.0970 0.0985 0.0989 

[TRAIN] Epoch[7](16/1500); Loss: 0.083627; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.1922 0.1135 0.0677 0.0672 0.0642 0.0643 0.0634 0.0688 0.0686 0.0737 0.0752 0.0787 0.0795 0.0847 0.0861 0.0902 

[TRAIN] Epoch[7](17/1500); Loss: 0.158917; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.2351 0.1920 0.1746 0.1696 0.1642 0.1586 0.1528 0.1495 0.1432 0.1434 0.1414 0.1405 0.1441 0.1443 0.1445 0.1448 

[TRAIN] Epoch[7](18/1500); Loss: 0.185989; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2294 0.1966 0.1880 0.1851 0.1832 0.1804 0.1789 0.1775 0.1781 0.1788 0.1791 0.1804 0.1824 0.1834 0.1861 0.1883 

[TRAIN] Epoch[7](19/1500); Loss: 0.155659; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2375 0.1940 0.1670 0.1650 0.1572 0.1464 0.1426 0.1397 0.1383 0.1371 0.1396 0.1402 0.1430 0.1446 0.1494 0.1489 

[TRAIN] Epoch[7](20/1500); Loss: 0.130238; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2602 0.1923 0.1364 0.1319 0.1220 0.1076 0.1043 0.1049 0.1073 0.1071 0.1125 0.1168 0.1152 0.1212 0.1216 0.1225 

[TRAIN] Epoch[7](21/1500); Loss: 0.180427; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.3836 0.2383 0.1467 0.1539 0.1563 0.1331 0.1261 0.1272 0.1348 0.1440 0.1563 0.1701 0.1835 0.1966 0.2112 0.2251 

[TRAIN] Epoch[7](22/1500); Loss: 0.072149; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0763 0.0758 0.0733 0.0709 0.0736 0.0692 0.0677 0.0728 0.0692 0.0692 0.0733 0.0712 0.0699 0.0750 0.0723 0.0747 

[TRAIN] Epoch[7](23/1500); Loss: 0.137197; Backpropagation: 0.0924 sec; Batch: 0.4246 sec
0.2409 0.2005 0.1556 0.1528 0.1430 0.1271 0.1179 0.1132 0.1114 0.1112 0.1141 0.1168 0.1173 0.1205 0.1251 0.1278 

[TRAIN] Epoch[7](24/1500); Loss: 0.112011; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1959 0.1405 0.1111 0.1079 0.1052 0.1003 0.0973 0.0962 0.0976 0.0983 0.1020 0.1018 0.1070 0.1083 0.1096 0.1130 

[TRAIN] Epoch[7](25/1500); Loss: 0.141194; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1669 0.1539 0.1440 0.1395 0.1387 0.1367 0.1348 0.1354 0.1348 0.1368 0.1367 0.1371 0.1405 0.1397 0.1406 0.1432 

[TRAIN] Epoch[7](26/1500); Loss: 0.155550; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1634 0.1581 0.1609 0.1593 0.1559 0.1548 0.1545 0.1531 0.1534 0.1537 0.1526 0.1522 0.1525 0.1538 0.1562 0.1544 

[TRAIN] Epoch[7](27/1500); Loss: 0.123517; Backpropagation: 0.0918 sec; Batch: 0.4270 sec
0.1604 0.1352 0.1252 0.1197 0.1163 0.1167 0.1162 0.1155 0.1153 0.1188 0.1195 0.1188 0.1212 0.1232 0.1248 0.1294 

[TRAIN] Epoch[7](28/1500); Loss: 0.106006; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1465 0.1172 0.1189 0.1205 0.1142 0.1078 0.1011 0.0942 0.0930 0.0972 0.0955 0.0946 0.0990 0.0984 0.0973 0.1010 

[TRAIN] Epoch[7](29/1500); Loss: 0.176522; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2210 0.1986 0.1896 0.1851 0.1797 0.1753 0.1706 0.1703 0.1705 0.1682 0.1686 0.1660 0.1658 0.1645 0.1661 0.1646 

[TRAIN] Epoch[7](30/1500); Loss: 0.112818; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1539 0.1194 0.1132 0.1075 0.1044 0.1049 0.1057 0.1052 0.1063 0.1092 0.1085 0.1083 0.1117 0.1155 0.1130 0.1181 

[TRAIN] Epoch[7](31/1500); Loss: 0.117704; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1432 0.1269 0.1205 0.1184 0.1170 0.1162 0.1149 0.1150 0.1141 0.1135 0.1131 0.1127 0.1138 0.1139 0.1149 0.1151 

[TRAIN] Epoch[7](32/1500); Loss: 0.138443; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2506 0.2052 0.1628 0.1500 0.1370 0.1261 0.1196 0.1169 0.1175 0.1170 0.1172 0.1184 0.1180 0.1178 0.1201 0.1209 

[TRAIN] Epoch[7](33/1500); Loss: 0.172988; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1912 0.1780 0.1757 0.1725 0.1721 0.1717 0.1704 0.1705 0.1692 0.1687 0.1703 0.1697 0.1710 0.1713 0.1727 0.1728 

[TRAIN] Epoch[7](34/1500); Loss: 0.057612; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.0866 0.0420 0.0485 0.0559 0.0499 0.0514 0.0570 0.0524 0.0531 0.0590 0.0550 0.0562 0.0638 0.0604 0.0614 0.0691 

[TRAIN] Epoch[7](35/1500); Loss: 0.065598; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1348 0.0960 0.0642 0.0541 0.0537 0.0542 0.0573 0.0573 0.0570 0.0581 0.0580 0.0583 0.0597 0.0607 0.0615 0.0645 

[TRAIN] Epoch[7](36/1500); Loss: 0.123544; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2329 0.1754 0.1562 0.1564 0.1466 0.1322 0.1152 0.1089 0.1001 0.0952 0.0920 0.0920 0.0920 0.0935 0.0942 0.0939 

[TRAIN] Epoch[7](37/1500); Loss: 0.116274; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1765 0.1509 0.1301 0.1247 0.1182 0.1127 0.1104 0.1079 0.1059 0.1035 0.1056 0.1022 0.1007 0.1029 0.1046 0.1037 

[TRAIN] Epoch[7](38/1500); Loss: 0.090615; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1038 0.0954 0.1038 0.1014 0.0929 0.0848 0.0915 0.0858 0.0807 0.0788 0.0840 0.0837 0.0873 0.0884 0.0923 0.0955 

[TRAIN] Epoch[7](39/1500); Loss: 0.154034; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.2041 0.1747 0.1773 0.1768 0.1691 0.1576 0.1477 0.1427 0.1421 0.1410 0.1392 0.1388 0.1399 0.1383 0.1378 0.1374 

[TRAIN] Epoch[7](40/1500); Loss: 0.171934; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2479 0.2055 0.1994 0.2002 0.1929 0.1820 0.1721 0.1658 0.1576 0.1500 0.1479 0.1473 0.1452 0.1444 0.1464 0.1463 

[TRAIN] Epoch[7](41/1500); Loss: 0.139971; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1945 0.1624 0.1570 0.1537 0.1495 0.1452 0.1367 0.1339 0.1276 0.1260 0.1259 0.1248 0.1237 0.1249 0.1270 0.1266 

[TRAIN] Epoch[7](42/1500); Loss: 0.094873; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1406 0.1132 0.0985 0.0921 0.0879 0.0881 0.0867 0.0892 0.0881 0.0878 0.0893 0.0913 0.0893 0.0913 0.0929 0.0916 

[TRAIN] Epoch[7](43/1500); Loss: 0.094177; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1089 0.0980 0.0957 0.0909 0.0915 0.0933 0.0914 0.0918 0.0915 0.0934 0.0925 0.0918 0.0942 0.0941 0.0938 0.0942 

[TRAIN] Epoch[7](44/1500); Loss: 0.081684; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1068 0.0820 0.0863 0.0867 0.0810 0.0788 0.0784 0.0756 0.0757 0.0764 0.0785 0.0785 0.0788 0.0786 0.0806 0.0841 

[TRAIN] Epoch[7](45/1500); Loss: 0.103607; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1350 0.1114 0.1136 0.1115 0.1069 0.1038 0.1025 0.0998 0.0975 0.0982 0.0950 0.0959 0.0966 0.0958 0.0973 0.0969 

[TRAIN] Epoch[7](46/1500); Loss: 0.106013; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1615 0.1304 0.1205 0.1185 0.1106 0.1035 0.0977 0.0928 0.0913 0.0938 0.0934 0.0938 0.0948 0.0977 0.0988 0.0970 

[TRAIN] Epoch[7](47/1500); Loss: 0.127605; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1889 0.1457 0.1335 0.1241 0.1173 0.1176 0.1153 0.1141 0.1176 0.1195 0.1184 0.1229 0.1225 0.1245 0.1301 0.1297 

[TRAIN] Epoch[7](48/1500); Loss: 0.113730; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1754 0.1307 0.1143 0.1095 0.1079 0.1094 0.1064 0.1065 0.1044 0.1041 0.1084 0.1089 0.1058 0.1068 0.1113 0.1100 

[TRAIN] Epoch[7](49/1500); Loss: 0.075285; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0998 0.0772 0.0794 0.0730 0.0696 0.0725 0.0720 0.0696 0.0688 0.0695 0.0730 0.0727 0.0723 0.0759 0.0790 0.0803 

[TRAIN] Epoch[7](50/1500); Loss: 0.149814; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1740 0.1593 0.1636 0.1587 0.1526 0.1494 0.1467 0.1438 0.1431 0.1426 0.1427 0.1423 0.1429 0.1450 0.1445 0.1460 

[TRAIN] Epoch[7](51/1500); Loss: 0.144301; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2095 0.1690 0.1675 0.1656 0.1592 0.1491 0.1396 0.1365 0.1312 0.1270 0.1262 0.1251 0.1256 0.1260 0.1254 0.1264 

[TRAIN] Epoch[7](52/1500); Loss: 0.166394; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.3867 0.2358 0.1385 0.1340 0.1352 0.1142 0.1121 0.1155 0.1230 0.1309 0.1445 0.1561 0.1647 0.1804 0.1894 0.2012 

[TRAIN] Epoch[7](53/1500); Loss: 0.110367; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1537 0.1231 0.1236 0.1212 0.1153 0.1094 0.1063 0.1048 0.1030 0.1017 0.1005 0.1008 0.1006 0.1006 0.1006 0.1007 

[TRAIN] Epoch[7](54/1500); Loss: 0.128462; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2050 0.1460 0.1223 0.1165 0.1144 0.1152 0.1157 0.1202 0.1216 0.1223 0.1259 0.1227 0.1237 0.1240 0.1302 0.1295 

[TRAIN] Epoch[7](55/1500); Loss: 0.117116; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1484 0.1315 0.1245 0.1194 0.1170 0.1182 0.1169 0.1161 0.1143 0.1126 0.1116 0.1090 0.1089 0.1092 0.1078 0.1084 

[TRAIN] Epoch[7](56/1500); Loss: 0.067482; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0968 0.0787 0.0787 0.0794 0.0772 0.0680 0.0595 0.0565 0.0578 0.0582 0.0577 0.0623 0.0599 0.0624 0.0615 0.0651 

[TRAIN] Epoch[7](57/1500); Loss: 0.160878; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1857 0.1717 0.1698 0.1660 0.1642 0.1626 0.1598 0.1588 0.1573 0.1565 0.1551 0.1534 0.1539 0.1535 0.1518 0.1539 

[TRAIN] Epoch[7](58/1500); Loss: 0.086547; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1366 0.1078 0.0931 0.0866 0.0830 0.0817 0.0820 0.0807 0.0799 0.0792 0.0795 0.0782 0.0787 0.0797 0.0783 0.0795 

[TRAIN] Epoch[7](59/1500); Loss: 0.147293; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1961 0.1660 0.1578 0.1504 0.1464 0.1433 0.1411 0.1391 0.1395 0.1395 0.1386 0.1388 0.1393 0.1401 0.1395 0.1412 

[TRAIN] Epoch[7](60/1500); Loss: 0.165166; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2713 0.2222 0.1969 0.1905 0.1803 0.1702 0.1594 0.1516 0.1423 0.1374 0.1337 0.1346 0.1382 0.1365 0.1386 0.1389 

[TRAIN] Epoch[7](61/1500); Loss: 0.105389; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2721 0.1608 0.0895 0.0845 0.0782 0.0769 0.0757 0.0806 0.0858 0.0846 0.0901 0.0917 0.0978 0.0992 0.1090 0.1098 

[TRAIN] Epoch[7](62/1500); Loss: 0.132036; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2488 0.1993 0.1863 0.1777 0.1622 0.1428 0.1294 0.1165 0.1055 0.0978 0.0926 0.0889 0.0901 0.0920 0.0902 0.0925 

[TRAIN] Epoch[7](63/1500); Loss: 0.214968; Backpropagation: 0.0953 sec; Batch: 0.4276 sec
0.2806 0.2422 0.2322 0.2248 0.2195 0.2142 0.2089 0.2053 0.2026 0.2005 0.1987 0.1999 0.1997 0.2014 0.2037 0.2054 

[TRAIN] Epoch[7](64/1500); Loss: 0.112871; Backpropagation: 0.0916 sec; Batch: 0.4421 sec
0.1518 0.1413 0.1263 0.1158 0.1090 0.1082 0.1055 0.1022 0.1054 0.1050 0.1043 0.1068 0.1051 0.1079 0.1047 0.1066 

[TRAIN] Epoch[7](65/1500); Loss: 0.098620; Backpropagation: 0.0929 sec; Batch: 0.4297 sec
0.1517 0.1181 0.1264 0.1240 0.1163 0.1041 0.0921 0.0846 0.0817 0.0831 0.0820 0.0815 0.0822 0.0826 0.0828 0.0845 

[TRAIN] Epoch[7](66/1500); Loss: 0.067546; Backpropagation: 0.0917 sec; Batch: 0.4277 sec
0.0761 0.0670 0.0662 0.0650 0.0659 0.0645 0.0641 0.0639 0.0648 0.0650 0.0664 0.0665 0.0688 0.0699 0.0731 0.0737 

[TRAIN] Epoch[7](67/1500); Loss: 0.098357; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1450 0.1137 0.1216 0.1187 0.1126 0.1043 0.0955 0.0898 0.0875 0.0842 0.0852 0.0829 0.0833 0.0816 0.0841 0.0837 

[TRAIN] Epoch[7](68/1500); Loss: 0.135712; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1603 0.1480 0.1404 0.1343 0.1333 0.1340 0.1331 0.1333 0.1322 0.1327 0.1314 0.1320 0.1308 0.1315 0.1314 0.1326 

[TRAIN] Epoch[7](69/1500); Loss: 0.135797; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2133 0.1802 0.1545 0.1443 0.1378 0.1310 0.1266 0.1232 0.1210 0.1199 0.1193 0.1209 0.1216 0.1200 0.1203 0.1188 

[TRAIN] Epoch[7](70/1500); Loss: 0.152427; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2880 0.2253 0.1757 0.1705 0.1600 0.1428 0.1334 0.1273 0.1223 0.1215 0.1234 0.1254 0.1271 0.1309 0.1329 0.1324 

[TRAIN] Epoch[7](71/1500); Loss: 0.135556; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2092 0.1655 0.1561 0.1519 0.1407 0.1286 0.1234 0.1226 0.1215 0.1219 0.1213 0.1216 0.1227 0.1218 0.1210 0.1192 

[TRAIN] Epoch[7](72/1500); Loss: 0.148440; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2495 0.2035 0.1682 0.1586 0.1503 0.1414 0.1346 0.1298 0.1290 0.1272 0.1291 0.1306 0.1285 0.1314 0.1321 0.1312 

[TRAIN] Epoch[7](73/1500); Loss: 0.158569; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2078 0.1724 0.1636 0.1538 0.1496 0.1507 0.1499 0.1483 0.1493 0.1511 0.1524 0.1552 0.1555 0.1574 0.1591 0.1610 

[TRAIN] Epoch[7](74/1500); Loss: 0.161581; Backpropagation: 0.0916 sec; Batch: 0.4247 sec
0.2353 0.1919 0.1877 0.1869 0.1790 0.1661 0.1567 0.1523 0.1501 0.1446 0.1408 0.1395 0.1400 0.1391 0.1378 0.1376 

[TRAIN] Epoch[7](75/1500); Loss: 0.146179; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1881 0.1558 0.1578 0.1585 0.1528 0.1452 0.1389 0.1400 0.1378 0.1368 0.1374 0.1369 0.1376 0.1386 0.1378 0.1389 

[TRAIN] Epoch[7](76/1500); Loss: 0.080978; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1414 0.0832 0.0883 0.0791 0.0711 0.0699 0.0742 0.0725 0.0717 0.0738 0.0730 0.0768 0.0767 0.0790 0.0808 0.0842 

[TRAIN] Epoch[7](77/1500); Loss: 0.080518; Backpropagation: 0.0924 sec; Batch: 0.4241 sec
0.1152 0.0903 0.0876 0.0841 0.0781 0.0749 0.0739 0.0714 0.0744 0.0745 0.0757 0.0733 0.0801 0.0770 0.0773 0.0806 

[TRAIN] Epoch[7](78/1500); Loss: 0.178676; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.3132 0.2622 0.2440 0.2152 0.1917 0.1666 0.1497 0.1387 0.1371 0.1405 0.1465 0.1479 0.1486 0.1499 0.1529 0.1541 

[TRAIN] Epoch[7](79/1500); Loss: 0.110955; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1384 0.1241 0.1290 0.1192 0.1104 0.1130 0.1104 0.1042 0.1038 0.1068 0.1054 0.0999 0.1001 0.1045 0.1024 0.1036 

[TRAIN] Epoch[7](80/1500); Loss: 0.107617; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1390 0.1105 0.1086 0.1022 0.0980 0.0975 0.1023 0.1003 0.1012 0.1014 0.1063 0.1081 0.1090 0.1091 0.1107 0.1177 

[TRAIN] Epoch[7](81/1500); Loss: 0.102147; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1558 0.1071 0.1081 0.0994 0.0915 0.0897 0.0965 0.0946 0.0949 0.0916 0.1005 0.1005 0.0980 0.0963 0.1057 0.1043 

[TRAIN] Epoch[7](82/1500); Loss: 0.144949; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.1979 0.1665 0.1672 0.1618 0.1533 0.1443 0.1382 0.1347 0.1323 0.1285 0.1283 0.1288 0.1338 0.1334 0.1346 0.1355 

[TRAIN] Epoch[7](83/1500); Loss: 0.201642; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2749 0.2441 0.2472 0.2447 0.2354 0.2224 0.2088 0.1987 0.1871 0.1786 0.1720 0.1668 0.1619 0.1591 0.1628 0.1618 

[TRAIN] Epoch[7](84/1500); Loss: 0.127009; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2134 0.1798 0.1505 0.1372 0.1260 0.1178 0.1145 0.1119 0.1122 0.1106 0.1105 0.1094 0.1097 0.1102 0.1095 0.1089 

[TRAIN] Epoch[7](85/1500); Loss: 0.085051; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1099 0.0910 0.0895 0.0850 0.0828 0.0834 0.0831 0.0815 0.0833 0.0820 0.0801 0.0807 0.0826 0.0825 0.0816 0.0818 

[TRAIN] Epoch[7](86/1500); Loss: 0.115266; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.3017 0.1671 0.0969 0.0919 0.0915 0.0842 0.0826 0.0862 0.0918 0.0920 0.0997 0.1048 0.1069 0.1112 0.1174 0.1185 

[TRAIN] Epoch[7](87/1500); Loss: 0.157307; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2104 0.1871 0.1841 0.1788 0.1704 0.1628 0.1541 0.1482 0.1443 0.1390 0.1371 0.1359 0.1402 0.1403 0.1413 0.1428 

[TRAIN] Epoch[7](88/1500); Loss: 0.130564; Backpropagation: 0.0925 sec; Batch: 0.4244 sec
0.1955 0.1554 0.1408 0.1329 0.1281 0.1237 0.1231 0.1227 0.1202 0.1201 0.1219 0.1204 0.1218 0.1205 0.1200 0.1221 

[TRAIN] Epoch[7](89/1500); Loss: 0.172606; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2146 0.1972 0.1905 0.1859 0.1815 0.1801 0.1760 0.1722 0.1699 0.1659 0.1634 0.1584 0.1545 0.1526 0.1501 0.1491 

[TRAIN] Epoch[7](90/1500); Loss: 0.167150; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2426 0.2096 0.1885 0.1789 0.1686 0.1589 0.1536 0.1528 0.1530 0.1511 0.1543 0.1537 0.1524 0.1511 0.1519 0.1533 

[TRAIN] Epoch[7](91/1500); Loss: 0.179619; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2304 0.2100 0.2084 0.2017 0.1927 0.1875 0.1834 0.1788 0.1729 0.1675 0.1634 0.1579 0.1565 0.1550 0.1542 0.1535 

[TRAIN] Epoch[7](92/1500); Loss: 0.105918; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1208 0.1090 0.1117 0.1079 0.1049 0.1053 0.1052 0.1041 0.1029 0.1043 0.1035 0.1026 0.1024 0.1033 0.1031 0.1036 

[TRAIN] Epoch[7](93/1500); Loss: 0.073392; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0869 0.0811 0.0818 0.0743 0.0704 0.0716 0.0702 0.0697 0.0690 0.0699 0.0704 0.0694 0.0716 0.0725 0.0721 0.0734 

[TRAIN] Epoch[7](94/1500); Loss: 0.150903; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1887 0.1719 0.1814 0.1743 0.1648 0.1570 0.1553 0.1459 0.1403 0.1372 0.1338 0.1332 0.1308 0.1318 0.1325 0.1355 

[TRAIN] Epoch[7](95/1500); Loss: 0.125368; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2686 0.2167 0.1606 0.1306 0.1124 0.1071 0.1053 0.1024 0.1016 0.1006 0.1013 0.0983 0.0970 0.0999 0.1024 0.1010 

[TRAIN] Epoch[7](96/1500); Loss: 0.116688; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1750 0.1418 0.1313 0.1257 0.1187 0.1126 0.1075 0.1031 0.1039 0.1062 0.1054 0.1052 0.1064 0.1096 0.1080 0.1067 

[TRAIN] Epoch[7](97/1500); Loss: 0.141746; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2391 0.1904 0.1626 0.1542 0.1454 0.1417 0.1347 0.1267 0.1228 0.1209 0.1206 0.1202 0.1215 0.1196 0.1232 0.1245 

[TRAIN] Epoch[7](98/1500); Loss: 0.137708; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2015 0.1794 0.1599 0.1441 0.1335 0.1281 0.1239 0.1238 0.1239 0.1227 0.1248 0.1254 0.1270 0.1278 0.1282 0.1293 

[TRAIN] Epoch[7](99/1500); Loss: 0.159231; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1982 0.1729 0.1734 0.1661 0.1625 0.1589 0.1547 0.1541 0.1521 0.1506 0.1510 0.1495 0.1503 0.1491 0.1497 0.1545 

[TRAIN] Epoch[7](100/1500); Loss: 0.131502; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1355 0.1488 0.1608 0.1524 0.1410 0.1290 0.1277 0.1255 0.1230 0.1207 0.1214 0.1230 0.1233 0.1236 0.1235 0.1248 

[TRAIN] Epoch[7](101/1500); Loss: 0.146499; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2675 0.2107 0.2172 0.2123 0.1947 0.1654 0.1345 0.1130 0.1015 0.1008 0.1049 0.1040 0.1017 0.1034 0.1061 0.1062 

[TRAIN] Epoch[7](102/1500); Loss: 0.143646; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1918 0.1651 0.1683 0.1634 0.1521 0.1389 0.1341 0.1327 0.1319 0.1302 0.1325 0.1314 0.1309 0.1317 0.1320 0.1317 

[TRAIN] Epoch[7](103/1500); Loss: 0.126218; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2147 0.1617 0.1378 0.1264 0.1209 0.1162 0.1150 0.1133 0.1137 0.1132 0.1141 0.1153 0.1139 0.1115 0.1130 0.1187 

[TRAIN] Epoch[7](104/1500); Loss: 0.151559; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1745 0.1616 0.1751 0.1717 0.1658 0.1575 0.1517 0.1481 0.1436 0.1415 0.1401 0.1405 0.1378 0.1373 0.1387 0.1394 

[TRAIN] Epoch[7](105/1500); Loss: 0.127473; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1558 0.1498 0.1525 0.1457 0.1378 0.1291 0.1238 0.1172 0.1182 0.1153 0.1160 0.1147 0.1165 0.1152 0.1161 0.1158 

[TRAIN] Epoch[7](106/1500); Loss: 0.130160; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2236 0.1762 0.1533 0.1484 0.1453 0.1347 0.1315 0.1226 0.1118 0.1034 0.1112 0.1079 0.1031 0.1005 0.1040 0.1049 

[TRAIN] Epoch[7](107/1500); Loss: 0.141612; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.2245 0.1780 0.1773 0.1699 0.1550 0.1383 0.1275 0.1212 0.1229 0.1221 0.1213 0.1208 0.1209 0.1214 0.1221 0.1227 

[TRAIN] Epoch[7](108/1500); Loss: 0.143769; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2280 0.1880 0.1664 0.1471 0.1373 0.1320 0.1301 0.1304 0.1301 0.1296 0.1283 0.1298 0.1306 0.1297 0.1309 0.1320 

[TRAIN] Epoch[7](109/1500); Loss: 0.151999; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2121 0.1857 0.1730 0.1626 0.1555 0.1516 0.1465 0.1463 0.1434 0.1394 0.1368 0.1370 0.1366 0.1362 0.1341 0.1353 

[TRAIN] Epoch[7](110/1500); Loss: 0.142238; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2175 0.1533 0.1512 0.1422 0.1344 0.1259 0.1349 0.1349 0.1340 0.1290 0.1260 0.1309 0.1382 0.1405 0.1401 0.1428 

[TRAIN] Epoch[7](111/1500); Loss: 0.146782; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1504 0.1551 0.1651 0.1602 0.1544 0.1503 0.1464 0.1459 0.1430 0.1400 0.1403 0.1393 0.1395 0.1384 0.1404 0.1399 

[TRAIN] Epoch[7](112/1500); Loss: 0.102576; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1612 0.1308 0.1162 0.1025 0.0950 0.0943 0.0965 0.0952 0.0934 0.0907 0.0948 0.0939 0.0918 0.0917 0.0974 0.0957 

[TRAIN] Epoch[7](113/1500); Loss: 0.094436; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1334 0.1040 0.1030 0.0978 0.0927 0.0917 0.0887 0.0880 0.0876 0.0861 0.0860 0.0903 0.0902 0.0891 0.0894 0.0931 

[TRAIN] Epoch[7](114/1500); Loss: 0.141571; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2187 0.1660 0.1575 0.1562 0.1488 0.1391 0.1364 0.1340 0.1307 0.1249 0.1224 0.1267 0.1266 0.1240 0.1249 0.1282 

[TRAIN] Epoch[7](115/1500); Loss: 0.181236; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.2545 0.2308 0.2331 0.2222 0.2066 0.1924 0.1826 0.1723 0.1640 0.1549 0.1483 0.1462 0.1437 0.1452 0.1502 0.1527 

[TRAIN] Epoch[7](116/1500); Loss: 0.128320; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2112 0.1583 0.1344 0.1298 0.1220 0.1213 0.1275 0.1270 0.1262 0.1229 0.1178 0.1148 0.1146 0.1106 0.1078 0.1070 

[TRAIN] Epoch[7](117/1500); Loss: 0.167276; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2265 0.2174 0.2179 0.2089 0.1930 0.1768 0.1638 0.1576 0.1507 0.1423 0.1362 0.1363 0.1372 0.1378 0.1363 0.1380 

[TRAIN] Epoch[7](118/1500); Loss: 0.083542; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0913 0.0804 0.0834 0.0861 0.0835 0.0826 0.0821 0.0819 0.0813 0.0816 0.0819 0.0828 0.0831 0.0836 0.0852 0.0859 

[TRAIN] Epoch[7](119/1500); Loss: 0.175975; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2192 0.2027 0.1986 0.1867 0.1761 0.1688 0.1668 0.1686 0.1679 0.1664 0.1671 0.1660 0.1656 0.1646 0.1643 0.1662 

[TRAIN] Epoch[7](120/1500); Loss: 0.145603; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.3253 0.2550 0.1863 0.1500 0.1433 0.1388 0.1297 0.1232 0.1187 0.1147 0.1106 0.1078 0.1059 0.1057 0.1067 0.1078 

[TRAIN] Epoch[7](121/1500); Loss: 0.131970; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1726 0.1493 0.1491 0.1405 0.1315 0.1234 0.1254 0.1240 0.1250 0.1216 0.1202 0.1220 0.1240 0.1267 0.1275 0.1286 

[TRAIN] Epoch[7](122/1500); Loss: 0.196783; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2907 0.2487 0.2578 0.2631 0.2532 0.2361 0.2149 0.1985 0.1838 0.1700 0.1580 0.1468 0.1368 0.1307 0.1283 0.1312 

[TRAIN] Epoch[7](123/1500); Loss: 0.147078; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1997 0.1732 0.1707 0.1636 0.1565 0.1529 0.1481 0.1428 0.1397 0.1351 0.1318 0.1293 0.1271 0.1254 0.1287 0.1286 

[TRAIN] Epoch[7](124/1500); Loss: 0.123168; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1895 0.1487 0.1432 0.1393 0.1306 0.1223 0.1132 0.1154 0.1144 0.1105 0.1080 0.1057 0.1075 0.1069 0.1079 0.1074 

[TRAIN] Epoch[7](125/1500); Loss: 0.148283; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1795 0.1821 0.1863 0.1748 0.1608 0.1508 0.1442 0.1397 0.1369 0.1331 0.1296 0.1306 0.1297 0.1299 0.1312 0.1331 

[TRAIN] Epoch[7](126/1500); Loss: 0.130263; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1944 0.1564 0.1415 0.1349 0.1314 0.1280 0.1270 0.1289 0.1249 0.1190 0.1175 0.1166 0.1149 0.1155 0.1166 0.1168 

[TRAIN] Epoch[7](127/1500); Loss: 0.130430; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1277 0.1227 0.1434 0.1437 0.1371 0.1362 0.1338 0.1301 0.1284 0.1274 0.1265 0.1263 0.1262 0.1265 0.1260 0.1248 

[TRAIN] Epoch[7](128/1500); Loss: 0.100395; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1170 0.1112 0.1187 0.1109 0.1025 0.0993 0.0958 0.0914 0.0900 0.0929 0.0923 0.0937 0.0953 0.0966 0.0985 0.1002 

[TRAIN] Epoch[7](129/1500); Loss: 0.155783; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2402 0.1840 0.1847 0.2000 0.1920 0.1786 0.1675 0.1565 0.1427 0.1302 0.1198 0.1187 0.1177 0.1189 0.1206 0.1205 

[TRAIN] Epoch[7](130/1500); Loss: 0.098864; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1514 0.1154 0.1119 0.1003 0.0942 0.0923 0.0914 0.0942 0.0926 0.0909 0.0896 0.0905 0.0911 0.0903 0.0911 0.0946 

[TRAIN] Epoch[7](131/1500); Loss: 0.085974; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1281 0.0900 0.0908 0.0864 0.0799 0.0769 0.0792 0.0789 0.0790 0.0792 0.0814 0.0823 0.0835 0.0849 0.0867 0.0882 

[TRAIN] Epoch[7](132/1500); Loss: 0.142533; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1668 0.1498 0.1587 0.1550 0.1486 0.1445 0.1407 0.1373 0.1344 0.1368 0.1354 0.1332 0.1336 0.1354 0.1348 0.1355 

[TRAIN] Epoch[7](133/1500); Loss: 0.124752; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1446 0.1152 0.1233 0.1285 0.1258 0.1226 0.1217 0.1210 0.1218 0.1222 0.1225 0.1233 0.1240 0.1256 0.1269 0.1270 

[TRAIN] Epoch[7](134/1500); Loss: 0.111467; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1008 0.0914 0.1028 0.1035 0.1038 0.1073 0.1092 0.1113 0.1131 0.1147 0.1164 0.1186 0.1200 0.1220 0.1237 0.1248 

[TRAIN] Epoch[7](135/1500); Loss: 0.182697; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2296 0.2050 0.1977 0.1910 0.1833 0.1790 0.1769 0.1762 0.1762 0.1751 0.1747 0.1738 0.1724 0.1719 0.1709 0.1694 

[TRAIN] Epoch[7](136/1500); Loss: 0.104374; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1226 0.1101 0.1360 0.1282 0.1154 0.1063 0.1010 0.0970 0.0993 0.0964 0.0937 0.0934 0.0912 0.0939 0.0931 0.0925 

[TRAIN] Epoch[7](137/1500); Loss: 0.166253; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2363 0.1950 0.1948 0.1966 0.1883 0.1755 0.1640 0.1564 0.1478 0.1423 0.1407 0.1418 0.1422 0.1446 0.1464 0.1475 

[TRAIN] Epoch[7](138/1500); Loss: 0.104276; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.3372 0.1840 0.0601 0.0796 0.0695 0.0594 0.0550 0.0752 0.0984 0.1001 0.0917 0.0811 0.0755 0.0926 0.1006 0.1084 

[TRAIN] Epoch[7](139/1500); Loss: 0.115855; Backpropagation: 0.0918 sec; Batch: 0.4253 sec
0.2442 0.1630 0.1187 0.1088 0.1049 0.1047 0.1021 0.0991 0.1008 0.0993 0.1003 0.0995 0.1020 0.1018 0.1011 0.1035 

[TRAIN] Epoch[7](140/1500); Loss: 0.070746; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0886 0.0700 0.0860 0.0881 0.0814 0.0738 0.0691 0.0674 0.0651 0.0621 0.0611 0.0629 0.0630 0.0627 0.0644 0.0663 

[TRAIN] Epoch[7](141/1500); Loss: 0.193460; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2237 0.2054 0.2612 0.2589 0.2446 0.2252 0.2062 0.1927 0.1776 0.1732 0.1672 0.1597 0.1504 0.1498 0.1497 0.1498 

[TRAIN] Epoch[7](142/1500); Loss: 0.101189; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1334 0.1079 0.1081 0.1088 0.1034 0.1034 0.1053 0.1024 0.0992 0.0974 0.0954 0.0931 0.0921 0.0903 0.0890 0.0897 

[TRAIN] Epoch[7](143/1500); Loss: 0.184737; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2098 0.1884 0.2023 0.2048 0.2000 0.1975 0.1921 0.1870 0.1832 0.1800 0.1776 0.1737 0.1684 0.1661 0.1637 0.1611 

[TRAIN] Epoch[7](144/1500); Loss: 0.163900; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1842 0.1693 0.1781 0.1776 0.1738 0.1755 0.1750 0.1721 0.1673 0.1624 0.1584 0.1540 0.1490 0.1450 0.1415 0.1392 

[TRAIN] Epoch[7](145/1500); Loss: 0.134746; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1638 0.1377 0.1570 0.1556 0.1460 0.1361 0.1373 0.1364 0.1309 0.1252 0.1225 0.1236 0.1232 0.1206 0.1207 0.1192 

[TRAIN] Epoch[7](146/1500); Loss: 0.085140; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2964 0.2087 0.1164 0.0639 0.0585 0.0560 0.0552 0.0568 0.0538 0.0522 0.0584 0.0575 0.0561 0.0548 0.0582 0.0594 

[TRAIN] Epoch[7](147/1500); Loss: 0.182086; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2816 0.2189 0.2409 0.2565 0.2458 0.2295 0.2060 0.1882 0.1667 0.1471 0.1339 0.1227 0.1177 0.1190 0.1193 0.1194 

[TRAIN] Epoch[7](148/1500); Loss: 0.140933; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2280 0.1554 0.1525 0.1535 0.1444 0.1337 0.1273 0.1242 0.1276 0.1268 0.1255 0.1278 0.1280 0.1304 0.1336 0.1361 

[TRAIN] Epoch[7](149/1500); Loss: 0.144806; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2609 0.1889 0.2220 0.2327 0.2199 0.1962 0.1666 0.1473 0.1257 0.1053 0.0897 0.0798 0.0725 0.0692 0.0692 0.0710 

[TRAIN] Epoch[7](150/1500); Loss: 0.130138; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1727 0.1512 0.1447 0.1380 0.1318 0.1293 0.1270 0.1247 0.1227 0.1211 0.1210 0.1192 0.1189 0.1196 0.1201 0.1204 

[TRAIN] Epoch[7](151/1500); Loss: 0.091972; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1162 0.0904 0.0961 0.1000 0.0966 0.0931 0.0900 0.0898 0.0885 0.0874 0.0874 0.0870 0.0866 0.0870 0.0875 0.0878 

[TRAIN] Epoch[7](152/1500); Loss: 0.247447; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.3844 0.3162 0.3381 0.3632 0.3505 0.3270 0.2940 0.2704 0.2423 0.2130 0.1880 0.1635 0.1422 0.1271 0.1203 0.1191 

[TRAIN] Epoch[7](153/1500); Loss: 0.073701; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.0945 0.0793 0.0804 0.0778 0.0744 0.0720 0.0712 0.0703 0.0696 0.0690 0.0688 0.0691 0.0697 0.0705 0.0709 0.0718 

[TRAIN] Epoch[7](154/1500); Loss: 0.132533; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1556 0.1512 0.1537 0.1481 0.1436 0.1372 0.1330 0.1297 0.1260 0.1220 0.1216 0.1210 0.1197 0.1180 0.1202 0.1201 

[TRAIN] Epoch[7](155/1500); Loss: 0.117037; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.1647 0.1356 0.1359 0.1321 0.1266 0.1205 0.1161 0.1127 0.1085 0.1053 0.1031 0.1021 0.1033 0.1025 0.1018 0.1019 

[TRAIN] Epoch[7](156/1500); Loss: 0.127755; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2265 0.1841 0.1585 0.1281 0.1201 0.1158 0.1138 0.1099 0.1082 0.1119 0.1138 0.1104 0.1083 0.1097 0.1127 0.1123 

[TRAIN] Epoch[7](157/1500); Loss: 0.198223; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2473 0.2178 0.2168 0.2165 0.2096 0.2029 0.1962 0.1919 0.1867 0.1829 0.1856 0.1840 0.1814 0.1815 0.1845 0.1861 

[TRAIN] Epoch[7](158/1500); Loss: 0.107909; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.2423 0.1820 0.1300 0.1012 0.0943 0.0939 0.0934 0.0911 0.0883 0.0859 0.0869 0.0858 0.0869 0.0884 0.0875 0.0884 

[TRAIN] Epoch[7](159/1500); Loss: 0.091753; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1013 0.0933 0.0985 0.0962 0.0931 0.0927 0.0917 0.0903 0.0897 0.0891 0.0885 0.0880 0.0884 0.0886 0.0891 0.0896 

[TRAIN] Epoch[7](160/1500); Loss: 0.097923; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3258 0.1864 0.0579 0.0772 0.0677 0.0573 0.0498 0.0673 0.0926 0.0968 0.0858 0.0727 0.0642 0.0803 0.0833 0.1017 

[TRAIN] Epoch[7](161/1500); Loss: 0.140766; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2665 0.2180 0.2010 0.1848 0.1665 0.1548 0.1415 0.1319 0.1221 0.1121 0.1029 0.0974 0.0916 0.0878 0.0867 0.0866 

[TRAIN] Epoch[7](162/1500); Loss: 0.102820; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1504 0.1386 0.1345 0.1207 0.1076 0.1035 0.0998 0.0997 0.0950 0.0899 0.0856 0.0851 0.0857 0.0834 0.0832 0.0824 

[TRAIN] Epoch[7](163/1500); Loss: 0.071019; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0670 0.0839 0.0930 0.0848 0.0770 0.0688 0.0672 0.0639 0.0636 0.0662 0.0651 0.0653 0.0657 0.0681 0.0673 0.0692 

[TRAIN] Epoch[7](164/1500); Loss: 0.173238; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2655 0.2178 0.2022 0.1994 0.1973 0.1886 0.1766 0.1695 0.1617 0.1545 0.1474 0.1413 0.1380 0.1362 0.1359 0.1400 

[TRAIN] Epoch[7](165/1500); Loss: 0.203044; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.3131 0.2579 0.2636 0.2692 0.2570 0.2346 0.2093 0.1896 0.1701 0.1547 0.1563 0.1551 0.1541 0.1523 0.1559 0.1557 

[TRAIN] Epoch[7](166/1500); Loss: 0.181532; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2331 0.2056 0.2218 0.2238 0.2153 0.2034 0.1912 0.1831 0.1736 0.1650 0.1592 0.1532 0.1483 0.1448 0.1427 0.1405 

[TRAIN] Epoch[7](167/1500); Loss: 0.113036; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1607 0.1328 0.1478 0.1480 0.1412 0.1323 0.1213 0.1119 0.1039 0.0960 0.0896 0.0854 0.0840 0.0835 0.0854 0.0847 

[TRAIN] Epoch[7](168/1500); Loss: 0.088241; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1995 0.1231 0.0842 0.0817 0.0775 0.0757 0.0779 0.0756 0.0756 0.0745 0.0774 0.0771 0.0768 0.0779 0.0769 0.0804 

[TRAIN] Epoch[7](169/1500); Loss: 0.141168; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1664 0.1388 0.1438 0.1442 0.1419 0.1408 0.1410 0.1403 0.1393 0.1386 0.1383 0.1375 0.1375 0.1369 0.1367 0.1367 

[TRAIN] Epoch[7](170/1500); Loss: 0.098515; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1544 0.1146 0.1299 0.1316 0.1242 0.1139 0.1026 0.0936 0.0864 0.0800 0.0757 0.0737 0.0740 0.0738 0.0739 0.0739 

[TRAIN] Epoch[7](171/1500); Loss: 0.143724; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2195 0.1837 0.1673 0.1662 0.1592 0.1491 0.1412 0.1358 0.1300 0.1254 0.1260 0.1232 0.1193 0.1186 0.1181 0.1171 

[TRAIN] Epoch[7](172/1500); Loss: 0.101840; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2909 0.2084 0.1154 0.0775 0.0770 0.0764 0.0759 0.0739 0.0777 0.0773 0.0747 0.0762 0.0790 0.0825 0.0832 0.0833 

[TRAIN] Epoch[7](173/1500); Loss: 0.099629; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2429 0.1681 0.1090 0.0872 0.0906 0.0851 0.0811 0.0798 0.0771 0.0774 0.0772 0.0789 0.0814 0.0837 0.0871 0.0876 

[TRAIN] Epoch[7](174/1500); Loss: 0.111452; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.3161 0.2483 0.1590 0.0992 0.0856 0.0789 0.0740 0.0852 0.0847 0.0807 0.0784 0.0773 0.0775 0.0781 0.0794 0.0811 

[TRAIN] Epoch[7](175/1500); Loss: 0.094895; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1241 0.1003 0.1173 0.1184 0.1096 0.0977 0.0891 0.0877 0.0854 0.0824 0.0830 0.0822 0.0850 0.0844 0.0848 0.0868 

[TRAIN] Epoch[7](176/1500); Loss: 0.090687; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1259 0.1072 0.1121 0.1100 0.1041 0.0982 0.0920 0.0867 0.0830 0.0800 0.0773 0.0753 0.0747 0.0747 0.0747 0.0753 

[TRAIN] Epoch[7](177/1500); Loss: 0.158613; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1746 0.1686 0.1777 0.1730 0.1664 0.1614 0.1568 0.1542 0.1527 0.1511 0.1500 0.1498 0.1499 0.1501 0.1504 0.1511 

[TRAIN] Epoch[7](178/1500); Loss: 0.185664; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2797 0.2286 0.2477 0.2592 0.2482 0.2280 0.2026 0.1832 0.1636 0.1483 0.1393 0.1330 0.1282 0.1267 0.1265 0.1280 

[TRAIN] Epoch[7](179/1500); Loss: 0.096326; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1153 0.1107 0.1170 0.1080 0.1008 0.0959 0.0937 0.0924 0.0907 0.0886 0.0878 0.0875 0.0886 0.0882 0.0884 0.0878 

[TRAIN] Epoch[7](180/1500); Loss: 0.081989; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0933 0.0926 0.0954 0.0868 0.0808 0.0802 0.0785 0.0768 0.0761 0.0786 0.0772 0.0776 0.0776 0.0802 0.0801 0.0801 

[TRAIN] Epoch[7](181/1500); Loss: 0.103016; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.2099 0.1405 0.1670 0.1767 0.1639 0.1391 0.1087 0.0866 0.0696 0.0576 0.0513 0.0514 0.0544 0.0582 0.0574 0.0562 

[TRAIN] Epoch[7](182/1500); Loss: 0.107284; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1223 0.1012 0.1518 0.1381 0.1269 0.1109 0.1007 0.0956 0.0940 0.0937 0.0980 0.0971 0.0967 0.0946 0.0937 0.1013 

[TRAIN] Epoch[7](183/1500); Loss: 0.190109; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2342 0.2166 0.2127 0.2079 0.2079 0.2000 0.1927 0.1876 0.1820 0.1784 0.1749 0.1718 0.1693 0.1689 0.1688 0.1681 

[TRAIN] Epoch[7](184/1500); Loss: 0.125573; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1689 0.1547 0.1484 0.1431 0.1374 0.1303 0.1246 0.1197 0.1149 0.1118 0.1107 0.1094 0.1088 0.1085 0.1082 0.1095 

[TRAIN] Epoch[7](185/1500); Loss: 0.131578; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1667 0.1451 0.1511 0.1459 0.1386 0.1321 0.1289 0.1254 0.1233 0.1208 0.1198 0.1199 0.1199 0.1214 0.1223 0.1240 

[TRAIN] Epoch[7](186/1500); Loss: 0.162660; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2417 0.1866 0.2156 0.2327 0.2216 0.2033 0.1814 0.1682 0.1515 0.1361 0.1242 0.1155 0.1109 0.1063 0.1039 0.1030 

[TRAIN] Epoch[7](187/1500); Loss: 0.087734; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.0888 0.0902 0.1165 0.1027 0.0957 0.0902 0.0843 0.0787 0.0796 0.0795 0.0788 0.0783 0.0801 0.0849 0.0874 0.0879 

[TRAIN] Epoch[7](188/1500); Loss: 0.103789; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1810 0.1130 0.1387 0.1717 0.1586 0.1352 0.1063 0.0890 0.0752 0.0669 0.0643 0.0655 0.0700 0.0747 0.0746 0.0758 

[TRAIN] Epoch[7](189/1500); Loss: 0.192311; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2773 0.2325 0.2163 0.2063 0.2066 0.2046 0.1967 0.1917 0.1871 0.1808 0.1754 0.1702 0.1647 0.1600 0.1551 0.1516 

[TRAIN] Epoch[7](190/1500); Loss: 0.101085; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1276 0.0982 0.1149 0.1256 0.1144 0.1007 0.0901 0.0876 0.0900 0.0900 0.0923 0.0935 0.0943 0.0982 0.0985 0.1014 

[TRAIN] Epoch[7](191/1500); Loss: 0.101522; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1267 0.1057 0.1147 0.1177 0.1136 0.1095 0.1055 0.1027 0.0992 0.0954 0.0915 0.0900 0.0895 0.0883 0.0872 0.0870 

[TRAIN] Epoch[7](192/1500); Loss: 0.219897; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.3342 0.2719 0.2989 0.3318 0.3195 0.2973 0.2664 0.2475 0.2209 0.1924 0.1668 0.1429 0.1233 0.1092 0.0994 0.0960 

[TRAIN] Epoch[7](193/1500); Loss: 0.192165; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.2326 0.2112 0.2309 0.2331 0.2269 0.2150 0.2028 0.1935 0.1844 0.1774 0.1719 0.1656 0.1601 0.1578 0.1570 0.1544 

[TRAIN] Epoch[7](194/1500); Loss: 0.078534; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1213 0.0992 0.0926 0.0844 0.0779 0.0737 0.0721 0.0709 0.0702 0.0715 0.0709 0.0712 0.0701 0.0694 0.0700 0.0712 

[TRAIN] Epoch[7](195/1500); Loss: 0.140499; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.2055 0.1777 0.1487 0.1779 0.1741 0.1603 0.1482 0.1380 0.1271 0.1190 0.1129 0.1091 0.1085 0.1126 0.1145 0.1139 

[TRAIN] Epoch[7](196/1500); Loss: 0.154186; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1647 0.1608 0.1669 0.1675 0.1642 0.1600 0.1576 0.1542 0.1514 0.1487 0.1470 0.1453 0.1444 0.1446 0.1449 0.1448 

[TRAIN] Epoch[7](197/1500); Loss: 0.056982; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.0912 0.0632 0.0689 0.0727 0.0675 0.0600 0.0538 0.0514 0.0491 0.0472 0.0478 0.0469 0.0466 0.0478 0.0485 0.0491 

[TRAIN] Epoch[7](198/1500); Loss: 0.129650; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.2267 0.1811 0.1304 0.1391 0.1305 0.1274 0.1307 0.1276 0.1184 0.1100 0.1059 0.1128 0.1164 0.1118 0.1047 0.1012 

[TRAIN] Epoch[7](199/1500); Loss: 0.089612; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1204 0.1004 0.0960 0.0951 0.0904 0.0876 0.0867 0.0853 0.0839 0.0835 0.0831 0.0830 0.0831 0.0838 0.0855 0.0862 

[TRAIN] Epoch[7](200/1500); Loss: 0.127962; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1640 0.1361 0.1811 0.1833 0.1728 0.1551 0.1353 0.1230 0.1114 0.1037 0.0984 0.0947 0.0942 0.0968 0.0979 0.0997 

[TRAIN] Epoch[7](201/1500); Loss: 0.077736; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.1363 0.1037 0.0920 0.0849 0.0766 0.0681 0.0615 0.0564 0.0560 0.0585 0.0624 0.0666 0.0714 0.0771 0.0833 0.0890 

[TRAIN] Epoch[7](202/1500); Loss: 0.155243; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1945 0.1697 0.1927 0.1940 0.1842 0.1705 0.1572 0.1479 0.1439 0.1395 0.1351 0.1311 0.1292 0.1329 0.1314 0.1298 

[TRAIN] Epoch[7](203/1500); Loss: 0.113151; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1221 0.0941 0.1865 0.1654 0.1519 0.1271 0.1049 0.0875 0.0877 0.0958 0.1018 0.0979 0.0931 0.0901 0.0993 0.1052 

[TRAIN] Epoch[7](204/1500); Loss: 0.181561; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2404 0.1952 0.2351 0.2377 0.2268 0.2089 0.1897 0.1785 0.1713 0.1631 0.1544 0.1447 0.1392 0.1385 0.1397 0.1419 

[TRAIN] Epoch[7](205/1500); Loss: 0.092316; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1014 0.0994 0.1063 0.1005 0.0944 0.0908 0.0889 0.0874 0.0869 0.0862 0.0865 0.0879 0.0880 0.0895 0.0907 0.0921 

[TRAIN] Epoch[7](206/1500); Loss: 0.098733; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1050 0.1027 0.1089 0.1090 0.1058 0.1021 0.0993 0.0972 0.0961 0.0948 0.0934 0.0933 0.0930 0.0927 0.0929 0.0934 

[TRAIN] Epoch[7](207/1500); Loss: 0.094909; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1137 0.1036 0.1210 0.1136 0.1018 0.0903 0.0855 0.0857 0.0850 0.0840 0.0846 0.0862 0.0879 0.0890 0.0921 0.0947 

[TRAIN] Epoch[7](208/1500); Loss: 0.159659; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2291 0.1915 0.2243 0.2249 0.2117 0.1914 0.1692 0.1552 0.1400 0.1256 0.1169 0.1123 0.1135 0.1152 0.1165 0.1173 

[TRAIN] Epoch[7](209/1500); Loss: 0.049036; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0825 0.0520 0.0632 0.0644 0.0574 0.0476 0.0412 0.0411 0.0402 0.0418 0.0411 0.0408 0.0401 0.0441 0.0439 0.0433 

[TRAIN] Epoch[7](210/1500); Loss: 0.166392; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2099 0.1981 0.1910 0.1848 0.1762 0.1658 0.1600 0.1601 0.1586 0.1559 0.1521 0.1500 0.1515 0.1511 0.1492 0.1481 

[TRAIN] Epoch[7](211/1500); Loss: 0.121706; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1801 0.1512 0.1275 0.1514 0.1523 0.1396 0.1263 0.1159 0.1077 0.1026 0.0994 0.1002 0.0985 0.0971 0.0979 0.0996 

[TRAIN] Epoch[7](212/1500); Loss: 0.137829; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1927 0.1645 0.1540 0.1673 0.1615 0.1493 0.1370 0.1285 0.1242 0.1212 0.1203 0.1189 0.1170 0.1162 0.1158 0.1168 

[TRAIN] Epoch[7](213/1500); Loss: 0.127976; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1456 0.1210 0.1543 0.1628 0.1532 0.1395 0.1269 0.1183 0.1146 0.1161 0.1160 0.1141 0.1134 0.1156 0.1171 0.1193 

[TRAIN] Epoch[7](214/1500); Loss: 0.140226; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1597 0.1487 0.1641 0.1667 0.1648 0.1551 0.1458 0.1409 0.1348 0.1294 0.1258 0.1233 0.1215 0.1205 0.1214 0.1212 

[TRAIN] Epoch[7](215/1500); Loss: 0.118643; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1626 0.1222 0.1255 0.1567 0.1509 0.1365 0.1214 0.1104 0.1025 0.0986 0.1015 0.1035 0.1011 0.0992 0.1014 0.1043 

[TRAIN] Epoch[7](216/1500); Loss: 0.160353; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.2506 0.1994 0.1731 0.2028 0.2069 0.1925 0.1749 0.1595 0.1450 0.1345 0.1284 0.1232 0.1190 0.1191 0.1182 0.1187 

[TRAIN] Epoch[7](217/1500); Loss: 0.088301; Backpropagation: 0.0942 sec; Batch: 0.4258 sec
0.1024 0.1014 0.1095 0.1022 0.0993 0.0931 0.0892 0.0861 0.0832 0.0812 0.0788 0.0775 0.0768 0.0775 0.0770 0.0775 

[TRAIN] Epoch[7](218/1500); Loss: 0.141346; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1882 0.1648 0.1627 0.1518 0.1416 0.1339 0.1300 0.1280 0.1299 0.1292 0.1294 0.1298 0.1318 0.1341 0.1369 0.1396 

[TRAIN] Epoch[7](219/1500); Loss: 0.166115; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2081 0.1856 0.2306 0.2373 0.2234 0.2013 0.1788 0.1643 0.1503 0.1387 0.1311 0.1250 0.1204 0.1196 0.1209 0.1225 

[TRAIN] Epoch[7](220/1500); Loss: 0.136787; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1971 0.1464 0.1847 0.1971 0.1854 0.1675 0.1456 0.1321 0.1191 0.1106 0.1040 0.0993 0.0975 0.0993 0.1006 0.1021 

[TRAIN] Epoch[7](221/1500); Loss: 0.153637; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1538 0.1564 0.1823 0.1775 0.1688 0.1597 0.1519 0.1453 0.1411 0.1390 0.1390 0.1410 0.1441 0.1483 0.1530 0.1571 

[TRAIN] Epoch[7](222/1500); Loss: 0.160405; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1599 0.1618 0.1820 0.1788 0.1734 0.1673 0.1625 0.1593 0.1570 0.1554 0.1537 0.1521 0.1518 0.1514 0.1502 0.1501 

[TRAIN] Epoch[7](223/1500); Loss: 0.111352; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1334 0.1157 0.1312 0.1324 0.1214 0.1081 0.1004 0.1007 0.1014 0.1041 0.1033 0.1036 0.1041 0.1056 0.1081 0.1082 

[TRAIN] Epoch[7](224/1500); Loss: 0.079005; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.0699 0.0769 0.1215 0.1139 0.1056 0.0941 0.0833 0.0764 0.0707 0.0664 0.0639 0.0629 0.0621 0.0637 0.0655 0.0672 

[TRAIN] Epoch[7](225/1500); Loss: 0.123744; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1522 0.1398 0.1396 0.1445 0.1363 0.1264 0.1192 0.1150 0.1131 0.1128 0.1120 0.1109 0.1126 0.1148 0.1153 0.1154 

[TRAIN] Epoch[7](226/1500); Loss: 0.185537; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.2319 0.2055 0.2037 0.2103 0.2086 0.1974 0.1869 0.1825 0.1778 0.1738 0.1700 0.1692 0.1666 0.1639 0.1613 0.1593 

[TRAIN] Epoch[7](227/1500); Loss: 0.109272; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1869 0.0812 0.1232 0.1625 0.1487 0.1310 0.1099 0.0899 0.0737 0.0648 0.0666 0.0780 0.1118 0.1180 0.1062 0.0958 

[TRAIN] Epoch[7](228/1500); Loss: 0.049539; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0869 0.0552 0.0662 0.0671 0.0601 0.0506 0.0423 0.0386 0.0380 0.0402 0.0402 0.0397 0.0397 0.0421 0.0433 0.0426 

[TRAIN] Epoch[7](229/1500); Loss: 0.256336; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.3769 0.3150 0.3423 0.3563 0.3449 0.3245 0.2974 0.2784 0.2557 0.2323 0.2109 0.1897 0.1693 0.1503 0.1347 0.1228 

[TRAIN] Epoch[7](230/1500); Loss: 0.129564; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1476 0.1365 0.1610 0.1702 0.1609 0.1472 0.1332 0.1237 0.1178 0.1152 0.1118 0.1095 0.1097 0.1103 0.1090 0.1095 

[TRAIN] Epoch[7](231/1500); Loss: 0.115568; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2048 0.1396 0.1624 0.1801 0.1662 0.1414 0.1126 0.0928 0.0775 0.0730 0.0776 0.0810 0.0831 0.0839 0.0854 0.0879 

[TRAIN] Epoch[7](232/1500); Loss: 0.081328; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1679 0.1011 0.0905 0.1126 0.1010 0.0843 0.0688 0.0577 0.0532 0.0650 0.0718 0.0690 0.0633 0.0609 0.0635 0.0706 

[TRAIN] Epoch[7](233/1500); Loss: 0.051335; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0833 0.0570 0.0653 0.0672 0.0604 0.0513 0.0440 0.0454 0.0446 0.0450 0.0431 0.0428 0.0419 0.0424 0.0438 0.0438 

[TRAIN] Epoch[7](234/1500); Loss: 0.110173; Backpropagation: 0.0916 sec; Batch: 0.4227 sec
0.1027 0.1179 0.1490 0.1383 0.1278 0.1193 0.1099 0.1024 0.0998 0.0985 0.0971 0.0972 0.0974 0.1009 0.1019 0.1026 

[TRAIN] Epoch[7](235/1500); Loss: 0.148324; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2103 0.1749 0.1706 0.1655 0.1599 0.1509 0.1435 0.1383 0.1356 0.1339 0.1339 0.1322 0.1312 0.1306 0.1312 0.1309 

[TRAIN] Epoch[7](236/1500); Loss: 0.118035; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1412 0.1319 0.1483 0.1459 0.1391 0.1308 0.1241 0.1186 0.1129 0.1085 0.1043 0.1002 0.0975 0.0962 0.0951 0.0941 

[TRAIN] Epoch[7](237/1500); Loss: 0.068511; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0999 0.0588 0.0636 0.0595 0.0607 0.0635 0.0620 0.0613 0.0644 0.0684 0.0676 0.0672 0.0704 0.0764 0.0763 0.0761 

[TRAIN] Epoch[7](238/1500); Loss: 0.161945; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2249 0.1877 0.1990 0.2000 0.1907 0.1757 0.1611 0.1493 0.1400 0.1353 0.1348 0.1357 0.1373 0.1386 0.1394 0.1418 

[TRAIN] Epoch[7](239/1500); Loss: 0.121889; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1629 0.1285 0.1212 0.1633 0.1694 0.1571 0.1407 0.1229 0.1085 0.0999 0.0951 0.0955 0.0960 0.0961 0.0962 0.0969 

[TRAIN] Epoch[7](240/1500); Loss: 0.105177; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1224 0.1189 0.1535 0.1465 0.1353 0.1202 0.1064 0.0957 0.0892 0.0855 0.0838 0.0832 0.0837 0.0849 0.0858 0.0878 

[TRAIN] Epoch[7](241/1500); Loss: 0.112011; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1899 0.0843 0.1003 0.1832 0.1684 0.1526 0.1294 0.1035 0.0826 0.0676 0.0671 0.0738 0.0879 0.1025 0.1028 0.0964 

[TRAIN] Epoch[7](242/1500); Loss: 0.109951; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1262 0.1205 0.1275 0.1338 0.1235 0.1160 0.1123 0.1069 0.1032 0.1017 0.0997 0.0977 0.0975 0.0968 0.0983 0.0976 

[TRAIN] Epoch[7](243/1500); Loss: 0.148960; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2261 0.1872 0.1527 0.1899 0.1811 0.1665 0.1490 0.1359 0.1325 0.1296 0.1334 0.1296 0.1229 0.1177 0.1146 0.1147 

[TRAIN] Epoch[7](244/1500); Loss: 0.075242; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1629 0.1296 0.0893 0.0845 0.0891 0.0789 0.0685 0.0618 0.0566 0.0540 0.0535 0.0550 0.0546 0.0551 0.0552 0.0552 

[TRAIN] Epoch[7](245/1500); Loss: 0.136749; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1758 0.1551 0.1654 0.1665 0.1580 0.1446 0.1340 0.1280 0.1256 0.1226 0.1195 0.1186 0.1173 0.1181 0.1194 0.1195 

[TRAIN] Epoch[7](246/1500); Loss: 0.170803; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2372 0.1958 0.2086 0.2274 0.2272 0.2110 0.1898 0.1711 0.1536 0.1408 0.1312 0.1260 0.1251 0.1289 0.1289 0.1301 

[TRAIN] Epoch[7](247/1500); Loss: 0.094279; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1325 0.1056 0.1191 0.1162 0.1073 0.0959 0.0871 0.0819 0.0797 0.0795 0.0811 0.0816 0.0818 0.0826 0.0867 0.0899 

[TRAIN] Epoch[7](248/1500); Loss: 0.106626; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1162 0.1063 0.1322 0.1285 0.1204 0.1100 0.1032 0.0992 0.0986 0.0976 0.0983 0.0981 0.0986 0.0978 0.0997 0.1010 

[TRAIN] Epoch[7](249/1500); Loss: 0.128594; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1511 0.1362 0.1460 0.1491 0.1443 0.1348 0.1273 0.1233 0.1208 0.1196 0.1191 0.1179 0.1170 0.1164 0.1174 0.1173 

[TRAIN] Epoch[7](250/1500); Loss: 0.161655; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1623 0.1729 0.2070 0.2014 0.1889 0.1726 0.1592 0.1511 0.1486 0.1485 0.1463 0.1447 0.1437 0.1446 0.1474 0.1472 

[TRAIN] Epoch[7](251/1500); Loss: 0.162733; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1837 0.1747 0.1771 0.1797 0.1797 0.1736 0.1656 0.1584 0.1540 0.1517 0.1503 0.1506 0.1511 0.1509 0.1509 0.1517 

[TRAIN] Epoch[7](252/1500); Loss: 0.168718; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2348 0.1959 0.2189 0.2331 0.2204 0.2023 0.1810 0.1656 0.1521 0.1431 0.1364 0.1293 0.1235 0.1210 0.1203 0.1218 

[TRAIN] Epoch[7](253/1500); Loss: 0.156846; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1966 0.1666 0.2119 0.2208 0.2060 0.1833 0.1603 0.1464 0.1379 0.1314 0.1283 0.1258 0.1238 0.1227 0.1232 0.1245 

[TRAIN] Epoch[7](254/1500); Loss: 0.157971; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1812 0.1735 0.2039 0.1980 0.1872 0.1714 0.1581 0.1503 0.1457 0.1424 0.1380 0.1360 0.1352 0.1348 0.1353 0.1366 

[TRAIN] Epoch[7](255/1500); Loss: 0.078837; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1163 0.1101 0.1080 0.0996 0.0880 0.0780 0.0711 0.0693 0.0689 0.0671 0.0652 0.0643 0.0636 0.0627 0.0634 0.0660 

[TRAIN] Epoch[7](256/1500); Loss: 0.160714; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1895 0.1682 0.1818 0.1862 0.1803 0.1718 0.1635 0.1583 0.1538 0.1506 0.1485 0.1463 0.1442 0.1428 0.1426 0.1430 

[TRAIN] Epoch[7](257/1500); Loss: 0.124490; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1344 0.1406 0.1498 0.1426 0.1337 0.1261 0.1201 0.1167 0.1157 0.1147 0.1146 0.1161 0.1173 0.1167 0.1162 0.1165 

[TRAIN] Epoch[7](258/1500); Loss: 0.094727; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1424 0.1195 0.1288 0.1271 0.1195 0.1078 0.0973 0.0894 0.0836 0.0779 0.0733 0.0705 0.0694 0.0694 0.0694 0.0705 

[TRAIN] Epoch[7](259/1500); Loss: 0.154807; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1724 0.1657 0.1759 0.1715 0.1644 0.1566 0.1537 0.1500 0.1493 0.1483 0.1467 0.1453 0.1455 0.1447 0.1440 0.1429 

[TRAIN] Epoch[7](260/1500); Loss: 0.092749; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1182 0.1092 0.1155 0.1106 0.1028 0.0955 0.0900 0.0860 0.0841 0.0823 0.0816 0.0813 0.0814 0.0816 0.0815 0.0824 

[TRAIN] Epoch[7](261/1500); Loss: 0.114674; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1483 0.1259 0.1506 0.1490 0.1359 0.1193 0.1053 0.0987 0.0963 0.0964 0.0974 0.0994 0.1018 0.1023 0.1037 0.1048 

[TRAIN] Epoch[7](262/1500); Loss: 0.148798; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2386 0.1896 0.1617 0.1791 0.1746 0.1614 0.1467 0.1368 0.1331 0.1281 0.1252 0.1234 0.1217 0.1196 0.1198 0.1215 

[TRAIN] Epoch[7](263/1500); Loss: 0.116756; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1321 0.1417 0.1539 0.1461 0.1325 0.1171 0.1078 0.1048 0.1012 0.1026 0.1006 0.1022 0.1046 0.1055 0.1070 0.1083 

[TRAIN] Epoch[7](264/1500); Loss: 0.071579; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0899 0.0834 0.0777 0.0698 0.0678 0.0661 0.0668 0.0669 0.0682 0.0672 0.0672 0.0687 0.0705 0.0705 0.0710 0.0733 

[TRAIN] Epoch[7](265/1500); Loss: 0.149510; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1958 0.1747 0.1702 0.1648 0.1634 0.1575 0.1485 0.1430 0.1375 0.1343 0.1317 0.1332 0.1344 0.1341 0.1340 0.1350 

[TRAIN] Epoch[7](266/1500); Loss: 0.166757; Backpropagation: 0.0917 sec; Batch: 0.4224 sec
0.2542 0.2056 0.2237 0.2193 0.2072 0.1871 0.1678 0.1530 0.1404 0.1336 0.1292 0.1297 0.1287 0.1298 0.1294 0.1296 

[TRAIN] Epoch[7](267/1500); Loss: 0.153795; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2072 0.1846 0.1919 0.1881 0.1797 0.1694 0.1604 0.1520 0.1438 0.1352 0.1287 0.1246 0.1233 0.1229 0.1244 0.1244 

[TRAIN] Epoch[7](268/1500); Loss: 0.068567; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1038 0.0830 0.0786 0.0742 0.0689 0.0651 0.0624 0.0607 0.0598 0.0595 0.0608 0.0613 0.0625 0.0634 0.0656 0.0674 

[TRAIN] Epoch[7](269/1500); Loss: 0.098918; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1516 0.1318 0.1151 0.1104 0.1036 0.0988 0.0939 0.0910 0.0868 0.0865 0.0852 0.0840 0.0858 0.0862 0.0860 0.0861 

[TRAIN] Epoch[7](270/1500); Loss: 0.127260; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1514 0.1437 0.1366 0.1332 0.1282 0.1244 0.1215 0.1212 0.1204 0.1199 0.1203 0.1214 0.1215 0.1224 0.1241 0.1260 

[TRAIN] Epoch[7](271/1500); Loss: 0.104033; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1948 0.1403 0.1259 0.1257 0.1188 0.1105 0.1014 0.0917 0.0835 0.0789 0.0801 0.0823 0.0812 0.0823 0.0823 0.0847 

[TRAIN] Epoch[7](272/1500); Loss: 0.128820; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1727 0.1301 0.1718 0.1641 0.1497 0.1276 0.1149 0.1115 0.1115 0.1136 0.1122 0.1134 0.1161 0.1158 0.1177 0.1183 

[TRAIN] Epoch[7](273/1500); Loss: 0.085245; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1269 0.1057 0.1093 0.1041 0.0975 0.0889 0.0838 0.0767 0.0740 0.0713 0.0706 0.0695 0.0702 0.0714 0.0720 0.0721 

[TRAIN] Epoch[7](274/1500); Loss: 0.115901; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1406 0.1525 0.1656 0.1462 0.1265 0.1116 0.1054 0.1002 0.0981 0.0977 0.0975 0.1002 0.1014 0.1019 0.1042 0.1050 

[TRAIN] Epoch[7](275/1500); Loss: 0.082384; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1068 0.0947 0.0902 0.0854 0.0820 0.0785 0.0778 0.0762 0.0755 0.0770 0.0768 0.0770 0.0784 0.0803 0.0804 0.0812 

[TRAIN] Epoch[7](276/1500); Loss: 0.088393; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1995 0.1226 0.1444 0.1369 0.1189 0.0923 0.0715 0.0604 0.0526 0.0536 0.0542 0.0598 0.0582 0.0609 0.0617 0.0667 

[TRAIN] Epoch[7](277/1500); Loss: 0.147476; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1784 0.1638 0.1669 0.1617 0.1541 0.1478 0.1448 0.1411 0.1392 0.1389 0.1376 0.1367 0.1375 0.1368 0.1370 0.1374 

[TRAIN] Epoch[7](278/1500); Loss: 0.069982; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0793 0.0829 0.0762 0.0727 0.0701 0.0685 0.0667 0.0661 0.0652 0.0649 0.0647 0.0652 0.0668 0.0682 0.0704 0.0718 

[TRAIN] Epoch[7](279/1500); Loss: 0.143103; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.2414 0.1897 0.1507 0.1650 0.1552 0.1437 0.1394 0.1353 0.1275 0.1202 0.1181 0.1166 0.1183 0.1192 0.1233 0.1261 

[TRAIN] Epoch[7](280/1500); Loss: 0.077891; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1083 0.0831 0.1276 0.1218 0.1049 0.0810 0.0631 0.0551 0.0552 0.0597 0.0606 0.0610 0.0623 0.0657 0.0677 0.0693 

[TRAIN] Epoch[7](281/1500); Loss: 0.230543; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.4439 0.3481 0.3693 0.3878 0.3673 0.3299 0.2806 0.2381 0.1897 0.1401 0.1030 0.0865 0.0975 0.0992 0.1025 0.1051 

[TRAIN] Epoch[7](282/1500); Loss: 0.132033; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1771 0.1597 0.1459 0.1430 0.1360 0.1296 0.1260 0.1248 0.1213 0.1210 0.1211 0.1213 0.1211 0.1216 0.1208 0.1224 

[TRAIN] Epoch[7](283/1500); Loss: 0.105204; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1137 0.1111 0.1290 0.1174 0.1068 0.0984 0.0966 0.0966 0.0964 0.0985 0.0985 0.1011 0.1015 0.1034 0.1059 0.1084 

[TRAIN] Epoch[7](284/1500); Loss: 0.088350; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0992 0.0967 0.1204 0.1081 0.0962 0.0836 0.0825 0.0780 0.0784 0.0781 0.0815 0.0811 0.0802 0.0814 0.0838 0.0845 

[TRAIN] Epoch[7](285/1500); Loss: 0.112863; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1707 0.0979 0.1404 0.1530 0.1381 0.1197 0.1020 0.0904 0.0885 0.0935 0.1033 0.1065 0.0999 0.0978 0.0990 0.1050 

[TRAIN] Epoch[7](286/1500); Loss: 0.142763; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1918 0.1691 0.1646 0.1601 0.1562 0.1476 0.1410 0.1352 0.1303 0.1259 0.1255 0.1263 0.1273 0.1268 0.1274 0.1290 

[TRAIN] Epoch[7](287/1500); Loss: 0.033866; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0405 0.0414 0.0350 0.0312 0.0306 0.0292 0.0287 0.0296 0.0299 0.0307 0.0318 0.0337 0.0351 0.0364 0.0381 0.0402 

[TRAIN] Epoch[7](288/1500); Loss: 0.081388; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0955 0.0849 0.1251 0.1149 0.1026 0.0841 0.0703 0.0667 0.0667 0.0674 0.0682 0.0681 0.0705 0.0708 0.0727 0.0736 

[TRAIN] Epoch[7](289/1500); Loss: 0.128745; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1451 0.1372 0.1430 0.1412 0.1325 0.1244 0.1214 0.1213 0.1206 0.1198 0.1209 0.1240 0.1246 0.1257 0.1278 0.1304 

[TRAIN] Epoch[7](290/1500); Loss: 0.130882; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1933 0.1539 0.1659 0.1873 0.1735 0.1533 0.1314 0.1198 0.1087 0.1049 0.1011 0.0981 0.0981 0.0977 0.1030 0.1041 

[TRAIN] Epoch[7](291/1500); Loss: 0.180437; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2326 0.1964 0.1997 0.2103 0.2019 0.1908 0.1806 0.1754 0.1702 0.1648 0.1617 0.1593 0.1589 0.1602 0.1621 0.1620 

[TRAIN] Epoch[7](292/1500); Loss: 0.098277; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1552 0.1265 0.1079 0.1091 0.1029 0.0951 0.0899 0.0863 0.0853 0.0840 0.0831 0.0855 0.0884 0.0898 0.0904 0.0932 

[TRAIN] Epoch[7](293/1500); Loss: 0.113745; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1671 0.1558 0.1406 0.1352 0.1227 0.1083 0.0995 0.0971 0.1004 0.1008 0.0985 0.0952 0.0953 0.0999 0.1013 0.1023 

[TRAIN] Epoch[7](294/1500); Loss: 0.038992; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0492 0.0397 0.0369 0.0356 0.0339 0.0331 0.0334 0.0343 0.0355 0.0370 0.0382 0.0397 0.0418 0.0435 0.0451 0.0470 

[TRAIN] Epoch[7](295/1500); Loss: 0.100361; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1436 0.1105 0.1180 0.1123 0.1040 0.0945 0.0951 0.0931 0.0925 0.0912 0.0912 0.0906 0.0908 0.0910 0.0927 0.0946 

[TRAIN] Epoch[7](296/1500); Loss: 0.153015; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1922 0.1796 0.1742 0.1726 0.1694 0.1640 0.1561 0.1434 0.1388 0.1398 0.1412 0.1378 0.1327 0.1331 0.1359 0.1374 

[TRAIN] Epoch[7](297/1500); Loss: 0.135006; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1736 0.1485 0.1484 0.1462 0.1416 0.1351 0.1291 0.1256 0.1244 0.1244 0.1254 0.1262 0.1272 0.1271 0.1281 0.1292 

[TRAIN] Epoch[7](298/1500); Loss: 0.228358; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.3399 0.2852 0.2844 0.2854 0.2744 0.2541 0.2303 0.2105 0.1923 0.1823 0.1812 0.1869 0.1846 0.1861 0.1867 0.1895 

[TRAIN] Epoch[7](299/1500); Loss: 0.114064; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1310 0.1241 0.1421 0.1402 0.1271 0.1125 0.1040 0.1019 0.1029 0.1031 0.1032 0.1032 0.1045 0.1064 0.1079 0.1110 

[TRAIN] Epoch[7](300/1500); Loss: 0.101858; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1571 0.1158 0.1188 0.1157 0.1086 0.0999 0.0944 0.0922 0.0907 0.0904 0.0903 0.0911 0.0904 0.0908 0.0916 0.0918 

[TRAIN] Epoch[7](301/1500); Loss: 0.127765; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1645 0.1430 0.1499 0.1461 0.1397 0.1307 0.1244 0.1190 0.1165 0.1150 0.1151 0.1153 0.1153 0.1157 0.1167 0.1174 

[TRAIN] Epoch[7](302/1500); Loss: 0.079284; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0999 0.0855 0.1069 0.0992 0.0891 0.0772 0.0699 0.0677 0.0683 0.0694 0.0708 0.0713 0.0715 0.0723 0.0744 0.0750 

[TRAIN] Epoch[7](303/1500); Loss: 0.149638; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2521 0.1991 0.2089 0.2099 0.1978 0.1768 0.1536 0.1357 0.1175 0.1058 0.1036 0.1063 0.1066 0.1068 0.1065 0.1073 

[TRAIN] Epoch[7](304/1500); Loss: 0.089490; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1009 0.0980 0.1027 0.0982 0.0935 0.0884 0.0856 0.0845 0.0849 0.0843 0.0839 0.0848 0.0844 0.0850 0.0860 0.0867 

[TRAIN] Epoch[7](305/1500); Loss: 0.063889; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0823 0.0701 0.0698 0.0675 0.0629 0.0581 0.0576 0.0567 0.0576 0.0577 0.0585 0.0599 0.0626 0.0639 0.0671 0.0698 

[TRAIN] Epoch[7](306/1500); Loss: 0.212362; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2878 0.2362 0.2624 0.2827 0.2710 0.2529 0.2310 0.2165 0.1998 0.1840 0.1724 0.1643 0.1598 0.1581 0.1583 0.1606 

[TRAIN] Epoch[7](307/1500); Loss: 0.102764; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1742 0.1402 0.1120 0.1125 0.1068 0.0999 0.0956 0.0938 0.0894 0.0871 0.0859 0.0852 0.0883 0.0903 0.0912 0.0921 

[TRAIN] Epoch[7](308/1500); Loss: 0.081900; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1161 0.1000 0.0999 0.0961 0.0904 0.0832 0.0776 0.0741 0.0719 0.0719 0.0714 0.0709 0.0719 0.0713 0.0720 0.0716 

[TRAIN] Epoch[7](309/1500); Loss: 0.108902; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1384 0.1162 0.1392 0.1394 0.1262 0.1089 0.0972 0.0942 0.0953 0.0978 0.0966 0.0959 0.0964 0.0982 0.1017 0.1009 

[TRAIN] Epoch[7](310/1500); Loss: 0.074049; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0903 0.0759 0.0862 0.0808 0.0746 0.0689 0.0695 0.0685 0.0680 0.0693 0.0705 0.0711 0.0717 0.0719 0.0731 0.0743 

[TRAIN] Epoch[7](311/1500); Loss: 0.086130; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1221 0.1031 0.1034 0.1014 0.0969 0.0918 0.0856 0.0806 0.0758 0.0737 0.0729 0.0737 0.0736 0.0740 0.0744 0.0752 

[TRAIN] Epoch[7](312/1500); Loss: 0.078490; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1404 0.0677 0.0884 0.0880 0.0741 0.0578 0.0524 0.0574 0.0720 0.0734 0.0705 0.0704 0.0768 0.0855 0.0892 0.0919 

[TRAIN] Epoch[7](313/1500); Loss: 0.081838; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.0888 0.0926 0.1094 0.0980 0.0858 0.0754 0.0701 0.0710 0.0734 0.0745 0.0762 0.0760 0.0778 0.0777 0.0798 0.0829 

[TRAIN] Epoch[7](314/1500); Loss: 0.096465; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1392 0.1069 0.1071 0.1051 0.1003 0.0939 0.0901 0.0886 0.0884 0.0885 0.0881 0.0891 0.0888 0.0890 0.0895 0.0907 

[TRAIN] Epoch[7](315/1500); Loss: 0.156232; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2088 0.1786 0.1808 0.1844 0.1779 0.1673 0.1566 0.1494 0.1443 0.1395 0.1369 0.1358 0.1355 0.1355 0.1342 0.1342 

[TRAIN] Epoch[7](316/1500); Loss: 0.096023; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1192 0.1109 0.1079 0.1035 0.0992 0.0954 0.0938 0.0909 0.0898 0.0901 0.0893 0.0884 0.0891 0.0894 0.0899 0.0895 

[TRAIN] Epoch[7](317/1500); Loss: 0.140254; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1779 0.1530 0.1576 0.1522 0.1434 0.1358 0.1336 0.1314 0.1301 0.1289 0.1304 0.1313 0.1331 0.1333 0.1352 0.1368 

[TRAIN] Epoch[7](318/1500); Loss: 0.113277; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1325 0.1286 0.1366 0.1314 0.1230 0.1146 0.1080 0.1053 0.1041 0.1060 0.1032 0.1019 0.1031 0.1040 0.1055 0.1046 

[TRAIN] Epoch[7](319/1500); Loss: 0.104731; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1750 0.1235 0.1290 0.1317 0.1214 0.1042 0.0908 0.0851 0.0855 0.0866 0.0881 0.0873 0.0878 0.0904 0.0930 0.0961 

[TRAIN] Epoch[7](320/1500); Loss: 0.134526; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1971 0.1554 0.1607 0.1800 0.1719 0.1540 0.1341 0.1203 0.1129 0.1129 0.1109 0.1097 0.1062 0.1075 0.1092 0.1096 

[TRAIN] Epoch[7](321/1500); Loss: 0.083228; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0943 0.0810 0.1491 0.1321 0.1165 0.0924 0.0745 0.0645 0.0627 0.0660 0.0661 0.0651 0.0650 0.0651 0.0674 0.0698 

[TRAIN] Epoch[7](322/1500); Loss: 0.081913; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.0962 0.0824 0.0996 0.0927 0.0847 0.0764 0.0758 0.0754 0.0754 0.0761 0.0783 0.0772 0.0778 0.0795 0.0820 0.0810 

[TRAIN] Epoch[7](323/1500); Loss: 0.081273; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0999 0.0962 0.1116 0.1020 0.0915 0.0817 0.0758 0.0705 0.0681 0.0675 0.0681 0.0701 0.0714 0.0720 0.0760 0.0780 

[TRAIN] Epoch[7](324/1500); Loss: 0.155914; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1695 0.1636 0.1637 0.1610 0.1575 0.1553 0.1540 0.1528 0.1525 0.1530 0.1517 0.1512 0.1517 0.1525 0.1522 0.1524 

[TRAIN] Epoch[7](325/1500); Loss: 0.098256; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1765 0.0708 0.1287 0.1567 0.1385 0.1169 0.0905 0.0684 0.0582 0.0610 0.0904 0.0950 0.0875 0.0787 0.0747 0.0795 

[TRAIN] Epoch[7](326/1500); Loss: 0.193330; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2271 0.2056 0.2073 0.2076 0.2026 0.1954 0.1900 0.1862 0.1870 0.1856 0.1841 0.1831 0.1808 0.1846 0.1839 0.1825 

[TRAIN] Epoch[7](327/1500); Loss: 0.105669; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1759 0.1264 0.1319 0.1309 0.1219 0.1058 0.0955 0.0913 0.0891 0.0901 0.0892 0.0885 0.0875 0.0885 0.0896 0.0887 

[TRAIN] Epoch[7](328/1500); Loss: 0.134466; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1460 0.1427 0.1632 0.1587 0.1506 0.1386 0.1303 0.1264 0.1252 0.1237 0.1237 0.1256 0.1248 0.1245 0.1232 0.1243 

[TRAIN] Epoch[7](329/1500); Loss: 0.101729; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1188 0.1051 0.1433 0.1343 0.1208 0.1025 0.0923 0.0884 0.0884 0.0879 0.0890 0.0879 0.0889 0.0918 0.0934 0.0949 

[TRAIN] Epoch[7](330/1500); Loss: 0.094422; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1769 0.1040 0.1181 0.1140 0.1037 0.0883 0.0821 0.0803 0.0783 0.0785 0.0774 0.0791 0.0809 0.0822 0.0828 0.0842 

[TRAIN] Epoch[7](331/1500); Loss: 0.162134; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.3150 0.2313 0.2550 0.2649 0.2498 0.2218 0.1869 0.1623 0.1324 0.1041 0.0841 0.0722 0.0730 0.0789 0.0823 0.0802 

[TRAIN] Epoch[7](332/1500); Loss: 0.138592; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1887 0.1543 0.1592 0.1573 0.1519 0.1428 0.1343 0.1294 0.1272 0.1252 0.1249 0.1260 0.1245 0.1235 0.1234 0.1249 

[TRAIN] Epoch[7](333/1500); Loss: 0.166028; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2020 0.1747 0.1829 0.1848 0.1789 0.1701 0.1621 0.1597 0.1567 0.1554 0.1535 0.1530 0.1544 0.1562 0.1564 0.1556 

[TRAIN] Epoch[7](334/1500); Loss: 0.115228; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1658 0.1224 0.1243 0.1379 0.1270 0.1132 0.1053 0.1028 0.1040 0.1034 0.1017 0.1045 0.1076 0.1079 0.1077 0.1082 

[TRAIN] Epoch[7](335/1500); Loss: 0.112475; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1477 0.1254 0.1395 0.1358 0.1282 0.1168 0.1098 0.1049 0.1023 0.1000 0.0991 0.0976 0.0977 0.0979 0.0986 0.0982 

[TRAIN] Epoch[7](336/1500); Loss: 0.153874; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1989 0.1829 0.2098 0.2121 0.1980 0.1796 0.1618 0.1492 0.1372 0.1285 0.1241 0.1188 0.1186 0.1155 0.1145 0.1126 

[TRAIN] Epoch[7](337/1500); Loss: 0.109218; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1852 0.1381 0.1220 0.1278 0.1204 0.1106 0.1046 0.1023 0.1005 0.0963 0.0925 0.0920 0.0904 0.0896 0.0877 0.0875 

[TRAIN] Epoch[7](338/1500); Loss: 0.157429; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1896 0.1762 0.1794 0.1794 0.1751 0.1655 0.1583 0.1534 0.1482 0.1456 0.1438 0.1423 0.1411 0.1405 0.1405 0.1401 

[TRAIN] Epoch[7](339/1500); Loss: 0.101211; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1474 0.1339 0.1206 0.1187 0.1135 0.1046 0.0963 0.0936 0.0918 0.0882 0.0850 0.0860 0.0852 0.0840 0.0835 0.0871 

[TRAIN] Epoch[7](340/1500); Loss: 0.128161; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1653 0.1705 0.1631 0.1546 0.1406 0.1269 0.1176 0.1106 0.1087 0.1127 0.1142 0.1126 0.1114 0.1128 0.1144 0.1145 

[TRAIN] Epoch[7](341/1500); Loss: 0.089679; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1316 0.0952 0.1098 0.1085 0.1006 0.0886 0.0811 0.0790 0.0788 0.0777 0.0782 0.0793 0.0823 0.0805 0.0811 0.0825 

[TRAIN] Epoch[7](342/1500); Loss: 0.113247; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2073 0.1583 0.1087 0.1341 0.1221 0.1079 0.0977 0.0963 0.1042 0.1034 0.0967 0.0895 0.0880 0.0924 0.1029 0.1026 

[TRAIN] Epoch[7](343/1500); Loss: 0.167366; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1775 0.1950 0.1964 0.1888 0.1794 0.1715 0.1656 0.1609 0.1575 0.1555 0.1563 0.1548 0.1545 0.1554 0.1544 0.1542 

[TRAIN] Epoch[7](344/1500); Loss: 0.173176; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2200 0.1977 0.2066 0.2089 0.2007 0.1893 0.1781 0.1707 0.1634 0.1583 0.1534 0.1488 0.1457 0.1445 0.1427 0.1419 

[TRAIN] Epoch[7](345/1500); Loss: 0.147295; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.2216 0.1851 0.1587 0.1824 0.1885 0.1729 0.1554 0.1394 0.1266 0.1201 0.1185 0.1189 0.1180 0.1177 0.1168 0.1161 

[TRAIN] Epoch[7](346/1500); Loss: 0.152316; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2263 0.1829 0.1887 0.1838 0.1742 0.1611 0.1497 0.1418 0.1363 0.1325 0.1295 0.1282 0.1269 0.1247 0.1256 0.1251 

[TRAIN] Epoch[7](347/1500); Loss: 0.115973; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1612 0.1335 0.1283 0.1322 0.1296 0.1215 0.1133 0.1084 0.1059 0.1049 0.1043 0.1033 0.1029 0.1026 0.1021 0.1017 

[TRAIN] Epoch[7](348/1500); Loss: 0.133894; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2364 0.1876 0.1320 0.1671 0.1879 0.1714 0.1505 0.1283 0.1091 0.0966 0.0935 0.0951 0.1009 0.0988 0.0947 0.0922 

[TRAIN] Epoch[7](349/1500); Loss: 0.100872; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1347 0.1190 0.1234 0.1316 0.1357 0.1206 0.1038 0.0882 0.0780 0.0762 0.0839 0.0872 0.0843 0.0805 0.0793 0.0874 

[TRAIN] Epoch[7](350/1500); Loss: 0.136609; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2072 0.1569 0.1847 0.1825 0.1706 0.1506 0.1326 0.1232 0.1149 0.1087 0.1067 0.1077 0.1092 0.1099 0.1105 0.1098 

[TRAIN] Epoch[7](351/1500); Loss: 0.076668; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2193 0.1308 0.0340 0.1037 0.0903 0.0735 0.0497 0.0389 0.0445 0.0734 0.0741 0.0637 0.0515 0.0488 0.0520 0.0784 

[TRAIN] Epoch[7](352/1500); Loss: 0.112881; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1404 0.1445 0.1539 0.1503 0.1366 0.1198 0.1065 0.0992 0.0960 0.0945 0.0943 0.0942 0.0942 0.0935 0.0931 0.0951 

[TRAIN] Epoch[7](353/1500); Loss: 0.076212; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1030 0.1092 0.1047 0.0929 0.0788 0.0699 0.0677 0.0700 0.0670 0.0657 0.0656 0.0654 0.0640 0.0643 0.0662 0.0649 

[TRAIN] Epoch[7](354/1500); Loss: 0.132689; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1767 0.1549 0.1560 0.1526 0.1462 0.1382 0.1318 0.1267 0.1229 0.1204 0.1185 0.1165 0.1149 0.1160 0.1156 0.1151 

[TRAIN] Epoch[7](355/1500); Loss: 0.065681; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1282 0.0859 0.0685 0.0755 0.0692 0.0607 0.0557 0.0550 0.0553 0.0555 0.0543 0.0557 0.0564 0.0576 0.0577 0.0596 

[TRAIN] Epoch[7](356/1500); Loss: 0.126712; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1527 0.1577 0.1628 0.1562 0.1414 0.1266 0.1169 0.1128 0.1124 0.1125 0.1110 0.1097 0.1103 0.1137 0.1146 0.1160 

[TRAIN] Epoch[7](357/1500); Loss: 0.166400; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2155 0.2026 0.2322 0.2238 0.2089 0.1870 0.1672 0.1534 0.1430 0.1357 0.1334 0.1328 0.1323 0.1317 0.1311 0.1318 

[TRAIN] Epoch[7](358/1500); Loss: 0.070785; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1191 0.0792 0.0846 0.0802 0.0727 0.0650 0.0634 0.0612 0.0610 0.0619 0.0635 0.0628 0.0632 0.0642 0.0654 0.0652 

[TRAIN] Epoch[7](359/1500); Loss: 0.103937; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1531 0.0996 0.1140 0.1545 0.1425 0.1252 0.1023 0.0861 0.0792 0.0816 0.0860 0.0881 0.0856 0.0860 0.0884 0.0909 

[TRAIN] Epoch[7](360/1500); Loss: 0.093047; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1697 0.1214 0.0835 0.1144 0.1060 0.0938 0.0803 0.0781 0.0829 0.0825 0.0784 0.0755 0.0808 0.0807 0.0810 0.0797 

[TRAIN] Epoch[7](361/1500); Loss: 0.083543; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0909 0.0941 0.1152 0.1120 0.1031 0.0922 0.0841 0.0767 0.0714 0.0685 0.0739 0.0715 0.0695 0.0690 0.0719 0.0726 

[TRAIN] Epoch[7](362/1500); Loss: 0.090526; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1301 0.0994 0.1089 0.1041 0.0967 0.0872 0.0847 0.0846 0.0833 0.0823 0.0798 0.0810 0.0815 0.0814 0.0822 0.0814 

[TRAIN] Epoch[7](363/1500); Loss: 0.112656; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1908 0.1334 0.1574 0.1584 0.1454 0.1227 0.1022 0.0913 0.0855 0.0850 0.0869 0.0875 0.0873 0.0884 0.0898 0.0905 

[TRAIN] Epoch[7](364/1500); Loss: 0.112458; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1715 0.1235 0.1429 0.1507 0.1397 0.1205 0.1042 0.0965 0.0938 0.0936 0.0922 0.0925 0.0923 0.0946 0.0952 0.0957 

[TRAIN] Epoch[7](365/1500); Loss: 0.147189; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1775 0.1636 0.1808 0.1717 0.1607 0.1479 0.1395 0.1351 0.1333 0.1321 0.1334 0.1329 0.1340 0.1353 0.1375 0.1397 

[TRAIN] Epoch[7](366/1500); Loss: 0.098322; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1438 0.1257 0.1341 0.1240 0.1126 0.1014 0.0894 0.0818 0.0763 0.0775 0.0795 0.0810 0.0828 0.0851 0.0879 0.0901 

[TRAIN] Epoch[7](367/1500); Loss: 0.103184; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1457 0.1289 0.1280 0.1208 0.1119 0.1050 0.0988 0.0946 0.0916 0.0897 0.0891 0.0887 0.0888 0.0892 0.0900 0.0901 

[TRAIN] Epoch[7](368/1500); Loss: 0.137681; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1609 0.1509 0.1532 0.1481 0.1421 0.1357 0.1327 0.1331 0.1323 0.1313 0.1304 0.1310 0.1303 0.1305 0.1302 0.1301 

[TRAIN] Epoch[7](369/1500); Loss: 0.073657; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0508 0.0620 0.1465 0.1321 0.1182 0.0959 0.0735 0.0578 0.0480 0.0478 0.0603 0.0617 0.0573 0.0502 0.0510 0.0653 

[TRAIN] Epoch[7](370/1500); Loss: 0.108909; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1487 0.1247 0.1259 0.1288 0.1212 0.1109 0.1033 0.1003 0.0965 0.0950 0.0952 0.0964 0.0961 0.0976 0.0991 0.1027 

[TRAIN] Epoch[7](371/1500); Loss: 0.107253; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2580 0.1667 0.1895 0.1825 0.1633 0.1333 0.1053 0.0835 0.0650 0.0528 0.0476 0.0499 0.0531 0.0536 0.0551 0.0568 

[TRAIN] Epoch[7](372/1500); Loss: 0.151549; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1806 0.1719 0.1745 0.1761 0.1692 0.1598 0.1519 0.1464 0.1428 0.1398 0.1384 0.1372 0.1359 0.1341 0.1326 0.1336 

[TRAIN] Epoch[7](373/1500); Loss: 0.123800; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1561 0.1274 0.1912 0.1866 0.1730 0.1514 0.1286 0.1133 0.1003 0.0938 0.0905 0.0917 0.0920 0.0937 0.0952 0.0964 

[TRAIN] Epoch[7](374/1500); Loss: 0.121692; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1652 0.1367 0.1242 0.1425 0.1375 0.1291 0.1190 0.1140 0.1119 0.1123 0.1111 0.1095 0.1087 0.1085 0.1092 0.1078 

[TRAIN] Epoch[7](375/1500); Loss: 0.120954; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1306 0.1471 0.1729 0.1723 0.1560 0.1378 0.1216 0.1138 0.1091 0.1031 0.0982 0.0950 0.0932 0.0954 0.0955 0.0937 

[TRAIN] Epoch[7](376/1500); Loss: 0.118160; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1667 0.1308 0.1448 0.1427 0.1363 0.1267 0.1193 0.1142 0.1086 0.1047 0.1021 0.0993 0.0985 0.0987 0.0981 0.0990 

[TRAIN] Epoch[7](377/1500); Loss: 0.085093; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0758 0.1171 0.1485 0.1344 0.1162 0.0957 0.0798 0.0716 0.0670 0.0651 0.0630 0.0647 0.0656 0.0649 0.0658 0.0663 

[TRAIN] Epoch[7](378/1500); Loss: 0.147237; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1510 0.1466 0.1728 0.1688 0.1616 0.1539 0.1479 0.1431 0.1395 0.1375 0.1362 0.1367 0.1378 0.1392 0.1403 0.1430 

[TRAIN] Epoch[7](379/1500); Loss: 0.087008; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1142 0.1266 0.1207 0.1096 0.0971 0.0862 0.0792 0.0742 0.0719 0.0726 0.0727 0.0723 0.0731 0.0734 0.0736 0.0749 

[TRAIN] Epoch[7](380/1500); Loss: 0.182100; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3423 0.2346 0.2723 0.2782 0.2648 0.2382 0.2091 0.1884 0.1636 0.1406 0.1214 0.1052 0.0932 0.0869 0.0858 0.0889 

[TRAIN] Epoch[7](381/1500); Loss: 0.163861; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2268 0.1801 0.2355 0.2453 0.2328 0.2125 0.1895 0.1706 0.1528 0.1380 0.1265 0.1169 0.1082 0.0999 0.0945 0.0919 

[TRAIN] Epoch[7](382/1500); Loss: 0.092473; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1057 0.0894 0.0982 0.1022 0.0976 0.0924 0.0893 0.0871 0.0874 0.0865 0.0877 0.0889 0.0902 0.0910 0.0924 0.0935 

[TRAIN] Epoch[7](383/1500); Loss: 0.136975; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1817 0.1705 0.1405 0.1445 0.1598 0.1524 0.1433 0.1340 0.1269 0.1231 0.1223 0.1207 0.1191 0.1167 0.1166 0.1193 

[TRAIN] Epoch[7](384/1500); Loss: 0.164326; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2020 0.1768 0.2077 0.2114 0.2025 0.1889 0.1758 0.1644 0.1536 0.1456 0.1395 0.1356 0.1324 0.1320 0.1301 0.1311 

[TRAIN] Epoch[7](385/1500); Loss: 0.172640; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2203 0.1987 0.2089 0.2052 0.1980 0.1881 0.1779 0.1705 0.1635 0.1557 0.1503 0.1474 0.1442 0.1441 0.1448 0.1447 

[TRAIN] Epoch[7](386/1500); Loss: 0.190303; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2904 0.2341 0.2543 0.2491 0.2390 0.2228 0.2062 0.1935 0.1810 0.1694 0.1576 0.1473 0.1373 0.1290 0.1201 0.1137 

[TRAIN] Epoch[7](387/1500); Loss: 0.132426; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1604 0.1442 0.1551 0.1628 0.1543 0.1428 0.1318 0.1242 0.1205 0.1199 0.1180 0.1179 0.1162 0.1165 0.1163 0.1178 

[TRAIN] Epoch[7](388/1500); Loss: 0.093671; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0952 0.1092 0.1246 0.1194 0.1115 0.1018 0.0938 0.0881 0.0846 0.0823 0.0818 0.0813 0.0815 0.0814 0.0811 0.0811 

[TRAIN] Epoch[7](389/1500); Loss: 0.187296; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2018 0.2053 0.2187 0.2134 0.2046 0.1945 0.1864 0.1813 0.1780 0.1749 0.1734 0.1729 0.1722 0.1730 0.1730 0.1733 

[TRAIN] Epoch[7](390/1500); Loss: 0.090726; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1293 0.1454 0.1351 0.1211 0.1050 0.0894 0.0776 0.0719 0.0713 0.0706 0.0707 0.0708 0.0726 0.0726 0.0738 0.0743 

[TRAIN] Epoch[7](391/1500); Loss: 0.089447; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1103 0.1221 0.1204 0.1110 0.1002 0.0901 0.0828 0.0793 0.0778 0.0767 0.0762 0.0761 0.0766 0.0769 0.0771 0.0777 

[TRAIN] Epoch[7](392/1500); Loss: 0.132313; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1510 0.1595 0.1697 0.1683 0.1589 0.1477 0.1386 0.1305 0.1232 0.1171 0.1143 0.1109 0.1085 0.1071 0.1062 0.1055 

[TRAIN] Epoch[7](393/1500); Loss: 0.182129; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2043 0.1982 0.2170 0.2262 0.2250 0.2128 0.1991 0.1865 0.1754 0.1665 0.1591 0.1536 0.1509 0.1475 0.1464 0.1455 

[TRAIN] Epoch[7](394/1500); Loss: 0.161922; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2989 0.2107 0.2403 0.2381 0.2274 0.2082 0.1865 0.1676 0.1473 0.1255 0.1078 0.0945 0.0855 0.0808 0.0830 0.0887 

[TRAIN] Epoch[7](395/1500); Loss: 0.161768; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1641 0.1604 0.2157 0.2199 0.2094 0.1935 0.1767 0.1623 0.1502 0.1413 0.1375 0.1360 0.1355 0.1315 0.1280 0.1262 

[TRAIN] Epoch[7](396/1500); Loss: 0.116686; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1434 0.1255 0.1291 0.1274 0.1230 0.1174 0.1139 0.1115 0.1101 0.1091 0.1092 0.1083 0.1088 0.1095 0.1103 0.1105 

[TRAIN] Epoch[7](397/1500); Loss: 0.126811; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2225 0.1376 0.0798 0.1889 0.1921 0.1812 0.1630 0.1414 0.1206 0.0989 0.0798 0.0685 0.0661 0.0948 0.1015 0.0923 

[TRAIN] Epoch[7](398/1500); Loss: 0.086753; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1025 0.1115 0.1250 0.1230 0.1116 0.0979 0.0859 0.0773 0.0719 0.0686 0.0685 0.0681 0.0688 0.0686 0.0694 0.0695 

[TRAIN] Epoch[7](399/1500); Loss: 0.129378; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1563 0.1256 0.1494 0.1672 0.1607 0.1505 0.1392 0.1296 0.1217 0.1153 0.1120 0.1102 0.1089 0.1081 0.1073 0.1081 

[TRAIN] Epoch[7](400/1500); Loss: 0.099474; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1296 0.1072 0.1210 0.1254 0.1184 0.1092 0.1009 0.0936 0.0899 0.0885 0.0863 0.0857 0.0841 0.0840 0.0838 0.0839 

[TRAIN] Epoch[7](401/1500); Loss: 0.160230; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1321 0.1111 0.1822 0.2271 0.2212 0.2095 0.1946 0.1796 0.1654 0.1530 0.1429 0.1351 0.1298 0.1270 0.1263 0.1267 

[TRAIN] Epoch[7](402/1500); Loss: 0.057228; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0803 0.0617 0.0600 0.0584 0.0529 0.0491 0.0498 0.0522 0.0524 0.0522 0.0537 0.0548 0.0585 0.0587 0.0601 0.0607 

[TRAIN] Epoch[7](403/1500); Loss: 0.083187; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.0896 0.0996 0.1013 0.1109 0.1063 0.0968 0.0874 0.0812 0.0760 0.0723 0.0701 0.0671 0.0675 0.0676 0.0686 0.0685 

[TRAIN] Epoch[7](404/1500); Loss: 0.139519; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1581 0.1555 0.1698 0.1646 0.1559 0.1455 0.1375 0.1329 0.1295 0.1279 0.1269 0.1257 0.1257 0.1259 0.1258 0.1251 

[TRAIN] Epoch[7](405/1500); Loss: 0.102859; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1364 0.1248 0.1360 0.1319 0.1227 0.1115 0.1019 0.0965 0.0919 0.0873 0.0859 0.0848 0.0853 0.0842 0.0830 0.0818 

[TRAIN] Epoch[7](406/1500); Loss: 0.090918; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.0957 0.1077 0.1160 0.1114 0.1035 0.0948 0.0871 0.0824 0.0809 0.0818 0.0821 0.0817 0.0811 0.0826 0.0828 0.0832 

[TRAIN] Epoch[7](407/1500); Loss: 0.091038; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1209 0.0938 0.1007 0.1305 0.1286 0.1186 0.1051 0.0925 0.0824 0.0761 0.0712 0.0685 0.0670 0.0672 0.0663 0.0669 

[TRAIN] Epoch[7](408/1500); Loss: 0.132290; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.1030 0.1621 0.2099 0.2006 0.1869 0.1694 0.1523 0.1368 0.1226 0.1107 0.1011 0.0949 0.0921 0.0908 0.0904 0.0930 

[TRAIN] Epoch[7](409/1500); Loss: 0.145045; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1952 0.1574 0.1619 0.1565 0.1517 0.1453 0.1410 0.1371 0.1348 0.1328 0.1319 0.1322 0.1334 0.1348 0.1365 0.1383 

[TRAIN] Epoch[7](410/1500); Loss: 0.171022; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2306 0.1952 0.2073 0.2024 0.1944 0.1829 0.1729 0.1647 0.1564 0.1503 0.1475 0.1467 0.1472 0.1467 0.1463 0.1448 

[TRAIN] Epoch[7](411/1500); Loss: 0.162618; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1686 0.1492 0.1730 0.2175 0.2235 0.2101 0.1920 0.1734 0.1590 0.1482 0.1402 0.1342 0.1301 0.1277 0.1272 0.1279 

[TRAIN] Epoch[7](412/1500); Loss: 0.105622; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1469 0.1074 0.1221 0.1212 0.1146 0.1064 0.1014 0.0978 0.0966 0.0959 0.0958 0.0956 0.0959 0.0971 0.0975 0.0978 

[TRAIN] Epoch[7](413/1500); Loss: 0.072195; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1414 0.1011 0.1007 0.1076 0.0965 0.0817 0.0674 0.0573 0.0538 0.0497 0.0499 0.0487 0.0493 0.0497 0.0492 0.0511 

[TRAIN] Epoch[7](414/1500); Loss: 0.105936; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1815 0.1512 0.1560 0.1476 0.1353 0.1203 0.1071 0.0947 0.0839 0.0784 0.0747 0.0735 0.0720 0.0716 0.0736 0.0736 

[TRAIN] Epoch[7](415/1500); Loss: 0.173224; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2049 0.1895 0.2074 0.2054 0.1975 0.1863 0.1764 0.1690 0.1637 0.1609 0.1566 0.1541 0.1518 0.1504 0.1495 0.1482 

[TRAIN] Epoch[7](416/1500); Loss: 0.127106; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1392 0.1431 0.1474 0.1455 0.1404 0.1341 0.1282 0.1237 0.1205 0.1183 0.1169 0.1157 0.1150 0.1145 0.1154 0.1155 

[TRAIN] Epoch[7](417/1500); Loss: 0.165024; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1815 0.1747 0.1912 0.1998 0.1945 0.1838 0.1735 0.1649 0.1579 0.1524 0.1487 0.1455 0.1443 0.1428 0.1433 0.1417 

[TRAIN] Epoch[7](418/1500); Loss: 0.166994; Backpropagation: 0.0917 sec; Batch: 0.4286 sec
0.2151 0.1915 0.2109 0.2075 0.1995 0.1858 0.1728 0.1627 0.1544 0.1469 0.1413 0.1390 0.1366 0.1354 0.1358 0.1368 

[TRAIN] Epoch[7](419/1500); Loss: 0.161412; Backpropagation: 0.0919 sec; Batch: 0.4259 sec
0.2100 0.1805 0.2188 0.2122 0.1992 0.1800 0.1612 0.1473 0.1374 0.1327 0.1322 0.1326 0.1347 0.1349 0.1345 0.1344 

[TRAIN] Epoch[7](420/1500); Loss: 0.125573; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2237 0.1416 0.0827 0.1856 0.1838 0.1732 0.1543 0.1317 0.1104 0.0893 0.0749 0.0722 0.0834 0.1046 0.1041 0.0937 

[TRAIN] Epoch[7](421/1500); Loss: 0.155823; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2166 0.1896 0.1962 0.1918 0.1825 0.1711 0.1610 0.1516 0.1445 0.1373 0.1313 0.1266 0.1234 0.1223 0.1228 0.1248 

[TRAIN] Epoch[7](422/1500); Loss: 0.146590; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1865 0.1680 0.1714 0.1662 0.1590 0.1510 0.1444 0.1418 0.1387 0.1365 0.1337 0.1323 0.1307 0.1294 0.1281 0.1278 

[TRAIN] Epoch[7](423/1500); Loss: 0.079967; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.0992 0.1003 0.1056 0.1029 0.0934 0.0823 0.0736 0.0688 0.0680 0.0674 0.0682 0.0681 0.0691 0.0710 0.0706 0.0709 

[TRAIN] Epoch[7](424/1500); Loss: 0.145889; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1843 0.1661 0.1697 0.1644 0.1571 0.1494 0.1440 0.1411 0.1388 0.1362 0.1346 0.1329 0.1301 0.1291 0.1284 0.1280 

[TRAIN] Epoch[7](425/1500); Loss: 0.129961; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1536 0.1507 0.1550 0.1557 0.1499 0.1408 0.1335 0.1273 0.1203 0.1167 0.1151 0.1146 0.1117 0.1113 0.1111 0.1120 

[TRAIN] Epoch[7](426/1500); Loss: 0.117034; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0880 0.0757 0.1808 0.2137 0.2035 0.1864 0.1644 0.1416 0.1182 0.0962 0.0777 0.0649 0.0594 0.0611 0.0673 0.0737 

[TRAIN] Epoch[7](427/1500); Loss: 0.137338; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1480 0.1719 0.2181 0.2056 0.1890 0.1660 0.1440 0.1259 0.1130 0.1058 0.1025 0.1024 0.1017 0.1014 0.1009 0.1010 

[TRAIN] Epoch[7](428/1500); Loss: 0.082554; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1033 0.1025 0.1106 0.1097 0.1015 0.0922 0.0832 0.0759 0.0703 0.0668 0.0653 0.0655 0.0659 0.0676 0.0696 0.0710 

[TRAIN] Epoch[7](429/1500); Loss: 0.222446; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.3515 0.2826 0.2894 0.2814 0.2686 0.2461 0.2228 0.2003 0.1830 0.1749 0.1730 0.1773 0.1740 0.1773 0.1781 0.1789 

[TRAIN] Epoch[7](430/1500); Loss: 0.068968; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.0782 0.0761 0.0716 0.0696 0.0691 0.0670 0.0657 0.0652 0.0646 0.0648 0.0649 0.0665 0.0670 0.0695 0.0712 0.0725 

[TRAIN] Epoch[7](431/1500); Loss: 0.155913; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1846 0.1757 0.1842 0.1837 0.1751 0.1650 0.1568 0.1493 0.1448 0.1428 0.1393 0.1379 0.1383 0.1395 0.1388 0.1391 

[TRAIN] Epoch[7](432/1500); Loss: 0.113424; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1664 0.1159 0.1472 0.1716 0.1611 0.1456 0.1243 0.1040 0.0896 0.0838 0.0834 0.0830 0.0844 0.0843 0.0847 0.0854 

[TRAIN] Epoch[7](433/1500); Loss: 0.114935; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1337 0.1115 0.1379 0.1510 0.1436 0.1316 0.1179 0.1073 0.1016 0.1001 0.1003 0.0999 0.0998 0.0993 0.1016 0.1020 

[TRAIN] Epoch[7](434/1500); Loss: 0.145664; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1643 0.1595 0.1657 0.1621 0.1564 0.1503 0.1443 0.1419 0.1403 0.1383 0.1373 0.1354 0.1343 0.1339 0.1334 0.1330 

[TRAIN] Epoch[7](435/1500); Loss: 0.161295; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1867 0.1694 0.2009 0.1963 0.1871 0.1726 0.1602 0.1516 0.1465 0.1450 0.1441 0.1419 0.1436 0.1447 0.1459 0.1442 

[TRAIN] Epoch[7](436/1500); Loss: 0.165441; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2228 0.1907 0.1724 0.1776 0.2036 0.2026 0.1901 0.1742 0.1586 0.1465 0.1394 0.1356 0.1344 0.1337 0.1328 0.1321 

[TRAIN] Epoch[7](437/1500); Loss: 0.133303; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1199 0.0812 0.2022 0.2096 0.1997 0.1837 0.1655 0.1475 0.1296 0.1134 0.1012 0.0942 0.0919 0.0931 0.0970 0.1031 

[TRAIN] Epoch[7](438/1500); Loss: 0.161348; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1846 0.1878 0.1997 0.1995 0.1890 0.1760 0.1640 0.1558 0.1496 0.1454 0.1428 0.1400 0.1382 0.1369 0.1363 0.1359 

[TRAIN] Epoch[7](439/1500); Loss: 0.135348; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1584 0.1626 0.1682 0.1692 0.1637 0.1514 0.1403 0.1314 0.1231 0.1186 0.1165 0.1145 0.1130 0.1127 0.1110 0.1109 

[TRAIN] Epoch[7](440/1500); Loss: 0.133507; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1211 0.0944 0.1352 0.1653 0.1643 0.1581 0.1516 0.1445 0.1372 0.1304 0.1249 0.1215 0.1200 0.1204 0.1221 0.1253 

[TRAIN] Epoch[7](441/1500); Loss: 0.192264; Backpropagation: 0.0924 sec; Batch: 0.4240 sec
0.1301 0.1683 0.2964 0.2906 0.2780 0.2584 0.2365 0.2155 0.1939 0.1740 0.1568 0.1439 0.1357 0.1314 0.1349 0.1319 

[TRAIN] Epoch[7](442/1500); Loss: 0.145228; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1860 0.1748 0.1591 0.1599 0.1653 0.1568 0.1465 0.1377 0.1331 0.1311 0.1308 0.1285 0.1282 0.1275 0.1287 0.1296 

[TRAIN] Epoch[7](443/1500); Loss: 0.089412; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1409 0.1215 0.1223 0.1143 0.1030 0.0911 0.0829 0.0772 0.0750 0.0739 0.0718 0.0707 0.0709 0.0716 0.0717 0.0718 

[TRAIN] Epoch[7](444/1500); Loss: 0.163820; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1769 0.1830 0.2051 0.2023 0.1918 0.1787 0.1675 0.1594 0.1532 0.1481 0.1452 0.1442 0.1432 0.1411 0.1408 0.1405 

[TRAIN] Epoch[7](445/1500); Loss: 0.165060; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2306 0.1864 0.2250 0.2198 0.2086 0.1908 0.1736 0.1606 0.1474 0.1394 0.1326 0.1297 0.1276 0.1236 0.1224 0.1229 

[TRAIN] Epoch[7](446/1500); Loss: 0.076655; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1512 0.0908 0.0948 0.0891 0.0797 0.0713 0.0667 0.0651 0.0633 0.0639 0.0639 0.0649 0.0644 0.0648 0.0657 0.0669 

[TRAIN] Epoch[7](447/1500); Loss: 0.092863; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0982 0.1036 0.1168 0.1159 0.1100 0.1004 0.0917 0.0865 0.0844 0.0827 0.0821 0.0821 0.0820 0.0826 0.0831 0.0837 

[TRAIN] Epoch[7](448/1500); Loss: 0.140354; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1895 0.1740 0.2061 0.2088 0.1942 0.1746 0.1545 0.1370 0.1217 0.1092 0.1011 0.0954 0.0930 0.0927 0.0964 0.0975 

[TRAIN] Epoch[7](449/1500); Loss: 0.169564; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1728 0.1670 0.2114 0.2228 0.2126 0.1980 0.1821 0.1683 0.1579 0.1516 0.1489 0.1477 0.1457 0.1434 0.1414 0.1414 

[TRAIN] Epoch[7](450/1500); Loss: 0.138699; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1260 0.1535 0.2031 0.1982 0.1871 0.1720 0.1568 0.1422 0.1297 0.1191 0.1108 0.1056 0.1038 0.1037 0.1039 0.1036 

[TRAIN] Epoch[7](451/1500); Loss: 0.142066; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1356 0.1411 0.2028 0.2048 0.1932 0.1752 0.1560 0.1391 0.1268 0.1207 0.1190 0.1168 0.1129 0.1100 0.1082 0.1108 

[TRAIN] Epoch[7](452/1500); Loss: 0.072906; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0886 0.1090 0.1016 0.0909 0.0788 0.0686 0.0631 0.0636 0.0648 0.0630 0.0610 0.0608 0.0644 0.0642 0.0627 0.0616 

[TRAIN] Epoch[7](453/1500); Loss: 0.107897; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1250 0.1125 0.1326 0.1285 0.1205 0.1112 0.1043 0.1005 0.0987 0.0991 0.0976 0.0982 0.0988 0.0998 0.0992 0.1000 

[TRAIN] Epoch[7](454/1500); Loss: 0.147496; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1696 0.1693 0.1887 0.1873 0.1769 0.1634 0.1507 0.1410 0.1347 0.1306 0.1275 0.1254 0.1239 0.1239 0.1238 0.1231 

[TRAIN] Epoch[7](455/1500); Loss: 0.174655; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2200 0.2077 0.2146 0.2193 0.2238 0.2098 0.1943 0.1786 0.1659 0.1550 0.1468 0.1403 0.1350 0.1301 0.1272 0.1263 

[TRAIN] Epoch[7](456/1500); Loss: 0.118134; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1158 0.1130 0.1657 0.1862 0.1724 0.1529 0.1297 0.1105 0.0977 0.0912 0.0888 0.0894 0.0913 0.0942 0.0949 0.0965 

[TRAIN] Epoch[7](457/1500); Loss: 0.143197; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1515 0.1534 0.1739 0.1696 0.1607 0.1495 0.1409 0.1365 0.1346 0.1335 0.1318 0.1308 0.1309 0.1308 0.1315 0.1312 

[TRAIN] Epoch[7](458/1500); Loss: 0.181519; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2080 0.2111 0.2163 0.2086 0.1983 0.1875 0.1799 0.1745 0.1713 0.1686 0.1656 0.1643 0.1653 0.1631 0.1610 0.1607 

[TRAIN] Epoch[7](459/1500); Loss: 0.088602; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1322 0.1155 0.1127 0.1035 0.0922 0.0809 0.0761 0.0717 0.0723 0.0738 0.0752 0.0777 0.0794 0.0816 0.0838 0.0889 

[TRAIN] Epoch[7](460/1500); Loss: 0.116372; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1305 0.1242 0.1204 0.1177 0.1154 0.1128 0.1108 0.1111 0.1121 0.1133 0.1136 0.1138 0.1152 0.1162 0.1171 0.1179 

[TRAIN] Epoch[7](461/1500); Loss: 0.156020; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2691 0.2003 0.2136 0.2034 0.1876 0.1662 0.1480 0.1343 0.1257 0.1219 0.1210 0.1224 0.1215 0.1208 0.1209 0.1195 

[TRAIN] Epoch[7](462/1500); Loss: 0.189839; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.3364 0.2725 0.2819 0.2680 0.2474 0.2208 0.1951 0.1683 0.1426 0.1254 0.1218 0.1306 0.1304 0.1328 0.1325 0.1309 

[TRAIN] Epoch[7](463/1500); Loss: 0.061986; Backpropagation: 0.0919 sec; Batch: 0.4228 sec
0.0708 0.0792 0.0653 0.0630 0.0575 0.0562 0.0553 0.0548 0.0542 0.0562 0.0591 0.0617 0.0611 0.0633 0.0657 0.0684 

[TRAIN] Epoch[7](464/1500); Loss: 0.121204; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1679 0.1322 0.1443 0.1427 0.1324 0.1233 0.1172 0.1118 0.1101 0.1098 0.1076 0.1075 0.1074 0.1091 0.1077 0.1082 

[TRAIN] Epoch[7](465/1500); Loss: 0.192860; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1826 0.1972 0.2280 0.2275 0.2190 0.2088 0.1992 0.1905 0.1835 0.1786 0.1758 0.1751 0.1761 0.1782 0.1810 0.1847 

[TRAIN] Epoch[7](466/1500); Loss: 0.104182; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1035 0.1037 0.1505 0.1719 0.1578 0.1400 0.1202 0.1019 0.0868 0.0763 0.0721 0.0737 0.0762 0.0774 0.0766 0.0784 

[TRAIN] Epoch[7](467/1500); Loss: 0.129686; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1670 0.1465 0.1733 0.1647 0.1538 0.1390 0.1261 0.1177 0.1135 0.1119 0.1106 0.1107 0.1108 0.1104 0.1097 0.1092 

[TRAIN] Epoch[7](468/1500); Loss: 0.124794; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1478 0.1295 0.1383 0.1396 0.1337 0.1265 0.1240 0.1221 0.1199 0.1172 0.1146 0.1149 0.1175 0.1175 0.1169 0.1166 

[TRAIN] Epoch[7](469/1500); Loss: 0.144448; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1393 0.1620 0.2015 0.1932 0.1793 0.1623 0.1474 0.1364 0.1279 0.1251 0.1245 0.1238 0.1227 0.1223 0.1212 0.1224 

[TRAIN] Epoch[7](470/1500); Loss: 0.099235; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1795 0.1333 0.1401 0.1316 0.1175 0.0992 0.0857 0.0788 0.0786 0.0760 0.0774 0.0768 0.0780 0.0776 0.0782 0.0795 

[TRAIN] Epoch[7](471/1500); Loss: 0.140932; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2109 0.1815 0.2082 0.1944 0.1755 0.1507 0.1294 0.1138 0.1073 0.1096 0.1116 0.1116 0.1112 0.1103 0.1143 0.1146 

[TRAIN] Epoch[7](472/1500); Loss: 0.120661; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1748 0.1394 0.1338 0.1458 0.1331 0.1179 0.1053 0.1054 0.1050 0.1082 0.1053 0.1068 0.1095 0.1119 0.1141 0.1143 

[TRAIN] Epoch[7](473/1500); Loss: 0.136596; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1509 0.1294 0.1606 0.1633 0.1532 0.1406 0.1321 0.1291 0.1306 0.1313 0.1278 0.1269 0.1276 0.1274 0.1281 0.1267 

[TRAIN] Epoch[7](474/1500); Loss: 0.088188; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1419 0.1376 0.1224 0.1060 0.0873 0.0729 0.0699 0.0735 0.0727 0.0716 0.0736 0.0764 0.0742 0.0745 0.0778 0.0786 

[TRAIN] Epoch[7](475/1500); Loss: 0.158761; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1879 0.1748 0.1911 0.1906 0.1795 0.1662 0.1555 0.1495 0.1473 0.1463 0.1447 0.1432 0.1417 0.1422 0.1399 0.1398 

[TRAIN] Epoch[7](476/1500); Loss: 0.130533; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1706 0.1457 0.1508 0.1459 0.1383 0.1319 0.1288 0.1260 0.1240 0.1205 0.1199 0.1178 0.1172 0.1166 0.1173 0.1173 

[TRAIN] Epoch[7](477/1500); Loss: 0.134736; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1636 0.1643 0.1742 0.1697 0.1579 0.1440 0.1331 0.1253 0.1201 0.1176 0.1160 0.1155 0.1139 0.1144 0.1130 0.1131 

[TRAIN] Epoch[7](478/1500); Loss: 0.185500; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2160 0.2068 0.2078 0.2110 0.2058 0.1964 0.1882 0.1821 0.1783 0.1756 0.1709 0.1694 0.1665 0.1653 0.1644 0.1635 

[TRAIN] Epoch[7](479/1500); Loss: 0.162781; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1775 0.1653 0.1729 0.1750 0.1718 0.1668 0.1621 0.1590 0.1578 0.1570 0.1563 0.1559 0.1560 0.1563 0.1573 0.1575 

[TRAIN] Epoch[7](480/1500); Loss: 0.072594; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0667 0.1090 0.0965 0.0825 0.0669 0.0566 0.0555 0.0609 0.0650 0.0652 0.0651 0.0675 0.0729 0.0751 0.0778 0.0785 

[TRAIN] Epoch[7](481/1500); Loss: 0.128730; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1618 0.1857 0.2010 0.1839 0.1616 0.1372 0.1193 0.1091 0.1029 0.1000 0.1013 0.0989 0.0983 0.0976 0.0996 0.1015 

[TRAIN] Epoch[7](482/1500); Loss: 0.101926; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1484 0.1401 0.1293 0.1249 0.1185 0.1076 0.0978 0.0930 0.0888 0.0864 0.0845 0.0831 0.0828 0.0824 0.0817 0.0816 

[TRAIN] Epoch[7](483/1500); Loss: 0.070429; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0618 0.0908 0.1005 0.0875 0.0747 0.0664 0.0644 0.0641 0.0626 0.0611 0.0626 0.0650 0.0664 0.0655 0.0657 0.0676 

[TRAIN] Epoch[7](484/1500); Loss: 0.122821; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1433 0.1342 0.1550 0.1570 0.1482 0.1351 0.1229 0.1140 0.1098 0.1090 0.1074 0.1065 0.1045 0.1060 0.1065 0.1058 

[TRAIN] Epoch[7](485/1500); Loss: 0.121298; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1724 0.1442 0.1419 0.1403 0.1357 0.1273 0.1192 0.1123 0.1079 0.1054 0.1055 0.1059 0.1064 0.1052 0.1051 0.1061 

[TRAIN] Epoch[7](486/1500); Loss: 0.160985; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2224 0.2069 0.2275 0.2170 0.2008 0.1796 0.1610 0.1486 0.1397 0.1354 0.1267 0.1231 0.1207 0.1221 0.1229 0.1215 

[TRAIN] Epoch[7](487/1500); Loss: 0.143711; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1687 0.0551 0.1490 0.2603 0.2484 0.2323 0.2076 0.1754 0.1424 0.1075 0.0811 0.0698 0.0733 0.1022 0.1162 0.1100 

[TRAIN] Epoch[7](488/1500); Loss: 0.158970; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2864 0.2212 0.2292 0.2120 0.1860 0.1569 0.1364 0.1263 0.1176 0.1207 0.1207 0.1245 0.1232 0.1248 0.1273 0.1302 

[TRAIN] Epoch[7](489/1500); Loss: 0.134838; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1571 0.1416 0.1595 0.1584 0.1480 0.1360 0.1283 0.1259 0.1283 0.1241 0.1223 0.1244 0.1263 0.1279 0.1244 0.1248 

[TRAIN] Epoch[7](490/1500); Loss: 0.156879; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2645 0.2161 0.2232 0.2145 0.2004 0.1813 0.1641 0.1491 0.1348 0.1219 0.1114 0.1061 0.1047 0.1060 0.1055 0.1066 

[TRAIN] Epoch[7](491/1500); Loss: 0.155452; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1889 0.1616 0.1710 0.1691 0.1618 0.1561 0.1527 0.1503 0.1487 0.1484 0.1464 0.1456 0.1465 0.1462 0.1463 0.1474 

[TRAIN] Epoch[7](492/1500); Loss: 0.077736; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0748 0.0969 0.0999 0.0947 0.0843 0.0799 0.0748 0.0705 0.0681 0.0663 0.0702 0.0727 0.0704 0.0709 0.0735 0.0758 

[TRAIN] Epoch[7](493/1500); Loss: 0.102501; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1415 0.1623 0.1544 0.1422 0.1260 0.1092 0.0963 0.0864 0.0798 0.0752 0.0750 0.0763 0.0777 0.0787 0.0788 0.0801 

[TRAIN] Epoch[7](494/1500); Loss: 0.170444; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1808 0.1768 0.1859 0.1835 0.1789 0.1734 0.1690 0.1664 0.1647 0.1642 0.1638 0.1637 0.1637 0.1637 0.1641 0.1646 

[TRAIN] Epoch[7](495/1500); Loss: 0.156953; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1768 0.1677 0.1768 0.1723 0.1672 0.1615 0.1565 0.1532 0.1530 0.1468 0.1461 0.1462 0.1479 0.1455 0.1463 0.1474 

[TRAIN] Epoch[7](496/1500); Loss: 0.124140; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1219 0.1356 0.1916 0.1843 0.1688 0.1490 0.1291 0.1114 0.1010 0.0982 0.0986 0.0988 0.0992 0.0975 0.0990 0.1021 

[TRAIN] Epoch[7](497/1500); Loss: 0.156276; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1417 0.1487 0.2399 0.2441 0.2265 0.2029 0.1772 0.1542 0.1341 0.1206 0.1154 0.1178 0.1230 0.1210 0.1187 0.1145 

[TRAIN] Epoch[7](498/1500); Loss: 0.164206; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2192 0.2004 0.1948 0.1858 0.1763 0.1666 0.1601 0.1546 0.1509 0.1481 0.1467 0.1462 0.1447 0.1444 0.1449 0.1437 

[TRAIN] Epoch[7](499/1500); Loss: 0.134470; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3182 0.2159 0.2404 0.2228 0.1966 0.1572 0.1217 0.0908 0.0703 0.0678 0.0735 0.0740 0.0749 0.0722 0.0747 0.0804 

[TRAIN] Epoch[7](500/1500); Loss: 0.116269; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1697 0.1708 0.1577 0.1445 0.1280 0.1105 0.0985 0.0930 0.0933 0.0959 0.0962 0.0967 0.0987 0.1015 0.1027 0.1025 

[TRAIN] Epoch[7](501/1500); Loss: 0.118462; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2038 0.1661 0.1393 0.1225 0.1311 0.1296 0.1191 0.1081 0.1006 0.0969 0.0975 0.0971 0.0964 0.0954 0.0965 0.0954 

[TRAIN] Epoch[7](502/1500); Loss: 0.114566; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1397 0.1202 0.1263 0.1214 0.1148 0.1124 0.1100 0.1095 0.1085 0.1091 0.1084 0.1088 0.1095 0.1104 0.1118 0.1121 

[TRAIN] Epoch[7](503/1500); Loss: 0.109729; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.1636 0.1305 0.1309 0.1241 0.1145 0.1097 0.1023 0.0998 0.0975 0.0966 0.0971 0.0976 0.0964 0.0976 0.0989 0.0985 

[TRAIN] Epoch[7](504/1500); Loss: 0.148280; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2188 0.1790 0.1498 0.1774 0.1733 0.1601 0.1450 0.1352 0.1319 0.1294 0.1302 0.1278 0.1275 0.1290 0.1296 0.1283 

[TRAIN] Epoch[7](505/1500); Loss: 0.099892; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1148 0.1084 0.1072 0.1058 0.1012 0.0976 0.0962 0.0957 0.0960 0.0965 0.0965 0.0961 0.0960 0.0969 0.0966 0.0968 

[TRAIN] Epoch[7](506/1500); Loss: 0.094336; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1089 0.1033 0.1015 0.0996 0.0953 0.0931 0.0916 0.0904 0.0895 0.0909 0.0909 0.0902 0.0898 0.0914 0.0915 0.0915 

[TRAIN] Epoch[7](507/1500); Loss: 0.071190; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0541 0.0697 0.0976 0.0870 0.0794 0.0767 0.0694 0.0645 0.0619 0.0634 0.0691 0.0701 0.0681 0.0669 0.0695 0.0717 

[TRAIN] Epoch[7](508/1500); Loss: 0.090238; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1580 0.1260 0.1247 0.1173 0.1080 0.0923 0.0791 0.0706 0.0688 0.0708 0.0698 0.0696 0.0718 0.0722 0.0720 0.0729 

[TRAIN] Epoch[7](509/1500); Loss: 0.089195; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2371 0.1499 0.1586 0.1408 0.1109 0.0721 0.0512 0.0514 0.0570 0.0558 0.0531 0.0553 0.0574 0.0579 0.0565 0.0621 

[TRAIN] Epoch[7](510/1500); Loss: 0.067877; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.0972 0.0794 0.0759 0.0701 0.0652 0.0627 0.0612 0.0603 0.0601 0.0610 0.0617 0.0628 0.0645 0.0655 0.0675 0.0709 

[TRAIN] Epoch[7](511/1500); Loss: 0.068931; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1352 0.0942 0.0896 0.0781 0.0628 0.0575 0.0520 0.0558 0.0540 0.0592 0.0561 0.0574 0.0607 0.0620 0.0633 0.0652 

[TRAIN] Epoch[7](512/1500); Loss: 0.087763; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.2202 0.1523 0.1490 0.1320 0.1035 0.0736 0.0568 0.0531 0.0541 0.0530 0.0551 0.0558 0.0580 0.0603 0.0624 0.0650 

[TRAIN] Epoch[7](513/1500); Loss: 0.082735; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1511 0.1201 0.1014 0.0699 0.0605 0.0668 0.0678 0.0679 0.0687 0.0707 0.0739 0.0768 0.0775 0.0806 0.0843 0.0858 

[TRAIN] Epoch[7](514/1500); Loss: 0.157316; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2022 0.1771 0.1705 0.1659 0.1613 0.1560 0.1518 0.1499 0.1481 0.1476 0.1481 0.1473 0.1484 0.1464 0.1480 0.1484 

[TRAIN] Epoch[7](515/1500); Loss: 0.072674; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.0870 0.0750 0.0715 0.0675 0.0630 0.0640 0.0644 0.0655 0.0676 0.0698 0.0728 0.0752 0.0767 0.0780 0.0813 0.0834 

[TRAIN] Epoch[7](516/1500); Loss: 0.063577; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.0731 0.0842 0.0654 0.0583 0.0556 0.0549 0.0555 0.0561 0.0573 0.0600 0.0605 0.0617 0.0653 0.0665 0.0689 0.0737 

[TRAIN] Epoch[7](517/1500); Loss: 0.147958; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2192 0.1867 0.1796 0.1646 0.1508 0.1399 0.1317 0.1323 0.1294 0.1312 0.1313 0.1337 0.1337 0.1327 0.1349 0.1354 

[TRAIN] Epoch[7](518/1500); Loss: 0.080762; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0910 0.0811 0.0983 0.0866 0.0754 0.0742 0.0757 0.0760 0.0737 0.0742 0.0765 0.0785 0.0789 0.0827 0.0832 0.0861 

[TRAIN] Epoch[7](519/1500); Loss: 0.110708; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1170 0.1152 0.1106 0.1069 0.1054 0.1045 0.1056 0.1056 0.1082 0.1082 0.1095 0.1121 0.1128 0.1139 0.1171 0.1187 

[TRAIN] Epoch[7](520/1500); Loss: 0.124188; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1340 0.1332 0.1308 0.1243 0.1203 0.1191 0.1171 0.1185 0.1177 0.1213 0.1199 0.1221 0.1240 0.1258 0.1287 0.1305 

[TRAIN] Epoch[7](521/1500); Loss: 0.176039; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2477 0.2067 0.2022 0.1961 0.1706 0.1567 0.1542 0.1635 0.1533 0.1574 0.1650 0.1624 0.1661 0.1719 0.1708 0.1722 

[TRAIN] Epoch[7](522/1500); Loss: 0.103087; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1490 0.0778 0.1574 0.1145 0.0855 0.0664 0.1081 0.1094 0.0912 0.0770 0.0960 0.0922 0.1029 0.1003 0.1071 0.1145 

[TRAIN] Epoch[7](523/1500); Loss: 0.133137; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1575 0.1317 0.1541 0.1470 0.1387 0.1233 0.1216 0.1194 0.1224 0.1224 0.1239 0.1283 0.1367 0.1320 0.1351 0.1362 

[TRAIN] Epoch[7](524/1500); Loss: 0.151264; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1950 0.1796 0.1645 0.1582 0.1509 0.1490 0.1410 0.1402 0.1409 0.1386 0.1415 0.1422 0.1422 0.1441 0.1459 0.1465 

[TRAIN] Epoch[7](525/1500); Loss: 0.134850; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1486 0.1485 0.1325 0.1318 0.1323 0.1305 0.1275 0.1304 0.1282 0.1316 0.1324 0.1343 0.1347 0.1367 0.1375 0.1402 

[TRAIN] Epoch[7](526/1500); Loss: 0.110281; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1305 0.1105 0.1153 0.1114 0.0959 0.0989 0.0978 0.1024 0.1008 0.1045 0.1060 0.1108 0.1147 0.1169 0.1217 0.1265 

[TRAIN] Epoch[7](527/1500); Loss: 0.165061; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1692 0.1902 0.1741 0.1638 0.1651 0.1657 0.1603 0.1610 0.1605 0.1618 0.1604 0.1597 0.1613 0.1619 0.1622 0.1638 

[TRAIN] Epoch[7](528/1500); Loss: 0.117739; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1477 0.1331 0.1131 0.1135 0.1108 0.1100 0.1085 0.1100 0.1115 0.1117 0.1141 0.1152 0.1182 0.1206 0.1222 0.1236 

[TRAIN] Epoch[7](529/1500); Loss: 0.103230; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0921 0.0971 0.1120 0.0947 0.0912 0.1008 0.0938 0.0983 0.0989 0.1049 0.1017 0.1080 0.1078 0.1159 0.1132 0.1214 

[TRAIN] Epoch[7](530/1500); Loss: 0.144914; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.3294 0.1983 0.2043 0.1759 0.1270 0.1009 0.1053 0.1059 0.1068 0.1130 0.1248 0.1171 0.1211 0.1300 0.1285 0.1302 

[TRAIN] Epoch[7](531/1500); Loss: 0.131818; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1680 0.1417 0.1316 0.1252 0.1147 0.1172 0.1161 0.1196 0.1201 0.1237 0.1286 0.1327 0.1351 0.1400 0.1459 0.1488 

[TRAIN] Epoch[7](532/1500); Loss: 0.168020; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2020 0.1943 0.1787 0.1650 0.1623 0.1648 0.1581 0.1599 0.1620 0.1583 0.1599 0.1631 0.1618 0.1638 0.1667 0.1677 

[TRAIN] Epoch[7](533/1500); Loss: 0.078919; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.0918 0.0718 0.0723 0.0679 0.0659 0.0688 0.0702 0.0697 0.0740 0.0756 0.0804 0.0839 0.0860 0.0922 0.0934 0.0987 

[TRAIN] Epoch[7](534/1500); Loss: 0.100729; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1562 0.1358 0.1010 0.0871 0.0855 0.0854 0.0859 0.0868 0.0898 0.0909 0.0944 0.0981 0.0994 0.0997 0.1067 0.1089 

[TRAIN] Epoch[7](535/1500); Loss: 0.170743; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1795 0.1786 0.1709 0.1705 0.1757 0.1691 0.1648 0.1665 0.1697 0.1660 0.1656 0.1679 0.1754 0.1670 0.1698 0.1750 

[TRAIN] Epoch[7](536/1500); Loss: 0.178663; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3104 0.2373 0.2309 0.2099 0.1741 0.1425 0.1431 0.1443 0.1480 0.1486 0.1634 0.1524 0.1646 0.1585 0.1602 0.1705 

[TRAIN] Epoch[7](537/1500); Loss: 0.082115; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0931 0.1117 0.0868 0.0668 0.0674 0.0686 0.0696 0.0710 0.0744 0.0768 0.0789 0.0830 0.0865 0.0900 0.0934 0.0958 

[TRAIN] Epoch[7](538/1500); Loss: 0.105104; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1375 0.1108 0.1016 0.0956 0.0986 0.0935 0.0963 0.0959 0.1005 0.1008 0.1019 0.1053 0.1058 0.1084 0.1145 0.1146 

[TRAIN] Epoch[7](539/1500); Loss: 0.152543; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1661 0.1639 0.1525 0.1507 0.1485 0.1473 0.1469 0.1493 0.1475 0.1489 0.1492 0.1532 0.1516 0.1536 0.1550 0.1564 

[TRAIN] Epoch[7](540/1500); Loss: 0.094856; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1205 0.1062 0.1288 0.1008 0.0837 0.0807 0.0796 0.0817 0.0860 0.0856 0.0853 0.0890 0.0901 0.0965 0.1012 0.1019 

[TRAIN] Epoch[7](541/1500); Loss: 0.204256; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.3570 0.2698 0.2565 0.2295 0.1889 0.1673 0.1787 0.1708 0.1761 0.1775 0.1748 0.1798 0.1828 0.1822 0.1863 0.1900 

[TRAIN] Epoch[7](542/1500); Loss: 0.185809; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2718 0.2411 0.2290 0.2106 0.1956 0.1765 0.1685 0.1647 0.1629 0.1629 0.1624 0.1631 0.1636 0.1669 0.1652 0.1682 

[TRAIN] Epoch[7](543/1500); Loss: 0.156024; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2206 0.1817 0.1778 0.1616 0.1482 0.1433 0.1401 0.1421 0.1421 0.1435 0.1459 0.1462 0.1486 0.1492 0.1516 0.1538 

[TRAIN] Epoch[7](544/1500); Loss: 0.106703; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1469 0.1263 0.1220 0.1074 0.0984 0.0964 0.0939 0.0944 0.0952 0.0993 0.0978 0.1008 0.1029 0.1070 0.1059 0.1127 

[TRAIN] Epoch[7](545/1500); Loss: 0.100795; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2043 0.1537 0.0919 0.0809 0.0805 0.0792 0.0814 0.0773 0.0879 0.0864 0.0910 0.0891 0.1006 0.0977 0.1061 0.1048 

[TRAIN] Epoch[7](546/1500); Loss: 0.088586; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2259 0.1190 0.1176 0.0836 0.0574 0.0675 0.0630 0.0670 0.0682 0.0672 0.0723 0.0748 0.0769 0.0820 0.0854 0.0893 

[TRAIN] Epoch[7](547/1500); Loss: 0.111164; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1224 0.1120 0.1031 0.1004 0.1009 0.1038 0.1061 0.1055 0.1072 0.1098 0.1128 0.1124 0.1156 0.1171 0.1224 0.1270 

[TRAIN] Epoch[7](548/1500); Loss: 0.142617; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2091 0.1578 0.1590 0.1404 0.1258 0.1280 0.1259 0.1304 0.1334 0.1387 0.1322 0.1366 0.1416 0.1422 0.1382 0.1425 

[TRAIN] Epoch[7](549/1500); Loss: 0.124838; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1748 0.1276 0.1261 0.1194 0.1153 0.1124 0.1124 0.1150 0.1150 0.1170 0.1196 0.1211 0.1258 0.1285 0.1308 0.1364 

[TRAIN] Epoch[7](550/1500); Loss: 0.087864; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1160 0.0954 0.0898 0.0863 0.0773 0.0793 0.0778 0.0831 0.0795 0.0828 0.0826 0.0883 0.0875 0.0908 0.0923 0.0969 

[TRAIN] Epoch[7](551/1500); Loss: 0.065942; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0813 0.0707 0.0627 0.0576 0.0559 0.0540 0.0523 0.0534 0.0565 0.0592 0.0629 0.0668 0.0726 0.0765 0.0842 0.0885 

[TRAIN] Epoch[7](552/1500); Loss: 0.086914; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1721 0.0712 0.0875 0.0664 0.0872 0.0684 0.0757 0.0822 0.0733 0.0780 0.0832 0.0817 0.0853 0.0891 0.0924 0.0971 

[TRAIN] Epoch[7](553/1500); Loss: 0.111665; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1568 0.1132 0.1044 0.1034 0.1012 0.1037 0.1031 0.1050 0.1058 0.1080 0.1085 0.1095 0.1122 0.1153 0.1166 0.1199 

[TRAIN] Epoch[7](554/1500); Loss: 0.144500; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1677 0.1527 0.1491 0.1419 0.1390 0.1385 0.1370 0.1380 0.1378 0.1402 0.1396 0.1430 0.1425 0.1455 0.1476 0.1519 

[TRAIN] Epoch[7](555/1500); Loss: 0.209157; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.3174 0.2476 0.2419 0.2185 0.1902 0.1843 0.1878 0.1883 0.1892 0.1914 0.1946 0.1936 0.1970 0.1988 0.2017 0.2043 

[TRAIN] Epoch[7](556/1500); Loss: 0.110002; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1190 0.1034 0.1136 0.1035 0.0961 0.0974 0.1000 0.1018 0.1042 0.1081 0.1092 0.1129 0.1169 0.1203 0.1243 0.1292 

[TRAIN] Epoch[7](557/1500); Loss: 0.138611; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2085 0.1502 0.1685 0.1421 0.1220 0.1175 0.1173 0.1212 0.1233 0.1236 0.1275 0.1354 0.1359 0.1370 0.1399 0.1478 

[TRAIN] Epoch[7](558/1500); Loss: 0.130940; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1785 0.1628 0.1530 0.1470 0.1355 0.1256 0.1163 0.1127 0.1145 0.1157 0.1174 0.1188 0.1204 0.1230 0.1259 0.1280 

[TRAIN] Epoch[7](559/1500); Loss: 0.082998; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0932 0.0730 0.1045 0.0798 0.0687 0.0674 0.0735 0.0718 0.0774 0.0797 0.0813 0.0839 0.0900 0.0906 0.0927 0.1004 

[TRAIN] Epoch[7](560/1500); Loss: 0.154617; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1662 0.1647 0.1550 0.1533 0.1534 0.1492 0.1494 0.1499 0.1527 0.1513 0.1516 0.1524 0.1553 0.1540 0.1580 0.1572 

[TRAIN] Epoch[7](561/1500); Loss: 0.090852; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1045 0.0898 0.0815 0.0791 0.0797 0.0816 0.0811 0.0837 0.0858 0.0893 0.0923 0.0934 0.0981 0.1003 0.1049 0.1086 

[TRAIN] Epoch[7](562/1500); Loss: 0.091768; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1043 0.1068 0.1011 0.0940 0.0874 0.0792 0.0793 0.0786 0.0839 0.0833 0.0857 0.0879 0.0947 0.0967 0.1017 0.1039 

[TRAIN] Epoch[7](563/1500); Loss: 0.119868; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1386 0.1234 0.1385 0.1189 0.1098 0.1071 0.1080 0.1084 0.1106 0.1122 0.1153 0.1186 0.1201 0.1255 0.1289 0.1339 

[TRAIN] Epoch[7](564/1500); Loss: 0.115490; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1172 0.1175 0.1115 0.1111 0.1158 0.1078 0.1103 0.1101 0.1134 0.1129 0.1146 0.1158 0.1197 0.1205 0.1232 0.1263 

[TRAIN] Epoch[7](565/1500); Loss: 0.137868; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1467 0.1389 0.1377 0.1303 0.1365 0.1289 0.1288 0.1319 0.1367 0.1351 0.1346 0.1431 0.1372 0.1420 0.1448 0.1527 

[TRAIN] Epoch[7](566/1500); Loss: 0.099296; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0946 0.0926 0.1063 0.0948 0.0904 0.0912 0.0863 0.0905 0.0918 0.0967 0.0957 0.1045 0.1062 0.1113 0.1137 0.1222 

[TRAIN] Epoch[7](567/1500); Loss: 0.151458; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1921 0.1832 0.1667 0.1577 0.1463 0.1391 0.1388 0.1386 0.1385 0.1408 0.1411 0.1438 0.1469 0.1483 0.1503 0.1511 

[TRAIN] Epoch[7](568/1500); Loss: 0.079669; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1126 0.1031 0.0797 0.0722 0.0705 0.0677 0.0696 0.0698 0.0701 0.0733 0.0751 0.0764 0.0797 0.0817 0.0844 0.0888 

[TRAIN] Epoch[7](569/1500); Loss: 0.140436; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2049 0.1659 0.1606 0.1512 0.1365 0.1238 0.1238 0.1235 0.1255 0.1306 0.1288 0.1291 0.1333 0.1333 0.1362 0.1400 

[TRAIN] Epoch[7](570/1500); Loss: 0.075409; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1510 0.0547 0.0792 0.0543 0.0668 0.0600 0.0601 0.0623 0.0706 0.0675 0.0760 0.0751 0.0768 0.0810 0.0838 0.0873 

[TRAIN] Epoch[7](571/1500); Loss: 0.073991; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1015 0.0930 0.0885 0.0720 0.0606 0.0599 0.0610 0.0589 0.0644 0.0644 0.0690 0.0692 0.0766 0.0780 0.0805 0.0864 

[TRAIN] Epoch[7](572/1500); Loss: 0.091163; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1006 0.0944 0.1027 0.0878 0.0841 0.0799 0.0832 0.0842 0.0857 0.0873 0.0886 0.0929 0.0941 0.0952 0.0992 0.0987 

[TRAIN] Epoch[7](573/1500); Loss: 0.167882; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2180 0.1998 0.1771 0.1717 0.1631 0.1616 0.1542 0.1557 0.1560 0.1573 0.1571 0.1605 0.1599 0.1625 0.1648 0.1667 

[TRAIN] Epoch[7](574/1500); Loss: 0.081582; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1093 0.0968 0.0879 0.0802 0.0731 0.0716 0.0724 0.0709 0.0738 0.0750 0.0757 0.0774 0.0806 0.0835 0.0867 0.0904 

[TRAIN] Epoch[7](575/1500); Loss: 0.121590; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.3255 0.2111 0.2376 0.2007 0.1358 0.0915 0.0606 0.0789 0.0689 0.0701 0.0710 0.0807 0.0729 0.0760 0.0821 0.0821 

[TRAIN] Epoch[7](576/1500); Loss: 0.076635; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0762 0.0955 0.0757 0.0661 0.0644 0.0652 0.0658 0.0686 0.0706 0.0717 0.0751 0.0789 0.0828 0.0864 0.0895 0.0937 

[TRAIN] Epoch[7](577/1500); Loss: 0.124235; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1353 0.1336 0.1238 0.1174 0.1199 0.1150 0.1166 0.1169 0.1226 0.1181 0.1213 0.1264 0.1248 0.1286 0.1320 0.1352 

[TRAIN] Epoch[7](578/1500); Loss: 0.128120; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1455 0.1382 0.1318 0.1242 0.1216 0.1224 0.1214 0.1220 0.1251 0.1223 0.1243 0.1271 0.1294 0.1281 0.1321 0.1345 

[TRAIN] Epoch[7](579/1500); Loss: 0.116796; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1199 0.1174 0.1130 0.1083 0.1111 0.1109 0.1089 0.1112 0.1163 0.1156 0.1160 0.1168 0.1213 0.1251 0.1262 0.1308 

[TRAIN] Epoch[7](580/1500); Loss: 0.140350; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1483 0.1475 0.1409 0.1416 0.1372 0.1343 0.1353 0.1353 0.1366 0.1370 0.1380 0.1391 0.1414 0.1423 0.1448 0.1462 

[TRAIN] Epoch[7](581/1500); Loss: 0.153593; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1805 0.1757 0.1672 0.1612 0.1547 0.1473 0.1417 0.1429 0.1421 0.1457 0.1464 0.1477 0.1481 0.1494 0.1518 0.1549 

[TRAIN] Epoch[7](582/1500); Loss: 0.083042; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1171 0.1022 0.0889 0.0786 0.0748 0.0730 0.0759 0.0730 0.0758 0.0754 0.0775 0.0793 0.0799 0.0832 0.0850 0.0892 

[TRAIN] Epoch[7](583/1500); Loss: 0.141077; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2355 0.1635 0.1892 0.1581 0.1266 0.1158 0.1152 0.1212 0.1208 0.1197 0.1243 0.1280 0.1331 0.1299 0.1377 0.1388 

[TRAIN] Epoch[7](584/1500); Loss: 0.072141; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1405 0.0537 0.0751 0.0534 0.0740 0.0587 0.0591 0.0635 0.0671 0.0630 0.0675 0.0699 0.0718 0.0761 0.0792 0.0816 

[TRAIN] Epoch[7](585/1500); Loss: 0.094093; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1002 0.0959 0.0907 0.0911 0.0862 0.0865 0.0868 0.0913 0.0896 0.0908 0.0927 0.0944 0.0981 0.0998 0.1047 0.1067 

[TRAIN] Epoch[7](586/1500); Loss: 0.065271; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0746 0.0656 0.0597 0.0563 0.0547 0.0548 0.0549 0.0563 0.0584 0.0617 0.0643 0.0690 0.0715 0.0772 0.0792 0.0859 

[TRAIN] Epoch[7](587/1500); Loss: 0.114246; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1494 0.0927 0.1579 0.1073 0.0849 0.0815 0.1092 0.1128 0.0985 0.0976 0.1179 0.1241 0.1147 0.1176 0.1305 0.1314 

[TRAIN] Epoch[7](588/1500); Loss: 0.096762; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1254 0.1207 0.0998 0.0973 0.0924 0.0897 0.0869 0.0864 0.0873 0.0876 0.0904 0.0925 0.0949 0.0961 0.1001 0.1008 

[TRAIN] Epoch[7](589/1500); Loss: 0.080045; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0910 0.1015 0.0868 0.0740 0.0677 0.0680 0.0681 0.0695 0.0733 0.0755 0.0759 0.0801 0.0822 0.0854 0.0893 0.0923 

[TRAIN] Epoch[7](590/1500); Loss: 0.091337; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1090 0.0877 0.1167 0.0903 0.0831 0.0778 0.0788 0.0778 0.0841 0.0846 0.0879 0.0892 0.1008 0.0956 0.0990 0.0988 

[TRAIN] Epoch[7](591/1500); Loss: 0.147945; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1743 0.1583 0.1544 0.1497 0.1437 0.1409 0.1417 0.1412 0.1424 0.1423 0.1417 0.1439 0.1451 0.1465 0.1498 0.1511 

[TRAIN] Epoch[7](592/1500); Loss: 0.091316; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1232 0.1026 0.0939 0.0899 0.0877 0.0819 0.0838 0.0824 0.0838 0.0854 0.0853 0.0880 0.0905 0.0926 0.0930 0.0969 

[TRAIN] Epoch[7](593/1500); Loss: 0.149628; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1782 0.1673 0.1530 0.1511 0.1513 0.1436 0.1428 0.1413 0.1397 0.1409 0.1433 0.1455 0.1457 0.1478 0.1505 0.1522 

[TRAIN] Epoch[7](594/1500); Loss: 0.139145; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1738 0.1670 0.1392 0.1325 0.1297 0.1270 0.1273 0.1296 0.1285 0.1336 0.1348 0.1346 0.1373 0.1423 0.1436 0.1453 

[TRAIN] Epoch[7](595/1500); Loss: 0.142721; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2019 0.1652 0.1656 0.1539 0.1385 0.1301 0.1294 0.1285 0.1321 0.1305 0.1351 0.1298 0.1339 0.1354 0.1374 0.1363 

[TRAIN] Epoch[7](596/1500); Loss: 0.079637; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1057 0.1046 0.0930 0.0751 0.0660 0.0635 0.0668 0.0681 0.0684 0.0713 0.0743 0.0762 0.0800 0.0846 0.0873 0.0893 

[TRAIN] Epoch[7](597/1500); Loss: 0.088998; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1163 0.0898 0.0847 0.0811 0.0853 0.0806 0.0811 0.0810 0.0829 0.0847 0.0856 0.0893 0.0903 0.0942 0.0964 0.1005 

[TRAIN] Epoch[7](598/1500); Loss: 0.081262; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1288 0.1067 0.0787 0.0688 0.0640 0.0664 0.0698 0.0735 0.0727 0.0751 0.0761 0.0792 0.0787 0.0870 0.0851 0.0898 

[TRAIN] Epoch[7](599/1500); Loss: 0.145976; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1691 0.1562 0.1579 0.1557 0.1452 0.1383 0.1387 0.1388 0.1380 0.1384 0.1418 0.1412 0.1418 0.1433 0.1452 0.1459 

[TRAIN] Epoch[7](600/1500); Loss: 0.108009; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1262 0.1180 0.1085 0.1055 0.1026 0.1043 0.1002 0.1009 0.1036 0.1046 0.1062 0.1059 0.1081 0.1092 0.1107 0.1139 

[TRAIN] Epoch[7](601/1500); Loss: 0.108753; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1408 0.0828 0.1368 0.1000 0.0872 0.0754 0.1083 0.1092 0.0983 0.0924 0.1069 0.1127 0.1201 0.1160 0.1221 0.1312 

[TRAIN] Epoch[7](602/1500); Loss: 0.139451; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2018 0.1819 0.1274 0.1334 0.1276 0.1263 0.1275 0.1301 0.1298 0.1306 0.1322 0.1350 0.1355 0.1356 0.1370 0.1395 

[TRAIN] Epoch[7](603/1500); Loss: 0.102595; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1462 0.1269 0.1558 0.1396 0.1129 0.0940 0.0849 0.0826 0.0822 0.0835 0.0837 0.0843 0.0880 0.0888 0.0922 0.0959 

[TRAIN] Epoch[7](604/1500); Loss: 0.140620; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1974 0.1636 0.1920 0.1728 0.1513 0.1346 0.1221 0.1163 0.1200 0.1226 0.1212 0.1220 0.1259 0.1297 0.1291 0.1293 

[TRAIN] Epoch[7](605/1500); Loss: 0.070347; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1057 0.0682 0.0700 0.0592 0.0594 0.0574 0.0603 0.0599 0.0643 0.0676 0.0670 0.0704 0.0752 0.0777 0.0796 0.0837 

[TRAIN] Epoch[7](606/1500); Loss: 0.114367; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1366 0.1298 0.1221 0.1159 0.1099 0.1034 0.1021 0.1034 0.1061 0.1076 0.1093 0.1109 0.1134 0.1173 0.1194 0.1226 

[TRAIN] Epoch[7](607/1500); Loss: 0.080633; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.1908 0.1508 0.0446 0.0609 0.0611 0.0497 0.0475 0.0689 0.0701 0.0626 0.0647 0.0810 0.0832 0.0781 0.0804 0.0956 

[TRAIN] Epoch[7](608/1500); Loss: 0.218186; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.3065 0.2579 0.2730 0.2557 0.2246 0.2015 0.1897 0.1938 0.1931 0.1937 0.1966 0.1982 0.1981 0.2007 0.2034 0.2047 

[TRAIN] Epoch[7](609/1500); Loss: 0.127789; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1853 0.1627 0.1540 0.1486 0.1296 0.1157 0.1093 0.1102 0.1090 0.1112 0.1118 0.1150 0.1175 0.1194 0.1211 0.1241 

[TRAIN] Epoch[7](610/1500); Loss: 0.103748; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1795 0.1362 0.1523 0.1387 0.1106 0.0860 0.0778 0.0777 0.0816 0.0806 0.0829 0.0864 0.0876 0.0899 0.0966 0.0956 

[TRAIN] Epoch[7](611/1500); Loss: 0.083534; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1615 0.1229 0.0653 0.0660 0.0610 0.0595 0.0644 0.0762 0.0732 0.0722 0.0746 0.0828 0.0822 0.0857 0.0924 0.0965 

[TRAIN] Epoch[7](612/1500); Loss: 0.125961; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1539 0.1323 0.1740 0.1598 0.1323 0.1126 0.1090 0.1024 0.1024 0.1076 0.1130 0.1155 0.1195 0.1258 0.1265 0.1288 

[TRAIN] Epoch[7](613/1500); Loss: 0.121105; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1927 0.1755 0.1317 0.1168 0.1146 0.1118 0.1076 0.1071 0.1072 0.1057 0.1056 0.1086 0.1109 0.1113 0.1142 0.1164 

[TRAIN] Epoch[7](614/1500); Loss: 0.157533; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1696 0.1575 0.1908 0.1776 0.1585 0.1459 0.1449 0.1433 0.1446 0.1457 0.1470 0.1530 0.1556 0.1594 0.1604 0.1667 

[TRAIN] Epoch[7](615/1500); Loss: 0.106814; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1438 0.1374 0.1082 0.0973 0.0917 0.0909 0.0906 0.0902 0.0938 0.0989 0.1017 0.1042 0.1098 0.1137 0.1163 0.1206 

[TRAIN] Epoch[7](616/1500); Loss: 0.116331; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1599 0.1534 0.1047 0.1028 0.1004 0.1008 0.1009 0.1012 0.1037 0.1106 0.1111 0.1129 0.1181 0.1248 0.1267 0.1293 

[TRAIN] Epoch[7](617/1500); Loss: 0.087428; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0798 0.0584 0.0997 0.0875 0.0675 0.0603 0.0792 0.0767 0.0777 0.0821 0.0924 0.0953 0.1003 0.1076 0.1156 0.1187 

[TRAIN] Epoch[7](618/1500); Loss: 0.166050; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1704 0.1703 0.1629 0.1611 0.1603 0.1600 0.1599 0.1599 0.1614 0.1634 0.1648 0.1659 0.1695 0.1725 0.1759 0.1786 

[TRAIN] Epoch[7](619/1500); Loss: 0.164613; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1789 0.1727 0.1607 0.1568 0.1543 0.1526 0.1539 0.1551 0.1570 0.1601 0.1607 0.1649 0.1707 0.1739 0.1781 0.1835 

[TRAIN] Epoch[7](620/1500); Loss: 0.168867; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1968 0.1768 0.2006 0.1929 0.1796 0.1654 0.1620 0.1585 0.1518 0.1495 0.1515 0.1535 0.1589 0.1639 0.1670 0.1732 

[TRAIN] Epoch[7](621/1500); Loss: 0.187921; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1954 0.1885 0.1701 0.1705 0.1748 0.1736 0.1800 0.1780 0.1825 0.1817 0.1881 0.1916 0.1988 0.2031 0.2104 0.2196 

[TRAIN] Epoch[7](622/1500); Loss: 0.357061; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.4061 0.3878 0.4442 0.4309 0.4085 0.3831 0.3748 0.3695 0.3462 0.3204 0.3214 0.3189 0.3022 0.2917 0.3021 0.3053 

[TRAIN] Epoch[7](623/1500); Loss: 0.125602; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1245 0.1215 0.1044 0.1019 0.1092 0.1096 0.1122 0.1136 0.1190 0.1220 0.1281 0.1350 0.1409 0.1472 0.1564 0.1641 

[TRAIN] Epoch[7](624/1500); Loss: 0.123997; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1018 0.1002 0.0920 0.0928 0.0970 0.0988 0.1089 0.1129 0.1204 0.1272 0.1343 0.1420 0.1507 0.1593 0.1682 0.1773 

[TRAIN] Epoch[7](625/1500); Loss: 0.185550; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1938 0.1916 0.1770 0.1751 0.1730 0.1737 0.1744 0.1761 0.1773 0.1803 0.1846 0.1882 0.1934 0.1976 0.2035 0.2092 

[TRAIN] Epoch[7](626/1500); Loss: 0.163475; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1553 0.1336 0.1379 0.1362 0.1354 0.1374 0.1411 0.1470 0.1552 0.1629 0.1699 0.1811 0.1908 0.2000 0.2101 0.2217 

[TRAIN] Epoch[7](627/1500); Loss: 0.186619; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2019 0.1970 0.1488 0.1440 0.1438 0.1555 0.1652 0.1717 0.1756 0.1838 0.1919 0.2023 0.2107 0.2217 0.2318 0.2402 

[TRAIN] Epoch[7](628/1500); Loss: 0.149094; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1345 0.1219 0.1437 0.1411 0.1419 0.1378 0.1434 0.1423 0.1443 0.1463 0.1524 0.1558 0.1606 0.1671 0.1729 0.1796 

[TRAIN] Epoch[7](629/1500); Loss: 0.130066; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1232 0.1096 0.1374 0.1309 0.1271 0.1238 0.1245 0.1243 0.1251 0.1265 0.1287 0.1330 0.1350 0.1390 0.1442 0.1486 

[TRAIN] Epoch[7](630/1500); Loss: 0.155026; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1520 0.1446 0.1606 0.1560 0.1556 0.1498 0.1492 0.1479 0.1477 0.1487 0.1524 0.1545 0.1580 0.1628 0.1676 0.1732 

[TRAIN] Epoch[7](631/1500); Loss: 0.202166; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1946 0.1929 0.1965 0.1945 0.1933 0.1927 0.1951 0.1958 0.1971 0.1980 0.2023 0.2076 0.2106 0.2159 0.2216 0.2263 

[TRAIN] Epoch[7](632/1500); Loss: 0.369076; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.3466 0.3630 0.3730 0.3707 0.3629 0.3623 0.3681 0.3696 0.3675 0.3670 0.3713 0.3740 0.3716 0.3741 0.3811 0.3823 

[TRAIN] Epoch[7](633/1500); Loss: 0.179788; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1715 0.1616 0.1614 0.1611 0.1628 0.1627 0.1655 0.1694 0.1735 0.1780 0.1835 0.1898 0.1965 0.2052 0.2124 0.2217 

[TRAIN] Epoch[7](634/1500); Loss: 0.163406; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1692 0.1660 0.1582 0.1505 0.1509 0.1520 0.1541 0.1562 0.1579 0.1605 0.1630 0.1668 0.1706 0.1750 0.1788 0.1848 

[TRAIN] Epoch[7](635/1500); Loss: 0.160570; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1655 0.1570 0.1626 0.1568 0.1540 0.1519 0.1544 0.1545 0.1558 0.1563 0.1584 0.1613 0.1643 0.1675 0.1723 0.1765 

[TRAIN] Epoch[7](636/1500); Loss: 0.232448; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2353 0.2259 0.2460 0.2408 0.2376 0.2326 0.2316 0.2309 0.2279 0.2260 0.2268 0.2282 0.2278 0.2303 0.2343 0.2374 

[TRAIN] Epoch[7](637/1500); Loss: 0.176680; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2136 0.2115 0.1715 0.1461 0.1474 0.1471 0.1575 0.1600 0.1650 0.1685 0.1750 0.1800 0.1862 0.1922 0.1994 0.2060 

[TRAIN] Epoch[7](638/1500); Loss: 0.108738; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.0777 0.0804 0.0802 0.0792 0.0849 0.0869 0.0917 0.0954 0.1044 0.1100 0.1184 0.1281 0.1373 0.1450 0.1556 0.1645 

[TRAIN] Epoch[7](639/1500); Loss: 0.130159; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1136 0.0984 0.1151 0.1162 0.1181 0.1119 0.1163 0.1174 0.1217 0.1273 0.1347 0.1410 0.1488 0.1595 0.1674 0.1752 

[TRAIN] Epoch[7](640/1500); Loss: 0.190543; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1382 0.1421 0.1706 0.1482 0.1774 0.1868 0.1935 0.1886 0.1898 0.1941 0.2021 0.2042 0.2148 0.2231 0.2314 0.2438 

[TRAIN] Epoch[7](641/1500); Loss: 0.130859; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1016 0.0915 0.1122 0.1113 0.1108 0.1117 0.1189 0.1218 0.1260 0.1320 0.1407 0.1468 0.1548 0.1631 0.1715 0.1791 

[TRAIN] Epoch[7](642/1500); Loss: 0.113698; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.0849 0.0862 0.0765 0.0597 0.0930 0.0953 0.1110 0.1038 0.1120 0.1161 0.1200 0.1271 0.1444 0.1511 0.1614 0.1767 

[TRAIN] Epoch[7](643/1500); Loss: 0.173711; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1752 0.1730 0.1700 0.1694 0.1684 0.1671 0.1680 0.1679 0.1694 0.1708 0.1729 0.1749 0.1781 0.1810 0.1852 0.1882 

[TRAIN] Epoch[7](644/1500); Loss: 0.177735; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1886 0.1790 0.1885 0.1728 0.1685 0.1626 0.1654 0.1731 0.1692 0.1688 0.1727 0.1777 0.1784 0.1865 0.1928 0.1993 

[TRAIN] Epoch[7](645/1500); Loss: 0.218119; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2163 0.2151 0.2346 0.2268 0.2189 0.2174 0.2162 0.2155 0.2113 0.2102 0.2127 0.2144 0.2137 0.2180 0.2223 0.2263 

[TRAIN] Epoch[7](646/1500); Loss: 0.125667; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1283 0.1217 0.1360 0.1245 0.1119 0.1118 0.1137 0.1148 0.1153 0.1185 0.1220 0.1268 0.1328 0.1378 0.1437 0.1510 

[TRAIN] Epoch[7](647/1500); Loss: 0.149440; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1474 0.1393 0.1485 0.1480 0.1493 0.1462 0.1476 0.1451 0.1455 0.1454 0.1484 0.1496 0.1530 0.1554 0.1601 0.1624 

[TRAIN] Epoch[7](648/1500); Loss: 0.138798; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1394 0.1317 0.1364 0.1348 0.1324 0.1260 0.1270 0.1262 0.1274 0.1301 0.1351 0.1403 0.1486 0.1565 0.1618 0.1670 

[TRAIN] Epoch[7](649/1500); Loss: 0.142807; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1543 0.1403 0.1589 0.1528 0.1458 0.1395 0.1396 0.1373 0.1342 0.1341 0.1369 0.1369 0.1387 0.1421 0.1458 0.1478 

[TRAIN] Epoch[7](650/1500); Loss: 0.168002; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1662 0.1529 0.1728 0.1701 0.1654 0.1599 0.1618 0.1602 0.1609 0.1615 0.1660 0.1685 0.1738 0.1776 0.1847 0.1859 

[TRAIN] Epoch[7](651/1500); Loss: 0.128238; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1235 0.1239 0.0900 0.0848 0.1038 0.0991 0.1228 0.1184 0.1323 0.1302 0.1360 0.1364 0.1501 0.1550 0.1672 0.1783 

[TRAIN] Epoch[7](652/1500); Loss: 0.156379; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1652 0.1623 0.1566 0.1492 0.1484 0.1486 0.1495 0.1504 0.1500 0.1517 0.1538 0.1559 0.1594 0.1631 0.1671 0.1710 

[TRAIN] Epoch[7](653/1500); Loss: 0.127466; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1206 0.1033 0.1183 0.1174 0.1110 0.1058 0.1141 0.1152 0.1195 0.1261 0.1318 0.1362 0.1443 0.1507 0.1594 0.1656 

[TRAIN] Epoch[7](654/1500); Loss: 0.333705; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.4276 0.4114 0.4639 0.4459 0.4101 0.3739 0.3662 0.3506 0.3088 0.2757 0.2807 0.2685 0.2417 0.2292 0.2425 0.2427 

[TRAIN] Epoch[7](655/1500); Loss: 0.104442; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1491 0.1477 0.0951 0.0741 0.0776 0.0812 0.0826 0.0902 0.0912 0.0952 0.0989 0.1060 0.1131 0.1163 0.1226 0.1301 

[TRAIN] Epoch[7](656/1500); Loss: 0.138754; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1516 0.1408 0.1529 0.1480 0.1421 0.1365 0.1372 0.1340 0.1314 0.1306 0.1321 0.1323 0.1339 0.1363 0.1394 0.1409 

[TRAIN] Epoch[7](657/1500); Loss: 0.123719; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1176 0.1109 0.1116 0.1102 0.1125 0.1106 0.1124 0.1151 0.1192 0.1227 0.1272 0.1320 0.1356 0.1421 0.1484 0.1514 

[TRAIN] Epoch[7](658/1500); Loss: 0.072671; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0792 0.0715 0.0657 0.0673 0.0664 0.0643 0.0638 0.0638 0.0653 0.0683 0.0712 0.0743 0.0782 0.0831 0.0877 0.0926 

[TRAIN] Epoch[7](659/1500); Loss: 0.127117; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1324 0.1158 0.1335 0.1306 0.1270 0.1157 0.1149 0.1139 0.1144 0.1167 0.1217 0.1257 0.1339 0.1397 0.1473 0.1506 

[TRAIN] Epoch[7](660/1500); Loss: 0.136015; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1361 0.1209 0.1416 0.1405 0.1316 0.1210 0.1217 0.1235 0.1240 0.1295 0.1355 0.1371 0.1430 0.1504 0.1562 0.1637 

[TRAIN] Epoch[7](661/1500); Loss: 0.173807; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1581 0.1694 0.1809 0.1789 0.1711 0.1703 0.1722 0.1710 0.1675 0.1700 0.1698 0.1717 0.1737 0.1808 0.1842 0.1912 

[TRAIN] Epoch[7](662/1500); Loss: 0.124298; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1296 0.1136 0.1277 0.1218 0.1139 0.1053 0.1136 0.1131 0.1165 0.1201 0.1244 0.1248 0.1324 0.1368 0.1456 0.1497 

[TRAIN] Epoch[7](663/1500); Loss: 0.066654; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0497 0.0535 0.0499 0.0480 0.0600 0.0578 0.0599 0.0573 0.0627 0.0649 0.0699 0.0755 0.0806 0.0873 0.0920 0.0974 

[TRAIN] Epoch[7](664/1500); Loss: 0.139224; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.1432 0.1348 0.1413 0.1381 0.1329 0.1273 0.1303 0.1301 0.1328 0.1350 0.1378 0.1393 0.1454 0.1491 0.1545 0.1558 

[TRAIN] Epoch[7](665/1500); Loss: 0.103055; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1205 0.1098 0.1001 0.0974 0.0978 0.0952 0.0972 0.0955 0.0986 0.0981 0.1003 0.1011 0.1062 0.1062 0.1113 0.1136 

[TRAIN] Epoch[7](666/1500); Loss: 0.097720; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1309 0.1110 0.1255 0.1170 0.1012 0.0886 0.0881 0.0829 0.0796 0.0807 0.0851 0.0850 0.0919 0.0948 0.1006 0.1006 

[TRAIN] Epoch[7](667/1500); Loss: 0.129121; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2146 0.2073 0.1164 0.0878 0.0895 0.1109 0.1048 0.1191 0.1133 0.1186 0.1150 0.1217 0.1270 0.1360 0.1389 0.1451 

[TRAIN] Epoch[7](668/1500); Loss: 0.130394; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1415 0.1335 0.1463 0.1404 0.1334 0.1260 0.1275 0.1235 0.1220 0.1227 0.1248 0.1242 0.1265 0.1285 0.1326 0.1330 

[TRAIN] Epoch[7](669/1500); Loss: 0.173722; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2053 0.1969 0.1860 0.1796 0.1748 0.1685 0.1684 0.1655 0.1590 0.1561 0.1644 0.1639 0.1652 0.1688 0.1763 0.1809 

[TRAIN] Epoch[7](670/1500); Loss: 0.125271; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1339 0.1319 0.1247 0.1227 0.1208 0.1207 0.1202 0.1198 0.1207 0.1214 0.1235 0.1245 0.1266 0.1284 0.1308 0.1338 

[TRAIN] Epoch[7](671/1500); Loss: 0.132787; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.1420 0.1375 0.1354 0.1313 0.1280 0.1238 0.1241 0.1239 0.1264 0.1273 0.1317 0.1318 0.1354 0.1381 0.1433 0.1445 

[TRAIN] Epoch[7](672/1500); Loss: 0.144798; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1563 0.1473 0.1540 0.1485 0.1402 0.1349 0.1364 0.1343 0.1349 0.1370 0.1404 0.1404 0.1459 0.1503 0.1565 0.1593 

[TRAIN] Epoch[7](673/1500); Loss: 0.139026; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1643 0.1502 0.1605 0.1529 0.1417 0.1334 0.1326 0.1296 0.1276 0.1275 0.1294 0.1295 0.1334 0.1342 0.1383 0.1392 

[TRAIN] Epoch[7](674/1500); Loss: 0.176741; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1863 0.1806 0.1917 0.1869 0.1824 0.1744 0.1730 0.1694 0.1669 0.1671 0.1688 0.1719 0.1728 0.1759 0.1765 0.1833 

[TRAIN] Epoch[7](675/1500); Loss: 0.120220; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1887 0.1764 0.1269 0.1132 0.1129 0.1112 0.1116 0.1099 0.1058 0.1066 0.1093 0.1095 0.1062 0.1090 0.1119 0.1145 

[TRAIN] Epoch[7](676/1500); Loss: 0.136239; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1372 0.1379 0.1303 0.1290 0.1312 0.1280 0.1347 0.1316 0.1337 0.1314 0.1337 0.1334 0.1410 0.1433 0.1500 0.1535 

[TRAIN] Epoch[7](677/1500); Loss: 0.133293; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.1669 0.1516 0.1698 0.1586 0.1381 0.1224 0.1217 0.1167 0.1158 0.1140 0.1180 0.1211 0.1251 0.1263 0.1337 0.1328 

[TRAIN] Epoch[7](678/1500); Loss: 0.107682; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1337 0.1163 0.1283 0.1213 0.1119 0.1030 0.1000 0.1000 0.0947 0.0938 0.0979 0.0988 0.1001 0.1037 0.1091 0.1102 

[TRAIN] Epoch[7](679/1500); Loss: 0.112632; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1321 0.1216 0.1334 0.1264 0.1145 0.1035 0.1029 0.1008 0.1002 0.1013 0.1041 0.1068 0.1097 0.1122 0.1140 0.1187 

[TRAIN] Epoch[7](680/1500); Loss: 0.113528; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1469 0.1313 0.1495 0.1418 0.1250 0.1090 0.1015 0.0944 0.0883 0.0915 0.0995 0.0995 0.1030 0.1079 0.1120 0.1154 

[TRAIN] Epoch[7](681/1500); Loss: 0.106124; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1080 0.0968 0.1076 0.1045 0.0990 0.0983 0.0992 0.0989 0.0994 0.1019 0.1058 0.1074 0.1126 0.1173 0.1194 0.1221 

[TRAIN] Epoch[7](682/1500); Loss: 0.117059; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1226 0.1100 0.1249 0.1196 0.1177 0.1078 0.1063 0.1085 0.1097 0.1098 0.1135 0.1175 0.1207 0.1230 0.1286 0.1327 

[TRAIN] Epoch[7](683/1500); Loss: 0.129454; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1472 0.1375 0.1409 0.1377 0.1272 0.1211 0.1222 0.1186 0.1181 0.1191 0.1226 0.1237 0.1291 0.1321 0.1354 0.1387 

[TRAIN] Epoch[7](684/1500); Loss: 0.112009; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1488 0.1438 0.1092 0.0933 0.0962 0.0935 0.0978 0.0981 0.0979 0.1017 0.1083 0.1125 0.1152 0.1176 0.1280 0.1302 

[TRAIN] Epoch[7](685/1500); Loss: 0.138584; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2194 0.2107 0.1707 0.1250 0.1249 0.1119 0.1252 0.1251 0.1221 0.1170 0.1198 0.1216 0.1232 0.1325 0.1311 0.1370 

[TRAIN] Epoch[7](686/1500); Loss: 0.105161; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1169 0.1112 0.1128 0.1054 0.1004 0.0984 0.0974 0.0971 0.0983 0.0982 0.1027 0.1031 0.1057 0.1087 0.1108 0.1154 

[TRAIN] Epoch[7](687/1500); Loss: 0.105211; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1497 0.1489 0.0980 0.0809 0.0861 0.0887 0.0889 0.0924 0.0941 0.0960 0.1010 0.1067 0.1075 0.1111 0.1152 0.1181 

[TRAIN] Epoch[7](688/1500); Loss: 0.064827; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0769 0.0624 0.0846 0.0741 0.0599 0.0517 0.0571 0.0531 0.0559 0.0561 0.0638 0.0614 0.0665 0.0666 0.0738 0.0734 

[TRAIN] Epoch[7](689/1500); Loss: 0.150237; Backpropagation: 0.0924 sec; Batch: 0.4234 sec
0.1980 0.1848 0.1760 0.1647 0.1561 0.1494 0.1465 0.1442 0.1350 0.1306 0.1300 0.1336 0.1344 0.1375 0.1391 0.1438 

[TRAIN] Epoch[7](690/1500); Loss: 0.178040; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2578 0.2426 0.2760 0.2599 0.2249 0.1995 0.1887 0.1637 0.1389 0.1334 0.1325 0.1227 0.1213 0.1244 0.1302 0.1319 

[TRAIN] Epoch[7](691/1500); Loss: 0.159548; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1705 0.1705 0.1580 0.1553 0.1542 0.1530 0.1530 0.1521 0.1556 0.1556 0.1569 0.1587 0.1615 0.1633 0.1657 0.1688 

[TRAIN] Epoch[7](692/1500); Loss: 0.218533; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2268 0.2256 0.2348 0.2298 0.2222 0.2181 0.2164 0.2138 0.2109 0.2119 0.2106 0.2105 0.2128 0.2159 0.2169 0.2193 

[TRAIN] Epoch[7](693/1500); Loss: 0.098115; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1128 0.1025 0.1071 0.1008 0.0959 0.0911 0.0926 0.0900 0.0916 0.0898 0.0928 0.0930 0.1004 0.0999 0.1045 0.1049 

[TRAIN] Epoch[7](694/1500); Loss: 0.140757; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1400 0.1397 0.1454 0.1418 0.1389 0.1341 0.1349 0.1324 0.1357 0.1345 0.1403 0.1388 0.1443 0.1456 0.1528 0.1529 

[TRAIN] Epoch[7](695/1500); Loss: 0.072781; Backpropagation: 0.0923 sec; Batch: 0.4236 sec
0.0743 0.0739 0.0684 0.0679 0.0670 0.0658 0.0684 0.0672 0.0710 0.0699 0.0737 0.0732 0.0788 0.0780 0.0833 0.0836 

[TRAIN] Epoch[7](696/1500); Loss: 0.117604; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1421 0.1372 0.1354 0.1297 0.1210 0.1129 0.1140 0.1082 0.1064 0.1054 0.1062 0.1079 0.1105 0.1114 0.1166 0.1167 

[TRAIN] Epoch[7](697/1500); Loss: 0.127989; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1449 0.1353 0.1335 0.1288 0.1230 0.1190 0.1200 0.1169 0.1192 0.1215 0.1230 0.1250 0.1280 0.1340 0.1345 0.1412 

[TRAIN] Epoch[7](698/1500); Loss: 0.150205; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1630 0.1575 0.1587 0.1566 0.1498 0.1463 0.1464 0.1454 0.1426 0.1442 0.1450 0.1453 0.1471 0.1502 0.1524 0.1529 

[TRAIN] Epoch[7](699/1500); Loss: 0.065577; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0681 0.0595 0.0751 0.0686 0.0637 0.0567 0.0557 0.0583 0.0611 0.0599 0.0656 0.0651 0.0695 0.0710 0.0759 0.0755 

[TRAIN] Epoch[7](700/1500); Loss: 0.135158; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1547 0.1480 0.1372 0.1351 0.1276 0.1260 0.1228 0.1218 0.1207 0.1246 0.1300 0.1322 0.1371 0.1442 0.1491 0.1515 

[TRAIN] Epoch[7](701/1500); Loss: 0.079453; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.0764 0.0648 0.0801 0.0768 0.0688 0.0634 0.0707 0.0708 0.0727 0.0784 0.0833 0.0837 0.0881 0.0933 0.0988 0.1013 

[TRAIN] Epoch[7](702/1500); Loss: 0.101371; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1077 0.1051 0.0996 0.0952 0.0951 0.0941 0.0955 0.0976 0.0984 0.0990 0.1010 0.1030 0.1040 0.1065 0.1087 0.1114 

[TRAIN] Epoch[7](703/1500); Loss: 0.068841; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0777 0.0667 0.0741 0.0687 0.0612 0.0573 0.0587 0.0603 0.0622 0.0648 0.0667 0.0699 0.0730 0.0757 0.0799 0.0846 

[TRAIN] Epoch[7](704/1500); Loss: 0.173196; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2039 0.1965 0.1903 0.1801 0.1708 0.1682 0.1651 0.1651 0.1624 0.1628 0.1628 0.1650 0.1663 0.1685 0.1699 0.1735 

[TRAIN] Epoch[7](705/1500); Loss: 0.124560; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2378 0.2288 0.1520 0.0888 0.1023 0.0878 0.1078 0.1101 0.1091 0.0975 0.1018 0.1046 0.1110 0.1131 0.1195 0.1210 

[TRAIN] Epoch[7](706/1500); Loss: 0.067270; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.0740 0.0667 0.0734 0.0694 0.0635 0.0559 0.0581 0.0588 0.0617 0.0616 0.0669 0.0662 0.0717 0.0722 0.0781 0.0781 

[TRAIN] Epoch[7](707/1500); Loss: 0.151664; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1773 0.1684 0.1714 0.1667 0.1573 0.1501 0.1466 0.1426 0.1414 0.1405 0.1402 0.1411 0.1439 0.1441 0.1472 0.1480 

[TRAIN] Epoch[7](708/1500); Loss: 0.110249; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1129 0.1116 0.1110 0.1086 0.1054 0.1021 0.1050 0.1049 0.1059 0.1063 0.1093 0.1118 0.1140 0.1154 0.1185 0.1210 

[TRAIN] Epoch[7](709/1500); Loss: 0.190408; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2293 0.2223 0.2216 0.2101 0.1996 0.1898 0.1882 0.1819 0.1746 0.1710 0.1729 0.1724 0.1729 0.1768 0.1791 0.1841 

[TRAIN] Epoch[7](710/1500); Loss: 0.113468; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1168 0.1201 0.1187 0.1114 0.1143 0.1093 0.1068 0.1077 0.1126 0.1098 0.1107 0.1101 0.1163 0.1153 0.1163 0.1193 

[TRAIN] Epoch[7](711/1500); Loss: 0.111966; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1392 0.1368 0.1083 0.0992 0.1034 0.1037 0.1056 0.1048 0.1040 0.1046 0.1080 0.1099 0.1122 0.1137 0.1180 0.1200 

[TRAIN] Epoch[7](712/1500); Loss: 0.134358; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1666 0.1662 0.1377 0.1232 0.1222 0.1234 0.1244 0.1255 0.1259 0.1265 0.1282 0.1314 0.1335 0.1356 0.1385 0.1409 

[TRAIN] Epoch[7](713/1500); Loss: 0.088196; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1063 0.1055 0.0818 0.0746 0.0752 0.0773 0.0756 0.0764 0.0802 0.0812 0.0844 0.0883 0.0959 0.0987 0.1021 0.1076 

[TRAIN] Epoch[7](714/1500); Loss: 0.091600; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1594 0.1581 0.0984 0.0586 0.0710 0.0747 0.0673 0.0751 0.0741 0.0767 0.0781 0.0931 0.0893 0.0938 0.0953 0.1026 

[TRAIN] Epoch[7](715/1500); Loss: 0.173729; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1993 0.1908 0.2099 0.1994 0.1905 0.1802 0.1770 0.1673 0.1591 0.1542 0.1576 0.1556 0.1552 0.1569 0.1639 0.1628 

[TRAIN] Epoch[7](716/1500); Loss: 0.165898; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1700 0.1650 0.1620 0.1619 0.1602 0.1575 0.1600 0.1603 0.1620 0.1598 0.1645 0.1675 0.1708 0.1716 0.1792 0.1821 

[TRAIN] Epoch[7](717/1500); Loss: 0.104309; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1168 0.1080 0.1166 0.1085 0.1009 0.0912 0.0936 0.0928 0.0962 0.0981 0.1004 0.1010 0.1071 0.1109 0.1135 0.1135 

[TRAIN] Epoch[7](718/1500); Loss: 0.160515; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1718 0.1677 0.1648 0.1638 0.1609 0.1589 0.1572 0.1557 0.1552 0.1549 0.1561 0.1569 0.1588 0.1594 0.1621 0.1642 

[TRAIN] Epoch[7](719/1500); Loss: 0.137679; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.1705 0.1572 0.1640 0.1544 0.1379 0.1318 0.1306 0.1248 0.1231 0.1248 0.1258 0.1249 0.1274 0.1309 0.1357 0.1391 

[TRAIN] Epoch[7](720/1500); Loss: 0.091242; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1318 0.1288 0.0753 0.0694 0.0703 0.0816 0.0809 0.0799 0.0773 0.0816 0.0850 0.0883 0.0964 0.0989 0.1047 0.1097 

[TRAIN] Epoch[7](721/1500); Loss: 0.106391; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1095 0.1014 0.1129 0.1051 0.1050 0.0972 0.1006 0.0947 0.1012 0.0988 0.0996 0.1100 0.1122 0.1156 0.1153 0.1233 

[TRAIN] Epoch[7](722/1500); Loss: 0.194092; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2394 0.2262 0.2243 0.2134 0.1994 0.1911 0.1884 0.1830 0.1789 0.1767 0.1772 0.1779 0.1799 0.1794 0.1836 0.1865 

[TRAIN] Epoch[7](723/1500); Loss: 0.195419; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1849 0.1723 0.1996 0.1943 0.1865 0.1858 0.1921 0.1876 0.1867 0.1956 0.1942 0.1969 0.2042 0.2096 0.2134 0.2231 

[TRAIN] Epoch[7](724/1500); Loss: 0.162478; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1753 0.1707 0.1676 0.1671 0.1642 0.1626 0.1604 0.1587 0.1588 0.1578 0.1580 0.1571 0.1586 0.1596 0.1613 0.1618 

[TRAIN] Epoch[7](725/1500); Loss: 0.067219; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0617 0.0577 0.0700 0.0622 0.0597 0.0592 0.0653 0.0639 0.0684 0.0627 0.0662 0.0701 0.0772 0.0744 0.0774 0.0795 

[TRAIN] Epoch[7](726/1500); Loss: 0.159410; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2044 0.1921 0.1934 0.1831 0.1713 0.1593 0.1558 0.1487 0.1429 0.1402 0.1406 0.1419 0.1415 0.1427 0.1465 0.1461 

[TRAIN] Epoch[7](727/1500); Loss: 0.108073; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1249 0.1117 0.1203 0.1135 0.1033 0.1002 0.1003 0.0983 0.0999 0.1013 0.1044 0.1034 0.1080 0.1098 0.1151 0.1148 

[TRAIN] Epoch[7](728/1500); Loss: 0.102259; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1132 0.1076 0.1098 0.1048 0.0986 0.0954 0.0960 0.0935 0.0957 0.0963 0.0998 0.0997 0.1037 0.1044 0.1088 0.1089 

[TRAIN] Epoch[7](729/1500); Loss: 0.140149; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1997 0.1886 0.1746 0.1556 0.1479 0.1374 0.1393 0.1309 0.1245 0.1185 0.1192 0.1181 0.1181 0.1198 0.1233 0.1268 

[TRAIN] Epoch[7](730/1500); Loss: 0.105273; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1427 0.1207 0.1317 0.1251 0.1085 0.0883 0.0818 0.0791 0.0835 0.0901 0.0918 0.0977 0.0995 0.1085 0.1157 0.1195 

[TRAIN] Epoch[7](731/1500); Loss: 0.144787; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1676 0.1685 0.1565 0.1465 0.1460 0.1410 0.1416 0.1372 0.1391 0.1368 0.1363 0.1361 0.1376 0.1405 0.1416 0.1436 

[TRAIN] Epoch[7](732/1500); Loss: 0.116129; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1382 0.1224 0.1440 0.1346 0.1225 0.1061 0.1042 0.0990 0.1006 0.1026 0.1060 0.1076 0.1130 0.1175 0.1204 0.1193 

[TRAIN] Epoch[7](733/1500); Loss: 0.101457; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1195 0.1143 0.0998 0.0956 0.0957 0.0909 0.0951 0.0929 0.0940 0.0941 0.0974 0.1001 0.1016 0.1071 0.1112 0.1139 

[TRAIN] Epoch[7](734/1500); Loss: 0.129912; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2018 0.1923 0.1736 0.1546 0.1396 0.1302 0.1256 0.1161 0.1088 0.1044 0.1033 0.1007 0.1043 0.1044 0.1093 0.1095 

[TRAIN] Epoch[7](735/1500); Loss: 0.069526; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.0641 0.0650 0.0663 0.0590 0.0631 0.0617 0.0637 0.0650 0.0725 0.0686 0.0699 0.0704 0.0794 0.0777 0.0806 0.0855 

[TRAIN] Epoch[7](736/1500); Loss: 0.078099; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0764 0.0673 0.0873 0.0771 0.0702 0.0685 0.0794 0.0743 0.0750 0.0694 0.0765 0.0822 0.0834 0.0834 0.0878 0.0913 

[TRAIN] Epoch[7](737/1500); Loss: 0.100688; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1219 0.1074 0.1170 0.1086 0.0972 0.0888 0.0943 0.0889 0.0922 0.0937 0.0965 0.0948 0.1004 0.1002 0.1048 0.1043 

[TRAIN] Epoch[7](738/1500); Loss: 0.118226; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1323 0.1335 0.1192 0.1173 0.1154 0.1146 0.1138 0.1143 0.1138 0.1138 0.1140 0.1150 0.1163 0.1183 0.1200 0.1200 

[TRAIN] Epoch[7](739/1500); Loss: 0.101897; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1079 0.1060 0.1075 0.1039 0.1000 0.0941 0.0979 0.0946 0.0947 0.0962 0.0997 0.0986 0.1031 0.1058 0.1102 0.1101 

[TRAIN] Epoch[7](740/1500); Loss: 0.101771; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1147 0.1047 0.1049 0.1039 0.0969 0.0915 0.0901 0.0921 0.0915 0.0947 0.0981 0.1005 0.1043 0.1094 0.1133 0.1178 

[TRAIN] Epoch[7](741/1500); Loss: 0.110585; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1270 0.1156 0.1260 0.1194 0.1091 0.1028 0.1047 0.1014 0.1005 0.1043 0.1061 0.1052 0.1079 0.1113 0.1138 0.1141 

[TRAIN] Epoch[7](742/1500); Loss: 0.152205; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.2067 0.1987 0.1871 0.1755 0.1592 0.1484 0.1412 0.1331 0.1280 0.1286 0.1323 0.1360 0.1359 0.1383 0.1413 0.1449 

[TRAIN] Epoch[7](743/1500); Loss: 0.096431; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1075 0.1065 0.1108 0.0961 0.1000 0.0980 0.0899 0.0773 0.0849 0.0782 0.0872 0.0884 0.0960 0.0986 0.1103 0.1133 

[TRAIN] Epoch[7](744/1500); Loss: 0.094512; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1019 0.0921 0.0996 0.0935 0.0888 0.0864 0.0887 0.0874 0.0876 0.0910 0.0915 0.0945 0.0990 0.1027 0.1010 0.1066 

[TRAIN] Epoch[7](745/1500); Loss: 0.163023; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1722 0.1687 0.1654 0.1643 0.1621 0.1608 0.1600 0.1593 0.1593 0.1590 0.1606 0.1606 0.1629 0.1629 0.1648 0.1655 

[TRAIN] Epoch[7](746/1500); Loss: 0.122471; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1348 0.1291 0.1288 0.1260 0.1219 0.1149 0.1139 0.1148 0.1145 0.1173 0.1183 0.1196 0.1235 0.1259 0.1284 0.1279 

[TRAIN] Epoch[7](747/1500); Loss: 0.152090; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1879 0.1823 0.1654 0.1514 0.1449 0.1396 0.1417 0.1445 0.1419 0.1420 0.1450 0.1461 0.1465 0.1478 0.1519 0.1543 

[TRAIN] Epoch[7](748/1500); Loss: 0.095530; Backpropagation: 0.0917 sec; Batch: 0.4258 sec
0.1173 0.1118 0.0992 0.0924 0.0939 0.0901 0.0888 0.0843 0.0898 0.0875 0.0893 0.0892 0.0973 0.0968 0.0983 0.1027 

[TRAIN] Epoch[7](749/1500); Loss: 0.088497; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0916 0.0894 0.0791 0.0764 0.0855 0.0813 0.0849 0.0814 0.0828 0.0898 0.0902 0.0912 0.0935 0.0974 0.0992 0.1022 

[TRAIN] Epoch[7](750/1500); Loss: 0.243704; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2633 0.2564 0.2586 0.2548 0.2492 0.2465 0.2433 0.2416 0.2407 0.2386 0.2359 0.2357 0.2355 0.2334 0.2333 0.2326 

[TRAIN] Epoch[7](751/1500); Loss: 0.097061; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1201 0.1181 0.1040 0.0944 0.1000 0.0939 0.0956 0.0906 0.0888 0.0881 0.0892 0.0895 0.0929 0.0929 0.0947 0.1001 

[TRAIN] Epoch[7](752/1500); Loss: 0.249220; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.4196 0.3948 0.4344 0.4117 0.3573 0.3085 0.2730 0.2254 0.1749 0.1501 0.1413 0.1419 0.1430 0.1334 0.1404 0.1380 

[TRAIN] Epoch[7](753/1500); Loss: 0.151941; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1603 0.1513 0.1636 0.1588 0.1540 0.1456 0.1465 0.1427 0.1424 0.1417 0.1493 0.1489 0.1536 0.1526 0.1594 0.1608 

[TRAIN] Epoch[7](754/1500); Loss: 0.128916; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1419 0.1387 0.1393 0.1353 0.1260 0.1214 0.1224 0.1189 0.1197 0.1210 0.1222 0.1245 0.1277 0.1311 0.1343 0.1384 

[TRAIN] Epoch[7](755/1500); Loss: 0.096977; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1284 0.1166 0.1165 0.1026 0.0970 0.0888 0.0849 0.0838 0.0829 0.0852 0.0880 0.0904 0.0924 0.0947 0.0982 0.1012 

[TRAIN] Epoch[7](756/1500); Loss: 0.130665; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1294 0.1214 0.1236 0.1186 0.1177 0.1207 0.1191 0.1208 0.1254 0.1287 0.1317 0.1360 0.1437 0.1473 0.1502 0.1563 

[TRAIN] Epoch[7](757/1500); Loss: 0.106605; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1069 0.1045 0.1043 0.1040 0.1029 0.0999 0.1006 0.1029 0.1041 0.1047 0.1064 0.1088 0.1112 0.1120 0.1156 0.1169 

[TRAIN] Epoch[7](758/1500); Loss: 0.116488; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1607 0.1548 0.1111 0.1079 0.1018 0.1104 0.1075 0.1063 0.0997 0.1063 0.1079 0.1102 0.1151 0.1182 0.1211 0.1249 

[TRAIN] Epoch[7](759/1500); Loss: 0.081054; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1141 0.1079 0.0534 0.0569 0.0667 0.0587 0.0824 0.0769 0.0788 0.0728 0.0865 0.0820 0.0881 0.0868 0.0905 0.0946 

[TRAIN] Epoch[7](760/1500); Loss: 0.164984; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2609 0.2481 0.2177 0.1838 0.1638 0.1546 0.1518 0.1484 0.1417 0.1364 0.1365 0.1362 0.1350 0.1383 0.1418 0.1445 

[TRAIN] Epoch[7](761/1500); Loss: 0.088534; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1189 0.1083 0.0960 0.0863 0.0799 0.0762 0.0775 0.0765 0.0775 0.0792 0.0825 0.0850 0.0889 0.0911 0.0943 0.0985 

[TRAIN] Epoch[7](762/1500); Loss: 0.109594; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1844 0.1607 0.1827 0.1671 0.1346 0.1101 0.0994 0.0785 0.0698 0.0734 0.0787 0.0771 0.0814 0.0819 0.0877 0.0861 

[TRAIN] Epoch[7](763/1500); Loss: 0.133319; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1527 0.1472 0.1405 0.1356 0.1303 0.1282 0.1271 0.1255 0.1251 0.1253 0.1280 0.1289 0.1299 0.1342 0.1369 0.1376 

[TRAIN] Epoch[7](764/1500); Loss: 0.180258; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2292 0.2236 0.2162 0.2086 0.1950 0.1864 0.1805 0.1703 0.1608 0.1581 0.1575 0.1556 0.1581 0.1603 0.1601 0.1639 

[TRAIN] Epoch[7](765/1500); Loss: 0.108392; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1137 0.1140 0.1035 0.1035 0.1017 0.1013 0.1021 0.1024 0.1040 0.1061 0.1093 0.1098 0.1118 0.1152 0.1176 0.1181 

[TRAIN] Epoch[7](766/1500); Loss: 0.175168; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2431 0.2373 0.2302 0.2226 0.2064 0.1865 0.1895 0.1708 0.1522 0.1395 0.1452 0.1346 0.1314 0.1313 0.1392 0.1427 

[TRAIN] Epoch[7](767/1500); Loss: 0.190718; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2605 0.2620 0.2445 0.2163 0.2004 0.1962 0.1866 0.1794 0.1670 0.1641 0.1625 0.1626 0.1605 0.1603 0.1639 0.1645 

[TRAIN] Epoch[7](768/1500); Loss: 0.096266; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1210 0.1163 0.0884 0.0881 0.0818 0.0803 0.0871 0.0853 0.0866 0.0896 0.0932 0.0947 0.1009 0.1060 0.1086 0.1123 

[TRAIN] Epoch[7](769/1500); Loss: 0.160366; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1693 0.1792 0.1862 0.1744 0.1616 0.1618 0.1572 0.1516 0.1459 0.1456 0.1443 0.1483 0.1541 0.1562 0.1616 0.1685 

[TRAIN] Epoch[7](770/1500); Loss: 0.100401; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1179 0.1150 0.1015 0.0995 0.0989 0.0955 0.0940 0.0938 0.0962 0.0963 0.0992 0.0964 0.0971 0.1004 0.1028 0.1020 

[TRAIN] Epoch[7](771/1500); Loss: 0.135992; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1862 0.1847 0.1927 0.1725 0.1384 0.1247 0.1187 0.1169 0.1169 0.1125 0.1141 0.1177 0.1205 0.1164 0.1189 0.1240 

[TRAIN] Epoch[7](772/1500); Loss: 0.150492; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1656 0.1629 0.1628 0.1602 0.1548 0.1496 0.1494 0.1481 0.1469 0.1458 0.1436 0.1418 0.1424 0.1431 0.1446 0.1463 

[TRAIN] Epoch[7](773/1500); Loss: 0.217859; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3494 0.3363 0.3504 0.3308 0.2886 0.2541 0.2243 0.1857 0.1546 0.1441 0.1440 0.1458 0.1399 0.1440 0.1440 0.1498 

[TRAIN] Epoch[7](774/1500); Loss: 0.086269; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1413 0.1165 0.1224 0.1084 0.0880 0.0783 0.0727 0.0681 0.0682 0.0677 0.0688 0.0720 0.0727 0.0766 0.0770 0.0815 

[TRAIN] Epoch[7](775/1500); Loss: 0.172617; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2010 0.1987 0.1645 0.1668 0.1649 0.1568 0.1704 0.1652 0.1697 0.1649 0.1686 0.1647 0.1756 0.1740 0.1777 0.1784 

[TRAIN] Epoch[7](776/1500); Loss: 0.114538; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1344 0.1283 0.1202 0.1180 0.1139 0.1088 0.1075 0.1037 0.1034 0.1020 0.1071 0.1083 0.1124 0.1140 0.1246 0.1260 

[TRAIN] Epoch[7](777/1500); Loss: 0.142093; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1490 0.1472 0.1394 0.1357 0.1401 0.1381 0.1364 0.1359 0.1386 0.1388 0.1411 0.1412 0.1453 0.1461 0.1484 0.1521 

[TRAIN] Epoch[7](778/1500); Loss: 0.150965; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1648 0.1679 0.1570 0.1519 0.1494 0.1447 0.1461 0.1423 0.1427 0.1429 0.1475 0.1475 0.1480 0.1510 0.1558 0.1557 

[TRAIN] Epoch[7](779/1500); Loss: 0.119637; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1333 0.1344 0.1289 0.1250 0.1153 0.1133 0.1128 0.1113 0.1138 0.1114 0.1147 0.1144 0.1172 0.1178 0.1249 0.1256 

[TRAIN] Epoch[7](780/1500); Loss: 0.115724; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1164 0.1157 0.1113 0.1101 0.1097 0.1094 0.1113 0.1102 0.1120 0.1134 0.1157 0.1173 0.1207 0.1235 0.1262 0.1288 

[TRAIN] Epoch[7](781/1500); Loss: 0.080492; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1195 0.1159 0.0965 0.0786 0.0685 0.0683 0.0699 0.0682 0.0724 0.0721 0.0726 0.0725 0.0754 0.0762 0.0791 0.0822 

[TRAIN] Epoch[7](782/1500); Loss: 0.118993; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1181 0.1150 0.1416 0.1201 0.1267 0.1147 0.1116 0.1042 0.1138 0.1105 0.1146 0.1134 0.1223 0.1212 0.1284 0.1277 

[TRAIN] Epoch[7](783/1500); Loss: 0.108878; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1363 0.1338 0.1015 0.1027 0.1002 0.0986 0.1030 0.1026 0.1050 0.1026 0.1051 0.1086 0.1095 0.1083 0.1098 0.1143 

[TRAIN] Epoch[7](784/1500); Loss: 0.148442; Backpropagation: 0.0927 sec; Batch: 0.4240 sec
0.2018 0.1931 0.1776 0.1652 0.1553 0.1461 0.1465 0.1398 0.1358 0.1298 0.1308 0.1287 0.1292 0.1300 0.1334 0.1320 

[TRAIN] Epoch[7](785/1500); Loss: 0.083568; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1034 0.1006 0.0727 0.0617 0.0829 0.0695 0.0748 0.0685 0.0869 0.0774 0.0792 0.0787 0.0929 0.0952 0.0950 0.0978 

[TRAIN] Epoch[7](786/1500); Loss: 0.118592; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1635 0.1606 0.1143 0.0999 0.1042 0.1023 0.1025 0.1052 0.1070 0.1090 0.1130 0.1160 0.1186 0.1231 0.1274 0.1311 

[TRAIN] Epoch[7](787/1500); Loss: 0.135169; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1604 0.1558 0.1401 0.1316 0.1279 0.1264 0.1271 0.1261 0.1302 0.1304 0.1305 0.1322 0.1335 0.1342 0.1372 0.1392 

[TRAIN] Epoch[7](788/1500); Loss: 0.087501; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1897 0.1813 0.0827 0.0552 0.0553 0.0681 0.0625 0.0659 0.0675 0.0812 0.0755 0.0781 0.0767 0.0880 0.0852 0.0872 

[TRAIN] Epoch[7](789/1500); Loss: 0.151288; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.2012 0.1891 0.1838 0.1700 0.1555 0.1454 0.1415 0.1364 0.1340 0.1327 0.1338 0.1354 0.1376 0.1395 0.1412 0.1435 

[TRAIN] Epoch[7](790/1500); Loss: 0.108524; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1384 0.1368 0.0980 0.0993 0.1009 0.0995 0.1000 0.0975 0.1011 0.1041 0.1059 0.1040 0.1070 0.1125 0.1161 0.1153 

[TRAIN] Epoch[7](791/1500); Loss: 0.115343; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1266 0.1197 0.1261 0.1203 0.1141 0.1138 0.1110 0.1083 0.1096 0.1111 0.1113 0.1114 0.1141 0.1156 0.1152 0.1174 

[TRAIN] Epoch[7](792/1500); Loss: 0.117963; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1299 0.1218 0.1246 0.1210 0.1150 0.1117 0.1123 0.1122 0.1131 0.1128 0.1152 0.1159 0.1171 0.1200 0.1222 0.1225 

[TRAIN] Epoch[7](793/1500); Loss: 0.076230; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1068 0.0934 0.0876 0.0829 0.0721 0.0660 0.0663 0.0647 0.0660 0.0670 0.0689 0.0699 0.0744 0.0748 0.0780 0.0810 

[TRAIN] Epoch[7](794/1500); Loss: 0.123147; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1558 0.1316 0.1509 0.1462 0.1276 0.1082 0.1044 0.1061 0.1080 0.1084 0.1119 0.1148 0.1208 0.1234 0.1245 0.1279 

[TRAIN] Epoch[7](795/1500); Loss: 0.142316; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1557 0.1501 0.1516 0.1499 0.1450 0.1408 0.1396 0.1389 0.1380 0.1374 0.1371 0.1370 0.1375 0.1390 0.1390 0.1404 

[TRAIN] Epoch[7](796/1500); Loss: 0.169781; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1797 0.1768 0.1790 0.1776 0.1728 0.1715 0.1660 0.1667 0.1682 0.1693 0.1630 0.1644 0.1658 0.1694 0.1626 0.1638 

[TRAIN] Epoch[7](797/1500); Loss: 0.077277; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1372 0.1350 0.0773 0.0552 0.0570 0.0566 0.0606 0.0648 0.0642 0.0675 0.0690 0.0709 0.0743 0.0792 0.0821 0.0855 

[TRAIN] Epoch[7](798/1500); Loss: 0.150954; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1731 0.1665 0.1825 0.1742 0.1592 0.1446 0.1447 0.1402 0.1378 0.1353 0.1407 0.1385 0.1425 0.1404 0.1468 0.1483 

[TRAIN] Epoch[7](799/1500); Loss: 0.134470; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1819 0.1644 0.1541 0.1400 0.1297 0.1251 0.1227 0.1246 0.1212 0.1238 0.1235 0.1258 0.1256 0.1279 0.1287 0.1325 

[TRAIN] Epoch[7](800/1500); Loss: 0.180340; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1991 0.1929 0.1968 0.1931 0.1848 0.1787 0.1784 0.1752 0.1728 0.1726 0.1723 0.1724 0.1722 0.1731 0.1750 0.1759 

[TRAIN] Epoch[7](801/1500); Loss: 0.146205; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1877 0.1795 0.1559 0.1421 0.1376 0.1334 0.1333 0.1341 0.1341 0.1344 0.1367 0.1407 0.1433 0.1452 0.1488 0.1525 

[TRAIN] Epoch[7](802/1500); Loss: 0.156379; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1858 0.1706 0.1774 0.1694 0.1568 0.1524 0.1498 0.1483 0.1473 0.1472 0.1468 0.1474 0.1491 0.1503 0.1506 0.1529 

[TRAIN] Epoch[7](803/1500); Loss: 0.087732; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2199 0.2129 0.0874 0.0483 0.0489 0.0717 0.0591 0.0594 0.0612 0.0773 0.0731 0.0718 0.0639 0.0856 0.0825 0.0806 

[TRAIN] Epoch[7](804/1500); Loss: 0.208424; Backpropagation: 0.0923 sec; Batch: 0.4237 sec
0.3596 0.3358 0.3470 0.3278 0.2846 0.2430 0.2094 0.1689 0.1364 0.1290 0.1360 0.1298 0.1284 0.1318 0.1329 0.1344 

[TRAIN] Epoch[7](805/1500); Loss: 0.125989; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2365 0.2302 0.1647 0.1077 0.1126 0.0975 0.1023 0.0970 0.0995 0.1051 0.1048 0.1077 0.1065 0.1110 0.1134 0.1195 

[TRAIN] Epoch[7](806/1500); Loss: 0.122460; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2095 0.2096 0.1242 0.0959 0.0979 0.1095 0.1001 0.1014 0.1037 0.1131 0.1101 0.1106 0.1081 0.1222 0.1206 0.1227 

[TRAIN] Epoch[7](807/1500); Loss: 0.099149; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1102 0.1041 0.1053 0.1017 0.0953 0.0919 0.0920 0.0929 0.0939 0.0951 0.0962 0.0974 0.0994 0.1029 0.1038 0.1042 

[TRAIN] Epoch[7](808/1500); Loss: 0.157574; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2540 0.2330 0.2501 0.2311 0.1977 0.1693 0.1503 0.1259 0.1128 0.1099 0.1106 0.1159 0.1123 0.1151 0.1137 0.1194 

[TRAIN] Epoch[7](809/1500); Loss: 0.114696; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1829 0.1880 0.0590 0.1032 0.0869 0.0932 0.0944 0.0930 0.0999 0.1117 0.1120 0.1140 0.1187 0.1223 0.1275 0.1285 

[TRAIN] Epoch[7](810/1500); Loss: 0.106940; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1386 0.1201 0.1279 0.1192 0.1047 0.0987 0.0990 0.0971 0.0983 0.0978 0.0996 0.0988 0.1012 0.1011 0.1049 0.1038 

[TRAIN] Epoch[7](811/1500); Loss: 0.134500; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1627 0.1591 0.1434 0.1280 0.1261 0.1208 0.1230 0.1218 0.1256 0.1261 0.1299 0.1318 0.1346 0.1361 0.1414 0.1416 

[TRAIN] Epoch[7](812/1500); Loss: 0.125540; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1332 0.1309 0.1259 0.1232 0.1204 0.1195 0.1195 0.1192 0.1204 0.1219 0.1237 0.1251 0.1280 0.1299 0.1329 0.1348 

[TRAIN] Epoch[7](813/1500); Loss: 0.108677; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2447 0.2377 0.1440 0.0766 0.0798 0.0685 0.0788 0.0774 0.0866 0.0825 0.0922 0.0868 0.0938 0.0918 0.1008 0.0969 

[TRAIN] Epoch[7](814/1500); Loss: 0.154894; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2475 0.2245 0.2445 0.2269 0.1920 0.1617 0.1429 0.1200 0.1127 0.1132 0.1129 0.1113 0.1148 0.1186 0.1156 0.1194 

[TRAIN] Epoch[7](815/1500); Loss: 0.103342; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1353 0.1276 0.1209 0.1138 0.1008 0.0939 0.0929 0.0920 0.0921 0.0937 0.0934 0.0948 0.0978 0.0987 0.1023 0.1034 

[TRAIN] Epoch[7](816/1500); Loss: 0.166130; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2029 0.1928 0.1942 0.1869 0.1737 0.1629 0.1599 0.1534 0.1507 0.1514 0.1518 0.1520 0.1530 0.1569 0.1561 0.1595 

[TRAIN] Epoch[7](817/1500); Loss: 0.150382; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1839 0.1826 0.1601 0.1556 0.1489 0.1426 0.1440 0.1404 0.1383 0.1404 0.1417 0.1413 0.1433 0.1450 0.1476 0.1504 

[TRAIN] Epoch[7](818/1500); Loss: 0.090401; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1081 0.1036 0.0943 0.0883 0.0844 0.0839 0.0855 0.0841 0.0857 0.0850 0.0866 0.0880 0.0901 0.0902 0.0932 0.0954 

[TRAIN] Epoch[7](819/1500); Loss: 0.128450; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1429 0.1421 0.1323 0.1309 0.1277 0.1232 0.1249 0.1226 0.1244 0.1221 0.1257 0.1238 0.1265 0.1257 0.1299 0.1305 

[TRAIN] Epoch[7](820/1500); Loss: 0.166470; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2117 0.2011 0.2069 0.1982 0.1817 0.1677 0.1583 0.1483 0.1449 0.1447 0.1467 0.1458 0.1496 0.1516 0.1525 0.1538 

[TRAIN] Epoch[7](821/1500); Loss: 0.195268; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2712 0.2528 0.2538 0.2437 0.2227 0.2043 0.1940 0.1814 0.1716 0.1642 0.1611 0.1577 0.1600 0.1594 0.1631 0.1633 

[TRAIN] Epoch[7](822/1500); Loss: 0.079168; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0985 0.0930 0.0903 0.0822 0.0736 0.0639 0.0675 0.0701 0.0712 0.0700 0.0736 0.0764 0.0806 0.0816 0.0860 0.0882 

[TRAIN] Epoch[7](823/1500); Loss: 0.080445; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1181 0.1049 0.0958 0.0863 0.0716 0.0676 0.0692 0.0693 0.0693 0.0722 0.0729 0.0722 0.0772 0.0768 0.0814 0.0823 

[TRAIN] Epoch[7](824/1500); Loss: 0.202400; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.4225 0.3844 0.3994 0.3714 0.3089 0.2488 0.1949 0.1370 0.0973 0.0958 0.0991 0.0917 0.0906 0.1005 0.0973 0.0988 

[TRAIN] Epoch[7](825/1500); Loss: 0.150584; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1922 0.1805 0.1831 0.1728 0.1565 0.1461 0.1414 0.1374 0.1381 0.1357 0.1370 0.1362 0.1380 0.1370 0.1388 0.1385 

[TRAIN] Epoch[7](826/1500); Loss: 0.126357; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1715 0.1690 0.1391 0.1357 0.1257 0.1173 0.1219 0.1119 0.1120 0.1118 0.1162 0.1139 0.1150 0.1185 0.1214 0.1211 

[TRAIN] Epoch[7](827/1500); Loss: 0.129184; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1553 0.1582 0.1215 0.1233 0.1201 0.1170 0.1245 0.1230 0.1219 0.1232 0.1269 0.1256 0.1265 0.1334 0.1331 0.1334 

[TRAIN] Epoch[7](828/1500); Loss: 0.141553; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1967 0.1932 0.1597 0.1435 0.1312 0.1280 0.1282 0.1259 0.1272 0.1271 0.1300 0.1289 0.1308 0.1363 0.1386 0.1394 

[TRAIN] Epoch[7](829/1500); Loss: 0.129368; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1360 0.1362 0.1323 0.1297 0.1242 0.1236 0.1254 0.1227 0.1254 0.1254 0.1287 0.1270 0.1311 0.1315 0.1355 0.1352 

[TRAIN] Epoch[7](830/1500); Loss: 0.114834; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1239 0.1205 0.1156 0.1139 0.1112 0.1108 0.1108 0.1118 0.1109 0.1118 0.1129 0.1129 0.1156 0.1160 0.1191 0.1197 

[TRAIN] Epoch[7](831/1500); Loss: 0.098206; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1361 0.1350 0.0964 0.0877 0.0765 0.0874 0.0829 0.0816 0.0815 0.0915 0.0912 0.0933 0.1004 0.1082 0.1086 0.1129 

[TRAIN] Epoch[7](832/1500); Loss: 0.184776; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1972 0.1949 0.1848 0.1844 0.1819 0.1812 0.1840 0.1828 0.1828 0.1800 0.1840 0.1831 0.1852 0.1818 0.1830 0.1854 

[TRAIN] Epoch[7](833/1500); Loss: 0.185663; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2012 0.1985 0.1987 0.1948 0.1890 0.1832 0.1803 0.1785 0.1778 0.1775 0.1785 0.1796 0.1805 0.1831 0.1828 0.1866 

[TRAIN] Epoch[7](834/1500); Loss: 0.128762; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1630 0.1667 0.1327 0.1279 0.1215 0.1176 0.1197 0.1185 0.1237 0.1206 0.1216 0.1229 0.1247 0.1230 0.1280 0.1281 

[TRAIN] Epoch[7](835/1500); Loss: 0.124635; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.1935 0.1864 0.1379 0.1221 0.1199 0.1156 0.1131 0.1122 0.1113 0.1096 0.1125 0.1091 0.1105 0.1138 0.1130 0.1136 

[TRAIN] Epoch[7](836/1500); Loss: 0.139325; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1596 0.1630 0.1448 0.1397 0.1357 0.1307 0.1333 0.1312 0.1317 0.1309 0.1340 0.1328 0.1386 0.1374 0.1411 0.1447 

[TRAIN] Epoch[7](837/1500); Loss: 0.105316; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1397 0.1435 0.1147 0.1016 0.0958 0.0949 0.0958 0.0955 0.0971 0.0981 0.0995 0.0984 0.1014 0.1025 0.1039 0.1029 

[TRAIN] Epoch[7](838/1500); Loss: 0.156284; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1715 0.1674 0.1643 0.1577 0.1508 0.1493 0.1476 0.1486 0.1505 0.1530 0.1518 0.1531 0.1556 0.1593 0.1594 0.1607 

[TRAIN] Epoch[7](839/1500); Loss: 0.129901; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1435 0.1372 0.1388 0.1342 0.1250 0.1207 0.1204 0.1206 0.1223 0.1249 0.1257 0.1297 0.1279 0.1336 0.1345 0.1396 

[TRAIN] Epoch[7](840/1500); Loss: 0.102183; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1004 0.1052 0.0989 0.0992 0.0995 0.0986 0.0990 0.0993 0.1002 0.1004 0.1013 0.1027 0.1053 0.1066 0.1086 0.1097 

[TRAIN] Epoch[7](841/1500); Loss: 0.148378; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1772 0.1650 0.1606 0.1572 0.1516 0.1454 0.1434 0.1410 0.1413 0.1402 0.1406 0.1398 0.1431 0.1414 0.1440 0.1426 

[TRAIN] Epoch[7](842/1500); Loss: 0.130630; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2511 0.2406 0.1906 0.1430 0.1191 0.1066 0.1092 0.0995 0.1003 0.0989 0.1029 0.1015 0.1048 0.1054 0.1072 0.1093 

[TRAIN] Epoch[7](843/1500); Loss: 0.084490; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0933 0.0959 0.0805 0.0795 0.0764 0.0755 0.0801 0.0776 0.0794 0.0810 0.0836 0.0837 0.0881 0.0888 0.0944 0.0939 

[TRAIN] Epoch[7](844/1500); Loss: 0.083723; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1881 0.1397 0.1583 0.1364 0.0909 0.0558 0.0476 0.0534 0.0509 0.0502 0.0567 0.0578 0.0571 0.0637 0.0634 0.0694 

[TRAIN] Epoch[7](845/1500); Loss: 0.118591; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2271 0.1899 0.1987 0.1830 0.1524 0.1279 0.1097 0.0922 0.0794 0.0739 0.0759 0.0743 0.0772 0.0763 0.0802 0.0794 

[TRAIN] Epoch[7](846/1500); Loss: 0.171640; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1822 0.1809 0.1765 0.1770 0.1737 0.1724 0.1694 0.1673 0.1672 0.1674 0.1666 0.1669 0.1684 0.1694 0.1700 0.1712 

[TRAIN] Epoch[7](847/1500); Loss: 0.144660; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2405 0.2059 0.2192 0.2022 0.1721 0.1488 0.1306 0.1146 0.1095 0.1085 0.1077 0.1083 0.1114 0.1097 0.1143 0.1114 

[TRAIN] Epoch[7](848/1500); Loss: 0.129569; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1768 0.1747 0.1427 0.1245 0.1192 0.1163 0.1207 0.1165 0.1212 0.1163 0.1228 0.1194 0.1238 0.1246 0.1274 0.1261 

[TRAIN] Epoch[7](849/1500); Loss: 0.164724; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1834 0.1815 0.1744 0.1714 0.1636 0.1621 0.1595 0.1599 0.1588 0.1602 0.1579 0.1581 0.1605 0.1622 0.1615 0.1606 

[TRAIN] Epoch[7](850/1500); Loss: 0.136112; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1812 0.1722 0.1646 0.1508 0.1369 0.1253 0.1251 0.1230 0.1227 0.1221 0.1221 0.1234 0.1240 0.1274 0.1271 0.1301 

[TRAIN] Epoch[7](851/1500); Loss: 0.119809; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2037 0.1662 0.1836 0.1678 0.1342 0.1033 0.0876 0.0910 0.0912 0.0900 0.0927 0.0967 0.0970 0.1010 0.1045 0.1066 

[TRAIN] Epoch[7](852/1500); Loss: 0.088223; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1091 0.0969 0.1001 0.0964 0.0889 0.0824 0.0795 0.0795 0.0805 0.0799 0.0830 0.0835 0.0858 0.0864 0.0899 0.0899 

[TRAIN] Epoch[7](853/1500); Loss: 0.156307; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.2188 0.2057 0.1979 0.1764 0.1586 0.1498 0.1457 0.1367 0.1388 0.1352 0.1370 0.1340 0.1378 0.1406 0.1439 0.1439 

[TRAIN] Epoch[7](854/1500); Loss: 0.067375; Backpropagation: 0.0915 sec; Batch: 0.4230 sec
0.0828 0.0775 0.0605 0.0587 0.0571 0.0564 0.0585 0.0583 0.0572 0.0624 0.0650 0.0675 0.0735 0.0769 0.0802 0.0857 

[TRAIN] Epoch[7](855/1500); Loss: 0.108915; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1224 0.1226 0.1105 0.1095 0.1048 0.1025 0.1048 0.1031 0.1028 0.1030 0.1060 0.1038 0.1097 0.1092 0.1144 0.1136 

[TRAIN] Epoch[7](856/1500); Loss: 0.144835; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1627 0.1722 0.1305 0.1303 0.1303 0.1329 0.1372 0.1374 0.1392 0.1430 0.1464 0.1473 0.1464 0.1512 0.1537 0.1565 

[TRAIN] Epoch[7](857/1500); Loss: 0.211250; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.3125 0.2769 0.2896 0.2743 0.2407 0.2070 0.1834 0.1783 0.1745 0.1746 0.1748 0.1773 0.1765 0.1781 0.1807 0.1810 

[TRAIN] Epoch[7](858/1500); Loss: 0.153781; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1817 0.1787 0.1610 0.1550 0.1477 0.1453 0.1443 0.1457 0.1455 0.1475 0.1475 0.1488 0.1496 0.1514 0.1550 0.1557 

[TRAIN] Epoch[7](859/1500); Loss: 0.142641; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1606 0.1525 0.1493 0.1457 0.1383 0.1362 0.1373 0.1360 0.1367 0.1373 0.1385 0.1382 0.1418 0.1424 0.1462 0.1452 

[TRAIN] Epoch[7](860/1500); Loss: 0.134363; Backpropagation: 0.0916 sec; Batch: 0.4228 sec
0.2285 0.1993 0.2150 0.1940 0.1629 0.1326 0.1184 0.0985 0.0958 0.0985 0.0953 0.0961 0.1008 0.1023 0.1034 0.1084 

[TRAIN] Epoch[7](861/1500); Loss: 0.143103; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1819 0.1799 0.1622 0.1473 0.1337 0.1306 0.1311 0.1320 0.1348 0.1346 0.1341 0.1355 0.1376 0.1360 0.1393 0.1391 

[TRAIN] Epoch[7](862/1500); Loss: 0.136723; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1498 0.1419 0.1419 0.1381 0.1351 0.1337 0.1340 0.1326 0.1328 0.1331 0.1336 0.1347 0.1346 0.1372 0.1350 0.1395 

[TRAIN] Epoch[7](863/1500); Loss: 0.165208; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1859 0.1810 0.1728 0.1685 0.1631 0.1593 0.1589 0.1580 0.1586 0.1585 0.1596 0.1600 0.1631 0.1641 0.1658 0.1661 

[TRAIN] Epoch[7](864/1500); Loss: 0.150404; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1703 0.1680 0.1579 0.1557 0.1525 0.1475 0.1462 0.1462 0.1447 0.1420 0.1431 0.1437 0.1451 0.1458 0.1483 0.1495 

[TRAIN] Epoch[7](865/1500); Loss: 0.106576; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1398 0.1389 0.1310 0.1259 0.1161 0.1065 0.1009 0.0938 0.0893 0.0883 0.0910 0.0921 0.0936 0.0971 0.0990 0.1017 

[TRAIN] Epoch[7](866/1500); Loss: 0.090671; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1014 0.1013 0.0959 0.0928 0.0883 0.0848 0.0846 0.0852 0.0862 0.0847 0.0883 0.0869 0.0914 0.0903 0.0942 0.0944 

[TRAIN] Epoch[7](867/1500); Loss: 0.131135; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1961 0.1770 0.1682 0.1538 0.1372 0.1268 0.1174 0.1122 0.1113 0.1128 0.1101 0.1115 0.1136 0.1151 0.1160 0.1191 

[TRAIN] Epoch[7](868/1500); Loss: 0.076161; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1015 0.0797 0.1024 0.0873 0.0665 0.0590 0.0601 0.0683 0.0678 0.0688 0.0686 0.0732 0.0757 0.0763 0.0794 0.0840 

[TRAIN] Epoch[7](869/1500); Loss: 0.083353; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1538 0.1640 0.0892 0.0578 0.0645 0.0586 0.0583 0.0753 0.0683 0.0703 0.0720 0.0782 0.0750 0.0808 0.0813 0.0863 

[TRAIN] Epoch[7](870/1500); Loss: 0.157274; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1970 0.1899 0.1792 0.1720 0.1613 0.1543 0.1507 0.1463 0.1441 0.1428 0.1444 0.1448 0.1453 0.1464 0.1490 0.1489 

[TRAIN] Epoch[7](871/1500); Loss: 0.123629; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1669 0.1701 0.1352 0.1214 0.1132 0.1136 0.1119 0.1129 0.1130 0.1128 0.1150 0.1152 0.1169 0.1171 0.1217 0.1211 

[TRAIN] Epoch[7](872/1500); Loss: 0.105790; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1162 0.1140 0.1105 0.1072 0.1025 0.0973 0.0978 0.0969 0.0999 0.0989 0.1033 0.1035 0.1094 0.1086 0.1127 0.1140 

[TRAIN] Epoch[7](873/1500); Loss: 0.123908; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1404 0.1309 0.1428 0.1326 0.1306 0.1206 0.1191 0.1188 0.1165 0.1155 0.1165 0.1179 0.1185 0.1177 0.1215 0.1226 

[TRAIN] Epoch[7](874/1500); Loss: 0.134982; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1418 0.1428 0.1367 0.1358 0.1328 0.1291 0.1299 0.1300 0.1324 0.1316 0.1324 0.1332 0.1355 0.1375 0.1376 0.1405 

[TRAIN] Epoch[7](875/1500); Loss: 0.103824; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1155 0.1136 0.1056 0.1053 0.0968 0.0965 0.0952 0.0967 0.0982 0.0985 0.1003 0.1041 0.1058 0.1075 0.1076 0.1140 

[TRAIN] Epoch[7](876/1500); Loss: 0.156621; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1743 0.1713 0.1642 0.1630 0.1590 0.1542 0.1531 0.1524 0.1506 0.1498 0.1508 0.1510 0.1518 0.1516 0.1551 0.1536 

[TRAIN] Epoch[7](877/1500); Loss: 0.116833; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1491 0.1297 0.1358 0.1235 0.1103 0.1058 0.1054 0.1057 0.1071 0.1087 0.1092 0.1120 0.1136 0.1144 0.1208 0.1182 

[TRAIN] Epoch[7](878/1500); Loss: 0.095970; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1168 0.1079 0.1063 0.1014 0.0861 0.0845 0.0864 0.0878 0.0874 0.0893 0.0908 0.0928 0.0954 0.0978 0.1011 0.1036 

[TRAIN] Epoch[7](879/1500); Loss: 0.068846; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0859 0.0814 0.0748 0.0700 0.0643 0.0616 0.0622 0.0604 0.0634 0.0630 0.0648 0.0648 0.0694 0.0688 0.0734 0.0731 

[TRAIN] Epoch[7](880/1500); Loss: 0.129113; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2026 0.1854 0.1786 0.1717 0.1510 0.1356 0.1259 0.1130 0.1070 0.0974 0.0976 0.0979 0.0999 0.0977 0.1020 0.1026 

[TRAIN] Epoch[7](881/1500); Loss: 0.132105; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1509 0.1472 0.1413 0.1385 0.1324 0.1290 0.1256 0.1256 0.1260 0.1244 0.1273 0.1263 0.1288 0.1275 0.1308 0.1321 

[TRAIN] Epoch[7](882/1500); Loss: 0.152828; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2143 0.1842 0.1961 0.1812 0.1600 0.1491 0.1417 0.1373 0.1350 0.1330 0.1329 0.1341 0.1357 0.1353 0.1380 0.1375 

[TRAIN] Epoch[7](883/1500); Loss: 0.123312; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1707 0.1539 0.1447 0.1337 0.1191 0.1115 0.1131 0.1095 0.1120 0.1098 0.1139 0.1123 0.1163 0.1142 0.1182 0.1202 

[TRAIN] Epoch[7](884/1500); Loss: 0.080950; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1405 0.1405 0.0886 0.0674 0.0623 0.0628 0.0634 0.0661 0.0662 0.0680 0.0708 0.0741 0.0761 0.0797 0.0828 0.0860 

[TRAIN] Epoch[7](885/1500); Loss: 0.083289; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1130 0.1056 0.0876 0.0826 0.0794 0.0774 0.0773 0.0758 0.0780 0.0751 0.0796 0.0764 0.0810 0.0781 0.0841 0.0817 

[TRAIN] Epoch[7](886/1500); Loss: 0.132684; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1753 0.1699 0.1465 0.1364 0.1285 0.1252 0.1244 0.1226 0.1242 0.1224 0.1247 0.1227 0.1253 0.1233 0.1259 0.1257 

[TRAIN] Epoch[7](887/1500); Loss: 0.078324; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.0913 0.0891 0.0754 0.0723 0.0753 0.0709 0.0727 0.0734 0.0759 0.0746 0.0775 0.0770 0.0796 0.0796 0.0847 0.0839 

[TRAIN] Epoch[7](888/1500); Loss: 0.147470; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2113 0.1904 0.1936 0.1814 0.1556 0.1389 0.1270 0.1236 0.1260 0.1239 0.1269 0.1301 0.1295 0.1305 0.1356 0.1352 

[TRAIN] Epoch[7](889/1500); Loss: 0.150793; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.2177 0.1996 0.1896 0.1778 0.1578 0.1459 0.1337 0.1265 0.1288 0.1288 0.1282 0.1327 0.1343 0.1345 0.1371 0.1396 

[TRAIN] Epoch[7](890/1500); Loss: 0.079590; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1661 0.1741 0.0969 0.0616 0.0528 0.0520 0.0593 0.0599 0.0588 0.0672 0.0672 0.0672 0.0696 0.0731 0.0714 0.0762 

[TRAIN] Epoch[7](891/1500); Loss: 0.104885; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1337 0.1252 0.1222 0.1167 0.1064 0.1015 0.0994 0.0960 0.0957 0.0944 0.0956 0.0953 0.0970 0.0974 0.1007 0.1010 

[TRAIN] Epoch[7](892/1500); Loss: 0.115464; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1371 0.1294 0.1235 0.1197 0.1102 0.1066 0.1056 0.1035 0.1060 0.1053 0.1092 0.1113 0.1147 0.1190 0.1206 0.1256 

[TRAIN] Epoch[7](893/1500); Loss: 0.096339; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1206 0.1123 0.0997 0.0972 0.0950 0.0920 0.0922 0.0904 0.0920 0.0894 0.0928 0.0902 0.0943 0.0920 0.0970 0.0944 

[TRAIN] Epoch[7](894/1500); Loss: 0.102610; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1897 0.2186 0.0640 0.0641 0.0693 0.0757 0.0759 0.0935 0.0868 0.0959 0.0924 0.0991 0.0975 0.1067 0.1023 0.1103 

[TRAIN] Epoch[7](895/1500); Loss: 0.097974; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1290 0.1249 0.1010 0.0924 0.0914 0.0874 0.0903 0.0890 0.0898 0.0892 0.0935 0.0934 0.0955 0.0981 0.1011 0.1016 

[TRAIN] Epoch[7](896/1500); Loss: 0.172185; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2042 0.1958 0.1932 0.1870 0.1775 0.1705 0.1658 0.1615 0.1581 0.1587 0.1600 0.1605 0.1624 0.1649 0.1668 0.1683 

[TRAIN] Epoch[7](897/1500); Loss: 0.127142; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1510 0.1427 0.1347 0.1300 0.1252 0.1187 0.1208 0.1181 0.1212 0.1190 0.1225 0.1212 0.1261 0.1253 0.1302 0.1276 

[TRAIN] Epoch[7](898/1500); Loss: 0.126161; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1332 0.1372 0.1259 0.1261 0.1236 0.1217 0.1227 0.1220 0.1220 0.1222 0.1244 0.1238 0.1276 0.1272 0.1299 0.1291 

[TRAIN] Epoch[7](899/1500); Loss: 0.137914; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2022 0.1976 0.1644 0.1532 0.1398 0.1331 0.1263 0.1193 0.1147 0.1155 0.1194 0.1185 0.1235 0.1233 0.1280 0.1279 

[TRAIN] Epoch[7](900/1500); Loss: 0.089483; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.0981 0.0965 0.0913 0.0878 0.0812 0.0779 0.0782 0.0802 0.0828 0.0853 0.0891 0.0891 0.0926 0.0972 0.0999 0.1045 

[TRAIN] Epoch[7](901/1500); Loss: 0.120340; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1649 0.1611 0.1502 0.1442 0.1311 0.1202 0.1129 0.1043 0.1003 0.0978 0.1022 0.1022 0.1046 0.1077 0.1097 0.1121 

[TRAIN] Epoch[7](902/1500); Loss: 0.177747; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2262 0.2161 0.2218 0.2120 0.1983 0.1868 0.1765 0.1646 0.1555 0.1521 0.1535 0.1538 0.1534 0.1549 0.1589 0.1595 

[TRAIN] Epoch[7](903/1500); Loss: 0.088677; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1256 0.1058 0.1105 0.0992 0.0816 0.0733 0.0726 0.0747 0.0748 0.0773 0.0797 0.0820 0.0851 0.0899 0.0913 0.0954 

[TRAIN] Epoch[7](904/1500); Loss: 0.092294; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1286 0.1392 0.0997 0.0977 0.0861 0.0797 0.0789 0.0790 0.0800 0.0801 0.0816 0.0846 0.0865 0.0883 0.0914 0.0955 

[TRAIN] Epoch[7](905/1500); Loss: 0.094167; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1192 0.1140 0.0972 0.0937 0.0905 0.0892 0.0898 0.0874 0.0902 0.0869 0.0909 0.0876 0.0932 0.0894 0.0955 0.0921 

[TRAIN] Epoch[7](906/1500); Loss: 0.100085; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1185 0.1288 0.0982 0.1009 0.0925 0.0884 0.0922 0.0897 0.0956 0.0897 0.0993 0.0944 0.1030 0.0973 0.1079 0.1052 

[TRAIN] Epoch[7](907/1500); Loss: 0.130176; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1710 0.1545 0.1535 0.1446 0.1300 0.1222 0.1193 0.1169 0.1175 0.1171 0.1194 0.1193 0.1226 0.1223 0.1264 0.1263 

[TRAIN] Epoch[7](908/1500); Loss: 0.126721; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2145 0.2101 0.1690 0.1443 0.1224 0.1091 0.1048 0.1024 0.1024 0.1013 0.1050 0.1042 0.1078 0.1074 0.1104 0.1125 

[TRAIN] Epoch[7](909/1500); Loss: 0.155474; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.2241 0.1970 0.1983 0.1842 0.1628 0.1480 0.1403 0.1332 0.1320 0.1344 0.1357 0.1369 0.1379 0.1398 0.1405 0.1425 

[TRAIN] Epoch[7](910/1500); Loss: 0.153588; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2091 0.2074 0.1783 0.1680 0.1516 0.1424 0.1418 0.1382 0.1429 0.1369 0.1442 0.1365 0.1393 0.1383 0.1424 0.1399 

[TRAIN] Epoch[7](911/1500); Loss: 0.185208; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2266 0.2107 0.2041 0.1988 0.1898 0.1829 0.1790 0.1773 0.1750 0.1735 0.1739 0.1728 0.1738 0.1740 0.1761 0.1750 

[TRAIN] Epoch[7](912/1500); Loss: 0.161028; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1897 0.1752 0.1758 0.1680 0.1590 0.1562 0.1538 0.1534 0.1535 0.1531 0.1547 0.1546 0.1555 0.1566 0.1581 0.1591 

[TRAIN] Epoch[7](913/1500); Loss: 0.122582; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1331 0.1317 0.1255 0.1249 0.1219 0.1195 0.1179 0.1166 0.1174 0.1174 0.1191 0.1209 0.1201 0.1236 0.1243 0.1271 

[TRAIN] Epoch[7](914/1500); Loss: 0.152757; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1936 0.1956 0.1597 0.1622 0.1486 0.1443 0.1420 0.1406 0.1417 0.1397 0.1428 0.1422 0.1462 0.1460 0.1492 0.1497 

[TRAIN] Epoch[7](915/1500); Loss: 0.098949; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1326 0.1160 0.1179 0.1089 0.0929 0.0861 0.0902 0.0887 0.0877 0.0906 0.0909 0.0934 0.0941 0.0960 0.0970 0.1001 

[TRAIN] Epoch[7](916/1500); Loss: 0.131801; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1562 0.1591 0.1425 0.1379 0.1267 0.1225 0.1222 0.1212 0.1227 0.1244 0.1233 0.1267 0.1273 0.1294 0.1327 0.1340 

[TRAIN] Epoch[7](917/1500); Loss: 0.138104; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1978 0.2358 0.0897 0.1164 0.0880 0.0990 0.1125 0.1135 0.1380 0.1267 0.1385 0.1410 0.1522 0.1499 0.1540 0.1569 

[TRAIN] Epoch[7](918/1500); Loss: 0.098477; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1379 0.1300 0.1129 0.1027 0.0923 0.0870 0.0883 0.0866 0.0897 0.0871 0.0913 0.0889 0.0943 0.0923 0.0966 0.0979 

[TRAIN] Epoch[7](919/1500); Loss: 0.190576; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2391 0.2309 0.2187 0.2108 0.1984 0.1879 0.1821 0.1777 0.1756 0.1744 0.1753 0.1733 0.1758 0.1747 0.1772 0.1772 

[TRAIN] Epoch[7](920/1500); Loss: 0.116635; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1656 0.1437 0.1461 0.1335 0.1186 0.1063 0.0982 0.0980 0.0992 0.0975 0.1022 0.1046 0.1088 0.1090 0.1152 0.1197 

[TRAIN] Epoch[7](921/1500); Loss: 0.096742; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1096 0.1117 0.0985 0.0960 0.0922 0.0920 0.0920 0.0913 0.0930 0.0918 0.0945 0.0938 0.0959 0.0967 0.0987 0.1002 

[TRAIN] Epoch[7](922/1500); Loss: 0.066181; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1045 0.1143 0.0609 0.0494 0.0499 0.0504 0.0537 0.0542 0.0599 0.0562 0.0645 0.0615 0.0702 0.0652 0.0745 0.0698 

[TRAIN] Epoch[7](923/1500); Loss: 0.077607; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0925 0.1129 0.0623 0.0697 0.0627 0.0639 0.0682 0.0668 0.0732 0.0707 0.0796 0.0771 0.0828 0.0819 0.0892 0.0880 

[TRAIN] Epoch[7](924/1500); Loss: 0.139362; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1831 0.1876 0.1549 0.1431 0.1337 0.1284 0.1263 0.1266 0.1271 0.1260 0.1295 0.1282 0.1324 0.1312 0.1369 0.1351 

[TRAIN] Epoch[7](925/1500); Loss: 0.101747; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1398 0.1176 0.1194 0.1078 0.0968 0.0933 0.0917 0.0909 0.0929 0.0923 0.0944 0.0955 0.0953 0.0985 0.0999 0.1017 

[TRAIN] Epoch[7](926/1500); Loss: 0.071212; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0785 0.0989 0.0606 0.0620 0.0592 0.0567 0.0607 0.0613 0.0677 0.0636 0.0709 0.0735 0.0798 0.0773 0.0828 0.0862 

[TRAIN] Epoch[7](927/1500); Loss: 0.130152; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1479 0.1400 0.1356 0.1313 0.1272 0.1243 0.1238 0.1249 0.1247 0.1256 0.1267 0.1272 0.1287 0.1303 0.1312 0.1331 

[TRAIN] Epoch[7](928/1500); Loss: 0.116329; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1311 0.1310 0.1198 0.1147 0.1083 0.1060 0.1073 0.1081 0.1109 0.1097 0.1143 0.1160 0.1195 0.1170 0.1245 0.1230 

[TRAIN] Epoch[7](929/1500); Loss: 0.104315; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1505 0.1629 0.1082 0.1030 0.0898 0.0854 0.0892 0.0922 0.0929 0.0911 0.0964 0.0971 0.1003 0.0975 0.1080 0.1044 

[TRAIN] Epoch[7](930/1500); Loss: 0.113140; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1582 0.1686 0.1235 0.1103 0.0982 0.0970 0.0984 0.0967 0.1022 0.0988 0.1062 0.1027 0.1086 0.1104 0.1126 0.1178 

[TRAIN] Epoch[7](931/1500); Loss: 0.091783; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1139 0.1070 0.1039 0.0993 0.0916 0.0897 0.0861 0.0846 0.0845 0.0843 0.0845 0.0854 0.0861 0.0874 0.0898 0.0906 

[TRAIN] Epoch[7](932/1500); Loss: 0.153110; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2113 0.2013 0.1733 0.1639 0.1494 0.1414 0.1388 0.1364 0.1367 0.1349 0.1396 0.1391 0.1430 0.1444 0.1488 0.1473 

[TRAIN] Epoch[7](933/1500); Loss: 0.109512; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1871 0.1584 0.1617 0.1463 0.1186 0.0978 0.0852 0.0851 0.0859 0.0837 0.0881 0.0867 0.0901 0.0901 0.0947 0.0928 

[TRAIN] Epoch[7](934/1500); Loss: 0.092485; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1426 0.1235 0.1109 0.0961 0.0867 0.0832 0.0791 0.0812 0.0801 0.0808 0.0838 0.0825 0.0865 0.0854 0.0856 0.0917 

[TRAIN] Epoch[7](935/1500); Loss: 0.241031; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.3079 0.2944 0.2993 0.2896 0.2712 0.2584 0.2451 0.2284 0.2211 0.2117 0.2062 0.2059 0.2033 0.2037 0.2044 0.2057 

[TRAIN] Epoch[7](936/1500); Loss: 0.157926; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1913 0.1820 0.1771 0.1719 0.1586 0.1548 0.1495 0.1468 0.1476 0.1470 0.1471 0.1484 0.1503 0.1491 0.1505 0.1547 

[TRAIN] Epoch[7](937/1500); Loss: 0.078377; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0930 0.0858 0.0942 0.0846 0.0735 0.0713 0.0686 0.0669 0.0715 0.0718 0.0725 0.0768 0.0774 0.0804 0.0809 0.0849 

[TRAIN] Epoch[7](938/1500); Loss: 0.104138; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1512 0.1636 0.1111 0.0955 0.0886 0.0878 0.0908 0.0910 0.0933 0.0908 0.0976 0.0960 0.0995 0.1007 0.1036 0.1051 

[TRAIN] Epoch[7](939/1500); Loss: 0.074063; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0839 0.0798 0.0837 0.0730 0.0670 0.0649 0.0643 0.0665 0.0673 0.0674 0.0725 0.0726 0.0759 0.0802 0.0815 0.0846 

[TRAIN] Epoch[7](940/1500); Loss: 0.071194; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1436 0.1091 0.1174 0.0965 0.0686 0.0537 0.0474 0.0473 0.0489 0.0500 0.0528 0.0556 0.0565 0.0604 0.0633 0.0680 

[TRAIN] Epoch[7](941/1500); Loss: 0.149047; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2110 0.2033 0.1739 0.1582 0.1454 0.1378 0.1336 0.1299 0.1297 0.1292 0.1339 0.1340 0.1383 0.1402 0.1429 0.1435 

[TRAIN] Epoch[7](942/1500); Loss: 0.172570; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2744 0.2488 0.2476 0.2328 0.2029 0.1843 0.1629 0.1417 0.1338 0.1300 0.1314 0.1295 0.1329 0.1343 0.1380 0.1359 

[TRAIN] Epoch[7](943/1500); Loss: 0.154541; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1762 0.1797 0.1582 0.1568 0.1502 0.1485 0.1480 0.1482 0.1475 0.1468 0.1490 0.1502 0.1514 0.1522 0.1538 0.1560 

[TRAIN] Epoch[7](944/1500); Loss: 0.105883; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1853 0.2026 0.1233 0.0940 0.0775 0.0779 0.0822 0.0828 0.0841 0.0857 0.0944 0.0937 0.0971 0.1016 0.1046 0.1074 

[TRAIN] Epoch[7](945/1500); Loss: 0.182704; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.3801 0.3284 0.3396 0.3083 0.2507 0.2056 0.1560 0.1074 0.0966 0.1039 0.1008 0.1042 0.1103 0.1057 0.1102 0.1154 

[TRAIN] Epoch[7](946/1500); Loss: 0.211512; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.3458 0.3020 0.3069 0.2840 0.2395 0.2049 0.1775 0.1629 0.1651 0.1655 0.1675 0.1688 0.1713 0.1721 0.1744 0.1762 

[TRAIN] Epoch[7](947/1500); Loss: 0.137713; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1661 0.1612 0.1476 0.1383 0.1344 0.1308 0.1320 0.1291 0.1316 0.1290 0.1325 0.1299 0.1349 0.1323 0.1379 0.1359 

[TRAIN] Epoch[7](948/1500); Loss: 0.103792; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2315 0.2538 0.1397 0.0868 0.0646 0.0643 0.0735 0.0721 0.0795 0.0744 0.0811 0.0817 0.0869 0.0872 0.0922 0.0914 

[TRAIN] Epoch[7](949/1500); Loss: 0.173856; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2114 0.1971 0.1969 0.1889 0.1793 0.1731 0.1658 0.1641 0.1615 0.1596 0.1613 0.1626 0.1620 0.1647 0.1647 0.1687 

[TRAIN] Epoch[7](950/1500); Loss: 0.110024; Backpropagation: 0.0923 sec; Batch: 0.4241 sec
0.1563 0.1621 0.1255 0.1102 0.0928 0.0918 0.0926 0.0930 0.0983 0.0972 0.1007 0.1034 0.1075 0.1069 0.1102 0.1119 

[TRAIN] Epoch[7](951/1500); Loss: 0.159607; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1851 0.1807 0.1653 0.1619 0.1572 0.1539 0.1538 0.1523 0.1524 0.1521 0.1537 0.1555 0.1552 0.1571 0.1584 0.1590 

[TRAIN] Epoch[7](952/1500); Loss: 0.172496; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2153 0.2047 0.2018 0.1903 0.1799 0.1708 0.1634 0.1611 0.1595 0.1572 0.1581 0.1568 0.1587 0.1578 0.1621 0.1623 

[TRAIN] Epoch[7](953/1500); Loss: 0.113910; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1351 0.1257 0.1239 0.1186 0.1125 0.1087 0.1079 0.1062 0.1080 0.1067 0.1089 0.1083 0.1112 0.1113 0.1144 0.1153 

[TRAIN] Epoch[7](954/1500); Loss: 0.125104; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2156 0.2093 0.1759 0.1395 0.1108 0.1071 0.1020 0.0960 0.1035 0.0965 0.1024 0.1051 0.1081 0.1072 0.1101 0.1124 

[TRAIN] Epoch[7](955/1500); Loss: 0.088915; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1244 0.1212 0.1024 0.0949 0.0877 0.0816 0.0813 0.0773 0.0799 0.0761 0.0805 0.0771 0.0830 0.0811 0.0888 0.0853 

[TRAIN] Epoch[7](956/1500); Loss: 0.160499; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2413 0.2227 0.2111 0.1996 0.1828 0.1699 0.1594 0.1455 0.1359 0.1280 0.1271 0.1279 0.1274 0.1298 0.1290 0.1306 

[TRAIN] Epoch[7](957/1500); Loss: 0.075284; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0893 0.0844 0.0778 0.0771 0.0717 0.0696 0.0704 0.0683 0.0714 0.0704 0.0735 0.0713 0.0770 0.0736 0.0812 0.0774 

[TRAIN] Epoch[7](958/1500); Loss: 0.177373; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3624 0.3146 0.3189 0.2907 0.2381 0.1944 0.1467 0.1062 0.1020 0.1086 0.1033 0.1040 0.1097 0.1084 0.1119 0.1180 

[TRAIN] Epoch[7](959/1500); Loss: 0.129096; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1543 0.1466 0.1408 0.1349 0.1304 0.1260 0.1259 0.1230 0.1246 0.1210 0.1235 0.1210 0.1239 0.1219 0.1241 0.1238 

[TRAIN] Epoch[7](960/1500); Loss: 0.080430; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1810 0.1963 0.1168 0.0763 0.0464 0.0540 0.0530 0.0502 0.0607 0.0540 0.0651 0.0609 0.0662 0.0669 0.0705 0.0687 

[TRAIN] Epoch[7](961/1500); Loss: 0.084571; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0978 0.0919 0.0892 0.0847 0.0792 0.0758 0.0791 0.0763 0.0780 0.0775 0.0804 0.0822 0.0856 0.0894 0.0902 0.0958 

[TRAIN] Epoch[7](962/1500); Loss: 0.101616; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1368 0.1371 0.1211 0.1075 0.0964 0.0892 0.0900 0.0901 0.0905 0.0922 0.0928 0.0946 0.0950 0.0967 0.0969 0.0990 

[TRAIN] Epoch[7](963/1500); Loss: 0.099831; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1025 0.0969 0.0977 0.0948 0.0906 0.0911 0.0917 0.0918 0.0967 0.0989 0.0998 0.1028 0.1058 0.1092 0.1120 0.1149 

[TRAIN] Epoch[7](964/1500); Loss: 0.106066; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1139 0.1094 0.1101 0.1082 0.1067 0.1062 0.1051 0.1014 0.1004 0.1007 0.1031 0.1034 0.1052 0.1060 0.1085 0.1088 

[TRAIN] Epoch[7](965/1500); Loss: 0.126234; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1413 0.1378 0.1303 0.1247 0.1228 0.1216 0.1211 0.1218 0.1212 0.1217 0.1229 0.1231 0.1264 0.1246 0.1299 0.1284 

[TRAIN] Epoch[7](966/1500); Loss: 0.156711; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.2205 0.2053 0.1965 0.1751 0.1579 0.1500 0.1441 0.1382 0.1382 0.1337 0.1373 0.1355 0.1424 0.1401 0.1464 0.1462 

[TRAIN] Epoch[7](967/1500); Loss: 0.117992; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1335 0.1337 0.1159 0.1151 0.1123 0.1118 0.1138 0.1124 0.1154 0.1138 0.1156 0.1158 0.1189 0.1178 0.1216 0.1205 

[TRAIN] Epoch[7](968/1500); Loss: 0.115517; Backpropagation: 0.0918 sec; Batch: 0.4261 sec
0.1453 0.1414 0.1259 0.1219 0.1150 0.1122 0.1092 0.1079 0.1062 0.1057 0.1069 0.1065 0.1095 0.1088 0.1131 0.1129 

[TRAIN] Epoch[7](969/1500); Loss: 0.121222; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1648 0.1509 0.1343 0.1221 0.1133 0.1130 0.1119 0.1146 0.1108 0.1144 0.1105 0.1145 0.1128 0.1180 0.1143 0.1194 

[TRAIN] Epoch[7](970/1500); Loss: 0.074751; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1237 0.1030 0.0971 0.0821 0.0650 0.0573 0.0602 0.0603 0.0584 0.0633 0.0629 0.0689 0.0667 0.0738 0.0742 0.0792 

[TRAIN] Epoch[7](971/1500); Loss: 0.161367; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1906 0.1818 0.1782 0.1739 0.1673 0.1619 0.1583 0.1539 0.1522 0.1510 0.1522 0.1509 0.1525 0.1513 0.1541 0.1518 

[TRAIN] Epoch[7](972/1500); Loss: 0.129316; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1501 0.1428 0.1373 0.1321 0.1270 0.1229 0.1223 0.1213 0.1234 0.1208 0.1255 0.1232 0.1291 0.1266 0.1337 0.1309 

[TRAIN] Epoch[7](973/1500); Loss: 0.095659; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1284 0.1356 0.1049 0.0935 0.0860 0.0837 0.0839 0.0849 0.0851 0.0871 0.0878 0.0897 0.0918 0.0936 0.0959 0.0985 

[TRAIN] Epoch[7](974/1500); Loss: 0.114264; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1746 0.2004 0.0935 0.0916 0.0846 0.0928 0.0958 0.1003 0.1019 0.1011 0.1060 0.1109 0.1119 0.1197 0.1219 0.1213 

[TRAIN] Epoch[7](975/1500); Loss: 0.109285; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2258 0.1775 0.1839 0.1555 0.1117 0.0860 0.0698 0.0779 0.0737 0.0724 0.0796 0.0806 0.0821 0.0884 0.0900 0.0937 

[TRAIN] Epoch[7](976/1500); Loss: 0.239178; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2606 0.2536 0.2505 0.2478 0.2458 0.2435 0.2387 0.2370 0.2324 0.2321 0.2318 0.2316 0.2301 0.2309 0.2305 0.2299 

[TRAIN] Epoch[7](977/1500); Loss: 0.136020; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1668 0.1549 0.1486 0.1426 0.1327 0.1273 0.1265 0.1254 0.1266 0.1269 0.1299 0.1294 0.1333 0.1327 0.1368 0.1360 

[TRAIN] Epoch[7](978/1500); Loss: 0.099046; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2154 0.1819 0.1685 0.1375 0.1022 0.0819 0.0678 0.0678 0.0708 0.0650 0.0715 0.0656 0.0716 0.0682 0.0766 0.0725 

[TRAIN] Epoch[7](979/1500); Loss: 0.122830; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1721 0.1644 0.1461 0.1336 0.1214 0.1145 0.1108 0.1082 0.1083 0.1099 0.1090 0.1117 0.1114 0.1134 0.1141 0.1164 

[TRAIN] Epoch[7](980/1500); Loss: 0.092099; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0952 0.0964 0.0900 0.0899 0.0877 0.0874 0.0881 0.0879 0.0899 0.0894 0.0928 0.0917 0.0957 0.0947 0.0991 0.0979 

[TRAIN] Epoch[7](981/1500); Loss: 0.092002; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2178 0.1730 0.1669 0.1424 0.1052 0.0801 0.0634 0.0541 0.0544 0.0544 0.0556 0.0562 0.0596 0.0597 0.0644 0.0649 

[TRAIN] Epoch[7](982/1500); Loss: 0.221521; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2488 0.2414 0.2446 0.2372 0.2271 0.2211 0.2169 0.2107 0.2091 0.2096 0.2093 0.2102 0.2116 0.2144 0.2153 0.2171 

[TRAIN] Epoch[7](983/1500); Loss: 0.141269; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2326 0.2176 0.1988 0.1868 0.1638 0.1494 0.1356 0.1161 0.1104 0.1010 0.1096 0.1041 0.1077 0.1065 0.1104 0.1099 

[TRAIN] Epoch[7](984/1500); Loss: 0.117455; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1349 0.1294 0.1225 0.1207 0.1157 0.1118 0.1120 0.1092 0.1131 0.1107 0.1152 0.1118 0.1186 0.1143 0.1221 0.1176 

[TRAIN] Epoch[7](985/1500); Loss: 0.122138; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1594 0.1612 0.1307 0.1186 0.1105 0.1083 0.1095 0.1071 0.1128 0.1083 0.1178 0.1129 0.1232 0.1181 0.1299 0.1259 

[TRAIN] Epoch[7](986/1500); Loss: 0.136888; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1631 0.1560 0.1465 0.1417 0.1344 0.1309 0.1297 0.1285 0.1299 0.1284 0.1319 0.1302 0.1340 0.1321 0.1373 0.1356 

[TRAIN] Epoch[7](987/1500); Loss: 0.129010; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1729 0.1593 0.1426 0.1305 0.1195 0.1165 0.1175 0.1156 0.1209 0.1165 0.1224 0.1203 0.1273 0.1225 0.1313 0.1285 

[TRAIN] Epoch[7](988/1500); Loss: 0.161568; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2508 0.2201 0.2214 0.2046 0.1767 0.1587 0.1465 0.1364 0.1314 0.1318 0.1314 0.1330 0.1341 0.1343 0.1368 0.1370 

[TRAIN] Epoch[7](989/1500); Loss: 0.107617; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1412 0.1473 0.1078 0.0951 0.0966 0.0958 0.0959 0.1016 0.0981 0.1022 0.1023 0.1038 0.1033 0.1098 0.1097 0.1113 

[TRAIN] Epoch[7](990/1500); Loss: 0.099582; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1167 0.1093 0.1042 0.0951 0.0907 0.0890 0.0900 0.0929 0.0924 0.0936 0.0985 0.0975 0.1031 0.1023 0.1093 0.1087 

[TRAIN] Epoch[7](991/1500); Loss: 0.080023; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.0943 0.1138 0.0713 0.0709 0.0626 0.0631 0.0680 0.0660 0.0749 0.0706 0.0811 0.0771 0.0908 0.0864 0.0954 0.0941 

[TRAIN] Epoch[7](992/1500); Loss: 0.072561; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.0659 0.0735 0.0668 0.0668 0.0664 0.0630 0.0662 0.0645 0.0694 0.0684 0.0762 0.0740 0.0821 0.0812 0.0892 0.0872 

[TRAIN] Epoch[7](993/1500); Loss: 0.156906; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2352 0.2421 0.1892 0.1572 0.1409 0.1381 0.1406 0.1363 0.1421 0.1343 0.1434 0.1357 0.1432 0.1414 0.1481 0.1427 

[TRAIN] Epoch[7](994/1500); Loss: 0.093996; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1269 0.1383 0.0992 0.0879 0.0814 0.0807 0.0841 0.0811 0.0870 0.0817 0.0886 0.0847 0.0954 0.0906 0.1006 0.0957 

[TRAIN] Epoch[7](995/1500); Loss: 0.091101; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1243 0.1170 0.1130 0.1034 0.0919 0.0829 0.0793 0.0731 0.0796 0.0737 0.0783 0.0779 0.0869 0.0870 0.0932 0.0962 

[TRAIN] Epoch[7](996/1500); Loss: 0.123829; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1590 0.1552 0.1359 0.1237 0.1182 0.1133 0.1130 0.1129 0.1145 0.1144 0.1138 0.1187 0.1162 0.1232 0.1211 0.1284 

[TRAIN] Epoch[7](997/1500); Loss: 0.105776; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1043 0.1068 0.0885 0.0868 0.0877 0.0899 0.0937 0.0964 0.1014 0.1042 0.1090 0.1139 0.1200 0.1246 0.1303 0.1351 

[TRAIN] Epoch[7](998/1500); Loss: 0.079829; Backpropagation: 0.0920 sec; Batch: 0.4229 sec
0.1299 0.1311 0.1055 0.0891 0.0731 0.0669 0.0634 0.0621 0.0647 0.0642 0.0670 0.0664 0.0713 0.0707 0.0766 0.0753 

[TRAIN] Epoch[7](999/1500); Loss: 0.111551; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1598 0.1731 0.1201 0.0997 0.0988 0.0950 0.0958 0.0973 0.0971 0.1003 0.1000 0.1047 0.1049 0.1106 0.1103 0.1173 

[TRAIN] Epoch[7](1000/1500); Loss: 0.075253; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1590 0.1184 0.1243 0.1019 0.0720 0.0573 0.0475 0.0494 0.0481 0.0511 0.0549 0.0572 0.0596 0.0650 0.0661 0.0722 

[TRAIN] Epoch[7](1001/1500); Loss: 0.124320; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2314 0.2307 0.1755 0.1321 0.0989 0.0956 0.0937 0.0933 0.0979 0.0950 0.1033 0.1009 0.1066 0.1075 0.1149 0.1117 

[TRAIN] Epoch[7](1002/1500); Loss: 0.092483; Backpropagation: 0.0997 sec; Batch: 0.4465 sec
0.1141 0.1142 0.0958 0.0884 0.0805 0.0807 0.0824 0.0811 0.0853 0.0843 0.0902 0.0884 0.0965 0.0945 0.1025 0.1009 

[TRAIN] Epoch[7](1003/1500); Loss: 0.161644; Backpropagation: 0.0929 sec; Batch: 0.4257 sec
0.1903 0.1870 0.1718 0.1646 0.1582 0.1555 0.1548 0.1523 0.1551 0.1518 0.1564 0.1537 0.1579 0.1555 0.1616 0.1598 

[TRAIN] Epoch[7](1004/1500); Loss: 0.111198; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2089 0.2065 0.1607 0.1257 0.1028 0.1015 0.0891 0.0915 0.0817 0.0815 0.0820 0.0857 0.0872 0.0889 0.0926 0.0928 

[TRAIN] Epoch[7](1005/1500); Loss: 0.097168; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.2202 0.1695 0.1753 0.1474 0.1020 0.0741 0.0598 0.0651 0.0639 0.0610 0.0651 0.0666 0.0695 0.0670 0.0762 0.0720 

[TRAIN] Epoch[7](1006/1500); Loss: 0.088953; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1107 0.0982 0.0954 0.0909 0.0845 0.0803 0.0809 0.0789 0.0822 0.0817 0.0857 0.0837 0.0907 0.0879 0.0966 0.0950 

[TRAIN] Epoch[7](1007/1500); Loss: 0.110632; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1253 0.1308 0.1045 0.1083 0.1003 0.0956 0.1019 0.0977 0.1075 0.1005 0.1104 0.1077 0.1204 0.1141 0.1229 0.1222 

[TRAIN] Epoch[7](1008/1500); Loss: 0.085369; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1271 0.1170 0.1043 0.0865 0.0694 0.0726 0.0700 0.0718 0.0733 0.0745 0.0768 0.0789 0.0812 0.0851 0.0854 0.0920 

[TRAIN] Epoch[7](1009/1500); Loss: 0.117357; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1331 0.1345 0.1232 0.1194 0.1149 0.1109 0.1102 0.1092 0.1108 0.1101 0.1139 0.1129 0.1172 0.1161 0.1209 0.1205 

[TRAIN] Epoch[7](1010/1500); Loss: 0.115558; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1306 0.1319 0.1186 0.1140 0.1105 0.1083 0.1086 0.1082 0.1106 0.1094 0.1136 0.1126 0.1166 0.1160 0.1198 0.1195 

[TRAIN] Epoch[7](1011/1500); Loss: 0.094352; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1220 0.1072 0.1021 0.0961 0.0898 0.0879 0.0880 0.0871 0.0873 0.0877 0.0881 0.0901 0.0904 0.0936 0.0940 0.0982 

[TRAIN] Epoch[7](1012/1500); Loss: 0.120149; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1643 0.1604 0.1366 0.1177 0.1104 0.1069 0.1082 0.1040 0.1110 0.1058 0.1136 0.1091 0.1187 0.1137 0.1229 0.1191 

[TRAIN] Epoch[7](1013/1500); Loss: 0.098695; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1485 0.1419 0.1180 0.1043 0.0971 0.0932 0.0937 0.0874 0.0889 0.0824 0.0881 0.0824 0.0893 0.0844 0.0920 0.0875 

[TRAIN] Epoch[7](1014/1500); Loss: 0.120451; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1625 0.1424 0.1358 0.1220 0.1100 0.1117 0.1090 0.1099 0.1090 0.1120 0.1115 0.1155 0.1147 0.1193 0.1186 0.1235 

[TRAIN] Epoch[7](1015/1500); Loss: 0.144939; Backpropagation: 0.0922 sec; Batch: 0.4232 sec
0.2184 0.2166 0.1753 0.1441 0.1286 0.1262 0.1306 0.1271 0.1335 0.1277 0.1311 0.1289 0.1323 0.1299 0.1354 0.1334 

[TRAIN] Epoch[7](1016/1500); Loss: 0.061849; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1310 0.1098 0.0851 0.0623 0.0417 0.0427 0.0418 0.0421 0.0465 0.0451 0.0528 0.0487 0.0592 0.0542 0.0659 0.0606 

[TRAIN] Epoch[7](1017/1500); Loss: 0.112847; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1582 0.1342 0.1430 0.1364 0.1177 0.1046 0.0953 0.0977 0.0979 0.0979 0.0976 0.1008 0.1022 0.1063 0.1056 0.1101 

[TRAIN] Epoch[7](1018/1500); Loss: 0.159566; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1681 0.1700 0.1625 0.1624 0.1594 0.1575 0.1569 0.1563 0.1560 0.1548 0.1557 0.1577 0.1576 0.1581 0.1587 0.1612 

[TRAIN] Epoch[7](1019/1500); Loss: 0.128396; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1417 0.1329 0.1340 0.1293 0.1296 0.1256 0.1256 0.1237 0.1252 0.1231 0.1264 0.1244 0.1273 0.1264 0.1295 0.1296 

[TRAIN] Epoch[7](1020/1500); Loss: 0.079135; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0867 0.0912 0.0779 0.0749 0.0723 0.0720 0.0735 0.0726 0.0774 0.0751 0.0800 0.0769 0.0838 0.0804 0.0873 0.0841 

[TRAIN] Epoch[7](1021/1500); Loss: 0.082304; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1057 0.0844 0.0876 0.0793 0.0747 0.0774 0.0760 0.0769 0.0772 0.0796 0.0781 0.0822 0.0803 0.0853 0.0831 0.0890 

[TRAIN] Epoch[7](1022/1500); Loss: 0.088736; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0939 0.0974 0.0884 0.0848 0.0856 0.0841 0.0838 0.0844 0.0851 0.0855 0.0870 0.0890 0.0892 0.0924 0.0928 0.0963 

[TRAIN] Epoch[7](1023/1500); Loss: 0.080490; Backpropagation: 0.0921 sec; Batch: 0.4249 sec
0.0887 0.0785 0.0775 0.0872 0.0789 0.0749 0.0742 0.0704 0.0731 0.0733 0.0803 0.0798 0.0820 0.0868 0.0901 0.0920 

[TRAIN] Epoch[7](1024/1500); Loss: 0.118828; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1504 0.1694 0.1027 0.1090 0.0990 0.1022 0.1060 0.1040 0.1128 0.1103 0.1152 0.1156 0.1251 0.1227 0.1263 0.1305 

[TRAIN] Epoch[7](1025/1500); Loss: 0.125289; Backpropagation: 0.0919 sec; Batch: 0.4248 sec
0.1465 0.1465 0.1299 0.1258 0.1246 0.1214 0.1230 0.1192 0.1231 0.1175 0.1207 0.1170 0.1246 0.1190 0.1246 0.1211 

[TRAIN] Epoch[7](1026/1500); Loss: 0.105310; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1142 0.1105 0.1003 0.0978 0.0959 0.0938 0.0956 0.0958 0.0986 0.1001 0.1052 0.1072 0.1114 0.1142 0.1201 0.1242 

[TRAIN] Epoch[7](1027/1500); Loss: 0.122304; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1971 0.1785 0.1741 0.1476 0.1257 0.1099 0.1051 0.0971 0.0969 0.0962 0.0990 0.1026 0.1042 0.1046 0.1092 0.1091 

[TRAIN] Epoch[7](1028/1500); Loss: 0.164526; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2299 0.2055 0.2257 0.2115 0.1877 0.1676 0.1550 0.1453 0.1438 0.1388 0.1375 0.1359 0.1370 0.1370 0.1361 0.1381 

[TRAIN] Epoch[7](1029/1500); Loss: 0.098438; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1232 0.1060 0.1163 0.1094 0.0956 0.0880 0.0901 0.0888 0.0899 0.0912 0.0933 0.0924 0.0944 0.0981 0.0991 0.0992 

[TRAIN] Epoch[7](1030/1500); Loss: 0.102412; Backpropagation: 0.0921 sec; Batch: 0.4249 sec
0.1688 0.1365 0.1590 0.1408 0.1130 0.0968 0.0872 0.0790 0.0764 0.0785 0.0807 0.0792 0.0833 0.0847 0.0883 0.0864 

[TRAIN] Epoch[7](1031/1500); Loss: 0.107674; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1799 0.1457 0.1740 0.1555 0.1254 0.0977 0.0822 0.0775 0.0797 0.0800 0.0808 0.0839 0.0860 0.0875 0.0920 0.0953 

[TRAIN] Epoch[7](1032/1500); Loss: 0.123014; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1460 0.1395 0.1241 0.1250 0.1259 0.1201 0.1221 0.1184 0.1191 0.1174 0.1172 0.1162 0.1184 0.1185 0.1207 0.1197 

[TRAIN] Epoch[7](1033/1500); Loss: 0.111486; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1337 0.1248 0.1241 0.1202 0.1132 0.1089 0.1101 0.1065 0.1044 0.1037 0.1041 0.1044 0.1040 0.1056 0.1076 0.1083 

[TRAIN] Epoch[7](1034/1500); Loss: 0.082517; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1353 0.1275 0.0875 0.0742 0.0723 0.0755 0.0728 0.0758 0.0736 0.0719 0.0731 0.0733 0.0738 0.0757 0.0777 0.0803 

[TRAIN] Epoch[7](1035/1500); Loss: 0.199221; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.2128 0.2037 0.2145 0.2073 0.2027 0.2025 0.2001 0.1954 0.1939 0.1956 0.1929 0.1897 0.1937 0.1937 0.1938 0.1952 

[TRAIN] Epoch[7](1036/1500); Loss: 0.110945; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1301 0.1190 0.1063 0.1109 0.1047 0.1026 0.1088 0.1065 0.1055 0.1084 0.1084 0.1087 0.1113 0.1128 0.1141 0.1169 

[TRAIN] Epoch[7](1037/1500); Loss: 0.212384; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.2228 0.2189 0.2174 0.2125 0.2088 0.2100 0.2095 0.2089 0.2083 0.2097 0.2105 0.2100 0.2109 0.2129 0.2136 0.2136 

[TRAIN] Epoch[7](1038/1500); Loss: 0.268716; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2178 0.2127 0.2520 0.2429 0.2505 0.2658 0.2649 0.2662 0.2763 0.2787 0.2811 0.2895 0.2923 0.2963 0.3045 0.3079 

[TRAIN] Epoch[7](1039/1500); Loss: 0.190082; Backpropagation: 0.0921 sec; Batch: 0.4248 sec
0.1412 0.1216 0.1317 0.1483 0.1487 0.1631 0.1785 0.1817 0.1931 0.2059 0.2111 0.2229 0.2335 0.2421 0.2532 0.2646 

[TRAIN] Epoch[7](1040/1500); Loss: 0.150865; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0711 0.0671 0.0797 0.1074 0.1120 0.1258 0.1430 0.1468 0.1563 0.1719 0.1796 0.1875 0.2013 0.2109 0.2202 0.2331 

[TRAIN] Epoch[7](1041/1500); Loss: 0.241797; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1892 0.1864 0.2199 0.2145 0.2188 0.2330 0.2342 0.2374 0.2476 0.2515 0.2563 0.2647 0.2691 0.2749 0.2833 0.2881 

[TRAIN] Epoch[7](1042/1500); Loss: 0.142869; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1434 0.1321 0.1006 0.1010 0.1024 0.1089 0.1141 0.1290 0.1363 0.1428 0.1563 0.1652 0.1716 0.1848 0.1956 0.2018 

[TRAIN] Epoch[7](1043/1500); Loss: 0.332262; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2511 0.2462 0.2817 0.2694 0.2787 0.3029 0.3104 0.3192 0.3395 0.3481 0.3592 0.3777 0.3870 0.3997 0.4181 0.4274 

[TRAIN] Epoch[7](1044/1500); Loss: 0.138696; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.0934 0.0877 0.0944 0.1095 0.1089 0.1186 0.1286 0.1326 0.1405 0.1501 0.1558 0.1633 0.1724 0.1793 0.1876 0.1966 

[TRAIN] Epoch[7](1045/1500); Loss: 0.139809; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1250 0.1134 0.1076 0.1111 0.1119 0.1176 0.1233 0.1295 0.1366 0.1431 0.1506 0.1582 0.1656 0.1737 0.1812 0.1886 

[TRAIN] Epoch[7](1046/1500); Loss: 0.378382; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2421 0.2473 0.3168 0.3081 0.3223 0.3530 0.3599 0.3720 0.3951 0.4028 0.4177 0.4383 0.4467 0.4610 0.4807 0.4903 

[TRAIN] Epoch[7](1047/1500); Loss: 0.196195; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1337 0.1355 0.1527 0.1516 0.1572 0.1730 0.1778 0.1853 0.1999 0.2065 0.2157 0.2305 0.2380 0.2477 0.2630 0.2710 

[TRAIN] Epoch[7](1048/1500); Loss: 0.299950; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1526 0.1457 0.1385 0.1452 0.1822 0.2163 0.2422 0.2791 0.3081 0.3351 0.3673 0.3986 0.4261 0.4569 0.4887 0.5167 

[TRAIN] Epoch[7](1049/1500); Loss: 0.238601; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2022 0.1935 0.1720 0.1660 0.1688 0.1837 0.1982 0.2104 0.2315 0.2476 0.2620 0.2830 0.2983 0.3140 0.3363 0.3502 

[TRAIN] Epoch[7](1050/1500); Loss: 0.480878; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2900 0.3071 0.3489 0.3510 0.3684 0.4125 0.4299 0.4574 0.4973 0.5167 0.5441 0.5824 0.6017 0.6301 0.6686 0.6881 

[TRAIN] Epoch[7](1051/1500); Loss: 0.406135; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2760 0.2798 0.3382 0.3295 0.3430 0.3755 0.3817 0.3938 0.4196 0.4291 0.4426 0.4679 0.4787 0.4934 0.5191 0.5301 

[TRAIN] Epoch[7](1052/1500); Loss: 0.197679; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0899 0.0818 0.0899 0.0918 0.1166 0.1504 0.1627 0.1823 0.2123 0.2247 0.2414 0.2685 0.2842 0.3000 0.3243 0.3421 

[TRAIN] Epoch[7](1053/1500); Loss: 0.332453; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1903 0.1975 0.2345 0.2334 0.2488 0.2838 0.2955 0.3128 0.3447 0.3590 0.3776 0.4094 0.4236 0.4425 0.4753 0.4906 

[TRAIN] Epoch[7](1054/1500); Loss: 0.245161; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1679 0.1729 0.2046 0.2010 0.2088 0.2271 0.2317 0.2389 0.2529 0.2593 0.2678 0.2802 0.2875 0.2969 0.3086 0.3165 

[TRAIN] Epoch[7](1055/1500); Loss: 0.182781; Backpropagation: 0.0924 sec; Batch: 0.4240 sec
0.0777 0.0720 0.0809 0.1243 0.1218 0.1370 0.1669 0.1727 0.1854 0.2114 0.2221 0.2346 0.2578 0.2717 0.2831 0.3050 

[TRAIN] Epoch[7](1056/1500); Loss: 0.195458; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1565 0.1598 0.1517 0.1531 0.1560 0.1669 0.1723 0.1801 0.1926 0.2002 0.2099 0.2237 0.2330 0.2441 0.2591 0.2685 

[TRAIN] Epoch[7](1057/1500); Loss: 0.183555; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.0716 0.0678 0.0925 0.0758 0.1137 0.1485 0.1506 0.1711 0.2026 0.2070 0.2251 0.2536 0.2609 0.2783 0.3043 0.3133 

[TRAIN] Epoch[7](1058/1500); Loss: 0.294986; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1901 0.1877 0.1997 0.1965 0.2137 0.2445 0.2532 0.2729 0.3033 0.3146 0.3342 0.3644 0.3785 0.3971 0.4267 0.4426 

[TRAIN] Epoch[7](1059/1500); Loss: 0.289585; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1715 0.1784 0.2157 0.2163 0.2259 0.2502 0.2618 0.2744 0.2973 0.3114 0.3239 0.3475 0.3642 0.3768 0.4001 0.4181 

[TRAIN] Epoch[7](1060/1500); Loss: 0.234507; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1196 0.1120 0.1436 0.1615 0.1701 0.1965 0.2150 0.2220 0.2445 0.2630 0.2721 0.2929 0.3124 0.3223 0.3426 0.3620 

[TRAIN] Epoch[7](1061/1500); Loss: 0.180606; Backpropagation: 0.0923 sec; Batch: 0.4249 sec
0.1352 0.1187 0.0658 0.0606 0.0855 0.1106 0.1239 0.1585 0.1831 0.1929 0.2225 0.2491 0.2589 0.2857 0.3139 0.3247 

[TRAIN] Epoch[7](1062/1500); Loss: 0.173005; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0714 0.0714 0.1097 0.1163 0.1237 0.1471 0.1571 0.1641 0.1823 0.1944 0.2030 0.2202 0.2334 0.2427 0.2588 0.2723 

[TRAIN] Epoch[7](1063/1500); Loss: 0.391507; Backpropagation: 0.0918 sec; Batch: 0.4245 sec
0.1623 0.1716 0.2355 0.2592 0.2786 0.3214 0.3554 0.3751 0.4104 0.4439 0.4655 0.4973 0.5313 0.5542 0.5844 0.6180 

[TRAIN] Epoch[7](1064/1500); Loss: 0.264225; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1422 0.1451 0.1651 0.1775 0.1893 0.2201 0.2361 0.2476 0.2741 0.2923 0.3041 0.3288 0.3499 0.3621 0.3850 0.4082 

[TRAIN] Epoch[7](1065/1500); Loss: 0.224750; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0756 0.0863 0.1479 0.1504 0.1631 0.1937 0.2047 0.2169 0.2412 0.2538 0.2667 0.2892 0.3028 0.3153 0.3370 0.3513 

[TRAIN] Epoch[7](1066/1500); Loss: 0.238256; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1464 0.1385 0.1516 0.1711 0.1753 0.1930 0.2138 0.2234 0.2410 0.2618 0.2722 0.2897 0.3111 0.3226 0.3394 0.3612 

[TRAIN] Epoch[7](1067/1500); Loss: 0.175061; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1140 0.1142 0.1320 0.1348 0.1406 0.1558 0.1618 0.1674 0.1797 0.1878 0.1946 0.2060 0.2145 0.2222 0.2335 0.2421 

[TRAIN] Epoch[7](1068/1500); Loss: 0.359175; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2724 0.2687 0.2998 0.2927 0.3034 0.3319 0.3387 0.3485 0.3686 0.3778 0.3879 0.4065 0.4178 0.4282 0.4462 0.4578 

[TRAIN] Epoch[7](1069/1500); Loss: 0.253414; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1998 0.1956 0.2062 0.2014 0.2118 0.2301 0.2328 0.2419 0.2580 0.2635 0.2718 0.2881 0.2964 0.3051 0.3210 0.3313 

[TRAIN] Epoch[7](1070/1500); Loss: 0.187980; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0874 0.0765 0.0936 0.1403 0.1364 0.1485 0.1784 0.1828 0.1923 0.2149 0.2272 0.2348 0.2535 0.2701 0.2773 0.2938 

[TRAIN] Epoch[7](1071/1500); Loss: 0.180098; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1486 0.1339 0.0990 0.0899 0.0980 0.1251 0.1421 0.1537 0.1808 0.1960 0.2075 0.2293 0.2458 0.2588 0.2770 0.2959 

[TRAIN] Epoch[7](1072/1500); Loss: 0.210760; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1704 0.1670 0.1791 0.1576 0.1628 0.1807 0.1855 0.1946 0.2098 0.2189 0.2279 0.2406 0.2531 0.2621 0.2742 0.2879 

[TRAIN] Epoch[7](1073/1500); Loss: 0.207127; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1254 0.1024 0.1395 0.1751 0.1730 0.1836 0.2028 0.2074 0.2152 0.2286 0.2376 0.2447 0.2560 0.2662 0.2732 0.2836 

[TRAIN] Epoch[7](1074/1500); Loss: 0.357944; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1682 0.1875 0.2774 0.2698 0.2886 0.3284 0.3379 0.3528 0.3814 0.3950 0.4069 0.4327 0.4500 0.4613 0.4852 0.5040 

[TRAIN] Epoch[7](1075/1500); Loss: 0.277192; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1246 0.1244 0.1694 0.1875 0.2016 0.2331 0.2548 0.2663 0.2915 0.3137 0.3261 0.3484 0.3722 0.3862 0.4045 0.4308 

[TRAIN] Epoch[7](1076/1500); Loss: 0.175698; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1390 0.1367 0.1501 0.1434 0.1484 0.1598 0.1624 0.1674 0.1768 0.1818 0.1879 0.1973 0.2033 0.2106 0.2198 0.2264 

[TRAIN] Epoch[7](1077/1500); Loss: 0.185113; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1842 0.1721 0.1202 0.1137 0.1135 0.1370 0.1544 0.1608 0.1772 0.1945 0.2025 0.2175 0.2349 0.2444 0.2590 0.2758 

[TRAIN] Epoch[7](1078/1500); Loss: 0.190311; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1302 0.1272 0.1475 0.1441 0.1496 0.1676 0.1744 0.1788 0.1934 0.2041 0.2094 0.2217 0.2353 0.2416 0.2532 0.2668 

[TRAIN] Epoch[7](1079/1500); Loss: 0.236063; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1572 0.1517 0.1734 0.1786 0.1861 0.2017 0.2139 0.2228 0.2384 0.2537 0.2639 0.2784 0.2945 0.3058 0.3203 0.3368 

[TRAIN] Epoch[7](1080/1500); Loss: 0.182179; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1169 0.1052 0.0905 0.0850 0.1054 0.1349 0.1388 0.1581 0.1917 0.1974 0.2112 0.2437 0.2568 0.2678 0.2949 0.3164 

[TRAIN] Epoch[7](1081/1500); Loss: 0.431185; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.2963 0.3063 0.3542 0.3530 0.3640 0.3932 0.4029 0.4152 0.4405 0.4555 0.4666 0.4932 0.5134 0.5230 0.5489 0.5726 

[TRAIN] Epoch[7](1082/1500); Loss: 0.241258; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1790 0.1734 0.1875 0.1837 0.1935 0.2182 0.2231 0.2308 0.2485 0.2571 0.2638 0.2787 0.2907 0.2975 0.3103 0.3242 

[TRAIN] Epoch[7](1083/1500); Loss: 0.197363; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1249 0.1263 0.1707 0.1644 0.1726 0.1870 0.1909 0.1965 0.2050 0.2115 0.2170 0.2242 0.2320 0.2376 0.2444 0.2528 

[TRAIN] Epoch[7](1084/1500); Loss: 0.176910; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1433 0.1412 0.1450 0.1463 0.1480 0.1576 0.1636 0.1662 0.1745 0.1833 0.1884 0.1968 0.2066 0.2139 0.2227 0.2330 

[TRAIN] Epoch[7](1085/1500); Loss: 0.228747; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1352 0.1408 0.1875 0.1788 0.1897 0.2152 0.2161 0.2223 0.2400 0.2470 0.2524 0.2671 0.2780 0.2835 0.2969 0.3093 

[TRAIN] Epoch[7](1086/1500); Loss: 0.237761; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1259 0.1157 0.1014 0.0808 0.1318 0.1829 0.1868 0.2103 0.2613 0.2690 0.2861 0.3293 0.3465 0.3597 0.3910 0.4259 

[TRAIN] Epoch[7](1087/1500); Loss: 0.281312; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2177 0.2157 0.2432 0.2367 0.2455 0.2653 0.2665 0.2720 0.2863 0.2946 0.2994 0.3111 0.3243 0.3286 0.3397 0.3545 

[TRAIN] Epoch[7](1088/1500); Loss: 0.221434; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1624 0.1645 0.1883 0.1835 0.1900 0.2069 0.2098 0.2137 0.2248 0.2336 0.2381 0.2471 0.2586 0.2641 0.2731 0.2845 

[TRAIN] Epoch[7](1089/1500); Loss: 0.134730; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1041 0.0978 0.1010 0.0934 0.1076 0.1225 0.1218 0.1268 0.1391 0.1422 0.1469 0.1567 0.1635 0.1689 0.1776 0.1856 

[TRAIN] Epoch[7](1090/1500); Loss: 0.292973; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1356 0.1360 0.1802 0.1587 0.2040 0.2497 0.2562 0.2739 0.3193 0.3320 0.3429 0.3778 0.4035 0.4114 0.4344 0.4718 

[TRAIN] Epoch[7](1091/1500); Loss: 0.266002; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1758 0.1760 0.1994 0.1965 0.2074 0.2336 0.2414 0.2505 0.2723 0.2856 0.2945 0.3134 0.3321 0.3410 0.3575 0.3793 

[TRAIN] Epoch[7](1092/1500); Loss: 0.132514; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.0806 0.0830 0.0640 0.0706 0.0786 0.0990 0.1093 0.1158 0.1336 0.1471 0.1552 0.1693 0.1850 0.1970 0.2079 0.2243 

[TRAIN] Epoch[7](1093/1500); Loss: 0.202680; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1939 0.1895 0.1845 0.1799 0.1794 0.1861 0.1873 0.1909 0.1977 0.2027 0.2073 0.2147 0.2220 0.2275 0.2354 0.2440 

[TRAIN] Epoch[7](1094/1500); Loss: 0.282250; Backpropagation: 0.0917 sec; Batch: 0.4228 sec
0.1689 0.1687 0.2127 0.2126 0.2228 0.2511 0.2620 0.2711 0.2921 0.3069 0.3168 0.3350 0.3526 0.3633 0.3799 0.3994 

[TRAIN] Epoch[7](1095/1500); Loss: 0.164976; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0953 0.0874 0.0898 0.1048 0.1110 0.1311 0.1453 0.1537 0.1701 0.1834 0.1948 0.2076 0.2222 0.2353 0.2462 0.2615 

[TRAIN] Epoch[7](1096/1500); Loss: 0.291377; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1559 0.1551 0.2099 0.2263 0.2316 0.2548 0.2766 0.2862 0.3019 0.3202 0.3359 0.3486 0.3659 0.3835 0.3962 0.4133 

[TRAIN] Epoch[7](1097/1500); Loss: 0.193206; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1926 0.1894 0.1820 0.1825 0.1833 0.1851 0.1860 0.1876 0.1901 0.1923 0.1949 0.1981 0.2014 0.2048 0.2087 0.2126 

[TRAIN] Epoch[7](1098/1500); Loss: 0.259412; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2441 0.2412 0.2450 0.2400 0.2408 0.2487 0.2487 0.2508 0.2575 0.2617 0.2640 0.2695 0.2776 0.2805 0.2857 0.2949 

[TRAIN] Epoch[7](1099/1500); Loss: 0.238867; Backpropagation: 0.0920 sec; Batch: 0.4249 sec
0.1599 0.1574 0.1856 0.1865 0.1955 0.2172 0.2252 0.2302 0.2462 0.2572 0.2643 0.2757 0.2903 0.2990 0.3084 0.3232 

[TRAIN] Epoch[7](1100/1500); Loss: 0.251010; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2048 0.2034 0.2280 0.2234 0.2282 0.2402 0.2422 0.2452 0.2535 0.2599 0.2637 0.2705 0.2792 0.2837 0.2905 0.2996 

[TRAIN] Epoch[7](1101/1500); Loss: 0.305858; Backpropagation: 0.0918 sec; Batch: 0.4226 sec
0.2380 0.2387 0.2719 0.2664 0.2732 0.2936 0.2962 0.2997 0.3121 0.3214 0.3242 0.3325 0.3468 0.3506 0.3571 0.3713 

[TRAIN] Epoch[7](1102/1500); Loss: 0.219518; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1655 0.1634 0.1606 0.1564 0.1661 0.1873 0.1946 0.2017 0.2205 0.2337 0.2412 0.2562 0.2733 0.2827 0.2954 0.3138 

[TRAIN] Epoch[7](1103/1500); Loss: 0.259399; Backpropagation: 0.0932 sec; Batch: 0.4261 sec
0.1353 0.1204 0.1599 0.2074 0.2000 0.2102 0.2514 0.2581 0.2641 0.2865 0.3110 0.3138 0.3280 0.3602 0.3671 0.3770 

[TRAIN] Epoch[7](1104/1500); Loss: 0.137718; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1238 0.1180 0.1090 0.1100 0.1146 0.1220 0.1245 0.1296 0.1363 0.1402 0.1460 0.1530 0.1588 0.1655 0.1727 0.1795 

[TRAIN] Epoch[7](1105/1500); Loss: 0.289164; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2035 0.1942 0.1755 0.1802 0.2052 0.2305 0.2474 0.2675 0.2978 0.3108 0.3298 0.3581 0.3762 0.3933 0.4159 0.4406 

[TRAIN] Epoch[7](1106/1500); Loss: 0.221666; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1348 0.1345 0.1529 0.1501 0.1646 0.1932 0.2024 0.2104 0.2297 0.2460 0.2530 0.2642 0.2858 0.2981 0.3059 0.3211 

[TRAIN] Epoch[7](1107/1500); Loss: 0.162265; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1625 0.1488 0.0765 0.0710 0.0700 0.1108 0.1419 0.1410 0.1581 0.1851 0.1893 0.1964 0.2188 0.2347 0.2387 0.2527 

[TRAIN] Epoch[7](1108/1500); Loss: 0.211491; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1686 0.1672 0.1888 0.1800 0.1853 0.2031 0.2026 0.2050 0.2145 0.2222 0.2237 0.2294 0.2411 0.2440 0.2485 0.2599 

[TRAIN] Epoch[7](1109/1500); Loss: 0.139366; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1328 0.1287 0.1202 0.1201 0.1197 0.1251 0.1294 0.1314 0.1359 0.1410 0.1447 0.1493 0.1551 0.1599 0.1651 0.1714 

[TRAIN] Epoch[7](1110/1500); Loss: 0.212760; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1670 0.1658 0.1956 0.1885 0.1918 0.2072 0.2078 0.2087 0.2168 0.2230 0.2247 0.2295 0.2379 0.2413 0.2455 0.2533 

[TRAIN] Epoch[7](1111/1500); Loss: 0.257998; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1674 0.1779 0.2134 0.2188 0.2219 0.2372 0.2511 0.2545 0.2618 0.2773 0.2843 0.2902 0.3045 0.3143 0.3211 0.3323 

[TRAIN] Epoch[7](1112/1500); Loss: 0.176007; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1675 0.1619 0.1629 0.1684 0.1662 0.1683 0.1718 0.1724 0.1740 0.1772 0.1799 0.1822 0.1856 0.1893 0.1924 0.1962 

[TRAIN] Epoch[7](1113/1500); Loss: 0.177049; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1502 0.1512 0.1591 0.1613 0.1621 0.1696 0.1721 0.1731 0.1775 0.1821 0.1847 0.1882 0.1940 0.1982 0.2018 0.2077 

[TRAIN] Epoch[7](1114/1500); Loss: 0.163010; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1264 0.1243 0.1189 0.1218 0.1260 0.1385 0.1477 0.1521 0.1614 0.1723 0.1799 0.1877 0.1990 0.2086 0.2165 0.2270 

[TRAIN] Epoch[7](1115/1500); Loss: 0.207956; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.1617 0.1554 0.1750 0.1851 0.1842 0.1913 0.2023 0.2039 0.2086 0.2174 0.2244 0.2285 0.2358 0.2453 0.2507 0.2579 

[TRAIN] Epoch[7](1116/1500); Loss: 0.118806; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.0703 0.0795 0.0642 0.0731 0.0775 0.0920 0.1016 0.1045 0.1164 0.1313 0.1377 0.1450 0.1610 0.1750 0.1803 0.1917 

[TRAIN] Epoch[7](1117/1500); Loss: 0.169996; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1320 0.1314 0.1439 0.1376 0.1399 0.1550 0.1613 0.1621 0.1693 0.1800 0.1836 0.1881 0.1985 0.2065 0.2111 0.2197 

[TRAIN] Epoch[7](1118/1500); Loss: 0.229068; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1260 0.1292 0.1988 0.1823 0.1917 0.2277 0.2254 0.2265 0.2423 0.2548 0.2547 0.2604 0.2786 0.2821 0.2858 0.2988 

[TRAIN] Epoch[7](1119/1500); Loss: 0.146218; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1959 0.1778 0.0906 0.0648 0.0737 0.0971 0.1030 0.1161 0.1390 0.1470 0.1517 0.1697 0.1885 0.1935 0.2043 0.2267 

[TRAIN] Epoch[7](1120/1500); Loss: 0.137851; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1125 0.1093 0.1190 0.1224 0.1235 0.1291 0.1324 0.1341 0.1379 0.1425 0.1459 0.1497 0.1550 0.1594 0.1639 0.1691 

[TRAIN] Epoch[7](1121/1500); Loss: 0.192119; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1065 0.1046 0.1363 0.1510 0.1506 0.1641 0.1846 0.1878 0.1949 0.2122 0.2221 0.2273 0.2411 0.2559 0.2625 0.2725 

[TRAIN] Epoch[7](1122/1500); Loss: 0.206157; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2131 0.2029 0.1900 0.1767 0.1788 0.1890 0.1927 0.1941 0.2005 0.2077 0.2106 0.2153 0.2236 0.2287 0.2337 0.2410 

[TRAIN] Epoch[7](1123/1500); Loss: 0.155863; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1041 0.0943 0.0995 0.1094 0.1122 0.1289 0.1407 0.1459 0.1578 0.1687 0.1791 0.1877 0.1999 0.2119 0.2209 0.2329 

[TRAIN] Epoch[7](1124/1500); Loss: 0.162189; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1447 0.1372 0.1248 0.1217 0.1280 0.1436 0.1425 0.1469 0.1625 0.1691 0.1719 0.1816 0.1955 0.1997 0.2056 0.2198 

[TRAIN] Epoch[7](1125/1500); Loss: 0.204114; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1053 0.0961 0.1319 0.1576 0.1545 0.1666 0.1967 0.2046 0.2080 0.2201 0.2450 0.2500 0.2567 0.2762 0.2964 0.3002 

[TRAIN] Epoch[7](1126/1500); Loss: 0.181826; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1370 0.1247 0.1313 0.1440 0.1422 0.1549 0.1705 0.1748 0.1813 0.1925 0.2042 0.2087 0.2196 0.2319 0.2429 0.2487 

[TRAIN] Epoch[7](1127/1500); Loss: 0.147758; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1172 0.1174 0.1345 0.1283 0.1301 0.1422 0.1417 0.1427 0.1492 0.1538 0.1557 0.1599 0.1665 0.1702 0.1742 0.1806 

[TRAIN] Epoch[7](1128/1500); Loss: 0.201021; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1649 0.1652 0.1796 0.1790 0.1808 0.1919 0.1952 0.1961 0.2008 0.2092 0.2121 0.2145 0.2237 0.2301 0.2332 0.2398 

[TRAIN] Epoch[7](1129/1500); Loss: 0.220691; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1854 0.1803 0.1944 0.1877 0.1942 0.2096 0.2098 0.2139 0.2239 0.2294 0.2318 0.2397 0.2499 0.2524 0.2585 0.2704 

[TRAIN] Epoch[7](1130/1500); Loss: 0.128128; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0987 0.0976 0.1105 0.1151 0.1149 0.1201 0.1247 0.1255 0.1286 0.1334 0.1367 0.1397 0.1445 0.1491 0.1530 0.1578 

[TRAIN] Epoch[7](1131/1500); Loss: 0.387923; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.3326 0.3281 0.3800 0.3621 0.3652 0.3937 0.3926 0.3907 0.3928 0.4064 0.4039 0.3997 0.4120 0.4175 0.4142 0.4152 

[TRAIN] Epoch[7](1132/1500); Loss: 0.192099; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1217 0.1231 0.1568 0.1602 0.1618 0.1777 0.1870 0.1888 0.1945 0.2075 0.2135 0.2167 0.2288 0.2388 0.2441 0.2524 

[TRAIN] Epoch[7](1133/1500); Loss: 0.143503; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1242 0.1211 0.1300 0.1269 0.1274 0.1361 0.1369 0.1384 0.1433 0.1474 0.1498 0.1536 0.1593 0.1627 0.1667 0.1724 

[TRAIN] Epoch[7](1134/1500); Loss: 0.166755; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1427 0.1383 0.1539 0.1491 0.1507 0.1606 0.1618 0.1627 0.1672 0.1721 0.1742 0.1772 0.1834 0.1872 0.1906 0.1963 

[TRAIN] Epoch[7](1135/1500); Loss: 0.191520; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2105 0.1979 0.1532 0.1356 0.1334 0.1546 0.1717 0.1726 0.1777 0.1989 0.2057 0.2060 0.2207 0.2381 0.2415 0.2462 

[TRAIN] Epoch[7](1136/1500); Loss: 0.242762; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1660 0.1663 0.1990 0.1861 0.1988 0.2316 0.2345 0.2365 0.2485 0.2673 0.2673 0.2716 0.2927 0.3014 0.3030 0.3135 

[TRAIN] Epoch[7](1137/1500); Loss: 0.143190; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1132 0.1129 0.1198 0.1271 0.1261 0.1317 0.1380 0.1396 0.1425 0.1481 0.1539 0.1564 0.1617 0.1685 0.1734 0.1781 

[TRAIN] Epoch[7](1138/1500); Loss: 0.130251; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1557 0.1458 0.0809 0.0622 0.0643 0.0898 0.1112 0.1094 0.1174 0.1391 0.1466 0.1469 0.1588 0.1807 0.1853 0.1898 

[TRAIN] Epoch[7](1139/1500); Loss: 0.232591; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1916 0.1901 0.2229 0.2158 0.2174 0.2296 0.2310 0.2304 0.2346 0.2420 0.2426 0.2442 0.2524 0.2557 0.2576 0.2636 

[TRAIN] Epoch[7](1140/1500); Loss: 0.253104; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2775 0.2673 0.2509 0.2272 0.2179 0.2288 0.2346 0.2371 0.2432 0.2514 0.2550 0.2580 0.2670 0.2730 0.2769 0.2838 

[TRAIN] Epoch[7](1141/1500); Loss: 0.146081; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1221 0.1055 0.1219 0.1432 0.1364 0.1351 0.1470 0.1487 0.1470 0.1500 0.1575 0.1581 0.1584 0.1656 0.1698 0.1710 

[TRAIN] Epoch[7](1142/1500); Loss: 0.161253; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1017 0.0992 0.1343 0.1261 0.1327 0.1554 0.1576 0.1567 0.1655 0.1782 0.1791 0.1805 0.1951 0.2030 0.2039 0.2109 

[TRAIN] Epoch[7](1143/1500); Loss: 0.212230; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1446 0.1436 0.1711 0.1594 0.1727 0.2001 0.2044 0.2032 0.2156 0.2343 0.2377 0.2376 0.2519 0.2718 0.2725 0.2751 

[TRAIN] Epoch[7](1144/1500); Loss: 0.158322; Backpropagation: 0.0924 sec; Batch: 0.4243 sec
0.1008 0.0898 0.1003 0.1020 0.1143 0.1332 0.1419 0.1444 0.1625 0.1747 0.1816 0.1885 0.2093 0.2208 0.2275 0.2414 

[TRAIN] Epoch[7](1145/1500); Loss: 0.276206; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2280 0.2252 0.2750 0.2604 0.2642 0.2839 0.2808 0.2772 0.2831 0.2895 0.2870 0.2857 0.2939 0.2954 0.2933 0.2966 

[TRAIN] Epoch[7](1146/1500); Loss: 0.151678; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1545 0.1494 0.1345 0.1325 0.1314 0.1348 0.1419 0.1439 0.1458 0.1517 0.1571 0.1592 0.1639 0.1708 0.1758 0.1793 

[TRAIN] Epoch[7](1147/1500); Loss: 0.402016; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.3339 0.3455 0.3755 0.3762 0.3757 0.3840 0.3978 0.3971 0.3982 0.4155 0.4229 0.4235 0.4326 0.4483 0.4512 0.4545 

[TRAIN] Epoch[7](1148/1500); Loss: 0.263332; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1864 0.1854 0.2236 0.2193 0.2245 0.2526 0.2591 0.2583 0.2659 0.2862 0.2892 0.2879 0.3047 0.3235 0.3226 0.3242 

[TRAIN] Epoch[7](1149/1500); Loss: 0.176592; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1311 0.1249 0.1492 0.1612 0.1584 0.1631 0.1745 0.1774 0.1782 0.1832 0.1930 0.1949 0.1978 0.2063 0.2150 0.2171 

[TRAIN] Epoch[7](1150/1500); Loss: 0.127927; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1001 0.0983 0.0902 0.0979 0.0999 0.1076 0.1145 0.1193 0.1262 0.1323 0.1414 0.1473 0.1546 0.1642 0.1730 0.1799 

[TRAIN] Epoch[7](1151/1500); Loss: 0.284534; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2136 0.2177 0.2691 0.2564 0.2609 0.2839 0.2839 0.2838 0.2911 0.3016 0.3010 0.3028 0.3170 0.3194 0.3203 0.3301 

[TRAIN] Epoch[7](1152/1500); Loss: 0.189864; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1397 0.1221 0.1356 0.1532 0.1501 0.1585 0.1771 0.1843 0.1897 0.1995 0.2144 0.2208 0.2294 0.2444 0.2552 0.2636 

[TRAIN] Epoch[7](1153/1500); Loss: 0.160536; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1557 0.1531 0.1536 0.1537 0.1532 0.1550 0.1561 0.1566 0.1581 0.1605 0.1622 0.1641 0.1672 0.1702 0.1730 0.1763 

[TRAIN] Epoch[7](1154/1500); Loss: 0.151542; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1267 0.1269 0.1274 0.1234 0.1276 0.1393 0.1414 0.1427 0.1502 0.1581 0.1615 0.1645 0.1747 0.1823 0.1861 0.1918 

[TRAIN] Epoch[7](1155/1500); Loss: 0.309520; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2347 0.2347 0.2945 0.2823 0.2838 0.3105 0.3118 0.3099 0.3164 0.3294 0.3290 0.3282 0.3413 0.3472 0.3469 0.3518 

[TRAIN] Epoch[7](1156/1500); Loss: 0.180939; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1839 0.1736 0.1633 0.1602 0.1585 0.1666 0.1732 0.1739 0.1768 0.1831 0.1870 0.1882 0.1942 0.2009 0.2037 0.2078 

[TRAIN] Epoch[7](1157/1500); Loss: 0.218840; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2100 0.2021 0.2085 0.2008 0.1985 0.2077 0.2130 0.2136 0.2152 0.2227 0.2263 0.2265 0.2326 0.2388 0.2409 0.2442 

[TRAIN] Epoch[7](1158/1500); Loss: 0.208559; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1647 0.1612 0.1761 0.1675 0.1784 0.1980 0.1993 0.1967 0.2108 0.2240 0.2241 0.2246 0.2433 0.2539 0.2536 0.2608 

[TRAIN] Epoch[7](1159/1500); Loss: 0.186892; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1572 0.1555 0.1823 0.1755 0.1757 0.1859 0.1868 0.1855 0.1878 0.1934 0.1941 0.1944 0.1998 0.2034 0.2045 0.2084 

[TRAIN] Epoch[7](1160/1500); Loss: 0.134447; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0705 0.0660 0.0800 0.1142 0.1050 0.1049 0.1321 0.1384 0.1352 0.1389 0.1621 0.1659 0.1647 0.1772 0.1983 0.1977 

[TRAIN] Epoch[7](1161/1500); Loss: 0.109321; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.0887 0.0878 0.0915 0.1012 0.0990 0.0992 0.1047 0.1064 0.1075 0.1109 0.1158 0.1185 0.1220 0.1273 0.1323 0.1363 

[TRAIN] Epoch[7](1162/1500); Loss: 0.216781; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2034 0.1974 0.2041 0.1965 0.1995 0.2130 0.2122 0.2110 0.2154 0.2230 0.2226 0.2230 0.2319 0.2370 0.2374 0.2412 

[TRAIN] Epoch[7](1163/1500); Loss: 0.104432; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1749 0.1590 0.0806 0.0655 0.0609 0.0767 0.0857 0.0844 0.0874 0.0984 0.1022 0.1025 0.1122 0.1239 0.1258 0.1309 

[TRAIN] Epoch[7](1164/1500); Loss: 0.185886; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1624 0.1597 0.1510 0.1514 0.1474 0.1593 0.1762 0.1800 0.1803 0.1895 0.2052 0.2054 0.2086 0.2247 0.2368 0.2363 

[TRAIN] Epoch[7](1165/1500); Loss: 0.299679; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1689 0.2118 0.2669 0.2650 0.2650 0.2811 0.3001 0.2986 0.3029 0.3256 0.3309 0.3331 0.3477 0.3606 0.3643 0.3726 

[TRAIN] Epoch[7](1166/1500); Loss: 0.210516; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1929 0.1904 0.2053 0.2017 0.2003 0.2070 0.2091 0.2079 0.2082 0.2143 0.2159 0.2152 0.2201 0.2253 0.2262 0.2283 

[TRAIN] Epoch[7](1167/1500); Loss: 0.186224; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1246 0.1179 0.1527 0.1607 0.1587 0.1715 0.1845 0.1859 0.1859 0.1987 0.2087 0.2084 0.2153 0.2307 0.2377 0.2377 

[TRAIN] Epoch[7](1168/1500); Loss: 0.144415; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1136 0.1135 0.1407 0.1325 0.1337 0.1450 0.1440 0.1428 0.1467 0.1511 0.1510 0.1523 0.1576 0.1598 0.1611 0.1655 

[TRAIN] Epoch[7](1169/1500); Loss: 0.171633; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1299 0.1182 0.1128 0.0876 0.1228 0.1526 0.1406 0.1400 0.1816 0.1952 0.1872 0.1965 0.2383 0.2416 0.2383 0.2630 

[TRAIN] Epoch[7](1170/1500); Loss: 0.179180; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1447 0.1335 0.1059 0.0870 0.1267 0.1510 0.1414 0.1496 0.1921 0.1978 0.1929 0.2138 0.2501 0.2474 0.2497 0.2834 

[TRAIN] Epoch[7](1171/1500); Loss: 0.327178; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.2980 0.2944 0.3201 0.3116 0.3082 0.3285 0.3324 0.3263 0.3220 0.3376 0.3399 0.3327 0.3373 0.3529 0.3502 0.3426 

[TRAIN] Epoch[7](1172/1500); Loss: 0.269147; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2394 0.2382 0.2782 0.2681 0.2634 0.2708 0.2776 0.2713 0.2652 0.2767 0.2771 0.2708 0.2732 0.2821 0.2789 0.2753 

[TRAIN] Epoch[7](1173/1500); Loss: 0.167134; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1522 0.1449 0.1474 0.1359 0.1358 0.1555 0.1598 0.1561 0.1582 0.1768 0.1784 0.1747 0.1870 0.2049 0.2034 0.2029 

[TRAIN] Epoch[7](1174/1500); Loss: 0.142882; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1374 0.1322 0.1240 0.1240 0.1258 0.1320 0.1328 0.1347 0.1394 0.1434 0.1467 0.1517 0.1574 0.1624 0.1678 0.1743 

[TRAIN] Epoch[7](1175/1500); Loss: 0.126607; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1664 0.1528 0.0829 0.0808 0.0779 0.0941 0.1074 0.1043 0.1111 0.1277 0.1354 0.1351 0.1459 0.1632 0.1682 0.1725 

[TRAIN] Epoch[7](1176/1500); Loss: 0.119698; Backpropagation: 0.0922 sec; Batch: 0.4233 sec
0.0726 0.0722 0.1139 0.1044 0.1050 0.1216 0.1211 0.1186 0.1231 0.1308 0.1302 0.1302 0.1381 0.1426 0.1432 0.1475 

[TRAIN] Epoch[7](1177/1500); Loss: 0.262465; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2246 0.2286 0.2534 0.2472 0.2439 0.2602 0.2637 0.2601 0.2588 0.2722 0.2748 0.2698 0.2765 0.2907 0.2895 0.2853 

[TRAIN] Epoch[7](1178/1500); Loss: 0.209924; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1751 0.1699 0.2019 0.1897 0.1912 0.2134 0.2109 0.2066 0.2112 0.2229 0.2192 0.2159 0.2296 0.2351 0.2318 0.2345 

[TRAIN] Epoch[7](1179/1500); Loss: 0.093831; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0831 0.0814 0.0881 0.0877 0.0863 0.0876 0.0883 0.0893 0.0912 0.0937 0.0962 0.0991 0.1024 0.1055 0.1088 0.1124 

[TRAIN] Epoch[7](1180/1500); Loss: 0.086583; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0764 0.0770 0.0778 0.0796 0.0777 0.0786 0.0802 0.0815 0.0837 0.0867 0.0895 0.0925 0.0959 0.0994 0.1027 0.1063 

[TRAIN] Epoch[7](1181/1500); Loss: 0.133299; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2110 0.1930 0.0935 0.0686 0.0638 0.0989 0.1037 0.1051 0.1190 0.1332 0.1342 0.1361 0.1566 0.1677 0.1674 0.1810 

[TRAIN] Epoch[7](1182/1500); Loss: 0.243684; Backpropagation: 0.0924 sec; Batch: 0.4237 sec
0.2090 0.2073 0.2446 0.2328 0.2315 0.2495 0.2482 0.2441 0.2439 0.2548 0.2522 0.2474 0.2554 0.2621 0.2588 0.2574 

[TRAIN] Epoch[7](1183/1500); Loss: 0.391572; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.3644 0.3590 0.4107 0.3915 0.3848 0.4092 0.4099 0.3993 0.3886 0.4037 0.4008 0.3858 0.3876 0.4008 0.3922 0.3770 

[TRAIN] Epoch[7](1184/1500); Loss: 0.233014; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1508 0.1557 0.2412 0.2183 0.2154 0.2475 0.2504 0.2405 0.2341 0.2567 0.2537 0.2400 0.2507 0.2676 0.2575 0.2481 

[TRAIN] Epoch[7](1185/1500); Loss: 0.144778; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1182 0.1128 0.1315 0.1362 0.1326 0.1381 0.1437 0.1441 0.1433 0.1494 0.1539 0.1532 0.1574 0.1648 0.1683 0.1691 

[TRAIN] Epoch[7](1186/1500); Loss: 0.223750; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1678 0.1710 0.2092 0.2008 0.2016 0.2214 0.2238 0.2201 0.2222 0.2395 0.2390 0.2347 0.2482 0.2632 0.2595 0.2580 

[TRAIN] Epoch[7](1187/1500); Loss: 0.145376; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1316 0.1220 0.1125 0.1107 0.1180 0.1288 0.1299 0.1296 0.1431 0.1525 0.1547 0.1570 0.1739 0.1829 0.1866 0.1923 

[TRAIN] Epoch[7](1188/1500); Loss: 0.263361; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2171 0.2145 0.2694 0.2523 0.2483 0.2743 0.2727 0.2657 0.2639 0.2794 0.2749 0.2652 0.2762 0.2863 0.2796 0.2741 

[TRAIN] Epoch[7](1189/1500); Loss: 0.188893; Backpropagation: 0.0917 sec; Batch: 0.4299 sec
0.1284 0.1131 0.1380 0.1612 0.1543 0.1547 0.1808 0.1910 0.1896 0.1909 0.2165 0.2252 0.2249 0.2331 0.2579 0.2628 

[TRAIN] Epoch[7](1190/1500); Loss: 0.175521; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1455 0.1449 0.1796 0.1688 0.1653 0.1793 0.1796 0.1753 0.1741 0.1833 0.1821 0.1783 0.1838 0.1907 0.1890 0.1887 

[TRAIN] Epoch[7](1191/1500); Loss: 0.115886; Backpropagation: 0.0919 sec; Batch: 0.4229 sec
0.1073 0.1054 0.0978 0.0981 0.1017 0.1074 0.1084 0.1096 0.1135 0.1171 0.1204 0.1235 0.1292 0.1335 0.1384 0.1428 

[TRAIN] Epoch[7](1192/1500); Loss: 0.110778; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.0695 0.0692 0.0843 0.0725 0.0861 0.1044 0.1012 0.0957 0.1138 0.1267 0.1231 0.1219 0.1443 0.1520 0.1493 0.1584 

[TRAIN] Epoch[7](1193/1500); Loss: 0.116355; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1460 0.1391 0.1120 0.1024 0.1003 0.1028 0.1047 0.1050 0.1068 0.1099 0.1126 0.1153 0.1196 0.1241 0.1281 0.1330 

[TRAIN] Epoch[7](1194/1500); Loss: 0.193228; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1923 0.1820 0.1763 0.1692 0.1730 0.1856 0.1865 0.1829 0.1884 0.1991 0.1988 0.1965 0.2083 0.2179 0.2163 0.2185 

[TRAIN] Epoch[7](1195/1500); Loss: 0.091244; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.0597 0.0606 0.0767 0.0801 0.0791 0.0841 0.0876 0.0884 0.0900 0.0955 0.0994 0.1013 0.1067 0.1129 0.1169 0.1208 

[TRAIN] Epoch[7](1196/1500); Loss: 0.214222; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.2685 0.2519 0.1980 0.1636 0.1642 0.1896 0.1890 0.1888 0.1994 0.2149 0.2119 0.2123 0.2352 0.2461 0.2425 0.2517 

[TRAIN] Epoch[7](1197/1500); Loss: 0.261847; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2112 0.2087 0.2747 0.2547 0.2480 0.2770 0.2758 0.2660 0.2616 0.2797 0.2740 0.2605 0.2722 0.2841 0.2750 0.2664 

[TRAIN] Epoch[7](1198/1500); Loss: 0.239655; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1990 0.1977 0.2434 0.2323 0.2283 0.2454 0.2470 0.2411 0.2388 0.2516 0.2498 0.2427 0.2510 0.2598 0.2550 0.2516 

[TRAIN] Epoch[7](1199/1500); Loss: 0.149506; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1519 0.1479 0.1269 0.1238 0.1236 0.1323 0.1358 0.1368 0.1418 0.1502 0.1554 0.1568 0.1665 0.1766 0.1810 0.1847 

[TRAIN] Epoch[7](1200/1500); Loss: 0.210741; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1976 0.1941 0.2154 0.2073 0.2036 0.2131 0.2136 0.2099 0.2076 0.2155 0.2143 0.2100 0.2144 0.2206 0.2183 0.2164 

[TRAIN] Epoch[7](1201/1500); Loss: 0.143515; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1231 0.1221 0.1405 0.1340 0.1314 0.1430 0.1420 0.1396 0.1421 0.1490 0.1483 0.1474 0.1543 0.1591 0.1589 0.1614 

[TRAIN] Epoch[7](1202/1500); Loss: 0.115678; Backpropagation: 0.0917 sec; Batch: 0.4227 sec
0.1571 0.1470 0.0874 0.0687 0.0679 0.0854 0.0963 0.0906 0.0987 0.1170 0.1227 0.1188 0.1333 0.1520 0.1529 0.1551 

[TRAIN] Epoch[7](1203/1500); Loss: 0.312406; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.2390 0.2415 0.3003 0.2882 0.2868 0.3111 0.3191 0.3129 0.3087 0.3321 0.3355 0.3267 0.3367 0.3585 0.3544 0.3471 

[TRAIN] Epoch[7](1204/1500); Loss: 0.103445; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1102 0.0969 0.0917 0.1029 0.0966 0.0923 0.0984 0.1016 0.0990 0.0976 0.1048 0.1067 0.1065 0.1108 0.1185 0.1208 

[TRAIN] Epoch[7](1205/1500); Loss: 0.177832; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1724 0.1719 0.1713 0.1714 0.1709 0.1722 0.1734 0.1740 0.1751 0.1774 0.1794 0.1813 0.1840 0.1871 0.1901 0.1934 

[TRAIN] Epoch[7](1206/1500); Loss: 0.187929; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1870 0.1825 0.1842 0.1802 0.1791 0.1819 0.1834 0.1830 0.1837 0.1879 0.1894 0.1900 0.1939 0.1983 0.1999 0.2027 

[TRAIN] Epoch[7](1207/1500); Loss: 0.152855; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1293 0.1283 0.1530 0.1438 0.1426 0.1536 0.1533 0.1506 0.1521 0.1589 0.1581 0.1567 0.1628 0.1676 0.1668 0.1684 

[TRAIN] Epoch[7](1208/1500); Loss: 0.102511; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1949 0.1771 0.0779 0.0600 0.0553 0.0682 0.0780 0.0734 0.0768 0.0914 0.0984 0.0992 0.1077 0.1237 0.1259 0.1321 

[TRAIN] Epoch[7](1209/1500); Loss: 0.209300; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1752 0.1668 0.1919 0.1750 0.1842 0.2087 0.2040 0.1953 0.2085 0.2265 0.2208 0.2147 0.2367 0.2510 0.2449 0.2447 

[TRAIN] Epoch[7](1210/1500); Loss: 0.171786; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1267 0.1105 0.1369 0.1640 0.1554 0.1520 0.1703 0.1788 0.1728 0.1724 0.1924 0.1941 0.1900 0.1997 0.2179 0.2146 

[TRAIN] Epoch[7](1211/1500); Loss: 0.113537; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0966 0.0784 0.1037 0.1227 0.1146 0.1066 0.1160 0.1198 0.1135 0.1101 0.1194 0.1200 0.1163 0.1205 0.1295 0.1289 

[TRAIN] Epoch[7](1212/1500); Loss: 0.131457; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0807 0.0791 0.0886 0.1132 0.1068 0.1061 0.1256 0.1328 0.1299 0.1339 0.1532 0.1570 0.1570 0.1686 0.1860 0.1849 

[TRAIN] Epoch[7](1213/1500); Loss: 0.123890; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1179 0.1194 0.1147 0.1169 0.1153 0.1154 0.1170 0.1184 0.1196 0.1219 0.1253 0.1282 0.1316 0.1358 0.1400 0.1445 

[TRAIN] Epoch[7](1214/1500); Loss: 0.163163; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1480 0.1444 0.1653 0.1583 0.1567 0.1653 0.1646 0.1621 0.1632 0.1673 0.1665 0.1651 0.1691 0.1713 0.1708 0.1726 

[TRAIN] Epoch[7](1215/1500); Loss: 0.118965; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1223 0.1191 0.1113 0.1083 0.1077 0.1098 0.1110 0.1117 0.1140 0.1170 0.1194 0.1222 0.1265 0.1305 0.1341 0.1386 

[TRAIN] Epoch[7](1216/1500); Loss: 0.138799; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1014 0.1011 0.1385 0.1319 0.1281 0.1409 0.1430 0.1395 0.1377 0.1469 0.1471 0.1430 0.1502 0.1575 0.1569 0.1571 

[TRAIN] Epoch[7](1217/1500); Loss: 0.188429; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2245 0.2124 0.1756 0.1467 0.1449 0.1692 0.1770 0.1720 0.1707 0.1910 0.1931 0.1870 0.2000 0.2192 0.2161 0.2155 

[TRAIN] Epoch[7](1218/1500); Loss: 0.169646; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1605 0.1553 0.1619 0.1555 0.1590 0.1670 0.1661 0.1634 0.1676 0.1744 0.1728 0.1720 0.1811 0.1858 0.1842 0.1878 

[TRAIN] Epoch[7](1219/1500); Loss: 0.203474; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1501 0.1550 0.2097 0.1957 0.1924 0.2085 0.2147 0.2060 0.1983 0.2167 0.2164 0.2068 0.2139 0.2299 0.2230 0.2184 

[TRAIN] Epoch[7](1220/1500); Loss: 0.110826; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0944 0.0915 0.0897 0.0843 0.0925 0.1045 0.1019 0.0986 0.1078 0.1157 0.1154 0.1191 0.1318 0.1368 0.1402 0.1492 

[TRAIN] Epoch[7](1221/1500); Loss: 0.198653; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1863 0.1811 0.2018 0.1950 0.1927 0.2011 0.2013 0.1983 0.1968 0.2029 0.2021 0.1984 0.2024 0.2077 0.2060 0.2045 

[TRAIN] Epoch[7](1222/1500); Loss: 0.183844; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1699 0.1671 0.1909 0.1814 0.1766 0.1874 0.1877 0.1834 0.1808 0.1885 0.1872 0.1819 0.1867 0.1931 0.1906 0.1885 

[TRAIN] Epoch[7](1223/1500); Loss: 0.261671; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2096 0.2042 0.2566 0.2399 0.2363 0.2663 0.2690 0.2596 0.2555 0.2798 0.2784 0.2660 0.2804 0.3038 0.2960 0.2854 

[TRAIN] Epoch[7](1224/1500); Loss: 0.173595; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1123 0.1051 0.1336 0.1345 0.1376 0.1528 0.1651 0.1641 0.1710 0.1892 0.1978 0.1968 0.2119 0.2313 0.2353 0.2391 

[TRAIN] Epoch[7](1225/1500); Loss: 0.139732; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1257 0.1262 0.1268 0.1305 0.1291 0.1306 0.1336 0.1359 0.1365 0.1398 0.1437 0.1464 0.1507 0.1558 0.1604 0.1640 

[TRAIN] Epoch[7](1226/1500); Loss: 0.124965; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1368 0.1339 0.1188 0.1144 0.1145 0.1157 0.1170 0.1176 0.1192 0.1218 0.1239 0.1260 0.1297 0.1335 0.1365 0.1402 

[TRAIN] Epoch[7](1227/1500); Loss: 0.140128; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1440 0.1311 0.1306 0.1311 0.1268 0.1212 0.1239 0.1267 0.1268 0.1327 0.1418 0.1457 0.1505 0.1632 0.1697 0.1762 

[TRAIN] Epoch[7](1228/1500); Loss: 0.135919; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1264 0.1235 0.1147 0.1188 0.1176 0.1198 0.1262 0.1288 0.1297 0.1354 0.1439 0.1449 0.1494 0.1601 0.1663 0.1691 

[TRAIN] Epoch[7](1229/1500); Loss: 0.186199; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1590 0.1565 0.1713 0.1739 0.1724 0.1765 0.1835 0.1836 0.1823 0.1906 0.1967 0.1952 0.1994 0.2113 0.2136 0.2133 

[TRAIN] Epoch[7](1230/1500); Loss: 0.133743; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.1633 0.1529 0.1080 0.1074 0.1033 0.1107 0.1185 0.1181 0.1202 0.1299 0.1380 0.1377 0.1449 0.1580 0.1632 0.1659 

[TRAIN] Epoch[7](1231/1500); Loss: 0.176271; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1783 0.1714 0.1821 0.1668 0.1612 0.1711 0.1731 0.1697 0.1688 0.1781 0.1781 0.1742 0.1816 0.1896 0.1884 0.1878 

[TRAIN] Epoch[7](1232/1500); Loss: 0.162476; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1762 0.1723 0.1538 0.1542 0.1509 0.1515 0.1533 0.1547 0.1559 0.1584 0.1616 0.1639 0.1675 0.1713 0.1750 0.1790 

[TRAIN] Epoch[7](1233/1500); Loss: 0.298689; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.2269 0.2289 0.3025 0.2832 0.2800 0.3082 0.3108 0.3003 0.2960 0.3207 0.3159 0.3029 0.3184 0.3381 0.3278 0.3183 

[TRAIN] Epoch[7](1234/1500); Loss: 0.181066; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1720 0.1689 0.1821 0.1760 0.1734 0.1819 0.1815 0.1783 0.1777 0.1842 0.1834 0.1805 0.1858 0.1913 0.1904 0.1896 

[TRAIN] Epoch[7](1235/1500); Loss: 0.134095; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2088 0.1918 0.0960 0.0822 0.0764 0.1013 0.1083 0.1090 0.1148 0.1292 0.1339 0.1357 0.1503 0.1647 0.1668 0.1763 

[TRAIN] Epoch[7](1236/1500); Loss: 0.185552; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1414 0.1340 0.1780 0.1776 0.1730 0.1842 0.1928 0.1898 0.1844 0.1943 0.1997 0.1932 0.1983 0.2097 0.2117 0.2067 

[TRAIN] Epoch[7](1237/1500); Loss: 0.176741; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1393 0.1415 0.1716 0.1655 0.1619 0.1751 0.1790 0.1742 0.1726 0.1856 0.1863 0.1816 0.1908 0.2028 0.2012 0.1988 

[TRAIN] Epoch[7](1238/1500); Loss: 0.127838; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1464 0.1383 0.1012 0.0953 0.0947 0.1033 0.1104 0.1095 0.1152 0.1267 0.1335 0.1351 0.1455 0.1583 0.1633 0.1687 

[TRAIN] Epoch[7](1239/1500); Loss: 0.203000; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2038 0.1959 0.2150 0.2017 0.1955 0.2063 0.2070 0.2006 0.1954 0.2051 0.2035 0.1964 0.2012 0.2104 0.2073 0.2028 

[TRAIN] Epoch[7](1240/1500); Loss: 0.079840; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0729 0.0741 0.0716 0.0733 0.0715 0.0719 0.0730 0.0744 0.0763 0.0794 0.0818 0.0848 0.0880 0.0917 0.0946 0.0982 

[TRAIN] Epoch[7](1241/1500); Loss: 0.178611; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1765 0.1718 0.1786 0.1736 0.1708 0.1766 0.1771 0.1749 0.1739 0.1796 0.1800 0.1781 0.1824 0.1879 0.1881 0.1879 

[TRAIN] Epoch[7](1242/1500); Loss: 0.177182; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1606 0.1581 0.1847 0.1755 0.1701 0.1798 0.1807 0.1760 0.1733 0.1810 0.1801 0.1762 0.1806 0.1869 0.1858 0.1854 

[TRAIN] Epoch[7](1243/1500); Loss: 0.184388; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1795 0.1757 0.1770 0.1727 0.1707 0.1741 0.1776 0.1788 0.1796 0.1840 0.1873 0.1888 0.1942 0.1999 0.2034 0.2067 

[TRAIN] Epoch[7](1244/1500); Loss: 0.173495; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1370 0.1193 0.1316 0.1491 0.1431 0.1439 0.1633 0.1706 0.1709 0.1746 0.1934 0.1992 0.2025 0.2131 0.2306 0.2339 

[TRAIN] Epoch[7](1245/1500); Loss: 0.095824; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1397 0.1227 0.1029 0.0964 0.0845 0.0775 0.0761 0.0779 0.0788 0.0810 0.0856 0.0902 0.0951 0.1013 0.1083 0.1152 

[TRAIN] Epoch[7](1246/1500); Loss: 0.149502; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1361 0.1394 0.1285 0.1334 0.1362 0.1391 0.1405 0.1427 0.1471 0.1504 0.1546 0.1584 0.1638 0.1689 0.1740 0.1789 

[TRAIN] Epoch[7](1247/1500); Loss: 0.160843; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1533 0.1482 0.1501 0.1466 0.1463 0.1520 0.1535 0.1529 0.1563 0.1627 0.1647 0.1657 0.1732 0.1800 0.1820 0.1859 

[TRAIN] Epoch[7](1248/1500); Loss: 0.368902; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2981 0.2988 0.3632 0.3514 0.3447 0.3712 0.3794 0.3715 0.3640 0.3871 0.3908 0.3782 0.3879 0.4119 0.4087 0.3956 

[TRAIN] Epoch[7](1249/1500); Loss: 0.068447; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.0953 0.0916 0.0737 0.0674 0.0609 0.0576 0.0561 0.0570 0.0576 0.0594 0.0619 0.0646 0.0679 0.0712 0.0748 0.0778 

[TRAIN] Epoch[7](1250/1500); Loss: 0.105708; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1004 0.0966 0.0971 0.0984 0.0971 0.0968 0.0982 0.0998 0.1008 0.1031 0.1069 0.1104 0.1142 0.1186 0.1237 0.1292 

[TRAIN] Epoch[7](1251/1500); Loss: 0.350576; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2727 0.2746 0.3554 0.3349 0.3279 0.3624 0.3651 0.3533 0.3472 0.3741 0.3707 0.3540 0.3686 0.3946 0.3840 0.3696 

[TRAIN] Epoch[7](1252/1500); Loss: 0.139105; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1190 0.1175 0.1455 0.1359 0.1325 0.1426 0.1418 0.1376 0.1376 0.1434 0.1421 0.1399 0.1448 0.1484 0.1476 0.1496 

[TRAIN] Epoch[7](1253/1500); Loss: 0.135791; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0950 0.0897 0.1293 0.1252 0.1198 0.1273 0.1393 0.1344 0.1287 0.1442 0.1489 0.1438 0.1504 0.1664 0.1656 0.1648 

[TRAIN] Epoch[7](1254/1500); Loss: 0.261579; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2359 0.2322 0.2857 0.2691 0.2605 0.2771 0.2783 0.2673 0.2582 0.2713 0.2666 0.2518 0.2578 0.2680 0.2587 0.2465 

[TRAIN] Epoch[7](1255/1500); Loss: 0.190901; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1348 0.1342 0.2055 0.1854 0.1768 0.2029 0.2051 0.1932 0.1858 0.2065 0.2026 0.1890 0.2011 0.2187 0.2105 0.2022 

[TRAIN] Epoch[7](1256/1500); Loss: 0.243043; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1852 0.1876 0.2710 0.2469 0.2386 0.2655 0.2680 0.2522 0.2402 0.2624 0.2546 0.2335 0.2462 0.2613 0.2460 0.2295 

[TRAIN] Epoch[7](1257/1500); Loss: 0.190730; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1033 0.0969 0.1485 0.1616 0.1536 0.1635 0.1900 0.1923 0.1861 0.2031 0.2250 0.2209 0.2256 0.2539 0.2659 0.2614 

[TRAIN] Epoch[7](1258/1500); Loss: 0.257576; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2485 0.2424 0.2711 0.2605 0.2530 0.2638 0.2642 0.2572 0.2525 0.2615 0.2590 0.2514 0.2569 0.2637 0.2600 0.2555 

[TRAIN] Epoch[7](1259/1500); Loss: 0.208668; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1826 0.1781 0.1822 0.1937 0.1886 0.1875 0.2007 0.2060 0.2023 0.2074 0.2250 0.2225 0.2218 0.2416 0.2505 0.2480 

[TRAIN] Epoch[7](1260/1500); Loss: 0.308936; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.2569 0.2547 0.3330 0.3112 0.3009 0.3270 0.3291 0.3152 0.3053 0.3264 0.3209 0.3019 0.3116 0.3302 0.3178 0.3010 

[TRAIN] Epoch[7](1261/1500); Loss: 0.156074; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1708 0.1662 0.1484 0.1519 0.1471 0.1456 0.1487 0.1508 0.1492 0.1496 0.1546 0.1559 0.1575 0.1624 0.1677 0.1708 

[TRAIN] Epoch[7](1262/1500); Loss: 0.108369; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1035 0.0950 0.1382 0.1224 0.1101 0.1153 0.1159 0.1047 0.0951 0.1019 0.1002 0.0960 0.1020 0.1081 0.1103 0.1151 

[TRAIN] Epoch[7](1263/1500); Loss: 0.182131; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1599 0.1608 0.1819 0.1757 0.1719 0.1814 0.1831 0.1792 0.1777 0.1875 0.1872 0.1833 0.1907 0.1988 0.1979 0.1970 

[TRAIN] Epoch[7](1264/1500); Loss: 0.146379; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1568 0.1440 0.1392 0.1401 0.1361 0.1305 0.1312 0.1340 0.1336 0.1371 0.1455 0.1488 0.1531 0.1640 0.1706 0.1774 

[TRAIN] Epoch[7](1265/1500); Loss: 0.064825; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.0492 0.0444 0.0561 0.0518 0.0504 0.0530 0.0546 0.0570 0.0611 0.0655 0.0697 0.0750 0.0800 0.0848 0.0896 0.0951 

[TRAIN] Epoch[7](1266/1500); Loss: 0.391944; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.3278 0.3277 0.4060 0.3875 0.3793 0.4042 0.4125 0.4000 0.3868 0.4104 0.4109 0.3930 0.3981 0.4223 0.4113 0.3933 

[TRAIN] Epoch[7](1267/1500); Loss: 0.189823; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1726 0.1691 0.1770 0.1764 0.1739 0.1789 0.1856 0.1834 0.1835 0.1938 0.1969 0.1958 0.2038 0.2145 0.2149 0.2172 

[TRAIN] Epoch[7](1268/1500); Loss: 0.155202; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1516 0.1458 0.1615 0.1542 0.1502 0.1551 0.1555 0.1508 0.1494 0.1551 0.1543 0.1530 0.1574 0.1620 0.1628 0.1647 

[TRAIN] Epoch[7](1269/1500); Loss: 0.160337; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1564 0.1502 0.1490 0.1453 0.1447 0.1502 0.1522 0.1520 0.1549 0.1614 0.1639 0.1653 0.1725 0.1795 0.1820 0.1857 

[TRAIN] Epoch[7](1270/1500); Loss: 0.153959; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1532 0.1426 0.1453 0.1541 0.1468 0.1410 0.1482 0.1533 0.1489 0.1472 0.1572 0.1585 0.1567 0.1635 0.1736 0.1731 

[TRAIN] Epoch[7](1271/1500); Loss: 0.237245; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1914 0.1932 0.2712 0.2480 0.2370 0.2584 0.2627 0.2463 0.2321 0.2520 0.2454 0.2248 0.2334 0.2480 0.2335 0.2184 

[TRAIN] Epoch[7](1272/1500); Loss: 0.178762; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1549 0.1576 0.1796 0.1726 0.1687 0.1782 0.1795 0.1754 0.1746 0.1841 0.1838 0.1800 0.1875 0.1958 0.1942 0.1937 

[TRAIN] Epoch[7](1273/1500); Loss: 0.171551; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2145 0.1990 0.1646 0.1545 0.1500 0.1537 0.1563 0.1564 0.1592 0.1642 0.1670 0.1701 0.1765 0.1826 0.1862 0.1900 

[TRAIN] Epoch[7](1274/1500); Loss: 0.189160; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1754 0.1747 0.1850 0.1810 0.1794 0.1845 0.1866 0.1843 0.1852 0.1910 0.1911 0.1924 0.1985 0.2028 0.2050 0.2097 

[TRAIN] Epoch[7](1275/1500); Loss: 0.157291; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1640 0.1580 0.1525 0.1492 0.1481 0.1527 0.1526 0.1502 0.1521 0.1572 0.1568 0.1564 0.1631 0.1666 0.1667 0.1706 

[TRAIN] Epoch[7](1276/1500); Loss: 0.108275; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1211 0.1133 0.0921 0.0894 0.0882 0.0926 0.0932 0.0940 0.0979 0.1032 0.1083 0.1141 0.1211 0.1274 0.1345 0.1418 

[TRAIN] Epoch[7](1277/1500); Loss: 0.255664; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2400 0.2341 0.2476 0.2408 0.2376 0.2481 0.2534 0.2481 0.2472 0.2621 0.2620 0.2595 0.2698 0.2826 0.2780 0.2796 

[TRAIN] Epoch[7](1278/1500); Loss: 0.169352; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1612 0.1598 0.1706 0.1633 0.1573 0.1645 0.1673 0.1638 0.1625 0.1707 0.1723 0.1696 0.1755 0.1839 0.1836 0.1837 

[TRAIN] Epoch[7](1279/1500); Loss: 0.110913; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0947 0.0937 0.1090 0.1020 0.0998 0.1073 0.1075 0.1044 0.1063 0.1120 0.1128 0.1149 0.1216 0.1259 0.1290 0.1337 

[TRAIN] Epoch[7](1280/1500); Loss: 0.255315; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2432 0.2379 0.2663 0.2435 0.2355 0.2570 0.2647 0.2542 0.2440 0.2637 0.2648 0.2514 0.2563 0.2762 0.2684 0.2580 

[TRAIN] Epoch[7](1281/1500); Loss: 0.182542; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1811 0.1797 0.1798 0.1786 0.1768 0.1779 0.1788 0.1786 0.1789 0.1815 0.1828 0.1838 0.1867 0.1897 0.1916 0.1944 

[TRAIN] Epoch[7](1282/1500); Loss: 0.156585; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1470 0.1375 0.1511 0.1493 0.1438 0.1452 0.1492 0.1475 0.1469 0.1547 0.1584 0.1598 0.1680 0.1768 0.1813 0.1892 

[TRAIN] Epoch[7](1283/1500); Loss: 0.369057; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.3166 0.3170 0.3899 0.3722 0.3613 0.3801 0.3893 0.3766 0.3628 0.3833 0.3839 0.3663 0.3696 0.3916 0.3808 0.3635 

[TRAIN] Epoch[7](1284/1500); Loss: 0.114644; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1088 0.1045 0.1259 0.1153 0.1096 0.1161 0.1161 0.1108 0.1095 0.1147 0.1138 0.1117 0.1157 0.1199 0.1199 0.1220 

[TRAIN] Epoch[7](1285/1500); Loss: 0.198955; Backpropagation: 0.0923 sec; Batch: 0.4250 sec
0.1653 0.1664 0.2316 0.2115 0.1999 0.2155 0.2194 0.2045 0.1920 0.2083 0.2019 0.1851 0.1942 0.2060 0.1952 0.1867 

[TRAIN] Epoch[7](1286/1500); Loss: 0.165188; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1685 0.1625 0.1785 0.1658 0.1585 0.1666 0.1675 0.1609 0.1571 0.1656 0.1636 0.1580 0.1636 0.1707 0.1685 0.1673 

[TRAIN] Epoch[7](1287/1500); Loss: 0.131281; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1392 0.1364 0.1278 0.1283 0.1245 0.1234 0.1237 0.1241 0.1251 0.1272 0.1291 0.1314 0.1353 0.1382 0.1414 0.1454 

[TRAIN] Epoch[7](1288/1500); Loss: 0.120921; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0967 0.0974 0.1260 0.1167 0.1093 0.1185 0.1203 0.1152 0.1139 0.1231 0.1231 0.1222 0.1297 0.1373 0.1406 0.1449 

[TRAIN] Epoch[7](1289/1500); Loss: 0.106928; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0974 0.0959 0.0985 0.1034 0.1003 0.0981 0.1005 0.1022 0.1026 0.1045 0.1086 0.1117 0.1152 0.1190 0.1240 0.1290 

[TRAIN] Epoch[7](1290/1500); Loss: 0.167990; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1458 0.1473 0.1495 0.1599 0.1559 0.1535 0.1611 0.1654 0.1634 0.1667 0.1771 0.1766 0.1789 0.1906 0.1971 0.1991 

[TRAIN] Epoch[7](1291/1500); Loss: 0.131130; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1006 0.0941 0.1050 0.1181 0.1138 0.1115 0.1234 0.1279 0.1262 0.1302 0.1450 0.1449 0.1473 0.1620 0.1731 0.1750 

[TRAIN] Epoch[7](1292/1500); Loss: 0.076321; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1364 0.1213 0.0661 0.0550 0.0547 0.0564 0.0570 0.0573 0.0598 0.0638 0.0682 0.0730 0.0788 0.0853 0.0910 0.0970 

[TRAIN] Epoch[7](1293/1500); Loss: 0.180317; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1593 0.1601 0.1625 0.1707 0.1667 0.1659 0.1738 0.1768 0.1754 0.1806 0.1892 0.1894 0.1926 0.2034 0.2083 0.2105 

[TRAIN] Epoch[7](1294/1500); Loss: 0.147368; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1617 0.1542 0.1367 0.1363 0.1329 0.1354 0.1363 0.1361 0.1382 0.1438 0.1454 0.1484 0.1564 0.1605 0.1641 0.1713 

[TRAIN] Epoch[7](1295/1500); Loss: 0.204061; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1877 0.1864 0.2107 0.2010 0.1951 0.2025 0.2072 0.2022 0.1980 0.2073 0.2073 0.2028 0.2089 0.2175 0.2159 0.2145 

[TRAIN] Epoch[7](1296/1500); Loss: 0.211266; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2175 0.2087 0.2195 0.2137 0.2078 0.2106 0.2126 0.2092 0.2051 0.2102 0.2101 0.2068 0.2091 0.2140 0.2135 0.2118 

[TRAIN] Epoch[7](1297/1500); Loss: 0.141018; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1593 0.1494 0.1355 0.1326 0.1307 0.1341 0.1338 0.1322 0.1340 0.1383 0.1384 0.1392 0.1456 0.1486 0.1500 0.1548 

[TRAIN] Epoch[7](1298/1500); Loss: 0.156115; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1599 0.1527 0.1595 0.1554 0.1517 0.1525 0.1530 0.1512 0.1507 0.1535 0.1543 0.1553 0.1579 0.1609 0.1632 0.1661 

[TRAIN] Epoch[7](1299/1500); Loss: 0.120378; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1625 0.1476 0.0828 0.0760 0.0777 0.0889 0.0956 0.0935 0.1028 0.1171 0.1241 0.1280 0.1412 0.1561 0.1605 0.1717 

[TRAIN] Epoch[7](1300/1500); Loss: 0.221030; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1929 0.1945 0.2215 0.2200 0.2143 0.2151 0.2235 0.2198 0.2154 0.2247 0.2283 0.2239 0.2287 0.2393 0.2375 0.2372 

[TRAIN] Epoch[7](1301/1500); Loss: 0.141818; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.1393 0.1363 0.1331 0.1351 0.1314 0.1307 0.1341 0.1347 0.1350 0.1387 0.1428 0.1465 0.1498 0.1548 0.1612 0.1655 

[TRAIN] Epoch[7](1302/1500); Loss: 0.232901; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2343 0.2291 0.2417 0.2353 0.2296 0.2331 0.2350 0.2311 0.2274 0.2323 0.2319 0.2281 0.2318 0.2364 0.2352 0.2340 

[TRAIN] Epoch[7](1303/1500); Loss: 0.146227; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1135 0.1005 0.1296 0.1438 0.1343 0.1289 0.1447 0.1456 0.1375 0.1460 0.1625 0.1568 0.1569 0.1780 0.1814 0.1797 

[TRAIN] Epoch[7](1304/1500); Loss: 0.136159; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1454 0.1367 0.1443 0.1364 0.1285 0.1246 0.1303 0.1292 0.1246 0.1285 0.1334 0.1330 0.1367 0.1448 0.1490 0.1532 

[TRAIN] Epoch[7](1305/1500); Loss: 0.126333; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1486 0.1363 0.1109 0.1105 0.1080 0.1109 0.1116 0.1125 0.1175 0.1224 0.1245 0.1288 0.1379 0.1418 0.1452 0.1541 

[TRAIN] Epoch[7](1306/1500); Loss: 0.100419; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.0943 0.0941 0.0782 0.0764 0.0792 0.0861 0.0874 0.0871 0.0934 0.0997 0.1041 0.1098 0.1190 0.1255 0.1320 0.1403 

[TRAIN] Epoch[7](1307/1500); Loss: 0.146565; Backpropagation: 0.0922 sec; Batch: 0.4249 sec
0.1565 0.1458 0.1415 0.1367 0.1362 0.1412 0.1405 0.1379 0.1402 0.1454 0.1450 0.1460 0.1536 0.1567 0.1584 0.1634 

[TRAIN] Epoch[7](1308/1500); Loss: 0.268647; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2362 0.2325 0.2750 0.2628 0.2577 0.2718 0.2766 0.2668 0.2619 0.2770 0.2790 0.2679 0.2755 0.2911 0.2865 0.2800 

[TRAIN] Epoch[7](1309/1500); Loss: 0.103072; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.0785 0.0692 0.0828 0.1046 0.0955 0.0838 0.0944 0.1009 0.0974 0.0982 0.1108 0.1143 0.1188 0.1258 0.1338 0.1403 

[TRAIN] Epoch[7](1310/1500); Loss: 0.218728; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1928 0.1851 0.2144 0.2105 0.2047 0.2131 0.2210 0.2156 0.2104 0.2239 0.2297 0.2222 0.2280 0.2447 0.2441 0.2396 

[TRAIN] Epoch[7](1311/1500); Loss: 0.199425; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1726 0.1677 0.2059 0.1902 0.1880 0.2042 0.2077 0.1968 0.1933 0.2086 0.2071 0.1969 0.2077 0.2198 0.2133 0.2109 

[TRAIN] Epoch[7](1312/1500); Loss: 0.080075; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0990 0.0894 0.0758 0.0730 0.0702 0.0678 0.0704 0.0720 0.0708 0.0724 0.0773 0.0799 0.0833 0.0878 0.0936 0.0986 

[TRAIN] Epoch[7](1313/1500); Loss: 0.176039; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1834 0.1737 0.1805 0.1766 0.1717 0.1706 0.1725 0.1702 0.1682 0.1719 0.1730 0.1736 0.1768 0.1810 0.1848 0.1880 

[TRAIN] Epoch[7](1314/1500); Loss: 0.138422; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1316 0.1216 0.1099 0.1118 0.1147 0.1190 0.1230 0.1219 0.1301 0.1380 0.1451 0.1502 0.1607 0.1721 0.1775 0.1877 

[TRAIN] Epoch[7](1315/1500); Loss: 0.160185; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1000 0.0893 0.1269 0.1446 0.1341 0.1315 0.1561 0.1563 0.1495 0.1667 0.1882 0.1834 0.1851 0.2140 0.2196 0.2176 

[TRAIN] Epoch[7](1316/1500); Loss: 0.055612; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0366 0.0370 0.0426 0.0413 0.0411 0.0436 0.0463 0.0507 0.0553 0.0595 0.0634 0.0678 0.0709 0.0746 0.0775 0.0816 

[TRAIN] Epoch[7](1317/1500); Loss: 0.110899; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1126 0.1119 0.1033 0.1042 0.1021 0.1029 0.1036 0.1044 0.1062 0.1086 0.1110 0.1138 0.1174 0.1203 0.1239 0.1282 

[TRAIN] Epoch[7](1318/1500); Loss: 0.091926; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1034 0.0943 0.0767 0.0767 0.0779 0.0815 0.0794 0.0791 0.0829 0.0857 0.0905 0.0966 0.1018 0.1074 0.1157 0.1213 

[TRAIN] Epoch[7](1319/1500); Loss: 0.183688; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1882 0.1826 0.2014 0.1927 0.1840 0.1883 0.1898 0.1831 0.1764 0.1823 0.1803 0.1737 0.1768 0.1820 0.1795 0.1780 

[TRAIN] Epoch[7](1320/1500); Loss: 0.159298; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1773 0.1634 0.1613 0.1594 0.1550 0.1519 0.1513 0.1494 0.1482 0.1508 0.1536 0.1555 0.1594 0.1658 0.1708 0.1756 

[TRAIN] Epoch[7](1321/1500); Loss: 0.087950; Backpropagation: 0.0921 sec; Batch: 0.4232 sec
0.0820 0.0816 0.0824 0.0830 0.0810 0.0811 0.0823 0.0840 0.0861 0.0882 0.0906 0.0928 0.0947 0.0968 0.0991 0.1014 

[TRAIN] Epoch[7](1322/1500); Loss: 0.141940; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1699 0.1580 0.1159 0.1141 0.1206 0.1274 0.1219 0.1211 0.1373 0.1381 0.1348 0.1474 0.1623 0.1594 0.1607 0.1821 

[TRAIN] Epoch[7](1323/1500); Loss: 0.153382; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2114 0.2002 0.1687 0.1448 0.1408 0.1414 0.1417 0.1397 0.1388 0.1420 0.1433 0.1434 0.1463 0.1499 0.1506 0.1512 

[TRAIN] Epoch[7](1324/1500); Loss: 0.115291; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1023 0.1016 0.1059 0.1058 0.1024 0.1042 0.1063 0.1075 0.1100 0.1148 0.1183 0.1241 0.1284 0.1319 0.1373 0.1440 

[TRAIN] Epoch[7](1325/1500); Loss: 0.118953; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1204 0.1180 0.1195 0.1172 0.1127 0.1128 0.1137 0.1123 0.1120 0.1152 0.1176 0.1193 0.1230 0.1265 0.1296 0.1336 

[TRAIN] Epoch[7](1326/1500); Loss: 0.154701; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.1718 0.1614 0.1476 0.1478 0.1427 0.1437 0.1466 0.1453 0.1459 0.1509 0.1536 0.1545 0.1596 0.1652 0.1673 0.1713 

[TRAIN] Epoch[7](1327/1500); Loss: 0.129352; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1397 0.1365 0.1230 0.1218 0.1195 0.1204 0.1208 0.1213 0.1224 0.1244 0.1274 0.1306 0.1342 0.1378 0.1428 0.1471 

[TRAIN] Epoch[7](1328/1500); Loss: 0.130664; Backpropagation: 0.0922 sec; Batch: 0.4234 sec
0.1351 0.1307 0.1398 0.1356 0.1273 0.1298 0.1308 0.1267 0.1236 0.1277 0.1283 0.1256 0.1293 0.1331 0.1331 0.1341 

[TRAIN] Epoch[7](1329/1500); Loss: 0.131171; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1308 0.1294 0.1256 0.1280 0.1258 0.1246 0.1245 0.1252 0.1270 0.1284 0.1303 0.1337 0.1384 0.1388 0.1415 0.1467 

[TRAIN] Epoch[7](1330/1500); Loss: 0.217528; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2430 0.2346 0.2333 0.2270 0.2168 0.2156 0.2164 0.2121 0.2071 0.2109 0.2109 0.2066 0.2092 0.2136 0.2130 0.2105 

[TRAIN] Epoch[7](1331/1500); Loss: 0.206901; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1902 0.1873 0.1937 0.2011 0.1970 0.1954 0.2042 0.2026 0.1997 0.2091 0.2155 0.2130 0.2164 0.2296 0.2279 0.2279 

[TRAIN] Epoch[7](1332/1500); Loss: 0.352434; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.3676 0.3598 0.4056 0.3879 0.3706 0.3792 0.3803 0.3636 0.3462 0.3528 0.3441 0.3228 0.3229 0.3273 0.3124 0.2957 

[TRAIN] Epoch[7](1333/1500); Loss: 0.141459; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1361 0.1316 0.1391 0.1336 0.1276 0.1315 0.1384 0.1335 0.1308 0.1420 0.1428 0.1415 0.1504 0.1592 0.1599 0.1653 

[TRAIN] Epoch[7](1334/1500); Loss: 0.267289; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2640 0.2572 0.2777 0.2742 0.2681 0.2675 0.2735 0.2686 0.2599 0.2681 0.2696 0.2616 0.2628 0.2735 0.2691 0.2613 

[TRAIN] Epoch[7](1335/1500); Loss: 0.292299; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2401 0.2403 0.2965 0.2880 0.2798 0.2895 0.3029 0.2942 0.2842 0.3060 0.3060 0.2951 0.3058 0.3243 0.3163 0.3077 

[TRAIN] Epoch[7](1336/1500); Loss: 0.135161; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1193 0.1122 0.1480 0.1359 0.1286 0.1387 0.1403 0.1320 0.1274 0.1388 0.1363 0.1297 0.1385 0.1477 0.1451 0.1440 

[TRAIN] Epoch[7](1337/1500); Loss: 0.133147; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1411 0.1331 0.1307 0.1275 0.1250 0.1242 0.1240 0.1242 0.1255 0.1276 0.1305 0.1346 0.1385 0.1428 0.1481 0.1531 

[TRAIN] Epoch[7](1338/1500); Loss: 0.198551; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1984 0.1953 0.2323 0.2199 0.2078 0.2116 0.2120 0.2020 0.1937 0.1982 0.1939 0.1838 0.1841 0.1874 0.1811 0.1753 

[TRAIN] Epoch[7](1339/1500); Loss: 0.199531; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1966 0.1893 0.2218 0.2097 0.2033 0.2092 0.2107 0.2011 0.1937 0.2025 0.1978 0.1879 0.1934 0.1986 0.1915 0.1856 

[TRAIN] Epoch[7](1340/1500); Loss: 0.125555; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1241 0.1046 0.1226 0.1365 0.1268 0.1147 0.1250 0.1290 0.1190 0.1169 0.1297 0.1261 0.1215 0.1331 0.1407 0.1386 

[TRAIN] Epoch[7](1341/1500); Loss: 0.243353; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2243 0.2191 0.2528 0.2455 0.2374 0.2465 0.2516 0.2444 0.2367 0.2485 0.2490 0.2397 0.2448 0.2568 0.2523 0.2444 

[TRAIN] Epoch[7](1342/1500); Loss: 0.206441; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2051 0.1996 0.2498 0.2339 0.2206 0.2266 0.2261 0.2129 0.2023 0.2085 0.2016 0.1857 0.1872 0.1914 0.1805 0.1712 

[TRAIN] Epoch[7](1343/1500); Loss: 0.158294; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1609 0.1551 0.1737 0.1653 0.1563 0.1588 0.1593 0.1542 0.1507 0.1549 0.1546 0.1521 0.1549 0.1595 0.1609 0.1616 

[TRAIN] Epoch[7](1344/1500); Loss: 0.239053; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2054 0.2027 0.2458 0.2350 0.2262 0.2407 0.2441 0.2356 0.2300 0.2480 0.2464 0.2365 0.2498 0.2653 0.2604 0.2529 

[TRAIN] Epoch[7](1345/1500); Loss: 0.087718; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.0910 0.0879 0.0829 0.0870 0.0828 0.0795 0.0807 0.0819 0.0821 0.0830 0.0865 0.0890 0.0924 0.0953 0.0986 0.1030 

[TRAIN] Epoch[7](1346/1500); Loss: 0.107782; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.0833 0.0799 0.1019 0.1038 0.0972 0.0966 0.1022 0.1024 0.1012 0.1071 0.1125 0.1147 0.1203 0.1277 0.1333 0.1402 

[TRAIN] Epoch[7](1347/1500); Loss: 0.339648; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.3024 0.3032 0.3784 0.3585 0.3435 0.3572 0.3653 0.3498 0.3310 0.3506 0.3451 0.3239 0.3319 0.3472 0.3332 0.3131 

[TRAIN] Epoch[7](1348/1500); Loss: 0.143158; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1188 0.1095 0.1384 0.1473 0.1371 0.1312 0.1442 0.1423 0.1326 0.1418 0.1533 0.1488 0.1475 0.1644 0.1678 0.1655 

[TRAIN] Epoch[7](1349/1500); Loss: 0.131894; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1401 0.1350 0.1392 0.1326 0.1268 0.1260 0.1268 0.1235 0.1226 0.1264 0.1276 0.1304 0.1327 0.1363 0.1407 0.1434 

[TRAIN] Epoch[7](1350/1500); Loss: 0.124101; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1829 0.1706 0.1262 0.1053 0.0993 0.1100 0.1199 0.1117 0.1028 0.1160 0.1175 0.1120 0.1193 0.1319 0.1295 0.1306 

[TRAIN] Epoch[7](1351/1500); Loss: 0.085680; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.0827 0.0851 0.0658 0.0665 0.0669 0.0713 0.0743 0.0726 0.0776 0.0841 0.0879 0.0920 0.1010 0.1088 0.1130 0.1213 

[TRAIN] Epoch[7](1352/1500); Loss: 0.094138; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1151 0.0959 0.1044 0.1139 0.1039 0.0916 0.0937 0.0933 0.0839 0.0813 0.0881 0.0847 0.0827 0.0883 0.0915 0.0941 

[TRAIN] Epoch[7](1353/1500); Loss: 0.148046; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1567 0.1476 0.1616 0.1526 0.1507 0.1536 0.1524 0.1452 0.1425 0.1468 0.1434 0.1389 0.1439 0.1461 0.1437 0.1431 

[TRAIN] Epoch[7](1354/1500); Loss: 0.144967; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1582 0.1448 0.1519 0.1480 0.1412 0.1389 0.1389 0.1344 0.1328 0.1369 0.1375 0.1393 0.1453 0.1505 0.1571 0.1638 

[TRAIN] Epoch[7](1355/1500); Loss: 0.130201; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1405 0.1355 0.1601 0.1388 0.1248 0.1315 0.1328 0.1236 0.1179 0.1267 0.1234 0.1169 0.1246 0.1293 0.1275 0.1294 

[TRAIN] Epoch[7](1356/1500); Loss: 0.113281; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2117 0.1956 0.0811 0.0959 0.0779 0.0889 0.1023 0.0945 0.0816 0.0988 0.1089 0.1037 0.1038 0.1257 0.1211 0.1209 

[TRAIN] Epoch[7](1357/1500); Loss: 0.223776; Backpropagation: 0.0924 sec; Batch: 0.4245 sec
0.2162 0.2144 0.2342 0.2269 0.2203 0.2261 0.2282 0.2223 0.2178 0.2258 0.2238 0.2184 0.2244 0.2297 0.2265 0.2254 

[TRAIN] Epoch[7](1358/1500); Loss: 0.267949; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2545 0.2536 0.2750 0.2717 0.2662 0.2682 0.2738 0.2687 0.2616 0.2726 0.2716 0.2638 0.2698 0.2773 0.2713 0.2677 

[TRAIN] Epoch[7](1359/1500); Loss: 0.210527; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2206 0.2182 0.2258 0.2190 0.2109 0.2105 0.2129 0.2078 0.2020 0.2073 0.2059 0.2011 0.2048 0.2084 0.2065 0.2066 

[TRAIN] Epoch[7](1360/1500); Loss: 0.140104; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1395 0.1316 0.1373 0.1411 0.1329 0.1319 0.1397 0.1344 0.1285 0.1388 0.1417 0.1390 0.1428 0.1539 0.1546 0.1539 

[TRAIN] Epoch[7](1361/1500); Loss: 0.198413; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.2159 0.2069 0.1938 0.1887 0.1950 0.1960 0.1943 0.1903 0.1938 0.1958 0.1922 0.1955 0.2007 0.2017 0.2033 0.2104 

[TRAIN] Epoch[7](1362/1500); Loss: 0.157164; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1644 0.1572 0.1598 0.1557 0.1523 0.1538 0.1551 0.1523 0.1506 0.1547 0.1549 0.1544 0.1582 0.1619 0.1639 0.1655 

[TRAIN] Epoch[7](1363/1500); Loss: 0.316833; Backpropagation: 0.0923 sec; Batch: 0.4246 sec
0.3234 0.3150 0.3475 0.3345 0.3234 0.3309 0.3317 0.3200 0.3091 0.3182 0.3124 0.2980 0.3054 0.3096 0.2999 0.2903 

[TRAIN] Epoch[7](1364/1500); Loss: 0.201055; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1941 0.1926 0.2247 0.2159 0.2063 0.2107 0.2110 0.2026 0.1959 0.2017 0.1977 0.1896 0.1947 0.1968 0.1922 0.1905 

[TRAIN] Epoch[7](1365/1500); Loss: 0.122307; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1194 0.1181 0.1128 0.1077 0.1118 0.1167 0.1148 0.1126 0.1181 0.1204 0.1208 0.1256 0.1330 0.1360 0.1400 0.1490 

[TRAIN] Epoch[7](1366/1500); Loss: 0.427166; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.4371 0.4298 0.5035 0.4788 0.4541 0.4659 0.4673 0.4434 0.4186 0.4307 0.4163 0.3843 0.3917 0.3949 0.3701 0.3482 

[TRAIN] Epoch[7](1367/1500); Loss: 0.156948; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1614 0.1555 0.1599 0.1619 0.1572 0.1526 0.1551 0.1538 0.1509 0.1513 0.1548 0.1554 0.1548 0.1589 0.1626 0.1651 

[TRAIN] Epoch[7](1368/1500); Loss: 0.115664; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1494 0.1380 0.1392 0.1232 0.1157 0.1154 0.1144 0.1080 0.1054 0.1083 0.1064 0.1046 0.1037 0.1056 0.1060 0.1075 

[TRAIN] Epoch[7](1369/1500); Loss: 0.216064; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2047 0.2053 0.2235 0.2183 0.2142 0.2149 0.2193 0.2146 0.2103 0.2183 0.2155 0.2128 0.2190 0.2221 0.2207 0.2235 

[TRAIN] Epoch[7](1370/1500); Loss: 0.162722; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1524 0.1538 0.1753 0.1686 0.1607 0.1652 0.1658 0.1602 0.1572 0.1641 0.1615 0.1575 0.1630 0.1664 0.1655 0.1664 

[TRAIN] Epoch[7](1371/1500); Loss: 0.291141; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2910 0.2890 0.3113 0.2921 0.2847 0.2893 0.2988 0.2892 0.2788 0.2960 0.2913 0.2808 0.2916 0.2982 0.2893 0.2868 

[TRAIN] Epoch[7](1372/1500); Loss: 0.151941; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1808 0.1719 0.1489 0.1464 0.1423 0.1435 0.1441 0.1423 0.1424 0.1461 0.1481 0.1483 0.1517 0.1554 0.1578 0.1612 

[TRAIN] Epoch[7](1373/1500); Loss: 0.175159; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1900 0.1831 0.1817 0.1774 0.1725 0.1711 0.1717 0.1698 0.1681 0.1701 0.1710 0.1723 0.1725 0.1745 0.1779 0.1787 

[TRAIN] Epoch[7](1374/1500); Loss: 0.101990; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1508 0.1358 0.0749 0.0680 0.0722 0.0829 0.0832 0.0790 0.0876 0.0935 0.0950 0.1022 0.1155 0.1227 0.1277 0.1410 

[TRAIN] Epoch[7](1375/1500); Loss: 0.174024; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2182 0.2063 0.1813 0.1704 0.1667 0.1667 0.1658 0.1627 0.1624 0.1656 0.1672 0.1649 0.1681 0.1728 0.1727 0.1727 

[TRAIN] Epoch[7](1376/1500); Loss: 0.113814; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1208 0.1022 0.0926 0.1023 0.0964 0.0922 0.1020 0.1009 0.0997 0.1098 0.1165 0.1201 0.1252 0.1402 0.1471 0.1528 

[TRAIN] Epoch[7](1377/1500); Loss: 0.300257; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2948 0.2968 0.3160 0.3135 0.3075 0.3046 0.3086 0.3018 0.2947 0.3022 0.2977 0.2910 0.2961 0.2961 0.2905 0.2925 

[TRAIN] Epoch[7](1378/1500); Loss: 0.176866; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1851 0.1811 0.2194 0.2071 0.1952 0.1967 0.1942 0.1820 0.1736 0.1760 0.1679 0.1546 0.1560 0.1554 0.1453 0.1403 

[TRAIN] Epoch[7](1379/1500); Loss: 0.137815; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1500 0.1437 0.1387 0.1386 0.1330 0.1308 0.1341 0.1320 0.1295 0.1330 0.1349 0.1353 0.1370 0.1421 0.1451 0.1473 

[TRAIN] Epoch[7](1380/1500); Loss: 0.120208; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1501 0.1402 0.1274 0.1205 0.1130 0.1110 0.1121 0.1111 0.1105 0.1123 0.1153 0.1158 0.1165 0.1201 0.1230 0.1244 

[TRAIN] Epoch[7](1381/1500); Loss: 0.116584; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1037 0.1042 0.1135 0.1115 0.1075 0.1092 0.1097 0.1107 0.1147 0.1147 0.1183 0.1255 0.1231 0.1264 0.1349 0.1376 

[TRAIN] Epoch[7](1382/1500); Loss: 0.099622; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.1045 0.0917 0.1103 0.1028 0.0933 0.0908 0.0902 0.0873 0.0876 0.0921 0.0978 0.1020 0.1041 0.1100 0.1132 0.1163 

[TRAIN] Epoch[7](1383/1500); Loss: 0.110913; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1095 0.1073 0.1033 0.1069 0.1037 0.1012 0.1023 0.1039 0.1064 0.1067 0.1116 0.1161 0.1185 0.1214 0.1254 0.1306 

[TRAIN] Epoch[7](1384/1500); Loss: 0.100202; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1021 0.0907 0.0986 0.0862 0.0909 0.0994 0.0959 0.0855 0.0921 0.0947 0.0931 0.0980 0.1102 0.1154 0.1202 0.1303 

[TRAIN] Epoch[7](1385/1500); Loss: 0.145202; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1549 0.1484 0.1765 0.1663 0.1557 0.1566 0.1537 0.1441 0.1383 0.1406 0.1356 0.1293 0.1313 0.1322 0.1300 0.1298 

[TRAIN] Epoch[7](1386/1500); Loss: 0.115548; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1233 0.1172 0.1152 0.1146 0.1097 0.1082 0.1092 0.1076 0.1071 0.1096 0.1126 0.1162 0.1179 0.1220 0.1271 0.1311 

[TRAIN] Epoch[7](1387/1500); Loss: 0.094842; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1014 0.0976 0.0970 0.0946 0.0892 0.0898 0.0891 0.0875 0.0878 0.0900 0.0929 0.0955 0.0971 0.1004 0.1031 0.1046 

[TRAIN] Epoch[7](1388/1500); Loss: 0.174334; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1895 0.1819 0.1791 0.1753 0.1698 0.1681 0.1686 0.1672 0.1681 0.1691 0.1706 0.1725 0.1741 0.1757 0.1780 0.1817 

[TRAIN] Epoch[7](1389/1500); Loss: 0.175412; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1779 0.1709 0.1892 0.1899 0.1822 0.1780 0.1797 0.1749 0.1694 0.1711 0.1713 0.1679 0.1689 0.1718 0.1716 0.1720 

[TRAIN] Epoch[7](1390/1500); Loss: 0.120793; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1179 0.1090 0.1201 0.1232 0.1169 0.1143 0.1194 0.1150 0.1118 0.1162 0.1193 0.1198 0.1226 0.1318 0.1364 0.1391 

[TRAIN] Epoch[7](1391/1500); Loss: 0.164098; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1662 0.1594 0.1821 0.1742 0.1697 0.1707 0.1698 0.1622 0.1585 0.1604 0.1587 0.1563 0.1576 0.1603 0.1611 0.1586 

[TRAIN] Epoch[7](1392/1500); Loss: 0.162155; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1680 0.1640 0.1755 0.1706 0.1635 0.1638 0.1637 0.1587 0.1563 0.1588 0.1582 0.1571 0.1574 0.1593 0.1604 0.1591 

[TRAIN] Epoch[7](1393/1500); Loss: 0.097287; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1359 0.1300 0.1119 0.0974 0.0858 0.0832 0.0836 0.0837 0.0850 0.0855 0.0885 0.0930 0.0949 0.0957 0.1004 0.1023 

[TRAIN] Epoch[7](1394/1500); Loss: 0.138938; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1442 0.1459 0.1317 0.1330 0.1316 0.1319 0.1328 0.1331 0.1349 0.1348 0.1385 0.1424 0.1407 0.1451 0.1506 0.1518 

[TRAIN] Epoch[7](1395/1500); Loss: 0.075308; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.0673 0.0645 0.0945 0.0873 0.0783 0.0776 0.0753 0.0697 0.0681 0.0695 0.0699 0.0726 0.0729 0.0767 0.0807 0.0801 

[TRAIN] Epoch[7](1396/1500); Loss: 0.106140; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1034 0.1055 0.1029 0.1048 0.1039 0.1037 0.1034 0.1040 0.1052 0.1054 0.1064 0.1084 0.1087 0.1090 0.1112 0.1125 

[TRAIN] Epoch[7](1397/1500); Loss: 0.109971; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0917 0.0945 0.0957 0.1044 0.1003 0.0986 0.1037 0.1050 0.1088 0.1092 0.1133 0.1194 0.1221 0.1258 0.1326 0.1346 

[TRAIN] Epoch[7](1398/1500); Loss: 0.176361; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1744 0.1722 0.1890 0.1881 0.1817 0.1795 0.1789 0.1749 0.1729 0.1710 0.1707 0.1712 0.1708 0.1731 0.1765 0.1767 

[TRAIN] Epoch[7](1399/1500); Loss: 0.105974; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0875 0.0904 0.0941 0.1011 0.0982 0.0972 0.1008 0.1013 0.1049 0.1054 0.1095 0.1157 0.1173 0.1194 0.1250 0.1279 

[TRAIN] Epoch[7](1400/1500); Loss: 0.107429; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1699 0.1593 0.1292 0.1075 0.0970 0.0971 0.0976 0.0947 0.0940 0.0947 0.0939 0.0944 0.0958 0.0966 0.0981 0.0991 

[TRAIN] Epoch[7](1401/1500); Loss: 0.119494; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1347 0.1252 0.1623 0.1493 0.1317 0.1259 0.1201 0.1058 0.0975 0.0995 0.1005 0.1008 0.1053 0.1133 0.1178 0.1222 

[TRAIN] Epoch[7](1402/1500); Loss: 0.080656; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0575 0.0502 0.0743 0.0879 0.0780 0.0730 0.0839 0.0799 0.0773 0.0803 0.0833 0.0845 0.0859 0.0947 0.0991 0.1010 

[TRAIN] Epoch[7](1403/1500); Loss: 0.121404; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1453 0.1391 0.1261 0.1270 0.1203 0.1191 0.1179 0.1150 0.1137 0.1133 0.1160 0.1151 0.1150 0.1196 0.1197 0.1205 

[TRAIN] Epoch[7](1404/1500); Loss: 0.107409; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1370 0.1256 0.0958 0.0776 0.1071 0.1163 0.1071 0.1004 0.1109 0.0995 0.0969 0.1094 0.1024 0.1037 0.1150 0.1139 

[TRAIN] Epoch[7](1405/1500); Loss: 0.088758; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0700 0.0716 0.1095 0.1053 0.0970 0.0954 0.0938 0.0867 0.0831 0.0847 0.0830 0.0826 0.0851 0.0876 0.0913 0.0934 

[TRAIN] Epoch[7](1406/1500); Loss: 0.176351; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1891 0.1793 0.1816 0.1857 0.1823 0.1781 0.1785 0.1750 0.1715 0.1715 0.1712 0.1696 0.1703 0.1724 0.1722 0.1734 

[TRAIN] Epoch[7](1407/1500); Loss: 0.187684; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1922 0.1878 0.1920 0.1945 0.1907 0.1872 0.1882 0.1858 0.1837 0.1840 0.1842 0.1839 0.1840 0.1868 0.1890 0.1889 

[TRAIN] Epoch[7](1408/1500); Loss: 0.167670; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2200 0.2083 0.1946 0.1773 0.1729 0.1720 0.1690 0.1634 0.1597 0.1585 0.1552 0.1515 0.1488 0.1468 0.1429 0.1417 

[TRAIN] Epoch[7](1409/1500); Loss: 0.086359; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0700 0.0583 0.0875 0.1021 0.0908 0.0831 0.0925 0.0873 0.0826 0.0847 0.0861 0.0859 0.0869 0.0922 0.0950 0.0965 

[TRAIN] Epoch[7](1410/1500); Loss: 0.121836; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1416 0.1358 0.1690 0.1574 0.1450 0.1406 0.1342 0.1219 0.1131 0.1103 0.1031 0.0966 0.0951 0.0955 0.0951 0.0951 

[TRAIN] Epoch[7](1411/1500); Loss: 0.302535; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.3399 0.3294 0.3744 0.3576 0.3386 0.3333 0.3253 0.3062 0.2901 0.2854 0.2765 0.2621 0.2570 0.2597 0.2538 0.2512 

[TRAIN] Epoch[7](1412/1500); Loss: 0.111122; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1181 0.1181 0.1092 0.1104 0.1085 0.1068 0.1065 0.1069 0.1072 0.1079 0.1099 0.1115 0.1117 0.1136 0.1152 0.1163 

[TRAIN] Epoch[7](1413/1500); Loss: 0.125557; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1429 0.1386 0.1280 0.1235 0.1210 0.1201 0.1195 0.1198 0.1211 0.1213 0.1232 0.1244 0.1243 0.1260 0.1269 0.1282 

[TRAIN] Epoch[7](1414/1500); Loss: 0.136638; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1434 0.1396 0.1391 0.1377 0.1342 0.1327 0.1323 0.1323 0.1325 0.1335 0.1344 0.1362 0.1366 0.1386 0.1405 0.1428 

[TRAIN] Epoch[7](1415/1500); Loss: 0.181938; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1652 0.1676 0.2209 0.2117 0.2015 0.1985 0.1963 0.1853 0.1762 0.1820 0.1745 0.1665 0.1717 0.1666 0.1616 0.1649 

[TRAIN] Epoch[7](1416/1500); Loss: 0.166755; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1838 0.1799 0.1782 0.1758 0.1711 0.1712 0.1686 0.1652 0.1631 0.1623 0.1610 0.1581 0.1583 0.1585 0.1577 0.1551 

[TRAIN] Epoch[7](1417/1500); Loss: 0.116060; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2209 0.2049 0.1056 0.1150 0.0988 0.1044 0.1083 0.0984 0.0879 0.0927 0.0897 0.0940 0.1140 0.1096 0.1073 0.1055 

[TRAIN] Epoch[7](1418/1500); Loss: 0.156228; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1604 0.1601 0.1604 0.1594 0.1569 0.1556 0.1546 0.1540 0.1534 0.1537 0.1538 0.1543 0.1541 0.1555 0.1558 0.1576 

[TRAIN] Epoch[7](1419/1500); Loss: 0.148575; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1793 0.1708 0.1997 0.1864 0.1719 0.1662 0.1596 0.1467 0.1371 0.1343 0.1276 0.1197 0.1186 0.1199 0.1199 0.1194 

[TRAIN] Epoch[7](1420/1500); Loss: 0.185627; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2298 0.2178 0.2145 0.2033 0.1958 0.1923 0.1883 0.1809 0.1770 0.1746 0.1704 0.1671 0.1654 0.1656 0.1652 0.1619 

[TRAIN] Epoch[7](1421/1500); Loss: 0.071142; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0676 0.0711 0.0693 0.0698 0.0675 0.0678 0.0676 0.0693 0.0685 0.0707 0.0703 0.0730 0.0731 0.0760 0.0768 0.0799 

[TRAIN] Epoch[7](1422/1500); Loss: 0.088797; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1738 0.1502 0.0538 0.0496 0.0958 0.0820 0.0787 0.0772 0.0691 0.0587 0.0682 0.0737 0.0757 0.0882 0.1141 0.1121 

[TRAIN] Epoch[7](1423/1500); Loss: 0.141396; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1723 0.1645 0.1427 0.1410 0.1380 0.1371 0.1355 0.1344 0.1348 0.1348 0.1354 0.1371 0.1365 0.1385 0.1398 0.1401 

[TRAIN] Epoch[7](1424/1500); Loss: 0.128233; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1404 0.1329 0.1360 0.1350 0.1307 0.1267 0.1244 0.1222 0.1214 0.1210 0.1228 0.1252 0.1257 0.1274 0.1297 0.1302 

[TRAIN] Epoch[7](1425/1500); Loss: 0.118898; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1447 0.1289 0.1362 0.1419 0.1323 0.1225 0.1203 0.1160 0.1100 0.1063 0.1073 0.1077 0.1033 0.1071 0.1114 0.1064 

[TRAIN] Epoch[7](1426/1500); Loss: 0.183026; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2088 0.2052 0.2746 0.2558 0.2366 0.2292 0.2163 0.1950 0.1811 0.1715 0.1534 0.1387 0.1315 0.1193 0.1075 0.1042 

[TRAIN] Epoch[7](1427/1500); Loss: 0.087714; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0752 0.0764 0.1227 0.1150 0.1045 0.0995 0.0940 0.0846 0.0793 0.0783 0.0755 0.0748 0.0769 0.0790 0.0833 0.0845 

[TRAIN] Epoch[7](1428/1500); Loss: 0.135525; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1236 0.1240 0.1455 0.1461 0.1392 0.1365 0.1347 0.1314 0.1315 0.1318 0.1324 0.1354 0.1356 0.1371 0.1406 0.1430 

[TRAIN] Epoch[7](1429/1500); Loss: 0.150349; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1759 0.1733 0.1438 0.1412 0.1398 0.1398 0.1403 0.1429 0.1451 0.1461 0.1492 0.1498 0.1522 0.1521 0.1561 0.1580 

[TRAIN] Epoch[7](1430/1500); Loss: 0.121296; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1592 0.1479 0.1372 0.1309 0.1289 0.1256 0.1210 0.1162 0.1138 0.1149 0.1120 0.1079 0.1084 0.1072 0.1052 0.1042 

[TRAIN] Epoch[7](1431/1500); Loss: 0.106080; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1073 0.1070 0.1549 0.1421 0.1284 0.1228 0.1144 0.1032 0.0965 0.0932 0.0889 0.0866 0.0858 0.0875 0.0895 0.0891 

[TRAIN] Epoch[7](1432/1500); Loss: 0.141093; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2007 0.1868 0.1646 0.1440 0.1366 0.1369 0.1336 0.1293 0.1276 0.1280 0.1281 0.1267 0.1276 0.1286 0.1293 0.1291 

[TRAIN] Epoch[7](1433/1500); Loss: 0.185108; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2079 0.2023 0.1953 0.1897 0.1848 0.1834 0.1826 0.1820 0.1807 0.1810 0.1813 0.1802 0.1790 0.1795 0.1763 0.1756 

[TRAIN] Epoch[7](1434/1500); Loss: 0.156202; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1764 0.1743 0.1941 0.1810 0.1659 0.1616 0.1568 0.1518 0.1485 0.1458 0.1433 0.1415 0.1403 0.1398 0.1399 0.1383 

[TRAIN] Epoch[7](1435/1500); Loss: 0.121277; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1515 0.1405 0.1752 0.1609 0.1396 0.1296 0.1191 0.1011 0.0930 0.0945 0.0950 0.0977 0.1030 0.1101 0.1130 0.1166 

[TRAIN] Epoch[7](1436/1500); Loss: 0.132795; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1472 0.1437 0.1892 0.1757 0.1611 0.1538 0.1445 0.1315 0.1222 0.1178 0.1111 0.1063 0.1056 0.1052 0.1054 0.1046 

[TRAIN] Epoch[7](1437/1500); Loss: 0.132781; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1779 0.1662 0.1351 0.1326 0.1365 0.1329 0.1279 0.1235 0.1222 0.1227 0.1243 0.1240 0.1245 0.1253 0.1233 0.1254 

[TRAIN] Epoch[7](1438/1500); Loss: 0.153591; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1781 0.1722 0.1699 0.1615 0.1563 0.1551 0.1519 0.1483 0.1458 0.1453 0.1445 0.1441 0.1453 0.1454 0.1464 0.1474 

[TRAIN] Epoch[7](1439/1500); Loss: 0.098697; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1045 0.0919 0.1101 0.1103 0.1029 0.0943 0.0913 0.0916 0.0917 0.0910 0.0939 0.0993 0.0975 0.1004 0.1023 0.1062 

[TRAIN] Epoch[7](1440/1500); Loss: 0.083133; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.0912 0.0864 0.0924 0.0915 0.0852 0.0802 0.0777 0.0772 0.0775 0.0783 0.0787 0.0817 0.0812 0.0833 0.0832 0.0845 

[TRAIN] Epoch[7](1441/1500); Loss: 0.208804; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2178 0.2148 0.2131 0.2146 0.2114 0.2082 0.2071 0.2064 0.2047 0.2039 0.2050 0.2050 0.2044 0.2071 0.2090 0.2084 

[TRAIN] Epoch[7](1442/1500); Loss: 0.141085; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.1599 0.1559 0.1695 0.1623 0.1540 0.1492 0.1442 0.1384 0.1333 0.1307 0.1277 0.1262 0.1259 0.1257 0.1269 0.1275 

[TRAIN] Epoch[7](1443/1500); Loss: 0.198883; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2329 0.2260 0.2326 0.2270 0.2180 0.2137 0.2079 0.1999 0.1939 0.1905 0.1855 0.1782 0.1754 0.1719 0.1654 0.1634 

[TRAIN] Epoch[7](1444/1500); Loss: 0.126028; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1439 0.1380 0.1527 0.1464 0.1381 0.1331 0.1286 0.1236 0.1184 0.1163 0.1137 0.1120 0.1118 0.1121 0.1129 0.1150 

[TRAIN] Epoch[7](1445/1500); Loss: 0.101102; Backpropagation: 0.0920 sec; Batch: 0.4249 sec
0.1953 0.1800 0.1211 0.0883 0.0839 0.1024 0.0993 0.0904 0.0820 0.0835 0.0776 0.0765 0.0814 0.0806 0.0865 0.0889 

[TRAIN] Epoch[7](1446/1500); Loss: 0.170105; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1949 0.1893 0.2104 0.1983 0.1882 0.1859 0.1798 0.1699 0.1652 0.1616 0.1542 0.1498 0.1473 0.1433 0.1421 0.1415 

[TRAIN] Epoch[7](1447/1500); Loss: 0.106048; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1700 0.1608 0.1227 0.1006 0.0992 0.0973 0.0957 0.0946 0.0941 0.0934 0.0939 0.0943 0.0936 0.0944 0.0953 0.0969 

[TRAIN] Epoch[7](1448/1500); Loss: 0.088013; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1044 0.1009 0.0968 0.0928 0.0895 0.0882 0.0863 0.0853 0.0844 0.0846 0.0825 0.0822 0.0820 0.0832 0.0818 0.0834 

[TRAIN] Epoch[7](1449/1500); Loss: 0.103773; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1153 0.1136 0.1057 0.1032 0.1003 0.0990 0.0990 0.1003 0.0997 0.1007 0.1022 0.1028 0.1034 0.1050 0.1043 0.1058 

[TRAIN] Epoch[7](1450/1500); Loss: 0.122875; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1301 0.1275 0.1528 0.1461 0.1356 0.1310 0.1255 0.1200 0.1171 0.1135 0.1114 0.1111 0.1100 0.1104 0.1114 0.1125 

[TRAIN] Epoch[7](1451/1500); Loss: 0.159199; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1596 0.1576 0.1813 0.1781 0.1698 0.1662 0.1622 0.1571 0.1551 0.1521 0.1514 0.1520 0.1500 0.1506 0.1521 0.1522 

[TRAIN] Epoch[7](1452/1500); Loss: 0.139789; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1607 0.1552 0.1470 0.1421 0.1383 0.1373 0.1355 0.1349 0.1345 0.1342 0.1350 0.1354 0.1352 0.1370 0.1369 0.1377 

[TRAIN] Epoch[7](1453/1500); Loss: 0.204770; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2230 0.2195 0.2451 0.2359 0.2260 0.2209 0.2148 0.2067 0.2028 0.1975 0.1918 0.1871 0.1833 0.1786 0.1728 0.1705 

[TRAIN] Epoch[7](1454/1500); Loss: 0.195130; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2361 0.2290 0.2426 0.2240 0.2132 0.2078 0.2010 0.1911 0.1861 0.1823 0.1764 0.1722 0.1693 0.1657 0.1634 0.1619 

[TRAIN] Epoch[7](1455/1500); Loss: 0.170086; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1817 0.1725 0.1734 0.1719 0.1693 0.1678 0.1663 0.1657 0.1671 0.1663 0.1678 0.1703 0.1688 0.1697 0.1714 0.1714 

[TRAIN] Epoch[7](1456/1500); Loss: 0.143762; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1672 0.1641 0.1809 0.1691 0.1661 0.1613 0.1521 0.1408 0.1361 0.1334 0.1287 0.1229 0.1226 0.1207 0.1165 0.1177 

[TRAIN] Epoch[7](1457/1500); Loss: 0.123219; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1315 0.1259 0.1177 0.1180 0.1180 0.1188 0.1179 0.1182 0.1189 0.1201 0.1223 0.1246 0.1263 0.1287 0.1309 0.1337 

[TRAIN] Epoch[7](1458/1500); Loss: 0.093376; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1128 0.1055 0.1086 0.1048 0.0978 0.0940 0.0912 0.0898 0.0867 0.0843 0.0853 0.0860 0.0854 0.0859 0.0876 0.0884 

[TRAIN] Epoch[7](1459/1500); Loss: 0.247634; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2708 0.2667 0.3296 0.3134 0.2957 0.2888 0.2775 0.2585 0.2476 0.2379 0.2197 0.2121 0.2027 0.1852 0.1818 0.1741 

[TRAIN] Epoch[7](1460/1500); Loss: 0.305091; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.3198 0.3208 0.4102 0.3878 0.3660 0.3560 0.3436 0.3202 0.3026 0.2955 0.2768 0.2560 0.2534 0.2380 0.2163 0.2184 

[TRAIN] Epoch[7](1461/1500); Loss: 0.145599; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1593 0.1586 0.1495 0.1474 0.1434 0.1426 0.1411 0.1409 0.1415 0.1402 0.1428 0.1433 0.1411 0.1440 0.1479 0.1460 

[TRAIN] Epoch[7](1462/1500); Loss: 0.134362; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1374 0.1326 0.1445 0.1446 0.1392 0.1348 0.1335 0.1314 0.1299 0.1293 0.1302 0.1299 0.1301 0.1331 0.1348 0.1344 

[TRAIN] Epoch[7](1463/1500); Loss: 0.313308; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.3611 0.3508 0.3917 0.3768 0.3573 0.3475 0.3369 0.3168 0.3035 0.2950 0.2793 0.2656 0.2614 0.2609 0.2553 0.2530 

[TRAIN] Epoch[7](1464/1500); Loss: 0.126070; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1686 0.1570 0.1504 0.1326 0.1334 0.1249 0.1221 0.1174 0.1125 0.1108 0.1119 0.1140 0.1120 0.1162 0.1176 0.1159 

[TRAIN] Epoch[7](1465/1500); Loss: 0.072769; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1481 0.1358 0.0736 0.0768 0.0670 0.0703 0.0670 0.0570 0.0522 0.0528 0.0532 0.0592 0.0615 0.0627 0.0621 0.0649 

[TRAIN] Epoch[7](1466/1500); Loss: 0.120237; Backpropagation: 0.0921 sec; Batch: 0.4231 sec
0.1367 0.1301 0.1286 0.1236 0.1198 0.1192 0.1169 0.1174 0.1160 0.1158 0.1165 0.1172 0.1152 0.1161 0.1169 0.1179 

[TRAIN] Epoch[7](1467/1500); Loss: 0.112063; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1382 0.1240 0.1394 0.1308 0.1177 0.1121 0.1061 0.0971 0.0953 0.0967 0.0989 0.1017 0.1045 0.1083 0.1094 0.1127 

[TRAIN] Epoch[7](1468/1500); Loss: 0.182929; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2012 0.1964 0.1931 0.1903 0.1849 0.1818 0.1799 0.1786 0.1772 0.1758 0.1764 0.1766 0.1768 0.1788 0.1789 0.1801 

[TRAIN] Epoch[7](1469/1500); Loss: 0.137510; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1367 0.1386 0.1985 0.1838 0.1693 0.1645 0.1541 0.1401 0.1347 0.1270 0.1165 0.1145 0.1094 0.1043 0.1046 0.1036 

[TRAIN] Epoch[7](1470/1500); Loss: 0.185438; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2029 0.1986 0.2210 0.2134 0.2046 0.1999 0.1945 0.1867 0.1818 0.1786 0.1741 0.1681 0.1660 0.1613 0.1581 0.1573 

[TRAIN] Epoch[7](1471/1500); Loss: 0.186230; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2120 0.2005 0.1967 0.1906 0.1950 0.1928 0.1871 0.1815 0.1805 0.1780 0.1771 0.1784 0.1774 0.1765 0.1773 0.1783 

[TRAIN] Epoch[7](1472/1500); Loss: 0.126097; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1059 0.1098 0.1429 0.1364 0.1275 0.1277 0.1236 0.1198 0.1212 0.1214 0.1241 0.1280 0.1295 0.1319 0.1332 0.1348 

[TRAIN] Epoch[7](1473/1500); Loss: 0.210702; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2486 0.2393 0.2393 0.2296 0.2203 0.2173 0.2130 0.2070 0.2036 0.2013 0.1966 0.1943 0.1936 0.1914 0.1882 0.1877 

[TRAIN] Epoch[7](1474/1500); Loss: 0.140226; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1530 0.1492 0.1876 0.1735 0.1660 0.1629 0.1530 0.1389 0.1356 0.1281 0.1207 0.1217 0.1165 0.1143 0.1130 0.1096 

[TRAIN] Epoch[7](1475/1500); Loss: 0.188683; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1725 0.1755 0.2099 0.2069 0.1995 0.1974 0.1945 0.1880 0.1877 0.1849 0.1816 0.1852 0.1834 0.1816 0.1855 0.1849 

[TRAIN] Epoch[7](1476/1500); Loss: 0.093325; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1087 0.1017 0.0919 0.0886 0.0892 0.0891 0.0880 0.0899 0.0898 0.0908 0.0933 0.0932 0.0927 0.0945 0.0954 0.0963 

[TRAIN] Epoch[7](1477/1500); Loss: 0.136652; Backpropagation: 0.0918 sec; Batch: 0.4228 sec
0.2114 0.1978 0.1499 0.1255 0.1257 0.1292 0.1271 0.1240 0.1224 0.1226 0.1229 0.1238 0.1239 0.1266 0.1269 0.1266 

[TRAIN] Epoch[7](1478/1500); Loss: 0.180231; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1873 0.1827 0.2321 0.2259 0.2112 0.2035 0.1966 0.1839 0.1777 0.1709 0.1616 0.1607 0.1538 0.1464 0.1478 0.1416 

[TRAIN] Epoch[7](1479/1500); Loss: 0.113539; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1185 0.1170 0.1433 0.1370 0.1274 0.1238 0.1183 0.1119 0.1089 0.1065 0.1038 0.1027 0.1007 0.1002 0.0982 0.0987 

[TRAIN] Epoch[7](1480/1500); Loss: 0.138222; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1557 0.1492 0.1629 0.1570 0.1468 0.1419 0.1370 0.1320 0.1288 0.1271 0.1274 0.1266 0.1282 0.1305 0.1302 0.1303 

[TRAIN] Epoch[7](1481/1500); Loss: 0.126380; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1351 0.1355 0.1259 0.1321 0.1270 0.1225 0.1223 0.1231 0.1229 0.1213 0.1249 0.1277 0.1226 0.1247 0.1284 0.1262 

[TRAIN] Epoch[7](1482/1500); Loss: 0.151261; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1805 0.1776 0.2512 0.2303 0.2095 0.2006 0.1851 0.1597 0.1494 0.1352 0.1109 0.1059 0.0940 0.0786 0.0766 0.0751 

[TRAIN] Epoch[7](1483/1500); Loss: 0.087411; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.0998 0.0856 0.1050 0.1119 0.1017 0.0898 0.0869 0.0822 0.0786 0.0772 0.0790 0.0785 0.0773 0.0803 0.0820 0.0826 

[TRAIN] Epoch[7](1484/1500); Loss: 0.156900; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1602 0.1550 0.1542 0.1544 0.1560 0.1563 0.1541 0.1526 0.1544 0.1529 0.1545 0.1578 0.1572 0.1607 0.1651 0.1649 

[TRAIN] Epoch[7](1485/1500); Loss: 0.144287; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1519 0.1511 0.1654 0.1603 0.1535 0.1505 0.1464 0.1420 0.1405 0.1379 0.1355 0.1356 0.1333 0.1336 0.1350 0.1361 

[TRAIN] Epoch[7](1486/1500); Loss: 0.090982; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1446 0.1304 0.0904 0.0838 0.0858 0.0850 0.0815 0.0794 0.0809 0.0817 0.0840 0.0840 0.0840 0.0847 0.0879 0.0876 

[TRAIN] Epoch[7](1487/1500); Loss: 0.181936; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2300 0.2177 0.1970 0.1883 0.1847 0.1853 0.1814 0.1752 0.1733 0.1714 0.1687 0.1695 0.1687 0.1671 0.1664 0.1663 

[TRAIN] Epoch[7](1488/1500); Loss: 0.146081; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1731 0.1696 0.2183 0.2035 0.1870 0.1799 0.1679 0.1517 0.1432 0.1347 0.1216 0.1134 0.1061 0.0950 0.0877 0.0845 

[TRAIN] Epoch[7](1489/1500); Loss: 0.119347; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1362 0.1364 0.1581 0.1425 0.1269 0.1244 0.1184 0.1134 0.1116 0.1088 0.1068 0.1056 0.1050 0.1051 0.1048 0.1055 

[TRAIN] Epoch[7](1490/1500); Loss: 0.100806; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1224 0.1055 0.1194 0.1264 0.1175 0.1052 0.1035 0.0977 0.0908 0.0892 0.0882 0.0884 0.0873 0.0903 0.0909 0.0901 

[TRAIN] Epoch[7](1491/1500); Loss: 0.133740; Backpropagation: 0.0923 sec; Batch: 0.4243 sec
0.1518 0.1428 0.1490 0.1497 0.1429 0.1362 0.1335 0.1306 0.1274 0.1250 0.1260 0.1252 0.1225 0.1259 0.1262 0.1252 

[TRAIN] Epoch[7](1492/1500); Loss: 0.170471; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1700 0.1692 0.1782 0.1775 0.1733 0.1713 0.1694 0.1678 0.1674 0.1666 0.1676 0.1686 0.1683 0.1708 0.1706 0.1709 

[TRAIN] Epoch[7](1493/1500); Loss: 0.104235; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1228 0.1208 0.1285 0.1200 0.1125 0.1116 0.1066 0.0999 0.0982 0.0952 0.0931 0.0937 0.0922 0.0914 0.0910 0.0902 

[TRAIN] Epoch[7](1494/1500); Loss: 0.097257; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1120 0.1047 0.0966 0.0945 0.0918 0.0923 0.0912 0.0927 0.0918 0.0936 0.0943 0.0956 0.0978 0.1001 0.1020 0.1051 

[TRAIN] Epoch[7](1495/1500); Loss: 0.085244; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.0963 0.0944 0.0893 0.0866 0.0842 0.0822 0.0814 0.0820 0.0818 0.0817 0.0828 0.0830 0.0833 0.0842 0.0851 0.0856 

[TRAIN] Epoch[7](1496/1500); Loss: 0.383642; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.4422 0.4335 0.5065 0.4838 0.4573 0.4461 0.4279 0.3978 0.3840 0.3668 0.3368 0.3289 0.3129 0.2826 0.2738 0.2574 

[TRAIN] Epoch[7](1497/1500); Loss: 0.195656; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2184 0.2086 0.2123 0.2022 0.2017 0.2034 0.1988 0.1924 0.1910 0.1886 0.1862 0.1863 0.1856 0.1855 0.1846 0.1850 

[TRAIN] Epoch[7](1498/1500); Loss: 0.101003; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1047 0.1001 0.1175 0.1184 0.1119 0.1068 0.1044 0.0998 0.0963 0.0945 0.0932 0.0935 0.0918 0.0926 0.0953 0.0953 

[TRAIN] Epoch[7](1499/1500); Loss: 0.218553; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1857 0.1750 0.2080 0.2197 0.2129 0.2105 0.2174 0.2136 0.2145 0.2237 0.2223 0.2258 0.2362 0.2365 0.2419 0.2532 

[TRAIN] Epoch[7](1500/1500); Loss: 0.199866; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2852 0.2766 0.2330 0.2077 0.1959 0.1999 0.2027 0.1910 0.1826 0.1842 0.1741 0.1726 0.1802 0.1722 0.1708 0.1694 

[TRAIN] Epoch[8](1/1500); Loss: 0.159855; Backpropagation: 0.0985 sec; Batch: 0.4603 sec
0.1877 0.1792 0.2096 0.1994 0.1870 0.1811 0.1723 0.1609 0.1539 0.1475 0.1389 0.1348 0.1306 0.1259 0.1244 0.1245 

[TRAIN] Epoch[8](2/1500); Loss: 0.178922; Backpropagation: 0.0936 sec; Batch: 0.4340 sec
0.1856 0.1823 0.2049 0.2014 0.1924 0.1871 0.1824 0.1772 0.1749 0.1713 0.1697 0.1690 0.1668 0.1665 0.1668 0.1645 

[TRAIN] Epoch[8](3/1500); Loss: 0.075112; Backpropagation: 0.0937 sec; Batch: 0.4281 sec
0.1183 0.1077 0.0798 0.0729 0.0704 0.0676 0.0664 0.0664 0.0666 0.0681 0.0688 0.0675 0.0694 0.0695 0.0711 0.0714 

[TRAIN] Epoch[8](4/1500); Loss: 0.176119; Backpropagation: 0.0937 sec; Batch: 0.4289 sec
0.2103 0.2021 0.2023 0.1926 0.1859 0.1818 0.1769 0.1707 0.1679 0.1658 0.1636 0.1609 0.1599 0.1594 0.1582 0.1594 

[TRAIN] Epoch[8](5/1500); Loss: 0.107144; Backpropagation: 0.0938 sec; Batch: 0.4264 sec
0.1142 0.1015 0.1265 0.1371 0.1265 0.1161 0.1176 0.1112 0.1040 0.1015 0.0988 0.0947 0.0922 0.0919 0.0915 0.0889 

[TRAIN] Epoch[8](6/1500); Loss: 0.134363; Backpropagation: 0.0935 sec; Batch: 0.4328 sec
0.1482 0.1375 0.1452 0.1452 0.1399 0.1340 0.1312 0.1289 0.1281 0.1266 0.1288 0.1298 0.1297 0.1314 0.1320 0.1332 

[TRAIN] Epoch[8](7/1500); Loss: 0.067897; Backpropagation: 0.0942 sec; Batch: 0.4263 sec
0.0814 0.0742 0.0650 0.0671 0.0656 0.0628 0.0604 0.0618 0.0628 0.0635 0.0661 0.0672 0.0676 0.0708 0.0735 0.0765 

[TRAIN] Epoch[8](8/1500); Loss: 0.072865; Backpropagation: 0.0937 sec; Batch: 0.4319 sec
0.1503 0.1337 0.0682 0.0692 0.0638 0.0742 0.0740 0.0627 0.0572 0.0571 0.0531 0.0549 0.0597 0.0605 0.0640 0.0632 

[TRAIN] Epoch[8](9/1500); Loss: 0.112484; Backpropagation: 0.0940 sec; Batch: 0.4265 sec
0.1485 0.1371 0.1267 0.1210 0.1172 0.1131 0.1104 0.1054 0.1025 0.1015 0.1010 0.1006 0.1013 0.1035 0.1037 0.1061 

[TRAIN] Epoch[8](10/1500); Loss: 0.121859; Backpropagation: 0.0939 sec; Batch: 0.4260 sec
0.1453 0.1429 0.2033 0.1866 0.1674 0.1574 0.1427 0.1223 0.1121 0.1011 0.0868 0.0815 0.0776 0.0748 0.0725 0.0756 

[TRAIN] Epoch[8](11/1500); Loss: 0.101602; Backpropagation: 0.1041 sec; Batch: 0.4369 sec
0.1128 0.1091 0.1330 0.1254 0.1143 0.1085 0.1019 0.0961 0.0933 0.0901 0.0892 0.0890 0.0892 0.0923 0.0894 0.0921 

[TRAIN] Epoch[8](12/1500); Loss: 0.153517; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.1780 0.1744 0.2018 0.1918 0.1785 0.1716 0.1619 0.1503 0.1441 0.1376 0.1307 0.1287 0.1265 0.1266 0.1266 0.1274 

[TRAIN] Epoch[8](13/1500); Loss: 0.136255; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1713 0.1638 0.1676 0.1558 0.1452 0.1408 0.1361 0.1299 0.1260 0.1243 0.1226 0.1220 0.1198 0.1198 0.1169 0.1182 

[TRAIN] Epoch[8](14/1500); Loss: 0.099397; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1288 0.1105 0.1120 0.1050 0.1003 0.0965 0.0931 0.0868 0.0850 0.0844 0.0843 0.0894 0.0937 0.0993 0.1075 0.1137 

[TRAIN] Epoch[8](15/1500); Loss: 0.087030; Backpropagation: 0.0918 sec; Batch: 0.4245 sec
0.1012 0.0964 0.1309 0.1195 0.1050 0.0984 0.0889 0.0795 0.0745 0.0720 0.0720 0.0707 0.0711 0.0730 0.0692 0.0700 

[TRAIN] Epoch[8](16/1500); Loss: 0.165918; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1744 0.1676 0.1926 0.1847 0.1768 0.1742 0.1681 0.1621 0.1594 0.1577 0.1576 0.1575 0.1561 0.1572 0.1548 0.1538 

[TRAIN] Epoch[8](17/1500); Loss: 0.081363; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0680 0.0667 0.0771 0.0872 0.0810 0.0756 0.0758 0.0776 0.0795 0.0786 0.0809 0.0861 0.0876 0.0901 0.0941 0.0961 

[TRAIN] Epoch[8](18/1500); Loss: 0.101590; Backpropagation: 0.0926 sec; Batch: 0.4250 sec
0.0996 0.0998 0.1143 0.1093 0.1021 0.0996 0.0964 0.0950 0.0957 0.0978 0.0998 0.1010 0.1029 0.1031 0.1050 0.1040 

[TRAIN] Epoch[8](19/1500); Loss: 0.096026; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1102 0.1000 0.1038 0.0934 0.1001 0.1028 0.0971 0.0880 0.0877 0.0860 0.0879 0.0910 0.0938 0.0981 0.0966 0.0998 

[TRAIN] Epoch[8](20/1500); Loss: 0.126984; Backpropagation: 0.0917 sec; Batch: 0.4243 sec
0.1295 0.1179 0.1537 0.1550 0.1428 0.1344 0.1307 0.1231 0.1168 0.1143 0.1134 0.1143 0.1156 0.1194 0.1233 0.1276 

[TRAIN] Epoch[8](21/1500); Loss: 0.125473; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1871 0.1727 0.1393 0.1251 0.1304 0.1326 0.1242 0.1153 0.1130 0.1102 0.1092 0.1126 0.1098 0.1085 0.1090 0.1085 

[TRAIN] Epoch[8](22/1500); Loss: 0.108472; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1254 0.1161 0.1137 0.0892 0.1220 0.1287 0.1178 0.1042 0.1125 0.1005 0.0960 0.1047 0.0971 0.0974 0.1076 0.1025 

[TRAIN] Epoch[8](23/1500); Loss: 0.171332; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.2060 0.1988 0.1963 0.1933 0.1854 0.1828 0.1777 0.1704 0.1671 0.1642 0.1586 0.1554 0.1509 0.1463 0.1444 0.1436 

[TRAIN] Epoch[8](24/1500); Loss: 0.081283; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1122 0.0942 0.0871 0.0868 0.0811 0.0749 0.0718 0.0722 0.0718 0.0714 0.0742 0.0756 0.0787 0.0799 0.0831 0.0858 

[TRAIN] Epoch[8](25/1500); Loss: 0.179757; Backpropagation: 0.0921 sec; Batch: 0.4250 sec
0.2157 0.2088 0.2478 0.2348 0.2190 0.2105 0.1990 0.1838 0.1734 0.1647 0.1531 0.1445 0.1386 0.1321 0.1270 0.1233 

[TRAIN] Epoch[8](26/1500); Loss: 0.064272; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0554 0.0612 0.0709 0.0631 0.0662 0.0677 0.0660 0.0654 0.0641 0.0617 0.0622 0.0621 0.0636 0.0680 0.0659 0.0649 

[TRAIN] Epoch[8](27/1500); Loss: 0.101430; Backpropagation: 0.0919 sec; Batch: 0.4272 sec
0.1065 0.1028 0.1086 0.1112 0.1061 0.1022 0.1007 0.0999 0.1002 0.0982 0.0981 0.0986 0.0981 0.0977 0.0971 0.0969 

[TRAIN] Epoch[8](28/1500); Loss: 0.091771; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1080 0.0907 0.1036 0.0967 0.0860 0.0824 0.0807 0.0827 0.0839 0.0865 0.0879 0.0905 0.0923 0.0958 0.0988 0.1019 

[TRAIN] Epoch[8](29/1500); Loss: 0.159094; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2065 0.1951 0.1831 0.1725 0.1692 0.1665 0.1607 0.1549 0.1523 0.1498 0.1464 0.1433 0.1407 0.1367 0.1351 0.1326 

[TRAIN] Epoch[8](30/1500); Loss: 0.151496; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1554 0.1527 0.1735 0.1710 0.1614 0.1563 0.1521 0.1488 0.1459 0.1438 0.1452 0.1448 0.1418 0.1440 0.1435 0.1437 

[TRAIN] Epoch[8](31/1500); Loss: 0.193677; Backpropagation: 0.0924 sec; Batch: 0.4248 sec
0.2157 0.2119 0.2130 0.2080 0.2003 0.1961 0.1918 0.1883 0.1866 0.1842 0.1840 0.1838 0.1843 0.1857 0.1821 0.1829 

[TRAIN] Epoch[8](32/1500); Loss: 0.089412; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.1056 0.0979 0.1127 0.1069 0.0962 0.0892 0.0847 0.0815 0.0804 0.0793 0.0822 0.0802 0.0816 0.0831 0.0847 0.0845 

[TRAIN] Epoch[8](33/1500); Loss: 0.095534; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1287 0.1085 0.1131 0.1063 0.0979 0.0879 0.0881 0.0879 0.0858 0.0830 0.0858 0.0876 0.0883 0.0906 0.0929 0.0961 

[TRAIN] Epoch[8](34/1500); Loss: 0.269247; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2967 0.2959 0.3627 0.3454 0.3264 0.3174 0.3018 0.2813 0.2692 0.2562 0.2374 0.2282 0.2160 0.1986 0.1926 0.1824 

[TRAIN] Epoch[8](35/1500); Loss: 0.150922; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1836 0.1747 0.1615 0.1566 0.1523 0.1501 0.1478 0.1457 0.1445 0.1436 0.1457 0.1449 0.1414 0.1425 0.1423 0.1375 

[TRAIN] Epoch[8](36/1500); Loss: 0.186673; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2312 0.2241 0.2322 0.2258 0.2144 0.2093 0.2007 0.1892 0.1834 0.1763 0.1652 0.1587 0.1529 0.1451 0.1405 0.1378 

[TRAIN] Epoch[8](37/1500); Loss: 0.074614; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.0735 0.0677 0.0857 0.0819 0.0828 0.0794 0.0750 0.0704 0.0697 0.0686 0.0716 0.0712 0.0720 0.0739 0.0747 0.0757 

[TRAIN] Epoch[8](38/1500); Loss: 0.095815; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1093 0.1058 0.1018 0.0967 0.0969 0.0950 0.0913 0.0894 0.0897 0.0898 0.0925 0.0920 0.0931 0.0942 0.0973 0.0983 

[TRAIN] Epoch[8](39/1500); Loss: 0.092618; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0985 0.0919 0.1035 0.1052 0.0966 0.0898 0.0888 0.0897 0.0874 0.0899 0.0877 0.0891 0.0894 0.0921 0.0900 0.0923 

[TRAIN] Epoch[8](40/1500); Loss: 0.143277; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1735 0.1628 0.1500 0.1479 0.1455 0.1418 0.1382 0.1363 0.1361 0.1378 0.1370 0.1349 0.1367 0.1396 0.1369 0.1377 

[TRAIN] Epoch[8](41/1500); Loss: 0.127975; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1417 0.1392 0.1454 0.1435 0.1381 0.1351 0.1313 0.1280 0.1261 0.1234 0.1210 0.1192 0.1161 0.1152 0.1125 0.1118 

[TRAIN] Epoch[8](42/1500); Loss: 0.156658; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1823 0.1731 0.1699 0.1656 0.1589 0.1550 0.1531 0.1525 0.1510 0.1499 0.1502 0.1498 0.1487 0.1484 0.1492 0.1491 

[TRAIN] Epoch[8](43/1500); Loss: 0.094988; Backpropagation: 0.0924 sec; Batch: 0.4252 sec
0.1058 0.1049 0.1221 0.1161 0.1097 0.1052 0.0967 0.0900 0.0872 0.0845 0.0852 0.0844 0.0816 0.0828 0.0819 0.0819 

[TRAIN] Epoch[8](44/1500); Loss: 0.170772; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1825 0.1796 0.1790 0.1771 0.1729 0.1707 0.1693 0.1692 0.1676 0.1661 0.1668 0.1673 0.1649 0.1660 0.1665 0.1669 

[TRAIN] Epoch[8](45/1500); Loss: 0.119969; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1519 0.1397 0.1165 0.1154 0.1119 0.1113 0.1108 0.1123 0.1119 0.1140 0.1155 0.1171 0.1193 0.1230 0.1237 0.1252 

[TRAIN] Epoch[8](46/1500); Loss: 0.117331; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1772 0.1666 0.1219 0.1155 0.1083 0.1084 0.1064 0.1041 0.1061 0.1077 0.1071 0.1073 0.1072 0.1087 0.1119 0.1128 

[TRAIN] Epoch[8](47/1500); Loss: 0.081969; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0917 0.0832 0.0924 0.0840 0.0857 0.0840 0.0781 0.0747 0.0746 0.0757 0.0792 0.0773 0.0786 0.0820 0.0838 0.0865 

[TRAIN] Epoch[8](48/1500); Loss: 0.133415; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1423 0.1382 0.1587 0.1465 0.1459 0.1447 0.1375 0.1292 0.1277 0.1239 0.1241 0.1251 0.1229 0.1217 0.1232 0.1230 

[TRAIN] Epoch[8](49/1500); Loss: 0.162391; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1724 0.1715 0.1596 0.1603 0.1583 0.1581 0.1583 0.1594 0.1604 0.1603 0.1615 0.1624 0.1625 0.1634 0.1645 0.1654 

[TRAIN] Epoch[8](50/1500); Loss: 0.071262; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1373 0.1213 0.0676 0.0687 0.0679 0.0732 0.0692 0.0600 0.0564 0.0568 0.0574 0.0578 0.0580 0.0603 0.0638 0.0645 

[TRAIN] Epoch[8](51/1500); Loss: 0.202181; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2314 0.2208 0.2337 0.2282 0.2193 0.2140 0.2079 0.2014 0.1948 0.1912 0.1870 0.1837 0.1830 0.1809 0.1784 0.1793 

[TRAIN] Epoch[8](52/1500); Loss: 0.113969; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1460 0.1370 0.1254 0.1185 0.1111 0.1089 0.1054 0.1018 0.1031 0.1047 0.1067 0.1078 0.1106 0.1112 0.1121 0.1131 

[TRAIN] Epoch[8](53/1500); Loss: 0.155296; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1926 0.1807 0.1722 0.1671 0.1669 0.1618 0.1549 0.1496 0.1470 0.1457 0.1447 0.1419 0.1418 0.1404 0.1382 0.1390 

[TRAIN] Epoch[8](54/1500); Loss: 0.227623; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2388 0.2357 0.2484 0.2464 0.2409 0.2363 0.2315 0.2273 0.2240 0.2212 0.2189 0.2173 0.2152 0.2141 0.2134 0.2125 

[TRAIN] Epoch[8](55/1500); Loss: 0.136635; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.1427 0.1407 0.1507 0.1484 0.1415 0.1365 0.1330 0.1307 0.1299 0.1296 0.1312 0.1305 0.1322 0.1358 0.1352 0.1376 

[TRAIN] Epoch[8](56/1500); Loss: 0.151814; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1721 0.1649 0.1573 0.1523 0.1501 0.1481 0.1456 0.1445 0.1453 0.1453 0.1471 0.1477 0.1498 0.1514 0.1525 0.1550 

[TRAIN] Epoch[8](57/1500); Loss: 0.228982; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2787 0.2733 0.3358 0.3178 0.2965 0.2850 0.2673 0.2437 0.2263 0.2097 0.1869 0.1733 0.1595 0.1433 0.1363 0.1303 

[TRAIN] Epoch[8](58/1500); Loss: 0.082410; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.0954 0.0844 0.1002 0.0983 0.0953 0.0885 0.0837 0.0785 0.0745 0.0723 0.0744 0.0705 0.0724 0.0763 0.0764 0.0775 

[TRAIN] Epoch[8](59/1500); Loss: 0.240865; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2949 0.2808 0.3144 0.3015 0.2813 0.2688 0.2538 0.2352 0.2211 0.2115 0.2002 0.1939 0.1966 0.1992 0.1979 0.2027 

[TRAIN] Epoch[8](60/1500); Loss: 0.164626; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1796 0.1726 0.1740 0.1714 0.1665 0.1643 0.1632 0.1646 0.1609 0.1608 0.1612 0.1624 0.1579 0.1573 0.1578 0.1595 

[TRAIN] Epoch[8](61/1500); Loss: 0.090972; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1029 0.1021 0.0968 0.0927 0.0901 0.0886 0.0877 0.0878 0.0875 0.0876 0.0874 0.0874 0.0879 0.0888 0.0898 0.0904 

[TRAIN] Epoch[8](62/1500); Loss: 0.158616; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1753 0.1729 0.1781 0.1749 0.1690 0.1665 0.1644 0.1628 0.1578 0.1546 0.1515 0.1465 0.1448 0.1410 0.1399 0.1376 

[TRAIN] Epoch[8](63/1500); Loss: 0.102492; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1442 0.1285 0.1601 0.1438 0.1211 0.1103 0.0950 0.0754 0.0697 0.0710 0.0754 0.0798 0.0869 0.0886 0.0929 0.0971 

[TRAIN] Epoch[8](64/1500); Loss: 0.132516; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.1361 0.1331 0.1389 0.1388 0.1344 0.1299 0.1290 0.1300 0.1309 0.1292 0.1310 0.1313 0.1304 0.1311 0.1323 0.1339 

[TRAIN] Epoch[8](65/1500); Loss: 0.073247; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1948 0.1762 0.0771 0.0606 0.0519 0.0613 0.0617 0.0524 0.0473 0.0495 0.0509 0.0561 0.0561 0.0564 0.0591 0.0605 

[TRAIN] Epoch[8](66/1500); Loss: 0.145444; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1606 0.1539 0.1736 0.1661 0.1564 0.1511 0.1443 0.1379 0.1343 0.1328 0.1327 0.1335 0.1349 0.1367 0.1387 0.1397 

[TRAIN] Epoch[8](67/1500); Loss: 0.238643; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2791 0.2732 0.3118 0.3000 0.2854 0.2765 0.2637 0.2480 0.2362 0.2241 0.2082 0.1997 0.1902 0.1786 0.1741 0.1694 

[TRAIN] Epoch[8](68/1500); Loss: 0.091482; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1092 0.1014 0.1040 0.1045 0.0969 0.0897 0.0859 0.0856 0.0848 0.0835 0.0843 0.0842 0.0856 0.0867 0.0882 0.0894 

[TRAIN] Epoch[8](69/1500); Loss: 0.130595; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1405 0.1312 0.1372 0.1394 0.1314 0.1260 0.1236 0.1232 0.1247 0.1255 0.1286 0.1301 0.1296 0.1314 0.1317 0.1354 

[TRAIN] Epoch[8](70/1500); Loss: 0.068771; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.0835 0.0777 0.0650 0.0663 0.0642 0.0629 0.0616 0.0619 0.0657 0.0629 0.0653 0.0681 0.0712 0.0720 0.0747 0.0772 

[TRAIN] Epoch[8](71/1500); Loss: 0.134702; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1258 0.1280 0.1262 0.1257 0.1258 0.1286 0.1312 0.1347 0.1350 0.1363 0.1394 0.1397 0.1423 0.1441 0.1456 0.1469 

[TRAIN] Epoch[8](72/1500); Loss: 0.142338; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1480 0.1468 0.1415 0.1413 0.1387 0.1396 0.1403 0.1401 0.1420 0.1416 0.1417 0.1416 0.1426 0.1430 0.1437 0.1448 

[TRAIN] Epoch[8](73/1500); Loss: 0.164332; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1616 0.1629 0.1725 0.1703 0.1661 0.1648 0.1628 0.1631 0.1608 0.1612 0.1642 0.1628 0.1627 0.1643 0.1645 0.1648 

[TRAIN] Epoch[8](74/1500); Loss: 0.125894; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1368 0.1295 0.1361 0.1334 0.1282 0.1231 0.1194 0.1183 0.1189 0.1199 0.1236 0.1227 0.1229 0.1245 0.1281 0.1288 

[TRAIN] Epoch[8](75/1500); Loss: 0.133206; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2058 0.1897 0.1496 0.1370 0.1302 0.1272 0.1247 0.1214 0.1224 0.1204 0.1188 0.1185 0.1166 0.1159 0.1176 0.1156 

[TRAIN] Epoch[8](76/1500); Loss: 0.133132; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1471 0.1390 0.1547 0.1492 0.1434 0.1373 0.1314 0.1261 0.1237 0.1229 0.1245 0.1225 0.1238 0.1260 0.1294 0.1291 

[TRAIN] Epoch[8](77/1500); Loss: 0.131674; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1580 0.1516 0.1378 0.1378 0.1314 0.1283 0.1265 0.1271 0.1274 0.1282 0.1278 0.1236 0.1253 0.1255 0.1252 0.1252 

[TRAIN] Epoch[8](78/1500); Loss: 0.140305; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1640 0.1587 0.1639 0.1593 0.1503 0.1447 0.1392 0.1334 0.1305 0.1288 0.1278 0.1268 0.1268 0.1286 0.1305 0.1315 

[TRAIN] Epoch[8](79/1500); Loss: 0.086469; Backpropagation: 0.0922 sec; Batch: 0.4248 sec
0.1060 0.0968 0.0939 0.0882 0.0893 0.0864 0.0816 0.0811 0.0811 0.0815 0.0831 0.0826 0.0815 0.0820 0.0836 0.0849 

[TRAIN] Epoch[8](80/1500); Loss: 0.139311; Backpropagation: 0.0928 sec; Batch: 0.4250 sec
0.1818 0.1752 0.1811 0.1755 0.1664 0.1592 0.1488 0.1384 0.1323 0.1257 0.1180 0.1121 0.1086 0.1050 0.1016 0.0993 

[TRAIN] Epoch[8](81/1500); Loss: 0.134668; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.1422 0.1405 0.1418 0.1394 0.1348 0.1322 0.1299 0.1306 0.1293 0.1306 0.1325 0.1333 0.1330 0.1352 0.1336 0.1359 

[TRAIN] Epoch[8](82/1500); Loss: 0.211694; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.2557 0.2500 0.2949 0.2799 0.2601 0.2474 0.2306 0.2118 0.1988 0.1872 0.1748 0.1675 0.1622 0.1577 0.1545 0.1540 

[TRAIN] Epoch[8](83/1500); Loss: 0.142569; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1600 0.1517 0.1564 0.1485 0.1506 0.1471 0.1409 0.1366 0.1374 0.1377 0.1400 0.1367 0.1353 0.1358 0.1339 0.1327 

[TRAIN] Epoch[8](84/1500); Loss: 0.127906; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1538 0.1397 0.1395 0.1351 0.1290 0.1232 0.1217 0.1224 0.1167 0.1173 0.1197 0.1212 0.1220 0.1270 0.1274 0.1307 

[TRAIN] Epoch[8](85/1500); Loss: 0.142002; Backpropagation: 0.0924 sec; Batch: 0.4242 sec
0.1627 0.1569 0.1541 0.1506 0.1452 0.1417 0.1403 0.1385 0.1377 0.1371 0.1362 0.1358 0.1336 0.1340 0.1337 0.1341 

[TRAIN] Epoch[8](86/1500); Loss: 0.079008; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0999 0.0906 0.0882 0.0792 0.0772 0.0738 0.0711 0.0743 0.0722 0.0718 0.0728 0.0766 0.0765 0.0779 0.0793 0.0826 

[TRAIN] Epoch[8](87/1500); Loss: 0.125046; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2169 0.2043 0.1900 0.1553 0.1293 0.1240 0.1180 0.1095 0.1026 0.0979 0.0935 0.0923 0.0915 0.0906 0.0916 0.0936 

[TRAIN] Epoch[8](88/1500); Loss: 0.154979; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.1757 0.1702 0.1804 0.1763 0.1686 0.1614 0.1560 0.1521 0.1471 0.1449 0.1435 0.1430 0.1406 0.1404 0.1396 0.1398 

[TRAIN] Epoch[8](89/1500); Loss: 0.070199; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1000 0.0842 0.0909 0.0893 0.0793 0.0687 0.0626 0.0593 0.0570 0.0566 0.0597 0.0596 0.0620 0.0629 0.0656 0.0656 

[TRAIN] Epoch[8](90/1500); Loss: 0.061833; Backpropagation: 0.0917 sec; Batch: 0.4243 sec
0.0634 0.0639 0.0613 0.0559 0.0602 0.0603 0.0583 0.0575 0.0559 0.0577 0.0624 0.0622 0.0633 0.0654 0.0695 0.0722 

[TRAIN] Epoch[8](91/1500); Loss: 0.159255; Backpropagation: 0.0925 sec; Batch: 0.4250 sec
0.2006 0.1920 0.1843 0.1759 0.1670 0.1619 0.1575 0.1533 0.1492 0.1474 0.1452 0.1429 0.1426 0.1432 0.1429 0.1422 

[TRAIN] Epoch[8](92/1500); Loss: 0.119742; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1465 0.1345 0.1237 0.1198 0.1163 0.1139 0.1127 0.1133 0.1126 0.1136 0.1144 0.1157 0.1172 0.1191 0.1205 0.1222 

[TRAIN] Epoch[8](93/1500); Loss: 0.123259; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1839 0.1734 0.1508 0.1291 0.1290 0.1350 0.1244 0.1140 0.1088 0.1045 0.1041 0.1028 0.1016 0.1025 0.1029 0.1051 

[TRAIN] Epoch[8](94/1500); Loss: 0.093866; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.0924 0.0929 0.1036 0.0989 0.0924 0.0907 0.0904 0.0913 0.0922 0.0916 0.0925 0.0930 0.0931 0.0946 0.0959 0.0962 

[TRAIN] Epoch[8](95/1500); Loss: 0.220366; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.2883 0.2757 0.3166 0.3003 0.2789 0.2644 0.2460 0.2251 0.2091 0.1945 0.1781 0.1673 0.1575 0.1471 0.1405 0.1364 

[TRAIN] Epoch[8](96/1500); Loss: 0.142137; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.1623 0.1594 0.1446 0.1401 0.1387 0.1381 0.1377 0.1391 0.1388 0.1389 0.1393 0.1384 0.1391 0.1391 0.1405 0.1401 

[TRAIN] Epoch[8](97/1500); Loss: 0.078802; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1109 0.1016 0.0848 0.0771 0.0738 0.0744 0.0714 0.0688 0.0663 0.0673 0.0714 0.0733 0.0749 0.0783 0.0815 0.0850 

[TRAIN] Epoch[8](98/1500); Loss: 0.103497; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1562 0.1445 0.0934 0.0913 0.0921 0.0931 0.0908 0.0898 0.0922 0.0953 0.0980 0.0995 0.1011 0.1050 0.1061 0.1075 

[TRAIN] Epoch[8](99/1500); Loss: 0.077279; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1713 0.1550 0.0803 0.0631 0.0587 0.0660 0.0640 0.0617 0.0613 0.0641 0.0654 0.0624 0.0636 0.0652 0.0662 0.0682 

[TRAIN] Epoch[8](100/1500); Loss: 0.128167; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1287 0.1258 0.1406 0.1389 0.1319 0.1273 0.1247 0.1248 0.1228 0.1235 0.1251 0.1249 0.1251 0.1285 0.1283 0.1299 

[TRAIN] Epoch[8](101/1500); Loss: 0.147967; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1667 0.1580 0.1674 0.1624 0.1536 0.1477 0.1428 0.1400 0.1381 0.1378 0.1395 0.1391 0.1409 0.1431 0.1442 0.1461 

[TRAIN] Epoch[8](102/1500); Loss: 0.123388; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.2122 0.1972 0.1718 0.1372 0.1287 0.1373 0.1266 0.1142 0.1041 0.0974 0.0951 0.0943 0.0906 0.0877 0.0886 0.0911 

[TRAIN] Epoch[8](103/1500); Loss: 0.142516; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1641 0.1564 0.1688 0.1647 0.1562 0.1495 0.1429 0.1378 0.1343 0.1303 0.1288 0.1265 0.1279 0.1293 0.1305 0.1322 

[TRAIN] Epoch[8](104/1500); Loss: 0.111933; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1287 0.1264 0.1158 0.1142 0.1108 0.1093 0.1088 0.1086 0.1082 0.1083 0.1087 0.1081 0.1089 0.1085 0.1085 0.1092 

[TRAIN] Epoch[8](105/1500); Loss: 0.097373; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0945 0.0959 0.1031 0.0998 0.0949 0.0945 0.0951 0.0961 0.0947 0.0965 0.0961 0.0968 0.0980 0.1000 0.1005 0.1013 

[TRAIN] Epoch[8](106/1500); Loss: 0.153391; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1646 0.1595 0.1707 0.1654 0.1599 0.1576 0.1558 0.1534 0.1505 0.1475 0.1461 0.1456 0.1449 0.1449 0.1445 0.1432 

[TRAIN] Epoch[8](107/1500); Loss: 0.137660; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1657 0.1592 0.1451 0.1428 0.1367 0.1334 0.1325 0.1327 0.1304 0.1299 0.1309 0.1313 0.1306 0.1331 0.1338 0.1347 

[TRAIN] Epoch[8](108/1500); Loss: 0.096742; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1148 0.1123 0.1163 0.1132 0.1076 0.1045 0.0992 0.0956 0.0917 0.0880 0.0854 0.0843 0.0825 0.0829 0.0837 0.0857 

[TRAIN] Epoch[8](109/1500); Loss: 0.076817; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1004 0.0917 0.1181 0.1073 0.0921 0.0829 0.0731 0.0664 0.0618 0.0613 0.0622 0.0606 0.0610 0.0619 0.0634 0.0650 

[TRAIN] Epoch[8](110/1500); Loss: 0.076196; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1003 0.0905 0.0868 0.0747 0.0740 0.0705 0.0687 0.0705 0.0685 0.0690 0.0704 0.0735 0.0734 0.0737 0.0761 0.0785 

[TRAIN] Epoch[8](111/1500); Loss: 0.126436; Backpropagation: 0.0919 sec; Batch: 0.4249 sec
0.1517 0.1421 0.1366 0.1355 0.1275 0.1238 0.1216 0.1209 0.1171 0.1175 0.1181 0.1205 0.1199 0.1216 0.1230 0.1255 

[TRAIN] Epoch[8](112/1500); Loss: 0.135108; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1883 0.1748 0.1590 0.1431 0.1422 0.1394 0.1338 0.1277 0.1250 0.1237 0.1204 0.1191 0.1179 0.1162 0.1156 0.1156 

[TRAIN] Epoch[8](113/1500); Loss: 0.068078; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1112 0.0976 0.0643 0.0586 0.0646 0.0622 0.0574 0.0587 0.0623 0.0612 0.0629 0.0623 0.0653 0.0654 0.0668 0.0685 

[TRAIN] Epoch[8](114/1500); Loss: 0.120546; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1499 0.1413 0.1277 0.1252 0.1199 0.1163 0.1140 0.1137 0.1141 0.1127 0.1144 0.1167 0.1135 0.1147 0.1170 0.1177 

[TRAIN] Epoch[8](115/1500); Loss: 0.106793; Backpropagation: 0.0922 sec; Batch: 0.4250 sec
0.1520 0.1433 0.1675 0.1579 0.1431 0.1335 0.1209 0.1078 0.0951 0.0844 0.0734 0.0678 0.0631 0.0642 0.0667 0.0679 

[TRAIN] Epoch[8](116/1500); Loss: 0.080512; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0868 0.0822 0.0859 0.0807 0.0800 0.0789 0.0771 0.0796 0.0764 0.0760 0.0767 0.0794 0.0800 0.0811 0.0828 0.0846 

[TRAIN] Epoch[8](117/1500); Loss: 0.093444; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1215 0.1027 0.1196 0.1189 0.1075 0.0947 0.0887 0.0837 0.0809 0.0813 0.0821 0.0811 0.0819 0.0827 0.0836 0.0840 

[TRAIN] Epoch[8](118/1500); Loss: 0.111265; Backpropagation: 0.0920 sec; Batch: 0.4247 sec
0.1400 0.1302 0.1188 0.0986 0.1258 0.1213 0.1106 0.0988 0.0989 0.0947 0.0978 0.1043 0.1037 0.1082 0.1128 0.1157 

[TRAIN] Epoch[8](119/1500); Loss: 0.080114; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1842 0.1664 0.0807 0.0646 0.0590 0.0667 0.0635 0.0595 0.0590 0.0614 0.0653 0.0669 0.0682 0.0688 0.0724 0.0751 

[TRAIN] Epoch[8](120/1500); Loss: 0.064026; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.0660 0.0591 0.0715 0.0741 0.0649 0.0599 0.0576 0.0600 0.0606 0.0601 0.0619 0.0638 0.0646 0.0647 0.0676 0.0683 

[TRAIN] Epoch[8](121/1500); Loss: 0.143393; Backpropagation: 0.0919 sec; Batch: 0.4246 sec
0.1604 0.1572 0.1695 0.1640 0.1584 0.1555 0.1500 0.1441 0.1385 0.1346 0.1292 0.1277 0.1261 0.1265 0.1257 0.1269 

[TRAIN] Epoch[8](122/1500); Loss: 0.180671; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.2249 0.2134 0.2377 0.2273 0.2130 0.2027 0.1904 0.1764 0.1658 0.1570 0.1493 0.1464 0.1463 0.1475 0.1461 0.1467 

[TRAIN] Epoch[8](123/1500); Loss: 0.143939; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1618 0.1542 0.1782 0.1711 0.1603 0.1537 0.1465 0.1392 0.1351 0.1320 0.1300 0.1275 0.1268 0.1277 0.1289 0.1302 

[TRAIN] Epoch[8](124/1500); Loss: 0.089896; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0992 0.0917 0.1112 0.1096 0.1007 0.0934 0.0883 0.0835 0.0809 0.0804 0.0793 0.0806 0.0818 0.0839 0.0870 0.0868 

[TRAIN] Epoch[8](125/1500); Loss: 0.168481; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1916 0.1839 0.1783 0.1749 0.1714 0.1693 0.1676 0.1681 0.1662 0.1662 0.1632 0.1610 0.1599 0.1585 0.1568 0.1587 

[TRAIN] Epoch[8](126/1500); Loss: 0.132487; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1362 0.1365 0.1336 0.1336 0.1298 0.1279 0.1286 0.1331 0.1309 0.1320 0.1352 0.1307 0.1311 0.1324 0.1343 0.1339 

[TRAIN] Epoch[8](127/1500); Loss: 0.090908; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1104 0.1015 0.1028 0.0989 0.0965 0.0942 0.0892 0.0843 0.0821 0.0825 0.0844 0.0834 0.0840 0.0852 0.0874 0.0879 

[TRAIN] Epoch[8](128/1500); Loss: 0.224404; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.2764 0.2603 0.2917 0.2770 0.2668 0.2605 0.2481 0.2326 0.2219 0.2117 0.1985 0.1888 0.1798 0.1671 0.1585 0.1507 

[TRAIN] Epoch[8](129/1500); Loss: 0.099141; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1067 0.1067 0.1158 0.1116 0.1049 0.1011 0.0970 0.0955 0.0928 0.0922 0.0924 0.0923 0.0925 0.0940 0.0952 0.0957 

[TRAIN] Epoch[8](130/1500); Loss: 0.084471; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2250 0.1995 0.0585 0.0738 0.0482 0.0848 0.1037 0.0907 0.0697 0.0675 0.0551 0.0464 0.0498 0.0509 0.0598 0.0682 

[TRAIN] Epoch[8](131/1500); Loss: 0.070472; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1033 0.0942 0.0754 0.0725 0.0694 0.0652 0.0632 0.0636 0.0632 0.0634 0.0633 0.0644 0.0650 0.0657 0.0672 0.0686 

[TRAIN] Epoch[8](132/1500); Loss: 0.122133; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1560 0.1453 0.1354 0.1318 0.1265 0.1236 0.1196 0.1144 0.1118 0.1106 0.1103 0.1106 0.1119 0.1143 0.1157 0.1164 

[TRAIN] Epoch[8](133/1500); Loss: 0.069698; Backpropagation: 0.0920 sec; Batch: 0.4250 sec
0.1088 0.1030 0.0848 0.0753 0.0677 0.0622 0.0604 0.0589 0.0592 0.0593 0.0597 0.0606 0.0615 0.0632 0.0643 0.0663 

[TRAIN] Epoch[8](134/1500); Loss: 0.080297; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1220 0.1076 0.0940 0.0867 0.0786 0.0724 0.0687 0.0682 0.0678 0.0686 0.0696 0.0715 0.0732 0.0755 0.0786 0.0817 

[TRAIN] Epoch[8](135/1500); Loss: 0.147525; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1982 0.1810 0.1785 0.1669 0.1622 0.1598 0.1519 0.1425 0.1370 0.1320 0.1280 0.1248 0.1231 0.1219 0.1248 0.1276 

[TRAIN] Epoch[8](136/1500); Loss: 0.118324; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1434 0.1346 0.1310 0.1285 0.1227 0.1187 0.1158 0.1131 0.1105 0.1099 0.1110 0.1110 0.1090 0.1102 0.1121 0.1119 

[TRAIN] Epoch[8](137/1500); Loss: 0.160850; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1964 0.1876 0.1757 0.1717 0.1678 0.1666 0.1617 0.1566 0.1547 0.1531 0.1522 0.1494 0.1474 0.1456 0.1438 0.1433 

[TRAIN] Epoch[8](138/1500); Loss: 0.109155; Backpropagation: 0.0919 sec; Batch: 0.4245 sec
0.1592 0.1403 0.1998 0.1815 0.1585 0.1448 0.1252 0.1007 0.0855 0.0708 0.0586 0.0589 0.0632 0.0643 0.0672 0.0680 

[TRAIN] Epoch[8](139/1500); Loss: 0.153625; Backpropagation: 0.0921 sec; Batch: 0.4248 sec
0.1592 0.1516 0.1637 0.1689 0.1631 0.1569 0.1557 0.1532 0.1494 0.1484 0.1485 0.1463 0.1461 0.1482 0.1496 0.1492 

[TRAIN] Epoch[8](140/1500); Loss: 0.088792; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.0979 0.0926 0.1172 0.1079 0.0983 0.0939 0.0858 0.0794 0.0785 0.0761 0.0774 0.0819 0.0803 0.0825 0.0849 0.0861 

[TRAIN] Epoch[8](141/1500); Loss: 0.104990; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1305 0.1238 0.1318 0.1249 0.1181 0.1134 0.1062 0.0990 0.0954 0.0928 0.0891 0.0887 0.0895 0.0913 0.0931 0.0924 

[TRAIN] Epoch[8](142/1500); Loss: 0.102325; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.1286 0.1211 0.1261 0.1201 0.1125 0.1082 0.1017 0.0953 0.0920 0.0901 0.0888 0.0885 0.0885 0.0920 0.0917 0.0921 

[TRAIN] Epoch[8](143/1500); Loss: 0.101716; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1802 0.1536 0.0690 0.0660 0.1134 0.1077 0.1068 0.1001 0.0909 0.0801 0.0851 0.0836 0.0876 0.0963 0.0991 0.1080 

[TRAIN] Epoch[8](144/1500); Loss: 0.146878; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1721 0.1610 0.1739 0.1671 0.1591 0.1534 0.1460 0.1383 0.1345 0.1325 0.1324 0.1325 0.1344 0.1362 0.1379 0.1386 

[TRAIN] Epoch[8](145/1500); Loss: 0.130187; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1766 0.1582 0.1998 0.1867 0.1690 0.1583 0.1437 0.1255 0.1133 0.1018 0.0917 0.0894 0.0895 0.0922 0.0943 0.0931 

[TRAIN] Epoch[8](146/1500); Loss: 0.091507; Backpropagation: 0.0920 sec; Batch: 0.4286 sec
0.1131 0.1037 0.0868 0.0851 0.0867 0.0870 0.0857 0.0850 0.0852 0.0866 0.0887 0.0893 0.0916 0.0938 0.0968 0.0989 

[TRAIN] Epoch[8](147/1500); Loss: 0.093709; Backpropagation: 0.0917 sec; Batch: 0.4251 sec
0.1218 0.1123 0.0934 0.0884 0.0990 0.0980 0.0920 0.0867 0.0864 0.0862 0.0882 0.0874 0.0881 0.0899 0.0902 0.0912 

[TRAIN] Epoch[8](148/1500); Loss: 0.080291; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.0833 0.0744 0.0965 0.0959 0.0912 0.0862 0.0821 0.0769 0.0742 0.0731 0.0749 0.0733 0.0731 0.0753 0.0773 0.0770 

[TRAIN] Epoch[8](149/1500); Loss: 0.145595; Backpropagation: 0.0919 sec; Batch: 0.4250 sec
0.1840 0.1750 0.1541 0.1421 0.1378 0.1369 0.1366 0.1373 0.1384 0.1391 0.1419 0.1411 0.1412 0.1418 0.1407 0.1414 

[TRAIN] Epoch[8](150/1500); Loss: 0.154846; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.2195 0.2035 0.1713 0.1607 0.1560 0.1522 0.1487 0.1448 0.1426 0.1425 0.1413 0.1400 0.1400 0.1384 0.1380 0.1378 

[TRAIN] Epoch[8](151/1500); Loss: 0.142529; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1904 0.1723 0.1732 0.1621 0.1564 0.1541 0.1462 0.1366 0.1310 0.1264 0.1230 0.1211 0.1194 0.1198 0.1236 0.1250 

[TRAIN] Epoch[8](152/1500); Loss: 0.122555; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1389 0.1303 0.1424 0.1278 0.1295 0.1301 0.1238 0.1159 0.1129 0.1094 0.1070 0.1102 0.1128 0.1166 0.1237 0.1296 

[TRAIN] Epoch[8](153/1500); Loss: 0.089893; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1047 0.1017 0.0936 0.0916 0.0901 0.0867 0.0846 0.0844 0.0845 0.0839 0.0873 0.0872 0.0876 0.0894 0.0901 0.0909 

[TRAIN] Epoch[8](154/1500); Loss: 0.119756; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1190 0.1169 0.1431 0.1368 0.1271 0.1244 0.1196 0.1170 0.1156 0.1134 0.1122 0.1123 0.1116 0.1130 0.1160 0.1182 

[TRAIN] Epoch[8](155/1500); Loss: 0.096044; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1036 0.1009 0.1050 0.1029 0.1007 0.0980 0.0951 0.0938 0.0916 0.0914 0.0913 0.0906 0.0909 0.0931 0.0941 0.0938 

[TRAIN] Epoch[8](156/1500); Loss: 0.105029; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1307 0.1138 0.1171 0.1156 0.1133 0.1095 0.1031 0.0956 0.0917 0.0903 0.0907 0.0933 0.0970 0.1020 0.1060 0.1108 

[TRAIN] Epoch[8](157/1500); Loss: 0.193311; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2426 0.2228 0.2398 0.2314 0.2181 0.2086 0.1997 0.1885 0.1801 0.1742 0.1685 0.1643 0.1630 0.1636 0.1635 0.1644 

[TRAIN] Epoch[8](158/1500); Loss: 0.166361; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.2221 0.1999 0.2068 0.1963 0.1809 0.1731 0.1658 0.1572 0.1513 0.1479 0.1457 0.1447 0.1438 0.1425 0.1417 0.1421 

[TRAIN] Epoch[8](159/1500); Loss: 0.128570; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1614 0.1465 0.1585 0.1560 0.1487 0.1413 0.1339 0.1260 0.1209 0.1177 0.1163 0.1127 0.1074 0.1051 0.1048 0.0999 

[TRAIN] Epoch[8](160/1500); Loss: 0.190490; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2442 0.2274 0.2196 0.2097 0.2006 0.1948 0.1907 0.1855 0.1812 0.1780 0.1745 0.1718 0.1703 0.1682 0.1666 0.1649 

[TRAIN] Epoch[8](161/1500); Loss: 0.129929; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1774 0.1601 0.1471 0.1384 0.1449 0.1418 0.1325 0.1225 0.1190 0.1163 0.1142 0.1132 0.1117 0.1132 0.1135 0.1130 

[TRAIN] Epoch[8](162/1500); Loss: 0.128559; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1442 0.1383 0.1416 0.1367 0.1305 0.1281 0.1248 0.1202 0.1195 0.1199 0.1211 0.1240 0.1242 0.1255 0.1283 0.1299 

[TRAIN] Epoch[8](163/1500); Loss: 0.234981; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2722 0.2594 0.2775 0.2693 0.2603 0.2553 0.2474 0.2384 0.2318 0.2251 0.2171 0.2119 0.2064 0.1995 0.1962 0.1919 

[TRAIN] Epoch[8](164/1500); Loss: 0.103126; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1197 0.1142 0.1066 0.1073 0.1041 0.1006 0.0994 0.0996 0.1005 0.0989 0.1010 0.1021 0.0983 0.1000 0.0994 0.0984 

[TRAIN] Epoch[8](165/1500); Loss: 0.122595; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1372 0.1324 0.1417 0.1385 0.1326 0.1281 0.1235 0.1203 0.1175 0.1156 0.1154 0.1136 0.1119 0.1122 0.1110 0.1100 

[TRAIN] Epoch[8](166/1500); Loss: 0.212492; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2491 0.2413 0.2379 0.2328 0.2240 0.2183 0.2143 0.2094 0.2059 0.2024 0.1994 0.1974 0.1948 0.1923 0.1907 0.1900 

[TRAIN] Epoch[8](167/1500); Loss: 0.151275; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1791 0.1692 0.1890 0.1796 0.1746 0.1694 0.1614 0.1519 0.1458 0.1406 0.1349 0.1297 0.1272 0.1239 0.1221 0.1220 

[TRAIN] Epoch[8](168/1500); Loss: 0.086586; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0989 0.0920 0.0895 0.0865 0.0834 0.0807 0.0796 0.0808 0.0809 0.0821 0.0833 0.0855 0.0870 0.0893 0.0914 0.0944 

[TRAIN] Epoch[8](169/1500); Loss: 0.085297; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1141 0.0902 0.1091 0.0979 0.0842 0.0762 0.0702 0.0669 0.0706 0.0749 0.0778 0.0791 0.0837 0.0865 0.0901 0.0932 

[TRAIN] Epoch[8](170/1500); Loss: 0.106202; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1480 0.1313 0.1760 0.1606 0.1419 0.1323 0.1176 0.1024 0.0932 0.0835 0.0764 0.0707 0.0662 0.0666 0.0651 0.0675 

[TRAIN] Epoch[8](171/1500); Loss: 0.128792; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1447 0.1345 0.1479 0.1438 0.1356 0.1311 0.1269 0.1225 0.1200 0.1194 0.1209 0.1225 0.1204 0.1227 0.1235 0.1244 

[TRAIN] Epoch[8](172/1500); Loss: 0.128816; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1285 0.1262 0.1361 0.1331 0.1298 0.1287 0.1259 0.1244 0.1250 0.1247 0.1269 0.1291 0.1290 0.1319 0.1314 0.1302 

[TRAIN] Epoch[8](173/1500); Loss: 0.126589; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1639 0.1464 0.1362 0.1341 0.1304 0.1275 0.1239 0.1208 0.1185 0.1185 0.1191 0.1168 0.1174 0.1182 0.1169 0.1170 

[TRAIN] Epoch[8](174/1500); Loss: 0.079761; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0960 0.0945 0.0804 0.0813 0.0778 0.0761 0.0749 0.0747 0.0740 0.0743 0.0767 0.0773 0.0784 0.0795 0.0800 0.0803 

[TRAIN] Epoch[8](175/1500); Loss: 0.157475; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1805 0.1772 0.1873 0.1776 0.1696 0.1653 0.1603 0.1559 0.1525 0.1489 0.1457 0.1425 0.1404 0.1394 0.1385 0.1378 

[TRAIN] Epoch[8](176/1500); Loss: 0.159000; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1813 0.1735 0.1739 0.1684 0.1617 0.1574 0.1543 0.1516 0.1507 0.1502 0.1521 0.1527 0.1521 0.1534 0.1552 0.1555 

[TRAIN] Epoch[8](177/1500); Loss: 0.090672; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1740 0.1452 0.0522 0.0512 0.1025 0.0967 0.0999 0.0976 0.0865 0.0737 0.0798 0.0724 0.0726 0.0817 0.0797 0.0850 

[TRAIN] Epoch[8](178/1500); Loss: 0.097353; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1091 0.0978 0.1187 0.1201 0.1118 0.1044 0.1015 0.0962 0.0916 0.0897 0.0878 0.0864 0.0854 0.0854 0.0856 0.0860 

[TRAIN] Epoch[8](179/1500); Loss: 0.061417; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0514 0.0593 0.0654 0.0597 0.0624 0.0625 0.0616 0.0626 0.0647 0.0605 0.0594 0.0593 0.0598 0.0639 0.0652 0.0650 

[TRAIN] Epoch[8](180/1500); Loss: 0.264292; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.3440 0.3162 0.3474 0.3324 0.3100 0.2957 0.2800 0.2589 0.2435 0.2310 0.2156 0.2087 0.2113 0.2092 0.2113 0.2133 

[TRAIN] Epoch[8](181/1500); Loss: 0.199474; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2548 0.2387 0.2565 0.2397 0.2272 0.2179 0.2085 0.1975 0.1891 0.1815 0.1745 0.1696 0.1650 0.1599 0.1569 0.1542 

[TRAIN] Epoch[8](182/1500); Loss: 0.128314; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1909 0.1677 0.2212 0.2042 0.1824 0.1685 0.1512 0.1282 0.1100 0.0953 0.0776 0.0682 0.0681 0.0698 0.0741 0.0755 

[TRAIN] Epoch[8](183/1500); Loss: 0.073774; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0802 0.0745 0.0869 0.0720 0.0872 0.0920 0.0838 0.0736 0.0755 0.0690 0.0640 0.0656 0.0624 0.0631 0.0655 0.0652 

[TRAIN] Epoch[8](184/1500); Loss: 0.125142; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1732 0.1633 0.1376 0.1206 0.1172 0.1164 0.1158 0.1146 0.1150 0.1151 0.1177 0.1183 0.1180 0.1191 0.1199 0.1204 

[TRAIN] Epoch[8](185/1500); Loss: 0.146817; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1802 0.1687 0.1560 0.1515 0.1511 0.1498 0.1462 0.1429 0.1408 0.1400 0.1403 0.1375 0.1372 0.1363 0.1348 0.1356 

[TRAIN] Epoch[8](186/1500); Loss: 0.160955; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1917 0.1752 0.1702 0.1671 0.1656 0.1632 0.1593 0.1561 0.1547 0.1536 0.1537 0.1525 0.1523 0.1535 0.1529 0.1539 

[TRAIN] Epoch[8](187/1500); Loss: 0.133768; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1503 0.1418 0.1407 0.1331 0.1332 0.1331 0.1309 0.1291 0.1305 0.1293 0.1299 0.1311 0.1299 0.1310 0.1325 0.1337 

[TRAIN] Epoch[8](188/1500); Loss: 0.181159; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2215 0.2074 0.2114 0.2045 0.1962 0.1913 0.1855 0.1785 0.1737 0.1699 0.1659 0.1627 0.1603 0.1580 0.1565 0.1553 

[TRAIN] Epoch[8](189/1500); Loss: 0.124717; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2008 0.1797 0.1456 0.1327 0.1207 0.1278 0.1332 0.1228 0.1129 0.1141 0.1057 0.0997 0.1014 0.0966 0.0965 0.1053 

[TRAIN] Epoch[8](190/1500); Loss: 0.188541; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2350 0.2126 0.2784 0.2604 0.2390 0.2277 0.2117 0.1912 0.1800 0.1664 0.1502 0.1480 0.1372 0.1274 0.1294 0.1221 

[TRAIN] Epoch[8](191/1500); Loss: 0.139468; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1504 0.1413 0.1579 0.1570 0.1491 0.1437 0.1403 0.1366 0.1338 0.1323 0.1315 0.1296 0.1295 0.1313 0.1332 0.1338 

[TRAIN] Epoch[8](192/1500); Loss: 0.090749; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0994 0.0968 0.0929 0.0922 0.0897 0.0873 0.0861 0.0871 0.0878 0.0877 0.0902 0.0891 0.0897 0.0910 0.0926 0.0923 

[TRAIN] Epoch[8](193/1500); Loss: 0.150704; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1724 0.1619 0.1736 0.1700 0.1629 0.1560 0.1531 0.1474 0.1426 0.1427 0.1402 0.1375 0.1379 0.1377 0.1368 0.1385 

[TRAIN] Epoch[8](194/1500); Loss: 0.105516; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1100 0.1085 0.1244 0.1180 0.1116 0.1083 0.1035 0.1004 0.0996 0.0988 0.0998 0.0999 0.0997 0.1013 0.1021 0.1024 

[TRAIN] Epoch[8](195/1500); Loss: 0.108718; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1267 0.1185 0.1270 0.1241 0.1171 0.1119 0.1089 0.1046 0.1010 0.1002 0.0998 0.0997 0.0983 0.0995 0.1008 0.1013 

[TRAIN] Epoch[8](196/1500); Loss: 0.136481; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2152 0.1995 0.1604 0.1385 0.1285 0.1370 0.1421 0.1325 0.1239 0.1244 0.1165 0.1109 0.1133 0.1093 0.1104 0.1213 

[TRAIN] Epoch[8](197/1500); Loss: 0.334093; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.4618 0.4244 0.4872 0.4645 0.4351 0.4163 0.3923 0.3588 0.3335 0.3093 0.2722 0.2490 0.2256 0.1895 0.1712 0.1548 

[TRAIN] Epoch[8](198/1500); Loss: 0.153231; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.2060 0.1827 0.2069 0.1940 0.1865 0.1816 0.1701 0.1557 0.1459 0.1364 0.1262 0.1195 0.1140 0.1102 0.1087 0.1076 

[TRAIN] Epoch[8](199/1500); Loss: 0.083353; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1773 0.1557 0.0705 0.0744 0.0678 0.0919 0.1014 0.0884 0.0767 0.0761 0.0654 0.0582 0.0590 0.0541 0.0579 0.0589 

[TRAIN] Epoch[8](200/1500); Loss: 0.074279; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0721 0.0676 0.0942 0.0889 0.0790 0.0740 0.0692 0.0663 0.0661 0.0664 0.0681 0.0714 0.0729 0.0745 0.0777 0.0799 

[TRAIN] Epoch[8](201/1500); Loss: 0.172566; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2185 0.2027 0.2229 0.2127 0.1985 0.1897 0.1794 0.1684 0.1608 0.1549 0.1499 0.1455 0.1425 0.1403 0.1381 0.1364 

[TRAIN] Epoch[8](202/1500); Loss: 0.100702; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1111 0.1032 0.1139 0.1118 0.1070 0.1033 0.0998 0.0958 0.0947 0.0918 0.0943 0.0967 0.0945 0.0977 0.0979 0.0978 

[TRAIN] Epoch[8](203/1500); Loss: 0.095783; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1173 0.1045 0.1249 0.1212 0.1139 0.1085 0.1030 0.0931 0.0866 0.0837 0.0795 0.0774 0.0771 0.0784 0.0805 0.0830 

[TRAIN] Epoch[8](204/1500); Loss: 0.126099; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1504 0.1362 0.1397 0.1356 0.1282 0.1224 0.1191 0.1161 0.1148 0.1149 0.1180 0.1193 0.1207 0.1249 0.1278 0.1294 

[TRAIN] Epoch[8](205/1500); Loss: 0.141353; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2242 0.2041 0.1533 0.1447 0.1396 0.1470 0.1454 0.1367 0.1293 0.1268 0.1226 0.1207 0.1196 0.1167 0.1159 0.1150 

[TRAIN] Epoch[8](206/1500); Loss: 0.204420; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2643 0.2438 0.2680 0.2567 0.2399 0.2275 0.2162 0.2010 0.1890 0.1811 0.1727 0.1650 0.1628 0.1616 0.1602 0.1611 

[TRAIN] Epoch[8](207/1500); Loss: 0.132126; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1461 0.1395 0.1502 0.1448 0.1395 0.1365 0.1321 0.1295 0.1287 0.1265 0.1255 0.1251 0.1225 0.1223 0.1231 0.1222 

[TRAIN] Epoch[8](208/1500); Loss: 0.073474; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.0726 0.0668 0.0839 0.0787 0.0817 0.0801 0.0751 0.0699 0.0697 0.0680 0.0688 0.0695 0.0699 0.0728 0.0733 0.0748 

[TRAIN] Epoch[8](209/1500); Loss: 0.118559; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1805 0.1653 0.1289 0.1142 0.1121 0.1108 0.1088 0.1068 0.1063 0.1066 0.1074 0.1077 0.1087 0.1097 0.1110 0.1122 

[TRAIN] Epoch[8](210/1500); Loss: 0.083095; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0911 0.0835 0.0956 0.0872 0.0940 0.0958 0.0892 0.0809 0.0795 0.0758 0.0747 0.0756 0.0737 0.0769 0.0784 0.0776 

[TRAIN] Epoch[8](211/1500); Loss: 0.111853; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1342 0.1247 0.1429 0.1334 0.1253 0.1210 0.1126 0.1054 0.1021 0.0989 0.0976 0.0978 0.0977 0.0991 0.0979 0.0992 

[TRAIN] Epoch[8](212/1500); Loss: 0.290106; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.4078 0.3740 0.4183 0.4002 0.3749 0.3575 0.3359 0.3088 0.2852 0.2638 0.2358 0.2128 0.1930 0.1687 0.1561 0.1488 

[TRAIN] Epoch[8](213/1500); Loss: 0.135965; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1783 0.1632 0.1767 0.1677 0.1579 0.1499 0.1409 0.1319 0.1245 0.1192 0.1151 0.1120 0.1103 0.1092 0.1090 0.1097 

[TRAIN] Epoch[8](214/1500); Loss: 0.131675; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1669 0.1567 0.1329 0.1347 0.1296 0.1308 0.1302 0.1271 0.1233 0.1229 0.1231 0.1251 0.1243 0.1259 0.1271 0.1262 

[TRAIN] Epoch[8](215/1500); Loss: 0.132795; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1650 0.1542 0.1320 0.1272 0.1357 0.1368 0.1314 0.1264 0.1259 0.1244 0.1254 0.1260 0.1270 0.1288 0.1284 0.1300 

[TRAIN] Epoch[8](216/1500); Loss: 0.171612; Backpropagation: 0.0915 sec; Batch: 0.4234 sec
0.2026 0.1900 0.2032 0.1971 0.1896 0.1842 0.1775 0.1707 0.1651 0.1605 0.1560 0.1527 0.1497 0.1485 0.1498 0.1486 

[TRAIN] Epoch[8](217/1500); Loss: 0.088698; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0865 0.0863 0.0840 0.0806 0.0870 0.0873 0.0854 0.0851 0.0866 0.0868 0.0893 0.0910 0.0921 0.0949 0.0975 0.0986 

[TRAIN] Epoch[8](218/1500); Loss: 0.100515; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1062 0.0979 0.1198 0.1211 0.1113 0.1049 0.1016 0.0972 0.0933 0.0921 0.0941 0.0926 0.0917 0.0937 0.0955 0.0952 

[TRAIN] Epoch[8](219/1500); Loss: 0.173670; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1837 0.1779 0.1934 0.1888 0.1824 0.1790 0.1747 0.1716 0.1689 0.1673 0.1661 0.1645 0.1642 0.1658 0.1652 0.1653 

[TRAIN] Epoch[8](220/1500); Loss: 0.073984; Backpropagation: 0.0916 sec; Batch: 0.4230 sec
0.0828 0.0710 0.0890 0.0855 0.0858 0.0815 0.0763 0.0700 0.0677 0.0660 0.0661 0.0669 0.0658 0.0679 0.0703 0.0711 

[TRAIN] Epoch[8](221/1500); Loss: 0.110684; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2123 0.1888 0.1316 0.1116 0.1000 0.1088 0.1141 0.1041 0.0936 0.0940 0.0862 0.0821 0.0841 0.0827 0.0864 0.0906 

[TRAIN] Epoch[8](222/1500); Loss: 0.126522; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1424 0.1356 0.1299 0.1261 0.1300 0.1284 0.1250 0.1231 0.1228 0.1222 0.1242 0.1227 0.1229 0.1236 0.1226 0.1229 

[TRAIN] Epoch[8](223/1500); Loss: 0.078920; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1186 0.1067 0.0980 0.0867 0.0798 0.0763 0.0728 0.0699 0.0688 0.0684 0.0691 0.0686 0.0693 0.0691 0.0694 0.0711 

[TRAIN] Epoch[8](224/1500); Loss: 0.103031; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1549 0.1367 0.1600 0.1473 0.1298 0.1169 0.1034 0.0899 0.0800 0.0749 0.0729 0.0737 0.0755 0.0765 0.0772 0.0790 

[TRAIN] Epoch[8](225/1500); Loss: 0.151205; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1773 0.1715 0.1777 0.1740 0.1676 0.1635 0.1586 0.1531 0.1470 0.1416 0.1370 0.1324 0.1300 0.1293 0.1290 0.1296 

[TRAIN] Epoch[8](226/1500); Loss: 0.126500; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1210 0.1099 0.1543 0.1364 0.1456 0.1507 0.1407 0.1283 0.1275 0.1202 0.1149 0.1150 0.1122 0.1128 0.1171 0.1173 

[TRAIN] Epoch[8](227/1500); Loss: 0.094013; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1356 0.1233 0.1118 0.1006 0.0928 0.0884 0.0850 0.0836 0.0834 0.0828 0.0846 0.0851 0.0852 0.0863 0.0878 0.0880 

[TRAIN] Epoch[8](228/1500); Loss: 0.078445; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0785 0.0785 0.0814 0.0812 0.0785 0.0762 0.0749 0.0750 0.0755 0.0753 0.0768 0.0771 0.0783 0.0817 0.0823 0.0839 

[TRAIN] Epoch[8](229/1500); Loss: 0.112323; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1639 0.1435 0.1681 0.1552 0.1371 0.1233 0.1094 0.0963 0.0878 0.0845 0.0847 0.0865 0.0870 0.0887 0.0901 0.0912 

[TRAIN] Epoch[8](230/1500); Loss: 0.229131; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.3181 0.2924 0.3490 0.3307 0.3090 0.2944 0.2741 0.2505 0.2278 0.2053 0.1798 0.1575 0.1387 0.1215 0.1109 0.1062 

[TRAIN] Epoch[8](231/1500); Loss: 0.136260; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1653 0.1545 0.1852 0.1744 0.1615 0.1538 0.1429 0.1324 0.1233 0.1170 0.1126 0.1115 0.1108 0.1116 0.1118 0.1115 

[TRAIN] Epoch[8](232/1500); Loss: 0.152537; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1720 0.1655 0.1707 0.1674 0.1626 0.1593 0.1541 0.1507 0.1475 0.1438 0.1430 0.1425 0.1420 0.1398 0.1402 0.1393 

[TRAIN] Epoch[8](233/1500); Loss: 0.072543; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.0853 0.0788 0.0787 0.0777 0.0724 0.0688 0.0677 0.0680 0.0677 0.0674 0.0689 0.0694 0.0697 0.0716 0.0743 0.0743 

[TRAIN] Epoch[8](234/1500); Loss: 0.169923; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1827 0.1816 0.1737 0.1739 0.1708 0.1694 0.1690 0.1688 0.1681 0.1672 0.1672 0.1656 0.1657 0.1653 0.1650 0.1648 

[TRAIN] Epoch[8](235/1500); Loss: 0.074063; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1071 0.0895 0.0821 0.0793 0.0737 0.0677 0.0647 0.0647 0.0648 0.0652 0.0669 0.0679 0.0701 0.0717 0.0736 0.0761 

[TRAIN] Epoch[8](236/1500); Loss: 0.087602; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1167 0.1010 0.1066 0.1056 0.0971 0.0892 0.0845 0.0792 0.0760 0.0751 0.0772 0.0778 0.0767 0.0776 0.0791 0.0820 

[TRAIN] Epoch[8](237/1500); Loss: 0.110424; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1150 0.1107 0.1228 0.1208 0.1143 0.1094 0.1059 0.1034 0.1025 0.1035 0.1072 0.1079 0.1080 0.1120 0.1110 0.1123 

[TRAIN] Epoch[8](238/1500); Loss: 0.268718; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.3506 0.3253 0.3471 0.3347 0.3151 0.2997 0.2823 0.2618 0.2428 0.2272 0.2185 0.2160 0.2172 0.2216 0.2190 0.2205 

[TRAIN] Epoch[8](239/1500); Loss: 0.124070; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1552 0.1505 0.1356 0.1271 0.1245 0.1225 0.1196 0.1181 0.1179 0.1162 0.1169 0.1161 0.1167 0.1156 0.1164 0.1161 

[TRAIN] Epoch[8](240/1500); Loss: 0.103379; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2392 0.2165 0.1278 0.0882 0.0809 0.1111 0.1063 0.0975 0.0869 0.0790 0.0675 0.0656 0.0733 0.0709 0.0729 0.0705 

[TRAIN] Epoch[8](241/1500); Loss: 0.087113; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0855 0.0739 0.1007 0.0751 0.1076 0.1111 0.0991 0.0867 0.0873 0.0793 0.0755 0.0794 0.0769 0.0798 0.0882 0.0876 

[TRAIN] Epoch[8](242/1500); Loss: 0.149816; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1628 0.1586 0.1529 0.1524 0.1504 0.1494 0.1482 0.1480 0.1462 0.1465 0.1457 0.1461 0.1462 0.1472 0.1474 0.1490 

[TRAIN] Epoch[8](243/1500); Loss: 0.115393; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1478 0.1287 0.1611 0.1492 0.1328 0.1209 0.1084 0.0991 0.0970 0.0968 0.0975 0.0996 0.1005 0.1011 0.1018 0.1042 

[TRAIN] Epoch[8](244/1500); Loss: 0.121361; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.1506 0.1419 0.1265 0.1207 0.1185 0.1183 0.1163 0.1160 0.1147 0.1151 0.1159 0.1163 0.1162 0.1176 0.1180 0.1191 

[TRAIN] Epoch[8](245/1500); Loss: 0.110360; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1279 0.1169 0.1217 0.1193 0.1133 0.1083 0.1060 0.1049 0.1043 0.1040 0.1057 0.1051 0.1060 0.1068 0.1075 0.1080 

[TRAIN] Epoch[8](246/1500); Loss: 0.079468; Backpropagation: 0.0916 sec; Batch: 0.4231 sec
0.0935 0.0911 0.0835 0.0815 0.0764 0.0746 0.0746 0.0761 0.0764 0.0759 0.0772 0.0764 0.0777 0.0780 0.0788 0.0798 

[TRAIN] Epoch[8](247/1500); Loss: 0.112551; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1132 0.1160 0.1137 0.1129 0.1112 0.1109 0.1110 0.1129 0.1125 0.1111 0.1122 0.1116 0.1121 0.1121 0.1130 0.1144 

[TRAIN] Epoch[8](248/1500); Loss: 0.169554; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2026 0.1942 0.2041 0.1992 0.1915 0.1854 0.1793 0.1655 0.1577 0.1522 0.1487 0.1450 0.1465 0.1484 0.1461 0.1465 

[TRAIN] Epoch[8](249/1500); Loss: 0.058270; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.0490 0.0568 0.0621 0.0567 0.0584 0.0588 0.0583 0.0590 0.0572 0.0562 0.0565 0.0579 0.0585 0.0619 0.0617 0.0633 

[TRAIN] Epoch[8](250/1500); Loss: 0.166972; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2035 0.1917 0.1966 0.1908 0.1819 0.1746 0.1680 0.1613 0.1553 0.1518 0.1502 0.1494 0.1491 0.1496 0.1492 0.1488 

[TRAIN] Epoch[8](251/1500); Loss: 0.174045; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2095 0.1998 0.2162 0.2082 0.1965 0.1887 0.1792 0.1706 0.1630 0.1575 0.1529 0.1509 0.1492 0.1482 0.1474 0.1469 

[TRAIN] Epoch[8](252/1500); Loss: 0.205160; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.2827 0.2580 0.3018 0.2865 0.2682 0.2556 0.2378 0.2176 0.1985 0.1804 0.1624 0.1472 0.1332 0.1232 0.1166 0.1129 

[TRAIN] Epoch[8](253/1500); Loss: 0.111087; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1335 0.1275 0.1217 0.1130 0.1074 0.1049 0.1026 0.1017 0.1024 0.1038 0.1060 0.1059 0.1083 0.1105 0.1134 0.1148 

[TRAIN] Epoch[8](254/1500); Loss: 0.121422; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.2030 0.1902 0.1393 0.1080 0.1091 0.1166 0.1140 0.1099 0.1066 0.1049 0.1061 0.1074 0.1068 0.1062 0.1071 0.1076 

[TRAIN] Epoch[8](255/1500); Loss: 0.114233; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1579 0.1442 0.1596 0.1514 0.1385 0.1294 0.1195 0.1101 0.1010 0.0943 0.0896 0.0865 0.0871 0.0866 0.0855 0.0865 

[TRAIN] Epoch[8](256/1500); Loss: 0.150514; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1658 0.1615 0.1668 0.1650 0.1586 0.1529 0.1499 0.1477 0.1456 0.1441 0.1437 0.1422 0.1411 0.1413 0.1408 0.1411 

[TRAIN] Epoch[8](257/1500); Loss: 0.133835; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1746 0.1625 0.1495 0.1448 0.1429 0.1396 0.1344 0.1304 0.1267 0.1233 0.1201 0.1181 0.1170 0.1185 0.1188 0.1200 

[TRAIN] Epoch[8](258/1500); Loss: 0.079725; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2041 0.1800 0.0664 0.0745 0.0570 0.0809 0.0913 0.0781 0.0608 0.0593 0.0491 0.0461 0.0596 0.0561 0.0573 0.0550 

[TRAIN] Epoch[8](259/1500); Loss: 0.078482; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1925 0.1715 0.0738 0.0636 0.0574 0.0689 0.0705 0.0630 0.0561 0.0580 0.0581 0.0610 0.0625 0.0640 0.0667 0.0682 

[TRAIN] Epoch[8](260/1500); Loss: 0.122284; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2312 0.2095 0.1495 0.1240 0.1119 0.1191 0.1216 0.1111 0.0997 0.0987 0.0923 0.0918 0.0999 0.0982 0.1001 0.0979 

[TRAIN] Epoch[8](261/1500); Loss: 0.118754; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1439 0.1321 0.1343 0.1289 0.1247 0.1205 0.1138 0.1092 0.1085 0.1111 0.1130 0.1099 0.1100 0.1121 0.1138 0.1143 

[TRAIN] Epoch[8](262/1500); Loss: 0.067740; Backpropagation: 0.0930 sec; Batch: 0.4247 sec
0.0908 0.0873 0.0734 0.0676 0.0633 0.0624 0.0602 0.0605 0.0604 0.0617 0.0621 0.0640 0.0649 0.0669 0.0681 0.0703 

[TRAIN] Epoch[8](263/1500); Loss: 0.224728; Backpropagation: 0.0927 sec; Batch: 0.4265 sec
0.2597 0.2459 0.2623 0.2548 0.2488 0.2420 0.2338 0.2258 0.2187 0.2126 0.2079 0.2023 0.1982 0.1956 0.1939 0.1933 

[TRAIN] Epoch[8](264/1500); Loss: 0.108541; Backpropagation: 0.0925 sec; Batch: 0.4243 sec
0.1392 0.1263 0.1144 0.1122 0.1106 0.1089 0.1036 0.0986 0.0971 0.0977 0.0992 0.1000 0.1018 0.1055 0.1086 0.1129 

[TRAIN] Epoch[8](265/1500); Loss: 0.111527; Backpropagation: 0.0929 sec; Batch: 0.4252 sec
0.1400 0.1329 0.1320 0.1193 0.1126 0.1078 0.1050 0.1029 0.1043 0.1026 0.1026 0.1041 0.1041 0.1039 0.1046 0.1058 

[TRAIN] Epoch[8](266/1500); Loss: 0.099737; Backpropagation: 0.0928 sec; Batch: 0.4248 sec
0.1228 0.1070 0.1262 0.1169 0.1065 0.0982 0.0908 0.0880 0.0881 0.0881 0.0905 0.0913 0.0928 0.0942 0.0964 0.0980 

[TRAIN] Epoch[8](267/1500); Loss: 0.132096; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1834 0.1675 0.1443 0.1474 0.1394 0.1373 0.1328 0.1281 0.1235 0.1219 0.1188 0.1156 0.1139 0.1139 0.1130 0.1128 

[TRAIN] Epoch[8](268/1500); Loss: 0.071195; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0705 0.0771 0.0805 0.0755 0.0706 0.0676 0.0678 0.0689 0.0685 0.0679 0.0685 0.0696 0.0697 0.0710 0.0726 0.0727 

[TRAIN] Epoch[8](269/1500); Loss: 0.097067; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1179 0.1102 0.1073 0.1018 0.0960 0.0929 0.0909 0.0909 0.0912 0.0912 0.0921 0.0922 0.0935 0.0940 0.0945 0.0964 

[TRAIN] Epoch[8](270/1500); Loss: 0.094683; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.2157 0.1919 0.0698 0.0931 0.0684 0.0983 0.1147 0.1012 0.0805 0.0772 0.0660 0.0582 0.0601 0.0625 0.0807 0.0767 

[TRAIN] Epoch[8](271/1500); Loss: 0.099548; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1106 0.1009 0.1207 0.1130 0.1031 0.0955 0.0905 0.0905 0.0917 0.0925 0.0939 0.0958 0.0965 0.0977 0.0992 0.1008 

[TRAIN] Epoch[8](272/1500); Loss: 0.100821; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1293 0.1222 0.1041 0.0989 0.1002 0.1003 0.0977 0.0952 0.0946 0.0945 0.0955 0.0950 0.0949 0.0963 0.0971 0.0974 

[TRAIN] Epoch[8](273/1500); Loss: 0.097240; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1141 0.1048 0.1134 0.1095 0.1042 0.0995 0.0946 0.0903 0.0878 0.0874 0.0892 0.0887 0.0903 0.0929 0.0942 0.0951 

[TRAIN] Epoch[8](274/1500); Loss: 0.146639; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.1915 0.1862 0.1609 0.1429 0.1377 0.1368 0.1376 0.1366 0.1365 0.1369 0.1383 0.1400 0.1410 0.1406 0.1412 0.1414 

[TRAIN] Epoch[8](275/1500); Loss: 0.112053; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1140 0.1130 0.1088 0.1075 0.1082 0.1075 0.1076 0.1097 0.1101 0.1108 0.1133 0.1134 0.1138 0.1172 0.1188 0.1191 

[TRAIN] Epoch[8](276/1500); Loss: 0.141219; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1844 0.1722 0.1542 0.1476 0.1418 0.1404 0.1374 0.1338 0.1304 0.1300 0.1302 0.1314 0.1310 0.1313 0.1318 0.1314 

[TRAIN] Epoch[8](277/1500); Loss: 0.112478; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1547 0.1461 0.1082 0.1065 0.1036 0.1073 0.1081 0.1074 0.1043 0.1054 0.1053 0.1070 0.1103 0.1087 0.1080 0.1087 

[TRAIN] Epoch[8](278/1500); Loss: 0.110146; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1785 0.1589 0.1801 0.1680 0.1498 0.1355 0.1186 0.1017 0.0873 0.0760 0.0699 0.0675 0.0667 0.0662 0.0699 0.0677 

[TRAIN] Epoch[8](279/1500); Loss: 0.041305; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.0368 0.0388 0.0346 0.0362 0.0357 0.0351 0.0364 0.0369 0.0384 0.0398 0.0425 0.0442 0.0475 0.0495 0.0531 0.0554 

[TRAIN] Epoch[8](280/1500); Loss: 0.139915; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1750 0.1619 0.1583 0.1504 0.1431 0.1388 0.1356 0.1339 0.1321 0.1311 0.1315 0.1292 0.1286 0.1294 0.1294 0.1303 

[TRAIN] Epoch[8](281/1500); Loss: 0.094361; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1546 0.1270 0.1636 0.1483 0.1263 0.1096 0.0908 0.0731 0.0623 0.0618 0.0627 0.0641 0.0632 0.0663 0.0659 0.0702 

[TRAIN] Epoch[8](282/1500); Loss: 0.242032; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.3699 0.3337 0.3880 0.3676 0.3419 0.3232 0.2969 0.2680 0.2381 0.2075 0.1765 0.1470 0.1224 0.1045 0.0947 0.0927 

[TRAIN] Epoch[8](283/1500); Loss: 0.115407; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1400 0.1261 0.1441 0.1380 0.1270 0.1192 0.1124 0.1081 0.1060 0.1040 0.1022 0.1022 0.1031 0.1030 0.1047 0.1064 

[TRAIN] Epoch[8](284/1500); Loss: 0.078660; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.0956 0.0830 0.0979 0.0930 0.0826 0.0758 0.0731 0.0734 0.0706 0.0722 0.0713 0.0730 0.0725 0.0735 0.0747 0.0765 

[TRAIN] Epoch[8](285/1500); Loss: 0.152782; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1896 0.1776 0.1558 0.1474 0.1487 0.1499 0.1470 0.1441 0.1439 0.1455 0.1457 0.1460 0.1481 0.1519 0.1511 0.1522 

[TRAIN] Epoch[8](286/1500); Loss: 0.165823; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1769 0.1739 0.1705 0.1699 0.1687 0.1679 0.1657 0.1655 0.1635 0.1636 0.1625 0.1613 0.1610 0.1608 0.1605 0.1608 

[TRAIN] Epoch[8](287/1500); Loss: 0.140557; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2065 0.1771 0.1931 0.1807 0.1707 0.1618 0.1476 0.1336 0.1226 0.1141 0.1088 0.1045 0.1045 0.1061 0.1081 0.1091 

[TRAIN] Epoch[8](288/1500); Loss: 0.176123; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2423 0.2225 0.2264 0.2156 0.2110 0.2042 0.1917 0.1796 0.1693 0.1607 0.1524 0.1404 0.1329 0.1274 0.1219 0.1197 

[TRAIN] Epoch[8](289/1500); Loss: 0.065592; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0833 0.0764 0.0612 0.0603 0.0633 0.0635 0.0599 0.0583 0.0587 0.0602 0.0614 0.0634 0.0655 0.0682 0.0712 0.0747 

[TRAIN] Epoch[8](290/1500); Loss: 0.101568; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1276 0.1094 0.1031 0.0823 0.1191 0.1207 0.1083 0.0981 0.0975 0.0898 0.0892 0.0929 0.0917 0.0950 0.0986 0.1019 

[TRAIN] Epoch[8](291/1500); Loss: 0.166674; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2206 0.2048 0.1886 0.1761 0.1716 0.1666 0.1625 0.1603 0.1591 0.1557 0.1543 0.1527 0.1505 0.1484 0.1483 0.1467 

[TRAIN] Epoch[8](292/1500); Loss: 0.091142; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1281 0.1152 0.1114 0.1020 0.0953 0.0895 0.0850 0.0827 0.0813 0.0805 0.0796 0.0799 0.0804 0.0817 0.0824 0.0832 

[TRAIN] Epoch[8](293/1500); Loss: 0.135242; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1832 0.1639 0.1824 0.1714 0.1556 0.1447 0.1324 0.1219 0.1163 0.1138 0.1130 0.1131 0.1128 0.1121 0.1140 0.1134 

[TRAIN] Epoch[8](294/1500); Loss: 0.139977; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1544 0.1491 0.1524 0.1501 0.1465 0.1429 0.1400 0.1380 0.1357 0.1344 0.1334 0.1336 0.1324 0.1324 0.1319 0.1325 

[TRAIN] Epoch[8](295/1500); Loss: 0.135502; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1900 0.1637 0.1741 0.1648 0.1512 0.1414 0.1315 0.1243 0.1191 0.1171 0.1175 0.1155 0.1141 0.1140 0.1144 0.1154 

[TRAIN] Epoch[8](296/1500); Loss: 0.142623; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2021 0.1776 0.1941 0.1835 0.1686 0.1571 0.1444 0.1325 0.1227 0.1163 0.1141 0.1142 0.1143 0.1134 0.1134 0.1138 

[TRAIN] Epoch[8](297/1500); Loss: 0.128387; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1431 0.1397 0.1388 0.1355 0.1319 0.1295 0.1267 0.1255 0.1239 0.1236 0.1243 0.1224 0.1218 0.1224 0.1224 0.1227 

[TRAIN] Epoch[8](298/1500); Loss: 0.131765; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1869 0.1696 0.1455 0.1416 0.1444 0.1396 0.1331 0.1272 0.1253 0.1229 0.1193 0.1161 0.1125 0.1099 0.1085 0.1059 

[TRAIN] Epoch[8](299/1500); Loss: 0.111150; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1362 0.1255 0.1142 0.1114 0.1136 0.1139 0.1090 0.1031 0.1024 0.1040 0.1058 0.1067 0.1071 0.1084 0.1083 0.1089 

[TRAIN] Epoch[8](300/1500); Loss: 0.129021; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1434 0.1386 0.1427 0.1398 0.1344 0.1304 0.1280 0.1270 0.1254 0.1248 0.1242 0.1217 0.1212 0.1212 0.1202 0.1212 

[TRAIN] Epoch[8](301/1500); Loss: 0.085976; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1083 0.0961 0.1081 0.1026 0.0913 0.0839 0.0812 0.0829 0.0786 0.0768 0.0778 0.0772 0.0767 0.0776 0.0778 0.0786 

[TRAIN] Epoch[8](302/1500); Loss: 0.126069; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1326 0.1301 0.1303 0.1295 0.1281 0.1267 0.1253 0.1249 0.1230 0.1232 0.1237 0.1234 0.1224 0.1235 0.1249 0.1255 

[TRAIN] Epoch[8](303/1500); Loss: 0.077398; Backpropagation: 0.0924 sec; Batch: 0.4239 sec
0.0881 0.0708 0.1074 0.1029 0.0894 0.0837 0.0768 0.0692 0.0649 0.0637 0.0643 0.0668 0.0692 0.0725 0.0733 0.0755 

[TRAIN] Epoch[8](304/1500); Loss: 0.155995; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.1960 0.1756 0.1453 0.1408 0.1679 0.1617 0.1563 0.1525 0.1461 0.1430 0.1447 0.1460 0.1521 0.1541 0.1550 0.1589 

[TRAIN] Epoch[8](305/1500); Loss: 0.139036; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1708 0.1606 0.1513 0.1477 0.1415 0.1379 0.1365 0.1356 0.1325 0.1318 0.1310 0.1290 0.1293 0.1291 0.1303 0.1298 

[TRAIN] Epoch[8](306/1500); Loss: 0.101022; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1269 0.1117 0.1232 0.1099 0.1051 0.0995 0.0959 0.0906 0.0880 0.0900 0.0906 0.0924 0.0933 0.0963 0.0996 0.1034 

[TRAIN] Epoch[8](307/1500); Loss: 0.118148; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.2300 0.2060 0.1448 0.1211 0.1081 0.1140 0.1153 0.1046 0.0936 0.0926 0.0869 0.0867 0.0982 0.0969 0.0965 0.0952 

[TRAIN] Epoch[8](308/1500); Loss: 0.140021; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1542 0.1455 0.1477 0.1444 0.1399 0.1368 0.1352 0.1348 0.1354 0.1351 0.1366 0.1366 0.1382 0.1387 0.1407 0.1405 

[TRAIN] Epoch[8](309/1500); Loss: 0.157445; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1742 0.1670 0.1743 0.1697 0.1640 0.1611 0.1580 0.1559 0.1539 0.1529 0.1512 0.1486 0.1475 0.1468 0.1468 0.1472 

[TRAIN] Epoch[8](310/1500); Loss: 0.069737; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0672 0.0601 0.0819 0.0752 0.0678 0.0650 0.0649 0.0630 0.0641 0.0655 0.0683 0.0704 0.0715 0.0743 0.0770 0.0797 

[TRAIN] Epoch[8](311/1500); Loss: 0.120289; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1769 0.1582 0.1390 0.1230 0.1276 0.1288 0.1187 0.1105 0.1063 0.1033 0.1041 0.1032 0.1039 0.1053 0.1067 0.1092 

[TRAIN] Epoch[8](312/1500); Loss: 0.069264; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0822 0.0846 0.0775 0.0690 0.0652 0.0651 0.0649 0.0642 0.0648 0.0646 0.0652 0.0662 0.0674 0.0681 0.0689 0.0703 

[TRAIN] Epoch[8](313/1500); Loss: 0.115038; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1633 0.1483 0.1041 0.1045 0.1134 0.1120 0.1072 0.1047 0.1037 0.1063 0.1075 0.1093 0.1117 0.1131 0.1151 0.1164 

[TRAIN] Epoch[8](314/1500); Loss: 0.142393; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1811 0.1634 0.1696 0.1630 0.1531 0.1454 0.1419 0.1392 0.1320 0.1306 0.1273 0.1260 0.1245 0.1256 0.1269 0.1286 

[TRAIN] Epoch[8](315/1500); Loss: 0.094473; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1674 0.1525 0.0916 0.0925 0.0870 0.0922 0.0907 0.0851 0.0803 0.0804 0.0785 0.0803 0.0814 0.0817 0.0844 0.0857 

[TRAIN] Epoch[8](316/1500); Loss: 0.085597; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1503 0.1394 0.0949 0.0781 0.0769 0.0759 0.0754 0.0760 0.0753 0.0751 0.0763 0.0741 0.0746 0.0754 0.0764 0.0755 

[TRAIN] Epoch[8](317/1500); Loss: 0.123278; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1379 0.1303 0.1288 0.1269 0.1233 0.1215 0.1203 0.1199 0.1195 0.1187 0.1196 0.1198 0.1202 0.1213 0.1217 0.1228 

[TRAIN] Epoch[8](318/1500); Loss: 0.088359; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1037 0.0926 0.1026 0.0982 0.0918 0.0880 0.0843 0.0818 0.0815 0.0816 0.0824 0.0825 0.0845 0.0845 0.0855 0.0882 

[TRAIN] Epoch[8](319/1500); Loss: 0.192012; Backpropagation: 0.0916 sec; Batch: 0.4239 sec
0.2548 0.2306 0.2746 0.2586 0.2396 0.2278 0.2115 0.1951 0.1804 0.1677 0.1573 0.1468 0.1386 0.1337 0.1288 0.1263 

[TRAIN] Epoch[8](320/1500); Loss: 0.120089; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1426 0.1338 0.1416 0.1339 0.1255 0.1207 0.1162 0.1131 0.1107 0.1086 0.1094 0.1113 0.1115 0.1133 0.1144 0.1148 

[TRAIN] Epoch[8](321/1500); Loss: 0.101929; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1238 0.1116 0.1202 0.1131 0.1042 0.1002 0.0957 0.0951 0.0919 0.0938 0.0960 0.0935 0.0959 0.0978 0.0991 0.0990 

[TRAIN] Epoch[8](322/1500); Loss: 0.076885; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1291 0.1040 0.1014 0.0937 0.0797 0.0714 0.0668 0.0625 0.0624 0.0628 0.0630 0.0648 0.0652 0.0661 0.0677 0.0693 

[TRAIN] Epoch[8](323/1500); Loss: 0.116547; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1526 0.1396 0.1487 0.1410 0.1307 0.1242 0.1186 0.1153 0.1096 0.1066 0.1019 0.0999 0.0964 0.0942 0.0928 0.0927 

[TRAIN] Epoch[8](324/1500); Loss: 0.137219; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1415 0.1400 0.1373 0.1358 0.1331 0.1318 0.1335 0.1364 0.1339 0.1362 0.1397 0.1375 0.1367 0.1389 0.1410 0.1423 

[TRAIN] Epoch[8](325/1500); Loss: 0.108332; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2155 0.1932 0.0866 0.1081 0.0868 0.1072 0.1103 0.0982 0.0819 0.0823 0.0777 0.0835 0.1036 0.1029 0.1001 0.0955 

[TRAIN] Epoch[8](326/1500); Loss: 0.194730; Backpropagation: 0.0916 sec; Batch: 0.4239 sec
0.1967 0.1928 0.1956 0.1933 0.1905 0.1889 0.1893 0.1927 0.1921 0.1970 0.1999 0.1954 0.1975 0.1982 0.1972 0.1988 

[TRAIN] Epoch[8](327/1500); Loss: 0.101515; Backpropagation: 0.0922 sec; Batch: 0.4240 sec
0.1288 0.1248 0.1058 0.1001 0.0965 0.0954 0.0961 0.0988 0.0958 0.0969 0.0973 0.0967 0.0966 0.0977 0.0982 0.0987 

[TRAIN] Epoch[8](328/1500); Loss: 0.091023; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1275 0.1070 0.1270 0.1191 0.1057 0.0978 0.0875 0.0782 0.0749 0.0733 0.0738 0.0739 0.0753 0.0778 0.0774 0.0801 

[TRAIN] Epoch[8](329/1500); Loss: 0.182447; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.2695 0.2533 0.2650 0.2545 0.2375 0.2226 0.2053 0.1896 0.1723 0.1537 0.1373 0.1224 0.1109 0.1039 0.1069 0.1144 

[TRAIN] Epoch[8](330/1500); Loss: 0.172546; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2256 0.2143 0.2027 0.1880 0.1788 0.1746 0.1693 0.1642 0.1614 0.1590 0.1555 0.1542 0.1512 0.1512 0.1533 0.1575 

[TRAIN] Epoch[8](331/1500); Loss: 0.131461; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2145 0.1990 0.1797 0.1637 0.1525 0.1441 0.1343 0.1260 0.1169 0.1098 0.1012 0.0959 0.0913 0.0913 0.0911 0.0920 

[TRAIN] Epoch[8](332/1500); Loss: 0.119746; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1330 0.1292 0.1318 0.1287 0.1247 0.1210 0.1204 0.1174 0.1150 0.1137 0.1126 0.1120 0.1124 0.1132 0.1149 0.1158 

[TRAIN] Epoch[8](333/1500); Loss: 0.099455; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1178 0.1084 0.1128 0.1062 0.1007 0.0957 0.0951 0.0967 0.0938 0.0926 0.0918 0.0922 0.0936 0.0967 0.0994 0.0978 

[TRAIN] Epoch[8](334/1500); Loss: 0.113940; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1227 0.1214 0.1144 0.1152 0.1115 0.1116 0.1115 0.1126 0.1118 0.1131 0.1116 0.1122 0.1124 0.1133 0.1133 0.1144 

[TRAIN] Epoch[8](335/1500); Loss: 0.208993; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2547 0.2335 0.2286 0.2244 0.2170 0.2111 0.2064 0.2027 0.1988 0.1971 0.1975 0.1960 0.1954 0.1943 0.1922 0.1941 

[TRAIN] Epoch[8](336/1500); Loss: 0.149081; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.2125 0.1877 0.2036 0.1891 0.1766 0.1660 0.1512 0.1382 0.1280 0.1210 0.1171 0.1156 0.1178 0.1176 0.1196 0.1237 

[TRAIN] Epoch[8](337/1500); Loss: 0.159612; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1731 0.1673 0.1627 0.1613 0.1586 0.1576 0.1589 0.1608 0.1568 0.1582 0.1574 0.1562 0.1563 0.1571 0.1554 0.1561 

[TRAIN] Epoch[8](338/1500); Loss: 0.128042; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1615 0.1456 0.1501 0.1435 0.1315 0.1241 0.1210 0.1217 0.1176 0.1200 0.1168 0.1194 0.1156 0.1191 0.1193 0.1219 

[TRAIN] Epoch[8](339/1500); Loss: 0.186033; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2380 0.2229 0.2421 0.2311 0.2179 0.2078 0.1969 0.1863 0.1765 0.1647 0.1578 0.1521 0.1471 0.1459 0.1456 0.1440 

[TRAIN] Epoch[8](340/1500); Loss: 0.103369; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1380 0.1217 0.1205 0.1124 0.1029 0.0987 0.0985 0.0964 0.0983 0.0964 0.0960 0.0944 0.0947 0.0946 0.0954 0.0950 

[TRAIN] Epoch[8](341/1500); Loss: 0.110963; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1254 0.1168 0.1185 0.0992 0.1206 0.1157 0.1075 0.0995 0.0967 0.0964 0.1032 0.1108 0.1160 0.1137 0.1171 0.1184 

[TRAIN] Epoch[8](342/1500); Loss: 0.106685; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1134 0.1027 0.1288 0.1163 0.1138 0.1094 0.1039 0.1020 0.0973 0.0990 0.1015 0.1015 0.1017 0.1041 0.1062 0.1054 

[TRAIN] Epoch[8](343/1500); Loss: 0.170042; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2231 0.2073 0.2035 0.1980 0.1879 0.1798 0.1707 0.1650 0.1596 0.1542 0.1501 0.1463 0.1439 0.1430 0.1442 0.1442 

[TRAIN] Epoch[8](344/1500); Loss: 0.110275; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1610 0.1486 0.1334 0.1182 0.1193 0.1150 0.1086 0.1037 0.1001 0.0979 0.0952 0.0932 0.0922 0.0914 0.0924 0.0943 

[TRAIN] Epoch[8](345/1500); Loss: 0.136010; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1986 0.1867 0.1519 0.1315 0.1261 0.1269 0.1275 0.1278 0.1261 0.1262 0.1239 0.1243 0.1235 0.1247 0.1251 0.1253 

[TRAIN] Epoch[8](346/1500); Loss: 0.097240; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1274 0.1081 0.1159 0.1077 0.0971 0.0900 0.0862 0.0873 0.0897 0.0890 0.0902 0.0910 0.0920 0.0932 0.0943 0.0966 

[TRAIN] Epoch[8](347/1500); Loss: 0.169226; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.2254 0.2048 0.2150 0.2022 0.1954 0.1869 0.1748 0.1642 0.1562 0.1491 0.1445 0.1376 0.1362 0.1375 0.1385 0.1395 

[TRAIN] Epoch[8](348/1500); Loss: 0.139800; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1527 0.1489 0.1456 0.1428 0.1399 0.1386 0.1364 0.1367 0.1377 0.1370 0.1356 0.1360 0.1366 0.1365 0.1376 0.1382 

[TRAIN] Epoch[8](349/1500); Loss: 0.071188; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0706 0.0765 0.0703 0.0650 0.0706 0.0702 0.0677 0.0680 0.0685 0.0690 0.0699 0.0713 0.0727 0.0738 0.0759 0.0789 

[TRAIN] Epoch[8](350/1500); Loss: 0.070621; Backpropagation: 0.0915 sec; Batch: 0.4234 sec
0.1927 0.1683 0.0617 0.0631 0.0517 0.0631 0.0581 0.0475 0.0406 0.0447 0.0572 0.0563 0.0533 0.0516 0.0541 0.0659 

[TRAIN] Epoch[8](351/1500); Loss: 0.158853; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1811 0.1682 0.1621 0.1508 0.1600 0.1545 0.1486 0.1450 0.1451 0.1484 0.1545 0.1597 0.1643 0.1646 0.1676 0.1671 

[TRAIN] Epoch[8](352/1500); Loss: 0.076927; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1183 0.1009 0.1043 0.0971 0.0846 0.0758 0.0695 0.0636 0.0612 0.0602 0.0615 0.0631 0.0635 0.0675 0.0692 0.0705 

[TRAIN] Epoch[8](353/1500); Loss: 0.259846; Backpropagation: 0.0920 sec; Batch: 0.4230 sec
0.4613 0.4100 0.4549 0.4281 0.3855 0.3478 0.3031 0.2563 0.2100 0.1652 0.1285 0.1098 0.1138 0.1336 0.1232 0.1265 

[TRAIN] Epoch[8](354/1500); Loss: 0.123525; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.1319 0.1293 0.1301 0.1281 0.1257 0.1236 0.1195 0.1214 0.1199 0.1189 0.1202 0.1190 0.1202 0.1206 0.1229 0.1250 

[TRAIN] Epoch[8](355/1500); Loss: 0.100301; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1256 0.1187 0.1213 0.1160 0.1071 0.1007 0.0944 0.0920 0.0903 0.0901 0.0890 0.0908 0.0913 0.0911 0.0925 0.0936 

[TRAIN] Epoch[8](356/1500); Loss: 0.185907; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2024 0.1936 0.1995 0.1957 0.1910 0.1886 0.1858 0.1844 0.1822 0.1804 0.1794 0.1808 0.1794 0.1767 0.1774 0.1771 

[TRAIN] Epoch[8](357/1500); Loss: 0.090655; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1371 0.1277 0.1175 0.1082 0.1011 0.0962 0.0891 0.0847 0.0785 0.0757 0.0738 0.0742 0.0706 0.0718 0.0716 0.0727 

[TRAIN] Epoch[8](358/1500); Loss: 0.162684; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2232 0.1990 0.2150 0.2058 0.1912 0.1792 0.1667 0.1551 0.1462 0.1409 0.1330 0.1280 0.1295 0.1287 0.1305 0.1309 

[TRAIN] Epoch[8](359/1500); Loss: 0.255996; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.4656 0.4123 0.4594 0.4318 0.3875 0.3480 0.3016 0.2522 0.2041 0.1573 0.1185 0.0996 0.1041 0.1247 0.1127 0.1166 

[TRAIN] Epoch[8](360/1500); Loss: 0.167786; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1921 0.1867 0.1603 0.1685 0.1621 0.1661 0.1656 0.1667 0.1623 0.1644 0.1653 0.1661 0.1651 0.1629 0.1644 0.1658 

[TRAIN] Epoch[8](361/1500); Loss: 0.096058; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0987 0.0983 0.0970 0.0963 0.0926 0.0924 0.0921 0.0931 0.0929 0.0944 0.0948 0.0960 0.0972 0.0989 0.1003 0.1020 

[TRAIN] Epoch[8](362/1500); Loss: 0.072095; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.0813 0.0679 0.0842 0.0777 0.0694 0.0656 0.0677 0.0649 0.0643 0.0661 0.0684 0.0700 0.0722 0.0746 0.0790 0.0804 

[TRAIN] Epoch[8](363/1500); Loss: 0.130036; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1340 0.1352 0.1356 0.1323 0.1299 0.1291 0.1242 0.1263 0.1294 0.1320 0.1266 0.1293 0.1290 0.1317 0.1286 0.1273 

[TRAIN] Epoch[8](364/1500); Loss: 0.157012; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.1750 0.1631 0.1834 0.1744 0.1642 0.1573 0.1511 0.1468 0.1437 0.1427 0.1446 0.1469 0.1486 0.1528 0.1574 0.1603 

[TRAIN] Epoch[8](365/1500); Loss: 0.173666; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1946 0.1843 0.1729 0.1711 0.1676 0.1686 0.1688 0.1710 0.1692 0.1744 0.1738 0.1748 0.1747 0.1715 0.1698 0.1718 

[TRAIN] Epoch[8](366/1500); Loss: 0.172233; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2955 0.2548 0.3035 0.2805 0.2477 0.2204 0.1883 0.1563 0.1287 0.1089 0.0955 0.0933 0.0968 0.0956 0.0943 0.0957 

[TRAIN] Epoch[8](367/1500); Loss: 0.072706; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0755 0.0658 0.0804 0.0751 0.0665 0.0641 0.0648 0.0657 0.0648 0.0687 0.0719 0.0744 0.0759 0.0804 0.0828 0.0864 

[TRAIN] Epoch[8](368/1500); Loss: 0.144815; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1658 0.1533 0.1642 0.1565 0.1513 0.1457 0.1410 0.1391 0.1383 0.1374 0.1378 0.1360 0.1361 0.1378 0.1380 0.1388 

[TRAIN] Epoch[8](369/1500); Loss: 0.137959; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1602 0.1521 0.1483 0.1448 0.1413 0.1377 0.1344 0.1353 0.1345 0.1335 0.1325 0.1319 0.1306 0.1303 0.1294 0.1306 

[TRAIN] Epoch[8](370/1500); Loss: 0.154712; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1643 0.1628 0.1555 0.1573 0.1564 0.1567 0.1530 0.1535 0.1507 0.1520 0.1494 0.1514 0.1507 0.1530 0.1530 0.1556 

[TRAIN] Epoch[8](371/1500); Loss: 0.160103; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1721 0.1677 0.1624 0.1625 0.1616 0.1620 0.1581 0.1586 0.1567 0.1570 0.1556 0.1567 0.1561 0.1578 0.1576 0.1593 

[TRAIN] Epoch[8](372/1500); Loss: 0.111266; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1514 0.1368 0.1308 0.1212 0.1142 0.1103 0.1076 0.1056 0.1017 0.0993 0.0983 0.1001 0.0993 0.1002 0.1012 0.1025 

[TRAIN] Epoch[8](373/1500); Loss: 0.122283; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1608 0.1448 0.1454 0.1371 0.1284 0.1215 0.1174 0.1154 0.1151 0.1117 0.1115 0.1101 0.1094 0.1094 0.1095 0.1090 

[TRAIN] Epoch[8](374/1500); Loss: 0.150169; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1646 0.1545 0.1506 0.1498 0.1487 0.1493 0.1471 0.1491 0.1473 0.1474 0.1467 0.1475 0.1480 0.1490 0.1503 0.1527 

[TRAIN] Epoch[8](375/1500); Loss: 0.083092; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1672 0.1420 0.0574 0.0507 0.0740 0.0582 0.0494 0.0479 0.0592 0.0909 0.0919 0.0849 0.0819 0.0855 0.0895 0.0988 

[TRAIN] Epoch[8](376/1500); Loss: 0.260275; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3974 0.3568 0.3760 0.3579 0.3259 0.2948 0.2606 0.2250 0.1983 0.1882 0.1926 0.2044 0.1952 0.1986 0.1932 0.1995 

[TRAIN] Epoch[8](377/1500); Loss: 0.077523; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.0793 0.0775 0.0853 0.0807 0.0758 0.0759 0.0759 0.0708 0.0735 0.0750 0.0768 0.0751 0.0779 0.0790 0.0803 0.0814 

[TRAIN] Epoch[8](378/1500); Loss: 0.169106; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2208 0.2065 0.2150 0.2077 0.1970 0.1894 0.1798 0.1703 0.1560 0.1492 0.1418 0.1362 0.1335 0.1332 0.1336 0.1357 

[TRAIN] Epoch[8](379/1500); Loss: 0.115992; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1336 0.1236 0.1302 0.1257 0.1189 0.1137 0.1110 0.1124 0.1132 0.1092 0.1106 0.1103 0.1106 0.1099 0.1114 0.1116 

[TRAIN] Epoch[8](380/1500); Loss: 0.110929; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1362 0.1196 0.1361 0.1288 0.1167 0.1072 0.1033 0.1035 0.1032 0.1000 0.1000 0.1027 0.1037 0.1027 0.1043 0.1067 

[TRAIN] Epoch[8](381/1500); Loss: 0.148133; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1936 0.1827 0.1668 0.1635 0.1575 0.1540 0.1497 0.1473 0.1420 0.1386 0.1345 0.1311 0.1273 0.1272 0.1268 0.1277 

[TRAIN] Epoch[8](382/1500); Loss: 0.158522; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2327 0.2049 0.2361 0.2200 0.1992 0.1815 0.1610 0.1423 0.1274 0.1176 0.1155 0.1160 0.1157 0.1188 0.1221 0.1256 

[TRAIN] Epoch[8](383/1500); Loss: 0.160327; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1870 0.1787 0.1725 0.1665 0.1613 0.1583 0.1561 0.1552 0.1556 0.1545 0.1527 0.1514 0.1522 0.1533 0.1539 0.1561 

[TRAIN] Epoch[8](384/1500); Loss: 0.168238; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1832 0.1792 0.1827 0.1789 0.1739 0.1714 0.1681 0.1655 0.1644 0.1612 0.1598 0.1601 0.1598 0.1602 0.1612 0.1621 

[TRAIN] Epoch[8](385/1500); Loss: 0.116925; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1360 0.1271 0.1253 0.1206 0.1170 0.1123 0.1099 0.1106 0.1142 0.1090 0.1118 0.1138 0.1159 0.1132 0.1162 0.1181 

[TRAIN] Epoch[8](386/1500); Loss: 0.173228; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.3177 0.2797 0.3160 0.2942 0.2629 0.2322 0.1983 0.1650 0.1303 0.1029 0.0865 0.0756 0.0716 0.0765 0.0833 0.0790 

[TRAIN] Epoch[8](387/1500); Loss: 0.161215; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1766 0.1709 0.1686 0.1670 0.1624 0.1607 0.1594 0.1598 0.1571 0.1562 0.1569 0.1558 0.1562 0.1560 0.1574 0.1585 

[TRAIN] Epoch[8](388/1500); Loss: 0.123693; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1445 0.1359 0.1303 0.1258 0.1233 0.1206 0.1205 0.1164 0.1194 0.1177 0.1202 0.1162 0.1183 0.1216 0.1248 0.1236 

[TRAIN] Epoch[8](389/1500); Loss: 0.119129; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1651 0.1522 0.1218 0.1204 0.1128 0.1119 0.1100 0.1109 0.1111 0.1099 0.1110 0.1111 0.1107 0.1133 0.1161 0.1177 

[TRAIN] Epoch[8](390/1500); Loss: 0.106099; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1320 0.1182 0.1326 0.1250 0.1130 0.1038 0.0975 0.0963 0.0950 0.0950 0.0955 0.0970 0.0971 0.0975 0.1006 0.1014 

[TRAIN] Epoch[8](391/1500); Loss: 0.141087; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1754 0.1598 0.1730 0.1642 0.1552 0.1478 0.1420 0.1323 0.1281 0.1256 0.1238 0.1245 0.1269 0.1259 0.1256 0.1276 

[TRAIN] Epoch[8](392/1500); Loss: 0.120426; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1494 0.1365 0.1331 0.1292 0.1238 0.1204 0.1169 0.1163 0.1139 0.1121 0.1120 0.1123 0.1115 0.1121 0.1131 0.1141 

[TRAIN] Epoch[8](393/1500); Loss: 0.161898; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2209 0.2085 0.1965 0.1784 0.1718 0.1656 0.1618 0.1587 0.1549 0.1498 0.1465 0.1415 0.1372 0.1337 0.1322 0.1325 

[TRAIN] Epoch[8](394/1500); Loss: 0.098951; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1503 0.1243 0.1327 0.1205 0.1037 0.0891 0.0824 0.0811 0.0848 0.0843 0.0850 0.0860 0.0871 0.0890 0.0894 0.0933 

[TRAIN] Epoch[8](395/1500); Loss: 0.106946; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1261 0.1124 0.1216 0.1132 0.1069 0.1026 0.1042 0.1014 0.1001 0.1001 0.0998 0.1014 0.1024 0.1040 0.1060 0.1087 

[TRAIN] Epoch[8](396/1500); Loss: 0.078113; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.0992 0.0871 0.0956 0.0896 0.0797 0.0728 0.0740 0.0718 0.0718 0.0695 0.0713 0.0711 0.0722 0.0728 0.0752 0.0760 

[TRAIN] Epoch[8](397/1500); Loss: 0.056653; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.0856 0.0682 0.0765 0.0670 0.0559 0.0483 0.0469 0.0472 0.0466 0.0467 0.0486 0.0503 0.0515 0.0534 0.0546 0.0591 

[TRAIN] Epoch[8](398/1500); Loss: 0.117051; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1880 0.1726 0.1313 0.1147 0.1101 0.1079 0.1062 0.1059 0.1046 0.1037 0.1045 0.1045 0.1043 0.1038 0.1052 0.1056 

[TRAIN] Epoch[8](399/1500); Loss: 0.108948; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1092 0.1019 0.1303 0.1115 0.1178 0.1124 0.1061 0.1006 0.0965 0.0974 0.1022 0.1074 0.1094 0.1115 0.1134 0.1154 

[TRAIN] Epoch[8](400/1500); Loss: 0.078728; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0876 0.0836 0.0770 0.0722 0.0737 0.0734 0.0720 0.0714 0.0757 0.0771 0.0802 0.0799 0.0825 0.0820 0.0857 0.0855 

[TRAIN] Epoch[8](401/1500); Loss: 0.109293; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1325 0.1177 0.1327 0.1264 0.1142 0.1040 0.0980 0.0917 0.0938 0.0970 0.0978 0.1012 0.1053 0.1091 0.1122 0.1149 

[TRAIN] Epoch[8](402/1500); Loss: 0.181734; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2359 0.2206 0.2304 0.2223 0.2113 0.1992 0.1881 0.1787 0.1692 0.1614 0.1558 0.1505 0.1466 0.1451 0.1458 0.1467 

[TRAIN] Epoch[8](403/1500); Loss: 0.131724; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1583 0.1439 0.1491 0.1434 0.1355 0.1309 0.1255 0.1254 0.1223 0.1236 0.1224 0.1238 0.1238 0.1251 0.1266 0.1281 

[TRAIN] Epoch[8](404/1500); Loss: 0.084794; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0980 0.0965 0.0874 0.0842 0.0790 0.0800 0.0798 0.0806 0.0807 0.0821 0.0816 0.0831 0.0838 0.0857 0.0862 0.0879 

[TRAIN] Epoch[8](405/1500); Loss: 0.141295; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2077 0.1854 0.1890 0.1784 0.1611 0.1433 0.1299 0.1227 0.1181 0.1159 0.1157 0.1156 0.1176 0.1187 0.1199 0.1217 

[TRAIN] Epoch[8](406/1500); Loss: 0.094029; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1388 0.1143 0.1330 0.1207 0.1037 0.0913 0.0848 0.0792 0.0773 0.0778 0.0790 0.0781 0.0800 0.0804 0.0825 0.0839 

[TRAIN] Epoch[8](407/1500); Loss: 0.181245; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.2294 0.2120 0.2437 0.2270 0.2159 0.2038 0.1903 0.1792 0.1709 0.1620 0.1569 0.1505 0.1460 0.1394 0.1365 0.1366 

[TRAIN] Epoch[8](408/1500); Loss: 0.067767; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1108 0.0871 0.0972 0.0864 0.0743 0.0660 0.0584 0.0545 0.0536 0.0538 0.0538 0.0552 0.0546 0.0587 0.0586 0.0612 

[TRAIN] Epoch[8](409/1500); Loss: 0.092661; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1030 0.0937 0.1156 0.1091 0.0996 0.0929 0.0883 0.0840 0.0834 0.0826 0.0832 0.0857 0.0880 0.0888 0.0906 0.0940 

[TRAIN] Epoch[8](410/1500); Loss: 0.143261; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1685 0.1642 0.1605 0.1580 0.1539 0.1520 0.1435 0.1420 0.1387 0.1369 0.1310 0.1293 0.1273 0.1286 0.1279 0.1300 

[TRAIN] Epoch[8](411/1500); Loss: 0.126308; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1553 0.1454 0.1400 0.1375 0.1304 0.1260 0.1236 0.1214 0.1183 0.1182 0.1167 0.1168 0.1163 0.1175 0.1184 0.1191 

[TRAIN] Epoch[8](412/1500); Loss: 0.096412; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1167 0.1060 0.1107 0.1055 0.0975 0.0934 0.0935 0.0905 0.0912 0.0905 0.0896 0.0901 0.0918 0.0908 0.0920 0.0929 

[TRAIN] Epoch[8](413/1500); Loss: 0.113517; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2093 0.1837 0.1943 0.1794 0.1572 0.1327 0.1095 0.0893 0.0741 0.0662 0.0649 0.0673 0.0692 0.0701 0.0745 0.0746 

[TRAIN] Epoch[8](414/1500); Loss: 0.087273; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1283 0.1192 0.0902 0.0818 0.0803 0.0796 0.0800 0.0828 0.0806 0.0814 0.0803 0.0826 0.0808 0.0817 0.0827 0.0840 

[TRAIN] Epoch[8](415/1500); Loss: 0.088285; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1122 0.1014 0.1008 0.0981 0.0908 0.0890 0.0851 0.0869 0.0824 0.0820 0.0790 0.0802 0.0790 0.0806 0.0814 0.0837 

[TRAIN] Epoch[8](416/1500); Loss: 0.147618; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2249 0.2039 0.2032 0.1841 0.1722 0.1602 0.1451 0.1322 0.1223 0.1159 0.1116 0.1134 0.1155 0.1173 0.1184 0.1217 

[TRAIN] Epoch[8](417/1500); Loss: 0.130152; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.2001 0.1708 0.1787 0.1652 0.1535 0.1391 0.1252 0.1162 0.1079 0.1045 0.1024 0.1030 0.1024 0.1031 0.1045 0.1059 

[TRAIN] Epoch[8](418/1500); Loss: 0.062259; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1072 0.0834 0.1026 0.0892 0.0724 0.0606 0.0503 0.0430 0.0449 0.0452 0.0431 0.0463 0.0489 0.0530 0.0518 0.0543 

[TRAIN] Epoch[8](419/1500); Loss: 0.088913; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1162 0.0989 0.1107 0.1028 0.0908 0.0844 0.0837 0.0816 0.0810 0.0815 0.0818 0.0808 0.0817 0.0824 0.0820 0.0823 

[TRAIN] Epoch[8](420/1500); Loss: 0.067402; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.0941 0.0802 0.0854 0.0792 0.0727 0.0673 0.0637 0.0618 0.0575 0.0584 0.0578 0.0579 0.0587 0.0595 0.0613 0.0629 

[TRAIN] Epoch[8](421/1500); Loss: 0.125559; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1875 0.1611 0.1868 0.1711 0.1511 0.1327 0.1174 0.1079 0.1006 0.0976 0.0977 0.0974 0.0990 0.0997 0.1007 0.1007 

[TRAIN] Epoch[8](422/1500); Loss: 0.173620; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2474 0.2193 0.2256 0.2145 0.1971 0.1810 0.1666 0.1565 0.1498 0.1446 0.1441 0.1451 0.1455 0.1458 0.1471 0.1477 

[TRAIN] Epoch[8](423/1500); Loss: 0.072204; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1663 0.1456 0.0678 0.0717 0.0653 0.0737 0.0675 0.0563 0.0485 0.0497 0.0519 0.0523 0.0575 0.0577 0.0625 0.0610 

[TRAIN] Epoch[8](424/1500); Loss: 0.163223; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2141 0.1967 0.1826 0.1785 0.1727 0.1670 0.1611 0.1577 0.1526 0.1479 0.1471 0.1472 0.1462 0.1458 0.1469 0.1475 

[TRAIN] Epoch[8](425/1500); Loss: 0.183581; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.3280 0.2869 0.3256 0.3027 0.2723 0.2407 0.2072 0.1772 0.1453 0.1174 0.0960 0.0841 0.0824 0.0891 0.0920 0.0905 

[TRAIN] Epoch[8](426/1500); Loss: 0.143706; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1817 0.1702 0.1716 0.1656 0.1569 0.1471 0.1409 0.1361 0.1331 0.1302 0.1298 0.1268 0.1268 0.1269 0.1284 0.1271 

[TRAIN] Epoch[8](427/1500); Loss: 0.097037; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.1047 0.0977 0.0969 0.0952 0.0922 0.0935 0.0953 0.0944 0.0957 0.0952 0.0962 0.0965 0.0978 0.0992 0.1004 0.1018 

[TRAIN] Epoch[8](428/1500); Loss: 0.114669; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1581 0.1370 0.1486 0.1411 0.1288 0.1166 0.1067 0.1005 0.0979 0.0969 0.0960 0.0968 0.0994 0.1008 0.1035 0.1060 

[TRAIN] Epoch[8](429/1500); Loss: 0.133761; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.1991 0.1819 0.1614 0.1491 0.1429 0.1373 0.1310 0.1262 0.1216 0.1162 0.1129 0.1118 0.1115 0.1122 0.1118 0.1135 

[TRAIN] Epoch[8](430/1500); Loss: 0.091591; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1435 0.1189 0.1239 0.1130 0.0988 0.0859 0.0775 0.0737 0.0763 0.0760 0.0776 0.0771 0.0794 0.0797 0.0812 0.0830 

[TRAIN] Epoch[8](431/1500); Loss: 0.161551; Backpropagation: 0.0916 sec; Batch: 0.4236 sec
0.2276 0.2020 0.2123 0.2006 0.1830 0.1656 0.1517 0.1415 0.1352 0.1370 0.1373 0.1366 0.1367 0.1381 0.1402 0.1394 

[TRAIN] Epoch[8](432/1500); Loss: 0.093149; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1416 0.1199 0.1270 0.1133 0.1003 0.0874 0.0800 0.0769 0.0783 0.0787 0.0794 0.0793 0.0806 0.0819 0.0821 0.0837 

[TRAIN] Epoch[8](433/1500); Loss: 0.105515; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1209 0.1096 0.1218 0.1151 0.1081 0.1041 0.1025 0.1033 0.1058 0.1014 0.0999 0.0996 0.1000 0.0986 0.0985 0.0991 

[TRAIN] Epoch[8](434/1500); Loss: 0.077197; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.0871 0.0675 0.0689 0.0659 0.0703 0.0690 0.0749 0.0723 0.0757 0.0755 0.0787 0.0796 0.0833 0.0855 0.0892 0.0916 

[TRAIN] Epoch[8](435/1500); Loss: 0.091164; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1229 0.1118 0.1077 0.1048 0.0947 0.0893 0.0832 0.0835 0.0810 0.0826 0.0808 0.0811 0.0849 0.0819 0.0835 0.0850 

[TRAIN] Epoch[8](436/1500); Loss: 0.076530; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0985 0.0935 0.0795 0.0741 0.0777 0.0744 0.0714 0.0710 0.0701 0.0713 0.0712 0.0736 0.0724 0.0739 0.0743 0.0776 

[TRAIN] Epoch[8](437/1500); Loss: 0.077978; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1605 0.1170 0.1467 0.1240 0.0928 0.0631 0.0467 0.0494 0.0532 0.0506 0.0508 0.0557 0.0588 0.0576 0.0582 0.0627 

[TRAIN] Epoch[8](438/1500); Loss: 0.189932; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.2594 0.2415 0.2511 0.2411 0.2279 0.2136 0.2000 0.1884 0.1770 0.1660 0.1577 0.1501 0.1435 0.1401 0.1395 0.1419 

[TRAIN] Epoch[8](439/1500); Loss: 0.101999; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1654 0.1526 0.1091 0.0997 0.0918 0.0937 0.0916 0.0897 0.0914 0.0902 0.0903 0.0906 0.0923 0.0936 0.0947 0.0952 

[TRAIN] Epoch[8](440/1500); Loss: 0.062162; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1224 0.1086 0.0631 0.0538 0.0534 0.0523 0.0509 0.0513 0.0519 0.0516 0.0528 0.0543 0.0547 0.0564 0.0578 0.0593 

[TRAIN] Epoch[8](441/1500); Loss: 0.150350; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1823 0.1691 0.1790 0.1707 0.1613 0.1530 0.1465 0.1425 0.1403 0.1401 0.1357 0.1358 0.1367 0.1367 0.1381 0.1377 

[TRAIN] Epoch[8](442/1500); Loss: 0.154934; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1652 0.1638 0.1604 0.1585 0.1563 0.1557 0.1540 0.1536 0.1535 0.1517 0.1517 0.1514 0.1506 0.1503 0.1505 0.1517 

[TRAIN] Epoch[8](443/1500); Loss: 0.249869; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2904 0.2793 0.2882 0.2817 0.2729 0.2636 0.2565 0.2505 0.2440 0.2378 0.2344 0.2248 0.2223 0.2195 0.2172 0.2150 

[TRAIN] Epoch[8](444/1500); Loss: 0.146481; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1704 0.1608 0.1454 0.1397 0.1475 0.1441 0.1404 0.1401 0.1421 0.1425 0.1447 0.1441 0.1431 0.1451 0.1473 0.1465 

[TRAIN] Epoch[8](445/1500); Loss: 0.135571; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1479 0.1425 0.1387 0.1373 0.1349 0.1337 0.1320 0.1318 0.1323 0.1324 0.1328 0.1333 0.1336 0.1343 0.1353 0.1364 

[TRAIN] Epoch[8](446/1500); Loss: 0.157585; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1649 0.1609 0.1551 0.1553 0.1555 0.1573 0.1558 0.1579 0.1558 0.1571 0.1563 0.1578 0.1565 0.1572 0.1583 0.1596 

[TRAIN] Epoch[8](447/1500); Loss: 0.179250; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2327 0.2178 0.2102 0.2005 0.1923 0.1837 0.1761 0.1705 0.1666 0.1618 0.1622 0.1590 0.1589 0.1580 0.1598 0.1581 

[TRAIN] Epoch[8](448/1500); Loss: 0.092945; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1212 0.1060 0.1080 0.1020 0.0952 0.0905 0.0888 0.0873 0.0870 0.0854 0.0858 0.0854 0.0856 0.0858 0.0865 0.0868 

[TRAIN] Epoch[8](449/1500); Loss: 0.148594; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1710 0.1671 0.1598 0.1576 0.1537 0.1515 0.1475 0.1465 0.1434 0.1418 0.1409 0.1401 0.1393 0.1393 0.1385 0.1396 

[TRAIN] Epoch[8](450/1500); Loss: 0.077647; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.0943 0.0818 0.0900 0.0857 0.0807 0.0778 0.0719 0.0718 0.0704 0.0707 0.0713 0.0731 0.0743 0.0744 0.0761 0.0782 

[TRAIN] Epoch[8](451/1500); Loss: 0.074281; Backpropagation: 0.0917 sec; Batch: 0.4395 sec
0.1034 0.0890 0.0908 0.0825 0.0777 0.0721 0.0654 0.0628 0.0621 0.0628 0.0657 0.0685 0.0678 0.0698 0.0718 0.0765 

[TRAIN] Epoch[8](452/1500); Loss: 0.131980; Backpropagation: 0.0917 sec; Batch: 0.4331 sec
0.1421 0.1402 0.1425 0.1390 0.1342 0.1318 0.1275 0.1263 0.1267 0.1280 0.1274 0.1293 0.1285 0.1277 0.1289 0.1315 

[TRAIN] Epoch[8](453/1500); Loss: 0.129824; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1930 0.1811 0.1368 0.1206 0.1189 0.1190 0.1191 0.1202 0.1209 0.1194 0.1203 0.1202 0.1226 0.1203 0.1224 0.1223 

[TRAIN] Epoch[8](454/1500); Loss: 0.097962; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1462 0.1285 0.1096 0.1061 0.1004 0.0918 0.0847 0.0808 0.0801 0.0823 0.0847 0.0878 0.0907 0.0927 0.0969 0.1039 

[TRAIN] Epoch[8](455/1500); Loss: 0.127762; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1277 0.1313 0.1290 0.1286 0.1290 0.1294 0.1269 0.1286 0.1252 0.1284 0.1250 0.1263 0.1255 0.1284 0.1272 0.1276 

[TRAIN] Epoch[8](456/1500); Loss: 0.086979; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1210 0.1105 0.0922 0.0875 0.0839 0.0817 0.0792 0.0791 0.0800 0.0800 0.0795 0.0805 0.0819 0.0840 0.0845 0.0864 

[TRAIN] Epoch[8](457/1500); Loss: 0.095128; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1208 0.1153 0.0995 0.0960 0.0919 0.0923 0.0919 0.0924 0.0899 0.0905 0.0892 0.0905 0.0885 0.0901 0.0904 0.0928 

[TRAIN] Epoch[8](458/1500); Loss: 0.090898; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1937 0.1518 0.1803 0.1585 0.1267 0.0948 0.0685 0.0517 0.0472 0.0524 0.0534 0.0514 0.0511 0.0560 0.0587 0.0583 

[TRAIN] Epoch[8](459/1500); Loss: 0.108475; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1375 0.1219 0.1429 0.1295 0.1174 0.1065 0.0984 0.0946 0.0952 0.0961 0.0966 0.0980 0.0984 0.0989 0.1010 0.1028 

[TRAIN] Epoch[8](460/1500); Loss: 0.138551; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1712 0.1587 0.1494 0.1436 0.1412 0.1372 0.1326 0.1298 0.1278 0.1278 0.1289 0.1309 0.1315 0.1340 0.1358 0.1364 

[TRAIN] Epoch[8](461/1500); Loss: 0.173995; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1857 0.1824 0.1796 0.1791 0.1758 0.1727 0.1711 0.1728 0.1718 0.1732 0.1746 0.1700 0.1698 0.1697 0.1682 0.1675 

[TRAIN] Epoch[8](462/1500); Loss: 0.130069; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1461 0.1434 0.1358 0.1351 0.1305 0.1300 0.1287 0.1278 0.1260 0.1265 0.1239 0.1248 0.1255 0.1267 0.1246 0.1257 

[TRAIN] Epoch[8](463/1500); Loss: 0.161377; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1946 0.1807 0.1709 0.1676 0.1613 0.1574 0.1561 0.1559 0.1545 0.1545 0.1549 0.1553 0.1544 0.1546 0.1550 0.1544 

[TRAIN] Epoch[8](464/1500); Loss: 0.133796; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1785 0.1635 0.1767 0.1683 0.1559 0.1448 0.1351 0.1283 0.1215 0.1166 0.1123 0.1090 0.1078 0.1077 0.1068 0.1080 

[TRAIN] Epoch[8](465/1500); Loss: 0.144972; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1794 0.1740 0.1479 0.1440 0.1389 0.1393 0.1393 0.1429 0.1367 0.1387 0.1395 0.1428 0.1368 0.1391 0.1396 0.1406 

[TRAIN] Epoch[8](466/1500); Loss: 0.107258; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1384 0.1286 0.1244 0.1198 0.1127 0.1059 0.1016 0.0988 0.0968 0.0980 0.0970 0.0973 0.0990 0.0987 0.0987 0.1005 

[TRAIN] Epoch[8](467/1500); Loss: 0.131853; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1856 0.1665 0.1697 0.1575 0.1526 0.1427 0.1317 0.1235 0.1184 0.1159 0.1126 0.1091 0.1064 0.1047 0.1048 0.1080 

[TRAIN] Epoch[8](468/1500); Loss: 0.068136; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.0773 0.0676 0.0789 0.0739 0.0656 0.0663 0.0579 0.0616 0.0613 0.0652 0.0638 0.0665 0.0694 0.0702 0.0713 0.0736 

[TRAIN] Epoch[8](469/1500); Loss: 0.117411; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1395 0.1276 0.1298 0.1245 0.1223 0.1140 0.1076 0.1040 0.1047 0.1054 0.1092 0.1118 0.1148 0.1171 0.1214 0.1250 

[TRAIN] Epoch[8](470/1500); Loss: 0.147592; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2169 0.1899 0.2086 0.1931 0.1814 0.1662 0.1507 0.1386 0.1271 0.1195 0.1147 0.1110 0.1125 0.1099 0.1116 0.1096 

[TRAIN] Epoch[8](471/1500); Loss: 0.115485; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1344 0.1278 0.1277 0.1250 0.1203 0.1174 0.1138 0.1128 0.1106 0.1103 0.1081 0.1085 0.1075 0.1081 0.1073 0.1083 

[TRAIN] Epoch[8](472/1500); Loss: 0.177792; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2223 0.2079 0.1968 0.1889 0.1812 0.1757 0.1727 0.1719 0.1703 0.1677 0.1681 0.1656 0.1654 0.1641 0.1639 0.1622 

[TRAIN] Epoch[8](473/1500); Loss: 0.095213; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1372 0.1065 0.1530 0.1408 0.1227 0.1069 0.0955 0.0830 0.0730 0.0685 0.0671 0.0693 0.0738 0.0739 0.0756 0.0766 

[TRAIN] Epoch[8](474/1500); Loss: 0.137185; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1582 0.1553 0.1486 0.1468 0.1420 0.1394 0.1352 0.1342 0.1315 0.1311 0.1302 0.1297 0.1272 0.1283 0.1281 0.1293 

[TRAIN] Epoch[8](475/1500); Loss: 0.203396; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.3415 0.2952 0.3105 0.2890 0.2550 0.2186 0.1879 0.1641 0.1483 0.1379 0.1410 0.1464 0.1499 0.1532 0.1584 0.1573 

[TRAIN] Epoch[8](476/1500); Loss: 0.115646; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1669 0.1484 0.1350 0.1180 0.1125 0.1114 0.1073 0.1060 0.1049 0.1036 0.1039 0.1036 0.1046 0.1056 0.1087 0.1099 

[TRAIN] Epoch[8](477/1500); Loss: 0.125023; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1508 0.1371 0.1344 0.1309 0.1260 0.1234 0.1223 0.1238 0.1175 0.1181 0.1169 0.1180 0.1181 0.1202 0.1200 0.1229 

[TRAIN] Epoch[8](478/1500); Loss: 0.086595; Backpropagation: 0.0917 sec; Batch: 0.4242 sec
0.1703 0.1418 0.0672 0.0571 0.0808 0.0733 0.0621 0.0537 0.0560 0.0626 0.0951 0.0928 0.0899 0.0895 0.0959 0.0974 

[TRAIN] Epoch[8](479/1500); Loss: 0.100604; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1150 0.1093 0.1001 0.0999 0.0971 0.0966 0.0953 0.0951 0.0949 0.0965 0.0967 0.0985 0.0994 0.1028 0.1045 0.1080 

[TRAIN] Epoch[8](480/1500); Loss: 0.089618; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1516 0.1370 0.0936 0.0857 0.0783 0.0814 0.0785 0.0754 0.0742 0.0771 0.0777 0.0807 0.0815 0.0842 0.0875 0.0894 

[TRAIN] Epoch[8](481/1500); Loss: 0.109223; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1190 0.1175 0.1159 0.1123 0.1090 0.1063 0.1043 0.1076 0.1064 0.1062 0.1072 0.1071 0.1075 0.1077 0.1070 0.1064 

[TRAIN] Epoch[8](482/1500); Loss: 0.190037; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.2394 0.2260 0.2263 0.2199 0.2096 0.2008 0.1941 0.1892 0.1801 0.1750 0.1709 0.1678 0.1617 0.1607 0.1599 0.1592 

[TRAIN] Epoch[8](483/1500); Loss: 0.123474; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1519 0.1333 0.1372 0.1306 0.1216 0.1168 0.1164 0.1171 0.1194 0.1159 0.1170 0.1185 0.1183 0.1189 0.1204 0.1222 

[TRAIN] Epoch[8](484/1500); Loss: 0.099149; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1664 0.1486 0.1111 0.1062 0.0963 0.0979 0.0925 0.0862 0.0826 0.0830 0.0851 0.0839 0.0843 0.0854 0.0881 0.0888 

[TRAIN] Epoch[8](485/1500); Loss: 0.126314; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1702 0.1559 0.1406 0.1387 0.1326 0.1267 0.1216 0.1203 0.1180 0.1151 0.1152 0.1125 0.1126 0.1129 0.1146 0.1135 

[TRAIN] Epoch[8](486/1500); Loss: 0.082608; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1120 0.0973 0.0943 0.0891 0.0816 0.0806 0.0797 0.0790 0.0770 0.0767 0.0758 0.0756 0.0751 0.0756 0.0756 0.0769 

[TRAIN] Epoch[8](487/1500); Loss: 0.145160; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2017 0.1811 0.1533 0.1470 0.1558 0.1483 0.1393 0.1341 0.1303 0.1303 0.1315 0.1310 0.1317 0.1332 0.1354 0.1386 

[TRAIN] Epoch[8](488/1500); Loss: 0.149131; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1534 0.1558 0.1478 0.1493 0.1495 0.1492 0.1470 0.1473 0.1466 0.1470 0.1469 0.1471 0.1480 0.1491 0.1502 0.1521 

[TRAIN] Epoch[8](489/1500); Loss: 0.087347; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.1172 0.1123 0.0932 0.0850 0.0846 0.0843 0.0836 0.0823 0.0815 0.0814 0.0811 0.0816 0.0819 0.0823 0.0821 0.0831 

[TRAIN] Epoch[8](490/1500); Loss: 0.131815; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1559 0.1456 0.1463 0.1422 0.1357 0.1320 0.1286 0.1306 0.1279 0.1257 0.1253 0.1232 0.1230 0.1218 0.1232 0.1219 

[TRAIN] Epoch[8](491/1500); Loss: 0.175755; Backpropagation: 0.0924 sec; Batch: 0.4247 sec
0.2416 0.2210 0.2172 0.2115 0.1994 0.1891 0.1802 0.1721 0.1623 0.1546 0.1471 0.1444 0.1421 0.1425 0.1431 0.1438 

[TRAIN] Epoch[8](492/1500); Loss: 0.079993; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.0870 0.0749 0.1031 0.0963 0.0859 0.0784 0.0749 0.0721 0.0721 0.0711 0.0748 0.0758 0.0760 0.0774 0.0792 0.0809 

[TRAIN] Epoch[8](493/1500); Loss: 0.090529; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1820 0.1510 0.1659 0.1495 0.1258 0.1020 0.0813 0.0643 0.0523 0.0485 0.0522 0.0524 0.0525 0.0550 0.0561 0.0578 

[TRAIN] Epoch[8](494/1500); Loss: 0.125518; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1930 0.1744 0.1306 0.1288 0.1305 0.1248 0.1180 0.1156 0.1171 0.1151 0.1124 0.1100 0.1116 0.1101 0.1090 0.1074 

[TRAIN] Epoch[8](495/1500); Loss: 0.142420; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1823 0.1756 0.1599 0.1469 0.1435 0.1394 0.1371 0.1364 0.1321 0.1307 0.1325 0.1321 0.1311 0.1326 0.1332 0.1335 

[TRAIN] Epoch[8](496/1500); Loss: 0.139935; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2405 0.2180 0.1982 0.1758 0.1631 0.1510 0.1417 0.1338 0.1242 0.1162 0.1094 0.0999 0.0960 0.0911 0.0898 0.0903 

[TRAIN] Epoch[8](497/1500); Loss: 0.121870; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1306 0.1244 0.1328 0.1300 0.1245 0.1212 0.1198 0.1184 0.1179 0.1171 0.1176 0.1177 0.1171 0.1188 0.1204 0.1214 

[TRAIN] Epoch[8](498/1500); Loss: 0.081165; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1518 0.1414 0.0762 0.0761 0.0693 0.0731 0.0731 0.0715 0.0696 0.0701 0.0696 0.0702 0.0714 0.0712 0.0716 0.0727 

[TRAIN] Epoch[8](499/1500); Loss: 0.162919; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1909 0.1776 0.1877 0.1831 0.1742 0.1654 0.1595 0.1588 0.1575 0.1540 0.1521 0.1511 0.1488 0.1492 0.1486 0.1482 

[TRAIN] Epoch[8](500/1500); Loss: 0.191523; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2027 0.2006 0.1938 0.1941 0.1924 0.1916 0.1906 0.1914 0.1888 0.1890 0.1883 0.1881 0.1883 0.1879 0.1880 0.1889 

[TRAIN] Epoch[8](501/1500); Loss: 0.189134; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2161 0.2064 0.2020 0.1976 0.1925 0.1897 0.1860 0.1832 0.1816 0.1811 0.1823 0.1802 0.1812 0.1826 0.1820 0.1817 

[TRAIN] Epoch[8](502/1500); Loss: 0.074838; Backpropagation: 0.0989 sec; Batch: 0.4470 sec
0.0958 0.0886 0.0859 0.0801 0.0782 0.0741 0.0696 0.0678 0.0661 0.0649 0.0664 0.0683 0.0705 0.0722 0.0734 0.0755 

[TRAIN] Epoch[8](503/1500); Loss: 0.101190; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1713 0.1571 0.1005 0.1007 0.0904 0.0970 0.0977 0.0929 0.0890 0.0869 0.0880 0.0888 0.0890 0.0895 0.0895 0.0907 

[TRAIN] Epoch[8](504/1500); Loss: 0.114226; Backpropagation: 0.0918 sec; Batch: 0.4245 sec
0.1343 0.1299 0.1238 0.1215 0.1162 0.1128 0.1108 0.1109 0.1080 0.1086 0.1067 0.1092 0.1062 0.1084 0.1088 0.1115 

[TRAIN] Epoch[8](505/1500); Loss: 0.143480; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1777 0.1687 0.1648 0.1565 0.1488 0.1439 0.1395 0.1365 0.1355 0.1332 0.1308 0.1322 0.1323 0.1309 0.1328 0.1317 

[TRAIN] Epoch[8](506/1500); Loss: 0.151588; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1752 0.1653 0.1579 0.1549 0.1505 0.1467 0.1446 0.1456 0.1456 0.1470 0.1484 0.1469 0.1471 0.1487 0.1507 0.1504 

[TRAIN] Epoch[8](507/1500); Loss: 0.092890; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1200 0.1065 0.1151 0.1068 0.0973 0.0924 0.0901 0.0875 0.0862 0.0843 0.0854 0.0823 0.0817 0.0824 0.0835 0.0847 

[TRAIN] Epoch[8](508/1500); Loss: 0.113318; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1607 0.1467 0.1086 0.1061 0.1142 0.1107 0.1050 0.1021 0.1020 0.1037 0.1057 0.1046 0.1074 0.1104 0.1118 0.1133 

[TRAIN] Epoch[8](509/1500); Loss: 0.241751; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.3314 0.2972 0.3050 0.2922 0.2706 0.2493 0.2303 0.2149 0.2056 0.2021 0.2049 0.2113 0.2081 0.2135 0.2141 0.2174 

[TRAIN] Epoch[8](510/1500); Loss: 0.110995; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1209 0.1151 0.1166 0.1156 0.1106 0.1096 0.1080 0.1087 0.1081 0.1093 0.1100 0.1070 0.1081 0.1090 0.1101 0.1092 

[TRAIN] Epoch[8](511/1500); Loss: 0.089029; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1993 0.1543 0.1829 0.1596 0.1251 0.0914 0.0635 0.0443 0.0419 0.0503 0.0484 0.0469 0.0495 0.0548 0.0566 0.0557 

[TRAIN] Epoch[8](512/1500); Loss: 0.117278; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1463 0.1352 0.1475 0.1412 0.1308 0.1228 0.1144 0.1089 0.1054 0.1044 0.1033 0.1021 0.1013 0.1036 0.1046 0.1046 

[TRAIN] Epoch[8](513/1500); Loss: 0.151351; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2057 0.1951 0.1752 0.1685 0.1605 0.1547 0.1490 0.1438 0.1380 0.1327 0.1318 0.1323 0.1330 0.1327 0.1340 0.1346 

[TRAIN] Epoch[8](514/1500); Loss: 0.178429; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2129 0.1993 0.2018 0.1962 0.1877 0.1809 0.1755 0.1716 0.1676 0.1671 0.1677 0.1643 0.1651 0.1654 0.1660 0.1657 

[TRAIN] Epoch[8](515/1500); Loss: 0.135674; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1649 0.1602 0.1476 0.1343 0.1295 0.1364 0.1321 0.1297 0.1278 0.1287 0.1309 0.1297 0.1290 0.1291 0.1309 0.1300 

[TRAIN] Epoch[8](516/1500); Loss: 0.128455; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.2069 0.1832 0.1904 0.1793 0.1612 0.1438 0.1262 0.1125 0.1006 0.0915 0.0917 0.0931 0.0924 0.0925 0.0952 0.0948 

[TRAIN] Epoch[8](517/1500); Loss: 0.123074; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2182 0.1916 0.1799 0.1554 0.1384 0.1345 0.1187 0.1040 0.0923 0.0905 0.0917 0.0906 0.0901 0.0912 0.0908 0.0911 

[TRAIN] Epoch[8](518/1500); Loss: 0.162002; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2161 0.2001 0.1920 0.1871 0.1778 0.1690 0.1620 0.1569 0.1490 0.1439 0.1403 0.1404 0.1398 0.1386 0.1393 0.1396 

[TRAIN] Epoch[8](519/1500); Loss: 0.133130; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1876 0.1712 0.1681 0.1615 0.1524 0.1416 0.1327 0.1271 0.1197 0.1152 0.1125 0.1085 0.1093 0.1074 0.1074 0.1078 

[TRAIN] Epoch[8](520/1500); Loss: 0.137577; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2044 0.1863 0.1669 0.1638 0.1535 0.1432 0.1356 0.1309 0.1248 0.1201 0.1149 0.1144 0.1108 0.1127 0.1095 0.1095 

[TRAIN] Epoch[8](521/1500); Loss: 0.110567; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1370 0.1260 0.1128 0.1102 0.1073 0.1067 0.1054 0.1070 0.1046 0.1057 0.1055 0.1065 0.1064 0.1081 0.1089 0.1110 

[TRAIN] Epoch[8](522/1500); Loss: 0.082809; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1044 0.1026 0.0889 0.0811 0.0824 0.0817 0.0764 0.0762 0.0751 0.0778 0.0772 0.0779 0.0769 0.0811 0.0818 0.0835 

[TRAIN] Epoch[8](523/1500); Loss: 0.167136; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2088 0.1902 0.2047 0.1950 0.1851 0.1752 0.1677 0.1633 0.1595 0.1588 0.1534 0.1505 0.1435 0.1411 0.1385 0.1389 

[TRAIN] Epoch[8](524/1500); Loss: 0.113800; Backpropagation: 0.0917 sec; Batch: 0.4241 sec
0.1231 0.1214 0.1123 0.1138 0.1123 0.1126 0.1104 0.1105 0.1100 0.1109 0.1115 0.1119 0.1133 0.1142 0.1156 0.1169 

[TRAIN] Epoch[8](525/1500); Loss: 0.140636; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1691 0.1622 0.1586 0.1551 0.1483 0.1430 0.1366 0.1351 0.1336 0.1319 0.1306 0.1302 0.1293 0.1288 0.1294 0.1285 

[TRAIN] Epoch[8](526/1500); Loss: 0.206384; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.3345 0.3008 0.3289 0.3100 0.2840 0.2578 0.2329 0.2101 0.1844 0.1619 0.1409 0.1219 0.1098 0.1040 0.1073 0.1129 

[TRAIN] Epoch[8](527/1500); Loss: 0.070742; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.0926 0.0766 0.0871 0.0820 0.0705 0.0663 0.0652 0.0635 0.0655 0.0630 0.0638 0.0642 0.0663 0.0672 0.0682 0.0699 

[TRAIN] Epoch[8](528/1500); Loss: 0.136165; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1768 0.1603 0.1555 0.1480 0.1394 0.1318 0.1282 0.1265 0.1269 0.1256 0.1258 0.1261 0.1276 0.1260 0.1269 0.1273 

[TRAIN] Epoch[8](529/1500); Loss: 0.106728; Backpropagation: 0.0928 sec; Batch: 0.4248 sec
0.1399 0.1338 0.1208 0.1139 0.1103 0.1085 0.1031 0.1013 0.0992 0.0972 0.0949 0.0961 0.0976 0.0960 0.0966 0.0983 

[TRAIN] Epoch[8](530/1500); Loss: 0.112288; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1593 0.1370 0.1579 0.1455 0.1296 0.1161 0.1026 0.0954 0.0924 0.0906 0.0890 0.0908 0.0945 0.0956 0.0983 0.1020 

[TRAIN] Epoch[8](531/1500); Loss: 0.066587; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1304 0.1166 0.0680 0.0574 0.0561 0.0577 0.0563 0.0565 0.0560 0.0554 0.0561 0.0578 0.0581 0.0588 0.0610 0.0630 

[TRAIN] Epoch[8](532/1500); Loss: 0.164552; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.2437 0.2161 0.2307 0.2180 0.2002 0.1826 0.1666 0.1543 0.1419 0.1321 0.1255 0.1226 0.1223 0.1225 0.1258 0.1280 

[TRAIN] Epoch[8](533/1500); Loss: 0.150217; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1794 0.1711 0.1683 0.1650 0.1601 0.1560 0.1510 0.1471 0.1434 0.1409 0.1379 0.1385 0.1369 0.1366 0.1355 0.1356 

[TRAIN] Epoch[8](534/1500); Loss: 0.088994; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1450 0.1380 0.1034 0.0865 0.0855 0.0846 0.0821 0.0800 0.0804 0.0776 0.0769 0.0769 0.0771 0.0766 0.0763 0.0768 

[TRAIN] Epoch[8](535/1500); Loss: 0.103903; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1720 0.1517 0.1160 0.0998 0.1005 0.1032 0.0933 0.0887 0.0865 0.0890 0.0914 0.0924 0.0929 0.0946 0.0946 0.0958 

[TRAIN] Epoch[8](536/1500); Loss: 0.075425; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.0883 0.0834 0.0904 0.0769 0.0833 0.0804 0.0756 0.0728 0.0665 0.0670 0.0677 0.0694 0.0704 0.0702 0.0714 0.0730 

[TRAIN] Epoch[8](537/1500); Loss: 0.095230; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1705 0.1545 0.0898 0.0966 0.0848 0.0889 0.0853 0.0793 0.0788 0.0814 0.0796 0.0835 0.0838 0.0870 0.0882 0.0919 

[TRAIN] Epoch[8](538/1500); Loss: 0.197204; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2847 0.2618 0.2675 0.2569 0.2406 0.2233 0.2076 0.1935 0.1811 0.1667 0.1567 0.1475 0.1433 0.1418 0.1412 0.1411 

[TRAIN] Epoch[8](539/1500); Loss: 0.073651; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1283 0.1177 0.0706 0.0701 0.0647 0.0662 0.0633 0.0644 0.0647 0.0661 0.0647 0.0660 0.0645 0.0681 0.0685 0.0706 

[TRAIN] Epoch[8](540/1500); Loss: 0.116766; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1231 0.1192 0.1157 0.1162 0.1149 0.1158 0.1136 0.1150 0.1137 0.1159 0.1144 0.1164 0.1160 0.1184 0.1187 0.1212 

[TRAIN] Epoch[8](541/1500); Loss: 0.128196; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1665 0.1618 0.1289 0.1228 0.1237 0.1253 0.1238 0.1228 0.1220 0.1213 0.1206 0.1207 0.1219 0.1219 0.1227 0.1246 

[TRAIN] Epoch[8](542/1500); Loss: 0.086890; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.0980 0.0952 0.0902 0.0874 0.0854 0.0866 0.0830 0.0834 0.0832 0.0844 0.0836 0.0845 0.0851 0.0857 0.0867 0.0878 

[TRAIN] Epoch[8](543/1500); Loss: 0.193047; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2006 0.1962 0.1962 0.1952 0.1931 0.1924 0.1926 0.1932 0.1936 0.1931 0.1905 0.1902 0.1901 0.1917 0.1896 0.1903 

[TRAIN] Epoch[8](544/1500); Loss: 0.083677; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1679 0.1403 0.0648 0.0547 0.0734 0.0604 0.0531 0.0526 0.0652 0.0877 0.0879 0.0830 0.0806 0.0829 0.0875 0.0969 

[TRAIN] Epoch[8](545/1500); Loss: 0.154356; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1828 0.1729 0.1658 0.1575 0.1530 0.1526 0.1515 0.1501 0.1508 0.1483 0.1464 0.1464 0.1482 0.1470 0.1472 0.1491 

[TRAIN] Epoch[8](546/1500); Loss: 0.090553; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2308 0.2026 0.1072 0.0764 0.0659 0.0716 0.0666 0.0584 0.0617 0.0765 0.0757 0.0679 0.0642 0.0684 0.0785 0.0766 

[TRAIN] Epoch[8](547/1500); Loss: 0.134623; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1801 0.1613 0.1541 0.1461 0.1355 0.1276 0.1259 0.1267 0.1236 0.1246 0.1245 0.1245 0.1239 0.1244 0.1254 0.1257 

[TRAIN] Epoch[8](548/1500); Loss: 0.083366; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0962 0.0861 0.1012 0.0896 0.0903 0.0845 0.0805 0.0806 0.0783 0.0770 0.0764 0.0753 0.0762 0.0779 0.0818 0.0819 

[TRAIN] Epoch[8](549/1500); Loss: 0.154856; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1924 0.1843 0.1779 0.1751 0.1686 0.1629 0.1571 0.1506 0.1430 0.1408 0.1390 0.1378 0.1371 0.1369 0.1371 0.1372 

[TRAIN] Epoch[8](550/1500); Loss: 0.105560; Backpropagation: 0.0916 sec; Batch: 0.4239 sec
0.1615 0.1466 0.1107 0.1077 0.1010 0.1016 0.0975 0.0952 0.0909 0.0941 0.0942 0.0945 0.0951 0.0972 0.0998 0.1015 

[TRAIN] Epoch[8](551/1500); Loss: 0.100451; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1191 0.1169 0.1092 0.1039 0.0974 0.0976 0.0958 0.0960 0.0957 0.0973 0.0956 0.0964 0.0951 0.0969 0.0962 0.0983 

[TRAIN] Epoch[8](552/1500); Loss: 0.208369; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2797 0.2635 0.2588 0.2493 0.2391 0.2272 0.2164 0.2084 0.1988 0.1890 0.1811 0.1726 0.1663 0.1620 0.1608 0.1610 

[TRAIN] Epoch[8](553/1500); Loss: 0.124076; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2093 0.1894 0.1667 0.1510 0.1413 0.1310 0.1197 0.1113 0.1038 0.0956 0.0928 0.0942 0.0953 0.0929 0.0938 0.0972 

[TRAIN] Epoch[8](554/1500); Loss: 0.130737; Backpropagation: 0.0920 sec; Batch: 0.4305 sec
0.1548 0.1398 0.1375 0.1354 0.1325 0.1291 0.1263 0.1267 0.1240 0.1250 0.1242 0.1257 0.1257 0.1265 0.1282 0.1302 

[TRAIN] Epoch[8](555/1500); Loss: 0.239389; Backpropagation: 0.0921 sec; Batch: 0.4247 sec
0.4273 0.3787 0.4046 0.3798 0.3408 0.2986 0.2597 0.2261 0.1878 0.1533 0.1282 0.1192 0.1287 0.1292 0.1325 0.1357 

[TRAIN] Epoch[8](556/1500); Loss: 0.149410; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1698 0.1639 0.1666 0.1621 0.1561 0.1525 0.1475 0.1459 0.1442 0.1424 0.1412 0.1397 0.1400 0.1407 0.1391 0.1388 

[TRAIN] Epoch[8](557/1500); Loss: 0.053835; Backpropagation: 0.0920 sec; Batch: 0.4246 sec
0.0468 0.0484 0.0463 0.0489 0.0469 0.0459 0.0456 0.0472 0.0486 0.0522 0.0545 0.0582 0.0614 0.0661 0.0698 0.0746 

[TRAIN] Epoch[8](558/1500); Loss: 0.083905; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2149 0.1906 0.0571 0.0922 0.0660 0.0907 0.0874 0.0691 0.0463 0.0447 0.0563 0.0693 0.0650 0.0610 0.0604 0.0713 

[TRAIN] Epoch[8](559/1500); Loss: 0.078970; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1518 0.1242 0.1347 0.1197 0.0979 0.0763 0.0591 0.0518 0.0545 0.0538 0.0526 0.0538 0.0561 0.0577 0.0584 0.0611 

[TRAIN] Epoch[8](560/1500); Loss: 0.121704; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1508 0.1315 0.1378 0.1305 0.1219 0.1195 0.1154 0.1134 0.1155 0.1132 0.1135 0.1141 0.1164 0.1170 0.1187 0.1179 

[TRAIN] Epoch[8](561/1500); Loss: 0.079141; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1070 0.0796 0.1240 0.1133 0.0933 0.0747 0.0645 0.0593 0.0605 0.0635 0.0656 0.0683 0.0703 0.0716 0.0732 0.0777 

[TRAIN] Epoch[8](562/1500); Loss: 0.120702; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1559 0.1364 0.1534 0.1426 0.1314 0.1198 0.1127 0.1097 0.1096 0.1073 0.1052 0.1069 0.1079 0.1091 0.1108 0.1125 

[TRAIN] Epoch[8](563/1500); Loss: 0.092647; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1111 0.1058 0.0893 0.0881 0.0863 0.0851 0.0840 0.0872 0.0856 0.0871 0.0882 0.0924 0.0941 0.0962 0.0988 0.1030 

[TRAIN] Epoch[8](564/1500); Loss: 0.116361; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1430 0.1341 0.1208 0.1186 0.1161 0.1125 0.1115 0.1131 0.1123 0.1120 0.1120 0.1121 0.1103 0.1105 0.1106 0.1122 

[TRAIN] Epoch[8](565/1500); Loss: 0.113349; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2424 0.2051 0.2171 0.1952 0.1632 0.1263 0.0934 0.0701 0.0577 0.0609 0.0615 0.0594 0.0617 0.0655 0.0657 0.0685 

[TRAIN] Epoch[8](566/1500); Loss: 0.108909; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1317 0.1228 0.1176 0.1146 0.1068 0.1023 0.1045 0.1062 0.1029 0.1050 0.1040 0.1055 0.1026 0.1048 0.1039 0.1072 

[TRAIN] Epoch[8](567/1500); Loss: 0.141386; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1914 0.1812 0.1375 0.1465 0.1345 0.1385 0.1371 0.1317 0.1297 0.1274 0.1291 0.1307 0.1331 0.1344 0.1391 0.1401 

[TRAIN] Epoch[8](568/1500); Loss: 0.162702; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.1975 0.1819 0.1887 0.1802 0.1736 0.1659 0.1608 0.1591 0.1580 0.1553 0.1503 0.1485 0.1457 0.1453 0.1450 0.1473 

[TRAIN] Epoch[8](569/1500); Loss: 0.158063; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2488 0.2177 0.2385 0.2208 0.1991 0.1752 0.1545 0.1398 0.1274 0.1190 0.1147 0.1150 0.1132 0.1138 0.1146 0.1167 

[TRAIN] Epoch[8](570/1500); Loss: 0.105711; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1790 0.1576 0.1623 0.1497 0.1308 0.1121 0.0948 0.0806 0.0751 0.0752 0.0786 0.0753 0.0770 0.0787 0.0812 0.0833 

[TRAIN] Epoch[8](571/1500); Loss: 0.142037; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1786 0.1665 0.1655 0.1593 0.1517 0.1445 0.1359 0.1327 0.1307 0.1322 0.1312 0.1287 0.1294 0.1278 0.1292 0.1288 

[TRAIN] Epoch[8](572/1500); Loss: 0.138330; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1848 0.1699 0.1649 0.1572 0.1478 0.1381 0.1332 0.1272 0.1259 0.1246 0.1245 0.1231 0.1236 0.1225 0.1227 0.1233 

[TRAIN] Epoch[8](573/1500); Loss: 0.112800; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1617 0.1491 0.1189 0.1183 0.1103 0.1070 0.1022 0.0991 0.1015 0.1013 0.1023 0.1034 0.1061 0.1067 0.1074 0.1094 

[TRAIN] Epoch[8](574/1500); Loss: 0.090531; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1729 0.1455 0.0728 0.0619 0.0812 0.0665 0.0591 0.0600 0.0842 0.0925 0.0904 0.0861 0.0874 0.0907 0.0934 0.1040 

[TRAIN] Epoch[8](575/1500); Loss: 0.102731; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1131 0.1149 0.1099 0.1092 0.1073 0.1051 0.1001 0.1006 0.0996 0.0976 0.0974 0.0970 0.0969 0.0975 0.0982 0.0994 

[TRAIN] Epoch[8](576/1500); Loss: 0.137788; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2142 0.1870 0.1963 0.1790 0.1642 0.1460 0.1321 0.1258 0.1167 0.1114 0.1098 0.1104 0.1050 0.1042 0.1016 0.1011 

[TRAIN] Epoch[8](577/1500); Loss: 0.155731; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.2813 0.2481 0.2468 0.2327 0.2092 0.1827 0.1595 0.1432 0.1254 0.1097 0.0968 0.0915 0.0921 0.0903 0.0910 0.0915 

[TRAIN] Epoch[8](578/1500); Loss: 0.104470; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2216 0.1909 0.1945 0.1758 0.1499 0.1212 0.0925 0.0707 0.0578 0.0528 0.0551 0.0547 0.0552 0.0576 0.0587 0.0627 

[TRAIN] Epoch[8](579/1500); Loss: 0.099295; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1145 0.1009 0.1075 0.1013 0.0975 0.1017 0.0943 0.0944 0.0963 0.0960 0.0945 0.0964 0.0966 0.0995 0.0977 0.0998 

[TRAIN] Epoch[8](580/1500); Loss: 0.129750; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1581 0.1484 0.1502 0.1449 0.1369 0.1329 0.1276 0.1239 0.1223 0.1208 0.1200 0.1183 0.1179 0.1174 0.1177 0.1185 

[TRAIN] Epoch[8](581/1500); Loss: 0.162345; Backpropagation: 0.0918 sec; Batch: 0.4243 sec
0.2216 0.2052 0.2068 0.1984 0.1859 0.1725 0.1606 0.1519 0.1444 0.1390 0.1369 0.1336 0.1347 0.1346 0.1366 0.1347 

[TRAIN] Epoch[8](582/1500); Loss: 0.107855; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1177 0.1159 0.1074 0.1065 0.1048 0.1050 0.1043 0.1050 0.1054 0.1063 0.1056 0.1062 0.1071 0.1088 0.1089 0.1107 

[TRAIN] Epoch[8](583/1500); Loss: 0.130706; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1508 0.1382 0.1420 0.1391 0.1330 0.1294 0.1273 0.1257 0.1254 0.1250 0.1249 0.1246 0.1258 0.1256 0.1271 0.1274 

[TRAIN] Epoch[8](584/1500); Loss: 0.115320; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1820 0.1659 0.1474 0.1324 0.1273 0.1185 0.1095 0.1060 0.1005 0.0962 0.0928 0.0926 0.0918 0.0920 0.0934 0.0969 

[TRAIN] Epoch[8](585/1500); Loss: 0.107255; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1663 0.1464 0.1432 0.1324 0.1191 0.1068 0.0971 0.0893 0.0882 0.0869 0.0882 0.0882 0.0895 0.0898 0.0914 0.0933 

[TRAIN] Epoch[8](586/1500); Loss: 0.150074; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2290 0.1969 0.2213 0.2006 0.1791 0.1560 0.1360 0.1256 0.1201 0.1148 0.1159 0.1178 0.1219 0.1214 0.1213 0.1235 

[TRAIN] Epoch[8](587/1500); Loss: 0.247229; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.3950 0.3534 0.3597 0.3382 0.3034 0.2600 0.2178 0.1905 0.1786 0.1863 0.1931 0.1950 0.1940 0.1950 0.1960 0.1996 

[TRAIN] Epoch[8](588/1500); Loss: 0.127936; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1480 0.1365 0.1357 0.1307 0.1263 0.1241 0.1239 0.1235 0.1229 0.1242 0.1242 0.1244 0.1242 0.1249 0.1260 0.1275 

[TRAIN] Epoch[8](589/1500); Loss: 0.119386; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1419 0.1408 0.1321 0.1266 0.1243 0.1232 0.1183 0.1168 0.1135 0.1123 0.1104 0.1095 0.1093 0.1098 0.1106 0.1109 

[TRAIN] Epoch[8](590/1500); Loss: 0.075555; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0882 0.0735 0.0856 0.0806 0.0739 0.0746 0.0735 0.0690 0.0700 0.0715 0.0717 0.0729 0.0732 0.0750 0.0768 0.0789 

[TRAIN] Epoch[8](591/1500); Loss: 0.204750; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.3055 0.2734 0.2755 0.2601 0.2356 0.2068 0.1776 0.1634 0.1611 0.1725 0.1677 0.1729 0.1750 0.1729 0.1771 0.1788 

[TRAIN] Epoch[8](592/1500); Loss: 0.143273; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1696 0.1555 0.1494 0.1468 0.1434 0.1395 0.1401 0.1379 0.1368 0.1367 0.1379 0.1387 0.1378 0.1388 0.1412 0.1425 

[TRAIN] Epoch[8](593/1500); Loss: 0.185382; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.2609 0.2405 0.2431 0.2328 0.2185 0.2040 0.1906 0.1801 0.1708 0.1613 0.1516 0.1447 0.1432 0.1432 0.1402 0.1406 

[TRAIN] Epoch[8](594/1500); Loss: 0.080197; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1462 0.1299 0.1042 0.0897 0.0747 0.0660 0.0629 0.0633 0.0633 0.0647 0.0651 0.0673 0.0684 0.0702 0.0725 0.0748 

[TRAIN] Epoch[8](595/1500); Loss: 0.179188; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1907 0.1860 0.1866 0.1851 0.1817 0.1785 0.1788 0.1822 0.1787 0.1767 0.1755 0.1743 0.1724 0.1732 0.1729 0.1738 

[TRAIN] Epoch[8](596/1500); Loss: 0.148775; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2252 0.2002 0.2033 0.1895 0.1724 0.1581 0.1487 0.1372 0.1293 0.1200 0.1164 0.1182 0.1151 0.1159 0.1145 0.1165 

[TRAIN] Epoch[8](597/1500); Loss: 0.111790; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1334 0.1210 0.1264 0.1195 0.1145 0.1089 0.1029 0.1015 0.0993 0.1006 0.1015 0.1053 0.1078 0.1108 0.1153 0.1199 

[TRAIN] Epoch[8](598/1500); Loss: 0.118594; Backpropagation: 0.0938 sec; Batch: 0.4258 sec
0.2521 0.2162 0.2232 0.2015 0.1738 0.1388 0.1051 0.0806 0.0628 0.0595 0.0633 0.0612 0.0622 0.0659 0.0651 0.0663 

[TRAIN] Epoch[8](599/1500); Loss: 0.069197; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1125 0.0942 0.0930 0.0846 0.0761 0.0701 0.0575 0.0582 0.0537 0.0569 0.0549 0.0558 0.0573 0.0599 0.0603 0.0622 

[TRAIN] Epoch[8](600/1500); Loss: 0.187838; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1977 0.1920 0.1921 0.1899 0.1864 0.1841 0.1850 0.1890 0.1915 0.1855 0.1863 0.1855 0.1857 0.1843 0.1869 0.1835 

[TRAIN] Epoch[8](601/1500); Loss: 0.161034; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2226 0.1996 0.2052 0.1933 0.1776 0.1622 0.1534 0.1483 0.1451 0.1399 0.1407 0.1388 0.1377 0.1371 0.1381 0.1369 

[TRAIN] Epoch[8](602/1500); Loss: 0.110813; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1448 0.1285 0.1340 0.1267 0.1156 0.1078 0.1043 0.1038 0.1031 0.1019 0.0986 0.0989 0.0992 0.1002 0.1020 0.1036 

[TRAIN] Epoch[8](603/1500); Loss: 0.092852; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1315 0.1216 0.1124 0.1091 0.1014 0.0955 0.0905 0.0866 0.0837 0.0802 0.0784 0.0774 0.0790 0.0779 0.0794 0.0811 

[TRAIN] Epoch[8](604/1500); Loss: 0.150168; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1766 0.1648 0.1577 0.1537 0.1470 0.1424 0.1418 0.1450 0.1416 0.1429 0.1453 0.1489 0.1456 0.1477 0.1492 0.1524 

[TRAIN] Epoch[8](605/1500); Loss: 0.099695; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2247 0.2028 0.1111 0.0864 0.0786 0.0873 0.0802 0.0736 0.0757 0.0819 0.0808 0.0788 0.0781 0.0844 0.0855 0.0853 

[TRAIN] Epoch[8](606/1500); Loss: 0.079529; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.0979 0.0956 0.0809 0.0824 0.0766 0.0772 0.0755 0.0757 0.0748 0.0754 0.0743 0.0758 0.0761 0.0771 0.0780 0.0792 

[TRAIN] Epoch[8](607/1500); Loss: 0.080973; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1653 0.1358 0.0612 0.0489 0.0690 0.0535 0.0461 0.0481 0.0886 0.0908 0.0840 0.0757 0.0751 0.0748 0.0799 0.0989 

[TRAIN] Epoch[8](608/1500); Loss: 0.129755; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1522 0.1475 0.1427 0.1392 0.1329 0.1316 0.1256 0.1259 0.1228 0.1227 0.1218 0.1234 0.1213 0.1216 0.1218 0.1231 

[TRAIN] Epoch[8](609/1500); Loss: 0.165925; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2019 0.1879 0.1990 0.1904 0.1804 0.1722 0.1661 0.1633 0.1626 0.1568 0.1512 0.1496 0.1453 0.1439 0.1419 0.1422 

[TRAIN] Epoch[8](610/1500); Loss: 0.160321; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1827 0.1774 0.1742 0.1719 0.1690 0.1672 0.1638 0.1561 0.1533 0.1514 0.1500 0.1486 0.1493 0.1496 0.1511 0.1495 

[TRAIN] Epoch[8](611/1500); Loss: 0.121973; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1311 0.1289 0.1272 0.1234 0.1217 0.1210 0.1236 0.1211 0.1205 0.1188 0.1183 0.1184 0.1204 0.1173 0.1187 0.1212 

[TRAIN] Epoch[8](612/1500); Loss: 0.065195; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.0621 0.0717 0.0614 0.0590 0.0616 0.0629 0.0639 0.0650 0.0646 0.0636 0.0641 0.0659 0.0674 0.0681 0.0699 0.0720 

[TRAIN] Epoch[8](613/1500); Loss: 0.110522; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.1450 0.1352 0.1105 0.1065 0.1042 0.1030 0.1015 0.1078 0.1045 0.1062 0.1037 0.1084 0.1058 0.1069 0.1066 0.1125 

[TRAIN] Epoch[8](614/1500); Loss: 0.071673; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1659 0.1458 0.0666 0.0706 0.0635 0.0653 0.0551 0.0498 0.0534 0.0556 0.0540 0.0538 0.0580 0.0639 0.0628 0.0626 

[TRAIN] Epoch[8](615/1500); Loss: 0.122989; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1447 0.1356 0.1320 0.1252 0.1212 0.1165 0.1167 0.1229 0.1136 0.1156 0.1184 0.1228 0.1160 0.1192 0.1213 0.1261 

[TRAIN] Epoch[8](616/1500); Loss: 0.135509; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2150 0.1892 0.1961 0.1760 0.1551 0.1350 0.1199 0.1142 0.1112 0.1085 0.1077 0.1081 0.1058 0.1078 0.1082 0.1105 

[TRAIN] Epoch[8](617/1500); Loss: 0.169507; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1871 0.1849 0.1803 0.1795 0.1773 0.1755 0.1702 0.1686 0.1651 0.1637 0.1609 0.1609 0.1600 0.1613 0.1580 0.1589 

[TRAIN] Epoch[8](618/1500); Loss: 0.071478; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0804 0.0724 0.0883 0.0807 0.0734 0.0705 0.0670 0.0624 0.0630 0.0663 0.0659 0.0663 0.0669 0.0721 0.0733 0.0747 

[TRAIN] Epoch[8](619/1500); Loss: 0.152844; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.2050 0.1850 0.1934 0.1842 0.1684 0.1554 0.1465 0.1362 0.1316 0.1333 0.1351 0.1333 0.1328 0.1337 0.1355 0.1361 

[TRAIN] Epoch[8](620/1500); Loss: 0.107032; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1700 0.1587 0.1050 0.1025 0.0985 0.0986 0.0968 0.0956 0.0954 0.0941 0.0968 0.0979 0.0973 0.0994 0.1015 0.1043 

[TRAIN] Epoch[8](621/1500); Loss: 0.090556; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1148 0.1034 0.1006 0.0930 0.0903 0.0846 0.0834 0.0839 0.0846 0.0847 0.0832 0.0849 0.0851 0.0879 0.0907 0.0936 

[TRAIN] Epoch[8](622/1500); Loss: 0.167845; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2432 0.2212 0.2288 0.2152 0.1961 0.1750 0.1546 0.1437 0.1418 0.1389 0.1417 0.1355 0.1369 0.1374 0.1371 0.1383 

[TRAIN] Epoch[8](623/1500); Loss: 0.162758; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2511 0.2218 0.2306 0.2123 0.1883 0.1644 0.1499 0.1435 0.1380 0.1334 0.1299 0.1300 0.1278 0.1274 0.1271 0.1286 

[TRAIN] Epoch[8](624/1500); Loss: 0.143092; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1828 0.1674 0.1710 0.1626 0.1533 0.1460 0.1357 0.1322 0.1306 0.1275 0.1283 0.1299 0.1293 0.1295 0.1314 0.1319 

[TRAIN] Epoch[8](625/1500); Loss: 0.109068; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1269 0.1216 0.1071 0.0990 0.0991 0.0994 0.1011 0.1046 0.1041 0.1051 0.1065 0.1103 0.1108 0.1128 0.1164 0.1203 

[TRAIN] Epoch[8](626/1500); Loss: 0.094433; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1196 0.0982 0.1025 0.0934 0.0881 0.0949 0.0870 0.0900 0.0904 0.0899 0.0892 0.0905 0.0909 0.0938 0.0945 0.0979 

[TRAIN] Epoch[8](627/1500); Loss: 0.100906; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2225 0.1846 0.2007 0.1760 0.1443 0.1087 0.0801 0.0588 0.0510 0.0506 0.0537 0.0531 0.0549 0.0559 0.0589 0.0608 

[TRAIN] Epoch[8](628/1500); Loss: 0.115307; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1363 0.1282 0.1373 0.1326 0.1236 0.1169 0.1124 0.1091 0.1051 0.1046 0.1043 0.1051 0.1060 0.1068 0.1075 0.1093 

[TRAIN] Epoch[8](629/1500); Loss: 0.085229; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1127 0.0963 0.1098 0.1029 0.0897 0.0791 0.0741 0.0786 0.0747 0.0728 0.0751 0.0763 0.0774 0.0791 0.0815 0.0835 

[TRAIN] Epoch[8](630/1500); Loss: 0.120836; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1375 0.1376 0.1271 0.1261 0.1232 0.1220 0.1163 0.1157 0.1134 0.1152 0.1140 0.1155 0.1157 0.1179 0.1171 0.1191 

[TRAIN] Epoch[8](631/1500); Loss: 0.128193; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1568 0.1405 0.1562 0.1471 0.1330 0.1261 0.1259 0.1143 0.1144 0.1156 0.1167 0.1176 0.1212 0.1206 0.1209 0.1243 

[TRAIN] Epoch[8](632/1500); Loss: 0.141261; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1622 0.1480 0.1560 0.1454 0.1382 0.1327 0.1390 0.1437 0.1342 0.1338 0.1343 0.1378 0.1352 0.1370 0.1408 0.1420 

[TRAIN] Epoch[8](633/1500); Loss: 0.114006; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1737 0.1470 0.1438 0.1238 0.1081 0.1101 0.1198 0.1057 0.1014 0.1011 0.0969 0.0971 0.0969 0.0984 0.0997 0.1003 

[TRAIN] Epoch[8](634/1500); Loss: 0.118316; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1123 0.1078 0.1358 0.1141 0.1151 0.1090 0.1075 0.1231 0.1135 0.1129 0.1160 0.1176 0.1241 0.1243 0.1285 0.1316 

[TRAIN] Epoch[8](635/1500); Loss: 0.101898; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1641 0.1494 0.0930 0.0940 0.0873 0.0865 0.0922 0.0916 0.0920 0.0909 0.0933 0.0943 0.0971 0.0989 0.1020 0.1039 

[TRAIN] Epoch[8](636/1500); Loss: 0.108351; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1335 0.1256 0.1191 0.1113 0.1096 0.1050 0.1077 0.1031 0.1024 0.0991 0.1005 0.1013 0.1016 0.1025 0.1045 0.1069 

[TRAIN] Epoch[8](637/1500); Loss: 0.073259; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.0790 0.0741 0.0675 0.0631 0.0612 0.0754 0.0663 0.0722 0.0693 0.0732 0.0712 0.0743 0.0779 0.0797 0.0823 0.0855 

[TRAIN] Epoch[8](638/1500); Loss: 0.099138; Backpropagation: 0.0919 sec; Batch: 0.4244 sec
0.1260 0.1109 0.1065 0.1022 0.0970 0.1084 0.1008 0.0991 0.0937 0.0929 0.0900 0.0905 0.0901 0.0912 0.0921 0.0947 

[TRAIN] Epoch[8](639/1500); Loss: 0.111315; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1430 0.1263 0.1174 0.1043 0.1014 0.1128 0.1133 0.1074 0.1063 0.1037 0.1053 0.1042 0.1068 0.1068 0.1103 0.1115 

[TRAIN] Epoch[8](640/1500); Loss: 0.088620; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2199 0.1953 0.1000 0.0808 0.0637 0.0654 0.0575 0.0679 0.0616 0.0631 0.0650 0.0687 0.0735 0.0758 0.0784 0.0815 

[TRAIN] Epoch[8](641/1500); Loss: 0.156481; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.2178 0.1948 0.2040 0.1853 0.1618 0.1437 0.1455 0.1495 0.1390 0.1383 0.1352 0.1354 0.1375 0.1372 0.1394 0.1395 

[TRAIN] Epoch[8](642/1500); Loss: 0.166792; Backpropagation: 0.0918 sec; Batch: 0.4242 sec
0.2195 0.1995 0.1977 0.1830 0.1687 0.1593 0.1589 0.1722 0.1633 0.1540 0.1521 0.1467 0.1472 0.1469 0.1489 0.1508 

[TRAIN] Epoch[8](643/1500); Loss: 0.154380; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1679 0.1612 0.1551 0.1524 0.1529 0.1615 0.1629 0.1555 0.1546 0.1490 0.1485 0.1467 0.1487 0.1487 0.1517 0.1530 

[TRAIN] Epoch[8](644/1500); Loss: 0.125909; Backpropagation: 0.0924 sec; Batch: 0.4244 sec
0.1690 0.1499 0.1436 0.1305 0.1250 0.1203 0.1268 0.1227 0.1183 0.1141 0.1153 0.1139 0.1154 0.1152 0.1170 0.1176 

[TRAIN] Epoch[8](645/1500); Loss: 0.123219; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1561 0.1412 0.1500 0.1340 0.1200 0.1208 0.1203 0.1208 0.1228 0.1129 0.1111 0.1116 0.1089 0.1128 0.1119 0.1163 

[TRAIN] Epoch[8](646/1500); Loss: 0.124213; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1470 0.1346 0.1577 0.1488 0.1352 0.1223 0.1095 0.1105 0.1183 0.1110 0.1102 0.1128 0.1139 0.1157 0.1179 0.1220 

[TRAIN] Epoch[8](647/1500); Loss: 0.104427; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1115 0.1083 0.1095 0.1112 0.1068 0.1022 0.1044 0.1039 0.0991 0.1002 0.0990 0.1008 0.1009 0.1030 0.1040 0.1061 

[TRAIN] Epoch[8](648/1500); Loss: 0.078312; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.0796 0.0758 0.0779 0.0767 0.0735 0.0762 0.0750 0.0744 0.0750 0.0749 0.0765 0.0783 0.0804 0.0833 0.0856 0.0899 

[TRAIN] Epoch[8](649/1500); Loss: 0.129210; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1525 0.1423 0.1440 0.1369 0.1271 0.1246 0.1298 0.1263 0.1218 0.1223 0.1221 0.1220 0.1217 0.1233 0.1245 0.1260 

[TRAIN] Epoch[8](650/1500); Loss: 0.088936; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.0983 0.0869 0.0875 0.0869 0.0829 0.0872 0.0839 0.0838 0.0827 0.0848 0.0855 0.0882 0.0911 0.0941 0.0981 0.1012 

[TRAIN] Epoch[8](651/1500); Loss: 0.111004; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1610 0.1429 0.1131 0.1070 0.0968 0.0951 0.0980 0.1028 0.1022 0.1003 0.1023 0.1042 0.1079 0.1110 0.1135 0.1180 

[TRAIN] Epoch[8](652/1500); Loss: 0.173464; Backpropagation: 0.0923 sec; Batch: 0.4240 sec
0.2424 0.2170 0.2067 0.1801 0.1655 0.1756 0.1744 0.1709 0.1674 0.1584 0.1580 0.1530 0.1528 0.1507 0.1518 0.1508 

[TRAIN] Epoch[8](653/1500); Loss: 0.273174; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.3617 0.3485 0.3464 0.3216 0.2942 0.2647 0.2381 0.2409 0.2521 0.2492 0.2430 0.2424 0.2413 0.2397 0.2439 0.2429 

[TRAIN] Epoch[8](654/1500); Loss: 0.126442; Backpropagation: 0.0926 sec; Batch: 0.4245 sec
0.1498 0.1384 0.1166 0.1149 0.1113 0.1155 0.1205 0.1252 0.1239 0.1241 0.1248 0.1259 0.1280 0.1314 0.1346 0.1381 

[TRAIN] Epoch[8](655/1500); Loss: 0.109418; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1052 0.1030 0.1078 0.0969 0.0984 0.1016 0.1046 0.1105 0.1054 0.1110 0.1099 0.1126 0.1144 0.1203 0.1230 0.1261 

[TRAIN] Epoch[8](656/1500); Loss: 0.066747; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1431 0.1290 0.0748 0.0486 0.0472 0.0450 0.0456 0.0511 0.0531 0.0538 0.0551 0.0577 0.0603 0.0637 0.0673 0.0723 

[TRAIN] Epoch[8](657/1500); Loss: 0.133772; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1803 0.1712 0.1355 0.1259 0.1249 0.1268 0.1292 0.1251 0.1229 0.1252 0.1257 0.1283 0.1272 0.1292 0.1300 0.1328 

[TRAIN] Epoch[8](658/1500); Loss: 0.124890; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1396 0.1355 0.1131 0.1184 0.1256 0.1213 0.1270 0.1236 0.1269 0.1212 0.1244 0.1225 0.1238 0.1231 0.1263 0.1260 

[TRAIN] Epoch[8](659/1500); Loss: 0.083207; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1667 0.1390 0.1094 0.0728 0.0553 0.0794 0.0822 0.0755 0.0655 0.0677 0.0654 0.0668 0.0667 0.0707 0.0721 0.0760 

[TRAIN] Epoch[8](660/1500); Loss: 0.106867; Backpropagation: 0.0926 sec; Batch: 0.4244 sec
0.1316 0.1178 0.0924 0.0903 0.0881 0.0906 0.0989 0.1005 0.1005 0.1041 0.1068 0.1092 0.1129 0.1182 0.1219 0.1262 

[TRAIN] Epoch[8](661/1500); Loss: 0.150476; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1559 0.1495 0.1461 0.1498 0.1565 0.1582 0.1517 0.1483 0.1471 0.1470 0.1466 0.1472 0.1484 0.1499 0.1520 0.1535 

[TRAIN] Epoch[8](662/1500); Loss: 0.064713; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0479 0.0596 0.0565 0.0516 0.0579 0.0552 0.0611 0.0668 0.0641 0.0664 0.0684 0.0694 0.0714 0.0775 0.0796 0.0819 

[TRAIN] Epoch[8](663/1500); Loss: 0.119122; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2103 0.1950 0.0950 0.1128 0.0938 0.0978 0.0899 0.1080 0.1022 0.1041 0.1053 0.1096 0.1136 0.1172 0.1231 0.1283 

[TRAIN] Epoch[8](664/1500); Loss: 0.116630; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1472 0.1323 0.1179 0.1070 0.1146 0.1182 0.1151 0.1150 0.1149 0.1089 0.1114 0.1081 0.1128 0.1115 0.1163 0.1149 

[TRAIN] Epoch[8](665/1500); Loss: 0.063583; Backpropagation: 0.0919 sec; Batch: 0.4231 sec
0.0841 0.0730 0.0554 0.0488 0.0540 0.0567 0.0574 0.0570 0.0584 0.0588 0.0631 0.0638 0.0664 0.0697 0.0731 0.0778 

[TRAIN] Epoch[8](666/1500); Loss: 0.100101; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1512 0.1423 0.0893 0.0768 0.0768 0.0810 0.0861 0.0885 0.0897 0.0921 0.0952 0.0987 0.1017 0.1057 0.1107 0.1160 

[TRAIN] Epoch[8](667/1500); Loss: 0.104736; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1668 0.1440 0.0551 0.0474 0.0689 0.0567 0.0734 0.0867 0.0942 0.0988 0.1146 0.1180 0.1276 0.1337 0.1422 0.1477 

[TRAIN] Epoch[8](668/1500); Loss: 0.115138; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1481 0.1308 0.1327 0.1200 0.1100 0.1155 0.1249 0.1145 0.1059 0.1055 0.1029 0.1048 0.1038 0.1065 0.1062 0.1101 

[TRAIN] Epoch[8](669/1500); Loss: 0.099723; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1033 0.0987 0.0975 0.0966 0.0986 0.1036 0.1001 0.1024 0.0962 0.0997 0.0965 0.0997 0.0973 0.1005 0.1007 0.1042 

[TRAIN] Epoch[8](670/1500); Loss: 0.148769; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1666 0.1523 0.1429 0.1405 0.1434 0.1504 0.1524 0.1462 0.1452 0.1434 0.1450 0.1467 0.1484 0.1510 0.1512 0.1545 

[TRAIN] Epoch[8](671/1500); Loss: 0.104264; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2540 0.2149 0.1858 0.1201 0.0578 0.0736 0.0871 0.0801 0.0769 0.0744 0.0705 0.0726 0.0717 0.0749 0.0750 0.0789 

[TRAIN] Epoch[8](672/1500); Loss: 0.077965; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.0781 0.0733 0.0705 0.0663 0.0718 0.0776 0.0737 0.0785 0.0715 0.0756 0.0768 0.0784 0.0874 0.0847 0.0928 0.0903 

[TRAIN] Epoch[8](673/1500); Loss: 0.138230; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1894 0.1610 0.1615 0.1335 0.1205 0.1290 0.1406 0.1332 0.1304 0.1266 0.1292 0.1266 0.1302 0.1303 0.1329 0.1367 

[TRAIN] Epoch[8](674/1500); Loss: 0.096353; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1451 0.1305 0.0864 0.0836 0.0884 0.0784 0.0733 0.0867 0.0816 0.0876 0.0882 0.0930 0.0954 0.1034 0.1070 0.1129 

[TRAIN] Epoch[8](675/1500); Loss: 0.093828; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1013 0.0903 0.0895 0.0889 0.0902 0.0949 0.0889 0.0894 0.0869 0.0902 0.0902 0.0942 0.0958 0.1000 0.1031 0.1075 

[TRAIN] Epoch[8](676/1500); Loss: 0.127318; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1258 0.1213 0.1109 0.0930 0.1060 0.1022 0.1171 0.1264 0.1223 0.1281 0.1355 0.1382 0.1434 0.1480 0.1575 0.1614 

[TRAIN] Epoch[8](677/1500); Loss: 0.073355; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.0579 0.0622 0.0632 0.0567 0.0631 0.0631 0.0668 0.0689 0.0686 0.0748 0.0769 0.0787 0.0873 0.0908 0.0935 0.1014 

[TRAIN] Epoch[8](678/1500); Loss: 0.141650; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1950 0.1833 0.1622 0.1455 0.1368 0.1308 0.1338 0.1299 0.1310 0.1274 0.1286 0.1297 0.1308 0.1318 0.1344 0.1353 

[TRAIN] Epoch[8](679/1500); Loss: 0.099269; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1205 0.1055 0.0915 0.0940 0.1097 0.1011 0.0916 0.0947 0.0940 0.0933 0.0947 0.0999 0.0980 0.0984 0.0995 0.1019 

[TRAIN] Epoch[8](680/1500); Loss: 0.107458; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1276 0.1252 0.1071 0.1039 0.1024 0.1031 0.1035 0.1015 0.1016 0.1014 0.1013 0.1034 0.1076 0.1074 0.1100 0.1121 

[TRAIN] Epoch[8](681/1500); Loss: 0.159473; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1967 0.1779 0.1690 0.1489 0.1502 0.1585 0.1596 0.1552 0.1547 0.1464 0.1497 0.1522 0.1541 0.1565 0.1604 0.1616 

[TRAIN] Epoch[8](682/1500); Loss: 0.126965; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1430 0.1331 0.1370 0.1375 0.1327 0.1241 0.1271 0.1203 0.1217 0.1192 0.1226 0.1187 0.1222 0.1213 0.1255 0.1254 

[TRAIN] Epoch[8](683/1500); Loss: 0.136682; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1786 0.1612 0.1483 0.1381 0.1334 0.1350 0.1343 0.1306 0.1301 0.1279 0.1280 0.1270 0.1273 0.1281 0.1287 0.1306 

[TRAIN] Epoch[8](684/1500); Loss: 0.111286; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1303 0.1191 0.1085 0.0957 0.1055 0.1005 0.0986 0.1011 0.1021 0.1058 0.1116 0.1118 0.1144 0.1208 0.1250 0.1296 

[TRAIN] Epoch[8](685/1500); Loss: 0.202151; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.2008 0.1936 0.1916 0.1884 0.1921 0.1995 0.2080 0.2059 0.2057 0.2048 0.2055 0.2052 0.2072 0.2066 0.2093 0.2103 

[TRAIN] Epoch[8](686/1500); Loss: 0.143164; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1551 0.1361 0.1293 0.1590 0.1628 0.1417 0.1405 0.1374 0.1387 0.1382 0.1386 0.1389 0.1443 0.1415 0.1437 0.1447 

[TRAIN] Epoch[8](687/1500); Loss: 0.119031; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1665 0.1506 0.1266 0.1098 0.1178 0.1158 0.1127 0.1121 0.1114 0.1090 0.1100 0.1092 0.1134 0.1108 0.1144 0.1144 

[TRAIN] Epoch[8](688/1500); Loss: 0.143874; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1438 0.1393 0.1330 0.1308 0.1348 0.1465 0.1393 0.1450 0.1403 0.1436 0.1428 0.1478 0.1479 0.1523 0.1542 0.1606 

[TRAIN] Epoch[8](689/1500); Loss: 0.155932; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2280 0.2077 0.1871 0.1563 0.1381 0.1464 0.1469 0.1434 0.1405 0.1426 0.1396 0.1394 0.1424 0.1423 0.1454 0.1489 

[TRAIN] Epoch[8](690/1500); Loss: 0.130447; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1731 0.1458 0.1316 0.1196 0.1377 0.1300 0.1248 0.1185 0.1228 0.1201 0.1233 0.1237 0.1263 0.1255 0.1319 0.1325 

[TRAIN] Epoch[8](691/1500); Loss: 0.119094; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1938 0.1792 0.1543 0.1262 0.1089 0.0982 0.0953 0.1010 0.0992 0.1005 0.1020 0.1037 0.1063 0.1096 0.1122 0.1150 

[TRAIN] Epoch[8](692/1500); Loss: 0.127929; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1650 0.1385 0.1243 0.1274 0.1397 0.1334 0.1286 0.1223 0.1213 0.1178 0.1203 0.1174 0.1212 0.1209 0.1253 0.1233 

[TRAIN] Epoch[8](693/1500); Loss: 0.102176; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1928 0.1687 0.1430 0.1117 0.0838 0.0825 0.0827 0.0797 0.0783 0.0789 0.0809 0.0812 0.0860 0.0915 0.0932 0.1000 

[TRAIN] Epoch[8](694/1500); Loss: 0.124074; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1261 0.1187 0.1254 0.1272 0.1245 0.1209 0.1204 0.1207 0.1206 0.1216 0.1226 0.1212 0.1238 0.1278 0.1313 0.1324 

[TRAIN] Epoch[8](695/1500); Loss: 0.096527; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1182 0.1045 0.0931 0.0913 0.0897 0.0886 0.0878 0.0875 0.0889 0.0902 0.0920 0.0956 0.0975 0.1028 0.1052 0.1116 

[TRAIN] Epoch[8](696/1500); Loss: 0.110166; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1186 0.1082 0.1025 0.0744 0.0912 0.0743 0.0890 0.0958 0.1022 0.1047 0.1144 0.1245 0.1306 0.1368 0.1431 0.1523 

[TRAIN] Epoch[8](697/1500); Loss: 0.074469; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.0819 0.0707 0.0787 0.0715 0.0704 0.0749 0.0675 0.0691 0.0661 0.0760 0.0704 0.0748 0.0749 0.0789 0.0804 0.0854 

[TRAIN] Epoch[8](698/1500); Loss: 0.146140; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2231 0.2005 0.1830 0.1500 0.1201 0.1321 0.1304 0.1281 0.1287 0.1313 0.1285 0.1292 0.1356 0.1368 0.1384 0.1425 

[TRAIN] Epoch[8](699/1500); Loss: 0.082167; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.0931 0.0848 0.0796 0.0713 0.0724 0.0837 0.0801 0.0811 0.0784 0.0794 0.0803 0.0811 0.0832 0.0853 0.0894 0.0915 

[TRAIN] Epoch[8](700/1500); Loss: 0.081281; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1099 0.0992 0.0954 0.0813 0.0789 0.0735 0.0663 0.0668 0.0696 0.0718 0.0731 0.0757 0.0788 0.0826 0.0859 0.0916 

[TRAIN] Epoch[8](701/1500); Loss: 0.175502; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2173 0.2030 0.1814 0.1702 0.1695 0.1718 0.1672 0.1631 0.1637 0.1655 0.1671 0.1688 0.1709 0.1745 0.1756 0.1784 

[TRAIN] Epoch[8](702/1500); Loss: 0.129340; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.1671 0.1555 0.1247 0.1277 0.1243 0.1199 0.1233 0.1203 0.1265 0.1218 0.1234 0.1244 0.1239 0.1261 0.1293 0.1314 

[TRAIN] Epoch[8](703/1500); Loss: 0.096136; Backpropagation: 0.0975 sec; Batch: 0.4304 sec
0.2070 0.1684 0.1222 0.0805 0.0843 0.0930 0.0854 0.0801 0.0758 0.0746 0.0733 0.0751 0.0756 0.0785 0.0806 0.0836 

[TRAIN] Epoch[8](704/1500); Loss: 0.087086; Backpropagation: 0.0974 sec; Batch: 0.4302 sec
0.1893 0.1469 0.1020 0.0793 0.0908 0.0849 0.0674 0.0655 0.0639 0.0664 0.0666 0.0687 0.0703 0.0744 0.0764 0.0807 

[TRAIN] Epoch[8](705/1500); Loss: 0.211800; Backpropagation: 0.0976 sec; Batch: 0.4298 sec
0.2860 0.2673 0.2437 0.2265 0.2162 0.2099 0.2065 0.2030 0.1990 0.1933 0.1921 0.1906 0.1903 0.1870 0.1898 0.1877 

[TRAIN] Epoch[8](706/1500); Loss: 0.135802; Backpropagation: 0.0952 sec; Batch: 0.4274 sec
0.1328 0.1267 0.1288 0.1321 0.1381 0.1414 0.1371 0.1315 0.1307 0.1304 0.1322 0.1356 0.1409 0.1419 0.1441 0.1483 

[TRAIN] Epoch[8](707/1500); Loss: 0.170098; Backpropagation: 0.0935 sec; Batch: 0.4256 sec
0.2087 0.1984 0.1788 0.1724 0.1753 0.1703 0.1668 0.1646 0.1580 0.1594 0.1582 0.1591 0.1595 0.1627 0.1629 0.1665 

[TRAIN] Epoch[8](708/1500); Loss: 0.092849; Backpropagation: 0.0934 sec; Batch: 0.4253 sec
0.1519 0.1416 0.1006 0.0815 0.0820 0.0821 0.0803 0.0830 0.0827 0.0832 0.0824 0.0831 0.0839 0.0866 0.0890 0.0917 

[TRAIN] Epoch[8](709/1500); Loss: 0.103259; Backpropagation: 0.0936 sec; Batch: 0.4253 sec
0.1510 0.1443 0.0897 0.0882 0.0845 0.0891 0.0906 0.0897 0.0919 0.0944 0.0972 0.1020 0.1052 0.1073 0.1120 0.1149 

[TRAIN] Epoch[8](710/1500); Loss: 0.155145; Backpropagation: 0.0933 sec; Batch: 0.4246 sec
0.1816 0.1667 0.1514 0.1520 0.1702 0.1716 0.1625 0.1543 0.1518 0.1477 0.1456 0.1445 0.1446 0.1450 0.1457 0.1471 

[TRAIN] Epoch[8](711/1500); Loss: 0.106594; Backpropagation: 0.0935 sec; Batch: 0.4251 sec
0.1230 0.1066 0.1084 0.1022 0.1038 0.1137 0.1084 0.1018 0.0999 0.1006 0.0994 0.1022 0.1047 0.1085 0.1086 0.1138 

[TRAIN] Epoch[8](712/1500); Loss: 0.143320; Backpropagation: 0.0933 sec; Batch: 0.4252 sec
0.1626 0.1560 0.1401 0.1304 0.1317 0.1329 0.1344 0.1391 0.1384 0.1384 0.1397 0.1434 0.1449 0.1495 0.1539 0.1577 

[TRAIN] Epoch[8](713/1500); Loss: 0.155170; Backpropagation: 0.0934 sec; Batch: 0.4249 sec
0.2338 0.2150 0.1698 0.1509 0.1361 0.1326 0.1388 0.1416 0.1408 0.1414 0.1413 0.1450 0.1459 0.1487 0.1496 0.1513 

[TRAIN] Epoch[8](714/1500); Loss: 0.154554; Backpropagation: 0.0931 sec; Batch: 0.4253 sec
0.3227 0.2941 0.2341 0.1726 0.1272 0.1077 0.1066 0.1169 0.1226 0.1210 0.1190 0.1209 0.1225 0.1254 0.1271 0.1326 

[TRAIN] Epoch[8](715/1500); Loss: 0.096436; Backpropagation: 0.0935 sec; Batch: 0.4252 sec
0.1276 0.1136 0.0847 0.0848 0.0875 0.0870 0.0894 0.0874 0.0909 0.0901 0.0924 0.0944 0.0980 0.1017 0.1050 0.1084 

[TRAIN] Epoch[8](716/1500); Loss: 0.102253; Backpropagation: 0.0933 sec; Batch: 0.4247 sec
0.1281 0.1238 0.0947 0.0887 0.0933 0.0957 0.0960 0.0936 0.0961 0.0958 0.0983 0.0996 0.1036 0.1058 0.1099 0.1132 

[TRAIN] Epoch[8](717/1500); Loss: 0.115366; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1395 0.1353 0.1090 0.1063 0.1159 0.1173 0.1113 0.1078 0.1077 0.1084 0.1083 0.1109 0.1129 0.1154 0.1186 0.1212 

[TRAIN] Epoch[8](718/1500); Loss: 0.150460; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1607 0.1542 0.1461 0.1347 0.1410 0.1371 0.1401 0.1506 0.1485 0.1462 0.1487 0.1519 0.1555 0.1597 0.1637 0.1686 

[TRAIN] Epoch[8](719/1500); Loss: 0.141907; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1556 0.1432 0.1369 0.1343 0.1344 0.1356 0.1360 0.1318 0.1337 0.1339 0.1374 0.1423 0.1455 0.1501 0.1567 0.1630 

[TRAIN] Epoch[8](720/1500); Loss: 0.129489; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1504 0.1383 0.1225 0.1183 0.1234 0.1278 0.1247 0.1229 0.1238 0.1237 0.1253 0.1282 0.1311 0.1339 0.1365 0.1410 

[TRAIN] Epoch[8](721/1500); Loss: 0.181621; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.2111 0.1963 0.1775 0.1649 0.1792 0.1800 0.1756 0.1736 0.1734 0.1721 0.1757 0.1802 0.1830 0.1856 0.1872 0.1908 

[TRAIN] Epoch[8](722/1500); Loss: 0.130201; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1676 0.1524 0.1343 0.1188 0.1307 0.1360 0.1266 0.1258 0.1216 0.1222 0.1208 0.1220 0.1233 0.1247 0.1273 0.1291 

[TRAIN] Epoch[8](723/1500); Loss: 0.114124; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.1620 0.1590 0.1320 0.1176 0.1073 0.1033 0.1068 0.1013 0.0999 0.1002 0.1001 0.1026 0.1043 0.1067 0.1097 0.1132 

[TRAIN] Epoch[8](724/1500); Loss: 0.133390; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1707 0.1610 0.1305 0.1305 0.1296 0.1263 0.1285 0.1288 0.1253 0.1272 0.1248 0.1278 0.1274 0.1311 0.1315 0.1333 

[TRAIN] Epoch[8](725/1500); Loss: 0.102820; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1125 0.1030 0.0935 0.1095 0.1250 0.1155 0.1018 0.0989 0.0938 0.0970 0.0945 0.0973 0.0969 0.1000 0.1015 0.1045 

[TRAIN] Epoch[8](726/1500); Loss: 0.143249; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1769 0.1645 0.1461 0.1360 0.1430 0.1478 0.1408 0.1367 0.1349 0.1329 0.1343 0.1357 0.1369 0.1391 0.1415 0.1448 

[TRAIN] Epoch[8](727/1500); Loss: 0.126223; Backpropagation: 0.0923 sec; Batch: 0.4248 sec
0.2217 0.1870 0.1483 0.1223 0.1212 0.1277 0.1278 0.1201 0.1104 0.1041 0.1025 0.1022 0.1043 0.1046 0.1072 0.1081 

[TRAIN] Epoch[8](728/1500); Loss: 0.126258; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1401 0.1289 0.1308 0.1252 0.1249 0.1324 0.1245 0.1192 0.1158 0.1184 0.1170 0.1207 0.1226 0.1277 0.1325 0.1394 

[TRAIN] Epoch[8](729/1500); Loss: 0.152619; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.2126 0.1928 0.1813 0.1600 0.1474 0.1473 0.1439 0.1351 0.1335 0.1338 0.1372 0.1375 0.1408 0.1433 0.1466 0.1487 

[TRAIN] Epoch[8](730/1500); Loss: 0.148164; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2031 0.1706 0.1424 0.1392 0.1635 0.1709 0.1546 0.1413 0.1372 0.1333 0.1344 0.1333 0.1360 0.1349 0.1377 0.1382 

[TRAIN] Epoch[8](731/1500); Loss: 0.149639; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1526 0.1483 0.1371 0.1380 0.1495 0.1561 0.1485 0.1482 0.1469 0.1486 0.1492 0.1504 0.1515 0.1542 0.1560 0.1592 

[TRAIN] Epoch[8](732/1500); Loss: 0.103254; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1270 0.1031 0.0994 0.0883 0.1005 0.1152 0.1045 0.0993 0.0951 0.0968 0.0987 0.0997 0.1030 0.1036 0.1083 0.1096 

[TRAIN] Epoch[8](733/1500); Loss: 0.149549; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1541 0.1471 0.1439 0.1486 0.1515 0.1504 0.1487 0.1462 0.1473 0.1467 0.1479 0.1479 0.1503 0.1513 0.1545 0.1564 

[TRAIN] Epoch[8](734/1500); Loss: 0.146151; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1755 0.1632 0.1388 0.1384 0.1413 0.1486 0.1434 0.1389 0.1379 0.1361 0.1387 0.1406 0.1439 0.1468 0.1505 0.1558 

[TRAIN] Epoch[8](735/1500); Loss: 0.117843; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1136 0.1153 0.1112 0.1163 0.1165 0.1152 0.1145 0.1135 0.1144 0.1168 0.1175 0.1204 0.1209 0.1237 0.1265 0.1291 

[TRAIN] Epoch[8](736/1500); Loss: 0.134894; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1415 0.1268 0.1135 0.1263 0.1500 0.1567 0.1449 0.1360 0.1313 0.1315 0.1304 0.1314 0.1309 0.1333 0.1357 0.1380 

[TRAIN] Epoch[8](737/1500); Loss: 0.159156; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1682 0.1676 0.1497 0.1536 0.1556 0.1581 0.1558 0.1590 0.1557 0.1572 0.1562 0.1582 0.1589 0.1623 0.1637 0.1668 

[TRAIN] Epoch[8](738/1500); Loss: 0.157770; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.2189 0.2043 0.1728 0.1593 0.1549 0.1562 0.1560 0.1512 0.1487 0.1473 0.1415 0.1426 0.1418 0.1421 0.1427 0.1440 

[TRAIN] Epoch[8](739/1500); Loss: 0.137890; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1470 0.1393 0.1333 0.1399 0.1479 0.1433 0.1373 0.1328 0.1325 0.1304 0.1321 0.1325 0.1361 0.1369 0.1411 0.1437 

[TRAIN] Epoch[8](740/1500); Loss: 0.116269; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.2052 0.1823 0.1355 0.1129 0.1003 0.1105 0.1102 0.0994 0.1008 0.0957 0.0971 0.0978 0.1018 0.1009 0.1046 0.1052 

[TRAIN] Epoch[8](741/1500); Loss: 0.104475; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1251 0.1092 0.1097 0.1097 0.1012 0.0984 0.0950 0.0916 0.0872 0.0918 0.0958 0.1011 0.1045 0.1112 0.1185 0.1217 

[TRAIN] Epoch[8](742/1500); Loss: 0.110410; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1391 0.1188 0.1051 0.1120 0.1231 0.1218 0.1113 0.1040 0.1041 0.1017 0.1011 0.1025 0.1027 0.1043 0.1063 0.1086 

[TRAIN] Epoch[8](743/1500); Loss: 0.096677; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2657 0.2173 0.1508 0.0722 0.0594 0.0772 0.0671 0.0697 0.0652 0.0689 0.0664 0.0695 0.0699 0.0724 0.0756 0.0793 

[TRAIN] Epoch[8](744/1500); Loss: 0.087612; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1053 0.0735 0.0853 0.0675 0.0686 0.0870 0.0890 0.0768 0.0765 0.0836 0.0841 0.0903 0.0966 0.1001 0.1054 0.1122 

[TRAIN] Epoch[8](745/1500); Loss: 0.094161; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1048 0.0900 0.1045 0.1090 0.1067 0.1003 0.0927 0.0855 0.0847 0.0835 0.0852 0.0868 0.0885 0.0913 0.0944 0.0989 

[TRAIN] Epoch[8](746/1500); Loss: 0.125488; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1503 0.1418 0.1262 0.1276 0.1328 0.1322 0.1218 0.1215 0.1153 0.1174 0.1153 0.1172 0.1182 0.1212 0.1229 0.1262 

[TRAIN] Epoch[8](747/1500); Loss: 0.090854; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2360 0.1841 0.1169 0.0693 0.0809 0.0967 0.0738 0.0648 0.0630 0.0618 0.0629 0.0642 0.0662 0.0677 0.0710 0.0742 

[TRAIN] Epoch[8](748/1500); Loss: 0.165013; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.2126 0.2007 0.1782 0.1631 0.1618 0.1646 0.1599 0.1578 0.1532 0.1549 0.1549 0.1545 0.1542 0.1565 0.1555 0.1577 

[TRAIN] Epoch[8](749/1500); Loss: 0.086771; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1112 0.1007 0.0919 0.0844 0.0888 0.0889 0.0804 0.0791 0.0771 0.0785 0.0787 0.0807 0.0834 0.0849 0.0889 0.0908 

[TRAIN] Epoch[8](750/1500); Loss: 0.132093; Backpropagation: 0.0916 sec; Batch: 0.4229 sec
0.1434 0.1380 0.1097 0.0971 0.1175 0.1075 0.1131 0.1269 0.1294 0.1301 0.1367 0.1434 0.1471 0.1523 0.1591 0.1623 

[TRAIN] Epoch[8](751/1500); Loss: 0.128470; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2265 0.2033 0.1343 0.1062 0.1131 0.1304 0.1146 0.1055 0.1138 0.1098 0.1078 0.1106 0.1154 0.1171 0.1217 0.1255 

[TRAIN] Epoch[8](752/1500); Loss: 0.088045; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1261 0.1010 0.0777 0.0962 0.1031 0.0805 0.0805 0.0751 0.0796 0.0768 0.0803 0.0796 0.0841 0.0854 0.0901 0.0926 

[TRAIN] Epoch[8](753/1500); Loss: 0.141802; Backpropagation: 0.0926 sec; Batch: 0.4260 sec
0.1846 0.1773 0.1550 0.1369 0.1351 0.1359 0.1341 0.1339 0.1317 0.1308 0.1322 0.1345 0.1339 0.1361 0.1373 0.1394 

[TRAIN] Epoch[8](754/1500); Loss: 0.072345; Backpropagation: 0.0923 sec; Batch: 0.4247 sec
0.0663 0.0578 0.0747 0.0902 0.0764 0.0678 0.0629 0.0622 0.0643 0.0666 0.0693 0.0725 0.0757 0.0789 0.0837 0.0882 

[TRAIN] Epoch[8](755/1500); Loss: 0.087890; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1172 0.0997 0.0983 0.0862 0.0758 0.0937 0.0937 0.0835 0.0779 0.0782 0.0781 0.0800 0.0821 0.0839 0.0876 0.0903 

[TRAIN] Epoch[8](756/1500); Loss: 0.148707; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1585 0.1505 0.1570 0.1625 0.1612 0.1518 0.1483 0.1425 0.1430 0.1408 0.1423 0.1409 0.1430 0.1431 0.1459 0.1479 

[TRAIN] Epoch[8](757/1500); Loss: 0.133498; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1857 0.1679 0.1529 0.1322 0.1281 0.1460 0.1352 0.1194 0.1167 0.1166 0.1195 0.1221 0.1219 0.1226 0.1242 0.1249 

[TRAIN] Epoch[8](758/1500); Loss: 0.095185; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.0900 0.0869 0.0907 0.0650 0.0832 0.0774 0.0907 0.0844 0.0965 0.0940 0.0960 0.1070 0.1070 0.1121 0.1170 0.1253 

[TRAIN] Epoch[8](759/1500); Loss: 0.131723; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1502 0.1461 0.1364 0.1281 0.1236 0.1299 0.1256 0.1234 0.1238 0.1276 0.1283 0.1285 0.1304 0.1325 0.1357 0.1376 

[TRAIN] Epoch[8](760/1500); Loss: 0.078769; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1241 0.1001 0.0772 0.0826 0.0961 0.0819 0.0657 0.0699 0.0633 0.0677 0.0650 0.0679 0.0696 0.0731 0.0758 0.0803 

[TRAIN] Epoch[8](761/1500); Loss: 0.131943; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1348 0.1248 0.1300 0.1283 0.1323 0.1370 0.1285 0.1307 0.1262 0.1278 0.1308 0.1301 0.1323 0.1363 0.1389 0.1422 

[TRAIN] Epoch[8](762/1500); Loss: 0.142177; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1719 0.1629 0.1300 0.1307 0.1372 0.1469 0.1471 0.1368 0.1361 0.1321 0.1349 0.1364 0.1393 0.1416 0.1430 0.1479 

[TRAIN] Epoch[8](763/1500); Loss: 0.162495; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1774 0.1729 0.1662 0.1719 0.1710 0.1632 0.1630 0.1624 0.1582 0.1561 0.1533 0.1549 0.1545 0.1562 0.1573 0.1614 

[TRAIN] Epoch[8](764/1500); Loss: 0.083866; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.0765 0.0664 0.0630 0.0642 0.0939 0.1025 0.0808 0.0760 0.0813 0.0806 0.0875 0.0851 0.0920 0.0930 0.0984 0.1005 

[TRAIN] Epoch[8](765/1500); Loss: 0.117066; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1866 0.1627 0.1334 0.1142 0.1137 0.1194 0.1018 0.0969 0.1008 0.0974 0.1021 0.1016 0.1053 0.1091 0.1123 0.1159 

[TRAIN] Epoch[8](766/1500); Loss: 0.123270; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1465 0.1392 0.1201 0.1157 0.1146 0.1171 0.1199 0.1200 0.1191 0.1190 0.1192 0.1198 0.1209 0.1239 0.1276 0.1297 

[TRAIN] Epoch[8](767/1500); Loss: 0.185301; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2446 0.2266 0.2111 0.1921 0.1726 0.1869 0.1785 0.1704 0.1700 0.1673 0.1702 0.1704 0.1730 0.1751 0.1783 0.1778 

[TRAIN] Epoch[8](768/1500); Loss: 0.071146; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.0615 0.0761 0.0559 0.0573 0.0601 0.0667 0.0636 0.0638 0.0690 0.0688 0.0744 0.0742 0.0808 0.0850 0.0884 0.0928 

[TRAIN] Epoch[8](769/1500); Loss: 0.097383; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1363 0.1234 0.0810 0.0776 0.0811 0.0709 0.0725 0.0811 0.0887 0.0878 0.0922 0.0999 0.1083 0.1120 0.1193 0.1261 

[TRAIN] Epoch[8](770/1500); Loss: 0.165642; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.2299 0.2145 0.1880 0.1665 0.1525 0.1507 0.1498 0.1488 0.1480 0.1485 0.1517 0.1548 0.1566 0.1586 0.1628 0.1686 

[TRAIN] Epoch[8](771/1500); Loss: 0.107102; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1371 0.1169 0.1050 0.1132 0.1176 0.1064 0.1031 0.0989 0.0987 0.0980 0.0995 0.1005 0.1021 0.1030 0.1058 0.1077 

[TRAIN] Epoch[8](772/1500); Loss: 0.104840; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1129 0.1136 0.1021 0.1013 0.1005 0.1015 0.1000 0.1005 0.1010 0.1024 0.1029 0.1043 0.1056 0.1082 0.1094 0.1112 

[TRAIN] Epoch[8](773/1500); Loss: 0.102324; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1174 0.1108 0.0995 0.0973 0.0942 0.0934 0.0916 0.0945 0.0948 0.0975 0.0985 0.1018 0.1048 0.1094 0.1142 0.1176 

[TRAIN] Epoch[8](774/1500); Loss: 0.129242; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1614 0.1522 0.1371 0.1221 0.1174 0.1270 0.1191 0.1194 0.1197 0.1250 0.1231 0.1247 0.1256 0.1291 0.1307 0.1344 

[TRAIN] Epoch[8](775/1500); Loss: 0.126590; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1590 0.1501 0.1099 0.1054 0.1113 0.1107 0.1130 0.1186 0.1240 0.1229 0.1261 0.1277 0.1316 0.1350 0.1379 0.1421 

[TRAIN] Epoch[8](776/1500); Loss: 0.090963; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.0901 0.0845 0.0892 0.0825 0.0818 0.0865 0.0889 0.0874 0.0870 0.0903 0.0921 0.0942 0.0965 0.0979 0.1029 0.1036 

[TRAIN] Epoch[8](777/1500); Loss: 0.115748; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1330 0.1292 0.1123 0.1095 0.1081 0.1117 0.1091 0.1093 0.1106 0.1107 0.1146 0.1143 0.1164 0.1181 0.1227 0.1225 

[TRAIN] Epoch[8](778/1500); Loss: 0.080725; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1244 0.1022 0.0877 0.0868 0.0713 0.0743 0.0670 0.0705 0.0675 0.0728 0.0715 0.0754 0.0760 0.0791 0.0808 0.0841 

[TRAIN] Epoch[8](779/1500); Loss: 0.098315; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.0931 0.0895 0.1138 0.1042 0.1009 0.0983 0.0966 0.0940 0.0971 0.0956 0.0953 0.0974 0.0986 0.0980 0.0990 0.1017 

[TRAIN] Epoch[8](780/1500); Loss: 0.146810; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.3489 0.2954 0.2232 0.1714 0.1210 0.1029 0.0936 0.1004 0.1039 0.1059 0.1064 0.1097 0.1131 0.1142 0.1170 0.1219 

[TRAIN] Epoch[8](781/1500); Loss: 0.122388; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1231 0.1150 0.1128 0.1184 0.1190 0.1198 0.1169 0.1188 0.1196 0.1223 0.1228 0.1258 0.1271 0.1293 0.1322 0.1351 

[TRAIN] Epoch[8](782/1500); Loss: 0.110845; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1866 0.1630 0.1334 0.1154 0.0996 0.0931 0.0889 0.0934 0.0903 0.0938 0.0953 0.0974 0.0993 0.1035 0.1083 0.1122 

[TRAIN] Epoch[8](783/1500); Loss: 0.109373; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.1486 0.1346 0.1141 0.1026 0.0989 0.1012 0.0999 0.1010 0.1011 0.1025 0.1033 0.1055 0.1066 0.1075 0.1097 0.1128 

[TRAIN] Epoch[8](784/1500); Loss: 0.144037; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.2135 0.1918 0.1554 0.1451 0.1337 0.1333 0.1331 0.1280 0.1296 0.1316 0.1321 0.1329 0.1328 0.1351 0.1373 0.1393 

[TRAIN] Epoch[8](785/1500); Loss: 0.093889; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1697 0.1499 0.0492 0.0469 0.0922 0.0614 0.0494 0.0969 0.0647 0.1233 0.0954 0.0793 0.0966 0.1078 0.1056 0.1137 

[TRAIN] Epoch[8](786/1500); Loss: 0.072401; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.0793 0.0873 0.0633 0.0630 0.0628 0.0652 0.0671 0.0670 0.0688 0.0666 0.0733 0.0743 0.0777 0.0774 0.0816 0.0837 

[TRAIN] Epoch[8](787/1500); Loss: 0.108580; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1490 0.1350 0.0976 0.0984 0.0950 0.0970 0.0972 0.1028 0.1003 0.1013 0.1039 0.1060 0.1087 0.1110 0.1153 0.1185 

[TRAIN] Epoch[8](788/1500); Loss: 0.087700; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.0930 0.0886 0.0889 0.0899 0.0885 0.0861 0.0848 0.0833 0.0837 0.0839 0.0856 0.0860 0.0880 0.0886 0.0910 0.0934 

[TRAIN] Epoch[8](789/1500); Loss: 0.158016; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.2053 0.1913 0.1737 0.1581 0.1531 0.1514 0.1438 0.1426 0.1444 0.1452 0.1479 0.1521 0.1521 0.1526 0.1558 0.1589 

[TRAIN] Epoch[8](790/1500); Loss: 0.154192; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1972 0.1769 0.1511 0.1456 0.1451 0.1461 0.1460 0.1462 0.1472 0.1463 0.1485 0.1492 0.1516 0.1553 0.1570 0.1579 

[TRAIN] Epoch[8](791/1500); Loss: 0.179431; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1816 0.1786 0.1744 0.1785 0.1808 0.1940 0.1846 0.1790 0.1795 0.1755 0.1749 0.1780 0.1763 0.1766 0.1778 0.1808 

[TRAIN] Epoch[8](792/1500); Loss: 0.151398; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1744 0.1601 0.1505 0.1440 0.1432 0.1539 0.1438 0.1457 0.1442 0.1462 0.1455 0.1479 0.1507 0.1546 0.1564 0.1612 

[TRAIN] Epoch[8](793/1500); Loss: 0.134491; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1585 0.1444 0.1299 0.1303 0.1277 0.1298 0.1310 0.1289 0.1298 0.1311 0.1302 0.1312 0.1349 0.1357 0.1380 0.1404 

[TRAIN] Epoch[8](794/1500); Loss: 0.118375; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1235 0.1251 0.1218 0.1224 0.1168 0.1165 0.1120 0.1151 0.1127 0.1166 0.1141 0.1167 0.1166 0.1198 0.1208 0.1235 

[TRAIN] Epoch[8](795/1500); Loss: 0.096732; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1267 0.1114 0.0872 0.0884 0.0920 0.0977 0.0927 0.0952 0.0869 0.0892 0.0900 0.0949 0.0963 0.0974 0.1001 0.1017 

[TRAIN] Epoch[8](796/1500); Loss: 0.079374; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1256 0.0936 0.0904 0.0740 0.0669 0.0769 0.0758 0.0714 0.0732 0.0699 0.0718 0.0711 0.0747 0.0757 0.0788 0.0801 

[TRAIN] Epoch[8](797/1500); Loss: 0.128047; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1453 0.1441 0.1352 0.1324 0.1256 0.1272 0.1239 0.1260 0.1221 0.1220 0.1226 0.1241 0.1235 0.1237 0.1257 0.1255 

[TRAIN] Epoch[8](798/1500); Loss: 0.145107; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1700 0.1597 0.1546 0.1594 0.1469 0.1418 0.1392 0.1367 0.1362 0.1359 0.1357 0.1381 0.1395 0.1407 0.1441 0.1431 

[TRAIN] Epoch[8](799/1500); Loss: 0.131572; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1282 0.1341 0.1275 0.1331 0.1395 0.1300 0.1324 0.1345 0.1337 0.1237 0.1279 0.1268 0.1363 0.1289 0.1340 0.1346 

[TRAIN] Epoch[8](800/1500); Loss: 0.123643; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2037 0.1899 0.1318 0.1086 0.1036 0.1093 0.1036 0.1045 0.1134 0.1078 0.1113 0.1117 0.1148 0.1172 0.1225 0.1247 

[TRAIN] Epoch[8](801/1500); Loss: 0.100635; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.2196 0.1821 0.1248 0.0898 0.0782 0.0863 0.0780 0.0808 0.0776 0.0793 0.0804 0.0839 0.0845 0.0858 0.0877 0.0912 

[TRAIN] Epoch[8](802/1500); Loss: 0.114715; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1564 0.1361 0.1079 0.1048 0.1056 0.1078 0.1066 0.1077 0.1066 0.1072 0.1126 0.1144 0.1139 0.1140 0.1167 0.1173 

[TRAIN] Epoch[8](803/1500); Loss: 0.087016; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2023 0.1886 0.0704 0.0648 0.0466 0.0464 0.0679 0.0671 0.0675 0.0692 0.0729 0.0772 0.0822 0.0861 0.0872 0.0958 

[TRAIN] Epoch[8](804/1500); Loss: 0.086107; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1433 0.1282 0.0562 0.0593 0.0717 0.0653 0.0608 0.0856 0.0679 0.0764 0.0826 0.0858 0.0852 0.1021 0.0992 0.1082 

[TRAIN] Epoch[8](805/1500); Loss: 0.136242; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1814 0.1706 0.1470 0.1338 0.1307 0.1293 0.1273 0.1274 0.1262 0.1281 0.1280 0.1287 0.1270 0.1295 0.1318 0.1330 

[TRAIN] Epoch[8](806/1500); Loss: 0.086344; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.0835 0.0782 0.0733 0.0791 0.0876 0.0800 0.0847 0.0814 0.0887 0.0840 0.0894 0.0879 0.0939 0.0917 0.0989 0.0993 

[TRAIN] Epoch[8](807/1500); Loss: 0.084215; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.0810 0.0817 0.0955 0.0855 0.0806 0.0788 0.0800 0.0785 0.0790 0.0805 0.0840 0.0844 0.0878 0.0884 0.0889 0.0928 

[TRAIN] Epoch[8](808/1500); Loss: 0.221330; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.2997 0.2763 0.2432 0.2284 0.2184 0.2119 0.2031 0.2043 0.2029 0.2040 0.2053 0.2045 0.2064 0.2080 0.2122 0.2129 

[TRAIN] Epoch[8](809/1500); Loss: 0.107768; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1426 0.1318 0.1079 0.0954 0.0953 0.1026 0.0962 0.0973 0.0968 0.1032 0.1025 0.1054 0.1073 0.1106 0.1144 0.1149 

[TRAIN] Epoch[8](810/1500); Loss: 0.126603; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1608 0.1504 0.1128 0.1091 0.1122 0.1097 0.1138 0.1194 0.1238 0.1193 0.1261 0.1260 0.1323 0.1343 0.1360 0.1396 

[TRAIN] Epoch[8](811/1500); Loss: 0.199711; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.3844 0.3200 0.2414 0.1847 0.1540 0.1587 0.1636 0.1634 0.1655 0.1683 0.1717 0.1746 0.1809 0.1845 0.1879 0.1919 

[TRAIN] Epoch[8](812/1500); Loss: 0.103914; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2098 0.1948 0.1061 0.0724 0.0654 0.0746 0.0813 0.0839 0.0822 0.0919 0.0838 0.0946 0.1013 0.1024 0.1050 0.1131 

[TRAIN] Epoch[8](813/1500); Loss: 0.131726; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1485 0.1406 0.1303 0.1295 0.1290 0.1278 0.1281 0.1272 0.1296 0.1308 0.1278 0.1298 0.1297 0.1321 0.1317 0.1351 

[TRAIN] Epoch[8](814/1500); Loss: 0.205574; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.2626 0.2438 0.2129 0.2075 0.2081 0.1953 0.1961 0.1931 0.1958 0.1958 0.1934 0.1951 0.1944 0.1989 0.1978 0.1987 

[TRAIN] Epoch[8](815/1500); Loss: 0.161304; Backpropagation: 0.0918 sec; Batch: 0.4321 sec
0.1772 0.1742 0.1677 0.1628 0.1610 0.1546 0.1551 0.1561 0.1533 0.1554 0.1569 0.1600 0.1577 0.1619 0.1615 0.1655 

[TRAIN] Epoch[8](816/1500); Loss: 0.163303; Backpropagation: 0.0920 sec; Batch: 0.4255 sec
0.2405 0.2175 0.1791 0.1595 0.1465 0.1485 0.1456 0.1467 0.1484 0.1499 0.1517 0.1530 0.1537 0.1544 0.1593 0.1585 

[TRAIN] Epoch[8](817/1500); Loss: 0.156887; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1598 0.1602 0.1618 0.1598 0.1556 0.1571 0.1509 0.1510 0.1488 0.1522 0.1523 0.1572 0.1559 0.1595 0.1647 0.1634 

[TRAIN] Epoch[8](818/1500); Loss: 0.093243; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1073 0.1012 0.0907 0.0872 0.0843 0.0845 0.0821 0.0834 0.0844 0.0875 0.0896 0.0935 0.0964 0.1015 0.1068 0.1114 

[TRAIN] Epoch[8](819/1500); Loss: 0.096556; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1113 0.1009 0.0975 0.0981 0.0927 0.0921 0.0905 0.0914 0.0900 0.0915 0.0926 0.0940 0.0972 0.0986 0.1022 0.1042 

[TRAIN] Epoch[8](820/1500); Loss: 0.139639; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1450 0.1416 0.1214 0.1133 0.1328 0.1483 0.1333 0.1301 0.1301 0.1342 0.1404 0.1443 0.1471 0.1520 0.1590 0.1612 

[TRAIN] Epoch[8](821/1500); Loss: 0.184315; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1816 0.1811 0.1840 0.1975 0.1925 0.1812 0.1844 0.1811 0.1813 0.1817 0.1815 0.1804 0.1832 0.1851 0.1847 0.1878 

[TRAIN] Epoch[8](822/1500); Loss: 0.094037; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1506 0.1260 0.0996 0.0853 0.0784 0.0762 0.0772 0.0806 0.0799 0.0819 0.0860 0.0875 0.0926 0.0961 0.1004 0.1063 

[TRAIN] Epoch[8](823/1500); Loss: 0.159803; Backpropagation: 0.0929 sec; Batch: 0.4249 sec
0.1592 0.1645 0.1681 0.1560 0.1597 0.1572 0.1577 0.1558 0.1562 0.1562 0.1590 0.1616 0.1573 0.1606 0.1644 0.1634 

[TRAIN] Epoch[8](824/1500); Loss: 0.091562; Backpropagation: 0.0923 sec; Batch: 0.4392 sec
0.1172 0.1012 0.0906 0.0841 0.0916 0.0867 0.0871 0.0854 0.0857 0.0857 0.0870 0.0885 0.0908 0.0926 0.0934 0.0975 

[TRAIN] Epoch[8](825/1500); Loss: 0.143737; Backpropagation: 0.0930 sec; Batch: 0.4253 sec
0.1642 0.1523 0.1398 0.1405 0.1379 0.1361 0.1344 0.1350 0.1363 0.1379 0.1402 0.1426 0.1475 0.1484 0.1504 0.1562 

[TRAIN] Epoch[8](826/1500); Loss: 0.208490; Backpropagation: 0.0923 sec; Batch: 0.4245 sec
0.3682 0.3107 0.2450 0.1918 0.1683 0.1800 0.1761 0.1754 0.1785 0.1818 0.1840 0.1875 0.1916 0.1947 0.1994 0.2027 

[TRAIN] Epoch[8](827/1500); Loss: 0.117515; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1391 0.1296 0.1046 0.1040 0.1030 0.1089 0.1096 0.1124 0.1119 0.1161 0.1188 0.1203 0.1212 0.1238 0.1273 0.1295 

[TRAIN] Epoch[8](828/1500); Loss: 0.132695; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.2537 0.2149 0.1540 0.1175 0.1107 0.1062 0.1059 0.1075 0.1107 0.1100 0.1117 0.1154 0.1205 0.1238 0.1298 0.1309 

[TRAIN] Epoch[8](829/1500); Loss: 0.148913; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2049 0.1923 0.1520 0.1392 0.1341 0.1332 0.1338 0.1344 0.1375 0.1358 0.1390 0.1437 0.1472 0.1480 0.1520 0.1555 

[TRAIN] Epoch[8](830/1500); Loss: 0.125804; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1861 0.1624 0.1312 0.1156 0.1159 0.1158 0.1101 0.1125 0.1130 0.1185 0.1182 0.1185 0.1208 0.1225 0.1247 0.1270 

[TRAIN] Epoch[8](831/1500); Loss: 0.100850; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2075 0.1858 0.0960 0.0688 0.0609 0.0682 0.0770 0.0804 0.0780 0.0805 0.0817 0.0918 0.0927 0.1138 0.1175 0.1129 

[TRAIN] Epoch[8](832/1500); Loss: 0.102134; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1511 0.1322 0.1093 0.0980 0.0892 0.0884 0.0887 0.0894 0.0902 0.0911 0.0954 0.0961 0.0997 0.1023 0.1046 0.1084 

[TRAIN] Epoch[8](833/1500); Loss: 0.138971; Backpropagation: 0.0928 sec; Batch: 0.4246 sec
0.1889 0.1768 0.1599 0.1469 0.1418 0.1357 0.1291 0.1259 0.1273 0.1239 0.1263 0.1248 0.1273 0.1272 0.1305 0.1312 

[TRAIN] Epoch[8](834/1500); Loss: 0.128890; Backpropagation: 0.0928 sec; Batch: 0.4248 sec
0.1542 0.1423 0.0996 0.0859 0.1050 0.1111 0.1155 0.1224 0.1227 0.1263 0.1374 0.1399 0.1432 0.1439 0.1529 0.1600 

[TRAIN] Epoch[8](835/1500); Loss: 0.115768; Backpropagation: 0.0929 sec; Batch: 0.4246 sec
0.1375 0.1247 0.1062 0.1070 0.1044 0.1048 0.1067 0.1072 0.1127 0.1100 0.1146 0.1153 0.1195 0.1231 0.1268 0.1319 

[TRAIN] Epoch[8](836/1500); Loss: 0.096032; Backpropagation: 0.0926 sec; Batch: 0.4243 sec
0.1073 0.1018 0.0911 0.0917 0.0851 0.0855 0.0858 0.0861 0.0879 0.0901 0.0946 0.0985 0.0998 0.1074 0.1078 0.1160 

[TRAIN] Epoch[8](837/1500); Loss: 0.097892; Backpropagation: 0.0928 sec; Batch: 0.4246 sec
0.0995 0.0936 0.1092 0.0819 0.0819 0.0924 0.0805 0.0874 0.0855 0.0964 0.0972 0.1030 0.1068 0.1147 0.1170 0.1192 

[TRAIN] Epoch[8](838/1500); Loss: 0.107119; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1271 0.1156 0.1018 0.1036 0.1011 0.1012 0.1009 0.1038 0.1032 0.1040 0.1050 0.1062 0.1074 0.1091 0.1102 0.1136 

[TRAIN] Epoch[8](839/1500); Loss: 0.181987; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.4493 0.3813 0.2887 0.2111 0.1626 0.1465 0.1215 0.1180 0.1206 0.1198 0.1318 0.1287 0.1254 0.1328 0.1353 0.1381 

[TRAIN] Epoch[8](840/1500); Loss: 0.077699; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1092 0.0838 0.0785 0.0742 0.0704 0.0684 0.0717 0.0698 0.0715 0.0735 0.0729 0.0755 0.0773 0.0798 0.0803 0.0863 

[TRAIN] Epoch[8](841/1500); Loss: 0.091872; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1499 0.1283 0.0926 0.0912 0.0831 0.0827 0.0820 0.0800 0.0787 0.0814 0.0813 0.0824 0.0869 0.0873 0.0902 0.0918 

[TRAIN] Epoch[8](842/1500); Loss: 0.149721; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1824 0.1771 0.1489 0.1405 0.1414 0.1405 0.1429 0.1416 0.1468 0.1435 0.1440 0.1453 0.1471 0.1490 0.1512 0.1533 

[TRAIN] Epoch[8](843/1500); Loss: 0.156801; Backpropagation: 0.0926 sec; Batch: 0.4242 sec
0.3068 0.2715 0.2280 0.1953 0.1771 0.1678 0.1367 0.1140 0.1159 0.1082 0.1080 0.1116 0.1141 0.1143 0.1168 0.1228 

[TRAIN] Epoch[8](844/1500); Loss: 0.136777; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1645 0.1539 0.1403 0.1354 0.1330 0.1321 0.1300 0.1297 0.1309 0.1301 0.1311 0.1333 0.1335 0.1361 0.1357 0.1390 

[TRAIN] Epoch[8](845/1500); Loss: 0.130316; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1726 0.1560 0.1282 0.1231 0.1221 0.1206 0.1207 0.1201 0.1198 0.1221 0.1233 0.1263 0.1284 0.1321 0.1326 0.1370 

[TRAIN] Epoch[8](846/1500); Loss: 0.085189; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0939 0.0855 0.0812 0.0760 0.0847 0.0759 0.0793 0.0775 0.0802 0.0821 0.0856 0.0871 0.0891 0.0930 0.0946 0.0974 

[TRAIN] Epoch[8](847/1500); Loss: 0.132726; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1518 0.1367 0.1339 0.1343 0.1293 0.1295 0.1289 0.1289 0.1274 0.1289 0.1291 0.1314 0.1309 0.1328 0.1335 0.1363 

[TRAIN] Epoch[8](848/1500); Loss: 0.109850; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1187 0.1202 0.1084 0.1060 0.1043 0.1055 0.1049 0.1067 0.1053 0.1069 0.1087 0.1092 0.1104 0.1121 0.1144 0.1158 

[TRAIN] Epoch[8](849/1500); Loss: 0.119599; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1404 0.1300 0.1253 0.1146 0.1116 0.1075 0.1109 0.1126 0.1132 0.1155 0.1167 0.1197 0.1184 0.1223 0.1246 0.1304 

[TRAIN] Epoch[8](850/1500); Loss: 0.166488; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2203 0.2010 0.1811 0.1743 0.1693 0.1645 0.1598 0.1562 0.1537 0.1540 0.1524 0.1529 0.1555 0.1549 0.1566 0.1575 

[TRAIN] Epoch[8](851/1500); Loss: 0.081376; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.0747 0.0773 0.0788 0.0746 0.0741 0.0740 0.0751 0.0757 0.0772 0.0798 0.0821 0.0854 0.0880 0.0919 0.0946 0.0988 

[TRAIN] Epoch[8](852/1500); Loss: 0.112297; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1089 0.1165 0.1050 0.1050 0.1019 0.1099 0.1043 0.1068 0.1088 0.1119 0.1121 0.1153 0.1213 0.1191 0.1235 0.1263 

[TRAIN] Epoch[8](853/1500); Loss: 0.141082; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1716 0.1650 0.1459 0.1396 0.1356 0.1336 0.1340 0.1340 0.1328 0.1335 0.1353 0.1364 0.1379 0.1392 0.1402 0.1428 

[TRAIN] Epoch[8](854/1500); Loss: 0.100483; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1602 0.1495 0.0989 0.0787 0.0803 0.0887 0.0859 0.0832 0.0939 0.0880 0.0912 0.0954 0.1010 0.1016 0.1041 0.1072 

[TRAIN] Epoch[8](855/1500); Loss: 0.071870; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1398 0.0983 0.0671 0.0613 0.0600 0.0560 0.0608 0.0602 0.0612 0.0611 0.0658 0.0661 0.0677 0.0730 0.0752 0.0763 

[TRAIN] Epoch[8](856/1500); Loss: 0.094989; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1209 0.1089 0.0967 0.0868 0.0881 0.0830 0.0850 0.0855 0.0872 0.0891 0.0924 0.0947 0.0968 0.0987 0.1015 0.1045 

[TRAIN] Epoch[8](857/1500); Loss: 0.105879; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1445 0.1222 0.1014 0.1014 0.0983 0.0978 0.0997 0.0987 0.1002 0.0997 0.1013 0.1022 0.1050 0.1055 0.1068 0.1094 

[TRAIN] Epoch[8](858/1500); Loss: 0.110715; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1415 0.1297 0.1081 0.0969 0.0960 0.1042 0.0997 0.0995 0.1022 0.1071 0.1070 0.1083 0.1149 0.1166 0.1177 0.1221 

[TRAIN] Epoch[8](859/1500); Loss: 0.111899; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1438 0.1297 0.0994 0.0983 0.0946 0.0994 0.1015 0.1020 0.1038 0.1081 0.1117 0.1127 0.1150 0.1201 0.1243 0.1262 

[TRAIN] Epoch[8](860/1500); Loss: 0.097416; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1741 0.1537 0.0483 0.0445 0.0824 0.0605 0.0556 0.0941 0.1007 0.0912 0.0839 0.1047 0.1150 0.1075 0.1158 0.1266 

[TRAIN] Epoch[8](861/1500); Loss: 0.118125; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1423 0.1309 0.1106 0.1079 0.1073 0.1081 0.1091 0.1092 0.1107 0.1134 0.1181 0.1186 0.1199 0.1249 0.1278 0.1312 

[TRAIN] Epoch[8](862/1500); Loss: 0.101653; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1876 0.1689 0.1231 0.0992 0.0964 0.0923 0.0869 0.0833 0.0813 0.0820 0.0831 0.0844 0.0859 0.0886 0.0904 0.0930 

[TRAIN] Epoch[8](863/1500); Loss: 0.151846; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1955 0.1837 0.1556 0.1440 0.1422 0.1401 0.1394 0.1397 0.1415 0.1434 0.1451 0.1474 0.1501 0.1510 0.1539 0.1569 

[TRAIN] Epoch[8](864/1500); Loss: 0.126295; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2593 0.2007 0.1290 0.1099 0.1100 0.1045 0.1001 0.1033 0.1031 0.1049 0.1105 0.1117 0.1118 0.1192 0.1200 0.1227 

[TRAIN] Epoch[8](865/1500); Loss: 0.114174; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1459 0.1366 0.1162 0.1083 0.1075 0.1082 0.1035 0.1081 0.1030 0.1100 0.1073 0.1102 0.1102 0.1140 0.1179 0.1198 

[TRAIN] Epoch[8](866/1500); Loss: 0.093494; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1233 0.1058 0.1013 0.0961 0.0913 0.0899 0.0873 0.0869 0.0852 0.0860 0.0868 0.0871 0.0899 0.0902 0.0930 0.0958 

[TRAIN] Epoch[8](867/1500); Loss: 0.084159; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1163 0.1070 0.0787 0.0760 0.0703 0.0725 0.0721 0.0730 0.0773 0.0778 0.0803 0.0822 0.0852 0.0897 0.0931 0.0952 

[TRAIN] Epoch[8](868/1500); Loss: 0.118216; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1323 0.1338 0.1291 0.1146 0.1140 0.1098 0.1129 0.1097 0.1118 0.1137 0.1127 0.1161 0.1171 0.1191 0.1216 0.1233 

[TRAIN] Epoch[8](869/1500); Loss: 0.139154; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2039 0.1797 0.1340 0.1260 0.1212 0.1234 0.1234 0.1253 0.1274 0.1309 0.1320 0.1328 0.1353 0.1407 0.1448 0.1458 

[TRAIN] Epoch[8](870/1500); Loss: 0.066976; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0489 0.0592 0.0797 0.0670 0.0578 0.0613 0.0600 0.0586 0.0635 0.0659 0.0674 0.0710 0.0710 0.0737 0.0828 0.0837 

[TRAIN] Epoch[8](871/1500); Loss: 0.149249; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1778 0.1531 0.1267 0.1374 0.1372 0.1351 0.1339 0.1366 0.1393 0.1432 0.1465 0.1523 0.1578 0.1635 0.1706 0.1770 

[TRAIN] Epoch[8](872/1500); Loss: 0.084527; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.0951 0.0851 0.0846 0.0875 0.0822 0.0796 0.0796 0.0797 0.0806 0.0808 0.0816 0.0848 0.0856 0.0862 0.0890 0.0905 

[TRAIN] Epoch[8](873/1500); Loss: 0.098564; Backpropagation: 0.0917 sec; Batch: 0.4237 sec
0.1522 0.1264 0.0989 0.0941 0.0921 0.0912 0.0895 0.0907 0.0881 0.0899 0.0912 0.0915 0.0929 0.0938 0.0965 0.0979 

[TRAIN] Epoch[8](874/1500); Loss: 0.103871; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1272 0.1220 0.1053 0.0973 0.0961 0.0953 0.0977 0.0965 0.0971 0.0990 0.1008 0.1025 0.1036 0.1051 0.1069 0.1095 

[TRAIN] Epoch[8](875/1500); Loss: 0.184089; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2475 0.2334 0.2060 0.1880 0.1839 0.1778 0.1732 0.1746 0.1715 0.1676 0.1706 0.1674 0.1698 0.1715 0.1720 0.1705 

[TRAIN] Epoch[8](876/1500); Loss: 0.089237; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1562 0.1414 0.0574 0.0639 0.0624 0.0633 0.0698 0.0725 0.0756 0.0773 0.0885 0.0885 0.0940 0.1025 0.1054 0.1089 

[TRAIN] Epoch[8](877/1500); Loss: 0.177136; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.2324 0.2158 0.1876 0.1698 0.1653 0.1627 0.1611 0.1613 0.1649 0.1654 0.1688 0.1708 0.1712 0.1752 0.1797 0.1823 

[TRAIN] Epoch[8](878/1500); Loss: 0.114540; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1233 0.1163 0.1128 0.1202 0.1139 0.1128 0.1068 0.1091 0.1090 0.1095 0.1108 0.1122 0.1151 0.1177 0.1217 0.1215 

[TRAIN] Epoch[8](879/1500); Loss: 0.150000; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1647 0.1622 0.1589 0.1535 0.1488 0.1483 0.1465 0.1455 0.1456 0.1467 0.1448 0.1461 0.1473 0.1456 0.1477 0.1477 

[TRAIN] Epoch[8](880/1500); Loss: 0.167231; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.3676 0.3199 0.2421 0.1887 0.1602 0.1436 0.1236 0.1271 0.1192 0.1220 0.1232 0.1244 0.1282 0.1267 0.1285 0.1307 

[TRAIN] Epoch[8](881/1500); Loss: 0.165932; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.1941 0.1869 0.1791 0.1713 0.1666 0.1624 0.1631 0.1589 0.1596 0.1580 0.1572 0.1593 0.1576 0.1598 0.1599 0.1612 

[TRAIN] Epoch[8](882/1500); Loss: 0.163268; Backpropagation: 0.0916 sec; Batch: 0.4238 sec
0.2032 0.1963 0.1784 0.1650 0.1586 0.1635 0.1556 0.1527 0.1530 0.1552 0.1529 0.1533 0.1537 0.1568 0.1566 0.1577 

[TRAIN] Epoch[8](883/1500); Loss: 0.084090; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0868 0.0780 0.0783 0.0770 0.0836 0.0758 0.0789 0.0769 0.0800 0.0819 0.0850 0.0866 0.0900 0.0926 0.0949 0.0992 

[TRAIN] Epoch[8](884/1500); Loss: 0.153041; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2253 0.1955 0.1646 0.1339 0.1288 0.1362 0.1273 0.1327 0.1336 0.1362 0.1429 0.1508 0.1512 0.1557 0.1634 0.1704 

[TRAIN] Epoch[8](885/1500); Loss: 0.111086; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1487 0.1281 0.0991 0.1076 0.1034 0.1043 0.1017 0.1024 0.1027 0.1057 0.1059 0.1089 0.1110 0.1131 0.1166 0.1182 

[TRAIN] Epoch[8](886/1500); Loss: 0.129119; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2381 0.2001 0.1400 0.1207 0.1173 0.1138 0.1124 0.1094 0.1108 0.1105 0.1120 0.1147 0.1138 0.1167 0.1167 0.1188 

[TRAIN] Epoch[8](887/1500); Loss: 0.087477; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1910 0.1762 0.0954 0.0579 0.0595 0.0651 0.0647 0.0679 0.0703 0.0705 0.0729 0.0769 0.0784 0.0813 0.0864 0.0854 

[TRAIN] Epoch[8](888/1500); Loss: 0.118734; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1443 0.1403 0.1223 0.1184 0.1104 0.1125 0.1122 0.1125 0.1117 0.1134 0.1127 0.1150 0.1166 0.1181 0.1192 0.1204 

[TRAIN] Epoch[8](889/1500); Loss: 0.089740; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1524 0.1400 0.1020 0.0753 0.0706 0.0713 0.0719 0.0765 0.0763 0.0826 0.0800 0.0790 0.0841 0.0875 0.0915 0.0950 

[TRAIN] Epoch[8](890/1500); Loss: 0.141184; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1399 0.1375 0.1473 0.1455 0.1401 0.1374 0.1349 0.1375 0.1359 0.1385 0.1388 0.1412 0.1426 0.1442 0.1474 0.1503 

[TRAIN] Epoch[8](891/1500); Loss: 0.088478; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1593 0.1238 0.0967 0.0926 0.0831 0.0787 0.0777 0.0763 0.0751 0.0754 0.0760 0.0773 0.0780 0.0801 0.0820 0.0836 

[TRAIN] Epoch[8](892/1500); Loss: 0.121111; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1207 0.1201 0.1317 0.1265 0.1211 0.1179 0.1179 0.1168 0.1174 0.1179 0.1188 0.1195 0.1200 0.1224 0.1238 0.1254 

[TRAIN] Epoch[8](893/1500); Loss: 0.068897; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.0767 0.0747 0.0680 0.0619 0.0576 0.0592 0.0621 0.0611 0.0651 0.0670 0.0687 0.0697 0.0753 0.0753 0.0782 0.0818 

[TRAIN] Epoch[8](894/1500); Loss: 0.138832; Backpropagation: 0.0918 sec; Batch: 0.4232 sec
0.1716 0.1574 0.1369 0.1312 0.1315 0.1364 0.1314 0.1283 0.1328 0.1332 0.1321 0.1342 0.1389 0.1395 0.1417 0.1443 

[TRAIN] Epoch[8](895/1500); Loss: 0.143153; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1858 0.1783 0.1634 0.1537 0.1483 0.1391 0.1366 0.1357 0.1316 0.1308 0.1291 0.1290 0.1307 0.1314 0.1330 0.1338 

[TRAIN] Epoch[8](896/1500); Loss: 0.115078; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1799 0.1582 0.1252 0.1142 0.1066 0.1054 0.1021 0.1021 0.1029 0.1035 0.1049 0.1044 0.1066 0.1078 0.1078 0.1096 

[TRAIN] Epoch[8](897/1500); Loss: 0.099965; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1346 0.0970 0.0905 0.1124 0.1013 0.0941 0.0956 0.0921 0.0933 0.0937 0.0945 0.0964 0.0972 0.0995 0.1025 0.1048 

[TRAIN] Epoch[8](898/1500); Loss: 0.083744; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1026 0.0949 0.0700 0.0698 0.0792 0.0771 0.0756 0.0784 0.0792 0.0804 0.0851 0.0847 0.0859 0.0914 0.0910 0.0944 

[TRAIN] Epoch[8](899/1500); Loss: 0.100904; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1300 0.1214 0.1095 0.1042 0.0966 0.0951 0.0955 0.0954 0.0931 0.0941 0.0944 0.0951 0.0959 0.0973 0.0971 0.0996 

[TRAIN] Epoch[8](900/1500); Loss: 0.116267; Backpropagation: 0.0916 sec; Batch: 0.4237 sec
0.1780 0.1481 0.1213 0.1145 0.1107 0.1037 0.1062 0.1034 0.1058 0.1039 0.1073 0.1080 0.1099 0.1115 0.1131 0.1148 

[TRAIN] Epoch[8](901/1500); Loss: 0.188729; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.2438 0.2205 0.1993 0.1933 0.1954 0.1938 0.1817 0.1765 0.1761 0.1691 0.1710 0.1728 0.1771 0.1789 0.1819 0.1884 

[TRAIN] Epoch[8](902/1500); Loss: 0.124872; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1493 0.1356 0.1285 0.1306 0.1262 0.1229 0.1209 0.1175 0.1192 0.1169 0.1193 0.1202 0.1208 0.1225 0.1227 0.1248 

[TRAIN] Epoch[8](903/1500); Loss: 0.102457; Backpropagation: 0.0921 sec; Batch: 0.4233 sec
0.1323 0.1162 0.1105 0.1090 0.1025 0.0967 0.0969 0.0938 0.0962 0.0939 0.0959 0.0967 0.0976 0.0981 0.1015 0.1017 

[TRAIN] Epoch[8](904/1500); Loss: 0.101190; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1122 0.1082 0.1036 0.0957 0.0959 0.0935 0.0947 0.0961 0.0972 0.0975 0.0985 0.1009 0.1032 0.1044 0.1075 0.1099 

[TRAIN] Epoch[8](905/1500); Loss: 0.093159; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1121 0.1037 0.0943 0.0923 0.0892 0.0860 0.0857 0.0853 0.0855 0.0868 0.0885 0.0908 0.0934 0.0958 0.0990 0.1022 

[TRAIN] Epoch[8](906/1500); Loss: 0.086374; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0985 0.0908 0.0841 0.0812 0.0814 0.0805 0.0789 0.0794 0.0818 0.0831 0.0841 0.0853 0.0892 0.0912 0.0953 0.0970 

[TRAIN] Epoch[8](907/1500); Loss: 0.138981; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1647 0.1488 0.1428 0.1428 0.1397 0.1370 0.1380 0.1345 0.1341 0.1329 0.1331 0.1338 0.1339 0.1348 0.1358 0.1370 

[TRAIN] Epoch[8](908/1500); Loss: 0.105159; Backpropagation: 0.0918 sec; Batch: 0.4231 sec
0.1630 0.1526 0.1208 0.1006 0.0912 0.0911 0.0917 0.0940 0.0915 0.0927 0.0945 0.0974 0.0983 0.0993 0.1011 0.1027 

[TRAIN] Epoch[8](909/1500); Loss: 0.183746; Backpropagation: 0.0921 sec; Batch: 0.4236 sec
0.2462 0.2312 0.2078 0.1963 0.1881 0.1808 0.1715 0.1716 0.1712 0.1672 0.1667 0.1666 0.1681 0.1678 0.1687 0.1701 

[TRAIN] Epoch[8](910/1500); Loss: 0.133893; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1287 0.1183 0.1137 0.1199 0.1245 0.1311 0.1258 0.1254 0.1303 0.1314 0.1338 0.1412 0.1455 0.1502 0.1581 0.1644 

[TRAIN] Epoch[8](911/1500); Loss: 0.101035; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.0971 0.0936 0.1043 0.0992 0.0927 0.0974 0.0970 0.0950 0.0966 0.1008 0.1013 0.1021 0.1065 0.1080 0.1113 0.1137 

[TRAIN] Epoch[8](912/1500); Loss: 0.142172; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.2089 0.1965 0.1484 0.1325 0.1294 0.1286 0.1290 0.1286 0.1302 0.1298 0.1312 0.1316 0.1346 0.1356 0.1380 0.1417 

[TRAIN] Epoch[8](913/1500); Loss: 0.084206; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1189 0.0981 0.0657 0.0691 0.0701 0.0709 0.0725 0.0759 0.0788 0.0794 0.0830 0.0863 0.0884 0.0936 0.0964 0.1003 

[TRAIN] Epoch[8](914/1500); Loss: 0.087393; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1222 0.1116 0.0792 0.0769 0.0796 0.0785 0.0779 0.0810 0.0788 0.0809 0.0847 0.0850 0.0867 0.0903 0.0916 0.0933 

[TRAIN] Epoch[8](915/1500); Loss: 0.085725; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.0942 0.0948 0.0860 0.0832 0.0813 0.0820 0.0811 0.0809 0.0820 0.0826 0.0825 0.0843 0.0870 0.0879 0.0886 0.0931 

[TRAIN] Epoch[8](916/1500); Loss: 0.120459; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.1509 0.1389 0.1082 0.1076 0.1055 0.1093 0.1095 0.1155 0.1128 0.1144 0.1185 0.1194 0.1238 0.1304 0.1301 0.1325 

[TRAIN] Epoch[8](917/1500); Loss: 0.162879; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2615 0.2217 0.1802 0.1649 0.1533 0.1457 0.1441 0.1470 0.1453 0.1460 0.1463 0.1469 0.1481 0.1498 0.1518 0.1536 

[TRAIN] Epoch[8](918/1500); Loss: 0.222865; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.3889 0.3325 0.2616 0.2267 0.2126 0.2050 0.1871 0.1799 0.2062 0.1905 0.1870 0.1894 0.1976 0.1966 0.2009 0.2032 

[TRAIN] Epoch[8](919/1500); Loss: 0.110098; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.1557 0.1383 0.1175 0.1078 0.1032 0.1041 0.1005 0.1012 0.1003 0.1014 0.1009 0.1041 0.1033 0.1060 0.1062 0.1112 

[TRAIN] Epoch[8](920/1500); Loss: 0.158376; Backpropagation: 0.0916 sec; Batch: 0.4234 sec
0.2410 0.2106 0.1780 0.1702 0.1629 0.1565 0.1486 0.1445 0.1448 0.1387 0.1394 0.1388 0.1390 0.1401 0.1401 0.1411 

[TRAIN] Epoch[8](921/1500); Loss: 0.145997; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.2405 0.2116 0.1698 0.1514 0.1447 0.1417 0.1269 0.1246 0.1268 0.1232 0.1238 0.1276 0.1270 0.1286 0.1344 0.1332 

[TRAIN] Epoch[8](922/1500); Loss: 0.119901; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.1134 0.1084 0.1178 0.1027 0.1030 0.1179 0.1139 0.1096 0.1115 0.1232 0.1228 0.1234 0.1324 0.1331 0.1379 0.1476 

[TRAIN] Epoch[8](923/1500); Loss: 0.159241; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1933 0.1875 0.1824 0.1723 0.1651 0.1605 0.1543 0.1518 0.1519 0.1475 0.1457 0.1462 0.1477 0.1460 0.1474 0.1484 

[TRAIN] Epoch[8](924/1500); Loss: 0.077474; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.1012 0.0973 0.0788 0.0709 0.0676 0.0687 0.0701 0.0693 0.0722 0.0738 0.0741 0.0747 0.0778 0.0788 0.0813 0.0828 

[TRAIN] Epoch[8](925/1500); Loss: 0.142123; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1907 0.1746 0.1407 0.1333 0.1345 0.1347 0.1334 0.1331 0.1347 0.1336 0.1340 0.1363 0.1388 0.1380 0.1410 0.1425 

[TRAIN] Epoch[8](926/1500); Loss: 0.193879; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.2496 0.2310 0.1918 0.1922 0.1898 0.1876 0.1871 0.1807 0.1834 0.1840 0.1855 0.1840 0.1863 0.1883 0.1888 0.1919 

[TRAIN] Epoch[8](927/1500); Loss: 0.101419; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1956 0.1781 0.0945 0.0758 0.0908 0.0821 0.0802 0.0867 0.0837 0.0830 0.0895 0.0917 0.0930 0.0956 0.1005 0.1020 

[TRAIN] Epoch[8](928/1500); Loss: 0.099284; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.0998 0.0958 0.1052 0.1038 0.0973 0.0952 0.0928 0.0936 0.0955 0.0955 0.0978 0.0987 0.1012 0.1030 0.1055 0.1080 

[TRAIN] Epoch[8](929/1500); Loss: 0.149974; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.2568 0.2409 0.1870 0.1535 0.1370 0.1360 0.1316 0.1287 0.1248 0.1250 0.1268 0.1289 0.1300 0.1296 0.1311 0.1319 

[TRAIN] Epoch[8](930/1500); Loss: 0.115594; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1589 0.1384 0.1147 0.1100 0.1115 0.1073 0.1065 0.1076 0.1035 0.1080 0.1078 0.1098 0.1125 0.1168 0.1168 0.1194 

[TRAIN] Epoch[8](931/1500); Loss: 0.151568; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1980 0.1844 0.1717 0.1618 0.1503 0.1487 0.1428 0.1450 0.1404 0.1409 0.1388 0.1394 0.1411 0.1387 0.1412 0.1421 

[TRAIN] Epoch[8](932/1500); Loss: 0.095540; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1837 0.1634 0.0450 0.0523 0.0716 0.0550 0.0527 0.0869 0.0910 0.0820 0.0833 0.1028 0.1077 0.1045 0.1153 0.1313 

[TRAIN] Epoch[8](933/1500); Loss: 0.128602; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1952 0.1638 0.1221 0.1128 0.1185 0.1169 0.1196 0.1179 0.1194 0.1200 0.1206 0.1227 0.1247 0.1260 0.1270 0.1306 

[TRAIN] Epoch[8](934/1500); Loss: 0.098562; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1392 0.1247 0.0746 0.0739 0.0707 0.0732 0.0796 0.0822 0.0831 0.0955 0.0966 0.1006 0.1121 0.1164 0.1233 0.1313 

[TRAIN] Epoch[8](935/1500); Loss: 0.084179; Backpropagation: 0.0922 sec; Batch: 0.4238 sec
0.0952 0.0847 0.0852 0.0852 0.0806 0.0818 0.0795 0.0799 0.0802 0.0824 0.0824 0.0842 0.0836 0.0853 0.0878 0.0888 

[TRAIN] Epoch[8](936/1500); Loss: 0.092325; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1291 0.1216 0.0971 0.0887 0.0847 0.0824 0.0841 0.0840 0.0842 0.0850 0.0864 0.0875 0.0878 0.0897 0.0910 0.0939 

[TRAIN] Epoch[8](937/1500); Loss: 0.117979; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1354 0.1202 0.1165 0.1200 0.1155 0.1135 0.1140 0.1130 0.1142 0.1131 0.1151 0.1162 0.1182 0.1179 0.1213 0.1236 

[TRAIN] Epoch[8](938/1500); Loss: 0.060149; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.0435 0.0450 0.0737 0.0703 0.0619 0.0546 0.0535 0.0534 0.0561 0.0566 0.0601 0.0607 0.0649 0.0659 0.0705 0.0717 

[TRAIN] Epoch[8](939/1500); Loss: 0.160361; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1849 0.1803 0.1736 0.1661 0.1593 0.1583 0.1551 0.1552 0.1533 0.1533 0.1539 0.1529 0.1540 0.1546 0.1559 0.1550 

[TRAIN] Epoch[8](940/1500); Loss: 0.117630; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1457 0.1350 0.1161 0.1066 0.1047 0.1141 0.1111 0.1092 0.1133 0.1124 0.1157 0.1173 0.1183 0.1181 0.1219 0.1226 

[TRAIN] Epoch[8](941/1500); Loss: 0.122746; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.1535 0.1459 0.1170 0.1147 0.1171 0.1191 0.1182 0.1177 0.1179 0.1194 0.1167 0.1180 0.1218 0.1226 0.1216 0.1227 

[TRAIN] Epoch[8](942/1500); Loss: 0.083923; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1252 0.1143 0.0933 0.0765 0.0742 0.0752 0.0743 0.0757 0.0754 0.0755 0.0755 0.0802 0.0786 0.0799 0.0833 0.0855 

[TRAIN] Epoch[8](943/1500); Loss: 0.097160; Backpropagation: 0.0920 sec; Batch: 0.4241 sec
0.1193 0.0958 0.0929 0.1071 0.0972 0.0954 0.0920 0.0928 0.0915 0.0927 0.0928 0.0939 0.0947 0.0967 0.0989 0.1009 

[TRAIN] Epoch[8](944/1500); Loss: 0.123691; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.2433 0.2130 0.1344 0.1257 0.1208 0.1159 0.1088 0.1015 0.0975 0.0978 0.0996 0.0990 0.1013 0.1055 0.1072 0.1080 

[TRAIN] Epoch[8](945/1500); Loss: 0.099834; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2515 0.2357 0.1113 0.0547 0.0552 0.0823 0.0723 0.0603 0.0837 0.0680 0.0725 0.0826 0.0806 0.0836 0.1055 0.0975 

[TRAIN] Epoch[8](946/1500); Loss: 0.127195; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1493 0.1386 0.1372 0.1397 0.1279 0.1275 0.1192 0.1198 0.1197 0.1207 0.1180 0.1209 0.1214 0.1229 0.1258 0.1265 

[TRAIN] Epoch[8](947/1500); Loss: 0.112625; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1221 0.1184 0.1086 0.1066 0.1058 0.1078 0.1079 0.1091 0.1097 0.1110 0.1121 0.1138 0.1153 0.1162 0.1180 0.1194 

[TRAIN] Epoch[8](948/1500); Loss: 0.092806; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1034 0.0925 0.0860 0.0799 0.0784 0.0837 0.0840 0.0841 0.0850 0.0926 0.0966 0.0940 0.0980 0.1058 0.1102 0.1106 

[TRAIN] Epoch[8](949/1500); Loss: 0.097329; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1299 0.1148 0.1056 0.1024 0.0948 0.0964 0.0915 0.0914 0.0887 0.0895 0.0886 0.0906 0.0917 0.0923 0.0930 0.0960 

[TRAIN] Epoch[8](950/1500); Loss: 0.120624; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1382 0.1334 0.1173 0.1196 0.1169 0.1166 0.1154 0.1173 0.1167 0.1168 0.1176 0.1186 0.1207 0.1214 0.1210 0.1225 

[TRAIN] Epoch[8](951/1500); Loss: 0.088238; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.1074 0.0930 0.0931 0.0834 0.0820 0.0810 0.0790 0.0786 0.0825 0.0825 0.0859 0.0883 0.0900 0.0926 0.0949 0.0977 

[TRAIN] Epoch[8](952/1500); Loss: 0.114780; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2664 0.2212 0.1549 0.1249 0.1100 0.0996 0.0830 0.0914 0.0835 0.0868 0.0831 0.0835 0.0878 0.0849 0.0861 0.0895 

[TRAIN] Epoch[8](953/1500); Loss: 0.184135; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1778 0.1782 0.1775 0.1862 0.1816 0.1840 0.1850 0.1847 0.1895 0.1852 0.1853 0.1862 0.1860 0.1866 0.1856 0.1871 

[TRAIN] Epoch[8](954/1500); Loss: 0.124589; Backpropagation: 0.0920 sec; Batch: 0.4234 sec
0.1824 0.1558 0.1231 0.1153 0.1178 0.1176 0.1156 0.1167 0.1145 0.1160 0.1171 0.1170 0.1186 0.1214 0.1215 0.1230 

[TRAIN] Epoch[8](955/1500); Loss: 0.083975; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.0956 0.0932 0.0817 0.0830 0.0807 0.0811 0.0797 0.0805 0.0801 0.0815 0.0810 0.0820 0.0837 0.0846 0.0861 0.0891 

[TRAIN] Epoch[8](956/1500); Loss: 0.101193; Backpropagation: 0.0918 sec; Batch: 0.4280 sec
0.1561 0.1278 0.1055 0.1002 0.0939 0.0926 0.0911 0.0912 0.0927 0.0926 0.0934 0.0939 0.0955 0.0957 0.0982 0.0988 

[TRAIN] Epoch[8](957/1500); Loss: 0.088503; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1210 0.1113 0.0712 0.0693 0.0712 0.0738 0.0752 0.0791 0.0807 0.0849 0.0871 0.0907 0.0937 0.0978 0.1031 0.1060 

[TRAIN] Epoch[8](958/1500); Loss: 0.085682; Backpropagation: 0.0918 sec; Batch: 0.4246 sec
0.2326 0.2146 0.0702 0.0552 0.0423 0.0422 0.0730 0.0542 0.0521 0.0650 0.0725 0.0700 0.0796 0.0776 0.0825 0.0875 

[TRAIN] Epoch[8](959/1500); Loss: 0.133146; Backpropagation: 0.0922 sec; Batch: 0.4253 sec
0.1541 0.1457 0.1298 0.1296 0.1237 0.1249 0.1254 0.1263 0.1267 0.1274 0.1311 0.1318 0.1339 0.1365 0.1407 0.1426 

[TRAIN] Epoch[8](960/1500); Loss: 0.179756; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1831 0.1855 0.1958 0.1879 0.1843 0.1847 0.1759 0.1761 0.1778 0.1747 0.1741 0.1758 0.1731 0.1732 0.1750 0.1790 

[TRAIN] Epoch[8](961/1500); Loss: 0.161989; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.2016 0.1801 0.1708 0.1708 0.1623 0.1569 0.1544 0.1542 0.1525 0.1533 0.1531 0.1532 0.1553 0.1573 0.1573 0.1587 

[TRAIN] Epoch[8](962/1500); Loss: 0.123272; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1487 0.1397 0.1315 0.1254 0.1211 0.1180 0.1175 0.1162 0.1166 0.1161 0.1179 0.1186 0.1197 0.1204 0.1218 0.1232 

[TRAIN] Epoch[8](963/1500); Loss: 0.188811; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.2421 0.2229 0.1844 0.1846 0.1832 0.1795 0.1762 0.1770 0.1783 0.1815 0.1795 0.1809 0.1846 0.1869 0.1879 0.1916 

[TRAIN] Epoch[8](964/1500); Loss: 0.220661; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.3543 0.3012 0.2436 0.2166 0.1972 0.1894 0.1948 0.1957 0.1966 0.1988 0.1994 0.2034 0.2048 0.2086 0.2114 0.2146 

[TRAIN] Epoch[8](965/1500); Loss: 0.110652; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1278 0.1118 0.1104 0.1197 0.1105 0.1070 0.1066 0.1056 0.1052 0.1056 0.1068 0.1083 0.1088 0.1106 0.1118 0.1140 

[TRAIN] Epoch[8](966/1500); Loss: 0.109365; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1398 0.1230 0.1061 0.1057 0.1031 0.1034 0.1028 0.1032 0.1034 0.1045 0.1056 0.1067 0.1087 0.1102 0.1111 0.1127 

[TRAIN] Epoch[8](967/1500); Loss: 0.102720; Backpropagation: 0.0917 sec; Batch: 0.4229 sec
0.1261 0.1032 0.1006 0.1108 0.1035 0.1020 0.0975 0.0987 0.0970 0.0972 0.0968 0.0999 0.0995 0.1023 0.1027 0.1057 

[TRAIN] Epoch[8](968/1500); Loss: 0.098472; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1167 0.0990 0.0999 0.1030 0.0965 0.0974 0.0939 0.0953 0.0934 0.0967 0.0946 0.0964 0.0960 0.0985 0.0982 0.1002 

[TRAIN] Epoch[8](969/1500); Loss: 0.057257; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.0656 0.0662 0.0559 0.0537 0.0509 0.0512 0.0508 0.0515 0.0525 0.0537 0.0556 0.0568 0.0598 0.0611 0.0648 0.0661 

[TRAIN] Epoch[8](970/1500); Loss: 0.076301; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1985 0.1487 0.0816 0.0619 0.0573 0.0542 0.0576 0.0572 0.0571 0.0599 0.0604 0.0614 0.0636 0.0657 0.0669 0.0687 

[TRAIN] Epoch[8](971/1500); Loss: 0.171671; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2340 0.2094 0.1821 0.1752 0.1697 0.1674 0.1668 0.1614 0.1618 0.1598 0.1614 0.1589 0.1590 0.1607 0.1602 0.1590 

[TRAIN] Epoch[8](972/1500); Loss: 0.253454; Backpropagation: 0.0916 sec; Batch: 0.4233 sec
0.3806 0.3549 0.3081 0.2829 0.2648 0.2456 0.2300 0.2215 0.2268 0.2189 0.2196 0.2196 0.2208 0.2179 0.2218 0.2214 

[TRAIN] Epoch[8](973/1500); Loss: 0.137841; Backpropagation: 0.0919 sec; Batch: 0.4230 sec
0.2125 0.1790 0.1493 0.1459 0.1362 0.1303 0.1237 0.1263 0.1234 0.1255 0.1239 0.1239 0.1248 0.1255 0.1267 0.1284 

[TRAIN] Epoch[8](974/1500); Loss: 0.133653; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1536 0.1436 0.1265 0.1252 0.1254 0.1323 0.1245 0.1262 0.1300 0.1327 0.1312 0.1327 0.1364 0.1373 0.1390 0.1418 

[TRAIN] Epoch[8](975/1500); Loss: 0.123832; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1365 0.1330 0.1208 0.1180 0.1164 0.1179 0.1190 0.1196 0.1207 0.1208 0.1229 0.1252 0.1256 0.1271 0.1279 0.1298 

[TRAIN] Epoch[8](976/1500); Loss: 0.141201; Backpropagation: 0.0917 sec; Batch: 0.4232 sec
0.1923 0.1723 0.1400 0.1286 0.1260 0.1301 0.1309 0.1285 0.1300 0.1338 0.1358 0.1354 0.1398 0.1436 0.1444 0.1478 

[TRAIN] Epoch[8](977/1500); Loss: 0.140057; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1430 0.1447 0.1439 0.1389 0.1384 0.1356 0.1361 0.1366 0.1371 0.1375 0.1396 0.1384 0.1399 0.1428 0.1444 0.1442 

[TRAIN] Epoch[8](978/1500); Loss: 0.152686; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.1722 0.1665 0.1509 0.1501 0.1512 0.1489 0.1485 0.1492 0.1469 0.1466 0.1490 0.1499 0.1525 0.1510 0.1549 0.1546 

[TRAIN] Epoch[8](979/1500); Loss: 0.161405; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.2899 0.2506 0.1964 0.1763 0.1628 0.1473 0.1414 0.1412 0.1357 0.1330 0.1328 0.1323 0.1341 0.1356 0.1365 0.1368 

[TRAIN] Epoch[8](980/1500); Loss: 0.116398; Backpropagation: 0.0916 sec; Batch: 0.4232 sec
0.1631 0.1426 0.1279 0.1210 0.1107 0.1075 0.1037 0.1014 0.1038 0.1047 0.1076 0.1074 0.1093 0.1145 0.1179 0.1193 

[TRAIN] Epoch[8](981/1500); Loss: 0.111825; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.2241 0.2103 0.1002 0.0894 0.0787 0.0787 0.1046 0.0872 0.0859 0.1027 0.0970 0.0948 0.1119 0.1084 0.1061 0.1094 

[TRAIN] Epoch[8](982/1500); Loss: 0.118029; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1226 0.1202 0.1161 0.1151 0.1138 0.1150 0.1141 0.1158 0.1157 0.1170 0.1177 0.1181 0.1188 0.1211 0.1229 0.1244 

[TRAIN] Epoch[8](983/1500); Loss: 0.129174; Backpropagation: 0.0923 sec; Batch: 0.4244 sec
0.1648 0.1492 0.1353 0.1300 0.1273 0.1268 0.1233 0.1234 0.1216 0.1210 0.1218 0.1224 0.1236 0.1244 0.1256 0.1262 

[TRAIN] Epoch[8](984/1500); Loss: 0.141254; Backpropagation: 0.0975 sec; Batch: 0.4304 sec
0.2525 0.2194 0.1689 0.1498 0.1381 0.1278 0.1192 0.1241 0.1147 0.1162 0.1185 0.1198 0.1196 0.1233 0.1233 0.1248 

[TRAIN] Epoch[8](985/1500); Loss: 0.108099; Backpropagation: 0.0976 sec; Batch: 0.4306 sec
0.1182 0.1152 0.1075 0.1055 0.1047 0.1025 0.1028 0.1044 0.1039 0.1047 0.1058 0.1067 0.1091 0.1105 0.1128 0.1155 

[TRAIN] Epoch[8](986/1500); Loss: 0.132299; Backpropagation: 0.0975 sec; Batch: 0.4297 sec
0.1582 0.1469 0.1283 0.1210 0.1222 0.1223 0.1249 0.1238 0.1244 0.1317 0.1293 0.1298 0.1333 0.1375 0.1400 0.1433 

[TRAIN] Epoch[8](987/1500); Loss: 0.140894; Backpropagation: 0.0976 sec; Batch: 0.4300 sec
0.1840 0.1724 0.1468 0.1404 0.1405 0.1364 0.1341 0.1335 0.1345 0.1325 0.1324 0.1320 0.1333 0.1332 0.1335 0.1349 

[TRAIN] Epoch[8](988/1500); Loss: 0.083279; Backpropagation: 0.0950 sec; Batch: 0.4269 sec
0.0822 0.0753 0.0757 0.0772 0.0708 0.0724 0.0770 0.0783 0.0754 0.0807 0.0889 0.0885 0.0880 0.0982 0.1023 0.1016 

[TRAIN] Epoch[8](989/1500); Loss: 0.130543; Backpropagation: 0.0953 sec; Batch: 0.4279 sec
0.1741 0.1645 0.1468 0.1338 0.1249 0.1207 0.1201 0.1199 0.1196 0.1203 0.1202 0.1213 0.1229 0.1248 0.1265 0.1283 

[TRAIN] Epoch[8](990/1500); Loss: 0.129713; Backpropagation: 0.0950 sec; Batch: 0.4269 sec
0.1552 0.1473 0.1352 0.1287 0.1291 0.1295 0.1242 0.1242 0.1234 0.1250 0.1239 0.1229 0.1248 0.1262 0.1272 0.1285 

[TRAIN] Epoch[8](991/1500); Loss: 0.112565; Backpropagation: 0.0952 sec; Batch: 0.4274 sec
0.1452 0.1358 0.1121 0.1083 0.1025 0.1052 0.1077 0.1045 0.1044 0.1076 0.1075 0.1082 0.1114 0.1121 0.1128 0.1158 

[TRAIN] Epoch[8](992/1500); Loss: 0.106329; Backpropagation: 0.0950 sec; Batch: 0.4271 sec
0.1906 0.1710 0.0653 0.0680 0.0929 0.0751 0.0701 0.1127 0.0781 0.0862 0.1049 0.1015 0.0993 0.1232 0.1314 0.1309 

[TRAIN] Epoch[8](993/1500); Loss: 0.128890; Backpropagation: 0.0951 sec; Batch: 0.4271 sec
0.2088 0.1798 0.1286 0.1211 0.1204 0.1168 0.1175 0.1203 0.1188 0.1167 0.1167 0.1177 0.1198 0.1196 0.1188 0.1211 

[TRAIN] Epoch[8](994/1500); Loss: 0.121707; Backpropagation: 0.0951 sec; Batch: 0.4274 sec
0.1538 0.1417 0.1184 0.1164 0.1159 0.1143 0.1145 0.1147 0.1155 0.1165 0.1161 0.1176 0.1211 0.1219 0.1228 0.1261 

[TRAIN] Epoch[8](995/1500); Loss: 0.170850; Backpropagation: 0.0952 sec; Batch: 0.4276 sec
0.1985 0.1914 0.1847 0.1818 0.1764 0.1695 0.1657 0.1624 0.1624 0.1611 0.1637 0.1625 0.1628 0.1620 0.1642 0.1645 

[TRAIN] Epoch[8](996/1500); Loss: 0.093192; Backpropagation: 0.0952 sec; Batch: 0.4271 sec
0.1256 0.1058 0.1043 0.0914 0.0835 0.0871 0.0823 0.0825 0.0848 0.0866 0.0874 0.0899 0.0919 0.0942 0.0952 0.0986 

[TRAIN] Epoch[8](997/1500); Loss: 0.126329; Backpropagation: 0.0952 sec; Batch: 0.4275 sec
0.1650 0.1468 0.1281 0.1214 0.1187 0.1193 0.1207 0.1181 0.1186 0.1193 0.1203 0.1211 0.1242 0.1243 0.1261 0.1292 

[TRAIN] Epoch[8](998/1500); Loss: 0.082770; Backpropagation: 0.0934 sec; Batch: 0.4255 sec
0.0687 0.0749 0.0774 0.0740 0.0741 0.0815 0.0794 0.0772 0.0795 0.0875 0.0872 0.0848 0.0906 0.0954 0.0940 0.0981 

[TRAIN] Epoch[8](999/1500); Loss: 0.135941; Backpropagation: 0.0934 sec; Batch: 0.4255 sec
0.2641 0.2411 0.1871 0.1573 0.1372 0.1271 0.1163 0.1074 0.1025 0.1009 0.1029 0.1041 0.1051 0.1050 0.1075 0.1092 

[TRAIN] Epoch[8](1000/1500); Loss: 0.109402; Backpropagation: 0.0934 sec; Batch: 0.4253 sec
0.1900 0.1648 0.1097 0.1008 0.1003 0.0949 0.0954 0.0959 0.0934 0.0941 0.0975 0.1013 0.0988 0.1029 0.1026 0.1081 

[TRAIN] Epoch[8](1001/1500); Loss: 0.172940; Backpropagation: 0.0924 sec; Batch: 0.4251 sec
0.2143 0.1927 0.1727 0.1741 0.1689 0.1679 0.1707 0.1678 0.1669 0.1658 0.1654 0.1663 0.1677 0.1683 0.1679 0.1695 

[TRAIN] Epoch[8](1002/1500); Loss: 0.141030; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1582 0.1523 0.1465 0.1433 0.1416 0.1400 0.1381 0.1366 0.1382 0.1366 0.1366 0.1369 0.1390 0.1365 0.1387 0.1374 

[TRAIN] Epoch[8](1003/1500); Loss: 0.084049; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.1003 0.0972 0.0751 0.0729 0.0738 0.0800 0.0785 0.0778 0.0788 0.0828 0.0819 0.0824 0.0881 0.0905 0.0905 0.0942 

[TRAIN] Epoch[8](1004/1500); Loss: 0.144576; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2207 0.1984 0.1593 0.1520 0.1456 0.1359 0.1267 0.1317 0.1262 0.1271 0.1291 0.1298 0.1303 0.1322 0.1327 0.1354 

[TRAIN] Epoch[8](1005/1500); Loss: 0.077950; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.0753 0.0708 0.0696 0.0742 0.0739 0.0746 0.0778 0.0774 0.0832 0.0757 0.0773 0.0798 0.0826 0.0812 0.0887 0.0851 

[TRAIN] Epoch[8](1006/1500); Loss: 0.140104; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1752 0.1668 0.1370 0.1393 0.1372 0.1396 0.1364 0.1330 0.1331 0.1355 0.1319 0.1335 0.1344 0.1357 0.1351 0.1382 

[TRAIN] Epoch[8](1007/1500); Loss: 0.092310; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1726 0.1534 0.0560 0.0514 0.0914 0.0683 0.0574 0.0881 0.0615 0.0669 0.0831 0.0890 0.0909 0.1100 0.1182 0.1188 

[TRAIN] Epoch[8](1008/1500); Loss: 0.163598; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2211 0.2022 0.1771 0.1703 0.1651 0.1624 0.1565 0.1524 0.1468 0.1496 0.1487 0.1506 0.1510 0.1576 0.1516 0.1546 

[TRAIN] Epoch[8](1009/1500); Loss: 0.115173; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1411 0.1305 0.1248 0.1232 0.1162 0.1130 0.1107 0.1097 0.1079 0.1092 0.1073 0.1072 0.1095 0.1097 0.1104 0.1123 

[TRAIN] Epoch[8](1010/1500); Loss: 0.108290; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1802 0.1622 0.0733 0.0662 0.1048 0.0878 0.0815 0.1109 0.0827 0.0875 0.0973 0.1068 0.1094 0.1245 0.1260 0.1316 

[TRAIN] Epoch[8](1011/1500); Loss: 0.105755; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1375 0.1305 0.1026 0.0962 0.0971 0.0997 0.0997 0.1000 0.0998 0.1010 0.1015 0.1031 0.1044 0.1054 0.1067 0.1068 

[TRAIN] Epoch[8](1012/1500); Loss: 0.098336; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1307 0.1117 0.1119 0.1011 0.0933 0.0907 0.0912 0.0875 0.0885 0.0932 0.0926 0.0918 0.0919 0.1016 0.0980 0.0977 

[TRAIN] Epoch[8](1013/1500); Loss: 0.119788; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1465 0.1319 0.1206 0.1152 0.1135 0.1152 0.1134 0.1129 0.1137 0.1147 0.1177 0.1167 0.1184 0.1206 0.1220 0.1237 

[TRAIN] Epoch[8](1014/1500); Loss: 0.095958; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1300 0.1247 0.1033 0.0893 0.0853 0.0860 0.0889 0.0868 0.0848 0.0906 0.0912 0.0912 0.0907 0.0958 0.0973 0.0996 

[TRAIN] Epoch[8](1015/1500); Loss: 0.148819; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1629 0.1566 0.1539 0.1486 0.1474 0.1456 0.1442 0.1440 0.1451 0.1450 0.1454 0.1461 0.1479 0.1478 0.1487 0.1517 

[TRAIN] Epoch[8](1016/1500); Loss: 0.105737; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1236 0.1133 0.1119 0.1068 0.1022 0.1004 0.0997 0.0970 0.0984 0.0987 0.1036 0.1017 0.1052 0.1062 0.1123 0.1108 

[TRAIN] Epoch[8](1017/1500); Loss: 0.097608; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.2390 0.2237 0.0907 0.0660 0.0577 0.0636 0.0784 0.0749 0.0704 0.0702 0.0806 0.0873 0.0831 0.0846 0.0915 0.1001 

[TRAIN] Epoch[8](1018/1500); Loss: 0.164803; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1668 0.1689 0.1778 0.1662 0.1683 0.1623 0.1655 0.1622 0.1673 0.1592 0.1619 0.1610 0.1682 0.1593 0.1604 0.1614 

[TRAIN] Epoch[8](1019/1500); Loss: 0.076887; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.0825 0.0821 0.0871 0.0753 0.0758 0.0716 0.0721 0.0714 0.0733 0.0741 0.0742 0.0755 0.0771 0.0792 0.0784 0.0804 

[TRAIN] Epoch[8](1020/1500); Loss: 0.082712; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1327 0.1271 0.0943 0.0798 0.0771 0.0737 0.0718 0.0707 0.0710 0.0730 0.0719 0.0728 0.0769 0.0760 0.0759 0.0786 

[TRAIN] Epoch[8](1021/1500); Loss: 0.117774; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1373 0.1313 0.1252 0.1210 0.1184 0.1157 0.1130 0.1126 0.1108 0.1122 0.1128 0.1135 0.1140 0.1167 0.1152 0.1146 

[TRAIN] Epoch[8](1022/1500); Loss: 0.074584; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0768 0.0789 0.0811 0.0714 0.0715 0.0675 0.0696 0.0702 0.0732 0.0710 0.0730 0.0754 0.0753 0.0766 0.0795 0.0822 

[TRAIN] Epoch[8](1023/1500); Loss: 0.178444; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.2258 0.2109 0.1971 0.1899 0.1841 0.1790 0.1719 0.1695 0.1674 0.1654 0.1658 0.1650 0.1667 0.1649 0.1659 0.1657 

[TRAIN] Epoch[8](1024/1500); Loss: 0.148925; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.2695 0.2341 0.1733 0.1639 0.1506 0.1363 0.1272 0.1219 0.1190 0.1188 0.1234 0.1246 0.1262 0.1271 0.1324 0.1346 

[TRAIN] Epoch[8](1025/1500); Loss: 0.131765; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1528 0.1454 0.1291 0.1248 0.1267 0.1259 0.1260 0.1280 0.1270 0.1274 0.1286 0.1308 0.1312 0.1319 0.1345 0.1381 

[TRAIN] Epoch[8](1026/1500); Loss: 0.218269; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.4389 0.3835 0.2977 0.2802 0.2586 0.2332 0.1956 0.1621 0.1489 0.1480 0.1503 0.1588 0.1556 0.1559 0.1574 0.1677 

[TRAIN] Epoch[8](1027/1500); Loss: 0.102891; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.1203 0.1115 0.1060 0.1074 0.1053 0.1047 0.1028 0.0999 0.0979 0.0996 0.0987 0.0968 0.0966 0.0986 0.0999 0.1003 

[TRAIN] Epoch[8](1028/1500); Loss: 0.188830; Backpropagation: 0.0918 sec; Batch: 0.4244 sec
0.2530 0.2382 0.2192 0.2077 0.2027 0.1906 0.1821 0.1761 0.1729 0.1677 0.1666 0.1672 0.1697 0.1686 0.1691 0.1701 

[TRAIN] Epoch[8](1029/1500); Loss: 0.077756; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1121 0.0976 0.0915 0.0814 0.0810 0.0714 0.0732 0.0689 0.0706 0.0680 0.0711 0.0689 0.0713 0.0705 0.0734 0.0734 

[TRAIN] Epoch[8](1030/1500); Loss: 0.107816; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1320 0.1235 0.1196 0.1153 0.1130 0.1044 0.1026 0.0999 0.1014 0.0990 0.1006 0.1003 0.1032 0.1023 0.1030 0.1049 

[TRAIN] Epoch[8](1031/1500); Loss: 0.142335; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1715 0.1694 0.1472 0.1369 0.1379 0.1381 0.1361 0.1338 0.1375 0.1361 0.1358 0.1357 0.1398 0.1391 0.1407 0.1417 

[TRAIN] Epoch[8](1032/1500); Loss: 0.122489; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.1497 0.1407 0.1380 0.1281 0.1218 0.1169 0.1168 0.1128 0.1115 0.1136 0.1160 0.1166 0.1158 0.1195 0.1208 0.1212 

[TRAIN] Epoch[8](1033/1500); Loss: 0.131143; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2356 0.2142 0.1469 0.1249 0.1199 0.1177 0.1119 0.1078 0.1085 0.1125 0.1122 0.1124 0.1144 0.1190 0.1198 0.1205 

[TRAIN] Epoch[8](1034/1500); Loss: 0.047350; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.0546 0.0460 0.0485 0.0417 0.0431 0.0392 0.0416 0.0409 0.0431 0.0445 0.0461 0.0485 0.0512 0.0534 0.0563 0.0588 

[TRAIN] Epoch[8](1035/1500); Loss: 0.123252; Backpropagation: 0.0922 sec; Batch: 0.4245 sec
0.1501 0.1342 0.1286 0.1254 0.1221 0.1231 0.1194 0.1191 0.1187 0.1196 0.1179 0.1171 0.1189 0.1192 0.1188 0.1197 

[TRAIN] Epoch[8](1036/1500); Loss: 0.079698; Backpropagation: 0.0917 sec; Batch: 0.4235 sec
0.0994 0.0912 0.0883 0.0721 0.0774 0.0727 0.0807 0.0757 0.0748 0.0714 0.0804 0.0773 0.0763 0.0754 0.0816 0.0804 

[TRAIN] Epoch[8](1037/1500); Loss: 0.161203; Backpropagation: 0.0922 sec; Batch: 0.4246 sec
0.1985 0.1905 0.1766 0.1669 0.1649 0.1577 0.1548 0.1518 0.1530 0.1496 0.1506 0.1508 0.1540 0.1520 0.1537 0.1538 

[TRAIN] Epoch[8](1038/1500); Loss: 0.109215; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1297 0.1195 0.1116 0.1097 0.1084 0.1050 0.1048 0.1031 0.1041 0.1044 0.1053 0.1053 0.1069 0.1081 0.1100 0.1115 

[TRAIN] Epoch[8](1039/1500); Loss: 0.115759; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1691 0.1595 0.1044 0.1055 0.1015 0.1013 0.1021 0.1064 0.1074 0.1064 0.1086 0.1132 0.1141 0.1141 0.1170 0.1215 

[TRAIN] Epoch[8](1040/1500); Loss: 0.167850; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2652 0.2376 0.1999 0.1906 0.1802 0.1658 0.1512 0.1460 0.1438 0.1437 0.1424 0.1436 0.1435 0.1442 0.1428 0.1451 

[TRAIN] Epoch[8](1041/1500); Loss: 0.071045; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.0812 0.0909 0.0604 0.0626 0.0642 0.0642 0.0642 0.0680 0.0684 0.0670 0.0675 0.0725 0.0757 0.0745 0.0752 0.0803 

[TRAIN] Epoch[8](1042/1500); Loss: 0.123539; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.1984 0.1789 0.1423 0.1395 0.1314 0.1222 0.1102 0.1031 0.0983 0.0998 0.1022 0.1051 0.1069 0.1088 0.1124 0.1171 

[TRAIN] Epoch[8](1043/1500); Loss: 0.139792; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1756 0.1681 0.1489 0.1393 0.1371 0.1340 0.1316 0.1299 0.1301 0.1323 0.1328 0.1340 0.1335 0.1351 0.1360 0.1383 

[TRAIN] Epoch[8](1044/1500); Loss: 0.118685; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1565 0.1431 0.1203 0.1144 0.1157 0.1123 0.1091 0.1091 0.1111 0.1109 0.1115 0.1139 0.1163 0.1170 0.1176 0.1202 

[TRAIN] Epoch[8](1045/1500); Loss: 0.120052; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1470 0.1391 0.1198 0.1192 0.1148 0.1142 0.1129 0.1123 0.1134 0.1130 0.1144 0.1156 0.1182 0.1203 0.1226 0.1241 

[TRAIN] Epoch[8](1046/1500); Loss: 0.171239; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1817 0.1799 0.1777 0.1767 0.1734 0.1735 0.1688 0.1678 0.1670 0.1679 0.1654 0.1665 0.1671 0.1687 0.1683 0.1695 

[TRAIN] Epoch[8](1047/1500); Loss: 0.092678; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1079 0.0992 0.0912 0.0896 0.0898 0.0883 0.0884 0.0885 0.0888 0.0897 0.0901 0.0916 0.0942 0.0943 0.0950 0.0962 

[TRAIN] Epoch[8](1048/1500); Loss: 0.145010; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1595 0.1521 0.1448 0.1446 0.1420 0.1404 0.1405 0.1402 0.1414 0.1414 0.1424 0.1433 0.1445 0.1463 0.1478 0.1491 

[TRAIN] Epoch[8](1049/1500); Loss: 0.120462; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1744 0.1611 0.1325 0.1218 0.1194 0.1117 0.1063 0.1078 0.1088 0.1081 0.1083 0.1091 0.1094 0.1126 0.1179 0.1182 

[TRAIN] Epoch[8](1050/1500); Loss: 0.108855; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1428 0.1255 0.1168 0.1097 0.1097 0.1042 0.1019 0.1027 0.1016 0.1026 0.1016 0.1030 0.1034 0.1048 0.1044 0.1070 

[TRAIN] Epoch[8](1051/1500); Loss: 0.094648; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.1395 0.1187 0.0982 0.0946 0.0906 0.0865 0.0874 0.0868 0.0875 0.0876 0.0881 0.0880 0.0887 0.0897 0.0902 0.0923 

[TRAIN] Epoch[8](1052/1500); Loss: 0.089950; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1138 0.1000 0.0996 0.0898 0.0859 0.0838 0.0815 0.0803 0.0819 0.0838 0.0869 0.0855 0.0872 0.0919 0.0934 0.0938 

[TRAIN] Epoch[8](1053/1500); Loss: 0.205108; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.3257 0.2965 0.2398 0.2363 0.2246 0.2116 0.1937 0.1810 0.1726 0.1671 0.1662 0.1666 0.1711 0.1763 0.1744 0.1783 

[TRAIN] Epoch[8](1054/1500); Loss: 0.057296; Backpropagation: 0.0917 sec; Batch: 0.4230 sec
0.0573 0.0574 0.0594 0.0539 0.0557 0.0517 0.0532 0.0522 0.0543 0.0549 0.0565 0.0574 0.0601 0.0618 0.0646 0.0664 

[TRAIN] Epoch[8](1055/1500); Loss: 0.102116; Backpropagation: 0.0921 sec; Batch: 0.4246 sec
0.1538 0.1441 0.1011 0.0900 0.0876 0.0906 0.0904 0.0890 0.0890 0.0913 0.0976 0.0969 0.0976 0.1012 0.1052 0.1084 

[TRAIN] Epoch[8](1056/1500); Loss: 0.155491; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.1991 0.1866 0.1699 0.1637 0.1590 0.1531 0.1501 0.1482 0.1464 0.1446 0.1446 0.1443 0.1450 0.1435 0.1443 0.1453 

[TRAIN] Epoch[8](1057/1500); Loss: 0.116599; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1655 0.1463 0.0743 0.0570 0.0862 0.1494 0.1348 0.1266 0.1149 0.1124 0.0992 0.1094 0.1026 0.1212 0.1329 0.1329 

[TRAIN] Epoch[8](1058/1500); Loss: 0.129435; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1542 0.1464 0.1324 0.1284 0.1271 0.1272 0.1233 0.1228 0.1230 0.1247 0.1242 0.1253 0.1272 0.1265 0.1285 0.1298 

[TRAIN] Epoch[8](1059/1500); Loss: 0.157236; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.1901 0.1753 0.1631 0.1610 0.1569 0.1517 0.1484 0.1489 0.1504 0.1485 0.1492 0.1499 0.1513 0.1540 0.1563 0.1609 

[TRAIN] Epoch[8](1060/1500); Loss: 0.132174; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1590 0.1458 0.1331 0.1338 0.1290 0.1283 0.1278 0.1252 0.1245 0.1267 0.1267 0.1259 0.1275 0.1328 0.1337 0.1350 

[TRAIN] Epoch[8](1061/1500); Loss: 0.143736; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1876 0.1730 0.1559 0.1536 0.1497 0.1443 0.1363 0.1333 0.1320 0.1322 0.1322 0.1319 0.1339 0.1338 0.1351 0.1351 

[TRAIN] Epoch[8](1062/1500); Loss: 0.122720; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1898 0.1665 0.1323 0.1216 0.1163 0.1083 0.1049 0.1060 0.1061 0.1090 0.1100 0.1138 0.1155 0.1192 0.1203 0.1240 

[TRAIN] Epoch[8](1063/1500); Loss: 0.077664; Backpropagation: 0.0918 sec; Batch: 0.4241 sec
0.1558 0.1464 0.0641 0.0638 0.0603 0.0560 0.0577 0.0681 0.0742 0.0691 0.0659 0.0656 0.0672 0.0758 0.0743 0.0782 

[TRAIN] Epoch[8](1064/1500); Loss: 0.139769; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1779 0.1641 0.1367 0.1302 0.1280 0.1231 0.1234 0.1255 0.1270 0.1291 0.1326 0.1382 0.1425 0.1461 0.1525 0.1595 

[TRAIN] Epoch[8](1065/1500); Loss: 0.093199; Backpropagation: 0.0921 sec; Batch: 0.4242 sec
0.0916 0.0927 0.1040 0.0905 0.0952 0.0886 0.0892 0.0902 0.0908 0.0914 0.0896 0.0928 0.0947 0.0975 0.0941 0.0983 

[TRAIN] Epoch[8](1066/1500); Loss: 0.092384; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1054 0.1008 0.0940 0.0897 0.0892 0.0886 0.0891 0.0880 0.0884 0.0900 0.0902 0.0901 0.0925 0.0937 0.0939 0.0947 

[TRAIN] Epoch[8](1067/1500); Loss: 0.059520; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.0637 0.0597 0.0570 0.0557 0.0542 0.0545 0.0542 0.0545 0.0561 0.0569 0.0592 0.0607 0.0630 0.0649 0.0680 0.0700 

[TRAIN] Epoch[8](1068/1500); Loss: 0.073531; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.0917 0.0939 0.0740 0.0660 0.0716 0.0645 0.0626 0.0629 0.0753 0.0710 0.0706 0.0683 0.0724 0.0766 0.0774 0.0777 

[TRAIN] Epoch[8](1069/1500); Loss: 0.113717; Backpropagation: 0.0919 sec; Batch: 0.4254 sec
0.1531 0.1332 0.1209 0.1266 0.1188 0.1162 0.1142 0.1110 0.1060 0.1035 0.1035 0.0999 0.1012 0.1038 0.1046 0.1029 

[TRAIN] Epoch[8](1070/1500); Loss: 0.084924; Backpropagation: 0.0920 sec; Batch: 0.4245 sec
0.1343 0.1046 0.0888 0.0809 0.0827 0.0773 0.0782 0.0782 0.0773 0.0773 0.0788 0.0795 0.0790 0.0797 0.0807 0.0813 

[TRAIN] Epoch[8](1071/1500); Loss: 0.201191; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2975 0.2738 0.2196 0.2247 0.2193 0.2126 0.2001 0.1887 0.1812 0.1755 0.1721 0.1682 0.1659 0.1697 0.1726 0.1774 

[TRAIN] Epoch[8](1072/1500); Loss: 0.204132; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2739 0.2433 0.2090 0.2134 0.2093 0.2049 0.1949 0.1907 0.1898 0.1874 0.1888 0.1895 0.1899 0.1920 0.1928 0.1966 

[TRAIN] Epoch[8](1073/1500); Loss: 0.146773; Backpropagation: 0.0921 sec; Batch: 0.4244 sec
0.2374 0.2243 0.1716 0.1443 0.1350 0.1331 0.1344 0.1311 0.1293 0.1273 0.1273 0.1273 0.1285 0.1299 0.1321 0.1354 

[TRAIN] Epoch[8](1074/1500); Loss: 0.093428; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1211 0.1042 0.1029 0.0932 0.0897 0.0891 0.0887 0.0851 0.0843 0.0853 0.0888 0.0902 0.0906 0.0921 0.0934 0.0960 

[TRAIN] Epoch[8](1075/1500); Loss: 0.116589; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1306 0.1279 0.1165 0.1157 0.1132 0.1121 0.1110 0.1106 0.1107 0.1119 0.1132 0.1154 0.1155 0.1168 0.1203 0.1238 

[TRAIN] Epoch[8](1076/1500); Loss: 0.108574; Backpropagation: 0.0917 sec; Batch: 0.4238 sec
0.2126 0.1993 0.1000 0.0883 0.0791 0.0862 0.0862 0.1073 0.1020 0.0987 0.0935 0.0924 0.0908 0.0978 0.1014 0.1017 

[TRAIN] Epoch[8](1077/1500); Loss: 0.151053; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1893 0.1762 0.1586 0.1579 0.1563 0.1517 0.1473 0.1450 0.1438 0.1428 0.1421 0.1411 0.1423 0.1408 0.1411 0.1407 

[TRAIN] Epoch[8](1078/1500); Loss: 0.157447; Backpropagation: 0.0920 sec; Batch: 0.4243 sec
0.2060 0.1849 0.1602 0.1606 0.1593 0.1546 0.1502 0.1488 0.1487 0.1465 0.1472 0.1493 0.1492 0.1498 0.1507 0.1531 

[TRAIN] Epoch[8](1079/1500); Loss: 0.074058; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0981 0.0845 0.0820 0.0697 0.0677 0.0650 0.0670 0.0656 0.0657 0.0672 0.0718 0.0718 0.0728 0.0746 0.0801 0.0814 

[TRAIN] Epoch[8](1080/1500); Loss: 0.084575; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1348 0.1173 0.0889 0.0830 0.0834 0.0797 0.0759 0.0733 0.0733 0.0737 0.0746 0.0746 0.0771 0.0798 0.0813 0.0824 

[TRAIN] Epoch[8](1081/1500); Loss: 0.103433; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1390 0.1227 0.1098 0.1044 0.1052 0.1012 0.1005 0.0971 0.0958 0.0952 0.0979 0.0953 0.0960 0.0958 0.0997 0.0995 

[TRAIN] Epoch[8](1082/1500); Loss: 0.097564; Backpropagation: 0.0918 sec; Batch: 0.4239 sec
0.1285 0.1102 0.1051 0.1031 0.0987 0.0941 0.0946 0.0930 0.0902 0.0910 0.0910 0.0903 0.0903 0.0925 0.0939 0.0947 

[TRAIN] Epoch[8](1083/1500); Loss: 0.131843; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1636 0.1569 0.1330 0.1293 0.1315 0.1281 0.1260 0.1245 0.1239 0.1239 0.1247 0.1258 0.1267 0.1282 0.1305 0.1330 

[TRAIN] Epoch[8](1084/1500); Loss: 0.061077; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.0551 0.0516 0.0693 0.0598 0.0651 0.0562 0.0613 0.0558 0.0604 0.0574 0.0614 0.0602 0.0641 0.0638 0.0674 0.0681 

[TRAIN] Epoch[8](1085/1500); Loss: 0.086473; Backpropagation: 0.0924 sec; Batch: 0.4251 sec
0.2150 0.1981 0.0498 0.0811 0.0607 0.0699 0.0699 0.0657 0.0587 0.0643 0.0652 0.0795 0.0767 0.0750 0.0749 0.0789 

[TRAIN] Epoch[8](1086/1500); Loss: 0.158781; Backpropagation: 0.0921 sec; Batch: 0.4245 sec
0.1709 0.1710 0.1695 0.1622 0.1613 0.1575 0.1571 0.1548 0.1546 0.1545 0.1544 0.1535 0.1538 0.1548 0.1549 0.1558 

[TRAIN] Epoch[8](1087/1500); Loss: 0.133757; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1476 0.1421 0.1379 0.1344 0.1332 0.1319 0.1311 0.1307 0.1303 0.1301 0.1300 0.1307 0.1319 0.1324 0.1326 0.1332 

[TRAIN] Epoch[8](1088/1500); Loss: 0.147554; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1683 0.1579 0.1507 0.1431 0.1423 0.1406 0.1404 0.1400 0.1407 0.1416 0.1438 0.1457 0.1476 0.1499 0.1522 0.1559 

[TRAIN] Epoch[8](1089/1500); Loss: 0.083258; Backpropagation: 0.0919 sec; Batch: 0.4243 sec
0.1168 0.1011 0.0858 0.0746 0.0777 0.0750 0.0745 0.0735 0.0750 0.0775 0.0793 0.0801 0.0816 0.0832 0.0872 0.0893 

[TRAIN] Epoch[8](1090/1500); Loss: 0.092436; Backpropagation: 0.0920 sec; Batch: 0.4244 sec
0.1055 0.1031 0.0976 0.0894 0.0886 0.0863 0.0862 0.0858 0.0862 0.0876 0.0887 0.0904 0.0926 0.0952 0.0967 0.0990 

[TRAIN] Epoch[8](1091/1500); Loss: 0.184787; Backpropagation: 0.0919 sec; Batch: 0.4240 sec
0.2991 0.2551 0.1796 0.2031 0.2045 0.1989 0.1833 0.1752 0.1714 0.1675 0.1615 0.1516 0.1486 0.1521 0.1536 0.1515 

[TRAIN] Epoch[8](1092/1500); Loss: 0.161271; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2166 0.1979 0.1655 0.1562 0.1561 0.1531 0.1513 0.1518 0.1507 0.1510 0.1523 0.1537 0.1540 0.1549 0.1566 0.1587 

[TRAIN] Epoch[8](1093/1500); Loss: 0.108109; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.1356 0.1216 0.1112 0.1054 0.1056 0.1021 0.1001 0.0992 0.0997 0.1007 0.1022 0.1037 0.1062 0.1090 0.1125 0.1149 

[TRAIN] Epoch[8](1094/1500); Loss: 0.173331; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2329 0.2137 0.1792 0.1844 0.1839 0.1801 0.1716 0.1670 0.1639 0.1596 0.1578 0.1548 0.1541 0.1557 0.1567 0.1578 

[TRAIN] Epoch[8](1095/1500); Loss: 0.080916; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0978 0.0919 0.0853 0.0796 0.0777 0.0765 0.0767 0.0759 0.0764 0.0767 0.0777 0.0780 0.0793 0.0805 0.0816 0.0831 

[TRAIN] Epoch[8](1096/1500); Loss: 0.268941; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.3834 0.3439 0.2706 0.2951 0.2955 0.2907 0.2753 0.2662 0.2585 0.2501 0.2436 0.2312 0.2233 0.2263 0.2274 0.2218 

[TRAIN] Epoch[8](1097/1500); Loss: 0.076213; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.0749 0.0696 0.0674 0.0797 0.0718 0.0696 0.0689 0.0696 0.0703 0.0730 0.0753 0.0781 0.0820 0.0859 0.0895 0.0936 

[TRAIN] Epoch[8](1098/1500); Loss: 0.149609; Backpropagation: 0.0919 sec; Batch: 0.4242 sec
0.1761 0.1651 0.1466 0.1399 0.1457 0.1425 0.1404 0.1393 0.1438 0.1445 0.1455 0.1468 0.1496 0.1519 0.1564 0.1596 

[TRAIN] Epoch[8](1099/1500); Loss: 0.136768; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1522 0.1458 0.1369 0.1311 0.1315 0.1314 0.1328 0.1317 0.1319 0.1319 0.1330 0.1350 0.1367 0.1389 0.1421 0.1454 

[TRAIN] Epoch[8](1100/1500); Loss: 0.107675; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1159 0.1138 0.1127 0.1067 0.1059 0.1033 0.1037 0.1032 0.1042 0.1043 0.1049 0.1060 0.1074 0.1085 0.1101 0.1121 

[TRAIN] Epoch[8](1101/1500); Loss: 0.113155; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.1669 0.1571 0.1095 0.1083 0.1059 0.1044 0.1022 0.1013 0.1014 0.1025 0.1033 0.1051 0.1089 0.1097 0.1109 0.1132 

[TRAIN] Epoch[8](1102/1500); Loss: 0.122626; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1498 0.1396 0.1237 0.1232 0.1215 0.1188 0.1173 0.1155 0.1164 0.1164 0.1165 0.1171 0.1197 0.1209 0.1219 0.1237 

[TRAIN] Epoch[8](1103/1500); Loss: 0.205857; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2558 0.2404 0.2085 0.2098 0.2092 0.2069 0.2026 0.2005 0.1987 0.1971 0.1962 0.1944 0.1931 0.1938 0.1937 0.1930 

[TRAIN] Epoch[8](1104/1500); Loss: 0.079731; Backpropagation: 0.0921 sec; Batch: 0.4241 sec
0.1104 0.1034 0.0884 0.0795 0.0766 0.0746 0.0740 0.0730 0.0721 0.0726 0.0722 0.0730 0.0740 0.0774 0.0772 0.0773 

[TRAIN] Epoch[8](1105/1500); Loss: 0.116095; Backpropagation: 0.0920 sec; Batch: 0.4236 sec
0.1774 0.1531 0.1062 0.1070 0.1174 0.1131 0.1081 0.1060 0.1085 0.1064 0.1061 0.1054 0.1102 0.1106 0.1108 0.1111 

[TRAIN] Epoch[8](1106/1500); Loss: 0.074710; Backpropagation: 0.0926 sec; Batch: 0.4247 sec
0.0796 0.0760 0.0718 0.0720 0.0686 0.0693 0.0701 0.0707 0.0708 0.0721 0.0740 0.0748 0.0767 0.0800 0.0830 0.0860 

[TRAIN] Epoch[8](1107/1500); Loss: 0.092613; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1325 0.1177 0.0816 0.0726 0.0850 0.0817 0.0790 0.0803 0.0836 0.0835 0.0862 0.0889 0.0935 0.1012 0.1049 0.1095 

[TRAIN] Epoch[8](1108/1500); Loss: 0.161576; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.2197 0.1970 0.1541 0.1665 0.1689 0.1642 0.1576 0.1556 0.1532 0.1504 0.1493 0.1472 0.1480 0.1504 0.1510 0.1523 

[TRAIN] Epoch[8](1109/1500); Loss: 0.130578; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1655 0.1567 0.1356 0.1281 0.1258 0.1249 0.1235 0.1223 0.1219 0.1222 0.1237 0.1246 0.1255 0.1275 0.1297 0.1319 

[TRAIN] Epoch[8](1110/1500); Loss: 0.088717; Backpropagation: 0.0922 sec; Batch: 0.4241 sec
0.1066 0.0946 0.0872 0.0891 0.0868 0.0842 0.0838 0.0831 0.0828 0.0830 0.0875 0.0876 0.0880 0.0893 0.0920 0.0939 

[TRAIN] Epoch[8](1111/1500); Loss: 0.099047; Backpropagation: 0.0923 sec; Batch: 0.4242 sec
0.1556 0.1290 0.1028 0.1003 0.1012 0.0964 0.0927 0.0903 0.0896 0.0879 0.0881 0.0874 0.0890 0.0895 0.0922 0.0926 

[TRAIN] Epoch[8](1112/1500); Loss: 0.111992; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1429 0.1392 0.1077 0.1039 0.1028 0.1030 0.1027 0.1027 0.1029 0.1042 0.1064 0.1084 0.1120 0.1145 0.1173 0.1213 

[TRAIN] Epoch[8](1113/1500); Loss: 0.162087; Backpropagation: 0.0927 sec; Batch: 0.4244 sec
0.1867 0.1797 0.1720 0.1624 0.1586 0.1575 0.1568 0.1556 0.1551 0.1558 0.1569 0.1575 0.1584 0.1590 0.1605 0.1609 

[TRAIN] Epoch[8](1114/1500); Loss: 0.095636; Backpropagation: 0.0922 sec; Batch: 0.4239 sec
0.1076 0.1057 0.0953 0.0925 0.0918 0.0921 0.0915 0.0915 0.0913 0.0921 0.0931 0.0941 0.0950 0.0968 0.0988 0.1009 

[TRAIN] Epoch[8](1115/1500); Loss: 0.206713; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2386 0.2222 0.2085 0.2085 0.2095 0.2081 0.2029 0.2017 0.2008 0.1998 0.2001 0.1993 0.1996 0.2017 0.2022 0.2039 

[TRAIN] Epoch[8](1116/1500); Loss: 0.094855; Backpropagation: 0.0922 sec; Batch: 0.4244 sec
0.1620 0.1289 0.0997 0.0967 0.0964 0.0909 0.0861 0.0829 0.0819 0.0814 0.0815 0.0826 0.0843 0.0849 0.0879 0.0897 

[TRAIN] Epoch[8](1117/1500); Loss: 0.142398; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1889 0.1731 0.1374 0.1431 0.1428 0.1407 0.1372 0.1357 0.1361 0.1346 0.1340 0.1341 0.1335 0.1349 0.1354 0.1371 

[TRAIN] Epoch[8](1118/1500); Loss: 0.112801; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1576 0.1495 0.1171 0.1060 0.1058 0.1064 0.1053 0.1049 0.1044 0.1042 0.1048 0.1054 0.1069 0.1080 0.1087 0.1097 

[TRAIN] Epoch[8](1119/1500); Loss: 0.151426; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1959 0.1852 0.1460 0.1439 0.1521 0.1476 0.1436 0.1414 0.1421 0.1411 0.1428 0.1438 0.1450 0.1490 0.1509 0.1524 

[TRAIN] Epoch[8](1120/1500); Loss: 0.084997; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.0936 0.0977 0.0846 0.0825 0.0824 0.0799 0.0793 0.0798 0.0806 0.0805 0.0816 0.0837 0.0860 0.0873 0.0888 0.0917 

[TRAIN] Epoch[8](1121/1500); Loss: 0.115511; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1465 0.1370 0.1184 0.1111 0.1105 0.1078 0.1078 0.1074 0.1083 0.1115 0.1122 0.1120 0.1119 0.1133 0.1150 0.1175 

[TRAIN] Epoch[8](1122/1500); Loss: 0.076096; Backpropagation: 0.0919 sec; Batch: 0.4241 sec
0.1070 0.0978 0.0647 0.0682 0.0758 0.0708 0.0688 0.0672 0.0701 0.0707 0.0702 0.0717 0.0746 0.0785 0.0795 0.0819 

[TRAIN] Epoch[8](1123/1500); Loss: 0.066885; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.0690 0.0703 0.0669 0.0636 0.0626 0.0625 0.0632 0.0627 0.0638 0.0652 0.0659 0.0670 0.0696 0.0705 0.0728 0.0746 

[TRAIN] Epoch[8](1124/1500); Loss: 0.181942; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.2893 0.2447 0.1698 0.1954 0.1998 0.1926 0.1770 0.1714 0.1676 0.1623 0.1594 0.1532 0.1531 0.1572 0.1589 0.1594 

[TRAIN] Epoch[8](1125/1500); Loss: 0.099958; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1643 0.1492 0.1030 0.0921 0.0873 0.0882 0.0862 0.0901 0.0883 0.0920 0.0903 0.0899 0.0903 0.0954 0.0958 0.0968 

[TRAIN] Epoch[8](1126/1500); Loss: 0.119596; Backpropagation: 0.0917 sec; Batch: 0.4231 sec
0.1312 0.1265 0.1166 0.1172 0.1141 0.1130 0.1144 0.1146 0.1154 0.1157 0.1173 0.1190 0.1208 0.1232 0.1260 0.1284 

[TRAIN] Epoch[8](1127/1500); Loss: 0.153094; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.2127 0.1878 0.1565 0.1605 0.1600 0.1549 0.1468 0.1428 0.1412 0.1395 0.1387 0.1393 0.1401 0.1417 0.1428 0.1443 

[TRAIN] Epoch[8](1128/1500); Loss: 0.119247; Backpropagation: 0.0917 sec; Batch: 0.4240 sec
0.1544 0.1441 0.1288 0.1143 0.1157 0.1137 0.1132 0.1128 0.1122 0.1115 0.1122 0.1133 0.1142 0.1142 0.1161 0.1171 

[TRAIN] Epoch[8](1129/1500); Loss: 0.146754; Backpropagation: 0.0922 sec; Batch: 0.4243 sec
0.2174 0.1913 0.1530 0.1574 0.1588 0.1536 0.1443 0.1382 0.1343 0.1302 0.1269 0.1244 0.1254 0.1288 0.1307 0.1334 

[TRAIN] Epoch[8](1130/1500); Loss: 0.107042; Backpropagation: 0.0918 sec; Batch: 0.4229 sec
0.1609 0.1507 0.0979 0.0995 0.0976 0.0963 0.0953 0.0963 0.0999 0.0992 0.0996 0.1000 0.1019 0.1036 0.1059 0.1081 

[TRAIN] Epoch[8](1131/1500); Loss: 0.075683; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.0953 0.0820 0.0842 0.0744 0.0737 0.0710 0.0719 0.0726 0.0718 0.0712 0.0715 0.0730 0.0725 0.0738 0.0750 0.0770 

[TRAIN] Epoch[8](1132/1500); Loss: 0.071661; Backpropagation: 0.0917 sec; Batch: 0.4233 sec
0.1407 0.1053 0.0968 0.0771 0.0623 0.0571 0.0594 0.0622 0.0583 0.0551 0.0585 0.0659 0.0603 0.0581 0.0604 0.0690 

[TRAIN] Epoch[8](1133/1500); Loss: 0.083964; Backpropagation: 0.0919 sec; Batch: 0.4233 sec
0.0967 0.0968 0.0879 0.0831 0.0807 0.0799 0.0799 0.0794 0.0790 0.0800 0.0806 0.0820 0.0822 0.0833 0.0850 0.0870 

[TRAIN] Epoch[8](1134/1500); Loss: 0.102791; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.1490 0.1419 0.0982 0.0927 0.0906 0.0926 0.0927 0.0924 0.0923 0.0937 0.0952 0.0977 0.0998 0.1017 0.1054 0.1089 

[TRAIN] Epoch[8](1135/1500); Loss: 0.105736; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1241 0.1226 0.1141 0.1047 0.1042 0.1020 0.1008 0.1000 0.1002 0.1001 0.1008 0.1013 0.1027 0.1039 0.1048 0.1053 

[TRAIN] Epoch[8](1136/1500); Loss: 0.169260; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1911 0.1833 0.1564 0.1544 0.1627 0.1727 0.1698 0.1683 0.1676 0.1675 0.1664 0.1683 0.1677 0.1684 0.1701 0.1735 

[TRAIN] Epoch[8](1137/1500); Loss: 0.119596; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1520 0.1494 0.1184 0.1140 0.1159 0.1148 0.1138 0.1135 0.1155 0.1134 0.1132 0.1130 0.1139 0.1174 0.1175 0.1179 

[TRAIN] Epoch[8](1138/1500); Loss: 0.080117; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1410 0.1181 0.0837 0.0776 0.0769 0.0735 0.0721 0.0702 0.0693 0.0690 0.0693 0.0710 0.0717 0.0722 0.0724 0.0740 

[TRAIN] Epoch[8](1139/1500); Loss: 0.142997; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1671 0.1598 0.1457 0.1415 0.1408 0.1390 0.1378 0.1373 0.1378 0.1377 0.1389 0.1394 0.1407 0.1403 0.1420 0.1422 

[TRAIN] Epoch[8](1140/1500); Loss: 0.111731; Backpropagation: 0.0925 sec; Batch: 0.4244 sec
0.1315 0.1258 0.1226 0.1152 0.1151 0.1115 0.1095 0.1070 0.1067 0.1057 0.1047 0.1044 0.1044 0.1067 0.1076 0.1092 

[TRAIN] Epoch[8](1141/1500); Loss: 0.071108; Backpropagation: 0.0922 sec; Batch: 0.4235 sec
0.0844 0.0781 0.0681 0.0637 0.0690 0.0664 0.0658 0.0663 0.0681 0.0676 0.0695 0.0706 0.0726 0.0734 0.0766 0.0777 

[TRAIN] Epoch[8](1142/1500); Loss: 0.085098; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1123 0.1053 0.0873 0.0822 0.0794 0.0798 0.0784 0.0771 0.0787 0.0788 0.0788 0.0786 0.0847 0.0862 0.0870 0.0872 

[TRAIN] Epoch[8](1143/1500); Loss: 0.090578; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1302 0.1125 0.0942 0.0887 0.0871 0.0827 0.0802 0.0786 0.0800 0.0791 0.0800 0.0836 0.0873 0.0913 0.0947 0.0990 

[TRAIN] Epoch[8](1144/1500); Loss: 0.122685; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1359 0.1319 0.1202 0.1215 0.1204 0.1183 0.1176 0.1175 0.1174 0.1182 0.1190 0.1213 0.1229 0.1246 0.1266 0.1299 

[TRAIN] Epoch[8](1145/1500); Loss: 0.131775; Backpropagation: 0.0918 sec; Batch: 0.4234 sec
0.1878 0.1643 0.1365 0.1367 0.1386 0.1337 0.1270 0.1232 0.1215 0.1192 0.1187 0.1188 0.1185 0.1200 0.1212 0.1226 

[TRAIN] Epoch[8](1146/1500); Loss: 0.085856; Backpropagation: 0.0917 sec; Batch: 0.4234 sec
0.1001 0.0995 0.0883 0.0855 0.0846 0.0832 0.0836 0.0827 0.0822 0.0823 0.0825 0.0825 0.0832 0.0836 0.0842 0.0857 

[TRAIN] Epoch[8](1147/1500); Loss: 0.138436; Backpropagation: 0.0923 sec; Batch: 0.4239 sec
0.2128 0.1854 0.1386 0.1481 0.1525 0.1458 0.1356 0.1304 0.1272 0.1218 0.1204 0.1187 0.1178 0.1192 0.1198 0.1209 

[TRAIN] Epoch[8](1148/1500); Loss: 0.139826; Backpropagation: 0.0916 sec; Batch: 0.4226 sec
0.2340 0.2054 0.1483 0.1470 0.1444 0.1424 0.1342 0.1288 0.1242 0.1203 0.1178 0.1166 0.1166 0.1174 0.1189 0.1207 

[TRAIN] Epoch[8](1149/1500); Loss: 0.139565; Backpropagation: 0.0922 sec; Batch: 0.4247 sec
0.1608 0.1507 0.1397 0.1358 0.1390 0.1375 0.1357 0.1342 0.1348 0.1350 0.1360 0.1360 0.1367 0.1382 0.1406 0.1423 

[TRAIN] Epoch[8](1150/1500); Loss: 0.144058; Backpropagation: 0.0916 sec; Batch: 0.4235 sec
0.1876 0.1692 0.1474 0.1453 0.1451 0.1422 0.1391 0.1376 0.1374 0.1365 0.1358 0.1363 0.1363 0.1361 0.1363 0.1369 

[TRAIN] Epoch[8](1151/1500); Loss: 0.194896; Backpropagation: 0.0921 sec; Batch: 0.4238 sec
0.2457 0.2367 0.2155 0.2076 0.2033 0.1975 0.1917 0.1883 0.1853 0.1820 0.1802 0.1787 0.1769 0.1764 0.1761 0.1766 

[TRAIN] Epoch[8](1152/1500); Loss: 0.093643; Backpropagation: 0.0918 sec; Batch: 0.4230 sec
0.1044 0.1044 0.1016 0.0924 0.0924 0.0901 0.0901 0.0886 0.0895 0.0906 0.0907 0.0906 0.0911 0.0930 0.0938 0.0950 

[TRAIN] Epoch[8](1153/1500); Loss: 0.116240; Backpropagation: 0.0920 sec; Batch: 0.4232 sec
0.1359 0.1314 0.1111 0.1055 0.1097 0.1095 0.1101 0.1107 0.1119 0.1123 0.1133 0.1153 0.1183 0.1194 0.1218 0.1238 

[TRAIN] Epoch[8](1154/1500); Loss: 0.126389; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1536 0.1471 0.1272 0.1264 0.1237 0.1221 0.1214 0.1199 0.1195 0.1197 0.1204 0.1212 0.1228 0.1242 0.1258 0.1272 

[TRAIN] Epoch[8](1155/1500); Loss: 0.097178; Backpropagation: 0.0920 sec; Batch: 0.4233 sec
0.2211 0.2025 0.0872 0.0732 0.0638 0.0743 0.0733 0.0762 0.0730 0.0923 0.0874 0.0887 0.0852 0.0857 0.0843 0.0866 

[TRAIN] Epoch[8](1156/1500); Loss: 0.081501; Backpropagation: 0.0918 sec; Batch: 0.4236 sec
0.0971 0.0857 0.1009 0.0839 0.0838 0.0803 0.0790 0.0793 0.0775 0.0766 0.0758 0.0758 0.0756 0.0762 0.0777 0.0787 

[TRAIN] Epoch[8](1157/1500); Loss: 0.082810; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1407 0.1172 0.0918 0.0871 0.0859 0.0814 0.0759 0.0730 0.0711 0.0696 0.0688 0.0697 0.0707 0.0719 0.0741 0.0761 

[TRAIN] Epoch[8](1158/1500); Loss: 0.086734; Backpropagation: 0.0919 sec; Batch: 0.4234 sec
0.1159 0.1117 0.0962 0.0848 0.0817 0.0812 0.0809 0.0800 0.0797 0.0814 0.0813 0.0805 0.0815 0.0838 0.0837 0.0836 

[TRAIN] Epoch[8](1159/1500); Loss: 0.158726; Backpropagation: 0.0922 sec; Batch: 0.4236 sec
0.1803 0.1789 0.1579 0.1590 0.1544 0.1550 0.1539 0.1537 0.1540 0.1548 0.1540 0.1542 0.1552 0.1571 0.1581 0.1592 

[TRAIN] Epoch[8](1160/1500); Loss: 0.102044; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1401 0.1266 0.1049 0.1028 0.1050 0.1020 0.0986 0.0959 0.0947 0.0927 0.0940 0.0931 0.0930 0.0946 0.0963 0.0986 

[TRAIN] Epoch[8](1161/1500); Loss: 0.103424; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1129 0.1070 0.0976 0.0951 0.0985 0.0977 0.0963 0.0956 0.0979 0.0990 0.1014 0.1046 0.1074 0.1108 0.1145 0.1184 

[TRAIN] Epoch[8](1162/1500); Loss: 0.294651; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.4483 0.3964 0.3070 0.3390 0.3404 0.3341 0.3106 0.2981 0.2862 0.2659 0.2572 0.2459 0.2279 0.2246 0.2215 0.2113 

[TRAIN] Epoch[8](1163/1500); Loss: 0.119227; Backpropagation: 0.0920 sec; Batch: 0.4240 sec
0.1350 0.1292 0.1207 0.1193 0.1174 0.1156 0.1158 0.1147 0.1141 0.1147 0.1160 0.1166 0.1177 0.1193 0.1199 0.1216 

[TRAIN] Epoch[8](1164/1500); Loss: 0.221222; Backpropagation: 0.0921 sec; Batch: 0.4239 sec
0.3069 0.2791 0.2249 0.2375 0.2369 0.2339 0.2228 0.2179 0.2133 0.2048 0.2018 0.1988 0.1927 0.1904 0.1900 0.1879 

[TRAIN] Epoch[8](1165/1500); Loss: 0.083741; Backpropagation: 0.0924 sec; Batch: 0.4241 sec
0.1224 0.1029 0.0895 0.0823 0.0831 0.0790 0.0768 0.0756 0.0766 0.0764 0.0781 0.0782 0.0788 0.0793 0.0805 0.0804 

[TRAIN] Epoch[8](1166/1500); Loss: 0.093349; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1198 0.1085 0.1040 0.0988 0.0950 0.0912 0.0882 0.0870 0.0884 0.0864 0.0852 0.0851 0.0869 0.0877 0.0891 0.0922 

[TRAIN] Epoch[8](1167/1500); Loss: 0.171197; Backpropagation: 0.0921 sec; Batch: 0.4243 sec
0.2333 0.2082 0.1797 0.1806 0.1798 0.1743 0.1652 0.1596 0.1573 0.1551 0.1560 0.1570 0.1574 0.1576 0.1583 0.1597 

[TRAIN] Epoch[8](1168/1500); Loss: 0.194152; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2500 0.2298 0.2051 0.2044 0.2036 0.1991 0.1918 0.1872 0.1842 0.1808 0.1799 0.1786 0.1777 0.1775 0.1781 0.1787 

[TRAIN] Epoch[8](1169/1500); Loss: 0.176482; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.2256 0.2112 0.1851 0.1756 0.1744 0.1749 0.1727 0.1699 0.1687 0.1676 0.1667 0.1663 0.1660 0.1661 0.1664 0.1665 

[TRAIN] Epoch[8](1170/1500); Loss: 0.087563; Backpropagation: 0.0918 sec; Batch: 0.4240 sec
0.2137 0.1969 0.0502 0.0801 0.0605 0.0749 0.0754 0.0718 0.0636 0.0676 0.0649 0.0642 0.0787 0.0788 0.0803 0.0795 

[TRAIN] Epoch[8](1171/1500); Loss: 0.119338; Backpropagation: 0.0921 sec; Batch: 0.4240 sec
0.1310 0.1306 0.1237 0.1172 0.1163 0.1143 0.1159 0.1156 0.1156 0.1156 0.1170 0.1171 0.1185 0.1193 0.1204 0.1212 

[TRAIN] Epoch[8](1172/1500); Loss: 0.168536; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.2255 0.2069 0.1694 0.1703 0.1723 0.1679 0.1620 0.1588 0.1569 0.1552 0.1548 0.1554 0.1575 0.1593 0.1608 0.1635 

[TRAIN] Epoch[8](1173/1500); Loss: 0.128302; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1562 0.1474 0.1283 0.1233 0.1248 0.1226 0.1213 0.1213 0.1240 0.1230 0.1229 0.1244 0.1261 0.1272 0.1289 0.1310 

[TRAIN] Epoch[8](1174/1500); Loss: 0.111640; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1487 0.1431 0.1163 0.1091 0.1082 0.1078 0.1063 0.1051 0.1043 0.1038 0.1038 0.1047 0.1051 0.1061 0.1067 0.1073 

[TRAIN] Epoch[8](1175/1500); Loss: 0.092337; Backpropagation: 0.0919 sec; Batch: 0.4237 sec
0.1081 0.1013 0.1070 0.0932 0.0923 0.0884 0.0904 0.0884 0.0869 0.0850 0.0853 0.0860 0.0882 0.0899 0.0920 0.0949 

[TRAIN] Epoch[8](1176/1500); Loss: 0.124741; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1788 0.1582 0.1237 0.1254 0.1250 0.1214 0.1179 0.1163 0.1149 0.1143 0.1150 0.1156 0.1165 0.1172 0.1177 0.1180 

[TRAIN] Epoch[8](1177/1500); Loss: 0.123477; Backpropagation: 0.0922 sec; Batch: 0.4242 sec
0.1228 0.1295 0.1284 0.1280 0.1228 0.1227 0.1218 0.1206 0.1199 0.1201 0.1215 0.1210 0.1220 0.1228 0.1257 0.1262 

[TRAIN] Epoch[8](1178/1500); Loss: 0.074701; Backpropagation: 0.0917 sec; Batch: 0.4236 sec
0.0852 0.0837 0.0847 0.0742 0.0697 0.0686 0.0685 0.0691 0.0694 0.0697 0.0708 0.0734 0.0743 0.0758 0.0778 0.0802 

[TRAIN] Epoch[8](1179/1500); Loss: 0.069120; Backpropagation: 0.0920 sec; Batch: 0.4235 sec
0.1133 0.0890 0.0756 0.0675 0.0692 0.0635 0.0626 0.0598 0.0607 0.0588 0.0611 0.0613 0.0650 0.0644 0.0665 0.0675 

[TRAIN] Epoch[8](1180/1500); Loss: 0.094115; Backpropagation: 0.0918 sec; Batch: 0.4238 sec
0.1160 0.1087 0.0975 0.0919 0.0913 0.0899 0.0895 0.0881 0.0882 0.0906 0.0897 0.0900 0.0919 0.0942 0.0936 0.0947 

[TRAIN] Epoch[8](1181/1500); Loss: 0.119659; Backpropagation: 0.0920 sec; Batch: 0.4242 sec
0.1443 0.1322 0.1197 0.1168 0.1173 0.1155 0.1136 0.1136 0.1141 0.1138 0.1153 0.1165 0.1185 0.1197 0.1212 0.1225 

[TRAIN] Epoch[8](1182/1500); Loss: 0.070491; Backpropagation: 0.0918 sec; Batch: 0.4233 sec
0.1058 0.0939 0.0723 0.0655 0.0668 0.0632 0.0611 0.0606 0.0617 0.0630 0.0630 0.0647 0.0672 0.0707 0.0735 0.0749 

[TRAIN] Epoch[8](1183/1500); Loss: 0.113693; Backpropagation: 0.0922 sec; Batch: 0.4237 sec
0.1226 0.1238 0.1200 0.1152 0.1133 0.1126 0.1125 0.1105 0.1098 0.1105 0.1108 0.1106 0.1102 0.1111 0.1126 0.1129 

[TRAIN] Epoch[8](1184/1500); Loss: 0.150387; Backpropagation: 0.0918 sec; Batch: 0.4237 sec
0.2340 0.2141 0.1614 0.1473 0.1484 0.1522 0.1446 0.1416 0.1381 0.1354 0.1339 0.1320 0.1309 0.1308 0.1310 0.1304 

[TRAIN] Epoch[8](1185/1500); Loss: 0.159196; Backpropagation: 0.0920 sec; Batch: 0.4239 sec
0.2004 0.1860 0.1634 0.1645 0.1640 0.1611 0.1570 0.1550 0.1534 0.1514 0.1497 0.1488 0.1481 0.1476 0.1479 0.1489 

[TRAIN] Epoch[8](1186/1500); Loss: 0.127473; Backpropagation: 0.0918 sec; Batch: 0.4235 sec
0.1497 0.1355 0.1311 0.1258 0.1264 0.1238 0.1234 0.1224 0.1221 0.1225 0.1238 0.1240 0.1251 0.1267 0.1283 0.1290 

[TRAIN] Epoch[8](1187/1500); Loss: 0.126036; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.1356 0.1397 0.1290 0.1286 0.1278 0.1270 0.1248 0.1233 0.1222 0.1217 0.1218 0.1217 0.1222 0.1222 0.1238 0.1252 

[TRAIN] Epoch[8](1188/1500); Loss: 0.117644; Backpropagation: 0.0918 sec; Batch: 0.4227 sec
0.1354 0.1362 0.1251 0.1200 0.1161 0.1158 0.1150 0.1139 0.1138 0.1128 0.1127 0.1121 0.1129 0.1134 0.1133 0.1138 

[TRAIN] Epoch[8](1189/1500); Loss: 0.162262; Backpropagation: 0.0921 sec; Batch: 0.4235 sec
0.2520 0.2176 0.1708 0.1833 0.1818 0.1723 0.1619 0.1553 0.1497 0.1424 0.1404 0.1368 0.1338 0.1332 0.1325 0.1324 

[TRAIN] Epoch[8](1190/1500); Loss: 0.151282; Backpropagation: 0.0919 sec; Batch: 0.4236 sec
0.1549 0.1573 0.1557 0.1514 0.1507 0.1505 0.1495 0.1486 0.1495 0.1505 0.1490 0.1490 0.1501 0.1507 0.1511 0.1520 

[TRAIN] Epoch[8](1191/1500); Loss: 0.102844; Backpropagation: 0.0919 sec; Batch: 0.4232 sec
0.1132 0.1097 0.1009 0.1006 0.0995 0.0994 0.0995 0.1003 0.0996 0.1005 0.1010 0.1021 0.1032 0.1044 0.1048 0.1068 

[TRAIN] Epoch[8](1192/1500); Loss: 0.100246; Backpropagation: 0.0919 sec; Batch: 0.4239 sec
0.1446 0.1191 0.1195 0.1046 0.1021 0.0960 0.0947 0.0921 0.0904 0.0890 0.0897 0.0915 0.0924 0.0915 0.0919 0.0949 

[TRAIN] Epoch[8](1193/1500); Loss: 0.160823; Backpropagation: 0.0920 sec; Batch: 0.4231 sec
0.2098 0.1881 0.1779 0.1692 0.1680 0.1611 0.1564 0.1533 0.1521 0.1494 0.1495 0.1477 0.1481 0.1475 0.1480 0.1469 

[TRAIN] Epoch[8](1194/1500); Loss: 0.111788; Backpropagation: 0.0920 sec; Batch: 0.4238 sec
0.1407 0.1267 0.1220 0.1155 0.1111 0.1079 0.1061 0.1044 0.1046 0.1039 0.1045 0.1062 0.1076 0.1077 0.1088 0.1108 

[TRAIN] Epoch[8](1195/1500); Loss: 0.080756; Backpropagation: 0.0920 sec; Batch: 0.4237 sec
0.1543 0.1443 0.0764 0.0674 0.0640 0.0679 0.0678 0.0692 0.0686 0.0687 0.0682 0.0706 0.0728 0.0746 0.0773 0.0798 

[TRAIN] Epoch[8](1196/1500); Loss: 0.115398; Backpropagation: 0.0921 sec; Batch: 0.4237 sec
0.1368 0.1251 0.1185 0.1152 0.1151 0.1125 0.1120 0.1126 0.1125 0.1107 0.1111 0.1117 0.1126 0.1125 0.1133 0.1141 

[TRAIN] Epoch[8](1197/1500); Loss: 0.174617; Backpropagation: 0.0917 sec; Batch: 0.4239 sec
0.2333 0.2145 0.1845 0.1897 0.1898 0.1849 0.1766 0.1724 0.1687 0.1621 0.1598 0.1571 0.1526 0.1502 0.1490 0.1486 

[TRAIN] Epoch[8](1198/1500); Loss: 0.168154; Backpropagation: 0.0919 sec; Batch: 0.4238 sec
0.2465 0.2160 0.1808 0.1818 0.1797 0.1730 0.1642 0.1593 0.1564 0.1523 0.1496 0.1474 0.1462 0.1456 0.1458 0.1458 

[TRAIN] Epoch[8](1199/1500); Loss: 0.168231; Backpropagation: 0.0919 sec; Batch: 0.4235 sec
0.1960 0.1733 0.1690 0.1543 0.1476 0.1441 0.1487 0.1491 0.1554 0.1625 0.1655 0.1718 0.1789 0.1848 0.1920 0.1988 

[TRAIN] Epoch[8](1200/1500); Loss: 0.155146; Backpropagation: 0.0921 sec; Batch: 0.4234 sec
0.2628 0.2183 0.1527 0.1728 0.1742 0.1638 0.1487 0.1411 0.1364 0.1309 0.1310 0.1298 0.1292 0.1282 0.1295 0.1329 

[TRAIN] Epoch[8](1201/1500); Loss: 0.135043; Backpropagation: 0.0921 sec; Batch: 0.4230 sec
0.1455 0.1423 0.1429 0.1305 0.1416 0.1381 0.1366 0.1318 0.1313 0.1289 0.1315 0.1294 0.1297 0.1316 0.1336 0.1354 

[TRAIN] Epoch[8](1202/1500); Loss: 0.114427; Backpropagation: 0.0918 sec; Batch: 0.4238 secTraceback (most recent call last):
  File "train.py", line 7, in <module>
    import torch
ImportError: No module named torch
